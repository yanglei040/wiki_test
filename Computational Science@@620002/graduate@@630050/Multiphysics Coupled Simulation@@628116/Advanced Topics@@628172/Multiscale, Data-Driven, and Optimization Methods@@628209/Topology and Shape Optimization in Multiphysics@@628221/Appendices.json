{"hands_on_practices": [{"introduction": "This first exercise provides a foundational experience in formulating and solving a multiphysics topology optimization problem from first principles. You will explore how to combine competing objectives—in this case, mechanical and thermal performance—into a single function using a weighted-sum approach. By applying the classic Solid Isotropic Material with Penalization (SIMP) model and the method of Lagrange multipliers to a simple one-dimensional bar, this problem builds the essential analytical skills needed to understand the core trade-offs in multiphysics design [@problem_id:3530728].", "problem": "Consider a one-dimensional, non-dimensionalized two-physics design problem on a bar discretized into two equal finite elements (indexed by $i \\in \\{1,2\\}$), each of length $1$ and cross-sectional area $1$. The bar is subjected to a quasi-static end force $F$ in linear elasticity and a steady end heat flux $Q$ in thermal conduction. The task is to distribute material via two element-wise design densities $\\rho_{1}$ and $\\rho_{2}$, with a Solid Isotropic Material with Penalization (SIMP) interpolation, to minimize a weighted sum of the mechanical and thermal compliances under a global volume constraint. The SIMP law is $E(\\rho_{i})=\\rho_{i}^{p} E_{0}$ for the Young’s modulus and $k(\\rho_{i})=\\rho_{i}^{p} k_{0}$ for the thermal conductivity, with the same penalization exponent $p$ for both physics. Assume negligible lower-bound regularization for $\\rho_{i}$ so that interior solutions are admissible. The optimization is carried out under non-dimensionalization such that $A=1$, $L_{i}=1$, $E_{0}=1$, $k_{0}=1$, $F=1$, and $Q=1$.\n\nStart from the following fundamental bases:\n- Linear momentum balance in one dimension, Hooke’s law, and strain energy for linear elasticity, and Fourier’s law and steady energy balance for thermal conduction.\n- The definitions of mechanical compliance as $F$ times the end displacement and thermal compliance as $Q$ times the end temperature rise, both expressible in one-dimensional series form through element properties.\n\nUsing these principles, derive the one-dimensional series expressions for the mechanical and thermal compliance in terms of $\\rho_{i}$ and $p$, and then formulate the weighted objective\n$$\nJ(\\rho_{1},\\rho_{2})=\\sum_{i=1}^{2}\\left(\\alpha\\,w_{i}\\,C_{\\text{mech},i}(\\rho_{i})+\\beta\\,t_{i}\\,C_{\\text{therm},i}(\\rho_{i})\\right),\n$$\nwhere $w_{i}$ and $t_{i}$ are given non-dimensional spatial weights and $\\alpha$ and $\\beta$ are positive scalars. Impose the volume constraint $\\rho_{1}+\\rho_{2}=1$ and assume a common penalization exponent $p=3$.\n\nGiven the specific data $\\alpha=1$, $\\beta=1$, $w_{1}=4$, $w_{2}=\\frac{1}{6}$, $t_{1}=\\frac{4}{3}$, $t_{2}=\\frac{1}{6}$, $p=3$, and the non-dimensionalization above, carry out the following:\n- Derive the first-order necessary optimality conditions for $(\\rho_{1},\\rho_{2})$ using a Lagrangian with a single multiplier for the volume constraint.\n- Solve these conditions explicitly to obtain the optimal $\\rho_{1}$.\n\nExpress your final answer for the optimal $\\rho_{1}$ as an exact fraction. Do not include units, and do not report an inequality or an equation, only the value. No rounding is required.", "solution": "The problem is validated as follows.\n\n**Step 1: Extract Givens**\n- **Domain**: A one-dimensional bar discretized into two equal finite elements, indexed by $i \\in \\{1,2\\}$.\n- **Geometry**: Each element has length $L_i=1$ and cross-sectional area $A_i=1$.\n- **Physics**: Quasi-static linear elasticity and steady-state thermal conduction.\n- **Loading**: An end force $F$ and an end heat flux $Q$.\n- **Material Model**: Solid Isotropic Material with Penalization (SIMP) with $E(\\rho_{i})=\\rho_{i}^{p} E_{0}$ for Young's modulus and $k(\\rho_{i})=\\rho_{i}^{p} k_{0}$ for thermal conductivity.\n- **Design Variables**: Element-wise material densities $\\rho_1$ and $\\rho_2$.\n- **Objective Function**: Minimize a weighted sum of compliances $J(\\rho_{1},\\rho_{2})=\\sum_{i=1}^{2}\\left(\\alpha\\,w_{i}\\,C_{\\text{mech},i}(\\rho_{i})+\\beta\\,t_{i}\\,C_{\\text{therm},i}(\\rho_{i})\\right)$.\n- **Constraint**: A global volume constraint $\\rho_1 + \\rho_2 = 1$.\n- **Constants and Parameters**:\n  - Non-dimensionalization: $A=1$, $L_i=1$, $E_0=1$, $k_0=1$, $F=1$, $Q=1$.\n  - Penalization exponent: $p=3$.\n  - Weighting factors: $\\alpha=1$, $\\beta=1$.\n  - Spatial weights: $w_{1}=4$, $w_{2}=\\frac{1}{6}$, $t_{1}=\\frac{4}{3}$, $t_{2}=\\frac{1}{6}$.\n- **Fundamental Principles**:\n  - Linear momentum balance, Hooke’s law, and strain energy for linear elasticity.\n  - Fourier’s law and steady energy balance for thermal conduction.\n  - Definitions of mechanical compliance ($F$ times end displacement) and thermal compliance ($Q$ times end temperature rise).\n- **Task**: Derive the first-order necessary optimality conditions and solve for the optimal $\\rho_1$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded**: The problem is based on fundamental principles of continuum mechanics (linear elasticity and heat conduction) and a standard method in structural optimization (SIMP). It is scientifically sound.\n- **Well-Posed**: The problem is a constrained optimization problem. The objective function is a sum of functions of the form $c \\rho^{-p}$, which is convex for $\\rho > 0$. The constraint is linear. This structure generally leads to a unique, stable solution. The problem is well-posed.\n- **Objective**: The language is precise, and all parameters are GIVEN explicitly. There is no subjective or ambiguous terminology.\n- **Other Flaws**: The problem is self-contained, consistent, and feasible within the context of an academic optimization problem. It is not trivial or tautological.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A solution will be derived.\n\n**Derivation of the Solution**\n\nFirst, we derive the expressions for the elemental compliances. For a system of two elements in series, the total force $F$ is transmitted through each element in the mechanical problem, and the total heat flux $Q$ flows through each element in the thermal problem.\n\nThe mechanical compliance contribution of element $i$ is related to its strain energy. The stiffness of a 1D bar element is $k_{\\text{mech},i} = \\frac{A_i E_i}{L_i}$. The total mechanical compliance of the system is the sum of the elemental contributions, where the contribution of element $i$ is given by $C_{\\text{mech},i} = \\frac{F^2 L_i}{A_i E_i}$.\nUsing the SIMP law, $E_i = E(\\rho_i) = \\rho_i^p E_0$.\nSo, $C_{\\text{mech},i}(\\rho_i) = \\frac{F^2 L_i}{A_i \\rho_i^p E_0}$.\n\nSimilarly, the thermal conductance of a 1D element is $k_{\\text{therm},i} = \\frac{A_i k_i}{L_i}$. The total thermal compliance is the sum of elemental contributions, with the contribution from element $i$ being $C_{\\text{therm},i} = \\frac{Q^2 L_i}{A_i k_i}$.\nUsing the SIMP law, $k_i = k(\\rho_i) = \\rho_i^p k_0$.\nSo, $C_{\\text{therm},i}(\\rho_i) = \\frac{Q^2 L_i}{A_i \\rho_i^p k_0}$.\n\nWe apply the non-dimensionalization: $A_i=1$, $L_i=1$, $E_0=1$, $k_0=1$, $F=1$, $Q=1$.\nThe compliance expressions simplify to:\n$C_{\\text{mech},i}(\\rho_i) = \\frac{1^2 \\cdot 1}{1 \\cdot \\rho_i^p \\cdot 1} = \\frac{1}{\\rho_i^p} = \\rho_i^{-p}$.\n$C_{\\text{therm},i}(\\rho_i) = \\frac{1^2 \\cdot 1}{1 \\cdot \\rho_i^p \\cdot 1} = \\frac{1}{\\rho_i^p} = \\rho_i^{-p}$.\n\nThe objective function to be minimized is:\n$J(\\rho_1, \\rho_2) = \\sum_{i=1}^{2} (\\alpha w_i C_{\\text{mech},i}(\\rho_i) + \\beta t_i C_{\\text{therm},i}(\\rho_i))$.\nSubstituting the compliance expressions:\n$J(\\rho_1, \\rho_2) = (\\alpha w_1 + \\beta t_1) \\rho_1^{-p} + (\\alpha w_2 + \\beta t_2) \\rho_2^{-p}$.\nLet us define sensitivity numbers $S_i = \\alpha w_i + \\beta t_i$. The objective function becomes:\n$J(\\rho_1, \\rho_2) = S_1 \\rho_1^{-p} + S_2 \\rho_2^{-p}$.\n\nThe optimization problem is:\nMinimize $J(\\rho_1, \\rho_2) = S_1 \\rho_1^{-p} + S_2 \\rho_2^{-p}$\nsubject to the constraint $g(\\rho_1, \\rho_2) = \\rho_1 + \\rho_2 - 1 = 0$.\n\nWe use the method of Lagrange multipliers. The Lagrangian function is:\n$\\mathcal{L}(\\rho_1, \\rho_2, \\lambda) = J(\\rho_1, \\rho_2) + \\lambda g(\\rho_1, \\rho_2) = S_1 \\rho_1^{-p} + S_2 \\rho_2^{-p} + \\lambda(\\rho_1 + \\rho_2 - 1)$.\n\nThe first-order necessary optimality conditions are obtained by setting the partial derivatives of the Lagrangian with respect to $\\rho_1$, $\\rho_2$, and $\\lambda$ to zero:\n1. $\\frac{\\partial \\mathcal{L}}{\\partial \\rho_1} = -p S_1 \\rho_1^{-p-1} + \\lambda = 0 \\implies \\lambda = p S_1 \\rho_1^{-p-1}$.\n2. $\\frac{\\partial \\mathcal{L}}{\\partial \\rho_2} = -p S_2 \\rho_2^{-p-1} + \\lambda = 0 \\implies \\lambda = p S_2 \\rho_2^{-p-1}$.\n3. $\\frac{\\partial \\mathcal{L}}{\\partial \\lambda} = \\rho_1 + \\rho_2 - 1 = 0$.\n\nEquating the two expressions for the Lagrange multiplier $\\lambda$:\n$p S_1 \\rho_1^{-p-1} = p S_2 \\rho_2^{-p-1}$\n$S_1 \\rho_1^{-p-1} = S_2 \\rho_2^{-p-1}$\n$\\frac{\\rho_2^{-p-1}}{\\rho_1^{-p-1}} = \\frac{S_1}{S_2}$\n$\\left(\\frac{\\rho_1}{\\rho_2}\\right)^{p+1} = \\frac{S_1}{S_2}$\n$\\frac{\\rho_1}{\\rho_2} = \\left(\\frac{S_1}{S_2}\\right)^{\\frac{1}{p+1}}$.\n\nFrom the constraint, we have $\\rho_2 = 1 - \\rho_1$. Substituting this into the equation:\n$\\frac{\\rho_1}{1 - \\rho_1} = \\left(\\frac{S_1}{S_2}\\right)^{\\frac{1}{p+1}}$.\nLet $R = \\left(\\frac{S_1}{S_2}\\right)^{\\frac{1}{p+1}}$. Then $\\rho_1 = R(1 - \\rho_1) = R - R\\rho_1$.\n$\\rho_1 (1 + R) = R$.\n$\\rho_1 = \\frac{R}{1+R} = \\frac{\\left(\\frac{S_1}{S_2}\\right)^{\\frac{1}{p+1}}}{1+\\left(\\frac{S_1}{S_2}\\right)^{\\frac{1}{p+1}}}$.\nThis can also be written as $\\rho_1 = \\frac{1}{1 + \\left(\\frac{S_2}{S_1}\\right)^{\\frac{1}{p+1}}}$.\n\nNow, we substitute the given numerical values:\n$\\alpha=1$, $\\beta=1$, $p=3$.\n$w_1=4$, $w_2=\\frac{1}{6}$.\n$t_1=\\frac{4}{3}$, $t_2=\\frac{1}{6}$.\n\nFirst, calculate the sensitivities $S_1$ and $S_2$:\n$S_1 = \\alpha w_1 + \\beta t_1 = (1)(4) + (1)(\\frac{4}{3}) = 4 + \\frac{4}{3} = \\frac{12}{3} + \\frac{4}{3} = \\frac{16}{3}$.\n$S_2 = \\alpha w_2 + \\beta t_2 = (1)(\\frac{1}{6}) + (1)(\\frac{1}{6}) = \\frac{1}{6} + \\frac{1}{6} = \\frac{2}{6} = \\frac{1}{3}$.\n\nNext, calculate the ratio $\\frac{S_2}{S_1}$:\n$\\frac{S_2}{S_1} = \\frac{1/3}{16/3} = \\frac{1}{3} \\cdot \\frac{3}{16} = \\frac{1}{16}$.\n\nThe exponent is $\\frac{1}{p+1} = \\frac{1}{3+1} = \\frac{1}{4}$.\nNow compute the term $\\left(\\frac{S_2}{S_1}\\right)^{\\frac{1}{p+1}}$:\n$\\left(\\frac{1}{16}\\right)^{\\frac{1}{4}} = \\frac{1^{1/4}}{16^{1/4}} = \\frac{1}{\\sqrt[4]{16}} = \\frac{1}{2}$.\n\nFinally, we calculate the optimal $\\rho_1$:\n$\\rho_1 = \\frac{1}{1 + \\frac{1}{2}} = \\frac{1}{\\frac{3}{2}} = \\frac{2}{3}$.\n\nThe optimal density for element $1$ is $\\frac{2}{3}$. Consequently, the optimal density for element $2$ is $\\rho_2 = 1 - \\rho_1 = 1 - \\frac{2}{3} = \\frac{1}{3}$. Both are valid interior solutions ($0 < \\rho_i < 1$).", "answer": "$$\\boxed{\\frac{2}{3}}$$", "id": "3530728"}, {"introduction": "Building upon the basics of objective formulation, this practice introduces the critical concept of performance constraints, which are common in real-world engineering. Here, you will tackle a problem where the goal is to optimize a thermal characteristic (minimizing the thermal time constant) while satisfying a strict constraint on mechanical stability, defined by a minimum natural frequency. This exercise [@problem_id:3530732] demonstrates how to handle eigenvalue-based constraints, a crucial skill for designing systems where dynamic response, vibration, or buckling are key considerations.", "problem": "A uniform bar-like design domain of length $L$ and cross-sectional area $A$ is embedded in a coupled thermoelastic device. A single pseudo-density design variable $x \\in [0,1]$ uniformly scales the local material distribution via the Solid Isotropic Material with Penalization (SIMP) model. The elastic modulus, mass density, and thermal conductivity are modeled as $E(x) = E_{0} x^{p}$, $\\rho(x) = \\rho_{0} x$, and $k(x) = k_{0} x^{q}$, respectively, where $p$ and $q$ are given positive exponents. The device-level objective is to minimize the dominant thermal time constant of the bar while guaranteeing a minimum mechanical vibration stability margin expressed as a lower bound on the fundamental natural frequency.\n\nUse the following fundamental bases:\n\n- Newton’s second law and Hooke’s law for a single-degree-of-freedom lumped mechanical oscillator: if the effective stiffness is $k_{m}(x)$ and the effective mass is $m(x)$, then the free vibration equation is $m(x) \\ddot{u} + k_{m}(x) u = 0$, whose harmonic solution $u(t) = U \\exp(\\mathrm{i} \\omega t)$ implies $\\omega^{2}(x) = k_{m}(x)/m(x)$.\n\n- Energy conservation with Fourier’s law for one-dimensional heat conduction: $\\rho(x) c \\, \\partial T/\\partial t = k(x) \\, \\partial^{2} T/\\partial X^{2}$ on $X \\in (0,L)$ with homogeneous Dirichlet boundary conditions $T(0,t) = 0$ and $T(L,t) = 0$. Separation of variables yields exponentially decaying modes with decay rates $\\lambda_{n}(x) = (k(x)/(\\rho(x)c)) (n \\pi/L)^{2}$ for $n \\in \\mathbb{N}$. The dominant thermal time constant is $\\tau(x) = 1/\\lambda_{1}(x) = (\\rho(x) c L^{2})/(\\pi^{2} k(x))$.\n\nAssume a consistent one-dimensional finite element condensation produces an effective stiffness $k_{m}(x) = k_{m0} x^{p}$ and an effective lumped mass $m(x) = m_{0} x$, with known positive constants $k_{m0}$ and $m_{0}$. Suppose the design must satisfy the eigenvalue-based mechanical stability constraint $\\omega(x) \\ge \\omega_{\\min}$.\n\nGiven the parameters $p = 3$, $q = \\tfrac{1}{2}$, $k_{m0} = 9$, $m_{0} = 1$, and $\\omega_{\\min} = 2$ (with all mechanical quantities in consistent coherent units, and $c$ and $L$ arbitrary but fixed and positive), formulate the scalar topology optimization problem\n$$\n\\min_{0 \\le x \\le 1} \\ \\tau(x) \\quad \\text{subject to} \\quad \\omega(x) \\ge \\omega_{\\min},\n$$\nusing the fundamental laws above. Then, determine the optimal pseudo-density $x^{\\star}$ that solves this problem. Express your final answer for $x^{\\star}$ as an exact number with no units.", "solution": "The problem statement has been critically examined and is determined to be valid. All provided information is scientifically grounded, self-contained, and well-posed. The problem is a standard scalar constrained optimization problem derived from fundamental principles of mechanics and heat transfer, as applied in the context of topology optimization using the Solid Isotropic Material with Penalization (SIMP) model.\n\nThe task is to find the optimal pseudo-density $x^{\\star}$ that solves the following problem:\n$$\n\\min_{0 \\le x \\le 1} \\ \\tau(x) \\quad \\text{subject to} \\quad \\omega(x) \\ge \\omega_{\\min}\n$$\n\nFirst, we express the objective function, the thermal time constant $\\tau(x)$, and the constraint function, the natural frequency $\\omega(x)$, in terms of the design variable $x$.\n\nThe thermal time constant is given by:\n$$\n\\tau(x) = \\frac{\\rho(x) c L^{2}}{\\pi^{2} k(x)}\n$$\nUsing the SIMP relations $\\rho(x) = \\rho_{0} x$ and $k(x) = k_{0} x^{q}$, we substitute these into the expression for $\\tau(x)$:\n$$\n\\tau(x) = \\frac{(\\rho_{0} x) c L^{2}}{\\pi^{2} (k_{0} x^{q})} = \\left(\\frac{\\rho_{0} c L^{2}}{\\pi^{2} k_{0}}\\right) x^{1-q}\n$$\nThe term in the parenthesis is a positive constant, which we can denote as $C_{\\tau} = \\frac{\\rho_{0} c L^{2}}{\\pi^{2} k_{0}}$. The specific value of this constant is not needed to find the optimal $x$. Using the given parameter $q = \\frac{1}{2}$, the objective function becomes:\n$$\n\\tau(x) = C_{\\tau} x^{1 - \\frac{1}{2}} = C_{\\tau} x^{\\frac{1}{2}}\n$$\n\nNext, we formulate the constraint. The squared natural frequency is given by:\n$$\n\\omega^{2}(x) = \\frac{k_{m}(x)}{m(x)}\n$$\nThe problem specifies the effective stiffness $k_{m}(x) = k_{m0} x^{p}$ and the effective mass $m(x) = m_{0} x$. Substituting these gives:\n$$\n\\omega^{2}(x) = \\frac{k_{m0} x^{p}}{m_{0} x} = \\frac{k_{m0}}{m_{0}} x^{p-1}\n$$\nThe natural frequency is the square root of this expression. Since $x \\in [0,1]$, we have:\n$$\n\\omega(x) = \\sqrt{\\frac{k_{m0}}{m_{0}}} x^{\\frac{p-1}{2}}\n$$\nWe now substitute the given parameter values $p=3$, $k_{m0}=9$, and $m_{0}=1$:\n$$\n\\omega(x) = \\sqrt{\\frac{9}{1}} x^{\\frac{3-1}{2}} = 3 x^{\\frac{2}{2}} = 3x\n$$\nThe mechanical stability constraint is $\\omega(x) \\ge \\omega_{\\min}$. With $\\omega_{\\min} = 2$, this becomes:\n$$\n3x \\ge 2 \\implies x \\ge \\frac{2}{3}\n$$\n\nThe optimization problem can now be stated solely in terms of $x$:\nMinimize $\\tau(x) = C_{\\tau} x^{\\frac{1}{2}}$\nsubject to the constraints:\n1. $x \\ge \\frac{2}{3}$ (from mechanical stability)\n2. $0 \\le x \\le 1$ (from definition of the design variable)\n\nThe intersection of these constraints defines the feasible region for $x$. This is the interval $x \\in [\\frac{2}{3}, 1]$.\n\nTo find the value of $x$ that minimizes the objective function $\\tau(x) = C_{\\tau} x^{\\frac{1}{2}}$ within this feasible region, we analyze the behavior of $\\tau(x)$. We can examine its derivative with respect to $x$:\n$$\n\\frac{d\\tau}{dx} = \\frac{d}{dx} \\left( C_{\\tau} x^{\\frac{1}{2}} \\right) = C_{\\tau} \\left( \\frac{1}{2} x^{-\\frac{1}{2}} \\right) = \\frac{C_{\\tau}}{2\\sqrt{x}}\n$$\nSince $C_{\\tau} > 0$ and the feasible region for $x$ is $[\\frac{2}{3}, 1]$, the derivative $\\frac{d\\tau}{dx}$ is strictly positive over the entire feasible domain. This means that the objective function $\\tau(x)$ is a strictly monotonically increasing function of $x$.\n\nTo minimize a strictly increasing function over a closed interval, one must select the smallest possible value of the variable within that interval. The feasible interval is $[\\frac{2}{3}, 1]$. The smallest value in this interval is $\\frac{2}{3}$.\n\nTherefore, the optimal pseudo-density $x^{\\star}$ that minimizes the thermal time constant while satisfying the mechanical stability constraint is the lower-bound of the feasible set.\n\n$$\nx^{\\star} = \\frac{2}{3}\n$$", "answer": "$$\\boxed{\\frac{2}{3}}$$", "id": "3530732"}, {"introduction": "To bridge the gap between analytical theory and practical, large-scale computation, this final exercise guides you through implementing the adjoint method for sensitivity analysis. For optimization problems with thousands or millions of design variables, calculating gradients via finite differences is computationally prohibitive; the adjoint method provides an elegant and efficient solution. By deriving the discrete adjoint equations for a coupled thermoelastic system and verifying your implementation against a finite-difference approximation, you will gain hands-on experience with the computational engine that powers modern topology optimization software [@problem_id:3530723].", "problem": "Consider a steady, linear, two-field coupled system modeling thermoelastic interactions in a discretized form suitable for topology and shape optimization. Let the mechanical displacement vector be $u \\in \\mathbb{R}^{2}$ and the temperature vector be $T \\in \\mathbb{R}^{2}$. Define the state vector $y \\in \\mathbb{R}^{4}$ by $y = \\begin{bmatrix} u \\\\ T \\end{bmatrix}$. The coupled governing equations are given in residual form by\n$$\nF(y,\\rho) = \\begin{bmatrix} K_u(\\rho) & -B \\\\ -S & K_T(\\rho) \\end{bmatrix} \\begin{bmatrix} u \\\\ T \\end{bmatrix} - \\begin{bmatrix} f_{\\mathrm{ext}} \\\\ q_{\\mathrm{ext}} \\end{bmatrix} = 0,\n$$\nwhere $K_u(\\rho) \\in \\mathbb{R}^{2 \\times 2}$ and $K_T(\\rho) \\in \\mathbb{R}^{2 \\times 2}$ are stiffness-like matrices for mechanics and heat, respectively, depending on the design vector $\\rho \\in [0,1]^m$ with $m=3$, and $B \\in \\mathbb{R}^{2 \\times 2}$, $S \\in \\mathbb{R}^{2 \\times 2}$ are fixed coupling matrices. The external mechanical load vector is $f_{\\mathrm{ext}} \\in \\mathbb{R}^{2}$ and the external heat load vector is $q_{\\mathrm{ext}} \\in \\mathbb{R}^{2}$.\n\nThe stiffness-like matrices are assembled from elementwise bases by Solid Isotropic Material with Penalization (SIMP) interpolation. Let the mechanical element bases be\n$$\nK_{u,1} = \\begin{bmatrix} 2 & -1 \\\\ -1 & 2 \\end{bmatrix}, \\quad\nK_{u,2} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}, \\quad\nK_{u,3} = \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix},\n$$\nand the thermal element bases be\n$$\nK_{T,1} = \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}, \\quad\nK_{T,2} = \\begin{bmatrix} 2 & -1 \\\\ -1 & 2 \\end{bmatrix}, \\quad\nK_{T,3} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\end{bmatrix}.\n$$\nFor each element index $i \\in \\{1,2,3\\}$, define the SIMP interpolations\n$$\nE_i(\\rho_i) = E_{\\min} + \\rho_i^p \\left(E_0 - E_{\\min}\\right), \\quad\nk_i(\\rho_i) = k_{\\min} + \\rho_i^p \\left(k_0 - k_{\\min}\\right),\n$$\nso that\n$$\nK_u(\\rho) = \\sum_{i=1}^{3} E_i(\\rho_i) K_{u,i}, \\qquad\nK_T(\\rho) = \\sum_{i=1}^{3} k_i(\\rho_i) K_{T,i}.\n$$\nAssume $E_0 > 0$, $k_0 > 0$, $E_{\\min} > 0$, $k_{\\min} > 0$, and $p \\ge 1$.\n\nThe objective functional for topology optimization is the compliance-like measure augmented with a thermal quadratic term and a linear regularization on the design:\n$$\nJ(y,\\rho) = f_{\\mathrm{ext}}^{\\top} u + \\gamma \\, T^{\\top} W T + \\eta \\sum_{i=1}^{3} \\rho_i,\n$$\nwhere $W \\in \\mathbb{R}^{2 \\times 2}$ is symmetric positive definite, and $\\gamma > 0$, $\\eta > 0$.\n\nYour tasks are:\n- Derive from first principles the discrete adjoint-based gradient of $J(y(\\rho),\\rho)$ with respect to the design $\\rho$, where $y(\\rho)$ solves $F(y,\\rho) = 0$. Use the Lagrangian $L(y,\\rho,\\lambda) = J(y,\\rho) + \\lambda^{\\top} F(y,\\rho)$ and the condition \n$$\n\\left(\\frac{\\partial F}{\\partial y}(y,\\rho)\\right)^{\\top} \\lambda + \\frac{\\partial J}{\\partial y}(y,\\rho) = 0\n$$\nto define the adjoint vector $\\lambda \\in \\mathbb{R}^{4}$ and express $\\nabla_{\\rho} J$ in terms of $y$, $\\lambda$, and the derivatives of $K_u(\\rho)$ and $K_T(\\rho)$.\n- Implement a program that, for given test cases, computes the adjoint gradient and verifies it against a finite-difference central approximation. Report, for each test case, the maximum absolute difference between the adjoint gradient and the finite-difference gradient across the design components.\n\nUse the following numerical parameters for the SIMP and objective:\n$$\nE_0 = 1.0,\\quad E_{\\min} = 10^{-3},\\quad k_0 = 1.0,\\quad k_{\\min} = 10^{-3},\\quad p = 3,\\quad \\gamma = 0.1,\\quad \\eta = 0.01,\\quad W = I_2,\n$$\nwhere $I_2$ denotes the $2 \\times 2$ identity matrix.\n\nUse the following test suite of $4$ cases, each defined by $(\\rho, B, S, f_{\\mathrm{ext}}, q_{\\mathrm{ext}})$:\n- Case $1$ (general coupled, moderate design):\n$$\n\\rho = \\begin{bmatrix} 0.6 \\\\ 0.8 \\\\ 0.3 \\end{bmatrix},\\quad\nB = \\begin{bmatrix} 0.4 & 0.0 \\\\ 0.0 & 0.2 \\end{bmatrix},\\quad\nS = \\begin{bmatrix} 0.1 & 0.05 \\\\ 0.0 & 0.2 \\end{bmatrix},\\quad\nf_{\\mathrm{ext}} = \\begin{bmatrix} 1.0 \\\\ 0.5 \\end{bmatrix},\\quad\nq_{\\mathrm{ext}} = \\begin{bmatrix} 0.3 \\\\ 0.2 \\end{bmatrix}.\n$$\n- Case $2$ (near-singular design, still well-posed due to $E_{\\min}$ and $k_{\\min}$):\n$$\n\\rho = \\begin{bmatrix} 10^{-3} \\\\ 10^{-3} \\\\ 10^{-3} \\end{bmatrix},\\quad\nB = \\begin{bmatrix} 0.4 & 0.0 \\\\ 0.0 & 0.2 \\end{bmatrix},\\quad\nS = \\begin{bmatrix} 0.1 & 0.05 \\\\ 0.0 & 0.2 \\end{bmatrix},\\quad\nf_{\\mathrm{ext}} = \\begin{bmatrix} 1.0 \\\\ 0.5 \\end{bmatrix},\\quad\nq_{\\mathrm{ext}} = \\begin{bmatrix} 0.3 \\\\ 0.2 \\end{bmatrix}.\n$$\n- Case $3$ (decoupled fields):\n$$\n\\rho = \\begin{bmatrix} 0.5 \\\\ 0.5 \\\\ 0.5 \\end{bmatrix},\\quad\nB = \\begin{bmatrix} 0.0 & 0.0 \\\\ 0.0 & 0.0 \\end{bmatrix},\\quad\nS = \\begin{bmatrix} 0.0 & 0.0 \\\\ 0.0 & 0.0 \\end{bmatrix},\\quad\nf_{\\mathrm{ext}} = \\begin{bmatrix} 1.0 \\\\ 0.5 \\end{bmatrix},\\quad\nq_{\\mathrm{ext}} = \\begin{bmatrix} 0.3 \\\\ 0.2 \\end{bmatrix}.\n$$\n- Case $4$ (strong coupling):\n$$\n\\rho = \\begin{bmatrix} 0.9 \\\\ 0.1 \\\\ 0.7 \\end{bmatrix},\\quad\nB = \\begin{bmatrix} 1.0 & 0.0 \\\\ 0.0 & 1.0 \\end{bmatrix},\\quad\nS = \\begin{bmatrix} 0.5 & 0.3 \\\\ 0.3 & 0.8 \\end{bmatrix},\\quad\nf_{\\mathrm{ext}} = \\begin{bmatrix} 1.0 \\\\ 0.5 \\end{bmatrix},\\quad\nq_{\\mathrm{ext}} = \\begin{bmatrix} 0.3 \\\\ 0.2 \\end{bmatrix}.\n$$\n\nYour program should, for each case, do the following:\n- Assemble $K_u(\\rho)$ and $K_T(\\rho)$.\n- Solve for $y(\\rho)$ from $F(y,\\rho) = 0$.\n- Form $\\dfrac{\\partial J}{\\partial y}(y,\\rho)$ and solve the adjoint system \n$$\n\\left(\\frac{\\partial F}{\\partial y}(y,\\rho)\\right)^{\\top} \\lambda + \\frac{\\partial J}{\\partial y}(y,\\rho) = 0,\n$$\nwhere $\\dfrac{\\partial F}{\\partial y}(y,\\rho) = \\begin{bmatrix} K_u(\\rho) & -B \\\\ -S & K_T(\\rho) \\end{bmatrix}$.\n- Compute the adjoint gradient $\\nabla_{\\rho} J = \\dfrac{\\partial J}{\\partial \\rho} + \\lambda^{\\top} \\dfrac{\\partial F}{\\partial \\rho}$, with components\n$$\n\\frac{\\partial J}{\\partial \\rho_i} = \\eta, \\qquad\n\\lambda^{\\top} \\frac{\\partial F}{\\partial \\rho_i} = \\lambda_u^{\\top} \\left(\\frac{\\partial K_u}{\\partial \\rho_i}\\right) u + \\lambda_T^{\\top} \\left(\\frac{\\partial K_T}{\\partial \\rho_i}\\right) T,\n$$\nand\n$$\n\\frac{\\partial K_u}{\\partial \\rho_i} = \\frac{d E_i}{d \\rho_i} K_{u,i}, \\quad \\frac{d E_i}{d \\rho_i} = p \\rho_i^{p-1} \\left(E_0 - E_{\\min}\\right), \\qquad\n\\frac{\\partial K_T}{\\partial \\rho_i} = \\frac{d k_i}{d \\rho_i} K_{T,i}, \\quad \\frac{d k_i}{d \\rho_i} = p \\rho_i^{p-1} \\left(k_0 - k_{\\min}\\right).\n$$\n- Compute a finite-difference central approximation of $\\nabla_{\\rho} J$ using a perturbation $\\varepsilon = 10^{-8}$.\n- Return, for each case, the maximum absolute difference between the adjoint gradient and the finite-difference gradient.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4]$), where each $r_j$ is the maximum absolute difference for case $j$. All reported values are dimensionless real numbers.", "solution": "We start from the discrete multiphysics system in residual form\n$$\nF(y,\\rho) = \\mathcal{A}(\\rho) y - b = 0,\n$$\nwhere\n$$\n\\mathcal{A}(\\rho) = \\begin{bmatrix} K_u(\\rho) & -B \\\\ -S & K_T(\\rho) \\end{bmatrix}, \\qquad\nb = \\begin{bmatrix} f_{\\mathrm{ext}} \\\\ q_{\\mathrm{ext}} \\end{bmatrix},\n$$\n$y = \\begin{bmatrix} u \\\\ T \\end{bmatrix}$, with $u \\in \\mathbb{R}^{2}$ and $T \\in \\mathbb{R}^{2}$, and $\\rho = \\begin{bmatrix} \\rho_1 \\\\ \\rho_2 \\\\ \\rho_3 \\end{bmatrix} \\in [0,1]^3$. The objective is\n$$\nJ(y,\\rho) = f_{\\mathrm{ext}}^{\\top} u + \\gamma \\, T^{\\top} W T + \\eta \\sum_{i=1}^{3} \\rho_i.\n$$\n\nThe adjoint methodology is derived from the Lagrangian\n$$\nL(y,\\rho,\\lambda) = J(y,\\rho) + \\lambda^{\\top} F(y,\\rho) = J(y,\\rho) + \\lambda^{\\top}\\left(\\mathcal{A}(\\rho) y - b\\right),\n$$\nwhere $\\lambda \\in \\mathbb{R}^{4}$ is the adjoint vector. Differentiating $L$ with respect to $y$ and setting the derivative to zero yields the adjoint equation. Specifically,\n$$\n\\frac{\\partial L}{\\partial y} = \\frac{\\partial J}{\\partial y} + \\left(\\frac{\\partial F}{\\partial y}\\right)^{\\top} \\lambda = 0,\n$$\nthat is,\n$$\n\\left(\\frac{\\partial F}{\\partial y}\\right)^{\\top} \\lambda + \\frac{\\partial J}{\\partial y} = 0.\n$$\nFor our residual $F(y,\\rho) = \\mathcal{A}(\\rho) y - b$, the Jacobian with respect to $y$ is\n$$\n\\frac{\\partial F}{\\partial y} = \\mathcal{A}(\\rho) = \\begin{bmatrix} K_u(\\rho) & -B \\\\ -S & K_T(\\rho) \\end{bmatrix}.\n$$\nThe gradient of the objective with respect to $y$ is\n$$\n\\frac{\\partial J}{\\partial y} = \\begin{bmatrix} \\frac{\\partial J}{\\partial u} \\\\ \\frac{\\partial J}{\\partial T} \\end{bmatrix}\n= \\begin{bmatrix} f_{\\mathrm{ext}} \\\\ 2 \\gamma W T \\end{bmatrix}.\n$$\nTherefore, the adjoint equation becomes\n$$\n\\mathcal{A}(\\rho)^{\\top} \\lambda + \\begin{bmatrix} f_{\\mathrm{ext}} \\\\ 2 \\gamma W T \\end{bmatrix} = 0.\n$$\nSolving this $4 \\times 4$ linear system yields $\\lambda = \\begin{bmatrix} \\lambda_u \\\\ \\lambda_T \\end{bmatrix}$, with $\\lambda_u \\in \\mathbb{R}^{2}$ and $\\lambda_T \\in \\mathbb{R}^{2}$.\n\nNext, the total derivative of the objective $J(y(\\rho),\\rho)$ with respect to $\\rho$ is\n$$\n\\frac{d}{d \\rho_i} J(y(\\rho),\\rho) = \\frac{\\partial J}{\\partial \\rho_i} + \\left(\\frac{\\partial J}{\\partial y}\\right)^{\\top} \\frac{\\partial y}{\\partial \\rho_i}.\n$$\nUsing the constraint $F(y(\\rho),\\rho) = 0$, we differentiate with respect to $\\rho_i$:\n$$\n\\frac{\\partial F}{\\partial y} \\frac{\\partial y}{\\partial \\rho_i} + \\frac{\\partial F}{\\partial \\rho_i} = 0\n\\quad \\Rightarrow \\quad\n\\frac{\\partial y}{\\partial \\rho_i} = - \\left(\\frac{\\partial F}{\\partial y}\\right)^{-1} \\frac{\\partial F}{\\partial \\rho_i}.\n$$\nSubstituting into the expression for $\\dfrac{dJ}{d\\rho_i}$ gives\n$$\n\\frac{dJ}{d\\rho_i} = \\frac{\\partial J}{\\partial \\rho_i} - \\left(\\frac{\\partial J}{\\partial y}\\right)^{\\top} \\left(\\frac{\\partial F}{\\partial y}\\right)^{-1} \\frac{\\partial F}{\\partial \\rho_i}.\n$$\nIntroduce the adjoint vector $\\lambda$ by solving\n$$\n\\left(\\frac{\\partial F}{\\partial y}\\right)^{\\top} \\lambda + \\frac{\\partial J}{\\partial y} = 0\n\\quad \\Rightarrow \\quad\n\\lambda = - \\left(\\frac{\\partial F}{\\partial y}\\right)^{-\\top} \\frac{\\partial J}{\\partial y}.\n$$\nThen\n$$\n\\frac{dJ}{d\\rho_i} = \\frac{\\partial J}{\\partial \\rho_i} + \\lambda^{\\top} \\frac{\\partial F}{\\partial \\rho_i}.\n$$\nThis is the classical adjoint sensitivity formula: the gradient with respect to design is the direct derivative plus the adjoint-weighted residual derivative.\n\nFor our specific problem, note that $b$ does not depend on $\\rho$, and the residual derivative with respect to $\\rho_i$ is\n$$\n\\frac{\\partial F}{\\partial \\rho_i} = \\begin{bmatrix} \\frac{\\partial K_u}{\\partial \\rho_i} & 0 \\\\ 0 & \\frac{\\partial K_T}{\\partial \\rho_i} \\end{bmatrix} \\begin{bmatrix} u \\\\ T \\end{bmatrix}\n= \\begin{bmatrix} \\left(\\frac{\\partial K_u}{\\partial \\rho_i}\\right) u \\\\ \\left(\\frac{\\partial K_T}{\\partial \\rho_i}\\right) T \\end{bmatrix}.\n$$\nTherefore,\n$$\n\\lambda^{\\top} \\frac{\\partial F}{\\partial \\rho_i} = \\lambda_u^{\\top} \\left(\\frac{\\partial K_u}{\\partial \\rho_i}\\right) u + \\lambda_T^{\\top} \\left(\\frac{\\partial K_T}{\\partial \\rho_i}\\right) T.\n$$\nThe partial derivatives of the stiffness-like matrices are\n$$\n\\frac{\\partial K_u}{\\partial \\rho_i} = \\frac{d E_i}{d \\rho_i} K_{u,i}, \\quad \\frac{d E_i}{d \\rho_i} = p \\rho_i^{p-1} \\left(E_0 - E_{\\min}\\right),\n$$\nand\n$$\n\\frac{\\partial K_T}{\\partial \\rho_i} = \\frac{d k_i}{d \\rho_i} K_{T,i}, \\quad \\frac{d k_i}{d \\rho_i} = p \\rho_i^{p-1} \\left(k_0 - k_{\\min}\\right).\n$$\nThe direct derivative of $J$ with respect to $\\rho_i$ is simply\n$$\n\\frac{\\partial J}{\\partial \\rho_i} = \\eta,\n$$\nsince the compliance-like term $f_{\\mathrm{ext}}^{\\top} u$ and the thermal quadratic term $\\gamma T^{\\top} W T$ have no explicit dependence on $\\rho$ other than through $y(\\rho)$, which is accounted for by the adjoint.\n\nAlgorithmic procedure for each test case:\n- Assemble $K_u(\\rho)$ and $K_T(\\rho)$ from the bases and SIMP coefficients $E_i(\\rho_i)$ and $k_i(\\rho_i)$.\n- Build the $4 \\times 4$ block matrix $\\mathcal{A}(\\rho)$ and the right-hand side $b$.\n- Solve the forward linear system $\\mathcal{A}(\\rho) y = b$ to obtain $y = \\begin{bmatrix} u \\\\ T \\end{bmatrix}$.\n- Form the objective gradient with respect to $y$ as $\\dfrac{\\partial J}{\\partial y} = \\begin{bmatrix} f_{\\mathrm{ext}} \\\\ 2 \\gamma W T \\end{bmatrix}$.\n- Solve the adjoint system $\\mathcal{A}(\\rho)^{\\top} \\lambda = - \\dfrac{\\partial J}{\\partial y}$ to obtain $\\lambda$.\n- Compute the adjoint gradient components\n$$\n\\left(\\nabla_{\\rho} J\\right)_i = \\eta + \\lambda_u^{\\top} \\left(\\frac{\\partial K_u}{\\partial \\rho_i}\\right) u + \\lambda_T^{\\top} \\left(\\frac{\\partial K_T}{\\partial \\rho_i}\\right) T, \\quad i = 1,2,3.\n$$\n- Verify by finite differences: for a small $\\varepsilon = 10^{-8}$, compute central differences\n$$\n\\left(\\nabla_{\\rho} J\\right)^{\\mathrm{FD}}_i \\approx \\frac{J\\left(y(\\rho + \\varepsilon e_i), \\rho + \\varepsilon e_i\\right) - J\\left(y(\\rho - \\varepsilon e_i), \\rho - \\varepsilon e_i\\right)}{2 \\varepsilon},\n$$\nwhere $e_i$ is the $i$-th unit vector in $\\mathbb{R}^3$, and $y(\\cdot)$ is obtained by solving the forward problem for the perturbed design.\n- Compute the maximum absolute difference\n$$\nr = \\max_{i \\in \\{1,2,3\\}} \\left| \\left(\\nabla_{\\rho} J\\right)_i - \\left(\\nabla_{\\rho} J\\right)^{\\mathrm{FD}}_i \\right|.\n$$\n\nNumerical stability and physical realism:\n- The SIMP lower bounds $E_{\\min} > 0$ and $k_{\\min} > 0$ ensure that $K_u(\\rho)$ and $K_T(\\rho)$ are positive definite combinations of symmetric positive semidefinite bases, so the block matrix $\\mathcal{A}(\\rho)$ is nonsingular for the provided couplings.\n- The coupling matrices $B$ and $S$ represent linearized thermoelastic interactions. While real thermoelastic couplings often enter the mechanical equation as thermal expansion loads and the heat equation via dissipation sources, the symmetric block representation provides a mathematically sound coupled linear system suitable for adjoint sensitivity demonstration.\n- The central finite-difference step $\\varepsilon$ is chosen small enough to ensure high-accuracy approximation without undue round-off error for double-precision arithmetic.\n\nThe program implements the described procedure and returns, for the $4$ test cases, the list $[r_1, r_2, r_3, r_4]$ of dimensionless real numbers measuring the discrepancy between adjoint and finite-difference gradients.\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef simp_coef(rho_i, x0, xmin, p):\n    # E(rho) or k(rho)\n    return xmin + (x0 - xmin) * (rho_i ** p)\n\ndef simp_deriv(rho_i, x0, xmin, p):\n    # derivative dE/drho or dk/drho\n    return p * (rho_i ** (p - 1)) * (x0 - xmin)\n\ndef assemble_matrices(rho, Ku_bases, Kt_bases, E0, Emin, k0, kmin, p):\n    Ku = np.zeros((2, 2))\n    Kt = np.zeros((2, 2))\n    dKu_drho = []\n    dKt_drho = []\n    for i in range(3):\n        Ei = simp_coef(rho[i], E0, Emin, p)\n        ki = simp_coef(rho[i], k0, kmin, p)\n        dEi = simp_deriv(rho[i], E0, Emin, p)\n        dki = simp_deriv(rho[i], k0, kmin, p)\n        Ku += Ei * Ku_bases[i]\n        Kt += ki * Kt_bases[i]\n        dKu_drho.append(dEi * Ku_bases[i])\n        dKt_drho.append(dki * Kt_bases[i])\n    return Ku, Kt, dKu_drho, dKt_drho\n\ndef build_block_matrix(Ku, Kt, B, S):\n    # Assemble 4x4 block matrix A = [[Ku, -B], [-S, Kt]]\n    A = np.zeros((4, 4))\n    A[0:2, 0:2] = Ku\n    A[0:2, 2:4] = -B\n    A[2:4, 0:2] = -S\n    A[2:4, 2:4] = Kt\n    return A\n\ndef solve_forward(rho, Ku_bases, Kt_bases, B, S, fext, qext, E0, Emin, k0, kmin, p):\n    Ku, Kt, dKu_drho, dKt_drho = assemble_matrices(rho, Ku_bases, Kt_bases, E0, Emin, k0, kmin, p)\n    A = build_block_matrix(Ku, Kt, B, S)\n    b = np.hstack([fext, qext])\n    y = np.linalg.solve(A, b)\n    u = y[0:2]\n    T = y[2:4]\n    return u, T, A, dKu_drho, dKt_drho\n\ndef objective(u, T, rho, fext, gamma, W, eta):\n    return float(fext @ u + gamma * (T @ (W @ T)) + eta * np.sum(rho))\n\ndef adjoint_gradient(rho, Ku_bases, Kt_bases, B, S, fext, qext, E0, Emin, k0, kmin, p, gamma, W, eta):\n    # Forward solve\n    u, T, A, dKu_drho, dKt_drho = solve_forward(rho, Ku_bases, Kt_bases, B, S, fext, qext, E0, Emin, k0, kmin, p)\n    # dJ/dy = [fext, 2*gamma*W*T]\n    dJ_du = fext\n    dJ_dT = 2.0 * gamma * (W @ T)\n    dJ_dy = np.hstack([dJ_du, dJ_dT])\n    # Solve adjoint: A^T * lambda = - dJ/dy\n    rhs = -dJ_dy\n    lam = np.linalg.solve(A.T, rhs)\n    lam_u = lam[0:2]\n    lam_T = lam[2:4]\n    # Gradient components\n    grad = np.zeros(3)\n    for i in range(3):\n        term_u = lam_u @ (dKu_drho[i] @ u)\n        term_T = lam_T @ (dKt_drho[i] @ T)\n        grad[i] = eta + term_u + term_T\n    return grad, u, T\n\ndef fd_gradient(rho, Ku_bases, Kt_bases, B, S, fext, qext, E0, Emin, k0, kmin, p, gamma, W, eta, eps=1e-8):\n    grad_fd = np.zeros(3)\n    for i in range(3):\n        rho_plus = rho.copy()\n        rho_minus = rho.copy()\n        rho_plus[i] += eps\n        rho_minus[i] -= eps\n        # clamp to avoid negative rho (though eps is small)\n        rho_plus[i] = max(0.0, min(1.0, rho_plus[i]))\n        rho_minus[i] = max(0.0, min(1.0, rho_minus[i]))\n        # forward solves\n        u_p, T_p, _, _, _ = solve_forward(rho_plus, Ku_bases, Kt_bases, B, S, fext, qext, E0, Emin, k0, kmin, p)\n        J_p = objective(u_p, T_p, rho_plus, fext, gamma, W, eta)\n        u_m, T_m, _, _, _ = solve_forward(rho_minus, Ku_bases, Kt_bases, B, S, fext, qext, E0, Emin, k0, kmin, p)\n        J_m = objective(u_m, T_m, rho_minus, fext, gamma, W, eta)\n        grad_fd[i] = (J_p - J_m) / (rho_plus[i] - rho_minus[i])  # central difference symmetric if bounds not hit\n    return grad_fd\n\ndef run_case(rho, B, S, fext, qext):\n    # SIMP and objective parameters\n    E0 = 1.0\n    Emin = 1e-3\n    k0 = 1.0\n    kmin = 1e-3\n    p = 3\n    gamma = 0.1\n    eta = 0.01\n    W = np.eye(2)\n\n    # Bases\n    Ku_bases = [\n        np.array([[2.0, -1.0], [-1.0, 2.0]]),\n        np.array([[1.0,  0.0], [ 0.0, 1.0]]),\n        np.array([[1.0, -1.0], [-1.0, 1.0]]),\n    ]\n    Kt_bases = [\n        np.array([[1.0, -1.0], [-1.0, 1.0]]),\n        np.array([[2.0, -1.0], [-1.0, 2.0]]),\n        np.array([[1.0,  0.0], [ 0.0, 1.0]]),\n    ]\n\n    grad_adj, u, T = adjoint_gradient(rho, Ku_bases, Kt_bases, B, S, fext, qext, E0, Emin, k0, kmin, p, gamma, W, eta)\n    grad_fd = fd_gradient(rho, Ku_bases, Kt_bases, B, S, fext, qext, E0, Emin, k0, kmin, p, gamma, W, eta, eps=1e-8)\n    max_diff = float(np.max(np.abs(grad_adj - grad_fd)))\n    return max_diff\n\ndef solve():\n    test_cases = [\n        # Case 1\n        (\n            np.array([0.6, 0.8, 0.3]),\n            np.array([[0.4, 0.0],\n                      [0.0, 0.2]]),\n            np.array([[0.1, 0.05],\n                      [0.0, 0.2]]),\n            np.array([1.0, 0.5]),\n            np.array([0.3, 0.2]),\n        ),\n        # Case 2\n        (\n            np.array([1e-3, 1e-3, 1e-3]),\n            np.array([[0.4, 0.0],\n                      [0.0, 0.2]]),\n            np.array([[0.1, 0.05],\n                      [0.0, 0.2]]),\n            np.array([1.0, 0.5]),\n            np.array([0.3, 0.2]),\n        ),\n        # Case 3\n        (\n            np.array([0.5, 0.5, 0.5]),\n            np.array([[0.0, 0.0],\n                      [0.0, 0.0]]),\n            np.array([[0.0, 0.0],\n                      [0.0, 0.0]]),\n            np.array([1.0, 0.5]),\n            np.array([0.3, 0.2]),\n        ),\n        # Case 4\n        (\n            np.array([0.9, 0.1, 0.7]),\n            np.array([[1.0, 0.0],\n                      [0.0, 1.0]]),\n            np.array([[0.5, 0.3],\n                      [0.3, 0.8]]),\n            np.array([1.0, 0.5]),\n            np.array([0.3, 0.2]),\n        ),\n    ]\n\n    results = []\n    for rho, B, S, fext, qext in test_cases:\n        result = run_case(rho, B, S, fext, qext)\n        # Use a reasonable formatting for floating values\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(lambda x: f'{x:.12e}', results))}]\")\n\n# The following lines are for execution if this script is run directly.\n# They are commented out here to prevent execution in this context,\n# as the functions are intended to be part of the solution documentation.\n# if __name__ == \"__main__\":\n#     solve()\n```", "answer": "[1.579450371303e-07,1.002931130095e-06,2.158580226938e-07,2.062025754021e-07]", "id": "3530723"}]}