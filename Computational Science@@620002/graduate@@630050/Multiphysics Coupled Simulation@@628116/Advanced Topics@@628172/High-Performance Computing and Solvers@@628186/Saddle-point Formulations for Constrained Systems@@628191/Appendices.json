{"hands_on_practices": [{"introduction": "Understanding the trade-offs between different constraint enforcement strategies is a cornerstone of computational mechanics. This first practice provides a direct, hands-on comparison between the Lagrange multiplier method, which leads to a saddle-point system, and the simpler penalty method. By implementing both for a one-dimensional problem, you will gain concrete insights into their accuracy, convergence behavior, and implementation complexity, particularly how the penalty parameter $\\gamma$ affects the solution quality [@problem_id:3525095].", "problem": "Consider the one-dimensional scalar Poisson problem on the interval $[0,1]$ with constant body force where the primary field $u(x)$ satisfies the strong form $-u''(x)=1$ for $x \\in (0,1)$, together with a zero-Neumann boundary condition at the right end $u'(1)=0$ and the boundary constraint at the left end $u(0)=0$. Treat $u(0)=0$ as a constraint to be enforced either by a Lagrange multiplier (saddle-point formulation) or by a penalty term. Starting from the standard variational statement for $-u''=1$ with a natural (Neumann) boundary at $x=1$, formulate the constrained weak problem with the Lagrange multiplier using the Principle of Virtual Work and, separately, the penalized weak problem by adding a quadratic penalty term for the constraint. Then discretize both formulations using uniform linear finite elements on $[0,1]$ with $N$ elements and mesh size $h=1/N$, and implement the following:\n\n- For the multiplier approach, introduce an additional scalar unknown (the multiplier) to enforce $u(0)=0$ in the weak sense, producing a saddle-point linear system coupling the finite element stiffness with the constraint.\n- For the penalty approach, add a symmetric penalty bilinear form proportional to a scalar penalty parameter $\\gamma$ that weakly enforces $u(0)\\approx 0$.\n\nUse the exact analytical solution consistent with the strong form and the constraint, selected within the same physics and mathematics, as a reference to quantify numerical error. Compute, for each approach and each test case, the following metrics:\n- The $L^2$ error norm $\\left(\\int_{0}^{1}\\left(u_{\\text{exact}}(x)-u_h(x)\\right)^2\\,dx\\right)^{1/2}$.\n- The $H^1$ seminorm of the error $\\left(\\int_{0}^{1}\\left(u'_{\\text{exact}}(x)-u'_h(x)\\right)^2\\,dx\\right)^{1/2}$.\n- The constraint residual at the boundary $|u_h(0)|$.\n\nYour implementation must use Gaussian quadrature with sufficient order to exactly integrate the polynomials that arise in these norms for linear elements in one dimension. All integrations must be performed over $x \\in [0,1]$.\n\nBase your derivation on:\n- The strong form $-u''(x)=1$ for $x \\in (0,1)$ with $u'(1)=0$ and the equality constraint $u(0)=0$.\n- The corresponding unconstrained weak form $\\int_{0}^{1}u'(x)v'(x)\\,dx=\\int_{0}^{1}1\\cdot v(x)\\,dx$ for all admissible $v(x)$, before adding the constraint.\n\nDefine the discrete formulations precisely and then implement them. Assume a uniform mesh and linear basis functions. The exact solution to compare against must be derived from the strong form and the boundary conditions specified. The test suite is defined by the set of parameter pairs $(N,\\gamma)$ with $N$ the number of elements and $\\gamma$ the penalty parameter:\n- $(N,\\gamma)=(4,10)$ as a general case,\n- $(N,\\gamma)=(16,10)$ to probe mesh refinement at small $\\gamma$,\n- $(N,\\gamma)=(16,1000)$ to probe increased $\\gamma$ at fixed $h$,\n- $(N,\\gamma)=(64,1000)$ as a refined mesh at moderate $\\gamma$,\n- $(N,\\gamma)=(64,10^6)$ to probe very large $\\gamma$,\n- $(N,\\gamma)=(2,1000)$ as a coarse mesh edge case.\n\nFor each test case, compute the three metrics for the penalty approach and for the multiplier approach (the multiplier approach does not depend on $\\gamma$, but must be evaluated at the same $N$ for comparability). Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list of six floating-point numbers ordered as `[E_{L^2}^{\\text{pen}},E_{H^1}^{\\text{pen}},r^{\\text{pen}},E_{L^2}^{\\text{mult}},E_{H^1}^{\\text{mult}},r^{\\text{mult}}]` with $E_{L^2}$ the $L^2$ error norm, $E_{H^1}$ the $H^1$ seminorm of error, and $r$ the constraint residual $|u_h(0)|$.\n\nAll mathematical symbols, variables, functions, operators, and numbers must be written in LaTeX enclosed in dollar signs, including $u$, $v$, $x$, $N$, $h$, $\\gamma$, $1$, $0$, and all integrals and norms. No physical units are involved in this problem; angles and percentages are not used. The output must be in the format described above, and all answers for the test cases must be floating-point numbers.", "solution": "The problem requires the solution of a one-dimensional Poisson equation, $-u''(x) = 1$ on the interval $x \\in (0,1)$, with boundary conditions $u'(1)=0$ and $u(0)=0$. The condition $u(0)=0$ is to be treated as a constraint enforced by two different methods: a penalty method and a Lagrange multiplier method. The solutions are to be obtained using the finite element method with linear basis functions.\n\n### 1. Analytical Solution\nFirst, we establish the exact analytical solution to serve as a benchmark for numerical error analysis. The strong form of the differential equation is:\n$$ -u''(x) = 1 $$\nIntegrating with respect to $x$ yields:\n$$ -u'(x) = x + C_1 $$\nThe Neumann boundary condition $u'(1)=0$ is applied to determine the constant $C_1$:\n$$ -u'(1) = 1 + C_1 = 0 \\implies C_1 = -1 $$\nThus, the derivative of the solution is:\n$$ u'(x) = 1 - x $$\nIntegrating a second time gives the general solution for $u(x)$:\n$$ u(x) = x - \\frac{1}{2}x^2 + C_2 $$\nThe constraint $u(0)=0$ is used to find $C_2$:\n$$ u(0) = 0 - 0 + C_2 = 0 \\implies C_2 = 0 $$\nTherefore, the exact solution is:\n$$ u_{\\text{exact}}(x) = x - \\frac{1}{2}x^2 $$\nAnd its derivative is $u'_{\\text{exact}}(x) = 1 - x$.\n\n### 2. Variational Formulations\nWe start from the given unconstrained weak form, which corresponds to the bilinear form $a(u,v) = \\int_{0}^{1} u'(x)v'(x) \\,dx$ and the linear functional $L(v) = \\int_{0}^{1} 1 \\cdot v(x) \\,dx$. The problem is to find a function $u(x)$ in an appropriate space $V$ (here $H^1(0,1)$) satisfying the variational equation and the constraint $u(0)=0$.\n\n#### 2.1. Penalty Method Formulation\nIn the penalty method, the constraint $u(0)=0$ is enforced weakly by adding a penalty term to the total potential energy functional. The modified functional to be minimized is:\n$$ J(u) = \\frac{1}{2} a(u,u) - L(u) + \\frac{1}{2}\\gamma (u(0))^2 $$\nwhere $\\gamma > 0$ is a large penalty parameter. The solution $u_\\gamma$ is found by requiring the first variation of $J(u)$ with respect to an arbitrary test function $v \\in V$ to be zero. This yields the penalized weak formulation:\nFind $u_\\gamma \\in V$ such that for all $v \\in V$:\n$$ a(u_\\gamma, v) + \\gamma u_\\gamma(0)v(0) = L(v) $$\nSubstituting the definitions for $a(\\cdot,\\cdot)$ and $L(\\cdot)$:\n$$ \\int_{0}^{1} u_\\gamma'(x)v'(x) \\,dx + \\gamma u_\\gamma(0)v(0) = \\int_{0}^{1} v(x) \\,dx $$\n\n#### 2.2. Lagrange Multiplier Formulation\nThis method introduces a Lagrange multiplier, $\\lambda$, to enforce the constraint exactly. We seek a pair $(u, \\lambda) \\in V \\times \\mathbb{R}$. The augmented functional (Lagrangian) is:\n$$ \\mathcal{L}(u, \\lambda) = \\frac{1}{2} a(u,u) - L(u) + \\lambda u(0) $$\nThe solution is a stationary point of $\\mathcal{L}$. Taking variations with respect to $u$ (in direction $v$) and $\\lambda$ (in direction $\\mu$) and setting them to zero gives the following system of equations:\n1.  $\\delta_u \\mathcal{L}(v) = a(u,v) - L(v) + \\lambda v(0) = 0$ for all $v \\in V$.\n2.  $\\delta_\\lambda \\mathcal{L}(\\mu) = \\mu u(0) = 0$ for all $\\mu \\in \\mathbb{R}$, which implies $u(0)=0$.\n\nThis leads to the saddle-point weak formulation: Find $(u, \\lambda) \\in V \\times \\mathbb{R}$ such that:\n$$ \\int_{0}^{1} u'(x)v'(x) \\,dx + \\lambda v(0) = \\int_{0}^{1} v(x) \\,dx \\quad \\forall v \\in V $$\n$$ u(0) = 0 $$\nPhysically, the multiplier $\\lambda$ can be identified with the reaction flux needed to enforce the constraint. Comparing with the boundary terms from integration by parts, $\\lambda = -u'(0)$. For the exact solution, $\\lambda = -(1-0) = -1$.\n\n### 3. Finite Element Discretization\nWe discretize the interval $[0,1]$ into $N$ uniform elements of length $h=1/N$. The nodes are located at $x_i = i h$ for $i=0, 1, \\dots, N$. We use linear basis functions (hat functions) $\\phi_i(x)$ where $\\phi_i(x_j) = \\delta_{ij}$. The finite element solution is approximated as $u_h(x) = \\sum_{j=0}^{N} u_j \\phi_j(x)$, where $\\mathbf{u} = (u_0, u_1, \\dots, u_N)^T$ is the vector of nodal unknown values.\n\nThe standard stiffness matrix $K$ and force vector $F$ are assembled with entries:\n$$ K_{ij} = a(\\phi_j, \\phi_i) = \\int_0^1 \\phi_j'(x) \\phi_i'(x) \\,dx $$\n$$ F_i = L(\\phi_i) = \\int_0^1 \\phi_i(x) \\,dx $$\nFor a uniform mesh with linear elements, this results in the $(N+1) \\times (N+1)$ symmetric tridiagonal stiffness matrix $K$ and load vector $F$:\n$$ K = \\frac{1}{h} \\begin{pmatrix} 1 & -1 & & \\\\ -1 & 2 & -1 & \\\\ & \\ddots & \\ddots & \\ddots \\\\ & & -1 & 2 & -1 \\\\ & & & -1 & 1 \\end{pmatrix}, \\quad F = h \\begin{pmatrix} 1/2 \\\\ 1 \\\\ \\vdots \\\\ 1 \\\\ 1/2 \\end{pmatrix} $$\n\n#### 3.1. Discrete Penalty System\nDiscretizing the penalty weak form by setting $u_h = \\sum_j u_j \\phi_j$ and $v = \\phi_i$ gives:\n$$ \\sum_{j=0}^{N} u_j K_{ij} + \\gamma \\left(\\sum_{j=0}^{N} u_j \\phi_j(0)\\right) \\phi_i(0) = F_i \\quad \\text{for } i=0, \\dots, N $$\nSince $\\phi_j(0) = \\delta_{j0}$ and $u_h(0) = u_0$, this simplifies. The penalty term only affects the first equation ($i=0$), adding $\\gamma u_0$ to the left-hand side. This is equivalent to adding $\\gamma$ to the $(0,0)$ entry of the stiffness matrix. The resulting linear system is:\n$$ (K + K_p) \\mathbf{u} = F \\quad \\text{where} \\quad K_p = \\begin{pmatrix} \\gamma & 0 & \\dots \\\\ 0 & 0 & \\dots \\\\ \\vdots & \\vdots & \\ddots \\end{pmatrix} $$\n\n#### 3.2. Discrete Lagrange Multiplier System\nDiscretizing the saddle-point formulation yields a larger, block-structured linear system for the unknowns $(\\mathbf{u}, \\lambda)$. The equations become:\n$$ \\sum_{j=0}^{N} u_j K_{ij} + \\lambda \\phi_i(0) = F_i \\quad \\text{for } i=0, \\dots, N $$\n$$ u_0 = 0 $$\nLet $B$ be the constraint vector such that $B_i = \\phi_i(0) = \\delta_{i0}$. The discrete system can be written in block matrix form:\n$$ \\begin{pmatrix} K & B \\\\ B^T & 0 \\end{pmatrix} \\begin{pmatrix} \\mathbf{u} \\\\ \\lambda \\end{pmatrix} = \\begin{pmatrix} F \\\\ 0 \\end{pmatrix} $$\nThis is an $(N+2) \\times (N+2)$ symmetric indefinite system.\n\n### 4. Error Metrics\nThe numerical solutions are compared to the exact solution using three metrics:\n1.  **$L^2$ error norm:** $E_{L^2} = \\left(\\int_{0}^{1}\\left(u_{\\text{exact}}(x)-u_h(x)\\right)^2\\,dx\\right)^{1/2}$\n2.  **$H^1$ seminorm of the error:** $E_{H^1} = \\left(\\int_{0}^{1}\\left(u'_{\\text{exact}}(x)-u'_h(x)\\right)^2\\,dx\\right)^{1/2}$\n3.  **Constraint residual:** $r = |u_h(0)| = |u_0|$\n\nThe integrals for the error norms are computed numerically using Gaussian quadrature. On each element, $u_h(x)$ is linear and $u_h'(x)$ is constant, while $u_{\\text{exact}}(x)$ is quadratic and $u'_{\\text{exact}}(x)$ is linear. Therefore, the integrand for the $L^2$ error is a polynomial of degree $4$, requiring a $3$-point Gauss rule for exact integration. The integrand for the $H^1$ seminorm of the error is a polynomial of degree $2$, requiring a $2$-point Gauss rule. For simplicity and consistency, a $3$-point rule is sufficient for both. The integration over $[0,1]$ is performed by summing the contributions from each element, applying the quadrature rule on a reference element and mapping to the physical element coordinates.", "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Solves the 1D Poisson problem with two different constraint enforcement methods\n    and computes error metrics against the exact solution.\n    \"\"\"\n\n    test_cases = [\n        (4, 10.0),\n        (16, 10.0),\n        (16, 1000.0),\n        (64, 1000.0),\n        (64, 1.0e6),\n        (2, 1000.0),\n    ]\n\n    all_results = []\n\n    for N, gamma in test_cases:\n        h = 1.0 / N\n        num_nodes = N + 1\n\n        # Assemble stiffness matrix K and force vector F\n        K = np.zeros((num_nodes, num_nodes))\n        F = np.zeros(num_nodes)\n\n        # Diagonals\n        K.flat[::num_nodes+1] = 2.0 / h\n        K[0, 0] = 1.0 / h\n        K[N, N] = 1.0 / h\n        # Off-diagonals\n        off_diag = -1.0 / h\n        K.flat[1::num_nodes+1] = off_diag\n        K.flat[num_nodes::num_nodes+1] = off_diag\n\n        # Force vector\n        F[:] = h\n        F[0] = h / 2.0\n        F[N] = h / 2.0\n\n        # --- Penalty Method ---\n        K_pen = np.copy(K)\n        K_pen[0, 0] += gamma\n        u_pen = linalg.solve(K_pen, F)\n        \n        l2_pen, h1_pen = calculate_error_norms(u_pen, N)\n        r_pen = np.abs(u_pen[0])\n\n        # --- Lagrange Multiplier Method ---\n        # Form the saddle-point system matrix A_mult\n        A_mult = np.zeros((num_nodes + 1, num_nodes + 1))\n        A_mult[:num_nodes, :num_nodes] = K\n        B = np.zeros(num_nodes)\n        B[0] = 1.0\n        A_mult[:num_nodes, num_nodes] = B\n        A_mult[num_nodes, :num_nodes] = B.T\n\n        # Form the right-hand side vector\n        rhs_mult = np.zeros(num_nodes + 1)\n        rhs_mult[:num_nodes] = F\n\n        # Solve the system\n        sol_mult = linalg.solve(A_mult, rhs_mult)\n        u_mult = sol_mult[:num_nodes]\n        # _lambda = sol_mult[num_nodes] # The multiplier is not used further\n        \n        l2_mult, h1_mult = calculate_error_norms(u_mult, N)\n        r_mult = np.abs(u_mult[0])\n\n        case_results = [l2_pen, h1_pen, r_pen, l2_mult, h1_mult, r_mult]\n        all_results.append(case_results)\n\n    # Format output string\n    # Replace Python's default representation to remove spaces for cleaner output\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\n\ndef calculate_error_norms(u_h_coeffs, N):\n    \"\"\"\n    Computes L2 and H1 error norms using Gaussian quadrature.\n    \"\"\"\n    h = 1.0 / N\n    \n    # 3-point Gauss quadrature on [-1, 1]\n    z_pts = [-np.sqrt(3.0/5.0), 0.0, np.sqrt(3.0/5.0)]\n    w_pts = [5.0/9.0, 8.0/9.0, 5.0/9.0]\n    \n    l2_err_sq = 0.0\n    h1_err_sq = 0.0\n\n    # Exact solution and its derivative\n    u_exact_func = lambda x: x - 0.5 * x**2\n    u_exact_prime_func = lambda x: 1.0 - x\n\n    for e in range(N):\n        # Nodal coordinates and values for element e\n        x_e = e * h\n        u_e = u_h_coeffs[e]\n        u_e1 = u_h_coeffs[e+1]\n        \n        # Derivative of FE solution on element e (constant)\n        u_h_prime_val = (u_e1 - u_e) / h\n\n        # Loop over Gauss points\n        for z_k, w_k in zip(z_pts, w_pts):\n            # Map reference point to physical coordinate\n            x_q = x_e + h * (z_k + 1.0) / 2.0\n            \n            # Evaluate exact solution and its derivative\n            u_exact_val = u_exact_func(x_q)\n            u_exact_prime_val = u_exact_prime_func(x_q)\n            \n            # Evaluate FE solution at x_q\n            # Local coordinate xi is (z_k+1)/2\n            xi_q = (z_k + 1.0) / 2.0\n            u_h_val = u_e * (1.0 - xi_q) + u_e1 * xi_q\n            \n            # Accumulate squared errors\n            l2_err_sq += w_k * (u_exact_val - u_h_val)**2\n            h1_err_sq += w_k * (u_exact_prime_val - u_h_prime_val)**2\n    \n    # Apply Jacobian determinant and take square root\n    # The Jacobian factor is h/2\n    l2_err = np.sqrt(l2_err_sq * h / 2.0)\n    h1_err = np.sqrt(h1_err_sq * h / 2.0)\n    \n    return l2_err, h1_err\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3525095"}, {"introduction": "A correct formulation is not always a stable one, and for saddle-point problems, this stability is governed by the celebrated Ladyzhenskaya-BabuÅ¡ka-Brezzi (LBB) or inf-sup condition. This exercise moves from implementation to the crucial theory of stability by asking you to demonstrate its failure for an unstable choice of finite elements for the Stokes equations. By explicitly constructing a non-physical 'checkerboard' pressure mode, you will make the abstract LBB condition tangible and appreciate why specific, stable element pairs are essential for reliable fluid dynamics simulations [@problem_id:3525102].", "problem": "Consider the stationary incompressible Stokes equations on the unit square domain $\\Omega = [0,1]^{2}$, with homogeneous Dirichlet boundary conditions for the velocity. Let the weak formulation be given by the saddle-point system: find velocity $u \\in V$ and pressure $p \\in Q$ such that\n$$\na(u,v) + b(v,p) = f(v) \\quad \\text{for all } v \\in V, \\qquad b(u,q) = 0 \\quad \\text{for all } q \\in Q,\n$$\nwhere $V$ is the Sobolev space of square-integrable vector fields with square-integrable gradients and vanishing trace on $\\partial \\Omega$, $Q$ is the space of square-integrable functions with zero mean over $\\Omega$, $a(u,v) = \\int_{\\Omega} 2\\mu \\, \\epsilon(u) : \\epsilon(v) \\, dx$ with $\\epsilon(u)$ the symmetric gradient, and $b(v,p) = -\\int_{\\Omega} p \\, \\nabla \\cdot v \\, dx$. In the Finite Element Method (FEM), consider the equal-order discrete spaces\n$$\nV_{h} = \\{ v_{h} \\in V : v_{h} \\text{ is continuous and piecewise linear ($P_{1}$) on a triangulation of } \\Omega \\}^{2},\n$$\n$$\nQ_{h} = \\{ q_{h} \\in Q : q_{h} \\text{ is continuous and piecewise linear ($P_{1}$) on the same triangulation} \\}.\n$$\n\nUse the following conforming triangulation $\\mathcal{T}_{h}$ of $\\Omega$: the vertex set consists of the four corners $(0,0)$, $(1,0)$, $(1,1)$, $(0,1)$ and the interior point $C = (1/2,1/2)$. The mesh is made of four triangles sharing the interior vertex $C$:\n- $T_{1}$ with vertices $C$, $(0,0)$, $(1,0)$,\n- $T_{2}$ with vertices $C$, $(1,0)$, $(1,1)$,\n- $T_{3}$ with vertices $C$, $(1,1)$, $(0,1)$,\n- $T_{4}$ with vertices $C$, $(0,1)$, $(0,0)$.\n\nAssume the discrete velocity space $V_{h}$ enforces homogeneous Dirichlet boundary conditions strongly, so only the interior node $C$ carries velocity degrees of freedom. Let $\\{N_{i}\\}$ denote the scalar $P_{1}$ nodal shape functions associated with the nodes $i \\in \\{(0,0), (1,0), (1,1), (0,1), C\\}$, and let velocity basis functions be $\\phi_{C}^{x} = (N_{C}, 0)$ and $\\phi_{C}^{y} = (0, N_{C})$. The discrete coupling bilinear form is\n$$\nb(v_{h},q_{h}) = -\\int_{\\Omega} q_{h} \\, \\nabla \\cdot v_{h} \\, dx.\n$$\n\nStarting from the above fundamental definitions and properties of piecewise linear functions on triangles, construct an explicit nonzero $q_{h} \\in Q_{h}$ whose nodal values $\\{p_{(0,0)}, p_{(1,0)}, p_{(1,1)}, p_{(0,1)}, p_{C}\\}$ satisfy\n$$\nb(v_{h}, q_{h}) = 0 \\quad \\text{for all } v_{h} \\in V_{h}.\n$$\n\nYour task:\n- Derive the necessary and sufficient conditions on $\\{p_{(0,0)}, p_{(1,0)}, p_{(1,1)}, p_{(0,1)}, p_{C}\\}$ implied by the structure of $\\mathcal{T}_{h}$ for $b(v_{h}, q_{h})$ to vanish for all $v_{h} \\in V_{h}$.\n- Use these conditions to construct a concrete nonzero spurious pressure mode $q_{h}$ represented by its nodal values.\n- Provide the final answer as the row vector of nodal values\n$$\n\\left(p_{(0,0)} \\ \\ p_{(1,0)} \\ \\ p_{(1,1)} \\ \\ p_{(0,1)} \\ \\ p_{C}\\right),\n$$\nin exact form. No rounding is required, and no physical units are involved.", "solution": "The objective is to find a nonzero discrete pressure field $q_{h} \\in Q_{h}$ such that it is orthogonal to the image of the discrete divergence operator, i.e., $b(v_{h}, q_{h}) = 0$ for all discrete velocity fields $v_{h} \\in V_{h}$. A pressure field $q_h$ with this property is known as a spurious pressure mode, and its existence indicates the instability of the chosen velocity-pressure finite element pair ($P_1-P_1$ in this case).\n\nThe condition to be satisfied is:\n$$b(v_{h}, q_{h}) = -\\int_{\\Omega} q_{h} \\, \\nabla \\cdot v_{h} \\, dx = 0 \\quad \\text{for all } v_{h} \\in V_{h}.$$\nSince this must hold for any $v_{h} \\in V_{h}$, it must hold for the basis functions that span $V_{h}$. From the problem description, the homogeneous Dirichlet boundary conditions are enforced strongly. The only node with non-zero velocity degrees of freedom is the interior node $C = (1/2, 1/2)$. Thus, the discrete velocity space $V_{h}$ is a $2$-dimensional space spanned by the basis functions $\\phi_{C}^{x} = (N_{C}, 0)$ and $\\phi_{C}^{y} = (0, N_{C})$, where $N_{C}$ is the continuous, piecewise linear nodal basis function associated with node $C$.\n\nThe pressure field $q_{h}$ is an element of $Q_{h}$ and can be expressed as a linear combination of the nodal basis functions $\\{N_i\\}$ for all five nodes: the corners $V_{(0,0)}=(0,0)$, $V_{(1,0)}=(1,0)$, $V_{(1,1)}=(1,1)$, $V_{(0,1)}=(0,1)$, and the center $C$. Let the nodal values of $q_{h}$ be $\\{p_{(0,0)}, p_{(1,0)}, p_{(1,1)}, p_{(0,1)}, p_{C}\\}$. Then,\n$$q_{h}(x,y) = p_{(0,0)}N_{(0,0)}(x,y) + p_{(1,0)}N_{(1,0)}(x,y) + p_{(1,1)}N_{(1,1)}(x,y) + p_{(0,1)}N_{(0,1)}(x,y) + p_{C}N_{C}(x,y).$$\n\nThe condition $b(v_{h}, q_{h}) = 0$ for all $v_h \\in V_h$ reduces to two scalar equations:\n$1.$ $b(\\phi_{C}^{x}, q_{h}) = -\\int_{\\Omega} q_{h} \\nabla \\cdot \\phi_{C}^{x} \\, dx = -\\int_{\\Omega} q_{h} \\frac{\\partial N_{C}}{\\partial x} \\, dx = 0$.\n$2.$ $b(\\phi_{C}^{y}, q_{h}) = -\\int_{\\Omega} q_{h} \\nabla \\cdot \\phi_{C}^{y} \\, dx = -\\int_{\\Omega} q_{h} \\frac{\\partial N_{C}}{\\partial y} \\, dx = 0$.\n\nLet's analyze the gradient of the basis function $N_C$. On each triangle $T_k$, $N_C$ is a linear function, so its gradient is a constant vector. The basis function $N_C$ has value $1$ at node $C$ and $0$ at all other nodes. The gradients on the four triangles are:\n- On $T_{1}$ (vertices $C, (0,0), (1,0)$): $\\nabla N_{C}|_{T_1} = (0, 2)$.\n- On $T_{2}$ (vertices $C, (1,0), (1,1)$): $\\nabla N_{C}|_{T_2} = (-2, 0)$.\n- On $T_{3}$ (vertices $C, (1,1), (0,1)$): $\\nabla N_{C}|_{T_3} = (0, -2)$.\n- On $T_{4}$ (vertices $C, (0,1), (0,0)$): $\\nabla N_{C}|_{T_4} = (2, 0)$.\n\nThus, $\\frac{\\partial N_C}{\\partial x}$ is non-zero only on $T_2$ and $T_4$, and $\\frac{\\partial N_C}{\\partial y}$ is non-zero only on $T_1$ and $T_3$.\n\nNow we evaluate the first equation:\n$$-\\int_{\\Omega} q_{h} \\frac{\\partial N_{C}}{\\partial x} \\, dx = -\\left( \\int_{T_2} q_{h} (-2) \\, dx + \\int_{T_4} q_{h} (2) \\, dx \\right) = 0.$$\nThis simplifies to $\\int_{T_2} q_{h} \\, dx = \\int_{T_4} q_{h} \\, dx$.\nThe integral of a linear function over a triangle is its area multiplied by the average of its nodal values at the vertices. The area of each triangle is $\\frac{1}{4}$.\nThe vertices of $T_2$ are $C, (1,0), (1,1)$. So, $\\int_{T_2} q_{h} dx = \\frac{\\text{Area}(T_2)}{3}(p_C + p_{(1,0)} + p_{(1,1)}) = \\frac{1}{12}(p_C + p_{(1,0)} + p_{(1,1)})$.\nThe vertices of $T_4$ are $C, (0,1), (0,0)$. So, $\\int_{T_4} q_{h} dx = \\frac{\\text{Area}(T_4)}{3}(p_C + p_{(0,1)} + p_{(0,0)}) = \\frac{1}{12}(p_C + p_{(0,1)} + p_{(0,0)})$.\nEquating these gives $p_C + p_{(1,0)} + p_{(1,1)} = p_C + p_{(0,1)} + p_{(0,0)}$, which yields our first condition on the nodal pressures:\n$$(1) \\quad p_{(0,0)} - p_{(1,0)} - p_{(1,1)} + p_{(0,1)} = 0.$$\n\nNext, we evaluate the second equation:\n$$-\\int_{\\Omega} q_{h} \\frac{\\partial N_{C}}{\\partial y} \\, dx = -\\left( \\int_{T_1} q_{h} (2) \\, dx + \\int_{T_3} q_{h} (-2) \\, dx \\right) = 0.$$\nThis simplifies to $\\int_{T_1} q_{h} \\, dx = \\int_{T_3} q_{h} \\, dx$.\nThe vertices of $T_1$ are $C, (0,0), (1,0)$. So, $\\int_{T_1} q_h dx = \\frac{1}{12}(p_C + p_{(0,0)} + p_{(1,0)})$.\nThe vertices of $T_3$ are $C, (1,1), (0,1)$. So, $\\int_{T_3} q_h dx = \\frac{1}{12}(p_C + p_{(1,1)} + p_{(0,1)})$.\nEquating these gives $p_C + p_{(0,0)} + p_{(1,0)} = p_C + p_{(1,1)} + p_{(0,1)}$, which yields our second condition:\n$$(2) \\quad p_{(0,0)} + p_{(1,0)} - p_{(1,1)} - p_{(0,1)} = 0.$$\n\nFinally, the space $Q_h$ is a subspace of $L^2_0(\\Omega)$, meaning the pressure field must have a zero mean over $\\Omega$:\n$$\\int_{\\Omega} q_{h} \\, dx = \\sum_{k=1}^4 \\int_{T_k} q_h \\, dx = 0.$$\nSumming the integrals over the four triangles:\n$$\\frac{1}{12} \\left[ (p_C+p_{(0,0)}+p_{(1,0)}) + (p_C+p_{(1,0)}+p_{(1,1)}) + (p_C+p_{(1,1)}+p_{(0,1)}) + (p_C+p_{(0,1)}+p_{(0,0)}) \\right] = 0.$$\nThis simplifies to $\\frac{1}{12} (4p_C + 2p_{(0,0)} + 2p_{(1,0)} + 2p_{(1,1)} + 2p_{(0,1)}) = 0$.\nSo, the third condition is:\n$$(3) \\quad p_{(0,0)} + p_{(1,0)} + p_{(1,1)} + p_{(0,1)} + 2p_C = 0.$$\n\nWe have a system of three linear equations for five unknowns. Let's find the relations between them.\nAdding equations $(1)$ and $(2)$:\n$(p_{(0,0)} - p_{(1,0)} - p_{(1,1)} + p_{(0,1)}) + (p_{(0,0)} + p_{(1,0)} - p_{(1,1)} - p_{(0,1)}) = 0 \\implies 2p_{(0,0)} - 2p_{(1,1)} = 0 \\implies p_{(1,1)} = p_{(0,0)}$.\nSubtracting equation $(1)$ from $(2)$:\n$(p_{(0,0)} + p_{(1,0)} - p_{(1,1)} - p_{(0,1)}) - (p_{(0,0)} - p_{(1,0)} - p_{(1,1)} + p_{(0,1)}) = 0 \\implies 2p_{(1,0)} - 2p_{(0,1)} = 0 \\implies p_{(0,1)} = p_{(1,0)}$.\nThese are necessary conditions: the nodal pressures at diagonally opposite corners must be equal.\n\nSubstituting these into equation (3):\n$p_{(0,0)} + p_{(1,0)} + p_{(0,0)} + p_{(1,0)} + 2p_C = 0 \\implies 2p_{(0,0)} + 2p_{(1,0)} + 2p_C = 0$.\nThis gives the final condition: $p_C = -p_{(0,0)} - p_{(1,0)}$.\n\nThe necessary and sufficient conditions on the nodal values for $q_h$ to be a spurious pressure mode are:\n- $p_{(1,1)} = p_{(0,0)}$\n- $p_{(0,1)} = p_{(1,0)}$\n- $p_C = -(p_{(0,0)} + p_{(1,0)})$\n\nThis defines a two-dimensional space of spurious modes. Any choice of $p_{(0,0)}$ and $p_{(1,0)}$ (not both zero) will generate a valid nonzero mode. A canonical choice for illustrating this phenomenon is the \"checkerboard\" mode. Let's set $p_{(0,0)} = 1$ and $p_{(1,0)} = -1$.\nUsing the derived conditions:\n- $p_{(1,1)} = p_{(0,0)} = 1$.\n- $p_{(0,1)} = p_{(1,0)} = -1$.\n- $p_C = -(1 + (-1)) = 0$.\n\nThis gives the nodal pressure vector $(p_{(0,0)}, p_{(1,0)}, p_{(1,1)}, p_{(0,1)}, p_C) = (1, -1, 1, -1, 0)$. This is a concrete, nonzero spurious pressure mode.\nThe final answer is the row vector of these nodal values in the specified order.", "answer": "$$\\boxed{\\begin{pmatrix} 1 & -1 & 1 & -1 & 0 \\end{pmatrix}}$$", "id": "3525102"}, {"introduction": "Once a stable saddle-point system is formulated, the next major challenge is solving the resulting large, ill-conditioned linear system efficiently, especially in multiphysics settings with high material contrasts. This practice delves into the critical topic of preconditioning, where the solver's performance can depend dramatically on the choice of preconditioner. By analyzing a model problem with high-contrast permeability, you will quantitatively measure how a 'robust' preconditioner, which respects the system's block structure, maintains its effectiveness while a naive approach fails, providing a key lesson in designing scalable solvers for complex simulations [@problem_id:3525074].", "problem": "Consider a mixed Darcy-type saddle-point formulation on a one-dimensional uniform grid that abstractly models a two-region medium with piecewise-constant permeability. Let there be $N$ cells and $m = N+1$ flux unknowns located on cell interfaces. Define the discrete divergence operator $B \\in \\mathbb{R}^{N \\times m}$ by\n$$\n(B u)_i = u_{i+1} - u_i, \\quad i = 1,\\dots,N,\n$$\nwhere $u \\in \\mathbb{R}^m$ is the vector of fluxes ordered from left to right. Let the permeability be piecewise constant across two contiguous regions: for an interface index $L \\in \\{1,\\dots,m-1\\}$, set\n$$\n\\kappa_j =\n\\begin{cases}\n\\kappa_L, & j \\in \\{1,2,\\dots,L\\}, \\\\\n\\kappa_R, & j \\in \\{L+1,\\dots,m\\}.\n\\end{cases}\n$$\nWe define the contrast parameter $\\gamma = \\kappa_R / \\kappa_L \\ge 1$. For definiteness, take $\\kappa_L = 1$ so that $\\kappa_R = \\gamma$. Define the symmetric positive definite (SPD) block\n$$\nA = \\mathrm{diag}(\\kappa_1^{-1}, \\dots, \\kappa_m^{-1}) \\in \\mathbb{R}^{m \\times m},\n$$\nand the saddle-point matrix\n$$\n\\mathcal{S} =\n\\begin{bmatrix}\nA & B^\\top \\\\\nB & 0\n\\end{bmatrix}\n\\in \\mathbb{R}^{(m+N) \\times (m+N)}.\n$$\nThis $\\mathcal{S}$ arises from the mixed Darcy equations $\\kappa^{-1} u + \\nabla p = 0$, $\\nabla \\cdot u = f$ upon lowest-order discretization, abstracting geometric constants, where $u$ are flux unknowns and $p$ are cellwise pressures, and $B$ discretizes the divergence operator.\n\nWe study parameter-robust block-diagonal preconditioning for $\\mathcal{S}$ with respect to the contrast $\\gamma$. Consider the following two SPD preconditioners:\n- A naive block-diagonal preconditioner\n$$\n\\mathcal{P}_{\\mathrm{N}} = \\mathrm{diag}(A, I_N),\n$$\nwhere $I_N \\in \\mathbb{R}^{N \\times N}$ is the identity matrix.\n- A robust block-diagonal preconditioner that uses the exact Schur complement\n$$\n\\mathcal{P}_{\\mathrm{R}} = \\mathrm{diag}\\big(A, \\, S_p\\big), \\quad \\text{with } S_p = B A^{-1} B^\\top = B \\, \\mathrm{diag}(\\kappa_1,\\dots,\\kappa_m)\\, B^\\top.\n$$\n\nFrom first principles of saddle-point theory and the Brezzi conditions, the spectral properties of the generalized eigenproblem\n$$\n\\mathcal{S} x = \\lambda \\, \\mathcal{P} \\, x\n$$\nwith an SPD $\\mathcal{P}$ determine the quality of the preconditioner; the spectral condition number of the preconditioned operator in the $\\mathcal{P}$-inner product is\n$$\n\\kappa(\\mathcal{P}^{-1}\\mathcal{S}) = \\frac{\\max_i |\\lambda_i|}{\\min_i |\\lambda_i|},\n$$\nwhere $\\{\\lambda_i\\}$ are the generalized eigenvalues of $(\\mathcal{S}, \\mathcal{P})$.\n\nYour tasks are:\n1. Starting from the mixed Darcy formulation $\\kappa^{-1} u + \\nabla p = 0$, $\\nabla \\cdot u = f$, and the definition of the discrete divergence $B$, justify why the Schur complement for pressures is $S_p = B A^{-1} B^\\top$ and explain, at the operator level, why the robust choice $\\mathcal{P}_{\\mathrm{R}}$ yields a condition number bounded independently of the contrast $\\gamma$, whereas $\\mathcal{P}_{\\mathrm{N}}$ does not.\n2. Implement the matrices $B$, $A$, $\\mathcal{S}$, and the preconditioners $\\mathcal{P}_{\\mathrm{N}}$ and $\\mathcal{P}_{\\mathrm{R}}$ as described above for a uniform grid. Use $L = \\lfloor \\alpha \\, m \\rfloor$ with interface fraction $\\alpha \\in (0,1)$ and enforce $L \\in \\{1,\\dots,m-1\\}$ by clamping if necessary.\n3. For each fixed configuration $(N,\\alpha)$, evaluate the spectral condition number $\\kappa(\\mathcal{P}^{-1}\\mathcal{S})$ by solving the generalized symmetric definite eigenproblem for the following set of contrast values\n$$\n\\gamma \\in \\{1, 10^2, 10^4, 10^6, 10^8\\}.\n$$\nFor each configuration and each preconditioner, compute the empirical scaling exponent $b$ in the power-law model\n$$\n\\kappa(\\mathcal{P}^{-1}\\mathcal{S}) \\approx C \\, \\gamma^{\\,b}\n$$\nby a least-squares linear fit of $\\log \\kappa$ versus $\\log \\gamma$ over the above set of $\\gamma$ values.\n4. Use the following test suite of grid/interface configurations:\n- Case A (happy path): $N = 64$, $\\alpha = 0.5$.\n- Case B (edge case with small high-contrast region): $N = 64$, $\\alpha = 0.1$.\n- Case C (refinement study): $N = 128$, $\\alpha = 0.5$.\nFor each case, compute two floats: the fitted exponent $b_{\\mathrm{N}}$ for $\\mathcal{P}_{\\mathrm{N}}$ and $b_{\\mathrm{R}}$ for $\\mathcal{P}_{\\mathrm{R}}$.\n5. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n$$\n[b_{\\mathrm{N}}^{\\mathrm{A}}, \\, b_{\\mathrm{R}}^{\\mathrm{A}}, \\, b_{\\mathrm{N}}^{\\mathrm{B}}, \\, b_{\\mathrm{R}}^{\\mathrm{B}}, \\, b_{\\mathrm{N}}^{\\mathrm{C}}, \\, b_{\\mathrm{R}}^{\\mathrm{C}}].\n$$\n\nNotes and constraints:\n- All computations are dimensionless; no physical units are required.\n- All angles, if any, must be in radians; no angles are used here.\n- For numerical stability, all matrices should be assembled in double precision and generalized eigenproblems should be solved as symmetric definite problems.\n- The implementation must be self-contained, with no user input or external files, and must adhere to the execution environment specified later.", "solution": "The problem is valid. It presents a well-posed and scientifically grounded numerical experiment in the field of preconditioning for saddle-point systems, which is a standard topic in numerical linear algebra and scientific computing. All terms are clearly defined, and the tasks are computationally and theoretically feasible.\n\n### Part 1: Theoretical Justification\n\nThis section addresses the first task: justifying the form of the Schur complement and explaining the contrast-dependency of the two preconditioners.\n\nThe discrete saddle-point system is given by the block matrix equation:\n$$\n\\mathcal{S} \\begin{pmatrix} u \\\\ p \\end{pmatrix} = \\begin{pmatrix} A & B^\\top \\\\ B & 0 \\end{pmatrix} \\begin{pmatrix} u \\\\ p \\end{pmatrix} = \\begin{pmatrix} g \\\\ f \\end{pmatrix}\n$$\nHere, $u \\in \\mathbb{R}^m$ is the vector of flux unknowns, and $p \\in \\mathbb{R}^N$ is the vector of cell-centered pressure unknowns. The physical origin is the mixed Darcy system $\\kappa^{-1} u + \\nabla p = 0$ and $\\nabla \\cdot u = f$, which corresponds to setting $g=0$ in the discrete system.\n\nThe two block-rows of the system are:\n$$\nA u + B^\\top p = g \\quad (1)\n$$\n$$\nB u = f \\quad (2)\n$$\nFrom equation $(1)$, we can formally express $u$ in terms of $p$. Since $A = \\mathrm{diag}(\\kappa_1^{-1}, \\dots, \\kappa_m^{-1})$ and all $\\kappa_j > 0$, $A$ is symmetric positive definite (SPD) and thus invertible.\n$$\nu = A^{-1} (g - B^\\top p) \\quad (3)\n$$\nSubstituting this expression for $u$ into equation $(2)$ eliminates the $u$ variable:\n$$\nB \\left( A^{-1} (g - B^\\top p) \\right) = f\n$$\nRearranging the terms to solve for $p$ yields:\n$$\n(B A^{-1} B^\\top) p = B A^{-1} g - f\n$$\nThe matrix $S_p = B A^{-1} B^\\top$ is defined as the Schur complement of the system with respect to the pressure variable $p$. This justifies the expression for $S_p$ given in the problem statement. The matrix $A^{-1}$ is $\\mathrm{diag}(\\kappa_1, \\dots, \\kappa_m)$, so $S_p = B \\, \\mathrm{diag}(\\kappa_1, \\dots, \\kappa_m) \\, B^\\top$.\n\nNow, we analyze the robustness of the two preconditioners with respect to the permeability contrast $\\gamma = \\kappa_R / \\kappa_L$.\n\n**Robust Preconditioner $\\mathcal{P}_{\\mathrm{R}} = \\mathrm{diag}(A, S_p)$:**\nThis preconditioner is constructed using the diagonal blocks of $\\mathcal{S}$, but with the zero block replaced by the exact Schur complement $S_p$. The preconditioned matrix is $\\mathcal{P}_{\\mathrm{R}}^{-1} \\mathcal{S}$. Its action on a vector is:\n$$\n\\mathcal{P}_{\\mathrm{R}}^{-1} \\mathcal{S} = \\begin{bmatrix} A^{-1} & 0 \\\\ 0 & S_p^{-1} \\end{bmatrix} \\begin{bmatrix} A & B^\\top \\\\ B & 0 \\end{bmatrix} = \\begin{bmatrix} I_m & A^{-1} B^\\top \\\\ S_p^{-1} B & 0 \\end{bmatrix}\n$$\nThe eigenvalues $\\lambda$ of this operator are known from the theory of saddle-point preconditioning. For any well-posed saddle-point problem, preconditioning with the exact Schur complement results in eigenvalues that are independent of the specific properties of the blocks $A$ and $B$. In this case, the non-zero, finite eigenvalues of $\\mathcal{P}_{\\mathrm{R}}^{-1} \\mathcal{S}$ are clustered at a few values, namely $1$ and $\\frac{1 \\pm \\sqrt{5}}{2}$. Since these values are constant, the spectral condition number $\\kappa(\\mathcal{P}_{\\mathrm{R}}^{-1}\\mathcal{S})$ is a small constant, bounded independently of the problem parameters, including the mesh size $N$ and, critically, the contrast parameter $\\gamma$. The inclusion of $A$ and $S_p = B A^{-1} B^\\top$ in the preconditioner construction perfectly captures the influence of the permeability $\\kappa$ (and thus $\\gamma$), rendering the preconditioned system immune to its variations.\n\n**Naive Preconditioner $\\mathcal{P}_{\\mathrm{N}} = \\mathrm{diag}(A, I_N)$:**\nThis preconditioner uses the identity matrix $I_N$ as an approximation for the Schur complement $S_p$. The preconditioned matrix is:\n$$\n\\mathcal{P}_{\\mathrm{N}}^{-1} \\mathcal{S} = \\begin{bmatrix} A^{-1} & 0 \\\\ 0 & I_N \\end{bmatrix} \\begin{bmatrix} A & B^\\top \\\\ B & 0 \\end{bmatrix} = \\begin{bmatrix} I_m & A^{-1} B^\\top \\\\ B & 0 \\end{bmatrix}\n$$\nThe quality of this preconditioner hinges on how well $I_N$ approximates $S_p$. The condition number of the preconditioned system is related to the spectral equivalence between the preconditioner blocks and the system blocks. In particular, it depends on the condition number of $I_N^{-1}S_p$, which is simply $\\kappa(S_p)$.\nThe Schur complement $S_p = B \\, \\mathrm{diag}(\\kappa_1, \\dots, \\kappa_m) \\, B^\\top$ is a discrete weighted Laplacian operator. Its matrix entries and therefore its eigenvalues are directly proportional to the values of $\\kappa_j$. As the contrast $\\gamma$ increases, some $\\kappa_j$ values become large, causing the eigenvalues of $S_p$ to span a range $[\\lambda_{\\min}, \\lambda_{\\max}]$ whose width scales with $\\gamma$. Consequently, $\\kappa(S_p) = \\lambda_{\\max}(S_p) / \\lambda_{\\min}(S_p)$ will grow with $\\gamma$. Since $I_N$ has all eigenvalues equal to $1$, it is a very poor approximation of $S_p$ when $\\gamma \\gg 1$. This poor approximation of the Schur complement block causes the overall condition number $\\kappa(\\mathcal{P}_{\\mathrm{N}}^{-1}\\mathcal{S})$ to degrade, exhibiting a strong dependency on $\\gamma$. We expect a power-law relationship $\\kappa \\approx C\\gamma^b$ with an exponent $b \\approx 1$.\n\n### Part 2: Numerical Implementation Strategy\n\nThe numerical tasks are to implement the matrices, solve the generalized eigenproblems, and compute the scaling exponents.\n\n1.  **Matrix Assembly:** For each configuration $(N, \\alpha)$ and each contrast value $\\gamma$, the matrices are assembled.\n    *   The permeability vector $\\kappa$ of size $m=N+1$ is constructed based on $L = \\lfloor \\alpha m \\rfloor$.\n    *   The matrix $A = \\mathrm{diag}(\\kappa_j^{-1})$ is formed.\n    *   The discrete divergence matrix $B \\in \\mathbb{R}^{N \\times m}$ is constructed such that $(Bu)_i = u_{i+1} - u_i$.\n    *   The full saddle-point matrix $\\mathcal{S}$ is assembled as a block matrix.\n    *   The preconditioners $\\mathcal{P}_{\\mathrm{N}} = \\mathrm{diag}(A, I_N)$ and $\\mathcal{P}_{\\mathrm{R}} = \\mathrm{diag}(A, S_p)$ are assembled, with $S_p = B A^{-1} B^\\top$.\n\n2.  **Eigenvalue Computation:** The spectral condition numbers are found by solving the generalized eigenproblems $\\mathcal{S}x = \\lambda \\mathcal{P} x$.\n    *   The matrix $\\mathcal{S}$ is singular, reflecting the fact that the pressure is only determined up to a constant (a pure Neumann problem). Its nullspace is spanned by $(u,p)^\\top = (0, \\mathbf{1})^\\top$, where $\\mathbf{1}$ is the vector of all ones. The preconditioner $\\mathcal{P_N}$ is SPD. The resulting generalized eigenproblem will have one zero eigenvalue.\n    *   The preconditioner $\\mathcal{P_R}$ is also singular, as $S_p$ inherits the nullspace of $B^\\top$ (the constant vectors). Crucially, the nullspaces of $\\mathcal{S}$ and $\\mathcal{P_R}$ are identical.\n    *   Due to the semi-definite nature of $\\mathcal{P_R}$, a generalized eigenvalue solver `scipy.linalg.eig` must be used, as solvers like `scipy.linalg.eigh` require a positive definite second matrix. The $0/0$ eigenvalue corresponding to the common nullspace may be returned as `NaN` (Not a Number).\n    *   For both preconditioners, the computed eigenvalues must be filtered. Any zero, `NaN`, or `Inf` values are removed to isolate the physical spectrum. The condition number is then computed as $\\kappa = \\max|\\lambda_i| / \\min|\\lambda_i|$ over the set of filtered, non-zero eigenvalues.\n\n3.  **Exponent Fitting:** For each test case and each preconditioner, a set of condition numbers $\\{\\kappa_j\\}$ is computed for the set of a contrast values $\\{\\gamma_j\\}$. The scaling exponent $b$ in the model $\\kappa \\approx C\\gamma^b$ is determined by a linear least-squares fit on the logarithmic data:\n    $$\n    \\log(\\kappa) = b \\log(\\gamma) + \\log(C)\n    $$\n    This is a linear regression of $\\log(\\kappa)$ against $\\log(\\gamma)$, where the slope of the fitted line is the desired exponent $b$. The numerical results are expected to show $b_{\\mathrm{N}} \\approx 1$ and $b_{\\mathrm{R}} \\approx 0$, confirming the theoretical analysis.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (64, 0.5),  # Case A\n        (64, 0.1),  # Case B\n        (128, 0.5), # Case C\n    ]\n\n    results = []\n    for N, alpha in test_cases:\n        b_N, b_R = compute_exponents(N, alpha)\n        results.extend([b_N, b_R])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\n\ndef assemble_matrices(N, alpha, gamma):\n    \"\"\"\n    Assembles the saddle-point system matrix and the two preconditioners\n    for a given grid size N, interface fraction alpha, and contrast gamma.\n    \"\"\"\n    m = N + 1\n    \n    # Determine the interface location L (0-based index).\n    # The problem defines L in {1, ..., m-1} (1-based).\n    # In 0-based, the interface is between index L-1 and L.\n    # Fluxes 0 to L-1 have kappa=1, fluxes L to m-1 have kappa=gamma.\n    L_float = alpha * m\n    L = int(L_float)\n    # Clamp L to ensure it's a valid interface index in {1, ..., m-1}.\n    L = max(1, min(m - 1, L))\n\n    # Permeability vector kappa (size m)\n    kappa = np.ones(m, dtype=np.float64)\n    kappa[L:] = gamma\n\n    # SPD block A (m x m)\n    A = np.diag(1.0 / kappa)\n\n    # Discrete divergence B (N x m)\n    # (B u)_i = u_{i+1} - u_i translates to B[i, i+1]=1, B[i, i]=-1 in 0-based index.\n    B = np.zeros((N, m), dtype=np.float64)\n    # Fast construction of B without loops\n    eye_N_m_k1 = np.eye(N, M=m, k=1, dtype=np.float64)\n    eye_N_m_k0 = np.eye(N, M=m, k=0, dtype=np.float64)\n    B = eye_N_m_k1 - eye_N_m_k0\n\n    # Saddle-point matrix S ((m+N) x (m+N))\n    S_mat = np.block([\n        [A, B.T],\n        [B, np.zeros((N, N), dtype=np.float64)]\n    ])\n\n    # Naive preconditioner P_N\n    I_N = np.eye(N, dtype=np.float64)\n    P_N = np.zeros_like(S_mat)\n    P_N[:m, :m] = A\n    P_N[m:, m:] = I_N\n\n    # Robust preconditioner P_R\n    # Schur complement S_p = B * diag(kappa) * B^T\n    K_matrix = np.diag(kappa)\n    S_p = B @ K_matrix @ B.T\n    P_R = np.zeros_like(S_mat)\n    P_R[:m, :m] = A\n    P_R[m:, m:] = S_p\n    \n    return S_mat, P_N, P_R\n\ndef compute_exponents(N, alpha):\n    \"\"\"\n    For a given configuration (N, alpha), computes the condition numbers\n    for a range of gamma values, and fits the scaling exponents b_N and b_R.\n    \"\"\"\n    gammas = np.array([1.0, 1e2, 1e4, 1e6, 1e8], dtype=np.float64)\n    log_gammas = np.log(gammas)\n\n    kappas_N = []\n    kappas_R = []\n\n    for gamma in gammas:\n        S, P_N, P_R = assemble_matrices(N, alpha, gamma)\n\n        # --- Naive Preconditioner P_N ---\n        # The generalized eigenproblem is S x = lambda * P_N x.\n        # P_N is symmetric positive definite, while S is symmetric indefinite.\n        eigvals_N = linalg.eig(S, P_N, right=False)\n        \n        # Filter out the zero eigenvalue corresponding to the nullspace of S.\n        eigvals_N_abs = np.abs(eigvals_N)\n        eigvals_N_nonzero = eigvals_N_abs[eigvals_N_abs > 1e-10]\n        kappa_N = np.max(eigvals_N_nonzero) / np.min(eigvals_N_nonzero)\n        kappas_N.append(kappa_N)\n\n        # --- Robust Preconditioner P_R ---\n        # The generalized eigenproblem is S x = lambda * P_R x.\n        # Both S and P_R are singular with a common nullspace. P_R is semi-definite.\n        # linalg.eig is used, which may produce 'nan' for the 0/0 eigenvalue.\n        eigvals_R = linalg.eig(S, P_R, right=False)\n        \n        # Filter out NaN, Inf, and near-zero eigenvalues.\n        finite_eigvals_R = eigvals_R[np.isfinite(eigvals_R)]\n        eigvals_R_abs = np.abs(finite_eigvals_R)\n        eigvals_R_nonzero = eigvals_R_abs[eigvals_R_abs > 1e-10]\n        \n        if len(eigvals_R_nonzero) == 0:\n            # This can happen in ideal cases where all physical eigenvalues are 1.\n            kappa_R = 1.0\n        else:\n            kappa_R = np.max(eigvals_R_nonzero) / np.min(eigvals_R_nonzero)\n        kappas_R.append(kappa_R)\n\n    # Perform a linear least-squares fit on log-log data to find the exponent b.\n    # We are fitting log(kappa) = b * log(gamma) + c.\n    A_fit = np.vstack([log_gammas, np.ones(len(log_gammas))]).T\n    \n    # Fit for P_N\n    log_kappas_N = np.log(kappas_N)\n    b_N, _ = np.linalg.lstsq(A_fit, log_kappas_N, rcond=None)[0]\n\n    # Fit for P_R\n    log_kappas_R = np.log(kappas_R)\n    b_R, _ = np.linalg.lstsq(A_fit, log_kappas_R, rcond=None)[0]\n\n    return b_N, b_R\n\nif __name__ == '__main__':\n    solve()\n\n```", "id": "3525074"}]}