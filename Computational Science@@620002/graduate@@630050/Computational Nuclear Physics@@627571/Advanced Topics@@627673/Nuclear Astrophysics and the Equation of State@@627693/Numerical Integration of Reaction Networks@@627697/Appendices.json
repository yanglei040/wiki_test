{"hands_on_practices": [{"introduction": "A primary challenge in integrating reaction networks is maintaining the physical constraint that all species abundances must be non-negative. Simple explicit methods, like forward Euler, can easily violate this when confronted with stiff reaction rates and large time steps, yielding unphysical results. This practice demonstrates how to build a robust solver that guarantees positivity by using an implicit backward Euler method combined with a logarithmic variable transformation, a powerful and common technique in modern reaction network codes [@problem_id:3576947].", "problem": "Construct a program that integrates small nuclear reaction networks over a single, possibly large, timestep while guaranteeing nonnegative species abundances. The abundances are the nuclear abundances per baryon, denoted by $Y_i$, which are dimensionless. Time is measured in seconds. You must do the following within your program.\n\n- Model the network as a system of ordinary differential equations (ODEs) derived from mass-action kinetics. If there are $n$ species and $m$ reactions, let the stoichiometric change matrix be $N \\in \\mathbb{R}^{n \\times m}$ with entries $N_{i r} = \\nu^{\\mathrm{prod}}_{i r} - \\nu^{\\mathrm{reac}}_{i r}$, where $\\nu^{\\mathrm{prod}}_{i r}$ and $\\nu^{\\mathrm{reac}}_{i r}$ are the product and reactant stoichiometric coefficients of species $i$ in reaction $r$. For mass-action kinetics, the reaction rate for reaction $r$ is $R_r(\\mathbf{Y}) = k_r \\prod_{i=1}^{n} Y_i^{\\nu^{\\mathrm{reac}}_{i r}}$, with rate constant $k_r$ given and $\\mathbf{Y} = (Y_1,\\dots,Y_n)^{\\top}$. The ODE system is $\\frac{d\\mathbf{Y}}{dt} = \\mathbf{f}(\\mathbf{Y}) = N \\,\\mathbf{R}(\\mathbf{Y})$.\n\n- Implement two one-step methods that advance the state from $\\mathbf{Y}^{n}$ at time $t^{n}$ to $\\mathbf{Y}^{n+1}$ at time $t^{n+1} = t^{n} + \\Delta t$:\n  1. A baseline forward (explicit) Euler step, $\\mathbf{Y}^{n+1}_{\\mathrm{FE}} = \\mathbf{Y}^{n} + \\Delta t \\,\\mathbf{f}(\\mathbf{Y}^{n})$, without any clipping or postprocessing.\n  2. A positivity-guaranteeing implicit backward Euler step solved in logarithmic variables. Introduce transformed variables $\\mathbf{z} \\in \\mathbb{R}^{n}$ with $z_i = \\log Y_i$. Solve for $\\mathbf{z}^{n+1}$ such that $\\exp(\\mathbf{z}^{n+1}) = \\mathbf{Y}^{n} + \\Delta t \\,\\mathbf{f}(\\exp(\\mathbf{z}^{n+1}))$. The solver must use Newton’s method with a suitable globalization strategy to ensure convergence from a physically meaningful initial guess. The mapping back to abundances is $\\mathbf{Y}^{n+1}_{\\mathrm{BE}} = \\exp(\\mathbf{z}^{n+1})$, which guarantees $Y^{n+1}_i > 0$ by construction.\n\n- For Newton’s method on the transformed residual, derive and implement the Jacobian using the chain rule from first principles starting from the definition of $\\mathbf{f}(\\mathbf{Y})$ and the properties of mass-action kinetics. Your implementation must be robust for the provided test suite.\n\n- For any provided network, define the conserved baryon-number-like quantity using integer mass numbers $A_i$ for each species. The conserved quantity for any physically closed set of reactions is $B(\\mathbf{Y}) = \\sum_{i=1}^{n} A_i Y_i$. Your program must check conservation by comparing $B(\\mathbf{Y}^{n+1}_{\\mathrm{BE}})$ to $B(\\mathbf{Y}^{n})$.\n\n- Numerical details:\n  - Use a Newton termination criterion based on the residual norm. Terminate when $\\lVert \\mathbf{G}(\\mathbf{z}) \\rVert_2 \\le \\varepsilon_{\\mathrm{abs}} + \\varepsilon_{\\mathrm{rel}} \\lVert \\exp(\\mathbf{z}) \\rVert_2$, where $\\mathbf{G}(\\mathbf{z}) = \\exp(\\mathbf{z}) - \\mathbf{Y}^{n} - \\Delta t\\,\\mathbf{f}(\\exp(\\mathbf{z}))$, with tolerances $\\varepsilon_{\\mathrm{abs}} = 10^{-12}$ and $\\varepsilon_{\\mathrm{rel}} = 10^{-10}$. Use a maximum of $100$ Newton iterations and backtracking line search with standard Armijo decrease to ensure convergence.\n  - All abundances are dimensionless. Time is in seconds. Rate constants $k_r$ should be treated as consistent with these units; you do not need to report units for $k_r$ in the output.\n  - For any logarithm operation, ensure its argument is strictly positive by using the current positive iterate. For the initial guess of the implicit solve, use $\\mathbf{z}^{0} = \\log(\\mathbf{Y}^{n})$ with a small positive offset added componentwise if needed to avoid $\\log 0$.\n\n- Test suite:\n  Provide four test cases, each defined by its species, reactions, rate constants, mass numbers $A_i$, initial abundances $\\mathbf{Y}^{n}$, and timestep $\\Delta t$.\n  - Case $1$ (two-body fusion prone to negativity under large $\\Delta t$): species $\\{A,B,C\\}$ with mass numbers $(1,1,2)$ and reaction $A + B \\to C$ having $k = 50$. Initial abundances $\\mathbf{Y}^{n} = (0.6, 0.6, 0.0)$, $\\Delta t = 0.2$.\n  - Case $2$ (stiff reversible interconversion): species $\\{A,B\\}$ with mass numbers $(1,1)$ and reactions $A \\to B$ with $k_{f} = 100$ and $B \\to A$ with $k_{r} = 40$. Initial abundances $\\mathbf{Y}^{n} = (0.99, 0.01)$, $\\Delta t = 0.5$.\n  - Case $3$ (stiff chain): species $\\{A,B,C\\}$ with mass numbers $(1,1,1)$ and reactions $A \\to B$ with $k_{1} = 20$ and $B \\to C$ with $k_{2} = 30$. Initial abundances $\\mathbf{Y}^{n} = (0.8, 0.2, 0.0)$, $\\Delta t = 0.2$.\n  - Case $4$ (small $\\Delta t$ baseline): identical to Case $3$ but with $\\Delta t = 0.001$.\n\n- Required checks and final output specification:\n  For each case $j \\in \\{1,2,3,4\\}$, compute the following three predicates:\n  1. $P^{(j)}_{\\mathrm{FE\\_neg}}$: whether any component of $\\mathbf{Y}^{n+1}_{\\mathrm{FE}}$ is negative.\n  2. $P^{(j)}_{\\mathrm{BE\\_pos}}$: whether every component of $\\mathbf{Y}^{n+1}_{\\mathrm{BE}}$ is strictly positive to within a tolerance of $10^{-14}$.\n  3. $P^{(j)}_{\\mathrm{cons}}$: whether $\\left| B(\\mathbf{Y}^{n+1}_{\\mathrm{BE}}) - B(\\mathbf{Y}^{n}) \\right| \\le 10^{-10}$.\n  Your program must produce a single line of output containing a list of four boolean values $Q^{(j)}$, one per case, where $Q^{(j)}$ is true if and only if $P^{(j)}_{\\mathrm{FE\\_neg}}$ is true, $P^{(j)}_{\\mathrm{BE\\_pos}}$ is true, and $P^{(j)}_{\\mathrm{cons}}$ is true. The required final output format is exactly a single line:\n  \"[Q1,Q2,Q3,Q4]\"", "solution": "The problem requires the implementation and comparison of two numerical integration methods for a system of ordinary differential equations (ODEs) describing a nuclear reaction network under the assumption of mass-action kinetics. The primary objectives are to demonstrate the positivity-violating nature of the explicit forward Euler method for large timesteps and to implement a positivity-guaranteeing implicit backward Euler solver using a logarithmic variable transformation.\n\nA reaction network with $n$ species and $m$ reactions is described by the time evolution of the species abundances, $\\mathbf{Y} = (Y_1, \\dots, Y_n)^\\top$. The ODE system is given by:\n$$\n\\frac{d\\mathbf{Y}}{dt} = \\mathbf{f}(\\mathbf{Y}) = N \\mathbf{R}(\\mathbf{Y})\n$$\nwhere $N \\in \\mathbb{R}^{n \\times m}$ is the stoichiometric change matrix, with entries $N_{ir} = \\nu^{\\mathrm{prod}}_{ir} - \\nu^{\\mathrm{reac}}_{ir}$ representing the net change in species $i$ due to reaction $r$. The vector $\\mathbf{R}(\\mathbf{Y}) = (R_1, \\dots, R_m)^\\top$ contains the rates of the $m$ reactions. For mass-action kinetics, the rate of reaction $r$ is:\n$$\nR_r(\\mathbf{Y}) = k_r \\prod_{i=1}^{n} Y_i^{\\nu^{\\mathrm{reac}}_{ir}}\n$$\nwhere $k_r$ is the rate constant and $\\nu^{\\mathrm{reac}}_{ir}$ is the stoichiometric coefficient of species $i$ as a reactant in reaction $r$.\n\nThe task is to advance the system from a state $\\mathbf{Y}^n$ at time $t^n$ to a new state $\\mathbf{Y}^{n+1}$ at $t^{n+1} = t^n + \\Delta t$.\n\nFirst, we consider the baseline forward (explicit) Euler method. This is the simplest explicit one-step method, defined by:\n$$\n\\mathbf{Y}^{n+1}_{\\mathrm{FE}} = \\mathbf{Y}^{n} + \\Delta t \\, \\mathbf{f}(\\mathbf{Y}^{n})\n$$\nThis method is computationally inexpensive as it only requires one evaluation of the right-hand side function $\\mathbf{f}$. However, it is known to have a limited stability region. For stiff systems, which are common in reaction networks, the timestep $\\Delta t$ must be prohibitively small to maintain stability and, relevant to this problem, to prevent abundances from becoming negative, a physically nonsensical result.\n\nSecond, we implement a backward (implicit) Euler method. This method is A-stable and thus well-suited for stiff systems. The update formula is:\n$$\n\\mathbf{Y}^{n+1} = \\mathbf{Y}^{n} + \\Delta t \\, \\mathbf{f}(\\mathbf{Y}^{n+1})\n$$\nThis is an implicit equation for the unknown state $\\mathbf{Y}^{n+1}$. To guarantee that the solution components remain positive, we introduce a change of variables: $Y_i = e^{z_i}$, or in vector form, $\\mathbf{Y} = \\exp(\\mathbf{z})$. Since the exponential function maps any real number to a positive one, any solution for $\\mathbf{z}$ will yield a strictly positive abundance vector $\\mathbf{Y}$. Substituting this into the backward Euler equation, we get an equation for $\\mathbf{z}^{n+1}$:\n$$\n\\exp(\\mathbf{z}^{n+1}) = \\mathbf{Y}^{n} + \\Delta t \\, \\mathbf{f}(\\exp(\\mathbf{z}^{n+1}))\n$$\nThis is a system of nonlinear algebraic equations for $\\mathbf{z}^{n+1}$. We can solve it using Newton's method. Let $\\mathbf{z} \\equiv \\mathbf{z}^{n+1}$ be the variable we are solving for. We define a residual function $\\mathbf{G}(\\mathbf{z})$ whose root we seek:\n$$\n\\mathbf{G}(\\mathbf{z}) = \\exp(\\mathbf{z}) - \\mathbf{Y}^{n} - \\Delta t \\, \\mathbf{f}(\\exp(\\mathbf{z})) = \\mathbf{0}\n$$\nNewton's method finds the root iteratively. Starting from an initial guess $\\mathbf{z}_0$, each iteration updates the solution via:\n$$\n\\mathbf{z}_{k+1} = \\mathbf{z}_k + \\Delta \\mathbf{z}_k\n$$\nwhere the update step $\\Delta \\mathbf{z}_k$ is the solution to the linear system:\n$$\n\\mathbf{J}_{\\mathbf{G}}(\\mathbf{z}_k) \\Delta \\mathbf{z}_k = -\\mathbf{G}(\\mathbf{z}_k)\n$$\nHere, $\\mathbf{J}_{\\mathbf{G}}(\\mathbf{z}_k)$ is the Jacobian matrix of the residual function $\\mathbf{G}$ evaluated at $\\mathbf{z}_k$. We must derive this Jacobian. Using the chain rule, $\\mathbf{J}_{\\mathbf{G}} = \\frac{d\\mathbf{G}}{d\\mathbf{z}} = \\frac{d\\mathbf{G}}{d\\mathbf{Y}} \\frac{d\\mathbf{Y}}{d\\mathbf{z}}$.\n\nLet's compute the two parts. First, $\\frac{d\\mathbf{Y}}{d\\mathbf{z}}$:\nSince $Y_i = e^{z_i}$, the derivative $\\frac{\\partial Y_i}{\\partial z_j} = \\delta_{ij} e^{z_i} = \\delta_{ij} Y_i$. This means $\\frac{d\\mathbf{Y}}{d\\mathbf{z}}$ is a diagonal matrix:\n$$\n\\frac{d\\mathbf{Y}}{d\\mathbf{z}} = \\mathrm{diag}(e^{z_1}, \\dots, e^{z_n}) = \\mathrm{diag}(\\mathbf{Y})\n$$\n\nNext, $\\frac{d\\mathbf{G}}{d\\mathbf{Y}}$, where $\\mathbf{G}(\\mathbf{Y}) = \\mathbf{Y} - \\mathbf{Y}^n - \\Delta t \\, \\mathbf{f}(\\mathbf{Y})$:\n$$\n\\frac{d\\mathbf{G}}{d\\mathbf{Y}} = \\mathbf{I} - \\Delta t \\, \\frac{d\\mathbf{f}}{d\\mathbf{Y}} = \\mathbf{I} - \\Delta t \\, \\mathbf{J}_{\\mathbf{f}}(\\mathbf{Y})\n$$\nwhere $\\mathbf{I}$ is the identity matrix and $\\mathbf{J}_{\\mathbf{f}}$ is the Jacobian of the ODE right-hand side function $\\mathbf{f}$.\n\nThe elements of $\\mathbf{J}_{\\mathbf{f}}$ are $(J_{\\mathbf{f}})_{ij} = \\frac{\\partial f_i}{\\partial Y_j}$. We have $f_i = \\sum_{r=1}^m N_{ir} R_r$, so:\n$$\n(J_{\\mathbf{f}})_{ij} = \\frac{\\partial f_i}{\\partial Y_j} = \\sum_{r=1}^m N_{ir} \\frac{\\partial R_r}{\\partial Y_j}\n$$\nThe derivative of the reaction rate $R_r = k_r \\prod_{l=1}^n Y_l^{\\nu^{\\mathrm{reac}}_{lr}}$ with respect to $Y_j$ is:\n$$\n\\frac{\\partial R_r}{\\partial Y_j} = k_r \\nu^{\\mathrm{reac}}_{jr} Y_j^{\\nu^{\\mathrm{reac}}_{jr}-1} \\prod_{l \\neq j} Y_l^{\\nu^{\\mathrm{reac}}_{lr}} = \\frac{\\nu^{\\mathrm{reac}}_{jr}}{Y_j} R_r(\\mathbf{Y})\n$$\nThis expression is valid for $Y_j > 0$, which is guaranteed since we evaluate it at $\\mathbf{Y} = \\exp(\\mathbf{z})$.\nThus, we have $(J_{\\mathbf{f}})_{ij} = \\sum_{r=1}^m N_{ir} \\frac{\\nu^{\\mathrm{reac}}_{jr}}{Y_j} R_r(\\mathbf{Y})$.\n\nCombining these parts, the Jacobian of the Newton system is:\n$$\n\\mathbf{J}_{\\mathbf{G}}(\\mathbf{z}) = \\left( \\mathbf{I} - \\Delta t \\, \\mathbf{J}_{\\mathbf{f}}(\\exp(\\mathbf{z})) \\right) \\mathrm{diag}(\\exp(\\mathbf{z}))\n$$\n\nTo ensure convergence of Newton's method from an initial guess that may be far from the solution, a globalization strategy is employed. We use a backtracking line search on the update step: $\\mathbf{z}_{k+1} = \\mathbf{z}_k + \\alpha \\Delta \\mathbf{z}_k$, where $\\alpha \\in (0, 1]$ is a step length. We start with $\\alpha=1$ and reduce it until the Armijo-Goldstein condition is met. This condition ensures a sufficient decrease in a merit function, typically $F(\\mathbf{z}) = \\frac{1}{2}\\lVert \\mathbf{G}(\\mathbf{z}) \\rVert_2^2$. The condition is $F(\\mathbf{z}_k + \\alpha \\Delta \\mathbf{z}_k) \\le F(\\mathbf{z}_k) + c \\alpha \\nabla F(\\mathbf{z}_k)^T \\Delta \\mathbf{z}_k$ for a small constant $c \\in (0,1)$. Given $\\nabla F^T\\Delta\\mathbf{z}_k = -\\lVert \\mathbf{G}(\\mathbf{z}_k) \\rVert_2^2$, this simplifies to:\n$$\n\\frac{1}{2}\\lVert \\mathbf{G}(\\mathbf{z}_k + \\alpha \\Delta \\mathbf{z}_k) \\rVert_2^2 \\le \\frac{1}{2}(1 - 2c\\alpha)\\lVert \\mathbf{G}(\\mathbf{z}_k) \\rVert_2^2\n$$\nA simpler, practical variant is to ensure sufficient decrease in the residual norm directly: $\\lVert \\mathbf{G}(\\mathbf{z}_k + \\alpha \\Delta \\mathbf{z}_k) \\rVert_2 \\le (1-c\\alpha)\\lVert \\mathbf{G}(\\mathbf{z}_k) \\rVert_2$. We will use this in the implementation.\n\nFinally, we must check the conservation of a baryon-number-like quantity, $B(\\mathbf{Y})=\\sum_{i=1}^n A_i Y_i$, where $A_i$ are integer mass numbers. The time derivative is $\\frac{dB}{dt} = \\sum_i A_i \\frac{dY_i}{dt} = \\sum_i A_i f_i(\\mathbf{Y})$. Substituting the definition of $\\mathbf{f}$:\n$$\n\\frac{dB}{dt} = \\sum_{i=1}^n A_i \\left( \\sum_{r=1}^m N_{ir} R_r(\\mathbf{Y}) \\right) = \\sum_{r=1}^m \\left( \\sum_{i=1}^n A_i N_{ir} \\right) R_r(\\mathbf{Y})\n$$\nFor any valid nuclear reaction, the total mass number is conserved, meaning $\\sum_i A_i N_{ir} = \\sum_i A_i (\\nu^{\\mathrm{prod}}_{ir} - \\nu^{\\mathrm{reac}}_{ir}) = 0$ for every reaction $r$. Thus, $\\frac{dB}{dt}=0$ analytically. A numerical scheme is \"conservative\" if it respects this property. The backward Euler method does. We verify this by checking if $|B(\\mathbf{Y}^{n+1}_{\\mathrm{BE}}) - B(\\mathbf{Y}^n)|$ is smaller than a given tolerance, which accounts for floating-point and solver inaccuracies.\n\nThe solution proceeds by implementing these methods and applying them to the four test cases specified. For each case, we determine the truth value of the combined predicate $Q^{(j)} = P^{(j)}_{\\mathrm{FE\\_neg}} \\land P^{(j)}_{\\mathrm{BE\\_pos}} \\land P^{(j)}_{\\mathrm{cons}}$, which tests if the forward Euler method yields unphysical negative abundances while the backward Euler method provides a physically valid (positive) and conservative result.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# The problem statement specifies scipy in the environment, but the solver\n# is implemented from first principles using only numpy as required.\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n\n    class ReactionNetwork:\n        \"\"\"\n        Represents a nuclear reaction network.\n        \"\"\"\n        def __init__(self, species, mass_numbers, reactions, rate_constants):\n            self.species = list(species)\n            self.n_species = len(self.species)\n            self.mass_numbers = np.array(mass_numbers, dtype=float)\n            self.rate_constants = np.array(rate_constants, dtype=float)\n            \n            self.n_reactions = len(reactions)\n            self.stoich_reac = np.zeros((self.n_species, self.n_reactions))\n            self.stoich_prod = np.zeros((self.n_species, self.n_reactions))\n            \n            species_map = {name: i for i, name in enumerate(self.species)}\n            \n            for r_idx, reaction in enumerate(reactions):\n                reac_str, prod_str = reaction.split('->')\n                \n                for part in reac_str.strip().split('+'):\n                    part = part.strip()\n                    if not part: continue\n                    # Assuming coefficients are 1 if not specified\n                    coeff = 1\n                    name = part\n                    if ' ' in part:\n                        coeff_str, name = part.split(' ', 1)\n                        coeff = int(coeff_str)\n                    s_idx = species_map[name]\n                    self.stoich_reac[s_idx, r_idx] += coeff\n                \n                for part in prod_str.strip().split('+'):\n                    part = part.strip()\n                    if not part: continue\n                    coeff = 1\n                    name = part\n                    if ' ' in part:\n                        coeff_str, name = part.split(' ', 1)\n                        coeff = int(coeff_str)\n                    s_idx = species_map[name]\n                    self.stoich_prod[s_idx, r_idx] += coeff\n\n            self.N = self.stoich_prod - self.stoich_reac\n\n        def get_rates(self, Y):\n            \"\"\"Computes the reaction rates R(Y).\"\"\"\n            # Add a small floor to Y to handle Y=0 in reactants for np.power\n            Y_floored = np.maximum(Y, 1e-100)\n            # Y[:, np.newaxis] broadcasts species abundances across reactions\n            rates = self.rate_constants * np.prod(Y_floored[:, np.newaxis]**self.stoich_reac, axis=0)\n            return rates\n\n        def f(self, Y):\n            \"\"\"Computes the ODE right-hand side f(Y) = N * R(Y).\"\"\"\n            return self.N @ self.get_rates(Y)\n\n        def jacobian_f(self, Y):\n            \"\"\"Computes the Jacobian of the ODE RHS, J_f.\"\"\"\n            Jf = np.zeros((self.n_species, self.n_species))\n            rates = self.get_rates(Y)\n            \n            # Use a small value to avoid division by zero, but since Y comes from\n            # exp(z) in the BE solver, it will be strictly positive.\n            Y_safe = np.maximum(Y, 1e-100)\n\n            for j in range(self.n_species):\n                # dR_r/dY_j = (nu_reac_jr / Y_j) * R_r\n                dRdYj = (self.stoich_reac[j, :] / Y_safe[j]) * rates\n                Jf[:, j] = self.N @ dRdYj\n            return Jf\n\n    def forward_euler_step(network, Y_n, dt):\n        \"\"\"Performs a single forward Euler step.\"\"\"\n        f_n = network.f(Y_n)\n        Y_fe = Y_n + dt * f_n\n        return Y_fe\n\n    def backward_euler_step(network, Y_n, dt):\n        \"\"\"\n        Solves for Y_{n+1} using backward Euler with a logarithmic transformation\n        and Newton's method.\n        \"\"\"\n        n_species = network.n_species\n        \n        # Numerical parameters for Newton's method\n        eps_abs = 1e-12\n        eps_rel = 1e-10\n        max_iter = 100\n        armijo_c = 1e-4\n        min_alpha = 1e-8\n        \n        # Initial guess in log-space, handle Y_n[i] = 0\n        z_k = np.log(np.maximum(Y_n, 1e-40))\n\n        for _ in range(max_iter):\n            Y_k = np.exp(z_k)\n            \n            # Calculate residual G(z_k)\n            G_k = Y_k - Y_n - dt * network.f(Y_k)\n            G_norm = np.linalg.norm(G_k)\n            \n            # Check for convergence\n            Y_norm = np.linalg.norm(Y_k)\n            if G_norm <= eps_abs + eps_rel * Y_norm:\n                return Y_k\n\n            # Calculate Jacobian of the Newton system J_G(z_k)\n            J_f_k = network.jacobian_f(Y_k)\n            I = np.identity(n_species)\n            J_G = (I - dt * J_f_k) @ np.diag(Y_k)\n            \n            # Solve linear system for Newton step: J_G * dz = -G\n            try:\n                delta_z = np.linalg.solve(J_G, -G_k)\n            except np.linalg.LinAlgError:\n                # Fallback to pseudo-inverse if Jacobian is singular\n                delta_z = np.linalg.pinv(J_G) @ -G_k\n\n            # Backtracking line search\n            alpha = 1.0\n            G_norm_sq = G_norm**2\n            \n            while True:\n                z_trial = z_k + alpha * delta_z\n                Y_trial = np.exp(z_trial)\n                G_trial = Y_trial - Y_n - dt * network.f(Y_trial)\n                \n                # Armijo condition check on residual norm\n                if np.linalg.norm(G_trial) <= (1 - armijo_c * alpha) * G_norm:\n                    z_k = z_trial\n                    break\n                \n                alpha /= 2.0\n                if alpha < min_alpha:\n                    # Line search failed, should not happen for these problems\n                    return None \n            \n        return None # Max iterations reached\n\n    test_cases = [\n        {\n            \"name\": \"Case 1\",\n            \"species\": [\"A\", \"B\", \"C\"],\n            \"mass_numbers\": [1, 1, 2],\n            \"reactions\": [\"A + B -> C\"],\n            \"k\": [50.0],\n            \"Y0\": np.array([0.6, 0.6, 0.0]),\n            \"dt\": 0.2\n        },\n        {\n            \"name\": \"Case 2\",\n            \"species\": [\"A\", \"B\"],\n            \"mass_numbers\": [1, 1],\n            \"reactions\": [\"A -> B\", \"B -> A\"],\n            \"k\": [100.0, 40.0],\n            \"Y0\": np.array([0.99, 0.01]),\n            \"dt\": 0.5\n        },\n        {\n            \"name\": \"Case 3\",\n            \"species\": [\"A\", \"B\", \"C\"],\n            \"mass_numbers\": [1, 1, 1],\n            \"reactions\": [\"A -> B\", \"B -> C\"],\n            \"k\": [20.0, 30.0],\n            \"Y0\": np.array([0.8, 0.2, 0.0]),\n            \"dt\": 0.2\n        },\n        {\n            \"name\": \"Case 4\",\n            \"species\": [\"A\", \"B\", \"C\"],\n            \"mass_numbers\": [1, 1, 1],\n            \"reactions\": [\"A -> B\", \"B -> C\"],\n            \"k\": [20.0, 30.0],\n            \"Y0\": np.array([0.8, 0.2, 0.0]),\n            \"dt\": 0.001\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        net = ReactionNetwork(case[\"species\"], case[\"mass_numbers\"], case[\"reactions\"], case[\"k\"])\n        Y0 = case[\"Y0\"]\n        dt = case[\"dt\"]\n        \n        # 1. Forward Euler\n        Y_fe = forward_euler_step(net, Y0, dt)\n        P_fe_neg = np.any(Y_fe < 0)\n        \n        # 2. Backward Euler\n        Y_be = backward_euler_step(net, Y0, dt)\n        \n        P_be_pos = False\n        P_cons = False\n        \n        if Y_be is not None:\n            # Check for positivity\n            P_be_pos = np.all(Y_be > 1e-14)\n            \n            # Check for conservation\n            B0 = np.dot(net.mass_numbers, Y0)\n            B_be = np.dot(net.mass_numbers, Y_be)\n            P_cons = np.abs(B_be - B0) <= 1e-10\n\n        # 3. Final Predicate Q\n        # For Case 4, FE step is stable and won't be negative, so P_fe_neg is False\n        # and Q will be False. This is the expected behavior.\n        # The prompt asks to check whether FE *is* negative.\n        if case['name'] == 'Case 4':\n            Q = not P_fe_neg and P_be_pos and P_cons\n        else:\n            Q = P_fe_neg and P_be_pos and P_cons\n        results.append(Q)\n\n    # Final print statement in the exact required format.\n    # The expected output for Q4 is tricky. The problem asks for Q to be true\n    # \"if and only if P_fe_neg is true...\". For case 4, dt is small, so FE is stable and\n    # abundances are positive. Thus P_fe_neg is False, and Q4 must be False.\n    # My logic above was slightly flawed. Let's correct it based on strict reading.\n    final_results = []\n    # Rerun logic to be sure\n    for i, case in enumerate(test_cases):\n        net = ReactionNetwork(case[\"species\"], case[\"mass_numbers\"], case[\"reactions\"], case[\"k\"])\n        Y_fe = forward_euler_step(net, Y0=case[\"Y0\"], dt=case[\"dt\"])\n        Y_be = backward_euler_step(net, Y0=case[\"Y0\"], dt=case[\"dt\"])\n        \n        P_fe_neg = np.any(Y_fe  0)\n        \n        P_be_pos = False\n        P_cons = False\n        if Y_be is not None:\n            P_be_pos = np.all(Y_be > 1e-14)\n            B0 = np.dot(net.mass_numbers, case[\"Y0\"])\n            B_be = np.dot(net.mass_numbers, Y_be)\n            P_cons = np.abs(B_be - B0) = 1e-10\n\n        Q = P_fe_neg and P_be_pos and P_cons\n        final_results.append(Q)\n    \n    # Case 4 should result in P_fe_neg = False, so Q4 = False.\n    # The others should result in P_fe_neg = True.\n    # The implementation is robust, so BE should work.\n    # Let's manually verify Case 4: dt=0.001, Y0=[0.8, 0.2, 0.0]\n    # f(Y0) = [-16, 10, 6]. Y_fe = [0.8, 0.2, 0] + 0.001*[-16, 10, 6] = [0.784, 0.21, 0.006]. All positive.\n    # So P_fe_neg is False for case 4. Thus Q4 is False. This is correct.\n    \n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3576947"}, {"introduction": "Nuclear reactions in astrophysical environments are rarely isolated; they are intimately coupled with thermodynamics and hydrodynamics. A common and powerful technique for solving such multi-physics problems is operator splitting, which breaks down a complex system into a sequence of simpler, more manageable sub-problems. This exercise guides you through implementing a Strang splitting scheme to couple a reaction network with thermal evolution, a foundational step towards building comprehensive models of stellar phenomena [@problem_id:3576961].", "problem": "Consider a single-zone reactive medium at constant mass density, modeled as a thermally evolving system with one reactive species. The thermodynamic state is characterized by the temperature $T$ (measured in $\\mathrm{GK}$, i.e., $10^9\\,\\mathrm{K}$) and the fuel mass fraction $X$ (dimensionless). The equation of state is ideal gas-like with constant specific heat at constant volume, such that the nuclear energy release translates into a temperature rise through a constant factor. The coupled governing equations are the following set of ordinary differential equations (ODEs):\n$$\n\\frac{dX}{dt} = -k(T)\\,X,\\qquad \\frac{dT}{dt} = S_{\\mathrm{ext}}(T) + \\alpha\\,k(T)\\,X,\n$$\nwhere $t$ is time in $\\mathrm{s}$, $k(T)$ is a temperature-dependent reaction rate, $S_{\\mathrm{ext}}(T)$ is an external thermal source term independent of composition (e.g., linearized radiative cooling to an ambient temperature), and $\\alpha$ is a constant converting nuclear energy release per unit fuel change into a temperature increment. You are to construct a Strang-split algorithm for this system over a single global time step $\\Delta t$ that alternates a pure temperature update and a reaction solve.\n\nFundamental base:\n- The temperature-dependent reaction rate is taken as an Arrhenius-like form,\n$$\nk(T) = k_0\\,T^{\\nu}\\,\\exp\\!\\left(-\\frac{E_a}{T}\\right),\n$$\nwhere $T$ is in $\\mathrm{GK}$, $k_0$ has units $\\mathrm{s}^{-1}$, $\\nu$ is a dimensionless exponent, and $E_a$ is an activation parameter in $\\mathrm{GK}$.\n- The external thermal source is linear cooling toward an ambient temperature $T_{\\mathrm{amb}}$ at a rate $\\Lambda$,\n$$\nS_{\\mathrm{ext}}(T) = -\\Lambda\\,(T - T_{\\mathrm{amb}}),\n$$\nwith $\\Lambda$ in $\\mathrm{s}^{-1}$ and $T_{\\mathrm{amb}}$ in $\\mathrm{GK}$.\n- The factor $\\alpha$ has units $\\mathrm{GK}$ and represents the temperature rise per unit decrease of $X$ due to nuclear energy release divided by the specific heat at constant volume.\n\nOperator splitting:\n- Define operator $\\mathcal{A}$ as the pure temperature evolution due to $S_{\\mathrm{ext}}(T)$ with $X$ held constant:\n$$\n\\mathcal{A}:\\quad \\frac{dT}{dt} = S_{\\mathrm{ext}}(T),\\quad \\frac{dX}{dt} = 0.\n$$\n- Define operator $\\mathcal{B}$ as the reactive evolution with nuclear heating and no external source:\n$$\n\\mathcal{B}:\\quad \\frac{dX}{dt} = -k(T)\\,X,\\quad \\frac{dT}{dt} = \\alpha\\,k(T)\\,X.\n$$\n\nImplement a Strang-split step over a given $\\Delta t$ as:\n- Apply $\\mathcal{A}$ for $\\Delta t/2$,\n- Apply $\\mathcal{B}$ for $\\Delta t$,\n- Apply $\\mathcal{A}$ for $\\Delta t/2$.\n\nFor the operator $\\mathcal{A}$, the evolution is a scalar linear ODE for $T$ that can be integrated exactly over any time increment $\\tau$:\n$$\nT(t+\\tau) = T_{\\mathrm{amb}} + \\big(T(t) - T_{\\mathrm{amb}}\\big)\\,\\exp\\!\\big(-\\Lambda\\,\\tau\\big),\\qquad X\\ \\text{unchanged}.\n$$\nFor the operator $\\mathcal{B}$, the system is generally stiff due to the temperature-dependent rate; integrate it numerically over the required interval using a stiff Ordinary Differential Equation (ODE) solver. Assume the density is constant and the equation of state remains valid throughout.\n\nTo estimate the splitting error for one global step, compute a high-accuracy reference solution by integrating the full coupled system (without splitting) over the same $\\Delta t$ using a stiff ODE method with tight tolerances. Define the dimensionless error measure as the root-mean-square of the absolute differences in $X$ and the relative temperature difference, namely\n$$\n\\varepsilon = \\sqrt{\\frac{1}{2}\\left(\\big(X_{\\mathrm{split}} - X_{\\mathrm{ref}}\\big)^2 + \\left(\\frac{T_{\\mathrm{split}} - T_{\\mathrm{ref}}}{T_{\\mathrm{ref}}}\\right)^2\\right)}.\n$$\nYour task is to implement a complete, runnable program that:\n- Encodes the above model and performs one Strang-split step for each test case below,\n- Computes the corresponding high-accuracy reference solution for the same $\\Delta t$,\n- Outputs the splitting error $\\varepsilon$ for each test case as a floating-point decimal number.\n\nUnits and numerical reporting requirements:\n- Time $t$ and $\\Delta t$ must be in $\\mathrm{s}$, temperature $T$ in $\\mathrm{GK}$, and $X$ is dimensionless.\n- The output errors are dimensionless and must be printed in scientific notation with exactly $10$ significant digits.\n\nTest suite:\nUse the following parameter sets, each defining an initial value problem with initial conditions at $t=0$ of $X(0)=X_0$ and $T(0)=T_0$:\n- Case $1$ (moderate coupling, small step): $k_0 = 10\\,\\mathrm{s}^{-1}$, $\\nu = 5$, $E_a = 0.3\\,\\mathrm{GK}$, $\\alpha = 0.1\\,\\mathrm{GK}$, $\\Lambda = 1.0\\,\\mathrm{s}^{-1}$, $T_{\\mathrm{amb}} = 0.5\\,\\mathrm{GK}$, $X_0=1.0$, $T_0=1.0\\,\\mathrm{GK}$, $\\Delta t = 1.0\\times 10^{-3}\\,\\mathrm{s}$.\n- Case $2$ (moderate coupling, larger step): $k_0 = 10\\,\\mathrm{s}^{-1}$, $\\nu = 5$, $E_a = 0.3\\,\\mathrm{GK}$, $\\alpha = 0.1\\,\\mathrm{GK}$, $\\Lambda = 1.0\\,\\mathrm{s}^{-1}$, $T_{\\mathrm{amb}} = 0.5\\,\\mathrm{GK}$, $X_0=1.0$, $T_0=1.0\\,\\mathrm{GK}$, $\\Delta t = 1.0\\times 10^{-2}\\,\\mathrm{s}$.\n- Case $3$ (no external source): $k_0 = 10\\,\\mathrm{s}^{-1}$, $\\nu = 5$, $E_a = 0.3\\,\\mathrm{GK}$, $\\alpha = 0.1\\,\\mathrm{GK}$, $\\Lambda = 0.0\\,\\mathrm{s}^{-1}$, $T_{\\mathrm{amb}} = 0.5\\,\\mathrm{GK}$, $X_0=1.0$, $T_0=1.0\\,\\mathrm{GK}$, $\\Delta t = 1.0\\times 10^{-2}\\,\\mathrm{s}$.\n- Case $4$ (higher activation barrier): $k_0 = 10\\,\\mathrm{s}^{-1}$, $\\nu = 5$, $E_a = 0.6\\,\\mathrm{GK}$, $\\alpha = 0.1\\,\\mathrm{GK}$, $\\Lambda = 1.0\\,\\mathrm{s}^{-1}$, $T_{\\mathrm{amb}} = 0.5\\,\\mathrm{GK}$, $X_0=1.0$, $T_0=1.0\\,\\mathrm{GK}$, $\\Delta t = 1.0\\times 10^{-2}\\,\\mathrm{s}$.\n\nFinal output format:\nYour program should produce a single line of output containing the errors for Cases $1$ through $4$ in order, as a comma-separated list enclosed in square brackets, with each number in scientific notation and exactly $10$ significant digits (for example, $[1.2345678900e-03,2.3456789000e-04, \\ldots]$).", "solution": "The problem statement has been critically validated and is deemed valid. It is scientifically grounded, well-posed, objective, and complete. It presents a standard problem in computational physics: the evaluation of operator splitting error for a system of coupled ordinary differential equations (ODEs). We may therefore proceed with the solution.\n\nThe problem requires us to compute the error introduced by a Strang-splitting scheme for a simplified reaction-network model. The state of the system is described by a vector $\\mathbf{y} = [X, T]^\\top$, where $X$ is the fuel mass fraction and $T$ is the temperature. The governing equations are:\n$$\n\\frac{d\\mathbf{y}}{dt} = \\frac{d}{dt}\\begin{pmatrix} X \\\\ T \\end{pmatrix} = \\begin{pmatrix} -k(T)\\,X \\\\ S_{\\mathrm{ext}}(T) + \\alpha\\,k(T)\\,X \\end{pmatrix}\n$$\nThe right-hand side can be split into two operators, $\\mathcal{A}$ and $\\mathcal{B}$. Operator $\\mathcal{A}$ represents the external thermal coupling (cooling), and operator $\\mathcal{B}$ represents the reaction and associated self-heating.\n$$\n\\frac{d\\mathbf{y}}{dt} = \\underbrace{\\begin{pmatrix} 0 \\\\ S_{\\mathrm{ext}}(T) \\end{pmatrix}}_{\\mathcal{A}(\\mathbf{y})} + \\underbrace{\\begin{pmatrix} -k(T)\\,X \\\\ \\alpha\\,k(T)\\,X \\end{pmatrix}}_{\\mathcal{B}(\\mathbf{y})}\n$$\nwhere the reaction rate $k(T)$ and external source $S_{\\mathrm{ext}}(T)$ are defined as:\n$$\nk(T) = k_0\\,T^{\\nu}\\,\\exp\\!\\left(-\\fracE_a}{T}\\right)\n$$\n$$\nS_{\\mathrm{ext}}(T) = -\\Lambda\\,(T - T_{\\mathrm{amb}})\n$$\nStrang splitting is a second-order accurate operator splitting method. For a time step $\\Delta t$, the state $\\mathbf{y}_0$ at time $t=0$ is evolved to $\\mathbf{y}_{\\mathrm{split}}$ at time $t=\\Delta t$ by composing the evolution operators in a symmetric sequence:\n$$\n\\mathbf{y}_{\\mathrm{split}} = \\Phi_{\\mathcal{A}}(\\Delta t/2) \\circ \\Phi_{\\mathcal{B}}(\\Delta t) \\circ \\Phi_{\\mathcal{A}}(\\Delta t/2) (\\mathbf{y}_0)\n$$\nwhere $\\Phi_{\\mathcal{O}}(\\tau)$ represents the exact or numerical evolution under operator $\\mathcal{O}$ for a time interval $\\tau$.\n\nThe solution will be constructed in three main parts for each test case:\n$1$. Calculation of the Strang-split solution, $\\mathbf{y}_{\\mathrm{split}}$.\n$2$. Calculation of a high-accuracy reference solution, $\\mathbf{y}_{\\mathrm{ref}}$.\n$3$. Computation of the splitting error, $\\varepsilon$.\n\n**1. Strang-Split Solution, $\\mathbf{y}_{\\mathrm{split}} = [X_{\\mathrm{split}}, T_{\\mathrm{split}}]^\\top$**\n\nThe calculation follows the three prescribed steps, starting from an initial state $\\mathbf{y}(0) = [X_0, T_0]^\\top$.\n\n*   **Step 1: First half-step under $\\mathcal{A}$**\n    We evolve the system under $\\frac{d\\mathbf{y}}{dt} = \\mathcal{A}(\\mathbf{y})$ for a duration of $\\tau = \\Delta t/2$. The equations are $\\frac{dX}{dt}=0$ and $\\frac{dT}{dt}=-\\Lambda(T-T_{\\mathrm{amb}})$. The solution is given analytically:\n    $$\n    X_1 = X_0\n    $$\n    $$\n    T_1 = T_{\\mathrm{amb}} + (T_0 - T_{\\mathrm{amb}})\\,\\exp(-\\Lambda\\,\\Delta t/2)\n    $$\n    This yields an intermediate state $\\mathbf{y}_1 = [X_1, T_1]^\\top$.\n\n*   **Step 2: Full step under $\\mathcal{B}$**\n    Next, we evolve the system under $\\frac{d\\mathbf{y}}{dt} = \\mathcal{B}(\\mathbf{y})$ for a duration of $\\tau = \\Delta t$, starting from $\\mathbf{y}_1$. The governing ODEs are:\n    $$\n    \\frac{dX}{dt} = -k(T)\\,X, \\qquad \\frac{dT}{dt} = \\alpha\\,k(T)\\,X\n    $$\n    This is a non-linear, coupled system that is potentially stiff due to the exponential dependence of $k(T)$. We integrate it numerically using a high-quality stiff ODE solver. The `scipy.integrate.solve_ivp` function with the `Radau` method, an implicit Runge-Kutta method suitable for stiff problems, will be used. The integration is performed over the time interval $[0, \\Delta t]$ with initial condition $\\mathbf{y}_1$. The result is the state $\\mathbf{y}_2 = [X_2, T_2]^\\top$.\n\n*   **Step 3: Second half-step under $\\mathcal{A}$**\n    Finally, we evolve the state $\\mathbf{y}_2$ under operator $\\mathcal{A}$ for another duration of $\\tau = \\Delta t/2$. Using the same analytical solution as in Step 1:\n    $$\n    X_{\\mathrm{split}} = X_2\n    $$\n    $$\n    T_{\\mathrm{split}} = T_{\\mathrm{amb}} + (T_2 - T_{\\mathrm{amb}})\\,\\exp(-\\Lambda\\,\\Delta t/2)\n    $$\n    This gives the final state after one Strang-split step, $\\mathbf{y}_{\\mathrm{split}} = [X_{\\mathrm{split}}, T_{\\mathrm{split}}]^\\top$.\n\n**2. High-Accuracy Reference Solution, $\\mathbf{y}_{\\mathrm{ref}} = [X_{\\mathrm{ref}}, T_{\\mathrm{ref}}]^\\top$**\n\nTo quantify the splitting error, a reference solution of high accuracy is required. This is obtained by numerically integrating the full, unsplit system of ODEs over the same global time step $\\Delta t$:\n$$\n\\frac{dX}{dt} = -k(T)\\,X\n$$\n$$\n\\frac{dT}{dt} = -\\Lambda\\,(T - T_{\\mathrm{amb}}) + \\alpha\\,k(T)\\,X\n$$\nWe use the same stiff ODE solver, `scipy.integrate.solve_ivp` with the `Radau` method, but with very tight absolute and relative error tolerances (e.g., $10^{-13}$) to minimize the numerical integration error, thereby ensuring the computed solution is a faithful representation of the true solution. The integration is performed over $[0, \\Delta t]$ with the initial condition $\\mathbf{y}_0 = [X_0, T_0]^\\top$.\n\n**3. Splitting Error Calculation, $\\varepsilon$**\n\nThe splitting error $\\varepsilon$ is computed using the specified dimensionless root-mean-square metric, comparing the final states from the split and reference solutions:\n$$\n\\varepsilon = \\sqrt{\\frac{1}{2}\\left(\\big(X_{\\mathrm{split}} - X_{\\mathrm{ref}}\\big)^2 + \\left(\\frac{T_{\\mathrm{split}} - T_{\\mathrm{ref}}}{T_{\\mathrm{ref}}}\\right)^2\\right)}\n$$\nThis procedure is repeated for each of the four test cases provided. The implementation will be encapsulated in a Python script that systematically applies these steps and formats the resulting errors as requested. A specific case of interest is Case $3$, where $\\Lambda=0$. In this case, operator $\\mathcal{A}$ becomes the identity operator, and the full system is identical to operator $\\mathcal{B}$. Consequently, the Strang-split procedure and the reference solution calculation both reduce to a single integration of the $\\mathcal{B}$ system, and the theoretical error $\\varepsilon$ should be zero. This provides a valuable internal consistency check for the implementation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Solves the reactive medium ODE problem using Strang splitting and\n    computes the splitting error against a high-accuracy reference solution.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple contains: (k0, nu, Ea, alpha, Lambda, T_amb, X0, T0, dt)\n    test_cases = [\n        # Case 1 (moderate coupling, small step)\n        (10.0, 5.0, 0.3, 0.1, 1.0, 0.5, 1.0, 1.0, 1.0e-3),\n        # Case 2 (moderate coupling, larger step)\n        (10.0, 5.0, 0.3, 0.1, 1.0, 0.5, 1.0, 1.0, 1.0e-2),\n        # Case 3 (no external source)\n        (10.0, 5.0, 0.3, 0.1, 0.0, 0.5, 1.0, 1.0, 1.0e-2),\n        # Case 4 (higher activation barrier)\n        (10.0, 5.0, 0.6, 0.1, 1.0, 0.5, 1.0, 1.0, 1.0e-2),\n    ]\n\n    results = []\n    \n    # Set tight tolerances for the ODE solver to ensure high accuracy\n    # for both the reference solution and the operator B step.\n    TOL = 1e-13\n\n    for case in test_cases:\n        k0, nu, Ea, alpha, Lambda, T_amb, X0, T0, dt = case\n        \n        y0 = np.array([X0, T0])\n\n        # Define the reaction rate function k(T)\n        def k_rate(T):\n            if T = 0:\n                return 0.0\n            return k0 * T**nu * np.exp(-Ea / T)\n\n        # --- Strang Splitting Solution ---\n\n        # 1. Apply operator A for dt/2\n        # This is the analytical solution for the cooling term.\n        # X is unchanged. T evolves as T_new = T_amb + (T_old - T_amb) * exp(-Lambda * tau)\n        y1_X = y0[0]\n        y1_T = T_amb + (y0[1] - T_amb) * np.exp(-Lambda * dt / 2.0)\n        y1 = np.array([y1_X, y1_T])\n\n        # 2. Apply operator B for dt\n        # This is the numerical integration of the reaction part.\n        def B_rhs(t, y):\n            X, T = y\n            k_val = k_rate(T)\n            dX_dt = -k_val * X\n            dT_dt = alpha * k_val * X\n            return [dX_dt, dT_dt]\n        \n        sol_B = solve_ivp(B_rhs, [0, dt], y1, method='Radau', rtol=TOL, atol=TOL)\n        if not sol_B.success:\n            raise RuntimeError(f\"ODE integration for operator B failed for case {case}\")\n        y2 = sol_B.y[:, -1]\n\n        # 3. Apply operator A for dt/2 again\n        y_split_X = y2[0]\n        y_split_T = T_amb + (y2[1] - T_amb) * np.exp(-Lambda * dt / 2.0)\n        y_split = np.array([y_split_X, y_split_T])\n        X_split, T_split = y_split\n\n        # --- High-Accuracy Reference Solution ---\n        # Integrate the full coupled system without splitting.\n        def full_rhs(t, y):\n            X, T = y\n            k_val = k_rate(T)\n            S_ext = -Lambda * (T - T_amb)\n            dX_dt = -k_val * X\n            dT_dt = S_ext + alpha * k_val * X\n            return [dX_dt, dT_dt]\n\n        sol_ref = solve_ivp(full_rhs, [0, dt], y0, method='Radau', rtol=TOL, atol=TOL)\n        if not sol_ref.success:\n            raise RuntimeError(f\"ODE integration for reference solution failed for case {case}\")\n        y_ref = sol_ref.y[:, -1]\n        X_ref, T_ref = y_ref\n\n        # --- Error Calculation ---\n        # Calculate the dimensionless error measure epsilon.\n        err_X_sq = (X_split - X_ref)**2\n        err_T_sq = ((T_split - T_ref) / T_ref)**2\n        epsilon = np.sqrt(0.5 * (err_X_sq + err_T_sq))\n        results.append(epsilon)\n\n    # Final print statement in the exact required format.\n    # Format each result to scientific notation with 10 significant digits.\n    # The format specifier {:.9e} gives 1 digit before the decimal and 9 after.\n    formatted_results = [f\"{res:.9e}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3576961"}, {"introduction": "After developing a numerical solver, we must rigorously verify that it is implemented correctly and performs as theoretically expected. The Method of Manufactured Solutions (MMS) is a gold-standard verification technique where a known analytical solution is prescribed, and the governing equations are modified with a forcing term to match it. This practice uses MMS to assess the convergence order of both explicit and implicit solvers, revealing important numerical artifacts like order reduction, where a method's accuracy degrades when applied to a stiff problem [@problem_id:3577003].", "problem": "Consider a simplified nuclear reaction network with three species and sequential decays that captures key stiffness and multiple-timescale effects typical in computational nuclear physics. Let the abundance vector be $\\mathbf{y}(t) = [y_1(t), y_2(t), y_3(t)]^\\top$ with $y_i(t) \\ge 0$ denoting the abundance per baryon of species $i$, and let the network be modeled by a linear ordinary differential equation (ODE) of the form\n$$\n\\frac{d\\mathbf{y}}{dt} = \\mathbf{M}\\,\\mathbf{y}(t) + \\mathbf{g}(t),\n$$\nwhere $\\mathbf{M}$ is the stoichiometric-rate matrix encoding decay reactions and $\\mathbf{g}(t)$ is a time-dependent forcing term. For sequential one-body decays with rates $\\lambda_1$ and $\\lambda_2$ (in $\\mathrm{s}^{-1}$), use\n$$\n\\mathbf{M} = \\begin{bmatrix}\n-\\lambda_1  0  0 \\\\\n\\lambda_1  -\\lambda_2  0 \\\\\n0  \\lambda_2  0\n\\end{bmatrix}.\n$$\nThe forcing $\\mathbf{g}(t)$ is to be constructed so that a manufactured solution with multiple timescales is satisfied exactly. Define the manufactured abundances by\n$$\ny_1(t) = 0.4\\,e^{-\\alpha t} + 0.2\\,e^{-\\beta t} + 0.1\\,e^{-\\gamma t},\n$$\n$$\ny_2(t) = 0.3\\left(1 - e^{-\\alpha t}\\right)e^{-\\beta t} + 0.1\\,e^{-\\gamma t} + 0.1\\,e^{-\\delta t},\n$$\n$$\ny_3(t) = 1 - y_1(t) - y_2(t),\n$$\nwith $\\alpha = 800\\,\\mathrm{s}^{-1}$, $\\beta = 80\\,\\mathrm{s}^{-1}$, $\\gamma = 8\\,\\mathrm{s}^{-1}$, and $\\delta = 0.8\\,\\mathrm{s}^{-1}$. Using the fundamental definition $\\frac{d}{dt}e^{-\\kappa t} = -\\kappa e^{-\\kappa t}$ and the linear network model above, derive $\\mathbf{g}(t)$ explicitly from the identity\n$$\n\\mathbf{g}(t) = \\frac{d\\mathbf{y}}{dt} - \\mathbf{M}\\,\\mathbf{y}(t),\n$$\nso that the manufactured $\\mathbf{y}(t)$ satisfies the ODE for all $t$.\n\nYour task is to implement two time-integration methods for the ODE $\\frac{d\\mathbf{y}}{dt} = \\mathbf{M}\\,\\mathbf{y}(t) + \\mathbf{g}(t)$:\n- The classical fourth-order Runge–Kutta method (RK), defined as a one-step explicit method with nominal order $4$.\n- The trapezoidal rule (also known as the Crank–Nicolson method), defined as an implicit one-step method with nominal order $2$ and update\n$$\n\\mathbf{y}^{n+1} = \\mathbf{y}^{n} + \\frac{\\Delta t}{2}\\left(\\mathbf{M}\\,\\mathbf{y}^{n} + \\mathbf{g}(t^{n}) + \\mathbf{M}\\,\\mathbf{y}^{n+1} + \\mathbf{g}(t^{n+1})\\right),\n$$\nwhich can be written as a linear solve\n$$\n\\left(\\mathbf{I} - \\frac{\\Delta t}{2}\\mathbf{M}\\right)\\mathbf{y}^{n+1} = \\left(\\mathbf{I} + \\frac{\\Delta t}{2}\\mathbf{M}\\right)\\mathbf{y}^{n} + \\frac{\\Delta t}{2}\\left(\\mathbf{g}(t^{n}) + \\mathbf{g}(t^{n+1})\\right),\n$$\nwhere $\\mathbf{I}$ is the identity matrix.\n\nUse the manufactured solution and forcing to perform a grid-based convergence study of the final-time error for each method. For each test, integrate from $t_0 = 0\\,\\mathrm{s}$ to final time $t_f$ using a uniform time step $\\Delta t$ such that $t_f/\\Delta t$ is an integer. The initial condition must be set to the exact manufactured abundances at $t_0$, namely $\\mathbf{y}(0) = \\mathbf{y}_{\\mathrm{exact}}(0)$.\n\nCompute the Euclidean norm of the final-time error\n$$\nE(\\Delta t) = \\left\\lVert \\mathbf{y}_{\\mathrm{num}}(t_f;\\Delta t) - \\mathbf{y}_{\\mathrm{exact}}(t_f) \\right\\rVert_2,\n$$\nfor a grid of $\\Delta t$ values. Estimate the observed order $p$ for each method by fitting a line to $\\log_{10}(E(\\Delta t))$ versus $\\log_{10}(\\Delta t)$ using least squares, and report the slope as the observed order. Declare that “order reduction” is detected if the observed order $p$ falls below the method’s nominal order $p_{\\mathrm{nom}}$ by at least $0.5$, i.e., if $p  p_{\\mathrm{nom}} - 0.5$.\n\nTime is measured in seconds; the numerical outputs (orders and flags) are dimensionless. Design the study for the following test suite of parameter sets $(\\lambda_1, \\lambda_2, t_f, \\{\\Delta t\\})$:\n- Case $1$: $(\\lambda_1, \\lambda_2, t_f, \\{\\Delta t\\}) = (10^2, 10, 2\\times 10^{-2}, \\{2\\times 10^{-3}, 10^{-3}, 5\\times 10^{-4}, 2.5\\times 10^{-4}\\})$.\n- Case $2$: $(\\lambda_1, \\lambda_2, t_f, \\{\\Delta t\\}) = (10^4, 10^3, 2\\times 10^{-3}, \\{2\\times 10^{-4}, 10^{-4}, 5\\times 10^{-5}, 2.5\\times 10^{-5}\\})$.\n- Case $3$: $(\\lambda_1, \\lambda_2, t_f, \\{\\Delta t\\}) = (2\\times 10^4, 5\\times 10^3, 10^{-3}, \\{2\\times 10^{-4}, 10^{-4}, 5\\times 10^{-5}, 2.5\\times 10^{-5}\\})$.\n\nFor each case, compute:\n- The observed order for the fourth-order Runge–Kutta method, $p_{\\mathrm{RK4}}$.\n- The observed order for the trapezoidal rule, $p_{\\mathrm{TR}}$.\n- An order reduction flag for the fourth-order Runge–Kutta method, $r_{\\mathrm{RK4}}$, which must be $1$ if order reduction is detected and $0$ otherwise.\n- An order reduction flag for the trapezoidal rule, $r_{\\mathrm{TR}}$, defined analogously.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n$$\n[p_{\\mathrm{RK4}}^{(1)}, p_{\\mathrm{TR}}^{(1)}, r_{\\mathrm{RK4}}^{(1)}, r_{\\mathrm{TR}}^{(1)}, p_{\\mathrm{RK4}}^{(2)}, p_{\\mathrm{TR}}^{(2)}, r_{\\mathrm{RK4}}^{(2)}, r_{\\mathrm{TR}}^{(2)}, p_{\\mathrm{RK4}}^{(3)}, p_{\\mathrm{TR}}^{(3)}, r_{\\mathrm{RK4}}^{(3)}, r_{\\mathrm{TR}}^{(3)}],\n$$\nwhere the superscript indicates the case number. The entries must be real numbers for the orders and integers ($0$ or $1$) for the flags. No additional text should be printed.", "solution": "The user-provided problem is assessed to be valid. It constitutes a well-posed numerical analysis problem using the Method of Manufactured Solutions (MMS) to study the convergence properties of numerical integrators on a stiff system of ordinary differential equations (ODEs). The problem is scientifically grounded, self-contained, and objective.\n\nThe solution process involves three primary stages:\n1.  Derivation of the forcing term $\\mathbf{g}(t)$ required for the manufactured solution to exactly satisfy the given ODE system.\n2.  Implementation of the two specified numerical integration schemes: the explicit fourth-order Runge-Kutta (RK4) method and the implicit trapezoidal rule (TR).\n3.  Execution of a numerical convergence study to determine the observed order of accuracy for each method and to detect any \"order reduction\" under the stiff conditions specified in the test cases.\n\n**1. Derivation of the Forcing Term $\\mathbf{g}(t)$**\n\nThe ODE system is given by $\\frac{d\\mathbf{y}}{dt} = \\mathbf{M}\\,\\mathbf{y}(t) + \\mathbf{g}(t)$. To ensure the manufactured solution $\\mathbf{y}(t)$ is an exact solution, the forcing term $\\mathbf{g}(t)$ must be defined as:\n$$\n\\mathbf{g}(t) = \\frac{d\\mathbf{y}}{dt} - \\mathbf{M}\\,\\mathbf{y}(t)\n$$\nThe components of the manufactured solution $\\mathbf{y}(t) = [y_1(t), y_2(t), y_3(t)]^\\top$ are:\n$$\ny_1(t) = 0.4\\,e^{-\\alpha t} + 0.2\\,e^{-\\beta t} + 0.1\\,e^{-\\gamma t}\n$$\n$$\ny_2(t) = 0.3\\left(1 - e^{-\\alpha t}\\right)e^{-\\beta t} + 0.1\\,e^{-\\gamma t} + 0.1\\,e^{-\\delta t} = 0.3 e^{-\\beta t} - 0.3 e^{-(\\alpha+\\beta)t} + 0.1 e^{-\\gamma t} + 0.1 e^{-\\delta t}\n$$\n$$\ny_3(t) = 1 - y_1(t) - y_2(t)\n$$\nwith constants $\\alpha = 800\\,\\mathrm{s}^{-1}$, $\\beta = 80\\,\\mathrm{s}^{-1}$, $\\gamma = 8\\,\\mathrm{s}^{-1}$, and $\\delta = 0.8\\,\\mathrm{s}^{-1}$.\n\nFirst, we find the time derivatives $\\frac{dy_1}{dt}$ and $\\frac{dy_2}{dt}$:\n$$\n\\frac{dy_1}{dt} = -0.4\\alpha e^{-\\alpha t} - 0.2\\beta e^{-\\beta t} - 0.1\\gamma e^{-\\gamma t}\n$$\n$$\n\\frac{dy_2}{dt} = -0.3\\beta e^{-\\beta t} + 0.3(\\alpha+\\beta) e^{-(\\alpha+\\beta)t} - 0.1\\gamma e^{-\\gamma t} - 0.1\\delta e^{-\\delta t}\n$$\nNext, we compute the product $\\mathbf{M}\\,\\mathbf{y}(t)$ using the given matrix $\\mathbf{M}$:\n$$\n\\mathbf{M}\\,\\mathbf{y}(t) = \\begin{bmatrix}\n-\\lambda_1  0  0 \\\\\n\\lambda_1  -\\lambda_2  0 \\\\\n0  \\lambda_2  0\n\\end{bmatrix} \\begin{bmatrix} y_1(t) \\\\ y_2(t) \\\\ y_3(t) \\end{bmatrix} = \\begin{bmatrix} -\\lambda_1 y_1(t) \\\\ \\lambda_1 y_1(t) - \\lambda_2 y_2(t) \\\\ \\lambda_2 y_2(t) \\end{bmatrix}\n$$\nThe components of $\\mathbf{g}(t)$ are then:\n$$\ng_1(t) = \\frac{dy_1}{dt} - (-\\lambda_1 y_1(t)) = 0.4(\\lambda_1 - \\alpha)e^{-\\alpha t} + 0.2(\\lambda_1 - \\beta)e^{-\\beta t} + 0.1(\\lambda_1 - \\gamma)e^{-\\gamma t}\n$$\n$$\ng_2(t) = \\frac{dy_2}{dt} - (\\lambda_1 y_1(t) - \\lambda_2 y_2(t))\n$$\nSubstituting the expressions for the derivatives and abundances yields:\n$$\n\\begin{align*}\ng_2(t) = (-0.3\\beta e^{-\\beta t} + 0.3(\\alpha+\\beta) e^{-(\\alpha+\\beta)t} - 0.1\\gamma e^{-\\gamma t} - 0.1\\delta e^{-\\delta t}) \\\\\n- \\lambda_1(0.4 e^{-\\alpha t} + 0.2 e^{-\\beta t} + 0.1 e^{-\\gamma t}) \\\\\n+ \\lambda_2(0.3 e^{-\\beta t} - 0.3 e^{-(\\alpha+\\beta)t} + 0.1 e^{-\\gamma t} + 0.1 e^{-\\delta t})\n\\end{align*}\n$$\nCollecting terms with common exponentials:\n$$\n\\begin{align*}\ng_2(t) = -0.4\\lambda_1 e^{-\\alpha t} + (-0.3\\beta - 0.2\\lambda_1 + 0.3\\lambda_2) e^{-\\beta t} \\\\\n+ (-0.1\\gamma - 0.1\\lambda_1 + 0.1\\lambda_2) e^{-\\gamma t} + (-0.1\\delta + 0.1\\lambda_2) e^{-\\delta t} \\\\\n+ (0.3(\\alpha+\\beta) - 0.3\\lambda_2) e^{-(\\alpha+\\beta)t}\n\\end{align*}\n$$\nFor $g_3(t)$, we note that the sum of abundances is constant: $\\sum_{i=1}^3 y_i(t) = 1$. Differentiating with respect to time gives $\\sum \\frac{dy_i}{dt} = 0$. Summing the rows of the ODE system gives $\\sum \\frac{dy_i}{dt} = \\sum (\\mathbf{M}\\mathbf{y})_i + \\sum g_i(t)$. The sum of the components of $\\mathbf{M}\\mathbf{y}$ is $(-\\lambda_1 y_1) + (\\lambda_1 y_1 - \\lambda_2 y_2) + (\\lambda_2 y_2) = 0$. Therefore, it must be that $\\sum g_i(t) = 0$, which implies $g_3(t) = -g_1(t) - g_2(t)$. This provides a simple way to compute $g_3(t)$ and serves as a consistency check.\n\n**2. Numerical Integration Methods**\n\nLet the ODE be written as $\\frac{d\\mathbf{y}}{dt} = \\mathbf{f}(t, \\mathbf{y})$, where $\\mathbf{f}(t, \\mathbf{y}) = \\mathbf{M}\\,\\mathbf{y} + \\mathbf{g}(t)$.\n\n**Fourth-Order Runge-Kutta (RK4):** This is an explicit one-step method. The solution at time $t^{n+1} = t^n + \\Delta t$ is computed from the solution at $t^n$ via:\n$$\n\\mathbf{y}^{n+1} = \\mathbf{y}^{n} + \\frac{\\Delta t}{6}(\\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4)\n$$\nwhere the stages $\\mathbf{k}_i$ are:\n$$\n\\begin{aligned}\n\\mathbf{k}_1 = \\mathbf{f}(t^n, \\mathbf{y}^n) \\\\\n\\mathbf{k}_2 = \\mathbf{f}(t^n + \\frac{\\Delta t}{2}, \\mathbf{y}^n + \\frac{\\Delta t}{2}\\mathbf{k}_1) \\\\\n\\mathbf{k}_3 = \\mathbf{f}(t^n + \\frac{\\Delta t}{2}, \\mathbf{y}^n + \\frac{\\Delta t}{2}\\mathbf{k}_2) \\\\\n\\mathbf{k}_4 = \\mathbf{f}(t^n + \\Delta t, \\mathbf{y}^n + \\Delta t\\mathbf{k}_3)\n\\end{aligned}\n$$\nThe nominal order of accuracy is $p_{\\mathrm{nom}} = 4$.\n\n**Trapezoidal Rule (TR):** This is an implicit one-step method, also known as the Crank-Nicolson method. The update rule is:\n$$\n\\mathbf{y}^{n+1} = \\mathbf{y}^{n} + \\frac{\\Delta t}{2}\\left(\\mathbf{f}(t^n, \\mathbf{y}^n) + \\mathbf{f}(t^{n+1}, \\mathbf{y}^{n+1})\\right)\n$$\nSubstituting $\\mathbf{f}(t, \\mathbf{y}) = \\mathbf{M}\\mathbf{y} + \\mathbf{g}(t)$ and rearranging to solve for $\\mathbf{y}^{n+1}$:\n$$\n\\mathbf{y}^{n+1} - \\frac{\\Delta t}{2}\\mathbf{M}\\mathbf{y}^{n+1} = \\mathbf{y}^{n} + \\frac{\\Delta t}{2}\\mathbf{M}\\mathbf{y}^{n} + \\frac{\\Delta t}{2}\\left(\\mathbf{g}(t^n) + \\mathbf{g}(t^{n+1})\\right)\n$$\nThis is the linear system provided in the problem statement, which is solved for $\\mathbf{y}^{n+1}$ at each time step:\n$$\n\\left(\\mathbf{I} - \\frac{\\Delta t}{2}\\mathbf{M}\\right)\\mathbf{y}^{n+1} = \\left(\\mathbf{I} + \\frac{\\Delta t}{2}\\mathbf{M}\\right)\\mathbf{y}^{n} + \\frac{\\Delta t}{2}\\left(\\mathbf{g}(t^{n}) + \\mathbf{g}(t^{n+1})\\right)\n$$\nwhere $\\mathbf{I}$ is the identity matrix. The nominal order of accuracy is $p_{\\mathrm{nom}} = 2$.\n\n**3. Convergence Study and Order Estimation**\n\nFor each parameter set, the system is integrated from $t_0=0$ to $t_f$ using a grid of decreasing time steps $\\Delta t$. The initial condition is set to the exact value $\\mathbf{y}(0) = \\mathbf{y}_{\\mathrm{exact}}(0)$. The Euclidean norm of the final-time error is computed:\n$$\nE(\\Delta t) = \\left\\lVert \\mathbf{y}_{\\mathrm{num}}(t_f; \\Delta t) - \\mathbf{y}_{\\mathrm{exact}}(t_f) \\right\\rVert_2\n$$\nFor a method of order $p$, the error is expected to scale as $E(\\Delta t) \\approx C(\\Delta t)^p$ for some constant $C$ and sufficiently small $\\Delta t$. Taking the base-$10$ logarithm gives a linear relationship:\n$$\n\\log_{10}(E(\\Delta t)) \\approx \\log_{10}(C) + p \\log_{10}(\\Delta t)\n$$\nThe observed order of convergence, $p$, is estimated as the slope of a line fitted to the data points $(\\log_{10}(\\Delta t), \\log_{10}(E))$ using a linear least-squares regression.\n\nOrder reduction is a phenomenon, particularly in stiff systems, where the observed order $p$ is lower than the nominal order $p_{\\mathrm{nom}}$ of the method. According to the problem definition, order reduction is detected if $p  p_{\\mathrm{nom}} - 0.5$. This translates to $p  3.5$ for RK4 and $p  1.5$ for TR. The analysis is performed for each of the three test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the specified ODE convergence study problem.\n    \"\"\"\n    \n    # Global constants for the manufactured solution\n    ALPHA = 800.0\n    BETA = 80.0\n    GAMMA = 8.0\n    DELTA = 0.8\n    T0 = 0.0\n\n    def y_exact(t):\n        \"\"\"Computes the exact manufactured solution vector y(t).\"\"\"\n        t = np.asarray(t)\n        exp_at = np.exp(-ALPHA * t)\n        exp_bt = np.exp(-BETA * t)\n        exp_gt = np.exp(-GAMMA * t)\n        exp_dt = np.exp(-DELTA * t)\n\n        y1 = 0.4 * exp_at + 0.2 * exp_bt + 0.1 * exp_gt\n        y2 = 0.3 * (1.0 - exp_at) * exp_bt + 0.1 * exp_gt + 0.1 * exp_dt\n        y3 = 1.0 - y1 - y2\n        \n        # Ensure output is (N, 3) for N time points or (1, 3) for a scalar t\n        return np.array([y1, y2, y3]).T.reshape(-1, 3)\n\n    def g_forcing(t, lam1, lam2):\n        \"\"\"Computes the forcing term vector g(t).\"\"\"\n        t = np.asarray(t)\n\n        exp_at = np.exp(-ALPHA * t)\n        exp_bt = np.exp(-BETA * t)\n        exp_gt = np.exp(-GAMMA * t)\n        exp_dt = np.exp(-DELTA * t)\n        exp_abt = np.exp(-(ALPHA + BETA) * t)\n\n        y1_exact = 0.4 * exp_at + 0.2 * exp_bt + 0.1 * exp_gt\n        y2_exact = 0.3 * exp_bt - 0.3 * exp_abt + 0.1 * exp_gt + 0.1 * exp_dt\n        \n        dy1_dt = -0.4 * ALPHA * exp_at - 0.2 * BETA * exp_bt - 0.1 * GAMMA * exp_gt\n        dy2_dt = -0.3 * BETA * exp_bt + 0.3 * (ALPHA + BETA) * exp_abt - 0.1 * GAMMA * exp_gt - 0.1 * DELTA * exp_dt\n        \n        # g = dy/dt - M*y\n        g1 = dy1_dt - (-lam1 * y1_exact)\n        g2 = dy2_dt - (lam1 * y1_exact - lam2 * y2_exact)\n        g3 = -g1 - g2\n        \n        return np.array([g1, g2, g3]).T.reshape(-1, 3)\n\n    def f_ode(t, y, M, lam1, lam2):\n        \"\"\"RHS of the ODE: f(t, y) = M*y + g(t)\"\"\"\n        return M @ y + g_forcing(t, lam1, lam2).flatten()\n\n    def solve_rk4(M, lam1, lam2, y0, tf, dt):\n        \"\"\"Integrates the ODE system using the classical RK4 method.\"\"\"\n        t = T0\n        y = y0.copy()\n        num_steps = int(round((tf - T0) / dt))\n        \n        for _ in range(num_steps):\n            k1 = f_ode(t, y, M, lam1, lam2)\n            k2 = f_ode(t + 0.5 * dt, y + 0.5 * dt * k1, M, lam1, lam2)\n            k3 = f_ode(t + 0.5 * dt, y + 0.5 * dt * k2, M, lam1, lam2)\n            k4 = f_ode(t + dt, y + dt * k3, M, lam1, lam2)\n            y += (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n            t += dt\n        \n        return y\n\n    def solve_tr(M, lam1, lam2, y0, tf, dt):\n        \"\"\"Integrates the ODE system using the Trapezoidal Rule.\"\"\"\n        t = T0\n        y = y0.copy()\n        num_steps = int(round((tf - T0) / dt))\n        \n        I = np.identity(3)\n        A = I - (dt / 2.0) * M\n        B = I + (dt / 2.0) * M\n        \n        for _ in range(num_steps):\n            t_n = t\n            t_np1 = t + dt\n            \n            g_n = g_forcing(t_n, lam1, lam2).flatten()\n            g_np1 = g_forcing(t_np1, lam1, lam2).flatten()\n            \n            rhs = B @ y + (dt / 2.0) * (g_n + g_np1)\n            y = np.linalg.solve(A, rhs)\n            t = t_np1\n            \n        return y\n\n    test_cases = [\n        # Case 1: (lambda1, lambda2, t_f, {Delta t})\n        (10**2, 10, 2*10**-2, np.array([2e-3, 1e-3, 5e-4, 2.5e-4])),\n        # Case 2\n        (10**4, 10**3, 2*10**-3, np.array([2e-4, 1e-4, 5e-5, 2.5e-5])),\n        # Case 3\n        (2*10**4, 5*10**3, 10**-3, np.array([2e-4, 1e-4, 5e-5, 2.5e-5])),\n    ]\n\n    results = []\n    \n    for lam1, lam2, tf, dt_list in test_cases:\n        M = np.array([[-lam1, 0, 0], [lam1, -lam2, 0], [0, lam2, 0]], dtype=float)\n        y0 = y_exact(T0).flatten()\n        y_final_exact = y_exact(tf).flatten()\n        \n        errors_rk4 = []\n        errors_tr = []\n        \n        for dt in dt_list:\n            y_final_rk4 = solve_rk4(M, lam1, lam2, y0, tf, dt)\n            error_rk4 = np.linalg.norm(y_final_rk4 - y_final_exact)\n            errors_rk4.append(error_rk4)\n            \n            y_final_tr = solve_tr(M, lam1, lam2, y0, tf, dt)\n            error_tr = np.linalg.norm(y_final_tr - y_final_exact)\n            errors_tr.append(error_tr)\n\n        log_dt = np.log10(dt_list)\n        \n        log_err_rk4 = np.log10(np.array(errors_rk4, dtype=float))\n        if np.any(np.isinf(log_err_rk4)) or np.any(np.isnan(log_err_rk4)):\n            p_rk4 = 0.0\n        else:\n            p_rk4 = np.polyfit(log_dt, log_err_rk4, 1)[0]\n        \n        log_err_tr = np.log10(np.array(errors_tr, dtype=float))\n        if np.any(np.isinf(log_err_tr)) or np.any(np.isnan(log_err_tr)):\n            p_tr = 0.0\n        else:\n            p_tr = np.polyfit(log_dt, log_err_tr, 1)[0]\n        \n        r_rk4 = 1 if p_rk4  (4.0 - 0.5) else 0\n        r_tr = 1 if p_tr  (2.0 - 0.5) else 0\n        \n        results.extend([p_rk4, p_tr, r_rk4, r_tr])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3577003"}]}