{"hands_on_practices": [{"introduction": "To master complex computational methods, we often start with a simple, exactly solvable \"laboratory\" system. This first practice uses the two-site Hubbard model to build the fundamental engine of an Auxiliary-Field Quantum Monte Carlo (AFQMC) simulation. You will implement the imaginary-time propagator using the Trotter-Suzuki and Hubbard-Stratonovich transformations, and then apply the constrained-path condition by evaluating the walker's overlap with a trial wavefunction. By calculating the constrained-path energy for this benchmark system, you will gain a concrete understanding of how the core theoretical components of AFQMC translate into a working algorithm [@problem_id:3551579].", "problem": "Consider a one-dimensional two-site Hubbard model that is invariant under spin rotations, exhibiting Special Unitary group of degree 2 (SU(2)) symmetry in spin space. Let the sites be labeled by $i \\in \\{1,2\\}$ and spins by $\\sigma \\in \\{\\uparrow,\\downarrow\\}$. The Hamiltonian is\n$$\n\\hat{H} = \\hat{K} + \\hat{V},\n$$\nwith the kinetic energy\n$$\n\\hat{K} = -t \\sum_{\\sigma} \\left( \\hat{c}_{1\\sigma}^{\\dagger} \\hat{c}_{2\\sigma} + \\hat{c}_{2\\sigma}^{\\dagger} \\hat{c}_{1\\sigma} \\right),\n$$\nand the on-site interaction\n$$\n\\hat{V} = U \\sum_{i=1}^{2} \\hat{n}_{i\\uparrow} \\hat{n}_{i\\downarrow},\n$$\nwhere $t > 0$ and $U \\ge 0$, $\\hat{c}_{i\\sigma}^{\\dagger}$ and $\\hat{c}_{i\\sigma}$ are fermionic creation and annihilation operators, and $\\hat{n}_{i\\sigma} = \\hat{c}_{i\\sigma}^{\\dagger} \\hat{c}_{i\\sigma}$ is the number operator. Work at half-filling with two fermions, one of each spin.\n\nThe ground-state energy for this two-site system at half-filling is exactly known and can be derived by direct diagonalization in the spin-singlet subspace. Denote it by $E_0(U,t)$. For this model it is:\n$$\nE_0(U,t) = \\frac{U}{2} - \\sqrt{\\left( \\frac{U}{2} \\right)^2 + 4 t^2 }.\n$$\n\nYou will implement an Auxiliary-Field Quantum Monte Carlo (AFQMC) projector with the constrained-path approximation. The AFQMC projector approximates the imaginary-time evolution operator using the Trotter-Suzuki factorization over a single time slice:\n$$\ne^{-\\Delta \\tau \\hat{H}} \\approx e^{-\\Delta \\tau \\hat{K}} e^{-\\Delta \\tau \\hat{V}}.\n$$\nThe interaction term is decoupled using the Hirsch discrete Hubbard-Stratonovich transformation:\n$$\ne^{-\\Delta \\tau U \\hat{n}_{i\\uparrow} \\hat{n}_{i\\downarrow}} = \\frac{1}{2} e^{-\\Delta \\tau U / 2} \\sum_{s_i=\\pm 1} e^{\\lambda s_i (\\hat{n}_{i\\uparrow} - \\hat{n}_{i\\downarrow})},\n$$\nwhere $\\lambda$ is chosen such that $\\cosh(\\lambda) = e^{\\Delta \\tau U / 2}$, i.e.,\n$$\n\\lambda = \\operatorname{arccosh}\\left( e^{\\Delta \\tau U / 2} \\right).\n$$\n\nRepresent the one-body propagators as $2 \\times 2$ matrices in site basis. The kinetic matrix is\n$$\nK = \\begin{pmatrix} 0 & -t \\\\ -t & 0 \\end{pmatrix},\n$$\nand its single-slice propagator is $B_K = e^{-\\Delta \\tau K}$ (the matrix exponential). The decoupled interaction yields a diagonal potential for each spin:\n$$\nD_{\\sigma}(\\mathbf{s}) = \\operatorname{diag}\\left( e^{\\sigma \\lambda s_1}, e^{\\sigma \\lambda s_2} \\right),\n$$\nwith $\\sigma = +1$ for spin-up and $\\sigma = -1$ for spin-down, and $\\mathbf{s} = (s_1,s_2)$ denotes the Hubbard-Stratonovich Ising fields on the two sites for the single time slice.\n\nUse the trial Slater determinant $|\\Psi_T\\rangle$ constructed from the bonding orbital for each spin:\n$$\n|\\phi_T\\rangle = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix},\n$$\nso the trial for each spin sector is the one-particle state $|\\phi_T\\rangle$. This trial encodes the exact fermion nodes in the noninteracting limit $U=0$. For a single time slice, the walker orbitals after propagation for spin $\\sigma$ under field configuration $\\mathbf{s}$ are:\n$$\n|\\phi_{\\sigma}(\\mathbf{s})\\rangle = B_K \\, D_{\\sigma}(\\mathbf{s}) \\, |\\phi_T\\rangle.\n$$\n\nDefine the overlap with the trial for spin $\\sigma$ as $O_{\\sigma}(\\mathbf{s}) = \\langle \\phi_T | \\phi_{\\sigma}(\\mathbf{s}) \\rangle$, and the total overlap $O(\\mathbf{s}) = O_{\\uparrow}(\\mathbf{s}) \\, O_{\\downarrow}(\\mathbf{s})$. The constrained-path approximation enforces the sign of the trial overlap by discarding any field configuration $\\mathbf{s}$ for which $O(\\mathbf{s}) \\le 0$.\n\nFor each allowed configuration $\\mathbf{s}$, define the mixed one-body Green's function for spin $\\sigma$ as\n$$\nG_{\\sigma}(\\mathbf{s}) = \\frac{|\\phi_{\\sigma}(\\mathbf{s})\\rangle \\langle \\phi_T |}{O_{\\sigma}(\\mathbf{s})},\n$$\nwhich yields the mixed estimator of the kinetic energy\n$$\nE_K(\\mathbf{s}) = \\sum_{\\sigma} \\operatorname{Tr}\\left[ K \\, G_{\\sigma}(\\mathbf{s}) \\right],\n$$\nand the mixed estimator of the interaction energy\n$$\nE_U(\\mathbf{s}) = U \\sum_{i=1}^{2} \\left( G_{\\uparrow}(\\mathbf{s}) \\right)_{ii} \\left( G_{\\downarrow}(\\mathbf{s}) \\right)_{ii}.\n$$\nThe local energy is $E_L(\\mathbf{s}) = E_K(\\mathbf{s}) + E_U(\\mathbf{s})$.\n\nThe constrained-path energy for a single time slice at time step $\\Delta \\tau$ is the overlap-weighted average over allowed configurations:\n$$\nE_{\\text{CP}}(\\Delta \\tau) = \\frac{\\sum_{\\mathbf{s} \\in \\mathcal{A}} O(\\mathbf{s}) \\, E_L(\\mathbf{s})}{\\sum_{\\mathbf{s} \\in \\mathcal{A}} O(\\mathbf{s})},\n$$\nwhere $\\mathcal{A}$ is the set of $\\mathbf{s}$ for which $O(\\mathbf{s}) > 0$. The constant prefactors in the Hubbard-Stratonovich transformation cancel in this ratio, so they need not be included in the weights.\n\nStarting from the Schrödinger equation in imaginary time and the above factorization and decoupling, implement the algorithm to compute $E_{\\text{CP}}(\\Delta \\tau)$ for the given model and compare it to the exact ground-state energy $E_0(U,t)$. Use the following test suite with fixed $t=1$ and a single time slice $L=1$:\n\n- Case 1 (happy path, noninteracting, coarse step): $U=0$, $\\Delta \\tau = 0.5$.\n- Case 2 (noninteracting, fine step): $U=0$, $\\Delta \\tau = 0.05$.\n- Case 3 (interacting, coarse step): $U=4$, $\\Delta \\tau = 0.5$.\n- Case 4 (interacting, medium step): $U=4$, $\\Delta \\tau = 0.2$.\n- Case 5 (interacting, fine step): $U=4$, $\\Delta \\tau = 0.05$.\n\nFor each case, compute and return the constrained-path energy $E_{\\text{CP}}(\\Delta \\tau)$ as a float. In addition, for Cases 1 and 2, return a boolean indicating whether the constrained-path approximation is exact when the trial encodes the nodes; that is, whether $|E_{\\text{CP}}(\\Delta \\tau) - E_0(U,t)| < 10^{-10}$ holds.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain seven entries in this order:\n$$\n\\left[ E_{\\text{CP}}(0.5; U{=}0), E_{\\text{CP}}(0.05; U{=}0), E_{\\text{CP}}(0.5; U{=}4), E_{\\text{CP}}(0.2; U{=}4), E_{\\text{CP}}(0.05; U{=}4), \\text{ExactCase1}, \\text{ExactCase2} \\right],\n$$\nwhere the last two are booleans. No physical units are required for the energies.", "solution": "### Step 1: Extract Givens\nThe problem provides the following data and definitions for a one-dimensional two-site Hubbard model at half-filling (two fermions, one spin-up, one spin-down):\n\n1.  **Hamiltonian**: $\\hat{H} = \\hat{K} + \\hat{V}$\n    *   Kinetic term: $\\hat{K} = -t \\sum_{\\sigma} \\left( \\hat{c}_{1\\sigma}^{\\dagger} \\hat{c}_{2\\sigma} + \\hat{c}_{2\\sigma}^{\\dagger} \\hat{c}_{1\\sigma} \\right)$\n    *   Interaction term: $\\hat{V} = U \\sum_{i=1}^{2} \\hat{n}_{i\\uparrow} \\hat{n}_{i\\downarrow}$\n    *   Parameters: $t > 0$, $U \\ge 0$.\n\n2.  **Exact Ground-State Energy**: $E_0(U,t) = \\frac{U}{2} - \\sqrt{\\left( \\frac{U}{2} \\right)^2 + 4 t^2 }$.\n\n3.  **AFQMC Projector (Single time slice $\\Delta \\tau$)**:\n    *   Trotter-Suzuki factorization: $e^{-\\Delta \\tau \\hat{H}} \\approx e^{-\\Delta \\tau \\hat{K}} e^{-\\Delta \\tau \\hat{V}}$.\n    *   Hirsch discrete Hubbard-Stratonovich transformation for the interaction term:\n        $$\n        e^{-\\Delta \\tau U \\hat{n}_{i\\uparrow} \\hat{n}_{i\\downarrow}} = \\frac{1}{2} e^{-\\Delta \\tau U / 2} \\sum_{s_i=\\pm 1} e^{\\lambda s_i (\\hat{n}_{i\\uparrow} - \\hat{n}_{i\\downarrow})}\n        $$\n    *   Hubbard-Stratonovich parameter: $\\lambda = \\operatorname{arccosh}\\left( e^{\\Delta \\tau U / 2} \\right)$.\n\n4.  **One-Body Representation (Site Basis)**:\n    *   Kinetic matrix: $K = \\begin{pmatrix} 0 & -t \\\\ -t & 0 \\end{pmatrix}$.\n    *   Kinetic propagator: $B_K = e^{-\\Delta \\tau K}$ (matrix exponential).\n    *   Interaction potential matrix (for HS fields $\\mathbf{s} = (s_1, s_2)$ and spin $\\sigma$):\n        $$\n        D_{\\sigma}(\\mathbf{s}) = \\operatorname{diag}\\left( e^{\\sigma \\lambda s_1}, e^{\\sigma \\lambda s_2} \\right)\n        $$\n        with $\\sigma = +1$ for spin-up and $\\sigma = -1$ for spin-down.\n\n5.  **Trial Wavefunction and Propagation**:\n    *   Trial orbital (for each spin): $|\\phi_T\\rangle = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n    *   Propagated walker orbital: $|\\phi_{\\sigma}(\\mathbf{s})\\rangle = B_K \\, D_{\\sigma}(\\mathbf{s}) \\, |\\phi_T\\rangle$.\n\n6.  **Observables and Constraint**:\n    *   Spin-resolved overlap: $O_{\\sigma}(\\mathbf{s}) = \\langle \\phi_T | \\phi_{\\sigma}(\\mathbf{s}) \\rangle$.\n    *   Total overlap: $O(\\mathbf{s}) = O_{\\uparrow}(\\mathbf{s}) \\, O_{\\downarrow}(\\mathbf{s})$.\n    *   Constrained-path condition: Keep configurations $\\mathbf{s}$ where $O(\\mathbf{s}) > 0$.\n    *   Mixed one-body Green's function: $G_{\\sigma}(\\mathbf{s}) = \\frac{|\\phi_{\\sigma}(\\mathbf{s})\\rangle \\langle \\phi_T |}{O_{\\sigma}(\\mathbf{s})}$.\n    *   Mixed kinetic energy estimator: $E_K(\\mathbf{s}) = \\sum_{\\sigma} \\operatorname{Tr}\\left[ K \\, G_{\\sigma}(\\mathbf{s}) \\right]$.\n    *   Mixed interaction energy estimator: $E_U(\\mathbf{s}) = U \\sum_{i=1}^{2} \\left( G_{\\uparrow}(\\mathbf{s}) \\right)_{ii} \\left( G_{\\downarrow}(\\mathbf{s}) \\right)_{ii}$.\n    *   Local energy: $E_L(\\mathbf{s}) = E_K(\\mathbf{s}) + E_U(\\mathbf{s})$.\n\n7.  **Final Constrained-Path Energy**:\n    *   $E_{\\text{CP}}(\\Delta \\tau) = \\frac{\\sum_{\\mathbf{s} \\in \\mathcal{A}} O(\\mathbf{s}) \\, E_L(\\mathbf{s})}{\\sum_{\\mathbf{s} \\in \\mathcal{A}} O(\\mathbf{s})}$, where $\\mathcal{A} = \\{\\mathbf{s} | O(\\mathbf{s}) > 0\\}$. Constant prefactors from the HS transform cancel and are to be ignored.\n\n8.  **Test Suite**: Fixed $t=1$, single time slice.\n    *   Case 1: $U=0$, $\\Delta \\tau = 0.5$.\n    *   Case 2: $U=0$, $\\Delta \\tau = 0.05$.\n    *   Case 3: $U=4$, $\\Delta \\tau = 0.5$.\n    *   Case 4: $U=4$, $\\Delta \\tau = 0.2$.\n    *   Case 5: $U=4$, $\\Delta \\tau = 0.05$.\n    *   For Cases 1 and 2, also return a boolean for $|E_{\\text{CP}}(\\Delta \\tau) - E_0(U,t)| < 10^{-10}$.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientifically Grounded**: The problem is firmly rooted in standard many-body quantum mechanics and computational physics. The Hubbard model, Auxiliary-Field Quantum Monte Carlo (AFQMC), Trotter-Suzuki factorization, and Hirsch-Hubbard-Stratonovich transformation are all cornerstone concepts in the field. The provided equations are correct representations of these concepts for the specified model. The exact solution for the two-site Hubbard model is a well-known benchmark.\n2.  **Well-Posed**: The problem is well-posed. It requests the calculation of a specific quantity, $E_{\\text{CP}}(\\Delta \\tau)$, for a deterministic algorithm. Since the system has only two sites, the sum over Hubbard-Stratonovich fields $\\mathbf{s}$ is not a Monte Carlo sampling but an exact enumeration over $2^2=4$ configurations. All necessary formulas, parameters, and initial states are explicitly provided, leading to a unique, computable solution for each test case.\n3.  **Objective**: The problem is stated in precise, objective mathematical language, free of ambiguity or subjective claims.\n4.  **Completeness and Consistency**: The problem is self-contained. It provides all the necessary components for the calculation, from the Hamiltonian to the final energy formula. There are no missing definitions or contradictory constraints.\n5.  **Relevance**: The problem is directly on-topic for *constrained-path approximations in Monte Carlo* within *computational nuclear physics* (and more broadly, computational quantum physics).\n\nThe problem does not exhibit any flaws such as scientific unsoundness, missing information, or ambiguity.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Principle-Based Design and Solution\nThe core task is to compute the constrained-path energy estimator, $E_{\\text{CP}}(\\Delta \\tau)$, for a single imaginary-time step. This involves averaging the local energy, $E_L(\\mathbf{s})$, over all possible auxiliary field configurations $\\mathbf{s}$, weighted by their corresponding overlaps, $O(\\mathbf{s})$. The calculation is deterministic because we sum over the entire space of auxiliary fields, which is small ($2^2 = 4$ configurations).\n\nThe algorithm proceeds as follows for each test case $(U, \\Delta\\tau)$:\n\n1.  **Initialization**: Define the physical parameters of the model. The hopping strength is fixed at $t=1$. The one-body kinetic matrix $K$ and the trial orbital $|\\phi_T\\rangle$ are constructed. $|\\phi_T\\rangle$ is the ground state of the non-interacting system ($U=0$), which is the bonding orbital.\n    $$\n    K = \\begin{pmatrix} 0 & -1 \\\\ -1 & 0 \\end{pmatrix}, \\quad |\\phi_T\\rangle = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n    $$\n\n2.  **Calculate Step-Dependent Parameters**:\n    *   The Hubbard-Stratonovich parameter $\\lambda$ depends on both $U$ and $\\Delta\\tau$. For $U=0$, we have $e^{\\Delta \\tau U / 2} = 1$, and $\\lambda = \\operatorname{arccosh}(1) = 0$, which correctly eliminates the interaction part of the propagator. For $U > 0$, $\\lambda > 0$.\n    *   The one-body kinetic propagator $B_K$ is the matrix exponential of $-\\Delta\\tau K$. This can be computed numerically or analytically. Analytically, for $K=\\begin{pmatrix} 0 & -t \\\\ -t & 0 \\end{pmatrix}$, \n$$\nB_K = e^{-\\Delta\\tau K} = \\begin{pmatrix} \\cosh(\\Delta\\tau t) & \\sinh(\\Delta\\tau t) \\\\ \\sinh(\\Delta\\tau t) & \\cosh(\\Delta\\tau t) \\end{pmatrix}\n$$\n\n3.  **Iterate Over Auxiliary Fields**: The calculation requires summing over all four possible configurations of the discrete Hubbard-Stratonovich fields $\\mathbf{s} = (s_1, s_2)$, where $s_i \\in \\{+1, -1\\}$. The set of configurations is $\\{(1,1), (1,-1), (-1,1), (-1,-1)\\}$. For each configuration $\\mathbf{s}$:\n\n    a.  **Construct Interaction Propagators**: For spins $\\sigma=+1$ (up) and $\\sigma=-1$ (down), define the diagonal matrices $D_{\\sigma}(\\mathbf{s})$ that represent the action of the interaction term for the given field configuration.\n        $$\n        D_{\\uparrow}(\\mathbf{s}) = \\operatorname{diag}(e^{\\lambda s_1}, e^{\\lambda s_2}), \\quad D_{\\downarrow}(\\mathbf{s}) = \\operatorname{diag}(e^{-\\lambda s_1}, e^{-\\lambda s_2})\n        $$\n\n    b.  **Propagate Walkers and Compute Overlaps**: The trial orbital $|\\phi_T\\rangle$ is propagated forward in imaginary time for one step under the influence of the kinetic term and the specific interaction configuration $\\mathbf{s}$.\n        $$\n        |\\phi_{\\sigma}(\\mathbf{s})\\rangle = B_K D_{\\sigma}(\\mathbf{s}) |\\phi_T\\rangle\n        $$\n        The overlap of this propagated walker with the original trial is calculated for each spin, $O_{\\sigma}(\\mathbf{s}) = \\langle \\phi_T |\\phi_{\\sigma}(\\mathbf{s})\\rangle$. The total overlap weight is the product $O(\\mathbf{s}) = O_{\\uparrow}(\\mathbf{s}) O_{\\downarrow}(\\mathbf{s})$. Because our trial orbital is the bonding orbital (all positive entries) and the propagators $B_K$ and $D_\\sigma$ are composed of positive exponentials, the resulting propagated walkers $|\\phi_{\\sigma}(\\mathbf{s})\\rangle$ will have all positive entries. Thus, the overlap $O(\\mathbf{s})$ will always be positive. The constrained-path condition $O(\\mathbf{s}) > 0$ is always satisfied, and the set of allowed configurations $\\mathcal{A}$ includes all four possibilities.\n\n    c.  **Compute Local Energy**: If the configuration is allowed (which all are), calculate the local energy $E_L(\\mathbf{s})$. This first requires the mixed one-body Green's functions:\n        $$\n        G_{\\sigma}(\\mathbf{s}) = \\frac{|\\phi_{\\sigma}(\\mathbf{s})\\rangle \\langle \\phi_T |}{O_{\\sigma}(\\mathbf{s})}\n        $$\n        From these, the kinetic and potential energy estimators are found:\n        $$\n        E_K(\\mathbf{s}) = \\operatorname{Tr}[K G_{\\uparrow}(\\mathbf{s})] + \\operatorname{Tr}[K G_{\\downarrow}(\\mathbf{s})]\n        $$\n        $$\n        E_U(\\mathbf{s}) = U \\left( (G_{\\uparrow}(\\mathbf{s}))_{11} (G_{\\downarrow}(\\mathbf{s}))_{11} + (G_{\\uparrow}(\\mathbf{s}))_{22} (G_{\\downarrow}(\\mathbf{s}))_{22} \\right)\n        $$\n        The total local energy is $E_L(\\mathbf{s}) = E_K(\\mathbf{s}) + E_U(\\mathbf{s})$.\n\n    d.  **Accumulate Results**: The weighted energy $O(\\mathbf{s}) E_L(\\mathbf{s})$ and the weight $O(\\mathbf{s})$ are added to running totals.\n\n4.  **Final Energy Calculation**: After iterating through all four field configurations, the final constrained-path energy is computed as the ratio of the accumulated sums:\n    $$\n    E_{\\text{CP}}(\\Delta \\tau) = \\frac{\\sum_{\\mathbf{s}} O(\\mathbf{s}) E_L(\\mathbf{s})}{\\sum_{\\mathbf{s}} O(\\mathbf{s})}\n    $$\n\n5.  **Special Case Analysis ($U=0$)**: For the non-interacting cases ($U=0$), we get $\\lambda=0$. This makes $D_{\\sigma}(\\mathbf{s})$ the identity matrix for all $\\mathbf{s}$. The walker propagation becomes independent of $\\mathbf{s}$, and the local energy $E_L$ becomes constant for all configurations. Since $|\\phi_T\\rangle$ is an eigenstate of $K$ with eigenvalue $-t$, the particle-hole symmetric trial wavefunction is an eigenstate of the non-interacting Hamiltonian $\\hat{K}$ with energy $2 \\times (-t) = -2t$. The mixed estimator formalism with a trial state that is an eigenstate of the Hamiltonian yields the exact eigenvalue. Thus, for $U=0$ and $t=1$, we expect $E_{\\text{CP}} = -2$. This matches the exact ground state energy $E_0(0,1) = -2$. Therefore, the check $|E_{\\text{CP}} - E_0| < 10^{-10}$ should evaluate to true, reflecting that the constrained-path approximation is exact when the trial wavefunction has the correct nodes of the ground state (which it does for $U=0$). The Trotter error also vanishes in this special case because $|\\phi_T\\rangle$ is an eigenstate of $\\hat{K}$.\n\nThe implementation will follow these steps precisely for each test case provided.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef solve():\n    \"\"\"\n    Computes the single-slice constrained-path AFQMC energy for a two-site Hubbard model.\n    \"\"\"\n    \n    test_cases = [\n        # (U, delta_tau)\n        (0.0, 0.5), # Case 1\n        (0.0, 0.05), # Case 2\n        (4.0, 0.5), # Case 3\n        (4.0, 0.2), # Case 4\n        (4.0, 0.05), # Case 5\n    ]\n\n    results_ecp = []\n    results_exact_check = []\n\n    for U, dtau in test_cases:\n        t = 1.0\n        \n        # Define matrices and trial wavefunction\n        K = np.array([[0, -t], \n                      [-t, 0]])\n        phi_T = (1.0 / np.sqrt(2.0)) * np.array([1.0, 1.0])\n\n        # Calculate step-dependent parameters\n        # For U=0, arg=1, arccosh(1)=0. For U>0, arg>1.\n        arg_arccosh = np.exp(dtau * U / 2.0)\n        # Add a small epsilon for stability if arg is very close to 1\n        if np.isclose(arg_arccosh, 1.0):\n            lambda_val = 0.0\n        else:\n            lambda_val = np.arccosh(arg_arccosh)\n        \n        # Kinetic propagator matrix\n        B_K = expm(-dtau * K)\n\n        total_weight = 0.0\n        total_energy_times_weight = 0.0\n\n        # Iterate over all 2^2 = 4 auxiliary field configurations\n        s_fields = [(1, 1), (1, -1), (-1, 1), (-1, -1)]\n        \n        for s1, s2 in s_fields:\n            s = np.array([s1, s2])\n\n            # 1. Construct interaction propagators D_sigma(s)\n            D_up = np.diag(np.exp(lambda_val * s))\n            D_dn = np.diag(np.exp(-lambda_val * s))\n\n            # 2. Propagate walkers\n            phi_up_s = B_K @ D_up @ phi_T\n            phi_dn_s = B_K @ D_dn @ phi_T\n            \n            # 3. Compute overlaps\n            # Since everything is real, transpose is equivalent to conjugate transpose\n            O_up_s = phi_T.T @ phi_up_s\n            O_dn_s = phi_T.T @ phi_dn_s\n            O_s = O_up_s * O_dn_s\n            \n            # 4. Constrained-path approximation check (O_s>0)\n            # For this specific trial function, O_s is always positive,\n            # so the check is implicitly passed for all configurations.\n            \n            # 5. Compute Green's functions\n            # G_sigma = |phi_sigma(s)> <phi_T| / O_sigma(s) \n            G_up_s = np.outer(phi_up_s, phi_T) / O_up_s\n            G_dn_s = np.outer(phi_dn_s, phi_T) / O_dn_s\n            \n            # 6. Compute local energy estimator\n            # Kinetic energy\n            E_K_s = np.trace(K @ G_up_s) + np.trace(K @ G_dn_s)\n            \n            # Potential energy\n            E_U_s = U * (G_up_s[0, 0] * G_dn_s[0, 0] + G_up_s[1, 1] * G_dn_s[1, 1])\n            \n            E_L_s = E_K_s + E_U_s\n            \n            # 7. Accumulate weighted values\n            total_energy_times_weight += O_s * E_L_s\n            total_weight += O_s\n        \n        # Final constrained-path energy for this time step\n        ecp = total_energy_times_weight / total_weight\n        results_ecp.append(ecp)\n\n        # For U=0 cases, perform the exactness check\n        if U == 0.0:\n            E_0 = (U / 2.0) - np.sqrt((U / 2.0)**2 + 4 * t**2)\n            is_exact = np.abs(ecp - E_0) < 1e-10\n            results_exact_check.append(is_exact)\n\n    # Format the final output string\n    # [Ecp1, Ecp2, Ecp3, Ecp4, Ecp5, ExactBool1, ExactBool2]\n    # Note: str(True) -> \"True\", str(False) -> \"False\"\n    final_results = results_ecp + [str(b).lower() for b in results_exact_check]\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3551579"}, {"introduction": "The standard constrained-path method uses a 'hard' constraint, discarding any walker that crosses the nodal surface. This practice explores a more nuanced 'soft' constraint, where walkers are weighted down based on how unfavorably their phase aligns with the trial wavefunction. This introduces the fundamental concept of the bias-variance trade-off: aggressively suppressing walkers with an exponent $\\gamma$ reduces statistical noise (variance) but can increase the systematic error (bias). By analyzing a model of walker-trial overlaps, you will learn to find the optimal constraint strength that minimizes the total error, a crucial skill for producing high-quality QMC results [@problem_id:3551580].", "problem": "Consider a simplified model of constrained-path approximations used in Auxiliary-Field Quantum Monte Carlo (AFQMC) for computational nuclear physics, where an ensemble of independent random walkers carries an overlap phase with a chosen trial wavefunction. Let the walker–trial overlap phase be denoted by the angle $\\,\\Delta \\theta \\in [-\\pi,\\pi]\\,$ in radians, and define $\\,c=\\cos \\Delta \\theta\\,$. The soft-constraint weight applied to each walker is defined as $\\,w(c;\\gamma)=\\max(0,c)^\\gamma\\,$, where $\\,\\gamma \\ge 0\\,$ is a tunable exponent. The goal is to diagnose the distribution of $\\,c\\,$ via the histogram $\\,P(c)\\,$ and then tune $\\,\\gamma\\,$ to balance bias and variance in a weighted ratio estimator for a scalar observable.\n\nFundamental base and core definitions:\n- In AFQMC with constrained-path or phaseless approximations, the complex overlap induces phase fluctuations $\\,\\Delta \\theta\\,$ and $\\,c=\\cos \\Delta \\theta\\,$ encodes their real-projection. The constrained-path soft weight $\\,w(c;\\gamma)\\,$ damps contributions with small or negative $\\,c\\,$ to control variance, at the price of bias.\n- A standard Monte Carlo weighted ratio estimator for a scalar observable $\\,\\mu\\,$ uses $\\,\\hat{\\mu}(\\gamma)=\\dfrac{\\sum_{i=1}^N w_i(\\gamma)L_i}{\\sum_{i=1}^N w_i(\\gamma)}\\,$, where $\\,L_i\\,$ are local energy estimates per walker. For large $\\,N\\,$ and independent walkers, $\\,\\hat{\\mu}(\\gamma)\\,$ concentrates near $\\,\\dfrac{\\mathbb{E}[w L]}{\\mathbb{E}[w]}\\,$ and admits a delta-method variance approximation built from $\\,\\mathrm{Var}(w L)\\,$, $\\,\\mathrm{Var}(w)\\,$, and $\\,\\mathrm{Cov}(w L, w)\\,$.\n- To make the problem self-contained and purely mathematical, assume a generative model in which local energies are linearly correlated with $\\,c\\,$ and have independent additive noise: $\\,L=\\mu+\\kappa_L c+\\eta\\,$, with $\\,\\eta\\,$ a zero-mean noise term with variance $\\,\\sigma^2\\,$, independent of $\\,c\\,$.\n\nTasks to implement:\n1. Generate $\\,N\\,$ independent samples of $\\,\\Delta \\theta\\,$ in radians for each test case, compute $\\,c=\\cos \\Delta \\theta\\,$, and construct a normalized histogram $\\,P(c)\\,$ on the interval $\\,[-1,1]\\,$ using $\\,M\\,$ equally spaced bins. The histogram must yield discrete bin centers $\\,\\{c_j\\}_{j=1}^M\\,$ and probabilities $\\,\\{p_j\\}_{j=1}^M\\,$ with $\\,\\sum_{j=1}^M p_j=1\\,$.\n2. For a grid of $\\,\\gamma\\,$ values, compute the bias and variance of the ratio estimator using only histogram-based moment approximations. For any fixed $\\,\\gamma\\,$ and using the discrete distribution $\\,\\{(c_j,p_j)\\}\\,$, define\n   $$w_j(\\gamma)=\\max(0,c_j)^\\gamma,\\quad \\mathbb{E}[w]=\\sum_{j=1}^M p_j\\,w_j,\\quad \\mathbb{E}[wc]=\\sum_{j=1}^M p_j\\,w_j\\,c_j,$$\n   $$\\mathbb{E}[wL]=\\mu\\,\\mathbb{E}[w]+\\kappa_L\\,\\mathbb{E}[wc],$$\n   $$\\mathbb{E}[w^2]=\\sum_{j=1}^M p_j\\,w_j^2,\\quad \\mathbb{E}[w^2L]=\\sum_{j=1}^M p_j\\,w_j^2\\left(\\mu+\\kappa_L c_j\\right),$$\n   $$\\mathbb{E}[w^2L^2]=\\sum_{j=1}^M p_j\\,w_j^2\\left[\\left(\\mu+\\kappa_L c_j\\right)^2+\\sigma^2\\right].$$\n   Then the bias and variance approximations are\n   $$\\mathrm{bias}(\\gamma)=\\frac{\\mathbb{E}[wL]}{\\mathbb{E}[w]}-\\mu=\\kappa_L\\frac{\\mathbb{E}[wc]}{\\mathbb{E}[w]},$$\n   $$\\mathrm{Var}(wL)=\\mathbb{E}[w^2L^2]-\\left(\\mathbb{E}[wL]\\right)^2,\\quad \\mathrm{Var}(w)=\\mathbb{E}[w^2]-\\left(\\mathbb{E}[w]\\right)^2,$$\n   $$\\mathrm{Cov}(wL,w)=\\mathbb{E}[w^2L]-\\mathbb{E}[wL]\\,\\mathbb{E}[w].$$\n   Using the delta method for ratio estimators with $\\,A=\\frac{1}{N}\\sum w_i L_i\\,$ and $\\,B=\\frac{1}{N}\\sum w_i\\,$, where $\\,a=\\mathbb{E}[wL]\\,$ and $\\,b=\\mathbb{E}[w]\\,$, the variance is approximated by\n   $$\\mathrm{Var}\\left(\\hat{\\mu}(\\gamma)\\right)\\approx \\frac{1}{N}\\left[\\frac{\\mathrm{Var}(wL)}{b^2}+\\frac{a^2}{b^4}\\mathrm{Var}(w)-\\frac{2a}{b^3}\\mathrm{Cov}(wL,w)\\right].$$\n   The mean-squared error is then\n   $$\\mathrm{MSE}(\\gamma)=\\left[\\mathrm{bias}(\\gamma)\\right]^2+\\mathrm{Var}\\left(\\hat{\\mu}(\\gamma)\\right).$$\n3. For each test case, scan $\\,\\gamma\\,$ over a specified grid and select the value that minimizes $\\,\\mathrm{MSE}(\\gamma)\\,$. If multiple $\\,\\gamma\\,$ values yield the same minimal $\\,\\mathrm{MSE}(\\gamma)\\,$ to within numerical precision, choose the smallest such $\\,\\gamma\\,$.\n4. Angles must be treated in radians. There are no physical units to report for the output, but the final $\\,\\gamma\\,$ values must be expressed as floats rounded to two decimal places.\n\nTest suite and parameters:\n- Case $\\,1\\,$ (happy path, moderately concentrated phases): $\\,N=200000\\,$ walkers; $\\,\\Delta \\theta\\,$ sampled from the von Mises distribution with mean $\\,0\\,$ and concentration $\\,\\kappa_\\theta=8.0\\,$; $\\,\\mu=1.5\\,$; $\\,\\kappa_L=0.8\\,$; $\\,\\sigma=0.7\\,$; $\\,M=200\\,$ bins; $\\,\\gamma\\,$ scanned from $\\,0.0\\,$ to $\\,6.0\\,$ in steps of $\\,0.25\\,$.\n- Case $\\,2\\,$ (edge case, uniform phases): $\\,N=200000\\,$ walkers; $\\,\\Delta \\theta\\,$ uniform on $\\,[-\\pi,\\pi]\\,$; $\\,\\mu=0.0\\,$; $\\,\\kappa_L=0.5\\,$; $\\,\\sigma=1.5\\,$; $\\,M=200\\,$ bins; $\\,\\gamma\\,$ scanned from $\\,0.0\\,$ to $\\,6.0\\,$ in steps of $\\,0.25\\,$.\n- Case $\\,3\\,$ (high noise, weak correlation): $\\,N=200000\\,$ walkers; $\\,\\Delta \\theta\\,$ sampled from von Mises with mean $\\,0\\,$ and concentration $\\,\\kappa_\\theta=1.5\\,$; $\\,\\mu=2.0\\,$; $\\,\\kappa_L=0.3\\,$; $\\,\\sigma=3.0\\,$; $\\,M=200\\,$ bins; $\\,\\gamma\\,$ scanned from $\\,0.0\\,$ to $\\,6.0\\,$ in steps of $\\,0.25\\,$.\n- Case $\\,4\\,$ (sign-challenging correlation): $\\,N=200000\\,$ walkers; $\\,\\Delta \\theta\\,$ uniform on $\\,[-\\pi,\\pi]\\,$; $\\,\\mu=-1.0\\,$; $\\,\\kappa_L=-0.6\\,$; $\\,\\sigma=1.0\\,$; $\\,M=200\\,$ bins; $\\,\\gamma\\,$ scanned from $\\,0.0\\,$ to $\\,6.0\\,$ in steps of $\\,0.25\\,$.\n\nFinal output specification:\nYour program should produce a single line of output containing the four optimal exponents $\\,\\gamma^\\star\\,$ for the test cases, as a comma-separated list enclosed in square brackets, with each value rounded to two decimal places, for example $\\,\\left[\\gamma^\\star_1,\\gamma^\\star_2,\\gamma^\\star_3,\\gamma^\\star_4\\right]\\,$. There are no physical units in the output.", "solution": "The problem requires finding the optimal soft-constraint exponent, denoted $\\,\\gamma^\\star\\,$, that minimizes the mean-squared error (MSE) of a weighted ratio estimator for a scalar observable in a simplified Auxiliary-Field Quantum Monte Carlo (AFQMC) model. The MSE represents the total error, combining the squared bias and the variance of the estimator. The optimization involves a trade-off: increasing $\\,\\gamma\\,$ typically reduces variance by suppressing noisy contributions but can introduce a systematic bias.\n\nThe solution proceeds systematically for each test case by following the prescribed tasks:\n1.  Generation of the underlying statistical distribution.\n2.  Calculation of statistical moments using a discrete histogram representation.\n3.  Computation of the bias, variance, and MSE for a range of $\\,\\gamma\\,$ values.\n4.  Identification of the optimal $\\,\\gamma^\\star\\,$ that minimizes the MSE.\n\n**Step 1: Simulation and Histogram Construction**\n\nThe first step is to model the distribution of the walker–trial overlap projection, $\\,c = \\cos \\Delta \\theta\\,$. For each test case, we generate $\\,N\\,$ samples of the phase angle $\\,\\Delta \\theta\\,$ from its specified distribution (either a von Mises or a uniform distribution).\n- For a von Mises distribution with mean $\\,\\mu_\\theta=0\\,$ and concentration $\\,\\kappa_\\theta\\,$, samples are drawn from $\\,\\mathrm{VM}(0, \\kappa_\\theta)\\,$.\n- For a uniform distribution, samples are drawn from $\\,\\mathrm{Unif}[-\\pi, \\pi]\\,$.\n\nFrom these $\\,N\\,$ samples of $\\,\\Delta \\theta_i\\,$, we compute $\\,c_i = \\cos \\Delta \\theta_i\\,$. To work with a discrete representation of the probability distribution of $\\,c\\,$, denoted $\\,P(c)\\,$, we construct a normalized histogram. The interval $\\,[-1, 1]\\,$ is divided into $\\,M\\,$ equally spaced bins. The histogram yields a set of bin centers $\\,\\{c_j\\}_{j=1}^M\\,$ and their corresponding probabilities $\\,\\{p_j\\}_{j=1}^M\\,$. The probability $\\,p_j\\,$ is the fraction of the $\\,N\\,$ samples that fall into the $\\,j\\,$th bin. By construction, $\\,\\sum_{j=1}^M p_j = 1\\,$.\n\n**Step 2: Calculation of Histogram-Based Moments**\n\nThe core of the analysis relies on computing various expectation values (moments) using the discrete probability distribution $\\,\\{(c_j, p_j)\\}_{j=1}^M\\,$. These moments are functions of the exponent $\\,\\gamma\\,$. The soft-constraint weight for each bin center $\\,c_j\\,$ is defined as $\\,w_j(\\gamma) = \\max(0, c_j)^\\gamma\\,$. Note that for $\\,\\gamma=0\\,$, the convention $\\,0^0=1\\,$ is used, making $\\,w_j(0) = 1\\,$ for all $\\,j\\,$.\n\nUsing the discrete distribution, any expectation $\\,\\mathbb{E}[f(c)]\\,$ is approximated by the sum $\\,\\sum_{j=1}^M p_j f(c_j)\\,$. We compute the following moments required for the bias and variance formulas:\n- $\\,\\mathbb{E}[w] = \\sum_{j=1}^M p_j w_j(\\gamma)\\,$\n- $\\,\\mathbb{E}[wc] = \\sum_{j=1}^M p_j w_j(\\gamma) c_j\\,$\n- $\\,\\mathbb{E}[w^2] = \\sum_{j=1}^M p_j \\left(w_j(\\gamma)\\right)^2\\,$\n\nThe local energy $\\,L\\,$ is modeled as $\\,L = \\mu + \\kappa_L c + \\eta\\,$, where $\\,\\eta\\,$ is independent noise with $\\,\\mathbb{E}[\\eta]=0\\,$ and $\\,\\mathbb{E}[\\eta^2]=\\sigma^2\\,$. The moments involving $\\,L\\,$ are derived by leveraging the independence of $\\,\\eta\\,$ from $\\,c\\,$ (and thus from $\\,w\\,$):\n- $\\,\\mathbb{E}[wL] = \\mathbb{E}[w(\\mu + \\kappa_L c + \\eta)] = \\mu\\mathbb{E}[w] + \\kappa_L\\mathbb{E}[wc] + \\mathbb{E}[w]\\mathbb{E}[\\eta] = \\mu\\mathbb{E}[w] + \\kappa_L\\mathbb{E}[wc]\\,$.\n- $\\,\\mathbb{E}[w^2L] = \\mathbb{E}[w^2(\\mu + \\kappa_L c + \\eta)] = \\mu\\mathbb{E}[w^2] + \\kappa_L\\mathbb{E}[w^2c]\\,$, where $\\,\\mathbb{E}[w^2c] = \\sum_{j=1}^M p_j (w_j(\\gamma))^2 c_j\\,$.\n- $\\,\\mathbb{E}[w^2L^2] = \\mathbb{E}[w^2(\\mu + \\kappa_L c + \\eta)^2] = \\mathbb{E}[w^2((\\mu + \\kappa_L c)^2 + 2\\eta(\\mu+\\kappa_L c) + \\eta^2)]\\,$. Taking the expectation and using $\\,\\mathbb{E}[\\eta]=0\\,$ simplifies this to $\\,\\mathbb{E}[w^2((\\mu + \\kappa_L c)^2 + \\sigma^2)]\\,$. In our discrete formalism, this becomes $\\,\\mathbb{E}[w^2L^2] = \\sum_{j=1}^M p_j (w_j(\\gamma))^2 \\left[ (\\mu + \\kappa_L c_j)^2 + \\sigma^2 \\right]\\,$.\n\n**Step 3: Bias, Variance, and MSE Computation**\n\nWith the necessary moments calculated for a given $\\,\\gamma\\,$, we can now evaluate the bias and variance of the ratio estimator $\\,\\hat{\\mu}(\\gamma)\\,$.\n\nThe bias is given by:\n$$\n\\mathrm{bias}(\\gamma) = \\frac{\\mathbb{E}[wL]}{\\mathbb{E}[w]} - \\mu = \\kappa_L \\frac{\\mathbb{E}[wc]}{\\mathbb{E}[w]}\n$$\nThis term quantifies the systematic error introduced by the weighting scheme.\n\nThe variance of the estimator, $\\,\\mathrm{Var}(\\hat{\\mu}(\\gamma))\\,$, is approximated using the delta method for the ratio of two random variables $\\,A = \\frac{1}{N}\\sum w_i L_i\\,$ and $\\,B = \\frac{1}{N}\\sum w_i\\,$. First, we compute the variances and covariance of the underlying quantities $\\,w\\,$ and $\\,wL\\,$:\n- $\\,\\mathrm{Var}(w) = \\mathbb{E}[w^2] - (\\mathbb{E}[w])^2\\,$\n- $\\,\\mathrm{Var}(wL) = \\mathbb{E}[w^2L^2] - (\\mathbb{E}[wL])^2\\,$\n- $\\,\\mathrm{Cov}(wL, w) = \\mathbb{E}[w^2L] - \\mathbb{E}[wL]\\mathbb{E}[w]\\,$\n\nLetting $\\,a = \\mathbb{E}[wL]\\,$ and $\\,b = \\mathbb{E}[w]\\,$, the estimator variance is:\n$$\n\\mathrm{Var}(\\hat{\\mu}(\\gamma)) \\approx \\frac{1}{N} \\left[ \\frac{\\mathrm{Var}(wL)}{b^2} + \\frac{a^2}{b^4}\\mathrm{Var}(w) - \\frac{2a}{b^3}\\mathrm{Cov}(wL, w) \\right]\n$$\nThis term quantifies the statistical uncertainty (noise) of the estimator.\n\nFinally, the Mean-Squared Error (MSE) is the sum of the squared bias and the variance:\n$$\n\\mathrm{MSE}(\\gamma) = \\left[\\mathrm{bias}(\\gamma)\\right]^2 + \\mathrm{Var}(\\hat{\\mu}(\\gamma))\n$$\n\n**Step 4: Optimization of the Exponent $\\,\\gamma\\,$**\n\nFor each test case, the procedure is to compute $\\,\\mathrm{MSE}(\\gamma)\\,$ for every value of $\\,\\gamma\\,$ on the specified grid (from $\\,0.0\\,$ to $\\,6.0\\,$ in steps of $\\,0.25\\,$). We then identify the value $\\,\\gamma^\\star\\,$ that yields the minimum MSE. According to the problem's tie-breaking rule, if multiple $\\,\\gamma\\,$ values produce the same minimum MSE, the smallest of these values is chosen as $\\,\\gamma^\\star\\,$. This process is repeated for all four test cases, and the resulting optimal exponents are collected. The implementation leverages `numpy` for efficient vectorized operations on the histogram data.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import vonmises\n\ndef solve():\n    \"\"\"\n    Solves the AFQMC constrained-path approximation problem for four test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"N\": 200000, \"dist\": \"vonmises\", \"kappa_theta\": 8.0,\n            \"mu\": 1.5, \"kappa_L\": 0.8, \"sigma\": 0.7, \"M\": 200,\n            \"gamma_min\": 0.0, \"gamma_max\": 6.0, \"gamma_step\": 0.25\n        },\n        {\n            \"N\": 200000, \"dist\": \"uniform\", \"kappa_theta\": None,\n            \"mu\": 0.0, \"kappa_L\": 0.5, \"sigma\": 1.5, \"M\": 200,\n            \"gamma_min\": 0.0, \"gamma_max\": 6.0, \"gamma_step\": 0.25\n        },\n        {\n            \"N\": 200000, \"dist\": \"vonmises\", \"kappa_theta\": 1.5,\n            \"mu\": 2.0, \"kappa_L\": 0.3, \"sigma\": 3.0, \"M\": 200,\n            \"gamma_min\": 0.0, \"gamma_max\": 6.0, \"gamma_step\": 0.25\n        },\n        {\n            \"N\": 200000, \"dist\": \"uniform\", \"kappa_theta\": None,\n            \"mu\": -1.0, \"kappa_L\": -0.6, \"sigma\": 1.0, \"M\": 200,\n            \"gamma_min\": 0.0, \"gamma_max\": 6.0, \"gamma_step\": 0.25\n        },\n    ]\n\n    optimal_gammas = []\n\n    for case in test_cases:\n        N = case[\"N\"]\n        M = case[\"M\"]\n        mu = case[\"mu\"]\n        kappa_L = case[\"kappa_L\"]\n        sigma = case[\"sigma\"]\n\n        # Step 1: Generate samples and construct histogram\n        if case[\"dist\"] == \"vonmises\":\n            delta_theta = vonmises.rvs(kappa=case[\"kappa_theta\"], loc=0, size=N)\n        elif case[\"dist\"] == \"uniform\":\n            delta_theta = np.random.uniform(-np.pi, np.pi, size=N)\n        \n        c = np.cos(delta_theta)\n        \n        counts, bin_edges = np.histogram(c, bins=M, range=(-1.0, 1.0))\n        p_j = counts / N\n        c_j = (bin_edges[:-1] + bin_edges[1:]) / 2.0\n        \n        min_mse = np.inf\n        optimal_gamma = -1.0\n        \n        gamma_grid = np.arange(case[\"gamma_min\"], case[\"gamma_max\"] + case[\"gamma_step\"], case[\"gamma_step\"])\n\n        # Steps 2 & 3: Iterate through gamma grid, calculate MSE\n        for gamma in gamma_grid:\n            # Calculate weights w_j\n            w_j = np.maximum(0, c_j)**gamma\n\n            # Calculate moments\n            E_w = np.sum(p_j * w_j)\n            \n            # If E[w] is zero, this gamma is invalid, continue.\n            if E_w == 0:\n                continue\n\n            E_wc = np.sum(p_j * w_j * c_j)\n            \n            E_w2 = np.sum(p_j * w_j**2)\n            E_w2c = np.sum(p_j * w_j**2 * c_j)\n            \n            # Moments involving L\n            E_wL = mu * E_w + kappa_L * E_wc\n            E_w2L = mu * E_w2 + kappa_L * E_w2c\n            \n            Lj_part_sq = (mu + kappa_L * c_j)**2\n            E_w2L2 = np.sum(p_j * w_j**2 * (Lj_part_sq + sigma**2))\n\n            # Calculate bias\n            bias_gamma = kappa_L * (E_wc / E_w)\n            \n            # Calculate variances and covariance\n            Var_w = E_w2 - E_w**2\n            Var_wL = E_w2L2 - E_wL**2\n            Cov_wL_w = E_w2L - E_wL * E_w\n\n            # Calculate variance of the estimator using delta method\n            a = E_wL\n            b = E_w\n            \n            # To avoid division by zero if b (E[w]) is extremely small\n            if b < 1e-15: continue\n            \n            var_mu_hat_term1 = Var_wL / b**2\n            var_mu_hat_term2 = (a**2 / b**4) * Var_w\n            var_mu_hat_term3 = (2 * a / b**3) * Cov_wL_w\n            \n            var_mu_hat = (1/N) * (var_mu_hat_term1 + var_mu_hat_term2 - var_mu_hat_term3)\n\n            # Calculate MSE\n            mse = bias_gamma**2 + var_mu_hat\n            \n            # Step 4: Find optimal gamma\n            if mse < min_mse:\n                min_mse = mse\n                optimal_gamma = gamma\n\n        optimal_gammas.append(optimal_gamma)\n\n    # Format the final output\n    formatted_results = [f\"{g:.2f}\" for g in optimal_gammas]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3551580"}, {"introduction": "Beyond refining the standard constraint, researchers have developed alternative strategies to control the phase problem. This practice introduces an advanced technique that uses an auxiliary 'imaginary chemical potential' as a mathematical knob to tame severe phase fluctuations during the simulation. The core idea is to intentionally bias the sampling process with a parameter $\\lambda$ to make the phase problem more manageable, and then systematically remove this bias by extrapolating the results to $\\lambda \\to 0$. By implementing this method on a model with a known exact answer, you will directly compare its accuracy against the standard constrained-phase approach and gain insight into how creative uses of importance sampling can lead to more powerful algorithms [@problem_id:3551602].", "problem": "Consider a toy model designed to isolate and study the effect of complex phases and constrained-path approximations that are commonly encountered in Auxiliary-Field Quantum Monte Carlo (AFQMC). Let the configuration variable be a real scalar $x \\in \\mathbb{R}$ with a real Gaussian baseline weight $P(x) \\propto \\exp\\!\\left(-\\dfrac{x^{2}}{2 \\sigma^{2}}\\right)$. A complex phase arises from a linear “determinant phase” factor $\\exp\\!\\left(i \\kappa x\\right)$, where $\\kappa \\in \\mathbb{R}$ models the phase severity. The observable is $O(x) = x^{2}$. The exact complex-phase average of $O$ is\n$$\n\\langle O \\rangle_{\\text{exact}} \\equiv \\dfrac{\\int_{-\\infty}^{\\infty} dx \\, \\exp\\!\\left(-\\dfrac{x^{2}}{2 \\sigma^{2}}\\right) \\exp\\!\\left(i \\kappa x\\right) \\, x^{2}}{\\int_{-\\infty}^{\\infty} dx \\, \\exp\\!\\left(-\\dfrac{x^{2}}{2 \\sigma^{2}}\\right) \\exp\\!\\left(i \\kappa x\\right)} \\, .\n$$\nThis mimics the typical complex-weight average in computational nuclear physics when sampling auxiliary fields with a complex determinant, and it is analytically tractable.\n\nA constrained-phase (phaseless) approximation replaces the complex phase factor by a projection using the real cosine of the phase, truncated to enforce a nonnegative weight. Specifically, define the standard constrained-phase estimate\n$$\n\\widehat{O}_{\\text{CP}} \\equiv \\dfrac{\\mathbb{E}_{x \\sim P}\\!\\left[\\max\\!\\left(0, \\cos(\\kappa x)\\right) \\, x^{2}\\right]}{\\mathbb{E}_{x \\sim P}\\!\\left[\\max\\!\\left(0, \\cos(\\kappa x)\\right)\\right]} \\, ,\n$$\nwhere $\\mathbb{E}_{x \\sim P}[\\cdot]$ denotes the expectation value under $P(x)$.\n\nTo tame phase fluctuations, introduce an auxiliary imaginary chemical potential $i \\mu_{I} N$ with “number” $N(x) = x$ and $\\mu_{I} \\in \\mathbb{R}$. In this toy model, this corresponds to two coupled actions:\n- A change of sampling distribution from $P(x)$ to a positive, exponentially tilted density\n$$\nq_{\\lambda}(x) \\propto P(x) \\, e^{\\lambda x} \\, , \\quad \\lambda \\equiv \\mu_{I} \\, ,\n$$\nwhich is a normal distribution with mean $\\sigma^{2} \\lambda$ and variance $\\sigma^{2}$.\n- A rotation of the complex phase by subtracting the trial phase $\\lambda x$, yielding a residual phase $(\\kappa - \\lambda) x$. The constrained-phase projection acts on this residual phase via $\\max\\!\\left(0, \\cos\\!\\left((\\kappa - \\lambda) x\\right)\\right)$.\n\nUnder importance sampling from $q_{\\lambda}(x)$, an unbiased ratio estimator for the $\\lambda$-dependent constrained observable is\n$$\n\\widehat{O}_{\\lambda} \\equiv \\dfrac{\\mathbb{E}_{x \\sim q_{\\lambda}}\\!\\left[r_{\\lambda}(x)\\, \\max\\!\\left(0, \\cos\\!\\left((\\kappa - \\lambda) x\\right)\\right) \\, x^{2}\\right]}{\\mathbb{E}_{x \\sim q_{\\lambda}}\\!\\left[r_{\\lambda}(x)\\, \\max\\!\\left(0, \\cos\\!\\left((\\kappa - \\lambda) x\\right)\\right)\\right]} \\, ,\n$$\nwhere the Radon–Nikodym derivative (reweighting factor) $r_{\\lambda}(x)$ satisfies\n$$\nr_{\\lambda}(x) = \\dfrac{P(x)}{q_{\\lambda}(x)} = \\exp\\!\\left(-\\lambda x + \\dfrac{1}{2} \\sigma^{2} \\lambda^{2}\\right) \\, .\n$$\nBecause the constant $\\exp\\!\\left(\\dfrac{1}{2} \\sigma^{2} \\lambda^{2}\\right)$ cancels between numerator and denominator in the ratio, one may equivalently implement $r_{\\lambda}(x) = \\exp\\!\\left(-\\lambda x\\right)$ in both numerator and denominator.\n\nBy evaluating $\\widehat{O}_{\\lambda}$ at several strictly positive $\\lambda$ values and fitting a low-order polynomial in $\\lambda$ to $\\widehat{O}_{\\lambda}$, one can extrapolate $\\lambda \\to 0$ to remove the auxiliary parameter:\n$$\n\\widehat{O}_{\\text{aux-extrap}} \\equiv \\lim_{\\lambda \\to 0^{+}} \\widehat{O}_{\\lambda} \\approx \\text{PolyFit}\\left(\\left\\{\\left(\\lambda_{j}, \\widehat{O}_{\\lambda_{j}}\\right)\\right\\}_{j=1}^{J}\\right)\\Big|_{\\lambda = 0} \\, .\n$$\nThis is to be compared against the standard constrained-phase $\\widehat{O}_{\\text{CP}}$ at $\\lambda = 0$ and the known exact value $\\langle O \\rangle_{\\text{exact}}$.\n\nTasks:\n1. Starting from Gaussian integration and importance sampling fundamentals, implement:\n   - The exact analytic value $\\langle O \\rangle_{\\text{exact}}$ for the specified model.\n   - The standard constrained-phase estimator $\\widehat{O}_{\\text{CP}}$ under baseline sampling $P(x)$.\n   - The auxiliary-parameter constrained estimator $\\widehat{O}_{\\lambda}$ for a list of strictly positive $\\lambda$ values, using sampling from $q_{\\lambda}(x)$ with reweighting $r_{\\lambda}(x)$ and the projected phase $\\max\\!\\left(0, \\cos\\!\\left((\\kappa - \\lambda) x\\right)\\right)$.\n   - A polynomial least-squares fit in $\\lambda$ of degree $d$ to $\\left\\{\\left(\\lambda_{j}, \\widehat{O}_{\\lambda_{j}}\\right)\\right\\}$, evaluated at $\\lambda = 0$ to produce $\\widehat{O}_{\\text{aux-extrap}}$.\n2. For each test case, compute the absolute errors $\\left|\\widehat{O}_{\\text{CP}} - \\langle O \\rangle_{\\text{exact}}\\right|$ and $\\left|\\widehat{O}_{\\text{aux-extrap}} - \\langle O \\rangle_{\\text{exact}}\\right|$.\n\nUse the following foundational base and modeling details:\n- Use the baseline $P(x) \\propto \\exp\\!\\left(-\\dfrac{x^{2}}{2 \\sigma^{2}}\\right)$, with $x$ distributed normally with mean $0$ and variance $\\sigma^{2}$.\n- Use the complex phase factor $\\exp\\!\\left(i \\kappa x\\right)$ and the observable $O(x) = x^{2}$.\n- Derive the exact analytic value by completing the square or using Gaussian moment formulas. The final closed form must be implemented in code derived from first principles.\n- The constrained-phase projection must use the truncation $\\max\\!\\left(0, \\cos(\\cdot)\\right)$.\n- For auxiliary sampling, use $q_{\\lambda}(x) \\propto P(x) \\, e^{\\lambda x}$, i.e., $x \\sim \\mathcal{N}\\!\\left(\\sigma^{2} \\lambda, \\sigma^{2}\\right)$, and the reweight factor $r_{\\lambda}(x) = \\exp\\!\\left(-\\lambda x\\right)$ (the constant cancels in the ratio).\n- Use a fixed pseudorandom seed $12345$ for reproducibility.\n- All outputs are dimensionless numbers; no physical units are involved.\n\nTest suite:\n- Case A (happy path): $\\sigma = 1.0$, $\\kappa = 1.0$, total baseline samples $M_{\\text{base}} = 200000$, auxiliary list $\\Lambda = [0.4, 0.8, 1.2]$, polynomial degree $d = 2$.\n- Case B (stronger oscillations): $\\sigma = 1.0$, $\\kappa = 2.5$, $M_{\\text{base}} = 300000$, $\\Lambda = [0.8, 1.2, 1.6, 2.0]$, $d = 2$.\n- Case C (edge, narrower Gaussian and strong phase): $\\sigma = 0.7$, $\\kappa = 3.0$, $M_{\\text{base}} = 400000$, $\\Lambda = [1.0, 1.5, 2.0, 2.5]$, $d = 2$.\n\nSampling details:\n- For each case, compute $\\widehat{O}_{\\text{CP}}$ using $M_{\\text{base}}$ samples drawn from $P(x)$.\n- For the auxiliary method in each case, allocate $M_{\\text{aux}} = M_{\\text{base}}$ total samples across the list $\\Lambda$ evenly, i.e., use $\\left\\lfloor \\dfrac{M_{\\text{base}}}{|\\Lambda|} \\right\\rfloor$ samples at each $\\lambda \\in \\Lambda$.\n\nRequired final output format:\n- Your program must produce a single line containing a list of results, one per test case, in the order A, B, C.\n- Each result must be a list of two floats: $\\left[\\left|\\widehat{O}_{\\text{CP}} - \\langle O \\rangle_{\\text{exact}}\\right|, \\left|\\widehat{O}_{\\text{aux-extrap}} - \\langle O \\rangle_{\\text{exact}}\\right|\\right]$.\n- The final printed line must be a single Python-style list, e.g., $\\left[\\left[a_{1}, b_{1}\\right], \\left[a_{2}, b_{2}\\right], \\left[a_{3}, b_{3}\\right]\\right]$, with no extra text.\n\nAngle measure:\n- All angles are implicitly in radians.\n\nNo physical units are involved, so no unit conversion is required. The program must be self-contained and require no inputs.", "solution": "We start from the definition of ensemble averages with complex weights. For a real Gaussian baseline density $P(x) \\propto \\exp\\!\\left(-\\dfrac{x^{2}}{2 \\sigma^{2}}\\right)$, a complex phase $\\exp\\!\\left(i \\kappa x\\right)$, and an observable $O(x) = x^{2}$, the exact complex average is\n$$\n\\langle O \\rangle_{\\text{exact}} = \\dfrac{\\int_{-\\infty}^{\\infty} dx \\, \\exp\\!\\left(-\\dfrac{x^{2}}{2 \\sigma^{2}}\\right) \\exp\\!\\left(i \\kappa x\\right) \\, x^{2}}{\\int_{-\\infty}^{\\infty} dx \\, \\exp\\!\\left(-\\dfrac{x^{2}}{2 \\sigma^{2}}\\right) \\exp\\!\\left(i \\kappa x\\right)} \\, .\n$$\nTo obtain a closed form, complete the square in the exponent:\n$$\n-\\dfrac{x^{2}}{2 \\sigma^{2}} + i \\kappa x = -\\dfrac{1}{2 \\sigma^{2}}\\left(x^{2} - 2 i \\kappa \\sigma^{2} x\\right) = -\\dfrac{1}{2 \\sigma^{2}}\\left(x - i \\kappa \\sigma^{2}\\right)^{2} - \\dfrac{1}{2} \\sigma^{2} \\kappa^{2} \\, .\n$$\nThus\n$$\n\\int_{-\\infty}^{\\infty} dx \\, \\exp\\!\\left(-\\dfrac{x^{2}}{2 \\sigma^{2}}\\right) \\exp\\!\\left(i \\kappa x\\right) = \\sqrt{2 \\pi} \\, \\sigma \\, \\exp\\!\\left(-\\dfrac{1}{2} \\sigma^{2} \\kappa^{2}\\right) \\, ,\n$$\nand, taking $x$ under the shifted Gaussian with mean $\\mu = i \\kappa \\sigma^{2}$ and variance $\\sigma^{2}$, the second moment is\n$$\n\\int_{-\\infty}^{\\infty} dx \\, \\exp\\!\\left(-\\dfrac{x^{2}}{2 \\sigma^{2}}\\right) \\exp\\!\\left(i \\kappa x\\right) \\, x^{2} = \\sqrt{2 \\pi} \\, \\sigma \\, \\exp\\!\\left(-\\dfrac{1}{2} \\sigma^{2} \\kappa^{2}\\right) \\left(\\sigma^{2} + \\mu^{2}\\right) \\, .\n$$\nSubstituting $\\mu = i \\kappa \\sigma^{2}$ gives $\\mu^{2} = - \\kappa^{2} \\sigma^{4}$, hence\n$$\n\\langle O \\rangle_{\\text{exact}} = \\dfrac{\\sigma^{2} - \\kappa^{2} \\sigma^{4}}{1} = \\sigma^{2} - \\kappa^{2} \\sigma^{4} \\, .\n$$\n\nConstrained-phase approximation. In constrained-path (phaseless) AFQMC, a complex overlap phase increment $\\Delta \\theta$ is controlled by projecting with $\\max\\!\\left(0, \\cos \\Delta \\theta\\right)$ to maintain nonnegative weights and suppress phase instability. In this toy model, the phase is $\\theta(x) = \\kappa x$, so the standard constrained-phase estimator is defined as\n$$\n\\widehat{O}_{\\text{CP}} = \\dfrac{\\mathbb{E}_{x \\sim P}\\!\\left[\\max\\!\\left(0, \\cos(\\kappa x)\\right) \\, x^{2}\\right]}{\\mathbb{E}_{x \\sim P}\\!\\left[\\max\\!\\left(0, \\cos(\\kappa x)\\right)\\right]} \\, ,\n$$\nwith $x \\sim \\mathcal{N}\\!\\left(0, \\sigma^{2}\\right)$.\n\nAuxiliary imaginary chemical potential. To tame phase fluctuations, one may introduce an auxiliary imaginary chemical potential $i \\mu_{I} N$ with $N(x) = x$ and $\\mu_{I} = \\lambda$. In the Euclidean-weight picture, this motivates sampling from an exponentially tilted distribution\n$$\nq_{\\lambda}(x) \\propto P(x) \\, e^{\\lambda x} \\, .\n$$\nSince $P$ is Gaussian, $q_{\\lambda}$ is also Gaussian with mean $\\sigma^{2} \\lambda$ and variance $\\sigma^{2}$. Simultaneously, we rotate the phase by a trial phase $\\lambda x$, so the residual phase is $\\left(\\kappa - \\lambda\\right) x$; the constrained-phase projection then uses $\\max\\!\\left(0, \\cos\\!\\left((\\kappa - \\lambda) x\\right)\\right)$.\n\nImportance sampling and reweighting. For a function $g(x)$,\n$$\n\\mathbb{E}_{x \\sim P}[g(x)] = \\mathbb{E}_{x \\sim q_{\\lambda}}\\!\\left[\\dfrac{P(x)}{q_{\\lambda}(x)} \\, g(x)\\right] \\, ,\n$$\nwith Radon–Nikodym derivative\n$$\n\\dfrac{P(x)}{q_{\\lambda}(x)} = \\exp\\!\\left(-\\lambda x + \\dfrac{1}{2} \\sigma^{2} \\lambda^{2}\\right) \\, .\n$$\nBecause the constrained-phase estimate is a ratio of expectations, the constant factor $\\exp\\!\\left(\\dfrac{1}{2} \\sigma^{2} \\lambda^{2}\\right)$ cancels; it is numerically advantageous to use\n$$\nr_{\\lambda}(x) \\equiv \\exp\\!\\left(-\\lambda x\\right) \\, .\n$$\nDefine the $\\lambda$-dependent constrained estimator as\n$$\n\\widehat{O}_{\\lambda} = \\dfrac{\\mathbb{E}_{x \\sim q_{\\lambda}}\\!\\left[r_{\\lambda}(x) \\, \\max\\!\\left(0, \\cos\\!\\left((\\kappa - \\lambda) x\\right)\\right) \\, x^{2}\\right]}{\\mathbb{E}_{x \\sim q_{\\lambda}}\\!\\left[r_{\\lambda}(x) \\, \\max\\!\\left(0, \\cos\\!\\left((\\kappa - \\lambda) x\\right)\\right)\\right]} \\, .\n$$\nNote that at $\\lambda = 0$, $q_{0} = P$ and $r_{0}(x) = 1$, so $\\widehat{O}_{0} = \\widehat{O}_{\\text{CP}}$.\n\nExtrapolation $\\lambda \\to 0$. Evaluate $\\widehat{O}_{\\lambda_{j}}$ at several strictly positive $\\lambda_{j}$ values and perform a least-squares polynomial fit of degree $d$:\n$$\n\\widehat{O}_{\\lambda} \\approx \\sum_{m=0}^{d} c_{m} \\, \\lambda^{m} \\, .\n$$\nThen the extrapolated value at zero auxiliary parameter is\n$$\n\\widehat{O}_{\\text{aux-extrap}} = \\left.\\sum_{m=0}^{d} c_{m} \\, \\lambda^{m}\\right|_{\\lambda = 0} = c_{0} \\, .\n$$\n\nAlgorithmic steps for each test case:\n1. Fix $\\sigma$, $\\kappa$, and $M_{\\text{base}}$.\n2. Compute $\\langle O \\rangle_{\\text{exact}} = \\sigma^{2} - \\kappa^{2} \\sigma^{4}$.\n3. Draw $M_{\\text{base}}$ samples $x$ from $\\mathcal{N}\\!\\left(0, \\sigma^{2}\\right)$ and compute $\\widehat{O}_{\\text{CP}}$ using the ratio-of-means formula with weights $w(x) = \\max\\!\\left(0, \\cos(\\kappa x)\\right)$.\n4. For the auxiliary method, distribute $M_{\\text{base}}$ evenly across the list $\\Lambda = \\{\\lambda_{j}\\}$, i.e., $M_{\\lambda} = \\left\\lfloor \\dfrac{M_{\\text{base}}}{|\\Lambda|} \\right\\rfloor$. For each $\\lambda \\in \\Lambda$, draw $M_{\\lambda}$ samples from $\\mathcal{N}\\!\\left(\\sigma^{2} \\lambda, \\sigma^{2}\\right)$, compute weights\n$$\nW_{\\lambda}(x) = r_{\\lambda}(x)\\, \\max\\!\\left(0, \\cos\\!\\left((\\kappa - \\lambda) x\\right)\\right) \\, , \\quad r_{\\lambda}(x) = e^{-\\lambda x} \\, ,\n$$\nand form the ratio estimator $\\widehat{O}_{\\lambda}$.\n5. Fit a polynomial in $\\lambda$ of degree $d$ to $\\left\\{\\left(\\lambda_{j}, \\widehat{O}_{\\lambda_{j}}\\right)\\right\\}$ and evaluate at $\\lambda = 0$ to obtain $\\widehat{O}_{\\text{aux-extrap}}$.\n6. Report the absolute errors $\\left|\\widehat{O}_{\\text{CP}} - \\langle O \\rangle_{\\text{exact}}\\right|$ and $\\left|\\widehat{O}_{\\text{aux-extrap}} - \\langle O \\rangle_{\\text{exact}}\\right|$.\n\nTest suite specification:\n- Case A: $\\sigma = 1.0$, $\\kappa = 1.0$, $M_{\\text{base}} = 200000$, $\\Lambda = [0.4, 0.8, 1.2]$, $d = 2$.\n- Case B: $\\sigma = 1.0$, $\\kappa = 2.5$, $M_{\\text{base}} = 300000$, $\\Lambda = [0.8, 1.2, 1.6, 2.0]$, $d = 2$.\n- Case C: $\\sigma = 0.7$, $\\kappa = 3.0$, $M_{\\text{base}} = 400000$, $\\Lambda = [1.0, 1.5, 2.0, 2.5]$, $d = 2$.\n\nAll random sampling must use a fixed seed $12345$ for reproducibility. The final program must print a single line formatted as $\\left[\\left[a_{1}, b_{1}\\right], \\left[a_{2}, b_{2}\\right], \\left[a_{3}, b_{3}\\right]\\right]$, where $a_{j} = \\left|\\widehat{O}_{\\text{CP}} - \\langle O \\rangle_{\\text{exact}}\\right|$ and $b_{j} = \\left|\\widehat{O}_{\\text{aux-extrap}} - \\langle O \\rangle_{\\text{exact}}\\right|$ for cases $A$, $B$, and $C$, respectively.\n\nThis construction is scientifically realistic: it captures the essence of constrained-phase control via cosine projection, the use of an auxiliary imaginary chemical potential to reshape sampling and rotate phases, and the extrapolation to remove the auxiliary parameter, all within a mathematically controlled Gaussian model that allows an exact benchmark.", "answer": "```python\nimport numpy as np\n\ndef exact_mean_x2(sigma, kappa):\n    # Exact value derived from complex Gaussian integral:\n    # <x^2> = sigma^2 - kappa^2 * sigma^4\n    return sigma**2 - (kappa**2) * (sigma**4)\n\ndef standard_constrained_phase_estimate(sigma, kappa, n_samples, rng):\n    # Sample from baseline P(x) ~ N(0, sigma^2)\n    x = rng.normal(loc=0.0, scale=sigma, size=n_samples)\n    w = np.cos(kappa * x)\n    w_pos = np.maximum(0.0, w)\n    denom = np.sum(w_pos)\n    if denom == 0.0:\n        return np.nan\n    num = np.sum(w_pos * (x**2))\n    return num / denom\n\ndef auxiliary_lambda_estimates(sigma, kappa, lambdas, n_total, rng):\n    # Compute O_lambda for each lambda in lambdas using sampling from q_lambda and reweight r_lambda\n    # Distribute samples evenly across lambdas\n    n_per = max(1, n_total // len(lambdas))\n    estimates = []\n    for lam in lambdas:\n        # q_lambda is Normal(mean=sigma^2 * lam, var=sigma^2)\n        mean = (sigma**2) * lam\n        x = rng.normal(loc=mean, scale=sigma, size=n_per)\n        # Reweight factor r_lambda(x) = exp(-lam * x); constant cancels in ratio\n        r = np.exp(-lam * x)\n        angles = (kappa - lam) * x\n        w_proj = np.maximum(0.0, np.cos(angles))\n        weights = r * w_proj\n        denom = np.sum(weights)\n        if denom == 0.0:\n            estimates.append(np.nan)\n        else:\n            num = np.sum(weights * (x**2))\n            estimates.append(num / denom)\n    return np.array(estimates, dtype=np.float64)\n\ndef auxiliary_extrapolated_estimate(sigma, kappa, lambdas, n_total, poly_deg, rng):\n    # Compute O_lambda at lambdas and fit polynomial of degree poly_deg in lambda, evaluate at 0\n    y = auxiliary_lambda_estimates(sigma, kappa, lambdas, n_total, rng)\n    x = np.array(lambdas, dtype=np.float64)\n    # Handle any NaNs by simple fallback: remove them\n    mask = np.isfinite(y)\n    if mask.sum() <= poly_deg:\n        # Not enough points to fit; return NaN\n        return np.nan\n    coeffs = np.polyfit(x[mask], y[mask], deg=poly_deg)\n    # Evaluate at lambda=0: equals constant term coeffs[-1]\n    return float(np.polyval(coeffs, 0.0))\n\ndef run_case(sigma, kappa, m_base, lambdas, poly_deg, rng):\n    exact = exact_mean_x2(sigma, kappa)\n    cp_est = standard_constrained_phase_estimate(sigma, kappa, m_base, rng)\n    aux_extrap = auxiliary_extrapolated_estimate(sigma, kappa, lambdas, m_base, poly_deg, rng)\n    err_cp = abs(cp_est - exact)\n    err_aux = abs(aux_extrap - exact)\n    return err_cp, err_aux\n\ndef solve():\n    rng = np.random.default_rng(12345)\n\n    # Define test cases: (sigma, kappa, M_base, lambdas, poly_degree)\n    test_cases = [\n        (1.0, 1.0, 200000, [0.4, 0.8, 1.2], 2),\n        (1.0, 2.5, 300000, [0.8, 1.2, 1.6, 2.0], 2),\n        (0.7, 3.0, 400000, [1.0, 1.5, 2.0, 2.5], 2),\n    ]\n\n    results = []\n    for sigma, kappa, m_base, lambdas, poly_deg in test_cases:\n        err_cp, err_aux = run_case(sigma, kappa, m_base, lambdas, poly_deg, rng)\n        results.append([err_cp, err_aux])\n\n    # Print single line in exact required format\n    print(f\"[{','.join('[' + ','.join(str(v) for v in pair) + ']' for pair in results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3551602"}]}