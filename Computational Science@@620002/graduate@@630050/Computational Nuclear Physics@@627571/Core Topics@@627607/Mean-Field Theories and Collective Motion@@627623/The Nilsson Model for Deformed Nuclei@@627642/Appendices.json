{"hands_on_practices": [{"introduction": "The Nilsson model describes nuclear deformation through a parameter, $\\varepsilon_2$, within its anisotropic potential, while the collective model uses a geometric parameter, $\\beta_2$, to describe the shape of the nucleus. To ensure these models provide a consistent physical picture, a clear mathematical relationship between these two parameters must be established. This foundational exercise guides you through a first-principles derivation to connect these two descriptions by equating their intrinsic quadrupole moments, thereby solidifying the physical meaning of the parameters used in the Nilsson model [@problem_id:3604825].", "problem": "In the Nilsson model for deformed nuclei, an axially symmetric quadrupole deformation is introduced through an anisotropic harmonic-oscillator potential. Consider two descriptions of a nucleus with the same particle number $A$ and the same size scale $R_0$: \n\n1. A uniform sharp-surface droplet with an axially symmetric quadrupole-deformed surface, described in the small-deformation limit by $R(\\theta) = R_0 \\left[1 + \\beta_2 Y_{20}(\\theta)\\right]$ with $Y_{20}(\\theta) = \\sqrt{\\frac{5}{16\\pi}}\\left(3\\cos^2\\theta - 1\\right)$.\n2. A volume-conserving anisotropic harmonic-oscillator density (representing the Nilsson mean-field), with axial frequencies $\\omega_{\\perp}$ and $\\omega_z$ satisfying, to linear order in a small dimensionless Nilsson deformation parameter $\\varepsilon_2$, the relations $\\omega_{\\perp} = \\omega_0\\left(1 + \\frac{\\varepsilon_2}{3}\\right)$ and $\\omega_z = \\omega_0\\left(1 - \\frac{2\\varepsilon_2}{3}\\right)$.\n\nUsing first principles only, derive the linear relation between the Nilsson deformation parameter $\\varepsilon_2$ and the collective deformation parameter $\\beta_2$ by equating the intrinsic mass quadrupole moments of the two descriptions in the small-deformation limit. Work in the following framework:\n\n- Define the intrinsic mass quadrupole as $Q_0^{(m)} = \\int \\rho(\\mathbf{r})\\left(2 z^2 - x^2 - y^2\\right)\\,d^3 r$.\n- For the uniform droplet, use only basic geometric facts about uniform ellipsoids and the small-deformation surface $R(\\theta)$.\n- For the harmonic-oscillator density, use the fact that the density in the semiclassical Thomas–Fermi (TF) approximation is a spherically symmetric function of the scaled coordinates $u_x = \\sqrt{\\omega_{\\perp}}\\,x$, $u_y = \\sqrt{\\omega_{\\perp}}\\,y$, $u_z = \\sqrt{\\omega_z}\\,z$, up to a Jacobian, and that the spherical-limit mean-square radius of a uniform sphere of radius $R_0$ is $\\langle r^2\\rangle = \\frac{3}{5} R_0^2$.\n- Assume axial symmetry and volume conservation to linear order.\n\nShow all steps from these principles to a closed-form relation $\\varepsilon_2 = C\\,\\beta_2$ with a constant $C$ that you must determine exactly. Express your final answer as a single exact analytic expression for $\\varepsilon_2$ in terms of $\\beta_2$. No numerical rounding is required, and no units should be included in the final expression.", "solution": "To derive the relationship between $\\varepsilon_2$ and $\\beta_2$, we will calculate the intrinsic mass quadrupole moment, $Q_0^{(m)}$, for each of the two nuclear descriptions and then equate them. The definition given is:\n$$\nQ_0^{(m)} = \\int \\rho(\\mathbf{r})\\left(2 z^2 - x^2 - y^2\\right)\\,d^3 r\n$$\nFor an axially symmetric system, $x^2+y^2=r_\\perp^2$, so the integrand is $(2z^2 - r_\\perp^2)$. In spherical coordinates, $z = r\\cos\\theta$ and $r_\\perp = r\\sin\\theta$. The term becomes $2(r\\cos\\theta)^2 - (r\\sin\\theta)^2 = r^2(2\\cos^2\\theta - \\sin^2\\theta) = r^2(3\\cos^2\\theta-1)$. This is proportional to the spherical harmonic $Y_{20}(\\theta)$:\n$$\n3\\cos^2\\theta - 1 = \\sqrt{\\frac{16\\pi}{5}} Y_{20}(\\theta)\n$$\nTherefore, the quadrupole moment can be expressed as:\n$$\nQ_0^{(m)} = \\sqrt{\\frac{16\\pi}{5}} \\int \\rho(\\mathbf{r}) r^2 Y_{20}(\\theta) \\,d^3 r\n$$\n\n**1. Quadrupole Moment of the Uniform Droplet ($Q_{0, \\text{droplet}}^{(m)}$)**\n\nFor the uniform droplet, the density $\\rho(\\mathbf{r})$ is a constant $\\rho_0$ inside the volume defined by the surface $R(\\theta) = R_0 [1 + \\beta_2 Y_{20}(\\theta)]$ and zero outside. The element of volume in spherical coordinates is $d^3r = r^2 \\sin\\theta \\,dr\\,d\\theta\\,d\\phi$.\n$$\nQ_{0, \\text{droplet}}^{(m)} = \\rho_0 \\sqrt{\\frac{16\\pi}{5}} \\int_0^{2\\pi} d\\phi \\int_0^\\pi \\sin\\theta \\, Y_{20}(\\theta) \\left( \\int_0^{R(\\theta)} r^4 \\,dr \\right) d\\theta\n$$\nThe integral over $r$ gives $\\frac{1}{5}[R(\\theta)]^5$. The integral over $\\phi$ gives $2\\pi$.\n$$\nQ_{0, \\text{droplet}}^{(m)} = \\frac{2\\pi\\rho_0}{5} \\sqrt{\\frac{16\\pi}{5}} \\int_0^\\pi [R(\\theta)]^5 Y_{20}(\\theta) \\sin\\theta \\,d\\theta\n$$\nWe are in the small-deformation limit ($\\beta_2 \\ll 1$), so we expand $[R(\\theta)]^5$:\n$$\n[R(\\theta)]^5 = R_0^5 [1 + \\beta_2 Y_{20}(\\theta)]^5 \\approx R_0^5 [1 + 5\\beta_2 Y_{20}(\\theta) + O(\\beta_2^2)]\n$$\nSubstituting this into the integral:\n$$\nQ_{0, \\text{droplet}}^{(m)} \\approx \\frac{2\\pi\\rho_0 R_0^5}{5} \\sqrt{\\frac{16\\pi}{5}} \\int_0^\\pi [1 + 5\\beta_2 Y_{20}(\\theta)] Y_{20}(\\theta) \\sin\\theta \\,d\\theta\n$$\nThe integral separates into two parts:\n$$\n\\int_0^\\pi Y_{20}(\\theta) \\sin\\theta \\,d\\theta + 5\\beta_2 \\int_0^\\pi [Y_{20}(\\theta)]^2 \\sin\\theta \\,d\\theta\n$$\nThe first integral is zero due to the orthogonality of Legendre polynomials ($P_2$ and $P_0$, since $Y_{20} \\propto P_2$ and $1 \\propto P_0$). The second integral is related to the normalization of spherical harmonics: $\\int_0^{2\\pi}d\\phi \\int_0^\\pi [Y_{lm}(\\theta,\\phi)]^2 \\sin\\theta \\, d\\theta = 1$. Since $Y_{20}$ is independent of $\\phi$, this gives $2\\pi \\int_0^\\pi [Y_{20}(\\theta)]^2 \\sin\\theta\\,d\\theta = 1$, so the integral is $1/(2\\pi)$.\n$$\nQ_{0, \\text{droplet}}^{(m)} \\approx \\frac{2\\pi\\rho_0 R_0^5}{5} \\sqrt{\\frac{16\\pi}{5}} \\left( 5\\beta_2 \\cdot \\frac{1}{2\\pi} \\right) = \\rho_0 R_0^5 \\beta_2 \\sqrt{\\frac{16\\pi}{5}} = 4\\rho_0 R_0^5 \\beta_2 \\sqrt{\\frac{\\pi}{5}}\n$$\nThe total mass of the nucleus is $M = \\rho_0 V_0 = \\rho_0 \\frac{4\\pi}{3}R_0^3$. We can express $\\rho_0$ as $\\rho_0 = \\frac{3M}{4\\pi R_0^3}$.\n$$\nQ_{0, \\text{droplet}}^{(m)} = 4 \\left( \\frac{3M}{4\\pi R_0^3} \\right) R_0^5 \\beta_2 \\sqrt{\\frac{\\pi}{5}} = \\frac{3M R_0^2}{\\pi} \\beta_2 \\sqrt{\\frac{\\pi}{5}} = \\frac{3}{\\sqrt{5\\pi}} M R_0^2 \\beta_2\n$$\n\n**2. Quadrupole Moment of the Anisotropic Harmonic Oscillator ($Q_{0, \\text{HO}}^{(m)}$)**\n\nThe problem states that the density $\\rho(\\mathbf{r})$ is a spherically symmetric function of the scaled coordinates $u_x = \\sqrt{\\omega_{\\perp}}x$, $u_y = \\sqrt{\\omega_{\\perp}}y$, $u_z = \\sqrt{\\omega_{z}}z$. Let's denote this by $\\rho(\\mathbf{r}) = g(u_x^2+u_y^2+u_z^2) = g(\\omega_\\perp r_\\perp^2 + \\omega_z z^2)$.\nThe quadrupole moment is $Q_{0, \\text{HO}}^{(m)} = M (2\\langle z^2 \\rangle - \\langle r_\\perp^2 \\rangle) = M(2\\langle z^2 \\rangle - 2\\langle x^2 \\rangle)$, where $\\langle \\cdot \\rangle$ denotes the average over the density distribution.\nLet's compute the mean square values:\n$$\nM\\langle z^2 \\rangle = \\int \\rho(\\mathbf{r}) z^2 \\,d^3r \\quad \\text{and} \\quad M\\langle x^2 \\rangle = \\int \\rho(\\mathbf{r}) x^2 \\,d^3r\n$$\nWe perform a change of variables to the scaled coordinates $\\mathbf{u}$. The Jacobian is $d^3r = (\\omega_\\perp \\sqrt{\\omega_z})^{-1} d^3u$. The volume conservation condition $\\omega_\\perp^2 \\omega_z = \\omega_0^3$ (valid to first order in $\\varepsilon_2$) gives $\\omega_\\perp \\sqrt{\\omega_z} = \\omega_0^{3/2}$.\n$$\nM\\langle z^2 \\rangle = \\int g(u^2) \\left(\\frac{u_z^2}{\\omega_z}\\right) \\frac{d^3u}{\\omega_0^{3/2}} = \\frac{1}{\\omega_z \\omega_0^{3/2}} \\int g(u^2) u_z^2 \\,d^3u\n$$\n$$\nM\\langle x^2 \\rangle = \\int g(u^2) \\left(\\frac{u_x^2}{\\omega_\\perp}\\right) \\frac{d^3u}{\\omega_0^{3/2}} = \\frac{1}{\\omega_\\perp \\omega_0^{3/2}} \\int g(u^2) u_x^2 \\,d^3u\n$$\nSince $g(u^2)$ is spherically symmetric in $\\mathbf{u}$-space, the integrals $\\int g(u^2) u_z^2 d^3u$ and $\\int g(u^2) u_x^2 d^3u$ are equal. Let this integral be $I$.\nThus, we have the relations $\\langle z^2 \\rangle \\propto 1/\\omega_z$ and $\\langle x^2 \\rangle \\propto 1/\\omega_\\perp$.\nLet $M\\langle z^2 \\rangle = C/\\omega_z$ and $M\\langle x^2 \\rangle = C/\\omega_\\perp$ for some constant $C$.\nTo find $C$, we consider the spherical limit ($\\varepsilon_2=0$), where $\\omega_z = \\omega_\\perp = \\omega_0$.\nThe mean square radius in this limit is $\\langle r^2 \\rangle_0 = \\langle x^2 \\rangle_0 + \\langle y^2 \\rangle_0 + \\langle z^2 \\rangle_0 = 3C/(M\\omega_0)$.\nThe problem provides that this should be matched to the uniform sphere value: $\\langle r^2 \\rangle_0 = \\frac{3}{5}R_0^2$.\n$$\n\\frac{3C}{M\\omega_0} = \\frac{3}{5}R_0^2 \\implies C = \\frac{1}{5} M\\omega_0 R_0^2\n$$\nNow we compute the quadrupole moment for the deformed case:\n$$\nQ_{0, \\text{HO}}^{(m)} = M(2\\langle z^2 \\rangle - 2\\langle x^2 \\rangle) = 2C \\left(\\frac{1}{\\omega_z} - \\frac{1}{\\omega_\\perp}\\right)\n$$\nSubstitute the relations for $\\omega_z$ and $\\omega_\\perp$ and expand to first order in $\\varepsilon_2$:\n$$\n\\frac{1}{\\omega_z} = \\frac{1}{\\omega_0(1-2\\varepsilon_2/3)} \\approx \\frac{1}{\\omega_0}(1+\\frac{2\\varepsilon_2}{3})\n$$\n$$\n\\frac{1}{\\omega_\\perp} = \\frac{1}{\\omega_0(1+\\varepsilon_2/3)} \\approx \\frac{1}{\\omega_0}(1-\\frac{\\varepsilon_2}{3})\n$$\nTheir difference is:\n$$\n\\frac{1}{\\omega_z} - \\frac{1}{\\omega_\\perp} \\approx \\frac{1}{\\omega_0} \\left( (1+\\frac{2\\varepsilon_2}{3}) - (1-\\frac{\\varepsilon_2}{3}) \\right) = \\frac{\\varepsilon_2}{\\omega_0}\n$$\nSubstituting this and the constant $C$ into the expression for $Q_{0, \\text{HO}}^{(m)}$:\n$$\nQ_{0, \\text{HO}}^{(m)} \\approx 2 \\left(\\frac{1}{5} M\\omega_0 R_0^2\\right) \\frac{\\varepsilon_2}{\\omega_0} = \\frac{2}{5} M R_0^2 \\varepsilon_2\n$$\n\n**3. Equating the Quadrupole Moments**\n\nFinally, we equate the two expressions for the quadrupole moment to find the relation between $\\varepsilon_2$ and $\\beta_2$:\n$$\nQ_{0, \\text{droplet}}^{(m)} = Q_{0, \\text{HO}}^{(m)}\n$$\n$$\n\\frac{3}{\\sqrt{5\\pi}} M R_0^2 \\beta_2 = \\frac{2}{5} M R_0^2 \\varepsilon_2\n$$\nThe factor $M R_0^2$ cancels on both sides. We solve for $\\varepsilon_2$:\n$$\n\\varepsilon_2 = \\frac{5}{2} \\cdot \\frac{3}{\\sqrt{5\\pi}} \\beta_2 = \\frac{15}{2\\sqrt{5\\pi}} \\beta_2\n$$\nSimplifying the constant:\n$$\n\\frac{15}{2\\sqrt{5}\\sqrt{\\pi}} = \\frac{3\\cdot 5}{2\\sqrt{5}\\sqrt{\\pi}} = \\frac{3\\sqrt{5}}{2\\sqrt{\\pi}} = \\frac{3}{2}\\sqrt{\\frac{5}{\\pi}}\n$$\nThus, the derived relation is:\n$$\n\\varepsilon_2 = \\frac{3}{2}\\sqrt{\\frac{5}{\\pi}} \\beta_2\n$$", "answer": "$$\n\\boxed{\\varepsilon_2 = \\frac{3}{2}\\sqrt{\\frac{5}{\\pi}} \\beta_2}\n$$", "id": "3604825"}, {"introduction": "Solving the Schrödinger equation with the Nilsson Hamiltonian requires diagonalizing a matrix that can be very large for a realistic basis. This practice moves from theory to practical computation by focusing on a critical optimization technique. You will explore how exploiting the conserved quantum numbers of the system—specifically the projection of total angular momentum, $\\Omega$, and parity, $\\pi$—allows the Hamiltonian matrix to be broken down into smaller, independent blocks, dramatically reducing computational cost and memory requirements [@problem_id:3604804].", "problem": "Consider the single-particle Nilsson Hamiltonian for axially symmetric deformed nuclei, where the deformation preserves a symmetry axis. The Hamiltonian is built from a deformed anisotropic harmonic oscillator plus spin-orbit and orbital terms. In the axially symmetric case, the Hamiltonian $\\hat{H}$ commutes with the projection of total angular momentum on the symmetry axis, $\\hat{J}_z$, and with the parity operator, $\\hat{\\Pi}$, that is, $[\\hat{H},\\hat{J}_z]=0$ and $[\\hat{H},\\hat{\\Pi}]=0$. As a consequence, the quantum numbers $\\Omega$ (the eigenvalue of $\\hat{J}_z$ in units of $\\hbar$) and $\\pi$ (the eigenvalue of $\\hat{\\Pi}$, equal to $+1$ or $-1$) are conserved. This permits the Hamiltonian matrix, expressed in a basis of states labeled by $(\\Omega,\\pi)$, to be reorganized into independent blocks, each corresponding to one $(\\Omega,\\pi)$ sector. The Rayleigh-Ritz variational principle ensures that diagonalizing each block yields the same eigenvalues as diagonalizing the full Hamiltonian, provided the basis respects the conserved quantum numbers.\n\nYour task is to formalize a block-diagonalization strategy that exploits $(\\Omega,\\pi)$ conservation and to estimate the computational scaling with basis size and number of deformations. Use the following foundational bases:\n- Hermiticity and symmetry: if $[\\hat{H},\\hat{A}]=0$ for an operator $\\hat{A}$, then $\\hat{H}$ and $\\hat{A}$ share a common eigenbasis, implying block structure in the representation of $\\hat{H}$ organized by eigenvalues of $\\hat{A}$.\n- Dense Hermitian eigenvalue problem complexity: for a dense $n \\times n$ Hermitian matrix, widely used algorithms have computational complexity scaling proportional to $n^3$ floating-point operations for full diagonalization, and memory usage scaling proportional to $n^2$ to store the matrix.\n\nDefine the following quantities for a computation over $D$ distinct deformations (for example, different quadrupole deformations characterized by differing values of the parameter often denoted $\\beta$):\n- Let the total basis dimension be $N$, obtained by summing the sizes $n_k$ of all blocks, where each block is identified by a pair $(\\Omega,\\pi)$ and contains all basis states with those conserved quantum numbers.\n- The cost of diagonalizing a dense Hermitian matrix scales as $N^3$ per deformation, thus the total reference cost without symmetry exploitation is proportional to $D N^3$.\n- With block-diagonalization, the cost per deformation is proportional to $\\sum_{k} n_k^3$, and the total cost over $D$ deformations is proportional to $D \\sum_{k} n_k^3$.\n- The memory required to store the full matrix scales as $N^2$, while the memory for the block representation scales as $\\sum_k n_k^2$.\n\nImplement a program that, for each test case below, computes:\n1. The speedup factor $S$ defined as $S = \\dfrac{D N^3}{D \\sum_k n_k^3} = \\dfrac{N^3}{\\sum_k n_k^3}$.\n2. The memory reduction factor $M$ defined as $M = \\dfrac{N^2}{\\sum_k n_k^2}$.\n\nYour program should assume unit proportionality constants, i.e., treat the costs and memory scalings as exact for the purpose of computing $S$ and $M$. The input to your program is implicit via the test suite given below. For each test case, you are given a list of block sizes $\\{n_k\\}$ (each a positive integer) and the number of deformations $D$ (a positive integer). The program must compute $S$ and $M$ as real numbers for each test case and report them rounded to six decimal places.\n\nTest suite:\n- Case $1$ (balanced blocks across multiple $(\\Omega,\\pi)$ sectors): $\\{n_k\\} = [\\,12,12,13,13,12,12,13,13\\,]$, $D=5$. Here, $N=100$.\n- Case $2$ (no symmetry exploited, single block): $\\{n_k\\} = [\\,100\\,]$, $D=5$. Here, $N=100$.\n- Case $3$ (highly uneven distribution of $(\\Omega,\\pi)$ sectors): $\\{n_k\\} = [\\,64,16,16,8,8,8,4,4\\,]$, $D=10$. Here, $N=128$.\n- Case $4$ (many small blocks): $\\{n_k\\} = [\\,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,2,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4,4\\,]$, $D=3$. Here, $N=96$.\n- Case $5$ (parity-only block split): $\\{n_k\\} = [\\,60,60\\,]$, $D=4$. Here, $N=120$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each pair $(S,M)$ for the cases presented in order. Concretely, the output should be $[S_1,M_1,S_2,M_2,S_3,M_3,S_4,M_4,S_5,M_5]$, where each $S_i$ and $M_i$ are rounded to six decimal places. No additional text should be printed.", "solution": "The problem requires an analysis of the computational advantages gained by exploiting symmetries in the single-particle Nilsson Hamiltonian for axially symmetric deformed nuclei. The core principle is that if a Hamiltonian operator $\\hat{H}$ commutes with another operator $\\hat{A}$, i.e., $[\\hat{H}, \\hat{A}] = 0$, then they share a common set of eigenstates. This allows the Hamiltonian matrix to be organized into a block-diagonal form, where each block corresponds to a specific eigenvalue of $\\hat{A}$.\n\nIn the context of the axially symmetric Nilsson model, the Hamiltonian $\\hat{H}$ commutes with both the operator for the projection of total angular momentum on the symmetry axis, $\\hat{J}_z$, and the parity operator, $\\hat{\\Pi}$. The eigenvalues of these operators, $\\Omega$ and $\\pi$ respectively, are conserved quantum numbers. Consequently, any basis state can be labeled by a pair $(\\Omega, \\pi)$, and the Hamiltonian matrix will not have any non-zero elements connecting states with different $(\\Omega, \\pi)$ pairs.\n\nLet the total dimension of the basis space be $N$. If we were to ignore the symmetries, we would construct a single, large Hamiltonian matrix of size $N \\times N$. The computational cost of diagonalizing a dense Hermitian matrix of size $n \\times n$ scales with the cube of its dimension, i.e., it is proportional to $n^3$. Thus, the total computational cost for finding the eigenvalues and eigenvectors of the full $N \\times N$ matrix for $D$ different nuclear deformations would be proportional to $D N^3$. The memory required to store this matrix is proportional to its number of elements, $N^2$.\n\nBy exploiting the $(\\Omega, \\pi)$ symmetry, the basis can be partitioned into smaller sets, each containing states with the same $(\\Omega, \\pi)$ values. Let there be $k$ such blocks, and let the size of the $k$-th block (i.e., the number of basis states with a particular $(\\Omega, \\pi)$ combination) be $n_k$. The total basis size is the sum of the block sizes: $N = \\sum_k n_k$. The full Hamiltonian matrix becomes block-diagonal, with blocks of dimensions $n_k \\times n_k$.\n\nDiagonalizing a block-diagonal matrix is equivalent to diagonalizing each block independently. The total computational cost for one deformation is the sum of the costs for each block: $\\sum_k n_k^3$. For $D$ deformations, the total cost is proportional to $D \\sum_k n_k^3$. Similarly, the memory required is the sum of the memory for each block, proportional to $\\sum_k n_k^2$.\n\nTo quantify the computational gain, we define the speedup factor $S$ and the memory reduction factor $M$. Assuming unit proportionality constants as instructed, these factors are the ratios of the costs without symmetry to the costs with symmetry.\n\nThe speedup factor $S$ is defined as:\n$$\nS = \\frac{\\text{Cost without symmetry}}{\\text{Cost with symmetry}} = \\frac{D N^3}{D \\sum_k n_k^3} = \\frac{N^3}{\\sum_k n_k^3}\n$$\nThe number of deformations $D$ cancels out, indicating that the relative speedup is independent of the number of deformation points calculated.\n\nThe memory reduction factor $M$ is defined as:\n$$\nM = \\frac{\\text{Memory without symmetry}}{\\text{Memory with symmetry}} = \\frac{N^2}{\\sum_k n_k^2}\n$$\n\nThe algorithm to solve the problem is as follows: for each test case, given a list of block sizes $\\{n_k\\}$:\n1.  Calculate the total basis dimension $N$ by summing the block sizes: $N = \\sum_k n_k$.\n2.  Calculate the sum of the cubes of the block sizes: $\\sum_k n_k^3$.\n3.  Calculate the sum of the squares of the block sizes: $\\sum_k n_k^2$.\n4.  Compute the speedup factor $S$ using the formula $S = N^3 / (\\sum_k n_k^3)$.\n5.  Compute the memory reduction factor $M$ using the formula $M = N^2 / (\\sum_k n_k^2)$.\n6.  Report the results for each case, rounded to six decimal places as required.\nThis procedure will be applied to each of the five test cases provided.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes speedup and memory reduction factors for block-diagonalization\n    of a Hamiltonian matrix based on symmetry principles.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each inner list represents the sizes {n_k} of the Hamiltonian matrix blocks.\n    test_cases = [\n        # Case 1: balanced blocks across multiple (Omega,pi) sectors\n        [12, 12, 13, 13, 12, 12, 13, 13],\n        # Case 2: no symmetry exploited, single block\n        [100],\n        # Case 3: highly uneven distribution of (Omega,pi) sectors\n        [64, 16, 16, 8, 8, 8, 4, 4],\n        # Case 4: many small blocks\n        [2]*16 + [4]*16,\n        # Case 5: parity-only block split\n        [60, 60]\n    ]\n\n    results = []\n    for block_sizes in test_cases:\n        # Use numpy arrays for efficient computation.\n        # Use a floating-point dtype to prevent potential integer overflow with large N.\n        n_k = np.array(block_sizes, dtype=np.float64)\n\n        # Calculate the total basis size N.\n        N = np.sum(n_k)\n\n        # Calculate the sum of squares and cubes of block sizes.\n        sum_n_k_squared = np.sum(np.power(n_k, 2))\n        sum_n_k_cubed = np.sum(np.power(n_k, 3))\n\n        # Calculate N^2 and N^3.\n        N_squared = np.power(N, 2)\n        N_cubed = np.power(N, 3)\n\n        # Compute the speedup factor S.\n        # This is the ratio of computational cost without symmetry (N^3)\n        # to the cost with symmetry (sum of n_k^3).\n        # Check for division by zero, although not expected for this problem's constraints.\n        if sum_n_k_cubed == 0:\n            S = 1.0 if N_cubed == 0 else np.inf\n        else:\n            S = N_cubed / sum_n_k_cubed\n\n        # Compute the memory reduction factor M.\n        # This is the ratio of memory usage without symmetry (N^2)\n        # to the usage with symmetry (sum of n_k^2).\n        if sum_n_k_squared == 0:\n            M = 1.0 if N_squared == 0 else np.inf\n        else:\n            M = N_squared / sum_n_k_squared\n\n        # Append the formatted results to the list.\n        results.append(f\"{S:.6f}\")\n        results.append(f\"{M:.6f}\")\n\n    # Final print statement in the exact required format.\n    # The output is a single line containing a comma-separated list of\n    # S and M values for all test cases, enclosed in square brackets.\n    print(f\"[{','.join(results)}]\")\n\n# Execute the main function.\nsolve()\n```", "id": "3604804"}, {"introduction": "A key output of the Nilsson model is the Nilsson diagram, which plots single-particle energy levels as a function of deformation. These diagrams often feature \"avoided crossings,\" where states with the same quantum numbers repel each other, and a naive energy-based sorting can incorrectly swap their identities. This hands-on exercise challenges you to implement a robust algorithm that tracks the physical character of each state across these crossings, a crucial skill for the correct interpretation of how nuclear structure evolves with deformation [@problem_id:3604776].", "problem": "You are given a parameter-dependent family of Hermitian matrices intended to model, in a simplified and computationally tractable way, the evolution of single-particle states in the Nilsson model for deformed nuclei as a function of an axial quadrupole deformation parameter. The goal is to establish and implement an algorithmic criterion that uses both state-to-state overlaps and expectation values of a chosen operator to consistently relabel states across avoided crossings so that asymptotic labels evolve smoothly with deformation. The algorithm must be general, mathematically well-defined, and must minimize spurious label swapping near avoided crossings.\n\nStart from the following fundamental base:\n- A parameter-dependent Hermitian Hamiltonian $H(\\lambda)$ has, at each fixed parameter value $\\lambda$, a complete orthonormal set of eigenstates $\\{ \\lvert \\psi_j(\\lambda) \\rangle \\}_{j=1}^{n}$ with eigenvalues $\\{ E_j(\\lambda) \\}_{j=1}^{n}$, which can be obtained by solving the matrix eigenvalue problem $H(\\lambda) \\mathbf{v}_j(\\lambda) = E_j(\\lambda) \\mathbf{v}_j(\\lambda)$.\n- The inner product (overlap) between two normalized states $\\lvert \\phi \\rangle$ and $\\lvert \\chi \\rangle$ is $\\langle \\phi \\mid \\chi \\rangle$, and the fidelity overlap between two states is $\\left\\lvert \\langle \\phi \\mid \\chi \\rangle \\right\\rvert^2 \\in [0,1]$.\n- The expectation value of a Hermitian operator $\\hat{O}$ in state $\\lvert \\psi \\rangle$ is $\\langle \\psi \\rvert \\hat{O} \\lvert \\psi \\rangle$.\n- Across small changes in $\\lambda$, when evolution is smooth and no exact level crossing occurs for the same quantum numbers, the subspace spanned by a state $\\lvert \\psi_j(\\lambda) \\rangle$ should be continuous as a function of $\\lambda$ at the scale of the change, and expectation values of slowly varying or asymptotically conserved operators should change smoothly.\n\nIn the computational setting below, the diabatic asymptotic basis represents Nilsson-model asymptotic states $\\lvert \\chi_i \\rangle$ (for example, asymptotic $\\lvert N n_z \\Lambda \\Sigma \\rangle$-like basis states), and a chosen diagonal operator $\\hat{O}$ encodes an asymptotic label (for example, an approximate $\\langle n_z \\rangle$ or $\\langle \\Lambda \\rangle$) through its eigenvalues.\n\nYour task:\n- Derive, justify, and implement a criterion that, for a discrete grid $\\{ \\lambda_k \\}_{k=0}^{K-1}$ with small increments, builds a one-to-one assignment between the eigenstates at $\\lambda_{k-1}$ and the eigenstates at $\\lambda_{k}$ by combining the fidelity overlaps $\\left\\lvert \\langle \\psi_i(\\lambda_{k-1}) \\mid \\psi_j(\\lambda_k) \\rangle \\right\\rvert^2$ and the smooth variation of the expectation values $\\langle \\psi(\\lambda) \\rvert \\hat{O} \\lvert \\psi(\\lambda) \\rangle$. The resulting assignment should relabel states so that labels evolve smoothly across avoided crossings. The problem explicitly requires using both overlaps and expectation values to define a cost to be minimized for the assignment, expressed in a way that is universally implementable.\n- Implement, on the given test suite of Hamiltonian families, both:\n  1. A naive labeling scheme based on sorting eigenstates by increasing energy independently at each $\\lambda_k$.\n  2. Your algorithmic criterion that uses overlaps and expectation values to set up and solve a minimal-cost assignment at each step to continue labels from $\\lambda_{k-1}$ to $\\lambda_k$.\n- For each scheme, compute a quantitative smoothness metric defined by\n  $$ D \\equiv \\sum_{k=1}^{K-1} \\sum_{i=1}^{n} \\left( \\langle \\psi_i(\\lambda_k) \\rvert \\hat{O} \\lvert \\psi_i(\\lambda_k) \\rangle - \\langle \\psi_i(\\lambda_{k-1}) \\rvert \\hat{O} \\lvert \\psi_i(\\lambda_{k-1}) \\rangle \\right)^2, $$\n  where, for the algorithmic scheme, the index $i$ tracks the label propagated by your assignment criterion, and for the naive scheme, $i$ is the fixed energy-sorted index at each $\\lambda_k$. Smaller $D$ indicates smoother evolution of asymptotic labels.\n\nHamiltonian families and operator definitions:\n- All matrices are defined on a fixed diabatic basis $\\{ \\lvert \\chi_i \\rangle \\}_{i=1}^{n}$, and have the form $H(\\lambda) = D(\\lambda) + V(\\lambda)$, where $D(\\lambda)$ is diagonal with entries $e_i(\\lambda)$ and $V(\\lambda)$ is real-symmetric with selected off-diagonal couplings $v_{ij}(\\lambda)$ modeled as localized Gaussian couplings to induce avoided crossings. The operator $\\hat{O}$ is diagonal in the diabatic basis with eigenvalues $o_i$.\n\nProvide the following three test cases:\n- Test case $\\#1$ (two-level avoided crossing):\n  - Dimension $n = 2$.\n  - Diabatic energies $e_1(\\lambda) = -a\\,\\lambda$, $e_2(\\lambda) = +a\\,\\lambda$ with $a = 1.0$.\n  - Coupling $v_{12}(\\lambda) = v_0 \\exp\\!\\left( - (\\lambda - \\lambda_0)^2 / (2 \\sigma^2) \\right)$ with $v_0 = 0.15$, $\\lambda_0 = 0.0$, $\\sigma = 0.2$; and $v_{21}(\\lambda) = v_{12}(\\lambda)$.\n  - All other $v_{ij}(\\lambda) = 0$.\n  - Operator $\\hat{O}$ has $o_1 = 0.0$, $o_2 = 1.0$.\n  - Grid $\\lambda \\in [-2.0, 2.0]$ sampled uniformly with step $\\Delta \\lambda = 0.05$.\n- Test case $\\#2$ (three-level, two separated avoided crossings):\n  - Dimension $n = 3$.\n  - Diabatic energies $e_1(\\lambda) = -1.0 + 0.5\\,\\lambda$, $e_2(\\lambda) = 0.0$, $e_3(\\lambda) = +1.0 - 0.5\\,\\lambda$.\n  - Couplings:\n    - $v_{12}(\\lambda) = v_{0,12} \\exp\\!\\left( - (\\lambda - \\lambda_{12})^2 / (2 \\sigma_{12}^2) \\right)$ with $v_{0,12} = 0.12$, $\\lambda_{12} = -0.5$, $\\sigma_{12} = 0.15$.\n    - $v_{23}(\\lambda) = v_{0,23} \\exp\\!\\left( - (\\lambda - \\lambda_{23})^2 / (2 \\sigma_{23}^2) \\right)$ with $v_{0,23} = 0.12$, $\\lambda_{23} = +0.5$, $\\sigma_{23} = 0.15$.\n    - $v_{13}(\\lambda) = v_{31}(\\lambda) = 0.0$.\n    - Symmetry $v_{ij}(\\lambda) = v_{ji}(\\lambda)$ holds.\n  - Operator $\\hat{O}$ has $o_1 = 0.0$, $o_2 = 1.0$, $o_3 = 2.0$.\n  - Grid $\\lambda \\in [-1.5, 1.5]$ sampled uniformly with step $\\Delta \\lambda = 0.05$.\n- Test case $\\#3$ (three-level with an exact crossing):\n  - Dimension $n = 3$.\n  - Diabatic energies $e_1(\\lambda) = -0.3\\,\\lambda$, $e_2(\\lambda) = +0.3\\,\\lambda$, $e_3(\\lambda) = 1.2$.\n  - All couplings $v_{ij}(\\lambda) = 0.0$ for all $i \\neq j$.\n  - Operator $\\hat{O}$ has $o_1 = 0.0$, $o_2 = 1.0$, $o_3 = 2.0$.\n  - Grid $\\lambda \\in [-1.0, 1.0]$ sampled uniformly with step $\\Delta \\lambda = 0.05$.\n\nImplementation and output requirements:\n- Implement the diagonalization of $H(\\lambda)$ at each grid point to obtain eigenpairs $\\{ E_j(\\lambda_k), \\lvert \\psi_j(\\lambda_k) \\rangle \\}$ for all $k$.\n- Implement the naive energy-sorted labeling and compute $D_{\\text{naive}}$ as specified.\n- Derive your algorithmic criterion using overlaps and expectation values, implement it to produce a stepwise assignment of states between $\\lambda_{k-1}$ and $\\lambda_k$ that minimizes a suitable total cost, and compute $D_{\\text{algo}}$ as specified.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with the following nested-list structure:\n  - For test cases $\\#1$, $\\#2$, $\\#3$, output the pair $\\left[D_{\\text{naive}}, D_{\\text{algo}}\\right]$ in that order.\n  - Aggregate them as $\\left[ [D_{\\text{naive}}^{(1)}, D_{\\text{algo}}^{(1)}], [D_{\\text{naive}}^{(2)}, D_{\\text{algo}}^{(2)}], [D_{\\text{naive}}^{(3)}, D_{\\text{algo}}^{(3)}] \\right]$.\n- All quantities are dimensionless; no physical units are required. Angles are not used. The final printed numbers should be rounded to $10^{-6}$ precision for reproducibility.", "solution": "The core of the problem is to devise a method for consistently labeling quantum states as a system parameter, $\\lambda$, is varied. In the vicinity of an avoided crossing, the eigenstates of the Hamiltonian $H(\\lambda)$ exhibit a rapid change in their character. A naïve labeling scheme, which sorts states by their energy $E_j(\\lambda)$ at each value of $\\lambda$, will result in labels swapping between states. This leads to a discontinuous evolution of physical observables associated with a given label, obscuring the underlying smooth, or \"diabatic\", nature of the states.\n\nThe task is to implement and compare two labeling schemes. The first is the naïve energy-sorting scheme. The second is a sophisticated algorithmic scheme that tracks state identity by minimizing a cost function that accounts for both the geometric overlap of state vectors and the smooth evolution of a chosen observable's expectation value. The performance of each scheme is quantified by a smoothness metric, $D$.\n\nFirst, we formalize the computational setup. The Hamiltonian $H(\\lambda)$ and an operator $\\hat{O}$ are represented as $n \\times n$ matrices in a fixed, time-independent \"diabatic\" basis $\\{ \\lvert \\chi_i \\rangle \\}_{i=1}^n$. At each discrete point $\\lambda_k$ on a grid, we solve the time-independent Schrödinger equation, which takes the form of a matrix eigenvalue problem:\n$$ H(\\lambda_k) \\lvert \\psi_j(\\lambda_k) \\rangle = E_j(\\lambda_k) \\lvert \\psi_j(\\lambda_k) \\rangle $$\nThis is solved computationally by diagonalizing the matrix representation of $H(\\lambda_k)$. The solution yields a set of $n$ eigenvalues $\\{E_j(\\lambda_k)\\}$ and a corresponding orthonormal set of eigenvectors $\\{\\lvert \\psi_j(\\lambda_k) \\rangle\\}$. The operator $\\hat{O}$ is diagonal in the diabatic basis, with eigenvalues $\\{o_i\\}$. An eigenvector $\\lvert \\psi_j \\rangle$ is a linear combination of diabatic basis states, $\\lvert \\psi_j \\rangle = \\sum_i c_{ji} \\lvert \\chi_i \\rangle$. Its expectation value for $\\hat{O}$ is $\\langle \\psi_j \\rvert \\hat{O} \\lvert \\psi_j \\rangle = \\sum_i \\lvert c_{ji} \\rvert^2 o_i$.\n\nThe naïve labeling scheme is straightforward. At each $\\lambda_k$, the eigenstates are indexed $j=1, \\dots, n$ in ascending order of their energy eigenvalues $E_j(\\lambda_k)$. The smoothness metric $D_{\\text{naive}}$ is then computed as:\n$$ D_{\\text{naive}} = \\sum_{k=1}^{K-1} \\sum_{i=1}^{n} \\left( \\langle \\psi_i^{\\text{naive}}(\\lambda_k) \\rvert \\hat{O} \\lvert \\psi_i^{\\text{naive}}(\\lambda_k) \\rangle - \\langle \\psi_i^{\\text{naive}}(\\lambda_{k-1}) \\rvert \\hat{O} \\lvert \\psi_i^{\\text{naive}}(\\lambda_{k-1}) \\rangle \\right)^2 $$\nwhere $\\lvert \\psi_i^{\\text{naive}}(\\lambda_k) \\rangle$ is the $i$-th state in the energy-sorted list at $\\lambda_k$. This metric is expected to be large for systems with avoided crossings, as the character of the $i$-th energy eigenstate changes abruptly.\n\nTo develop the more robust algorithmic scheme, we establish a criterion for connecting the labeled states from step $\\lambda_{k-1}$ to the newly computed, initially unlabeled, eigenstates at $\\lambda_k$. The fundamental principle is that for a sufficiently small step $\\Delta \\lambda = \\lambda_k - \\lambda_{k-1}$, a physical state should evolve into a state that is \"close\" to it in the Hilbert space and whose properties change minimally. This suggests a cost-minimization approach. Let $\\{\\lvert \\psi_i^{\\text{old}} \\rangle\\}_{i=1}^n$ be the set of labeled states from step $\\lambda_{k-1}$, and let $\\{\\lvert \\phi_j^{\\text{new}} \\rangle\\}_{j=1}^n$ be the set of new, energy-sorted eigenstates at $\\lambda_k$. We seek a one-to-one assignment (a permutation) $i \\to j=\\pi(i)$ that minimizes a total cost.\n\nThe cost $C_{ij}$ of assigning the old label $i$ to the new state $j$ must be formulated. The problem requires combining two independent criteria:\n1.  Fidelity Overlap: The similarity between two states is measured by the fidelity, $F_{ij} = \\left\\lvert \\langle \\psi_i^{\\text{old}} \\mid \\phi_j^{\\text{new}} \\rangle \\right\\rvert^2$. A cost can be defined as $1 - F_{ij}$, which is small when the states are nearly identical and large when they are nearly orthogonal.\n2.  Expectation Value Smoothness: The expectation value of the operator $\\hat{O}$, which represents an approximate quantum number, should evolve smoothly. The squared difference, $(\\langle \\phi_j^{\\text{new}} \\rvert \\hat{O} \\lvert \\phi_j^{\\text{new}} \\rangle - \\langle \\psi_i^{\\text{old}} \\rvert \\hat{O} \\lvert \\psi_i^{\\text{old}} \\rangle)^2$, penalizes assignments that cause large jumps in this quantity.\n\nTo combine these terms into a single, balanced, and dimensionless cost, we use a weighted sum. The expectation value term is normalized by the maximum possible range of expectation values, $\\Delta O_{\\text{max}} = \\max(o_l) - \\min(o_l)$, to ensure it is of a comparable magnitude to the fidelity term. The resulting cost matrix element $C_{ij}$ is:\n$$ C_{ij} = w \\left(1 - \\left\\lvert \\langle \\psi_i^{\\text{old}} \\mid \\phi_j^{\\text{new}} \\rangle \\right\\rvert^2\\right) + (1-w) \\left( \\frac{\\langle \\phi_j^{\\text{new}} \\rvert \\hat{O} \\lvert \\phi_j^{\\text{new}} \\rangle - \\langle \\psi_i^{\\text{old}} \\rvert \\hat{O} \\lvert \\psi_i^{\\text{old}} \\rangle}{\\Delta O_{\\text{max}}} \\right)^2 $$\nA balanced choice of the weighting factor is $w=0.5$, giving equal importance to both criteria. The problem of finding the optimal assignment of labels is then to find the permutation $\\pi$ that minimizes the total cost, $\\sum_{i=1}^n C_{i, \\pi(i)}$. This is the well-known linear sum assignment problem, which can be efficiently solved using standard algorithms such as the Hungarian algorithm.\n\nThe algorithmic procedure is as follows:\n1. At $\\lambda_0$, diagonalize $H(\\lambda_0)$ and assign initial labels to the eigenstates according to their energy order. Let this be the set $\\{\\lvert \\psi_i(\\lambda_0) \\rangle\\}$.\n2. For each subsequent step $k = 1, \\dots, K-1$:\n    a. Let $\\{\\lvert \\psi_i(\\lambda_{k-1}) \\rangle\\}$ be the labeled states from the previous step.\n    b. Diagonalize $H(\\lambda_k)$ to obtain a new set of energy-sorted eigenstates, $\\{\\lvert \\phi_j(\\lambda_k) \\rangle\\}$.\n    c. Construct the $n \\times n$ cost matrix $C$ with elements $C_{ij}$ as defined above.\n    d. Solve the linear sum assignment problem on $C$ to find the optimal permutation $\\pi$ mapping old labels $i$ to new indices $j$.\n    e. The newly labeled states are $\\{\\lvert \\psi_i(\\lambda_k) \\rangle = \\lvert \\phi_{\\pi(i)}(\\lambda_k) \\rangle\\}$. Store their properties.\n3. Once all steps are complete, compute the smoothness metric $D_{\\text{algo}}$ using the tracked expectation values.\n\nThis algorithmic scheme is designed to follow the diabatic character of the states, preventing label-swapping at avoided crossings and thus producing a much smaller value for the smoothness metric $D$ compared to the naïve scheme.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef run_test_case(n, e_funcs, v_funcs, o_diag, lambda_range, d_lambda):\n    \"\"\"\n    Runs a single test case for state tracking.\n\n    Args:\n        n (int): Dimension of the Hilbert space.\n        e_funcs (list): List of lambda functions for diagonal energies e_i(lambda).\n        v_funcs (dict): Dictionary of lambda functions for off-diagonal couplings v_ij(lambda).\n        o_diag (list): List of diagonal elements of the operator O.\n        lambda_range (tuple): Start and end of the lambda grid.\n        d_lambda (float): Step size for the lambda grid.\n\n    Returns:\n        tuple: A pair of floats (D_naive, D_algo).\n    \"\"\"\n    lambdas = np.arange(lambda_range[0], lambda_range[1] + d_lambda / 2.0, d_lambda)\n    K = len(lambdas)\n    O_diag_np = np.array(o_diag)\n\n    # Pre-calculate all energy-sorted eigenpairs\n    evals_sorted = np.zeros((K, n))\n    evecs_sorted = np.zeros((K, n, n))  # K matrices of size n x n\n\n    for k, lmbda in enumerate(lambdas):\n        H = np.zeros((n, n))\n        for i in range(n):\n            H[i, i] = e_funcs[i](lmbda)\n        for (i, j), func in v_funcs.items():\n            val = func(lmbda)\n            H[i, j] = val\n            H[j, i] = val\n        \n        evals, evecs = np.linalg.eigh(H)\n        evals_sorted[k, :] = evals\n        evecs_sorted[k, :, :] = evecs\n\n    # Expectation values of O for energy-sorted states\n    exp_vals_sorted = np.sum(evecs_sorted**2 * O_diag_np[np.newaxis, :, np.newaxis], axis=1)\n\n    # 1. Naive Labeling Scheme\n    diff_sq_naive = (exp_vals_sorted[1:, :] - exp_vals_sorted[:-1, :])**2\n    D_naive = np.sum(diff_sq_naive)\n\n    # 2. Algorithmic Labeling Scheme\n    labeled_evecs = np.zeros_like(evecs_sorted)\n    labeled_exp_vals = np.zeros_like(exp_vals_sorted)\n\n    labeled_evecs[0, :, :] = evecs_sorted[0, :, :]\n    labeled_exp_vals[0, :] = exp_vals_sorted[0, :]\n\n    delta_O_max = np.max(O_diag_np) - np.min(O_diag_np)\n    if delta_O_max < 1e-9:  # Avoid division by zero\n        delta_O_max = 1.0\n    \n    alpha = 0.5  # Weighting factor for the cost function\n\n    for k in range(1, K):\n        old_vecs = labeled_evecs[k - 1, :, :]\n        old_exp_vals = labeled_exp_vals[k - 1, :]\n        \n        new_vecs_sorted = evecs_sorted[k, :, :]\n        new_exp_vals_sorted = exp_vals_sorted[k, :]\n        \n        cost_matrix = np.zeros((n, n))\n\n        # cost_overlap = 1 - |<old_i|new_j>|^2\n        cost_overlap = 1.0 - (old_vecs.T @ new_vecs_sorted)**2\n        \n        # cost_exp_val = ((O_new_j - O_old_i) / dO_max)^2\n        # Use broadcasting to compute all at once\n        exp_val_diff = (new_exp_vals_sorted[np.newaxis, :] - old_exp_vals[:, np.newaxis])\n        cost_exp_val = (exp_val_diff / delta_O_max)**2\n\n        cost_matrix = alpha * cost_overlap + (1.0 - alpha) * cost_exp_val\n\n        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n        \n        # col_ind is the permutation for the new states\n        labeled_evecs[k, :, :] = new_vecs_sorted[:, col_ind]\n        labeled_exp_vals[k, :] = new_exp_vals_sorted[col_ind]\n\n    diff_sq_algo = (labeled_exp_vals[1:, :] - labeled_exp_vals[:-1, :])**2\n    D_algo = np.sum(diff_sq_algo)\n\n    return D_naive, D_algo\n\n\ndef solve():\n    \"\"\"\n    Main solver function to define and run all test cases.\n    \"\"\"\n    test_cases = [\n        # Test case #1 (two-level avoided crossing)\n        {\n            \"n\": 2,\n            \"e_funcs\": [lambda l: -1.0 * l, lambda l: 1.0 * l],\n            \"v_funcs\": {(0, 1): lambda l: 0.15 * np.exp(-(l - 0.0)**2 / (2 * 0.2**2))},\n            \"o_diag\": [0.0, 1.0],\n            \"lambda_range\": (-2.0, 2.0),\n            \"d_lambda\": 0.05,\n        },\n        # Test case #2 (three-level, two separated avoided crossings)\n        {\n            \"n\": 3,\n            \"e_funcs\": [lambda l: -1.0 + 0.5 * l, lambda l: 0.0, lambda l: 1.0 - 0.5 * l],\n            \"v_funcs\": {\n                (0, 1): lambda l: 0.12 * np.exp(-(l - -0.5)**2 / (2 * 0.15**2)),\n                (1, 2): lambda l: 0.12 * np.exp(-(l - 0.5)**2 / (2 * 0.15**2)),\n            },\n            \"o_diag\": [0.0, 1.0, 2.0],\n            \"lambda_range\": (-1.5, 1.5),\n            \"d_lambda\": 0.05,\n        },\n        # Test case #3 (three-level with an exact crossing)\n        {\n            \"n\": 3,\n            \"e_funcs\": [lambda l: -0.3 * l, lambda l: 0.3 * l, lambda l: 1.2],\n            \"v_funcs\": {},\n            \"o_diag\": [0.0, 1.0, 2.0],\n            \"lambda_range\": (-1.0, 1.0),\n            \"d_lambda\": 0.05,\n        },\n    ]\n\n    results = []\n    for case_params in test_cases:\n        D_n, D_a = run_test_case(**case_params)\n        results.append([D_n, D_a])\n\n    sub_results_str = []\n    for dn, da in results:\n        sub_results_str.append(f\"[{dn:.6f},{da:.6f}]\")\n    \n    print(f\"[{','.join(sub_results_str)}]\")\n\nsolve()\n```", "id": "3604776"}]}