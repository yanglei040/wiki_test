{"hands_on_practices": [{"introduction": "A fundamental challenge in computational scattering theory is solving the Schrödinger equation on a finite numerical grid without introducing artifacts from the artificial boundaries. This practice addresses this issue head-on by guiding you through the implementation of absorbing boundary conditions, a crucial technique for obtaining physically meaningful results. You will implement and compare two powerful methods, the Complex Absorbing Potential (CAP) and the Perfectly Matched Layer (PML), to suppress spurious reflections and ensure the accuracy of your calculated wavefunction [@problem_id:3567471].", "problem": "Construct a complete, runnable program that, in nondimensional units where $\\hbar^{2}/(2\\mu)=1$, discretizes the one-dimensional radial scattering equation for the $s$-wave with a local complex optical model potential on a finite lattice and implements two absorbing boundary strategies to mitigate spurious reflections from the truncation at a finite radius. The governing stationary radial equation for the reduced wavefunction $\\psi(r)$ is the scalar boundary value problem\n$$\n-\\frac{d^{2}\\psi}{dr^{2}} + V(r)\\,\\psi(r) = k^{2}\\,\\psi(r) + S(r), \\quad r \\in [0,R_{\\max}],\n$$\nsubject to a regularity condition at the origin, which for numerical purposes you must enforce as the Dirichlet boundary condition $\\psi(0)=0$, and a truncation at $r=R_{\\max}$, which you must also enforce as the Dirichlet boundary condition $\\psi(R_{\\max})=0$ after adding an absorbing layer to ensure that the imposed truncation is not the dominant source of reflection. The optical model potential is local and complex, with a central Woods–Saxon form for both its real and imaginary parts,\n$$\nV(r) = -\\frac{V_{0}}{1+\\exp\\left(\\frac{r-R_{0}}{a_{0}}\\right)} - i\\,\\frac{W_{0}}{1+\\exp\\left(\\frac{r-R_{w}}{a_{w}}\\right)}.\n$$\nYou must drive the system with a compact source $S(r)$ localized near the left of the domain to generate rightward-propagating waves,\n$$\nS(r) = A_{s}\\,\\exp\\!\\left(-\\frac{(r-r_{s})^{2}}{2\\sigma_{s}^{2}}\\right).\n$$\n\nTo reduce spurious reflections at the truncated right boundary, implement the following two absorbing strategies in the right subdomain $[R_{\\mathrm{abs}},R_{\\max}]$:\n- A complex absorbing potential (CAP), realized by adding an extra purely imaginary potential $-i\\,\\eta(r)$ supported only on $[R_{\\mathrm{abs}},R_{\\max}]$, with a smooth polynomial profile $\\eta(r) = \\eta_{0}\\left(\\frac{r-R_{\\mathrm{abs}}}{L_{\\mathrm{abs}}}\\right)^{m}$, where $L_{\\mathrm{abs}}=R_{\\max}-R_{\\mathrm{abs}}$ and $m$ is a positive integer.\n- A Perfectly Matched Layer (PML), realized by a complex coordinate stretching in the right subdomain, $r \\mapsto s(r)$, characterized by a complex stretch factor $s'(r)=1+i\\,\\sigma(r)$ with $\\sigma(r) = \\sigma_{0}\\left(\\frac{r-R_{\\mathrm{abs}}}{L_{\\mathrm{abs}}}\\right)^{m}$ for $r \\in [R_{\\mathrm{abs}},R_{\\max}]$ and $\\sigma(r)=0$ otherwise. Under this stretching, the second derivative transforms to the symmetric differential operator $-\\frac{d}{dr}\\left(\\frac{1}{s'(r)}\\frac{d\\psi}{dr}\\right)$ in the sense of the frequency-domain formulation.\n\nThe fundamental base you must start from is the definition of the time-independent Schrödinger equation in radial form for $s$-waves and the construction of absorbing layers either by adding an imaginary potential (for the CAP) or by complex coordinate stretching (for the PML) in the frequency domain. You must not assume any prefabricated discretization; instead, derive a consistent second-order finite-difference scheme for the symmetric operator $-\\frac{d}{dr}\\!\\left(a(r)\\,\\frac{d\\psi}{dr}\\right)$ with $a(r)=1$ for the CAP scheme and $a(r)=\\frac{1}{1+i\\,\\sigma(r)}$ for the PML scheme, enforce the stated Dirichlet boundary conditions, and solve the resulting linear system on a uniform grid.\n\nTo quantify residual spurious reflection, extract an estimate of the reflection amplitude in a monitoring window $[r_{1},r_{2}]$ that lies strictly to the left of the right absorbing region. In that window, where $V(r)=0$ and there is no absorbing profile, the solution is well approximated by a superposition of right- and left-propagating plane waves,\n$$\n\\psi(r) \\approx A\\,e^{i\\,k\\,r} + B\\,e^{-i\\,k\\,r},\n$$\nwith real $k=\\sqrt{E}$, where $E=k^{2}$ is the scattering energy. Use a least-squares fit over grid points in $[r_{1},r_{2}]$ to estimate the complex amplitudes $A$ and $B$, and report the scalar reflection measure $\\mathcal{R}=\\left|B\\right|/\\left|A\\right|$.\n\nAll quantities are nondimensional, so you must not report any physical units. Angles are not used. Your numerical implementation must be stable and convergent for the parameters below.\n\nGrid and domain specification:\n- Total radius $R_{\\max}=30.0$.\n- Uniform grid spacing $h=0.02$.\n- Left absorbing buffer of length $L_{\\mathrm{left}}=3.0$ to suppress reflections from $r=0$ by a left-side CAP with strength parameter $\\eta_{\\mathrm{left}}=5.0$ and polynomial power $m_{\\mathrm{left}}=2$.\n- Source parameters $A_{s}=1.0$, $r_{s}=4.0$, $\\sigma_{s}=0.3$.\n- Optical model potential parameters $V_{0}=50.0$, $W_{0}=5.0$, $R_{0}=6.0$, $a_{0}=0.5$, $R_{w}=6.0$, $a_{w}=0.5$.\n- Scattering energy $E=1.0$, so that $k=\\sqrt{E}=1.0$.\n\nRight-layer monitoring window placement:\n- For each test, set the right absorbing region start at $R_{\\mathrm{abs}}=R_{\\max}-L_{\\mathrm{right}}$, and define the monitoring window $[r_{1},r_{2}]$ with $r_{1}=R_{\\mathrm{abs}}-4.0$ and $r_{2}=R_{\\mathrm{abs}}-1.0$.\n\nTest suite:\nImplement the following four test cases, which differ only in the right-layer type and parameters. For each case, compute and return the reflection measure $\\mathcal{R}$ obtained from the fit in the monitoring window.\n- Case $\\mathbf{1}$ (no right absorber): right-layer type is “none,” $L_{\\mathrm{right}}=6.0$; set the right-layer profiles to zero so that $a(r)=1$ everywhere and no additional imaginary potential is added on the right.\n- Case $\\mathbf{2}$ (weak CAP): right-layer type is “cap,” $L_{\\mathrm{right}}=6.0$, CAP strength $\\eta_{0}=0.5$, polynomial power $m=2$.\n- Case $\\mathbf{3}$ (strong CAP): right-layer type is “cap,” $L_{\\mathrm{right}}=8.0$, CAP strength $\\eta_{0}=3.0$, polynomial power $m=4$.\n- Case $\\mathbf{4}$ (PML): right-layer type is “pml,” $L_{\\mathrm{right}}=8.0$, PML strength $\\sigma_{0}=2.0$, polynomial power $m=3$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of cases $\\mathbf{1}$ through $\\mathbf{4}$. Each entry must be a floating-point number representing $\\mathcal{R}$ for that case. For example, a syntactically correct output with placeholder values would look like “$[0.5,0.1,0.01,0.0001]$”, but you must output the actual computed values for the specified test suite.", "solution": "The user's request is to solve the one-dimensional radial Schrödinger equation for $s$-waves with a local complex optical potential, discretized on a finite lattice. The key task is to implement and compare two different types of absorbing boundary conditions—a Complex Absorbing Potential (CAP) and a Perfectly Matched Layer (PML)—to mitigate spurious reflections from the artificial truncation of the domain at $r=R_{\\max}$. The performance is quantified by a reflection measure $\\mathcal{R}$ extracted from a least-squares fit in a specific monitoring window.\n\nThe governing equation is a boundary value problem given by:\n$$\n-\\frac{d}{dr}\\left(a(r)\\,\\frac{d\\psi}{dr}\\right) + V_{\\mathrm{eff}}(r)\\,\\psi(r) = E\\,\\psi(r) + S(r)\n$$\non the domain $r \\in [0, R_{\\max}]$, with Dirichlet boundary conditions $\\psi(0) = 0$ and $\\psi(R_{\\max}) = 0$. The energy is fixed at $E=k^2=1.0$.\n\nFirst, we establish a uniform numerical grid $r_j = j \\cdot h$ for $j=0, 1, \\dots, N$, where $h$ is the grid spacing and $N = R_{\\max}/h$. The wavefunction on this grid is denoted by $\\psi_j = \\psi(r_j)$.\n\nThe problem specifies two scenarios for the term $a(r)$ and the effective potential $V_{\\mathrm{eff}}(r)$:\n1.  **CAP Strategy**: An imaginary potential $-i\\eta(r)$ is added to the physical potential. In this case, $a(r)=1$ everywhere. The total effective potential is $V_{\\mathrm{eff}}(r) = V(r) - i\\eta_{\\mathrm{left}}(r) - i\\eta_{\\mathrm{right}}(r)$, where $V(r)$ is the Woods-Saxon optical potential, and $\\eta_{\\mathrm{left}}(r)$ and $\\eta_{\\mathrm{right}}(r)$ are the left and right absorbing potentials, respectively.\n2.  **PML Strategy**: A complex coordinate stretching is applied in the absorbing region. This modifies the kinetic operator. The function $a(r)$ becomes $a(r) = (1+i\\sigma(r))^{-1}$, where $\\sigma(r)$ is non-zero only in the PML region. The effective potential consists of only the physical optical potential and the left-side absorber: $V_{\\mathrm{eff}}(r) = V(r) - i\\eta_{\\mathrm{left}}(r)$.\n\nThe differential operator $-\\frac{d}{dr}\\left(a(r)\\frac{d\\psi}{dr}\\right)$ is discretized using a second-order finite-difference scheme. We evaluate $a(r)$ at half-grid points $r_{j+1/2} = r_j + h/2$. The discretized equation at an interior grid point $r_j$ (for $j=1, \\dots, N-1$) is:\n$$\n-\\frac{1}{h^2} \\left[ a_{j+1/2}(\\psi_{j+1}-\\psi_j) - a_{j-1/2}(\\psi_j - \\psi_{j-1}) \\right] + (V_{\\mathrm{eff},j} - E)\\psi_j = S_j\n$$\nwhere $a_{j\\pm 1/2}=a(r_{j\\pm 1/2})$, $V_{\\mathrm{eff},j}=V_{\\mathrm{eff}}(r_j)$, and $S_j=S(r_j)$. Rearranging the terms, we obtain a linear system for the unknown interior wavefunction values $\\vec{\\psi}_{\\mathrm{int}} = (\\psi_1, \\psi_2, \\dots, \\psi_{N-1})^T$:\n$$\n-\\frac{a_{j-1/2}}{h^2} \\psi_{j-1} + \\left(\\frac{a_{j+1/2}+a_{j-1/2}}{h^2} + V_{\\mathrm{eff},j} - E\\right) \\psi_j - \\frac{a_{j+1/2}}{h^2} \\psi_{j+1} = S_j\n$$\nThis forms a complex-valued, tridiagonal linear system of equations $M \\vec{\\psi}_{\\mathrm{int}} = \\vec{S}_{\\mathrm{int}}$. The matrix $M$ is defined by:\n-   **Diagonal elements**: $M_{j-1,j-1} = \\frac{a_{j+1/2}+a_{j-1/2}}{h^2} + V_{\\mathrm{eff},j} - E$\n-   **Off-diagonal elements**: $M_{j-1,j} = -\\frac{a_{j+1/2}}{h^2}$ and $M_{j,j-1} = -\\frac{a_{j-1/2}}{h^2}$. Note that if $a(r)$ is a slowly varying function, the matrix is approximately complex-symmetric, i.e., $M_{ij} \\approx M_{ji}$.\n\nThis tridiagonal system is efficiently solved using a specialized algorithm, such as the one provided by `scipy.linalg.solve_banded`.\n\nAfter solving for $\\vec{\\psi}_{\\mathrm{int}}$, the full numerical solution $\\vec{\\psi} = (0, \\psi_1, \\dots, \\psi_{N-1}, 0)^T$ is constructed.\n\nTo quantify reflections, we analyze the solution in a \"monitoring window\" $[r_1, r_2]$, which is located in the free-space region (where $V(r) \\approx 0$ and absorbers are absent). In this region, the solution is a superposition of a right-propagating wave and a reflected left-propagating wave:\n$$\n\\psi(r) \\approx A\\,e^{ikr} + B\\,e^{-ikr}\n$$\nWe perform a linear least-squares fit to the numerical solution $\\psi_j$ over the grid points $r_j \\in [r_1, r_2]$ to determine the complex amplitudes $A$ and $B$. The design matrix $X$ for this fit has two columns, $[e^{ikr_j}]$ and $[e^{-ikr_j}]$, and the coefficient vector is $\\beta = (A, B)^T$. The least-squares solution is found via $\\beta = (X^H X)^{-1} X^H \\vec{\\psi}_{\\mathrm{fit}}$. Finally, the reflection measure is computed as the ratio of the magnitudes of the amplitudes: $\\mathcal{R} = |B|/|A|$.\n\nThe implementation will proceed by defining a function that takes the parameters for each test case, constructs all potential and coefficient arrays, assembles and solves the linear system, and performs the reflection analysis. This function is then called for each of the four specified test cases.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef solve():\n    \"\"\"\n    Constructs and solves the discretized 1D radial scattering equation\n    with different absorbing boundary conditions, and computes the reflection measure\n    for four test cases.\n    \"\"\"\n\n    def run_simulation(case_params):\n        \"\"\"\n        Solves the radial Schrödinger equation for a single set of parameters.\n\n        Args:\n            case_params (dict): A dictionary containing parameters for the test case.\n\n        Returns:\n            float: The computed reflection measure R = |B|/|A|.\n        \"\"\"\n        # --- Fixed parameters from the problem statement ---\n        R_max = 30.0\n        h = 0.02\n        E = 1.0\n        k = np.sqrt(E)\n\n        # --- Grid setup ---\n        N = int(R_max / h)\n        r = np.linspace(0.0, R_max, N + 1)\n        r_int = r[1:-1]\n        r_half = r[:-1] + h / 2\n\n        # --- Base potential and source definitions ---\n        # Optical model potential (Woods-Saxon form)\n        V0, W0, R0, a0, Rw, aw = 50.0, 5.0, 6.0, 0.5, 6.0, 0.5\n        V_r = -V0 / (1.0 + np.exp((r - R0) / a0))\n        V_i = -W0 / (1.0 + np.exp((r - Rw) / aw))\n        V_optical = V_r + 1j * V_i\n        \n        # Gaussian source term\n        A_s, r_s, sigma_s = 1.0, 4.0, 0.3\n        S = A_s * np.exp(-(r - r_s)**2 / (2.0 * sigma_s**2))\n\n        # --- Absorbing layers setup ---\n        # Left-side Complex Absorbing Potential (CAP)\n        L_left, eta_left_strength, m_left = 3.0, 5.0, 2\n        eta_left = np.zeros_like(r, dtype=np.float64)\n        left_mask = r <= L_left\n        eta_left[left_mask] = eta_left_strength * ((L_left - r[left_mask]) / L_left)**m_left\n        V_eff = V_optical - 1j * eta_left\n\n        # Right-side absorber (case-specific)\n        absorber_type = case_params['type']\n        L_right = case_params['L_right']\n        R_abs = R_max - L_right\n\n        # Pre-calculate relative positions for right absorber profiles\n        right_mask = r >= R_abs\n        r_in_absorber = np.zeros_like(r, dtype=np.float64)\n        r_in_absorber[right_mask] = (r[right_mask] - R_abs) / L_right\n\n        right_mask_half = r_half >= R_abs\n        r_half_in_absorber = np.zeros_like(r_half, dtype=np.float64)\n        r_half_in_absorber[right_mask_half] = (r_half[right_mask_half] - R_abs) / L_right\n\n        a_half = np.ones(N, dtype=np.complex128)\n\n        if absorber_type == 'cap':\n            eta_0, m = case_params['strength'], case_params['power']\n            eta_right = np.zeros_like(r, dtype=np.float64)\n            eta_right[right_mask] = eta_0 * (r_in_absorber[right_mask]**m)\n            V_eff -= 1j * eta_right\n        elif absorber_type == 'pml':\n            sigma_0, m = case_params['strength'], case_params['power']\n            sigma_r_half = np.zeros_like(r_half, dtype=np.float64)\n            sigma_r_half[right_mask_half] = sigma_0 * (r_half_in_absorber[right_mask_half]**m)\n            a_half = 1.0 / (1.0 + 1j * sigma_r_half)\n\n        # --- Discretization and Linear System Construction ---\n        V_eff_int = V_eff[1:-1]\n        S_int = S[1:-1]\n        N_mat = N - 1\n\n        # Tridiagonal matrix components for M * psi = S\n        main_diag = (a_half[1:N] + a_half[0:N-1]) / h**2 + V_eff_int - E\n        upper_diag = -a_half[1:N-1] / h**2\n        lower_diag = -a_half[1:N-1] / h**2\n        \n        # Scipy's solve_banded uses a specific banded matrix format (ab)\n        ab = np.zeros((3, N_mat), dtype=np.complex128)\n        ab[0, 1:] = upper_diag\n        ab[1, :] = main_diag\n        ab[2, :-1] = lower_diag\n        \n        # Solve the linear system\n        psi_int = solve_banded((1, 1), ab, S_int)\n        \n        # Reconstruct full wavefunction with boundary conditions\n        psi = np.concatenate(([0j], psi_int, [0j]))\n\n        # --- Reflection Analysis ---\n        r1, r2 = R_abs - 4.0, R_abs - 1.0\n        j1 = int(round(r1 / h))\n        j2 = int(round(r2 / h))\n\n        r_fit = r[j1 : j2 + 1]\n        psi_fit = psi[j1 : j2 + 1]\n\n        # Least squares fit to model: psi(r) = A*exp(ikr) + B*exp(-ikr)\n        phi1 = np.exp(1j * k * r_fit)\n        phi2 = np.exp(-1j * k * r_fit)\n        X = np.stack([phi1, phi2], axis=1)\n        \n        coeffs, _, _, _ = np.linalg.lstsq(X, psi_fit, rcond=None)\n        A, B = coeffs[0], coeffs[1]\n        \n        reflection_measure = np.abs(B) / np.abs(A)\n        return reflection_measure\n        \n    # --- Test Suite Definition ---\n    test_cases = [\n        # Case 1: No right absorber\n        {'type': 'none', 'L_right': 6.0},\n        # Case 2: Weak CAP\n        {'type': 'cap', 'L_right': 6.0, 'strength': 0.5, 'power': 2},\n        # Case 3: Strong CAP\n        {'type': 'cap', 'L_right': 8.0, 'strength': 3.0, 'power': 4},\n        # Case 4: PML\n        {'type': 'pml', 'L_right': 8.0, 'strength': 2.0, 'power': 3},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_simulation(case)\n        results.append(result)\n\n    # --- Final Output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3567471"}, {"introduction": "The real and imaginary parts of the optical model potential are not independent but are deeply connected by the principle of causality, expressed through the Kramers-Kronig dispersion relations. This hands-on exercise transitions from using a simple phenomenological potential to constructing a more physically rigorous dispersive optical model. By numerically implementing the subtracted Kramers-Kronig integral, you will compute the dispersive correction $\\Delta V(E)$ from a given imaginary potential $W(E)$, gaining insight into how fundamental principles constrain and enrich the structure of the potential [@problem_id:3567524].", "problem": "A spin-averaged nucleon optical potential in a finite nucleus can be constrained by causality via the Kramers–Kronig relations, which connect its energy-dependent real and imaginary parts. Consider a single-particle energy variable $E$ (in $\\mathrm{MeV}$) measured relative to a Fermi energy $E_F$ (also in $\\mathrm{MeV}$). Let the imaginary part be modeled by a smooth, integrable, even function around $E_F$, designed to vanish at $E=E_F$ and to decay at large $|E-E_F|$ to guarantee numerical convergence. Specifically, define\n$$\nW(E) \\equiv W_0 \\left(1 - e^{-\\frac{(E-E_F)^2}{d^2}}\\right) e^{-\\frac{(E-E_F)^2}{s^2}},\n$$\nwith parameters $W_0 = 50\\,\\mathrm{MeV}$, $d = 10\\,\\mathrm{MeV}$, $s = 80\\,\\mathrm{MeV}$, and $E_F = -8\\,\\mathrm{MeV}$. Due to causality, the real-part dispersive correction $\\Delta V(E)$ is given by the subtracted Kramers–Kronig relation, expressed as a Cauchy principal value integral of a subtracted Cauchy kernel. Your task is to implement numerically the subtracted principal value integral for $\\Delta V(E)$ using two independent numerical strategies and to validate Kramers–Kronig consistency properties against synthetic reference data produced by one of the strategies.\n\nImplement the following in a complete, runnable program:\n\n- Use energy integration bounds $[E_{\\min}, E_{\\max}] = [E_F - 400\\,\\mathrm{MeV}, E_F + 400\\,\\mathrm{MeV}]$ to approximate the infinite-domain principal value integral. Treat the integral as a principal value at both $E$ and $E_F$.\n- Method A (piecewise principal value): Implement a direct numerical quadrature of the principal value integral by splitting the integration domain into subintervals that exclude small symmetric neighborhoods of any singular points at $E$ and $E_F$ within the bounds. Use a small exclusion half-width $\\varepsilon = 10^{-6}\\,\\mathrm{MeV}$ and high-accuracy quadrature on each subinterval. This produces a numerical result for $\\Delta V(E)$.\n- Method B (reference weighted quadrature): Implement a reference calculation by using a Cauchy-weighted principal value quadrature on the same finite bounds to compute separately the two principal value integrals with Cauchy kernels centered at $E$ and $E_F$, and then subtract them to obtain $\\Delta V(E)$. This serves as the synthetic “data” against which you validate Method A.\n\nUsing both methods, evaluate the following validation quantities, all expressed in $\\mathrm{MeV}$:\n1. The absolute value $|\\Delta V(E_F)|$ computed by Method A.\n2. The oddness residual at symmetric offsets $\\Delta = 25\\,\\mathrm{MeV}$ about $E_F$, namely $|\\Delta V(E_F+\\Delta) + \\Delta V(E_F-\\Delta)|$, computed by Method A.\n3. The maximum absolute deviation between Method A and Method B across the energy set $\\{E_F-60\\,\\mathrm{MeV},\\,E_F-20\\,\\mathrm{MeV},\\,E_F,\\,E_F+20\\,\\mathrm{MeV},\\,E_F+60\\,\\mathrm{MeV}\\}$.\n\nAngle units are not applicable in this problem. All energies and outputs must be in $\\mathrm{MeV}$. Your program should produce a single line of output containing the three results as a comma-separated list enclosed in square brackets, in the order specified above (for example, \"[x1,x2,x3]\").\n\nTest suite:\n- Use the energy grid $\\{E_F-60\\,\\mathrm{MeV},\\,E_F-20\\,\\mathrm{MeV},\\,E_F,\\,E_F+20\\,\\mathrm{MeV},\\,E_F+60\\,\\mathrm{MeV}\\}$ to compute the deviation in item $3$.\n- Use the Fermi energy $E_F=-8\\,\\mathrm{MeV}$ for item $1$.\n- Use $\\Delta=25\\,\\mathrm{MeV}$ for item $2$.\nThe answers for the three test cases must be three floats in $\\mathrm{MeV}$, aggregated as a single list on one line as specified.", "solution": "The problem requires the numerical implementation and validation of a subtracted Kramers–Kronig relation for a nucleon optical potential in nuclear physics. The core of the problem lies in the computation of a dispersive correction to the real part of the potential, $\\Delta V(E)$, derived from its imaginary part, $W(E)$.\n\nThe imaginary part of the potential is given by the function:\n$$\nW(E) = W_0 \\left(1 - e^{-\\frac{(E-E_F)^2}{d^2}}\\right) e^{-\\frac{(E-E_F)^2}{s^2}}\n$$\nwith parameters $W_0 = 50\\,\\mathrm{MeV}$, $d = 10\\,\\mathrm{MeV}$, $s = 80\\,\\mathrm{MeV}$, and a Fermi energy $E_F = -8\\,\\mathrm{MeV}$. This function is even with respect to the variable $(E-E_F)$, i.e., $W(E_F + \\delta E) = W(E_F - \\delta E)$. Furthermore, the term $\\left(1 - \\exp\\left(-\\frac{(E-E_F)^2}{d^2}\\right)\\right)$ ensures that $W(E)$ vanishes quadratically at the Fermi energy, i.e., $W(E) \\propto (E-E_F)^2$ for $E \\to E_F$.\n\nThe real-part dispersive correction, $\\Delta V(E)$, is connected to $W(E)$ via a once-subtracted Kramers–Kronig relation. The subtraction is performed at the Fermi energy $E_F$ to ensure that $\\Delta V(E_F) = 0$. The relation can be expressed as a difference of two Cauchy principal value integrals:\n$$\n\\Delta V(E) = \\frac{1}{\\pi} \\mathcal{P} \\int_{-\\infty}^{\\infty} \\frac{W(E')}{E' - E} dE' - \\frac{1}{\\pi} \\mathcal{P} \\int_{-\\infty}^{\\infty} \\frac{W(E')}{E' - E_F} dE'\n$$\nThis form is equivalent to the more common single-integral expression:\n$$\n\\Delta V(E) = \\frac{E - E_F}{\\pi} \\mathcal{P} \\int_{-\\infty}^{\\infty} \\frac{W(E')}{(E' - E)(E' - E_F)} dE'\n$$\nThe problem specifies approximating the infinite integral by integrating over the finite, symmetric domain $[E_{\\min}, E_{\\max}] = [E_F - 400\\,\\mathrm{MeV}, E_F + 400\\,\\mathrm{MeV}]$.\n\nBecause $W(E)$ is an even function with respect to $E_F$ and the integration domain is symmetric around $E_F$, the resulting dispersive correction $\\Delta V(E)$ must be an odd function with respect to $E_F$. This implies two key properties that are to be validated numerically:\n1.  $\\Delta V(E_F) = 0$.\n2.  $\\Delta V(E_F + \\delta E) = - \\Delta V(E_F - \\delta E)$, or equivalently, $\\Delta V(E_F + \\delta E) + \\Delta V(E_F - \\delta E) = 0$.\n\nTwo numerical methods are implemented to compute $\\Delta V(E)$.\n\n**Method A: Piecewise Principal Value Quadrature**\nThis method directly implements the definition of a principal value integral. The integrand function is:\n$$\nf(E') = \\frac{W(E')}{\\pi} \\left( \\frac{1}{E' - E} - \\frac{1}{E' - E_F} \\right)\n$$\nThis integrand has singularities at $E' = E$ and $E' = E_F$. To compute the principal value, the integration domain $[E_{\\min}, E_{\\max}]$ is split into subintervals that explicitly exclude small, symmetric neighborhoods $(E - \\varepsilon, E + \\varepsilon)$ and $(E_F - \\varepsilon, E_F + \\varepsilon)$ around the singularities, where $\\varepsilon = 10^{-6}\\,\\mathrm{MeV}$. The integral is then the sum of the integrals over the remaining subintervals. For example, if $E > E_F$, the integral is computed as:\n$$\n\\int_{E_{\\min}}^{E_F-\\varepsilon} f(E') dE' + \\int_{E_F+\\varepsilon}^{E-\\varepsilon} f(E') dE' + \\int_{E+\\varepsilon}^{E_{\\max}} f(E') dE'\n$$\nEach integral over a non-singular subinterval is calculated using a high-accuracy numerical quadrature routine (`scipy.integrate.quad`). In the special case where $E = E_F$, the two terms in the subtrahend cancel, and the integrand is identically zero for $E' \\ne E_F$. Thus, the integral evaluates to zero.\n\n**Method B: Reference Weighted Quadrature**\nThis method serves as a high-accuracy reference. It computes the two principal value integrals in the definition of $\\Delta V(E)$ separately using a specialized numerical algorithm for Cauchy-weighted integrals.\n$$\n\\Delta V(E) = \\frac{1}{\\pi} \\left( I(E) - I(E_F) \\right) \\quad \\text{where} \\quad I(x) = \\mathcal{P} \\int_{E_{\\min}}^{E_{\\max}} \\frac{W(E')}{E' - x} dE'\n$$\nThe integral $I(x)$ is computed using `scipy.integrate.quad` with its `weight='cauchy'` and `wvar=x` options, which is designed for this specific type of integral and typically provides very accurate results.\n\n**Validation Quantities**\nThe three quantities to be computed serve to validate the implementation of Method A against theoretical expectations and the reference calculation (Method B).\n1.  **$|\\Delta V_A(E_F)|$**: This tests the implementation's handling of the subtraction point. Theoretically, this value is $0$. As implemented in Method A, if $E = E_F$, the integrand becomes identically zero, yielding a result of $0.0$.\n2.  **$|\\Delta V_A(E_F+\\Delta) + \\Delta V_A(E_F-\\Delta)|$**: This tests the numerical preservation of the oddness property of $\\Delta V(E)$ around $E_F$. Due to the symmetric integration limits and the even nature of $W(E)$, this sum should be zero. The calculated value represents the numerical residual error, which should be very small.\n3.  **Maximum absolute deviation**: This quantity, $\\max_{E} |\\Delta V_A(E) - \\Delta V_B(E)|$, quantifies the agreement between the \"brute-force\" principal value calculation (Method A) and the specialized library routine (Method B) over a set of test energies. A small deviation confirms the correctness of both implementations.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Solves the computational nuclear physics problem as specified.\n    1. Defines the optical potential model and parameters.\n    2. Implements two numerical methods (A and B) for the Kramers-Kronig integral.\n    3. Computes the three specified validation quantities.\n    4. Prints the results in the required format.\n    \"\"\"\n    \n    # --- Define constants and parameters ---\n    W0 = 50.0  # MeV\n    d = 10.0   # MeV\n    s = 80.0   # MeV\n    EF = -8.0  # MeV\n    eps = 1e-6 # MeV, exclusion half-width for Method A\n\n    # Integration bounds\n    E_min = EF - 400.0  # MeV\n    E_max = EF + 400.0  # MeV\n\n    # --- Test case parameters ---\n    delta_oddness = 25.0  # MeV, for validation quantity 2\n    E_grid_relative = np.array([-60.0, -20.0, 0.0, 20.0, 60.0])\n    E_grid_test = EF + E_grid_relative  # MeV, for validation quantity 3\n\n    # --- Imaginary Potential W(E) ---\n    def W_func(E_prime, EF_val, W0_val, d_val, s_val):\n        \"\"\"\n        Calculates the imaginary part of the optical potential W(E').\n        \"\"\"\n        # Using a shifted energy variable to avoid large numbers\n        x = E_prime - EF_val\n        term1 = 1.0 - np.exp(-(x**2) / (d_val**2))\n        term2 = np.exp(-(x**2) / (s_val**2))\n        return W0_val * term1 * term2\n\n    # --- Method A: Piecewise Principal Value Quadrature ---\n    def delta_V_A(E, EF_val, W0_val, d_val, s_val):\n        \"\"\"\n        Computes the dispersive correction Delta_V(E) using Method A.\n        The integral is split to avoid singularities at E and EF.\n        \"\"\"\n        # The integrand for the subtracted dispersion relation\n        def integrand(E_prime, E_val):\n            w_val = W_func(E_prime, EF_val, W0_val, d_val, s_val)\n            # This form can be unstable if E is very close to EF.\n            # However, the problem specifies PV at both E and EF.\n            if abs(E_prime - E_val) < 1e-15 or abs(E_prime - EF_val) < 1e-15:\n                 return 0.0 # Should be handled by interval exclusion\n            term_E = 1.0 / (E_prime - E_val)\n            term_EF = 1.0 / (E_prime - EF_val)\n            return w_val * (term_E - term_EF)\n\n        # Handle singularities by splitting the integration domain\n        s1 = min(E, EF_val)\n        s2 = max(E, EF_val)\n\n        # If E and EF are identical, the integrand is zero everywhere (numerically).\n        # This correctly reflects Delta_V(EF) = 0.\n        if abs(E - EF_val) < 1e-12:\n            return 0.0\n        \n        total_integral = 0.0\n        \n        # Integrate from E_min to the first singularity\n        res1, _ = quad(integrand, E_min, s1 - eps, args=(E,))\n        total_integral += res1\n        \n        # Integrate between the two singularities\n        if (s1 + eps) < (s2 - eps):\n            res2, _ = quad(integrand, s1 + eps, s2 - eps, args=(E,))\n            total_integral += res2\n        \n        # Integrate from the second singularity to E_max\n        res3, _ = quad(integrand, s2 + eps, E_max, args=(E,))\n        total_integral += res3\n        \n        return total_integral / np.pi\n\n    # --- Method B: Reference Weighted Quadrature ---\n    def delta_V_B(E, EF_val, W0_val, d_val, s_val):\n        \"\"\"\n        Computes Delta_V(E) using Method B (Cauchy-weighted quadrature).\n        This serves as the reference \"data\".\n        \"\"\"\n        \n        # Function to integrate is just W(E')\n        def w_integrand(E_prime):\n            return W_func(E_prime, EF_val, W0_val, d_val, s_val)\n\n        # If E and EF are identical, result is 0 by definition\n        if abs(E - EF_val) < 1e-12:\n            return 0.0\n\n        # Calculate the two principal value integrals separately\n        # I(E) = P.V. integral of W(E')/(E' - E)\n        integral_E, _ = quad(w_integrand, E_min, E_max, weight='cauchy', wvar=E)\n        \n        # I(EF) = P.V. integral of W(E')/(E' - EF)\n        integral_EF, _ = quad(w_integrand, E_min, E_max, weight='cauchy', wvar=EF_val)\n        \n        return (integral_E - integral_EF) / np.pi\n\n    # --- Compute the three validation quantities ---\n    results = []\n\n    # 1. Absolute value |Delta V(EF)| computed by Method A.\n    # The definition of the subtracted dispersion relation ensures this is 0.\n    # Method A implementation also yields 0 when E=EF.\n    val1 = abs(delta_V_A(EF, EF, W0, d, s))\n    results.append(val1)\n\n    # 2. Oddness residual |Delta V(EF+d) + Delta V(EF-d)| by Method A.\n    # Theoretically, this is 0 due to symmetry. The result is a numerical residual.\n    v_plus_delta = delta_V_A(EF + delta_oddness, EF, W0, d, s)\n    v_minus_delta = delta_V_A(EF - delta_oddness, EF, W0, d, s)\n    val2 = abs(v_plus_delta + v_minus_delta)\n    results.append(val2)\n\n    # 3. Maximum absolute deviation between Method A and Method B.\n    max_deviation = 0.0\n    for E_test in E_grid_test:\n        v_a = delta_V_A(E_test, EF, W0, d, s)\n        v_b = delta_V_B(E_test, EF, W0, d, s)\n        deviation = abs(v_a - v_b)\n        if deviation > max_deviation:\n            max_deviation = deviation\n    val3 = max_deviation\n    results.append(val3)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3567524"}, {"introduction": "Fitting optical model potentials to experimental data can often result in multiple, distinct sets of parameters that describe the data equally well, a phenomenon known as multimodal posteriors. This advanced practice simulates a common challenge in nuclear science: designing new experiments to resolve such ambiguities. You will implement a greedy algorithm to select a minimal set of spin observable measurements that can statistically discriminate between competing parameter \"islands,\" demonstrating how computational models are used to optimize and guide future experimental campaigns [@problem_id:3567510].", "problem": "Consider elastic nucleon–nucleus scattering in the nonrelativistic limit governed by the time-independent Schrödinger equation with a complex, local optical model potential. Let the optical model potential be parameterized by a small set of effective strengths collected in a vector $\\boldsymbol{\\theta} = (V, W, V_{\\mathrm{so}})$, representing, respectively, an effective real central depth, an effective imaginary strength, and an effective spin–orbit strength. In a global optical model analysis, one introduces explicit energy dependence through parameterizations, whereas in local fits one estimates $\\boldsymbol{\\theta}$ at fixed projectile energy and target. This problem considers a computational design task: given a multimodal posterior distribution over $\\boldsymbol{\\theta}$ (multiple well-separated islands in parameter space), select a minimal set of spin observables and projectile energies that, when measured at specified laboratory scattering angles, yields sufficient statistical discrimination between all competing islands.\n\nFoundational starting points are as follows.\n\n- The complex optical model potential enters the Schrödinger equation and induces an $S$-matrix whose elements determine laboratory observables such as the unpolarized differential cross section, the vector analyzing power, and the spin-rotation function. These observables are differentiable functionals of the potential strengths.\n- For small perturbations in $\\boldsymbol{\\theta}$ around a nominal value, a first-order linearization is appropriate: a scalar observable $y$ admits $y(\\boldsymbol{\\theta}) \\approx y(\\boldsymbol{\\mu}) + \\boldsymbol{J}(\\boldsymbol{\\mu}) \\cdot (\\boldsymbol{\\theta} - \\boldsymbol{\\mu})$, where $\\boldsymbol{\\mu}$ is a reference parameter and $\\boldsymbol{J}$ is the gradient with respect to $\\boldsymbol{\\theta}$.\n- If $\\boldsymbol{\\theta}$ has covariance $\\boldsymbol{\\Sigma}$ and the measurement has independent Gaussian noise of variance $\\sigma_{\\mathrm{meas}}^2$, then the predictive variance of the linearized observable is $s^2 = \\boldsymbol{J}\\,\\boldsymbol{\\Sigma}\\,\\boldsymbol{J}^\\top + \\sigma_{\\mathrm{meas}}^2$.\n- For two competing islands $i$ and $j$ producing one-dimensional Gaussian predictive distributions $\\mathcal{N}(\\mu_i,s_i^2)$ and $\\mathcal{N}(\\mu_j,s_j^2)$, a discriminability measure that increases with separability is the Bhattacharyya distance,\n$$\nD_B^{(1\\mathrm{D})}(i,j) = \\frac{1}{4}\\ln\\!\\left(\\frac{1}{4}\\left(\\frac{s_i^2}{s_j^2} + \\frac{s_j^2}{s_i^2} + 2\\right)\\right)\n+ \\frac{1}{4}\\frac{(\\mu_i - \\mu_j)^2}{s_i^2 + s_j^2}.\n$$\n- For a set of independent measurements, additivity holds under this approximation, so the cumulative distance for a pair $(i,j)$ is the sum over chosen measurement channels.\n\nTo keep the computation self-contained, approximate the map from $(\\boldsymbol{\\theta}, E, \\vartheta_{\\mathrm{lab}})$ to laboratory observables via the following smooth surrogate functions, which reflect qualitative sensitivity patterns of local versus global optical model potentials and are differentiable in $\\boldsymbol{\\theta}$. Let $E$ denote the projectile kinetic energy in megaelectronvolts (MeV), and let $\\vartheta_{\\mathrm{lab}}$ denote the laboratory scattering angle in degrees. Define $x = \\cos(\\vartheta_{\\mathrm{lab}} \\times \\pi/180)$, $s_v(E) = 1/(1 + E/E_v)$ with $E_v = 80$, and $s_w(E) = E/(E + E_w)$ with $E_w = 40$. Let $V_{\\mathrm{eff}} = V\\,s_v(E)$ and $W_{\\mathrm{eff}} = W\\,s_w(E)$. For the unpolarized differential cross section (normalized to a convenient scale) $\\sigma$, the vector analyzing power $A_y$, and the spin-rotation function $Q$, use\n- $\\sigma(\\boldsymbol{\\theta};E,\\vartheta_{\\mathrm{lab}}) = 1 + 10^{-3}\\!\\left(V_{\\mathrm{eff}}^2 + 0.5\\,W_{\\mathrm{eff}}^2\\right) + 5\\cdot 10^{-4}\\,P_2(x)\\,V_{\\mathrm{eff}}W_{\\mathrm{eff}}$, where $P_2(x) = (3x^2 - 1)/2$,\n- $A_y(\\boldsymbol{\\theta};E,\\vartheta_{\\mathrm{lab}}) = \\tanh\\!\\left( \\kappa(E)\\,V_{\\mathrm{so}}\\,\\sin(\\vartheta_{\\mathrm{lab}}\\times \\pi/180)\\,\\big(1 + 2\\cdot 10^{-3}V_{\\mathrm{eff}} - 10^{-3}W_{\\mathrm{eff}}\\big) \\right)$ with $\\kappa(E) = 0.01 + 0.4\\,E/(E+50)$,\n- $Q(\\boldsymbol{\\theta};E,\\vartheta_{\\mathrm{lab}}) = \\tanh\\!\\left( q_0(E)\\,V_{\\mathrm{so}}\\,x + 10^{-4}\\,q_1(E)\\,V_{\\mathrm{eff}}W_{\\mathrm{eff}}\\,x \\right)$ with $q_0(E) = 0.002\\,E$ and $q_1(E) = 0.5$.\n\nAssume that the multimodal posterior is represented by $K$ islands, each approximated locally by a multivariate normal distribution $\\mathcal{N}(\\boldsymbol{\\mu}_k,\\boldsymbol{\\Sigma}_k)$ in the parameter space of $\\boldsymbol{\\theta}$. For each candidate measurement channel $m$ consisting of a choice of observable, energy, and laboratory angle, you will:\n- evaluate the surrogate mean $\\mu_k^{(m)} = y(\\boldsymbol{\\mu}_k)$ for $k \\in \\{1,\\dots,K\\}$,\n- estimate the Jacobian row vector $\\boldsymbol{J}_k^{(m)}$ at $\\boldsymbol{\\mu}_k$ by central finite differences,\n- compute the predictive variance $s_{k}^{2\\,(m)} = \\boldsymbol{J}_k^{(m)}\\,\\boldsymbol{\\Sigma}_k\\,(\\boldsymbol{J}_k^{(m)})^\\top + \\sigma_{\\mathrm{meas}}^2$ with a specified measurement noise variance $\\sigma_{\\mathrm{meas}}^2$ dependent on the observable but independent of $E$ and $\\vartheta_{\\mathrm{lab}}$,\n- compute the Bhattacharyya distance $D_B^{(1\\mathrm{D})}(i,j\\mid m)$ between all island pairs $(i,j)$ for the channel $m$.\n\nLet $\\mathcal{M}$ denote the set of candidate channels. The design problem is to find a smallest-cardinality subset $S \\subseteq \\mathcal{M}$ such that, for every unordered pair $(i,j)$ with $i \\neq j$, the cumulative distance $\\sum_{m \\in S} D_B^{(1\\mathrm{D})}(i,j\\mid m)$ is at least a specified threshold $T$. If no such subset exists, return an indicator for impossibility.\n\nYou must implement a greedy selection strategy that, starting from the empty set, iteratively adds the channel $m \\in \\mathcal{M}$ that maximizes the total reduction of the remaining deficits $\\max\\{0, T - \\sum_{m' \\in S} D_B^{(1\\mathrm{D})}(i,j\\mid m')\\}$ summed over all island pairs. The iteration stops when all pairs meet or exceed the threshold $T$, or when no further improvement is possible. The finite-difference step sizes in the parameter directions should be constant and chosen to be small but numerically stable.\n\nYour program must use the following test suite. In all cases, angles are in degrees, energies are in megaelectronvolts (MeV), and the measurement noise standard deviations are constant per observable. Use zero-based indexing for channels, where the channel index $j$ for a triple $(e,o,a)$ with energy index $e$, observable index $o$, and angle index $a$ is given by\n$$\nj = e\\cdot (N_O\\,N_A) + o\\cdot N_A + a,\n$$\nwith $N_E = 3$, $N_O = 3$, and $N_A = 3$. The energies, observables, and angles are ordered as follows:\n- energies: $[12.0, 25.0, 45.0]$ MeV,\n- observables: $[\\sigma, A_y, Q]$,\n- angles: $[30.0, 60.0, 120.0]$ degrees.\n\nMeasurement noise standard deviations are:\n- $\\sigma_{\\mathrm{meas}}(\\sigma) = 0.05$,\n- $\\sigma_{\\mathrm{meas}}(A_y) = 0.03$,\n- $\\sigma_{\\mathrm{meas}}(Q) = 0.03$.\n\nFor each test case, specify the islands and the threshold $T$.\n\n- Test case $1$ (three-island discrimination):\n  - $\\boldsymbol{\\mu}_1 = (50.0, 6.0, 5.0)$, $\\boldsymbol{\\Sigma}_1 = \\mathrm{diag}(2.0^2, 0.8^2, 0.5^2)$,\n  - $\\boldsymbol{\\mu}_2 = (56.0, 7.5, 6.0)$, $\\boldsymbol{\\Sigma}_2 = \\mathrm{diag}(2.5^2, 1.0^2, 0.5^2)$,\n  - $\\boldsymbol{\\mu}_3 = (48.0, 9.0, 3.5)$, $\\boldsymbol{\\Sigma}_3 = \\mathrm{diag}(1.5^2, 0.7^2, 0.4^2)$,\n  - threshold $T = 2.0$.\n- Test case $2$ (widely separated two islands):\n  - $\\boldsymbol{\\mu}_1 = (50.0, 7.0, 5.0)$, $\\boldsymbol{\\Sigma}_1 = \\mathrm{diag}(1.5^2, 0.6^2, 0.4^2)$,\n  - $\\boldsymbol{\\mu}_2 = (65.0, 12.0, 8.0)$, $\\boldsymbol{\\Sigma}_2 = \\mathrm{diag}(1.5^2, 0.6^2, 0.4^2)$,\n  - threshold $T = 1.0$.\n- Test case $3$ (degenerate islands, impossible design):\n  - $\\boldsymbol{\\mu}_1 = (55.0, 8.0, 6.0)$, $\\boldsymbol{\\Sigma}_1 = \\mathrm{diag}(1.0^2, 0.5^2, 0.4^2)$,\n  - $\\boldsymbol{\\mu}_2 = (55.0, 8.0, 6.0)$, $\\boldsymbol{\\Sigma}_2 = \\mathrm{diag}(1.0^2, 0.5^2, 0.4^2)$,\n  - threshold $T = 0.5$.\n\nImplementation requirements:\n- Use central finite differences with step sizes $(h_V,h_W,h_{V_{\\mathrm{so}}}) = (0.1, 0.1, 0.05)$ for numerical Jacobians.\n- Treat each island’s predictive distribution at a channel as univariate Gaussian with the mean and variance specified above.\n- Apply the greedy selection until either all unordered island pairs satisfy the threshold or no further improvement occurs. If the latter, return the integer $-1$ as the result for that test case.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output either a list of selected channel indices in strictly increasing order (zero-based) or the integer $-1$ if no feasible set exists. For example, a valid overall output might look like $[[0,5], [7], -1]$.\n\nAll answers that involve angles must use degrees, all energies must be interpreted in megaelectronvolts (MeV), and the only accepted output units are index integers as specified. The final program must be complete, deterministic, and require no user input.", "solution": "The problem requires the design and implementation of a greedy algorithm to select a minimal set of experiments for discriminating between different parameter sets (islands) in a nuclear optical model analysis. The selection is based on maximizing the statistical separability, quantified by the Bhattacharyya distance, between predictions for various spin observables. The analysis proceeds in three main stages: defining the physical and statistical model, pre-calculating the discriminative power of each possible experiment, and iteratively selecting experiments using a greedy strategy.\n\nFirst, we establish the mathematical framework. The optical model potential is parameterized by a vector $\\boldsymbol{\\theta} = (V, W, V_{\\mathrm{so}})$. The observables depend on $\\boldsymbol{\\theta}$, the projectile energy $E$, and the laboratory scattering angle $\\vartheta_{\\mathrm{lab}}$. This dependence is given by surrogate functions. Let $x = \\cos(\\vartheta_{\\mathrm{lab}} \\pi/180)$, $s_v(E) = 1/(1 + E/E_v)$ with $E_v = 80$, and $s_w(E) = E/(E + E_w)$ with $E_w = 40$. The effective potential depths are $V_{\\mathrm{eff}} = V s_v(E)$ and $W_{\\mathrm{eff}} = W s_w(E)$. The observables—unpolarized differential cross section $\\sigma$, vector analyzing power $A_y$, and spin-rotation function $Q$—are given by:\n- $\\sigma(\\boldsymbol{\\theta};E,\\vartheta_{\\mathrm{lab}}) = 1 + 10^{-3}(V_{\\mathrm{eff}}^2 + 0.5 W_{\\mathrm{eff}}^2) + 5 \\cdot 10^{-4} P_2(x) V_{\\mathrm{eff}} W_{\\mathrm{eff}}$, where $P_2(x) = (3x^2 - 1)/2$.\n- $A_y(\\boldsymbol{\\theta};E,\\vartheta_{\\mathrm{lab}}) = \\tanh( \\kappa(E) V_{\\mathrm{so}} \\sin(\\vartheta_{\\mathrm{lab}}\\pi/180)(1 + 2 \\cdot 10^{-3}V_{\\mathrm{eff}} - 10^{-3}W_{\\mathrm{eff}}) )$ with $\\kappa(E) = 0.01 + 0.4 E/(E+50)$.\n- $Q(\\boldsymbol{\\theta};E,\\vartheta_{\\mathrm{lab}}) = \\tanh( q_0(E) V_{\\mathrm{so}} x + 10^{-4} q_1(E) V_{\\mathrm{eff}} W_{\\mathrm{eff}} x )$ with $q_0(E) = 0.002 E$ and $q_1(E) = 0.5$.\n\nThe posterior distribution over $\\boldsymbol{\\theta}$ is described by $K$ distinct islands, each modeled as a multivariate normal distribution $\\mathcal{N}(\\boldsymbol{\\mu}_k, \\boldsymbol{\\Sigma}_k)$ for $k \\in \\{1, \\dots, K\\}$. For a given measurement channel $m$ (a specific observable at a specific energy and angle), the predicted observable value for island $k$ is also a normal distribution. Its mean $\\mu_k^{(m)}$ and variance $s_k^{2(m)}$ are found using a first-order Taylor expansion (linearization). The mean is simply the surrogate function evaluated at the island's center: $\\mu_k^{(m)} = y(\\boldsymbol{\\mu}_k)$. The variance is calculated by propagating the parameter covariance $\\boldsymbol{\\Sigma}_k$ through the linearized model and adding the measurement noise variance $\\sigma_{\\mathrm{meas}}^2$:\n$$s_k^{2(m)} = \\boldsymbol{J}_k^{(m)} \\boldsymbol{\\Sigma}_k (\\boldsymbol{J}_k^{(m)})^\\top + \\sigma_{\\mathrm{meas}}^{2(m)}$$\nwhere $\\boldsymbol{J}_k^{(m)}$ is the Jacobian row vector of the observable function $y$ with respect to $\\boldsymbol{\\theta}$, evaluated at $\\boldsymbol{\\mu}_k$. This Jacobian is estimated numerically using central finite differences with specified step sizes $\\boldsymbol{h} = (h_V, h_W, h_{V_{\\mathrm{so}}})$. For example, the first component is $(\\partial y/\\partial V) \\approx (y(\\boldsymbol{\\mu}_k + (h_V,0,0)) - y(\\boldsymbol{\\mu}_k - (h_V,0,0)))/(2h_V)$.\n\nThe statistical distinguishability between any two islands $i$ and $j$ for a single channel $m$ is measured by the Bhattacharyya distance for one-dimensional normal distributions $\\mathcal{N}(\\mu_i^{(m)}, s_i^{2(m)})$ and $\\mathcal{N}(\\mu_j^{(m)}, s_j^{2(m)})$:\n$$D_B^{(1\\mathrm{D})}(i,j \\mid m) = \\frac{1}{4}\\ln\\left(\\frac{1}{4}\\left(\\frac{s_i^{2(m)}}{s_j^{2(m)}} + \\frac{s_j^{2(m)}}{s_i^{2(m)}} + 2\\right)\\right) + \\frac{1}{4}\\frac{(\\mu_i^{(m)} - \\mu_j^{(m)})^2}{s_i^{2(m)} + s_j^{2(m)}}$$\nFor a set of independent measurements $S$, the total distance is the sum $\\sum_{m \\in S} D_B^{(1\\mathrm{D})}(i, j \\mid m)$.\n\nThe core of the problem is to solve a set-cover type optimization problem using a greedy algorithm. The goal is to find the smallest set of measurement channels $S$ such that the cumulative Bhattacharyya distance for every pair of islands $(i,j)$ with $i \\neq j$ meets or exceeds a specified threshold $T$. The algorithm proceeds as follows:\n1. Initialize the selected set $S = \\emptyset$ and the cumulative distance for all pairs $(i,j)$ to $D_{ij}^{\\text{cumulative}} = 0$.\n2. For efficiency, pre-compute and store the Bhattacharyya distance $D_B(i,j \\mid m)$ for all unordered pairs $(i, j)$ and all available measurement channels $m \\in \\mathcal{M}$.\n3. In each iteration, identify the set of pairs that have not yet met the threshold: $\\{(i,j) \\mid D_{ij}^{\\text{cumulative}} < T\\}$. If this set is empty, the task is complete.\n4. If unsatisfied pairs remain, calculate the current deficit for each pair, $d_{ij} = \\max(0, T - D_{ij}^{\\text{cumulative}})$.\n5. Select the next best channel $m^* \\notin S$ by finding the one that provides the maximum total reduction in deficits across all unsatisfied pairs. The reduction provided by a channel $m$ is calculated as $\\sum_{i<j} \\min(D_B(i,j \\mid m), d_{ij})$.\n6. Add the best channel $m^*$ to the set $S$. Update the cumulative distances $D_{ij}^{\\text{cumulative}}$ for all pairs by adding the contribution from $m^*$.\n7. Repeat from step 3. The process terminates when all pairs satisfy the threshold $T$, or when no available channel can provide any further positive deficit reduction. In the latter case, if any pair is still below the threshold, the design is deemed impossible, and the result is $-1$. Otherwise, the result is the sorted list of indices of the channels in $S$.\n\nThe set of candidate channels $\\mathcal{M}$ is constructed from $N_E=3$ energies, $N_O=3$ observables, and $N_A=3$ angles, for a total of $N_E N_O N_A = 27$ channels. A unique zero-based index for each channel is defined as $j = e \\cdot (N_O N_A) + o \\cdot N_A + a$, where $e, o, a$ are the indices for energy, observable, and angle, respectively. This systematic procedure provides a deterministic method for constructing the optimal experimental design under the greedy-choice heuristic.", "answer": "```python\nimport numpy as np\nimport itertools\n\ndef solve():\n    \"\"\"\n    Main function to solve the experimental design problem for all test cases.\n    \"\"\"\n    # Problem constants\n    E_v = 80.0\n    E_w = 40.0\n    h_steps = np.array([0.1, 0.1, 0.05])  # (h_V, h_W, h_Vso)\n\n    # Candidate measurement channels\n    energies = np.array([12.0, 25.0, 45.0])\n    angles_deg = np.array([30.0, 60.0, 120.0])\n    observables = ['sigma', 'Ay', 'Q']\n    \n    # Noise variances (sigma^2)\n    noise_variances = {\n        'sigma': 0.05**2,\n        'Ay': 0.03**2,\n        'Q': 0.03**2\n    }\n\n    # Test cases\n    test_cases = [\n        {\n            \"islands\": [\n                {\"mu\": np.array([50.0, 6.0, 5.0]), \"Sigma\": np.diag([2.0**2, 0.8**2, 0.5**2])},\n                {\"mu\": np.array([56.0, 7.5, 6.0]), \"Sigma\": np.diag([2.5**2, 1.0**2, 0.5**2])},\n                {\"mu\": np.array([48.0, 9.0, 3.5]), \"Sigma\": np.diag([1.5**2, 0.7**2, 0.4**2])},\n            ],\n            \"T\": 2.0\n        },\n        {\n            \"islands\": [\n                {\"mu\": np.array([50.0, 7.0, 5.0]), \"Sigma\": np.diag([1.5**2, 0.6**2, 0.4**2])},\n                {\"mu\": np.array([65.0, 12.0, 8.0]), \"Sigma\": np.diag([1.5**2, 0.6**2, 0.4**2])},\n            ],\n            \"T\": 1.0\n        },\n        {\n            \"islands\": [\n                {\"mu\": np.array([55.0, 8.0, 6.0]), \"Sigma\": np.diag([1.0**2, 0.5**2, 0.4**2])},\n                {\"mu\": np.array([55.0, 8.0, 6.0]), \"Sigma\": np.diag([1.0**2, 0.5**2, 0.4**2])},\n            ],\n            \"T\": 0.5\n        }\n    ]\n\n    # --- Surrogate Functions ---\n    def get_surrogate_funcs():\n        def s_v(E): return 1.0 / (1.0 + E / E_v)\n        def s_w(E): return E / (E + E_w)\n        def P2(x): return (3.0 * x**2 - 1.0) / 2.0\n        def kappa(E): return 0.01 + 0.4 * E / (E + 50.0)\n        def q0(E): return 0.002 * E\n        def q1(E): return 0.5\n\n        def sigma_func(theta, E, theta_lab_deg):\n            V, W, _ = theta\n            x = np.cos(np.deg2rad(theta_lab_deg))\n            V_eff = V * s_v(E)\n            W_eff = W * s_w(E)\n            return 1.0 + 1e-3 * (V_eff**2 + 0.5 * W_eff**2) + 5e-4 * P2(x) * V_eff * W_eff\n\n        def Ay_func(theta, E, theta_lab_deg):\n            V, W, V_so = theta\n            theta_lab_rad = np.deg2rad(theta_lab_deg)\n            V_eff = V * s_v(E)\n            W_eff = W * s_w(E)\n            arg = kappa(E) * V_so * np.sin(theta_lab_rad) * (1.0 + 2e-3 * V_eff - 1e-3 * W_eff)\n            return np.tanh(arg)\n\n        def Q_func(theta, E, theta_lab_deg):\n            V, W, V_so = theta\n            x = np.cos(np.deg2rad(theta_lab_deg))\n            V_eff = V * s_v(E)\n            W_eff = W * s_w(E)\n            arg = q0(E) * V_so * x + 1e-4 * q1(E) * V_eff * W_eff * x\n            return np.tanh(arg)\n            \n        return {'sigma': sigma_func, 'Ay': Ay_func, 'Q': Q_func}\n\n    surrogate_funcs = get_surrogate_funcs()\n\n    def calculate_jacobian(func, theta, E, theta_lab_deg):\n        J = np.zeros(3)\n        for i in range(3):\n            h_vec = np.zeros(3)\n            h_vec[i] = h_steps[i]\n            y_plus = func(theta + h_vec, E, theta_lab_deg)\n            y_minus = func(theta - h_vec, E, theta_lab_deg)\n            J[i] = (y_plus - y_minus) / (2 * h_steps[i])\n        return J\n\n    def bhattacharyya_dist(mu1, s1_sq, mu2, s2_sq):\n        if s1_sq <= 0 or s2_sq <= 0: return 0.0 # Should not happen with noise\n        term1_inner = 0.25 * (s1_sq / s2_sq + s2_sq / s1_sq + 2.0)\n        term1 = 0.25 * np.log(term1_inner)\n        term2 = 0.25 * (mu1 - mu2)**2 / (s1_sq + s2_sq)\n        return term1 + term2\n\n    results = []\n    \n    N_E, N_O, N_A = len(energies), len(observables), len(angles_deg)\n    num_channels = N_E * N_O * N_A\n    \n    for case in test_cases:\n        islands = case[\"islands\"]\n        T = case[\"T\"]\n        K = len(islands)\n        island_pairs = list(itertools.combinations(range(K), 2))\n        num_pairs = len(island_pairs)\n\n        # Pre-compute Bhattacharyya distances for all channels and pairs\n        db_distances = np.zeros((num_pairs, num_channels))\n\n        for e_idx, E in enumerate(energies):\n            for o_idx, obs_name in enumerate(observables):\n                for a_idx, angle in enumerate(angles_deg):\n                    channel_idx = e_idx * (N_O * N_A) + o_idx * N_A + a_idx\n                    \n                    obs_func = surrogate_funcs[obs_name]\n                    noise_var = noise_variances[obs_name]\n                    \n                    # Calculate predicted means and variances for this channel for all islands\n                    means = np.zeros(K)\n                    variances = np.zeros(K)\n                    for k in range(K):\n                        mu_k = islands[k][\"mu\"]\n                        Sigma_k = islands[k][\"Sigma\"]\n                        \n                        means[k] = obs_func(mu_k, E, angle)\n                        J_k = calculate_jacobian(obs_func, mu_k, E, angle)\n                        variances[k] = J_k @ Sigma_k @ J_k.T + noise_var\n                        \n                    # Calculate DB for all pairs for this channel\n                    for p_idx, (i, j) in enumerate(island_pairs):\n                        if np.allclose(islands[i]['mu'], islands[j]['mu']) and np.allclose(islands[i]['Sigma'], islands[j]['Sigma']):\n                            db = 0.0\n                        else:\n                            db = bhattacharyya_dist(means[i], variances[i], means[j], variances[j])\n                        db_distances[p_idx, channel_idx] = db\n        \n        # Greedy selection\n        selected_channels = []\n        available_channels = list(range(num_channels))\n        cumulative_distances = np.zeros(num_pairs)\n        \n        while True:\n            deficits = T - cumulative_distances\n            unsatisfied_mask = deficits > 1e-9 # Use a small epsilon for float comparison\n            \n            if not np.any(unsatisfied_mask):\n                break\n\n            best_channel = -1\n            max_reduction = -1.0\n            \n            for channel_idx in available_channels:\n                current_reduction = 0.0\n                for p_idx in range(num_pairs):\n                    if unsatisfied_mask[p_idx]:\n                        contribution = db_distances[p_idx, channel_idx]\n                        current_reduction += min(contribution, deficits[p_idx])\n                \n                if current_reduction > max_reduction:\n                    max_reduction = current_reduction\n                    best_channel = channel_idx\n\n            if max_reduction <= 1e-9: # No improvement possible\n                break\n            \n            selected_channels.append(best_channel)\n            available_channels.remove(best_channel)\n            \n            for p_idx in range(num_pairs):\n                cumulative_distances[p_idx] += db_distances[p_idx, best_channel]\n\n        final_deficits = T - cumulative_distances\n        if np.any(final_deficits > 1e-9):\n            results.append(-1)\n        else:\n            results.append(sorted(selected_channels))\n\n    # Format output\n    final_results_str = []\n    for res in results:\n        if res == -1:\n            final_results_str.append(\"-1\")\n        else:\n            res_str = f\"[{','.join(map(str, res))}]\"\n            final_results_str.append(res_str)\n            \n    print(f\"[{','.join(final_results_str)}]\")\n\nsolve()\n```", "id": "3567510"}]}