{"hands_on_practices": [{"introduction": "To build a solid foundation, we begin with an analytical exercise that illuminates the core of the Rayleigh-Ritz method. This problem explores the exactly solvable harmonic oscillator but introduces a crucial twist: the trial subspace is constructed from basis functions of a different harmonic oscillator potential with frequency $\\Omega$ instead of the physical frequency $\\omega$. By calculating the variational energy, you will gain a quantitative understanding of how the accuracy of the Rayleigh-Ritz approximation directly depends on the suitability of the chosen basis, a key concept in all variational calculations [@problem_id:3610839].", "problem": "In computational nuclear physics, the variational characterization of the ground-state energy of a self-adjoint Hamiltonian $h$ is given by the Rayleigh quotient $R[\\psi] = \\langle \\psi | h | \\psi \\rangle / \\langle \\psi | \\psi \\rangle$, and the Rayleigh-Ritz (RR) method approximates the ground state by minimizing $R[\\psi]$ over a finite-dimensional subspace. Consider a one-body Hamiltonian in one Cartesian dimension,\n$$\nh = \\frac{p^{2}}{2 m} + \\frac{1}{2} m \\omega^{2} x^{2},\n$$\nwith mass $m$, reference frequency parameter $\\Omega$ used to build a Harmonic Oscillator (HO) basis, and physical frequency $\\omega$ defining $h$. Let $\\{ \\phi_{0}(x;\\Omega), \\phi_{1}(x;\\Omega) \\}$ denote the first two normalized HO eigenfunctions of the reference Hamiltonian\n$$\nh_{\\Omega} = \\frac{p^{2}}{2 m} + \\frac{1}{2} m \\Omega^{2} x^{2}.\n$$\nUsing only the canonical commutation relation $[x,p] = i \\hbar$ and the orthonormality and ladder-operator structure of the HO basis states of $h_{\\Omega}$, construct the $2 \\times 2$ matrix representation of $h$ in the subspace spanned by $\\{ \\phi_{0}, \\phi_{1} \\}$ and determine the minimal Rayleigh quotient over this subspace, i.e., the smallest eigenvalue of the projected Hamiltonian. The exact ground-state energy of $h$ is $E_{0} = \\frac{1}{2} \\hbar \\omega$. Provide your comparison in the form of the fractional error\n$$\n\\frac{E_{\\mathrm{var}} - E_{0}}{E_{0}},\n$$\nwhere $E_{\\mathrm{var}}$ is the minimal Rayleigh quotient in the specified subspace. Express your final answer as a single closed-form analytic expression in terms of $\\Omega$ and $\\omega$. No numerical rounding is required, and since this quantity is dimensionless, no units are to be reported.", "solution": "The problem statement has been meticulously reviewed and is determined to be valid. It is scientifically grounded in the principles of quantum mechanics, specifically the harmonic oscillator and the Rayleigh-Ritz variational method. It is well-posed, objective, and contains all necessary information for a unique solution.\n\nThe task is to find the lowest-energy variational approximation, $E_{\\mathrm{var}}$, for a harmonic oscillator Hamiltonian $h$ within a two-state trial space, and then to compute the fractional error relative to the exact ground-state energy, $E_0$.\n\nThe Hamiltonian of the physical system is given by:\n$$\nh = \\frac{p^{2}}{2 m} + \\frac{1}{2} m \\omega^{2} x^{2}\n$$\nThe variational subspace is spanned by the first two orthonormal eigenfunctions, $\\{ \\phi_{0}, \\phi_{1} \\}$, of a reference harmonic oscillator Hamiltonian, $h_{\\Omega}$:\n$$\nh_{\\Omega} = \\frac{p^{2}}{2 m} + \\frac{1}{2} m \\Omega^{2} x^{2}\n$$\nThe eigenfunctions $\\phi_n \\equiv \\phi_n(x; \\Omega)$ satisfy $h_{\\Omega} \\phi_n = E_n^{(\\Omega)} \\phi_n$, with eigenvalues $E_n^{(\\Omega)} = (n + \\frac{1}{2})\\hbar\\Omega$.\n\nThe Rayleigh-Ritz method requires us to construct the matrix representation of the Hamiltonian $h$ in the basis $\\{ \\phi_{0}, \\phi_{1} \\}$ and find its lowest eigenvalue. This eigenvalue corresponds to the minimal Rayleigh quotient, $E_{\\mathrm{var}}$. The matrix elements are $H_{ij} = \\langle \\phi_i | h | \\phi_j \\rangle$.\n\nTo simplify the calculation of the matrix elements, we can express $h$ in terms of $h_{\\Omega}$:\n$$\nh = h_{\\Omega} - \\frac{1}{2} m \\Omega^{2} x^{2} + \\frac{1}{2} m \\omega^{2} x^{2} = h_{\\Omega} + \\frac{1}{2} m (\\omega^{2} - \\Omega^{2}) x^{2}\n$$\nThe matrix elements are therefore:\n$$\nH_{ij} = \\langle \\phi_i | h_{\\Omega} + \\frac{1}{2} m (\\omega^{2} - \\Omega^{2}) x^{2} | \\phi_j \\rangle\n$$\nUsing the fact that $\\phi_j$ are eigenfunctions of $h_{\\Omega}$ and the basis is orthonormal ($\\langle \\phi_i | \\phi_j \\rangle = \\delta_{ij}$):\n$$\nH_{ij} = \\langle \\phi_i | E_j^{(\\Omega)} | \\phi_j \\rangle + \\frac{1}{2} m (\\omega^{2} - \\Omega^{2}) \\langle \\phi_i | x^{2} | \\phi_j \\rangle\n$$\n$$\nH_{ij} = E_j^{(\\Omega)} \\delta_{ij} + \\frac{1}{2} m (\\omega^{2} - \\Omega^{2}) \\langle \\phi_i | x^{2} | \\phi_j \\rangle\n$$\nThe eigenfunctions of the harmonic oscillator have definite parity: $\\phi_n(-x) = (-1)^n \\phi_n(x)$. Thus, $\\phi_0$ is an even function and $\\phi_1$ is an odd function. The operator $x^2$ is an even operator, as $x^2 = (-x)^2$. The matrix element $\\langle \\phi_i | x^2 | \\phi_j \\rangle$ involves an integral of the form $\\int \\phi_i^*(x) x^2 \\phi_j(x) dx$. For the off-diagonal elements ($i \\neq j$), the integrand is a product of an even function ($\\phi_0$), an even function ($x^2$), and an odd function ($\\phi_1$). The overall integrand is odd, and its integral over symmetric limits $(-\\infty, \\infty)$ is zero.\nTherefore, $\\langle \\phi_0 | x^{2} | \\phi_1 \\rangle = 0$ and $\\langle \\phi_1 | x^{2} | \\phi_0 \\rangle = 0$.\nThis implies that the matrix representation of $h$ in this basis is diagonal:\n$$\nH = \\begin{pmatrix} H_{00}  0 \\\\ 0  H_{11} \\end{pmatrix}\n$$\nThe eigenvalues are simply the diagonal elements, $H_{00}$ and $H_{11}$. We must now compute these elements. This requires the expectation values $\\langle \\phi_0 | x^2 | \\phi_0 \\rangle$ and $\\langle \\phi_1 | x^2 | \\phi_1 \\rangle$. We use the ladder operator formalism for the reference Hamiltonian $h_{\\Omega}$. The position operator $x$ is expressed in terms of the annihilation ($a$) and creation ($a^{\\dagger}$) operators:\n$$\nx = \\sqrt{\\frac{\\hbar}{2 m \\Omega}}(a + a^{\\dagger})\n$$\nSquaring this gives:\n$$\nx^{2} = \\frac{\\hbar}{2 m \\Omega} (a + a^{\\dagger})^{2} = \\frac{\\hbar}{2 m \\Omega} (a^2 + (a^{\\dagger})^2 + a a^{\\dagger} + a^{\\dagger} a)\n$$\nUsing the commutation relation $[a, a^{\\dagger}] = 1$, we can write $a a^{\\dagger} = a^{\\dagger} a + 1$. The number operator is $N = a^{\\dagger} a$.\n$$\nx^{2} = \\frac{\\hbar}{2 m \\Omega} (a^2 + (a^{\\dagger})^2 + 2N + 1)\n$$\nWe now compute the expectation values. Note that $\\langle \\phi_n | a^2 | \\phi_n \\rangle = 0$ and $\\langle \\phi_n | (a^{\\dagger})^2 | \\phi_n \\rangle = 0$ due to orthogonality.\nFor the state $\\phi_0$ ($n=0$):\n$$\n\\langle \\phi_0 | x^2 | \\phi_0 \\rangle = \\frac{\\hbar}{2 m \\Omega} \\langle \\phi_0 | 2N + 1 | \\phi_0 \\rangle = \\frac{\\hbar}{2 m \\Omega} (2(0) + 1) = \\frac{\\hbar}{2 m \\Omega}\n$$\nFor the state $\\phi_1$ ($n=1$):\n$$\n\\langle \\phi_1 | x^2 | \\phi_1 \\rangle = \\frac{\\hbar}{2 m \\Omega} \\langle \\phi_1 | 2N + 1 | \\phi_1 \\rangle = \\frac{\\hbar}{2 m \\Omega} (2(1) + 1) = \\frac{3\\hbar}{2 m \\Omega}\n$$\nNow we can construct the diagonal matrix elements of $H$:\n$$\nH_{00} = E_0^{(\\Omega)} + \\frac{1}{2} m (\\omega^{2} - \\Omega^{2}) \\langle \\phi_0 | x^{2} | \\phi_0 \\rangle = \\frac{1}{2}\\hbar\\Omega + \\frac{1}{2} m (\\omega^{2} - \\Omega^{2}) \\frac{\\hbar}{2 m \\Omega}\n$$\n$$\nH_{00} = \\frac{1}{2}\\hbar\\Omega + \\frac{\\hbar(\\omega^{2} - \\Omega^{2})}{4\\Omega} = \\frac{\\hbar}{4\\Omega} [2\\Omega^2 + \\omega^2 - \\Omega^2] = \\frac{\\hbar}{4\\Omega}(\\Omega^2 + \\omega^2)\n$$\nAnd for $H_{11}$:\n$$\nH_{11} = E_1^{(\\Omega)} + \\frac{1}{2} m (\\omega^{2} - \\Omega^{2}) \\langle \\phi_1 | x^{2} | \\phi_1 \\rangle = \\frac{3}{2}\\hbar\\Omega + \\frac{1}{2} m (\\omega^{2} - \\Omega^{2}) \\frac{3\\hbar}{2 m \\Omega}\n$$\n$$\nH_{11} = \\frac{3}{2}\\hbar\\Omega + \\frac{3\\hbar(\\omega^{2} - \\Omega^{2})}{4\\Omega} = \\frac{3\\hbar}{4\\Omega} [2\\Omega^2 + \\omega^2 - \\Omega^2] = \\frac{3\\hbar}{4\\Omega}(\\Omega^2 + \\omega^2)\n$$\nThe eigenvalues of the projected Hamiltonian are $H_{00}$ and $H_{11}$. The minimal Rayleigh quotient, $E_{\\mathrm{var}}$, is the minimum of these two values. Since $\\hbar, \\Omega, \\omega^2, \\Omega^2$ are all positive, $H_{00}  H_{11}$.\nTherefore:\n$$\nE_{\\mathrm{var}} = H_{00} = \\frac{\\hbar}{4\\Omega}(\\Omega^2 + \\omega^2)\n$$\nThe exact ground-state energy of the physical Hamiltonian $h$ is given as $E_0 = \\frac{1}{2} \\hbar \\omega$. We are asked to compute the fractional error:\n$$\n\\frac{E_{\\mathrm{var}} - E_{0}}{E_{0}} = \\frac{E_{\\mathrm{var}}}{E_{0}} - 1\n$$\nSubstituting the expressions for $E_{\\mathrm{var}}$ and $E_0$:\n$$\n\\frac{E_{\\mathrm{var}}}{E_{0}} = \\frac{\\frac{\\hbar}{4\\Omega}(\\Omega^2 + \\omega^2)}{\\frac{1}{2}\\hbar\\omega} = \\frac{\\Omega^2 + \\omega^2}{2\\Omega\\omega}\n$$\nThe fractional error is then:\n$$\n\\frac{E_{\\mathrm{var}} - E_{0}}{E_{0}} = \\frac{\\Omega^2 + \\omega^2}{2\\Omega\\omega} - 1 = \\frac{\\Omega^2 + \\omega^2 - 2\\Omega\\omega}{2\\Omega\\omega} = \\frac{(\\Omega - \\omega)^2}{2\\Omega\\omega}\n$$\nThis result is consistent with the variational theorem, which guarantees $E_{\\mathrm{var}} \\ge E_0$, as the expression is always non-negative. The error vanishes only when $\\Omega = \\omega$, which is the case where the basis state $\\phi_0(x; \\Omega)$ is identical to the true ground state of $h$.", "answer": "$$\n\\boxed{\\frac{(\\Omega - \\omega)^2}{2\\Omega\\omega}}\n$$", "id": "3610839"}, {"introduction": "Moving from analytical theory to practical computation, this exercise guides you through a complete Configuration Interaction (CI) calculation for a two-nucleon system. A fundamental challenge in nuclear structure theory is the appearance of unphysical \"spurious\" states arising from the motion of the center of mass, an artifact of truncating the basis space. In this hands-on coding task [@problem_id:3610851], you will not only construct the many-body Hamiltonian from first principles but also implement and apply the Lawson method, a powerful variational technique to diagnose and filter out this contamination.", "problem": "You will implement a complete Rayleigh–Ritz variational calculation for a two-nucleon system in one spatial dimension to diagnose and variationally filter center-of-mass contamination in a truncated Configuration Interaction (CI) space. Your implementation must be a single, runnable program that constructs the many-body Hamiltonian, computes its lowest eigenstates, evaluates the expectation value of the center-of-mass Hamiltonian for each eigenstate, and applies a variational filter by augmenting the Hamiltonian with a center-of-mass penalty. All steps must start from first principles without using closed-form matrix elements that shortcut the derivations.\n\nThe physical model is as follows. Consider two distinguishable nucleons of mass $m$ moving in one spatial dimension. Adopt natural units with reduced Planck constant $\\hbar = 1$ and mass $m = 1$. The single-particle confining field is a harmonic oscillator with angular frequency $\\omega  0$. The two-body interaction is translationally invariant and depends only on the relative coordinate, taken as a finite-range Gaussian potential of strength $V_0$ and range $a  0$:\n$$\nV(x_1, x_2) = V_0 \\exp\\!\\left(-\\frac{(x_1 - x_2)^2}{2 a^2}\\right).\n$$\nThe full two-body Hamiltonian is\n$$\nH = \\sum_{i=1}^2 \\left(\\frac{p_i^2}{2 m} + \\frac{1}{2} m \\omega^2 x_i^2\\right) + V(x_1, x_2),\n$$\nwith $\\hbar = 1$ and $m = 1$ to be used in all numerical results. The center-of-mass (CM) Hamiltonian in one dimension for $A=2$ particles is\n$$\nH_{\\mathrm{cm}} = \\frac{P_{\\mathrm{cm}}^2}{2 A m} + \\frac{1}{2} A m \\omega^2 R_{\\mathrm{cm}}^2 - \\frac{1}{2}\\,\\omega,\n$$\nwhere $A = 2$, $R_{\\mathrm{cm}} = \\frac{x_1 + x_2}{2}$, and $P_{\\mathrm{cm}} = p_1 + p_2$. The subtraction of $\\frac{1}{2}\\,\\omega$ sets the ground $0S$ center-of-mass mode to zero expectation value. In an exact (untruncated) calculation with a translationally invariant interaction, any eigenstate with a center-of-mass ground component has $\\langle H_{\\mathrm{cm}} \\rangle = 0$, while spurious center-of-mass excitations yield $\\langle H_{\\mathrm{cm}} \\rangle \\approx n_{\\mathrm{cm}} \\,\\omega$ with integer $n_{\\mathrm{cm}} \\ge 1$. In a truncated CI space, spurious mixtures lead to nonzero $\\langle H_{\\mathrm{cm}} \\rangle$ in states that should be free of center-of-mass excitations.\n\nYour computational task is to perform a Rayleigh–Ritz calculation in a truncated CI space and to quantify and filter center-of-mass contamination.\n\n1. Basis and truncation. Use the one-dimensional harmonic oscillator single-particle eigenfunctions $\\{\\varphi_n(x)\\}_{n=0}^{n_{\\max}}$ as your finite basis for each particle, with oscillator length $b = \\sqrt{1/\\omega}$. The two-body CI basis is the direct-product $\\{\\varphi_{n_1}(x_1)\\varphi_{n_2}(x_2)\\}$ with $0 \\le n_1, n_2 \\le n_{\\max}$, which constitutes a truncation by the single-particle maximum quantum number $n_{\\max}$. This truncation does not enforce a fixed total quanta and therefore breaks exact factorization of intrinsic and center-of-mass motion, enabling spurious contamination to appear.\n\n2. Variational principle and Rayleigh–Ritz. Starting from the time-independent Schrödinger equation and the Rayleigh quotient\n$$\n\\mathcal{E}[\\psi] = \\frac{\\langle \\psi| H | \\psi\\rangle}{\\langle \\psi|\\psi\\rangle},\n$$\napply the Rayleigh–Ritz method by expanding trial states $|\\psi\\rangle$ in the truncated CI basis and diagonalizing the Hamiltonian matrix to obtain approximate eigenvalues and eigenvectors.\n\n3. Operator construction. Construct the single-particle position and momentum operators using the canonical commutation relation and ladder operators,\n$$\nx = \\sqrt{\\frac{1}{2 \\omega}}\\,(a + a^\\dagger),\\qquad p = \\mathrm{i}\\sqrt{\\frac{\\omega}{2}}\\,(a^\\dagger - a),\n$$\nthen form $x^2$ and $p^2$ matrices in the truncated single-particle basis by matrix multiplication. Assemble the two-body operators via Kronecker products to form the one-body part of $H$ on the CI basis. For the two-body Gaussian interaction, do not use closed-form matrix elements. Instead, evaluate the matrix elements\n$$\n\\langle n_1 n_2 | V | n_1' n_2' \\rangle = \\int_{-\\infty}^{\\infty}\\!\\!\\int_{-\\infty}^{\\infty} \\varphi_{n_1}(x_1)\\varphi_{n_2}(x_2) V(x_1-x_2) \\varphi_{n_1'}(x_1)\\varphi_{n_2'}(x_2)\\, \\mathrm{d}x_1 \\mathrm{d}x_2\n$$\nnumerically using Gauss–Hermite quadrature with a sufficient number of points to achieve stable results across the provided test cases. You may exploit the polynomial–Gaussian structure of $\\varphi_n$ to use Gauss–Hermite rules that integrate functions of the form $e^{-y^2}$ times a smooth function, taking care to use the correct oscillator length scaling for general $\\omega$.\n\n4. Center-of-mass Hamiltonian. Derive and implement $H_{\\mathrm{cm}}$ in terms of single-particle operators $x_1, x_2, p_1, p_2$ on the CI basis without transforming to relative and center-of-mass coordinates. Then compute $\\langle H_{\\mathrm{cm}} \\rangle$ for each CI eigenstate as a diagnostic of spurious contamination.\n\n5. Variational filtering (Lawson method). Define the penalized Hamiltonian\n$$\nH_\\beta = H + \\beta\\, H_{\\mathrm{cm}},\n$$\nwith penalty parameter $\\beta \\ge 0$. Diagonalize $H_\\beta$ to obtain the lowest eigenstates. Use a threshold $\\tau  0$ and filter out any states with $\\langle H_{\\mathrm{cm}} \\rangle  \\tau$ among the lowest $k$ eigenstates, where $k$ is specified per test case.\n\nImplementation requirements:\n- Adopt units with $\\hbar = 1$ and $m = 1$, so all energies are in units of $\\omega$ and lengths in units of $b = \\sqrt{1/\\omega}$.\n- Angles do not appear, so no angle units are needed.\n- Your program must produce, for each test case, the integer count of eigenstates among the lowest $k$ eigenstates of $H_\\beta$ whose center-of-mass expectation value satisfies $\\langle H_{\\mathrm{cm}} \\rangle \\le \\tau$. Aggregate these counts for all test cases into a single output line as described below.\n\nTest suite. Run your program on the following parameter sets, each specified as a tuple $\\left(n_{\\max}, \\omega, V_0, a, k, \\tau, \\beta\\right)$:\n- Case $1$: $\\left(4,\\, 1.0,\\, -0.6,\\, 0.8,\\, 6,\\, 0.02,\\, 0.0\\right)$\n- Case $2$: $\\left(4,\\, 1.0,\\, -0.6,\\, 0.8,\\, 6,\\, 0.02,\\, 10.0\\right)$\n- Case $3$: $\\left(3,\\, 1.2,\\, -0.6,\\, 0.5,\\, 6,\\, 0.02,\\, 10.0\\right)$\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For the above three cases, the output must be of the form\n$$\n[\\text{count}_1,\\text{count}_2,\\text{count}_3],\n$$\nwhere each $\\text{count}_i$ is an integer as defined above. No other text should be printed. All numerical calculations must be performed by your code; do not hard-code expected values.", "solution": "The user-provided problem is a valid exercise in computational quantum physics. It asks for the implementation of a Rayleigh-Ritz variational calculation for a two-nucleon system within a truncated configuration interaction (CI) space. The problem is scientifically grounded in the principles of quantum mechanics and numerical methods, specifically the shell model and variational techniques. It is well-posed, with all necessary parameters, physical model definitions, and a clear computational objective provided. The specified method of building operators from first principles using ladder operators and numerical quadrature for matrix elements is a standard and instructive approach in the field. The inclusion of center-of-mass contamination diagnosis and the Lawson filtering method makes it a realistic representation of challenges in nuclear structure theory. There are no contradictions, ambiguities, or scientifically unsound premises.\n\nThe solution proceeds as follows:\nFirst, for each test case, we define the parameters of the model: the single-particle basis truncation $n_{\\max}$, harmonic oscillator frequency $\\omega$, interaction strength $V_0$ and range $a$, and the parameters for the Lawson filtering method $k, \\tau, \\beta$. We work in natural units where $\\hbar=1$ and the nucleon mass $m=1$.\n\nThe single-particle basis consists of the eigenstates of the one-dimensional quantum harmonic oscillator (QHO), $\\{|n\\rangle\\}$, truncated at $n=n_{\\max}$. The dimension of this single-particle space is $N_{sp} = n_{\\max}+1$.\n\nThe single-particle operators for position $x$ and momentum $p$ are constructed in this truncated basis. We start with the matrix representations of the ladder operators, $a$ and $a^\\dagger$, defined by their action on the basis states, $\\langle n' | a | n \\rangle = \\sqrt{n}\\,\\delta_{n',n-1}$ and $\\langle n' | a^\\dagger | n \\rangle = \\sqrt{n+1}\\,\\delta_{n',n+1}$. The $x$ and $p$ matrices are then formed using their standard definitions in terms of $a$ and $a^\\dagger$:\n$$\nx = \\sqrt{\\frac{1}{2 \\omega}}\\,(a + a^\\dagger),\\qquad p = \\mathrm{i}\\sqrt{\\frac{\\omega}{2}}\\,(a^\\dagger - a)\n$$\nThe matrices for $x^2$ and $p^2$ are obtained by matrix multiplication of the $x$ and $p$ matrices, respectively. It is important to note that due to the basis truncation, the canonical commutation relation $[x,p]=i$ is not perfectly satisfied, which is an expected artifact of the method.\n\nThe two-body CI basis is a direct product of the single-particle bases: $\\{|n_1 n_2\\rangle = |n_1\\rangle \\otimes |n_2\\rangle\\}$, where $0 \\le n_1, n_2 \\le n_{\\max}$. The dimension of this two-body space is $N_{basis} = N_{sp}^2$. Two-body operators are constructed as Kronecker products of the single-particle operators. For example, $x_1$ is represented by $x \\otimes I$ and $x_2$ by $I \\otimes x$, where $I$ is the identity matrix in the single-particle space.\n\nThe full Hamiltonian $H = H_{1-body} + V$ is constructed in the two-body basis. The one-body part, representing the kinetic energy and harmonic confinement, is formed from the single-particle Hamiltonian matrices $h = p^2/2 + \\omega^2 x^2/2$ as $H_{1-body} = h \\otimes I + I \\otimes h$.\n\nThe matrix elements of the two-body Gaussian interaction, $\\langle n_1 n_2 | V | n_1' n_2' \\rangle$, are calculated numerically using Gauss-Hermite quadrature as specified. The integral is transformed to dimensionless coordinates $y_i = x_i/b$ where $b=\\sqrt{1/\\omega}$ is the oscillator length. The $e^{-y_1^2-y_2^2}$ factor arising from the QHO wavefunctions is absorbed into the quadrature weights, and the remaining smooth function is evaluated at the quadrature points. A sufficiently large number of quadrature points is used to ensure numerical stability and accuracy.\n\nThe center-of-mass Hamiltonian $H_{cm}$ is also constructed in the two-body basis from the single-particle operators, using its definition:\n$$\nH_{\\mathrm{cm}} = \\frac{P_{\\mathrm{cm}}^2}{4} + \\omega^2 R_{\\mathrm{cm}}^2 - \\frac{\\omega}{2}\n$$\nwhere $R_{cm} = (x_1+x_2)/2$ and $P_{cm} = p_1+p_2$.\n\nThe Lawson method is implemented by forming the penalized Hamiltonian $H_\\beta = H + \\beta H_{cm}$. This matrix is diagonalized to find its eigenvalues and eigenvectors. The eigenvectors represent the approximate eigenstates of the system as per the Rayleigh-Ritz method.\n\nFinally, for each of the $k$ lowest-energy eigenstates obtained from diagonalizing $H_\\beta$, we compute the expectation value of the original center-of-mass Hamiltonian, $\\langle H_{cm} \\rangle$. We then count how many of these $k$ states satisfy the condition $\\langle H_{cm} \\rangle \\le \\tau$. This count is the result for one test case. The process is repeated for all cases provided in the test suite.", "answer": "```python\n# language: Python\n# version: 3.12\n# libraries:\n#   name: numpy\n#   version: 1.23.5\n#   name: scipy\n#   version: 1.11.4\n\nimport numpy as np\nfrom scipy.special import roots_hermite, eval_hermite\nfrom scipy.linalg import eigh\nimport math\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the calculation for all test cases.\n    It implements the Rayleigh-Ritz method for a two-nucleon system in a \n    truncated harmonic oscillator basis, including diagnostics and filtering \n    of center-of-mass excitations.\n    \"\"\"\n    \n    # Test suite from the problem statement\n    test_cases = [\n        # (n_max, omega, V0, a, k, tau, beta)\n        (4, 1.0, -0.6, 0.8, 6, 0.02, 0.0),\n        (4, 1.0, -0.6, 0.8, 6, 0.02, 10.0),\n        (3, 1.2, -0.6, 0.5, 6, 0.02, 10.0),\n    ]\n\n    results = []\n    \n    # Using a fixed large number of quadrature points for stability\n    # across all test cases.\n    N_quad = 60\n    yq, wq = roots_hermite(N_quad)\n\n    for case in test_cases:\n        n_max, omega, V0, a, k, tau, beta = case\n        \n        # 1. Setup basis and physical constants in natural units (hbar=1, m=1)\n        N_sp = n_max + 1\n        N_basis = N_sp ** 2\n        \n        hbar = 1.0\n        m = 1.0\n        b = np.sqrt(hbar / (m * omega))  # HO length scale\n\n        # 2. Construct single-particle operators in the truncated HO basis { |n> }\n        # Ladder operators (annihilation and creation)\n        a_op = np.zeros((N_sp, N_sp), dtype=float)\n        for n in range(1, N_sp):\n            a_op[n - 1, n] = np.sqrt(n)\n        adag_op = a_op.T\n        \n        # Position and momentum operators from ladder operators\n        x_sp = np.sqrt(hbar / (2 * m * omega)) * (a_op + adag_op)\n        p_sp = 1j * np.sqrt(m * hbar * omega / 2) * (adag_op - a_op)\n        \n        # 3. Construct two-body operators from single-particle ones via Kronecker product\n        I_sp = np.identity(N_sp)\n        I_basis = np.identity(N_basis)\n        \n        X1 = np.kron(x_sp, I_sp)\n        X2 = np.kron(I_sp, x_sp)\n        P1 = np.kron(p_sp, I_sp)\n        P2 = np.kron(I_sp, p_sp)\n        \n        # 4. Construct the many-body Hamiltonian matrix H\n        # One-body part: H_1b = sum_i(p_i^2/2m + 1/2 m omega^2 x_i^2)\n        p2_sp = p_sp @ p_sp\n        x2_sp = x_sp @ x_sp\n        h_sp = (1 / (2 * m)) * p2_sp + (m * omega**2 / 2) * x2_sp\n        H_1body = np.kron(h_sp, I_sp) + np.kron(I_sp, h_sp)\n        \n        # Two-body part: V(x1, x2) matrix from numerical quadrature\n        # Precompute values for efficiency\n        fact = [math.factorial(i) for i in range(2 * n_max + 2)]\n        hermite_vals = np.zeros((N_sp, N_quad))\n        for n in range(N_sp):\n            hermite_vals[n, :] = eval_hermite(n, yq)\n            \n        psi_poly_parts = np.zeros((N_sp, N_quad))\n        for n in range(N_sp):\n            norm = 1.0 / np.sqrt(np.sqrt(np.pi) * (2**n) * fact[n])\n            psi_poly_parts[n, :] = norm * hermite_vals[n, :]\n            \n        V_mat = np.zeros((N_basis, N_basis))\n\n        # Helper to map a flat index to (n1, n2) quantum numbers\n        def get_n_tuple(idx, n_sp_dim):\n            return idx // n_sp_dim, idx % n_sp_dim\n\n        for i in range(N_basis):\n            for j in range(i, N_basis):  # Exploit symmetry V_ij = V_ji\n                n1, n2 = get_n_tuple(i, N_sp)\n                n1p, n2p = get_n_tuple(j, N_sp)\n\n                term_y1 = psi_poly_parts[n1, :] * psi_poly_parts[n1p, :]\n                term_y2 = psi_poly_parts[n2, :] * psi_poly_parts[n2p, :]\n                poly_part = np.outer(term_y1, term_y2)\n                \n                y1_grid, y2_grid = np.meshgrid(yq, yq)\n                exp_arg = -b**2 * (y1_grid - y2_grid)**2 / (2 * a**2)\n                interaction_part = V0 * np.exp(exp_arg)\n                \n                integrand = poly_part * interaction_part\n                integral = np.einsum('i,j,ij-', wq, wq, integrand)\n                \n                V_mat[i, j] = integral\n                if i != j:\n                    V_mat[j, i] = integral\n\n        H_mat = H_1body + V_mat\n        H_mat = np.real(H_mat)\n\n        # 5. Construct the center-of-mass Hamiltonian H_cm\n        A = 2.0  # Number of nucleons\n        R_cm_op = (X1 + X2) / A\n        P_cm_op = P1 + P2\n        \n        H_cm_mat = (1 / (2 * A * m)) * (P_cm_op @ P_cm_op) + \\\n                   (A * m * omega**2 / 2) * (R_cm_op @ R_cm_op) - \\\n                   0.5 * hbar * omega * I_basis\n        H_cm_mat = np.real(H_cm_mat)\n\n        # 6. Apply Lawson's method: create and diagonalize H_beta = H + beta*H_cm\n        H_beta_mat = H_mat + beta * H_cm_mat\n        eigenvalues, eigenvectors = eigh(H_beta_mat)\n        \n        # 7. Analyze results: count states with small H_cm\n        count = 0\n        num_states_to_check = min(k, N_basis)\n        \n        for i in range(num_states_to_check):\n            eigenvector = eigenvectors[:, i]\n            # Compute expectation value psi_i| H_cm |psi_i\n            h_cm_exp = eigenvector.conj().T @ H_cm_mat @ eigenvector\n            h_cm_exp = np.real(h_cm_exp)\n            \n            if h_cm_exp = tau:\n                count += 1\n                \n        results.append(count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3610851"}, {"introduction": "This advanced practice delves into the optimization of nonlinear parameters within the variational ansatz itself, a powerful technique for enhancing the accuracy and flexibility of trial wavefunctions. Here, you will go beyond the linear Rayleigh-Ritz procedure by treating the widths of Gaussian basis functions as variational parameters [@problem_id:3610889]. The exercise requires implementing a Newton method to find stationary points on the energy landscape, providing deep insights into the nature of variational minima for ground states and the characteristic saddle points encountered when targeting excited states.", "problem": "Consider the Rayleigh-Ritz variational method for a one-dimensional harmonic oscillator Hamiltonian acting on a finite non-orthogonal Gaussian-polynomial basis, as typically employed in computational nuclear physics to approximate bound states in a truncated harmonic-oscillator configuration space. Let the Hamiltonian operator be the harmonic oscillator in dimensionless units, with reduced Planck constant $\\,\\hbar\\,$ and particle mass $\\,m\\,$ set to unity, and oscillator frequency fixed to $\\,\\omega = 1\\,$. In these units, energies are dimensionless. The continuous Hamiltonian is\n$$\n\\hat{H} = -\\frac{1}{2}\\frac{d^2}{dx^2} + \\frac{1}{2} x^2.\n$$\nWe work with a three-function basis with nonlinear width parameters, where each basis function is a polynomial times a Gaussian:\n- Basis polynomials are $P_0(x) = 1$, $P_1(x) = x$, and $P_2(x) = x^2 - c$, with a fixed constant $c$ chosen to break redundancy. \n- Each basis function takes the form $\\phi_i(x) = P_i(x)\\,\\exp(-\\alpha_i x^2)$.\n- The widths $\\alpha_i$ satisfy $\\alpha_2$ is fixed and positive, while $\\alpha_0$ and $\\alpha_1$ are positive and parameterized as $\\alpha_0 = e^{a_0}$ and $\\alpha_1 = e^{a_1}$ with nonlinear parameters $a_0, a_1 \\in \\mathbb{R}$.\n\nDefine the overlap matrix $\\,S(a_0,a_1)\\,$ and Hamiltonian matrix $\\,H(a_0,a_1)\\,$ with elements\n$$\nS_{ij}(a_0,a_1) = \\int_{-\\infty}^{\\infty} \\phi_i(x)\\,\\phi_j(x)\\,dx,\n\\qquad\nH_{ij}(a_0,a_1) = \\int_{-\\infty}^{\\infty} \\phi_i(x)\\,\\hat{H}\\,\\phi_j(x)\\,dx,\n$$\nand use the symmetric form of the kinetic energy via integration by parts,\n$$\nT_{ij}(a_0,a_1) = \\frac{1}{2}\\int_{-\\infty}^{\\infty} \\frac{d\\phi_i}{dx}(x)\\,\\frac{d\\phi_j}{dx}(x)\\,dx,\n\\qquad\nV_{ij}(a_0,a_1) = \\frac{1}{2}\\int_{-\\infty}^{\\infty} x^2\\,\\phi_i(x)\\,\\phi_j(x)\\,dx,\n\\qquad\nH_{ij} = T_{ij} + V_{ij},\n$$\nwhere $\\,\\phi_i(x) = P_i(x)\\,e^{-\\alpha_i x^2}\\,$ and $\\frac{d\\phi_i}{dx}(x) = \\left(P_i'(x) - 2\\alpha_i x\\,P_i(x)\\right)e^{-\\alpha_i x^2}$. All integrals are Gaussian moments of polynomials and are thus finite and computable analytically.\n\nFor a fixed parameter pair $(a_0,a_1)$, define the generalized Rayleigh-Ritz eigenproblem\n$$\nH(a_0,a_1)\\,v_k(a_0,a_1) = E_k(a_0,a_1)\\,S(a_0,a_1)\\,v_k(a_0,a_1),\n$$\nwith normalization $v_k(a_0,a_1)^{\\top} S(a_0,a_1) v_k(a_0,a_1) = 1$, and the eigenvalues sorted in ascending order $E_0 \\le E_1 \\le E_2$. The variational principle guarantees that $E_0(a_0,a_1)$ is an upper bound to the true ground state. Targeting excited states such as $E_1(a_0,a_1)$ enforces stationarity under orthogonality constraints and generally yields saddle points in the unconstrained parameter space.\n\nTask:\n1) Starting from the Rayleigh-Ritz principle and the generalized eigenvalue problem $H v = E S v$, derive the gradient $\\,\\nabla E_k(a_0,a_1)\\,$ and the Hessian $\\,\\nabla^2 E_k(a_0,a_1)\\,$ of the targeted eigenvalue $\\,E_k\\,$ with respect to the nonlinear parameters $(a_0,a_1)$. Your derivation must begin from fundamental variational principles and the definition of the Rayleigh quotient, proceed to the generalized Hellmann-Feynman theorem for the gradient, and then obtain the second-order perturbative expression for the Hessian in terms of matrix derivatives and a spectral sum over non-target eigenstates. You must express all mathematical entities in LaTeX and avoid shortcuts directly stating the final formulas without justification.\n2) Implement a Newton method in code to find a stationary point of $E_k(a_0,a_1)$ by iteratively updating $(a_0,a_1)$ with the Newton step $-\\left[\\nabla^2 E_k\\right]^{-1}\\nabla E_k$. Use robust numerical approximations for the gradient and Hessian via central finite differences of the scalar map $(a_0,a_1)\\mapsto E_k(a_0,a_1)$, and stabilize the method with regularization and a simple backtracking strategy to ensure convergence of the stationarity conditions. After convergence, diagnose whether the converged point is a saddle point by examining the eigenvalues of the Hessian: report it as a saddle if the Hessian has both positive and negative eigenvalues.\n3) Use the following physically plausible constants and test suite. Take $\\,\\alpha_2 = 1.0\\,$ and $\\,c = \\frac{1}{2\\alpha_2} = 0.5\\,$. Express all energies in the specified dimensionless units. Define three test cases, each as a tuple $(k,a_0,a_1)$ with target index $k$ and initial values for $(a_0,a_1)$:\n   - Case 1 (happy path): $(k=0, a_0=\\ln(0.8), a_1=\\ln(1.2))$.\n   - Case 2 (excited state): $(k=1, a_0=\\ln(0.8), a_1=\\ln(1.2))$.\n   - Case 3 (edge case with disparate widths): $(k=1, a_0=\\ln(0.4), a_1=\\ln(1.6))$.\n\nThe final output format requirement:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each result is a two-element list $[E,\\text{saddle}]$ with energy $E$ as a floating-point number (in dimensionless units) and $\\text{saddle}$ as a boolean indicating whether the converged point is a saddle. For example: \"[[E1,True],[E2,False],[E3,True]]\".", "solution": "The problem is valid as it represents a standard and well-posed application of the Rayleigh-Ritz variational method to a quantum harmonic oscillator, a foundational problem in computational physics. It is scientifically grounded, objective, and contains all necessary information for a unique solution.\n\nThe solution requires two main components: a theoretical derivation of the gradient and Hessian of the energy eigenvalues with respect to the nonlinear variational parameters, and a numerical implementation of a Newton-Raphson optimization algorithm to locate stationary points of the energy surface.\n\n### Part 1: Theoretical Derivation\n\nLet the nonlinear parameters be denoted by a vector $\\mathbf{p} = (a_0, a_1)$. The basis functions $\\phi_i(\\mathbf{p}; x)$ depend on these parameters, and consequently, so do the Hamiltonian matrix $\\mathbf{H}(\\mathbf{p})$ and the overlap matrix $\\mathbf{S}(\\mathbf{p})$. The Rayleigh-Ritz method approximates the true energy eigenvalues by solving the generalized eigenvalue problem:\n$$\n\\mathbf{H}(\\mathbf{p}) \\mathbf{v}_k(\\mathbf{p}) = E_k(\\mathbf{p}) \\mathbf{S}(\\mathbf{p}) \\mathbf{v}_k(\\mathbf{p})\n$$\nThe eigenvectors $\\mathbf{v}_k$ are assumed to be normalized according to $\\mathbf{v}_k^\\top \\mathbf{S} \\mathbf{v}_k = 1$. The eigenvalues $E_k(\\mathbf{p})$ are given by the Rayleigh quotient:\n$$\nE_k(\\mathbf{p}) = \\frac{\\mathbf{v}_k^\\top \\mathbf{H} \\mathbf{v}_k}{\\mathbf{v}_k^\\top \\mathbf{S} \\mathbf{v}_k}\n$$\nGiven the normalization, this simplifies to $E_k(\\mathbf{p}) = \\mathbf{v}_k^\\top \\mathbf{H} \\mathbf{v}_k$.\n\n#### 1. Gradient of the Eigenvalue: $\\nabla E_k$\n\nTo find the gradient of $E_k$ with respect to a parameter $p_\\lambda \\in \\{a_0, a_1\\}$, we differentiate the eigenvalue equation $E_k \\mathbf{v}_k^\\top \\mathbf{S} \\mathbf{v}_k = \\mathbf{v}_k^\\top \\mathbf{H} \\mathbf{v}_k$. Using the product rule for differentiation:\n$$\n\\frac{\\partial E_k}{\\partial p_\\lambda} (\\mathbf{v}_k^\\top \\mathbf{S} \\mathbf{v}_k) + E_k \\frac{\\partial}{\\partial p_\\lambda}(\\mathbf{v}_k^\\top \\mathbf{S} \\mathbf{v}_k) = \\frac{\\partial}{\\partial p_\\lambda}(\\mathbf{v}_k^\\top \\mathbf{H} \\mathbf{v}_k)\n$$\nThe derivative of a quadratic form $\\mathbf{v}^\\top \\mathbf{M} \\mathbf{v}$ is $2(\\frac{\\partial \\mathbf{v}^\\top}{\\partial p_\\lambda})\\mathbf{M}\\mathbf{v} + \\mathbf{v}^\\top \\frac{\\partial \\mathbf{M}}{\\partial p_\\lambda} \\mathbf{v}$ (for real vectors and symmetric matrices). Applying this, we get:\n$$\n\\frac{\\partial E_k}{\\partial p_\\lambda} (\\mathbf{v}_k^\\top \\mathbf{S} \\mathbf{v}_k) + E_k \\left( 2\\frac{\\partial \\mathbf{v}_k^\\top}{\\partial p_\\lambda}\\mathbf{S}\\mathbf{v}_k + \\mathbf{v}_k^\\top \\frac{\\partial \\mathbf{S}}{\\partial p_\\lambda} \\mathbf{v}_k \\right) = 2\\frac{\\partial \\mathbf{v}_k^\\top}{\\partial p_\\lambda}\\mathbf{H}\\mathbf{v}_k + \\mathbf{v}_k^\\top \\frac{\\partial \\mathbf{H}}{\\partial p_\\lambda} \\mathbf{v}_k\n$$\nRearranging terms involving the derivative of the eigenvector, $\\frac{\\partial \\mathbf{v}_k}{\\partial p_\\lambda}$:\n$$\n\\frac{\\partial E_k}{\\partial p_\\lambda} (\\mathbf{v}_k^\\top \\mathbf{S} \\mathbf{v}_k) + \\mathbf{v}_k^\\top \\left( E_k \\frac{\\partial \\mathbf{S}}{\\partial p_\\lambda} - \\frac{\\partial \\mathbf{H}}{\\partial p_\\lambda} \\right) \\mathbf{v}_k = 2\\frac{\\partial \\mathbf{v}_k^\\top}{\\partial p_\\lambda} (\\mathbf{H}\\mathbf{v}_k - E_k \\mathbf{S}\\mathbf{v}_k)\n$$\nFrom the original eigenvalue equation, the term in the parenthesis on the right-hand side is zero: $\\mathbf{H}\\mathbf{v}_k - E_k \\mathbf{S}\\mathbf{v}_k = \\mathbf{0}$. This elegant cancellation, a consequence of the stationarity of the Rayleigh quotient, leaves:\n$$\n\\frac{\\partial E_k}{\\partial p_\\lambda} (\\mathbf{v}_k^\\top \\mathbf{S} \\mathbf{v}_k) = \\mathbf{v}_k^\\top \\left( \\frac{\\partial \\mathbf{H}}{\\partial p_\\lambda} - E_k \\frac{\\partial \\mathbf{S}}{\\partial p_\\lambda} \\right) \\mathbf{v}_k\n$$\nThis result is the generalized Hellmann-Feynman theorem. Given the normalization $\\mathbf{v}_k^\\top \\mathbf{S} \\mathbf{v}_k = 1$, the expression for the gradient component simplifies to:\n$$\n\\frac{\\partial E_k}{\\partial p_\\lambda} = \\mathbf{v}_k^\\top \\left( \\frac{\\partial \\mathbf{H}(\\mathbf{p})}{\\partial p_\\lambda} - E_k(\\mathbf{p}) \\frac{\\partial \\mathbf{S}(\\mathbf{p})}{\\partial p_\\lambda} \\right) \\mathbf{v}_k\n$$\nThe full gradient vector is $\\nabla E_k = \\left( \\frac{\\partial E_k}{\\partial a_0}, \\frac{\\partial E_k}{\\partial a_1} \\right)^\\top$.\n\n#### 2. Hessian of the Eigenvalue: $\\nabla^2 E_k$\n\nTo obtain the Hessian matrix, we must differentiate the gradient component $\\frac{\\partial E_k}{\\partial p_\\lambda}$ with respect to another parameter, $p_\\mu \\in \\{a_0, a_1\\}$. For simplicity, let's denote the operator inside the expectation value as $\\mathbf{O}_\\lambda(\\mathbf{p}) = \\frac{\\partial \\mathbf{H}}{\\partial p_\\lambda} - E_k \\frac{\\partial \\mathbf{S}}{\\partial p_\\lambda}$.\n$$\n\\frac{\\partial^2 E_k}{\\partial p_\\mu \\partial p_\\lambda} = \\frac{\\partial}{\\partial p_\\mu} \\left( \\mathbf{v}_k^\\top \\mathbf{O}_\\lambda \\mathbf{v}_k \\right)\n$$\nApplying the product rule again:\n$$\n\\frac{\\partial^2 E_k}{\\partial p_\\mu \\partial p_\\lambda} = \\frac{\\partial \\mathbf{v}_k^\\top}{\\partial p_\\mu} \\mathbf{O}_\\lambda \\mathbf{v}_k + \\mathbf{v}_k^\\top \\mathbf{O}_\\lambda \\frac{\\partial \\mathbf{v}_k}{\\partial p_\\mu} + \\mathbf{v}_k^\\top \\frac{\\partial \\mathbf{O}_\\lambda}{\\partial p_\\mu} \\mathbf{v}_k = 2\\,\\text{Re}\\left( \\mathbf{v}_k^\\top \\mathbf{O}_\\lambda \\frac{\\partial \\mathbf{v}_k}{\\partial p_\\mu} \\right) + \\mathbf{v}_k^\\top \\frac{\\partial \\mathbf{O}_\\lambda}{\\partial p_\\mu} \\mathbf{v}_k\n$$\nThe derivative of the operator is:\n$$\n\\frac{\\partial \\mathbf{O}_\\lambda}{\\partial p_\\mu} = \\frac{\\partial^2 \\mathbf{H}}{\\partial p_\\mu \\partial p_\\lambda} - \\frac{\\partial E_k}{\\partial p_\\mu} \\frac{\\partial \\mathbf{S}}{\\partial p_\\lambda} - E_k \\frac{\\partial^2 \\mathbf{S}}{\\partial p_\\mu \\partial p_\\lambda}\n$$\nThe main challenge is the term $\\frac{\\partial \\mathbf{v}_k}{\\partial p_\\mu}$, which is found using first-order perturbation theory. We differentiate $(\\mathbf{H} - E_k \\mathbf{S})\\mathbf{v}_k = \\mathbf{0}$ with respect to $p_\\mu$:\n$$\n\\left( \\frac{\\partial \\mathbf{H}}{\\partial p_\\mu} - \\frac{\\partial E_k}{\\partial p_\\mu} \\mathbf{S} - E_k \\frac{\\partial \\mathbf{S}}{\\partial p_\\mu} \\right) \\mathbf{v}_k + (\\mathbf{H} - E_k \\mathbf{S}) \\frac{\\partial \\mathbf{v}_k}{\\partial p_\\mu} = \\mathbf{0}\n$$\nwhich can be written as $(\\mathbf{O}_\\mu - \\frac{\\partial E_k}{\\partial p_\\mu}\\mathbf{S})\\mathbf{v}_k + (\\mathbf{H} - E_k \\mathbf{S})\\frac{\\partial \\mathbf{v}_k}{\\partial p_\\mu} = \\mathbf{0}$.\nTo find the components of $\\frac{\\partial \\mathbf{v}_k}{\\partial p_\\mu}$, we expand it in the basis of eigenvectors $\\{\\mathbf{v}_j\\}$, which form an $\\mathbf{S}$-orthonormal set ($\\mathbf{v}_j^\\top \\mathbf{S} \\mathbf{v}_m = \\delta_{jm}$): $\\frac{\\partial \\mathbf{v}_k}{\\partial p_\\mu} = \\sum_{j} c_{j} \\mathbf{v}_j$.\nLeft-multiplying the perturbed equation by $\\mathbf{v}_j^\\top$ for $j \\neq k$:\n$$\n\\mathbf{v}_j^\\top (\\mathbf{O}_\\mu - \\frac{\\partial E_k}{\\partial p_\\mu}\\mathbf{S})\\mathbf{v}_k + \\mathbf{v}_j^\\top (\\mathbf{H} - E_k \\mathbf{S}) \\frac{\\partial \\mathbf{v}_k}{\\partial p_\\mu} = 0\n$$\nSince $\\mathbf{v}_j^\\top \\mathbf{S} \\mathbf{v}_k = 0$ for $j \\neq k$, the first term is $\\mathbf{v}_j^\\top \\mathbf{O}_\\mu \\mathbf{v}_k$. The second term becomes $\\mathbf{v}_j^\\top (\\mathbf{H} - E_k \\mathbf{S}) \\sum_m c_m \\mathbf{v}_m = c_j \\mathbf{v}_j^\\top (E_j \\mathbf{S} - E_k \\mathbf{S})\\mathbf{v}_j = c_j(E_j - E_k)$.\nThis yields the coefficient for $j \\neq k$:\n$$\nc_j = \\frac{\\mathbf{v}_j^\\top \\mathbf{O}_\\mu \\mathbf{v}_k}{E_k - E_j}\n$$\nSubstituting the expansion of $\\frac{\\partial \\mathbf{v}_k}{\\partial p_\\mu}$ into the Hessian equation, the `Re` term becomes:\n$$\n2\\,\\text{Re} \\left( \\sum_{j \\neq k} c_j \\mathbf{v}_k^\\top \\mathbf{O}_\\lambda \\mathbf{v}_j \\right) + 2\\,\\text{Re}(c_k \\mathbf{v}_k^\\top \\mathbf{O}_\\lambda \\mathbf{v}_k)\n$$\nThe second part of this term includes $c_k$, which is determined by the normalization condition. The first part, the sum, is the second-order perturbation term:\n$$\n2\\,\\text{Re} \\sum_{j \\neq k} \\frac{(\\mathbf{v}_k^\\top \\mathbf{O}_\\lambda \\mathbf{v}_j)(\\mathbf{v}_j^\\top \\mathbf{O}_\\mu \\mathbf{v}_k)}{E_k - E_j}\n$$\nThe full analytical expression for the Hessian is quite involved. It contains terms with second derivatives of the matrices $\\mathbf{H}$ and $\\mathbf{S}$, first-derivative terms, and the spectral sum over all other states $j \\neq k$. This complexity justifies the use of numerical finite differences for the implementation, as requested by the problem.\n\n### Part 2: Numerical Implementation\n\nThe core of the implementation involves four parts:\n1.  A function to analytically compute the matrix elements $H_{ij}$ and $S_{ij}$ for given parameters $(a_0, a_1)$. This requires computing Gaussian integrals of the form $\\int_{-\\infty}^{\\infty} x^n e^{-\\beta x^2} dx$.\n2.  A function that, for a given set of parameters $(a_0, a_1)$, builds the matrices $\\mathbf{H}$ and $\\mathbf{S}$ and solves the generalized eigenproblem to return the $k$-th eigenvalue, $E_k(a_0, a_1)$.\n3.  Numerical calculation of the gradient $\\nabla E_k$ and Hessian $\\nabla^2 E_k$ using central finite differences on the scalar function $(a_0, a_1) \\mapsto E_k(a_0, a_1)$.\n4.  A Newton-Raphson optimizer to find stationary points where $\\nabla E_k = 0$. The update step is $\\mathbf{p}_{n+1} = \\mathbf{p}_n - [\\nabla^2 E_k(\\mathbf{p}_n)]^{-1} \\nabla E_k(\\mathbf{p}_n)$. The method is stabilized with Hessian regularization (adding a small multiple of the identity matrix) and a backtracking line search to ensure robust convergence. After convergence, the nature of the stationary point is determined by the eigenvalues of the Hessian: if they have mixed signs (one positive, one negative), it is a saddle point. For a $2 \\times 2$ matrix, this is equivalent to its determinant being negative.\nThis procedure will be applied to each test case.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef solve():\n    \"\"\"\n    Main solver function that executes the Newton method for all test cases.\n    \"\"\"\n\n    C_CONST = 0.5\n    ALPHA2 = 1.0\n\n    def gaussian_integral(n, beta):\n        \"\"\"\n        Computes the integral of x^n * exp(-beta * x^2) from -inf to inf.\n        \"\"\"\n        if n  0 or n % 2 != 0:\n            return 0.0\n        if beta = 0:\n            # This should not happen with the given parameterization\n            raise ValueError(\"beta must be positive\")\n        m = n // 2\n        if m == 0:\n            return np.sqrt(np.pi / beta)\n        \n        # Calculate (2m-1)!! = (2m-1)*(2m-3)*...*1\n        double_factorial = np.prod(np.arange(1, 2 * m, 2))\n        \n        return (double_factorial / ((2 * beta)**m)) * np.sqrt(np.pi / beta)\n\n    def build_matrices(a0, a1):\n        \"\"\"\n        Builds the Hamiltonian (H) and Overlap (S) matrices.\n        \"\"\"\n        alpha_vec = np.array([np.exp(a0), np.exp(a1), ALPHA2])\n        \n        # Polynomials: P0=1, P1=x, P2=x^2-c\n        # Derivatives: P'0=0, P'1=1, P'2=2x\n        polys = [\n            (0, {0: 1}),          # P0(x) = 1\n            (1, {1: 1}),          # P1(x) = x\n            (2, {2: 1, 0: -C_CONST})  # P2(x) = x^2 - c\n        ]\n        poly_derivs = [\n            (0, {}),              # P'0(x) = 0\n            (0, {0: 1}),          # P'1(x) = 1\n            (1, {1: 2})           # P'2(x) = 2x\n        ]\n\n        h_mat = np.zeros((3, 3))\n        s_mat = np.zeros((3, 3))\n        \n        for i in range(3):\n            for j in range(i, 3):\n                beta = alpha_vec[i] + alpha_vec[j]\n                \n                # Integrals for S_ij and V_ij\n                # Integrand for S_ij is (Pi * Pj) * exp(-beta*x^2)\n                # Integrand for V_ij is (x^2 * Pi * Pj) * exp(-beta*x^2)\n                s_ij = 0.0\n                v_ij = 0.0\n                p_i = polys[i][1]\n                p_j = polys[j][1]\n                for pow_i, c_i in p_i.items():\n                    for pow_j, c_j in p_j.items():\n                        s_ij += c_i * c_j * gaussian_integral(pow_i + pow_j, beta)\n                        v_ij += 0.5 * c_i * c_j * gaussian_integral(pow_i + pow_j + 2, beta)\n                \n                s_mat[i, j] = s_mat[j, i] = s_ij\n                \n                # Integrals for T_ij\n                # phi'_i = (P'_i - 2*alpha_i*x*Pi) * exp(-alpha_i*x^2)\n                # T_ij = 0.5 * integral(phi'_i * phi'_j)\n                # Integrand: 0.5 * [P'i*P'j - 2*alpha_j*x*P'i*Pj - 2*alpha_i*x*Pi*P'j + 4*alpha_i*alpha_j*x^2*Pi*Pj] * exp(-beta*x^2)\n                \n                t_ij = 0.0\n                # Term 1: P'_i * P'_j\n                pd_i, pd_j = poly_derivs[i][1], poly_derivs[j][1]\n                for pow_di, c_di in pd_i.items():\n                    for pow_dj, c_dj in pd_j.items():\n                        t_ij += c_di * c_dj * gaussian_integral(pow_di + pow_dj, beta)\n\n                # Term 2: -2*alpha_j*x*P'_i*P_j\n                term2 = 0.0\n                for pow_di, c_di in pd_i.items():\n                    for pow_j, c_j in p_j.items():\n                        term2 += c_di * c_j * gaussian_integral(pow_di + pow_j + 1, beta)\n                t_ij -= 2 * alpha_vec[j] * term2\n\n                # Term 3: -2*alpha_i*x*P_i*P'_j\n                term3 = 0.0\n                for pow_i, c_i in p_i.items():\n                    for pow_dj, c_dj in pd_j.items():\n                        term3 += c_i * c_dj * gaussian_integral(pow_i + pow_dj + 1, beta)\n                t_ij -= 2 * alpha_vec[i] * term3\n\n                # Term 4: 4*alpha_i*alpha_j*x^2*P_i*P_j\n                term4 = 0.0\n                for pow_i, c_i in p_i.items():\n                    for pow_j, c_j in p_j.items():\n                        term4 += c_i * c_j * gaussian_integral(pow_i + pow_j + 2, beta)\n                t_ij += 4 * alpha_vec[i] * alpha_vec[j] * term4\n                \n                t_ij *= 0.5\n                h_mat[i, j] = h_mat[j, i] = t_ij + v_ij\n                \n        return h_mat, s_mat\n\n    def get_eigenvalue(params, k):\n        \"\"\"\n        Solves the generalized eigenvalue problem and returns the k-th energy.\n        \"\"\"\n        a0, a1 = params\n        try:\n            h_mat, s_mat = build_matrices(a0, a1)\n            # Use eigh for symmetric matrices; it returns sorted eigenvalues.\n            eigenvalues = eigh(h_mat, s_mat, eigvals_only=True)\n            if k  len(eigenvalues):\n                return eigenvalues[k]\n            else:\n                return np.inf\n        except (ValueError, np.linalg.LinAlgError):\n            return np.inf\n\n    def compute_gradient_hessian(params, k, h=1e-5):\n        \"\"\"\n        Computes gradient and Hessian using central finite differences.\n        \"\"\"\n        grad = np.zeros(2)\n        hess = np.zeros((2, 2))\n        \n        # Central function value\n        f_center = get_eigenvalue(params, k)\n\n        # Gradient\n        for i in range(2):\n            params_p = params.copy()\n            params_m = params.copy()\n            params_p[i] += h\n            params_m[i] -= h\n            grad[i] = (get_eigenvalue(params_p, k) - get_eigenvalue(params_m, k)) / (2 * h)\n\n        # Hessian diagonal\n        for i in range(2):\n            params_p = params.copy()\n            params_m = params.copy()\n            params_p[i] += h\n            params_m[i] -= h\n            hess[i, i] = (get_eigenvalue(params_p, k) - 2 * f_center + get_eigenvalue(params_m, k)) / (h**2)\n            \n        # Hessian off-diagonal\n        h_pp = np.array([h, h])\n        h_pm = np.array([h, -h])\n        f_pp = get_eigenvalue(params + h_pp, k)\n        f_pm = get_eigenvalue(params + h_pm, k)\n        f_mp = get_eigenvalue(params - h_pm, k)\n        f_mm = get_eigenvalue(params - h_pp, k)\n        hess[0, 1] = hess[1, 0] = (f_pp - f_pm - f_mp + f_mm) / (4 * h**2)\n\n        return grad, hess\n\n    def solve_newton(k, a0_init, a1_init):\n        \"\"\"\n        Finds a stationary point of E_k using a stabilized Newton method.\n        \"\"\"\n        params = np.array([a0_init, a1_init])\n        max_iter = 50\n        tol = 1e-8\n        reg = 1e-4  # Hessian regularization\n        \n        for i in range(max_iter):\n            grad, hess = compute_gradient_hessian(params, k)\n            \n            if np.linalg.norm(grad)  tol:\n                break\n            \n            try:\n                # Regularized inverse\n                hess_reg = hess + reg * np.eye(2)\n                step = -np.linalg.inv(hess_reg) @ grad\n            except np.linalg.LinAlgError:\n                # Fallback to gradient descent if Hessian is singular\n                step = -grad\n\n            # Backtracking line search to ensure gradient norm decreases\n            alpha = 1.0  # Initial step size\n            beta = 0.5  # Reduction factor\n            c1 = 0.1 # Armijo condition parameter\n            \n            current_grad_norm = np.linalg.norm(grad)\n            \n            for _ in range(10): # Max 10 backtracking steps\n                params_new = params + alpha * step\n                grad_new, _ = compute_gradient_hessian(params_new, k, h=1e-6)\n                if np.linalg.norm(grad_new)  (1.0 - c1 * alpha) * current_grad_norm:\n                    break\n                alpha *= beta\n            else: # If backtracking fails, stop\n                break\n                \n            params = params_new\n    \n        # Final diagnosis\n        final_energy = get_eigenvalue(params, k)\n        _, final_hess = compute_gradient_hessian(params, k)\n        \n        # A 2D stationary point is a saddle if det(Hessian)  0\n        is_saddle = np.linalg.det(final_hess)  0\n        \n        return [final_energy, is_saddle]\n\n    test_cases = [\n        # (k, a0_init, a1_init)\n        (0, np.log(0.8), np.log(1.2)),\n        (1, np.log(0.8), np.log(1.2)),\n        (1, np.log(0.4), np.log(1.6)),\n    ]\n\n    results = []\n    for k, a0, a1 in test_cases:\n        result = solve_newton(k, a0, a1)\n        # Format the result to match requested precision and boolean style\n        formatted_result = f\"[{result[0]:.8f},{str(result[1]).lower()}]\"\n        results.append(formatted_result)\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3610889"}]}