{"hands_on_practices": [{"introduction": "The cornerstone of forward error analysis is understanding that backward stability alone does not guarantee an accurate answer. This first practice invites you to construct a simple yet powerful example of an ill-conditioned system. You will see firsthand how a computed solution with a tiny backward error can have a large forward error, and you will use the matrix condition number to explain exactly why this amplification occurs. [@problem_id:3546754]", "problem": "Let $\\|\\cdot\\|$ denote the spectral norm (the Euclidean $2$-norm for vectors and the induced operator $2$-norm for matrices). Consider the $2 \\times 2$ diagonal matrix\n$$\nA = \\begin{pmatrix} 1 & 0 \\\\[4pt] 0 & \\varepsilon \\end{pmatrix},\n\\quad \\text{with } \\varepsilon = 10^{-14},\n$$\nthe exact solution\n$$\nx = \\begin{pmatrix} 1 \\\\[2pt] 1 \\end{pmatrix},\n$$\nand the corresponding right-hand side\n$$\nb = A x = \\begin{pmatrix} 1 \\\\[2pt] \\varepsilon \\end{pmatrix}.\n$$\nSuppose a computed solution is reported as\n$$\n\\hat{x} = \\begin{pmatrix} 1 \\\\[2pt] 1 - \\alpha \\end{pmatrix},\n\\quad \\text{with } \\alpha = 10^{-2}.\n$$\nYou will verify that the normwise backward error is no larger than $10^{-16}$ while the normwise forward error is approximately $10^{-2}$, and then justify this discrepancy using the condition number of $A$.\n\nTasks:\n1. Using the normwise backward error definition (the minimal $\\eta$ for which there exist perturbations $\\Delta A$ and $\\Delta b$ satisfying $(A + \\Delta A)\\hat{x} = b + \\Delta b$, with $\\|\\Delta A\\| \\le \\eta \\|A\\|$ and $\\|\\Delta b\\| \\le \\eta \\|b\\|$), exhibit specific $\\Delta A$ and $\\Delta b$ showing that the backward error for $\\hat{x}$ does not exceed $10^{-16}$.\n2. Compute the normwise forward error ratio $\\|x - \\hat{x}\\| / \\|x\\|$.\n3. Starting from the definitions of the condition number $\\kappa_{2}(A) = \\|A\\| \\,\\|A^{-1}\\|$, the backward error, and the forward error, derive a bound that explains why the forward error can be much larger than the backward error for ill-conditioned $A$, and evaluate this bound for the given data to interpret your result.\n\nReport, as your final answer, the numerical value of the forward error ratio $\\|x - \\hat{x}\\| / \\|x\\|$ rounded to four significant figures.", "solution": "The problem asks for a three-part analysis of a computed solution to a linear system, focusing on the concepts of backward error, forward error, and the condition number.\n\nThe given quantities are:\n- The matrix $A = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\varepsilon \\end{pmatrix}$ with $\\varepsilon = 10^{-14}$.\n- The exact solution $x = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n- The right-hand side $b = Ax = \\begin{pmatrix} 1 \\\\ \\varepsilon \\end{pmatrix}$.\n- The computed solution $\\hat{x} = \\begin{pmatrix} 1 \\\\ 1 - \\alpha \\end{pmatrix}$ with $\\alpha = 10^{-2}$.\n- The norm $\\|\\cdot\\|$ is the spectral norm ($2$-norm for vectors, induced $2$-norm for matrices).\n\n### Task 1: Backward Error Verification\n\nThe normwise backward error $\\eta$ is the smallest non-negative number for which there exist perturbations $\\Delta A$ and $\\Delta b$ satisfying $(A + \\Delta A)\\hat{x} = b + \\Delta b$, with $\\|\\Delta A\\| \\le \\eta \\|A\\|$ and $\\|\\Delta b\\| \\le \\eta \\|b\\|$. This condition can be rewritten by defining the residual vector $r = b - A\\hat{x}$. The equation becomes:\n$$\n\\Delta b - \\Delta A \\hat{x} = A\\hat{x} - b = -r\n$$\nFirst, let's compute the residual $r$:\n$$\nA\\hat{x} = \\begin{pmatrix} 1 & 0 \\\\ 0 & \\varepsilon \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1-\\alpha \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\varepsilon(1-\\alpha) \\end{pmatrix}\n$$\n$$\nr = b - A\\hat{x} = \\begin{pmatrix} 1 \\\\ \\varepsilon \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ \\varepsilon(1-\\alpha) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\varepsilon\\alpha \\end{pmatrix}\n$$\nTo show that the backward error does not exceed $10^{-16}$, we need to exhibit specific perturbations $\\Delta A$ and $\\Delta b$ that satisfy the error equation and the norm bounds for an $\\eta \\le 10^{-16}$. A simple choice is to attribute the entire residual to a perturbation in $b$ by setting $\\Delta A = 0$.\nLet $\\Delta A$ be the $2 \\times 2$ zero matrix, $\\Delta A = \\begin{pmatrix} 0 & 0 \\\\ 0 & 0 \\end{pmatrix}$. The error equation simplifies to $\\Delta b = -r$.\n$$\n\\Delta b = -r = \\begin{pmatrix} 0 \\\\ -\\varepsilon\\alpha \\end{pmatrix}\n$$\nNow we must verify the norm conditions for some $\\eta \\le 10^{-16}$. The first condition, $\\|\\Delta A\\| \\le \\eta \\|A\\|$, becomes $0 \\le \\eta \\|A\\|$, which is true for any $\\eta \\ge 0$.\nFor the second condition, we need to find the smallest $\\eta$ that satisfies $\\|\\Delta b\\| \\le \\eta \\|b\\|$. This gives $\\eta \\ge \\frac{\\|\\Delta b\\|}{\\|b\\|}$. Let's calculate the norms:\n$$\n\\|\\Delta b\\| = \\left\\| \\begin{pmatrix} 0 \\\\ -\\varepsilon\\alpha \\end{pmatrix} \\right\\|_2 = \\sqrt{0^2 + (-\\varepsilon\\alpha)^2} = \\varepsilon\\alpha = (10^{-14})(10^{-2}) = 10^{-16}\n$$\n$$\n\\|b\\| = \\left\\| \\begin{pmatrix} 1 \\\\ \\varepsilon \\end{pmatrix} \\right\\|_2 = \\sqrt{1^2 + \\varepsilon^2} = \\sqrt{1 + (10^{-14})^2} = \\sqrt{1 + 10^{-28}}\n$$\nFor our choice of $\\Delta A$ and $\\Delta b$, the backward error measure is $\\eta = \\frac{\\|\\Delta b\\|}{\\|b\\|} = \\frac{10^{-16}}{\\sqrt{1 + 10^{-28}}}$.\nSince $\\sqrt{1 + 10^{-28}} > 1$, we have $\\eta < 10^{-16}$. The true normwise backward error is the minimum over all possible perturbations, so it must be less than or equal to this value. Thus, we have shown that the backward error for $\\hat{x}$ does not exceed $10^{-16}$.\n\n### Task 2: Forward Error Computation\n\nThe normwise forward error ratio is given by $\\frac{\\|x - \\hat{x}\\|}{\\|x\\|}$.\nFirst, we compute the error vector $x - \\hat{x}$:\n$$\nx - \\hat{x} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 1-\\alpha \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\alpha \\end{pmatrix}\n$$\nNext, we compute the required norms:\n$$\n\\|x - \\hat{x}\\| = \\left\\| \\begin{pmatrix} 0 \\\\ \\alpha \\end{pmatrix} \\right\\|_2 = \\sqrt{0^2 + \\alpha^2} = \\alpha = 10^{-2}\n$$\n$$\n\\|x\\| = \\left\\| \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right\\|_2 = \\sqrt{1^2 + 1^2} = \\sqrt{2}\n$$\nThe forward error ratio is:\n$$\n\\frac{\\|x - \\hat{x}\\|}{\\|x\\|} = \\frac{10^{-2}}{\\sqrt{2}}\n$$\nTo provide the numerical value rounded to four significant figures:\n$$\n\\frac{10^{-2}}{\\sqrt{2}} \\approx \\frac{10^{-2}}{1.41421356} \\approx 0.0070710678 \\approx 7.071 \\times 10^{-3}\n$$\nThe value is approximately $0.007071$.\n\n### Task 3: Justification using the Condition Number\n\nThe discrepancy between the small backward error (approx. $10^{-16}$) and the much larger forward error (approx. $10^{-2}$) is explained by the condition number of the matrix $A$.\n\nFirst, we derive a general bound relating forward error and backward error. From $(A + \\Delta A)\\hat{x} = b + \\Delta b$ and $Ax = b$, we can write:\n$$\n(A+\\Delta A)\\hat{x} = Ax + \\Delta b \\implies \\hat{x} = (A+\\Delta A)^{-1}(Ax + \\Delta b)\n$$\nThe error is $\\hat{x}-x = (A+\\Delta A)^{-1}(Ax+\\Delta b) - x = (A+\\Delta A)^{-1}[Ax+\\Delta b - (A+\\Delta A)x] = (A+\\Delta A)^{-1}(\\Delta b - \\Delta A x)$.\nTaking norms, we get $\\|\\hat{x}-x\\| \\le \\|(A+\\Delta A)^{-1}\\| (\\|\\Delta b\\| + \\|\\Delta A\\|\\|x\\|)$.\nUsing the Banach Lemma, if $\\|\\Delta A\\|\\|A^{-1}\\| < 1$, then $\\|(A+\\Delta A)^{-1}\\| \\le \\frac{\\|A^{-1}\\|}{1-\\|A^{-1}\\|\\|\\Delta A\\|}$.\nSubstituting this in, we get:\n$$\n\\|\\hat{x}-x\\| \\le \\frac{\\|A^{-1}\\|}{1-\\|A^{-1}\\|\\|\\Delta A\\|} (\\|\\Delta b\\| + \\|\\Delta A\\|\\|x\\|)\n$$\nDividing by $\\|x\\|$ to get the relative error:\n$$\n\\frac{\\|\\hat{x}-x\\|}{\\|x\\|} \\le \\frac{\\|A^{-1}\\|}{1-\\|A^{-1}\\|\\|\\Delta A\\|} \\left(\\frac{\\|\\Delta b\\|}{\\|x\\|} + \\|\\Delta A\\|\\right)\n$$\nUsing the inequality $\\|b\\|=\\|Ax\\| \\le \\|A\\|\\|x\\| \\implies \\frac{1}{\\|x\\|} \\le \\frac{\\|A\\|}{\\|b\\|}$:\n$$\n\\frac{\\|\\hat{x}-x\\|}{\\|x\\|} \\le \\frac{\\|A^{-1}\\|}{1-\\|A^{-1}\\|\\|\\Delta A\\|} \\left(\\frac{\\|\\Delta b\\|\\|A\\|}{\\|b\\|} + \\|\\Delta A\\|\\right) = \\frac{\\|A\\|\\|A^{-1}\\|}{1-\\|A\\|\\|A^{-1}\\|\\frac{\\|\\Delta A\\|}{\\|A\\|}} \\left(\\frac{\\|\\Delta b\\|}{\\|b\\|} + \\frac{\\|\\Delta A\\|}{\\|A\\|}\\right)\n$$\nLetting $\\kappa_2(A) = \\|A\\|\\|A^{-1}\\|$ be the condition number, and using the definition of backward error $\\eta$ which bounds $\\frac{\\|\\Delta A\\|}{\\|A\\|}$ and $\\frac{\\|\\Delta b\\|}{\\|b\\|}$, we arrive at the standard bound:\n$$\n\\frac{\\|\\hat{x}-x\\|}{\\|x\\|} \\le \\frac{\\kappa_2(A)}{1-\\kappa_2(A)\\frac{\\|\\Delta A\\|}{\\|A\\|}} \\left(\\frac{\\|\\Delta A\\|}{\\|A\\|} + \\frac{\\|\\Delta b\\|}{\\|b\\|}\\right)\n$$\nFor small backward error, the term $1-\\kappa_2(A)\\frac{\\|\\Delta A\\|}{\\|A\\|}$ is close to $1$. The bound illustrates that the forward error can be amplified by a factor of the condition number $\\kappa_2(A)$ relative to the backward error.\n\nNow, we evaluate this for the given data. First, we compute the condition number $\\kappa_2(A)$. The spectral norm of a diagonal matrix is the maximum absolute value of its diagonal entries.\n$$\n\\|A\\|_2 = \\max(1, |\\varepsilon|) = \\max(1, 10^{-14}) = 1\n$$\nThe inverse of $A$ is $A^{-1} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1/\\varepsilon \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 10^{14} \\end{pmatrix}$.\n$$\n\\|A^{-1}\\|_2 = \\max(1, |1/\\varepsilon|) = \\max(1, 10^{14}) = 10^{14}\n$$\nThe condition number is:\n$$\n\\kappa_2(A) = \\|A\\|_2 \\|A^{-1}\\|_2 = 1 \\cdot 10^{14} = 10^{14}\n$$\nThis is an extremely large condition number, indicating that the matrix $A$ is very ill-conditioned.\n\nThe derived inequality shows that the forward error is bounded by a quantity proportional to the product of the condition number and the backward error:\n$$\n\\text{Forward Error} \\lesssim \\kappa_2(A) \\times (\\text{Backward Error})\n$$\nIn our case, the backward error $\\eta$ is of the order $10^{-16}$, while the condition number $\\kappa_2(A)$ is $10^{14}$. Their product is approximately $10^{14} \\times 10^{-16} = 10^{-2}$. This theoretical estimate aligns perfectly with the forward error ratio we computed, which is $\\frac{10^{-2}}{\\sqrt{2}} \\approx 7.071 \\times 10^{-3}$. The large condition number acts as an amplification factor, transforming a very small backward error (meaning $\\hat{x}$ is the exact solution to a nearby problem) into a large forward error (meaning $\\hat{x}$ is far from the true solution $x$).", "answer": "$$\\boxed{0.007071}$$", "id": "3546754"}, {"introduction": "While the condition number provides a bound on the overall, or normwise, error, this can sometimes be misleading. A vector's norm can be dominated by its large components, masking significant relative errors in smaller, but potentially critical, components. This exercise explores the crucial distinction between normwise and componentwise error analysis by constructing a scenario where catastrophic cancellation leads to a 100% relative error in one component, even though the normwise error remains deceptively small. [@problem_id:3546786]", "problem": "Consider a linear system $A x = b$ with $A \\in \\mathbb{R}^{3 \\times 3}$ and $b \\in \\mathbb{R}^{3}$. In exact arithmetic, set $A = I_{3}$, and define the right-hand side by\n$$\nb^{\\ast} = \\begin{pmatrix}\n\\left(10^{8} + 1\\right) - 10^{8} \\\\\n10^{8} \\\\\n-10^{8}\n\\end{pmatrix}.\n$$\nAssume that $b^{\\ast}$ is formed by first computing $\\left(10^{8} + 1\\right)$ using decimal floating-point arithmetic with precision $t = 8$ significant digits and rounding to nearest at each operation, and then subtracting $10^{8}$, again in the same arithmetic. Let $\\widehat{b}$ denote the floating-point result of these two operations in the first component and exact assignments in the second and third components, and let $\\widehat{x}$ denote the computed solution to $A x = \\widehat{b}$ in the same arithmetic. Because $A = I_{3}$, we have $x^{\\ast} = b^{\\ast}$ and $\\widehat{x} = \\widehat{b}$.\n\nUsing the standard definitions of forward error in numerical linear algebra, where the normwise relative forward error is $\\left\\|\\widehat{x} - x^{\\ast}\\right\\|_{2} / \\left\\|x^{\\ast}\\right\\|_{2}$ and the componentwise relative forward error is $\\max_{i} \\left|\\widehat{x}_{i} - x^{\\ast}_{i}\\right| / \\left|x^{\\ast}_{i}\\right|$, construct the explicit vectors $x^{\\ast}$ and $\\widehat{x}$ induced by the above arithmetic and cancellation, and explain why the componentwise forward error is large while the normwise forward error is small. Then compute the ratio\n$$\n\\rho = \\frac{\\displaystyle \\max_{i} \\frac{\\left|\\widehat{x}_{i} - x^{\\ast}_{i}\\right|}{\\left|x^{\\ast}_{i}\\right|}}{\\displaystyle \\frac{\\left\\|\\widehat{x} - x^{\\ast}\\right\\|_{2}}{\\left\\|x^{\\ast}\\right\\|_{2}}}.\n$$\nExpress your final answer for $\\rho$ as a single closed-form analytic expression. No rounding is required.", "solution": "This problem explores the difference between normwise and componentwise forward error, highlighting how catastrophic cancellation can lead to large relative errors in small components that are masked by a small overall normwise error.\n\nFirst, we determine the exact solution vector $x^{\\ast}$. Since $A=I_3$, we have $x^{\\ast} = b^{\\ast}$.\nThe components of $b^{\\ast}$ are:\n- $b^{\\ast}_{1} = (10^{8} + 1) - 10^{8} = 1$\n- $b^{\\ast}_{2} = 10^{8}$\n- $b^{\\ast}_{3} = -10^{8}$\nThus, the exact solution is $x^{\\ast} = \\begin{pmatrix} 1 \\\\ 10^{8} \\\\ -10^{8} \\end{pmatrix}$.\n\nNext, we determine the computed solution $\\widehat{x}$. This is equal to the computed vector $\\widehat{b}$, which is formed using decimal floating-point arithmetic with $t=8$ significant digits.\n- To compute $\\widehat{b}_{1}$:\n  1. The first operation is $10^8 + 1$. In scientific notation, this is $1.0000000 \\times 10^8 + 1.0 \\times 10^0 = 1.0000000 \\times 10^8 + 0.00000001 \\times 10^8 = 1.00000001 \\times 10^8$.\n  2. This result has 9 significant digits. We must round it to the available precision $t=8$. Since the 9th digit is '1' (which is less than 5), we round down (truncate).\n  3. $\\text{fl}(10^8 + 1) = 1.0000000 \\times 10^8 = 10^8$.\n  4. The second operation is the subtraction: $\\text{fl}(10^8+1) - 10^8 = 10^8 - 10^8 = 0$.\n  5. Thus, $\\widehat{b}_{1} = 0$. This is a classic case of catastrophic cancellation, where the smaller term '1' was lost during the initial addition.\n- The second and third components are exact assignments, so $\\widehat{b}_{2} = 10^{8}$ and $\\widehat{b}_{3} = -10^{8}$.\nThe computed solution is therefore $\\widehat{x} = \\begin{pmatrix} 0 \\\\ 10^{8} \\\\ -10^{8} \\end{pmatrix}$.\n\nNow we compute the error measures. The absolute error vector is:\n$$\n\\widehat{x} - x^{\\ast} = \\begin{pmatrix} 0 \\\\ 10^{8} \\\\ -10^{8} \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 10^{8} \\\\ -10^{8} \\end{pmatrix} = \\begin{pmatrix} -1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n- **Componentwise relative forward error**:\n$$\n\\max_{i} \\frac{\\left|\\widehat{x}_{i} - x^{\\ast}_{i}\\right|}{\\left|x^{\\ast}_{i}\\right|} = \\max\\left( \\frac{|-1|}{|1|}, \\frac{|0|}{|10^8|}, \\frac{|0|}{|-10^8|} \\right) = \\max(1, 0, 0) = 1\n$$\nThe componentwise error is $1$, or $100\\%$, indicating a complete loss of accuracy in the first component. This is a large error.\n\n- **Normwise relative forward error**:\nThe norm of the error vector is $\\|\\widehat{x} - x^{\\ast}\\|_{2} = \\sqrt{(-1)^2 + 0^2 + 0^2} = 1$.\nThe norm of the exact solution is $\\|x^{\\ast}\\|_{2} = \\sqrt{1^2 + (10^8)^2 + (-10^8)^2} = \\sqrt{1 + 2 \\times 10^{16}}$.\nThe normwise error is:\n$$\n\\frac{\\left\\|\\widehat{x} - x^{\\ast}\\right\\|_{2}}{\\left\\|x^{\\ast}\\right\\|_{2}} = \\frac{1}{\\sqrt{1 + 2 \\times 10^{16}}}\n$$\nSince $2 \\times 10^{16} \\gg 1$, this value is extremely small, approximately $\\frac{1}{\\sqrt{2} \\times 10^8} \\approx 7.07 \\times 10^{-9}$. This is a small error.\n\nFinally, we compute the ratio $\\rho$:\n$$\n\\rho = \\frac{\\displaystyle \\max_{i} \\frac{\\left|\\widehat{x}_{i} - x^{\\ast}_{i}\\right|}{\\left|x^{\\ast}_{i}\\right|}}{\\displaystyle \\frac{\\left\\|\\widehat{x} - x^{\\ast}\\right\\|_{2}}{\\left\\|x^{\\ast}\\right\\|_{2}}} = \\frac{1}{\\frac{1}{\\sqrt{1 + 2 \\times 10^{16}}}} = \\sqrt{1 + 2 \\times 10^{16}}\n$$\nThe large value of $\\rho$ quantifies the discrepancy between the two error measures. The componentwise measure correctly identifies the catastrophic failure in one component, while the normwise measure, being dominated by the large and accurately computed components, misleadingly suggests the solution is highly accurate overall.", "answer": "$$ \\boxed{\\sqrt{1 + 2 \\times 10^{16}}} $$", "id": "3546786"}, {"introduction": "Having diagnosed the problem of ill-conditioning, we now turn to a practical remedy. Poor scaling in a matrix is a common source of large condition numbers, and often, this can be fixed. This practice demonstrates the power of equilibration, a preconditioning technique involving row and column scaling, to dramatically improve a system's condition number and, consequently, tighten the forward error bound for its solution. [@problem_id:3546820]", "problem": "Consider the linear system $A x = b$ with\n$$\nA = \\begin{pmatrix} 10^{-3} & 0 \\\\[4pt] 0 & 1 \\end{pmatrix}, \n\\qquad \nx_{\\star} = \\begin{pmatrix} 1 \\\\[4pt] 1 \\end{pmatrix},\n\\qquad \nb = A x_{\\star} = \\begin{pmatrix} 10^{-3} \\\\[4pt] 1 \\end{pmatrix}.\n$$\nWe solve for $x$ using a naive direct solver in base-$10$ floating-point arithmetic with $t=3$ significant digits rounded to nearest. Assume the solver is normwise backward stable in the following sense: the computed solution $\\widehat{x}$ is the exact solution to a perturbed system $(A + \\Delta A)\\widehat{x} = b + \\Delta b$ with\n$$\n\\max\\!\\left\\{\\frac{\\|\\Delta A\\|_{2}}{\\|A\\|_{2}},\\,\\frac{\\|\\Delta b\\|_{2}}{\\|b\\|_{2}}\\right\\} \\le u,\n\\qquad\nu = 5\\times 10^{-4}.\n$$\nYou will examine the forward error before and after an equilibration step that uses both row and column scalings. Define the diagonal scalings\n$$\nD_{r} = \\operatorname{diag}\\big(10^{3/2},\\,1\\big),\n\\qquad\nD_{c} = \\operatorname{diag}\\big(10^{3/2},\\,1\\big),\n$$\nand consider the equilibrated system\n$$\n\\big(D_{r} A D_{c}\\big)\\,y = D_{r} b,\n\\qquad\nx = D_{c}\\,y.\n$$\n\nUsing normwise forward error analysis in the spectral norm (also called the $2$-norm), proceed as follows:\n\n1. Start from the defining relations of backward stability and the basic perturbation identity to derive the standard bound that, provided $\\kappa_{2}(M)\\,\\eta < 1$,\n$$\n\\frac{\\|\\widehat{z}-z\\|_{2}}{\\|z\\|_{2}} \\le \\frac{\\kappa_{2}(M)\\,\\eta}{\\,1 - \\kappa_{2}(M)\\,\\eta\\,},\n$$\nwhere $M$ is a nonsingular coefficient matrix, $z$ the exact solution to $M z = f$, $\\widehat{z}$ the computed solution, and $\\eta$ the normwise relative backward error.\n2. Compute the $2$-norm condition numbers $\\kappa_{2}(A)$ and $\\kappa_{2}(D_{r} A D_{c})$.\n3. Using $u$ in place of $\\eta$ as justified by the backward stability assumption, form the worst-case relative forward error bounds for the original and for the equilibrated systems, and then compute the ratio\n$$\nR = \\frac{\\text{bound before equilibration}}{\\text{bound after equilibration}}.\n$$\n\nWhat is the numerical value of $R$? Round your answer to four significant figures. The final answer must be reported as a pure number without units.", "solution": "The problem requires a three-part analysis of forward error for a linear system, both before and after an equilibration step. We must first validate the problem, then proceed with the derivation and calculations as instructed.\n\n### Problem Validation\nThe problem is well-defined, scientifically grounded in numerical linear algebra, and provides all necessary information to proceed.\n- **Givens**: The matrices $A$, $D_r$, $D_c$, the vector $x_{\\star}$, the constant $u$, and the definitions of the original and equilibrated systems are provided.\n- **Tasks**: The tasks are clear: 1. Derive a standard forward error bound. 2. Compute two condition numbers. 3. Compute a ratio of error bounds.\n- **Consistency**: The problem asks to derive the forward error bound $\\frac{\\kappa_{2}(M)\\,\\eta}{\\,1 - \\kappa_{2}(M)\\,\\eta\\,}$, which is standard for a backward error model of the form $(M+\\Delta M)\\widehat{z}=f$ (i.e., with no perturbation on the right-hand side vector). The problem's stated backward stability model is $(A + \\Delta A)\\widehat{x} = b + \\Delta b$, which includes a perturbation $\\Delta b$. This model rigorously leads to a slightly different bound, typically $\\frac{2\\kappa_{2}(M)\\,\\eta}{\\,1 - \\kappa_{2}(M)\\,\\eta\\,}$ in its simplified form. However, the problem explicitly instructs us to first derive the former expression and then use it for the subsequent analysis. This suggests we should follow the instructions precisely as stated. As it turns out, the final ratio $R$ is independent of which of these two bounds is used, so this subtle inconsistency does not affect the final result. The problem is therefore deemed valid and solvable.\n\nWe now proceed with the solution, following the three specified steps.\n\n### Part 1: Derivation of the Forward Error Bound\n\nWe are asked to derive the standard forward error bound for a linear system $Mz=f$. Let $M$ be a nonsingular matrix. The exact solution is $z = M^{-1}f$. Let $\\widehat{z}$ be the computed solution, which is assumed to be the exact solution to a perturbed system. For the purpose of deriving the target formula, we consider the perturbation to be only in the matrix, i.e.,\n$$(M + \\Delta M) \\widehat{z} = f$$\nwhere the backward error is bounded by $\\|\\Delta M\\|_2 \\le \\eta \\|M\\|_2$ for some backward error measure $\\eta$.\n\nSubtracting the original equation $Mz=f$ from the perturbed one gives:\n$$(M + \\Delta M) \\widehat{z} - Mz = 0$$\n$$M\\widehat{z} + \\Delta M \\widehat{z} - Mz = 0$$\nRearranging the terms to find an expression for the error vector $\\widehat{z}-z$:\n$$M(\\widehat{z} - z) = -\\Delta M \\widehat{z}$$\nProvided $M$ is nonsingular, we can multiply by $M^{-1}$:\n$$\\widehat{z} - z = -M^{-1} \\Delta M \\widehat{z}$$\nTaking the $2$-norm of both sides and applying the sub-multiplicativity of matrix norms:\n$$\\|\\widehat{z} - z\\|_{2} = \\|-M^{-1} \\Delta M \\widehat{z}\\|_{2} \\le \\|M^{-1}\\|_{2} \\|\\Delta M\\|_{2} \\|\\widehat{z}\\|_{2}$$\nTo obtain the relative forward error, we divide by $\\|z\\|_2$ (assuming $z \\ne 0$):\n$$\\frac{\\|\\widehat{z} - z\\|_{2}}{\\|z\\|_{2}} \\le \\|M^{-1}\\|_{2} \\|\\Delta M\\|_{2} \\frac{\\|\\widehat{z}\\|_{2}}{\\|z\\|_{2}}$$\nNow, we use the backward error bound $\\|\\Delta M\\|_2 \\le \\eta \\|M\\|_2$:\n$$\\frac{\\|\\widehat{z} - z\\|_{2}}{\\|z\\|_{2}} \\le \\eta \\|M\\|_2 \\|M^{-1}\\|_{2} \\frac{\\|\\widehat{z}\\|_{2}}{\\|z\\|_{2}}$$\nRecognizing the $2$-norm condition number $\\kappa_2(M) = \\|M\\|_2 \\|M^{-1}\\|_2$:\n$$\\frac{\\|\\widehat{z} - z\\|_{2}}{\\|z\\|_{2}} \\le \\kappa_2(M) \\eta \\frac{\\|\\widehat{z}\\|_{2}}{\\|z\\|_{2}}$$\nThis bound depends on the unknown computed solution $\\widehat{z}$. We can eliminate this dependency by noting that $\\widehat{z} = z + (\\widehat{z}-z)$. Using the triangle inequality:\n$$\\|\\widehat{z}\\|_2 = \\|z + (\\widehat{z}-z)\\|_2 \\le \\|z\\|_2 + \\|\\widehat{z}-z\\|_2$$\nDividing by $\\|z\\|_2$ gives:\n$$\\frac{\\|\\widehat{z}\\|_2}{\\|z\\|_2} \\le 1 + \\frac{\\|\\widehat{z}-z\\|_2}{\\|z\\|_2}$$\nLet $e_{rel} = \\frac{\\|\\widehat{z} - z\\|_{2}}{\\|z\\|_{2}}$. The inequality becomes $e_{rel} \\le \\kappa_2(M) \\eta (1 + e_{rel})$.\n$$e_{rel} \\le \\kappa_2(M)\\eta + \\kappa_2(M)\\eta\\,e_{rel}$$\n$$e_{rel}(1 - \\kappa_2(M)\\eta) \\le \\kappa_2(M)\\eta$$\nProvided that $\\kappa_2(M)\\eta < 1$, the term $(1 - \\kappa_2(M)\\eta)$ is positive, and we can divide by it without changing the inequality direction:\n$$\\frac{\\|\\widehat{z}-z\\|_{2}}{\\|z\\|_{2}} \\le \\frac{\\kappa_{2}(M)\\,\\eta}{\\,1 - \\kappa_{2}(M)\\,\\eta\\,}$$\nThis completes the derivation of the specified bound.\n\n### Part 2: Computation of Condition Numbers\n\nFirst, we compute the condition number of the original matrix $A$.\n$$A = \\begin{pmatrix} 10^{-3} & 0 \\\\ 0 & 1 \\end{pmatrix}$$\nSince $A$ is a diagonal matrix, its singular values are the absolute values of its diagonal entries: $\\sigma_1 = 1$ and $\\sigma_2 = 10^{-3}$.\nThe $2$-norm of $A$ is its largest singular value, $\\|A\\|_2 = \\sigma_{max}(A) = 1$.\nThe inverse of $A$ is $A^{-1} = \\begin{pmatrix} 10^{3} & 0 \\\\ 0 & 1 \\end{pmatrix}$.\nThe $2$-norm of $A^{-1}$ is its largest singular value, $\\|A^{-1}\\|_2 = 10^3$.\nThe $2$-norm condition number is $\\kappa_2(A) = \\|A\\|_2 \\|A^{-1}\\|_2$.\n$$\\kappa_2(A) = 1 \\times 10^3 = 1000$$\nAlternatively, for a diagonal matrix, $\\kappa_2(A) = \\frac{\\sigma_{max}}{\\sigma_{min}} = \\frac{1}{10^{-3}} = 1000$.\n\nNext, we compute the condition number of the equilibrated matrix $\\tilde{A} = D_r A D_c$.\nThe scaling matrices are $D_r = \\operatorname{diag}(10^{3/2}, 1)$ and $D_c = \\operatorname{diag}(10^{3/2}, 1)$.\n$$\\tilde{A} = D_r A D_c = \\begin{pmatrix} 10^{3/2} & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 10^{-3} & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 10^{3/2} & 0 \\\\ 0 & 1 \\end{pmatrix}$$\n$$\\tilde{A} = \\begin{pmatrix} 10^{3/2} \\cdot 10^{-3} \\cdot 10^{3/2} & 0 \\\\ 0 & 1 \\cdot 1 \\cdot 1 \\end{pmatrix} = \\begin{pmatrix} 10^{3/2 - 3 + 3/2} & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 10^{0} & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$$\nThe equilibrated matrix is the $2 \\times 2$ identity matrix, $\\tilde{A}=I$.\nThe condition number of the identity matrix is:\n$$\\kappa_2(D_r A D_c) = \\kappa_2(I) = 1$$\n\n### Part 3: Ratio of Forward Error Bounds\n\nWe are instructed to use the formula derived in Part 1 to form the worst-case relative forward error bounds. We use $\\eta = u = 5 \\times 10^{-4}$.\n\nThe bound for the original system $Ax=b$ is:\n$$\\text{Bound}_{before} = \\frac{\\kappa_2(A) u}{1 - \\kappa_2(A) u}$$\nWe have $\\kappa_2(A) = 1000$ and $u = 5 \\times 10^{-4}$. The product is $\\kappa_2(A)u = 1000 \\times 5 \\times 10^{-4} = 0.5$. Since $0.5 < 1$, the bound is well-defined.\n$$\\text{Bound}_{before} = \\frac{0.5}{1 - 0.5} = \\frac{0.5}{0.5} = 1$$\n\nThe bound for the equilibrated system $\\tilde{A}y=\\tilde{b}$ is:\n$$\\text{Bound}_{after} = \\frac{\\kappa_2(\\tilde{A}) u}{1 - \\kappa_2(\\tilde{A}) u}$$\nWe have $\\kappa_2(\\tilde{A}) = 1$. The product is $\\kappa_2(\\tilde{A})u = 1 \\times 5 \\times 10^{-4} = 0.0005$. Since $0.0005 < 1$, the bound is well-defined.\n$$\\text{Bound}_{after} = \\frac{5 \\times 10^{-4}}{1 - 5 \\times 10^{-4}} = \\frac{5 \\times 10^{-4}}{0.9995}$$\nThis bound applies to the relative error in the solution $y$ of the equilibrated system. The problem asks for the ratio of the bounds \"for the original and for the equilibrated systems\", which compares the conditioning of the problem solved by the direct method in each case.\n\nThe ratio $R$ is:\n$$R = \\frac{\\text{Bound}_{before}}{\\text{Bound}_{after}} = \\frac{1}{\\frac{5 \\times 10^{-4}}{0.9995}} = \\frac{0.9995}{5 \\times 10^{-4}}$$\n$$R = \\frac{9995 \\times 10^{-4}}{5 \\times 10^{-4}} = \\frac{9995}{5} = 1999$$\nThe result $R=1999$ is an exact integer. The problem asks for the answer to be rounded to four significant figures. As $1999$ already has four significant figures, no rounding is necessary.", "answer": "$$\\boxed{1999}$$", "id": "3546820"}]}