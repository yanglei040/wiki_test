{"hands_on_practices": [{"introduction": "The ability to efficiently modify a matrix factorization is a cornerstone of dynamic numerical methods. When a column is removed from a matrix $A$, its upper trapezoidal factor $R$ in the QR factorization is disrupted, creating a subdiagonal entry. This exercise provides direct practice in the essential technique of using a Givens rotation to restore the required structure, a process often visualized as \"zeroing out a bulge\". Mastering this fundamental manipulation is key to developing efficient downdating algorithms. [@problem_id:3600365]", "problem": "Let $n=3$ and $m=5$. Consider a real matrix $A \\in \\mathbb{R}^{n \\times m}$ that has an orthogonal-triangular (QR) factorization $A = Q R$, where $Q \\in \\mathbb{R}^{3 \\times 3}$ is orthogonal and $R \\in \\mathbb{R}^{3 \\times 5}$ is upper trapezoidal, with the leading $3 \\times 3$ block upper triangular. Suppose the factor $R$ is\n$$\nR \\;=\\;\n\\begin{pmatrix}\n2  1  2  0  3 \\\\\n0  5  3  1  2 \\\\\n0  0  4  2  1\n\\end{pmatrix}.\n$$\nWe remove the second column of $A$ (and hence the second column of $R$) to form a downdated matrix $A' \\in \\mathbb{R}^{3 \\times 4}$ and an intermediate $R_{\\text{del}} \\in \\mathbb{R}^{3 \\times 4}$ obtained by deleting the second column of $R$. Using only fundamental properties of orthogonal transformations and Givens rotations, carry out the QR downdate by explicitly specifying the sequence of Givens rotations that are applied to $R_{\\text{del}}$ to restore the upper trapezoidal structure with an upper triangular leading $3 \\times 3$ block. In particular, derive the rotation parameters from first principles and apply them to the affected columns to eliminate the subdiagonal entry introduced by the column deletion.\n\nReport, as your final answer, the exact value of the updated diagonal entry in the second column of the leading triangular block, namely $r'_{22}$. Provide the exact value; no rounding is required.", "solution": "The problem statement is validated as scientifically grounded, well-posed, and objective. It is a standard exercise in numerical linear algebra concerning the downdating of a QR factorization after the removal of a column. All necessary data are provided, and the task is clearly defined.\n\nThe starting point is the given upper trapezoidal factor $R \\in \\mathbb{R}^{3 \\times 5}$ of a matrix $A \\in \\mathbb{R}^{3 \\times 5}$.\n$$\nR \\;=\\;\n\\begin{pmatrix}\n2  1  2  0  3 \\\\\n0  5  3  1  2 \\\\\n0  0  4  2  1\n\\end{pmatrix}.\n$$\nThe problem specifies that the second column of the original matrix $A$ is removed, which corresponds to removing the second column of $R$. This operation yields an intermediate matrix $R_{\\text{del}} \\in \\mathbb{R}^{3 \\times 4}$.\n$$\nR_{\\text{del}} \\;=\\;\n\\begin{pmatrix}\n2  2  0  3 \\\\\n0  3  1  2 \\\\\n0  4  2  1\n\\end{pmatrix}.\n$$\nThis matrix $R_{\\text{del}}$ is no longer in upper trapezoidal form because of the non-zero entry at position $(3, 2)$, which is $r_{32} = 4$. This structure, where all entries below the first subdiagonal are zero, is known as an upper Hessenberg form.\n\nTo restore the upper trapezoidal form, we must introduce a zero at the $(3, 2)$ position. This can be accomplished by left-multiplying $R_{\\text{del}}$ by a suitable orthogonal matrix that rotates the second and third rows. A Givens rotation is the elementary orthogonal transformation designed for this purpose. We seek a Givens rotation matrix $G_{23} \\in \\mathbb{R}^{3 \\times 3}$ that acts on the plane spanned by the second and third standard basis vectors. This matrix has the form:\n$$\nG_{23} =\n\\begin{pmatrix}\n1  0  0 \\\\\n0  c  s \\\\\n0  -s  c\n\\end{pmatrix}\n$$\nwhere $c = \\cos(\\theta)$ and $s = \\sin(\\theta)$ for some angle $\\theta$, satisfying the condition $c^2 + s^2 = 1$.\n\nThe new upper trapezoidal matrix, which we will call $R'$, is obtained by the product $R' = G_{23} R_{\\text{del}}$. The transformation only affects the second and third rows of $R_{\\text{del}}$. Let the second and third rows of $R_{\\text{del}}$ be $\\mathbf{r}_2^T = \\begin{pmatrix} 0  3  1  2 \\end{pmatrix}$ and $\\mathbf{r}_3^T = \\begin{pmatrix} 0  4  2  1 \\end{pmatrix}$, respectively. The new second and third rows, $\\mathbf{r'}_2^T$ and $\\mathbf{r'}_3^T$, will be linear combinations of the old rows:\n$$\n\\begin{pmatrix} \\mathbf{r'}_2^T \\\\ \\mathbf{r'}_3^T \\end{pmatrix} = \\begin{pmatrix} c  s \\\\ -s  c \\end{pmatrix} \\begin{pmatrix} \\mathbf{r}_2^T \\\\ \\mathbf{r}_3^T \\end{pmatrix}.\n$$\nThe parameters $c$ and $s$ are determined by the requirement that the entry at position $(3, 2)$ in the resulting matrix $R'$ becomes zero. This condition applies to the second column of $R_{\\text{del}}$, specifically the sub-vector $\\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix}$. We require:\n$$\n\\begin{pmatrix} c  s \\\\ -s  c \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} r'_{22} \\\\ 0 \\end{pmatrix}\n$$\nwhere $r'_{22}$ is the new diagonal entry. This matrix-vector equation yields a system of two linear equations:\n$1.$ $3c + 4s = r'_{22}$\n$2.$ $-3s + 4c = 0$\n\nFrom the second equation, we find $4c = 3s$. We can express $s$ in terms of $c$ as $s = \\frac{4}{3}c$. Substituting this into the identity $c^2+s^2=1$:\n$$ c^2 + \\left(\\frac{4}{3}c\\right)^2 = 1 \\implies c^2 + \\frac{16}{9}c^2 = 1 \\implies \\frac{25}{9}c^2 = 1 \\implies c^2 = \\frac{9}{25}. $$\nA standard convention for Givens rotations is to choose the positive root for $c$, so $c = \\frac{3}{5}$. Consequently, $s = \\frac{4}{3}c = \\frac{4}{3} \\cdot \\frac{3}{5} = \\frac{4}{5}$.\n\nThese values for $c$ and $s$ define the specific Givens rotation. We can now compute the new diagonal element $r'_{22}$ using the first equation:\n$$ r'_{22} = 3c + 4s = 3\\left(\\frac{3}{5}\\right) + 4\\left(\\frac{4}{5}\\right) = \\frac{9}{5} + \\frac{16}{5} = \\frac{25}{5} = 5. $$\nAlternatively, for a Givens rotation designed to zero out an element $b$ using a pivot $a$, the new pivot value is always the Euclidean norm of the vector $\\begin{pmatrix} a \\\\ b \\end{pmatrix}$. In our case, $a = 3$ and $b = 4$, so $r'_{22} = \\sqrt{3^2 + 4^2} = \\sqrt{9+16} = \\sqrt{25} = 5$. This confirms our calculation.\n\nThe problem asks for $r'_{22}$, which we have found. For completeness, we can compute the entire updated matrix $R'$. The first row remains unchanged. The new second and third rows are:\n$$\n\\mathbf{r'}_2^T = c \\mathbf{r}_2^T + s \\mathbf{r}_3^T = \\frac{3}{5}\\begin{pmatrix} 0  3  1  2 \\end{pmatrix} + \\frac{4}{5}\\begin{pmatrix} 0  4  2  1 \\end{pmatrix} = \\begin{pmatrix} 0  \\frac{9+16}{5}  \\frac{3+8}{5}  \\frac{6+4}{5} \\end{pmatrix} = \\begin{pmatrix} 0  5  \\frac{11}{5}  2 \\end{pmatrix}.\n$$\n$$\n\\mathbf{r'}_3^T = -s \\mathbf{r}_2^T + c \\mathbf{r}_3^T = -\\frac{4}{5}\\begin{pmatrix} 0  3  1  2 \\end{pmatrix} + \\frac{3}{5}\\begin{pmatrix} 0  4  2  1 \\end{pmatrix} = \\begin{pmatrix} 0  \\frac{-12+12}{5}  \\frac{-4+6}{5}  \\frac{-8+3}{5} \\end{pmatrix} = \\begin{pmatrix} 0  0  \\frac{2}{5}  -1 \\end{pmatrix}.\n$$\nThe fully updated matrix $R'$ is:\n$$\nR' =\n\\begin{pmatrix}\n2  2  0  3 \\\\\n0  5  \\frac{11}{5}  2 \\\\\n0  0  \\frac{2}{5}  -1\n\\end{pmatrix}.\n$$\nThis matrix is in the required upper trapezoidal form, and its leading $3 \\times 3$ block is upper triangular. The value at position $(2, 2)$ is indeed $5$.\n\nThe specific value requested is the updated diagonal entry in the second column, $r'_{22}$.\n$$\nr'_{22} = 5.\n$$", "answer": "$$\n\\boxed{5}\n$$", "id": "3600365"}, {"introduction": "Matrix factorizations are not just abstract tools; they are the engines behind many applications in data analysis. A prime example is updating a linear least-squares model when a data point is removed. This exercise bridges theory and practice by tasking you to downdate an LS solution using two different but related approaches: one based on the QR factorization and another on the Cholesky factorization of the normal equations. By showing that both paths lead to the same solution, you will gain a deeper appreciation for the interconnectedness of these methods and their practical utility. [@problem_id:3600432]", "problem": "Consider the linear least-squares (LS) problem defined by the overdetermined system $\\min_{x \\in \\mathbb{R}^{2}} \\|A x - b\\|_{2}$ with\n$$\nA \\;=\\;\n\\begin{pmatrix}\n1  0\\\\\n1  1\\\\\n1  2\\\\\n2  1\n\\end{pmatrix}\n,\\quad\nb \\;=\\;\n\\begin{pmatrix}\n1\\\\\n2\\\\\n2\\\\\n3\n\\end{pmatrix}.\n$$\nA single observation is removed: delete the third row of $A$ and the third entry of $b$, producing the downdated data\n$$\nA' \\;=\\;\n\\begin{pmatrix}\n1  0\\\\\n1  1\\\\\n2  1\n\\end{pmatrix}\n,\\quad\nb' \\;=\\;\n\\begin{pmatrix}\n1\\\\\n2\\\\\n3\n\\end{pmatrix}.\n$$\nStarting from the fundamental definition of LS and the core facts about orthogonal-triangular (QR) factorization and Cholesky factorization of the normal equations, derive the updated LS solution $\\hat{x}'$ after the row deletion using both of the following principled approaches:\n- A QR-based downdate that restores an upper-triangular factor via orthogonal transformations.\n- A Cholesky-based rank-one downdate of the normal matrix and right-hand-side.\n\nDemonstrate that both approaches produce the same $\\hat{x}'$. Express the final answer as a single row vector. No rounding is required.", "solution": "The problem requires the solution to a downdated linear least-squares (LS) problem. An initial LS problem $\\min_{x \\in \\mathbb{R}^{2}} \\|A x - b\\|_{2}$ is given, and a new problem $\\min_{x' \\in \\mathbb{R}^{2}} \\|A' x' - b'\\|_{2}$ is formed by deleting the third row from matrix $A$ and the third element from vector $b$. We must find the new solution vector $\\hat{x}'$ using two distinct methods: a QR-based downdate and a Cholesky-based downdate, and show they yield the same result.\n\nThe original data are:\n$$\nA \\;=\\;\n\\begin{pmatrix}\n1  0\\\\\n1  1\\\\\n1  2\\\\\n2  1\n\\end{pmatrix}\n,\\quad\nb \\;=\\;\n\\begin{pmatrix}\n1\\\\\n2\\\\\n2\\\\\n3\n\\end{pmatrix}.\n$$\nThe third row of $A$ is $a_3^T = \\begin{pmatrix} 1  2 \\end{pmatrix}$, and the third element of $b$ is $b_3 = 2$.\nThe downdated data are:\n$$\nA' \\;=\\;\n\\begin{pmatrix}\n1  0\\\\\n1  1\\\\\n2  1\n\\end{pmatrix}\n,\\quad\nb' \\;=\\;\n\\begin{pmatrix}\n1\\\\\n2\\\\\n3\n\\end{pmatrix}.\n$$\nThe solution $\\hat{x}$ to the LS problem $\\min_{x} \\|Ax-b\\|_2$ is formally given by the solution to the normal equations $A^T A x = A^T b$. Similarly, the downdated solution $\\hat{x}'$ is the solution to $A'^T A' x' = A'^T b'$.\n\nFirst, we establish the relationship between the original and downdated normal equations. The downdated normal matrix $A'^T A'$ is related to the original $A^T A$ by a rank-one update:\n$$\nA'^T A' = A^T A - a_3 a_3^T.\n$$\nSimilarly, the downdated right-hand-side vector is:\n$$\nA'^T b' = A^T b - a_3 b_3.\n$$\n\nWe will now solve for $\\hat{x}'$ using the two specified methods.\n\n**Method 1: QR-based Downdate**\n\nThis approach involves downdating the factors of the QR factorization of $A$. The LS solution is found by solving the triangular system $Rx=c_1$, where $A=QR$ ($Q$ has orthonormal columns, $R$ is upper triangular) and $c_1$ consists of the first $n$ components of $Q^T b$. The normal equations can be written as $R^T R x = R^T c_1$.\n\nThe downdating procedure updates the factors $R$ and $c_1$ to $R'$ and $c_1'$ for the new problem. The new factors satisfy:\n$$\nR'^T R' = A'^T A' = A^T A - a_3 a_3^T = R^T R - a_3 a_3^T\n$$\n$$\nR'^T c_1' = A'^T b' = A^T b - a_3 b_3 = R^T c_1 - a_3 b_3\n$$\n\n1.  First, let's compute the components for the original normal equations, $A^T A$ and $A^T b$.\n    $$\n    A^T A = \\begin{pmatrix} 1  1  1  2 \\\\ 0  1  2  1 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 1  1 \\\\ 1  2 \\\\ 2  1 \\end{pmatrix} = \\begin{pmatrix} 1+1+1+4  0+1+2+2 \\\\ 0+1+2+2  0+1+4+1 \\end{pmatrix} = \\begin{pmatrix} 7  5 \\\\ 5  6 \\end{pmatrix}.\n    $$\n    $$\n    A^T b = \\begin{pmatrix} 1  1  1  2 \\\\ 0  1  2  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 2 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} 1+2+2+6 \\\\ 0+2+4+3 \\end{pmatrix} = \\begin{pmatrix} 11 \\\\ 9 \\end{pmatrix}.\n    $$\n    So, $R^T R = \\begin{pmatrix} 7  5 \\\\ 5  6 \\end{pmatrix}$ and $R^T c_1 = \\begin{pmatrix} 11 \\\\ 9 \\end{pmatrix}$.\n\n2.  Next, we compute the downdated matrices $R'^T R'$ and $R'^T c_1'$. With $a_3 = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$ and $b_3=2$:\n    $$\n    R'^T R' = \\begin{pmatrix} 7  5 \\\\ 5  6 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\begin{pmatrix} 1  2 \\end{pmatrix} = \\begin{pmatrix} 7  5 \\\\ 5  6 \\end{pmatrix} - \\begin{pmatrix} 1  2 \\\\ 2  4 \\end{pmatrix} = \\begin{pmatrix} 6  3 \\\\ 3  2 \\end{pmatrix}.\n    $$\n    $$\n    R'^T c_1' = \\begin{pmatrix} 11 \\\\ 9 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} (2) = \\begin{pmatrix} 11 \\\\ 9 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} 9 \\\\ 5 \\end{pmatrix}.\n    $$\n\n3.  To restore the upper-triangular structure, we find the new factor $R'$ from $R'^T R'$ using Cholesky factorization. Let $R' = \\begin{pmatrix} r'_{11}  r'_{12} \\\\ 0  r'_{22} \\end{pmatrix}$.\n    $r'_{11} = \\sqrt{6}$.\n    $r'_{11} r'_{12} = 3 \\implies r'_{12} = 3 / \\sqrt{6} = \\sqrt{3/2}$.\n    $(r'_{12})^2 + (r'_{22})^2 = 2 \\implies 3/2 + (r'_{22})^2 = 2 \\implies (r'_{22})^2 = 1/2 \\implies r'_{22} = 1/\\sqrt{2}$.\n    So, $R' = \\begin{pmatrix} \\sqrt{6}  \\sqrt{3/2} \\\\ 0  1/\\sqrt{2} \\end{pmatrix}$.\n\n4.  We find the new right-hand-side vector $c_1'$ by solving the lower triangular system $R'^T c_1' = \\begin{pmatrix} 9 \\\\ 5 \\end{pmatrix}$.\n    Let $c_1' = \\begin{pmatrix} c'_1 \\\\ c'_2 \\end{pmatrix}$.\n    $R'^T = \\begin{pmatrix} \\sqrt{6}  0 \\\\ \\sqrt{3/2}  1/\\sqrt{2} \\end{pmatrix}$.\n    $\\sqrt{6} c'_1 = 9 \\implies c'_1 = 9/\\sqrt{6}$.\n    $\\sqrt{3/2} c'_1 + (1/\\sqrt{2}) c'_2 = 5 \\implies \\sqrt{3/2} (9/\\sqrt{6}) + c'_2/\\sqrt{2} = 5$.\n    $9\\sqrt{3/12} + c'_2/\\sqrt{2} = 5 \\implies 9\\sqrt{1/4} + c'_2/\\sqrt{2} = 5 \\implies 9/2 + c'_2/\\sqrt{2} = 5$.\n    $c'_2/\\sqrt{2} = 1/2 \\implies c'_2 = \\sqrt{2}/2 = 1/\\sqrt{2}$.\n    So, $c_1' = \\begin{pmatrix} 9/\\sqrt{6} \\\\ 1/\\sqrt{2} \\end{pmatrix}$.\n\n5.  Finally, we solve the upper triangular system $R' \\hat{x}' = c_1'$ for the downdated solution $\\hat{x}' = \\begin{pmatrix} x'_1 \\\\ x'_2 \\end{pmatrix}$.\n    $$\n    \\begin{pmatrix} \\sqrt{6}  \\sqrt{3/2} \\\\ 0  1/\\sqrt{2} \\end{pmatrix} \\begin{pmatrix} x'_1 \\\\ x'_2 \\end{pmatrix} = \\begin{pmatrix} 9/\\sqrt{6} \\\\ 1/\\sqrt{2} \\end{pmatrix}.\n    $$\n    From the second row: $(1/\\sqrt{2}) x'_2 = 1/\\sqrt{2} \\implies x'_2 = 1$.\n    From the first row: $\\sqrt{6} x'_1 + \\sqrt{3/2} x'_2 = 9/\\sqrt{6}$.\n    $\\sqrt{6} x'_1 + \\sqrt{3/2} (1) = 9/\\sqrt{6}$.\n    Multiplying by $\\sqrt{6}$: $6 x'_1 + \\sqrt{3/2}\\sqrt{6} = 9 \\implies 6 x'_1 + \\sqrt{9} = 9 \\implies 6 x'_1 + 3 = 9$.\n    $6 x'_1 = 6 \\implies x'_1 = 1$.\n    Thus, the solution is $\\hat{x}' = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n\n**Method 2: Cholesky-based Rank-one Downdate**\n\nThis method directly downdates the normal equations matrix $M=A^T A$ and right-hand-side vector $y=A^T b$, and then solves the resulting linear system.\n\n1.  Start with the original normal equations matrix $M=A^T A$ and vector $y=A^T b$:\n    $$\n    M = \\begin{pmatrix} 7  5 \\\\ 5  6 \\end{pmatrix}, \\quad y = \\begin{pmatrix} 11 \\\\ 9 \\end{pmatrix}.\n    $$\n\n2.  Perform the rank-one downdate using $a_3 = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$ and $b_3=2$.\n    The downdated matrix is $M' = M - a_3 a_3^T$:\n    $$\n    M' = \\begin{pmatrix} 7  5 \\\\ 5  6 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} \\begin{pmatrix} 1  2 \\end{pmatrix} = \\begin{pmatrix} 7  5 \\\\ 5  6 \\end{pmatrix} - \\begin{pmatrix} 1  2 \\\\ 2  4 \\end{pmatrix} = \\begin{pmatrix} 6  3 \\\\ 3  2 \\end{pmatrix}.\n    $$\n    The downdated vector is $y' = y - a_3 b_3$:\n    $$\n    y' = \\begin{pmatrix} 11 \\\\ 9 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix} (2) = \\begin{pmatrix} 11 \\\\ 9 \\end{pmatrix} - \\begin{pmatrix} 2 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} 9 \\\\ 5 \\end{pmatrix}.\n    $$\n\n3.  Solve the downdated normal equations $M' \\hat{x}' = y'$:\n    $$\n    \\begin{pmatrix} 6  3 \\\\ 3  2 \\end{pmatrix} \\begin{pmatrix} x'_1 \\\\ x'_2 \\end{pmatrix} = \\begin{pmatrix} 9 \\\\ 5 \\end{pmatrix}.\n    $$\n    This is a system of two linear equations:\n    $6x'_1 + 3x'_2 = 9 \\implies 2x'_1 + x'_2 = 3$.\n    $3x'_1 + 2x'_2 = 5$.\n    From the first equation, $x'_2 = 3 - 2x'_1$.\n    Substituting into the second equation: $3x'_1 + 2(3 - 2x'_1) = 5$.\n    $3x'_1 + 6 - 4x'_1 = 5 \\implies -x'_1 = -1 \\implies x'_1 = 1$.\n    Substituting back: $x'_2 = 3 - 2(1) = 1$.\n    The solution is $\\hat{x}' = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n\n**Conclusion**\n\nBoth the QR-based downdate method and the Cholesky-based downdate method produce the same solution for the downdated least-squares problem: $\\hat{x}' = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$. This confirms the correctness of both derivations. The final answer is expressed as a row vector as requested.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1  1\n\\end{pmatrix}\n}\n$$", "id": "3600432"}, {"introduction": "In numerical linear algebra, a mathematically correct algorithm can still fail in practice due to finite-precision arithmetic. This exercise serves as a crucial cautionary tale, demonstrating how a naive downdate of a symmetric indefinite $LDL^T$ factorization can lead to catastrophic numerical instability. By working through a carefully chosen example, you will witness firsthand how neglecting to revisit pivoting choices can cause explosive element growth in the factors, compromising the accuracy of the solution. [@problem_id:3600385]", "problem": "Consider the lower–diagonal–lower transpose ($LDL^{T}$) factorization of a symmetric matrix $A \\in \\mathbb{R}^{3 \\times 3}$ with unit lower-triangular $L$ and diagonal $D$. You are told that $A$ is the identity matrix, so $A = I_{3}$, $L = I_{3}$, and $D = I_{3}$. Define the symmetric rank-$1$ downdate\n$$\nA_{-} = A - u u^{T}\n$$\nwith $u = \\begin{pmatrix} 1 - \\delta \\\\ 1 \\\\ 0 \\end{pmatrix}$ and $\\delta = 10^{-8}$. A naive $LDL^{T}$ downdate that does not revisit pivoting choices proceeds by forcing the first pivot to remain a $1 \\times 1$ pivot at index $1$ and performing the first symmetric elimination step directly on $A_{-}$, without changing the pivot order or switching to a $2 \\times 2$ pivot. In this step, let $\\tilde{d}_{1}$ denote the updated first diagonal pivot and $\\tilde{L}_{21}$ the updated first-column subdiagonal multiplier.\n\nStarting only from the definition of the $LDL^{T}$ factorization, the identity $A = L D L^{T}$, and the definition of the downdate $A_{-} = A - u u^{T}$, derive an explicit expression for $\\tilde{L}_{21}$ produced by this naive first step and evaluate its magnitude for the data above. Your answer must be the numerical value of $\\left|\\tilde{L}_{21}\\right|$. Round your answer to four significant figures.\n\nBriefly justify why this constitutes a counterexample demonstrating that a naive $LDL^{T}$ downdate without revisiting pivots can cause large element growth or breakdown, and explain the mechanism in terms of the updated pivot and multipliers. No additional assumptions or external formulas beyond the stated definitions may be used.", "solution": "The problem is valid as it presents a well-posed, scientifically grounded question in numerical linear algebra. All necessary information is provided, and the task is to perform a specific calculation and provide a justification based on fundamental principles of matrix factorization.\n\nFirst, we construct the downdated matrix $A_{-} = A - u u^{T}$. Given $A = I_{3}$, the $3 \\times 3$ identity matrix, and $u = \\begin{pmatrix} 1 - \\delta \\\\ 1 \\\\ 0 \\end{pmatrix}$, we first compute the outer product $u u^{T}$:\n$$\nu u^{T} = \\begin{pmatrix} 1 - \\delta \\\\ 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1 - \\delta  1  0 \\end{pmatrix} = \\begin{pmatrix} (1-\\delta)^{2}  1-\\delta  0 \\\\ 1-\\delta  1  0 \\\\ 0  0  0 \\end{pmatrix}\n$$\nThe downdated matrix $A_{-}$ is then:\n$$\nA_{-} = I_{3} - u u^{T} = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} - \\begin{pmatrix} (1-\\delta)^{2}  1-\\delta  0 \\\\ 1-\\delta  1  0 \\\\ 0  0  0 \\end{pmatrix}\n$$\n$$\nA_{-} = \\begin{pmatrix} 1 - (1-\\delta)^{2}  -(1-\\delta)  0 \\\\ -(1-\\delta)  1-1  0 \\\\ 0  0  1-0 \\end{pmatrix}\n$$\nLet's simplify the element $A_{-}(1,1)$:\n$$\nA_{-}(1,1) = 1 - (1 - 2\\delta + \\delta^{2}) = 2\\delta - \\delta^{2} = \\delta(2-\\delta)\n$$\nThus, the downdated matrix is:\n$$\nA_{-} = \\begin{pmatrix} \\delta(2-\\delta)  -(1-\\delta)  0 \\\\ -(1-\\delta)  0  0 \\\\ 0  0  1 \\end{pmatrix}\n$$\nThe problem describes a naive $LDL^{T}$ factorization step that proceeds without repivoting, forcing the use of the $(1,1)$ element as the pivot. The $LDL^{T}$ factorization is a form of symmetric Gaussian elimination. In the first step, the pivot is $\\tilde{d}_{1} = A_{-}(1,1)$. The multipliers required to eliminate the subdiagonal elements in the first column are stored in the first column of the unit lower-triangular matrix $\\tilde{L}$.\nThe multiplier $\\tilde{L}_{21}$ is defined as the factor by which row $1$ of $A_{-}$ is multiplied and subtracted from row $2$ to create a zero in the $(2,1)$ position. This is given by the ratio of the element to be eliminated to the pivot element:\n$$\n\\tilde{L}_{21} = \\frac{A_{-}(2,1)}{A_{-}(1,1)}\n$$\nSubstituting the expressions for the elements of $A_{-}$:\n$$\n\\tilde{L}_{21} = \\frac{-(1-\\delta)}{\\delta(2-\\delta)}\n$$\nWe are asked to evaluate the magnitude $|\\tilde{L}_{21}|$ for $\\delta = 10^{-8}$.\n$$\n\\left|\\tilde{L}_{21}\\right| = \\left| \\frac{-(1-\\delta)}{\\delta(2-\\delta)} \\right| = \\frac{1-\\delta}{\\delta(2-\\delta)}\n$$\nSubstituting $\\delta = 10^{-8}$:\n$$\n\\left|\\tilde{L}_{21}\\right| = \\frac{1 - 10^{-8}}{10^{-8}(2 - 10^{-8})} = \\frac{0.99999999}{10^{-8}(1.99999998)} = \\frac{0.99999999}{1.99999998 \\times 10^{-8}}\n$$\nPerforming the division:\n$$\n\\left|\\tilde{L}_{21}\\right| = 0.5000000025 \\times 10^{8} = 50000000.25\n$$\nRounding this result to four significant figures gives $5.000 \\times 10^{7}$.\n\nThis result serves as a counterexample demonstrating the instability of a naive downdating procedure for the following reasons:\nThe original factorization $A = I_{3} = I_{3} I_{3} I_{3}^{T}$ consists of well-behaved matrices with elements of magnitude $1$ or $0$. The rank-$1$ modification with vector $u$ is seemingly innocuous. However, it transforms the matrix $A$ into $A_{-}$, which has a very different structure.\nThe pivot element $\\tilde{d}_{1} = A_{-}(1,1) = 2\\delta - \\delta^{2}$ with $\\delta = 10^{-8}$ is approximately $2 \\times 10^{-8}$, which is extremely close to zero. The off-diagonal element $A_{-}(2,1) = -(1-\\delta)$ has a magnitude close to $1$.\nThe mechanism for instability is the division of a moderately sized off-diagonal element ($A_{-}(2,1) \\approx -1$) by a very small pivot element ($\\tilde{d}_{1} \\approx 2 \\times 10^{-8}$). This results in an extremely large multiplier, $|\\tilde{L}_{21}| \\approx 0.5 \\times 10^{8}$. This phenomenon is known as element growth. Large elements in the factor matrices are a primary indicator of numerical instability, as they magnify rounding errors in subsequent computations. A robust symmetric indefinite factorization algorithm, such as one using Bunch-Kaufman pivoting, would inspect the matrix $A_{-}$ and identify that the $1 \\times 1$ pivot $A_{-}(1,1)$ is too small relative to the off-diagonal elements. It would then opt for a more stable pivot, such as a $2 \\times 2$ block pivot using the leading $2 \\times 2$ submatrix $\\begin{pmatrix} A_{-}(1,1)  A_{-}(1,2) \\\\ A_{-}(2,1)  A_{-}(2,2) \\end{pmatrix}$, thereby avoiding the division by a small number and the consequent element growth. The naive approach fails because it does not revisit the pivoting choice, which became poor after the downdate.", "answer": "$$\\boxed{5.000 \\times 10^{7}}$$", "id": "3600385"}]}