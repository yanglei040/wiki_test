{"hands_on_practices": [{"introduction": "Mastering a new computational tool begins with applying it to a concrete example. This first exercise provides a direct, hands-on application of the Sturm sequence method for counting eigenvalues. By evaluating the sequence of principal minor determinants at two different points and counting the sign changes, you will determine the number of eigenvalues within a specific interval, solidifying the fundamental mechanics of this powerful technique [@problem_id:3582435].", "problem": "Consider the real symmetric tridiagonal matrix $A \\in \\mathbb{R}^{4 \\times 4}$ given by\n$$\nA \\;=\\;\n\\begin{pmatrix}\n4  1  0  0 \\\\\n1  2  1  0 \\\\\n0  1  2  1 \\\\\n0  0  1  3\n\\end{pmatrix}.\n$$\nFor $\\lambda \\in \\mathbb{R}$, let $p_k(\\lambda)$ denote the determinant of the leading $k \\times k$ principal minor of $A - \\lambda I$, with the convention $p_0(\\lambda) = 1$. Define the two shifts $\\lambda_1 = \\tfrac{3}{2}$ and $\\lambda_2 = \\tfrac{5}{2}$ with $\\lambda_1  \\lambda_2$. Using only the fundamental definitions of the Sturm sequence and its role in eigenvalue counting for real symmetric matrices, evaluate the signs of $p_k(\\lambda_1)$ and $p_k(\\lambda_2)$ for $k = 0, 1, 2, 3, 4$, determine the counts $\\nu(\\lambda_1)$ and $\\nu(\\lambda_2)$ of eigenvalues of $A$ that are strictly less than $\\lambda_1$ and $\\lambda_2$, respectively, and interpret the difference $\\nu(\\lambda_2) - \\nu(\\lambda_1)$ as the number of eigenvalues of $A$ in the half-open interval $(\\lambda_1, \\lambda_2]$. Provide the number of eigenvalues in $(\\lambda_1,\\lambda_2]$ as an exact integer (no rounding required).", "solution": "The user wants me to solve a problem that requires the use of Sturm sequences to count the number of eigenvalues of a given $4 \\times 4$ real symmetric tridiagonal matrix within a specific interval.\n\n### Problem Validation\n\nFirst, the problem statement must be validated.\n\n**Step 1: Extract Givens**\n- The matrix $A \\in \\mathbb{R}^{4 \\times 4}$ is given by: $A \\;=\\; \\begin{pmatrix} 4  1  0  0 \\\\ 1  2  1  0 \\\\ 0  1  2  1 \\\\ 0  0  1  3 \\end{pmatrix}$.\n- For $\\lambda \\in \\mathbb{R}$, $p_k(\\lambda)$ is defined as the determinant of the leading $k \\times k$ principal minor of $A - \\lambda I$.\n- A convention is provided: $p_0(\\lambda) = 1$.\n- Two shifts are given: $\\lambda_1 = \\frac{3}{2}$ and $\\lambda_2 = \\frac{5}{2}$.\n- The objective is to find the signs of $p_k(\\lambda_1)$ and $p_k(\\lambda_2)$ for $k = 0, 1, 2, 3, 4$, determine the eigenvalue counts $\\nu(\\lambda_1)$ and $\\nu(\\lambda_2)$, and find the number of eigenvalues in the interval $(\\lambda_1, \\lambda_2]$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is a standard application of the Sturm sequence method (specifically, the sequence of characteristic polynomials of leading principal minors) to localize eigenvalues of a real symmetric tridiagonal matrix. This is a fundamental and well-established topic in numerical linear algebra.\n- **Well-Posed:** The problem is clearly defined. The matrix, the definition of the polynomial sequence, and the evaluation points are all specified. The task leads to a unique, stable, and meaningful numerical answer.\n- **Objective:** The problem statement is precise, quantitative, and free from any subjective or ambiguous language.\n\n**Step 3: Verdict and Action**\nThe problem is valid as it is scientifically sound, well-posed, and objective. I will proceed with a full solution.\n\n### Solution\n\nThe problem requires using the Sturm sequence property of the characteristic polynomials of the leading principal minors of the matrix $A - \\lambda I$. For a real symmetric tridiagonal matrix $A$, the number of eigenvalues strictly less than a given value $\\lambda$, denoted $\\nu(\\lambda)$, is equal to the number of sign changes in the sequence $\\{p_0(\\lambda), p_1(\\lambda), \\dots, p_n(\\lambda)\\}$. If any $p_k(\\lambda) = 0$, its sign is taken to be opposite to the sign of $p_{k-1}(\\lambda)$.\n\nThe matrix is $A = \\begin{pmatrix} d_1  e_1  0  0 \\\\ e_1  d_2  e_2  0 \\\\ 0  e_2  d_3  e_3 \\\\ 0  0  e_3  d_4 \\end{pmatrix}$, where $d_1=4$, $d_2=2$, $d_3=2$, $d_4=3$, and $e_1=e_2=e_3=1$. The polynomials $p_k(\\lambda) = \\det(A_k - \\lambda I_k)$ satisfy the three-term recurrence relation:\n$p_k(\\lambda) = (d_k - \\lambda) p_{k-1}(\\lambda) - e_{k-1}^2 p_{k-2}(\\lambda)$ for $k \\ge 2$.\n\nThe sequence of polynomials is defined as follows:\n$p_0(\\lambda) = 1$\n$p_1(\\lambda) = d_1 - \\lambda = 4 - \\lambda$\nFor $k=2,3,4$, we use the recurrence with $e_k=1$ for all $k$: $p_k(\\lambda) = (d_k - \\lambda) p_{k-1}(\\lambda) - p_{k-2}(\\lambda)$.\n\n$p_2(\\lambda) = (d_2 - \\lambda)p_1(\\lambda) - p_0(\\lambda) = (2 - \\lambda)(4 - \\lambda) - 1 = \\lambda^2 - 6\\lambda + 8 - 1 = \\lambda^2 - 6\\lambda + 7$\n\n$p_3(\\lambda) = (d_3 - \\lambda)p_2(\\lambda) - p_1(\\lambda) = (2 - \\lambda)(\\lambda^2 - 6\\lambda + 7) - (4 - \\lambda) = (2\\lambda^2 - 12\\lambda + 14 - \\lambda^3 + 6\\lambda^2 - 7\\lambda) - (4 - \\lambda) = -\\lambda^3 + 8\\lambda^2 - 19\\lambda + 14 - 4 + \\lambda = -\\lambda^3 + 8\\lambda^2 - 18\\lambda + 10$\n\n$p_4(\\lambda) = (d_4 - \\lambda)p_3(\\lambda) - p_2(\\lambda) = (3 - \\lambda)(-\\lambda^3 + 8\\lambda^2 - 18\\lambda + 10) - (\\lambda^2 - 6\\lambda + 7) = (-3\\lambda^3 + 24\\lambda^2 - 54\\lambda + 30 + \\lambda^4 - 8\\lambda^3 + 18\\lambda^2 - 10\\lambda) - (\\lambda^2 - 6\\lambda + 7) = \\lambda^4 - 11\\lambda^3 + 42\\lambda^2 - 64\\lambda + 30 - \\lambda^2 + 6\\lambda - 7 = \\lambda^4 - 11\\lambda^3 + 41\\lambda^2 - 58\\lambda + 23$\n\nNow, we evaluate this sequence at the two given shifts, $\\lambda_1 = \\frac{3}{2}$ and $\\lambda_2 = \\frac{5}{2}$.\n\n**Evaluation at $\\lambda_1 = \\frac{3}{2}$:**\n$p_0(\\frac{3}{2}) = 1$\n$p_1(\\frac{3}{2}) = 4 - \\frac{3}{2} = \\frac{5}{2}$\n$p_2(\\frac{3}{2}) = (\\frac{3}{2})^2 - 6(\\frac{3}{2}) + 7 = \\frac{9}{4} - 9 + 7 = \\frac{9}{4} - 2 = \\frac{1}{4}$\n$p_3(\\frac{3}{2}) = -(\\frac{3}{2})^3 + 8(\\frac{3}{2})^2 - 18(\\frac{3}{2}) + 10 = -\\frac{27}{8} + 8(\\frac{9}{4}) - 27 + 10 = -\\frac{27}{8} + 18 - 17 = 1 - \\frac{27}{8} = -\\frac{19}{8}$\n$p_4(\\frac{3}{2}) = \\lambda_1^4 - 11\\lambda_1^3 + 41\\lambda_1^2 - 58\\lambda_1 + 23 = (\\frac{3}{2})^4 - 11(\\frac{3}{2})^3 + 41(\\frac{3}{2})^2 - 58(\\frac{3}{2}) + 23 = \\frac{81}{16} - \\frac{297}{8} + \\frac{369}{4} - 87 + 23 = \\frac{81 - 594 + 1476 - 1024}{16} = \\frac{1557 - 1618}{16} = -\\frac{61}{16}$\n\nThe signs of the sequence $\\{p_k(\\frac{3}{2})\\}$ for $k=0, 1, 2, 3, 4$ are $\\{+, +, +, -, -\\}$.\nThe number of sign changes in this sequence is the count of successions of non-like signs. There is one sign change between $p_2(\\frac{3}{2})$ and $p_3(\\frac{3}{2})$.\nThus, the number of eigenvalues of $A$ strictly less than $\\frac{3}{2}$ is $\\nu(\\lambda_1) = \\nu(\\frac{3}{2}) = 1$.\n\n**Evaluation at $\\lambda_2 = \\frac{5}{2}$:**\n$p_0(\\frac{5}{2}) = 1$\n$p_1(\\frac{5}{2}) = 4 - \\frac{5}{2} = \\frac{3}{2}$\n$p_2(\\frac{5}{2}) = (\\frac{5}{2})^2 - 6(\\frac{5}{2}) + 7 = \\frac{25}{4} - 15 + 7 = \\frac{25}{4} - 8 = -\\frac{7}{4}$\n$p_3(\\frac{5}{2}) = -(\\frac{5}{2})^3 + 8(\\frac{5}{2})^2 - 18(\\frac{5}{2}) + 10 = -\\frac{125}{8} + 8(\\frac{25}{4}) - 45 + 10 = -\\frac{125}{8} + 50 - 35 = 15 - \\frac{125}{8} = \\frac{120-125}{8} = -\\frac{5}{8}$\n$p_4(\\frac{5}{2}) = (\\frac{5}{2})^4 - 11(\\frac{5}{2})^3 + 41(\\frac{5}{2})^2 - 58(\\frac{5}{2}) + 23 = \\frac{625}{16} - \\frac{1375}{8} + \\frac{1025}{4} - 145 + 23 = \\frac{625 - 2750 + 4100 - 1952}{16} = \\frac{4725 - 4702}{16} = \\frac{23}{16}$\n\nThe signs of the sequence $\\{p_k(\\frac{5}{2})\\}$ for $k=0, 1, 2, 3, 4$ are $\\{+, +, -, -, +\\}$.\nThere is a sign change from $p_1(\\frac{5}{2})$ to $p_2(\\frac{5}{2})$ and another from $p_3(\\frac{5}{2})$ to $p_4(\\frac{5}{2})$.\nThus, the number of eigenvalues of $A$ strictly less than $\\frac{5}{2}$ is $\\nu(\\lambda_2) = \\nu(\\frac{5}{2}) = 2$.\n\n**Interpretation of the Difference**\nThe quantity $\\nu(\\lambda_2) - \\nu(\\lambda_1)$ counts the number of eigenvalues of $A$ in the interval $[\\lambda_1, \\lambda_2)$. As $p_4(\\lambda) = \\det(A - \\lambda I)$, the roots of $p_4(\\lambda)$ are the eigenvalues of $A$. Since $p_4(\\lambda_1) = -\\frac{61}{16} \\neq 0$ and $p_4(\\lambda_2) = \\frac{23}{16} \\neq 0$, neither $\\lambda_1$ nor $\\lambda_2$ is an eigenvalue of $A$. Therefore, the number of eigenvalues in the half-open interval $(\\lambda_1, \\lambda_2]$ is the same as the number of eigenvalues in the open interval $(\\lambda_1, \\lambda_2)$, which is given by $\\nu(\\lambda_2) - \\nu(\\lambda_1)$.\n\nThe number of eigenvalues in $(\\lambda_1, \\lambda_2] = (\\frac{3}{2}, \\frac{5}{2}]$ is:\n$\\nu(\\lambda_2) - \\nu(\\lambda_1) = 2 - 1 = 1$.\n\nSo, there is exactly one eigenvalue of $A$ in the interval $(\\frac{3}{2}, \\frac{5}{2}]$.", "answer": "$$\\boxed{1}$$", "id": "3582435"}, {"introduction": "Effective algorithms often gain their power by exploiting the underlying structure of a problem. This practice explores a crucial structural property of tridiagonal matrices: what happens when an off-diagonal entry is zero. You will see how this decouples the matrix into independent blocks and how the Sturm count additively decomposes, a principle that forms the basis of deflation in modern eigenvalue solvers [@problem_id:3582454].", "problem": "Consider the real symmetric tridiagonal matrix $T \\in \\mathbb{R}^{7 \\times 7}$ with diagonal entries $a_1, \\dots, a_7$ and sub/super-diagonal entries $b_1, \\dots, b_6$, given explicitly by\n$$\nT =\n\\begin{pmatrix}\n4  1  0  0  0  0  0 \\\\\n1  -2  -1  0  0  0  0 \\\\\n0  -1  5  0  0  0  0 \\\\\n0  0  0  2  2  0  0 \\\\\n0  0  0  2  0  -1  0 \\\\\n0  0  0  0  -1  3  1 \\\\\n0  0  0  0  0  1  -1\n\\end{pmatrix},\n$$\nso that the off-diagonal entry $b_3 = 0$ and $T$ is block-diagonal with respect to the $(3,4)$ split. Let the shift be $\\sigma = 1$. Starting from the core definition of the Sturm sequence for a real symmetric tridiagonal matrix applied to $T - \\sigma I$, explain why a zero off-diagonal $b_k = 0$ induces an additive decomposition of the eigenvalue count strictly less than $\\sigma$ into independent counts on the leading and trailing tridiagonal principal blocks. Then, for the specific $T$ and $\\sigma$ above, compute the Sturm count for each block and thereby for $T$. Finally, briefly articulate how this structural decomposition is exploited for deflation in eigenvalue algorithms that use inertia, such as bisection or Multiple Relatively Robust Representations (MRRR).\n\nReport the total number $N$ of eigenvalues of $T$ strictly less than $\\sigma$. Provide only $N$ as your final answer.", "solution": "The user has provided a valid problem from the field of numerical linear algebra. The problem is well-posed, scientifically grounded, and contains all necessary information to arrive at a unique solution.\n\nThe core of the problem is to use the Sturm sequence property to count the number of eigenvalues of a real symmetric tridiagonal matrix $T$ that are strictly less than a given shift $\\sigma$. A special feature of the given matrix $T$ is that it is block-diagonal, which simplifies the eigenvalue problem.\n\n**Part 1: The Additive Decomposition Principle**\n\nLet $T$ be a real symmetric tridiagonal matrix of size $n \\times n$ with diagonal entries $a_1, \\dots, a_n$ and sub/super-diagonal entries $b_1, \\dots, b_{n-1}$. Let $p_k(\\lambda)$ be the characteristic polynomial of the leading $k \\times k$ principal submatrix of $T$. The sequence of polynomials $\\{p_k(\\lambda)\\}_{k=0}^n$ is defined by the three-term recurrence relation:\n$$p_k(\\lambda) = (a_k - \\lambda)p_{k-1}(\\lambda) - b_{k-1}^2 p_{k-2}(\\lambda), \\quad \\text{for } k \\ge 2$$\nwith initial conditions $p_0(\\lambda) = 1$ and $p_1(\\lambda) = a_1 - \\lambda$.\n\nThe number of eigenvalues of $T$ strictly less than a real number $\\sigma$, denoted $N(\\sigma)$, is given by the number of sign changes in the evaluated sequence $\\{p_0(\\sigma), p_1(\\sigma), \\dots, p_n(\\sigma)\\}$. This sequence is known as the Sturm sequence. If a term $p_k(\\sigma)$ is zero, its sign is taken to be the opposite of the sign of the previous term, $p_{k-1}(\\sigma)$.\n\nNow, consider the case where a subdiagonal entry $b_k$ is zero for some $k \\in \\{1, \\dots, n-1\\}$. This means the matrix $T$ is block-diagonal:\n$$T = \\begin{pmatrix} T_1  0 \\\\ 0  T_2 \\end{pmatrix}$$\nwhere $T_1$ is the leading $k \\times k$ principal block and $T_2$ is the trailing $(n-k) \\times (n-k)$ principal block. The eigenvalue spectrum of $T$ is the union of the spectra of $T_1$ and $T_2$. Consequently, the number of eigenvalues of $T$ less than $\\sigma$ must be the sum of the counts for $T_1$ and $T_2$:\n$$N(\\sigma) = N_1(\\sigma) + N_2(\\sigma)$$\nwhere $N_1(\\sigma)$ and $N_2(\\sigma)$ are the number of eigenvalues of $T_1$ and $T_2$ strictly less than $\\sigma$, respectively.\n\nWe can formally demonstrate this within the Sturm sequence framework. The sequence $\\{p_0(\\sigma), \\dots, p_k(\\sigma)\\}$ is precisely the Sturm sequence for the block $T_1$. Let the Sturm sequence for the block $T_2$ (with its own local indexing) be $\\{q_0(\\sigma), \\dots, q_{n-k}(\\sigma)\\}$. A relationship can be established between the full sequence for $T$ and the sequences for its blocks. When $b_k=0$, the recurrence relation for $p_{k+1}(\\lambda)$ becomes:\n$$p_{k+1}(\\lambda) = (a_{k+1} - \\lambda)p_k(\\lambda) - b_k^2 p_{k-1}(\\lambda) = (a_{k+1} - \\lambda)p_k(\\lambda)$$\nRecognizing that $q_1(\\lambda) = (a_{k+1} - \\lambda)$, we have $p_{k+1}(\\lambda) = q_1(\\lambda) p_k(\\lambda)$. By induction, it can be shown that for $j=1, \\dots, n-k$:\n$$p_{k+j}(\\lambda) = q_j(\\lambda) p_k(\\lambda)$$\nThus, the full Sturm sequence for $T$ evaluated at $\\sigma$ is:\n$$\\{ p_0(\\sigma), \\dots, p_k(\\sigma), q_1(\\sigma)p_k(\\sigma), \\dots, q_{n-k}(\\sigma)p_k(\\sigma) \\}$$\nThe total number of sign changes, $N(\\sigma)$, is the sum of sign changes in the first part of the sequence, $\\{p_0(\\sigma), \\dots, p_k(\\sigma)\\}$, and the second part, $\\{p_k(\\sigma), q_1(\\sigma)p_k(\\sigma), \\dots, q_{n-k}(\\sigma)p_k(\\sigma)\\}$. The first count is $N_1(\\sigma)$. For the second part, assuming $p_k(\\sigma) \\neq 0$, the number of sign changes is identical to the number of sign changes in $\\{1, q_1(\\sigma), \\dots, q_{n-k}(\\sigma)\\}$, which, since $q_0(\\sigma)=1$, is exactly $N_2(\\sigma)$. Therefore, $N(\\sigma) = N_1(\\sigma) + N_2(\\sigma)$. This confirms the additive decomposition.\n\n**Part 2: Calculation for the Given Matrix and Shift**\n\nThe given matrix $T$ is a $7 \\times 7$ real symmetric tridiagonal matrix:\n$$\nT =\n\\begin{pmatrix}\n4  1  0  0  0  0  0 \\\\\n1  -2  -1  0  0  0  0 \\\\\n0  -1  5  0  0  0  0 \\\\\n0  0  0  2  2  0  0 \\\\\n0  0  0  2  0  -1  0 \\\\\n0  0  0  0  -1  3  1 \\\\\n0  0  0  0  0  1  -1\n\\end{pmatrix}\n$$\nThe off-diagonal entry $b_3 = T_{3,4} = 0$, so the matrix splits into a $3 \\times 3$ block $T_1$ and a $4 \\times 4$ block $T_2$.\n$$T_1 = \\begin{pmatrix} 4  1  0 \\\\ 1  -2  -1 \\\\ 0  -1  5 \\end{pmatrix}, \\quad T_2 = \\begin{pmatrix} 2  2  0  0 \\\\ 2  0  -1  0 \\\\ 0  -1  3  1 \\\\ 0  0  1  -1 \\end{pmatrix}$$\nWe need to find the number of eigenvalues of $T$ strictly less than the shift $\\sigma = 1$. We compute the Sturm sequence counts for each block separately and add them.\n\n**Block $T_1$:**\nThe diagonal entries are $a_1=4, a_2=-2, a_3=5$. The subdiagonal entries are $b_1=1, b_2=-1$. The shift is $\\sigma=1$.\n- $p_0(1) = 1$\n- $p_1(1) = (a_1 - \\sigma) = 4 - 1 = 3$\n- $p_2(1) = (a_2 - \\sigma)p_1(1) - b_1^2 p_0(1) = (-2 - 1)(3) - (1)^2(1) = -9 - 1 = -10$\n- $p_3(1) = (a_3 - \\sigma)p_2(1) - b_2^2 p_1(1) = (5 - 1)(-10) - (-1)^2(3) = 4(-10) - 3 = -43$\n\nThe sequence of values is $\\{1, 3, -10, -43\\}$.\nThe sequence of signs is $\\{+, +, -, -\\}$.\nThere is one sign change (from $3$ to $-10$). So, $N_1(1) = 1$.\n\n**Block $T_2$:**\nThe diagonal entries are $a_1'=2, a_2'=0, a_3'=3, a_4'=-1$. The subdiagonal entries are $b_1'=2, b_2'=-1, b_3'=1$. The shift is $\\sigma=1$. Let its Sturm sequence polynomials be $q_k$.\n- $q_0(1) = 1$\n- $q_1(1) = (a_1' - \\sigma) = 2 - 1 = 1$\n- $q_2(1) = (a_2' - \\sigma)q_1(1) - (b_1')^2 q_0(1) = (0 - 1)(1) - (2)^2(1) = -1 - 4 = -5$\n- $q_3(1) = (a_3' - \\sigma)q_2(1) - (b_2')^2 q_1(1) = (3 - 1)(-5) - (-1)^2(1) = 2(-5) - 1 = -11$\n- $q_4(1) = (a_4' - \\sigma)q_3(1) - (b_3')^2 q_2(1) = (-1 - 1)(-11) - (1)^2(-5) = (-2)(-11) + 5 = 22 + 5 = 27$\n\nThe sequence of values is $\\{1, 1, -5, -11, 27\\}$.\nThe sequence of signs is $\\{+, +, -, -, +\\}$.\nThere are two sign changes (from $1$ to $-5$, and from $-11$ to $27$). So, $N_2(1) = 2$.\n\n**Total Count:**\nThe total number $N$ of eigenvalues of $T$ strictly less than $\\sigma=1$ is the sum of the counts for the two blocks:\n$$N = N_1(1) + N_2(1) = 1 + 2 = 3$$\n\n**Part 3: Exploitation for Deflation**\n\nThe decomposition of the eigenvalue problem when an off-diagonal element $b_k$ is zero is known as deflation. Eigenvalue algorithms like the QR algorithm, bisection, or Multiple Relatively Robust Representations (MRRR) exploit this property to significantly enhance efficiency. Instead of solving a single large $n \\times n$ problem, the algorithm can solve two smaller, independent problems for the blocks $T_1$ (size $k \\times k$) and $T_2$ (size $(n-k) \\times (n-k)$). Since the complexity of many eigenvalue algorithms scales with the cube of the matrix size, this decomposition leads to a substantial reduction in computational cost, from $\\mathcal{O}(n^3)$ to $\\mathcal{O}(k^3 + (n-k)^3)$.\n\nIn the context of algorithms that use inertia (counts of eigenvalues greater than, less than, or equal to a shift $\\sigma$), such as bisection and MRRR, this structural decomposition is fundamental. The inertia of a block-diagonal matrix is the sum of the inertias of its blocks. Our calculation of $N(\\sigma) = N_1(\\sigma)+N_2(\\sigma)$ is a direct application of this principle. In practice, if an iterative method causes an off-diagonal element to become numerically negligible (i.e., smaller than a certain tolerance), it is set to zero, and the problem is deflated, with the subproblems being solved recursively. This is a critical strategy for the practical performance of modern eigenvalue software.", "answer": "$$\\boxed{3}$$", "id": "3582454"}, {"introduction": "An algorithm that is correct in exact arithmetic may fail in practice due to the limitations of floating-point computation. This exercise confronts the critical issue of numerical stability in the implementation of the Sturm sequence count via the $LDL^\\top$ factorization. By analyzing how rounding errors can corrupt the count and identifying a robust fix, you will gain insight into the sophisticated techniques required to build reliable numerical software [@problem_id:3586281].", "problem": "Let $T \\in \\mathbb{R}^{n \\times n}$ be a real symmetric tridiagonal matrix with diagonal entries $\\{a_i\\}_{i=1}^n$ and positive subdiagonal entries $\\{b_i\\}_{i=1}^{n-1}$, that is, $b_i  0$ for all $i$. For a shift $\\sigma \\in \\mathbb{R}$, consider the Lower Diagonal Lower-transpose ($LDL^\\top$) factorization without pivoting of $T - \\sigma I$, whose diagonal pivots $\\{d_i(\\sigma)\\}$ are defined recursively by\n- $d_1(\\sigma) = a_1 - \\sigma$,\n- $d_i(\\sigma) = a_i - \\sigma - \\dfrac{b_{i-1}^2}{d_{i-1}(\\sigma)}$ for $i = 2, \\dots, n$,\nprovided no zero pivot occurs. In exact arithmetic, the number of negative pivots equals the number of eigenvalues of $T$ that are strictly less than $\\sigma$, and as a function of $\\sigma$ this count is nondecreasing.\n\nIn floating point arithmetic with rounding, the computed sequence $\\{\\widehat{d}_i(\\sigma)\\}$ can be affected by severe cancellation when $|d_{i-1}(\\sigma)|$ is small, which in turn can cause the computed negative-pivot count $\\widehat{v}(\\sigma)$ to violate the monotonicity of the exact count $v(\\sigma)$ as $\\sigma$ varies. Your goal is to reason from first principles about why such monotonicity violations can occur and how to robustly prevent them while preserving the correctness of the bisection method for symmetric tridiagonal eigenvalue computation.\n\nWhich of the following statements most correctly characterizes the effect of floating point rounding on the $LDL^\\top$-based Sturm sequence and proposes a robust, principled guard that restores the monotonicity of the computed negative-pivot count without destroying the correspondence to the inertia of $T - \\sigma I$?\n\nA. Introduce a small positive guard $\\tau$ chosen relative to the matrix scale so that $\\dfrac{b_{i-1}^2}{\\tau}$ does not overflow. Evaluate the recurrence using a sign-preserving floor on the denominator and a negative-zero tie-break:\n- replace $d_{i-1}$ by $\\widetilde{d}_{i-1} := \\operatorname{sign}(d_{i-1}) \\max\\{|d_{i-1}|, \\tau\\}$ before forming $\\dfrac{b_{i-1}^2}{d_{i-1}}$,\n- set $d_i := (a_i - \\sigma) - \\dfrac{b_{i-1}^2}{\\widetilde{d}_{i-1}}$,\n- if the computed $d_i$ underflows or rounds to $0$, force $d_i := -\\tau$.\nWith this modification, the computed count $\\widehat{v}(\\sigma)$ is nondecreasing in $\\sigma$, agrees with $v(\\sigma)$ except possibly when $\\sigma$ lies within $\\mathcal{O}(\\tau)$ of an eigenvalue, and the bisection method remains correct.\n\nB. Apply symmetric pivoting in the $LDL^\\top$ factorization of $T - \\sigma I$ so that no small pivots occur. Counting negative pivots in the pivoted factorization yields an exact eigenvalue count regardless of rounding, so no additional guards are needed and monotonicity is automatic.\n\nC. Modify the recurrence by replacing $b_{i-1}^2$ with $b_{i-1}^2 + \\varepsilon$, where $\\varepsilon$ is the machine rounding unit, to avoid division by tiny denominators. This perturbation leaves the count invariant to rounding and guarantees monotonicity of $\\widehat{v}(\\sigma)$.\n\nD. Switch to the polynomial Sturm sequence $p_0 = 1$, $p_1 = a_1 - \\sigma$, and $p_i = (a_i - \\sigma) p_{i-1} - b_{i-1}^2 p_{i-2}$, and rescale $\\{p_i\\}$ by a common positive factor whenever overflow threatens. Because sign changes are invariant under positive scaling, this alone is sufficient to ensure the computed sign-change count is monotone in $\\sigma$ and equal to $v(\\sigma)$.", "solution": "The user wants me to validate a problem statement regarding numerical stability in eigenvalue computations for symmetric tridiagonal matrices and then evaluate several proposed solutions.\n\n### Step 1: Extract Givens\n-   Matrix: $T \\in \\mathbb{R}^{n \\times n}$, real, symmetric, tridiagonal.\n-   Diagonal entries: $\\{a_i\\}_{i=1}^n$.\n-   Subdiagonal entries: $\\{b_i\\}_{i=1}^{n-1}$, with $b_i  0$ for all $i$.\n-   Shift: $\\sigma \\in \\mathbb{R}$.\n-   Factorization: $LDL^\\top$ factorization of $T - \\sigma I$ without pivoting.\n-   Pivots: A sequence $\\{d_i(\\sigma)\\}$ defined by the recurrence:\n    -   $d_1(\\sigma) = a_1 - \\sigma$\n    -   $d_i(\\sigma) = a_i - \\sigma - \\dfrac{b_{i-1}^2}{d_{i-1}(\\sigma)}$ for $i = 2, \\dots, n$.\n-   Condition: The recurrence is valid provided no zero pivot occurs.\n-   Inertia Property (Exact Arithmetic): The number of negative pivots, denoted $v(\\sigma)$, is equal to the number of eigenvalues of $T$ that are strictly less than $\\sigma$.\n-   Monotonicity Property (Exact Arithmetic): $v(\\sigma)$ is a nondecreasing function of $\\sigma$.\n-   Floating Point Issue: In floating point arithmetic, the computed sequence is $\\{\\widehat{d}_i(\\sigma)\\}$. Severe cancellation can occur when $|d_{i-1}(\\sigma)|$ is small.\n-   Consequence: The computed negative-pivot count, $\\widehat{v}(\\sigma)$, can violate the monotonicity property of $v(\\sigma)$.\n-   Goal: To find a robust, principled method to prevent monotonicity violations while preserving the correctness of the bisection method.\n\n### Step 2: Validate Using Extracted Givens\n1.  **Scientific Groundedness:** The problem statement is firmly grounded in the field of numerical linear algebra. The use of the $LDL^\\top$ factorization of $T - \\sigma I$ to form a Sturm sequence for eigenvalue counting is a classic and fundamental technique, directly related to Sylvester's Law of Inertia. The fact that $b_i  0$ ensures the matrix is unreduced and has distinct eigenvalues, a common assumption. The description of numerical instability due to cancellation when a pivot $d_{i-1}(\\sigma)$ is small is a well-documented, real-world issue in scientific computing (see, e.g., works by W. Kahan, J. Demmel, B. Parlett). The problem is scientifically sound.\n\n2.  **Well-Posedness:** The problem is well-posed. It asks for the identification of a correct characterization of a known numerical pathology and an effective, principled remedy among a set of options. The goal—restoring monotonicity for the bisection method—is clear and meaningful.\n\n3.  **Objectivity:** The problem uses precise, objective terminology from numerical analysis. Statements about floating point behavior, cancellation, and monotonicity are factual and not subject to opinion.\n\n4.  **No other flaws:** The problem is complete, consistent, and does not contain any of the other invalidating flaws listed in the instructions. It represents a standard, non-trivial challenge in implementing robust eigenvalue algorithms.\n\n### Step 3: Verdict and Action\nThe problem statement is **valid**. I will proceed to derive the solution and evaluate the options.\n\n### Derivation and Analysis\n\nThe core of the problem lies in the floating-point computation of the recurrence relation:\n$$\nd_i(\\sigma) = (a_i - \\sigma) - \\frac{b_{i-1}^2}{d_{i-1}(\\sigma)}\n$$\nThis recurrence computes the diagonal elements of the matrix $D$ in the factorization $T - \\sigma I = L D L^\\top$. By Sylvester's Law of Inertia, the number of negative entries in $D$, which is $v(\\sigma) = |\\{i : d_i(\\sigma)  0\\}|$, equals the number of eigenvalues of $T$ less than $\\sigma$.\n\nThe numerical difficulty arises when $d_{i-1}(\\sigma)$ is very close to zero. This occurs when the shift $\\sigma$ is very close to an eigenvalue of the leading principal submatrix $T_{i-1}$. In this situation:\n1.  The term $\\frac{b_{i-1}^2}{d_{i-1}(\\sigma)}$ becomes very large in magnitude.\n2.  The expression for $d_i(\\sigma)$ involves the subtraction of two potentially large numbers, $(a_i - \\sigma)$ and $\\frac{b_{i-1}^2}{d_{i-1}(\\sigma)}$.\n3.  If these two terms are nearly equal, their subtraction in floating-point arithmetic leads to catastrophic cancellation, resulting in a computed value $\\widehat{d}_i(\\sigma)$ that may have very few or no correct significant figures. Most importantly, its sign can be incorrect.\n4.  An incorrect sign for $\\widehat{d}_i(\\sigma)$ leads to an incorrect count $\\widehat{v}(\\sigma)$.\n5.  As $\\sigma$ varies smoothly, the computed sign of $\\widehat{d}_i(\\sigma)$ can flip erratically in the region of cancellation, causing the computed count $\\widehat{v}(\\sigma)$ to decrease for an increasing $\\sigma$, thus violating the crucial monotonicity property required for the bisection method to function correctly.\n\nA robust solution must handle this cancellation gracefully. The key insight, due to Kahan, is that if $|d_{i-1}(\\sigma)|$ is small, the true value of $d_i(\\sigma)$ is dominated by the term $-\\frac{b_{i-1}^2}{d_{i-1}(\\sigma)}$, so its sign is approximately $-\\text{sign}(d_{i-1}(\\sigma))$. A catastrophic cancellation that results in a computed zero, $\\widehat{d}_i(\\sigma) = 0$, signifies that the true value is crossing the origin. To maintain monotonicity, a consistent tie-breaking rule must be applied. The standard robust procedure involves two main components:\n1.  **Guarding the division:** To prevent overflow when calculating the quotient and to bound the perturbation, the denominator $d_{i-1}$ is \"floored\" at a small positive threshold $\\tau$. That is, one uses $\\widetilde{d}_{i-1} = \\text{sign}(d_{i-1}) \\max(|d_{i-1}|, \\tau)$ in the denominator. The value of $\\tau$ is typically chosen as a small, safe number related to the machine precision and matrix norm, e.g., the \"safe minimum\" from LAPACK's `slamch`.\n2.  **Handling cancellation:** If the final subtraction $\\widehat{d}_i := \\text{fl}((a_i - \\sigma) - \\frac{b_{i-1}^2}{\\widetilde{d}_{i-1}})$ results in $0$ (either by exact cancellation in floating point or by underflow), it is a sign that the true value is near zero. To ensure monotonicity, the result is forced to a specific signed value. The established convention is to set it to a small *negative* number, e.g., $-\\tau$. This \"negative zero\" convention ensures that the count $\\widehat{v}(\\sigma)$ is non-decreasing.\n\nThis perturbed computation corresponds to finding the inertia of a slightly different matrix, $T - \\sigma I - E$, where $E$ is a small diagonal perturbation. The bisection method will still converge to small intervals containing the eigenvalues, and the monotonicity of the count is guaranteed.\n\n### Evaluation of Options\n\n**A. Introduce a small positive guard $\\tau$ chosen relative to the matrix scale so that $\\dfrac{b_{i-1}^2}{\\tau}$ does not overflow. Evaluate the recurrence using a sign-preserving floor on the denominator and a negative-zero tie-break: ...**\nThis option describes the robust procedure detailed above.\n1.  Replacing $d_{i-1}$ with $\\widetilde{d}_{i-1} := \\operatorname{sign}(d_{i-1}) \\max\\{|d_{i-1}|, \\tau\\}$ is precisely the safeguarding of the division.\n2.  Forcing a result of $0$ to be $-\\tau$ is the \"negative-zero\" tie-breaking rule that handles catastrophic cancellation and ensures monotonicity.\n3.  The claims that the computed count $\\widehat{v}(\\sigma)$ becomes nondecreasing and that the bisection method remains correct are the direct and desired consequences of this procedure. The statement that the count may differ from the true count $v(\\sigma)$ only when $\\sigma$ is very close to an eigenvalue (within a region of size related to $\\tau$) is also accurate.\nThis option provides a correct and complete description of the state-of-the-art solution.\n**Verdict: Correct.**\n\n**B. Apply symmetric pivoting in the $LDL^\\top$ factorization of $T - \\sigma I$ so that no small pivots occur. Counting negative pivots in the pivoted factorization yields an exact eigenvalue count regardless of rounding, so no additional guards are needed and monotonicity is automatic.**\nSymmetric pivoting, $P(T - \\sigma I)P^\\top = L D L^\\top$, does preserve the inertia of the matrix. However, the permutation matrix $P$ will destroy the tridiagonal structure of $T - \\sigma I$, introducing fill-in. This means the computationally cheap $O(n)$ recurrence for the pivots is no longer applicable. The factorization would become an expensive $O(n^3)$ operation (or $O(n^2)$ at best), which defeats the entire purpose of using the tridiagonal form for rapid eigenvalue counting. The problem is about fixing the given recurrence, not replacing it with a computationally infeasible alternative.\n**Verdict: Incorrect.**\n\n**C. Modify the recurrence by replacing $b_{i-1}^2$ with $b_{i-1}^2 + \\varepsilon$, where $\\varepsilon$ is the machine rounding unit, to avoid division by tiny denominators. This perturbation leaves the count invariant to rounding and guarantees monotonicity of $\\widehat{v}(\\sigma)$.**\nThis modification is misguided. The primary numerical issue is not the value of the numerator $b_{i-1}^2$, but the combination of a tiny denominator $d_{i-1}(\\sigma)$ and the subsequent catastrophic cancellation in the subtraction. Adding machine epsilon to the numerator has a negligible effect when $d_{i-1}(\\sigma)$ is tiny and does absolutely nothing to prevent the subtraction of two nearly equal large numbers. It does not address the root cause of the instability.\n**Verdict: Incorrect.**\n\n**D. Switch to the polynomial Sturm sequence $p_0 = 1$, $p_1 = a_1 - \\sigma$, and $p_i = (a_i - \\sigma) p_{i-1} - b_{i-1}^2 p_{i-2}$, and rescale $\\{p_i\\}$ by a common positive factor whenever overflow threatens. Because sign changes are invariant under positive scaling, this alone is sufficient to ensure the computed sign-change count is monotone in $\\sigma$ and equal to $v(\\sigma)$.**\nThis option proposes using the three-term recurrence for the characteristic polynomials $p_i(\\sigma) = \\det(T_i - \\sigma I)$. The pivot recurrence and this polynomial recurrence are mathematically related by $d_i(\\sigma) = p_i(\\sigma) / p_{i-1}(\\sigma)$. Therefore, they suffer from the same fundamental numerical instability: when $p_{i-1}(\\sigma) \\approx 0$, the computation of $p_i(\\sigma)$ is prone to error. While scaling is necessary to prevent overflow/underflow, which is a major problem with the polynomial recurrence, it does not solve the problem of cancellation. The claim that scaling `alone is sufficient` to ensure monotonicity is false. The same sign-flipping behavior due to rounding errors will occur near roots of $p_{i-1}(\\sigma)$, and the same non-monotonicity of the sign-change count will result. A robust implementation of this method would require the same kind of careful guards as described in option A.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{A}$$", "id": "3586281"}]}