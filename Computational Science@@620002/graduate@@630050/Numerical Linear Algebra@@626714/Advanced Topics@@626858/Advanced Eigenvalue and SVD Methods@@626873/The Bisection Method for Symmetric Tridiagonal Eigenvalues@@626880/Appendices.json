{"hands_on_practices": [{"introduction": "The most effective way to internalize a numerical algorithm is to implement it from first principles. This practice guides you through building a complete eigenvalue solver for symmetric tridiagonal matrices based on the bisection method. You will implement the Sturm sequence count using a stable $LDL^T$ factorization and use Gershgorin's theorem to establish initial search bounds, providing a hands-on opportunity to connect these theoretical pillars to a working code [@problem_id:3586250]. By validating your implementation against a matrix with a known analytical spectrum—the discretized 1D Laplacian—you will also engage in the essential practice of numerical verification.", "problem": "You are asked to implement from first principles the bisection method for computing all eigenvalues of a real symmetric tridiagonal matrix using Sturm theory, and to validate both numerical accuracy and scaling behavior on a family of matrices with known spectra. The family is the centered second-difference discretization of the one-dimensional negative second derivative with Dirichlet boundary conditions on the unit interval. For a chosen integer size $n \\ge 1$, with interior grid spacing $h = 1/(n+1)$, the unscaled matrix is the $n \\times n$ tridiagonal matrix with diagonal entries $2/h^2$ and subdiagonal/superdiagonal entries $-1/h^2$. For any positive scalar $c  0$, consider the scaled matrix $A_n(c) = c \\cdot A_n(1)$. The exact eigenvalues of $A_n(c)$ are known in closed form and can be used as ground truth for validation.\n\nFundamental base you may rely on includes only the following well-tested facts and core definitions:\n- Real symmetric matrices have real eigenvalues and admit orthogonal diagonalization.\n- The eigenvalues of a real symmetric tridiagonal matrix can be counted below a real scalar shift via Sturm theory, equivalently via the number of negative pivots in the $L D L^\\top$ factorization of the shifted matrix.\n- The Gershgorin circle theorem provides bounds that contain the spectrum.\n- For the centered second-difference operator with Dirichlet boundary conditions on $[0,1]$, the discrete sine transform diagonalizes the matrix family $A_n(c)$, and the exact eigenvalues form a strictly increasing sequence.\n- Scaling a matrix by a positive scalar $c$ scales its eigenvalues by the same scalar $c$.\n\nYour tasks are:\n- Implement a function that, given diagonal entries $d_i$ and off-diagonal entries $e_i$ of a real symmetric tridiagonal matrix of size $n$, together with a real scalar $x$, returns the count of eigenvalues strictly less than $x$ using a numerically stable realization of Sturm theory grounded in $L D L^\\top$ factorization without pivoting.\n- Implement a global eigenvalue bisection routine that, given such $(d,e)$ and tolerances, returns all $n$ eigenvalues in nondecreasing order. Use Gershgorin bounds to obtain a provably enclosing interval and perform interval subdivision guided by Sturm counts so that each eigenvalue is isolated to within the specified tolerance.\n- Construct the family $A_n(c)$ with $n$ interior points and scaling $c$, and compute the exact eigenvalues from the closed-form expression implied by the discrete sine transform. Use these exact values to quantify accuracy.\n- Design and execute the following test suite, reporting one scalar per test:\n  1. Accuracy on a moderate-sized unscaled case: $n=8$, $c=1$.\n  2. Boundary case: $n=1$, $c=1$.\n  3. Small case: $n=2$, $c=1$.\n  4. Scaling validation on a medium case: $n=32$, $c=3.7$.\n  5. Larger case for performance and clustering behavior: $n=200$, $c=1$.\n\nFor each test, compute the maximum relative error between the numerically computed eigenvalues $\\{\\hat{\\lambda}_k\\}_{k=1}^n$ and the exact eigenvalues $\\{\\lambda_k\\}_{k=1}^n$:\n$$\n\\varepsilon_{\\max} = \\max_{1 \\le k \\le n} \\frac{|\\hat{\\lambda}_k - \\lambda_k|}{|\\lambda_k|}.\n$$\nReport each $\\varepsilon_{\\max}$ as a floating-point number.\n\nImplementation requirements:\n- Your program must compute all eigenvalues solely via the bisection method driven by Sturm counts on the symmetric tridiagonal, without calling any black-box dense eigenvalue routines.\n- Use Gershgorin discs to construct the initial global search interval.\n- Terminate bisection for an interval containing exactly one eigenvalue when the interval width is at most $\\max\\{ \\text{atol}, \\text{rtol} \\cdot \\max(|a|,|b|,1) \\}$, where $[a,b]$ is the current interval, with absolute tolerance $\\text{atol}$ and relative tolerance $\\text{rtol}$ chosen to be stringent but feasible in double precision arithmetic.\n\nExact spectrum for validation:\n- For $A_n(c)$ with grid spacing $h = 1/(n+1)$, the exact eigenvalues are given by\n$$\n\\lambda_k = c \\cdot \\frac{4}{h^2} \\sin^2\\!\\left( \\frac{k \\pi}{2 (n+1)} \\right), \\quad k=1,2,\\dots,n.\n$$\n\nFinal output specification:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (for example, \"[$r_1$,$r_2$,$r_3$,$r_4$,$r_5$]\"), where $r_i$ is the maximum relative error $\\varepsilon_{\\max}$ for test $i$.\n\nThe test suite parameters are exactly the five pairs $(n,c)$ listed above:\n- Test $1$: $(n,c) = (8,1)$.\n- Test $2$: $(n,c) = (1,1)$.\n- Test $3$: $(n,c) = (2,1)$.\n- Test $4$: $(n,c) = (32,3.7)$.\n- Test $5$: $(n,c) = (200,1)$.\n\nNo physical units are involved. Angles in the exact spectrum formula use radians. The final answers must be floating-point numbers. The program must require no input and must not print any additional text besides the single specified output line.", "solution": "The user-provided problem is valid and requires the implementation of the bisection method to find all eigenvalues of a real symmetric tridiagonal matrix. The solution will be validated against a known analytical test case. The implementation will follow the specified first-principles approach, incorporating Sturm theory for eigenvalue counting and Gershgorin circles for initial spectral bounds.\n\n### 1. Theoretical Foundation\n\nA real symmetric tridiagonal matrix $T$ of size $n$ has $n$ real eigenvalues. The bisection method for finding these eigenvalues relies on a function, `count(x)`, that determines the number of eigenvalues of $T$ that are less than or equal to a given scalar $x$.\n\n#### 1.1. Sturm Sequence and Eigenvalue Counting\n\nSturm theory provides the foundation for the `count(x)` function. For a symmetric matrix $T$, the number of eigenvalues strictly less than $x$ is given by the number of sign changes in the sequence of determinants of the leading principal submatrices of $T - xI$, denoted $\\{p_k(x) = \\det((T-xI)_{1:k, 1:k})\\}_{k=1}^n$. This can be computed stably without risk of overflow or underflow by analyzing the $LDL^\\top$ factorization of $T - xI$, where $L$ is a unit lower bidiagonal matrix and $D$ is a diagonal matrix of pivots.\n\nBy Sylvester's Law of inertia, the number of negative pivots in $D$ is equal to the number of negative eigenvalues of $T - xI$, which is precisely the number of eigenvalues of $T$ that are strictly less than $x$. The pivots, let's call them $\\delta_i$, can be computed via the recurrence:\n$$\n\\delta_1 = d_1 - x \\\\\n\\delta_i = (d_i - x) - \\frac{e_{i-1}^2}{\\delta_{i-1}}, \\quad i=2, \\dots, n\n$$\nwhere $d_i$ are the diagonal entries and $e_{i-1}$ are the off-diagonal entries of $T$. A division by zero occurs if a pivot $\\delta_{i-1}$ is zero, which happens if and only if $x$ is an eigenvalue of the leading principal submatrix $T_{i-1}$. In floating-point arithmetic, this is rare. A robust implementation handles this by perturbing a zero pivot to a small value $\\varepsilon$. Choosing $\\varepsilon > 0$ corresponds to counting eigenvalues strictly less than $x$, i.e., count(x). This is sufficient for the bisection algorithm, as the set of eigenvalues has measure zero.\n\n#### 1.2. Gershgorin Circle Theorem\n\nTo begin the bisection process, we need an interval $[a, b]$ that is guaranteed to contain the entire spectrum of $T$. The Gershgorin circle theorem states that all eigenvalues lie in the union of disks $D_i$ in the complex plane, where $D_i = \\{ z : |z - d_i| \\le R_i \\}$, and the radii $R_i$ are the sum of the absolute values of the off-diagonal entries in the $i$-th row. For a real symmetric tridiagonal matrix, the eigenvalues are real, so we only need the real interval covering these disks:\n$$\n\\lambda \\in \\left[ \\min_{i} (d_i - R_i), \\max_{i} (d_i + R_i) \\right]\n$$\nwhere $R_1 = |e_1|$, $R_n = |e_{n-1}|$, and $R_i = |e_{i-1}| + |e_i|$ for $1  i  n$.\n\n#### 1.3. Bisection Algorithm\n\nThe overall algorithm proceeds as follows:\n1.  Determine an initial search interval $[a, b]$ using the Gershgorin circle theorem.\n2.  Initialize a queue of intervals to process, starting with $([a, b], \\text{count}(a), \\text{count}(b))$. Each tuple represents an interval and the number of eigenvalues found to its left by the Sturm count.\n3.  Repeatedly process intervals from the queue:\n    a. If an interval $[l, h)$ contains $k = \\text{count}(h) - \\text{count}(l) = 1$ eigenvalue, refine this interval using standard bisection until its width is less than a specified tolerance $\\tau = \\max(\\text{atol}, \\text{rtol} \\cdot \\max(|l|, |h|, 1))$. The midpoint of the final interval is an approximation of the eigenvalue.\n    b. If an interval contains $k  1$ eigenvalues, split it at its midpoint $m = l + (h-l)/2$. This creates two new sub-intervals, $[l, m)$ and $[m, h)$, which are added to the queue for further processing.\n    c. If an interval contains $k=0$ eigenvalues, it is discarded.\n4.  The process terminates when all $n$ eigenvalues have been isolated and refined to the desired precision. The found eigenvalues are then sorted.\n\n### 2. Implementation for the Test Matrix Family\n\nThe problem specifies a test family of matrices $A_n(c)$, which are scaled discretizations of the 1D negative Laplacian.\n\n- **Matrix Construction**: For given $n$ and $c$, we compute $h = 1/(n+1)$ and construct the diagonal vector $d$ and off-diagonal vector $e$ with entries $d_i = 2c/h^2$ and $e_i = -c/h^2$.\n\n- **Exact Spectrum**: The exact eigenvalues $\\lambda_k$ serve as the ground truth for validation. They are given by:\n$$\n\\lambda_k = c \\cdot \\frac{4}{h^2} \\sin^2\\!\\left( \\frac{k \\pi}{2 (n+1)} \\right), \\quad k=1,2,\\dots,n\n$$\n\n- **Error Calculation**: The numerical accuracy is measured by the maximum relative error over all eigenvalues:\n$$\n\\varepsilon_{\\max} = \\max_{1 \\le k \\le n} \\frac{|\\hat{\\lambda}_k - \\lambda_k|}{|\\lambda_k|}\n$$\nwhere $\\{\\hat{\\lambda}_k\\}$ are the computed eigenvalues. Since $\\lambda_k  0$ for all $k$ in this family, the division is always well-defined.\n\nThe final Python code implements these components to solve for the eigenvalues of the specified test cases and report the maximum relative error for each.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Global tolerances for bisection, chosen to be stringent for double precision.\nATOL = 1e-14\nRTOL = 1e-14\n\ndef sturm_count(d, e, x):\n    \"\"\"\n    Counts the number of eigenvalues of a symmetric tridiagonal matrix T\n    that are strictly less than a given scalar x.\n    Uses the LDL^T factorization of T - xI and Sylvester's Law of Inertia.\n    The number of eigenvalues  x is the number of negative pivots (diagonal entries of D).\n\n    Args:\n        d (np.ndarray): Diagonal entries of T (length n).\n        e (np.ndarray): Off-diagonal entries of T (length n-1).\n        x (float): The scalar shift.\n\n    Returns:\n        int: The number of eigenvalues of T strictly less than x.\n    \"\"\"\n    n = len(d)\n    if n == 0:\n        return 0\n\n    count = 0\n    # A small positive value to perturb zero pivots, relative to the matrix norm.\n    # This ensures numerical stability and prevents division by zero.\n    # A positive perturbation corresponds to counting eigenvalues strictly less than x.\n    if n == 1:\n        norm_est = np.abs(d[0])\n    else:\n        norm_est = np.max(np.abs(d)) + 2 * np.max(np.abs(e))\n    \n    eps = np.finfo(float).eps * (norm_est if norm_est  0 else 1.0)\n    \n    delta = d[0] - x\n    if delta  0:\n        count += 1\n    if delta == 0:\n        delta = eps\n    \n    for i in range(1, n):\n        delta = (d[i] - x) - (e[i-1]**2) / delta\n        if delta  0:\n            count += 1\n        if delta == 0:\n            delta = eps\n            \n    return count\n\ndef find_all_eigenvalues(d, e):\n    \"\"\"\n    Computes all eigenvalues of a real symmetric tridiagonal matrix\n    using the bisection method driven by Sturm sequence counts.\n\n    Args:\n        d (np.ndarray): Diagonal entries of T (length n).\n        e (np.ndarray): Off-diagonal entries of T (length n-1).\n\n    Returns:\n        np.ndarray: A sorted array of the computed eigenvalues.\n    \"\"\"\n    n = len(d)\n    if n == 0:\n        return np.array([])\n    if n == 1:\n        return np.array([d[0]])\n\n    # Step 1: Find an interval [low, high] containing all eigenvalues using Gershgorin circles.\n    radii = np.zeros(n)\n    radii[0] = np.abs(e[0])\n    radii[-1] = np.abs(e[-1])\n    for i in range(1, n - 1):\n        radii[i] = np.abs(e[i - 1]) + np.abs(e[i])\n    \n    low = np.min(d - radii)\n    high = np.max(d + radii)\n\n    # Slightly expand the interval to ensure endpoints are not eigenvalues and counts are stable.\n    span = high - low\n    if span == 0:\n        span = abs(low) if low != 0 else 1.0\n    low -= span * 1e-10 + 1e-10\n    high += span * 1e-10 + 1e-10\n\n    # Step 2: Use bisection to isolate eigenvalues.\n    # Each item is (l, h, n_l, n_h), where [l, h) contains n_h - n_l eigenvalues.\n    n_low = sturm_count(d, e, low)\n    n_high = sturm_count(d, e, high)\n    intervals = [(low, high, n_low, n_high)]\n    \n    found_eigs = []\n\n    while intervals:\n        l, h, nl, nh = intervals.pop(0)\n        \n        num_eigs_in_interval = nh - nl\n        if num_eigs_in_interval == 0:\n            continue\n        \n        # Termination tolerance for isolating a single eigenvalue.\n        tol = max(ATOL, RTOL * max(abs(l), abs(h), 1.0))\n        \n        if num_eigs_in_interval == 1:\n            # Refine the interval for the single eigenvalue.\n            while (h - l)  tol:\n                m = l + (h - l) / 2\n                nm = sturm_count(d, e, m)\n                if nm == nl:  # Eigenvalue is in [m, h)\n                    l = m\n                else:  # Eigenvalue is in [l, m)\n                    h = m\n            found_eigs.append(l + (h - l) / 2)\n        else:\n            # If interval is too small to split but contains multiple eigenvalues,\n            # it indicates a cluster. We cannot resolve them further.\n            if (h - l) = tol:\n                mid = l + (h - l) / 2\n                for _ in range(num_eigs_in_interval):\n                    found_eigs.append(mid)\n                continue\n\n            # Split the interval and add new sub-intervals to the queue.\n            mid = l + (h - l) / 2\n            n_mid = sturm_count(d, e, mid)\n            \n            # Left sub-interval [l, mid)\n            if n_mid  nl:\n                intervals.append((l, mid, nl, n_mid))\n            \n            # Right sub-interval [mid, h)\n            if nh  n_mid:\n                intervals.append((mid, h, n_mid, nh))\n\n    found_eigs.sort()\n    return np.array(found_eigs)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (8, 1.0),\n        (1, 1.0),\n        (2, 1.0),\n        (32, 3.7),\n        (200, 1.0),\n    ]\n\n    results = []\n    for n, c in test_cases:\n        # Construct the matrix T = A_n(c) and its exact eigenvalues.\n        h = 1.0 / (n + 1)\n        d_val = c * 2.0 / h**2\n        e_val = c * -1.0 / h**2\n        \n        d = np.full(n, d_val)\n        e = np.full(n - 1, e_val) if n  1 else np.array([])\n        \n        k = np.arange(1, n + 1)\n        exact_eigs = c * (4.0 / h**2) * np.sin(k * np.pi / (2.0 * (n + 1)))**2\n        \n        # Compute eigenvalues using the implemented bisection method.\n        computed_eigs = find_all_eigenvalues(d, e)\n        \n        if len(computed_eigs) != n:\n             raise RuntimeError(f\"Error: Found {len(computed_eigs)} eigenvalues, expected {n} for case (n={n}, c={c}).\")\n\n        # Quantify the maximum relative error.\n        if n  0:\n            relative_errors = np.abs(computed_eigs - exact_eigs) / np.abs(exact_eigs)\n            max_rel_error = np.max(relative_errors)\n        else:\n            max_rel_error = 0.0\n\n        results.append(max_rel_error)\n\n    # Final print statement must be in the exact specified format.\n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```", "id": "3586250"}, {"introduction": "While the bisection method is guaranteed to converge, its efficiency is not uniform and depends heavily on the structure of the spectrum. This exercise explores a worst-case scenario where eigenvalues are geometrically clustered, a situation that can demand significant computational effort to resolve [@problem_id:3586212]. By analyzing a specially constructed diagonal matrix, you will quantify the number of bisection steps required to separate these clusters and achieve a target precision, developing a deeper intuition for how eigenvalue distribution impacts algorithmic performance.", "problem": "Consider the problem of locating eigenvalues of a real symmetric tridiagonal matrix using the bisection method guided by the Sturm sequence count, which gives the number of eigenvalues strictly less than a real shift. The bisection method refines an initial spectral interval into subintervals by repeatedly halving, using the monotonicity of the count to assign how many eigenvalues lie in each subinterval. In the worst case when eigenvalues are highly clustered, the number of halving operations can be dominated by how finely one must place subinterval boundaries to resolve the gaps between clusters and, additionally, by the tolerance requirement for the final interval widths.\n\nYour task is to construct worst-case input matrices whose eigenvalues are geometrically clustered and, for each, determine two integers measuring bisection refinement complexity:\n\n- The first integer is the minimal number of uniform bisection levels required so that the endpoints of the resulting dyadic partition align with all inter-cluster gaps, meaning every gap between consecutive clusters contains at least one subinterval boundary.\n- The second integer is the minimal number of uniform bisection levels required so that the width of the smallest subinterval is at most a specified absolute tolerance $\\,\\varepsilon\\,$.\n\nThe matrices shall be constructed as follows. Let $\\,n\\,$ be a positive integer and let there be $\\,q\\,$ clusters with centers $\\,c_1,\\dots,c_q\\,$ and cluster sizes $\\,m_1,\\dots,m_q\\,$ summing to $\\,n\\,$. For fixed base offset $\\,\\delta0\\,$ and ratio $\\,r\\in(0,1)\\,$, define, for each cluster $\\,j\\,$, the eigenvalues\n$$\n\\lambda_{j,k} \\;=\\; c_j \\;+\\; \\delta\\, r^{\\,k}, \\qquad k=0,1,\\dots,m_j-1,\n$$\nand form the $\\,n\\times n\\,$ symmetric tridiagonal matrix $\\,T\\,$ by placing these $\\,n\\,$ values on the diagonal and setting all off-diagonal entries to zero. This construction produces a symmetric tridiagonal matrix with geometrically clustered eigenvalues, and it realizes a worst-case scenario for bisection in the sense that cluster separation is governed entirely by placement of dyadic subinterval boundaries, independent of any smoothing effect of nonzero off-diagonals.\n\nFor each test case below, you must:\n\n1. Construct $\\,T\\,$ according to the geometric clustering rule described.\n2. Determine a safe global spectral interval $[a,b]$ that contains all eigenvalues of $\\,T\\,$ by using a Gershgorin-type bound based on the tridiagonal structure.\n3. Identify the inter-cluster gaps as the open intervals between the maximum of one cluster and the minimum of the next cluster in the sorted order of cluster centers.\n4. Compute:\n   - The minimal number of uniform bisection levels, denoted $\\,s_{\\mathrm{clusters}}\\,$, such that the dyadic partition of $[a,b]$ into $2^{\\,s_{\\mathrm{clusters}}}$ equal subintervals has at least one boundary point lying strictly inside each inter-cluster gap.\n   - The minimal number of uniform bisection levels, denoted $\\,s_{\\varepsilon}\\,$, such that the width of each dyadic subinterval is at most the given absolute tolerance $\\,\\varepsilon\\,$.\n\nYou must implement the logic from first principles: the Sturm sequence count for symmetric tridiagonal matrices defines the eigenvalue counting function, and the bisection method’s uniform refinement creates dyadic partitions whose boundary spacing decreases geometrically with the number of levels. The quantities $\\,s_{\\mathrm{clusters}}\\,$ and $\\,s_{\\varepsilon}\\,$ convert these principles into integers that quantify the worst-case refinement needed to resolve cluster gaps and to meet the prescribed absolute tolerance.\n\nTest Suite:\n- Test Case $\\,1\\,$:\n  - $\\,n=12\\,$, $\\,q=2\\,$, centers $\\,c_1=0\\,$ and $\\,c_2=1\\,$, sizes $\\,m_1=7\\,$ and $\\,m_2=5\\,$.\n  - Base offset $\\,\\delta = 10^{-3}\\,$, ratio $\\,r = \\tfrac{1}{3}\\,$.\n  - Absolute tolerance $\\,\\varepsilon = 10^{-6}\\,$.\n- Test Case $\\,2\\,$:\n  - $\\,n=10\\,$, $\\,q=2\\,$, centers $\\,c_1=0\\,$ and $\\,c_2=3\\,$, sizes $\\,m_1=9\\,$ and $\\,m_2=1\\,$.\n  - Base offset $\\,\\delta = 10^{-8}\\,$, ratio $\\,r = 0.9\\,$.\n  - Absolute tolerance $\\,\\varepsilon = 10^{-12}\\,$.\n- Test Case $\\,3\\,$:\n  - $\\,n=8\\,$, $\\,q=3\\,$, centers $\\,c_1=-2\\,$, $\\,c_2=0\\,$, $\\,c_3=2\\,$, sizes $\\,m_1=3\\,$, $\\,m_2=3\\,$, $\\,m_3=2\\,$.\n  - Base offset $\\,\\delta = 10^{-5}\\,$, ratio $\\,r = \\tfrac{1}{2}\\,$.\n  - Absolute tolerance $\\,\\varepsilon = 10^{-8}\\,$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the six results from the test suite, ordered as $[s_{\\mathrm{clusters}}^{(1)}, s_{\\varepsilon}^{(1)}, s_{\\mathrm{clusters}}^{(2)}, s_{\\varepsilon}^{(2)}, s_{\\mathrm{clusters}}^{(3)}, s_{\\varepsilon}^{(3)}]$, printed as a comma-separated list enclosed in square brackets (for example, $[1,2,3,4,5,6]$). Each entry must be an integer.", "solution": "The problem requires the calculation of two integers, $s_{\\mathrm{clusters}}$ and $s_{\\varepsilon}$, which quantify the number of uniform bisection levels needed to resolve eigenvalue clusters and meet a specified tolerance for a special class of diagonal matrices. The solution proceeds by first formalizing the quantities to be computed and then applying these formulas to the specific test cases.\n\nThe matrix $T$ is an $n \\times n$ symmetric tridiagonal matrix, but is constructed to be diagonal. Its diagonal entries are the specified eigenvalues, and its off-diagonal entries are zero. The eigenvalues are grouped into $q$ clusters. For each cluster $j \\in \\{1, \\dots, q\\}$, with center $c_j$ and size $m_j$, the eigenvalues are given by the formula:\n$$\n\\lambda_{j,k} = c_j + \\delta r^k, \\qquad k=0, 1, \\dots, m_j-1\n$$\nwhere $\\delta  0$ is a base offset and $r \\in (0,1)$ is a ratio. The total number of eigenvalues is $n = \\sum_{j=1}^q m_j$.\n\nThe first step is to determine a safe global spectral interval $[a, b]$ containing all eigenvalues. The problem suggests a Gershgorin-type bound. For a general symmetric tridiagonal matrix with diagonal entries $d_i$ and off-diagonal entries $e_i$, the eigenvalues lie in the union of the intervals $[d_i - |e_{i-1}| - |e_i|, d_i + |e_{i-1}| + |e_i|]$ (with $e_0=e_n=0$). In our specific case, the matrix $T$ is diagonal, so all off-diagonal entries are zero. The Gershgorin disks are simply the points corresponding to the diagonal entries, which are the eigenvalues themselves. Therefore, the smallest rigorous interval $[a, b]$ containing all eigenvalues is $[ \\min(\\lambda), \\max(\\lambda) ]$.\n\nSince $\\delta  0$ and $r \\in (0,1)$, the term $\\delta r^k$ is positive and strictly decreasing with $k$.\nThe maximum eigenvalue in cluster $j$ is $\\lambda_{j,0} = c_j + \\delta r^0 = c_j + \\delta$.\nThe minimum eigenvalue in cluster $j$ is $\\lambda_{j,m_j-1} = c_j + \\delta r^{m_j-1}$.\nThe global maximum eigenvalue is the maximum of the cluster maxima: $b = \\max_{j} (\\lambda_{j,0}) = \\max_{j} (c_j + \\delta) = (\\max_{j} c_j) + \\delta$.\nThe global minimum eigenvalue is the minimum of the cluster minima: $a = \\min_{j} (\\lambda_{j,m_j-1}) = \\min_{j} (c_j + \\delta r^{m_j-1})$.\nThe total width of the spectral interval is $W = b-a$.\n\nThe second step is to identify the inter-cluster gaps. Let the cluster centers be sorted as $c_{(1)}  c_{(2)}  \\dots  c_{(q)}$, with corresponding sizes $m_{(1)}, m_{(2)}, \\dots, m_{(q)}$. There are $q-1$ inter-cluster gaps. The $i$-th gap, for $i \\in \\{1, \\dots, q-1\\}$, is the open interval between the largest eigenvalue of cluster $(i)$ and the smallest eigenvalue of cluster $(i+1)$.\nThe left boundary of the $i$-th gap is $g_{i,L} = \\max_{\\text{eigs in cluster }(i)} \\lambda = c_{(i)} + \\delta$.\nThe right boundary of the $i$-th gap is $g_{i,R} = \\min_{\\text{eigs in cluster }(i+1)} \\lambda = c_{(i+1)} + \\delta r^{m_{(i+1)}-1}$.\nThe width of the $i$-th gap is $w_i = g_{i,R} - g_{i,L}$. The narrowest of these gaps determines the resolution requirement: $w_{\\mathrm{gap\\_min}} = \\min_{i} w_i$.\n\nThe third step is to compute $s_{\\mathrm{clusters}}$. A uniform bisection of $[a,b]$ for $s$ levels creates $2^s$ subintervals of equal width $W_s = (b-a)/2^s$. For the dyadic partition boundaries to resolve every inter-cluster gap, at least one boundary point must lie strictly inside each gap. A sufficient condition to guarantee this is that the subinterval width $W_s$ must be strictly smaller than the width of the narrowest gap, $w_{\\mathrm{gap\\_min}}$.\n$$\nW_s  w_{\\mathrm{gap\\_min}} \\implies \\frac{b-a}{2^s}  w_{\\mathrm{gap\\_min}}\n$$\nRearranging this inequality gives:\n$$\n2^s  \\frac{b-a}{w_{\\mathrm{gap\\_min}}} \\implies s  \\log_2\\left(\\frac{b-a}{w_{\\mathrm{gap\\_min}}}\\right)\n$$\nSince $s$ must be an integer, the minimal value for $s$ is given by $s_{\\mathrm{clusters}} = \\left\\lfloor \\log_2\\left(\\frac{b-a}{w_{\\mathrm{gap\\_min}}}\\right) \\right\\rfloor + 1$. This formula holds even if the argument of the logarithm is a power of $2$, as the inequality is strict.\n\nThe fourth step is to compute $s_{\\varepsilon}$. This requires the width of each subinterval to be no more than the absolute tolerance $\\varepsilon$.\n$$\nW_s \\le \\varepsilon \\implies \\frac{b-a}{2^s} \\le \\varepsilon\n$$\nRearranging this inequality gives:\n$$\n2^s \\ge \\frac{b-a}{\\varepsilon} \\implies s \\ge \\log_2\\left(\\frac{b-a}{\\varepsilon}\\right)\n$$\nSince $s$ must be an integer, the minimal value for $s$ is given by $s_{\\varepsilon} = \\left\\lceil \\log_2\\left(\\frac{b-a}{\\varepsilon}\\right) \\right\\rceil$.\n\nThese derived formulas are implemented for each test case to find the required integer values.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_refinement_levels(n, q, centers, sizes, delta, r, epsilon):\n    \"\"\"\n    Calculates the minimal bisection levels s_clusters and s_epsilon.\n\n    Args:\n        n (int): Total number of eigenvalues.\n        q (int): Number of clusters.\n        centers (list): List of cluster centers c_j.\n        sizes (list): List of cluster sizes m_j.\n        delta (float): Base offset.\n        r (float): Ratio.\n        epsilon (float): Absolute tolerance.\n\n    Returns:\n        tuple: A tuple containing (s_clusters, s_epsilon).\n    \"\"\"\n\n    # Combine centers and sizes for sorting\n    clusters = sorted(zip(centers, sizes))\n    sorted_centers = [c for c, s in clusters]\n    sorted_sizes = [s for c, s in clusters]\n\n    # Step 1: Determine the global spectral interval [a, b]\n    # b = max(c_j) + delta\n    b = sorted_centers[-1] + delta\n    \n    # a = min(c_j + delta * r^(m_j-1))\n    min_eigs_per_cluster = [\n        c + delta * (r**(s - 1)) for c, s in clusters\n    ]\n    a = min(min_eigs_per_cluster)\n\n    # Total width of the spectral interval\n    interval_width = b - a\n\n    # Step 2: Identify inter-cluster gaps and find the minimum width\n    if q  1:\n        gap_widths = []\n        for i in range(q - 1):\n            # Left boundary of gap i: max eigenvalue of cluster i\n            gap_left = sorted_centers[i] + delta\n            # Right boundary of gap i: min eigenvalue of cluster i+1\n            gap_right = sorted_centers[i+1] + delta * (r**(sorted_sizes[i+1] - 1))\n            \n            width = gap_right - gap_left\n            if width = 0:\n                # This case implies overlapping clusters, which would invalidate the premise\n                # of inter-cluster gaps as defined. The problem setup avoids this.\n                raise ValueError(\"Invalid problem setup: Non-positive gap width detected.\")\n            gap_widths.append(width)\n        \n        min_gap_width = min(gap_widths)\n\n        # Step 3: Compute s_clusters\n        # We need 2^s  (b-a) / w_gap_min\n        if min_gap_width  0:\n            ratio_clusters = interval_width / min_gap_width\n            s_clusters = int(np.floor(np.log2(ratio_clusters))) + 1\n        else: # Should not happen with problem data\n            s_clusters = -1 # Error indicator\n    else:\n        # If there is only one cluster, there are no inter-cluster gaps.\n        # The concept of s_clusters is not applicable.\n        # We can set it to 0 as no refinement is needed to separate clusters.\n        s_clusters = 0\n\n    # Step 4: Compute s_epsilon\n    # We need 2^s = (b-a) / epsilon\n    ratio_epsilon = interval_width / epsilon\n    s_epsilon = int(np.ceil(np.log2(ratio_epsilon)))\n\n    return s_clusters, s_epsilon\n\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite.\n    \"\"\"\n    test_cases = [\n        # Test Case 1\n        {\n            \"n\": 12, \"q\": 2, \"centers\": [0, 1], \"sizes\": [7, 5],\n            \"delta\": 1e-3, \"r\": 1/3, \"epsilon\": 1e-6\n        },\n        # Test Case 2\n        {\n            \"n\": 10, \"q\": 2, \"centers\": [0, 3], \"sizes\": [9, 1],\n            \"delta\": 1e-8, \"r\": 0.9, \"epsilon\": 1e-12\n        },\n        # Test Case 3\n        {\n            \"n\": 8, \"q\": 3, \"centers\": [-2, 0, 2], \"sizes\": [3, 3, 2],\n            \"delta\": 1e-5, \"r\": 1/2, \"epsilon\": 1e-8\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        s_c, s_e = calculate_refinement_levels(\n            case[\"n\"], case[\"q\"], case[\"centers\"], case[\"sizes\"],\n            case[\"delta\"], case[\"r\"], case[\"epsilon\"]\n        )\n        results.extend([s_c, s_e])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3586212"}, {"introduction": "A robust numerical implementation must account for the limitations of floating-point arithmetic. This practice investigates the important technique of deflation, where a problem is split into smaller, independent subproblems by strategically neglecting numerically tiny off-diagonal entries [@problem_id:3586270]. You will derive a criterion for when an off-diagonal element is small enough to be set to zero and use Weyl's perturbation theorem to rigorously bound the resulting error in the computed eigenvalues, gaining insight into the trade-offs between computational efficiency and numerical accuracy.", "problem": "Consider a real symmetric tridiagonal matrix $T \\in \\mathbb{R}^{n \\times n}$ with diagonal entries $\\{a_{i}\\}_{i=1}^{n}$ and off-diagonal entries $\\{b_{i}\\}_{i=1}^{n-1}$, so that\n$$\nT = \\begin{pmatrix}\na_{1}  b_{1}  0  \\cdots  0 \\\\\nb_{1}  a_{2}  b_{2}  \\ddots  \\vdots \\\\\n0  b_{2}  a_{3}  \\ddots  0 \\\\\n\\vdots  \\ddots  \\ddots  \\ddots  b_{n-1} \\\\\n0  \\cdots  0  b_{n-1}  a_{n}\n\\end{pmatrix}.\n$$\nIn the bisection method for computing eigenvalues of $T$, the Sturm sequence count is obtained via a scalar $L D L^{\\top}$ factorization of $T - x I$ for a real shift $x$, with recurrence\n$$\np_{1}(x) = a_{1} - x,\\qquad p_{i+1}(x) = a_{i+1} - x - \\frac{b_{i}^{2}}{p_{i}(x)},\\quad i=1,\\dots,n-1,\n$$\nand the number of negative pivots $\\{p_{i}(x)\\}$ equals the number of eigenvalues of $T$ less than $x$. Under the standard floating-point error model for arithmetic operations, where for any basic operation $\\circ \\in \\{+,-,\\times,\\div\\}$ the computed result satisfies $\\operatorname{fl}(u \\circ v) = (u \\circ v)(1+\\delta)$ with $|\\delta| \\leq \\varepsilon$, and with $\\varepsilon$ denoting the machine precision (for the Institute of Electrical and Electronics Engineers Standard for Floating-Point Arithmetic (IEEE 754) double precision, $\\varepsilon = 2^{-53}$), it is observed that if $|b_{i}|$ is sufficiently small relative to neighboring diagonal magnitudes, an effective deflation can be performed by setting $b_{i}$ to zero without materially affecting the Sturm count or the eigenvalues beyond the scale of floating-point rounding.\n\nDerive, from first principles of the floating-point error model and the Sturm sequence recurrence above, a sufficient deflation detection criterion of the form\n$$\n|b_{i}| \\leq \\tau_{i},\n$$\nwhere $\\tau_{i}$ depends only on $\\varepsilon$ and neighboring diagonal magnitudes, and justify that this criterion ensures the coupling term $\\frac{b_{i}^{2}}{p_{i}(x)}$ is of the same order as rounding perturbations across the relevant range of $x$. Then, using the Weyl eigenvalue perturbation bound for symmetric matrices and an explicit computation of the perturbation norm when setting one $b_{i}$ to zero, provide a rigorous bound on the possible change in each eigenvalue caused by the deflation.\n\nApply your analysis to the following concrete instance with $n=5$:\n$$\nT = \\begin{pmatrix}\n6.0  0.5  0  0  0 \\\\\n0.5  5.5  0.45  0  0 \\\\\n0  0.45  5.6  3.2 \\times 10^{-9}  0 \\\\\n0  0  3.2 \\times 10^{-9}  -1.0  0.3 \\\\\n0  0  0  0.3  2.0\n\\end{pmatrix}.\n$$\nTake $\\varepsilon = 2^{-53}$. Use your derived deflation criterion to decide whether deflation at position $i=3$ (i.e., setting $b_{3}$ to zero) is justified. Then compute the upper bound $B$ on the change of each eigenvalue of $T$ resulting from setting $b_{3}$ to zero, expressed as the spectral norm of the corresponding symmetric perturbation.\n\nRound your final numerical bound $B$ to four significant figures. No physical units are involved in this problem, and your final answer must be a single real number.", "solution": "The problem is assessed to be valid. It is a well-posed problem within the established framework of numerical linear algebra, specifically concerning eigenvalue computations for symmetric tridiagonal matrices. The premises are scientifically sound, the terminology is precise, and the objectives are clearly defined and solvable with the provided information.\n\nThis problem requires a multi-part analysis. First, we derive and justify a deflation criterion for small off-diagonal elements in a symmetric tridiagonal matrix, based on the Sturm sequence recurrence used in the bisection method. Second, we establish a rigorous bound on the resulting eigenvalue perturbation using matrix norm analysis. Finally, we apply these results to a specific numerical example.\n\n**Part 1: Derivation of the Deflation Criterion**\n\nThe bisection method for finding eigenvalues of a real symmetric tridiagonal matrix $T$ can utilize the Sturm sequence property, where the number of eigenvalues of $T$ less than a given shift $x \\in \\mathbb{R}$ is equal to the number of negative terms in a specific sequence. This sequence can be generated from the pivots of the $L D L^{\\top}$ factorization of $T - xI$. The recurrence for these pivots $\\{p_i(x)\\}_{i=1}^n$ is given as:\n$$p_{1}(x) = a_{1} - x$$\n$$p_{i+1}(x) = (a_{i+1} - x) - \\frac{b_{i}^{2}}{p_{i}(x)}, \\quad i=1,\\dots,n-1$$\nDeflation at position $i$ involves setting the off-diagonal element $b_i$ to $0$. In the context of the recurrence, this means neglecting the coupling term $C_i(x) = \\frac{b_i^2}{p_i(x)}$ in the calculation of $p_{i+1}(x)$. The decision to deflate hinges on whether this neglected term is small enough to be considered \"in the noise\" of the floating-point computation.\n\nWe follow the principle that a term can be neglected if its magnitude is comparable to or smaller than the uncertainty introduced by floating-point rounding errors in the primary terms of the calculation. The recurrence for $p_{i+1}(x)$ is fundamentally a subtraction. The standard floating-point error model for an operation $\\circ$ is $\\operatorname{fl}(u \\circ v) = (u \\circ v)(1+\\delta)$ with $|\\delta| \\leq \\varepsilon$. When computing a difference $\\alpha - \\beta$, the absolute rounding error is approximately $\\varepsilon|\\alpha - \\beta|$. If we are to neglect the term $\\beta$, the error we introduce is $|\\beta|$. A sufficient condition for this to be permissible is that this introduced error is on the order of the rounding error that would be present anyway, i.e., $|\\beta| \\lesssim \\varepsilon|\\alpha - \\beta|$. If $|\\beta| \\ll |\\alpha|$, this condition simplifies to $|\\beta| \\lesssim \\varepsilon|\\alpha|$.\n\nIn our recurrence, $\\alpha = a_{i+1} - x$ and $\\beta = C_i(x) = \\frac{b_i^2}{p_i(x)}$. Applying the simplified condition, we require:\n$$ \\left| \\frac{b_i^2}{p_i(x)} \\right| \\lesssim \\varepsilon |a_{i+1} - x| $$\nThis is equivalent to $b_i^2 \\lesssim \\varepsilon |p_i(x) (a_{i+1} - x)|$. This criterion is dependent on the shift $x$, which is undesirable for a general-purpose deflation rule. To obtain a robust, $x$-independent criterion, we replace the $x$-dependent terms with their characteristic magnitudes. For a small off-diagonal $b_{i-1}$, the pivot $p_i(x)$ is approximately $a_i - x$. The characteristic scale of $|a_k - x|$ across the spectrum of $T$ can be taken as $|a_k|$. Substituting these scales, we get:\n$$ b_i^2 \\lesssim \\varepsilon |a_i a_{i+1}| $$\nThis provides a sufficient criterion for deflation. We formalize this as:\n$$ |b_i| \\leq \\sqrt{\\varepsilon |a_i a_{i+1}|} $$\nThis is our deflation detection criterion. The threshold $\\tau_i = \\sqrt{\\varepsilon |a_i a_{i+1}|}$ depends only on the machine precision $\\varepsilon$ and the magnitudes of the neighboring diagonal entries, as required.\n\n**Part 2: Bound on Eigenvalue Change**\n\nNext, we provide a rigorous bound on the change in the eigenvalues resulting from this deflation. Setting $b_i$ to $0$ transforms the matrix $T$ into a new matrix $T'$. The difference is the perturbation matrix $E = T - T'$. This matrix $E$ has only two non-zero entries: $E_{i,i+1} = E_{i+1,i} = b_i$. We can write $E$ as:\n$$ E = b_i (e_i e_{i+1}^{\\top} + e_{i+1} e_i^{\\top}) $$\nwhere $e_k$ is the $k$-th standard basis vector.\n\nThe magnitude of the change in the eigenvalues is bounded by the spectral norm ($2$-norm) of the perturbation matrix $E$. By Weyl's eigenvalue perturbation theorem for symmetric matrices, if $\\lambda_k(T)$ and $\\lambda_k(T')$ are the $k$-th eigenvalues of $T$ and $T'$ (sorted in non-decreasing order), then:\n$$ |\\lambda_k(T) - \\lambda_k(T')| \\leq \\|E\\|_2 $$\nThe spectral norm of $E$ is given by $\\|E\\|_2 = |b_i| \\|e_i e_{i+1}^{\\top} + e_{i+1} e_i^{\\top}\\|_2$. The matrix $S = e_i e_{i+1}^{\\top} + e_{i+1} e_i^{\\top}$ is a permutation matrix corresponding to a swap of indices $i$ and $i+1$ confined to the subspace spanned by $e_i$ and $e_{i+1}$. Its eigenvalues are the solution to $S v = \\lambda v$. For any vector $v$ in the orthogonal complement of $\\mathrm{span}\\{e_i, e_{i+1}\\}$, $Sv=0$, so there is an eigenvalue of $0$ with multiplicity $n-2$. For $v = \\alpha e_i + \\beta e_{i+1}$, we have $Sv = \\beta e_i + \\alpha e_{i+1}$. The eigenvalue equation becomes $\\beta e_i + \\alpha e_{i+1} = \\lambda (\\alpha e_i + \\beta e_{i+1})$, which implies $\\beta = \\lambda \\alpha$ and $\\alpha = \\lambda \\beta$. Substituting one into the other gives $\\beta = \\lambda^2 \\beta$, so $\\lambda^2=1$, yielding eigenvalues $\\lambda = 1$ and $\\lambda = -1$.\nThe spectral norm of a symmetric matrix is its spectral radius (the maximum absolute value of its eigenvalues). Thus, $\\|S\\|_2 = \\max\\{|-1|,|1|,|0|\\} = 1$.\nTherefore, the spectral norm of the perturbation is:\n$$ \\|E\\|_2 = |b_i| \\cdot 1 = |b_i| $$\nThe upper bound $B$ on the absolute change in any eigenvalue of $T$ upon setting $b_i$ to $0$ is precisely $|b_i|$.\n\n**Part 3: Application to the Concrete Instance**\n\nWe are given the matrix $T \\in \\mathbb{R}^{5 \\times 5}$:\n$$\nT = \\begin{pmatrix}\n6.0  0.5  0  0  0 \\\\\n0.5  5.5  0.45  0  0 \\\\\n0  0.45  5.6  3.2 \\times 10^{-9}  0 \\\\\n0  0  3.2 \\times 10^{-9}  -1.0  0.3 \\\\\n0  0  0  0.3  2.0\n\\end{pmatrix}\n$$\nWe must analyze deflation at position $i=3$. The relevant parameters are:\n$a_3 = 5.6$\n$a_4 = -1.0$\n$b_3 = 3.2 \\times 10^{-9}$\n$\\varepsilon = 2^{-53}$\n\nFirst, we check if deflation is justified using the criterion derived in Part 1:\n$$ |b_3| \\leq \\sqrt{\\varepsilon |a_3 a_4|} $$\nThe left-hand side is $|b_3| = 3.2 \\times 10^{-9}$.\nThe right-hand side is the threshold $\\tau_3$:\n$$ \\tau_3 = \\sqrt{2^{-53} |(5.6)(-1.0)|} = \\sqrt{5.6 \\times 2^{-53}} $$\nWe evaluate this numerically. Given $2^{-53} \\approx 1.110223 \\times 10^{-16}$:\n$$ \\tau_3 \\approx \\sqrt{5.6 \\times 1.110223 \\times 10^{-16}} \\approx \\sqrt{6.217249 \\times 10^{-16}} \\approx 2.493441 \\times 10^{-8} $$\nThe condition to check is:\n$$ 3.2 \\times 10^{-9} \\leq 2.493441 \\times 10^{-8} $$\nThis inequality is true, as $0.32 \\times 10^{-8} \\leq 2.493441 \\times 10^{-8}$. Therefore, deflation at position $i=3$ is justified according to our derived criterion.\n\nSecond, we compute the upper bound $B$ on the change of each eigenvalue. As established in Part 2, this bound is the spectral norm of the perturbation, which is simply $|b_i|$.\nFor $i=3$:\n$$ B = \\|E\\|_2 = |b_3| = 3.2 \\times 10^{-9} $$\nThe problem asks for this value rounded to four significant figures.\n$$ B = 3.200 \\times 10^{-9} $$\nThis value represents the maximum possible absolute shift of any eigenvalue of the matrix $T$ when the off-diagonal element $b_3$ is set to zero.", "answer": "$$\\boxed{3.200 \\times 10^{-9}}$$", "id": "3586270"}]}