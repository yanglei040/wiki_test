{"hands_on_practices": [{"introduction": "The Arnoldi process forms the core of many modern iterative eigensolvers. This first practice explores a special and highly instructive scenario known as an exact breakdown, which occurs when the process terminates before the prescribed number of steps. By analyzing the consequences when the residual term $h_{m+1,m}$ becomes zero [@problem_id:3589863], you will discover that this is not a failure but rather a sign of success, revealing a fundamental connection between the Krylov subspace and an exact invariant subspace of the original matrix.", "problem": "Consider a large, sparse, nonsymmetric matrix $A \\in \\mathbb{C}^{n \\times n}$ and the Arnoldi process applied to a nonzero starting vector $v_1 \\in \\mathbb{C}^{n}$ to construct an orthonormal basis $V_m = [v_1,\\dots,v_m] \\in \\mathbb{C}^{n \\times m}$ for the Krylov subspace $\\mathcal{K}_m(A,v_1) = \\mathrm{span}\\{v_1, Av_1, \\dots, A^{m-1} v_1\\}$. By the fundamental Arnoldi relations, there exists an upper Hessenberg matrix $H_m \\in \\mathbb{C}^{m \\times m}$ and a scalar $h_{m+1,m} \\in \\mathbb{C}$ such that\n$$\nA V_m \\;=\\; V_m H_m \\;+\\; h_{m+1,m} \\, v_{m+1} e_m^\\top,\n$$\nwhere $e_m \\in \\mathbb{R}^{m}$ is the $m$-th canonical basis vector and $v_{m+1} \\in \\mathbb{C}^{n}$ is the next Arnoldi vector. The case $h_{m+1,m} = 0$ is referred to as exact breakdown.\n\nUsing only the core definitions of the Arnoldi process and Krylov subspaces, and the characterization of exact breakdown via the displayed Arnoldi relation, reason about what $h_{m+1,m} = 0$ implies for the subspace $\\mathrm{span}(V_m)$ and for Ritz pairs, and explain how this situation is interpreted within the Implicitly Restarted Arnoldi Method (IRAM), defined here as a restarting strategy that uses implicit shifted orthogonal transformations (implicit QR steps with shifts) to filter and compress the Krylov subspace without explicitly forming powers of $A$.\n\nSelect all statements that are correct in this setting:\n\nA. If $h_{m+1,m} = 0$, then $A V_m = V_m H_m$, so $\\mathrm{span}(V_m)$ is an $A$-invariant subspace. Consequently, if $H_m y_i = \\theta_i y_i$ for some $y_i \\in \\mathbb{C}^{m}$, the Ritz pair $(\\theta_i, V_m y_i)$ is an exact eigenpair of $A$ with $A (V_m y_i) = \\theta_i (V_m y_i)$. In the Implicitly Restarted Arnoldi Method (IRAM), any subsequent implicit restart with shifts induces only an orthogonal change of basis within $\\mathrm{span}(V_m)$ and the process has effectively converged on that invariant subspace.\n\nB. If $h_{m+1,m} = 0$, then $H_m$ must be diagonal and equal to the restriction of $A$ to $\\mathrm{span}(V_m)$, implying that the Ritz vectors are exactly the canonical basis vectors $e_i$.\n\nC. If $h_{m+1,m} = 0$, then $\\mathcal{K}_m(A,v_1)$ is orthogonal to $A\\,\\mathcal{K}_m(A,v_1)$, which implies that $A$ is normal with respect to the Arnoldi basis and the Arnoldi process must be restarted with a different starting vector to avoid degeneracy.\n\nD. In the Implicitly Restarted Arnoldi Method (IRAM), if $h_{m+1,m} = 0$, choosing shifts at the unwanted Ritz values prevents the implicit QR step from being performed because the zero subdiagonal entry makes $H_m$ nonsimilar to its shifted forms, so the algorithm must increase $m$ to continue.", "solution": "This problem explores the consequences of an exact breakdown in the Arnoldi process, where the residual norm becomes zero before the desired number of iterations is complete, i.e., $h_{m+1,m} = 0$. This is not a failure, but a sign of success.\n\n1.  **Analysis of the Breakdown Condition**: The fundamental Arnoldi relation is $A V_m = V_m H_m + h_{m+1,m} v_{m+1} e_m^\\top$. When an exact breakdown occurs, $h_{m+1,m} = 0$, and the relation simplifies to:\n    $$A V_m = V_m H_m$$\n    This equation means that applying the matrix $A$ to the basis vectors in $V_m$ produces a set of vectors that can be written as linear combinations of the original basis vectors. Therefore, the Krylov subspace $\\mathcal{K}_m(A, v_1) = \\mathrm{span}(V_m)$ is an **$A$-invariant subspace**.\n\n2.  **Implications for Ritz Pairs**: A Ritz pair $(\\theta_i, u_i)$ is formed from an eigenpair $(\\theta_i, y_i)$ of the small matrix $H_m$ (where $H_m y_i = \\theta_i y_i$) and the Arnoldi basis $u_i = V_m y_i$. Using the simplified relation from the breakdown, we can test if this Ritz pair is an exact eigenpair of the large matrix $A$:\n    $$A u_i = A (V_m y_i) = (A V_m) y_i = (V_m H_m) y_i = V_m (H_m y_i) = V_m (\\theta_i y_i) = \\theta_i (V_m y_i) = \\theta_i u_i$$\n    This confirms that all $m$ Ritz pairs are exact eigenpairs of $A$. The process has successfully found an $m$-dimensional invariant subspace and all eigenvalues associated with it.\n\n3.  **Implications for IRAM**: An implicit restart would perform orthogonal transformations on this basis. However, since $\\mathrm{span}(V_m)$ is already a perfect invariant subspace, any such operation simply amounts to a change of basis within that subspace. The algorithm has converged and cannot find new information.\n\nBased on this analysis:\n\n*   **A is correct.** It accurately summarizes all three points above: $\\mathrm{span}(V_m)$ is an $A$-invariant subspace, the Ritz pairs become exact eigenpairs, and a restart becomes a mere change of basis within this converged subspace.\n*   **B is incorrect.** $H_m$ is the representation of $A$ restricted to the invariant subspace; it is guaranteed to be upper Hessenberg, but not necessarily diagonal.\n*   **C is incorrect.** Invariance means $A\\mathcal{K}_m \\subseteq \\mathcal{K}_m$, not that $A\\mathcal{K}_m$ is orthogonal to $\\mathcal{K}_m$. A breakdown signifies convergence, not a degeneracy that requires restarting with a new vector.\n*   **D is incorrect.** A breakdown means the process has naturally terminated and found an invariant subspace. It does not prevent the application of QR steps, but it makes further expansion of the subspace impossible (and unnecessary).", "answer": "$$\\boxed{A}$$", "id": "3589863"}, {"introduction": "The power of IRAM lies in its ability to intelligently restart the Arnoldi process, refining the search for eigenvalues without sacrificing previously gathered information. This is achieved through an elegant polynomial filtering mechanism, performed implicitly via QR steps. This exercise asks you to justify the fundamental design choice $m=k+p$, relating the total subspace dimension $m$ to the desired number of eigenpairs $k$ and the number of filter shifts $p$ [@problem_id:3589878]. Understanding this relationship is key to grasping how IRAM uses the extra subspace dimensions to actively suppress unwanted spectral components and accelerate convergence.", "problem": "Consider the Implicitly Restarted Arnoldi Method (IRAM) applied to a matrix $A \\in \\mathbb{C}^{n \\times n}$. Let the Arnoldi process produce an orthonormal basis $V_{m}$ and an upper Hessenberg matrix $H_{m}$ satisfying the Arnoldi relation\n$$\nA V_{m} \\;=\\; V_{m} H_{m} \\;+\\; h_{m+1,m}\\, v_{m+1} e_{m}^{\\top},\n$$\nwith Ritz pairs given by eigenpairs of $H_{m}$. In IRAM, one performs an implicit restarting phase that applies $p$ implicit shifts $\\{\\sigma_{j}\\}_{j=1}^{p}$, typically chosen near unwanted Ritz values, which is known to be equivalent to applying a degree-$p$ polynomial filter $\\phi_{p}(A) = \\prod_{j=1}^{p}(A - \\sigma_{j} I)$ within the Krylov process, thereby attenuating components associated with the unwanted invariant subspace. Suppose one seeks $k$ eigenpairs and must choose the Arnoldi subspace dimension $m$ and the number of shifts $p$ per restart under a fixed memory budget. Which option best justifies, from first principles of Krylov subspace projection and polynomial filtering, the canonical rule that ties $m$, $k$, and $p$ by taking the subspace dimension equal to the number of retained Ritz vectors plus the number of shifts per restart?\n\nA. The implicit restarting step is a polynomial filter of degree $p$ with roots at the selected shifts, which suppresses components aligned with the unwanted Ritz vectors. To retain a $k$-dimensional approximation to the desired invariant subspace across restarts while still allowing a degree-$p$ filtering action on the residual subspace, one needs $m$ to accommodate both the $k$ retained directions and the $p$ degrees of freedom consumed by filtering; the minimal such choice is to set the subspace dimension equal to the sum of the retained dimension and the number of shifts.\n\nB. The implicit QR steps preserve the full Krylov subspace dimension regardless of the shifts, so the number of shifts must equal the number of desired eigenpairs to maintain stability; therefore the only consistent choice is to take the subspace dimension equal to twice the number of desired eigenpairs.\n\nC. Because the Arnoldi recurrence updates with a three-term relation, a single extra dimension suffices to represent the effect of any number of shifts, so the number of shifts does not affect the subspace dimension and one can always choose the subspace dimension to exceed the desired count by only one.\n\nD. The degree of the effective restart filter grows with the subspace dimension and is independent of the number of shifts, so any positive number of shifts yields identical damping strength, and hence the subspace dimension should equal the desired count to maximize efficiency.", "solution": "The Implicitly Restarted Arnoldi Method (IRAM) is designed to find $k$ desired eigenpairs by iteratively refining a Krylov subspace. The standard implementation uses a subspace of dimension $m > k$. The relationship $m = k+p$ is fundamental to the algorithm's \"implicit filtering\" mechanism.\n\n1.  **Subspace Roles**: An $m$-dimensional Krylov subspace is constructed. Within this space, we identify $k$ \"wanted\" Ritz vectors that we wish to improve and retain, and $p$ \"unwanted\" Ritz vectors that we wish to discard. To make this distinction, the initial space must be large enough to hold both sets, so we need $m \\ge k+p$. The choice $m=k+p$ is the most direct approach.\n\n2.  **Polynomial Filtering**: The \"implicit restart\" phase uses the $p$ unwanted Ritz values as shifts to construct and apply a degree-$p$ polynomial filter, $\\phi_p(A)$. This filter is designed to be small on the unwanted parts of the spectrum and large elsewhere. Applying it has the effect of damping components of the basis vectors associated with unwanted eigenvectors.\n\n3.  **Restart Mechanism**: The implicit QR algorithm performs this filtering without explicitly forming $\\phi_p(A)$, which would be computationally expensive. It transforms the $m$-dimensional basis and Hessenberg matrix, then truncates them to dimension $k$. The resulting $k$-dimensional subspace is a refined version of the original, now purified of the unwanted components. The $p$ \"extra\" dimensions were the necessary workspace for the filtering to take place.\n\nTherefore, the choice $m = k+p$ directly reflects the needs of the algorithm: $k$ dimensions to preserve the improving approximations and $p$ dimensions to serve as the degrees of freedom for a degree-$p$ polynomial filter that drives the purification and convergence.\n\n*   **A is correct.** This option accurately describes this logic. The subspace dimension $m$ must accommodate both the $k$ retained directions and the $p$ degrees of freedom consumed by the filtering process.\n*   **B is incorrect.** The restart process explicitly truncates the subspace from dimension $m$ to $k$. The number of shifts $p$ is independent of $k$.\n*   **C is incorrect.** The general Arnoldi method uses a long recurrence. Even for the symmetric case (Lanczos), which has a three-term recurrence, a degree-$p$ filter still requires $p$ extra dimensions.\n*   **D is incorrect.** The degree of the filter is exactly $p$, the number of shifts. More shifts (a larger $p$) allow for a more aggressive or selective filter. Setting $p=0$ (i.e., $m=k$) would eliminate the filtering step.", "answer": "$$\n\\boxed{A}\n$$", "id": "3589878"}, {"introduction": "While algorithms are often designed in the pristine world of exact arithmetic, their real-world performance depends critically on their behavior in finite precision. This practice delves into one of the most important practical aspects of the Arnoldi method: the loss of orthogonality among the basis vectors due to floating-point errors. You will analyze how this leads to the emergence of spurious \"ghost\" eigenvalues and explore the standard techniques, such as reorthogonalization and locking, that are essential for making IRAM a robust and reliable tool [@problem_id:3589891].", "problem": "Consider a large, sparse, nonsingular matrix $A \\in \\mathbb{C}^{n \\times n}$ and the task of computing the $k$ eigenvalues of $A$ of largest magnitude using the Implicitly Restarted Arnoldi Method (IRAM). In exact arithmetic, the Arnoldi process started from a unit vector $v_1$ produces an orthonormal basis $V_{m+1} = [v_1,\\dots,v_{m+1}] \\in \\mathbb{C}^{n \\times (m+1)}$ and an upper Hessenberg matrix $H_{m+1,m} \\in \\mathbb{C}^{(m+1)\\times m}$ satisfying the Arnoldi relation\n$$\nA V_m \\;=\\; V_{m+1} H_{m+1,m},\n$$\nwith $V_m = [v_1,\\dots,v_m] \\in \\mathbb{C}^{n \\times m}$ and $H_m \\in \\mathbb{C}^{m \\times m}$ denoting the leading principal block of $H_{m+1,m}$. Ritz values are the eigenvalues $\\theta \\in \\mathbb{C}$ of $H_m$, and corresponding Ritz vectors are of the form $V_m y$, where $y \\in \\mathbb{C}^m$ is an eigenvector of $H_m$. The Rayleigh–Ritz condition states that the residual $r = A (V_m y) - \\theta (V_m y)$ is orthogonal to $\\mathcal{K}_m(A, v_1) = \\mathrm{span}\\{v_1, A v_1, \\dots, A^{m-1} v_1\\}$, i.e., $V_m^\\ast r = 0$.\n\nIn floating-point arithmetic with unit roundoff $u$, the computed basis vectors $v_j$ may lose orthogonality so that $V_m^\\ast V_m = I + E$ with a small but nonzero matrix $E \\in \\mathbb{C}^{m \\times m}$ satisfying $\\|E\\| = \\mathcal{O}(u) \\cdot \\mathrm{poly}(m)$. The IRAM algorithm applies an implicit polynomial filter $p(A)$ induced by $s$ shifts to restart the subspace, ideally suppressing undesired components while retaining approximations to the desired invariant subspace.\n\nAnalyze, from first principles of projection methods and floating-point perturbation, how the loss of orthogonality among the Arnoldi vectors affects the distribution of computed Ritz values in IRAM, with particular attention to the emergence of spurious and repeated Ritz values. Select all statements that are correct.\n\nA. In finite precision, loss of orthogonality among the Arnoldi vectors implies that the Ritz pairs computed from $H_m$ are still exactly the eigenpairs of the orthogonal projection of $A$ onto $\\mathcal{K}_m(A,v_1)$, so spurious duplicated Ritz values cannot occur.\n\nB. When $V_m^\\ast V_m = I + E$ with $E \\neq 0$, the computed Ritz values can be interpreted as exact eigenvalues of a nearby generalized Rayleigh–Ritz problem $(V_m^\\ast A V_m,\\, V_m^\\ast V_m)$; near linear dependence in the columns of $V_m$ can allow multiple Ritz vectors to approximate the same invariant subspace of $A$, leading to repeated (ghost) Ritz values.\n\nC. In IRAM, the implicit polynomial filtering ideally damps unwanted components, but loss of orthogonality can allow already converged components to persist or leak back into the restarted subspace, producing ghost Ritz values that duplicate converged eigenvalues; strategies such as selective reorthogonalization or locking mitigate this effect.\n\nD. A reliable practical diagnostic for spurious duplicate Ritz values is that their residual norms $\\|A (V_m y) - \\theta (V_m y)\\|_2$ are much larger than those of genuine Ritz pairs; therefore, large residuals flag spurious duplicates.\n\nE. For normal matrices (in particular, Hermitian matrices), loss of orthogonality cannot create repeated Ritz values in IRAM because the field of values is convex; ghost eigenvalues do not occur for normal $A$.\n\nF. Maintaining full reorthogonalization to keep $V_m$ numerically orthonormal and explicitly locking converged Ritz vectors so that they are kept fixed and orthogonal to the active Krylov basis eliminates the mechanism that creates spurious duplicates in IRAM, in the sense that in exact arithmetic models of these steps, repeated Ritz values due to loss of orthogonality do not arise.\n\nChoose all that apply.", "solution": "The problem statement describes the implicitly restarted Arnoldi method (IRAM) for computing a few eigenvalues of a large matrix $A$. It correctly defines the Arnoldi factorization, Ritz pairs, the Rayleigh-Ritz condition, and the issue of loss of orthogonality in finite-precision arithmetic. The core of the problem is to analyze the emergence of spurious or repeated Ritz values (often called \"ghost\" eigenvalues) as a consequence of this loss of orthogonality. The premises are grounded in the standard, well-established theory of numerical linear algebra, particularly the analysis of Krylov subspace methods in floating-point arithmetic. The problem is scientifically sound, well-posed, objective, and provides sufficient context to evaluate the given statements. Therefore, the problem is valid, and we may proceed with the analysis.\n\nThe fundamental principle of the Arnoldi method in exact arithmetic is the construction of an orthonormal basis $V_m$ for the Krylov subspace $\\mathcal{K}_m(A, v_1)$. The Ritz pairs $(\\theta, V_m y)$ are derived from the standard eigenvalue problem for $H_m = V_m^\\ast A V_m$, which represents the orthogonal projection of $A$ onto $\\mathcal{K}_m(A, v_1)$. The defining property is the Galerkin condition: the residual $r = A(V_m y) - \\theta (V_m y)$ is orthogonal to the subspace $\\mathcal{K}_m(A, v_1)$, i.e., $V_m^\\ast r = 0$.\n\nIn finite-precision arithmetic, the computed basis, which we will also denote by $V_m$ for simplicity, is no longer perfectly orthonormal. We have $V_m^\\ast V_m = I + E$, where $E$ is a non-zero matrix whose norm depends on the unit roundoff $u$ and problem parameters. The computed Ritz pairs are still obtained by solving a standard eigenvalue problem for a computed Hessenberg matrix $H_m$. However, the underlying projection is no longer orthogonal. The Galerkin condition $V_m^\\ast (A(V_m y) - \\theta (V_m y)) = 0$ is what the algorithm attempts to enforce. This rearranges to:\n$$\n(V_m^\\ast A V_m) y = \\theta (V_m^\\ast V_m) y\n$$\nThis is a generalized eigenvalue problem for the matrix pencil $(V_m^\\ast A V_m, V_m^\\ast V_m)$. The computed Ritz values $\\theta$ are the eigenvalues of this pencil.\n\nThe phenomenon of \"ghost\" eigenvalues arises directly from this framework. As a Ritz value converges to a true eigenvalue of $A$, the Arnoldi process suffers a catastrophic loss of orthogonality in the basis vectors. Subsequent vectors in the basis tend to develop significant components along the direction of the corresponding converged eigenvector. When IRAM performs a restart, the filtering process is meant to discard unwanted parts of the subspace. However, due to the loss of orthogonality, a component of the converged eigenvector can \"leak\" through the filter and remain in the starting vector for the new cycle. The Arnoldi process then \"rediscovers\" this eigenvector, leading to a second Ritz value converging to the same eigenvalue of $A$. This is the ghost.\n\nWe now evaluate each statement based on these principles.\n\n**A. In finite precision, loss of orthogonality among the Arnoldi vectors implies that the Ritz pairs computed from $H_m$ are still exactly the eigenpairs of the orthogonal projection of $A$ onto $\\mathcal{K}_m(A,v_1)$, so spurious duplicated Ritz values cannot occur.**\n\nThis statement is **Incorrect**. When the basis $V_m$ is not orthonormal, the procedure does not correspond to an orthogonal projection. As derived above, it corresponds to a generalized eigenvalue problem $(V_m^\\ast A V_m) y = \\theta (V_m^\\ast V_m) y$. The matrix of this projection would be $P = V_m (V_m^\\ast V_m)^{-1} V_m^\\ast$, which is an oblique projector, not an orthogonal one. The central claim that spurious duplicates cannot occur is factually wrong; their occurrence is a well-documented artifact of the method in finite precision and is the primary subject of this problem.\n\n**B. When $V_m^\\ast V_m = I + E$ with $E \\neq 0$, the computed Ritz values can be interpreted as exact eigenvalues of a nearby generalized Rayleigh–Ritz problem $(V_m^\\ast A V_m,\\, V_m^\\ast V_m)$; near linear dependence in the columns of $V_m$ can allow multiple Ritz vectors to approximate the same invariant subspace of $A$, leading to repeated (ghost) Ritz values.**\n\nThis statement is **Correct**. It accurately identifies the mathematical framework describing the computed Ritz values in the presence of lost orthogonality: they are the exact eigenvalues of the generalized eigenproblem $(V_m^\\ast A V_m, V_m^\\ast V_m)$. Furthermore, it correctly identifies the consequence of this. Loss of orthogonality implies that the basis vectors $v_j$ are no longer linearly independent in a numerically robust sense. This \"near linear dependence\" is precisely what allows multiple distinct linear combinations of the basis vectors (i.e., multiple Ritz vectors $V_m y_1$, $V_m y_2$) to approximate the same eigenvector of $A$, leading to multiple Ritz values $\\theta_1, \\theta_2$ approximating the same eigenvalue.\n\n**C. In IRAM, the implicit polynomial filtering ideally damps unwanted components, but loss of orthogonality can allow already converged components to persist or leak back into the restarted subspace, producing ghost Ritz values that duplicate converged eigenvalues; strategies such as selective reorthogonalization or locking mitigate this effect.**\n\nThis statement is **Correct**. It provides a precise and accurate description of the dynamics within IRAM that lead to ghost eigenvalues. The implicit restart applies a polynomial filter $p(A)$ to the basis. This is intended to isolate the desired invariant subspace. However, because loss of orthogonality has mixed components of the converged eigenvectors throughout the basis, the filtering is imperfect. A converged component can \"leak\" back into the Krylov subspace after the restart, prompting the Arnoldi process to find it again. This leads to the ghost copy. The statement correctly lists the two primary and effective countermeasures: reorthogonalization (maintaining the orthogonality of the basis, often selectively against converged vectors) and locking (explicitly deflating converged eigenvectors from the computation).\n\n**D. A reliable practical diagnostic for spurious duplicate Ritz values is that their residual norms $\\|A (V_m y) - \\theta (V_m y)\\|_2$ are much larger than those of genuine Ritz pairs; therefore, large residuals flag spurious duplicates.**\n\nThis statement is **Incorrect**. A \"ghost\" eigenvalue is typically a very good approximation of a true eigenvalue of $A$, just as its \"genuine\" counterpart is. Therefore, both the genuine Ritz pair and the ghost Ritz pair will typically have small residual norms, signaling convergence. A large residual norm indicates a poor approximation, i.e., a non-converged Ritz pair, which is a different issue from a ghost. The defining characteristic of a ghost is not a large residual but rather its status as a *duplicate* of another converged Ritz value. In practice, one detects ghosts by looking for clusters of tightly packed Ritz values, all with small residuals. A large residual flags a Ritz value that should be discarded by the IRAM restart filter, not a ghost.\n\n**E. For normal matrices (in particular, Hermitian matrices), loss of orthogonality cannot create repeated Ritz values in IRAM because the field of values is convex; ghost eigenvalues do not occur for normal $A$.**\n\nThis statement is **Incorrect**. The specialization of the Arnoldi method for Hermitian matrices is the Lanczos algorithm. The phenomenon of ghost eigenvalues is famous and well-studied in the context of the Lanczos algorithm. C. C. Paige's seminal 1971 thesis provided the definitive analysis of how loss of orthogonality in the Lanczos algorithm leads to multiple copies of converged eigenvalues. The mechanism is identical to the one described for the general Arnoldi method. The convexity of the field of values (for a normal matrix, this is the convex hull of its eigenvalues) is a property of the exact operator and has no bearing on this floating-point artifact.\n\n**F. Maintaining full reorthogonalization to keep $V_m$ numerically orthonormal and explicitly locking converged Ritz vectors so that they are kept fixed and orthogonal to the active Krylov basis eliminates the mechanism that creates spurious duplicates in IRAM, in the sense that in exact arithmetic models of these steps, repeated Ritz values due to loss of orthogonality do not arise.**\n\nThis statement is **Correct**. It describes the two most effective and theoretically sound strategies for preventing ghost eigenvalues.\n1.  **Full reorthogonalization:** By enforcing $V_m^\\ast V_m = I$ to working precision, the method becomes numerically equivalent to an orthogonal projection. The generalized eigenvalue problem from (B) reduces to a standard eigenvalue problem, and the near-linear dependence that allows for multiple representations of the same eigenvector is eliminated.\n2.  **Explicit locking:** Once a Ritz pair $(\\theta, x)$ has converged, it is \"locked.\" The subsequent IRAM process is constrained to the subspace orthogonal to all locked vectors. This explicitly prevents the algorithm from rediscovering $x$.\nThe qualifier \"in the sense that in exact arithmetic models of these steps\" is crucial and correct. It acknowledges that these are algorithmic procedures which, if performed perfectly, provably eliminate the ghosting mechanism. In practice, they are implemented in finite precision, but they are designed to be stable and work effectively to suppress ghosts to the level of machine error.", "answer": "$$\\boxed{BCF}$$", "id": "3589891"}]}