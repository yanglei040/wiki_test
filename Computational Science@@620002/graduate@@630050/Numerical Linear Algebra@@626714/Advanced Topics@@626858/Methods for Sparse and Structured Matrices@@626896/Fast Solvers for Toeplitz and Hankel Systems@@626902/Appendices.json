{"hands_on_practices": [{"introduction": "Iterative methods like the Conjugate Gradient algorithm are indispensable for solving large Toeplitz systems, and their efficiency hinges on performing matrix-vector products quickly. This practice [@problem_id:3545696] guides you through implementing the cornerstone technique for this task: embedding the Toeplitz matrix into a larger circulant one to leverage the computational power of the Fast Fourier Transform (FFT). You will explore the crucial link between the smoothness of the matrix's generating symbol and the approximation error, learning how to select an optimal embedding size to balance accuracy and computational cost.", "problem": "Consider a family of symmetric Toeplitz matrices of size $n \\times n$ generated by a two-sided Fourier series symbol $g(\\theta)$ on $[0,2\\pi)$, defined via real, nonnegative Fourier coefficients $\\{t_k\\}_{k \\in \\mathbb{N}_0}$ satisfying $t_{-k} = t_k$. The Toeplitz matrix $T_n$ has entries $(T_n)_{ij} = t_{\\lvert i-j \\rvert}$ for $1 \\leq i,j \\leq n$. The task is to compute the matrix-vector product $y = T_n x$ efficiently using a circulant embedding and the Fast Fourier Transform (FFT), and to optimize the embedding size to minimize aliasing effects.\n\nFundamental Basis:\n- The Discrete Fourier Transform (DFT) diagonalizes circulant matrices. Circular convolution of a length-$m$ kernel with a length-$m$ vector is computable in $\\mathcal{O}(m \\log m)$ by FFT.\n- The Fourier series representation $g(\\theta) = \\sum_{k \\in \\mathbb{Z}} t_k \\mathrm{e}^{-\\mathrm{i} k \\theta}$ with $t_{-k}=t_k$ defines a translation-invariant kernel on the cyclic group of order $m$. Sampling $g(\\theta)$ on an $m$-point grid yields a circulant whose time-domain kernel equals the periodic summation of the Fourier coefficients.\n\nAliasing and the Periodic Summation Principle:\n- Sampling $g(\\theta)$ at $m$ equispaced points and applying the inverse DFT yields a time-domain sequence $c[r]$ ($0 \\leq r < m$) equal to the periodic summation of the Fourier coefficients:\n$$\nc[r] = \\sum_{\\ell \\in \\mathbb{Z}} t_{\\lvert r + \\ell m \\rvert}.\n$$\n- Computing the circular convolution of $c$ with a zero-padded $x$ approximates $T_n x$. The difference relative to the exact Toeplitz product can be bounded in terms of aliasing error arising from the periodic summation tail.\n\nSymbol smoothness models:\n- Exponential decay (analytic symbol): $t_k = C \\mathrm{e}^{-\\alpha k}$ for $k \\geq 0$, with parameters $C > 0$, $\\alpha > 0$.\n- Algebraic decay (finite smoothness): $t_k = C (1+k)^{-p}$ for $k \\geq 0$, with parameters $C > 0$, $p > 1$.\n\nAliasing error bounds for the periodic summation of $\\{t_k\\}$:\n- For exponential decay, the periodic aliasing tail for any fixed $r$ is bounded by\n$$\nE_{\\mathrm{alias}}^{\\mathrm{exp}}(m) \\leq 2 C \\frac{\\mathrm{e}^{-\\alpha m}}{1 - \\mathrm{e}^{-\\alpha m}}.\n$$\n- For algebraic decay, the periodic aliasing tail for any fixed $r$ is bounded by\n$$\nE_{\\mathrm{alias}}^{\\mathrm{alg}}(m) \\leq 2 C \\zeta(p) m^{-p},\n$$\nwhere $\\zeta(p)$ is the Riemann zeta function evaluated at $p$.\n\nOptimization objective:\n- Given $n$, a smoothness model with known parameters, and a tolerance $\\varepsilon$, choose the smallest power-of-two embedding size $m$ such that the aliasing bound for the chosen model is at most $\\varepsilon$, while ensuring $m \\geq 2n$ so that the circular convolution window covers the linear range without wrap-around of the input.\n\nImplementation details:\n- Construct the periodic kernel $c[r]$ using the identity $c[r] = \\sum_{\\ell \\in \\mathbb{Z}} t_{\\lvert r + \\ell m \\rvert}$, truncated by neglecting terms below a threshold $\\tau$. Because $t_k$ is monotone decreasing in $k$ under both models, a simple loop over $\\ell \\geq 1$ suffices, stopping when both $t_{r + \\ell m}$ and $t_{\\ell m - r}$ fall below $\\tau$. For $r=0$, use $c[0] = t_0 + 2\\sum_{\\ell \\geq 1} t_{\\ell m}$ truncated at $\\tau$.\n- Compute the approximate product $y_{\\mathrm{FFT}}$ by circular convolution of $c$ with $x$ zero-padded to length $m$ using FFT.\n- Compute the exact product $y_{\\mathrm{exact}}$ by direct summation $y_i = \\sum_{j=1}^n t_{\\lvert i-j \\rvert} x_j$.\n- Measure the relative error $\\|y_{\\mathrm{FFT}} - y_{\\mathrm{exact}}\\|_{\\infty}/\\|y_{\\mathrm{exact}}\\|_{\\infty}$.\n\nTest suite:\nFor each test case below, use tolerance $\\varepsilon = 10^{-8}$ and truncation threshold $\\tau = 10^{-12}$.\n\n1. Exponential decay (analytic symbol):\n   - $n = 64$, $C = 1$, $\\alpha = 0.5$.\n2. Algebraic decay (finite smoothness):\n   - $n = 64$, $C = 1$, $p = 2.2$.\n3. Exponential decay (analytic symbol, faster):\n   - $n = 128$, $C = 1$, $\\alpha = 1.0$.\n4. Algebraic decay (finite smoothness, smoother):\n   - $n = 128$, $C = 1$, $p = 3.0$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result is the relative $\\ell_{\\infty}$ error (a float) for the corresponding test case, in the same order as listed above. For example: \"[e1,e2,e3,e4]\".", "solution": "The user has provided a problem in the domain of numerical linear algebra, specifically concerning the fast computation of a matrix-vector product for a symmetric Toeplitz matrix $T_n$. The proposed method involves embedding the $n \\times n$ Toeplitz matrix into a larger $m \\times m$ circulant matrix and using the Fast Fourier Transform (FFT) to perform the convolution efficiently in $\\mathcal{O}(m \\log m)$ time.\n\n### Step 1: Problem Validation\n\nThe problem is subjected to rigorous validation before a solution is attempted.\n\n-   **Extraction of Givens**:\n    -   **Matrix**: Symmetric Toeplitz matrix $T_n$ of size $n \\times n$, with entries $(T_n)_{ij} = t_{\\lvert i-j \\rvert}$.\n    -   **Coefficients**: The sequence $\\{t_k\\}_{k \\in \\mathbb{N}_0}$ is real, nonnegative, and even ($t_{-k} = t_k$).\n    -   **Task**: Compute $y = T_n x$ using a circulant embedding of size $m \\times m$ and FFT.\n    -   **Circulant Kernel**: The first column of the circulant matrix, $c$, is defined by the periodic summation $c[r] = \\sum_{\\ell \\in \\mathbb{Z}} t_{\\lvert r + \\ell m \\rvert}$.\n    -   **Coefficient Decay Models**:\n        1.  Exponential (analytic): $t_k = C \\mathrm{e}^{-\\alpha k}$ for $k \\geq 0$, with $C > 0, \\alpha > 0$.\n        2.  Algebraic (finite smoothness): $t_k = C (1+k)^{-p}$ for $k \\geq 0$, with $C > 0, p > 1$.\n    -   **Aliasing Error Bounds**: Explicit formulas are provided for the error in the circulant kernel due to periodic summation for each decay model.\n        -   Exponential: $E_{\\mathrm{alias}}^{\\mathrm{exp}}(m) \\leq 2 C \\frac{\\mathrm{e}^{-\\alpha m}}{1 - \\mathrm{e}^{-\\alpha m}}$.\n        -   Algebraic: $E_{\\mathrm{alias}}^{\\mathrm{alg}}(m) \\leq 2 C \\zeta(p) m^{-p}$.\n    -   **Optimization Goal**: For a given $n$, decay model, and tolerance $\\varepsilon$, find the smallest power-of-two integer $m$ such that $m \\geq 2n$ and the corresponding aliasing error bound is no more than $\\varepsilon$.\n    -   **Implementation Details**:\n        -   Kernel construction involves truncating the summation for $c[r]$ when terms fall below a threshold $\\tau$.\n        -   The final error is measured by the relative $\\ell_{\\infty}$ norm: $\\|y_{\\mathrm{FFT}} - y_{\\mathrm{exact}}\\|_{\\infty}/\\|y_{\\mathrm{exact}}\\|_{\\infty}$.\n    -   **Test Suite Parameters**: Four test cases are specified with values for $n$, $C$, $\\alpha$, $p$. Tolerances are given as $\\varepsilon = 10^{-8}$ and $\\tau = 10^{-12}$.\n\n-   **Validation Verdict**:\n    -   **Scientifically Grounded**: The problem is a classic application of Fourier analysis in numerical linear algebra. The use of circulant preconditioners and fast convolution for Toeplitz systems is a well-established, fundamental technique. The connection between the symbol's smoothness (decay of Fourier coefficients) and the convergence of the circulant approximation is a core concept in the field. The provided error bounds are standard results. The problem is scientifically and mathematically sound.\n    -   **Well-Posed and Complete**: The problem is clearly defined. All necessary parameters, models, and objectives are specified. The optimization goal for the embedding size $m$ is unambiguous. The only unspecified element is the input vector $x$. In the context of testing a numerical algorithm's accuracy, a standard practice is to use a fixed or random vector. Using a vector of pseudorandom numbers (generated from a fixed seed for reproducibility) is a valid and standard approach to complete the problem specification.\n    -   **Objective**: The language is precise and mathematical, free from any subjectivity or ambiguity.\n\nThe problem is deemed **valid**. It is a well-posed, scientifically grounded exercise in computational mathematics. The solution can proceed.\n\n### Step 2: Solution Derivation\n\nThe solution involves implementing the described algorithm for each of the four test cases. A random vector $x$ will be generated for each test case to perform the computations. For reproducibility, a single pseudorandom number generator with a fixed seed is used.\n\n**Algorithm Outline for Each Test Case:**\n\n1.  **Parameter Setup**: Isolate the parameters for the current test case: $n$, the model type ('exponential' or 'algebraic'), and the model parameters ($C, \\alpha$ or $C, p$). Set the tolerances $\\varepsilon = 10^{-8}$ and $\\tau = 10^{-12}$.\n\n2.  **Determine Embedding Size $m$**:\n    -   Initialize $m$ to be the smallest power of two that is greater than or equal to $2n$. This ensures that linear convolution is correctly computed without wrap-around effects.\n    -   Enter a loop:\n        -   Calculate the aliasing error bound based on the specified model for the current $m$. For the algebraic model, this requires the Riemann zeta function $\\zeta(p)$, available in `scipy.special`.\n        -   If the calculated bound is less than or equal to the tolerance $\\varepsilon$, exit the loop.\n        -   Otherwise, double the value of $m$ and continue the loop.\n\n3.  **Generate Test Data**:\n    -   Create the input vector $x$ of size $n$ with random entries drawn from a uniform distribution on $[0, 1)$.\n    -   Define a helper function, `t_k_func(k)`, which evaluates the coefficient $t_k$ according to the specified decay model.\n\n4.  **Compute Exact Product $y_{\\mathrm{exact}}$**:\n    -   Generate the first column of the Toeplitz matrix $T_n$, which consists of $[t_0, t_1, \\dots, t_{n-1}]$.\n    -   Construct the full $n \\times n$ symmetric Toeplitz matrix $T_n$ using the function `scipy.linalg.toeplitz`.\n    -   Compute the exact matrix-vector product $y_{\\mathrm{exact}} = T_n x$.\n\n5.  **Compute Approximate Product $y_{\\mathrm{FFT}}$**:\n    -   **Construct Circulant Kernel $c$**: Create a vector $c$ of length $m$. Based on the identity $c[r] = \\sum_{\\ell \\in \\mathbb{Z}} t_{|r+\\ell m|}$ and the evenness of $t_k$, $c$ is also even with respect to the midpoint $m/2$, i.e., $c[r] = c[m-r]$. This symmetry is exploited for efficiency.\n        -   Compute $c[r]$ for $r \\in [0, m/2]$ by summing the series $t_r + \\sum_{\\ell=1}^{\\infty} (t_{\\ell m - r} + t_{\\ell m + r})$ (with a special form for $r=0$). The summation over $\\ell$ is truncated when the term to be added falls below the threshold $\\tau$.\n        -   Populate the remaining entries $c[r]$ for $r \\in (m/2, m)$ using the symmetry $c[r] = c[m-r]$.\n    -   **Circular Convolution by FFT**:\n        -   Zero-pad the input vector $x$ to length $m$.\n        -   Compute the DFTs of the kernel $c$ and the padded vector $x$ using `numpy.fft.fft`.\n        -   Multiply the DFTs element-wise.\n        -   Compute the inverse DFT of the product using `numpy.fft.ifft`. The result is the circular convolution.\n        -   Extract the first $n$ components of the resulting vector and take its real part (to discard negligible imaginary components arising from floating-point inaccuracies). This is the approximate product $y_{\\mathrm{FFT}}$.\n\n6.  **Compute Relative Error**: Calculate the relative error using the $\\ell_{\\infty}$-norm:\n    $$\n    \\text{error} = \\frac{\\|y_{\\mathrm{FFT}} - y_{\\mathrm{exact}}\\|_{\\infty}}{\\|y_{\\mathrm{exact}}\\|_{\\infty}}\n    $$\n    A check is made to handle the case where $\\|y_{\\mathrm{exact}}\\|_{\\infty}$ might be zero.\n\n7.  **Store and Report**: The computed error is stored. After all test cases are processed, the results are formatted into a single string as specified.\n\nThis systematic procedure is implemented in the Python code provided in the final answer.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import toeplitz\nfrom scipy.special import zeta\n\ndef solve():\n    \"\"\"\n    Computes the matrix-vector product y = T_n x for a symmetric Toeplitz\n    matrix T_n using a circulant embedding and FFT, and evaluates the\n    accuracy against a direct computation.\n    \"\"\"\n    # Define problem constants and test suite\n    TOL_EPS = 1e-8\n    TOL_TAU = 1e-12\n\n    test_cases = [\n        {'n': 64, 'model': 'exponential', 'params': {'C': 1.0, 'alpha': 0.5}},\n        {'n': 64, 'model': 'algebraic', 'params': {'C': 1.0, 'p': 2.2}},\n        {'n': 128, 'model': 'exponential', 'params': {'C': 1.0, 'alpha': 1.0}},\n        {'n': 128, 'model': 'algebraic', 'params': {'C': 1.0, 'p': 3.0}},\n    ]\n\n    results = []\n    # Use a seeded random number generator for reproducible results\n    rng = np.random.default_rng(12345)\n\n    for case in test_cases:\n        n = case['n']\n        model = case['model']\n        params = case['params']\n\n        # Define the tk generator function based on the model\n        if model == 'exponential':\n            C, alpha = params['C'], params['alpha']\n            t_k_func = lambda k: C * np.exp(-alpha * np.abs(k))\n        else: # algebraic\n            C, p = params['C'], params['p']\n            t_k_func = lambda k: C * (1 + np.abs(k))**(-p)\n\n        # 1. Determine the optimal embedding size m\n        # Smallest power of two >= 2n\n        m = 1 << (2 * n - 1).bit_length()\n        while True:\n            if model == 'exponential':\n                bound = 2 * C * np.exp(-alpha * m) / (1 - np.exp(-alpha * m))\n            else: # algebraic\n                bound = 2 * C * zeta(p) * (m**(-p))\n            \n            if bound <= TOL_EPS:\n                break\n            m *= 2\n            \n        # 2. Generate test vector x\n        x = rng.random(n)\n        \n        # 3. Compute the exact matrix-vector product\n        t_coeffs = t_k_func(np.arange(n))\n        T_n = toeplitz(t_coeffs)\n        y_exact = T_n @ x\n\n        # 4. Compute the approximate product using FFT\n        # 4.1 Construct the circulant kernel c\n        c = np.zeros(m)\n        \n        # Compute c[0] through c[m/2] by summing the periodic terms\n        for r in range(m // 2 + 1):\n            c[r] = t_k_func(r)\n            ell = 1\n            while True:\n                if r == 0:\n                    # For r=0, term is t(lm) + t(-lm) = 2*t(lm)\n                    term = 2 * t_k_func(ell * m)\n                else:\n                    # For r>0, term is t(lm+r) + t(lm-r)\n                    term = t_k_func(ell * m - r) + t_k_func(ell * m + r)\n                \n                if term < TOL_TAU:\n                    break\n                \n                c[r] += term\n                ell += 1\n        \n        # Exploit symmetry c[r] = c[m-r] for the other half of the kernel\n        for r in range(1, m // 2):\n            c[m - r] = c[r]\n\n        # 4.2 Perform circular convolution via FFT\n        x_pad = np.zeros(m)\n        x_pad[:n] = x\n        \n        y_pad = np.fft.ifft(np.fft.fft(c) * np.fft.fft(x_pad))\n        # Result should be real; take real part to discard numerical noise\n        y_fft = np.real(y_pad[:n])\n        \n        # 5. Calculate the relative l-infinity error\n        norm_y_exact = np.linalg.norm(y_exact, np.inf)\n        if norm_y_exact == 0:\n            error = 0.0\n        else:\n            error = np.linalg.norm(y_fft - y_exact, np.inf) / norm_y_exact\n            \n        results.append(error)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3545696"}, {"introduction": "Beyond iterative techniques, classical fast direct solvers like the Levinson-Durbin and Schur algorithms provide an alternative path to the solution. However, their numerical stability, especially for ill-conditioned systems, is a primary concern. This theoretical exercise [@problem_id:3545681] challenges you to uncover the mathematical origins of this potential instability. By analyzing a carefully chosen family of Toeplitz matrices, you will prove how reflection coefficients approaching unit magnitude are a direct consequence of the generating symbol's roots nearing the unit circle, leading to catastrophic error amplification in the recursion.", "problem": "Consider the Schur algorithm (also known as the Schur recursion) for solving Hermitian Toeplitz linear systems via reflection coefficients arising from the Levinson–Durbin recursion (Levinson–Durbin Algorithm (LDA)). Construct a family of Hermitian Toeplitz covariance matrices from a real AutoRegressive process of order two (AR(2)) whose associated polynomial has a repeated root approaching the unit circle, and use this to exhibit potential instability of the Schur algorithm. Specifically, let $n \\geq 3$ be fixed and define, for $0 < \\varepsilon < \\frac{1}{2}$, the AR(2) polynomial\n$$\nA_{\\varepsilon}(z) = 1 - 2(1 - \\varepsilon) z^{-1} + (1 - \\varepsilon)^{2} z^{-2} = \\left(1 - (1 - \\varepsilon) z^{-1}\\right)^{2}.\n$$\nAssume a stationary AR(2) process $x_t$ driven by a white-noise input with variance chosen so that the lag-zero autocorrelation $r_0$ equals $1$, and let $T_n(\\varepsilon)$ be the $n \\times n$ Hermitian Toeplitz matrix with entries $\\left[T_n(\\varepsilon)\\right]_{ij} = r_{|i-j|}$ built from the autocorrelation sequence of $x_t$. The Schur/LDA reflection coefficients $k_1(\\varepsilon), k_2(\\varepsilon), \\dots$ are defined by the standard Schur recursion on the normalized autocorrelation sequence.\n\nUsing only first principles (the AR(2) recursion for autocorrelations and the defining equations of the Schur/LDA reflection coefficient update), carry out the following:\n\n- Prove that the second reflection coefficient satisfies $\\left|k_2(\\varepsilon)\\right| = \\left(1 - \\varepsilon\\right)^{2}$.\n- Interpret this in terms of the proximity of the repeated root of $A_{\\varepsilon}(z)$ to the unit circle and explain why the Schur algorithm’s update involving the factor $1 - \\left|k_2(\\varepsilon)\\right|^{2}$ is potentially ill-conditioned as $\\varepsilon \\to 0^{+}$.\n- As a concrete instability witness, derive the closed-form expression for the amplification factor of rounding errors incurred at the second step of the Schur recursion,\n$$\nG(\\varepsilon) = \\frac{1}{1 - \\left|k_2(\\varepsilon)\\right|^{2}},\n$$\nas a function of $\\varepsilon$.\n\nYour final answer must be the exact analytic expression for $G(\\varepsilon)$ in terms of $\\varepsilon$. No rounding is required and no units are involved.", "solution": "The problem is validated as scientifically grounded, well-posed, and objective. It is rooted in the established theories of stationary time series analysis and numerical linear algebra, specifically concerning AutoRegressive (AR) processes and algorithms for solving Toeplitz systems. The problem statement is self-contained and free of contradictions or ambiguities. We may therefore proceed with a formal derivation.\n\nThe problem investigates the numerical stability of the Schur algorithm when applied to a family of Hermitian Toeplitz matrices derived from an AR(2) process whose characteristic polynomial has a repeated root approaching the unit circle. Our analysis will proceed from first principles as stipulated.\n\nFirst, we identify the coefficients of the AR(2) process. A general AR(p) process is defined by $x_t = \\sum_{i=1}^{p} a_i x_{t-i} + w_t$, where $w_t$ is a white-noise process. The associated polynomial is $A(z) = 1 - \\sum_{i=1}^{p} a_i z^{-i}$. The given AR(2) polynomial is\n$$\nA_{\\varepsilon}(z) = 1 - 2(1 - \\varepsilon) z^{-1} + (1 - \\varepsilon)^{2} z^{-2}\n$$\nBy comparing this to the general form, we identify the AR coefficients as:\n$$\na_1 = 2(1 - \\varepsilon)\n$$\n$$\na_2 = -(1 - \\varepsilon)^{2}\n$$\nThe condition $0 < \\varepsilon < \\frac{1}{2}$ ensures that the poles of the system's transfer function $H(z)=1/A_{\\varepsilon}(z)$, which are the roots of $z^2 A_{\\varepsilon}(z) = 0$, lie inside the unit circle, guaranteeing the stationarity of the process. The roots of $A_{\\varepsilon}(z)=0$ are given by $(1 - (1-\\varepsilon)z^{-1})^2 = 0$, which implies a repeated root at $z = 1 - \\varepsilon$. Since $|\\varepsilon| < 1$, $|z| = 1-\\varepsilon < 1$.\n\nNext, we determine the initial terms of the autocorrelation sequence $r_k = E[x_{t+k} x_t^*]$, where $E[\\cdot]$ denotes the expectation operator. For a stationary process with real coefficients, the autocorrelation sequence is real ($r_k = r_{-k}$) and satisfies the Yule-Walker equations. We are given the normalization $r_0 = 1$. The Yule-Walker equations for $k > 0$ are:\n$$\nr_k = \\sum_{i=1}^{2} a_i r_{k-i} = a_1 r_{k-1} + a_2 r_{k-2}\n$$\nFor $k=1$, using $r_{-1}=r_1$:\n$$\nr_1 = a_1 r_0 + a_2 r_{-1} = a_1 r_0 + a_2 r_1 \\implies r_1(1-a_2) = a_1 r_0\n$$\nSubstituting $r_0=1$ and the expressions for $a_1$ and $a_2$:\n$$\nr_1 \\left(1 - (-(1 - \\varepsilon)^2)\\right) = 2(1 - \\varepsilon)\n$$\n$$\nr_1 \\left(1 + (1 - 2\\varepsilon + \\varepsilon^2)\\right) = 2(1 - \\varepsilon)\n$$\n$$\nr_1 \\left(2 - 2\\varepsilon + \\varepsilon^2\\right) = 2(1 - \\varepsilon)\n$$\n$$\nr_1 = \\frac{2(1 - \\varepsilon)}{2 - 2\\varepsilon + \\varepsilon^2}\n$$\nFor $k=2$:\n$$\nr_2 = a_1 r_1 + a_2 r_0 = 2(1 - \\varepsilon) r_1 - (1 - \\varepsilon)^2\n$$\nSubstituting the derived expression for $r_1$:\n$$\nr_2 = 2(1 - \\varepsilon) \\left(\\frac{2(1 - \\varepsilon)}{2 - 2\\varepsilon + \\varepsilon^2}\\right) - (1 - \\varepsilon)^2 = \\frac{4(1 - \\varepsilon)^2}{2 - 2\\varepsilon + \\varepsilon^2} - (1 - \\varepsilon)^2\n$$\n$$\nr_2 = \\frac{4(1 - \\varepsilon)^2 - (1 - \\varepsilon)^2 (2 - 2\\varepsilon + \\varepsilon^2)}{2 - 2\\varepsilon + \\varepsilon^2} = \\frac{(1 - \\varepsilon)^2 \\left[4 - (2 - 2\\varepsilon + \\varepsilon^2)\\right]}{2 - 2\\varepsilon + \\varepsilon^2}\n$$\n$$\nr_2 = \\frac{(1 - \\varepsilon)^2 (2 + 2\\varepsilon - \\varepsilon^2)}{2 - 2\\varepsilon + \\varepsilon^2}\n$$\nNow we compute the reflection coefficients using the Levinson-Durbin recursion. A fundamental result of time series analysis, which follows from the Yule-Walker equations, is that for a true AR(p) process, the coefficients of the process itself, $a_1, \\dots, a_p$, are identical to the coefficients of the optimal order-$p$ linear predictor, $a_1^{(p)}, \\dots, a_p^{(p)}$. The Levinson-Durbin algorithm, in turn, defines the $m$-th reflection coefficient as $k_m = a_m^{(m)}$.\n\nCombining these first principles for our AR(2) case ($p=2$), the second reflection coefficient $k_2$ must be equal to the second AR coefficient $a_2$:\n$$\nk_2(\\varepsilon) = a_2^{(2)} = a_2 = -(1 - \\varepsilon)^2\n$$\nTherefore, the magnitude of the second reflection coefficient is\n$$\n|k_2(\\varepsilon)| = |-(1 - \\varepsilon)^2| = (1 - \\varepsilon)^2\n$$\nThis proves the first required result.\n\nNow for the interpretation. The roots of the AR polynomial $A_{\\varepsilon}(z) = \\left(1 - (1 - \\varepsilon) z^{-1}\\right)^{2}$ are at $z = 1-\\varepsilon$. As $\\varepsilon \\to 0^+$, this repeated real root approaches $z=1$, which lies on the unit circle. For a stationary AR process, all reflection coefficients $k_m$ must satisfy $|k_m| < 1$. The case $|k_m|=1$ for some $m$ corresponds to a predictable process, which is associated with roots of the AR polynomial lying on the unit circle. Our result shows that as the root approaches the unit circle ($\\varepsilon \\to 0^+$), the magnitude of the second reflection coefficient approaches unity:\n$$\n\\lim_{\\varepsilon \\to 0^+} |k_2(\\varepsilon)| = \\lim_{\\varepsilon \\to 0^+} (1 - \\varepsilon)^2 = 1\n$$\nThe Schur algorithm, and other fast algorithms for Toeplitz systems, computes a sequence of quantities based on the reflection coefficients. A critical step in these recursions involves a multiplicative factor of the form $(1 - |k_m|^2)$ or a divisive factor of $(1 - |k_m|^2)^{-1}$ or $(1 - |k_m|^2)^{-1/2}$. For $m=2$, this factor is $1 - |k_2(\\varepsilon)|^2$. As $\\varepsilon \\to 0^+$, this factor approaches $1 - 1^2 = 0$. Division by a quantity approaching zero amplifies any rounding errors present in the numerator, leading to catastrophic loss of precision. This is the source of the potential ill-conditioning. The matrix $T_n(\\varepsilon)$ becomes progressively more ill-conditioned as $\\varepsilon \\to 0^+$. The fact that $|k_2(\\varepsilon)| \\to 1$ is a direct indicator of this developing ill-conditioning.\n\nFinally, we derive the closed-form expression for the error amplification factor $G(\\varepsilon)$.\n$$\nG(\\varepsilon) = \\frac{1}{1 - \\left|k_2(\\varepsilon)\\right|^{2}}\n$$\nUsing our result $|k_2(\\varepsilon)| = (1 - \\varepsilon)^2$:\n$$\nG(\\varepsilon) = \\frac{1}{1 - \\left((1 - \\varepsilon)^2\\right)^2} = \\frac{1}{1 - (1 - \\varepsilon)^4}\n$$\nTo obtain a more insightful form, we factor the denominator using the difference of squares identity, $a^2 - b^2 = (a-b)(a+b)$:\n$$\n1 - (1 - \\varepsilon)^4 = \\left(1 - (1 - \\varepsilon)^2\\right) \\left(1 + (1 - \\varepsilon)^2\\right)\n$$\nWe expand each factor:\n$$\n1 - (1 - \\varepsilon)^2 = 1 - (1 - 2\\varepsilon + \\varepsilon^2) = 2\\varepsilon - \\varepsilon^2 = \\varepsilon(2 - \\varepsilon)\n$$\n$$\n1 + (1 - \\varepsilon)^2 = 1 + (1 - 2\\varepsilon + \\varepsilon^2) = 2 - 2\\varepsilon + \\varepsilon^2\n$$\nCombining these factors, we obtain the denominator:\n$$\n1 - (1 - \\varepsilon)^4 = \\varepsilon(2 - \\varepsilon)(2 - 2\\varepsilon + \\varepsilon^2)\n$$\nTherefore, the amplification factor $G(\\varepsilon)$ is:\n$$\nG(\\varepsilon) = \\frac{1}{\\varepsilon(2 - \\varepsilon)(2 - 2\\varepsilon + \\varepsilon^2)}\n$$\nAs $\\varepsilon \\to 0^+$, the terms $(2-\\varepsilon)$ and $(2-2\\varepsilon+\\varepsilon^2)$ approach $2$, so $G(\\varepsilon) \\approx \\frac{1}{4\\varepsilon}$. This explicitly shows that the amplification factor diverges as the root approaches the unit circle, confirming the instability.", "answer": "$$\n\\boxed{\\frac{1}{\\varepsilon(2 - \\varepsilon)(2 - 2\\varepsilon + \\varepsilon^{2})}}\n$$", "id": "3545681"}, {"introduction": "Building directly upon the previous theoretical insights, this computational experiment [@problem_id:3545692] allows you to witness the consequences of algorithmic instability firsthand. You will construct a series of increasingly ill-conditioned Toeplitz matrices and compare the performance of the non-pivoted Levinson-Durbin algorithm against a robust, pivoted baseline. By measuring both solution error and residual norm, this practice provides a powerful demonstration of why naive fast algorithms can fail and underscores the importance of pivoting for achieving accurate solutions in challenging cases.", "problem": "Construct a family of Hermitian Toeplitz linear systems from a symbol with zeros on the unit circle and design a parameterized experiment to compare numerical stability and accuracy between the Levinson–Durbin recursion and the Gohberg–Kailath–Olshevsky (GKO) paradigm as the zero approaches $\\{e^{\\pm i\\theta_0}\\}$. Begin from the following foundational base.\n\nA Toeplitz matrix $T_n(f)$ of size $n\\times n$ is generated by a $2\\pi$-periodic symbol $f(\\theta)$ via its Fourier coefficients. For a function $f(\\theta)$, the Fourier coefficients are $c_k = \\frac{1}{2\\pi}\\int_0^{2\\pi} f(\\theta)e^{-ik\\theta}\\,d\\theta$ for integers $k$, and the Toeplitz matrix is defined by $[T_n(f)]_{ij} = c_{i-j}$ for $i,j \\in \\{1,2,\\dots,n\\}$ with the convention $c_{-k} = \\overline{c_k}$ to ensure Hermitian structure.\n\nConsider the family of symbols\n$$\nf_{\\delta,\\theta_0}(\\theta) = \\delta + 2 - 2\\cos(\\theta - \\theta_0),\n$$\nwhere $\\delta > 0$ is a small parameter and $\\theta_0 \\in (0,\\pi)$ is fixed. The function $f_{\\delta,\\theta_0}(\\theta)$ is nonnegative for all $\\theta$ and has a zero at $\\theta = \\theta_0$ when $\\delta = 0$, hence the associated Toeplitz matrices become increasingly ill-conditioned as $\\delta \\to 0^+$. Derive the Fourier coefficients of $f_{\\delta,\\theta_0}(\\theta)$ and use them to construct a Hermitian Toeplitz matrix $T_n(f_{\\delta,\\theta_0})$ with first column $c$ and first row $r$. Choose a deterministic nonzero target solution vector $x_{\\text{true}} \\in \\mathbb{C}^n$, form the right-hand side $b = T_n(f_{\\delta,\\theta_0}) x_{\\text{true}}$, and solve the system $T_n(f_{\\delta,\\theta_0}) x = b$ by two methods:\n- Levinson–Durbin recursion specialized for Hermitian Toeplitz matrices.\n- A Gohberg–Kailath–Olshevsky (GKO)-style pivoted approach. For this experiment, you must emulate the pivoting and robustness of GKO by applying classical Gaussian elimination with partial pivoting to the dense Toeplitz matrix, accepting the loss of fast complexity but focusing on stability and accuracy as the zero approaches the unit circle.\n\nFor each solution $\\hat{x}$ computed by a method, evaluate the following quantifiable metrics:\n1. The relative solution error $E = \\frac{\\| \\hat{x} - x_{\\text{true}} \\|_2}{\\| x_{\\text{true}} \\|_2}$.\n2. The relative residual norm $R = \\frac{\\| b - T_n(f_{\\delta,\\theta_0}) \\hat{x} \\|_2}{\\| b \\|_2}$.\n3. The $2$-norm condition number $\\kappa_2(T_n(f_{\\delta,\\theta_0})) = \\|T_n(f_{\\delta,\\theta_0})\\|_2 \\cdot \\|T_n(f_{\\delta,\\theta_0})^{-1}\\|_2$.\n\nDesign and run a parameterized experiment with the following test suite of $(n,\\theta_0,\\delta)$ values to probe stability and accuracy over a range of conditioning levels and angles:\n- Test case $1$: $(n,\\theta_0,\\delta) = (32,\\frac{\\pi}{4},10^{-2})$.\n- Test case $2$: $(n,\\theta_0,\\delta) = (64,\\frac{\\pi}{3},10^{-6})$.\n- Test case $3$: $(n,\\theta_0,\\delta) = (64,0.01,10^{-8})$.\n- Test case $4$: $(n,\\theta_0,\\delta) = (16,\\pi - 0.01,10^{-9})$.\n- Test case $5$: $(n,\\theta_0,\\delta) = (8,\\frac{\\pi}{6},10^{-12})$.\n\nFor reproducibility, select a deterministic nonzero $x_{\\text{true}}$ defined by\n$$\nx_{\\text{true}}[j] = \\sin\\left(\\frac{2\\pi j}{n}\\right) + \\frac{1}{2}\\cos\\left(\\frac{4\\pi j}{n}\\right), \\quad j=0,1,\\dots,n-1,\n$$\nand treat it as a real vector embedded in $\\mathbb{C}^n$.\n\nYour program must:\n- Construct $T_n(f_{\\delta,\\theta_0})$ exactly from the derived Fourier coefficients for each test case.\n- Compute $b$ from $x_{\\text{true}}$.\n- Solve the system by Levinson–Durbin recursion and by pivoted Gaussian elimination (as a GKO-style stability proxy).\n- Compute the three metrics $(E,R,\\kappa_2)$ for each method and matrix.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each test case, output five floating-point numbers in the order:\n$$\n\\left[E_{\\text{LD}},E_{\\text{GKO}},R_{\\text{LD}},R_{\\text{GKO}},\\kappa_2\\right],\n$$\nand concatenate these groups across the five test cases into a single flat list. For example, the final output format must be\n$$\n\\left[ E_{\\text{LD}}^{(1)}, E_{\\text{GKO}}^{(1)}, R_{\\text{LD}}^{(1)}, R_{\\text{GKO}}^{(1)}, \\kappa_2^{(1)}, \\dots, E_{\\text{LD}}^{(5)}, E_{\\text{GKO}}^{(5)}, R_{\\text{LD}}^{(5)}, R_{\\text{GKO}}^{(5)}, \\kappa_2^{(5)} \\right].\n$$\nNo physical units are involved, and all angles are in radians. The output must be exactly one line with the list format described and values represented as decimal floating-point numbers.", "solution": "The user-provided problem is valid. It is scientifically grounded in numerical linear algebra, specifically concerning structured linear systems. The setup is well-posed: for $\\delta > 0$, the symbol $f_{\\delta,\\theta_0}(\\theta)$ is strictly positive, guaranteeing that the Hermitian Toeplitz matrix $T_n(f)$ is positive definite and thus invertible. All definitions, parameters, and experimental goals are specified precisely and objectively, forming a complete and non-contradictory problem statement.\n\n### Step 1: Derivation of Fourier Coefficients and Matrix Structure\n\nThe problem requires constructing a family of Hermitian Toeplitz matrices $T_n(f_{\\delta,\\theta_0})$ from the symbol $f_{\\delta,\\theta_0}(\\theta) = \\delta + 2 - 2\\cos(\\theta - \\theta_0)$. The elements of the Toeplitz matrix, $[T_n(f)]_{ij} = c_{i-j}$, are the Fourier coefficients of the symbol $f$. The $k$-th Fourier coefficient $c_k$ is defined as:\n$$\nc_k = \\frac{1}{2\\pi}\\int_0^{2\\pi} f_{\\delta,\\theta_0}(\\theta)e^{-ik\\theta}\\,d\\theta\n$$\nWe substitute the expression for $f_{\\delta,\\theta_0}(\\theta)$:\n$$\nc_k = \\frac{1}{2\\pi}\\int_0^{2\\pi} (\\delta + 2 - 2\\cos(\\theta - \\theta_0))e^{-ik\\theta}\\,d\\theta\n$$\nWe can separate the integral into two parts:\n1.  The constant term: $\\frac{1}{2\\pi}\\int_0^{2\\pi} (\\delta + 2)e^{-ik\\theta}\\,d\\theta$. This integral evaluates to $\\delta + 2$ for $k=0$ and $0$ for $k \\ne 0$.\n2.  The cosine term: We use Euler's formula, $\\cos(x) = \\frac{e^{ix} + e^{-ix}}{2}$, to write $-2\\cos(\\theta - \\theta_0) = -e^{i(\\theta - \\theta_0)} - e^{-i(\\theta - \\theta_0)} = -e^{-i\\theta_0}e^{i\\theta} - e^{i\\theta_0}e^{-i\\theta}$.\n    The integral becomes:\n    $$\n    -\\frac{1}{2\\pi}\\int_0^{2\\pi} (e^{-i\\theta_0}e^{i\\theta} + e^{i\\theta_0}e^{-i\\theta})e^{-ik\\theta}\\,d\\theta = -\\frac{e^{-i\\theta_0}}{2\\pi}\\int_0^{2\\pi} e^{i(1-k)\\theta}\\,d\\theta - \\frac{e^{i\\theta_0}}{2\\pi}\\int_0^{2\\pi} e^{-i(1+k)\\theta}\\,d\\theta\n    $$\n    The first integral is non-zero only for $1-k=0$, i.e., $k=1$, where it evaluates to $-e^{-i\\theta_0}$. The second integral is non-zero only for $1+k=0$, i.e., $k=-1$, where it evaluates to $-e^{i\\theta_0}$.\n\nCombining these results, the Fourier coefficients are:\n-   For $k=0$: $c_0 = \\delta + 2$.\n-   For $k=1$: $c_1 = -e^{-i\\theta_0}$.\n-   For $k=-1$: $c_{-1} = -e^{i\\theta_0}$.\n-   For $|k| \\ge 2$: $c_k = 0$.\n\nThe Hermitian property $c_{-k} = \\overline{c_k}$ is satisfied, as $c_{-1} = -e^{i\\theta_0} = -(\\cos\\theta_0 + i\\sin\\theta_0)$ and $\\overline{c_1} = \\overline{-e^{-i\\theta_0}} = -\\overline{\\cos(-\\theta_0) + i\\sin(-\\theta_0)} = -(\\cos\\theta_0 - i\\sin\\theta_0)$, which is not equal to $c_{-1}$. There is a sign error in this reasoning. Correctly, $\\overline{c_1} = \\overline{-e^{-i\\theta_0}} = -e^{i\\theta_0} = c_{-1}$. The property holds. Because coefficients $c_k$ are zero for $|k| \\ge 2$, the resulting $n \\times n$ matrix $T_n(f_{\\delta,\\theta_0})$ is a Hermitian tridiagonal Toeplitz matrix:\n$$\nT_n = \\begin{pmatrix}\nc_0 & c_{-1} & 0 & \\dots & 0 \\\\\nc_1 & c_0 & c_{-1} & \\dots & 0 \\\\\n0 & c_1 & c_0 & \\ddots & \\vdots \\\\\n\\vdots & & \\ddots & \\ddots & c_{-1} \\\\\n0 & \\dots & 0 & c_1 & c_0\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\delta+2 & \\overline{c_1} & 0 & \\dots & 0 \\\\\nc_1 & \\delta+2 & \\overline{c_1} & \\dots & 0 \\\\\n0 & c_1 & \\delta+2 & \\ddots & \\vdots \\\\\n\\vdots & & \\ddots & \\ddots & \\overline{c_1} \\\\\n0 & \\dots & 0 & c_1 & \\delta+2\n\\end{pmatrix}\n$$\nwhere $c_1 = -e^{-i\\theta_0}$.\n\n### Step 2: Algorithmic Design and Experiment Setup\n\nThe experiment compares two algorithms for solving the linear system $T_n x = b$. The vector $x_{\\text{true}}$ is defined, and the right-hand side $b$ is computed as $b = T_n x_{\\text{true}}$ to establish a ground truth for accuracy analysis.\n\n1.  **Levinson–Durbin Recursion**: This is a fast algorithm, with complexity $O(n^2)$, for solving linear systems with a Toeplitz matrix structure. For a Hermitian Toeplitz matrix defined by its first column $c = [c_0, c_1, \\dots, c_{n-1}]^T$, the algorithm iteratively builds up the solution. It is known to be numerically stable for positive-definite matrices. However, as $\\delta \\to 0$, $T_n$ becomes ill-conditioned, and the algorithm's accuracy may degrade due to the propagation of rounding errors without a pivoting mechanism. A standard implementation, such as `scipy.linalg.solve_toeplitz`, will be used.\n\n2.  **GKO-Style Pivoted Approach (Proxy)**: The Gohberg–Kailath–Olshevsky (GKO) algorithm is a fast $O(n^2)$ solver for structured matrices that can incorporate pivoting for numerical stability. Pivoting disrupts the matrix structure, making the algorithm significantly more complex. As a proxy for a stable, pivoted fast solver, the problem specifies using classical Gaussian Elimination with Partial Pivoting (GEPP) on the dense matrix. While this has a higher complexity of $O(n^3)$, it serves as a baseline for numerical stability against which the non-pivoted Levinson-Durbin method can be compared. GEPP is the standard robust algorithm for general dense linear systems and is implemented in routines like `numpy.linalg.solve`.\n\n### Step 3: Evaluation Metrics\n\nThe performance of each method is quantified by three metrics:\n\n1.  **Relative Solution Error ($E$)**: Measures how close the computed solution $\\hat{x}$ is to the known true solution $x_{\\text{true}}$.\n    $$\n    E = \\frac{\\| \\hat{x} - x_{\\text{true}} \\|_2}{\\| x_{\\text{true}} \\|_2}\n    $$\n2.  **Relative Residual Norm ($R$)**: Measures how well the computed solution satisfies the original equation. A small residual indicates that $\\hat{x}$ is the exact solution to a nearby problem $T_n x = b + \\Delta b$.\n    $$\n    R = \\frac{\\| b - T_n \\hat{x} \\|_2}{\\| b \\|_2}\n    $$\n3.  **2-Norm Condition Number ($\\kappa_2$)**: An intrinsic property of the matrix $T_n$ that bounds the amplification of errors in the input data (both $T_n$ and $b$) to the output solution $x$. A large condition number indicates an ill-conditioned problem, where small input perturbations can lead to large changes in the solution.\n    $$\n    \\kappa_2(T_n) = \\|T_n\\|_2 \\cdot \\|T_n^{-1}\\|_2\n    $$\n    For a given method, we expect a relationship approximately like $E \\lesssim \\kappa_2(T_n) (R + \\epsilon_{\\text{mach}})$, where $\\epsilon_{\\text{mach}}$ is machine precision.\n\nThe experiment systematically varies the parameters $(n, \\theta_0, \\delta)$ to observe how matrix size, position of the symbol's near-zero, and the proximity to singularity affect stability and accuracy. As $\\delta$ approaches $0$, $\\kappa_2(T_n)$ is expected to grow large, challenging the numerical stability of the solvers. The expectation is that the GEPP proxy, due to its pivoting strategy, will maintain better accuracy (smaller $E$) than the non-pivoted Levinson-Durbin recursion in severely ill-conditioned cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import toeplitz, solve_toeplitz\n\ndef solve():\n    \"\"\"\n    Designs and runs a parameterized experiment to compare the numerical stability\n    of Levinson-Durbin recursion and a GKO-style pivoted approach (proxied by GEPP)\n    for solving ill-conditioned Hermitian Toeplitz linear systems.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (32, np.pi/4, 1e-2),\n        (64, np.pi/3, 1e-6),\n        (64, 0.01, 1e-8),\n        (16, np.pi - 0.01, 1e-9),\n        (8, np.pi/6, 1e-12),\n    ]\n\n    results = []\n    for n, theta0, delta in test_cases:\n        # Step 1: Construct the Hermitian Toeplitz matrix T_n\n        \n        # Derive the Fourier coefficients c_k from the symbol.\n        # c_0 = delta + 2\n        # c_1 = -exp(-i*theta0)\n        # c_k = 0 for |k| >= 2\n        c0 = delta + 2.0\n        c1 = -np.exp(-1j * theta0)\n        \n        # The first column of the Toeplitz matrix\n        c_col = np.zeros(n, dtype=np.complex128)\n        c_col[0] = c0\n        if n > 1:\n            c_col[1] = c1\n\n        # The first row of the Hermitian Toeplitz matrix.\n        # r_k = c_{-k} = conjugate(c_k)\n        r_row = np.conjugate(c_col)\n\n        # Construct the dense matrix T_n.\n        # This is a tridiagonal Hermitian Toeplitz matrix.\n        T = toeplitz(c_col, r_row)\n\n        # Step 2: Define the true solution x_true and compute the RHS b\n        j = np.arange(n)\n        x_true = np.sin(2 * np.pi * j / n) + 0.5 * np.cos(4 * np.pi * j / n)\n        x_true = x_true.astype(np.complex128) # Treat as complex vector\n        \n        b = T @ x_true\n        \n        # Step 3: Solve the system T*x = b using both methods.\n        \n        # Method 1: Levinson-Durbin recursion\n        # scipy.linalg.solve_toeplitz uses Levinson-Durbin for Hermitian matrices.\n        # It takes the first column `c_col` as input.\n        x_ld = solve_toeplitz(c_col, b)\n        \n        # Method 2: GKO-style proxy (Gaussian Elimination with Partial Pivoting)\n        # numpy.linalg.solve uses LAPACK's gesv, which implements GEPP.\n        x_gko = np.linalg.solve(T, b)\n\n        # Step 4: Compute the evaluation metrics\n        \n        # Norms for relative error and residual calculations\n        norm_xtrue = np.linalg.norm(x_true, 2)\n        norm_b = np.linalg.norm(b, 2)\n\n        # Relative solution error E\n        E_ld = np.linalg.norm(x_ld - x_true, 2) / norm_xtrue\n        E_gko = np.linalg.norm(x_gko - x_true, 2) / norm_xtrue\n\n        # Relative residual norm R\n        R_ld = np.linalg.norm(b - T @ x_ld, 2) / norm_b\n        R_gko = np.linalg.norm(b - T @ x_gko, 2) / norm_b\n\n        # 2-norm condition number kappa_2\n        kappa2 = np.linalg.cond(T, p=2)\n\n        results.extend([E_ld, E_gko, R_ld, R_gko, kappa2])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{v:.15e}' for v in results)}]\")\n\nsolve()\n```", "id": "3545692"}]}