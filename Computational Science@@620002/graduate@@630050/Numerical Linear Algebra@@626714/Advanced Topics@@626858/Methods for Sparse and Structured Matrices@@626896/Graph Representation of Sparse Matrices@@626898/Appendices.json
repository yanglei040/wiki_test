{"hands_on_practices": [{"introduction": "Many sparse matrix algorithms, particularly direct solvers, have computational costs that depend heavily on the matrix's profile or bandwidth. This practice demonstrates that reordering the rows and columns of a matrix—which corresponds to relabeling the vertices of its associated graph—can dramatically alter these structural properties. By working through a concrete example involving a star graph, you will gain a hands-on understanding of how strategic reordering can significantly reduce the matrix profile, providing a tangible link between an algebraic measure and its intuitive graph-theoretic counterpart [@problem_id:3549161].", "problem": "Let $A \\in \\mathbb{R}^{7 \\times 7}$ be a symmetric sparse matrix whose sparsity pattern corresponds to a star graph on $7$ vertices: vertex $1$ is connected to each of vertices $2,3,4,5,6,7$, and there are no other off-diagonal connections. Concretely, suppose $a_{11},\\ldots,a_{77}$ are nonzero (diagonal structure), and $a_{1k} = a_{k1} \\neq 0$ for $k \\in \\{2,3,4,5,6,7\\}$, with all other off-diagonal entries zero. Consider the identity ordering (rows and columns labeled $1,2,\\ldots,7$) and the permutation $\\pi$ given by $\\pi(1) = 7$ and $\\pi(k) = k - 1$ for $k \\in \\{2,3,4,5,6,7\\}$, which induces the permutation matrix $P \\in \\mathbb{R}^{7 \\times 7}$ and the symmetrically permuted matrix $B = P A P^{\\top}$. Define the profile of a matrix $M$ in an ordering by\n$$\n\\operatorname{prof}(M) \\;=\\; \\sum_{i=1}^{n} \\max\\{\\, i - j \\;:\\; m_{ij} \\neq 0 \\,\\}.\n$$\nStarting only from core definitions of the graph representation of the sparsity pattern and the above profile, compute the reduction\n$$\n\\Delta \\;=\\; \\operatorname{prof}(A) \\;-\\; \\operatorname{prof}(B).\n$$\nAdditionally, justify in words the corresponding effect on edge lengths in a linear embedding of the graph under the two orderings, where each vertex $i$ is embedded at location $i \\in \\mathbb{R}$ and each edge $(i,j)$ has length $|i - j|$. Your final answer must be the single real-valued number $\\Delta$. No rounding is required.", "solution": "The problem asks for the computation of the reduction in the profile of a specific sparse matrix $A$ after a symmetric permutation. The profile of an $n \\times n$ matrix $M$ is given by\n$$\n\\operatorname{prof}(M) = \\sum_{i=1}^{n} \\max\\{ i - j : m_{ij} \\neq 0 \\}\n$$\nFor a given row $i$, the term $\\max\\{ i - j : m_{ij} \\neq 0 \\}$ is equivalent to $i - \\min\\{j : m_{ij} \\neq 0\\}$. This term represents the distance from the diagonal to the first non-zero element in that row, often called the row-wise lower bandwidth.\n\n**1. Calculation of $\\operatorname{prof}(A)$**\n\nThe matrix $A \\in \\mathbb{R}^{7 \\times 7}$ is symmetric. Its non-zero entries are $a_{ii} \\neq 0$ for $i \\in \\{1, \\ldots, 7\\}$ and $a_{1k}=a_{k1} \\neq 0$ for $k \\in \\{2, \\ldots, 7\\}$. We compute the contribution to the profile for each row $i$:\n\n-   For $i=1$: The non-zero entries are in column $j=1$. The set of column indices is $\\{1\\}$.\n    $\\max\\{1-j : a_{1j} \\neq 0\\} = \\max\\{1-1\\} = 0$.\n-   For $i=2$: The non-zero entries are $a_{21}$ and $a_{22}$. The set of column indices is $\\{1, 2\\}$.\n    $\\max\\{2-j : a_{2j} \\neq 0\\} = \\max\\{2-1, 2-2\\} = 1$.\n-   For $i=3$: The non-zero entries are $a_{31}$ and $a_{33}$. The set of column indices is $\\{1, 3\\}$.\n    $\\max\\{3-j : a_{3j} \\neq 0\\} = \\max\\{3-1, 3-3\\} = 2$.\n-   For $i=4$: The non-zero entries are $a_{41}$ and $a_{44}$. The set of column indices is $\\{1, 4\\}$.\n    $\\max\\{4-j : a_{4j} \\neq 0\\} = \\max\\{4-1, 4-4\\} = 3$.\n-   For $i=5$: The non-zero entries are $a_{51}$ and $a_{55}$. The set of column indices is $\\{1, 5\\}$.\n    $\\max\\{5-j : a_{5j} \\neq 0\\} = \\max\\{5-1, 5-5\\} = 4$.\n-   For $i=6$: The non-zero entries are $a_{61}$ and $a_{66}$. The set of column indices is $\\{1, 6\\}$.\n    $\\max\\{6-j : a_{6j} \\neq 0\\} = \\max\\{6-1, 6-6\\} = 5$.\n-   For $i=7$: The non-zero entries are $a_{71}$ and $a_{77}$. The set of column indices is $\\{1, 7\\}$.\n    $\\max\\{7-j : a_{7j} \\neq 0\\} = \\max\\{7-1, 7-7\\} = 6$.\n\nThe total profile of $A$ is the sum of these values:\n$$\n\\operatorname{prof}(A) = 0 + 1 + 2 + 3 + 4 + 5 + 6 = 21\n$$\n\n**2. Calculation of $\\operatorname{prof}(B)$**\n\nThe matrix $B$ is obtained by a symmetric permutation $B = P A P^{\\top}$. An entry $b_{ij}$ is non-zero if and only if the entry $a_{\\pi^{-1}(i), \\pi^{-1}(j)}$ is non-zero. The permutation $\\pi$ is given by $\\pi(1) = 7$ and $\\pi(k) = k-1$ for $k \\in \\{2, \\ldots, 7\\}$. This corresponds to re-labeling the graph vertices. The original vertex $1$ becomes vertex $7$, original vertex $2$ becomes vertex $1$, original vertex $3$ becomes vertex $2$, and so on.\n\nThe edges in the graph for $A$ are $(1,k)$ for $k \\in \\{2, \\ldots, 7\\}$. The edges in the graph for $B$ are $(\\pi(1), \\pi(k))$ for $k \\in \\{2, \\ldots, 7\\}$.\n- $\\pi(1)=7$\n- $\\pi(2)=1$, edge is $(7,1)$\n- $\\pi(3)=2$, edge is $(7,2)$\n...\n- $\\pi(7)=6$, edge is $(7,6)$\n\nSo, the non-zero off-diagonal entries of $B$ are $b_{i,7} = b_{7,i} \\neq 0$ for $i \\in \\{1, \\ldots, 6\\}$. The diagonal entries $b_{ii}$ are also non-zero.\n\nWe now compute the contribution to the profile for each row $i$ of matrix $B$:\n-   For $i \\in \\{1, 2, 3, 4, 5, 6\\}$: The non-zero entries in row $i$ are $b_{ii}$ and $b_{i,7}$. The column indices are $\\{i, 7\\}$.\n    $\\max\\{i-j : b_{ij} \\neq 0\\} = \\max\\{i-i, i-7\\}$. Since $i  7$, $i-7$ is negative. Thus, the maximum is $0$.\n-   For $i=7$: The non-zero entries are $b_{7j}$ for $j \\in \\{1, 2, 3, 4, 5, 6, 7\\}$. The set of column indices is $\\{1, 2, 3, 4, 5, 6, 7\\}$.\n    $\\max\\{7-j : b_{7j} \\neq 0\\} = \\max\\{7-1, 7-2, \\ldots, 7-7\\} = \\max\\{6, 5, 4, 3, 2, 1, 0\\} = 6$.\n\nThe total profile of $B$ is the sum of these values:\n$$\n\\operatorname{prof}(B) = \\underbrace{0+0+0+0+0+0}_{\\text{rows } 1 \\text{ to } 6} + 6 = 6\n$$\n\n**3. Calculation of the Reduction $\\Delta$**\n\nThe reduction in profile is:\n$$\n\\Delta = \\operatorname{prof}(A) - \\operatorname{prof}(B) = 21 - 6 = 15\n$$\n\n**4. Justification in Terms of Linear Embedding**\n\nThe profile of a symmetric matrix can be interpreted in the context of a linear embedding of its associated graph, where vertex $i$ is placed at position $i$ on the real line. The term for row $i$, $\\max\\{i - j : a_{ij} \\neq 0\\}$, corresponds to the length of the longest edge connecting vertex $i$ to a neighbor $j$ with a smaller position index ($j  i$).\n\nIn the initial identity ordering for matrix $A$, the vertices are arranged $(1, 2, 3, 4, 5, 6, 7)$. The central vertex $1$ is at the beginning. For any leaf vertex $k \\in \\{2, \\ldots, 7\\}$, its only neighbor is vertex $1$. Since $1  k$, this connection contributes to the profile. The contribution for vertex $k$ is $k-1$. The total profile, $\\operatorname{prof}(A)=21$, is the sum of these \"backward-pointing\" edge lengths from each leaf to the center.\n\nThe permutation $\\pi$ rearranges the vertices to place the central hub (original vertex $1$) at the end of the ordering, at position $7$. The leaf vertices (original vertices $2, \\ldots, 7$) now occupy positions $1, \\ldots, 6$.\n\nIn this new ordering for matrix $B$, consider any leaf vertex $k \\in \\{1, \\ldots, 6\\}$. Its only neighbor is the central hub, now at position $7$. Since $k  7$, there is no neighbor $j$ with an index smaller than $k$. Thus, the contribution to the profile from each of the first $6$ vertices is $0$. Only the central vertex, now at position $7$, has neighbors at smaller-indexed positions ($1, 2, 3, 4, 5, 6$). Its \"most backward\" neighbor is vertex $1$, giving a contribution of $7-1=6$. The total profile is $\\operatorname{prof}(B)=6$.\n\nThe reduction $\\Delta = 15$ quantifies the benefit of this reordering. By moving the high-degree vertex to the end of the ordering, we have minimized the sum of backward-pointing edge lengths, which directly corresponds to reducing the matrix profile. This is a fundamental strategy in minimizing fill-in and work in sparse matrix factorization algorithms.", "answer": "$$\\boxed{15}$$", "id": "3549161"}, {"introduction": "The nonzero pattern of a non-symmetric matrix $A$ corresponds to a directed graph, but many applications require working with the symmetric positive semidefinite matrix $A^{\\top}A$. This exercise explores the structural transformation that occurs when forming this normal equations matrix, revealing a new, undirected graph whose connections are not immediately apparent in the original directed graph. You will compute the structure of $A^{\\top}A$ and interpret the new adjacencies in graph-theoretic terms as paths of length two, a concept fundamental to network analysis and the behavior of iterative solvers [@problem_id:3549136].", "problem": "Consider the sparse matrix $A \\in \\mathbb{R}^{4 \\times 4}$ given by\n$$\nA \\;=\\;\n\\begin{pmatrix}\n0  1  1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  1 \\\\\n1  0  0  0\n\\end{pmatrix}.\n$$\nTreat the nonzero pattern of $A$ as the adjacency structure of a directed graph on $4$ vertices, where $a_{ij} \\neq 0$ represents a directed edge from vertex $i$ to vertex $j$. Note that there are pairs $(i,j)$ with $a_{ij} \\neq 0$ but $a_{ji} = 0$, so the directed graph is not symmetric. Form the normal-equations matrix $M = A^{\\top} A$, which is symmetric positive semidefinite, and consider the Jacobi fixed-point iteration for the linear system $M x = A^{\\top} b$, where $D = \\operatorname{diag}(M)$ denotes the diagonal of $M$. The Jacobi iteration matrix is defined by\n$$\nB \\;=\\; I - D^{-1} M.\n$$\nStarting from first principles and definitions, carry out the following:\n- Compute $M = A^{\\top} A$ explicitly and identify $D$.\n- Compute $B$ explicitly and justify, from the nonzero pattern of $B$, how an undirected adjacency is induced between a pair of vertices that were not directly adjacent (in either direction) in the original directed graph represented by $A$. Provide a clear graph-theoretic interpretation based on shared in-neighbors or co-citations.\n- Compute the spectral radius $\\rho(B)$ of the iteration matrix $B$.\n\nGive your final answer as the single real number $\\rho(B)$. No rounding is required.", "solution": "### Step 1: Compute $M = A^{\\top}A$ and $D = \\operatorname{diag}(M)$\n\nGiven the matrix $A$:\n$$\nA = \\begin{pmatrix}\n0  1  1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  1 \\\\\n1  0  0  0\n\\end{pmatrix}\n$$\nIts transpose, $A^{\\top}$, is:\n$$\nA^{\\top} = \\begin{pmatrix}\n0  0  0  1 \\\\\n1  0  0  0 \\\\\n1  0  0  0 \\\\\n0  1  1  0\n\\end{pmatrix}\n$$\nThe normal equations matrix $M$ is the product $A^{\\top}A$:\n$$\nM = A^{\\top}A = \\begin{pmatrix}\n0  0  0  1 \\\\\n1  0  0  0 \\\\\n1  0  0  0 \\\\\n0  1  1  0\n\\end{pmatrix}\n\\begin{pmatrix}\n0  1  1  0 \\\\\n0  0  0  1 \\\\\n0  0  0  1 \\\\\n1  0  0  0\n\\end{pmatrix} =\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  1  0 \\\\\n0  1  1  0 \\\\\n0  0  0  2\n\\end{pmatrix}\n$$\nThe diagonal part of $M$, denoted by $D$, is:\n$$\nD = \\operatorname{diag}(M) = \\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  2\n\\end{pmatrix}\n$$\n\n### Step 2: Compute $B$ and Provide Interpretation\n\nThe Jacobi iteration matrix is $B = I - D^{-1} M$. First, we find $D^{-1}$:\n$$\nD^{-1} = \\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1/2\n\\end{pmatrix}\n$$\nNext, we compute the product $D^{-1}M$:\n$$\nD^{-1} M = \\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1/2\n\\end{pmatrix}\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  1  0 \\\\\n0  1  1  0 \\\\\n0  0  0  2\n\\end{pmatrix} =\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  1  0 \\\\\n0  1  1  0 \\\\\n0  0  0  1\n\\end{pmatrix}\n$$\nFinally, we compute $B = I - D^{-1}M$:\n$$\nB = \\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1\n\\end{pmatrix} -\n\\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  1  0 \\\\\n0  1  1  0 \\\\\n0  0  0  1\n\\end{pmatrix} =\n\\begin{pmatrix}\n0  0  0  0 \\\\\n0  0  -1  0 \\\\\n0  -1  0  0 \\\\\n0  0  0  0\n\\end{pmatrix}\n$$\n**Interpretation:** The original directed graph represented by $A$ has edges $1 \\to 2$, $1 \\to 3$, $2 \\to 4$, $3 \\to 4$, and $4 \\to 1$. In this graph, there is no direct edge between vertex 2 and vertex 3 in either direction. The matrix $M = A^{\\top}A$ represents adjacencies in the undirected \"co-citation\" graph, where an edge $(i,j)$ exists if vertices $i$ and $j$ share a common in-neighbor in the directed graph of $A$. Here, vertices 2 and 3 both receive an edge from vertex 1. This shared in-neighbor (or co-citation) induces a new adjacency between 2 and 3, which is reflected in the nonzero entries $M_{23} = M_{32} = 1$. The Jacobi iteration matrix $B$ has the same off-diagonal sparsity pattern as $M$. The nonzero entries $B_{23}$ and $B_{32}$ directly correspond to this new adjacency between vertices 2 and 3 that was not present in the original graph of $A$.\n\n### Step 3: Compute the Spectral Radius $\\rho(B)$\n\nThe spectral radius is the maximum absolute value of the eigenvalues of $B$. We find the eigenvalues by solving the characteristic equation $\\det(B - \\lambda I) = 0$.\n$$\n\\det\\left( \\begin{pmatrix}\n0  0  0  0 \\\\\n0  0  -1  0 \\\\\n0  -1  0  0 \\\\\n0  0  0  0\n\\end{pmatrix} - \\lambda \\begin{pmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1\n\\end{pmatrix} \\right) = \\det\\begin{pmatrix}\n-\\lambda  0  0  0 \\\\\n0  -\\lambda  -1  0 \\\\\n0  -1  -\\lambda  0 \\\\\n0  0  0  -\\lambda\n\\end{pmatrix} = 0\n$$\nThe determinant of this block-diagonal matrix is the product of the determinants of its diagonal blocks:\n$$\n(-\\lambda) \\cdot (-\\lambda) \\cdot \\det\\begin{pmatrix} -\\lambda  -1 \\\\ -1  -\\lambda \\end{pmatrix} = 0\n$$\n$$\n\\lambda^2 (\\lambda^2 - 1) = 0 \\implies \\lambda^2 (\\lambda - 1)(\\lambda + 1) = 0\n$$\nThe eigenvalues are $\\lambda = \\{1, -1, 0, 0\\}$. The spectral radius $\\rho(B)$ is the maximum of the absolute values of these eigenvalues:\n$$\n\\rho(B) = \\max\\{|1|, |-1|, |0|, |0|\\} = 1\n$$", "answer": "$$\n\\boxed{1}\n$$", "id": "3549136"}, {"introduction": "For a sparse linear system to be reliably solvable, its matrix must possess full structural rank. This advanced practice delves into the trade-off between ensuring a matrix is structurally non-singular and minimizing the \"fill-in\" (new nonzeros) that arises during its factorization. You will use bipartite graph matching to identify a structural deficiency, propose minimal repairs, and analyze how these different repairs impact the computational cost of a subsequent Cholesky factorization. This exercise engages with a realistic design problem in sparse solvers, highlighting that the optimal solution requires a careful balance between algebraic correctness and computational efficiency [@problem_id:3549164].", "problem": "Consider a sparse matrix $A \\in \\mathbb{R}^{5 \\times 5}$ with row set $\\{r_1,r_2,r_3,r_4,r_5\\}$ and column set $\\{c_1,c_2,c_3,c_4,c_5\\}$. The bipartite graph representation of $A$, denoted $B(A)$, has left part $\\{c_1,c_2,c_3,c_4,c_5\\}$ and right part $\\{r_1,r_2,r_3,r_4,r_5\\}$, with an edge $(c_j,r_i)$ if and only if the structural pattern of $A$ contains a potential nonzero at position $(i,j)$. The nonzero pattern is specified by the following edges in $B(A)$:\n- $c_1$ is adjacent to $r_1$,\n- $c_2$ is adjacent to $r_1$ and $r_2$,\n- $c_3$ is adjacent to $r_2$,\n- $c_4$ is adjacent to $r_3$ and $r_5$,\n- $c_5$ is adjacent to $r_4$ and $r_5$.\n\nUsing only core definitions from numerical linear algebra and graph theory, and without invoking any pre-packaged theorems beyond those definitions, proceed as follows.\n\n1. Starting from the definition that the structural rank of $A$ equals the maximum size of a matching in $B(A)$, determine the minimal number of edge additions to $B(A)$ required to guarantee full structural rank (i.e., structural rank equal to $5$). Restrict attention to adding edges that connect one of the columns in $\\{c_1,c_2,c_3\\}$ to one of the rows in $\\{r_3,r_4,r_5\\}$, and justify minimality.\n\n2. For each such minimal single-edge addition, analyze the trade-off with fill-in during factorization via the following principled model. Consider the pattern of $A^{\\top}A$, whose column intersection graph $G$ has vertices $\\{c_1,c_2,c_3,c_4,c_5\\}$ and an undirected edge $(c_i,c_j)$ if and only if columns $c_i$ and $c_j$ share at least one common row index where both have a potential nonzero. Model Cholesky factorization of $A^{\\top}A$ with the natural elimination ordering $c_1,c_2,c_3,c_4,c_5$. Using the elimination graph framework, where eliminating a vertex adds edges to make its higher-index neighbors a clique, compute the number of fill-in edges $f$ introduced for each candidate single-edge addition identified in part $1$.\n\n3. Define the quantitative trade-off objective $J = \\alpha \\cdot k + \\beta \\cdot f$, where $k$ is the number of added edges and $f$ is the number of fill-in edges computed in part $2$. Take $\\alpha = \\frac{17}{10}$ and $\\beta = \\frac{9}{10}$. Among all minimal single-edge additions from part $1$, select the design that minimizes $J$, and report this minimal value of $J$ as a single real number. Do not use any units and do not express the result as an inequality or equation. If an approximation is not required, present the exact value.", "solution": "### Part 1: Minimal Edge Additions for Full Structural Rank\n\nFirst, we determine the structure of the matrix $A$ from the given adjacencies in the bipartite graph $B(A)$. An entry $A_{ij}$ is a potential nonzero if there is an edge $(c_j, r_i)$.\nThe sets of rows associated with each column are:\n$S(c_1) = \\{r_1\\}$\n$S(c_2) = \\{r_1, r_2\\}$\n$S(c_3) = \\{r_2\\}$\n$S(c_4) = \\{r_3, r_5\\}$\n$S(c_5) = \\{r_4, r_5\\}$\n\nThe structural rank of $A$ is the size of the maximum matching in $B(A)$. A perfect matching of size $5$ would imply full structural rank. The existence of a perfect matching can be tested using Hall's Marriage Theorem condition. For a perfect matching to exist that covers the set of columns $C = \\{c_1, c_2, c_3, c_4, c_5\\}$, for every subset $C' \\subseteq C$, the size of its neighborhood, $|N(C')|$, must be greater than or equal to the size of the subset, $|C'|$.\n\nLet's test this condition. Consider the subset of columns $C' = \\{c_1, c_2, c_3\\}$.\nThe neighborhood of this subset is $N(C') = S(c_1) \\cup S(c_2) \\cup S(c_3) = \\{r_1\\} \\cup \\{r_1, r_2\\} \\cup \\{r_2\\} = \\{r_1, r_2\\}$.\nWe find that $|C'|=3$ and $|N(C')|=2$. Since $|N(C')|  |C'|$, Hall's condition is violated. This proves that a perfect matching of size $5$ does not exist. The structural rank is less than $5$.\n\nThe size of the maximum matching is $4$. For example, the set of edges $M = \\{(c_1, r_1), (c_3, r_2), (c_4, r_3), (c_5, r_4)\\}$ is a valid matching of size $4$. The rank deficiency is $5 - 4 = 1$.\n\nTo achieve full structural rank, we must add edges to $B(A)$ to satisfy Hall's condition for all subsets. The problem asks for the *minimal* number of edge additions. Since the deficiency is $1$, a single edge addition might be sufficient. The violating set we found is $C_{viol} = \\{c_1, c_2, c_3\\}$. To remedy this violation, we must add an edge from a column in $C_{viol}$ to a row not in its current neighborhood $N(C_{viol}) = \\{r_1, r_2\\}$. The available rows are $\\{r_3, r_4, r_5\\}$. The problem constrains the additions to exactly these possibilities: connecting a column in $\\{c_1, c_2, c_3\\}$ to a row in $\\{r_3, r_4, r_5\\}$.\n\nAdding any single such edge will increase the size of $N(C_{viol})$ to $3$, thus satisfying the condition for this specific subset. It can be shown that in this case, adding one such edge is sufficient to enable a perfect matching. Therefore, the minimal number of edge additions required is $k=1$. The problem directs us to consider these minimal, single-edge additions for the subsequent parts. There are $3 \\times 3 = 9$ such possible edge additions.\n\n### Part 2: Fill-in Analysis\n\nWe analyze the fill-in during the Cholesky factorization of $A^{\\top}A$ using the natural elimination ordering $c_1, c_2, c_3, c_4, c_5$. This is modeled using the column intersection graph $G$.\n\nFirst, we construct the initial graph $G_0$ corresponding to the unmodified matrix $A$. An edge $(c_i, c_j)$ exists if columns $c_i$ and $c_j$ have non-empty intersection of their row sets.\n- $S(c_1) \\cap S(c_2) = \\{r_1\\} \\neq \\emptyset \\implies$ edge $(c_1, c_2)$.\n- $S(c_2) \\cap S(c_3) = \\{r_2\\} \\neq \\emptyset \\implies$ edge $(c_2, c_3)$.\n- $S(c_4) \\cap S(c_5) = \\{r_5\\} \\neq \\emptyset \\implies$ edge $(c_4, c_5)$.\nThe initial edge set of $G_0$ is $E_0 = \\{(c_1, c_2), (c_2, c_3), (c_4, c_5)\\}$.\n\nNow we consider each of the $k=1$ minimal edge additions. An addition corresponds to adding a potential nonzero $A_{ji}$ (edge $(c_i, r_j)$). This may add edges to the column intersection graph if the new row index $j$ is already present in another column's pattern.\nThe original row presences are: $r_3$ in $S(c_4)$, $r_4$ in $S(c_5)$, and $r_5$ in both $S(c_4)$ and $S(c_5)$.\n\nLet's analyze the $9$ candidate edge additions:\n1.  **Add $(c_i, r_3)$ for $i \\in \\{1,2,3\\}$**: This adds the entry $A_{3i}$. Since $r_3 \\in S(c_4)$, a new edge $(c_i, c_4)$ is added to $G$.\n2.  **Add $(c_i, r_4)$ for $i \\in \\{1,2,3\\}$**: This adds the entry $A_{4i}$. Since $r_4 \\in S(c_5)$, a new edge $(c_i, c_5)$ is added to $G$.\n3.  **Add $(c_i, r_5)$ for $i \\in \\{1,2,3\\}$**: This adds the entry $A_{5i}$. Since $r_5 \\in S(c_4)$ and $S(c_5)$, new edges $(c_i, c_4)$ and $(c_i, c_5)$ are added to $G$.\n\nWe now compute the fill-in $f$ for each case. Fill-in occurs when we eliminate vertex $c_i$ and its higher-indexed neighbors $N^+(c_i)$ are not fully connected (a clique).\n\n- **Cases with addition to $r_3$**:\n    - Add $(c_3, r_3) \\implies G$ has edges $E_0 \\cup \\{(c_3, c_4)\\}$.\n        - Elim $c_1$: $N^+(c_1)=\\{c_2\\}$. No fill.\n        - Elim $c_2$: $N^+(c_2)=\\{c_3\\}$. No fill.\n        - Elim $c_3$: $N^+(c_3)=\\{c_4\\}$. No fill.\n        - Elim $c_4$: $N^+(c_4)=\\{c_5\\}$. No fill.\n        - Total fill-in $f=0$.\n    - Add $(c_2, r_3) \\implies G$ has edges $E_0 \\cup \\{(c_2, c_4)\\}$.\n        - Elim $c_1$: $N^+(c_1)=\\{c_2\\}$. No fill.\n        - Elim $c_2$: $N^+(c_2)=\\{c_3,c_4\\}$. Add fill-in edge $(c_3, c_4)$.\n        - Total fill-in $f=1$.\n    - Add $(c_1, r_3) \\implies G$ has edges $E_0 \\cup \\{(c_1, c_4)\\}$.\n        - Elim $c_1$: $N^+(c_1)=\\{c_2, c_4\\}$. Add fill-in edge $(c_2, c_4)$.\n        - Graph now includes $(c_2, c_4)$. Elim $c_2$: $N^+(c_2)=\\{c_3, c_4\\}$. Add fill-in edge $(c_3, c_4)$.\n        - Total fill-in $f=2$.\n\n- **Cases with addition to $r_4$**:\n    - Add $(c_3, r_4) \\implies G$ has edges $E_0 \\cup \\{(c_3, c_5)\\}$.\n        - Elim $c_1$: $N^+(c_1)=\\{c_2\\}$. No fill.\n        - Elim $c_2$: $N^+(c_2)=\\{c_3\\}$. No fill.\n        - Elim $c_3$: $N^+(c_3)=\\{c_5\\}$. No fill.\n        - Elim $c_4$: $N^+(c_4)=\\{c_5\\}$. No fill.\n        - Total fill-in $f=0$.\n    - Add $(c_2, r_4) \\implies G$ has edges $E_0 \\cup \\{(c_2, c_5)\\}$.\n        - Elim $c_1$: $N^+(c_1)=\\{c_2\\}$. No fill.\n        - Elim $c_2$: $N^+(c_2)=\\{c_3, c_5\\}$. Add fill-in edge $(c_3, c_5)$.\n        - Total fill-in $f=1$.\n    - Add $(c_1, r_4) \\implies G$ has edges $E_0 \\cup \\{(c_1, c_5)\\}$.\n        - Elim $c_1$: $N^+(c_1)=\\{c_2, c_5\\}$. Add fill-in edge $(c_2, c_5)$.\n        - Graph now includes $(c_2, c_5)$. Elim $c_2$: $N^+(c_2)=\\{c_3, c_5\\}$. Add fill-in edge $(c_3, c_5)$.\n        - Total fill-in $f=2$.\n\n- **Cases with addition to $r_5$**:\n    - Add $(c_3, r_5) \\implies G$ has edges $E_0 \\cup \\{(c_3, c_4), (c_3, c_5)\\}$.\n        - Elim $c_1$: $N^+(c_1)=\\{c_2\\}$. No fill.\n        - Elim $c_2$: $N^+(c_2)=\\{c_3\\}$. No fill.\n        - Elim $c_3$: $N^+(c_3)=\\{c_4, c_5\\}$. Edge $(c_4, c_5)$ exists in $E_0$. No fill.\n        - Total fill-in $f=0$.\n    - Add $(c_2, r_5) \\implies G$ has edges $E_0 \\cup \\{(c_2, c_4), (c_2, c_5)\\}$.\n        - Elim $c_1$: $N^+(c_1)=\\{c_2\\}$. No fill.\n        - Elim $c_2$: $N^+(c_2)=\\{c_3, c_4, c_5\\}$. Edge $(c_4, c_5)$ exists. Add fill-in edges $(c_3, c_4)$ and $(c_3, c_5)$.\n        - Total fill-in $f=2$.\n    - Add $(c_1, r_5) \\implies G$ has edges $E_0 \\cup \\{(c_1, c_4), (c_1, c_5)\\}$.\n        - Elim $c_1$: $N^+(c_1)=\\{c_2, c_4, c_5\\}$. Edge $(c_4, c_5)$ exists. Add fill-in edges $(c_2, c_4)$ and $(c_2, c_5)$.\n        - Graph includes $(c_2,c_4), (c_2,c_5)$. Elim $c_2$: $N^+(c_2)=\\{c_3, c_4, c_5\\}$. Edge $(c_4,c_5)$ exists. Add fill-in edges $(c_3, c_4)$ and $(c_3, c_5)$.\n        - Total fill-in $f=4$.\n\nSummary of fill-in values ($f$):\n- Add $(c_1, r_3): f=2$\n- Add $(c_2, r_3): f=1$\n- Add $(c_3, r_3): f=0$\n- Add $(c_1, r_4): f=2$\n- Add $(c_2, r_4): f=1$\n- Add $(c_3, r_4): f=0$\n- Add $(c_1, r_5): f=4$\n- Add $(c_2, r_5): f=2$\n- Add $(c_3, r_5): f=0$\n\n### Part 3: Trade-off Minimization\n\nThe objective function to minimize is $J = \\alpha \\cdot k + \\beta \\cdot f$. We are given $\\alpha = \\frac{17}{10}$ and $\\beta = \\frac{9}{10}$. For all candidate designs, the number of added edges is $k=1$. Thus, the objective function simplifies to:\n$J = \\frac{17}{10} \\cdot 1 + \\frac{9}{10} \\cdot f = 1.7 + 0.9 \\cdot f$.\n\nTo minimize $J$, we must choose the design that results in the minimum number of fill-in edges, $f$. From the analysis in Part 2, the minimum value of $f$ is $0$. This minimum is achieved by three distinct single-edge additions:\n1.  Adding edge $(c_3, r_3)$.\n2.  Adding edge $(c_3, r_4)$.\n3.  Adding edge $(c_3, r_5)$.\n\nFor any of these optimal designs, the minimal value of the objective function $J$ is:\n$J_{min} = 1.7 + 0.9 \\cdot 0 = 1.7$.\n\nThe question asks for this minimal value of $J$.", "answer": "$$\\boxed{1.7}$$", "id": "3549164"}]}