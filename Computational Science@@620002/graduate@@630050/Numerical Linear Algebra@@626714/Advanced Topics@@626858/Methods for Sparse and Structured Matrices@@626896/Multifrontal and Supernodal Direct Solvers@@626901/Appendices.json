{"hands_on_practices": [{"introduction": "Understanding multifrontal and supernodal solvers begins with the fundamental mechanism of fill-in. This first exercise isolates the core operation of sparse elimination: the effect of removing a single variable. By deriving a general formula for the Schur complement update, you will formalize the \"clique formation\" rule that governs where new nonzeros appear, providing a foundational model for the entire factorization process.", "problem": "Consider a symmetric positive definite (SPD) sparse matrix $A \\in \\mathbb{R}^{n \\times n}$, and let its sparsity pattern be represented by the undirected graph $G(A)$ with vertex set $\\{1,2,\\dots,n\\}$, where an undirected edge $\\{p,q\\}$ exists if and only if $A_{pq} \\neq 0$ for $p \\neq q$. Let $i \\in \\{1,\\dots,n\\}$ be a node to be eliminated in a multifrontal or supernodal direct solver. Define the neighbor set $N(i) = \\{ j \\in \\{1,\\dots,n\\} \\setminus \\{i\\} : A_{ij} \\neq 0 \\}$ and let $R = \\{1,\\dots,n\\} \\setminus \\{i\\}$. The Schur complement on $R$ produced by eliminating $i$ is the matrix $S^{(i)} \\in \\mathbb{R}^{(n-1) \\times (n-1)}$ given by\n$$\nS^{(i)} = A_{RR} - A_{Ri} A_{ii}^{-1} A_{iR}.\n$$\nAssume exact arithmetic and no numerical cancellation. Let $k = |N(i)|$, and let $m$ denote the number of upper-triangular off-diagonal nonzero entries originally present in the submatrix $A_{N(i),N(i)}$ (equivalently, the number of undirected edges in the induced subgraph of $G(A)$ on $N(i)$).\n\nUsing only the core definitions of the graph of a sparse matrix and the Schur complement, derive:\n- the size of the submatrix of the Schur complement update that is affected by eliminating $i$ (expressed as the dimension of the affected index set), and\n- the count of newly introduced upper-triangular off-diagonal nonzero entries within the affected submatrix of $S^{(i)}$ relative to $A_{RR}$.\n\nExpress your final answer as a two-entry row vector using the pmatrix environment, with the first entry equal to the dimension and the second entry equal to the count of new upper-triangular off-diagonal nonzeros, in symbolic form as a function of $k$ and $m$. No rounding is required, and no physical units are involved.", "solution": "We start from the fundamental definitions of the graph of a sparse matrix and the Schur complement. For a symmetric positive definite matrix $A$, the elimination of a single node $i$ within a multifrontal or supernodal direct solver produces a Schur complement on the remaining index set $R = \\{1,\\dots,n\\} \\setminus \\{i\\}$:\n$$\nS^{(i)} = A_{RR} - A_{Ri} A_{ii}^{-1} A_{iR}.\n$$\nThe term $A_{Ri} A_{ii}^{-1} A_{iR}$ is the update induced by eliminating $i$. Because $A$ is symmetric, $A_{Ri} = A_{iR}^{\\top}$, and the update can be written as a rank-one outer product scaled by the scalar $A_{ii}^{-1}$. Define the vector $u \\in \\mathbb{R}^{n-1}$ by\n$$\nu = A_{Ri},\n$$\nwhich collects the entries of column $i$ of $A$ excluding the diagonal entry $A_{ii}$. The support of $u$ (the set of indices where $u$ is nonzero) is exactly $N(i)$ by definition of the neighbor set. Then the update term is\n$$\nU^{(i)} := A_{Ri} A_{ii}^{-1} A_{iR} = A_{ii}^{-1} \\, u \\, u^{\\top}.\n$$\n\nWe analyze two aspects: the size (dimension) of the affected submatrix, and the sparsity (count of new upper-triangular off-diagonal nonzeros).\n\n1. Size (dimension of the affected submatrix):\nThe update $U^{(i)}$ has nonzero entries only at index pairs $(p,q)$ where both $p$ and $q$ are in the support of $u$, that is, $p \\in N(i)$ and $q \\in N(i)$. Therefore, the update affects only the submatrix indexed by $N(i) \\times N(i)$. The dimension of this affected submatrix (i.e., the cardinality of the index set $N(i)$) is\n$$\nk = |N(i)|.\n$$\nThus, the size of the affected block in the Schur complement is $k$ (meaning a $k \\times k$ submatrix).\n\n2. Sparsity (count of newly introduced upper-triangular off-diagonal nonzeros):\nSince $U^{(i)} = A_{ii}^{-1} \\, u \\, u^{\\top}$ is an outer product and $u$ has nonzeros exactly on $N(i)$, the update $U^{(i)}$ restricted to $N(i) \\times N(i)$ is dense: for any $p,q \\in N(i)$, we have\n$$\nU^{(i)}_{pq} = A_{ii}^{-1} \\, u_{p} \\, u_{q},\n$$\nwhich is nonzero under the assumption of no numerical cancellation and exact arithmetic whenever $u_{p}$ and $u_{q}$ are nonzero. Therefore, all off-diagonal positions $(p,q)$ with $p \\neq q$ and $p,q \\in N(i)$ in the upper triangle become nonzero in the update. The total number of distinct upper-triangular off-diagonal positions in a $k \\times k$ matrix is $\\binom{k}{2}$.\n\nHowever, some of these positions may already be nonzero in the original submatrix $A_{N(i),N(i)}$. Let $m$ denote the number of upper-triangular off-diagonal nonzero entries originally present in $A_{N(i),N(i)}$. These correspond to the undirected edges in the induced subgraph on $N(i)$ in $G(A)$ and are counted once in the upper triangle. The newly introduced upper-triangular off-diagonal nonzeros (i.e., fill-in) are the positions that were zero in $A_{N(i),N(i)}$ but become nonzero due to $U^{(i)}$. Therefore, the count of new upper-triangular off-diagonal nonzeros is\n$$\n\\binom{k}{2} - m.\n$$\n\nCollecting the two quantities requested:\n- The dimension of the affected submatrix is $k$.\n- The number of newly introduced upper-triangular off-diagonal nonzeros within that submatrix is $\\binom{k}{2} - m$.\n\nThe final answer is thus the two-entry row vector\n$$\n\\begin{pmatrix}\nk & \\binom{k}{2} - m\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} k & \\binom{k}{2} - m \\end{pmatrix}}$$", "id": "3560966"}, {"introduction": "Building on the local fill-in principle [@problem_id:3560966], we now apply the elimination rule sequentially to a complete, albeit small, system. This practice guides you through the symbolic Cholesky factorization of a matrix representing a 2D grid, allowing you to trace the propagation of fill-in across the graph. You will construct the elimination tree and verify the nonzero pattern of the factor from both the graph elimination and multifrontal perspectives, bridging these two crucial viewpoints.", "problem": "Consider a real, symmetric positive definite (SPD) matrix $A \\in \\mathbb{R}^{6 \\times 6}$ whose sparsity graph $G(A)$ is the $2 \\times 3$ rectangular grid with natural row-major ordering. That is, the vertex set is $\\{1,2,3,4,5,6\\}$ and the undirected edge set is\n$$\nE \\;=\\; \\{(1,2),(2,3),(4,5),(5,6),(1,4),(2,5),(3,6)\\}.\n$$\nAssume generic nonzero values consistent with $G(A)$ so that no numerical cancellation induces structural zeros, and perform a Cholesky factorization without pivoting and without reordering (i.e., the elimination order is $1,2,3,4,5,6$). Use the graph model of sparse Cholesky factorization and the elimination tree to derive, from first principles, the nonzero pattern of the Cholesky factor $L$ (lower triangular with positive diagonal) and to predict all fill edges created by elimination. Then, verify the predicted pattern by reasoning from the multifrontal viewpoint: at the elimination of each vertex $j$, its current higher-index neighbors form a clique, which is the variable part of the frontal matrix, and this saturation induces fill as appropriate.\n\nYour tasks are:\n- Derive the elimination tree and the predicted nonzero pattern of each column of $L$ using only core definitions: at the elimination of a vertex $j$, the current higher-index neighbors of $j$ are made into a clique; the parent of $j$ in the elimination tree is the minimal higher-index row index of $L$ in column $j$.\n- Independently verify the same pattern via the multifrontal perspective by enumerating the variable sets in the frontal matrices and the fill edges they imply.\n- Determine the exact number of fill-in nonzeros created in the strict lower triangle of $L$ (i.e., nonzeros of $L$ below the diagonal that do not correspond to original edges of $G(A)$).\n\nReport as your final answer the exact count of fill-in entries in the strict lower triangle of $L$. Do not round. No units are required.", "solution": "The core of the problem is to determine the nonzero structure of the Cholesky factor $L$ of a sparse matrix $A$. This structure is equivalent to the structure of the filled graph, $G^+(A)$, which is obtained by adding \"fill-in\" edges to the original graph $G(A)$ during a symbolic elimination process.\n\nThe graph-theoretic model of Cholesky factorization proceeds by eliminating vertices one by one. When a vertex $k$ is eliminated, its current set of higher-indexed neighbors is made into a clique by adding any missing edges. These new edges are the \"fill edges\". The final graph, after all vertices are eliminated, is the filled graph $G^+(A)$. The nonzero structure of $L$ is then given by: $L_{ij} \\neq 0$ for $i \\geq j$ if and only if $(i,j)$ is an edge in $G^+(A)$ (with self-loops $(j,j)$ for the diagonal).\n\nLet $G_0 = G(A)$. We will generate a sequence of graphs $G_1, G_2, \\ldots, G_5$ where $G_k$ is the graph after eliminating vertex $k$.\n\n**Initial Graph $G_0$:**\nThe adjacency list of $G_0 = (V,E)$ is:\n-   $\\text{adj}_0(1) = \\{2, 4\\}$\n-   $\\text{adj}_0(2) = \\{1, 3, 5\\}$\n-   $\\text{adj}_0(3) = \\{2, 6\\}$\n-   $\\text{adj}_0(4) = \\{1, 5\\}$\n-   $\\text{adj}_0(5) = \\{2, 4, 6\\}$\n-   $\\text{adj}_0(6) = \\{3, 5\\}$\n\n**Step 1: Eliminate Vertex 1**\n-   The neighbors of vertex $1$ in $G_0$ are $\\{2, 4\\}$.\n-   The set of higher-indexed neighbors is also $\\{2, 4\\}$.\n-   These neighbors must form a clique. The edge $(2,4)$ does not exist in $G_0$.\n-   **Fill-in Edge:** We add the edge $(2,4)$ to the graph. This is the first fill-in.\n-   The new graph is $G_1 = (V, E \\cup \\{(2,4)\\})$.\n-   The nonzero structure of column $1$ of $L$ is determined by the neighbors of $1$ in $G_0$: $L_{11}, L_{21}, L_{41}$ are non-zero.\n-   The parent of vertex $1$ in the elimination tree is given by $\\text{parent}(1) = \\min\\{i > 1 \\mid L_{i1} \\neq 0\\} = \\min\\{2, 4\\} = 2$.\n\n**Step 2: Eliminate Vertex 2**\n-   The neighbors of vertex $2$ in $G_1$ are $\\{1, 3, 5\\}$ (from $G_0$) and $\\{4\\}$ (from fill-in). Thus, $\\text{adj}_1(2) = \\{1, 3, 4, 5\\}$.\n-   The set of higher-indexed neighbors is $\\{3, 4, 5\\}$.\n-   These neighbors must form a clique.\n    -   Edge $(4,5)$ exists in $G_0$.\n    -   Edge $(3,4)$ does not exist. **Fill-in Edge:** Add $(3,4)$.\n    -   Edge $(3,5)$ does not exist. **Fill-in Edge:** Add $(3,5)$.\n-   The new graph is $G_2 = (V, E \\cup \\{(2,4), (3,4), (3,5)\\})$.\n-   The nonzero structure of column $2$ of $L$ is determined by the neighbors of $2$ in $G_1$: $L_{22}, L_{32}, L_{42}, L_{52}$ are non-zero.\n-   $\\text{parent}(2) = \\min\\{i > 2 \\mid L_{i2} \\neq 0\\} = \\min\\{3, 4, 5\\} = 3$.\n\n**Step 3: Eliminate Vertex 3**\n-   The neighbors of vertex $3$ in $G_2$ are $\\{2, 6\\}$ (from $G_0$) and $\\{4, 5\\}$ (from fill-in). Thus, $\\text{adj}_2(3) = \\{2, 4, 5, 6\\}$.\n-   The set of higher-indexed neighbors is $\\{4, 5, 6\\}$.\n-   These neighbors must form a clique.\n    -   Edge $(4,5)$ exists in $G_0$.\n    -   Edge $(5,6)$ exists in $G_0$.\n    -   Edge $(4,6)$ does not exist. **Fill-in Edge:** Add $(4,6)$.\n-   The new graph is $G_3 = (V, E \\cup \\{(2,4), (3,4), (3,5), (4,6)\\})$.\n-   The nonzero structure of column $3$ of $L$ corresponds to neighbors of $3$ in $G_2$: $L_{33}, L_{43}, L_{53}, L_{63}$ are non-zero.\n-   $\\text{parent}(3) = \\min\\{i > 3 \\mid L_{i3} \\neq 0\\} = \\min\\{4, 5, 6\\} = 4$.\n\n**Step 4: Eliminate Vertex 4**\n-   The neighbors of vertex $4$ in $G_3$ are $\\{1, 5\\}$ (from $G_0$) and $\\{2, 3, 6\\}$ (from fill-in). Thus, $\\text{adj}_3(4) = \\{1, 2, 3, 5, 6\\}$.\n-   The set of higher-indexed neighbors is $\\{5, 6\\}$.\n-   These neighbors must form a clique. The edge $(5,6)$ already exists in $G_0$. No new fill-in.\n-   $G_4 = G_3$.\n-   The nonzero structure of column $4$ of $L$ corresponds to neighbors of $4$ in $G_3$: $L_{44}, L_{54}, L_{64}$ are non-zero.\n-   $\\text{parent}(4) = \\min\\{i > 4 \\mid L_{i4} \\neq 0\\} = \\min\\{5, 6\\} = 5$.\n\n**Step 5: Eliminate Vertex 5**\n-   The neighbors of vertex $5$ in $G_4$ are $\\{2, 4, 6\\}$ (from $G_0$) and $\\{3\\}$ (from fill-in). Thus, $\\text{adj}_4(5) = \\{2, 3, 4, 6\\}$.\n-   The set of higher-indexed neighbors is $\\{6\\}$. A single vertex is a trivial clique. No new fill-in.\n-   $G_5 = G_4$.\n-   The nonzero structure of column $5$ of $L$ corresponds to neighbors of $5$ in $G_4$: $L_{55}, L_{65}$ are non-zero.\n-   $\\text{parent}(5) = \\min\\{i > 5 \\mid L_{i5} \\neq 0\\} = \\min\\{6\\} = 6$.\n\n**Step 6: Eliminate Vertex 6**\n-   Vertex $6$ is the last vertex. It has no higher-indexed neighbors. The process is complete. Vertex $6$ is the root of the elimination tree.\n\n**Summary of Results from Graph Elimination:**\n\n1.  **Elimination Tree:** The parent relations are $1 \\to 2$, $2 \\to 3$, $3 \\to 4$, $4 \\to 5$, $5 \\to 6$. This forms a path:\n    $$1 \\to 2 \\to 3 \\to 4 \\to 5 \\to 6$$\n2.  **Nonzero Pattern of L:** The nonzeros $L_{ij}$ for $i>j$ correspond to edges $(i,j)$ in the final filled graph $G^+ = G_5$.\n    -   Column $1$: $\\{1, 2, 4\\}$\n    -   Column $2$: $\\{2, 3, 4, 5\\}$\n    -   Column $3$: $\\{3, 4, 5, 6\\}$\n    -   Column $4$: $\\{4, 5, 6\\}$\n    -   Column $5$: $\\{5, 6\\}$\n    -   Column $6$: $\\{6\\}$\n3.  **Fill-in Edges:** A total of $4$ fill-in edges were created: $(2,4), (3,4), (3,5), (4,6)$.\n\n### Multifrontal Verification\n\nThe multifrontal method provides an alternative but equivalent view. At each step $k$, a small, dense \"frontal matrix\" $F_k$ is formed for vertex $k$ and its higher-indexed neighbors in the current graph. Factoring $k$ out of $F_k$ produces a \"Schur complement\" or \"update matrix\" on those neighbors, which is then assembled into the main system. The key insight is that this update matrix is dense, which corresponds precisely to making the neighbors a clique.\n\n-   **Frontal Matrix $F_1$:** Variables are $\\{1\\} \\cup \\text{adj}_{G_0}(1, >1) = \\{1, 2, 4\\}$. Factoring $1$ from this $3 \\times 3$ matrix creates a dense $2 \\times 2$ update on $\\{2, 4\\}$. This creates a nonzero contribution to the $(2,4)$ entry of the system, verifying the fill-in edge $(2,4)$.\n\n-   **Frontal Matrix $F_2$:** Variables are $\\{2\\} \\cup \\text{adj}_{G_1}(2, >2) = \\{2, 3, 4, 5\\}$. Factoring $2$ from this $4 \\times 4$ matrix creates a dense $3 \\times 3$ update on $\\{3, 4, 5\\}$. This verifies the fill-in edges $(3,4)$ and $(3,5)$.\n\n-   **Frontal Matrix $F_3$:** Variables are $\\{3\\} \\cup \\text{adj}_{G_2}(3, >3) = \\{3, 4, 5, 6\\}$. Factoring $3$ from this $4 \\times 4$ matrix creates a dense $3 \\times 3$ update on $\\{4, 5, 6\\}$. This verifies the fill-in edge $(4,6)$.\n\n-   **Frontal Matrix $F_4$:** Variables are $\\{4\\} \\cup \\text{adj}_{G_3}(4, >4) = \\{4, 5, 6\\}$. Factoring $4$ creates a dense $2 \\times 2$ update on $\\{5, 6\\}$. Since $(5,6)$ is already an edge, this does not create fill-in but populates an existing nonzero.\n\n-   **Frontal Matrix $F_5$:** Variables are $\\{5\\} \\cup \\text{adj}_{G_4}(5, >5) = \\{5, 6\\}$. No new fill is created.\n\nThe multifrontal perspective thus independently confirms the sequence of fill-in generated by the graph elimination model.\n\n### Determination of Fill-in Count\n\nThe fill-in nonzeros in the strict lower triangle of $L$ are the entries $L_{ij}$ with $i>j$ such that $L_{ij} \\neq 0$ but $A_{ij} = 0$. This count is identical to the number of fill-in edges created during the symbolic factorization.\n\nThe original graph $G(A)$ has $7$ edges in its upper triangle: $(1,2), (1,4), (2,3), (2,5), (3,6), (4,5), (5,6)$.\nThe filled graph $G^+(A)$ has all of these plus the fill-in edges.\nThe fill-in edges are:\n1.  $(2,4)$\n2.  $(3,4)$\n3.  $(3,5)$\n4.  $(4,6)$\n\nThese four edges correspond to the fill-in nonzeros $L_{42}$, $L_{43}$, $L_{53}$, and $L_{64}$ in the strict lower triangle of the Cholesky factor $L$.\nThe total number of fill-in nonzeros is $4$.", "answer": "$$\n\\boxed{4}\n$$", "id": "3560922"}, {"introduction": "Having explored the symbolic structure of factorization, we now turn to the numerical mechanics of the multifrontal method. This exercise requires you to perform a complete $LDL^{\\top}$ factorization of a simple tridiagonal matrix, tracking the flow of data and computation. You will assemble frontal matrices, perform numerical eliminations, and calculate the Schur complement 'update' blocks that are passed up the elimination tree, giving you a concrete understanding of the algorithm in action.", "problem": "Consider the symmetric positive definite (SPD) banded matrix\n$$\nA \\;=\\; \\begin{pmatrix}\n2 & -1 & 0 & 0 & 0\\\\\n-1 & 2 & -1 & 0 & 0\\\\\n0 & -1 & 2 & -1 & 0\\\\\n0 & 0 & -1 & 2 & -1\\\\\n0 & 0 & 0 & -1 & 2\n\\end{pmatrix} \\in \\mathbb{R}^{5 \\times 5}.\n$$\nUsing the multifrontal method and the natural elimination order on variables $\\{1,2,3,4,5\\}$, perform a complete Lower-Diagonal-Lower transpose (LDL$^{\\top}$) factorization of $A$ without numerical pivoting. Assume the standard multifrontal terminology: at each step $i$, assemble a frontal matrix on the variable set $\\{i,i+1\\}$ (or $\\{5\\}$ for the last step), incorporate any contributions from previously eliminated variables, eliminate the pivot $i$ to produce a contribution block on the remaining variable(s), and propagate this contribution forward for later assembly. Explicitly list the sequence of frontal assemblies, eliminations, and updates (contributions) carried through the process until the factorization is complete.\n\nAfter completing the factorization, compute $\\det(A)$ from your factors. Your final answer must be a single real number. Do not round.", "solution": "The multifrontal method proceeds step-by-step, eliminating one variable at a time according to the specified order. At each step $k$, a frontal matrix $F_k$ is assembled. This assembly involves taking the corresponding entries from the original matrix $A$ and adding to them any update contributions from previously eliminated variables (children in the elimination tree). For this problem, the elimination tree is a simple path $1 \\to 2 \\to 3 \\to 4 \\to 5$, so each step $k > 1$ receives a contribution only from step $k-1$.\n\nThe factorization of a frontal matrix $F_k$, partitioned with respect to the pivot variable $k$, is:\n$$ F_k = \\begin{pmatrix} F_{11} & F_{12} \\\\ F_{21} & F_{22} \\end{pmatrix} = \\begin{pmatrix} I & 0 \\\\ F_{21}F_{11}^{-1} & I \\end{pmatrix} \\begin{pmatrix} F_{11} & 0 \\\\ 0 & F_{22} - F_{21}F_{11}^{-1}F_{12} \\end{pmatrix} \\begin{pmatrix} I & F_{11}^{-1}F_{12} \\\\ 0 & I \\end{pmatrix} $$\nThe diagonal block of the final factor $D$ is $D_{kk} = F_{11}$. The entries of the final factor $L$ are computed from $F_{21}F_{11}^{-1}$. The term $C_{k+1} = -F_{21}F_{11}^{-1}F_{12}$ is the update contribution block passed to the parent node.\n\n**Step 1: Eliminate variable 1**\nThe frontal set is $\\{1, 2\\}$. The initial frontal matrix $F_1$ is formed from the corresponding submatrix of $A$, as there are no prior contributions.\n$$ F_1 = \\begin{pmatrix} A_{11} & A_{12} \\\\ A_{21} & A_{22} \\end{pmatrix} = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} $$\nWe eliminate the pivot variable $1$. The pivot block is $D_{11} = 2$.\nThe corresponding entry in the $L$ factor is $L_{21} = A_{21} D_{11}^{-1} = (-1) (2)^{-1} = -\\frac{1}{2}$.\nThe update contribution for the remaining variable $2$ is a $1 \\times 1$ matrix $C_2$ that will be assembled in the next step.\n$$ C_2 = -A_{21} D_{11}^{-1} A_{12} = -(-1)(2^{-1})(-1) = -\\frac{1}{2} $$\n\n**Step 2: Eliminate variable 2**\nThe frontal set is $\\{2, 3\\}$. The frontal matrix $F_2$ is assembled by taking the submatrix of $A$ for indices $\\{2, 3\\}$ and adding the contribution $C_2$ to the entry corresponding to variable $2$.\n$$ F_2 = \\begin{pmatrix} A_{22} & A_{23} \\\\ A_{32} & A_{33} \\end{pmatrix} + \\begin{pmatrix} C_2 & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} + \\begin{pmatrix} -\\frac{1}{2} & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{3}{2} & -1 \\\\ -1 & 2 \\end{pmatrix} $$\nWe eliminate the pivot variable $2$. The pivot block is $D_{22} = \\frac{3}{2}$.\nThe entry in the $L$ factor is $L_{32} = F_{2(2,1)} D_{22}^{-1} = (-1) (\\frac{3}{2})^{-1} = -\\frac{2}{3}$.\nThe update contribution for variable $3$ is $C_3$.\n$$ C_3 = -F_{2(2,1)} D_{22}^{-1} F_{2(1,2)} = -(-1)(\\frac{2}{3})(-1) = -\\frac{2}{3} $$\n\n**Step 3: Eliminate variable 3**\nThe frontal set is $\\{3, 4\\}$. The frontal matrix $F_3$ is assembled from the corresponding part of $A$ and the contribution $C_3$.\n$$ F_3 = \\begin{pmatrix} A_{33} & A_{34} \\\\ A_{43} & A_{44} \\end{pmatrix} + \\begin{pmatrix} C_3 & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} + \\begin{pmatrix} -\\frac{2}{3} & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{3} & -1 \\\\ -1 & 2 \\end{pmatrix} $$\nWe eliminate the pivot variable $3$. The pivot block is $D_{33} = \\frac{4}{3}$.\nThe entry in the $L$ factor is $L_{43} = F_{3(2,1)} D_{33}^{-1} = (-1) (\\frac{4}{3})^{-1} = -\\frac{3}{4}$.\nThe update contribution for variable $4$ is $C_4$.\n$$ C_4 = -F_{3(2,1)} D_{33}^{-1} F_{3(1,2)} = -(-1)(\\frac{3}{4})(-1) = -\\frac{3}{4} $$\n\n**Step 4: Eliminate variable 4**\nThe frontal set is $\\{4, 5\\}$. The frontal matrix $F_4$ is assembled from the corresponding part of $A$ and the contribution $C_4$.\n$$ F_4 = \\begin{pmatrix} A_{44} & A_{45} \\\\ A_{54} & A_{55} \\end{pmatrix} + \\begin{pmatrix} C_4 & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 2 & -1 \\\\ -1 & 2 \\end{pmatrix} + \\begin{pmatrix} -\\frac{3}{4} & 0 \\\\ 0 & 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{4} & -1 \\\\ -1 & 2 \\end{pmatrix} $$\nWe eliminate the pivot variable $4$. The pivot block is $D_{44} = \\frac{5}{4}$.\nThe entry in the $L$ factor is $L_{54} = F_{4(2,1)} D_{44}^{-1} = (-1) (\\frac{5}{4})^{-1} = -\\frac{4}{5}$.\nThe update contribution for variable $5$ is $C_5$.\n$$ C_5 = -F_{4(2,1)} D_{44}^{-1} F_{4(1,2)} = -(-1)(\\frac{4}{5})(-1) = -\\frac{4}{5} $$\n\n**Step 5: Eliminate variable 5**\nThe frontal set is $\\{5\\}$. This is the final step (the root of the elimination tree). The frontal matrix $F_5$ is assembled from $A_{55}$ and the contribution $C_5$.\n$$ F_5 = (A_{55}) + (C_5) = (2) + (-\\frac{4}{5}) = (\\frac{6}{5}) $$\nThis fully assembled matrix is the final pivot block, $D_{55} = \\frac{6}{5}$. The factorization is complete.\n\nThe resulting factors in the decomposition $A = LDL^{\\top}$ are:\n$$\nL = \\begin{pmatrix}\n1 & 0 & 0 & 0 & 0 \\\\\n-\\frac{1}{2} & 1 & 0 & 0 & 0 \\\\\n0 & -\\frac{2}{3} & 1 & 0 & 0 \\\\\n0 & 0 & -\\frac{3}{4} & 1 & 0 \\\\\n0 & 0 & 0 & -\\frac{4}{5} & 1\n\\end{pmatrix},\n\\quad\nD = \\begin{pmatrix}\n2 & 0 & 0 & 0 & 0 \\\\\n0 & \\frac{3}{2} & 0 & 0 & 0 \\\\\n0 & 0 & \\frac{4}{3} & 0 & 0 \\\\\n0 & 0 & 0 & \\frac{5}{4} & 0 \\\\\n0 & 0 & 0 & 0 & \\frac{6}{5}\n\\end{pmatrix}\n$$\n\nFinally, we compute the determinant of $A$. Using the property $\\det(XYZ) = \\det(X)\\det(Y)\\det(Z)$, we have:\n$$ \\det(A) = \\det(L)\\det(D)\\det(L^{\\top}) $$\nSince $L$ and $L^{\\top}$ are unit triangular matrices, their determinants are $1$. Thus, $\\det(A) = \\det(D)$. The determinant of the diagonal matrix $D$ is the product of its diagonal entries.\n$$ \\det(A) = D_{11} \\cdot D_{22} \\cdot D_{33} \\cdot D_{44} \\cdot D_{55} $$\n$$ \\det(A) = 2 \\times \\frac{3}{2} \\times \\frac{4}{3} \\times \\frac{5}{4} \\times \\frac{6}{5} $$\nThis is a telescoping product:\n$$ \\det(A) = \\cancel{2} \\times \\frac{\\cancel{3}}{\\cancel{2}} \\times \\frac{\\cancel{4}}{\\cancel{3}} \\times \\frac{\\cancel{5}}{\\cancel{4}} \\times \\frac{6}{\\cancel{5}} = 6 $$\nThe determinant of the matrix $A$ is $6$.", "answer": "$$\n\\boxed{6}\n$$", "id": "3560937"}]}