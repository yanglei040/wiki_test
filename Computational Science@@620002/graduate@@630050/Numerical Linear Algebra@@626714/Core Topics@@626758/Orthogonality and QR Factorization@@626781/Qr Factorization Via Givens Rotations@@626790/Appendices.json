{"hands_on_practices": [{"introduction": "Understanding QR factorization via Givens rotations begins with mastering the core operation: using a single plane rotation to annihilate a specific matrix element. This exercise provides a concrete, step-by-step calculation to solidify your grasp of the underlying mechanics and build intuition for the geometry of the transformation ([@problem_id:1029885]). By working through this small example, you will practice applying the formulas that form the building blocks of the entire factorization process.", "problem": "Consider the $3 \\times 3$ matrix $A$ given by:\n\n$$\nA = \\begin{bmatrix} \n1  2  1 \\\\\n0  3  1 \\\\\n2  1  2 \n\\end{bmatrix}.\n$$\n\nCompute the QR decomposition of $A$ using Givens rotations, ensuring that the diagonal entries of the upper triangular matrix $R$ are positive. What is the $(2,3)$-entry of $R$?", "solution": "We perform two Givens rotations on the rows of $A$ to zero out the sub‐diagonal entries, keeping the diagonal of $R$ positive.\n\n1.  Zero the $(3,1)$‐entry.  Let\n   $$\n   c_1 = \\frac{a_{11}}{\\sqrt{a_{11}^2 + a_{31}^2}}\n       = \\frac{1}{\\sqrt{1+4}}\n       = \\frac{1}{\\sqrt5}, \n   \\quad\n   s_1 = \\frac{a_{31}}{\\sqrt{1+4}}\n       = \\frac{2}{\\sqrt5}.\n   $$\n   The Givens rotation $G_1$ in the $(1,3)$‐plane gives\n   $$\n   G_1 A = \\begin{bmatrix}\\sqrt5  \\frac{4}{\\sqrt5}  \\sqrt5\\\\\n                             0         3             1\\\\\n                             0         -\\frac{3}{\\sqrt5}  0\n            \\end{bmatrix}.\n   $$\n\n2.  Zero the new $(3,2)$‐entry.  Set\n   $$\n   c_2 = \\frac{3}{\\sqrt{9 + \\tfrac{9}{5}}}\n       = \\sqrt{\\frac56},\n   \\quad\n   s_2 = \\frac{-\\tfrac{3}{\\sqrt5}}{\\sqrt{9 + \\tfrac{9}{5}}}\n       = -\\frac{1}{\\sqrt6}.\n   $$\n   Applying $G_2$ to the last two rows yields\n   $$\n   G_2G_1 A\n     = \\begin{bmatrix}\n         \\sqrt5       \\tfrac{4}{\\sqrt5}   \\sqrt5 \\\\[6pt]\n         0            \\tfrac{3\\sqrt{30}}{5}  \\tfrac{\\sqrt{30}}{6} \\\\[4pt]\n         0            0                     r_{33}\n       \\end{bmatrix}\n     = R,\n   $$\n   with $r_{33}$ automatically positive by construction.  Hence the $(2,3)$‐entry of $R$ is\n   $$\n   r_{23} = \\frac{\\sqrt{30}}{6}.\n   $$", "answer": "$$\\boxed{\\frac{\\sqrt{30}}{6}}$$", "id": "1029885"}, {"introduction": "Moving from a manual calculation to a robust computer program requires careful consideration of numerical stability and algorithmic structure. This practice challenges you to implement the full QR factorization using Givens rotations, with a key constraint to avoid trigonometric functions, forcing a deeper understanding of the rotation's algebraic construction ([@problem_id:3236226]). Successfully completing this implementation demonstrates your ability to translate a theoretical method into practical, reliable code that can handle a variety of matrix structures.", "problem": "Implement a program that computes the thin-factorization of a real matrix into an orthogonal factor and an upper-triangular factor using Givens rotations, subject to the following constraints and checks.\n\nGiven a real matrix $A \\in \\mathbb{R}^{m \\times n}$ with $m \\ge n$, the goal is to find matrices $Q \\in \\mathbb{R}^{m \\times m}$ and $R \\in \\mathbb{R}^{m \\times n}$ such that $Q$ is orthogonal and $R$ is upper triangular, and they satisfy $A \\approx Q R$ up to floating-point roundoff. You must compute these factors using Givens rotations that zero individual subdiagonal elements by left-multiplication on rows. You are strictly forbidden from using any trigonometric functions; instead, compute the Givens parameters solely from the matrix elements to be annihilated. In particular, when eliminating an entry $b$ below a pivot $a$, your rotation must be constructed only from $a$ and $b$.\n\nFundamental base:\n- A square matrix $Q$ is orthogonal if $Q^\\mathsf{T} Q = I$.\n- A Givens rotation in the plane spanned by the $i$-th and $j$-th coordinate axes is defined by a $2 \\times 2$ block\n$$\nG_{(i,j)} = \\begin{bmatrix} c  s \\\\ -s  c \\end{bmatrix}\n$$\nwith real scalars $c$ and $s$ that satisfy $c^2 + s^2 = 1$, and identity entries elsewhere. Left-multiplication by $G_{(i,j)}$ mixes only rows $i$ and $j$ of the target matrix.\n\nYour task:\n- Implement a robust algorithm that for each column $j$ uses successive Givens rotations to annihilate entries $A_{i,j}$ for all $i  j$.\n- When eliminating an entry $b$ beneath a pivot $a$, determine $c$ and $s$ without trigonometric functions, using only $a$ and $b$. Your method must be well-scaled and numerically stable for very large, very small, or zero values of $a$ and $b$.\n- Accumulate the overall orthogonal factor as the product of the transposes of the applied Givens rotations so that the final factorization satisfies $A \\approx Q R$.\n\nVerification requirements:\n- Define a tolerance $\\tau = 10^{-10}$.\n- For each test matrix $A$, compute factors $Q$ and $R$ and verify the following:\n  1. Reconstruction: the relative Frobenius-norm error satisfies\n  $$\n  \\frac{\\lVert A - Q R \\rVert_F}{\\max\\{\\lVert A \\rVert_F, 1\\}} \\le \\tau.\n  $$\n  2. Orthogonality: the deviation from orthogonality satisfies\n  $$\n  \\lVert Q^\\mathsf{T} Q - I \\rVert_{\\max} \\le \\tau.\n  $$\n  3. Triangularity: the strict lower-triangular part of $R$ is small,\n  $$\n  \\max_{i  j} |R_{i,j}| \\le \\tau.\n  $$\n- Your program must return, for each test matrix, a single boolean that is true if and only if all three checks above pass.\n\nTest suite:\nUse exactly the following five real matrices (each with $m \\ge n$):\n\n1. $A_1 \\in \\mathbb{R}^{4 \\times 3}$: The rows are:\n   $\n   (\\,\\,2,\\,-1,\\,0\\,),\\quad (\\,\\,3,\\,4,\\,1\\,),\\quad (\\,\\,0,\\,1,\\,3\\,),\\quad (\\,\\,5,\\,-2,\\,2\\,).\n   $\n\n2. $A_2 \\in \\mathbb{R}^{5 \\times 3}$: The rows are:\n   $\n   (\\,\\,10^{-12},\\,2,\\,-3\\,),\\quad (\\,\\,4,\\,-5,\\,6\\,),\\quad (\\,\\,7,\\,8,\\,-10^{-12}\\,),\n   $\n   $\n   (\\,\\,-2,\\,0.5,\\,1.5\\,),\\quad (\\,\\,3,\\,-10^{-9},\\,2.5\\,).\n   $\n\n3. $A_3 \\in \\mathbb{R}^{3 \\times 3}$ (already upper triangular): The rows are:\n   $\n   (\\,\\,4,\\,-1,\\,2\\,),\\quad (\\,\\,0,\\,3,\\,-5\\,),\\quad (\\,\\,0,\\,0,\\,2\\,).\n   $\n\n4. $A_4 \\in \\mathbb{R}^{6 \\times 4}$: The rows are:\n   $\n   (\\,\\,1,\\,2,\\,3,\\,4\\,),\\quad (\\,\\,2,\\,0,\\,-1,\\,1\\,),\\quad (\\,\\,0,\\,-3,\\,1,\\,2\\,),\n   $\n   $\n   (\\,\\,-1,\\,4,\\,0,\\,-2\\,),\\quad (\\,\\,3,\\,-1,\\,2,\\,0\\,),\\quad (\\,\\,5,\\,2,\\,-2,\\,1\\,).\n   $\n\n5. $A_5 \\in \\mathbb{R}^{4 \\times 3}$ (rank-deficient columns: the third column equals the first plus twice the second): The rows are:\n   $\n   (\\,\\,1,\\,0,\\,1\\,),\\quad (\\,\\,2,\\,-1,\\,0\\,),\\quad (\\,\\,3,\\,1,\\,5\\,),\\quad (\\,\\,4,\\,2,\\,8\\,).\n   $\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with one boolean per test matrix in the order $A_1$ through $A_5$. For example, the output should look like\n$\n[\\mathrm{True},\\mathrm{True},\\mathrm{True},\\mathrm{True},\\mathrm{True}]\n$\nif all tests pass.\n\nAngle and physical units:\n- No angles or physical units are required in this problem; do not report any angles or physical quantities.\n\nImplementation constraints:\n- Do not call any trigonometric functions. You may use square roots and the Euclidean norm computed from $a$ and $b$.\n- The implementation language is specified in the final answer section; no input reading is required.", "solution": "The user requires an implementation of the QR factorization for a real matrix $A \\in \\mathbb{R}^{m \\times n}$ (with $m \\ge n$) using Givens rotations. The factorization should produce an orthogonal matrix $Q \\in \\mathbb{R}^{m \\times m}$ and an upper triangular matrix $R \\in \\mathbb{R}^{m \\times n}$ such that $A \\approx QR$. The implementation must not use trigonometric functions and must be numerically stable.\n\n### Problem Validation\n\nFirst, I will validate the problem statement against the established criteria.\n\n**Step 1: Extract Givens**\n\n-   **Task**: Compute the QR factorization of a matrix $A \\in \\mathbb{R}^{m \\times n}$ ($m \\ge n$) using Givens rotations.\n-   **Output Matrices**: An orthogonal matrix $Q \\in \\mathbb{R}^{m \\times m}$ and an upper triangular matrix $R \\in \\mathbb{R}^{m \\times n}$.\n-   **Method**: Sequentially annihilate subdiagonal elements $A_{i,j}$ ($i  j$) by left-multiplying with Givens rotation matrices $G$.\n-   **Constraint on Givens Parameters**: The parameters $c$ and $s$ for a rotation must be computed from the pivot element $a$ and the element to be zeroed $b$ without using trigonometric functions. The computation must be numerically stable.\n-   **Accumulation of Q**: $Q$ is formed by accumulating the transposes of the individual Givens rotation matrices: $Q = G_1^\\mathsf{T} G_2^\\mathsf{T} \\cdots G_k^\\mathsf{T}$.\n-   **Verification**: Three checks are required with a tolerance $\\tau = 10^{-10}$:\n    1.  Reconstruction error: $\\frac{\\lVert A - Q R \\rVert_F}{\\max\\{\\lVert A \\rVert_F, 1\\}} \\le \\tau$.\n    2.  Orthogonality error: $\\lVert Q^\\mathsf{T} Q - I \\rVert_{\\max} \\le \\tau$.\n    3.  Triangularity error: $\\max_{i  j} |R_{i,j}| \\le \\tau$.\n-   **Test Cases**: Five specific matrices $A_1, \\dots, A_5$ are provided.\n-   **Final Output**: A list of booleans, one for each test case, indicating if all three checks pass.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem is scientifically grounded, well-posed, and objective. It describes a standard, fundamental algorithm in numerical linear algebra. The constraints and verification checks are precise and formalizable.\n\nThere exists a minor inconsistency: the problem is titled \"thin-factorization,\" but the explicit definitions of the output matrices ($Q \\in \\mathbb{R}^{m \\times m}$, $R \\in \\mathbb{R}^{m \\times n}$) describe what is commonly known as the *full* QR factorization. The verification check for orthogonality, $\\lVert Q^\\mathsf{T} Q - I \\rVert_{\\max} \\le \\tau$, further confirms that the full $m \\times m$ identity matrix is expected, reinforcing the requirement for the full factorization. This discrepancy is a misnomer in the title rather than a substantive contradiction. The detailed instructions in the problem body are consistent and unambiguous.\n\n**Step 3: Verdict and Action**\n\nThe problem is deemed **valid**. I will proceed with the implementation of the full QR factorization as explicitly specified by the dimensions and verification requirements.\n\n### Algorithmic Design and Principles\n\nThe core of the algorithm is to transform the matrix $A$ into an upper triangular matrix $R$ by applying a sequence of Givens rotations from the left:\n$$\nG_k \\cdots G_2 G_1 A = R\n$$\nEach Givens rotation $G$ is an orthogonal matrix, so their product is also orthogonal. Let $Q_{\\text{applied}} = G_k \\cdots G_1$. Then $Q_{\\text{applied}} A = R$, which implies $A = Q_{\\text{applied}}^\\mathsf{T} R$. The desired orthogonal factor is thus $Q = Q_{\\text{applied}}^\\mathsf{T} = (G_k \\cdots G_1)^\\mathsf{T} = G_1^\\mathsf{T} G_2^\\mathsf{T} \\cdots G_k^\\mathsf{T}$.\n\nWe can implement this by initializing $R=A$ and $Q=I_m$ (the $m \\times m$ identity matrix) and iteratively updating them. For each Givens rotation $G$ applied to zero an element, we update:\n1.  $R \\leftarrow G R$\n2.  $Q \\leftarrow Q G^\\mathsf{T}$\n\n**Givens Rotation**\n\nA Givens rotation matrix $G$ is used to zero out a specific element in a vector. To annihilate an element $b$ at row $i$ using a pivot $a$ at row $j$ (in the same column), we apply a rotation in the $(j, i)$-plane. The transformation on the vector $\\begin{pmatrix} a \\\\ b \\end{pmatrix}$ is:\n$$\n\\begin{pmatrix} c  s \\\\ -s  c \\end{pmatrix} \\begin{pmatrix} a \\\\ b \\end{pmatrix} = \\begin{pmatrix} \\sqrt{a^2+b^2} \\\\ 0 \\end{pmatrix}\n$$\nThis requires $c^2 + s^2 = 1$. The parameters $c$ and $s$ can be determined without trigonometric functions:\n$$\nr = \\sqrt{a^2+b^2}, \\quad c = \\frac{a}{r}, \\quad s = \\frac{b}{r}\n$$\nFor numerical stability, especially to prevent overflow with large $a, b$ or precision loss with small $a, b$, the calculation of $r = \\sqrt{a^2+b^2}$ is performed using a robust function equivalent to `hypot(a, b)`.\n\n**Procedure**\n\nThe algorithm proceeds column by column, from $j=0$ to $n-1$. For each column $j$, it iterates through the rows below the diagonal, from $i=j+1$ to $m-1$, zeroing out the element $R_{i,j}$.\n\nFor each element $R_{i,j}$ to be zeroed:\n1.  The pivot is $a = R_{j,j}$ and the target element is $b = R_{i,j}$.\n2.  The rotation parameters $c$ and $s$ are computed stably. If $b$ is already zero, the rotation is the identity ($c=1, s=0$).\n3.  The rotation is applied to rows $j$ and $i$ of matrix $R$. For each column $k$ from $j$ to $n-1$, the elements $(R_{j,k}, R_{i,k})$ are updated:\n    $$\n    \\begin{pmatrix} R'_{j,k} \\\\ R'_{i,k} \\end{pmatrix} = \\begin{pmatrix} c  s \\\\ -s  c \\end{pmatrix} \\begin{pmatrix} R_{j,k} \\\\ R_{i,k} \\end{pmatrix}\n    $$\n4.  The matrix $Q$ is updated by post-multiplying with $G^\\mathsf{T}$. This mixes columns $j$ and $i$ of $Q$:\n    $$\n    \\begin{pmatrix} Q'_{\\text{col } j}  Q'_{\\text{col } i} \\end{pmatrix} = \\begin{pmatrix} Q_{\\text{col } j}  Q_{\\text{col } i} \\end{pmatrix} \\begin{pmatrix} c  -s \\\\ s  c \\end{pmatrix}\n    $$\n\nThis process is repeated until all subdiagonal elements are zero, resulting in the final matrices $Q$ and $R$. The verification checks are then performed on the computed factors.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef givens_qr_factorization(A: np.ndarray) - tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Computes the full QR factorization of a matrix A using Givens rotations.\n\n    Args:\n        A (np.ndarray): An m x n real matrix with m = n.\n\n    Returns:\n        tuple[np.ndarray, np.ndarray]: A tuple (Q, R) where Q is an m x m\n        orthogonal matrix and R is an m x n upper triangular matrix.\n    \"\"\"\n    m, n = A.shape\n    # Use float64 for higher precision to meet the tight tolerance\n    R = A.copy().astype(np.float64)\n    Q = np.identity(m, dtype=np.float64)\n\n    # Iterate through columns to introduce zeros\n    for j in range(n):\n        # Iterate through rows below the diagonal to zero out elements\n        for i in range(j + 1, m):\n            # Pivot element is R[j, j], element to zero is R[i, j]\n            a = R[j, j]\n            b = R[i, j]\n\n            # If the subdiagonal element is already zero, no rotation is needed.\n            # Using a small tolerance check is robust for floating point numbers.\n            if np.isclose(b, 0.0):\n                continue\n\n            # Compute Givens rotation parameters c and s stably.\n            # np.hypot(a, b) calculates sqrt(a^2 + b^2) without intermediate\n            # overflow or underflow. This satisfies the problem's constraint\n            # as it relies only on arithmetic and square roots.\n            r = np.hypot(a, b)\n            c = a / r\n            s = b / r\n\n            # The Givens rotation matrix G has the 2x2 block [[c, s], [-s, c]].\n            # Update R: R_new = G @ R_old.\n            # This transformation affects rows j and i of R.\n            # new_row_j = c * old_row_j + s * old_row_i\n            # new_row_i = -s * old_row_j + c * old_row_i\n            # We copy the slices to avoid overwriting data that's still needed.\n            R_j_row = R[j, j:].copy()\n            R_i_row = R[i, j:].copy()\n            R[j, j:] = c * R_j_row + s * R_i_row\n            R[i, j:] = -s * R_j_row + c * R_i_row\n\n            # Update Q: Q_new = Q_old @ G.T.\n            # G.T has the 2x2 block [[c, -s], [s, c]].\n            # This transformation affects columns j and i of Q.\n            # new_col_j = c * old_col_j + s * old_col_i\n            # new_col_i = -s * old_col_j + c * old_col_i\n            Q_j_col = Q[:, j].copy()\n            Q_i_col = Q[:, i].copy()\n            Q[:, j] = c * Q_j_col + s * Q_i_col\n            Q[:, i] = -s * Q_j_col + c * Q_i_col\n\n    return Q, R\n\ndef solve():\n    \"\"\"\n    Main function to run the Givens QR factorization on test cases and verify.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        np.array([[2, -1, 0], [3, 4, 1], [0, 1, 3], [5, -2, 2]], dtype=float),\n        np.array([[1e-12, 2, -3], [4, -5, 6], [7, 8, -1e-12], [-2, 0.5, 1.5], [3, -1e-9, 2.5]], dtype=float),\n        np.array([[4, -1, 2], [0, 3, -5], [0, 0, 2]], dtype=float),\n        np.array([[1, 2, 3, 4], [2, 0, -1, 1], [0, -3, 1, 2], [-1, 4, 0, -2], [3, -1, 2, 0], [5, 2, -2, 1]], dtype=float),\n        np.array([[1, 0, 1], [2, -1, 0], [3, 1, 5], [4, 2, 8]], dtype=float),\n    ]\n\n    tau = 1e-10\n    results = []\n\n    for A in test_cases:\n        m, n = A.shape\n        Q, R = givens_qr_factorization(A)\n\n        # 1. Reconstruction check\n        norm_A = np.linalg.norm(A, 'fro')\n        recon_err = np.linalg.norm(A - Q @ R, 'fro') / max(norm_A, 1.0)\n        check1 = recon_err = tau\n\n        # 2. Orthogonality check\n        I_m = np.identity(m)\n        ortho_err = np.max(np.abs(Q.T @ Q - I_m))\n        check2 = ortho_err = tau\n\n        # 3. Triangularity check\n        # np.tril(R, k=-1) extracts the strict lower triangular part of R.\n        tri_err = np.max(np.abs(np.tril(R, k=-1)))\n        check3 = tri_err = tau\n        \n        results.append(check1 and check2 and check3)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3236226"}, {"introduction": "The true power and complexity of numerical algorithms are often revealed in the context of large-scale, sparse problems. This exercise explores the critical issue of 'fill-in,' where applying Givens rotations in a naive order can destroy sparsity and lead to catastrophic performance degradation ([@problem_id:3569157]). By analyzing the connection between matrix structure and factorization efficiency, you will learn to think combinatorially about numerical algorithms, a key skill in high-performance scientific computing.", "problem": "Let $k \\ge 3$ be an integer and consider the sparse matrix $A \\in \\mathbb{R}^{(k+1)\\times (k+1)}$ with columns indexed by $0,1,2,\\dots,k$ and rows indexed by $0,1,2,\\dots,k$, defined by\n$$\nA_{0,0}=1,\\quad A_{i,0}=1\\ \\text{for}\\ i=1,\\dots,k,\\quad A_{i,i}=1\\ \\text{for}\\ i=1,\\dots,k,\n$$\nand all other entries equal to $0$. In words, the first column has a nonzero in every row, and each other column $i \\in \\{1,\\dots,k\\}$ has a single nonzero in its own row $i$.\n\nYou perform a thin QR factorization $A=Q R$ using Givens rotations, with the following protocol: process the columns in the order $0,1,2,\\dots,k$; for each column $j$, apply a sequence of Givens rotations on pairs of rows to zero all entries of column $j$ below the diagonal position $(j,j)$ while preserving orthogonality of $Q$ and upper triangularity of $R$.\n\nStarting from the core facts that (i) a Givens rotation is an orthogonal transformation that acts as the identity on all but a selected $2\\times 2$ principal subspace of rows, and (ii) without column pivoting the nonzero pattern of the upper triangular factor $R$ in QR factorization equals the nonzero pattern of the Cholesky factor of $A^{\\top}A$ under the same column ordering, answer the following:\n\n1. Construct the column-intersection graph associated with $A$ and explain, using graph elimination, why processing column $0$ first causes severe fill-in when forming $R$.\n2. Determine, as a closed-form expression in $k$, the exact number of strictly upper-triangular entries of the submatrix of $R$ corresponding to columns $1,2,\\dots,k$ that become nonzero solely due to fill-in caused by this ordering (i.e., entries that are structurally zero in the input but nonzero in $R$).\n3. Propose a column ordering strategy that avoids this fill-in and justify it from a combinatorial standpoint.\n\nYour final answer should be the single closed-form expression asked in item 2. No rounding is required.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is based on established principles of numerical linear algebra, specifically sparse QR factorization. All necessary information is provided, and the questions are unambiguous. The problem is therefore valid, and I shall proceed with a full solution.\n\nThe matrix $A \\in \\mathbb{R}^{(k+1)\\times (k+1)}$ for an integer $k \\ge 3$ is defined by its nonzero entries: $A_{0,0}=1$, $A_{i,0}=1$ for $i=1,\\dots,k$, and $A_{i,i}=1$ for $i=1,\\dots,k$. All other entries are zero. The rows and columns are indexed from $0$ to $k$.\n\nLet $c_j$ denote the $j$-th column of $A$. Based on the definition:\n- The first column, $c_0$, has entries $A_{i,0}=1$ for all $i \\in \\{0, 1, \\dots, k\\}$. Thus, $c_0$ is the vector of all ones.\n- For any other column $j \\in \\{1, \\dots, k\\}$, the only nonzero entry is $A_{j,j}=1$. Thus, $c_j$ is the standard basis vector $e_j$ (with a $1$ in the $j$-th position, using $0$-based indexing).\n\nFor example, with $k=3$, the matrix $A$ is:\n$$\nA = \\begin{pmatrix}\n1  0  0  0 \\\\\n1  1  0  0 \\\\\n1  0  1  0 \\\\\n1  0  0  1\n\\end{pmatrix}\n$$\nThis matrix is lower triangular. However, as we will see, performing QR factorization by eliminating subdiagonal elements column-by-column from left to right introduces substantial fill-in.\n\nThe problem states a crucial fact: the nonzero pattern of the upper triangular factor $R$ from the QR factorization of $A$ is identical to the nonzero pattern of the Cholesky factor of the matrix $A^{\\top}A$. This allows us to analyze the structure of $A^{\\top}A$ and its symbolic Cholesky factorization to determine the fill-in in $R$.\n\nLet $B = A^{\\top}A$. The entry $B_{ij}$ is the inner product of columns $c_i$ and $c_j$ of $A$.\n- For $i=j=0$: $B_{00} = c_0^{\\top} c_0 = \\sum_{l=0}^{k} 1^2 = k+1$.\n- For $i=0$ and $j \\in \\{1, \\dots, k\\}$: $B_{0j} = c_0^{\\top} c_j = c_0^{\\top} e_j = 1$. By symmetry, $B_{j0}=1$.\n- For $i, j \\in \\{1, \\dots, k\\}$ and $i \\neq j$: $B_{ij} = c_i^{\\top} c_j = e_i^{\\top} e_j = 0$.\n- For $i \\in \\{1, \\dots, k\\}$: $B_{ii} = c_i^{\\top} c_i = e_i^{\\top} e_i = 1$.\n\nSo, the matrix $B=A^{\\top}A$ has the structure:\n$$\nB = \\begin{pmatrix}\nk+1  1  1  \\dots  1 \\\\\n1  1  0  \\dots  0 \\\\\n1  0  1  \\dots  0 \\\\\n\\vdots  \\vdots  \\vdots  \\ddots  \\vdots \\\\\n1  0  0  \\dots  1\n\\end{pmatrix}\n$$\n\n**1. Column-intersection graph and fill-in**\n\nThe column-intersection graph of $A$, denoted $G_A$, has vertices $\\{0, 1, \\dots, k\\}$ corresponding to the columns of $A$. An edge exists between vertices $i$ and $j$ if and only if columns $c_i$ and $c_j$ both have a nonzero entry in the same row. This is equivalent to the condition that $B_{ij} = (A^{\\top}A)_{ij} \\neq 0$ for $i \\neq j$.\n\nFrom the structure of $B$, we can construct $G_A$:\n- An edge $(0, j)$ exists for all $j \\in \\{1, \\dots, k\\}$ because $B_{0j}=1$.\n- No edge $(i, j)$ exists for $i, j \\in \\{1, \\dots, k\\}$ with $i \\neq j$, because $B_{ij}=0$.\nThis graph is a \"star graph\" with vertex $0$ as the center and vertices $\\{1, 2, \\dots, k\\}$ as the leaves.\n\nThe process of forming the Cholesky factor (or performing Gaussian elimination) can be modeled on this graph. When a vertex $v$ is eliminated, its neighbors become a clique (i.e., they are all pairwise connected). These new edges correspond to \"fill-in\"—entries that were zero in $B$ but become nonzero in the Cholesky factor.\n\nThe problem specifies processing columns in the order $0, 1, 2, \\dots, k$. This corresponds to eliminating vertices in $G_A$ in the same order. We start by eliminating vertex $0$. The neighbors of vertex $0$ are the set $\\{1, 2, \\dots, k\\}$. When vertex $0$ is eliminated, edges are added between all pairs of these neighbors. That is, for every distinct pair $i, j \\in \\{1, 2, \\dots, k\\}$, a new edge $(i, j)$ is created.\n\nThe original subgraph induced by vertices $\\{1, \\dots, k\\}$ was empty (no edges). After eliminating vertex $0$, this subgraph becomes a complete graph (a clique). This signifies that the corresponding submatrix in the Cholesky factor of $B$ (and thus in $R$) becomes completely dense. This is the \"severe fill-in\" caused by this ordering.\n\n**2. Number of fill-in entries**\n\nWe are asked for the number of strictly upper-triangular entries of the submatrix of $R$ corresponding to columns $1, 2, \\dots, k$ that are fill-in. Let us denote this $k \\times k$ submatrix as $R_{1:k, 1:k}$.\n\n- **Original structure**: The columns of the original matrix $A$ from $1$ to $k$ are the standard basis vectors $e_1, \\dots, e_k$. Thus, for any pair of indices $(i, j)$ such that $1 \\le i  j \\le k$, the entry $A_{ij}$ is $0$. The strictly upper-triangular part of the submatrix of $A$ corresponding to columns $\\{1, \\dots, k\\}$ and rows $\\{1, \\dots, k\\}$ is entirely zero.\n- **Structure after factorization**: As explained above, eliminating column $0$ first causes the subgraph on vertices $\\{1, \\dots, k\\}$ to become a clique. This means that in the upper triangular factor $R$, the submatrix $R_{1:k, 1:k}$ will be a dense upper triangular matrix. Every entry $R_{ij}$ for $1 \\le i \\le j \\le k$ will be nonzero.\n- **Counting fill-in**: The fill-in entries are those that were zero in $A$ but are nonzero in $R$. We are interested in the strictly upper-triangular entries of the submatrix for columns $1, \\dots, k$. These are the entries $R_{ij}$ with $1 \\le i  j \\le k$.\nSince all these entries were zero in $A$ and become nonzero in $R$, the number of fill-in entries is the total count of such positions. This is the number of elements in the strict upper triangle of a $k \\times k$ matrix.\n\nThe number of such entries is given by the sum:\n$$ \\sum_{j=2}^{k} (j-1) = \\sum_{i=1}^{k-1} i = \\frac{(k-1)k}{2} = \\binom{k}{2} $$\nThis expression gives the exact number of fill-in entries as requested. For $k \\ge 3$, this number is always positive.\n\n**3. Optimal column ordering**\n\nThe severe fill-in resulted from eliminating the highest-degree vertex (the center of the star graph) first. To minimize fill-in, a general heuristic is the \"minimum degree\" ordering, which prioritizes eliminating vertices with the fewest neighbors.\n\nIn the graph $G_A$, vertex $0$ has degree $k$, while each vertex $j \\in \\{1, \\dots, k\\}$ has degree $1$. The minimum degree ordering would therefore eliminate the vertices $1, 2, \\dots, k$ (in any sequence) before eliminating vertex $0$.\nLet's consider the ordering $1, 2, \\dots, k, 0$.\n- Eliminating vertex $1$: Its only neighbor is $0$. No pair of neighbors to connect, so no fill-in.\n- Eliminating vertex $2$: Its only neighbor is $0$. No fill-in.\n- ...\n- Eliminating vertex $k$: Its only neighbor is $0$. No fill-in.\nAfter eliminating all vertices from $1$ to $k$, no new edges have been created. The graph is left with the single isolated vertex $0$. Then, eliminating vertex $0$ also creates no fill-in.\nThis ordering is a \"perfect elimination ordering\" as it produces zero fill-in.\n\nTherefore, any ordering that processes column $0$ last, such as $(1, 2, \\dots, k, 0)$, will avoid the fill-in described. From a combinatorial standpoint, this is justified by applying the minimum degree algorithm to the column-intersection graph.\n\nThe final answer required is the closed-form expression from part 2.\nNumber of fill-in entries = $\\frac{k(k-1)}{2}$.", "answer": "$$\\boxed{\\frac{k(k-1)}{2}}$$", "id": "3569157"}]}