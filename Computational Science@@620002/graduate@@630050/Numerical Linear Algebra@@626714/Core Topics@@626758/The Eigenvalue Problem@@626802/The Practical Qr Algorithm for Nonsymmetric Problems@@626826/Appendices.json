{"hands_on_practices": [{"introduction": "This practice demonstrates the fundamental limitation of the unshifted QR algorithm, which can stagnate on certain classes of matrices. By constructing a specific example where the algorithm cycles, you will see firsthand why shifts are not just an optimization but a necessity for convergence. This exercise illuminates how the elegant Wilkinson shift strategy effectively breaks such cycles, a cornerstone of modern eigenvalue solvers. [@problem_id:3593257]", "problem": "Construct a concrete, self-contained computational experiment that demonstrates a failure mode of the unshifted orthogonal-triangular (QR) algorithm on a real, nonsymmetric upper Hessenberg matrix and how introducing Wilkinson shifts breaks that cycle. Work strictly in exact mathematical terms and implement the following from first principles.\n\nYou may use only the following fundamental base:\n- The definition of a real upper Hessenberg matrix: a square matrix $A \\in \\mathbb{R}^{n \\times n}$ with $A_{i,j} = 0$ for all $i > j + 1$.\n- The definition of the unshifted orthogonal-triangular (QR) step: given a matrix $A \\in \\mathbb{R}^{n \\times n}$, compute a QR factorization $A = Q R$ where $Q$ is orthogonal and $R$ is upper triangular with strictly positive diagonal entries, and define the next iterate as $A^{+} = R Q$.\n- The definition of the Wilkinson shift for nonsymmetric problems: let $A \\in \\mathbb{R}^{n \\times n}$, form the trailing $2 \\times 2$ principal submatrix $T = A_{n-1:n, n-1:n}$; let $\\lambda_1,\\lambda_2 \\in \\mathbb{C}$ be the eigenvalues of $T$; define the shift $\\mu \\in \\mathbb{C}$ to be whichever of $\\{\\lambda_1,\\lambda_2\\}$ minimizes the modulus $|\\mu - A_{n,n}|$; the shifted step is computed by forming a QR factorization $A - \\mu I = Q R$ and setting $A^{+} = R Q + \\mu I$.\n- The uniqueness of the QR factorization with positive diagonal: if $A \\in \\mathbb{R}^{n \\times n}$ is nonsingular and $A = Q R$ with $Q$ orthogonal and $R$ upper triangular with strictly positive diagonal, then $Q$ and $R$ are uniquely determined.\n\nYou must implement the following.\n1) Construct a concrete real, nonsymmetric, orthogonal $3 \\times 3$ upper Hessenberg matrix $H(\\theta_1,\\theta_2)$ as the product of two real Givens rotations acting on adjacent coordinate planes:\n   - Define the planar rotation $G_{12}(\\theta_1) \\in \\mathbb{R}^{3 \\times 3}$ by\n     $$\n     G_{12}(\\theta_1) =\n     \\begin{bmatrix}\n     \\cos(\\theta_1) & -\\sin(\\theta_1) & 0 \\\\\n     \\sin(\\theta_1) & \\cos(\\theta_1) & 0 \\\\\n     0 & 0 & 1\n     \\end{bmatrix}.\n     $$\n   - Define the planar rotation $G_{23}(\\theta_2) \\in \\mathbb{R}^{3 \\times 3}$ by\n     $$\n     G_{23}(\\theta_2) =\n     \\begin{bmatrix}\n     1 & 0 & 0 \\\\\n     0 & \\cos(\\theta_2) & -\\sin(\\theta_2) \\\\\n     0 & \\sin(\\theta_2) & \\cos(\\theta_2)\n     \\end{bmatrix}.\n     $$\n   - Set $H(\\theta_1,\\theta_2) = G_{12}(\\theta_1)\\, G_{23}(\\theta_2)$. Prove in your solution that $H(\\theta_1,\\theta_2)$ is orthogonal, is upper Hessenberg, and is nonsymmetric for generic $\\theta_1,\\theta_2$.\n\n2) Define the subdiagonal measure for any square matrix $A \\in \\mathbb{C}^{n \\times n}$ by\n   $$\n   S(A) \\stackrel{\\mathrm{def}}{=} \\left\\| \\big( A_{2,1}, A_{3,2}, \\dots, A_{n,n-1} \\big) \\right\\|_2.\n   $$\n   This is the Euclidean norm of the first subdiagonal. In your code, apply this definition literally for any square matrix, even if it ceases to be Hessenberg after an iteration.\n\n3) Implement one unshifted step and one Wilkinson-shifted step as defined above. To remove sign ambiguity and to align with the uniqueness property, when computing the unshifted QR factorization $A = Q R$, you must flip the signs of columns of $Q$ and rows of $R$ so that the diagonal entries of $R$ are strictly positive real numbers, before forming $A^{+} = R Q$. For the shifted step with possibly complex $\\mu$, no positivity convention is required.\n\n4) For each test, compute the ratios\n   $$\n   r_{\\mathrm{unsh}} \\stackrel{\\mathrm{def}}{=} \n   \\begin{cases}\n   \\dfrac{S(A^{+}_{\\mathrm{unsh}})}{S(A_0)} & \\text{if } S(A_0) \\neq 0,\\\\\n   0 & \\text{if } S(A_0) = 0,\n   \\end{cases}\n   \\qquad\n   r_{\\mathrm{shift}} \\stackrel{\\mathrm{def}}{=}\n   \\begin{cases}\n   \\dfrac{S(A^{+}_{\\mathrm{shift}})}{S(A_0)} & \\text{if } S(A_0) \\neq 0,\\\\\n   0 & \\text{if } S(A_0) = 0,\n   \\end{cases}\n   $$\n   where $A_0 = H(\\theta_1,\\theta_2)$, $A^{+}_{\\mathrm{unsh}}$ is the result of a single unshifted step applied to $A_0$, and $A^{+}_{\\mathrm{shift}}$ is the result of a single Wilkinson-shifted step applied to $A_0$.\n\n5) Angle unit requirement: interpret all angles $\\theta$ in radians.\n\nTest suite and answer specification:\n- Use the following three tests, each specified by a pair $(\\theta_1,\\theta_2)$ in radians.\n  - Test $1$ (general nonsymmetric orthogonal upper Hessenberg): $\\theta_1 = 0.4$, $\\theta_2 = -0.7$.\n  - Test $2$ (boundary case, already block upper triangular): $\\theta_1 = 0.9$, $\\theta_2 = 0$.\n  - Test $3$ (another general nonsymmetric orthogonal upper Hessenberg): $\\theta_1 = -1.1$, $\\theta_2 = 0.6$.\n- For each test, compute $r_{\\mathrm{unsh}}$ and $r_{\\mathrm{shift}}$ as defined above. These are real-valued nonnegative floats.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order\n  $$\n  \\big[ r_{\\mathrm{unsh}}^{(1)}, r_{\\mathrm{shift}}^{(1)}, r_{\\mathrm{unsh}}^{(2)}, r_{\\mathrm{shift}}^{(2)}, r_{\\mathrm{unsh}}^{(3)}, r_{\\mathrm{shift}}^{(3)} \\big].\n  $$\n  No other output is permitted.\n\nYour implementation must be correct for the provided test suite and scientifically well-justified from the definitions above. Emphasize the logical reasoning that explains why the unshifted step cycles on these inputs and why the Wilkinson shift breaks that cycle. The output quantities are floats as specified, with angles in radians.", "solution": "The problem statement is a valid, self-contained computational exercise in numerical linear algebra. It asks for the construction and analysis of a specific failure mode in the unshifted QR algorithm and its resolution using a Wilkinson shift.\n\nThe experiment is based on a real, nonsymmetric, orthogonal upper Hessenberg matrix $H$. We will first establish the properties of this matrix, then analyze the behavior of the two QR algorithm variants when applied to it.\n\n### Construction and Properties of the Matrix $H(\\theta_1, \\theta_2)$\n\nThe matrix is defined as the product of two Givens rotations in $\\mathbb{R}^3$: $H(\\theta_1, \\theta_2) = G_{12}(\\theta_1) G_{23}(\\theta_2)$. Let $c_k = \\cos(\\theta_k)$ and $s_k = \\sin(\\theta_k)$ for $k=1,2$. The matrices are:\n$$\nG_{12}(\\theta_1) =\n\\begin{bmatrix}\nc_1 & -s_1 & 0 \\\\\ns_1 &  c_1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix},\n\\quad\nG_{23}(\\theta_2) =\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & c_2 & -s_2 \\\\\n0 & s_2 &  c_2\n\\end{bmatrix}.\n$$\nThe product is calculated as:\n$$\nH(\\theta_1, \\theta_2) =\n\\begin{bmatrix}\nc_1 & -s_1 & 0 \\\\\ns_1 &  c_1 & 0 \\\\\n0 & 0 & 1\n\\end{bmatrix}\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\n0 & c_2 & -s_2 \\\\\n0 & s_2 &  c_2\n\\end{bmatrix}\n=\n\\begin{bmatrix}\nc_1 & -s_1 c_2 & s_1 s_2 \\\\\ns_1 &  c_1 c_2 & -c_1 s_2 \\\\\n0 & s_2 & c_2\n\\end{bmatrix}.\n$$\n\nWe now prove its required properties.\n1.  **Orthogonality**: A Givens rotation matrix is orthogonal. The product of two orthogonal matrices is orthogonal. Let $Q_1, Q_2$ be orthogonal matrices, so $Q_1^T Q_1 = I$ and $Q_2^T Q_2 = I$. Then their product $Q_1 Q_2$ satisfies $(Q_1 Q_2)^T (Q_1 Q_2) = Q_2^T Q_1^T Q_1 Q_2 = Q_2^T I Q_2 = Q_2^T Q_2 = I$. Since $G_{12}(\\theta_1)$ and $G_{23}(\\theta_2)$ are orthogonal, their product $H(\\theta_1, \\theta_2)$ is also an orthogonal matrix.\n\n2.  **Upper Hessenberg Form**: A matrix $A$ is upper Hessenberg if $A_{i,j}=0$ for all $i > j+1$. For a $3 \\times 3$ matrix, this condition only requires the entry $A_{3,1}$ to be zero. From the computed form of $H(\\theta_1, \\theta_2)$, the entry $H_{3,1}$ is $0$. Thus, $H$ is an upper Hessenberg matrix.\n\n3.  **Nonsymmetry**: A matrix $H$ is symmetric if $H = H^T$. The transpose of $H$ is:\n    $$\n    H^T =\n    \\begin{bmatrix}\n    c_1 & s_1 & 0 \\\\\n    -s_1 c_2 & c_1 c_2 & s_2 \\\\\n    s_1 s_2 & -c_1 s_2 & c_2\n    \\end{bmatrix}.\n    $$\n    For $H = H^T$, we must have, for example, $H_{1,2} = H_{2,1}$ and $H_{1,3}=H_{3,1}$.\n    -   $H_{1,3} = s_1 s_2$ and $H_{3,1} = 0$. For these to be equal, we require $s_1 s_2 = 0$, which implies $\\sin(\\theta_1)=0$ or $\\sin(\\theta_2)=0$.\n    -   $H_{1,2} = -s_1 c_2$ and $H_{2,1} = s_1$. For these to be equal, we require $-s_1 c_2 = s_1$, or $s_1(1+c_2)=0$.\n    Symmetry thus requires restrictive conditions on $\\theta_1$ and $\\theta_2$ (e.g., being integer multiples of $\\pi$). For generic angles, such as those provided in the test suite, these conditions are not met, and the matrix $H$ is nonsymmetric.\n\n### Failure of the Unshifted QR Algorithm\n\nThe unshifted QR step is defined by $A_0 = Q_0 R_0$ and $A_1 = R_0 Q_0$. A critical detail is the uniqueness of the QR factorization for a nonsingular matrix $A_0$ when the diagonal entries of $R_0$ are constrained to be strictly positive.\n\nOur starting matrix $A_0 = H(\\theta_1, \\theta_2)$ is orthogonal. Consider its factorization into an orthogonal matrix $Q_0$ and an upper-triangular matrix $R_0$. One trivial factorization is $A_0 = A_0 \\cdot I$, where $Q_0 = A_0$ and $R_0 = I$. The matrix $R_0=I$ is upper triangular and its diagonal entries are all $1$, which are strictly positive. By the uniqueness property, this must be *the* required QR factorization.\n\nGiven $Q_0 = A_0$ and $R_0=I$, the next iterate of the unshifted QR algorithm is:\n$$\nA_1 = R_0 Q_0 = I \\cdot A_0 = A_0.\n$$\nThe algorithm stagnates immediately: $A_{k+1} = A_k$ for all $k \\ge 0$. The subdiagonal entries do not change. The subdiagonal norm for a $3 \\times 3$ matrix $A$ is $S(A) = \\sqrt{|A_{2,1}|^2 + |A_{3,2}|^2}$. For our starting matrix $A_0=H$, we have:\n$$\nS(A_0) = \\sqrt{|\\sin(\\theta_1)|^2 + |\\sin(\\theta_2)|^2}.\n$$\nSince $A_1 = A_0$, we have $S(A_1) = S(A_0)$. The convergence ratio is:\n$$\nr_{\\mathrm{unsh}} = \\frac{S(A_1)}{S(A_0)} = 1,\n$$\nprovided $S(A_0) \\neq 0$. This ratio of $1$ signifies a complete lack of progress, demonstrating the failure of the unshifted algorithm for this class of matrices. This failure is a known phenomenon for any real orthogonal Hessenberg matrix.\n\n### Success of the Wilkinson-Shifted QR Algorithm\n\nThe Wilkinson-shifted step breaks this stagnation. The key is the introduction of a shift $\\mu \\in \\mathbb{C}$.\n1.  The shift $\\mu$ is chosen as an eigenvalue of the trailing $2 \\times 2$ submatrix of $A_0$, specifically the one closer to the corner entry $A_{0,n,n}$. For our $3 \\times 3$ matrix $H$, the submatrix is $T = H_{2:3, 2:3}$.\n2.  The algorithm then factorizes a shifted matrix: $A_0 - \\mu I = QR$.\n3.  The next iterate is $A_1 = RQ + \\mu I = Q^T A_0 Q$.\n\nThe crucial difference is that the matrix $B = A_0 - \\mu I$ is no longer orthogonal (unless $\\mu=0$, which is not generally the case). Its QR factorization is therefore non-trivial ($Q \\ne B, R \\ne I$). The resulting orthogonal similarity transformation $A_1 = Q^T A_0 Q$ produces a new matrix $A_1$ that is generally different from $A_0$.\n\nThe Wilkinson shift is a particularly effective choice because it is derived from the part of the matrix where we want to achieve convergence (i.e., drive the subdiagonal entry $A_{n,n-1}$ to zero). The theory of the QR algorithm, particularly the implicit Q theorem, shows that this choice of shift leads to very rapid, typically quadratic, convergence for the targeted subdiagonal entry.\n\nTherefore, we expect the magnitude of the subdiagonal entries of $A_1$ to be significantly smaller than those of $A_0$. This will result in a subdiagonal norm ratio $r_{\\mathrm{shift}} = S(A_1)/S(A_0)$ that is much less than $1$, demonstrating successful progress towards convergence. Even in the special case where one subdiagonal entry is already zero (as in Test 2, where $\\theta_2=0$), the Wilkinson shift correctly adapts, effectively deflating the problem and working on the remaining subproblem, still promoting convergence.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and runs the computational experiment as per the problem description.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.4, -0.7),   # Test 1\n        (0.9, 0),      # Test 2\n        (-1.1, 0.6)    # Test 3\n    ]\n\n    results = []\n    \n    for theta1, theta2 in test_cases:\n        # Step 1: Construct the initial matrix H(theta1, theta2)\n        c1, s1 = np.cos(theta1), np.sin(theta1)\n        c2, s2 = np.cos(theta2), np.sin(theta2)\n        \n        # H = G12 * G23\n        h_matrix = np.array([\n            [c1, -s1 * c2, s1 * s2],\n            [s1, c1 * c2, -c1 * s2],\n            [0, s2, c2]\n        ])\n        \n        a0 = h_matrix\n        \n        # Step 2: Define the subdiagonal measure S(A)\n        def subdiagonal_norm(A):\n            n = A.shape[0]\n            # Get the first subdiagonal elements A[1,0], A[2,1], ...\n            subdiag = np.diagonal(A, offset=-1)\n            # The definition is || (A_2,1, ..., A_n,n-1) ||_2\n            # np.diagonal handles this perfectly.\n            return np.linalg.norm(subdiag)\n\n        # Calculate initial subdiagonal norm\n        s_a0 = subdiagonal_norm(a0)\n\n        # Step 3: Implement one unshifted and one Wilkinson-shifted step\n\n        # Unshifted QR step\n        def unshifted_step(A):\n            # QR factorization with positive diagonal on R\n            q, r = np.linalg.qr(A)\n            \n            # Enforce strictly positive diagonal on R as per the problem.\n            # numpy's qr returns non-negative, which is sufficient for non-singular A.\n            # We implement the sign flip explicitly to adhere to the prompt.\n            d = np.sign(np.diag(r))\n            d[d == 0] = 1  # Handle case of zero on diagonal\n            D = np.diag(d)\n            \n            q_prime = q @ D\n            r_prime = D @ r # D is its own inverse\n            \n            # Next iterate is R'Q'\n            a_plus = r_prime @ q_prime\n            return a_plus\n\n        # Wilkinson-shifted QR step\n        def shifted_step(A):\n            n = A.shape[0]\n            \n            # Form the trailing 2x2 submatrix\n            T = A[n-2:n, n-2:n]\n            \n            # Find its eigenvalues\n            e_vals = np.linalg.eigvals(T)\n            \n            # Define the shift mu as the eigenvalue closer to A[n-1, n-1]\n            a_nn = A[n-1, n-1]\n            dist0 = np.abs(e_vals[0] - a_nn)\n            dist1 = np.abs(e_vals[1] - a_nn)\n            mu = e_vals[0] if dist0 < dist1 else e_vals[1]\n\n            # Form A - mu*I and compute its QR factorization.\n            # This can involve complex numbers.\n            B = A - mu * np.identity(n)\n            q, r = np.linalg.qr(B)\n            \n            # Next iterate is RQ + mu*I\n            a_plus = r @ q + mu * np.identity(n)\n            return a_plus\n\n        # Apply the steps\n        a_plus_unsh = unshifted_step(a0)\n        a_plus_shift = shifted_step(a0)\n\n        # Calculate final subdiagonal norms\n        s_unsh = subdiagonal_norm(a_plus_unsh)\n        s_shift = subdiagonal_norm(a_plus_shift)\n\n        # Step 4: Compute the ratios\n        if s_a0 != 0:\n            r_unsh = s_unsh / s_a0\n            r_shift = s_shift / s_a0\n        else:\n            r_unsh = 0.0\n            r_shift = 0.0\n        \n        results.extend([r_unsh, r_shift])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "3593257"}, {"introduction": "A robust QR algorithm must include a reliable test to stop iterating on a subproblem, a process known as deflation. This exercise explores the subtleties of deflation criteria in floating-point arithmetic, where a naive check can fail dramatically for highly nonnormal matrices. You will implement and compare a simple rule with a corrected version that accounts for nonnormal amplification, revealing what makes a numerical algorithm truly robust in practice. [@problem_id:3593287]", "problem": "You are to design and implement a robust deflation test for the Francis implicitly shifted QR iteration applied to a real upper Hessenberg matrix. The deflation decision at position $i$ considers the $2\\times 2$ trailing principal subproblem determined by the rows and columns $i$ and $i+1$, and specifically the subdiagonal entry $h_{i+1,i}$. The classic, but naive, deflation rule declares a deflation when $|h_{i+1,i}| \\le \\tau \\left(|h_{i,i}| + |h_{i+1,i+1}|\\right)$, for a small threshold $\\tau$. In highly nonnormal cases, this rule can fail because the effective coupling between the two diagonal blocks scales like the product $|h_{i,i+1}|\\,|h_{i+1,i}|$, so that large $|h_{i,i+1}|$ can amplify the effect of $|h_{i+1,i}|$ on the spectrum and undermine deflation safety. Your task is to create a corrected deflation rule that is robust under diagonal similarity scaling and mitigates nonnormal amplification.\n\nStarting from the following fundamental bases:\n- For an upper Hessenberg matrix, a deflation at position $i$ means setting $h_{i+1,i}$ to zero, which splits the matrix into two decoupled blocks at the level of exact arithmetic.\n- In floating-point arithmetic adhering to the Institute of Electrical and Electronics Engineers (IEEE) standard, small entries relative to an appropriate local scale can be neglected if the induced backward error is within $O(u)$, where $u$ is the unit roundoff. In practice one uses a tunable threshold $\\tau$ as a stand-in for a modest multiple of $u$ times a scale.\n- For a $2\\times 2$ block $\\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}$, the discriminant of the characteristic polynomial is $(a-d)^2 + 4bc$. Perturbing $c$ to $0$ changes the discriminant by $-4bc$, so that the resulting eigenvalue perturbation depends on $bc$ and the separation $|a-d|$.\n\nDevise a corrected, practical deflation test that meets these criteria:\n- It reduces to the naive test when $|h_{i,i+1}|$ is comparable to $|h_{i,i}|+|h_{i+1,i+1}|$ or vanishing.\n- It strengthens the naive test when $|h_{i,i+1}|$ is large relative to $|h_{i,i}|+|h_{i+1,i+1}|$ in order to suppress unsafe deflations caused by nonnormal amplification.\n- It is invariant under diagonal similarity scaling of the $2\\times 2$ block at rows and columns $i$ and $i+1$, i.e., under transforms of the form $D^{-1}\\begin{bmatrix} h_{i,i} & h_{i,i+1} \\\\ h_{i+1,i} & h_{i+1,i+1}\\end{bmatrix}D$ with $D=\\mathrm{diag}(d_i,d_{i+1})$ and $d_i,d_{i+1} \\neq 0$.\n\nYou must do the following.\n1) From first principles, propose a corrected rule that declares deflation only if both the naive bound $|h_{i+1,i}| \\le \\tau \\left(|h_{i,i}| + |h_{i+1,i+1}|\\right)$ holds and an additional nonnormality guard holds. The guard must explicitly involve the product $|h_{i,i+1}|\\,|h_{i+1,i}|$ and the local scale $\\left(|h_{i,i}| + |h_{i+1,i+1}|\\right)^2$. The justification must be based on a comparison of the change in the discriminant and a chosen scale, and must not rely on any shortcut formulas beyond the stated fundamental bases.\n2) Explain why the naive rule can fail on nonnormal examples by analyzing the $2\\times 2$ block $\\begin{bmatrix} a & b \\\\ c & d\\end{bmatrix}$ with $a=d$ and $|b|$ large but $|c|$ extremely small. Show that the eigenvalue separation scales like $2\\sqrt{bc}$ when $a=d$, and derive conditions on $bc$ necessary to ensure that setting $c$ to $0$ does not cause an $O(1)$ change in the eigenvalues relative to the local scale.\n3) Implement a program that, given a set of test cases, evaluates both the naive rule and your corrected rule at the requested deflation position $i$, using zero-based indexing. In every test case, $i$ denotes the top-left index of the $2\\times 2$ block, so the coupling is $h_{i+1,i}$, the upper off-diagonal is $h_{i,i+1}$, and the diagonals are $h_{i,i}$ and $h_{i+1,i+1}$.\n\nUse the following test suite. Each test case is a triple consisting of a matrix $H$, an index $i$, and a threshold $\\tau$:\n- Case $1$ (general, nearly normal): \n  $H = \\begin{bmatrix} 2 & 10^{-1} \\\\ 10^{-8} & 3 \\end{bmatrix}$, $i=0$, $\\tau = 10^{-6}$.\n- Case $2$ (nonnormal amplification with $|h_{i,i+1}|$ huge):\n  $H = \\begin{bmatrix} 1 & 10^{8} \\\\ 10^{-8} & 1 \\end{bmatrix}$, $i=0$, $\\tau = 10^{-6}$.\n- Case $3$ (embedded $3\\times 3$ Hessenberg with large $|h_{i,i+1}|$ relative to diagonal scale):\n  $H = \\begin{bmatrix} 1 & 10^{6} & 0 \\\\ 0 & 1 & 10^{6} \\\\ 0 & 10^{-10} & 1 \\end{bmatrix}$, test deflation at $i=1$, $\\tau = 10^{-6}$.\n- Case $4$ (upper-triangular $2\\times 2$ off by a tiny coupling only):\n  $H = \\begin{bmatrix} 2 & 0 \\\\ 10^{-12} & 3 \\end{bmatrix}$, $i=0$, $\\tau = 10^{-6}$.\n- Case $5$ (naive rule fails due to a larger subdiagonal relative to scale):\n  $H = \\begin{bmatrix} 1 & 1 \\\\ 10^{-5} & 1 \\end{bmatrix}$, $i=0$, $\\tau = 10^{-6}$.\n\nYour program must compute, for each case, two boolean values:\n- The naive decision, which is true if and only if $|h_{i+1,i}| \\le \\tau \\left(|h_{i,i}| + |h_{i+1,i+1}|\\right)$.\n- The corrected decision, which is true if and only if the naive decision is true and, in addition, the nonnormality guard $|h_{i,i+1}|\\,|h_{i+1,i}| \\le \\tau \\left(|h_{i,i}| + |h_{i+1,i+1}|\\right)^2$ holds.\n\nProduce a single line of output containing all decisions, aggregated across the five cases in order, with each case contributing the naive decision followed by the corrected decision. The required output format is a single Python-style list with $10$ boolean entries in this order:\n$[\\text{naive}_1,\\text{corrected}_1,\\text{naive}_2,\\text{corrected}_2,\\dots,\\text{naive}_5,\\text{corrected}_5]$.", "solution": "The problem requires the derivation and implementation of a robust deflation test for the Francis QR iteration on a real upper Hessenberg matrix. This involves analyzing the shortcomings of a naive test and proposing a corrected rule that is safer in the presence of nonnormal structures.\n\n### Step 1: Analysis of the Naive Deflation Rule and its Failure Mode\n\nThe decision to deflate a Hessenberg matrix $H$ at position $i$ involves analyzing the $2 \\times 2$ principal submatrix at rows and columns $i$ and $i+1$. Let this block be\n$$\nB = \\begin{bmatrix}\nh_{i,i} & h_{i,i+1} \\\\\nh_{i+1,i} & h_{i+1,i+1}\n\\end{bmatrix} = \\begin{bmatrix} a & b \\\\ c & d \\end{bmatrix}\n$$\nThe eigenvalues $\\lambda_{\\pm}$ of this block are given by the roots of its characteristic polynomial, $\\lambda^2 - (a+d)\\lambda + (ad-bc) = 0$, which are:\n$$\n\\lambda_{\\pm} = \\frac{a+d}{2} \\pm \\frac{1}{2}\\sqrt{(a-d)^2 + 4bc}\n$$\nDeflation at this position is equivalent to setting the subdiagonal entry $c = h_{i+1,i}$ to zero. The matrix $\\tilde{B}$ after deflation is upper triangular, $\\tilde{B} = \\begin{bmatrix} a & b \\\\ 0 & d \\end{bmatrix}$, and its eigenvalues are simply its diagonal entries, $a$ and $d$. A deflation test is considered safe if the eigenvalues of $B$ are close to $a$ and $d$.\n\nThe naive deflation rule is given as $|c| \\le \\tau(|a|+|d|)$, where $\\tau$ is a small tolerance. This rule is often adequate but fails in highly nonnormal cases. A canonical example of nonnormality in a $2 \\times 2$ matrix is when the diagonal entries are close ($a \\approx d$) and the off-diagonal entries have disparate magnitudes, particularly with $|b|$ being very large.\n\nLet's analyze the special case where $a=d$, as requested. The eigenvalues of $B$ become:\n$$\n\\lambda_{\\pm} = a \\pm \\sqrt{bc}\n$$\nUpon setting $c=0$, the eigenvalues become $a, a$. The magnitude of the eigenvalue perturbation is $|\\sqrt{bc}|$. For deflation to be safe, this perturbation must be small relative to a characteristic local scale, such as $|a|+|d|$. That is, we require $|\\sqrt{bc}| \\ll |a|+|d|$.\n\nConsider the test case $H = \\begin{bmatrix} 1 & 10^{8} \\\\ 10^{-8} & 1 \\end{bmatrix}$ (Case 2). Here, $a=d=1$, $b=10^8$, and $c=10^{-8}$. The local scale is $|a|+|d|=|1|+|1|=2$.\nThe naive rule checks if $|c| \\le \\tau(|a|+|d|)$:\n$$\n|10^{-8}| \\le \\tau(2)\n$$\nWith $\\tau=10^{-6}$, this becomes $10^{-8} \\le 2 \\times 10^{-6}$, which is true. The naive rule would erroneously signal for deflation.\n\nHowever, the actual eigenvalues of this matrix are $\\lambda_{\\pm} = 1 \\pm \\sqrt{10^8 \\cdot 10^{-8}} = 1 \\pm 1$, so $\\lambda_1=2$ and $\\lambda_2=0$. After deflation, the eigenvalues would be $1, 1$. The change in eigenvalues is of order $1$, which is an $O(1)$ relative change with respect to the local scale of $2$. This is a catastrophic error. The failure occurs because the naive rule only bounds $|c|$, while the eigenvalue perturbation depends on the product $|bc|$. The large value of $|b|$ amplifies the effect of the small $|c|$, a phenomenon known as nonnormal amplification. To ensure the change in eigenvalues is small, we must control the quantity $|bc|$, not just $|c|$. The condition to ensure the perturbation is small is $|\\sqrt{bc}| \\le \\tau(|a|+|d|)$, which implies $|bc| \\le \\tau^2(|a|+|d|)^2$.\n\n### Step 2: Derivation of a Corrected, Robust Rule\n\nA robust rule must account for the product $|bc|$. We start from the discriminant of the characteristic polynomial, $\\Delta = (a-d)^2 + 4bc$. Deflation, i.e., setting $c=0$, changes the discriminant by $-4bc$. For deflation to be safe, this change must be \"small\". A natural reference scale for the discriminant, which is a squared quantity, is the square of a linear scale of the matrix. We use $(|a|+|d|)^2$ as this reference. Thus, we require the magnitude of the change in the discriminant to be small relative to this scale:\n$$\n|4bc| \\le \\epsilon(|a|+|d|)^2\n$$\nwhere $\\epsilon$ is a small dimensionless tolerance. By absorbing the constant $4$ into the tolerance and using the problem's threshold $\\tau$, we arrive at the nonnormality guard:\n$$\n|bc| \\le \\tau(|a|+|d|)^2\n$$\nThis condition directly controls the term responsible for nonnormal amplification. For the failing example from Case 2, this guard gives:\n$$\n|10^8 \\cdot 10^{-8}| \\le 10^{-6}(|1|+|1|)^2 \\implies 1 \\le 4 \\times 10^{-6}\n$$\nThis inequality is false, so the corrected test correctly prevents the unsafe deflation.\n\nThe final corrected rule, as specified for implementation, combines the naive test and the nonnormality guard. Deflation is permitted if and only if both conditions are met:\n1.  **Naive Test**: $|c| \\le \\tau(|a|+|d|)$\n2.  **Nonnormality Guard**: $|bc| \\le \\tau(|a|+|d|)^2$\n\nWe check the required properties for this combined rule:\n-   **Reduction to naive test**: If $|b|$ is of the same order as $|a|+|d|$, say $|b| \\approx k(|a|+|d|)$ for some constant $k$ of order $1$, the guard becomes $|c|k(|a|+|d|) \\le \\tau(|a|+|d|)^2$, which simplifies to $|c| \\le (\\tau/k)(|a|+|d|)$. This is essentially the same condition as the naive test.\n-   **Strengthening**: If $|b|$ is large, $|b| \\gg |a|+|d|$, the guard imposes $|c| \\le \\tau \\frac{(|a|+|d|)^2}{|b|}$. Since $\\frac{|a|+|d|}{|b|} \\ll 1$, this condition is much stricter than the naive test, correctly tightening the criterion.\n-   **Invariance under diagonal similarity scaling**: A similarity transform with $D=\\mathrm{diag}(d_i, d_{i+1})$ transforms the block to $\\tilde{B} = \\begin{bmatrix} a & b(d_{i+1}/d_i) \\\\ c(d_i/d_{i+1}) & d \\end{bmatrix}$. The diagonal entries $a, d$ are invariant. The product $\\tilde{b}\\tilde{c} = (b d_{i+1}/d_i)(c d_i/d_{i+1}) = bc$ is also invariant. Thus, the nonnormality guard, $|bc| \\le \\tau(|a|+|d|)^2$, is invariant. However, the subdiagonal entry $c$ is not invariant. Consequently, the naive rule $|c| \\le \\tau(|a|+|d|)$ is not invariant, and therefore the combined rule is not strictly invariant. This is a known deficiency of the classic naive rule. The corrected rule represents a significant improvement by adding an invariant guard, making it more robust even if full invariance is not achieved.\n\n### Step 3: Implementation and Evaluation\n\nThe implementation will follow the logic derived above, calculating the boolean outcomes for both the naive and the corrected tests for each of the five provided cases. The corrected test is true if and only if the naive test is true and the nonnormality guard is also true. The values for $a, b, c, d$ are extracted from the $2 \\times 2$ subproblem defined by index $i$.\n\n- **Case 1**: $a=2, d=3, b=10^{-1}, c=10^{-8}, \\tau=10^{-6}$.\n  - Naive: $|10^{-8}| \\le 10^{-6}(|2|+|3|) = 5 \\times 10^{-6}$. (True)\n  - Guard: $|10^{-1} \\cdot 10^{-8}| \\le 10^{-6}(|2|+|3|)^2 = 2.5 \\times 10^{-5}$. (True)\n  - Corrected: True $\\land$ True $\\implies$ True.\n\n- **Case 2**: $a=1, d=1, b=10^8, c=10^{-8}, \\tau=10^{-6}$.\n  - Naive: $|10^{-8}| \\le 10^{-6}(|1|+|1|) = 2 \\times 10^{-6}$. (True)\n  - Guard: $|10^8 \\cdot 10^{-8}| \\le 10^{-6}(|1|+|1|)^2 = 4 \\times 10^{-6}$. (False)\n  - Corrected: True $\\land$ False $\\implies$ False.\n\n- **Case 3**: At $i=1$, we have $a=1, d=1, b=10^6, c=10^{-10}, \\tau=10^{-6}$.\n  - Naive: $|10^{-10}| \\le 10^{-6}(|1|+|1|) = 2 \\times 10^{-6}$. (True)\n  - Guard: $|10^6 \\cdot 10^{-10}| \\le 10^{-6}(|1|+|1|)^2 = 4 \\times 10^{-6}$. (False)\n  - Corrected: True $\\land$ False $\\implies$ False.\n\n- **Case 4**: $a=2, d=3, b=0, c=10^{-12}, \\tau=10^{-6}$.\n  - Naive: $|10^{-12}| \\le 10^{-6}(|2|+|3|) = 5 \\times 10^{-6}$. (True)\n  - Guard: $|0 \\cdot 10^{-12}| \\le 10^{-6}(|2|+|3|)^2 = 2.5 \\times 10^{-5}$. (True)\n  - Corrected: True $\\land$ True $\\implies$ True.\n\n- **Case 5**: $a=1, d=1, b=1, c=10^{-5}, \\tau=10^{-6}$.\n  - Naive: $|10^{-5}| \\le 10^{-6}(|1|+|1|) = 2 \\times 10^{-6}$. (False)\n  - Guard: $|1 \\cdot 10^{-5}| \\le 10^{-6}(|1|+|1|)^2 = 4 \\times 10^{-6}$. (False, but this is moot since naive is false)\n  - Corrected: False $\\land$ False $\\implies$ False.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Evaluates naive and corrected deflation rules for the QR algorithm on a set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (matrix H, index i, threshold tau)\n    test_cases = [\n        (np.array([[2, 1e-1], [1e-8, 3]]), 0, 1e-6),\n        (np.array([[1, 1e8], [1e-8, 1]]), 0, 1e-6),\n        (np.array([[1, 1e6, 0], [0, 1, 1e6], [0, 1e-10, 1]]), 1, 1e-6),\n        (np.array([[2, 0], [1e-12, 3]]), 0, 1e-6),\n        (np.array([[1, 1], [1e-5, 1]]), 0, 1e-6),\n    ]\n\n    results = []\n    for H, i, tau in test_cases:\n        # Extract the 2x2 block B = [[a, b], [c, d]]\n        # a = h_i,i\n        # b = h_i,i+1\n        # c = h_i+1,i\n        # d = h_i+1,i+1\n        a = H[i, i]\n        b = H[i, i + 1]\n        c = H[i + 1, i]\n        d = H[i + 1, i + 1]\n\n        # Naive deflation rule: |c| <= tau * (|a| + |d|)\n        naive_decision = np.abs(c) <= tau * (np.abs(a) + np.abs(d))\n        results.append(naive_decision)\n\n        # Nonnormality guard: |b*c| <= tau * (|a| + |d|)^2\n        # The problem statement defines the corrected rule as (naive AND guard).\n        guard = np.abs(b * c) <= tau * (np.abs(a) + np.abs(d))**2\n        corrected_decision = naive_decision and guard\n        \n        results.append(corrected_decision)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3593287"}, {"introduction": "To achieve state-of-the-art performance, modern QR algorithms employ techniques to find and deflate converged eigenvalues as early as possible. This practice provides a hands-on introduction to Aggressive Early Deflation (AED), a key innovation that significantly accelerates convergence. You will implement a simplified version of AED to understand its core mechanism: analyzing a small trailing \"window\" of the matrix to lock in eigenvalues and shrink the active problem size. [@problem_id:3593260]", "problem": "You are given the task of implementing a toy version of Aggressive Early Deflation (AED) within the practical shifted Francisâ€“QR algorithm for nonsymmetric problems. Aggressive Early Deflation (AED) is used to accelerate convergence by identifying and locking eigenvalues from a trailing window of a real upper Hessenberg matrix before the full QR iteration has numerically decoupled them. You must work from first principles of orthogonal similarity and the Schur decomposition.\n\nWork solely with real matrices and real arithmetic, and use the following fundamental base:\n- A real upper Hessenberg matrix is a real square matrix $H \\in \\mathbb{R}^{n \\times n}$ whose entries satisfy $h_{ij} = 0$ for all $i > j + 1$.\n- The Real Schur Decomposition of a real square matrix $W \\in \\mathbb{R}^{k \\times k}$ states that there exists an orthogonal matrix $Q \\in \\mathbb{R}^{k \\times k}$ such that $Q^{\\mathsf{T}} W Q = T$, where $T$ is quasi-upper triangular with real $1 \\times 1$ and $2 \\times 2$ diagonal blocks, and $\\|Q\\|_2 = 1$.\n- Orthogonal similarity preserves eigenvalues and the Frobenius norm.\n\nYour task is to implement the following toy AED procedure on a real $7 \\times 7$ upper Hessenberg matrix $H$, using a trailing window of size $k = 4$:\n1. Partition $H$ as follows. Let $n = 7$ and $t = n - k + 1 = 4$. Extract the trailing window $W = H_{t:n,\\, t:n} \\in \\mathbb{R}^{4 \\times 4}$ indexed from row $t$ to $n$ and column $t$ to $n$. Extract the spike row $x = H_{t-1,\\, t:n} \\in \\mathbb{R}^{1 \\times 4}$, the row directly above the trailing window.\n2. Compute the Real Schur Decomposition of the trailing window: find an orthogonal $Q \\in \\mathbb{R}^{4 \\times 4}$ and quasi-upper triangular $T \\in \\mathbb{R}^{4 \\times 4}$ such that $Q^{\\mathsf{T}} W Q = T$.\n3. Transform the spike by the same orthogonal similarity: $y = x Q \\in \\mathbb{R}^{1 \\times 4}$.\n4. Determine deflatable diagonal blocks of $T$ by comparing the components of $y$ associated with each diagonal block against a scale-sensitive tolerance. Let $u$ denote the unit roundoff for IEEE-754 double precision and write $\\sqrt{u}$ for its square root. Let $\\|T\\|_F$ denote the Frobenius norm of $T$.\n   - For a $1 \\times 1$ block at position $j$ (so $T_{j,j}$ is real and $T_{j+1,j} = 0$), declare it deflatable if\n     $$ |y_j| \\le \\sqrt{u} \\cdot \\max\\left(\\|T\\|_F,\\, |T_{j,j}|\\right). $$\n   - For a $2 \\times 2$ diagonal block spanning indices $j, j+1$ (i.e., $T_{j+1,j} \\ne 0$), declare it deflatable if\n     $$ \\sqrt{y_j^2 + y_{j+1}^2} \\le \\sqrt{u} \\cdot \\max\\left(\\|T\\|_F,\\, \\|T_{j:j+2,\\, j:j+2}\\|_F\\right). $$\n   In this toy problem, the provided test matrices are constructed so that the trailing Schur form $T$ has only $1 \\times 1$ diagonal blocks with real diagonal entries.\n5. The eigenvalues that can be locked are the eigenvalues corresponding to the diagonal $1 \\times 1$ blocks that pass the test above. The active submatrix shrinks by the total number $d$ of deflatable eigenvalues, from $n$ down to $n - d$.\n\nImplement this procedure and apply it to the following three $7 \\times 7$ real upper Hessenberg matrices. In each case, use $k = 4$ (so $t = 4$) and follow the steps above. All entries are exact real numbers.\n\nTest case 1:\n- The $3 \\times 3$ leading Hessenberg block:\n  $$ A_1 = \\begin{bmatrix}\n  0.0 & 2.0 & -1.0 \\\\\n  3.0 & 0.5 & 4.0 \\\\\n  0.0 & -2.0 & 1.5\n  \\end{bmatrix}. $$\n- The spike row:\n  $$ x_1 = \\begin{bmatrix} 10^{-12} & 10^{-4} & 10^{-12} & 5 \\cdot 10^{-9} \\end{bmatrix}. $$\n- The $4 \\times 4$ trailing window (already upper triangular):\n  $$ W_1 = \\begin{bmatrix}\n  1.0 & 0.05 & 0 & 0 \\\\\n  0 & 2.0 & 0.05 & 0 \\\\\n  0 & 0 & 3.0 & 0.05 \\\\\n  0 & 0 & 0 & 4.0\n  \\end{bmatrix}. $$\n- Assemble $H_1$ by placing $A_1$ in the leading $3 \\times 3$ block, $x_1$ in row $3$ columns $4:7$, and $W_1$ in rows and columns $4:7$, with all other entries set to $0$, ensuring $H_1$ is upper Hessenberg.\n\nTest case 2:\n- The $3 \\times 3$ leading Hessenberg block:\n  $$ A_2 = \\begin{bmatrix}\n  1.0 & -1.0 & 0.5 \\\\\n  2.0 & 0.0 & -0.3 \\\\\n  0.0 & 1.2 & 2.0\n  \\end{bmatrix}. $$\n- The spike row:\n  $$ x_2 = \\begin{bmatrix} 10^{-3} & 2 \\cdot 10^{-3} & 3 \\cdot 10^{-3} & 4 \\cdot 10^{-3} \\end{bmatrix}. $$\n- The trailing window:\n  $$ W_2 = \\begin{bmatrix}\n  1.0 & 0.05 & 0 & 0 \\\\\n  0 & 2.0 & 0.05 & 0 \\\\\n  0 & 0 & 3.0 & 0.05 \\\\\n  0 & 0 & 0 & 4.0\n  \\end{bmatrix}. $$\n- Assemble $H_2$ analogously to test case $1$.\n\nTest case 3:\n- The $3 \\times 3$ leading Hessenberg block:\n  $$ A_3 = \\begin{bmatrix}\n  -0.5 & 0.7 & -0.2 \\\\\n  1.1 & 0.3 & 0.4 \\\\\n  0.0 & -0.9 & 0.8\n  \\end{bmatrix}. $$\n- The spike row:\n  $$ x_3 = \\begin{bmatrix} 10^{-8} & 10^{-7} & 10^{-9} & 10^{-6} \\end{bmatrix}. $$\n- The trailing window:\n  $$ W_3 = \\begin{bmatrix}\n  0.7 & 0.02 & 0 & 0 \\\\\n  0 & 0.9 & 0.02 & 0 \\\\\n  0 & 0 & 1.1 & 0.02 \\\\\n  0 & 0 & 0 & 1.3\n  \\end{bmatrix}. $$\n\nFor each test case $i \\in \\{1,2,3\\}$:\n- Perform the Real Schur Decomposition on $W_i$.\n- Transform $x_i$ to $y_i$ using the orthogonal factor from the Schur decomposition.\n- Apply the deflation tests described above to identify which diagonal $1 \\times 1$ blocks are deflatable.\n- Report the list of locked eigenvalues (the real diagonal entries of the deflatable $1 \\times 1$ blocks, in order from top of the window to bottom), the count $d_i$ of locked eigenvalues, and the new active size $n - d_i$.\n\nUse the following conventions in your implementation and output:\n- Use double-precision arithmetic throughout; use $u = \\text{machine epsilon}$ for double precision, and use $\\sqrt{u}$ in the deflation test.\n- The Real Schur Decomposition must be used to define the deflation test.\n- In these test cases, the trailing Schur form has only $1 \\times 1$ blocks, so all locked eigenvalues are real numbers.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must be a list of the form $[d, m, [\\ell_1, \\ell_2, \\dots]]$, where $d$ is the integer number of locked eigenvalues, $m$ is the integer size of the new active submatrix, and $[\\ell_1, \\ell_2, \\dots]$ is the list of real locked eigenvalues in nondecreasing index order as they appear on the diagonal of the trailing Schur form. For the three test cases, the full output should look like:\n  $$ [[d_1,m_1,[\\dots]],[d_2,m_2,[\\dots]],[d_3,m_3,[\\dots]]]. $$", "solution": "The problem asks for an implementation of a simplified Aggressive Early Deflation (AED) procedure, a technique used to accelerate the convergence of the practical Francis QR algorithm for finding eigenvalues of nonsymmetric real matrices. The core principle of AED is to identify and \"lock\" eigenvalues that have nearly converged before they are fully decoupled by the standard QR iteration. This is achieved by analyzing a small trailing submatrix of the Hessenberg matrix.\n\nLet $H \\in \\mathbb{R}^{n \\times n}$ be a real upper Hessenberg matrix. The QR algorithm iteratively applies similarity transformations to $H$ to drive its subdiagonal elements to zero, revealing the eigenvalues in a quasi-upper triangular matrix known as the real Schur form. An iteration becomes computationally expensive for large $n$. AED targets a trailing subproblem of size $k \\times k$, where $k \\ll n$, to find converged eigenvalues and deflate the problem, reducing $n$ and thus the cost of subsequent iterations.\n\nFollowing the problem statement, we work with a matrix of size $n=7$ and a trailing window of size $k=4$. The matrix $H$ is partitioned as:\n$$\nH = \\begin{bmatrix}\nH_{1:t-1,\\, 1:t-1} & H_{1:t-1,\\, t:n} \\\\\nx & W \\\\\n\\boldsymbol{0} & \\boldsymbol{0}\n\\end{bmatrix}\n$$\nwhere the partition is indexed such that $t = n - k + 1 = 7 - 4 + 1 = 4$. The submatrices are:\n- $W = H_{t:n,\\, t:n} \\in \\mathbb{R}^{4 \\times 4}$ is the trailing window.\n- $x = H_{t-1,\\, t:n} \\in \\mathbb{R}^{1 \\times 4}$ is the \"spike\" row vector, which couples the leading part of the matrix to the trailing window.\n\nThe procedure is as follows:\n\n**Step 1: Orthogonal Similarity Transformation on the Window**\n\nThe central idea is to analyze the eigenvalues of the trailing window $W$. We seek an orthogonal similarity transformation that simplifies $W$ into a more structured form. The Real Schur Decomposition provides such a transformation. For the matrix $W \\in \\mathbb{R}^{k \\times k}$, there exists an orthogonal matrix $Q \\in \\mathbb{R}^{k \\times k}$ (i.e., $Q^{\\mathsf{T}}Q = QQ^{\\mathsf{T}} = I$) and a real quasi-upper triangular matrix $T \\in \\mathbb{R}^{k \\times k}$ such that:\n$$\nQ^{\\mathsf{T}} W Q = T\n$$\nThe eigenvalues of $T$ are the same as the eigenvalues of $W$, and they are revealed by the $1 \\times 1$ and $2 \\times 2$ blocks on the diagonal of $T$.\n\nTo maintain the eigenvalues of the full matrix $H$, this transformation must be applied as a similarity transformation to $H$. We define a block-diagonal orthogonal matrix $\\mathcal{Q} \\in \\mathbb{R}^{n \\times n}$:\n$$\n\\mathcal{Q} = \\begin{bmatrix}\nI_{n-k} & \\boldsymbol{0} \\\\\n\\boldsymbol{0} & Q\n\\end{bmatrix}\n$$\nwhere $I_{n-k}$ is the $(n-k) \\times (n-k)$ identity matrix. The transformed Hessenberg matrix $H'$ is:\n$$\nH' = \\mathcal{Q}^{\\mathsf{T}} H \\mathcal{Q} = \\begin{bmatrix}\nI_{n-k} & \\boldsymbol{0} \\\\\n\\boldsymbol{0} & Q^{\\mathsf{T}}\n\\end{bmatrix}\n\\begin{bmatrix} H_{11} & H_{12} \\\\ x' & W \\end{bmatrix}\n\\begin{bmatrix} I_{n-k} & \\boldsymbol{0} \\\\\n\\boldsymbol{0} & Q\n\\end{bmatrix}\n= \\begin{bmatrix}\nH_{11} & H_{12}Q \\\\\nQ^{\\mathsf{T}}x' & Q^{\\mathsf{T}}WQ\n\\end{bmatrix}\n$$\nNote that for the partitioning of $H$ to match this structure, $x'$ would be a column vector. In our specific problem, $H$ is upper Hessenberg, and the relevant spike is the row $x = H_{t-1,\\, t:n}$. Let's reconsider the transformation's effect on the specified partition. The transformed matrix $H'$ will have its trailing window updated to $Q^{\\mathsf{T}}WQ=T$. The spike row $x$ is post-multiplied by $Q$, becoming a new spike $y$:\n$$\ny = x Q\n$$\nThe entry $h_{t-1, t-1}$ is unchanged, and the new non-zero entries in row $t-1$ are given by the components of $y$.\n\n**Step 2: The Deflation Criterion**\n\nAn eigenvalue of $W$ (and thus of $T$) can be considered a converged eigenvalue of the full matrix $H$ if the corresponding diagonal block in $T$ is weakly coupled to the rest of the matrix. This coupling is measured by the magnitude of the corresponding components in the transformed spike $y$. If a coupling is small enough, we can treat it as zero, which decouples, or \"deflates,\" the eigenvalue.\n\nThe problem specifies that the Schur form $T$ of the test matrices will be upper triangular, containing only $1 \\times 1$ diagonal blocks. For a $1 \\times 1$ block $T_{j,j}$ (where $j$ is the $0$-based index within the $4 \\times 4$ window), the corresponding coupling is the $j$-th element of the transformed spike, $y_j$. The block is declared deflatable if this element is small relative to the scale of the subproblem. The criterion is:\n$$\n|y_j| \\le \\sqrt{u} \\cdot \\max\\left(\\|T\\|_F, |T_{j,j}|\\right)\n$$\nHere, $u$ is the machine epsilon for double-precision floating-point arithmetic, representing the upper bound on relative error. The term $\\sqrt{u}$ is a standard choice for such \"negligibility\" tests. The scale is determined by the maximum of the Frobenius norm of the Schur form, $\\|T\\|_F$, and the magnitude of the eigenvalue itself, $|T_{j,j}|$. Eigenvalues that correspond to deflatable blocks are considered \"locked\".\n\n**Step 3: Calculating Results for Each Test Case**\n\nWe apply this procedure to each test case. Let $n=7$ and $k=4$. The number of locked eigenvalues is $d_i$, and the new active matrix size will be $m_i = n - d_i = 7 - d_i$.\n\n**Test Case 1:**\n- $x_1 = \\begin{bmatrix} 10^{-12} & 10^{-4} & 10^{-12} & 5 \\cdot 10^{-9} \\end{bmatrix}$\n- $W_1 = \\begin{bmatrix} 1.0 & 0.05 & 0 & 0 \\\\ 0 & 2.0 & 0.05 & 0 \\\\ 0 & 0 & 3.0 & 0.05 \\\\ 0 & 0 & 0 & 4.0 \\end{bmatrix}$\nSince $W_1$ is upper triangular with distinct eigenvalues, its real Schur decomposition is $T_1 = W_1$ and $Q_1 = I_4$.\nThus, $y_1 = x_1 Q_1 = x_1$.\nThe machine epsilon is $u \\approx 2.22 \\times 10^{-16}$, so $\\sqrt{u} \\approx 1.49 \\times 10^{-8}$.\n$\\|T_1\\|_F = \\|W_1\\|_F = \\sqrt{1^2+0.05^2+2^2+0.05^2+3^2+0.05^2+4^2} \\approx 5.4779$.\nThe tolerance scale is $\\max(\\|T_1\\|_F, |T_{1,jj}|)$. Since all $|T_{1,jj}| \\le 4.0 < \\|T_1\\|_F$, the scale is $\\|T_1\\|_F$.\nTolerance $\\approx 1.49 \\times 10^{-8} \\cdot 5.4779 \\approx 8.16 \\times 10^{-8}$.\n- $j=0$ (eigenvalue $1.0$): $|y_1[0]| = 10^{-12} \\le 8.16 \\times 10^{-8}$. **Deflatable**.\n- $j=1$ (eigenvalue $2.0$): $|y_1[1]| = 10^{-4} > 8.16 \\times 10^{-8}$. Not deflatable.\n- $j=2$ (eigenvalue $3.0$): $|y_1[2]| = 10^{-12} \\le 8.16 \\times 10^{-8}$. **Deflatable**.\n- $j=3$ (eigenvalue $4.0$): $|y_1[3]| = 5 \\times 10^{-9} \\le 8.16 \\times 10^{-8}$. **Deflatable**.\nLocked eigenvalues: $[1.0, 3.0, 4.0]$. Count $d_1 = 3$. New size $m_1 = 7-3 = 4$. Result: $[3, 4, [1.0, 3.0, 4.0]]$.\n\n**Test Case 2:**\n- $x_2 = \\begin{bmatrix} 10^{-3} & 2 \\cdot 10^{-3} & 3 \\cdot 10^{-3} & 4 \\cdot 10^{-3} \\end{bmatrix}$\n- $W_2$ is identical to $W_1$, so $T_2=W_2$, $Q_2=I$, and the tolerance is $\\approx 8.16 \\times 10^{-8}$.\n- $y_2 = x_2$.\n- $j=0$: $|y_2[0]| = 10^{-3} > 8.16 \\times 10^{-8}$. Not deflatable.\n- $j=1$: $|y_2[1]| = 2 \\times 10^{-3} > 8.16 \\times 10^{-8}$. Not deflatable.\n- $j=2$: $|y_2[2]| = 3 \\times 10^{-3} > 8.16 \\times 10^{-8}$. Not deflatable.\n- $j=3$: $|y_2[3]| = 4 \\times 10^{-3} > 8.16 \\times 10^{-8}$. Not deflatable.\nLocked eigenvalues: $[]$. Count $d_2 = 0$. New size $m_2 = 7-0 = 7$. Result: $[0, 7, []]$.\n\n**Test Case 3:**\n- $x_3 = \\begin{bmatrix} 10^{-8} & 10^{-7} & 10^{-9} & 10^{-6} \\end{bmatrix}$\n- $W_3 = \\begin{bmatrix} 0.7 & 0.02 & 0 & 0 \\\\ 0 & 0.9 & 0.02 & 0 \\\\ 0 & 0 & 1.1 & 0.02 \\\\ 0 & 0 & 0 & 1.3 \\end{bmatrix}$\nAgain, $W_3$ is upper triangular, so $T_3 = W_3$ and $Q_3 = I_4$. Thus $y_3=x_3$.\n$\\|T_3\\|_F = \\sqrt{0.7^2+0.02^2+0.9^2+0.02^2+1.1^2+0.02^2+1.3^2} \\approx 2.0497$.\n- $j=0$ (eigenvalue $0.7$): Scale is $\\max(2.0497, 0.7) = 2.0497$. Tol $\\approx 1.49 \\times 10^{-8} \\cdot 2.0497 \\approx 3.05 \\times 10^{-8}$. $|y_3[0]| = 10^{-8} \\le 3.05 \\times 10^{-8}$. **Deflatable**.\n- $j=1$ (eigenvalue $0.9$): Scale is $\\max(2.0497, 0.9) = 2.0497$. Tol $\\approx 3.05 \\times 10^{-8}$. $|y_3[1]| = 10^{-7} > 3.05 \\times 10^{-8}$. Not deflatable.\n- $j=2$ (eigenvalue $1.1$): Scale is $\\max(2.0497, 1.1) = 2.0497$. Tol $\\approx 3.05 \\times 10^{-8}$. $|y_3[2]| = 10^{-9} \\le 3.05 \\times 10^{-8}$. **Deflatable**.\n- $j=3$ (eigenvalue $1.3$): Scale is $\\max(2.0497, 1.3) = 2.0497$. Tol $\\approx 3.05 \\times 10^{-8}$. $|y_3[3]| = 10^{-6} > 3.05 \\times 10^{-8}$. Not deflatable.\nLocked eigenvalues: $[0.7, 1.1]$. Count $d_3 = 2$. New size $m_3 = 7-2 = 5$. Result: $[2, 5, [0.7, 1.1]]$.\n\nThese manual calculations will be confirmed by the provided Python implementation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Implements the specified Aggressive Early Deflation (AED) procedure\n    for three test cases and prints the results in the required format.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple (W, x), where W is the trailing window and x is the spike.\n    test_cases = [\n        (\n            np.array([\n                [1.0, 0.05, 0.0, 0.0],\n                [0.0, 2.0, 0.05, 0.0],\n                [0.0, 0.0, 3.0, 0.05],\n                [0.0, 0.0, 0.0, 4.0]\n            ]),\n            np.array([1e-12, 1e-4, 1e-12, 5e-9])\n        ),\n        (\n            np.array([\n                [1.0, 0.05, 0.0, 0.0],\n                [0.0, 2.0, 0.05, 0.0],\n                [0.0, 0.0, 3.0, 0.05],\n                [0.0, 0.0, 0.0, 4.0]\n            ]),\n            np.array([1e-3, 2e-3, 3e-3, 4e-3])\n        ),\n        (\n            np.array([\n                [0.7, 0.02, 0.0, 0.0],\n                [0.0, 0.9, 0.02, 0.0],\n                [0.0, 0.0, 1.1, 0.02],\n                [0.0, 0.0, 0.0, 1.3]\n            ]),\n            np.array([1e-8, 1e-7, 1e-9, 1e-6])\n        )\n    ]\n\n    # Global parameters\n    n = 7\n    u = np.finfo(float).eps\n    sqrt_u = np.sqrt(u)\n\n    results = []\n    for W, x in test_cases:\n        # Step 2: Compute the Real Schur Decomposition of the trailing window.\n        # T, Q are returned such that W = Q @ T @ Q.T, which means Q.T @ W @ Q = T.\n        T, Q = linalg.schur(W, output='real')\n\n        # Step 3: Transform the spike by the same orthogonal similarity.\n        y = x @ Q\n\n        # Step 4: Determine deflatable diagonal blocks.\n        norm_T_fro = linalg.norm(T, 'fro')\n        locked_eigenvalues = []\n        \n        # The problem states that T will have only 1x1 blocks.\n        # We iterate through the diagonal elements.\n        for j in range(T.shape[0]):\n            eigenvalue = T[j, j]\n            \n            # Deflation test for a 1x1 block\n            tolerance_scale = max(norm_T_fro, abs(eigenvalue))\n            criterion = sqrt_u * tolerance_scale\n            \n            if abs(y[j]) <= criterion:\n                locked_eigenvalues.append(eigenvalue)\n        \n        # Step 5: Report the results for the current test case.\n        d = len(locked_eigenvalues)\n        m = n - d\n        \n        # The output format requires a list wrapping the results for each case.\n        results.append([d, m, locked_eigenvalues])\n\n    # Convert the list of results to the required string format.\n    # The default string representation of lists in Python matches the required format.\n    # e.g., str([3, 4, [1.0, 3.0, 4.0]]) -> '[3, 4, [1.0, 3.0, 4.0]]'\n    final_output_string = f\"[{','.join(map(str, results))}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output_string)\n\nsolve()\n```", "id": "3593260"}]}