{"hands_on_practices": [{"introduction": "This first practice connects the abstract concept of eigenvalues to the concrete structure of the real Schur form. By analyzing a matrix with a known complex conjugate eigenpair $\\alpha \\pm i\\beta$, you will see how these values directly populate the canonical $2 \\times 2$ block $\\begin{pmatrix} \\alpha  \\beta \\\\ -\\beta  \\alpha \\end{pmatrix}$ in the quasi-triangular output. This exercise solidifies the fundamental principle that the diagonal blocks of a real Schur form reveal the eigenvalues of the original matrix [@problem_id:3595443].", "problem": "Let $A \\in \\mathbb{R}^{3 \\times 3}$ be the real companion matrix of the monic polynomial $p(\\lambda) = \\lambda^{3} - 5 \\lambda^{2} + 11 \\lambda - 15$, that is,\n$$\nA = \\begin{pmatrix}\n0 & 0 & 15 \\\\\n1 & 0 & -11 \\\\\n0 & 1 & 5\n\\end{pmatrix}.\n$$\nStarting from the definitions of invariant subspace and orthogonal similarity, construct the real Schur form of $A$ by identifying a real $2$-dimensional invariant subspace associated with the nonreal spectrum and building an orthonormal basis for this subspace, followed by completion to an orthonormal basis of $\\mathbb{R}^{3}$. In the basis you construct, the real Schur form $R = Q^{\\top} A Q$ is quasi-upper triangular and contains a $2 \\times 2$ real block corresponding to the complex conjugate eigenpair of $A$. By fully justifying the choice of the invariant subspace and the orthonormalization procedure from first principles, determine the exact value of the parameter $\\beta$ appearing in that $2 \\times 2$ block, which has the canonical form\n$$\n\\begin{pmatrix}\n\\alpha & \\beta \\\\\n-\\beta & \\alpha\n\\end{pmatrix}.\n$$\nProvide your final answer as a single real number. No rounding is required.", "solution": "The user wants me to determine the value of the parameter $\\beta$ in the real Schur form of a given matrix $A$.\n\n### Step 1: Problem Validation\n\n**1. Extract Givens:**\n- The matrix $A \\in \\mathbb{R}^{3 \\times 3}$ is the real companion matrix of the monic polynomial $p(\\lambda) = \\lambda^{3} - 5 \\lambda^{2} + 11 \\lambda - 15$.\n- The explicit form of the matrix is $A = \\begin{pmatrix} 0 & 0 & 15 \\\\ 1 & 0 & -11 \\\\ 0 & 1 & 5 \\end{pmatrix}$.\n- The real Schur form $R = Q^{\\top} A Q$ is to be constructed, where $Q$ is an orthogonal matrix.\n- The Schur form $R$ contains a $2 \\times 2$ real block corresponding to the complex conjugate eigenpair of $A$.\n- This $2 \\times 2$ block has the canonical form $\\begin{pmatrix} \\alpha & \\beta \\\\ -\\beta & \\alpha \\end{pmatrix}$.\n- The task is to find the exact value of $\\beta$.\n\n**2. Validate Using Extracted Givens:**\n- **Scientifically Grounded:** The problem is a standard exercise in numerical linear algebra, specifically concerning the real Schur decomposition of a real matrix. The concepts are well-established. It is scientifically sound.\n- **Well-Posed:** For any real matrix $A$, a real Schur decomposition exists. The eigenvalues of any block in the Schur form must be eigenvalues of the original matrix $A$. This constraint, combined with the specified canonical structure of the block, determines the values of $\\alpha$ and $|\\beta|$. The problem asks for \"the\" value of $\\beta$, which implies uniqueness. This uniqueness is conventionally established by choosing $\\beta$ to be positive. Therefore, the problem is well-posed under this standard convention.\n- **Objective:** The problem is stated in precise mathematical language and is free of subjectivity.\n\n**3. Verdict and Action:**\nThe problem is valid. I will proceed with the solution.\n\n### Step 2: Solution\n\nThe problem requires finding the parameter $\\beta$ in a $2 \\times 2$ block of the real Schur form of the matrix $A$. The solution proceeds as follows:\n\nFirst, we must determine the eigenvalues of the matrix $A$. The characteristic polynomial of a companion matrix is given directly. In this case, the characteristic polynomial $p(\\lambda)$ is provided:\n$$p(\\lambda) = \\det(A - \\lambda I) = \\lambda^{3} - 5 \\lambda^{2} + 11 \\lambda - 15 = 0$$\nWe seek the roots of this polynomial. By the rational root theorem, any integer root must be a divisor of the constant term, $-15$. The divisors are $\\pm 1, \\pm 3, \\pm 5, \\pm 15$. We test these values:\nFor $\\lambda=3$:\n$$p(3) = (3)^{3} - 5(3)^{2} + 11(3) - 15 = 27 - 5(9) + 33 - 15 = 27 - 45 + 33 - 15 = 60 - 60 = 0$$\nSo, $\\lambda_1 = 3$ is a real eigenvalue.\nTo find the other eigenvalues, we perform polynomial division of $p(\\lambda)$ by $(\\lambda - 3)$:\n$$ \\frac{\\lambda^{3} - 5 \\lambda^{2} + 11 \\lambda - 15}{\\lambda - 3} = \\lambda^2 - 2\\lambda + 5 $$\nThe remaining eigenvalues are the roots of the quadratic equation $\\lambda^2 - 2\\lambda + 5 = 0$. Using the quadratic formula:\n$$ \\lambda = \\frac{-(-2) \\pm \\sqrt{(-2)^2 - 4(1)(5)}}{2(1)} = \\frac{2 \\pm \\sqrt{4 - 20}}{2} = \\frac{2 \\pm \\sqrt{-16}}{2} = \\frac{2 \\pm 4i}{2} = 1 \\pm 2i $$\nThus, the eigenvalues of $A$ are $\\lambda_1 = 3$, $\\lambda_2 = 1+2i$, and $\\lambda_3 = 1-2i$.\n\nAccording to the real Schur decomposition theorem, for any real matrix $A$, there exists an orthogonal matrix $Q$ such that $R = Q^{\\top} A Q$ is a real, quasi-upper triangular matrix. The diagonal entries of $R$ are composed of $1 \\times 1$ blocks corresponding to the real eigenvalues of $A$ and $2 \\times 2$ blocks corresponding to the complex conjugate eigenpairs.\n\nIn our case, the eigenvalues are $\\{3, 1+2i, 1-2i\\}$. The real Schur form $R$ will have a $1 \\times 1$ block $[3]$ and a $2 \\times 2$ block whose eigenvalues are the complex conjugate pair $\\{1+2i, 1-2i\\}$.\n\nThe problem specifies that this $2 \\times 2$ block has the canonical form:\n$$ R_{11} = \\begin{pmatrix} \\alpha & \\beta \\\\ -\\beta & \\alpha \\end{pmatrix} $$\nThe eigenvalues of this block are the roots of its characteristic polynomial:\n$$ \\det(R_{11} - \\lambda I) = \\det \\begin{pmatrix} \\alpha - \\lambda & \\beta \\\\ -\\beta & \\alpha - \\lambda \\end{pmatrix} = (\\alpha - \\lambda)^2 + \\beta^2 = 0 $$\nSolving for $\\lambda$:\n$$ (\\lambda - \\alpha)^2 = -\\beta^2 \\implies \\lambda - \\alpha = \\pm i\\sqrt{\\beta^2} \\implies \\lambda = \\alpha \\pm i|\\beta| $$\nSo, the eigenvalues of the canonical block are $\\{\\alpha + i|\\beta|, \\alpha - i|\\beta|\\}$.\n\nThese eigenvalues must be equal to the complex conjugate eigenpair of $A$, which is $\\{1+2i, 1-2i\\}$. By comparing the real and imaginary parts of these two sets of eigenvalues, we can identify $\\alpha$ and $|\\beta|$:\n$$ \\alpha = \\text{Re}(1 \\pm 2i) = 1 $$\n$$ |\\beta| = |\\text{Im}(1 \\pm 2i)| = | \\pm 2 | = 2 $$\nThis implies that $\\alpha = 1$ and $\\beta = \\pm 2$.\n\nThe problem asks for \"the exact value of the parameter $\\beta$,\" implying a unique solution. The choice between $\\beta = 2$ and $\\beta = -2$ depends on the orientation of the basis vectors chosen for the invariant subspace. However, in numerical linear algebra, it is a standard convention to choose the sign of the off-diagonal element to be positive (or based on the sign of the imaginary part of the eigenvalue in the upper half-plane). Specifically, for a complex conjugate pair of eigenvalues $a \\pm ib$ with $b>0$, the canonical block is often defined such that the parameter corresponding to the imaginary part is $b$ itself, which is positive.\n\nAdhering to this convention, we associate the parameter $\\beta$ with the positive imaginary part of the eigenvalue pair, which is $2$.\nTherefore, we have $\\alpha=1$ and we select $\\beta=2$.\nThe resulting block would be $\\begin{pmatrix} 1 & 2 \\\\ -2 & 1 \\end{pmatrix}$, whose eigenvalues are $1\\pm 2i$.\n\nThe core of the argument is that the eigenvalues of the Schur block are determined by the eigenvalues of the matrix A. The specified structure of the Schur block then forces the values of $\\alpha$ and $|\\beta|$. The uniqueness of $\\beta$ is resolved by standard convention.", "answer": "$$\\boxed{2}$$", "id": "3595443"}, {"introduction": "A primary advantage of the Schur decomposition over eigendecomposition is its universality; it applies to all square matrices, not just those that are diagonalizable. This exercise focuses on a defective matrix, which lacks a complete set of eigenvectors, to demonstrate this robustness. You will not only construct a valid real Schur form but also quantify the matrix's departure from normality, a key concept for understanding numerical stability [@problem_id:3595396].", "problem": "Consider the real matrix\n$$\nA \\;=\\; \\begin{pmatrix}\n0 & 1 & 0\\\\\n0 & 0 & 1\\\\\n0 & 0 & 0\n\\end{pmatrix} \\in \\mathbb{R}^{3 \\times 3}.\n$$\nThis matrix is known to be defective in the sense that it does not admit a complete basis of eigenvectors. Work from first principles to address the following in the context of the real Schur decomposition.\n\n- Using only the definition that a matrix is defective if its geometric multiplicity is strictly smaller than its algebraic multiplicity, verify that $A$ is defective.\n- Starting from the foundational statement that for any real matrix $A$ there exists an orthogonal matrix $Q \\in \\mathbb{R}^{3 \\times 3}$ such that $Q^{\\mathsf{T}} A Q$ is real upper quasi-triangular (the real Schur form), explicitly construct a valid real Schur decomposition for $A$ and explain why it is well-defined even though $A$ is defective.\n- To quantify nonnormality as it pertains to numerical stability under orthogonal similarity, define the commutator\n$$\n\\Delta \\;=\\; T^{\\mathsf{T}} T \\;-\\; T T^{\\mathsf{T}},\n$$\nwhere $T$ is a real Schur form of $A$, and compute the Frobenius norm $\\lVert \\Delta \\rVert_{F}$ exactly.\n\nProvide your final answer as the exact value of $\\lVert \\Delta \\rVert_{F}$ with no rounding. The final answer must be a single real number or a single closed-form analytic expression.", "solution": "The problem requires a three-part analysis of the matrix $A = \\begin{pmatrix} 0 & 1 & 0\\\\ 0 & 0 & 1\\\\ 0 & 0 & 0 \\end{pmatrix}$. We first validate the problem statement.\n\n### Problem Validation\n**1. Extract Givens:**\n- The matrix $A = \\begin{pmatrix} 0 & 1 & 0\\\\ 0 & 0 & 1\\\\ 0 & 0 & 0 \\end{pmatrix} \\in \\mathbb{R}^{3 \\times 3}$.\n- Definition of a defective matrix: The geometric multiplicity of at least one eigenvalue is strictly smaller than its algebraic multiplicity.\n- Real Schur decomposition: For a real matrix $A$, there exists an orthogonal matrix $Q \\in \\mathbb{R}^{3 \\times 3}$ such that $T = Q^{\\mathsf{T}} A Q$ is real upper quasi-triangular.\n- Commutator definition: $\\Delta = T^{\\mathsf{T}} T - T T^{\\mathsf{T}}$, where $T$ is a real Schur form of $A$.\n- Task: Verify $A$ is defective, construct a real Schur decomposition for $A$, and compute the Frobenius norm $\\lVert \\Delta \\rVert_{F}$.\n\n**2. Validate Using Extracted Givens:**\n- **Scientific Grounding:** The problem is firmly rooted in standard, well-established concepts of numerical linear algebra, including eigenvalues, eigenvectors, matrix decompositions (Schur), and matrix norms. The matrix $A$ is a classical example of a nilpotent Jordan block, frequently used to illustrate concepts like defectiveness and non-normality.\n- **Well-Posedness:** The problem is well-posed. The tasks are clearly defined and lead to a unique and meaningful solution. The existence of the real Schur decomposition is a fundamental theorem. The quantity to be computed, $\\lVert \\Delta \\rVert_{F}$, is invariant under the choice of the orthogonal matrix $Q$ in the Schur decomposition, since the Frobenius norm is unitarily invariant. That is, $\\lVert \\Delta \\rVert_{F} = \\lVert T^{\\mathsf{T}} T - T T^{\\mathsf{T}} \\rVert_F = \\lVert (Q^{\\mathsf{T}}AQ)^{\\mathsf{T}}(Q^{\\mathsf{T}}AQ) - (Q^{\\mathsf{T}}AQ)(Q^{\\mathsf{T}}AQ)^{\\mathsf{T}} \\rVert_F = \\lVert Q^{\\mathsf{T}}(A^{\\mathsf{T}}A - AA^{\\mathsf{T}})Q \\rVert_F = \\lVert A^{\\mathsf{T}}A - AA^{\\mathsf{T}} \\rVert_F$. This ensures the uniqueness of the final answer.\n- **Objectivity:** The problem is stated using precise, objective mathematical language.\n- **Completeness:** All necessary information and definitions are provided.\n\n**3. Verdict and Action:**\nThe problem is valid as it is scientifically sound, well-posed, and unambiguous. We proceed with the solution.\n\n### Part 1: Verification of Defectiveness\n\nA matrix is defective if, for at least one of its eigenvalues, the geometric multiplicity is strictly less than the algebraic multiplicity.\n\nFirst, we determine the eigenvalues and their algebraic multiplicities by finding the roots of the characteristic polynomial, $p(\\lambda) = \\det(A - \\lambda I)$.\n$$\np(\\lambda) = \\det \\begin{pmatrix} -\\lambda & 1 & 0\\\\ 0 & -\\lambda & 1\\\\ 0 & 0 & -\\lambda \\end{pmatrix} = (-\\lambda)^3\n$$\nSetting $p(\\lambda) = 0$ gives $-\\lambda^3 = 0$, which yields a single eigenvalue $\\lambda = 0$ with algebraic multiplicity $m_a(0) = 3$.\n\nNext, we determine the geometric multiplicity of $\\lambda = 0$. The geometric multiplicity, $m_g(\\lambda)$, is the dimension of the eigenspace corresponding to $\\lambda$, which is the null space of the matrix $(A - \\lambda I)$. For $\\lambda = 0$, we need to find the dimension of the null space of $A$.\n$$\n\\text{Nul}(A) = \\{ \\mathbf{x} \\in \\mathbb{R}^3 \\mid A\\mathbf{x} = \\mathbf{0} \\}\n$$\nWe solve the system $A\\mathbf{x} = \\mathbf{0}$:\n$$\n\\begin{pmatrix} 0 & 1 & 0\\\\ 0 & 0 & 1\\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\\\ x_3 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\nThis matrix equation corresponds to the system of linear equations:\n$x_2 = 0$\n$x_3 = 0$\n$0 = 0$\nThe variable $x_1$ is free. Any eigenvector must be of the form $\\begin{pmatrix} x_1 \\\\ 0 \\\\ 0 \\end{pmatrix} = x_1 \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$. The eigenspace is the span of the vector $\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$. The dimension of this space is $1$.\nThus, the geometric multiplicity of the eigenvalue $\\lambda=0$ is $m_g(0) = 1$.\n\nComparing the multiplicities, we have $m_g(0) = 1 < m_a(0) = 3$. By definition, the matrix $A$ is defective.\n\n### Part 2: Real Schur Decomposition\n\nThe real Schur decomposition theorem guarantees that for any real matrix $A \\in \\mathbb{R}^{n \\times n}$, there exists an orthogonal matrix $Q \\in \\mathbb{R}^{n \\times n}$ and a real upper quasi-triangular matrix $T \\in \\mathbb{R}^{n \\times n}$ such that $A = Q T Q^{\\mathsf{T}}$, or equivalently $T = Q^{\\mathsf{T}} A Q$. The matrix $T$ is called a real Schur form of $A$. Its diagonal entries consist of $1 \\times 1$ blocks corresponding to real eigenvalues and $2 \\times 2$ blocks corresponding to complex conjugate pairs of eigenvalues.\n\nThe existence of this decomposition is established by a constructive proof that does not require the matrix to be diagonalizable (i.e., non-defective). The proof proceeds by induction and only requires that any matrix has at least one eigenvalue and a corresponding eigenvector (which is guaranteed over $\\mathbb{C}$ by the Fundamental Theorem of Algebra, and for real matrices, if a complex eigenvalue exists, so does its conjugate pair, leading to a real invariant subspace). The process finds one real eigenvector (or a 2D invariant subspace for a complex pair), uses it to form the first one (or two) column(s) of $Q$, performs a similarity transformation that block-triangularizes the matrix, and then proceeds recursively on the lower-right submatrix. This process always succeeds, regardless of whether the matrix is defective.\n\nSince all eigenvalues of our matrix $A$ are real ($\\lambda=0$), its real Schur form $T$ will be strictly upper triangular.\n\nTo construct the decomposition, we follow the constructive proof.\n1. Find an eigenvector of $A$. We already found that $\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$ is an eigenvector for $\\lambda=0$. We normalize it to get the first column of $Q$: $\\mathbf{q}_1 = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}$.\n2. Extend $\\{\\mathbf{q}_1\\}$ to an orthonormal basis for $\\mathbb{R}^3$. The simplest way to do this is to choose the standard basis vectors. Let $\\mathbf{q}_2 = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}$ and $\\mathbf{q}_3 = \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix}$. The set $\\{\\mathbf{q}_1, \\mathbf{q}_2, \\mathbf{q}_3\\}$ forms an orthonormal basis.\n3. Form the orthogonal matrix $Q$ with these vectors as its columns:\n$$\nQ = \\begin{pmatrix} \\mathbf{q}_1 & \\mathbf{q}_2 & \\mathbf{q}_3 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 1 \\end{pmatrix} = I\n$$\n4. Compute the Schur form $T$:\n$$\nT = Q^{\\mathsf{T}} A Q = I^{\\mathsf{T}} A I = A = \\begin{pmatrix} 0 & 1 & 0\\\\ 0 & 0 & 1\\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\nThe resulting matrix $T=A$ is upper triangular, so it is a valid real Schur form of $A$. The associated orthogonal matrix is the identity matrix $Q=I$. This decomposition $A = I A I^{\\mathsf{T}}$ is well-defined and demonstrates that even a defective matrix has a real Schur decomposition.\n\n### Part 3: Computation of $\\lVert \\Delta \\rVert_{F}$\n\nWe are asked to compute the Frobenius norm of the commutator $\\Delta = T^{\\mathsf{T}} T - T T^{\\mathsf{T}}$, where $T$ is a real Schur form of $A$. Using the Schur form we found in Part 2, $T=A$.\n\nFirst, we compute the two products $T^{\\mathsf{T}} T$ and $T T^{\\mathsf{T}}$.\n$$\nT = A = \\begin{pmatrix} 0 & 1 & 0\\\\ 0 & 0 & 1\\\\ 0 & 0 & 0 \\end{pmatrix} \\quad \\implies \\quad T^{\\mathsf{T}} = A^{\\mathsf{T}} = \\begin{pmatrix} 0 & 0 & 0\\\\ 1 & 0 & 0\\\\ 0 & 1 & 0 \\end{pmatrix}\n$$\nNow, we calculate the matrix products:\n$$\nT^{\\mathsf{T}} T = \\begin{pmatrix} 0 & 0 & 0\\\\ 1 & 0 & 0\\\\ 0 & 1 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 1 & 0\\\\ 0 & 0 & 1\\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} 0 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\n$$\nT T^{\\mathsf{T}} = \\begin{pmatrix} 0 & 1 & 0\\\\ 0 & 0 & 1\\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 & 0\\\\ 1 & 0 & 0\\\\ 0 & 1 & 0 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\nNext, we compute the commutator $\\Delta$:\n$$\n\\Delta = T^{\\mathsf{T}} T - T T^{\\mathsf{T}} = \\begin{pmatrix} 0 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 1 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 & 0\\\\ 0 & 1 & 0\\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} -1 & 0 & 0\\\\ 0 & 0 & 0\\\\ 0 & 0 & 1 \\end{pmatrix}\n$$\nFinally, we compute the Frobenius norm of $\\Delta$. The Frobenius norm of a matrix $M$ is defined as $\\lVert M \\rVert_{F} = \\sqrt{\\sum_{i,j} |m_{ij}|^2}$.\n$$\n\\lVert \\Delta \\rVert_{F} = \\sqrt{(-1)^2 + 0^2 + 0^2 + 0^2 + 0^2 + 0^2 + 0^2 + 0^2 + 1^2} = \\sqrt{1 + 1} = \\sqrt{2}\n$$\nThe value $\\lVert \\Delta \\rVert_{F}$ quantifies the departure of $T$ from normality. As noted in the validation, this quantity is independent of the specific Schur form chosen, as it is equal to $\\lVert A^{\\mathsf{T}}A - AA^{\\mathsf{T}} \\rVert_{F}$. Our calculation confirms this general property for the specific case of $T=A$.", "answer": "$$\\boxed{\\sqrt{2}}$$", "id": "3595396"}, {"introduction": "Theory and computational practice intersect in this numerical experiment, which explores the impact of finite-precision arithmetic on the Schur decomposition. Through a short coding task, you will investigate a critical step in algorithms like the QR iteration: deflation. This practice reveals how a tolerance, scaled by the matrix norm and machine precision, is used to decide whether a matrix with eigenvalues $a \\pm i\\epsilon$ should be represented with a $2 \\times 2$ complex block or be \"deflated\" into two $1 \\times 1$ real blocks, a crucial distinction in real-world applications [@problem_id:3595428].", "problem": "You are to investigate how the finite precision of floating-point arithmetic influences the block structure identified by the real Schur decomposition for a family of real $2\\times 2$ matrices that, in exact arithmetic, encode a complex conjugate pair of eigenvalues with a tiny imaginary part. In exact real Schur form, a $2\\times 2$ block corresponds to a complex conjugate pair of eigenvalues, whereas two $1\\times 1$ blocks correspond to two real eigenvalues. In finite precision, during the implicit orthogonal transformations in the orthogonal-triangular (QR) iterations that compute the real Schur form, a subdiagonal entry that is sufficiently small relative to the local scale is set to zero (a process known as deflation), which can flip the classification from a $2\\times 2$ block to two $1\\times 1$ blocks.\n\nFor parameters $a\\in\\mathbb{R}$ and $\\epsilon\\in\\mathbb{R}$, consider the real $2\\times 2$ matrix\n$$\nA(a,\\epsilon) \\;=\\;\n\\begin{bmatrix}\na & \\epsilon\\\\\n-\\epsilon & a\n\\end{bmatrix}.\n$$\nIn exact arithmetic, the eigenvalues of $A(a,\\epsilon)$ are $a\\pm i\\,\\epsilon$, so $A(a,\\epsilon)$ is already in real Schur form with a single $2\\times 2$ block. In finite precision floating-point arithmetic, the subdiagonal entry can be deemed negligible and set to zero by the QR algorithm, producing two $1\\times 1$ blocks with repeated real eigenvalue $a$, depending on the scale of $\\epsilon$ relative to the machine unit roundoff and the local matrix norm.\n\nYour task is to write a program that, for each specified $(a,\\epsilon)$ pair, computes the real Schur form $T$ of $A(a,\\epsilon)$ using an orthogonal similarity (you may call a reliable numerical library routine for the real Schur decomposition), and then classifies the $2\\times 2$ block versus two $1\\times 1$ blocks by testing the subdiagonal entry $T_{21}$ against a machine-precision-aware tolerance. Use the following decision rule: define the tolerance\n$$\n\\tau \\;=\\; 10\\,u\\,\\|T\\|_{1},\n$$\nwhere $u$ is the unit roundoff of IEEE 754 double precision and $\\|\\cdot\\|_{1}$ denotes the matrix $1$-norm. Classify the case as a $2\\times 2$ complex conjugate pair if $|T_{21}| > \\tau$, and as two $1\\times 1$ real blocks otherwise. For each test case, output the integer $2$ if a $2\\times 2$ block is detected and the integer $1$ if two $1\\times 1$ blocks are detected.\n\nTest suite:\n- Case 1 (general, clearly complex pair): $a=1$, $\\epsilon=10^{-2}$.\n- Case 2 (general, still complex pair under typical precision): $a=1$, $\\epsilon=10^{-12}$.\n- Case 3 (boundary regime near unit roundoff): $a=1$, $\\epsilon=10^{-16}$.\n- Case 4 (deflated regime, imaginary part far below roundoff): $a=1$, $\\epsilon=10^{-20}$.\n- Case 5 (large scale, off-diagonal negligible relative to magnitude): $a=10^{16}$, $\\epsilon=1$.\n- Case 6 (small scale, off-diagonal dominates the deflation threshold): $a=10^{-16}$, $\\epsilon=10^{-16}$.\n\nYour program should produce a single line of output containing the results for the six cases, in order, as a comma-separated list enclosed in square brackets. For example, a valid output format is\n$$\n[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5,\\text{result}_6].\n$$\nEach $\\text{result}_k$ must be an integer equal to either $2$ (detected $2\\times 2$ block) or $1$ (detected two $1\\times 1$ blocks). No physical units or angle units are involved in this problem, and all outputs are unitless integers.", "solution": "The user-provided problem is assessed as valid. It is scientifically grounded in the principles of numerical linear algebra, specifically concerning the computation of the real Schur decomposition and the effects of finite precision arithmetic. The problem is well-posed, with all necessary data, definitions, and a clear, objective classification rule provided. It is a formalizable and verifiable computational task.\n\nThe analysis and solution are based on the following principles. For any real $n \\times n$ matrix $A$, its real Schur decomposition is given by $A = Q T Q^T$, where $Q$ is an orthogonal matrix ($Q^T Q = I$) and $T$ is a real quasi-upper triangular matrix. A quasi-upper triangular matrix is an upper triangular matrix with the possible exception of $2 \\times 2$ blocks on the diagonal. Each $1 \\times 1$ diagonal block $T_{ii}$ corresponds to a real eigenvalue of $A$. Each $2 \\times 2$ diagonal block of the form $\\begin{psmallmatrix} \\alpha & \\beta \\\\ \\gamma & \\delta \\end{psmallmatrix}$ corresponds to a complex conjugate pair of eigenvalues.\n\nThe problem specifies a family of matrices $A(a,\\epsilon)$ defined as:\n$$\nA(a,\\epsilon) \\;=\\;\n\\begin{bmatrix}\na & \\epsilon\\\\\n-\\epsilon & a\n\\end{bmatrix}\n$$\nwhere $a, \\epsilon \\in \\mathbb{R}$. The characteristic polynomial is $\\det(A - \\lambda I) = (\\lambda-a)^2 + \\epsilon^2 = 0$, which yields the eigenvalues $\\lambda = a \\pm i\\,\\epsilon$. For any $\\epsilon \\neq 0$, the matrix has a complex conjugate pair of eigenvalues. In exact arithmetic, $A(a,\\epsilon)$ is already in real Schur form, representing a single $2 \\times 2$ block.\n\nHowever, numerical algorithms for computing the Schur form, such as the QR algorithm, are performed in finite precision floating-point arithmetic. A critical step in such algorithms is deflation, where a subdiagonal entry $T_{i+1, i}$ is set to zero if its magnitude is considered negligible relative to the scale of the neighboring diagonal entries or the overall matrix norm. This action can numerically change a $2 \\times 2$ block into two $1 \\times 1$ blocks, thereby classifying the eigenvalues as real instead of complex.\n\nThe problem provides a specific rule to model this behavior. The classification depends on the computed real Schur form $T$ of $A(a,\\epsilon)$. A tolerance $\\tau$ is defined as:\n$$\n\\tau \\;=\\; 10\\,u\\,\\|T\\|_{1}\n$$\n- The constant $u$ represents the unit roundoff for IEEE 754 double-precision arithmetic. This is the maximum relative error incurred when rounding a number, defined as $u = 2^{-53}$, which is half the machine epsilon $\\epsilon_{mach} = 2^{-52}$.\n- The term $\\|T\\|_{1}$ is the matrix $1$-norm of the computed Schur form $T$, calculated as the maximum absolute column sum: $\\|T\\|_{1} = \\max_{j} \\sum_{i} |T_{ij}|$. This norm provides a measure of the local scale of the matrix.\n\nThe decision rule is:\n- If $|T_{21}| > \\tau$, the subdiagonal element is significant. The matrix is classified as having a $2 \\times 2$ block structure, corresponding to a complex conjugate pair of eigenvalues. The output is the integer $2$.\n- If $|T_{21}| \\le \\tau$, the subdiagonal element is numerically negligible. The matrix is classified as having two $1 \\times 1$ blocks, corresponding to two real eigenvalues. The output is the integer $1$.\n\nWe now apply this procedure to each test case. First, the unit roundoff is $u = 2^{-53} \\approx 1.11022 \\times 10^{-16}$.\n\n**Case 1:** $a=1, \\epsilon=10^{-2}$.\nThe matrix is $A = \\begin{bmatrix} 1 & 0.01 \\\\ -0.01 & 1 \\end{bmatrix}$. The off-diagonal term $\\epsilon$ is large compared to machine precision. The Schur decomposition will yield a matrix $T$ very close to $A$. Thus, $|T_{21}| \\approx 0.01$. The $1$-norm $\\|T\\|_1 \\approx \\|A\\|_1 = 1.01$. The tolerance is $\\tau \\approx 10 \\cdot (1.11 \\times 10^{-16}) \\cdot 1.01 \\approx 1.12 \\times 10^{-15}$. Since $|T_{21}| \\approx 10^{-2} \\gg 1.12 \\times 10^{-15}$, we classify this as a $2 \\times 2$ block. Result: $2$.\n\n**Case 2:** $a=1, \\epsilon=10^{-12}$.\nThe matrix is $A = \\begin{bmatrix} 1 & 10^{-12} \\\\ -10^{-12} & 1 \\end{bmatrix}$. The off-diagonal term is small but still significantly larger than machine precision relative to the diagonal elements. $|T_{21}| \\approx 10^{-12}$. The $1$-norm is $\\|T\\|_1 \\approx \\|A\\|_1 = 1 + 10^{-12} \\approx 1$. The tolerance is $\\tau \\approx 10 \\cdot (1.11 \\times 10^{-16}) \\cdot 1 \\approx 1.11 \\times 10^{-15}$. Since $|T_{21}| \\approx 10^{-12} \\gg 1.11 \\times 10^{-15}$, we classify this as a $2 \\times 2$ block. Result: $2$.\n\n**Case 3:** $a=1, \\epsilon=10^{-16}$.\nThe matrix is $A = \\begin{bmatrix} 1 & 10^{-16} \\\\ -10^{-16} & 1 \\end{bmatrix}$. Here, $\\epsilon$ is very close to the unit roundoff $u$ relative to $a=1$. The QR algorithm's internal deflation logic will likely test if $|-\\epsilon|$ is small compared to $u \\cdot (|a|+|a|)$. This condition, $|-10^{-16}| \\le (1.11 \\times 10^{-16}) \\cdot 2$, is true. Thus, the algorithm will likely set the subdiagonal entry to zero, resulting in a computed $T$ where $|T_{21}|$ is zero or of the order of machine precision sludge, far smaller than $10^{-16}$. Our explicit test confirms this: $\\|T\\|_1 \\approx 1$, so $\\tau \\approx 1.11 \\times 10^{-15}$. The initial subdiagonal is $10^{-16}$, which is already smaller than $\\tau$. The deflation within the solver makes a final $|T_{21}|$ value even smaller. We classify this as two $1 \\times 1$ blocks. Result: $1$.\n\n**Case 4:** $a=1, \\epsilon=10^{-20}$.\nThe matrix is $A = \\begin{bmatrix} 1 & 10^{-20} \\\\ -10^{-20} & 1 \\end{bmatrix}$. The off-diagonal is far below machine precision relative to the diagonal. Due to rounding, $1.0 + 10^{-20}$ might evaluate to $1.0$. Even if the input matrix is stored correctly, the subdiagonal is negligible. $\\|T\\|_1 \\approx 1$, $\\tau \\approx 1.11 \\times 10^{-15}$. Since $|T_{21}|$ will be at most on the order of $10^{-20}$, it is much smaller than $\\tau$. We classify this as two $1 \\times 1$ blocks. Result: $1$.\n\n**Case 5:** $a=10^{16}, \\epsilon=1$.\nThe matrix is $A = \\begin{bmatrix} 10^{16} & 1 \\\\ -1 & 10^{16} \\end{bmatrix}$. This case highlights the importance of relative scale. The nominal imaginary part of the eigenvalue, $\\epsilon=1$, is not small in an absolute sense. However, it is very small relative to the magnitude of the diagonal entries. The $1$-norm of the computed Schur form $T$ will be $\\|T\\|_1 \\approx \\|A\\|_1 = 10^{16}+1$. The tolerance is $\\tau \\approx 10 \\cdot u \\cdot \\|T\\|_1 \\approx 10 \\cdot (1.11 \\times 10^{-16}) \\cdot (10^{16}+1) \\approx 11.1$. The subdiagonal entry of the computed Schur form, $|T_{21}|$, will be close to $|-\\epsilon|=1$. Since $|T_{21}| \\approx 1 \\le 11.1$, the condition $|T_{21}| > \\tau$ is false. The off-diagonal is considered negligible relative to the large scale of the matrix. We classify this as two $1 \\times 1$ blocks. Result: $1$.\n\n**Case 6:** $a=10^{-16}, \\epsilon=10^{-16}$.\nThe matrix is $A = \\begin{bmatrix} 10^{-16} & 10^{-16} \\\\ -10^{-16} & 10^{-16} \\end{bmatrix}$. Here, all entries are of the same small magnitude. The off-diagonal $\\epsilon$ is not small relative to the diagonal $a$. The $1$-norm will be $\\|T\\|_1 \\approx 2 \\times 10^{-16}$. The tolerance is $\\tau \\approx 10 \\cdot u \\cdot \\|T\\|_1 \\approx 10 \\cdot (1.11 \\times 10^{-16}) \\cdot (2 \\times 10^{-16}) \\approx 2.22 \\times 10^{-31}$. The subdiagonal $|T_{21}|$ will be approximately $|\\epsilon|=10^{-16}$. Since $|T_{21}| \\approx 10^{-16} \\gg 2.22 \\times 10^{-31}$, the subdiagonal is significant. We classify this as a $2 \\times 2$ block. Result: $2$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import schur\n\ndef solve():\n    \"\"\"\n    Computes the real Schur form for a family of 2x2 matrices and classifies\n    the block structure based on a machine-precision-aware tolerance.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (a, epsilon).\n    test_cases = [\n        (1.0, 1e-2),     # Case 1\n        (1.0, 1e-12),    # Case 2\n        (1.0, 1e-16),    # Case 3\n        (1.0, 1e-20),    # Case 4\n        (1e16, 1.0),     # Case 5\n        (1e-16, 1e-16),  # Case 6\n    ]\n\n    results = []\n    \n    # Unit roundoff for IEEE 754 double precision.\n    # np.finfo(float).eps is machine epsilon (2^-52), unit roundoff is half of that.\n    u = np.finfo(float).eps / 2.0\n\n    for a, epsilon in test_cases:\n        # Construct the matrix A(a, epsilon).\n        A = np.array([[a, epsilon], \n                      [-epsilon, a]], dtype=float)\n\n        # Compute the real Schur form T.\n        # The orthogonal matrix Q is also returned but not needed.\n        T, Q = schur(A, output='real')\n\n        # Calculate the 1-norm of the computed Schur form T.\n        norm_T_1 = np.linalg.norm(T, ord=1)\n        \n        # Define the tolerance tau based on the problem specification.\n        tau = 10 * u * norm_T_1\n\n        # Extract the subdiagonal element T_21.\n        T_21 = T[1, 0]\n\n        # Classify the block structure based on the tolerance.\n        # Output 2 for a 2x2 block (complex conjugate pair).\n        # Output 1 for two 1x1 blocks (real eigenvalues).\n        if np.abs(T_21) > tau:\n            results.append(2)\n        else:\n            results.append(1)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3595428"}]}