{"hands_on_practices": [{"introduction": "To truly understand LU factorization, we must first build it from the ground up. This exercise guides you through the symbolic derivation of the factorization for a general $3 \\times 3$ matrix using the logic of Gaussian elimination. By tracking each multiplier and pivot, you will directly see how the condition on non-zero leading principal minors guarantees the existence of the factorization without row exchanges [@problem_id:3545102].", "problem": "Let $A \\in \\mathbb{R}^{3 \\times 3}$ be given by $A = \\left[a_{ij}\\right]_{i,j=1}^{3}$ with the property that the leading principal minors are nonzero, that is $a_{11} \\neq 0$ and $\\det\\!\\begin{pmatrix} a_{11} & a_{12} \\\\ a_{21} & a_{22} \\end{pmatrix} \\neq 0$. Starting from the definitions and basic properties of Gaussian elimination (GE) and lower-upper (LU) factorization, and without invoking any pre-memorized formulas, do the following:\n\n- Use the mechanism of elimination to derive, step by step, the unique LU factorization $A = L U$ where $L$ is unit lower triangular and $U$ is upper triangular. Explicitly track each elimination multiplier and express every nontrivial entry of $L$ and $U$ symbolically in terms of the entries $a_{ij}$.\n\n- Justify, using only the stated nonvanishing leading principal minors and triangularity, why this LU factorization exists without row exchanges and is unique under the normalization that $L$ has unit diagonal.\n\n- From your symbolic derivation, simplify the $(3,3)$-entry of $U$ to a closed-form expression that depends only on the entries $a_{ij}$ (and not on intermediate multipliers). Your final answer should be a single closed-form analytic expression. Do not round.", "solution": "The problem as stated is valid. It is a well-posed problem in numerical linear algebra, resting on fundamental principles of matrix factorization. It is self-contained, mathematically consistent, and objective. We may therefore proceed with a full solution.\n\nThe objective is to derive the LU factorization of a $3 \\times 3$ matrix $A$ using the mechanism of Gaussian elimination. We are given the matrix $A = \\left[a_{ij}\\right]_{i,j=1}^{3}$ and the conditions that its first two leading principal minors are nonzero, i.e., $a_{11} \\neq 0$ and $\\det(A_{1:2, 1:2}) \\neq 0$.\n\nLet the matrix $A$ be\n$$ A = \\begin{pmatrix} a_{11} & a_{12} & a_{13} \\\\ a_{21} & a_{22} & a_{23} \\\\ a_{31} & a_{32} & a_{33} \\end{pmatrix} $$\nThe LU factorization seeks to find a unit lower triangular matrix $L$ and an upper triangular matrix $U$ such that $A = LU$. This factorization can be derived from the steps of Gaussian elimination. The process involves transforming $A$ into an upper triangular matrix $U$ by applying a sequence of elementary row operations, specifically, subtracting multiples of upper rows from lower rows.\n\n### Step 1: Elimination in the first column\nThe first step is to create zeros in the first column below the diagonal. The first pivot is $a_{11}$. The problem states $a_{11} \\neq 0$, which ensures this step is possible without row exchanges.\nTo eliminate $a_{21}$, we subtract a multiple of the first row from the second row. The multiplier is $l_{21} = \\frac{a_{21}}{a_{11}}$.\nThe new second row becomes $R_2' \\leftarrow R_2 - l_{21} R_1$.\nTo eliminate $a_{31}$, we subtract a multiple of the first row from the third row. The multiplier is $l_{31} = \\frac{a_{31}}{a_{11}}$.\nThe new third row becomes $R_3' \\leftarrow R_3 - l_{31} R_1$.\n\nThis transformation can be represented by multiplication with an elimination matrix $E_1$:\n$$ E_1 = \\begin{pmatrix} 1 & 0 & 0 \\\\ -l_{21} & 1 & 0 \\\\ -l_{31} & 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ -\\frac{a_{21}}{a_{11}} & 1 & 0 \\\\ -\\frac{a_{31}}{a_{11}} & 0 & 1 \\end{pmatrix} $$\nThe resulting matrix, let's call it $A^{(1)}$, is:\n$$ A^{(1)} = E_1 A = \\begin{pmatrix} a_{11} & a_{12} & a_{13} \\\\ 0 & a_{22} - l_{21}a_{12} & a_{23} - l_{21}a_{13} \\\\ 0 & a_{32} - l_{31}a_{12} & a_{33} - l_{31}a_{13} \\end{pmatrix} $$\nLet us denote the entries of $A^{(1)}$ as $a_{ij}^{(1)}$. So, $a_{1j}^{(1)}=a_{1j}$, and for $i>1$:\n$a_{i2}^{(1)} = a_{i2} - l_{i1} a_{12}$\n$a_{i3}^{(1)} = a_{i3} - l_{i1} a_{13}$\n\n### Step 2: Elimination in the second column\nThe next step is to create a zero in the second column below the diagonal. The pivot for this step is $a_{22}^{(1)}$. We must verify that this pivot is non-zero.\n$$ a_{22}^{(1)} = a_{22} - l_{21}a_{12} = a_{22} - \\frac{a_{21}}{a_{11}}a_{12} = \\frac{a_{11}a_{22} - a_{21}a_{12}}{a_{11}} $$\nThe numerator is the determinant of the leading $2 \\times 2$ principal submatrix of $A$, which is given to be non-zero. The denominator $a_{11}$ is also non-zero. Therefore, $a_{22}^{(1)} \\neq 0$, and the elimination can proceed without a row exchange. This demonstrates why the non-vanishing of leading principal minors guarantees the existence of an LU factorization without pivoting.\n\nTo eliminate $a_{32}^{(1)}$, we subtract a multiple of the new second row from the new third row. The multiplier is $l_{32} = \\frac{a_{32}^{(1)}}{a_{22}^{(1)}}$.\nThe new third row becomes $R_3'' \\leftarrow R_3' - l_{32} R_2'$.\nThis corresponds to an elimination matrix $E_2$:\n$$ E_2 = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & -l_{32} & 1 \\end{pmatrix} $$\nThe final upper triangular matrix $U$ is obtained as $U = E_2 A^{(1)} = E_2 E_1 A$.\n$$ U = \\begin{pmatrix} a_{11}^{(1)} & a_{12}^{(1)} & a_{13}^{(1)} \\\\ 0 & a_{22}^{(1)} & a_{23}^{(1)} \\\\ 0 & 0 & a_{33}^{(1)} - l_{32}a_{23}^{(1)} \\end{pmatrix} = \\begin{pmatrix} u_{11} & u_{12} & u_{13} \\\\ 0 & u_{22} & u_{23} \\\\ 0 & 0 & u_{33} \\end{pmatrix} $$\nThe entries of $U$ are:\n$u_{11} = a_{11}$\n$u_{12} = a_{12}$\n$u_{13} = a_{13}$\n$u_{22} = a_{22}^{(1)} = a_{22} - \\frac{a_{21}}{a_{11}}a_{12}$\n$u_{23} = a_{23}^{(1)} = a_{23} - \\frac{a_{21}}{a_{11}}a_{13}$\n$u_{33} = a_{33}^{(2)} = a_{33}^{(1)} - l_{32}a_{23}^{(1)}$\n\nFrom $U = E_2 E_1 A$, we can write $A = (E_2 E_1)^{-1} U = E_1^{-1} E_2^{-1} U$. The matrix $L$ is defined as $L = E_1^{-1} E_2^{-1}$. The inverse of an elementary elimination matrix is obtained by negating the off-diagonal entries.\n$$ E_1^{-1} = \\begin{pmatrix} 1 & 0 & 0 \\\\ l_{21} & 1 & 0 \\\\ l_{31} & 0 & 1 \\end{pmatrix} \\quad , \\quad E_2^{-1} = \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & l_{32} & 1 \\end{pmatrix} $$\nMultiplying these gives $L$:\n$$ L = E_1^{-1} E_2^{-1} = \\begin{pmatrix} 1 & 0 & 0 \\\\ l_{21} & 1 & 0 \\\\ l_{31} & 0 & 1 \\end{pmatrix} \\begin{pmatrix} 1 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & l_{32} & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 0 & 0 \\\\ l_{21} & 1 & 0 \\\\ l_{31} & l_{32} & 1 \\end{pmatrix} $$\nThis matrix $L$ is unit lower triangular, and its non-trivial entries are precisely the multipliers from the elimination process.\nThe entries of $L$ are:\n$l_{21} = \\frac{a_{21}}{a_{11}}$\n$l_{31} = \\frac{a_{31}}{a_{11}}$\n$l_{32} = \\frac{a_{32}^{(1)}}{a_{22}^{(1)}} = \\frac{a_{32} - l_{31}a_{12}}{a_{22} - l_{21}a_{12}} = \\frac{a_{32} - (\\frac{a_{31}}{a_{11}})a_{12}}{a_{22} - (\\frac{a_{21}}{a_{11}})a_{12}} = \\frac{a_{11}a_{32} - a_{31}a_{12}}{a_{11}a_{22} - a_{21}a_{12}}$\n\n### Justification of Uniqueness\nThe constructive process above demonstrates the existence of the factorization. To prove uniqueness under the constraint that $L$ is unit lower triangular, suppose we have two such factorizations: $A = L_1 U_1 = L_2 U_2$.\nHere $L_1, L_2$ are unit lower triangular and $U_1, U_2$ are upper triangular. The condition on the leading principal minors ensures $A$ is nonsingular (as we will see, $u_{33}$ is also non-zero, meaning $\\det(U) \\neq 0$). Thus, $L_1, U_1, L_2, U_2$ are all nonsingular.\nWe can write $L_2^{-1} L_1 = U_2 U_1^{-1}$.\nThe inverse of a unit lower triangular matrix ($L_2^{-1}$) is also unit lower triangular. The product of two unit lower triangular matrices ($L_2^{-1}L_1$) is unit lower triangular.\nThe inverse of an upper triangular matrix ($U_1^{-1}$) is also upper triangular. The product of two upper triangular matrices ($U_2 U_1^{-1}$) is upper triangular.\nTherefore, the matrix $M = L_2^{-1} L_1 = U_2 U_1^{-1}$ must be simultaneously unit lower triangular and upper triangular. The only such matrix is the identity matrix, $I$.\nThus, $L_2^{-1} L_1 = I \\implies L_1 = L_2$, and $U_2 U_1^{-1} = I \\implies U_1 = U_2$. The factorization is unique.\n\n### Derivation of $u_{33}$\nFinally, we derive the closed-form expression for $u_{33}$ in terms of the original entries $a_{ij}$.\n$$ u_{33} = a_{33}^{(2)} = a_{33}^{(1)} - l_{32}a_{23}^{(1)} $$\nSubstitute the expressions for $a_{33}^{(1)}$, $a_{23}^{(1)}$, and $l_{32}$:\n$$ u_{33} = \\left( a_{33} - l_{31}a_{13} \\right) - \\left( \\frac{a_{32}^{(1)}}{a_{22}^{(1)}} \\right) \\left( a_{23} - l_{21}a_{13} \\right) $$\n$$ u_{33} = \\left( a_{33} - \\frac{a_{31}a_{13}}{a_{11}} \\right) - \\left( \\frac{a_{11}a_{32} - a_{31}a_{12}}{a_{11}a_{22} - a_{21}a_{12}} \\right) \\left( a_{23} - \\frac{a_{21}a_{13}}{a_{11}} \\right) $$\n$$ u_{33} = \\frac{a_{11}a_{33} - a_{31}a_{13}}{a_{11}} - \\left( \\frac{a_{11}a_{32} - a_{31}a_{12}}{a_{11}a_{22} - a_{21}a_{12}} \\right) \\left( \\frac{a_{11}a_{23} - a_{21}a_{13}}{a_{11}} \\right) $$\nTo combine these terms, we use the common denominator $a_{11}(a_{11}a_{22} - a_{21}a_{12})$:\n$$ u_{33} = \\frac{(a_{11}a_{33} - a_{31}a_{13})(a_{11}a_{22} - a_{21}a_{12}) - (a_{11}a_{32} - a_{31}a_{12})(a_{11}a_{23} - a_{21}a_{13})}{a_{11}(a_{11}a_{22} - a_{21}a_{12})} $$\nLet's expand the numerator.\nFirst term: $(a_{11}a_{33} - a_{13}a_{31})(a_{11}a_{22} - a_{12}a_{21}) = a_{11}^2a_{22}a_{33} - a_{11}a_{12}a_{21}a_{33} - a_{11}a_{13}a_{22}a_{31} + a_{12}a_{13}a_{21}a_{31}$\nSecond term: $(a_{11}a_{32} - a_{12}a_{31})(a_{11}a_{23} - a_{13}a_{21}) = a_{11}^2a_{23}a_{32} - a_{11}a_{13}a_{21}a_{32} - a_{11}a_{12}a_{23}a_{31} + a_{12}a_{13}a_{21}a_{31}$\nSubtracting the second expansion from the first, the term $a_{12}a_{13}a_{21}a_{31}$ cancels out. The numerator becomes:\n$$ \\mathrm{Num} = a_{11}^2a_{22}a_{33} - a_{11}a_{12}a_{21}a_{33} - a_{11}a_{13}a_{22}a_{31} - a_{11}^2a_{23}a_{32} + a_{11}a_{13}a_{21}a_{32} + a_{11}a_{12}a_{23}a_{31} $$\nWe can factor out $a_{11}$ from every term in the numerator:\n$$ \\mathrm{Num} = a_{11} \\left[ a_{11}a_{22}a_{33} - a_{12}a_{21}a_{33} - a_{13}a_{22}a_{31} - a_{11}a_{23}a_{32} + a_{13}a_{21}a_{32} + a_{12}a_{23}a_{31} \\right] $$\nThe expression in the square brackets is precisely the definition of the determinant of $A$, $\\det(A)$, calculated by cofactor expansion along the first row:\n$$ \\det(A) = a_{11}(a_{22}a_{33} - a_{23}a_{32}) - a_{12}(a_{21}a_{33} - a_{23}a_{31}) + a_{13}(a_{21}a_{32} - a_{22}a_{31}) $$\nRearranging the terms in the bracket verifies they match $\\det(A)$.\nSo, the numerator is $a_{11} \\det(A)$.\nSubstituting this back into the expression for $u_{33}$:\n$$ u_{33} = \\frac{a_{11} \\det(A)}{a_{11}(a_{11}a_{22} - a_{21}a_{12})} $$\nCanceling the common factor $a_{11}$ (which is non-zero) yields:\n$$ u_{33} = \\frac{\\det(A)}{a_{11}a_{22} - a_{12}a_{21}} $$\nThis is a known result relating the diagonal elements of $U$ to the determinants of the leading principal submatrices, known as $\\det(A_k) = u_{11}u_{22}\\dots u_{kk}$ which implies $u_{kk} = \\det(A_k)/\\det(A_{k-1})$. For $k=3$, this is $u_{33}=\\det(A_3)/\\det(A_2)$.\nThe final answer requires the full expression in terms of $a_{ij}$.\n$$ u_{33} = \\frac{a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33}}{a_{11}a_{22} - a_{12}a_{21}} $$", "answer": "$$ \\boxed{\\frac{a_{11}a_{22}a_{33} + a_{12}a_{23}a_{31} + a_{13}a_{21}a_{32} - a_{13}a_{22}a_{31} - a_{11}a_{23}a_{32} - a_{12}a_{21}a_{33}}{a_{11}a_{22} - a_{12}a_{21}}} $$", "id": "3545102"}, {"introduction": "While the LU factorization with a unit lower triangular matrix $L$ is unique, this is just one choice among many. This practice explores the family of possible LU factorizations by demonstrating how they are all related through diagonal scaling [@problem_id:3545095]. By solving for a specific scaling matrix that satisfies given constraints, you will gain a concrete understanding of why the more general $LDU$ form is needed to fully characterize uniqueness.", "problem": "Let $A \\in \\mathbb{R}^{3 \\times 3}$ be the matrix\n$$\nA \\;=\\; \\begin{pmatrix}\n2 & 4 & 6 \\\\\n1 & 5 & 7 \\\\\n3 & 1 & 8\n\\end{pmatrix}.\n$$\nWork from first principles of triangular factorization in numerical linear algebra.\n\n(1) Using only the definition of a Lower–Upper (LU) factorization and the mechanics of Gaussian elimination without row exchanges, verify that the first two leading principal minors of $A$ are nonzero and construct an $LU$ factorization $A = LU$ with $L$ unit lower triangular (that is, lower triangular with all $1$’s on the diagonal) and $U$ upper triangular. Justify existence and uniqueness of this unit-diagonal factorization from these checks, using only foundational facts about triangular systems and elimination.\n\n(2) Suppose the unit-diagonal constraint on $L$ is dropped. Using only the definition of an $LU$ factorization (with $L$ lower triangular and $U$ upper triangular, both invertible) and algebraic properties of triangular matrices, characterize all possible alternative factorizations $A = \\widetilde{L}\\,\\widetilde{U}$ in terms of invertible diagonal scalings. Your characterization must be derived from first principles and must not assume any uniqueness beyond what follows from the triangular structure.\n\n(3) Among all such alternative factorizations, determine the unique diagonal matrix $D = \\mathrm{diag}(d_{1}, d_{2}, d_{3})$ that simultaneously enforces the following constraints on the pair $(\\widetilde{L}, \\widetilde{U})$ produced by your characterization in part (2):\n- the first and second diagonal entries of $\\widetilde{L}$ are $3$ and $\\tfrac{1}{2}$, respectively;\n- the determinant of $\\widetilde{U}$ is $17$.\n\nProvide your final answer as the row vector $(d_{1}, d_{2}, d_{3})$. No rounding is required; report exact values.", "solution": "The problem is assessed to be valid as it is scientifically grounded in numerical linear algebra, well-posed, and objective. It consists of a standard, verifiable set of calculations and theoretical justifications regarding LU factorization.\n\n(1) We are given the matrix $A \\in \\mathbb{R}^{3 \\times 3}$ as\n$$\nA \\;=\\; \\begin{pmatrix}\n2 & 4 & 6 \\\\\n1 & 5 & 7 \\\\\n3 & 1 & 8\n\\end{pmatrix}.\n$$\nThe first part of the problem requires verification that the first two leading principal minors of $A$ are nonzero, and based on this, the construction of a unit-diagonal LU factorization $A = LU$.\n\nThe leading principal submatrices of $A$ are the upper-left submatrices. The $k$-th leading principal minor, denoted $\\Delta_k$, is the determinant of the $k \\times k$ leading principal submatrix.\n\nFor $k=1$, the first leading principal submatrix is $A[1:1, 1:1] = \\begin{pmatrix} 2 \\end{pmatrix}$. The first leading principal minor is\n$$\n\\Delta_1 = \\det\\begin{pmatrix} 2 \\end{pmatrix} = 2.\n$$\nSince $\\Delta_1 = 2 \\neq 0$, the first minor is nonzero.\n\nFor $k=2$, the second leading principal submatrix is $A[1:2, 1:2] = \\begin{pmatrix} 2 & 4 \\\\ 1 & 5 \\end{pmatrix}$. The second leading principal minor is\n$$\n\\Delta_2 = \\det\\begin{pmatrix} 2 & 4 \\\\ 1 & 5 \\end{pmatrix} = (2)(5) - (4)(1) = 10 - 4 = 6.\n$$\nSince $\\Delta_2 = 6 \\neq 0$, the second minor is also nonzero.\n\nThe existence and uniqueness of a unit-diagonal LU factorization $A=LU$ (where $L$ has $1$'s on its diagonal) is guaranteed if all leading principal minors of $A$ are non-zero. The process of Gaussian elimination without row exchanges provides the foundation for this fact. The pivot element at step $k$ of the elimination, $u_{kk}$, is given by the ratio of successive leading principal minors: $u_{kk} = \\Delta_k / \\Delta_{k-1}$ (with $\\Delta_0 = 1$). For the process to proceed without division by zero, all pivots must be nonzero, which is equivalent to all leading principal minors being nonzero. Since each multiplier $l_{ij}$ for $i>j$ is uniquely determined by $l_{ij} = a_{ij}^{(j-1)} / u_{jj}$, where $a_{ij}^{(j-1)}$ is the entry in the matrix after $j-1$ steps, the entire process is unique. We have verified $\\Delta_1 \\neq 0$ and $\\Delta_2 \\neq 0$, which ensures the first two steps of Gaussian elimination are well-defined.\n\nWe now construct the factorization $A=LU$ using Gaussian elimination.\nStarting with $A$:\n$$\nA^{(0)} = \\begin{pmatrix}\n2 & 4 & 6 \\\\\n1 & 5 & 7 \\\\\n3 & 1 & 8\n\\end{pmatrix}\n$$\nStep 1: Use the first pivot $a_{11} = 2$ to zero out the entries below it.\nThe multipliers are $l_{21} = \\frac{a_{21}}{a_{11}} = \\frac{1}{2}$ and $l_{31} = \\frac{a_{31}}{a_{11}} = \\frac{3}{2}$.\nThe row operations are $R_2 \\leftarrow R_2 - l_{21} R_1$ and $R_3 \\leftarrow R_3 - l_{31} R_1$.\n$R_2 \\leftarrow R_2 - \\frac{1}{2} R_1 = (1, 5, 7) - (\\frac{1}{2})(2, 4, 6) = (1, 5, 7) - (1, 2, 3) = (0, 3, 4)$.\n$R_3 \\leftarrow R_3 - \\frac{3}{2} R_1 = (3, 1, 8) - (\\frac{3}{2})(2, 4, 6) = (3, 1, 8) - (3, 6, 9) = (0, -5, -1)$.\nThe matrix after step $1$ is:\n$$\nA^{(1)} = \\begin{pmatrix}\n2 & 4 & 6 \\\\\n0 & 3 & 4 \\\\\n0 & -5 & -1\n\\end{pmatrix}\n$$\nStep 2: Use the second pivot $a_{22}^{(1)} = 3$ to zero out the entry below it.\nThe multiplier is $l_{32} = \\frac{a_{32}^{(1)}}{a_{22}^{(1)}} = \\frac{-5}{3}$.\nThe row operation is $R_3 \\leftarrow R_3 - l_{32} R_2$.\n$R_3 \\leftarrow R_3 - (-\\frac{5}{3}) R_2 = (0, -5, -1) + (\\frac{5}{3})(0, 3, 4) = (0, -5, -1) + (0, 5, \\frac{20}{3}) = (0, 0, -1+\\frac{20}{3}) = (0, 0, \\frac{17}{3})$.\nThe final upper triangular matrix $U$ is:\n$$\nU = A^{(2)} = \\begin{pmatrix}\n2 & 4 & 6 \\\\\n0 & 3 & 4 \\\\\n0 & 0 & \\frac{17}{3}\n\\end{pmatrix}\n$$\nThe unit lower triangular matrix $L$ is formed by the multipliers:\n$$\nL = \\begin{pmatrix}\n1 & 0 & 0 \\\\\nl_{21} & 1 & 0 \\\\\nl_{31} & l_{32} & 1\n\\end{pmatrix} = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n\\frac{1}{2} & 1 & 0 \\\\\n\\frac{3}{2} & -\\frac{5}{3} & 1\n\\end{pmatrix}\n$$\n\n(2) We now drop the unit-diagonal constraint. Let $A=LU$ be the unique factorization from part (1) where $L$ is unit lower triangular and $U$ is upper triangular. Let $A = \\widetilde{L}\\widetilde{U}$ be any other factorization where $\\widetilde{L}$ is lower triangular and $\\widetilde{U}$ is upper triangular. Since $\\det(A) = \\det(L)\\det(U) = (1) \\cdot (2 \\cdot 3 \\cdot \\frac{17}{3}) = 34 \\neq 0$, $A$ is invertible, and so must be $\\widetilde{L}$ and $\\widetilde{U}$.\n\nFrom $LU = \\widetilde{L}\\widetilde{U}$, we can multiply by inverses. For instance, $\\widetilde{L}^{-1}LU = \\widetilde{U}$. Since $\\widetilde{L}$ is invertible lower triangular, its inverse $\\widetilde{L}^{-1}$ is also lower triangular. The product of lower triangular matrices $\\widetilde{L}^{-1}L$ is lower triangular. This implies that $\\widetilde{U}$ is the product of a lower triangular matrix and an upper triangular matrix $U$. This doesn't seem to lead anywhere.\n\nLet's rearrange as $\\widetilde{L}^{-1}L = \\widetilde{U}U^{-1}$.\nThe left hand side, $\\widetilde{L}^{-1}L$, is a product of two lower triangular matrices, so it is lower triangular.\nThe right hand side, $\\widetilde{U}U^{-1}$, is a product of two upper triangular matrices, so it is upper triangular.\nThe only way a lower triangular matrix can be equal to an upper triangular matrix is if it is a diagonal matrix. Let us call this matrix $D$.\nSo, $\\widetilde{L}^{-1}L = D$ and $\\widetilde{U}U^{-1} = D$, where $D$ is an invertible diagonal matrix. Let $D = \\mathrm{diag}(d_1, d_2, \\dots, d_n)$.\nFrom the first equality, $L = \\widetilde{L}D$, which implies $\\widetilde{L} = LD^{-1}$.\nFrom the second equality, $\\widetilde{U} = DU$.\nThus, any alternative factorization must be of the form $A = \\widetilde{L}\\widetilde{U} = (LD^{-1})(DU)$. Let's rename the scaling matrix. A more standard convention is to write the factorization as $A = (LD)(D^{-1}U)$, where $D$ is an invertible diagonal matrix. Let $\\widehat{L} = LD$ and $\\widehat{U} = D^{-1}U$.\n$\\widehat{L}$ is a product of a lower triangular matrix and a diagonal matrix, which is lower triangular.\n$\\widehat{U}$ is a product of a diagonal matrix and an upper triangular matrix, which is upper triangular.\nThe product is $\\widehat{L}\\widehat{U} = (LD)(D^{-1}U) = L(DD^{-1})U = LIU = LU = A$.\nSo, all possible LU factorizations (where the factors are not constrained to have unit diagonals) are given by $(\\widetilde{L}, \\widetilde{U}) = (LD, D^{-1}U)$, where $L$ and $U$ are the unique factors from the unit-diagonal LU factorization, and $D$ is any invertible diagonal matrix of the same dimension.\n\n(3) We need to find the specific diagonal matrix $D = \\mathrm{diag}(d_{1}, d_{2}, d_{3})$ that satisfies three given constraints. The new factorization is $\\widetilde{L} = LD$ and $\\widetilde{U} = D^{-1}U$.\nUsing the $L$ and $U$ from part (1):\n$$\nL = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n\\frac{1}{2} & 1 & 0 \\\\\n\\frac{3}{2} & -\\frac{5}{3} & 1\n\\end{pmatrix}, \\quad U = \\begin{pmatrix}\n2 & 4 & 6 \\\\\n0 & 3 & 4 \\\\\n0 & 0 & \\frac{17}{3}\n\\end{pmatrix}.\n$$\nLet $D = \\begin{pmatrix} d_1 & 0 & 0 \\\\ 0 & d_2 & 0 \\\\ 0 & 0 & d_3 \\end{pmatrix}$.\nThen,\n$$\n\\widetilde{L} = LD = \\begin{pmatrix}\n1 & 0 & 0 \\\\\n\\frac{1}{2} & 1 & 0 \\\\\n\\frac{3}{2} & -\\frac{5}{3} & 1\n\\end{pmatrix} \\begin{pmatrix}\nd_1 & 0 & 0 \\\\\n0 & d_2 & 0 \\\\\n0 & 0 & d_3\n\\end{pmatrix} = \\begin{pmatrix}\nd_1 & 0 & 0 \\\\\n\\frac{1}{2}d_1 & d_2 & 0 \\\\\n\\frac{3}{2}d_1 & -\\frac{5}{3}d_2 & d_3\n\\end{pmatrix}.\n$$\nAnd,\n$$\n\\widetilde{U} = D^{-1}U = \\begin{pmatrix}\nd_1^{-1} & 0 & 0 \\\\\n0 & d_2^{-1} & 0 \\\\\n0 & 0 & d_3^{-1}\n\\end{pmatrix} \\begin{pmatrix}\n2 & 4 & 6 \\\\\n0 & 3 & 4 \\\\\n0 & 0 & \\frac{17}{3}\n\\end{pmatrix} = \\begin{pmatrix}\n2d_1^{-1} & 4d_1^{-1} & 6d_1^{-1} \\\\\n0 & 3d_2^{-1} & 4d_2^{-1} \\\\\n0 & 0 & \\frac{17}{3}d_3^{-1}\n\\end{pmatrix}.\n$$\nNow we apply the given constraints:\nConstraint 1: The first diagonal entry of $\\widetilde{L}$ is $3$.\nThe diagonal entries of $\\widetilde{L}$ are $\\tilde{l}_{11} = d_1$, $\\tilde{l}_{22} = d_2$, $\\tilde{l}_{33} = d_3$.\nSo, $\\tilde{l}_{11} = d_1 = 3$.\n\nConstraint 2: The second diagonal entry of $\\widetilde{L}$ is $\\frac{1}{2}$.\nSo, $\\tilde{l}_{22} = d_2 = \\frac{1}{2}$.\n\nConstraint 3: The determinant of $\\widetilde{U}$ is $17$.\nThe determinant of a triangular matrix is the product of its diagonal entries.\n$$\n\\det(\\widetilde{U}) = (2d_1^{-1}) \\cdot (3d_2^{-1}) \\cdot (\\frac{17}{3}d_3^{-1}) = \\frac{2 \\cdot 3 \\cdot 17}{3 \\cdot d_1 d_2 d_3} = \\frac{34}{d_1 d_2 d_3}.\n$$\nWe are given that $\\det(\\widetilde{U}) = 17$.\n$$\n\\frac{34}{d_1 d_2 d_3} = 17 \\implies 34 = 17 d_1 d_2 d_3 \\implies 2 = d_1 d_2 d_3.\n$$\nSubstituting the values we found for $d_1$ and $d_2$:\n$$\n2 = (3)\\left(\\frac{1}{2}\\right)d_3 \\implies 2 = \\frac{3}{2}d_3.\n$$\nSolving for $d_3$:\n$$\nd_3 = 2 \\cdot \\frac{2}{3} = \\frac{4}{3}.\n$$\nThe diagonal entries of the scaling matrix $D$ are $d_1=3$, $d_2=\\frac{1}{2}$, and $d_3=\\frac{4}{3}$. The required final answer is the row vector $(d_1, d_2, d_3)$.\nThus, the vector is $(3, \\frac{1}{2}, \\frac{4}{3})$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 3 & \\frac{1}{2} & \\frac{4}{3} \\end{pmatrix}}\n$$", "id": "3545095"}, {"introduction": "In numerical analysis, theoretical existence does not always imply practical utility. This computational exercise demonstrates a critical pitfall: even when an LU factorization is guaranteed to exist, a very small pivot can lead to explosive growth in the elements of $U$, causing catastrophic loss of precision [@problem_id:3545136]. By calculating the element growth factor for a specially designed matrix, you will witness why pivoting is an essential strategy for numerical stability in real-world applications.", "problem": "Consider the Lower-Upper (LU) factorization of a square matrix, where a matrix $A \\in \\mathbb{R}^{n \\times n}$ is written as $A = L U$ with $L$ unit lower triangular and $U$ upper triangular. A classical existence criterion states that an LU factorization without row pivoting exists if and only if each leading principal minor of $A$ is nonzero. Uniqueness holds under the unit diagonal constraint on $L$. Numerical linear algebra further studies how small pivots can cause severe numerical ill-conditioning, manifesting as large element growth in $U$ during Gaussian Elimination (GE) without pivoting.\n\nYour task is to instantiate a family of matrices that has exact LU existence and uniqueness while presenting severe numerical ill-conditioning through a very small leading principal minor, and to quantify the risk via the element growth of $U$ produced by Doolittle’s algorithm (GE without pivoting). For parameters $(\\epsilon,\\alpha) \\in \\mathbb{R}^2$ with $\\epsilon \\neq 0$ and $\\alpha \\neq 0$, define the matrix\n$$\nA(\\epsilon,\\alpha) \\;=\\;\n\\begin{bmatrix}\n\\epsilon & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1+\\alpha\n\\end{bmatrix}\n\\in \\mathbb{R}^{3 \\times 3}.\n$$\nThis family is designed so that the first leading principal minor, namely the $(1,1)$ entry, is $\\epsilon$, which can be made arbitrarily small while keeping exact LU existence intact, provided the higher-order leading principal minors are also nonzero.\n\nStarting from the core definitions and facts above, implement the following steps for each test case:\n- Construct $A(\\epsilon,\\alpha)$ as specified.\n- Compute an LU factorization $A = L U$ without pivoting, with $L$ unit lower triangular, using Doolittle’s algorithm and standard floating-point arithmetic. You must not use any pivoting; detect and divide by the pivots $U_{kk}$ directly.\n- Compute the element growth factor\n$$\n\\gamma(A) \\;=\\; \\frac{\\max_{i,j} |U_{ij}|}{\\max_{i,j} |A_{ij}|}.\n$$\n- Decide the exact existence of LU without pivoting by verifying the nonvanishing of leading principal minors of $A(\\epsilon,\\alpha)$. Use the fundamental characterization that LU without pivoting exists if and only if each leading principal minor is nonzero, and determine existence by symbolic reasoning appropriate to $A(\\epsilon,\\alpha)$.\n- Decide uniqueness under the unit diagonal constraint on $L$ in the case where LU exists.\n\nYour program must process the following test suite of parameter pairs $(\\epsilon,\\alpha)$:\n- Test $1$: $(\\epsilon,\\alpha) = (10^{-2}, 10^{-3})$.\n- Test $2$: $(\\epsilon,\\alpha) = (10^{-8}, 10^{-3})$.\n- Test $3$: $(\\epsilon,\\alpha) = (10^{-16}, 10^{-3})$.\n- Test $4$: $(\\epsilon,\\alpha) = (-10^{-8}, 10^{-3})$.\n- Test $5$: $(\\epsilon,\\alpha) = (1 - 10^{-12}, 10^{-3})$.\n\nFor each test case, your program must output a list of the form $[\\text{exists}, \\text{unique}, \\gamma]$, where $\\text{exists}$ and $\\text{unique}$ are boolean values and $\\gamma$ is a floating-point number representing the element growth factor $\\gamma(A)$ computed from the numerically obtained $U$ and the given $A$. Aggregate the results for all test cases into a single line of output containing a comma-separated list of these per-case lists, enclosed in square brackets. For example, the output must look like\n$$\n[\\,[\\text{exists}_1,\\text{unique}_1,\\gamma_1],\\,[\\text{exists}_2,\\text{unique}_2,\\gamma_2],\\,\\dots\\,]\n$$\nwith no additional text.\n\nNo physical units are involved, so none are required. Angles are not used. Percentages are not used; all values are represented as booleans or floating-point numbers. Ensure scientific realism by implementing exact existence and uniqueness decisions from the leading principal minors of $A(\\epsilon,\\alpha)$ and by computing $\\gamma(A)$ from an actual unpivoted LU factorization in floating-point arithmetic for each specified test case.", "solution": "The problem submitted for consideration is valid. It is scientifically grounded in the principles of numerical linear algebra, specifically concerning the existence, uniqueness, and numerical stability of the LU factorization. The problem is well-posed, with all necessary data and conditions provided, and it is free from ambiguity, contradiction, or factual error. We may therefore proceed with a full solution.\n\nThe core of the problem is to analyze the LU factorization of a parameterized matrix family $A(\\epsilon,\\alpha)$ for its existence, uniqueness, and numerical properties. The matrix is given by:\n$$\nA(\\epsilon,\\alpha) \\;=\\;\n\\begin{bmatrix}\n\\epsilon & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1+\\alpha\n\\end{bmatrix}\n$$\nfor parameters $(\\epsilon,\\alpha) \\in \\mathbb{R}^2$ with $\\epsilon \\neq 0$ and $\\alpha \\neq 0$.\n\n**1. Existence and Uniqueness of the LU Factorization**\n\nA fundamental theorem in linear algebra states that a square matrix $A$ has an LU factorization (without row pivoting) if and only if all of its leading principal minors are nonzero. If such a factorization exists and the matrix $A$ is invertible, then the factorization $A = LU$ is unique under the constraint that $L$ is a unit lower triangular matrix (i.e., $L_{ii}=1$ for all $i$).\n\nWe must compute the leading principal minors of $A(\\epsilon,\\alpha)$. Let $M_k$ be the $k$-th leading principal minor.\n\nThe first leading principal minor, $M_1$, is the determinant of the upper-left $1 \\times 1$ submatrix:\n$$\nM_1 = \\det([\\epsilon]) = \\epsilon\n$$\nThe problem statement specifies $\\epsilon \\neq 0$, so $M_1$ is guaranteed to be nonzero.\n\nThe second leading principal minor, $M_2$, is the determinant of the upper-left $2 \\times 2$ submatrix:\n$$\nM_2 = \\det \\begin{bmatrix} \\epsilon & 1 \\\\ 1 & 1 \\end{bmatrix} = (\\epsilon)(1) - (1)(1) = \\epsilon - 1\n$$\nFor $M_2$ to be nonzero, we must have $\\epsilon \\neq 1$.\n\nThe third leading principal minor, $M_3$, is the determinant of the entire matrix $A$:\n$$\nM_3 = \\det(A) = \\det \\begin{bmatrix} \\epsilon & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 1 & 1 & 1+\\alpha \\end{bmatrix}\n$$\nWe can simplify the calculation by performing a row operation that does not change the determinant's value. Subtracting row $2$ from row $3$ ($R_3 \\to R_3 - R_2$):\n$$\nM_3 = \\det \\begin{bmatrix} \\epsilon & 1 & 1 \\\\ 1 & 1 & 1 \\\\ 0 & 0 & \\alpha \\end{bmatrix}\n$$\nExpanding the determinant along the third row yields:\n$$\nM_3 = \\alpha \\cdot ( -1 )^{3+3} \\det \\begin{bmatrix} \\epsilon & 1 \\\\ 1 & 1 \\end{bmatrix} = \\alpha (\\epsilon - 1)\n$$\nFor $M_3$ to be nonzero, we require $\\alpha \\neq 0$ and $\\epsilon - 1 \\neq 0$, which means $\\epsilon \\neq 1$. The condition $\\alpha \\neq 0$ is given in the problem statement.\n\nCombining these conditions, the LU factorization of $A(\\epsilon,\\alpha)$ without pivoting exists if and only if:\n1. $M_1 = \\epsilon \\neq 0$ (given)\n2. $M_2 = \\epsilon - 1 \\neq 0 \\implies \\epsilon \\neq 1$\n3. $M_3 = \\alpha(\\epsilon - 1) \\neq 0 \\implies \\alpha \\neq 0$ (given) and $\\epsilon \\neq 1$\n\nThe sole condition for existence is therefore $\\epsilon \\neq 1$. If this condition holds, the matrix $A$ is invertible since its determinant $M_3$ is nonzero. Consequently, the LU factorization with a unit lower triangular matrix $L$ is unique. For all test cases provided, $\\epsilon$ is never equal to $1$. Thus, for every test case, the LU factorization both exists and is unique.\n\n**2. Numerical Stability and the Growth Factor**\n\nThe numerical stability of Gaussian elimination is often assessed by the element growth factor, $\\gamma(A)$, defined as:\n$$\n\\gamma(A) \\;=\\; \\frac{\\max_{i,j} |U_{ij}|}{\\max_{i,j} |A_{ij}|}\n$$\nThis factor measures the extent to which the magnitudes of the matrix elements grow during the elimination process. A large $\\gamma(A)$ indicates potential ill-conditioning and loss of precision.\n\nWe compute the upper triangular matrix $U$ using Doolittle's algorithm, which is equivalent to performing Gaussian elimination on $A$ to obtain an upper triangular form.\nLet $L$ be unit lower triangular and $U$ be upper triangular such that $A=LU$.\n$$\n\\begin{bmatrix}\n\\epsilon & 1 & 1\\\\\n1 & 1 & 1\\\\\n1 & 1 & 1+\\alpha\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 & 0 & 0 \\\\\nl_{21} & 1 & 0 \\\\\nl_{31} & l_{32} & 1\n\\end{bmatrix}\n\\begin{bmatrix}\nu_{11} & u_{12} & u_{13} \\\\\n0 & u_{22} & u_{23} \\\\\n0 & 0 & u_{33}\n\\end{bmatrix}\n$$\nThe algorithm proceeds as follows:\n- **First row of $U$**: $u_{1j} = a_{1j}$.\n  $u_{11} = \\epsilon$, $u_{12} = 1$, $u_{13} = 1$.\n- **First column of $L$**: $l_{i1} = a_{i1} / u_{11}$.\n  $l_{21} = 1/\\epsilon$, $l_{31} = 1/\\epsilon$.\n- **Second row of $U$**: $u_{2j} = a_{2j} - l_{21} u_{1j}$.\n  $u_{22} = a_{22} - l_{21} u_{12} = 1 - (1/\\epsilon)(1) = 1 - 1/\\epsilon = (\\epsilon - 1)/\\epsilon$.\n  $u_{23} = a_{23} - l_{21} u_{13} = 1 - (1/\\epsilon)(1) = 1 - 1/\\epsilon = (\\epsilon - 1)/\\epsilon$.\n  The first pivot is $u_{11} = \\epsilon$. If $|\\epsilon|$ is small, the multiplier $l_{21} = 1/\\epsilon$ becomes very large. This large multiplier can lead to a large element $u_{22}$, since $|u_{22}| \\approx | -1/\\epsilon |$. This is the primary mechanism for element growth in this problem.\n- **Second column of $L$**: $l_{32} = (a_{32} - l_{31}u_{12}) / u_{22}$.\n  $l_{32} = (1 - (1/\\epsilon)(1)) / ((\\epsilon - 1)/\\epsilon) = ((\\epsilon - 1)/\\epsilon) / ((\\epsilon - 1)/\\epsilon) = 1$. (This holds since $\\epsilon \\neq 1$)\n- **Third row of $U$**: $u_{33} = a_{33} - (l_{31}u_{13} + l_{32}u_{23})$.\n  $u_{33} = (1+\\alpha) - ((1/\\epsilon)(1) + (1)((\\epsilon-1)/\\epsilon)) = (1+\\alpha) - (1/\\epsilon + (\\epsilon-1)/\\epsilon) = (1+\\alpha) - (\\epsilon/\\epsilon) = 1 + \\alpha - 1 = \\alpha$.\n\nSo, the resulting upper triangular matrix is:\n$$\nU =\n\\begin{bmatrix}\n\\epsilon & 1 & 1 \\\\\n0 & 1 - 1/\\epsilon & 1 - 1/\\epsilon \\\\\n0 & 0 & \\alpha\n\\end{bmatrix}\n$$\nThe maximum element in $A$ is $\\max_{i,j}|A_{ij}| = \\max(|\\epsilon|,|1|,|1+\\alpha|)$. For the given test cases, this is always $1+\\alpha = 1.001$.\nThe maximum element in $U$ is $\\max_{i,j}|U_{ij}| = \\max(|\\epsilon|,|1|,|1-1/\\epsilon|,|\\alpha|)$. When $|\\epsilon|$ is small, the dominant term is $|1-1/\\epsilon| \\approx 1/|\\epsilon|$.\n\n**3. Evaluation of Test Cases**\n\n- **Cases 1-4**: $\\epsilon$ is small ($10^{-2}, 10^{-8}, 10^{-16}, -10^{-8}$). In these cases, $|U_{22}| = |1-1/\\epsilon| \\approx 1/|\\epsilon|$, which is large. This leads to a large growth factor $\\gamma(A)$, demonstrating the ill-conditioning caused by a small first pivot.\n- **Case 5**: $\\epsilon = 1 - 10^{-12}$ is close to $1$. In this case, the first pivot $u_{11}=\\epsilon$ is not small. The second pivot, $u_{22} = (\\epsilon-1)/\\epsilon = (-10^{-12})/(1-10^{-12}) \\approx -10^{-12}$, is extremely small. However, this does not cause subsequent element growth in $U$. The multipliers in $L$ remain bounded ($l_{21} \\approx 1, l_{31} \\approx 1, l_{32} = 1$), and the elements of $U$ also remain small, with $\\max|U_{ij}|=1$. Therefore, the growth factor $\\gamma(A)$ is close to $1$, indicating numerical stability despite a near-singular leading principal submatrix.\n\nThe implementation will compute these values numerically for each test case. The boolean values for existence and uniqueness will be `True` for all cases as $\\epsilon \\neq 1$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the LU factorization problem for a suite of test cases.\n    For each case (epsilon, alpha), it determines existence and uniqueness of the\n    LU factorization without pivoting and calculates the element growth factor.\n    \"\"\"\n    test_cases = [\n        (10**-2, 10**-3),   # Test 1\n        (10**-8, 10**-3),   # Test 2\n        (10**-16, 10**-3),  # Test 3\n        (-10**-8, 10**-3),  # Test 4\n        (1 - 10**-12, 10**-3) # Test 5\n    ]\n\n    results = []\n    \n    for eps, alpha in test_cases:\n        # Step 1: Decide exact existence and uniqueness\n        # An LU factorization without pivoting exists iff all leading principal\n        # minors are non-zero. For A(epsilon, alpha), the minors are:\n        # M1 = epsilon\n        # M2 = epsilon - 1\n        # M3 = alpha * (epsilon - 1)\n        # Given epsilon != 0 and alpha != 0, existence requires epsilon != 1.\n        # If it exists for an invertible matrix, the LU factorization with\n        # unit L is unique. Invertibility is guaranteed if epsilon != 1.\n        \n        exists = (eps != 1.0)\n        unique = exists\n\n        # Step 2: Construct the matrix A\n        A = np.array([\n            [eps, 1.0, 1.0],\n            [1.0, 1.0, 1.0],\n            [1.0, 1.0, 1.0 + alpha]\n        ], dtype=float)\n\n        # Step 3: Compute the LU factorization without pivoting (Doolittle's algorithm)\n        # The result of forward elimination on A is the matrix U.\n        # We operate on a copy to preserve the original A.\n        U = A.copy()\n        \n        # Elimination process for a 3x3 matrix\n        # Row 2 update\n        if U[0, 0] != 0:\n            multiplier_21 = U[1, 0] / U[0, 0]\n            U[1, :] -= multiplier_21 * U[0, :]\n        \n        # Row 3 update (step 1)\n        if U[0, 0] != 0:\n            multiplier_31 = U[2, 0] / U[0, 0]\n            U[2, :] -= multiplier_31 * U[0, :]\n        \n        # Row 3 update (step 2)\n        if U[1, 1] != 0:\n            multiplier_32 = U[2, 1] / U[1, 1]\n            U[2, :] -= multiplier_32 * U[1, :]\n\n        # Step 4: Compute the element growth factor gamma\n        max_abs_A = np.max(np.abs(A))\n        max_abs_U = np.max(np.abs(U))\n        \n        gamma = max_abs_U / max_abs_A\n        \n        results.append([exists, unique, gamma])\n\n    # Final print statement in the exact required format.\n    # Convert bools to lowercase 'true'/'false' as shown in problem example.\n    results_str = \",\".join([f\"[{str(e).lower()},{str(u).lower()},{g}]\" for e, u, g in results])\n    print(f\"[{results_str}]\")\n\nsolve()\n\n```", "id": "3545136"}]}