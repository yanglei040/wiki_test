{"hands_on_practices": [{"introduction": "The geometric interpretation of the SVD describes how a matrix transforms a unit sphere. We begin by examining a special case: transformations that preserve shape and size. This exercise [@problem_id:3548104] explores reflections, a fundamental type of isometry, and challenges you to connect the algebraic property of having singular values equal to one with the geometric outcome of mapping a circle to a circle of the same size.", "problem": "Let $A \\in \\mathbb{R}^{2 \\times 2}$ be the linear map representing reflection across the line through the origin with direction unit vector $u = (\\cos\\theta, \\sin\\theta)^{\\top}$, where $\\theta \\in \\mathbb{R}$ is arbitrary. The matrix $A$ is given by $A = 2 u u^{\\top} - I_2$, where $I_2$ denotes the $2 \\times 2$ identity matrix. Starting from the definition of the singular value decomposition (SVD), namely $A = U \\Sigma V^{\\top}$ with $U, V \\in \\mathbb{R}^{2 \\times 2}$ orthogonal and $\\Sigma = \\operatorname{diag}(\\sigma_1, \\sigma_2)$ having nonnegative diagonal entries, and from the fundamental characterization that the singular values are the square roots of the eigenvalues of $A^{\\top} A$, derive the singular values of $A$. Then, using only these principles and the geometric meaning of the SVD as describing how $A$ maps the unit circle into an ellipse whose semi-axes are the singular values, explain why the image of the unit circle under $A$ remains a circle. Report your final answer as the ordered pair of singular values in a row vector. No rounding is required.", "solution": "The problem asks for two things: first, to derive the singular values of the reflection matrix $A = 2 u u^{\\top} - I_2$ using the characterization through $A^{\\top} A$, and second, to explain geometrically why the image of the unit circle under $A$ is another circle.\n\nFirst, we validate the problem statement.\nThe givens are:\n- $A \\in \\mathbb{R}^{2 \\times 2}$, a linear map for reflection.\n- The reflection is across the line with direction unit vector $u = (\\cos\\theta, \\sin\\theta)^{\\top}$.\n- The matrix is $A = 2 u u^{\\top} - I_2$, where $I_2$ is the $2 \\times 2$ identity matrix.\n- The Singular Value Decomposition (SVD) is $A = U \\Sigma V^{\\top}$, where $U, V \\in \\mathbb{R}^{2 \\times 2}$ are orthogonal and $\\Sigma = \\operatorname{diag}(\\sigma_1, \\sigma_2)$ with $\\sigma_1 \\ge \\sigma_2 \\ge 0$.\n- The singular values $\\sigma_i$ are the square roots of the eigenvalues of $A^{\\top} A$.\n\nThe problem is scientifically grounded in linear algebra, well-posed with all necessary information, and stated objectively. It does not violate any of the invalidity criteria. Therefore, the problem is valid, and we proceed with the solution.\n\nPart 1: Derivation of Singular Values\n\nAccording to the problem, the singular values of $A$ are the square roots of the eigenvalues of the matrix $A^{\\top} A$. We must first compute $A^{\\top} A$. Let's start by finding the transpose of $A$.\nThe matrix $A$ is given by $A = 2 u u^{\\top} - I_2$.\nIts transpose is:\n$$ A^{\\top} = (2 u u^{\\top} - I_2)^{\\top} = (2 u u^{\\top})^{\\top} - (I_2)^{\\top} $$\nUsing the property $(k B)^{\\top} = k B^{\\top}$ for a scalar $k$ and $(B C)^{\\top} = C^{\\top} B^{\\top}$ for matrices $B, C$, we get:\n$$ (2 u u^{\\top})^{\\top} = 2 (u u^{\\top})^{\\top} = 2 (u^{\\top})^{\\top} u^{\\top} = 2 u u^{\\top} $$\nThe transpose of the identity matrix is itself, $I_2^{\\top} = I_2$.\nSubstituting these back, we find:\n$$ A^{\\top} = 2 u u^{\\top} - I_2 = A $$\nThis shows that the reflection matrix $A$ is symmetric.\n\nNow we compute the product $A^{\\top} A$. Since $A^{\\top} = A$, this is equivalent to computing $A^2$:\n$$ A^{\\top} A = A^2 = (2 u u^{\\top} - I_2)(2 u u^{\\top} - I_2) $$\nExpanding the product:\n$$ A^2 = (2 u u^{\\top})(2 u u^{\\top}) - (2 u u^{\\top})I_2 - I_2(2 u u^{\\top}) + I_2^2 $$\n$$ A^2 = 4 (u u^{\\top} u u^{\\top}) - 2 u u^{\\top} - 2 u u^{\\top} + I_2 $$\nThe vector $u$ is a unit vector, so its inner product with itself, $u^{\\top} u$, is a scalar equal to $1$:\n$$ u^{\\top} u = \\|u\\|_{2}^{2} = \\cos^2\\theta + \\sin^2\\theta = 1 $$\nWe can group the terms in the expansion of $A^2$ as $u (u^{\\top} u) u^{\\top}$:\n$$ A^2 = 4 u (u^{\\top} u) u^{\\top} - 4 u u^{\\top} + I_2 $$\nSubstituting $u^{\\top} u = 1$:\n$$ A^2 = 4 u (1) u^{\\top} - 4 u u^{\\top} + I_2 = 4 u u^{\\top} - 4 u u^{\\top} + I_2 = I_2 $$\nSo, we have found that $A^{\\top} A = I_2$.\n\nNext, we find the eigenvalues of $A^{\\top} A = I_2$. The identity matrix $I_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$ has a characteristic equation $\\det(I_2 - \\lambda I_2) = 0$, which is $(1 - \\lambda)^2 = 0$. The eigenvalues are the roots of this equation, which are $\\lambda_1 = 1$ and $\\lambda_2 = 1$.\n\nThe singular values $\\sigma_1, \\sigma_2$ are the non-negative square roots of the eigenvalues of $A^{\\top} A$.\n$$ \\sigma_1 = \\sqrt{\\lambda_1} = \\sqrt{1} = 1 $$\n$$ \\sigma_2 = \\sqrt{\\lambda_2} = \\sqrt{1} = 1 $$\nBy convention, we order them such that $\\sigma_1 \\ge \\sigma_2$. In this case, they are equal. The singular values of $A$ are $1$ and $1$.\n\nPart 2: Geometric Interpretation\n\nThe problem asks for an explanation of why the image of the unit circle under $A$ is a circle, based on the geometric meaning of the SVD. The SVD of a matrix $A$, given by $A = U \\Sigma V^{\\top}$, describes the action of $A$ on a vector as a sequence of three fundamental geometric transformations:\n1.  A rotation or reflection represented by the orthogonal matrix $V^{\\top}$.\n2.  A scaling along the Cartesian axes, represented by the diagonal matrix $\\Sigma = \\operatorname{diag}(\\sigma_1, \\sigma_2)$.\n3.  Another rotation or reflection represented by the orthogonal matrix $U$.\n\nLet's apply this sequence to the set of all points on the unit circle in $\\mathbb{R}^2$. The unit circle is the set of vectors $x$ such that $\\|x\\|_2 = 1$.\n\n1.  Transformation by $V^{\\top}$: Since $V^{\\top}$ is an orthogonal matrix, it preserves lengths. It maps the unit circle onto itself. The set of points $y = V^{\\top}x$ for all $x$ on the unit circle is still the unit circle.\n\n2.  Transformation by $\\Sigma$: This is the critical step. The matrix $\\Sigma$ scales the components of the vectors $y$. A point $y = (y_1, y_2)^{\\top}$ on the unit circle is transformed into $z = \\Sigma y = (\\sigma_1 y_1, \\sigma_2 y_2)^{\\top}$. The set of all such points $z$ forms an ellipse whose equation is given by $(\\frac{z_1}{\\sigma_1})^2 + (\\frac{z_2}{\\sigma_2})^2 = y_1^2 + y_2^2 = 1$. The semi-axes of this ellipse have lengths equal to the singular values $\\sigma_1$ and $\\sigma_2$.\n\n3.  Transformation by $U$: The final transformation by the orthogonal matrix $U$ takes the ellipse from the previous step and rotates or reflects it. This operation does not change the shape or size of the ellipse, only its orientation in space.\n\nIn our specific case, we have calculated the singular values of the reflection matrix $A$ to be $\\sigma_1 = 1$ and $\\sigma_2 = 1$.\nTherefore, the scaling matrix is:\n$$ \\Sigma = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = I_2 $$\nWhen this scaling is applied in Step 2, the \"ellipse\" has semi-axes of length $\\sigma_1 = 1$ and $\\sigma_2 = 1$. An ellipse with equal semi-axes is, by definition, a circle. The radius of this circle is $1$. The transformation $\\Sigma=I_2$ is the identity transformation, which maps the unit circle to itself.\n\nThus, the sequence of transformations is: unit circle $\\xrightarrow{V^{\\top}}$ unit circle $\\xrightarrow{\\Sigma=I_2}$ unit circle $\\xrightarrow{U}$ unit circle.\n\nThe image of the unit circle under the linear map $A$ remains a circle because the singular values of $A$ are equal. This signifies that the scaling part of the transformation is uniform in all directions, which is characteristic of an isometry. A reflection is an isometry, and isometries map circles to circles of the same radius. The SVD provides the specific mechanism: the non-uniform scaling step becomes a uniform scaling because $\\sigma_1 = \\sigma_2$.\n\nThe final ordered pair of singular values is $(1, 1)$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1 & 1 \\end{pmatrix}}\n$$", "id": "3548104"}, {"introduction": "In contrast to isometries, many linear transformations reduce the dimensionality of the input space. This exercise [@problem_id:3234717] focuses on orthogonal projection, a classic example of a rank-deficient transformation. By analyzing its SVD, you will see how a zero singular value geometrically corresponds to the collapse of the unit circle into a degenerate ellipse—a line segment—providing a powerful visual for the meaning of rank.", "problem": "Consider the linear map $P:\\mathbb{R}^{2}\\to\\mathbb{R}^{2}$ that orthogonally projects every vector onto the line $y=2x$. Starting from the definitions of the Euclidean inner product, orthogonal projection onto a one-dimensional subspace, and the Singular Value Decomposition (SVD) as a factorization $A=U\\Sigma V^{\\top}$ with $U$ and $V$ orthogonal and $\\Sigma$ diagonal with nonnegative entries, do the following:\n\n- Construct the matrix representation of $P$ by expressing it in terms of a unit direction vector for the line $y=2x$.\n- Determine the SVD of $P$ by identifying its singular values and the corresponding left and right singular vectors from first principles.\n- Using the geometric interpretation of SVD, describe how $P$ transforms the unit circle in $\\mathbb{R}^{2}$, including the semi-axis lengths and directions of the resulting image, and comment on whether the image is a degenerate ellipse.\n\nExpress your final answer as the ordered pair of singular values $(\\sigma_{1},\\sigma_{2})$ in a single row using the $\\mathrm{pmatrix}$ environment. No rounding is required.", "solution": "The problem asks for the construction of a projection matrix $P$, its Singular Value Decomposition (SVD), and a geometric interpretation of its action on the unit circle.\n\nFirst, we construct the matrix representation of the linear map $P$ that orthogonally projects vectors in $\\mathbb{R}^{2}$ onto the line $y=2x$.\nA direction vector for the line $y=2x$ is $\\mathbf{d} = \\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$. To create an orthogonal projection matrix, we first need a unit vector in this direction. The norm of $\\mathbf{d}$ is $\\|\\mathbf{d}\\| = \\sqrt{1^{2} + 2^{2}} = \\sqrt{5}$.\nThe unit direction vector is thus $\\mathbf{u} = \\frac{\\mathbf{d}}{\\|\\mathbf{d}\\|} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$.\nThe matrix $P$ for orthogonal projection onto the one-dimensional subspace spanned by a unit vector $\\mathbf{u}$ is given by the outer product $P = \\mathbf{u}\\mathbf{u}^{\\top}$.\nSubstituting our vector $\\mathbf{u}$:\n$$P = \\left(\\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & 2 \\end{pmatrix}\\right) = \\frac{1}{5}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}\\begin{pmatrix} 1 & 2 \\end{pmatrix} = \\frac{1}{5}\\begin{pmatrix} 1 \\cdot 1 & 1 \\cdot 2 \\\\ 2 \\cdot 1 & 2 \\cdot 2 \\end{pmatrix} = \\frac{1}{5}\\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}$$\nThis is the matrix representation of the projection $P$.\n\nNext, we determine the SVD of $P$. The SVD is a factorization $P = U\\Sigma V^{\\top}$. The singular values $\\sigma_{i}$, which form the diagonal of $\\Sigma$, are the square roots of the eigenvalues of the matrix $P^{\\top}P$.\nThe matrix $P$ is symmetric, i.e., $P^{\\top} = P$. Therefore, $P^{\\top}P = P^{2}$.\nFor a projection matrix, it is an idempotent operator, meaning $P^{2} = P$. We can verify this:\n$$P^{2} = \\left(\\frac{1}{5}\\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}\\right)\\left(\\frac{1}{5}\\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix}\\right) = \\frac{1}{25}\\begin{pmatrix} 1(1)+2(2) & 1(2)+2(4) \\\\ 2(1)+4(2) & 2(2)+4(4) \\end{pmatrix} = \\frac{1}{25}\\begin{pmatrix} 5 & 10 \\\\ 10 & 20 \\end{pmatrix} = \\frac{1}{5}\\begin{pmatrix} 1 & 2 \\\\ 2 & 4 \\end{pmatrix} = P$$\nThus, we need to find the eigenvalues of $P$ itself. The eigenvalues of a projection matrix are always $1$ and $0$.\n- Any vector lying on the line of projection is an eigenvector with eigenvalue $\\lambda=1$, since $P\\mathbf{x} = \\mathbf{x}$. The eigenspace for $\\lambda_1=1$ is the line $y=2x$.\n- Any vector orthogonal to the line of projection is mapped to the zero vector, so it is an eigenvector with eigenvalue $\\lambda=0$. The eigenspace for $\\lambda_2=0$ is the line orthogonal to $y=2x$, which is $y=-x/2$.\n\nThe eigenvalues of $P$ are $\\lambda_{1}=1$ and $\\lambda_{2}=0$. The singular values are the square roots of these eigenvalues, ordered non-increasingly:\n$\\sigma_{1} = \\sqrt{\\lambda_{1}} = \\sqrt{1} = 1$\n$\\sigma_{2} = \\sqrt{\\lambda_{2}} = \\sqrt{0} = 0$\nSo, the matrix $\\Sigma$ is $\\Sigma = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix}$.\n\nThe columns of $V$ (the right singular vectors, $\\mathbf{v}_i$) are the orthonormal eigenvectors of $P^{\\top}P = P$.\n- For $\\lambda_{1}=1$, the eigenvector is any vector along the line $y=2x$. We choose the unit vector $\\mathbf{v}_{1} = \\mathbf{u} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$.\n- For $\\lambda_{2}=0$, the eigenvector must be orthogonal to $\\mathbf{v}_1$. A vector orthogonal to $\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$ is $\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$. Normalizing this vector gives $\\mathbf{v}_{2} = \\frac{1}{\\sqrt{(-2)^{2}+1^{2}}}\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$.\nThe matrix $V$ is formed by these vectors as columns: $V = \\begin{pmatrix} \\mathbf{v}_{1} & \\mathbf{v}_{2} \\end{pmatrix} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & -2 \\\\ 2 & 1 \\end{pmatrix}$.\n\nThe columns of $U$ (the left singular vectors, $\\mathbf{u}_i$) are determined by the relation $P\\mathbf{v}_i = \\sigma_i \\mathbf{u}_i$.\n- For $\\sigma_{1}=1$: $\\mathbf{u}_{1} = \\frac{1}{\\sigma_{1}}P\\mathbf{v}_{1} = \\frac{1}{1}P\\mathbf{v}_{1}$. Since $\\mathbf{v}_1$ is an eigenvector of $P$ with eigenvalue $1$, $P\\mathbf{v}_1 = \\mathbf{v}_1$. So, $\\mathbf{u}_{1} = \\mathbf{v}_{1} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$.\n- For $\\sigma_{2}=0$: the relation is $P\\mathbf{v}_2 = 0\\cdot\\mathbf{u}_2 = \\mathbf{0}$, which is true since $\\mathbf{v}_2$ is in the null space of $P$. $\\mathbf{u}_2$ must be a unit vector orthogonal to $\\mathbf{u}_1$. We can choose $\\mathbf{u}_2 = \\mathbf{v}_2 = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$.\nThe matrix $U$ is formed by these vectors as columns: $U = \\begin{pmatrix} \\mathbf{u}_{1} & \\mathbf{u}_{2} \\end{pmatrix} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & -2 \\\\ 2 & 1 \\end{pmatrix}$.\nNote that since $P$ is symmetric positive semi-definite, it is possible to choose $U=V$.\n\nThe SVD of $P$ is $P = U\\Sigma V^{\\top} = \\left(\\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & -2 \\\\ 2 & 1 \\end{pmatrix}\\right) \\begin{pmatrix} 1 & 0 \\\\ 0 & 0 \\end{pmatrix} \\left(\\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 & 2 \\\\ -2 & 1 \\end{pmatrix}\\right)$.\n\nFinally, we provide the geometric interpretation of how $P$ transforms the unit circle in $\\mathbb{R}^{2}$. The SVD provides a clear picture of this transformation. The action of any matrix $A=U\\Sigma V^{\\top}$ on the unit circle can be seen as a sequence of three operations:\n1. A rotation/reflection by $V^{\\top}$, which aligns the standard basis with the right singular vectors $\\mathbf{v}_i$.\n2. A scaling along these new axes, where the scaling factor along axis $\\mathbf{v}_i$ is the singular value $\\sigma_i$.\n3. A rotation/reflection by $U$, which aligns the scaled axes with the left singular vectors $\\mathbf{u}_i$.\n\nFor the matrix $P$, the unit circle is transformed into an ellipse, whose semi-axes are given by the vectors $\\sigma_{i}\\mathbf{u}_{i}$.\n- The first semi-axis has length $\\sigma_{1}=1$ and direction $\\mathbf{u}_{1} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} 1 \\\\ 2 \\end{pmatrix}$. This vector lies along the line $y=2x$.\n- The second semi-axis has length $\\sigma_{2}=0$ and direction $\\mathbf{u}_{2} = \\frac{1}{\\sqrt{5}}\\begin{pmatrix} -2 \\\\ 1 \\end{pmatrix}$. This vector is orthogonal to the line $y=2x$.\n\nSince one of the semi-axis lengths is $0$, the resulting image is a **degenerate ellipse**. The transformation collapses the entire unit circle onto a one-dimensional object: a line segment. This line segment lies on the line $y=2x$ and is defined by the set of points $\\{c\\mathbf{u}_1 : c \\in [-1, 1]\\}$. The endpoints of the segment are $-\\mathbf{u}_1$ and $\\mathbf{u}_1$, so it stretches from $(-\\frac{1}{\\sqrt{5}}, -\\frac{2}{\\sqrt{5}})$ to $(\\frac{1}{\\sqrt{5}}, \\frac{2}{\\sqrt{5}})$. This outcome is expected, as an orthogonal projection onto a line must map all points in the plane onto that line.\n\nThe ordered pair of singular values is $(\\sigma_{1}, \\sigma_{2})=(1, 0)$.", "answer": "$$\\boxed{\\begin{pmatrix} 1 & 0 \\end{pmatrix}}$$", "id": "3234717"}, {"introduction": "Having explored transformations in the plane, we now generalize these geometric insights to higher dimensions. This practice [@problem_id:3548105] challenges you to think beyond 2D ellipses and consider the image of an $n$-sphere under a general rank-$r$ matrix. You will construct the geometry of the resulting image, a solid $r$-dimensional ball, and locate it within the correct subspace of the target space, solidifying your understanding of the roles played by the left singular vectors and singular values.", "problem": "Let $m$, $n$, and $r$ be integers with $m \\geq r \\geq 1$ and $n \\geq r$. Let $\\alpha > 0$ be given. Consider a real $m \\times n$ matrix $A$ whose Singular Value Decomposition (SVD, Singular Value Decomposition) has exactly $r$ equal positive singular values, all equal to $\\alpha$, and all remaining singular values equal to $0$. Starting only from the definitions of the SVD, orthogonal matrices, and the Euclidean norm, do the following:\n- Construct an explicit nonzero example of such a matrix $A$.\n- Derive, from first principles, the geometry of the image $A(S^{n-1})$ of the unit sphere $S^{n-1} = \\{ x \\in \\mathbb{R}^{n} : \\|x\\|_{2} = 1 \\}$ under $A$, explaining what geometric set $A(S^{n-1})$ is and in which subspace it lies.\n- Compute the $r$-dimensional Hausdorff measure (i.e., the intrinsic $r$-dimensional volume) of $A(S^{n-1})$.\n\nExpress your final answer as a closed-form analytic expression in terms of $\\alpha$, $r$, $\\pi$, and the Gamma function $\\Gamma(\\cdot)$. No rounding is required.", "solution": "The problem statement is evaluated as valid. It is self-contained, mathematically sound, and well-posed, grounded in the established principles of linear algebra.\n\nThe problem asks for three tasks related to a specific class of matrices. I will address each in sequence, starting from first principles as required.\n\nLet $A$ be an $m \\times n$ real matrix. The Singular Value Decomposition (SVD) of $A$ is a factorization $A = U \\Sigma V^T$, where:\n- $U$ is an $m \\times m$ orthogonal matrix, whose columns $\\{u_1, u_2, \\dots, u_m\\}$ form an orthonormal basis for $\\mathbb{R}^m$.\n- $V$ is an $n \\times n$ orthogonal matrix, whose columns $\\{v_1, v_2, \\dots, v_n\\}$ form an orthonormal basis for $\\mathbb{R}^n$.\n- $\\Sigma$ is an $m \\times n$ diagonal matrix with non-negative real entries $\\sigma_i = \\Sigma_{ii}$ called singular values, ordered non-increasingly: $\\sigma_1 \\geq \\sigma_2 \\geq \\dots \\geq 0$.\n\nThe problem specifies that $A$ has exactly $r$ positive singular values, all equal to a constant $\\alpha > 0$. The remaining singular values are zero. Thus, the singular values are $\\sigma_1 = \\sigma_2 = \\dots = \\sigma_r = \\alpha$ and $\\sigma_i = 0$ for $i > r$.\n\n**Part 1: Construction of an example matrix $A$.**\nTo construct the simplest non-zero example of such a matrix $A$, we can choose the orthogonal matrices $U$ and $V$ to be the identity matrices of appropriate size, i.e., $U = I_m$ and $V = I_n$. In this case, $A = I_m \\Sigma (I_n)^T = \\Sigma$.\nThe matrix $\\Sigma$ is an $m \\times n$ matrix whose entries are $\\Sigma_{ij} = 0$ for $i \\neq j$. The diagonal entries are given by the singular values:\n$\\Sigma_{ii} = \\sigma_i = \\alpha$ for $1 \\leq i \\leq r$.\n$\\Sigma_{ii} = \\sigma_i = 0$ for $i > r$.\n\nThus, an explicit non-zero example for $A$ is the $m \\times n$ matrix given by:\n$$\nA = \\begin{pmatrix}\n\\alpha & 0 & \\dots & 0 & & \\dots & & 0 \\\\\n0 & \\alpha & \\dots & 0 & & \\dots & & 0 \\\\\n\\vdots & \\vdots & \\ddots & \\vdots & & & & \\vdots \\\\\n0 & 0 & \\dots & \\alpha & & \\dots & & 0 \\\\\n& & & & 0 & & & \\\\\n\\vdots & \\vdots & & \\vdots & & \\ddots & & \\vdots \\\\\n& & & & & & 0 & \\\\\n0 & 0 & \\dots & 0 & & \\dots & & 0\n\\end{pmatrix}\n$$\nwhere there are $r$ entries equal to $\\alpha$ on the main diagonal, and all other entries are $0$. This is an $m \\times n$ matrix. Since $r \\geq 1$ and $\\alpha > 0$, this matrix is non-zero.\n\n**Part 2: Geometry of the image $A(S^{n-1})$.**\nLet $S^{n-1} = \\{ x \\in \\mathbb{R}^{n} : \\|x\\|_{2} = 1 \\}$ be the unit sphere in $\\mathbb{R}^n$. We want to find the geometric shape of the set $A(S^{n-1}) = \\{ Ax : x \\in S^{n-1} \\}$. Let $y = Ax$.\n\nUsing the SVD, we have $y = U \\Sigma V^T x$.\nAny vector $x \\in S^{n-1}$ can be written in the orthonormal basis $\\{v_1, \\dots, v_n\\}$ as:\n$x = \\sum_{j=1}^{n} c_j v_j$, where $c_j = v_j^T x$ are the coordinates of $x$ in this basis.\nThe condition $\\|x\\|_2=1$ implies $\\|x\\|_2^2 = x^T x = (\\sum_{j} c_j v_j)^T (\\sum_{k} c_k v_k) = \\sum_{j,k} c_j c_k (v_j^T v_k) = \\sum_{j} c_j^2 = 1$. The vector of coefficients $c = (c_1, \\dots, c_n)^T$ is also a unit vector.\n\nNow we compute $y$:\n$y = U \\Sigma V^T x = U \\Sigma V^T (\\sum_{j=1}^{n} c_j v_j) = U \\Sigma (\\sum_{j=1}^{n} c_j V^T v_j)$.\nSince $V^T v_j = e_j$ (the $j$-th standard basis vector in $\\mathbb{R}^n$), this simplifies to:\n$y = U \\Sigma (\\sum_{j=1}^{n} c_j e_j) = U (\\Sigma c)$.\n\nThe product $\\Sigma c$ is an $m$-dimensional vector:\n$$\n\\Sigma c = \\begin{pmatrix} \\sigma_1 c_1 \\\\ \\sigma_2 c_2 \\\\ \\vdots \\\\ \\sigma_n c_n \\\\ 0 \\\\ \\vdots \\end{pmatrix} = \\begin{pmatrix} \\alpha c_1 \\\\ \\vdots \\\\ \\alpha c_r \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix} \\in \\mathbb{R}^m\n$$\nThe last components are zero because $\\sigma_j=0$ for $j>r$.\n\nNext, we multiply by $U$. Writing $U$ in terms of its column vectors $U=[u_1, \\dots, u_m]$:\n$$\ny = U (\\Sigma c) = \\sum_{i=1}^{m} (\\Sigma c)_i u_i = \\sum_{i=1}^{r} (\\alpha c_i) u_i = \\alpha \\sum_{i=1}^{r} c_i u_i\n$$\nThis result shows that any vector $y$ in the image $A(S^{n-1})$ is a linear combination of the first $r$ left singular vectors $\\{u_1, \\dots, u_r\\}$, which are orthonormal. Therefore, the entire image lies within the $r$-dimensional subspace of $\\mathbb{R}^m$ spanned by these vectors, which we denote by $W = \\text{span}\\{u_1, \\dots, u_r\\}$.\n\nTo understand the shape of the image within $W$, let's analyze the vector of coefficients $(c_1, \\dots, c_r)$. These are the first $r$ coordinates of a unit vector $c \\in S^{n-1} \\subset \\mathbb{R}^n$. The constraint is $\\sum_{j=1}^{n} c_j^2 = 1$. This implies $\\sum_{j=1}^{r} c_j^2 \\leq 1$.\nLet $c' = (c_1, \\dots, c_r)^T \\in \\mathbb{R}^r$. The set of all possible vectors $c'$ is $\\{ (c_1, \\dots, c_r) : \\exists c_{r+1}, \\dots, c_n \\text{ s.t. } \\sum_{j=1}^n c_j^2 = 1 \\}$.\n\nTwo cases arise based on the values of $n$ and $r$:\n1.  If $n = r$, the constraint becomes $\\sum_{j=1}^{r} c_j^2 = 1$. The set of vectors $c'$ is the unit $(r-1)$-sphere $S^{r-1}$ in $\\mathbb{R}^r$. The image set within $W$ is $\\{ \\alpha c' : c' \\in S^{r-1} \\}$, which is an $(r-1)$-dimensional sphere of radius $\\alpha$.\n2.  If $n > r$, for any set of coefficients $c_1, \\dots, c_r$ such that $\\sum_{j=1}^{r} c_j^2 \\leq 1$, we can always find $c_{r+1}, \\dots, c_n$ to satisfy the unit norm constraint. For instance, set $c_{r+1} = \\sqrt{1 - \\sum_{j=1}^{r} c_j^2}$ and $c_j=0$ for $j > r+1$. This is possible as $n \\geq r+1$. Therefore, the vector $c'$ can be any vector in the closed unit $r$-ball $B^r = \\{z \\in \\mathbb{R}^r : \\|z\\|_2 \\le 1\\}$. The image set within $W$ is $\\{\\alpha c' : c' \\in B^r \\}$, which is the solid, closed $r$-dimensional ball of radius $\\alpha$.\n\nIn summary, the geometry of the image $A(S^{n-1})$ is a solid $r$-dimensional ball of radius $\\alpha$, centered at the origin, lying in the $r$-dimensional subspace spanned by the first $r$ left singular vectors of $A$. In the specific case where $n=r$, the image is the boundary of this ball, i.e., an $(r-1)$-dimensional sphere of radius $\\alpha$.\n\n**Part 3: Computation of the $r$-dimensional Hausdorff measure.**\nThe $r$-dimensional Hausdorff measure, $H^r$, of a set generalizes the notion of $r$-dimensional volume. We are asked to compute $H^r(A(S^{n-1}))$.\nAs determined above, the image set $A(S^{n-1})$ is an object living in the $r$-dimensional space $W$.\n\nIf $n=r$, the image is an $(r-1)$-dimensional sphere. This is an $(r-1)$-dimensional manifold, which has zero $r$-dimensional volume. Thus, $H^r(A(S^{n-1})) = 0$ in this case.\n\nIf $n>r$, the image is a solid $r$-dimensional ball of radius $\\alpha$. Its $r$-dimensional Hausdorff measure is its volume. The volume of an $r$-dimensional ball of radius $R$ is given by the formula:\n$$ V_r(R) = \\frac{\\pi^{r/2}}{\\Gamma(\\frac{r}{2}+1)} R^r $$\nwhere $\\Gamma(\\cdot)$ is the Gamma function.\n\nThe problem asks for a single closed-form analytic expression for the measure. This suggests we should provide the result for the non-degenerate case ($n > r$) where the image has a non-zero $r$-volume.\nSubstituting the radius $R=\\alpha$ into the formula, we find the $r$-dimensional measure of the image:\n$$ H^r(A(S^{n-1})) = \\frac{\\pi^{r/2}}{\\Gamma(\\frac{r}{2}+1)} \\alpha^r $$\nThis expression gives the volume of the solid $r$-ball of radius $\\alpha$.", "answer": "$$ \\boxed{\\frac{\\pi^{r/2} \\alpha^r}{\\Gamma(\\frac{r}{2} + 1)}} $$", "id": "3548105"}]}