{"hands_on_practices": [{"introduction": "The first step in analyzing large-scale structure is to identify gravitationally bound objects, or \"halos,\" from the sea of simulation particles. The Friends-of-Friends (FOF) algorithm is a widely-used percolation method for this task, but it can mistakenly link physically distinct halos that are merely close in space. This hands-on exercise [@problem_id:3480804] challenges you to implement and compare the standard spatial FOF with a more sophisticated phase-space FOF, which uses both position and velocity information to better resolve these complex fly-by encounters and improve the purity of the resulting halo catalog.", "problem": "You are given a toy setup to perform on-the-fly halo finding and analysis, intended to demonstrate how augmenting configuration-space Friends-of-Friends (FOF) with phase-space information improves the separation of close flybys. The setup models a cosmological particle distribution in a periodic cubic box and requires building FOF groups incrementally as particles are streamed into memory. The goal is to compute groups under two different linking criteria and evaluate their quantitative purity with respect to known generative labels, showing the superiority of phase-space FOF for close flybys.\n\nFundamental base and definitions:\n- A periodic cubic box of side length $L_{\\mathrm{box}}$ with positions in comoving units of $h^{-1}\\,\\mathrm{Mpc}$ and velocities in $\\mathrm{km}\\,\\mathrm{s}^{-1}$ is assumed. Periodic boundary conditions must be enforced using the minimal image convention.\n- A Friends-of-Friends (FOF) group is the set of particles that are mutually connected under a binary neighbor relation. The neighbor relation must be defined so that if any two particles are linked, they belong to the same connected component of the undirected graph defined by pairwise links.\n- On-the-fly processing means particles are ingested sequentially, and group unions are performed as edges become known, without requiring the full pairwise graph to be stored at once. The final grouping must be identical to that obtained by constructing the full graph, which is a property of union-find (disjoint-set) connectivity under edge insertions.\n\nYou must implement two FOF variants:\n1. Configuration-space FOF: Two particles $i$ and $j$ are considered linked if their Euclidean separation in configuration space, computed with periodic boundary conditions, is below a specified spatial linking length $l_{\\mathrm{pos}}$ in $h^{-1}\\,\\mathrm{Mpc}$. The minimal image convention must be used to compute the separation within the periodic box of side $L_{\\mathrm{box}}$.\n2. Phase-space FOF: Two particles $i$ and $j$ are considered linked by a combined distance that accounts for both configuration-space separation and velocity-space separation and uses characteristic scales $l_{\\mathrm{pos}}$ (in $h^{-1}\\,\\mathrm{Mpc}$) and $l_{\\mathrm{vel}}$ (in $\\mathrm{km}\\,\\mathrm{s}^{-1}$). The combined metric must be a proper dimensionless quantity that reduces to configuration-space FOF when velocity differences are negligible compared to $l_{\\mathrm{vel}}$ and should be robust to units. Use the same periodic boundary convention for positions. Particles are linked if the combined phase-space distance falls below a threshold of unity.\n\nDataset generation:\n- For each test case, you must generate particles from $K$ distinct halos. Halo $k$ has a center position $\\boldsymbol{x}_k$ in $h^{-1}\\,\\mathrm{Mpc}$, a center velocity $\\boldsymbol{v}_k$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$, a position dispersion $\\sigma_{\\mathrm{pos}}$ in $h^{-1}\\,\\mathrm{Mpc}$, a velocity dispersion $\\sigma_{\\mathrm{vel}}$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$, and a particle count $N_k$. Particle positions must be drawn independently from a three-dimensional normal distribution centered at $\\boldsymbol{x}_k$ with isotropic standard deviation $\\sigma_{\\mathrm{pos}}$ and then wrapped into the periodic box of side $L_{\\mathrm{box}}$. Velocities must be drawn from a three-dimensional normal distribution centered at $\\boldsymbol{v}_k$ with isotropic standard deviation $\\sigma_{\\mathrm{vel}}$. Assign each particle a ground-truth label $k\\in\\{0,1,\\dots,K-1\\}$ based on its parent halo.\n\nPurity metric:\n- Compute the micro-averaged purity of the grouping with respect to the ground-truth labels. If the set of recovered groups is $\\{G_m\\}$, with $|G_m|$ the size of group $m$ and $n_{m,i}$ the number of particles in $G_m$ whose ground-truth label is $i$, define the micro-averaged purity as\n$$\nP_{\\mathrm{micro}} \\equiv \\frac{1}{N} \\sum_{m} \\max_{i} n_{m,i},\n$$\nwhere $N$ is the total number of particles across all groups. This quantity is dimensionless. Report $P_{\\mathrm{micro}}$ for both configuration-space FOF and phase-space FOF for each test case, and also report the improvement $\\Delta P \\equiv P_{\\mathrm{micro}}^{\\mathrm{phase}} - P_{\\mathrm{micro}}^{\\mathrm{config}}$.\n\nPeriodic boundary conditions:\n- For positions, use the minimal image convention. For any coordinate difference $\\Delta x$ along one axis, compute the periodic difference as the unique value in $(-L_{\\mathrm{box}}/2, L_{\\mathrm{box}}/2]$ congruent to $\\Delta x$ modulo $L_{\\mathrm{box}}$.\n\nStreaming constraint:\n- Implement the grouping on-the-fly: process particles in sequence and add links to previously ingested particles if they satisfy the linking criterion. Maintain a disjoint-set union (union-find) structure with path compression and union by size or rank to merge components as edges are discovered. Do not construct the full pairwise graph at once.\n\nUnits:\n- Positions must be handled in $h^{-1}\\,\\mathrm{Mpc}$, velocities in $\\mathrm{km}\\,\\mathrm{s}^{-1}$. Any reported metric must be dimensionless. No angle units are involved.\n\nTest suite and parameters:\n- Use a fixed random seed for reproducibility.\n- The box size is $L_{\\mathrm{box}} = 1.0$ in $h^{-1}\\,\\mathrm{Mpc}$ for all test cases.\n- Test Case 1 (happy path, well-separated halos): $K=3$, centers $\\boldsymbol{x}_k = (0.1,0.1,0.1),(0.7,0.5,0.4),(0.3,0.8,0.2)$, center velocities $\\boldsymbol{v}_k = (0,0,0),(300,0,0),(-250,0,0)$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$, particle counts $N_k = 60,60,60$, dispersions $\\sigma_{\\mathrm{pos}}=0.015$ in $h^{-1}\\,\\mathrm{Mpc}$ and $\\sigma_{\\mathrm{vel}}=30$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$, linking scales $l_{\\mathrm{pos}}=0.05$ in $h^{-1}\\,\\mathrm{Mpc}$ and $l_{\\mathrm{vel}}=150$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$.\n- Test Case 2 (close flyby, overlap in configuration space but distinct in velocity): $K=3$, centers $\\boldsymbol{x}_k = (0.5,0.5,0.5),(0.535,0.5,0.5),(0.8,0.2,0.2)$, center velocities $\\boldsymbol{v}_k = (300,0,0),(-300,0,0),(50,0,0)$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$, particle counts $N_k = 80,80,60$, dispersions $\\sigma_{\\mathrm{pos}}=0.012$ in $h^{-1}\\,\\mathrm{Mpc}$ and $\\sigma_{\\mathrm{vel}}=25$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$, linking scales $l_{\\mathrm{pos}}=0.05$ in $h^{-1}\\,\\mathrm{Mpc}$ and $l_{\\mathrm{vel}}=150$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$.\n- Test Case 3 (boundary case near spatial threshold with moderate velocity offset): $K=3$, centers $\\boldsymbol{x}_k = (0.4,0.4,0.4),(0.45,0.4,0.4),(0.2,0.7,0.5)$, center velocities $\\boldsymbol{v}_k = (200,0,0),(20,0,0),(80,0,0)$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$, particle counts $N_k = 70,70,60$, dispersions $\\sigma_{\\mathrm{pos}}=0.015$ in $h^{-1}\\,\\mathrm{Mpc}$ and $\\sigma_{\\mathrm{vel}}=35$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$, linking scales $l_{\\mathrm{pos}}=0.05$ in $h^{-1}\\,\\mathrm{Mpc}$ and $l_{\\mathrm{vel}}=150$ in $\\mathrm{km}\\,\\mathrm{s}^{-1}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a list of three floats $[P_{\\mathrm{micro}}^{\\mathrm{config}}, P_{\\mathrm{micro}}^{\\mathrm{phase}}, \\Delta P]$ rounded to three decimal places. For example, the printed output must look like $[[0.995,0.998,0.003],[\\dots],[\\dots]]$ exactly on a single line with no additional text.", "solution": "The problem is valid as it is scientifically grounded in the principles of computational cosmology, specifically halo finding algorithms. It is well-posed, with all necessary parameters, definitions, and constraints provided to derive a unique, verifiable solution. The problem statement is objective and uses standard, formalizable terminology from the field.\n\nThe objective is to implement and compare two variants of the Friends-of-Friends (FOF) halo finding algorithm: a standard configuration-space version and an enhanced phase-space version. The comparison will be quantified using a micro-averaged purity metric, demonstrating the superiority of the phase-space approach in resolving fly-by encounters, where halos are spatially close but kinematically distinct. The implementation must adhere to an on-the-fly processing model using a union-find data structure.\n\nFirst, we define the methodology for generating the particle data. For each of the $K$ true halos in a given test case, we generate $N_k$ particles. The position $\\boldsymbol{x}$ of each particle belonging to halo $k$ is drawn from a $3$-dimensional isotropic normal distribution with mean $\\boldsymbol{x}_k$ (the halo center) and standard deviation $\\sigma_{\\mathrm{pos}}$. These generated positions are then mapped into the periodic cubic box of side length $L_{\\mathrm{box}}$ using the modulo operator, ensuring coordinates lie in the range $[0, L_{\\mathrm{box}})$. The velocity $\\boldsymbol{v}$ of each particle is similarly drawn from a $3$-dimensional isotropic normal distribution with mean $\\boldsymbol{v}_k$ and standard deviation $\\sigma_{\\mathrm{vel}}$. Each particle is assigned a ground-truth integer label $k \\in \\{0, 1, ..., K-1\\}$.\n\nThe core of the FOF algorithm is the pairwise linking condition. We must compute the separation between any two particles $i$ and $j$. For positions $\\boldsymbol{x}_i$ and $\\boldsymbol{x}_j$, the vector difference $\\Delta\\boldsymbol{x} = \\boldsymbol{x}_i - \\boldsymbol{x}_j$ must account for the periodic boundary conditions. We use the minimal image convention. For each component $\\Delta x_c$ of $\\Delta\\boldsymbol{x}$, the periodic difference is the unique value in the interval $(-L_{\\mathrm{box}}/2, L_{\\mathrm{box}}/2]$. This can be computed as $\\Delta x_{p,c} = \\Delta x_c - L_{\\mathrm{box}} \\cdot \\mathrm{round}(\\Delta x_c / L_{\\mathrm{box}})$, with a special check to map any result equal to $-L_{\\mathrm{box}}/2$ to $+L_{\\mathrm{box}}/2$ to adhere strictly to the interval. The squared Euclidean distance in configuration space is then $d_{\\mathrm{pos}}^2 = \\|\\Delta\\boldsymbol{x}_p\\|^2$. The velocity separation is the standard squared Euclidean distance in velocity space, $d_{\\mathrm{vel}}^2 = \\|\\boldsymbol{v}_i - \\boldsymbol{v}_j\\|^2$.\n\nWe implement two linking criteria:\n1.  **Configuration-space FOF**: Two particles are linked if their physical separation is less than the linking length $l_{\\mathrm{pos}}$. To avoid computationally expensive square roots, we use squared distances: $d_{\\mathrm{pos}}^2  l_{\\mathrm{pos}}^2$.\n2.  **Phase-space FOF**: The problem specifies a dimensionless, combined metric. A standard choice that satisfies all given constraints is the sum of squared, normalized separations. Two particles are linked if the condition\n    $$\n    \\left(\\frac{d_{\\mathrm{pos}}}{l_{\\mathrm{pos}}}\\right)^2 + \\left(\\frac{d_{\\mathrm{vel}}}{l_{\\mathrm{vel}}}\\right)^2  1\n    $$\n    is met. This is equivalent to $d_{\\mathrm{pos}}^2 / l_{\\mathrm{pos}}^2 + d_{\\mathrm{vel}}^2 / l_{\\mathrm{vel}}^2  1$. This metric correctly reduces to the configuration-space criterion when the velocity difference $d_{\\mathrm{vel}}$ is negligible compared to the velocity scale $l_{\\mathrm{vel}}$.\n\nTo satisfy the on-the-fly processing constraint, we employ a disjoint-set union (DSU) or union-find data structure, optimized with path compression and union by size. The algorithm proceeds as follows:\n1.  Initialize the DSU structure, with each of the $N$ total particles in its own set.\n2.  Iterate through each particle $i$ from $0$ to $N-1$.\n3.  For each $i$, iterate through all previously considered particles $j$ from $0$ to $i-1$.\n4.  For each pair $(i, j)$, check if they are linked according to the chosen FOF criterion.\n5.  If they are linked, perform a `union` operation on the sets containing $i$ and $j$.\nThis process does not require storing the full pairwise graph, respecting the memory efficiency aspect of on-the-fly algorithms. A separate run is performed for each of the two FOF criteria.\n\nFinally, we calculate the micro-averaged purity, $P_{\\mathrm{micro}}$, for each grouping result. After the DSU structure for a given FOF run is finalized, we identify the distinct groups by finding the root representative for each particle. For each resulting group $G_m$, we count the number of member particles from each ground-truth halo origin, giving the counts $n_{m,i}$. The purity is then calculated using the formula:\n$$\nP_{\\mathrm{micro}} = \\frac{1}{N} \\sum_{m} \\max_{i} n_{m,i}\n$$\nwhere the sum is over all recovered groups $\\{G_m\\}$, and $N$ is the total number of particles. We compute this purity for both configuration-space ($P_{\\mathrm{micro}}^{\\mathrm{config}}$) and phase-space ($P_{\\mathrm{micro}}^{\\mathrm{phase}}$) FOF, and report the improvement $\\Delta P = P_{\\mathrm{micro}}^{\\mathrm{phase}} - P_{\\mathrm{micro}}^{\\mathrm{config}}$. The calculations are performed for each test case provided, using a fixed random seed for reproducibility.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the FOF analysis for all test cases and print the results.\n    \"\"\"\n\n    class UnionFind:\n        \"\"\"\n        A disjoint-set union (DSU) data structure with path compression and union by size.\n        \"\"\"\n        def __init__(self, n):\n            self.parent = np.arange(n)\n            self.size = np.ones(n, dtype=int)\n\n        def find(self, i):\n            if self.parent[i] == i:\n                return i\n            self.parent[i] = self.find(self.parent[i])\n            return self.parent[i]\n\n        def union(self, i, j):\n            root_i = self.find(i)\n            root_j = self.find(j)\n            if root_i != root_j:\n                if self.size[root_i]  self.size[root_j]:\n                    root_i, root_j = root_j, root_i\n                self.parent[root_j] = root_i\n                self.size[root_i] += self.size[root_j]\n\n    def generate_particles(params, rng):\n        \"\"\"\n        Generates particle data based on halo parameters for a single test case.\n        \"\"\"\n        L_box = params['L_box']\n        all_pos, all_vel, all_labels = [], [], []\n        \n        particle_idx = 0\n        for k in range(params['K']):\n            N_k = params['N_k'][k]\n            pos = rng.normal(loc=params['x_k'][k], scale=params['sigma_pos'], size=(N_k, 3))\n            vel = rng.normal(loc=params['v_k'][k], scale=params['sigma_vel'], size=(N_k, 3))\n            \n            # Wrap positions into the periodic box [0, L_box)\n            pos %= L_box\n            \n            all_pos.append(pos)\n            all_vel.append(vel)\n            all_labels.append(np.full(N_k, k, dtype=int))\n            particle_idx += N_k\n\n        return np.vstack(all_pos), np.vstack(all_vel), np.concatenate(all_labels)\n\n    def run_fof(positions, velocities, L_box, l_pos, l_vel=None):\n        \"\"\"\n        Performs on-the-fly FOF grouping using a Union-Find structure.\n        \"\"\"\n        n_particles = positions.shape[0]\n        uf = UnionFind(n_particles)\n        l_pos_sq = l_pos**2\n        \n        is_phase_space = l_vel is not None\n        if is_phase_space:\n            l_vel_sq = l_vel**2\n\n        for i in range(n_particles):\n            for j in range(i):\n                # Configuration-space distance\n                delta_pos = positions[i] - positions[j]\n                # Minimal image convention for (-L_box/2, L_box/2]\n                wrapped_delta = delta_pos - L_box * np.round(delta_pos / L_box)\n                # Ensure the interval is (-L/2, L/2] by adjusting the lower bound\n                wrapped_delta[wrapped_delta == -L_box / 2] = L_box / 2\n                d_pos_sq = np.sum(wrapped_delta**2)\n\n                if is_phase_space:\n                    # Phase-space FOF\n                    delta_vel = velocities[i] - velocities[j]\n                    d_vel_sq = np.sum(delta_vel**2)\n                    \n                    if (d_pos_sq / l_pos_sq) + (d_vel_sq / l_vel_sq)  1.0:\n                        uf.union(i, j)\n                else:\n                    # Configuration-space FOF\n                    if d_pos_sq  l_pos_sq:\n                        uf.union(i, j)\n        return uf\n        \n    def calculate_purity(uf, labels, K):\n        \"\"\"\n        Calculates the micro-averaged purity of the found groups.\n        \"\"\"\n        n_particles = len(labels)\n        if n_particles == 0:\n            return 1.0\n\n        groups = {}\n        for i in range(n_particles):\n            root = uf.find(i)\n            if root not in groups:\n                groups[root] = []\n            groups[root].append(i)\n        \n        sum_max_n = 0\n        for root in groups:\n            group_indices = groups[root]\n            group_labels = labels[group_indices]\n            \n            if len(group_labels) > 0:\n                # Count occurrences of each ground-truth label in this group\n                counts = np.bincount(group_labels, minlength=K)\n                sum_max_n += np.max(counts)\n                \n        return sum_max_n / n_particles\n\n    def process_case(params, rng):\n        \"\"\"\n        Processes a single test case: generates particles, runs both FOFs, computes purities.\n        \"\"\"\n        positions, velocities, labels = generate_particles(params, rng)\n        \n        # Configuration-space FOF\n        uf_config = run_fof(positions, velocities, params['L_box'], params['l_pos'])\n        p_config = calculate_purity(uf_config, labels, params['K'])\n        \n        # Phase-space FOF\n        uf_phase = run_fof(positions, velocities, params['L_box'], params['l_pos'], l_vel=params['l_vel'])\n        p_phase = calculate_purity(uf_phase, labels, params['K'])\n        \n        delta_p = p_phase - p_config\n        \n        return [p_config, p_phase, delta_p]\n\n    test_cases = [\n        # Test Case 1 (happy path, well-separated halos)\n        {\n            'L_box': 1.0, 'K': 3,\n            'x_k': np.array([[0.1, 0.1, 0.1], [0.7, 0.5, 0.4], [0.3, 0.8, 0.2]]),\n            'v_k': np.array([[0, 0, 0], [300, 0, 0], [-250, 0, 0]]),\n            'N_k': [60, 60, 60],\n            'sigma_pos': 0.015, 'sigma_vel': 30.0,\n            'l_pos': 0.05, 'l_vel': 150.0\n        },\n        # Test Case 2 (close flyby, overlap in config-space)\n        {\n            'L_box': 1.0, 'K': 3,\n            'x_k': np.array([[0.5, 0.5, 0.5], [0.535, 0.5, 0.5], [0.8, 0.2, 0.2]]),\n            'v_k': np.array([[300, 0, 0], [-300, 0, 0], [50, 0, 0]]),\n            'N_k': [80, 80, 60],\n            'sigma_pos': 0.012, 'sigma_vel': 25.0,\n            'l_pos': 0.05, 'l_vel': 150.0\n        },\n        # Test Case 3 (boundary case near spatial threshold)\n        {\n            'L_box': 1.0, 'K': 3,\n            'x_k': np.array([[0.4, 0.4, 0.4], [0.45, 0.4, 0.4], [0.2, 0.7, 0.5]]),\n            'v_k': np.array([[200, 0, 0], [20, 0, 0], [80, 0, 0]]),\n            'N_k': [70, 70, 60],\n            'sigma_pos': 0.015, 'sigma_vel': 35.0,\n            'l_pos': 0.05, 'l_vel': 150.0\n        }\n    ]\n\n    # Fixed random seed for reproducibility\n    seed = 42\n    rng = np.random.default_rng(seed)\n\n    all_results = []\n    for case_params in test_cases:\n        result = process_case(case_params, rng)\n        all_results.append(result)\n    \n    # Format the output string exactly as specified\n    inner_strings = [f\"[{res[0]:.3f},{res[1]:.3f},{res[2]:.3f}]\" for res in all_results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3480804"}, {"introduction": "Halo finders like Friends-of-Friends often produce candidate groups that include particles not gravitationally bound to the main structure. To obtain physically meaningful halo properties, it is crucial to perform an \"unbinding\" procedure to remove these contaminants. In this practice [@problem_id:3480808], you will implement a standard iterative algorithm to calculate the specific binding energy of each particle—accounting for both the halo's self-gravity and the external tidal field of its environment—and progressively refine the halo to its true, self-bound core.", "problem": "You are given a small collection of particles representing a candidate dark matter halo embedded within a larger host environment. Using Newtonian gravity and a local tidal approximation of the host field, you must implement an on-the-fly unbinding procedure: compute the specific binding energy of each particle, iteratively remove unbound particles, and return the final bound set. All quantities must be treated in physically consistent units, and the numerical algorithm must be derived from first principles.\n\nFundamental base to use:\n- Newtonian gravitational dynamics in an expanding universe is well approximated by non-relativistic dynamics on halo scales. The gravitational potential of a system of point masses is defined by $ \\Phi(\\boldsymbol{r}) = - G \\sum_{j} \\dfrac{m_j}{\\left\\lVert \\boldsymbol{r} - \\boldsymbol{r}_j \\right\\rVert} $, where $ G $ is the gravitational constant and $ \\boldsymbol{r}_j $ are source positions. To prevent divergence in the discrete representation, adopt Plummer-equivalent softening by replacing $ \\left\\lVert \\boldsymbol{r} - \\boldsymbol{r}_j \\right\\rVert $ with $ \\sqrt{\\left\\lVert \\boldsymbol{r} - \\boldsymbol{r}_j \\right\\rVert^2 + \\epsilon^2} $ for a small softening length $ \\epsilon $.\n- For the host environment, approximate the potential near the halo center by a quadratic expansion using the tidal tensor $ \\mathbf{T} = \\nabla \\nabla \\Phi_{\\text{host}}(\\boldsymbol{r}) \\big\\vert_{\\boldsymbol{r} = \\boldsymbol{r}_{\\text{com}}} $. For a point-mass host at position $ \\boldsymbol{R}_{\\text{host}} $, relative to the halo center-of-mass position $ \\boldsymbol{r}_{\\text{com}} $, the tidal tensor is $ \\mathbf{T} = \\dfrac{G M_{\\text{host}}}{R^3} \\left( 3 \\hat{\\boldsymbol{n}} \\hat{\\boldsymbol{n}}^\\top - \\mathbf{I} \\right) $, where $ R = \\left\\lVert \\boldsymbol{R}_{\\text{host}} - \\boldsymbol{r}_{\\text{com}} \\right\\rVert $, $ \\hat{\\boldsymbol{n}} = \\dfrac{\\boldsymbol{R}_{\\text{host}} - \\boldsymbol{r}_{\\text{com}}}{R} $, and $ \\mathbf{I} $ is the identity matrix. The corresponding local tidal potential is $ \\Phi_{\\text{tid}}(\\boldsymbol{x}) \\approx \\dfrac{1}{2} \\boldsymbol{x}^\\top \\mathbf{T} \\boldsymbol{x} $, for displacements $ \\boldsymbol{x} = \\boldsymbol{r} - \\boldsymbol{r}_{\\text{com}} $.\n- Specific kinetic energy relative to the halo bulk motion is $ k(\\boldsymbol{v}) = \\dfrac{1}{2} \\left\\lVert \\boldsymbol{v} - \\boldsymbol{v}_{\\text{com}} \\right\\rVert^2 $, where $ \\boldsymbol{v}_{\\text{com}} $ is the mass-weighted center-of-mass velocity of the current bound set.\n\nDefinitions and criterion:\n- The specific total energy per particle is $ e_i = \\dfrac{1}{2} \\left\\lVert \\boldsymbol{v}_i - \\boldsymbol{v}_{\\text{com}} \\right\\rVert^2 + \\Phi_{\\text{self}}(\\boldsymbol{r}_i) + \\Phi_{\\text{tid}}(\\boldsymbol{r}_i - \\boldsymbol{r}_{\\text{com}}) $, where $ \\Phi_{\\text{self}}(\\boldsymbol{r}_i) = - G \\sum_{j \\neq i} \\dfrac{m_j}{\\sqrt{\\left\\lVert \\boldsymbol{r}_i - \\boldsymbol{r}_j \\right\\rVert^2 + \\epsilon^2}} $. A particle is bound if and only if $ e_i  0 $.\n- The on-the-fly unbinding step repeatedly computes $ e_i $ for all particles in the current bound set, removes all with $ e_i \\ge 0 $, and updates $ \\boldsymbol{r}_{\\text{com}} $, $ \\boldsymbol{v}_{\\text{com}} $, and $ \\mathbf{T} $ until no further removals occur or the bound set is empty.\n\nUnits:\n- Use $ \\boldsymbol{r} $ in $ \\mathrm{kpc} $, $ \\boldsymbol{v} $ in $ \\mathrm{km}/\\mathrm{s} $, $ m $ in $ M_{\\odot} $, and $ G = 4.30091 \\times 10^{-6} \\, \\mathrm{kpc} \\, (\\mathrm{km}/\\mathrm{s})^2 \\, M_{\\odot}^{-1} $. Energies $ e_i $ must be in $ (\\mathrm{km}/\\mathrm{s})^2 $ and treated as specific energies (per unit mass). Angles, if any, must be interpreted implicitly via vector normalization and do not require an explicit unit; all directions are dimensionless unit vectors.\n\nAlgorithmic requirements:\n- Compute the mass-weighted center-of-mass position $ \\boldsymbol{r}_{\\text{com}} = \\dfrac{\\sum_i m_i \\boldsymbol{r}_i}{\\sum_i m_i} $ and center-of-mass velocity $ \\boldsymbol{v}_{\\text{com}} = \\dfrac{\\sum_i m_i \\boldsymbol{v}_i}{\\sum_i m_i} $ using only the currently bound particles.\n- For a given current bound set, compute the self-gravitational potential $ \\Phi_{\\text{self}}(\\boldsymbol{r}_i) $ with softening $ \\epsilon $.\n- Compute the host tidal tensor $ \\mathbf{T} $ from the host mass and the vector from the current $ \\boldsymbol{r}_{\\text{com}} $ to the host position $ \\boldsymbol{R}_{\\text{host}} $.\n- Compute $ e_i $ for each particle in the current set and remove those with $ e_i \\ge 0 $. Iterate until convergence or a maximum number of iterations is reached.\n\nTest suite:\nProvide three test cases to exercise different regimes. In each case, specify arrays of positions, velocities, and masses for all particles, the softening $ \\epsilon $, the host mass $ M_{\\text{host}} $, and the host position vector $ \\boldsymbol{R}_{\\text{host}} $.\n\n- Test case $1$ (compact, weak tide, expected to remain largely bound):\n  - $ N = 5 $\n  - Positions in $ \\mathrm{kpc} $:\n    - $ \\boldsymbol{r}_0 = (0.0, 0.0, 0.0) $\n    - $ \\boldsymbol{r}_1 = (0.3, 0.1, 0.0) $\n    - $ \\boldsymbol{r}_2 = (-0.2, -0.1, 0.1) $\n    - $ \\boldsymbol{r}_3 = (0.1, -0.3, 0.2) $\n    - $ \\boldsymbol{r}_4 = (-0.1, 0.2, -0.2) $\n  - Velocities in $ \\mathrm{km}/\\mathrm{s} $:\n    - $ \\boldsymbol{v}_0 = (0.0, 0.0, 0.0) $\n    - $ \\boldsymbol{v}_1 = (8.0, 0.0, 0.0) $\n    - $ \\boldsymbol{v}_2 = (-5.0, 2.0, 1.0) $\n    - $ \\boldsymbol{v}_3 = (3.0, -4.0, 2.0) $\n    - $ \\boldsymbol{v}_4 = (-2.0, 1.0, -3.0) $\n  - Masses in $ M_{\\odot} $: all equal to $ 1.0 \\times 10^8 $\n  - Softening $ \\epsilon = 0.1 \\, \\mathrm{kpc} $\n  - Host mass $ M_{\\text{host}} = 1.0 \\times 10^{12} \\, M_{\\odot} $\n  - Host position $ \\boldsymbol{R}_{\\text{host}} = (300.0, 0.0, 0.0) \\, \\mathrm{kpc} $\n  - Maximum iterations $ 10 $\n\n- Test case $2$ (moderate tide, some outer particles unbind):\n  - $ N = 6 $\n  - Positions in $ \\mathrm{kpc} $:\n    - $ \\boldsymbol{r}_0 = (0.0, 0.0, 0.0) $\n    - $ \\boldsymbol{r}_1 = (0.3, 0.1, 0.0) $\n    - $ \\boldsymbol{r}_2 = (-0.2, -0.1, 0.1) $\n    - $ \\boldsymbol{r}_3 = (0.1, -0.3, 0.2) $\n    - $ \\boldsymbol{r}_4 = (-0.1, 0.2, -0.2) $\n    - $ \\boldsymbol{r}_5 = (2.0, 0.0, 0.0) $\n  - Velocities in $ \\mathrm{km}/\\mathrm{s} $:\n    - $ \\boldsymbol{v}_0 = (0.0, 0.0, 0.0) $\n    - $ \\boldsymbol{v}_1 = (6.0, 0.0, 0.0) $\n    - $ \\boldsymbol{v}_2 = (-4.0, 1.5, 0.5) $\n    - $ \\boldsymbol{v}_3 = (2.5, -3.0, 1.5) $\n    - $ \\boldsymbol{v}_4 = (-1.5, 0.5, -2.5) $\n    - $ \\boldsymbol{v}_5 = (50.0, 0.0, 0.0) $\n  - Masses in $ M_{\\odot} $: all equal to $ 2.0 \\times 10^8 $\n  - Softening $ \\epsilon = 0.05 \\, \\mathrm{kpc} $\n  - Host mass $ M_{\\text{host}} = 1.0 \\times 10^{12} \\, M_{\\odot} $\n  - Host position $ \\boldsymbol{R}_{\\text{host}} = (50.0, 0.0, 0.0) \\, \\mathrm{kpc} $\n  - Maximum iterations $ 10 $\n\n- Test case $3$ (mixed masses, borderline binding):\n  - $ N = 4 $\n  - Positions in $ \\mathrm{kpc} $:\n    - $ \\boldsymbol{r}_0 = (0.0, 0.0, 0.0) $\n    - $ \\boldsymbol{r}_1 = (0.5, 0.0, 0.0) $\n    - $ \\boldsymbol{r}_2 = (0.0, 0.5, 0.0) $\n    - $ \\boldsymbol{r}_3 = (0.0, 0.0, 0.5) $\n  - Velocities in $ \\mathrm{km}/\\mathrm{s} $:\n    - $ \\boldsymbol{v}_0 = (0.0, 0.0, 0.0) $\n    - $ \\boldsymbol{v}_1 = (12.0, 0.0, 0.0) $\n    - $ \\boldsymbol{v}_2 = (0.0, 12.0, 0.0) $\n    - $ \\boldsymbol{v}_3 = (0.0, 0.0, 12.0) $\n  - Masses in $ M_{\\odot} $:\n    - $ m_0 = 3.0 \\times 10^8 $\n    - $ m_1 = 1.0 \\times 10^8 $\n    - $ m_2 = 2.0 \\times 10^8 $\n    - $ m_3 = 1.5 \\times 10^8 $\n  - Softening $ \\epsilon = 0.1 \\, \\mathrm{kpc} $\n  - Host mass $ M_{\\text{host}} = 5.0 \\times 10^{11} \\, M_{\\odot} $\n  - Host position $ \\boldsymbol{R}_{\\text{host}} = (1000.0, 1000.0, 0.0) \\, \\mathrm{kpc} $\n  - Maximum iterations $ 10 $\n\nRequired final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each result must be a list of the zero-based indices of particles that remain bound after the on-the-fly unbinding procedure for that test case, sorted in ascending order. For example, the printed output should look like $ [ [0,1,2], [0,1], [0] ] $, adapted to the actual results of the specified test suite.", "solution": "The problem requires the implementation of an iterative unbinding algorithm for a set of particles representing a dark matter subhalo. The subhalo is subject to its own self-gravity and the tidal forces of a larger host environment. This procedure is a standard technique in computational cosmology for identifying the gravitationally bound components of structures that form in N-body simulations.\n\nThe solution is predicated on the principle of conservation of energy in a local, non-inertial reference frame co-moving with the subhalo. A particle is considered bound to the system if its total specific energy, relative to the system's center of mass, is negative. The total specific energy $e_i$ of a particle $i$ is the sum of its specific kinetic energy $k_i$, its self-gravitational potential energy $\\Phi_{\\text{self}}(\\boldsymbol{r}_i)$, and its tidal potential energy $\\Phi_{\\text{tid}}(\\boldsymbol{x}_i)$.\n\nThe algorithm proceeds iteratively as follows:\n\n1.  **Initialization**: The procedure begins by assuming all $N$ initial particles constitute the candidate bound group. An iterative loop is initiated, which will successively refine this set. The loop terminates when the set of bound particles no longer changes between iterations, if the set becomes empty, or after a specified maximum number of iterations.\n\n2.  **Bulk Properties Calculation**: In each iteration, we first determine the bulk properties of the *current* set of bound particles. These are the mass-weighted center-of-mass position $\\boldsymbol{r}_{\\text{com}}$ and velocity $\\boldsymbol{v}_{\\text{com}}$:\n    $$ \\boldsymbol{r}_{\\text{com}} = \\frac{\\sum_{j \\in \\text{bound}} m_j \\boldsymbol{r}_j}{\\sum_{j \\in \\text{bound}} m_j}, \\quad \\boldsymbol{v}_{\\text{com}} = \\frac{\\sum_{j \\in \\text{bound}} m_j \\boldsymbol{v}_j}{\\sum_{j \\in \\text{bound}} m_j} $$\n    These values define the origin and state of motion of the reference frame in which the binding energies are computed.\n\n3.  **Energy Calculation**: For each particle $i$ in the current bound set, its total specific energy $e_i$ is calculated by summing three components:\n\n    a.  **Specific Kinetic Energy**: This is the kinetic energy per unit mass relative to the bulk motion of the halo. For a particle with velocity $\\boldsymbol{v}_i$, its specific kinetic energy is:\n        $$ k_i = \\frac{1}{2} \\left\\lVert \\boldsymbol{v}_i - \\boldsymbol{v}_{\\text{com}} \\right\\rVert^2 $$\n\n    b.  **Specific Self-Potential Energy**: This is the gravitational potential energy per unit mass of particle $i$ due to the gravitational attraction of all *other* particles $j$ in the currently bound set. To avoid the singularity at zero separation, a Plummer-equivalent softening length $\\epsilon$ is used.\n        $$ \\Phi_{\\text{self}}(\\boldsymbol{r}_i) = - G \\sum_{j \\in \\text{bound}, j \\neq i} \\frac{m_j}{\\sqrt{\\left\\lVert \\boldsymbol{r}_i - \\boldsymbol{r}_j \\right\\rVert^2 + \\epsilon^2}} $$\n        Here, $G$ is the gravitational constant, $G = 4.30091 \\times 10^{-6} \\, \\mathrm{kpc} \\, (\\mathrm{km}/\\mathrm{s})^2 \\, M_{\\odot}^{-1}$.\n\n    c.  **Specific Tidal Potential Energy**: The gravitational field of the host galaxy is approximated locally by its tidal tensor, which describes the differential forces across the subhalo. The tidal tensor $\\mathbf{T}$ for a point-mass host $M_{\\text{host}}$ at position $\\boldsymbol{R}_{\\text{host}}$ is given by:\n        $$ \\mathbf{T} = \\frac{G M_{\\text{host}}}{R^3} \\left( 3 \\hat{\\boldsymbol{n}} \\hat{\\boldsymbol{n}}^\\top - \\mathbf{I} \\right) $$\n        where $R = \\left\\lVert \\boldsymbol{R}_{\\text{host}} - \\boldsymbol{r}_{\\text{com}} \\right\\rVert$ is the distance from the subhalo's center of mass to the host, $\\hat{\\boldsymbol{n}} = (\\boldsymbol{R}_{\\text{host}} - \\boldsymbol{r}_{\\text{com}})/R$ is the unit vector in that direction, and $\\mathbf{I}$ is the $3 \\times 3$ identity matrix. The tidal potential energy for a particle $i$ at a position $\\boldsymbol{x}_i = \\boldsymbol{r}_i - \\boldsymbol{r}_{\\text{com}}$ relative to the center of mass is:\n        $$ \\Phi_{\\text{tid}}(\\boldsymbol{x}_i) = \\frac{1}{2} \\boldsymbol{x}_i^\\top \\mathbf{T} \\boldsymbol{x}_i $$\n\n4.  **Binding Criterion and Iteration**: The total specific energy for particle $i$ is the sum $e_i = k_i + \\Phi_{\\text{self}}(\\boldsymbol{r}_i) + \\Phi_{\\text{tid}}(\\boldsymbol{x}_i)$. A particle is considered unbound if its total energy is non-negative, i.e., $e_i \\ge 0$.\n    After calculating $e_i$ for all particles in the current set, any unbound particles are identified and removed. This creates a new, smaller set of bound particles. The algorithm then returns to step $2$ with this new set. If, after an iteration, no particles are removed, the system has converged to a stable, self-bound configuration, and the algorithm terminates, returning the final set of bound particles.\n\nThe implementation will utilize `numpy` for efficient vectorized computation of distances, centers of mass, and matrix-vector operations, which is crucial for the performance of N-body algorithms.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ... (Not used in this implementation)\n\ndef perform_unbinding(positions, velocities, masses, epsilon, m_host, r_host, max_iter):\n    \"\"\"\n    Performs an iterative unbinding procedure on a set of particles.\n    \n    Args:\n        positions (np.ndarray): Particle positions (N, 3) in kpc.\n        velocities (np.ndarray): Particle velocities (N, 3) in km/s.\n        masses (np.ndarray): Particle masses (N,) in M_sun.\n        epsilon (float): Softening length in kpc.\n        m_host (float): Host mass in M_sun.\n        r_host (np.ndarray): Host position (3,) in kpc.\n        max_iter (int): Maximum number of iterations.\n        \n    Returns:\n        list: A sorted list of indices of the finally bound particles.\n    \"\"\"\n    G = 4.30091e-6  # kpc * (km/s)^2 / M_sun\n    \n    num_particles = len(positions)\n    is_bound_mask = np.ones(num_particles, dtype=bool)\n    \n    for _ in range(max_iter):\n        num_bound_before = np.sum(is_bound_mask)\n        \n        if num_bound_before == 0:\n            break\n            \n        current_indices = np.where(is_bound_mask)[0]\n        \n        # Get data for currently bound particles\n        m_bound = masses[is_bound_mask]\n        r_bound = positions[is_bound_mask]\n        v_bound = velocities[is_bound_mask]\n\n        # Step 1: Compute center of mass position and velocity\n        m_total = np.sum(m_bound)\n        r_com = np.sum(m_bound[:, np.newaxis] * r_bound, axis=0) / m_total\n        v_com = np.sum(m_bound[:, np.newaxis] * v_bound, axis=0) / m_total\n        \n        # Step 2: Calculate energy components for each bound particle\n        \n        # Specific Kinetic Energy\n        v_rel = v_bound - v_com\n        kinetic_energy = 0.5 * np.sum(v_rel**2, axis=1)\n        \n        # Specific Self-Potential Energy\n        if num_bound_before > 1:\n            diffs = r_bound[:, np.newaxis, :] - r_bound[np.newaxis, :, :]\n            dist_sq = np.sum(diffs**2, axis=2)\n            dists_soft = np.sqrt(dist_sq + epsilon**2)\n            \n            # Create a matrix of potential contributions: pot_matrix[i, j] is pot from j onto i\n            pot_matrix = -G * m_bound[np.newaxis, :] / dists_soft\n            np.fill_diagonal(pot_matrix, 0) # Exclude self-potential (j != i)\n            self_potential = np.sum(pot_matrix, axis=1)\n        else:\n            self_potential = np.zeros(1)\n\n        # Specific Tidal Potential Energy\n        R_vec = r_host - r_com\n        R = np.linalg.norm(R_vec)\n        if R == 0: # Avoid division by zero if halo is at host center\n            tidal_tensor = np.zeros((3, 3))\n        else:\n            n_hat = R_vec / R\n            n_outer = np.outer(n_hat, n_hat)\n            tidal_tensor = (G * m_host / R**3) * (3 * n_outer - np.identity(3))\n        \n        # Displacement vectors from COM\n        x_disp = r_bound - r_com\n        # Einstein summation for x^T * T * x for all particles\n        tidal_potential = 0.5 * np.einsum('ij,jk,ik->i', x_disp, tidal_tensor, x_disp)\n\n        # Step 3: Total energy and identifying unbound particles\n        total_energy = kinetic_energy + self_potential + tidal_potential\n        is_unbound_in_subset = total_energy >= 0\n        \n        # Step 4: Update the bound set and check for convergence\n        unbound_global_indices = current_indices[is_unbound_in_subset]\n\n        if len(unbound_global_indices) == 0:\n            # Converged\n            break\n        \n        is_bound_mask[unbound_global_indices] = False\n    \n    return np.where(is_bound_mask)[0].tolist()\n\ndef solve():\n    \"\"\"\n    Solves the unbinding problem for the defined test suite.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (compact, weak tide)\n        {\n            \"positions\": np.array([\n                [0.0, 0.0, 0.0], [0.3, 0.1, 0.0], [-0.2, -0.1, 0.1], \n                [0.1, -0.3, 0.2], [-0.1, 0.2, -0.2]\n            ]),\n            \"velocities\": np.array([\n                [0.0, 0.0, 0.0], [8.0, 0.0, 0.0], [-5.0, 2.0, 1.0], \n                [3.0, -4.0, 2.0], [-2.0, 1.0, -3.0]\n            ]),\n            \"masses\": np.full(5, 1.0e8),\n            \"epsilon\": 0.1,\n            \"m_host\": 1.0e12,\n            \"r_host\": np.array([300.0, 0.0, 0.0]),\n            \"max_iter\": 10\n        },\n        # Test case 2 (moderate tide, some unbinding)\n        {\n            \"positions\": np.array([\n                [0.0, 0.0, 0.0], [0.3, 0.1, 0.0], [-0.2, -0.1, 0.1], \n                [0.1, -0.3, 0.2], [-0.1, 0.2, -0.2], [2.0, 0.0, 0.0]\n            ]),\n            \"velocities\": np.array([\n                [0.0, 0.0, 0.0], [6.0, 0.0, 0.0], [-4.0, 1.5, 0.5], \n                [2.5, -3.0, 1.5], [-1.5, 0.5, -2.5], [50.0, 0.0, 0.0]\n            ]),\n            \"masses\": np.full(6, 2.0e8),\n            \"epsilon\": 0.05,\n            \"m_host\": 1.0e12,\n            \"r_host\": np.array([50.0, 0.0, 0.0]),\n            \"max_iter\": 10\n        },\n        # Test case 3 (mixed masses, borderline)\n        {\n            \"positions\": np.array([\n                [0.0, 0.0, 0.0], [0.5, 0.0, 0.0], [0.0, 0.5, 0.0], [0.0, 0.0, 0.5]\n            ]),\n            \"velocities\": np.array([\n                [0.0, 0.0, 0.0], [12.0, 0.0, 0.0], [0.0, 12.0, 0.0], [0.0, 0.0, 12.0]\n            ]),\n            \"masses\": np.array([3.0e8, 1.0e8, 2.0e8, 1.5e8]),\n            \"epsilon\": 0.1,\n            \"m_host\": 5.0e11,\n            \"r_host\": np.array([1000.0, 1000.0, 0.0]),\n            \"max_iter\": 10\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        bound_indices = perform_unbinding(**case)\n        results.append(bound_indices)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3480808"}, {"introduction": "The true power of cosmological simulations lies not in a single snapshot, but in following the evolution of structures over cosmic time. Building \"merger trees\" is the primary way we track halo growth, mergers, and accretion history. This practice [@problem_id:3480850] provides a foundational exercise in this process, guiding you to link halo catalogs from two consecutive timesteps by identifying progenitors and descendants based on their shared particle content, from which crucial quantities like mass accretion rates and first infall times can be derived.", "problem": "Consider two consecutive simulation outputs at times $t_0$ and $t_1$ for multiple toy datasets representing small cosmological regions. In each dataset, each dark matter halo is characterized by its unique identifier, a set of particle identifiers, its mass, its comoving position vector, and its virial radius. Assume a constant particle mass $m_p = 10^{10}\\ M_\\odot$ so that a halo’s mass $M(h)$ is given by $M(h) = |P(h)| \\cdot m_p$, where $P(h)$ is the set of its particle identifiers. Times are measured in gigayears (Gyr), positions in comoving megaparsecs (Mpc), virial radii in comoving megaparsecs (Mpc), and masses in solar masses ($M_\\odot$).\n\nYou must compute progenitor–descendant links on-the-fly, build branches, record first infall times, and compute mass accretion rates using only the following fundamental definitions:\n\n- Progenitor–descendant merit: For a progenitor halo $p$ at $t_0$ and a candidate descendant halo $d$ at $t_1$, define $S(p,d) = |P(p) \\cap P(d)|$. A progenitor $p$ links forward to the descendant $d$ that maximizes $S(p,d)$, provided the fractional overlap criterion $S(p,d)/|P(p)| \\ge f_{\\min}$ is satisfied with $f_{\\min} = 0.5$. Ties are broken by larger $S(p,d)$, then by larger $M(d)$, then by smaller identifier of $d$.\n- Main progenitor per descendant: For a given descendant $d$, among the set of progenitors that selected $d$ in the previous step, choose the one with the largest $S(p,d)$ as the main progenitor. Ties are broken by larger $M(p)$, then by smaller identifier of $p$. If no progenitor selects $d$, treat $d$ as newly formed with effective progenitor mass $M_0(d) = 0$ for accretion purposes.\n- Mass accretion rate: For each descendant $d$, define $M_1(d)$ as its mass at $t_1$ and $M_0(d)$ as the mass of its main progenitor at $t_0$ (or $0$ if none). The mass accretion rate is $\\dot{M}(d) = \\big(M_1(d) - M_0(d)\\big)/\\Delta t$, where $\\Delta t = t_1 - t_0$. Express $\\dot{M}(d)$ in $M_\\odot/\\mathrm{Gyr}$.\n- Subhalo identification and first infall time: At a given time $t$, a halo $h$ is a subhalo if there exists a distinct halo $H$ with $M(H)  M(h)$ and $\\|\\mathbf{x}(h) - \\mathbf{x}(H)\\|  R_{\\mathrm{vir}}(H)$. For a descendant $d$ at $t_1$, define its first infall time as $t_1$ if $d$ is a subhalo at $t_1$ and its main progenitor (if any) is not a subhalo at $t_0$. If this condition is not met or if no main progenitor exists, but $d$ is not a subhalo at $t_1$, return $-1$. Express infall times in $\\mathrm{Gyr}$.\n\nImplement an algorithm that adheres strictly to these definitions. Do not assume any formula beyond these definitions.\n\nThe program must process the following four datasets (test suite) independently and aggregate the results. For each dataset, use $t_0 = 0.0\\ \\mathrm{Gyr}$, $t_1 = 1.0\\ \\mathrm{Gyr}$, so that $\\Delta t = 1.0\\ \\mathrm{Gyr}$.\n\nDataset A (happy path with first infall):\n- $t_0$ halos:\n  - id $10$, $P = \\{1,2,3,4,5,6\\}$, position $(0.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.25\\ \\mathrm{Mpc}$.\n  - id $20$, $P = \\{100,101,102,103,104,105,106,107\\}$, position $(1.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.30\\ \\mathrm{Mpc}$.\n- $t_1$ halos:\n  - id $11$, $P = \\{1,2,3,4,5,200,201\\}$, position $(0.9,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.27\\ \\mathrm{Mpc}$.\n  - id $21$, $P = \\{100,101,102,103,104,105,106,300,301\\}$, position $(1.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.32\\ \\mathrm{Mpc}$.\n\nDataset B (boundary tie case and newly formed halo):\n- $t_0$ halos:\n  - id $30$, $P = \\{1,2,3,4\\}$, position $(0.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.24\\ \\mathrm{Mpc}$.\n  - id $40$, $P = \\{10,11,12,13\\}$, position $(2.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.24\\ \\mathrm{Mpc}$.\n- $t_1$ halos:\n  - id $31$, $P = \\{1,2,50,51\\}$, position $(0.1,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.24\\ \\mathrm{Mpc}$.\n  - id $41$, $P = \\{3,4,60,61\\}$, position $(2.1,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.24\\ \\mathrm{Mpc}$.\n\nDataset C (merger: two progenitors to one descendant):\n- $t_0$ halos:\n  - id $50$, $P = \\{1,2,3,4,5\\}$, position $(0.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.26\\ \\mathrm{Mpc}$.\n  - id $60$, $P = \\{10,11,12,13,14\\}$, position $(0.3,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.26\\ \\mathrm{Mpc}$.\n- $t_1$ halos:\n  - id $51$, $P = \\{1,2,3,10,11,12,200\\}$, position $(0.15,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.27\\ \\mathrm{Mpc}$.\n\nDataset D (no-link threshold and host-driven first infall):\n- $t_0$ halos:\n  - id $70$, $P = \\{1,2,3,4\\}$, position $(0.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.24\\ \\mathrm{Mpc}$.\n  - id $80$, $P = \\{20,21,22,23\\}$, position $(10.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.24\\ \\mathrm{Mpc}$.\n  - id $90$, $P = \\{1000,1001,1002,1003,1004,1005,1006,1007,1008,1009\\}$, position $(2.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.50\\ \\mathrm{Mpc}$.\n- $t_1$ halos:\n  - id $71$, $P = \\{1,100,101,102\\}$, position $(0.05,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.24\\ \\mathrm{Mpc}$.\n  - id $81$, $P = \\{20,21,22,23\\}$, position $(10.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.24\\ \\mathrm{Mpc}$.\n  - id $91$, $P = \\{1000,1001,1002,1003,1004,1005,1006,1007,1008,1009\\}$, position $(0.0,0.0,0.0)$ $\\mathrm{Mpc}$, $R_{\\mathrm{vir}} = 0.50\\ \\mathrm{Mpc}$.\n\nFor each dataset, perform the linking and analysis, then produce an ordered result by sorting the $t_1$ halo identifiers in ascending order and, for each $t_1$ halo $d$ in that order, appending the pair $\\big(\\dot{M}(d), t_{\\mathrm{infall}}(d)\\big)$ to a flat output list. Here, $t_{\\mathrm{infall}}(d)$ is $t_1$ if and only if $d$ experiences first infall by the above criterion, and $-1$ otherwise. Express $\\dot{M}$ in $M_\\odot/\\mathrm{Gyr}$ and $t_{\\mathrm{infall}}$ in $\\mathrm{Gyr}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, enumerating the results for Dataset A, then Dataset B, then Dataset C, then Dataset D, in that order, each dataset contributing its pairs in the specified $t_1$ identifier order. The list elements must be numeric (floats or integers). No additional text should be printed.\n\nThe test suite is designed to cover:\n- A standard case with clean links and a first infall event.\n- A boundary tie on the fractional overlap threshold leading to a deterministic tie-break and a newly formed halo.\n- A merger where two progenitors link to one descendant and the main progenitor must be selected.\n- A case where a progenitor fails the linking threshold, and a host-induced first infall is detected.", "solution": "We proceed from first principles grounded in the provided definitions. Each halo is characterized by particle membership, from which halo mass follows as $M = |P| \\cdot m_p$ with $m_p = 10^{10}\\ M_\\odot$. The forward linking from time $t_0$ to $t_1$ is defined by maximizing the particle overlap merit $S(p,d) = |P(p)\\cap P(d)|$ subject to $S/|P(p)| \\ge f_{\\min}$ with $f_{\\min} = 0.5$. The main progenitor of a descendant is chosen among progenitors that selected it by the same $S$, $M$, and identifier tie-breaks. Subhalo identification follows a geometric criterion relative to more massive hosts. The mass accretion rate for a descendant $d$ is $\\dot{M}(d) = \\big(M_1(d)-M_0(d)\\big)/\\Delta t$, where $M_0(d)$ is the mass of the main progenitor or $0$ if none, and $\\Delta t = t_1 - t_0 = 1.0\\ \\mathrm{Gyr}$. The first infall time is $t_1$ if the descendant is a subhalo at $t_1$ and its main progenitor is not a subhalo at $t_0$, else it is set to $-1$.\n\nWe now apply this to each dataset.\n\nDataset A:\n- Parameters: $t_0 = 0.0\\ \\mathrm{Gyr}$, $t_1 = 1.0\\ \\mathrm{Gyr}$, $\\Delta t = 1.0\\ \\mathrm{Gyr}$.\n- $t_0$ halos: id $10$ with $|P| = 6 \\Rightarrow M = 6\\times 10^{10}\\ M_\\odot$, id $20$ with $|P| = 8 \\Rightarrow M = 8\\times 10^{10}\\ M_\\odot$.\n- $t_1$ halos: id $11$ with $|P| = 7 \\Rightarrow M = 7\\times 10^{10}\\ M_\\odot$, id $21$ with $|P| = 9 \\Rightarrow M = 9\\times 10^{10}\\ M_\\odot$.\n\nLinking merits:\n- For progenitor $10$ to descendants, $S(10,11) = |\\{1,2,3,4,5,6\\}\\cap \\{1,2,3,4,5,200,201\\}| = 5$, so $S/|P(10)| = 5/6 \\approx 0.833 \\ge 0.5$. $S(10,21) = 0$. Thus $10 \\to 11$.\n- For progenitor $20$ to descendants, $S(20,21) = |\\{100,\\dots,107\\}\\cap \\{100,101,102,103,104,105,106,300,301\\}| = 7$, so $S/|P(20)| = 7/8 = 0.875 \\ge 0.5$. $S(20,11) = 0$. Thus $20 \\to 21$.\n\nMain progenitors at $t_1$:\n- For descendant $11$, only progenitor $10$ selected it, so main progenitor is $10$.\n- For descendant $21$, only progenitor $20$ selected it, so main progenitor is $20$.\n\nMass accretion rates:\n- $\\dot{M}(11) = \\big(7\\times 10^{10} - 6\\times 10^{10}\\big)/1.0 = 1\\times 10^{10}\\ M_\\odot/\\mathrm{Gyr}$.\n- $\\dot{M}(21) = \\big(9\\times 10^{10} - 8\\times 10^{10}\\big)/1.0 = 1\\times 10^{10}\\ M_\\odot/\\mathrm{Gyr}$.\n\nFirst infall:\n- Subhalo test at $t_1$: For $11$ relative to $21$, $\\|\\mathbf{x}(11)-\\mathbf{x}(21)\\| = \\sqrt{(0.9-1.0)^2} = 0.1\\ \\mathrm{Mpc}  R_{\\mathrm{vir}}(21) = 0.32\\ \\mathrm{Mpc}$ and $M(21)  M(11)$, so $11$ is a subhalo at $t_1$. At $t_0$, for $10$ relative to $20$, distance $\\sqrt{(0.0-1.0)^2} = 1.0\\ \\mathrm{Mpc}  R_{\\mathrm{vir}}(20) = 0.30\\ \\mathrm{Mpc}$, so not a subhalo. Hence first infall time is $t_1 = 1.0\\ \\mathrm{Gyr}$ for $11$.\n- For $21$, there is no more massive halo at $t_1$, so not a subhalo; first infall is $-1$.\n\nOrdered by $t_1$ ids $(11, 21)$, the outputs are $\\big(1\\times 10^{10}, 1.0\\big)$ and $\\big(1\\times 10^{10}, -1\\big)$.\n\nDataset B:\n- $t_0$ halos $30$ and $40$ each have $|P| = 4 \\Rightarrow 4\\times 10^{10}\\ M_\\odot$. $t_1$ halos $31$ and $41$ each have $|P| = 4 \\Rightarrow 4\\times 10^{10}\\ M_\\odot$.\n- Linking merits for progenitor $30$: $S(30,31) = |\\{1,2,3,4\\}\\cap \\{1,2,50,51\\}| = 2$, $S/|P| = 2/4 = 0.5$, and $S(30,41) = |\\{1,2,3,4\\}\\cap \\{3,4,60,61\\}| = 2$, $S/|P| = 0.5$. Tie on $S$ and $M(d)$; break by smaller descendant id, so $30 \\to 31$.\n- Progenitor $40$ shares zero with both descendants, so no link is formed.\n- Main progenitors: $31$ has main progenitor $30$; $41$ has none (newly formed).\n- Mass accretion rates: $\\dot{M}(31) = (4\\times 10^{10} - 4\\times 10^{10})/1.0 = 0$, $\\dot{M}(41) = (4\\times 10^{10} - 0)/1.0 = 4\\times 10^{10}$.\n- First infall: At both $t_0$ and $t_1$, inter-halo distances are large compared to $R_{\\mathrm{vir}}$, and there is no more massive host, so both are not subhalos. First infall times are $-1$ for both.\n\nOrdered by $t_1$ ids $(31, 41)$, the outputs are $\\big(0, -1\\big)$ and $\\big(4\\times 10^{10}, -1\\big)$.\n\nDataset C:\n- $t_0$ halos $50$ and $60$ each have $|P| = 5 \\Rightarrow 5\\times 10^{10}\\ M_\\odot$. $t_1$ halo $51$ has $|P| = 7 \\Rightarrow 7\\times 10^{10}\\ M_\\odot$.\n- Linking merits: $S(50,51) = |\\{1,2,3,4,5\\}\\cap \\{1,2,3,10,11,12,200\\}| = 3$, so $3/5 = 0.6 \\ge 0.5$. $S(60,51) = |\\{10,11,12,13,14\\}\\cap \\{1,2,3,10,11,12,200\\}| = 3$, so $0.6 \\ge 0.5$. Both progenitors link to $51$.\n- Main progenitor selection for $51$: Tie on $S$ and $M$, break by smaller id, so main progenitor is $50$.\n- Mass accretion rate: $\\dot{M}(51) = (7\\times 10^{10} - 5\\times 10^{10})/1.0 = 2\\times 10^{10}$.\n- First infall: There is no more massive host at $t_1$, so not a subhalo; first infall is $-1$.\n\nOrdered by $t_1$ id $(51)$, the output is $\\big(2\\times 10^{10}, -1\\big)$.\n\nDataset D:\n- $t_0$ halos: $70$ and $80$ with $|P| = 4 \\Rightarrow 4\\times 10^{10}\\ M_\\odot$, and $90$ with $|P| = 10 \\Rightarrow 1\\times 10^{11}\\ M_\\odot$.\n- $t_1$ halos: $71$ with $|P| = 4 \\Rightarrow 4\\times 10^{10}\\ M_\\odot$, $81$ with $|P| = 4 \\Rightarrow 4\\times 10^{10}\\ M_\\odot$, and $91$ with $|P| = 10 \\Rightarrow 1\\times 10^{11}\\ M_\\odot$.\n- Linking merits:\n  - Progenitor $70$ to $71$: $S(70,71) = |\\{1,2,3,4\\}\\cap \\{1,100,101,102\\}| = 1$, so $1/4 = 0.25  0.5$, no link. To others, zero.\n  - Progenitor $80$ to $81$: $S(80,81) = 4$, so $4/4 = 1.0 \\ge 0.5$, link $80 \\to 81$.\n  - Progenitor $90$ to $91$: $S(90,91) = 10$, so $10/10 = 1.0 \\ge 0.5$, link $90 \\to 91$.\n- Main progenitors: $71$ has none (newly formed), $81$ main progenitor $80$, $91$ main progenitor $90$.\n- Mass accretion rates: $\\dot{M}(71) = (4\\times 10^{10} - 0)/1.0 = 4\\times 10^{10}$, $\\dot{M}(81) = (4\\times 10^{10} - 4\\times 10^{10})/1.0 = 0$, $\\dot{M}(91) = (1\\times 10^{11} - 1\\times 10^{11})/1.0 = 0$.\n- First infall:\n  - For $71$ at $t_1$, distance to $91$ is $\\|\\mathbf{x}(71)-\\mathbf{x}(91)\\| = \\sqrt{(0.05-0.0)^2} = 0.05\\ \\mathrm{Mpc}  R_{\\mathrm{vir}}(91) = 0.50\\ \\mathrm{Mpc}$ with $M(91)  M(71)$, so $71$ is a subhalo at $t_1$. At $t_0$, progenitor $70$ relative to $90$ has distance $\\sqrt{(0.0-2.0)^2} = 2.0\\ \\mathrm{Mpc}  0.50\\ \\mathrm{Mpc}$, so not a subhalo. First infall time is $t_1 = 1.0\\ \\mathrm{Gyr}$.\n  - For $81$, there is no more massive nearby host, so not a subhalo; first infall is $-1$.\n  - For $91$, no more massive host exists; first infall is $-1$.\n\nOrdered by $t_1$ ids $(71, 81, 91)$, the outputs are $\\big(4\\times 10^{10}, 1.0\\big)$, $\\big(0, -1\\big)$, and $\\big(0, -1\\big)$.\n\nAggregating across datasets in order A, B, C, D, and flattening pairs in ascending $t_1$ id order within each dataset yields the final numeric list:\n- Dataset A: $\\left[1.0\\times 10^{10},\\ 1.0,\\ 1.0\\times 10^{10},\\ -1.0\\right]$.\n- Dataset B: $\\left[0.0,\\ -1.0,\\ 4.0\\times 10^{10},\\ -1.0\\right]$.\n- Dataset C: $\\left[2.0\\times 10^{10},\\ -1.0\\right]$.\n- Dataset D: $\\left[4.0\\times 10^{10},\\ 1.0,\\ 0.0,\\ -1.0,\\ 0.0,\\ -1.0\\right]$.\n\nThese values are what the program must output as a single flat list in the specified order, with $\\dot{M}$ in $M_\\odot/\\mathrm{Gyr}$ and times in $\\mathrm{Gyr}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef euclidean_distance(x, y):\n    return float(np.linalg.norm(np.array(x) - np.array(y)))\n\ndef link_progenitors_to_descendants(t0_halos, t1_halos, f_min=0.5):\n    \"\"\"\n    Forward link each progenitor (at t0) to at most one descendant (at t1)\n    based on shared particle count S(p,d) and threshold S/|P(p)| >= f_min.\n    Ties: higher S, then higher descendant mass, then smaller descendant id.\n    Returns:\n        forward_link: dict {prog_id: desc_id}\n        S_matrix: dict {(prog_id, desc_id): S}\n    \"\"\"\n    # Build quick lookup\n    t1_ids = [h['id'] for h in t1_halos]\n    t1_id_to_idx = {h['id']: i for i, h in enumerate(t1_halos)}\n    S_matrix = {}\n    forward_link = {}\n\n    for p in t0_halos:\n        best = None  # tuple (S, M_desc, -id_desc, desc_id)\n        best_desc_id = None\n        Pp = set(p['particles'])\n        for d in t1_halos:\n            Pd = set(d['particles'])\n            S = len(Pp.intersection(Pd))\n            S_matrix[(p['id'], d['id'])] = S\n        # choose descendant\n        for d in t1_halos:\n            S = S_matrix[(p['id'], d['id'])]\n            frac = S / max(1, len(p['particles']))\n            if frac >= f_min:\n                cand = (S, d['mass'], -d['id'], d['id'])\n                if best is None or cand > best:\n                    best = cand\n                    best_desc_id = d['id']\n        if best_desc_id is not None:\n            forward_link[p['id']] = best_desc_id\n    return forward_link, S_matrix\n\ndef main_progenitor_per_descendant(t0_halos, t1_halos, forward_link, S_matrix):\n    \"\"\"\n    Among progenitors that forward-linked to a given descendant, select main progenitor:\n    highest S, then higher progenitor mass, then smaller progenitor id.\n    Returns:\n        main_prog: dict {desc_id: prog_id or None}\n    \"\"\"\n    # Collect candidates per descendant\n    desc_candidates = {d['id']: [] for d in t1_halos}\n    t0_id_to_halo = {h['id']: h for h in t0_halos}\n    t1_id_to_halo = {h['id']: h for h in t1_halos}\n    for p_id, d_id in forward_link.items():\n        S = S_matrix[(p_id, d_id)]\n        p_mass = t0_id_to_halo[p_id]['mass']\n        desc_candidates[d_id].append((S, p_mass, -p_id, p_id))\n    main_prog = {}\n    for d in t1_halos:\n        did = d['id']\n        cands = desc_candidates[did]\n        if not cands:\n            main_prog[did] = None\n        else:\n            cands.sort(reverse=True)\n            main_prog[did] = cands[0][3]\n    return main_prog\n\ndef is_subhalo_at_time(target, halos_same_time):\n    \"\"\"\n    Determine if 'target' halo is a subhalo among halos at the same time:\n    exists host H with M(H) > M(target) and distance  Rvir(H).\n    \"\"\"\n    x_t = target['pos']\n    m_t = target['mass']\n    for H in halos_same_time:\n        if H['id'] == target['id']:\n            continue\n        if H['mass'] > m_t:\n            d = euclidean_distance(x_t, H['pos'])\n            if d  H['rvir']:\n                return True\n    return False\n\ndef analyze_dataset(t0_halos, t1_halos, t0, t1, f_min=0.5):\n    \"\"\"\n    Perform linking, main progenitor selection, accretion rate, and first infall detection.\n    Returns a flat list ordered by ascending t1 halo id:\n        [dotM(d1), infall_time_or_minus1(d1), dotM(d2), infall_time_or_minus1(d2), ...]\n    \"\"\"\n    # Forward link per definitions\n    forward_link, S_matrix = link_progenitors_to_descendants(t0_halos, t1_halos, f_min=f_min)\n    # Main progenitor per descendant\n    main_prog = main_progenitor_per_descendant(t0_halos, t1_halos, forward_link, S_matrix)\n    # Index maps\n    t0_map = {h['id']: h for h in t0_halos}\n    # Compute outputs\n    dt = t1 - t0\n    results = []\n    # Order t1 halos by id ascending\n    for d in sorted(t1_halos, key=lambda h: h['id']):\n        d_id = d['id']\n        M1 = float(d['mass'])\n        p_id = main_prog[d_id]\n        if p_id is None:\n            M0 = 0.0\n            sub_at_t0 = False\n        else:\n            M0 = float(t0_map[p_id]['mass'])\n            # subhalo state of progenitor at t0\n            sub_at_t0 = is_subhalo_at_time(t0_map[p_id], t0_halos)\n        dotM = (M1 - M0) / dt\n        # subhalo state of descendant at t1\n        sub_at_t1 = is_subhalo_at_time(d, t1_halos)\n        if sub_at_t1 and not sub_at_t0:\n            t_infall = float(t1)\n        else:\n            t_infall = -1.0\n        results.append(float(dotM))\n        results.append(float(t_infall))\n    return results\n\ndef build_halo(id_, particles, pos, rvir, mp=1.0e10):\n    return {\n        'id': id_,\n        'particles': list(particles),\n        'pos': tuple(pos),\n        'rvir': float(rvir),\n        'mass': float(len(particles) * mp),\n    }\n\ndef solve():\n    mp = 1.0e10\n    # Dataset A\n    A_t0 = [\n        build_halo(10, [1,2,3,4,5,6], (0.0,0.0,0.0), 0.25, mp),\n        build_halo(20, [100,101,102,103,104,105,106,107], (1.0,0.0,0.0), 0.30, mp),\n    ]\n    A_t1 = [\n        build_halo(11, [1,2,3,4,5,200,201], (0.9,0.0,0.0), 0.27, mp),\n        build_halo(21, [100,101,102,103,104,105,106,300,301], (1.0,0.0,0.0), 0.32, mp),\n    ]\n    # Dataset B\n    B_t0 = [\n        build_halo(30, [1,2,3,4], (0.0,0.0,0.0), 0.24, mp),\n        build_halo(40, [10,11,12,13], (2.0,0.0,0.0), 0.24, mp),\n    ]\n    B_t1 = [\n        build_halo(31, [1,2,50,51], (0.1,0.0,0.0), 0.24, mp),\n        build_halo(41, [3,4,60,61], (2.1,0.0,0.0), 0.24, mp),\n    ]\n    # Dataset C\n    C_t0 = [\n        build_halo(50, [1,2,3,4,5], (0.0,0.0,0.0), 0.26, mp),\n        build_halo(60, [10,11,12,13,14], (0.3,0.0,0.0), 0.26, mp),\n    ]\n    C_t1 = [\n        build_halo(51, [1,2,3,10,11,12,200], (0.15,0.0,0.0), 0.27, mp),\n    ]\n    # Dataset D\n    D_t0 = [\n        build_halo(70, [1,2,3,4], (0.0,0.0,0.0), 0.24, mp),\n        build_halo(80, [20,21,22,23], (10.0,0.0,0.0), 0.24, mp),\n        build_halo(90, [1000,1001,1002,1003,1004,1005,1006,1007,1008,1009], (2.0,0.0,0.0), 0.50, mp),\n    ]\n    D_t1 = [\n        build_halo(71, [1,100,101,102], (0.05,0.0,0.0), 0.24, mp),\n        build_halo(81, [20,21,22,23], (10.0,0.0,0.0), 0.24, mp),\n        build_halo(91, [1000,1001,1002,1003,1004,1005,1006,1007,1008,1009], (0.0,0.0,0.0), 0.50, mp),\n    ]\n\n    t0 = 0.0\n    t1 = 1.0\n    results = []\n    # Analyze each dataset and extend results\n    results.extend(analyze_dataset(A_t0, A_t1, t0, t1, f_min=0.5))\n    results.extend(analyze_dataset(B_t0, B_t1, t0, t1, f_min=0.5))\n    results.extend(analyze_dataset(C_t0, C_t1, t0, t1, f_min=0.5))\n    results.extend(analyze_dataset(D_t0, D_t1, t0, t1, f_min=0.5))\n\n    # Final print statement in the exact required format.\n    # Ensure default float formatting.\n    print(f\"[{','.join(map(lambda x: str(float(x)), results))}]\")\n\nsolve()\n```", "id": "3480850"}]}