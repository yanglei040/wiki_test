{"hands_on_practices": [{"introduction": "Many powerful cosmic web classification methods rely on the Hessian matrix of a smoothed density field. This first practice focuses on the essential numerical skill of implementing Gaussian smoothing and differentiation in Fourier space, which is a highly efficient and accurate method for periodic data. By mastering the connection between convolution, differentiation, and Fourier-space multiplication, you will build the foundational computational tool required for sophisticated web classifiers like the T-web formalism. [@problem_id:3502022]", "problem": "You are given a two-dimensional scalar field representative of a Delaunay Tessellation Field Estimator (DTFE) reconstruction sampled on a uniform periodic grid, and you are asked to implement Gaussian smoothing in Fourier space and quantify the attenuation it induces on gradients and Hessians. Use the Discrete Fourier Transform (DFT) computed via the Fast Fourier Transform (FFT) and exploit the following foundational facts: (i) convolution in real space corresponds to multiplication in Fourier space, (ii) the Fourier transform of a Gaussian with variance $\\,\\sigma^{2}\\,$ is another Gaussian with multiplier $\\,\\exp\\!\\left(-k^{2}\\sigma^{2}/2\\right)\\,$ in the wavenumber domain, where $\\,k^{2} = k_{x}^{2}+k_{y}^{2}\\,$, and (iii) differentiation corresponds to multiplication by $\\,\\mathrm{i}k_{x}\\,$ and $\\,\\mathrm{i}k_{y}\\,$ in Fourier space for partial derivatives with respect to $\\,x\\,$ and $\\,y\\,$, respectively. For a smoothed field $\\,\\phi_{\\sigma}\\,$ obtained by convolving the original field $\\,\\phi\\,$ with a Gaussian kernel of variance $\\,\\sigma^{2}\\,$, the Fourier coefficients satisfy $\\,\\widehat{\\phi_{\\sigma}}(\\boldsymbol{k}) = \\widehat{\\phi}(\\boldsymbol{k})\\exp\\!\\left(-k^{2}\\sigma^{2}/2\\right)\\,$. The Fourier-space gradient and Hessian follow from these properties. In the context of cosmic web classification, Hessian eigenvalues are used to identify voids and other structures, and Gaussian smoothing modifies their amplitudes by damping high-wavenumber modes.\n\nYour task is to write a complete program that:\n- Constructs specified test fields $\\,\\phi(x,y)\\,$ on a periodic square domain of side length $\\,L = 1\\,$ sampled on a grid of $\\,N \\times N\\,$ points with $\\,N = 64\\,$.\n- Implements Gaussian smoothing in Fourier space with variance $\\,\\sigma^{2}\\,$ using multiplication by $\\,\\exp\\!\\left(-k^{2}\\sigma^{2}/2\\right)\\,$.\n- Computes the gradient $\\,\\nabla \\phi\\,$ and Hessian $\\,\\nabla \\nabla \\phi\\,$ via Fourier-space differentiation.\n- For single-mode fields, estimates the attenuation factor of the root-mean-square (RMS) gradient magnitude and the RMS of the minimum Hessian eigenvalue and compares them against the theoretical factor $\\,\\exp\\!\\left(-k_{0}^{2}\\sigma^{2}/2\\right)\\,$ for that mode with wavenumber magnitude $\\,k_{0}\\,$.\n- For a two-mode superposition, estimates the attenuation factor of the RMS gradient magnitude and of the RMS Frobenius norm of the Hessian, and compares each to a predicted ratio computed purely from Fourier-space energy weighting:\n$$\nR_{\\mathrm{grad,pred}}(\\sigma) \\equiv \\sqrt{\\frac{\\sum_{\\boldsymbol{k}} k^{2}\\,\\left|\\widehat{\\phi}(\\boldsymbol{k})\\right|^{2}\\, \\exp\\!\\left(-k^{2}\\sigma^{2}\\right)}{\\sum_{\\boldsymbol{k}} k^{2}\\,\\left|\\widehat{\\phi}(\\boldsymbol{k})\\right|^{2}}}, \\quad\nR_{\\mathrm{H,pred}}(\\sigma) \\equiv \\sqrt{\\frac{\\sum_{\\boldsymbol{k}} k^{4}\\,\\left|\\widehat{\\phi}(\\boldsymbol{k})\\right|^{2}\\, \\exp\\!\\left(-k^{2}\\sigma^{2}\\right)}{\\sum_{\\boldsymbol{k}} k^{4}\\,\\left|\\widehat{\\phi}(\\boldsymbol{k})\\right|^{2}}}.\n$$\nHere $\\,k^{2} = k_{x}^{2}+k_{y}^{2}\\,$, and the sums run over all discrete Fourier modes on the grid. The use of the Frobenius norm $\\,\\|\\nabla \\nabla \\phi\\|_{F} = \\sqrt{\\phi_{xx}^{2} + 2\\phi_{xy}^{2} + \\phi_{yy}^{2}}\\,$ ensures linear spectral weighting for multi-mode fields.\n\nDefinitions and assumptions:\n- Delaunay Tessellation Field Estimator (DTFE): a method to reconstruct a continuous density-like field from discrete samples. In this task, you operate on an already gridded field representative of a DTFE output.\n- Fast Fourier Transform (FFT): an algorithm to compute the Discrete Fourier Transform (DFT) efficiently.\n- The computational domain is $[0,1)\\times[0,1)$ with periodic boundary conditions.\n- All quantities are nondimensional; no physical units are required.\n- Angles, where present implicitly through trigonometric functions, are in radians.\n\nImplement the following test suite. For each case, construct the specified field $\\,\\phi(x,y)\\,$ on the grid and perform the operations above.\n\n- Test $\\,1\\,$ (single mode, baseline attenuation):\n  - Field: $\\,\\phi(x,y) = A\\cos(2\\pi n_{x} x)\\,$ with $\\,A = 1\\,$ and $\\,n_{x} = 4\\,$.\n  - Smoothing variance: $\\,\\sigma^{2}\\,$ with $\\,\\sigma = 0.05\\,$.\n  - Predicted attenuation factor for both RMS gradient magnitude and RMS minimum Hessian eigenvalue: $\\,\\exp\\!\\left(-k_{0}^{2}\\sigma^{2}/2\\right)\\,$ with $\\,k_{0} = 2\\pi n_{x}\\,$.\n  - Output two floats: the relative error between the measured gradient RMS ratio and the predicted factor, and the relative error between the measured RMS minimum eigenvalue ratio and the predicted factor.\n\n- Test $\\,2\\,$ (identity smoothing boundary):\n  - Same field as Test $\\,1\\,$.\n  - Smoothing variance: $\\,\\sigma^{2}\\,$ with $\\,\\sigma = 0.0\\,$.\n  - Predicted attenuation factor: $\\,1\\,$.\n  - Output two floats as in Test $\\,1\\,$.\n\n- Test $\\,3\\,$ (higher frequency with stronger attenuation):\n  - Field: $\\,\\phi(x,y) = A\\cos(2\\pi n_{x} x)\\,$ with $\\,A = 1\\,$ and $\\,n_{x} = 8\\,$.\n  - Smoothing variance: $\\,\\sigma^{2}\\,$ with $\\,\\sigma = 0.12\\,$.\n  - Predicted attenuation factor: $\\,\\exp\\!\\left(-k_{0}^{2}\\sigma^{2}/2\\right)\\,$ with $\\,k_{0} = 2\\pi n_{x}\\,$.\n  - Output two floats as in Test $\\,1\\,$.\n\n- Test $\\,4\\,$ (two-mode superposition, spectral-energy prediction):\n  - Field: $\\,\\phi(x,y) = A_{1}\\cos(2\\pi n_{1} x) + A_{2}\\cos(2\\pi n_{2} y)\\,$ with $\\,A_{1} = 1\\,$, $\\,n_{1} = 3\\,$, $\\,A_{2} = 0.8\\,$, $\\,n_{2} = 5\\,$.\n  - Smoothing variance: $\\,\\sigma^{2}\\,$ with $\\,\\sigma = 0.07\\,$.\n  - Predicted gradient RMS ratio $\\,R_{\\mathrm{grad,pred}}(\\sigma)\\,$ and predicted Hessian Frobenius RMS ratio $\\,R_{\\mathrm{H,pred}}(\\sigma)\\,$ computed from the Fourier-space weighted sums above using the unsmoothed $\\,\\widehat{\\phi}\\,$.\n  - Output two floats: the relative error between the measured gradient RMS ratio and $\\,R_{\\mathrm{grad,pred}}(\\sigma)\\,$, and the relative error between the measured Hessian Frobenius RMS ratio and $\\,R_{\\mathrm{H,pred}}(\\sigma)\\,$.\n\nFor each test, define the measured ratios as:\n- Gradient RMS ratio: the RMS of $\\,\\|\\nabla \\phi_{\\sigma}\\|\\,$ divided by the RMS of $\\,\\|\\nabla \\phi\\|\\,$, where $\\,\\|\\nabla \\phi\\| = \\sqrt{\\phi_{x}^{2} + \\phi_{y}^{2}}\\,$.\n- Minimum Hessian eigenvalue RMS ratio for single-mode tests: the RMS of the pointwise minimum eigenvalue of $\\,\\nabla \\nabla \\phi_{\\sigma}\\,$ divided by the RMS of the pointwise minimum eigenvalue of $\\,\\nabla \\nabla \\phi\\,$.\n- Hessian Frobenius RMS ratio for the two-mode test: the RMS of the Frobenius norm $\\,\\|\\nabla \\nabla \\phi_{\\sigma}\\|_{F}\\,$ divided by the RMS of $\\,\\|\\nabla \\nabla \\phi\\|_{F}\\,$.\n\nAll FFT-based derivatives and smoothing must be implemented consistently on the periodic domain. Use $\\,N = 64\\,$ and $\\,L = 1\\,$ for all tests. The final program must compute, in order, the following eight floats: \n$[\\,$Test $\\,1$ gradient relative error, Test $\\,1$ minimum-eigenvalue relative error, Test $\\,2$ gradient relative error, Test $\\,2$ minimum-eigenvalue relative error, Test $\\,3$ gradient relative error, Test $\\,3$ minimum-eigenvalue relative error, Test $\\,4$ gradient relative error, Test $\\,4$ Hessian-Frobenius relative error$\\,]$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\mathrm{result1},\\mathrm{result2},\\mathrm{result3}]$). Each result must be a float. No external input is required, and all computations are nondimensional with no unit conversions necessary. Angles, if any, are in radians by construction.", "solution": "The problem is evaluated to be valid. It is scientifically grounded in the principles of Fourier analysis and its application to numerical field theory, is well-posed with all necessary parameters and definitions provided, and is stated in an objective, formal language. It presents a non-trivial but feasible computational task that tests the understanding and implementation of these principles.\n\nThe solution proceeds by implementing the specified numerical methods in a systematic manner. First, we establish the computational grid and the corresponding Fourier-space coordinates (wavenumbers). Then, we define a set of functions to compute the gradient and Hessian of a field using Fourier-space differentiation. These functions will form the core of our analysis. We will also implement the Gaussian smoothing operation as a multiplication in Fourier space. Finally, we will process each test case by constructing the specified field, applying the smoothing and differentiation operators, calculating the required root-mean-square (RMS) metrics, and comparing the results to their theoretical predictions.\n\n**1. Grid and Wavenumber Representation**\n\nThe problem is defined on a two-dimensional periodic domain $[0, L) \\times [0, L)$ with side length $L = 1$, sampled on a uniform grid of $N \\times N$ points, where $N=64$. The grid coordinates $(x_j, y_l)$ are given by:\n$$ x_j = j \\frac{L}{N}, \\quad y_l = l \\frac{L}{N} \\quad \\text{for } j, l \\in \\{0, 1, \\dots, N-1\\} $$\nThe Discrete Fourier Transform (DFT) maps a function on this real-space grid to its coefficients on a grid of discrete wavenumbers. The wavenumbers $(k_x, k_y)$ are determined by the grid size $N$ and domain length $L$. For a DFT implemented using a Fast Fourier Transform (FFT) algorithm, the corresponding frequencies are provided by standard library functions (e.g., `numpy.fft.fftfreq`). The wavenumbers are obtained by scaling these frequencies by $2\\pi$:\n$$ k_{x,m} = 2\\pi f_m, \\quad k_{y,n} = 2\\pi f_n $$\nwhere $f_m$ and $f_n$ are the discrete frequencies for an $N$-point transform with sample spacing $d = L/N$. We construct two-dimensional arrays for $k_x$, $k_y$, and the squared wavenumber magnitude $k^2 = k_x^2 + k_y^2$, which will be used repeatedly.\n\n**2. Fourier-Space Operators**\n\nThe foundation of this problem lies in the properties of the Fourier transform. Let $\\widehat{\\phi}(\\boldsymbol{k})$ denote the DFT of the scalar field $\\phi(\\boldsymbol{x})$, where $\\boldsymbol{k} = (k_x, k_y)$.\n\n**a. Gaussian Smoothing:**\nConvolution of the field $\\phi$ with a Gaussian kernel of variance $\\sigma^2$ is equivalent to multiplying its Fourier transform $\\widehat{\\phi}(\\boldsymbol{k})$ by the Fourier transform of the Gaussian. This is given as the filter:\n$$ S(\\boldsymbol{k}, \\sigma) = \\exp\\left(-\\frac{k^2 \\sigma^2}{2}\\right) $$\nThe Fourier transform of the smoothed field, $\\phi_\\sigma$, is thus:\n$$ \\widehat{\\phi_\\sigma}(\\boldsymbol{k}) = \\widehat{\\phi}(\\boldsymbol{k}) S(\\boldsymbol{k}, \\sigma) $$\nThe smoothed field $\\phi_\\sigma(\\boldsymbol{x})$ is then recovered by applying the inverse DFT.\n\n**b. Differentiation:**\nThe differentiation property of the Fourier transform states that the transform of a partial derivative is equivalent to multiplying the original transform by the corresponding imaginary wavenumber.\n$$ \\mathcal{F}\\left[\\frac{\\partial \\phi}{\\partial x}\\right] = \\mathrm{i}k_x \\widehat{\\phi}(\\boldsymbol{k}), \\quad \\mathcal{F}\\left[\\frac{\\partial \\phi}{\\partial y}\\right] = \\mathrm{i}k_y \\widehat{\\phi}(\\boldsymbol{k}) $$\nSecond derivatives follow by applying this rule twice:\n$$ \\mathcal{F}\\left[\\frac{\\partial^2 \\phi}{\\partial x^2}\\right] = (\\mathrm{i}k_x)^2 \\widehat{\\phi}(\\boldsymbol{k}) = -k_x^2 \\widehat{\\phi}(\\boldsymbol{k}) $$\n$$ \\mathcal{F}\\left[\\frac{\\partial^2 \\phi}{\\partial y^2}\\right] = (\\mathrm{i}k_y)^2 \\widehat{\\phi}(\\boldsymbol{k}) = -k_y^2 \\widehat{\\phi}(\\boldsymbol{k}) $$\n$$ \\mathcal{F}\\left[\\frac{\\partial^2 \\phi}{\\partial x \\partial y}\\right] = (\\mathrm{i}k_x)(\\mathrm{i}k_y) \\widehat{\\phi}(\\boldsymbol{k}) = -k_x k_y \\widehat{\\phi}(\\boldsymbol{k}) $$\nTo compute the gradient vector $\\nabla\\phi = (\\phi_x, \\phi_y)$ or the Hessian tensor $\\nabla\\nabla\\phi$, we first compute the DFT of $\\phi$, multiply by the appropriate wavenumber factors (e.g., $\\mathrm{i}k_x$, $-k_x^2$), and then apply the inverse DFT to return to real space. The resulting fields may have negligible imaginary components due to floating-point inaccuracies, which must be discarded.\n\n**3. Calculation of Observables**\n\nThe problem requires the calculation of several quantities for both the original field $\\phi$ and the smoothed field $\\phi_\\sigma$.\n\n**a. RMS values:** The root-mean-square of a quantity $Q$ on the $N \\times N$ grid is calculated as:\n$$ \\text{RMS}(Q) = \\sqrt{\\frac{1}{N^2} \\sum_{j=0}^{N-1} \\sum_{l=0}^{N-1} Q(x_j, y_l)^2} $$\n\n**b. Gradient Magnitude:** The magnitude of the gradient is $\\|\\nabla\\phi\\| = \\sqrt{\\phi_x^2 + \\phi_y^2}$. We compute its RMS value across the grid.\n\n**c. Hessian Eigenvalues (Single-mode tests):** The Hessian is a $2 \\times 2$ symmetric matrix at each grid point:\n$$ H(\\boldsymbol{x}) = \\begin{pmatrix} \\phi_{xx}(\\boldsymbol{x})  \\phi_{xy}(\\boldsymbol{x}) \\\\ \\phi_{xy}(\\boldsymbol{x})  \\phi_{yy}(\\boldsymbol{x}) \\end{pmatrix} $$\nIts eigenvalues are given by the formula $\\lambda_{\\pm} = \\frac{1}{2}\\left( \\text{Tr}(H) \\pm \\sqrt{(\\text{Tr}(H))^2 - 4\\det(H)} \\right)$, which simplifies to:\n$$ \\lambda_{\\pm} = \\frac{1}{2}\\left( (\\phi_{xx} + \\phi_{yy}) \\pm \\sqrt{(\\phi_{xx}-\\phi_{yy})^2 + 4\\phi_{xy}^2} \\right) $$\nWe are interested in the minimum eigenvalue, $\\lambda_{-}$. We compute the field of minimum eigenvalues and then its RMS value.\n\n**d. Hessian Frobenius Norm (Two-mode test):** The Frobenius norm of the Hessian is given by:\n$$ \\|\\nabla\\nabla\\phi\\|_F = \\sqrt{\\phi_{xx}^2 + \\phi_{yy}^2 + 2\\phi_{xy}^2} $$\nWe compute the field of Frobenius norms and then its RMS value.\n\n**4. Theoretical Predictions and Error Calculation**\n\nThe measured attenuation, quantified by the ratio of RMS values (e.g., $\\text{RMS}(\\|\\nabla\\phi_\\sigma\\|)/\\text{RMS}(\\|\\nabla\\phi\\|)$), is compared against theoretical predictions.\n\n**a. Single-mode fields:** For a field dominated by a single wavenumber magnitude $k_0$, such as $\\phi(x,y) = A\\cos(2\\pi n_x x)$ which has $k_0 = 2\\pi n_x$, every derivative operation simply multiplies the field's amplitude by a factor related to $k_0$. Smoothing introduces a further multiplicative factor of $\\exp(-k_0^2\\sigma^2/2)$. Consequently, the amplitudes of the gradient and all Hessian components are attenuated by this same factor. Since the RMS is proportional to the amplitude, the ratio of RMS values for any of these quantities (gradient magnitude, Hessian eigenvalues) is predicted to be:\n$$ R_{\\text{pred}}(\\sigma) = \\exp\\left(-\\frac{k_0^2 \\sigma^2}{2}\\right) $$\n\n**b. Two-mode fields:** For a superposition of modes, the simple prediction above does not hold. The problem provides spectral-energy weighted predictions. The predicted ratio for the RMS gradient magnitude is:\n$$ R_{\\mathrm{grad,pred}}(\\sigma) = \\sqrt{\\frac{\\sum_{\\boldsymbol{k}} k^{2}\\,|\\widehat{\\phi}(\\boldsymbol{k})|^{2}\\, \\exp(-k^{2}\\sigma^{2})}{\\sum_{\\boldsymbol{k}} k^{2}\\,|\\widehat{\\phi}(\\boldsymbol{k})|^{2}}} $$\nThis formula weights the contribution of each mode's power $|\\widehat{\\phi}(\\boldsymbol{k})|^2$ by $k^2$ (from the gradient) and the smoothing factor. The denominator is the total \"gradient power\" of the unsmoothed field. Similarly, the predicted ratio for the RMS Hessian Frobenius norm is:\n$$ R_{\\mathrm{H,pred}}(\\sigma) = \\sqrt{\\frac{\\sum_{\\boldsymbol{k}} k^{4}\\,|\\widehat{\\phi}(\\boldsymbol{k})|^{2}\\, \\exp(-k^{2}\\sigma^{2})}{\\sum_{\\boldsymbol{k}} k^{4}\\,|\\widehat{\\phi}(\\boldsymbol{k})|^{2}}} $$\nThe weighting $k^4$ arises because the Frobenius norm-squared is a sum of squares of second derivatives, and each second derivative contributes a factor of $k^2$ in Fourier space, leading to an overall $k^4$ scaling for the power.\n\nThe final output for each test is the relative error between the measured ratio and the predicted ratio:\n$$ \\text{Relative Error} = \\frac{|\\text{Measured Ratio} - \\text{Predicted Ratio}|}{|\\text{Predicted Ratio}|} $$\n\nThis systematic process will be implemented for all four test cases to obtain the required eight output values.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for Fourier-space smoothing and differentiation.\n    \"\"\"\n\n    def compute_derivatives(phi_hat, kx, ky):\n        \"\"\"Computes gradient and Hessian components in real space from a Fourier-space field.\"\"\"\n        # Gradient components\n        phi_x_hat = 1j * kx * phi_hat\n        phi_y_hat = 1j * ky * phi_hat\n        phi_x = np.fft.ifftn(phi_x_hat).real\n        phi_y = np.fft.ifftn(phi_y_hat).real\n\n        # Hessian components\n        phi_xx_hat = -kx**2 * phi_hat\n        phi_yy_hat = -ky**2 * phi_hat\n        phi_xy_hat = -kx * ky * phi_hat\n        phi_xx = np.fft.ifftn(phi_xx_hat).real\n        phi_yy = np.fft.ifftn(phi_yy_hat).real\n        phi_xy = np.fft.ifftn(phi_xy_hat).real\n        \n        return phi_x, phi_y, phi_xx, phi_yy, phi_xy\n\n    def get_rms(field):\n        \"\"\"Computes the root-mean-square of a 2D field.\"\"\"\n        return np.sqrt(np.mean(field**2))\n\n    def run_analysis(phi, sigma, kx, ky, k_sq, test_type, phi_hat=None):\n        \"\"\"\n        Performs the core analysis for a given field and smoothing parameter.\n        `test_type` can be 'single_mode' or 'two_mode'.\n        \"\"\"\n        N, _ = phi.shape\n        \n        # --- Unsmoothed Field Analysis ---\n        if phi_hat is None:\n            phi_hat = np.fft.fftn(phi)\n        \n        phi_x, phi_y, phi_xx, phi_yy, phi_xy = compute_derivatives(phi_hat, kx, ky)\n\n        # --- Smoothed Field Analysis ---\n        smoothing_kernel = np.exp(-k_sq * sigma**2 / 2.0)\n        phi_sigma_hat = phi_hat * smoothing_kernel\n        \n        phi_sigma_x, phi_sigma_y, phi_sigma_xx, phi_sigma_yy, phi_sigma_xy = \\\n            compute_derivatives(phi_sigma_hat, kx, ky)\n\n        # --- Compute Ratios ---\n        # Gradient RMS ratio\n        grad_mag = np.sqrt(phi_x**2 + phi_y**2)\n        grad_mag_sigma = np.sqrt(phi_sigma_x**2 + phi_sigma_y**2)\n        measured_ratio_grad = get_rms(grad_mag_sigma) / get_rms(grad_mag) if get_rms(grad_mag) != 0 else 0\n\n        # Hessian ratio (depends on test type)\n        if test_type == 'single_mode':\n            # Minimum eigenvalue of Hessian\n            trace = phi_xx + phi_yy\n            discriminant = np.sqrt(np.maximum(0, (phi_xx - phi_yy)**2 + 4 * phi_xy**2))\n            min_eig = 0.5 * (trace - discriminant)\n\n            trace_sigma = phi_sigma_xx + phi_sigma_yy\n            discriminant_sigma = np.sqrt(np.maximum(0, (phi_sigma_xx - phi_sigma_yy)**2 + 4 * phi_sigma_xy**2))\n            min_eig_sigma = 0.5 * (trace_sigma - discriminant_sigma)\n\n            measured_ratio_hess = get_rms(min_eig_sigma) / get_rms(min_eig) if get_rms(min_eig) != 0 else 0\n            \n        elif test_type == 'two_mode':\n            # Frobenius norm of Hessian\n            frob_norm = np.sqrt(phi_xx**2 + 2 * phi_xy**2 + phi_yy**2)\n            frob_norm_sigma = np.sqrt(phi_sigma_xx**2 + 2 * phi_sigma_xy**2 + phi_sigma_yy**2)\n            measured_ratio_hess = get_rms(frob_norm_sigma) / get_rms(frob_norm) if get_rms(frob_norm) != 0 else 0\n\n        return measured_ratio_grad, measured_ratio_hess, phi_hat\n\n\n    # --- Simulation Parameters ---\n    N = 64\n    L = 1.0\n\n    # --- Grid and Wavenumber Setup ---\n    grid_coords = np.linspace(0, L, N, endpoint=False)\n    xx, yy = np.meshgrid(grid_coords, grid_coords, indexing='ij')\n\n    k_freq = np.fft.fftfreq(N, d=L / N)\n    kx_base = 2 * np.pi * k_freq\n    ky_base = 2 * np.pi * k_freq\n    kx, ky = np.meshgrid(kx_base, ky_base, indexing='ij')\n    k_sq = kx**2 + ky**2\n\n    # --- Test Suite ---\n    test_cases = [\n        # Test 1: single mode, baseline attenuation\n        {'type': 'single_mode', 'A': 1.0, 'nx': 4, 'sigma': 0.05},\n        # Test 2: identity smoothing\n        {'type': 'single_mode', 'A': 1.0, 'nx': 4, 'sigma': 0.0},\n        # Test 3: higher frequency\n        {'type': 'single_mode', 'A': 1.0, 'nx': 8, 'sigma': 0.12},\n        # Test 4: two-mode superposition\n        {'type': 'two_mode', 'A1': 1.0, 'n1': 3, 'A2': 0.8, 'n2': 5, 'sigma': 0.07}\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Construct the field\n        if case['type'] == 'single_mode':\n            phi = case['A'] * np.cos(2 * np.pi * case['nx'] * xx)\n        else: # two_mode\n            phi = case['A1'] * np.cos(2 * np.pi * case['n1'] * xx) + \\\n                  case['A2'] * np.cos(2 * np.pi * case['n2'] * yy)\n        \n        # Run analysis\n        measured_grad_ratio, measured_hess_ratio, phi_hat = run_analysis(\n            phi, case['sigma'], kx, ky, k_sq, case['type']\n        )\n\n        # Compute predictions and relative errors\n        if case['type'] == 'single_mode':\n            sigma = case['sigma']\n            if sigma == 0.0:\n                pred_ratio_grad = 1.0\n                pred_ratio_hess = 1.0\n            else:\n                k0 = 2 * np.pi * case['nx']\n                pred_ratio = np.exp(-k0**2 * sigma**2 / 2.0)\n                pred_ratio_grad = pred_ratio\n                pred_ratio_hess = pred_ratio\n        else: # two_mode\n            sigma = case['sigma']\n            power_spectrum = np.abs(phi_hat)**2\n            \n            # Grad prediction\n            grad_numerator = np.sum(k_sq * power_spectrum * np.exp(-k_sq * sigma**2))\n            grad_denominator = np.sum(k_sq * power_spectrum)\n            pred_ratio_grad = np.sqrt(grad_numerator / grad_denominator) if grad_denominator != 0 else 0\n\n            # Hessian prediction\n            hess_numerator = np.sum(k_sq**2 * power_spectrum * np.exp(-k_sq * sigma**2))\n            hess_denominator = np.sum(k_sq**2 * power_spectrum)\n            pred_ratio_hess = np.sqrt(hess_numerator / hess_denominator) if hess_denominator != 0 else 0\n\n        # Relative errors\n        rel_err_grad = np.abs(measured_grad_ratio - pred_ratio_grad) / pred_ratio_grad\n        rel_err_hess = np.abs(measured_hess_ratio - pred_ratio_hess) / pred_ratio_hess\n        \n        results.extend([rel_err_grad, rel_err_hess])\n\n    # Final print statement\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```", "id": "3502022"}, {"introduction": "With the tools of field analysis established, we can now apply them to the practical task of identifying cosmic structures. This exercise delves into two distinct and widely used algorithms for finding cosmic voids: the Lagrangian-space ORIGAMI method, which classifies regions based on their deformation history and the absence of shell-crossing, and the Eulerian-space watershed algorithm, which partitions the final density field into basins around local minima. Implementing and comparing both will provide you with direct experience of different philosophical approaches to defining cosmic voids and a deeper appreciation for the complexities of cosmic web analysis. [@problem_id:3502019]", "problem": "You are given a synthetic three-dimensional particle distribution representing a single-time N-body snapshot in a periodic cubic box of side length $L$. The initial particle configuration is a uniform Lagrangian lattice of $N^3$ particles at positions $\\mathbf{q} \\in [0,L)^3$. The Eulerian positions $\\mathbf{x}$ are obtained by a first-order Lagrangian perturbation (the Zel'dovich approximation), $\\mathbf{x}(\\mathbf{q}) = \\mathbf{q} + \\mathbf{s}(\\mathbf{q})$, where the displacement field $\\mathbf{s}(\\mathbf{q}) = -D \\nabla \\phi(\\mathbf{q})$ is derived from a random Gaussian potential $\\phi$ smoothed by a Gaussian kernel of scale $R_s$. Assume periodic boundary conditions at all times.\n\nYour task is to implement, from first principles, two void-finding measures and compare them:\n\n1. Lagrangian void classification using Order-ReversIng Galaxy Morphology Identification (ORIGAMI), defined as follows. For each principal axis $\\alpha \\in \\{x,y,z\\}$, consider one-dimensional lines of particles parallel to $\\alpha$ at fixed orthogonal coordinates. A particle is said to have undergone shell-crossing along axis $\\alpha$ if, along its line, the sequence of Eulerian coordinates along $\\alpha$ is not strictly increasing when the particles are ordered by their initial Lagrangian coordinate along $\\alpha$. For the purpose of this problem, detect shell-crossing along $\\alpha$ by finding adjacent pairs on each line where the discrete difference of Eulerian coordinates is negative. Classify a particle as a Lagrangian void particle if it has zero detected shell-crossings across all three axes. The Lagrangian void fraction is the fraction of particles classified as void (dimensionless decimal in $[0,1]$).\n\n2. Eulerian watershed void volume computed on a density field obtained via Cloud-in-Cell (CIC) mass assignment. Construct the Eulerian density $\\rho(\\mathbf{x})$ on an $N^3$ grid by depositing particle masses with CIC weights. Define the density contrast $\\delta(\\mathbf{x}) = \\rho(\\mathbf{x})/\\bar{\\rho} - 1$, where $\\bar{\\rho}$ is the mean density. Identify local minima of $\\rho$ using six-neighbor (face-adjacent) comparisons under periodic boundary conditions. Perform a discrete watershed segmentation by assigning each grid cell to a basin via steepest descent: iteratively move from each cell to its lowest-density neighbor among the six face neighbors if that neighbor has strictly lower density; if no strictly lower neighbor exists, the cell is the sink (a local minimum or plateau minimum). Label basins by the index of their sink cell. Define the Eulerian watershed void volume fraction as the fraction of grid cells whose basin sink density contrast $\\delta_{\\mathrm{sink}}$ is less than a specified threshold $\\delta_v$ (dimensionless decimal), i.e., basins seeded by sufficiently underdense minima.\n\nThe fundamental base and assumptions you must use are:\n\n- First-order Lagrangian perturbation (Zel'dovich approximation): $\\mathbf{x}(\\mathbf{q}) = \\mathbf{q} - D \\nabla \\phi(\\mathbf{q})$ for some scalar growth amplitude $D$.\n- Periodic boundary conditions on the cubic domain.\n- Mass conservation and Cloud-in-Cell (CIC) deposition: each particle of equal mass contributes to the eight surrounding grid vertices with trilinear weights based on its fractional offset within the grid cell.\n- Definition of density contrast: $\\delta(\\mathbf{x}) = \\rho(\\mathbf{x})/\\bar{\\rho} - 1$.\n\nYou must generate the Gaussian potential $\\phi$ by drawing a real-space Gaussian random field and applying Fourier-space Gaussian smoothing with scale $R_s$. The displacement amplitude is set by a parameter $A$ that multiplies the gradient of the smoothed potential, i.e., $\\mathbf{s} = -A \\nabla \\phi$. Use periodic Fourier wavenumbers $\\mathbf{k} = (k_x,k_y,k_z)$ with $k_\\alpha = 2\\pi n_\\alpha / L$ for integer $n_\\alpha$ consistent with the discrete Fourier transform on the $N^3$ grid.\n\nImplementation details and constraints:\n\n- Use a reproducible random number seed per test case when generating $\\phi$.\n- Enforce periodic boundary conditions by wrapping particle positions into $[0,L)$ along each axis.\n- For ORIGAMI shell-crossing detection along each axis, operate line-by-line along the lattice and mark both particles in any adjacent pair where the Eulerian coordinate difference along that axis is negative. Count, per particle, the number of axes with at least one detected adjacent-pair inversion; Lagrangian void particles have count zero.\n- For the watershed, use six face neighbors. If the field is completely flat such that strict minima do not exist, treat any cell with no strictly lower neighbor as a sink (plateau minimum), and proceed accordingly.\n\nYour program must process the following test suite, where $N$ is the grid resolution per dimension, $L$ is the box size (units of comoving $h^{-1}\\,\\mathrm{Mpc}$; no unit should be printed), $A$ is the displacement amplitude, $R_s$ is the Gaussian smoothing scale in the same physical units as $L$, $\\delta_v$ is the watershed void threshold on the sink density contrast, and $\\mathrm{seed}$ is the pseudorandom seed:\n\n- Test case 1 (happy path, weakly nonlinear): $(N,L,A,R_s,\\delta_v,\\mathrm{seed}) = (16,100.0,0.5,5.0,-0.5,42)$.\n- Test case 2 (moderate nonlinearity): $(16,100.0,1.5,3.0,-0.3,123)$.\n- Test case 3 (stronger nonlinearity): $(16,100.0,3.0,2.0,0.0,7)$.\n- Test case 4 (edge threshold high, small grid): $(8,100.0,0.1,2.0,0.5,31415)$.\n\nFor each test case, compute and return three quantities:\n\n- The Lagrangian void fraction $f_{\\mathrm{L}}$ (decimal).\n- The Eulerian watershed void volume fraction $f_{\\mathrm{E}}$ (decimal).\n- The absolute mismatch $m = |f_{\\mathrm{E}} - f_{\\mathrm{L}}|$ (decimal).\n\nYour program should produce a single line of output containing the results as a comma-separated list of lists, one per test case, each inner list ordered as $[f_{\\mathrm{L}},f_{\\mathrm{E}},m]$ and expressed as decimal floats. For example, a valid output format is like `[[0.9,0.6,0.3],[...],...]`. No other text should be printed.\n\nNote: All requested quantities are dimensionless decimals. Angles are not used. Percentages must be expressed as decimals, not with a percentage sign.", "solution": "The problem requires the implementation and comparison of two distinct void-finding algorithms on a synthetic cosmological particle distribution. The particle positions are generated using the Zel'dovich approximation, a first-order Lagrangian perturbation theory model. The analysis will proceed in three main stages: first, generating the particle snapshot; second, applying the Lagrangian-space ORIGAMI classification; and third, applying the Eulerian-space watershed algorithm.\n\n### I. Generation of the Particle Distribution\n\nThe initial state of the universe is modeled as a uniform cubic lattice of $N^3$ particles, with initial (Lagrangian) positions $\\mathbf{q}$. The grid spacing is $\\Delta q = L/N$, and the position of a particle indexed by $(i,j,k)$ is $\\mathbf{q}_{ijk} = ((i+0.5)\\Delta q, (j+0.5)\\Delta q, (k+0.5)\\Delta q)$ for $i,j,k \\in \\{0, 1, ..., N-1\\}$.\n\nThe evolution from Lagrangian positions $\\mathbf{q}$ to final (Eulerian) positions $\\mathbf{x}$ is described by the Zel'dovich approximation:\n$$\n\\mathbf{x}(\\mathbf{q}) = \\mathbf{q} + \\mathbf{s}(\\mathbf{q})\n$$\nwhere $\\mathbf{s}(\\mathbf{q})$ is the displacement field. The displacement field is derived from the gradient of a scalar potential $\\phi(\\mathbf{q})$, scaled by an amplitude parameter $A$:\n$$\n\\mathbf{s}(\\mathbf{q}) = -A \\nabla \\phi(\\mathbf{q})\n$$\nThe potential $\\phi(\\mathbf{q})$ is a spatially random Gaussian field, smoothed at a characteristic scale $R_s$. This field is generated computationally in Fourier space.\n\n1.  **Fourier Space Grid**: We define a grid of wavevectors $\\mathbf{k} = (k_x, k_y, k_z)$ corresponding to the discrete Fourier modes of the $N^3$ lattice. The components are given by $k_\\alpha = 2\\pi n_\\alpha/L$, where $n_\\alpha$ are integers ranging from $-N/2$ to $N/2-1$.\n\n2.  **Generating the Potential**: An unsmoothed potential is first generated by creating a grid of white noise in real space and performing a Fast Fourier Transform (FFT). Let this be $\\hat{\\phi}_{\\text{raw}}(\\mathbf{k})$. This procedure ensures that the reality condition $\\hat{\\phi}(\\mathbf{k}) = \\hat{\\phi}^*(-\\mathbf{k})$ is satisfied, such that its inverse transform is a real-valued field.\n\n3.  **Smoothing**: The field is smoothed by multiplication in Fourier space with a Gaussian filter, $W(|\\mathbf{k}|) = \\exp(-|\\mathbf{k}|^2 R_s^2 / 2)$.\n    $$\n    \\hat{\\phi}(\\mathbf{k}) = \\hat{\\phi}_{\\text{raw}}(\\mathbf{k}) W(|\\mathbf{k}|)\n    $$\n    The DC component $\\hat{\\phi}(\\mathbf{k}=\\mathbf{0})$ is set to zero to ensure the mean displacement is null.\n\n4.  **Calculating Displacement**: The gradient operator $\\nabla$ in real space corresponds to multiplication by $i\\mathbf{k}$ in Fourier space. Thus, the Fourier transform of the displacement field is:\n    $$\n    \\hat{\\mathbf{s}}(\\mathbf{k}) = -A (i\\mathbf{k}) \\hat{\\phi}(\\mathbf{k})\n    $$\n    An inverse FFT is then applied to each component of $\\hat{\\mathbf{s}}(\\mathbf{k})$ to obtain the real-space displacement field $\\mathbf{s}(\\mathbf{q})$ on the Lagrangian grid.\n\n5.  **Final Positions**: The Eulerian positions are computed as $\\mathbf{x} = \\mathbf{q} + \\mathbf{s}$ and folded back into the periodic box of side length $L$ using the modulo operator: $x_\\alpha' = x_\\alpha \\pmod L$.\n\n### II. Lagrangian Void Fraction ($f_L$) via ORIGAMI\n\nThe ORIGAMI method classifies regions of the cosmic web based on the deformation of the initial Lagrangian lattice. A void region is one that has expanded but has not undergone shell-crossing (where different streams of matter intersect).\n\n1.  **Shell-Crossing Detection**: We assess shell-crossing independently along each principal axis $\\alpha \\in \\{x,y,z\\}$. For a given axis, we consider the $N^2$ one-dimensional lines of particles that were initially aligned with that axis. For each line, the particles are ordered by their initial Lagrangian coordinate, e.g., $q_x$. If the structure has not shell-crossed along this axis, the corresponding Eulerian coordinates $x_x$ should also be monotonically increasing. A shell-crossing is detected if this order is inverted for any pair of adjacent particles on the line.\n    Specifically, for a line of particles $p_0, p_1, \\ldots, p_{N-1}$ ordered by their initial $q_\\alpha$ coordinates, we detect a crossing if $x_\\alpha(p_{i+1})  x_\\alpha(p_i)$ for any $i \\in \\{0, \\ldots, N-2\\}$.\n\n2.  **Particle Classification**: According to the problem's prescription, if such an order inversion occurs between particles $p_i$ and $p_{i+1}$, both particles are marked as having shell-crossed along axis $\\alpha$. This process is repeated for every line and every axis. A per-particle count, $C_{sc}$, is maintained, which tracks the number of axes along which a particle has been marked for shell-crossing.\n\n3.  **Void Fraction Calculation**: A particle is classified as a \"Lagrangian void particle\" if it has not been involved in any shell-crossing events along any of the three axes, i.e., if its shell-crossing axis count is $C_{sc}=0$. The Lagrangian void fraction, $f_L$, is the total number of void particles divided by the total number of particles, $N^3$.\n    $$\n    f_L = \\frac{\\text{Number of particles with } C_{sc}=0}{N^3}\n    $$\n\n### III. Eulerian Watershed Void Volume Fraction ($f_E$)\n\nThis method identifies voids as underdense basins in the Eulerian density field.\n\n1.  **Density Field Construction**: The continuous density field is discretized onto an $N^3$ grid. The mass of the particles is assigned to the grid points using the Cloud-in-Cell (CIC) scheme. For each particle, its mass (taken as $m_p=1$) is distributed to the $8$ surrounding grid vertices using trilinear interpolation weights based on its sub-grid position. Summing the contributions from all $N^3$ particles yields a gridded mass field, which we denote $\\rho_{\\text{grid}}$.\n\n2.  **Density Contrast**: The density contrast, $\\delta$, is defined as $\\delta(\\mathbf{x}) = \\rho(\\mathbf{x})/\\bar{\\rho} - 1$. With our choice of $m_p=1$ for $N^3$ particles in an $N^3$ grid, the mean mass per grid cell is $\\bar{m}=1$. The density contrast can thus be computed directly from the gridded mass as $\\delta = \\rho_{\\text{grid}} - 1$.\n\n3.  **Watershed Segmentation**: The watershed algorithm partitions the grid into basins associated with local density minima.\n    -   **Sinks**: A sink is a grid cell that has no face-adjacent neighbor with a strictly lower density. Sinks correspond to local minima or the minima of plateau regions.\n    -   **Steepest Descent**: For each grid cell, a path of steepest descent is traced by iteratively moving to the lowest-density neighbor, until a sink is reached.\n    -   **Basin Assignment**: Every cell in the grid is assigned to the basin of the sink where its descent path terminates. This creates a `basin_map` where each cell is labeled by the index of its corresponding sink.\n\n4.  **Void Volume Fraction**: A basin is classified as a void if its sink has a density contrast $\\delta_{\\text{sink}}$ below a given threshold $\\delta_v$. The Eulerian void volume fraction, $f_E$, is the fraction of grid cells that belong to these void basins.\n    $$\n    f_E = \\frac{\\text{Number of grid cells in basins with } \\delta_{\\text{sink}}  \\delta_v}{N^3}\n    $$\n\nFinally, the absolute mismatch between the two measures is calculated as $m = |f_E - f_L|$.", "answer": "```python\nimport numpy as np\n\ndef generate_displacement_field(N, L, A, Rs, seed):\n    \"\"\"\n    Generates a 3D displacement field using the Zel'dovich approximation.\n    \"\"\"\n    np.random.seed(seed)\n\n    # 1. Generate Gaussian random potential in Fourier space\n    # Generate real-space white noise and FFT to get a k-space field\n    # that satisfies the reality condition.\n    noise = np.random.randn(N, N, N)\n    phi_k = np.fft.fftn(noise)\n\n    # 2. Define k-space grid and apply smoothing\n    k_vec = 2 * np.pi * np.fft.fftfreq(N, d=L / N)\n    kx, ky, kz = np.meshgrid(k_vec, k_vec, k_vec, indexing='ij')\n    ksq = kx**2 + ky**2 + kz**2\n    ksq[0, 0, 0] = 1.0  # Avoid division by zero, will be set to 0 later\n    \n    smoothing_filter = np.exp(-ksq * Rs**2 / 2.0)\n    phi_k_smoothed = phi_k * smoothing_filter\n    phi_k_smoothed[0, 0, 0] = 0.0  # Set DC mode to zero\n\n    # 3. Calculate gradient in k-space and transform back\n    grad_phi_x_k = 1j * kx * phi_k_smoothed\n    grad_phi_y_k = 1j * ky * phi_k_smoothed\n    grad_phi_z_k = 1j * kz * phi_k_smoothed\n\n    s_x = np.real(np.fft.ifftn(grad_phi_x_k))\n    s_y = np.real(np.fft.ifftn(grad_phi_y_k))\n    s_z = np.real(np.fft.ifftn(grad_phi_z_k))\n\n    # Displacement field s = -A * grad(phi)\n    return -A * s_x, -A * s_y, -A * s_z\n\ndef compute_lagrangian_void_fraction(x, y, z, N):\n    \"\"\"\n    Computes Lagrangian void fraction using the ORIGAMI method.\n    \"\"\"\n    # sc_on_axis[i,j,k,ax] is True if particle (i,j,k) shell-crossed on axis ax\n    sc_on_axis = np.zeros((N, N, N, 3), dtype=bool)\n\n    # Axis 0 (x)\n    diffs_x = np.diff(x, axis=0)  0\n    sc_on_axis[:-1, :, :, 0] |= diffs_x\n    sc_on_axis[1:, :, :, 0] |= diffs_x\n\n    # Axis 1 (y)\n    diffs_y = np.diff(y, axis=1)  0\n    sc_on_axis[:, :-1, :, 1] |= diffs_y\n    sc_on_axis[:, 1:, :, 1] |= diffs_y\n\n    # Axis 2 (z)\n    diffs_z = np.diff(z, axis=2)  0\n    sc_on_axis[:, :, :-1, 2] |= diffs_z\n    sc_on_axis[:, :, 1:, 2] |= diffs_z\n\n    # Count number of axes with shell-crossing for each particle\n    num_crossed_axes = np.sum(sc_on_axis, axis=3)\n    \n    # Void particles are those with zero shell-crossed axes\n    num_void_particles = np.sum(num_crossed_axes == 0)\n    \n    return num_void_particles / (N**3)\n\ndef compute_eulerian_void_fraction(x_p, y_p, z_p, N, L, delta_v):\n    \"\"\"\n    Computes Eulerian void fraction using a watershed algorithm on a CIC density field.\n    \"\"\"\n    # 1. CIC mass assignment\n    rho_grid = np.zeros((N, N, N), dtype=np.float64)\n    dx = L / N\n    num_particles = N**3\n    \n    # Flatten particle positions\n    x_flat, y_flat, z_flat = x_p.flatten(), y_p.flatten(), z_p.flatten()\n\n    # Normalized coordinates\n    px_norm = x_flat / dx\n    py_norm = y_flat / dx\n    pz_norm = z_flat / dx\n    \n    i = np.floor(px_norm).astype(int)\n    j = np.floor(py_norm).astype(int)\n    k = np.floor(pz_norm).astype(int)\n    \n    tx = px_norm - i\n    ty = py_norm - j\n    tz = pz_norm - k\n    \n    # Ensure indices are within [0, N-1] after flooring (due to modulo op)\n    i = i % N\n    j = j % N\n    k = k % N\n    \n    i_plus_1 = (i + 1) % N\n    j_plus_1 = (j + 1) % N\n    k_plus_1 = (k + 1) % N\n\n    # Trilinear weights\n    wx = [1 - tx, tx]\n    wy = [1 - ty, ty]\n    wz = [1 - tz, tz]\n\n    indices_i = [i, i_plus_1]\n    indices_j = [j, j_plus_1]\n    indices_k = [k, k_plus_1]\n    \n    # Add mass contributions\n    for a in range(2):\n        for b in range(2):\n            for c in range(2):\n                weight = wx[a] * wy[b] * wz[c]\n                np.add.at(rho_grid, (indices_i[a], indices_j[b], indices_k[c]), weight)\n\n    # 2. Density contrast\n    delta = rho_grid - 1.0\n    delta_flat = delta.flatten()\n\n    # 3. Watershed segmentation\n    basin_map = -np.ones(N**3, dtype=int)\n    coords = np.indices((N, N, N))\n    indices_flat = np.arange(N**3).reshape(N,N,N)\n\n    for idx in range(N**3):\n        if basin_map[idx] != -1:\n            continue\n            \n        path = []\n        curr_idx = idx\n        \n        while basin_map[curr_idx] == -1:\n            path.append(curr_idx)\n            i, j, k = np.unravel_index(curr_idx, (N, N, N))\n            \n            neighbors_indices = []\n            neighbors_deltas = []\n\n            for di, dj, dk in [(1,0,0), (-1,0,0), (0,1,0), (0,-1,0), (0,0,1), (0,0,-1)]:\n                ni, nj, nk = (i + di) % N, (j + dj) % N, (k + dk) % N\n                neighbors_indices.append(indices_flat[ni, nj, nk])\n                neighbors_deltas.append(delta[ni, nj, nk])\n\n            min_delta_neighbor = min(neighbors_deltas)\n            \n            if min_delta_neighbor  delta_flat[curr_idx]:\n                min_neighbor_idx = neighbors_indices[np.argmin(neighbors_deltas)]\n                curr_idx = min_neighbor_idx\n            else:\n                # Current cell is a sink\n                basin_map[curr_idx] = curr_idx\n                break\n        \n        sink_idx = basin_map[curr_idx]\n        for node_idx in path:\n            basin_map[node_idx] = sink_idx\n\n    # 4. Compute void fraction\n    unique_sinks = np.unique(basin_map)\n    sink_deltas = delta_flat[unique_sinks]\n    \n    void_sinks = unique_sinks[sink_deltas  delta_v]\n    \n    is_in_void_basin = np.isin(basin_map, void_sinks)\n    f_E = np.sum(is_in_void_basin) / (N**3)\n    \n    return f_E\n\ndef solve():\n    test_cases = [\n        (16, 100.0, 0.5, 5.0, -0.5, 42),\n        (16, 100.0, 1.5, 3.0, -0.3, 123),\n        (16, 100.0, 3.0, 2.0, 0.0, 7),\n        (8, 100.0, 0.1, 2.0, 0.5, 31415),\n    ]\n\n    results = []\n    for N, L, A, Rs, delta_v, seed in test_cases:\n        # Generate initial Lagrangian grid\n        grid_1d = (np.arange(N) + 0.5) * L / N\n        q_x, q_y, q_z = np.meshgrid(grid_1d, grid_1d, grid_1d, indexing='ij')\n\n        # Generate displacement field\n        s_x, s_y, s_z = generate_displacement_field(N, L, A, Rs, seed)\n        \n        # Calculate Eulerian positions\n        x = (q_x + s_x) % L\n        y = (q_y + s_y) % L\n        z = (q_z + s_z) % L\n\n        # Calculate Lagrangian void fraction\n        f_L = compute_lagrangian_void_fraction(x, y, z, N)\n\n        # Calculate Eulerian void fraction\n        f_E = compute_eulerian_void_fraction(x, y, z, N, L, delta_v)\n        \n        # Calculate mismatch\n        m = abs(f_E - f_L)\n        \n        results.append([f_L, f_E, m])\n    \n    # Print results in the required format\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3502019"}, {"introduction": "Any measurement derived from observational data, such as a galaxy survey, is inevitably affected by noise. This final practice shifts our focus from algorithm implementation to error analysis, a critical step in assessing the reliability of any scientific result. You will derive from first principles how Poisson shot noise—an unavoidable consequence of using discrete tracers to sample a continuous field—propagates through a finite-difference Hessian calculation, thereby quantifying the uncertainty it induces on the eigenvalues used for cosmic web classification. [@problem_id:3502070]", "problem": "In the context of classifying the cosmic web via the eigenvalues of the Hessian of the mass overdensity field, consider a counts-in-cells estimate of the dimensionless overdensity field sampled by discrete tracers with homogeneous mean number density $\\bar{n}$. The survey volume is discretized on a uniform cubic grid with spacing $h$, so that each voxel has volume $h^{3}$. Let $N_{\\boldsymbol{i}}$ denote the count of tracers in the voxel centered at grid index $\\boldsymbol{i}$, with $N_{\\boldsymbol{i}} \\sim \\mathrm{Poisson}(\\bar{n} h^{3})$, independently across voxels. Define the overdensity estimator in voxel $\\boldsymbol{i}$ by $\\delta_{\\boldsymbol{i}} \\equiv \\left(N_{\\boldsymbol{i}} - \\bar{n} h^{3}\\right)/\\left(\\bar{n} h^{3}\\right)$.\n\nAt a fixed grid location $\\boldsymbol{i}_{0}$, the Hessian of $\\delta$ is estimated using second-order central finite differences:\n- For diagonal second derivatives,\n$$\n\\widehat{H}_{xx} \\equiv \\frac{\\delta_{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{x}}}-2\\,\\delta_{\\boldsymbol{i}_{0}}+\\delta_{\\boldsymbol{i}_{0}-\\hat{\\boldsymbol{x}}}}{h^{2}},\\quad\n\\widehat{H}_{yy} \\equiv \\frac{\\delta_{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{y}}}-2\\,\\delta_{\\boldsymbol{i}_{0}}+\\delta_{\\boldsymbol{i}_{0}-\\hat{\\boldsymbol{y}}}}{h^{2}},\\quad\n\\widehat{H}_{zz} \\equiv \\frac{\\delta_{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{z}}}-2\\,\\delta_{\\boldsymbol{i}_{0}}+\\delta_{\\boldsymbol{i}_{0}-\\hat{\\boldsymbol{z}}}}{h^{2}}.\n$$\n- For off-diagonal mixed second derivatives,\n$$\n\\widehat{H}_{xy} \\equiv \\frac{\\delta_{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{x}}+\\hat{\\boldsymbol{y}}}-\\delta_{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{x}}-\\hat{\\boldsymbol{y}}}-\\delta_{\\boldsymbol{i}_{0}-\\hat{\\boldsymbol{x}}+\\hat{\\boldsymbol{y}}}+\\delta_{\\boldsymbol{i}_{0}-\\hat{\\boldsymbol{x}}-\\hat{\\boldsymbol{y}}}}{4 h^{2}},\n$$\nwith analogous definitions for $\\widehat{H}_{xz}$ and $\\widehat{H}_{yz}$ via cyclic permutations of coordinates. Here $\\hat{\\boldsymbol{x}},\\hat{\\boldsymbol{y}},\\hat{\\boldsymbol{z}}$ denote unit index displacements by one voxel along the corresponding axes.\n\nAssume that shot noise is the only source of uncertainty, that distinct voxel overdensity estimates $\\delta_{\\boldsymbol{i}}$ are statistically independent with zero mean, and that the true underlying Hessian at $\\boldsymbol{i}_{0}$ is diagonal with non-degenerate eigenvalues $\\lambda_{1}^{(0)}\\lambda_{2}^{(0)}\\lambda_{3}^{(0)}$ whose orthonormal eigenvectors coincide with the grid axes $\\{\\hat{\\boldsymbol{x}},\\hat{\\boldsymbol{y}},\\hat{\\boldsymbol{z}}\\}$.\n\nTasks:\n- Starting from the Poisson statistics of $N_{\\boldsymbol{i}}$ and the above finite-difference operators, derive the covariance of the Hessian component estimators $\\widehat{H}_{ab}$ at $\\boldsymbol{i}_{0}$ that arises purely from shot noise, expressing your results in terms of $\\bar{n}$ and $h$.\n- Using first-order perturbation theory for symmetric matrices with non-degenerate eigenvalues, propagate this covariance to obtain the variance of the estimator of the smallest eigenvalue, $\\widehat{\\lambda}_{1}$, induced by shot noise under the stated alignment assumption.\n\nProvide your final answer as a single closed-form analytic expression for $\\mathrm{Var}(\\widehat{\\lambda}_{1})$ in terms of $\\bar{n}$ and $h$. No rounding is required. Do not include units in your final boxed answer.", "solution": "The problem statement has been validated and is deemed valid. It is scientifically grounded in the methods of numerical cosmology, well-posed, objective, and internally consistent. We may proceed with the solution.\n\nThe solution is developed in two primary stages as requested by the problem statement. First, we derive the covariance matrix for the components of the Hessian estimator, arising from Poisson shot noise. Second, we use first-order perturbation theory to propagate this uncertainty to determine the variance of the estimator for the smallest eigenvalue.\n\n**Part 1: Covariance of the Hessian Component Estimators**\n\nThe fundamental source of noise is the Poissonian nature of the tracer counts $N_{\\boldsymbol{i}}$ in each voxel. The overdensity estimator in voxel $\\boldsymbol{i}$ is given by $\\delta_{\\boldsymbol{i}} \\equiv \\left(N_{\\boldsymbol{i}} - \\bar{n} h^{3}\\right)/\\left(\\bar{n} h^{3}\\right)$. Let $\\mu \\equiv \\bar{n} h^{3}$ be the mean number of tracers per voxel. We have $N_{\\boldsymbol{i}} \\sim \\mathrm{Poisson}(\\mu)$.\n\nThe expected value and variance of $N_{\\boldsymbol{i}}$ are $\\mathrm{E}[N_{\\boldsymbol{i}}] = \\mu$ and $\\mathrm{Var}(N_{\\boldsymbol{i}}) = \\mu$.\nThe expected value of the overdensity estimator is $\\mathrm{E}[\\delta_{\\boldsymbol{i}}] = \\mathrm{E}[N_{\\boldsymbol{i}}/\\mu - 1] = \\mathrm{E}[N_{\\boldsymbol{i}}]/\\mu - 1 = \\mu/\\mu - 1 = 0$. This confirms the statement that $\\delta_{\\boldsymbol{i}}$ has zero mean.\nThe variance of the overdensity estimator is $\\mathrm{Var}(\\delta_{\\boldsymbol{i}}) = \\mathrm{Var}(N_{\\boldsymbol{i}}/\\mu - 1) = \\mathrm{Var}(N_{\\boldsymbol{i}}/\\mu) = \\frac{1}{\\mu^{2}}\\mathrm{Var}(N_{\\boldsymbol{i}}) = \\frac{\\mu}{\\mu^{2}} = \\frac{1}{\\mu}$.\nSubstituting $\\mu = \\bar{n} h^{3}$, we get the variance of the overdensity in a single voxel:\n$$\n\\sigma_{\\delta}^{2} \\equiv \\mathrm{Var}(\\delta_{\\boldsymbol{i}}) = \\frac{1}{\\bar{n} h^{3}}\n$$\nThe problem states that the voxel counts $N_{\\boldsymbol{i}}$, and therefore the overdensity estimates $\\delta_{\\boldsymbol{i}}$, are statistically independent for distinct voxels $\\boldsymbol{i} \\neq \\boldsymbol{j}$. Thus, their covariance is:\n$$\n\\mathrm{Cov}(\\delta_{\\boldsymbol{i}}, \\delta_{\\boldsymbol{j}}) = \\sigma_{\\delta}^{2} \\delta_{\\boldsymbol{i}\\boldsymbol{j}}^{\\text{Kronecker}}\n$$\nwhere $\\delta_{\\boldsymbol{i}\\boldsymbol{j}}^{\\text{Kronecker}}$ is the Kronecker delta, equal to $1$ if $\\boldsymbol{i}=\\boldsymbol{j}$ and $0$ otherwise.\n\nThe Hessian estimators $\\widehat{H}_{ab}$ are linear combinations of the $\\delta_{\\boldsymbol{i}}$ values. For any two such estimators, $\\widehat{H}_{ab} = \\sum_{\\boldsymbol{i}} c_{\\boldsymbol{i}}^{(ab)} \\delta_{\\boldsymbol{i}}$ and $\\widehat{H}_{cd} = \\sum_{\\boldsymbol{j}} c_{\\boldsymbol{j}}^{(cd)} \\delta_{\\boldsymbol{j}}$, their covariance is given by:\n$$\n\\mathrm{Cov}(\\widehat{H}_{ab}, \\widehat{H}_{cd}) = \\mathrm{Cov}\\left(\\sum_{\\boldsymbol{i}} c_{\\boldsymbol{i}}^{(ab)} \\delta_{\\boldsymbol{i}}, \\sum_{\\boldsymbol{j}} c_{\\boldsymbol{j}}^{(cd)} \\delta_{\\boldsymbol{j}}\\right) = \\sum_{\\boldsymbol{i},\\boldsymbol{j}} c_{\\boldsymbol{i}}^{(ab)} c_{\\boldsymbol{j}}^{(cd)} \\mathrm{Cov}(\\delta_{\\boldsymbol{i}}, \\delta_{\\boldsymbol{j}}) = \\sigma_{\\delta}^{2} \\sum_{\\boldsymbol{k}} c_{\\boldsymbol{k}}^{(ab)} c_{\\boldsymbol{k}}^{(cd)}\n$$\nwhere the last sum is over all voxels $\\boldsymbol{k}$ where the product of coefficients is non-zero.\n\nLet's apply this formula to calculate the required covariances.\n\nVariance of a diagonal component, e.g., $\\mathrm{Var}(\\widehat{H}_{xx})$:\nThe estimator is $\\widehat{H}_{xx} = \\frac{1}{h^{2}}(\\delta_{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{x}}} - 2\\delta_{\\boldsymbol{i}_{0}} + \\delta_{\\boldsymbol{i}_{0}-\\hat{\\boldsymbol{x}}})$. The involved voxels are distinct.\n$$\n\\mathrm{Var}(\\widehat{H}_{xx}) = \\sigma_{\\delta}^{2} \\left[ \\left(\\frac{1}{h^{2}}\\right)^{2} + \\left(\\frac{-2}{h^{2}}\\right)^{2} + \\left(\\frac{1}{h^{2}}\\right)^{2} \\right] = \\sigma_{\\delta}^{2} \\frac{1^{2} + (-2)^{2} + 1^{2}}{h^{4}} = \\frac{6\\sigma_{\\delta}^{2}}{h^{4}} = \\frac{6}{\\bar{n} h^{7}}\n$$\nBy symmetry, $\\mathrm{Var}(\\widehat{H}_{yy}) = \\mathrm{Var}(\\widehat{H}_{zz}) = \\frac{6}{\\bar{n} h^{7}}$.\n\nVariance of an off-diagonal component, e.g., $\\mathrm{Var}(\\widehat{H}_{xy})$:\nThe estimator is $\\widehat{H}_{xy} = \\frac{1}{4h^{2}}(\\delta_{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{x}}+\\hat{\\boldsymbol{y}}} - \\delta_{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{x}}-\\hat{\\boldsymbol{y}}} - \\delta_{\\boldsymbol{i}_{0}-\\hat{\\boldsymbol{x}}+\\hat{\\boldsymbol{y}}} + \\delta_{\\boldsymbol{i}_{0}-\\hat{\\boldsymbol{x}}-\\hat{\\boldsymbol{y}}})$. The involved voxels are distinct.\n$$\n\\mathrm{Var}(\\widehat{H}_{xy}) = \\sigma_{\\delta}^{2} \\left(\\frac{1}{4h^{2}}\\right)^{2} \\left[ (1)^{2} + (-1)^{2} + (-1)^{2} + (1)^{2} \\right] = \\sigma_{\\delta}^{2} \\frac{4}{16h^{4}} = \\frac{\\sigma_{\\delta}^{2}}{4h^{4}} = \\frac{1}{4\\bar{n} h^{7}}\n$$\nBy symmetry, $\\mathrm{Var}(\\widehat{H}_{xz}) = \\mathrm{Var}(\\widehat{H}_{yz}) = \\frac{1}{4\\bar{n} h^{7}}$.\n\nCovariance between two distinct diagonal components, e.g., $\\mathrm{Cov}(\\widehat{H}_{xx}, \\widehat{H}_{yy})$:\nThe stencil for $\\widehat{H}_{xx}$ involves voxels $\\{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{x}}, \\boldsymbol{i}_{0}, \\boldsymbol{i}_{0}-\\hat{\\boldsymbol{x}}\\}$. The stencil for $\\widehat{H}_{yy}$ involves voxels $\\{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{y}}, \\boldsymbol{i}_{0}, \\boldsymbol{i}_{0}-\\hat{\\boldsymbol{y}}\\}$. The only common voxel is the central one, $\\boldsymbol{i}_{0}$. The coefficient for $\\delta_{\\boldsymbol{i}_{0}}$ is $-2/h^{2}$ in both estimators.\n$$\n\\mathrm{Cov}(\\widehat{H}_{xx}, \\widehat{H}_{yy}) = \\sigma_{\\delta}^{2} \\left( \\frac{-2}{h^{2}} \\right) \\left( \\frac{-2}{h^{2}} \\right) = \\frac{4\\sigma_{\\delta}^{2}}{h^{4}} = \\frac{4}{\\bar{n} h^{7}}\n$$\nBy symmetry, $\\mathrm{Cov}(\\widehat{H}_{xx}, \\widehat{H}_{zz}) = \\mathrm{Cov}(\\widehat{H}_{yy}, \\widehat{H}_{zz}) = \\frac{4}{\\bar{n} h^{7}}$.\n\nCovariance between a diagonal and an off-diagonal component, e.g., $\\mathrm{Cov}(\\widehat{H}_{xx}, \\widehat{H}_{xy})$:\nThe stencil for $\\widehat{H}_{xx}$ is $\\{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{x}}, \\boldsymbol{i}_{0}, \\boldsymbol{i}_{0}-\\hat{\\boldsymbol{x}}\\}$. The stencil for $\\widehat{H}_{xy}$ is $\\{\\boldsymbol{i}_{0}+\\hat{\\boldsymbol{x}}+\\hat{\\boldsymbol{y}}, \\boldsymbol{i}_{0}+\\hat{\\boldsymbol{x}}-\\hat{\\boldsymbol{y}}, \\boldsymbol{i}_{0}-\\hat{\\boldsymbol{x}}+\\hat{\\boldsymbol{y}}, \\boldsymbol{i}_{0}-\\hat{\\boldsymbol{x}}-\\hat{\\boldsymbol{y}}\\}$. These two sets of voxels are disjoint. Therefore, their covariance is zero.\n$$\n\\mathrm{Cov}(\\widehat{H}_{xx}, \\widehat{H}_{xy}) = 0\n$$\nBy symmetry, all covariances between diagonal and off-diagonal components are zero.\n\nCovariance between two distinct off-diagonal components, e.g., $\\mathrm{Cov}(\\widehat{H}_{xy}, \\widehat{H}_{xz})$:\nThe stencil for $\\widehat{H}_{xy}$ involves displacements in $\\hat{\\boldsymbol{x}}$ and $\\hat{\\boldsymbol{y}}$. The stencil for $\\widehat{H}_{xz}$ involves displacements in $\\hat{\\boldsymbol{x}}$ and $\\hat{\\boldsymbol{z}}$. These two sets of voxels are disjoint. Therefore, their covariance is zero.\n$$\n\\mathrm{Cov}(\\widehat{H}_{xy}, \\widehat{H}_{xz}) = 0\n$$\nBy symmetry, all covariances between distinct off-diagonal components are zero.\n\n**Part 2: Variance of the Smallest Eigenvalue Estimator**\n\nThe estimated Hessian matrix $\\widehat{H}$ can be written as the sum of the true Hessian $H^{(0)}$ and a noise perturbation matrix $\\Delta H$, so $\\widehat{H} = H^{(0)} + \\Delta H$. The expectation of the estimator is the true value, $\\mathrm{E}[\\widehat{H}] = H^{(0)}$, thus $\\mathrm{E}[\\Delta H] = 0$. The covariance matrix of the components of $\\Delta H$ is what we derived in Part 1.\n\nWe use first-order linear error propagation to find the variance of an eigenvalue. If a quantity of interest $\\lambda$ is a function of random variables $\\{X_k\\}$, its variance is approximately $\\mathrm{Var}(\\lambda) \\approx \\sum_{k,l} \\frac{\\partial \\lambda}{\\partial X_k} \\frac{\\partial \\lambda}{\\partial X_l} \\mathrm{Cov}(X_k, X_l)$. Here, $\\lambda$ is one of the eigenvalues of $\\widehat{H}$, and the variables $X_k$ are the components $\\widehat{H}_{ab}$.\n\nThe derivative of an eigenvalue $\\lambda_k$ of a symmetric matrix $H$ with respect to its component $H_{ab}$ is given by $\\frac{\\partial \\lambda_k}{\\partial H_{ab}} = (2-\\delta_{ab}^{\\text{Kronecker}}) v_{ka} v_{kb}$, where $\\boldsymbol{v}_k$ is the normalized eigenvector corresponding to $\\lambda_k$, and its components are $v_{ka}, v_{kb}$.\n\nThe problem states that the true Hessian $H^{(0)}$ is diagonal in the grid basis, and its eigenvectors coincide with the axes $\\{\\hat{\\boldsymbol{x}},\\hat{\\boldsymbol{y}},\\hat{\\boldsymbol{z}}\\}$. Let's order the axes such that the eigenvector corresponding to the smallest eigenvalue $\\lambda_{1}^{(0)}$ is $\\boldsymbol{v}_{1}^{(0)} = \\hat{\\boldsymbol{x}} = (1, 0, 0)^T$. The components are $v_{1x}=1$, $v_{1y}=0$, $v_{1z}=0$.\n\nWe evaluate the partial derivatives at the true (unperturbed) values:\n$$\n\\frac{\\partial \\lambda_1}{\\partial \\widehat{H}_{xx}} = (2-1)v_{1x}v_{1x} = 1 \\cdot 1 \\cdot 1 = 1\n$$\n$$\n\\frac{\\partial \\lambda_1}{\\partial \\widehat{H}_{yy}} = (2-1)v_{1y}v_{1y} = 1 \\cdot 0 \\cdot 0 = 0\n$$\n$$\n\\frac{\\partial \\lambda_1}{\\partial \\widehat{H}_{zz}} = (2-1)v_{1z}v_{1z} = 1 \\cdot 0 \\cdot 0 = 0\n$$\n$$\n\\frac{\\partial \\lambda_1}{\\partial \\widehat{H}_{xy}} = (2-0)v_{1x}v_{1y} = 2 \\cdot 1 \\cdot 0 = 0\n$$\nSimilarly, all other derivatives with respect to off-diagonal components are zero.\n\nThe only non-zero derivative is $\\frac{\\partial \\lambda_1}{\\partial \\widehat{H}_{xx}} = 1$. The propagation of variance formula then simplifies dramatically:\n$$\n\\mathrm{Var}(\\widehat{\\lambda}_1) \\approx \\sum_{ab,cd} \\left(\\frac{\\partial \\lambda_1}{\\partial \\widehat{H}_{ab}}\\right) \\left(\\frac{\\partial \\lambda_1}{\\partial \\widehat{H}_{cd}}\\right) \\mathrm{Cov}(\\widehat{H}_{ab}, \\widehat{H}_{cd})\n= \\left(\\frac{\\partial \\lambda_1}{\\partial \\widehat{H}_{xx}}\\right)^{2} \\mathrm{Var}(\\widehat{H}_{xx})\n$$\n$$\n\\mathrm{Var}(\\widehat{\\lambda}_1) \\approx (1)^{2} \\cdot \\mathrm{Var}(\\widehat{H}_{xx}) = \\mathrm{Var}(\\widehat{H}_{xx})\n$$\nThis result is consistent with first-order matrix perturbation theory. The first-order change in the eigenvalue is $\\Delta\\lambda_1 \\approx \\boldsymbol{v}_{1}^{(0)T} (\\Delta H) \\boldsymbol{v}_{1}^{(0)} = \\Delta H_{xx} = \\widehat{H}_{xx} - \\lambda_1^{(0)}$. The variance of this change is simply $\\mathrm{Var}(\\widehat{H}_{xx})$.\n\nSubstituting the result from Part 1:\n$$\n\\mathrm{Var}(\\widehat{\\lambda}_1) = \\frac{6}{\\bar{n} h^{7}}\n$$", "answer": "$$\n\\boxed{\\frac{6}{\\bar{n} h^{7}}}\n$$", "id": "3502070"}]}