{"hands_on_practices": [{"introduction": "Before we can analyze or apply renewal processes, we must be able to simulate their behavior accurately. This first practice focuses on building a fundamental, event-driven simulation engine for generating sample paths of a renewal counting process, $N(t)$. Mastering this implementation [@problem_id:3343949] is the essential first step, as it forms the bedrock for more advanced simulation-based studies and applications.", "problem": "Design and implement a provably correct event-driven simulation algorithm for the renewal counting process. Let $\\{X_i\\}_{i \\geq 1}$ be independent and identically distributed interarrival times with cumulative distribution function $F$, and define the renewal epochs $T_n = \\sum_{i=1}^n X_i$ with the convention $T_0 = 0$. The renewal counting process is $N(t) = \\max\\{n \\geq 0 : T_n \\le t\\}$ for $t \\ge 0$. Your task is to derive, justify, and implement an algorithm that, given a finite horizon $T$, simulates all renewal epochs $\\{T_n : T_n \\le T\\}$ and evaluates $N(t)$ at specified query times $t \\in [0,T]$. The algorithm must be event-driven, meaning it advances the simulated time only at renewal epochs, and must:\n- Use a correct stopping rule that halts when the next proposed epoch would exceed the horizon, that is, when $T_{n+1} > T$.\n- Correctly handle ties when the interarrival distribution is lattice-supported or has an atom at $0$, so that simultaneous renewals at the same time are all counted and queries at exact renewal times include all renewals up to and including that time (that is, use the convention $N(t) = \\max\\{n : T_n \\le t\\}$).\n- Be reproducible by fixing the pseudorandom number generator seed as specified below.\n\nFundamental starting point: You must base your derivation on the definitions of the renewal epochs $T_n$ and the counting process $N(t)$, the independence and identical distribution of the interarrivals $X_i \\sim F$, and the event-driven update rule that $T_{n+1} = T_n + X_{n+1}$.\n\nYour program must:\n- Implement samplers for each specified interarrival distribution $F$.\n- Simulate the set of renewal times $\\{T_n \\le T\\}$, including repeated epochs when $X_i = 0$ occurs, and evaluate $N(t)$ at the provided list of query times using the definition $N(t) = \\max\\{n : T_n \\le t\\}$.\n- Use a pseudorandom number generator initialized with seed $s = 20231019$.\n- Produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets without spaces, where each test case’s result is itself a list of integers corresponding to the query times in the same order (for example, output of two test cases might look like $[[1,2],[3]]$).\n\nAssumptions: Assume $F$ is a proper distribution on $[0,\\infty)$ with $\\mathbb{P}(X_1 = 0) < 1$ so that an infinite number of renewals at time $0$ occurs with probability $0$.\n\nTest suite. For each test case $k \\in \\{1,2,3,4,5\\}$, you are given an interarrival distribution, a horizon $T^{(k)}$, and an ordered list of query times $\\mathcal{Q}^{(k)} \\subset [0,T^{(k)}]$. For each test case, the program must output the list $\\bigl[N(t) : t \\in \\mathcal{Q}^{(k)}\\bigr]$ in the order of the queries.\n\n- Test case $1$ (continuous): $F$ is exponential with rate $\\lambda = 1.7$; $T^{(1)} = 5.0$; $\\mathcal{Q}^{(1)} = [0.0, 1.0, 2.5, 5.0]$.\n- Test case $2$ (deterministic lattice): $F$ is deterministic with $X_i \\equiv c$ for $c = 0.5$; $T^{(2)} = 3.0$; $\\mathcal{Q}^{(2)} = [1.0, 1.5, 3.0]$.\n- Test case $3$ (discrete lattice): $F$ is discrete with $\\mathbb{P}(X_i = 0.25) = 0.2$, $\\mathbb{P}(X_i = 0.5) = 0.5$, $\\mathbb{P}(X_i = 0.75) = 0.3$; $T^{(3)} = 2.0$; $\\mathcal{Q}^{(3)} = [0.25, 1.0, 2.0]$.\n- Test case $4$ (zero-inflated continuous): $F$ has an atom at $0$ with probability $p_0 = 0.3$, and otherwise is exponential with rate $\\lambda = 2.0$; $T^{(4)} = 1.0$; $\\mathcal{Q}^{(4)} = [0.0, 1.0]$.\n- Test case $5$ (boundary): $F$ is exponential with rate $\\lambda = 1.0$; $T^{(5)} = 0.0$; $\\mathcal{Q}^{(5)} = [0.0]$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets and without spaces, where each element is the list of integers for one test case in the same order as specified above. For example, the required format is like $[[a_{1,1},a_{1,2},\\dots],[a_{2,1},\\dots],\\dots]$ with no spaces anywhere in the line.\n\nThere are no physical units in this problem. All numerical answers must be produced as integers. The pseudorandom seed must be set to $s = 20231019$, and the conventions for inclusions at ties are as above.", "solution": "The problem requires the design and implementation of an event-driven simulation algorithm for a renewal counting process, $N(t)$, up to a finite horizon $T$. The solution must be derived from fundamental principles and be provably correct.\n\n**1. Foundational Principles and Definitions**\n\nThe renewal process is defined by a sequence of independent and identically distributed (IID) non-negative random variables $\\{X_i\\}_{i \\geq 1}$, representing interarrival times, with a common cumulative distribution function (CDF) $F$.\n\nThe renewal epochs, $T_n$, are the times at which renewals occur. They are defined as the sum of the first $n$ interarrival times:\n$$T_n = \\sum_{i=1}^{n} X_i \\quad \\text{for } n \\geq 1$$\nBy convention, the process starts at time $0$, so we define $T_0 = 0$.\n\nThe renewal counting process, $N(t)$, counts the number of renewals that have occurred up to and including time $t$. It is formally defined as:\n$$N(t) = \\max\\{n \\geq 0 : T_n \\le t\\}$$\n\n**2. Algorithm Derivation: Event-Driven Simulation**\n\nThe objective is to simulate a single realization (a sample path) of the renewal process $\\{T_n\\}_{n \\ge 0}$ and use it to evaluate $N(t)$ at specified query times. An event-driven simulation approach is mandated, which is the natural and most efficient method for this system. In this paradigm, the simulation clock does not advance continuously but \"jumps\" from one event time to the next. For a renewal process, the only events are the renewals themselves.\n\nThe core of the algorithm is an iterative procedure to generate the sequence of renewal epochs $\\{T_n\\}$. The state of the simulation at any point can be characterized by the time of the last renewal, $T_n$. The next state, $T_{n+1}$, is found by generating a new interarrival time, $X_{n+1}$, and updating the time.\n\n_State Variables_:\n- $t_{current}$: The current time of the simulation, corresponding to the most recently generated renewal epoch.\n- `epochs`: A list storing the sequence of generated renewal epochs, $\\{T_0, T_1, T_2, \\dots\\}$.\n\n_Algorithmic Steps_:\n1.  **Initialization**:\n    The simulation starts at time $0$ with the $0$-th renewal.\n    - Initialize the current time: $t_{current} = T_0 = 0$.\n    - Initialize the list of epochs: `epochs` $= [0.0]$.\n    - Initialize a pseudorandom number generator (PRNG) with the specified seed, $s=20231019$, to ensure reproducibility. All random variates must be drawn from this single PRNG instance.\n\n2.  **Event Generation Loop**:\n    The simulation proceeds by generating one renewal at a time. The loop continues until the next potential renewal would occur after the simulation horizon $T$.\n    - A `while True` loop structure is employed.\n    - **Generate Interarrival Time**: Inside the loop, draw a sample $x$ from the interarrival distribution $F$. This is done using a sampler specific to the given CDF $F$.\n    - **Calculate Next Epoch**: The time of the next potential renewal is $t_{next} = t_{current} + x$. Based on the definition of $T_n$, if $t_{current} = T_n$, then $t_{next} = T_n + X_{n+1} = T_{n+1}$.\n    - **Stopping Rule**: The simulation must halt if the next event occurs beyond the horizon $T$. Therefore, if $t_{next} > T$, the loop terminates. This correctly implements the requirement to simulate all epochs $\\{T_n : T_n \\leq T\\}$.\n    - **Update State**: If $t_{next} \\le T$, the renewal is valid. The simulation state is updated:\n        - The current time advances to the new epoch: $t_{current} = t_{next}$.\n        - The new epoch is recorded: append $t_{current}$ to the `epochs` list.\n\nThis procedure generates a list `epochs` containing $[T_0, T_1, \\dots, T_k]$ where $k = \\max\\{n : T_n \\le T\\}$. By construction, this list is sorted in non-decreasing order. The possibility of $X_i=0$ is naturally handled, as it results in $T_{n+1} = T_n$ and appends a duplicate time to the `epochs` list, correctly increasing the count of renewals at that specific time.\n\n**3. Evaluation of the Counting Process $N(t)$**\n\nOnce the list of renewal epochs $[T_0, T_1, \\dots, T_k]$ is generated, we can evaluate $N(t)$ for any query time $t \\in [0, T]$. From its definition, $N(t) = \\max\\{n \\geq 0 : T_n \\le t\\}$.\n\nGiven the sorted `epochs` list, $N(t)$ corresponds to the largest index $n$ such that `epochs[n]` $\\le t$. This is equivalent to finding the number of elements in `epochs` that are less than or equal to $t$, and then subtracting $1$ (since the indices $n$ are $0$-based, and correspond to $n+1$ elements $T_0, \\dots, T_n$).\n\nThis search can be performed efficiently using a binary search algorithm. Specifically, a right-sided binary search (like `numpy.searchsorted` with `side='right'`) finds the insertion point for $t$ that maintains the sorted order. This insertion point is precisely the count of elements in the array that are less than or equal to $t$. Let this count be $c$. Then, $N(t) = c - 1$. This approach is robust and correctly handles query times that coincide with renewal epochs, as required by the $T_n \\le t$ condition.\n\n**4. Interarrival Time Samplers**\n\nThe generation of interarrival times $X_i$ requires implementing samplers for the specified distributions. This is typically done using the inverse transform sampling method or by utilizing built-in library functions that are based on standard, proven algorithms.\n\n- **Exponential Distribution ($\\text{Exp}(\\lambda)$)**: The CDF is $F(x) = 1 - e^{-\\lambda x}$. By the inverse transform method, a sample can be generated as $X = F^{-1}(U) = -\\frac{1}{\\lambda}\\ln(1-U)$, where $U \\sim \\text{Uniform}(0,1)$. This is equivalent to sampling from `numpy.random.Generator.exponential(scale=1/lambda)`.\n\n- **Deterministic Distribution ($X=c$)**: The sampler simply returns the constant $c$.\n\n- **Discrete Distribution**: For a discrete distribution with probability mass function $\\mathbb{P}(X=v_j) = p_j$, a sample is generated by drawing $U \\sim \\text{Uniform}(0,1)$ and finding the index $j$ such that $\\sum_{i=1}^{j-1} p_i \\le U < \\sum_{i=1}^{j} p_i$. This is efficiently implemented by `numpy.random.Generator.choice(values, p=probabilities)`.\n\n- **Zero-Inflated Mixed Distribution**: A mixture of an atom at $0$ with probability $p_0$ and a continuous distribution $G$ with probability $1-p_0$. A sample is drawn by first generating $U \\sim \\text{Uniform}(0,1)$. If $U < p_0$, the sample is $0$. Otherwise, a sample is drawn from the distribution $G$.\n\nThis systematic approach, founded on the mathematical definitions of the renewal process and employing standard, correct simulation techniques, guarantees a valid and reproducible implementation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases for the renewal process simulation.\n    \"\"\"\n\n    def simulate_renewal_process(sampler, T, query_times, rng):\n        \"\"\"\n        Simulates a renewal process and evaluates N(t) at query times.\n\n        Args:\n            sampler (function): A function that takes an rng instance and returns a\n                                sample from the interarrival distribution F.\n            T (float): The simulation time horizon.\n            query_times (list of float): A list of times t to evaluate N(t).\n            rng (np.random.Generator): The random number generator instance.\n\n        Returns:\n            list of int: A list of the values of N(t) for each query time.\n        \"\"\"\n        t_current = 0.0\n        epochs = [0.0]  # Store T_0, T_1, ...\n\n        while True:\n            interarrival = sampler(rng)\n            t_next = t_current + interarrival\n\n            if t_next > T:\n                break\n            \n            t_current = t_next\n            epochs.append(t_current)\n\n        # Convert to numpy array for efficient search\n        np_epochs = np.array(epochs)\n        \n        results = []\n        for t in query_times:\n            # N(t) = max{n >= 0 : T_n <= t}\n            # np.searchsorted with side='right' finds the number of elements <= t.\n            # This count is n+1. So, N(t) is count - 1.\n            count = np.searchsorted(np_epochs, t, side='right')\n            n_t = count - 1\n            results.append(int(n_t))\n            \n        return results\n\n    # Define samplers for each test case\n    def sampler_case1(rng):\n        return rng.exponential(scale=1.0 / 1.7)\n\n    def sampler_case2(rng):\n        return 0.5\n\n    def sampler_case3(rng):\n        values = [0.25, 0.5, 0.75]\n        probabilities = [0.2, 0.5, 0.3]\n        return rng.choice(values, p=probabilities)\n\n    def sampler_case4(rng):\n        p0 = 0.3\n        if rng.random() < p0:\n            return 0.0\n        else:\n            return rng.exponential(scale=1.0 / 2.0)\n\n    def sampler_case5(rng):\n        return rng.exponential(scale=1.0 / 1.0)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'sampler': sampler_case1, 'T': 5.0, 'query_times': [0.0, 1.0, 2.5, 5.0]},\n        {'sampler': sampler_case2, 'T': 3.0, 'query_times': [1.0, 1.5, 3.0]},\n        {'sampler': sampler_case3, 'T': 2.0, 'query_times': [0.25, 1.0, 2.0]},\n        {'sampler': sampler_case4, 'T': 1.0, 'query_times': [0.0, 1.0]},\n        {'sampler': sampler_case5, 'T': 0.0, 'query_times': [0.0]},\n    ]\n    \n    # Initialize a single PRNG instance for reproducibility across all tests.\n    rng = np.random.default_rng(20231019)\n    \n    all_results = []\n    for case in test_cases:\n        result_list = simulate_renewal_process(\n            case['sampler'], case['T'], case['query_times'], rng\n        )\n        all_results.append(result_list)\n\n    # Format the final output string exactly as specified.\n    # e.g., [[1,2],[3,4,5]]\n    inner_strs = [f\"[{','.join(map(str, r))}]\" for r in all_results]\n    final_output_str = f\"[{','.join(inner_strs)}]\"\n\n    # Final print statement in the exact required format.\n    print(final_output_str)\n\nsolve()\n```", "id": "3343949"}, {"introduction": "With a reliable simulation engine in hand, we can tackle realistic inverse problems, such as calibrating a model from observations. This exercise demonstrates how to use the Simulated Method of Moments (SMM) to infer the parameters of the interarrival time distribution from sparse count data. This powerful technique, explored in [@problem_id:3344008], bridges the gap between theoretical models and real-world data by using simulation as the core of a statistical estimation procedure.", "problem": "You are tasked with calibrating a renewal arrival model by the Simulated Method of Moments (SMM). A renewal process is defined by independent and identically distributed interarrival times $\\{X_i\\}_{i \\ge 1}$ with common distribution $F$, arrival epochs $S_n = \\sum_{i=1}^n X_i$, and counting process $N(t) = \\max\\{n \\ge 0: S_n \\le t\\}$. For a fixed observation horizon $T > 0$, we can obtain independent observations of the count $N(T)$ by simulating independent copies of the renewal process started at a renewal epoch at time $t=0$.\n\nYour goal is to infer the interarrival distribution $F$ from sparse count data by matching simulated and empirical summary statistics using the Simulated Method of Moments (SMM). Consider a parametric model class consisting of two families:\n\n- Gamma family: $X \\sim \\mathrm{Gamma}(k,\\theta)$ with shape $k>0$ and scale $\\theta>0$.\n- Lognormal family: $X \\sim \\mathrm{LogNormal}(\\mu,\\sigma)$ with $\\log X \\sim \\mathcal{N}(\\mu,\\sigma^2)$, $\\sigma>0$.\n\nLet $T>0$ and $M \\in \\mathbb{N}$ be given. Suppose we observe $M$ independent counts $N_1(T),\\dots,N_M(T)$, each generated as the number of renewals in the interval $[0,T]$ from a fresh start at a renewal epoch at time $t=0$. Define the empirical moments vector $\\widehat{m} = (\\widehat{\\mathrm{mean}}, \\widehat{\\mathrm{var}}, \\widehat{p}_0)$, where $\\widehat{\\mathrm{mean}}$ is the sample mean of the $M$ observed counts, $\\widehat{\\mathrm{var}}$ is the population sample variance (dividing by $M$), and $\\widehat{p}_0$ is the proportion of zero counts among the $M$ observations. For any candidate parameter $\\vartheta$ within a family, let $g_T(\\vartheta)$ denote the simulated moments vector $(\\mathrm{mean}, \\mathrm{var}, p_0)$ computed from $R$ independent simulations of $N(T)$ under the renewal model with interarrival distribution specified by $\\vartheta$. Consider the SMM criterion\n$$\nJ(\\vartheta) \\equiv \\| g_T(\\vartheta) - \\widehat{m} \\|_2^2,\n$$\nwith identity weighting. The calibrated parameter $\\hat{\\vartheta}$ is any minimizer of $J(\\vartheta)$ over a prescribed grid of candidate values.\n\nYour program must implement the following, starting from fundamental definitions and principles:\n\n1. Use the core definition of a renewal process and direct simulation to generate $N(T)$ for each independent replicate. Each replicate must be simulated by drawing interarrival times $X_1,X_2,\\dots$ from the specified candidate distribution and counting complete renewals until the partial sum exceeds $T$.\n2. Compute empirical moments $\\widehat{m}$ from a synthetic dataset that you generate according to the specified true model for each test case below. Use the specified seed to ensure reproducibility.\n3. For calibration, for each candidate parameter $\\vartheta$ in each family, simulate $R$ independent replicates of $N(T)$ and compute $g_T(\\vartheta)$. Then evaluate $J(\\vartheta)$ and select the minimizer. In the event of an exact tie in the criterion value, the program must select the lexicographically earliest candidate according to the enumeration order defined below.\n\nFamilies and parameter grids. You must search the following finite grids:\n\n- Gamma family (family index $0$): shape grid $k \\in \\{0.5, 1.0, 1.5, 2.0, 3.0\\}$ and scale grid $\\theta \\in \\{0.5, 0.75, 1.0, 1.5, 2.0, 5.0\\}$. Enumerate candidates in ascending order of $k$, and within each $k$ in ascending order of $\\theta$.\n- Lognormal family (family index $1$): mean grid $\\mu \\in \\{-1.0, -0.5, -0.2, 0.0, 0.2\\}$ and standard deviation grid $\\sigma \\in \\{0.4, 0.6, 0.8, 1.0\\}$. Enumerate candidates in ascending order of $\\mu$, and within each $\\mu$ in ascending order of $\\sigma$.\n\nSimulated moment replications. Use $R = 5000$ simulations for the evaluation of $g_T(\\vartheta)$ for each candidate. For reproducibility of the SMM component, for dataset index $d \\in \\{0,1,2\\}$ and global candidate index $c \\in \\mathbb{N}$, you must seed the random number generator for that candidate with the seed $777000 + 1000 d + c$. The global candidate index $c$ starts at $0$ for the first candidate of the Gamma family, increases by $1$ as you traverse the Gamma grid in the specified enumeration order, and continues increasing across the Lognormal grid in its specified enumeration order.\n\nEmpirical data generation. For each test case below, generate the $M$ observed counts independently using the specified true interarrival distribution family, parameters, window length $T$, and seed. For the empirical data generation only, seed the random number generator with the specified seed before generating the $M$ counts.\n\nTest suite. Your program must solve the calibration for the following three datasets. Each dataset is defined by a true model, an observation window length, a number of independent windows, and a seed.\n\n- Test case $1$ (happy path; Gamma truth): true interarrival distribution $X \\sim \\mathrm{Gamma}(k^{\\star},\\theta^{\\star})$ with $k^{\\star} = 2.0$ and $\\theta^{\\star} = 0.75$, window length $T = 1.0$, number of windows $M = 400$, empirical data seed $20231105$.\n- Test case $2$ (alternative family; Lognormal truth): true interarrival distribution $X \\sim \\mathrm{LogNormal}(\\mu^{\\star},\\sigma^{\\star})$ with $\\mu^{\\star} = -0.2$ and $\\sigma^{\\star} = 0.6$, window length $T = 1.0$, number of windows $M = 400$, empirical data seed $20231106$.\n- Test case $3$ (boundary sparsity; Exponential truth as Gamma with shape $1$): true interarrival distribution $X \\sim \\mathrm{Gamma}(k^{\\star},\\theta^{\\star})$ with $k^{\\star} = 1.0$ and $\\theta^{\\star} = 5.0$, window length $T = 1.0$, number of windows $M = 2000$, empirical data seed $20231107$.\n\nAdditional implementation requirements.\n\n- For all variances, use the population variance convention dividing by the sample size (not $M-1$ or $R-1$).\n- The program must not require any user input and must be fully deterministic given the specified seeds and grids.\n- The program should select the minimizing candidate by the specified lexicographic enumeration order to break ties.\n- Family indices must be integers: Gamma family $=0$, Lognormal family $=1$.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The $i$-th element of this list corresponds to test case $i$ and must itself be a list of the form $[f,\\;p_1,\\;p_2,\\;m,\\;v,\\;p0,\\;J]$, where $f$ is the integer family index, $p_1$ and $p_2$ are the two calibrated parameters in the order $(k,\\theta)$ for Gamma and $(\\mu,\\sigma)$ for Lognormal, $m$ is the fitted simulated mean of $N(T)$ under the selected parameter, $v$ is the fitted simulated variance, $p0$ is the fitted simulated zero-probability, and $J$ is the minimized SMM criterion value. All numerical outputs must be decimal numbers or integers. The final line must look like a bracketed list of three bracketed lists, for example $[[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot]]$ with the actual numbers in place of the placeholders.", "solution": "The problem presents a well-posed and scientifically sound task in computational statistics: calibrating a renewal process model using the Simulated Method of Moments (SMM). All components of the problem—the definition of a renewal process, the statistical moments, the SMM criterion, the candidate parameter grids, the simulation parameters, and the seeding protocol—are specified with sufficient clarity and internal consistency to permit a unique, verifiable solution. The problem is grounded in established principles of stochastic simulation and statistical inference, and it is free of scientific flaws, ambiguities, or contradictions. Therefore, the problem is deemed valid, and a full solution is provided below.\n\nThe core of the problem is to estimate the parameters $\\vartheta$ of an interarrival time distribution $F_\\vartheta$ for a renewal process. A renewal process is characterized by a sequence of arrival epochs $S_n = \\sum_{i=1}^n X_i$, where the interarrival times $\\{X_i\\}_{i \\ge 1}$ are independent and identically distributed (i.i.d.) positive random variables with common distribution $F_\\vartheta$. The number of renewals in an interval $[0, T]$ is given by the counting process $N(T) = \\max\\{n \\ge 0 : S_n \\le T\\}$. We assume the process starts with a renewal at time $t=0$, so $S_0=0$.\n\nThe estimation is performed using the Simulated Method of Moments (SMM). This method operates by matching moments computed from observed data with moments generated by simulating the model under different parameter assumptions.\n\nFirst, we define a vector of summary statistics (moments) to characterize the process. For a given set of $M$ observed counts $\\{N_j(T)\\}_{j=1}^M$, we compute the empirical moments vector:\n$$\n\\widehat{m} = (\\widehat{\\mathrm{mean}}, \\widehat{\\mathrm{var}}, \\widehat{p}_0)\n$$\nwhere $\\widehat{\\mathrm{mean}} = \\frac{1}{M}\\sum_{j=1}^M N_j(T)$ is the sample mean, $\\widehat{\\mathrm{var}} = \\frac{1}{M}\\sum_{j=1}^M (N_j(T) - \\widehat{\\mathrm{mean}})^2$ is the population variance of the sample, and $\\widehat{p}_0 = \\frac{1}{M}\\sum_{j=1}^M \\mathbf{1}\\{N_j(T)=0\\}$ is the sample proportion of zero counts.\n\nSecond, for a candidate parameter vector $\\vartheta$ from a specified parametric family, we generate a corresponding vector of simulated moments, $g_T(\\vartheta)$. This is achieved by simulating the renewal process with interarrival distribution $F_\\vartheta$ for $R$ independent replicates, obtaining counts $\\{N_r(T;\\vartheta)\\}_{r=1}^R$, and then calculating the mean, variance, and zero-proportion from this simulated sample.\n\nThird, the SMM estimator $\\hat{\\vartheta}$ is the parameter vector that minimizes the discrepancy between the empirical and simulated moments. The problem specifies a quadratic loss function with an identity weighting matrix:\n$$\nJ(\\vartheta) = \\| g_T(\\vartheta) - \\widehat{m} \\|_2^2 = (\\mathrm{mean}(\\vartheta) - \\widehat{\\mathrm{mean}})^2 + (\\mathrm{var}(\\vartheta) - \\widehat{\\mathrm{var}})^2 + (p_0(\\vartheta) - \\widehat{p}_0)^2\n$$\nThe search for the minimizer $\\hat{\\vartheta}$ is conducted over prescribed finite grids of parameters for two families of distributions: Gamma and Lognormal.\n\nThe algorithm proceeds as follows for each of the $3$ specified test cases:\n1.  **Generate Empirical Data**: For a given test case $d \\in \\{0, 1, 2\\}$, we use the specified true model (family and parameters), observation window $T$, sample size $M$, and a dedicated seed to generate $M$ independent observations of $N(T)$. The core of this step is a function that simulates $N(T)$ by iteratively drawing interarrival times $X_i$ from the true distribution and summing them until the total time exceeds $T$. The number of terms in the sum before the threshold is passed is the value of $N(T)$.\n2.  **Compute Empirical Moments**: From the $M$ generated counts, we compute the target moments vector $\\widehat{m} = (\\widehat{\\mathrm{mean}}, \\widehat{\\mathrm{var}}, \\widehat{p}_0)$.\n3.  **Calibrate via SMM**: We iterate through every candidate parameter $\\vartheta$ in the predefined grids for the Gamma and Lognormal families. The candidates are enumerated in a specified lexicographical order, which defines a global candidate index $c$.\n    a. For each candidate $\\vartheta$ and test case $d$, a unique seed is set: $s = 777000 + 1000 d + c$.\n    b. Using this seed, we simulate $R=5000$ independent realizations of $N(T)$ under the model with parameter $\\vartheta$.\n    c. From these $R$ simulations, we compute the simulated moments vector $g_T(\\vartheta)$.\n    d. We evaluate the objective function $J(\\vartheta) = \\| g_T(\\vartheta) - \\widehat{m} \\|_2^2$.\n    e. We track the candidate yielding the minimum value of $J(\\vartheta)$ found so far. The specified enumeration order and a strict inequality check for improvement ensure that any ties are broken by selecting the lexicographically first candidate.\n4.  **Store and Report Results**: After checking all candidates, the best-fitting family index, its parameters, the corresponding simulated moments, and the minimized $J$ value are recorded for the test case. This process is repeated for all $3$ test cases, and the results are aggregated into a final list.\n\nThe two parametric families for interarrival times are:\n-   **Gamma distribution** (family index $0$): $X \\sim \\mathrm{Gamma}(k, \\theta)$ with shape $k>0$ and scale $\\theta>0$. The parameter grid is $k \\in \\{0.5, 1.0, 1.5, 2.0, 3.0\\}$ and $\\theta \\in \\{0.5, 0.75, 1.0, 1.5, 2.0, 5.0\\}$.\n-   **Lognormal distribution** (family index $1$): $X \\sim \\mathrm{LogNormal}(\\mu, \\sigma)$ where $\\log X \\sim \\mathcal{N}(\\mu, \\sigma^2)$. The parameter grid is $\\mu \\in \\{-1.0, -0.5, -0.2, 0.0, 0.2\\}$ and $\\sigma \\in \\{0.4, 0.6, 0.8, 1.0\\}$.\n\nThe implementation relies on `numpy` for random number generation from these distributions (`numpy.random.Generator.gamma` and `numpy.random.Generator.lognormal`) and for array operations to compute the moments efficiently.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Simulated Method of Moments (SMM) to calibrate a renewal process model.\n    \"\"\"\n\n    def simulate_n_t(rng, family, params, T, num_reps):\n        \"\"\"\n        Simulates num_reps independent realizations of the renewal count N(T).\n\n        Args:\n            rng (numpy.random.Generator): The random number generator.\n            family (int): 0 for Gamma, 1 for Lognormal.\n            params (tuple): Distribution parameters.\n            T (float): Observation window length.\n            num_reps (int): Number of independent simulations.\n\n        Returns:\n            numpy.ndarray: An array of num_reps counts.\n        \"\"\"\n        counts = np.zeros(num_reps, dtype=int)\n        for i in range(num_reps):\n            current_time = 0.0\n            num_events = 0\n            while True:\n                if family == 0:  # Gamma\n                    k, theta = params\n                    interarrival_time = rng.gamma(k, theta)\n                else:  # Lognormal\n                    mu, sigma = params\n                    interarrival_time = rng.lognormal(mu, sigma)\n\n                if current_time + interarrival_time <= T:\n                    current_time += interarrival_time\n                    num_events += 1\n                else:\n                    break\n            counts[i] = num_events\n        return counts\n\n    def compute_moments(counts):\n        \"\"\"\n        Computes the mean, population variance, and proportion of zeros.\n\n        Args:\n            counts (numpy.ndarray): An array of observed counts.\n\n        Returns:\n            tuple: (mean, variance, p0).\n        \"\"\"\n        mean = np.mean(counts)\n        var = np.var(counts)  # Population variance (ddof=0 is default)\n        p0 = np.mean(counts == 0)\n        return mean, var, p0\n\n    # Define test cases\n    test_cases = [\n        {\n            \"true_family\": 0, \"true_params\": (2.0, 0.75), \"T\": 1.0, \n            \"M\": 400, \"seed\": 20231105\n        },\n        {\n            \"true_family\": 1, \"true_params\": (-0.2, 0.6), \"T\": 1.0,\n            \"M\": 400, \"seed\": 20231106\n        },\n        {\n            \"true_family\": 0, \"true_params\": (1.0, 5.0), \"T\": 1.0,\n            \"M\": 2000, \"seed\": 20231107\n        },\n    ]\n\n    # Define parameter grids\n    gamma_k_grid = [0.5, 1.0, 1.5, 2.0, 3.0]\n    gamma_theta_grid = [0.5, 0.75, 1.0, 1.5, 2.0, 5.0]\n    lognormal_mu_grid = [-1.0, -0.5, -0.2, 0.0, 0.2]\n    lognormal_sigma_grid = [0.4, 0.6, 0.8, 1.0]\n\n    candidates = []\n    # Gamma family (index 0)\n    for k in gamma_k_grid:\n        for theta in gamma_theta_grid:\n            candidates.append({\"family\": 0, \"params\": (k, theta)})\n    # Lognormal family (index 1)\n    for mu in lognormal_mu_grid:\n        for sigma in lognormal_sigma_grid:\n            candidates.append({\"family\": 1, \"params\": (mu, sigma)})\n            \n    R = 5000  # Number of replications for SMM\n    all_results = []\n\n    for d, case in enumerate(test_cases):\n        # 1. Generate \"empirical\" data\n        rng_empirical = np.random.default_rng(case[\"seed\"])\n        empirical_counts = simulate_n_t(\n            rng_empirical, case[\"true_family\"], case[\"true_params\"], case[\"T\"], case[\"M\"]\n        )\n        m_hat = compute_moments(empirical_counts)\n        \n        min_J = np.inf\n        best_result = None\n\n        # 2. SMM Calibration\n        for c, cand in enumerate(candidates):\n            # Set seed for SMM simulation\n            smm_seed = 777000 + 1000 * d + c\n            rng_smm = np.random.default_rng(smm_seed)\n\n            # Simulate for the candidate\n            sim_counts = simulate_n_t(\n                rng_smm, cand[\"family\"], cand[\"params\"], case[\"T\"], R\n            )\n            g_theta = compute_moments(sim_counts)\n\n            # Calculate SMM criterion J\n            J = (g_theta[0] - m_hat[0])**2 + \\\n                (g_theta[1] - m_hat[1])**2 + \\\n                (g_theta[2] - m_hat[2])**2\n\n            if J < min_J:\n                min_J = J\n                p1, p2 = cand[\"params\"]\n                m, v, p0 = g_theta\n                best_result = [cand[\"family\"], p1, p2, m, v, p0, J]\n\n        all_results.append(best_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3344008"}, {"introduction": "While simulating sample paths reveals the full random behavior of a renewal process, we are often interested in its long-run average characteristics. This final practice shifts focus from Monte Carlo simulation to the numerical analysis of the renewal equation, which governs the expected number of renewals, $m(t) = \\mathbb{E}[N(t)]$. You will derive and implement a discrete convolution scheme [@problem_id:3343983] to solve this equation, providing a deterministic approach to understanding the process's central tendency.", "problem": "Consider a renewal process with independent and identically distributed interarrival times having cumulative distribution function $F$. Let $N(t)$ denote the number of renewals by time $t$, and let the renewal function be $m(t) = \\mathbb{E}[N(t)]$. From the foundational renewal theory, the renewal function satisfies the renewal equation\n$$\nm(t) = F(t) + \\int_{0}^{t} m(t - s) \\, \\mathrm{d}F(s),\n$$\nwhere the integral is understood as a Lebesgue-Stieltjes integral. Your task is to derive, implement, and validate a numerical convolution scheme arising from a lattice approximation of $F$ with span $d > 0$ on the discretization grid $\\{0, d, 2d, \\dots\\}$, and then quantify the discretization bias as a function of $d$ and $t$.\n\nDerivation requirements:\n- Starting from the renewal equation, construct a lattice approximation of $F$ on the grid $\\{0, d, 2d, \\dots\\}$ by assigning probabilities to grid cells via increments of $F$. Denote these grid probabilities by $\\{p_k\\}_{k \\ge 1}$ where $p_k$ corresponds to the interval $((k-1)d, kd]$.\n- Use the grid-based approximation to transform the renewal equation into a discrete convolution relation for the sequence $\\{m_k\\}_{k \\ge 0}$, where $m_k$ approximates $m(kd)$ and $m_0 = 0$.\n- Implement an algorithm that solves this discrete convolution relation up to index $K = \\lfloor t/d \\rfloor$. The algorithm must rely solely on the grid increments of $F$ and a numerically stable accumulation of the convolution terms.\n\nBias quantification:\n- Define the discretization bias at time $t$ for grid span $d$ as\n$$\nB(d, t) = \\left| m_d(t) - m(t) \\right|,\n$$\nwhere $m_d(t)$ is the grid-based approximation using the lattice scheme evaluated at $t$ (you may take $m_d(t) := m_{\\lfloor t/d \\rfloor}$) and $m(t)$ is the true renewal function when available in closed form; otherwise use a reference computation at a strictly finer grid span $h_{\\mathrm{ref}}$ satisfying $h_{\\mathrm{ref}} \\ll d$.\n\nTest suite:\nImplement your program to compute $B(d, t)$ for the following five test cases. In all cases, produce results at times $t$ that are exact integer multiples of $d$ so that $t = Kd$ for some integer $K$.\n\n1. Exponential interarrival distribution with rate $\\lambda = 0.7$; use $t = 8.0$ and $d = 0.5$. The true renewal function is $m(t) = \\lambda t$.\n2. Exponential interarrival distribution with rate $\\lambda = 0.7$; use $t = 8.0$ and $d = 0.1$. The true renewal function is $m(t) = \\lambda t$.\n3. Deterministic interarrival time $c = 2.0$; use $t = 10.0$ and $d = 0.5$. The true renewal function is $m(t) = \\lfloor t/c \\rfloor$.\n4. Pareto interarrival distribution with scale $x_m = 1.0$ and shape $\\alpha = 2.5$; use $t = 20.0$ and $d = 0.5$. No simple closed form is assumed for $m(t)$; instead use a reference computation with a finer grid $h_{\\mathrm{ref}} = 0.01$ to obtain $m_{\\mathrm{ref}}(t)$ and set $m(t) := m_{\\mathrm{ref}}(t)$.\n5. Exponential interarrival distribution with rate $\\lambda = 1.5$; use $t = 0.5$ and $d = 0.5$. The true renewal function is $m(t) = \\lambda t$.\n\nAlgorithmic constraints:\n- You must solve the discrete convolution relation exactly on the grid up to index $K$ using numerically stable summations. You may not assume or use any closed-form generating function solution in the implementation.\n- When a closed-form $m(t)$ is available, use it as the truth; otherwise, compute a reference solution using a strictly finer lattice span $h_{\\mathrm{ref}}$.\n- Your implementation must rely only on basic numerical operations and linear algebra to accumulate convolution terms. If you refer to any transform-based methods such as the Fast Fourier Transform (FFT), you must spell out the full name on its first appearance, but you are not required to use it.\n\nFinal output:\n- Your program should produce a single line of output containing the five biases $\\{B(d, t)\\}$ for the test cases in the order listed above, as a comma-separated list enclosed in square brackets, for example, $[b_1,b_2,b_3,b_4,b_5]$.\n- All outputs must be floating-point numbers.\n\nNo physical units are involved in this problem. Angles are not present. Percentages are not required.", "solution": "The problem requires the derivation and implementation of a numerical scheme to solve the renewal equation on a discrete lattice, and to quantify the resulting discretization bias for several test cases.\n\n### 1. Derivation of the Discrete Renewal Equation\n\nThe cornerstone of this problem is the integral renewal equation for the renewal function $m(t) = \\mathbb{E}[N(t)]$:\n$$\nm(t) = F(t) + \\int_{0}^{t} m(t - s) \\, \\mathrm{d}F(s)\n$$\nHere, $F(t)$ is the cumulative distribution function (CDF) of the i.i.d. interarrival times. The integral is a Lebesgue-Stieltjes integral representing a convolution, which can be written as $m(t) = F(t) + (m * \\mathrm{d}F)(t)$.\n\nTo derive a numerical scheme, we discretize the time axis on a lattice with span $d > 0$, defined by the points $\\{t_n = nd\\}_{n \\ge 0}$. We seek an approximation $m_n \\approx m(t_n) = m(nd)$. By definition, $m(0) = 0$, so we set $m_0 = 0$.\n\nThe continuous interarrival time distribution is replaced by a discrete probability mass function $\\{p_k\\}_{k \\ge 1}$ on the lattice points $\\{d, 2d, 3d, \\dots\\}$. The probability $p_k$ is defined as the probability that a continuous interarrival time falls within the interval $((k-1)d, kd]$:\n$$\np_k := F(kd) - F((k-1)d), \\quad k = 1, 2, 3, \\dots\n$$\nAssuming interarrival times are non-negative, $F(0)=0$, and we have $\\sum_{k=1}^{\\infty} p_k = \\lim_{N \\to \\infty} F(Nd) - F(0) = 1$.\n\nWe now discretize the renewal equation by evaluating it at a grid point $t_n = nd$:\n$$\nm(nd) = F(nd) + \\int_{0}^{nd} m(nd - s) \\, \\mathrm{d}F(s)\n$$\nEach term is replaced by its discrete counterpart:\n1.  $m(nd)$ is approximated by $m_n$.\n2.  $F(nd)$, the probability of the first renewal occurring by time $nd$, is replaced by its discrete analogue, $F_d(n) = \\sum_{k=1}^{n} p_k$.\n3.  The integral term is a convolution. We can approximate it by partitioning the integration domain into intervals $[(k-1)d, kd]$:\n    $$\n    \\int_{0}^{nd} m(nd - s) \\, \\mathrm{d}F(s) = \\sum_{k=1}^{n} \\int_{(k-1)d}^{kd} m(nd - s) \\, \\mathrm{d}F(s)\n    $$\n    Within each interval $((k-1)d, kd]$, we approximate the function $m(nd-s)$ by a constant value, for instance, its value at the right endpoint of the effective time argument, $m(nd - kd) = m((n-k)d)$, which is approximated by $m_{n-k}$. This yields:\n    $$\n    \\int_{0}^{nd} m(nd - s) \\, \\mathrm{d}F(s) \\approx \\sum_{k=1}^{n} m_{n-k} \\int_{(k-1)d}^{kd} \\mathrm{d}F(s) = \\sum_{k=1}^{n} m_{n-k} p_k\n    $$\nCombining these terms, we arrive at the discrete renewal equation:\n$$\nm_n = \\sum_{k=1}^{n} p_k + \\sum_{k=1}^{n} m_{n-k} p_k, \\quad n \\ge 1\n$$\nwith the initial condition $m_0 = 0$. This is a recursive formula for the sequence $\\{m_n\\}$.\n\n### 2. Algorithmic Implementation\n\nThe discrete renewal equation provides a direct method for computing the sequence $\\{m_n\\}$ up to a desired index $K = \\lfloor t/d \\rfloor$.\n\nThe algorithm proceeds as follows:\n1.  Given a time horizon $t$, a grid span $d$, and the CDF $F(t)$.\n2.  Determine the maximum index $K = \\lfloor t/d \\rfloor$. If $K=0$, $m_d(t) = 0$.\n3.  Pre-compute the probabilities $p_k = F(kd) - F((k-1)d)$ for $k = 1, \\dots, K$.\n4.  Initialize an array for the renewal function values, $m$, of size $K+1$ with $m_0 = 0$.\n5.  Iteratively compute $m_n$ for $n = 1, \\dots, K$. In each step $n$:\n    a. Compute the discrete CDF value $F_d(n) = \\sum_{k=1}^{n} p_k$. This can be done efficiently using a running sum.\n    b. Compute the discrete convolution sum $C_n = \\sum_{k=1}^{n} m_{n-k} p_k$. This can be written as the vector dot product $\\mathbf{m}_{0:n-1} \\cdot \\mathbf{p}_{n:1}$, where $\\mathbf{m}_{0:n-1} = [m_0, m_1, \\dots, m_{n-1}]$ and $\\mathbf{p}_{n:1} = [p_n, p_{n-1}, \\dots, p_1]$.\n    c. The value of $m_n$ is then $m_n = F_d(n) + C_n$.\n6.  The final approximation is $m_d(t) = m_K$.\n\nThe computational complexity of this direct summation algorithm is $O(K^2)$. For problems requiring very large $K$, faster algorithms based on methods like the Fast Fourier Transform (FFT) can reduce the complexity of the convolution, but for the parameters in this problem, the direct $O(K^2)$ approach is sufficient and explicitly follows from the derived recurrence. The accumulation of positive terms is numerically stable.\n\n### 3. Bias Quantification and Test Cases\n\nThe discretization bias is defined as $B(d, t) = |m_d(t) - m(t)|$, where $m_d(t) = m_{\\lfloor t/d \\rfloor}$ is the value from our numerical scheme and $m(t)$ is the true value.\n\nThe five test cases are handled as follows:\n\n1.  **Exponential ($\\lambda = 0.7, t = 8.0, d = 0.5$):**\n    The CDF is $F(t) = 1 - e^{-\\lambda t}$. The true renewal function is $m(t) = \\lambda t = 0.7 \\times 8.0 = 5.6$. We compute $m_{16}$ and find the bias $|m_{16} - 5.6|$.\n\n2.  **Exponential ($\\lambda = 0.7, t = 8.0, d = 0.1$):**\n    Similar to case 1, but with a finer grid. $m(t) = 5.6$. We compute $m_{80}$ and the bias $|m_{80} - 5.6|$.\n\n3.  **Deterministic ($c = 2.0, t = 10.0, d = 0.5$):**\n    The CDF is a step function: $F(t) = 0$ for $t < c$ and $F(t) = 1$ for $t \\ge c$. Since $d$ divides $c$, the discrete probability mass is $p_4 = 1$ (for $k=c/d=4$) and $p_k=0$ for $k \\ne 4$. The discrete process exactly replicates the continuous one, so the bias should be zero. The true renewal function is $m(t) = \\lfloor t/c \\rfloor = \\lfloor 10.0/2.0 \\rfloor = 5$.\n\n4.  **Pareto ($x_m = 1.0, \\alpha = 2.5, t = 20.0, d = 0.5$):**\n    The CDF is $F(x) = 1 - (x_m/x)^\\alpha$ for $x \\ge x_m$. No closed-form for $m(t)$ is available. We first compute a high-resolution reference value $m_{\\mathrm{ref}}(t)$ using the same algorithm but with a much finer grid span $h_{\\mathrm{ref}} = 0.01$. Then, we compute the approximation $m_d(t)$ with $d=0.5$. The bias is $|m_d(t) - m_{\\mathrm{ref}}(t)|$.\n\n5.  **Exponential ($\\lambda = 1.5, t = 0.5, d = 0.5$):**\n    This is a simple case where $K=1$. The true value is $m(t) = \\lambda t = 1.5 \\times 0.5 = 0.75$. The approximation is $m_1 = p_1 = F(0.5) - F(0) = 1-e^{-1.5 \\times 0.5} = 1-e^{-0.75}$. The bias is $|(1 - e^{-0.75}) - 0.75|$.\n\nThe implementation will consist of a general solver for the discrete renewal equation, which is then applied to each of these specific cases to calculate the biases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives, implements, and validates a numerical convolution scheme for the\n    renewal equation and quantifies discretization bias.\n    \"\"\"\n\n    # --- CDF Definitions ---\n    def cdf_exp(lmbda: float):\n        \"\"\"Returns the CDF of an exponential distribution.\"\"\"\n        def F(t: float) -> float:\n            if t < 0:\n                return 0.0\n            return 1.0 - np.exp(-lmbda * t)\n        return F\n\n    def cdf_det(c: float):\n        \"\"\"Returns the CDF of a deterministic distribution.\"\"\"\n        def F(t: float) -> float:\n            return 1.0 if t >= c else 0.0\n        return F\n\n    def cdf_pareto(xm: float, alpha: float):\n        \"\"\"Returns the CDF of a Pareto distribution.\"\"\"\n        def F(x: float) -> float:\n            if x < xm:\n                return 0.0\n            return 1.0 - (xm / x)**alpha\n        return F\n\n    # --- Core Numerical Solver ---\n    def solve_discrete_renewal(t: float, d: float, F: callable) -> float:\n        \"\"\"\n        Solves the discrete renewal equation on a lattice.\n        \n        Args:\n            t: The time horizon.\n            d: The grid span.\n            F: The CDF of the interarrival times.\n\n        Returns:\n            The approximated renewal function value m_d(t).\n        \"\"\"\n        if t <= 0 or d <= 0:\n            return 0.0\n        \n        # Use a small tolerance for floating point comparison to determine K\n        K = int(t / d + 1e-9)\n\n        if K == 0:\n            return 0.0\n\n        p = np.zeros(K + 1)\n        for k in range(1, K + 1):\n            p[k] = F(k * d) - F((k - 1) * d)\n\n        m = np.zeros(K + 1)\n        # m[0] = 0.0 is implicitly set by np.zeros\n\n        F_d = 0.0\n        for n in range(1, K + 1):\n            F_d += p[n]\n            # Convolution sum: sum_{k=1 to n} m_{n-k} * p_k\n            # This is equivalent to sum_{j=0 to n-1} m_j * p_{n-j}\n            conv_sum = np.dot(m[:n], p[n:0:-1])\n            m[n] = F_d + conv_sum\n            \n        return m[K]\n\n    # --- Test Case Configuration ---\n    test_cases = [\n        {'id': 1, 'dist': 'exp', 'params': {'lmbda': 0.7}, 't': 8.0, 'd': 0.5},\n        {'id': 2, 'dist': 'exp', 'params': {'lmbda': 0.7}, 't': 8.0, 'd': 0.1},\n        {'id': 3, 'dist': 'det', 'params': {'c': 2.0}, 't': 10.0, 'd': 0.5},\n        {'id': 4, 'dist': 'pareto', 'params': {'xm': 1.0, 'alpha': 2.5}, 't': 20.0, 'd': 0.5, 'h_ref': 0.01},\n        {'id': 5, 'dist': 'exp', 'params': {'lmbda': 1.5}, 't': 0.5, 'd': 0.5},\n    ]\n\n    results = []\n    \n    # --- Processing Test Cases ---\n    for case in test_cases:\n        t, d, dist = case['t'], case['d'], case['dist']\n        params = case['params']\n        \n        m_true = 0.0\n        F = None\n\n        if dist == 'exp':\n            lmbda = params['lmbda']\n            F = cdf_exp(lmbda)\n            m_true = lmbda * t\n        elif dist == 'det':\n            c = params['c']\n            F = cdf_det(c)\n            m_true = np.floor(t / c)\n        elif dist == 'pareto':\n            xm, alpha = params['xm'], params['alpha']\n            F = cdf_pareto(xm, alpha)\n            h_ref = case['h_ref']\n            m_true = solve_discrete_renewal(t, h_ref, F)\n        \n        # The line `K = int(round(t / d))` in the solution description was found to be less\n        # robust than `int(t / d + epsilon)` for floating point arithmetic, so a change was made here.\n        m_approx = solve_discrete_renewal(t, d, F)\n        \n        bias = np.abs(m_approx - m_true)\n        results.append(bias)\n\n    # --- Final Output ---\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```", "id": "3343983"}]}