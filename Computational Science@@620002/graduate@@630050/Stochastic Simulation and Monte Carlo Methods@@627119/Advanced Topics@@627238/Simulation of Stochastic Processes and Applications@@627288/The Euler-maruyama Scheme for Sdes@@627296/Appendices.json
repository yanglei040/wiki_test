{"hands_on_practices": [{"introduction": "A fundamental test for any numerical integrator is to assess its local accuracy—how well it performs over a single, small step. This practice delves into the core of the Euler-Maruyama scheme by examining its behavior on a multi-dimensional linear SDE. By deriving and comparing the first two moments (mean and covariance) of a single EM step against the exact short-time expansions of the true solution, you will gain first-hand insight into the scheme's local error structure and its order of accuracy for the mean and covariance [@problem_id:3352555].", "problem": "Consider the two-dimensional linear Stochastic Differential Equation (SDE)\n$$\ndX_{t} \\;=\\; A X_{t}\\, dt \\;+\\; b\\, dt \\;+\\; B\\, dW_{t},\n$$\nwhere $X_{t} \\in \\mathbb{R}^{2}$ is the state, $A \\in \\mathbb{R}^{2 \\times 2}$ is the drift Jacobian, $b \\in \\mathbb{R}^{2}$ is a constant drift vector, $B \\in \\mathbb{R}^{2 \\times 2}$ is the diffusion matrix, and $W_{t} \\in \\mathbb{R}^{2}$ is a two-dimensional standard Wiener process (Brownian motion) with independent components. Assume the initial condition $X_{0}$ is Gaussian $X_{0} \\sim \\mathcal{N}(m_{0}, \\Sigma_{0})$, independent of $W_{t}$. The Euler–Maruyama (EM) scheme with step size $h$ is defined as\n$$\nX_{1} \\;=\\; X_{0} \\;+\\; \\big(A X_{0} + b\\big)\\, h \\;+\\; B\\, \\Delta W,\n$$\nwhere $\\Delta W \\sim \\mathcal{N}(0, h I_{2})$ is independent of $X_{0}$ and $I_{2}$ is the $2 \\times 2$ identity matrix. Let the system parameters be\n$$\nA \\;=\\; \\begin{pmatrix} -1.2  0.8 \\\\ -2.0  -0.5 \\end{pmatrix}, \\quad\nb \\;=\\; \\begin{pmatrix} 0.05 \\\\ -0.08 \\end{pmatrix}, \\quad\nB \\;=\\; \\begin{pmatrix} 0.6  0.3 \\\\ 0.1  0.7 \\end{pmatrix},\n$$\nwith initial mean and covariance\n$$\nm_{0} \\;=\\; \\begin{pmatrix} 0.4 \\\\ -0.2 \\end{pmatrix}, \\quad\n\\Sigma_{0} \\;=\\; \\begin{pmatrix} 0.5  0.15 \\\\ 0.15  0.4 \\end{pmatrix},\n$$\nand step size $h = 0.02$.\n\nUsing first principles for linear SDEs and Itô calculus, do the following:\n\n1. Derive the exact short-time expansions (to first order in $h$) for the mean vector $m_{\\text{exact}}(h)$ and covariance matrix $\\Sigma_{\\text{exact}}(h)$ at time $t = h$, in terms of $A$, $b$, $B$, $m_{0}$, and $\\Sigma_{0}$. Do not assume any solution formulas beyond the definitions of expectation, covariance, and the Itô product rule.\n\n2. Derive the one-step Euler–Maruyama mean $m_{\\text{EM}}$ and covariance $\\Sigma_{\\text{EM}}$ in terms of $A$, $b$, $B$, $m_{0}$, $\\Sigma_{0}$, and $h$.\n\n3. Evaluate $m_{\\text{EM}}$ and $\\Sigma_{\\text{EM}}$ numerically for the given parameters, and write down the corresponding exact short-time mean and covariance from part $1$.\n\n4. Compare $\\Sigma_{\\text{EM}}$ with $\\Sigma_{\\text{exact}}(h)$ and compute the scalar quantity\n$$\n\\operatorname{tr}\\!\\big(\\Sigma_{\\text{EM}} - \\Sigma_{\\text{exact}}(h)\\big),\n$$\nwhere $\\operatorname{tr}(\\cdot)$ denotes the trace. Express the final answer as a single real number. Round your final answer to four significant figures.", "solution": "The problem is first subjected to a rigorous validation process.\n\n### Step 1: Extract Givens\nThe problem provides the following information:\n- A two-dimensional linear Stochastic Differential Equation (SDE): $dX_{t} = (A X_{t} + b) dt + B dW_{t}$, where $X_{t} \\in \\mathbb{R}^{2}$, $W_{t} \\in \\mathbb{R}^{2}$ is a standard Wiener process.\n- Initial condition: $X_{0} \\sim \\mathcal{N}(m_{0}, \\Sigma_{0})$, independent of $W_{t}$.\n- Euler-Maruyama (EM) scheme with step size $h$: $X_{1} = X_{0} + (A X_{0} + b) h + B \\Delta W$, where $\\Delta W \\sim \\mathcal{N}(0, h I_{2})$ is independent of $X_{0}$.\n- Drift Jacobian: $A = \\begin{pmatrix} -1.2  0.8 \\\\ -2.0  -0.5 \\end{pmatrix}$.\n- Constant drift vector: $b = \\begin{pmatrix} 0.05 \\\\ -0.08 \\end{pmatrix}$.\n- Diffusion matrix: $B = \\begin{pmatrix} 0.6  0.3 \\\\ 0.1  0.7 \\end{pmatrix}$.\n- Initial mean vector: $m_{0} = \\begin{pmatrix} 0.4 \\\\ -0.2 \\end{pmatrix}$.\n- Initial covariance matrix: $\\Sigma_{0} = \\begin{pmatrix} 0.5  0.15 \\\\ 0.15  0.4 \\end{pmatrix}$.\n- Step size: $h = 0.02$.\n- The task is to derive and compare the mean and covariance of the exact solution (to first order) and the EM scheme, and compute $\\operatorname{tr}(\\Sigma_{\\text{EM}} - \\Sigma_{\\text{exact}}(h))$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard exercise in the field of numerical analysis for stochastic differential equations. It deals with well-established concepts such as linear SDEs, the Wiener process, Gaussian distributions, and the Euler-Maruyama method. All principles are rooted in stochastic calculus and are factually sound.\n- **Well-Posed:** The problem is clearly stated, providing all necessary parameters and definitions. It asks for specific derivations and a numerical calculation, which lead to a unique and meaningful solution.\n- **Objective:** The problem is expressed in precise mathematical language, free from any subjectivity or ambiguity.\n- **Completeness and Consistency:** The problem is self-contained. All matrices and parameters are given with compatible dimensions. There are no contradictions in the setup.\n- **No other flaws are detected.** The problem is formalizable, relevant, realistic, and non-trivial.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\n---\n\n### Part 1: Exact Short-Time Expansions\nWe derive the evolution equations for the exact mean $m(t) = E[X_t]$ and covariance $\\Sigma(t) = \\operatorname{Cov}(X_t)$.\nTaking the expectation of the SDE, and using $E[dW_t] = 0$:\n$$\ndE[X_t] = E[(A X_t + b) dt + B dW_t] = (A E[X_t] + b) dt\n$$\nThis gives the ordinary differential equation (ODE) for the mean vector:\n$$\n\\frac{dm(t)}{dt} = A m(t) + b\n$$\nFor a short time interval $h$, we can approximate $m(h)$ using a first-order Taylor expansion around $t=0$:\n$$\nm_{\\text{exact}}(h) \\approx m(0) + h \\frac{dm}{dt}\\bigg|_{t=0} = m_0 + h (A m_0 + b)\n$$\nThis is the first-order expansion for the mean.\n\nFor the covariance, we first derive its governing ODE. The covariance is $\\Sigma(t) = E[(X_t - m(t))(X_t - m(t))^T]$. Let's first find the ODE for the second moment $M_2(t) = E[X_t X_t^T]$. Using the Itô product rule for $X_t X_t^T$:\n$$\nd(X_t X_t^T) = (dX_t)X_t^T + X_t(dX_t)^T + (dX_t)(dX_t)^T\n$$\nThe quadratic variation term is $(dX_t)(dX_t)^T = (B dW_t)(B dW_t)^T = B (dW_t dW_t^T) B^T = B (I_2 dt) B^T = BB^T dt$.\nSubstituting $dX_t$ and taking expectations:\n$$\ndE[X_t X_t^T] = E[(AX_t + b)X_t^T dt + X_t(AX_t + b)^T dt + BB^T dt]\n$$\nNoting that stochastic integral terms have zero expectation, we get the ODE for $M_2(t)$:\n$$\n\\frac{dM_2(t)}{dt} = A M_2(t) + b m(t)^T + M_2(t) A^T + m(t) b^T + BB^T\n$$\nNow, since $\\Sigma(t) = M_2(t) - m(t)m(t)^T$, we have $\\frac{d\\Sigma}{dt} = \\frac{dM_2}{dt} - \\frac{d(mm^T)}{dt}$.\n$$\n\\frac{d(mm^T)}{dt} = \\frac{dm}{dt}m^T + m\\frac{dm^T}{dt} = (Am+b)m^T + m(Am+b)^T = Amm^T + bm^T + mm^TA^T + mb^T\n$$\nSubtracting this from the ODE for $M_2(t)$:\n$$\n\\frac{d\\Sigma}{dt} = A(M_2 - mm^T) + (M_2 - mm^T)A^T + BB^T = A\\Sigma + \\Sigma A^T + BB^T\n$$\nThis is the Lyapunov differential equation for the covariance matrix.\nThe first-order Taylor expansion for $\\Sigma(h)$ around $t=0$ is:\n$$\n\\Sigma_{\\text{exact}}(h) \\approx \\Sigma(0) + h \\frac{d\\Sigma}{dt}\\bigg|_{t=0} = \\Sigma_0 + h(A\\Sigma_0 + \\Sigma_0 A^T + BB^T)\n$$\n\n### Part 2: Euler-Maruyama Mean and Covariance\nThe one-step Euler-Maruyama approximation is given by:\n$$\nX_1 = X_0 + (A X_0 + b)h + B\\Delta W = (I_2 + Ah)X_0 + bh + B\\Delta W\n$$\nThe mean of $X_1$, denoted $m_{\\text{EM}}$, is found by taking the expectation. Given that $E[X_0] = m_0$ and $E[\\Delta W] = 0$:\n$$\nm_{\\text{EM}} = E[X_1] = E[(I_2 + Ah)X_0 + bh + B\\Delta W] = (I_2 + Ah)E[X_0] + bh + B E[\\Delta W]\n$$\n$$\nm_{\\text{EM}} = (I_2 + Ah)m_0 + bh = m_0 + (Am_0 + b)h\n$$\nThe covariance of $X_1$, denoted $\\Sigma_{\\text{EM}}$, is $\\operatorname{Cov}(X_1) = E[(X_1 - m_{\\text{EM}})(X_1 - m_{\\text{EM}})^T]$.\nFirst, we find the deviation from the mean:\n$$\nX_1 - m_{\\text{EM}} = ((I_2 + Ah)X_0 + bh + B\\Delta W) - ((I_2 + Ah)m_0 + bh) = (I_2 + Ah)(X_0 - m_0) + B\\Delta W\n$$\nNow we compute the covariance. Since $X_0$ and $\\Delta W$ are independent, the cross-terms in the expectation vanish: $E[(X_0 - m_0)(\\Delta W)^T] = E[X_0 - m_0]E[(\\Delta W)^T] = 0$.\n$$\n\\Sigma_{\\text{EM}} = E[((I_2 + Ah)(X_0-m_0) + B\\Delta W)((I_2+Ah)(X_0-m_0) + B\\Delta W)^T]\n$$\n$$\n\\Sigma_{\\text{EM}} = E[(I_2+Ah)(X_0-m_0)(X_0-m_0)^T(I_2+Ah)^T] + E[B\\Delta W (\\Delta W)^T B^T]\n$$\nUsing $E[(X_0-m_0)(X_0-m_0)^T] = \\Sigma_0$ and $E[\\Delta W (\\Delta W)^T] = \\operatorname{Cov}(\\Delta W) = hI_2$:\n$$\n\\Sigma_{\\text{EM}} = (I_2+Ah)\\Sigma_0(I_2+Ah)^T + B(hI_2)B^T = (I_2+Ah)\\Sigma_0(I_2+hA^T) + hBB^T\n$$\nExpanding the product:\n$$\n\\Sigma_{\\text{EM}} = \\Sigma_0 + h\\Sigma_0 A^T + hA\\Sigma_0 + h^2 A\\Sigma_0 A^T + hBB^T = \\Sigma_0 + h(A\\Sigma_0 + \\Sigma_0 A^T + BB^T) + h^2 A\\Sigma_0 A^T\n$$\n\n### Part 3: Numerical Evaluation\nWe have $h=0.02$, $A = \\begin{pmatrix} -1.2  0.8 \\\\ -2.0  -0.5 \\end{pmatrix}$, $b = \\begin{pmatrix} 0.05 \\\\ -0.08 \\end{pmatrix}$, $B = \\begin{pmatrix} 0.6  0.3 \\\\ 0.1  0.7 \\end{pmatrix}$, $m_0 = \\begin{pmatrix} 0.4 \\\\ -0.2 \\end{pmatrix}$, $\\Sigma_0 = \\begin{pmatrix} 0.5  0.15 \\\\ 0.15  0.4 \\end{pmatrix}$.\n\nFirst, we evaluate $m_{\\text{EM}}$:\n$$\nAm_0 + b = \\begin{pmatrix} -1.2(0.4) + 0.8(-0.2) \\\\ -2.0(0.4) - 0.5(-0.2) \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.08 \\end{pmatrix} = \\begin{pmatrix} -0.64 \\\\ -0.7 \\end{pmatrix} + \\begin{pmatrix} 0.05 \\\\ -0.08 \\end{pmatrix} = \\begin{pmatrix} -0.59 \\\\ -0.78 \\end{pmatrix}\n$$\n$$\nm_{\\text{EM}} = m_0 + h(Am_0+b) = \\begin{pmatrix} 0.4 \\\\ -0.2 \\end{pmatrix} + 0.02 \\begin{pmatrix} -0.59 \\\\ -0.78 \\end{pmatrix} = \\begin{pmatrix} 0.4 - 0.0118 \\\\ -0.2 - 0.0156 \\end{pmatrix} = \\begin{pmatrix} 0.3882 \\\\ -0.2156 \\end{pmatrix}\n$$\nThe first-order exact mean $m_{\\text{exact}}(h)$ has the same formula, so $m_{\\text{exact}}(h) \\approx \\begin{pmatrix} 0.3882 \\\\ -0.2156 \\end{pmatrix}$.\n\nNext, we evaluate the covariances. We need several intermediate matrices:\n$$\nA^T = \\begin{pmatrix} -1.2  -2.0 \\\\ 0.8  -0.5 \\end{pmatrix}\n$$\n$$\nA\\Sigma_0 = \\begin{pmatrix} -1.2  0.8 \\\\ -2.0  -0.5 \\end{pmatrix} \\begin{pmatrix} 0.5  0.15 \\\\ 0.15  0.4 \\end{pmatrix} = \\begin{pmatrix} -0.48  0.14 \\\\ -1.075  -0.5 \\end{pmatrix}\n$$\n$$\n\\Sigma_0 A^T = (A\\Sigma_0)^T = \\begin{pmatrix} -0.48  -1.075 \\\\ 0.14  -0.5 \\end{pmatrix}\n$$\n$$\nBB^T = \\begin{pmatrix} 0.6  0.3 \\\\ 0.1  0.7 \\end{pmatrix} \\begin{pmatrix} 0.6  0.1 \\\\ 0.3  0.7 \\end{pmatrix} = \\begin{pmatrix} 0.45  0.27 \\\\ 0.27  0.5 \\end{pmatrix}\n$$\nThe first-order expansion of the exact covariance is:\n$$\n\\Sigma_{\\text{exact}}(h) \\approx \\Sigma_0 + h(A\\Sigma_0 + \\Sigma_0 A^T + BB^T)\n$$\n$$\nA\\Sigma_0 + \\Sigma_0 A^T + BB^T = \\begin{pmatrix} -0.96  -0.935 \\\\ -0.935  -1.0 \\end{pmatrix} + \\begin{pmatrix} 0.45  0.27 \\\\ 0.27  0.5 \\end{pmatrix} = \\begin{pmatrix} -0.51  -0.665 \\\\ -0.665  -0.5 \\end{pmatrix}\n$$\n$$\n\\Sigma_{\\text{exact}}(h) \\approx \\begin{pmatrix} 0.5  0.15 \\\\ 0.15  0.4 \\end{pmatrix} + 0.02 \\begin{pmatrix} -0.51  -0.665 \\\\ -0.665  -0.5 \\end{pmatrix} = \\begin{pmatrix} 0.5 - 0.0102  0.15 - 0.0133 \\\\ 0.15 - 0.0133  0.4 - 0.01 \\end{pmatrix}\n$$\n$$\n\\Sigma_{\\text{exact}}(h) \\approx \\begin{pmatrix} 0.4898  0.1367 \\\\ 0.1367  0.39 \\end{pmatrix}\n$$\nThe EM covariance is $\\Sigma_{\\text{EM}} = (\\Sigma_0 + h(A\\Sigma_0 + \\Sigma_0 A^T + BB^T)) + h^2 A\\Sigma_0 A^T$. The term in parenthesis is the approximation of $\\Sigma_{\\text{exact}}(h)$.\n$$\nA\\Sigma_0 A^T = (A\\Sigma_0) A^T = \\begin{pmatrix} -0.48  0.14 \\\\ -1.075  -0.5 \\end{pmatrix} \\begin{pmatrix} -1.2  -2.0 \\\\ 0.8  -0.5 \\end{pmatrix} = \\begin{pmatrix} 0.688  0.89 \\\\ 0.89  2.4 \\end{pmatrix}\n$$\n$$\nh^2 A\\Sigma_0 A^T = (0.02)^2 \\begin{pmatrix} 0.688  0.89 \\\\ 0.89  2.4 \\end{pmatrix} = 0.0004 \\begin{pmatrix} 0.688  0.89 \\\\ 0.89  2.4 \\end{pmatrix} = \\begin{pmatrix} 0.0002752  0.000356 \\\\ 0.000356  0.00096 \\end{pmatrix}\n$$\n$$\n\\Sigma_{\\text{EM}} = \\begin{pmatrix} 0.4898  0.1367 \\\\ 0.1367  0.39 \\end{pmatrix} + \\begin{pmatrix} 0.0002752  0.000356 \\\\ 0.000356  0.00096 \\end{pmatrix} = \\begin{pmatrix} 0.4900752  0.137056 \\\\ 0.137056  0.39096 \\end{pmatrix}\n$$\n\n### Part 4: Comparison and Trace Calculation\nThe question asks to compare $\\Sigma_{\\text{EM}}$ with $\\Sigma_{\\text{exact}}(h)$, where the latter is the first-order expansion derived in Part 1. The difference is:\n$$\n\\Sigma_{\\text{EM}} - \\Sigma_{\\text{exact}}(h) \\approx \\Sigma_{\\text{EM}} - (\\Sigma_0 + h(A\\Sigma_0 + \\Sigma_0 A^T + BB^T)) = h^2 A\\Sigma_0 A^T\n$$\nWe compute the trace of this difference matrix:\n$$\n\\operatorname{tr}(\\Sigma_{\\text{EM}} - \\Sigma_{\\text{exact}}(h)) = \\operatorname{tr}(h^2 A\\Sigma_0 A^T) = h^2 \\operatorname{tr}(A\\Sigma_0 A^T)\n$$\nUsing our numerical calculation of $A\\Sigma_0 A^T$:\n$$\n\\operatorname{tr}(A\\Sigma_0 A^T) = 0.688 + 2.4 = 3.088\n$$\nThus, the required quantity is:\n$$\n\\operatorname{tr}(\\Sigma_{\\text{EM}} - \\Sigma_{\\text{exact}}(h)) = (0.02)^2 \\times 3.088 = 0.0004 \\times 3.088 = 0.0012352\n$$\nRounding this value to four significant figures gives $0.001235$.", "answer": "$$\n\\boxed{1.235 \\times 10^{-3}}\n$$", "id": "3352555"}, {"introduction": "While local accuracy is crucial, the long-term behavior of a numerical simulation is often of paramount importance, especially in fields like statistical mechanics or finance. This exercise shifts the focus from a single step to the global, asymptotic properties of the Euler-Maruyama scheme [@problem_id:3352613]. You will investigate how the local discretization error accumulates by analyzing the scheme's ability to reproduce the correct invariant (stationary) distribution for the ergodic Ornstein-Uhlenbeck process, revealing a systematic bias that depends on the step size $h$.", "problem": "Consider the Ornstein–Uhlenbeck process defined by the stochastic differential equation (SDE) $dX_{t} = -\\lambda X_{t}\\,dt + \\sigma\\,dW_{t}$ with $\\lambda  0$ and $\\sigma  0$, where $W_{t}$ is a standard Wiener process. The exact invariant distribution of this SDE is known to be Gaussian with zero mean and variance $\\sigma^{2}/(2\\lambda)$. Let $X_{n}$ denote the Euler–Maruyama (EM) discretization (with step size $h  0$) of this SDE, given by the recursion $X_{n+1} = X_{n} - \\lambda X_{n} h + \\sigma \\sqrt{h}\\,\\xi_{n}$, where $(\\xi_{n})_{n\\ge 0}$ are independent and identically distributed standard normal random variables and $X_{0}$ is independent of $(\\xi_{n})_{n\\ge 0}$. Assume $0  h  2/\\lambda$ so that the resulting Markov chain is stable.\n\nStarting from fundamental definitions and facts about linear Gaussian Markov chains, derive the exact discrete-time invariant measure of the EM scheme, and compute the stationary variance of $X_{n}$. Then, quantify the bias in the stationary second moment induced by EM by comparing the EM stationary variance to the exact invariant variance of the continuous-time SDE. Express this bias as a single closed-form analytic expression in terms of $\\lambda$, $\\sigma$, and $h$, and provide its leading-order asymptotic behavior as $h \\to 0$.\n\nProvide, as your final answer, the exact closed-form expression for the variance bias $\\operatorname{Var}_{\\mathrm{EM}}(X_{n}) - \\sigma^{2}/(2\\lambda)$. Do not provide any numerical approximation; no rounding is required. Use no units in the final expression.", "solution": "We begin with the Ornstein–Uhlenbeck SDE $dX_{t} = -\\lambda X_{t}\\,dt + \\sigma\\,dW_{t}$, with $\\lambda  0$ and $\\sigma  0$. A classical result for this linear SDE is that it has a unique invariant distribution that is Gaussian with mean $0$ and variance $\\sigma^{2}/(2\\lambda)$, obtained by solving the stationary Fokker–Planck equation or, equivalently, the continuous-time Lyapunov equation for the covariance of the linear system.\n\nWe now consider the Euler–Maruyama (EM) scheme with step size $h  0$ applied to this SDE. The EM update is\n$$\nX_{n+1} = X_{n} - \\lambda X_{n} h + \\sigma \\sqrt{h}\\,\\xi_{n}\n= (1 - \\lambda h) X_{n} + \\sigma \\sqrt{h}\\,\\xi_{n},\n$$\nwhere $(\\xi_{n})_{n\\ge 0}$ are independent and identically distributed standard normal random variables. This defines a linear Gaussian autoregressive Markov chain of order one,\n$$\nX_{n+1} = a X_{n} + b \\xi_{n}, \\quad \\text{with} \\quad a = 1 - \\lambda h, \\quad b = \\sigma \\sqrt{h}.\n$$\nFor a linear recursion of the form $X_{n+1} = a X_{n} + b \\xi_{n}$ with $|a|  1$ (which here holds for $0  h  2/\\lambda$), the invariant distribution exists and is Gaussian with mean $0$. The stationary variance $v_{h} = \\operatorname{Var}(X_{n})$ solves the discrete Lyapunov equation obtained by taking variances on both sides at stationarity:\n$$\nv_{h} = \\operatorname{Var}(X_{n+1}) = \\operatorname{Var}(a X_{n} + b \\xi_{n})\n= a^{2} \\operatorname{Var}(X_{n}) + b^{2} = a^{2} v_{h} + b^{2}.\n$$\nSolving for $v_{h}$ gives\n$$\nv_{h} = \\frac{b^{2}}{1 - a^{2}} = \\frac{\\sigma^{2} h}{1 - (1 - \\lambda h)^{2}}\n= \\frac{\\sigma^{2} h}{1 - \\left(1 - 2\\lambda h + \\lambda^{2} h^{2}\\right)}\n= \\frac{\\sigma^{2} h}{2\\lambda h - \\lambda^{2} h^{2}}\n= \\frac{\\sigma^{2}}{2\\lambda - \\lambda^{2} h}.\n$$\nTherefore, the exact discrete-time invariant measure of the EM chain is Gaussian with mean $0$ and variance\n$$\n\\operatorname{Var}_{\\mathrm{EM}}(X_{n}) = \\frac{\\sigma^{2}}{2\\lambda - \\lambda^{2} h}.\n$$\n\nWe now quantify the stationary variance bias induced by EM, defined as the difference between the EM stationary variance and the exact invariant variance of the continuous-time SDE:\n$$\n\\Delta(h) = \\operatorname{Var}_{\\mathrm{EM}}(X_{n}) - \\frac{\\sigma^{2}}{2\\lambda}\n= \\frac{\\sigma^{2}}{2\\lambda - \\lambda^{2} h} - \\frac{\\sigma^{2}}{2\\lambda}.\n$$\nWe simplify this expression by putting it over a common denominator:\n$$\n\\Delta(h) = \\sigma^{2} \\left( \\frac{1}{2\\lambda - \\lambda^{2} h} - \\frac{1}{2\\lambda} \\right)\n= \\sigma^{2} \\cdot \\frac{2\\lambda - (2\\lambda - \\lambda^{2} h)}{(2\\lambda)(2\\lambda - \\lambda^{2} h)}\n= \\sigma^{2} \\cdot \\frac{\\lambda^{2} h}{4\\lambda^{2} - 2\\lambda^{3} h}\n= \\frac{\\sigma^{2} h}{4 - 2\\lambda h}.\n$$\nThis provides the exact closed-form expression for the variance bias as a function of $\\lambda$, $\\sigma$, and $h$.\n\nTo understand the error as $h \\to 0$, we expand $\\Delta(h)$ in a Taylor series around $h = 0$. Write\n$$\n\\Delta(h) = \\frac{\\sigma^{2} h}{4 - 2\\lambda h}\n= \\frac{\\sigma^{2} h}{4} \\cdot \\frac{1}{1 - (\\lambda h)/2}\n= \\frac{\\sigma^{2} h}{4} \\left( 1 + \\frac{\\lambda h}{2} + \\left(\\frac{\\lambda h}{2}\\right)^{2} + \\cdots \\right).\n$$\nHence, the leading-order asymptotic behavior is\n$$\n\\Delta(h) = \\frac{\\sigma^{2} h}{4} + \\frac{\\sigma^{2} \\lambda h^{2}}{8} + \\mathcal{O}(h^{3}), \\quad \\text{as } h \\to 0,\n$$\nshowing that the EM stationary variance overestimates the exact invariant variance by an amount that is linear in $h$ to first order, with leading coefficient $\\sigma^{2}/4$.\n\nSummarizing, the discrete-time invariant measure of the EM scheme is $\\mathcal{N}\\!\\left(0,\\,\\sigma^{2}/(2\\lambda - \\lambda^{2} h)\\right)$, and the exact variance bias is $\\Delta(h) = \\sigma^{2} h/(4 - 2\\lambda h)$, with leading-order term $\\sigma^{2} h/4$ as $h \\to 0$.", "answer": "$$\\boxed{\\frac{\\sigma^{2} h}{4 - 2\\lambda h}}$$", "id": "3352613"}, {"introduction": "Theoretical analysis provides essential insights, but true mastery comes from implementation and observation. This final practice bridges the gap between theory and computation, challenging you to code both the Euler-Maruyama scheme and an exact simulation algorithm for the Ornstein-Uhlenbeck process [@problem_id:3226711]. By running these simulations with coupled random numbers and comparing key path-dependent functionals, you will gain a tangible understanding of the practical differences between an approximate scheme and an exact one, and see the theoretical error manifest in concrete numerical results.", "problem": "You will implement and compare two discrete-time approximations for the Ornstein–Uhlenbeck process, starting from the defining stochastic differential equation (SDE) and core properties of linear SDEs and Gaussian processes. Consider the Ornstein–Uhlenbeck (OU) SDE\n$$\ndX_t = -\\lambda X_t \\, dt + \\sigma \\, dW_t, \\quad X_0 = x_0,\n$$\nwhere $W_t$ is a standard Wiener process (also called Brownian motion), $\\lambda \\ge 0$ is the mean-reversion rate, and $\\sigma \\ge 0$ is the volatility.\n\nStarting from the fundamental definition of the Euler–Maruyama (EM) method and the fact that the OU SDE is a linear SDE with Gaussian transition law over finite intervals, derive the following, without assuming any special-purpose formulas:\n- The Euler–Maruyama one-step recursion driven by increments of the Wiener process over a uniform time grid of step $ \\Delta t = T/N $, where $N$ is a positive integer.\n- The exact discrete-time transition law over a single step of length $\\Delta t$, obtained by solving the linear SDE and identifying the normal distribution of the stochastic integral. Ensure that your derivation includes the correct continuous limit as $\\lambda \\to 0$.\n\nThen, implement both schemes on the same discrete grid and couple them by using the same sequence of independent standard normal random variables $\\{\\xi_n\\}_{n=0}^{N-1}$ so that the Brownian increments satisfy $ \\Delta W_n = \\sqrt{\\Delta t}\\,\\xi_n $. For a path $\\{X_n\\}_{n=0}^{N}$ on the grid $t_n = n \\Delta t$, define the following path functionals:\n- Terminal value $X_N$ at time $T$.\n- Left Riemann sum approximation of the time integral $A = \\sum_{n=0}^{N-1} X_n \\,\\Delta t$.\n- Discrete quadratic variation $Q = \\sum_{n=0}^{N-1} (X_{n+1} - X_n)^2$.\n\nYour program must:\n- For each test case below, simulate one coupled pair of paths, one with Euler–Maruyama and one with the exact transition, using the same sequence $\\{\\xi_n\\}$ generated from a fixed pseudo-random seed. Use double precision arithmetic.\n- Compute the absolute differences between the two paths for the three path functionals, namely\n$$\nd_T = \\left|X_N^{\\text{EM}} - X_N^{\\text{Exact}}\\right|,\\quad\nd_A = \\left|A^{\\text{EM}} - A^{\\text{Exact}}\\right|,\\quad\nd_Q = \\left|Q^{\\text{EM}} - Q^{\\text{Exact}}\\right|.\n$$\n- Use numerically stable expressions for any formulas that can suffer from cancellation, and implement the correct small-$\\lambda$ limit for the exact transition to handle $\\lambda$ close to zero.\n\nTest suite. Run the three-metric evaluation for each of the following parameter sets $(x_0,\\lambda,\\sigma,T,N,\\text{seed})$:\n- Case $1$: $(x_0,\\lambda,\\sigma,T,N,\\text{seed}) = (\\,1.0,\\,0.7,\\,0.8,\\,2.0,\\,4096,\\,20231105\\,)$.\n- Case $2$: $(x_0,\\lambda,\\sigma,T,N,\\text{seed}) = (\\,1.0,\\,0.7,\\,0.8,\\,2.0,\\,8192,\\,42\\,)$.\n- Case $3$: $(x_0,\\lambda,\\sigma,T,N,\\text{seed}) = (\\,{-}0.2,\\,10.0,\\,0.5,\\,1.0,\\,5000,\\,7\\,)$.\n- Case $4$: $(x_0,\\lambda,\\sigma,T,N,\\text{seed}) = (\\,{-}0.3,\\,10^{-6},\\,1.2,\\,1.0,\\,4096,\\,999\\,)$.\n\nAll time is in abstract units; no physical units are required. Angles are not used in this problem. Percentages are not used.\n\nFinal output format. Your program should produce a single line of output containing a comma-separated list enclosed in square brackets with the twelve floating-point results in the following order:\n$$\n[\\,d_T^{(1)},\\,d_A^{(1)},\\,d_Q^{(1)},\\,d_T^{(2)},\\,d_A^{(2)},\\,d_Q^{(2)},\\,d_T^{(3)},\\,d_A^{(3)},\\,d_Q^{(3)},\\,d_T^{(4)},\\,d_A^{(4)},\\,d_Q^{(4)}\\,],\n$$\nwhere the superscript indicates the test case index. No additional text should be printed.", "solution": "The objective is to implement and compare two numerical schemes for the Ornstein-Uhlenbeck (OU) stochastic differential equation (SDE): the Euler-Maruyama method and a method based on the exact transition law. The comparison will be based on the absolute differences of three path functionals computed for a single realization of each process, coupled by using the same underlying sequence of random innovations.\n\nThe Ornstein-Uhlenbeck SDE is given by:\n$$\ndX_t = -\\lambda X_t dt + \\sigma dW_t, \\quad X_0 = x_0\n$$\nwhere $X_t$ is the state of the process, $\\lambda \\ge 0$ is the mean-reversion rate, $\\sigma \\ge 0$ is the volatility, and $W_t$ is a standard Wiener process.\n\n**Derivation of the Euler-Maruyama (EM) Scheme**\n\nThe Euler-Maruyama method is derived by constructing a forward-difference approximation of the SDE on a discrete time grid $t_n = n \\Delta t$ for $n=0, 1, \\dots, N$. The infinitesimal increments are approximated as:\n- $dt \\approx \\Delta t = t_{n+1} - t_n$\n- $dX_t \\approx X_{n+1} - X_n$\n- $dW_t \\approx W_{t_{n+1}} - W_{t_n} = \\Delta W_n$\n\nThe increment of the Wiener process, $\\Delta W_n$, is a random variable drawn from a normal distribution with mean $0$ and variance $\\Delta t$. We can therefore write $\\Delta W_n = \\sqrt{\\Delta t} \\xi_n$, where $\\xi_n$ is a standard normal random variable, $\\xi_n \\sim N(0, 1)$.\n\nSubstituting these approximations into the SDE yields the discrete recursion:\n$$\nX_{n+1} - X_n = -\\lambda X_n \\Delta t + \\sigma \\Delta W_n\n$$\nRearranging for $X_{n+1}$, we obtain the one-step recursion for the Euler-Maruyama scheme:\n$$\nX_{n+1} = X_n - \\lambda X_n \\Delta t + \\sigma \\sqrt{\\Delta t} \\xi_n = (1 - \\lambda \\Delta t) X_n + \\sigma \\sqrt{\\Delta t} \\xi_n\n$$\nThis formula is used to propagate the process from one time step to the next.\n\n**Derivation of the Exact Transition Law**\n\nThe OU SDE is a linear SDE and can be solved exactly. We rewrite the SDE as:\n$$\ndX_t + \\lambda X_t dt = \\sigma dW_t\n$$\nThis form suggests the use of an integrating factor, $I_t = e^{\\lambda t}$. Multiplying the SDE by $I_t$ is equivalent to considering the differential of the product $Y_t = e^{\\lambda t} X_t$. Using Itô's product rule:\n$$\nd(e^{\\lambda t} X_t) = (\\lambda e^{\\lambda t} dt) X_t + e^{\\lambda t} dX_t = e^{\\lambda t} (\\lambda X_t dt + dX_t)\n$$\nSubstituting from the SDE, we get:\n$$\nd(e^{\\lambda t} X_t) = e^{\\lambda t} (\\sigma dW_t) = \\sigma e^{\\lambda t} dW_t\n$$\nIntegrating both sides from time $t_n$ to $t_{n+1} = t_n + \\Delta t$:\n$$\n\\int_{t_n}^{t_{n+1}} d(e^{\\lambda s} X_s) = \\int_{t_n}^{t_{n+1}} \\sigma e^{\\lambda s} dW_s\n$$\n$$\ne^{\\lambda t_{n+1}} X_{t_{n+1}} - e^{\\lambda t_n} X_{t_n} = \\sigma \\int_{t_n}^{t_{n+1}} e^{\\lambda s} dW_s\n$$\nSolving for $X_{t_{n+1}}$ (denoted as $X_{n+1}$):\n$$\nX_{n+1} = e^{-\\lambda (t_{n+1} - t_n)} X_{t_n} + \\sigma \\int_{t_n}^{t_{n+1}} e^{-\\lambda(t_{n+1}-s)} dW_s\n$$\nThe second term is an Itô integral with a deterministic integrand. Such an integral is a normally distributed random variable with a mean of zero. Its variance is calculated using the Itô isometry:\n$$\n\\text{Var}\\left( \\sigma \\int_{t_n}^{t_{n+1}} e^{-\\lambda(t_{n+1}-s)} dW_s \\right) = \\sigma^2 \\int_{t_n}^{t_{n+1}} \\left( e^{-\\lambda(t_{n+1}-s)} \\right)^2 ds = \\sigma^2 \\int_{t_n}^{t_{n+1}} e^{-2\\lambda(t_{n+1}-s)} ds\n$$\nBy substituting $u = t_{n+1}-s$, the integral becomes $\\int_0^{\\Delta t} e^{-2\\lambda u} du$. Assuming $\\lambda  0$, this evaluates to:\n$$\n\\left[ \\frac{e^{-2\\lambda u}}{-2\\lambda} \\right]_0^{\\Delta t} = \\frac{e^{-2\\lambda \\Delta t} - 1}{-2\\lambda} = \\frac{1 - e^{-2\\lambda \\Delta t}}{2\\lambda}\n$$\nThe stochastic integral can thus be expressed as $\\sqrt{\\text{Var}} \\cdot \\xi_n$, where $\\xi_n \\sim N(0, 1)$. To couple the two schemes, we use the same $\\xi_n$ as in the EM method. The exact one-step recursion is:\n$$\nX_{n+1} = e^{-\\lambda \\Delta t} X_n + \\sigma \\sqrt{\\frac{1 - e^{-2\\lambda \\Delta t}}{2\\lambda}} \\xi_n\n$$\n\n**Numerical Stability and the Small-$\\lambda$ Limit**\n\nIn the limit $\\lambda \\to 0$, the SDE becomes $dX_t = \\sigma dW_t$, a scaled Brownian motion. The exact recursion should reflect this. As $\\lambda \\to 0$, $e^{-\\lambda \\Delta t} \\to 1$. The coefficient of $\\xi_n$ requires more care. Using the Taylor series $e^{-x} \\approx 1 - x$ for small $x$:\n$$\n\\lim_{\\lambda \\to 0} \\sigma \\sqrt{\\frac{1 - e^{-2\\lambda \\Delta t}}{2\\lambda}} = \\sigma \\sqrt{\\lim_{\\lambda \\to 0} \\frac{1 - (1 - 2\\lambda \\Delta t + O((\\lambda \\Delta t)^2))}{2\\lambda}} = \\sigma \\sqrt{\\lim_{\\lambda \\to 0} \\frac{2\\lambda \\Delta t}{2\\lambda}} = \\sigma \\sqrt{\\Delta t}\n$$\nThis matches the coefficient in the EM scheme for $\\lambda=0$. However, for small but non-zero $\\lambda$, direct computation of $\\frac{1-e^{-2\\lambda\\Delta t}}{2\\lambda}$ can lead to catastrophic cancellation because the numerator approaches zero. To ensure stability, we analyze the function $f(y) = \\frac{1-e^{-y}}{y}$ for small $y = 2\\lambda\\Delta t$. Its Taylor series expansion is $f(y) = 1 - \\frac{y}{2} + \\frac{y^2}{6} - \\dots$. This expansion is used for the variance calculation when the argument $2\\lambda\\Delta t$ is close to zero, preventing numerical instability. Specifically, the variance of the stochastic term can be computed as $\\sigma^2 \\Delta t \\cdot f(2\\lambda\\Delta t)$.\n\n**Simulation and Evaluation**\n\nFor each test case, we perform the following steps:\n1.  Set the parameters $(x_0, \\lambda, \\sigma, T, N, \\text{seed})$.\n2.  Calculate the time step $\\Delta t = T/N$.\n3.  Generate a single vector of $N$ standard normal random numbers, $\\{\\xi_n\\}_{n=0}^{N-1}$, using the specified seed.\n4.  Simultaneously simulate two paths, $\\{X_n^{\\text{EM}}\\}$ and $\\{X_n^{\\text{Exact}}\\}$, of length $N+1$, starting from $X_0 = x_0$ and using their respective recursion formulas with the same sequence $\\{\\xi_n\\}$.\n5.  Compute the three path functionals for each path:\n    -   Terminal value: $X_N = X[N]$\n    -   Integral approximation: $A = \\sum_{n=0}^{N-1} X_n \\Delta t$\n    -   Quadratic variation: $Q = \\sum_{n=0}^{N-1} (X_{n+1} - X_n)^2$\n6.  Calculate the absolute differences $d_T$, $d_A$, and $d_Q$ between the functionals for the EM and exact paths.\nThe final output aggregates these twelve difference values from the four test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares Euler-Maruyama and exact simulation schemes for the\n    Ornstein-Uhlenbeck process, computing differences in path functionals.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (x0, lambda, sigma, T, N, seed)\n        (1.0, 0.7, 0.8, 2.0, 4096, 20231105),\n        (1.0, 0.7, 0.8, 2.0, 8192, 42),\n        (-0.2, 10.0, 0.5, 1.0, 5000, 7),\n        (-0.3, 1e-6, 1.2, 1.0, 4096, 999),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        x0, lam, sigma, T, N, seed = case\n        \n        dt = T / N\n        \n        # Generate the common sequence of standard normal random variables\n        rng = np.random.default_rng(seed)\n        xi = rng.standard_normal(N)\n        \n        # Initialize path arrays with double precision floating point numbers\n        X_em = np.zeros(N + 1, dtype=np.float64)\n        X_exact = np.zeros(N + 1, dtype=np.float64)\n        X_em[0] = x0\n        X_exact[0] = x0\n        \n        # --- Coefficients for simulation step ---\n        # 1. Euler-Maruyama coefficients\n        em_drift_factor = 1.0 - lam * dt\n        em_diffusion_term = sigma * np.sqrt(dt)\n\n        # 2. Exact scheme coefficients\n        exact_drift_factor = np.exp(-lam * dt)\n        \n        # Numerically stable calculation for the exact diffusion term's standard deviation\n        # The variance is sigma^2 * (1 - exp(-2*lam*dt)) / (2*lam).\n        # Let arg = 2*lam*dt. The variance factor is (1 - exp(-arg)) / (2*lam).\n        arg = 2.0 * lam * dt\n        if np.abs(arg)  1e-8:\n            # Use Taylor expansion for variance term to avoid cancellation:\n            # (1-exp(-x))/x = 1 - x/2 + x^2/6 - ...\n            # The variance is sigma^2 * dt * (1 - arg/2 + arg^2/6 - ...)\n            var_factor = dt * (1.0 - arg / 2.0 + arg**2 / 6.0)\n        else:\n            var_factor = (1.0 - np.exp(-arg)) / (2.0 * lam)\n        \n        exact_diffusion_term = sigma * np.sqrt(var_factor)\n\n        # --- Simulation loop ---\n        for n in range(N):\n            # Euler-Maruyama step\n            X_em[n+1] = em_drift_factor * X_em[n] + em_diffusion_term * xi[n]\n            \n            # Exact propagator step\n            X_exact[n+1] = exact_drift_factor * X_exact[n] + exact_diffusion_term * xi[n]\n            \n        # --- Compute path functionals ---\n        # 1. Terminal value X_N\n        X_N_em = X_em[N]\n        X_N_exact = X_exact[N]\n        \n        # 2. Left Riemann sum approximation of the time integral A\n        A_em = np.sum(X_em[:-1]) * dt\n        A_exact = np.sum(X_exact[:-1]) * dt\n        \n        # 3. Discrete quadratic variation Q\n        Q_em = np.sum(np.diff(X_em)**2)\n        Q_exact = np.sum(np.diff(X_exact)**2)\n        \n        # --- Compute absolute differences ---\n        d_T = np.abs(X_N_em - X_N_exact)\n        d_A = np.abs(A_em - A_exact)\n        d_Q = np.abs(Q_em - Q_exact)\n        \n        results.extend([d_T, d_A, d_Q])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3226711"}]}