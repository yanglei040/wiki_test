{"hands_on_practices": [{"introduction": "The heart of any particle filter is the sequential importance sampling (SIS) step, where particles are first propagated according to a proposal distribution and then re-weighted based on new observations. This practice focuses on implementing this crucial one-step update for a nonlinear system, demonstrating how to correctly combine the transition dynamics, the observation likelihood, and the proposal distribution to compute the incremental weights [@problem_id:3338877]. You will also work with log-weights, a vital technique for maintaining numerical stability in real-world applications.", "problem": "Consider a hidden Markov model with latent state sequence $\\{x_t\\}_{t \\ge 0}$ and observations $\\{y_t\\}_{t \\ge 1}$, where the state transition is given by a Markov kernel with density $p(x_t \\mid x_{t-1})$ and the observation model is nonlinear with density $p(y_t \\mid x_t)$ induced by $y_t = h(x_t) + \\epsilon_t$ for a known function $h(\\cdot)$ and independent noise $\\epsilon_t$. Suppose that at time $t-1$ you have a weighted particle system $\\{x_{t-1}^{(i)}, w_{t-1}^{(i)}\\}_{i=1}^N$ that approximates the filtering distribution $p(x_{t-1} \\mid y_{1:t-1})$ by a weighted empirical measure. For the time-$t$ update, you sample $x_t^{(i)} \\sim q_t(\\cdot \\mid x_{t-1}^{(i)}, y_t)$ independently for $i = 1, \\dots, N$ from a proposal distribution $q_t$ and then compute normalized weights $\\tilde{w}_t^{(i)}$.\n\nStarting only from the principles of importance sampling and Bayes' rule, implement a one-step Sequential Importance Sampling (SIS) weight update for a single time step $t$ without resampling, for the specific case where:\n- The state transition density is Gaussian,\n$$\np(x_t \\mid x_{t-1}) = \\mathcal{N}\\!\\left(x_t; a x_{t-1} + b \\sin(x_{t-1}), \\sigma_x^2\\right),\n$$\n- The observation model is\n$$\ny_t = h(x_t) + \\epsilon_t, \\quad h(x) = \\tfrac{1}{2} x^2, \\quad \\epsilon_t \\sim \\mathcal{N}(0, \\sigma_y^2),\n$$\nso that\n$$\np(y_t \\mid x_t) = \\mathcal{N}\\!\\left(y_t; \\tfrac{1}{2} x_t^2, \\sigma_y^2\\right),\n$$\n- The proposal $q_t$ is either the transition (bootstrap proposal) or a Gaussian with mean depending on $x_{t-1}$,\n$$\nq_t(x_t \\mid x_{t-1}, y_t) =\n\\begin{cases}\n\\mathcal{N}\\!\\left(x_t; a x_{t-1} + b \\sin(x_{t-1}), \\sigma_x^2\\right),  \\text{bootstrap case},\\\\[4pt]\n\\mathcal{N}\\!\\left(x_t; a_p x_{t-1} + c x_{t-1}^3, \\sigma_q^2\\right),  \\text{general case}.\n\\end{cases}\n$$\n\nYour program must:\n- Use log-weights to maintain numerical stability, and then return normalized weights $\\tilde{w}_t^{(i)}$ by exponentiating and normalizing.\n- For each particle $i$, compute the unnormalized weight increment using the importance sampling principle applied to the target $p(x_t, x_{t-1} \\mid y_{1:t})$ and proposal $q_t(x_t \\mid x_{t-1}, y_t)$.\n- Normalize the weights so that $\\sum_{i=1}^N \\tilde{w}_t^{(i)} = 1$.\n\nYou must implement and evaluate the update for the following test suite. In each case, use the specified random seed to generate the proposals $x_t^{(i)}$ reproducibly. All arrays and constants are given in exact values that must be used unchanged. The function $h(x)$ is fixed as $h(x) = \\tfrac{1}{2} x^2$ in all cases.\n\nTest case A (general proposal, moderate regime):\n- Number of particles $N = 5$,\n- Previous particles $x_{t-1}^{(i)}$ set to $[-1.0, -0.2, 0.3, 1.0, 2.0]$,\n- Previous normalized weights $w_{t-1}^{(i)}$ set to $[0.1, 0.2, 0.4, 0.2, 0.1]$,\n- Parameters: $a = 0.7$, $b = 0.3$, $\\sigma_x = 0.5$, $\\sigma_y = 0.8$,\n- Proposal parameters (general): $a_p = 0.5$, $c = -0.1$, $\\sigma_q = 0.7$,\n- Observation $y_t = 1.25$,\n- Random seed $= 123$.\n\nTest case B (bootstrap proposal, random-walk transition):\n- Number of particles $N = 4$,\n- Previous particles $x_{t-1}^{(i)}$ set to $[-0.5, 0.0, 0.5, 1.5]$,\n- Previous normalized weights $w_{t-1}^{(i)}$ set to $[0.25, 0.25, 0.25, 0.25]$,\n- Parameters: $a = 1.0$, $b = 0.0$, $\\sigma_x = 0.3$, $\\sigma_y = 0.4$,\n- Proposal: bootstrap (i.e., equal to transition),\n- Observation $y_t = 0.5$,\n- Random seed $= 7$.\n\nTest case C (general proposal, near-degenerate likelihood regime):\n- Number of particles $N = 3$,\n- Previous particles $x_{t-1}^{(i)}$ set to $[-2.0, 0.0, 2.0]$,\n- Previous normalized weights $w_{t-1}^{(i)}$ set to $[0.2, 0.6, 0.2]$,\n- Parameters: $a = 0.9$, $b = 0.1$, $\\sigma_x = 0.2$, $\\sigma_y = 0.05$,\n- Proposal parameters (general): $a_p = 0.9$, $c = 0.0$, $\\sigma_q = 1.0$,\n- Observation $y_t = 10.0$,\n- Random seed $= 42$.\n\nTest case D (single-particle edge case):\n- Number of particles $N = 1$,\n- Previous particles $x_{t-1}^{(i)}$ set to $[0.3]$,\n- Previous normalized weights $w_{t-1}^{(i)}$ set to $[1.0]$,\n- Parameters: $a = 0.5$, $b = 0.5$, $\\sigma_x = 1.2$, $\\sigma_y = 0.3$,\n- Proposal parameters (general): $a_p = 0.5$, $c = 0.0$, $\\sigma_q = 0.8$,\n- Observation $y_t = 0.1$,\n- Random seed $= 99$.\n\nYour program must implement the sampling and weight update exactly as described for each test case. The final output format must be a single line containing the concatenated normalized weights across all test cases in order A, B, C, D, as a comma-separated list enclosed in square brackets. Each floating-point number must be rounded to exactly $10$ decimal places. For example, an output with two numbers would look like $[0.1234567890,0.8765432110]$. There are no physical units or angles involved, so no unit conversions are needed. The required data types for the final answers are floating-point numbers, and the final output is a single list of such floats.", "solution": "The present task is to implement a one-step weight update for a Sequential Importance Sampling (SIS) particle filter. The derivation of the update rule must be grounded in the fundamental principles of Bayesian inference and importance sampling.\n\nWe consider a state-space model defined by a latent state process $\\{x_t\\}_{t \\ge 0}$ and an observation process $\\{y_t\\}_{t \\ge 1}$. The model is specified by:\n1.  An initial distribution $p(x_0)$.\n2.  A state transition model with density $p(x_t \\mid x_{t-1})$.\n3.  An observation model with density $p(y_t \\mid x_t)$.\n\nThe objective of filtering is to recursively compute the posterior distribution of the state $x_t$ given all observations up to time $t$, denoted as $p(x_t \\mid y_{1:t})$. The Bayesian filtering recursion proceeds in two steps: prediction and update.\n\nThe prediction step evolves the previous filtering distribution $p(x_{t-1} \\mid y_{1:t-1})$ through the state dynamics to obtain the predictive distribution for $x_t$:\n$$\np(x_t \\mid y_{1:t-1}) = \\int p(x_t \\mid x_{t-1}) p(x_{t-1} \\mid y_{1:t-1}) dx_{t-1}\n$$\nThe update step then incorporates the new observation $y_t$ via Bayes' rule:\n$$\np(x_t \\mid y_{1:t}) = \\frac{p(y_t \\mid x_t) p(x_t \\mid y_{1:t-1})}{p(y_t \\mid y_{1:t-1})} \\propto p(y_t \\mid x_t) p(x_t \\mid y_{1:t-1})\n$$\nFor nonlinear and/or non-Gaussian models, these steps are typically analytically intractable. SIS provides a numerical approximation.\n\nAt time $t-1$, we assume the filtering distribution is approximated by a weighted empirical measure:\n$$\np(x_{t-1} \\mid y_{1:t-1}) \\approx \\sum_{i=1}^N w_{t-1}^{(i)} \\delta_{x_{t-1}^{(i)}}(x_{t-1})\n$$\nwhere $\\{x_{t-1}^{(i)}\\}_{i=1}^N$ are the particles, $\\{w_{t-1}^{(i)}\\}_{i=1}^N$ are their corresponding normalized weights ($\\sum_i w_{t-1}^{(i)} = 1$), and $\\delta_a(x)$ is the Dirac delta measure at $a$.\n\nTo approximate the time-$t$ distribution $p(x_t \\mid y_{1:t})$, we can apply importance sampling. The target distribution for the SIS update is proportional to $p(y_t \\mid x_t) p(x_t \\mid x_{t-1}) p(x_{t-1} \\mid y_{1:t-1})$. We draw a new set of particles $\\{x_t^{(i)}\\}_{i=1}^N$ from a proposal distribution $q_t(x_t \\mid x_{t-1}, y_t)$. For each existing particle path ending at $x_{t-1}^{(i)}$, we sample a new state $x_t^{(i)} \\sim q_t(\\cdot \\mid x_{t-1}^{(i)}, y_t)$.\n\nThe importance weight for the state trajectory is updated recursively. The weight $w_t^{(i)}$ for the path ending at $(x_{t-1}^{(i)}, x_t^{(i)})$ is given by:\n$$\nw_t^{(i)} \\propto w_{t-1}^{(i)} \\times \\alpha_t^{(i)}\n$$\nwhere $\\alpha_t^{(i)}$ is the incremental importance weight. This incremental weight corrects for the discrepancy between the target dynamics and the proposal distribution. It is defined as the ratio of the target density to the proposal density:\n$$\n\\alpha_t^{(i)} = \\frac{p(y_t \\mid x_t^{(i)}) p(x_t^{(i)} \\mid x_{t-1}^{(i)})}{q_t(x_t^{(i)} \\mid x_{t-1}^{(i)}, y_t)}\n$$\nThe new unnormalized weights are $w_t^{\\prime(i)} = w_{t-1}^{(i)} \\alpha_t^{(i)}$. These are then normalized to sum to one: $\\tilde{w}_t^{(i)} = w_t^{\\prime(i)} / \\sum_{j=1}^N w_t^{\\prime(j)}$.\n\nFor improved numerical stability, especially when dealing with products of small probabilities, computations are performed in the log-domain. The unnormalized log-weight is:\n$$\n\\log w_t^{\\prime(i)} = \\log w_{t-1}^{(i)} + \\log \\alpha_t^{(i)}\n$$\nwhere the log-incremental weight is:\n$$\n\\log \\alpha_t^{(i)} = \\log p(y_t \\mid x_t^{(i)}) + \\log p(x_t^{(i)} \\mid x_{t-1}^{(i)}) - \\log q_t(x_t^{(i)} \\mid x_{t-1}^{(i)}, y_t)\n$$\nThe log-probability density of a Gaussian distribution $\\mathcal{N}(x; \\mu, \\sigma^2)$ is given by:\n$$\n\\log \\mathcal{N}(x; \\mu, \\sigma^2) = -\\frac{(x-\\mu)^2}{2\\sigma^2} - \\frac{1}{2}\\log(2\\pi\\sigma^2)\n$$\nApplying this to the problem-specific densities:\n1.  **Log-Likelihood:** From $p(y_t \\mid x_t) = \\mathcal{N}(y_t; \\tfrac{1}{2} x_t^2, \\sigma_y^2)$, we have:\n    $$\n    \\log p(y_t \\mid x_t^{(i)}) = -\\frac{(y_t - \\frac{1}{2}(x_t^{(i)})^2)^2}{2\\sigma_y^2} - \\frac{1}{2}\\log(2\\pi\\sigma_y^2)\n    $$\n2.  **Log-Transition:** From $p(x_t \\mid x_{t-1}) = \\mathcal{N}(x_t; a x_{t-1} + b \\sin(x_{t-1}), \\sigma_x^2)$, let $\\mu_{trans}^{(i)} = a x_{t-1}^{(i)} + b \\sin(x_{t-1}^{(i)})$. Then:\n    $$\n    \\log p(x_t^{(i)} \\mid x_{t-1}^{(i)}) = -\\frac{(x_t^{(i)} - \\mu_{trans}^{(i)})^2}{2\\sigma_x^2} - \\frac{1}{2}\\log(2\\pi\\sigma_x^2)\n    $$\n3.  **Log-Proposal:** The proposal $q_t$ has two forms.\n    - **General Case:** $q_t(x_t \\mid x_{t-1}, y_t) = \\mathcal{N}(x_t; a_p x_{t-1} + c x_{t-1}^3, \\sigma_q^2)$. Let $\\mu_{prop}^{(i)} = a_p x_{t-1}^{(i)} + c (x_{t-1}^{(i)})^3$. Then:\n      $$\n      \\log q_t(x_t^{(i)} \\mid x_{t-1}^{(i)}, y_t) = -\\frac{(x_t^{(i)} - \\mu_{prop}^{(i)})^2}{2\\sigma_q^2} - \\frac{1}{2}\\log(2\\pi\\sigma_q^2)\n      $$\n    - **Bootstrap Case:** The proposal is the state transition prior, $q_t(x_t \\mid x_{t-1}, y_t) = p(x_t \\mid x_{t-1})$. In this case, $\\mu_{prop}^{(i)} = \\mu_{trans}^{(i)}$ and $\\sigma_q^2 = \\sigma_x^2$. The log-transition and log-proposal terms cancel out, simplifying the log-incremental weight to just the log-likelihood:\n      $$\n      \\log \\alpha_t^{(i)} = \\log p(y_t \\mid x_t^{(i)})\n      $$\n\nFinally, to convert the unnormalized log-weights $\\log w_t^{\\prime(i)}$ back to normalized weights $\\tilde{w}_t^{(i)}$, we use the log-sum-exp trick to prevent numerical overflow and underflow. Let $L_i = \\log w_t^{\\prime(i)}$ and $L_{max} = \\max_j L_j$. Then:\n$$\n\\tilde{w}_t^{(i)} = \\frac{\\exp(L_i)}{\\sum_{j=1}^N \\exp(L_j)} = \\frac{\\exp(L_i - L_{max})}{\\sum_{j=1}^N \\exp(L_j - L_{max})}\n$$\nThis procedure provides a numerically stable method for performing the one-step SIS update. The implementation will follow these derived formulas for each test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases for the SIS weight update.\n    \"\"\"\n    test_cases = [\n        # Test case A (general proposal, moderate regime)\n        {\n            \"N\": 5,\n            \"x_tm1\": np.array([-1.0, -0.2, 0.3, 1.0, 2.0]),\n            \"w_tm1\": np.array([0.1, 0.2, 0.4, 0.2, 0.1]),\n            \"a\": 0.7, \"b\": 0.3, \"sigma_x\": 0.5, \"sigma_y\": 0.8,\n            \"proposal_type\": \"general\",\n            \"a_p\": 0.5, \"c\": -0.1, \"sigma_q\": 0.7,\n            \"y_t\": 1.25,\n            \"seed\": 123\n        },\n        # Test case B (bootstrap proposal, random-walk transition)\n        {\n            \"N\": 4,\n            \"x_tm1\": np.array([-0.5, 0.0, 0.5, 1.5]),\n            \"w_tm1\": np.array([0.25, 0.25, 0.25, 0.25]),\n            \"a\": 1.0, \"b\": 0.0, \"sigma_x\": 0.3, \"sigma_y\": 0.4,\n            \"proposal_type\": \"bootstrap\",\n            \"a_p\": None, \"c\": None, \"sigma_q\": None, # Will be set from transition\n            \"y_t\": 0.5,\n            \"seed\": 7\n        },\n        # Test case C (general proposal, near-degenerate likelihood regime)\n        {\n            \"N\": 3,\n            \"x_tm1\": np.array([-2.0, 0.0, 2.0]),\n            \"w_tm1\": np.array([0.2, 0.6, 0.2]),\n            \"a\": 0.9, \"b\": 0.1, \"sigma_x\": 0.2, \"sigma_y\": 0.05,\n            \"proposal_type\": \"general\",\n            \"a_p\": 0.9, \"c\": 0.0, \"sigma_q\": 1.0,\n            \"y_t\": 10.0,\n            \"seed\": 42\n        },\n        # Test case D (single-particle edge case)\n        {\n            \"N\": 1,\n            \"x_tm1\": np.array([0.3]),\n            \"w_tm1\": np.array([1.0]),\n            \"a\": 0.5, \"b\": 0.5, \"sigma_x\": 1.2, \"sigma_y\": 0.3,\n            \"proposal_type\": \"general\",\n            \"a_p\": 0.5, \"c\": 0.0, \"sigma_q\": 0.8,\n            \"y_t\": 0.1,\n            \"seed\": 99\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        # Extract parameters\n        N = case[\"N\"]\n        x_tm1 = case[\"x_tm1\"]\n        w_tm1 = case[\"w_tm1\"]\n        a, b, sigma_x, sigma_y = case[\"a\"], case[\"b\"], case[\"sigma_x\"], case[\"sigma_y\"]\n        y_t = case[\"y_t\"]\n        seed = case[\"seed\"]\n        \n        # Set up random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # Define proposal parameters based on type\n        if case[\"proposal_type\"] == \"bootstrap\":\n            # For bootstrap, proposal is the transition prior\n            a_p, c, sigma_q = a, 0.0, sigma_x\n            if b != 0: # need to handle sin term if b is not 0\n                mu_prop_trans_part = b * np.sin(x_tm1)\n            else:\n                mu_prop_trans_part = 0\n            mu_prop = a_p * x_tm1 + mu_prop_trans_part\n        else: # general\n            a_p, c, sigma_q = case[\"a_p\"], case[\"c\"], case[\"sigma_q\"]\n            mu_prop = a_p * x_tm1 + c * x_tm1**3\n\n        # 1. Sample new particles x_t from the proposal distribution q_t\n        # sample new particles\n        x_t = mu_prop + sigma_q * rng.standard_normal(size=N)\n\n        # 2. Compute importance weights in log-domain\n        # Log of previous weights\n        # np.log can produce -inf for w=0, but all given weights are > 0.\n        log_w_tm1 = np.log(w_tm1)\n\n        # Calculate the three components of the log-incremental weight\n        # a) Log-likelihood: log p(y_t | x_t)\n        log_p_yt_xt = norm.logpdf(y_t, loc=0.5 * x_t**2, scale=sigma_y)\n        \n        # b) Log-transition: log p(x_t | x_{t-1})\n        mu_trans = a * x_tm1 + b * np.sin(x_tm1)\n        log_p_xt_xtm1 = norm.logpdf(x_t, loc=mu_trans, scale=sigma_x)\n\n        # c) Log-proposal: log q(x_t | x_{t-1}, y_t)\n        # The means mu_prop were already computed for sampling\n        log_q_xt = norm.logpdf(x_t, loc=mu_prop, scale=sigma_q)\n        \n        # Log-incremental weight\n        log_alpha_t = log_p_yt_xt + log_p_xt_xtm1 - log_q_xt\n\n        # Unnormalized log-weights at time t\n        log_w_t_unnormalized = log_w_tm1 + log_alpha_t\n        \n        # 3. Normalize weights using log-sum-exp trick for numerical stability\n        if N > 0:\n            log_w_max = np.max(log_w_t_unnormalized)\n            # Subtract max for stability, then exponentiate\n            w_t_shifted = np.exp(log_w_t_unnormalized - log_w_max)\n            # Normalize\n            w_t_normalized = w_t_shifted / np.sum(w_t_shifted)\n        else:\n            w_t_normalized = np.array([])\n            \n        # Append formatted results to the final list\n        for w in w_t_normalized:\n            all_results.append(f\"{w:.10f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3338877"}, {"introduction": "After updating weights, a critical question arises: how healthy is our particle system? A common issue, known as weight degeneracy, is when a few particles have very high weights while the rest are negligible, rendering the approximation inefficient. This practice introduces the Effective Sample Size (ESS), a key diagnostic for quantifying this problem, and guides you through deriving its formula from first principles [@problem_id:3338911]. By computing the ESS for a given set of weights, you will learn the standard criterion for deciding when the crucial resampling step is necessary to rejuvenate the particle population.", "problem": "In a Sequential Importance Resampling (SIR) bootstrap filter, a particular time step $t$ yields a particle system with $N = 5$ particles $\\{X_{t}^{(i)}\\}_{i=1}^{5}$ and associated unnormalized importance weights $\\{w_{t}^{(i)}\\}_{i=1}^{5}$. These unnormalized weights are known only up to an unknown positive scale factor $k  0$, and their values are\n$$\nw_{t}^{(1)} = 3k,\\quad w_{t}^{(2)} = 0,\\quad w_{t}^{(3)} = k,\\quad w_{t}^{(4)} = k,\\quad w_{t}^{(5)} = 5k.\n$$\nLet $\\tilde{w}_{t}^{(i)} = w_{t}^{(i)}\\big/\\sum_{j=1}^{N} w_{t}^{(j)}$ denote the normalized weights. The self-normalized importance sampling estimator for a bounded test function $h$ is\n$$\n\\hat{I}_{t}(h) = \\sum_{i=1}^{N} \\tilde{w}_{t}^{(i)}\\, h\\!\\left(X_{t}^{(i)}\\right).\n$$\nStart from the foundational definition of Effective Sample Size (ESS) as the unique $N_{\\mathrm{eff}}$ such that the variance of $\\hat{I}_{t}(h)$ under independence and identical variance assumptions matches the variance of a standard Monte Carlo estimator based on $N_{\\mathrm{eff}}$ equally weighted and independent samples. Using only this definition and standard variance properties of independent sums, first derive an expression for $N_{\\mathrm{eff}}$ in terms of the normalized weights $\\{\\tilde{w}_{t}^{(i)}\\}_{i=1}^{N}$. Then use your expression to compute $N_{\\mathrm{eff}}$ for the given weight vector above, explicitly showing that it is invariant to the unknown scale factor $k$. \n\nThe algorithmâ€™s resampling rule at time $t$ is to trigger resampling if and only if $N_{\\mathrm{eff}}  \\tau_{t}$, where the threshold is $\\tau_{t} = \\alpha N$ with $\\alpha = \\tfrac{1}{2}$. Determine whether resampling should be performed at this time $t$ according to this rule.\n\nExpress your final answer as the exact value of $N_{\\mathrm{eff}}$ written as a reduced fraction, with no units. Do not include the resampling decision in your final numeric answer.", "solution": "The problem is first validated to ensure it is scientifically sound, well-posed, and objective.\n\n### Step 1: Extract Givens\n- Number of particles: $N = 5$\n- Unnormalized importance weights: $\\{w_{t}^{(i)}\\}_{i=1}^{5}$, with values $w_{t}^{(1)} = 3k$, $w_{t}^{(2)} = 0$, $w_{t}^{(3)} = k$, $w_{t}^{(4)} = k$, $w_{t}^{(5)} = 5k$, where $k  0$ is an unknown positive scale factor.\n- Normalized weights: $\\tilde{w}_{t}^{(i)} = w_{t}^{(i)}\\big/\\sum_{j=1}^{N} w_{t}^{(j)}$.\n- Self-normalized importance sampling estimator: $\\hat{I}_{t}(h) = \\sum_{i=1}^{N} \\tilde{w}_{t}^{(i)}\\, h\\!\\left(X_{t}^{(i)}\\right)$ for a bounded test function $h$.\n- Foundational definition of Effective Sample Size ($N_{\\mathrm{eff}}$): $N_{\\mathrm{eff}}$ is the unique value such that the variance of $\\hat{I}_{t}(h)$ under independence and identical variance assumptions matches the variance of a standard Monte Carlo estimator based on $N_{\\mathrm{eff}}$ equally weighted and independent samples.\n- Resampling rule: Resample if $N_{\\mathrm{eff}}  \\tau_{t}$.\n- Resampling threshold: $\\tau_{t} = \\alpha N$ with $\\alpha = \\tfrac{1}{2}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard exercise in the field of Sequential Monte Carlo methods (particle filters). It asks for the derivation of a fundamental quantity, the Effective Sample Size (ESS), from its conceptual definition and its subsequent calculation for a given set of parameters. All concepts (importance weights, self-normalized estimator, ESS, resampling) are standard and well-defined in the literature. The problem is self-contained, mathematically consistent, and free of any scientific or logical flaws. The provided values are for a typical \"toy\" example used in teaching this subject.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. A full solution will be provided.\n\n### Derivation of the Effective Sample Size ($N_{\\mathrm{eff}}$)\n\nThe problem requires deriving the expression for $N_{\\mathrm{eff}}$ starting from its foundational definition. We are given the self-normalized importance sampling estimator:\n$$\n\\hat{I}_{t}(h) = \\sum_{i=1}^{N} \\tilde{w}_{t}^{(i)}\\, h\\!\\left(X_{t}^{(i)}\\right)\n$$\nTo find its variance, we treat the normalized weights $\\{\\tilde{w}_{t}^{(i)}\\}$ as fixed constants and the particles $\\{X_{t}^{(i)}\\}$ as having been drawn independently. This implies that the random variables $h(X_{t}^{(i)})$ are independent. The problem states to assume they have an identical variance, which we denote as $\\sigma^2 = \\mathrm{Var}(h(X_{t}^{(i)}))$.\n\nUsing the property of variance for a weighted sum of independent random variables, $\\mathrm{Var}(\\sum a_i Y_i) = \\sum a_i^2 \\mathrm{Var}(Y_i)$, we have:\n$$\n\\mathrm{Var}(\\hat{I}_{t}(h)) = \\mathrm{Var}\\left(\\sum_{i=1}^{N} \\tilde{w}_{t}^{(i)}\\, h(X_{t}^{(i)})\\right) = \\sum_{i=1}^{N} (\\tilde{w}_{t}^{(i)})^2 \\mathrm{Var}(h(X_{t}^{(i)}))\n$$\nApplying the identical variance assumption:\n$$\n\\mathrm{Var}(\\hat{I}_{t}(h)) = \\sum_{i=1}^{N} (\\tilde{w}_{t}^{(i)})^2 \\sigma^2 = \\sigma^2 \\sum_{i=1}^{N} (\\tilde{w}_{t}^{(i)})^2\n$$\nNext, consider a standard Monte Carlo estimator for the same quantity, but based on $N_{\\mathrm{eff}}$ independent and identically distributed samples $\\{Y_j\\}_{j=1}^{N_{\\mathrm{eff}}}$ drawn directly from the target distribution. This estimator is the sample mean:\n$$\n\\hat{J}_{N_{\\mathrm{eff}}}(h) = \\frac{1}{N_{\\mathrm{eff}}} \\sum_{j=1}^{N_{\\mathrm{eff}}} h(Y_j)\n$$\nThe variance of this standard estimator, assuming $\\mathrm{Var}(h(Y_j)) = \\sigma^2$, is:\n$$\n\\mathrm{Var}(\\hat{J}_{N_{\\mathrm{eff}}}(h)) = \\mathrm{Var}\\left(\\frac{1}{N_{\\mathrm{eff}}} \\sum_{j=1}^{N_{\\mathrm{eff}}} h(Y_j)\\right) = \\frac{1}{(N_{\\mathrm{eff}})^2} \\sum_{j=1}^{N_{\\mathrm{eff}}} \\mathrm{Var}(h(Y_j)) = \\frac{1}{(N_{\\mathrm{eff}})^2} N_{\\mathrm{eff}} \\sigma^2 = \\frac{\\sigma^2}{N_{\\mathrm{eff}}}\n$$\nThe definition of $N_{\\mathrm{eff}}$ requires that these two variances be equal:\n$$\n\\mathrm{Var}(\\hat{I}_{t}(h)) = \\mathrm{Var}(\\hat{J}_{N_{\\mathrm{eff}}}(h))\n$$\n$$\n\\sigma^2 \\sum_{i=1}^{N} (\\tilde{w}_{t}^{(i)})^2 = \\frac{\\sigma^2}{N_{\\mathrm{eff}}}\n$$\nAssuming a non-trivial test function $h$ such that $\\sigma^2 > 0$, we can divide both sides by $\\sigma^2$:\n$$\n\\sum_{i=1}^{N} (\\tilde{w}_{t}^{(i)})^2 = \\frac{1}{N_{\\mathrm{eff}}}\n$$\nSolving for $N_{\\mathrm{eff}}$ yields the desired expression:\n$$\nN_{\\mathrm{eff}} = \\frac{1}{\\sum_{i=1}^{N} (\\tilde{w}_{t}^{(i)})^2}\n$$\n\n### Calculation of $N_{\\mathrm{eff}}$ and Resampling Decision\n\nWe are given $N=5$ and the unnormalized weights:\n$w_{t}^{(1)} = 3k$, $w_{t}^{(2)} = 0$, $w_{t}^{(3)} = k$, $w_{t}^{(4)} = k$, $w_{t}^{(5)} = 5k$.\n\nFirst, we calculate the sum of the unnormalized weights, which is the normalization constant:\n$$\n\\sum_{j=1}^{5} w_{t}^{(j)} = 3k + 0 + k + k + 5k = 10k\n$$\nNext, we compute the normalized weights $\\tilde{w}_{t}^{(i)} = w_{t}^{(i)} / \\sum_{j=1}^{5} w_{t}^{(j)}$:\n$$\n\\tilde{w}_{t}^{(1)} = \\frac{3k}{10k} = \\frac{3}{10}\n$$\n$$\n\\tilde{w}_{t}^{(2)} = \\frac{0}{10k} = 0\n$$\n$$\n\\tilde{w}_{t}^{(3)} = \\frac{k}{10k} = \\frac{1}{10}\n$$\n$$\n\\tilde{w}_{t}^{(4)} = \\frac{k}{10k} = \\frac{1}{10}\n$$\n$$\n\\tilde{w}_{t}^{(5)} = \\frac{5k}{10k} = \\frac{5}{10} = \\frac{1}{2}\n$$\nAs shown, the unknown scale factor $k>0$ cancels out in the normalization process, demonstrating that the normalized weights, and consequently $N_{\\mathrm{eff}}$, are invariant to this factor.\n\nNow, we compute the sum of the squares of the normalized weights:\n$$\n\\sum_{i=1}^{5} (\\tilde{w}_{t}^{(i)})^2 = \\left(\\frac{3}{10}\\right)^2 + 0^2 + \\left(\\frac{1}{10}\\right)^2 + \\left(\\frac{1}{10}\\right)^2 + \\left(\\frac{1}{2}\\right)^2\n$$\n$$\n= \\frac{9}{100} + 0 + \\frac{1}{100} + \\frac{1}{100} + \\frac{1}{4} = \\frac{9}{100} + \\frac{1}{100} + \\frac{1}{100} + \\frac{25}{100}\n$$\n$$\n= \\frac{9+1+1+25}{100} = \\frac{36}{100}\n$$\nUsing the derived formula for $N_{\\mathrm{eff}}$:\n$$\nN_{\\mathrm{eff}} = \\frac{1}{\\sum_{i=1}^{5} (\\tilde{w}_{t}^{(i)})^2} = \\frac{1}{36/100} = \\frac{100}{36}\n$$\nReducing the fraction to its simplest form:\n$$\nN_{\\mathrm{eff}} = \\frac{100 \\div 4}{36 \\div 4} = \\frac{25}{9}\n$$\n\nFinally, we determine whether resampling should be performed. The resampling threshold is $\\tau_{t} = \\alpha N$ with $\\alpha = \\frac{1}{2}$ and $N=5$:\n$$\n\\tau_{t} = \\frac{1}{2} \\times 5 = \\frac{5}{2}\n$$\nThe rule is to resample if $N_{\\mathrm{eff}}  \\tau_{t}$. We compare our calculated $N_{\\mathrm{eff}}$ with the threshold $\\tau_t$:\n$$\nN_{\\mathrm{eff}} = \\frac{25}{9} \\quad \\text{and} \\quad \\tau_{t} = \\frac{5}{2}\n$$\nTo compare these fractions, we can find a common denominator, which is $18$:\n$$\nN_{\\mathrm{eff}} = \\frac{25 \\times 2}{9 \\times 2} = \\frac{50}{18}\n$$\n$$\n\\tau_{t} = \\frac{5 \\times 9}{2 \\times 9} = \\frac{45}{18}\n$$\nSince $\\frac{50}{18}  \\frac{45}{18}$, we have $N_{\\mathrm{eff}}  \\tau_{t}$. The condition for resampling ($N_{\\mathrm{eff}}  \\tau_{t}$) is not met. Therefore, resampling should not be performed at time $t$.\n\nThe final answer required is the exact value of $N_{\\mathrm{eff}}$ as a reduced fraction.", "answer": "$$\\boxed{\\frac{25}{9}}$$", "id": "3338911"}, {"introduction": "Now it's time to assemble the individual components into a complete, functioning bootstrap filter. This capstone exercise guides you through implementing the full recursive algorithm, combining the propagation and weighting steps with a resampling procedure to maintain a healthy particle set over time [@problem_id:3338910]. The true test of any approximation method is to compare it against a known ground truth; here, you will assess your filter's performance by running it on a linear Gaussian system where the exact posterior distribution is provided by the Kalman filter, allowing for a direct and quantitative evaluation of the filter's accuracy.", "problem": "Consider a scalar linear Gaussian state-space model defined by the following generative process: for time index $t \\in \\{1,2,\\dots,T\\}$, the latent state $x_t$ and the observation $y_t$ evolve according to\n$$\nx_t = a\\,x_{t-1} + u_t,\\quad u_t \\sim \\mathcal{N}(0,q),\n$$\n$$\ny_t = c\\,x_t + v_t,\\quad v_t \\sim \\mathcal{N}(0,r),\n$$\nwith an initial prior $x_0 \\sim \\mathcal{N}(m_0,P_0)$. The goal is to approximate the filtering distribution $p(x_t \\mid y_{1:t})$ at a fixed time $t$ using Sequential Importance Resampling (SIR), also known as the bootstrap filter, and compare its particle-based posterior mean and variance to those produced by the exact Kalman filter for this model.\n\nStarting from the foundational Bayesian filtering recursion for the posterior,\n$$\np(x_t \\mid y_{1:t}) \\propto p(y_t \\mid x_t)\\int p(x_t \\mid x_{t-1})\\,p(x_{t-1} \\mid y_{1:t-1})\\,dx_{t-1},\n$$\ndesign and implement an algorithm that:\n- Generates a single realization of the latent state and observation sequences of length $T$ for specified parameters $(a,c,q,r,m_0,P_0)$ using a fixed random seed.\n- Implements the bootstrap filter with a proposal equal to the transition prior $p(x_t \\mid x_{t-1})$ and multinomial resampling at each time step. At time $t$, compute the particle-based posterior mean and variance of $p(x_t \\mid y_{1:t})$ from the normalized importance weights before resampling.\n- Implements the exact Kalman filter for the same model and computes the exact posterior mean and variance at time $t$ given $y_{1:t}$.\n- Computes the absolute errors between the particle-based posterior mean and variance and the Kalman filter posterior mean and variance at time $t$.\n\nYour program must evaluate the following test suite. For each case, simulate a single trajectory under the specified parameters and seed, then perform the described comparison at the specified time $t$. Use independent random number generation for the simulation and for the particle filter by offsetting the seed by $+1$ for the particle filter.\n\nTest Suite (each case specifies $(a,c,q,r,m_0,P_0,T,t,N,\\text{seed})$):\n1. Happy path, moderate noise, large particle count: $(a,c,q,r,m_0,P_0,T,t,N,\\text{seed}) = (0.9,\\,1.0,\\,0.5,\\,0.5,\\,0.0,\\,1.0,\\,25,\\,25,\\,1000,\\,11)$.\n2. Boundary case, very few particles (degeneracy stress test): $(a,c,q,r,m_0,P_0,T,t,N,\\text{seed}) = (0.9,\\,1.0,\\,0.5,\\,0.5,\\,0.0,\\,1.0,\\,25,\\,25,\\,10,\\,11)$ with the same simulated data as in case $1$ (same seed), but a smaller particle count.\n3. High observation noise scenario: $(a,c,q,r,m_0,P_0,T,t,N,\\text{seed}) = (0.9,\\,1.0,\\,0.5,\\,3.0,\\,0.0,\\,1.0,\\,25,\\,25,\\,500,\\,22)$.\n4. Nearly deterministic observations (very small observation noise): $(a,c,q,r,m_0,P_0,T,t,N,\\text{seed}) = (0.9,\\,1.0,\\,0.5,\\,0.01,\\,0.0,\\,1.0,\\,25,\\,25,\\,200,\\,33)$.\n\nFor each case, your program should compute two quantities: the absolute mean error $| \\hat{\\mu}_t - m_t |$ and the absolute variance error $| \\hat{V}_t - P_t |$, where $\\hat{\\mu}_t$ and $\\hat{V}_t$ are the particle-based posterior mean and variance at time $t$, and $m_t$ and $P_t$ are the Kalman filter posterior mean and variance at time $t$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, in the order of the test suite and within each case as $(\\text{mean error}, \\text{variance error})$. For example, the final output must have the form\n$$\n[\\text{err\\_mean\\_case1},\\text{err\\_var\\_case1},\\text{err\\_mean\\_case2},\\text{err\\_var\\_case2},\\text{err\\_mean\\_case3},\\text{err\\_var\\_case3},\\text{err\\_mean\\_case4},\\text{err\\_var\\_case4}]\n$$\nwith each entry a real number.", "solution": "The user wants to solve the problem by following these steps:\n1.  **Problem Validation**: First, I will validate the user's problem statement.\n2.  **Detailed Explanation**: If the problem is valid, I will provide a detailed explanation of the solution.\n3.  **Code Implementation**: Finally, I will write the Python code to solve the problem.\n\n### Step 1: Problem Validation\n\nI have analyzed the problem statement provided by the user and have validated it against the required criteria.\n\n*   **Extraction of Givens**:\n    *   **Model**: A scalar linear Gaussian state-space model is defined by:\n        *   State transition equation: $x_t = a\\,x_{t-1} + u_t$, where $u_t \\sim \\mathcal{N}(0,q)$.\n        *   Observation equation: $y_t = c\\,x_t + v_t$, where $v_t \\sim \\mathcal{N}(0,r)$.\n        *   Initial prior: $x_0 \\sim \\mathcal{N}(m_0,P_0)$.\n    *   **Task**: Approximate the filtering distribution $p(x_t \\mid y_{1:t})$ using a bootstrap filter and compare its posterior mean and variance with the exact Kalman filter results.\n    *   **Bayesian Filtering Recursion**: $p(x_t \\mid y_{1:t}) \\propto p(y_t \\mid x_t)\\int p(x_t \\mid x_{t-1})\\,p(x_{t-1} \\mid y_{1:t-1})\\,dx_{t-1}$.\n    *   **Bootstrap Filter Specifications**:\n        *   Proposal distribution: $p(x_t \\mid x_{t-1})$.\n        *   Resampling method: Multinomial resampling at each step.\n        *   Statistic calculation: From normalized importance weights *before* resampling.\n    *   **RNG**: Simulate data with a given `seed`. Implement the particle filter with `seed + 1`.\n    *   **Comparison**: Compute absolute errors $|\\hat{\\mu}_t - m_t|$ and $|\\hat{V}_t - P_t|$ at a specified time $t$.\n    *   **Test Suite**: Four test cases are provided, each specifying $(a,c,q,r,m_0,P_0,T,t,N,\\text{seed})$. Case 2 must use the same simulated data as Case 1.\n\n*   **Validation Verdict**:\n    1.  **Scientifically Grounded**: The problem is sound. It concerns the comparison of the exact analytical solution (Kalman filter) and a numerical approximation method (bootstrap filter) for a fundamental model in statistical signal processing. Both methods are standard and well-established.\n    2.  **Well-Posed**: The problem is well-posed. The inputs are clearly defined, and the desired outputs (absolute errors) are uniquely computable given the specified algorithms and random seeds.\n    3.  **Objective**: The problem is stated in objective, mathematical language.\n    4.  **Completeness**: The problem is self-contained and provides all necessary parameters and specifications for implementation.\n    5.  **Relevance**: The problem is directly relevant to the specified topic of sequential importance resampling and stochastic simulation methods.\n\n*   **Conclusion**: The problem is **valid**. I will proceed to design and explain the solution.\n\n### Step 2: Detailed Explanation\n\nThis problem requires the implementation and comparison of two standard filtering algorithms for a linear Gaussian state-space model: the exact Kalman filter and the approximate bootstrap particle filter.\n\n**1. The State-Space Model and Filtering Problem**\nThe system is described by a latent (unobserved) state $x_t$ that evolves over time $t$ according to a linear stochastic process, and an observation $y_t$ that is a noisy linear function of the current state. The model equations are:\n$$\nx_t = a\\,x_{t-1} + u_t, \\quad u_t \\sim \\mathcal{N}(0,q) \\quad \\text{(State Equation)}\n$$\n$$\ny_t = c\\,x_t + v_t, \\quad v_t \\sim \\mathcal{N}(0,r) \\quad \\text{(Observation Equation)}\n$$\nThe filtering problem is to recursively estimate the posterior probability distribution of the current state, $p(x_t \\mid y_{1:t})$, given all observations up to the current time, $y_{1:t} = \\{y_1, \\dots, y_t\\}$. This posterior distribution represents our belief about the state $x_t$ after incorporating the information from the measurement $y_t$. The general Bayesian filtering recursion breaks this problem into a two-step process:\n\n*   **Prediction**: Use the state transition model to predict the current state's distribution based on the previous posterior:\n    $$\n    p(x_t \\mid y_{1:t-1}) = \\int p(x_t \\mid x_{t-1})\\,p(x_{t-1} \\mid y_{1:t-1})\\,dx_{t-1}\n    $$\n*   **Update**: Use the latest observation $y_t$ to update the predicted distribution into the new posterior, via Bayes' theorem:\n    $$\n    p(x_t \\mid y_{1:t}) = \\frac{p(y_t \\mid x_t)\\,p(x_t \\mid y_{1:t-1})}{p(y_t \\mid y_{1:t-1})} \\propto p(y_t \\mid x_t)\\,p(x_t \\mid y_{1:t-1})\n    $$\n\n**2. The Kalman Filter: An Exact Solution**\nFor linear Gaussian models, all distributions involved (priors, posteriors, likelihoods) are Gaussian. This allows for an exact, closed-form solution to the Bayesian recursion. The Kalman filter propagates the mean and variance of these Gaussian distributions through the prediction and update steps.\n\nStarting with the posterior from the previous step, $p(x_{t-1} \\mid y_{1:t-1}) = \\mathcal{N}(x_{t-1}; m_{t-1|t-1}, P_{t-1|t-1})$, the algorithm proceeds as follows for each time $t$:\n\n*   **Prediction Step**:\n    *   Predicted Mean: $m_{t|t-1} = a \\cdot m_{t-1|t-1}$\n    *   Predicted Variance: $P_{t|t-1} = a^2 \\cdot P_{t-1|t-1} + q$\n    This gives the predicted distribution $p(x_t \\mid y_{1:t-1}) = \\mathcal{N}(x_t; m_{t|t-1}, P_{t|t-1})$.\n\n*   **Update Step**:\n    *   Innovation (Residual): $\\tilde{y}_t = y_t - c \\cdot m_{t|t-1}$\n    *   Innovation Variance: $S_t = c^2 \\cdot P_{t|t-1} + r$\n    *   Kalman Gain: $K_t = \\frac{P_{t|t-1} \\cdot c}{S_t}$\n    *   Updated (Posterior) Mean: $m_{t|t} = m_{t|t-1} + K_t \\cdot \\tilde{y}_t$\n    *   Updated (Posterior) Variance: $P_{t|t} = (1 - K_t \\cdot c) \\cdot P_{t|t-1}$\n    This gives the final posterior for time $t$, $p(x_t \\mid y_{1:t}) = \\mathcal{N}(x_t; m_{t|t}, P_{t|t})$. The algorithm is initialized with $m_{0|0} = m_0$ and $P_{0|0} = P_0$.\n\n**3. The Bootstrap Filter: A Monte Carlo Approximation**\nFor non-linear/non-Gaussian models, the integrals in the Bayesian recursion are often intractable. Sequential Importance Resampling (SIR), a type of particle filter, provides a numerical approximation. The bootstrap filter is a specific SIR filter where the proposal distribution is the state transition prior.\n\nThe core idea is to represent the posterior distribution $p(x_t \\mid y_{1:t})$ by a set of $N$ weighted random samples, or \"particles\", $\\{x_t^{(i)}, w_t^{(i)}\\}_{i=1}^N$. The distribution is approximated as a discrete measure:\n$$\np(x_t \\mid y_{1:t}) \\approx \\sum_{i=1}^N \\tilde{w}_t^{(i)} \\delta(x_t - x_t^{(i)})\n$$\nwhere $\\tilde{w}_t^{(i)}$ are normalized weights and $\\delta(\\cdot)$ is the Dirac delta function. The algorithm recursively updates these particles and weights:\n\n*   **Initialization ($t=0$)**: Draw $N$ particles from the initial prior: $x_0^{(i)} \\sim \\mathcal{N}(m_0, P_0)$.\n\n*   **Recursive Step (for $t=1, \\dots, T$)**:\n    1.  **Propagate**: For each particle $x_{t-1}^{(i)}$ from the previous step (after resampling), propagate it forward using the state transition model to get a new particle:\n        $$\n        x_t^{(i)} \\sim p(x_t \\mid x_{t-1}^{(i)}) \\implies x_t^{(i)} = a \\cdot x_{t-1}^{(i)} + u_t^{(i)}, \\quad u_t^{(i)} \\sim \\mathcal{N}(0,q)\n        $$\n    2.  **Weight**: Assign an importance weight to each new particle $x_t^{(i)}$ based on how well it explains the current observation $y_t$. Since the proposal is the prior, the weight is proportional to the likelihood of the observation given the particle:\n        $$\n        w_t^{(i)} \\propto p(y_t \\mid x_t^{(i)}) = \\mathcal{N}(y_t; c \\cdot x_t^{(i)}, r)\n        $$\n        The weights are then normalized: $\\tilde{w}_t^{(i)} = w_t^{(i)} / \\sum_{j=1}^N w_t^{(j)}$.\n    3.  **Compute Statistics (Before Resampling)**: As required, the posterior mean $\\hat{\\mu}_t$ and variance $\\hat{V}_t$ are computed from the weighted particle set:\n        $$\n        \\hat{\\mu}_t = \\sum_{i=1}^N \\tilde{w}_t^{(i)} x_t^{(i)}\n        $$\n        $$\n        \\hat{V}_t = \\sum_{i=1}^N \\tilde{w}_t^{(i)} (x_t^{(i)} - \\hat{\\mu}_t)^2\n        $$\n    4.  **Resample**: A key issue in particle filtering is weight degeneracy, where after a few steps, one particle has a weight near $1$ and all others are near $0$. Resampling mitigates this by replacing the current particle set with a new set drawn from the current particles with probabilities equal to their normalized weights. Particles with high weights are likely to be selected multiple times, while those with low weights are likely to be discarded. This step effectively focuses computational resources on more promising regions of the state space. Multinomial resampling is used, where we draw $N$ new particles from the set $\\{x_t^{(i)}\\}_{i=1}^N$ with replacement, according to the probabilities $\\{\\tilde{w}_t^{(i)}\\}_{i=1}^N$. After resampling, the new set of particles becomes the input for the next time step's propagation stage.\n\n**4. Implementation Strategy**\nThe implementation will consist of three main functions: one to generate the data, one for the Kalman filter, and one for the bootstrap filter. The main part of the program will iterate through the test cases, call these functions, compute the absolute errors $| \\hat{\\mu}_t - m_t |$ and $| \\hat{V}_t - P_t |$, and collect the results for final output. To handle the case where two tests use the same simulated data, the generated data will be cached based on its random seed.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _generate_data(a, c, q, r, m0, P0, T, seed):\n    \"\"\"\n    Generates a single realization of the latent state and observation sequences.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    # x has T+1 elements (x_0 to x_T)\n    x = np.zeros(T + 1)\n    # y has T+1 elements, index 0 is unused for 1-based time indexing\n    y = np.zeros(T + 1)\n    \n    # Initial state x_0\n    x[0] = rng.normal(loc=m0, scale=np.sqrt(P0))\n    \n    for t in range(1, T + 1):\n        # State transition\n        x[t] = a * x[t-1] + rng.normal(loc=0, scale=np.sqrt(q))\n        # Observation\n        y[t] = c * x[t] + rng.normal(loc=0, scale=np.sqrt(r))\n        \n    return x, y\n\ndef _kalman_filter(a, c, q, r, m0, P0, T, y_obs):\n    \"\"\"\n    Implements the exact Kalman filter for the scalar linear Gaussian model.\n    \"\"\"\n    m_post = np.zeros(T + 1)\n    P_post = np.zeros(T + 1)\n    \n    # Initialize with prior at t=0\n    m_post[0] = m0\n    P_post[0] = P0\n    \n    for t in range(1, T + 1):\n        # Prediction step\n        m_pred = a * m_post[t-1]\n        P_pred = a**2 * P_post[t-1] + q\n        \n        # Update step\n        residual = y_obs[t] - c * m_pred\n        S = c**2 * P_pred + r\n        K = (P_pred * c) / S\n        \n        m_post[t] = m_pred + K * residual\n        P_post[t] = (1 - K * c) * P_pred\n        \n    return m_post, P_post\n\ndef _bootstrap_filter(a, c, q, r, m0, P0, T, t_target, N, y_obs, seed):\n    \"\"\"\n    Implements the bootstrap filter (Sequential Importance Resampling).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # Initialization (t=0): Draw particles from the prior\n    particles = rng.normal(loc=m0, scale=np.sqrt(P0), size=N)\n    \n    post_mean_at_t = None\n    post_var_at_t = None\n\n    # Pre-calculate constant part of log-likelihood for efficiency\n    log_likelihood_const = -0.5 * np.log(2 * np.pi * r)\n\n    for t in range(1, T + 1):\n        # 1. Propagate particles using the state transition model\n        noise = rng.normal(loc=0, scale=np.sqrt(q), size=N)\n        particles = a * particles + noise\n        \n        # 2. Weight particles based on the likelihood of the observation\n        log_weights = log_likelihood_const - (y_obs[t] - c * particles)**2 / (2 * r)\n\n        # Normalize weights using log-sum-exp trick for numerical stability\n        max_log_weight = np.max(log_weights)\n        weights = np.exp(log_weights - max_log_weight)\n        normalized_weights = weights / np.sum(weights)\n        \n        # 3. Compute statistics (before resampling) if at the target time\n        if t == t_target:\n            # Weighted mean\n            post_mean_at_t = np.sum(normalized_weights * particles)\n            # Weighted variance\n            post_var_at_t = np.sum(normalized_weights * (particles - post_mean_at_t)**2)\n\n        # 4. Resample particles to combat weight degeneracy\n        # The new set of particles is drawn with replacement based on their weights\n        indices = rng.choice(N, size=N, p=normalized_weights)\n        particles = particles[indices]\n        # After resampling, weights are implicitly reset to 1/N for the next step.\n        \n    return post_mean_at_t, post_var_at_t\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (a,  c,   q,   r,   m0, P0,  T,  t, N,    seed)\n        (0.9, 1.0, 0.5, 0.5, 0.0, 1.0, 25, 25, 1000, 11),\n        (0.9, 1.0, 0.5, 0.5, 0.0, 1.0, 25, 25, 10,   11),\n        (0.9, 1.0, 0.5, 3.0, 0.0, 1.0, 25, 25, 500,  22),\n        (0.9, 1.0, 0.5, 0.01, 0.0, 1.0, 25, 25, 200, 33),\n    ]\n\n    all_results = []\n    \n    # A cache to store generated data to ensure case 2 uses data from case 1\n    data_cache = {}\n    \n    for case in test_cases:\n        a, c, q, r, m0, P0, T, t_target, N, seed = case\n        \n        # 1. Generate data or retrieve from cache if the seed is repeated\n        if seed in data_cache:\n            x_true, y_obs = data_cache[seed]\n        else:\n            # The parameters for data generation are (a, c, q, r, m0, P0, T)\n            data_gen_params = (a, c, q, r, m0, P0, T, seed)\n            x_true, y_obs = _generate_data(*data_gen_params)\n            data_cache[seed] = (x_true, y_obs)\n            \n        # 2. Run Kalman Filter for the exact posterior\n        # The parameters for the KF model are (a, c, q, r, m0, P0)\n        kf_params = (a, c, q, r, m0, P0)\n        m_kf_seq, P_kf_seq = _kalman_filter(*kf_params, T, y_obs)\n        m_t_exact = m_kf_seq[t_target]\n        P_t_exact = P_kf_seq[t_target]\n        \n        # 3. Run Bootstrap Filter for the approximate posterior\n        # The seed for the particle filter is offset by +1 as specified\n        pf_seed = seed + 1\n        pf_params = (a, c, q, r, m0, P0)\n        mu_hat, V_hat = _bootstrap_filter(*pf_params, T, t_target, N, y_obs, pf_seed)\n        \n        # 4. Compute absolute errors and store results\n        err_mean = np.abs(mu_hat - m_t_exact)\n        err_var = np.abs(V_hat - P_t_exact)\n        \n        all_results.append(err_mean)\n        all_results.append(err_var)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3338910"}]}