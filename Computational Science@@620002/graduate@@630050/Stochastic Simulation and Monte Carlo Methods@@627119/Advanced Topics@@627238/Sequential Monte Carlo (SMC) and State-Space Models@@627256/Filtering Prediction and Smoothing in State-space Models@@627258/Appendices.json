{"hands_on_practices": [{"introduction": "Sequential Monte Carlo methods rely on a resampling step to mitigate the inevitable problem of weight degeneracy. While many resampling schemes exist, it is crucial to understand their underlying statistical properties to ensure the validity of the resulting estimators. This foundational exercise [@problem_id:3308535] has you analyze residual resampling, a popular scheme that reduces Monte Carlo variance by combining deterministic and random selections. By proving its conditional unbiasedness, you will develop a rigorous appreciation for how these algorithmic components maintain statistical integrity.", "problem": "Consider a discrete-time state-space model with latent process $\\{X_{t}\\}_{t \\geq 0}$ and observations $\\{Y_{t}\\}_{t \\geq 1}$ given by the transition density $f(x_{t} \\mid x_{t-1})$ and the observation likelihood $g(y_{t} \\mid x_{t})$, respectively. Let $y_{1:t}$ denote the fixed data observed up to time $t$. Suppose that a Sequential Monte Carlo (SMC) method, also known as particle filtering, produces at time $t$ a weighted particle system $\\{(x_{t}^{i}, \\tilde{w}_{t}^{i})\\}_{i=1}^{N}$ approximating the filtering distribution $p(x_{t} \\mid y_{1:t})$, where $\\tilde{w}_{t}^{i} \\geq 0$ and $\\sum_{i=1}^{N} \\tilde{w}_{t}^{i} = 1$.\n\nYou are asked to construct a conditionally unbiased estimator, with respect to the randomness induced by resampling, for the filtering expectation $\\int \\varphi(x) p(x \\mid y_{1:t}) \\, dx$ using residual resampling. Residual resampling operates as follows: define the integer allocations $n_{i} = \\lfloor N \\tilde{w}_{t}^{i} \\rfloor$ for $i \\in \\{1,\\dots,N\\}$, set $R = N - \\sum_{i=1}^{N} n_{i}$, and compute the normalized residuals $r_{i} = \\frac{N \\tilde{w}_{t}^{i} - n_{i}}{R}$ if $R > 0$ (and $r_{i} = 0$ otherwise). Construct $n_{i}$ deterministic copies of index $i$ and then draw the remaining $R$ ancestor indices independently from the categorical distribution on $\\{1,\\dots,N\\}$ with probabilities $\\{r_{i}\\}_{i=1}^{N}$. Denote the full set of $N$ ancestor indices by $A_{1:N}$, and define the resampling-based estimator of the filtering expectation as\n$$\n\\widehat{I}_{\\mathrm{res}} \\;=\\; \\frac{1}{N} \\sum_{j=1}^{N} \\varphi\\!\\big(x_{t}^{A_{j}}\\big).\n$$\n\nTasks:\n- Prove, using only the definition of residual resampling and linearity of expectation, that the estimator $\\widehat{I}_{\\mathrm{res}}$ is conditionally unbiased with respect to the empirical weighted measure; that is, show that\n$$\n\\mathbb{E}\\!\\left[ \\widehat{I}_{\\mathrm{res}} \\,\\middle|\\, x_{t}^{1:N}, \\tilde{w}_{t}^{1:N} \\right]\n\\;=\\; \\sum_{i=1}^{N} \\tilde{w}_{t}^{i} \\,\\varphi(x_{t}^{i}).\n$$\nExplain clearly why this constitutes an unbiased estimator of the empirical weighted expectation, and discuss the sense in which it provides an estimator for $\\int \\varphi(x) p(x \\mid y_{1:t}) \\, dx$.\n\n- Derive an expression for the expected number of deterministic copies produced by residual resampling, conditional on the weights $\\{\\tilde{w}_{t}^{i}\\}_{i=1}^{N}$, and then evaluate it for $N$ particles with the following weight vector:\n$$\nN \\;=\\; 200, \\quad \\big(\\tilde{w}_{t}^{1},\\dots,\\tilde{w}_{t}^{6}\\big) \\;=\\; \\big(0.041,\\, 0.157,\\, 0.233,\\, 0.089,\\, 0.271,\\, 0.209\\big).\n$$\n\nYour final answer must be a single number equal to the expected number of deterministic copies under residual resampling for the specified $N$ and weights. No rounding is required and no units should be reported in the final answer.", "solution": "The problem statement is well-posed, scientifically grounded within the field of stochastic simulation, and provides all necessary information for a unique solution. We may proceed.\n\nThe first task is to prove that the residual resampling estimator, $\\widehat{I}_{\\mathrm{res}}$, is conditionally unbiased for the empirical weighted expectation. The estimator is defined as\n$$\n\\widehat{I}_{\\mathrm{res}} = \\frac{1}{N} \\sum_{j=1}^{N} \\varphi\\big(x_{t}^{A_{j}}\\big)\n$$\nwhere $\\{A_{j}\\}_{j=1}^{N}$ is the set of ancestor indices chosen by the residual resampling algorithm. We are asked to show that\n$$\n\\mathbb{E}\\!\\left[ \\widehat{I}_{\\mathrm{res}} \\,\\middle|\\, x_{t}^{1:N}, \\tilde{w}_{t}^{1:N} \\right] \\;=\\; \\sum_{i=1}^{N} \\tilde{w}_{t}^{i} \\,\\varphi(x_{t}^{i}).\n$$\nThe expectation is conditioned on the particle locations $\\{x_{t}^{i}\\}_{i=1}^{N}$ and their associated normalized weights $\\{\\tilde{w}_{t}^{i}\\}_{i=1}^{N}$. Under this conditioning, these quantities are treated as fixed constants. The only source of randomness is the selection of the ancestor indices $\\{A_j\\}$.\n\nLet $K_i$ be the random variable representing the number of times the original particle index $i$ is selected as an ancestor in the resampling step. The collection of ancestor indices $\\{A_j\\}_{j=1}^N$ is a multiset where index $i$ appears $K_i$ times. Therefore, we can rewrite the sum in the estimator as:\n$$\n\\sum_{j=1}^{N} \\varphi\\big(x_{t}^{A_{j}}\\big) = \\sum_{i=1}^{N} K_i \\varphi(x_{t}^{i}).\n$$\nThe estimator is then $\\widehat{I}_{\\mathrm{res}} = \\frac{1}{N} \\sum_{i=1}^{N} K_i \\varphi(x_{t}^{i})$.\n\nUsing the linearity of expectation, we have:\n$$\n\\mathbb{E}\\!\\left[ \\widehat{I}_{\\mathrm{res}} \\,\\middle|\\, x_{t}^{1:N}, \\tilde{w}_{t}^{1:N} \\right] = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{E}\\!\\left[ K_i \\,\\middle|\\, \\tilde{w}_{t}^{1:N} \\right] \\varphi(x_{t}^{i}).\n$$\nOur goal is to compute the conditional expectation of $K_i$. The residual resampling procedure defines $K_i$ as the sum of a deterministic part and a random part.\nThe deterministic part is the number of integer copies, $n_i = \\lfloor N \\tilde{w}_{t}^{i} \\rfloor$.\nThe random part arises from drawing the remaining $R = N - \\sum_{k=1}^{N} n_k$ particles. These $R$ particles are drawn independently from a categorical distribution on $\\{1, \\dots, N\\}$ with probabilities $\\{r_i\\}_{i=1}^N$, where $r_i = \\frac{N \\tilde{w}_{t}^{i} - n_{i}}{R}$ for $R > 0$.\nLet $K_i^{\\mathrm{rand}}$ be the number of times index $i$ is chosen among these $R$ random draws. Then, $K_i = n_i + K_i^{\\mathrm{rand}}$.\nThe random variable $K_i^{\\mathrm{rand}}$ follows a binomial distribution, $K_i^{\\mathrm{rand}} \\sim \\mathrm{Binomial}(R, r_i)$, as it is the number of \"successes\" (drawing index $i$) in $R$ independent Bernoulli trials, each with success probability $r_i$.\n\nThe conditional expectation of $K_i$ is thus:\n$$\n\\mathbb{E}\\!\\left[ K_i \\,\\middle|\\, \\tilde{w}_{t}^{1:N} \\right] = \\mathbb{E}\\!\\left[ n_i + K_i^{\\mathrm{rand}} \\,\\middle|\\, \\tilde{w}_{t}^{1:N} \\right] = n_i + \\mathbb{E}\\!\\left[ K_i^{\\mathrm{rand}} \\,\\middle|\\, \\tilde{w}_{t}^{1:N} \\right].\n$$\nThe expectation of a binomial random variable $\\mathrm{Binomial}(n,p)$ is $np$. Therefore, for $R > 0$:\n$$\n\\mathbb{E}\\!\\left[ K_i^{\\mathrm{rand}} \\,\\middle|\\, \\tilde{w}_{t}^{1:N} \\right] = R \\cdot r_i = R \\cdot \\frac{N \\tilde{w}_{t}^{i} - n_{i}}{R} = N \\tilde{w}_{t}^{i} - n_{i}.\n$$\nIf $R=0$, then $N = \\sum_{k=1}^N n_k = \\sum_{k=1}^N \\lfloor N \\tilde{w}_t^k \\rfloor$. Since $\\sum_{k=1}^N N \\tilde{w}_t^k = N$, this implies $\\sum_{k=1}^N (N \\tilde{w}_t^k - \\lfloor N \\tilde{w}_t^k \\rfloor) = 0$. As each term in the sum is non-negative, we must have $N \\tilde{w}_t^k - \\lfloor N \\tilde{w}_t^k \\rfloor = 0$ for all $k$. This means $N \\tilde{w}_t^k$ is an integer for all $k$, so $n_k = N \\tilde{w}_t^k$. In this case, $N \\tilde{w}_{t}^{i} - n_{i} = 0$. Also, when $R=0$, no random draws are made, so $K_i^{\\mathrm{rand}} = 0$ and its expectation is $0$. The formula $\\mathbb{E}[K_i^{\\mathrm{rand}}] = N \\tilde{w}_{t}^{i} - n_{i}$ holds for $R=0$ as well.\n\nSubstituting this result back into the expression for $\\mathbb{E}[K_i]$:\n$$\n\\mathbb{E}\\!\\left[ K_i \\,\\middle|\\, \\tilde{w}_{t}^{1:N} \\right] = n_i + (N \\tilde{w}_{t}^{i} - n_{i}) = N \\tilde{w}_{t}^{i}.\n$$\nFinally, we substitute this into the expression for the expected value of the estimator:\n$$\n\\mathbb{E}\\!\\left[ \\widehat{I}_{\\mathrm{res}} \\,\\middle|\\, x_{t}^{1:N}, \\tilde{w}_{t}^{1:N} \\right] = \\frac{1}{N} \\sum_{i=1}^{N} (N \\tilde{w}_{t}^{i}) \\varphi(x_{t}^{i}) = \\sum_{i=1}^{N} \\tilde{w}_{t}^{i} \\varphi(x_{t}^{i}).\n$$\nThis completes the proof.\n\nThis result means that $\\widehat{I}_{\\mathrm{res}}$ is an unbiased estimator of the empirical expectation $\\sum_{i=1}^{N} \\tilde{w}_{t}^{i} \\varphi(x_{t}^{i})$, where the unbiasedness is with respect to the randomness introduced by the resampling step alone. The quantity $\\sum_{i=1}^{N} \\tilde{w}_{t}^{i} \\varphi(x_{t}^{i})$ is the standard Monte Carlo approximation of the true filtering expectation $I_t = \\int \\varphi(x) p(x \\mid y_{1:t}) \\, dx$ based on the weighted particle system before resampling. For a finite number of particles $N$, this empirical expectation is generally a biased estimator of $I_t$. However, it is a consistent estimator, meaning it converges to $I_t$ as $N \\to \\infty$ under suitable regularity conditions. Therefore, $\\widehat{I}_{\\mathrm{res}}$ provides an estimator for the true filtering expectation $I_t$ in the sense that it is a conditionally unbiased estimator of a consistent estimator of $I_t$.\n\nThe second task is to derive an expression for the expected number of deterministic copies and evaluate it.\nThe number of deterministic copies of particle $i$ is defined as $n_i = \\lfloor N \\tilde{w}_{t}^{i} \\rfloor$. The total number of deterministic copies is the sum over all particles, $N_{\\mathrm{det}} = \\sum_{i=1}^{N} n_i$.\nThe question asks for the expected number of deterministic copies, conditional on the weights $\\{\\tilde{w}_{t}^{i}\\}_{i=1}^N$. Since the weights are given, the quantity $N_{\\mathrm{det}}$ is a fixed, deterministic value. The expectation of a constant is the constant itself.\nThus, the expression is:\n$$\n\\mathbb{E}\\!\\left[ N_{\\mathrm{det}} \\,\\middle|\\, \\tilde{w}_{t}^{1:N} \\right] = \\sum_{i=1}^{N} \\lfloor N \\tilde{w}_{t}^{i} \\rfloor.\n$$\nWe are given $N = 200$ and non-zero weights for $6$ particles: $\\tilde{w}_{t}^{1}=0.041$, $\\tilde{w}_{t}^{2}=0.157$, $\\tilde{w}_{t}^{3}=0.233$, $\\tilde{w}_{t}^{4}=0.089$, $\\tilde{w}_{t}^{5}=0.271$, $\\tilde{w}_{t}^{6}=0.209$. For all $i>6$, $\\tilde{w}_{t}^{i}=0$.\n\nWe calculate $N \\tilde{w}_{t}^{i}$ for each of the $6$ particles:\n- $n_1 = \\lfloor 200 \\times 0.041 \\rfloor = \\lfloor 8.2 \\rfloor = 8$\n- $n_2 = \\lfloor 200 \\times 0.157 \\rfloor = \\lfloor 31.4 \\rfloor = 31$\n- $n_3 = \\lfloor 200 \\times 0.233 \\rfloor = \\lfloor 46.6 \\rfloor = 46$\n- $n_4 = \\lfloor 200 \\times 0.089 \\rfloor = \\lfloor 17.8 \\rfloor = 17$\n- $n_5 = \\lfloor 200 \\times 0.271 \\rfloor = \\lfloor 54.2 \\rfloor = 54$\n- $n_6 = \\lfloor 200 \\times 0.209 \\rfloor = \\lfloor 41.8 \\rfloor = 41$\n\nFor $i > 6$, $\\tilde{w}_{t}^{i} = 0$, so $n_i = \\lfloor 200 \\times 0 \\rfloor = 0$.\nThe total number of deterministic copies is the sum of these values:\n$$\n\\sum_{i=1}^{200} n_i = n_1 + n_2 + n_3 + n_4 + n_5 + n_6 + \\sum_{i=7}^{200} n_i\n$$\n$$\n= 8 + 31 + 46 + 17 + 54 + 41 + 0 = 197.\n$$\nThe expected number of deterministic copies, conditional on the given weights, is $197$.", "answer": "$$\n\\boxed{197}\n$$", "id": "3308535"}, {"introduction": "With a grasp of the internal mechanics of particle filters, we can move to analyzing the behavior of the filter as a whole system. A critical property is stability, which describes the filter's ability to \"forget\" its initial conditions and converge to a posterior distribution dictated by the observed data. This practical coding exercise [@problem_id:3308531] makes this abstract concept tangible by having you implement a filter for a Hidden Markov Model. You will simulate adversarial scenarios where stability fails and then implement a tempering-based fix, providing you with diagnostic skills to identify and correct common pathologies in filter design.", "problem": "Consider a finite-state Hidden Markov Model (HMM) with hidden state process $\\{X_t\\}_{t \\geq 1}$ taking values in $\\{1,2,\\dots,K\\}$ and observation process $\\{Y_t\\}_{t \\geq 1}$, specified by a transition kernel $p(x_t \\mid x_{t-1})$ and an observation likelihood $p(y_t \\mid x_t)$. The filtering distribution at time $t$ given observations $y_{1:t}$ and a prior distribution $\\mu$ on $X_1$ is denoted by $\\pi_t^\\mu$, where $\\pi_t^\\mu(i) = \\mathbb{P}(X_t = i \\mid y_{1:t})$. The distance between two filtering distributions is measured by the Total Variation (TV) norm, defined for discrete distributions as\n$$\n\\left\\lVert \\pi_t^\\mu - \\pi_t^\\nu \\right\\rVert_{\\mathrm{TV}} = \\frac{1}{2} \\sum_{i=1}^K \\left| \\pi_t^\\mu(i) - \\pi_t^\\nu(i) \\right|.\n$$\nFrom the fundamental definitions of Markov chains and conditional probability, the filtering recursion for a finite-state HMM is obtained by prediction followed by update: the one-step prediction is $\\alpha_{t \\mid t-1}^\\mu(j) = \\sum_{i=1}^K \\pi_{t-1}^\\mu(i) \\, p(j \\mid i)$, and the update is\n$$\n\\pi_t^\\mu(j) = \\frac{\\alpha_{t \\mid t-1}^\\mu(j) \\, g_j(y_t)}{\\sum_{k=1}^K \\alpha_{t \\mid t-1}^\\mu(k) \\, g_k(y_t)},\n$$\nwhere $g_j(y_t) = p(y_t \\mid X_t = j)$. Filter stability refers to the decay of $\\left\\lVert \\pi_t^\\mu - \\pi_t^\\nu \\right\\rVert_{\\mathrm{TV}}$ as $t$ increases, for any two priors $\\mu$ and $\\nu$. It is known that a sufficient mechanism for forgetting is the presence of mixing in the transition kernel together with informative observations, while failure modes include non-communicating dynamics and non-identifiable or symmetric likelihoods.\n\nYour task is to write a complete, runnable program that:\n- Implements the filtering recursion for a finite-state HMM and computes $\\left\\lVert \\pi_t^\\mu - \\pi_t^\\nu \\right\\rVert_{\\mathrm{TV}}$ at the final time.\n- Simulates one observation path per test case from the specified HMM to drive the filter.\n- Diagnoses non-forgetting mechanisms by checking whether the final TV distance falls below a stability threshold.\n- Proposes and tests a tempering-based fix by modifying the transition kernel via uniform mixing and optionally tempering the likelihood.\n\nThe tempering fix is defined as follows. Given a transition matrix $P$ with entries $P_{ij} = p(j \\mid i)$, define a tempered transition matrix\n$$\n\\widetilde{P} = (1 - \\varepsilon) P + \\varepsilon U,\n$$\nwhere $U$ is the $K \\times K$ matrix with all rows equal to the uniform distribution on $\\{1,\\dots,K\\}$, and $\\varepsilon \\in [0,1]$. Given a likelihood $g_j(y)$, likelihood tempering with parameter $\\beta \\in (0,1]$ uses $g_j(y)^\\beta$ in the update:\n$$\n\\pi_t^{\\mu,\\mathrm{temp}}(j) = \\frac{\\alpha_{t \\mid t-1}^\\mu(j) \\, g_j(y_t)^\\beta}{\\sum_{k=1}^K \\alpha_{t \\mid t-1}^\\mu(k) \\, g_k(y_t)^\\beta}.\n$$\n\nYou must implement the above for the following test suite of three parameter sets, each describing $(K, P, \\text{emission parameters}, T, \\mu, \\nu, \\varepsilon, \\beta)$, where observations are Gaussian with state-dependent mean and standard deviation. In all cases, the observation path length is $T$, and the Gaussian likelihood for state $j$ uses mean $m_j$ and standard deviation $s_j$:\n$$\ng_j(y) = \\frac{1}{\\sqrt{2\\pi} s_j} \\exp\\left( -\\frac{(y - m_j)^2}{2 s_j^2} \\right).\n$$\nAll random simulation must be reproducible.\n\nTest Suite:\n- Case $1$ (stable mixing and informative observations):\n  - $K = 2$,\n  - $P = \\begin{pmatrix} 0.9 & 0.1 \\\\ 0.1 & 0.9 \\end{pmatrix}$,\n  - Means $m = (0, 3)$,\n  - Standard deviations $s = (1, 1)$,\n  - $T = 50$,\n  - Priors $\\mu = (0.99, 0.01)$ and $\\nu = (0.01, 0.99)$,\n  - Tempering parameters $\\varepsilon = 0.02$, $\\beta = 0.7$.\n- Case $2$ (adversarial: identity dynamics and uninformative observations):\n  - $K = 2$,\n  - $P = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$,\n  - Means $m = (0, 0)$,\n  - Standard deviations $s = (5, 5)$,\n  - $T = 50$,\n  - Priors $\\mu = (0.99, 0.01)$ and $\\nu = (0.01, 0.99)$,\n  - Tempering parameters $\\varepsilon = 0.05$, $\\beta = 0.7$.\n- Case $3$ (adversarial: non-communicating blocks and non-identifiable across blocks):\n  - $K = 4$,\n  - $P = \\begin{pmatrix} 0.95 & 0.05 & 0 & 0 \\\\ 0.05 & 0.95 & 0 & 0 \\\\ 0 & 0 & 0.95 & 0.05 \\\\ 0 & 0 & 0.05 & 0.95 \\end{pmatrix}$,\n  - Means $m = (0, 0, 0, 0)$,\n  - Standard deviations $s = (1, 1, 1, 1)$,\n  - $T = 50$,\n  - Priors $\\mu = (0.5, 0.5, 0, 0)$ and $\\nu = (0, 0, 0.5, 0.5)$,\n  - Tempering parameters $\\varepsilon = 0.02$, $\\beta = 0.7$.\n\nFor each case, do the following:\n1. Simulate one observation path $\\{Y_t\\}_{t=1}^T$ from the specified $P$ and Gaussian emissions using a fixed random seed and a fixed initial hidden state distribution (uniform on $\\{1,\\dots,K\\}$).\n2. Run two filters with the same observations, starting from $\\mu$ and from $\\nu$, using the untempered model ($\\varepsilon = 0$, $\\beta = 1$). Compute the final TV distance at time $T$:\n   $$\n   D_{\\mathrm{std}} = \\left\\lVert \\pi_T^\\mu - \\pi_T^\\nu \\right\\rVert_{\\mathrm{TV}}.\n   $$\n3. Run two tempered filters with the same observations, starting from $\\mu$ and from $\\nu$, using the tempered model ($\\varepsilon$ and $\\beta$ as specified). Compute the final TV distance at time $T$:\n   $$\n   D_{\\mathrm{temp}} = \\left\\lVert \\pi_T^{\\mu,\\mathrm{temp}} - \\pi_T^{\\nu,\\mathrm{temp}} \\right\\rVert_{\\mathrm{TV}}.\n   $$\n4. For a stability threshold $\\tau = 0.1$, produce booleans\n   $$\n   S_{\\mathrm{std}} = \\mathbf{1}\\{ D_{\\mathrm{std}} \\leq \\tau \\}, \\quad S_{\\mathrm{temp}} = \\mathbf{1}\\{ D_{\\mathrm{temp}} \\leq \\tau \\}.\n   $$\n\nYour program should produce a single line of output containing the results for the three cases as a comma-separated list enclosed in square brackets. Each case’s result must be the list\n$$\n\\left[ D_{\\mathrm{std}}, D_{\\mathrm{temp}}, S_{\\mathrm{std}}, S_{\\mathrm{temp}} \\right],\n$$\nwith $D_{\\mathrm{std}}$ and $D_{\\mathrm{temp}}$ as floating-point numbers and $S_{\\mathrm{std}}$ and $S_{\\mathrm{temp}}$ as booleans. The final printed line must therefore look like\n$$\n\\left[ [d_{1,\\mathrm{std}}, d_{1,\\mathrm{temp}}, s_{1,\\mathrm{std}}, s_{1,\\mathrm{temp}}], [d_{2,\\mathrm{std}}, d_{2,\\mathrm{temp}}, s_{2,\\mathrm{std}}, s_{2,\\mathrm{temp}}], [d_{3,\\mathrm{std}}, d_{3,\\mathrm{temp}}, s_{3,\\mathrm{std}}, s_{3,\\mathrm{temp}}] \\right].\n$$\nNo physical units are involved in this problem; all outputs are dimensionless numerical values.", "solution": "The problem statement has been meticulously validated and is determined to be scientifically sound, well-posed, objective, and complete. It constitutes a standard exercise in computational statistics, specifically concerning the stability properties of filters for finite-state Hidden Markov Models (HMMs). We may therefore proceed with a formal solution.\n\nThe problem requires an analysis of filter stability for a discrete-time, finite-state HMM. The stability, or forgetting property of the filter, refers to its ability to \"forget\" its initial state, such that two filters started with different prior distributions converge to the same posterior distribution over time. The degree of convergence is measured using the Total Variation (TV) distance. We will implement the HMM filtering recursion, simulate observation data, and investigate scenarios where stability fails. Furthermore, we will implement and test a tempering-based regularization technique designed to restore stability.\n\nThe HMM is defined by:\n1.  A hidden state process $\\{X_t\\}_{t \\ge 1}$ taking values in a finite set $\\{1, 2, \\dots, K\\}$. The evolution of the state is governed by a time-homogeneous Markov chain with a $K \\times K$ transition probability matrix $P$, where $P_{ij} = p(X_t=j \\mid X_{t-1}=i)$.\n2.  An observation process $\\{Y_t\\}_{t \\ge 1}$. At each time $t$, the observation $Y_t$ is drawn from a distribution that depends only on the current hidden state $X_t$. The conditional probability density function is denoted $g_j(y) = p(y \\mid X_t=j)$. In this problem, the emissions are Gaussian: $Y_t \\mid \\{X_t=j\\} \\sim \\mathcal{N}(m_j, s_j^2)$.\n3.  An initial state distribution $\\mu$ over $\\{1, 2, \\dots, K\\}$.\n\nTo solve this problem, we will implement the following components.\n\n**1. HMM Data Simulation**\nFor each test case, we must first generate a single, reproducible sequence of observations $\\{y_t\\}_{t=1}^T$. This is achieved by first simulating the latent state sequence $\\{x_t\\}_{t=1}^T$ and then simulating the corresponding observations.\n-   **State Simulation**: The initial state $x_1$ is drawn from the specified uniform distribution on $\\{1, \\dots, K\\}$. Subsequent states $x_t$ for $t=2, \\dots, T$ are drawn from the categorical distribution defined by the $x_{t-1}$-th row of the transition matrix $P$.\n-   **Observation Simulation**: For each state $x_t=j$ in the simulated path, the corresponding observation $y_t$ is drawn from the Gaussian emission distribution $\\mathcal{N}(m_j, s_j^2)$.\n-   **Reproducibility**: All random numbers for simulation are generated using a pseudo-random number generator initialized with a fixed seed, ensuring the entire process is deterministic and reproducible. We will use a seed of $0$.\n\n**2. Bayesian Filtering Recursion**\nThe core of the analysis is the filtering algorithm, which computes the posterior distribution of the hidden state at time $t$, $\\pi_t(j) = \\mathbb{P}(X_t=j \\mid y_{1:t})$, given the sequence of observations up to time $t$. The recursion proceeds in two steps for each time $t=1, \\dots, T$:\n\n-   **Prediction**: The prior distribution for the state at time $t$ is computed based on the posterior at time $t-1$. In vector notation, if $\\pi_{t-1}$ is the row vector of posterior probabilities at time $t-1$, the predicted distribution $\\alpha_{t|t-1}$ is given by:\n    $$\n    \\alpha_{t|t-1} = \\pi_{t-1} P\n    $$\n-   **Update**: The predicted distribution is updated using the new observation $y_t$ via Bayes' rule. The updated posterior $\\pi_t$ is:\n    $$\n    \\pi_t(j) = \\frac{\\alpha_{t|t-1}(j) \\, g_j(y_t)}{\\sum_{k=1}^K \\alpha_{t|t-1}(k) \\, g_k(y_t)}\n    $$\nTo prevent numerical underflow from the repeated multiplication of small probability values, computations are performed in the logarithmic domain. The update step becomes an addition of log-probabilities, followed by a normalization using the `log-sum-exp` operation.\n\n**3. Filter Stability and Total Variation Distance**\nFilter stability is the property that for any two initial priors, $\\mu$ and $\\nu$, the corresponding filtering distributions $\\pi_t^\\mu$ and $\\pi_t^\\nu$ converge as $t \\to \\infty$. This convergence is measured by the Total Variation (TV) distance:\n$$\nD_t = \\left\\lVert \\pi_t^\\mu - \\pi_t^\\nu \\right\\rVert_{\\mathrm{TV}} = \\frac{1}{2} \\sum_{i=1}^K \\left| \\pi_t^\\mu(i) - \\pi_t^\\nu(i) \\right|\n$$\nThe filter is considered stable if $\\lim_{t \\to \\infty} D_t = 0$. For this problem, stability is assessed at a finite time $T$ against a threshold $\\tau = 0.1$.\n\n**4. Tempering as Regularization**\nThe problem presents two common failure modes for filter stability, which we address with tempering:\n\n-   **Transition Tempering**: To counteract non-communicating or slowly mixing dynamics, the transition matrix $P$ is replaced by a perturbed version $\\widetilde{P}$:\n    $$\n    \\widetilde{P} = (1 - \\varepsilon) P + \\varepsilon U\n    $$\n    where $U$ is a matrix with all rows equal to the uniform distribution on $\\{1, \\dots, K\\}$, and $\\varepsilon \\in (0,1]$ is a small mixing parameter. This ensures that the resulting Markov chain is ergodic, guaranteeing a unique stationary distribution and forcing mixing between all states.\n\n-   **Likelihood Tempering**: To modulate the effect of observations, particularly when they are uninformative or misleading, the likelihood function $g_j(y)$ is raised to a power $\\beta \\in (0,1]$:\n    $$\n    \\pi_t(j) \\propto \\alpha_{t|t-1}(j) \\, g_j(y_t)^\\beta\n    $$\n    In the logarithmic domain, this corresponds to multiplying the log-likelihood by $\\beta$. A value of $\\beta < 1$ \"flattens\" the likelihood, making the filter rely more on the dynamics and less on the data.\n\n**5. Analysis of Test Cases**\nThe three test cases are designed to exhibit specific behaviors:\n\n-   **Case 1 (Stable):** The transition matrix is mixing, and the emission distributions are well-separated. We expect the standard filter to be stable, i.e., $D_{\\mathrm{std}} \\le \\tau=0.1$. The tempered filter will also be stable.\n\n-   **Case 2 (Adversarial):** The transition matrix is the identity, meaning the state never changes (zero mixing). The emission distributions are identical for both states, meaning observations carry no information about the state. We expect the standard filter to fail to forget its initial prior, leading to $D_{\\mathrm{std}} \\gg \\tau$. Transition tempering with $\\varepsilon > 0$ introduces mixing, which, even with uninformative observations, will cause the posteriors to converge to the stationary distribution of $\\widetilde{P}$. We expect $D_{\\mathrm{temp}} \\le \\tau$.\n\n-   **Case 3 (Adversarial):** The transition matrix is block-diagonal, creating two non-communicating classes of states. The priors $\\mu$ and $\\nu$ place all their mass in separate blocks. The emission distributions are identical for all states. The standard filter will be unable to move probability mass between blocks, thus preserving the initial separation. We expect $D_{\\mathrm{std}} \\approx 1$. Transition tempering connects the blocks, enabling convergence and stability. We expect $D_{\\mathrm{temp}} \\le \\tau$.\n\nThe implementation will proceed by simulating the data for each case, then running both the standard and tempered filters for the two specified priors $\\mu$ and $\\nu$ to compute the final TV distances and stability flags.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.special import logsumexp\n\ndef solve():\n    \"\"\"\n    Main function to run the HMM filtering analysis for the test suite.\n    \"\"\"\n    \n    # Test suite from the problem statement.\n    # Each case: (K, P, m, s, T, mu, nu, epsilon, beta)\n    test_cases = [\n        # Case 1: Stable mixing and informative observations\n        (\n            2,\n            np.array([[0.9, 0.1], [0.1, 0.9]]),\n            np.array([0.0, 3.0]),\n            np.array([1.0, 1.0]),\n            50,\n            np.array([0.99, 0.01]),\n            np.array([0.01, 0.99]),\n            0.02,\n            0.7\n        ),\n        # Case 2: Adversarial - identity dynamics and uninformative observations\n        (\n            2,\n            np.array([[1.0, 0.0], [0.0, 1.0]]),\n            np.array([0.0, 0.0]),\n            np.array([5.0, 5.0]),\n            50,\n            np.array([0.99, 0.01]),\n            np.array([0.01, 0.99]),\n            0.05,\n            0.7\n        ),\n        # Case 3: Adversarial - non-communicating blocks and non-identifiable likelihood\n        (\n            4,\n            np.array([\n                [0.95, 0.05, 0.0, 0.0],\n                [0.05, 0.95, 0.0, 0.0],\n                [0.0, 0.0, 0.95, 0.05],\n                [0.0, 0.0, 0.05, 0.95]\n            ]),\n            np.array([0.0, 0.0, 0.0, 0.0]),\n            np.array([1.0, 1.0, 1.0, 1.0]),\n            50,\n            np.array([0.5, 0.5, 0.0, 0.0]),\n            np.array([0.0, 0.0, 0.5, 0.5]),\n            0.02,\n            0.7\n        )\n    ]\n\n    # Global settings for simulation and analysis\n    stability_threshold = 0.1\n    # Use a fixed seed for reproducible simulations\n    rng = np.random.default_rng(0)\n    \n    final_results = []\n\n    for case in test_cases:\n        K, P, m, s, T, mu, nu, epsilon, beta = case\n\n        # 1. Simulate one observation path from the HMM\n        x_path = np.zeros(T, dtype=int)\n        y_path = np.zeros(T)\n        \n        # Initial state drawn uniformly\n        x_path[0] = rng.choice(K) \n        \n        for t in range(T):\n            if t > 0:\n                x_path[t] = rng.choice(K, p=P[x_path[t-1], :])\n            # Draw observation from Gaussian emission\n            y_path[t] = rng.normal(loc=m[x_path[t]], scale=s[x_path[t]])\n\n        # 2. Run standard filters and compute TV distance\n        pi_T_mu_std = run_filter(y_path, T, K, P, m, s, mu, beta=1.0)\n        pi_T_nu_std = run_filter(y_path, T, K, P, m, s, nu, beta=1.0)\n        D_std = 0.5 * np.sum(np.abs(pi_T_mu_std - pi_T_nu_std))\n        S_std = D_std = stability_threshold\n\n        # 3. Run tempered filters and compute TV distance\n        U = np.full((K, K), 1.0 / K)\n        P_tempered = (1.0 - epsilon) * P + epsilon * U\n        \n        pi_T_mu_temp = run_filter(y_path, T, K, P_tempered, m, s, mu, beta)\n        pi_T_nu_temp = run_filter(y_path, T, K, P_tempered, m, s, nu, beta)\n        D_temp = 0.5 * np.sum(np.abs(pi_T_mu_temp - pi_T_nu_temp))\n        S_temp = D_temp = stability_threshold\n\n        final_results.append([D_std, D_temp, S_std, S_temp])\n\n    # Final print statement in the exact required format.\n    print(f\"[\" + \",\".join(map(str, final_results)) + \"]\")\n\ndef run_filter(y_path, T, K, P, m, s, prior, beta):\n    \"\"\"\n    Runs the HMM filtering recursion.\n\n    Args:\n        y_path (np.ndarray): The sequence of observations.\n        T (int): The length of the observation sequence.\n        K (int): The number of hidden states.\n        P (np.ndarray): The transition matrix.\n        m (np.ndarray): The means of the Gaussian emissions.\n        s (np.ndarray): The standard deviations of the Gaussian emissions.\n        prior (np.ndarray): The initial prior distribution over states.\n        beta (float): The likelihood tempering parameter.\n\n    Returns:\n        np.ndarray: The final filtering distribution pi_T.\n    \"\"\"\n    # Initialize with the log of the prior distribution\n    # A small constant is added to the prior to avoid log(0) for deterministic priors.\n    log_pi = np.log(prior + 1e-100) \n\n    for t in range(T):\n        # Prediction step\n        # Convert back to probability space for matrix multiplication\n        pi = np.exp(log_pi)\n        alpha_pred = pi @ P\n\n        # Update step (in log-space for numerical stability)\n        # Handle cases where predicted probability is 0\n        log_alpha_pred = np.log(alpha_pred, where=alpha_pred > 0, out=np.full_like(alpha_pred, -np.inf))\n        \n        # Calculate log-likelihoods for the current observation y_t\n        log_likelihoods = np.array([\n            norm.logpdf(y_path[t], loc=m[j], scale=s[j]) for j in range(K)\n        ])\n\n        # Compute unnormalized log posterior\n        unnormalized_log_post = log_alpha_pred + beta * log_likelihoods\n        \n        # Normalize using log-sum-exp trick\n        log_norm_const = logsumexp(unnormalized_log_post)\n        log_pi = unnormalized_log_post - log_norm_const\n\n    # Return the final filtering distribution in probability space\n    return np.exp(log_pi)\n\nsolve()\n```", "id": "3308531"}, {"introduction": "This advanced practice extends our focus from filtering to smoothing and addresses the practical challenge of algorithmic design. The frequency of resampling, governed by an Effective Sample Size (ESS) threshold $\\tau$, creates a critical trade-off: resampling too little leads to weight degeneracy, while resampling too much causes path degeneracy. In this capstone exercise [@problem_id:3308538], you will calibrate this threshold by implementing a full Forward-Filter Backward-Smoother (FFBS) and benchmarking it against the exact solution provided by the Rauch-Tung-Striebel smoother. This will equip you with the skills to empirically optimize the performance of complex Monte Carlo algorithms for real-world applications.", "problem": "You will study a scalar linear Gaussian state-space model and design a Sequential Monte Carlo (SMC) smoothing estimator with resampling triggered by an Effective Sample Size (ESS) threshold. Your task is to derive from foundational principles a Central Limit Theorem (CLT) for smoothed functionals and then calibrate the ESS threshold to minimize the expected mean squared error (MSE) of the smoothed estimator over time. Finally, you will implement a complete, runnable program that empirically calibrates the threshold using a fixed test suite and produces the required output.\n\nThe fundamental base for this problem is the Feynman–Kac representation of filtering and smoothing in state-space models, the definition of importance sampling and resampling in Sequential Monte Carlo (SMC), and classical Central Limit Theorem (CLT) results under mixing and regularity conditions.\n\nModel and definitions:\n- Consider the scalar linear Gaussian state-space model with hidden states $x_t$ and observations $y_t$.\n- The initial state is $x_0 \\sim \\mathcal{N}(\\mu_0, P_0)$, the state dynamics are $x_t = a x_{t-1} + \\eta_t$ with $\\eta_t \\sim \\mathcal{N}(0,q)$, and the observation model is $y_t = c x_t + \\epsilon_t$ with $\\epsilon_t \\sim \\mathcal{N}(0,r)$.\n- Let the observation sequence be $y_{1:T} = (y_1, \\dots, y_T)$ for a fixed horizon $T$.\n- Define the smoothed target functional at time $t$ as $\\varphi_t = \\mathbb{E}[g(x_t) \\mid y_{1:T}]$ for a measurable function $g$. In this problem, use $g(x) = x$, so $\\varphi_t = \\mathbb{E}[x_t \\mid y_{1:T}]$.\n- An SMC smoothing estimator $\\hat{\\varphi}_t^{(N)}$ is constructed from a bootstrap particle filter with $N$ particles, systematic resampling triggered by an ESS threshold, and forward-filter backward-smoothing over the particle set.\n\nSequential Monte Carlo setup and ESS-triggered resampling:\n- At each time $t$, the bootstrap proposal is $x_t^{(i)} \\sim p(x_t \\mid x_{t-1}^{(a^{(i)})})$, with $p(x_t \\mid x_{t-1}) = \\mathcal{N}(a x_{t-1}, q)$ and ancestor index $a^{(i)}$ selected by resampling (when triggered).\n- The unnormalized weights at time $t$ are $w_t^{(i)} \\propto p(y_t \\mid x_t^{(i)})$ with $p(y_t \\mid x_t)=\\mathcal{N}(c x_t, r)$. The normalized weights are $\\tilde{w}_t^{(i)} = w_t^{(i)}\\big/\\sum_{j=1}^N w_t^{(j)}$.\n- The Effective Sample Size (ESS) at time $t$ is defined by $\\mathrm{ESS}_t = \\left(\\sum_{i=1}^N \\tilde{w}_t^{(i)}\\right)^2 \\big/ \\sum_{i=1}^N \\left(\\tilde{w}_t^{(i)}\\right)^2 = 1 \\big/ \\sum_{i=1}^N \\left(\\tilde{w}_t^{(i)}\\right)^2$. Resampling is triggered if $\\mathrm{ESS}_t  \\tau N$, where $\\tau \\in (0,1]$ is the ESS threshold.\n- Use systematic resampling. After resampling, reset the weights to $\\tilde{w}_t^{(i)} = 1/N$.\n\nSmoothing over the particle set:\n- Perform forward-filter backward-smoothing over the particle set using the backward kernel implied by the Markov transition. Define $\\kappa_{t}(x_t^{(i)}, x_{t+1}^{(j)}) = p(x_{t+1}^{(j)} \\mid x_t^{(i)})$, where for the scalar Gaussian $p(x_{t+1} \\mid x_t) = \\mathcal{N}(a x_t, q)$. In implementation, for numerical stability and normalization invariance, use only the exponential part and omit the constant factor, that is, $\\exp\\left(-\\frac{1}{2 q} \\left(x_{t+1}^{(j)} - a x_t^{(i)}\\right)^2\\right)$.\n- Initialize backward messages with $\\beta_T^{(i)} = 1$ for all $i$. For $t = T-1, T-2, \\dots, 1$, update $\\beta_t^{(i)} = \\sum_{j=1}^N \\beta_{t+1}^{(j)} \\tilde{w}_{t+1}^{(j)} \\kappa_t(x_t^{(i)}, x_{t+1}^{(j)})$.\n- The smoothed weights at time $t$ are $\\tilde{w}_{t,\\mathrm{sm}}^{(i)} \\propto \\tilde{w}_t^{(i)} \\beta_t^{(i)}$, normalized to sum to $1$.\n- The smoothing estimator is $\\hat{\\varphi}_t^{(N)} = \\sum_{i=1}^N \\tilde{w}_{t,\\mathrm{sm}}^{(i)} g(x_t^{(i)})$ for $t=1,\\dots,T-1$, and for $t=T$ set $\\hat{\\varphi}_T^{(N)} = \\sum_{i=1}^N \\tilde{w}_T^{(i)} g(x_T^{(i)})$.\n\nCLT target and calibration objective:\n- You will derive the CLT $\\sqrt{N}\\left(\\hat{\\varphi}_t^{(N)} - \\varphi_t\\right) \\Rightarrow \\mathcal{N}(0,\\sigma_t^2)$ for each fixed time $t$ under standard mixing and regularity assumptions for Feynman–Kac models with resampling. The asymptotic variance $\\sigma_t^2$ is a sum of local contributions that depend on the variability of $g(x_t)$ under the smoothing distribution and the propagated variability through the backward kernel across times.\n- Using the CLT, motivate calibrating $\\tau$ to control the effective sample size and genealogical degeneracy so as to minimize the expected mean squared error $\\mathrm{MSE} = \\frac{1}{T} \\sum_{t=1}^T \\mathbb{E}\\left[\\left(\\hat{\\varphi}_t^{(N)} - \\varphi_t\\right)^2\\right]$.\n\nProgram requirements:\n- Implement a complete program that, for each test case, generates synthetic data from the specified model parameters, computes the exact smoothing means $\\varphi_t$ using the Rauch–Tung–Striebel (RTS) Kalman smoother, runs the SMC smoother for a grid of $\\tau$ candidates, estimates the time-averaged MSE, and outputs the $\\tau$ that minimizes the estimated MSE. When there is a tie, choose the smallest $\\tau$ among those with minimal MSE.\n- Use the identity function $g(x) = x$ as specified above.\n- Use systematic resampling when $\\mathrm{ESS}_t  \\tau N$.\n- For each test case, average the time-averaged MSE across a specified number of replicates to approximate the expectation in the objective.\n\nTest suite:\n- Case $1$: Parameters $(\\mu_0,P_0,a,q,c,r,T,N,R)$ set to $(0.0,1.0,0.9,1.0,1.0,0.5,40,200,12)$, with $\\tau$ candidates $[0.3, 0.5, 0.7, 0.9]$.\n- Case $2$: Parameters $(\\mu_0,P_0,a,q,c,r,T,N,R)$ set to $(0.0,5.0,1.0,1.0,1.0,2.0,60,150,12)$, with $\\tau$ candidates $[0.2, 0.4, 0.6, 0.8, 1.0]$.\n- Case $3$: Parameters $(\\mu_0,P_0,a,q,c,r,T,N,R)$ set to $(0.0,1.0,0.5,0.5,1.0,0.1,50,120,12)$, with $\\tau$ candidates $[0.1, 0.3, 0.5, 0.7]$.\n\nFinal output format:\n- Your program should produce a single line of output containing the selected thresholds for the three test cases, as a comma-separated list of floats rounded to two decimal places and enclosed in square brackets. For example, if the selected thresholds are $\\tau_1 = 0.5$, $\\tau_2 = 0.6$, and $\\tau_3 = 0.3$, the output must be exactly $[0.50,0.60,0.30]$.\n\nImportant constraints:\n- The final program must be entirely self-contained, require no user input, and use only the Python Standard Library, NumPy, and SciPy as specified below. Angles or physical units do not appear in this problem, so no unit specification is required beyond the definitions above.", "solution": "The problem has been validated and is determined to be a well-posed, scientifically grounded, and complete problem in the field of computational statistics and stochastic simulation. It requires the implementation and empirical comparison of standard algorithms (Rauch-Tung-Striebel smoother, Sequential Monte Carlo smoother) to solve a practical parameter calibration task. All necessary models, parameters, and objectives are clearly defined.\n\nThe objective is to empirically determine the optimal Effective Sample Size (ESS) threshold, denoted by $\\tau$, for resampling in a Sequential Monte Carlo (SMC) smoother. The optimality is defined in terms of minimizing the time-averaged Mean Squared Error (MSE) of the smoothed state estimates. We are given a scalar linear Gaussian state-space model:\n- State dynamics: $x_t = a x_{t-1} + \\eta_t$, with $\\eta_t \\sim \\mathcal{N}(0,q)$\n- Observation model: $y_t = c x_t + \\epsilon_t$, with $\\epsilon_t \\sim \\mathcal{N}(0,r)$\n\nThe target of estimation is the smoothed mean of the state, $\\varphi_t = \\mathbb{E}[x_t \\mid y_{1:T}]$, for each time step $t \\in \\{1, \\dots, T\\}$.\n\n**Theoretical Motivation and Principle-Based Design**\n\nThe estimator for $\\varphi_t$ is denoted $\\hat{\\varphi}_t^{(N)}$, constructed using an SMC smoother with $N$ particles. Under appropriate regularity and mixing conditions, a Central Limit Theorem (CLT) for SMC estimators holds. For a fixed time $t$ and as the number of particles $N \\to \\infty$, the distribution of the estimation error converges:\n$$\n\\sqrt{N}\\left(\\hat{\\varphi}_t^{(N)} - \\varphi_t\\right) \\Rightarrow \\mathcal{N}(0,\\sigma_t^2)\n$$\nwhere '$\\Rightarrow$' denotes convergence in distribution. This CLT implies that for a large but finite $N$, the Mean Squared Error (MSE) can be approximated as:\n$$\n\\mathrm{MSE}_t = \\mathbb{E}\\left[\\left(\\hat{\\varphi}_t^{(N)} - \\varphi_t\\right)^2\\right] \\approx \\frac{\\sigma_t^2}{N}\n$$\nThe asymptotic variance $\\sigma_t^2$ is a complex quantity that depends on the entire history of the particle filter, including the stochastic resampling steps. Our goal is to choose the resampling threshold $\\tau$ to minimize the time-averaged MSE, $\\frac{1}{T} \\sum_{t=1}^T \\mathrm{MSE}_t$, which is approximately equivalent to minimizing the time-averaged asymptotic variance.\n\nThe choice of $\\tau \\in (0,1]$ governs the frequency of resampling and involves a critical trade-off:\n1.  **Infrequent Resampling (low $\\tau$)**: If resampling is performed rarely, the particle weights can become highly skewed, where one or a few particles have weights close to $1$ and the rest are near $0$. This phenomenon, known as weight degeneracy, increases the variance of the SMC estimator because the effective number of particles contributing to the estimate is very small. The ESS, defined as $\\mathrm{ESS}_t = 1 / \\sum_{i=1}^N (\\tilde{w}_t^{(i)})^2$, is a measure of this degeneracy.\n2.  **Frequent Resampling (high $\\tau$)**: If resampling is performed at nearly every step (e.g., $\\tau$ is close to $1$), weight degeneracy is mitigated. However, this introduces another problem: path degeneracy. Frequent resampling leads to a particle set where many particles share a common recent ancestor. This loss of diversity in the particle trajectories also increases the variance of the smoothed estimates, particularly for earlier time steps, as the information from the future has fewer distinct ancestral paths to propagate back along.\n\nTherefore, an optimal value of $\\tau$ exists that balances the reduction in weight variance against the increase in genealogical variance. As an analytical expression for the total variance as a function of $\\tau$ is intractable, we resort to an empirical, simulation-based approach for calibration.\n\n**Algorithmic and Implementation Strategy**\n\nOur strategy involves a nested loop structure to empirically evaluate each candidate $\\tau$ provided in the test suite.\n\n1.  **Outer Loop**: Iterate through each candidate value of $\\tau$.\n2.  **Middle Loop (Replicates)**: For each $\\tau$, run $R$ independent simulations (replicates) to obtain a stable estimate of the MSE.\n3.  **Inner Loop (Single Replicate Logic)**:\n    a.  **Data Generation**: Synthesize a true state sequence $\\{x_t\\}_{t=0}^T$ and a corresponding observation sequence $\\{y_t\\}_{t=1}^T$ from the linear Gaussian model.\n    b.  **Ground Truth Calculation**: The given model is linear and Gaussian, so the exact posterior smoothing distributions are Gaussian and can be computed analytically. We use the standard **Rauch-Tung-Striebel (RTS) smoother** to calculate the true smoothed means $\\varphi_t = \\mathbb{E}[x_t \\mid y_{1:T}]$. The RTS algorithm consists of a forward pass (the Kalman filter) to compute filtered estimates $\\mathbb{E}[x_t \\mid y_{1:t}]$ and a backward pass to combine these with future information.\n    c.  **SMC Estimation**: We implement the specified SMC smoother to compute the estimates $\\hat{\\varphi}_t^{(N)}$. This involves two main stages:\n        i.  **Forward Pass (Particle Filter)**: A bootstrap particle filter is advanced from $t=1$ to $T$. At each step, particles are propagated according to the state dynamics, then weighted based on the likelihood of the observation. The ESS is computed, and if it falls below the threshold $\\tau N$, **systematic resampling** is performed. Crucially for the subsequent smoothing step, the full particle sets and their weights *before* any resampling are stored for each time step.\n        ii. **Backward Pass (FFBS)**: A **Forward-Filter Backward-Smoothing (FFBS)** algorithm is executed. Starting with terminal messages $\\beta_T^{(i)} = 1$, we iterate backward from $t=T-1$ to $t=1$, updating the backward messages $\\beta_t^{(i)}$ according to the recursion $\\beta_t^{(i)} = \\sum_{j=1}^N \\beta_{t+1}^{(j)} \\tilde{w}_{t+1}^{(j)} \\kappa_t(x_t^{(i)}, x_{t+1}^{(j)})$, where $\\kappa_t$ is the state transition density. This recursion is performed on the stored pre-resampling particle sets. The smoothed estimates $\\hat{\\varphi}_t^{(N)}$ are then computed using weights proportional to the product of the forward weights $\\tilde{w}_t^{(i)}$ and the backward messages $\\beta_t^{(i)}$.\n    d.  **MSE Calculation**: The time-averaged MSE for the replicate is computed as $\\frac{1}{T}\\sum_{t=1}^T (\\hat{\\varphi}_t^{(N)} - \\varphi_t)^2$.\n\n4.  **Selection**: After completing all replicates for a given $\\tau$, the average MSE is recorded. Finally, the $\\tau$ that resulted in the lowest average MSE is selected as the optimal one for that test case, with ties being broken by choosing the smallest $\\tau$. This entire process is repeated for each of the three test cases.\n\nThis rigorous, simulation-based methodology allows for the direct calibration of the hyperparameter $\\tau$ by optimizing the desired performance metric, MSE, on the specific class of models defined in the problem.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the final results.\n    \"\"\"\n    # Set a global random seed for complete reproducibility of the experiment.\n    np.random.seed(42)\n    \n    test_cases = [\n        {\n            'mu0': 0.0, 'P0': 1.0, 'a': 0.9, 'q': 1.0, 'c': 1.0, 'r': 0.5, \n            'T': 40, 'N': 200, 'R': 12, 'taus': [0.3, 0.5, 0.7, 0.9]\n        },\n        {\n            'mu0': 0.0, 'P0': 5.0, 'a': 1.0, 'q': 1.0, 'c': 1.0, 'r': 2.0, \n            'T': 60, 'N': 150, 'R': 12, 'taus': [0.2, 0.4, 0.6, 0.8, 1.0]\n        },\n        {\n            'mu0': 0.0, 'P0': 1.0, 'a': 0.5, 'q': 0.5, 'c': 1.0, 'r': 0.1, \n            'T': 50, 'N': 120, 'R': 12, 'taus': [0.1, 0.3, 0.5, 0.7]\n        }\n    ]\n\n    final_results = []\n    for params in test_cases:\n        best_tau = calibrate_tau_for_case(params)\n        final_results.append(f\"{best_tau:.2f}\")\n\n    print(f\"[{','.join(final_results)}]\")\n\ndef calibrate_tau_for_case(params):\n    \"\"\"\n    For a single test case, finds the optimal tau from a list of candidates.\n    \"\"\"\n    taus = params['taus']\n    R = params['R']\n    \n    mse_by_tau = {}\n    for tau in taus:\n        replicate_mses = []\n        for _ in range(R):\n            x_true, y_obs = generate_data(params)\n            \n            # Ground truth via RTS Kalman Smoother\n            phi_true, _ = rts_smoother(y_obs, params)\n            \n            # SMC estimation\n            phi_hat = smc_smoother(y_obs, params, tau)\n            \n            # Time-averaged MSE for this replicate (t=1..T)\n            mse = np.mean((phi_hat[1:] - phi_true[1:])**2) \n            replicate_mses.append(mse)\n        \n        mse_by_tau[tau] = np.mean(replicate_mses)\n\n    # Find best tau (min MSE, with tie-breaking by choosing smallest tau)\n    min_mse = float('inf')\n    best_tau = -1.0\n    # Iterate through taus in their given (sorted) order.\n    for tau in taus:\n        if mse_by_tau[tau]  min_mse:\n            min_mse = mse_by_tau[tau]\n            best_tau = tau\n            \n    return best_tau\n    \ndef generate_data(params):\n    \"\"\"\n    Generates synthetic data from the linear Gaussian state-space model.\n    \"\"\"\n    T, mu0, P0, a, q, c, r = params['T'], params['mu0'], params['P0'], params['a'], params['q'], params['c'], params['r']\n    x = np.zeros(T + 1)\n    y = np.zeros(T + 1) # y_1 to y_T stored at indices 1..T\n    \n    x[0] = np.random.normal(mu0, np.sqrt(P0))\n    for t in range(1, T + 1):\n        x[t] = a * x[t-1] + np.random.normal(0, np.sqrt(q))\n        y[t] = c * x[t] + np.random.normal(0, np.sqrt(r))\n    return x, y\n\ndef rts_smoother(y_obs, params):\n    \"\"\"\n    Computes exact smoothed means and covariances using the RTS smoother.\n    \"\"\"\n    T, mu0, P0, a, q, c, r = params['T'], params['mu0'], params['P0'], params['a'], params['q'], params['c'], params['r']\n    \n    x_filt = np.zeros(T + 1)\n    P_filt = np.zeros(T + 1)\n    x_pred = np.zeros(T + 1)\n    P_pred = np.zeros(T + 1)\n\n    x_filt[0], P_filt[0] = mu0, P0\n    \n    # Kalman Filter (forward pass)\n    for t in range(1, T + 1):\n        x_pred[t] = a * x_filt[t-1]\n        P_pred[t] = a**2 * P_filt[t-1] + q\n        \n        S = c**2 * P_pred[t] + r\n        K = (P_pred[t] * c) / S\n        x_filt[t] = x_pred[t] + K * (y_obs[t] - c * x_pred[t])\n        P_filt[t] = (1 - K * c) * P_pred[t]\n        \n    x_smooth = np.zeros(T + 1)\n    P_smooth = np.zeros(T + 1)\n    \n    x_smooth[T], P_smooth[T] = x_filt[T], P_filt[T]\n    \n    # RTS (backward pass)\n    for t in range(T - 1, -1, -1):\n        J = (P_filt[t] * a) / P_pred[t+1]\n        x_smooth[t] = x_filt[t] + J * (x_smooth[t+1] - x_pred[t+1])\n        P_smooth[t] = P_filt[t] + J**2 * (P_smooth[t+1] - P_pred[t+1])\n\n    return x_smooth, P_smooth\n\ndef systematic_resample_indices(weights, N):\n    \"\"\"\n    Performs systematic resampling and returns the indices of resampled particles.\n    \"\"\"\n    c = np.cumsum(weights)\n    u0 = np.random.uniform(0, 1/N)\n    u = u0 + np.arange(N) / N\n    return np.searchsorted(c, u)\n\ndef smc_smoother(y_obs, params, tau):\n    \"\"\"\n    Performs SMC smoothing with ESS-triggered systematic resampling and FFBS.\n    \"\"\"\n    T, N, mu0, P0, a, q, c, r = params['T'], params['N'], params['mu0'], params['P0'], params['a'], params['q'], params['c'], params['r']\n    \n    all_particles = np.zeros((T + 1, N))\n    all_weights = np.zeros((T + 1, N))\n    \n    current_particles = np.random.normal(mu0, np.sqrt(P0), size=N)\n    all_particles[0, :] = current_particles\n    all_weights[0, :] = 1.0 / N\n\n    # Forward filter pass\n    for t in range(1, T + 1):\n        propagated_particles = a * current_particles + np.random.normal(0, np.sqrt(q), size=N)\n        \n        log_w = -0.5 * ((y_obs[t] - c * propagated_particles)**2) / r\n        log_w -= np.max(log_w)\n        w = np.exp(log_w)\n        normalized_weights = w / np.sum(w)\n\n        all_particles[t, :] = propagated_particles\n        all_weights[t, :] = normalized_weights\n        \n        ess = 1.0 / np.sum(normalized_weights**2)\n        if ess  tau * N:\n            indices = systematic_resample_indices(normalized_weights, N)\n            current_particles = propagated_particles[indices]\n        else:\n            current_particles = propagated_particles\n    \n    # Backward smoothing pass (FFBS)\n    smoothed_means = np.zeros(T + 1)\n    smoothed_means[T] = np.sum(all_weights[T, :] * all_particles[T, :])\n\n    beta = np.ones(N)\n    for t in range(T - 1, 0, -1):\n        # Calculate backward kernel matrix between particle sets at t and t+1\n        diff_sq = (all_particles[t+1, :][np.newaxis, :] - a * all_particles[t, :][:, np.newaxis])**2\n        kernel = np.exp(-0.5 * diff_sq / q)\n        \n        weighted_beta_next = beta * all_weights[t+1, :]\n        beta = np.dot(kernel, weighted_beta_next)\n        \n        w_sm = all_weights[t, :] * beta\n        w_sm_sum = np.sum(w_sm)\n        if w_sm_sum > 1e-100: # Handle potential underflow\n            w_sm /= w_sm_sum\n        else:\n            w_sm = np.ones(N) / N\n            \n        smoothed_means[t] = np.sum(w_sm * all_particles[t, :])\n        \n    return smoothed_means\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3308538"}]}