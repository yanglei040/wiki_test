{"hands_on_practices": [{"introduction": "The convergence of any stochastic approximation algorithm is critically dependent on the choice of its step-size sequence, $a_n$. This exercise guides you through a comparative analysis of different step-size schedules to reveal their profound impact on performance [@problem_id:3348661]. By examining convergence rates and the conditions under which a Central Limit Theorem holds, you will master the core theoretical principles that govern the efficiency and reliability of the Robbins-Monro method.", "problem": "Consider the scalar Robbins–Monro stochastic approximation recursion\n$$\nX_{n+1} \\;=\\; X_n \\;-\\; a_n\\,Y_{n+1},\n$$\nwhere the goal is to find the unique root $\\theta^\\star$ of an unknown function $f$ satisfying $f(\\theta^\\star)=0$. Assume the following foundational conditions:\n- The observation noise is given by $Y_{n+1} \\;=\\; f(X_n) \\;+\\; \\xi_{n+1}$, where $\\{\\xi_n\\}$ is a martingale difference sequence with respect to the natural filtration, with $\\mathbb{E}[\\xi_{n+1}\\mid \\mathcal{F}_n]=0$ and $\\mathbb{E}[\\xi_{n+1}^2\\mid \\mathcal{F}_n]\\to \\sigma^2\\in(0,\\infty)$.\n- The function $f$ is continuously differentiable in a neighborhood of $\\theta^\\star$, with $f'(\\theta^\\star)=\\gamma>0$, and $f$ is locally monotone so that the linearization around $\\theta^\\star$ is valid.\n- The step-size sequence is either $a_n=c/n$ with $c>0$, or $a_n=c/n^\\alpha$ with $c>0$ and $\\alpha\\in(0,1]$.\n\nUsing only these well-tested facts and definitions, compare the two step-size regimes in terms of convergence speed (as captured by the decay of $\\mathbb{E}[(X_n-\\theta^\\star)^2]$) and asymptotic variance, and determine the regimes where a Central Limit Theorem (CLT) holds for the appropriately normalized error. Select all statements that are correct.\n\nA. If $a_n=c/n$ and $2\\gamma c>1$, then a Central Limit Theorem holds with normalization $\\sqrt{n}$, and\n$$\n\\sqrt{n}\\,(X_n-\\theta^\\star)\\;\\Rightarrow\\;\\mathcal{N}\\!\\left(0,\\;\\frac{\\sigma^2 c^2}{2\\gamma c - 1}\\right),\n$$\nwith the choice $c=1/\\gamma$ minimizing the asymptotic variance among all $c>1/(2\\gamma)$.\n\nB. If $a_n=c/n$, then $\\mathbb{E}[(X_n-\\theta^\\star)^2]\\sim K/n^2$ for some constant $K>0$, so the normalization $\\sqrt{n}$ yields a degenerate limit; therefore, no Central Limit Theorem is possible in this regime.\n\nC. If $a_n=c/n^\\alpha$ with $\\alpha\\in(1/2,1)$, then $\\mathbb{E}[(X_n-\\theta^\\star)^2]\\sim \\left(\\frac{c\\sigma^2}{2\\gamma}\\right)\\,n^{-\\alpha}$ and a Central Limit Theorem holds with normalization $n^{\\alpha/2}$:\n$$\nn^{\\alpha/2}\\,(X_n-\\theta^\\star)\\;\\Rightarrow\\;\\mathcal{N}\\!\\left(0,\\;\\frac{c\\sigma^2}{2\\gamma}\\right).\n$$\n\nD. If $a_n=c/n^\\alpha$ with $\\alpha\\in(0,1/2]$, then almost sure convergence still holds by virtue of $\\sum_n a_n^2<\\infty$, but the Central Limit Theorem fails because the noise does not average sufficiently.\n\nE. For $\\alpha\\in(1/2,1)$, taking smaller $\\alpha$ always yields faster convergence than $a_n=c/n$ in the sense that the standard deviation of $X_n-\\theta^\\star$ decays strictly faster in $n$; moreover, $a_n=c/n^\\alpha$ dominates $a_n=c/n$ in asymptotic variance for all $c>0$.", "solution": "The problem asks for an analysis of the Robbins-Monro stochastic approximation algorithm under two different step-size regimes. The core of the analysis relies on the behavior of the error, $\\tilde{X}_n = X_n - \\theta^\\star$.\n\nThe recursion for the iterate is given by $X_{n+1} = X_n - a_n Y_{n+1}$. Substituting the observation model $Y_{n+1} = f(X_n) + \\xi_{n+1}$ and using $\\tilde{X}_n = X_n - \\theta^\\star$, we obtain the recursion for the error:\n$$\n\\tilde{X}_{n+1} = X_{n+1} - \\theta^\\star = (X_n - \\theta^\\star) - a_n(f(X_n) + \\xi_{n+1}) = \\tilde{X}_n - a_n(f(\\theta^\\star + \\tilde{X}_n) + \\xi_{n+1}).\n$$\nGiven that $f$ is continuously differentiable near $\\theta^\\star$ with $f'(\\theta^\\star) = \\gamma > 0$, and $f(\\theta^\\star)=0$, a first-order Taylor expansion gives $f(\\theta^\\star + \\tilde{X}_n) = f(\\theta^\\star) + f'(\\theta^\\star)\\tilde{X}_n + o(\\tilde{X}_n) = \\gamma \\tilde{X}_n + o(\\tilde{X}_n)$. Assuming convergence, so that $\\tilde{X}_n$ is small for large $n$, we can use the linearization:\n$$\n\\tilde{X}_{n+1} \\approx (1 - a_n \\gamma) \\tilde{X}_n - a_n \\xi_{n+1}.\n$$\nTo analyze the convergence speed, we examine the mean squared error (MSE), $V_n = \\mathbb{E}[\\tilde{X}_n^2]$. Squaring the linearized error recursion and taking the expectation yields:\n$$\nV_{n+1} = \\mathbb{E}[\\tilde{X}_{n+1}^2] \\approx \\mathbb{E}[((1 - a_n \\gamma) \\tilde{X}_n - a_n \\xi_{n+1})^2] = \\mathbb{E}[(1 - a_n \\gamma)^2 \\tilde{X}_n^2 - 2a_n(1 - a_n \\gamma)\\tilde{X}_n\\xi_{n+1} + a_n^2 \\xi_{n+1}^2].\n$$\nSince $\\tilde{X}_n$ is $\\mathcal{F}_n$-measurable and $\\mathbb{E}[\\xi_{n+1} \\mid \\mathcal{F}_n] = 0$, the cross-term vanishes: $\\mathbb{E}[\\tilde{X}_n\\xi_{n+1}] = \\mathbb{E}[\\tilde{X}_n \\mathbb{E}[\\xi_{n+1} \\mid \\mathcal{F}_n]] = 0$. Given $\\mathbb{E}[\\xi_{n+1}^2 \\mid \\mathcal{F}_n] \\to \\sigma^2$, we have $\\mathbb{E}[\\xi_{n+1}^2] \\to \\sigma^2$. For large $n$, we can approximate $\\mathbb{E}[a_n^2 \\xi_{n+1}^2] \\approx a_n^2 \\sigma^2$. The recursion for the MSE is approximately:\n$$\nV_{n+1} \\approx (1 - a_n \\gamma)^2 V_n + a_n^2 \\sigma^2 \\approx (1 - 2 a_n \\gamma) V_n + a_n^2 \\sigma^2,\n$$\nwhere we used $(1-x)^2 \\approx 1-2x$ for small $x=a_n\\gamma$. This recursion is the foundation for analyzing the options.\n\n### Option-by-Option Analysis\n\n**A. If $a_n=c/n$ and $2\\gamma c>1$, then a Central Limit Theorem holds with normalization $\\sqrt{n}$, and $\\sqrt{n}\\,(X_n-\\theta^\\star)\\;\\Rightarrow\\;\\mathcal{N}\\!\\left(0,\\;\\frac{\\sigma^2 c^2}{2\\gamma c - 1}\\right)$, with the choice $c=1/\\gamma$ minimizing the asymptotic variance among all $c>1/(2\\gamma)$.**\n\nWith $a_n = c/n$, the MSE recursion is $V_{n+1} \\approx (1 - 2\\gamma c/n) V_n + c^2\\sigma^2/n^2$. Under the condition $2\\gamma c > 1$, the algorithm achieves the optimal convergence rate for this class of recursions. Let's assume a solution of the form $V_n \\sim K/n$. Substituting this into the recursion:\n$$\n\\frac{K}{n+1} \\approx \\left(1 - \\frac{2\\gamma c}{n}\\right) \\frac{K}{n} + \\frac{c^2\\sigma^2}{n^2}.\n$$\nUsing the Taylor expansion $1/(n+1) \\approx 1/n - 1/n^2$:\n$$\n\\frac{K}{n} - \\frac{K}{n^2} \\approx \\frac{K}{n} - \\frac{2\\gamma c K}{n^2} + \\frac{c^2\\sigma^2}{n^2}.\n$$\nEquating the coefficients of the $1/n^2$ terms gives $-K \\approx -2\\gamma c K + c^2\\sigma^2$, which implies $K(2\\gamma c - 1) = c^2\\sigma^2$. For this to be well-defined with $K>0$, we need $2\\gamma c - 1 > 0$, or $2\\gamma c > 1$. This yields:\n$$\nK = \\frac{c^2\\sigma^2}{2\\gamma c - 1}.\n$$\nSince $\\mathbb{E}[(X_n-\\theta^\\star)^2] \\sim K/n$, the standard deviation decays as $1/\\sqrt{n}$. A Central Limit Theorem (CLT) for the error normalized by $\\sqrt{n}$ is expected. The asymptotic variance is given by $\\lim_{n\\to\\infty} n\\mathbb{E}[(X_n-\\theta^\\star)^2] = K$. Thus, $\\sqrt{n}(X_n-\\theta^\\star) \\Rightarrow \\mathcal{N}(0, \\frac{c^2\\sigma^2}{2\\gamma c - 1})$.\n\nTo find the value of $c > 1/(2\\gamma)$ that minimizes this variance, let $V(c) = \\frac{c^2\\sigma^2}{2\\gamma c - 1}$. We compute the derivative with respect to $c$:\n$$\n\\frac{dV}{dc} = \\sigma^2 \\frac{2c(2\\gamma c - 1) - c^2(2\\gamma)}{(2\\gamma c - 1)^2} = \\sigma^2 \\frac{4\\gamma c^2 - 2c - 2\\gamma c^2}{(2\\gamma c - 1)^2} = \\frac{2c\\sigma^2(\\gamma c - 1)}{(2\\gamma c - 1)^2}.\n$$\nSetting $dV/dc=0$ for $c>0$ gives $\\gamma c - 1 = 0$, so $c=1/\\gamma$. This value satisfies the condition $c > 1/(2\\gamma)$ since $\\gamma > 0$. Therefore, $c=1/\\gamma$ minimizes the asymptotic variance.\nThe statement is fully consistent with established theory.\nVerdict: **Correct**.\n\n**B. If $a_n=c/n$, then $\\mathbb{E}[(X_n-\\theta^\\star)^2]\\sim K/n^2$ for some constant $K>0$, so the normalization $\\sqrt{n}$ yields a degenerate limit; therefore, no Central Limit Theorem is possible in this regime.**\n\nAs shown in the analysis for option A, for the optimal case $2\\gamma c > 1$, the MSE behaves as $\\mathbb{E}[(X_n-\\theta^\\star)^2] \\sim K/n$. The statement's premise that the MSE decays as $K/n^2$ is incorrect. In fact, an MSE of order $O(1/n)$ is the characteristic behavior that leads to a non-degenerate CLT with $\\sqrt{n}$ normalization. If the MSE were $O(1/n^2)$, the correct normalization would be $n$, not $\\sqrt{n}$. The core claim about the MSE rate is false.\nVerdict: **Incorrect**.\n\n**C. If $a_n=c/n^\\alpha$ with $\\alpha\\in(1/2,1)$, then $\\mathbb{E}[(X_n-\\theta^\\star)^2]\\sim \\left(\\frac{c\\sigma^2}{2\\gamma}\\right)\\,n^{-\\alpha}$ and a Central Limit Theorem holds with normalization $n^{\\alpha/2}$: $n^{\\alpha/2}\\,(X_n-\\theta^\\star)\\;\\Rightarrow\\;\\mathcal{N}\\!\\left(0,\\;\\frac{c\\sigma^2}{2\\gamma}\\right)$.**\n\nFor this regime, the MSE recursion is $V_{n+1} \\approx (1 - 2\\gamma c n^{-\\alpha}) V_n + c^2 \\sigma^2 n^{-2\\alpha}$. The asymptotic behavior of this type of recursion can be found by approximating it with an ordinary differential equation (ODE). This analysis shows that the bias and variance terms balance in a way that leads to $V_n \\sim K n^{-\\alpha}$. More formally, standard results in stochastic approximation theory (e.g., from Fabian, 1968) establish that:\n$$\n\\lim_{n\\to\\infty} n^\\alpha \\mathbb{E}[(X_n-\\theta^\\star)^2] = \\frac{c^2 \\sigma^2}{2 c \\gamma} = \\frac{c \\sigma^2}{2\\gamma}.\n$$\nThis confirms the stated MSE rate: $\\mathbb{E}[(X_n-\\theta^\\star)^2] \\sim \\frac{c\\sigma^2}{2\\gamma} n^{-\\alpha}$.\nThe convergence rate of the standard deviation is thus $O(\\sqrt{n^{-\\alpha}}) = O(n^{-\\alpha/2})$. A CLT would therefore require normalization by $n^{\\alpha/2}$. The variance of the limiting normal distribution is given by the limit of the variance of the normalized sequence:\n$$\n\\lim_{n\\to\\infty} \\mathbb{E}[(n^{\\alpha/2}(X_n-\\theta^\\star))^2] = \\lim_{n\\to\\infty} n^\\alpha \\mathbb{E}[(X_n-\\theta^\\star)^2] = \\frac{c\\sigma^2}{2\\gamma}.\n$$\nSo, $n^{\\alpha/2}(X_n-\\theta^\\star) \\Rightarrow \\mathcal{N}(0, \\frac{c\\sigma^2}{2\\gamma})$. The statement accurately presents these established results.\nVerdict: **Correct**.\n\n**D. If $a_n=c/n^\\alpha$ with $\\alpha\\in(0,1/2]$, then almost sure convergence still holds by virtue of $\\sum_n a_n^2<\\infty$, but the Central Limit Theorem fails because the noise does not average sufficiently.**\n\nThis statement contains a critical flaw. The standard conditions for almost sure convergence of the Robbins-Monro algorithm (the Dvoretzky conditions) are $\\sum_n a_n = \\infty$ and $\\sum_n a_n^2 < \\infty$. For $a_n = c/n^\\alpha$:\n- $\\sum_n a_n = c \\sum_n n^{-\\alpha}$ diverges for $\\alpha \\le 1$, which is satisfied here.\n- $\\sum_n a_n^2 = c^2 \\sum_n n^{-2\\alpha}$ converges only if $2\\alpha > 1$, i.e., $\\alpha > 1/2$.\nFor the regime $\\alpha \\in (0, 1/2]$, the condition $\\sum_n a_n^2 < \\infty$ is violated. The statement's claim that almost sure convergence holds \"by virtue of $\\sum_n a_n^2 < \\infty$\" is false on two grounds: the premise ($\\sum a_n^2 < \\infty$) is false, and this condition is necessary for convergence, not just a nice-to-have property. When $\\sum a_n^2$ diverges, the accumulated noise variance is infinite, and the iterates typically fail to converge. The MSE does not go to zero, so convergence fails, and a CLT for the error (which should converge to $0$) is nonsensical.\nVerdict: **Incorrect**.\n\n**E. For $\\alpha\\in(1/2,1)$, taking smaller $\\alpha$ always yields faster convergence than $a_n=c/n$ in the sense that the standard deviation of $X_n-\\theta^\\star$ decays strictly faster in $n$; moreover, $a_n=c/n^\\alpha$ dominates $a_n=c/n$ in asymptotic variance for all $c>0$.**\n\nThis statement makes a comparison of convergence rates.\n- For $a_n = c/n$ (with $2\\gamma c > 1$), the standard deviation of the error decays as $O(n^{-1/2})$.\n- For $a_n = c/n^\\alpha$ with $\\alpha \\in (1/2, 1)$, the standard deviation decays as $O(n^{-\\alpha/2})$.\nSince $\\alpha \\in (1/2, 1)$, we have $\\alpha < 1$, which implies $\\alpha/2 < 1/2$. Therefore, $-1/2 < -\\alpha/2$. This means that $n^{-1/2}$ decays faster to zero than $n^{-\\alpha/2}$. The $a_n=c/n$ step-size rule yields a faster convergence rate than any $a_n=c/n^\\alpha$ with $\\alpha \\in (1/2,1)$.\nThe statement claims the opposite, that the $n^{-\\alpha/2}$ decay is faster; this is false. It also incorrectly claims smaller $\\alpha$ is better within the $(1/2,1)$ range; in fact, larger $\\alpha$ (closer to $1$) is better.\nThe second part of the statement compares asymptotic variances. The asymptotic variance for $a_n=c/n$ is for the $\\sqrt{n}$-normalized error, while for $a_n=c/n^\\alpha$ it is for the $n^{\\alpha/2}$-normalized error. These are fundamentally different quantities, and comparing their numerical values is like comparing apples and oranges; it is not a meaningful way to assess performance. The primary metric is the rate of convergence, which is superior for the $a_n=c/n$ case. The statement is incorrect in its comparison of rates and its comparison of variances.\nVerdict: **Incorrect**.", "answer": "$$\\boxed{AC}$$", "id": "3348661"}, {"introduction": "While the Kiefer-Wolfowitz algorithm provides a powerful framework for gradient-free optimization, its performance is often limited by the variance of its finite-difference gradient estimator. This practice introduces Common Random Numbers (CRN), a fundamental variance reduction technique, and asks you to quantify its impact [@problem_id:3348680]. By deriving the variance reduction ratio, you will gain a concrete understanding of how strategic use of random seeds can significantly accelerate convergence.", "problem": "Consider a stochastic objective with mean response function $f(\\theta) = \\mathbb{E}[Y(\\theta, \\xi)]$ that is differentiable in a neighborhood of a given scalar parameter $\\theta \\in \\mathbb{R}$. In the Kiefer-Wolfowitz (KW) finite-difference method, the gradient is estimated via a symmetric difference using two noisy observations at perturbations $\\theta \\pm \\delta$, where $\\delta > 0$ is small. Define the one-step KW gradient estimator\n$$\n\\widehat{g}(\\theta; \\delta) = \\frac{Y(\\theta + \\delta) - Y(\\theta - \\delta)}{2 \\delta}.\n$$\nAssume the following noise structure for the observations: for any fixed $\\theta$ and $\\delta$, write\n$$\nY(\\theta \\pm \\delta) = f(\\theta \\pm \\delta) + \\varepsilon_{\\pm},\n$$\nwhere $\\mathbb{E}[\\varepsilon_{\\pm}] = 0$, $\\operatorname{Var}(\\varepsilon_{\\pm}) = \\sigma^{2}$ for some $\\sigma^{2} \\in (0, \\infty)$, and, when using Common Random Numbers (CRN), the pair $(\\varepsilon_{+}, \\varepsilon_{-})$ has correlation $\\rho \\in [-1, 1]$. Without CRN, the pair is independent, corresponding to $\\rho = 0$. Throughout, $f(\\cdot)$ is deterministic and the only source of randomness is $(\\varepsilon_{+}, \\varepsilon_{-})$.\n\nUsing only linearity of expectation and the definitions of variance and covariance, perform the following:\n\n- Derive $\\operatorname{Cov}(Y(\\theta + \\delta), Y(\\theta - \\delta))$ under CRN in terms of $\\sigma^{2}$ and $\\rho$.\n\n- Derive $\\operatorname{Var}(\\widehat{g}(\\theta; \\delta))$ under CRN and, separately, under independence.\n\n- Define the variance impact ratio $R(\\rho)$ as\n$$\nR(\\rho) \\equiv \\frac{\\operatorname{Var}(\\widehat{g}(\\theta; \\delta) \\text{ under CRN})}{\\operatorname{Var}(\\widehat{g}(\\theta; \\delta) \\text{ under independence})}.\n$$\nCompute a closed-form analytic expression for $R(\\rho)$ as a function of $\\rho$.\n\nProvide, as your final answer, the expression for $R(\\rho)$. No numerical rounding is required.", "solution": "The problem is first validated to ensure it is scientifically grounded, well-posed, and objective.\n\n### Step 1: Extract Givens\n-   Objective function mean: $f(\\theta) = \\mathbb{E}[Y(\\theta, \\xi)]$\n-   Parameter: $\\theta \\in \\mathbb{R}$\n-   Kiefer-Wolfowitz gradient estimator: $\\widehat{g}(\\theta; \\delta) = \\frac{Y(\\theta + \\delta) - Y(\\theta - \\delta)}{2 \\delta}$, with $\\delta > 0$.\n-   Observation noise model: $Y(\\theta \\pm \\delta) = f(\\theta \\pm \\delta) + \\varepsilon_{\\pm}$.\n-   Noise properties: $\\mathbb{E}[\\varepsilon_{\\pm}] = 0$, $\\operatorname{Var}(\\varepsilon_{\\pm}) = \\sigma^{2}$ for $\\sigma^{2} \\in (0, \\infty)$.\n-   Correlation under Common Random Numbers (CRN): $\\rho = \\operatorname{Corr}(\\varepsilon_{+}, \\varepsilon_{-}) \\in [-1, 1]$.\n-   Independence case: The pair $(\\varepsilon_{+}, \\varepsilon_{-})$ is independent, corresponding to $\\rho = 0$.\n-   Function $f(\\cdot)$ is deterministic.\n-   The only source of randomness is the noise pair $(\\varepsilon_{+}, \\varepsilon_{-})$.\n-   Variance impact ratio definition: $R(\\rho) \\equiv \\frac{\\operatorname{Var}(\\widehat{g}(\\theta; \\delta) \\text{ under CRN})}{\\operatorname{Var}(\\widehat{g}(\\theta; \\delta) \\text{ under independence})}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is a standard theoretical exercise in stochastic simulation and optimization, specifically concerning the variance of the Kiefer-Wolfowitz finite-difference gradient estimator.\n-   **Scientifically Grounded**: The problem is based on established principles of probability theory (expectation, variance, covariance, correlation) and their application to the analysis of stochastic algorithms. The Kiefer-Wolfowitz method is a cornerstone of stochastic approximation.\n-   **Well-Posed**: The problem is clearly stated, providing all necessary definitions and assumptions to derive the required quantities. The questions are specific and lead to a unique analytical solution.\n-   **Objective**: The language is precise and mathematical, containing no subjective or ambiguous statements.\n\nThe problem is deemed valid as it does not violate any of the specified criteria for invalidity. We may proceed with the solution.\n\n---\n\nThe solution is derived in three parts as requested by the problem statement.\n\n### Part 1: Derivation of $\\operatorname{Cov}(Y(\\theta + \\delta), Y(\\theta - \\delta))$\nWe are asked to derive the covariance between the two noisy observations, $Y(\\theta + \\delta)$ and $Y(\\theta - \\delta)$, under the CRN assumption. The definition of covariance between two random variables $X$ and $Z$ is $\\operatorname{Cov}(X, Z) = \\mathbb{E}[(X - \\mathbb{E}[X])(Z - \\mathbb{E}[Z])]$.\n\nLet $X = Y(\\theta + \\delta)$ and $Z = Y(\\theta - \\delta)$. First, we compute their expectations. Using the linearity of expectation and the given properties:\n$$\n\\mathbb{E}[Y(\\theta + \\delta)] = \\mathbb{E}[f(\\theta + \\delta) + \\varepsilon_{+}] = \\mathbb{E}[f(\\theta + \\delta)] + \\mathbb{E}[\\varepsilon_{+}]\n$$\nSince $f(\\cdot)$ is a deterministic function, $\\mathbb{E}[f(\\theta + \\delta)] = f(\\theta + \\delta)$. We are given $\\mathbb{E}[\\varepsilon_{+}] = 0$. Thus,\n$$\n\\mathbb{E}[Y(\\theta + \\delta)] = f(\\theta + \\delta)\n$$\nSimilarly, for $Y(\\theta - \\delta)$:\n$$\n\\mathbb{E}[Y(\\theta - \\delta)] = \\mathbb{E}[f(\\theta - \\delta) + \\varepsilon_{-}] = f(\\theta - \\delta) + \\mathbb{E}[\\varepsilon_{-}] = f(\\theta - \\delta)\n$$\nNow we can apply the definition of covariance:\n$$\n\\operatorname{Cov}(Y(\\theta + \\delta), Y(\\theta - \\delta)) = \\mathbb{E}[(Y(\\theta + \\delta) - \\mathbb{E}[Y(\\theta + \\delta)])(Y(\\theta - \\delta) - \\mathbb{E}[Y(\\theta - \\delta)])]\n$$\nSubstituting the expressions for the observations and their means:\n$$\n= \\mathbb{E}[((f(\\theta + \\delta) + \\varepsilon_{+}) - f(\\theta + \\delta))((f(\\theta - \\delta) + \\varepsilon_{-}) - f(\\theta - \\delta))]\n$$\n$$\n= \\mathbb{E}[\\varepsilon_{+} \\varepsilon_{-}]\n$$\nBy definition, the covariance of the noise terms is $\\operatorname{Cov}(\\varepsilon_{+}, \\varepsilon_{-}) = \\mathbb{E}[\\varepsilon_{+} \\varepsilon_{-}] - \\mathbb{E}[\\varepsilon_{+}]\\mathbb{E}[\\varepsilon_{-}]$. Since $\\mathbb{E}[\\varepsilon_{+}] = 0$ and $\\mathbb{E}[\\varepsilon_{-}] = 0$, this simplifies to $\\operatorname{Cov}(\\varepsilon_{+}, \\varepsilon_{-}) = \\mathbb{E}[\\varepsilon_{+} \\varepsilon_{-}]$.\n\nThe correlation $\\rho$ is defined as $\\rho = \\operatorname{Corr}(\\varepsilon_{+}, \\varepsilon_{-}) = \\frac{\\operatorname{Cov}(\\varepsilon_{+}, \\varepsilon_{-})}{\\sqrt{\\operatorname{Var}(\\varepsilon_{+})\\operatorname{Var}(\\varepsilon_{-})}}$.\nWe are given $\\operatorname{Var}(\\varepsilon_{+}) = \\sigma^2$ and $\\operatorname{Var}(\\varepsilon_{-}) = \\sigma^2$. Substituting these into the correlation formula:\n$$\n\\rho = \\frac{\\operatorname{Cov}(\\varepsilon_{+}, \\varepsilon_{-})}{\\sqrt{\\sigma^2 \\cdot \\sigma^2}} = \\frac{\\operatorname{Cov}(\\varepsilon_{+}, \\varepsilon_{-})}{\\sigma^2}\n$$\nFrom this, we find $\\operatorname{Cov}(\\varepsilon_{+}, \\varepsilon_{-}) = \\rho \\sigma^2$. Therefore,\n$$\n\\operatorname{Cov}(Y(\\theta + \\delta), Y(\\theta - \\delta)) = \\rho \\sigma^2\n$$\n\n### Part 2: Derivation of $\\operatorname{Var}(\\widehat{g}(\\theta; \\delta))$\nWe need to derive the variance of the gradient estimator $\\widehat{g}(\\theta; \\delta)$ under CRN and, separately, under independence. We use the property of variance for a linear combination of random variables: $\\operatorname{Var}(aX + bZ) = a^2\\operatorname{Var}(X) + b^2\\operatorname{Var}(Z) + 2ab\\operatorname{Cov}(X, Z)$.\n\nThe estimator is $\\widehat{g}(\\theta; \\delta) = \\frac{1}{2\\delta} Y(\\theta + \\delta) - \\frac{1}{2\\delta} Y(\\theta - \\delta)$.\nHere, $a = \\frac{1}{2\\delta}$, $b = -\\frac{1}{2\\delta}$, $X = Y(\\theta + \\delta)$, and $Z = Y(\\theta - \\delta)$. The variance is:\n$$\n\\operatorname{Var}(\\widehat{g}(\\theta; \\delta)) = \\left(\\frac{1}{2\\delta}\\right)^2 \\operatorname{Var}(Y(\\theta + \\delta)) + \\left(-\\frac{1}{2\\delta}\\right)^2 \\operatorname{Var}(Y(\\theta - \\delta)) + 2\\left(\\frac{1}{2\\delta}\\right)\\left(-\\frac{1}{2\\delta}\\right) \\operatorname{Cov}(Y(\\theta + \\delta), Y(\\theta - \\delta))\n$$\n$$\n= \\frac{1}{4\\delta^2} \\left[ \\operatorname{Var}(Y(\\theta + \\delta)) + \\operatorname{Var}(Y(\\theta - \\delta)) - 2\\operatorname{Cov}(Y(\\theta + \\delta), Y(\\theta - \\delta)) \\right]\n$$\nFirst, we find the variances of the individual observations:\n$$\n\\operatorname{Var}(Y(\\theta + \\delta)) = \\operatorname{Var}(f(\\theta + \\delta) + \\varepsilon_{+}) = \\operatorname{Var}(\\varepsilon_{+}) = \\sigma^2\n$$\nbecause $f(\\theta + \\delta)$ is a deterministic constant. Similarly, $\\operatorname{Var}(Y(\\theta - \\delta)) = \\sigma^2$.\n\n**Case 1: Under CRN**\nWe substitute the variances and the covariance derived in Part 1 ($\\operatorname{Cov}(Y(\\theta + \\delta), Y(\\theta - \\delta)) = \\rho \\sigma^2$) into the expression for $\\operatorname{Var}(\\widehat{g}(\\theta; \\delta))$:\n$$\n\\operatorname{Var}(\\widehat{g}(\\theta; \\delta) \\text{ under CRN}) = \\frac{1}{4\\delta^2} [\\sigma^2 + \\sigma^2 - 2(\\rho \\sigma^2)] = \\frac{2\\sigma^2 - 2\\rho\\sigma^2}{4\\delta^2} = \\frac{2\\sigma^2(1 - \\rho)}{4\\delta^2}\n$$\n$$\n\\operatorname{Var}(\\widehat{g}(\\theta; \\delta) \\text{ under CRN}) = \\frac{\\sigma^2(1-\\rho)}{2\\delta^2}\n$$\n\n**Case 2: Under Independence**\nThe independence of $\\varepsilon_{+}$ and $\\varepsilon_{-}$ is equivalent to setting their correlation $\\rho = 0$. In this case, their covariance is zero, and thus $\\operatorname{Cov}(Y(\\theta + \\delta), Y(\\theta - \\delta)) = 0$. We can obtain the result by setting $\\rho=0$ in the CRN formula:\n$$\n\\operatorname{Var}(\\widehat{g}(\\theta; \\delta) \\text{ under independence}) = \\frac{\\sigma^2(1-0)}{2\\delta^2} = \\frac{\\sigma^2}{2\\delta^2}\n$$\nAlternatively, substituting $\\operatorname{Cov}(\\cdot)=0$ directly into the general variance formula:\n$$\n\\operatorname{Var}(\\widehat{g}(\\theta; \\delta) \\text{ under independence}) = \\frac{1}{4\\delta^2} [\\sigma^2 + \\sigma^2 - 0] = \\frac{2\\sigma^2}{4\\delta^2} = \\frac{\\sigma^2}{2\\delta^2}\n$$\n\n### Part 3: Computation of the Variance Impact Ratio $R(\\rho)$\nThe variance impact ratio $R(\\rho)$ is defined as the ratio of the variance of the estimator under CRN to its variance under independence.\n$$\nR(\\rho) = \\frac{\\operatorname{Var}(\\widehat{g}(\\theta; \\delta) \\text{ under CRN})}{\\operatorname{Var}(\\widehat{g}(\\theta; \\delta) \\text{ under independence})}\n$$\nUsing the expressions derived in Part 2:\n$$\nR(\\rho) = \\frac{\\frac{\\sigma^2(1-\\rho)}{2\\delta^2}}{\\frac{\\sigma^2}{2\\delta^2}}\n$$\nThe terms $\\frac{\\sigma^2}{2\\delta^2}$ in the numerator and denominator cancel out, as long as $\\sigma^2 > 0$ and $\\delta > 0$, which are given. This leaves:\n$$\nR(\\rho) = 1 - \\rho\n$$\nThis expression quantifies the effect of using CRN. A positive correlation ($\\rho > 0$) reduces the variance of the gradient estimate, which is the primary motivation for using CRN in this context. A negative correlation ($\\rho < 0$) inflates the variance.", "answer": "$$\n\\boxed{1 - \\rho}\n$$", "id": "3348680"}, {"introduction": "Bridging classical theory with modern large-scale optimization, this exercise explores the use of mini-batching within the Robbins-Monro framework [@problem_id:3348743]. You will investigate how averaging over small batches of data at each step influences the algorithm's convergence properties. The ultimate goal is to optimize the learning rate and batch schedule jointly to minimize error under a fixed computational budget, revealing how these foundational algorithms can be adapted for maximum efficiency in data-rich environments.", "problem": "Consider the one-dimensional Robbins-Monro (RM) stochastic approximation for finding the unique root $\\theta^{\\star}$ of a continuously differentiable function $h(\\theta)$ satisfying $h(\\theta^{\\star})=0$ and $h'(\\theta^{\\star})=b>0$. At iteration $n$, you observe conditionally independent and identically distributed (i.i.d.) samples $\\{g(\\theta_n,\\xi_{n,i})\\}_{i=1}^{m_n}$ given $\\theta_n$, where $\\xi_{n,i}$ are i.i.d. exogenous random inputs, and the observation model satisfies $\\mathbb{E}[\\,g(\\theta,\\xi)\\,]=h(\\theta)$ and $\\operatorname{Var}(g(\\theta^{\\star},\\xi))=\\sigma^2 \\in (0,\\infty)$. Define the mini-batch average \n$$\n\\overline{Y}_n \\equiv \\frac{1}{m_n}\\sum_{i=1}^{m_n} g(\\theta_n,\\xi_{n,i}),\n$$\nand consider the mini-batched RM update \n$$\n\\theta_{n+1}=\\theta_n - a_n \\overline{Y}_n,\n$$\nwith step-size sequence $a_n=\\frac{a}{n}$ for a constant $a>0$ and an integer batch-size sequence $\\{m_n\\}_{n\\geq 1}$.\n\nAssume that $h$ is twice continuously differentiable in a neighborhood of $\\theta^{\\star}$, that $b=h'(\\theta^{\\star})>0$, and that the family $\\{g(\\theta,\\xi)\\}$ satisfies a local quadratic expansion with a Lindeberg condition ensuring a central limit theorem for triangular arrays. Suppose the algorithm is run for $N$ iterations at total sample budget \n$$\nK=\\sum_{n=1}^{N} m_n,\n$$\nand consider the asymptotic regime $K\\to\\infty$ and $N\\to\\infty$ with $a_n=\\frac{a}{n}$ and a batch schedule satisfying $\\lim_{n\\to\\infty} m_n=\\overline{m}\\in(0,\\infty)$.\n\nStarting from the linearization of $h(\\theta)$ around $\\theta^{\\star}$ and the conditional variance reduction induced by the averaging $\\overline{Y}_n$, derive the leading-order asymptotic expression for the mean squared error $\\mathbb{E}\\big[(\\theta_N-\\theta^{\\star})^2\\big]$ in terms of $a$, $b$, $\\sigma^2$, $N$, and $\\{m_n\\}$. Then, using only this first-order asymptotic and the budget constraint $K=\\sum_{n=1}^{N} m_n$, optimize jointly over the constant $a>0$ and the batch schedule $\\{m_n\\}$ to minimize the leading-order asymptotic mean squared error as a function of $K$. \n\nWhat is the resulting minimal leading-order asymptotic mean squared error as a closed-form expression in $b$, $\\sigma^2$, and $K$? Provide your final expression in exact form. Do not include units.", "solution": "The problem asks for the minimal leading-order asymptotic mean squared error (MSE) of a mini-batched Robbins-Monro (RM) algorithm, optimized over both the step-size constant $a$ and the batch schedule $\\{m_n\\}$.\n\nLet the error at iteration $n$ be $e_n \\equiv \\theta_n - \\theta^{\\star}$. The RM update rule is given as:\n$$\n\\theta_{n+1} = \\theta_n - a_n \\overline{Y}_n\n$$\nSubtracting the true root $\\theta^{\\star}$ from both sides, we obtain the recursion for the error:\n$$\ne_{n+1} = e_n - a_n \\overline{Y}_n\n$$\nThe mini-batch average $\\overline{Y}_n$ is an estimate of $h(\\theta_n)$. We can decompose it as:\n$$\n\\overline{Y}_n = \\mathbb{E}[\\overline{Y}_n | \\theta_n] + (\\overline{Y}_n - \\mathbb{E}[\\overline{Y}_n | \\theta_n]) = h(\\theta_n) + M_n\n$$\nwhere $M_n$ is a martingale difference sequence with respect to the filtration generated by the iterates, $\\mathcal{F}_n = \\sigma(\\theta_1, \\dots, \\theta_n)$. The conditional variance of $M_n$ is the variance of the mini-batch average:\n$$\n\\operatorname{Var}(\\overline{Y}_n | \\theta_n) = \\frac{1}{m_n} \\operatorname{Var}(g(\\theta_n, \\xi))\n$$\nAs $\\theta_n \\to \\theta^{\\star}$, this conditional variance converges to $\\frac{\\sigma^2}{m_n}$, since $\\operatorname{Var}(g(\\theta^{\\star}, \\xi)) = \\sigma^2$.\n\nThe function $h(\\theta)$ is continuously differentiable near $\\theta^{\\star}$ with $h(\\theta^{\\star})=0$ and $h'(\\theta^{\\star})=b>0$. A first-order Taylor expansion of $h(\\theta_n)$ around $\\theta^{\\star}$ yields:\n$$\nh(\\theta_n) = h(\\theta^{\\star}) + h'(\\theta^{\\star})(\\theta_n - \\theta^{\\star}) + o(|\\theta_n - \\theta^{\\star}|) = b e_n + o(|e_n|)\n$$\nSubstituting these expressions into the error recursion, we get the linearized recursion:\n$$\ne_{n+1} \\approx e_n - a_n (b e_n + M_n) = (1 - a_n b) e_n - a_n M_n\n$$\nWith the step-size $a_n = \\frac{a}{n}$, the recursion becomes:\n$$\ne_{n+1} \\approx \\left(1 - \\frac{ab}{n}\\right) e_n - \\frac{a}{n} M_n\n$$\nThis is a standard stochastic approximation recursion. For this algorithm, under the given conditions (including the Lindeberg condition and $\\lim_{n \\to \\infty} m_n = \\overline{m} \\in (0, \\infty)$), a central limit theorem holds for $\\theta_n$ provided that $ab > 1/2$. The theorem states that:\n$$\n\\sqrt{n}(\\theta_n - \\theta^{\\star}) \\xrightarrow{d} \\mathcal{N}(0, V)\n$$\nwhere $\\xrightarrow{d}$ denotes convergence in distribution, and $V$ is the asymptotic variance. The standard formula for the asymptotic variance, adapted for mini-batching, is:\n$$\nV = \\frac{a^2 (\\sigma^2 / \\overline{m})}{2ab - 1} = \\frac{a^2 \\sigma^2}{(2ab - 1)\\overline{m}}\n$$\nFrom this asymptotic normality result, the leading-order expression for the mean squared error at a large number of iterations $N$ is:\n$$\n\\mathbb{E}\\big[(\\theta_N - \\theta^{\\star})^2\\big] \\approx \\frac{V}{N} = \\frac{a^2 \\sigma^2}{(2ab - 1)N\\overline{m}}\n$$\nThis expression constitutes the first-order asymptotic MSE requested by the problem.\n\nThe next step is to optimize this MSE jointly over $a > 0$ and the batch schedule $\\{m_n\\}_{n\\geq 1}$, subject to the total sample budget $K = \\sum_{n=1}^{N} m_n$. The asymptotic MSE expression depends on the schedule $\\{m_n\\}$ only through its limit $\\overline{m}$. The budget constraint provides a relationship between $K$, $N$, and the batch sizes. For large $N$ and a schedule where $m_n$ converges to $\\overline{m}$, the sum can be approximated by the average:\n$$\nK = \\sum_{n=1}^{N} m_n \\approx N \\overline{m}\n$$\nThis implies $\\overline{m} \\approx \\frac{K}{N}$. This approximation is consistent with the problem's asymptotic regime ($K \\to \\infty, N \\to \\infty$) and the constraint that $\\lim m_n$ exists and is finite. Substituting $\\overline{m} \\approx K/N$ into the MSE expression, we find that the terms $N$ and $\\overline{m}$ cancel out:\n$$\n\\mathbb{E}\\big[(\\theta_N - \\theta^{\\star})^2\\big] \\approx \\frac{a^2 \\sigma^2}{(2ab - 1)N (K/N)} = \\frac{\\sigma^2}{K} \\cdot \\frac{a^2}{2ab - 1}\n$$\nThe optimization problem now simplifies to minimizing this expression. Since $\\sigma^2$, $b$, and $K$ are positive constants, we only need to minimize the factor depending on $a$:\n$$\nf(a) = \\frac{a^2}{2ab - 1}\n$$\nThis minimization is subject to the stability condition $2ab - 1 > 0$, which means $a > \\frac{1}{2b}$. To find the minimum, we compute the derivative of $f(a)$ with respect to $a$:\n$$\nf'(a) = \\frac{d}{da} \\left( \\frac{a^2}{2ab - 1} \\right) = \\frac{2a(2ab - 1) - a^2(2b)}{(2ab - 1)^2} = \\frac{4a^2b - 2a - 2a^2b}{(2ab - 1)^2} = \\frac{2a^2b - 2a}{(2ab - 1)^2}\n$$\nSetting the derivative to zero to find critical points for $a > 0$:\n$$\n2a^2b - 2a = 0 \\implies 2a(ab - 1) = 0\n$$\nSince $a>0$, the solution is $ab - 1 = 0$, which yields the optimal step-size constant:\n$$\na^{\\star} = \\frac{1}{b}\n$$\nThis value satisfies the stability condition $a^{\\star} = \\frac{1}{b} > \\frac{1}{2b}$ since $b > 0$. A check of the second derivative confirms this is a minimum.\n\nFinally, we substitute this optimal value $a^{\\star} = 1/b$ back into the minimal factor $f(a)$:\n$$\nf(a^{\\star}) = f\\left(\\frac{1}{b}\\right) = \\frac{(1/b)^2}{2(1/b)b - 1} = \\frac{1/b^2}{2 - 1} = \\frac{1}{b^2}\n$$\nThe resulting minimal leading-order asymptotic MSE is obtained by multiplying this minimal factor by $\\frac{\\sigma^2}{K}$:\n$$\n\\text{Minimal MSE} = \\frac{\\sigma^2}{K} \\cdot \\frac{1}{b^2} = \\frac{\\sigma^2}{b^2 K}\n$$\nThis expression represents the lowest achievable MSE under the given conditions and asymptotic framework, and it equals the Cramér-Rao lower bound for estimating $\\theta^{\\star}$ given $K$ samples in an equivalent oracle problem, indicating that the optimized RM procedure is asymptotically efficient.", "answer": "$$\\boxed{\\frac{\\sigma^2}{b^2 K}}$$", "id": "3348743"}]}