{"hands_on_practices": [{"introduction": "Before simulating the long-timescale evolution of a system, we must first define the rules of its dynamics. This exercise [@problem_id:3358266] focuses on the foundational task of constructing a valid generator matrix for a Kinetic Monte Carlo (KMC) simulation. You will learn how to translate physical parameters, such as energy barriers and attempt frequencies, into a set of transition rates that correctly satisfy the crucial principle of detailed balance, ensuring your simulation can accurately capture the system's equilibrium properties.", "problem": "Consider a continuous-time Markov chain defined on a one-dimensional periodic lattice with $N$ sites labeled $i \\in \\{0,1,\\dots,N-1\\}$ and nearest-neighbor connectivity. The generator matrix $Q$ of a continuous-time Markov chain satisfies that for each $i$, $q_{ii} = -\\sum_{j \\neq i} q_{ij}$ and $q_{ij} \\ge 0$ for $j \\neq i$. The off-diagonal entries $q_{ij}$ are transition rates $k_{ij}$.\n\nAssume the dynamics are governed by Transition State Theory (TST) with Arrhenius form, where the rate from state $i$ to state $j$ is given by $k_{ij} = \\nu_{ij} \\exp\\left(-\\frac{E^{\\ddagger}_{ij} - E_i}{k_{\\mathrm{B}} T}\\right)$, with $E_i$ the energy of state $i$, $E^{\\ddagger}_{ij}$ the transition saddle energy for the $i \\to j$ transition, $\\nu_{ij}$ the attempt frequency, $k_{\\mathrm{B}}$ the Boltzmann constant, and $T$ the absolute temperature. Microscopic reversibility requires that for any pair of neighboring states $(i,j)$, the same saddle energy governs both directions, i.e., $E^{\\ddagger}_{ij} = E^{\\ddagger}_{ji}$.\n\nDetailed balance with respect to the Boltzmann distribution requires that there exists an equilibrium distribution $\\pi$ with $\\pi_i \\propto \\exp\\left(-\\frac{E_i}{k_{\\mathrm{B}} T}\\right)$ such that for all pairs $(i,j)$, $\\pi_i k_{ij} = \\pi_j k_{ji}$. Starting from the fundamental definitions above, construct a generator $Q$ that enforces microscopic reversibility for given barrier suggestions and attempt frequencies, and verify detailed balance numerically.\n\nFor each test case below, you are given:\n- A lattice size $N$ and periodic nearest-neighbor connectivity between $i$ and $(i+1) \\bmod N$.\n- State energies $E_i$ in electronvolts ($\\mathrm{eV}$).\n- Barrier suggestions for forward transitions $b^{\\mathrm{fwd}}_i$ for $i \\to (i+1) \\bmod N$, and for backward transitions $b^{\\mathrm{bwd}}_i$ for $(i+1) \\bmod N \\to i$, both in $\\mathrm{eV}$.\n- Attempt frequencies $\\nu^{\\mathrm{fwd}}_i$ and $\\nu^{\\mathrm{bwd}}_i$ in $\\mathrm{s}^{-1}$.\n- A temperature $T$ in Kelvin ($\\mathrm{K}$).\nUse the Boltzmann constant $k_{\\mathrm{B}} = 8.617333262145 \\times 10^{-5}$ $\\mathrm{eV}/\\mathrm{K}$.\n\nYour tasks for each test case:\n1. From the provided $E$, $b^{\\mathrm{fwd}}$, $b^{\\mathrm{bwd}}$, $\\nu^{\\mathrm{fwd}}$, and $\\nu^{\\mathrm{bwd}}$, construct transition rates $k_{ij}$ for the ring that satisfy microscopic reversibility and yield a reversible generator $Q$ with respect to the Boltzmann distribution at temperature $T$. The construction must start from the provided fundamental definitions without assuming any non-derived shortcut formulas.\n2. Form the generator $Q$ with $q_{ij} = k_{ij}$ for $j \\neq i$ and $q_{ii} = -\\sum_{j \\neq i} k_{ij}$.\n3. Compute the Boltzmann equilibrium weights $\\pi_i \\propto \\exp\\left(-\\frac{E_i}{k_{\\mathrm{B}} T}\\right)$, normalized so that $\\sum_i \\pi_i = 1$.\n4. Compute the maximum absolute detailed-balance residual over all nearest-neighbor pairs,\n$$\nr_{\\max} = \\max_{i} \\left| \\pi_i k_{i,(i+1)\\bmod N} - \\pi_{(i+1)\\bmod N} k_{(i+1)\\bmod N,i} \\right|.\n$$\nReport $r_{\\max}$ in $\\mathrm{s}^{-1}$ for each test case.\n\nTest suite:\n- Case $1$ (happy path, symmetric attempt frequencies and consistent barriers):\n    - $N = 4$,\n    - $E = [\\,0.00,\\,0.05,\\,0.10,\\,0.20\\,]$ $\\mathrm{eV}$,\n    - $b^{\\mathrm{fwd}} = [\\,0.40,\\,0.45,\\,0.50,\\,0.60\\,]$ $\\mathrm{eV}$,\n    - $b^{\\mathrm{bwd}} = [\\,0.40,\\,0.45,\\,0.50,\\,0.60\\,]$ $\\mathrm{eV}$,\n    - $\\nu^{\\mathrm{fwd}} = [\\,1.0 \\times 10^{13},\\,1.0 \\times 10^{13},\\,1.0 \\times 10^{13},\\,1.0 \\times 10^{13}\\,]$ $\\mathrm{s}^{-1}$,\n    - $\\nu^{\\mathrm{bwd}} = [\\,1.0 \\times 10^{13},\\,1.0 \\times 10^{13},\\,1.0 \\times 10^{13},\\,1.0 \\times 10^{13}\\,]$ $\\mathrm{s}^{-1}$,\n    - $T = 300.0$ $\\mathrm{K}$.\n- Case $2$ (non-symmetric attempt frequencies and asymmetric barrier suggestions):\n    - $N = 5$,\n    - $E = [\\,0.00,\\,0.02,\\,0.08,\\,0.04,\\,0.10\\,]$ $\\mathrm{eV}$,\n    - $b^{\\mathrm{fwd}} = [\\,0.35,\\,0.37,\\,0.42,\\,0.40,\\,0.45\\,]$ $\\mathrm{eV}$,\n    - $b^{\\mathrm{bwd}} = [\\,0.33,\\,0.39,\\,0.41,\\,0.43,\\,0.44\\,]$ $\\mathrm{eV}$,\n    - $\\nu^{\\mathrm{fwd}} = [\\,1.0 \\times 10^{13},\\,2.0 \\times 10^{13},\\,0.5 \\times 10^{13},\\,1.5 \\times 10^{13},\\,1.0 \\times 10^{13}\\,]$ $\\mathrm{s}^{-1}$,\n    - $\\nu^{\\mathrm{bwd}} = [\\,0.8 \\times 10^{13},\\,1.8 \\times 10^{13},\\,0.7 \\times 10^{13},\\,1.2 \\times 10^{13},\\,0.9 \\times 10^{13}\\,]$ $\\mathrm{s}^{-1}$,\n    - $T = 350.0$ $\\mathrm{K}$.\n- Case $3$ (high barriers, slow kinetics):\n    - $N = 3$,\n    - $E = [\\,0.00,\\,0.10,\\,0.20\\,]$ $\\mathrm{eV}$,\n    - $b^{\\mathrm{fwd}} = [\\,1.00,\\,0.90,\\,1.10\\,]$ $\\mathrm{eV}$,\n    - $b^{\\mathrm{bwd}} = [\\,1.00,\\,0.90,\\,1.10\\,]$ $\\mathrm{eV}$,\n    - $\\nu^{\\mathrm{fwd}} = [\\,1.0 \\times 10^{13},\\,1.0 \\times 10^{13},\\,1.0 \\times 10^{13}\\,]$ $\\mathrm{s}^{-1}$,\n    - $\\nu^{\\mathrm{bwd}} = [\\,1.0 \\times 10^{13},\\,1.0 \\times 10^{13},\\,1.0 \\times 10^{13}\\,]$ $\\mathrm{s}^{-1}$,\n    - $T = 300.0$ $\\mathrm{K}$.\n- Case $4$ (degenerate energies, heterogeneous attempt frequencies and barrier suggestions):\n    - $N = 4$,\n    - $E = [\\,0.05,\\,0.05,\\,0.05,\\,0.05\\,]$ $\\mathrm{eV}$,\n    - $b^{\\mathrm{fwd}} = [\\,0.25,\\,0.30,\\,0.28,\\,0.27\\,]$ $\\mathrm{eV}$,\n    - $b^{\\mathrm{bwd}} = [\\,0.26,\\,0.29,\\,0.31,\\,0.24\\,]$ $\\mathrm{eV}$,\n    - $\\nu^{\\mathrm{fwd}} = [\\,1.0 \\times 10^{13},\\,1.2 \\times 10^{13},\\,0.9 \\times 10^{13},\\,1.1 \\times 10^{13}\\,]$ $\\mathrm{s}^{-1}$,\n    - $\\nu^{\\mathrm{bwd}} = [\\,0.8 \\times 10^{13},\\,1.3 \\times 10^{13},\\,1.0 \\times 10^{13},\\,1.2 \\times 10^{13}\\,]$ $\\mathrm{s}^{-1}$,\n    - $T = 400.0$ $\\mathrm{K}$.\n\nFinal output format:\nYour program should produce a single line of output containing the list of the four $r_{\\max}$ values, in $\\mathrm{s}^{-1}$, as a comma-separated Python-style list, for example $[r_1,r_2,r_3,r_4]$, where each $r_i$ corresponds to Case $i$ in the same order. No extra text should be printed.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in statistical mechanics and the theory of stochastic processes, well-posed, objective, and contains all necessary information to construct a unique and meaningful solution. The core of the problem involves constructing a physically consistent rate model from potentially inconsistent input suggestions, which is a standard and non-trivial task in computational physics and chemistry.\n\nThe solution proceeds by first establishing the theoretical framework and then detailing the construction of the transition rates and the subsequent calculation of the detailed balance residual.\n\nThe system is a continuous-time Markov chain on a periodic one-dimensional lattice of $N$ sites, indexed by $i \\in \\{0, 1, \\dots, N-1\\}$. Transitions are restricted to nearest neighbors. The rate of transition from state $i$ to state $j$, $k_{ij}$, is given by the Arrhenius form derived from Transition State Theory:\n$$\nk_{ij} = \\nu_{ij} \\exp\\left(-\\frac{E^{\\ddagger}_{ij} - E_i}{k_{\\mathrm{B}} T}\\right)\n$$\nwhere $E_i$ is the energy of state $i$, $E^{\\ddagger}_{ij}$ is the energy of the transition state (saddle point) between $i$ and $j$, $\\nu_{ij}$ is the attempt frequency, $k_{\\mathrm{B}}$ is the Boltzmann constant, and $T$ is the absolute temperature.\n\nThe dynamics must satisfy two fundamental principles: microscopic reversibility and detailed balance.\n\n1.  **Microscopic Reversibility**: The problem defines this principle as requiring that the transition path between two states $i$ and $j$ is the same regardless of direction. This implies a single, shared saddle point energy, i.e., $E^{\\ddagger}_{ij} = E^{\\ddagger}_{ji}$ for any connected pair $(i,j)$.\n\n2.  **Detailed Balance**: For a system at thermal equilibrium, the net flux between any two states must be zero. This is expressed by the detailed balance condition:\n    $$\n    \\pi_i k_{ij} = \\pi_j k_{ji}\n    $$\n    where $\\pi$ is the equilibrium distribution. For a system in contact with a thermal reservoir, this is the Boltzmann distribution:\n    $$\n    \\pi_i = \\frac{1}{Z} \\exp\\left(-\\frac{E_i}{k_{\\mathrm{B}} T}\\right)\n    $$\n    with $Z = \\sum_k \\exp(-\\frac{E_k}{k_{\\mathrm{B}} T})$ being the partition function.\n\nLet us substitute the Arrhenius expression for the rates into the detailed balance equation. Let $\\beta = 1/(k_{\\mathrm{B}}T)$.\n$$\n\\frac{e^{-\\beta E_i}}{Z} \\left( \\nu_{ij} e^{-\\beta(E^{\\ddagger}_{ij} - E_i)} \\right) = \\frac{e^{-\\beta E_j}}{Z} \\left( \\nu_{ji} e^{-\\beta(E^{\\ddagger}_{ji} - E_j)} \\right)\n$$\nSimplifying the exponentials yields:\n$$\n\\nu_{ij} e^{-\\beta E^{\\ddagger}_{ij}} = \\nu_{ji} e^{-\\beta E^{\\ddagger}_{ji}}\n$$\nThis equation is the fundamental constraint imposed by detailed balance on the TST parameters. If we now enforce the principle of microscopic reversibility, $E^{\\ddagger}_{ij} = E^{\\ddagger}_{ji}$, the exponential terms cancel, leaving a constraint on the attempt frequencies:\n$$\n\\nu_{ij} = \\nu_{ji}\n$$\nThus, to construct a physically valid model satisfying both principles, we must ensure that for each pair of connected states $(i,j)$, there is a single saddle energy $E^{\\ddagger}_{ij}=E^{\\ddagger}_{ji}$ and a single attempt frequency $\\nu_{ij}=\\nu_{ji}$.\n\nThe problem provides potentially inconsistent \"suggestions\" for these parameters from forward and backward perspectives. The task is to construct a consistent set of parameters from these suggestions. For each nearest-neighbor pair $(i, j=(i+1)\\bmod N)$:\n\n-   **Saddle Energy Construction**: The problem provides a forward barrier suggestion $b^{\\mathrm{fwd}}_i$ and a backward barrier suggestion $b^{\\mathrm{bwd}}_i$. These correspond to two suggestions for the absolute saddle energy:\n    -   Forward suggestion: $E^{\\ddagger, \\mathrm{fwd}}_{ij} = E_i + b^{\\mathrm{fwd}}_i$\n    -   Backward suggestion: $E^{\\ddagger, \\mathrm{bwd}}_{ji} = E_j + b^{\\mathrm{bwd}}_i$\n    To satisfy $E^{\\ddagger}_{ij} = E^{\\ddagger}_{ji}$, we must reconcile these two values. A physically symmetric and robust choice is the arithmetic mean of the two suggested absolute energies. Let us denote the single saddle for the pair $(i,j)$ by $E^{\\ddagger}_{i,(i+1)\\bmod N}$:\n    $$\n    E^{\\ddagger}_{i,(i+1)\\bmod N} = \\frac{1}{2} \\left[ (E_i + b^{\\mathrm{fwd}}_i) + (E_{(i+1)\\bmod N} + b^{\\mathrm{bwd}}_i) \\right]\n    $$\n\n-   **Attempt Frequency Construction**: The problem provides a forward attempt frequency suggestion $\\nu^{\\mathrm{fwd}}_i$ and a backward suggestion $\\nu^{\\mathrm{bwd}}_i$. To satisfy $\\nu_{ij}=\\nu_{ji}$, we must again reconcile these. For rates and frequencies, which are combined multiplicatively in the underlying statistical theories, the geometric mean is the appropriate choice for averaging. We define the single attempt frequency for the pair $(i,j)$ as:\n    $$\n    \\nu_{i,(i+1)\\bmod N} = \\sqrt{\\nu^{\\mathrm{fwd}}_i \\nu^{\\mathrm{bwd}}_i}\n    $$\n\nWith these constructed symmetric parameters, we can define the final, consistent forward and backward rates for each pair $(i, j=(i+1)\\bmod N)$:\n-   Forward rate: $k_{i,j} = \\nu_{i,j} \\exp\\left( - \\frac{E^{\\ddagger}_{i,j} - E_i}{k_{\\mathrm{B}} T} \\right)$\n-   Backward rate: $k_{j,i} = \\nu_{i,j} \\exp\\left( - \\frac{E^{\\ddagger}_{i,j} - E_j}{k_{\\mathrm{B}} T} \\right)$\nBy construction, these rates will satisfy the detailed balance condition. The numerical task is to calculate the residual $\\left| \\pi_i k_{i,j} - \\pi_j k_{j,i} \\right|$ for each pair, which should be zero up to floating-point precision, and report the maximum such value.\n\nThe algorithm is as follows for each test case:\n1.  Define constants $k_{\\mathrm{B}}$ and calculate $\\beta = 1/(k_{\\mathrm{B}}T)$.\n2.  Initialize an empty matrix for the rates $k_{ij}$.\n3.  For each site $i$ from $0$ to $N-1$:\n    a. Identify the neighbor $j = (i+1) \\bmod N$.\n    b. Construct the symmetric saddle energy $E^{\\ddagger}_{i,j}$ using the arithmetic mean of the suggestions.\n    c. Construct the symmetric attempt frequency $\\nu_{i,j}$ using the geometric mean of the suggestions.\n    d. Calculate the forward rate $k_{ij}$ and backward rate $k_{ji}$ using these constructed parameters. Store them.\n4.  Calculate the normalized Boltzmann distribution $\\pi_i = \\exp(-\\beta E_i) / \\sum_k \\exp(-\\beta E_k)$.\n5.  Initialize $r_{\\max} = 0$.\n6.  For each site $i$ from $0$ to $N-1$:\n    a. Identify the neighbor $j=(i+1)\\bmod N$.\n    b. Compute the residual $r = |\\pi_i k_{ij} - \\pi_j k_{ji}|$.\n    c. Update $r_{\\max} = \\max(r_{\\max}, r)$.\n7.  The final result for the case is $r_{\\max}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the problem of constructing a consistent Markov chain generator\n    and verifying detailed balance numerically for several test cases.\n    \"\"\"\n    \n    # Define the Boltzmann constant in eV/K.\n    k_B = 8.617333262145e-5\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\n            \"N\": 4,\n            \"E\": np.array([0.00, 0.05, 0.10, 0.20]),\n            \"b_fwd\": np.array([0.40, 0.45, 0.50, 0.60]),\n            \"b_bwd\": np.array([0.40, 0.45, 0.50, 0.60]),\n            \"nu_fwd\": np.array([1.0e13, 1.0e13, 1.0e13, 1.0e13]),\n            \"nu_bwd\": np.array([1.0e13, 1.0e13, 1.0e13, 1.0e13]),\n            \"T\": 300.0\n        },\n        # Case 2\n        {\n            \"N\": 5,\n            \"E\": np.array([0.00, 0.02, 0.08, 0.04, 0.10]),\n            \"b_fwd\": np.array([0.35, 0.37, 0.42, 0.40, 0.45]),\n            \"b_bwd\": np.array([0.33, 0.39, 0.41, 0.43, 0.44]),\n            \"nu_fwd\": np.array([1.0e13, 2.0e13, 0.5e13, 1.5e13, 1.0e13]),\n            \"nu_bwd\": np.array([0.8e13, 1.8e13, 0.7e13, 1.2e13, 0.9e13]),\n            \"T\": 350.0\n        },\n        # Case 3\n        {\n            \"N\": 3,\n            \"E\": np.array([0.00, 0.10, 0.20]),\n            \"b_fwd\": np.array([1.00, 0.90, 1.10]),\n            \"b_bwd\": np.array([1.00, 0.90, 1.10]),\n            \"nu_fwd\": np.array([1.0e13, 1.0e13, 1.0e13]),\n            \"nu_bwd\": np.array([1.0e13, 1.0e13, 1.0e13]),\n            \"T\": 300.0\n        },\n        # Case 4\n        {\n            \"N\": 4,\n            \"E\": np.array([0.05, 0.05, 0.05, 0.05]),\n            \"b_fwd\": np.array([0.25, 0.30, 0.28, 0.27]),\n            \"b_bwd\": np.array([0.26, 0.29, 0.31, 0.24]),\n            \"nu_fwd\": np.array([1.0e13, 1.2e13, 0.9e13, 1.1e13]),\n            \"nu_bwd\": np.array([0.8e13, 1.3e13, 1.0e13, 1.2e13]),\n            \"T\": 400.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        N = case[\"N\"]\n        E = case[\"E\"]\n        b_fwd = case[\"b_fwd\"]\n        b_bwd = case[\"b_bwd\"]\n        nu_fwd = case[\"nu_fwd\"]\n        nu_bwd = case[\"nu_bwd\"]\n        T = case[\"T\"]\n\n        # Calculate thermal energy in eV\n        kT = k_B * T\n\n        # The rate matrix k_matrix will store the off-diagonal elements of the generator Q.\n        k_matrix = np.zeros((N, N))\n\n        for i in range(N):\n            j = (i + 1) % N\n\n            # Construct the single, symmetric saddle energy E_saddle for the pair (i,j)\n            # by taking the arithmetic mean of the suggested absolute saddle energies.\n            suggested_fwd_saddle = E[i] + b_fwd[i]\n            suggested_bwd_saddle = E[j] + b_bwd[i]\n            E_saddle = 0.5 * (suggested_fwd_saddle + suggested_bwd_saddle)\n\n            # Construct the single, symmetric attempt frequency nu_sym for the pair (i,j)\n            # by taking the geometric mean of the suggested frequencies.\n            nu_sym = np.sqrt(nu_fwd[i] * nu_bwd[i])\n\n            # Calculate the forward rate k_ij (i -> j)\n            activation_energy_fwd = E_saddle - E[i]\n            k_ij = nu_sym * np.exp(-activation_energy_fwd / kT)\n            \n            # Calculate the backward rate k_ji (j -> i)\n            activation_energy_bwd = E_saddle - E[j]\n            k_ji = nu_sym * np.exp(-activation_energy_bwd / kT)\n\n            k_matrix[i, j] = k_ij\n            k_matrix[j, i] = k_ji\n        \n        # Calculate the normalized Boltzmann equilibrium distribution pi.\n        pi_unnorm = np.exp(-E / kT)\n        partition_func = np.sum(pi_unnorm)\n        pi = pi_unnorm / partition_func\n\n        # Calculate the maximum absolute detailed-balance residual.\n        max_residual = 0.0\n        for i in range(N):\n            j = (i + 1) % N\n            residual = np.abs(pi[i] * k_matrix[i, j] - pi[j] * k_matrix[j, i])\n            if residual > max_residual:\n                max_residual = residual\n        \n        results.append(max_residual)\n\n    # Final print statement in the exact required format.\n    # The results should be nearly zero due to the construction method.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3358266"}, {"introduction": "The heart of Transition Path Sampling (TPS) lies in its ability to generate new examples of rare reactive events from existing ones. This hands-on problem [@problem_id:3358213] challenges you to implement the workhorse of TPS: the shooting move. By taking an existing path, applying a small perturbation, and \"shooting\" forward and backward in time, you will construct a new candidate trajectory and, most importantly, derive and compute the correct Metropolis acceptance probability that ensures detailed balance is maintained in path space.", "problem": "You are asked to implement a complete, deterministic computation of the acceptance probability for a single shooting move in Transition Path Sampling (TPS) for a one-dimensional overdamped Langevin process. The goal is to algorithmically compute the Metropolis acceptance probability for a proposed path generated by a guided shooting move that perturbs one time slice and reuses the Gaussian noise increments of the original discretized path.\n\nThe physical and probabilistic base is the overdamped Langevin Stochastic Differential Equation (SDE) with potential energy function $U(x)$, diffusion coefficient $D$, and inverse temperature $\\beta$ specified as $1$:\n- The SDE is $dx_t = b(x_t)\\,dt + \\sqrt{2D}\\,dW_t$, where $b(x) = -D\\,\\beta\\,U'(x)$.\n- The process is discretized by the Euler–Maruyama scheme with time step $dt$, so that for a path $\\{x_0, x_1, \\dots, x_T\\}$,\n  $$x_{t+1} = x_t + b(x_t)\\,dt + \\sqrt{2D\\,dt}\\,w_t,$$\n  where each $w_t$ is a standard normal variate.\n\nIn the path ensemble, the path probability density (relative to Wiener measure) can be represented by the discrete Onsager–Machlup functional,\n$$\\mathcal{S}[x_0,\\dots,x_T] = \\sum_{t=0}^{T-1}\\left[\\frac{\\left(x_{t+1}-x_t-b(x_t)\\,dt\\right)^2}{4D\\,dt} + \\frac{1}{2}\\,b'(x_t)\\,dt\\right],$$\nwhere $b'(x) = \\frac{db(x)}{dx}$. The Metropolis–Hastings acceptance probability for a proposed new path is determined by detailed balance in path space with respect to this weight.\n\nImplement the following guided shooting move and compute its acceptance probability under the Metropolis rule:\n- Given an original discretized path $\\{x_0,\\dots,x_T\\}$, a perturbation magnitude $\\sigma$, a shooting time index $s\\in\\{0,1,\\dots,T\\}$, and a scalar $z$ defining the kick $\\delta = \\sigma\\,z$, generate a proposed path $\\{x'_0,\\dots,x'_T\\}$ by:\n  1. Computing the Gaussian noise increments from the original path using\n     $$w_t = \\frac{x_{t+1}-x_t-b(x_t)\\,dt}{\\sqrt{2D\\,dt}},\\quad t=0,\\dots,T-1.$$\n  2. Applying the kick at the shooting index: $x'_s = x_s + \\delta$.\n  3. Propagating forward for $t=s,\\dots,T-1$ with the same $w_t$:\n     $$x'_{t+1} = x'_t + b(x'_t)\\,dt + \\sqrt{2D\\,dt}\\,w_t.$$\n  4. Propagating backward for $t=s-1,\\dots,0$ by solving for $x'_t$ in\n     $$x'_{t+1} = x'_t + b(x'_t)\\,dt + \\sqrt{2D\\,dt}\\,w_t.$$\n     This is a one-dimensional nonlinear equation for each $t$, which must be solved numerically to high precision. You may assume the function $f(x) = x + b(x)\\,dt + \\sqrt{2D\\,dt}\\,w_t - x'_{t+1}$ is smooth, with derivative $f'(x) = 1 + b'(x)\\,dt$, and is solvable by a robust root-finding method such as Newton’s method with line search.\n\n- The basins defining transition path endpoints are sets $A$ and $B$ on the real line. For this problem, take $A = \\{x \\mid x \\le -1\\}$ and $B = \\{x \\mid x \\ge 1\\}$. A valid transition path must satisfy $x_0 \\in A$ and $x_T \\in B$. If the proposed path violates these endpoint constraints, its acceptance probability is $0$.\n\n- The acceptance probability must be computed using the Metropolis–Hastings rule consistent with detailed balance in path space under the guided proposal described above and the Onsager–Machlup functional $\\mathcal{S}[\\cdot]$. You must account for the fact that the proposal is symmetric in $\\delta$ and uses the same Gaussian noises $w_t$ as the original path.\n\nPotential and drift:\n- Use the double-well potential\n  $$U(x) = \\frac{x^4}{4}-\\frac{x^2}{2},\\quad U'(x)=x^3-x.$$\n- Use $\\beta = 1$ and define the drift and its derivative as\n  $$b(x) = -D\\,U'(x) = D\\,(x - x^3),\\quad b'(x) = D\\,(1-3x^2).$$\n\nNumerical and algorithmic requirements:\n- All calculations must be done in floating-point arithmetic.\n- Use a robust root-finding approach for the backward propagation, with a convergence tolerance no weaker than $10^{-10}$ in absolute value for the root condition.\n- If a root does not converge within a reasonable iteration cap, you may either treat the move as rejected (acceptance probability $0$) or implement a safeguarded Newton method; your implementation must be deterministic and must not rely on any random number generation.\n- No physical units are required for the outputs.\n- Angles are not used.\n- Percentages are not used.\n\nTest suite:\n- The program must compute the acceptance probability for the following four cases, in order. Each case specifies the path, diffusion coefficient, time step, shooting index, perturbation magnitude, and scalar $z$.\n\n  Case 1 (happy path):\n  - Path: $[-1.5,\\,-0.7175,\\,0.1448,\\,0.7629,\\,1.1609,\\,1.2029]$\n  - $D = 0.5$, $dt = 0.05$\n  - Shooting index $s = 2$\n  - $\\sigma = 0.2$, $z = 1.0$\n\n  Case 2 (constraint violation expected):\n  - Path: $[-1.5,\\,-0.7175,\\,0.1448,\\,0.7629,\\,1.1609,\\,1.2029]$\n  - $D = 0.5$, $dt = 0.05$\n  - Shooting index $s = 3$\n  - $\\sigma = 1.0$, $z = 5.0$\n\n  Case 3 (zero perturbation edge case):\n  - Path: $[-1.5,\\,-0.7175,\\,0.1448,\\,0.7629,\\,1.1609,\\,1.2029]$\n  - $D = 0.5$, $dt = 0.05$\n  - Shooting index $s = 1$\n  - $\\sigma = 0.0$, $z = 0.0$\n\n  Case 4 (short path with interior shooting):\n  - Path: $[-1.2,\\,-0.6,\\,1.0]$\n  - $D = 0.5$, $dt = 0.05$\n  - Shooting index $s = 1$\n  - $\\sigma = 0.05$, $z = 1.0$\n\nFinal output format:\n- Your program must produce a single line containing the four acceptance probabilities, in the same order as the test cases, formatted as a comma-separated list enclosed in square brackets. Each probability must be printed as a decimal number rounded to eight digits after the decimal point. For example, an output could look like\n  $$[0.73123456,0.00000000,1.00000000,0.84561234].$$", "solution": "The problem requires the computation of the Metropolis acceptance probability for a guided shooting move in Transition Path Sampling (TPS) applied to a one-dimensional overdamped Langevin process. The solution involves deriving the acceptance probability from first principles and then implementing the deterministic algorithm to compute it for the given test cases.\n\nThe state of the system is a discretized path, $x = \\{x_0, x_1, \\dots, x_T\\}$, evolving according to the Euler-Maruyama scheme:\n$$x_{t+1} = x_t + b(x_t)\\,dt + \\sqrt{2D\\,dt}\\,w_t$$\nwhere $b(x) = -D\\beta U'(x)$ is the drift, $D$ is the diffusion coefficient, $dt$ is the time step, and $w_t \\sim \\mathcal{N}(0,1)$ are independent standard normal variates. For this problem, $\\beta=1$.\n\nThe probability density of a path in the ensemble is proportional to $\\exp(-\\mathcal{S}[x])$, where $\\mathcal{S}[x]$ is the discrete Onsager–Machlup action:\n$$\\mathcal{S}[x] = \\sum_{t=0}^{T-1}\\left[\\frac{\\left(x_{t+1}-x_t-b(x_t)\\,dt\\right)^2}{4D\\,dt} + \\frac{1}{2}\\,b'(x_t)\\,dt\\right]$$\nThe first term can be rewritten using the noise increments $w_t = \\frac{x_{t+1}-x_t-b(x_t)\\,dt}{\\sqrt{2D\\,dt}}$, which gives $\\frac{w_t^2}{2}$. The second term, $\\frac{1}{2}b'(x_t)dt$, is the Itô-to-Stratonovich correction (a Jacobian term from the change of variables from noise to path coordinates), ensuring the path probability is correctly weighted.\n\nThe Metropolis-Hastings acceptance probability for a move from an old path $x$ to a new path $x'$ is:\n$$ P_{\\text{acc}}(x \\to x') = \\min\\left(1, \\frac{\\pi(x') g(x' \\to x)}{\\pi(x) g(x \\to x')}\\right) $$\nwhere $\\pi(x) \\propto \\exp(-\\mathcal{S}[x])$ is the target probability and $g$ is the proposal probability.\n\nThe specific \"guided\" shooting move is defined as follows:\n1. A shooting point $s \\in \\{0, \\dots, T\\}$ and a perturbation $\\delta$ are chosen.\n2. The noise increments $\\{w_t\\}$ are calculated from the old path $x$.\n3. A new path $x'$ is generated by setting $x'_s = x_s + \\delta$ and propagating forward and backward from this point using the *same* noise sequence $\\{w_t\\}$. The propagation rules are:\n   - Forward ($t \\ge s$): $x'_{t+1} = x'_t + b(x'_t)\\,dt + \\sqrt{2D\\,dt}\\,w_t$\n   - Backward ($t < s$): $x'_{t+1} = x'_t + b(x'_t)\\,dt + \\sqrt{2D\\,dt}\\,w_t$\n\nA crucial property of this proposal is that the noise sequence for the new path, $w'_t = \\frac{x'_{t+1}-x'_t-b(x'_t)\\,dt}{\\sqrt{2D\\,dt}}$, is identical to the original noise sequence $w_t$. This implies that the reverse move, from $x'$ to $x$, would require a kick of $-\\delta$ at the same shooting point $s$, and would use the noise sequence of $x'$, which is $\\{w_t\\}$. If the probability of choosing a kick $\\delta$ is the same as choosing $-\\delta$ (a symmetric distribution, as hinted by the problem), then the proposal mechanism is symmetric: $g(x \\to x') = g(x' \\to x)$. The acceptance probability then simplifies to the Metropolis form:\n$$ P_{\\text{acc}}(x \\to x') = \\min\\left(1, \\frac{\\pi(x')}{\\pi(x)}\\right) = \\min\\left(1, e^{-(\\mathcal{S}[x'] - \\mathcal{S}[x])}\\right) = \\min\\left(1, e^{-\\Delta\\mathcal{S}}\\right) $$\n\nNow, let's compute the change in action, $\\Delta\\mathcal{S} = \\mathcal{S}[x'] - \\mathcal{S}[x]$:\n$$ \\Delta\\mathcal{S} = \\sum_{t=0}^{T-1}\\left[\\frac{(w'_t)^2 - w_t^2}{2} + \\frac{1}{2}(b'(x'_t) - b'(x_t))dt\\right] $$\nSince $w'_t = w_t$ for all $t$ by construction, the first term in the sum is zero. This leaves only the contribution from the Jacobian term:\n$$ \\Delta\\mathcal{S} = \\frac{dt}{2} \\sum_{t=0}^{T-1} (b'(x'_t) - b'(x_t)) $$\nThis simplified expression is what we need to compute.\n\nThe overall algorithm is as follows:\n1.  Given an old path $x=\\{x_0, ..., x_T\\}$ and parameters $D$, $dt$, $s$, $\\sigma$, $z$. The potential is $U(x) = \\frac{x^4}{4}-\\frac{x^2}{2}$, so the drift is $b(x) = D(x-x^3)$ and its derivative is $b'(x) = D(1-3x^2)$.\n2.  Compute the noise sequence $\\{w_t\\}_{t=0}^{T-1}$ from the old path $x$ using $w_t = (x_{t+1} - x_t - b(x_t) dt) / \\sqrt{2Ddt}$.\n3.  Generate the new path $x'$. Initialize an array for $x'$.\n    a. Apply the kick: $\\delta = \\sigma z$, so $x'_s = x_s + \\delta$.\n    b. Propagate forward for $t = s, \\dots, T-1$: $x'_{t+1} = x'_t + b(x'_t) dt + \\sqrt{2Ddt} w_t$.\n    c. Propagate backward for $t = s-1, \\dots, 0$. For each $t$, solve the nonlinear equation for $x'_t$:\n       $$x'_{t+1} = x'_t + b(x'_t) dt + \\sqrt{2Ddt} w_t$$\n       This is a root-finding problem for the function $f(\\xi) = \\xi + b(\\xi)dt + \\sqrt{2Ddt}w_t - x'_{t+1} = 0$. We use Newton's method with an initial guess $\\xi_0 = x_t$. The update rule is $\\xi_{k+1} = \\xi_k - f(\\xi_k)/f'(\\xi_k)$, where $f'(\\xi) = 1 + b'(\\xi)dt$. Iteration continues until $|f(\\xi)| < 10^{-10}$. If convergence fails, the move is rejected ($P_{\\text{acc}} = 0$).\n4.  Check endpoint constraints. A valid transition path must start in basin $A=\\{x \\mid x \\le -1\\}$ and end in basin $B=\\{x \\mid x \\ge 1\\}$. If $x'_0 > -1$ or $x'_T < 1$, the proposed path is invalid, and $P_{\\text{acc}} = 0$.\n5.  If the new path is valid, calculate the change in action $\\Delta\\mathcal{S} = \\frac{dt}{2} \\sum_{t=0}^{T-1} (b'(x'_t) - b'(x_t))$.\n6.  The acceptance probability is $P_{\\text{acc}} = \\min(1, \\exp(-\\Delta\\mathcal{S}))$. For the case $\\delta=0$, $x'=x$, $\\Delta\\mathcal{S}=0$, and $P_{\\text{acc}}=1$.\n\nThis deterministic procedure is implemented for each test case to obtain the required acceptance probabilities.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import newton\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all given test cases.\n    \"\"\"\n\n    def b(x, D):\n        \"\"\"Calculates the drift term b(x) = D*(x - x^3).\"\"\"\n        return D * (x - x**3)\n\n    def b_prime(x, D):\n        \"\"\"Calculates the derivative of the drift term b'(x) = D*(1 - 3*x^2).\"\"\"\n        return D * (1 - 3 * x**2)\n\n    def compute_acceptance_probability(path_arr, D, dt, s, sigma, z):\n        \"\"\"\n        Computes the acceptance probability for a single shooting move.\n        \"\"\"\n        path = np.array(path_arr, dtype=float)\n        T = len(path) - 1\n\n        # Step 1: Recover the noise sequence from the original path.\n        w = np.zeros(T)\n        sqrt_2Ddt = np.sqrt(2 * D * dt)\n        if sqrt_2Ddt == 0:\n            return 0.0 # Avoid division by zero in deterministic case\n\n        for t in range(T):\n            w[t] = (path[t+1] - path[t] - b(path[t], D) * dt) / sqrt_2Ddt\n\n        # Step 2: Generate the proposed new path.\n        delta = sigma * z\n        new_path = np.zeros(T + 1)\n        \n        if not (0 <= s <= T):\n            # This case shouldn't occur with valid problem inputs.\n            return 0.0\n            \n        new_path[s] = path[s] + delta\n\n        # Step 2a: Forward propagation from the shooting point.\n        for t in range(s, T):\n            new_path[t+1] = new_path[t] + b(new_path[t], D) * dt + sqrt_2Ddt * w[t]\n\n        # Step 2b: Backward propagation from the shooting point.\n        try:\n            for t in range(s - 1, -1, -1):\n                x_tp1_prime = new_path[t+1]\n                const_term = sqrt_2Ddt * w[t]\n\n                # We need to find the root of f(xi) = 0, where:\n                # f(xi) = xi + b(xi)*dt + const_term - x_tp1_prime\n                f = lambda xi: xi + b(xi, D) * dt + const_term - x_tp1_prime\n                fprime = lambda xi: 1 + b_prime(xi, D) * dt\n                \n                # Use Newton's method for root-finding.\n                # Initial guess is the point from the original path.\n                x0_guess = path[t]\n                root = newton(f, x0_guess, fprime=fprime, tol=1e-12, maxiter=100, rtol=1e-12)\n\n                # Verify root condition as per problem statement\n                if abs(f(root)) > 1e-10:\n                    return 0.0 # Convergence did not meet root condition\n\n                new_path[t] = root\n        except RuntimeError:\n            # newton solver failed to converge. Reject the move.\n            return 0.0\n\n        # Step 3: Check endpoint constraints for the new path.\n        # A = {x | x <= -1}, B = {x | x >= 1}\n        if not (new_path[0] <= -1.0 and new_path[T] >= 1.0):\n            return 0.0\n\n        # Step 4: Calculate the change in the Onsager-Machlup action.\n        delta_S = 0.0\n        # The sum is over time slices t=0,...,T-1.\n        for t in range(T):\n            delta_S += b_prime(new_path[t], D) - b_prime(path[t], D)\n        delta_S *= (dt / 2.0)\n\n        # Step 5: Compute the final acceptance probability.\n        prob = min(1.0, np.exp(-delta_S))\n        \n        return prob\n\n    test_cases = [\n        # Case 1: Standard 'happy path' case\n        {'path_arr': [-1.5, -0.7175, 0.1448, 0.7629, 1.1609, 1.2029], 'D': 0.5, 'dt': 0.05, 's': 2, 'sigma': 0.2, 'z': 1.0},\n        # Case 2: Large perturbation, likely to violate constraints\n        {'path_arr': [-1.5, -0.7175, 0.1448, 0.7629, 1.1609, 1.2029], 'D': 0.5, 'dt': 0.05, 's': 3, 'sigma': 1.0, 'z': 5.0},\n        # Case 3: Zero perturbation, should yield acceptance probability of 1\n        {'path_arr': [-1.5, -0.7175, 0.1448, 0.7629, 1.1609, 1.2029], 'D': 0.5, 'dt': 0.05, 's': 1, 'sigma': 0.0, 'z': 0.0},\n        # Case 4: Short path with an interior shooting point\n        {'path_arr': [-1.2, -0.6, 1.0], 'D': 0.5, 'dt': 0.05, 's': 1, 'sigma': 0.05, 'z': 1.0},\n    ]\n\n    results = []\n    for case in test_cases:\n        probability = compute_acceptance_probability(**case)\n        results.append(f\"{probability:.8f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3358213"}, {"introduction": "While generating reactive paths is essential, the ultimate goal is often to compute a precise reaction rate. This advanced exercise [@problem_id:3358229] demonstrates a powerful variance reduction technique that combines the strengths of Kinetic Monte Carlo and concepts from Transition Path Sampling. You will first estimate the committor probability—the chance of a trajectory committing to the product state—using rapid KMC simulations, and then use this information as a control variate to dramatically improve the statistical efficiency of the overall rate constant calculation.", "problem": "Consider a one-dimensional birth–death Markov chain with discrete states $i \\in \\{0,1,\\dots,N\\}$ evolving with forward and backward transition rates that satisfy detailed balance with respect to a specified double-well potential. Let the left metastable basin be $A = \\{0,1,\\dots,a\\}$ and the right metastable basin be $B = \\{b,b+1,\\dots,N\\}$, with $0 < a < b < N$. Define the dividing surface to be the single-step crossing from state $a$ to state $a+1$. The energy landscape is a double well shaped by a quartic polynomial centered at the two minima $i_{\\mathrm{L}}$ and $i_{\\mathrm{R}}$, with magnitude controlled by a positive parameter $\\alpha$. The potential at state $i$ is\n$$\nU(i) = \\alpha \\left(i - i_{\\mathrm{L}}\\right)^2 \\left(i - i_{\\mathrm{R}}\\right)^2,\n$$\nand the transition rates are constructed to enforce detailed balance with respect to the Boltzmann distribution with dimensionless inverse temperature absorbed into $\\alpha$, using the symmetric choice\n$$\nr_i^{+} = \\exp\\left(-\\frac{U(i+1) - U(i)}{2}\\right), \\quad r_i^{-} = \\exp\\left(-\\frac{U(i-1) - U(i)}{2}\\right),\n$$\nfor $1 \\le i \\le N-1$, with $r_0^{-} = 0$ and $r_N^{+} = 0$. The stationary distribution is\n$$\n\\pi(i) = \\frac{\\exp\\left(-U(i)\\right)}{\\sum_{j=0}^{N} \\exp\\left(-U(j)\\right)}.\n$$\nDefine the committor function $q(i)$ as the probability that, starting from state $i$, the dynamics reaches basin $B$ before basin $A$. The committor satisfies the backward equation for $a < i < b$,\n$$\nr_i^{-} \\left[q(i-1) - q(i)\\right] + r_i^{+} \\left[q(i+1) - q(i)\\right] = 0,\n$$\nwith boundary conditions $q(i) = 0$ for $i \\le a$ and $q(i) = 1$ for $i \\ge b$.\n\nTransition Path Sampling (TPS) generates reactive trajectories that go from $A$ to $B$. A common estimator of the reactive rate constant from $A$ to $B$ is based on decomposing the rate into an average product of a flux across the dividing surface and a probability of commitment to $B$ given an outward crossing. Your task is to construct a variance-reduced estimator of this reactive rate using a control variate derived from short Kinetic Monte Carlo (kMC) bursts that estimate the committor at the shooting point. The kMC dynamics here reduces to a random walk with nearest-neighbor jumps, where at state $i$ the probability of stepping to $i+1$ is\n$$\np_i^{+} = \\frac{r_i^{+}}{r_i^{+} + r_i^{-}}, \\quad p_i^{-} = 1 - p_i^{+}.\n$$\n\nYou must proceed from first principles:\n\n- Use the definition of the committor and properties of reversible Markov chains to deduce an expression for the reactive rate constant in terms of the stationary flux across the dividing surface and the committor evaluated at the just-outside-$A$ state. Do not begin from any prepackaged rate formula; derive it from the definition of flux and first-passage probabilities.\n- Design a TPS-based estimator where each path is generated by starting from the shooting point $i = a+1$ and evolving the kMC dynamics until absorption in $A$ or $B$. Let $X$ be the indicator that a sampled trajectory reaches $B$ before $A$.\n- Estimate the committor at $i = a+1$ using $K$ independent short kMC bursts starting from $i = a+1$ that are run until they hit $A$ or $B$, yielding the unbiased Monte Carlo estimator $Y$ as the fraction of bursts that reach $B$. Embed $Y$ as a control variate into the TPS estimator for the reactive rate. Use the control variate form $X_{\\mathrm{cv}} = X - c\\,(Y - \\mu)$ where the coefficient $c$ is chosen optimally by minimizing variance at fixed unbiasedness, and where $\\mu = \\mathbb{E}[Y]$ must be equal to the exact mean of $Y$ under the chosen initial state distribution for $i = a+1$.\n- Compute $\\mu$ by solving for the exact committor $q(i)$ and evaluating it at $i = a+1$ using the backward equation, and then averaging appropriately given the single shooting point choice. Use this $\\mu$ to guarantee unbiasedness of the control variate.\n- For each test case below, generate $M$ TPS paths and associated control variates, compute both the plain and control-variate reactive rate estimates, and report their sample variances. All quantities are unitless floats. The final answer must be reproducible by fixing the random seed given in each test case.\n\nThe test suite consists of three parameter sets. For each case, the system parameters are given by the tuple $(N, i_{\\mathrm{L}}, i_{\\mathrm{R}}, \\alpha, a, b, M, K, \\text{seed})$. Use the values:\n\n- Case 1 (moderate barrier, happy path): $(50, 10, 40, 2 \\times 10^{-5}, 12, 38, 8000, 8, 123)$.\n- Case 2 (higher barrier, rarer events): $(50, 10, 40, 4 \\times 10^{-5}, 12, 38, 12000, 8, 456)$.\n- Case 3 (lower barrier, near-symmetric commit probability): $(50, 10, 40, 1 \\times 10^{-5}, 12, 38, 8000, 8, 789)$.\n\nFor each test case:\n\n- Derive and compute the stationary flux out of $A$ across the dividing surface at the edge $i = a \\rightarrow i = a+1$ from first principles.\n- Compute the stationary probability of being in basin $A$ and combine with the flux and committor to obtain the reactive rate estimate.\n- Generate $M$ TPS paths starting at $i = a+1$ and record $X$ as the indicator of reaching $B$ before $A$. Estimate the reactive rate using the plain estimator and compute its sample variance-of-mean.\n- For each sampled path, independently generate $K$ kMC bursts starting from $i = a+1$ to compute $Y$ as the empirical committor estimator. Compute the exact committor at $i = a+1$ and set $\\mu$ to this value. Form the control variate estimator with optimal $c$ determined empirically from the joint samples and compute its sample variance-of-mean.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list should contain one sub-list per test case, and each sub-list must be of the form $[k_{\\mathrm{plain}}, k_{\\mathrm{cv}}, \\sigma^2_{\\mathrm{plain}}, \\sigma^2_{\\mathrm{cv}}]$, where $k_{\\mathrm{plain}}$ and $k_{\\mathrm{cv}}$ are the plain and control variate reactive rate estimates, respectively, and $\\sigma^2_{\\mathrm{plain}}$ and $\\sigma^2_{\\mathrm{cv}}$ are their corresponding sample variances-of-mean. For example, your output must look like $[[k_1^{\\mathrm{plain}},k_1^{\\mathrm{cv}},\\sigma^2_{1,\\mathrm{plain}},\\sigma^2_{1,\\mathrm{cv}}],[k_2^{\\mathrm{plain}},k_2^{\\mathrm{cv}},\\sigma^2_{2,\\mathrm{plain}},\\sigma^2_{2,\\mathrm{cv}}],[k_3^{\\mathrm{plain}},k_3^{\\mathrm{cv}},\\sigma^2_{3,\\mathrm{plain}},\\sigma^2_{3,\\mathrm{cv}}]]$, with all entries as unitless floats. No additional text should be printed.", "solution": "The user provided a valid problem statement.\n\nThe problem requires the estimation of a reactive rate constant for a one-dimensional birth-death process on a double-well potential. The estimation is to be performed using a plain Monte Carlo method and a more advanced control variate method for variance reduction. The solution involves a combination of analytical derivation, numerical solution of a linear system, and Monte Carlo simulation.\n\n### 1. Derivation of the Reactive Rate Constant\n\nThe reactive rate constant, $k_{A \\to B}$, quantifies the rate of transitions from a metastable reactant basin $A$ to a product basin $B$. We derive its expression from first principles, based on the concept of stationary flux.\n\nLet the system be in a stationary state described by the distribution $\\pi(i) = C \\exp(-U(i))$, where $C$ is a normalization constant. The total probability of the system being in the reactant basin $A = \\{0, 1, \\dots, a\\}$ is $P_A = \\sum_{i=0}^{a} \\pi(i)$.\n\nThe rate of reactive events, defined as transitions from $A$ to $B$ without returning to $A$, can be expressed as the product of the total flux of trajectories leaving $A$ and the probability that these departing trajectories commit to $B$.\n\nIn this one-dimensional system, the only exit from basin $A$ is the transition from state $i=a$ to $i=a+1$. The stationary flux of trajectories making this transition is given by the product of the stationary probability of being in state $a$ and the forward rate from $a$:\n$$\n\\Phi_{A \\to A^c} = \\pi(a) r_a^{+}\n$$\nwhere $A^c$ is the complement of $A$. Here, $r_a^{+}$ is the forward transition rate from state $a$.\n\nOnce a trajectory has crossed the dividing surface and arrived at state $a+1$, it may either proceed to basin $B$ or return to basin $A$. The probability that a trajectory starting at state $i$ reaches basin $B$ before returning to $A$ is given by the committor function, $q(i)$. Therefore, the probability that a trajectory just leaving $A$ at state $a+1$ will react and reach $B$ is $q(a+1)$.\n\nThe reactive flux, $J_{A \\to B}$, is the total flux leaving $A$ multiplied by this commitment probability:\n$$\nJ_{A \\to B} = \\pi(a) r_a^{+} q(a+1)\n$$\nThe rate constant $k_{A \\to B}$ is defined as the reactive flux per unit population in the reactant state $A$. Thus,\n$$\nk_{A \\to B} = \\frac{J_{A \\to B}}{P_A} = \\frac{\\pi(a) r_a^{+} q(a+1)}{\\sum_{i=0}^{a} \\pi(i)}\n$$\nThis expression forms the basis for our estimators. The quantities $\\pi(i)$ and $r_a^{+}$ depend only on the potential $U(i)$ and can be calculated directly. The key quantity to be estimated via simulation is the committor $q(a+1)$.\n\n### 2. Exact Committor Calculation\n\nThe committor function $q(i)$ can be determined exactly by solving its governing backward master equation for the intermediate states $i \\in \\{a+1, \\dots, b-1\\}$. The equation reflects the fact that a trajectory starting at $i$ will, after one step, be at $i-1$ or $i+1$, and the committor value at $i$ is the weighted average of the committor values at these neighboring states. For a continuous-time Markov chain, this leads to:\n$$\nr_i^{-} \\left[q(i-1) - q(i)\\right] + r_i^{+} \\left[q(i+1) - q(i)\\right] = 0\n$$\nThis can be rewritten as:\n$$\nr_i^{-} q(i-1) - (r_i^{-} + r_i^{+}) q(i) + r_i^{+} q(i+1) = 0\n$$\nThe boundary conditions are defined by the basins: any trajectory starting in $A$ has already returned to $A$ (so its probability of reaching $B$ first is $0$), and any trajectory starting in $B$ has already reached $B$.\n$$\nq(i) = 0 \\quad \\text{for } i \\le a\n$$\n$$\nq(i) = 1 \\quad \\text{for } i \\ge b\n$$\nThe set of equations for $i = a+1, \\dots, b-1$ forms a tridiagonal system of linear equations for the unknown vector $\\mathbf{q} = [q(a+1), \\dots, q(b-1)]^T$.\nFor $i = a+1$, the equation is $-(r_{a+1}^{-} + r_{a+1}^{+}) q(a+1) + r_{a+1}^{+} q(a+2) = 0$.\nFor $i = b-1$, it is $r_{b-1}^{-} q(b-2) - (r_{b-1}^{-} + r_{b-1}^{+}) q(b-1) = -r_{b-1}^{+}$.\nThis system can be efficiently solved to find the exact values of the committor function for all intermediate states, including the crucial value $q(a+1)$, which we denote as $\\mu_q \\equiv q(a+1)$.\n\n### 3. Monte Carlo Estimation Scheme\n\nWe use Monte Carlo simulations to estimate $q(a+1)$. The \"TPS\" approach described in the problem involves generating trajectories that start at the shooting point $i=a+1$ and evolve according to the kMC dynamics until they are absorbed into either basin $A$ or $B$.\n\nThe kMC dynamics simplifies to a discrete-time random walk where, from state $i$, the probability of moving to $i+1$ is $p_i^{+} = r_i^{+} / (r_i^{+} + r_i^{-})$ and to $i-1$ is $p_i^{-} = 1 - p_i^{+}$.\n\nFor each of the $M$ simulated paths starting at $i=a+1$, we record an indicator variable $X_m$:\n$$\nX_m = \\begin{cases} 1 & \\text{if path } m \\text{ reaches } B \\text{ before } A \\\\ 0 & \\text{if path } m \\text{ reaches } A \\text{ before } B \\end{cases}\n$$\nThe expected value of $X_m$ is precisely the committor at the starting point, $\\mathbb{E}[X_m] = q(a+1)$.\n\n#### 3.1. Plain Monte Carlo Estimator\n\nThe plain Monte Carlo estimator for $q(a+1)$ is the sample mean of the $M$ path outcomes:\n$$\n\\hat{q}_{\\text{plain}} = \\frac{1}{M} \\sum_{m=1}^{M} X_m\n$$\nThe corresponding rate constant estimate is:\n$$\nk_{\\text{plain}} = \\frac{\\pi(a) r_a^{+}}{\\sum_{i=0}^{a} \\pi(i)} \\cdot \\hat{q}_{\\text{plain}}\n$$\n\n#### 3.2. Control Variate Estimator\n\nTo reduce the variance of the estimate, we introduce a control variate. For each main path $m$ (which gives us $X_m$), we generate $K$ additional independent short kMC bursts. Each burst starts at $i=a+1$ and runs to absorption, yielding an outcome $Y_{m,k} \\in \\{0, 1\\}$. We form an auxiliary variable $Y_m$:\n$$\nY_m = \\frac{1}{K} \\sum_{k=1}^{K} Y_{m,k}\n$$\n$Y_m$ is another, independent estimator of $q(a+1)$. Its expected value is $\\mathbb{E}[Y_m] = q(a+1)$. We use the exact value $\\mu_q = q(a+1)$ calculated from the backward equation.\n\nThe control variate estimator for $q(a+1)$ is constructed as:\n$$\n\\hat{q}_{\\mathrm{cv}} = \\frac{1}{M} \\sum_{m=1}^{M} \\left[ X_m - c(Y_m - \\mu_q) \\right]\n$$\nThis estimator is unbiased for any choice of $c$ because $\\mathbb{E}[Y_m - \\mu_q] = 0$. The variance is minimized by choosing the optimal coefficient:\n$$\nc^* = \\frac{\\mathrm{Cov}(X, Y)}{\\mathrm{Var}(Y)}\n$$\nIn practice, $c^*$ is estimated from the samples:\n$$\n\\hat{c}^* = \\frac{\\sum_{m=1}^{M} (X_m - \\bar{X})(Y_m - \\bar{Y})}{\\sum_{m=1}^{M} (Y_m - \\bar{Y})^2}\n$$\nwhere $\\bar{X}$ and $\\bar{Y}$ are the sample means. With this, the final control variate estimator for $q(a+1)$ is:\n$$\n\\hat{q}_{\\mathrm{cv}} = \\bar{X} - \\hat{c}^*(\\bar{Y} - \\mu_q)\n$$\nThe corresponding rate constant estimate is:\n$$\nk_{\\mathrm{cv}} = \\frac{\\pi(a) r_a^{+}}{\\sum_{i=0}^{a} \\pi(i)} \\cdot \\hat{q}_{\\mathrm{cv}}\n$$\n\n### 4. Variance of the Mean\n\nThe performance of the estimators is compared by their sample variances-of-the-mean. For an estimator $\\hat{\\theta}$ based on $M$ samples $Z_m$, the variance of the mean is estimated as:\n$$\n\\sigma^2_{\\hat{\\theta}} = \\frac{s_Z^2}{M} = \\frac{1}{M(M-1)}\\sum_{m=1}^{M}(Z_m - \\bar{Z})^2\n$$\nFor the plain estimator, the samples are $Z_m = X_m$. For the control variate estimator, the samples are $Z_m = X_m - \\hat{c}^*(Y_m - \\mu_q)$. The variances of the rate constant estimates, $\\sigma^2_{\\text{plain}}$ and $\\sigma^2_{\\text{cv}}$, are obtained by scaling the variances of $\\hat{q}_{\\text{plain}}$ and $\\hat{q}_{\\text{cv}}$ by the square of the prefactor $\\mathcal{F} = \\frac{\\pi(a) r_a^{+}}{\\sum_{i=0}^{a} \\pi(i)}$. The control variate method is effective if $\\sigma^2_{\\mathrm{cv}} < \\sigma^2_{\\mathrm{plain}}$.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases, calculating reactive rate constants\n    and their variances using plain Monte Carlo and a control variate method.\n    \"\"\"\n    test_cases = [\n        # (N, i_L, i_R, alpha, a, b, M, K, seed)\n        (50, 10, 40, 2e-5, 12, 38, 8000, 8, 123),\n        (50, 10, 40, 4e-5, 12, 38, 12000, 8, 456),\n        (50, 10, 40, 1e-5, 12, 38, 8000, 8, 789),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, iL, iR, alpha, a, b, M, K, seed = case\n        \n        # 1. System setup\n        states = np.arange(N + 1)\n        # Potential energy U(i)\n        U = alpha * ((states - iL)**2) * ((states - iR)**2)\n        \n        # Transition rates r_i^+, r_i^-\n        # Note: rates_fwd[i] = r_i^+, rates_bwd[i] = r_i^-\n        rates_fwd = np.zeros(N + 1)\n        rates_bwd = np.zeros(N + 1)\n        \n        # Symmetric choice for rates\n        rates_fwd[:N] = np.exp(-(U[1:] - U[:-1]) / 2.0)\n        rates_bwd[1:] = np.exp(-(U[:-1] - U[1:]) / 2.0)\n        \n        # Stationary distribution pi(i)\n        # Numerical stability by shifting potential\n        U_shifted = U - np.min(U)\n        pi_unnormalized = np.exp(-U_shifted)\n        pi = pi_unnormalized / np.sum(pi_unnormalized)\n\n        # 2. Exact committor q(i)\n        # Solve the tridiagonal system for q(i) for i in {a+1, ..., b-1}\n        num_unknowns = b - a - 1\n        # Scipy's solve_banded expects matrix in a special format (l, u)\n        # l=1 (sub-diagonal), u=1 (super-diagonal)\n        ab = np.zeros((3, num_unknowns))\n        d = np.zeros(num_unknowns)\n        \n        # Main diagonal\n        ab[1, :] = -(rates_bwd[a+1:b] + rates_fwd[a+1:b])\n        # Super-diagonal (upper)\n        ab[0, 1:] = rates_fwd[a+1:b-1]\n        # Sub-diagonal (lower)\n        ab[2, :-1] = rates_bwd[a+2:b]\n        \n        # RHS vector for boundary conditions\n        # q(a)=0 contributes nothing\n        # q(b)=1 contributes at i=b-1\n        d[-1] = -rates_fwd[b-1] # from r_{b-1}^+ * q(b)\n        \n        q_intermediate = solve_banded((1, 1), ab, d)\n        \n        q = np.zeros(N + 1)\n        q[b:] = 1.0\n        q[a+1:b] = q_intermediate\n        \n        mu_q = q[a+1]\n\n        # 3. Rate prefactor F\n        flux_A_out = pi[a] * rates_fwd[a]\n        pop_A = np.sum(pi[:a+1])\n        F_prefactor = flux_A_out / pop_A\n\n        # 4. Monte Carlo simulation\n        rng = np.random.default_rng(seed)\n        \n        # Pre-calculate jump probabilities\n        p_plus = np.zeros(N + 1)\n        # Denominator can be zero at boundaries if a rate is zero. Handle safely.\n        rate_sum = rates_fwd + rates_bwd\n        # Only interior states are visited in the sim\n        valid_idx = (rate_sum > 0) & (np.arange(N + 1) > a) & (np.arange(N + 1) < b)\n        p_plus[valid_idx] = rates_fwd[valid_idx] / rate_sum[valid_idx]\n\n        def run_kmc_path(start_i):\n            i = start_i\n            while a < i < b:\n                if rng.random() < p_plus[i]:\n                    i += 1\n                else:\n                    i -= 1\n            return 1 if i >= b else 0\n\n        X_samples = np.zeros(M)\n        Y_samples = np.zeros(M)\n\n        for m in range(M):\n            # Main path for estimator X\n            X_samples[m] = run_kmc_path(a + 1)\n            \n            # K bursts for control variate Y\n            Y_m_bursts = np.zeros(K)\n            for k in range(K):\n                Y_m_bursts[k] = run_kmc_path(a + 1)\n            Y_samples[m] = np.mean(Y_m_bursts)\n\n        # 5. Analysis\n        # Plain estimator\n        q_hat_plain = np.mean(X_samples)\n        k_plain = F_prefactor * q_hat_plain\n        # Variance of the mean\n        var_q_plain = np.var(X_samples, ddof=1) / M\n        sigma2_plain = (F_prefactor**2) * var_q_plain\n\n        # Control variate estimator\n        var_Y = np.var(Y_samples, ddof=1)\n        if var_Y > 1e-12:\n            cov_XY = np.cov(X_samples, Y_samples, ddof=1)[0, 1]\n            c_hat = cov_XY / var_Y\n        else: # Handle case of zero variance in Y\n            c_hat = 0.0\n\n        q_hat_cv = q_hat_plain - c_hat * (np.mean(Y_samples) - mu_q)\n        k_cv = F_prefactor * q_hat_cv\n        \n        # Calculate samples for CV estimator to find its variance\n        Z_samples = X_samples - c_hat * (Y_samples - mu_q)\n        var_q_cv = np.var(Z_samples, ddof=1) / M\n        sigma2_cv = (F_prefactor**2) * var_q_cv\n\n        results.append([k_plain, k_cv, sigma2_plain, sigma2_cv])\n\n    # Format the output as specified\n    sub_lists = [f\"[{','.join(map(str, res))}]\" for res in results]\n    print(f\"[{','.join(sub_lists)}]\")\n\nsolve()\n```", "id": "3358229"}]}