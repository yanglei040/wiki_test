{"hands_on_practices": [{"introduction": "Before applying complex copula models, it is essential to master the fundamentals. This first practice requires you to work from the ground up, starting with a candidate for a copula density function [@problem_id:3300458]. You will verify its validity by checking the core properties of a copula, including the crucial 2-increasing condition, and reinforce the conceptual definition of Kendall's tau by deriving it from first principles.", "problem": "Consider the bivariate function with density on the unit square given by the Farlie–Gumbel–Morgenstern (FGM) copula candidate\n$$\nc(u,v) \\;=\\; 1 + \\theta\\,(1 - 2u)(1 - 2v), \\quad (u,v)\\in[0,1]^2,\\quad \\theta\\in\\mathbb{R}.\n$$\nYou are told only that a bivariate copula is a distribution function on $[0,1]^2$ with uniform marginals, and that a function $C:[0,1]^2\\to[0,1]$ is a copula if and only if it is grounded, has uniform marginals, and is $2$-increasing, where $2$-increasingness means that for every axis-aligned rectangle $R=[u_1,u_2]\\times[v_1,v_2]\\subset[0,1]^2$ with $u_1\\le u_2$ and $v_1\\le v_2$, the volume\n$$\nV_C(R)\\;=\\; C(u_2,v_2)-C(u_2,v_1)-C(u_1,v_2)+C(u_1,v_1)\n$$\nis nonnegative.\n\n(a) Starting from these definitions, derive the distribution function $C(u,v)$ corresponding to the given $c(u,v)$ and determine for which real values of $\\theta$ the function $C$ is a valid copula. Your verification must explicitly address groundedness, uniform marginals, and $2$-increasingness.\n\n(b) Using only the definition of Kendall’s tau for continuous bivariate distributions as a concordance measure,\n$$\n\\tau \\;=\\; \\mathbb{P}\\big((X-X')(Y-Y')0\\big)\\;-\\;\\mathbb{P}\\big((X-X')(Y-Y')0\\big),\n$$\nwhere $(X,Y)$ and $(X',Y')$ are independent and identically distributed, derive a closed-form expression for Kendall’s tau as a function of $\\theta$ for the copula you obtained in part (a). Do not assume any special-purpose formula for Kendall’s tau; derive it from first principles by transforming to uniform marginals and expressing $\\tau$ as an integral that you evaluate.\n\nProvide your final answer as a single closed-form analytic expression in terms of $\\theta$. No numerical approximation is required. Do not include any units. If you find parameter restrictions for validity, you may assume $\\theta$ satisfies them when reporting Kendall’s tau.", "solution": "The problem is divided into two parts. Part (a) requires the derivation of the distribution function $C(u,v)$ from the given density candidate $c(u,v)$ and the determination of the parameter range for $\\theta$ that makes $C(u,v)$ a valid copula. Part (b) requires a first-principles derivation of Kendall's tau, $\\tau$, for this copula family.\n\nPart (a): Validation of the FGM Copula\n\nFirst, we derive the bivariate distribution function $C(u,v)$ by integrating the density $c(u,v)$ over the rectangle $[0,u]\\times[0,v]$.\nThe density is given as $c(s,t) = 1 + \\theta(1 - 2s)(1 - 2t)$ for $(s,t) \\in [0,1]^2$.\n$$\nC(u,v) = \\int_0^u \\int_0^v c(s,t) \\, dt \\, ds = \\int_0^u \\int_0^v \\left[1 + \\theta(1 - 2s)(1 - 2t)\\right] \\, dt \\, ds\n$$\nWe integrate with respect to $t$ first:\n$$\n\\int_0^v \\left[1 + \\theta(1 - 2s)(1 - 2t)\\right] \\, dt = \\left[t + \\theta(1 - 2s)(t - t^2)\\right]_{t=0}^{t=v} = v + \\theta(1 - 2s)(v - v^2)\n$$\nNow, we integrate this result with respect to $s$:\n$$\nC(u,v) = \\int_0^u \\left[v + \\theta(1 - 2s)(v - v^2)\\right] \\, ds = \\left[vs + \\theta(s - s^2)(v - v^2)\\right]_{s=0}^{s=u}\n$$\n$$\nC(u,v) = uv + \\theta(u - u^2)(v - v^2) = uv + \\theta u(1-u)v(1-v)\n$$\nThis is the candidate for the copula distribution function. Now, we must verify the three conditions for it to be a valid copula for some range of $\\theta \\in \\mathbb{R}$.\n\n1.  Groundedness: A function $C$ is grounded if $C(u,0) = 0$ for all $u \\in [0,1]$ and $C(0,v) = 0$ for all $v \\in [0,1]$.\n    $$\n    C(u,0) = u(0) + \\theta u(1-u)(0)(1-0) = 0\n    $$\n    $$\n    C(0,v) = (0)v + \\theta (0)(1-0)v(1-v) = 0\n    $$\n    The function is grounded for any value of $\\theta$.\n\n2.  Uniform Marginals: The function must satisfy $C(u,1) = u$ for all $u \\in [0,1]$ and $C(1,v) = v$ for all $v \\in [0,1]$.\n    $$\n    C(u,1) = u(1) + \\theta u(1-u)(1)(1-1) = u + \\theta u(1-u)(0) = u\n    $$\n    $$\n    C(1,v) = (1)v + \\theta (1)(1-1)v(1-v) = v + \\theta (0)v(1-v) = v\n    $$\n    The function has uniform marginals for any value of $\\theta$.\n\n3.  $2$-increasingness: The function $C$ must be $2$-increasing, which means the volume $V_C(R)$ of any rectangle $R = [u_1, u_2] \\times [v_1, v_2] \\subseteq [0,1]^2$ must be non-negative.\n    $$\n    V_C(R) = C(u_2,v_2)-C(u_2,v_1)-C(u_1,v_2)+C(u_1,v_1) \\ge 0\n    $$\n    Since the density $c(u,v) = \\frac{\\partial^2 C}{\\partial u \\partial v}$ exists, this condition is equivalent to requiring the density to be non-negative everywhere on its domain, i.e., $c(u,v) \\ge 0$ for all $(u,v) \\in [0,1]^2$.\n    We must find the values of $\\theta$ for which:\n    $$\n    1 + \\theta\\,(1 - 2u)(1 - 2v) \\ge 0 \\quad \\forall (u,v) \\in [0,1]^2\n    $$\n    Let $x = 1 - 2u$ and $y = 1 - 2v$. As $u$ and $v$ vary in $[0,1]$, $x$ and $y$ vary in $[-1,1]$. The term $(1-2u)(1-2v)$ takes values in the interval $[-1,1]$. The extreme values are achieved at the corners of the unit square:\n    -   Maximum value: $(1-2(0))(1-2(0)) = 1$ at $(u,v)=(0,0)$.\n    -   Maximum value: $(1-2(1))(1-2(1)) = 1$ at $(u,v)=(1,1)$.\n    -   Minimum value: $(1-2(0))(1-2(1)) = -1$ at $(u,v)=(0,1)$.\n    -   Minimum value: $(1-2(1))(1-2(0)) = -1$ at $(u,v)=(1,0)$.\n\n    To ensure $c(u,v) \\ge 0$, we must check the inequality $1 + \\theta(1-2u)(1-2v) \\ge 0$ under the most restrictive conditions.\n    -   If $\\theta  0$, the minimum value of $\\theta(1-2u)(1-2v)$ is $\\theta \\times (-1) = -\\theta$. The condition becomes $1 - \\theta \\ge 0$, which implies $\\theta \\le 1$.\n    -   If $\\theta  0$, the minimum value of $\\theta(1-2u)(1-2v)$ is $\\theta \\times (1) = \\theta$. The condition becomes $1 + \\theta \\ge 0$, which implies $\\theta \\ge -1$.\n    -   If $\\theta = 0$, $c(u,v) = 1 \\ge 0$, which is valid.\n    Combining these cases, the function $C(u,v)$ is a valid copula if and only if $\\theta \\in [-1, 1]$.\n\nPart (b): Derivation of Kendall's Tau\n\nKendall's tau, $\\tau$, is defined as the difference between the probability of concordance and the probability of discordance for two independent, identically distributed pairs of random variables $(X,Y)$ and $(X',Y')$.\n$$\n\\tau = \\mathbb{P}\\big((X-X')(Y-Y')0\\big) - \\mathbb{P}\\big((X-X')(Y-Y')0\\big)\n$$\nLet $P_c$ be the probability of concordance and $P_d$ be the probability of discordance. For continuous random variables, the probability of a tie is $0$, so $P_c + P_d = 1$. This implies $\\tau = P_c - (1-P_c) = 2P_c - 1$.\n\nThe concordance event $(X-X')(Y-Y')0$ is equivalent to $(XX' \\text{ and } YY')$ or $(XX' \\text{ and } YY')$. By transforming to uniform marginals $U=F_X(X)$ and $V=F_Y(Y)$, this is equivalent to $(UU' \\text{ and } VV')$ or $(UU' \\text{ and } VV')$. The pairs $(U,V)$ and $(U',V')$ are i.i.d. with distribution function $C(u,v)$ and density $c(u,v)$.\n\nThe probability of concordance is $P_c = \\mathbb{P}(UU', VV') + \\mathbb{P}(UU', VV')$.\nWe can calculate $P_c$ using the law of total expectation by conditioning on the value of one pair, say $(U,V)$. Let $(U,V)=(u,v)$.\n$$\nP_c = \\mathbb{E}\\left[ \\mathbb{P}\\left((U-U')(V-V')0 \\mid (U,V)=(u,v)\\right) \\right]\n$$\nThe conditional probability is:\n\\begin{align*}\n\\mathbb{P}\\left((u-U')(v-V')0\\right) = \\mathbb{P}(U'u, V'v) + \\mathbb{P}(U'u, V'v) \\\\\n= C(u,v) + \\int_u^1 \\int_v^1 c(s,t) \\, ds \\, dt \\\\\n= C(u,v) + \\left[ C(1,1) - C(1,v) - C(u,1) + C(u,v) \\right] \\\\\n= C(u,v) + \\left[ 1 - v - u + C(u,v) \\right] \\\\\n= 1 - u - v + 2C(u,v)\n\\end{align*}\nTaking the expectation with respect to $(U,V)$:\n$$\nP_c = \\mathbb{E}\\left[1 - U - V + 2C(U,V)\\right] = 1 - \\mathbb{E}[U] - \\mathbb{E}[V] + 2\\mathbb{E}[C(U,V)]\n$$\nSince $U$ and $V$ are standard uniform random variables, $\\mathbb{E}[U] = 1/2$ and $\\mathbb{E}[V] = 1/2$.\n$$\nP_c = 1 - \\frac{1}{2} - \\frac{1}{2} + 2\\mathbb{E}[C(U,V)] = 2\\mathbb{E}[C(U,V)]\n$$\nSubstituting this into the expression for $\\tau$:\n$$\n\\tau = 2P_c - 1 = 2(2\\mathbb{E}[C(U,V)]) - 1 = 4\\mathbb{E}[C(U,V)] - 1\n$$\nThe expectation $\\mathbb{E}[C(U,V)]$ is given by the integral:\n$$\n\\mathbb{E}[C(U,V)] = \\int_0^1 \\int_0^1 C(u,v) c(u,v) \\, du \\, dv\n$$\nWe substitute the expressions for $C(u,v)$ and $c(u,v)$:\n$$\nC(u,v)c(u,v) = \\left[uv + \\theta u(1-u)v(1-v)\\right] \\left[1 + \\theta (1-2u)(1-2v)\\right]\n$$\n$$\n= uv + \\theta uv(1-2u)(1-2v) + \\theta u(1-u)v(1-v) + \\theta^2 u(1-u)(1-2u)v(1-v)(1-2v)\n$$\nThe integral is separable for each term. Let's evaluate the necessary one-dimensional integrals:\n$$\n\\int_0^1 u \\, du = \\left[\\frac{u^2}{2}\\right]_0^1 = \\frac{1}{2}\n$$\n$$\n\\int_0^1 u(1-u) \\, du = \\int_0^1 (u-u^2) \\, du = \\left[\\frac{u^2}{2} - \\frac{u^3}{3}\\right]_0^1 = \\frac{1}{2} - \\frac{1}{3} = \\frac{1}{6}\n$$\n$$\n\\int_0^1 u(1-2u) \\, du = \\int_0^1 (u-2u^2) \\, du = \\left[\\frac{u^2}{2} - \\frac{2u^3}{3}\\right]_0^1 = \\frac{1}{2} - \\frac{2}{3} = -\\frac{1}{6}\n$$\n$$\n\\int_0^1 u(1-u)(1-2u) \\, du = \\int_0^1 (u-3u^2+2u^3) \\, du = \\left[\\frac{u^2}{2} - u^3 + \\frac{u^4}{2}\\right]_0^1 = \\frac{1}{2} - 1 + \\frac{1}{2} = 0\n$$\nNow we compute $\\mathbb{E}[C(U,V)]$ by integrating the four terms:\n\\begin{align*}\n\\mathbb{E}[C(U,V)] = \\left(\\int_0^1 u \\, du\\right)^2 + \\theta \\left(\\int_0^1 u(1-2u) \\, du\\right)^2 + \\theta \\left(\\int_0^1 u(1-u) \\, du\\right)^2 \\\\\n\\quad + \\theta^2 \\left(\\int_0^1 u(1-u)(1-2u) \\, du\\right)^2 \\\\\n= \\left(\\frac{1}{2}\\right)^2 + \\theta \\left(-\\frac{1}{6}\\right)^2 + \\theta \\left(\\frac{1}{6}\\right)^2 + \\theta^2(0)^2 \\\\\n= \\frac{1}{4} + \\frac{\\theta}{36} + \\frac{\\theta}{36} + 0 = \\frac{1}{4} + \\frac{2\\theta}{36} = \\frac{1}{4} + \\frac{\\theta}{18}\n\\end{align*}\nFinally, we substitute this result into the expression for $\\tau$:\n$$\n\\tau = 4\\mathbb{E}[C(U,V)] - 1 = 4\\left(\\frac{1}{4} + \\frac{\\theta}{18}\\right) - 1 = 1 + \\frac{4\\theta}{18} - 1 = \\frac{2\\theta}{9}\n$$\nThis is the closed-form expression for Kendall's tau for the FGM copula, valid for $\\theta \\in [-1,1]$.", "answer": "$$\\boxed{\\frac{2\\theta}{9}}$$", "id": "3300458"}, {"introduction": "Archimedean copulas are a versatile class of models built from a single function known as a generator. This exercise focuses on the Clayton copula, which is widely used in fields like finance and hydrology for its ability to capture strong lower tail dependence [@problem_id:3300435]. You will derive the relationship between the copula's parameter $\\theta$ and Kendall's tau, a key step that enables model calibration from empirical data via the method of moments.", "problem": "In calibrating a bivariate dependence model for Monte Carlo sampling, you intend to use a one-parameter Archimedean copula to capture positive dependence while keeping marginal specifications separate. Consider the Clayton copula with parameter $\\theta0$, defined for $(u,v)\\in[0,1]^{2}$ by\n$$\nC(u,v) \\;=\\; \\left(u^{-\\theta} + v^{-\\theta} - 1\\right)^{-1/\\theta}.\n$$\nLet $\\tau$ denote Kendall's tau for the bivariate distribution whose copula is $C$. Use only fundamental definitions of copulas and Kendall's tau to derive an analytic expression $\\tau=\\tau(\\theta)$ and then invert it to express $\\theta$ as a function of $\\tau$. As your final answer, report the closed-form expression for $\\theta$ in terms of $\\tau$. No numerical rounding is required, and no physical units are involved.", "solution": "Kendall's rank correlation coefficient, $\\tau$, is fundamentally defined as the difference between the probability of concordance and the probability of discordance for two independent pairs of random variables, $(X_1, Y_1)$ and $(X_2, Y_2)$, drawn from the same bivariate distribution. For a continuous distribution, this is $\\tau = P((X_1-X_2)(Y_1-Y_2)0) - P((X_1-X_2)(Y_1-Y_2)0)$.\n\nA cornerstone result in copula theory states that for any bivariate distribution with copula $C$, Kendall's tau depends only on $C$. For the specific class of Archimedean copulas, which have the structure $C(u,v) = \\phi^{-1}(\\phi(u) + \\phi(v))$ for a suitable generator function $\\phi$, there exists a direct relationship between $\\tau$ and the generator $\\phi$. This relationship is given by the identity:\n$$\n\\tau = 1 + 4 \\int_0^1 \\frac{\\phi(t)}{\\phi'(t)} \\, dt\n$$\nWe will use this fundamental relationship to solve the problem.\n\nFirst, we must identify the generator function $\\phi(t)$ for the Clayton copula provided:\n$$\nC(u,v) = \\left(u^{-\\theta} + v^{-\\theta} - 1\\right)^{-1/\\theta}\n$$\nThe generator for the Clayton family with parameter $\\theta  0$ is:\n$$\n\\phi(t) = \\frac{1}{\\theta} \\left(t^{-\\theta} - 1\\right)\n$$\nThis function satisfies the necessary properties of an Archimedean generator for $\\theta  0$: $\\phi(1) = \\frac{1}{\\theta}(1-1) = 0$, and for $t \\in (0, 1]$, $\\phi(t)$ is a non-negative, strictly decreasing, and convex function.\n\nNext, we compute the derivative of the generator, $\\phi'(t)$:\n$$\n\\phi'(t) = \\frac{d}{dt} \\left[ \\frac{1}{\\theta} \\left(t^{-\\theta} - 1\\right) \\right] = \\frac{1}{\\theta} \\left(-\\theta t^{-\\theta-1}\\right) = -t^{-\\theta-1}\n$$\n\nNow, we construct the ratio $\\frac{\\phi(t)}{\\phi'(t)}$ to be used in the integral for $\\tau$:\n$$\n\\frac{\\phi(t)}{\\phi'(t)} = \\frac{\\frac{1}{\\theta}\\left(t^{-\\theta} - 1\\right)}{-t^{-\\theta-1}} = -\\frac{1}{\\theta}\\left(t^{-\\theta} - 1\\right)t^{\\theta+1} = -\\frac{1}{\\theta}\\left(t^{-\\theta}t^{\\theta+1} - t^{\\theta+1}\\right) = -\\frac{1}{\\theta}\\left(t - t^{\\theta+1}\\right)\n$$\n\nWe now evaluate the definite integral from the formula for $\\tau$. The integral is convergent since $\\theta  0$.\n$$\n\\int_0^1 \\frac{\\phi(t)}{\\phi'(t)} \\, dt = \\int_0^1 -\\frac{1}{\\theta}\\left(t - t^{\\theta+1}\\right) \\, dt\n$$\n$$\n= -\\frac{1}{\\theta} \\left[ \\frac{t^2}{2} - \\frac{t^{\\theta+2}}{\\theta+2} \\right]_0^1\n$$\n$$\n= -\\frac{1}{\\theta} \\left( \\left(\\frac{1^2}{2} - \\frac{1^{\\theta+2}}{\\theta+2}\\right) - \\left(\\frac{0^2}{2} - \\frac{0^{\\theta+2}}{\\theta+2}\\right) \\right)\n$$\n$$\n= -\\frac{1}{\\theta} \\left( \\frac{1}{2} - \\frac{1}{\\theta+2} \\right) = -\\frac{1}{\\theta} \\left( \\frac{(\\theta+2) - 2}{2(\\theta+2)} \\right) = -\\frac{1}{\\theta} \\left( \\frac{\\theta}{2(\\theta+2)} \\right)\n$$\n$$\n= -\\frac{1}{2(\\theta+2)}\n$$\n\nSubstituting this result back into the formula for $\\tau$:\n$$\n\\tau = 1 + 4 \\left( -\\frac{1}{2(\\theta+2)} \\right) = 1 - \\frac{2}{\\theta+2}\n$$\n$$\n\\tau = \\frac{(\\theta+2) - 2}{\\theta+2} = \\frac{\\theta}{\\theta+2}\n$$\nThis gives the explicit relationship $\\tau = \\tau(\\theta)$.\n\nThe final part of the task is to invert this expression to find $\\theta$ as a function of $\\tau$. We start with the derived relation:\n$$\n\\tau = \\frac{\\theta}{\\theta+2}\n$$\nWe solve for $\\theta$:\n$$\n\\tau (\\theta+2) = \\theta\n$$\n$$\n\\tau\\theta + 2\\tau = \\theta\n$$\n$$\n2\\tau = \\theta - \\tau\\theta\n$$\n$$\n2\\tau = \\theta(1 - \\tau)\n$$\n$$\n\\theta = \\frac{2\\tau}{1-\\tau}\n$$\nThis is the closed-form expression for the Clayton copula parameter $\\theta$ in terms of Kendall's tau, $\\tau$. The condition $\\theta  0$ corresponds to a positive dependence structure, which implies $0  \\tau  1$, for which this expression is well-defined.", "answer": "$$\n\\boxed{\\frac{2\\tau}{1-\\tau}}\n$$", "id": "3300435"}, {"introduction": "One of the most powerful applications of copulas is modeling the dependence between extreme events, a feature not captured by the simple Gaussian copula. This advanced exercise delves into the Student-t copula, a popular choice for capturing such behavior [@problem_id:3300430]. You will derive its tail dependence coefficients, which quantify the probability of joint extremes, and analyze how this property vanishes as the degrees of freedom parameter $\\nu$ approaches infinity, causing the t-copula to converge to the Gaussian case.", "problem": "Consider a bivariate Student-$t$ copula constructed from an elliptical scale-mixture representation of a bivariate Student-$t$ distribution with degrees of freedom $\\nu \\in (2,\\infty)$ and correlation parameter $\\rho \\in (-1,1)$. Let $(X,Y)$ be a bivariate Student-$t$ random vector with correlation $\\rho$ and common degrees of freedom $\\nu$, and define the copula variables $U = t_{\\nu}(X)$ and $V = t_{\\nu}(Y)$, where $t_{\\nu}$ denotes the cumulative distribution function (CDF) of the standard univariate Student-$t$ distribution with $\\nu$ degrees of freedom. The upper and lower tail dependence coefficients of the copula are defined by\n$$\n\\lambda_{U} \\equiv \\lim_{u \\to 1^{-}} \\mathbb{P}\\!\\left(U  u \\mid V  u\\right), \n\\qquad\n\\lambda_{L} \\equiv \\lim_{u \\to 0^{+}} \\mathbb{P}\\!\\left(U \\leq u \\mid V \\leq u\\right).\n$$\nStarting only from core definitions of copula tail dependence, the scale-mixture construction of the bivariate Student-$t$ law, and the exact conditional distribution of one Student-$t$ component given the other, derive a closed-form expression for $\\lambda_U$ and $\\lambda_L$ in terms of the CDF $t_{\\nu+1}$ of the standard univariate Student-$t$ distribution with $\\nu+1$ degrees of freedom. Then, analyze the limiting value of these coefficients as $\\nu \\to \\infty$ for fixed $\\rho \\in (-1,1)$. Your final answer must be a single closed-form analytic expression for $\\lambda_U=\\lambda_L$ together with its limit as $\\nu \\to \\infty$, presented as a row matrix. No numerical approximation or rounding is required.", "solution": "The problem requires the derivation of the upper and lower tail dependence coefficients, $\\lambda_U$ and $\\lambda_L$, for a bivariate Student-$t$ copula, and their limiting value as the degrees of freedom $\\nu \\to \\infty$.\n\nThe bivariate Student-$t$ distribution is an elliptical distribution, which is centrally symmetric. This implies that the distribution of $(-X, -Y)$ is the same as the distribution of $(X,Y)$. Because the univariate Student-$t$ CDF $t_\\nu$ is symmetric in the sense that $t_\\nu(-x) = 1 - t_\\nu(x)$, the resulting copula is radially symmetric. A direct consequence of this symmetry is that the upper and lower tail dependence coefficients are equal: $\\lambda_U = \\lambda_L$. We shall denote this common value by $\\lambda$.\n\nTo derive $\\lambda$, we can use the result $\\lambda = 2 \\lim_{u \\to 1^-} \\mathbb{P}(V > u \\mid U=u)$, which is valid for differentiable, symmetric copulas. We express this in terms of the original random variables $X$ and $Y$. The event $V > u$ is equivalent to $Y > t_\\nu^{-1}(u)$, and the condition $U=u$ is equivalent to $X = t_\\nu^{-1}(u)$. Let $x_u = t_\\nu^{-1}(u)$. As $u \\to 1^-$, $x_u \\to \\infty$. The expression becomes:\n$$\n\\lambda = 2 \\lim_{x_u \\to \\infty} \\mathbb{P}(Y > x_u \\mid X=x_u)\n$$\nWe now use the provided property for the conditional distribution: given $X=x$, the variable $T = \\frac{Y - \\rho x}{\\sqrt{\\frac{\\nu+x^2}{\\nu+1}(1-\\rho^2)}}$ follows a standard Student-$t$ distribution with $\\nu+1$ degrees of freedom ($T_{\\nu+1}$). The conditional probability is:\n$$\n\\mathbb{P}(Y > x \\mid X=x) = \\mathbb{P}\\left(T_{\\nu+1} > \\frac{x(1 - \\rho)}{\\sqrt{\\frac{\\nu+x^2}{\\nu+1}(1-\\rho^2)}} \\right)\n$$\nWe find the limit of the argument of the probability as $x \\to \\infty$:\n$$\n\\lim_{x \\to \\infty} \\frac{x(1 - \\rho)}{\\sqrt{\\frac{x^2(1+\\nu/x^2)}{\\nu+1}(1-\\rho^2)}} = \\lim_{x \\to \\infty} \\frac{x(1 - \\rho)}{\\frac{x\\sqrt{1-\\rho^2}}{\\sqrt{\\nu+1}}\\sqrt{1+\\nu/x^2}} = \\frac{1 - \\rho}{\\frac{\\sqrt{(1-\\rho)(1+\\rho)}}{\\sqrt{\\nu+1}}} = \\sqrt{\\frac{(\\nu+1)(1-\\rho)}{1+\\rho}}\n$$\nSo the limiting conditional probability is $\\mathbb{P}\\left(T_{\\nu+1} > \\sqrt{\\frac{(\\nu+1)(1-\\rho)}{1+\\rho}}\\right)$. Using the CDF $t_{\\nu+1}$ of the $T_{\\nu+1}$ distribution, this is equal to $t_{\\nu+1}\\left(-\\sqrt{\\frac{(\\nu+1)(1-\\rho)}{1+\\rho}}\\right)$ by symmetry. Substituting this back, we get the expression for the tail dependence coefficient:\n$$\n\\lambda = 2 t_{\\nu+1}\\left(-\\sqrt{\\frac{(\\nu+1)(1-\\rho)}{1+\\rho}}\\right)\n$$\nFinally, we analyze the limit of $\\lambda$ as $\\nu \\to \\infty$. As $\\nu \\to \\infty$, the Student-$t$ distribution $t_{\\nu+1}$ converges to the standard Normal distribution, whose CDF is denoted by $\\Phi$. The argument of the CDF, $-\\sqrt{\\frac{(\\nu+1)(1-\\rho)}{1+\\rho}}$, approaches $-\\infty$ since $\\rho \\in (-1,1)$. Therefore:\n$$\n\\lim_{\\nu \\to \\infty} \\lambda = 2 \\lim_{\\nu \\to \\infty} t_{\\nu+1}\\left(-\\sqrt{\\frac{(\\nu+1)(1-\\rho)}{1+\\rho}}\\right) = 2 \\lim_{z \\to -\\infty} \\Phi(z) = 2 \\times 0 = 0\n$$\nThis result is consistent with the fact that as $\\nu \\to \\infty$, the Student-$t$ copula converges to the Gaussian copula, which is known to have zero tail dependence for any correlation $\\rho \\in (-1,1)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 t_{\\nu+1}\\left(-\\sqrt{\\frac{(\\nu+1)(1-\\rho)}{1+\\rho}}\\right)  0\n\\end{pmatrix}\n}\n$$", "id": "3300430"}]}