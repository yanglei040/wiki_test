{"hands_on_practices": [{"introduction": "Classifying states as transient or recurrent is fundamental, but how stable is this classification? Real-world systems are subject to noise, and our model parameters are often estimates. This exercise [@problem_id:3295790] challenges you to determine the robustness of a transient class by calculating the maximum perturbation the system can withstand before its transient nature is lost. By connecting the spectral radius of the transient submatrix to matrix perturbation theory, you will develop a precise understanding of the structural stability of Markov chains.", "problem": "Consider a discrete-time finite-state Markov chain with state space $\\{1,2,3\\}$. Its one-step transition probability matrix is\n$$\nP \\;=\\;\n\\begin{pmatrix}\n0.3  0.2  0.5 \\\\\n0.2  0.4  0.4 \\\\\n0    0    1\n\\end{pmatrix}.\n$$\nLet the transient class be $T=\\{1,2\\}$ and the absorbing state be $\\{3\\}$. Denote by $Q$ the $2\\times 2$ sub-stochastic block corresponding to transitions within $T$, and by $R$ the $2\\times 1$ block for transitions from $T$ to $\\{3\\}$. You may take as fundamental that a class $T$ is transient if and only if the spectral radius $\\rho(Q)$ satisfies $\\rho(Q)1$.\n\nSuppose $P$ is perturbed to $P' = P + \\Delta P$, where $P'$ remains a valid stochastic matrix on the same state space, with the same indexing for $T=\\{1,2\\}$, and where the perturbation is bounded in spectral norm by $\\|\\Delta P\\|_{2} \\le \\varepsilon$. Let $\\Delta Q$ be the corresponding perturbation of $Q$ extracted from $\\Delta P$. Using fundamental definitions of transience, matrix norms, and well-tested spectral perturbation bounds for eigenvalues of diagonalizable matrices, derive the supremal uniform radius $\\varepsilon^{\\star}$ such that for every perturbation with $\\|\\Delta P\\|_{2}  \\varepsilon^{\\star}$ the class $T$ remains transient for $P'$.\n\nCompute the numerical value of $\\varepsilon^{\\star}$ for the given $P$ and express your final answer rounded to four significant figures. No units are required.", "solution": "The problem is first validated to ensure it is scientifically sound, well-posed, and complete.\n\n### Step 1: Extract Givens\n- A discrete-time finite-state Markov chain with state space $S = \\{1, 2, 3\\}$.\n- The one-step transition probability matrix is $P = \\begin{pmatrix} 0.3  0.2  0.5 \\\\ 0.2  0.4  0.4 \\\\ 0  0  1 \\end{pmatrix}$.\n- The set of transient states is $T = \\{1, 2\\}$.\n- The absorbing state is $\\{3\\}$.\n- $Q$ is the submatrix of $P$ corresponding to transitions within $T$: $Q = \\begin{pmatrix} 0.3  0.2 \\\\ 0.2  0.4 \\end{pmatrix}$.\n- $R$ is the submatrix for transitions from $T$ to $\\{3\\}$: $R = \\begin{pmatrix} 0.5 \\\\ 0.4 \\end{pmatrix}$.\n- A class $T$ is transient if and only if the spectral radius of $Q$, $\\rho(Q)$, satisfies $\\rho(Q)  1$.\n- A perturbed matrix $P' = P + \\Delta P$ is a valid stochastic matrix.\n- The perturbation is bounded in the spectral norm: $\\|\\Delta P\\|_{2} \\le \\varepsilon$.\n- $\\Delta Q$ is the submatrix of $\\Delta P$ corresponding to the states in $T$.\n- The objective is to find the supremal uniform radius $\\varepsilon^{\\star}$ such that for any valid perturbation with $\\|\\Delta P\\|_{2}  \\varepsilon^{\\star}$, the class $T$ remains transient for the perturbed matrix $P'$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is a standard application of matrix perturbation theory to the stability analysis of Markov chains. All concepts—transience, spectral radius, spectral norm, stochastic matrices—are rigorously defined in mathematics and engineering. The given matrix $P$ is a valid stochastic matrix as its entries are non-negative and its rows sum to $1$.\n- **Well-Posed:** The problem is well-defined. It asks for the computation of a specific quantity, $\\varepsilon^{\\star}$, defined as a supremum under clear constraints. A unique solution is expected.\n- **Objective:** The problem is stated in precise, objective mathematical language.\n\nThe problem is free of any scientific, logical, or structural flaws.\n\n### Step 3: Verdict and Action\nThe problem is deemed valid. A full solution will be provided.\n\n### Solution Derivation\nThe condition for the class of states $T = \\{1, 2\\}$ to be transient is that the spectral radius of the submatrix $Q$ is strictly less than $1$, i.e., $\\rho(Q)  1$. For the perturbed matrix $P'$, the corresponding submatrix for transitions within $T$ is $Q' = Q + \\Delta Q$. The class $T$ remains transient under this perturbation if and only if $\\rho(Q')  1$.\n\nA key result from the theory of Markov chains states that the class $T$ is transient if and only if the matrix $I-Q$ is invertible, where $I$ is the identity matrix of appropriate size. The matrix $N = (I-Q)^{-1}$ is known as the fundamental matrix, and its entries give the expected number of visits to states in $T$ before absorption. The convergence of the geometric series $N = \\sum_{k=0}^{\\infty} Q^k$ is equivalent to $\\rho(Q)  1$.\n\nFor the perturbed system, transience is maintained if and only if $I-Q'$ is invertible. We can write $I-Q'$ as a perturbation of $I-Q$:\n$$\nI - Q' = I - (Q + \\Delta Q) = (I - Q) - \\Delta Q\n$$\nAccording to a fundamental theorem in matrix perturbation theory, if a matrix $A$ is invertible, then the matrix $A+E$ is also invertible provided that the norm of the perturbation $E$ is sufficiently small. Specifically, if $\\|E\\|  \\frac{1}{\\|A^{-1}\\|}$ for some matrix norm, then $A+E$ is guaranteed to be invertible.\n\nLet's apply this theorem with $A = I - Q$ and the perturbation $E = -\\Delta Q$, using the spectral norm (induced $2$-norm). The matrix $I-Q$ is invertible since the original class $T$ is transient. The perturbed matrix $I-Q'$ remains invertible if:\n$$\n\\|-\\Delta Q\\|_{2}  \\frac{1}{\\|(I-Q)^{-1}\\|_{2}}\n$$\nSince $\\|-\\Delta Q\\|_{2} = \\|\\Delta Q\\|_{2}$, the condition is:\n$$\n\\|\\Delta Q\\|_{2}  \\frac{1}{\\|(I-Q)^{-1}\\|_{2}}\n$$\nThe perturbation $\\Delta Q$ is a principal submatrix of the full perturbation $\\Delta P$. A standard property of the spectral norm is that the norm of any submatrix is less than or equal to the norm of the full matrix. Thus, we have:\n$$\n\\|\\Delta Q\\|_{2} \\le \\|\\Delta P\\|_{2}\n$$\nThe problem states that $\\|\\Delta P\\|_{2}  \\varepsilon^{\\star}$. Therefore, we have $\\|\\Delta Q\\|_{2}  \\varepsilon^{\\star}$. To guarantee that the transience condition holds for any such perturbation, we must require that the upper bound $\\varepsilon^{\\star}$ on $\\|\\Delta P\\|_{2}$ satisfies:\n$$\n\\varepsilon^{\\star} \\le \\frac{1}{\\|(I-Q)^{-1}\\|_{2}}\n$$\nThe problem asks for the supremal uniform radius $\\varepsilon^{\\star}$. The bound is tight, meaning we can find a perturbation with norm equal to $1/\\|(I-Q)^{-1}\\|_{2}$ that makes $I-Q'$ singular. Thus, the supremum is:\n$$\n\\varepsilon^{\\star} = \\frac{1}{\\|(I-Q)^{-1}\\|_{2}}\n$$\nNow we must compute $\\|(I-Q)^{-1}\\|_{2}$. The matrix $Q$ is given by $Q = \\begin{pmatrix} 0.3  0.2 \\\\ 0.2  0.4 \\end{pmatrix}$. This is a real symmetric matrix. Consequently, the matrix $I-Q$ is also symmetric, and its inverse $(I-Q)^{-1}$ is symmetric. For a symmetric matrix, the spectral norm is equal to its spectral radius (the maximum absolute value of its eigenvalues).\n$$\n\\|(I-Q)^{-1}\\|_{2} = \\rho((I-Q)^{-1})\n$$\nThe eigenvalues of $(I-Q)^{-1}$ are related to the eigenvalues of $Q$. Let $\\lambda_i$ be the eigenvalues of $Q$. Then the eigenvalues of $I-Q$ are $1-\\lambda_i$, and the eigenvalues of $(I-Q)^{-1}$ are $(1-\\lambda_i)^{-1}$.\nTherefore:\n$$\n\\rho((I-Q)^{-1}) = \\max_i \\left| \\frac{1}{1-\\lambda_i} \\right|\n$$\nTo find the eigenvalues of $Q$, we solve the characteristic equation $\\det(Q - \\lambda I) = 0$:\n$$\n\\det \\begin{pmatrix} 0.3-\\lambda  0.2 \\\\ 0.2  0.4-\\lambda \\end{pmatrix} = (0.3-\\lambda)(0.4-\\lambda) - (0.2)(0.2) = 0\n$$\n$$\n\\lambda^2 - 0.7\\lambda + 0.12 - 0.04 = 0\n$$\n$$\n\\lambda^2 - 0.7\\lambda + 0.08 = 0\n$$\nUsing the quadratic formula, the eigenvalues are:\n$$\n\\lambda = \\frac{-(-0.7) \\pm \\sqrt{(-0.7)^2 - 4(1)(0.08)}}{2(1)} = \\frac{0.7 \\pm \\sqrt{0.49 - 0.32}}{2} = \\frac{0.7 \\pm \\sqrt{0.17}}{2}\n$$\nThe two eigenvalues are $\\lambda_1 = \\frac{0.7 + \\sqrt{0.17}}{2}$ and $\\lambda_2 = \\frac{0.7 - \\sqrt{0.17}}{2}$. Both eigenvalues are real and positive. The spectral radius of $Q$ is the larger eigenvalue:\n$$\n\\rho(Q) = \\lambda_1 = \\frac{0.7 + \\sqrt{0.17}}{2}\n$$\nNumerically, $\\sqrt{0.17} \\approx 0.412$, so $\\rho(Q) \\approx \\frac{1.112}{2} = 0.556  1$, confirming that $T$ is indeed a transient class.\nNow, we find the spectral radius of $(I-Q)^{-1}$. Since $0  \\lambda_2  \\lambda_1  1$, the expression $|(1-\\lambda_i)^{-1}|$ is maximized when $1-\\lambda_i$ is minimized, which occurs for the largest eigenvalue $\\lambda_1 = \\rho(Q)$.\n$$\n\\rho((I-Q)^{-1}) = \\frac{1}{1 - \\lambda_1} = \\frac{1}{1 - \\rho(Q)}\n$$\nSubstituting this back into the expression for $\\varepsilon^{\\star}$:\n$$\n\\varepsilon^{\\star} = \\frac{1}{\\rho((I-Q)^{-1})} = 1 - \\rho(Q)\n$$\nWe can now compute the numerical value:\n$$\n\\varepsilon^{\\star} = 1 - \\frac{0.7 + \\sqrt{0.17}}{2} = \\frac{2 - (0.7 + \\sqrt{0.17})}{2} = \\frac{1.3 - \\sqrt{0.17}}{2}\n$$\nUsing a calculator, $\\sqrt{0.17} \\approx 0.41231056256$.\n$$\n\\varepsilon^{\\star} = \\frac{1.3 - 0.41231056256}{2} = \\frac{0.88768943744}{2} = 0.44384471872\n$$\nRounding the result to four significant figures gives $0.4438$.", "answer": "$$\\boxed{0.4438}$$", "id": "3295790"}, {"introduction": "While many stochastic processes are naturally modeled on infinite state spaces, any practical simulation must operate on a finite subset. This necessary simplification raises a critical question: what errors do we introduce by truncating the state space? This problem [@problem_id:3295771] provides a hands-on theoretical workout in quantifying this error, known as truncation bias. Using first-step analysis on a classic birth-death process, you will derive a tight, analytical bound on how an artificial boundary affects absorption probabilities, a key skill for validating finite-dimensional approximations of larger systems.", "problem": "Consider a discrete-time birth–death Markov chain on the countable state space $\\{0,1,2,\\ldots\\}$ with transition probabilities defined as follows. For each state $k \\geq 1$, the chain moves to $k-1$ with probability $q \\in (1/2,1)$ and to $k+1$ with probability $p = 1 - q \\in (0,1/2)$. State $0$ is absorbing. From the core definitions of classification of states, argue that $0$ is an absorbing state and that every state $i \\in \\{1,2,\\ldots\\}$ is transient for this chain. Now, for a fixed finite cutoff $N \\in \\mathbb{N}$ with $N \\geq 2$, define a truncated chain on $\\{0,1,\\ldots,N\\}$ that evolves with the same local transition probabilities on $\\{1,\\ldots,N-1\\}$ but treats both $0$ and $N$ as absorbing states. Let $\\alpha_i$ denote the true absorption probability at $0$ for the infinite-state chain started from $i \\in \\{1,\\ldots,N-1\\}$, and let $\\widehat{\\alpha}_i^{(N)}$ denote the absorption probability at $0$ for the truncated chain started from the same $i$.\n\nUsing only first-step analysis and a monotone coupling between the infinite-state chain and the truncated chain, derive a computable and tight upper bound $b_{i,N}$ on the truncation bias $\\alpha_i - \\widehat{\\alpha}_i^{(N)}$ that depends only on $p$, $q$, $i$, and $N$. Your bound must be expressed as a single closed-form analytic expression. Provide this bound as your final answer in terms of $p$, $q$, $i$, and $N$. Do not give an inequality; give only the expression for the smallest such $b_{i,N}$ that can be certified by this coupling argument. No numerical evaluation is required, and no rounding is needed.", "solution": "The problem requires the validation of its premises and, if valid, the derivation of a tight upper bound on the truncation bias for a birth-death process.\n\n**Problem Validation**\n\nFirst, the problem statement is subjected to critical validation.\n\n*   **Givens:**\n    *   **Infinite Chain:** A discrete-time birth–death Markov chain on the state space $S = \\{0, 1, 2, \\dots\\}$.\n    *   Transition probabilities for $k \\ge 1$: $P(k \\to k-1) = q$ and $P(k \\to k+1) = p$, where $p=1-q$.\n    *   State $0$ is absorbing: $P(0 \\to 0) = 1$.\n    *   Parameter constraints: $q \\in (1/2, 1)$, implying $p \\in (0, 1/2)$.\n    *   **Truncated Chain:** A Markov chain on $S_N = \\{0, 1, \\dots, N\\}$ for $N \\ge 2$.\n    *   Transition probabilities for $k \\in \\{1, \\dots, N-1\\}$ are identical to the infinite chain.\n    *   States $0$ and $N$ are absorbing.\n    *   **Quantities of Interest:**\n        *   $\\alpha_i$: The probability of absorption at state $0$ for the infinite chain, starting from state $i$.\n        *   $\\widehat{\\alpha}_i^{(N)}$: The probability of absorption at state $0$ for the truncated chain, starting from state $i$.\n        *   $b_{i,N}$: A tight upper bound on the truncation bias, $\\alpha_i - \\widehat{\\alpha}_i^{(N)}$.\n*   **Validation Verdict:** The problem is scientifically grounded, well-posed, and objective. It describes a standard birth-death process, a cornerstone of stochastic process theory. The specified drift condition $q  p$ is critical and well-defined. All terms are standard and the objectives are clear. The problem is a non-trivial but solvable exercise in Markov chain analysis, specifically involving the comparison of a process and its truncated version. It does not violate any of the invalidity criteria. Therefore, the problem is deemed **valid**.\n\n**Solution Derivation**\n\nThe solution will proceed in three stages: (1) classification of states for the infinite chain, (2) derivation of an exact expression for the truncation bias using first-step analysis, and (3) determination of the tightest upper bound by combining the results.\n\n**1. Classification of States in the Infinite Chain**\n\nBy definition, state $0$ is absorbing since the chain cannot leave it. To classify the states $i \\in \\{1, 2, \\dots\\}$, we determine $\\alpha_i$, the probability of eventual absorption at $0$ starting from state $i$. The problem specifies using a monotone coupling argument.\n\nConsider a family of such infinite chains, parameterized by their upward probability $p \\in (0, 1/2]$. Let $\\alpha_i(p)$ be the absorption probability at $0$ starting from $i$ for a chain with parameter $p$. Let $p_1, p_2$ be two such parameters with $p_1  p_2$. Let $X_n^{(1)}$ and $X_n^{(2)}$ be chains with parameters $p_1$ and $p_2$ respectively, both starting from $X_0^{(1)} = X_0^{(2)} = i$. We can couple their evolutions using a single sequence of i.i.d. uniform random variables $U_n \\sim U(0,1)$. The state update from $k0$ is a function of $U_{n+1}$: $+1$ if $U_{n+1}  p$, and $-1$ if $U_{n+1} \\ge p$.\nSince $p_1  p_2$, the increment $\\Delta X_n^{(1)}$ is always less than or equal to the increment $\\Delta X_n^{(2)}$. This establishes a pathwise ordering $X_n^{(1)} \\le X_n^{(2)}$ for all $n \\ge 0$.\n\nThis ordering implies that the process with the smaller upward drift is more likely to be absorbed at $0$. Hence, $\\alpha_i(p)$ is a non-increasing function of $p$. For the special case of a symmetric random walk where $p=1/2$, it is a standard result that the chain on $\\{0, 1, \\dots\\}$ is null-recurrent, which guarantees that it will hit state $0$ with probability $1$. Thus, $\\alpha_i(1/2) = 1$.\n\nGiven that $\\alpha_i(p)$ is non-increasing, for our case where $p = 1-q  1/2$, we must have $\\alpha_i(p) \\ge \\alpha_i(1/2) = 1$. Since $\\alpha_i(p)$ is a probability, it cannot exceed $1$. Therefore, we conclude that $\\alpha_i(p)=1$ for all $p \\in (0, 1/2]$.\n\nFor our chain, this means $\\alpha_i = 1$ for all $i \\ge 1$. A state is transient if the probability of ever returning to it, starting from it, is less than $1$. Since any state $i \\ge 1$ is absorbed at $0$ with probability $1$, it can only visit state $i$ a finite number of times. Thus, every state $i \\in \\{1, 2, \\dots\\}$ is transient.\n\n**2. Truncation Bias Analysis**\n\nLet the truncation bias be $\\epsilon_i = \\alpha_i - \\widehat{\\alpha}_i^{(N)}$. We use first-step analysis to find an expression for $\\epsilon_i$.\nFor the infinite chain, the absorption probabilities satisfy:\n$\\alpha_i = p \\alpha_{i+1} + q \\alpha_{i-1}$ for $i \\ge 1$, with boundary condition $\\alpha_0 = 1$.\n\nFor the truncated chain, the absorption probabilities at $0$ satisfy:\n$\\widehat{\\alpha}_i^{(N)} = p \\widehat{\\alpha}_{i+1}^{(N)} + q \\widehat{\\alpha}_{i-1}^{(N)}$ for $i \\in \\{1, \\dots, N-1\\}$, with boundary conditions $\\widehat{\\alpha}_0^{(N)} = 1$ and $\\widehat{\\alpha}_N^{(N)} = 0$.\n\nSubtracting the second equation from the first for $i \\in \\{1, \\dots, N-1\\}$ gives a recurrence relation for the bias $\\epsilon_i$:\n$\\epsilon_i = p \\epsilon_{i+1} + q \\epsilon_{i-1}$.\nThis is the same homogeneous recurrence relation. We need to determine the boundary conditions for $\\epsilon_i$.\nAt $i=0$: $\\epsilon_0 = \\alpha_0 - \\widehat{\\alpha}_0^{(N)} = 1 - 1 = 0$.\nAt $i=N$: $\\epsilon_N = \\alpha_N - \\widehat{\\alpha}_N^{(N)} = \\alpha_N - 0 = \\alpha_N$.\n\nThe problem of finding $\\epsilon_i$ is now equivalent to a classic gambler's ruin problem on the state space $\\{0, 1, \\dots, N\\}$, where the probability of \"winning\" (reaching state $N$ before state $0$) is sought. The general solution to the recurrence is $\\epsilon_i = A \\cdot 1^i + B \\cdot (q/p)^i$.\nApplying the boundary conditions:\nFor $i=0$: $A + B = \\epsilon_0 = 0 \\implies A = -B$.\nFor $i=N$: $A + B(q/p)^N = \\epsilon_N$.\nSubstituting $A=-B$ into the second equation gives:\n$-B + B(q/p)^N = \\epsilon_N \\implies B \\left( (q/p)^N - 1 \\right) = \\epsilon_N \\implies B = \\frac{\\epsilon_N}{(q/p)^N - 1}$.\nThus, the solution for the bias is:\n$\\epsilon_i = \\frac{\\epsilon_N}{(q/p)^N - 1} \\left( (q/p)^i - 1 \\right)$.\n\n**3. Final Upper Bound Expression**\n\nSubstituting $\\epsilon_N = \\alpha_N$ into the expression for $\\epsilon_i$ yields the exact truncation bias:\n$\\alpha_i - \\widehat{\\alpha}_i^{(N)} = \\alpha_N \\frac{(q/p)^i - 1}{(q/p)^N - 1}$.\nThis expression for the bias is what can be certified by the specified methodology. The problem asks for a computable, tight upper bound $b_{i,N}$ that depends only on $p, q, i, N$. To achieve this, we must substitute the value of $\\alpha_N$.\nFrom Part 1, we rigorously established using a monotone coupling argument that $\\alpha_i=1$ for all initial states $i \\ge 1$. In particular, for the state $N \\ge 2$, we have $\\alpha_N=1$.\n\nSubstituting $\\alpha_N=1$ into the exact bias formula gives:\n$\\alpha_i - \\widehat{\\alpha}_i^{(N)} = \\frac{(q/p)^i - 1}{(q/p)^N - 1}$.\nThis expression is the exact value of the truncation bias. It is, therefore, the tightest possible upper bound on the bias, and it depends only on the given parameters $p, q, i, N$. This is the requested expression for $b_{i,N}$.\n\nFinal expression for the bound $b_{i,N}$:\nLet $\\rho = q/p$. The expression is $\\frac{\\rho^i - 1}{\\rho^N - 1}$.", "answer": "$$\\boxed{\\frac{\\left(\\frac{q}{p}\\right)^i - 1}{\\left(\\frac{q}{p}\\right)^N - 1}}$$", "id": "3295771"}, {"introduction": "Moving from theoretical analysis to computational practice, this final exercise explores how the choice of numerical algorithm can profoundly impact a simulation's validity. You will implement and compare the state classifications of a continuous-time Markov chain against two of its discrete-time approximations, including a common but heuristic Euler method [@problem_id:3295807]. This coding-intensive practice reveals how seemingly minor numerical choices can create artificial absorbing states and alter a system's long-term dynamics, equipping you with the critical skills to diagnose and avoid such pitfalls in your own simulation work.", "problem": "Consider a finite-state, continuous-time Markov jump process with generator matrix $Q \\in \\mathbb{R}^{n \\times n}$, where $q_{ij} \\ge 0$ for $i \\ne j$ and each row sums to zero, i.e., $\\sum_{j=1}^{n} q_{ij} = 0$. The discrete-time skeleton at time step $\\Delta t  0$ has transition matrix $P_{\\mathrm{exact}}(\\Delta t) = \\exp(Q \\Delta t)$, the matrix exponential of $Q \\Delta t$. In practice, one often uses a first-order Euler discretization $P_{\\mathrm{raw}}(\\Delta t) = I + \\Delta t \\, Q$. To enforce stochasticity and handle numerical sparsification, a heuristic thresholding-and-renormalization scheme with tolerance $\\tau  0$ is applied as follows:\n- Threshold: For each entry, set $(P_{\\mathrm{raw}}(\\Delta t))_{ij}$ to $0$ if $(P_{\\mathrm{raw}}(\\Delta t))_{ij}  \\tau$.\n- Renormalize: For each row $i$, compute the row sum $s_i = \\sum_{j=1}^{n} (P_{\\mathrm{raw}}(\\Delta t))_{ij}$ after thresholding. If $s_i  0$, set $(P_{\\mathrm{EC}})_{ij} = (P_{\\mathrm{raw}}(\\Delta t))_{ij} / s_i$. If $s_i = 0$, set the row to the $i$-th standard basis vector (i.e., $(P_{\\mathrm{EC}})_{ii} = 1$ and $(P_{\\mathrm{EC}})_{ij} = 0$ for $j \\ne i$). Denote the resulting matrix by $P_{\\mathrm{EC}}(\\Delta t,\\tau)$.\n\nState classification is defined as follows.\n- For the continuous-time Markov chain (CTMC) with generator $Q$, construct the directed graph on $\\{1,\\dots,n\\}$ with an edge $i \\to j$ if and only if $q_{ij}  0$ for $i \\ne j$. A communicating class is a strongly connected component of this graph. A class is closed if there is no edge from any state inside the class to any state outside the class. A state $i$ is absorbing if $q_{ij} = 0$ for all $j \\ne i$ (equivalently, $q_{ii} = 0$). A state is recurrent if it lies in a closed communicating class; otherwise it is transient.\n- For any discrete-time Markov chain (DTMC) with transition matrix $P$ (e.g., $P_{\\mathrm{exact}}$ or $P_{\\mathrm{EC}}$), construct the directed graph on $\\{1,\\dots,n\\}$ with an edge $i \\to j$ if and only if $p_{ij}  0$. Use the same communicating class definitions. A state $i$ is absorbing if $p_{ii} = 1$ and $p_{ij} = 0$ for all $j \\ne i$. A state is recurrent if it lies in a closed communicating class; otherwise it is transient.\n\nYour task is to implement a program that, for several given test cases, compares the classification of states for the CTMC and its two discretizations $P_{\\mathrm{exact}}(\\Delta t)$ and $P_{\\mathrm{EC}}(\\Delta t,\\tau)$, and empirically studies the effect of thresholding by estimating return probabilities via Monte Carlo simulation.\n\nStart from first principles: definitions of the generator $Q$, the skeleton $P_{\\mathrm{exact}}(\\Delta t)$, and the graph-theoretic classification into transient, recurrent, and absorbing states. Do not assume shortcut classification formulas beyond these definitions. You must implement:\n- An exact discretization subroutine using the matrix exponential.\n- The Euler-with-thresholding discretization $P_{\\mathrm{EC}}(\\Delta t,\\tau)$ as specified.\n- A graph-based classifier to label every state as one of the three categories: absorbing, recurrent non-absorbing, or transient, for both $Q$ and any $P$.\n- A Monte Carlo estimator for the probability that a trajectory starting in state $1$ (indexing states as $1,2,\\dots,n$) returns to state $1$ at some time $k \\ge 1$ within a fixed horizon of $N_{\\mathrm{steps}}$ steps under a given $P$. Use a fixed number of paths $N_{\\mathrm{paths}}$ and a fixed random seed for reproducibility.\n\nFor each test case, compute the following three quantities:\n1. $k_{\\mathrm{art}}$: the number of states that are absorbing under $P_{\\mathrm{EC}}(\\Delta t,\\tau)$ but not absorbing under the CTMC generator $Q$.\n2. $k_{\\mathrm{chg}}$: the number of states whose classification label among $\\{\\text{transient}, \\text{recurrent non-absorbing}, \\text{absorbing}\\}$ under $P_{\\mathrm{EC}}(\\Delta t,\\tau)$ differs from their classification label under the CTMC generator $Q$.\n3. $\\Delta r$: the difference between Monte Carlo estimated return probabilities to state $1$ under $P_{\\mathrm{EC}}(\\Delta t,\\tau)$ and $P_{\\mathrm{exact}}(\\Delta t)$, i.e., $\\Delta r = \\widehat{\\mathbb{P}}_{\\mathrm{EC}}(\\text{return to state }1) - \\widehat{\\mathbb{P}}_{\\mathrm{exact}}(\\text{return to state }1)$. Round $\\Delta r$ to three decimal places.\n\nUse the following test suite. In each case, states are indexed $1,2,\\dots,n$ with $n$ implicit in $Q$:\n- Test $1$ (irreducible two-state CTMC, small time step but large threshold):\n  - $Q = \\begin{bmatrix} -3  3 \\\\ 4  -4 \\end{bmatrix}$, $\\Delta t = 0.01$, $\\tau = 0.05$.\n- Test $2$ (same CTMC, moderate time step and tiny threshold):\n  - $Q = \\begin{bmatrix} -3  3 \\\\ 4  -4 \\end{bmatrix}$, $\\Delta t = 0.2$, $\\tau = 0.001$.\n- Test $3$ (three-state chain with a true absorbing state):\n  - $Q = \\begin{bmatrix} -1  1  0 \\\\ 0  -1  1 \\\\ 0  0  0 \\end{bmatrix}$, $\\Delta t = 0.1$, $\\tau = 10^{-4}$.\n- Test $4$ (same three-state chain, very small time step and large threshold creating artificial self-loops):\n  - $Q = \\begin{bmatrix} -1  1  0 \\\\ 0  -1  1 \\\\ 0  0  0 \\end{bmatrix}$, $\\Delta t = 0.001$, $\\tau = 0.05$.\n\nMonte Carlo parameters must be fixed as $N_{\\mathrm{paths}} = 5000$, $N_{\\mathrm{steps}} = 200$, and random seed $12345$. The event “return to state $1$” is defined as visiting state $1$ at any time step $k \\in \\{1,2,\\dots,N_{\\mathrm{steps}}\\}$ after starting in state $1$ at time $0$.\n\nYour program should produce a single line of output containing the results for all test cases as a comma-separated list of triplets enclosed in square brackets, with each triplet in the order $[k_{\\mathrm{art}}, k_{\\mathrm{chg}}, \\Delta r]$, for Tests $1$ through $4$ in order, i.e., an output of the form $[[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot]]$. All quantities are dimensionless and must be printed as numbers (with $\\Delta r$ rounded to three decimal places).", "solution": "The problem requires a comparative analysis of state classifications for a continuous-time Markov chain (CTMC) and two of its discrete-time approximations. This involves implementing graph-based classification algorithms, numerical matrix operations, and a Monte Carlo simulation. The problem is scientifically grounded, well-posed, and all necessary parameters and definitions are provided. I will proceed with a full solution.\n\nThe core of the problem lies in correctly classifying the states of a Markov chain as transient, recurrent non-absorbing, or absorbing. The provided definitions are based on the graph structure of the chain.\n\n**1. State Classification Algorithm**\n\nThe classification of states relies on the concept of communicating classes and closed classes. A communicating class is a strongly connected component (SCC) of the state-space graph. A class is closed if no state within it can transition to any state outside of it. A state is recurrent if it belongs to a closed communicating class and transient otherwise. An absorbing state is a special case of a recurrent state that forms a closed class of size one.\n\nLet $n$ be the number of states.\nThe algorithm proceeds as follows for a given matrix ($Q$ for a CTMC or $P$ for a DTMC):\n1.  **Construct the Adjacency List:** A directed graph is constructed on the states $\\{1, \\dots, n\\}$.\n    -   For a CTMC generator $Q$, an edge exists from state $i$ to $j$ ($i \\neq j$) if and only if the transition rate $q_{ij}  0$.\n    -   For a DTMC transition matrix $P$, an edge exists from $i$ to $j$ if and only if the transition probability $p_{ij}  0$.\n2.  **Find Strongly Connected Components (SCCs):** We use Tarjan's algorithm, a depth-first search based approach, to find all SCCs of the graph. Each SCC is a communicating class.\n3.  **Identify Closed Classes:** For each SCC, we check if it is closed. An SCC is closed if there are no outgoing edges from any of its constituent states to any state not in that SCC.\n4.  **Classify States:** Each state $i \\in \\{1, \\dots, n\\}$ is classified based on the following hierarchy:\n    a.  **Absorbing:** A state $i$ is absorbing if it is a sink. For a CTMC, this is defined by $q_{ii} = 0$, which implies $q_{ij} = 0$ for all $j \\neq i$. For a DTMC, this is defined by $p_{ii} = 1$.\n    b.  **Recurrent Non-Absorbing:** If a state $i$ is not absorbing, but belongs to a closed communicating class, it is classified as recurrent non-absorbing.\n    c.  **Transient:** If a state $i$ is neither absorbing nor recurrent non-absorbing, it is transient. This means it belongs to a communicating class that is not closed, implying there is a path to escape the class.\n\n**2. Discretization Schemes**\n\nTwo discretization schemes are considered:\n\n-   **Exact Discretization ($P_{\\mathrm{exact}}$):** The transition matrix for the discrete-time skeleton over a time step $\\Delta t  0$ is given by the matrix exponential:\n    $$P_{\\mathrm{exact}}(\\Delta t) = \\exp(Q \\Delta t)$$\n    This is computed using `scipy.linalg.expm`.\n\n-   **Euler with Correction ($P_{\\mathrm{EC}}$):** This is a heuristic scheme involving three steps:\n    1.  **Euler Step:** A first-order approximation is made: $P_{\\mathrm{raw}}(\\Delta t) = I + \\Delta t \\, Q$, where $I$ is the identity matrix.\n    2.  **Thresholding:** Small entries, which may be numerical noise or small but true probabilities, are removed. Given a tolerance $\\tau  0$, any entry $(P_{\\mathrm{raw}})_{ij}  \\tau$ is set to $0$.\n    3.  **Renormalization:** To restore the stochastic property (rows summing to $1$), each row is renormalized. For each row $i$, let $s_i$ be its sum after thresholding.\n        -   If $s_i  0$, each element in the row is divided by $s_i$, yielding $(P_{\\mathrm{EC}})_{ij} = (P_{\\mathrm{raw}})_{ij} / s_i$.\n        -   If $s_i = 0$ (all entries in the row were thresholded to zero), the state is made absorbing: $(P_{\\mathrm{EC}})_{ii} = 1$ and $(P_{\\mathrm{EC}})_{ij} = 0$ for $j \\neq i$.\n\n**3. Monte Carlo Estimation of Return Probability**\n\nWe estimate the probability that a trajectory starting in state $1$ (index $0$) visits state $1$ again at any time step $k \\in \\{1, 2, \\dots, N_{\\mathrm{steps}}\\}$. This is the probability of the event $\\bigcup_{k=1}^{N_{\\mathrm{steps}}} \\{X_k=1\\} \\mid X_0=1$.\n\nThe estimation is performed using a Monte Carlo simulation with $N_{\\mathrm{paths}}$ trajectories, each simulated for up to $N_{\\mathrm{steps}}$.\n1.  Initialize a counter for returning paths, `return_count = 0`. A fixed random seed ensures reproducibility.\n2.  For each of the $N_{\\mathrm{paths}}$ simulations:\n    a.  Start the trajectory at `current_state = 0` (for state $1$).\n    b.  For each time step from $1$ to $N_{\\mathrm{steps}}$:\n        i. Sample the `next_state` from the categorical distribution defined by the `current_state` row of the transition matrix $P$.\n        ii. If `next_state` is $0$, the trajectory has returned. Mark this path as a success and break the inner loop to start the next path.\n        iii. Update `current_state = next_state`.\n    c.  If the path was a success, increment `return_count`.\n3.  The estimated probability is $\\widehat{\\mathbb{P}} = \\text{return\\_count} / N_{\\mathrm{paths}}$.\n\n**4. Analysis and Computation**\n\nFor each test case, we perform the following computations:\n-   Determine the classification arrays for the CTMC ($Q$) and the $P_{\\mathrm{EC}}$ approximation.\n-   $k_{\\mathrm{art}}$: The number of artificial absorbing states. This is the count of states that are absorbing under $P_{\\mathrm{EC}}$ but not under $Q$.\n-   $k_{\\mathrm{chg}}$: The number of states whose classification changes. This is found by comparing the classification arrays for $Q$ and $P_{\\mathrm{EC}}$ element-wise.\n-   $\\Delta r$: The difference in estimated return probabilities. We compute $\\widehat{\\mathbb{P}}_{\\mathrm{EC}}(\\text{return})$ and $\\widehat{\\mathbb{P}}_{\\mathrm{exact}}(\\text{return})$ via Monte Carlo and calculate $\\Delta r = \\widehat{\\mathbb{P}}_{\\mathrm{EC}} - \\widehat{\\mathbb{P}}_{\\mathrm{exact}}$, rounded to three decimal places.\n\nThese steps are systematically applied to each of the four test cases provided.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import expm\n\ndef get_classification(M, is_ctmc):\n    \"\"\"\n    Classifies states of a Markov chain as 'absorbing', 'recurrent non-absorbing', or 'transient'.\n\n    Args:\n        M (np.ndarray): The generator matrix Q (if is_ctmc) or transition matrix P.\n        is_ctmc (bool): True for CTMC (Q), False for DTMC (P).\n\n    Returns:\n        list[str]: A list of classification labels for each state.\n    \"\"\"\n    n = M.shape[0]\n\n    # 1. Build adjacency list based on the graph definition\n    adj = [[] for _ in range(n)]\n    if is_ctmc: # Graph from Q\n        for i in range(n):\n            for j in range(n):\n                if i != j and M[i, j]  0:\n                    adj[i].append(j)\n    else: # Graph from P\n        for i in range(n):\n            for j in range(n):\n                if M[i, j]  0:\n                    # Self-loops are part of the graph for DTMCs\n                    adj[i].append(j)\n\n    # 2. Find Strongly Connected Components (SCCs) using Tarjan's algorithm\n    ids = [-1] * n\n    low = [-1] * n\n    onStack = [False] * n\n    stack = []\n    at_scc = 0\n    sccs = []\n    \n    def tarjan_dfs(at):\n        nonlocal at_scc\n        stack.append(at)\n        onStack[at] = True\n        ids[at] = low[at] = at_scc\n        at_scc += 1\n\n        for to in adj[at]:\n            if ids[to] == -1:\n                tarjan_dfs(to)\n            if onStack[to]:\n                low[at] = min(low[at], low[to])\n\n        if ids[at] == low[at]:\n            scc = []\n            while stack:\n                node = stack.pop()\n                onStack[node] = False\n                low[node] = ids[at]\n                scc.append(node)\n                if node == at: break\n            sccs.append(scc)\n\n    for i in range(n):\n        if ids[i] == -1:\n            tarjan_dfs(i)\n\n    # 3. Identify closed classes\n    state_to_scc_id = {state: i for i, scc in enumerate(sccs) for state in scc}\n    closed_scc_ids = set()\n    for i, scc in enumerate(sccs):\n        is_closed = True\n        for u in scc:\n            for v in adj[u]:\n                if state_to_scc_id.get(v) != i:\n                    is_closed = False\n                    break\n            if not is_closed:\n                break\n        if is_closed:\n            closed_scc_ids.add(i)\n\n    # 4. Classify states\n    labels = [''] * n\n    for i in range(n):\n        is_absorbing = False\n        if is_ctmc:\n            if M[i, i] == 0:\n                is_absorbing = True\n        else: # DTMC\n            if M[i, i] == 1.0:\n                # For a stochastic matrix, p_ii=1 implies p_ij=0 for j!=i\n                is_absorbing = True\n\n        if is_absorbing:\n            labels[i] = 'absorbing'\n        else:\n            scc_id = state_to_scc_id[i]\n            if scc_id in closed_scc_ids:\n                labels[i] = 'recurrent non-absorbing'\n            else:\n                labels[i] = 'transient'\n    \n    return labels\n\ndef get_p_ec(Q, dt, tau):\n    \"\"\"\n    Computes the Euler-with-correction discretization P_EC.\n    \"\"\"\n    P_raw = np.eye(Q.shape[0]) + dt * Q\n    P_thresh = np.where(P_raw  tau, 0, P_raw)\n    \n    P_ec = np.zeros_like(P_thresh)\n    row_sums = P_thresh.sum(axis=1)\n    \n    for i in range(Q.shape[0]):\n        if row_sums[i]  0:\n            P_ec[i, :] = P_thresh[i, :] / row_sums[i]\n        else:\n            P_ec[i, i] = 1.0\n            \n    return P_ec\n\ndef monte_carlo_return_prob(P, n_paths, n_steps, seed):\n    \"\"\"\n    Estimates the probability of returning to state 1 (index 0).\n    \"\"\"\n    n = P.shape[0]\n    rng = np.random.default_rng(seed)\n    states = np.arange(n)\n    \n    return_count = 0\n    start_state = 0\n\n    for _ in range(n_paths):\n        current_state = start_state\n        has_returned = False\n        for _ in range(n_steps):\n            probs = P[current_state, :]\n            # Normalize to handle potential float inaccuracies\n            probs /= probs.sum() \n            next_state = rng.choice(states, p=probs)\n            \n            if next_state == start_state:\n                has_returned = True\n                break\n            current_state = next_state\n        \n        if has_returned:\n            return_count += 1\n            \n    return return_count / n_paths\n\n\ndef solve():\n    \"\"\"\n    Main solver function to process test cases and produce the final output.\n    \"\"\"\n    # Define test cases from the problem statement.\n    test_cases = [\n        {\n            'Q': np.array([[-3., 3.], [4., -4.]]),\n            'dt': 0.01,\n            'tau': 0.05\n        },\n        {\n            'Q': np.array([[-3., 3.], [4., -4.]]),\n            'dt': 0.2,\n            'tau': 0.001\n        },\n        {\n            'Q': np.array([[-1., 1., 0.], [0., -1., 1.], [0., 0., 0.]]),\n            'dt': 0.1,\n            'tau': 1e-4\n        },\n        {\n            'Q': np.array([[-1., 1., 0.], [0., -1., 1.], [0., 0., 0.]]),\n            'dt': 0.001,\n            'tau': 0.05\n        }\n    ]\n\n    mc_params = {\n        'n_paths': 5000,\n        'n_steps': 200,\n        'seed': 12345\n    }\n\n    results = []\n    for case in test_cases:\n        Q, dt, tau = case['Q'], case['dt'], case['tau']\n        n = Q.shape[0]\n\n        # Classifications\n        class_q = get_classification(Q, is_ctmc=True)\n        \n        P_ec = get_p_ec(Q, dt, tau)\n        class_pec = get_classification(P_ec, is_ctmc=False)\n        \n        P_exact = expm(Q * dt)\n\n        # 1. k_art: artificial absorbing states\n        absorbing_q = {i for i, label in enumerate(class_q) if label == 'absorbing'}\n        absorbing_pec = {i for i, label in enumerate(class_pec) if label == 'absorbing'}\n        k_art = len(absorbing_pec - absorbing_q)\n\n        # 2. k_chg: states with changed classification\n        k_chg = sum(1 for i in range(n) if class_q[i] != class_pec[i])\n\n        # 3. Δr: difference in return probabilities\n        # Note: The MC simulation needs a different seed for each run to be independent\n        # However, the problem asks for a fixed seed for reproducibility. We use the same seed\n        # for both simulations, which means we test both matrices against the same random numbers.\n        # This is a valid way to reduce variance in the *difference* of estimates.\n        prob_ec = monte_carlo_return_prob(P_ec, **mc_params)\n        prob_exact = monte_carlo_return_prob(P_exact, **mc_params)\n        delta_r = round(prob_ec - prob_exact, 3)\n\n        results.append([k_art, k_chg, delta_r])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3295807"}]}