{"hands_on_practices": [{"introduction": "This exercise transitions you from qualitative visual inspection of trace plots to quantitative rigor. You will build a core toolkit of MCMC diagnostics from the ground up, starting from fundamental statistical principles. By deriving and implementing metrics like the potential scale reduction factor ($\\hat{R}$), autocorrelation, and effective sample size, you will gain a deep understanding of how to numerically assess whether your chains have converged and are mixing efficiently [@problem_id:3289581].", "problem": "You are tasked with formalizing a quantitative method to assess convergence from trace plots in stochastic simulation, starting from core definitions in probability and statistics. You will then implement and apply this method to a specified test suite of simulated Markov Chain Monte Carlo traces.\n\nFundamental base and scenario: Consider $m$ parallel simulated sequences (“chains”) $\\{x_{j,t}\\}_{t=1}^{n}$ for $j \\in \\{1,\\dots,m\\}$ of a scalar parameter, each generated by a first-order autoregressive process (AR($1$)) centered on a possibly time-varying mean:\n$$\nx_{j,t} \\;=\\; \\mu_{j,t} \\;+\\; \\phi\\left(x_{j,t-1}-\\mu_{j,t}\\right) \\;+\\; \\varepsilon_{j,t},\n$$\nwith $\\varepsilon_{j,t} \\overset{\\text{i.i.d.}}{\\sim} \\mathcal{N}\\!\\left(0, \\sigma^2(1-\\phi^2)\\right)$, where $\\phi \\in (-1,1)$ controls correlation and $\\sigma^2$ is the stationary marginal variance when $\\mu_{j,t}$ is constant. For constant $\\mu_{j,t} \\equiv \\mu$, the stationary distribution is $\\mathcal{N}(\\mu,\\sigma^2)$.\n\nYour goal is to derive, implement, and apply the following quantitative “trace-extraction” diagnostics, each grounded in core definitions:\n- A between-versus-within variance comparison across split chains (to detect between-chain inconsistencies) derived from the law of total variance and sample variance definitions.\n- A lag-$1$ autocorrelation estimator (to detect poor mixing) derived from sample autocovariance and variance.\n- An early-versus-late window standardized drift magnitude (to detect nonstationary trends) derived from sample means and pooled variance.\n- An approximate total effective sample size under an AR($1$) approximation derived from the integrated autocorrelation time.\n\nUsing these diagnostics, a chain ensemble is declared “converged” if and only if all of the following are simultaneously satisfied:\n1. The split-chain potential scale reduction factor $\\hat{R}$ is at most $\\tau_R = 1.05$.\n2. The average lag-$1$ autocorrelation across chains is at most $\\tau_\\rho = 0.3$.\n3. The standardized drift magnitude is at most $\\tau_D = 0.15$.\n4. The total effective sample size is at least $E_{\\min} = 2000$.\n\nDerive computable formulas as follows, starting only from the definitions of sample mean, sample variance, autocovariance, the law of total variance, and the AR($1$) integrated autocorrelation time:\n\n- Split-chain variability comparison: Split each chain into two halves, yielding $m_s = 2m$ sequences of equal length $n_s = n/2$. Let $\\bar{x}_{.j}$ denote the sample mean of split sequence $j$ and $s_j^2$ its sample variance. Let $\\bar{x}_{..}$ be the mean across all split sequences. Define the within-sequence variance $W$ as the average of $s_j^2$ and the between-sequence variance $B$ proportional to the variance of $\\bar{x}_{.j}$, and from these construct an overdispersed variance estimator $V^+$ and the potential scale reduction factor $\\hat{R}$. The derivation must begin from the sample mean and variance definitions and the law of total variance, and must not assume any pre-packaged formula.\n\n- Lag-$1$ autocorrelation: For each chain $j$, estimate the lag-$1$ autocovariance and autocorrelation using the definitions of sample autocovariance and sample variance, then average the autocorrelations across chains.\n\n- Standardized drift magnitude: For each chain $j$, compute the mean of the first $k$ samples and the mean of the last $k$ samples, where $k = \\lfloor 0.4 n \\rfloor$. Define the drift for chain $j$ as the absolute difference of these two means, and standardize by the pooled standard deviation across all chains and all times. Average this standardized drift over $j=1,\\dots,m$.\n\n- Effective sample size under AR($1$): Using the AR($1$) approximation, the integrated autocorrelation time is obtained from the geometric series of autocorrelations, yielding a computable expression in terms of lag-$1$ autocorrelation $\\rho$. From this, derive the total effective sample size for $m$ chains each of length $n$.\n\nTest suite: You must simulate the data for four cases, each with $m=4$ chains and $n=2000$ samples per chain, Gaussian noise variance specified via $\\sigma^2=1$, and random seed fixed at $12345$ for reproducibility. Use the AR($1$) recursion above with initial values $x_{j,1}$ drawn from the stationary distribution corresponding to the initial mean in each chain. For each case, define $\\mu_{j,t}$ by constant or stepwise-constant means as specified. For all cases, set $\\sigma^2=1$.\n\n- Case A (well-mixed, stationary): $m=4$, $n=2000$, $\\phi=0.2$, and $\\mu_{j,t} \\equiv 0$ for all $j$ and $t$.\n- Case B (sticky, highly autocorrelated): $m=4$, $n=2000$, $\\phi=0.98$, and $\\mu_{j,t} \\equiv 0$ for all $j$ and $t$.\n- Case C (intra-chain mean shift): $m=4$, $n=2000$, $\\phi=0.5$, and for each chain $j$, $\\mu_{j,t} = 0$ for $t \\le n/2$ and $\\mu_{j,t} = 1$ for $t > n/2$.\n- Case D (between-chain location discrepancy): $m=4$, $n=2000$, $\\phi=0.5$, with two chains having $\\mu_{j,t} \\equiv 0$ and two chains having $\\mu_{j,t} \\equiv 1$ for all $t$.\n\nAngle units and physical units are not applicable; no unit conversions are required.\n\nYour program must:\n- Implement the simulation for each case exactly as specified, using the same autoregressive recursion with $\\sigma^2=1$ and the fixed seed $12345$.\n- Compute the four diagnostics as derived above.\n- For each case, output an integer $1$ if all four inequalities are satisfied, and $0$ otherwise.\n\nFinal output format: Your program should produce a single line of output containing the results for the four cases as a comma-separated list enclosed in square brackets (e.g., \"[1,0,1,1]\") with no spaces.", "solution": "The problem is well-posed and scientifically grounded, providing a complete and consistent set of requirements for deriving, implementing, and applying a suite of MCMC convergence diagnostics. The task is to formalize these diagnostics from fundamental statistical definitions, apply them to simulated data under specified conditions, and determine whether the simulations meet a set of convergence criteria. The problem is valid.\n\nThe solution proceeds in two parts: first, the derivation of the four required diagnostic formulas, and second, their implementation in a program to analyze the specified test cases.\n\n### Derivation of Convergence Diagnostics\n\nLet there be $m$ chains, each of length $n$. The data for chain $j$ is the sequence $\\{x_{j,t}\\}_{t=1}^{n}$.\n\n#### 1. Split-Chain Variability Comparison ($\\hat{R}$)\nThis diagnostic, known as the potential scale reduction factor or Gelman-Rubin statistic, compares the variance within individual chains to an estimate of the total variance across all chains. A significant discrepancy indicates that the chains have not all converged to the same distribution. The derivation begins by splitting each of the $m$ chains of length $n$ into two halves, yielding $m_s=2m$ split chains, each of length $n_s = n/2$.\n\nLet $x_{j,t}$ now denote the $t$-th sample of the $j$-th *split* chain, where $j \\in \\{1, \\dots, m_s\\}$ and $t \\in \\{1, \\dots, n_s\\}$.\n\nThe sample mean of split chain $j$ is defined as:\n$$\n\\bar{x}_{.j} = \\frac{1}{n_s} \\sum_{t=1}^{n_s} x_{j,t}\n$$\n\nThe sample variance of split chain $j$ is:\n$$\ns_j^2 = \\frac{1}{n_s-1} \\sum_{t=1}^{n_s} (x_{j,t} - \\bar{x}_{.j})^2\n$$\n\nThe **within-sequence variance**, $W$, is the average of these individual sample variances. It estimates the mean of the variances within each sequence, corresponding to $E[\\text{Var}(\\psi|\\text{chain})]$ from the law of total variance.\n$$\nW = \\frac{1}{m_s} \\sum_{j=1}^{m_s} s_j^2\n$$\n\nThe **between-sequence variance**, $B$, is proportional to the sample variance of the split-chain means. It captures the variance of the means between sequences, related to $\\text{Var}[E(\\psi|\\text{chain})]$. Let $\\bar{x}_{..}$ be the grand mean of all samples across all split chains, $\\bar{x}_{..} = \\frac{1}{m_s} \\sum_{j=1}^{m_s} \\bar{x}_{.j}$.\n$$\nB = \\frac{n_s}{m_s-1} \\sum_{j=1}^{m_s} (\\bar{x}_{.j} - \\bar{x}_{..})^2\n$$\nThe factor $n_s$ scales the variance of the means to be comparable to the variance of the individual data points.\n\nAn overdispersed estimator for the marginal variance of the parameter, denoted $V^+$, is constructed as a weighted average of the within-sequence and between-sequence variances:\n$$\nV^+ = \\frac{n_s-1}{n_s} W + \\frac{1}{n_s} B\n$$\nThis formula combines the two sources of variation to provide a more robust estimate of the overall parameter variance than $W$ alone, especially when chains have not fully mixed.\n\nFinally, the **potential scale reduction factor**, $\\hat{R}$, is the ratio of the total variance estimate to the within-chain variance estimate:\n$$\n\\hat{R} = \\sqrt{\\frac{V^+}{W}} = \\sqrt{\\frac{n_s-1}{n_s} + \\frac{B}{n_s W}}\n$$\nIf all chains have converged to the same stationary distribution, $B$ will be of similar magnitude to $W$, and $\\hat{R}$ will be close to $1$. A value of $\\hat{R} > 1$ suggests that the chains have not yet fully explored the target distribution and that the variance could be reduced by running the chains longer.\n\n#### 2. Lag-1 Autocorrelation ($\\bar{\\rho}_1$)\nHigh autocorrelation within a chain indicates poor mixing, as adjacent samples are highly dependent and provide redundant information. We estimate the lag-$1$ autocorrelation for each original chain ($j \\in \\{1, \\dots, m\\}$ of length $n$).\n\nFor each chain $j$, the sample mean is $\\bar{x}_j = \\frac{1}{n} \\sum_{t=1}^{n} x_{j,t}$.\nThe sample autocovariance at lag $k$ is defined as:\n$$\n\\hat{\\gamma}_j(k) = \\frac{1}{n} \\sum_{t=1}^{n-k} (x_{j,t} - \\bar{x}_j)(x_{j,t+k} - \\bar{x}_j)\n$$\nThe sample variance is the autocovariance at lag $0$ (using a divisor of $n$ for consistency):\n$$\n\\hat{\\gamma}_j(0) = \\frac{1}{n} \\sum_{t=1}^{n} (x_{j,t} - \\bar{x}_j)^2\n$$\nThe sample autocorrelation at lag $k=1$ for chain $j$ is the ratio of the autocovariance at lag $1$ to the variance:\n$$\n\\hat{\\rho}_j(1) = \\frac{\\hat{\\gamma}_j(1)}{\\hat{\\gamma}_j(0)}\n$$\nThe final diagnostic is the average lag-$1$ autocorrelation across all $m$ chains:\n$$\n\\bar{\\rho}_1 = \\frac{1}{m} \\sum_{j=1}^{m} \\hat{\\rho}_j(1)\n$$\n\n#### 3. Standardized Drift Magnitude ($\\bar{D}_{\\text{std}}$)\nThis diagnostic detects non-stationarity by comparing the mean of the early part of a chain to the mean of the late part. A significant difference suggests the chain is still trending and has not reached its stationary distribution.\n\nFor each chain $j$ of length $n$, we define two windows of size $k = \\lfloor 0.4n \\rfloor$.\nThe mean of the first $k$ samples is:\n$$\n\\bar{x}_{j, \\text{early}} = \\frac{1}{k} \\sum_{t=1}^{k} x_{j,t}\n$$\nThe mean of the last $k$ samples is:\n$$\n\\bar{x}_{j, \\text{late}} = \\frac{1}{k} \\sum_{t=n-k+1}^{n} x_{j,t}\n$$\nThe drift for chain $j$ is the absolute difference between these means:\n$$\nD_j = |\\bar{x}_{j, \\text{early}} - \\bar{x}_{j, \\text{late}}|\n$$\nTo make this quantity comparable across different problems, it is standardized by the pooled standard deviation, $S$, computed over all $m \\times n$ samples. Let $\\bar{x}_{\\text{grand}}$ be the mean of all samples. The pooled sample variance is:\n$$\nS^2 = \\frac{1}{mn-1} \\sum_{j=1}^{m} \\sum_{t=1}^{n} (x_{j,t} - \\bar{x}_{\\text{grand}})^2\n$$\nThe pooled standard deviation is $S = \\sqrt{S^2}$. The standardized drift for chain $j$ is $D_{j, \\text{std}} = D_j / S$.\nThe final diagnostic is the average standardized drift over all chains:\n$$\n\\bar{D}_{\\text{std}} = \\frac{1}{m} \\sum_{j=1}^{m} D_{j, \\text{std}}\n$$\n\n#### 4. Effective Sample Size ($ESS_{total}$)\nThe effective sample size adjusts the nominal sample size ($m \\times n$) downward to account for autocorrelation. Under an AR($1$) approximation, the autocorrelation at lag $k$ is $\\rho(k) = (\\rho_1)^k$ for $k \\ge 0$, where $\\rho_1$ is the lag-$1$ autocorrelation.\n\nThe integrated autocorrelation time (IACT), denoted by $\\tau$, is given by the sum of all autocorrelations:\n$$\n\\tau = 1 + 2\\sum_{k=1}^{\\infty} \\rho(k)\n$$\nSubstituting the AR($1$) form for $\\rho(k)$ and using the formula for a geometric series for $|\\rho_1| < 1$:\n$$\n\\sum_{k=1}^{\\infty} (\\rho_1)^k = \\frac{\\rho_1}{1-\\rho_1}\n$$\nThis gives the IACT as a simple function of $\\rho_1$:\n$$\n\\tau = 1 + 2 \\frac{\\rho_1}{1-\\rho_1} = \\frac{1-\\rho_1+2\\rho_1}{1-\\rho_1} = \\frac{1+\\rho_1}{1-\\rho_1}\n$$\nThe effective sample size for a single chain of length $n$ is $ESS_{\\text{single}} = n/\\tau$. For $m$ independent chains, the total effective sample size is the sum of the individual effective sample sizes. Using the average lag-$1$ autocorrelation $\\bar{\\rho}_1$ (from part 2) as our estimate for $\\rho_1$:\n$$\nESS_{total} = m \\times \\frac{n}{\\tau} = m \\times n \\times \\frac{1-\\bar{\\rho}_1}{1+\\bar{\\rho}_1}\n$$\n---\nThe provided implementation will now compute these four diagnostics for each test case and apply the specified thresholding rules to determine convergence.", "answer": "```python\nimport numpy as np\n\ndef simulate_ar1_traces(m, n, phi, mu_func, sigma_sq, seed):\n    \"\"\"\n    Simulates m traces from an AR(1) process.\n    x_jt = mu_jt + phi*(x_j,t-1 - mu_jt) + eps_jt\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    traces = np.zeros((m, n))\n    mu = np.zeros((m, n))\n    for j in range(m):\n        for t in range(n):\n            mu[j, t] = mu_func(j, t, n)\n\n    # Initial values x_j,1 drawn from stationary dist N(mu_j,1, sigma^2)\n    traces[:, 0] = rng.normal(loc=mu[:, 0], scale=np.sqrt(sigma_sq), size=m)\n\n    # Noise standard deviation\n    noise_std = np.sqrt(sigma_sq * (1 - phi**2))\n\n    # Generate traces for t > 1\n    for t in range(1, n):\n        epsilon = rng.normal(loc=0, scale=noise_std, size=m)\n        mu_t = mu[:, t]\n        x_prev = traces[:, t - 1]\n        traces[:, t] = mu_t + phi * (x_prev - mu_t) + epsilon\n    \n    return traces\n\ndef calculate_r_hat(traces):\n    \"\"\"Computes the potential scale reduction factor R-hat.\"\"\"\n    m, n = traces.shape\n    if n % 2 != 0:\n        raise ValueError(\"Number of samples n must be even for splitting.\")\n    \n    n_s = n // 2\n    m_s = 2 * m\n    \n    # Split chains into two halves\n    split_traces = traces.reshape(m_s, n_s)\n    \n    # Calculate within-chain means and variances\n    chain_means = np.mean(split_traces, axis=1)\n    chain_vars = np.var(split_traces, axis=1, ddof=1)\n    \n    # Within-sequence variance W\n    W = np.mean(chain_vars)\n    if W == 0: return 1.0 # Avoid division by zero if variance is nil\n\n    # Between-sequence variance B\n    grand_mean = np.mean(chain_means)\n    B = (n_s / (m_s - 1)) * np.sum((chain_means - grand_mean)**2)\n    \n    # Overdispersed variance estimator V+\n    V_plus = ((n_s - 1) / n_s) * W + (1 / n_s) * B\n    \n    r_hat = np.sqrt(V_plus / W)\n    return r_hat\n\ndef calculate_avg_autocorr(traces):\n    \"\"\"Calculates the average lag-1 autocorrelation across chains.\"\"\"\n    m, n = traces.shape\n    autocorrs = []\n    \n    for j in range(m):\n        chain = traces[j, :]\n        mean = np.mean(chain)\n        centered_chain = chain - mean\n        \n        # Autocovariance at lag 1, using n as divisor\n        gamma_1 = np.dot(centered_chain[:-1], centered_chain[1:]) / n\n        \n        # Variance (autocovariance at lag 0)\n        gamma_0 = np.dot(centered_chain, centered_chain) / n\n        \n        if gamma_0 == 0:\n            rho_1 = 0.0\n        else:\n            rho_1 = gamma_1 / gamma_0\n        autocorrs.append(rho_1)\n        \n    return np.mean(autocorrs)\n\ndef calculate_drift(traces):\n    \"\"\"Calculates the average standardized drift magnitude.\"\"\"\n    m, n = traces.shape\n    k = int(0.4 * n)\n    \n    early_means = np.mean(traces[:, :k], axis=1)\n    late_means = np.mean(traces[:, -k:], axis=1)\n    \n    drifts = np.abs(early_means - late_means)\n    \n    # Pooled standard deviation across all samples\n    pooled_std = np.std(traces, ddof=1)\n    \n    if pooled_std == 0:\n        return 0.0 # No drift if there is no variation\n        \n    std_drifts = drifts / pooled_std\n    \n    return np.mean(std_drifts)\n\ndef calculate_ess(traces, avg_rho1):\n    \"\"\"Calculates the total effective sample size.\"\"\"\n    m, n = traces.shape\n    \n    # Ensure rho1 is in a valid range to prevent division by zero or negative ESS\n    if avg_rho1 >= 1.0:\n        return 0.0\n    \n    iact = (1.0 + avg_rho1) / (1.0 - avg_rho1)\n    \n    ess = m * n / iact\n    return ess\n\ndef solve():\n    # Define thresholds\n    tau_R = 1.05\n    tau_rho = 0.3\n    tau_D = 0.15\n    E_min = 2000\n\n    # Common parameters\n    m = 4\n    n = 2000\n    sigma_sq = 1.0\n    seed = 12345\n\n    # Test cases setup\n    test_cases = [\n        # Case A: Well-mixed, stationary\n        {'phi': 0.2, 'mu_func': lambda j, t, n: 0.0},\n        # Case B: Sticky, highly autocorrelated\n        {'phi': 0.98, 'mu_func': lambda j, t, n: 0.0},\n        # Case C: Intra-chain mean shift\n        {'phi': 0.5, 'mu_func': lambda j, t, n: 1.0 if t >= n / 2 else 0.0},\n        # Case D: Between-chain location discrepancy\n        {'phi': 0.5, 'mu_func': lambda j, t, n: 1.0 if j >= m / 2 else 0.0},\n    ]\n\n    results = []\n    for case in test_cases:\n        # Simulate data for the current case\n        traces = simulate_ar1_traces(m, n, case['phi'], case['mu_func'], sigma_sq, seed)\n        \n        # Calculate diagnostics\n        r_hat = calculate_r_hat(traces)\n        avg_rho1 = calculate_avg_autocorr(traces)\n        drift = calculate_drift(traces)\n        ess = calculate_ess(traces, avg_rho1)\n        \n        # Check convergence criteria\n        converged = (\n            r_hat <= tau_R and\n            avg_rho1 <= tau_rho and\n            drift <= tau_D and\n            ess >= E_min\n        )\n        \n        results.append(1 if converged else 0)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3289581"}, {"introduction": "Standard diagnostics based on raw parameter values can sometimes be misleading, especially for target distributions that are not approximately normal. This practice introduces a powerful and modern solution: rank-based diagnostics, which are robust to the shape of the posterior distribution. You will learn to implement rank-normalization and apply it to compute a rank-based $\\hat{R}$, seeing firsthand how this approach provides a more reliable assessment of convergence across a variety of challenging scenarios [@problem_id:3289568].", "problem": "You are given multiple independent Monte Carlo Markov Chain (MCMC) chains for a scalar parameter $ \\theta $ and tasked with assessing convergence using rank-normalized trace plots and a rank-based potential scale reduction factor. The fundamental base for this assessment must begin from the definition of exchangeable draws approximating a stationary target distribution, the notion of empirical ranks mapping to distribution-free quantiles, and the decomposition of variability into within-chain and between-chain components when comparing multiple chains.\n\nStarting from this base, implement the following algorithmic procedures in a complete, runnable program:\n\n1. Construct rank-normalized traces: Pool all draws of $ \\theta $ across chains, compute their empirical ranks, map each pooled rank to an approximate standard normal score by applying the inverse cumulative distribution function of the standard normal distribution to the rescaled ranks, and then reshape back to the original chain-by-iteration layout.\n\n2. Compute a rank-normalized split potential scale reduction factor (often referred to as a rank-$\\hat{R}$) by splitting each chain into two halves, computing the within-chain variance and the between-chain variance across the split chains, producing a variance estimate that blends these components, and finally forming the ratio that reflects potential scale reduction.\n\n3. Define a quantitative proxy for visual rank stability in the trace plots: Using the last half of iterations in the rank-normalized traces, compute the standard deviation of the per-chain means and normalize this by the pooled standard deviation across all chains and iterations in that last half. This ratio quantifies overlap of chain means relative to the typical spread in the traces.\n\n4. Declare that “small rank-$\\hat{R}$” holds if the rank-normalized split potential scale reduction factor is strictly less than $1.05$, and declare that “visual rank stability” holds if the last-half mean-overlap ratio is strictly less than $0.1$. For each test case below, report whether these two declarations agree, i.e., whether both are simultaneously true or both are simultaneously false.\n\nThe program must generate synthetic MCMC outputs for $ \\theta $ according to the test suite below. Random number generation must be made reproducible using the specified seeds. All angles (if any arise) must be treated in radians. No physical units are involved. The final program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n\nTest suite:\n\n- Case A (well-mixed): $ 4 $ chains, $ 2000 $ iterations per chain, seed $ 123 $. Each chain’s draws are independent and identically distributed from a normal distribution with mean $ 0 $ and standard deviation $ 1 $.\n\n- Case B (location-shift in one chain): $ 4 $ chains, $ 2000 $ iterations per chain, seed $ 456 $. Chains $ 1 $, $ 2 $, and $ 3 $ are drawn from a normal distribution with mean $ 0 $ and standard deviation $ 1 $. Chain $ 4 $ is drawn from a normal distribution with mean $ 1.5 $ and standard deviation $ 1 $.\n\n- Case C (multi-modality across chains): $ 4 $ chains, $ 2000 $ iterations per chain, seed $ 789 $. Chain $ 1 $ is drawn from a normal distribution with mean $ -2 $ and standard deviation $ 1 $. Chain $ 2 $ is drawn from a normal distribution with mean $ 2 $ and standard deviation $ 1 $. Chain $ 3 $ takes its first $ 1000 $ iterations from a normal distribution with mean $ -2 $ and standard deviation $ 1 $ and its last $ 1000 $ iterations from a normal distribution with mean $ 2 $ and standard deviation $ 1 $. Chain $ 4 $ alternates between means $ -2 $ and $ 2 $ every $ 25 $ iterations with standard deviation $ 1 $.\n\n- Case D (heavy-tailed target with short chains): $ 4 $ chains, $ 50 $ iterations per chain, seed $ 321 $. Each chain’s draws are independently from a standard Cauchy distribution with location $ 0 $ and scale $ 1 $.\n\nOutput specification:\n\n- For each case A–D, compute the rank-normalized split potential scale reduction factor and the last-half mean-overlap ratio as described. Let $ r_{\\text{thresh}} = 1.05 $ and $ v_{\\text{thresh}} = 0.1 $. The result for a case is the boolean value of the statement $\\big(\\text{rank-}\\hat{R}  r_{\\text{thresh}}\\big)$ equals $\\big(\\text{ratio}  v_{\\text{thresh}}\\big)$.\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as $ [\\text{Case A result},\\text{Case B result},\\text{Case C result},\\text{Case D result}] $.", "solution": "The problem requires the implementation and comparison of two MCMC convergence diagnostics for a scalar parameter $ \\theta $: the rank-normalized split potential scale reduction factor ($ \\hat{R} $) and a quantitative proxy for visual rank stability. The assessment is to be performed on four synthetic test cases representing different convergence scenarios.\n\nThe fundamental principle behind these diagnostics is to assess whether multiple MCMC chains, initiated from diverse starting points, have all converged to sampling from the same stationary target distribution. If they have, the variation between chains should be statistically indistinguishable from the variation within each chain. Using ranks rather than raw parameter values makes these diagnostics robust to the specific shape of the target distribution, particularly those with heavy tails or other challenging geometries.\n\nLet the MCMC output consist of $ M $ chains, each with $ N $ iterations. The draws are denoted by $ \\theta_{i,j} $ for chain $ i \\in \\{1, \\dots, M\\} $ and iteration $ j \\in \\{1, \\dots, N\\} $. The total number of draws is $ S = MN $.\n\n### 1. Constructing Rank-Normalized Traces\n\nThe first step is to transform the raw draws $ \\theta_{i,j} $ into a space where their distributional properties are standardized. This is achieved through rank normalization.\n\n1.  **Pooling and Ranking**: All $ S = MN $ draws are pooled into a single collection $\\{ \\theta_k \\}_{k=1}^S$. The empirical rank $ r_k $ is computed for each draw $ \\theta_k $, representing its position in the sorted collection (from $ 1 $ to $ S $).\n2.  **Rescaling**: Each rank $ r_k $ is rescaled to the interval $ (0, 1) $ to approximate its cumulative probability. A standard approach is to use a continuity correction, yielding $ p_k = \\frac{r_k - 0.5}{S} $.\n3.  **Normalization**: The rescaled ranks are transformed into standard normal scores by applying the inverse cumulative distribution function (CDF) of the standard normal distribution, $ \\Phi^{-1} $. The resulting rank-normalized draw is $ z_k = \\Phi^{-1}(p_k) $.\n4.  **Reshaping**: The flat vector of $ S $ normalized scores $\\{ z_k \\}_{k=1}^S$ is reshaped back into an $ M \\times N $ matrix, let's call it $ z_{i,j} $, preserving the original chain and iteration structure. All subsequent calculations are performed on these $ z_{i,j} $ values.\n\n### 2. Computing the Rank-Normalized Split Potential Scale Reduction Factor ($ \\hat{R} $)\n\nThe $ \\hat{R} $ statistic compares the variance between chains to the variance within chains. The \"split\" version enhances its ability to detect non-stationarity by treating the first and second halves of each chain as separate chains.\n\n1.  **Splitting Chains**: The $ M $ rank-normalized chains of length $ N $ are split into $ m = 2M $ chains of length $ n = N/2 $. Let these split chains be denoted by $ \\phi_{k,l} $ for $ k \\in \\{1, \\dots, m\\} $ and $ l \\in \\{1, \\dots, n\\} $.\n2.  **Within-Chain Variance ($ W $)**: For each split chain $ k $, we compute its sample variance:\n    $$ s_k^2 = \\frac{1}{n-1} \\sum_{l=1}^{n} (\\phi_{k,l} - \\bar{\\phi}_{k\\cdot})^2 $$\n    where $ \\bar{\\phi}_{k\\cdot} $ is the mean of chain $ k $. The average of these variances gives the within-chain variance:\n    $$ W = \\frac{1}{m} \\sum_{k=1}^{m} s_k^2 $$\n3.  **Between-Chain Variance ($ B $)**: We compute the variance of the means of the split chains:\n    $$ B = \\frac{n}{m-1} \\sum_{k=1}^{m} (\\bar{\\phi}_{k\\cdot} - \\bar{\\phi}_{\\cdot\\cdot})^2 $$\n    where $ \\bar{\\phi}_{\\cdot\\cdot} $ is the mean of all draws across all split chains. The factor $ n $ scales this variance to be comparable to $ W $.\n4.  **Pooled Variance ($ \\hat{V} $)**: An estimate of the marginal variance of the target distribution is formed by a weighted average of $ W $ and $ B $:\n    $$ \\hat{V} = \\frac{n-1}{n} W + \\frac{1}{n} B $$\n5.  **Scale Reduction Factor ($ \\hat{R} $)**: The final statistic is the ratio of the pooled variance estimate to the within-chain variance, which represents the potential reduction in scale if sampling were to continue:\n    $$ \\hat{R} = \\sqrt{\\frac{\\hat{V}}{W}} $$\n    If the chains have converged, $ W $ and $ \\hat{V} $ will be nearly equal, and $ \\hat{R} $ will be close to $ 1.0 $. The problem specifies a threshold $ r_{\\text{thresh}} = 1.05 $.\n\n### 3. Quantitative Proxy for Visual Rank Stability\n\nThis metric quantifies the visual impression one gets from inspecting trace plots. For well-mixed, converged chains, the traces should overlap, and their individual means should be close to each other relative to the overall spread.\n\n1.  **Isolate Last Half**: We consider only the second half of the rank-normalized traces, i.e., $ z_{i,j} $ for $ i \\in \\{1, \\dots, M\\} $ and $ j \\in \\{N/2+1, \\dots, N\\} $.\n2.  **Per-Chain Mean**: For each chain $ i $, compute its mean over this last half, $ \\bar{z}'_{i\\cdot} $.\n3.  **Standard Deviation of Means**: Compute the sample standard deviation of these $ M $ chain means, let's call this $ \\sigma_{\\text{means}} $. This measures the spread between the central tendencies of the chains.\n4.  **Pooled Standard Deviation**: Compute the sample standard deviation of all draws across all chains in the last half, let's call this $ \\sigma_{\\text{pooled}} $. This measures the typical spread of the draws within the traces.\n5.  **Ratio**: The final overlap ratio is:\n    $$ \\rho = \\frac{\\sigma_{\\text{means}}}{\\sigma_{\\text{pooled}}} $$\n    A small ratio indicates that the differences between chain means are small compared to the typical fluctuations within the chains, suggesting good mixing and overlap. The problem specifies a threshold $ v_{\\text{thresh}} = 0.1 $.\n\n### 4. Decision Logic\n\nFor each test case, we compute the rank-normalized split $ \\hat{R} $ and the last-half mean-overlap ratio $ \\rho $. We then evaluate two boolean conditions:\n- \"small rank-$ \\hat{R} $\" is true if $ \\hat{R}  1.05 $.\n- \"visual rank stability\" is true if $ \\rho  0.1 $.\n\nThe final result for the case is the boolean value of the logical test that these two conditions agree, i.e., whether they are both true or both false:\n$$ \\text{Result} = (\\hat{R}  1.05) == (\\rho  0.1) $$\nThis tests the consistency of the two diagnostic measures across different scenarios.\n- **Case A** represents an ideal, well-mixed scenario where both diagnostics should indicate convergence.\n- **Case B** introduces a location shift in one chain, a clear failure to converge that both diagnostics should detect.\n- **Case C** simulates complex non-stationarity and multimodality, another failure mode that diagnostics should identify.\n- **Case D** uses short chains from a heavy-tailed Cauchy distribution, testing the robustness of rank-based methods in a challenging, high-variance, low-information setting. In such a difficult case, both diagnostics are expected to flag non-convergence.\n\nThe goal is to verify if these two distinct but related measures provide a consistent signal about convergence status.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef generate_case_data(case_params):\n    \"\"\"Generates synthetic MCMC data based on case parameters.\"\"\"\n    M = case_params['M']\n    N = case_params['N']\n    seed = case_params['seed']\n    name = case_params['name']\n    \n    np.random.seed(seed)\n    \n    draws = np.zeros((M, N))\n    \n    if name == 'A':\n        # All chains are i.i.d. from a standard normal distribution.\n        draws = np.random.normal(loc=0.0, scale=1.0, size=(M, N))\n    elif name == 'B':\n        # 3 chains from N(0,1), 1 chain from N(1.5, 1).\n        draws[:3, :] = np.random.normal(loc=0.0, scale=1.0, size=(M - 1, N))\n        draws[3, :] = np.random.normal(loc=1.5, scale=1.0, size=N)\n    elif name == 'C':\n        # Complex multi-modality and non-stationarity.\n        N_half = N // 2\n        # Chain 1: N(-2, 1)\n        draws[0, :] = np.random.normal(loc=-2.0, scale=1.0, size=N)\n        # Chain 2: N(2, 1)\n        draws[1, :] = np.random.normal(loc=2.0, scale=1.0, size=N)\n        # Chain 3: Switches from N(-2, 1) to N(2, 1) halfway.\n        draws[2, :N_half] = np.random.normal(loc=-2.0, scale=1.0, size=N_half)\n        draws[2, N_half:] = np.random.normal(loc=2.0, scale=1.0, size=N_half)\n        # Chain 4: Alternates between modes every 25 iterations.\n        alt_size = 25\n        num_blocks = N // alt_size\n        for i in range(num_blocks):\n            start_idx = i * alt_size\n            end_idx = start_idx + alt_size\n            mean = -2.0 if i % 2 == 0 else 2.0\n            draws[3, start_idx:end_idx] = np.random.normal(loc=mean, scale=1.0, size=alt_size)\n    elif name == 'D':\n        # Heavy-tailed Cauchy distribution.\n        draws = np.random.standard_cauchy(size=(M, N))\n        \n    return draws\n\ndef compute_diagnostics(draws):\n    \"\"\"\n    Computes rank-normalized split R-hat and the last-half mean-overlap ratio.\n    \"\"\"\n    M, N = draws.shape\n    if N  2:\n        # Not enough data to split chains or calculate variance\n        return np.inf, np.inf\n\n    # 1. Rank-normalize the traces\n    S = M * N\n    flat_draws = draws.flatten()\n    # Compute ranks from 1 to S\n    ranks = flat_draws.argsort().argsort() + 1\n    # Rescale ranks to (0, 1)\n    rescaled_ranks = (ranks - 0.5) / S\n    # Apply inverse normal CDF (probit function)\n    z_scores_flat = norm.ppf(rescaled_ranks)\n    z_traces = z_scores_flat.reshape(M, N)\n\n    # 2. Compute rank-normalized split R-hat\n    m = 2 * M\n    n = N // 2\n    \n    # Reshape into split chains\n    split_chains = z_traces[:, :2*n].reshape(m, n)\n\n    # Calculate within-chain and between-chain variance\n    chain_means = np.mean(split_chains, axis=1)\n    # ddof=1 for sample variance\n    W = np.mean(np.var(split_chains, axis=1, ddof=1)) \n    \n    if W == 0:\n        # If all chains are constant and identical, W can be 0.\n        # This implies perfect convergence in a trivial case.\n        R_hat = 1.0\n    else:\n        # ddof=1 for sample variance of the means\n        B = n * np.var(chain_means, ddof=1)\n        V_hat = ((n - 1) / n) * W + (1 / n) * B\n        R_hat = np.sqrt(V_hat / W)\n\n    # 3. Compute last-half mean-overlap ratio\n    last_half_traces = z_traces[:, N//2:]\n    \n    # Per-chain means for the last half\n    last_half_means = np.mean(last_half_traces, axis=1)\n    \n    sigma_means = np.std(last_half_means, ddof=1) if M  1 else 0.0\n    \n    # Pooled standard deviation for the last half\n    # ddof=1 for sample standard deviation\n    sigma_pooled = np.std(last_half_traces, ddof=1)\n    \n    if sigma_pooled == 0:\n        # Chains are constant in the last half.\n        # If means are also identical, ratio is 0. If not, it's undefined.\n        # We can treat this as 0 if sigma_means is also 0, else a large number.\n        ratio = 0.0 if sigma_means == 0.0 else np.inf\n    else:\n        ratio = sigma_means / sigma_pooled\n\n    return R_hat, ratio\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        {'name': 'A', 'M': 4, 'N': 2000, 'seed': 123},\n        {'name': 'B', 'M': 4, 'N': 2000, 'seed': 456},\n        {'name': 'C', 'M': 4, 'N': 2000, 'seed': 789},\n        {'name': 'D', 'M': 4, 'N': 50, 'seed': 321},\n    ]\n\n    r_thresh = 1.05\n    v_thresh = 0.1\n\n    results = []\n    for case in test_cases:\n        draws = generate_case_data(case)\n        rank_R_hat, mean_overlap_ratio = compute_diagnostics(draws)\n        \n        # Check if the declarations agree\n        r_hat_ok = rank_R_hat  r_thresh\n        ratio_ok = mean_overlap_ratio  v_thresh\n        \n        agreement = (r_hat_ok == ratio_ok)\n        results.append(agreement)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3289568"}, {"introduction": "One of the most critical challenges in MCMC is distinguishing true convergence from a situation where chains appear stable but are trapped in different modes of a multimodal distribution. This exercise highlights this crucial distinction by contrasting a global, rank-based diagnostic with a local, within-chain stationarity test. Through this hands-on comparison, you will learn why rank-based methods provide stronger evidence of convergence and develop a critical eye for diagnosing complex, multimodal problems [@problem_id:3289524].", "problem": "You are asked to design and implement a complete program that quantitatively assesses Markov chain Monte Carlo (MCMC) convergence by contrasting two diagnostics: (i) a rank-based, trace-like visualization converted into a formal test, and (ii) a raw-parameter, per-chain stationarity test. The goal is to evaluate whether convergence in ranks provides stronger evidence than raw parameter traces in settings that include multimodal target distributions.\n\nFundamental base. Use the following universally accepted foundations:\n\n- A Markov chain $\\{X_t\\}_{t \\ge 0}$ with transition kernel that preserves a target probability density $\\pi(x)$ has $\\pi(x)$ as its stationary distribution. Under Metropolis–Hastings with a symmetric random-walk proposal $q(y \\mid x) = \\mathcal{N}(y; x, \\sigma_{\\text{prop}}^2)$, the acceptance probability is\n$$\n\\alpha(x,y) = \\min\\left\\{1, \\frac{\\pi(y)}{\\pi(x)}\\right\\}.\n$$\n- When multiple independent chains target $\\pi(x)$ and have converged, their draws are exchangeable across chains and iterations, and pooled ranks of draws yield Uniform distribution after rank-normalization. For a pooled set of $K$ chains and $N$ iterations post-burn-in, the rank-normalized values $U$ formed by mapping pooled ranks to $(0,1)$ should be independent and identically distributed as $\\text{Uniform}(0,1)$ when convergence is achieved.\n- The Kolmogorov–Smirnov (KS) statistic $D = \\sup_{u \\in [0,1]} |F_n(u) - u|$ comparing the empirical cumulative distribution function $F_n(u)$ of a sample to the cumulative distribution function of $\\text{Uniform}(0,1)$ can be used to test uniformity, producing a $p$-value. Fisher’s method combines independent $p$-values $p_1,\\dots,p_K$ via the statistic $-2\\sum_{k=1}^K \\log p_k$, which under the null follows a chi-square distribution with $2K$ degrees of freedom, providing a combined $p$-value.\n- A raw-parameter stationarity check can be approximated with a Geweke-style test: split the chain into an early fraction $A$ and a late fraction $B$. Under independent sampling, the statistic\n$$\nZ = \\frac{\\bar{X}_A - \\bar{X}_B}{\\sqrt{\\hat{\\sigma}_A^2/n_A + \\hat{\\sigma}_B^2/n_B}}\n$$\nis approximately standard normal when the chain is stationary; here $\\bar{X}_A$ and $\\bar{X}_B$ are sample means over $A$ and $B$, with sample variances $\\hat{\\sigma}_A^2$ and $\\hat{\\sigma}_B^2$ and segment sizes $n_A$ and $n_B$. A two-sided $p$-value is $p = 2(1 - \\Phi(|Z|))$, where $\\Phi$ is the standard normal cumulative distribution function. Combining $K$ per-chain $p$-values with Fisher’s method yields an overall test for stationarity across chains.\n\nProgram requirements:\n\n1. Implement $K$ independent Metropolis–Hastings random-walk chains for each test case. Use a burn-in of $B$ iterations and analyze the post-burn-in draws. For reproducibility, fix the random seed.\n2. Rank-normalized trace-like diagnostic:\n   - Pool the $K$ chains’ post-burn-in draws (size $K \\times (N-B)$), compute ranks of each draw among all pooled draws, and convert ranks $r \\in \\{1, \\dots, K(N-B)\\}$ to $U \\in (0,1)$ via a continuous mapping such as $U = \\frac{r - 0.5}{K(N-B)}$.\n   - For each chain separately, perform the Kolmogorov–Smirnov test of $U$ against $\\text{Uniform}(0,1)$ to obtain $p$-values $p_1,\\dots,p_K$.\n   - Combine the $K$ $p$-values using Fisher’s method to obtain a single $p_{\\text{rank}}$.\n3. Raw-parameter stationarity diagnostic:\n   - For each chain, compute the Geweke-style $Z$ statistic using an early fraction of $A = 0.1$ and a late fraction of $B = 0.5$ of the post-burn-in samples, with the naive independent-sample variance formula above.\n   - Convert each $Z$ to a two-sided $p$-value $p_k = 2(1-\\Phi(|Z_k|))$, and combine the $K$ values by Fisher’s method to obtain $p_{\\text{raw}}$.\n4. Decision rule:\n   - Use significance level $\\alpha = 0.05$.\n   - Define a boolean outcome for each test case: return $\\text{True}$ if $p_{\\text{rank}}  \\alpha$ and $p_{\\text{raw}} \\ge \\alpha$, and $\\text{False}$ otherwise. Under this rule, the rank-based diagnostic is deemed to provide stronger evidence of non-convergence than the raw trace-based test.\n\nTest suite design. Implement three test cases that collectively exercise unimodal and multimodal scenarios, including stuck and partially mixing multimodal chains.\n\n- Case $1$ (unimodal, well-mixing): Target $\\pi(x) = \\mathcal{N}(x; 0, 1)$, with $K = 4$ chains, $N = 4000$ total iterations, burn-in $B = 1000$, proposal standard deviation $\\sigma_{\\text{prop}} = 1.0$, and initial states $[-10, -3, 3, 10]$.\n- Case $2$ (multimodal, stuck in modes): Target $\\pi(x) = 0.5\\,\\mathcal{N}(x; -d, \\sigma_1^2) + 0.5\\,\\mathcal{N}(x; d, \\sigma_2^2)$ with $d = 6$, $\\sigma_1 = 0.5$, $\\sigma_2 = 0.5$, $K = 4$ chains, $N = 4000$, $B = 1000$, proposal $\\sigma_{\\text{prop}} = 0.3$, initial states $[-d, -d, d, d]$. These chains are expected to remain in their initial modes due to small proposals relative to separation.\n- Case $3$ (multimodal, partial mixing): Same mixture target as Case $2$, with $K = 4$, $N = 6000$, $B = 1000$, proposal $\\sigma_{\\text{prop}} = 3.5$, initial states $[-d, -d, d, d]$. Large proposals permit occasional mode-switching, partially alleviating cross-chain rank imbalance.\n\nRequired final output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For the three test cases above, print a single line in the format $[b_1,b_2,b_3]$, where each $b_i$ is a boolean computed by the decision rule described above.\n\nUnits and angles. This problem is purely mathematical; no physical units or angles apply.\n\nAnswer types. The program must output booleans. No other types are permitted in the final line.\n\nExecution constraints. The program must be self-contained, accept no inputs, and adhere to the specified runtime environment.", "solution": "The problem requires the design and implementation of a program to quantitatively compare two different Markov Chain Monte Carlo (MCMC) convergence diagnostics. The first is a rank-based diagnostic that tests for the exchangeability of draws across multiple chains. The second is a raw-parameter stationarity test applied to each chain individually. The comparison is performed across three test cases designed to represent well-mixed, non-mixing (stuck), and partially-mixing chains.\n\nThe core of the simulation is a Metropolis-Hastings algorithm. For $K$ independent chains targeting a probability density $\\pi(x)$, we generate sequences of states $\\{X_t\\}_{t \\ge 0}$. Given the current state $x_t$, a new state $y$ is proposed from a symmetric random-walk proposal distribution, $q(y \\mid x_t) = \\mathcal{N}(y; x_t, \\sigma_{\\text{prop}}^2)$, where $\\mathcal{N}$ denotes a normal distribution. The proposed state $y$ is accepted with probability\n$$\n\\alpha(x_t, y) = \\min\\left\\{1, \\frac{\\pi(y)}{\\pi(x_t)}\\right\\}.\n$$\nIf the proposal is accepted, $X_{t+1} = y$; otherwise, $X_{t+1} = x_t$. For numerical stability, calculations are performed using log-probabilities: the acceptance condition becomes $\\log(u)  \\log(\\pi(y)) - \\log(\\pi(x_t))$, where $u \\sim \\text{Uniform}(0,1)$. After running $N$ iterations for each of the $K$ chains, the initial $B$ iterations are discarded as burn-in.\n\nThe analysis is performed on the post-burn-in samples. Let the total number of post-burn-in samples per chain be $M = N-B$.\n\nThe two target distributions are:\n1.  A standard normal distribution, with log-probability density (up to a constant) given by $\\log \\pi(x) = -0.5 x^2$.\n2.  A bimodal mixture of two Gaussians, $\\pi(x) = 0.5\\,\\mathcal{N}(x; -d, \\sigma^2) + 0.5\\,\\mathcal{N}(x; d, \\sigma^2)$. The log-probability is computed using the log-sum-exp trick for numerical stability:\n    $$\n    \\log \\pi(x) = \\log(0.5) + \\text{logsumexp}\\left(\\log\\mathcal{N}(x; -d, \\sigma^2), \\log\\mathcal{N}(x; d, \\sigma^2)\\right),\n    $$\n    where $\\log\\mathcal{N}(x; \\mu, \\sigma^2) = -0.5 \\log(2\\pi\\sigma^2) - \\frac{(x-\\mu)^2}{2\\sigma^2}$.\n\nThe first diagnostic is a rank-based test. If all $K$ chains have converged to the stationary distribution $\\pi(x)$, their combined draws should be exchangeable.\n1.  The $K \\times M$ post-burn-in samples from all chains are pooled into a single dataset of size $KM$.\n2.  The rank $r$ of each sample within this pooled dataset is computed, where $r \\in \\{1, 2, \\dots, KM\\}$.\n3.  These integer ranks are converted into continuous, rank-normalized values $U$ on the interval $(0,1)$ using the formula $U = \\frac{r - 0.5}{KM}$.\n4.  If the chains are converged and mixing, the set of $U$ values corresponding to the samples from any single chain should be distributed as $\\text{Uniform}(0,1)$. We test this hypothesis for each of the $K$ chains using the two-sided Kolmogorov-Smirnov (KS) test, which yields $K$ p-values, $\\{p_1, \\dots, p_K\\}$.\n5.  These p-values are combined using Fisher's method. The test statistic $C = -2\\sum_{k=1}^K \\log p_k$ is calculated. Under the null hypothesis that all chains' rank-normalized values are uniform, $C$ follows a chi-square distribution with $2K$ degrees of freedom. The combined p-value, $p_{\\text{rank}}$, is the survival function of this distribution evaluated at $C$. A small $p_{\\text{rank}}$ indicates that at least one chain's rank distribution deviates significantly from uniform, suggesting a lack of convergence.\n\nThe second diagnostic is a raw-parameter Geweke-style stationarity test, applied independently to each chain.\n1.  For each chain's post-burn-in trace of length $M$, we define an early segment $A$ consisting of the first $n_A = \\lfloor 0.1 M \\rfloor$ samples and a late segment $B$ consisting of the last $n_B = \\lfloor 0.5 M \\rfloor$ samples.\n2.  The sample means ($\\bar{X}_A, \\bar{X}_B$) and sample variances ($\\hat{\\sigma}_A^2, \\hat{\\sigma}_B^2$) are computed for each segment.\n3.  The Z-statistic is calculated as $Z = \\frac{\\bar{X}_A - \\bar{X}_B}{\\sqrt{\\hat{\\sigma}_A^2/n_A + \\hat{\\sigma}_B^2/n_B}}$. Under the null hypothesis that the chain is stationary, $Z$ is approximately distributed as a standard normal $\\mathcal{N}(0,1)$.\n4.  A two-sided p-value is computed for each chain as $p_k = 2(1 - \\Phi(|Z_k|))$, where $\\Phi$ is the cumulative distribution function of the standard normal distribution.\n5.  As with the rank diagnostic, these $K$ p-values are combined using Fisher's method to produce a single overall p-value, $p_{\\text{raw}}$. A small $p_{\\text{raw}}$ suggests that at least one chain exhibits non-stationarity.\n\nThe final decision rule compares the outcomes of these two tests at a significance level of $\\alpha = 0.05$. The program returns $\\text{True}$ for a test case if the rank-based test indicates non-convergence ($p_{\\text{rank}}  \\alpha$) while the raw-parameter test fails to do so ($p_{\\text{raw}} \\ge \\alpha$). This specific outcome highlights scenarios where the between-chain rank diagnostic is more sensitive to a lack of overall convergence than the within-chain stationarity test. Otherwise, the program returns $\\text{False}$. The procedure is evaluated on three distinct test cases to observe the behavior of the diagnostics under different mixing conditions.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Main function to run the MCMC simulations and diagnostics for all test cases.\n    \"\"\"\n    # Set a fixed random seed for reproducibility.\n    np.random.seed(123)\n    \n    # Define the three test cases as specified in the problem statement.\n    test_cases = [\n        {\n            # Case 1: Unimodal target, chains are expected to mix well.\n            'target_type': 'normal',\n            'K': 4, \n            'N': 4000, \n            'B': 1000,\n            'sigma_prop': 1.0,\n            'initial_states': np.array([-10.0, -3.0, 3.0, 10.0]),\n            'target_params': {}\n        },\n        {\n            # Case 2: Multimodal target, small proposal width, chains get stuck in modes.\n            'target_type': 'mixture',\n            'K': 4, \n            'N': 4000, \n            'B': 1000,\n            'sigma_prop': 0.3,\n            'initial_states': np.array([-6.0, -6.0, 6.0, 6.0]),\n            'target_params': {'d': 6.0, 'sigma': 0.5}\n        },\n        {\n            # Case 3: Multimodal target, larger proposal width allows for partial mixing.\n            'target_type': 'mixture',\n            'K': 4, \n            'N': 6000, \n            'B': 1000,\n            'sigma_prop': 3.5,\n            'initial_states': np.array([-6.0, -6.0, 6.0, 6.0]),\n            'target_params': {'d': 6.0, 'sigma': 0.5}\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        # Run the simulation and diagnostics for one case.\n        result = run_simulation_and_diagnostics(params)\n        results.append(result)\n\n    # Format the final output as a comma-separated list of booleans.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef log_prob_normal(x):\n    \"\"\"Log-probability for a standard normal distribution (constants omitted).\"\"\"\n    return -0.5 * x**2\n\ndef log_prob_mixture(x, d, sigma):\n    \"\"\"Log-probability for a bimodal Gaussian mixture.\"\"\"\n    # Log-PDFs of the two components\n    log_pdf1 = stats.norm.logpdf(x, loc=-d, scale=sigma)\n    log_pdf2 = stats.norm.logpdf(x, loc=d, scale=sigma)\n    \n    # Log-sum-exp for numerical stability: log(0.5*exp(lp1) + 0.5*exp(lp2))\n    # = log(0.5) + log(exp(lp1) + exp(lp2))\n    # = log(0.5) + lp1 + log(1 + exp(lp2 - lp1)) if lp1 is max\n    max_log = np.maximum(log_pdf1, log_pdf2)\n    min_log = np.minimum(log_pdf1, log_pdf2)\n    return np.log(0.5) + max_log + np.log(1 + np.exp(min_log - max_log))\n\ndef run_simulation_and_diagnostics(params):\n    \"\"\"\n    Executes the entire MCMC process for a single test case.\n    \"\"\"\n    K, N, B = params['K'], params['N'], params['B']\n    sigma_prop = params['sigma_prop']\n    initial_states = params['initial_states']\n\n    # Select the target log-probability function\n    if params['target_type'] == 'normal':\n        log_pi = log_prob_normal\n    else:\n        d, sigma = params['target_params']['d'], params['target_params']['sigma']\n        log_pi = lambda x: log_prob_mixture(x, d, sigma)\n\n    # Run K Metropolis-Hastings chains\n    traces = np.zeros((K, N))\n    traces[:, 0] = initial_states\n    \n    current_log_pi = log_pi(traces[:, 0])\n\n    for t in range(N - 1):\n        # Propose new states for all chains\n        proposals = np.random.normal(traces[:, t], sigma_prop)\n        \n        # Calculate log-probabilities of proposed states\n        proposal_log_pi = log_pi(proposals)\n        \n        # Calculate acceptance log-probabilities\n        log_alpha = proposal_log_pi - current_log_pi\n        \n        # Determine which proposals are accepted\n        accept_mask = np.log(np.random.rand(K))  log_alpha\n        \n        # Update traces and current log-probabilities\n        traces[accept_mask, t + 1] = proposals[accept_mask]\n        traces[~accept_mask, t + 1] = traces[~accept_mask, t]\n        current_log_pi[accept_mask] = proposal_log_pi[accept_mask]\n\n    # Discard burn-in samples\n    post_burn_traces = traces[:, B:]\n\n    # --- 1. Rank-based diagnostic ---\n    p_values_rank = []\n    flat_traces = post_burn_traces.flatten()\n    total_samples = len(flat_traces)\n    # Compute ranks on pooled data. stats.rankdata starts ranks from 1.\n    ranks = stats.rankdata(flat_traces)\n    u_values = (ranks - 0.5) / total_samples\n    u_values_by_chain = u_values.reshape(post_burn_traces.shape)\n    \n    for k in range(K):\n        # Test if the U-values for each chain are uniformly distributed\n        _, p_val = stats.kstest(u_values_by_chain[k, :], 'uniform')\n        p_values_rank.append(p_val)\n\n    # Combine p-values using Fisher's method\n    # Clip p-values to avoid log(0)\n    log_p_ranks = np.log(np.maximum(1e-300, np.array(p_values_rank)))\n    fisher_stat_rank = -2 * np.sum(log_p_ranks)\n    p_rank = stats.chi2.sf(fisher_stat_rank, df=2 * K)\n\n    # --- 2. Raw-parameter (Geweke-style) diagnostic ---\n    p_values_raw = []\n    M = N - B\n    n_A = int(0.1 * M)\n    n_B = int(0.5 * M)\n\n    for k in range(K):\n        chain_trace = post_burn_traces[k, :]\n        trace_A = chain_trace[:n_A]\n        trace_B = chain_trace[-n_B:]\n        \n        mean_A, var_A = np.mean(trace_A), np.var(trace_A, ddof=1)\n        mean_B, var_B = np.mean(trace_B), np.var(trace_B, ddof=1)\n        \n        denominator = np.sqrt(var_A / n_A + var_B / n_B)\n        \n        if denominator == 0:\n            # If segments have zero variance (stuck chain)\n            z_stat = 0.0 if mean_A == mean_B else np.inf\n        else:\n            z_stat = (mean_A - mean_B) / denominator\n        \n        # Two-sided p-value from standard normal\n        p_val = 2 * stats.norm.sf(np.abs(z_stat))\n        p_values_raw.append(p_val)\n        \n    # Combine p-values using Fisher's method\n    log_p_raw = np.log(np.maximum(1e-300, np.array(p_values_raw)))\n    fisher_stat_raw = -2 * np.sum(log_p_raw)\n    p_raw = stats.chi2.sf(fisher_stat_raw, df=2 * K)\n\n    # --- 3. Decision rule ---\n    alpha = 0.05\n    return (p_rank  alpha) and (p_raw = alpha)\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3289524"}]}