{"hands_on_practices": [{"introduction": "The Rao-Blackwell theorem is more than a theoretical curiosity; it is a constructive tool for discovering better estimators. This first practice provides a compelling theoretical demonstration of this principle in the context of a sequential experiment [@problem_id:1922452]. By starting with a very simple, unbiased estimator and conditioning it on the experiment's sufficient statistic, we can derive a new estimator that is not only superior but also elegant, showcasing the theorem's power to reduce variance and reveal more efficient ways to extract information from data.", "problem": "A sequential clinical trial is designed to test a new drug. Patients are treated one by one, and the outcome for each is either a \"success\" or a \"failure\". The probability of success, $p$, is assumed to be constant for all patients, with $0 < p < 1$. The trial continues until exactly $k$ successes have been recorded. Let $N$ be the total number of patients treated, which is a random variable.\n\nAn initial, simple unbiased estimator for the success probability $p$ is proposed: $\\hat{p}_{crude} = X_1$, where $X_1=1$ if the first patient has a successful outcome, and $X_1=0$ otherwise.\n\nAccording to statistical theory, this estimator can be improved using the Rao-Blackwell theorem. The process involves conditioning $\\hat{p}_{crude}$ on a sufficient statistic for the parameter $p$. For this experimental design, the total number of trials, $N$, is a sufficient statistic. The resulting Rao-Blackwellized estimator is $\\hat{p}_{RB} = E[\\hat{p}_{crude} | N]$.\n\nYour task is to analyze the improvement in estimation quality for the specific case where the trial is set to stop after $k=2$ successes. Calculate the variance reduction factor, defined as the ratio $\\mathcal{R} = \\frac{\\text{Var}(\\hat{p}_{crude})}{\\text{Var}(\\hat{p}_{RB})}$. Express your final answer as an analytical function of $p$.", "solution": "Let $X_{i} \\sim \\text{Bernoulli}(p)$ independently with $0<p<1$. The stopping rule is to stop at the time $N$ when $k=2$ successes have been observed. The crude estimator is $\\hat{p}_{\\text{crude}}=X_{1}$, with\n$$\n\\mathbb{E}[X_{1}]=p,\\qquad \\text{Var}(X_{1})=p(1-p).\n$$\n\nBy the Rao-Blackwell theorem, the improved estimator is $\\hat{p}_{\\text{RB}}=\\mathbb{E}[X_{1}\\mid N]$. For $k=2$, conditioning on $N=n$ implies that among the first $n-1$ trials there is exactly one success and $X_{n}=1$. The conditional distribution over sequences with $N=n$ is uniform because each such sequence has probability $p^{2}(1-p)^{n-2}$. Hence, among the first $n-1$ positions, exactly one is a success, uniformly located; therefore\n$$\n\\mathbb{P}(X_{1}=1\\mid N=n)=\\frac{1}{n-1},\\qquad \\text{so}\\qquad \\hat{p}_{\\text{RB}}=\\frac{1}{N-1}.\n$$\n\nWe next compute $\\text{Var}(\\hat{p}_{\\text{RB}})$. For $k=2$, $N$ has the negative binomial distribution\n$$\n\\mathbb{P}(N=n)=(n-1)p^{2}(1-p)^{n-2},\\quad n=2,3,\\ldots\n$$\nThus\n$$\n\\mathbb{E}\\!\\left[\\frac{1}{N-1}\\right]=\\sum_{n=2}^{\\infty}\\frac{1}{n-1}(n-1)p^{2}(1-p)^{n-2}\n=p^{2}\\sum_{m=0}^{\\infty}(1-p)^{m}=p,\n$$\nwhich confirms unbiasedness. Also,\n$$\n\\mathbb{E}\\!\\left[\\frac{1}{(N-1)^{2}}\\right]\n=\\sum_{n=2}^{\\infty}\\frac{1}{(n-1)^{2}}(n-1)p^{2}(1-p)^{n-2}\n=p^{2}\\sum_{m=0}^{\\infty}\\frac{(1-p)^{m}}{m+1}.\n$$\nUsing the series identity $\\sum_{m=0}^{\\infty}\\frac{x^{m}}{m+1}=\\frac{-\\ln(1-x)}{x}$ for $|x|<1$ with $x=1-p$, we get\n$$\n\\mathbb{E}\\!\\left[\\frac{1}{(N-1)^{2}}\\right]\n=p^{2}\\cdot \\frac{-\\ln(1-(1-p))}{1-p}\n=\\frac{p^{2}(-\\ln p)}{1-p}.\n$$\nTherefore,\n$$\n\\text{Var}\\!\\left(\\hat{p}_{\\text{RB}}\\right)\n=\\mathbb{E}\\!\\left[\\frac{1}{(N-1)^{2}}\\right]-\\left(\\mathbb{E}\\!\\left[\\frac{1}{N-1}\\right]\\right)^{2}\n=\\frac{p^{2}(-\\ln p)}{1-p}-p^{2}\n=p^{2}\\left(\\frac{-\\ln p}{1-p}-1\\right).\n$$\nThe variance reduction factor is\n$$\n\\mathcal{R}=\\frac{\\text{Var}(\\hat{p}_{\\text{crude}})}{\\text{Var}(\\hat{p}_{\\text{RB}})}\n=\\frac{p(1-p)}{p^{2}\\left(\\frac{-\\ln p}{1-p}-1\\right)}\n=\\frac{(1-p)^{2}}{p\\left(-\\ln p-(1-p)\\right)}\n=\\frac{(1-p)^{2}}{p\\left(p-1-\\ln p\\right)}.\n$$\nThis is an analytical function of $p$, valid for $0<p<1$.", "answer": "$$\\boxed{\\frac{(1-p)^{2}}{p\\left(p-1-\\ln p\\right)}}$$", "id": "1922452"}, {"introduction": "Moving from pure theory to computational practice, we now explore how Rao-Blackwellization serves as a powerful variance reduction technique in Monte Carlo simulation. This exercise focuses on a common task in Bayesian analysis: estimating a posterior predictive probability [@problem_id:3315544]. You will compare a straightforward sampling approach with a more sophisticated method that first analytically integrates out a model parameter, directly illustrating how reducing the number of random components in a simulation yields more precise estimates for the same computational effort.", "problem": "Consider the hierarchical model defined by a likelihood and a prior. Let $x_1,\\ldots,x_n \\mid \\theta \\stackrel{\\text{ind}}{\\sim} \\operatorname{Poisson}(\\theta)$ and $\\theta \\sim \\operatorname{Gamma}(\\alpha,\\beta)$ where $\\operatorname{Gamma}(\\alpha,\\beta)$ denotes the gamma distribution with shape parameter $\\alpha$ and rate parameter $\\beta$ (so its probability density function is proportional to $\\theta^{\\alpha-1}\\exp(-\\beta \\theta)$). Define the joint distribution $f(x,\\theta)=f(x\\mid \\theta)\\,\\pi(\\theta)$, and the marginal (also called the evidence or marginal likelihood) $m(x)=\\int f(x\\mid \\theta)\\,\\pi(\\theta)\\,\\mathrm{d}\\theta$. After observing data $x=(x_1,\\ldots,x_n)$, the posterior distribution for $\\theta$ is $\\pi(\\theta\\mid x)\\propto f(x\\mid \\theta)\\,\\pi(\\theta)$ and the posterior predictive distribution for a new count $Y$ is $m(y\\mid x)=\\int f(y\\mid \\theta)\\,\\pi(\\theta\\mid x)\\,\\mathrm{d}\\theta$.\n\nTasks:\n- Starting from the core definitions of joint, marginal, and conditional distributions, derive the posterior $\\pi(\\theta\\mid x)$ and the closed-form expression for the posterior predictive mass function $m(y\\mid x)$ for the conjugate pair above. Your derivation must begin from $f(x\\mid \\theta)=\\prod_{i=1}^n \\frac{\\exp(-\\theta)\\,\\theta^{x_i}}{x_i!}$ and $\\pi(\\theta)\\propto \\theta^{\\alpha-1}\\exp(-\\beta \\theta)$ and proceed via first principles to the integral defining $m(y\\mid x)$; do not skip steps by invoking a pre-remembered final expression.\n- Construct and compare two unbiased Monte Carlo (MC) estimators of $m(y\\mid x)$:\n  1. A numerical integration estimator that samples $\\theta_1,\\ldots,\\theta_N \\stackrel{\\text{iid}}{\\sim} \\pi(\\theta\\mid x)$ and computes $\\widehat{m}_{\\text{num}}(y\\mid x)=\\frac{1}{N}\\sum_{j=1}^N f(y\\mid \\theta_j)$.\n  2. An estimator that first integrates out $\\theta$ analytically to obtain the closed-form posterior predictive distribution for $Y\\mid x$, then samples $Y_1,\\ldots,Y_N \\stackrel{\\text{iid}}{\\sim} m(\\cdot\\mid x)$ and computes $\\widehat{m}_{\\text{an}}(y\\mid x)=\\frac{1}{N}\\sum_{j=1}^N \\mathbb{I}\\{Y_j=y\\}$.\nExplain conceptually, in terms of conditional expectation and the Raoâ€“Blackwell theorem, why these two estimators differ in variance, and connect this difference to the structure of the hierarchy $Y\\mid \\theta$ and $\\theta\\mid x$.\n\nUse the following test suite of parameter values to evaluate and compare these estimators. In all cases, fix the pseudorandom generator seed to $12345$ so that the outputs are deterministic.\n\n- Test case $1$: $\\alpha=3$, $\\beta=1.2$, $x=(3,1,0,2)$, target $y=2$, MC sample size $N=100000$.\n- Test case $2$: $\\alpha=1$, $\\beta=0.5$, $x=()$ (empty, so $n=0$), target $y=0$, MC sample size $N=100000$.\n- Test case $3$: $\\alpha=10$, $\\beta=3$, $x=(10,9,12,8,11)$, target $y=15$, MC sample size $N=100000$.\n\nYour program must:\n- Compute the closed-form value $m(y\\mid x)$ for each test case.\n- Compute $\\widehat{m}_{\\text{num}}(y\\mid x)$ and $\\widehat{m}_{\\text{an}}(y\\mid x)$ as defined above for each test case.\n- Return, for each test case in order, the following five floats: the closed-form $m(y\\mid x)$, the numerical-integration MC estimate $\\widehat{m}_{\\text{num}}(y\\mid x)$, the analytically-integrated MC estimate $\\widehat{m}_{\\text{an}}(y\\mid x)$, the absolute error $\\left|\\widehat{m}_{\\text{num}}(y\\mid x)-m(y\\mid x)\\right|$, and the absolute error $\\left|\\widehat{m}_{\\text{an}}(y\\mid x)-m(y\\mid x)\\right|$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with the $5$ floats for test case $1$ first, followed by the $5$ floats for test case $2$, and then the $5$ floats for test case $3$; for example, $[m_1,\\widehat{m}_{\\text{num},1},\\widehat{m}_{\\text{an},1},e_{\\text{num},1},e_{\\text{an},1},m_2,\\ldots]$.\n- No physical units or angle units are involved in this problem. All outputs must be real numbers.", "solution": "**Analytical Derivations**\n\nFirst, we derive the posterior distribution $\\pi(\\theta\\mid x)$. The posterior is proportional to the product of the likelihood and the prior, $\\pi(\\theta\\mid x) \\propto f(x\\mid\\theta)\\,\\pi(\\theta)$. For $n$ i.i.d. observations $x=(x_1,\\ldots,x_n)$ from a $\\operatorname{Poisson}(\\theta)$ distribution, the likelihood is $f(x\\mid\\theta) \\propto \\exp(-n\\theta)\\,\\theta^{\\sum x_i}$. The prior is $\\pi(\\theta) \\propto \\theta^{\\alpha-1}\\exp(-\\beta \\theta)$. Combining them yields:\n$$\n\\pi(\\theta\\mid x) \\propto \\left( \\exp(-n\\theta)\\,\\theta^{\\sum x_i} \\right) \\left( \\theta^{\\alpha-1}\\exp(-\\beta \\theta) \\right) = \\theta^{(\\alpha + \\sum x_i) - 1} \\exp(-(\\beta+n)\\theta)\n$$\nThis is the kernel of a Gamma distribution. Therefore, the posterior distribution is $\\theta\\mid x \\sim \\operatorname{Gamma}(\\alpha', \\beta')$, where the posterior parameters are $\\alpha' = \\alpha + \\sum_{i=1}^n x_i$ and $\\beta' = \\beta + n$.\n\nSecond, we derive the posterior predictive mass function $m(y\\mid x)$ by averaging the likelihood of a new observation $y$ over the posterior distribution of $\\theta$:\n$$\nm(y\\mid x) = \\int_0^\\infty f(y\\mid\\theta)\\,\\pi(\\theta\\mid x)\\,\\mathrm{d}\\theta = \\int_0^\\infty \\left( \\frac{e^{-\\theta}\\theta^y}{y!} \\right) \\left( \\frac{(\\beta')^{\\alpha'}}{\\Gamma(\\alpha')} \\theta^{\\alpha'-1} e^{-\\beta'\\theta} \\right) \\mathrm{d}\\theta\n$$\nCollecting terms involving $\\theta$ inside the integral gives $\\int_0^\\infty \\theta^{(y+\\alpha')-1} \\exp(-(\\beta'+1)\\theta)\\,\\mathrm{d}\\theta$. This is a standard gamma integral, which evaluates to $\\frac{\\Gamma(y+\\alpha')}{(\\beta'+1)^{y+\\alpha'}}$. Substituting this back gives the PMF of a Negative Binomial distribution, $Y\\mid x \\sim \\operatorname{NB}(r=\\alpha', p=\\frac{\\beta'}{\\beta'+1})$.\n\n**Monte Carlo Estimators and Variance Comparison**\n\nThe estimator $\\widehat{m}_{\\text{num}}(y\\mid x)$ computes the average of $f(y\\mid\\theta_j)$ over posterior samples $\\theta_j$. The estimator $\\widehat{m}_{\\text{an}}(y\\mid x)$ computes the frequency of the event $\\{Y_j=y\\}$ over samples $Y_j$ from the posterior predictive distribution. The difference in variance is a direct consequence of the Rao-Blackwell theorem.\n\nLet $W = \\mathbb{I}\\{Y=y\\}$ be the random variable for a single sample used in $\\widehat{m}_{\\text{an}}$. Its conditional expectation given $\\theta$ is $\\mathbb{E}[W\\mid\\theta] = P(Y=y\\mid\\theta) = f(y\\mid\\theta)$, which is the random variable for a single sample used in $\\widehat{m}_{\\text{num}}$. The law of total variance states:\n$$\n\\operatorname{Var}(W) = \\mathbb{E}[\\operatorname{Var}(W\\mid\\theta)] + \\operatorname{Var}(\\mathbb{E}[W\\mid\\theta])\n$$\nThe variance of a single sample for $\\widehat{m}_{\\text{an}}$ is $\\operatorname{Var}(W)$, while for $\\widehat{m}_{\\text{num}}$ it is $\\operatorname{Var}(\\mathbb{E}[W\\mid\\theta])$. Since the term $\\mathbb{E}[\\operatorname{Var}(W\\mid\\theta)]$ is non-negative, it follows that $\\operatorname{Var}(\\mathbb{E}[W\\mid\\theta]) \\le \\operatorname{Var}(W)$. This implies that the variance of the estimator $\\widehat{m}_{\\text{num}}$ is lower. Conceptually, $\\widehat{m}_{\\text{num}}$ reduces variance by analytically averaging out one layer of randomness (the sampling of $Y$ from the Poisson distribution), replacing the noisy binary indicator $\\mathbb{I}\\{Y=y\\}$ with its smoother conditional expectation $f(y\\mid\\theta)$.", "answer": "```python\nimport numpy as np\nfrom scipy.special import gammaln\nfrom scipy.stats import poisson\n\ndef solve():\n    \"\"\"\n    Computes and compares two Monte Carlo estimators for the posterior predictive\n    probability mass function in a Poisson-Gamma conjugate model.\n    \"\"\"\n    \n    test_cases = [\n        # (alpha, beta, x, y, N)\n        (3.0, 1.2, (3, 1, 0, 2), 2, 100000),\n        (1.0, 0.5, (), 0, 100000),\n        (10.0, 3.0, (10, 9, 12, 8, 11), 15, 100000),\n    ]\n\n    # Fix the pseudorandom generator seed for deterministic output.\n    np.random.seed(12345)\n\n    results = []\n    for alpha, beta, x, y, N in test_cases:\n        # Step 1: Calculate posterior parameters\n        n = len(x)\n        sum_x = sum(x)\n        \n        alpha_prime = alpha + sum_x\n        beta_prime = beta + n\n\n        # Step 2: Compute the closed-form value of m(y|x)\n        # This is the PMF of a Negative Binomial distribution with parameters\n        # r = alpha_prime and p = beta_prime / (beta_prime + 1)\n        log_m_true = (gammaln(y + alpha_prime) \n                      - (gammaln(y + 1) + gammaln(alpha_prime))\n                      + alpha_prime * np.log(beta_prime) \n                      - (y + alpha_prime) * np.log(beta_prime + 1))\n        m_true = np.exp(log_m_true)\n\n        # Step 3: Compute the numerical integration estimator, hat_m_num\n        # Sample thetas from the posterior Gamma(alpha', beta')\n        # Note: numpy.random.gamma uses a scale parameter, which is 1/rate.\n        scale_param = 1.0 / beta_prime\n        thetas = np.random.gamma(shape=alpha_prime, scale=scale_param, size=N)\n        \n        # Calculate the Poisson PMF f(y|theta) for each sample\n        # This is E[I(Y=y)|theta]\n        f_values = poisson.pmf(y, thetas)\n        m_hat_num = np.mean(f_values)\n        \n        # Step 4: Compute the analytically-integrated estimator, hat_m_an\n        # Sample Y from the posterior predictive NegativeBinomial(r, p)\n        # and compute the proportion of samples equal to y.\n        p_nb = beta_prime / (beta_prime + 1)\n        Y_samples = np.random.negative_binomial(n=alpha_prime, p=p_nb, size=N)\n        m_hat_an = np.mean(Y_samples == y)\n\n        # Step 5: Calculate absolute errors\n        error_num = abs(m_hat_num - m_true)\n        error_an = abs(m_hat_an - m_true)\n        \n        results.extend([m_true, m_hat_num, m_hat_an, error_num, error_an])\n\n    # Format the final output as a single comma-separated list in brackets.\n    # Use general formatting to avoid scientific notation where possible, but allow it if needed.\n    print(f\"[{','.join(f'{r:.8f}' for r in results)}]\")\n\nsolve()\n```", "id": "3315544"}, {"introduction": "A deep understanding of any powerful tool requires knowing not only when to use it, but also when it does not apply. This final practice provides a crucial insight into the limits of the Rao-Blackwell theorem [@problem_id:3297948]. Through a carefully constructed scenario, you will discover that if an estimator is already a function of the sufficient statistic, conditioning offers no further variance reduction. This exercise solidifies your understanding by demonstrating that the \"magic\" of Rao-Blackwellization is not automatic, but depends on the relationship between the estimator and the underlying statistical structure of the problem.", "problem": "Consider independent and identically distributed random variables $X_1,\\ldots,X_n$ with $X_i \\sim \\text{Exp}(\\lambda)$, where $\\text{Exp}(\\lambda)$ denotes the exponential distribution with rate parameter $\\lambda$. Define the sample mean $\\bar{X}$ by $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^n X_i$ and the sufficient statistic $T$ by $T=\\sum_{i=1}^n X_i$. Fix a measurable function $g:\\mathbb{R}_+\\to\\mathbb{R}$ given by $g(x)=\\exp(-\\alpha x)$ for a fixed constant $\\alpha>0$. The objective is to approximate the expectation $E[g(\\bar{X})]$ and to compare the Monte Carlo variance of a naive estimator with a Rao-Blackwellized estimator, conditioning on $T$.\n\nYour tasks are:\n\n- Derive, from first principles, a naive Monte Carlo estimator for $E[g(\\bar{X})]$ using $M$ independent replicates, each replicate consisting of $n$ independent draws from $\\text{Exp}(\\lambda)$. The naive estimator is the empirical average of $g(\\bar{X})$ over the $M$ replicates. Here $M$ is a positive integer chosen for computational stability, and its choice should be justified in your algorithmic design.\n- Derive a Rao-Blackwellized estimator that conditions on the sufficient statistic $T=\\sum_{i=1}^n X_i$ and quantify its Monte Carlo variance relative to the naive estimator as $n$ varies.\n- Use the foundational definitions of sufficient statistics, conditional expectation, and the law of total variance to justify the construction and the comparison.\n\nFor reproducibility, set $\\alpha$ to the fixed value $\\alpha=1.3$. No physical units or angles are involved in this problem; all quantities are dimensionless. The Monte Carlo variance comparison should be expressed through the ratio $R(n,\\lambda)$ defined as\n$$\nR(n,\\lambda)=\\frac{\\operatorname{Var}(\\text{naive single-replicate }g(\\bar{X}))}{\\operatorname{Var}(\\text{Rao-Blackwellized single-replicate }E[g(\\bar{X})\\mid T])},\n$$\nestimated empirically over $M$ replicates for each test case.\n\nUse the following test suite of parameter values for $(n,\\lambda)$:\n- Test case $1$: $n=1$, $\\lambda=0.7$.\n- Test case $2$: $n=2$, $\\lambda=1.0$.\n- Test case $3$: $n=10$, $\\lambda=1.0$.\n- Test case $4$: $n=100$, $\\lambda=2.0$.\n\nYour program must:\n- Implement the naive estimator and the Rao-Blackwellized estimator for each test case.\n- Estimate the empirical variances of the single-replicate quantities $g(\\bar{X})$ and $E[g(\\bar{X})\\mid T]$ using $M$ replicates, with $M$ chosen to be a large positive integer to ensure numerical stability while keeping computation feasible.\n- Compute the ratio $R(n,\\lambda)$ for each test case as a float.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases given above, for example, $[r_1,r_2,r_3,r_4]$ where each $r_i$ is the empirically estimated ratio $R(n,\\lambda)$ for the corresponding test case.", "solution": "The solution rests on a key observation about the relationship between the estimator and the sufficient statistic.\n\nFor independent random variables $X_1,\\ldots,X_n$ from an $\\text{Exp}(\\lambda)$ distribution, the sum $T=\\sum_{i=1}^n X_i$ is a sufficient statistic for the rate parameter $\\lambda$. This can be shown using the factorization theorem on the joint probability density function.\n\nThe naive single-replicate estimator is $Y = g(\\bar{X})$, where $\\bar{X}=\\frac{1}{n}\\sum_{i=1}^n X_i = \\frac{T}{n}$. Substituting this into the function $g(x)=\\exp(-\\alpha x)$ gives:\n$$\nY = g(\\bar{X}) = \\exp\\left(-\\alpha \\frac{T}{n}\\right)\n$$\nThis shows that the naive estimator $Y$ is already a function of the sufficient statistic $T$.\n\nThe Rao-Blackwellized estimator is defined as $\\tilde{Y} = E[Y \\mid T]$. By the properties of conditional expectation, if a random variable (like $Y$) is already measurable with respect to the conditioning information (the $\\sigma$-algebra generated by $T$), then its conditional expectation is itself. Therefore:\n$$\n\\tilde{Y} = E[g(\\bar{X}) \\mid T] = g(\\bar{X})\n$$\nThe naive and Rao-Blackwellized estimators are identical.\n\nConsequently, their variances must also be identical: $\\operatorname{Var}(g(\\bar{X})) = \\operatorname{Var}(E[g(\\bar{X})\\mid T])$. The ratio of their variances, $R(n,\\lambda)$, is therefore exactly 1. This exercise demonstrates a crucial limitation of Rao-Blackwellization: it offers no improvement if the estimator being conditioned is already a function of the sufficient statistic. The Monte Carlo simulation will empirically confirm that the variance ratio is 1 for all test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef estimate_variance_ratio(n: int, lam: float, alpha: float, M: int, chunk_size: int = 10000) -> float:\n    \"\"\"\n    Estimate the ratio Var(naive g(barX)) / Var(Rao-Blackwellized E[g(barX)|T])\n    using M replicates in chunks to control memory.\n    For this problem, Rao-Blackwellized estimator equals the naive estimator exactly,\n    so the ratio should be exactly 1.0. We compute both variances empirically to\n    demonstrate equality.\n    \"\"\"\n    # Welford's algorithm for online variance estimation (unbiased sample variance)\n    # for the naive estimator Y and the RB estimator Y_rb. They will track identical values.\n    count = 0\n    mean_naive = 0.0\n    M2_naive = 0.0\n\n    mean_rb = 0.0\n    M2_rb = 0.0\n\n    # Process in chunks to limit memory usage\n    remaining = M\n    rng = np.random.default_rng(seed=12345)\n    scale = 1.0 / lam\n\n    while remaining > 0:\n        m = min(chunk_size, remaining)\n        # Draw m replicates of length n from Exp(lam)\n        x = rng.exponential(scale=scale, size=(m, n))\n        # Compute sample mean per replicate\n        xbar = x.mean(axis=1)\n        # Naive single-replicate values\n        y = np.exp(-alpha * xbar)\n        # Rao-Blackwellized single-replicate values; here equals g(T/n) = g(xbar)\n        y_rb = np.exp(-alpha * xbar)\n\n        # Update Welford statistics for naive\n        for val in y:\n            count += 1\n            delta = val - mean_naive\n            mean_naive += delta / count\n            M2_naive += delta * (val - mean_naive)\n\n        # Update Welford statistics for RB\n        # Note: y_rb equals y elementwise; we still update separately for clarity.\n        count_rb = count - m  # RB count before this chunk\n        mean_rb_chunk = mean_rb\n        M2_rb_chunk = M2_rb\n        for val in y_rb:\n            count_rb += 1\n            delta_rb = val - mean_rb_chunk\n            mean_rb_chunk += delta_rb / count_rb\n            M2_rb_chunk += delta_rb * (val - mean_rb_chunk)\n        mean_rb = mean_rb_chunk\n        M2_rb = M2_rb_chunk\n\n        remaining -= m\n\n    # Unbiased sample variance with ddof=1\n    var_naive = M2_naive / (count - 1) if count > 1 else 0.0\n    var_rb = M2_rb / (count - 1) if count > 1 else 0.0\n\n    # Ratio; guard against division by zero (should not happen unless M<2).\n    ratio = var_naive / var_rb if var_rb > 0 else float('nan')\n    return ratio\n\ndef solve():\n    # Define alpha and Monte Carlo replicates count M\n    alpha = 1.3\n    M = 100000  # Large enough for stability, small enough for speed\n\n    # Define the test cases from the problem statement.\n    # Each test case is a tuple (n, lambda)\n    test_cases = [\n        (1, 0.7),\n        (2, 1.0),\n        (10, 1.0),\n        (100, 2.0),\n    ]\n\n    results = []\n    for n, lam in test_cases:\n        ratio = estimate_variance_ratio(n=n, lam=lam, alpha=alpha, M=M, chunk_size=10000)\n        # To ensure clean output, round to 6 decimal places\n        results.append(f\"{ratio:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3297948"}]}