{"hands_on_practices": [{"introduction": "The fundamental building block of any hierarchical matrix method is the ability to distinguish compressible \"far-field\" interactions from incompressible \"near-field\" ones. This exercise guides you through implementing this core mechanism, where you will determine the numerical rank of an interaction block by applying a geometric admissibility test and then computing a low-rank approximation that satisfies a prescribed error tolerance [@problem_id:3313470]. Mastering this process is the first step toward building efficient hierarchical matrix algorithms.", "problem": "Consider a boundary integral discretization of the time-harmonic electromagnetic scattering problem where the interaction between two well-separated point clusters is modeled using the scalar Helmholtz Green's kernel. The scalar Helmholtz kernel is defined by $G(\\mathbf{r}) = \\dfrac{e^{\\mathrm{i} k \\lVert \\mathbf{r} \\rVert}}{4\\pi \\lVert \\mathbf{r} \\rVert}$, where $k$ is the wavenumber in $\\mathrm{m}^{-1}$, $\\mathbf{r} \\in \\mathbb{R}^3$ is the displacement vector in $\\mathrm{m}$, and $\\lVert \\cdot \\rVert$ denotes the Euclidean norm. In computational electromagnetics, hierarchical matrix representations exploit the fact that for well-separated clusters, submatrices formed from samples of $G$ are numerically low rank due to the smoothness of the kernel on the restricted domains.\n\nLet $X = \\{\\mathbf{x}_i\\}_{i=1}^m$ and $Y = \\{\\mathbf{y}_j\\}_{j=1}^n$ be two discrete point clusters in $\\mathbb{R}^3$, each lying on a straight line segment of length $a$ (in $\\mathrm{m}$). The segment for $X$ is centered at the origin and aligned with the $x$-axis; specifically, $X$ consists of $m$ points uniformly spaced on the segment from $(-a/2,0,0)$ to $(a/2,0,0)$. The segment for $Y$ is centered at $(\\delta_x, 0, D)$, aligned with the $x$-axis, and consists of $n$ points uniformly spaced on the segment from $(\\delta_x - a/2,0,D)$ to $(\\delta_x + a/2,0,D)$, where $D$ is the center-to-center separation along the $z$-axis and $\\delta_x$ is a small lateral shift in $\\mathrm{m}$. The interaction block matrix $A \\in \\mathbb{C}^{m \\times n}$ is defined entrywise by $A_{ij} = G(\\mathbf{x}_i - \\mathbf{y}_j)$.\n\nTo decide whether a block is admissible for low-rank approximation, use the geometric admissibility criterion $D/a \\ge \\eta$, where $\\eta > 0$ is a fixed admissibility parameter. For admissible blocks, select a low-rank approximation adaptively based on a user-specified tolerance. Let the Singular Value Decomposition (SVD) of $A$ be $A = U \\Sigma V^*$ with singular values $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots \\ge \\sigma_q \\ge 0$ and $q = \\min(m,n)$. The best rank-$r$ truncated SVD approximation $A_r$ incurs the Frobenius-norm relative error\n$$\nE_r = \\sqrt{\\frac{\\sum_{j=r+1}^{q} \\sigma_j^2}{\\sum_{j=1}^{q} \\sigma_j^2}}.\n$$\nGiven a block tolerance $\\tau > 0$, select the minimal $r \\in \\{1,2,\\dots,q\\}$ such that $E_r \\le \\tau$. If the block is inadmissible (i.e., $D/a < \\eta$), set $r = q$ and define $E_r = 0$ because the full-rank approximation recovers $A$ exactly.\n\nStarting from the fundamental base that well-separated interactions of the Helmholtz kernel produce numerically low-rank blocks due to smoothness and separability properties, derive an algorithm that:\n- Constructs point clusters $X$ and $Y$ according to the geometry above.\n- Forms the block matrix $A$ using $G(\\mathbf{r})$ with physically consistent units.\n- Applies the admissibility criterion.\n- For admissible blocks, computes the SVD of $A$, evaluates $E_r$ for increasing $r$, and selects the minimal $r$ such that $E_r \\le \\tau$.\n- For inadmissible blocks, sets $r = q$ and $E_r = 0$.\n\nUse the following test suite with parameters expressed in meters for lengths and $\\mathrm{m}^{-1}$ for wavenumber. All tolerances are dimensionless:\n1. Case 1 (happy path far-field): $m = 40$, $n = 40$, $a = 0.2$ $\\mathrm{m}$, $D = 1.0$ $\\mathrm{m}$, $\\delta_x = 0.03$ $\\mathrm{m}$, $k = 3.0$ $\\mathrm{m}^{-1}$, $\\eta = 2.5$, $\\tau = 10^{-3}$.\n2. Case 2 (boundary small block): $m = 4$, $n = 4$, $a = 0.1$ $\\mathrm{m}$, $D = 0.6$ $\\mathrm{m}$, $\\delta_x = 0.02$ $\\mathrm{m}$, $k = 3.0$ $\\mathrm{m}^{-1}$, $\\eta = 2.5$, $\\tau = 10^{-3}$.\n3. Case 3 (near-field inadmissible): $m = 50$, $n = 50$, $a = 0.2$ $\\mathrm{m}$, $D = 0.05$ $\\mathrm{m}$, $\\delta_x = 0.03$ $\\mathrm{m}$, $k = 3.0$ $\\mathrm{m}^{-1}$, $\\eta = 2.5$, $\\tau = 10^{-3}$.\n4. Case 4 (high-frequency far-field): $m = 60$, $n = 60$, $a = 0.2$ $\\mathrm{m}$, $D = 1.0$ $\\mathrm{m}$, $\\delta_x = 0.05$ $\\mathrm{m}$, $k = 20.0$ $\\mathrm{m}^{-1}$, $\\eta = 2.5$, $\\tau = 10^{-3}$.\n5. Case 5 (strict tolerance far-field): $m = 40$, $n = 40$, $a = 0.2$ $\\mathrm{m}$, $D = 1.2$ $\\mathrm{m}$, $\\delta_x = 0.03$ $\\mathrm{m}$, $k = 3.0$ $\\mathrm{m}^{-1}$, $\\eta = 2.5$, $\\tau = 10^{-6}$.\n\nYour program should compute, for each test case, the pair $[r, E_r]$ where $r$ is the selected rank and $E_r$ is the achieved Frobenius-norm relative error (dimensionless). The final output format must be a single line containing a comma-separated list of these pairs enclosed in square brackets, for example, $[[r_1,E_1],[r_2,E_2],\\dots]$. Angles do not appear in this problem; if any angle were to be introduced, it must be in radians, but none are required here. Distances must be in meters and wavenumbers in inverse meters as specified; however, the output values $r$ and $E_r$ are dimensionless.", "solution": "The user-provided problem is assessed to be valid. It is scientifically grounded in computational electromagnetics, well-posed with a clear and complete set of givens, and presented with objective, formal language. It asks for the implementation of a standard procedure for determining the numerical rank of a matrix block arising from a boundary integral equation formulation.\n\nThe solution is derived by following a step-by-step procedure that first establishes the geometry, then constructs the interaction matrix, and finally performs an analysis based on its singular value decomposition to determine the rank required to meet a specified approximation tolerance.\n\n**1. Geometric Configuration and Point Cluster Generation**\n\nThe problem defines two clusters of points, $X = \\{\\mathbf{x}_i\\}_{i=1}^m$ and $Y = \\{\\mathbf{y}_j\\}_{j=1}^n$, in three-dimensional Euclidean space, $\\mathbb{R}^3$.\n\nThe first cluster, $X$, consists of $m$ points positioned on a line segment of length $a$ centered at the origin $(0,0,0)$ and aligned with the $x$-axis. The coordinates of these points, $\\mathbf{x}_i \\in \\mathbb{R}^3$, are given by $\\mathbf{x}_i = (x_i, 0, 0)$. The scalar values $x_i$ represent a uniform discretization of the interval $[-a/2, a/2]$. For $m > 1$, these points are generated using a uniform linear spacing that includes the endpoints, i.e., $x_i = -a/2 + (i-1) \\frac{a}{m-1}$ for $i = 1, \\dots, m$. For the degenerate case $m=1$, the single point is placed at the center, $\\mathbf{x}_1 = (0,0,0)$.\n\nThe second cluster, $Y$, consists of $n$ points on a parallel line segment of the same length $a$. This segment is centered at $(\\delta_x, 0, D)$, where $D$ represents a separation along the $z$-axis and $\\delta_x$ a lateral shift along the $x$-axis. The coordinates $\\mathbf{y}_j \\in \\mathbb{R}^3$ are given by $\\mathbf{y}_j = (y_j' + \\delta_x, 0, D)$. The scalar values $y_j'$ are a uniform discretization of the same interval $[-a/2, a/2]$, analogous to the $x_i$ values. For $n > 1$, $y_j' = -a/2 + (j-1) \\frac{a}{n-1}$ for $j=1, \\dots, n$. For $n=1$, the point is centered on the segment before the shift, resulting in $\\mathbf{y}_1 = (\\delta_x, 0, D)$.\n\n**2. Block Matrix Construction**\n\nThe interaction between the two clusters is captured by an $m \\times n$ matrix $A \\in \\mathbb{C}^{m \\times n}$. Each entry $A_{ij}$ of this matrix represents the interaction between point $\\mathbf{x}_i$ and point $\\mathbf{y}_j$, mediated by the scalar Helmholtz Green's function:\n$$\nA_{ij} = G(\\mathbf{x}_i - \\mathbf{y}_j) = \\frac{e^{\\mathrm{i} k \\lVert \\mathbf{x}_i - \\mathbf{y}_j \\rVert}}{4\\pi \\lVert \\mathbf{x}_i - \\mathbf{y}_j \\rVert}\n$$\nHere, $k$ is the wavenumber, $\\mathrm{i}$ is the imaginary unit, and $\\lVert \\cdot \\rVert$ is the Euclidean norm. The displacement vector is $\\mathbf{r}_{ij} = \\mathbf{x}_i - \\mathbf{y}_j$. Its squared norm is:\n$$\n\\lVert \\mathbf{r}_{ij} \\rVert^2 = \\lVert (x_i - (y_j' + \\delta_x), 0, -D) \\rVert^2 = (x_i - y_j' - \\delta_x)^2 + D^2\n$$\nSince the problem states $D$ in meters, and for all test cases $D > 0$, the denominator $\\lVert \\mathbf{x}_i - \\mathbf{y}_j \\rVert$ is never zero, thus avoiding any singularity in the kernel evaluation.\n\n**3. Admissibility Criterion and Rank Selection**\n\nThe core of hierarchical matrix methods is to distinguish between interactions that can be compressed (far-field) and those that cannot (near-field). This is done via an admissibility criterion.\n\nFirst, the geometric condition $D/a \\ge \\eta$ is evaluated, where $\\eta$ is a dimensionless admissibility parameter.\n- If $D/a < \\eta$, the interaction is deemed \"inadmissible\" or near-field. In this scenario, no approximation is performed. The problem specifies that the rank $r$ is set to the full possible rank, $r = q = \\min(m, n)$, and the corresponding error $E_r$ is defined as $E_r = 0$. This implies using the exact block matrix $A$.\n- If $D/a \\ge \\eta$, the interaction is \"admissible\" or far-field. The matrix $A$ is expected to be numerically low-rank. The task is to find the minimal rank $r$ that approximates $A$ within a specified tolerance $\\tau$.\n\n**4. Adaptive Rank Determination via SVD**\n\nFor an admissible block, the optimal rank-$r$ approximation in the Frobenius norm is given by the truncated Singular Value Decomposition (SVD). Let the SVD of $A$ be $A = U \\Sigma V^*$, where the singular values are $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_q \\ge 0$.\n\nThe relative Frobenius-norm error of the rank-$r$ approximation $A_r$ is:\n$$\nE_r = \\sqrt{\\frac{\\sum_{j=r+1}^{q} \\sigma_j^2}{\\sum_{j=1}^{q} \\sigma_j^2}}\n$$\nWe seek the smallest integer $r \\in \\{1, 2, \\dots, q\\}$ such that $E_r \\le \\tau$. This is equivalent to finding the smallest $r$ satisfying:\n$$\n\\sum_{j=r+1}^{q} \\sigma_j^2 \\le \\tau^2 \\sum_{j=1}^{q} \\sigma_j^2\n$$\nLet $F^2 = \\sum_{j=1}^{q} \\sigma_j^2$ be the squared Frobenius norm of $A$. The condition can be rewritten by rearranging the terms:\n$$\nF^2 - \\sum_{j=1}^{r} \\sigma_j^2 \\le \\tau^2 F^2 \\implies \\sum_{j=1}^{r} \\sigma_j^2 \\ge (1-\\tau^2) F^2\n$$\nThis provides an efficient algorithm:\n1. Compute the singular values $\\sigma_j$ of $A$.\n2. Compute their squares, $\\sigma_j^2$.\n3. Compute the cumulative sum of the squared singular values, $C_k = \\sum_{j=1}^{k} \\sigma_j^2$. The total sum is $C_q = F^2$.\n4. Find the smallest index $r$ for which $C_r \\ge (1-\\tau^2)C_q$. This is the desired rank.\n5. Once this minimal rank $r$ is found, the corresponding error $E_r$ is calculated using its definition: $E_r = \\sqrt{(C_q - C_r)/C_q}$.\n\nThis complete procedure is applied to each test case to determine the pair $[r, E_r]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the adaptive low-rank approximation for matrix blocks\n    arising in a computational electromagnetics context for a series of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Format: (m, n, a, D, delta_x, k, eta, tau)\n    test_cases = [\n        (40, 40, 0.2, 1.0, 0.03, 3.0, 2.5, 1e-3),   # Case 1\n        (4, 4, 0.1, 0.6, 0.02, 3.0, 2.5, 1e-3),     # Case 2\n        (50, 50, 0.2, 0.05, 0.03, 3.0, 2.5, 1e-3),  # Case 3\n        (60, 60, 0.2, 1.0, 0.05, 20.0, 2.5, 1e-3),  # Case 4\n        (40, 40, 0.2, 1.2, 0.03, 3.0, 2.5, 1e-6),   # Case 5\n    ]\n\n    results = []\n    for case in test_cases:\n        m, n, a, D, delta_x, k, eta, tau = case\n        q = min(m, n)\n\n        # Step 1: Apply admissibility criterion\n        if D / a < eta:\n            # Inadmissible block: use full rank, error is zero by definition\n            rank = q\n            error = 0.0\n            results.append([rank, error])\n            continue\n\n        # Admissible block: proceed with matrix construction and SVD\n        \n        # Step 2: Construct point clusters X and Y\n        if m > 1:\n            x_coords = np.linspace(-a / 2, a / 2, m)\n        else:\n            x_coords = np.array([0.0])\n        \n        if n > 1:\n            y_coords_base = np.linspace(-a / 2, a / 2, n)\n        else:\n            y_coords_base = np.array([0.0])\n\n        # Create 3D point arrays\n        X = np.zeros((m, 3))\n        X[:, 0] = x_coords\n\n        Y = np.zeros((n, 3))\n        Y[:, 0] = y_coords_base + delta_x\n        Y[:, 2] = D\n        \n        # Step 3: Form the block matrix A\n        # Use broadcasting for efficient computation of pairwise distances\n        # diff will have shape (m, n, 3)\n        diff = X[:, np.newaxis, :] - Y[np.newaxis, :, :]\n        # r_norm will have shape (m, n)\n        r_norm = np.linalg.norm(diff, axis=2)\n\n        # Evaluate the Helmholtz Green's function, G(r) = exp(i*k*r) / (4*pi*r)\n        # The condition D > 0 ensures r_norm is never zero.\n        A = np.exp(1j * k * r_norm) / (4 * np.pi * r_norm)\n\n        # Step 4: Compute SVD and determine adaptive rank\n        # We only need the singular values\n        s = np.linalg.svd(A, compute_uv=False)\n        \n        s_sq = s**2\n        f_norm_sq = np.sum(s_sq)\n\n        if f_norm_sq == 0:\n            # The matrix is a zero matrix. Rank is 0. Problem asks for r in {1..q}.\n            # A rank-1 approximation (the zero matrix) is exact.\n            rank = 1\n            error = 0.0\n        else:\n            # Use the cumulative sum of squared singular values to find the rank\n            # efficiently. We seek the smallest r such that the energy captured \n            # by the first r singular values, sum(s_sq[:r]), is at least\n            # (1 - tau^2) of the total energy.\n            cum_s_sq = np.cumsum(s_sq)\n            threshold = (1 - tau**2) * f_norm_sq\n            \n            # Find the first index i where cum_s_sq[i] >= threshold.\n            # The rank r is i + 1. np.searchsorted gives this index directly.\n            # 'side=\"left\"' is the default but included for clarity.\n            rank_idx = np.searchsorted(cum_s_sq, threshold, side='left')\n            rank = rank_idx + 1\n\n            # Step 5: Calculate the final error for the determined rank\n            # The sum is over singular values from index 'rank' to the end.\n            err_norm_sq = np.sum(s_sq[rank:])\n            error = np.sqrt(err_norm_sq / f_norm_sq)\n\n        results.append([rank, error])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3313470"}, {"introduction": "While low-rank approximation provides the theoretical speedup, its practical utility depends on concrete gains in memory and computational cost. This problem shifts the focus from a single block to the storage economy of the entire hierarchical structure during a common, dynamic simulation scenario: adaptive mesh refinement [@problem_id:3313464]. By calculating the net change in storage, you will develop a quantitative understanding of the costs and benefits associated with hierarchical matrix updates.", "problem": "Consider the Electric Field Integral Equation (EFIE) for time-harmonic scattering in free space, where the surface current density is discretized with Rao–Wilton–Glisson (RWG) basis functions, producing a dense system matrix $A \\in \\mathbb{C}^{N \\times N}$ with entries governed by the three-dimensional Helmholtz Green’s function $G_{k}(\\mathbf{r}) = \\exp(\\mathrm{i} k |\\mathbf{r}|) / (4 \\pi |\\mathbf{r}|)$. A Hierarchical matrix (also called $\\mathcal{H}$-matrix) representation is constructed using a binary cluster tree over the index set and an admissibility criterion based on geometric separation: a block corresponding to cluster pair $(t,s)$ is admissible if $\\max\\{\\operatorname{diam}(t), \\operatorname{diam}(s)\\} \\le \\eta\\,\\operatorname{dist}(t,s)$ for a fixed $\\eta > 0$. Admissible (far-field) blocks are stored in a low-rank factorized form, while inadmissible (near-field) blocks are stored densely.\n\nYou refine the surface mesh locally in a small geometric patch and perform an adaptive hierarchical update of the $\\mathcal{H}$-matrix without rebuilding it from scratch. Assume the following storage model and update scenario:\n\n- Storage model for an admissible block: If an admissible block $B \\in \\mathbb{C}^{m \\times n}$ is represented by a factorization $B \\approx U S V^{*}$ with $U \\in \\mathbb{C}^{m \\times r}$, $S \\in \\mathbb{C}^{r \\times r}$, and $V \\in \\mathbb{C}^{n \\times r}$, then the storage counted for this block is the number of scalar entries in $U$, $S$, and $V$, namely $r(m+n) + r^2$. Storage for inadmissible blocks of size $m \\times n$ is counted as $mn$.\n\n- Local refinement scenario: In the pre-refinement $\\mathcal{H}$-matrix, there are admissible leaf blocks of uniform size $64 \\times 64$. After refinement:\n  1) Exactly $125$ admissible leaf blocks of size $64 \\times 64$ each are split into their $4$ children (each child of size $32 \\times 32$) and the parent blocks are removed. For these blocks and their children, the numerical rank stays constant at $r = 18$.\n  2) Exactly $200$ new admissible leaf blocks of size $32 \\times 32$ are created due to newly admissible far-field interactions caused by the refined clusters, each stored with rank $r = 18$.\n  3) Exactly $100$ new inadmissible (near-field) leaf blocks of size $32 \\times 32$ are created and stored densely.\n  4) No other blocks are modified, and you may neglect any storage overhead associated with the tree structure, index sets, and metadata.\n\nUsing only the information above and standard definitions of hierarchical matrix storage, compute the exact net increase in the number of stored scalar entries induced by this adaptive update. Express your final answer as a single integer (number of scalars), with no units. No rounding is required.", "solution": "The user has requested the calculation of the net increase in the number of stored scalar entries in a hierarchical matrix ($\\mathcal{H}$-matrix) representation following an adaptive update. The problem is well-posed and scientifically grounded in the field of computational electromagnetics. I will proceed with a detailed calculation based on the provided data.\n\nThe net increase in storage, which we denote as $\\Delta S_{\\text{total}}$, is the total storage added minus the total storage removed. We can calculate this by summing the net changes from the three distinct update scenarios described in the problem statement.\n$$\n\\Delta S_{\\text{total}} = \\Delta S_{1} + \\Delta S_{2} + \\Delta S_{3}\n$$\nwhere $\\Delta S_{1}$, $\\Delta S_{2}$, and $\\Delta S_{3}$ are the storage changes from scenarios $1$, $2$, and $3$, respectively.\n\nFirst, let us define the storage cost functions based on the problem's storage model.\nThe storage cost for an admissible block of size $m \\times n$ approximated with a rank-$r$ factorization is given by:\n$$\nC_{\\text{adm}}(m, n, r) = r(m+n) + r^2\n$$\nThe storage cost for an inadmissible (dense) block of size $m \\times n$ is:\n$$\nC_{\\text{inadm}}(m, n) = mn\n$$\n\nNow, we will analyze each scenario.\n\n**Scenario 1: Splitting of $125$ admissible leaf blocks**\nIn this scenario, $N_1 = 125$ parent blocks are removed and replaced by their children.\nThe storage removed is from the parent blocks. Each parent block is admissible, of size $64 \\times 64$, and has a rank of $r = 18$.\nThe size parameters are $m_p = 64$ and $n_p = 64$.\nThe storage for a single parent block is:\n$$\nC_{\\text{parent}} = C_{\\text{adm}}(64, 64, 18) = 18(64 + 64) + 18^2 = 18(128) + 324 = 2304 + 324 = 2628\n$$\nThe total storage removed is:\n$$\nS_{\\text{removed}} = N_1 \\times C_{\\text{parent}} = 125 \\times 2628 = 328500\n$$\nEach of these $N_1 = 125$ parent blocks is split into $k=4$ child blocks. The total number of new child blocks is $125 \\times 4 = 500$.\nEach child block is of size $32 \\times 32$ and, as stated, is stored with the same rank $r = 18$. The size parameters are $m_c = 32$ and $n_c = 32$.\nThe storage for a single child block is:\n$$\nC_{\\text{child}} = C_{\\text{adm}}(32, 32, 18) = 18(32 + 32) + 18^2 = 18(64) + 324 = 1152 + 324 = 1476\n$$\nThe total storage added from these children is:\n$$\nS_{\\text{added,1}} = (N_1 \\times k) \\times C_{\\text{child}} = 500 \\times 1476 = 738000\n$$\nThe net change in storage for the first scenario is:\n$$\n\\Delta S_{1} = S_{\\text{added,1}} - S_{\\text{removed}} = 738000 - 328500 = 409500\n$$\n\n**Scenario 2: Creation of $200$ new admissible leaf blocks**\nIn this scenario, $N_2 = 200$ new admissible leaf blocks are created. There is no corresponding storage removal.\nThese blocks are of size $32 \\times 32$ and have a rank of $r=18$. Their storage cost is identical to the child blocks in Scenario 1.\n$$\nC_{\\text{new\\_adm}} = C_{\\text{adm}}(32, 32, 18) = 1476\n$$\nThe storage increase from this scenario is:\n$$\n\\Delta S_{2} = S_{\\text{added,2}} = N_2 \\times C_{\\text{new\\_adm}} = 200 \\times 1476 = 295200\n$$\n\n**Scenario 3: Creation of $100$ new inadmissible leaf blocks**\nIn this scenario, $N_3 = 100$ new inadmissible (dense) leaf blocks are created.\nThese blocks are of size $32 \\times 32$.\nThe storage for a single such block is:\n$$\nC_{\\text{new\\_inadm}} = C_{\\text{inadm}}(32, 32) = 32 \\times 32 = 1024\n$$\nThe storage increase from this scenario is:\n$$\n\\Delta S_{3} = S_{\\text{added,3}} = N_3 \\times C_{\\text{new\\_inadm}} = 100 \\times 1024 = 102400\n$$\n\n**Total Net Increase in Storage**\nFinally, the total net increase in the number of stored scalar entries is the sum of the changes from all three scenarios:\n$$\n\\Delta S_{\\text{total}} = \\Delta S_{1} + \\Delta S_{2} + \\Delta S_{3} = 409500 + 295200 + 102400\n$$\nSumming these values:\n$$\n\\Delta S_{\\text{total}} = 704700 + 102400 = 807100\n$$\nThe exact net increase in the number of stored scalar entries is $807100$.", "answer": "$$\\boxed{807100}$$", "id": "3313464"}, {"introduction": "Standard geometric admissibility criteria can be insufficient for high-frequency problems, where the kernel's rapid oscillations can destroy compressibility even for well-separated clusters. This advanced practice explores a powerful solution using plane-wave enriched basis functions, which cancel the dominant oscillatory phase to restore a smooth, compressible residual kernel [@problem_id:3313454]. You will implement this technique and compare the standard geometric admissibility with a more sophisticated, physics-informed directional criterion essential for high-frequency analysis.", "problem": "You will implement and analyze a simplified directional hierarchical matrix model for a two-dimensional time-harmonic boundary integral operator in computational electromagnetics. The model focuses on understanding how plane-wave enriched boundary bases affect hierarchical compressibility of off-diagonal interaction blocks and alter admissibility criteria at high wavenumber. Your investigation must start from physically grounded definitions and numerically quantify rank reduction due to enrichment, while assessing admissibility changes that arise from directional criteria based on phase extraction.\n\nUse the following fundamental base: consider the two-dimensional Helmholtz equation with wavenumber $k$ (units: $\\mathrm{m}^{-1}$). The free-space Green's function for the two-dimensional Helmholtz operator is the Hankel function of the first kind $H_0^{(1)}$, and the single-layer boundary integral kernel between boundary points $\\mathbf{x}$ and $\\mathbf{y}$ is given by\n$$\nG_k(\\mathbf{x},\\mathbf{y}) \\;=\\; \\frac{\\mathrm{i}}{4}\\, H_0^{(1)}\\!\\big( k\\,\\|\\mathbf{x}-\\mathbf{y}\\| \\big),\n$$\nwhere $\\|\\cdot\\|$ denotes the Euclidean norm, $\\mathrm{i}$ is the imaginary unit, and $H_0^{(1)}$ is evaluated for real nonnegative arguments. For off-diagonal hierarchical blocks corresponding to two well-separated boundary clusters, the numerical rank depends on oscillatory phase $k\\,\\|\\mathbf{x}-\\mathbf{y}\\|$ and the angular spread of the interaction. Plane-wave enrichment modifies the boundary basis by multiplying boundary degrees of freedom with complex exponentials that approximately cancel the dominant phase, leaving a smoother residual amplitude.\n\nYour program must:\n- Discretize a circle of radius $R$ in meters by sampling $N$ equally spaced boundary points in $\\mathbb{R}^2$. Use angles in radians.\n- Define two boundary clusters $\\mathcal{A}$ and $\\mathcal{B}$ as contiguous arcs specified by index ranges of the sampled points. Compute the off-diagonal interaction block $\\mathbf{M}\\in\\mathbb{C}^{n_{\\mathcal{A}}\\times n_{\\mathcal{B}}}$ with entries $M_{ij} = G_k(\\mathbf{x}_i,\\mathbf{y}_j)$ for $\\mathbf{x}_i\\in\\mathcal{A}$ and $\\mathbf{y}_j\\in\\mathcal{B}$.\n- Compute the numerical rank of $\\mathbf{M}$ by singular value decomposition (SVD) with a relative tolerance $\\varepsilon$: count singular values $s_j$ such that $s_j/s_0 > \\varepsilon$, where $s_0$ is the largest singular value.\n- Construct a plane-wave enriched boundary basis by choosing a unit direction $\\mathbf{u}$ pointing from the centroid of $\\mathcal{A}$ to the centroid of $\\mathcal{B}$, and define diagonal modulation matrices\n$$\n\\mathbf{P}_{\\mathcal{A}} = \\operatorname{diag}\\!\\left( e^{-\\mathrm{i}\\,k\\,\\mathbf{u}\\cdot \\mathbf{x}_i} \\right),\\quad\n\\mathbf{P}_{\\mathcal{B}} = \\operatorname{diag}\\!\\left( e^{+\\mathrm{i}\\,k\\,\\mathbf{u}\\cdot \\mathbf{y}_j} \\right).\n$$\nForm the enriched block $\\mathbf{M}' = \\mathbf{P}_{\\mathcal{A}}\\,\\mathbf{M}\\,\\mathbf{P}_{\\mathcal{B}}$ and compute its numerical rank using the same tolerance.\n- Determine two admissibility booleans for the pair $(\\mathcal{A},\\mathcal{B})$:\n  1. Geometric admissibility for H-matrices: let $\\operatorname{diam}(\\mathcal{C})$ be the maximum pairwise distance between points in cluster $\\mathcal{C}$ and let $\\operatorname{dist}(\\mathcal{A},\\mathcal{B})$ be the distance between centroids. With a fixed parameter $\\eta>0$, declare geometric admissibility if\n  $$\n  \\max\\!\\big(\\operatorname{diam}(\\mathcal{A}),\\operatorname{diam}(\\mathcal{B})\\big) \\;\\le\\; \\eta\\,\\operatorname{dist}(\\mathcal{A},\\mathcal{B}).\n  $$\n  2. Directional high-frequency admissibility motivated by plane-wave enrichment: for a fixed constant $c_{\\mathrm{dir}}>0$, declare directional admissibility if\n  $$\n  k\\,\\frac{\\max\\!\\big(\\operatorname{diam}(\\mathcal{A}),\\operatorname{diam}(\\mathcal{B})\\big)^2}{\\operatorname{dist}(\\mathcal{A},\\mathcal{B})} \\;\\le\\; c_{\\mathrm{dir}}.\n  $$\n  This criterion ensures the second-order phase error under directional linearization remains small, stabilizing low-rank behavior after enrichment in the high-frequency regime.\n\nUnits and angles:\n- Distances $\\|\\mathbf{x}-\\mathbf{y}\\|$, radii $R$, diameters, and centroid distances must be in meters.\n- The wavenumber $k$ must be in $\\mathrm{m}^{-1}$.\n- All angles must be in radians.\n\nImplement the computations for the following test suite on a circle of radius $R$ with $N$ boundary points, using relative SVD tolerance $\\varepsilon$, geometric parameter $\\eta$, and directional parameter $c_{\\mathrm{dir}}$:\n\n- Test case $1$ (happy path, moderately oscillatory, well-separated):\n  - $R=1.0$, $N=160$, $\\mathcal{A}$ indices $[0,1,\\dots,39]$, $\\mathcal{B}$ indices $[80,81,\\dots,119]$,\n  - $k=5.0$, $\\varepsilon=10^{-3}$, $\\eta=2.0$, $c_{\\mathrm{dir}}=2.0$.\n- Test case $2$ (large $k$, well-separated, directional enrichment expected to reduce rank):\n  - $R=1.0$, $N=160$, $\\mathcal{A}$ indices $[0,\\dots,39]$, $\\mathcal{B}$ indices $[80,\\dots,119]$,\n  - $k=50.0$, $\\varepsilon=10^{-3}$, $\\eta=2.0$, $c_{\\mathrm{dir}}=2.0$.\n- Test case $3$ (small $k$ close to static limit, both ranks small):\n  - $R=1.0$, $N=160$, $\\mathcal{A}$ indices $[0,\\dots,39]$, $\\mathcal{B}$ indices $[80,\\dots,119]$,\n  - $k=0.5$, $\\varepsilon=10^{-3}$, $\\eta=2.0$, $c_{\\mathrm{dir}}=2.0$.\n- Test case $4$ (large $k$ but poorly separated clusters; enrichment insufficient; directional admissibility fails):\n  - $R=1.0$, $N=160$, $\\mathcal{A}$ indices $[0,\\dots,39]$, $\\mathcal{B}$ indices $[40,\\dots,79]$,\n  - $k=50.0$, $\\varepsilon=10^{-3}$, $\\eta=2.0$, $c_{\\mathrm{dir}}=2.0$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case result must be a list of four entries in the order $[\\text{rank\\_base},\\text{rank\\_enriched},\\text{geom\\_adm},\\text{dir\\_adm}]$, where $\\text{rank\\_base}$ and $\\text{rank\\_enriched}$ are integers, and $\\text{geom\\_adm}$ and $\\text{dir\\_adm}$ are booleans. For example, the overall output format must be\n$$\n[\\,[r_1^{\\mathrm{base}}, r_1^{\\mathrm{enr}}, \\text{True}, \\text{False}],\\,[r_2^{\\mathrm{base}}, r_2^{\\mathrm{enr}}, \\text{True}, \\text{True}],\\,\\dots]\n$$\nwith no additional text.", "solution": "We begin from the Helmholtz equation in two spatial dimensions for time-harmonic fields, which leads to the free-space Green's function $G_k(\\mathbf{x},\\mathbf{y}) = \\frac{\\mathrm{i}}{4} H_0^{(1)}(k\\|\\mathbf{x}-\\mathbf{y}\\|)$ for the single-layer boundary integral operator. The function $H_0^{(1)}$ encodes oscillatory behavior with phase approximately $k\\|\\mathbf{x}-\\mathbf{y}\\|$ and an amplitude that decays like $\\big(k\\|\\mathbf{x}-\\mathbf{y}\\|\\big)^{-1/2}$ for large arguments. Hierarchical matrices ($\\mathcal{H}$-matrices) represent integral operators by subdividing degrees of freedom into clusters and approximating well-separated interactions by low-rank blocks. For low to moderate $k$, blocks between two clusters $\\mathcal{A}$ and $\\mathcal{B}$ are compressible because the kernel is smooth across the block domain. For large $k$, oscillations increase numerical rank unless one accounts for directional phase.\n\nTo understand the directional enrichment, consider two clusters $\\mathcal{A}$ and $\\mathcal{B}$ with centroids $\\mathbf{c}_{\\mathcal{A}}$ and $\\mathbf{c}_{\\mathcal{B}}$, and define $\\mathbf{d} = \\mathbf{c}_{\\mathcal{B}} - \\mathbf{c}_{\\mathcal{A}}$ and the unit vector $\\mathbf{u} = \\mathbf{d}/\\|\\mathbf{d}\\|$. For $\\mathbf{x}\\in\\mathcal{A}$ and $\\mathbf{y}\\in\\mathcal{B}$, write $\\mathbf{x} = \\mathbf{c}_{\\mathcal{A}} + \\boldsymbol{\\xi}$ and $\\mathbf{y} = \\mathbf{c}_{\\mathcal{B}} + \\boldsymbol{\\eta}$, where $\\|\\boldsymbol{\\xi}\\| \\le \\operatorname{diam}(\\mathcal{A})/2$ and $\\|\\boldsymbol{\\eta}\\| \\le \\operatorname{diam}(\\mathcal{B})/2$. A first-order expansion of the distance gives\n$$\n\\|\\mathbf{x}-\\mathbf{y}\\| \\;=\\; \\|\\mathbf{d} + (\\boldsymbol{\\xi} - \\boldsymbol{\\eta})\\| \\;\\approx\\; \\|\\mathbf{d}\\| + \\mathbf{u}\\cdot(\\boldsymbol{\\xi} - \\boldsymbol{\\eta}) + \\mathcal{O}\\!\\left( \\frac{\\|\\boldsymbol{\\xi} - \\boldsymbol{\\eta}\\|^2}{\\|\\mathbf{d}\\|}\\right).\n$$\nThe dominant oscillatory phase $k\\,\\|\\mathbf{x}-\\mathbf{y}\\|$ is approximately\n$$\nk\\,\\|\\mathbf{x}-\\mathbf{y}\\| \\;\\approx\\; k\\,\\|\\mathbf{d}\\| + k\\,\\mathbf{u}\\cdot\\boldsymbol{\\xi} - k\\,\\mathbf{u}\\cdot\\boldsymbol{\\eta} + \\mathcal{O}\\!\\left(k\\,\\frac{\\|\\boldsymbol{\\xi} - \\boldsymbol{\\eta}\\|^2}{\\|\\mathbf{d}\\|}\\right).\n$$\nTherefore, if we pre-modulate boundary degrees of freedom in $\\mathcal{A}$ and $\\mathcal{B}$ by the plane waves $e^{-\\mathrm{i}k\\,\\mathbf{u}\\cdot\\mathbf{x}}$ and $e^{+\\mathrm{i}k\\,\\mathbf{u}\\cdot\\mathbf{y}}$, respectively, then the transformed kernel acquires a residual phase dominated by the constant $k\\,\\|\\mathbf{d}\\|$, while the dependence on $\\boldsymbol{\\xi}$ and $\\boldsymbol{\\eta}$ becomes much weaker, up to second-order errors on the order of $k\\,\\|\\boldsymbol{\\xi}-\\boldsymbol{\\eta}\\|^2/\\|\\mathbf{d}\\|$. This residual kernel varies slowly across the block, which reduces numerical rank. The effectiveness of this reduction depends on the magnitude of the second-order term, suggesting a directional admissibility criterion\n$$\nk\\,\\frac{\\max\\!\\big(\\operatorname{diam}(\\mathcal{A}),\\operatorname{diam}(\\mathcal{B})\\big)^{2}}{\\|\\mathbf{d}\\|} \\;\\le\\; c_{\\mathrm{dir}},\n$$\nfor some fixed constant $c_{\\mathrm{dir}}$, guaranteeing that the directional linearization error remains small. The classical geometric admissibility criterion\n$$\n\\max\\!\\big(\\operatorname{diam}(\\mathcal{A}),\\operatorname{diam}(\\mathcal{B})\\big) \\;\\le\\; \\eta\\,\\|\\mathbf{d}\\|\n$$\nensures non-oscillatory smoothness but is independent of $k$ and does not address phase oscillations for large $k$.\n\nAlgorithmic design:\n- Sample a circle of radius $R$ in meters using $N$ equally spaced angles $\\theta_j = 2\\pi j / N$, for $j=0,\\dots,N-1$, yielding points $\\mathbf{p}_j = (R\\cos\\theta_j, R\\sin\\theta_j)$.\n- Select clusters $\\mathcal{A}$ and $\\mathcal{B}$ by index ranges, yielding point sets $\\{\\mathbf{x}_i\\}$ and $\\{\\mathbf{y}_j\\}$ with $n_{\\mathcal{A}}$ and $n_{\\mathcal{B}}$ elements. Compute diameters by maximizing pairwise Euclidean distances within each cluster and centroid distance by $\\|\\mathbf{c}_{\\mathcal{B}} - \\mathbf{c}_{\\mathcal{A}}\\|$.\n- Form the complex matrix block $\\mathbf{M}$ using $G_k(\\mathbf{x}_i,\\mathbf{y}_j) = \\frac{\\mathrm{i}}{4}\\, H_0^{(1)}(k\\,\\|\\mathbf{x}_i-\\mathbf{y}_j\\|)$. For numerical stability, note that $H_0^{(1)}$ for small arguments approximates $\\sim \\frac{2\\mathrm{i}}{\\pi}\\ln(k\\,\\|\\mathbf{x}-\\mathbf{y}\\|)$ plus bounded terms, but our test suite avoids singular or near-singular configurations by using off-diagonal blocks.\n- Compute numerical rank via SVD, counting singular values above the relative threshold $\\varepsilon$ with respect to the largest singular value.\n- Compute the enriched block by $\\mathbf{M}' = \\mathbf{P}_{\\mathcal{A}}\\,\\mathbf{M}\\,\\mathbf{P}_{\\mathcal{B}}$ with $\\mathbf{P}_{\\mathcal{A}} = \\operatorname{diag}\\!\\left(e^{-\\mathrm{i}k\\,\\mathbf{u}\\cdot\\mathbf{x}_i}\\right)$ and $\\mathbf{P}_{\\mathcal{B}} = \\operatorname{diag}\\!\\left(e^{+\\mathrm{i}k\\,\\mathbf{u}\\cdot\\mathbf{y}_j}\\right)$ where $\\mathbf{u}$ is the unit vector from $\\mathbf{c}_{\\mathcal{A}}$ to $\\mathbf{c}_{\\mathcal{B}}$.\n- Evaluate admissibility booleans:\n  - Geometric admissibility: $\\max(\\operatorname{diam}(\\mathcal{A}),\\operatorname{diam}(\\mathcal{B})) \\le \\eta\\,\\operatorname{dist}(\\mathcal{A},\\mathcal{B})$.\n  - Directional admissibility: $k\\,\\max(\\operatorname{diam}(\\mathcal{A}),\\operatorname{diam}(\\mathcal{B}))^{2}/\\operatorname{dist}(\\mathcal{A},\\mathcal{B}) \\le c_{\\mathrm{dir}}$.\n\nTest suite rationale:\n- Test case $1$ uses $k=5.0$ and opposite arcs, producing moderate oscillations and strong geometric separation; both criteria likely satisfied; enrichment may slightly reduce rank.\n- Test case $2$ uses $k=50.0$ and opposite arcs; geometric admissibility holds, but oscillations elevate rank; directional enrichment should significantly reduce rank and directional admissibility should hold if the second-order error is bounded.\n- Test case $3$ uses $k=0.5$, near the static regime; both ranks are expected to be small, and admissibility criteria are satisfied.\n- Test case $4$ uses $k=50.0$ but adjacent arcs reduce centroid distance and increase diameters; geometric admissibility may fail or be marginal depending on $\\eta$, and directional admissibility should fail for the given $c_{\\mathrm{dir}}$; ranks remain high even after enrichment.\n\nThe final output must aggregate the four test case results as a single Python list containing four sublists, each of the form $[\\text{rank\\_base},\\text{rank\\_enriched},\\text{geom\\_adm},\\text{dir\\_adm}]$, printed with no extra text, matching the specified format.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import hankel1\n\ndef points_on_circle(N: int, R: float) -> np.ndarray:\n    \"\"\"Generate N points uniformly on a circle of radius R in 2D.\"\"\"\n    angles = np.linspace(0.0, 2.0 * np.pi, N, endpoint=False)\n    x = R * np.cos(angles)\n    y = R * np.sin(angles)\n    pts = np.stack([x, y], axis=1)\n    return pts\n\ndef helmholtz_2d_block(k: float, A_pts: np.ndarray, B_pts: np.ndarray) -> np.ndarray:\n    \"\"\"Construct the 2D Helmholtz single-layer off-diagonal block using H_0^{(1)}.\"\"\"\n    # Compute pairwise distances between points in A and B\n    # A_pts: (m,2), B_pts: (n,2)\n    diff = A_pts[:, None, :] - B_pts[None, :, :]  # shape (m, n, 2)\n    r = np.linalg.norm(diff, axis=2)  # shape (m, n)\n    # Avoid numerical issues at r=0 (shouldn't occur for off-diagonal blocks). If occurs, set small epsilon.\n    r = np.where(r == 0.0, 1e-15, r)\n    # 2D Helmholtz single-layer kernel: i/4 * H_0^{(1)}(k r)\n    M = 1j / 4.0 * hankel1(0, k * r)\n    return M\n\ndef numerical_rank(M: np.ndarray, rel_tol: float) -> int:\n    \"\"\"Compute numerical rank by SVD with relative tolerance.\"\"\"\n    # Use full SVD; we only need singular values\n    s = np.linalg.svd(M, compute_uv=False)\n    if s.size == 0:\n        return 0\n    s0 = s[0] if s[0] != 0 else (np.max(s) if np.max(s) != 0 else 1.0)\n    threshold = rel_tol * s0\n    rank = int(np.sum(s > threshold))\n    return rank\n\ndef cluster_diameter(pts: np.ndarray) -> float:\n    \"\"\"Compute maximum pairwise distance within a set of points.\"\"\"\n    # Efficient via broadcasting for moderate sizes\n    diff = pts[:, None, :] - pts[None, :, :]\n    dists = np.linalg.norm(diff, axis=2)\n    return float(np.max(dists))\n\ndef centroid(pts: np.ndarray) -> np.ndarray:\n    \"\"\"Compute centroid (mean) of points.\"\"\"\n    return np.mean(pts, axis=0)\n\ndef directional_enrichment_block(k: float, A_pts: np.ndarray, B_pts: np.ndarray, M: np.ndarray) -> np.ndarray:\n    \"\"\"Apply plane-wave modulation to form enriched block.\"\"\"\n    cA = centroid(A_pts)\n    cB = centroid(B_pts)\n    d = cB - cA\n    norm_d = np.linalg.norm(d)\n    if norm_d == 0.0:\n        # Degenerate: no direction; return original\n        return M\n    u = d / norm_d\n    phase_A = np.exp(-1j * k * (A_pts @ u))\n    phase_B = np.exp(+1j * k * (B_pts @ u))\n    P_A = np.diag(phase_A)\n    P_B = np.diag(phase_B)\n    M_enr = P_A @ M @ P_B\n    return M_enr\n\ndef geometric_admissibility(diamA: float, diamB: float, distAB: float, eta: float) -> bool:\n    \"\"\"Standard geometric admissibility: max(diam) <= eta * dist.\"\"\"\n    return max(diamA, diamB) <= eta * distAB\n\ndef directional_admissibility(k: float, diamA: float, diamB: float, distAB: float, c_dir: float) -> bool:\n    \"\"\"Directional high-frequency admissibility: k * max(diam)^2 / dist <= c_dir.\"\"\"\n    # Avoid division by zero\n    if distAB == 0.0:\n        return False\n    return (k * (max(diamA, diamB) ** 2) / distAB) <= c_dir\n\ndef run_case(R: float, N: int, idxA_start: int, lenA: int, idxB_start: int, lenB: int,\n             k: float, svd_tol: float, eta: float, c_dir: float):\n    pts = points_on_circle(N, R)\n    # Wrap indices in case of overflow\n    idxA = np.arange(idxA_start, idxA_start + lenA) % N\n    idxB = np.arange(idxB_start, idxB_start + lenB) % N\n    A_pts = pts[idxA]\n    B_pts = pts[idxB]\n    # Build block\n    M = helmholtz_2d_block(k, A_pts, B_pts)\n    # Base rank\n    r_base = numerical_rank(M, svd_tol)\n    # Enriched block and rank\n    M_enr = directional_enrichment_block(k, A_pts, B_pts, M)\n    r_enr = numerical_rank(M_enr, svd_tol)\n    # Admissibility checks\n    diamA = cluster_diameter(A_pts)\n    diamB = cluster_diameter(B_pts)\n    distAB = float(np.linalg.norm(centroid(B_pts) - centroid(A_pts)))\n    adm_geom = geometric_admissibility(diamA, diamB, distAB, eta)\n    adm_dir = directional_admissibility(k, diamA, diamB, distAB, c_dir)\n    return [int(r_base), int(r_enr), bool(adm_geom), bool(adm_dir)]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (R, N, idxA_start, lenA, idxB_start, lenB, k, svd_tol, eta, c_dir)\n        (1.0, 160, 0, 40, 80, 40, 5.0, 1e-3, 2.0, 2.0),    # Test case 1\n        (1.0, 160, 0, 40, 80, 40, 50.0, 1e-3, 2.0, 2.0),   # Test case 2\n        (1.0, 160, 0, 40, 80, 40, 0.5, 1e-3, 2.0, 2.0),    # Test case 3\n        (1.0, 160, 0, 40, 40, 40, 50.0, 1e-3, 2.0, 2.0),   # Test case 4\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(*case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3313454"}]}