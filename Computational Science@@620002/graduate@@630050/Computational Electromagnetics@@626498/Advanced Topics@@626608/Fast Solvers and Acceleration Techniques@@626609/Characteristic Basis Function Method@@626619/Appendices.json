{"hands_on_practices": [{"introduction": "The primary motivation for employing advanced techniques like the Characteristic Basis Function Method (CBFM) is to solve electrically large problems that are intractable for the conventional Method of Moments (MoM). Before diving into the theoretical details, it is instructive to perform a straightforward calculation to appreciate the scale of the computational savings. This first exercise [@problem_id:3292505] provides a tangible understanding of how replacing a large number of elementary basis functions with a much smaller set of macro-basis functions dramatically reduces memory requirements.", "problem": "A perfectly electrically conducting scatterer is modeled with the Method of Moments (MoM) using Rao–Wilton–Glisson (RWG) basis functions, producing a dense impedance matrix $\\mathbf{Z}\\in\\mathbb{C}^{N\\times N}$ with $N=6.4\\times 10^{4}$ unknowns. Under the dense storage assumption, the memory required to store $\\mathbf{Z}$ is proportional to the number of its entries. The scatterer is partitioned into $P=16$ contiguous subdomains, and the Characteristic Basis Function Method (CBFM) is applied by constructing $M_p$ characteristic basis functions on each subdomain $p\\in\\{1,\\dots,16\\}$, where the counts are\n$$\nM_1=160,\\;M_2=180,\\;M_3=190,\\;M_4=200,\\;M_5=210,\\;M_6=220,\\;M_7=190,\\;M_8=230,\\\\\nM_9=210,\\;M_{10}=170,\\;M_{11}=200,\\;M_{12}=180,\\;M_{13}=220,\\;M_{14}=210,\\;M_{15}=190,\\;M_{16}=240.\n$$\nLet $M=\\sum_{p=1}^{16} M_p$ denote the total number of characteristic basis functions, so that the reduced CBFM coupling matrix is $\\mathbf{Z}_c\\in\\mathbb{C}^{M\\times M}$ and is also dense. Using only foundational principles that (i) dense storage for a matrix of size $n\\times n$ scales with $n^2$ and (ii) CBFM replaces the original RWG basis with a reduced set of macro-basis functions of total count $M$, compute the reduction ratio $r$, defined as the total number of characteristic basis functions divided by the original number of unknowns, and estimate the fractional memory savings obtained by storing $\\mathbf{Z}_c$ instead of $\\mathbf{Z}$ under dense storage assumptions. Express both quantities as decimal fractions and round your answers to four significant figures. Provide your final result as a row matrix $\\begin{pmatrix} r & \\text{memory\\_savings} \\end{pmatrix}$ with no units.", "solution": "The problem statement has been validated and is deemed valid. It is scientifically sound, well-posed, and contains all necessary information to derive a unique solution. The context and parameters are consistent with standard practices in computational electromagnetics concerning the application of the Method of Moments (MoM) and the Characteristic Basis Function Method (CBFM).\n\nThe first step is to calculate the total number of characteristic basis functions (CBFs), denoted by $M$. This is the sum of the CBFs constructed on each of the $P=16$ subdomains.\n$$\nM = \\sum_{p=1}^{16} M_p\n$$\nSubstituting the given values for $M_p$:\n$$\nM = 160 + 180 + 190 + 200 + 210 + 220 + 190 + 230 + 210 + 170 + 200 + 180 + 220 + 210 + 190 + 240\n$$\nSumming these values yields:\n$$\nM = 3200\n$$\nThe problem defines the reduction ratio, $r$, as the total number of characteristic basis functions divided by the original number of unknowns. The original number of unknowns is given as $N = 6.4 \\times 10^{4} = 64000$.\n$$\nr = \\frac{M}{N}\n$$\nSubstituting the values for $M$ and $N$:\n$$\nr = \\frac{3200}{64000} = \\frac{32}{640} = \\frac{1}{20} = 0.05\n$$\nThe problem requires this value to be expressed as a decimal fraction rounded to four significant figures.\n$$\nr \\approx 0.05000\n$$\nNext, we estimate the fractional memory savings. The problem states that for a dense matrix of size $n \\times n$, the memory required for storage scales with $n^2$. Let the memory required to store a dense $k \\times k$ complex matrix be $C \\cdot k^2$, where $C$ is a constant of proportionality related to the storage cost per complex entry.\n\nThe memory required to store the original dense impedance matrix $\\mathbf{Z} \\in \\mathbb{C}^{N \\times N}$ is:\n$$\n\\text{Mem}_{\\mathbf{Z}} = C \\cdot N^2\n$$\nThe memory required to store the reduced dense CBFM coupling matrix $\\mathbf{Z}_c \\in \\mathbb{C}^{M \\times M}$ is:\n$$\n\\text{Mem}_{\\mathbf{Z}_c} = C \\cdot M^2\n$$\nThe fractional memory savings, which we denote by $S$, is the reduction in memory relative to the original memory requirement.\n$$\nS = \\frac{\\text{Mem}_{\\mathbf{Z}} - \\text{Mem}_{\\mathbf{Z}_c}}{\\text{Mem}_{\\mathbf{Z}}} = \\frac{C N^2 - C M^2}{C N^2} = 1 - \\frac{M^2}{N^2}\n$$\nThis expression can be rewritten in terms of the reduction ratio $r = \\frac{M}{N}$:\n$$\nS = 1 - \\left(\\frac{M}{N}\\right)^2 = 1 - r^2\n$$\nSubstituting the calculated value of $r=0.05$:\n$$\nS = 1 - (0.05)^2 = 1 - 0.0025 = 0.9975\n$$\nThis value is already expressed with four significant figures.\n\nThe final answer requires the reduction ratio $r$ and the fractional memory savings $S$ presented as a row matrix. The required values are $r \\approx 0.05000$ and $S = 0.9975$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.05000 & 0.9975 \\end{pmatrix}}\n$$", "id": "3292505"}, {"introduction": "Having established the significant computational advantages of CBFM, we now turn to the mechanics of how this reduction is achieved. The core idea is to project the full-system operator, represented by the impedance matrix $\\mathbf{Z}$, onto a lower-dimensional subspace spanned by the characteristic basis functions (CBFs). This exercise [@problem_id:3292539] makes this concept concrete by guiding you through the calculation of the reduced impedance matrix $\\mathbf{Z}_r$ from the full matrix and a given set of CBFs, demonstrating the fundamental operation $\\mathbf{Z}_r = \\mathbf{T}^H \\mathbf{Z} \\mathbf{T}$.", "problem": "A perfectly electrically conducting surface is partitioned into two contiguous subdomains, each meshed with three Rao–Wilton–Glisson (RWG) basis functions. The unknown surface current density is expanded in these six RWG functions and tested in the Method of Moments (MoM) discretization of the Electric Field Integral Equation (EFIE). A reduced-order model is formed using the Characteristic Basis Function Method (CBFM) by projecting the EFIE operator onto two composite characteristic basis functions, one per subdomain, resulting in a reduced Galerkin system.\n\nStart from Maxwell’s equations in the frequency domain and the perfect electric conductor boundary condition, use the standard EFIE with the free-space dyadic Green’s function, describe the MoM Galerkin procedure in RWG basis, and then explain how the CBFM projection constructs a reduced operator on the span of the two composite characteristic basis functions. From these principles, derive the expression for the reduced Galerkin operator between two composite characteristic basis functions as an inner product of tested RWG expansions against the EFIE operator applied to RWG expansions, and assemble the reduced $2 \\times 2$ system.\n\nFor a symmetric configuration at angular frequency $\\omega$ where the full MoM impedance operator is approximated by the block matrix\n$$\nZ \\in \\mathbb{C}^{6 \\times 6}\n=\n\\begin{pmatrix}\nZ_{11} & Z_{12} \\\\\nZ_{21} & Z_{22}\n\\end{pmatrix},\n$$\nwith\n$$\nZ_{11} = (5 + \\mathrm{i}\\,2)\\, I_{3}, \\quad\nZ_{22} = (4 + \\mathrm{i}\\,1)\\, I_{3}, \\quad\nZ_{12} = Z_{21}^{\\top} = (0.6 + \\mathrm{i}\\,0.3)\\, \\mathbf{1}_{3 \\times 3},\n$$\nwhere $I_{3}$ is the $3 \\times 3$ identity matrix and $\\mathbf{1}_{3 \\times 3}$ is the $3 \\times 3$ matrix of ones, consider the two composite characteristic basis functions represented in the RWG expansion by the columns of the matrix\n$$\nT \\in \\mathbb{R}^{6 \\times 2} =\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{3}} & 0 \\\\\n\\frac{1}{\\sqrt{3}} & 0 \\\\\n\\frac{1}{\\sqrt{3}} & 0 \\\\\n0 & \\frac{1}{\\sqrt{3}} \\\\\n0 & \\frac{1}{\\sqrt{3}} \\\\\n0 & \\frac{1}{\\sqrt{3}}\n\\end{pmatrix},\n$$\nso that the first composite basis function is the uniform combination on subdomain $1$ and the second is the uniform combination on subdomain $2$, each normalized by $\\sqrt{3}$.\n\nUsing the CBFM projection and reduced assembly derived from first principles, form the reduced $2 \\times 2$ Galerkin operator and compute the real part of its determinant. Express the final value in $\\mathrm{\\Omega}^{2}$ and round your answer to four significant figures.", "solution": "The problem requires the derivation of the reduced Galerkin operator in the Characteristic Basis Function Method (CBFM) starting from fundamental principles, followed by a specific calculation for a given full impedance matrix and a set of composite basis functions.\n\nThe analysis begins with Maxwell's equations in the frequency domain, assuming a time-harmonic dependence of the form $\\exp(\\mathrm{i}\\omega t)$:\n$$\n\\nabla \\times \\mathbf{E}(\\mathbf{r}) = -\\mathrm{i}\\omega\\mu\\mathbf{H}(\\mathbf{r})\n$$\n$$\n\\nabla \\times \\mathbf{H}(\\mathbf{r}) = \\mathbf{J}(\\mathbf{r}) + \\mathrm{i}\\omega\\epsilon\\mathbf{E}(\\mathbf{r})\n$$\nwhere $\\mathbf{E}$ is the electric field, $\\mathbf{H}$ is the magnetic field, $\\mathbf{J}$ is the current density, $\\omega$ is the angular frequency, and $\\mu$ and $\\epsilon$ are the permeability and permittivity of the medium, respectively.\n\nFor a perfect electric conductor (PEC) surface $S$ illuminated by an incident electric field $\\mathbf{E}^i$, an induced surface current $\\mathbf{J}_s$ is generated. This current produces a scattered field $\\mathbf{E}^s$. The boundary condition on the PEC surface is that the total tangential electric field must be zero:\n$$\n[\\mathbf{E}^i(\\mathbf{r}) + \\mathbf{E}^s(\\mathbf{r})]_{\\text{tan}} = 0 \\quad \\text{for } \\mathbf{r} \\in S\n$$\nThe scattered field $\\mathbf{E}^s$ can be expressed in terms of the induced current $\\mathbf{J}_s$ via the magnetic vector potential $\\mathbf{A}$ and the scalar electric potential $\\Phi$:\n$$\n\\mathbf{E}^s(\\mathbf{r}) = -\\mathrm{i}\\omega\\mathbf{A}(\\mathbf{r}) - \\nabla\\Phi(\\mathbf{r})\n$$\nThe potentials are related to the surface sources ($\\mathbf{J}_s$ and surface charge density $\\rho_s$) through the free-space dyadic Green's function $G(\\mathbf{r}, \\mathbf{r}') = \\frac{\\exp(-\\mathrm{i}k|\\mathbf{r}-\\mathbf{r}'|)}{4\\pi|\\mathbf{r}-\\mathbf{r}'|}$, where $k = \\omega\\sqrt{\\mu\\epsilon}$ is the wavenumber.\n$$\n\\mathbf{A}(\\mathbf{r}) = \\mu \\int_S G(\\mathbf{r}, \\mathbf{r}') \\mathbf{J}_s(\\mathbf{r}') dS'\n$$\n$$\n\\Phi(\\mathbf{r}) = \\frac{1}{\\epsilon} \\int_S G(\\mathbf{r}, \\mathbf{r}') \\rho_s(\\mathbf{r}') dS'\n$$\nUsing the continuity equation $\\nabla_s \\cdot \\mathbf{J}_s = -\\mathrm{i}\\omega\\rho_s$, we can write the Electric Field Integral Equation (EFIE) by enforcing the PEC boundary condition:\n$$\n[\\mathrm{i}\\omega\\mu \\int_S G(\\mathbf{r}, \\mathbf{r}') \\mathbf{J}_s(\\mathbf{r}') dS' + \\frac{\\mathrm{i}}{\\omega\\epsilon} \\nabla \\int_S G(\\mathbf{r}, \\mathbf{r}') (\\nabla'_s \\cdot \\mathbf{J}_s(\\mathbf{r}')) dS']_{\\text{tan}} = [\\mathbf{E}^i(\\mathbf{r})]_{\\text{tan}}\n$$\nWe define the linear operator $\\mathcal{L}$ such that the EFIE is written compactly as $\\mathcal{L}(\\mathbf{J}_s) = \\mathbf{E}^i_{\\text{tan}}$.\n\nIn the Method of Moments (MoM), the unknown current $\\mathbf{J}_s$ is expanded in a set of $N$ basis functions $\\{\\mathbf{f}_n(\\mathbf{r})\\}_{n=1}^N$, which are the Rao–Wilton–Glisson (RWG) functions in this problem.\n$$\n\\mathbf{J}_s(\\mathbf{r}) \\approx \\sum_{n=1}^{N} I_n \\mathbf{f}_n(\\mathbf{r})\n$$\nwhere $I_n$ are unknown complex coefficients. Substituting this expansion into the EFIE and applying Galerkin's method, we test the equation with each basis function $\\mathbf{f}_m$. This involves taking an inner product, defined as $\\langle \\mathbf{a}, \\mathbf{b} \\rangle = \\int_S \\mathbf{a}^*(\\mathbf{r}) \\cdot \\mathbf{b}(\\mathbf{r}) dS$. The result is a system of linear equations:\n$$\n\\sum_{n=1}^{N} I_n \\langle \\mathbf{f}_m, \\mathcal{L}(\\mathbf{f}_n) \\rangle = \\langle \\mathbf{f}_m, \\mathbf{E}^i_{\\text{tan}} \\rangle \\quad \\text{for } m=1, \\dots, N\n$$\nThis system is written in matrix form as $Z I = V$, where $Z$ is the $N \\times N$ impedance matrix with elements $Z_{mn} = \\langle \\mathbf{f}_m, \\mathcal{L}(\\mathbf{f}_n) \\rangle$, $I$ is the column vector of coefficients $I_n$, and $V$ is the excitation vector with elements $V_m = \\langle \\mathbf{f}_m, \\mathbf{E}^i_{\\text{tan}} \\rangle$. Note that for Galerkin testing with real basis functions, the complex conjugate on $\\mathbf{f}_m$ in the inner product is irrelevant for the spatial part, but the inner product is sesquilinear. The standard definition of the MoM matrix entry is $Z_{mn}=\\int_S \\mathbf{f}_m \\cdot \\mathcal{L}(\\mathbf{f}_n) dS$.\n\nThe Characteristic Basis Function Method (CBFM) is a model order reduction technique. The current $\\mathbf{J}_s$ is approximated by a small number of composite basis functions, called characteristic basis functions (CBFs), $\\{\\mathbf{\\Psi}_k\\}_{k=1}^P$, where $P \\ll N$. Each CBF is a linear combination of the original RWG basis functions:\n$$\n\\mathbf{\\Psi}_k(\\mathbf{r}) = \\sum_{n=1}^{N} T_{nk} \\mathbf{f}_n(\\mathbf{r})\n$$\nThe coefficients $T_{nk}$ form an $N \\times P$ transformation matrix $T$. The current is now approximated as:\n$$\n\\mathbf{J}_s(\\mathbf{r}) \\approx \\sum_{k=1}^{P} \\alpha_k \\mathbf{\\Psi}_k(\\mathbf{r}) = \\sum_{k=1}^{P} \\alpha_k \\sum_{n=1}^{N} T_{nk} \\mathbf{f}_n(\\mathbf{r})\n$$\nThis implies that the vector of RWG coefficients $I$ is approximated by $I \\approx T\\alpha$, where $\\alpha$ is the $P \\times 1$ vector of unknown coefficients $\\alpha_k$.\n\nTo find $\\alpha$, we substitute $I = T\\alpha$ into the full system $ZI=V$, yielding $ZT\\alpha = V$. We then use Galerkin's method on this reduced-basis representation, testing with the CBFs themselves. The testing function $\\mathbf{\\Psi}_j$ is represented in the RWG basis as $\\sum_m T_{mj} \\mathbf{f}_m$. The reduced system is:\n$$\n\\langle \\mathbf{\\Psi}_j, \\mathcal{L}(\\sum_{k=1}^P \\alpha_k \\mathbf{\\Psi}_k) \\rangle = \\langle \\mathbf{\\Psi}_j, \\mathbf{E}^i_{\\text{tan}} \\rangle \\quad \\text{for } j=1, \\dots, P\n$$\nThe reduced system is $Z_r \\alpha = V_r$. The elements of the reduced impedance matrix $Z_r$ are:\n$$\n(Z_r)_{jk} = \\langle \\mathbf{\\Psi}_j, \\mathcal{L}(\\mathbf{\\Psi}_k) \\rangle = \\langle \\sum_{m=1}^N T_{mj} \\mathbf{f}_m, \\mathcal{L}(\\sum_{n=1}^N T_{nk} \\mathbf{f}_n) \\rangle\n$$\nUsing the sesquilinearity of the inner product and linearity of $\\mathcal{L}$:\n$$\n(Z_r)_{jk} = \\sum_{m=1}^N \\sum_{n=1}^N T_{mj}^* T_{nk} \\langle \\mathbf{f}_m, \\mathcal{L}(\\mathbf{f}_n) \\rangle = \\sum_{m=1}^N \\sum_{n=1}^N T_{mj}^* Z_{mn} T_{nk}\n$$\nIn matrix notation, this is $Z_r = T^H Z T$, where $T^H$ is the conjugate transpose of $T$. Since the problem specifies $T \\in \\mathbb{R}^{6 \\times 2}$, its conjugate transpose is simply its transpose, $T^H = T^\\top$. So, $Z_r = T^\\top Z T$.\n\nNow, we perform the calculation for the specific problem. We are given $N=6$, $P=2$.\nThe full impedance matrix is $Z \\in \\mathbb{C}^{6 \\times 6}$ with blocks:\n$Z_{11} = (5 + \\mathrm{i}\\,2)\\, I_{3}$, $Z_{22} = (4 + \\mathrm{i}\\,1)\\, I_{3}$, and $Z_{12} = Z_{21}^{\\top} = (0.6 + \\mathrm{i}\\,0.3)\\, \\mathbf{1}_{3 \\times 3}$. Since $\\mathbf{1}_{3 \\times 3}$ is a symmetric matrix, $Z_{21}^{\\top} = Z_{12}$ implies $Z_{21} = Z_{12}$.\nThe transformation matrix is $T \\in \\mathbb{R}^{6 \\times 2}$:\n$$\nT =\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{3}} & 0 \\\\\n\\frac{1}{\\sqrt{3}} & 0 \\\\\n\\frac{1}{\\sqrt{3}} & 0 \\\\\n0 & \\frac{1}{\\sqrt{3}} \\\\\n0 & \\frac{1}{\\sqrt{3}} \\\\\n0 & \\frac{1}{\\sqrt{3}}\n\\end{pmatrix}\n$$\nWe can partition $T$ into $T = \\begin{pmatrix} T_1 \\\\ T_2 \\end{pmatrix}$, where $T_1 = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 1 & 0 \\\\ 1 & 0 \\\\ 1 & 0 \\end{pmatrix}$ and $T_2 = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 0 & 1 \\\\ 0 & 1 \\\\ 0 & 1 \\end{pmatrix}$.\nThe reduced impedance matrix $Z_r$ is calculated as:\n$$\nZ_r = T^\\top Z T = \\begin{pmatrix} T_1^\\top & T_2^\\top \\end{pmatrix} \\begin{pmatrix} Z_{11} & Z_{12} \\\\ Z_{21} & Z_{22} \\end{pmatrix} \\begin{pmatrix} T_1 \\\\ T_2 \\end{pmatrix} = T_1^\\top Z_{11} T_1 + T_1^\\top Z_{12} T_2 + T_2^\\top Z_{21} T_1 + T_2^\\top Z_{22} T_2\n$$\nLet the columns of $T$ be $\\mathbf{t}_1, \\mathbf{t}_2$. Then $(Z_r)_{jk} = \\mathbf{t}_j^\\top Z \\mathbf{t}_k$.\n$\\mathbf{t}_1 = \\frac{1}{\\sqrt{3}}[1,1,1,0,0,0]^\\top$ and $\\mathbf{t}_2 = \\frac{1}{\\sqrt{3}}[0,0,0,1,1,1]^\\top$. Let $\\mathbf{u} = [1,1,1]^\\top$.\n\n$(Z_r)_{11} = \\mathbf{t}_1^\\top Z \\mathbf{t}_1 = \\frac{1}{3} \\begin{pmatrix} \\mathbf{u}^\\top & \\mathbf{0}^\\top \\end{pmatrix} \\begin{pmatrix} Z_{11} & Z_{12} \\\\ Z_{21} & Z_{22} \\end{pmatrix} \\begin{pmatrix} \\mathbf{u} \\\\ \\mathbf{0} \\end{pmatrix} = \\frac{1}{3} \\mathbf{u}^\\top Z_{11} \\mathbf{u}$.\n$Z_{11} = (5 + \\mathrm{i}\\,2)I_3$, so $\\mathbf{u}^\\top Z_{11} \\mathbf{u} = (5 + \\mathrm{i}\\,2) \\mathbf{u}^\\top I_3 \\mathbf{u} = (5 + \\mathrm{i}\\,2) \\|\\mathbf{u}\\|^2 = 3(5 + \\mathrm{i}\\,2)$.\n$(Z_r)_{11} = \\frac{1}{3} \\times 3(5 + \\mathrm{i}\\,2) = 5 + \\mathrm{i}\\,2$.\n\n$(Z_r)_{22} = \\mathbf{t}_2^\\top Z \\mathbf{t}_2 = \\frac{1}{3} \\begin{pmatrix} \\mathbf{0}^\\top & \\mathbf{u}^\\top \\end{pmatrix} Z \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{u} \\end{pmatrix} = \\frac{1}{3} \\mathbf{u}^\\top Z_{22} \\mathbf{u}$.\n$Z_{22} = (4 + \\mathrm{i}\\,1)I_3$, so $\\mathbf{u}^\\top Z_{22} \\mathbf{u} = (4 + \\mathrm{i}\\,1) \\|\\mathbf{u}\\|^2 = 3(4 + \\mathrm{i}\\,1)$.\n$(Z_r)_{22} = \\frac{1}{3} \\times 3(4 + \\mathrm{i}\\,1) = 4 + \\mathrm{i}\\,1$.\n\n$(Z_r)_{12} = \\mathbf{t}_1^\\top Z \\mathbf{t}_2 = \\frac{1}{3} \\begin{pmatrix} \\mathbf{u}^\\top & \\mathbf{0}^\\top \\end{pmatrix} Z \\begin{pmatrix} \\mathbf{0} \\\\ \\mathbf{u} \\end{pmatrix} = \\frac{1}{3} \\mathbf{u}^\\top Z_{12} \\mathbf{u}$.\n$Z_{12} = (0.6 + \\mathrm{i}\\,0.3)\\mathbf{1}_{3\\times3}$, so $\\mathbf{u}^\\top Z_{12} \\mathbf{u} = (0.6 + \\mathrm{i}\\,0.3) \\mathbf{u}^\\top \\mathbf{1}_{3\\times3} \\mathbf{u}$.\n$\\mathbf{1}_{3\\times3} \\mathbf{u} = [3,3,3]^\\top$, thus $\\mathbf{u}^\\top (\\mathbf{1}_{3\\times3} \\mathbf{u}) = [1,1,1][3,3,3]^\\top = 9$.\n$\\mathbf{u}^\\top Z_{12} \\mathbf{u} = 9(0.6 + \\mathrm{i}\\,0.3) = 5.4 + \\mathrm{i}\\,2.7$.\n$(Z_r)_{12} = \\frac{1}{3} (5.4 + \\mathrm{i}\\,2.7) = 1.8 + \\mathrm{i}\\,0.9$.\n\n$(Z_r)_{21} = \\mathbf{t}_2^\\top Z \\mathbf{t}_1 = \\frac{1}{3} \\mathbf{u}^\\top Z_{21} \\mathbf{u}$. Since $Z_{21} = Z_{12}$, $(Z_r)_{21} = (Z_r)_{12}$.\nThe reduced $2 \\times 2$ Galerkin operator is:\n$$\nZ_r = \\begin{pmatrix}\n5 + \\mathrm{i}\\,2 & 1.8 + \\mathrm{i}\\,0.9 \\\\\n1.8 + \\mathrm{i}\\,0.9 & 4 + \\mathrm{i}\\,1\n\\end{pmatrix}\n$$\nThe determinant of $Z_r$ is:\n$$\n\\det(Z_r) = (5 + \\mathrm{i}\\,2)(4 + \\mathrm{i}\\,1) - (1.8 + \\mathrm{i}\\,0.9)^2\n$$\nThe first term is:\n$$\n(5 + \\mathrm{i}\\,2)(4 + \\mathrm{i}\\,1) = (5 \\times 4 - 2 \\times 1) + \\mathrm{i}(5 \\times 1 + 2 \\times 4) = (20 - 2) + \\mathrm{i}(5 + 8) = 18 + \\mathrm{i}\\,13\n$$\nThe second term is:\n$$\n(1.8 + \\mathrm{i}\\,0.9)^2 = 1.8^2 + 2(\\mathrm{i})(1.8)(0.9) + (\\mathrm{i}\\,0.9)^2 = 3.24 + \\mathrm{i}\\,3.24 - 0.81 = 2.43 + \\mathrm{i}\\,3.24\n$$\nTherefore, the determinant is:\n$$\n\\det(Z_r) = (18 + \\mathrm{i}\\,13) - (2.43 + \\mathrm{i}\\,3.24) = (18 - 2.43) + \\mathrm{i}(13 - 3.24) = 15.57 + \\mathrm{i}\\,9.76\n$$\nThe problem asks for the real part of the determinant, which is:\n$$\n\\mathrm{Re}(\\det(Z_r)) = 15.57\n$$\nThe units are impedance squared, or $\\mathrm{\\Omega}^2$. The value $15.57$ is already given to four significant figures.", "answer": "$$\\boxed{15.57}$$", "id": "3292539"}, {"introduction": "Model order reduction inherently introduces an approximation error. A crucial practical question is: how accurate is our CBFM solution? This final practice [@problem_id:3292540] introduces the concept of a posteriori error estimation, a powerful tool for assessing the quality of the solution without knowing the exact answer. By computing estimators based on the system residual, we can quantify the approximation error and establish an automated criterion for adaptively enriching the CBF basis until a desired accuracy is met.", "problem": "Consider a frequency-domain scattering problem discretized by the Method of Moments (MoM), for which the Electric Field Integral Equation (EFIE) leads to a non-Hermitian linear system of the form $\\mathbf{Z}\\mathbf{x}=\\mathbf{b}$, where $\\mathbf{Z}\\in\\mathbb{C}^{N\\times N}$ is the impedance matrix, $\\mathbf{x}\\in\\mathbb{C}^{N}$ is the vector of surface current expansion coefficients, and $\\mathbf{b}\\in\\mathbb{C}^{N}$ is the excitation vector. In the Characteristic Basis Function Method (CBFM), a coarse subspace approximation is used: $\\mathbf{x}\\approx \\mathbf{W}\\mathbf{x}_c$, where $\\mathbf{W}\\in\\mathbb{C}^{N\\times n_c}$ (with $n_c\\leq N$) collects the characteristic basis functions, and $\\mathbf{x}_c\\in\\mathbb{C}^{n_c}$ are the corresponding coarse coefficients. The algebraic residual is $\\mathbf{r}=\\mathbf{b}-\\mathbf{Z}\\mathbf{W}\\mathbf{x}_c$.\n\nStarting from the discrete system and the notion that for passive electromagnetic systems the Hermitian part of $\\mathbf{Z}$, $\\mathbf{S}=\\tfrac{1}{2}(\\mathbf{Z}+\\mathbf{Z}^H)$, is positive semidefinite, derive residual-based a posteriori error estimators that can drive adaptive enrichment of the CBF set. Use the following two estimators:\n\n- The Euclidean norm-based residual estimator $\\eta_2=\\|\\mathbf{r}\\|_2$.\n- The energy-dual residual estimator induced by the Hermitian part with Tikhonov regularization parameter $\\tau>0$:\n$$\n\\eta_E=\\sqrt{\\mathbf{r}^H\\mathbf{M}^{-1}\\mathbf{r}},\\quad \\mathbf{M}=\\tfrac{1}{2}(\\mathbf{Z}+\\mathbf{Z}^H)+\\tau \\mathbf{I},\n$$\nwhere $\\mathbf{I}$ is the identity matrix. The regularization parameter $\\tau$ guarantees that $\\mathbf{M}$ is Hermitian positive definite even when $\\tfrac{1}{2}(\\mathbf{Z}+\\mathbf{Z}^H)$ is only semidefinite.\n\nYour task is to produce a complete program that, for each provided test case, computes $\\mathbf{r}$, $\\eta_2$, and $\\eta_E$, and then decides whether to enrich the CBF set based on the decision rule $\\eta_E > t$, where $t$ is a given threshold. The final result for each test case must be a three-element list $[\\eta_2,\\eta_E,\\text{decision}]$, where $\\eta_2$ and $\\eta_E$ are rounded to $6$ decimals, and $\\text{decision}$ is a boolean. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[\\text{result}_1,\\text{result}_2,\\text{result}_3]$).\n\nImplement your solution for the following test suite. All matrices and vectors are given explicitly. For complex numbers, the imaginary unit is $\\mathrm{j}$.\n\nTest case $1$ (general complex, happy path):\n- $N=4$, $n_c=2$.\n- $$ \\mathbf{Z}_1=\\begin{bmatrix}\n2+1\\mathrm{j} & 0.5-0.2\\mathrm{j} & 0 & 0\\\\\n0.5+0.2\\mathrm{j} & 1.5+0.8\\mathrm{j} & 0.3 & 0\\\\\n0 & 0.3 & 1.2+0.5\\mathrm{j} & 0.1-0.1\\mathrm{j}\\\\\n0 & 0 & 0.1+0.1\\mathrm{j} & 1+0.3\\mathrm{j}\n\\end{bmatrix} $$\n- $$ \\mathbf{W}_1=\\begin{bmatrix}\n1 & 0\\\\\n0 & 1\\\\\n0.2 & -0.1\\\\\n0 & 0.3\n\\end{bmatrix} $$\n- $$ \\mathbf{x}_{c,1}=\\begin{bmatrix}1-0.5\\mathrm{j}\\\\0.8+0.2\\mathrm{j}\\end{bmatrix} $$\n$$ \\mathbf{b}_1=\\begin{bmatrix}1+0\\mathrm{j}\\\\0.5+0.2\\mathrm{j}\\\\0.1-0.1\\mathrm{j}\\\\-0.3+0.4\\mathrm{j}\\end{bmatrix} $$\n- $\\tau_1=10^{-3}$, $t_1=0.5$\n\nTest case $2$ (coarse equals full, zero approximation):\n- $N=3$, $n_c=3$.\n- $$ \\mathbf{Z}_2=\\begin{bmatrix}\n1 & 0.2 & 0\\\\\n0.2 & 0.9 & 0.1\\\\\n0 & 0.1 & 1.1\n\\end{bmatrix} + \\mathrm{j}\\begin{bmatrix}\n0.3 & -0.1 & 0.05\\\\\n0.1 & 0.2 & -0.06\\\\\n-0.05 & 0.06 & 0.1\n\\end{bmatrix} $$\n- $$ \\mathbf{W}_2=\\mathbf{I}_3 $$\n- $$ \\mathbf{x}_{c,2}=\\begin{bmatrix}0\\\\0\\\\0\\end{bmatrix} $$\n$$ \\mathbf{b}_2=\\begin{bmatrix}0.5-0.2\\mathrm{j}\\\\-0.3+0.1\\mathrm{j}\\\\0.2+0.05\\mathrm{j}\\end{bmatrix} $$\n- $\\tau_2=10^{-4}$, $t_2=0.25$\n\nTest case $3$ (nearly singular Hermitian part, regularization active):\n- $N=3$, $n_c=2$.\n- $$ \\mathbf{Z}_3=\\mathrm{j}\\begin{bmatrix}\n2 & -0.5 & 0\\\\\n0.5 & 1.5 & -0.3\\\\\n0 & 0.3 & 1\n\\end{bmatrix} + \\begin{bmatrix}\n10^{-3} & 0 & 0\\\\\n0 & 1.5\\cdot 10^{-3} & 0\\\\\n0 & 0 & 10^{-3}\n\\end{bmatrix} $$\n- $$ \\mathbf{W}_3=\\begin{bmatrix}\n1 & 0\\\\\n0.2 & 1\\\\\n0 & -0.1\n\\end{bmatrix} $$\n- $$ \\mathbf{x}_{c,3}=\\begin{bmatrix}0.7-0.3\\mathrm{j}\\\\-0.2+0.5\\mathrm{j}\\end{bmatrix} $$\n$$ \\mathbf{b}_3=\\begin{bmatrix}0.1+0.2\\mathrm{j}\\\\-0.05+0.1\\mathrm{j}\\\\0.02-0.03\\mathrm{j}\\end{bmatrix} $$\n- $\\tau_3=10^{-2}$, $t_3=0.1$\n\nTest case $4$ (real symmetric, positive definite):\n- $N=4$, $n_c=3$.\n- $$ \\mathbf{Z}_4=\\begin{bmatrix}\n2 & -0.3 & 0 & 0\\\\\n-0.3 & 1.7 & 0.2 & 0\\\\\n0 & 0.2 & 1.3 & -0.1\\\\\n0 & 0 & -0.1 & 0.9\n\\end{bmatrix} $$\n- $$ \\mathbf{W}_4=\\begin{bmatrix}\n1 & 0 & 0\\\\\n0 & 1 & 0\\\\\n0.4 & 0 & 1\\\\\n0 & -0.2 & 0.3\n\\end{bmatrix} $$\n- $$ \\mathbf{x}_{c,4}=\\begin{bmatrix}0.3\\\\-0.1\\\\0.2\\end{bmatrix} $$\n$$ \\mathbf{b}_4=\\begin{bmatrix}0.2\\\\-0.05\\\\0.1\\\\-0.02\\end{bmatrix} $$\n- $\\tau_4=10^{-8}$, $t_4=0.05$\n\nRequirements:\n- For each test case $k\\in\\{1,2,3,4\\}$, compute $\\mathbf{r}_k$, $\\eta_{2,k}$, $\\eta_{E,k}$, and the boolean decision $\\eta_{E,k}>t_k$.\n- The final program must output a single line containing a list of the four per-case results, each formatted as $[\\eta_{2,k},\\eta_{E,k},\\text{decision}_k]$, with $\\eta_{2,k}$ and $\\eta_{E,k}$ rounded to $6$ decimals.\n- No physical units are required. Angles are not involved. All outputs must be numeric floats or booleans as specified.", "solution": "The problem requires the computation of two a posteriori error estimators for an approximate solution to a linear system arising from the Method of Moments (MoM) in computational electromagnetics. The system is $\\mathbf{Z}\\mathbf{x}=\\mathbf{b}$, with a coarse approximation $\\mathbf{x} \\approx \\mathbf{W}\\mathbf{x}_c$. The estimators are then used to decide whether to enrich the basis $\\mathbf{W}$. The computational procedure for each test case is detailed below.\n\nThe fundamental quantities are the impedance matrix $\\mathbf{Z} \\in \\mathbb{C}^{N\\times N}$, the excitation vector $\\mathbf{b} \\in \\mathbb{C}^{N}$, the matrix of characteristic basis functions (CBFs) $\\mathbf{W} \\in \\mathbb{C}^{N\\times n_c}$, and the vector of coarse coefficients $\\mathbf{x}_c \\in \\mathbb{C}^{n_c}$.\n\nThe procedure involves four main steps for each test case $k \\in \\{1, 2, 3, 4\\}$:\n1.  Calculation of the residual vector $\\mathbf{r}_k$.\n2.  Calculation of the Euclidean norm-based estimator $\\eta_{2,k}$.\n3.  Calculation of the energy-dual norm-based estimator $\\eta_{E,k}$.\n4.  Application of the decision rule $\\eta_{E,k} > t_k$.\n\n**Step 1: Residual Calculation**\nThe approximate solution in the full $N$-dimensional space is obtained by mapping the coarse coefficients back through the basis matrix, $\\mathbf{x}_{approx} = \\mathbf{W}\\mathbf{x}_c$. The algebraic residual $\\mathbf{r}$ measures how well this approximate solution satisfies the original linear system. It is defined as the difference between the excitation vector and the result of applying the impedance matrix to the approximate solution vector:\n$$\n\\mathbf{r} = \\mathbf{b} - \\mathbf{Z}\\mathbf{x}_{approx} = \\mathbf{b} - \\mathbf{Z}\\mathbf{W}\\mathbf{x}_c\n$$\nThis is a standard vector-matrix multiplication and subtraction process.\n\n**Step 2: Euclidean Norm-Based Estimator ($\\eta_2$)**\nThe first estimator, $\\eta_2$, is simply the Euclidean ($L_2$) norm of the residual vector $\\mathbf{r}$. It provides a direct measure of the magnitude of the error in the equation.\n$$\n\\eta_2 = \\|\\mathbf{r}\\|_2 = \\sqrt{\\mathbf{r}^H \\mathbf{r}} = \\sqrt{\\sum_{i=1}^{N} |r_i|^2}\n$$\nwhere $\\mathbf{r}^H$ is the conjugate transpose of $\\mathbf{r}$, and $r_i$ are the components of $\\mathbf{r}$.\n\n**Step 3: Energy-Dual Norm-Based Estimator ($\\eta_E$)**\nThe second estimator, $\\eta_E$, is physically motivated. For passive electromagnetic systems, the time-averaged power dissipated or radiated is non-negative. This is mathematically equivalent to the Hermitian part of the impedance matrix, $\\mathbf{S} = \\frac{1}{2}(\\mathbf{Z} + \\mathbf{Z}^H)$, being positive semidefinite. The estimator $\\eta_E$ is defined in a norm induced by this part of the impedance matrix. This is often called an \"energy norm\" because of the connection between $\\mathbf{S}$ and power.\n\nThe estimator is defined as:\n$$\n\\eta_E = \\sqrt{\\mathbf{r}^H \\mathbf{M}^{-1} \\mathbf{r}}\n$$\nwhere the matrix $\\mathbf{M}$ is a regularized version of the Hermitian part of $\\mathbf{Z}$:\n$$\n\\mathbf{M} = \\mathbf{S} + \\tau \\mathbf{I} = \\frac{1}{2}(\\mathbf{Z} + \\mathbf{Z}^H) + \\tau \\mathbf{I}\n$$\nHere, $\\mathbf{I}$ is the $N \\times N$ identity matrix and $\\tau > 0$ is a Tikhonov regularization parameter. Since $\\mathbf{S}$ is Hermitian and $\\tau\\mathbf{I}$ is Hermitian, their sum $\\mathbf{M}$ is also Hermitian. The addition of the term $\\tau\\mathbf{I}$ with $\\tau > 0$ ensures that $\\mathbf{M}$ is strictly positive definite, and therefore invertible, even if $\\mathbf{S}$ is only positive semidefinite or, due to numerical/modeling artifacts, has small negative eigenvalues.\n\nNumerically, computing the inverse $\\mathbf{M}^{-1}$ directly can be unstable and inefficient. A better approach is to first solve the linear system $\\mathbf{M}\\mathbf{y} = \\mathbf{r}$ for the vector $\\mathbf{y}$, which is equivalent to $\\mathbf{y} = \\mathbf{M}^{-1}\\mathbf{r}$. Then, $\\eta_E$ can be computed via a vector inner product:\n$$\n\\eta_E = \\sqrt{\\mathbf{r}^H \\mathbf{y}}\n$$\nSince $\\mathbf{M}$ is Hermitian positive definite, the quadratic form $\\mathbf{r}^H \\mathbf{M}^{-1} \\mathbf{r}$ is guaranteed to be a non-negative real number, so its square root is well-defined and real.\n\n**Step 4: Decision Rule**\nThe final step is to apply the decision rule for enriching the CBF set. The computed energy-dual estimator $\\eta_E$ is compared against a predefined tolerance threshold $t$.\n$$\n\\text{Enrichment Decision} = (\\eta_E > t)\n$$\nIf the estimator exceeds the threshold, the decision is `True`, indicating that the basis $\\mathbf{W}$ should be enriched with new functions to improve the approximation accuracy. Otherwise, the decision is `False`.\n\nThese four steps are systematically applied to each of the provided test cases to obtain the required results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Computes a posteriori error estimators for a series of test cases\n    from the Characteristic Basis Function Method (CBFM) and decides\n    whether to enrich the basis set.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            # Test case 1 (general complex, happy path)\n            \"N\": 4, \"nc\": 2,\n            \"Z\": np.array([\n                [2. + 1.j, 0.5 - 0.2j, 0., 0.],\n                [0.5 + 0.2j, 1.5 + 0.8j, 0.3, 0.],\n                [0., 0.3, 1.2 + 0.5j, 0.1 - 0.1j],\n                [0., 0., 0.1 + 0.1j, 1. + 0.3j]\n            ]),\n            \"W\": np.array([\n                [1., 0.],\n                [0., 1.],\n                [0.2, -0.1],\n                [0., 0.3]\n            ]),\n            \"xc\": np.array([1. - 0.5j, 0.8 + 0.2j]),\n            \"b\": np.array([1. + 0.j, 0.5 + 0.2j, 0.1 - 0.1j, -0.3 + 0.4j]),\n            \"tau\": 1e-3, \"t\": 0.5\n        },\n        {\n            # Test case 2 (coarse equals full, zero approximation)\n            \"N\": 3, \"nc\": 3,\n            \"Z\": np.array([\n                [1., 0.2, 0.],\n                [0.2, 0.9, 0.1],\n                [0., 0.1, 1.1]\n            ]) + 1j * np.array([\n                [0.3, -0.1, 0.05],\n                [0.1, 0.2, -0.06],\n                [-0.05, 0.06, 0.1]\n            ]),\n            \"W\": np.eye(3),\n            \"xc\": np.array([0., 0., 0.]),\n            \"b\": np.array([0.5 - 0.2j, -0.3 + 0.1j, 0.2 + 0.05j]),\n            \"tau\": 1e-4, \"t\": 0.25\n        },\n        {\n            # Test case 3 (nearly singular Hermitian part, regularization active)\n            \"N\": 3, \"nc\": 2,\n            \"Z\": 1j * np.array([\n                [2., -0.5, 0.],\n                [0.5, 1.5, -0.3],\n                [0., 0.3, 1.]\n            ]) + np.array([\n                [1e-3, 0., 0.],\n                [0., 1.5e-3, 0.],\n                [0., 0., 1e-3]\n            ]),\n            \"W\": np.array([\n                [1., 0.],\n                [0.2, 1.],\n                [0., -0.1]\n            ]),\n            \"xc\": np.array([0.7 - 0.3j, -0.2 + 0.5j]),\n            \"b\": np.array([0.1 + 0.2j, -0.05 + 0.1j, 0.02 - 0.03j]),\n            \"tau\": 1e-2, \"t\": 0.1\n        },\n        {\n            # Test case 4 (real symmetric, positive definite)\n            \"N\": 4, \"nc\": 3,\n            \"Z\": np.array([\n                [2., -0.3, 0., 0.],\n                [-0.3, 1.7, 0.2, 0.],\n                [0., 0.2, 1.3, -0.1],\n                [0., 0., -0.1, 0.9]\n            ]),\n            \"W\": np.array([\n                [1., 0., 0.],\n                [0., 1., 0.],\n                [0.4, 0., 1.],\n                [0., -0.2, 0.3]\n            ]),\n            \"xc\": np.array([0.3, -0.1, 0.2]),\n            \"b\": np.array([0.2, -0.05, 0.1, -0.02]),\n            \"tau\": 1e-8, \"t\": 0.05\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Extract data for the current case\n        Z, W, xc, b = case[\"Z\"], case[\"W\"], case[\"xc\"], case[\"b\"]\n        tau, t, N = case[\"tau\"], case[\"t\"], case[\"N\"]\n\n        # Step 1: Compute the residual vector r\n        r = b - Z @ W @ xc\n        \n        # Step 2: Compute the Euclidean norm-based estimator eta_2\n        eta_2 = np.linalg.norm(r)\n        \n        # Step 3: Compute the energy-dual residual estimator eta_E\n        # 3a: Hermitian part of Z\n        S = 0.5 * (Z + Z.conj().T)\n        # 3b: Regularized matrix M\n        M = S + tau * np.eye(N)\n        # 3c: Solve M*y = r for y\n        # Check if M is real symmetric for optimized solver\n        is_symmetric = np.allclose(M, M.T) and np.isrealobj(M)\n        if is_symmetric:\n            y = linalg.solve(M, r, assume_a='sym')\n        else:\n            y = linalg.solve(M, r, assume_a='her')\n\n        # 3d: Compute eta_E = sqrt(r^H * y)\n        q_form = np.vdot(r, y)\n        eta_E = np.sqrt(np.real(q_form)) # Take real part to discard tiny numerical imaginary noise\n        \n        # Step 4: Make the decision\n        decision = eta_E > t\n        \n        # Store results rounded to 6 decimals\n        current_result = [round(eta_2, 6), round(eta_E, 6), decision]\n        results.append(current_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3292540"}]}