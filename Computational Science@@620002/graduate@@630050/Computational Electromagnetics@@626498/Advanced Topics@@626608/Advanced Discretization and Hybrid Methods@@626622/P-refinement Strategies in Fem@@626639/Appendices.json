{"hands_on_practices": [{"introduction": "The primary motivation for using p-refinement is its ability to achieve exceptionally fast, or 'exponential', convergence for problems with smooth solutions. This practice takes you to the theoretical heart of this phenomenon, grounding the abstract concept in a concrete analytical exercise. By applying principles from complex analysis, you will derive the explicit convergence rate for a model wave problem, providing a clear understanding of why high-order polynomials are so effective. [@problem_id:3314615]", "problem": "Consider a one-dimensional proxy of a time-harmonic electromagnetic field in a homogeneous, lossless medium, where the exact complex electric field component is given by the analytic function $u(x) = \\exp(\\mathrm{i}\\kappa x)$ on the closed interval $\\Omega = [-1,1]$, with real wavenumber $\\kappa > 0$. The field is to be approximated by a p-version Finite Element Method (FEM) on a single element spanning the domain $\\Omega$; this is a pure p-refinement strategy (i.e., a fixed mesh and variable polynomial degree $p$) using a trial space of polynomials of degree at most $p$. Assume the error is measured in the uniform norm $\\|\\cdot\\|_{L^{\\infty}(\\Omega)}$.\n\nUse as foundational facts the analyticity of $u$ together with standard approximation theory of analytic functions on the interval $[-1,1]$ via polynomial spaces and the Bernstein ellipse technique. In particular, recall that for a function analytic in and on a Bernstein ellipse $\\mathcal{E}_{\\rho}$ with parameter $\\rho > 1$ (the image of the circle $|w|=\\rho$ under the Joukowski map $z=\\frac{1}{2}(w+w^{-1})$), with maximum modulus $M_{\\rho} = \\max_{z\\in \\mathcal{E}_{\\rho}}|u(z)|$, the best degree-$p$ polynomial approximation error on $[-1,1]$ admits an upper bound of the form $\\frac{2M_{\\rho}}{\\rho - 1}\\rho^{-p}$ in the $L^{\\infty}$ norm.\n\nFor the specified analytic field $u(x) = \\exp(\\mathrm{i}\\kappa x)$ and the single-element discretization (which is a trivial mesh grading scheme with a single element of length $2$), set the Bernstein ellipse parameter to the explicit value $\\rho = 2$. Treat the discrete solution $u_{hp}$ as the best approximation in the polynomial trial space (which provides a rigorous upper bound for any Galerkin solution due to quasi-optimality in norms equivalent to $L^{\\infty}$ under analyticity).\n\nCompute explicit constants $C$ and $\\alpha$ such that the following bound holds for all polynomial degrees $p \\in \\mathbb{N}$:\n$$\n\\|u - u_{hp}\\|_{L^{\\infty}(\\Omega)} \\le C \\exp(-\\alpha p).\n$$\nExpress the final answer as a closed-form analytic expression in terms of $\\kappa$ only. No numerical rounding is required and no physical units are to be reported. The angle unit is radians.", "solution": "The user wants me to solve a problem. As a professor, I will first validate the problem statement.\n\n### Step 1: Extract Givens\n-   **Exact Solution:** The complex electric field component is given by $u(x) = \\exp(\\mathrm{i}\\kappa x)$ on the domain $\\Omega = [-1,1]$, where $\\kappa > 0$ is a real wavenumber. The function $u(x)$ is analytic.\n-   **Approximation Method:** A single-element $hp$-Finite Element Method (FEM) is used, which corresponds to a polynomial approximation on $\\Omega$ using polynomials of degree at most $p$.\n-   **Error Norm:** The error is measured in the uniform norm, $\\| \\cdot \\|_{L^{\\infty}(\\Omega)}$.\n-   **Approximation Theory Bound:** For a function $u(z)$ analytic in and on a Bernstein ellipse $\\mathcal{E}_{\\rho}$ with parameter $\\rho > 1$, the best degree-$p$ polynomial approximation error is bounded by:\n    $$ \\|u - u_p\\|_{L^{\\infty}([-1,1])} \\le \\frac{2M_{\\rho}}{\\rho - 1}\\rho^{-p} $$\n    where $M_{\\rho} = \\max_{z\\in \\mathcal{E}_{\\rho}}|u(z)|$.\n-   **Specific Parameters:** The Bernstein ellipse parameter is set to $\\rho = 2$.\n-   **Assumption:** The discrete FEM solution $u_{hp}$ is treated as the best polynomial approximation $u_p$.\n-   **Task:** Find explicit constants $C$ and $\\alpha$ in terms of $\\kappa$ such that the following bound holds for all $p \\in \\mathbb{N}$:\n    $$ \\|u - u_{hp}\\|_{L^{\\infty}(\\Omega)} \\le C \\exp(-\\alpha p) $$\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to validation against the specified criteria.\n\n-   **Scientific or Factual Unsoundness:** The problem is scientifically sound. It is a standard model problem in the theory of numerical methods for wave propagation, specifically concerning the convergence analysis of $p$-version and $hp$-version FEM for the Helmholtz equation. The use of Bernstein ellipses and approximation theory for analytic functions is a cornerstone of this analysis.\n-   **Non-Formalizable or Irrelevant:** The problem is directly relevant to the topic of $hp$-refinement in computational electromagnetics and is stated in a formal, mathematical way.\n-   **Incomplete or Contradictory Setup:** The problem is self-contained. It provides the exact solution, the approximation framework, the explicit error bound formula to be used, and all necessary parameters (like $\\rho=2$). The assumption that the FEM solution is the best approximation is a standard simplifying step in this type of analysis, making the problem well-defined.\n-   **Unrealistic or Infeasible:** All conditions are standard within the theoretical context of numerical analysis.\n-   **Ill-Posed or Poorly Structured:** The problem is well-posed. A unique solution for the constants $C$ and $\\alpha$ within the specified framework is expected.\n-   **Pseudo-Profound, Trivial, or Tautological:** The problem is non-trivial, requiring the application of complex analysis (Joukowski map, properties of analytic functions) to a specific function within a given theoretical framework.\n-   **Outside Scientific Verifiability:** The result is mathematically derivable and verifiable.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution Derivation\n\nThe objective is to determine the constants $C$ and $\\alpha$ in the error bound $\\|u - u_{hp}\\|_{L^{\\infty}(\\Omega)} \\le C \\exp(-\\alpha p)$. The problem states that the discrete solution $u_{hp}$ can be treated as the best polynomial approximation of degree $p$, denoted $u_p$. We are given the theoretical bound for the error of the best approximation:\n$$ \\|u - u_p\\|_{L^{\\infty}([-1,1])} \\le \\frac{2M_{\\rho}}{\\rho - 1}\\rho^{-p} $$\nWe are given $\\rho = 2$. Substituting this value into the bound gives:\n$$ \\|u - u_p\\|_{L^{\\infty}([-1,1])} \\le \\frac{2M_{2}}{2 - 1}2^{-p} = 2 M_2 2^{-p} $$\nThe next step is to calculate $M_2$, which is the maximum modulus of the analytic continuation of $u(x)$ on the Bernstein ellipse $\\mathcal{E}_2$. The function is $u(x) = \\exp(\\mathrm{i}\\kappa x)$. Its analytic continuation into the complex plane is $u(z) = \\exp(\\mathrm{i}\\kappa z)$ for $z \\in \\mathbb{C}$.\n\nWe need to compute $M_2 = \\max_{z \\in \\mathcal{E}_2} |u(z)|$. Let $z = x + \\mathrm{i}y$. The modulus of $u(z)$ is:\n$$ |u(z)| = |\\exp(\\mathrm{i}\\kappa(x + \\mathrm{i}y))| = |\\exp(\\mathrm{i}\\kappa x - \\kappa y)| = |\\exp(\\mathrm{i}\\kappa x)| \\cdot |\\exp(-\\kappa y)| = 1 \\cdot \\exp(-\\kappa y) = \\exp(-\\kappa y) $$\nSince the wavenumber $\\kappa$ is given as positive ($\\kappa > 0$), the function $\\exp(-\\kappa y)$ is a strictly decreasing function of $y$. Therefore, its maximum value on the ellipse $\\mathcal{E}_2$ will occur at the point where the imaginary part $y$ is minimum.\n\nA Bernstein ellipse $\\mathcal{E}_{\\rho}$ is defined by the Joukowski map $z = \\frac{1}{2}(w + w^{-1})$ applied to the circle $|w| = \\rho$ in the complex $w$-plane. Let $w = \\rho \\exp(\\mathrm{i}\\theta)$ for $\\theta \\in [0, 2\\pi)$. Then $z$ is given by:\n$$ z(\\theta) = \\frac{1}{2} \\left(\\rho \\exp(\\mathrm{i}\\theta) + \\frac{1}{\\rho} \\exp(-\\mathrm{i}\\theta) \\right) $$\nExpanding the complex exponentials:\n$$ z(\\theta) = \\frac{1}{2} \\left( \\rho(\\cos\\theta + \\mathrm{i}\\sin\\theta) + \\frac{1}{\\rho}(\\cos\\theta - \\mathrm{i}\\sin\\theta) \\right) $$\n$$ z(\\theta) = \\frac{1}{2} \\left(\\rho + \\frac{1}{\\rho}\\right)\\cos\\theta + \\mathrm{i} \\frac{1}{2}\\left(\\rho - \\frac{1}{\\rho}\\right)\\sin\\theta $$\nThe imaginary part of $z$ is $y(\\theta) = \\frac{1}{2}(\\rho - \\frac{1}{\\rho})\\sin\\theta$. Since $\\rho > 1$, the term $(\\rho - \\frac{1}{\\rho})$ is positive. The minimum value of $y(\\theta)$ occurs when $\\sin\\theta = -1$, which gives:\n$$ y_{\\min} = -\\frac{1}{2}\\left(\\rho - \\frac{1}{\\rho}\\right) $$\nNow we can evaluate $M_{\\rho}$:\n$$ M_{\\rho} = \\max_{z \\in \\mathcal{E}_{\\rho}} \\exp(-\\kappa y) = \\exp(-\\kappa y_{\\min}) = \\exp\\left(\\kappa \\frac{1}{2}\\left(\\rho - \\frac{1}{\\rho}\\right)\\right) $$\nFor the specific case $\\rho = 2$, the minimum value of $y$ is:\n$$ y_{\\min} = -\\frac{1}{2}\\left(2 - \\frac{1}{2}\\right) = -\\frac{1}{2}\\left(\\frac{3}{2}\\right) = -\\frac{3}{4} $$\nAnd the maximum modulus $M_2$ is:\n$$ M_2 = \\exp(-\\kappa y_{\\min}) = \\exp\\left(-\\kappa \\left(-\\frac{3}{4}\\right)\\right) = \\exp\\left(\\frac{3\\kappa}{4}\\right) $$\nSubstituting this expression for $M_2$ into our error bound:\n$$ \\|u - u_p\\|_{L^{\\infty}([-1,1])} \\le 2 \\exp\\left(\\frac{3\\kappa}{4}\\right) 2^{-p} $$\nTo match the target form $C \\exp(-\\alpha p)$, we rewrite the term $2^{-p}$ using the natural exponential function:\n$$ 2^{-p} = (e^{\\ln 2})^{-p} = \\exp(-p \\ln 2) $$\nThe error bound thus becomes:\n$$ \\|u - u_p\\|_{L^{\\infty}([-1,1])} \\le 2 \\exp\\left(\\frac{3\\kappa}{4}\\right) \\exp(-(\\ln 2)p) $$\nComparing this to the form $C \\exp(-\\alpha p)$, we can identify the constants $C$ and $\\alpha$:\n$$ C = 2 \\exp\\left(\\frac{3\\kappa}{4}\\right) $$\n$$ \\alpha = \\ln 2 $$\nThese constants are expressed in terms of $\\kappa$ as required.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2 \\exp\\left(\\frac{3\\kappa}{4}\\right) & \\ln(2)\n\\end{pmatrix}\n}\n$$", "id": "3314615"}, {"introduction": "While p-refinement is ideal for smooth solutions, real-world electromagnetic problems are rarely so simple; they often feature a mix of smooth regions, geometric singularities, and high-frequency waves. A successful adaptive strategy must intelligently assign polynomial degrees based on these local characteristics. This hands-on coding exercise challenges you to implement a decision-making algorithm that balances the need for high-order elements in smooth regions against the limited regularity near singularities and the numerical stability requirements for wave propagation. [@problem_id:3314596]", "problem": "You are tasked with implementing a principled polynomial-degree selection algorithm for two-dimensional time-harmonic Computational Electromagnetics (CEM) using the Finite Element Method (FEM) with hybrid mesh-size and polynomial-degree refinement (hp-refinement). The goal is to decide the polynomial degree per element for a given mesh over a domain that includes both smooth regions and re-entrant corners that induce field singularities.\n\nFundamentals. Time-harmonic Maxwell equations reduce in two dimensions, for a single polarized component, to a curl-curl Helmholtz-type equation for the field component, with wavenumber $k$. It is a well-tested fact that in polygonal domains, a re-entrant corner with interior angle $\\theta$ greater than $\\pi$ induces a local singularity in the form of a corner singular exponent $\\lambda = \\pi/\\theta$, which implies reduced regularity near such corners. In contrast, away from re-entrant corners and material discontinuities, the field is smooth and often analytic, allowing superior convergence under polynomial enrichment. Additionally, to control wave dispersion error in FEM, a commonly used resolution guideline is that the nondimensional ratio $k h / p$ should be bounded by a prescribed constant, where $h$ is the element size and $p$ is the polynomial degree on the element.\n\nDecision problem. You must implement a decision algorithm that, given the element size and positions relative to specified re-entrant corners, a wavenumber $k$, and a target elementwise tolerance, classifies elements as either locally influenced by a corner singularity or smooth. It must then select a polynomial degree $p$ on each element by combining:\n- a corner-regularity-aware cap in singular neighborhoods,\n- an analyticity-driven choice in smooth regions to meet a target tolerance,\n- and a wave-resolution constraint to control dispersion.\n\nFor this exercise, adopt the following concrete and conservative numerical constants and modeling primitives, which are standardized solely to make the task well-posed and testable:\n- A corner is considered re-entrant and thus singular if $\\theta > \\pi$. For such a corner at position $(x_c,y_c)$ with angle $\\theta$, define its singularity exponent $\\lambda = \\pi/\\theta$.\n- For an element with centroid $(x_e,y_e)$ and size $h_e$, define the minimum Euclidean distance to any re-entrant corner as $d_e$, and declare the element to be in a singular neighborhood if $d_e \\le \\alpha h_e$ with $\\alpha = 1.5$. If there are no re-entrant corners, all elements are deemed smooth.\n- In a singular neighborhood, set a regularity-informed cap $p_{\\text{cap}} = \\lfloor \\lambda + 0.5 \\rfloor$, and then define a singular-neighborhood base choice $p_{\\text{sing}} = \\max(p_{\\min}, \\min(p_{\\text{cap}}, p_{\\text{max,sing}}))$ with $p_{\\min} = 1$ and $p_{\\text{max,sing}} = 3$.\n- In a smooth region, use an analytic error model with elementwise exponential decay in $p$ of the form $\\text{error} \\approx A_e \\exp(-b p)$ and select $p$ as the smallest integer meeting a target tolerance $\\tau$. For this exercise, use $A_e = k h_e$, $b = 0.6$, and a given $\\tau$ per test case. That is, choose $p_{\\text{smooth}}$ as the minimal integer satisfying $A_e \\exp(-b p) \\le \\tau$.\n- Impose a wave-resolution constraint $k h_e / p \\le \\chi$ with $\\chi = 0.5$ by enforcing $p \\ge p_{\\text{disp}} = \\lceil k h_e / \\chi \\rceil$.\n- Finally, enforce global bounds $p_{\\min} \\le p \\le p_{\\max}$ with $p_{\\max} = 8$, and set\n$$\np_e = \\min\\left(p_{\\max}, \\max\\left(p_{\\text{disp}}, \\begin{cases}\np_{\\text{sing}} & \\text{if in singular neighborhood},\\\\\np_{\\text{smooth}} & \\text{otherwise.}\n\\end{cases}\\right)\\right).\n$$\n\nInput specification is embedded in the test suite below. All geometric coordinates are in a consistent Cartesian coordinate system with distances measured in the same unit as $h_e$, and the wavenumber $k$ is in reciprocal length units. The final answers are unitless integers per element.\n\nTest suite. Implement the algorithm on the following five cases. In each case, you are given:\n- a list of elements, each with centroid $(x_e,y_e)$ and size $h_e$,\n- a wavenumber $k$,\n- a set of re-entrant corners specified by $(x_c,y_c,\\theta)$ with $\\theta$ in radians,\n- and a target tolerance $\\tau$ to be enforced in smooth regions.\n\nUse the constants $\\alpha = 1.5$, $p_{\\min} = 1$, $p_{\\max} = 8$, $p_{\\text{max,sing}} = 3$, $\\chi = 0.5$, $A_e = k h_e$, and $b = 0.6$ exactly as specified above.\n\n- Case $1$ (smooth unit square surrogate):\n    - Elements: $[(0.25, 0.25, h=0.5), (0.75, 0.25, h=0.5), (0.25, 0.75, h=0.5), (0.75, 0.75, h=0.5)]$.\n    - Re-entrant corners: $[]$ (none).\n    - Wavenumber: $k = 5$.\n    - Tolerance: $\\tau = 10^{-3}$.\n\n- Case $2$ (single re-entrant corner, mixed proximity):\n    - Elements: $[(0.05, 0.05, h=0.08), (0.20, 0.05, h=0.08), (0.40, 0.40, h=0.20), (0.80, 0.80, h=0.30)]$.\n    - Re-entrant corners: $[(0.0, 0.0, \\theta = 3\\pi/2)]$.\n    - Wavenumber: $k = 5$.\n    - Tolerance: $\\tau = 10^{-3}$.\n\n- Case $3$ (two re-entrant corners, mixed smoothness):\n    - Elements: $[(0.10, 0.10, h=0.10), (0.90, 0.50, h=0.08), (0.50, 0.50, h=0.20), (0.50, 0.10, h=0.15)]$.\n    - Re-entrant corners: $[(0.0, 0.0, \\theta = 3\\pi/2), (1.0, 0.5, \\theta = 3\\pi/2)]$.\n    - Wavenumber: $k = 1$.\n    - Tolerance: $\\tau = 10^{-4}$.\n\n- Case $4$ (high-frequency smooth domain):\n    - Elements: $[(0.10, 0.10, h=0.10), (0.30, 0.20, h=0.08), (0.60, 0.40, h=0.05), (0.80, 0.70, h=0.20), (0.50, 0.90, h=0.12)]$.\n    - Re-entrant corners: $[]$.\n    - Wavenumber: $k = 80$.\n    - Tolerance: $\\tau = 10^{-2}$.\n\n- Case $5$ (threshold classification near singular neighborhood boundary):\n    - Elements: $[(0.65, 0.50, h=0.10)]$.\n    - Re-entrant corners: $[(0.50, 0.50, \\theta = 3\\pi/2)]$.\n    - Wavenumber: $k = 10$.\n    - Tolerance: $\\tau = 10^{-3}$.\n\nRequired output. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each caseâ€™s result is itself a list of integers (the selected polynomial degrees per element, in the same order as listed). For example, the output must have the form\n$[ [p_{1,1}, p_{1,2}, \\dots], [p_{2,1}, \\dots], \\dots ]$\nwith no additional text. The final answers are plain integers without any unit.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of computational electromagnetics and the finite element method, internally consistent, and provides a complete, well-posed specification for a deterministic algorithm. All necessary constants, formulas, and test data are provided, enabling the derivation of a unique and verifiable solution.\n\nThe task is to implement a polynomial-degree selection algorithm for a two-dimensional `hp-FEM` (hybrid mesh-size and polynomial-degree refinement) simulation of time-harmonic electromagnetic waves. The algorithm must intelligently assign a polynomial degree $p_e$ to each element of a finite element mesh based on local field characteristics, a target accuracy, and numerical stability criteria. The core idea of `hp-FEM` is to adaptively use a combination of mesh refinement ($h$-refinement, reducing element size $h_e$) and polynomial enrichment ($p$-refinement, increasing basis function degree $p_e$) to achieve optimal convergence. This problem focuses solely on the $p$-selection part for a given mesh.\n\nThe algorithm synthesizes three fundamental considerations in modern FEM for wave problems:\n\n1.  **Local Regularity of the Solution:** The smoothness of the electromagnetic field dictates the effectiveness of high-order polynomial approximations.\n    -   In regions where the solution is smooth (analytic), the approximation error decreases exponentially with the polynomial degree $p$. The provided error model, $\\text{error} \\approx (k h_e) \\exp(-b p)$, reflects this, and inverting it to find the minimum $p$ to meet a tolerance $\\tau$ is an efficient strategy for $p$-refinement.\n    -   Near geometric singularities, such as re-entrant corners in the domain boundary, the solution is not smooth. For a corner with angle $\\theta > \\pi$, the field exhibits a power-law singularity of the form $r^{\\lambda}$ where $r$ is the distance from the corner and $\\lambda = \\pi/\\theta$ is the singularity exponent. The solution's regularity is limited to the Sobolev space $H^{\\lambda+1-\\epsilon}$ for any $\\epsilon > 0$. Approximation theory for FEM indicates that the convergence rate with respect to $p$ is limited by $\\lambda$. Consequently, using very high polynomial degrees in these regions yields diminishing returns. The algorithm prudently caps the polynomial degree at $p_{\\text{cap}} = \\lfloor \\lambda + 0.5 \\rfloor$ in such singular neighborhoods, focusing computational resources where they are most effective.\n\n2.  **Dispersion Error Control:** Numerical schemes for wave equations, including FEM, can introduce a non-physical, frequency-dependent phase velocity for propagating waves. This \"numerical dispersion\" leads to phase errors that accumulate over distance. To control this, the numerical resolution must be sufficient to represent the wave. A standard rule of thumb is to maintain a certain number of degrees of freedom per wavelength. This is captured by the wave-resolution constraint $k h_e / p_e \\le \\chi$, where $k=2\\pi/\\text{wavelength}$ is the wavenumber. This constraint establishes a minimum required polynomial degree, $p_{\\text{disp}}$, for a given element size $h_e$ and wavenumber $k$ to ensure simulation fidelity.\n\n3.  **Algorithmic Synthesis:** The final polynomial degree $p_e$ for an element is determined by a clear hierarchy of these criteria. The choice is based on whether the element is in a \"singular\" or \"smooth\" region, but this base choice is then required to satisfy the dispersion constraint and global bounds. The final formula,\n    $$\n    p_e = \\min\\left(p_{\\max}, \\max\\left(p_{\\text{disp}}, \\begin{cases}\n    p_{\\text{sing}} & \\text{if in singular neighborhood},\\\\\n    p_{\\text{smooth}} & \\text{otherwise.}\n    \\end{cases}\\right)\\right)\n    $$\n    encapsulates this logic. It takes the appropriate base choice ($p_{\\text{sing}}$ or $p_{\\text{smooth}}$), ensures it is at least high enough to control dispersion (by taking the maximum with $p_{\\text{disp}}$), and finally caps it by a global maximum $p_{\\max}$ to limit computational cost.\n\nLet us now apply this algorithm to a representative test case, Case 2, which involves both singular and smooth regions.\n\n**Case 2: Detailed Walkthrough**\n-   **Givens:** Wavenumber $k=5$, tolerance $\\tau = 10^{-3}$.\n-   **Re-entrant Corner:** One corner at $(0.0, 0.0)$ with angle $\\theta = 3\\pi/2$. Since $\\theta > \\pi$, it is re-entrant. The singularity exponent is $\\lambda = \\pi / (3\\pi/2) = 2/3$.\n-   **Constants:** $\\alpha = 1.5, p_{\\min} = 1, p_{\\max} = 8, p_{\\text{max,sing}} = 3, \\chi = 0.5, b = 0.6$.\n\n**Element 1:** Centroid $(0.05, 0.05)$, size $h_e=0.08$.\n1.  **Region Classification:**\n    -   Distance to corner: $d_e = \\sqrt{(0.05-0)^2 + (0.05-0)^2} = \\sqrt{0.005} \\approx 0.0707$.\n    -   Neighborhood threshold: $\\alpha h_e = 1.5 \\times 0.08 = 0.12$.\n    -   Since $d_e \\approx 0.0707 \\le 0.12$, the element is in a **singular neighborhood**.\n2.  **Base Polynomial Degree ($p_{\\text{sing}}$):**\n    -   $p_{\\text{cap}} = \\lfloor \\lambda + 0.5 \\rfloor = \\lfloor 2/3 + 0.5 \\rfloor = \\lfloor 1.166... \\rfloor = 1$.\n    -   $p_{\\text{sing}} = \\max(p_{\\min}, \\min(p_{\\text{cap}}, p_{\\text{max,sing}})) = \\max(1, \\min(1, 3)) = 1$. So, $p_{\\text{base}} = 1$.\n3.  **Dispersion Constraint ($p_{\\text{disp}}$):**\n    -   $p_{\\text{disp}} = \\lceil k h_e / \\chi \\rceil = \\lceil (5 \\times 0.08) / 0.5 \\rceil = \\lceil 0.4 / 0.5 \\rceil = \\lceil 0.8 \\rceil = 1$.\n4.  **Final Degree ($p_e$):**\n    -   $p_e = \\min(p_{\\max}, \\max(p_{\\text{disp}}, p_{\\text{base}})) = \\min(8, \\max(1, 1)) = 1$.\n\n**Element 2:** Centroid $(0.20, 0.05)$, size $h_e=0.08$.\n1.  **Region Classification:**\n    -   Distance to corner: $d_e = \\sqrt{(0.20-0)^2 + (0.05-0)^2} = \\sqrt{0.0425} \\approx 0.2062$.\n    -   Neighborhood threshold: $\\alpha h_e = 1.5 \\times 0.08 = 0.12$.\n    -   Since $d_e \\approx 0.2062 > 0.12$, the element is in a **smooth region**.\n2.  **Base Polynomial Degree ($p_{\\text{smooth}}$):**\n    -   We require $(k h_e) \\exp(-b p) \\le \\tau$. This gives $p \\ge \\ln(k h_e / \\tau)/b$.\n    -   $k h_e = 5 \\times 0.08 = 0.4$.\n    -   $p_{\\text{smooth}} = \\lceil \\frac{\\ln(0.4 / 10^{-3})}{0.6} \\rceil = \\lceil \\frac{\\ln(400)}{0.6} \\rceil \\approx \\lceil 5.991 / 0.6 \\rceil = \\lceil 9.985 \\rceil = 10$. So, $p_{\\text{base}} = 10$.\n3.  **Dispersion Constraint ($p_{\\text{disp}}$):**\n    -   $p_{\\text{disp}} = \\lceil (5 \\times 0.08) / 0.5 \\rceil = \\lceil 0.8 \\rceil = 1$.\n4.  **Final Degree ($p_e$):**\n    -   $p_e = \\min(p_{\\max}, \\max(p_{\\text{disp}}, p_{\\text{base}})) = \\min(8, \\max(1, 10)) = \\min(8, 10) = 8$.\n\nThe remaining elements in Case 2 are also in smooth regions and yield $p_e=8$. This demonstrates how the algorithm assigns a low degree ($p_e=1$) to the element affected by the singularity and a high degree ($p_e=8$, capped by $p_{\\max}$) to elements in smooth regions where high-order approximation is effective.\n\nApplying this procedure to all test cases yields the following results:\n\n-   **Case 1:** All elements are smooth, requiring a high degree to meet the tolerance. The dispersion constraint is not dominant. The final degrees are all capped by $p_{\\max}$.\n    -   Result: $[8, 8, 8, 8]$\n-   **Case 2:** The first element is near a corner and assigned $p_e=1$. The other elements are smooth and are assigned $p_e=8$.\n    -   Result: $[1, 8, 8, 8]$\n-   **Case 3:** Two elements are near corners and assigned low degrees ($p_e=1$). The other two are in smooth regions and are assigned high degrees ($p_e=8$).\n    -   Result: $[1, 1, 8, 8]$\n-   **Case 4:** A high-frequency case ($k=80$) where all elements are smooth. The dispersion constraint ($p_{\\text{disp}}$) becomes the dominant factor, requiring very high degrees which are all ultimately capped by $p_{\\max}=8$.\n    -   Result: $[8, 8, 8, 8, 8]$\n-   **Case 5:** An element lies exactly on the boundary of a singular neighborhood ($d_e = \\alpha h_e$). It is classified as singular. The dispersion constraint ($p_{\\text{disp}}=2$) is more demanding than the singularity-based choice ($p_{\\text{sing}}=1$), so the final degree is $p_e=2$.\n    -   Result: $[2]$\n\nThe complete set of results is: $[[8, 8, 8, 8], [1, 8, 8, 8], [1, 1, 8, 8], [8, 8, 8, 8, 8], [2]]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the hp-refinement polynomial degree selection algorithm\n    and runs it on the specified test cases.\n    \"\"\"\n\n    # --- Fixed constants for the algorithm ---\n    ALPHA = 1.5\n    P_MIN = 1\n    P_MAX = 8\n    P_MAX_SING = 3\n    CHI = 0.5\n    B_COEFF = 0.6\n\n    # --- Test suite definition ---\n    test_cases = [\n        # Case 1 (smooth unit square surrogate)\n        {\n            \"elements\": [(0.25, 0.25, 0.5), (0.75, 0.25, 0.5), (0.25, 0.75, 0.5), (0.75, 0.75, 0.5)],\n            \"corners\": [],\n            \"k\": 5.0,\n            \"tau\": 1e-3\n        },\n        # Case 2 (single re-entrant corner, mixed proximity)\n        {\n            \"elements\": [(0.05, 0.05, 0.08), (0.20, 0.05, 0.08), (0.40, 0.40, 0.20), (0.80, 0.80, 0.30)],\n            \"corners\": [(0.0, 0.0, 3 * np.pi / 2)],\n            \"k\": 5.0,\n            \"tau\": 1e-3\n        },\n        # Case 3 (two re-entrant corners, mixed smoothness)\n        {\n            \"elements\": [(0.10, 0.10, 0.10), (0.90, 0.50, 0.08), (0.50, 0.50, 0.20), (0.50, 0.10, 0.15)],\n            \"corners\": [(0.0, 0.0, 3 * np.pi / 2), (1.0, 0.5, 3 * np.pi / 2)],\n            \"k\": 1.0,\n            \"tau\": 1e-4\n        },\n        # Case 4 (high-frequency smooth domain)\n        {\n            \"elements\": [(0.10, 0.10, 0.10), (0.30, 0.20, 0.08), (0.60, 0.40, 0.05), (0.80, 0.70, 0.20), (0.50, 0.90, 0.12)],\n            \"corners\": [],\n            \"k\": 80.0,\n            \"tau\": 1e-2\n        },\n        # Case 5 (threshold classification near singular neighborhood boundary)\n        {\n            \"elements\": [(0.65, 0.50, 0.10)],\n            \"corners\": [(0.50, 0.50, 3 * np.pi / 2)],\n            \"k\": 10.0,\n            \"tau\": 1e-3\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        case_results = []\n        elements = case[\"elements\"]\n        corners = case[\"corners\"]\n        k = case[\"k\"]\n        tau = case[\"tau\"]\n\n        re_entrant_corners = [(xc, yc, theta) for xc, yc, theta in corners if theta > np.pi]\n\n        for xe, ye, he in elements:\n            # Step 1: Calculate minimum distance to a re-entrant corner\n            min_dist = float('inf')\n            closest_corner_theta = None\n            if re_entrant_corners:\n                for xc, yc, theta in re_entrant_corners:\n                    dist = np.sqrt((xe - xc)**2 + (ye - yc)**2)\n                    if dist < min_dist:\n                        min_dist = dist\n                        closest_corner_theta = theta\n            \n            # Step 2: Classify element and calculate base p\n            is_singular = (min_dist <= ALPHA * he) if re_entrant_corners else False\n            \n            if is_singular:\n                # In singular neighborhood\n                lambda_exp = np.pi / closest_corner_theta\n                p_cap = int(np.floor(lambda_exp + 0.5))\n                p_sing = max(P_MIN, min(p_cap, P_MAX_SING))\n                p_base = p_sing\n            else:\n                # In smooth region\n                kh = k * he\n                # Ae * exp(-b*p) <= tau  =>  p >= ln(Ae/tau)/b\n                # Ae = kh\n                if kh <= 0 or tau <= 0 or kh/tau <= 1:\n                    # To avoid math domain error with log, though problem inputs prevent this.\n                    # Or if tolerance is already met with p=0.\n                    p_smooth_raw = 0\n                else:\n                    p_smooth_raw = np.log(kh / tau) / B_COEFF\n                \n                p_smooth = int(np.ceil(p_smooth_raw))\n                # The final formula implicitly handles p_min through max(p_disp, ...),\n                # where p_disp >= 1 and p_smooth for reasonable inputs will be >=1.\n                p_base = max(P_MIN, p_smooth)\n\n            # Step 3: Calculate dispersion-constrained p\n            p_disp = int(np.ceil((k * he) / CHI))\n            \n            # Step 4: Combine and finalize p_e\n            p_intermediate = max(p_disp, p_base)\n            p_element = min(P_MAX, p_intermediate)\n            \n            case_results.append(p_element)\n            \n        all_results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # The default str() for a list includes spaces, which matches the example in the problem description.\n    # The template 'f\"[{','.join(map(str, results))}]\"' recreates this string representation.\n    print(str(all_results).replace(\" \", \"\"))\n\n```", "id": "3314596"}, {"introduction": "One of the most significant challenges in high-frequency wave modeling is the 'pollution effect,' a numerical artifact where phase error accumulates over large distances, eventually corrupting the simulation. This practice requires you to build a 1D finite element solver to investigate this critical issue firsthand. By comparing different p-refinement strategies, you will explore their effectiveness in mitigating pollution error, a key consideration for designing robust and accurate high-frequency solvers. [@problem_id:3336597]", "problem": "Consider a one-dimensional model problem representative of time-harmonic electromagnetic wave propagation: the scalar Helmholtz equation on the interval $\\left[0,L\\right]$,\n$$\nu''(x) + k^2 u(x) = 0 \\quad \\text{for } x \\in (0,L),\n$$\nwith a Dirichlet boundary condition at the left end and a radiation (impedance) boundary condition at the right end,\n$$\nu(0) = 1, \\qquad u'(L) - i k u(L) = 0,\n$$\nwhere $k>0$ is the wavenumber (units: $\\mathrm{m}^{-1}$), $L>0$ is the domain length (units: $\\mathrm{m}$), and $i=\\sqrt{-1}$. The exact solution is the right-traveling plane wave $u_{\\mathrm{exact}}(x) = e^{i k x}$, which has unit amplitude and phase $k x$.\n\nYou will approximate this problem using a continuous Galerkin finite element method with $p$-refinement. Use a uniform mesh with $N$ elements of length $h = L/N$, and polynomial degree $p$ on each element. On each reference element $\\xi \\in [-1,1]$, use the hierarchical basis consisting of two vertex functions and $(p-1)$ bubble functions:\n- Vertex basis functions:\n$$\n\\phi_0(\\xi) = \\frac{1-\\xi}{2}, \\qquad \\phi_1(\\xi) = \\frac{1+\\xi}{2}.\n$$\n- Interior hierarchical bubble basis functions for $m \\in \\{2,3,\\dots,p\\}$:\n$$\n\\phi_m(\\xi) = P_m(\\xi) - P_{m-2}(\\xi),\n$$\nwhere $P_n(\\xi)$ denotes the Legendre polynomial of degree $n$. Note that $\\phi_m(\\pm 1) = 0$ for all $m\\ge 2$. Map derivatives by the affine map $x(\\xi) = x_e + \\frac{h}{2}(1+\\xi)$ so that $\\frac{d}{dx} = \\frac{2}{h}\\frac{d}{d\\xi}$. Use exact integration of the volume bilinear forms via Gaussian quadrature of sufficient order (you may choose any quadrature that is exact for polynomials up to the necessary degrees).\n\nDerive the weak form from first principles: multiply the differential equation by a test function, integrate by parts, and use the boundary conditions to obtain the discrete algebraic system. Assemble the global system with the radiation boundary condition incorporated as the boundary term at $x=L$ and impose the Dirichlet condition at $x=0$ strongly by elimination.\n\nDefine the numerical phase at $x=L$ by $\\theta_h = \\arg\\left(u_h(L)\\right)$ and the exact phase by $\\theta_{\\mathrm{exact}} = k L$. Define the phase error as the principal value difference,\n$$\n\\varepsilon_\\theta = \\left| \\operatorname{atan2}\\left(\\sin(\\theta_h - \\theta_{\\mathrm{exact}}), \\cos(\\theta_h - \\theta_{\\mathrm{exact}})\\right) \\right|,\n$$\nexpressed in radians.\n\nInvestigate the high-frequency Helmholtz pollution effect by comparing two $p$-refinement scaling strategies as the wavenumber $k$ increases:\n- Logarithmic scaling: $p = \\left\\lceil \\alpha \\log(k) \\right\\rceil$,\n- Linear-in-$kh$ scaling: $p = \\left\\lceil \\beta \\, k h \\right\\rceil$,\nwith fixed $\\alpha>0$ and $\\beta>0$. For a fair comparison across $k$, choose the number of elements so that the elements-per-wavelength is fixed:\n$$\nN = \\left\\lceil \\frac{m_e \\, L \\, k}{2\\pi} \\right\\rceil, \\qquad h = \\frac{L}{N},\n$$\nwhere $m_e$ is the prescribed number of elements per wavelength. This choice fixes $k h = \\frac{2\\pi}{m_e}$.\n\nYour program must:\n1. Assemble and solve the complex-valued linear system for the finite element approximation $u_h$ for the test cases specified below.\n2. Compute the phase error $\\varepsilon_\\theta$ for each of the two scaling strategies.\n3. Report, for each test case, a list with three entries: the phase error for logarithmic scaling (rounded to six decimal places), the phase error for linear-in-$kh$ scaling (rounded to six decimal places), and an integer indicator equal to $1$ if the logarithmic scaling yields a strictly smaller phase error than the linear-in-$kh$ scaling, and $0$ otherwise.\n\nUse the following parameter values (units: $k$ in $\\mathrm{m}^{-1}$, $L$ in $\\mathrm{m}$, and the angle in radians):\n- Test case $\\#1$: $k = 50$, $L = 1.0$, $m_e = 8$, $\\alpha = 2.0$, $\\beta = 6.0$.\n- Test case $\\#2$: $k = 100$, $L = 1.0$, $m_e = 8$, $\\alpha = 2.0$, $\\beta = 6.0$.\n- Test case $\\#3$: $k = 200$, $L = 1.0$, $m_e = 8$, $\\alpha = 2.0$, $\\beta = 6.0$.\n- Test case $\\#4$: $k = 100$, $L = 1.0$, $m_e = 4$, $\\alpha = 2.0$, $\\beta = 6.0$.\n\nAngle unit requirement: all phases and phase errors must be computed and reported in radians. Numerical output requirement: your program should produce a single line of output containing the results as a comma-separated list of lists, where each inner list is of the form $[\\varepsilon_{\\theta,\\log}, \\varepsilon_{\\theta,kh}, I]$, with the two phase errors rounded to six decimal places and $I \\in \\{0,1\\}$. For example, a valid output format is\n$$\n[[x_1,y_1,z_1],[x_2,y_2,z_2],[x_3,y_3,z_3],[x_4,y_4,z_4]],\n$$\nwith no spaces and no additional text.\n\nTest suite coverage rationale:\n- The cases $k \\in \\{50,100,200\\}$ with $m_e = 8$ probe the high-frequency regime while maintaining a fixed elements-per-wavelength to isolate pollution effects.\n- The case $k=100$ with $m_e = 4$ probes a coarser resolution edge case (larger $k h$) to test robustness under stronger dispersion.\n- Comparing $p \\sim \\log k$ versus $p \\sim k h$ under fixed $k h$ highlights differing asymptotic behaviors of $p$-refinement strategies in controlling phase error.\n\nYour final program must be complete and runnable, require no user input, and adhere to the exact output format specified above.", "solution": "The problem is assessed to be valid. It is scientifically grounded in the theory of computational electromagnetics, specifically the finite element analysis of the Helmholtz equation. It is well-posed, with a clearly defined differential equation, boundary conditions, and a unique, physically meaningful exact solution for comparison. All parameters and methods are specified unambiguously, allowing for a reproducible numerical experiment.\n\nThe objective is to solve the one-dimensional scalar Helmholtz equation on the domain $[0, L]$ using a continuous Galerkin finite element method (FEM) with $p$-refinement. The governing equation is\n$$\nu''(x) + k^2 u(x) = 0, \\quad x \\in (0,L)\n$$\nsubject to a Dirichlet boundary condition at $x=0$ and a first-order absorbing (radiation) boundary condition at $x=L$:\n$$\nu(0) = 1, \\qquad u'(L) - i k u(L) = 0.\n$$\nHere, $k > 0$ is the wavenumber. This boundary value problem models a right-traveling plane wave, and its exact solution is $u_{\\mathrm{exact}}(x) = e^{ikx}$.\n\n**1. Weak Formulation**\n\nThe foundation of the finite element method is the conversion of the strong form of the differential equation into an equivalent integral weak form. We multiply the Helmholtz equation by an arbitrary test function $v(x)$ from a suitable function space and integrate over the domain $[0,L]$:\n$$\n\\int_0^L v(x) \\left( u''(x) + k^2 u(x) \\right) dx = 0.\n$$\nTo reduce the order of the highest derivative and to incorporate the boundary conditions naturally, we apply integration by parts to the second-derivative term:\n$$\n\\int_0^L v(x) u''(x) dx = \\left[ v(x) u'(x) \\right]_0^L - \\int_0^L v'(x) u'(x) dx.\n$$\nSubstituting this back into the integrated equation gives:\n$$\n\\left[ v(x) u'(x) \\right]_0^L - \\int_0^L v'(x) u'(x) dx + k^2 \\int_0^L v(x) u(x) dx = 0.\n$$\nThe boundary term is $\\left[ v u' \\right]_0^L = v(L)u'(L) - v(0)u'(0)$. We substitute the radiation condition $u'(L) = i k u(L)$ into this term. The Dirichlet condition $u(0)=1$ is enforced strongly, which implies that for all test functions $v(x)$ associated with unknown degrees of freedom, we must have $v(0)=0$. This eliminates the term at $x=0$. The weak form is then: Find a solution $u(x)$ such that for all valid test functions $v(x)$,\n$$\n- \\int_0^L u'(x) v'(x) dx + k^2 \\int_0^L u(x) v(x) dx + i k u(L) v(L) = 0.\n$$\nRearranging to the canonical bilinear form $a(u,v) = f(v)$, we have:\n$$\n\\int_0^L u'(x) v'(x) dx - k^2 \\int_0^L u(x) v(x) dx - i k u(L) v(L) = 0.\n$$\n\n**2. Finite Element Discretization**\n\nWe discretize the domain $[0,L]$ into $N$ uniform elements of length $h=L/N$. Within each element, the solution $u_h(x)$ is approximated as a polynomial of degree $p$. The approximation is written as a linear combination of basis functions $\\phi_j(\\xi)$:\n$$\nu_h(x)|_{I_e} = \\sum_{j=0}^{p} U_j^e \\phi_j(\\xi(x)),\n$$\nwhere $U_j^e$ are the local degrees of freedom (DoFs) for element $e$, and $\\xi(x) = 2(x-x_e)/h - 1$ is the affine map from the physical element $I_e=[x_e, x_{e+1}]$ to the reference element $\\xi \\in [-1,1]$.\n\nThe basis functions specified are a hierarchical set of polynomials up to degree $p$:\n- Two linear vertex functions: $\\phi_0(\\xi) = \\frac{1-\\xi}{2}$, $\\phi_1(\\xi) = \\frac{1+\\xi}{2}$.\n- $(p-1)$ higher-order bubble functions: $\\phi_m(\\xi) = P_m(\\xi) - P_{m-2}(\\xi)$ for $m=2, \\dots, p$, where $P_n(\\xi)$ is the Legendre polynomial of degree $n$. These functions are zero at the element endpoints $\\xi = \\pm 1$.\n\nThe discrete form of the problem is obtained by substituting the approximation for $u_h$ into the weak form and choosing the test functions $v_h$ from the same space (the Galerkin method). This leads to a linear algebraic system $A \\mathbf{U} = \\mathbf{F}$. The system matrix $A$ and vector $\\mathbf{F}$ are assembled from element-level contributions. On each element, we compute an element system matrix $K_{\\text{sys}}^e$:\n$$\n(K_{\\text{sys}}^e)_{ij} = \\int_{I_e} \\left( (\\phi_j^e)' (\\phi_i^e)' - k^2 \\phi_j^e \\phi_i^e \\right) dx.\n$$\nUsing the affine map, the derivatives and integral measure transform as $\\frac{d}{dx} = \\frac{2}{h}\\frac{d}{d\\xi}$ and $dx = \\frac{h}{2} d\\xi$. The element matrix becomes:\n$$\n(K_{\\text{sys}}^e)_{ij} = \\frac{2}{h} \\int_{-1}^1 \\phi_j'(\\xi) \\phi_i'(\\xi)d\\xi - k^2\\frac{h}{2} \\int_{-1}^1 \\phi_j(\\xi) \\phi_i(\\xi)d\\xi.\n$$\nThe integrals on the reference element are computed numerically using Gaussian quadrature with $p+1$ points, which is sufficient to integrate the polynomial products exactly.\n\n**3. System Assembly and Solution**\n\nThe global system matrix is assembled by summing the contributions from each element matrix according to a local-to-global DoF mapping. The numbering of global DoFs is as follows: indices $0, \\dots, N$ correspond to the $N+1$ vertex nodes, and indices $N+1, \\dots, Np$ correspond to the $N(p-1)$ internal bubble function coefficients. This structure leads to a sparse global matrix.\n\nThe radiation boundary condition contributes the term $-i k u(L) v(L)$. In the discrete system, this term only affects the equation for the DoF at the final node $x=L$ (global index $N$). It results in subtracting $ik$ from the diagonal element $A_{NN}$ of the global matrix.\n\nThe Dirichlet condition $u(0)=1$ is imposed strongly. The DoF corresponding to the node at $x=0$ (global index $0$) is set to $1$. The system is then partitioned to solve for the remaining unknown DoFs. If the full system is $A\\mathbf{U}=\\mathbf{F}$, we partition it into known ($U_0=1$) and unknown ($U_R$) parts. The equation for the unknowns becomes $A_{RR} U_R = F_R - A_{R0} U_0$. Since the right-hand side $\\mathbf{F}$ is zero before applying BCs, this simplifies to solving $A_{RR} U_R = -A_{R0}$. The resulting sparse complex-valued linear system is solved for the vector of unknown DoFs $U_R$.\n\n**4. Error Analysis and p-Refinement Strategies**\n\nAfter solving for the coefficient vector $\\mathbf{U}$, the numerical solution at the endpoint $u_h(L)$ is simply the value of the DoF at node $N$, i.e., $u_h(L) = U_N$. We compute the phase error $\\varepsilon_\\theta$ as the absolute principal value of the difference between the numerical phase $\\theta_h = \\arg(u_h(L))$ and the exact phase $\\theta_{\\mathrm{exact}} = kL$:\n$$\n\\varepsilon_\\theta = \\left| \\operatorname{atan2}\\left(\\sin(\\theta_h - \\theta_{\\mathrm{exact}}), \\cos(\\theta_h - \\theta_{\\mathrm{exact}})\\right) \\right|.\n$$\nThe numerical experiment compares two strategies for choosing the polynomial degree $p$ as the wavenumber $k$ increases, while keeping the number of elements per wavelength ($m_e$) fixed. This setup isolates the high-frequency pollution effect, where error increases with $k$ even if the mesh resolution per wavelength is constant. The strategies are:\n- Logarithmic scaling: $p = \\lceil \\alpha \\log(k) \\rceil$.\n- Linear-in-$kh$ scaling: $p = \\lceil \\beta \\, k h \\rceil$. Since $kh \\approx 2\\pi/m_e$ is fixed, this strategy corresponds to a fixed polynomial degree.\n\nThe provided Python code implements this entire procedure, building a sparse system matrix, solving for the nodal values, and calculating the phase errors for the specified test cases and scaling strategies.", "answer": "```python\nimport numpy as np\nfrom scipy.special import eval_legendre\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\nimport math\n\ndef solve_fem(k, L, N, p):\n    \"\"\"\n    Solves the 1D Helmholtz equation using a p-version finite element method.\n\n    Args:\n        k (float): Wavenumber.\n        L (float): Domain length.\n        N (int): Number of elements.\n        p (int): Polynomial degree.\n\n    Returns:\n        complex: The numerical solution at x=L.\n    \"\"\"\n    h = L / N\n    # Total number of degrees of freedom: N+1 vertices + N*(p-1) bubbles\n    num_dofs = N * p + 1 if p > 0 else N + 1\n\n    # Local element matrices calculations\n    local_dim = p + 1\n    \n    # Gaussian quadrature exact for polynomials of degree up to 2p\n    # A rule with p+1 points is exact for degree 2(p+1)-1 = 2p+1.\n    n_quad = p + 1\n    xi_q, w_q = np.polynomial.legendre.leggauss(n_quad)\n\n    # Evaluate basis functions and their derivatives at quadrature points\n    # phi_vals[j, q] = phi_j(xi_q)\n    # dphi_vals[j, q] = phi'_j(xi_q)\n    phi_vals = np.zeros((local_dim, n_quad))\n    dphi_vals = np.zeros((local_dim, n_quad))\n\n    # Vertex functions (j=0, 1)\n    phi_vals[0, :] = (1 - xi_q) / 2\n    dphi_vals[0, :] = -0.5\n    if p > 0:\n        phi_vals[1, :] = (1 + xi_q) / 2\n        dphi_vals[1, :] = 0.5\n    \n    # Bubble functions (j=2...p)\n    if p > 1:\n        for j in range(2, local_dim):\n            # phi_j = P_j - P_{j-2}\n            phi_vals[j, :] = eval_legendre(j, xi_q) - eval_legendre(j - 2, xi_q)\n            # phi'_j = (2j-1) * P_{j-1}\n            dphi_vals[j, :] = (2 * j - 1) * eval_legendre(j - 1, xi_q)\n\n    # Compute local stiffness and mass matrices on reference element [-1, 1]\n    # K_ref_ij = integral(phi'_i * phi'_j dxi)\n    # S_ref_ij = integral(phi_i * phi_j dxi)\n    K_ref = dphi_vals @ np.diag(w_q) @ dphi_vals.T\n    S_ref = phi_vals @ np.diag(w_q) @ phi_vals.T\n\n    # Element system matrix\n    K_sys_elem = (2 / h) * K_ref - (k**2 * h / 2) * S_ref\n\n    # Assemble global matrix using a sparse format for efficiency\n    A_glob = sparse.lil_matrix((num_dofs, num_dofs), dtype=np.complex128)\n    \n    num_bubbles_per_elem = p - 1 if p > 1 else 0\n\n    for e in range(N):\n        dof_map = np.zeros(local_dim, dtype=int)\n        dof_map[0] = e\n        dof_map[1] = e + 1\n        if p > 1:\n            bubble_start_idx = N + 1 + e * num_bubbles_per_elem\n            dof_map[2:] = bubble_start_idx + np.arange(num_bubbles_per_elem)\n        \n        for i in range(local_dim):\n            for j in range(local_dim):\n                I, J = dof_map[i], dof_map[j]\n                A_glob[I, J] += K_sys_elem[i, j]\n\n    # Apply radiation boundary condition u'(L) - iku(L) = 0\n    # Affects the diagonal entry for the last vertex node (node N).\n    A_glob[N, N] -= 1j * k\n\n    # Apply Dirichlet boundary condition u(0) = 1 by elimination\n    A_glob_csc = A_glob.tocsc()\n    A_RR = A_glob_csc[1:, 1:]\n    F_R = -A_glob_csc[1:, 0].toarray().flatten()\n\n    # Solve for unknown DOFs\n    U_R = spsolve(A_RR, F_R)\n\n    # Reconstruct the full solution vector\n    U = np.concatenate(([1.0 + 0.0j], U_R))\n\n    # The value at x=L corresponds to the DOF at node N\n    u_h_L = U[N]\n    return u_h_L\n\ndef calculate_phase_error(u_h_L, k, L):\n    \"\"\"\n    Calculates the phase error at x=L.\n    \"\"\"\n    theta_h = np.angle(u_h_L)\n    theta_exact = k * L\n    delta_theta = theta_h - theta_exact\n    # Use atan2 for a robust principal value of the angle difference\n    phase_error = np.abs(np.arctan2(np.sin(delta_theta), np.cos(delta_theta)))\n    return phase_error\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        (50.0, 1.0, 8, 2.0, 6.0),\n        (100.0, 1.0, 8, 2.0, 6.0),\n        (200.0, 1.0, 8, 2.0, 6.0),\n        (100.0, 1.0, 4, 2.0, 6.0),\n    ]\n\n    results = []\n    for k, L, m_e, alpha, beta in test_cases:\n        # Determine mesh size to fix elements-per-wavelength\n        N = math.ceil(m_e * L * k / (2 * np.pi))\n        h = L / N\n        kh = k * h\n\n        # Logarithmic scaling for p\n        p_log = math.ceil(alpha * np.log(k))\n        u_L_log = solve_fem(k, L, N, int(p_log))\n        err_log = calculate_phase_error(u_L_log, k, L)\n        \n        # Linear-in-kh scaling for p\n        p_kh = math.ceil(beta * kh)\n        u_L_kh = solve_fem(k, L, N, int(p_kh))\n        err_kh = calculate_phase_error(u_L_kh, k, L)\n        \n        indicator = 1 if err_log < err_kh else 0\n        \n        results.append([\n            round(err_log, 6),\n            round(err_kh, 6),\n            indicator\n        ])\n\n    sub_strings = [f\"[{r[0]},{r[1]},{r[2]}]\" for r in results]\n    final_output = f\"[{','.join(sub_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3336597"}]}