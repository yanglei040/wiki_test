{"hands_on_practices": [{"introduction": "The foundation of using Ewald summation is a correct and robust implementation. This first practice guides you through deriving and coding the Ewald representation for the 3D electrostatic periodic Green function from first principles, focusing on numerical stability and diagnostic checks that are crucial for verifying any scientific computing code. By implementing the method and testing for properties like symmetry and parameter independence [@problem_id:3340050], you will build a solid, practical understanding of how the method works.", "problem": "Consider the three-dimensional scalar electrostatic Green function under triply periodic boundary conditions for a simple cubic lattice of period $L$, representing a unit point source embedded in a uniform neutralizing background, so that the potential satisfies the Laplace equation with periodic images and has finite spatial average over a unit cell. Starting from the governing equation $\\nabla^2 \\Phi(\\mathbf{r}) = -4\\pi \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3}\\delta\\!\\left(\\mathbf{r} - \\mathbf{n}L\\right) + \\frac{4\\pi}{L^3}$, where the final term enforces charge neutrality by the uniform background, derive an Ewald-splitting representation that decomposes the potential into a rapidly convergent real-space sum, a rapidly convergent reciprocal-space sum, and a background constant, with a Gaussian screening parameter $\\alpha > 0$. Your derivation must begin from the definition of the free-space Green function $G(\\mathbf{r}) = \\frac{1}{4\\pi \\|\\mathbf{r}\\|}$, the convolution identity, and the Poisson summation formula, and it must justify the removal of the zero reciprocal mode and the addition of the background constant. Do not assume any textbook formulas for the Ewald summation; instead, reason from these base principles.\n\nImplementation objective: Design and implement a numerically stable algorithm to evaluate the resulting Ewald representation for the periodic Green function $\\Phi(\\mathbf{r})$ in a simple cubic cell of side $L$, using finite truncations in both real and reciprocal spaces. The algorithm should:\n- Use a real-space cutoff specified by an integer $N_r$, summing over all integer lattice vectors $\\mathbf{n} = (n_x,n_y,n_z)$ with $n_i \\in \\{-N_r,\\ldots,N_r\\}$, and evaluating the screened direct terms at $\\mathbf{r} + \\mathbf{n}L$ while avoiding the singular self-term at $\\mathbf{r}=\\mathbf{0}$.\n- Use a reciprocal-space cutoff specified by an integer $N_g$, summing over all reciprocal lattice vectors $\\mathbf{G} = \\frac{2\\pi}{L}\\mathbf{m}$ with $\\mathbf{m} = (m_x,m_y,m_z)$ and $m_i \\in \\{-N_g,\\ldots,N_g\\}$, excluding $\\mathbf{G}=\\mathbf{0}$, and including the Gaussian attenuation factor determined by $\\alpha$.\n- Include the uniform background constant implied by the neutralizing background and the exclusion of the $\\mathbf{G}=\\mathbf{0}$ mode.\n- Return a real-valued potential $\\Phi(\\mathbf{r})$ that is independent of the choice of $\\alpha$ in the limit of large cutoffs.\n\nFocus on numerical stability and implementation pitfalls that arise in practical computation:\n- Explain how the choice of $\\alpha$ mediates the division of work between real and reciprocal sums, and why poor choices can cause slow convergence or loss of accuracy due to truncation or catastrophic cancellation.\n- Describe how to treat the near-field behavior for $\\|\\mathbf{r}\\|\\to 0$, including the subtraction of the singular free-space term and the interpretation of the finite regularized limit.\n- Justify the removal of the zero reciprocal mode and the necessity of a uniform background to ensure physical and mathematical consistency under periodic boundary conditions.\n- Identify symmetry properties of $\\Phi(\\mathbf{r})$ and how to leverage them to design diagnostics for implementation errors.\n\nAll quantities in this problem are dimensionless. Angles, where applicable, are in radians.\n\nTest suite and required outputs: Implement your algorithm to compute the following four diagnostics, each returning a single floating-point value.\n\nCase A (screening-parameter independence): With $L = 1.0$, $\\mathbf{r} = \\left(0.31,0.2,0.1\\right)$, $N_r = 4$, $N_g = 4$, compute the absolute difference $\\left|\\Phi_{\\alpha_1}(\\mathbf{r}) - \\Phi_{\\alpha_2}(\\mathbf{r})\\right|$ with $\\alpha_1 = 2.0$ and $\\alpha_2 = 4.0$.\n\nCase B (truncation sensitivity): With $L = 1.0$, $\\mathbf{r} = \\left(0.33,0.27,0.41\\right)$, $\\alpha = 3.0$, compute the absolute difference between a loosely truncated and a tightly truncated evaluation: $\\left|\\Phi^{(N_r=1,N_g=1)}(\\mathbf{r}) - \\Phi^{(N_r=4,N_g=4)}(\\mathbf{r})\\right|$.\n\nCase C (near-field regularization): With $L = 1.0$, $\\mathbf{r}_\\varepsilon = \\left(10^{-4},0.0,0.0\\right)$, $\\alpha = 3.5$, $N_r=5$, $N_g=5$, compute the regularized value $\\Phi(\\mathbf{r}_\\varepsilon) - \\frac{1}{\\|\\mathbf{r}_\\varepsilon\\|}$.\n\nCase D (symmetry diagnostic): With $L = 1.0$, $\\mathbf{r} = \\left(0.21,0.37,0.49\\right)$, $\\alpha = 3.0$, $N_r=4$, $N_g=4$, compute $\\left|\\Phi(\\mathbf{r}) - \\Phi(-\\mathbf{r})\\right|$.\n\nFinal program output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order $\\left[\\text{Case A}, \\text{Case B}, \\text{Case C}, \\text{Case D}\\right]$. For example, a valid output line has the form $\\left[\\text{resultA},\\text{resultB},\\text{resultC},\\text{resultD}\\right]$.", "solution": "The user wants to derive and implement the Ewald summation method for the triply periodic scalar electrostatic Green function for a simple cubic lattice. The problem is well-posed and scientifically sound, representing a standard and fundamental technique in computational physics.\n\n### Derivation of the Ewald Summation Formula\n\nThe objective is to compute the potential $\\Phi(\\mathbf{r})$ generated by a periodic lattice of unit point charges located at positions $\\mathbf{n}L$ for $\\mathbf{n} \\in \\mathbb{Z}^3$, embedded in a uniform neutralizing background. The governing equation is the Poisson equation:\n$$\n\\nabla^2 \\Phi(\\mathbf{r}) = -4\\pi \\rho(\\mathbf{r})\n$$\nwhere the total charge density $\\rho(\\mathbf{r})$ includes the point charges and the background:\n$$\n\\rho(\\mathbf{r}) = \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3} \\delta(\\mathbf{r} - \\mathbf{n}L) - \\frac{1}{L^3}\n$$\nThe formal solution is a sum over the potential from all image charges, $\\Phi(\\mathbf{r}) = \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3} \\frac{1}{\\|\\mathbf{r} - \\mathbf{n}L\\|}$, plus a term for the background. This sum is conditionally convergent and computationally prohibitive. The Ewald method splits this sum into two rapidly convergent series: one in real space and one in reciprocal space.\n\nThe core idea is to add and subtract a lattice of smooth Gaussian charge distributions centered on each point charge. We split the point charge density $\\delta(\\mathbf{r})$ into a short-range part (a point charge screened by a surrounding negative Gaussian) and a long-range part (the positive Gaussian itself):\n$$\n\\delta(\\mathbf{r}) = \\underbrace{\\left( \\delta(\\mathbf{r}) - \\rho_G(\\mathbf{r}, \\alpha) \\right)}_{\\text{short-range}} + \\underbrace{\\rho_G(\\mathbf{r}, \\alpha)}_{\\text{long-range}}\n$$\nwhere $\\rho_G(\\mathbf{r}, \\alpha) = \\frac{\\alpha^3}{\\pi^{3/2}} e^{-\\alpha^2 \\|\\mathbf{r}\\|^2}$ is a normalized Gaussian charge distribution with a tunable width parameter $\\alpha$. The total potential $\\Phi$ is likewise split into $\\Phi = \\Phi_{real} + \\Phi_{recip} + \\Phi_{const}$.\n\n**1. Real-Space Sum ($\\Phi_{real}$)**\n\nThe real-space contribution arises from the lattice of short-range charge densities. The potential of a single point charge screened by a Gaussian is found by solving the Poisson equation, which yields the well-known result:\n$$\n\\phi_{screened}(\\mathbf{r}) = \\frac{1}{\\|\\mathbf{r}\\|} - \\int_{\\mathbb{R}^3} \\frac{\\rho_G(\\mathbf{r'})}{\\|\\mathbf{r}-\\mathbf{r'}\\|} d^3\\mathbf{r'} = \\frac{1}{\\|\\mathbf{r}\\|} - \\frac{\\text{erf}(\\alpha \\|\\mathbf{r}\\|)}{\\|\\mathbf{r}\\|} = \\frac{\\text{erfc}(\\alpha \\|\\mathbf{r}\\|)}{\\|\\mathbf{r}\\|}\n$$\nwhere $\\text{erfc}$ is the complementary error function. Summing this potential over the entire lattice gives the real-space sum:\n$$\n\\Phi_{real}(\\mathbf{r}) = \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3} \\frac{\\text{erfc}(\\alpha \\|\\mathbf{r} - \\mathbf{n}L\\|)}{\\|\\mathbf{r} - \\mathbf{n}L\\|}\n$$\nThis sum converges rapidly because $\\text{erfc}(x)$ decays exponentially for large $x$. The summation is truncated in practice to a finite number of lattice vectors, controlled by the cutoff $N_r$.\n\n**2. Reciprocal-Space Sum ($\\Phi_{recip}$)**\n\nThe reciprocal-space contribution arises from the smooth, periodic lattice of Gaussian charge distributions, $\\rho_{long}(\\mathbf{r}) = \\sum_{\\mathbf{n}\\in\\mathbb{Z}^3} \\rho_G(\\mathbf{r} - \\mathbf{n}L, \\alpha)$, plus the neutralizing background. The total charge density for this part, $\\rho_{recip}(\\mathbf{r}) = \\rho_{long}(\\mathbf{r}) - 1/L^3$, is periodic and has zero average charge. We can therefore expand it in a Fourier series over the reciprocal lattice vectors $\\mathbf{G} = \\frac{2\\pi}{L}\\mathbf{m}$ for $\\mathbf{m} \\in \\mathbb{Z}^3$:\n$$\n\\rho_{recip}(\\mathbf{r}) = \\sum_{\\mathbf{G}\\neq\\mathbf{0}} \\hat{\\rho}_{\\mathbf{G}} e^{i\\mathbf{G}\\cdot\\mathbf{r}}\n$$\nThe Fourier coefficients $\\hat{\\rho}_{\\mathbf{G}}$ are found by integrating over the unit cell. Due to periodicity, this is equivalent to the Fourier transform of a single Gaussian, scaled by the cell volume $V=L^3$:\n$$\n\\hat{\\rho}_{\\mathbf{G}} = \\frac{1}{L^3} \\int_{\\mathbb{R}^3} \\rho_G(\\mathbf{r}, \\alpha) e^{-i\\mathbf{G}\\cdot\\mathbf{r}} d^3\\mathbf{r} = \\frac{1}{L^3} e^{-\\|\\mathbf{G}\\|^2/(4\\alpha^2)}\n$$\nThe $\\mathbf{G}=\\mathbf{0}$ component is zero because the total average charge density is zero. This is the justification for excluding the $\\mathbf{G}=\\mathbf{0}$ term from the sum and for the physical necessity of the neutralizing background; without it, the potential would diverge.\n\nSolving the Poisson equation $\\nabla^2 \\Phi_{recip} = -4\\pi \\rho_{recip}$ in Fourier space gives a simple algebraic relation: $-\\|\\mathbf{G}\\|^2 \\hat{\\Phi}_{\\mathbf{G}} = -4\\pi \\hat{\\rho}_{\\mathbf{G}}$. For $\\mathbf{G} \\ne \\mathbf{0}$, we have:\n$$\n\\hat{\\Phi}_{\\mathbf{G}} = \\frac{4\\pi \\hat{\\rho}_{\\mathbf{G}}}{\\|\\mathbf{G}\\|^2} = \\frac{4\\pi}{L^3 \\|\\mathbf{G}\\|^2} e^{-\\|\\mathbf{G}\\|^2/(4\\alpha^2)}\n$$\nTransforming back to real space gives the reciprocal-space potential sum. Since $\\Phi_{recip}$ must be real and the charge density is even, the sum simplifies using $\\cos(\\mathbf{G}\\cdot\\mathbf{r})$:\n$$\n\\Phi_{recip}(\\mathbf{r}) = \\sum_{\\mathbf{G}\\neq\\mathbf{0}} \\hat{\\Phi}_{\\mathbf{G}} e^{i\\mathbf{G}\\cdot\\mathbf{r}} = \\frac{4\\pi}{L^3} \\sum_{\\mathbf{G}\\neq\\mathbf{0}} \\frac{e^{-\\|\\mathbf{G}\\|^2/(4\\alpha^2)}}{\\|\\mathbf{G}\\|^2} \\cos(\\mathbf{G}\\cdot\\mathbf{r})\n$$\nThis sum converges rapidly because of the Gaussian exponential factor. The summation is truncated with a cutoff $N_g$.\n\n**3. Background Constant ($\\Phi_{const}$)**\n\nThe exclusion of the $\\mathbf{G}=\\mathbf{0}$ mode means that the average value of the potential, $\\langle \\Phi \\rangle$, is not determined by Poisson's equation. A convention must be chosen. A common and physically meaningful one is to set the average potential of the entire system to zero. The combined average of the real and reciprocal space sums is not zero. A constant must be added to enforce $\\langle \\Phi \\rangle=0$. The average of $\\Phi_{recip}$ is zero by construction. The average of $\\Phi_{real}$ is:\n$$\n\\langle \\Phi_{real} \\rangle = \\frac{1}{L^3} \\int_{cell} \\sum_{\\mathbf{n}} \\frac{\\text{erfc}(\\alpha\\|\\mathbf{r}-\\mathbf{n}L\\|)}{\\|\\mathbf{r}-\\mathbf{n}L\\|} d^3\\mathbf{r} = \\frac{1}{L^3} \\int_{\\mathbb{R}^3} \\frac{\\text{erfc}(\\alpha r)}{r} d^3\\mathbf{r} = \\frac \\pi{\\alpha^2 L^3}\n$$\nTo make the total average potential zero, we must subtract this value. Thus, the background constant is:\n$$\n\\Phi_{const} = -\\frac{\\pi}{\\alpha^2 L^3}\n$$\n\n**Final Ewald Formula:**\nThe complete potential is the sum of these three parts:\n$$\n\\Phi(\\mathbf{r}) = \\sum_{\\mathbf{n}} \\frac{\\text{erfc}(\\alpha \\|\\mathbf{r} - \\mathbf{n}L\\|)}{\\|\\mathbf{r} - \\mathbf{n}L\\|} + \\frac{4\\pi}{L^3} \\sum_{\\mathbf{G}\\neq\\mathbf{0}} \\frac{e^{-\\|\\mathbf{G}\\|^2/(4\\alpha^2)}}{\\|\\mathbf{G}\\|^2} \\cos(\\mathbf{G}\\cdot\\mathbf{r}) - \\frac{\\pi}{\\alpha^2 L^3}\n$$\n\n### Numerical Implementation Considerations\n\n- **Choice of $\\alpha$**: The Ewald parameter $\\alpha$ balances the workload between the real- and reciprocal-space sums. A large $\\alpha$ makes the real-space sum converge quickly but the reciprocal-space sum slowly. A small $\\alpha$ has the opposite effect. An optimal $\\alpha$ minimizes the total computation time by roughly equating the truncation errors from both sums. Poor choices of $\\alpha$ can lead to slow convergence and necessitate large cutoffs ($N_r, N_g$) for a given accuracy.\n- **Near-field Behavior**: As the evaluation point $\\mathbf{r}$ approaches a lattice site (e.g., the origin), the $\\mathbf{n}=\\mathbf{0}$ term in the real-space sum, $\\frac{\\text{erfc}(\\alpha \\|\\mathbf{r}\\|)}{\\|\\mathbf{r}\\|}$, becomes singular. For small $\\|\\mathbf{r}\\|$, this term has the expansion $\\frac{1}{\\|\\mathbf{r}\\|} - \\frac{2\\alpha}{\\sqrt{\\pi}} + O(\\|\\mathbf{r}\\|^2)$. The $\\frac{1}{\\|\\mathbf{r}\\|}$ part is the expected singularity of the Green function. The \"regularized\" value, $\\lim_{\\|\\mathbf{r}\\|\\to 0} \\left(\\Phi(\\mathbf{r}) - \\frac{1}{\\|\\mathbf{r}\\|}\\right)$, is a finite constant representing the potential at a charge's location due to all its periodic images and the background field. This value is computed in Case C.\n- **Symmetry**: The source charge distribution $\\rho(\\mathbf{r})$ is an even function, $\\rho(\\mathbf{r}) = \\rho(-\\mathbf{r})$. The resulting potential $\\Phi(\\mathbf{r})$ must also be an even function, $\\Phi(\\mathbf{r}) = \\Phi(-\\mathbf{r})$. This property serves as a powerful diagnostic tool. Any significant deviation in the computed values of $|\\Phi(\\mathbf{r}) - \\Phi(-\\mathbf{r})|$ from zero indicates a potential programming error, for example, in handling vector dot products or in implementing the trigonometric part of the reciprocal-space sum.", "answer": "```python\nimport numpy as np\nfrom scipy.special import erfc\n\ndef compute_phi(r_vec, L, alpha, Nr, Ng):\n    \"\"\"\n    Computes the periodic electrostatic Green function using Ewald summation for a simple cubic lattice.\n\n    This function calculates the potential Phi(r) satisfying the periodic Poisson equation\n    ∇²Φ = -4π Σ_n δ(r - nL) + 4π/L³, which represents a lattice of unit point charges\n    in a uniform neutralizing background.\n\n    Args:\n        r_vec (np.array): Position vector (x, y, z) to evaluate the potential.\n        L (float): Side length of the simple cubic cell.\n        alpha (float): Ewald splitting parameter.\n        Nr (int): Real-space cutoff (sum over n_i in [-Nr, Nr]).\n        Ng (int): Reciprocal-space cutoff (sum over m_i in [-Ng, Ng]).\n\n    Returns:\n        float: The value of the potential Phi(r).\n    \"\"\"\n    r_vec = np.asarray(r_vec, dtype=np.float64)\n    V = L**3\n\n    # Part 1: Real-space sum\n    # This sum is over the short-range part of the potential, which decays rapidly.\n    phi_real = 0.0\n    n_range = range(-Nr, Nr + 1)\n    for nx in n_range:\n        for ny in n_range:\n            for nz in n_range:\n                n_vec = np.array([nx, ny, nz], dtype=np.float64)\n                # The distance between the evaluation point r and the lattice point nL.\n                r_minus_nL = r_vec - n_vec * L\n                d = np.linalg.norm(r_minus_nL)\n                \n                # Avoid division by zero if r is exactly on a lattice point.\n                if d > 1e-14:\n                    phi_real += erfc(alpha * d) / d\n\n    # Part 2: Reciprocal-space sum\n    # This sum is over the long-range, smooth part of the potential.\n    phi_recip = 0.0\n    m_range = range(-Ng, Ng + 1)\n    for mx in m_range:\n        for my in m_range:\n            for mz in m_range:\n                if mx == 0 and my == 0 and mz == 0:\n                    continue  # Exclude the G=0 term, as required for charge neutrality.\n                \n                m_vec = np.array([mx, my, mz], dtype=np.float64)\n                G_vec = (2.0 * np.pi / L) * m_vec\n                G2 = np.dot(G_vec, G_vec)\n                \n                term = np.exp(-G2 / (4.0 * alpha**2)) / G2\n                term *= np.cos(np.dot(G_vec, r_vec))\n                \n                phi_recip += term\n\n    phi_recip *= (4.0 * np.pi / V)\n\n    # Part 3: Background constant term\n    # This constant is added to enforce the convention that the average potential is zero.\n    C_bkg = -np.pi / (alpha**2 * V)\n    \n    return phi_real + phi_recip + C_bkg\n\ndef solve():\n    \"\"\"\n    Calculates and prints the results for the four test cases specified in the problem.\n    \"\"\"\n    # Case A: Screening parameter independence check.\n    # For sufficiently large cutoffs, the result should be nearly independent of alpha.\n    L_A = 1.0\n    r_A = np.array([0.31, 0.2, 0.1])\n    Nr_A, Ng_A = 4, 4\n    alpha1_A, alpha2_A = 2.0, 4.0\n    phi1_A = compute_phi(r_A, L_A, alpha1_A, Nr_A, Ng_A)\n    phi2_A = compute_phi(r_A, L_A, alpha2_A, Nr_A, Ng_A)\n    result_A = np.abs(phi1_A - phi2_A)\n\n    # Case B: Truncation sensitivity check.\n    # Demonstrates that insufficient cutoffs lead to significant error.\n    L_B = 1.0\n    r_B = np.array([0.33, 0.27, 0.41])\n    alpha_B = 3.0\n    phi_loose_B = compute_phi(r_B, L_B, alpha_B, Nr=1, Ng=1)\n    phi_tight_B = compute_phi(r_B, L_B, alpha_B, Nr=4, Ng=4)\n    result_B = np.abs(phi_loose_B - phi_tight_B)\n\n    # Case C: Near-field regularization.\n    # Computes the finite, regularized potential at the location of a source charge.\n    L_C = 1.0\n    r_eps_C_val = 1e-4\n    r_eps_C = np.array([r_eps_C_val, 0.0, 0.0])\n    alpha_C = 3.5\n    Nr_C, Ng_C = 5, 5\n    phi_eps_C = compute_phi(r_eps_C, L_C, alpha_C, Nr_C, Ng_C)\n    result_C = phi_eps_C - 1.0 / r_eps_C_val\n\n    # Case D: Symmetry diagnostic.\n    # Checks if the computed potential satisfies the even symmetry Phi(r) = Phi(-r).\n    L_D = 1.0\n    r_D = np.array([0.21, 0.37, 0.49])\n    alpha_D = 3.0\n    Nr_D, Ng_D = 4, 4\n    phi_r_D = compute_phi(r_D, L_D, alpha_D, Nr_D, Ng_D)\n    phi_neg_r_D = compute_phi(-r_D, L_D, alpha_D, Nr_D, Ng_D)\n    result_D = np.abs(phi_r_D - phi_neg_r_D)\n    \n    results = [result_A, result_B, result_C, result_D]\n    \n    # Print the final output in the required format.\n    print(f\"[{','.join(f'{res:.10f}' for res in results)}]\")\n\nsolve()\n```", "id": "3340050"}, {"introduction": "An efficient Ewald summation requires a careful choice of the splitting parameter, $\\alpha$, which balances the computational effort between the rapidly decaying real-space sum and the reciprocal-space sum. This exercise challenges you to move beyond implementation and into optimization by deriving an analytical expression for the optimal $\\alpha$ [@problem_id:3340042]. This theoretical practice sharpens your ability to analyze algorithmic complexity and connect it to the underlying physics of the problem.", "problem": "Consider the scalar three-dimensional Helmholtz equation for time-harmonic fields with free-space wavenumber $k$, and the associated periodic Green function over a simple-cubic Bravais lattice of lattice constant $a$. The free-space Green function is $G_{0}(\\mathbf{r})=\\exp(\\mathrm{i} k r)/(4\\pi r)$, where $r=|\\mathbf{r}|$. In the Ewald method, one introduces a Gaussian screening with a splitting parameter $\\alpha>0$ to write the periodic Green function as a sum of a rapidly decaying real-space lattice sum and a rapidly decaying reciprocal-space lattice sum. The real-space sum is truncated at radius $R_{c}$, and the reciprocal-space sum is truncated at wavenumber radius $G_{c}$. Assume the wavelength and lattice scale satisfy $k a < 2\\pi$ so that the reciprocal-space tail is exponentially suppressed by the Ewald Gaussian in the lowest reciprocal shell.\n\nFor large arguments, the complementary error function and Gaussian screening imply that the leading-order truncation errors are exponentially dominated as follows (neglecting algebraic prefactors): the real-space truncation error decays as $\\exp\\!\\left(-(\\alpha R_{c})^{2}\\right)$, and the reciprocal-space truncation error decays as $\\exp\\!\\left(-\\left(G_{c}^{2}-k^{2}\\right)/(4\\alpha^{2})\\right)$. You are given a target absolute tolerance $\\varepsilon\\in(0,1)$ on the total truncation error of the Ewald-summed periodic Green function.\n\nAssume an equal allocation of the error budget to the two sums, so that each truncation error is controlled at level approximately $\\varepsilon/2$ via its dominant exponential. This implies the relations\n$$\n(\\alpha R_{c})^{2}=\\ln\\!\\left(\\frac{2}{\\varepsilon}\\right),\\qquad \\frac{G_{c}^{2}-k^{2}}{4\\alpha^{2}}=\\ln\\!\\left(\\frac{2}{\\varepsilon}\\right).\n$$\nFor a simple-cubic lattice with lattice constant $a$, estimate the number of retained real-space and reciprocal-space terms by continuum counts:\n$$\nN_{r}\\approx \\frac{4\\pi R_{c}^{3}}{3 a^{3}},\\qquad N_{k}\\approx \\frac{V}{(2\\pi)^{3}}\\cdot \\frac{4\\pi G_{c}^{3}}{3},\\quad V=a^{3}.\n$$\nChoose the Ewald splitting parameter $\\alpha$ so as to balance the computational work between the two sums by imposing $N_{r}\\approx N_{k}$ while meeting the target tolerance via the exponential controls above. Derive an analytic approximation for the optimal splitting parameter $\\alpha$ as a closed-form function of $\\varepsilon$, $k$, and $a$. Express your final answer as a single analytical expression for $\\alpha(\\varepsilon,k,a)$. No numerical evaluation is required, and no units should be included in the final expression.", "solution": "The problem requires the derivation of an optimal Ewald splitting parameter, $\\alpha$, that balances the computational work between the real-space and reciprocal-space sums while achieving a specified error tolerance, $\\varepsilon$. The computational work is estimated by the number of terms in each sum, $N_r$ and $N_k$, respectively. The optimization criterion is to set $N_r \\approx N_k$.\n\nFirst, we formalize the given relationships. Let the quantity $L$ be defined as $L = \\ln(2/\\varepsilon)$. The two equations governing the error tolerance are given as:\n$$\n(\\alpha R_{c})^{2} = L \\quad (1)\n$$\n$$\n\\frac{G_{c}^{2}-k^{2}}{4\\alpha^{2}} = L \\quad (2)\n$$\nwhere $R_c$ and $G_c$ are the truncation radii in real and reciprocal space, respectively, $k$ is the free-space wavenumber, and $\\alpha$ is the Ewald splitting parameter.\n\nThe number of terms in the real-space sum, $N_r$, and the reciprocal-space sum, $N_k$, are approximated by continuum counts for a simple-cubic lattice with lattice constant $a$:\n$$\nN_{r} \\approx \\frac{4\\pi R_{c}^{3}}{3 a^{3}} \\quad (3)\n$$\n$$\nN_{k} \\approx \\frac{V}{(2\\pi)^{3}}\\cdot \\frac{4\\pi G_{c}^{3}}{3} = \\frac{a^{3}}{8\\pi^3} \\cdot \\frac{4\\pi G_{c}^{3}}{3} = \\frac{a^{3} G_{c}^{3}}{6\\pi^{2}} \\quad (4)\n$$\nwhere $V=a^3$ is the volume of the real-space unit cell.\n\nThe optimization condition to balance the computational work is $N_r \\approx N_k$. Equating the expressions from $(3)$ and $(4)$:\n$$\n\\frac{4\\pi R_{c}^{3}}{3 a^{3}} = \\frac{a^{3} G_{c}^{3}}{6\\pi^{2}}\n$$\nWe can rearrange this equation to find a relationship between $R_c$ and $G_c$:\n$$\n\\frac{R_{c}^{3}}{G_{c}^{3}} = \\frac{a^{3}}{6\\pi^{2}} \\cdot \\frac{3a^3}{4\\pi} = \\frac{3a^6}{24\\pi^3} = \\frac{a^6}{8\\pi^3}\n$$\nTaking the cube root of both sides gives a simple linear relationship:\n$$\n\\frac{R_c}{G_c} = \\left(\\frac{a^6}{8\\pi^3}\\right)^{1/3} = \\frac{a^2}{2\\pi}\n$$\nThis implies $G_c = \\frac{2\\pi}{a^2} R_c$.\n\nNext, we express $R_c$ and $G_c$ in terms of $\\alpha$ using the error control equations $(1)$ and $(2)$. From equation $(1)$:\n$$\nR_c = \\frac{\\sqrt{L}}{\\alpha} \\quad (5)\n$$\nFrom equation $(2)$:\n$$\nG_c^2 = k^2 + 4\\alpha^2 L \\implies G_c = \\sqrt{k^2 + 4\\alpha^2 L} \\quad (6)\n$$\nNow, substitute expressions $(5)$ and $(6)$ into the relationship $G_c = \\frac{2\\pi}{a^2} R_c$:\n$$\n\\sqrt{k^2 + 4\\alpha^2 L} = \\frac{2\\pi}{a^2} \\left(\\frac{\\sqrt{L}}{\\alpha}\\right)\n$$\nTo solve for $\\alpha$, we square both sides of the equation:\n$$\nk^2 + 4\\alpha^2 L = \\left(\\frac{2\\pi}{a^2}\\right)^2 \\left(\\frac{\\sqrt{L}}{\\alpha}\\right)^2 = \\frac{4\\pi^2}{a^4} \\frac{L}{\\alpha^2}\n$$\nMultiplying the entire equation by $\\alpha^2$ clears the denominator:\n$$\nk^2 \\alpha^2 + 4L \\alpha^4 = \\frac{4\\pi^2 L}{a^4}\n$$\nThis can be rearranged into a standard quadratic equation for the variable $\\alpha^2$. Let $x = \\alpha^2$:\n$$\n(4L)x^2 + (k^2)x - \\frac{4\\pi^2 L}{a^4} = 0\n$$\nWe solve this quadratic equation for $x$ using the quadratic formula $x = \\frac{-b \\pm \\sqrt{b^2 - 4ac}}{2a}$, where the coefficients are $a_{quad} = 4L$, $b_{quad} = k^2$, and $c_{quad} = -\\frac{4\\pi^2 L}{a^4}$:\n$$\nx = \\alpha^2 = \\frac{-k^2 \\pm \\sqrt{(k^2)^2 - 4(4L)\\left(-\\frac{4\\pi^2 L}{a^4}\\right)}}{2(4L)}\n$$\n$$\n\\alpha^2 = \\frac{-k^2 \\pm \\sqrt{k^4 + \\frac{64\\pi^2 L^2}{a^4}}}{8L}\n$$\nSince $\\alpha$ is a real-valued physical parameter, $\\alpha^2$ must be a positive real number. The term under the square root, $\\sqrt{k^4 + \\frac{64\\pi^2 L^2}{a^4}}$, is strictly greater than $\\sqrt{k^4} = k^2$. Therefore, to ensure $\\alpha^2 > 0$, we must choose the positive sign in the numerator:\n$$\n\\alpha^2 = \\frac{-k^2 + \\sqrt{k^4 + \\frac{64\\pi^2 L^2}{a^4}}}{8L}\n$$\nTaking the square root of both sides gives the expression for $\\alpha$. We substitute back $L = \\ln(2/\\varepsilon)$:\n$$\n\\alpha = \\sqrt{\\frac{-k^2 + \\sqrt{k^4 + \\frac{64\\pi^2 (\\ln(2/\\varepsilon))^2}{a^4}}}{8 \\ln(2/\\varepsilon)}}\n$$\nThis is the final analytical expression for the optimal splitting parameter $\\alpha$ as a function of the tolerance $\\varepsilon$, the wavenumber $k$, and the lattice constant $a$.", "answer": "$$\n\\boxed{\\sqrt{\\frac{-k^2 + \\sqrt{k^4 + \\frac{64\\pi^2 \\left(\\ln\\left(\\frac{2}{\\varepsilon}\\right)\\right)^2}{a^4}}}{8 \\ln\\left(\\frac{2}{\\varepsilon}\\right)}}}\n$$", "id": "3340042"}, {"introduction": "While Ewald summation is a powerful tool, it is not the only method for accelerating slowly convergent series. To place it in a broader context, this practice involves a comparative study in a simplified one-dimensional setting [@problem_id:3340030]. You will implement and test Ewald summation against other classical techniques like the Shanks transformation and Euler acceleration, revealing the specific regimes where each method excels and developing your intuition for choosing the right numerical tool for the job.", "problem": "Consider the one-dimensional periodic lattice sum associated with the scalar Helmholtz problem, restricted to the axial slice where the source lies on the lattice line. For a dimensionless spectral parameter $t \\in (0, 2\\pi)$, define the lattice sum\n$$\nS(t) \\equiv \\sum_{n=1}^{\\infty} \\frac{2 \\cos(n t)}{n}.\n$$\nThis sum is conditionally convergent and is representative of the slow convergence behavior encountered in periodic Green function evaluations for the three-dimensional Helmholtz equation with one-dimensional periodicity. The goal is to design, implement, and compare numerical accelerations for $S(t)$ using three distinct methods: Ewald summation, Shanks transformation, and Euler acceleration, and to determine regimes of $t$ where Ewald summation is superior or inferior to the other accelerations.\n\nStart from the following foundational bases:\n- The Helmholtz operator $\\nabla^2 + k^2$ and its free-space Green function underpin lattice sums and quasi-periodic Green function evaluations.\n- Poisson summation and Gaussian screening are standard tools for Ewald splitting of conditionally convergent lattice sums.\n- The following well-tested identity for the target sum provides a reference (ground truth) for error assessment:\n$$\nS(t) = - 2 \\log\\!\\left(2 \\sin\\!\\left(\\frac{t}{2}\\right)\\right), \\quad \\text{for } t \\in (0, 2\\pi).\n$$\nUse this identity only as the reference against which numerical approximations are compared.\n\nYou must implement the following estimators for $S(t)$:\n\n$1.$ Truncated direct sum:\n$$\nS_N(t) = \\sum_{n=1}^{N} \\frac{2 \\cos(n t)}{n}.\n$$\n\n$2.$ Shanks transformation (applied to the sequence of partial sums). Given $S_{N-1}(t)$, $S_{N}(t)$, and $S_{N+1}(t)$, define\n$$\n\\mathcal{S}(S_N) = \\frac{S_{N+1}(t)\\, S_{N-1}(t) - \\left(S_{N}(t)\\right)^2}{S_{N+1}(t) + S_{N-1}(t) - 2 S_{N}(t)},\n$$\nprovided the denominator is nonzero; otherwise use $S_{N}(t)$.\n\n$3.$ Euler acceleration via forward differences of the partial sums. Let $\\Delta^0 S_N = S_N$, and recursively define forward differences by\n$$\n\\Delta^{m} S_N = \\Delta^{m-1} S_{N+1} - \\Delta^{m-1} S_{N}, \\quad \\text{for } m \\ge 1.\n$$\nDefine the $K$-term Euler-accelerated estimate\n$$\nE_K(S_N) = \\Delta^0 S_N + \\sum_{m=1}^{K} \\frac{\\Delta^m S_N}{2^m}.\n$$\n\n$4.$ Ewald summation for the one-dimensional Helmholtz lattice sum. Using the complementary error function (erfc) and exponential integral of order one, $\\operatorname{E1}$, implement the Ewald-split approximation\n$$\nS^{\\mathrm{E}}_{\\alpha, N_{\\mathrm{r}}, M_{\\mathrm{g}}}(t) = \n\\underbrace{\\sum_{n=1}^{N_{\\mathrm{r}}} \\frac{2 \\cos(n t)}{n}\\, \\operatorname{erfc}(\\alpha n)}_{\\text{real-space, short-range}}\n\\;+\\;\n\\underbrace{\\sum_{m=-M_{\\mathrm{g}}}^{M_{\\mathrm{g}}} \\operatorname{E1}\\!\\left(\\frac{(t + 2\\pi m)^2}{4 \\alpha^2}\\right)}_{\\text{reciprocal-space, long-range}}.\n$$\nHere $\\alpha > 0$ is the Ewald screening parameter, $N_{\\mathrm{r}}$ is the real-space truncation, and $M_{\\mathrm{g}}$ is the reciprocal-space truncation. The reciprocal-space sum excludes no terms for $t \\in (0, 2\\pi)$ since $(t + 2\\pi m)^2/(4 \\alpha^2) > 0$. The representation above follows from the Gaussian integral identity for $1/|x|$ and the Poisson summation formula specialized to one dimension.\n\nFor each estimator, define the absolute error\n$$\ne_{\\mathrm{method}}(t) = \\left|S_{\\mathrm{method}}(t) - S(t)\\right|,\n$$\nwhere $S(t)$ is the exact reference given above. Angles must be treated in radians.\n\nYour program must perform numerical experiments on the following test suite and, for each test case, determine which method achieves the smallest absolute error. Use the following parameters:\n- Test case $1$: $t = 0.2$, $\\alpha = 0.9$, $N = 200$, $N_{\\mathrm{r}} = 80$, $M_{\\mathrm{g}} = 80$, $K = 8$.\n- Test case $2$: $t = 1.2$, $\\alpha = 0.9$, $N = 200$, $N_{\\mathrm{r}} = 80$, $M_{\\mathrm{g}} = 80$, $K = 8$.\n- Test case $3$: $t = 2.9$, $\\alpha = 0.9$, $N = 200$, $N_{\\mathrm{r}} = 80$, $M_{\\mathrm{g}} = 80$, $K = 8$.\n- Test case $4$: $t = \\pi$, $\\alpha = 0.9$, $N = 200$, $N_{\\mathrm{r}} = 80$, $M_{\\mathrm{g}} = 80$, $K = 8$.\n- Test case $5$: $t = 0.01$, $\\alpha = 0.9$, $N = 200$, $N_{\\mathrm{r}} = 120$, $M_{\\mathrm{g}} = 120$, $K = 8$.\n\nInterpretation guidance:\n- For $t$ near $\\pi$, the terms $\\cos(n t)$ are strongly alternating, favoring Shanks and Euler accelerations.\n- For $t$ near $0$, the series exhibits slow convergence due to weak oscillations, favoring Ewald summation because its reciprocal-space corrections resolve the long-range behavior efficiently.\n- For intermediate $t$, performance can vary depending on parameter choices.\n\nFinal output specification:\n- Label the methods by integers: direct truncated sum $= 0$, Shanks $= 1$, Euler $= 2$, Ewald $= 3$.\n- For each test case, compute $e_{\\mathrm{method}}(t)$ for all methods and select the label of the method with the smallest absolute error.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\"[1,3,2,2,3]\"$). No other text should be printed.\n\nAll angles must be in radians. There are no physical units involved beyond angles, and angles must be specified and treated in radians. The answers for each test case are integers selecting the best method, as defined above.", "solution": "We consider the periodic Green function context for the Helmholtz equation $\\nabla^2 + k^2$ in three dimensions with one-dimensional periodicity. The scalar lattice sum $S(t)$,\n$$\nS(t) = \\sum_{n=1}^{\\infty} \\frac{2 \\cos(n t)}{n},\n$$\ncaptures the slow decay ($\\sim 1/n$) and oscillatory behavior that cause severe convergence issues in direct summation. This is a canonical setting in computational electromagnetics for benchmarking summation acceleration techniques such as Ewald splitting, Shanks transformation, and Euler acceleration. We proceed by building each method from first principles and defining precise algorithms for implementation.\n\n$1.$ Exact reference from Fourier series identity. A well-known identity for trigonometric series gives\n$$\n\\sum_{n=1}^{\\infty} \\frac{\\cos(n t)}{n} = -\\log\\!\\left(2 \\sin\\!\\left(\\frac{t}{2}\\right)\\right), \\quad t \\in (0, 2\\pi).\n$$\nTherefore,\n$$\nS(t) = \\sum_{n=1}^{\\infty} \\frac{2 \\cos(n t)}{n} = - 2 \\log\\!\\left(2 \\sin\\!\\left(\\frac{t}{2}\\right)\\right).\n$$\nWe use this closed-form as the ground truth against which the numerical methods are compared. It is a well-tested formula derived from Fourier analysis and is not the target of our derivation; rather, it serves as a benchmark for error assessment.\n\n$2.$ Direct truncated sum. The simplest estimator truncates the infinite series at $n = N$:\n$$\nS_N(t) = \\sum_{n=1}^{N} \\frac{2 \\cos(n t)}{n}.\n$$\nThis estimator converges slowly for small $t$ due to weak oscillations and the harmonic decay of $1/n$. It provides a baseline for assessing accelerations.\n\n$3.$ Shanks transformation. The Shanks transformation is a nonlinear sequence acceleration method that cancels leading-order asymptotic behavior in sequences. Applied to the sequence $\\{S_N(t)\\}$, it constructs an improved estimate from three consecutive partial sums:\n$$\n\\mathcal{S}(S_N) = \\frac{S_{N+1}(t) S_{N-1}(t) - \\left(S_{N}(t)\\right)^2}{S_{N+1}(t) + S_{N-1}(t) - 2 S_{N}(t)},\n$$\nprovided the denominator is nonzero. Intuitively, if $S_N$ admits an asymptotic form $S_N \\approx S + A/N + B/N^2 + \\cdots$, the Shanks transformation cancels the leading terms, accelerating convergence. In practice, we compute $S_{N-1}(t)$, $S_{N}(t)$, and $S_{N+1}(t)$ from the direct sum and apply the formula.\n\n$4.$ Euler acceleration via forward differences. Euler acceleration is traditionally derived for alternating series, expressing the sum in terms of forward differences weighted by powers of $1/2$. For a general sequence of partial sums, we employ the forward differences of $S_N$:\n$$\n\\Delta^0 S_N = S_N, \\quad \\Delta^1 S_N = S_{N+1} - S_N, \\quad \\Delta^2 S_N = (S_{N+2} - S_{N+1}) - (S_{N+1} - S_N), \\quad \\text{etc.}\n$$\nThen the Euler-accelerated estimate with $K$ terms is\n$$\nE_K(S_N) = \\Delta^0 S_N + \\sum_{m=1}^{K} \\frac{\\Delta^m S_N}{2^m}.\n$$\nWhile this method is most effective for alternating series, it can still improve convergence for sequences with near-alternation or damped oscillations. In our experiment design, cases near $t = \\pi$ exhibit strong alternation and thus suit Euler acceleration.\n\n$5.$ Ewald summation for one-dimensional Helmholtz lattice sums. Ewald summation splits a conditionally convergent lattice sum into rapidly converging real-space and reciprocal-space parts using Gaussian screening and Poisson summation. Starting from the integral identity\n$$\n\\frac{1}{|x|} = \\frac{2}{\\sqrt{\\pi}} \\int_{0}^{\\infty} e^{-x^2 u^2} \\, du,\n$$\nand applying it to the one-dimensional sum with oscillatory factor $e^{i t x}$, we split the integral at the Ewald screening parameter $u = \\alpha$:\n$$\n\\frac{1}{|x|} = \\underbrace{\\frac{2}{\\sqrt{\\pi}} \\int_{\\alpha}^{\\infty} e^{-x^2 u^2} \\, du}_{\\text{real-space}} + \\underbrace{\\frac{2}{\\sqrt{\\pi}} \\int_{0}^{\\alpha} e^{-x^2 u^2} \\, du}_{\\text{reciprocal-space precursor}}.\n$$\nRecognizing\n$$\n\\frac{2}{\\sqrt{\\pi}} \\int_{\\alpha}^{\\infty} e^{-x^2 u^2} \\, du = \\frac{\\operatorname{erfc}(\\alpha |x|)}{|x|},\n$$\nwe form the real-space term\n$$\n\\sum_{n=1}^{\\infty} \\frac{2 \\cos(n t)}{n} \\operatorname{erfc}(\\alpha n).\n$$\nFor the reciprocal-space term, we use the one-dimensional Poisson summation formula on the Gaussian sum\n$$\n\\sum_{n \\in \\mathbb{Z}} e^{-(n)^2 u^2} e^{i t n} = \\frac{\\sqrt{\\pi}}{u} \\sum_{m \\in \\mathbb{Z}} e^{- \\frac{(t + 2\\pi m)^2}{4 u^2}},\n$$\nand integrate from $0$ to $\\alpha$:\n$$\n\\frac{2}{\\sqrt{\\pi}} \\int_{0}^{\\alpha} \\frac{\\sqrt{\\pi}}{u} \\sum_{m \\in \\mathbb{Z}} e^{-\\frac{(t + 2\\pi m)^2}{4 u^2}} \\, du = 2 \\sum_{m \\in \\mathbb{Z}} \\int_{0}^{\\alpha} \\frac{1}{u} e^{-\\frac{(t + 2\\pi m)^2}{4 u^2}} \\, du.\n$$\nWith substitution $s = \\frac{(t + 2\\pi m)^2}{4 u^2}$, $u = \\frac{|t + 2\\pi m|}{2 \\sqrt{s}}$, we get\n$$\n\\int_{0}^{\\alpha} \\frac{1}{u} e^{-\\frac{(t + 2\\pi m)^2}{4 u^2}} \\, du = \\frac{1}{2} \\int_{\\frac{(t + 2\\pi m)^2}{4 \\alpha^2}}^{\\infty} \\frac{e^{-s}}{s} \\, ds = \\frac{1}{2} \\operatorname{E1}\\!\\left(\\frac{(t + 2\\pi m)^2}{4 \\alpha^2}\\right),\n$$\nwhere $\\operatorname{E1}(x) = \\int_{x}^{\\infty} \\frac{e^{-s}}{s} \\, ds$ is the exponential integral of order one. Hence the reciprocal-space sum becomes\n$$\n\\sum_{m \\in \\mathbb{Z}} \\operatorname{E1}\\!\\left(\\frac{(t + 2\\pi m)^2}{4 \\alpha^2}\\right),\n$$\nand the full Ewald representation is\n$$\nS^{\\mathrm{E}}_{\\alpha}(t) = \\sum_{n=1}^{\\infty} \\frac{2 \\cos(n t)}{n} \\operatorname{erfc}(\\alpha n) + \\sum_{m \\in \\mathbb{Z}} \\operatorname{E1}\\!\\left(\\frac{(t + 2\\pi m)^2}{4 \\alpha^2}\\right).\n$$\nTruncating the real-space sum at $n = N_{\\mathrm{r}}$ and the reciprocal-space sum at $m = -M_{\\mathrm{g}}, \\ldots, M_{\\mathrm{g}}$ yields the practical estimator\n$$\nS^{\\mathrm{E}}_{\\alpha, N_{\\mathrm{r}}, M_{\\mathrm{g}}}(t) = \\sum_{n=1}^{N_{\\mathrm{r}}} \\frac{2 \\cos(n t)}{n} \\operatorname{erfc}(\\alpha n) + \\sum_{m=-M_{\\mathrm{g}}}^{M_{\\mathrm{g}}} \\operatorname{E1}\\!\\left(\\frac{(t + 2\\pi m)^2}{4 \\alpha^2}\\right).\n$$\nThis split captures short-range contributions in real space via the complementary error function (which decays rapidly for large $n$) and long-range behavior in reciprocal space via exponential integrals (which decay for large $|m|$).\n\n$6.$ Algorithmic design. For each test case $(t, \\alpha, N, N_{\\mathrm{r}}, M_{\\mathrm{g}}, K)$ (angles in radians), we compute:\n- $S(t)$ exactly by $- 2 \\log\\!\\left(2 \\sin\\!\\left(\\frac{t}{2}\\right)\\right)$.\n- $S_N(t)$ by direct truncation with $N$ terms.\n- $\\mathcal{S}(S_N)$ using $S_{N-1}(t)$, $S_N(t)$, $S_{N+1}(t)$.\n- $E_K(S_N)$ via $K$ forward differences from the sequence $S_N(t), S_{N+1}(t), \\ldots, S_{N+K}(t)$.\n- $S^{\\mathrm{E}}_{\\alpha, N_{\\mathrm{r}}, M_{\\mathrm{g}}}(t)$ using the specified $(\\alpha, N_{\\mathrm{r}}, M_{\\mathrm{g}})$.\n\nWe then compute the absolute errors\n$$\ne_{\\mathrm{direct}}(t) = \\left|S_N(t) - S(t)\\right|,\n\\quad\ne_{\\mathrm{shanks}}(t) = \\left|\\mathcal{S}(S_N) - S(t)\\right|,\n$$\n$$\ne_{\\mathrm{euler}}(t) = \\left|E_K(S_N) - S(t)\\right|,\n\\quad\ne_{\\mathrm{ewald}}(t) = \\left|S^{\\mathrm{E}}_{\\alpha, N_{\\mathrm{r}}, M_{\\mathrm{g}}}(t) - S(t)\\right|.\n$$\nFinally, we select the method label with the smallest absolute error: direct truncated sum $= 0$, Shanks $= 1$, Euler $= 2$, Ewald $= 3$.\n\n$7.$ Regime interpretation. The numerical experiments are structured to reveal the following behaviors:\n- For $t$ near $\\pi$, $\\cos(n t)$ alternates strongly between $+1$ and $-1$, and both Shanks and Euler accelerations effectively cancel leading error terms, often outperforming Ewald for moderate truncations.\n- For $t$ small (e.g., $t = 0.01$), the series exhibits weak oscillation and slow convergence, making reciprocal-space corrections in Ewald summation particularly effective; Ewald typically dominates.\n- For intermediate $t$ values (e.g., $t = 1.2$, $t = 2.9$), performance depends on parameter choices; Ewald and Shanks/Euler may compete.\n\nBy computing and comparing the absolute errors per case and selecting the best method via the specified integer labels, the program generates a clear summary of superiority regimes. The output is a single line containing the integer labels for the test suite, in the required comma-separated list format enclosed in square brackets.", "answer": "```python\nimport numpy as np\nfrom scipy.special import erfc, exp1\n\ndef exact_S(t):\n    # Exact reference: S(t) = -2 * log(2 * sin(t/2)), for t in (0, 2*pi)\n    return -2.0 * np.log(2.0 * np.sin(t / 2.0))\n\ndef direct_truncated(t, N):\n    n = np.arange(1, N + 1, dtype=float)\n    return np.sum(2.0 * np.cos(n * t) / n)\n\ndef shanks_transform(t, N):\n    # Compute S_{N-1}, S_N, S_{N+1}\n    SNm1 = direct_truncated(t, N - 1) if N - 1 >= 1 else direct_truncated(t, 1)\n    SN = direct_truncated(t, N)\n    SNp1 = direct_truncated(t, N + 1)\n    denom = (SNp1 + SNm1 - 2.0 * SN)\n    if denom == 0.0:\n        return SN\n    num = SNp1 * SNm1 - SN * SN\n    return num / denom\n\ndef euler_acceleration(t, N, K):\n    # Build sequence of partial sums: S_N, S_{N+1}, ..., S_{N+K}\n    s_vals = [direct_truncated(t, N + j) for j in range(K + 1)]\n    # Forward differences\n    diffs = [s_vals]\n    for m in range(1, K + 1):\n        prev = diffs[m - 1]\n        diffs.append([prev[i + 1] - prev[i] for i in range(len(prev) - 1)])\n    # Euler accelerated estimate\n    est = diffs[0][0]\n    for m in range(1, K + 1):\n        est += diffs[m][0] / (2.0 ** m)\n    return est\n\ndef ewald_sum_1d_helmholtz(t, alpha, N_real, M_recip):\n    # Real-space short-range sum with complementary error function\n    n = np.arange(1, N_real + 1, dtype=float)\n    real_sum = np.sum(2.0 * np.cos(n * t) / n * erfc(alpha * n))\n    # Reciprocal-space long-range sum via exponential integral E1\n    m = np.arange(-M_recip, M_recip + 1, dtype=float)\n    tm = t + 2.0 * np.pi * m\n    recip_sum = np.sum(exp1((tm ** 2) / (4.0 * alpha * alpha)))\n    return real_sum + recip_sum\n\ndef solve():\n    # Define the test cases from the problem statement:\n    # Each case: (t, alpha, N, N_real, M_recip, K)\n    test_cases = [\n        (0.2, 0.9, 200, 80, 80, 8),\n        (1.2, 0.9, 200, 80, 80, 8),\n        (2.9, 0.9, 200, 80, 80, 8),\n        (np.pi, 0.9, 200, 80, 80, 8),\n        (0.01, 0.9, 200, 120, 120, 8),\n    ]\n\n    # Method labels: 0 = direct truncated, 1 = Shanks, 2 = Euler, 3 = Ewald\n    results = []\n    for (t, alpha, N, N_real, M_recip, K) in test_cases:\n        # Exact reference\n        S_exact = exact_S(t)\n        # Methods\n        S_direct = direct_truncated(t, N)\n        S_shanks = shanks_transform(t, N)\n        S_euler = euler_acceleration(t, N, K)\n        S_ewald = ewald_sum_1d_helmholtz(t, alpha, N_real, M_recip)\n\n        # Errors\n        err_direct = abs(S_direct - S_exact)\n        err_shanks = abs(S_shanks - S_exact)\n        err_euler = abs(S_euler - S_exact)\n        err_ewald = abs(S_ewald - S_exact)\n\n        errors = [err_direct, err_shanks, err_euler, err_ewald]\n        best_method = int(np.argmin(errors))\n        results.append(best_method)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3340030"}]}