{"hands_on_practices": [{"introduction": "Resonators are fundamental components in countless electromagnetic systems, from microwave filters to optical cavities. A crucial design task is to determine their resonant frequencies and energy loss characteristics. The Rayleigh quotient provides a powerful variational tool for estimating the eigenvalues of a system, which are directly related to its resonant frequencies. By extending this principle to a complex-valued functional, we can elegantly model losses from both radiation and material absorption, encapsulating them in a complex frequency. This practice [@problem_id:3359395] offers hands-on experience in implementing a numerical solver to find these complex resonances and their associated quality factors ($Q$), connecting an abstract variational principle to a tangible engineering metric.", "problem": "Consider the time-harmonic Maxwell equations in a one-dimensional setting for a Transverse Electric (TE) polarization, where the electric field scalar amplitude $E(x)$ satisfies a Helmholtz-type equation derived from the curl-curl operator in a stratified medium. Let the computational domain be the interval $[0,L]$ with a physical subdomain containing a dielectric slab of relative permittivity $\\varepsilon_r(x)$ and two outer absorbing layers implemented by a Perfectly Matched Layer (PML). The PML is realized via a complex coordinate stretch factor $s(x)$, which is $1$ in the physical region and equals $1 + i\\alpha$ in the PML regions near the boundaries. Assume a homogeneous magnetic permeability $\\mu(x) = \\mu_0$ and electric permittivity $\\varepsilon(x) = \\varepsilon_0 \\varepsilon_r(x)$, where $\\varepsilon_0$ is the vacuum permittivity and $\\mu_0$ is the vacuum permeability.\n\nStarting from the time-harmonic Maxwell equations and the weak (variational) formulation for the electric field, consider the bilinear forms\n$$\na(E,F) = \\int_{0}^{L} \\frac{1}{\\mu_0} \\frac{1}{s(x)} \\frac{dE}{dx}(x) \\frac{dF}{dx}(x)\\,dx,\n\\qquad\nm(E,F) = \\int_{0}^{L} \\varepsilon_0\\,\\varepsilon_r(x)\\,s(x)\\,E(x)\\,F(x)\\,dx,\n$$\nand define the complex-valued Rayleigh quotient\n$$\n\\lambda(E) = \\frac{a(E,E)}{m(E,E)}.\n$$\nThis quotient, evaluated at an eigenfunction of the PML-augmented operator with homogeneous Dirichlet boundary conditions $E(0)=E(L)=0$, approximates a complex eigenvalue associated with a scattering resonance. The eigenvalue has the interpretation $\\lambda \\approx \\omega^2$, where $\\omega$ is a complex angular frequency, and its imaginary part encodes radiation and absorption losses.\n\nYour tasks are:\n1. Starting strictly from the above variational setting and the time-harmonic Maxwell equations, state why the stationary values of the Rayleigh quotient correspond to generalized eigenvalues of the operator pair $(a(\\cdot,\\cdot), m(\\cdot,\\cdot))$ and how their complex nature arises when a Perfectly Matched Layer (PML) is present. Do not assume any pre-derived formulas not implied by the fundamental laws.\n2. Explain, from first principles of energy decay for damped oscillations in electromagnetics, how a complex angular frequency $ \\omega = \\omega_{\\mathrm{r}} + i \\omega_{\\mathrm{i}} $ with $ \\omega_{\\mathrm{i}} < 0 $ leads to a dimensionless quality factor $Q$ that can be computed from the variational eigenvalues. The relationship must be derived, not assumed.\n3. Implement a complete program that discretizes the one-dimensional weak form using a second-order finite difference scheme on a uniform grid of $N$ points. Use the midpoint flux for the stiffness contribution and a diagonal (lumped) mass approximation. Assemble the generalized eigenproblem\n$$\n\\mathbf{K}\\,\\mathbf{v} = \\lambda\\,\\mathbf{M}\\,\\mathbf{v},\n$$\nwhere $\\mathbf{K}$ and $\\mathbf{M}$ are the discrete analogues of $a(\\cdot,\\cdot)$ and $m(\\cdot,\\cdot)$, respectively, and $\\mathbf{v}$ is the eigenvector of interior degrees of freedom with homogeneous Dirichlet boundaries enforced.\n4. Compute the complex spectrum $\\{\\lambda_j\\}$, map each eigenvalue to its complex angular frequency $\\omega_j$ via $\\omega_j = \\sqrt{\\lambda_j}$ using the principal complex square root, and, for each test case, select the fundamental resonant mode as the one with the smallest positive real part $\\omega_{\\mathrm{r}} > 0$ among those with negative imaginary part $\\omega_{\\mathrm{i}} < 0$. From this selected mode, compute the quality factor $Q$ following your derivation in item 2.\n\nPhysical constants must be used as $\\varepsilon_0 = 8.854187817 \\times 10^{-12}$ farads per meter and $\\mu_0 = 4\\pi \\times 10^{-7}$ henries per meter. All lengths must be expressed in meters. The final reported quantity $Q$ is dimensionless. Angles, where relevant to the analysis of complex exponentials, must be understood in radians.\n\nDiscretization details:\n- Use a uniform grid of $N$ nodes, spacing $h = L/(N-1)$, interior unknowns indexed by $i=1,\\dots,N-2$ enforcing $E(0)=E(L)=0$.\n- Define $s(x)=1$ in the physical region and $s(x)=1+i\\alpha$ in the PML layers $[0,t_{\\mathrm{pml}}]$ and $[L-t_{\\mathrm{pml}},L]$.\n- Define the slab permittivity as $\\varepsilon_r(x) = \\varepsilon_{\\mathrm{slab}}$ in the interval $[x_0-d/2,x_0+d/2]$ and $\\varepsilon_r(x)=1$ elsewhere; allow $\\varepsilon_{\\mathrm{slab}}$ to be complex to model material loss.\n- Discrete stiffness uses $c(x) = \\frac{1}{\\mu_0}\\frac{1}{s(x)}$, midpoint values $c_{i+1/2} = \\frac{1}{2}\\left(c_i + c_{i+1}\\right)$, and the standard three-point stencil\n$$\nK_{ii} = \\frac{c_{i+1/2} + c_{i-1/2}}{h^2},\\quad\nK_{i,i+1} = -\\frac{c_{i+1/2}}{h^2},\\quad\nK_{i,i-1} = -\\frac{c_{i-1/2}}{h^2}.\n$$\n- Discrete mass is lumped on the diagonal as\n$$\nM_{ii} = \\varepsilon_0\\,\\varepsilon_r(x_i)\\,s(x_i)\\,h.\n$$\n\nTest suite:\nProvide and use the following three parameter sets in your program to compute three quality factors $Q$:\n- Case A (baseline resonator, well-absorbing PML): $L=1.0$, $N=200$, $x_0=0.5$, $d=0.4$, $\\varepsilon_{\\mathrm{slab}}=4.0$, $t_{\\mathrm{pml}}=0.2$, $\\alpha=1.0$.\n- Case B (baseline resonator, weak PML): $L=1.0$, $N=180$, $x_0=0.5$, $d=0.4$, $\\varepsilon_{\\mathrm{slab}}=4.0$, $t_{\\mathrm{pml}}=0.2$, $\\alpha=0.2$.\n- Case C (lossy slab, well-absorbing PML): $L=1.0$, $N=200$, $x_0=0.5$, $d=0.4$, $\\varepsilon_{\\mathrm{slab}}=4.0 - 0.5 i$, $t_{\\mathrm{pml}}=0.2$, $\\alpha=1.0$.\n\nImplementation and output specification:\n- Your program must build $\\mathbf{K}$ and $\\mathbf{M}$ for each case, solve the generalized eigenproblem, select the fundamental resonance according to the rule above, and compute the corresponding $Q$.\n- If no suitable resonance is found (no eigenvalue with $\\omega_{\\mathrm{r}}>0$ and $\\omega_{\\mathrm{i}}<0$), output a Not-a-Number for that case.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[q_A,q_B,q_C]\").\n- All computations must be done in double precision complex arithmetic.\n\nYour final answer must be a complete, runnable program that performs these computations without requiring any user input or external files and prints the final results in the specified format.", "solution": "The problem is subjected to validation and is deemed well-posed, scientifically sound, and internally consistent. It presents a standard computational task in electromagnetics involving the calculation of resonant modes in a 1D cavity with Perfectly Matched Layers (PML). The theoretical derivations and numerical implementation steps are clearly outlined and based on established principles. We may therefore proceed with a complete solution.\n\nThe solution is presented in two parts as required: first, a theoretical discussion of the variational principles and the derivation of the quality factor, and second, the numerical implementation.\n\n### 1. Variational Eigenproblem and Complex Eigenvalues\n\nThe core of the problem lies in finding the resonant modes of an open electromagnetic structure. These modes are solutions to the time-harmonic Maxwell's equations that satisfy the boundary conditions without any external source. In the one-dimensional Transverse Electric (TE) case, with an electric field $\\mathbf{E} = E(x)\\hat{\\mathbf{y}}$, Maxwell's equations in a source-free region reduce to the Helmholtz equation. With a complex coordinate stretching $s(x)$ to model the PML, the governing equation is:\n$$\n-\\frac{d}{dx}\\left(\\frac{1}{\\mu_0 s(x)}\\frac{dE}{dx}\\right) = \\omega^2 \\varepsilon_0 \\varepsilon_r(x) s(x) E(x)\n$$\nwhere $\\omega$ is the angular frequency. The solutions $E(x)$ are the resonant modes, and the corresponding values of $\\omega$ are the complex resonant frequencies. We are given the homogeneous Dirichlet boundary conditions $E(0)=E(L)=0$.\n\nTo find the solutions, we use a weak (variational) formulation. Multiplying by a test function $F(x)$ (from the same space of functions as $E(x)$, satisfying the same boundary conditions) and integrating over the domain $[0,L]$ yields:\n$$\n-\\int_0^L F(x) \\frac{d}{dx}\\left(\\frac{1}{\\mu_0 s(x)}\\frac{dE}{dx}\\right) dx = \\omega^2 \\int_0^L F(x) \\varepsilon_0 \\varepsilon_r(x) s(x) E(x) dx\n$$\nApplying integration by parts to the left-hand side:\n$$\n\\int_0^L \\frac{dF}{dx} \\frac{1}{\\mu_0 s(x)} \\frac{dE}{dx} dx - \\left[ F(x) \\frac{1}{\\mu_0 s(x)} \\frac{dE}{dx} \\right]_0^L = \\omega^2 \\int_0^L F(x) \\varepsilon_0 \\varepsilon_r(x) s(x) E(x) dx\n$$\nSince the test function $F(x)$ must satisfy the same homogeneous Dirichlet boundary conditions, $F(0)=F(L)=0$, the boundary term vanishes. This gives the weak form of the eigenproblem: find $E(x)$ such that for all valid test functions $F(x)$,\n$$\n\\int_0^L \\frac{1}{\\mu_0 s(x)} \\frac{dE}{dx}\\frac{dF}{dx} dx - \\omega^2 \\int_0^L \\varepsilon_0 \\varepsilon_r(x) s(x) E(x) F(x) dx = 0\n$$\nBy defining the bilinear forms\n$$\na(E,F) = \\int_{0}^{L} \\frac{1}{\\mu_0 s(x)} \\frac{dE}{dx} \\frac{dF}{dx}\\,dx, \\qquad m(E,F) = \\int_{0}^{L} \\varepsilon_0\\,\\varepsilon_r(x)\\,s(x)\\,E(x)\\,F(x)\\,dx\n$$\nand the eigenvalue $\\lambda = \\omega^2$, the weak form becomes:\n$$\na(E,F) - \\lambda m(E,F) = 0\n$$\nThis is the generalized eigenvalue problem in its continuous, variational form.\n\nThe Rayleigh quotient is defined as $\\lambda(E) = \\frac{a(E,E)}{m(E,E)}$. The stationary values of this quotient correspond to the eigenvalues of the system. To demonstrate this, we find the function $E(x)$ for which the variation of $\\lambda(E)$ is zero, $\\delta\\lambda=0$. The variation with respect to a perturbation $\\delta E$ is:\n$$\n\\delta\\lambda = \\frac{\\delta a(E,E) m(E,E) - a(E,E) \\delta m(E,E)}{[m(E,E)]^2} = 0\n$$\nThis requires $\\delta a(E,E) = \\frac{a(E,E)}{m(E,E)} \\delta m(E,E) = \\lambda(E) \\delta m(E,E)$.\nFor the given symmetric bilinear forms, the first-order variations are $\\delta a(E,E) = 2a(E,\\delta E)$ and $\\delta m(E,E) = 2m(E,\\delta E)$. Substituting these gives:\n$$\n2a(E,\\delta E) = \\lambda(E) \\cdot 2m(E,\\delta E) \\implies a(E,\\delta E) - \\lambda(E) m(E,\\delta E) = 0\n$$\nThis equation must hold for any arbitrary admissible perturbation $\\delta E$. This is precisely the weak form of the eigenvalue problem, where $\\delta E$ plays the role of the test function $F$. Thus, the functions $E$ that render the Rayleigh quotient stationary are the eigenfunctions of the operator pair $(a, m)$, and the stationary values are the corresponding eigenvalues $\\lambda$.\n\nThe complex nature of the eigenvalues arises from the material properties being complex. In this problem, the PML introduces a complex coordinate stretch factor $s(x) = 1 + i\\alpha$ with $\\alpha>0$ in the absorbing layers. This makes the integrands in both $a(E,F)$ and $m(E,F)$ complex-valued. Consequently, the operators they represent are non-Hermitian (specifically, they are complex-symmetric). Non-Hermitian operators generally possess complex eigenvalues. The physical interpretation of a complex eigenvalue $\\lambda = \\omega^2$ is a complex resonant frequency $\\omega$, which signifies a mode that decays over time due to energy loss. The PML is designed to mimic an open, infinite space by absorbing outgoing waves, hence representing radiation loss. If the dielectric constant $\\varepsilon_r(x)$ is also complex, its imaginary part represents material absorption loss.\n\n### 2. Derivation of the Quality Factor $Q$\n\nThe Quality factor, or $Q$ factor, of a resonator quantifies its ability to store energy compared to the rate at which it loses energy. For an electromagnetic resonance with a complex angular frequency $\\omega = \\omega_r + i\\omega_i$, the time evolution of the fields follows $e^{-i\\omega t}$. The problem states that a physically meaningful resonance has $\\omega_r > 0$ and $\\omega_i < 0$. The time-dependent field is given by $\\mathcal{E}(x,t) = \\text{Re}\\{E(x)e^{-i\\omega t}\\}$, where $E(x)$ is the complex eigenfunction.\nThe time-dependent part of the field is:\n$$\ne^{-i\\omega t} = e^{-i(\\omega_r + i\\omega_i)t} = e^{-i\\omega_r t}e^{\\omega_i t}\n$$\nThe total energy $U(t)$ stored in the resonant mode is proportional to the square of the field amplitude. Its temporal evolution follows the envelope of the field squared:\n$$\nU(t) \\propto |e^{-i\\omega t}|^2 = |e^{-i\\omega_r t}e^{\\omega_i t}|^2 = e^{2\\omega_i t}\n$$\nSo, we can write the stored energy as $U(t) = U_0 e^{2\\omega_i t}$, where $U_0$ is the energy at $t=0$. Since $\\omega_i < 0$, the energy decays exponentially, as expected for a lossy system.\n\nThe power dissipated, $P_{\\text{loss}}(t)$, is the rate of decrease of stored energy:\n$$\nP_{\\text{loss}}(t) = -\\frac{dU(t)}{dt} = -\\frac{d}{dt}(U_0 e^{2\\omega_i t}) = -2\\omega_i U_0 e^{2\\omega_i t} = -2\\omega_i U(t)\n$$\nA standard definition of the quality factor is the resonant frequency multiplied by the ratio of the energy stored to the power loss:\n$$\nQ = \\omega_r \\frac{\\text{Energy Stored}}{\\text{Power Loss}}\n$$\nUsing the expressions derived above:\n$$\nQ = \\omega_r \\frac{U(t)}{P_{\\text{loss}}(t)} = \\omega_r \\frac{U(t)}{-2\\omega_i U(t)} = -\\frac{\\omega_r}{2\\omega_i}\n$$\nThis formula directly relates the dimensionless quality factor $Q$ to the real and imaginary parts of the complex resonant frequency $\\omega$. Since $\\omega_r > 0$ and $\\omega_i < 0$, $Q$ is a positive real number, consistent with its physical meaning.\n\n### 3. Numerical Discretization and Implementation\n\nThe continuous problem $a(E,F) = \\lambda m(E,F)$ is discretized using a finite difference method on a uniform grid with $N$ points and spacing $h=L/(N-1)$. The field values at the boundaries are fixed by $E(x_0)=E(x_{N-1})=0$. We solve for the $N-2$ interior field values, $\\mathbf{v} = [E(x_1), \\dots, E(x_{N-2})]^T$. This leads to a matrix generalized eigenvalue problem $\\mathbf{K}\\mathbf{v} = \\lambda\\mathbf{M}\\mathbf{v}$.\n\nThe matrices $\\mathbf{K}$ and $\\mathbf{M}$ are the discrete representations of the bilinear forms $a(\\cdot,\\cdot)$ and $m(\\cdot,\\cdot)$.\nThe stiffness matrix $\\mathbf{K}$ discretizes the term $\\int \\frac{1}{\\mu_0 s(x)} |E'|^2 dx$. Using the given second-order central difference scheme with midpoint averaging for the coefficient $c(x) = \\frac{1}{\\mu_0 s(x)}$, we obtain a tridiagonal, complex-symmetric matrix $\\mathbf{K}$ of size $(N-2) \\times (N-2)$. Its non-zero elements for row $j$ (corresponding to grid point $x_{j+1}$) are:\n$$\nK_{j,j-1} = -\\frac{c_{j+1/2}}{h^2}, \\quad K_{j,j} = \\frac{c_{j+1/2} + c_{j-1/2}}{h^2}, \\quad K_{j,j+1} = -\\frac{c_{j+1/2}}{h^2}\n$$\nwhere $c_{i+1/2} = \\frac{1}{2}(c(x_i) + c(x_{i+1}))$.\n\nThe mass matrix $\\mathbf{M}$ discretizes the term $\\int \\varepsilon_0 \\varepsilon_r(x) s(x) |E|^2 dx$. Using the specified lumped mass approximation, we obtain a diagonal matrix $\\mathbf{M}$ of size $(N-2) \\times (N-2)$ with entries:\n$$\nM_{j,j} = \\varepsilon_0 \\varepsilon_r(x_{j+1}) s(x_{j+1}) h\n$$\nAfter constructing $\\mathbf{K}$ and $\\mathbf{M}$, the generalized eigenvalue problem is solved numerically. The resulting eigenvalues $\\lambda_j$ are used to compute the complex frequencies $\\omega_j = \\sqrt{\\lambda_j}$ (using the principal square root). The fundamental resonant mode is identified as the one with the smallest positive real part $\\omega_r$ among all modes with negative imaginary part $\\omega_i < 0$. Finally, the quality factor $Q$ is computed using the derived formula $Q = -\\omega_r/(2\\omega_i)$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import eig\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases and print the results.\n    \"\"\"\n    # Physical constants\n    EPS0 = 8.854187817e-12  # Vacuum permittivity in F/m\n    MU0 = 4 * np.pi * 1e-7   # Vacuum permeability in H/m\n\n    # Test suite parameters\n    test_cases = [\n        # Case A (baseline resonator, well-absorbing PML)\n        {'L': 1.0, 'N': 200, 'x0': 0.5, 'd': 0.4, 'eps_slab': 4.0, 't_pml': 0.2, 'alpha': 1.0},\n        # Case B (baseline resonator, weak PML)\n        {'L': 1.0, 'N': 180, 'x0': 0.5, 'd': 0.4, 'eps_slab': 4.0, 't_pml': 0.2, 'alpha': 0.2},\n        # Case C (lossy slab, well-absorbing PML)\n        {'L': 1.0, 'N': 200, 'x0': 0.5, 'd': 0.4, 'eps_slab': 4.0 - 0.5j, 't_pml': 0.2, 'alpha': 1.0}\n    ]\n\n    results = []\n    for params in test_cases:\n        q_factor = calculate_q_factor(params, EPS0, MU0)\n        results.append(q_factor)\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_q_factor(params, eps0, mu0):\n    \"\"\"\n    Calculates the quality factor for a single set of parameters.\n    \"\"\"\n    L = params['L']\n    N = params['N']\n    x0 = params['x0']\n    d = params['d']\n    eps_slab = params['eps_slab']\n    t_pml = params['t_pml']\n    alpha = params['alpha']\n\n    # 1. Discretization and Grid Setup\n    h = L / (N - 1)\n    x = np.linspace(0, L, N, dtype=np.float64)\n    dim = N - 2  # Number of interior nodes\n\n    # 2. Define Material and PML Profiles\n    # Relative permittivity profile eps_r(x)\n    eps_r_vec = np.ones(N, dtype=np.complex128)\n    slab_mask = (x >= x0 - d / 2) & (x <= x0 + d / 2)\n    eps_r_vec[slab_mask] = eps_slab\n\n    # PML stretch factor profile s(x)\n    s_vec = np.ones(N, dtype=np.complex128)\n    pml_mask1 = x <= t_pml\n    pml_mask2 = x >= L - t_pml\n    s_vec[pml_mask1] = 1 + 1j * alpha\n    s_vec[pml_mask2] = 1 + 1j * alpha\n    \n    # 3. Assemble Stiffness (K) and Mass (M) Matrices\n    \n    # Stiffness Matrix K\n    c_vec = 1.0 / (mu0 * s_vec)\n    c_mid = 0.5 * (c_vec[:-1] + c_vec[1:])\n    \n    diag_vals = (c_mid[:-1] + c_mid[1:]) / (h**2)\n    offdiag_vals = -c_mid[1:-1] / (h**2)\n    \n    K = np.diag(diag_vals) + np.diag(offdiag_vals, k=1) + np.diag(offdiag_vals, k=-1)\n    K = K.astype(np.complex128)\n\n    # Mass Matrix M (lumped)\n    M_diag = eps0 * eps_r_vec[1:-1] * s_vec[1:-1] * h\n    M = np.diag(M_diag)\n    M = M.astype(np.complex128)\n\n    # 4. Solve the Generalized Eigenvalue Problem\n    try:\n        lambdas, _ = eig(K, M)\n    except np.linalg.LinAlgError:\n        return np.nan\n\n    # 5. Compute Complex Frequencies and Select Fundamental Resonance\n    \n    # Filter out non-physical or unstable eigenvalues\n    valid_lambdas = lambdas[np.isfinite(lambdas)]\n    \n    # Map eigenvalues to complex angular frequencies: omega = sqrt(lambda)\n    omegas = np.sqrt(valid_lambdas)\n    \n    # Filter for resonant modes: Re(omega) > 0 and Im(omega)  0\n    res_mask = (omegas.real  1e-6)  (omegas.imag  -1e-9) # Use small tolerance\n    resonant_omegas = omegas[res_mask]\n\n    if resonant_omegas.size == 0:\n        return np.nan\n\n    # Select the fundamental mode (smallest positive real part)\n    fundamental_omega = resonant_omegas[np.argmin(resonant_omegas.real)]\n    \n    # 6. Compute the Quality Factor Q\n    omega_r = fundamental_omega.real\n    omega_i = fundamental_omega.imag\n    \n    q_factor = -omega_r / (2 * omega_i)\n    \n    return q_factor\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3359395"}, {"introduction": "When discretizing Maxwell's equations, a seemingly straightforward choice of numerical basis functions can unfortunately lead to non-physical, or \"spurious,\" solutions that contaminate the spectrum and corrupt simulation results. This is a classic pitfall in computational electromagnetics, especially when using simple nodal elements for vector fields. Variational principles offer a solution: by augmenting the original energy functional with a penalty term that weakly enforces a physical constraint, such as the divergence-free condition on the electric field, we can suppress these spurious modes. This exercise [@problem_id:3359367] guides you through the derivation and implementation of such a stabilization technique, providing a clear, practical demonstration of how modifying the variational functional directly enhances the physical fidelity of a numerical model.", "problem": "Consider the source-free, time-harmonic Maxwell eigenproblem for the electric field $\\mathbf{E}$ in a simply connected domain with relative permittivity $\\epsilon(\\mathbf{x})$ and relative permeability $\\mu(\\mathbf{x})$, where $\\mu(\\mathbf{x})$ is strictly positive and bounded away from zero. The continuous formulation seeks nontrivial $\\mathbf{E}$ and angular frequency $\\omega$ such that the curl-curl equation and the Gauss law hold in the sense of distributions:\n$$\n\\nabla \\times \\left(\\mu^{-1} \\nabla \\times \\mathbf{E}\\right) \\;=\\; \\omega^2 \\, \\epsilon \\, \\mathbf{E}, \n\\qquad\n\\nabla\\cdot\\left(\\epsilon \\, \\mathbf{E}\\right) \\;=\\; 0,\n$$\nwith appropriate boundary conditions. In the Hilbert space $H(\\mathrm{curl})$, the physically correct eigenmodes are enforced by the divergence constraint $\\nabla\\cdot(\\epsilon \\mathbf{E})=0$. However, when one discretizes with nodal (scalar) elements that do not conform to $H(\\mathrm{curl})$, spurious curl-free modes contaminate the discrete spectrum.\n\nYour task is to derive and computationally study a stabilization derived from a variational principle that weakly enforces the Gauss law. You must then implement a self-contained program that constructs a discrete, periodic two-dimensional model, assembles the stabilized operator, and analyzes the spectral impact of the stabilization for a small test suite.\n\n1) Starting point and derivation target:\n- Begin from the constrained variational statement: find $\\mathbf{E}\\neq \\mathbf{0}$ that is a stationary point of the field energy functional under a normalization,\n$$\n\\mathcal{J}[\\mathbf{E}] \\;=\\; \\int_{\\Omega} \\mu^{-1} \\, \\lVert \\nabla \\times \\mathbf{E} \\rVert^2 \\, \\mathrm{d}\\mathbf{x},\n\\quad \\text{subject to} \\quad \n\\int_{\\Omega} \\epsilon \\, \\lVert \\mathbf{E} \\rVert^2 \\, \\mathrm{d}\\mathbf{x} \\;=\\; 1\n\\quad \\text{and} \\quad \n\\nabla\\cdot(\\epsilon \\mathbf{E}) \\;=\\; 0.\n$$\n- Replace the hard enforcement of $\\nabla\\cdot(\\epsilon \\mathbf{E})=0$ by a quadratic penalty term with a scalar stabilization parameter $\\alpha \\ge 0$, and derive from first principles the Euler–Lagrange equation for the augmented functional. Your derivation must start from the stationary action principle and clearly show how the additional operator arises from the penalty term. Avoid any assumptions that bypass the variational calculus; start from the functional definition and obtain the strong form by taking variations and integrating by parts.\n- You must keep the derivation general for spatially varying $\\epsilon(\\mathbf{x})$ and constant $\\mu(\\mathbf{x})=\\mu_0$ (you may set $\\mu_0=1$ for normalization). Express the final operator in terms of the curl and divergence operators acting on $\\mathbf{E}$ and $\\epsilon \\mathbf{E}$, respectively, and show why the added term modifies the irrotational subspace.\n\n2) Discretization model to implement:\n- Work in two spatial dimensions on the periodic unit torus $\\Omega = [0,1]^2$ with periodic boundary conditions in both directions. Adopt a two-dimensional model with the in-plane electric field $\\mathbf{E} = (E_x,E_y)$; for the curl energy use the out-of-plane scalar curl $\\left(\\nabla \\times \\mathbf{E}\\right)_z = \\partial_x E_y - \\partial_y E_x$ and its square in the integrand.\n- Discretize $\\Omega$ by a uniform $n \\times n$ grid of nodes with grid spacing $h = 1/n$, where $n$ is a positive integer. Represent $E_x$ and $E_y$ by nodal degrees of freedom at the same grid points (i.e., a nodal, nonconforming discretization for $H(\\mathrm{curl})$).\n- Use centered periodic finite differences for first derivatives. In one dimension, the discrete derivative operator must be the circulant matrix approximating $\\partial/\\partial x$ with stencil coefficients $(-\\tfrac{1}{2h}, 0, \\tfrac{1}{2h})$ acting with periodic wrap-around. In two dimensions, construct $\\partial_x$ and $\\partial_y$ via Kronecker products of the one-dimensional operators and identity matrices. Let $D_x$ and $D_y$ denote these two-dimensional discrete derivative matrices acting on nodal scalar fields.\n- Define the discrete scalar curl operator $S$ and discrete divergence operator $D$ by\n  - $S [E_x;E_y] = D_x E_y - D_y E_x$,\n  - $D [E_x;E_y] = D_x E_x + D_y E_y$,\n  where stacking $[E_x;E_y]$ denotes vertical concatenation of the nodal values of $E_x$ and $E_y$ into a single vector.\n- Define the nodal permittivity array $\\epsilon$ at nodes and let $E_\\epsilon$ be the block-diagonal matrix that multiplies $E_x$ and $E_y$ nodally by $\\epsilon$ (that is, $E_\\epsilon = \\mathrm{diag}(\\epsilon,\\epsilon)$ in block form).\n- Assemble the following symmetric, positive semidefinite matrices that discretize the energy and the mass:\n  - The curl energy matrix $A_{\\mathrm{curl}} = S^\\top S \\, h^2$,\n  - The stabilization matrix $A_{\\mathrm{stab}}(\\alpha) = \\alpha \\, E_\\epsilon^\\top D^\\top D \\, E_\\epsilon \\, h^2$,\n  - The mass matrix $M = \\mathrm{diag}(\\epsilon,\\epsilon) \\, h^2$.\n- The generalized stabilized eigenproblem to solve is\n$$\n\\left(A_{\\mathrm{curl}} + A_{\\mathrm{stab}}(\\alpha)\\right) \\mathbf{u} \\;=\\; \\lambda \\, M \\, \\mathbf{u},\n$$\nwhere $\\lambda$ approximates $\\omega^2$ under the stated normalizations. To compute the spectrum robustly, form the scaled symmetric matrix $K = M^{-1/2} \\left(A_{\\mathrm{curl}} + A_{\\mathrm{stab}}(\\alpha)\\right) M^{-1/2}$ and use a dense symmetric eigensolver to obtain all eigenvalues.\n\n3) Spectral metrics to report:\n- Let the full set of eigenvalues be sorted in nondecreasing order. Define a small threshold $\\tau$ to count numerically zero eigenvalues as those $\\lambda$ with $\\lambda  \\tau$.\n- For each test case below, compute:\n  - The integer count $c$ of eigenvalues strictly less than $\\tau$,\n  - The smallest strictly positive eigenvalue $\\lambda_{\\min}^+$, defined as the minimal eigenvalue $\\lambda$ such that $\\lambda \\ge \\tau'$, where $\\tau'$ is a slightly larger threshold with $\\tau'  \\tau$ to avoid reporting numerical zeros. If no such eigenvalue exists, return $\\lambda_{\\min}^+ = 0.0$.\n\n4) Test suite:\nUse the following three test cases, all on the periodic domain, all with $n = 8$ nodes per direction (so $h = 1/8$), and with thresholds $\\tau = 10^{-10}$ and $\\tau' = 10^{-8}$.\n- Case A (no stabilization, uniform medium): $\\alpha = 0$, and $\\epsilon(x,y) \\equiv 1$ for all $(x,y)$.\n- Case B (stabilized, uniform medium): $\\alpha = 1$, and $\\epsilon(x,y) \\equiv 1$ for all $(x,y)$.\n- Case C (stabilized, heterogeneous medium): $\\alpha = 1$, and\n  $$\n  \\epsilon(x,y) \\;=\\; \\begin{cases}\n  2,  \\text{if } x  0.5,\\\\\n  1,  \\text{otherwise.}\n  \\end{cases}\n  $$\n  Evaluate $\\epsilon$ at the nodal coordinates $(x_i,y_j)$, where $x_i = (i+\\tfrac{1}{2})h$ and $y_j = (j+\\tfrac{1}{2})h$ for integers $i,j \\in \\{0,1,\\dots,n-1\\}$, so that the discontinuity is aligned with the interface $x=0.5$ between columns.\n\n5) Required final output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the six values in the following order:\n  - $c_A$, $\\lambda_{\\min,A}^+$, $c_B$, $\\lambda_{\\min,B}^+$, $c_C$, $\\lambda_{\\min,C}^+$,\n  where $c_\\cdot$ are integers and $\\lambda_{\\min,\\cdot}^+$ are decimal numbers rounded to ten digits after the decimal point.\n- Angles do not appear in this problem. There are no physical units to report; all reported values are dimensionless.\n\nYour implementation must be a complete, runnable program that constructs the matrices exactly as specified, solves the eigenproblems for the three cases, and prints the aggregate results in the exact required format.", "solution": "The problem requires the derivation of a stabilized formulation for the Maxwell eigenproblem and its numerical implementation to study the spectral consequences of the stabilization. The core issue is the appearance of non-physical, spurious modes when using nodal finite element or finite difference discretizations, which do not correctly enforce the divergence-free constraint on the electric field.\n\n### 1. Variational Principle and Stabilization\n\nThe source-free, time-harmonic Maxwell's equations in a medium described by relative permittivity $\\epsilon(\\mathbf{x})$ and permeability $\\mu(\\mathbf{x})$ are given by:\n$$\n\\nabla \\times \\mathbf{H} = -i \\omega \\epsilon_0 \\epsilon \\mathbf{E}\n$$\n$$\n\\nabla \\times \\mathbf{E} = i \\omega \\mu_0 \\mu \\mathbf{H}\n$$\n$$\n\\nabla \\cdot (\\epsilon \\mathbf{E}) = 0\n$$\n$$\n\\nabla \\cdot (\\mu \\mathbf{H}) = 0\n$$\nCombining the two curl equations to eliminate the magnetic field $\\mathbf{H}$ and setting the free-space constants $\\epsilon_0, \\mu_0$ to $1$ for normalization, we obtain the curl-curl eigenproblem for the electric field $\\mathbf{E}$:\n$$\n\\nabla \\times \\left(\\mu^{-1} \\nabla \\times \\mathbf{E}\\right) = \\omega^2 \\epsilon \\mathbf{E}\n$$\nThis equation must be solved subject to the Gauss's law constraint $\\nabla \\cdot (\\epsilon \\mathbf{E}) = 0$. The eigenproblem can be formulated variationally. The eigenvalue $\\omega^2$ corresponds to the stationary values of the Rayleigh quotient, which compares the magnetic field energy to the electric field energy. The magnetic energy is proportional to $\\int \\mu^{-1} \\lVert \\nabla \\times \\mathbf{E} \\rVert^2 d\\mathbf{x}$ and the electric energy to $\\int \\epsilon \\lVert \\mathbf{E} \\rVert^2 d\\mathbf{x}$.\n\nThe problem states we should start from a constrained variational problem. We seek stationary points of the functional $\\mathcal{J}[\\mathbf{E}] = \\int_{\\Omega} \\mu^{-1} \\lVert \\nabla \\times \\mathbf{E} \\rVert^2 d\\mathbf{x}$ under the constraints $\\int_{\\Omega} \\epsilon \\lVert \\mathbf{E} \\rVert^2 d\\mathbf{x} = 1$ and $\\nabla\\cdot(\\epsilon \\mathbf{E}) = 0$. The eigenvalue $\\omega^2$ is the Lagrange multiplier for the normalization constraint.\n\nTo weakly enforce the divergence constraint, we add a quadratic penalty term to the energy functional. We set $\\mu(\\mathbf{x})=1$ as per the problem. The augmented Rayleigh quotient for the eigenvalue $\\lambda = \\omega^2$ is:\n$$\n\\lambda = \\frac{\\int_{\\Omega} \\left( \\lVert \\nabla \\times \\mathbf{E} \\rVert^2 + \\alpha \\lVert \\nabla \\cdot (\\epsilon \\mathbf{E}) \\rVert^2 \\right) d\\mathbf{x}}{\\int_{\\Omega} \\epsilon \\lVert \\mathbf{E} \\rVert^2 d\\mathbf{x}}\n$$\nwhere $\\alpha \\ge 0$ is a dimensionless stabilization parameter. To find the Euler-Lagrange equation, we seek the field $\\mathbf{E}$ that makes this quotient stationary. This is equivalent to finding the stationary points of the numerator functional, let's call it $\\mathcal{F}_{\\alpha}[\\mathbf{E}]$, subject to the normalization constraint on the denominator.\n\nLet's find the variation of $\\mathcal{F}_{\\alpha}[\\mathbf{E}]$ with respect to a small perturbation $\\delta\\mathbf{E}$ such that boundary terms vanish (which is satisfied by periodic boundary conditions).\n$$\n\\mathcal{F}_{\\alpha}[\\mathbf{E}] = \\int_{\\Omega} \\left( (\\nabla \\times \\mathbf{E}) \\cdot (\\nabla \\times \\mathbf{E}) + \\alpha (\\nabla \\cdot (\\epsilon \\mathbf{E}))^2 \\right) d\\mathbf{x}\n$$\nThe variation $\\delta \\mathcal{F}_{\\alpha}$ has two parts:\n1.  Variation of the curl term:\n    $\\delta \\int (\\nabla \\times \\mathbf{E}) \\cdot (\\nabla \\times \\mathbf{E}) \\,d\\mathbf{x} = 2 \\int (\\nabla \\times \\mathbf{E}) \\cdot (\\nabla \\times \\delta\\mathbf{E}) \\,d\\mathbf{x}$.\n    Using the vector identity $(\\nabla \\times \\mathbf{A}) \\cdot \\mathbf{B} = (\\nabla \\times \\mathbf{B}) \\cdot \\mathbf{A} - \\nabla \\cdot (\\mathbf{A} \\times \\mathbf{B})$ and integration by parts (divergence theorem), this becomes:\n    $2 \\int (\\nabla \\times (\\nabla \\times \\mathbf{E})) \\cdot \\delta\\mathbf{E} \\,d\\mathbf{x}$.\n\n2.  Variation of the penalty term:\n    $\\delta \\int \\alpha (\\nabla \\cdot (\\epsilon \\mathbf{E}))^2 \\,d\\mathbf{x} = 2 \\alpha \\int (\\nabla \\cdot (\\epsilon \\mathbf{E})) (\\nabla \\cdot (\\epsilon \\delta\\mathbf{E})) \\,d\\mathbf{x}$.\n    Let $f = \\nabla \\cdot (\\epsilon \\mathbf{E})$. Using the identity $\\nabla \\cdot (g \\mathbf{F}) = g(\\nabla \\cdot \\mathbf{F}) + (\\nabla g) \\cdot \\mathbf{F}$ and integration by parts:\n    $2 \\alpha \\int f (\\nabla \\cdot (\\epsilon \\delta\\mathbf{E})) \\,d\\mathbf{x} = 2 \\alpha \\int \\left( \\nabla \\cdot (f \\epsilon \\delta\\mathbf{E}) - (\\nabla f) \\cdot (\\epsilon \\delta\\mathbf{E}) \\right) d\\mathbf{x} = -2\\alpha \\int \\epsilon (\\nabla (\\nabla \\cdot (\\epsilon \\mathbf{E}))) \\cdot \\delta\\mathbf{E} \\,d\\mathbf{x}$.\n\nCombining these terms, the total variation of the numerator is:\n$$\n\\delta \\mathcal{F}_{\\alpha}[\\mathbf{E}] = \\int 2 \\left( \\nabla \\times (\\nabla \\times \\mathbf{E}) - \\alpha \\epsilon \\nabla(\\nabla \\cdot (\\epsilon \\mathbf{E})) \\right) \\cdot \\delta\\mathbf{E} \\,d\\mathbf{x}\n$$\nThe variation of the denominator is $\\delta \\int \\epsilon \\lVert \\mathbf{E} \\rVert^2 d\\mathbf{x} = \\int 2 \\epsilon \\mathbf{E} \\cdot \\delta\\mathbf{E} \\,d\\mathbf{x}$.\nThe stationary condition $\\delta(\\lambda)=0$ leads to the weak form of the Euler-Lagrange equation. For any test function $\\mathbf{V}$, we have:\n$$\n\\int \\left( \\left( \\nabla \\times \\mathbf{E} \\right) \\cdot (\\nabla \\times \\mathbf{V}) + \\alpha \\left( \\nabla \\cdot (\\epsilon \\mathbf{E}) \\right) (\\nabla \\cdot (\\epsilon \\mathbf{V})) \\right) d\\mathbf{x} = \\lambda \\int \\epsilon \\mathbf{E} \\cdot \\mathbf{V} \\, d\\mathbf{x}\n$$\nThe strong form of the Euler-Lagrange equation is obtained by requiring the integrand of the variation with respect to $\\delta\\mathbf{E}$ to be zero, which gives:\n$$\n\\nabla \\times (\\nabla \\times \\mathbf{E}) - \\alpha \\epsilon \\nabla(\\nabla \\cdot (\\epsilon \\mathbf{E})) = \\lambda \\epsilon \\mathbf{E}\n$$\nThe added term, $-\\alpha \\epsilon \\nabla(\\nabla \\cdot (\\epsilon \\mathbf{E}))$, is the stabilization operator. Its purpose is to penalize fields with non-zero divergence. In the unstabilized case ($\\alpha=0$), any irrotational (curl-free) field, $\\mathbf{E}_{\\mathrm{irr}} = \\nabla \\phi$, is an eigenvector with eigenvalue $\\lambda=0$, since $\\nabla \\times (\\nabla \\phi) = \\mathbf{0}$. Nodal discretizations support a large number of such spurious, zero-eigenvalue modes which contaminate the physical spectrum.\n\nWhen $\\alpha  0$, the stabilized operator acts on these modes. For an irrotational field $\\mathbf{E}_{\\mathrm{irr}} = \\nabla \\phi$, the eigenproblem becomes:\n$$\n-\\alpha \\epsilon \\nabla(\\nabla \\cdot (\\epsilon \\nabla\\phi)) = \\lambda \\epsilon \\nabla\\phi\n$$\nThis is a non-trivial equation, which generally implies that $\\lambda  0$ for non-zero fields. The penalty term thus \"lifts\" the eigenvalues of the spurious modes from zero to positive values, effectively separating them from the physically meaningful part of the spectrum.\n\n### 2. Discretization and Numerical Model\n\nWe implement a finite difference discretization on a $2$D periodic unit torus $\\Omega = [0,1]^2$. The grid is uniform with $n \\times n$ nodes and spacing $h=1/n$. The electric field is $\\mathbf{E}=(E_x, E_y)$. The nodal values of $E_x$ and $E_y$ are represented by vectors $\\mathbf{u}_x$ and $\\mathbf{u}_y$, each of length $N = n^2$. The full state vector is $\\mathbf{u} = [\\mathbf{u}_x; \\mathbf{u}_y]$, a column vector of length $2N$.\n\nThe first partial derivatives $\\partial_x$ and $\\partial_y$ are approximated by matrices $D_x$ and $D_y$ constructed using centered finite differences on the periodic grid. The $1$D derivative matrix on an $n$-point grid, $d_{1D}$, is a circulant matrix with stencil $(1/2h, 0, -1/2h)$ modified for periodicity. The $2$D operators are built using Kronecker products. Adopting a row-major ordering of grid points $(x_j, y_i)$, where $i,j \\in \\{0, \\dots, n-1\\}$, the discrete derivatives are $D_x = I_n \\otimes d_{1D}$ and $D_y = d_{1D} \\otimes I_n$.\n\nThe discrete scalar curl and divergence operators, acting on the state vector $\\mathbf{u}$, are defined as block matrices:\n- Discrete scalar curl: $S = [-D_y, D_x]$, such that $S\\mathbf{u}$ approximates $\\partial_x E_y - \\partial_y E_x$.\n- Discrete divergence: $D = [D_x, D_y]$, such that $D\\mathbf{u}$ approximates $\\partial_x E_x + \\partial_y E_y$.\n\nThe permittivity $\\epsilon(x,y)$ is evaluated at each node, forming a vector $\\boldsymbol{\\epsilon}$ of length $N$. The nodal multiplication by $\\epsilon$ is represented by a diagonal matrix $E_{\\epsilon} = \\mathrm{diag}(\\boldsymbol{\\epsilon}, \\boldsymbol{\\epsilon})$.\n\nDiscretizing the weak form of the stabilized eigenproblem using this framework leads to a generalized matrix eigenvalue problem. The integrals become sums over grid cells, scaled by the cell area $h^2$.\n- The curl term $\\int (\\nabla \\times \\mathbf{E}) \\cdot (\\nabla \\times \\mathbf{V}) d\\mathbf{x}$ becomes $\\mathbf{v}^\\top (S^\\top S h^2) \\mathbf{u}$. Thus, $A_{\\mathrm{curl}} = S^\\top S h^2$.\n- The stabilization term $\\int \\alpha (\\nabla \\cdot \\epsilon \\mathbf{E})(\\nabla \\cdot \\epsilon \\mathbf{V})d\\mathbf{x}$ becomes $\\mathbf{v}^\\top (\\alpha E_{\\epsilon}^\\top D^\\top D E_{\\epsilon} h^2) \\mathbf{u}$. Thus, $A_{\\mathrm{stab}}(\\alpha) = \\alpha E_{\\epsilon}^\\top D^\\top D E_{\\epsilon} h^2$.\n- The mass term $\\int \\epsilon \\mathbf{E} \\cdot \\mathbf{V} d\\mathbf{x}$ becomes $\\mathbf{v}^\\top (\\mathrm{diag}(\\boldsymbol{\\epsilon}, \\boldsymbol{\\epsilon}) h^2) \\mathbf{u}$. We define the mass matrix $M = \\mathrm{diag}(\\boldsymbol{\\epsilon}, \\boldsymbol{\\epsilon}) h^2$.\n\nThe resulting generalized symmetric eigenvalue problem is:\n$$\n(A_{\\mathrm{curl}} + A_{\\mathrm{stab}}(\\alpha)) \\mathbf{u} = \\lambda M \\mathbf{u}\n$$\nTo solve this numerically, we transform it into a standard symmetric eigenvalue problem. Since $M$ is diagonal and positive definite, we can compute its inverse square root $M^{-1/2}$ and form the matrix $K = M^{-1/2} (A_{\\mathrm{curl}} + A_{\\mathrm{stab}}(\\alpha)) M^{-1/2}$. The standard eigenproblem $K\\mathbf{w} = \\lambda \\mathbf{w}$ yields the same eigenvalues $\\lambda$, and the original eigenvectors can be recovered via $\\mathbf{u} = M^{-1/2}\\mathbf{w}$.\n\n### 3. Spectral Analysis\n\nThe effect of the stabilization is analyzed by computing the spectrum for three test cases. We count the number of eigenvalues $c$ that are numerically zero (i.e., less than a small threshold $\\tau = 10^{-10}$) and find the smallest strictly positive eigenvalue $\\lambda_{\\min}^+$, defined as the minimum eigenvalue greater than or equal to a threshold $\\tau' = 10^{-8}$.\n\n- **Case A ($\\alpha=0$, uniform $\\epsilon=1$)**: Without stabilization, the operator is $A_{\\mathrm{curl}}$, whose null space consists of all discrete curl-free fields. This space is large, and we expect a large count $c_A$ of zero eigenvalues, representing the spurious modes.\n- **Case B ($\\alpha=1$, uniform $\\epsilon=1$)**: With stabilization, the operator penalizes divergence. The only modes remaining in the null space are those that are both curl-free and divergence-free. On a $2$D torus, these are the two constant vector fields, so we expect $c_B=2$.\n- **Case C ($\\alpha=1$, heterogeneous $\\epsilon$)**: The stabilization term penalizes $\\nabla \\cdot (\\epsilon \\mathbf{E})$. A constant vector field in the $y$-direction, $\\mathbf{E}=(0, C)$, remains curl-free and satisfies $\\nabla\\cdot(\\epsilon \\mathbf{E}) = \\partial_y (C \\epsilon) = 0$ since $\\epsilon$ only varies with $x$. A constant field in the $x$-direction, $\\mathbf{E}=(C, 0)$, gives $\\nabla\\cdot(\\epsilon \\mathbf{E}) = \\partial_x (C \\epsilon) \\neq 0$, so it is penalized. We expect $c_C=1$.\n\nThe smallest positive eigenvalue $\\lambda_{\\min}^+$ represents the lowest frequency physical mode of the discretized system. By removing the clutter of spurious modes around zero, stabilization makes $\\lambda_{\\min}^+$ easier to identify and compute accurately.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and computationally studies a stabilized formulation for the 2D Maxwell eigenproblem\n    on a periodic domain, discretized with finite differences.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    n = 8\n    h = 1.0 / n\n    tau = 1e-10\n    tau_prime = 1e-8\n    \n    # --- Test Case Definitions ---\n    # Case A: No stabilization, uniform medium\n    # Case B: Stabilization, uniform medium\n    # Case C: Stabilization, heterogeneous medium\n    test_cases = [\n        {'alpha': 0.0, 'eps_func': lambda x, y: 1.0},\n        {'alpha': 1.0, 'eps_func': lambda x, y: 1.0},\n        {'alpha': 1.0, 'eps_func': lambda x, y: 2.0 if x  0.5 else 1.0}\n    ]\n    \n    results = []\n\n    # --- Construct 1D and 2D Derivative Operators ---\n    N = n * n\n    \n    # 1D centered derivative matrix with periodic BCs\n    d1 = np.zeros((n, n))\n    for i in range(n):\n        d1[i, (i + 1) % n] = 1.0 / (2 * h)\n        d1[i, (i - 1 + n) % n] = -1.0 / (2 * h)\n\n    # 2D derivative matrices via Kronecker products (for row-major mapping)\n    # Dx acts along columns (changes j in (i,j)), Dy acts along rows (changes i)\n    I_n = np.identity(n)\n    Dx = np.kron(I_n, d1)\n    Dy = np.kron(d1, I_n)\n    \n    # --- Discrete curl and divergence operators ---\n    # S: R^(2N) - R^N, D: R^(2N) - R^N\n    # u = [u_x; u_y]\n    # S maps [Ex; Ey] to (dx Ey - dy Ex)\n    # D maps [Ex; Ey] to (dx Ex + dy Ey)\n    # PyTorch/MATLAB use [Dx, Dy] for Gradient, so Divergence is [-Dx, -Dy] of a vector field\n    # In our notation, this corresponds to [D_x, D_y]\n    S = np.block([[-Dy, Dx]])\n    D = np.block([[Dx, Dy]])\n\n    for case in test_cases:\n        alpha = case['alpha']\n        eps_func = case['eps_func']\n\n        # --- Construct Permittivity Vector ---\n        # Grid coordinates are cell-centered as specified for Case C\n        x_coords = (np.arange(n) + 0.5) * h\n        y_coords = (np.arange(n) + 0.5) * h\n        xx, yy = np.meshgrid(x_coords, y_coords)\n        \n        eps_grid = np.zeros_like(xx)\n        for i in range(n):\n            for j in range(n):\n                eps_grid[i, j] = eps_func(xx[i, j], yy[i, j])\n\n        # Flatten in row-major order\n        eps_vec = eps_grid.flatten()\n        \n        # --- Assemble System Matrices ---\n        # A_curl: curl energy matrix, (2N, 2N)\n        A_curl = S.T @ S * (h**2)\n        \n        # E_eps: Nodal permittivity matrix, (2N, 2N)\n        eps_full_vec = np.concatenate([eps_vec, eps_vec])\n        E_eps_mat = np.diag(eps_full_vec)\n        \n        # A_stab: stabilization matrix, (2N, 2N)\n        A_stab = alpha * (E_eps_mat.T @ D.T @ D @ E_eps_mat) * (h**2)\n        \n        # M: Mass matrix, (2N, 2N)\n        M = np.diag(eps_full_vec) * (h**2)\n\n        # --- Solve the Generalized Eigenproblem ---\n        # A_total u = lambda M u\n        # Transform to standard form: K w = lambda w, where K is symmetric\n        A_total = A_curl + A_stab\n        \n        diag_M = np.diag(M)\n        # Add a small epsilon to avoid division by zero if any epsilon is zero\n        # although problem constraints imply epsilon is positive.\n        M_inv_sqrt = np.diag(1.0 / np.sqrt(diag_M + 1e-20))\n        \n        K = M_inv_sqrt @ A_total @ M_inv_sqrt\n        \n        # Use eigh for symmetric matrices; it returns sorted eigenvalues\n        eigenvalues = np.linalg.eigh(K)[0]\n        \n        # --- Compute Spectral Metrics ---\n        # Count of numerically zero eigenvalues\n        c = np.sum(eigenvalues  tau)\n        \n        # Smallest strictly positive eigenvalue\n        positive_eigs = eigenvalues[eigenvalues = tau_prime]\n        lambda_min_plus = positive_eigs.min() if len(positive_eigs)  0 else 0.0\n        \n        results.extend([c, lambda_min_plus])\n\n    # --- Format and Print Final Output ---\n    output_str = \",\".join(\n        [f\"{x:.10f}\" if isinstance(x, float) else str(x) for x in results]\n    )\n    print(f\"[{output_str}]\")\n\nsolve()\n\n```", "id": "3359367"}, {"introduction": "Beyond analyzing existing systems, a primary goal in engineering is to design new devices that achieve optimal performance. This leads to the \"inverse problem,\" which asks: what input should I provide to get a desired output? The calculus of variations, through the method of Lagrange multipliers and adjoint fields, provides a systematic and computationally efficient framework for solving such constrained optimization problems. This approach allows us to compute the sensitivity of an objective function (e.g., energy loss) with respect to every design variable (e.g., a source current) at the cost of just one extra simulation. This practice [@problem_id:3359382] walks you through the derivation of the core optimality conditions for a source design problem and their implementation in a discrete setting, introducing the powerful adjoint method that underpins modern electromagnetic design.", "problem": "Consider a linear, isotropic, source-driven electromagnetic system in a homogeneous background medium characterized by permittivity $\\varepsilon$, permeability $\\mu$, and conductivity $\\sigma$. Let the impressed source current density be $\\mathbf{J}(\\mathbf{x},t)$, and the total electric and magnetic fields be $\\mathbf{E}(\\mathbf{x},t)$ and $\\mathbf{H}(\\mathbf{x},t)$, respectively. The macroscopic Maxwell equations in the time domain are the fundamental base:\n- $\\nabla \\times \\mathbf{E}(\\mathbf{x},t) = -\\dfrac{\\partial \\mathbf{B}(\\mathbf{x},t)}{\\partial t}$,\n- $\\nabla \\times \\mathbf{H}(\\mathbf{x},t) = \\dfrac{\\partial \\mathbf{D}(\\mathbf{x},t)}{\\partial t} + \\sigma \\mathbf{E}(\\mathbf{x},t) + \\mathbf{J}(\\mathbf{x},t)$,\nwith constitutive relations $\\mathbf{D}(\\mathbf{x},t) = \\varepsilon \\mathbf{E}(\\mathbf{x},t)$ and $\\mathbf{B}(\\mathbf{x},t) = \\mu \\mathbf{H}(\\mathbf{x},t)$. Assume a finite-duration experiment over $t \\in [0,T]$ with vanishing fields outside $[0,T]$. The design variable is the drive current density $\\mathbf{J}(\\mathbf{x},t)$.\n\nYou are asked to design $\\mathbf{J}(\\mathbf{x},t)$ to minimize the time-integrated Joule dissipation density $\\int_{0}^{T} \\int_{\\Omega} \\sigma \\lVert \\mathbf{E}(\\mathbf{x},t) \\rVert^{2} \\, d\\mathbf{x}\\, dt$, subject to a linear far-field constraint. Specifically, suppose a linear functional $\\mathcal{F}$ maps the source to a scalar far-field datum, and the requirement is $\\mathcal{F}[\\mathbf{J}] = d$, where $d$ is a prescribed scalar. Assume that all quantities are nondimensionalized (no physical units are required in the final answers).\n\nPart A. Derivation task (continuous time and space): Starting only from the Maxwell equations stated above, the constitutive relations, and the standard calculus of variations with Lagrange multipliers, derive the Euler–Lagrange optimality conditions for the constrained optimization problem\n$$\n\\min_{\\mathbf{J}} \\int_{0}^{T} \\int_{\\Omega} \\sigma \\lVert \\mathbf{E}(\\mathbf{x},t) \\rVert^{2} \\, d\\mathbf{x} \\, dt \\quad \\text{subject to} \\quad \n\\text{Maxwell's equations and } \\mathcal{F}[\\mathbf{J}] = d.\n$$\nIntroduce Lagrange multiplier fields that enforce Maxwell’s dynamical constraints and a scalar Lagrange multiplier that enforces the far-field constraint. Do not assume any specific form for $\\mathcal{F}$ beyond linearity. Express clearly:\n- the primal (forward) equations,\n- the adjoint (backward) equations,\n- the stationarity condition with respect to $\\mathbf{J}$, and\n- the complementary far-field constraint.\n\nPart B. Reduced one-dimensional model and discrete-time formulation for computation: To make the computation concrete and self-contained, adopt a single-port, single-mode reduction where the spatial current density is separable as $\\mathbf{J}(\\mathbf{x},t) = \\mathbf{s}(\\mathbf{x}) J(t)$ with a fixed spatial profile $\\mathbf{s}(\\mathbf{x})$. In this setting, the electric field at the dissipative region’s representative location is modeled as a linear time-invariant convolution of the scalar source current $J(t)$ with a causal impulse response $g(t)$:\n$$\nE(t) = (g * J)(t) = \\int_{0}^{t} g(t-\\tau) J(\\tau)\\, d\\tau.\n$$\nIntroduce a small quadratic Tikhonov regularization term with coefficient $\\eta  0$ to guarantee a unique minimizer in the discrete setting. The reduced objective and constraint become\n$$\n\\min_{J} \\; \\mathcal{J}[J] = \\int_{0}^{T} \\gamma\\, |(g * J)(t)|^{2} \\, dt + \\eta \\int_{0}^{T} |J(t)|^{2}\\, dt\n\\quad \\text{subject to} \\quad \\int_{0}^{T} w(t) J(t)\\, dt = d,\n$$\nwhere $\\gamma  0$ is a weighting constant and $w(t)$ defines the far-field linear functional $\\mathcal{F}[J] = \\int_{0}^{T} w(t) J(t)\\, dt$. Derive the Euler–Lagrange normal equation for $J(t)$ in this reduced model.\n\nPart C. Discretization and algorithm: Discretize $t \\in [0,T]$ uniformly with $N$ samples and spacing $\\Delta t = T/N$. Let $J_{n} \\approx J(n \\Delta t)$, $g_{n} \\approx g(n \\Delta t)$ with $g_{n} = 0$ for $n  0$, $E_{n} = \\sum_{k=0}^{n} g_{n-k} J_{k}$, and $w_{n} \\approx w(n \\Delta t)$. The discrete objective and constraint are\n$$\n\\mathcal{J}_{d}(\\mathbf{J}) = \\Delta t \\left( \\gamma \\lVert \\mathbf{K}\\mathbf{J} \\rVert_{2}^{2} + \\eta \\lVert \\mathbf{J} \\rVert_{2}^{2} \\right), \n\\quad \\Delta t \\, \\mathbf{w}^{\\top} \\mathbf{J} = d,\n$$\nwhere $\\mathbf{K}$ is the strictly lower-triangular Toeplitz convolution matrix induced by $\\{g_{n}\\}_{n\\ge 0}$. Show that the discrete Karush–Kuhn–Tucker (KKT) system for the optimal $\\mathbf{J}^{\\star}$ and scalar Lagrange multiplier $\\lambda$ is\n$$\n\\begin{bmatrix}\n2 \\Delta t \\, \\mathbf{Q}  \\Delta t \\, \\mathbf{w} \\\\\n\\Delta t \\, \\mathbf{w}^{\\top}  0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{J}^{\\star} \\\\\n\\lambda\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{0} \\\\\nd\n\\end{bmatrix},\n\\quad \\text{with} \\quad \\mathbf{Q} = \\gamma \\, \\mathbf{K}^{\\top} \\mathbf{K} + \\eta \\, \\mathbf{I}.\n$$\n\nProgramming task: Implement a program that constructs $\\mathbf{K}$, forms the KKT system above, solves for $\\mathbf{J}^{\\star}$ and $\\lambda$, and reports the requested quantities for the following test suite. All quantities are nondimensionalized. Angles, where applicable, are in radians.\n\nUse the following test suite, which you must hard-code:\n- Test $1$ (happy path): $N = 128$, $\\Delta t = 0.01$, $T = N \\Delta t$. Let $g_{n} = \\exp(-\\alpha \\, n \\Delta t)$ for $n \\ge 0$ and $g_{n}=0$ for $n0$, with $\\alpha = 4.0$. Let $w_{n} = \\sin(2 \\pi f \\, n \\Delta t)$ for $n \\Delta t \\in [0, 0.5]$ and $w_{n} = 0$ otherwise, with $f = 2.0$. Let $\\gamma = 1.0$, $\\eta = 1.0 \\times 10^{-4}$, and $d = 1.0$. Report the minimized discrete objective value $\\mathcal{J}_{d}(\\mathbf{J}^{\\star})$ as a floating-point number.\n- Test $2$ (identity kernel boundary case with analytic check): $N = 64$, $\\Delta t = 0.02$, $T = N \\Delta t$. Let $g_{0} = 1.0$ and $g_{n} = 0$ for $n \\ge 1$ (so $E_{n} = J_{n}$). Let $w_{n} = 1.0$ for $n = 0,1,\\dots,M-1$ and $w_{n} = 0$ for $n \\ge M$, with $M = 20$. Let $\\gamma = 1.0$, $\\eta = 10^{-8}$, and $d = 2.0$. In this case, the analytic minimizer satisfies $\\mathbf{J}^{\\star} = c \\, \\mathbf{w}$ with $c = d / (\\Delta t \\lVert \\mathbf{w} \\rVert_{2}^{2})$. Report a boolean indicating whether the numerical $\\mathbf{J}^{\\star}$ matches the analytic solution within an $\\ell_{2}$-norm tolerance of $10^{-6}$.\n- Test $3$ (near-singular kernel edge case with regularization): $N = 100$, $\\Delta t = 0.01$, $T = N \\Delta t$. Let the base kernel $\\tilde{g}_{n} = \\exp(-\\beta \\, n \\Delta t)$ for $n \\ge 0$ with $\\beta = 3.0$, then define $g_{n} = \\epsilon \\, \\tilde{g}_{n}$ with $\\epsilon = 10^{-4}$. Let $w_{n} = \\cos(2 \\pi f \\, n \\Delta t)$ for $n \\Delta t \\in [0, 0.4]$ and $w_{n} = 0$ otherwise, with $f = 1.5$. Let $\\gamma = 1.0$, $\\eta = 10^{-2}$, and $d = 0.3$. Report the absolute constraint violation $|\\Delta t \\, \\mathbf{w}^{\\top} \\mathbf{J}^{\\star} - d|$ as a floating-point number.\n\nFinal output specification: Your program should produce a single line of output containing the results for Tests $1$–$3$ as a comma-separated list enclosed in square brackets, in the order described: $[\\mathcal{J}_{d}(\\mathbf{J}^{\\star}) \\text{ from Test } 1, \\text{ boolean from Test } 2, \\text{ absolute violation from Test } 3]$. For example, a valid output line would look like $[0.123456,True,1e-09]$.", "solution": "The problem asks for derivations related to an electromagnetic optimization problem and a numerical implementation of its reduced, discretized form. The validation confirms the problem is scientifically sound, well-posed, and self-contained.\n\n### Part A: Derivation of Continuous Optimality Conditions\n\nThe optimization problem is to minimize the time-integrated Joule dissipation subject to Maxwell's equations and a linear far-field constraint.\n$$\n\\min_{\\mathbf{J}} \\int_{0}^{T} \\int_{\\Omega} \\sigma \\lVert \\mathbf{E}(\\mathbf{x},t) \\rVert^{2} \\, d\\mathbf{x} \\, dt \\quad \\text{subject to} \\quad \n\\begin{cases}\n\\nabla \\times \\mathbf{E} + \\mu \\frac{\\partial \\mathbf{H}}{\\partial t} = \\mathbf{0} \\\\\n\\nabla \\times \\mathbf{H} - \\varepsilon \\frac{\\partial \\mathbf{E}}{\\partial t} - \\sigma \\mathbf{E} = \\mathbf{J} \\\\\n\\mathcal{F}[\\mathbf{J}] = d\n\\end{cases}\n$$\nWe introduce Lagrange multipliers: vector fields $\\mathbf{E}_a(\\mathbf{x},t)$ and $\\mathbf{H}_a(\\mathbf{x},t)$ for the two Maxwell's equations, and a scalar $\\lambda$ for the far-field constraint. The augmented Lagrangian functional $\\mathcal{L}$ is:\n$$\n\\mathcal{L}[\\mathbf{E}, \\mathbf{H}, \\mathbf{J}, \\mathbf{E}_a, \\mathbf{H}_a, \\lambda] = \\int_{0}^{T}\\int_{\\Omega} \\sigma \\mathbf{E} \\cdot \\mathbf{E} \\, d\\mathbf{x}dt + \\lambda(\\mathcal{F}[\\mathbf{J}] - d) \\\\\n+ \\int_{0}^{T}\\int_{\\Omega} \\mathbf{E}_a \\cdot \\left(\\nabla \\times \\mathbf{H} - \\varepsilon \\frac{\\partial \\mathbf{E}}{\\partial t} - \\sigma \\mathbf{E} - \\mathbf{J}\\right) d\\mathbf{x}dt \\\\\n+ \\int_{0}^{T}\\int_{\\Omega} \\mathbf{H}_a \\cdot \\left(\\nabla \\times \\mathbf{E} + \\mu \\frac{\\partial \\mathbf{H}}{\\partial t}\\right) d\\mathbf{x}dt\n$$\nThe optimality conditions are found by setting the first variation $\\delta\\mathcal{L}$ with respect to all variables to zero.\n\nTaking variations with respect to the Lagrange multipliers $\\mathbf{E}_a, \\mathbf{H}_a, \\lambda$ recovers the primal equations and constraints.\n\nThe variation with respect to the state fields $\\mathbf{E}$ and $\\mathbf{H}$ yields the adjoint equations. We use integration by parts in time and space, assuming boundary terms on $\\partial\\Omega$ and at $t=0,T$ vanish.\nThe variation with respect to $\\mathbf{E}$ gives:\n$$\n\\delta_{\\mathbf{E}} \\mathcal{L} = \\int_{0}^{T}\\int_{\\Omega} \\left( 2\\sigma\\mathbf{E} - \\sigma\\mathbf{E}_a + \\varepsilon \\frac{\\partial \\mathbf{E}_a}{\\partial t} + \\nabla \\times \\mathbf{H}_a \\right) \\cdot \\delta\\mathbf{E} \\,d\\mathbf{x}dt = 0\n$$\nSince this holds for arbitrary $\\delta\\mathbf{E}$, the term in parentheses must be zero, which gives one of the adjoint Maxwell's equations.\nThe variation with respect to $\\mathbf{H}$ gives:\n$$\n\\delta_{\\mathbf{H}} \\mathcal{L} = \\int_{0}^{T}\\int_{\\Omega} \\left( \\nabla \\times \\mathbf{E}_a - \\mu \\frac{\\partial \\mathbf{H}_a}{\\partial t} \\right) \\cdot \\delta\\mathbf{H} \\,d\\mathbf{x}dt = 0\n$$\nThis gives the other adjoint Maxwell's equation.\n\nThe variation with respect to the control variable $\\mathbf{J}$ gives the stationarity condition. Given the linearity of $\\mathcal{F}$, we can write $\\mathcal{F}[\\delta\\mathbf{J}] = \\langle \\nabla_{\\mathbf{J}}\\mathcal{F}, \\delta\\mathbf{J} \\rangle$, where $\\nabla_{\\mathbf{J}}\\mathcal{F}$ is the Riesz representer of the functional derivative.\n$$\n\\delta_{\\mathbf{J}} \\mathcal{L} = \\int_{0}^{T}\\int_{\\Omega} (-\\mathbf{E}_a) \\cdot \\delta\\mathbf{J} \\,d\\mathbf{x}dt + \\lambda \\mathcal{F}[\\delta\\mathbf{J}] = 0 \\implies \\langle -\\mathbf{E}_a + \\lambda \\nabla_{\\mathbf{J}}\\mathcal{F}, \\delta\\mathbf{J} \\rangle = 0\n$$\nThis must hold for all admissible variations $\\delta\\mathbf{J}$, leading to the stationarity condition.\n\nThe complete optimality system is as follows:\n\n**Primal (Forward) Equations** ($t \\in [0,T]$):\n- $\\nabla \\times \\mathbf{E}(\\mathbf{x},t) + \\mu \\dfrac{\\partial \\mathbf{H}(\\mathbf{x},t)}{\\partial t} = \\mathbf{0}$\n- $\\nabla \\times \\mathbf{H}(\\mathbf{x},t) - \\varepsilon \\dfrac{\\partial \\mathbf{E}(\\mathbf{x},t)}{\\partial t} - \\sigma \\mathbf{E}(\\mathbf{x},t) = \\mathbf{J}(\\mathbf{x},t)$\n- With initial conditions $\\mathbf{E}(\\mathbf{x},0) = \\mathbf{0}$, $\\mathbf{H}(\\mathbf{x},0) = \\mathbf{0}$.\n\n**Adjoint (Backward) Equations** ($t \\in [0,T]$):\n- $\\nabla \\times \\mathbf{E}_a(\\mathbf{x},t) - \\mu \\dfrac{\\partial \\mathbf{H}_a(\\mathbf{x},t)}{\\partial t} = \\mathbf{0}$\n- $\\nabla \\times \\mathbf{H}_a(\\mathbf{x},t) + \\varepsilon \\dfrac{\\partial \\mathbf{E}_a(\\mathbf{x},t)}{\\partial t} - \\sigma \\mathbf{E}_a(\\mathbf{x},t) = -2\\sigma \\mathbf{E}(\\mathbf{x},t)$\n- With terminal conditions $\\mathbf{E}_a(\\mathbf{x},T) = \\mathbf{0}$, $\\mathbf{H}_a(\\mathbf{x},T) = \\mathbf{0}$. Note the negative sign on the time-derivative term for $\\mathbf{H}_a$, indicating time-reversal.\n\n**Stationarity Condition:**\n- $\\mathbf{E}_a(\\mathbf{x},t) = \\lambda \\left( \\nabla_{\\mathbf{J}} \\mathcal{F} \\right)(\\mathbf{x},t)$, where $\\nabla_{\\mathbf{J}} \\mathcal{F}$ is the representer of the functional derivative of $\\mathcal{F}$.\n\n**Complementary Far-Field Constraint:**\n- $\\mathcal{F}[\\mathbf{J}] = d$.\n\n### Part B: Euler–Lagrange Equation for the Reduced 1D Model\n\nThe reduced problem is:\n$$\n\\min_{J} \\; \\mathcal{J}[J] = \\int_{0}^{T} \\gamma\\, |(g * J)(t)|^{2} \\, dt + \\eta \\int_{0}^{T} |J(t)|^{2}\\, dt\n\\quad \\text{subject to} \\quad \\int_{0}^{T} w(t) J(t)\\, dt = d.\n$$\nThe Lagrangian is:\n$$\n\\mathcal{L}[J, \\lambda] = \\int_{0}^{T} \\left( \\gamma |(g * J)(t)|^{2} + \\eta |J(t)|^{2} \\right) dt + \\lambda \\left( \\int_{0}^{T} w(t) J(t) dt - d \\right).\n$$\nTaking the variation with respect to $J$ and setting it to zero gives $\\delta_J \\mathcal{L} = 0$:\n$$\n\\int_{0}^{T} 2\\gamma (g*J)(t) \\cdot (g*\\delta J)(t) \\,dt + \\int_{0}^{T} 2\\eta J(t) \\cdot \\delta J(t) \\,dt + \\lambda \\int_{0}^{T} w(t) \\cdot \\delta J(t) \\,dt = 0.\n$$\nUsing the property of convolutions in an inner product, $\\langle u, v*z \\rangle = \\langle v^{rev}*u, z \\rangle$ where $v^{rev}(t) = v(-t)$, the first term becomes:\n$$\n\\int_{0}^{T} 2\\gamma (g^{rev} * (g*J))(t) \\cdot \\delta J(t) \\,dt.\n$$\nCombining terms, we have:\n$$\n\\int_{0}^{T} \\left( 2\\gamma (g^{rev} * g * J)(t) + 2\\eta J(t) + \\lambda w(t) \\right) \\delta J(t) \\,dt = 0.\n$$\nSince this holds for arbitrary variations $\\delta J(t)$, the integrand must be zero. This yields the Euler-Lagrange normal equation for $J(t)$:\n$$\n2\\gamma (g^{rev} * g * J)(t) + 2\\eta J(t) + \\lambda w(t) = 0.\n$$\n\n### Part C: Derivation of the Discrete KKT System\n\nThe discrete problem has the objective $\\mathcal{J}_{d}(\\mathbf{J}) = \\Delta t \\left( \\gamma \\lVert \\mathbf{K}\\mathbf{J} \\rVert_{2}^{2} + \\eta \\lVert \\mathbf{J} \\rVert_{2}^{2} \\right)$ and constraint $\\Delta t \\, \\mathbf{w}^{\\top} \\mathbf{J} = d$.\nWe can rewrite the objective using the definition of $\\mathbf{Q} = \\gamma \\, \\mathbf{K}^{\\top} \\mathbf{K} + \\eta \\, \\mathbf{I}$:\n$$\n\\mathcal{J}_{d}(\\mathbf{J}) = \\Delta t \\left( \\gamma \\mathbf{J}^{\\top}\\mathbf{K}^{\\top}\\mathbf{K}\\mathbf{J} + \\eta \\mathbf{J}^{\\top}\\mathbf{I}\\mathbf{J} \\right) = \\Delta t \\, \\mathbf{J}^{\\top} (\\gamma \\mathbf{K}^{\\top}\\mathbf{K} + \\eta \\mathbf{I}) \\mathbf{J} = \\Delta t \\, \\mathbf{J}^{\\top} \\mathbf{Q} \\mathbf{J}.\n$$\nThe discrete Lagrangian $\\mathcal{L}_d$ for this constrained optimization problem is:\n$$\n\\mathcal{L}_d(\\mathbf{J}, \\lambda) = \\Delta t \\, \\mathbf{J}^{\\top} \\mathbf{Q} \\mathbf{J} + \\lambda (\\Delta t \\, \\mathbf{w}^{\\top} \\mathbf{J} - d).\n$$\nThe Karush-Kuhn-Tucker (KKT) conditions are found by setting the gradients with respect to $\\mathbf{J}$ and $\\lambda$ to zero.\n1. Gradient with respect to $\\mathbf{J}$:\nUsing matrix calculus identities $\\nabla_{\\mathbf{x}} (\\mathbf{x}^{\\top}\\mathbf{A}\\mathbf{x}) = 2\\mathbf{A}\\mathbf{x}$ for symmetric $\\mathbf{A}$ (note $\\mathbf{Q}$ is symmetric) and $\\nabla_{\\mathbf{x}} (\\mathbf{b}^{\\top}\\mathbf{x}) = \\mathbf{b}$, we get:\n$$\n\\nabla_{\\mathbf{J}} \\mathcal{L}_d = 2 \\Delta t \\, \\mathbf{Q} \\mathbf{J} + \\lambda \\Delta t \\, \\mathbf{w} = \\mathbf{0}.\n$$\n2. Gradient with respect to $\\lambda$:\nThis simply recovers the constraint equation:\n$$\n\\nabla_{\\lambda} \\mathcal{L}_d = \\Delta t \\, \\mathbf{w}^{\\top} \\mathbf{J} - d = 0 \\implies \\Delta t \\, \\mathbf{w}^{\\top} \\mathbf{J} = d.\n$$\nThese two equations can be written in a single block matrix system. Let $\\mathbf{J}^{\\star}$ be the optimal solution.\n$$\n(2 \\Delta t \\, \\mathbf{Q}) \\mathbf{J}^{\\star} + (\\Delta t \\, \\mathbf{w}) \\lambda = \\mathbf{0} \\\\\n(\\Delta t \\, \\mathbf{w}^{\\top}) \\mathbf{J}^{\\star} + (0) \\lambda = d\n$$\nThis corresponds exactly to the specified KKT system:\n$$\n\\begin{bmatrix}\n2 \\Delta t \\, \\mathbf{Q}  \\Delta t \\, \\mathbf{w} \\\\\n\\Delta t \\, \\mathbf{w}^{\\top}  0\n\\end{bmatrix}\n\\begin{bmatrix}\n\\mathbf{J}^{\\star} \\\\\n\\lambda\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\mathbf{0} \\\\\nd\n\\end{bmatrix}.\n$$\nThis completes the required derivation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    results = []\n\n    # --- Test 1 ---\n    N1 = 128\n    dt1 = 0.01\n    alpha1 = 4.0\n    f1 = 2.0\n    gamma1 = 1.0\n    eta1 = 1.0e-4\n    d1 = 1.0\n    t1 = np.arange(N1) * dt1\n    \n    # Define g1 and w1\n    g1 = np.exp(-alpha1 * t1)\n    w1 = np.zeros(N1)\n    w1_end_idx = int(0.5 / dt1) + 1\n    w1[:w1_end_idx] = np.sin(2 * np.pi * f1 * t1[:w1_end_idx])\n\n    # Construct K1 matrix\n    r1 = np.zeros(N1)\n    r1[0] = g1[0]\n    K1 = linalg.toeplitz(c=g1, r=r1)\n    \n    # Construct Q1 matrix\n    Q1 = gamma1 * (K1.T @ K1) + eta1 * np.eye(N1)\n    \n    # Construct and solve KKT system\n    A_kkt1 = np.zeros((N1 + 1, N1 + 1))\n    A_kkt1[:N1, :N1] = 2 * dt1 * Q1\n    A_kkt1[:N1, N1] = dt1 * w1\n    A_kkt1[N1, :N1] = dt1 * w1.T\n    b_kkt1 = np.zeros(N1 + 1)\n    b_kkt1[N1] = d1\n    \n    sol1 = np.linalg.solve(A_kkt1, b_kkt1)\n    J_star1 = sol1[:N1]\n    \n    # Calculate objective value\n    obj1 = dt1 * (gamma1 * np.linalg.norm(K1 @ J_star1)**2 + eta1 * np.linalg.norm(J_star1)**2)\n    results.append(obj1)\n\n    # --- Test 2 ---\n    N2 = 64\n    dt2 = 0.02\n    M2 = 20\n    gamma2 = 1.0\n    eta2 = 1.0e-8\n    d2 = 2.0\n\n    # Define g2 and w2\n    g2 = np.zeros(N2)\n    g2[0] = 1.0\n    w2 = np.zeros(N2)\n    w2[:M2] = 1.0\n\n    # Construct K2 matrix\n    r2 = np.zeros(N2)\n    r2[0] = g2[0]\n    K2 = linalg.toeplitz(c=g2, r=r2)\n    \n    # Construct Q2 matrix\n    Q2 = gamma2 * (K2.T @ K2) + eta2 * np.eye(N2)\n\n    # Construct and solve KKT system\n    A_kkt2 = np.zeros((N2 + 1, N2 + 1))\n    A_kkt2[:N2, :N2] = 2 * dt2 * Q2\n    A_kkt2[:N2, N2] = dt2 * w2\n    A_kkt2[N2, :N2] = dt2 * w2.T\n    b_kkt2 = np.zeros(N2 + 1)\n    b_kkt2[N2] = d2\n\n    sol2 = np.linalg.solve(A_kkt2, b_kkt2)\n    J_star_num2 = sol2[:N2]\n\n    # Analytic check\n    c2 = d2 / (dt2 * np.linalg.norm(w2)**2)\n    J_star_analyt2 = c2 * w2\n    \n    is_close = np.linalg.norm(J_star_num2 - J_star_analyt2)  1e-6\n    results.append(is_close)\n    \n    # --- Test 3 ---\n    N3 = 100\n    dt3 = 0.01\n    beta3 = 3.0\n    epsilon3 = 1.0e-4\n    f3 = 1.5\n    gamma3 = 1.0\n    eta3 = 1.0e-2\n    d3 = 0.3\n    t3 = np.arange(N3) * dt3\n\n    # Define g3 and w3\n    g3 = epsilon3 * np.exp(-beta3 * t3)\n    w3 = np.zeros(N3)\n    w3_end_idx = int(0.4 / dt3) + 1\n    w3[:w3_end_idx] = np.cos(2 * np.pi * f3 * t3[:w3_end_idx])\n\n    # Construct K3 matrix\n    r3 = np.zeros(N3)\n    r3[0] = g3[0]\n    K3 = linalg.toeplitz(c=g3, r=r3)\n\n    # Construct Q3 matrix\n    Q3 = gamma3 * (K3.T @ K3) + eta3 * np.eye(N3)\n\n    # Construct and solve KKT system\n    A_kkt3 = np.zeros((N3 + 1, N3 + 1))\n    A_kkt3[:N3, :N3] = 2 * dt3 * Q3\n    A_kkt3[:N3, N3] = dt3 * w3\n    A_kkt3[N3, :N3] = dt3 * w3.T\n    b_kkt3 = np.zeros(N3 + 1)\n    b_kkt3[N3] = d3\n\n    sol3 = np.linalg.solve(A_kkt3, b_kkt3)\n    J_star3 = sol3[:N3]\n\n    # Calculate constraint violation\n    violation = np.abs(dt3 * w3.T @ J_star3 - d3)\n    results.append(violation)\n\n    # Final print statement\n    print(f\"[{results[0]},{results[1]},{results[2]}]\")\n\nsolve()\n```", "id": "3359382"}]}