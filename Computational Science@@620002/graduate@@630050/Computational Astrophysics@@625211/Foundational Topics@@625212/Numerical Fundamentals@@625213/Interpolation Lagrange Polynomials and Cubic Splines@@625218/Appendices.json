{"hands_on_practices": [{"introduction": "Moving from theory to practice, our first exercise confronts a classic challenge in numerical analysis: the surprising behavior of high-degree polynomial interpolation. While it seems intuitive to fit a single, smooth polynomial through a set of data points, this approach can lead to wild oscillations, especially near the ends of the interval. This exercise [@problem_id:3515473] uses the famous Runge function to let you experience this \"Runge's phenomenon\" firsthand, demonstrating why simply increasing the number of equally spaced data points can worsen the interpolation. You will then explore two powerful remedies: using a more strategic placement of nodes (Chebyshev nodes) and switching to a fundamentally different approach (piecewise cubic splines).", "problem": "In computational astrophysics, reconstructing smooth instrument response functions or line profiles from discrete samples requires robust interpolation. Consider the analytic test function $f(x) = \\dfrac{1}{1 + 25 x^2}$ on the closed interval $[-1, 1]$. This function is known to reveal interpolation instabilities when using high-degree global polynomials on equispaced nodes. You are asked to investigate how node placement and interpolation scheme influence the maximum error.\n\nImplement a program that performs the following tasks using $N = n+1$ nodes with $n = 10$ (thus the interpolating polynomial has degree $10$):\n\n1. Construct Lagrange polynomial interpolants of degree $10$ for $f(x)$ on $[-1, 1]$ using two node sets:\n   - Equispaced nodes $x_i = -1 + \\frac{2 i}{n}$ for $i = 0, 1, \\dots, n$.\n   - Chebyshev nodes of the second kind $x_i = \\cos\\!\\left(\\dfrac{i \\pi}{n}\\right)$ for $i = 0, 1, \\dots, n$, with the angle $\\pi$ in radians.\n2. Construct a natural cubic spline interpolant (piecewise cubic polynomial with continuous first and second derivatives and zero second derivative at the endpoints) using the same equispaced nodes.\n3. For each interpolant, estimate the maximum absolute interpolation error on a dense evaluation grid of $M = 20001$ points uniformly spaced on $[-1, 1]$. The maximum absolute interpolation error is defined as $\\max_{x \\in \\mathcal{G}} \\left| f(x) - s(x) \\right|$, where $\\mathcal{G}$ is the evaluation grid and $s(x)$ is the interpolant.\n4. Additionally, estimate the maximum absolute interpolation error for the degree $10$ Lagrange polynomial using equispaced nodes restricted to the “edge region” given by the union of intervals $[-1, -0.9] \\cup [0.9, 1]$. Use a dense evaluation grid for this edge region consisting of $5001$ points per sub-interval (uniformly spaced in each of the two sub-intervals).\n5. No physical units are involved. Angles used in cosine for Chebyshev nodes must be in radians.\n\nYour test suite must include these four cases:\n- Case A: Degree $10$ Lagrange interpolation with equispaced nodes on $[-1, 1]$; report the maximum absolute error as a float.\n- Case B: Degree $10$ Lagrange interpolation with Chebyshev nodes of the second kind on $[-1, 1]$; report the maximum absolute error as a float.\n- Case C: Natural cubic spline interpolation with equispaced nodes on $[-1, 1]$; report the maximum absolute error as a float.\n- Case D: Degree $10$ Lagrange interpolation with equispaced nodes, error restricted to $[-1, -0.9] \\cup [0.9, 1]$; report the maximum absolute error as a float.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., `[resultA,resultB,resultC,resultD]`), where each entry is a float in decimal format.\n\nFinally, in your solution explanation, justify the observed differences in errors by referencing the structure of polynomial interpolation error, the effect of node placement on the growth of the interpolation operator, and the smoothing properties and local nature of cubic splines.", "solution": "The problem asks for an analysis of interpolation error for the Runge function, $f(x) = \\dfrac{1}{1 + 25 x^2}$, on the interval $[-1, 1]$ using different interpolation schemes and node distributions. We will compare Lagrange polynomial interpolation on equispaced and Chebyshev nodes, and natural cubic spline interpolation on equispaced nodes. The analysis will be based on the maximum absolute error, $\\max |f(x) - s(x)|$, where $s(x)$ is the interpolant.\n\nThe theoretical basis for polynomial interpolation error is given by the formula:\n$$E(x) = f(x) - P_n(x) = \\frac{f^{(n+1)}(\\xi_x)}{(n+1)!} \\prod_{i=0}^{n} (x - x_i)$$\nwhere $P_n(x)$ is the interpolating polynomial of degree $n$, the points $x_i$ are the interpolation nodes, and $\\xi_x$ is a point in the smallest interval containing $x$ and all the nodes $x_i$. The error is a product of two terms: one related to the function's derivatives, $\\frac{f^{(n+1)}(\\xi_x)}{(n+1)!}$, and one related to the node placement, the nodal polynomial $\\omega_{n+1}(x) = \\prod_{i=0}^{n} (x - x_i)$. The behavior of both terms dictates the accuracy of the interpolation.\n\n**Case A: Lagrange Interpolation with Equispaced Nodes**\n\nFor this case, we use a single polynomial of degree $n=10$ that passes through $N=11$ equispaced nodes $x_i = -1 + 2i/10$ for $i=0, \\dots, 10$. The Runge function $f(x)$ is analytic on the real line, but its higher-order derivatives grow very rapidly. For example, $f^{(12)}(0)$ is on the order of $10^{11}$. This means the term $\\frac{f^{(n+1)}(\\xi_x)}{(n+1)!}$ can become very large.\n\nConcurrently, for equispaced nodes, the nodal polynomial $\\omega_{n+1}(x)$ has a magnitude that is not uniform across $[-1, 1]$. It has relatively small values in the center of the interval but grows exponentially fast towards the endpoints. The combination of large derivatives and the large magnitude of $|\\omega_{n+1}(x)|$ near $x = \\pm 1$ causes the interpolation error to become very large at the edges of the interval. This results in wild oscillations of the interpolant, a phenomenon known as Runge's phenomenon. Consequently, we expect a large maximum absolute error in this case.\n\n**Case D: Edge Region Error for Equispaced Lagrange Interpolation**\n\nThis case specifically measures the maximum error from Case A but restricted to the \"edge region\" $[-1, -0.9] \\cup [0.9, 1]$. As explained for Case A, Runge's phenomenon manifests as large oscillations and error concentrated near the endpoints of the interpolation interval. Therefore, the maximum error over the entire interval $[-1, 1]$ is almost certain to occur within this edge region. We expect the result for Case D to be very close to, if not identical to, the result for Case A.\n\n**Case B: Lagrange Interpolation with Chebyshev Nodes**\n\nThis case uses the same degree $10$ Lagrange polynomial but with a different set of nodes: the Chebyshev nodes of the second kind, given by $x_i = \\cos(i\\pi/n)$ for $i=0, \\dots, n$. These nodes are the extrema of the Chebyshev polynomial of degree $n$, $T_n(x)$. Unlike equispaced nodes, Chebyshev nodes are clustered near the endpoints of the interval $[-1, 1]$.\n\nThis specific placement is optimal in the sense that it minimizes the maximum absolute value of the nodal polynomial, $$\\|\\omega_{n+1}(x)\\|_{\\infty} = \\max_{x \\in [-1,1]} \\left|\\prod_{i=0}^{n} (x-x_i)\\right|$$ By minimizing this geometric factor in the error formula, interpolation with Chebyshev nodes effectively tames the error growth, even for functions with large higher-order derivatives. This strategy guarantees convergence of the interpolant to the function as $n \\to \\infty$ for any function with a continuous first derivative. For the Runge function, this change in node distribution dramatically reduces the oscillations near the endpoints and yields a much smaller maximum error compared to the equispaced case.\n\n**Case C: Natural Cubic Spline Interpolation**\n\nA cubic spline is a different type of interpolant. Instead of using a single high-degree polynomial over the entire interval, it uses a series of piecewise cubic polynomials, one for each subinterval $[x_i, x_{i+1}]$. These pieces are joined together smoothly by enforcing continuity of the function and its first and second derivatives at the interior nodes. A \"natural\" cubic spline imposes the additional boundary condition that the second derivative is zero at the endpoints ($x_0$ and $x_n$).\n\nThe key advantage of splines is their *local* nature. The interpolant in a given subinterval $[x_i, x_{i+1}]$ is determined primarily by the data points in its immediate vicinity. This property prevents the kind of global error propagation that plagues high-degree polynomial interpolation, making splines immune to Runge's phenomenon. The error for a cubic spline is proportional to $h^4 \\max|f^{(4)}(x)|$, where $h$ is the maximum spacing between nodes. For a fixed function and sufficiently small $h$, this guarantees good approximation. Given that we are using the same equispaced nodes as in Case A, the spline interpolant avoids the large oscillations and is expected to produce a small maximum error, comparable to or even better than the Chebyshev polynomial interpolation for this value of $n$. The spline provides a stable and reliable method for interpolating smooth data.", "answer": "```python\nimport numpy as np\nfrom scipy.interpolate import BarycentricInterpolator, CubicSpline\n\ndef solve():\n    \"\"\"\n    Computes interpolation errors for the Runge function using different methods.\n    \"\"\"\n    # Define the analytic test function\n    f = lambda x: 1.0 / (1.0 + 25.0 * x**2)\n\n    # --- Common Parameters ---\n    n = 10\n    N = n + 1  # Number of nodes\n    M = 20001  # Number of evaluation points for the full interval\n\n    # --- Evaluation Grids ---\n    # Dense grid for the full interval [-1, 1]\n    x_eval_full = np.linspace(-1.0, 1.0, M)\n    y_true_full = f(x_eval_full)\n\n    # Dense grid for the edge region [-1, -0.9] U [0.9, 1]\n    M_edge_per_interval = 5001\n    x_edge1 = np.linspace(-1.0, -0.9, M_edge_per_interval)\n    x_edge2 = np.linspace(0.9, 1.0, M_edge_per_interval)\n    x_eval_edge = np.concatenate((x_edge1, x_edge2))\n    y_true_edge = f(x_eval_edge)\n\n    # --- Node Sets ---\n    # Equispaced nodes\n    x_equi = np.linspace(-1.0, 1.0, N)\n    y_equi = f(x_equi)\n\n    # Chebyshev nodes of the second kind\n    i_cheby = np.arange(N)\n    x_cheby = np.cos(i_cheby * np.pi / n)\n    y_cheby = f(x_cheby)\n\n    results = []\n\n    # --- Case A: Lagrange with Equispaced Nodes on [-1, 1] ---\n    # This interpolant will also be used for Case D\n    poly_lagrange_equi = BarycentricInterpolator(x_equi, y_equi)\n    y_interp_A = poly_lagrange_equi(x_eval_full)\n    error_A = np.max(np.abs(y_true_full - y_interp_A))\n    results.append(error_A)\n\n    # --- Case B: Lagrange with Chebyshev Nodes on [-1, 1] ---\n    poly_lagrange_cheby = BarycentricInterpolator(x_cheby, y_cheby)\n    y_interp_B = poly_lagrange_cheby(x_eval_full)\n    error_B = np.max(np.abs(y_true_full - y_interp_B))\n    results.append(error_B)\n\n    # --- Case C: Natural Cubic Spline with Equispaced Nodes on [-1, 1] ---\n    spline_natural = CubicSpline(x_equi, y_equi, bc_type='natural')\n    y_interp_C = spline_natural(x_eval_full)\n    error_C = np.max(np.abs(y_true_full - y_interp_C))\n    results.append(error_C)\n\n    # --- Case D: Lagrange with Equispaced Nodes, Error on Edge Region ---\n    # Use the interpolant from Case A, evaluated on the edge grid\n    y_interp_D = poly_lagrange_equi(x_eval_edge)\n    error_D = np.max(np.abs(y_true_edge - y_interp_D))\n    results.append(error_D)\n\n    # Format and print the final output as a single line\n    print(f\"[{','.join(f'{r:.15f}' for r in results)}]\")\n\nsolve()\n```", "id": "3515473"}, {"introduction": "Having established that cubic splines provide a stable and accurate alternative to high-degree global polynomials, we now delve deeper into their construction. A key feature that defines a cubic spline is the set of boundary conditions imposed at the endpoints of the interpolation interval. This practice [@problem_id:3515414] guides you through a comparison of two standard choices: \"natural\" splines, which are used when no information about the function's derivatives is available, and \"clamped\" splines, which incorporate known derivative values. By examining the resulting interpolation error and the maximum curvature—a physical measure of the interpolant's smoothness—you will gain practical insight into how boundary conditions influence the global quality of the fit.", "problem": "Consider the function $f(x)=e^{x}$ on the interval $[0,1]$. In computational astrophysics, interpolation is frequently used to reconstruct smooth profiles (for example, logarithmic intensity or spectral flux profiles) from discrete samples. Two widely used interpolants are polynomial interpolation via Lagrange polynomials and piecewise-cubic interpolation via cubic splines. The curvature of an interpolant is physically meaningful because it measures local bending and is related to smoothness; for a twice differentiable function $y(x)$, the planar curvature $\\kappa(x)$ is defined by\n$$\n\\kappa(x)=\\frac{\\lvert y''(x)\\rvert}{\\left(1+\\left(y'(x)\\right)^{2}\\right)^{3/2}}.\n$$\nCubic splines are constructed as piecewise cubic polynomials satisfying continuity of $y(x)$, $y'(x)$, and $y''(x)$ at the knots, and enforcing boundary conditions at the endpoints. Two standard endpoint conditions are: natural boundary conditions, which enforce $y''(0)=0$ and $y''(1)=0$, and clamped boundary conditions, which enforce $y'(0)=f'(0)$ and $y'(1)=f'(1)$, where $f'(x)=e^{x}$.\n\nYour task is to implement a program that, for several node sets on $[0,1]$, constructs cubic spline interpolants of $f(x)=e^{x}$ under both natural and clamped boundary conditions, and compares:\n- the maximum curvature over $[0,1]$ for each spline, and\n- the maximum interior interpolation error, defined as $\\max_{x\\in(0,1)}\\lvert S(x)-f(x)\\rvert$, where $S(x)$ is the spline interpolant.\n\nYou must use a uniform fine grid of $M=10001$ points on $[0,1]$ to numerically approximate the maxima. The interior error must be computed excluding the endpoints $x=0$ and $x=1$. The interpolation nodes $\\{x_{k}\\}_{k=0}^{n-1}$ must be chosen as either:\n- uniform nodes, $x_{k}=\\frac{k}{n-1}$, or\n- Chebyshev-type nodes mapped to $[0,1]$, $x_{k}=\\frac{1}{2}\\left(1-\\cos\\left(\\frac{\\pi k}{n-1}\\right)\\right)$.\n\nFor each test case below, perform the following:\n1. Construct the natural cubic spline and the clamped cubic spline using the given nodes and the samples $y_{k}=f(x_{k})$.\n2. Compute the maximum curvature $\\max_{x\\in[0,1]}\\kappa(x)$ for each spline on the fine grid.\n3. Compute the maximum interior error $\\max_{x\\in(0,1)}\\lvert S(x)-f(x)\\rvert$ for each spline on the same fine grid, excluding the endpoints.\n\nTest suite (each test case is a pair $(n,\\text{distribution})$):\n- $(5,\\text{uniform})$\n- $(8,\\text{uniform})$\n- $(8,\\text{chebyshev})$\n- $(17,\\text{uniform})$\n\nAll quantities are dimensionless; no physical units are required. Angles, where they appear inside trigonometric functions, are in radians. Your program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a list in the format $[C_{\\mathrm{nat}},C_{\\mathrm{clamp}},E_{\\mathrm{nat}},E_{\\mathrm{clamp}}]$, with each floating-point number rounded to eight decimal places. For example, a valid overall output format is\n$$\n\\big[ [\\ldots,\\ldots,\\ldots,\\ldots], [\\ldots,\\ldots,\\ldots,\\ldots], [\\ldots,\\ldots,\\ldots,\\ldots], [\\ldots,\\ldots,\\ldots,\\ldots] \\big].\n$$", "solution": "The problem requires a comparison between natural and clamped cubic splines for interpolating the function $f(x)=e^x$ on the interval $[0,1]$. The choice of boundary conditions is critical for the accuracy of a spline interpolant, especially when the function's derivatives at the boundaries are non-zero.\n\nThe function to be interpolated is $f(x)=e^x$. Its first and second derivatives are also $e^x$.\n-   At the left boundary ($x=0$), the true derivatives are $f'(0)=1$ and $f''(0)=1$.\n-   At the right boundary ($x=1$), the true derivatives are $f'(1)=e \\approx 2.718$ and $f''(1)=e \\approx 2.718$.\n\n**Natural Cubic Spline:**\nThe natural spline imposes the boundary conditions $S''_{\\mathrm{nat}}(0)=0$ and $S''_{\\mathrm{nat}}(1)=0$. This is a \"default\" choice made in the absence of information about the function's boundary behavior. However, for $f(x)=e^x$, these conditions are in direct conflict with the true second derivatives of the function, which are $1$ and $e$. This incorrect assumption forces the interpolant to have zero curvature at the endpoints, artificially flattening the curve where it should be bending. This discrepancy introduces a significant error that propagates from the boundaries into the interior of the interval. We expect the natural spline to have a larger interpolation error and a maximum curvature that might not accurately reflect the function's true curvature profile.\n\n**Clamped Cubic Spline:**\nThe clamped spline incorporates the exact first derivative information into its construction by enforcing $S'_{\\mathrm{clamp}}(0)=f'(0)=1$ and $S'_{\\mathrm{clamp}}(1)=f'(1)=e$. By providing this \"side information,\" we are guiding the spline to match the true slope of the function at the endpoints. This leads to a system of equations that produces a much more accurate interpolant across the entire domain. The error for a clamped spline is generally of a higher order of accuracy than a natural spline when the derivative information is correct. Consequently, we expect the clamped spline to yield a significantly smaller maximum interpolation error. Its curvature profile will also be a much better match to the true curvature of $f(x)=e^x$.\n\n**Node Distribution:**\nThe problem also explores uniform versus Chebyshev-type node distributions. While node placement is critically important for high-degree *polynomial* interpolation (to mitigate Runge's phenomenon), its effect on cubic splines is less dramatic. For a sufficiently smooth function like $e^x$, cubic spline interpolation is stable and converges for any reasonably uniform sequence of nodes. However, slight differences in error might be observed due to how the node distribution samples the function's curvature.\n\nIn summary, the clamped spline is theoretically superior for this problem because it uses more information about the function being interpolated, leading to a more accurate model. The numerical results should confirm this by showing a smaller maximum error and a better-behaved curvature for the clamped spline compared to the natural spline.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import CubicSpline\n\ndef solve():\n    \"\"\"\n    Constructs natural and clamped cubic splines for f(x)=e^x on [0,1]\n    and computes their maximum curvature and maximum interior error for\n    several node configurations.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (5, 'uniform'),\n        (8, 'uniform'),\n        (8, 'chebyshev'),\n        (17, 'uniform')\n    ]\n\n    all_results = []\n\n    # Setup for numerical approximation\n    M = 10001\n    # Fine grid for evaluating curvature and error\n    x_fine = np.linspace(0, 1, M)\n    # Interior part of the fine grid for error calculation\n    x_fine_interior = x_fine[1:-1]\n    \n    # Pre-calculate true function values on the grids\n    f_x_interior = np.exp(x_fine_interior)\n\n    for n, dist in test_cases:\n        # 1. Generate interpolation nodes\n        if dist == 'uniform':\n            nodes_x = np.linspace(0, 1, n)\n        elif dist == 'chebyshev':\n            k = np.arange(n)\n            nodes_x = 0.5 * (1 - np.cos(np.pi * k / (n - 1)))\n        \n        # 2. Sample the function at the nodes\n        nodes_y = np.exp(nodes_x)\n\n        # 3. Construct natural cubic spline and evaluate metrics\n        spline_nat = CubicSpline(nodes_x, nodes_y, bc_type='natural')\n        \n        # Derivatives for curvature\n        S1_nat_vals = spline_nat(x_fine, 1)\n        S2_nat_vals = spline_nat(x_fine, 2)\n        \n        # Maximum curvature for natural spline\n        kappa_nat_vals = np.abs(S2_nat_vals) / (1 + S1_nat_vals**2)**1.5\n        C_nat = np.max(kappa_nat_vals)\n        \n        # Maximum interior error for natural spline\n        error_nat_vals = np.abs(spline_nat(x_fine_interior) - f_x_interior)\n        E_nat = np.max(error_nat_vals)\n\n        # 4. Construct clamped cubic spline and evaluate metrics\n        f_prime_0 = 1.0\n        f_prime_1 = np.e\n        spline_clamp = CubicSpline(nodes_x, nodes_y, bc_type=((1, f_prime_0), (1, f_prime_1)))\n        \n        # Derivatives for curvature\n        S1_clamp_vals = spline_clamp(x_fine, 1)\n        S2_clamp_vals = spline_clamp(x_fine, 2)\n        \n        # Maximum curvature for clamped spline\n        kappa_clamp_vals = np.abs(S2_clamp_vals) / (1 + S1_clamp_vals**2)**1.5\n        C_clamp = np.max(kappa_clamp_vals)\n        \n        # Maximum interior error for clamped spline\n        error_clamp_vals = np.abs(spline_clamp(x_fine_interior) - f_x_interior)\n        E_clamp = np.max(error_clamp_vals)\n\n        # 5. Collect results for the current test case\n        case_results = [C_nat, C_clamp, E_nat, E_clamp]\n        all_results.append(case_results)\n\n    # 6. Format the final output string as specified\n    formatted_cases = []\n    for case_res in all_results:\n        formatted_cases.append(f\"[{','.join(f'{val:.8f}' for val in case_res)}]\")\n    \n    print(f\"[{','.join(formatted_cases)}]\")\n\nsolve()\n```", "id": "3515414"}, {"introduction": "In many astrophysical models, interpolated quantities are not just expected to be accurate; they must also be physically realistic. For instance, a physical quantity might be known to be always positive or, as in this exercise, monotonically decreasing. Standard interpolation methods, including the global Lagrange polynomial, do not inherently respect such constraints and can introduce spurious oscillations or extrema, leading to non-physical predictions like artificial multiple-path solutions in a ray-tracing simulation. This practice [@problem_id:3515484] introduces shape-preserving cubic splines (PCHIP) as a robust tool to enforce monotonicity, ensuring that your numerical model honors the underlying physics of the problem.", "problem": "Consider a stratified, plane-parallel atmosphere with refractive index modeled by $n(z) = 1 + \\beta \\exp(-z/H)$, where $z$ is the altitude in meters, $\\beta$ is a small dimensionless parameter, and $H$ is a scale height in meters. Assume that the electromagnetic wave ray travels along a straight line at elevation angle $\\theta$ above the local horizon, from $z=0$ to $z=z_{\\max}$. Let the speed of light in vacuum be $c$. Under the straight-line assumption, the travel time $T(\\theta)$ along the path obeys the path integral $T(\\theta) = \\dfrac{1}{c \\sin \\theta} \\int_{0}^{z_{\\max}} n(z)\\,dz$, which is valid for small refractivity when bending is negligible.\n\nYour task is to implement a $C^1$ cubic spline interpolation of $T(\\theta)$ as a function of $\\theta$ sampled at a finite number of nodes, derive principled conditions that prevent the interpolant from creating spurious multiple-path minima that are absent in the underlying $T(\\theta)$, and compare this with the behavior of the global Lagrange polynomial interpolant constructed on the same nodes. In computational astrophysics, such interpolations arise in ray-tracing through stratified media (e.g., planetary atmospheres or stellar envelopes), and spurious minima can lead to artificial multiple-path solutions that misrepresent physical reality.\n\nFundamental base and parameters to use:\n- Use $c = 3 \\times 10^8 \\, \\text{m/s}$.\n- Use $\\beta = 3 \\times 10^{-4}$ and $H = 8 \\times 10^3 \\, \\text{m}$.\n- Use $z_{\\max} = 1 \\times 10^5 \\, \\text{m}$.\n- Angles in the computational steps must be in radians; input node specifications below are given in degrees and must be converted to radians before computation.\n\nDefinitions and requirements:\n- The exact function is $T(\\theta) = \\dfrac{1}{c \\sin \\theta} \\int_{0}^{z_{\\max}} \\left(1 + \\beta e^{-z/H}\\right) dz$. You must use this exact $T(\\theta)$ to generate data values at the sampling nodes; do not numerically ray-trace the path.\n- Implement a $C^1$ shape-preserving cubic spline via a Piecewise Cubic Hermite Interpolating Polynomial (PCHIP) using Fritsch–Carlson slope limiting to preserve monotonicity when the sampled data are monotonic in $\\theta$.\n- Implement the global Lagrange polynomial interpolant of degree $N-1$ for $N$ nodes using the same sampling nodes.\n- Derive, from first principles, conditions on the interpolant and sampling that prevent spurious multiple-path minima in the interpolated $T(\\theta)$ over the domain. Your derivation must start from the definition of a monotonic function and its derivative sign, and the cubic Hermite slope limiting rules for monotonic data. Relate these to bounds involving the second derivative of $T(\\theta)$ and node spacing that help avoid sign changes in secant slopes induced by discretization. These conditions must be expressed mathematically and logically; do not rely on any shortcut formulas beyond these fundamentals.\n- Numerically verify the presence or absence of spurious minima by sampling each interpolant on a dense grid and detecting interior local minima (excluding endpoints). A spurious minimum is defined as an interior point where the discretized derivative changes sign from negative to positive while the exact $T(\\theta)$ has no interior minima over the domain.\n\nTest suite:\nFor each test case, use equally spaced nodes in degrees on the specified interval, convert them to radians for computation, evaluate $T(\\theta)$ exactly at those nodes, and then construct both interpolants. For each case, evaluate both interpolants at the given evaluation angle (in degrees) and compute the absolute errors relative to the exact $T(\\theta)$. Also report boolean flags indicating whether each interpolant exhibits at least one spurious interior minimum over the interval when sampled on a dense grid of $2000$ points.\n- Case A (happy path): $\\theta \\in [10^\\circ, 80^\\circ]$, $N=9$ nodes, evaluation angle $\\theta^\\ast = 50^\\circ$.\n- Case B (sparse sampling boundary): $\\theta \\in [5^\\circ, 85^\\circ]$, $N=5$ nodes, evaluation angle $\\theta^\\ast = 30^\\circ$.\n- Case C (higher-degree global interpolation): $\\theta \\in [5^\\circ, 85^\\circ]$, $N=13$ nodes, evaluation angle $\\theta^\\ast = 20^\\circ$.\n- Case D (near-edge with many nodes): $\\theta \\in [5^\\circ, 85^\\circ]$, $N=17$ nodes, evaluation angle $\\theta^\\ast = 15^\\circ$.\n\nFinal output specification:\nYour program should produce a single line of output containing the aggregated results for all four cases as a comma-separated list enclosed in square brackets. For each case, output four items in order: the absolute error of the PCHIP interpolant at $\\theta^\\ast$ (a float in seconds), the absolute error of the Lagrange interpolant at $\\theta^\\ast$ (a float in seconds), a boolean indicating whether the PCHIP interpolant has any spurious interior minima, and a boolean indicating whether the Lagrange interpolant has any spurious interior minima. The final output should thus contain $16$ items in total, in the order of Case A items followed by Case B, Case C, and Case D items. Angles must be converted to radians internally, and all time quantities are in seconds. The output must be in the exact format\n$[r_1,r_2,\\dots,r_{16}]$\nwith booleans formatted as either True or False and floats in standard decimal notation.", "solution": "**1. Analytical Formulation and Properties of Travel Time $T(\\theta)$**\n\nThe refractive index of the atmosphere is given by $n(z) = 1 + \\beta e^{-z/H}$. The travel time $T(\\theta)$ for a straight-line ray path at elevation angle $\\theta$ is:\n$$T(\\theta) = \\frac{1}{c \\sin \\theta} \\int_{0}^{z_{\\max}} n(z)\\,dz$$\nEvaluating the integral gives a constant, which we can call $K_{atm}$:\n$$ K_{atm} = \\int_{0}^{z_{\\max}} \\left(1 + \\beta e^{-z/H}\\right) dz = z_{\\max} + \\beta H \\left(1 - e^{-z_{\\max}/H}\\right) $$\nThe travel time function is therefore $T(\\theta) = \\frac{K}{ \\sin\\theta} = K \\csc\\theta$, where $K = K_{atm}/c$ is a positive constant.\n\nTo understand the required shape of the interpolant, we analyze the derivatives of $T(\\theta)$ for $\\theta \\in (0, \\pi/2)$:\n-   **First Derivative:** $T'(\\theta) = -K \\csc\\theta \\cot\\theta$. Since $K>0$ and both trigonometric functions are positive on this interval, $T'(\\theta)$ is strictly negative. This proves that the exact travel time $T(\\theta)$ is a **strictly monotonic decreasing function**. Therefore, the true function has no interior local minima, and any such minimum found in an interpolant is spurious.\n-   **Second Derivative:** $T''(\\theta) = K \\csc\\theta (2\\csc^2\\theta - 1)$. Since $\\csc\\theta \\ge 1$ on the interval, $T''(\\theta)$ is strictly positive. This proves that $T(\\theta)$ is also a **strictly convex function**.\n\n**2. Conditions for Preventing Spurious Minima**\n\nA spurious minimum requires the interpolant's derivative to be positive in some region. We analyze the two interpolation methods:\n\n**A. Piecewise Cubic Hermite Interpolating Polynomial (PCHIP)**\nPCHIP is a $C^1$ shape-preserving interpolant. The key is how it determines the slopes (first derivatives) at the data nodes. The Fritsch–Carlson method, used in standard PCHIP implementations, is specifically designed to preserve monotonicity. When the input data points $( \\theta_i, y_i = T(\\theta_i) )$ are monotonic (as they are here, since they are sampled from a strictly decreasing function), the algorithm ensures that the estimated slopes at the nodes have the same sign as the secant lines connecting the data points. For our decreasing function, all secant slopes are negative, and the PCHIP algorithm will compute negative slopes at the nodes. This is a sufficient condition to guarantee that each piecewise cubic segment is also monotonic. Thus, the resulting global PCHIP interpolant will be monotonic and cannot contain spurious minima.\n\n**B. Global Lagrange Polynomial**\nThe Lagrange interpolant is a single high-degree polynomial that is not inherently shape-preserving. It is prone to oscillatory behavior (Runge's phenomenon), especially for high-degree polynomials and equally spaced nodes. These oscillations can easily violate monotonicity. The error of the Lagrange interpolant $L(\\theta)$ is $E(\\theta) = T(\\theta) - L(\\theta)$, and its derivative is $L'(\\theta) = T'(\\theta) - E'(\\theta)$. A spurious minimum can occur where $L'(\\theta)=0$, which requires the error derivative $E'(\\theta)$ to exactly cancel the true function's derivative, $T'(\\theta)$. The magnitude of the error and its derivative is influenced by:\n1.  **High-order derivatives of $T(\\theta)$:** The function $T(\\theta) = K \\csc\\theta$ has derivatives that grow very large as $\\theta \\to 0$.\n2.  **Node distribution:** Equally spaced nodes cause the error term to be largest near the interval boundaries.\n\nThe combination of these factors makes it highly likely that for a sufficiently large number of nodes ($N$), the Lagrange polynomial will develop oscillations and spurious minima, particularly when the interpolation interval includes small angles where the function is steep. In contrast to PCHIP, there is no simple condition on node spacing that guarantees monotonicity for the Lagrange polynomial.\n\nThis analysis predicts that the PCHIP interpolant will correctly preserve the monotonicity of the travel time function, while the Lagrange interpolant is expected to fail, producing non-physical spurious minima, especially as the number of nodes increases.", "answer": "```python\nimport numpy as np\nfrom scipy.interpolate import PchipInterpolator, lagrange\n\ndef solve():\n    \"\"\"\n    Solves the interpolation problem by comparing PCHIP and Lagrange methods.\n\n    The solution performs the following steps for each test case:\n    1. Defines physical constants and calculates the analytical form of the travel time T(theta).\n    2. Generates a set of N equally spaced nodes (theta_i, y_i) from the exact function.\n    3. Constructs a PCHIP (shape-preserving) cubic spline interpolant.\n    4. Constructs a global Lagrange polynomial interpolant.\n    5. For each interpolant, it calculates the absolute error at a specific evaluation angle theta*.\n    6. It checks for the presence of spurious interior minima by sampling the interpolant on a\n       dense grid and verifying if the function's monotonicity is violated.\n    7. Aggregates and prints the results in the specified format.\n    \"\"\"\n    # Define physical constants and model parameters\n    c = 3.0e8  # Speed of light in m/s\n    beta = 3.0e-4  # Dimensionless refractive index parameter\n    H = 8.0e3  # Atmospheric scale height in meters\n    z_max = 1.0e5  # Maximum integration altitude in meters\n\n    # Pre-calculate the constant factor K for T(theta) = K / sin(theta)\n    # The integral part is z_max + beta * H * (1 - exp(-z_max / H))\n    integral_val = z_max + beta * H * (1 - np.exp(-z_max / H))\n    K = integral_val / c\n\n    def T_exact(theta_deg):\n        \"\"\"Calculates the exact travel time T for a given angle in degrees.\"\"\"\n        # Ensure input is a float array for vectorized operations\n        theta_deg_arr = np.atleast_1d(theta_deg).astype(float)\n        # Avoid division by zero at 0 or 180 degrees\n        # Very small angles can still lead to large results, which is physically correct\n        theta_rad = np.deg2rad(theta_deg_arr)\n        \n        # Using a mask for invalid angles to avoid warnings and return inf\n        invalid_mask = np.isclose(np.sin(theta_rad), 0.0)\n        result = np.full_like(theta_rad, np.inf)\n        valid_mask = ~invalid_mask\n        result[valid_mask] = K / np.sin(theta_rad[valid_mask])\n        \n        return result[0] if result.size == 1 else result\n\n    # Test suite from the problem statement\n    test_cases = [\n        # (theta_min_deg, theta_max_deg, N_nodes, theta_star_deg)\n        (10.0, 80.0, 9, 50.0),   # Case A\n        (5.0, 85.0, 5, 30.0),    # Case B\n        (5.0, 85.0, 13, 20.0),   # Case C\n        (5.0, 85.0, 17, 15.0),   # Case D\n    ]\n    \n    # Dense grid for checking for spurious minima\n    DENSE_GRID_POINTS = 2000\n\n    results = []\n\n    for case in test_cases:\n        theta_min_deg, theta_max_deg, N, theta_star_deg = case\n\n        # Generate N equally spaced nodes for interpolation\n        theta_nodes_deg = np.linspace(theta_min_deg, theta_max_deg, N)\n        theta_nodes_rad = np.deg2rad(theta_nodes_deg)\n        \n        # Evaluate T at the nodes to get the data values\n        y_nodes = T_exact(theta_nodes_deg)\n\n        # 1. PCHIP Interpolation\n        pchip_interpolator = PchipInterpolator(theta_nodes_rad, y_nodes)\n        \n        # Evaluate at the specified angle theta*\n        theta_star_rad = np.deg2rad(theta_star_deg)\n        pchip_val_at_star = pchip_interpolator(theta_star_rad)\n        \n        # Calculate absolute error\n        exact_val_at_star = T_exact(theta_star_deg)\n        pchip_abs_error = np.abs(pchip_val_at_star - exact_val_at_star)\n\n        # Check for spurious minima in PCHIP interpolant\n        theta_dense_rad = np.linspace(np.deg2rad(theta_min_deg), np.deg2rad(theta_max_deg), DENSE_GRID_POINTS)\n        pchip_dense_vals = pchip_interpolator(theta_dense_rad)\n        # A spurious minimum exists if the function increases at any point,\n        # as the true function is strictly decreasing.\n        pchip_has_spurious_minima = np.any(np.diff(pchip_dense_vals) > 0)\n        \n        # 2. Lagrange Interpolation\n        lagrange_poly = lagrange(theta_nodes_rad, y_nodes)\n\n        # Evaluate at theta*\n        lagrange_val_at_star = lagrange_poly(theta_star_rad)\n        \n        # Calculate absolute error\n        lagrange_abs_error = np.abs(lagrange_val_at_star - exact_val_at_star)\n\n        # Check for spurious minima in Lagrange interpolant\n        lagrange_dense_vals = lagrange_poly(theta_dense_rad)\n        lagrange_has_spurious_minima = np.any(np.diff(lagrange_dense_vals) > 0)\n\n        results.extend([\n            pchip_abs_error,\n            lagrange_abs_error,\n            bool(pchip_has_spurious_minima),\n            bool(lagrange_has_spurious_minima)\n        ])\n    \n    # Format the final output string as a list of comma-separated values\n    formatted_results = [f\"{val}\" for val in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3515484"}]}