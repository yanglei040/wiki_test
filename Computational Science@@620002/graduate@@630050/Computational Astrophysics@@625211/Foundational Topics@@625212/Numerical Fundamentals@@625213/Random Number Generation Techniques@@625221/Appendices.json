{"hands_on_practices": [{"introduction": "In many astrophysical simulations, such as modeling stellar feedback or stochastic star formation, we must efficiently sample outcomes from a discrete set of possibilities. This exercise introduces the alias method, a powerful and classic algorithm that allows for sampling from any discrete categorical distribution in constant time, $O(1)$, after an initial setup. Mastering this technique is essential for building high-performance Monte Carlo codes where millions or billions of such decisions must be made without creating a computational bottleneck [@problem_id:3531161].", "problem": "In a large-scale Monte Carlo (MC) radiation transport module of a computational astrophysics code, each star particle must probabilistically trigger one of $5$ discrete feedback channels on each timestep based on precomputed occurrence rates. Let the channels be enumerated by indices $i \\in \\{1,2,3,4,5\\}$, and let the categorical probability vector be\n$$\n\\mathbf{p} = \\left(p_{1},p_{2},p_{3},p_{4},p_{5}\\right) = \\left(\\frac{3}{20}, \\frac{4}{20}, \\frac{1}{20}, \\frac{8}{20}, \\frac{4}{20}\\right),\n$$\nwhich models, for example, the joint distribution of feedback events such as Type Ia supernova, core-collapse supernova, stellar wind burst, neutron star natal kick, and radiative heating, respectively. You must sample from this discrete distribution in $O(1)$ operations per sample and with exact probabilities, in order to avoid timestep-dependent bias.\n\nStarting from the fundamental definition of a discrete probability distribution, the law of total probability, and the construction of random variables via transformations of uniform deviates, derive and explain the alias method (also known as the Walker alias method) for sampling a discrete distribution with $N$ categories in $O(1)$ time per sample. Then, for the given vector $\\mathbf{p}$ with $N=5$, construct the complete alias table consisting of the threshold array $\\mathbf{q}=\\left(q_{1},\\dots,q_{5}\\right)$ and the alias index array $\\mathbf{a}=\\left(a_{1},\\dots,a_{5}\\right)$ such that one sample is obtained by drawing an integer column index $J$ uniformly from $\\{1,2,3,4,5\\}$ and a uniform deviate $U \\in [0,1)$, and returning $J$ if $U  q_{J}$ and returning $a_{J}$ otherwise.\n\nAssuming a particular realization in which the random integer is $J=3$ and the uniform deviate is $U=\\frac{7}{10}$, compute the single integer that will be returned by the alias sampler given your constructed alias table. Provide the final answer as the integer channel index only. No rounding is required and no physical units are involved. Express the final answer as a pure number.", "solution": "The problem statement is critically validated and found to be valid. It is scientifically grounded, well-posed, objective, and self-contained, presenting a standard problem in computational statistics relevant to the specified field of computational astrophysics. All necessary data and definitions are provided and are internally consistent. The probabilities sum to $1$, as required. We may therefore proceed with the solution.\n\nThe problem requires the derivation and explanation of the alias method for sampling from a discrete categorical distribution, the construction of the specific alias table for the given probability vector $\\mathbf{p}$, and the application of the resulting sampler to a given realization of random numbers.\n\n**1. Derivation and Explanation of the Alias Method**\n\nThe fundamental goal is to draw a random sample from a discrete probability distribution with $N$ categories, where the probability of drawing category $i$ is $p_i$, and $\\sum_{i=1}^{N} p_i = 1$. A naive approach, such as searching through a cumulative distribution, takes $O(\\log N)$ or $O(N)$ time per sample. The alias method achieves this in $O(1)$ time after an initial $O(N)$ setup.\n\nThe core principle of the alias method is to transform the original non-uniform distribution into a uniform mixture of $N$ simple two-point distributions. We can visualize this by imagining $N$ bins, each of width $1$ and height $1$. The total area of these bins is $N$. We want to represent the total probability $\\sum p_i = 1$ within this structure.\n\nFirst, we scale the probabilities by $N$: let $P_i = N p_i$. The sum of these scaled probabilities is $\\sum_{i=1}^{N} P_i = N \\sum_{i=1}^{N} p_i = N$. The average value of $P_i$ is $1$. This implies that some categories will have $P_i  1$ (we can call them \"underfull\"), some will have $P_i > 1$ (\"overfull\"), and some may have $P_i=1$ (\"full\").\n\nThe alias method redistributes the \"excess\" probability mass from the overfull categories to fill the \"deficient\" space in the underfull categories. After this redistribution, each of the $N$ bins will be exactly full (i.e., contain a total probability mass of $1$), and each bin $j$ will contain portions from at most two original categories: the primary category $j$ and an \"alias\" category $a_j$.\n\nThe sampling procedure, as defined in the problem, is as follows:\n1.  Draw an integer index $J$ uniformly from $\\{1, 2, \\ldots, N\\}$. This selects a bin with probability $1/N$.\n2.  Draw a uniform random number $U \\in [0,1)$.\n3.  If $U  q_J$, the outcome is $J$. The value $q_J$ is the threshold probability, representing the portion of bin $J$ occupied by category $J$.\n4.  If $U \\ge q_J$, the outcome is the alias index $a_J$. The remaining portion of the bin, $1-q_J$, is occupied by category $a_J$.\n\nThe total probability of sampling category $k$ is the sum of probabilities of obtaining $k$ from any of the $N$ bins:\n$$p_k = \\sum_{j=1}^{N} P(\\text{outcome}=k | \\text{bin } j \\text{ chosen}) \\times P(\\text{bin } j \\text{ chosen})$$\nSince a bin is chosen uniformly, $P(\\text{bin } j \\text{ chosen}) = 1/N$. The conditional probability is given by the sampling rule:\n$$P(\\text{outcome}=k | \\text{bin } j \\text{ chosen}) = q_j \\cdot \\mathbb{I}(j=k) + (1-q_j) \\cdot \\mathbb{I}(a_j=k)$$\nwhere $\\mathbb{I}(\\cdot)$ is the indicator function. Substituting this into the previous equation gives the fundamental relation the alias table must satisfy:\n$$p_k = \\frac{1}{N} \\sum_{j=1}^{N} \\left[ q_j \\mathbb{I}(j=k) + (1-q_j) \\mathbb{I}(a_j=k) \\right]$$\nMultiplying by $N$, we get the condition on the scaled probabilities:\n$$P_k = N p_k = q_k \\mathbb{I}(k \\text{ is primary in any bin}) + \\sum_{j: a_j=k} (1-q_j)$$\n\nAn efficient $O(N)$ algorithm to construct the threshold array $\\mathbf{q}$ and alias array $\\mathbf{a}$ (e.g., Vose's algorithm) proceeds as follows:\n1.  Create two worklists, `Small` and `Large`, for indices $i$ where $P_i  1$ and $P_i > 1$, respectively. (Categories with $P_i=1$ can be set aside).\n2.  While `Small` is not empty, pick an arbitrary index $l$ from `Small` and an arbitrary index $g$ from `Large`.\n3.  Fill bin $l$: Set the threshold $q_l = P_l$. The remaining space $1-P_l$ is filled by the overfull category $g$, so set the alias $a_l = g$.\n4.  Update the probability mass of category $g$: it has given away $1-P_l$ of its mass. The new scaled probability is $P_g' = P_g - (1-P_l) = P_g + P_l - 1$.\n5.  Re-classify $g$: if $P_g'  1$, move it to the `Small` list. If $P_g' > 1$, it remains in the `Large` list. If $P_g' = 1$, it can be removed from the worklists.\n6.  Repeat until the worklists are empty. Any category $k$ that was never in `Small` (i.e., had initial $P_k \\ge 1$) will have its bin $k$ filled entirely by its own probability. For these, we set $q_k=1$ (and $a_k$ becomes irrelevant, conventionally set to $k$).\n\nThis construction ensures that underfull categories are never used as aliases and that the probabilities are conserved exactly.\n\n**2. Construction of the Alias Table**\n\nGiven the probability vector $\\mathbf{p} = \\left(\\frac{3}{20}, \\frac{4}{20}, \\frac{1}{20}, \\frac{8}{20}, \\frac{4}{20}\\right)$ and $N=5$.\nThe average probability is $1/N = 1/5 = 4/20$.\n\nFirst, we compute the scaled probabilities $P_i = N p_i = 5 p_i$:\n$P_1 = 5 \\times \\frac{3}{20} = \\frac{15}{20} = \\frac{3}{4}$\n$P_2 = 5 \\times \\frac{4}{20} = \\frac{20}{20} = 1$\n$P_3 = 5 \\times \\frac{1}{20} = \\frac{5}{20} = \\frac{1}{4}$\n$P_4 = 5 \\times \\frac{8}{20} = \\frac{40}{20} = 2$\n$P_5 = 5 \\times \\frac{4}{20} = \\frac{20}{20} = 1$\nSo, $\\mathbf{P} = \\left(\\frac{3}{4}, 1, \\frac{1}{4}, 2, 1\\right)$.\n\nWe initialize the worklists:\n- `Small` (where $P_i1$): `{1, 3}` corresponding to values $\\{3/4, 1/4\\}$.\n- `Large` (where $P_i>1$): `{4}` corresponding to value {$2$}.\n- Categories with $P_i=1$ are `{2, 5}`. For these, we can immediately set $q_2=1$ and $q_5=1$. Their aliases are irrelevant; we set $a_2=2$ and $a_5=5$.\n\nNow we execute the main loop:\n\n**Iteration 1:**\n- Pop an index from `Small`: let's choose $l=3$ ($P_3=1/4$).\n- Pop an index from `Large`: we must choose $g=4$ ($P_4=2$).\n- Set the table for bin $3$: $q_3 = P_3 = 1/4$, and the alias is $a_3=4$.\n- Update the scaled probability for category $4$: $P_4' = P_4 - (1-P_3) = 2 - (1 - 1/4) = 2 - 3/4 = 5/4$.\n- Since $P_4' = 5/4 > 1$, category $4$ remains in the `Large` worklist. The `Small` list now only contains `{1}`.\n\n**Iteration 2:**\n- Pop the last index from `Small`: $l=1$ ($P_1=3/4$).\n- Pop from `Large`: we must again choose $g=4$ (with its updated probability $P_4'=5/4$).\n- Set the table for bin $1$: $q_1 = P_1 = 3/4$, and the alias is $a_1=4$.\n- Update the scaled probability for category $4$: $P_4'' = P_4' - (1-P_1) = 5/4 - (1 - 3/4) = 5/4 - 1/4 = 1$.\n- The `Small` list is now empty, so the loop terminates.\n\n**Finalization:**\nThe remaining category, $4$, now has a scaled probability of $1$. For this bin, we set $q_4=1$ (and $a_4=4$).\nCombining all parts, the complete alias table is:\n- Threshold array: $\\mathbf{q} = \\left(q_1, q_2, q_3, q_4, q_5 \\right) = \\left(\\frac{3}{4}, 1, \\frac{1}{4}, 1, 1\\right)$\n- Alias array: $\\mathbf{a} = \\left(a_1, a_2, a_3, a_4, a_5 \\right) = \\left(4, 2, 4, 4, 5\\right)$\n\n**3. Computing the Sampled Outcome**\n\nThe problem provides a specific realization of the random draws:\n- Integer column index: $J=3$.\n- Uniform deviate: $U=\\frac{7}{10}$.\n\nWe apply the sampling rule for the chosen bin $J=3$:\n1. Retrieve the threshold and alias for bin $3$: $q_3 = 1/4$ and $a_3=4$.\n2. Compare the uniform deviate $U$ with the threshold $q_3$:\n   Is $U  q_3$?\n   Is $\\frac{7}{10}  \\frac{1}{4}$?\n   To compare, we can use a common denominator of $20$: $\\frac{14}{20}  \\frac{5}{20}$. This is false.\n3. Since the condition $U  q_J$ is false, the sampler returns the alias index $a_J$.\n   For $J=3$, the alias is $a_3=4$.\n\nTherefore, the integer channel index returned by the sampler is $4$.", "answer": "$$\\boxed{4}$$", "id": "3531161"}, {"introduction": "Pseudo-random number generators are deterministic algorithms, and their outputs can contain subtle correlations that compromise a simulation's validity. This practice delves into the spectral test, a fundamental method for quantifying the quality of Linear Congruential Generators (LCGs) by analyzing their inherent lattice structure. By deriving and implementing this test, you will gain a geometric intuition for how LCGs can fail and learn to connect an abstract quality metric to a concrete proxy for sampling bias in astrophysical contexts [@problem_id:3531220].", "problem": "You are tasked with constructing, implementing, and analyzing a three-dimensional spectral test for a Linear Congruential Generator (LCG) used in a Monte Carlo setting for cosmic ray propagation. Your solution must start from the core definition of an LCG and the geometric interpretation of its output as a lattice in successive dimensions, then derive a computationally implementable form of the spectral test in dimension $d=3$ and relate the test outcome to a quantitative bias proxy that is relevant to sampling tasks in computational astrophysics.\n\nStarting point and definitions:\n- An LCG is defined by $X_{n+1} \\equiv a X_n + c \\pmod m$ with $X_0 \\in \\{0,1,\\dots,m-1\\}$ and parameters $a, c, m \\in \\mathbb{Z}$, $m \\ge 2$. The normalized output is $U_n = X_n / m \\in [0,1)$.\n- Consider the sequence of $d$-tuples formed by consecutive outputs, here $d=3$, namely $Y_n = (U_n, U_{n+1}, U_{n+2}) \\in [0,1)^3$.\n- It is a well-tested fact that the set $\\{Y_n\\}$ lies on a finite number of parallel planes in $\\mathbb{R}^3$. The spectral test in dimension $d=3$ measures the distance between adjacent such planes, which is determined by the shortest nonzero vector of the dual lattice.\n\nTasks to complete:\n1) Derive, starting from the LCG definition and the structure of $Y_n$, the congruence that characterizes all integer vectors $w = (w_0,w_1,w_2) \\in \\mathbb{Z}^3$ normal to families of planes containing $\\{Y_n\\}$, showing that they satisfy\n$$\nw_0 + a w_1 + a^2 w_2 \\equiv 0 \\pmod m.\n$$\nExplain why the increment $c$ does not affect this condition for $d \\ge 2$ when considering differences of tuples and hence the lattice structure that underlies the spectral test.\n2) Show that the set of all integer solutions $w$ to the congruence in item $1$ forms a full-rank lattice in $\\mathbb{Z}^3$, and construct an explicit integer basis for it using only $m$ and $a$. One convenient choice is\n$$\nb_1 = (m,0,0), \\quad b_2 = (-a,1,0), \\quad b_3 = (-a^2,0,1),\n$$\nwhere $a^2$ can be taken modulo $m$ without loss of generality because $b_1$ accounts for multiples of $m$ in the first coordinate. Justify that any solution $w$ can be written as $w = \\lambda_1 b_1 + \\lambda_2 b_2 + \\lambda_3 b_3$ with $\\lambda_i \\in \\mathbb{Z}$.\n3) Prove that the distance between adjacent parallel planes that contain the points $\\{Y_n\\}$ and are orthogonal to a nonzero integer vector $w$ is $\\Delta = \\lVert w \\rVert_2^{-1}$, where $\\lVert \\cdot \\rVert_2$ is the Euclidean norm. Therefore, the three-dimensional spectral test reduces to finding the shortest nonzero vector $w^\\star$ in the lattice of solutions, and the spectral spacing is $\\Delta^\\star = \\lVert w^\\star \\rVert_2^{-1}$.\n4) Define the normalized three-dimensional spectral figure of merit\n$$\nQ = \\frac{\\lVert w^\\star \\rVert_2}{m^{1/3}},\n$$\nwhich compares the actual number of planes per unit thickness to the ideal scaling for $m$ points in three dimensions. Argue why $Q$ of order unity indicates acceptable structure, while significantly smaller $Q$ indicates poor structure (large gaps between planes relative to the ideal $m^{-1/3}$ scale).\n5) To relate the test outcome to sampling bias in a computational astrophysics context, consider linear observables $f(y) = \\hat{n} \\cdot y$ with $\\hat{n} \\in \\mathbb{R}^3$ and $\\lVert \\hat{n} \\rVert_2 = 1$ as proxies for sensitivity to anisotropy in sampling tasks. Show that the worst-case absolute deviation in the mean of such a $1$-Lipschitz observable due to confinement of points to parallel planes spaced by $\\Delta^\\star$ is bounded by\n$$\nB = \\frac{\\Delta^\\star}{2} = \\frac{1}{2 \\lVert w^\\star \\rVert_2}.\n$$\nExplain why this bound is a principled proxy for anisotropy or correlation-induced bias that can affect Monte Carlo propagation when successive coordinates are used to parameterize physical quantities.\n\nAlgorithmic requirements:\n- Construct the lattice basis in item $2$, reduce it to a near-orthogonal basis using a standard lattice-basis reduction method that preserves the integer lattice (for example, the Lenstra–Lenstra–Lovász basis reduction algorithm), and then enumerate short integer combinations in a bounded range to recover the exact shortest nonzero vector $w^\\star$.\n- Compute $\\lVert w^\\star \\rVert_2$, $Q$, and $B$ for each test case below. Use floating-point arithmetic with sufficient precision to reliably distinguish the cases.\n\nTest suite and required outputs:\n- Use $d=3$ in all cases. Evaluate the following three parameter sets, each given as $(m,a,c)$:\n  - Case A (moderate modulus, multiplicative): $(m,a,c) = (65537,3,0)$.\n  - Case B (small modulus with a known short relation): $(m,a,c) = (13,3,0)$.\n  - Case C (same as Case A but mixed): $(m,a,c) = (65537,3,12345)$.\n- For each case, compute and report the triplet of floats $(\\lVert w^\\star \\rVert_2, Q, B)$, and additionally report the absolute difference in $Q$ between Case A and Case C,\n$$\n\\Delta Q = \\left| Q_{\\mathrm{A}} - Q_{\\mathrm{C}} \\right|,\n$$\nto empirically confirm the independence from the increment $c$ in the spectral test for $d \\ge 2$.\n- Final output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in this exact order and rounded to six decimal places:\n$[\\lVert w^\\star \\rVert_{2,\\mathrm{A}}, Q_{\\mathrm{A}}, B_{\\mathrm{A}}, \\lVert w^\\star \\rVert_{2,\\mathrm{B}}, Q_{\\mathrm{B}}, B_{\\mathrm{B}}, \\lVert w^\\star \\rVert_{2,\\mathrm{C}}, Q_{\\mathrm{C}}, B_{\\mathrm{C}}, \\Delta Q]$.\nNo other text should be printed. All quantities are dimensionless; do not include any units in the output. Angles, when discussed conceptually, are in radians.", "solution": "The problem requires the construction, implementation, and analysis of a three-dimensional spectral test for a Linear Congruential Generator (LCG). We will first derive the theoretical underpinnings of the test, and then develop an algorithm to compute the required metrics for the given test cases.\n\nAn LCG is defined by the recurrence relation $X_{n+1} \\equiv a X_n + c \\pmod m$, producing a sequence of integers. Normalizing these by the modulus $m$ gives a sequence of pseudorandom numbers $U_n = X_n / m \\in [0,1)$. The spectral test assesses the quality of this generator by examining the geometric structure of $d$-tuples of consecutive numbers, $Y_n = (U_n, U_{n+1}, \\dots, U_{n+d-1})$. For this problem, we focus on dimension $d=3$.\n\n**1. Derivation of the Lattice Condition**\n\nThe set of points $\\{Y_n\\}_{n \\ge 0}$ generated by an LCG is not truly random; it exhibits a regular lattice structure. The points lie on a finite number of parallel hyperplanes. In dimension $d=3$, these are planes. A family of parallel planes is characterized by a normal vector $w = (w_0, w_1, w_2) \\in \\mathbb{Z}^3$. The points $y \\in \\mathbb{R}^3$ on any one of these planes satisfy $w \\cdot y = \\text{constant}$. For the set $\\{Y_n\\}$ to lie on such planes, the expression $w \\cdot Y_n$ must take values from a discrete set.\n\nLet us analyze the dot product $w \\cdot Y_n$:\n$$w \\cdot Y_n = w_0 U_n + w_1 U_{n+1} + w_2 U_{n+2} = \\frac{1}{m}(w_0 X_n + w_1 X_{n+1} + w_2 X_{n+2})$$\nWe can express $X_{n+1}$ and $X_{n+2}$ in terms of $X_n$ using the LCG recurrence. For some integers $k_{n,1}$ and $k_{n,2}$, we have:\n$X_{n+1} = a X_n + c - k_{n,1} m$\n$X_{n+2} = a X_{n+1} + c - k_{n,2} m = a(a X_n + c - k_{n,1} m) + c - k_{n,2} m = a^2 X_n + c(a+1) - (a k_{n,1} + k_{n,2})m$\n\nSubstituting these into the dot product (within the parenthesis) gives:\n$$w_0 X_n + w_1 X_{n+1} + w_2 X_{n+2} = w_0 X_n + w_1(aX_n+c) + w_2(a^2X_n+c(a+1)) \\pmod m$$\n$$= (w_0 + a w_1 + a^2 w_2)X_n + c(w_1 + (a+1)w_2) \\pmod m$$\nThe full expression for the dot product is:\n$$w \\cdot Y_n = \\frac{1}{m}\\left((w_0 + a w_1 + a^2 w_2)X_n + c(w_1 + (a+1)w_2)\\right) - K_n$$\nwhere $K_n$ is some integer capturing the various multiples of $m$ from the modulo arithmetic.\nFor the points $\\{Y_n\\}$ to be confined to a few planes, the coefficient of the varying term $X_n$ must effectively vanish. This is achieved if the coefficient is a multiple of $m$, which ensures that $(w_0 + a w_1 + a^2 w_2)X_n / m$ is an integer for all $X_n$ if the LCG has full period, or at least restricts its contribution. The fundamental condition is that the vector $w$ belongs to the dual of the generator's lattice, which is defined by the congruence:\n$$w_0 + a w_1 + a^2 w_2 \\equiv 0 \\pmod m$$\nWhen this congruence holds, $w_0 + a w_1 + a^2 w_2 = k_w m$ for some integer $k_w$, and the dot product becomes:\n$$w \\cdot Y_n = \\frac{1}{m}(k_w m X_n + c(w_1 + (a+1)w_2)) - K_n = k_w X_n - K_n + \\frac{c(w_1 + (a+1)w_2)}{m}$$\nSince $k_w, X_n, K_n$ are integers, the values of $w \\cdot Y_n$ are restricted to a set of the form $\\{ I + \\delta_c \\}$, where $I \\in \\mathbb{Z}$ and $\\delta_c$ is a constant offset depending on $c$. This confirms the planar structure.\n\nThe additive constant $c$ does not affect the lattice structure itself, only its position in space (an affine shift). The lattice is characterized by the set of difference vectors $\\{Y_{n'} - Y_n\\}$. For $d \\ge 2$, the difference between consecutive integer vectors $(X_{n+1}, \\dots, X_{n+d}) - (X_n, \\dots, X_{n+d-1})$ is governed by a recurrence that is independent of $c$. Specifically, $X_{k+1}-X_k \\equiv a(X_k-X_{k-1}) \\pmod m$. The spectral test probes the geometry of this underlying vector lattice, which is why the value of $c$ is irrelevant for $d \\ge 2$.\n\n**2. The Lattice of Solutions and its Basis**\n\nThe set of all integer vectors $w = (w_0, w_1, w_2) \\in \\mathbb{Z}^3$ satisfying the congruence $w_0 + a w_1 + a^2 w_2 \\equiv 0 \\pmod m$ forms a lattice. To show that the given vectors $b_1 = (m,0,0)$, $b_2 = (-a,1,0)$, and $b_3 = (-a^2,0,1)$ form an integer basis for this lattice, we must show two things: (i) each basis vector satisfies the congruence, and (ii) any solution $w$ can be uniquely expressed as an integer linear combination of them.\n\n(i) Check basis vectors:\nFor $b_1$: $m + a(0) + a^2(0) = m \\equiv 0 \\pmod m$.\nFor $b_2$: $-a + a(1) + a^2(0) = 0 \\equiv 0 \\pmod m$.\nFor $b_3$: $-a^2 + a(0) + a^2(1) = 0 \\equiv 0 \\pmod m$.\nAll three vectors belong to the solution set.\n\n(ii) Show they generate all solutions. Let $w = (w_0, w_1, w_2)$ be an arbitrary integer vector satisfying the congruence. We seek integers $\\lambda_1, \\lambda_2, \\lambda_3$ such that $w = \\lambda_1 b_1 + \\lambda_2 b_2 + \\lambda_3 b_3$.\n$$\n(w_0, w_1, w_2) = \\lambda_1(m,0,0) + \\lambda_2(-a,1,0) + \\lambda_3(-a^2,0,1) = (\\lambda_1 m - \\lambda_2 a - \\lambda_3 a^2, \\lambda_2, \\lambda_3)\n$$\nBy comparing components, we immediately find $\\lambda_2 = w_1$ and $\\lambda_3 = w_2$. Substituting these into the first component equation:\n$w_0 = \\lambda_1 m - w_1 a - w_2 a^2 \\implies \\lambda_1 m = w_0 + w_1 a + w_2 a^2$.\nSince $w$ is a solution to the congruence, we know that $w_0 + w_1 a + w_2 a^2$ is an integer multiple of $m$. Therefore, $\\lambda_1 = (w_0 + w_1 a + w_2 a^2)/m$ is an integer. Thus, any solution $w$ can be expressed as an integer linear combination of $\\{b_1, b_2, b_3\\}$. The basis matrix has determinant $m$, so the vectors are linearly independent, making the lattice full-rank. The use of $a^2 \\pmod m$ in $b_3$ is valid because any multiple of $m$ in the first component can be absorbed by an integer change in $\\lambda_1$.\n\n**3. Distance Between Planes**\n\nFor a given nonzero integer normal vector $w$ from the solution lattice, the points $\\{Y_n\\}$ are constrained to lie on planes of the form $w \\cdot y = C_k$, where the values $C_k$ form an arithmetic progression. It can be shown that the values of $w \\cdot Y_n$ are of the form $k + \\delta$ for integers $k$ and some fixed offset $\\delta$. This means the points lie on planes $w \\cdot y = k+\\delta$. The distance between two adjacent planes, $w \\cdot y = k+\\delta$ and $w \\cdot y = k+1+\\delta$, is the shortest distance between them. This distance is along the normal direction $\\hat{w} = w/\\lVert w \\rVert_2$. The projection of the separation vector between any two points on these planes onto the normal direction is constant. The distance $\\Delta$ is given by the difference in the constant terms of the plane equations, divided by the norm of the vector $w$, which is $\\Delta = ((k+1+\\delta)-(k+\\delta)) / \\lVert w \\rVert_2 = 1 / \\lVert w \\rVert_2$.\n\nTo find the largest empty regions in the sampling space, we must find the maximum possible distance between adjacent planes. This corresponds to choosing the family of planes with the largest spacing, which in turn means finding the nonzero vector $w$ in the solution lattice with the minimum possible Euclidean norm, $\\lVert w \\rVert_2$. This vector is called the shortest nonzero vector, denoted $w^\\star$. The corresponding maximum plane spacing is the three-dimensional spectral value $\\Delta^\\star = \\lVert w^\\star \\rVert_2^{-1}$.\n\n**4. Figure of Merit $Q$**\n\nThe figure of merit $Q = \\lVert w^\\star \\rVert_2 / m^{1/3}$ provides a normalized measure of the generator's quality. If $m$ points were distributed truly uniformly and randomly in $[0,1)^3$, the typical distance between neighboring points would scale as $(1/m)^{1/3} = m^{-1/3}$. The spectral test reveals that the largest guaranteed empty region is a slab of thickness $\\Delta^\\star = 1/\\lVert w^\\star \\rVert_2$. A good generator should have this largest gap be of the same order as the typical random spacing, i.e., $\\Delta^\\star \\approx m^{-1/3}$, which implies $\\lVert w^\\star \\rVert_2 \\approx m^{1/3}$. In this case, $Q \\approx 1$.\n- If $Q \\ll 1$, then $\\lVert w^\\star \\rVert_2 \\ll m^{1/3}$, meaning $\\Delta^\\star \\gg m^{-1/3}$. The planes are far apart, indicating a coarse, highly correlated lattice structure. This is highly undesirable for Monte Carlo simulations.\n- If $Q \\ge 1$, the lattice structure is fine-grained, with plane spacings on par with or smaller than the ideal random spacing. This is characteristic of a high-quality generator.\n\n**5. Bias Proxy $B$**\n\nIn computational astrophysics, Monte Carlo methods are used to simulate processes like cosmic ray propagation. Using correlated coordinates from a poor LCG to represent physical quantities (e.g., momentum components) can introduce systematic errors, or bias. A linear observable $f(y) = \\hat{n} \\cdot y$ with $\\lVert \\hat{n} \\rVert_2 = 1$ is a simple proxy for physical quantities sensitive to sampling anisotropy. Such a function is $1$-Lipschitz continuous, as $|f(y_1)-f(y_2)|=|\\hat{n}\\cdot(y_1-y_2)| \\le \\lVert\\hat{n}\\rVert_2 \\lVert y_1-y_2\\rVert_2 = \\lVert y_1-y_2\\rVert_2$.\n\nThe worst-case deviation of such an observable occurs when its gradient, $\\nabla f = \\hat{n}$, is aligned with the direction of sparsest sampling, which is the normal vector $w^\\star$. The LCG points lie on planes separated by a distance $\\Delta^\\star = 1/\\lVert w^\\star \\rVert_2$. The region most poorly sampled is the empty slab between two such planes. A point at the center of this slab is at a distance of $\\Delta^\\star/2$ from the nearest sample plane. The error in a 1-Lipschitz function's value at this point compared to its value on the nearest plane is at most this distance. This \"radius\" of unsampled regions, $B = \\Delta^\\star/2 = 1/(2\\lVert w^\\star \\rVert_2)$, serves as a principled bound on the local estimation error. While a full analysis of the bias in the mean involves integrating over the domain, $B$ quantifies the scale of the worst-case local deviation and thus provides a powerful and intuitive proxy for the potential systematic bias introduced by the generator's lattice structure.\n\n**Algorithmic Implementation**\n\nTo compute the spectral test metrics, we must find the shortest nonzero vector $w^\\star$ in the lattice spanned by the basis $\\{b_1, b_2, b_3\\}$. This is the Shortest Vector Problem (SVP), which is hard in general but feasible in low dimensions like $d=3$. The strategy is to first use a lattice basis reduction algorithm, such as the Lenstra–Lenstra–Lovász (LLL) algorithm, to transform the highly skewed initial basis into a new basis of short, nearly orthogonal vectors. The shortest vector in the lattice is then likely to be one of these new basis vectors or a very short integer linear combination of them. We implement the LLL algorithm for $d=3$ followed by a search over a small box of integer coefficients to find the exact $w^\\star$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy  # Imported to adhere to problem spec, although not directly used.\n\ndef lll_3d(basis, delta=0.75):\n    \"\"\"\n    Performs LLL lattice basis reduction for a 3D basis.\n    \n    Args:\n        basis (list of lists or np.ndarray): The initial basis vectors (as rows).\n        delta (float): The LLL reduction parameter, typically in (0.25, 1).\n    \n    Returns:\n        np.ndarray: The LLL-reduced basis.\n    \"\"\"\n    B = np.array(basis, dtype=np.int64)\n    \n    while True:\n        # Gram-Schmidt Orthogonalization\n        B_star = np.zeros_like(B, dtype=np.float64)\n        mu = np.zeros((3, 3), dtype=np.float64)\n        \n        B_star[0] = B[0]\n        for i in range(1, 3):\n            B_star[i] = B[i].astype(np.float64)\n            for j in range(i):\n                # Ensure dot products are computed with high precision floats\n                dot_bi_bstarj = np.dot(B[i].astype(np.float64), B_star[j])\n                dot_bstarj_bstarj = np.dot(B_star[j], B_star[j])\n                if dot_bstarj_bstarj == 0:\n                    mu[i, j] = 0\n                else:\n                    mu[i, j] = dot_bi_bstarj / dot_bstarj_bstarj\n\n                B_star[i] -= mu[i, j] * B_star[j]\n\n        # Size Reduction step\n        reduced_in_pass = False\n        for i in range(1, 3):\n            for j in range(i - 1, -1, -1):\n                if abs(mu[i, j])  0.5:\n                    B[i] -= np.round(mu[i, j]).astype(np.int64) * B[j]\n                    reduced_in_pass = True\n        \n        if reduced_in_pass:\n            continue\n\n        # Lovasz Condition and Swapping step\n        swapped = False\n        for i in range(1, 3):\n            norm_b_star_i_sq = np.dot(B_star[i], B_star[i])\n            norm_b_star_prev_sq = np.dot(B_star[i-1], B_star[i-1])\n\n            if norm_b_star_i_sq  (delta - mu[i, i-1]**2) * norm_b_star_prev_sq:\n                B[[i, i-1]] = B[[i-1, i]]\n                swapped = True\n                break # Restart LLL\n        \n        if not swapped:\n            break # LLL terminated\n            \n    return B\n\ndef find_shortest_vector(basis, search_range=5):\n    \"\"\"Finds the shortest non-zero vector in a lattice given a basis.\"\"\"\n    \n    # Use LLL to get a basis of shorter vectors\n    reduced_basis = lll_3d(basis)\n    \n    # The shortest vector is often one of the reduced basis vectors\n    min_sq_norm = float('inf')\n    shortest_vec = None\n    \n    for vec in reduced_basis:\n        sq_norm = np.dot(vec, vec)\n        if 0  sq_norm  min_sq_norm:\n            min_sq_norm = sq_norm\n            shortest_vec = vec\n\n    # Enumerate short integer combinations of the reduced basis vectors\n    b1, b2, b3 = reduced_basis\n    for c1 in range(-search_range, search_range + 1):\n        for c2 in range(-search_range, search_range + 1):\n            for c3 in range(-search_range, search_range + 1):\n                if c1 == 0 and c2 == 0 and c3 == 0:\n                    continue\n                \n                vec = c1 * b1 + c2 * b2 + c3 * b3\n                sq_norm = np.dot(vec, vec)\n                \n                if 0  sq_norm  min_sq_norm:\n                    min_sq_norm = sq_norm\n                    shortest_vec = vec\n                    \n    return shortest_vec\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (m, a, c)\n        (65537, 3, 0),        # Case A\n        (13, 3, 0),          # Case B\n        (65537, 3, 12345),    # Case C\n    ]\n\n    results = []\n    q_values = []\n\n    for m, a, c in test_cases:\n        # Construct the lattice basis for vectors w = (w0, w1, w2) satisfying\n        # w0 + a*w1 + a^2*w2 === 0 (mod m)\n        # We use a^2 % m to keep initial numbers smaller, which is valid.\n        a2_mod_m = (a * a) % m\n        basis = [\n            [m, 0, 0],\n            [-a, 1, 0],\n            [-a2_mod_m, 0, 1]\n        ]\n        \n        # Find the shortest non-zero vector in this lattice\n        w_star = find_shortest_vector(np.array(basis, dtype=np.int64))\n        \n        # Calculate the required metrics\n        norm_w_star = np.linalg.norm(w_star)\n        q_metric = norm_w_star / (m**(1/3.0))\n        b_metric = 1.0 / (2.0 * norm_w_star)\n        \n        results.extend([norm_w_star, q_metric, b_metric])\n        q_values.append(q_metric)\n\n    # Calculate the difference in Q between Case A and Case C\n    delta_q = abs(q_values[0] - q_values[2])\n    results.append(delta_q)\n    \n    # Format the final output string with results rounded to six decimal places.\n    output_str = f\"[{','.join(['{:.6f}'.format(x) for x in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3531220"}, {"introduction": "The ultimate test of a random number generator is its performance within a specific scientific application. This practice moves beyond generic statistical tests to an advanced, domain-specific validation method rooted in the simulation of Gaussian random fields, which are foundational models in cosmology and turbulence studies. You will implement a test that uses the shell-averaged power spectrum, $P(k)$, to reveal how flaws in a generator propagate into systematic errors in a physical simulation, highlighting the direct impact of RNG quality on scientific accuracy [@problem_id:3531195].", "problem": "You are asked to implement a spectral uniformity test for random number generators in the context of computational astrophysics. The objective is to use uniform deviates to sample complex Fourier modes of an isotropic Gaussian random field in $k$-space and to quantify uniformity via deviations in shell-averaged power spectrum values. The program must be a complete, runnable program that produces the requested outputs with no user input.\n\nFundamental base:\n- Homogeneous, isotropic Gaussian random field models are widely used in computational astrophysics. The Fourier-space field is characterized by a power spectrum $P(k)$ that depends only on the magnitude $k = \\lVert \\mathbf{k} \\rVert$.\n- For a Gaussian random field, each independent complex Fourier mode $a_{\\mathbf{k}}$ has real and imaginary parts that are independent Gaussian random variables with zero mean and variance $P(k)/2$. Consequently, the squared amplitude $X_{\\mathbf{k}} = \\lvert a_{\\mathbf{k}} \\rvert^2$ has an exponential distribution with mean $P(k)$ and variance $P(k)^2$.\n- Uniform deviates on the interval $(0,1)$ are transformed to Gaussian deviates using the Box–Muller method. Angles used in the Box–Muller transform must be in radians.\n\nDefinitions and target computation:\n1. Let the discrete two-dimensional Fourier grid be indexed by $(i,j)$ with sizes $N_x$ and $N_y$. Define wave numbers using the discrete Fourier frequencies such that $k_x \\in \\{-\\lfloor N_x/2 \\rfloor, \\ldots, \\lfloor N_x/2 \\rfloor - 1\\}$ and similarly for $k_y$. Define $k = \\sqrt{k_x^2 + k_y^2}$.\n2. Define radial shells by integer binning of $k$ via $s = \\lfloor k + 0.5 \\rfloor$. Exclude the $s = 0$ shell (the zero mode).\n3. For each shell $s$, let $\\mathcal{K}_s$ be the set of indices $(i,j)$ whose wave number magnitude falls in shell $s$ and let $K_s = \\lvert \\mathcal{K}_s \\rvert$ be the number of modes in shell $s$.\n4. For each test case, generate $M$ independent ensembles of complex Fourier coefficients $a_{\\mathbf{k}}$ via Box–Muller from uniform deviates, with $\\operatorname{Re}(a_{\\mathbf{k}})$ and $\\operatorname{Im}(a_{\\mathbf{k}})$ sampled from $\\mathcal{N}(0, P(k)/2)$.\n5. For each shell $s$, compute the aggregated sample mean of the squared amplitudes across all ensembles and modes in the shell:\n   $$\\widehat{P}_s = \\frac{1}{M K_s} \\sum_{m=1}^{M} \\sum_{(i,j) \\in \\mathcal{K}_s} X_{\\mathbf{k},m}, \\quad \\text{where } X_{\\mathbf{k},m} = \\lvert a_{\\mathbf{k},m} \\rvert^2.$$\n6. The expected shell mean is\n   $$\\mathbb{E}[\\widehat{P}_s] = \\frac{1}{K_s} \\sum_{(i,j) \\in \\mathcal{K}_s} P(k_{i,j}).$$\n   Because $X_{\\mathbf{k}}$ is exponential with variance $P(k)^2$ and samples are independent, the variance of $\\widehat{P}_s$ is\n   $$\\operatorname{Var}(\\widehat{P}_s) = \\frac{\\sum_{(i,j) \\in \\mathcal{K}_s} P(k_{i,j})^2}{M K_s^2},$$\n   and the corresponding standard deviation is\n   $$\\sigma_s = \\sqrt{\\frac{\\sum_{(i,j) \\in \\mathcal{K}_s} P(k_{i,j})^2}{M K_s^2}}.$$\n7. Define the shell-wise normalized deviation (a $z$-score):\n   $$z_s = \\frac{\\lvert \\widehat{P}_s - \\mathbb{E}[\\widehat{P}_s] \\rvert}{\\sigma_s}.$$\n8. Define a test threshold $T$ and declare the test case as passing if the maximum shell deviation satisfies $\\max_s z_s \\leq T$, and failing otherwise.\n\nImplementation requirements:\n- Use only uniform deviates to generate Gaussian deviates via the Box–Muller transform. Use angles in radians.\n- Implement multiple uniform random number generators:\n  - A high-quality generator based on Permuted Congruential Generator 64-bit (PCG64).\n  - A deliberately pathological generator that alternates between two values in $(0,1)$, thus violating uniformity.\n- Implement the power spectrum $P(k)$ in a dimensionless form. You must handle at least:\n  - White spectrum: $P(k) = P_0$ for $k > 0$.\n  - Power-law spectrum: $P(k) = P_0 \\left( \\frac{k}{k_0} \\right)^{n}$ for $k > 0$, with specified exponent $n$ and scale $k_0$.\n\nUnits:\n- All quantities are dimensionless. Angles in any trigonometric operations must be in radians.\n\nTest suite:\nYou must implement the following test cases. Each case specifies $(\\text{rng\\_type}, N_x, N_y, M, P_0, n, k_0, T)$, where $\\text{rng\\_type} \\in \\{\\text{\"pcg\"}, \\text{\"alt\"}\\}$ selects the random number generator.\n\n- Case 1 (happy path): $(\\text{\"pcg\"}, 64, 64, 60, 1.0, 0, 1.0, 3.5)$, white spectrum.\n- Case 2 (coverage with power-law): $(\\text{\"pcg\"}, 32, 32, 20, 1.0, -2.0, 6.0, 3.5)$, power-law spectrum $P(k) = P_0 (k/k_0)^n$ for $k > 0$.\n- Case 3 (pathological RNG): $(\\text{\"alt\"}, 64, 64, 60, 1.0, 0, 1.0, 3.5)$, white spectrum.\n- Case 4 (boundary: small sample size): $(\\text{\"pcg\"}, 16, 16, 8, 1.0, 0, 1.0, 4.0)$, white spectrum.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,result3,result4]\"), where each result is a boolean indicating whether the corresponding test case passed (True) or failed (False).", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of statistical field theory and computational astrophysics, specifically concerning the properties of Gaussian random fields and their Fourier-space representation. The problem is well-posed, with all necessary definitions, constants, and computational steps adequately specified. It is objective, complete, and computationally feasible.\n\nThe solution involves implementing a statistical test to validate the quality of a random number generator (RNG). The test leverages the statistical properties of a simulated two-dimensional homogeneous and isotropic Gaussian random field. The core principle is that if the underlying uniform deviates from an RNG are truly uniform, the derived physical quantities from the simulation will match their theoretical expectations within a certain statistical tolerance. Deviations from uniformity in the RNG will propagate into systematic biases in the simulated field, which the test is designed to detect.\n\nThe solution proceeds through the following steps for each test case provided:\n\n1.  **Parameter Initialization**: For each test case, we define the grid dimensions ($N_x$, $N_y$), the number of ensembles ($M$), the power spectrum parameters ($P_0$, $n$, $k_0$), the test threshold ($T$), and the type of random number generator (`rng_type`).\n\n2.  **Wave Number Grid Generation**: A two-dimensional discrete Fourier grid is constructed. The wave number components, $k_x$ and $k_y$, are defined according to the discrete Fourier transform convention, centered around zero. Specifically, for a grid of size $N$, the wave numbers are integers in the range $\\{-\\lfloor N/2 \\rfloor, \\ldots, \\lfloor N/2 \\rfloor - 1\\}$. From these components, the magnitude of the wave vector, $k = \\sqrt{k_x^2 + k_y^2}$, is calculated for each point on the grid.\n\n3.  **Power Spectrum Model**: A function is implemented to calculate the theoretical power spectrum, $P(k)$. This function supports both a white spectrum, where $P(k) = P_0$ for $k > 0$, and a power-law spectrum, $P(k) = P_0 (k/k_0)^n$ for $k > 0$. For the $k=0$ mode, the power is defined to be $P(0) = 0$, consistent with standard cosmological assumptions and the problem's explicit focus on $k > 0$.\n\n4.  **Shell Binning and Theoretical Statistics**: The k-space is partitioned into radial shells based on the integer value of the wave number magnitude, $s = \\lfloor k + 0.5 \\rfloor$. The $s=0$ shell, corresponding to the DC component, is excluded from the analysis. For each remaining shell $s$:\n    *   The number of discrete Fourier modes, $K_s$, is counted.\n    *   The expected shell-averaged power, $\\mathbb{E}[\\widehat{P}_s]$, is computed as the average of $P(k)$ over all modes within that shell:\n        $$ \\mathbb{E}[\\widehat{P}_s] = \\frac{1}{K_s} \\sum_{(i,j) \\in \\mathcal{K}_s} P(k_{i,j}) $$\n    *   The theoretical standard deviation of the estimator, $\\sigma_s$, is calculated. This relies on the fact that the squared amplitude of a mode, $X_{\\mathbf{k}} = |a_{\\mathbf{k}}|^2$, is an exponentially distributed random variable with variance $P(k)^2$. The variance of the shell-averaged power estimator $\\widehat{P}_s$ is then:\n        $$ \\operatorname{Var}(\\widehat{P}_s) = \\frac{\\sum_{(i,j) \\in \\mathcal{K}_s} P(k_{i,j})^2}{M K_s^2} $$\n        And the standard deviation is $\\sigma_s = \\sqrt{\\operatorname{Var}(\\widehat{P}_s)}$. Shells with no modes ($K_s=0$) are excluded from further calculations.\n\n5.  **Random Field Simulation**:\n    *   An appropriate RNG is initialized based on the `rng_type` parameter. For `\"pcg\"`, a seeded `numpy.random.PCG64` generator is used for reproducibility. For `\"alt\"`, a custom generator is implemented to produce a pathological sequence of alternating values (e.g., $0.25$ and $0.75$).\n    *   For each of the $M$ ensembles, a complex Fourier-space field $a_{\\mathbf{k}}$ is generated. This is done by first generating grids of uniform deviates, $u_1$ and $u_2$, in the interval $(0,1)$. To avoid numerical issues with $\\log(0)$, any generated values of $u_1$ that are exactly $0$ are replaced with a small positive number.\n    *   The Box-Muller transform is applied to $(u_1, u_2)$ to produce two grids of independent standard normal deviates, $g_1$ and $g_2$.\n        $$ g_1 = \\sqrt{-2 \\ln u_1} \\cos(2 \\pi u_2) $$\n        $$ g_2 = \\sqrt{-2 \\ln u_1} \\sin(2 \\pi u_2) $$\n    *   The real and imaginary parts of the complex Fourier amplitudes $a_{\\mathbf{k}}$ are then constructed by scaling these standard normal deviates to have the required variance $P(k)/2$:\n        $$ \\operatorname{Re}(a_{\\mathbf{k}}) = g_1 \\sqrt{P(k)/2} $$\n        $$ \\operatorname{Im}(a_{\\mathbf{k}}) = g_2 \\sqrt{P(k)/2} $$\n    *   The squared amplitude for each mode, $X_{\\mathbf{k},m} = |a_{\\mathbf{k},m}|^2 = (\\operatorname{Re}(a_{\\mathbf{k},m}))^2 + (\\operatorname{Im}(a_{\\mathbf{k},m}))^2$, is calculated for the current ensemble $m$.\n\n6.  **Statistical Analysis and Verdict**:\n    *   The simulated squared amplitudes $X_{\\mathbf{k},m}$ are aggregated. Specifically, they are summed over all $M$ ensembles and binned into the same radial shells $s$ used for the theoretical values.\n    *   The simulated shell-averaged power, $\\widehat{P}_s$, is calculated:\n        $$ \\widehat{P}_s = \\frac{1}{M K_s} \\sum_{m=1}^{M} \\sum_{(i,j) \\in \\mathcal{K}_s} X_{\\mathbf{k},m} $$\n    *   For each shell, the normalized deviation (z-score) is computed:\n        $$ z_s = \\frac{|\\widehat{P}_s - \\mathbb{E}[\\widehat{P}_s]|}{\\sigma_s} $$\n    *   The maximum deviation across all shells, $\\max_s z_s$, is found.\n    *   The test case is declared as passing if this maximum deviation is less than or equal to the specified threshold $T$, i.e., if $\\max_s z_s \\leq T$. Otherwise, it fails.\n\nThis entire process is performed for each of the four test cases specified in the problem statement. The implementation is fully vectorized using `numpy` for efficiency, avoiding explicit loops over grid points or ensembles where possible. The final output is a list of boolean values indicating the pass/fail result for each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# No other libraries are permitted as per the instructions.\n\ndef solve():\n    \"\"\"\n    Main function to run the spectral uniformity tests and print the results.\n    \"\"\"\n\n    class AlternatingRNG:\n        \"\"\"\n        A pathological RNG that alternates between two fixed values.\n        This class mimics the interface of a numpy.random.Generator.\n        \"\"\"\n        def __init__(self, val1=0.25, val2=0.75):\n            self._vals = np.array([val1, val2])\n            self._state = 0\n\n        def random(self, size=None):\n            if size is None:\n                val = self._vals[self._state]\n                self._state = (self._state + 1) % 2\n                return val\n\n            n_elements = int(np.prod(size))\n            start_index = self._state\n            indices = (np.arange(n_elements) + start_index) % 2\n            output = self._vals[indices]\n            self._state = (start_index + n_elements) % 2\n            return output.reshape(size)\n\n    def power_spectrum(k, P0, n, k0):\n        \"\"\"\n        Calculates the power spectrum P(k).\n        \"\"\"\n        pk = np.zeros_like(k, dtype=float)\n        # The k=0 mode has P(0)=0. The problem states the formula is for k0.\n        non_zero_k_mask = k  0\n        k_pos = k[non_zero_k_mask]\n        \n        # White spectrum is a special case of power-law with n=0\n        if n == 0.0:\n            pk[non_zero_k_mask] = P0\n        else: # Power-law spectrum\n            pk[non_zero_k_mask] = P0 * (k_pos / k0)**n\n            \n        return pk\n\n    def run_test_case(rng_type, Nx, Ny, M, P0, n, k0, T):\n        \"\"\"\n        Executes a single test case for the spectral uniformity test.\n        \"\"\"\n        # 1. RNG Setup\n        if rng_type == \"pcg\":\n            # Use a fixed seed for reproducibility.\n            rng = np.random.Generator(np.random.PCG64(seed=12345))\n        elif rng_type == \"alt\":\n            rng = AlternatingRNG(val1=0.25, val2=0.75)\n        else:\n            raise ValueError(\"Unknown rng_type\")\n\n        # 2. Grid and k-space Setup\n        kx_int = np.fft.fftshift(np.fft.fftfreq(Nx) * Nx)\n        ky_int = np.fft.fftshift(np.fft.fftfreq(Ny) * Ny)\n        kx_grid, ky_grid = np.meshgrid(kx_int, ky_int)\n        \n        # In meshgrid with 'ij' indexing, first index is row (y), second is col (x)\n        # So we swap them to match physical (x, y) coordinates\n        k_grid = np.sqrt(ky_grid**2 + kx_grid**2)\n\n        # 3. Power Spectrum Model\n        pk_grid = power_spectrum(k_grid, P0, n, k0)\n\n        # 4. Shell Binning and Theoretical Statistics\n        s_grid = np.floor(k_grid + 0.5).astype(int)\n        max_s_val = np.max(s_grid)\n        \n        # Use bincount for efficient aggregation into shells\n        # We need counts up to max_s_val, so length must be max_s_val + 1\n        s_ravel = s_grid.ravel()\n        Ks_all = np.bincount(s_ravel, minlength=max_s_val + 1)\n        \n        sum_pk_s = np.bincount(s_ravel, weights=pk_grid.ravel(), minlength=max_s_val + 1)\n        sum_pk_sq_s = np.bincount(s_ravel, weights=(pk_grid**2).ravel(), minlength=max_s_val + 1)\n        \n        # Exclude shell s=0 and any shells with no modes\n        valid_shells_mask = (np.arange(max_s_val + 1)  0)  (Ks_all  0)\n        \n        Ks = Ks_all[valid_shells_mask]\n        \n        # Theoretical expectations\n        E_Phat_s = sum_pk_s[valid_shells_mask] / Ks\n        Var_Phat_s = sum_pk_sq_s[valid_shells_mask] / (M * Ks**2)\n        sigma_s = np.sqrt(Var_Phat_s)\n\n        # 5. Random Field Simulation (fully vectorized over ensembles)\n        sim_size = (M, Ny, Nx)\n        \n        # Generate uniform deviates for Box-Muller\n        u1 = rng.random(size=sim_size)\n        \n        # Handle u1=0 to avoid log(0) = -inf\n        u1[u1 == 0.0] = np.finfo(float).eps\n        \n        u2 = rng.random(size=sim_size)\n        \n        # Box-Muller transform\n        mag = np.sqrt(-2.0 * np.log(u1))\n        g1 = mag * np.cos(2.0 * np.pi * u2)\n        g2 = mag * np.sin(2.0 * np.pi * u2)\n        \n        # Scale to get Re(a_k) and Im(a_k)\n        # pk_grid must be broadcast to the simulation shape\n        sqrt_pk_half = np.sqrt(pk_grid / 2.0)\n        \n        re_ak = g1 * sqrt_pk_half\n        im_ak = g2 * sqrt_pk_half\n        \n        # Calculate squared amplitude X_k = |a_k|^2\n        Xk_m = re_ak**2 + im_ak**2\n        \n        # 6. Statistical Analysis and Verdict\n        # Sum over ensembles\n        Xk_total_ensembles = np.sum(Xk_m, axis=0) # Shape (Ny, Nx)\n        \n        # Bin into shells\n        total_Xk_s = np.bincount(s_ravel, weights=Xk_total_ensembles.ravel(), minlength=max_s_val + 1)\n        \n        # Calculate simulated shell-averaged power\n        Phat_s = total_Xk_s[valid_shells_mask] / (M * Ks)\n        \n        # Calculate z-scores\n        z_s = np.abs(Phat_s - E_Phat_s) / sigma_s\n        \n        # Some shells might have sigma_s = 0 if P(k)=0 for all k in that shell.\n        # This can happen if P(k)=0 for kk_max for example.\n        # In that case, P_hat_s should also be 0, resulting in 0/0.\n        # We define 0/0 as 0 for the z-score.\n        z_s[sigma_s == 0.0] = 0.0\n        \n        max_z = np.max(z_s)\n        \n        return max_z = T\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (rng_type, Nx, Ny, M, P0, n, k0, T)\n        (\"pcg\", 64, 64, 60, 1.0, 0.0, 1.0, 3.5),\n        (\"pcg\", 32, 32, 20, 1.0, -2.0, 6.0, 3.5),\n        (\"alt\", 64, 64, 60, 1.0, 0.0, 1.0, 3.5),\n        (\"pcg\", 16, 16, 8, 1.0, 0.0, 1.0, 4.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(*case)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3531195"}]}