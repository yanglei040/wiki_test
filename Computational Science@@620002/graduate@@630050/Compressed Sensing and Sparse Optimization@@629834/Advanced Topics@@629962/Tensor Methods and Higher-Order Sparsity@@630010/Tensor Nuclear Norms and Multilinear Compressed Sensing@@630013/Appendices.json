{"hands_on_practices": [{"introduction": "Before deploying tensor nuclear norms in complex optimization algorithms, it is crucial to build a firm intuition for how they are calculated. The overlapped tensor nuclear norm is a widely used convex surrogate for the non-convex tensor rank, defined as a weighted sum of the nuclear norms of the tensor's matrix unfoldings. This exercise provides direct, hands-on practice in applying this definition. By working through the calculation, you will solidify the connection between an abstract tensor, its various matrix representations, and the resulting norm value, ensuring a solid grasp of a fundamental tool in low-rank tensor recovery. [@problem_id:3485954]", "problem": "Consider a real $3$-way tensor $X \\in \\mathbb{R}^{I_{1} \\times I_{2} \\times I_{3}}$. For each mode $n \\in \\{1,2,3\\}$, let $X_{(n)}$ denote the mode-$n$ unfolding of $X$ as a matrix. The matrix nuclear norm $\\|\\cdot\\|_{*}$ is defined as the sum of the singular values of its matrix argument. The overlapped tensor nuclear norm is defined by\n$$\n\\|X\\|_{\\text{overlap}} \\triangleq \\sum_{n=1}^{3} \\lambda_{n} \\, \\|X_{(n)}\\|_{*},\n$$\nfor prescribed positive weights $\\lambda_{n}$. Suppose that, for each $n \\in \\{1,2,3\\}$, the unfolding $X_{(n)}$ is a rectangular matrix that is, up to multiplication on the left and right by orthogonal matrices, block-diagonal with diagonal blocks that are themselves diagonal matrices whose diagonal entries (all nonnegative) are listed below. Equivalently, the nonzero singular values of $X_{(n)}$ are precisely the multiset union of the diagonal entries listed for its blocks. Assume the supports of these blocks are disjoint across the matrix so that the singular values of $X_{(n)}$ are exactly the listed entries, and that these specifications are jointly consistent across modes (for instance, via an orthogonally decomposable Tucker model), so such a tensor $X$ exists.\n\nThe blocks and their diagonal entries for each unfolding are as follows:\n- For $X_{(1)}$: three diagonal blocks with diagonals $[6,\\,4]$, $[3,\\,2,\\,1]$, and $[5]$.\n- For $X_{(2)}$: two diagonal blocks with diagonals $[7,\\,1,\\,1]$ and $[2,\\,2,\\,2]$.\n- For $X_{(3)}$: four diagonal blocks with diagonals $[3,\\,3]$, $[4]$, $[2,\\,1]$, and $[5]$.\n\nLet the weights be $\\lambda_{1}=\\tfrac{3}{5}$, $\\lambda_{2}=\\tfrac{5}{4}$, and $\\lambda_{3}=\\tfrac{4}{5}$.\n\nCompute the exact value of $\\|X\\|_{\\text{overlap}}$ as a single simplified number. Do not round your answer.", "solution": "The problem statement is deemed valid as it is scientifically grounded in the field of multilinear algebra, mathematically well-posed, and all necessary data and definitions are provided without contradiction or ambiguity. The existence of a tensor $X$ satisfying the specified singular value properties for its unfoldings is explicitly asserted, making the problem self-contained.\n\nThe objective is to compute the overlapped tensor nuclear norm $\\|X\\|_{\\text{overlap}}$ of a $3$-way tensor $X \\in \\mathbb{R}^{I_{1} \\times I_{2} \\times I_{3}}$. This norm is defined as a weighted sum of the nuclear norms of its mode-$n$ unfoldings, $X_{(n)}$:\n$$\n\\|X\\|_{\\text{overlap}} \\triangleq \\sum_{n=1}^{3} \\lambda_{n} \\, \\|X_{(n)}\\|_{*}\n$$\nThe weights are given as $\\lambda_{1}=\\frac{3}{5}$, $\\lambda_{2}=\\frac{5}{4}$, and $\\lambda_{3}=\\frac{4}{5}$.\n\nThe nuclear norm of a matrix, denoted $\\|\\cdot\\|_{*}$, is the sum of its singular values. The problem provides the non-zero singular values for each of the three matrix unfoldings of the tensor $X$.\n\nFirst, we compute the nuclear norm of the mode-$1$ unfolding, $\\|X_{(1)}\\|_{*}$. The problem states that the non-zero singular values of $X_{(1)}$ are given by the collection of entries from its diagonal blocks: $\\{6, 4\\}$, $\\{3, 2, 1\\}$, and $\\{5\\}$. The complete multiset of singular values is therefore $\\{6, 4, 3, 2, 1, 5\\}$. The nuclear norm is the sum of these values:\n$$\n\\|X_{(1)}\\|_{*} = 6 + 4 + 3 + 2 + 1 + 5 = 21\n$$\n\nSecond, we compute the nuclear norm of the mode-$2$ unfolding, $\\|X_{(2)}\\|_{*}$. The singular values of $X_{(2)}$ are given by the entries from its diagonal blocks: $\\{7, 1, 1\\}$ and $\\{2, 2, 2\\}$. The complete multiset of singular values is $\\{7, 1, 1, 2, 2, 2\\}$. The nuclear norm is the sum of these values:\n$$\n\\|X_{(2)}\\|_{*} = 7 + 1 + 1 + 2 + 2 + 2 = 15\n$$\n\nThird, we compute the nuclear norm of the mode-$3$ unfolding, $\\|X_{(3)}\\|_{*}$. The singular values of $X_{(3)}$ are given by the entries from its diagonal blocks: $\\{3, 3\\}$, $\\{4\\}$, $\\{2, 1\\}$, and $\\{5\\}$. The complete multiset of singular values is $\\{3, 3, 4, 2, 1, 5\\}$. The nuclear norm is the sum of these values:\n$$\n\\|X_{(3)}\\|_{*} = 3 + 3 + 4 + 2 + 1 + 5 = 18\n$$\n\nNow, we substitute these nuclear norm values and the given weights into the definition of the overlapped tensor nuclear norm:\n$$\n\\|X\\|_{\\text{overlap}} = \\lambda_{1} \\|X_{(1)}\\|_{*} + \\lambda_{2} \\|X_{(2)}\\|_{*} + \\lambda_{3} \\|X_{(3)}\\|_{*}\n$$\n$$\n\\|X\\|_{\\text{overlap}} = \\left(\\frac{3}{5}\\right) (21) + \\left(\\frac{5}{4}\\right) (15) + \\left(\\frac{4}{5}\\right) (18)\n$$\nWe compute each term:\n$$\n\\left(\\frac{3}{5}\\right) (21) = \\frac{63}{5}\n$$\n$$\n\\left(\\frac{5}{4}\\right) (15) = \\frac{75}{4}\n$$\n$$\n\\left(\\frac{4}{5}\\right) (18) = \\frac{72}{5}\n$$\nSumming these terms:\n$$\n\\|X\\|_{\\text{overlap}} = \\frac{63}{5} + \\frac{75}{4} + \\frac{72}{5}\n$$\nWe can combine the terms with the denominator $5$:\n$$\n\\|X\\|_{\\text{overlap}} = \\left( \\frac{63}{5} + \\frac{72}{5} \\right) + \\frac{75}{4} = \\frac{135}{5} + \\frac{75}{4}\n$$\nSimplifying the first term:\n$$\n\\frac{135}{5} = 27\n$$\nSo, the expression becomes:\n$$\n\\|X\\|_{\\text{overlap}} = 27 + \\frac{75}{4}\n$$\nTo obtain a single fraction, we find a common denominator, which is $4$:\n$$\n\\|X\\|_{\\text{overlap}} = \\frac{27 \\times 4}{4} + \\frac{75}{4} = \\frac{108}{4} + \\frac{75}{4} = \\frac{108 + 75}{4} = \\frac{183}{4}\n$$\nThe exact value of the overlapped tensor nuclear norm is $\\frac{183}{4}$.", "answer": "$$\\boxed{\\frac{183}{4}}$$", "id": "3485954"}, {"introduction": "Moving from foundational definitions to practical applications, we now explore how tensor nuclear norms guide the design of efficient data acquisition strategies in multilinear compressed sensing. A central challenge in this field is how to best allocate a limited measurement budget across different tensor modes to minimize recovery error. This practice is rooted in the principle that recovery quality depends directly on the number of measurements per mode, a relationship that can be modeled and optimized. You will develop an algorithm to solve this real-world resource allocation problem, connecting abstract tensor properties like rank and coherence to a concrete engineering design and honing your skills in convex optimization and algorithm implementation. [@problem_id:3485962]", "problem": "Consider a $K$-mode tensor $\\mathcal{X} \\in \\mathbb{R}^{n_1 \\times \\cdots \\times n_K}$ that is approximately low multilinear rank, with per-mode ranks $r_k$ for $k \\in \\{1,\\dots,K\\}$. Measurements are acquired through a separable, multi-resolution sensing design that allocates a mode-specific measurement budget $m_k$ along each mode-$k$ subspace, where $m_k$ counts are nonnegative integers that must satisfy $L_k \\le m_k \\le U_k$ and a global constraint $\\sum_{k=1}^K m_k = M$. The sensing model is linear with additive noise that is independent identically distributed Gaussian with zero mean and finite variance, and the recovery is performed by a weighted tensor nuclear norm minimization, where the weighted tensor nuclear norm is defined as $\\|\\mathcal{X}\\|_{\\text{W-TNN}} = \\sum_{k=1}^K w_k \\|X_{(k)}\\|_*$, with $X_{(k)}$ denoting the mode-$k$ unfolding of $\\mathcal{X}$, $\\| \\cdot \\|_*$ the matrix nuclear norm, and $w_k  0$ are fixed weights.\n\nA foundational fact from compressed sensing and low-rank recovery with nuclear norm regularization under Gaussian sensing and a Restricted Isometry Property (RIP) type condition is that error bounds for the recovered entity typically exhibit inverse square-root dependence on the number of measurements. Specifically, per-mode contributions to an upper bound on the recovery error (measured, for instance, in Frobenius norm) can be abstracted as a sum of terms that scale as $m_k^{-1/2}$, modulated by problem-dependent coefficients. In a mode-wise characterization that accounts for subspace coherence and rank, it is scientifically justified to model a tractable upper bound as\n$$\n\\mathcal{E}(\\mathbf{m}) \\le \\sum_{k=1}^K \\frac{a_k}{\\sqrt{m_k}},\n$$\nwhere $a_k = \\gamma \\, w_k \\, \\sqrt{\\mu_k \\, r_k}$, $\\mu_k \\ge 1$ is a mode-$k$ coherence parameter (measuring alignment of the mode-$k$ subspace with the canonical basis), $r_k$ is the mode-$k$ multilinear rank, $w_k$ is the mode-$k$ weight in the weighted tensor nuclear norm, and $\\gamma  0$ is a universal constant absorbing noise level and other bounded factors.\n\nYou must construct an algorithm that, given $\\{a_k\\}_{k=1}^K$, lower and upper bounds $\\{L_k,U_k\\}$, and a total budget $M$, computes an integer allocation $\\{m_k\\}_{k=1}^K$ that minimizes the bound $\\sum_{k=1}^K a_k/\\sqrt{m_k}$ subject to $L_k \\le m_k \\le U_k$ and $\\sum_{k=1}^K m_k = M$. Your algorithm must exploit the convexity structure of the continuous relaxation and deliver a globally optimal integer solution under the stated separable convex objective and linear constraints. The final recovery-error bound should be evaluated at the computed integer allocation. All mathematical variables appearing in this description are as defined above.\n\nYou are required to implement the following computational design:\n1. Compute $a_k = \\gamma \\, w_k \\, \\sqrt{\\mu_k \\, r_k}$ for $k \\in \\{1,\\dots,K\\}$.\n2. Solve the continuous relaxation by minimizing $\\sum_{k=1}^K a_k \\, m_k^{-1/2}$ subject to $L_k \\le m_k \\le U_k$ and $\\sum_{k=1}^K m_k = M$, using a principled method that is consistent with the Karush–Kuhn–Tucker (KKT) conditions.\n3. Project the continuous solution to integers that exactly satisfy the constraints using a procedure that preserves global optimality for separable convex objectives under a single equality constraint. The final integer solution must satisfy $L_k \\le m_k \\le U_k$ and $\\sum_{k=1}^K m_k = M$.\n4. Compute the bound value $\\sum_{k=1}^K a_k/\\sqrt{m_k}$ at the integer solution and round this bound to six decimal places.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. Each test case must output a list that concatenates the optimal integer budget vector $[m_1,\\dots,m_K]$ followed by the computed bound value. Therefore, for a test case with $K=3$, the output item should be of the form $[m_1,m_2,m_3,E]$, where $E$ is the rounded bound value.\n\nUse the following test suite, which spans a general case, a highly coherent mode case, a boundary case where the lower bounds saturate the budget, and a case with active upper bounds. In all cases set $\\gamma = 1$.\n\nTest case 1 (general multi-resolution design):\n- $K = 3$,\n- $n = [80,80,40]$ (dimensions, not used directly),\n- $\\mu = [5,2,3]$,\n- $r = [5,5,3]$,\n- $w = [1.5,1.0,1.2]$,\n- $L = [5,5,5]$,\n- $U = [60,60,40]$,\n- $M = 90$.\n\nTest case 2 (highly coherent mode prioritization):\n- $K = 3$,\n- $n = [100,60,60]$ (dimensions, not used directly),\n- $\\mu = [20,3,2]$,\n- $r = [3,3,3]$,\n- $w = [2.0,1.0,1.0]$,\n- $L = [2,2,2]$,\n- $U = [50,50,50]$,\n- $M = 30$.\n\nTest case 3 (boundary case with lower bounds saturating the budget):\n- $K = 3$,\n- $n = [50,50,50]$ (dimensions, not used directly),\n- $\\mu = [3,3,3]$,\n- $r = [2,2,2]$,\n- $w = [1.0,1.0,1.0]$,\n- $L = [4,4,4]$,\n- $U = [10,10,10]$,\n- $M = 12$.\n\nTest case 4 (upper bounds active in multi-resolution allocation):\n- $K = 4$,\n- $n = [120,60,60,30]$ (dimensions, not used directly),\n- $\\mu = [8,8,8,1]$,\n- $r = [10,2,2,1]$,\n- $w = [1.0,1.0,1.0,0.5]$,\n- $L = [1,1,1,1]$,\n- $U = [5,3,3,100]$,\n- $M = 20$.\n\nYour program should produce a single line with the aggregated results of all four test cases in the specified format, for example: \"[[m11,m12,m13,E1],[m21,m22,m23,E2],[m31,m32,m33,E3],[m41,m42,m43,m44,E4]]\". All values $m_{ik}$ must be integers and each $E_i$ must be a float rounded to six decimal places. No physical units, angles, or percentages are involved in this problem.", "solution": "The problem asks for an optimal integer allocation of a total measurement budget $M$ to minimize an upper bound on the recovery error in a multilinear compressed sensing problem. The problem is formally stated as a separable convex integer optimization problem.\n\nThe objective is to minimize the error bound $\\mathcal{E}(\\mathbf{m}) = \\sum_{k=1}^K \\frac{a_k}{\\sqrt{m_k}}$ subject to the constraints:\n1. $\\sum_{k=1}^K m_k = M$ (Total budget constraint)\n2. $L_k \\le m_k \\le U_k$ for $k \\in \\{1, \\dots, K\\}$ (Per-mode budget bounds)\n3. $m_k \\in \\mathbb{Z}_{\\ge 0}$ (Integer measurement counts)\n\nThe coefficients $a_k$ are given by $a_k = \\gamma \\, w_k \\, \\sqrt{\\mu_k \\, r_k}$, where the parameters are defined in the problem statement. For all test cases, $\\gamma=1$.\n\nThe solution strategy involves three main steps:\n1. Solve the continuous relaxation of the problem to find a non-integer optimal allocation.\n2. Project the continuous solution onto the feasible integer set using a method that guarantees optimality for this class of separable convex problems.\n3. Evaluate the objective function at the optimal integer allocation.\n\n**Step 1: Continuous Relaxation and KKT Conditions**\n\nWe first consider the problem where the variables $m_k$ are real numbers, i.e., $m_k \\in \\mathbb{R}$. The objective function $f_k(m_k) = a_k / \\sqrt{m_k}$ is strictly convex for $m_k  0$, as its second derivative $f_k''(m_k) = \\frac{3}{4} a_k m_k^{-5/2}$ is positive. The sum of convex functions is convex, so the total objective function $\\mathcal{E}(\\mathbf{m})$ is strictly convex. We are minimizing a strictly convex function over a convex feasible set (defined by linear constraints), which guarantees a unique optimal solution.\n\nTo find this solution, we use the method of Lagrange multipliers. The Lagrangian for the continuous problem is:\n$$\n\\mathcal{L}(\\mathbf{m}, \\lambda, \\boldsymbol{\\nu}^L, \\boldsymbol{\\nu}^U) = \\sum_{k=1}^K \\frac{a_k}{\\sqrt{m_k}} + \\lambda \\left(\\sum_{k=1}^K m_k - M\\right) + \\sum_{k=1}^K \\nu^L_k (L_k - m_k) + \\sum_{k=1}^K \\nu^U_k (m_k - U_k)\n$$\nwhere $\\lambda$, $\\nu^L_k$, and $\\nu^U_k$ are the Lagrange multipliers for the equality, lower-bound, and upper-bound constraints, respectively.\n\nThe Karush-Kuhn-Tucker (KKT) conditions for optimality require that the gradient of the Lagrangian with respect to each $m_k$ equals zero:\n$$ \\frac{\\partial \\mathcal{L}}{\\partial m_k} = -\\frac{1}{2} a_k m_k^{-3/2} + \\lambda - \\nu^L_k + \\nu^U_k = 0 $$\nThis must hold along with the complementary slackness conditions ($\\nu^L_k(L_k - m_k) = 0$, $\\nu^U_k(m_k - U_k) = 0$) and positivity of multipliers ($\\nu^L_k, \\nu^U_k \\ge 0$).\n\nFrom the stationarity condition, we have $\\frac{1}{2} a_k m_k^{-3/2} = \\lambda - \\nu^L_k + \\nu^U_k$. We analyze three cases for the optimal value of $m_k$:\n- If $L_k  m_k  U_k$, the bound constraints are inactive, so $\\nu^L_k = \\nu^U_k = 0$. This yields $-\\frac{1}{2} a_k m_k^{-3/2} + \\lambda = 0$, which implies $m_k = \\left(\\frac{a_k}{2\\lambda}\\right)^{2/3}$.\n- If $m_k = L_k$, the upper-bound constraint is inactive, so $\\nu^U_k = 0$. The condition becomes $\\lambda \\ge \\frac{1}{2} a_k L_k^{-3/2}$.\n- If $m_k = U_k$, the lower-bound constraint is inactive, so $\\nu^L_k = 0$. The condition becomes $\\lambda \\le \\frac{1}{2} a_k U_k^{-3/2}$.\n\nCombining these cases, the optimal continuous value for $m_k$ for a given Lagrange multiplier $\\lambda  0$ is a clipped version of the unconstrained solution:\n$$ m_k^*(\\lambda) = \\text{clip}\\left( \\left(\\frac{a_k}{2\\lambda}\\right)^{2/3}, L_k, U_k \\right) \\equiv \\text{median}\\left(L_k, U_k, \\left(\\frac{a_k}{2\\lambda}\\right)^{2/3}\\right) $$\nThe function $M(\\lambda) = \\sum_{k=1}^K m_k^*(\\lambda)$ is a monotonically decreasing function of $\\lambda$. The correct value of $\\lambda$ is the one that satisfies the budget constraint $\\sum_{k=1}^K m_k^*(\\lambda) = M$. We can find this unique $\\lambda$ efficiently using a root-finding method like bisection search on the function $g(\\lambda) = \\sum_{k=1}^K m_k^*(\\lambda) - M$. The search domain for $\\lambda$ is bounded, as $\\lambda \\to 0^+$ implies $\\sum m_k^* \\to \\sum U_k$ and $\\lambda \\to \\infty$ implies $\\sum m_k^* \\to \\sum L_k$. Since the problem is specified to be feasible, a solution for $\\lambda$ must exist in $(0, \\infty)$.\n\n**Step 2: Projection to an Optimal Integer Solution**\n\nLet $\\mathbf{m}^* = (m_1^*, \\dots, m_K^*)$ be the optimal continuous solution. For a separable convex integer program of this form, an optimal integer solution $\\mathbf{m}^{\\text{int}}$ can be found by a specific rounding procedure based on marginal gains.\n\nThe algorithm is as follows:\n1. Initialize an integer allocation by taking the floor of the continuous solution: $m_k^{\\text{init}} = \\lfloor m_k^* \\rfloor$. Note that this automatically satisfies $L_k \\le m_k^{\\text{init}} \\le U_k$.\n2. Calculate the remaining budget to be distributed: $\\Delta = M - \\sum_{k=1}^K m_k^{\\text{init}}$. This $\\Delta$ will be a non-negative integer.\n3. Distribute the $\\Delta$ units one by one. In each of the $\\Delta$ steps, we add one unit to the mode $k$ that provides the largest decrease in the objective function. The marginal gain (decrease in error) from incrementing $m_k$ is:\n$$ g(m_k) = \\mathcal{E}(m_k) - \\mathcal{E}(m_k+1) = \\frac{a_k}{\\sqrt{m_k}} - \\frac{a_k}{\\sqrt{m_k+1}} $$\n4. For $i=1, \\dots, \\Delta$, we find the index $k^* = \\arg\\max_{k: m_k  U_k} g(m_k)$ and update $m_{k^*} \\leftarrow m_{k^*} + 1$.\nThis greedy procedure is guaranteed to yield an optimal integer solution for this problem structure.\n\nA preliminary check for boundary cases simplifies the process. If $\\sum_{k=1}^K L_k = M$, the only feasible solution is $m_k = L_k$ for all $k$, which must be the optimum.\n\n**Step 3: Final Computation**\n\nOnce the optimal integer allocation vector $\\mathbf{m}^{\\text{opt}} = (m_1^{\\text{opt}}, \\dots, m_K^{\\text{opt}})$ is determined, the minimum error bound is calculated by substituting these values into the objective function:\n$$ \\mathcal{E}_{\\text{min}} = \\sum_{k=1}^K \\frac{a_k}{\\sqrt{m_k^{\\text{opt}}}} $$\nThe final value is then rounded to six decimal places as required. The overall algorithm is implemented by applying these steps to each test case.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of separable convex integer optimization problems related to\n    resource allocation in multilinear compressed sensing.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (general multi-resolution design)\n        {\n            \"K\": 3, \"mu\": [5, 2, 3], \"r\": [5, 5, 3], \"w\": [1.5, 1.0, 1.2],\n            \"L\": [5, 5, 5], \"U\": [60, 60, 40], \"M\": 90, \"gamma\": 1.0\n        },\n        # Test case 2 (highly coherent mode prioritization)\n        {\n            \"K\": 3, \"mu\": [20, 3, 2], \"r\": [3, 3, 3], \"w\": [2.0, 1.0, 1.0],\n            \"L\": [2, 2, 2], \"U\": [50, 50, 50], \"M\": 30, \"gamma\": 1.0\n        },\n        # Test case 3 (boundary case with lower bounds saturating the budget)\n        {\n            \"K\": 3, \"mu\": [3, 3, 3], \"r\": [2, 2, 2], \"w\": [1.0, 1.0, 1.0],\n            \"L\": [4, 4, 4], \"U\": [10, 10, 10], \"M\": 12, \"gamma\": 1.0\n        },\n        # Test case 4 (upper bounds active in multi-resolution allocation)\n        {\n            \"K\": 4, \"mu\": [8, 8, 8, 1], \"r\": [10, 2, 2, 1], \"w\": [1.0, 1.0, 1.0, 0.5],\n            \"L\": [1, 1, 1, 1], \"U\": [5, 3, 3, 100], \"M\": 20, \"gamma\": 1.0\n        }\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        K = case[\"K\"]\n        mu = np.array(case[\"mu\"], dtype=float)\n        r = np.array(case[\"r\"], dtype=float)\n        w = np.array(case[\"w\"], dtype=float)\n        L = np.array(case[\"L\"], dtype=int)\n        U = np.array(case[\"U\"], dtype=int)\n        M = case[\"M\"]\n        gamma = case[\"gamma\"]\n\n        a = gamma * w * np.sqrt(mu * r)\n\n        if np.sum(L)  M or np.sum(U)  M:\n            # Problem is infeasible, not expected for the given test cases.\n            continue\n        \n        if np.sum(L) == M:\n            m_int = L\n        else:\n            # Step 1: Solve continuous relaxation using bisection search for lambda\n            def get_m_sum(lambda_val, a_vec, L_vec, U_vec):\n                if lambda_val = 0: return np.inf\n                m_unconstrained = (a_vec / (2 * lambda_val))**(2/3)\n                m_constrained = np.clip(m_unconstrained, L_vec, U_vec)\n                return np.sum(m_constrained)\n\n            # Define a search range for lambda\n            lambda_low, lambda_high = 1e-9, 1e9\n            \n            # Bisection search\n            for _ in range(100): # 100 iterations for high precision\n                lambda_mid = (lambda_low + lambda_high) / 2\n                current_M = get_m_sum(lambda_mid, a, L, U)\n                if current_M  M:\n                    lambda_low = lambda_mid\n                else:\n                    lambda_high = lambda_mid\n            \n            final_lambda = (lambda_low + lambda_high) / 2\n            \n            # Continuous solution\n            m_star = np.clip((a / (2 * final_lambda))**(2/3), L, U)\n\n            # Step 2: Project to integer solution\n            m_int = np.floor(m_star).astype(int)\n            \n            # Ensure m_int doesn't fall below L after flooring\n            # In this problem, L_k=floor(m_k*) is guaranteed if L_k are integers\n            # because m_k* = L_k.\n            \n            delta = int(M - np.sum(m_int))\n\n            if delta  0:\n                # Distribute remaining budget using marginal gain\n                def marginal_gain(a_k, m_k):\n                    if m_k = 0: return np.inf\n                    # This check is just for safety, m_k should be = L_k = 1\n                    return a_k / np.sqrt(m_k) - a_k / np.sqrt(m_k + 1)\n                \n                for _ in range(delta):\n                    gains = np.array([marginal_gain(a[k], m_int[k]) if m_int[k]  U[k] else -1 for k in range(K)])\n                    k_star = np.argmax(gains)\n                    if gains[k_star] == -1:\n                        # Should not happen if solution exists\n                        break\n                    m_int[k_star] += 1\n\n        # Step 3: Compute final error bound\n        # Ensure m_int components are positive to avoid division by zero\n        m_int_positive = np.maximum(m_int, 1)\n        error_bound = np.sum(a / np.sqrt(m_int_positive))\n        \n        rounded_error = round(error_bound, 6)\n        \n        result_item = m_int.tolist() + [rounded_error]\n        all_results.append(result_item)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\".replace(\" \", \"\"))\n\nsolve()\n```", "id": "3485962"}]}