{"hands_on_practices": [{"introduction": "To begin our hands-on exploration, we first solidify the definition of the atomic norm in its native, continuous setting. This foundational exercise asks you to compute the atomic norm for a simple signal composed of two sinusoids, a canonical example in super-resolution. By comparing the continuous off-the-grid norm with the limit of its on-grid $\\ell_1$ approximation, you will gain a concrete understanding of how the atomic norm elegantly captures the principle of sparsity over a continuous dictionary [@problem_id:3484477].", "problem": "Consider a line spectral model in the complex vector space $\\mathbb{C}^{n}$ with the atomic set $\\mathcal{A}$ defined by\n$$\n\\mathcal{A} \\triangleq \\left\\{ a(f,\\phi) \\in \\mathbb{C}^{n} : a(f,\\phi)_{m} = \\frac{1}{\\sqrt{n}} \\exp\\!\\big(i\\,(2\\pi f m + \\phi)\\big),\\; m = 0,1,\\dots,n-1,\\; f \\in [0,1),\\; \\phi \\in [0,2\\pi)\\right\\},\n$$\nso that every atom $a(f,\\phi)$ has unit $\\ell_{2}$ norm. The atomic norm associated with $\\mathcal{A}$ is the gauge of the convex hull of $\\mathcal{A}$, equivalently\n$$\n\\|x\\|_{\\mathcal{A}} \\triangleq \\inf\\left\\{\\sum_{k} |c_{k}| : x = \\sum_{k} c_{k}\\, a(f_{k},\\phi_{k}),\\; f_{k} \\in [0,1),\\; \\phi_{k} \\in [0,2\\pi)\\right\\}.\n$$\nLet the signal $x \\in \\mathbb{C}^{n}$ be the sum of two equal-amplitude, phase-aligned sinusoids at distinct frequencies $f_{1}, f_{2} \\in [0,1)$, specifically\n$$\nx = \\alpha\\, a(f_{1},0) + \\alpha\\, a(f_{2},0),\n$$\nwith $\\alpha > 0$ and $f_{1} \\neq f_{2}$. Assume a minimum separation $|f_{1} - f_{2}| \\geq \\frac{1}{n}$ so that standard dual certificates for super-resolution exist. \n\nIn parallel, consider a gridded dictionary $\\mathcal{D}_{\\delta}$ formed by discretizing the frequency interval $[0,1)$ at uniform spacing $\\delta > 0$, i.e.,\n$$\n\\mathcal{D}_{\\delta} \\triangleq \\left\\{ d_{j} = a(j\\delta, 0) : j = 0,1,\\dots,\\left\\lfloor\\frac{1}{\\delta}\\right\\rfloor \\right\\},\n$$\nand for any coefficient vector $c \\in \\mathbb{C}^{M}$ (with $M = \\left\\lfloor\\frac{1}{\\delta}\\right\\rfloor + 1$), define the synthesis map $Dc = \\sum_{j} c_{j}\\, d_{j}$ and the $\\ell_{1}$ norm $\\|c\\|_{1} = \\sum_{j} |c_{j}|$. Consider the exact representation problem\n$$\n\\min_{c \\in \\mathbb{C}^{M}} \\|c\\|_{1} \\quad \\text{subject to} \\quad Dc = x,\n$$\nand denote by $L_{\\delta}(x)$ its optimal value. \n\nCompute the atomic norm $\\|x\\|_{\\mathcal{A}}$ and determine the limit $\\lim_{\\delta \\to 0} L_{\\delta}(x)$ under the stated assumptions. Report the common value as a single closed-form analytic expression. No rounding is required, and no physical units are involved.", "solution": "The problem asks for the computation of two quantities related to the signal $x \\in \\mathbb{C}^{n}$ defined as the sum of two complex sinusoids: the atomic norm $\\|x\\|_{\\mathcal{A}}$ and the limit of the $\\ell_{1}$-norm of its optimal representation on a progressively finer grid, $\\lim_{\\delta \\to 0} L_{\\delta}(x)$. We are asked to find their common value.\n\nFirst, we analyze the atomic norm, $\\|x\\|_{\\mathcal{A}}$. The signal is given by\n$$\nx = \\alpha\\, a(f_{1},0) + \\alpha\\, a(f_{2},0)\n$$\nwhere $\\alpha > 0$, $f_{1} \\neq f_{2}$, and the atoms $a(f,\\phi)$ belong to the atomic set $\\mathcal{A}$ defined as\n$$\n\\mathcal{A} \\triangleq \\left\\{ a(f,\\phi) \\in \\mathbb{C}^{n} : a(f,\\phi)_{m} = \\frac{1}{\\sqrt{n}} \\exp\\!\\big(i\\,(2\\pi f m + \\phi)\\big),\\; m = 0,1,\\dots,n-1,\\; f \\in [0,1),\\; \\phi \\in [0,2\\pi)\\right\\}.\n$$\nThe atomic norm is defined as the gauge of the convex hull of $\\mathcal{A}$:\n$$\n\\|x\\|_{\\mathcal{A}} \\triangleq \\inf\\left\\{\\sum_{k} |c_{k}| : x = \\sum_{k} c_{k}\\, a(f_{k},\\phi_{k}),\\; a(f_{k},\\phi_{k}) \\in \\mathcal{A} \\right\\}.\n$$\nThe given expression for $x$ is a specific representation in terms of atoms from $\\mathcal{A}$, with coefficients $c_{1}=\\alpha$ and $c_{2}=\\alpha$. The sum of the absolute values of these coefficients is $|c_{1}| + |c_{2}| = |\\alpha| + |\\alpha| = 2\\alpha$, since $\\alpha > 0$. By the definition of the infimum, this provides an immediate upper bound on the atomic norm:\n$$\n\\|x\\|_{\\mathcal{A}} \\leq 2\\alpha.\n$$\nTo show that this bound is tight, we appeal to the dual formulation of the atomic norm. The atomic norm of $x$ can also be expressed as:\n$$\n\\|x\\|_{\\mathcal{A}} = \\sup_{\\|q\\|_{\\mathcal{A}}^{*} \\leq 1} |\\langle x, q \\rangle|\n$$\nwhere $\\|q\\|_{\\mathcal{A}}^{*} = \\sup_{a \\in \\mathcal{A}} |\\langle q, a \\rangle|$ is the dual norm.\nA standard result in the theory of super-resolution, which is explicitly invoked by the problem statement, is the existence of a dual certificate under certain conditions. The problem states that a minimum separation $|f_{1} - f_{2}| \\geq \\frac{1}{n}$ is maintained, for which \"standard dual certificates for super-resolution exist.\" For the given signal $x$, whose atomic decomposition has positive coefficients ($\\alpha > 0$), a dual certificate is a vector $q \\in \\mathbb{C}^{n}$ that satisfies:\n1.  $\\langle q, a(f_{1},0) \\rangle = \\mathrm{sign}(\\alpha) = 1$.\n2.  $\\langle q, a(f_{2},0) \\rangle = \\mathrm{sign}(\\alpha) = 1$.\n3.  $\\|q\\|_{\\mathcal{A}}^{*} \\leq 1$.\n\nThe existence of such a $q$ allows us to establish a lower bound on $\\|x\\|_{\\mathcal{A}}$. By choosing this specific $q$ in the supremum definition, we get:\n$$\n\\|x\\|_{\\mathcal{A}} \\geq |\\langle x, q \\rangle| = |\\langle \\alpha\\, a(f_{1},0) + \\alpha\\, a(f_{2},0), q \\rangle|.\n$$\nUsing the linearity of the inner product, this becomes:\n$$\n\\|x\\|_{\\mathcal{A}} \\geq |\\alpha \\langle a(f_{1},0), q \\rangle + \\alpha \\langle a(f_{2},0), q \\rangle| = |\\alpha \\cdot 1 + \\alpha \\cdot 1| = |2\\alpha| = 2\\alpha.\n$$\nCombining the upper bound $\\|x\\|_{\\mathcal{A}} \\leq 2\\alpha$ with the lower bound $\\|x\\|_{\\mathcal{A}} \\geq 2\\alpha$, we conclude that the atomic norm is precisely\n$$\n\\|x\\|_{\\mathcal{A}} = 2\\alpha.\n$$\nThis result confirms that the given representation of $x$ is the sparsest possible in terms of the sum of magnitudes of coefficients over the continuous dictionary $\\mathcal{A}$.\n\nNext, we consider the quantity $L_{\\delta}(x)$, which is the optimal value of the discrete $\\ell_{1}$ minimization problem:\n$$\nL_{\\delta}(x) = \\min_{c \\in \\mathbb{C}^{M}} \\|c\\|_{1} \\quad \\text{subject to} \\quad Dc = x,\n$$\nwhere the columns of the matrix $D$ are atoms from the gridded dictionary $\\mathcal{D}_{\\delta} = \\{ a(j\\delta, 0) : j = 0, \\dots, \\lfloor 1/\\delta \\rfloor \\}$. This problem is a discretized version of the atomic norm problem, often referred to as Basis Pursuit. The frequencies $f_{1}$ and $f_{2}$ of the signal $x$ are, in general, not on the grid defined by the spacing $\\delta$. This is a classic \"off-the-grid\" problem setup.\n\nThe connection between the continuous atomic norm and its discrete approximation is a central topic in modern sparse recovery. For any $\\delta > 0$, the dictionary $\\mathcal{D}_{\\delta}$ is a subset of the atomic set $\\mathcal{A}$ (restricted to zero phase, which is sufficient here as $x$ is composed of zero-phase atoms). Any feasible solution $c$ to the discrete problem provides a representation $x = \\sum_{j} c_{j} d_{j}$ which is also a valid representation in the continuous framework, since each $d_{j} \\in \\mathcal{A}$. Therefore, for any such $c$, we have $\\|x\\|_{\\mathcal{A}} \\leq \\sum_{j} |c_{j}| = \\|c\\|_{1}$. This must also hold for the optimal $c$ that achieves the minimum, so:\n$$\n\\|x\\|_{\\mathcal{A}} \\leq L_{\\delta}(x) \\quad \\text{for all } \\delta > 0.\n$$\nTaking the limit inferior as $\\delta \\to 0$, we get $\\liminf_{\\delta \\to 0} L_{\\delta}(x) \\geq \\|x\\|_{\\mathcal{A}}$.\n\nThe convergence in the other direction, i.e., $\\limsup_{\\delta \\to 0} L_{\\delta}(x) \\leq \\|x\\|_{\\mathcal{A}}$, is a more profound result. It has been established that for signals that are sparse in the continuous dictionary $\\mathcal{A}$, the optimal value of the discretized $\\ell_{1}$ problem converges to the true atomic norm as the grid becomes infinitely dense. This holds because any off-the-grid atom can be represented with increasing accuracy by atoms on a sufficiently fine grid. Specifically, an atom $a(f,0)$ with $f$ between grid points $j\\delta$ and $(j+1)\\delta$ can be written as a linear combination of a few nearby grid atoms, and the $\\ell_{1}$ cost of this local representation converges to $1$ (the atomic norm of a single atom) as $\\delta \\to 0$. By applying this principle to the two atoms comprising $x$, one can construct a sequence of on-grid representations whose $\\ell_{1}$ norm converges to $2\\alpha$. Since $L_{\\delta}(x)$ is the minimal $\\ell_{1}$ norm for a given $\\delta$, it must be less than or equal to the norm of this constructed representation. This leads to the conclusion that:\n$$\n\\lim_{\\delta \\to 0} L_{\\delta}(x) = \\|x\\|_{\\mathcal{A}}.\n$$\n\nSince we have already determined that $\\|x\\|_{\\mathcal{A}} = 2\\alpha$, it follows that the limit of the discrete problem's solution value is also $2\\alpha$.\n$$\n\\lim_{\\delta \\to 0} L_{\\delta}(x) = 2\\alpha.\n$$\nTherefore, the common value sought by the problem is $2\\alpha$.", "answer": "$$\n\\boxed{2\\alpha}\n$$", "id": "3484477"}, {"introduction": "Building on the concept of the atomic norm, we now turn to its dual formulation, which provides the theoretical certificates for recovery guarantees. This computational practice guides you through the construction of dual polynomials using kernel interpolation, a powerful and widely used technique. By implementing and comparing certificates based on the Dirichlet and Fejér kernels, you will develop practical intuition for their distinct properties and understand why the non-negativity of the Fejér kernel often leads to more stable and reliable results in practice [@problem_id:3484478].", "problem": "Consider the one-dimensional torus $\\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$ and a discrete measure $x^\\star = \\sum_{j=1}^{m} a_j \\delta_{t_j}$ supported at locations $t_j \\in \\mathbb{T}$ with real amplitudes $a_j$. In super-resolution via the atomic norm over measures, a dual certificate is a trigonometric polynomial $q(t) = \\sum_{k=-n}^{n} c_k e^{\\mathrm{i} 2 \\pi k t}$ that interpolates the signs $s_j = \\operatorname{sign}(a_j)$ on the support while remaining bounded in magnitude off the support. Kernel interpolation is a constructive approach to design such certificates using translates of a bandlimited kernel centered at the support points. Two canonical choices in Fourier analysis are the Dirichlet kernel and the Fejér kernel.\n\nLet $n \\in \\mathbb{N}$ be the Fourier cutoff. Define the Dirichlet kernel of order $n$ by\n$$\nD_n(t) = \\sum_{k=-n}^{n} e^{\\mathrm{i} 2 \\pi k t} = \\frac{\\sin\\big((2n+1)\\pi t\\big)}{\\sin(\\pi t)}.\n$$\nDefine the Fejér kernel of order $n$ by\n$$\nF_n(t) = \\frac{1}{n} \\sum_{k=0}^{n-1} D_k(t) = \\frac{1}{n} \\left( \\frac{\\sin(n \\pi t)}{\\sin(\\pi t)} \\right)^2.\n$$\nFor stable interpolation, normalize both kernels to have value $1$ at $t=0$:\n$$\nK_D^{(n)}(t) = \\frac{D_n(t)}{2n+1}, \\qquad K_F^{(n)}(t) = \\frac{F_n(t)}{n}.\n$$\nConsider the kernel-based interpolation certificate\n$$\nq_K(t) = \\sum_{j=1}^{m} c_j \\, K^{(n)}(t - t_j),\n$$\nwhere $K^{(n)}$ denotes either $K_D^{(n)}$ or $K_F^{(n)}$, and the coefficients $c_j \\in \\mathbb{R}$ are chosen to enforce interpolation of the signs on the support, namely\n$$\nq_K(t_i) = s_i \\quad \\text{for all } i \\in \\{1,\\dots,m\\}.\n$$\nThis yields a linear system in the unknown coefficients $c = (c_1,\\dots,c_m)$:\n$$\nA c = s, \\quad \\text{where } A_{ij} = K^{(n)}(t_i - t_j) \\text{ and } s = (s_1,\\dots,s_m).\n$$\nFor a given separation parameter $\\Delta \\in (0,1)$ such that the minimum wrap-around distance between any two support points is at least $\\Delta$, we define the off-support maximum of the certificate by sampling on a uniform grid of $\\mathbb{T}$, excluding neighborhoods of radius $\\rho = \\Delta/2$ around each support point:\n$$\nM_K = \\max_{t \\in \\mathbb{T} \\setminus \\bigcup_{j=1}^{m} B_{\\rho}(t_j)} \\left| q_K(t) \\right|, \\quad \\text{where } B_{\\rho}(t_j) = \\{ t \\in \\mathbb{T} : d_{\\mathbb{T}}(t, t_j) < \\rho \\},\n$$\nand $d_{\\mathbb{T}}(u,v) = \\min\\big( |u-v|, 1 - |u-v| \\big)$ is the geodesic distance on $\\mathbb{T}$.\n\nYour task is to numerically compare the performance of Dirichlet-based versus Fejér-based certificates in terms of the off-support maximum $M_K$ for a fixed $n$ and separation $\\Delta$, across four test configurations. For each configuration, construct both certificates $q_{K_D}$ and $q_{K_F}$ by solving the interpolation system, and compute the corresponding off-support maxima $M_{K_D}$ and $M_{K_F}$ on a uniform grid of $N_{\\text{grid}}$ points with $N_{\\text{grid}} = 8192$.\n\nUse the following fixed parameters across all tests:\n- Fourier cutoff $n = 30$,\n- separation $\\Delta = 0.08$,\n- exclusion radius $\\rho = \\Delta/2$,\n- grid size $N_{\\text{grid}} = 8192$.\n\nUse the following test suite of support configurations and sign patterns on $\\mathbb{T}$:\n1. Two spikes with equal signs: $t = [0.25,\\, 0.25+\\Delta]$, $s = [+1,\\,+1]$.\n2. Two spikes with opposite signs: $t = [0.25,\\, 0.25+\\Delta]$, $s = [+1,\\,-1]$.\n3. Three spikes with alternating signs: $t = [0.10,\\, 0.10+\\Delta,\\, 0.10+2\\Delta]$, $s = [+1,\\,-1,\\,+1]$.\n4. Three spikes near wrap-around with alternating signs: $t = [0.95,\\, (0.95+\\Delta) \\bmod 1,\\, (0.95+2\\Delta) \\bmod 1]$, $s = [-1,\\,+1,\\,-1]$.\n\nFor each test case, solve for the interpolation coefficients $c$ using $K_D^{(n)}$ and $K_F^{(n)}$ respectively, compute $M_{K_D}$ and $M_{K_F}$, and report them as floating-point numbers.\n\nYour program should produce a single line of output containing the results as a comma-separated list of pairs, each pair being a two-element list $[M_{K_D},\\, M_{K_F}]$ for the corresponding test case, enclosed in square brackets. For example, the output should have the form\n$$\n\\big[ [M_{K_D}^{(1)}, M_{K_F}^{(1)}], [M_{K_D}^{(2)}, M_{K_F}^{(2)}], [M_{K_D}^{(3)}, M_{K_F}^{(3)}], [M_{K_D}^{(4)}, M_{K_F}^{(4)}] \\big].\n$$\nNo physical units are involved. Angles are implicitly in radians through the dependence on $\\pi$, and all reported values must be plain decimal numbers without percentage signs.", "solution": "The problem statement is assessed to be valid, scientifically grounded, and well-posed. It presents a clear computational task based on established principles in the field of super-resolution and sparse signal recovery. We proceed with the solution.\n\nThe core of the problem is to construct and evaluate dual-certificate polynomials for super-resolution. A dual certificate $q(t)$ is a trigonometric polynomial designed to certify the optimality of a proposed solution in atomic norm minimization. It must satisfy specific interpolation and boundedness conditions. Here, we construct $q(t)$ using kernel interpolation.\n\nThe certificate is of the form:\n$$\nq_K(t) = \\sum_{j=1}^{m} c_j K^{(n)}(t - t_j)\n$$\nwhere $t_j \\in \\mathbb{T} = \\mathbb{R}/\\mathbb{Z}$ for $j \\in \\{1, \\dots, m\\}$ are the locations of $m$ spikes, $K^{(n)}$ is a chosen bandlimited kernel, and $c_j$ are real coefficients. The coefficients are determined by enforcing the interpolation conditions $q_K(t_i) = s_i$ for all $i \\in \\{1, \\dots, m\\}$, where $s_i$ are the prescribed signs at the spike locations. This leads to the $m \\times m$ linear system of equations:\n$$\nA c = s\n$$\nHere, $c = (c_1, \\dots, c_m)^T$ is the vector of unknown coefficients, $s = (s_1, \\dots, s_m)^T$ is the vector of signs, and the matrix $A$ has entries $A_{ij} = K^{(n)}(t_i - t_j)$.\n\nWe compare two kernels, the Dirichlet kernel and the Fejér kernel, both normalized to have a value of $1$ at $t=0$.\nThe normalized Dirichlet kernel of order $n$ is:\n$$\nK_D^{(n)}(t) = \\frac{D_n(t)}{2n+1} = \\frac{1}{2n+1} \\frac{\\sin\\big((2n+1)\\pi t\\big)}{\\sin(\\pi t)}\n$$\nThe normalized Fejér kernel of order $n$ is:\n$$\nK_F^{(n)}(t) = \\frac{F_n(t)}{n} = \\frac{1}{n^2} \\left( \\frac{\\sin(n \\pi t)}{\\sin(\\pi t)} \\right)^2\n$$\nFor numerical evaluation, care must be taken at integer values of $t$, where the denominator $\\sin(\\pi t)$ becomes zero. In these cases, the values are determined by their limits: $K_D^{(n)}(k) = 1$ and $K_F^{(n)}(k) = 1$ for any integer $k$.\n\nThe performance of a certificate is judged by its off-support magnitude. A good certificate should be close to the target signs $s_j$ on the support and small elsewhere. We quantify this by the off-support maximum, $M_K$:\n$$\nM_K = \\max_{t \\in \\mathbb{T} \\setminus \\bigcup_{j=1}^{m} B_{\\rho}(t_j)} \\left| q_K(t) \\right|\n$$\nwhere $B_{\\rho}(t_j)$ is an open ball of radius $\\rho = \\Delta/2$ around each spike $t_j$, with $\\Delta$ being the minimum separation between spikes. The distance $d_{\\mathbb{T}}(u,v) = \\min(|u-v|, 1-|u-v|)$ is the wrap-around distance on the torus $\\mathbb{T}$.\n\nThe numerical procedure for each of the four specified test configurations is as follows:\n1.  Set the global parameters: Fourier cutoff $n=30$, minimum separation $\\Delta=0.08$, exclusion radius $\\rho=0.04$, and grid size $N_{\\text{grid}}=8192$.\n2.  For a given support $\\{t_j\\}_{j=1}^m$ and signs $\\{s_j\\}_{j=1}^m$:\n    a.  For each kernel, $K_D^{(n)}$ and $K_F^{(n)}$:\n        i.  Construct the interpolation matrix $A$ where $A_{ij} = K^{(n)}(t_i - t_j)$.\n        ii. Solve the linear system $Ac=s$ to find the coefficients $c$.\n        iii. Define a uniform grid on the torus: $t_{\\text{grid}, k} = k/N_{\\text{grid}}$ for $k \\in \\{0, \\dots, N_{\\text{grid}}-1\\}$.\n        iv. Synthesize the certificate polynomial $q_K(t)$ on this grid by computing $\\sum_{j=1}^{m} c_j K^{(n)}(t_{\\text{grid}, k} - t_j)$ for each grid point.\n        v.  Determine the set of off-support grid points by excluding all $t_{\\text{grid}, k}$ for which the wrap-around distance to any spike $t_j$ is less than $\\rho$.\n        vi. Compute $M_K$ as the maximum absolute value of $q_K(t)$ over the identified off-support grid points.\n3.  Store the pair of computed maxima $[M_{K_D}, M_{K_F}]$ for each test case.\n4.  Consolidate the results for all four cases into a single list for the final output.\n\nThis procedure is implemented in the provided Python code, utilizing `numpy` for numerical linear algebra and array manipulations.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the off-support maxima for Dirichlet and Fejér kernel-based\n    dual certificates for four different support/sign configurations.\n    \"\"\"\n    # Global parameters\n    N_CUTOFF = 30\n    DELTA = 0.08\n    RHO = DELTA / 2\n    N_GRID = 8192\n\n    # Test suite configurations\n    test_cases = [\n        (np.array([0.25, 0.25 + DELTA]), np.array([1.0, 1.0])),\n        (np.array([0.25, 0.25 + DELTA]), np.array([1.0, -1.0])),\n        (np.array([0.10, 0.10 + DELTA, 0.10 + 2 * DELTA]), np.array([1.0, -1.0, 1.0])),\n        (np.array([0.95, (0.95 + DELTA) % 1.0, (0.95 + 2 * DELTA) % 1.0]), np.array([-1.0, 1.0, -1.0]))\n    ]\n    \n    def dirichlet_kernel_normalized(t, n):\n        \"\"\"\n        Computes the normalized Dirichlet kernel K_D^{(n)}(t) for order n.\n        \"\"\"\n        # Map t to [-0.5, 0.5] for numerical stability around integer values\n        t_mod = np.mod(t + 0.5, 1.0) - 0.5\n        \n        denom = np.sin(np.pi * t_mod)\n        zero_mask = np.isclose(denom, 0.0)\n        \n        # Avoid division by zero warning\n        safe_denom = np.where(zero_mask, 1.0, denom)\n        num = np.sin((2 * n + 1) * np.pi * t_mod)\n        \n        val = num / safe_denom\n        \n        # At integer t, the limit of D_n(t) is 2n+1\n        d_n = np.where(zero_mask, 2 * n + 1, val)\n        \n        return d_n / (2 * n + 1)\n\n    def fejer_kernel_normalized(t, n):\n        \"\"\"\n        Computes the normalized Fejér kernel K_F^{(n)}(t) for order n.\n        \"\"\"\n        # Map t to [-0.5, 0.5] for numerical stability\n        t_mod = np.mod(t + 0.5, 1.0) - 0.5\n\n        denom = np.sin(np.pi * t_mod)\n        zero_mask = np.isclose(denom, 0.0)\n\n        # Avoid division by zero warning\n        safe_denom = np.where(zero_mask, 1.0, denom)\n        num = np.sin(n * np.pi * t_mod)\n\n        term = num / safe_denom\n        val = (1 / n**2) * (term**2)\n\n        # At integer t, the limit of K_F(t) is 1.0\n        k_f = np.where(zero_mask, 1.0, val)\n        \n        return k_f\n\n    def torus_distance(u, v):\n        \"\"\"\n        Computes the wrap-around distance on the torus T = R/Z.\n        \"\"\"\n        diff = np.abs(u - v)\n        return np.minimum(diff, 1.0 - diff)\n\n    all_results = []\n    t_grid = np.linspace(0, 1, N_GRID, endpoint=False)\n\n    for t_locs, s_signs in test_cases:\n        m = len(t_locs)\n        case_results = []\n        \n        for kernel_func in [dirichlet_kernel_normalized, fejer_kernel_normalized]:\n            # 1. Construct the interpolation matrix A\n            diff_matrix = t_locs[:, None] - t_locs[None, :]\n            A = kernel_func(diff_matrix, N_CUTOFF)\n            \n            # 2. Solve the linear system Ac = s for coefficients c\n            c = np.linalg.solve(A, s_signs)\n            \n            # 3. Synthesize the certificate polynomial on the grid\n            t_diff_grid = t_grid[:, None] - t_locs[None, :]\n            kernel_evals = kernel_func(t_diff_grid, N_CUTOFF)\n            q_k = kernel_evals @ c\n            \n            # 4. Identify off-support grid points and compute the maximum\n            # Compute distances from each grid point to each spike location\n            distances = torus_distance(t_grid[:, None], t_locs[None, :])\n            # For each grid point, find the minimum distance to any spike\n            min_distances = np.min(distances, axis=1)\n            # The off-support region is where this minimum distance is >= RHO\n            off_support_mask = min_distances >= RHO\n            \n            max_off_support_mag = np.max(np.abs(q_k[off_support_mask]))\n            case_results.append(max_off_support_mag)\n            \n        all_results.append(case_results)\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3484478"}, {"introduction": "In this capstone practice, we synthesize the primal and dual perspectives into a complete, off-the-grid recovery algorithm. You are tasked with implementing an iterative method that alternates between estimating signal coefficients and refining their continuous frequencies, a common strategy in modern super-resolution solvers. The key insight is to use the dual polynomial, not merely as a passive certificate, but as an active guide whose gradient information can be used to navigate the non-convex landscape of frequency estimation, demonstrating the profound link between duality and algorithmic design [@problem_id:3484465].", "problem": "Consider a line spectral estimation model where a complex discrete-time observation vector $y \\in \\mathbb{C}^n$ is generated by a superposition of $K$ continuous-frequency complex sinusoids corrupted by additive noise. Specifically, for indices $j \\in \\{0,1,\\dots,n-1\\}$, the data follow\n$$\ny_j \\;=\\; \\sum_{k=1}^K c_k \\, e^{i 2\\pi f_k j} \\;+\\; w_j,\n$$\nwhere $f_k \\in [0,1)$ are the unknown normalized frequencies, $c_k \\in \\mathbb{C}$ are the unknown complex amplitudes, and $w_j \\in \\mathbb{C}$ are independent complex Gaussian noise samples with zero mean and variance $\\sigma^2$ per complex dimension. Define the atom $a(f) \\in \\mathbb{C}^n$ by $[a(f)]_j = e^{i 2\\pi f j}$ for all $j \\in \\{0,1,\\dots,n-1\\}$. The atomic norm associated with the continuous dictionary $\\mathcal{A} = \\{ a(f) : f \\in [0,1) \\}$ is the gauge of the convex hull of $\\mathcal{A}$, which coincides with the total variation norm of a complex measure on $[0,1)$ whose Fourier moments reproduce the sinusoidal sum.\n\nA widely studied convex denoising formulation known as atomic norm denoising is\n$$\n\\min_{\\mu} \\;\\; \\|\\mu\\|_{\\mathrm{TV}} \\;+\\; \\frac{\\lambda}{2}\\,\\|y - \\Phi \\mu\\|_2^2,\n$$\nwhere $\\mu$ is a complex measure on $[0,1)$, $\\Phi \\mu = \\int_{0}^{1} a(f)\\, d\\mu(f)$ is the linear measurement operator that maps the measure to $\\mathbb{C}^n$, and $\\lambda > 0$ is a regularization parameter. A well-tested dual formulation (which you may treat as given) is\n$$\n\\max_{q \\in \\mathbb{C}^n} \\;\\; \\operatorname{Re}\\langle y, q \\rangle \\;-\\; \\frac{\\lambda}{2}\\,\\|q\\|_2^2\n\\quad \\text{subject to} \\quad \\sup_{f \\in [0,1)} \\big|\\langle q, a(f) \\rangle\\big| \\le 1,\n$$\nwhere $\\langle \\cdot, \\cdot \\rangle$ denotes the standard complex inner product on $\\mathbb{C}^n$ with linearity in its first argument, and the dual trigonometric polynomial is\n$$\nQ(f) \\;=\\; \\langle q, a(f) \\rangle \\;=\\; \\sum_{j=0}^{n-1} q_j \\, e^{-i 2\\pi f j}.\n$$\nAt optimality, a classical certificate condition is that the magnitude of the dual polynomial saturates on the support frequencies, namely $\\big|Q(f_k)\\big| = 1$ for all $k \\in \\{1,\\dots,K\\}$, while $\\big|Q(f)\\big| < 1$ elsewhere.\n\nYour task is to implement, in a single complete program, a small-scale off-the-grid alternating algorithm inspired by atomic norm principles that alternates between coefficient estimation and frequency refinement guided by the dual polynomial. The algorithm must be derived from the following valid base and facts:\n\n- The linear measurement model $y \\approx \\sum_{k=1}^K c_k a(f_k)$.\n- The convex dual formulation displayed above and the saturation property $\\big|Q(f_k)\\big|=1$ at support frequencies at optimality.\n- The fundamental derivative identity for the dual polynomial\n$$\n\\frac{d}{df} Q(f) \\;=\\; \\sum_{j=0}^{n-1} q_j \\,\\frac{d}{df}\\big(e^{-i 2\\pi f j}\\big) \\;=\\; -\\,i\\,2\\pi \\sum_{j=0}^{n-1} j\\, q_j \\, e^{-i 2\\pi f j}.\n$$\n\nThe program shall implement the following components without accessing any external files or user input:\n\n1. A synthetic data generator that, for specified $n$, $K$, true frequencies $\\{f_k^\\star\\}$, complex amplitudes $\\{c_k^\\star\\}$, and noise standard deviation $\\sigma$, constructs $y \\in \\mathbb{C}^n$ as above.\n\n2. An initialization routine that computes an initial set of $K$ frequency guesses by identifying the $K$ largest peaks of the periodogram on a uniform grid of size $G$ (with $G$ a large integer), where the periodogram at grid frequency $f_g$ is $P(f_g) = \\big|\\langle y, a(f_g) \\rangle\\big|$.\n\n3. An alternating refinement loop for $T$ iterations that performs:\n   - Coefficient update: with the current frequency estimates $\\{f_k\\}$, compute the complex coefficient estimates $c \\in \\mathbb{C}^K$ by solving the Tikhonov-regularized least squares subproblem\n     $$\n     \\min_{c \\in \\mathbb{C}^K} \\;\\; \\frac{1}{2}\\,\\big\\|y - A(f)\\,c\\big\\|_2^2 \\;+\\; \\frac{\\gamma}{2}\\,\\|c\\|_2^2,\n     $$\n     where $A(f) \\in \\mathbb{C}^{n \\times K}$ has columns $a(f_k)$ and $\\gamma > 0$.\n   - Dual-guided frequency refinement: form the residual $r = y - A(f)\\,c$ and define the dual iterate $q = r / \\lambda$. Let $Q(f) = \\langle q, a(f) \\rangle$ and define the dual-mismatch loss\n     $$\n     L(f_1,\\dots,f_K) \\;=\\; \\frac{1}{2}\\,\\sum_{k=1}^K \\big( |Q(f_k)| - 1 \\big)^2.\n     $$\n     Compute its gradient with respect to each $f_k$ using the chain rule and the displayed derivative of $Q(f)$, and perform a gradient descent step\n     $$\n     f_k \\;\\leftarrow\\; \\mathrm{mod}_1\\!\\Big(f_k \\;-\\; \\eta \\,\\frac{\\partial L}{\\partial f_k}\\Big),\n     $$\n     where $\\eta > 0$ is a step size and $\\mathrm{mod}_1$ denotes reduction modulo $1$ to keep $f_k \\in [0,1)$.\n\n4. A final evaluation routine that, after $T$ iterations, computes:\n   - The average absolute frequency error between the refined $\\{f_k\\}$ and the true $\\{f_k^\\star\\}$ under optimal matching, measured on the circle with wrap-around distance $d(f,g) = \\min\\{|f-g|, 1-|f-g|\\}$.\n   - The approximate dual feasibility by evaluating $\\sup_{f \\in \\mathcal{G}} |Q(f)|$ on a dense uniform grid $\\mathcal{G}$ of size $G_{\\mathrm{dual}}$.\n\nYour program shall implement and run the algorithm on the following test suite, which uses zero-based time indices and specifies all parameters precisely. All angles are implicitly in radians because frequencies are normalized to the unit interval. No physical units are involved. For each case, set the random seed to $12345$ before any random amplitude phase generation to ensure reproducibility.\n\n- Test Case A (happy path): $n = 64$, $K = 3$, true frequencies $\\{f_k^\\star\\} = \\{0.12,\\,0.31,\\,0.56\\}$, amplitudes $c^\\star = [1.0\\,e^{i \\phi_1},\\;0.8\\,e^{i \\phi_2},\\;1.2\\,e^{i \\phi_3}]$ with $\\phi_1,\\phi_2,\\phi_3$ drawn independently and uniformly from $[0,2\\pi)$, noise standard deviation $\\sigma = 10^{-3}$. Use grid size $G = 4096$ for initialization and $G_{\\mathrm{dual}} = 8192$ for dual feasibility. Set $\\lambda = 2\\,\\sigma\\,\\sqrt{2 \\log n}$, Tikhonov parameter $\\gamma = 10^{-3}$, step size $\\eta = 10^{-2}$, and iterations $T = 200$.\n\n- Test Case B (boundary separation): $n = 64$, $K = 2$, true frequencies $\\{f_k^\\star\\} = \\{0.25,\\;0.25 + 1.5/n\\}$, amplitudes $c^\\star = [1.0\\,e^{i \\phi_1},\\;1.0\\,e^{i \\phi_2}]$ with independent phases as above, noise $\\sigma = 3 \\times 10^{-4}$, and the same $G$, $G_{\\mathrm{dual}}$, $\\lambda$, $\\gamma$, $\\eta$, and $T$ set according to this case’s $n$ and $\\sigma$.\n\n- Test Case C (dynamic range): $n = 64$, $K = 3$, true frequencies $\\{f_k^\\star\\} = \\{0.15,\\,0.41,\\,0.73\\}$, amplitudes $c^\\star = [1.0\\,e^{i \\phi_1},\\;0.2\\,e^{i \\phi_2},\\;2.0\\,e^{i \\phi_3}]$ with independent phases as above, noise $\\sigma = 10^{-3}$, and the same $G$, $G_{\\mathrm{dual}}$, $\\lambda$, $\\gamma$, $\\eta$, and $T$ set according to this case’s $n$ and $\\sigma$.\n\nDefine success for a test case as the conjunction of two conditions: the optimally matched average absolute frequency error is strictly less than the threshold $\\tau_f = 0.25/n$, and the approximate dual feasibility satisfies $\\sup_{f \\in \\mathcal{G}} |Q(f)| \\le 1.1$ on the evaluation grid. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for the three test cases in the order A, B, C, where each entry is the boolean success value for that case (for example, $[{\\tt True},{\\tt False},{\\tt True}]$).", "solution": "The user-provided problem is assessed as **valid**. It is scientifically grounded in the principles of signal processing and convex optimization, specifically concerning super-resolution line spectral estimation via atomic norms. The problem is well-posed, providing a complete and consistent set of parameters, definitions, and algorithmic steps to implement a numerical simulation. The language is objective and the success criteria are quantitative and unambiguous.\n\nThe task is to implement an off-the-grid alternating algorithm for super-resolution frequency estimation from noisy data and evaluate its performance on three specific test cases. The algorithm alternates between estimating the complex amplitudes of sinusoidal components and refining their frequencies.\n\nThe core of the problem lies in the model and the algorithm design:\nA complex discrete-time observation vector $y \\in \\mathbb{C}^n$ is modeled as a sum of $K$ complex sinusoids corrupted by noise:\n$$y_j \\;=\\; \\sum_{k=1}^K c_k^\\star \\, e^{i 2\\pi f_k^\\star j} \\;+\\; w_j, \\quad j \\in \\{0, 1, \\dots, n-1\\}$$\nwhere $\\{f_k^\\star\\}$ are the true frequencies, $\\{c_k^\\star\\}$ are the true complex amplitudes, and $w_j$ are complex Gaussian noise samples. Using the definition of an atom $a(f) \\in \\mathbb{C}^n$ as $[a(f)]_j = e^{i 2\\pi f j}$, the model can be written in vector form as $y \\approx \\sum_{k=1}^K c_k a(f_k)$.\n\nThe algorithm proceeds in four main stages:\n\n**1. Synthetic Data Generation**\nFor each test case, we first synthesize the observation vector $y$.\n- Given the number of samples $n$, number of sinusoids $K$, true frequencies $\\{f_k^\\star\\}_{k=1}^K$, and true amplitude magnitudes $\\{|c_k^\\star|\\}_{k=1}^K$, we generate the complex amplitudes $c_k^\\star = |c_k^\\star| e^{i\\phi_k}$ by drawing phases $\\phi_k$ independently and uniformly from $[0, 2\\pi)$. The random number generator is seeded with $12345$ for reproducibility.\n- The clean signal vector $x \\in \\mathbb{C}^n$ is formed as $x = \\sum_{k=1}^K c_k^\\star a(f_k^\\star)$.\n- Additive complex Gaussian noise $w \\in \\mathbb{C}^n$ is generated. Each component $w_j = u_j + i v_j$, where $u_j$ and $v_j$ are independent real Gaussian random variables with mean $0$ and variance $\\sigma^2$. The final observation vector is $y = x + w$.\n\n**2. Initialization via Periodogram**\nAn initial estimate of the frequencies is obtained by finding the peaks of the signal's periodogram, which measures the signal's power at different frequencies. The periodogram on a fine grid of frequencies $\\mathcal{G}_{\\text{init}} = \\{g/G : g=0, \\dots, G-1\\}$ is given by $P(f_g) = |\\langle y, a(f_g) \\rangle|$. The initial frequency estimates $\\{f_k^{(0)}\\}_{k=1}^K$ are the frequencies corresponding to the $K$ largest values of $P(f_g)$ on this grid.\n\n**3. Iterative Refinement**\nThe algorithm then enters an iterative loop for $T$ iterations to refine the initial estimates. Each iteration consists of two steps:\n\n**a. Coefficient Update:**\nGiven the current frequency estimates $\\{f_k^{(t)}\\}$, we estimate the complex amplitudes $\\{c_k^{(t)}\\}$ by solving a Tikhonov-regularized least-squares problem. Let $A(f^{(t)})$ be the $n \\times K$ matrix whose columns are the atoms $a(f_k^{(t)})$. The problem is:\n$$ \\min_{c \\in \\mathbb{C}^K} \\;\\; \\frac{1}{2}\\,\\big\\|y - A(f^{(t)})\\,c\\big\\|_2^2 \\;+\\; \\frac{\\gamma}{2}\\,\\|c\\|_2^2 $$\nThe solution is given by the normal equations:\n$$ c^{(t)} = \\left( A(f^{(t)})^H A(f^{(t)}) + \\gamma I \\right)^{-1} A(f^{(t)})^H y $$\nwhere $A^H$ is the conjugate transpose of $A$ and $I$ is the identity matrix.\n\n**b. Dual-Guided Frequency Refinement:**\nThis step leverages the dual formulation of the atomic norm denoising problem. The update is guided by a loss function that penalizes deviations from the optimality condition $|Q(f_k)|=1$ for the dual polynomial $Q(f)$.\nFirst, we form the residual $r^{(t)} = y - A(f^{(t)})c^{(t)}$ and the dual iterate $q^{(t)} = r^{(t)} / \\lambda$, where $\\lambda = 2\\sigma\\sqrt{2\\log n}$ is the regularization parameter. The dual polynomial is $Q(f) = \\langle q^{(t)}, a(f) \\rangle = \\sum_{j=0}^{n-1} q_j^{(t)} e^{-i 2\\pi f j}$.\nThe loss function is defined as:\n$$ L(f_1, \\dots, f_K) \\;=\\; \\frac{1}{2}\\,\\sum_{k=1}^K \\big( |Q(f_k)| - 1 \\big)^2 $$\nWe perform a gradient descent step on this loss. The partial derivative of $L$ with respect to $f_k$ is:\n$$ \\frac{\\partial L}{\\partial f_k} = \\big( |Q(f_k)| - 1 \\big) \\frac{\\partial |Q(f_k)|}{\\partial f_k} $$\nUsing the identity $\\frac{\\partial|z|}{\\partial x} = \\frac{\\operatorname{Re}(\\frac{\\partial z}{\\partial x} \\bar{z})}{|z|}$, we find:\n$$ \\frac{\\partial |Q(f)|}{\\partial f} = \\frac{\\operatorname{Re}\\left(\\frac{dQ(f)}{df} \\overline{Q(f)}\\right)}{|Q(f)|} $$\nThe derivative of the dual polynomial is given as $\\frac{dQ(f)}{df} = -i 2\\pi \\sum_{j=0}^{n-1} j q_j e^{-i 2\\pi f j}$.\nBy computing these quantities, the gradient $\\frac{\\partial L}{\\partial f_k}$ is evaluated at the current estimate $f_k^{(t)}$. The frequencies are then updated:\n$$ f_k^{(t+1)} \\leftarrow \\mathrm{mod}_1\\!\\left(f_k^{(t)} - \\eta \\frac{\\partial L}{\\partial f_k}\\right) $$\nwhere $\\eta$ is the step size and $\\mathrm{mod}_1$ ensures the frequencies remain in the interval $[0,1)$.\n\n**4. Final Evaluation**\nAfter $T$ iterations, the algorithm's performance is evaluated based on two criteria:\n\n**a. Frequency Estimation Error:** The average absolute frequency error is computed between the final estimated frequencies $\\{f_k\\}$ and the true frequencies $\\{f_k^\\star\\}$. To account for permutation ambiguity, we find an optimal matching that minimizes the total error. The distance between two frequencies $f$ and $g$ is the wrap-around distance on the circle, $d(f,g) = \\min\\{|f-g|, 1-|f-g|\\}$. The average error of the optimal matching must be less than a threshold $\\tau_f = 0.25/n$.\n\n**b. Dual Feasibility:** The dual feasibility condition requires $\\sup_{f \\in [0,1)} |Q(f)| \\le 1$. We approximate this by computing the final dual vector $q$ and evaluating $\\max_{f \\in \\mathcal{G}_{\\text{dual}}} |Q(f)|$ on a very dense grid $\\mathcal{G}_{\\text{dual}}$. This value must be less than or equal to $1.1$.\n\nA test case is deemed successful if both conditions are met. The final program outputs a boolean list indicating success for each of the three specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef solve():\n    \"\"\"\n    Implements and evaluates an off-the-grid alternating algorithm for\n    line spectral estimation based on atomic norm principles.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"n\": 64, \"K\": 3, \"f_star\": np.array([0.12, 0.31, 0.56]),\n            \"c_mag\": np.array([1.0, 0.8, 1.2]), \"sigma\": 1e-3,\n            \"G\": 4096, \"G_dual\": 8192,\n            \"gamma\": 1e-3, \"eta\": 1e-2, \"T\": 200\n        },\n        {\n            \"name\": \"Case B\",\n            \"n\": 64, \"K\": 2, \"f_star\": np.array([0.25, 0.25 + 1.5/64]),\n            \"c_mag\": np.array([1.0, 1.0]), \"sigma\": 3e-4,\n            \"G\": 4096, \"G_dual\": 8192,\n            \"gamma\": 1e-3, \"eta\": 1e-2, \"T\": 200\n        },\n        {\n            \"name\": \"Case C\",\n            \"n\": 64, \"K\": 3, \"f_star\": np.array([0.15, 0.41, 0.73]),\n            \"c_mag\": np.array([1.0, 0.2, 2.0]), \"sigma\": 1e-3,\n            \"G\": 4096, \"G_dual\": 8192,\n            \"gamma\": 1e-3, \"eta\": 1e-2, \"T\": 200\n        }\n    ]\n\n    results = []\n\n    def build_atom_matrix(n, freqs):\n        \"\"\"Constructs the matrix A(f) with columns a(f_k) = exp(i*2*pi*f_k*j).\"\"\"\n        time_indices = np.arange(n)\n        return np.exp(1j * 2 * np.pi * time_indices[:, np.newaxis] * freqs[np.newaxis, :])\n\n    def wrap_around_dist_matrix(f1, f2):\n        \"\"\"Computes the matrix of wrap-around distances between two sets of frequencies.\"\"\"\n        d = np.abs(f1[:, np.newaxis] - f2[np.newaxis, :])\n        return np.minimum(d, 1.0 - d)\n\n    for case in test_cases:\n        # Set seed for reproducibility for each case\n        np.random.seed(12345)\n\n        # Unpack parameters\n        n, K, f_star = case[\"n\"], case[\"K\"], case[\"f_star\"]\n        c_mag, sigma = case[\"c_mag\"], case[\"sigma\"]\n        G, G_dual = case[\"G\"], case[\"G_dual\"]\n        gamma, eta, T = case[\"gamma\"], case[\"eta\"], case[\"T\"]\n        \n        lambda_val = 2 * sigma * np.sqrt(2 * np.log(n))\n        tau_f = 0.25 / n\n        time_indices = np.arange(n)\n\n        # 1. Synthetic Data Generation\n        phases = np.random.uniform(0, 2 * np.pi, K)\n        c_star = c_mag * np.exp(1j * phases)\n        A_star = build_atom_matrix(n, f_star)\n        x_true = A_star @ c_star\n        # Noise variance is sigma^2 per real/imaginary dimension\n        noise = sigma * (np.random.randn(n) + 1j * np.random.randn(n))\n        y = x_true + noise\n\n        # 2. Initialization\n        f_grid_init = np.linspace(0, 1, G, endpoint=False)\n        A_grid_init = build_atom_matrix(n, f_grid_init)\n        # Periodogram P(f_g) = |<y, a(f_g)>|. Using <u,v> = v^H u.\n        periodogram = np.abs(A_grid_init.T.conj() @ y)\n        peak_indices = np.argsort(periodogram)[-K:]\n        f_est = f_grid_init[peak_indices]\n        f_est.sort()\n\n        # 3. Alternating Refinement Loop\n        for _ in range(T):\n            # a. Coefficient Update\n            A_est = build_atom_matrix(n, f_est)\n            H = A_est.T.conj() @ A_est # A^H A\n            c_est = np.linalg.solve(H + gamma * np.eye(K), A_est.T.conj() @ y)\n            \n            # b. Dual-guided Frequency Refinement\n            r = y - A_est @ c_est\n            q = r / lambda_val\n            \n            grads = np.zeros(K)\n            for k in range(K):\n                fk = f_est[k]\n                exp_vec = np.exp(-1j * 2 * np.pi * fk * time_indices)\n\n                # Q(f_k) = sum_j q_j * exp(-i*2*pi*f_k*j)\n                Q_fk = np.sum(q * exp_vec)\n                \n                # Q'(f_k) = sum_j q_j * (-i*2*pi*j) * exp(-i*2*pi*f_k*j)\n                Q_prime_fk = np.sum(q * (-1j * 2 * np.pi * time_indices) * exp_vec)\n\n                abs_Q_fk = np.abs(Q_fk)\n                if abs_Q_fk > 1e-12:\n                    grad = (abs_Q_fk - 1) * np.real(Q_prime_fk * np.conj(Q_fk)) / abs_Q_fk\n                    grads[k] = grad\n\n            f_est -= eta * grads\n            f_est %= 1.0\n\n        # 4. Final Evaluation\n        f_est.sort()\n\n        # a. Average absolute frequency error\n        cost_matrix = wrap_around_dist_matrix(f_est, f_star)\n        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n        avg_freq_error = cost_matrix[row_ind, col_ind].mean()\n\n        # b. Approximate dual feasibility\n        A_est = build_atom_matrix(n, f_est)\n        H = A_est.T.conj() @ A_est\n        c_est = np.linalg.solve(H + gamma * np.eye(K), A_est.T.conj() @ y)\n        r = y - A_est @ c_est\n        q = r / lambda_val\n        \n        f_grid_dual = np.linspace(0, 1, G_dual, endpoint=False)\n        A_grid_dual = build_atom_matrix(n, f_grid_dual)\n        \n        # Q(f) = sum_j q_j * exp(-i*2*pi*f*j) is <q, a(f)>.\n        # This is a(f)^H q in standard inner product.\n        Q_on_grid = A_grid_dual.T.conj() @ q\n        max_dual_poly = np.max(np.abs(Q_on_grid))\n\n        # Check success conditions\n        success = (avg_freq_error  tau_f) and (max_dual_poly = 1.1)\n        results.append(success)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3484465"}]}