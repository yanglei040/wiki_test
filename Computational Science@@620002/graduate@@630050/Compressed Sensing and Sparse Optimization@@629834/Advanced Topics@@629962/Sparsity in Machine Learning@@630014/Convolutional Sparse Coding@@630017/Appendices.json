{"hands_on_practices": [{"introduction": "The sparse coding stage of Convolutional Sparse Coding (CSC) involves solving a convex optimization problem, for which proximal gradient methods are the standard tool. A critical parameter for guaranteeing the convergence of these algorithms is the step size, which is inversely related to the Lipschitz constant of the data-fidelity term's gradient. This exercise will allow you to derive this constant by leveraging the properties of the Fourier transform, providing essential insight into the stability and implementation of algorithms like ISTA and FISTA. [@problem_id:3440981]", "problem": "Let a one-dimensional periodic signal $x \\in \\mathbb{R}^{N}$ be modeled by convolutional sparse coding (CSC), where the data term is $f(\\{z_{k}\\}) = \\frac{1}{2} \\left\\| x - \\sum_{k=1}^{K} d_{k} * z_{k} \\right\\|_{2}^{2}$, the convolution $*$ is circular, and the filters $\\{d_{k}\\}_{k=1}^{K}$ and codes $\\{z_{k}\\}_{k=1}^{K}$ are real-valued sequences of length $N$. Define the linear operator $\\mathcal{D}$ that maps the stacked code vector $z = (z_{1},\\dots,z_{K})$ to the synthesized signal $\\sum_{k=1}^{K} d_{k} * z_{k}$. The gradient of $f$ with respect to the stacked codes is $\\nabla f(z) = \\mathcal{D}^{\\top}(\\mathcal{D}z - x)$. Consider the Discrete Fourier Transform (DFT) with unitary normalization (so Parseval's identity holds as $\\sum_{n=0}^{N-1} |u[n]|^{2} = \\sum_{i=0}^{N-1} |U[\\omega_{i}]|^{2}$ for every $u \\in \\mathbb{R}^{N}$, where $U$ is the DFT of $u$ and $\\{\\omega_{i}\\}_{i=0}^{N-1}$ are the frequency bins). Let $D_{k}[\\omega_{i}]$ denote the DFT of $d_{k}$ at frequency $\\omega_{i}$.\n\nStarting from the definitions of Lipschitz continuity of a gradient mapping and the unitary properties of the DFT for circular convolution, derive a valid global Lipschitz constant $L$ of $\\nabla f$ with respect to the Euclidean norm on the stacked codes, expressed in terms of the Fourier magnitudes $\\{|D_{k}[\\omega_{i}]|\\}_{k,i}$. Then derive a simple, computable upper bound on $L$ that depends only on the filter energies $\\sum_{k=1}^{K} \\|d_{k}\\|_{2}^{2}$. Use the constant $L$ to set a fixed step size $\\alpha$ for the Iterative Shrinkage-Thresholding Algorithm (ISTA) and the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA), in accordance with standard convergence guarantees for smooth plus nonsmooth convex objectives. Report your final answer as a row matrix $\\begin{pmatrix} L & \\alpha \\end{pmatrix}$, using the exact Fourier-magnitude expression for $L$ and the canonical choice $\\alpha = 1/L$. No numerical approximation is required, and no units are involved.", "solution": "We consider the smooth convex function $f(z) = \\frac{1}{2} \\|\\mathcal{D}z - x\\|_{2}^{2}$ defined on the stacked code vector $z = (z_{1},\\dots,z_{K}) \\in \\mathbb{R}^{KN}$. The gradient mapping is\n$$\n\\nabla f(z) = \\mathcal{D}^{\\top}(\\mathcal{D}z - x).\n$$\nA global Lipschitz constant $L$ of $\\nabla f$ with respect to the Euclidean norm is any constant $L \\ge 0$ such that\n$$\n\\|\\nabla f(z) - \\nabla f(z')\\|_{2} \\le L \\|z - z'\\|_{2} \\quad \\text{for all } z, z' \\in \\mathbb{R}^{KN}.\n$$\nBy linearity,\n$$\n\\nabla f(z) - \\nabla f(z') = \\mathcal{D}^{\\top}\\mathcal{D}(z - z'),\n$$\nso the tightest global Lipschitz constant equals the spectral norm of the linear operator $\\mathcal{D}^{\\top}\\mathcal{D}$ with respect to the Euclidean norm:\n$$\nL = \\|\\mathcal{D}^{\\top}\\mathcal{D}\\|_{2}.\n$$\nBecause $\\mathcal{D}^{\\top}\\mathcal{D}$ is symmetric and positive semidefinite, $\\|\\mathcal{D}^{\\top}\\mathcal{D}\\|_{2} = \\lambda_{\\max}(\\mathcal{D}^{\\top}\\mathcal{D}) = \\|\\mathcal{D}\\|_{2}^{2}$, where $\\|\\mathcal{D}\\|_{2}$ is the operator norm (largest singular value) of $\\mathcal{D}$.\n\nWe now compute $\\|\\mathcal{D}\\|_{2}$ using the unitary Discrete Fourier Transform (DFT) and the structure of circular convolution. Under circular boundary conditions, each convolution by $d_{k}$ is represented by a circulant matrix $C_{d_{k}}$, and the synthesis operator is\n$$\n\\mathcal{D} = \\begin{bmatrix} C_{d_{1}} & C_{d_{2}} & \\cdots & C_{d_{K}} \\end{bmatrix},\n$$\nmapping $z = (z_{1},\\dots,z_{K})$ to $\\sum_{k} C_{d_{k}} z_{k}$. The DFT diagonalizes each circulant matrix: there exists a unitary DFT matrix $F$ such that $C_{d_{k}} = F^{\\ast} \\Lambda_{k} F$, where $\\Lambda_{k}$ is diagonal with entries $\\{D_{k}[\\omega_{i}]\\}_{i=0}^{N-1}$, the DFT of $d_{k}$ evaluated at the frequency bins. In the frequency domain, the action of $\\mathcal{D}$ on $z$ decouples across frequencies:\n$$\n\\widehat{y}[\\omega_{i}] = \\sum_{k=1}^{K} D_{k}[\\omega_{i}] \\, \\widehat{z}_{k}[\\omega_{i}], \\quad i = 0,\\dots,N-1,\n$$\nwhere $\\widehat{y} = F(\\mathcal{D}z)$ and $\\widehat{z}_{k} = F z_{k}$. For each fixed frequency $\\omega_{i}$, this is a linear map from the $K$-dimensional vector $(\\widehat{z}_{1}[\\omega_{i}],\\dots,\\widehat{z}_{K}[\\omega_{i}])$ to the scalar $\\widehat{y}[\\omega_{i}]$, with operator norm equal to the Euclidean norm of the coefficient vector $\\big(D_{1}[\\omega_{i}],\\dots,D_{K}[\\omega_{i}]\\big)$. Therefore, the singular values of $\\mathcal{D}$ are given by these per-frequency norms, and the largest singular value is\n$$\n\\|\\mathcal{D}\\|_{2} = \\max_{i \\in \\{0,\\dots,N-1\\}} \\left( \\sum_{k=1}^{K} |D_{k}[\\omega_{i}]|^{2} \\right)^{1/2}.\n$$\nConsequently,\n$$\nL = \\|\\mathcal{D}\\|_{2}^{2} = \\max_{i \\in \\{0,\\dots,N-1\\}} \\sum_{k=1}^{K} |D_{k}[\\omega_{i}]|^{2}.\n$$\n\nWe now derive a simple upper bound on $L$ that depends only on the filter energies $\\sum_{k=1}^{K} \\|d_{k}\\|_{2}^{2}$. Using the unitary normalization of the DFT and Parseval's identity, we have for each $k$:\n$$\n\\sum_{i=0}^{N-1} |D_{k}[\\omega_{i}]|^{2} = \\|d_{k}\\|_{2}^{2}.\n$$\nHence,\n$$\n\\max_{i} \\sum_{k=1}^{K} |D_{k}[\\omega_{i}]|^{2} \\le \\sum_{i=0}^{N-1} \\sum_{k=1}^{K} |D_{k}[\\omega_{i}]|^{2} = \\sum_{k=1}^{K} \\|d_{k}\\|_{2}^{2}.\n$$\nThis shows that a valid global Lipschitz constant is given exactly by\n$$\nL = \\max_{i} \\sum_{k=1}^{K} |D_{k}[\\omega_{i}]|^{2},\n$$\nand it is upper bounded by $\\sum_{k=1}^{K} \\|d_{k}\\|_{2}^{2}$, which can be used when only time-domain energies are available.\n\nFor the Iterative Shrinkage-Thresholding Algorithm (ISTA) and the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA), standard convergence guarantees for composite convex objectives with smooth part $f$ require a step size $\\alpha$ satisfying $0 < \\alpha \\le 1/L$. A canonical choice is $\\alpha = 1/L$. Using the exact expression for $L$, this yields\n$$\n\\alpha = \\frac{1}{\\max_{i} \\sum_{k=1}^{K} |D_{k}[\\omega_{i}]|^{2}}.\n$$\n\nPer the reporting requirement, we return the row matrix $\\begin{pmatrix} L & \\alpha \\end{pmatrix}$ built from the exact Fourier-magnitude expression for $L$ and the corresponding canonical step size $\\alpha = 1/L$.", "answer": "$$\\boxed{\\begin{pmatrix}\n\\displaystyle \\max_{i} \\sum_{k=1}^{K} |D_{k}[\\omega_{i}]|^{2} & \\displaystyle \\frac{1}{\\max_{i} \\sum_{k=1}^{K} |D_{k}[\\omega_{i}]|^{2}}\n\\end{pmatrix}}$$", "id": "3440981"}, {"introduction": "Convolutional dictionary learning algorithms typically alternate between updating the sparse codes and the dictionary filters. This exercise focuses on the dictionary update step, where the goal is to find the optimal filters for a given set of sparse codes. You will see how this otherwise complex problem elegantly decouples in the Fourier domain, allowing for a closed-form solution for each filter, a cornerstone technique in modern CSC methods. [@problem_id:3440972]", "problem": "Consider one-dimensional convolutional sparse coding with circular boundary conditions on signals of length $N \\in \\mathbb{N}$. Let $x \\in \\mathbb{R}^{N}$ be a fixed signal, and let $\\{z_{k}\\}_{k=1}^{K} \\subset \\mathbb{R}^{N}$ be fixed coefficient maps. We seek filters $\\{d_{k}\\}_{k=1}^{K} \\subset \\mathbb{R}^{N}$ that minimize the penalized least-squares objective in the spatial domain\n$$\n\\min_{\\{d_{k}\\}} \\;\\; \\frac{1}{2}\\left\\|x - \\sum_{k=1}^{K} d_{k} * z_{k}\\right\\|_{2}^{2} \\;+\\; \\frac{\\alpha}{2} \\sum_{k=1}^{K} \\|d_{k}\\|_{2}^{2}\n\\quad \\text{subject to} \\quad \\|d_{k}\\|_{2} = 1 \\;\\; \\text{for all } k \\in \\{1,\\dots,K\\},\n$$\nwhere $*$ denotes circular convolution and $\\alpha>0$ is given. Let $\\mathcal{F}$ denote the unitary $N$-point Discrete Fourier Transform (DFT) defined by\n$$\n\\hat{s}(\\omega) = \\frac{1}{\\sqrt{N}} \\sum_{n=0}^{N-1} s[n] \\exp\\!\\left(-\\mathrm{i}\\,\\frac{2\\pi \\omega n}{N}\\right),\n\\quad\ns[n] = \\frac{1}{\\sqrt{N}} \\sum_{\\omega=0}^{N-1} \\hat{s}(\\omega) \\exp\\!\\left(\\mathrm{i}\\,\\frac{2\\pi \\omega n}{N}\\right),\n$$\nso that the Parseval identity $\\|s\\|_{2}^{2} = \\sum_{\\omega=0}^{N-1} |\\hat{s}(\\omega)|^{2}$ holds exactly and circular convolution becomes pointwise multiplication in the Fourier domain.\n\nUsing only the stated transform properties, the fact that circular convolution diagonalizes under the unitary Discrete Fourier Transform (DFT), and first principles of least-squares with an $\\ell_{2}$ Tikhonov penalty, derive the closed-form update of the filters in the Fourier domain. Specifically, by transforming the problem to the Fourier domain and solving the decoupled per-frequency penalized least-squares subproblems, then imposing the spatial unit-norm constraints via an exact normalization step valid for a unitary DFT, obtain a single analytic expression for the updated Fourier-domain filters $\\{\\hat{d}_{k}^{\\mathrm{new}}(\\omega)\\}$ in terms of $\\hat{x}(\\omega)$, $\\{\\hat{z}_{k}(\\omega)\\}$, and $\\alpha$.\n\nExpress your final answer as a single closed-form expression for $\\hat{d}_{k}^{\\mathrm{new}}(\\omega)$ that depends only on $\\hat{x}$, $\\{\\hat{z}_{k}\\}$, and $\\alpha$. No numerical evaluation is required, and no units are involved.", "solution": "The problem asks for the closed-form update rule for a set of filters $\\{d_{k}\\}_{k=1}^{K}$ that minimize a penalized least-squares objective, subject to a unit-norm constraint on each filter. The problem statement combines a Tikhonov regularization term $\\frac{\\alpha}{2} \\sum_{k=1}^{K} \\|d_{k}\\|_{2}^{2}$ with a hard constraint $\\|d_{k}\\|_{2} = 1$. When the hard constraint is active, the regularization term becomes a constant $\\frac{\\alpha K}{2}$ and does not influence the optimization. However, the prompt specifies a procedure: solve the penalized least-squares problem and then impose the unit-norm constraint via normalization. This implies a two-step process: first, find the filters $\\{\\tilde{d}_{k}\\}$ that minimize the unconstrained penalized objective, and second, normalize these filters to obtain the final result.\n\nLet the unconstrained filters be denoted by $\\{\\tilde{d}_{k}\\}$. The objective function to minimize is:\n$$ L(\\{\\tilde{d}_{k}\\}) = \\frac{1}{2}\\left\\|x - \\sum_{k=1}^{K} \\tilde{d}_{k} * z_{k}\\right\\|_{2}^{2} + \\frac{\\alpha}{2} \\sum_{k=1}^{K} \\|\\tilde{d}_{k}\\|_{2}^{2} $$\nWe will solve this optimization problem in the Fourier domain. Let $\\hat{s} = \\mathcal{F}(s)$ denote the unitary Discrete Fourier Transform of a signal $s$. The provided DFT is unitary, so Parseval's identity holds: $\\|s\\|_{2}^{2} = \\|\\hat{s}\\|_{2}^{2} = \\sum_{\\omega=0}^{N-1} |\\hat{s}(\\omega)|^{2}$. The convolution theorem for this unitary DFT is $\\mathcal{F}(a*b)(\\omega) = \\sqrt{N}\\hat{a}(\\omega)\\hat{b}(\\omega)$.\n\nApplying the DFT to the objective function, we transform each term. The squared $\\ell_2$-norm of the residual becomes:\n$$ \\left\\|x - \\sum_{k=1}^{K} \\tilde{d}_{k} * z_{k}\\right\\|_{2}^{2} = \\left\\|\\hat{x} - \\sum_{k=1}^{K} \\sqrt{N} (\\hat{\\tilde{d}}_{k} \\odot \\hat{z}_{k})\\right\\|_{2}^{2} = \\sum_{\\omega=0}^{N-1} \\left|\\hat{x}(\\omega) - \\sqrt{N} \\sum_{k=1}^{K} \\hat{\\tilde{d}}_{k}(\\omega) \\hat{z}_{k}(\\omega)\\right|^{2} $$\nThe regularization term becomes:\n$$ \\sum_{k=1}^{K} \\|\\tilde{d}_{k}\\|_{2}^{2} = \\sum_{k=1}^{K} \\|\\hat{\\tilde{d}}_{k}\\|_{2}^{2} = \\sum_{k=1}^{K} \\sum_{\\omega=0}^{N-1} |\\hat{\\tilde{d}}_{k}(\\omega)|^{2} $$\nCombining these, the objective function in the Fourier domain is:\n$$ L(\\{\\hat{\\tilde{d}}_{k}\\}) = \\frac{1}{2}\\sum_{\\omega=0}^{N-1} \\left|\\hat{x}(\\omega) - \\sqrt{N} \\sum_{k=1}^{K} \\hat{\\tilde{d}}_{k}(\\omega) \\hat{z}_{k}(\\omega)\\right|^{2} + \\frac{\\alpha}{2} \\sum_{k=1}^{K} \\sum_{\\omega=0}^{N-1} |\\hat{\\tilde{d}}_{k}(\\omega)|^{2} $$\nWe can swap the order of summation and group terms by frequency $\\omega$:\n$$ L(\\{\\hat{\\tilde{d}}_{k}\\}) = \\sum_{\\omega=0}^{N-1} \\left( \\frac{1}{2}\\left|\\hat{x}(\\omega) - \\sqrt{N} \\sum_{k=1}^{K} \\hat{\\tilde{d}}_{k}(\\omega) \\hat{z}_{k}(\\omega)\\right|^{2} + \\frac{\\alpha}{2} \\sum_{k=1}^{K} |\\hat{\\tilde{d}}_{k}(\\omega)|^{2} \\right) $$\nThe total objective function is a sum of independent terms, one for each frequency $\\omega$. We can minimize $L$ by minimizing each term $L_{\\omega}$ independently with respect to the set of variables $\\{\\hat{\\tilde{d}}_{k}(\\omega)\\}_{k=1}^{K}$.\nThe objective for a single frequency $\\omega$ is:\n$$ L_{\\omega}(\\{\\hat{\\tilde{d}}_{k}(\\omega)\\}) = \\frac{1}{2}\\left|\\hat{x}(\\omega) - \\sqrt{N} \\sum_{j=1}^{K} \\hat{\\tilde{d}}_{j}(\\omega) \\hat{z}_{j}(\\omega)\\right|^{2} + \\frac{\\alpha}{2} \\sum_{j=1}^{K} |\\hat{\\tilde{d}}_{j}(\\omega)|^{2} $$\nTo find the minimum, we compute the complex gradient of $L_{\\omega}$ with respect to $\\overline{\\hat{\\tilde{d}}_{k}(\\omega)}$ (the complex conjugate of $\\hat{\\tilde{d}}_{k}(\\omega)$) and set it to zero for each $k \\in \\{1,\\dots,K\\}$.\nUsing Wirtinger calculus, $\\frac{\\partial}{\\partial z^{*}} |f(z)|^2 = f(z)\\frac{\\partial f(z)^{*}}{\\partial z^{*}}$ and $\\frac{\\partial}{\\partial z^{*}} |z|^2 = z$.\n$$ \\frac{\\partial L_{\\omega}}{\\partial \\overline{\\hat{\\tilde{d}}_{k}(\\omega)}} = \\frac{1}{2} \\left( \\hat{x}(\\omega) - \\sqrt{N} \\sum_{j=1}^{K} \\hat{\\tilde{d}}_{j}(\\omega) \\hat{z}_{j}(\\omega) \\right) (-\\sqrt{N} \\overline{\\hat{z}_{k}(\\omega)}) + \\frac{\\alpha}{2} \\hat{\\tilde{d}}_{k}(\\omega) = 0 $$\nMultiplying by $2$ and rearranging gives:\n$$ \\alpha \\hat{\\tilde{d}}_{k}(\\omega) - \\sqrt{N} \\overline{\\hat{z}_{k}(\\omega)} \\left( \\hat{x}(\\omega) - \\sqrt{N} \\sum_{j=1}^{K} \\hat{\\tilde{d}}_{j}(\\omega) \\hat{z}_{j}(\\omega) \\right) = 0 $$\n$$ \\alpha \\hat{\\tilde{d}}_{k}(\\omega) + N \\overline{\\hat{z}_{k}(\\omega)} \\sum_{j=1}^{K} \\hat{\\tilde{d}}_{j}(\\omega) \\hat{z}_{j}(\\omega) = \\sqrt{N} \\overline{\\hat{z}_{k}(\\omega)} \\hat{x}(\\omega) $$\nThis is a system of $K$ linear equations for the $K$ variables $\\{\\hat{\\tilde{d}}_{k}(\\omega)\\}$. Let $S(\\omega) = \\sum_{j=1}^{K} \\hat{\\tilde{d}}_{j}(\\omega) \\hat{z}_{j}(\\omega)$. The equation for $\\hat{\\tilde{d}}_{k}(\\omega)$ becomes:\n$$ \\alpha \\hat{\\tilde{d}}_{k}(\\omega) + N \\overline{\\hat{z}_{k}(\\omega)} S(\\omega) = \\sqrt{N} \\overline{\\hat{z}_{k}(\\omega)} \\hat{x}(\\omega) $$\nWe can isolate $\\hat{\\tilde{d}}_{k}(\\omega)$:\n$$ \\hat{\\tilde{d}}_{k}(\\omega) = \\frac{1}{\\alpha} \\left( \\sqrt{N} \\overline{\\hat{z}_{k}(\\omega)} \\hat{x}(\\omega) - N \\overline{\\hat{z}_{k}(\\omega)} S(\\omega) \\right) = \\frac{\\overline{\\hat{z}_{k}(\\omega)}}{\\alpha} (\\sqrt{N}\\hat{x}(\\omega) - N S(\\omega)) $$\nTo find $S(\\omega)$, we substitute this expression back into its definition:\n$$ S(\\omega) = \\sum_{k=1}^{K} \\left( \\frac{\\overline{\\hat{z}_{k}(\\omega)}}{\\alpha} (\\sqrt{N}\\hat{x}(\\omega) - N S(\\omega)) \\right) \\hat{z}_{k}(\\omega) $$\n$$ S(\\omega) = \\frac{1}{\\alpha} (\\sqrt{N}\\hat{x}(\\omega) - N S(\\omega)) \\sum_{k=1}^{K} |\\hat{z}_{k}(\\omega)|^{2} $$\nLet $\\Sigma_{z}(\\omega) = \\sum_{j=1}^{K} |\\hat{z}_{j}(\\omega)|^{2}$. The equation becomes:\n$$ \\alpha S(\\omega) = (\\sqrt{N}\\hat{x}(\\omega) - N S(\\omega)) \\Sigma_{z}(\\omega) $$\n$$ (\\alpha + N \\Sigma_{z}(\\omega)) S(\\omega) = \\sqrt{N}\\hat{x}(\\omega)\\Sigma_{z}(\\omega) $$\n$$ S(\\omega) = \\frac{\\sqrt{N}\\hat{x}(\\omega)\\Sigma_{z}(\\omega)}{\\alpha + N \\Sigma_{z}(\\omega)} $$\nNow, we substitute this back into the expression for $\\hat{\\tilde{d}}_{k}(\\omega)$:\n$$ \\hat{\\tilde{d}}_{k}(\\omega) = \\frac{\\overline{\\hat{z}_{k}(\\omega)}}{\\alpha} \\left( \\sqrt{N}\\hat{x}(\\omega) - N \\frac{\\sqrt{N}\\hat{x}(\\omega)\\Sigma_{z}(\\omega)}{\\alpha + N \\Sigma_{z}(\\omega)} \\right) $$\n$$ \\hat{\\tilde{d}}_{k}(\\omega) = \\frac{\\sqrt{N} \\overline{\\hat{z}_{k}(\\omega)} \\hat{x}(\\omega)}{\\alpha} \\left( 1 - \\frac{N \\Sigma_{z}(\\omega)}{\\alpha + N \\Sigma_{z}(\\omega)} \\right) $$\nSimplifying the term in parentheses:\n$$ 1 - \\frac{N \\Sigma_{z}(\\omega)}{\\alpha + N \\Sigma_{z}(\\omega)} = \\frac{\\alpha + N \\Sigma_{z}(\\omega) - N \\Sigma_{z}(\\omega)}{\\alpha + N \\Sigma_{z}(\\omega)} = \\frac{\\alpha}{\\alpha + N \\Sigma_{z}(\\omega)} $$\nThus, the solution for the unconstrained filter coefficients is:\n$$ \\hat{\\tilde{d}}_{k}(\\omega) = \\frac{\\sqrt{N} \\overline{\\hat{z}_{k}(\\omega)} \\hat{x}(\\omega)}{\\alpha + N \\sum_{j=1}^{K} |\\hat{z}_{j}(\\omega)|^{2}} $$\nThe second step is to impose the unit-norm constraint $\\|d_{k}\\|_{2} = 1$ by normalizing the unconstrained solution $\\tilde{d}_{k}$. The updated filter $d_{k}^{\\mathrm{new}}$ is given by:\n$$ d_{k}^{\\mathrm{new}} = \\frac{\\tilde{d}_{k}}{\\|\\tilde{d}_{k}\\|_{2}} $$\nIn the Fourier domain, this corresponds to:\n$$ \\hat{d}_{k}^{\\mathrm{new}}(\\omega) = \\frac{\\hat{\\tilde{d}}_{k}(\\omega)}{\\|\\tilde{d}_{k}\\|_{2}} $$\nUsing Parseval's identity, the norm $\\|\\tilde{d}_{k}\\|_{2}$ can be calculated from the Fourier coefficients:\n$$ \\|\\tilde{d}_{k}\\|_{2} = \\left( \\sum_{\\nu=0}^{N-1} |\\hat{\\tilde{d}}_{k}(\\nu)|^{2} \\right)^{1/2} $$\nSubstituting the expression for $\\hat{\\tilde{d}}_{k}(\\nu)$:\n$$ |\\hat{\\tilde{d}}_{k}(\\nu)|^{2} = \\frac{N |\\overline{\\hat{z}_{k}(\\nu)}|^{2} |\\hat{x}(\\nu)|^{2}}{(\\alpha + N \\sum_{j=1}^{K} |\\hat{z}_{j}(\\nu)|^{2})^{2}} = \\frac{N |\\hat{z}_{k}(\\nu)|^{2} |\\hat{x}(\\nu)|^{2}}{(\\alpha + N \\sum_{j=1}^{K} |\\hat{z}_{j}(\\nu)|^{2})^{2}} $$\nThe norm is therefore:\n$$ \\|\\tilde{d}_{k}\\|_{2} = \\left( \\sum_{\\nu=0}^{N-1} \\frac{N |\\hat{z}_{k}(\\nu)|^{2} |\\hat{x}(\\nu)|^{2}}{(\\alpha + N \\sum_{j=1}^{K} |\\hat{z}_{j}(\\nu)|^{2})^{2}} \\right)^{1/2} $$\nFinally, the expression for the normalized filter update $\\hat{d}_{k}^{\\mathrm{new}}(\\omega)$ is the ratio of $\\hat{\\tilde{d}}_{k}(\\omega)$ to $\\|\\tilde{d}_{k}\\|_{2}$:\n$$ \\hat{d}_{k}^{\\mathrm{new}}(\\omega) = \\frac{\\frac{\\sqrt{N} \\overline{\\hat{z}_{k}(\\omega)} \\hat{x}(\\omega)}{\\alpha + N \\sum_{j=1}^{K} |\\hat{z}_{j}(\\omega)|^{2}}}{\\left( \\sum_{\\nu=0}^{N-1} \\frac{N |\\hat{z}_{k}(\\nu)|^{2} |\\hat{x}(\\nu)|^{2}}{(\\alpha + N \\sum_{j=1}^{K} |\\hat{z}_{j}(\\nu)|^{2})^{2}} \\right)^{1/2}} $$\nThe factor of $\\sqrt{N}$ in the numerator and denominator can be cancelled:\n$$ \\hat{d}_{k}^{\\mathrm{new}}(\\omega) = \\frac{\\frac{\\overline{\\hat{z}_{k}(\\omega)} \\hat{x}(\\omega)}{\\alpha + N \\sum_{j=1}^{K} |\\hat{z}_{j}(\\omega)|^{2}}}{\\left( \\sum_{\\nu=0}^{N-1} \\frac{|\\hat{z}_{k}(\\nu)|^{2} |\\hat{x}(\\nu)|^{2}}{(\\alpha + N \\sum_{j=1}^{K} |\\hat{z}_{j}(\\nu)|^{2})^{2}} \\right)^{1/2}} $$\nThis is the final closed-form expression for the updated filter in the Fourier domain.", "answer": "$$ \\boxed{ \\frac{ \\frac{\\overline{\\hat{z}_{k}(\\omega)} \\hat{x}(\\omega)}{\\alpha + N \\sum_{j=1}^{K} |\\hat{z}_{j}(\\omega)|^{2}} }{ \\left( \\sum_{\\nu=0}^{N-1} \\frac{|\\hat{z}_{k}(\\nu)|^2 |\\hat{x}(\\nu)|^2}{ \\left( \\alpha + N \\sum_{j=1}^{K} |\\hat{z}_{j}(\\nu)|^2 \\right)^2 } \\right)^{1/2} } } $$", "id": "3440972"}, {"introduction": "While circular convolution enables computationally efficient algorithms via the Fast Fourier Transform, it can introduce modeling inaccuracies known as boundary artifacts. This advanced practice moves beyond algorithmic mechanics to explore the crucial impact of boundary conditions on the solution's fidelity. By deriving an analytical bound on the error induced by circular convolution compared to the more physically-grounded \"valid\" convolution, you will develop a quantitative understanding of this important trade-off. [@problem_id:3440968]", "problem": "Consider one-dimensional Convolutional Sparse Coding (CSC) under two boundary conditions for convolution: circular convolution and zero-padded convolution (valid convolution). Let there be $K$ filters $\\{d_k\\}_{k=1}^{K}$, each of length $m \\in \\mathbb{N}$, with $\\|d_k\\|_{2} = 1$ and uniform energy distribution across taps in the following sense: for any $r \\in \\{1,\\dots,m-1\\}$ and any index subset of $r$ consecutive taps, the $\\ell_{2}$-norm of that subvector equals $\\sqrt{r/m}$. Assume a signal $x \\in \\mathbb{R}^{N}$ is generated noiselessly by zero-padded convolution of these filters with sparse codes $\\{z_k^{\\star}\\}_{k=1}^{K}$:\n$$\nx = \\sum_{k=1}^{K} d_k * z_k^{\\star},\n$$\nwhere $*$ denotes the zero-padded (valid) convolution. The sparse codes are supported on indices in $\\{1,\\dots,N\\}$ and satisfy a separation condition: within each filter index $k$, the nonzero entries of $z_k^{\\star}$ are separated by at least $m$ indices (so their generated responses do not overlap), and supports across different filters do not overlap in their generated responses. Let $S_{e,k} \\subset \\{1,\\dots,N\\}$ be the subset of indices for the $k$-th code that lie within $m-1$ samples of either boundary (i.e., indices in $\\{1,\\dots,m-1\\} \\cup \\{N-m+2,\\dots,N\\}$), and let $s_{e,k} = |S_{e,k}|$. Assume an amplitude bound $A_{\\max} = \\max_{k \\in \\{1,\\dots,K\\}} \\max_{i \\in S_{e,k}} |z_{k,i}^{\\star}| < \\infty$.\n\nDefine the CSC optimization under a common regularization parameter $\\lambda > 0$ as minimizing the convex objective\n$$\n\\min_{\\{z_k\\}} \\;\\frac{1}{2}\\left\\| x - \\sum_{k=1}^{K} d_k \\star z_k \\right\\|_{2}^{2} + \\lambda \\sum_{k=1}^{K} \\|z_k\\|_{1},\n$$\nwhere $\\star$ denotes the chosen convolution boundary condition. Let $\\{z_k^{\\text{valid}}\\}_{k=1}^{K}$ be an optimal set of codes under zero-padded (valid) convolution and $\\{z_k^{\\text{circ}}\\}_{k=1}^{K}$ be an optimal set of codes under circular convolution, both obtained from the optimization problem above on the same signal $x$ and with the same set of filters and the same regularization parameter $\\lambda$. Let $z^{\\text{valid}}$ and $z^{\\text{circ}}$ denote the concatenations of codes across filters into a single vector in $\\mathbb{R}^{KN}$.\n\nStarting from the definitions of convolution, the CSC objective, and the separation assumption, and using only well-established properties of convex optimization and subgradients for $\\ell_{1}$-regularized least squares, derive a closed-form analytic upper bound on the Euclidean norm difference $\\|z^{\\text{circ}} - z^{\\text{valid}}\\|_{2}$ that depends only on the filter length $m$, the boundary sparsity counts $\\{s_{e,k}\\}_{k=1}^{K}$, and the boundary amplitude bound $A_{\\max}$. Express your final bound as a single analytic expression in terms of $m$, $\\{s_{e,k}\\}_{k=1}^{K}$, and $A_{\\max}$. No numerical evaluation is required. The final answer must be a single expression; do not present it as an inequality. No rounding is necessary.", "solution": "The user wants me to derive a closed-form upper bound on the Euclidean norm of the difference between two solutions to a Convolutional Sparse Coding (CSC) problem, where the solutions are obtained using different convolution boundary conditions.\n\n### Step 1: Formalization and Setup\n\nLet us represent the one-dimensional convolution as a matrix-vector product. For each filter $d_k \\in \\mathbb{R}^m$, we can construct a convolution matrix.\nLet $D_k^{\\text{valid}}$ be the $N \\times N$ Toeplitz matrix for zero-padded (valid) convolution. Its $(i,j)$-th entry is $(D_k^{\\text{valid}})_{i,j} = d_k(i-j+1)$ if $1 \\le i-j+1 \\le m$ and $0$ otherwise.\nLet $D_k^{\\text{circ}}$ be the $N \\times N$ circulant matrix for circular convolution. Its $(i,j)$-th entry is $(D_k^{\\text{circ}})_{i,j} = d_k(((i-j) \\pmod N)+1)$, assuming $1$-based indexing for $d_k$ and the signal.\n\nLet $D^{\\text{valid}} = [D_1^{\\text{valid}}, \\dots, D_K^{\\text{valid}}]$ and $D^{\\text{circ}} = [D_1^{\\text{circ}}, \\dots, D_K^{\\text{circ}}]$ be the $N \\times KN$ concatenated dictionary matrices. Let $z = [z_1^T, \\dots, z_K^T]^T \\in \\mathbb{R}^{KN}$ be the concatenated vector of sparse codes.\n\nThe signal is generated noiselessly as $x = \\sum_{k=1}^{K} d_k * z_k^{\\star} = D^{\\text{valid}} z^{\\star}$, where $*$ denotes the valid convolution.\n\nThe two optimization problems are:\n1.  Valid convolution: $\\{z_k^{\\text{valid}}\\}$ is a solution to $\\min_{z} \\frac{1}{2}\\|x - D^{\\text{valid}}z\\|_2^2 + \\lambda\\|z\\|_1$.\n2.  Circular convolution: $\\{z_k^{\\text{circ}}\\}$ is a solution to $\\min_{z} \\frac{1}{2}\\|x - D^{\\text{circ}}z\\|_2^2 + \\lambda\\|z\\|_1$.\n\nLet $z^{\\text{valid}}$ and $z^{\\text{circ}}$ be the respective concatenated solution vectors. We want to find an upper bound for $\\|z^{\\text{circ}} - z^{\\text{valid}}\\|_2$.\n\n### Step 2: Analysis of the Dictionaries and the Signal Structure\n\nThe problem states a \"uniform energy distribution\" for the filters: the $\\ell_2$-norm of any $r$ consecutive taps is $\\sqrt{r/m}$. For $r=1$, this implies that each tap $d_{k,j}$ has magnitude $|d_{k,j}| = \\sqrt{1/m} = 1/\\sqrt{m}$. This is consistent with the normalization $\\|d_k\\|_2 = 1$, since $\\sum_{j=1}^m |d_{k,j}|^2 = m \\cdot (1/m) = 1$.\n\nThe \"separation condition\" on the true sparse codes $\\{z_k^{\\star}\\}$ is critical. It states that the generated filter responses do not overlap. A response from a coefficient $z_{k,i}^{\\star}$ is the filter $d_k$ shifted to position $i$, which occupies the signal indices $[i, i+m-1]$. The separation condition means that for any two nonzero coefficients $z_{k,i}^{\\star}$ and $z_{k',j}^{\\star}$ (with $(k,i) \\neq (k',j)$), the supports of their responses are disjoint: $[i, i+m-1] \\cap [j, j+m-1] = \\emptyset$. A direct consequence of this is that the columns of $D^{\\text{valid}}$ corresponding to the support of $z^{\\star}$ are mutually orthogonal. Since each filter is normalized ($\\|d_k\\|_2=1$), these columns are orthonormal.\n\nThis orthogonality simplifies the \"valid\" problem. Since $x = D^{\\text{valid}}z^{\\star}$ and the columns of $D^{\\text{valid}}$ corresponding to the support of $z^{\\star}$ are orthonormal, a solution to the valid CSC problem is $z^{\\text{valid}} = z^{\\star}$, provided that $\\lambda$ is sufficiently small and an incoherence condition holds. The problem asks for a bound independent of $\\lambda$, which is a strong indicator that we should analyze the system in a regime where the solution is simple. Assuming $z^{\\text{valid}} = z^{\\star}$ is the most reasonable simplification that allows for a $\\lambda$-independent bound. This is justified because $z^{\\star}$ is the ground truth that generated the data $x$ using the *same* forward model as the \"valid\" optimization problem.\n\nUnder this assumption, the task reduces to bounding $\\|z^{\\textcirc} - z^{\\star}\\|_2$.\n\n### Step 3: Analysis of the Circular Convolution Problem\n\nThe solution $z^{\\text{circ}}$ minimizes the objective $J^{\\text{circ}}(z) = \\frac{1}{2}\\|x - D^{\\text{circ}}z\\|_2^2 + \\lambda\\|z\\|_1$.\nSince $z^{\\text{circ}}$ is the minimizer, its objective value is less than or equal to the objective value for any other vector, including $z^{\\star}$:\n$$J^{\\text{circ}}(z^{\\text{circ}}) \\le J^{\\text{circ}}(z^{\\star})$$\nLet's evaluate $J^{\\text{circ}}(z^{\\star})$:\n$$J^{\\text{circ}}(z^{\\star}) = \\frac{1}{2}\\|x - D^{\\text{circ}}z^{\\star}\\|_2^2 + \\lambda\\|z^{\\star}\\|_1$$\nSubstitute $x = D^{\\text{valid}}z^{\\star}$:\n$$J^{\\text{circ}}(z^{\\star}) = \\frac{1}{2}\\|D^{\\text{valid}}z^{\\star} - D^{\\text{circ}}z^{\\star}\\|_2^2 + \\lambda\\|z^{\\star}\\|_1 = \\frac{1}{2}\\|(D^{\\text{valid}} - D^{\\text{circ}})z^{\\star}\\|_2^2 + \\lambda\\|z^{\\star}\\|_1$$\nLet $\\Delta D = D^{\\text{circ}} - D^{\\text{valid}}$. Then $J^{\\text{circ}}(z^{\\star}) = \\frac{1}{2}\\|\\Delta D z^{\\star}\\|_2^2 + \\lambda\\|z^{\\star}\\|_1$.\n\nThe difference between the circular and valid convolution matrices, $\\Delta D$, is non-zero only for columns and rows corresponding to the signal boundaries. A column $j$ of $D_k^{\\text{valid}}$ and $D_k^{\\text{circ}}$ are identical if the support of the filter $d_k$ shifted by $j-1$ is fully contained within $[1, N]$. This is true for $j \\in \\{m, \\dots, N-m+1\\}$. Therefore, $\\Delta D z^{\\star}$ depends only on the components of $z^{\\star}$ at boundary indices. The set of these \"boundary-effective\" indices for code $z_k$ is $S_{e,k}$.\n\nThe perturbation term $\\Delta D z^{\\star}$ is the source of the difference between $z^{\\text{circ}}$ and $z^{\\star}$. In many stability analyses, the norm of the solution's error is on the order of the norm of the perturbation. We will therefore establish an upper bound on $\\|z^{\\text{circ}} - z^{\\star}\\|_2$ by bounding the norm of the perturbation term $\\|\\Delta D z^{\\star}\\|_2$.\n\n### Step 4: Bounding the Perturbation Norm\n\nThe total perturbation is a sum of perturbations from each filter: $\\Delta D z^{\\star} = \\sum_{k=1}^K \\Delta D_k z_k^{\\star}$.\nDue to the separation of supports of the responses, the vectors $\\Delta D_k z_k^{\\star}$ for different $k$ have disjoint support. Thus, the squared norm of the sum is the sum of the squared norms:\n$$\\|\\Delta D z^{\\star}\\|_2^2 = \\sum_{k=1}^K \\|\\Delta D_k z_k^{\\star}\\|_2^2$$\nLet's analyze the term for a single filter $k$: $\\|\\Delta D_k z_k^{\\star}\\|_2^2$. The vector $\\delta_k = \\Delta D_k z_k^{\\star}$ has non-zero entries only near the signal boundaries, for indices $i \\in \\{1,\\dots,m-1\\}$ and $i \\in \\{N-m+2,\\dots,N\\}$.\nLet's analyze the \"head\" part, for $i \\in \\{1, \\dots, m-1\\}$. The $i$-th component of $\\delta_k$ is due to wrap-around from the right boundary of $z_k^{\\star}$:\n$$(\\delta_k)_i = \\sum_{j=1}^N (\\Delta D_k)_{i,j} z_{k,j}^{\\star} = \\sum_{j=N-m+2}^N (D_k^{\\text{circ}})_{i,j} z_{k,j}^{\\star}$$\nLet $S_{e,k,R}^{\\star}$ be the support of $z_k^{\\star}$ on the right boundary indices $\\{N-m+2, \\dots, N\\}$, with cardinality $s_{e,k,R} = |S_{e,k,R}^{\\star}|$. Let $S_{e,k,L}^{\\star}$ be the support on the left boundary indices $\\{1, \\dots, m-1\\}$, with $s_{e,k,L} = |S_{e,k,L}^{\\star}|$. We have $s_{e,k,L} + s_{e,k,R} \\le s_{e,k}$.\nLet $v_{k,j}$ be the $j$-th column of $\\Delta D_k$. Then $\\delta_k = \\sum_{j \\in \\text{supp}(z_k^\\star)} z_{k,j}^\\star v_{k,j}$.\nThe vector $\\delta_k$ can be split into a head part (supported on $i \\in \\{1, \\dots, m-1\\}$) and a tail part (supported on $i \\in \\{N-m+2, \\dots, N\\}$).\nLet's bound the norm of the head part. By the triangle inequality and properties of norms:\n$$\\|\\delta_{k, \\text{head}}\\|_2 = \\left\\| \\sum_{j \\in S_{e,k,R}^\\star} z_{k,j}^{\\star} (v_{k,j})_{\\text{head}} \\right\\|_2 \\le \\sum_{j \\in S_{e,k,R}^\\star} |z_{k,j}^{\\star}| \\|(v_{k,j})_{\\text{head}}\\|_2$$\nUsing the given amplitude bound, $|z_{k,j}^{\\star}| \\le A_{\\max}$ for $j \\in S_{e,k}$.\n$$\\|\\delta_{k, \\text{head}}\\|_2 \\le A_{\\max} \\sum_{j \\in S_{e,k,R}^\\star} \\|(v_{k,j})_{\\text{head}}\\|_2$$\nThe vector $(v_{k,j})_{\\text{head}}$ is the part of the $j$-th column of $\\Delta D_k$ corresponding to rows $1$ to $m-1$. Its entries are $(D_k^{\\text{circ}})_{i,j}$ for $i=1,\\dots,m-1$. For $j$ near the right boundary, say $j=N-p$ for $p=0, \\dots, m-2$, the non-zero entries of this vector are a subvector of $d_k$ (or its reversal). The norm of this subvector of $d_k$ is at most the norm of $d_k$ itself, which is $1$. A tighter bound comes from the problem's energy distribution property. The $j$-th column of $D_k^{\\text{circ}}$ is a shifted version of $d_k$. The part that \"wraps around\" is composed of taps of $d_k$. The squared norm of $(v_{k,j})_{\\text{head}}$ is the sum of squares of some taps of $d_k$. At most, it's the squared norm of $m-1$ taps, which is $\\frac{m-1}{m}$. Thus, $\\|(v_{k,j})_{\\text{head}}\\|_2 \\le \\sqrt{\\frac{m-1}{m}}$.\n\nUsing this uniform bound for each column:\n$$\\|\\delta_{k, \\text{head}}\\|_2 \\le A_{\\max} \\sum_{j \\in S_{e,k,R}^\\star} \\sqrt{\\frac{m-1}{m}} = A_{\\max} \\, s_{e,k,R} \\sqrt{\\frac{m-1}{m}}$$\nSimilarly, for the tail part, which depends on $z_k^\\star$ on the left boundary:\n$$\\|\\delta_{k, \\text{tail}}\\|_2 \\le A_{\\max} \\, s_{e,k,L} \\sqrt{\\frac{m-1}{m}}$$\nSince the head and tail parts have disjoint support:\n$$\\|\\Delta D_k z_k^{\\star}\\|_2^2 = \\|\\delta_{k, \\text{head}}\\|_2^2 + \\|\\delta_{k, \\text{tail}}\\|_2^2 \\le A_{\\max}^2 \\frac{m-1}{m} (s_{e,k,R}^2 + s_{e,k,L}^2)$$\nWe are given $s_{e,k}$, which is an upper bound on $s_{e,k,R} + s_{e,k,L}$. We know that for non-negative numbers, $a^2+b^2 \\le (a+b)^2$. Therefore, $s_{e,k,R}^2 + s_{e,k,L}^2 \\le (s_{e,k,R} + s_{e,k,L})^2 \\le s_{e,k}^2$.\n$$\\|\\Delta D_k z_k^{\\star}\\|_2^2 \\le A_{\\max}^2 s_{e,k}^2 \\frac{m-1}{m}$$\nSumming over all filters $k$:\n$$\\|\\Delta D z^{\\star}\\|_2^2 = \\sum_{k=1}^K \\|\\Delta D_k z_k^{\\star}\\|_2^2 \\le A_{\\max}^2 \\frac{m-1}{m} \\sum_{k=1}^K s_{e,k}^2$$\nTaking the square root gives the bound on the perturbation norm:\n$$\\|\\Delta D z^{\\star}\\|_2 \\le A_{\\max} \\sqrt{\\frac{m-1}{m} \\sum_{k=1}^K s_{e,k}^2}$$\nBased on the reasoning that the error norm $\\|z^{\\text{circ}} - z^{\\text{valid}}\\|_2$ is bounded by the perturbation norm, we adopt this as our final upper bound. This expression depends only on $m$, $A_{\\max}$, and $\\{s_{e,k}\\}_{k=1}^K$ as required.\n\nFinal expression for the upper bound on $\\|z^{\\text{circ}} - z^{\\text{valid}}\\|_{2}$:\n$$A_{\\max} \\sqrt{\\frac{m-1}{m} \\sum_{k=1}^{K} s_{e,k}^{2}}$$", "answer": "$$\n\\boxed{A_{\\max} \\sqrt{\\frac{m-1}{m} \\sum_{k=1}^{K} s_{e,k}^{2}}}\n$$", "id": "3440968"}]}