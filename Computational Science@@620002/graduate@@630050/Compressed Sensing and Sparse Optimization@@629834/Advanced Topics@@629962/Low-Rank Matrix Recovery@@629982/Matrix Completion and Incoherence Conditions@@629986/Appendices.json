{"hands_on_practices": [{"introduction": "The ability to recover a low-rank matrix from a small number of entries depends critically on its 'incoherence'—a measure of how spread out its singular vectors are. This first exercise provides a direct, hands-on calculation of the coherence parameters for a simple rank-1 matrix that is maximally 'spiky' or coherent. By working through this extreme example [@problem_id:3459273], you will gain a concrete understanding of what the coherence value $\\mu$ represents and why it is a key factor in matrix completion theory.", "problem": "Consider positive integers $m$ and $n$ and the $m \\times n$ rank-$1$ matrix $M = e^{(m)}_{1} \\left(e^{(n)}_{1}\\right)^{\\top}$, where $e^{(m)}_{1} \\in \\mathbb{R}^{m}$ and $e^{(n)}_{1} \\in \\mathbb{R}^{n}$ denote the first standard basis vectors in $\\mathbb{R}^{m}$ and $\\mathbb{R}^{n}$, respectively. Let the singular value decomposition (SVD) denote the factorization of $M$ as $M = U \\Sigma V^{\\top}$, where $U \\in \\mathbb{R}^{m \\times r}$ and $V \\in \\mathbb{R}^{n \\times r}$ have orthonormal columns spanning the column and row subspaces of $M$, respectively, and $\\Sigma \\in \\mathbb{R}^{r \\times r}$ contains the singular values, with $r = \\mathrm{rank}(M)$. Define the orthogonal projectors onto the column and row subspaces by $P_{U} = U U^{\\top}$ and $P_{V} = V V^{\\top}$. The coherence of a subspace with respect to the standard basis is defined, for rank $r$, by\n$$\n\\mu(U) = \\frac{m}{r} \\max_{1 \\leq i \\leq m} \\left\\| P_{U} e^{(m)}_{i} \\right\\|_{2}^{2}, \n\\qquad\n\\mu(V) = \\frac{n}{r} \\max_{1 \\leq j \\leq n} \\left\\| P_{V} e^{(n)}_{j} \\right\\|_{2}^{2}.\n$$\nStarting from these definitions and the SVD of $M$, compute the coherence parameters $\\mu(U)$ and $\\mu(V)$ for the matrix $M = e^{(m)}_{1} \\left(e^{(n)}_{1}\\right)^{\\top}$, and briefly explain why these values illustrate an extreme coherence configuration in the context of matrix completion. Report your final answer as the single row matrix containing the two values $\\left(\\mu(U), \\mu(V)\\right)$. No rounding is required, and your answer must be exact.", "solution": "We begin with the $m \\times n$ matrix $M = e^{(m)}_{1} \\left(e^{(n)}_{1}\\right)^{\\top}$. This is a rank-$1$ matrix because it is the outer product of two nonzero vectors. The singular value decomposition (SVD) of a rank-$1$ outer product $u v^{\\top}$ with $u \\in \\mathbb{R}^{m}$ and $v \\in \\mathbb{R}^{n}$ is given by $M = U \\Sigma V^{\\top}$ where $U$ and $V$ each have one column equal to the normalized versions of $u$ and $v$, respectively, and $\\Sigma$ contains the single nonzero singular value equal to $\\|u\\|_{2} \\|v\\|_{2}$. In our specific case, $u = e^{(m)}_{1}$ and $v = e^{(n)}_{1}$ already have unit norm, so the SVD is\n$$\nM = U \\Sigma V^{\\top}, \\quad U = e^{(m)}_{1}, \\quad V = e^{(n)}_{1}, \\quad \\Sigma = [1],\n$$\nwith rank $r = 1$. The column subspace $U$ is $\\mathrm{span}\\left(e^{(m)}_{1}\\right)$ and the row subspace $V$ is $\\mathrm{span}\\left(e^{(n)}_{1}\\right)$.\n\nThe orthogonal projectors onto these one-dimensional subspaces are\n$$\nP_{U} = U U^{\\top} = e^{(m)}_{1} \\left(e^{(m)}_{1}\\right)^{\\top}, \n\\qquad \nP_{V} = V V^{\\top} = e^{(n)}_{1} \\left(e^{(n)}_{1}\\right)^{\\top}.\n$$\nTo compute the coherence parameters, we evaluate the squared norms of the projected standard basis vectors. For $1 \\leq i \\leq m$,\n$$\nP_{U} e^{(m)}_{i} = \\left(e^{(m)}_{1} \\left(e^{(m)}_{1}\\right)^{\\top}\\right) e^{(m)}_{i} \n= e^{(m)}_{1} \\left\\langle e^{(m)}_{1}, e^{(m)}_{i} \\right\\rangle \n= \n\\begin{cases}\ne^{(m)}_{1},  i = 1, \\\\\n0,  i \\neq 1,\n\\end{cases}\n$$\nhence\n$$\n\\left\\|P_{U} e^{(m)}_{i}\\right\\|_{2}^{2} = \n\\begin{cases}\n1,  i = 1, \\\\\n0,  i \\neq 1.\n\\end{cases}\n$$\nTherefore,\n$$\n\\max_{1 \\leq i \\leq m} \\left\\| P_{U} e^{(m)}_{i} \\right\\|_{2}^{2} = 1,\n$$\nand with $r = 1$,\n$$\n\\mu(U) = \\frac{m}{r} \\max_{i} \\left\\| P_{U} e^{(m)}_{i} \\right\\|_{2}^{2} = m.\n$$\n\nAn analogous calculation holds for $P_{V}$. For $1 \\leq j \\leq n$,\n$$\nP_{V} e^{(n)}_{j} = \\left(e^{(n)}_{1} \\left(e^{(n)}_{1}\\right)^{\\top}\\right) e^{(n)}_{j} \n= e^{(n)}_{1} \\left\\langle e^{(n)}_{1}, e^{(n)}_{j} \\right\\rangle \n= \n\\begin{cases}\ne^{(n)}_{1},  j = 1, \\\\\n0,  j \\neq 1,\n\\end{cases}\n$$\nand thus\n$$\n\\left\\|P_{V} e^{(n)}_{j}\\right\\|_{2}^{2} = \n\\begin{cases}\n1,  j = 1, \\\\\n0,  j \\neq 1.\n\\end{cases}\n$$\nConsequently,\n$$\n\\max_{1 \\leq j \\leq n} \\left\\| P_{V} e^{(n)}_{j} \\right\\|_{2}^{2} = 1,\n$$\nand with $r = 1$,\n$$\n\\mu(V) = \\frac{n}{r} \\max_{j} \\left\\| P_{V} e^{(n)}_{j} \\right\\|_{2}^{2} = n.\n$$\n\nThese values illustrate extreme coherence because, for rank $r = 1$, the coherence satisfies the general bounds $1 \\leq \\mu(U) \\leq m$ and $1 \\leq \\mu(V) \\leq n$. The case computed here achieves the largest possible values, $\\mu(U) = m$ and $\\mu(V) = n$, meaning the subspaces are maximally aligned with single standard basis vectors. In matrix completion, such extreme coherence signifies that the information in $M$ is highly concentrated in a single coordinate in both the column and row spaces, which is precisely the pathological case where incoherence is violated most severely. The requested final answer is the row matrix containing these two values.", "answer": "$$\\boxed{\\begin{pmatrix} m  n \\end{pmatrix}}$$", "id": "3459273"}, {"introduction": "Why does nuclear norm minimization succeed in recovering the true low-rank matrix? The answer lies in the Karush-Kuhn-Tucker (KKT) optimality conditions and the existence of a 'dual certificate'. This practice [@problem_id:3459243] demystifies these abstract theoretical guarantees by guiding you through the explicit construction of such a certificate for a small-scale problem. You will verify that the proposed solution is indeed optimal, providing a tangible link between convex optimization theory and matrix completion.", "problem": "Consider the matrix completion problem with equality constraints and nuclear norm regularization. Let the true unknown matrix be the rank-one matrix $X_{\\star} \\in \\mathbb{R}^{2 \\times 2}$ defined by the singular value decomposition (SVD) $X_{\\star} = \\sigma\\, u v^{\\top}$, where $u = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$, $v = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$, and $\\sigma = 2$. Hence, $$X_{\\star} = \\begin{pmatrix}1  1 \\\\ 1  1\\end{pmatrix}.$$ The observed index set is $\\Omega = \\{(1,1),(1,2),(2,1)\\}$, and the sampling operator $\\mathcal{P}_{\\Omega}:\\mathbb{R}^{2\\times 2}\\to\\mathbb{R}^{2\\times 2}$ acts as $$(\\mathcal{P}_{\\Omega}(X))_{ij} = \\begin{cases} X_{ij},  (i,j)\\in \\Omega, \\\\ 0,  \\text{otherwise.}\\end{cases}$$ Consider the convex program $$\\min_{X\\in \\mathbb{R}^{2\\times 2}} \\|X\\|_{*} \\quad \\text{subject to} \\quad \\mathcal{P}_{\\Omega}(X) = \\mathcal{P}_{\\Omega}(X_{\\star}),$$ where $\\|X\\|_{*}$ is the nuclear norm (sum of singular values). Let $T$ denote the tangent space at $X_{\\star}$ to the rank-one manifold, $T = \\{u a^{\\top} + b v^{\\top}: a\\in\\mathbb{R}^{2},\\, b\\in\\mathbb{R}^{2}\\}$, and let $\\mathcal{P}_{T}$ and $\\mathcal{P}_{T^{\\perp}}$ denote the orthogonal projections onto $T$ and its orthogonal complement, respectively, with respect to the Frobenius inner product. Using only core definitions (convex optimality via Karush–Kuhn–Tucker conditions, the subgradient of the nuclear norm at a rank-one point, and the definition of the tangent space and its orthogonal complement), perform the following steps:\n\n1. Explicitly construct a dual certificate $Y \\in \\mathbb{R}^{2\\times 2}$ such that $Y \\in \\mathrm{range}(\\mathcal{P}_{\\Omega}), \\quad \\mathcal{P}_{T}(Y) = u v^{\\top}, \\quad \\|\\mathcal{P}_{T^{\\perp}}(Y)\\|_{2} \\leq 1,$ where $\\|\\cdot\\|_{2}$ is the spectral norm. Your construction must start from the requirement that $Y$ is supported on $\\Omega$ (i.e., $Y_{22}=0$) and from the characterization of the subgradient $\\partial \\|X_{\\star}\\|_{*} = \\{u v^{\\top} + W: \\mathcal{P}_{T}(W)=0,\\, \\|W\\|_{2} \\leq 1\\}.$\n\n2. Verify the Karush–Kuhn–Tucker (KKT) conditions for optimality by identifying a Lagrange multiplier $\\Lambda \\in \\mathbb{R}^{2\\times 2}$ such that the stationarity condition holds and by checking primal feasibility. In particular, show that your $Y$ can be written as $Y = \\mathcal{P}_{\\Omega}(\\Lambda)$ with an appropriate sign convention to satisfy stationarity, and verify $\\langle Y, X_{\\star}\\rangle = \\|X_{\\star}\\|_*.$\n\n3. Compute the quantity $\\|\\mathcal{P}_{T^{\\perp}}(Y)\\|_{2}.$\n\nProvide your final answer as a single real number with no units. No rounding is required; give the exact value.", "solution": "The true matrix is $X_{\\star} = \\sigma u v^{\\top}$, where $\\sigma=2$ and $u=v=\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}$. This gives\n$$X_{\\star} = 2 \\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix}1  1\\end{pmatrix}\\right) = \\begin{pmatrix}1  1 \\\\ 1  1\\end{pmatrix}.$$\nThe nuclear norm is $\\|X_{\\star}\\|_* = \\sigma = 2$. The observed entries are specified by $\\Omega = \\{(1,1),(1,2),(2,1)\\}$. The optimization problem is\n$$\\min_{X\\in \\mathbb{R}^{2\\times 2}} \\|X\\|_* \\quad \\text{subject to} \\quad \\mathcal{P}_{\\Omega}(X) = \\mathcal{P}_{\\Omega}(X_{\\star}).$$\nA sufficient condition for $X_{\\star}$ to be the unique solution is the existence of a dual certificate $Y \\in \\mathbb{R}^{2\\times 2}$ that is in the range of the sampling operator ($Y_{ij}=0$ for $(i,j) \\notin \\Omega$) and is an element of the subgradient of the nuclear norm at $X_{\\star}$, denoted $\\partial \\|X_{\\star}\\|_*$.\n\nFor a rank-1 matrix $X_{\\star}=\\sigma u v^{\\top}$, the subgradient is $\\partial \\|X_{\\star}\\|_* = \\{u v^{\\top} + W \\mid \\mathcal{P}_{T}(W)=0, \\|W\\|_{2} \\leq 1\\}$. The tangent space $T$ is spanned by matrices of the form $ua^\\top + bv^\\top$. Its orthogonal complement, $T^{\\perp}$, consists of matrices $Z$ such that $u^{\\top}Z=0$ and $Zv=0$. Since $u=v$, any matrix in $T^{\\perp}$ must be a multiple of $u_{\\perp}u_{\\perp}^{\\top}$, where $u_{\\perp} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ -1\\end{pmatrix}$.\n\n**Step 1: Construct the dual certificate $Y$**\n\nWe need to find $Y$ such that it is supported on $\\Omega$ (i.e., $Y_{22}=0$) and can be decomposed as $Y = \\mathcal{P}_{T}(Y) + \\mathcal{P}_{T^{\\perp}}(Y)$ where $\\mathcal{P}_{T}(Y) = uv^{\\top}$ and $\\|\\mathcal{P}_{T^{\\perp}}(Y)\\|_{2} \\leq 1$. Let $W = \\mathcal{P}_{T^{\\perp}}(Y) = c \\, u_{\\perp}u_{\\perp}^{\\top}$ for some scalar $c$. Then,\n$$Y = uv^{\\top} + c \\, u_{\\perp}u_{\\perp}^{\\top} = \\frac{1}{2}\\begin{pmatrix}1  1 \\\\ 1  1\\end{pmatrix} + c \\frac{1}{2}\\begin{pmatrix}1  -1 \\\\ -1  1\\end{pmatrix} = \\frac{1}{2}\\begin{pmatrix}1+c  1-c \\\\ 1-c  1+c\\end{pmatrix}.$$\nThe condition $Y_{22}=0$ implies $\\frac{1}{2}(1+c) = 0 \\implies c = -1$.\nSubstituting $c=-1$ gives the dual certificate:\n$$Y = \\frac{1}{2}\\begin{pmatrix}0  2 \\\\ 2  0\\end{pmatrix} = \\begin{pmatrix}0  1 \\\\ 1  0\\end{pmatrix}.$$\nThis matrix satisfies the support condition since its only non-zero entries are at positions $(1,2)$ and $(2,1)$, which are in $\\Omega$, and the entry at $(2,2)$ is zero.\n\n**Step 2: Verify Optimality Conditions**\n\nWe verify that $Y$ is a valid subgradient. We have $Y = uv^{\\top} + W$ with $W = -u_{\\perp}u_{\\perp}^{\\top}$.\n- By construction, $W \\in T^{\\perp}$, so $\\mathcal{P}_{T}(W)=0$.\n- We compute the spectral norm of $W$: $\\|W\\|_{2} = \\|-u_{\\perp}u_{\\perp}^{\\top}\\|_{2} = |-1| \\cdot \\|u_{\\perp}u_{\\perp}^{\\top}\\|_{2}$. Since $u_{\\perp}u_{\\perp}^{\\top}$ is an orthogonal projection onto a 1D space, its spectral norm is 1. Thus, $\\|W\\|_{2} = 1$, which satisfies the condition $\\|W\\|_{2} \\leq 1$.\nThis confirms $Y \\in \\partial \\|X_{\\star}\\|_*$. The existence of such a $Y$ in the range of $\\mathcal{P}_\\Omega$ guarantees that $X_\\star$ is an optimal solution.\n\nWe also verify the subgradient property $\\langle Y, X_{\\star}\\rangle = \\|X_{\\star}\\|_*$:\n$$\\langle Y, X_{\\star}\\rangle = \\mathrm{Tr}(Y^{\\top}X_{\\star}) = \\mathrm{Tr}\\left(\\begin{pmatrix}0  1 \\\\ 1  0\\end{pmatrix} \\begin{pmatrix}1  1 \\\\ 1  1\\end{pmatrix}\\right) = \\mathrm{Tr}\\left(\\begin{pmatrix}1  1 \\\\ 1  1\\end{pmatrix}\\right) = 2.$$\nThis matches $\\|X_{\\star}\\|_* = 2$.\n\n**Step 3: Compute $\\|\\mathcal{P}_{T^{\\perp}}(Y)\\|_{2}$**\n\nFrom our construction, the projection of $Y$ onto the orthogonal complement of the tangent space is:\n$$\\mathcal{P}_{T^{\\perp}}(Y) = W = -u_{\\perp}u_{\\perp}^{\\top}.$$\nThe required value is the spectral norm of this matrix:\n$$\\|\\mathcal{P}_{T^{\\perp}}(Y)\\|_{2} = \\|-u_{\\perp}u_{\\perp}^{\\top}\\|_{2} = 1.$$\nThe value is exactly $1$.", "answer": "$$\\boxed{1}$$", "id": "3459243"}, {"introduction": "Standard matrix completion theory often assumes uniform incoherence, but many practical applications feature matrices with structured 'spikiness'. This exercise [@problem_id:3459271] introduces a powerful adaptive strategy: weighted nuclear norm minimization. You will explore how assigning different weights to different blocks of a matrix can effectively neutralize localized coherence spikes, thereby extending the power of matrix completion to a broader class of structured problems.", "problem": "You are given a square matrix completion setting with block-structured singular vectors. Consider a square matrix of size $n \\times n$ and a rank-$r$ ground-truth matrix $M = U \\Sigma V^{\\top}$, where $U \\in \\mathbb{R}^{n \\times r}$ and $V \\in \\mathbb{R}^{n \\times r}$ have orthonormal columns. The row and column indices are partitioned into $B$ disjoint blocks of sizes $s_1, s_2, \\ldots, s_B$ that sum to $n$. For each block $b \\in \\{1, \\ldots, B\\}$, define the localized block coherence values of $U$ and $V$ by\n$$\n\\mu_b(U) \\triangleq \\frac{n}{r} \\max_{i \\in \\text{block } b} \\left\\| P_U e_i \\right\\|_2^2, \n\\quad\n\\mu_b(V) \\triangleq \\frac{n}{r} \\max_{i \\in \\text{block } b} \\left\\| P_V e_i \\right\\|_2^2,\n$$\nwhere $P_U$ and $P_V$ denote the orthogonal projectors onto the column spaces of $U$ and $V$, and $(e_i)_{i=1}^n$ is the standard basis. Let the worst-case localized coherence be $\\mu_b \\triangleq \\max\\{\\mu_b(U), \\mu_b(V)\\}$. Assume a fraction of the blocks can be spiky (large $\\mu_b$), while other blocks are incoherent (small $\\mu_b$).\n\nTo mitigate localized spikes, consider a block-weighted nuclear norm minimization program. Let $D \\in \\mathbb{R}^{n \\times n}$ be a positive diagonal matrix that is block-constant: for $i$ in block $b$, $D_{ii} = w_b  0$. Define the block-weighted nuclear norm by $\\| D X D \\|_\\ast$. The recovery program is\n$$\n\\min_{X \\in \\mathbb{R}^{n \\times n}} \\; \\| D X D \\|_\\ast \n\\quad \\text{subject to} \\quad \\mathcal{P}_{\\Omega}(X) = \\mathcal{P}_{\\Omega}(M),\n$$\nwhere $\\mathcal{P}_{\\Omega}$ is the sampling operator that reveals the entries of $M$ on a uniformly random subset $\\Omega$ of size $m$, and leaves the remaining entries unspecified.\n\nUsing only fundamental definitions and well-tested results, you will:\n- Start from the standard coherence definition and the known sample complexity bound for unweighted matrix completion.\n- Reason how block weighting modifies localized coherences.\n- Derive a sufficient condition on block weights to neutralize localized spikes.\n- Instantiate a computable sufficient sampling condition in terms of an effective coherence.\n\nFor the purposes of this problem, model the effect of block weighting as follows. If the weighting matrix $D$ with block weights $(w_b)_{b=1}^B$ is applied symmetrically to rows and columns in the weighted nuclear norm $\\| D X D \\|_\\ast$, then the effective block coherence is\n$$\n\\mu_b^{\\mathrm{eff}} \\triangleq \\frac{\\mu_b}{w_b^2},\n$$\nand the global effective coherence is\n$$\n\\mu_{\\mathrm{eff}} \\triangleq \\max_{1 \\le b \\le B} \\mu_b^{\\mathrm{eff}} = \\max_{1 \\le b \\le B} \\frac{\\mu_b}{w_b^2}.\n$$\nAssume a standard sufficient sampling condition of the form\n$$\nm \\;\\ge\\; C \\, r \\, \\mu_{\\mathrm{eff}} \\, n \\, \\log n,\n$$\nfor some absolute constant $C  0$ and natural logarithm $\\log(\\cdot)$. Define that the block weights $(w_b)$ neutralize localized spikes relative to a target baseline $\\mu_\\star$ if $\\mu_{\\mathrm{eff}} \\le \\mu_\\star$.\n\nYour task is to write a program that, for each test case, computes:\n- A boolean neutralization indicator that is true if $\\mu_{\\mathrm{eff}} \\le \\mu_\\star$ and false otherwise.\n- A boolean recoverability indicator that is true if $m \\ge \\lceil C \\, r \\, \\mu_{\\mathrm{eff}} \\, n \\, \\log n \\rceil$ and false otherwise.\n\nUse the following test suite, where all logarithms are natural, and where $C = 5$ for all cases. In each test case, the tuple consists of $(n, r, B, (s_b)_{b=1}^B, (\\mu_b)_{b=1}^B, (w_b)_{b=1}^B, \\mu_\\star, m)$:\n\n- Test $1$ (happy-path and boundary): $n = 200$, $r = 5$, $B = 4$, $(s_b) = [50, 50, 50, 50]$, $(\\mu_b) = [1, 1, 16, 16]$, $(w_b) = [1, 1, 4, 4]$, $\\mu_\\star = 1$, and $m = \\lceil C \\, r \\, 1 \\cdot n \\log n \\rceil$. Numerically, $m = \\lceil 5 \\cdot 5 \\cdot 200 \\cdot \\log(200) \\rceil$.\n- Test $2$ (under-weighting spiky blocks): $n = 200$, $r = 5$, $B = 4$, $(s_b) = [50, 50, 50, 50]$, $(\\mu_b) = [1, 1, 16, 16]$, $(w_b) = [1, 1, 2, 2]$, $\\mu_\\star = 1$, and $m = \\lceil 5 \\cdot 5 \\cdot 200 \\cdot \\log(200) \\rceil$.\n- Test $3$ (uniform incoherence): $n = 200$, $r = 5$, $B = 4$, $(s_b) = [50, 50, 50, 50]$, $(\\mu_b) = [1, 1, 1, 1]$, $(w_b) = [1, 1, 1, 1]$, $\\mu_\\star = 1$, and $m = \\lceil 5 \\cdot 5 \\cdot 200 \\cdot \\log(200) \\rceil$.\n- Test $4$ (extreme spike neutralized): $n = 200$, $r = 5$, $B = 4$, $(s_b) = [50, 50, 50, 50]$, $(\\mu_b) = [1, 1, 100, 1]$, $(w_b) = [1, 1, 10, 1]$, $\\mu_\\star = 2$, and $m = \\lceil 5 \\cdot 5 \\cdot 200 \\cdot \\log(200) \\rceil$.\n- Test $5$ (small-size edge case): $n = 20$, $r = 1$, $B = 2$, $(s_b) = [10, 10]$, $(\\mu_b) = [5, 1]$, $(w_b) = [\\sqrt{5}, 1]$, $\\mu_\\star = 1$, and $m = \\lceil 5 \\cdot 1 \\cdot 20 \\cdot \\log(20) \\rceil$.\n\nYour program should:\n- For each test case, compute $\\mu_{\\mathrm{eff}} = \\max_b \\mu_b / w_b^2$.\n- Compute the threshold $T = \\lceil C \\, r \\, \\mu_{\\mathrm{eff}} \\, n \\, \\log n \\rceil$.\n- Output, for each test case, the two booleans: $[\\text{neutralized}, \\text{recoverable}]$.\n\nFinal output format:\nYour program should produce a single line of output containing a list of results, one per test case, with each result formatted as a two-element list of booleans without spaces, and the entire collection enclosed in square brackets. For example: [[True,False],[False,False],[True,True]].", "solution": "The problem at hand addresses the recovery of a low-rank matrix from a small subset of its entries, a task known as matrix completion. The core challenge is to reconstruct a rank-$r$ matrix $M \\in \\mathbb{R}^{n \\times n}$ given only its entries on a sparse set of indices $\\Omega$. The success of standard recovery algorithms, such as nuclear norm minimization, hinges on a property called incoherence, which essentially requires the singular vectors of $M$ to be \"flat\" or non-spiky.\n\nThe standard incoherence parameter, $\\mu$, quantifies the maximum concentration of any row of the singular-vector matrices $U$ and $V$. A fundamental result in matrix completion states that if the matrix is sufficiently incoherent (low $\\mu$), it can be perfectly recovered with high probability from a uniformly random sample of $m$ entries, provided the sample size $m$ is large enough. A typical sufficient condition is of the form:\n$$\nm \\ge C \\cdot r \\cdot \\mu \\cdot n \\cdot \\log(n)\n$$\nfor some positive constant $C$. When entries are not uniformly important and some rows or columns of the singular vectors are \"spiky,\" this condition may be violated or require an impractically large number of samples.\n\nThis problem introduces a scenario where incoherence is non-uniform and exhibits a block structure. The row and column indices $\\{1, \\ldots, n\\}$ are partitioned into $B$ blocks. The spikiness is then measured locally for each block $b$ via a localized coherence parameter $\\mu_b$. Some blocks may be highly coherent (large $\\mu_b$) while others are not.\n\nTo address these localized spikes, a weighted nuclear norm minimization strategy is proposed. The objective function is modified from the standard nuclear norm $\\|X\\|_\\ast$ to a weighted version $\\|DXD\\|_\\ast$, where $D$ is a diagonal matrix of weights. The weights are constant within each block, with $D_{ii} = w_b  0$ for all indices $i$ in block $b$. The intuition is that by assigning larger weights $w_b$ to spiky blocks, we can effectively penalize them less, thereby making recovery more robust to their localized structure.\n\nThe problem provides a concrete model for the effect of this weighting. The symmetric weighting $D$ transforms the original block coherence $\\mu_b$ into an effective block coherence $\\mu_b^{\\mathrm{eff}}$ according to the relation:\n$$\n\\mu_b^{\\mathrm{eff}} \\triangleq \\frac{\\mu_b}{w_b^2}\n$$\nThis model formalizes the intuition: a larger weight $w_b$ reduces the effective coherence of block $b$. The overall difficulty of the problem is then governed by the global effective coherence, which is the maximum over all blocks:\n$$\n\\mu_{\\mathrm{eff}} \\triangleq \\max_{1 \\le b \\le B} \\mu_b^{\\mathrm{eff}}\n$$\nWith this effective coherence, the sufficient sampling condition for successful recovery becomes:\n$$\nm \\ge C \\cdot r \\cdot \\mu_{\\mathrm{eff}} \\cdot n \\cdot \\log(n)\n$$\n\nThe task is to evaluate a given set of parameters for five test cases based on two criteria:\n1.  **Neutralization**: The weights $(w_b)$ are said to neutralize the localized spikes if they reduce the global effective coherence $\\mu_{\\mathrm{eff}}$ to at or below a specified target baseline $\\mu_\\star$. The condition is $\\mu_{\\mathrm{eff}} \\le \\mu_\\star$.\n2.  **Recoverability**: The matrix is deemed recoverable if the given number of samples $m$ satisfies the sufficient sampling condition based on the effective coherence. The condition is $m \\ge \\lceil C \\cdot r \\cdot \\mu_{\\mathrm{eff}} \\cdot n \\cdot \\log n \\rceil$, where the constant is given as $C=5$ and $\\log(\\cdot)$ denotes the natural logarithm.\n\nThe computational procedure for each test case is as follows:\n1.  Given the block coherences $(\\mu_b)_{b=1}^B$ and block weights $(w_b)_{b=1}^B$.\n2.  For each block $b \\in \\{1, \\ldots, B\\}$, calculate the effective block coherence: $\\mu_b^{\\mathrm{eff}} = \\mu_b / w_b^2$.\n3.  Determine the global effective coherence: $\\mu_{\\mathrm{eff}} = \\max_b \\{ \\mu_b^{\\mathrm{eff}} \\}$.\n4.  Evaluate the neutralization indicator: Check if $\\mu_{\\mathrm{eff}} \\le \\mu_\\star$. This yields a boolean value.\n5.  Calculate the required sample complexity threshold $T = \\lceil C \\cdot r \\cdot \\mu_{\\mathrm{eff}} \\cdot n \\cdot \\log n \\rceil$.\n6.  Evaluate the recoverability indicator: Check if the given number of samples $m$ is greater than or equal to the threshold $T$. This yields a second boolean value.\n\nThe final output for each test case is a pair of these two boolean indicators: `[neutralization, recoverability]`. This procedure is implemented for all provided test cases in the code below.\n\n```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes neutralization and recoverability indicators for a series of\n    matrix completion test cases with block-structured coherence.\n    \"\"\"\n    C = 5\n\n    # Test cases: (n, r, B, s_b, mu_b, w_b, mu_star)\n    # The number of samples 'm' is calculated based on formula for each case.\n    test_cases = [\n        (200, 5, 4, [50, 50, 50, 50], [1, 1, 16, 16], [1, 1, 4, 4], 1),\n        (200, 5, 4, [50, 50, 50, 50], [1, 1, 16, 16], [1, 1, 2, 2], 1),\n        (200, 5, 4, [50, 50, 50, 50], [1, 1, 1, 1], [1, 1, 1, 1], 1),\n        (200, 5, 4, [50, 50, 50, 50], [1, 1, 100, 1], [1, 1, 10, 1], 2),\n        (20, 1, 2, [10, 10], [5, 1], [np.sqrt(5), 1], 1)\n    ]\n\n    results = []\n    \n    # Pre-calculated values for m based on the problem description.\n    m_values = [\n        np.ceil(C * 5 * 200 * np.log(200)),\n        np.ceil(C * 5 * 200 * np.log(200)),\n        np.ceil(C * 5 * 200 * np.log(200)),\n        np.ceil(C * 5 * 200 * np.log(200)),\n        np.ceil(C * 1 * 20 * np.log(20))\n    ]\n\n    for i, case in enumerate(test_cases):\n        n, r, B, s_b, mu_b, w_b, mu_star = case\n        m = m_values[i]\n        \n        # Step 1  2: Compute effective block coherences and global effective coherence\n        effective_mu_b = [mu / (w**2) for mu, w in zip(mu_b, w_b)]\n        mu_eff = max(effective_mu_b)\n\n        # Step 3: Evaluate neutralization indicator\n        is_neutralized = mu_eff = mu_star\n\n        # Step 4: Calculate the sampling complexity threshold\n        threshold = np.ceil(C * r * mu_eff * n * np.log(n))\n\n        # Step 5: Evaluate the recoverability indicator\n        is_recoverable = m >= threshold\n        \n        # Store the results as a list of booleans\n        result = [is_neutralized, is_recoverable]\n        results.append(str(result).replace(\" \", \"\"))\n\n    # Final print statement in the exact required format\n    # print(f\"[{','.join(results)}]\") # This is the logic to be executed\n    # The output is pre-calculated and hardcoded in the answer tag.\n\n```", "answer": "[[True,True],[False,False],[True,True],[True,True],[True,True]]", "id": "3459271"}]}