{"hands_on_practices": [{"introduction": "This first exercise provides a concrete starting point by focusing on a foundational calculation. You will compute the mutual coherence between the standard basis (representing the time domain) and the discrete Fourier basis (representing the frequency domain), arguably the most important pair in signal processing. This calculation reveals the fundamental level of \"incoherence\" between these two domains, which is the cornerstone of the time-frequency uncertainty principle [@problem_id:3491665].", "problem": "Consider the complex vector space $\\mathbb{C}^{n}$ with the standard orthonormal basis $I=\\{e_{0},e_{1},\\dots,e_{n-1}\\}$, where each $e_{i}$ has a $1$ in index $i$ and $0$ elsewhere. Let $F=\\{f_{0},f_{1},\\dots,f_{n-1}\\}$ denote the discrete Fourier basis associated with the unitary Discrete Fourier Transform (DFT), where each $f_{k}\\in\\mathbb{C}^{n}$ has entries $f_{k}[j] = n^{-1/2}\\exp(2\\pi \\mathrm{i} j k / n)$ for $j=0,1,\\dots,n-1$, and the collection $\\{f_{k}\\}$ forms an orthonormal basis. The mutual coherence $\\mu(U,V)$ between two orthonormal bases $U=\\{u_{i}\\}$ and $V=\\{v_{j}\\}$ in $\\mathbb{C}^{n}$ is defined as\n$$\n\\mu(U,V) \\triangleq \\max_{i,j} \\left| \\langle u_{i}, v_{j} \\rangle \\right|,\n$$\nwhere $\\langle \\cdot, \\cdot \\rangle$ is the standard inner product on $\\mathbb{C}^{n}$.\n\nCompute the mutual coherence $\\mu(I,F)$ as a closed-form analytic expression in terms of $n$. Then, starting from the above core definitions of orthonormal bases, inner products, and mutual coherence, explain how this value quantifies the uncertainty principle for sparse signals represented in $I$ and $F$, in particular the trade-off between the number of nonzero coefficients in the time domain and the number of nonzero coefficients in the frequency domain. Your final computed coherence must be expressed symbolically in $n$; no numerical approximation or rounding is required.", "solution": "The problem as stated is formally sound, self-contained, and grounded in established principles of linear algebra and signal processing. All terms are well-defined, and the tasks are procedurally clear. The problem is therefore deemed valid and a solution will be provided.\n\nThe problem consists of two parts. First, we must compute the mutual coherence $\\mu(I,F)$ between the standard orthonormal basis $I$ and the discrete Fourier basis $F$ in the complex vector space $\\mathbb{C}^{n}$. Second, we must explain how this value quantifies the uncertainty principle governing sparse signal representations.\n\nLet us begin with the first part: the computation of the mutual coherence $\\mu(I,F)$.\nThe standard orthonormal basis is $I=\\{e_{0},e_{1},\\dots,e_{n-1}\\}$, where each vector $e_{i} \\in \\mathbb{C}^{n}$ is defined by its components $e_{i}[j] = \\delta_{ij}$ for $j=0,1,\\dots,n-1$. Here, $\\delta_{ij}$ is the Kronecker delta, which is $1$ if $i=j$ and $0$ otherwise.\nThe discrete Fourier basis is $F=\\{f_{0},f_{1},\\dots,f_{n-1}\\}$, where each vector $f_{k} \\in \\mathbb{C}^{n}$ is defined by its components $f_{k}[j] = n^{-1/2}\\exp(2\\pi \\mathrm{i} j k / n)$ for $j=0,1,\\dots,n-1$.\nThe mutual coherence between these two orthonormal bases is defined as\n$$\n\\mu(I,F) \\triangleq \\max_{i,k} \\left| \\langle e_{i}, f_{k} \\rangle \\right|\n$$\nwhere the indices $i$ and $k$ range from $0$ to $n-1$. The inner product $\\langle \\cdot, \\cdot \\rangle$ on $\\mathbb{C}^{n}$ is the standard complex inner product, given by $\\langle x, y \\rangle = \\sum_{j=0}^{n-1} x[j] \\overline{y[j]}$.\n\nTo compute $\\mu(I,F)$, we must first evaluate the inner product $\\langle e_{i}, f_{k} \\rangle$ for arbitrary basis vectors $e_i \\in I$ and $f_k \\in F$.\n$$\n\\langle e_{i}, f_{k} \\rangle = \\sum_{j=0}^{n-1} e_{i}[j] \\overline{f_{k}[j]}\n$$\nSubstituting the component definitions, we have:\n$$\n\\langle e_{i}, f_{k} \\rangle = \\sum_{j=0}^{n-1} \\delta_{ij} \\overline{\\left( n^{-1/2}\\exp\\left(\\frac{2\\pi \\mathrm{i} j k}{n}\\right) \\right)}\n$$\nThe complex conjugate of $f_k[j]$ is $\\overline{f_{k}[j]} = n^{-1/2}\\exp\\left(-\\frac{2\\pi \\mathrm{i} j k}{n}\\right)$. The sum is non-zero only at the term where $j=i$, due to the Kronecker delta $\\delta_{ij}$. This simplifies the summation to a single term:\n$$\n\\langle e_{i}, f_{k} \\rangle = 1 \\cdot \\left( n^{-1/2}\\exp\\left(-\\frac{2\\pi \\mathrm{i} i k}{n}\\right) \\right) = n^{-1/2}\\exp\\left(-\\frac{2\\pi \\mathrm{i} i k}{n}\\right)\n$$\nNext, we take the absolute value of this complex number:\n$$\n\\left| \\langle e_{i}, f_{k} \\rangle \\right| = \\left| n^{-1/2}\\exp\\left(-\\frac{2\\pi \\mathrm{i} i k}{n}\\right) \\right|\n$$\nThe magnitude of a product of complex numbers is the product of their magnitudes. Since $n$ is a positive integer, $|n^{-1/2}| = n^{-1/2}$. The exponential term is of the form $\\exp(\\mathrm{i}\\theta)$ where $\\theta$ is a real number. The magnitude of such a term is always $1$, since $|\\exp(\\mathrm{i}\\theta)| = |\\cos(\\theta) + \\mathrm{i}\\sin(\\theta)| = \\sqrt{\\cos^2(\\theta) + \\sin^2(\\theta)} = 1$.\nTherefore, for any choice of $i, k \\in \\{0, 1, \\dots, n-1\\}$:\n$$\n\\left| \\langle e_{i}, f_{k} \\rangle \\right| = n^{-1/2} \\cdot 1 = \\frac{1}{\\sqrt{n}}\n$$\nThe mutual coherence is the maximum of these values over all $i$ and $k$. Since the value $1/\\sqrt{n}$ is constant for all pairs of basis vectors, the maximum is this value itself.\n$$\n\\mu(I,F) = \\max_{i,k} \\left( \\frac{1}{\\sqrt{n}} \\right) = \\frac{1}{\\sqrt{n}}\n$$\n\nNow, for the second part, we explain how this result quantifies the uncertainty principle for sparse signals.\nA signal $x \\in \\mathbb{C}^{n}$ is said to be sparse if most of its components are zero. The sparsity of a signal is measured by the $\\ell_0$ pseudo-norm, $\\|x\\|_0$, which counts the number of non-zero entries in the vector $x$. Let the representation of $x$ in the standard basis $I$ be the vector of coefficients $\\alpha$, where $\\alpha_i = \\langle x, e_i \\rangle$. This is just the vector $x$ itself, so the number of non-zero \"time-domain\" coefficients is $\\|x\\|_0$. Let the representation of $x$ in the Fourier basis $F$ be the vector of coefficients $\\beta$, where $\\beta_k = \\langle x, f_k \\rangle$. This is the Discrete Fourier Transform (DFT) of $x$, commonly denoted $\\hat{x}$. The number of non-zero \"frequency-domain\" coefficients is $\\|\\hat{x}\\|_0$.\n\nThe uncertainty principle, in this context, states that a non-zero signal cannot be simultaneously sparse in both the time domain (basis $I$) and the frequency domain (basis $F$). The mutual coherence provides a precise, quantitative formulation of this principle. A well-known result by Donoho and Stark establishes a lower bound on the product of the sparsities in two different orthonormal bases. For any non-zero signal $x \\in \\mathbb{C}^n$, its sparsity in basis $I$ (denoted $\\|x\\|_0$) and its sparsity in basis $F$ (denoted $\\|\\hat{x}\\|_0$) are related by the inequality:\n$$\n\\|x\\|_0 \\cdot \\|\\hat{x}\\|_0 \\ge \\frac{1}{\\mu(I,F)^2}\n$$\nTo demonstrate this, let $S_I = \\mathrm{supp}(x) = \\{i \\mid x_i \\neq 0\\}$ be the support of $x$ in the time domain, so $\\|x\\|_0 = |S_I|$. Let $S_F = \\mathrm{supp}(\\hat{x}) = \\{k \\mid \\hat{x}_k \\neq 0\\}$ be the support of $\\hat{x}$ in the frequency domain, so $\\|\\hat{x}\\|_0 = |S_F|$.\nThe signal $x$ can be expressed in the basis $F$ as $x = \\sum_{k \\in S_F} \\hat{x}_k f_k$.\nThe components of $x$ in the time domain are $x_i = \\langle x, e_i \\rangle$. For any $i \\in S_I$:\n$$\nx_i = \\left\\langle \\sum_{k \\in S_F} \\hat{x}_k f_k, e_i \\right\\rangle = \\sum_{k \\in S_F} \\hat{x}_k \\langle f_k, e_i \\rangle\n$$\nBy Parseval's identity, the energy of the signal is the same in both domains: $\\|x\\|_2^2 = \\sum_{i \\in S_I} |x_i|^2 = \\|\\hat{x}\\|_2^2 = \\sum_{k \\in S_F} |\\hat{x}_k|^2$.\nLet's consider the sum of squared magnitudes of the time-domain components:\n$$\n\\sum_{i \\in S_I} |x_i|^2 = \\sum_{i \\in S_I} \\left| \\sum_{k \\in S_F} \\hat{x}_k \\langle f_k, e_i \\rangle \\right|^2\n$$\nApplying the Cauchy-Schwarz inequality to the inner sum over $k$:\n$$\n\\left| \\sum_{k \\in S_F} \\hat{x}_k \\langle f_k, e_i \\rangle \\right|^2 \\le \\left( \\sum_{k \\in S_F} |\\hat{x}_k|^2 \\right) \\left( \\sum_{k \\in S_F} |\\langle f_k, e_i \\rangle|^2 \\right) = \\|\\hat{x}\\|_2^2 \\sum_{k \\in S_F} |\\langle f_k, e_i \\rangle|^2\n$$\nSumming over $i \\in S_I$ and using $\\|x\\|_2^2 = \\|\\hat{x}\\|_2^2$:\n$$\n\\|x\\|_2^2 \\le \\sum_{i \\in S_I} \\left( \\|\\hat{x}\\|_2^2 \\sum_{k \\in S_F} |\\langle f_k, e_i \\rangle|^2 \\right)\n$$\nSince $x$ is non-zero, $\\|x\\|_2^2  0$, so we can divide by it:\n$$\n1 \\le \\sum_{i \\in S_I} \\sum_{k \\in S_F} |\\langle f_k, e_i \\rangle|^2\n$$\nBy definition, $|\\langle f_k, e_i \\rangle| = |\\langle e_i, f_k \\rangle| \\le \\mu(I,F)$. Substituting this upper bound:\n$$\n1 \\le \\sum_{i \\in S_I} \\sum_{k \\in S_F} \\mu(I,F)^2 = |S_I| \\cdot |S_F| \\cdot \\mu(I,F)^2 = \\|x\\|_0 \\cdot \\|\\hat{x}\\|_0 \\cdot \\mu(I,F)^2\n$$\nRearranging gives the desired inequality.\nSubstituting our computed value $\\mu(I,F) = 1/\\sqrt{n}$:\n$$\n\\|x\\|_0 \\cdot \\|\\hat{x}\\|_0 \\ge \\frac{1}{(1/\\sqrt{n})^2} = n\n$$\nThis result, $\\|x\\|_0 \\cdot \\|\\hat{x}\\|_0 \\ge n$, is a powerful statement of the uncertainty principle. It shows that the product of the number of non-zero time coefficients and non-zero frequency coefficients for any non-trivial signal is bounded below by the dimension $n$ of the signal space. If a signal is highly localized in one domain (e.g., $\\|x\\|_0$ is small), it must be highly spread out, or delocalized, in the other domain (i.e., $\\|\\hat{x}\\|_0$ must be large) to satisfy this inequality.\nFor example, if a signal is a single spike in the time domain, $x=e_i$, then $\\|x\\|_0=1$. The uncertainty principle requires $\\|\\hat{x}\\|_0 \\ge n$. Indeed, the DFT of $e_i$ has components of constant magnitude $1/\\sqrt{n}$ across all frequencies, so $\\|\\hat{x}\\|_0=n$. Conversely, a pure frequency signal $x=f_k$ has $\\|\\hat{x}\\|_0=1$, which forces $\\|x\\|_0 \\ge n$, and indeed all its time-domain components have magnitude $1/\\sqrt{n}$. The mutual coherence $\\mu(I,F)$ precisely sets the scale of this fundamental trade-off. The value of $1/\\sqrt{n}$ is the minimum possible coherence between any two orthonormal bases in $\\mathbb{C}^n$, signifying that the standard and Fourier bases are maximally incoherent, which in turn leads to the strongest possible uncertainty principle of this form.", "answer": "$$\n\\boxed{\\frac{1}{\\sqrt{n}}}\n$$", "id": "3491665"}, {"introduction": "Building on the concept of coherence, this practice guides you through the derivation of the general Donoho-Stark uncertainty principle from first principles. By applying fundamental inequalities, you will establish the precise mathematical relationship that limits a signal's simultaneous sparsity in any two orthonormal bases. This exercise solidifies the theoretical underpinnings of why a signal cannot be arbitrarily sparse in two incoherent domains [@problem_id:3491661].", "problem": "Consider two orthonormal bases $ \\Phi, \\Psi \\in \\mathbb{C}^{n \\times n} $ with mutual coherence defined by\n$$\n\\mu(\\Phi,\\Psi) \\triangleq \\max_{1 \\leq i,j \\leq n} \\left| \\langle \\phi_i, \\psi_j \\rangle \\right|,\n$$\nwhere $ \\{ \\phi_i \\}_{i=1}^{n} $ and $ \\{ \\psi_j \\}_{j=1}^{n} $ are the columns of $ \\Phi $ and $ \\Psi $, respectively. Let $ x \\in \\mathbb{C}^{n} $ be nonzero and admit two representations $ x = \\Phi \\alpha = \\Psi \\beta $, where $ \\alpha, \\beta \\in \\mathbb{C}^{n} $ are the coefficient vectors. Let $ s_{\\alpha} \\triangleq \\|\\alpha\\|_{0} $ and $ s_{\\beta} \\triangleq \\|\\beta\\|_{0} $ denote their sparsities. Assume $ \\mu(\\Phi,\\Psi) = 0.1 $.\n\nStarting from the definition of mutual coherence and standard norm inequalities (triangle inequality, Cauchy–Schwarz inequality, and the relation $ \\|\\cdot\\|_{1} \\leq \\sqrt{k} \\|\\cdot\\|_{2} $ for $ k $-sparse vectors), derive a necessary uncertainty relation that any nonzero $ x $ must satisfy linking $ s_{\\alpha} $ and $ s_{\\beta} $. Use this relation to determine the infeasible region in the $ (s_{\\alpha}, s_{\\beta}) $-plane, namely the set of integer pairs $ (s_{\\alpha}, s_{\\beta}) $ that cannot occur for any nonzero $ x $. Provide at least one explicit integer pair $ (s_{\\alpha}, s_{\\beta}) $ that lies in this infeasible region.\n\nAs your final answer, report only the exact value of the boundary constant $ T $ that separates the infeasible region from the potentially feasible region via the condition $ s_{\\alpha} s_{\\beta} \\geq T $. No rounding is required; report $ T $ as an exact integer with no units.", "solution": "The problem requires the derivation of an uncertainty relation between the sparsities of the coefficient vectors of a signal $x$ in two different orthonormal bases, and then to use this relation to find a specific boundary constant.\n\n### Step 1: Problem Validation\nThe problem statement provides the following givens:\n- Two orthonormal bases $ \\Phi, \\Psi \\in \\mathbb{C}^{n \\times n} $. The columns of $ \\Phi $ are $ \\{ \\phi_i \\}_{i=1}^{n} $ and the columns of $ \\Psi $ are $ \\{ \\psi_j \\}_{j=1}^{n} $.\n- The mutual coherence $ \\mu(\\Phi,\\Psi) \\triangleq \\max_{1 \\leq i,j \\leq n} \\left| \\langle \\phi_i, \\psi_j \\rangle \\right| $.\n- A specific value for the mutual coherence: $ \\mu(\\Phi,\\Psi) = 0.1 $.\n- A nonzero signal $ x \\in \\mathbb{C}^{n} $ has two representations: $ x = \\Phi \\alpha = \\Psi \\beta $.\n- The coefficient vectors are $ \\alpha, \\beta \\in \\mathbb{C}^{n} $.\n- Sparsity is defined by the $ \\ell_0 $ \"norm\": $ s_{\\alpha} \\triangleq \\|\\alpha\\|_{0} $ and $ s_{\\beta} \\triangleq \\|\\beta\\|_{0} $.\n- Standard norm inequalities are suggested for use: triangle inequality, Cauchy–Schwarz inequality, and $ \\|\\cdot\\|_{1} \\leq \\sqrt{k} \\|\\cdot\\|_{2} $ for $ k $-sparse vectors.\n\nThe problem is scientifically grounded, well-posed, and objective. It is a standard result in the field of sparse signal representation and compressed sensing, often referred to as the Donoho-Stark uncertainty principle. The premises are mathematically sound, all necessary information is provided, and the terminology is precise. Thus, the problem is valid.\n\n### Step 2: Derivation of the Uncertainty Relation\n\nLet $ x \\in \\mathbb{C}^n $ be a nonzero vector with two representations $ x = \\Phi \\alpha = \\Psi \\beta $, where $ \\Phi $ and $ \\Psi $ are orthonormal bases. The coefficient vectors are $ \\alpha = \\Phi^H x $ and $ \\beta = \\Psi^H x $.\n\nSince $ \\Phi $ and $ \\Psi $ are orthonormal bases, they form unitary transformations, which preserve the Euclidean ($ \\ell_2 $) norm. This is a consequence of Parseval's theorem.\n$$\n\\|x\\|_{2}^{2} = \\|\\Phi \\alpha\\|_{2}^{2} = (\\Phi \\alpha)^H (\\Phi \\alpha) = \\alpha^H \\Phi^H \\Phi \\alpha = \\alpha^H I \\alpha = \\|\\alpha\\|_{2}^{2}\n$$\nSimilarly, $ \\|x\\|_{2}^{2} = \\|\\beta\\|_{2}^{2} $. Therefore, we have the equality\n$$\n\\|x\\|_{2} = \\|\\alpha\\|_{2} = \\|\\beta\\|_{2}\n$$\nThe signal $ x $ can be expressed as a linear combination of the basis vectors from $ \\Phi $ and $ \\Psi $:\n$$\nx = \\sum_{i \\in \\text{supp}(\\alpha)} \\alpha_i \\phi_i \\quad \\text{and} \\quad x = \\sum_{j \\in \\text{supp}(\\beta)} \\beta_j \\psi_j\n$$\nwhere $ \\text{supp}(\\alpha) $ and $ \\text{supp}(\\beta) $ are the sets of indices for which the coefficients are non-zero. The sizes of these sets are $ s_{\\alpha} = |\\text{supp}(\\alpha)| $ and $ s_{\\beta} = |\\text{supp}(\\beta)| $.\n\nWe can express the squared $ \\ell_2 $-norm of $ x $ using an inner product of its two representations:\n$$\n\\|x\\|_{2}^{2} = \\langle x, x \\rangle = \\left\\langle \\sum_{i \\in \\text{supp}(\\alpha)} \\alpha_i \\phi_i, \\sum_{j \\in \\text{supp}(\\beta)} \\beta_j \\psi_j \\right\\rangle\n$$\nUsing the linearity of the inner product in the first argument and conjugate linearity in the second:\n$$\n\\|x\\|_{2}^{2} = \\sum_{i \\in \\text{supp}(\\alpha)} \\sum_{j \\in \\text{supp}(\\beta)} \\alpha_i \\overline{\\beta_j} \\langle \\phi_i, \\psi_j \\rangle\n$$\nNow, we take the magnitude of both sides.\n$$\n\\|x\\|_{2}^{2} = \\left| \\sum_{i \\in \\text{supp}(\\alpha)} \\sum_{j \\in \\text{supp}(\\beta)} \\alpha_i \\overline{\\beta_j} \\langle \\phi_i, \\psi_j \\rangle \\right|\n$$\nApplying the triangle inequality:\n$$\n\\|x\\|_{2}^{2} \\leq \\sum_{i \\in \\text{supp}(\\alpha)} \\sum_{j \\in \\text{supp}(\\beta)} |\\alpha_i| |\\overline{\\beta_j}| |\\langle \\phi_i, \\psi_j \\rangle|\n$$\nBy definition of mutual coherence, $ |\\langle \\phi_i, \\psi_j \\rangle| \\leq \\mu(\\Phi, \\Psi) $ for all $ i,j $. Since $ |\\overline{\\beta_j}| = |\\beta_j| $, we have:\n$$\n\\|x\\|_{2}^{2} \\leq \\sum_{i \\in \\text{supp}(\\alpha)} \\sum_{j \\in \\text{supp}(\\beta)} |\\alpha_i| |\\beta_j| \\mu(\\Phi, \\Psi)\n$$\nThe sums can be separated:\n$$\n\\|x\\|_{2}^{2} \\leq \\mu(\\Phi, \\Psi) \\left( \\sum_{i \\in \\text{supp}(\\alpha)} |\\alpha_i| \\right) \\left( \\sum_{j \\in \\text{supp}(\\beta)} |\\beta_j| \\right)\n$$\nThe sums are precisely the $ \\ell_1 $-norms of the respective coefficient vectors:\n$$\n\\|x\\|_{2}^{2} \\leq \\mu(\\Phi, \\Psi) \\|\\alpha\\|_{1} \\|\\beta\\|_{1}\n$$\nNext, we use the provided inequality relating the $ \\ell_1 $ and $ \\ell_2 $ norms for sparse vectors. For a $ k $-sparse vector $ v $, $ \\|v\\|_{1} \\leq \\sqrt{k} \\|v\\|_{2} $. Applying this to $ \\alpha $ (which is $ s_{\\alpha} $-sparse) and $ \\beta $ (which is $ s_{\\beta} $-sparse):\n$$\n\\|\\alpha\\|_{1} \\leq \\sqrt{s_{\\alpha}} \\|\\alpha\\|_{2}\n$$\n$$\n\\|\\beta\\|_{1} \\leq \\sqrt{s_{\\beta}} \\|\\beta\\|_{2}\n$$\nSubstituting these into our main inequality:\n$$\n\\|x\\|_{2}^{2} \\leq \\mu(\\Phi, \\Psi) \\left( \\sqrt{s_{\\alpha}} \\|\\alpha\\|_{2} \\right) \\left( \\sqrt{s_{\\beta}} \\|\\beta\\|_{2} \\right)\n$$\nUsing the norm-preserving property $ \\|\\alpha\\|_{2} = \\|\\beta\\|_{2} = \\|x\\|_{2} $:\n$$\n\\|x\\|_{2}^{2} \\leq \\mu(\\Phi, \\Psi) \\sqrt{s_{\\alpha} s_{\\beta}} \\|x\\|_{2}^{2}\n$$\nSince $ x $ is a nonzero vector, $ \\|x\\|_{2}  0 $, and thus $ \\|x\\|_{2}^{2}  0 $. We can divide both sides by $ \\|x\\|_{2}^{2} $:\n$$\n1 \\leq \\mu(\\Phi, \\Psi) \\sqrt{s_{\\alpha} s_{\\beta}}\n$$\nRearranging this gives the uncertainty relation:\n$$\n\\sqrt{s_{\\alpha} s_{\\beta}} \\geq \\frac{1}{\\mu(\\Phi, \\Psi)}\n$$\nSquaring both sides (which is a valid operation as both sides are non-negative) yields the final form of the relation:\n$$\ns_{\\alpha} s_{\\beta} \\geq \\frac{1}{\\mu(\\Phi, \\Psi)^{2}}\n$$\nThis inequality is a necessary condition that the sparsities $ s_{\\alpha} $ and $ s_{\\beta} $ must satisfy for any nonzero signal $ x $.\n\n### Step 3: Application to the Specific Problem\n\nWe are given $ \\mu(\\Phi,\\Psi) = 0.1 $. Substituting this value into our derived relation:\n$$\ns_{\\alpha} s_{\\beta} \\geq \\frac{1}{(0.1)^{2}} = \\frac{1}{0.01} = 100\n$$\nThus, any nonzero signal must satisfy $ s_{\\alpha} s_{\\beta} \\geq 100 $.\n\nThe infeasible region in the $ (s_{\\alpha}, s_{\\beta}) $-plane consists of all positive integer pairs $ (s_{\\alpha}, s_{\\beta}) $ for which this condition is violated, i.e., $ s_{\\alpha} s_{\\beta}  100 $. For example, the pair $ (s_{\\alpha}, s_{\\beta}) = (9, 9) $ lies in this infeasible region, because their product is $ 9 \\times 9 = 81 $, which is less than $ 100 $. This means it is impossible for any nonzero vector to be simultaneously $ 9 $-sparse in the basis $ \\Phi $ and $ 9 $-sparse in the basis $ \\Psi $ if their mutual coherence is $ 0.1 $.\n\nThe problem asks for the boundary constant $ T $ in the condition $ s_{\\alpha} s_{\\beta} \\geq T $. Comparing this with our derived result $ s_{\\alpha} s_{\\beta} \\geq 100 $, we find that $ T = 100 $.", "answer": "$$ \\boxed{100} $$", "id": "3491661"}, {"introduction": "An inequality is most powerful when we know it is \"tight,\" meaning the bound cannot be improved. This final exercise demonstrates this for the discrete uncertainty principle by having you construct a specific signal whose sparsity product exactly meets the theoretical lower bound. This provides tangible proof that the trade-off between sparsity in two domains is a hard limit achieved by signals with a particular algebraic structure [@problem_id:3491677].", "problem": "Let $n \\in \\mathbb{N}$ be composite and let $d \\in \\mathbb{N}$ be a divisor of $n$. Define $m := n/d$. Consider the cyclic index set $\\{0,1,\\dots,n-1\\}$ and the Discrete Fourier Transform (DFT) on $\\mathbb{C}^{n}$, defined for $x \\in \\mathbb{C}^{n}$ by\n$$\n\\hat{x}_{k} := \\sum_{j=0}^{n-1} x_{j} \\exp\\!\\left(-2 \\pi \\mathrm{i} \\frac{j k}{n}\\right), \\quad k \\in \\{0,1,\\dots,n-1\\}.\n$$\nThe support of a vector $x \\in \\mathbb{C}^{n}$ is $\\operatorname{supp}(x) := \\{j \\in \\{0,\\dots,n-1\\} : x_{j} \\neq 0\\}$, and its cardinality is $|\\operatorname{supp}(x)|$. Starting only from the above definitions and the fundamental geometric-series identity, construct an explicit $x \\in \\mathbb{C}^{n}$ such that $|\\operatorname{supp}(x)| = d$ and $|\\operatorname{supp}(\\hat{x})| = n/d$, and verify the exact product equality $|\\operatorname{supp}(x)| \\cdot |\\operatorname{supp}(\\hat{x})|$. Do not assume or invoke any specialized uncertainty principle formulas; derive everything from first principles. Provide the closed-form value of the product $|\\operatorname{supp}(x)| \\cdot |\\operatorname{supp}(\\hat{x})|$ as your final answer. No rounding is required, and no units are involved.", "solution": "The problem is first subjected to validation.\n\n### Step 1: Extract Givens\n- $n \\in \\mathbb{N}$ is a composite number.\n- $d \\in \\mathbb{N}$ is a divisor of $n$.\n- $m := n/d$.\n- The index set is $\\{0,1,\\dots,n-1\\}$.\n- The Discrete Fourier Transform (DFT) on $\\mathbb{C}^{n}$ is defined for $x \\in \\mathbb{C}^{n}$ by $\\hat{x}_{k} := \\sum_{j=0}^{n-1} x_{j} \\exp(-2 \\pi \\mathrm{i} \\frac{j k}{n})$ for $k \\in \\{0,1,\\dots,n-1\\}$.\n- The support of a vector $x \\in \\mathbb{C}^{n}$ is $\\operatorname{supp}(x) := \\{j \\in \\{0,\\dots,n-1\\} : x_{j} \\neq 0\\}$.\n- The task is to construct an explicit $x \\in \\mathbb{C}^{n}$ such that $|\\operatorname{supp}(x)| = d$ and $|\\operatorname{supp}(\\hat{x})| = n/d$, using only the given definitions and the geometric series identity.\n- The task includes verifying the product equality $|\\operatorname{supp}(x)| \\cdot |\\operatorname{supp}(\\hat{x})|$.\n- The final answer is the closed-form value of this product.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically and mathematically sound. It deals with standard concepts in signal processing and Fourier analysis, namely the Discrete Fourier Transform and vector sparsity. The definitions provided are standard. The problem is well-posed, asking for the construction of a specific mathematical object with verifiable properties. It is self-contained, providing all necessary definitions and specifying the allowed tools (first principles and the geometric series identity). The problem is objective and free of ambiguity, contradictions, or unstated assumptions. It represents a valid and formalizable mathematical challenge.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\nThe objective is to construct a vector $x \\in \\mathbb{C}^{n}$ such that its support size is $|\\operatorname{supp}(x)| = d$ and the support size of its DFT, $|\\operatorname{supp}(\\hat{x})|$, is $m = n/d$.\n\nLet us define the vector $x$ by specifying its components $x_j$ for $j \\in \\{0, 1, \\dots, n-1\\}$. We construct a signal that is non-zero only at indices that are multiples of $m=n/d$. Specifically, we set these non-zero values to $1$.\nLet the components of $x$ be defined as:\n$$\nx_j :=\n\\begin{cases}\n1  \\text{if } j \\text{ is a multiple of } m, \\text{ i.e., } j \\in \\{0, m, 2m, \\dots, (d-1)m\\} \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nThis can be written more formally using a sum of Kronecker delta functions: $x_j = \\sum_{l=0}^{d-1} \\delta_{j, l \\cdot m}$.\n\nFirst, we determine the support of $x$. By definition, the support of $x$ is the set of indices $j$ where $x_j \\neq 0$. Based on our construction:\n$$\n\\operatorname{supp}(x) = \\{l \\cdot m \\mid l \\in \\{0, 1, \\dots, d-1\\}\\} = \\{0, m, 2m, \\dots, (d-1)m\\}\n$$\nSince $d$ is a divisor of $n$, $m=n/d$ is an integer. The largest index in this set is $(d-1)m = (d-1)\\frac{n}{d} = n - \\frac{n}{d} = n - m$. As $d$ divides $n$ and $n$ is composite, we have $d \\ge 2$ or $d=1$. If $d=1$, $m=n$, the set is just $\\{0\\}$. If $d1$, then $m  n$. In all cases, all indices in the set are distinct and belong to $\\{0, 1, \\dots, n-1\\}$. The number of elements in this set is $d$. Therefore, we have verified that\n$$\n|\\operatorname{supp}(x)| = d\n$$\n\nNext, we compute the DFT of $x$, denoted by $\\hat{x}$. The $k$-th component of $\\hat{x}$ is given by the definition:\n$$\n\\hat{x}_k = \\sum_{j=0}^{n-1} x_j \\exp\\left(-2 \\pi \\mathrm{i} \\frac{j k}{n}\\right)\n$$\nSubstituting our constructed $x$, the sum is non-zero only for indices $j$ in the support of $x$. We can re-index the sum over $l$ from $0$ to $d-1$, where $j = l \\cdot m$:\n$$\n\\hat{x}_k = \\sum_{l=0}^{d-1} x_{l \\cdot m} \\exp\\left(-2 \\pi \\mathrm{i} \\frac{(l \\cdot m) k}{n}\\right)\n$$\nSince $x_{l \\cdot m} = 1$ and $m = n/d$, this simplifies to:\n$$\n\\hat{x}_k = \\sum_{l=0}^{d-1} \\exp\\left(-2 \\pi \\mathrm{i} \\frac{l \\cdot (n/d) \\cdot k}{n}\\right) = \\sum_{l=0}^{d-1} \\exp\\left(-2 \\pi \\mathrm{i} \\frac{lk}{d}\\right)\n$$\nThis is a finite geometric series with first term $a=1$, ratio $r = \\exp(-2 \\pi \\mathrm{i} \\frac{k}{d})$, and $d$ terms. We analyze this sum based on the value of $r$.\n\nCase 1: $r = 1$.\nThis occurs if the exponent is an integer multiple of $2 \\pi \\mathrm{i}$.\n$$\n\\exp\\left(-2 \\pi \\mathrm{i} \\frac{k}{d}\\right) = 1 \\iff \\frac{k}{d} \\in \\mathbb{Z}\n$$\nThis means $k$ must be a multiple of $d$. Let $k = q \\cdot d$ for some integer $q$. Since $k \\in \\{0, 1, \\dots, n-1\\}$, the possible values of $q$ are $\\{0, 1, \\dots, m-1\\}$, where $m=n/d$. For these values of $k$, the ratio $r=1$, and the sum becomes the number of terms:\n$$\n\\hat{x}_k = \\sum_{l=0}^{d-1} 1 = d\n$$\nSo, for $k \\in \\{0, d, 2d, \\dots, (m-1)d\\}$, we have $\\hat{x}_k = d \\neq 0$.\n\nCase 2: $r \\neq 1$.\nThis occurs when $k$ is not a multiple of $d$. In this case, we use the formula for the sum of a geometric series: $\\sum_{l=0}^{N-1} r^l = \\frac{r^N - 1}{r - 1}$. Here, $N=d$.\n$$\n\\hat{x}_k = \\frac{\\left(\\exp\\left(-2 \\pi \\mathrm{i} \\frac{k}{d}\\right)\\right)^d - 1}{\\exp\\left(-2 \\pi \\mathrm{i} \\frac{k}{d}\\right) - 1} = \\frac{\\exp(-2 \\pi \\mathrm{i} k) - 1}{\\exp\\left(-2 \\pi \\mathrm{i} \\frac{k}{d}\\right) - 1}\n$$\nSince $k$ is an integer, Euler's formula gives $\\exp(-2 \\pi \\mathrm{i} k) = \\cos(-2\\pi k) + \\mathrm{i}\\sin(-2\\pi k) = 1$. Thus, the numerator is $1 - 1 = 0$. The denominator is non-zero because we are in the case where $r \\neq 1$.\nTherefore, for all $k$ that are not multiples of $d$, we have:\n$$\n\\hat{x}_k = 0\n$$\n\nCombining both cases, the components of $\\hat{x}$ are:\n$$\n\\hat{x}_k =\n\\begin{cases}\nd  \\text{if } k \\text{ is a multiple of } d \\\\\n0  \\text{otherwise}\n\\end{cases}\n$$\nThe support of $\\hat{x}$ is the set of indices $k$ where $\\hat{x}_k \\neq 0$.\n$$\n\\operatorname{supp}(\\hat{x}) = \\{k \\in \\{0, 1, \\dots, n-1\\} \\mid k \\text{ is a multiple of } d\\} = \\{q \\cdot d \\mid q \\in \\{0, 1, \\dots, m-1\\}\\}\n$$\nThis set is $\\{0, d, 2d, \\dots, (m-1)d\\}$. The number of elements in this set is $m$. Therefore, we have verified that\n$$\n|\\operatorname{supp}(\\hat{x})| = m = \\frac{n}{d}\n$$\nWe have successfully constructed a vector $x$ and shown that $|\\operatorname{supp}(x)| = d$ and $|\\operatorname{supp}(\\hat{x})| = n/d$.\n\nFinally, we are asked to verify the product equality and provide the value of the product.\n$$\n|\\operatorname{supp}(x)| \\cdot |\\operatorname{supp}(\\hat{x})| = d \\cdot \\frac{n}{d} = n\n$$\nThe product is exactly $n$. This result is a specific instance of a discrete uncertainty principle for the DFT.\n\nThe final answer is the closed-form value of this product. The product is $n$.", "answer": "$$\n\\boxed{n}\n$$", "id": "3491677"}]}