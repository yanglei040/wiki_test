{"hands_on_practices": [{"introduction": "The computational advantage of Toeplitz and circulant matrices is rooted in their connection to convolution, which can be computed efficiently via the Fast Fourier Transform (FFT). This exercise provides a foundational hands-on implementation of this principle. You will develop routines to compute the matrix-vector products $A x$ and $A^* y$ for a subsampled circulant matrix, not by forming the matrix explicitly, but by leveraging the Convolution Theorem to work in the Fourier domain. Mastering this technique is the first step toward building scalable algorithms for large-scale signal processing and inverse problems [@problem_id:3490937].", "problem": "You are given an $n \\times n$ circulant sensing matrix $C(g)$ generated by a vector $g \\in \\mathbb{C}^n$, and a sampling operator $P \\in \\{0,1\\}^{m \\times n}$ that selects $m$ distinct rows of an input matrix according to an index set $S \\subset \\{0,1,\\dots,n-1\\}$. Define $A = P C(g)$. The operator $C(g)$ acts on a vector $x \\in \\mathbb{C}^n$ by circular convolution with $g$, and the operator $P$ acts by selecting the entries of a vector with indices in $S$, in order. Let $A^*$ denote the conjugate transpose of $A$.\n\nYour tasks are:\n- Design routines that compute $A x$ and $A^* y$ using the Fast Fourier Transform (FFT) without explicitly forming $A$.\n- Provide a clear complexity analysis, in terms of $n$ and $m$, for your FFT-based routines and for the na√Øve dense-matrix approach that explicitly forms and multiplies by $A$.\n\nStart from the following fundamental base:\n- The action of a circulant matrix $C(g)$ on a vector is equal to circular convolution by $g$.\n- Circular convolution in the time domain corresponds to pointwise multiplication in the frequency domain under the Discrete Fourier Transform (DFT).\n- The sampling operator $P$ selects $m$ entries indexed by $S$ in order, and its adjoint $P^*$ embeds a length-$m$ vector into $\\mathbb{C}^n$ by placing its entries at indices $S$ and zeros elsewhere.\n\nThe program you produce must:\n- Implement routines that compute $A x$ and $A^* y$ using FFTs without forming $A$.\n- For verification, compute reference results using explicit dense matrices (forming the circulant matrix and, when needed, the sampling operator or its adjoint) and compare to the FFT-based outputs.\n- For each test case, return a single float equal to the maximum of two relative errors: one for $A x$ and one for $A^* y$, where relative error is defined as $\\lVert u_{\\mathrm{FFT}} - u_{\\mathrm{dense}} \\rVert_2 / \\lVert u_{\\mathrm{dense}} \\rVert_2$ with the convention that if the denominator is $0$, the relative error is the numerator.\n\nTest suite:\nUse the following five test cases with the specified random seeds to ensure reproducibility. In each case, $S$ is the index set for $P$ and vectors are drawn from standard normal distributions as specified.\n\n- Case $1$: $n = 64$, $m = 32$, $S$ is a uniformly random subset of size $32$ from $\\{0,1,\\dots,63\\}$ sorted in ascending order (seed $0$). $g \\in \\mathbb{C}^{64}$ and $x \\in \\mathbb{C}^{64}$ are complex with independent real and imaginary parts drawn from $\\mathcal{N}(0,1)$; $y \\in \\mathbb{C}^{32}$ is complex with independent real and imaginary parts drawn from $\\mathcal{N}(0,1)$.\n- Case $2$: $n = 64$, $m = 64$, $S = \\{0,1,\\dots,63\\}$ (seed $1$). $g \\in \\mathbb{R}^{64}$ and $x \\in \\mathbb{R}^{64}$ are real with entries drawn from $\\mathcal{N}(0,1)$; $y \\in \\mathbb{R}^{64}$ is real with entries drawn from $\\mathcal{N}(0,1)$.\n- Case $3$: $n = 17$, $m = 1$, $S = \\{5\\}$ (seed $2$). $g \\in \\mathbb{C}^{17}$ and $x \\in \\mathbb{C}^{17}$ are complex with independent real and imaginary parts drawn from $\\mathcal{N}(0,1)$; $y \\in \\mathbb{C}$ is complex with independent real and imaginary parts drawn from $\\mathcal{N}(0,1)$.\n- Case $4$: $n = 50$, $m = 25$, $S = \\{0,1,\\dots,24\\}$ (seed $3$). $g \\in \\mathbb{R}^{50}$ and $x \\in \\mathbb{R}^{50}$ are real with entries drawn from $\\mathcal{N}(0,1)$; $y \\in \\mathbb{R}^{25}$ is real with entries drawn from $\\mathcal{N}(0,1)$.\n- Case $5$: $n = 128$, $m = 60$, $S$ is a uniformly random subset of size $60$ from $\\{0,1,\\dots,127\\}$ sorted in ascending order (seed $4$). $g \\in \\mathbb{R}^{128}$ is real with entries drawn from $\\mathcal{N}(0,1)$; $x \\in \\mathbb{R}^{128}$ is $k$-sparse with $k = 5$ nonzero entries selected uniformly at random (seed $4$) with values drawn from $\\mathcal{N}(0,1)$; $y \\in \\mathbb{R}^{60}$ is real with entries drawn from $\\mathcal{N}(0,1)$.\n\nComplexity analysis requirements:\n- Derive the asymptotic complexity of computing $A x$ and $A^* y$ with FFTs, assuming precomputation of the DFT of $g$.\n- Contrast this with the complexity of explicitly forming $A$ and performing dense matrix-vector multiplications.\n- Clearly state the dependence on $n$ and $m$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where the $i$-th entry is the float for test case $i$ (for $i = 1,2,3,4,5$), for example, $[r_1,r_2,r_3,r_4,r_5]$.", "solution": "The problem requires the design and analysis of efficient algorithms for computing the matrix-vector products $A x$ and $A^* y$, where $A$ is a structured sensing matrix defined as $A = P C(g)$. The matrix $C(g)$ is an $n \\times n$ circulant matrix generated by a vector $g \\in \\mathbb{C}^n$, and $P$ is an $m \\times n$ sampling operator that selects $m$ rows according to a given index set $S$. The key is to leverage the Fast Fourier Transform (FFT) to avoid the explicit formation and storage of the potentially large matrices involved.\n\n### Fast Computation of $A x$\n\nThe operation $A x$ is defined as $A x = P (C(g) x)$. We can compute this in two stages:\n1.  Compute the intermediate vector $z = C(g) x$.\n2.  Apply the sampling operator $P$ to $z$ to get the final result.\n\nThe action of a circulant matrix $C(g)$ on a vector $x$ is equivalent to the circular convolution of its generating vector $g$ and the vector $x$. This is denoted as $z = g * x$. The Convolution Theorem states that circular convolution in the time domain corresponds to element-wise multiplication in the frequency domain. Let $\\mathcal{F}$ denote the Discrete Fourier Transform (DFT) and $\\mathcal{F}^{-1}$ denote its inverse. The theorem is expressed as:\n$$\n\\mathcal{F}(g * x) = \\mathcal{F}(g) \\odot \\mathcal{F}(x)\n$$\nwhere $\\odot$ represents the Hadamard (element-wise) product.\n\nTherefore, the vector $z$ can be computed efficiently as:\n$$\nz = \\mathcal{F}^{-1}(\\mathcal{F}(g) \\odot \\mathcal{F}(x))\n$$\n\nThe second step is to apply the sampling operator $P$. The operator $P$ selects the entries of $z$ corresponding to the indices in the set $S \\subset \\{0, 1, \\dots, n-1\\}$. If $z = [z_0, z_1, \\dots, z_{n-1}]^T$, then $Pz$ is a vector of length $m$ containing the elements $\\{z_i\\}_{i \\in S}$.\n\nThe complete FFT-based algorithm for computing $A x$ is as follows:\n1.  Compute the DFT of the generating vector, $\\hat{g} = \\mathcal{F}(g)$. This can be pre-computed and stored if $A$ is applied multiple times.\n2.  Compute the DFT of the input vector, $\\hat{x} = \\mathcal{F}(x)$.\n3.  Perform the element-wise product in the frequency domain: $\\hat{z} = \\hat{g} \\odot \\hat{x}$.\n4.  Compute the inverse DFT to return to the time domain: $z = \\mathcal{F}^{-1}(\\hat{z})$.\n5.  Extract the $m$ elements of $z$ at the indices specified by $S$.\n\n### Fast Computation of $A^* y$\n\nThe adjoint operator $A^*$ is given by $A^* = (P C(g))^* = C(g)^* P^*$. The action on a vector $y \\in \\mathbb{C}^m$ is thus $A^* y = C(g)^* (P^* y)$. This can also be computed in stages.\n\n1.  Compute the intermediate vector $v = P^* y$. The operator $P^*$ is the adjoint of the sampling operator $P$. It performs an embedding operation: it takes a vector $y$ of length $m$ and creates a vector $v$ of length $n$ by placing the elements of $y$ at the indices specified by $S$ and filling the remaining entries with zeros. That is, for $i \\in \\{0, 1, \\dots, n-1\\}$, $v_i = y_k$ if $i$ is the $k$-th element of the sorted index set $S$, and $v_i = 0$ if $i \\notin S$.\n\n2.  Compute the product $w = C(g)^* v$. We must first characterize the matrix $C(g)^*$. The conjugate transpose of a circulant matrix is also a circulant matrix. If $C(g)$ is generated by the vector $g$, then $C(g)^*$ is generated by a vector $g'$ where $g'_k = \\overline{g_{(-k) \\pmod{n}}}$ for $k \\in \\{0, 1, \\dots, n-1\\}$. This vector $g'$ is the conjugated and time-reversed version of $g$.\n\nThe action $C(g)^* v$ is therefore equivalent to the circular convolution $g' * v$. We can again apply the Convolution Theorem:\n$$\nw = g' * v = \\mathcal{F}^{-1}(\\mathcal{F}(g') \\odot \\mathcal{F}(v))\n$$\nA crucial property connects the DFT of $g'$ to the DFT of $g$. The DFT of $g'$ is the element-wise complex conjugate of the DFT of $g$:\n$$\n\\mathcal{F}(g')_k = \\sum_{j=0}^{n-1} g'_j e^{-2\\pi i jk / n} = \\sum_{j=0}^{n-1} \\overline{g_{(-j) \\pmod n}} e^{-2\\pi i jk / n}\n$$\nLetting $l = (-j) \\pmod n$, we have $j = (-l) \\pmod n$. The sum becomes:\n$$\n\\sum_{l=0}^{n-1} \\overline{g_l} e^{-2\\pi i (-l)k / n} = \\sum_{l=0}^{n-1} \\overline{g_l} e^{2\\pi i lk / n} = \\overline{\\sum_{l=0}^{n-1} g_l e^{-2\\pi i lk / n}} = \\overline{\\mathcal{F}(g)_k}\n$$\nThus, $\\mathcal{F}(g') = \\overline{\\mathcal{F}(g)}$. Substituting this into the expression for $w$ gives:\n$$\nw = \\mathcal{F}^{-1}(\\overline{\\mathcal{F}(g)} \\odot \\mathcal{F}(v))\n$$\n\nThe complete FFT-based algorithm for computing $A^* y$ is as follows:\n1.  Compute the DFT of the generating vector, $\\hat{g} = \\mathcal{F}(g)$. This is the same pre-computation as for $A x$.\n2.  Construct the sparse vector $v \\in \\mathbb{C}^n$ by embedding $y \\in \\mathbb{C}^m$ at indices $S$.\n3.  Compute the DFT of the embedded vector, $\\hat{v} = \\mathcal{F}(v)$.\n4.  Compute the element-wise product in the frequency domain: $\\hat{w} = \\overline{\\hat{g}} \\odot \\hat{v}$.\n5.  Compute the inverse DFT to obtain the final result: $w = \\mathcal{F}^{-1}(\\hat{w})$.\n\n### Complexity Analysis\n\nWe analyze the computational complexity of both the FFT-based methods and the naive dense matrix approaches. The complexity of an $N$-point FFT or IFFT is $O(N \\log N)$.\n\n**FFT-based Approach:**\n-   **Pre-computation:** Computing $\\hat{g} = \\mathcal{F}(g)$ requires $O(n \\log n)$ operations. This is a one-time cost.\n-   **Computation of $A x$:**\n    1.  $\\mathcal{F}(x)$: $O(n \\log n)$.\n    2.  $\\hat{g} \\odot \\hat{x}$: $O(n)$.\n    3.  $\\mathcal{F}^{-1}(\\hat{z})$: $O(n \\log n)$.\n    4.  Sampling $Pz$: $O(m)$.\n    The total complexity, assuming $\\hat{g}$ is pre-computed, is dominated by the FFTs, resulting in **$O(n \\log n)$**.\n-   **Computation of $A^* y$:**\n    1.  Embedding $P^*y$: $O(n)$ to initialize a zero vector and $O(m)$ to place the elements. Total $O(n)$.\n    2.  $\\mathcal{F}(v)$: $O(n \\log n)$.\n    3.  $\\overline{\\hat{g}} \\odot \\hat{v}$: $O(n)$.\n    4.  $\\mathcal{F}^{-1}(\\hat{w})$: $O(n \\log n)$.\n    The total complexity, assuming $\\hat{g}$ is pre-computed, is again dominated by the FFTs, resulting in **$O(n \\log n)$**.\n\n**Dense Matrix Approach:**\n-   **Forming the matrix $A$:** The full circulant matrix $C(g)$ has $n^2$ entries. Constructing it takes $O(n^2)$ time. The matrix $A = P C(g)$ is an $m \\times n$ matrix formed by selecting $m$ rows from $C(g)$. This sub-sampling can be done in $O(mn)$ time.\n-   **Computation of $A x$:** This is a multiplication of an $m \\times n$ matrix with an $n \\times 1$ vector. This requires $m$ inner products of length $n$, giving a complexity of **$O(mn)$**.\n-   **Computation of $A^* y$:** The matrix $A^*$ is $n \\times m$. Multiplying it by an $m \\times 1$ vector requires $n$ inner products of length $m$, also leading to a complexity of **$O(mn)$**.\n\n**Comparison:**\nThe FFT-based approach has a complexity of $O(n \\log n)$ for both forward ($A x$) and adjoint ($A^* y$) operations. The dense matrix approach has a complexity of $O(mn)$. The FFT-based method is computationally superior whenever $n \\log n < mn$, which simplifies to $m > \\log n$. In typical compressed sensing scenarios, $m$ is proportional to the sparsity of the signal and the log factors, i.e., $m \\approx k \\log(n/k)$, which is almost always greater than $\\log n$. For large-scale problems where $m$ is not trivially small, the FFT-based routines provide a significant performance advantage, turning a quadratic-time problem (if $m=O(n)$) into a near-linear-time one.", "answer": "```python\nimport numpy as np\nfrom scipy.fft import fft, ifft\nfrom scipy.linalg import circulant\n\ndef compute_Ax_fft(g, x, S):\n    \"\"\"Computes A @ x using FFT, where A = P @ C(g).\"\"\"\n    n = g.shape[0]\n    # Step 1: Compute z = C(g) @ x via FFT\n    # This corresponds to circular convolution g * x\n    g_hat = fft(g)\n    x_hat = fft(x)\n    z_hat = g_hat * x_hat\n    z = ifft(z_hat)\n    \n    # Step 2: Apply sampling operator P\n    # Select entries of z at indices S\n    return z[S]\n\ndef compute_A_star_y_fft(g, y, S, n):\n    \"\"\"Computes A.conj().T @ y using FFT, where A = P @ C(g).\"\"\"\n    # Adjoint is A* = C(g)* @ P*\n    \n    # Step 1: Apply P*, which embeds y into a sparse vector of size n\n    v = np.zeros(n, dtype=y.dtype)\n    v[S] = y\n    \n    # Step 2: Apply C(g)*, which is convolution with conj(g_timereversed)\n    # In frequency domain, this is multiplication with conj(fft(g))\n    g_hat = fft(g)\n    v_hat = fft(v)\n    w_hat = np.conj(g_hat) * v_hat\n    w = ifft(w_hat)\n    \n    return w\n\ndef relative_error(u_test, u_ref):\n    \"\"\"\n    Calculates the relative error ||u_test - u_ref|| / ||u_ref||.\n    If ||u_ref|| is 0, returns ||u_test - u_ref||.\n    \"\"\"\n    diff_norm = np.linalg.norm(u_test - u_ref)\n    ref_norm = np.linalg.norm(u_ref)\n    \n    if ref_norm == 0:\n        return diff_norm\n    return diff_norm / ref_norm\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and compute errors.\n    \"\"\"\n    test_cases = [\n        {'n': 64, 'm': 32, 's_type': 'random', 'seed': 0, 'cplx': True, 'sparse_x': False},\n        {'n': 64, 'm': 64, 's_type': 'full', 'seed': 1, 'cplx': False, 'sparse_x': False},\n        {'n': 17, 'm': 1, 's_type': 'single', 'seed': 2, 'cplx': True, 'sparse_x': False},\n        {'n': 50, 'm': 25, 's_type': 'first_m', 'seed': 3, 'cplx': False, 'sparse_x': False},\n        {'n': 128, 'm': 60, 's_type': 'random', 'seed': 4, 'cplx': False, 'sparse_x': True, 'k': 5},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        n, m, seed = case['n'], case['m'], case['seed']\n        rng = np.random.default_rng(seed)\n\n        # Generate index set S\n        if case['s_type'] == 'random':\n            S = rng.choice(n, m, replace=False)\n            S.sort()\n        elif case['s_type'] == 'full':\n            S = np.arange(n)\n        elif case['s_type'] == 'single':\n            S = np.array([5])\n        elif case['s_type'] == 'first_m':\n            S = np.arange(m)\n        \n        # Determine data type\n        dtype = np.complex128 if case['cplx'] else np.float64\n\n        # Generate vectors g, x, y\n        if case['cplx']:\n            g = rng.standard_normal(n) + 1j * rng.standard_normal(n)\n            y = rng.standard_normal(m) + 1j * rng.standard_normal(m)\n            if case.get('sparse_x', False):\n                 k = case['k']\n                 x = np.zeros(n, dtype=dtype)\n                 nonzero_indices = rng.choice(n, k, replace=False)\n                 nonzero_values = rng.standard_normal(k) + 1j * rng.standard_normal(k)\n                 x[nonzero_indices] = nonzero_values\n            else:\n                 x = rng.standard_normal(n) + 1j * rng.standard_normal(n)\n        else:\n            g = rng.standard_normal(n)\n            y = rng.standard_normal(m)\n            if case.get('sparse_x', False):\n                 k = case['k']\n                 x = np.zeros(n, dtype=dtype)\n                 # Use a different seed for x's sparsity pattern for reproducibility as per problem \n                 # (even if seed is the same, this is good practice).\n                 rng_sparse = np.random.default_rng(seed)\n                 nonzero_indices = rng_sparse.choice(n, k, replace=False)\n                 nonzero_values = rng_sparse.standard_normal(k)\n                 x[nonzero_indices] = nonzero_values\n            else:\n                 x = rng.standard_normal(n)\n        \n        # --- FFT-based computation ---\n        ax_fft = compute_Ax_fft(g, x, S)\n        a_star_y_fft = compute_A_star_y_fft(g, y, S, n)\n\n        # --- Dense matrix computation for verification ---\n        C_dense = circulant(g)\n        A_dense = C_dense[S, :]\n        \n        ax_dense = A_dense @ x\n        \n        # Using A_dense.conj().T for A*\n        a_star_y_dense = A_dense.conj().T @ y\n\n        # --- Compare results and compute error ---\n        err_ax = relative_error(ax_fft, ax_dense)\n        err_a_star_y = relative_error(a_star_y_fft, a_star_y_dense)\n        \n        results.append(max(err_ax, err_a_star_y))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```", "id": "3490937"}, {"introduction": "Beyond simple matrix-vector multiplications, many sparse recovery algorithms require knowledge of the sensing operator's properties to set crucial parameters. This practice demonstrates a more advanced application of FFT-based computation: calculating the maximum column norm of a structured matrix, $\\|A\\|_{2,\\infty}$. You will learn how this quantity, essential for methods like the Dantzig selector, can be derived from a circular cross-correlation that is itself efficiently computable using FFTs. This exercise highlights how the Fourier domain provides a powerful analytical tool, not just an accelerant for basic operations [@problem_id:3490910].", "problem": "Consider the following setting in compressed sensing with structured sensing operators. Let $n \\in \\mathbb{N}$ and let $h \\in \\mathbb{C}^n$ define the circulant convolution operator $C_h:\\mathbb{C}^n \\to \\mathbb{C}^n$ given by $C_h x = h \\circledast x$, where $\\circledast$ denotes circular convolution on $\\mathbb{Z}_n$. Let $S \\in \\{0,1\\}^{m \\times n}$ be a row-selection matrix that extracts the entries of a vector indexed by a subset $\\Omega \\subset \\{0,\\dots,n-1\\}$ of cardinality $m$, with $m \\le n$. The sensing matrix is $A = S C_h$. For additive noise $e \\in \\mathbb{R}^m$ with independent normal entries of variance $\\sigma^2$, the Dantzig selector constraint requires evaluating $\\|A^* e\\|_\\infty$ efficiently and choosing $\\lambda$ in terms of $\\sigma$ and $\\log n$.\n\nStarting from the following fundamental bases:\n- The discrete Fourier transform diagonalizes circulant operators: if $\\mathcal{F}$ denotes the discrete Fourier transform operator and $\\widehat{h} = \\mathcal{F} h$, then $C_h = \\mathcal{F}^{-1} \\operatorname{diag}(\\widehat{h}) \\mathcal{F}$, and its adjoint is $C_h^* = \\mathcal{F}^{-1} \\operatorname{diag}(\\overline{\\widehat{h}}) \\mathcal{F}$.\n- The adjoint of a row selection operator $S$ is the zero-insertion operator $S^*$ that maps a vector $e \\in \\mathbb{R}^m$ to a vector $z \\in \\mathbb{R}^n$ with $z_i = e_j$ for $i \\in \\Omega$ corresponding to the $j$-th selected index, and $z_i = 0$ otherwise.\n- For independent Gaussian noise with variance $\\sigma^2$, the random variable $\\langle a_j, e\\rangle$ for the $j$-th column $a_j$ of $A$ is Gaussian with variance $\\sigma^2 \\|a_j\\|_2^2$, so a union bound implies that with high probability $\\|A^* e\\|_\\infty \\le \\sigma \\sqrt{2 \\log n} \\, \\|A\\|_{2,\\infty}$, where $\\|A\\|_{2,\\infty} = \\max_j \\|a_j\\|_2$.\n\nYour tasks are:\n- Derive an $\\mathcal{O}(n \\log n)$ algorithm to compute $g = A^* e$ using the fast Fourier transform (FFT) without explicitly forming $A$. Express $g$ in terms of $\\mathcal{F}$, $\\widehat{h}$, and the zero-inserted vector $z = S^* e$.\n- Derive an $\\mathcal{O}(n \\log n)$ method to compute $\\|A\\|_{2,\\infty}$ using FFTs. Argue that the squared column $\\ell_2$ norms are given by a circular cross-correlation of $|h|^2$ with the binary mask of $\\Omega$, and show how to evaluate this cross-correlation via FFTs.\n- Choose $\\lambda$ in terms of $\\sigma$ and $\\log n$ so that the Dantzig selector constraint $\\|A^* e\\|_\\infty \\le \\lambda$ holds with high probability under the stated Gaussian noise model.\n\nYour program must implement the following procedure for each test case:\n- Construct $A = S C_h$ implicitly from $h$ and $\\Omega$.\n- Generate $e \\in \\mathbb{R}^m$ with independent entries distributed as $\\mathcal{N}(0,\\sigma^2)$ using a pseudorandom generator initialized with the specified seed for each test.\n- Compute $g = A^* e$ using FFTs and the zero-insertion vector $z = S^* e$.\n- Compute $\\|A\\|_{2,\\infty}$ via FFTs by evaluating the circular cross-correlation of $|h|^2$ with the binary mask of $\\Omega$ and taking the square root of its maximum value.\n- Set $\\lambda = \\sigma \\sqrt{2 \\log n} \\, \\|A\\|_{2,\\infty}$.\n- Return the ratio $r = \\|g\\|_\\infty / \\lambda$ as a floating-point number rounded to six digits after the decimal point.\n\nTest suite specification:\n- Test $1$ (general case): $n = 64$, $m = 32$. The set $\\Omega$ is chosen by sampling $m$ distinct indices uniformly at random without replacement using seed $2$. The vector $h$ has independent standard normal entries generated with seed $1$. The noise standard deviation is $\\sigma = 0.1$, and noise $e$ is generated with seed $3$.\n- Test $2$ (full circulant, boundary case): $n = 64$, $m = 64$. The set $\\Omega$ equals $\\{0,1,\\dots,63\\}$. The vector $h$ has independent standard normal entries generated with seed $4$. The noise standard deviation is $\\sigma = 0.2$, and noise $e$ is generated with seed $5$.\n- Test $3$ (small $m$, deterministic filter): $n = 128$, $m = 8$. The set $\\Omega$ equals $\\{0,1,\\dots,7\\}$. The vector $h$ is deterministic with entries $h[i] = \\exp(-i/20)$ for $i \\in \\{0,\\dots,127\\}$. The noise standard deviation is $\\sigma = 0.05$, and noise $e$ is generated with seed $6$.\n- Test $4$ (denser sampling with randomness): $n = 128$, $m = 80$. The set $\\Omega$ is chosen by sampling $m$ distinct indices uniformly at random without replacement using seed $8$. The vector $h$ has independent standard normal entries generated with seed $7$. The noise standard deviation is $\\sigma = 0.5$, and noise $e$ is generated with seed $9$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The $k$-th entry must be the ratio $r$ for Test $k$, rounded to six digits after the decimal point, so the output has the form $[r_1,r_2,r_3,r_4]$ with each $r_k$ represented as a decimal numeral with exactly six digits after the decimal point.", "solution": "The problem is assessed to be valid as it is scientifically grounded in the principles of compressed sensing and sparse optimization, is well-posed with a clear objective, and provides a complete and consistent setup for each test case.\n\nThe task is to analyze a structured sensing matrix $A = S C_h$, where $C_h$ is a circulant convolution operator and $S$ is a row-selection operator. We must develop and implement efficient algorithms to compute quantities related to the Dantzig selector constraint $\\|A^* e\\|_\\infty \\le \\lambda$ for a given noise vector $e$.\n\n### Derivation of an $\\mathcal{O}(n \\log n)$ Algorithm for $g = A^* e$\n\nThe vector $g$ is defined as $g = A^* e$. The sensing matrix is $A = S C_h$, where $S$ is the row-selection operator and $C_h$ is the circulant convolution operator. The adjoint operator $A^*$ is given by the composition of the adjoints in reverse order:\n$$A^* = (S C_h)^* = C_h^* S^*$$\nThus, we need to compute $g = C_h^* (S^* e)$. This computation can be performed in two steps.\n\nFirst, we apply $S^*$ to the vector $e \\in \\mathbb{R}^m$. The operator $S$ selects $m$ rows corresponding to indices in the set $\\Omega \\subset \\{0, \\dots, n-1\\}$. Its adjoint, $S^*$, is a zero-insertion operator. It maps a vector $e \\in \\mathbb{R}^m$ to a vector $z \\in \\mathbb{R}^n$ (or $\\mathbb{C}^n$ in a general context). The entries of $z$ are given by:\n$$\nz_i = \\begin{cases} e_j & \\text{if } i \\in \\Omega \\text{ (where } i \\text{ is the } j\\text{-th index in } \\Omega\\text{)} \\\\ 0 & \\text{if } i \\notin \\Omega \\end{cases}\n$$\nThis operation requires creating a zero vector of size $n$ and populating $m$ of its entries, which takes $\\mathcal{O}(n)$ time.\n\nSecond, we apply $C_h^*$ to the resulting vector $z$. The problem states that a circulant operator $C_h$ is diagonalized by the Discrete Fourier Transform ($\\mathcal{F}$). Specifically, $C_h = \\mathcal{F}^{-1} \\operatorname{diag}(\\widehat{h}) \\mathcal{F}$, where $\\widehat{h} = \\mathcal{F} h$ is the DFT of the vector $h \\in \\mathbb{C}^n$, and $\\operatorname{diag}(\\widehat{h})$ is the diagonal matrix with $\\widehat{h}$ on its diagonal. The adjoint operator is then $C_h^* = (\\mathcal{F}^{-1} \\operatorname{diag}(\\widehat{h}) \\mathcal{F})^* = \\mathcal{F}^* \\operatorname{diag}(\\widehat{h})^* (\\mathcal{F}^{-1})^*$. Since $\\mathcal{F}^{-1} = \\frac{1}{n}\\mathcal{F}^*$, we have $\\mathcal{F}^* = n \\mathcal{F}^{-1}$. Also $\\mathcal{F}^* = \\mathcal{F}^{-1 *}$. For the DFT matrix, $\\mathcal{F}^*$ is the matrix with complex conjugate entries. The adjoint of a diagonal matrix is the diagonal matrix of complex conjugates. Thus, $C_h^* = \\mathcal{F}^{-1} \\operatorname{diag}(\\overline{\\widehat{h}}) \\mathcal{F}$, where $\\overline{\\widehat{h}}$ denotes the element-wise complex conjugate of $\\widehat{h}$.\n\nApplying this to $z$, we get:\n$$g = C_h^* z = \\mathcal{F}^{-1} \\operatorname{diag}(\\overline{\\widehat{h}}) (\\mathcal{F} z)$$\nThis expression suggests an efficient algorithm using the Fast Fourier Transform (FFT), which computes the DFT and its inverse in $\\mathcal{O}(n \\log n)$ time.\n\nThe algorithm to compute $g = A^*e$ is as follows:\n1.  Construct the zero-inserted vector $z = S^*e$. ($\\mathcal{O}(n)$)\n2.  Compute $\\widehat{h} = \\mathcal{F} h$ using an FFT. ($\\mathcal{O}(n \\log n)$)\n3.  Compute $\\widehat{z} = \\mathcal{F} z$ using an FFT. ($\\mathcal{O}(n \\log n)$)\n4.  Perform the element-wise product in the Fourier domain: $v = \\overline{\\widehat{h}} \\odot \\widehat{z}$. ($\\mathcal{O}(n)$)\n5.  Compute the final result by inverse FFT: $g = \\mathcal{F}^{-1} v$. ($\\mathcal{O}(n \\log n)$)\n\nThe total complexity is dominated by the FFT and IFFT steps, yielding an overall complexity of $\\mathcal{O}(n \\log n)$.\n\n### Derivation of an $\\mathcal{O}(n \\log n)$ Algorithm for $\\|A\\|_{2,\\infty}$\n\nThe quantity $\\|A\\|_{2,\\infty}$ is the maximum $\\ell_2$-norm of the columns of $A$. Let $a_j$ be the $j$-th column of $A$, for $j \\in \\{0, \\dots, n-1\\}$. Then $\\|A\\|_{2,\\infty} = \\max_j \\|a_j\\|_2$.\nThe $j$-th column $a_j$ is obtained by applying $A$ to the $j$-th standard basis vector $\\delta_j$:\n$$a_j = A \\delta_j = S C_h \\delta_j$$\nThe action of $C_h$ on $\\delta_j$ is a circular convolution $h \\circledast \\delta_j$, which results in a cyclically shifted version of $h$. Specifically, $(h \\circledast \\delta_j)_k = h_{k-j \\pmod n}$. Let us denote this shifted vector by $h^{(j)}$. So, the columns of $C_h$ are cyclically shifted versions of $h$.\nThe column $a_j$ of $A$ is therefore $a_j = S h^{(j)}$, which is the vector $h^{(j)}$ with only the entries indexed by $\\Omega$ retained.\n\nThe squared $\\ell_2$-norm of $a_j$ is:\n$$\\|a_j\\|_2^2 = \\sum_{k \\in \\Omega} |(h^{(j)})_k|^2 = \\sum_{k \\in \\Omega} |h_{k-j \\pmod n}|^2$$\nLet $p \\in \\{0, 1\\}^n$ be the binary mask of the set $\\Omega$, i.e., $p_k=1$ if $k \\in \\Omega$ and $p_k=0$ otherwise. Let $q \\in \\mathbb{R}^n$ be the vector of squared magnitudes of $h$, i.e., $q_k = |h_k|^2$. We can rewrite the sum as:\n$$\\|a_j\\|_2^2 = \\sum_{k=0}^{n-1} p_k q_{k-j \\pmod n}$$\nLet $l=k-j \\pmod n$, so $k=l+j \\pmod n$. The sum becomes $\\sum_{l=0}^{n-1} p_{l+j \\pmod n} q_l$. This is the definition of the circular cross-correlation of $q$ and $p$ at lag $j$:\n$$\\|a_j\\|_2^2 = (q \\star p)_j = \\sum_{l=0}^{n-1} q_l p_{l+j \\pmod n}$$\n(Since $q$ and $p$ are real, the complex conjugate on $q_l$ is not needed).\n\nThe Correlation Theorem, a corollary of the Convolution Theorem, states that the DFT of a cross-correlation is the element-wise product of the conjugate DFT of the first signal and the DFT of the second signal:\n$$\\mathcal{F}(q \\star p) = \\overline{\\mathcal{F}(q)} \\odot \\mathcal{F}(p)$$\nLet $v$ be the vector where $v_j = \\|a_j\\|_2^2$. Then $v = q \\star p$. We can compute $v$ efficiently:\n$$v = \\mathcal{F}^{-1}(\\overline{\\mathcal{F}(q)} \\odot \\mathcal{F}(p))$$\n\nThe algorithm to compute $\\|A\\|_{2,\\infty}$ is:\n1.  Construct the vector $q$ with entries $q_k = |h_k|^2$. ($\\mathcal{O}(n)$)\n2.  Construct the binary mask vector $p$ for $\\Omega$. ($\\mathcal{O}(n)$)\n3.  Compute $\\widehat{q} = \\mathcal{F}q$ and $\\widehat{p} = \\mathcal{F}p$ using FFTs. ($\\mathcal{O}(n \\log n)$)\n4.  Perform the element-wise product: $w = \\overline{\\widehat{q}} \\odot \\widehat{p}$. ($\\mathcal{O}(n)$)\n5.  Compute the vector of squared norms by inverse FFT: $v = \\mathcal{F}^{-1} w$. This should be a real vector; we take the real part to remove numerical noise. ($\\mathcal{O}(n \\log n)$)\n6.  Find the maximum squared norm: $v_{\\max} = \\max_j v_j$. ($\\mathcal{O}(n)$)\n7.  The final result is $\\|A\\|_{2,\\infty} = \\sqrt{v_{\\max}}$.\n\nThe total complexity is $\\mathcal{O}(n \\log n)$.\n\n### Choice of the Dantzig Selector Parameter $\\lambda$\n\nThe Dantzig selector constraint is $\\|A^*e\\|_\\infty \\le \\lambda$. The vector $g = A^*e$ has components $g_j = \\langle a_j, e \\rangle$. Given that $e \\in \\mathbb{R}^m$ has i.i.d. entries $e_k \\sim \\mathcal{N}(0, \\sigma^2)$, each $g_j$ is a Gaussian random variable with mean $0$ and variance $\\operatorname{Var}(g_j) = \\sigma^2 \\|a_j\\|_2^2$.\n\nThe problem directs us to use the standard high-probability bound derived from a union bound over the $n$ random variables $g_j$. This approach leads to the choice of $\\lambda$ being proportional to the maximum standard deviation of the $g_j$, scaled by a factor related to $\\log n$. The problem explicitly gives the form:\n$$\\lambda = \\sigma \\sqrt{2 \\log n} \\, \\|A\\|_{2,\\infty}$$\nThis choice ensures that, with high probability, the constraint $\\|A^* e\\|_\\infty \\le \\lambda$ is satisfied. We use this formula directly in our implementation. The computed ratio $r = \\|g\\|_\\infty / \\lambda$ is expected to be a random variable with a value typically less than or equal to $1$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_test_case(n, m, h, Omega, sigma, e_seed):\n    \"\"\"\n    Solves a single test case for the structured compressed sensing problem.\n\n    Args:\n        n (int): Ambient dimension.\n        m (int): Number of measurements.\n        h (np.ndarray): The filter for the circulant matrix, of shape (n,).\n        Omega (np.ndarray): The set of selected indices, of shape (m,).\n        sigma (float): Standard deviation of the Gaussian noise.\n        e_seed (int): Seed for the pseudorandom noise generator.\n\n    Returns:\n        float: The ratio r = ||A*e||_inf / lambda.\n    \"\"\"\n    # Generate the noise vector e\n    rng_e = np.random.default_rng(e_seed)\n    e = rng_e.normal(loc=0.0, scale=sigma, size=m)\n\n    # 1. Compute g = A*e using FFTs.\n    # A*e = C_h* S* e. First, compute z = S* e.\n    # Using complex type for z is important for general complex h.\n    z = np.zeros(n, dtype=np.complex128)\n    # Sort Omega to ensure deterministic mapping, although not strictly needed\n    # for random choice since order is fixed by rng.choice.\n    Omega.sort() \n    z[Omega] = e\n    \n    # Compute g = F_inv(conj(F(h)) * F(z))\n    h_fft = np.fft.fft(h)\n    z_fft = np.fft.fft(z)\n    g_fft = np.conj(h_fft) * z_fft\n    g = np.fft.ifft(g_fft)\n    \n    # Compute the infinity norm of g\n    norm_g_inf = np.max(np.abs(g))\n\n    # 2. Compute ||A||_{2,inf} using FFTs via cross-correlation.\n    # The squared column norms are given by the circular cross-correlation\n    # of q = |h|^2 with p = mask of Omega.\n    q = np.abs(h)**2\n    p = np.zeros(n)\n    p[Omega] = 1.0\n    \n    # Use correlation theorem: F(q star p) = conj(F(q)) * F(p)\n    q_fft = np.fft.fft(q)\n    p_fft = np.fft.fft(p)\n    col_norms_sq_fft = np.conj(q_fft) * p_fft\n    col_norms_sq = np.fft.ifft(col_norms_sq_fft)\n    \n    # The result must be real. Take the real part to discard numerical noise.\n    # Max value of this vector is max(||a_j||_2^2).\n    max_col_norm_sq = np.max(col_norms_sq.real)\n    norm_A_2_inf = np.sqrt(max_col_norm_sq)\n\n    # 3. Set lambda based on the derived quantities.\n    lambda_val = sigma * np.sqrt(2 * np.log(n)) * norm_A_2_inf\n    \n    # 4. Compute the final ratio r.\n    # Handle the case where lambda_val might be zero to avoid division by zero.\n    if lambda_val == 0:\n        r = 0.0 if norm_g_inf == 0 else np.inf\n    else:\n        r = norm_g_inf / lambda_val\n    \n    return r\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run them, and print the results.\n    \"\"\"\n    test_specs = [\n        {'n': 64, 'm': 32, 'h_type': 'random', 'h_seed': 1, 'omega_type': 'random', 'omega_seed': 2, 'sigma': 0.1, 'e_seed': 3},\n        {'n': 64, 'm': 64, 'h_type': 'random', 'h_seed': 4, 'omega_type': 'full', 'sigma': 0.2, 'e_seed': 5},\n        {'n': 128, 'm': 8, 'h_type': 'deterministic', 'omega_type': 'contiguous', 'omega_start': 0, 'sigma': 0.05, 'e_seed': 6},\n        {'n': 128, 'm': 80, 'h_type': 'random', 'h_seed': 7, 'omega_type': 'random', 'omega_seed': 8, 'sigma': 0.5, 'e_seed': 9},\n    ]\n\n    results = []\n    for spec in test_specs:\n        n, m, sigma, e_seed = spec['n'], spec['m'], spec['sigma'], spec['e_seed']\n        \n        # Generate h vector\n        if spec['h_type'] == 'random':\n            rng_h = np.random.default_rng(spec['h_seed'])\n            h = rng_h.standard_normal(n)\n        else: # deterministic\n            h = np.exp(-np.arange(n) / 20.0)\n            \n        # Generate Omega index set\n        if spec['omega_type'] == 'random':\n            rng_omega = np.random.default_rng(spec['omega_seed'])\n            Omega = rng_omega.choice(n, m, replace=False)\n        elif spec['omega_type'] == 'full':\n            Omega = np.arange(n)\n        else: # contiguous\n            Omega = np.arange(spec['omega_start'], spec['omega_start'] + m)\n        \n        r = run_test_case(n, m, h, Omega, sigma, e_seed)\n        results.append(f\"{r:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3490910"}, {"introduction": "This practice integrates the preceding concepts to construct a complete, high-performance solver for a cornerstone problem in compressed sensing: Basis Pursuit. You will implement the Alternating Direction Method of Multipliers (ADMM) to solve $\\min \\|x\\|_1$ subject to $A x = y$, where $A$ is a circulant operator. The key is to see how the computationally intensive projection step within ADMM becomes remarkably efficient by exploiting the diagonalization of the operator $A A^{\\top}$ in the Fourier domain. This exercise bridges the gap from implementing fundamental operations to building a practical optimization algorithm capable of handling large-scale structured inverse problems [@problem_id:3490941].", "problem": "Consider the constrained Basis Pursuit problem in compressed sensing: minimize the entrywise one-norm of a signal subject to exact linear measurements,\n$$\n\\min_{x \\in \\mathbb{R}^n} \\ \\|x\\|_1 \\quad \\text{subject to} \\quad A x = y,\n$$\nwhere $A \\in \\mathbb{R}^{n \\times n}$ is a real-valued circulant sensing matrix generated by a real kernel $a \\in \\mathbb{R}^n$ via circular convolution. The circulant matrix $A$ represents the linear operator $x \\mapsto a \\star x$ (circular convolution), and is diagonalizable by the Discrete Fourier Transform (DFT). Let $F \\in \\mathbb{C}^{n \\times n}$ denote the unitary DFT matrix with entries\n$$\nF_{k\\ell} = \\frac{1}{\\sqrt{n}} \\exp\\left(-\\mathrm{i} \\frac{2\\pi k \\ell}{n}\\right), \\quad 0 \\le k,\\ell \\le n-1,\n$$\nso that $A$ admits the Fourier diagonalization\n$$\nA = F^{\\ast} \\ \\mathrm{diag}(\\widehat{a}) \\ F,\n$$\nwhere $\\widehat{a} = F a$ is the DFT of $a$ and $F^{\\ast}$ is the conjugate transpose of $F$. This implies $A x = F^{\\ast} \\left( \\widehat{a} \\odot (F x) \\right)$ and $A^{\\top} r = F^{\\ast} \\left( \\overline{\\widehat{a}} \\odot (F r) \\right)$, where $\\odot$ denotes elementwise multiplication and $\\overline{\\widehat{a}}$ is the complex conjugate. Furthermore, $A A^{\\top} = F^{\\ast} \\ \\mathrm{diag}(|\\widehat{a}|^2) \\ F$, so $(A A^{\\top})^{-1}$ is diagonal in the Fourier domain when $|\\widehat{a}|$ has strictly positive entries.\n\nYou are asked to implement the Alternating Direction Method of Multipliers (ADMM) to solve the constrained Basis Pursuit, exploiting the circulant structure to compute updates efficiently using Fast Fourier Transforms (FFTs). Use the splitting\n$$\n\\min_{x,z \\in \\mathbb{R}^n} \\ \\underbrace{I_{\\{u \\in \\mathbb{R}^n : A u = y\\}}(x)}_{f(x)} + \\underbrace{\\|z\\|_1}_{g(z)} \\quad \\text{subject to} \\quad x = z,\n$$\nwhere $I_{\\mathcal{C}}$ is the indicator function of the set $\\mathcal{C}$, and apply ADMM in scaled form with parameter $\\rho > 0$. The fundamental bases to use are:\n- The proximal operator of the one-norm is entrywise soft-thresholding: for $\\lambda > 0$,\n$$\n\\mathrm{prox}_{\\lambda \\|\\cdot\\|_1}(v)_i = \\mathrm{sign}(v_i) \\cdot \\max\\{|v_i| - \\lambda, 0\\}.\n$$\n- The projection onto the affine subspace $\\{x \\in \\mathbb{R}^n : A x = y\\}$ in Euclidean norm is given by\n$$\n\\Pi_{\\{A x = y\\}}(w) = w + A^{\\top} (A A^{\\top})^{-1} (y - A w).\n$$\n- Circulant matrices are diagonalized by the DFT, so products by $A$, $A^{\\top}$, and $(A A^{\\top})^{-1}$ can be computed via FFTs.\n\nDerive from first principles the ADMM updates for $x$, $z$, and the scaled dual variable $u$, showing how each step is computed and why FFTs yield efficient implementations for circulant $A$. In particular, express the $x$-update as the projection onto the affine set using the diagonalization of $A A^{\\top}$ in the Fourier domain, and the $z$-update as soft-thresholding. Clarify the role of the scaled dual variable and the stopping criteria in terms of primal and dual residuals.\n\nThen implement a complete, runnable program that:\n- Constructs circulant matrices implicitly via kernels $a$ and uses FFTs to compute all required linear operations.\n- Solves the constrained Basis Pursuit using ADMM with the described splitting.\n- Uses a small ridge parameter $\\gamma \\ge 0$ in the inversion of $A A^{\\top}$ to handle potential near-singular cases by replacing $(A A^{\\top})^{-1}$ with $(A A^{\\top} + \\gamma I)^{-1}$, which remains diagonal in the Fourier domain.\n- Validates the solution on the following test suite of three cases, each specified by $(n, a, x^{\\star})$ with $y = A x^{\\star}$:\n  1. A general \"happy path\" case: $n = 64$. Choose $a \\in \\mathbb{R}^n$ with independent standard normal entries. Choose $x^{\\star}$ to be $3$-sparse with nonzero entries drawn from a standard normal distribution at random positions. Set $\\gamma = 10^{-12}$ and $\\rho = 1$.\n  2. A boundary case (identity operator): $n = 32$. Let $a = e_1 \\in \\mathbb{R}^n$ (first standard basis vector), which yields $A = I_n$. Choose any $5$-sparse $x^{\\star}$ with nonzero entries drawn from a standard normal distribution at random positions. Set $\\gamma = 0$ and $\\rho = 1$.\n  3. An edge case (near singular spectrum): $n = 64$. Choose $a$ such that $a_0 = 10^{-3}$, $a_1 = 1$, and $a_k = 0$ for $k \\ge 2$. Choose $x^{\\star}$ to be $4$-sparse with nonzero entries drawn from a standard normal distribution at random positions. Set $\\gamma = 10^{-8}$ and $\\rho = 1$.\n\nFor each test case, run ADMM until convergence or a fixed iteration cap. Declare success if and only if both conditions hold:\n- The relative recovery error satisfies\n$$\n\\frac{\\|x^{(K)} - x^{\\star}\\|_2}{\\max\\{\\|x^{\\star}\\|_2, 10^{-12}\\}} \\le 10^{-3},\n$$\nwhere $x^{(K)}$ is the final ADMM estimate.\n- The measurement residual satisfies\n$$\n\\|A x^{(K)} - y\\|_2 \\le 10^{-8}.\n$$\n\nYour program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets (e.g., \"[true_case1,true_case2,true_case3]\"), where each entry is a boolean indicating success for that case. Angles and physical units are not applicable; all quantities are purely mathematical. Do not print anything else besides this single line.", "solution": "The problem asks for the derivation and implementation of the Alternating Direction Method of Multipliers (ADMM) to solve the constrained Basis Pursuit problem, leveraging the circulant structure of the sensing matrix $A$ for computational efficiency using the Fast Fourier Transform (FFT).\n\nThe optimization problem is:\n$$\n\\min_{x \\in \\mathbb{R}^n} \\|x\\|_1 \\quad \\text{subject to} \\quad A x = y\n$$\nHere, $A \\in \\mathbb{R}^{n \\times n}$ is a circulant matrix generated by a kernel $a \\in \\mathbb{R}^n$, such that the operation $Ax$ corresponds to the circular convolution $a \\star x$.\n\nTo apply ADMM, we introduce a splitting variable $z \\in \\mathbb{R}^n$ and an auxiliary constraint $x=z$. The problem is reformulated as:\n$$\n\\min_{x,z \\in \\mathbb{R}^n} f(x) + g(z) \\quad \\text{subject to} \\quad x - z = 0\n$$\nwhere $f(x) = I_{\\{u \\in \\mathbb{R}^n : A u = y\\}}(x)$ is the indicator function for the affine set of measurement consistency, and $g(z) = \\|z\\|_1$ is the sparsity-promoting one-norm. The indicator function $I_{\\mathcal{C}}(x)$ is $0$ if $x \\in \\mathcal{C}$ and $+\\infty$ otherwise.\n\nThe scaled-form augmented Lagrangian for this problem, with penalty parameter $\\rho > 0$ and scaled dual variable $u$, is:\n$$\n\\mathcal{L}_{\\rho}(x, z, u) = f(x) + g(z) + \\frac{\\rho}{2} \\|x - z + u\\|_2^2 - \\frac{\\rho}{2} \\|u\\|_2^2\n$$\nADMM proceeds by iteratively minimizing $\\mathcal{L}_{\\rho}$ with respect to $x$ and $z$, followed by an update of the dual variable $u$. The sequence of updates at iteration $k+1$ is:\n1.  $x^{(k+1)} := \\arg\\min_x \\mathcal{L}_{\\rho}(x, z^{(k)}, u^{(k)})$\n2.  $z^{(k+1)} := \\arg\\min_z \\mathcal{L}_{\\rho}(x^{(k+1)}, z, u^{(k)})$\n3.  $u^{(k+1)} := u^{(k)} + x^{(k+1)} - z^{(k+1)}$\n\nWe now derive each update step in detail.\n\n**1. The $x$-update**\n\nThe minimization for $x$ is:\n$$\nx^{(k+1)} = \\arg\\min_x \\left( I_{\\{x : Ax=y\\}}(x) + \\frac{\\rho}{2} \\|x - z^{(k)} + u^{(k)}\\|_2^2 \\right)\n$$\nThis update is equivalent to finding a point $x$ that satisfies the constraint $Ax=y$ while being closest in the Euclidean sense to the vector $w^{(k)} = z^{(k)} - u^{(k)}$. This is precisely the orthogonal projection of $w^{(k)}$ onto the affine subspace $\\mathcal{C} = \\{x \\in \\mathbb{R}^n : A x = y\\}$.\n$$\nx^{(k+1)} = \\Pi_{\\mathcal{C}}(w^{(k)})\n$$\nThe formula for this projection is given as $\\Pi_{\\mathcal{C}}(w) = w + A^{\\top} (A A^{\\top})^{-1} (y - A w)$. To handle potentially singular or ill-conditioned $A A^{\\top}$, a small ridge parameter $\\gamma \\ge 0$ is added, leading to the regularized projection:\n$$\nx^{(k+1)} = w^{(k)} + A^{\\top}(A A^{\\top} + \\gamma I)^{-1}(y - A w^{(k)})\n$$\nThe efficiency of this step comes from the circulant structure of $A$. A circulant matrix is diagonalized by the Discrete Fourier Transform. Let $\\text{fft}(\\cdot)$ and $\\text{ifft}(\\cdot)$ denote the Fast Fourier Transform and its inverse. The circular convolution property states that $a \\star x = \\text{ifft}(\\text{fft}(a) \\odot \\text{fft}(x))$, where $\\odot$ is elementwise multiplication. Let $\\hat{v} = \\text{fft}(v)$.\n-   The action of $A$ is $Ax = \\text{ifft}(\\hat{a} \\odot \\hat{x})$.\n-   The action of the transpose $A^{\\top}$ (which is circulant with a flipped kernel) corresponds to $A^{\\top}r = \\text{ifft}(\\overline{\\hat{a}} \\odot \\hat{r})$, where $\\overline{\\hat{a}}$ is the complex conjugate of $\\hat{a}$.\n-   The operator $AA^{\\top}$ corresponds to multiplication in the Fourier domain by $\\hat{a} \\odot \\overline{\\hat{a}} = |\\hat{a}|^2$.\n-   The operator $(AA^{\\top} + \\gamma I)$ corresponds to multiplication in the Fourier domain by $|\\hat{a}|^2 + \\gamma$.\n-   Consequently, the inverse operator $(AA^{\\top} + \\gamma I)^{-1}$ corresponds to elementwise division in the Fourier domain by $|\\hat{a}|^2 + \\gamma$.\n\nLet $r^{(k)} = y - A w^{(k)}$. The correction term $c^{(k)} = A^{\\top}(A A^{\\top} + \\gamma I)^{-1} r^{(k)}$ can be computed efficiently.\nFirst, apply the inverse operator to $r^{(k)}$: $v^{(k)} = (A A^{\\top} + \\gamma I)^{-1} r^{(k)}$. In the Fourier domain, this is $\\hat{v}^{(k)} = \\hat{r}^{(k)} \\oslash (|\\hat{a}|^2 + \\gamma)$, where $\\oslash$ denotes elementwise division.\nThen, apply $A^\\top$ to $v^{(k)}$: $c^{(k)} = A^\\top v^{(k)}$. In the Fourier domain, this is $\\hat{c}^{(k)} = \\overline{\\hat{a}} \\odot \\hat{v}^{(k)}$.\nCombining these, the Fourier transform of the correction term is:\n$$\n\\hat{c}^{(k)} = \\overline{\\hat{a}} \\odot \\left( \\frac{\\text{fft}(y - A w^{(k)})}{|\\hat{a}|^2 + \\gamma} \\right)\n$$\nThe full $x$-update consists of computing $w^{(k)} = z^{(k)} - u^{(k)}$, then computing $c^{(k)} = \\text{ifft}(\\hat{c}^{(k)})$, and finally setting $x^{(k+1)} = w^{(k)} + c^{(k)}$. Since all input vectors are real, the updated $x^{(k+1)}$ must also be real; any imaginary part is due to numerical noise and should be discarded.\n\n**2. The $z$-update**\n\nThe minimization for $z$ is:\n$$\nz^{(k+1)} = \\arg\\min_z \\left( \\|z\\|_1 + \\frac{\\rho}{2} \\|x^{(k+1)} - z + u^{(k)}\\|_2^2 \\right)\n$$\nRearranging the quadratic term gives:\n$$\nz^{(k+1)} = \\arg\\min_z \\left( \\|z\\|_1 + \\frac{\\rho}{2} \\|z - (x^{(k+1)} + u^{(k)})\\|_2^2 \\right)\n$$\nThis is the definition of the proximal operator of the $\\ell_1$-norm. Specifically, it is $\\mathrm{prox}_{\\frac{1}{\\rho}\\|\\cdot\\|_1}(x^{(k+1)} + u^{(k)})$. The proximal operator of $\\lambda \\|\\cdot\\|_1$ is the elementwise soft-thresholding operator $S_{\\lambda}(v)_i = \\mathrm{sign}(v_i) \\max(|v_i| - \\lambda, 0)$. For our problem, the function is $1 \\cdot \\|\\cdot\\|_1$ and the penalty parameter is $\\rho/2$, which corresponds to a prox-parameter of $1/\\rho$.\nThus, the update is given by entrywise soft-thresholding:\n$$\nz^{(k+1)} = S_{1/\\rho}(x^{(k+1)} + u^{(k)})\n$$\n\n**3. The $u$-update**\n\nThe update for the scaled dual variable $u$ is straightforward:\n$$\nu^{(k+1)} = u^{(k)} + x^{(k+1)} - z^{(k+1)}\n$$\nThis step enforces the constraint $x=z$. The term $x^{(k+1)} - z^{(k+1)}$ is the primal residual at the current iteration.\n\n**Stopping Criteria**\n\nThe convergence of ADMM can be monitored using primal and dual residuals. The primal residual is $r_{\\text{primal}}^{(k+1)} = x^{(k+1)} - z^{(k+1)}$, measuring the violation of the constraint $x-z=0$. The dual residual, $r_{\\text{dual}}^{(k+1)} = \\rho A^\\top A (z^{(k+1)} - z^{(k)})$, measures the change in the dual objective. In practice, a simpler form $r_{\\text{dual}}^{(k+1)} = \\rho(z^{(k+1)} - z^{(k)})$ is often used. The algorithm is considered to have converged when the norms of both residuals fall below certain tolerances. For the present problem, we run the algorithm for a fixed number of iterations and then check the final solution against specified quality criteria.\nThe dual variable $u$ can be interpreted as a running sum of the primal errors, providing an integral-like correction that drives the primal residual to zero.\n\n**Algorithm Summary**\nInitialize $x^{(0)}$, $z^{(0)}$, $u^{(0)}$ (e.g., to zero vectors), and choose $\\rho > 0$, $\\gamma > 0$. For $k=0, 1, 2, \\ldots$\n1.  $w^{(k)} = z^{(k)} - u^{(k)}$\n2.  $r^{(k)} = y - \\text{ifft}(\\hat{a} \\odot \\text{fft}(w^{(k)}))$\n3.  $\\hat{c}^{(k)} = \\overline{\\hat{a}} \\odot \\text{fft}(r^{(k)}) \\oslash (|\\hat{a}|^2 + \\gamma)$\n4.  $c^{(k)} = \\text{ifft}(\\hat{c}^{(k)})$\n5.  $x^{(k+1)} = \\text{real}(w^{(k)} + c^{(k)})$\n6.  $v^{(k)} = x^{(k+1)} + u^{(k)}$\n7.  $z^{(k+1)} = \\text{sign}(v^{(k)}) \\odot \\max(\\text{abs}(v^{(k)}) - 1/\\rho, 0)$\n8.  $u^{(k+1)} = u^{(k)} + x^{(k+1)} - z^{(k+1)}$\nThis iterative process is implemented to solve the given problem.", "answer": "```python\nimport numpy as np\nfrom numpy.fft import fft, ifft\n\ndef admm_basis_pursuit(a, y, rho, gamma, max_iter=1000):\n    \"\"\"\n    Solves the constrained Basis Pursuit problem using ADMM.\n\n    min ||x||_1 subject to Ax=y, where A is a circulant matrix.\n\n    Args:\n        a (np.ndarray): The real kernel generating the circulant matrix A.\n        y (np.ndarray): The measurement vector.\n        rho (float): The ADMM penalty parameter.\n        gamma (float): The ridge regularization parameter for matrix inversion.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        np.ndarray: The estimated sparse signal x.\n    \"\"\"\n    n = len(a)\n    \n    # Pre-compute Fourier transform of the kernel and related quantities\n    a_hat = fft(a)\n    a_hat_conj = np.conj(a_hat)\n    a_hat_mag_sq = np.abs(a_hat)**2\n\n    # Denominator for the x-update, pre-computed for efficiency\n    x_update_denom = a_hat_mag_sq + gamma\n\n    # Initialize variables\n    x = np.zeros(n)\n    z = np.zeros(n)\n    u = np.zeros(n)\n\n    # Soft-thresholding lambda\n    lambda_st = 1.0 / rho\n\n    for _ in range(max_iter):\n        # x-update (projection onto {x | Ax=y})\n        w = z - u\n        \n        # Aw = ifft(fft(a) * fft(w))\n        Aw = np.real(ifft(a_hat * fft(w)))\n        \n        # residual r = y - Aw\n        r = y - Aw\n        \n        # FFT of residual\n        r_hat = fft(r)\n        \n        # Correction term in Fourier domain\n        # c_hat = conj(a_hat) * r_hat / (|a_hat|^2 + gamma)\n        c_hat = a_hat_conj * r_hat / x_update_denom\n        \n        # Correction term in signal domain\n        c = np.real(ifft(c_hat))\n        \n        x = w + c\n\n        # z-update (soft-thresholding)\n        v = x + u\n        z = np.sign(v) * np.maximum(np.abs(v) - lambda_st, 0)\n        \n        # u-update (dual variable update)\n        u = u + x - z\n        \n    return x\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    rng = np.random.default_rng(42)  # Seed for reproducibility\n    results = []\n\n    # --- Test Case 1: General \"happy path\" case ---\n    n1 = 64\n    k1 = 3\n    a1 = rng.standard_normal(n1)\n    x_star1 = np.zeros(n1)\n    indices1 = rng.choice(n1, k1, replace=False)\n    x_star1[indices1] = rng.standard_normal(k1)\n    y1 = np.real(ifft(fft(a1) * fft(x_star1)))\n    gamma1 = 1e-12\n    rho1 = 1.0\n\n    x_final1 = admm_basis_pursuit(a1, y1, rho1, gamma1)\n    \n    err_norm1 = np.linalg.norm(x_final1 - x_star1)\n    x_star_norm1 = np.linalg.norm(x_star1)\n    rel_err1 = err_norm1 / max(x_star_norm1, 1e-12)\n    \n    y_final1 = np.real(ifft(fft(a1) * fft(x_final1)))\n    res_norm1 = np.linalg.norm(y_final1 - y1)\n    \n    success1 = rel_err1 <= 1e-3 and res_norm1 <= 1e-8\n    results.append(success1)\n    \n    # --- Test Case 2: Boundary case (identity operator) ---\n    n2 = 32\n    k2 = 5\n    a2 = np.zeros(n2)\n    a2[0] = 1.0  # a = e_1 => A = I\n    x_star2 = np.zeros(n2)\n    indices2 = rng.choice(n2, k2, replace=False)\n    x_star2[indices2] = rng.standard_normal(k2)\n    y2 = np.real(ifft(fft(a2) * fft(x_star2))) # y2 = x_star2\n    gamma2 = 0.0\n    rho2 = 1.0\n    \n    # For A=I, problem is min ||x||_1 s.t. x=y. Solution is x=y.\n    # ADMM should converge very quickly.\n    x_final2 = admm_basis_pursuit(a2, y2, rho2, gamma2, max_iter=20)\n    \n    err_norm2 = np.linalg.norm(x_final2 - x_star2)\n    x_star_norm2 = np.linalg.norm(x_star2)\n    rel_err2 = err_norm2 / max(x_star_norm2, 1e-12)\n    \n    y_final2 = np.real(ifft(fft(a2) * fft(x_final2)))\n    res_norm2 = np.linalg.norm(y_final2 - y2)\n    \n    success2 = rel_err2 <= 1e-3 and res_norm2 <= 1e-8\n    results.append(success2)\n\n    # --- Test Case 3: Edge case (near singular spectrum) ---\n    n3 = 64\n    k3 = 4\n    a3 = np.zeros(n3)\n    a3[0] = 1e-3\n    a3[1] = 1.0\n    x_star3 = np.zeros(n3)\n    indices3 = rng.choice(n3, k3, replace=False)\n    x_star3[indices3] = rng.standard_normal(k3)\n    y3 = np.real(ifft(fft(a3) * fft(x_star3)))\n    gamma3 = 1e-8\n    rho3 = 1.0\n    \n    x_final3 = admm_basis_pursuit(a3, y3, rho3, gamma3, max_iter=2000)\n    \n    err_norm3 = np.linalg.norm(x_final3 - x_star3)\n    x_star_norm3 = np.linalg.norm(x_star3)\n    rel_err3 = err_norm3 / max(x_star_norm3, 1e-12)\n    \n    y_final3 = np.real(ifft(fft(a3) * fft(x_final3)))\n    res_norm3 = np.linalg.norm(y_final3 - y3)\n    \n    success3 = rel_err3 <= 1e-3 and res_norm3 <= 1e-8\n    results.append(success3)\n    \n    # Print results in the specified format\n    print(f\"[{','.join(map(str, results))}]\".lower())\n\nsolve()\n```", "id": "3490941"}]}