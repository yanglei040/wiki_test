{"hands_on_practices": [{"introduction": "Before applying basis functions to solve complex equations, it's essential to understand their fundamental construction. This exercise guides you through a first-principles derivation of the quadratic ($P_2$) Lagrange basis functions on a reference element. By constructing and inverting the Vandermonde matrix, you will solidify your understanding of the direct link between the abstract definition of nodal basis functions and their explicit polynomial form [@problem_id:3359471].", "problem": "In the context of the Finite Element Method (FEM) for Partial Differential Equations (PDEs), consider the reference interval $[-1,1]$ with the nodal set $\\{-1,0,1\\}$. The quadratic Lagrange basis functions $\\{\\ell_{-1}(x), \\ell_{0}(x), \\ell_{1}(x)\\}$ are the unique polynomials in the space of degree at most $2$ that satisfy the nodal Kronecker-delta conditions $\\ell_{i}(x_{j})=\\delta_{ij}$ for the nodes $x_{-1}=-1$, $x_{0}=0$, and $x_{1}=1$. Using only first principles, namely the definition of Lagrange nodal basis functions and the construction and inversion of the associated Vandermonde matrix built from the monomial basis $\\{1,x,x^{2}\\}$, derive the coefficient vectors of these polynomials by inverting the $3\\times 3$ Vandermonde matrix for the nodes $\\{-1,0,1\\}$, and explicitly write each basis polynomial in simplified standard polynomial form. Provide your final answer as a single row matrix containing the three polynomials in $x$. No rounding is required.", "solution": "The problem is subjected to validation before a solution is attempted.\n\n### Step 1: Extract Givens\n- **Domain:** The reference interval is $[-1,1]$.\n- **Nodes:** The nodal set is $\\{x_{-1}, x_{0}, x_{1}\\} = \\{-1, 0, 1\\}$.\n- **Basis Functions:** We seek the quadratic Lagrange basis functions $\\{\\ell_{-1}(x), \\ell_{0}(x), \\ell_{1}(x)\\}$.\n- **Polynomial Space:** The basis functions are polynomials of degree at most $2$.\n- **Defining Property:** The basis functions must satisfy the Kronecker-delta conditions at the nodes: $\\ell_{i}(x_{j})=\\delta_{ij}$, where $i, j \\in \\{-1, 0, 1\\}$.\n- **Methodology:** The derivation must use the monomial basis $\\{1, x, x^2\\}$ to construct the Vandermonde matrix for the given nodes, invert this matrix, and use the inverse to find the coefficients of the basis polynomials.\n- **Output:** The final answer must be the explicit polynomials in simplified standard form, presented as a single row matrix.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is based on fundamental, well-established principles of numerical analysis, specifically the theory of polynomial interpolation and the Finite Element Method. The concepts of Lagrange basis functions, monomial bases, and Vandermonde matrices are standard in mathematics and engineering.\n- **Well-Posed:** The problem is well-posed. For any set of $n+1$ distinct nodes, there exists a unique set of $n+1$ Lagrange basis polynomials of degree at most $n$. The problem provides $3$ distinct nodes and asks for the unique quadratic (degree $2$) basis, and specifies a valid constructive method.\n- **Objective:** The problem is stated in precise, objective mathematical language, free from ambiguity or subjective claims.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid** as it is scientifically sound, well-posed, and objective. A solution will be derived following the specified methodology.\n\n### Solution Derivation\n\nA general quadratic polynomial can be expressed as a linear combination of the monomial basis $\\{1, x, x^2\\}$:\n$$p(x) = c_0 \\cdot 1 + c_1 \\cdot x + c_2 \\cdot x^2$$\nWe seek three such polynomials, $\\ell_{-1}(x)$, $\\ell_{0}(x)$, and $\\ell_{1}(x)$, with coefficient vectors $(c_{-1,0}, c_{-1,1}, c_{-1,2})$, $(c_{0,0}, c_{0,1}, c_{0,2})$, and $(c_{1,0}, c_{1,1}, c_{1,2})$ respectively.\n\nThe defining property of Lagrange basis functions is $\\ell_{i}(x_j) = \\delta_{ij}$. For a generic basis function $\\ell_i(x) = c_{i0} + c_{i1}x + c_{i2}x^2$, evaluating at the three nodes $x_{-1}=-1$, $x_0=0$, and $x_1=1$ yields a system of three linear equations for its three coefficients:\n$$\n\\begin{cases}\nc_{i0} + c_{i1}(x_{-1}) + c_{i2}(x_{-1})^2 = \\delta_{i, -1} \\\\\nc_{i0} + c_{i1}(x_{0}) + c_{i2}(x_{0})^2 = \\delta_{i, 0} \\\\\nc_{i0} + c_{i1}(x_{1}) + c_{i2}(x_{1})^2 = \\delta_{i, 1}\n\\end{cases}\n$$\nSubstituting the nodal values $x_{-1}=-1$, $x_0=0$, $x_1=1$:\n$$\n\\begin{cases}\nc_{i0} - c_{i1} + c_{i2} = \\delta_{i, -1} \\\\\nc_{i0} = \\delta_{i, 0} \\\\\nc_{i0} + c_{i1} + c_{i2} = \\delta_{i, 1}\n\\end{cases}\n$$\nThis system can be written in matrix form as $V \\mathbf{c}_i = \\mathbf{d}_i$, where $\\mathbf{c}_i = (c_{i0}, c_{i1}, c_{i2})^T$, $\\mathbf{d}_i = (\\delta_{i,-1}, \\delta_{i,0}, \\delta_{i,1})^T$, and $V$ is the Vandermonde matrix constructed from the nodes:\n$$V = \\begin{pmatrix} 1  x_{-1}  x_{-1}^2 \\\\ 1  x_{0}  x_{0}^2 \\\\ 1  x_{1}  x_{1}^2 \\end{pmatrix} = \\begin{pmatrix} 1  -1  (-1)^2 \\\\ 1  0  0^2 \\\\ 1  1  1^2 \\end{pmatrix} = \\begin{pmatrix} 1  -1  1 \\\\ 1  0  0 \\\\ 1  1  1 \\end{pmatrix}$$\nThe right-hand side vectors for $i = -1, 0, 1$ are the standard basis vectors of $\\mathbb{R}^3$, albeit ordered differently due to the node indexing:\n$\\mathbf{d}_{-1} = (1,0,0)^T$, $\\mathbf{d}_{0} = (0,1,0)^T$, and $\\mathbf{d}_{1} = (0,0,1)^T$.\n\nThe coefficient vectors $\\mathbf{c}_i$ are found by solving $\\mathbf{c}_i = V^{-1}\\mathbf{d}_i$. This means the coefficient vector for $\\ell_{-1}(x)$ is the first column of $V^{-1}$, the vector for $\\ell_0(x)$ is the second column, and for $\\ell_1(x)$ is the third column. Our task reduces to finding the inverse of the Vandermonde matrix $V$.\n\nFirst, we compute the determinant of $V$ by expanding along the second row:\n$$\\det(V) = 1 \\cdot (-1)^{2+1} \\det\\begin{pmatrix} -1  1 \\\\ 1  1 \\end{pmatrix} = -1((-1)(1) - (1)(1)) = -1(-2) = 2$$\nSince $\\det(V) \\neq 0$, the inverse $V^{-1}$ exists. We find it using the adjugate matrix formula, $V^{-1} = \\frac{1}{\\det(V)}\\text{adj}(V)$. The adjugate matrix is the transpose of the cofactor matrix.\n\nThe matrix of cofactors, $C_{ij} = (-1)^{i+j}M_{ij}$, is:\n$$\n\\text{cof}(V) = \\begin{pmatrix}\n+\\det\\begin{pmatrix} 0  0 \\\\ 1  1 \\end{pmatrix}  -\\det\\begin{pmatrix} 1  0 \\\\ 1  1 \\end{pmatrix}  +\\det\\begin{pmatrix} 1  0 \\\\ 1  1 \\end{pmatrix} \\\\\n-\\det\\begin{pmatrix} -1  1 \\\\ 1  1 \\end{pmatrix}  +\\det\\begin{pmatrix} 1  1 \\\\ 1  1 \\end{pmatrix}  -\\det\\begin{pmatrix} 1  -1 \\\\ 1  1 \\end{pmatrix} \\\\\n+\\det\\begin{pmatrix} -1  1 \\\\ 0  0 \\end{pmatrix}  -\\det\\begin{pmatrix} 1  1 \\\\ 1  0 \\end{pmatrix}  +\\det\\begin{pmatrix} 1  -1 \\\\ 1  0 \\end{pmatrix}\n\\end{pmatrix}\n= \\begin{pmatrix}\n0  -1  1 \\\\\n2  0  -2 \\\\\n0  1  1\n\\end{pmatrix}\n$$\nThe adjugate matrix is the transpose of the cofactor matrix:\n$$\\text{adj}(V) = (\\text{cof}(V))^T = \\begin{pmatrix} 0  2  0 \\\\ -1  0  1 \\\\ 1  -2  1 \\end{pmatrix}$$\nThe inverse matrix is:\n$$V^{-1} = \\frac{1}{2} \\begin{pmatrix} 0  2  0 \\\\ -1  0  1 \\\\ 1  -2  1 \\end{pmatrix} = \\begin{pmatrix} 0  1  0 \\\\ -\\frac{1}{2}  0  \\frac{1}{2} \\\\ \\frac{1}{2}  -1  \\frac{1}{2} \\end{pmatrix}$$\nThe columns of $V^{-1}$ contain the coefficients $(c_{i0}, c_{i1}, c_{i2})$ for the polynomials.\nThe first column gives the coefficients for $\\ell_{-1}(x)$:\n$$\\begin{pmatrix} c_{-1,0} \\\\ c_{-1,1} \\\\ c_{-1,2} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -\\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} \\implies \\ell_{-1}(x) = 0 - \\frac{1}{2}x + \\frac{1}{2}x^2 = \\frac{1}{2}x^2 - \\frac{1}{2}x$$\nThe second column gives the coefficients for $\\ell_{0}(x)$:\n$$\\begin{pmatrix} c_{0,0} \\\\ c_{0,1} \\\\ c_{0,2} \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ -1 \\end{pmatrix} \\implies \\ell_{0}(x) = 1 + 0x - 1x^2 = 1 - x^2$$\nThe third column gives the coefficients for $\\ell_{1}(x)$:\n$$\\begin{pmatrix} c_{1,0} \\\\ c_{1,1} \\\\ c_{1,2} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ \\frac{1}{2} \\\\ \\frac{1}{2} \\end{pmatrix} \\implies \\ell_{1}(x) = 0 + \\frac{1}{2}x + \\frac{1}{2}x^2 = \\frac{1}{2}x^2 + \\frac{1}{2}x$$\nThe three basis polynomials in simplified standard form are:\n$\\ell_{-1}(x) = \\frac{1}{2}x^2 - \\frac{1}{2}x$\n$\\ell_{0}(x) = -x^2 + 1$\n$\\ell_{1}(x) = \\frac{1}{2}x^2 + \\frac{1}{2}x$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{2}x^2 - \\frac{1}{2}x  1 - x^2  \\frac{1}{2}x^2 + \\frac{1}{2}x\n\\end{pmatrix}\n}\n$$", "id": "3359471"}, {"introduction": "In the Finite Element Method, we translate differential equations into systems of linear equations by integrating products of basis functions. This exercise addresses a critical practical aspect of this process: how to perform these integrations efficiently and exactly using numerical quadrature. You will determine the minimum number of quadrature points needed to precisely calculate the stiffness matrix entries for quadratic and cubic elements, linking the polynomial degree of the derivatives to the required order of the integration rule [@problem_id:3359439].", "problem": "In the finite element method (FEM) for the numerical solution of one-dimensional partial differential equations (PDEs), consider the reference element $\\hat{\\Omega} = [-1,1]$ and the standard Lagrange nodal basis $\\{\\ell_i(\\hat{x})\\}$ of degree $p$ on $\\hat{\\Omega}$. The local stiffness matrix entries for a constant-coefficient elliptic operator on $\\hat{\\Omega}$ are\n$$\nK_{ij} \\;=\\; \\int_{-1}^{1} \\ell_i'(\\hat{x})\\,\\ell_j'(\\hat{x})\\,d\\hat{x}.\n$$\nAssume these integrals are evaluated using $n$-point Gauss–Legendre quadrature on $[-1,1]$, which has polynomial exactness of degree $2n-1$. For polynomial degrees $p=2$ and $p=3$ (denoted $P_2$ and $P_3$), determine the minimal number of quadrature points $n$ required so that $K_{ij}$ is integrated exactly for all basis function index pairs $(i,j)$ in each case. Express your answers for $P_2$ and $P_3$ as a single row vector in increasing order of $p$. No rounding is required and no physical units are involved.", "solution": "The problem requires determining the minimal number of Gauss-Legendre quadrature points, $n$, needed to exactly compute the entries of the local stiffness matrix $K_{ij}$ for one-dimensional Lagrange finite elements of polynomial degree $p=2$ and $p=3$.\n\nThe entries of the stiffness matrix on the reference element $\\hat{\\Omega} = [-1,1]$ are given by the integral:\n$$\nK_{ij} = \\int_{-1}^{1} \\ell_i'(\\hat{x})\\,\\ell_j'(\\hat{x})\\,d\\hat{x}\n$$\nHere, $\\{\\ell_i(\\hat{x})\\}$ is the set of Lagrange basis functions of degree $p$. By definition, each basis function $\\ell_i(\\hat{x})$ is a polynomial of degree $p$.\n\nThe first step is to determine the polynomial degree of the integrand, which is $I(\\hat{x}) = \\ell_i'(\\hat{x})\\,\\ell_j'(\\hat{x})$.\nThe derivative of a polynomial of degree $p$ is a polynomial of degree $p-1$. Therefore, both $\\ell_i'(\\hat{x})$ and $\\ell_j'(\\hat{x})$ are polynomials of degree $p-1$.\n\nThe product of two polynomials of degree $p-1$ is a polynomial of degree $(p-1) + (p-1) = 2p-2$. Thus, the integrand $I(\\hat{x})$ is a polynomial of degree $2p-2$.\n\nThe problem states that an $n$-point Gauss-Legendre quadrature rule is exact for polynomials of degree up to $2n-1$. For the integral of $I(\\hat{x})$ to be evaluated exactly, the degree of exactness of the quadrature rule must be greater than or equal to the degree of the polynomial $I(\\hat{x})$. This gives the following inequality:\n$$\n2n-1 \\ge \\deg(I(\\hat{x}))\n$$\nSubstituting the degree of the integrand, we have:\n$$\n2n-1 \\ge 2p-2\n$$\nTo find the minimal number of points $n$, we solve this inequality for $n$:\n$$\n2n \\ge 2p-2+1\n$$\n$$\n2n \\ge 2p-1\n$$\n$$\nn \\ge \\frac{2p-1}{2}\n$$\n$$\nn \\ge p - \\frac{1}{2}\n$$\nSince the number of quadrature points $n$ must be an integer, the minimal value for $n$ is the smallest integer that satisfies this condition. This is found by taking the ceiling of the right-hand side:\n$$\nn_{min} = \\lceil p - \\frac{1}{2} \\rceil\n$$\nFor any integer $p \\ge 1$, this simplifies to $n_{min} = p$.\n\nWe now apply this general result to the two specific cases requested.\n\nCase 1: $p=2$ (Quadratic basis functions, $P_2$)\nFor $p=2$, the minimal number of quadrature points is:\n$$\nn \\ge 2 - \\frac{1}{2} = 1.5\n$$\nThe smallest integer $n$ satisfying this is $n=2$.\nAlternatively, the degree of the integrand is $2(2)-2 = 2$. The exactness condition is $2n-1 \\ge 2$, which gives $2n \\ge 3$, or $n \\ge 1.5$. The minimal integer is $n=2$.\n\nCase 2: $p=3$ (Cubic basis functions, $P_3$)\nFor $p=3$, the minimal number of quadrature points is:\n$$\nn \\ge 3 - \\frac{1}{2} = 2.5\n$$\nThe smallest integer $n$ satisfying this is $n=3$.\nAlternatively, the degree of the integrand is $2(3)-2 = 4$. The exactness condition is $2n-1 \\ge 4$, which gives $2n \\ge 5$, or $n \\ge 2.5$. The minimal integer is $n=3$.\n\nThe minimal number of quadrature points required for $p=2$ is $2$, and for $p=3$ is $3$. The problem asks for these answers as a single row vector in increasing order of $p$. The order is $(p=2, p=3)$, so the corresponding values of $n$ are $(2, 3)$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n2  3\n\\end{pmatrix}\n}\n$$", "id": "3359439"}, {"introduction": "This advanced practice integrates the preceding concepts into a comprehensive computational problem involving the wave equation. You will implement a finite element model using both quadratic and cubic bases, exploring the practical technique of mass lumping and its effect on the system's dynamics. By analyzing the eigenvalues of the resulting semi-discrete systems, you will directly observe how theoretical choices about basis functions and matrix assembly influence the numerical stability and maximum permissible time step of an explicit simulation [@problem_id:3359464].", "problem": "You are asked to implement and analyze one-dimensional continuous Galerkin finite element semi-discretizations of the wave equation using quadratic and cubic Lagrange bases with Gauss–Lobatto nodal points and Gauss–Lobatto quadrature for mass lumping.\n\nConsider the one-dimensional wave equation on the unit interval with homogeneous Dirichlet boundary conditions,\n$$\nu_{tt}(x,t) - u_{xx}(x,t) = 0,\\quad x\\in(0,1),\\ t0,\\qquad u(0,t)=u(1,t)=0,\n$$\nand initial data that need not be specified for the purposes of this spectral analysis. Use the Galerkin Finite Element Method (FEM) with continuous Lagrange basis functions of polynomial degree $p\\in\\{2,3\\}$ on a uniform partition of $[0,1]$ into $N_e$ elements of equal length $h=1/N_e$. On each element, use Lagrange nodal basis functions defined on the reference interval $[-1,1]$ with Gauss–Lobatto nodes. Assemble the global semi-discrete system\n$$\n\\mathbf{M}\\,\\ddot{\\mathbf{u}}(t) + \\mathbf{K}\\,\\mathbf{u}(t) = \\mathbf{0},\n$$\nwhere $\\mathbf{M}$ and $\\mathbf{K}$ denote the mass and stiffness matrices corresponding to the bilinear forms\n$$\nm(u,v)=\\int_0^1 u\\,v\\,dx,\\qquad a(u,v)=\\int_0^1 u_x\\,v_x\\,dx.\n$$\nImpose the homogeneous Dirichlet boundary conditions by eliminating the boundary degrees of freedom.\n\nLocal element matrices should be constructed by mapping the reference element $[-1,1]$ via the affine map $x(\\xi) = x_e + \\tfrac{h}{2}(\\xi+1)$, so that\n$$\n\\int_{x_e}^{x_{e+1}} \\phi_i(x)\\,\\phi_j(x)\\,dx = \\frac{h}{2}\\int_{-1}^1 \\ell_i(\\xi)\\,\\ell_j(\\xi)\\,d\\xi,\\quad\n\\int_{x_e}^{x_{e+1}} \\phi_i'(x)\\,\\phi_j'(x)\\,dx = \\frac{2}{h}\\int_{-1}^1 \\ell_i'(\\xi)\\,\\ell_j'(\\xi)\\,d\\xi,\n$$\nwith $\\{\\ell_i\\}_{i=0}^p$ denoting the degree-$p$ Lagrange basis on the Gauss–Lobatto nodes of the reference interval and primes denoting differentiation with respect to the indicated variable. Use Gauss–Legendre quadrature with $p+1$ points to compute the consistent mass and stiffness integrals exactly. Implement mass lumping by replacing the consistent element mass matrix with the Gauss–Lobatto quadrature applied to the same integrand, which produces a diagonal element mass matrix when the quadrature nodes coincide with the Lagrange interpolation nodes. For $p=2$ use the Gauss–Lobatto nodes $\\{-1,0,1\\}$ with weights $\\{1/3,4/3,1/3\\}$, and for $p=3$ use the Gauss–Lobatto nodes $\\{-1,-1/\\sqrt{5},1/\\sqrt{5},1\\}$ with weights $\\{1/6,5/6,5/6,1/6\\}$, all on $[-1,1]$.\n\nYour tasks are:\n- Assemble the global consistent mass matrix $\\mathbf{M}_c$ and stiffness matrix $\\mathbf{K}$, and the global lumped mass matrix $\\mathbf{M}_\\ell$ obtained by Gauss–Lobatto quadrature on each element.\n- For each case, compute the spectral radius of the generalized eigenvalue problem\n$$\n\\mathbf{K}\\,\\mathbf{v} = \\lambda\\,\\mathbf{M}\\,\\mathbf{v},\n$$\nnamely the largest eigenvalue $\\lambda_{\\max}$ for $\\mathbf{M}=\\mathbf{M}_c$ and for $\\mathbf{M}=\\mathbf{M}_\\ell$.\n- Determine, by a linear stability analysis of the explicit second-order central difference time discretization applied to the semi-discrete system, the largest time step $\\Delta t_{\\max}$ that guarantees linear stability as a function of $\\lambda_{\\max}$. Express $\\Delta t_{\\max}$ in the same dimensionless units as the problem data.\n\nDesign a program that carries out these steps for the following test suite:\n- Case $1$: $p=2$, $N_e=1$.\n- Case $2$: $p=2$, $N_e=10$.\n- Case $3$: $p=3$, $N_e=1$.\n- Case $4$: $p=3$, $N_e=10$.\n\nFor each case, report a list of four floating-point values in the following order: $\\lambda_{\\max}$ with the consistent mass, $\\lambda_{\\max}$ with the lumped mass, $\\Delta t_{\\max}$ with the consistent mass, $\\Delta t_{\\max}$ with the lumped mass. Aggregate the results for the four cases, in order, into a single list of $16$ floats.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with each float rounded to $8$ decimal places (e.g., $[x_1,x_2,\\dots,x_{16}]$).", "solution": "We begin from the weak form of the one-dimensional wave equation with homogeneous Dirichlet boundary conditions: find $u(\\cdot,t)\\in H_0^1(0,1)$ such that for all $v\\in H_0^1(0,1)$,\n$$\n\\int_0^1 u_{tt}(x,t)\\,v(x)\\,dx + \\int_0^1 u_x(x,t)\\,v_x(x)\\,dx = 0.\n$$\nThe Galerkin Finite Element Method (FEM) seeks an approximation $u_h(x,t)=\\sum_{j=1}^{n} U_j(t)\\,\\phi_j(x)$ in a finite-dimensional subspace spanned by basis functions $\\{\\phi_j\\}_{j=1}^{n}\\subset H_0^1(0,1)$. Substituting $u_h$ and testing with each $\\phi_i$ yields the semi-discrete system\n$$\n\\mathbf{M}\\,\\ddot{\\mathbf{U}}(t) + \\mathbf{K}\\,\\mathbf{U}(t) = \\mathbf{0},\n$$\nwhere $\\mathbf{U}(t)=[U_1(t),\\dots,U_n(t)]^\\top$, with mass and stiffness matrices given by\n$$\nM_{ij}=\\int_0^1 \\phi_i(x)\\,\\phi_j(x)\\,dx,\\qquad K_{ij}=\\int_0^1 \\phi_i'(x)\\,\\phi_j'(x)\\,dx.\n$$\n\nWe construct $\\{\\phi_j\\}$ using continuous Lagrange basis functions of degree $p\\in\\{2,3\\}$ on a uniform mesh of $N_e$ elements over $[0,1]$, with element length $h=1/N_e$. On each element $[x_e,x_{e+1}]$, we map the reference interval $[-1,1]$ to the physical element via $x(\\xi)=x_e+\\tfrac{h}{2}(\\xi+1)$, so $dx=\\tfrac{h}{2}\\,d\\xi$. The local basis functions are the degree-$p$ Lagrange polynomials $\\{\\ell_i(\\xi)\\}_{i=0}^p$ associated with the Gauss–Lobatto nodes on $[-1,1]$. The global basis functions $\\{\\phi_j\\}$ are assembled with $C^0$ continuity, identifying shared values at element boundaries, and the essential boundary conditions $u(0,t)=u(1,t)=0$ are imposed by eliminating the first and last global nodes.\n\nWith this mapping, local element contributions satisfy\n$$\n\\int_{x_e}^{x_{e+1}} \\phi_i(x)\\,\\phi_j(x)\\,dx = \\frac{h}{2}\\int_{-1}^1 \\ell_i(\\xi)\\,\\ell_j(\\xi)\\,d\\xi,\\qquad\n\\int_{x_e}^{x_{e+1}} \\phi_i'(x)\\,\\phi_j'(x)\\,dx = \\frac{2}{h}\\int_{-1}^1 \\ell_i'(\\xi)\\,\\ell_j'(\\xi)\\,d\\xi.\n$$\nThe exact integrals on the right-hand side are polynomials of degrees $2p$ and $2p-2$, respectively. Gauss–Legendre quadrature with $p+1$ points on $[-1,1]$ integrates both exactly, since it is exact for polynomials up to degree $2(p+1)-1=2p+1\\ge 2p$. Thus, the consistent element matrices are computed by\n$$\nM^{(e)}_{ij} = \\frac{h}{2}\\sum_{k=1}^{p+1} w_k^{\\text{GL}}\\,\\ell_i(\\xi_k^{\\text{GL}})\\,\\ell_j(\\xi_k^{\\text{GL}}),\\qquad\nK^{(e)}_{ij} = \\frac{2}{h}\\sum_{k=1}^{p+1} w_k^{\\text{GL}}\\,\\ell_i'(\\xi_k^{\\text{GL}})\\,\\ell_j'(\\xi_k^{\\text{GL}}),\n$$\nwhere $\\{(\\xi_k^{\\text{GL}},w_k^{\\text{GL}})\\}_{k=1}^{p+1}$ are the Gauss–Legendre nodes and weights on $[-1,1]$.\n\nFor mass lumping, we apply Gauss–Lobatto quadrature with $p+1$ points, using nodes and weights that coincide with the Lagrange interpolation nodes. For $p=2$, the Gauss–Lobatto nodes are $\\{-1,0,1\\}$ with weights $\\{1/3,4/3,1/3\\}$; for $p=3$, the Gauss–Lobatto nodes are $\\{-1,-1/\\sqrt{5},1/\\sqrt{5},1\\}$ with weights $\\{1/6,5/6,5/6,1/6\\}$. The quadrature approximation of the local mass matrix is\n$$\n\\widetilde{M}^{(e)}_{ij} = \\frac{h}{2}\\sum_{k=0}^{p} w_k^{\\text{GLo}}\\,\\ell_i(\\xi_k^{\\text{GLo}})\\,\\ell_j(\\xi_k^{\\text{GLo}}).\n$$\nBecause the Lagrange basis satisfies $\\ell_i(\\xi_k^{\\text{GLo}})=\\delta_{ik}$ and the quadrature nodes coincide with interpolation nodes, the off-diagonal entries vanish:\n$$\n\\widetilde{M}^{(e)}_{ij} = 0\\quad\\text{for }i\\ne j,\\qquad\n\\widetilde{M}^{(e)}_{ii} = \\frac{h}{2}\\,w_i^{\\text{GLo}}.\n$$\nThus, the Gauss–Lobatto-based lumped mass matrix is diagonal elementwise and remains diagonal after global assembly.\n\nAfter assembling the global matrices and eliminating boundary degrees of freedom, we analyze the generalized eigenvalue problem\n$$\n\\mathbf{K}\\,\\mathbf{v} = \\lambda\\,\\mathbf{M}\\,\\mathbf{v},\n$$\nwith $\\mathbf{M}=\\mathbf{M}_c$ (consistent) and $\\mathbf{M}=\\mathbf{M}_\\ell$ (lumped). The spectrum $\\{\\lambda_j\\}$ is real and positive for both cases. The largest eigenvalue $\\lambda_{\\max}$ controls the stability-limiting time step for explicit central difference time discretization of the second-order system. Let $\\Delta t$ denote the time step and consider a single modal component with amplitude $a(t)$ satisfying $\\ddot{a}(t)+\\lambda a(t)=0$. Applying the central difference scheme,\n$$\n\\frac{a^{n+1}-2a^{n}+a^{n-1}}{(\\Delta t)^2} + \\lambda\\,a^{n} = 0,\n$$\nproduces the characteristic polynomial $r^2 - 2r + 1 + (\\Delta t)^2\\lambda = 0$ for the amplification factor $r$. The method is stable for a given $\\lambda$ if and only if all characteristic roots satisfy $|r|\\le 1$, which holds if and only if $(\\Delta t)^2\\lambda \\le 4$. Therefore, the maximum stable time step is\n$$\n\\Delta t_{\\max} = \\frac{2}{\\sqrt{\\lambda_{\\max}}}.\n$$\n\nAlgorithmic steps for implementation:\n- For each $p\\in\\{2,3\\}$, construct the Gauss–Lobatto node set and weights on $[-1,1]$ and the corresponding Lagrange basis and derivatives evaluated at required quadrature points.\n- For the consistent matrices, use Gauss–Legendre quadrature with $p+1$ points to compute element mass and stiffness exactly; assemble globally.\n- For the lumped mass, use Gauss–Lobatto quadrature with the same nodes to obtain diagonal element mass matrices; assemble globally.\n- Eliminate the boundary nodes to enforce $u(0,t)=u(1,t)=0$.\n- Solve the generalized eigenvalue problems $\\mathbf{K}\\mathbf{v}=\\lambda\\,\\mathbf{M}\\mathbf{v}$ for each case with $\\mathbf{M}=\\mathbf{M}_c$ and $\\mathbf{M}=\\mathbf{M}_\\ell$; extract $\\lambda_{\\max}$ in each case.\n- Compute $\\Delta t_{\\max}=2/\\sqrt{\\lambda_{\\max}}$.\n- Aggregate results as prescribed.\n\nQuantitative behavior: For fixed $p$ and decreasing $h$, the largest eigenvalue scales like $\\lambda_{\\max}\\sim C_p\\,h^{-2}$, with a constant $C_p$ depending on the choice of basis and mass matrix. Mass lumping with Gauss–Lobatto quadrature typically increases $\\lambda_{\\max}$ relative to the consistent mass, leading to a slightly smaller $\\Delta t_{\\max}$, because the lumped mass is generally smaller in the energy norm for high-frequency modes. The numerical program computes these values for the four test cases:\n- Case $1$: $p=2$, $N_e=1$.\n- Case $2$: $p=2$, $N_e=10$.\n- Case $3$: $p=3$, $N_e=1$.\n- Case $4$: $p=3$, $N_e=10$.\n\nThe final program outputs a single line with a list of $16$ floats, ordered by case, reporting $(\\lambda_{\\max}^{(c)},\\lambda_{\\max}^{(\\ell)},\\Delta t_{\\max}^{(c)},\\Delta t_{\\max}^{(\\ell)})$ for each case, each value rounded to $8$ decimal places.", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import eigh\n\ndef gauss_legendre(n):\n    # Nodes and weights on [-1,1]\n    from numpy.polynomial.legendre import leggauss\n    xi, w = leggauss(n)\n    return xi, w\n\ndef gauss_lobatto(n):\n    # Only support n=3 (p=2) and n=4 (p=3)\n    if n == 3:\n        # nodes: -1, 0, 1; weights: 1/3, 4/3, 1/3\n        xi = np.array([-1.0, 0.0, 1.0])\n        w = np.array([1.0/3.0, 4.0/3.0, 1.0/3.0])\n        return xi, w\n    elif n == 4:\n        s5 = np.sqrt(5.0)\n        xi = np.array([-1.0, -1.0/s5, 1.0/s5, 1.0])\n        w = np.array([1.0/6.0, 5.0/6.0, 5.0/6.0, 1.0/6.0])\n        return xi, w\n    else:\n        raise ValueError(\"Gauss–Lobatto only implemented for n=3 (p=2) and n=4 (p=3).\")\n\ndef lagrange_basis_and_derivative(nodes, eval_points):\n    # Compute Lagrange basis L[i,k] = l_i(eval_points[k])\n    # and derivatives dL[i,k] = l_i'(eval_points[k]) on reference [-1,1]\n    nodes = np.asarray(nodes)\n    eval_points = np.asarray(eval_points)\n    m = len(nodes)\n    q = len(eval_points)\n    L = np.ones((m, q))\n    dL = np.zeros((m, q))\n    # Precompute denominators for each basis function\n    denom = np.ones(m)\n    for i in range(m):\n        for j in range(m):\n            if j != i:\n                denom[i] *= (nodes[i] - nodes[j])\n    # Compute basis values\n    for i in range(m):\n        for j in range(m):\n            if j != i:\n                L[i, :] *= (eval_points - nodes[j])\n        L[i, :] /= denom[i]\n    # Compute derivatives using formula: l_i'(x) = sum_{m!=i} prod_{k!=i,m} (x - x_k) / prod_{k!=i} (x_i - x_k)\n    for i in range(m):\n        for k in range(q):\n            s = 0.0\n            for m_idx in range(m):\n                if m_idx == i:\n                    continue\n                prod = 1.0\n                for j in range(m):\n                    if j == i or j == m_idx:\n                        continue\n                    prod *= (eval_points[k] - nodes[j])\n                s += prod\n            dL[i, k] = s / denom[i]\n    return L, dL\n\ndef assemble_matrices(p, Ne, lumped=False):\n    # Construct global M and K with Dirichlet at ends eliminated\n    nloc = p + 1\n    # Gauss–Lobatto nodes for basis\n    xi_glob, w_glob = gauss_lobatto(nloc)\n    # Gauss–Legendre for exact consistent integration\n    xi_gleg, w_gleg = gauss_legendre(p + 1)\n    # Basis evals at Gauss–Legendre points\n    L_gl, dL_gl = lagrange_basis_and_derivative(xi_glob, xi_gleg)\n    # For lumped mass, we need nothing other than weights (diagonal)\n    # Number of global nodes before BCs\n    Nn = Ne * p + 1\n    # Initialize global matrices\n    M = np.zeros((Nn, Nn))\n    K = np.zeros((Nn, Nn))\n    h = 1.0 / Ne\n    # Element assembly\n    for e in range(Ne):\n        # Local consistent mass and stiffness\n        Me = np.zeros((nloc, nloc))\n        Ke = np.zeros((nloc, nloc))\n        # Consistent mass and stiffness using Gauss-Legendre\n        # Mass: (h/2) * sum w * L_i L_j\n        # Stiff: (2/h) * sum w * dL_i dL_j\n        Me = (h / 2.0) * (L_gl @ np.diag(w_gleg) @ L_gl.T)\n        Ke = (2.0 / h) * (dL_gl @ np.diag(w_gleg) @ dL_gl.T)\n        if lumped:\n            # Replace Me with Gauss–Lobatto lumped diagonal\n            # Me_lumped(i,i) = (h/2) * w_glob[i]\n            Me = np.diag((h / 2.0) * w_glob)\n        # Scatter to global\n        offset = e * p\n        idx = np.arange(offset, offset + nloc)\n        M[np.ix_(idx, idx)] += Me\n        K[np.ix_(idx, idx)] += Ke\n    # Apply Dirichlet BCs by eliminating first and last node\n    interior = np.arange(1, Nn - 1)\n    M_int = M[np.ix_(interior, interior)]\n    K_int = K[np.ix_(interior, interior)]\n    return M_int, K_int\n\ndef largest_generalized_eigenvalue(K, M):\n    # Solve K v = lambda M v; return largest lambda\n    # Use scipy.linalg.eigh for symmetric generalized eigenproblem\n    evals = eigh(K, M, eigvals_only=True)\n    # Numerical safety: ensure positive\n    lam_max = np.max(evals)\n    return float(lam_max)\n\ndef compute_case(p, Ne):\n    # Consistent mass\n    M_c, K = assemble_matrices(p, Ne, lumped=False)\n    lam_max_c = largest_generalized_eigenvalue(K, M_c)\n    dt_max_c = 2.0 / np.sqrt(lam_max_c)\n    # Lumped mass\n    M_l, K2 = assemble_matrices(p, Ne, lumped=True)\n    # K2 should equal K, but recompute to be safe; we could reuse K\n    lam_max_l = largest_generalized_eigenvalue(K2, M_l)\n    dt_max_l = 2.0 / np.sqrt(lam_max_l)\n    return lam_max_c, lam_l, dt_c, dt_l\n\ndef solve():\n    # Test suite as specified: (p, Ne)\n    test_cases = [\n        (2, 1),\n        (2, 10),\n        (3, 1),\n        (3, 10),\n    ]\n    results = []\n    for p, Ne in test_cases:\n        lam_c, lam_l, dt_c, dt_l = compute_case(p, Ne)\n        results.extend([lam_c, lam_l, dt_c, dt_l])\n    # Round to 8 decimal places in output\n    formatted = \",\".join(f\"{x:.8f}\" for x in results)\n    print(f\"[{formatted}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3359464"}]}