{"hands_on_practices": [{"introduction": "The first step in solving a partial differential equation with the Finite Element Method is translating the continuous weak form into a discrete linear system, $K U = F$. This exercise focuses on the heart of this process: the assembly of the global stiffness matrix $K$. By deriving the local stiffness matrix for a standard $P_1$ triangular element from first principles and then implementing the assembly algorithm, you will gain hands-on experience with the fundamental data structures and logic that connect the mesh geometry to the final algebraic problem. [@problem_id:3406212]", "problem": "Consider the scalar Poisson problem, with constant isotropic diffusivity, on a polygonal domain discretized by an unstructured triangular mesh. The strong form is given by the boundary value problem\n$$\n-\\nabla \\cdot (\\nabla u) = f \\quad \\text{in } \\Omega,\\qquad u = 0 \\quad \\text{on } \\partial\\Omega,\n$$\nwhere $\\Omega \\subset \\mathbb{R}^2$ is a bounded open set with sufficiently regular boundary. The corresponding weak (variational) formulation is: find $u \\in H_0^1(\\Omega)$ such that for all $v \\in H_0^1(\\Omega)$,\n$$\n\\int_{\\Omega} \\nabla u \\cdot \\nabla v \\, d\\Omega = \\int_{\\Omega} f v \\, d\\Omega.\n$$\nLet a conforming simplicial mesh of $\\Omega$ be given, and let $V_h \\subset H_0^1(\\Omega)$ denote the space of continuous, piecewise linear functions (also called $P_1$ Lagrange basis functions) associated with the mesh nodes. Let $\\{\\varphi_i\\}$ be the global nodal basis. The discrete Galerkin method seeks $u_h \\in V_h$ such that\n$$\n\\sum_{i,j} \\left( \\int_{\\Omega} \\nabla \\varphi_i \\cdot \\nabla \\varphi_j \\, d\\Omega \\right) U_j \\, \\delta v_i = \\sum_i \\left( \\int_{\\Omega} f \\, \\varphi_i \\, d\\Omega \\right) \\delta v_i,\n$$\nwhich leads to a linear system $K U = F$ with stiffness matrix entries\n$$\nK_{ij} = \\int_{\\Omega} \\nabla \\varphi_i \\cdot \\nabla \\varphi_j \\, d\\Omega.\n$$\n\nTask 1 (Local element derivation): For a single triangle $T$ with vertices at coordinates $(x_1,y_1)$, $(x_2,y_2)$, $(x_3,y_3)$ and local $P_1$ basis functions $\\{\\phi_1,\\phi_2,\\phi_3\\}$ associated with these vertices, derive from first principles that\n$$\nK_T(i,j) = \\int_T \\nabla \\phi_i \\cdot \\nabla \\phi_j \\, dA = |T| \\, \\nabla \\phi_i \\cdot \\nabla \\phi_j,\n$$\nand that the gradients are constant on $T$. Using barycentric-coordinate identities, prove that\n$$\n\\nabla \\phi_i = \\frac{1}{2|T|}\\begin{bmatrix} b_i \\\\ c_i \\end{bmatrix}, \\quad \\text{where } b_i = y_j - y_k, \\; c_i = x_k - x_j, \\; \\text{for a cyclic permutation } (i,j,k) \\text{ of } (1,2,3),\n$$\nand hence obtain the explicit local stiffness matrix\n$$\nK_T(i,j) = \\frac{1}{4|T|}\\left(b_i b_j + c_i c_j\\right), \\quad i,j \\in \\{1,2,3\\}.\n$$\nHere $|T|$ denotes the area of $T$, which must be taken as a positive quantity regardless of the local vertex orientation.\n\nTask 2 (Global assembly on an unstructured mesh): Let the mesh be specified by:\n- A list of $N$ node coordinates as an array of shape $N \\times 2$, where the $p$-th row contains $(x_p,y_p)$.\n- A list of $M$ triangles as an array of shape $M \\times 3$, where the $e$-th row lists the global node indices $(g_1,g_2,g_3)$ of the vertices of element $e$ using zero-based indexing.\nDefine the consistent local-to-global mapping that sends local indices $i \\in \\{0,1,2\\}$ of element $e$ to global indices $g_i$ as given by the connectivity array. Assemble the global stiffness matrix $K \\in \\mathbb{R}^{N \\times N}$ in Compressed Sparse Row (CSR) format by summing local contributions:\n$$\nK(g_i,g_j) \\mathrel{+}= K_T(i,j) \\quad \\text{for all elements } T \\text{ and all pairs } (i,j) \\in \\{0,1,2\\}^2.\n$$\nEnsure that the final CSR structure has column indices sorted within each row.\n\nTest suite and required outputs: Implement a program that computes the global stiffness matrices for the three independent test cases below. For each test case, convert the assembled global CSR matrix to a dense array, flatten it in row-major order, and round each entry to $10$ decimal places. The program must output a single line containing a list of these three flattened lists in the order of the test cases, with zero-based indexing used throughout.\n\n- Test case A (single canonical right triangle): Nodes $N_A = 3$ with coordinates $\\big[(0,0),(1,0),(0,1)\\big]$ and elements $M_A = 1$ with connectivity $\\big[(0,1,2)\\big]$.\n- Test case B (two triangles forming a unit square): Nodes $N_B = 4$ with coordinates $\\big[(0,0),(1,0),(1,1),(0,1)\\big]$ and elements $M_B = 2$ with connectivity $\\big[(0,1,3),(1,2,3)\\big]$.\n- Test case C (single obtuse, non-axis-aligned triangle): Nodes $N_C = 3$ with coordinates $\\big[(0.2,0.3),(1.1,0.4),(0.5,1.2)\\big]$ and elements $M_C = 1$ with connectivity $\\big[(0,1,2)\\big]$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets and containing exactly three inner lists, one per test case, each inner list being the row-major flattened dense global stiffness matrix entries rounded to $10$ decimal places, for example\n$$\n[\\,[\\dots],\\,[\\dots],\\,[\\dots]\\,].\n$$\nNo physical units are involved in this problem. Angles are not used. All numeric indices must be zero-based in your implementation.", "solution": "The problem requires the derivation of the local stiffness matrix for a $P_1$ triangular finite element for the Poisson equation, and the subsequent implementation of an algorithm to assemble the global stiffness matrix for an unstructured triangular mesh.\n\n### Task 1: Derivation of the Local Stiffness Matrix\n\nThe starting point is the entry for the local stiffness matrix $K_T$ for a single triangular element $T$:\n$$\nK_T(i,j) = \\int_T \\nabla \\phi_i \\cdot \\nabla \\phi_j \\, dA\n$$\nwhere $\\{\\phi_i\\}_{i=1,2,3}$ are the local $P_1$ Lagrange basis functions on $T$. By definition, a $P_1$ basis function $\\phi_i$ is a linear polynomial in the spatial coordinates $(x,y)$, of the form $\\phi_i(x,y) = \\alpha_i + \\beta_i x + \\gamma_i y$. The gradient of such a function is a constant vector:\n$$\n\\nabla \\phi_i = \\begin{pmatrix} \\frac{\\partial \\phi_i}{\\partial x} \\\\ \\frac{\\partial \\phi_i}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} \\beta_i \\\\ \\gamma_i \\end{pmatrix}\n$$\nSince the gradients $\\nabla \\phi_i$ and $\\nabla \\phi_j$ are constant vectors over the entire element $T$, their dot product $\\nabla \\phi_i \\cdot \\nabla \\phi_j$ is a constant scalar. The integral of a constant over a domain is simply the constant multiplied by the measure (area) of the domain. Thus, the integral simplifies to:\n$$\nK_T(i,j) = (\\nabla \\phi_i \\cdot \\nabla \\phi_j) \\int_T \\, dA = |T| (\\nabla \\phi_i \\cdot \\nabla \\phi_j)\n$$\nwhere $|T|$ is the area of the triangle $T$. This validates the first part of the required derivation.\n\nNext, we derive the explicit formula for the gradient. The basis function $\\phi_i$ is identical to the barycentric coordinate $\\lambda_i$ associated with vertex $i$ of the triangle. Let the vertices of $T$ be $v_i=(x_i, y_i)$, $v_j=(x_j, y_j)$, and $v_k=(x_k, y_k)$ for a cyclic permutation of $(1,2,3)$. The barycentric coordinate $\\lambda_i$ for a point $P=(x,y)$ is the ratio of the area of the sub-triangle formed by $P$ and the other two vertices, to the area of the full triangle $T$. The signed area of a triangle with vertices $(x_a, y_a), (x_b, y_b), (x_c, y_c)$ can be expressed using a determinant:\n$$\n\\text{Area}(v_a, v_b, v_c) = \\frac{1}{2} \\det \\begin{pmatrix} x_a & y_a & 1 \\\\ x_b & y_b & 1 \\\\ x_c & y_c & 1 \\end{pmatrix} = \\frac{1}{2} [x_a(y_b - y_c) + x_b(y_c - y_a) + x_c(y_a - y_b)]\n$$\nThe value of $|T|$ is the absolute value of this expression for the three vertices of the element. The basis function $\\phi_i(x,y)$ is:\n$$\n\\phi_i(x,y) = \\lambda_i(x,y) = \\frac{\\text{Area}(P, v_j, v_k)}{\\text{Area}(v_i, v_j, v_k)} = \\frac{1}{2|T|} [x(y_j - y_k) + y(x_k - x_j) + (x_j y_k - x_k y_j)]\n$$\nThe gradient $\\nabla \\phi_i$ is found by differentiating with respect to $x$ and $y$:\n$$\n\\frac{\\partial \\phi_i}{\\partial x} = \\frac{1}{2|T|} (y_j - y_k)\n$$\n$$\n\\frac{\\partial \\phi_i}{\\partial y} = \\frac{1}{2|T|} (x_k - x_j)\n$$\nDefining $b_i = y_j - y_k$ and $c_i = x_k - x_j$ for the cyclic permutation $(i,j,k)$ of $(1,2,3)$, we obtain the vector expression for the gradient:\n$$\n\\nabla \\phi_i = \\frac{1}{2|T|} \\begin{pmatrix} b_i \\\\ c_i \\end{pmatrix}\n$$\nThis proves the required gradient formula.\n\nFinally, we substitute this gradient expression back into the simplified integral for $K_T(i,j)$:\n$$\nK_T(i,j) = |T| (\\nabla \\phi_i \\cdot \\nabla \\phi_j) = |T| \\left( \\left( \\frac{1}{2|T|} \\begin{pmatrix} b_i \\\\ c_i \\end{pmatrix} \\right) \\cdot \\left( \\frac{1}{2|T|} \\begin{pmatrix} b_j \\\\ c_j \\end{pmatrix} \\right) \\right)\n$$\n$$\nK_T(i,j) = |T| \\frac{1}{4|T|^2} (b_i b_j + c_i c_j) = \\frac{1}{4|T|} (b_i b_j + c_i c_j)\n$$\nThis completes the derivation of the explicit formula for the entries of the local stiffness matrix $K_T$.\n\n### Task 2: Global Stiffness Matrix Assembly\n\nThe global stiffness matrix $K$ is an $N \\times N$ matrix, where $N$ is the total number of nodes in the mesh. It is assembled by summing the contributions from all $M$ triangular elements in the mesh. The assembly process is governed by the rule:\n$$\nK(g_i, g_j) \\mathrel{+}= K_T(i,j)\n$$\nThis means that for each element $T$, its local stiffness entry $K_T(i,j)$ (connecting local nodes $i$ and $j$) is added to the global stiffness matrix entry $K(g_i, g_j)$, where $g_i$ and $g_j$ are the global indices corresponding to local indices $i$ and $j$. This mapping is provided by the mesh connectivity array.\n\nA standard and efficient algorithm for this assembly process is to first build the matrix in a Coordinate (COO) format and then convert it to Compressed Sparse Row (CSR) format. The COO format uses three lists: one for row indices, one for column indices, and one for the corresponding values.\n\nThe algorithm is as follows:\n1.  Initialize three empty lists: `coo_data`, `coo_row_indices`, `coo_col_indices`.\n2.  Iterate through each triangle $T_e$ in the mesh, for $e = 0, \\dots, M-1$.\n    a. Retrieve the global indices of its vertices, $(g_0, g_1, g_2)$, from the connectivity array.\n    b. Retrieve the coordinates of these vertices, $(x_0,y_0)$, $(x_1,y_1)$, and $(x_2,y_2)$, from the node coordinate array.\n    c. Calculate the area $|T_e|$ using the shoelace formula, ensuring it is positive:\n       $$\n       |T_e| = \\frac{1}{2} |x_0(y_1-y_2) + x_1(y_2-y_0) + x_2(y_0-y_1)|\n       $$\n    d. For each local node $i \\in \\{0,1,2\\}$, compute the coefficients $b_i$ and $c_i$. Using zero-based indexing and the cyclic permutation $(i, (i+1)\\%3, (i+2)\\%3)$:\n       $$\n       b_i = y_{(i+1)\\%3} - y_{(i+2)\\%3} \\quad , \\quad c_i = x_{(i+2)\\%3} - x_{(i+1)\\%3}\n       $$\n    e. Compute the $3 \\times 3$ local stiffness matrix $K_{T_e}$ using the derived formula $K_{T_e}(i,j) = \\frac{1}{4|T_e|}(b_i b_j + c_i c_j)$.\n    f. For each local entry $K_{T_e}(i,j)$, where $i,j \\in \\{0,1,2\\}$, append the global row index $g_i$ to `coo_row_indices`, the global column index $g_j$ to `coo_col_indices`, and the value $K_{T_e}(i,j)$ to `coo_data`.\n3.  After iterating through all elements, create the global CSR matrix from the COO lists. This step automatically handles the summation of contributions for entries $(g_i, g_j)$ that are contributed to by multiple elements (i.e., shared edges or nodes). This process also ensures the column indices within each row of the final CSR structure are sorted.\n4.  For the final output, this sparse matrix is converted to a dense `numpy` array, flattened into a one-dimensional array in row-major order, and its entries rounded to the specified precision.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import csr_matrix\n\ndef assemble_stiffness_matrix(nodes, triangles):\n    \"\"\"\n    Assembles the global stiffness matrix for a 2D Poisson problem\n    on an unstructured triangular mesh using P1 finite elements.\n\n    Args:\n        nodes (np.ndarray): Array of node coordinates, shape (N, 2).\n        triangles (np.ndarray): Array of triangle connectivity, shape (M, 3),\n                                listing global node indices for each element.\n\n    Returns:\n        list: The flattened, row-major, dense global stiffness matrix,\n              with entries rounded to 10 decimal places.\n    \"\"\"\n    num_nodes = nodes.shape[0]\n    coo_data = []\n    coo_row = []\n    coo_col = []\n\n    for tri_indices in triangles:\n        # 1. Get vertex coordinates using the global indices\n        # tri_indices are the global indices, e.g., [g0, g1, g2]\n        # vertices are the corresponding coordinates\n        v0, v1, v2 = nodes[tri_indices[0]], nodes[tri_indices[1]], nodes[tri_indices[2]]\n\n        # 2. Calculate triangle area |T| (must be positive)\n        area = 0.5 * np.abs(v0[0] * (v1[1] - v2[1]) + v1[0] * (v2[1] - v0[1]) + v2[0] * (v0[1] - v1[1]))\n        \n        # Avoid division by zero for degenerate triangles\n        if area  1e-14:\n            continue\n\n        # 3. Calculate b and c coefficients for local nodes {0,1,2}\n        # b_i = y_j - y_k, c_i = x_k - x_j for cyclic (i,j,k)\n        # For local node 0 (maps to global g0): coords are v0=(x0,y0)\n        # j refers to local node 1, k to local node 2\n        b = np.array([v1[1] - v2[1], v2[1] - v0[1], v0[1] - v1[1]])\n        c = np.array([v2[0] - v1[0], v0[0] - v2[0], v1[0] - v0[0]])\n\n        # 4. Calculate the 3x3 local stiffness matrix K_T\n        # K_T(i,j) = (b_i*b_j + c_i*c_j) / (4*|T|)\n        factor = 1.0 / (4.0 * area)\n        k_local = factor * (np.outer(b, b) + np.outer(c, c))\n\n        # 5. Add local contributions to COO-format lists\n        for i in range(3):\n            for j in range(3):\n                # Map local indices (i,j) to global indices (g_i, g_j)\n                global_row_idx = tri_indices[i]\n                global_col_idx = tri_indices[j]\n                \n                coo_row.append(global_row_idx)\n                coo_col.append(global_col_idx)\n                coo_data.append(k_local[i, j])\n\n    # 6. Create the sparse CSR matrix from the COO data.\n    # Duplicates are automatically summed.\n    k_global_sparse = csr_matrix((coo_data, (coo_row, coo_col)), shape=(num_nodes, num_nodes))\n    \n    # 7. Convert to dense, flatten, round, and convert to list for output\n    k_global_dense = k_global_sparse.toarray()\n    result = np.round(k_global_dense.flatten(), 10).tolist()\n    \n    return result\n\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print the final output.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"nodes\": np.array([[0.0, 0.0], [1.0, 0.0], [0.0, 1.0]]),\n            \"triangles\": np.array([[0, 1, 2]])\n        },\n        {\n            \"nodes\": np.array([[0.0, 0.0], [1.0, 0.0], [1.0, 1.0], [0.0, 1.0]]),\n            \"triangles\": np.array([[0, 1, 3], [1, 2, 3]])\n        },\n        {\n            \"nodes\": np.array([[0.2, 0.3], [1.1, 0.4], [0.5, 1.2]]),\n            \"triangles\": np.array([[0, 1, 2]])\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        stiffness_flat = assemble_stiffness_matrix(case[\"nodes\"], case[\"triangles\"])\n        all_results.append(stiffness_flat)\n\n    # Final print statement in the exact required format.\n    # The str() of a list in Python produces the desired '[...]' format.\n    # ','.join() then separates these list-strings with commas.\n    # The outer f-string adds the final container brackets.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3406212"}, {"introduction": "While solving PDEs on a static mesh is a fundamental skill, many advanced computational strategies rely on a hierarchy of meshes or adaptive changes to the mesh itself. This practice delves into the crucial topic of mesh coarsening, a key component in geometric multigrid methods and mesh adaptation. You will implement a greedy edge-collapse algorithm, forcing you to navigate the challenges of updating mesh connectivity while rigorously enforcing geometric quality constraints to prevent the formation of ill-conditioned 'sliver' triangles. [@problem_id:3406190]", "problem": "Consider a two-dimensional triangulation of a polygonal domain for the numerical solution of a Partial Differential Equation (PDE). Let the mesh be represented by a set of vertices $\\{x_i\\}_{i=0}^{N-1}$, with $x_i \\in \\mathbb{R}^2$, and a set of triangles $\\mathcal{T} = \\{K_m\\}_{m=0}^{M-1}$, where each triangle $K_m$ is an ordered triplet of vertex indices $(i,j,k)$ referring to $\\{x_i\\}$. A mesh is called conforming if the intersection of any two distinct triangles is either empty, a shared vertex, or a shared edge, and no edge is incident to more than two triangles. A coarsening operation merges elements to reduce mesh complexity while preserving conformity and avoiding poor-quality triangles.\n\nYour task is to implement an edge-collapse based coarsening procedure on an unstructured triangular mesh subject to geometric constraints. The procedure should attempt to collapse internal edges, updating the mesh connectivity and vertex positions, while maintaining global conformity and avoiding sliver triangles.\n\nStart from the following fundamental geometric definitions for a triangle with vertices $x_a, x_b, x_c \\in \\mathbb{R}^2$:\n- The squared edge lengths are $a^2 = \\|x_b - x_c\\|_2^2$, $b^2 = \\|x_c - x_a\\|_2^2$, and $c^2 = \\|x_a - x_b\\|_2^2$.\n- The angles at the vertices $\\alpha, \\beta, \\gamma$ satisfy the law of cosines:\n$$\n\\cos(\\alpha) = \\frac{b^2 + c^2 - a^2}{2\\,\\sqrt{b^2}\\,\\sqrt{c^2}},\\quad\n\\cos(\\beta) = \\frac{c^2 + a^2 - b^2}{2\\,\\sqrt{c^2}\\,\\sqrt{a^2}},\\quad\n\\cos(\\gamma) = \\frac{a^2 + b^2 - c^2}{2\\,\\sqrt{a^2}\\,\\sqrt{b^2}},\n$$\nwith angles computed by $\\arccos$ of the clamped cosine values.\n- The (unsigned) area is\n$$\n\\mathcal{A}(K) = \\frac{1}{2}\\left| (x_b - x_a)^\\perp \\cdot (x_c - x_a) \\right|,\n$$\nwhere for $v = (v_x, v_y)$, $v^\\perp = (v_y, -v_x)$ and $\\cdot$ denotes the Euclidean dot product.\n\nDefine the minimal angle of a triangle $K$ as $\\theta_{\\min}(K) = \\min\\{\\alpha,\\beta,\\gamma\\}$. A sliver triangle is one with $\\theta_{\\min}(K)  \\alpha_{\\min}$ or $\\mathcal{A}(K)  A_{\\min}$ for prescribed thresholds $\\alpha_{\\min}  0$ (in radians) and $A_{\\min}  0$ (in the same area units as the coordinates).\n\nImplement a coarsening step that attempts to collapse internal edges as follows:\n- An internal edge $(i,j)$ is an edge shared by exactly two triangles in $\\mathcal{T}$.\n- An edge $(i,j)$ is eligible for merging only if both adjacent triangles have area less than or equal to a prescribed upper bound $A_{\\max}$.\n- Collapsing $(i,j)$ replaces the two vertices by a single vertex at $\\tilde{x} = \\frac{1}{2}(x_i + x_j)$. In the data structure, use the index $i$ to represent the merged vertex, update $x_i \\leftarrow \\tilde{x}$, and replace all occurrences of index $j$ in the triangle list by $i$.\n- After replacement, immediately remove any degenerate triangles with repeated vertex indices or with area strictly less than $A_{\\min}$, and remove duplicate triangles that have the same set of vertex indices.\n\nAcceptance criteria to avoid slivers and preserve conformity:\n- The collapse of $(i,j)$ must be rejected unless all triangles incident to the merged vertex after the operation have minimal angle greater than or equal to $\\alpha_{\\min}$ and area greater than or equal to $A_{\\min}$.\n- The global edge incidence must remain conforming: every edge is incident to either one triangle (boundary edge) or two triangles (internal edge), and there must be no edge incident to more than two triangles.\n- The mesh must remain non-empty: at least one triangle must remain after any accepted collapse.\n\nAlgorithmic requirements:\n- Iterate greedily over eligible internal edges, attempting collapses one by one. After each accepted collapse, update the mesh and recompute internal edge eligibility. Terminate when no eligible, acceptable collapse exists.\n- Implement robust angle computation with cosine clamping to the interval $[-1,1]$ to avoid rounding errors, and ensure all tests are numerically stable.\n\nYou must derive and implement the sliver-avoidance conditions, given the definitions above, to ensure that the coarsened mesh preserves a lower bound on angle quality and area while maintaining global conformity.\n\nAngle unit requirement: All angles must be measured in radians.\n\nFinal output format requirement: Your program should produce a single line of output containing the results for the provided test suite as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a comma-separated triple enclosed in square brackets of the form $[n,\\mathrm{valid},\\theta]$, with $n$ the integer number of triangles after coarsening, $\\mathrm{valid}$ a boolean indicating whether the final mesh satisfies global conformity as defined above together with the angle and area lower bounds, and $\\theta$ the minimal angle of the final mesh as a floating point number in radians. For example, an output with two test cases might look like $[[3,\\mathrm{True},0.523599],[5,\\mathrm{False},0.087266]]$.\n\nTest suite and parameters to cover different facets:\n- Case $1$ (general case): vertices $x_0=(0,0)$, $x_1=(1,0)$, $x_2=(1,1)$, $x_3=(0,1)$, $x_4=(0.5,0.5)$; triangles $[4,0,1],[4,1,2],[4,2,3],[4,3,0]$; thresholds $\\alpha_{\\min}=0.3$, $A_{\\min}=0.01$, $A_{\\max}=0.3$.\n- Case $2$ (sliver-avoidance stress): vertices $x_0=(0,0)$, $x_1=(1.8,0)$, $x_2=(0.02,0.2)$, $x_3=(0,2)$, $x_4=(1.8,2)$; triangles $[0,1,2],[0,2,3],[1,4,2],[3,2,4]$; thresholds $\\alpha_{\\min}=0.8$, $A_{\\min}=0.05$, $A_{\\max}=0.19$.\n- Case $3$ (boundary-only, no internal edges): vertices $x_0=(0,0)$, $x_1=(1,0)$, $x_2=(0,1)$; triangles $[0,1,2]$; thresholds $\\alpha_{\\min}=0.2$, $A_{\\min}=0.001$, $A_{\\max}=0.5$.\n- Case $4$ (boundary condition at angle limit): vertices $x_0=(0,0)$, $x_1=(1,0)$, $x_2=(1,1)$, $x_3=(0,1)$, $x_4=(0.5,0.5)$; triangles $[4,0,1],[4,1,2],[4,2,3],[4,3,0]$; thresholds $\\alpha_{\\min}=\\pi/4$, $A_{\\min}=0.01$, $A_{\\max}=0.24$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets with the format described above.", "solution": "The user has provided a computational geometry problem requiring the implementation of a mesh coarsening algorithm based on edge collapse for a 2D triangular mesh. The process must adhere to specific geometric and topological constraints.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n-   **Mesh Representation**: A set of 2D vertices $\\{x_i\\}_{i=0}^{N-1}$ and a set of triangles $\\mathcal{T} = \\{K_m\\}_{m=0}^{M-1}$, where each triangle is an ordered triplet of vertex indices.\n-   **Conforming Mesh Definition**: The intersection of any two distinct triangles is empty, a shared vertex, or a shared edge. No edge is incident to more than two triangles.\n-   **Geometric Formulas**:\n    -   Squared edge lengths: $a^2 = \\|x_b - x_c\\|_2^2$, $b^2 = \\|x_c - x_a\\|_2^2$, $c^2 = \\|x_a - x_b\\|_2^2$.\n    -   Angle computation via Law of Cosines, with values clamped to $[-1, 1]$.\n    -   Area computation: $\\mathcal{A}(K) = \\frac{1}{2}\\left| (x_b - x_a)^\\perp \\cdot (x_c - x_a) \\right|$.\n-   **Quality Thresholds**: Minimum angle $\\alpha_{\\min}$, minimum area $A_{\\min}$, maximum area $A_{\\max}$. All angles are in radians.\n-   **Sliver Triangle Definition**: A triangle $K$ with $\\theta_{\\min}(K)  \\alpha_{\\min}$ or $\\mathcal{A}(K)  A_{\\min}$.\n-   **Edge Collapse Procedure**:\n    1.  **Select Edge**: Choose an *internal edge* $(i,j)$ (shared by exactly two triangles).\n    2.  **Eligibility**: The edge $(i,j)$ is eligible only if both adjacent triangles have area less than or equal to $A_{\\max}$.\n    3.  **Collapse**: Merge vertices $x_i, x_j$ to a new vertex at $\\tilde{x} = \\frac{1}{2}(x_i + x_j)$. The merged vertex uses index $i$, so $x_i \\leftarrow \\tilde{x}$ and all occurrences of index $j$ in $\\mathcal{T}$ are replaced by $i$.\n    4.  **Cleanup**: After substitution, remove degenerate triangles (repeated indices), triangles with area $ A_{\\min}$, and duplicate triangles (same set of vertices).\n-   **Acceptance Criteria for a Collapse**:\n    1.  **Quality**: All triangles incident to the merged vertex must satisfy $\\theta_{\\min} \\ge \\alpha_{\\min}$ and $\\mathcal{A} \\ge A_{\\min}$.\n    2.  **Conformity**: The global mesh must remain conforming.\n    3.  **Non-Emptiness**: At least one triangle must remain after the collapse.\n-   **Algorithm**: Iterate greedily over eligible internal edges. After each accepted collapse, update the mesh and restart the process. Terminate when no more eligible and acceptable collapses can be found.\n-   **Output Format**: A list of results, one per test case. Each result is `[n, valid, theta]`, where $n$ is the final triangle count, `valid` is a boolean for final mesh quality and conformity, and $\\theta$ is the minimum angle in the final mesh.\n-   **Test Suite**: Four test cases with specified vertices, triangles, and thresholds are provided.\n\n**Step 2: Validate Using Extracted Givens**\n-   **Scientific Grounding**: The problem is well-grounded in the established field of computational geometry and numerical methods for PDEs. The concepts of triangular meshes, conformity, edge collapse, and quality metrics (minimum angle, area) are standard. The provided geometric formulas are correct.\n-   **Well-Posedness**: The problem describes a greedy algorithm. While a greedy approach may not find a global optimum, it defines a deterministic procedure that terminates. The termination condition (no more acceptable collapses) is clear. The problem is well-posed for an algorithmic implementation. The order of iteration over eligible edges is not specified, but this ambiguity is common and can be resolved by choosing a deterministic order (e.g., sorting by vertex indices).\n-   **Objectivity**: The problem is stated using precise, objective, and quantitative language. All terms are clearly defined.\n-   The problem is self-contained, formalizable, and scientifically sound. It does not violate any of the invalidity criteria.\n\n**Step 3: Verdict and Action**\nThe problem is valid. A reasoned solution will be developed.\n\n### Algorithmic Design and Principles\n\nThe solution will be structured as a main loop that repeatedly attempts to coarsen the mesh until no further valid collapses are possible. The core of the algorithm involves identifying candidate edges, simulating a collapse, and validating the resulting mesh against the specified criteria.\n\n**1. Geometric Helper Functions**\n-   **Area Calculation**: A function `calculate_area(p1, p2, p3)` will implement the formula $\\mathcal{A} = \\frac{1}{2}\\left| (x_b - x_a)^\\perp \\cdot (x_c - x_a) \\right|$, where $x_a, x_b, x_c$ are the vertex coordinates. This is equivalent to half the magnitude of the 2D cross product, or $\\frac{1}{2} |x_a(y_b - y_c) + x_b(y_c - y_a) + x_c(y_a - y_b)|$.\n-   **Angle Calculation**: A function `calculate_min_angle(p1, p2, p3)` will compute the three angles of a triangle. It will first calculate the squared edge lengths $a^2, b^2, c^2$ to avoid premature `sqrt` operations. Then, it will apply the Law of Cosines as specified. Crucially, the argument to `arccos` will be clamped to the range $[-1, 1]$ to prevent domain errors from floating-point inaccuracies. The minimum of the three computed angles will be returned.\n\n**2. Mesh Topology and State Management**\n-   **Data Structures**: The vertices will be stored in a NumPy array of shape $(N, 2)$ and triangles in an $(M, 3)$ integer array.\n-   **Edge-to-Triangle Map**: A helper function `get_edge_to_triangle_map(triangles)` is essential. It will create a dictionary mapping each edge (represented as a sorted tuple of vertex indices `(min(i,j), max(i,j))`) to a list of indices of triangles containing that edge. This map allows for efficient identification of internal edges (map value has length 2) and boundary edges (length 1).\n\n**3. Coarsening Algorithm**\nThe main coarsening process is a `while` loop that continues as long as a successful collapse occurs in a pass.\n\n-   **Iteration**: Inside the loop, a `collapse_performed` flag is initialized to `False`.\n-   **Edge Identification**: All internal edges are identified using the edge-to-triangle map.\n-   **Eligibility Filtering**: The list of internal edges is filtered to find *eligible* edges. For an edge $(i, j)$ adjacent to triangles $K_1$ and $K_2$, it is eligible if $\\mathcal{A}(K_1) \\le A_{\\max}$ and $\\mathcal{A}(K_2) \\le A_{\\max}$. For determinism, the list of eligible edges is sorted.\n-   **Greedy Attempt**: The algorithm iterates through the sorted eligible edges. For each edge $(i, j)$, it attempts a collapse.\n    -   **Propose State**: A hypothetical new mesh state is created.\n        1.  The vertex list is copied. The vertex $x_i$ is updated to the midpoint $\\tilde{x} = \\frac{1}{2}(x_i + x_j)$.\n        2.  The triangle list is copied. All occurrences of index $j$ are replaced with $i$.\n        3.  **Cleanup**: The proposed triangle list is cleaned by:\n            a. Removing degenerate triangles (those with repeated vertex indices, e.g., $(i,i,k)$).\n            b. Removing triangles with area strictly less than $A_{\\min}$.\n            c. Removing duplicate triangles (e.g., $(i,k,l)$ and $(k,l,i)$). This is done by normalizing each triangle's vertex representation (e.g., as a `frozenset`) and keeping only unique sets.\n    -   **Validate Proposal**: The proposed mesh is validated against the acceptance criteria:\n        1.  **Non-empty**: The proposed triangle list must not be empty.\n        2.  **Angle/Area quality**: For every triangle incident to the merged vertex $i$, its minimum angle must be $\\ge \\alpha_{\\min}$ and its area must be $\\ge A_{\\min}$. The area check is partially redundant due to the cleanup step but serves as a safeguard.\n        3.  **Conformity**: A new edge-to-triangle map is built for the proposed mesh, and we verify that no edge is incident to more than two triangles.\n    -   **Commit or Discard**: If the proposal is valid, the collapse is *accepted*. The main mesh data structures are updated with the proposed ones, `collapse_performed` is set to `True`, and the loop over eligible edges is broken to restart the entire process from the top with the new mesh. If the proposal is rejected, the algorithm proceeds to the next eligible edge.\n-   **Termination**: If a full pass over all eligible edges results in no accepted collapses, the `collapse_performed` flag remains `False`, and the main `while` loop terminates.\n\n**4. Final Analysis**\nAfter the coarsening loop finishes, a final validation is performed on the resulting mesh to generate the output tuple `[n, valid, theta]`.\n-   $n$: The number of triangles in the final mesh.\n-   `valid`: A boolean flag. It is `True` if and only if all triangles in the final mesh satisfy $\\theta_{\\min} \\ge \\alpha_{\\min}$ and $\\mathcal{A} \\ge A_{\\min}$, AND the mesh is globally conforming.\n-   $\\theta$: The minimum of all minimal angles across all triangles in the final mesh. If the mesh is empty, it is reported as `0.0`.\n\nThis systematic approach ensures all constraints from the problem statement are respected, leading to a robust implementation.", "answer": "```python\nimport numpy as np\nfrom collections import defaultdict\nimport math\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"vertices\": np.array([[0,0], [1,0], [1,1], [0,1], [0.5,0.5]]),\n            \"triangles\": np.array([[4,0,1],[4,1,2],[4,2,3],[4,3,0]]),\n            \"alpha_min\": 0.3, \"A_min\": 0.01, \"A_max\": 0.3\n        },\n        {\n            \"vertices\": np.array([[0,0], [1.8,0], [0.02,0.2], [0,2], [1.8,2]]),\n            \"triangles\": np.array([[0,1,2],[0,2,3],[1,4,2],[3,2,4]]),\n            \"alpha_min\": 0.8, \"A_min\": 0.05, \"A_max\": 0.19\n        },\n        {\n            \"vertices\": np.array([[0,0], [1,0], [0,1]]),\n            \"triangles\": np.array([[0,1,2]]),\n            \"alpha_min\": 0.2, \"A_min\": 0.001, \"A_max\": 0.5\n        },\n        {\n            \"vertices\": np.array([[0,0], [1,0], [1,1], [0,1], [0.5,0.5]]),\n            \"triangles\": np.array([[4,0,1],[4,1,2],[4,2,3],[4,3,0]]),\n            \"alpha_min\": math.pi / 4, \"A_min\": 0.01, \"A_max\": 0.24\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Use .copy() to avoid modifying the original test case data\n        final_verts, final_tris = coarsen_mesh(\n            case[\"vertices\"].copy(), case[\"triangles\"].copy(),\n            case[\"alpha_min\"], case[\"A_min\"], case[\"A_max\"]\n        )\n        n, is_valid, min_angle_final = analyze_final_mesh(\n            final_verts, final_tris, case[\"alpha_min\"], case[\"A_min\"]\n        )\n        results.append(f\"[{n},{is_valid},{min_angle_final}]\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_area(p1, p2, p3):\n    \"\"\"Calculates the area of a triangle given its 3 vertices.\"\"\"\n    return 0.5 * abs(p1[0]*(p2[1]-p3[1]) + p2[0]*(p3[1]-p1[1]) + p3[0]*(p1[1]-p2[1]))\n\ndef calculate_min_angle(p1, p2, p3):\n    \"\"\"Calculates the minimum angle of a triangle in radians.\"\"\"\n    # Squared edge lengths\n    a2 = np.sum((p2-p3)**2)\n    b2 = np.sum((p1-p3)**2)\n    c2 = np.sum((p1-p2)**2)\n    \n    # Avoid division by zero for degenerate triangles\n    if a2 == 0 or b2 == 0 or c2 == 0:\n        return 0.0\n\n    a, b, c = np.sqrt(a2), np.sqrt(b2), np.sqrt(c2)\n\n    # Cosine values clamped to [-1, 1] for numerical stability\n    cos_alpha = np.clip((b2 + c2 - a2) / (2 * b * c), -1.0, 1.0)\n    cos_beta = np.clip((a2 + c2 - b2) / (2 * a * c), -1.0, 1.0)\n    cos_gamma = np.clip((a2 + b2 - c2) / (2 * a * b), -1.0, 1.0)\n\n    return min(np.arccos(cos_alpha), np.arccos(cos_beta), np.arccos(cos_gamma))\n    \ndef get_edge_to_triangle_map(triangles):\n    \"\"\"Builds a map from edges to triangles that contain them.\"\"\"\n    edge_map = defaultdict(list)\n    for i, tri in enumerate(triangles):\n        for j in range(3):\n            v1 = tri[j]\n            v2 = tri[(j + 1) % 3]\n            edge = tuple(sorted((v1, v2)))\n            edge_map[edge].append(i)\n    return edge_map\n\ndef coarsen_mesh(vertices, triangles, alpha_min, A_min, A_max):\n    \"\"\"\n    Performs the greedy edge-collapse coarsening procedure.\n    \"\"\"\n    while True:\n        collapse_performed = False\n        edge_map = get_edge_to_triangle_map(triangles)\n        \n        internal_edges = [edge for edge, tris in edge_map.items() if len(tris) == 2]\n\n        eligible_edges = []\n        for edge in internal_edges:\n            tri_idx1, tri_idx2 = edge_map[edge]\n            p1, p2, p3 = vertices[triangles[tri_idx1]]\n            area1 = calculate_area(p1, p2, p3)\n            p1, p2, p3 = vertices[triangles[tri_idx2]]\n            area2 = calculate_area(p1, p2, p3)\n            if area1 = A_max and area2 = A_max:\n                eligible_edges.append(edge)\n\n        # Sort for deterministic behavior\n        eligible_edges.sort()\n\n        for edge in eligible_edges:\n            i, j = edge # smaller index first\n            \n            # Propose collapse j -> i\n            proposed_verts = vertices.copy()\n            proposed_verts[i] = 0.5 * (vertices[i] + vertices[j])\n            \n            proposed_tris = triangles.copy()\n            proposed_tris[proposed_tris == j] = i\n            \n            # --- Cleanup ---\n            # 1. Remove degenerate triangles (repeated vertices)\n            valid_tris_mask = [len(set(tri)) == 3 for tri in proposed_tris]\n            proposed_tris = proposed_tris[valid_tris_mask]\n            \n            # 2. Remove small area triangles\n            if len(proposed_tris) > 0:\n                area_ok_mask = [calculate_area(*proposed_verts[tri]) >= A_min for tri in proposed_tris]\n                proposed_tris = proposed_tris[area_ok_mask]\n            \n            # 3. Remove duplicate triangles\n            if len(proposed_tris) > 0:\n                unique_tris_reps = {}\n                for tri in proposed_tris:\n                    rep = frozenset(tri)\n                    if rep not in unique_tris_reps:\n                        unique_tris_reps[rep] = tri\n                proposed_tris = np.array(list(unique_tris_reps.values())) if unique_tris_reps else np.array([], dtype=int)\n\n            # --- Validation ---\n            is_acceptable = True\n            if len(proposed_tris) == 0:\n                is_acceptable = False # Mesh must not become empty\n\n            if is_acceptable:\n                # Check quality of triangles incident to merged vertex\n                incident_tris = [tri for tri in proposed_tris if i in tri]\n                for tri_indices in incident_tris:\n                    min_ang = calculate_min_angle(*proposed_verts[tri_indices])\n                    if min_ang  alpha_min:\n                        is_acceptable = False\n                        break\n                \n            if is_acceptable:\n                # Check global conformity\n                prop_edge_map = get_edge_to_triangle_map(proposed_tris)\n                if any(len(tris) > 2 for tris in prop_edge_map.values()):\n                    is_acceptable = False\n\n            if is_acceptable:\n                vertices = proposed_verts\n                triangles = proposed_tris\n                collapse_performed = True\n                break  # Restart greedy search with the new mesh\n        \n        if not collapse_performed:\n            break\n\n    return vertices, triangles\n\ndef analyze_final_mesh(vertices, triangles, alpha_min, A_min):\n    \"\"\"\n    Analyzes the final mesh for validity and computes its minimal angle.\n    \"\"\"\n    n = len(triangles)\n    if n == 0:\n        # Edge case: empty mesh. Valid by vacuous truth? Problem says >=1 triangle must remain so shouldn't happen.\n        # But if initial mesh is empty, it can be. Assume it is not valid\n        # if the goal is to have a valid mesh.\n        # Alternatively, can be seen as valid. Let's say it is valid but has no angle.\n        # The prompt says final mesh must satisfy conformity, angle, area bounds.\n        # An empty mesh has no triangles to violate this.\n        return 0, True, 0.0 # Or np.inf\n    \n    is_valid = True\n    min_angle_final = float('inf')\n\n    # Check conformity\n    edge_map = get_edge_to_triangle_map(triangles)\n    if any(len(tris) > 2 for tris in edge_map.values()):\n        is_valid = False\n\n    # Check triangle quality\n    for tri in triangles:\n        points = vertices[tri]\n        area = calculate_area(*points)\n        min_angle = calculate_min_angle(*points)\n        \n        if area  A_min or min_angle  alpha_min:\n            is_valid = False\n            \n        if min_angle  min_angle_final:\n            min_angle_final = min_angle\n            \n    return n, is_valid, min_angle_final if min_angle_final != float('inf') else 0.0\n\nsolve()\n```", "id": "3406190"}, {"introduction": "Standard finite element methods assume a degree of smoothness in the solution that is not always present in physical problems like multiphase flow or fracture mechanics. This exercise provides a hands-on introduction to handling such complexities by tasking you with the robust numerical integration of a discontinuous function over a polygonal cell. By implementing and comparing different geometric approximations of the discontinuity interface, you will explore the core ideas behind advanced techniques like the eXtended Finite Element Method (XFEM) and appreciate the interplay between computational geometry and quadrature needed to achieve accuracy. [@problem_id:3406224]", "problem": "You are tasked with implementing a robust numerical integration algorithm for discontinuous functions over polygonal cells on unstructured meshes. The objective is to compare two geometric treatments of the discontinuity interface and to quantify the geometric approximation error. The discontinuity is represented by a smooth implicit curve given as the zero level-set of a scalar field, and the piecewise function is linear on each side of the interface.\n\nConsider a polygonal cell $P \\subset \\mathbb{R}^2$ with vertices given in counterclockwise order. Define a level-set field $\\phi:\\mathbb{R}^2\\to\\mathbb{R}$ by\n$$\n\\phi(x,y) = (x - c_x)^2 + (y - c_y)^2 - R^2,\n$$\nwhere $(c_x,c_y)\\in\\mathbb{R}^2$ is the circle center and $R0$ is the radius. The discontinuity interface is $\\{\\phi=0\\}$, separating the inside region $\\{\\phi0\\}$ (the disk) from the outside region $\\{\\phi0\\}$ (its complement).\n\nLet the target integrand be the discontinuous function\n$$\nf(x,y) = H(\\phi(x,y))\\,f_+(x,y) + \\left(1 - H(\\phi(x,y))\\right)\\,f_-(x,y),\n$$\nwhere $H$ is the Heaviside step function and $f_+$ and $f_-$ are linear functions:\n$$\nf_+(x,y) = \\alpha_0 + \\alpha_1 x + \\alpha_2 y,\\qquad f_-(x,y) = \\beta_0 + \\beta_1 x + \\beta_2 y,\n$$\nwith real coefficients $\\alpha_0,\\alpha_1,\\alpha_2$ and $\\beta_0,\\beta_1,\\beta_2$.\n\nYour program must compute, for each provided polygonal cell and level-set parameters $(c_x,c_y,R)$, the absolute error introduced by approximating the curved interface $\\{\\phi=0\\}$ by a straight segment (a chord) within the cell. Concretely, compute two approximations of the integral\n$$\nI = \\int_P f(x,y)\\,dA,\n$$\nbased on the following methodologies:\n\n- High-accuracy reference via convex clipping and moment-fitting:\n  - Observe the identity\n    $$\n    I = \\int_P f_+(x,y)\\,dA + \\int_{P \\cap \\{\\phi0\\}} \\left( f_-(x,y) - f_+(x,y) \\right)\\,dA.\n    $$\n  - Approximate the disk $\\{\\phi0\\}$ by a regular $N$-gon centered at $(c_x,c_y)$ with radius $R$ and $N$ vertices, with $N$ large (e.g., $N=2048$), forming a convex polygon $C_N$ in counterclockwise order.\n  - Compute the convex polygonal intersection $R_{\\text{ref}} = P \\cap C_N$ using a robust convex clipping algorithm.\n  - Evaluate the integrals of linear functions over $P$ and $R_{\\text{ref}}$ using area and centroid-based moment formulas derived from Green’s theorem. Use positive area measure for integration.\n\n- Geometric approximation via local chord:\n  - If $P$ is entirely on one side of the interface according to the signs of $\\phi$ at its vertices, classify accordingly and set the inside region to either $P$ or the empty set.\n  - Otherwise, find all intersection points between the circle $\\{\\phi=0\\}$ and the edges of $P$. If there are at least two distinct intersections, select the pair of intersection points that maximize the Euclidean distance and define the chord as the straight segment connecting this pair. Define the half-plane whose boundary is this chord that contains the circle center $(c_x,c_y)$.\n  - Construct $R_{\\text{chord}}$ as the polygon obtained by clipping $P$ with this half-plane.\n  - Use the same moment formulas to integrate over $P$ and $R_{\\text{chord}}$:\n    $$\n    I_{\\text{chord}} = \\int_P f_+(x,y)\\,dA + \\int_{R_{\\text{chord}}} \\left( f_-(x,y) - f_+(x,y) \\right)\\,dA.\n    $$\n\nDefine the geometric approximation error as\n$$\nE = \\left| I_{\\text{chord}} - I_{\\text{ref}} \\right|.\n$$\n\nFoundational base you must use to design the algorithm and justify each step:\n- The decomposition identity for $I$ using the Heaviside step function and the inside region $\\{\\phi0\\}$.\n- Green’s theorem and polygon moment formulas establishing that the integral of any linear function $g(x,y)=\\gamma_0+\\gamma_1 x+\\gamma_2 y$ over a polygon with area $A$ and centroid $(\\bar{x},\\bar{y})$ equals\n  $$\n  \\int_{\\text{polygon}} g(x,y)\\,dA = A\\left(\\gamma_0 + \\gamma_1 \\bar{x} + \\gamma_2 \\bar{y}\\right).\n  $$\n- Robust polygon clipping for convex clip polygons and half-planes.\n\nImplement the above for the following test suite. All coordinates and parameters are real numbers with no physical units. Angles, if any are used internally, are in radians. Each test case provides:\n- Polygon vertices in counterclockwise order.\n- Circle parameters $(c_x,c_y,R)$.\n- Coefficients $(\\alpha_0,\\alpha_1,\\alpha_2)$ and $(\\beta_0,\\beta_1,\\beta_2)$.\n\nUse the same coefficients for all test cases:\n- $f_+$ coefficients: $\\alpha_0 = 1.2$, $\\alpha_1 = -0.7$, $\\alpha_2 = 0.3$.\n- $f_-$ coefficients: $\\beta_0 = -0.5$, $\\beta_1 = 0.4$, $\\beta_2 = 0.9$.\n\nUse a regular polygon with $N=2048$ vertices to approximate the disk $\\{\\phi0\\}$ in the reference computation.\n\nTest suite of polygons and level-set parameters:\n- Test case $1$ (happy path, convex quadrilateral cut by interface): polygon $P_1$ with vertices $(-0.1,-0.05)$, $(0.6,0.1)$, $(0.45,0.5)$, $(-0.2,0.35)$; circle center $(0,0)$ and radius $R=0.5$.\n- Test case $2$ (entirely inside): polygon $P_2$ triangle with vertices $(0.1,0.0)$, $(0.2,0.05)$, $(0.05,0.15)$; circle center $(0,0)$ and radius $R=1.0$.\n- Test case $3$ (entirely outside): polygon $P_3$ triangle with vertices $(0.8,0.8)$, $(0.9,0.7)$, $(0.7,0.9)$; circle center $(0,0)$ and radius $R=0.5$.\n- Test case $4$ (tangent edge case): polygon $P_4$ quadrilateral with vertices $(-0.1,0.5)$, $(0.1,0.5)$, $(0.1,0.7)$, $(-0.1,0.7)$; circle center $(0,0)$ and radius $R=0.5$.\n\nProgram requirements:\n- Implement the algorithms precisely as described.\n- For each test case, compute the absolute geometric approximation error $E$ as a floating-point number.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases, with each number rounded to $8$ decimal places, for example, $\\left[\\dots\\right]$.\n\nNo external input is provided; all data are embedded in the program. The answer requires only dimensionless floating-point values and must be printed exactly in the specified format as a single line.", "solution": "The user-provided problem is assessed to be **valid**. It is a well-posed problem in the domain of numerical analysis and computational geometry, specifically concerning the numerical integration of discontinuous functions on unstructured meshes, a topic relevant to methods like the eXtended Finite Element Method (XFEM). All data, definitions, and required algorithms are specified completely and consistently, with a clear and objective measure for the final result. The problem is scientifically grounded in established mathematical principles, such as Green's theorem and polygon clipping algorithms.\n\nThe solution proceeds by implementing the two specified methodologies for approximating the integral of a discontinuous function over a polygonal cell and then computing the absolute difference between their results.\n\nThe discontinuous integrand is given by\n$$\nf(x,y) = H(\\phi(x,y))\\,f_+(x,y) + \\left(1 - H(\\phi(x,y))\\right)\\,f_-(x,y)\n$$\nwhere $\\phi(x,y) = (x - c_x)^2 + (y - c_y)^2 - R^2$ is the level-set function defining a circular interface, $H$ is the Heaviside step function, and $f_+, f_-$ are linear functions. The integral to compute is $I = \\int_P f(x,y)\\,dA$ over a polygon $P$.\n\nA key step is the decomposition of this integral. The region where $1 - H(\\phi) = 1$ is the interior of the circle, $\\{\\phi  0\\}$, and the region where $H(\\phi) = 1$ is the exterior, $\\{\\phi  0\\}$. The integral can be rewritten as:\n$$\nI = \\int_P \\left( H(\\phi)f_+ + (1-H(\\phi))f_- \\right) dA = \\int_P f_+ dA + \\int_P (1-H(\\phi))(f_- - f_+) dA\n$$\nThe term $(1-H(\\phi))$ acts as an indicator function for the region $\\{\\phi  0\\}$. Thus, letting $g(x,y) = f_-(x,y) - f_+(x,y)$, the integral becomes:\n$$\nI = \\int_P f_+(x,y) \\,dA + \\int_{P \\cap \\{\\phi0\\}} g(x,y) \\,dA\n$$\nSince $f_+$ and $f_-$ are linear, their difference $g$ is also a linear function. The problem thus reduces to integrating linear functions over polygons. Based on Green's theorem, the integral of a linear function $\\gamma(x,y) = \\gamma_0 + \\gamma_1 x + \\gamma_2 y$ over a polygon $\\mathcal{P}$ with area $A$ and centroid $(\\bar{x}, \\bar{y})$ is given by:\n$$\n\\int_{\\mathcal{P}} \\gamma(x,y) \\,dA = A \\cdot \\gamma(\\bar{x}, \\bar{y}) = A(\\gamma_0 + \\gamma_1 \\bar{x} + \\gamma_2 \\bar{y})\n$$\nTo implement this, we require a robust method for computing the area and centroid of an arbitrary simple polygon. For a polygon with vertices $(x_0, y_0), (x_1, y_1), \\dots, (x_{n-1}, y_{n-1})$ in order, the signed area $A$ and centroid $(\\bar{x}, \\bar{y})$ are computed as:\n$$\nA = \\frac{1}{2} \\sum_{i=0}^{n-1} (x_i y_{i+1} - x_{i+1} y_i)\n$$\n$$\n\\bar{x} = \\frac{1}{6A} \\sum_{i=0}^{n-1} (x_i + x_{i+1})(x_i y_{i+1} - x_{i+1} y_i)\n$$\n$$\n\\bar{y} = \\frac{1}{6A} \\sum_{i=0}^{n-1} (y_i + y_{i+1})(x_i y_{i+1} - x_{i+1} y_i)\n$$\nwhere $(x_n, y_n) = (x_0, y_0)$. The problem requires using a positive area measure, so we use $|A|$.\n\nThe two approximations of the integral, $I_{\\text{ref}}$ and $I_{\\text{chord}}$, differ in how they approximate the region of integration $P_{\\text{in}} = P \\cap \\{\\phi0\\}$ for the second term.\n\n1.  **Reference Calculation ($I_{\\text{ref}}$)**: The circular region $\\{\\phi0\\}$ is approximated by a high-resolution regular $N$-gon, $C_N$, with $N=2048$ vertices. The integration domain is then $R_{\\text{ref}} = P \\cap C_N$. This intersection of two convex polygons (since $P$ in the test cases are convex, and $C_N$ is convex) is computed using the Sutherland-Hodgman algorithm, which clips a subject polygon against the edges of a convex clip polygon. The integral is then $I_{\\text{ref}} = \\int_P f_+ dA + \\int_{R_{\\text{ref}}} g\\,dA$.\n\n2.  **Chord Approximation ($I_{\\text{chord}}$)**: This method simplifies the curved interface within the cell $P$.\n    - First, if all vertices of $P$ have the same sign of $\\phi$, the cell is classified as entirely inside ($\\phi \\le 0$) or outside ($\\phi \\ge 0$). In this case, $R_{\\text{chord}}$ is set to $P$ or the empty set, respectively.\n    - Otherwise, the cell is cut. The intersection points of the circle $\\{\\phi=0\\}$ with the edges of $P$ are computed by solving a quadratic equation for each edge.\n    - From the set of distinct intersection points, the pair with the maximum Euclidean distance defines a chord. This chord partitions the plane into two half-planes.\n    - The correct half-plane is the one containing the circle's center $(c_x, c_y)$.\n    - $R_{\\text{chord}}$ is then the result of clipping $P$ against this half-plane. This clipping is a single pass of the Sutherland-Hodgman algorithm.\n    - The integral is $I_{\\text{chord}} = \\int_P f_+ dA + \\int_{R_{\\text{chord}}} g\\,dA$.\n\nThe geometric approximation error is the absolute difference $E = |I_{\\text{chord}} - I_{\\text{ref}}|$. The implementation encapsulates these geometric and integration primitives into a workflow that processes each test case to compute this error. For cases where the polygon lies entirely on one side of the interface, both methods yield the same (exact) result, leading to zero error. The error is non-zero only for cut cells where the chord is a non-exact approximation of the circular arc.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the computation for all test cases.\n    It calculates the geometric approximation error E for each case and prints the results.\n    \"\"\"\n    \n    # --- Global Constants and Coefficients ---\n    \n    # Coefficients for the linear functions f_+(x,y) and f_-(x,y)\n    # f_+(x,y) = alpha_0 + alpha_1*x + alpha_2*y\n    ALPHA_COEFFS = np.array([1.2, -0.7, 0.3])\n    # f_-(x,y) = beta_0 + beta_1*x + beta_2*y\n    BETA_COEFFS = np.array([-0.5, 0.4, 0.9])\n    \n    # Coefficients for the difference function g(x,y) = f_-(x,y) - f_+(x,y)\n    GAMMA_COEFFS = BETA_COEFFS - ALPHA_COEFFS\n    \n    # Number of vertices for the regular polygon approximation of the circle\n    N_REF = 2048\n    \n    # Tolerance for floating-point comparisons\n    TOL = 1e-12\n\n    # --- Geometric and Integration Helper Functions ---\n\n    def poly_area_centroid(poly_verts):\n        \"\"\"\n        Computes the signed area and centroid of a non-self-intersecting polygon\n        using the shoelace formula. Vertices are assumed to be in order.\n        \"\"\"\n        if poly_verts.shape[0]  3:\n            return 0.0, np.array([0.0, 0.0])\n\n        x = poly_verts[:, 0]\n        y = poly_verts[:, 1]\n        \n        x_plus_1 = np.roll(x, -1)\n        y_plus_1 = np.roll(y, -1)\n        \n        cross_prod_terms = x * y_plus_1 - x_plus_1 * y\n        signed_area = 0.5 * np.sum(cross_prod_terms)\n\n        if abs(signed_area)  TOL:\n            return 0.0, np.mean(poly_verts, axis=0)\n\n        cx = (1 / (6 * signed_area)) * np.sum((x + x_plus_1) * cross_prod_terms)\n        cy = (1 / (6 * signed_area)) * np.sum((y + y_plus_1) * cross_prod_terms)\n        \n        return signed_area, np.array([cx, cy])\n\n    def integrate_linear_over_poly(poly_verts, coeffs):\n        \"\"\"\n        Integrates a linear function g(x,y) over a polygon using the formula:\n        Integral(g) = Area(poly) * g(centroid(poly)).\n        \"\"\"\n        if poly_verts.shape[0]  3:\n            return 0.0\n        \n        signed_area, centroid = poly_area_centroid(poly_verts)\n        if abs(signed_area)  TOL: return 0.0\n\n        area = abs(signed_area)\n        val_at_centroid = coeffs[0] + coeffs[1] * centroid[0] + coeffs[2] * centroid[1]\n        \n        return area * val_at_centroid\n\n    def line_intersection(p1, p2, p3, p4):\n        \"\"\"Finds the intersection of two lines defined by (p1, p2) and (p3, p4).\"\"\"\n        den = (p1[0] - p2[0]) * (p3[1] - p4[1]) - (p1[1] - p2[1]) * (p3[0] - p4[0])\n        if abs(den)  TOL: return p1  # Fallback for parallel/collinear lines\n        t = ((p1[0] - p3[0]) * (p3[1] - p4[1]) - (p1[1] - p3[1]) * (p3[0] - p4[0])) / den\n        return p1 + t * (p2 - p1)\n\n    def clip_sutherland_hodgman(subject_polygon, clip_polygon):\n        \"\"\"Clips a subject polygon against a convex clip polygon (both CCW).\"\"\"\n        clipped = subject_polygon\n        for i in range(clip_polygon.shape[0]):\n            if clipped.shape[0] == 0: return np.array([])\n            \n            p1, p2 = clip_polygon[i], clip_polygon[(i + 1) % clip_polygon.shape[0]]\n            input_list, output_list = clipped, []\n            S = input_list[-1]\n            for E in input_list:\n                s_cross = (p2[0]-p1[0])*(S[1]-p1[1]) - (p2[1]-p1[1])*(S[0]-p1[0])\n                e_cross = (p2[0]-p1[0])*(E[1]-p1[1]) - (p2[1]-p1[1])*(E[0]-p1[0])\n                s_inside, e_inside = s_cross >= -TOL, e_cross >= -TOL\n\n                if e_inside:\n                    if not s_inside:\n                        output_list.append(line_intersection(S, E, p1, p2))\n                    output_list.append(E)\n                elif s_inside:\n                    output_list.append(line_intersection(S, E, p1, p2))\n                S = E\n            clipped = np.array(output_list)\n        return clipped\n\n    def intersect_segment_circle(p1, p2, c_center, R):\n        \"\"\"Finds intersection points of a line segment with a circle.\"\"\"\n        d = p2 - p1; f = p1 - c_center\n        a, b, c = np.dot(d,d), 2*np.dot(f,d), np.dot(f,f) - R**2\n        if a  TOL: return []\n        discriminant = b**2 - 4*a*c\n        if discriminant  -TOL: return []\n        \n        t_vals = [-b/(2*a)] if discriminant  TOL else [(-b+np.sqrt(discriminant))/(2*a), (-b-np.sqrt(discriminant))/(2*a)]\n        return [p1 + max(0.0, min(1.0, t)) * d for t in t_vals if -TOL = t = 1 + TOL]\n\n    def get_chord_polygon(P, c_center, R):\n        \"\"\"Calculates the inside-region R_chord using the chord approximation.\"\"\"\n        phi_vals = np.sum((P - c_center)**2, axis=1) - R**2\n        if np.all(phi_vals >= -TOL): return np.array([])\n        if np.all(phi_vals = TOL): return P\n        \n        intersections = []\n        for i in range(P.shape[0]):\n            pts = intersect_segment_circle(P[i], P[(i + 1) % P.shape[0]], c_center, R)\n            for pt in pts:\n                if not any(np.linalg.norm(pt - ex_pt)  TOL for ex_pt in intersections):\n                    intersections.append(pt)\n        \n        if len(intersections)  2: return np.array([])\n\n        max_dist_sq, chord_p1, chord_p2 = -1.0, None, None\n        for i in range(len(intersections)):\n            for j in range(i + 1, len(intersections)):\n                dist_sq = np.sum((intersections[i] - intersections[j])**2)\n                if dist_sq > max_dist_sq:\n                    max_dist_sq, chord_p1, chord_p2 = dist_sq, intersections[i], intersections[j]\n\n        normal = np.array([chord_p2[1] - chord_p1[1], chord_p1[0] - chord_p2[0]])\n        center_side_val = np.dot(normal, c_center - chord_p1)\n        \n        output_list, S = [], P[-1]\n        for E in P:\n            s_dot = np.dot(normal, S - chord_p1)\n            e_dot = np.dot(normal, E - chord_p1)\n            s_inside, e_inside = s_dot * center_side_val >= -TOL, e_dot * center_side_val >= -TOL\n            \n            if e_inside:\n                if not s_inside: output_list.append(line_intersection(S, E, chord_p1, chord_p2))\n                output_list.append(E)\n            elif s_inside:\n                output_list.append(line_intersection(S, E, chord_p1, chord_p2))\n            S = E\n        return np.array(output_list)\n\n    def calculate_integral_approx(P, c_center, R, method):\n        \"\"\"\n        Computes I_ref or I_chord based on the specified method.\n        I = integral_P(f+) + integral_{R}(g), where R is the approximated inside region.\n        \"\"\"\n        integral_fplus_on_P = integrate_linear_over_poly(P, ALPHA_COEFFS)\n        \n        if method == 'ref':\n            angles = np.linspace(0, 2 * np.pi, N_REF, endpoint=False)\n            C_N_verts = c_center + R * np.c_[np.cos(angles), np.sin(angles)]\n            R_approx = clip_sutherland_hodgman(P, C_N_verts)\n        elif method == 'chord':\n            R_approx = get_chord_polygon(P, c_center, R)\n        else:\n            raise ValueError(\"Invalid method specified\")\n            \n        integral_g_on_R = integrate_linear_over_poly(R_approx, GAMMA_COEFFS)\n        return integral_fplus_on_P + integral_g_on_R\n\n    # --- Test Suite ---\n    test_cases = [\n        # (Polygon vertices, (circle_cx, circle_cy, circle_R))\n        ( [(-0.1,-0.05), (0.6,0.1), (0.45,0.5), (-0.2,0.35)], (0.0, 0.0, 0.5) ), # Case 1\n        ( [(0.1,0.0), (0.2,0.05), (0.05,0.15)], (0.0, 0.0, 1.0) ),              # Case 2\n        ( [(0.8,0.8), (0.9,0.7), (0.7,0.9)], (0.0, 0.0, 0.5) ),                # Case 3\n        ( [(-0.1,0.5), (0.1,0.5), (0.1,0.7), (-0.1,0.7)], (0.0, 0.0, 0.5) ),    # Case 4\n    ]\n\n    results = []\n    for P_verts, circle_params in test_cases:\n        P = np.array(P_verts)\n        c_center = np.array(circle_params[:2])\n        R = circle_params[2]\n        \n        I_ref = calculate_integral_approx(P, c_center, R, 'ref')\n        I_chord = calculate_integral_approx(P, c_center, R, 'chord')\n        \n        error = abs(I_chord - I_ref)\n        results.append(f\"{error:.8f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3406224"}]}