{"hands_on_practices": [{"introduction": "Before applying a numerical scheme, it is essential to understand its core mathematical properties. This foundational exercise guides you through a von Neumann stability analysis of the MacCormack scheme for the 1D linear advection equation. By deriving the scheme's amplification factor, you will not only determine its stability limit—the famous Courant–Friedrichs–Lewy (CFL) condition—but also investigate its phase error, revealing the precise conditions under which the scheme perfectly propagates waves without distortion [@problem_id:3418392].", "problem": "Consider the linear advection equation $u_{t} + a\\,u_{x} = 0$ with constant wave speed $a>0$ on a spatially periodic domain. Let the spatial grid be $x_{j} = j\\,\\Delta x$ for integers $j$, and time levels be $t^{n} = n\\,\\Delta t$. Define the Courant number $\\nu = a\\,\\Delta t/\\Delta x$. The two-step MacCormack predictor-corrector scheme (using a forward spatial difference in the predictor and a backward spatial difference in the corrector for $a>0$) is given by\n$$\nu_{j}^{*} = u_{j}^{n} - \\nu\\left(u_{j+1}^{n} - u_{j}^{n}\\right), \\quad\nu_{j}^{n+1} = \\frac{1}{2}\\left(u_{j}^{n} + u_{j}^{*}\\right) - \\frac{\\nu}{2}\\left(u_{j}^{*} - u_{j-1}^{*}\\right).\n$$\nPerform a von Neumann (Fourier) analysis by assuming a plane-wave solution $u_{j}^{n} = \\hat{u}^{n}\\,\\exp(i\\,j\\,\\theta)$ with dimensionless wavenumber $\\theta = k\\,\\Delta x \\in [0,\\pi]$. Starting from the definitions above and fundamental properties of complex exponentials, carry out the following:\n\n1) Derive the one-step update $u_{j}^{n+1} = \\sum_{m=-1}^{1} c_{m}(\\nu)\\,u_{j+m}^{n}$ and thereby obtain the amplification factor $G(\\theta) = \\hat{u}^{n+1}/\\hat{u}^{n}$ as an explicit function of $\\nu$ and $\\theta$.\n\n2) Using the amplification factor, determine the condition on $\\nu$ for von Neumann stability by requiring $|G(\\theta)| \\leq 1$ for all $\\theta \\in [0,\\pi]$.\n\n3) Define the numerical phase $\\phi(\\theta)$ as the continuous argument of $G(\\theta)$ with the branch chosen so that $\\phi(0)=0$, and let the exact phase for one time step be $\\phi_{\\text{exact}}(\\theta) = -\\nu\\,\\theta$. Define the phase error measure\n$$\nE_{\\text{phase}}(\\nu) = \\sup_{\\theta \\in [0,\\pi]} \\left|\\phi(\\theta) - \\phi_{\\text{exact}}(\\theta)\\right|.\n$$\nDetermine the value of $\\nu \\in (0,1]$ that minimizes $E_{\\text{phase}}(\\nu)$. Express your final answer as a single exact real number. No rounding is required and no units are needed.", "solution": "The problem is valid as it is scientifically grounded, well-posed, and objective. It consists of a standard von Neumann stability and phase error analysis of the MacCormack scheme for the linear advection equation, which is a fundamental topic in the numerical solution of partial differential equations. All definitions are standard and the tasks are mathematically rigorous.\n\nWe address the three parts of the problem in sequence.\n\n### Part 1: One-step Update and Amplification Factor\n\nThe MacCormack scheme is given by a predictor-corrector pair of equations:\nPredictor:\n$$\nu_{j}^{*} = u_{j}^{n} - \\nu\\left(u_{j+1}^{n} - u_{j}^{n}\\right)\n\\label{eq:1} \\tag{1}\n$$\nCorrector:\n$$\nu_{j}^{n+1} = \\frac{1}{2}\\left(u_{j}^{n} + u_{j}^{*}\\right) - \\frac{\\nu}{2}\\left(u_{j}^{*} - u_{j-1}^{*}\\right)\n\\label{eq:2} \\tag{2}\n$$\nwhere $\\nu = a\\Delta t / \\Delta x$ is the Courant number.\n\nTo derive the one-step update formula, we first substitute the predictor result from Eq. \\eqref{eq:1} into the corrector equation, Eq. \\eqref{eq:2}.\nFirst, let's express $u_j^*$ and $u_{j-1}^*$ in terms of values at time level $n$.\nFrom Eq. \\eqref{eq:1}, we have:\n$$\nu_{j}^{*} = (1+\\nu)u_{j}^{n} - \\nu u_{j+1}^{n}\n$$\nBy shifting the index $j$ to $j-1$, we get the expression for the predicted value at the adjacent grid point:\n$$\nu_{j-1}^{*} = u_{j-1}^{n} - \\nu\\left(u_{j}^{n} - u_{j-1}^{n}\\right) = (1+\\nu)u_{j-1}^{n} - \\nu u_{j}^{n}\n$$\nNow, substitute these into the corrector step, Eq. \\eqref{eq:2}:\n$$\nu_{j}^{n+1} = \\frac{1}{2}\\left(u_{j}^{n} + \\left[(1+\\nu)u_{j}^{n} - \\nu u_{j+1}^{n}\\right]\\right) - \\frac{\\nu}{2}\\left(\\left[(1+\\nu)u_{j}^{n} - \\nu u_{j+1}^{n}\\right] - \\left[(1+\\nu)u_{j-1}^{n} - \\nu u_{j}^{n}\\right]\\right)\n$$\nLet's collect the coefficients for $u_{j-1}^{n}$, $u_{j}^{n}$, and $u_{j+1}^{n}$.\nCoefficient of $u_{j-1}^{n}$:\n$$\nc_{-1} = -\\frac{\\nu}{2} (-(1+\\nu)) = \\frac{\\nu(1+\\nu)}{2} = \\frac{\\nu^2+\\nu}{2}\n$$\nCoefficient of $u_{j+1}^{n}$:\n$$\nc_{1} = \\frac{1}{2}(-\\nu) - \\frac{\\nu}{2}(-\\nu) = -\\frac{\\nu}{2} + \\frac{\\nu^2}{2} = \\frac{\\nu^2-\\nu}{2}\n$$\nCoefficient of $u_{j}^{n}$:\n$$\nc_{0} = \\frac{1}{2}(1 + (1+\\nu)) - \\frac{\\nu}{2}((1+\\nu) - (-\\nu)) = \\frac{2+\\nu}{2} - \\frac{\\nu}{2}(1+2\\nu) = 1 + \\frac{\\nu}{2} - \\frac{\\nu}{2} - \\nu^2 = 1-\\nu^2\n$$\nThus, the one-step update is:\n$$\nu_{j}^{n+1} = \\left(\\frac{\\nu^2+\\nu}{2}\\right)u_{j-1}^{n} + (1-\\nu^2)u_{j}^{n} + \\left(\\frac{\\nu^2-\\nu}{2}\\right)u_{j+1}^{n}\n$$\nThis is of the form $u_{j}^{n+1} = \\sum_{m=-1}^{1} c_{m}(\\nu)\\,u_{j+m}^{n}$ with the derived coefficients $c_{-1}$, $c_0$, and $c_1$.\n\nNext, we find the amplification factor $G(\\theta)$. We substitute the plane-wave solution $u_{j}^{n} = \\hat{u}^{n}\\,\\exp(i\\,j\\,\\theta)$ into the one-step formula. Note that $u_{j+m}^{n} = \\hat{u}^{n}\\,\\exp(i\\,(j+m)\\,\\theta) = u_{j}^{n}\\exp(i\\,m\\,\\theta)$.\n$$\n\\hat{u}^{n+1}e^{ij\\theta} = c_{-1}\\hat{u}^{n}e^{i(j-1)\\theta} + c_{0}\\hat{u}^{n}e^{ij\\theta} + c_{1}\\hat{u}^{n}e^{i(j+1)\\theta}\n$$\nDividing by $\\hat{u}^{n}e^{ij\\theta}$, we obtain the amplification factor $G(\\theta) = \\hat{u}^{n+1}/\\hat{u}^{n}$:\n$$\nG(\\theta) = c_{-1}e^{-i\\theta} + c_{0} + c_{1}e^{i\\theta}\n$$\nSubstituting the expressions for the coefficients:\n$$\nG(\\theta) = \\left(\\frac{\\nu^2+\\nu}{2}\\right)e^{-i\\theta} + (1-\\nu^2) + \\left(\\frac{\\nu^2-\\nu}{2}\\right)e^{i\\theta}\n$$\nWe group terms with $\\nu^2$ and $\\nu$:\n$$\nG(\\theta) = (1-\\nu^2) + \\frac{\\nu^2}{2}(e^{i\\theta} + e^{-i\\theta}) - \\frac{\\nu}{2}(e^{i\\theta} - e^{-i\\theta})\n$$\nUsing Euler's identities, $\\cos\\theta = \\frac{e^{i\\theta} + e^{-i\\theta}}{2}$ and $\\sin\\theta = \\frac{e^{i\\theta} - e^{-i\\theta}}{2i}$:\n$$\nG(\\theta) = (1-\\nu^2) + \\nu^2\\cos\\theta - \\nu(i\\sin\\theta)\n$$\nFinally, we obtain the amplification factor as an explicit function of $\\nu$ and $\\theta$:\n$$\nG(\\theta) = 1 - \\nu^2(1-\\cos\\theta) - i\\nu\\sin\\theta\n$$\n\n### Part 2: Von Neumann Stability Condition\n\nFor the scheme to be stable in the von Neumann sense, the modulus of the amplification factor must satisfy $|G(\\theta)| \\le 1$ for all relevant wavenumbers, i.e., for all $\\theta \\in [0, \\pi]$. We analyze $|G(\\theta)|^2$:\n$$\n|G(\\theta)|^2 = (\\operatorname{Re}(G(\\theta)))^2 + (\\operatorname{Im}(G(\\theta)))^2\n$$\nFrom the expression derived in Part 1:\n$\\operatorname{Re}(G(\\theta)) = 1 - \\nu^2(1-\\cos\\theta)$\n$\\operatorname{Im}(G(\\theta)) = -\\nu\\sin\\theta$\nSo,\n$$\n|G(\\theta)|^2 = \\left(1 - \\nu^2(1-\\cos\\theta)\\right)^2 + (-\\nu\\sin\\theta)^2\n$$\n$$\n|G(\\theta)|^2 = 1 - 2\\nu^2(1-\\cos\\theta) + \\nu^4(1-\\cos\\theta)^2 + \\nu^2\\sin^2\\theta\n$$\nLet's use the identity $\\sin^2\\theta = 1-\\cos^2\\theta$:\n$$\n|G(\\theta)|^2 = 1 - 2\\nu^2 + 2\\nu^2\\cos\\theta + \\nu^4(1-2\\cos\\theta+\\cos^2\\theta) + \\nu^2(1-\\cos^2\\theta)\n$$\n$$\n= (1 - 2\\nu^2 + \\nu^2) + (2\\nu^2\\cos\\theta) + \\nu^4 - 2\\nu^4\\cos\\theta + \\nu^4\\cos^2\\theta - \\nu^2\\cos^2\\theta\n$$\n$$\n= 1 - \\nu^2 + 2\\nu^2(1-\\nu^2)\\cos\\theta - \\nu^2(1-\\nu^2)\\cos^2\\theta\n$$\nThis looks complicated. An alternative simplification using half-angle identities proves more direct. Let's use $1-\\cos\\theta = 2\\sin^2(\\theta/2)$ and $\\sin\\theta = 2\\sin(\\theta/2)\\cos(\\theta/2)$:\n$$\n\\operatorname{Re}(G(\\theta)) = 1 - 2\\nu^2\\sin^2(\\theta/2)\n$$\n$$\n\\operatorname{Im}(G(\\theta)) = -\\nu \\left(2\\sin(\\theta/2)\\cos(\\theta/2)\\right)\n$$\n$$\n|G(\\theta)|^2 = \\left(1 - 2\\nu^2\\sin^2(\\theta/2)\\right)^2 + \\left(-2\\nu\\sin(\\theta/2)\\cos(\\theta/2)\\right)^2\n$$\n$$\n= 1 - 4\\nu^2\\sin^2(\\theta/2) + 4\\nu^4\\sin^4(\\theta/2) + 4\\nu^2\\sin^2(\\theta/2)\\cos^2(\\theta/2)\n$$\nUsing $\\cos^2(\\theta/2) = 1-\\sin^2(\\theta/2)$:\n$$\n= 1 - 4\\nu^2\\sin^2(\\theta/2) + 4\\nu^4\\sin^4(\\theta/2) + 4\\nu^2\\sin^2(\\theta/2)\\left(1-\\sin^2(\\theta/2)\\right)\n$$\n$$\n= 1 - 4\\nu^2\\sin^2(\\theta/2) + 4\\nu^4\\sin^4(\\theta/2) + 4\\nu^2\\sin^2(\\theta/2) - 4\\nu^2\\sin^4(\\theta/2)\n$$\nThe terms $\\pm 4\\nu^2\\sin^2(\\theta/2)$ cancel out:\n$$\n|G(\\theta)|^2 = 1 + 4\\nu^4\\sin^4(\\theta/2) - 4\\nu^2\\sin^4(\\theta/2)\n$$\n$$\n|G(\\theta)|^2 = 1 - 4\\nu^2(1-\\nu^2)\\sin^4(\\theta/2)\n$$\nThe stability condition $|G(\\theta)|^2 \\le 1$ translates to:\n$$\n1 - 4\\nu^2(1-\\nu^2)\\sin^4(\\theta/2) \\le 1\n$$\n$$\n-4\\nu^2(1-\\nu^2)\\sin^4(\\theta/2) \\le 0\n$$\nDividing by $-1$ and reversing the inequality sign:\n$$\n4\\nu^2(1-\\nu^2)\\sin^4(\\theta/2) \\ge 0\n$$\nThis inequality must hold for all $\\theta \\in [0, \\pi]$. The terms $4$, $\\nu^2$ (since $\\nu=a\\Delta t/\\Delta x$ and $a>0$, we have $\\nu>0$), and $\\sin^4(\\theta/2)$ are all non-negative. Therefore, the stability of the scheme depends solely on the sign of the term $(1-\\nu^2)$.\nWe must have:\n$$\n1-\\nu^2 \\ge 0 \\implies \\nu^2 \\le 1\n$$\nSince $\\nu>0$, the condition for von Neumann stability is $0 < \\nu \\le 1$.\n\n### Part 3: Minimization of Phase Error\n\nThe phase error is defined as the difference between the numerical phase $\\phi(\\theta) = \\arg(G(\\theta))$ and the exact phase for one time step, $\\phi_{\\text{exact}}(\\theta) = -\\nu\\theta$. The objective is to find the value of $\\nu \\in (0,1]$ that minimizes the phase error measure\n$$\nE_{\\text{phase}}(\\nu) = \\sup_{\\theta \\in [0,\\pi]} \\left|\\phi(\\theta) - \\phi_{\\text{exact}}(\\theta)\\right|.\n$$\nBy definition, the absolute value ensures that $E_{\\text{phase}}(\\nu) \\geq 0$ for all $\\nu$. The minimum possible value for this error measure is $0$. If we can find a value of $\\nu \\in (0,1]$ for which $E_{\\text{phase}}(\\nu)=0$, that value must be the minimizer.\n\nLet's investigate the special case where $\\nu=1$. The stability analysis in Part 2 showed that this is the stability limit.\nSubstituting $\\nu=1$ into the expression for the amplification factor $G(\\theta)$:\n$$\nG(\\theta)|_{\\nu=1} = 1 - 1^2(1-\\cos\\theta) - i(1)\\sin\\theta\n$$\n$$\n= 1 - 1 + \\cos\\theta - i\\sin\\theta\n$$\n$$\n= \\cos\\theta - i\\sin\\theta\n$$\nUsing Euler's formula, this simplifies to:\n$$\nG(\\theta)|_{\\nu=1} = \\exp(-i\\theta)\n$$\nThe numerical phase $\\phi(\\theta)$ is the argument of $G(\\theta)$. For $\\nu=1$:\n$$\n\\phi(\\theta)|_{\\nu=1} = \\arg(\\exp(-i\\theta)) = -\\theta\n$$\nThis holds for $\\theta \\in [0, \\pi]$ as per the problem's convention that $\\phi(0)=0$.\nNow we evaluate the exact phase for $\\nu=1$:\n$$\n\\phi_{\\text{exact}}(\\theta)|_{\\nu=1} = -1 \\cdot \\theta = -\\theta\n$$\nThe phase error for $\\nu=1$ is therefore:\n$$\n\\left|\\phi(\\theta) - \\phi_{\\text{exact}}(\\theta)\\right|_{\\nu=1} = |(-\\theta) - (-\\theta)| = |0| = 0\n$$\nThis is true for all values of $\\theta \\in [0, \\pi]$.\nConsequently, the phase error measure for $\\nu=1$ is:\n$$\nE_{\\text{phase}}(1) = \\sup_{\\theta \\in [0,\\pi]} 0 = 0\n$$\nSince $E_{\\text{phase}}(\\nu) \\ge 0$ for all $\\nu$, and we have found $E_{\\text{phase}}(1)=0$, this means that $\\nu=1$ results in the minimum possible phase error.\nFor any $\\nu \\in (0,1)$, the phase error is not identically zero. For small $\\theta$, the phase error can be shown to be $\\phi(\\theta) - \\phi_{\\text{exact}}(\\theta) \\approx \\frac{\\nu(1-\\nu^2)}{6}\\theta^3$. This is non-zero for $\\theta \\neq 0$ and $\\nu \\in (0,1)$, which implies $E_{\\text{phase}}(\\nu) > 0$ for $\\nu \\in (0,1)$.\n\nTherefore, the value of $\\nu \\in (0,1]$ that minimizes the phase error measure $E_{\\text{phase}}(\\nu)$ is $1$.", "answer": "$$\n\\boxed{1}\n$$", "id": "3418392"}, {"introduction": "Moving from linear advection to nonlinear conservation laws introduces new challenges, most notably the formation of shock waves. This practice demonstrates a fundamental principle in computational fluid dynamics: the necessity of a \"conservative\" discretization to capture the correct shock physics. You will implement both a conservative and a nonconservative version of the MacCormack scheme to solve the inviscid Burgers' equation, a prototype for nonlinear fluid dynamics, and observe firsthand how only the conservative form correctly reproduces the shock speed predicted by the Rankine-Hugoniot condition [@problem_id:3342598]. This hands-on comparison provides an unforgettable lesson on the subtle but critical importance of numerical formulation.", "problem": "Consider the one-dimensional inviscid Burgers equation in conservation form, given by $u_t + \\left(\\frac{u^2}{2}\\right)_x = 0$, where $u = u(x,t)$ denotes a scalar velocity field on a periodic domain with spatial coordinate $x$. The conservation law is understood in the weak sense, so that discontinuous solutions may occur and obey an integral balance derived from the conservation principle. The flux function is $f(u) = \\frac{u^2}{2}$. This equation admits shock waves for Riemann-type initial data with $u_L > u_R$, and the shock speed determined by the Rankine–Hugoniot jump condition is $s = \\frac{f(u_L) - f(u_R)}{u_L - u_R} = \\frac{u_L + u_R}{2}$.\n\nMacCormack predictor–corrector schemes are used to advance hyperbolic partial differential equations. In conservation law form, a MacCormack method advances the solution by predicting with a forward spatial difference of flux and correcting with a backward difference of the predicted flux. A nonconservative variant instead advances the variable using the nonconservative differential form $u_t + u\\,u_x = 0$, applying forward and backward differences to $u$ rather than to the flux $f(u)$. For discontinuous solutions, only the conservative formulation enforces the correct shock motion derived from the integral conservation law, while the nonconservative formulation is not guaranteed to propagate shocks with the correct speed.\n\nYour task is to construct a counterexample demonstrating that a nonconservative MacCormack update yields an incorrect shock location compared to both the conservative MacCormack update and the analytical Rankine–Hugoniot speed for the inviscid Burgers equation. Proceed as follows:\n\n1. Use a periodic domain of length $L=2$, identified with the interval $[-1,1)$. Let $N$ be the number of uniformly spaced grid points, so that $\\Delta x = L/N$. Represent values at cell centers $x_i = -L/2 + i\\,\\Delta x$ for $i = 0,1,\\dots,N-1$.\n\n2. Initialize Riemann data at time $t=0$ with a single discontinuity located at $x = x_0$, defined by\n   $$\n   u(x,0) = \n   \\begin{cases}\n   u_L, & x < x_0, \\\\\n   u_R, & x \\ge x_0,\n   \\end{cases}\n   $$\n   with periodic continuation outside the interval $[-1,1)$.\n\n3. Implement two explicit MacCormack predictor–corrector schemes with a constant time step $\\Delta t$ satisfying a Courant–Friedrichs–Lewy condition based on the maximum characteristic speed. Use a dimensionless Courant number $\\text{CFL}$ and set $\\Delta t = \\text{CFL}\\,\\Delta x / \\max(|u_L|,|u_R|)$.\n   - Conservative MacCormack: apply predictor and corrector using forward and backward differences of the flux function $f(u) = \\frac{u^2}{2}$, ensuring a discretization consistent with the conservation law.\n   - Nonconservative MacCormack: apply predictor and corrector using forward and backward differences of the primitive variable $u$ in the nonconservative form $u_t + u\\,u_x = 0$.\n\n4. Advance each scheme for $n$ steps where $n = \\lceil T/\\Delta t \\rceil$, yielding a final time $t_{\\text{end}} = n\\,\\Delta t$.\n\n5. Estimate the numerical shock location at $t_{\\text{end}}$ for each scheme by identifying the position $x$ at which the solution crosses the midpoint value $m = \\frac{u_L + u_R}{2}$ between neighboring grid points, using linear interpolation between cell centers. If multiple crossings exist due to periodicity or numerical oscillations, select the crossing whose position minimizes the periodic distance to the analytical shock location. If no crossing is detected, approximate the shock location by the position of maximum magnitude of the discrete gradient and then refine using local interpolation.\n\n6. Compute the analytical shock location using the Rankine–Hugoniot speed $s = \\frac{u_L + u_R}{2}$, namely $x_{\\text{exact}}(t_{\\text{end}}) = x_0 + s\\,t_{\\text{end}}$, interpreting positions modulo the domain length $L$ to remain in $[-1,1)$.\n\n7. For each test case, report the absolute periodic distance between the numerical shock location and the analytical shock location at $t_{\\text{end}}$, separately for the conservative and nonconservative MacCormack schemes.\n\nUse the following test suite, which includes a clear shock propagation, a moderate shock, and a stationary shock:\n- Case 1: $u_L = 2.0$, $u_R = 0.0$, $x_0 = 0.0$, $N = 1000$, $T = 0.3$, $\\text{CFL} = 0.4$.\n- Case 2: $u_L = 1.5$, $u_R = 0.5$, $x_0 = -0.2$, $N = 1000$, $T = 0.5$, $\\text{CFL} = 0.4$.\n- Case 3: $u_L = 1.0$, $u_R = -1.0$, $x_0 = 0.3$, $N = 1000$, $T = 0.4$, $\\text{CFL} = 0.4$.\n\nAll quantities are dimensionless; no physical units are required. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of conservative error followed by nonconservative error for each case, namely [$e_{\\text{cons},1}, e_{\\text{noncons},1}, e_{\\text{cons},2}, e_{\\text{noncons},2}, e_{\\text{cons},3}, e_{\\text{noncons},3}$], where each $e$ is a floating-point number representing the absolute periodic distance between the computed and analytical shock locations at the final time for the corresponding scheme and case.", "solution": "The problem requires constructing a numerical counterexample to demonstrate that a nonconservative finite difference scheme fails to compute the correct shock speed for the inviscid Burgers' equation, unlike a conservative scheme. This will be achieved by implementing and comparing two variants of the MacCormack method.\n\nThe one-dimensional inviscid Burgers' equation in conservation-law form is\n$$\n\\frac{\\partial u}{\\partial t} + \\frac{\\partial}{\\partial x} \\left( \\frac{u^2}{2} \\right) = 0\n$$\nwhere $u(x,t)$ is the velocity, and the flux function is $f(u) = \\frac{u^2}{2}$. For smooth solutions, where the derivatives exist, the chain rule can be applied to yield the nonconservative form:\n$$\n\\frac{\\partial u}{\\partial t} + u \\frac{\\partial u}{\\partial x} = 0\n$$\nHowever, hyperbolic conservation laws like Burgers' equation are known to develop discontinuities (shock waves) even from smooth initial data. For discontinuous solutions, the differential forms are not well-defined, and one must refer to the integral form of the conservation law. The dynamics of a discontinuity are governed by the Rankine–Hugoniot jump condition, which is a direct consequence of this integral form. For a shock moving with speed $s$, separating two constant states $u_L$ (left) and $u_R$ (right), the condition is:\n$$\ns = \\frac{f(u_L) - f(u_R)}{u_L - u_R}\n$$\nFor Burgers' equation, this gives the analytical shock speed:\n$$\ns = \\frac{\\frac{1}{2}u_L^2 - \\frac{1}{2}u_R^2}{u_L - u_R} = \\frac{u_L + u_R}{2}\n$$\nA numerical scheme must be formulated in \"conservation form\" to ensure that its solutions converge to a weak solution that satisfies this jump condition. A nonconservative scheme does not respect the integral balance and typically converges to a solution with an incorrect shock speed.\n\nWe will discretize the spatial domain $x \\in [-1, 1)$, of length $L=2$, using $N$ uniformly spaced cell centers $x_i = -L/2 + i \\Delta x$ for $i = 0, \\dots, N-1$, where $\\Delta x = L/N$. The time step $\\Delta t$ is determined by a Courant–Friedrichs–Lewy (CFL) condition, $\\Delta t = \\text{CFL} \\Delta x / \\max(|u_L|, |u_R|)$, to ensure numerical stability.\n\nThe initial condition is a Riemann problem with a step discontinuity at $x=x_0$:\n$$\nu(x,0) = \n\\begin{cases}\nu_L, & x < x_0, \\\\\nu_R, & x \\ge x_0,\n\\end{cases}\n$$\nWe advance the solution to a final time $t_{\\text{end}} = n \\Delta t$, where $n = \\lceil T/\\Delta t \\rceil$.\n\nThe two MacCormack schemes are implemented as follows. Let $u_i^n$ be the numerical solution at grid point $i$ and time $t^n = n \\Delta t$.\n\n**1. Conservative MacCormack Scheme**\nThis scheme discretizes the conservation law $u_t + f(u)_x=0$.\n*   Predictor step (forward difference on flux):\n    $$\n    u_i^* = u_i^n - \\frac{\\Delta t}{\\Delta x} \\left( f(u_{i+1}^n) - f(u_i^n) \\right)\n    $$\n*   Corrector step (backward difference on predicted flux):\n    $$\n    u_i^{n+1} = \\frac{1}{2} \\left( u_i^n + u_i^* - \\frac{\\Delta t}{\\Delta x} \\left( f(u_i^*) - f(u_{i-1}^*) \\right) \\right)\n    $$\nHere, indices are handled periodically, e.g., $u_{N} = u_0$ and $u_{-1} = u_{N-1}$. This scheme is in conservation form and is expected to compute the correct shock speed in the limit of grid refinement.\n\n**2. Nonconservative MacCormack Scheme**\nThis scheme discretizes the nonconservative form $u_t + u u_x=0$.\n*   Predictor step (forward difference on $u$):\n    $$\n    u_i^* = u_i^n - u_i^n \\frac{\\Delta t}{\\Delta x} (u_{i+1}^n - u_i^n)\n    $$\n*   Corrector step (backward difference on predicted $u$):\n    $$\n    u_i^{n+1} = \\frac{1}{2} \\left( u_i^n + u_i^* - u_i^* \\frac{\\Delta t}{\\Delta x} (u_i^* - u_{i-1}^*) \\right)\n    $$\nThis formulation does not discretize a flux difference at the cell interfaces and thus does not enforce a local conservation property. As a result, it is not guaranteed to capture the correct shock dynamics.\n\nAfter evolving the solution to $t_{\\text{end}}$ with both schemes, we determine the numerical shock location. This is done by finding where the numerical solution profile crosses the midpoint value $m = (u_L + u_R)/2$. We use linear interpolation between the two grid points bracketing the crossing. If multiple crossings occur due to numerical oscillations, we select the one closest to the analytical shock position, $x_{\\text{analytical}}(t_{\\text{end}}) = x_0 + s \\cdot t_{\\text{end}}$, using the periodic distance on the domain. The absolute periodic distance between two points $p_1$ and $p_2$ on a domain of length $L$ is given by $\\min(|p_1 - p_2|, L - |p_1 - p_2|)$.\n\nThe error for each scheme is then calculated as the absolute periodic distance between its computed numerical shock location, $x_{\\text{numerical}}$, and the analytical shock location, $x_{\\text{analytical}}$, at the final time $t_{\\text{end}}$. The results for the three test cases will demonstrate that the error for the nonconservative scheme is substantially larger than for the conservative one, confirming that the former computes an incorrect shock speed.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the 1D inviscid Burgers' equation using conservative and nonconservative\n    MacCormack schemes to demonstrate the importance of conservation form\n    for shock capturing.\n    \"\"\"\n    test_cases = [\n        # (u_L, u_R, x_0, N, T, CFL)\n        (2.0, 0.0, 0.0, 1000, 0.3, 0.4),\n        (1.5, 0.5, -0.2, 1000, 0.5, 0.4),\n        (1.0, -1.0, 0.3, 1000, 0.4, 0.4),\n    ]\n\n    results = []\n\n    for u_L, u_R, x_0, N, T, CFL in test_cases:\n        L = 2.0\n        dx = L / N\n        x = -L/2 + np.arange(N) * dx\n        \n        # CFL condition and time steps\n        max_speed = max(abs(u_L), abs(u_R))\n        if max_speed == 0:\n            # Avoid division by zero if max speed is zero, choose a reasonable dt\n            max_speed = 1.0\n        dt = CFL * dx / max_speed\n        num_steps = math.ceil(T / dt)\n        t_end = num_steps * dt\n\n        # Initial condition\n        u0 = np.full(N, u_R, dtype=np.float64)\n        u0[x < x_0] = u_L\n        \n        u_cons = u0.copy()\n        u_noncons = u0.copy()\n\n        # --- Time evolution ---\n        for _ in range(num_steps):\n            # Conservative MacCormack\n            f = 0.5 * u_cons**2\n            # Predictor\n            u_star_c = u_cons - (dt / dx) * (np.roll(f, -1) - f)\n            # Corrector\n            f_star = 0.5 * u_star_c**2\n            u_cons = 0.5 * (u_cons + u_star_c - (dt / dx) * (f_star - np.roll(f_star, 1)))\n\n            # Nonconservative MacCormack\n            # Predictor\n            u_star_nc = u_noncons - u_noncons * (dt / dx) * (np.roll(u_noncons, -1) - u_noncons)\n            # Corrector\n            u_noncons = 0.5 * (u_noncons + u_star_nc - u_star_nc * (dt / dx) * (u_star_nc - np.roll(u_star_nc, 1)))\n        \n        # --- Analysis ---\n        # Analytical shock location\n        s = (u_L + u_R) / 2.0\n        x_analytical = x_0 + s * t_end\n        # Map to periodic domain [-L/2, L/2)\n        x_analytical = -L/2 + (x_analytical - (-L/2)) % L\n\n        midpoint_val = (u_L + u_R) / 2.0\n        \n        def find_shock_location(u_final, x_grid, L_domain, analytical_pos, dx_grid):\n            \"\"\"\n            Finds the numerical shock location by looking for a crossing of the\n            midpoint value, refined by linear interpolation.\n            \"\"\"\n            crossings = []\n            # Find all crossings of midpoint_val\n            for i in range(N):\n                u_i = u_final[i]\n                u_i_plus_1 = u_final[(i + 1) % N]\n                if (u_i - midpoint_val) * (u_i_plus_1 - midpoint_val) <= 0 and u_i != u_i_plus_1:\n                    x_i = x_grid[i]\n                    x_cross = x_i + dx_grid * (midpoint_val - u_i) / (u_i_plus_1 - u_i)\n                    crossings.append(x_cross)\n\n            if crossings:\n                # Find crossing closest to analytical solution\n                min_dist = float('inf')\n                best_pos = crossings[0]\n                for pos in crossings:\n                    dist = abs(pos - analytical_pos)\n                    periodic_dist = min(dist, L_domain - dist)\n                    if periodic_dist < min_dist:\n                        min_dist = periodic_dist\n                        best_pos = pos\n                return best_pos\n            else:\n                # Fallback: max gradient\n                grad = np.abs(np.roll(u_final, -1) - u_final)\n                max_grad_idx = np.argmax(grad)\n                \n                u_a = u_final[max_grad_idx]\n                u_b = u_final[(max_grad_idx + 1) % N]\n                x_a = x_grid[max_grad_idx]\n                \n                if abs(u_b - u_a) < 1e-9: # Avoid division by zero\n                    return x_a + dx_grid / 2.0\n                \n                x_pos = x_a + dx_grid * (midpoint_val - u_a) / (u_b - u_a)\n                return x_pos\n\n        def periodic_map(pos, length):\n            \"\"\"Maps a position to the periodic interval [-length/2, length/2).\"\"\"\n            return -length/2 + (pos - (-length/2)) % length\n\n        x_num_cons = find_shock_location(u_cons, x, L, x_analytical, dx)\n        x_num_noncons = find_shock_location(u_noncons, x, L, x_analytical, dx)\n        \n        x_num_cons = periodic_map(x_num_cons, L)\n        x_num_noncons = periodic_map(x_num_noncons, L)\n        \n        def periodic_distance(p1, p2, length):\n            \"\"\"Calculates the absolute periodic distance between two points.\"\"\"\n            dist = abs(p1 - p2)\n            return min(dist, length - dist)\n\n        error_cons = periodic_distance(x_num_cons, x_analytical, L)\n        error_noncons = periodic_distance(x_num_noncons, x_analytical, L)\n\n        results.extend([error_cons, error_noncons])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3342598"}, {"introduction": "The theoretical elegance of a high-order scheme can be easily compromised by improper implementation, especially at domain boundaries. This exercise shifts the focus to this crucial practical aspect by examining the MacCormack scheme on a finite domain with an outflow boundary. Using the method of manufactured solutions, you will code and compare several common boundary closures and measure their impact on the scheme's global accuracy [@problem_id:3418379]. This practice provides invaluable experience in diagnosing and remedying the degradation of accuracy caused by boundary treatments, a common hurdle in the development of robust numerical solvers.", "problem": "Consider the linear advection equation $u_t + a u_x = 0$ on the spatial domain $x \\in [0,1]$ and time $t \\in [0,T]$, with constant advection speed $a > 0$. The MacCormack predictor-corrector scheme is a two-step explicit method that, on a uniform grid with spacing $\\Delta x$, advances a discrete solution $u_i^n \\approx u(x_i,t^n)$ from time $t^n$ to time $t^{n+1} = t^n + \\Delta t$ by a predictor using a forward difference in space and a corrector using a backward difference in space. Interior nodes use centered-in-time updates and achieve second-order accuracy when both spatial and temporal discretizations are second order and smooth boundary data are applied consistently at each stage. However, at outflow boundaries where no physical boundary condition is specified, numerical closures are required to update boundary nodes and furnish values needed in the predictor and corrector steps. Using first-order one-sided closures at either stage can reduce the global order of accuracy to first order even if the interior scheme is second order.\n\nFrom first principles, start with the governing equation $u_t + a u_x = 0$ with $a > 0$ and a smooth exact solution $u(x,t)$ used as a manufactured solution. Use the consistency of Taylor expansions and the requirement that discrete approximations match the continuous differential operator up to a specified order at all nodes, including boundaries. Treat the inflow boundary at $x=0$ using a smooth prescribed boundary function $g(t) = u(0,t)$ applied at the appropriate stage times. Analyze how a first-order outflow boundary closure introduces a local truncation error of order $\\mathcal{O}(\\Delta x)$ at $x=1$ that can dominate the global error. Then, design a boundary-corrected stencil at $x=1$ that is consistent with the MacCormack time integration and uses a second-order one-sided spatial derivative to update $u_N \\approx u(1,t)$ such that the overall scheme recovers second-order convergence.\n\nYour program must implement three variants for the outflow boundary at $x=1$ within the MacCormack predictor-corrector framework on a uniform grid with $N+1$ nodes $x_i = i \\Delta x$, $\\Delta x = 1/N$, Courant number $\\nu = a \\Delta t/\\Delta x$, and $a=1$:\n\n- Variant A (naive constant extrapolation): At both predictor and corrector stages, set the outflow boundary value by $u_N = u_{N-1}$.\n- Variant B (first-order backward-difference boundary update): At the predictor stage, update $u_N$ using the first-order backward difference for $u_x$ at time $t^n$, i.e., $u_N^\\star = u_N^n - a \\frac{\\Delta t}{\\Delta x} (u_N^n - u_{N-1}^n)$. At the corrector stage, update $u_N$ using trapezoidal time averaging with first-order backward differences, i.e., $u_N^{n+1} = u_N^n - \\frac{a \\Delta t}{2} \\left( \\frac{u_N^n - u_{N-1}^n}{\\Delta x} + \\frac{u_N^\\star - u_{N-1}^\\star}{\\Delta x} \\right)$.\n- Variant C (second-order boundary-corrected stencil): At the predictor stage, update $u_N$ using the second-order backward difference for $u_x$ at time $t^n$, i.e., $u_N^\\star = u_N^n - a \\Delta t \\left( \\frac{3 u_N^n - 4 u_{N-1}^n + u_{N-2}^n}{2 \\Delta x} \\right)$. At the corrector stage, update $u_N$ using trapezoidal time averaging with second-order backward differences, i.e., $u_N^{n+1} = u_N^n - \\frac{a \\Delta t}{2} \\left( \\frac{3 u_N^n - 4 u_{N-1}^n + u_{N-2}^n}{2 \\Delta x} + \\frac{3 u_N^\\star - 4 u_{N-1}^\\star + u_{N-2}^\\star}{2 \\Delta x} \\right)$.\n\nFor all variants, apply the inflow boundary condition at $x=0$ using the manufactured exact boundary value at the appropriate stage time: $u_0^n = g(t^n)$ and $u_0^\\star = g(t^{n+1})$. For interior nodes, use the standard MacCormack predictor with a forward difference and the corrector with a backward difference.\n\nUse the manufactured solution $u(x,t) = \\sin(2 \\pi (x - a t))$ with $a = 1$, which exactly satisfies the homogeneous advection equation. Initialize the discrete solution by $u_i^0 = \\sin(2 \\pi x_i)$ and set the inflow boundary by $g(t) = \\sin(-2 \\pi t)$. Integrate to final time $T = 1$ with Courant number $\\nu = 0.8$ (dimensionless). Use a time step $\\Delta t$ chosen to satisfy $\\nu \\le 0.8$ and an integer number of steps, and enforce the boundary condition at $x=0$ at each stage time $t^n$ and $t^{n+1}$ as noted.\n\nDefine the discrete $\\ell^2$-error at time $T$ by\n$$\nE(N) = \\left( \\frac{1}{N+1} \\sum_{i=0}^N \\left( u_i^N - \\sin(2 \\pi (x_i - a T)) \\right)^2 \\right)^{1/2}.\n$$\nFor each variant, compute the observed order of accuracy $p$ between two successive grid refinements $N$ and $2N$ using $p = \\log_2\\left( \\frac{E(N)}{E(2N)} \\right)$.\n\nTest suite specification:\n- Use grid sizes $N \\in \\{64, 128, 256, 512\\}$.\n- Use advection speed $a = 1$, Courant number $\\nu = 0.8$, and final time $T = 1$ (dimensionless).\n- Evaluate the observed order using the two finest grids $N=256$ and $N=512$ for each variant.\n- The three test cases correspond to the variants: A, B, and C as defined above.\n\nYour program must output a single line containing a list of three floating-point numbers [$p_A, p_B, p_C$], where $p_A$ is the observed order for Variant A, $p_B$ is the observed order for Variant B, and $p_C$ is the observed order for Variant C, in this order. No units are involved. The single line must be exactly a comma-separated list enclosed in square brackets, with no additional whitespace requirements beyond standard formatting. The answer values are floats.", "solution": "The user wants to analyze the MacCormack scheme for the linear advection equation, focusing on the impact of outflow boundary conditions on the global order of accuracy.\n\n### 1. Problem Formulation\n\nThe problem under consideration is the one-dimensional linear advection equation:\n$$\n\\frac{\\partial u}{\\partial t} + a \\frac{\\partial u}{\\partial x} = 0\n$$\non a spatial domain $x \\in [0, 1]$ and time domain $t \\in [0, T]$, with a constant advection speed $a > 0$. We will use the method of manufactured solutions to verify the numerical scheme's order of accuracy. The chosen exact solution is $u(x,t) = \\sin(2 \\pi (x - a t))$, which satisfies the governing equation. This provides an initial condition $u(x,0) = \\sin(2 \\pi x)$ and an inflow boundary condition at $x=0$, $g(t) = u(0,t) = \\sin(-2 \\pi a t)$. Since $a>0$, characteristics flow out of the domain at the boundary $x=1$, so no physical boundary condition is specified there; a numerical closure is required.\n\nThe domain is discretized on a uniform grid with $N+1$ points $x_i = i \\Delta x$ for $i=0, 1, \\dots, N$, where $\\Delta x = 1/N$. The solution is advanced in time with steps of size $\\Delta t$, where $t^n = n \\Delta t$. The dimensionless Courant-Friedrichs-Lewy (CFL) number is defined as $\\nu = a \\Delta t / \\Delta x$.\n\n### 2. The Interior MacCormack Scheme\n\nThe MacCormack scheme is an explicit, two-step predictor-corrector method. For interior nodes $i=1, \\dots, N-1$, the scheme is as follows:\n\n**Predictor Step:** A forward Euler time step is taken using a forward spatial difference for $u_x$:\n$$\nu_i^\\star = u_i^n - a \\frac{\\Delta t}{\\Delta x} (u_{i+1}^n - u_i^n)\n$$\nHere, $u_i^n$ is the numerical solution at $(x_i, t^n)$, and $u_i^\\star$ is the predicted value at an intermediate time.\n\n**Corrector Step:** The final value at the new time level $t^{n+1} = t^n + \\Delta t$ is obtained by averaging the time derivatives at $t^n$ and the predicted state, resembling a trapezoidal rule. The spatial derivative in this step uses a backward difference on the predicted values:\n$$\nu_i^{n+1} = \\frac{1}{2} \\left( u_i^n + u_i^\\star - a \\frac{\\Delta t}{\\Delta x} (u_i^\\star - u_{i-1}^\\star) \\right)\n$$\nThis scheme is second-order accurate in both space and time, $\\mathcal{O}(\\Delta t^2, \\Delta x^2)$, for interior nodes, provided the solution is sufficiently smooth. The combination of a forward difference followed by a backward difference is crucial for the cancellation of leading-order error terms, which results in second-order accuracy.\n\n### 3. Analysis of Outflow Boundary Conditions\n\nThe global accuracy of a numerical scheme is determined by the lowest order of the local truncation error (LTE) anywhere in the computational domain. If the numerical boundary condition has a lower order of accuracy than the interior scheme, it can contaminate the entire solution and reduce the global order of convergence. We analyze three different numerical boundary conditions at the outflow boundary $x=1$ (node $i=N$).\n\n*   **Variant A (Naive Constant Extrapolation):** The problem describes this as \"At both predictor and corrector stages, set the outflow boundary value by $u_N = u_{N-1}$.\" We interpret this as a procedural rule:\n    1.  After computing the predicted values $u_i^\\star$ for the interior, the predicted value at the boundary is set by extrapolation: $u_N^\\star = u_{N-1}^\\star$.\n    2.  After computing the corrected values $u_i^{n+1}$ for the interior, the final value at the boundary is set by extrapolation: $u_N^{n+1} = u_{N-1}^{n+1}$.\n    This is a zeroth-order extrapolation, which is equivalent to assuming $(\\partial u / \\partial x)_N = 0$. This is generally inconsistent with the solution of the PDE. This introduces a local truncation error at the boundary of order $\\mathcal{O}(\\Delta x)$. This first-order local error at a single point is sufficient to degrade the global accuracy of the entire scheme to first order, $\\mathcal{O}(\\Delta x)$.\n\n*   **Variant B (First-Order Backward-Difference Update):** This variant updates the boundary value $u_N$ using stencils consistent with the governing equation $u_t = -a u_x$, but with first-order accurate spatial differences.\n    -   Predictor: $u_N^\\star = u_N^n - a \\Delta t \\left( \\frac{u_N^n - u_{N-1}^n}{\\Delta x} \\right)$. This is a forward Euler step in time with a first-order backward difference for $u_x$.\n    -   Corrector: $u_N^{n+1} = u_N^n - \\frac{a \\Delta t}{2} \\left[ \\left(\\frac{u_N^n - u_{N-1}^n}{\\Delta x}\\right) + \\left(\\frac{u_N^\\star - u_{N-1}^\\star}{\\Delta x}\\right) \\right]$. This uses the trapezoidal rule for time integration, which is second-order accurate.\n    However, the spatial discretization remains first-order accurate. The MacCormack scheme's second-order accuracy relies on the specific symmetric cancellation of errors from the forward-predictor and backward-corrector steps. By using a backward difference in the predictor stage (or any stencil other than the forward one), this error cancellation mechanism is broken at the boundary and adjacent nodes. The resulting local truncation error near the boundary is $\\mathcal{O}(\\Delta x^2)$, but the disruption of the cancellation mechanism typically results in a global error of first order, $\\mathcal{O}(\\Delta x)$.\n\n*   **Variant C (Second-Order Boundary-Corrected Stencil):** To restore second-order accuracy, the numerical boundary condition must itself be at least second-order accurate. This variant uses a second-order accurate one-sided (backward) difference for the spatial derivative $u_x$ at the boundary node $i=N$. The stencil is given by:\n    $$\n    \\left( \\frac{\\partial u}{\\partial x} \\right)_N \\approx \\frac{3 u_N - 4 u_{N-1} + u_{N-2}}{2 \\Delta x} + \\mathcal{O}(\\Delta x^2)\n    $$\n    This approximation is used in a time-integration scheme consistent with the interior MacCormack method:\n    -   Predictor: $u_N^\\star = u_N^n - a \\Delta t \\left( \\frac{3 u_N^n - 4 u_{N-1}^n + u_{N-2}^n}{2 \\Delta x} \\right)$.\n    -   Corrector: $u_N^{n+1} = u_N^n - \\frac{a \\Delta t}{2} \\left[ \\left(\\frac{3 u_N^n - 4 u_{N-1}^n + u_{N-2}^n}{2 \\Delta x}\\right) + \\left(\\frac{3 u_N^\\star - 4 u_{N-1}^\\star + u_{N-2}^\\star}{2 \\Delta x}\\right) \\right]$.\n    Since the LTE of this boundary update is $\\mathcal{O}(\\Delta x^2, \\Delta t^2)$, it matches the second-order accuracy of the interior scheme. Consequently, the global order of accuracy for the entire computation is expected to be second-order, $\\mathcal{O}(\\Delta x^2)$.\n\n### 4. Implementation and Verification\n\nA Python program will implement the three variants. For each variant, the simulation is run for a sequence of refining grid sizes ($N=256, 512$). The discrete $\\ell^2$-error, $E(N)$, is calculated at the final time $T=1$ by comparing the numerical solution to the exact manufactured solution. The observed order of accuracy, $p$, is then computed using the errors from the two finest grids:\n$$\np = \\log_2\\left( \\frac{E(N)}{E(2N)} \\right)\n$$\nWe expect to find $p_A \\approx 1$, $p_B \\approx 1$, and $p_C \\approx 2$.", "answer": "```python\nimport numpy as np\n\ndef run_simulation(N, variant, a, nu, T):\n    \"\"\"\n    Solves the 1D linear advection equation using the MacCormack scheme\n    with specified outflow boundary condition variants.\n\n    Args:\n        N (int): Number of spatial intervals.\n        variant (str): Outflow boundary condition variant ('A', 'B', or 'C').\n        a (float): Advection speed.\n        nu (float): Courant number.\n        T (float): Final time.\n\n    Returns:\n        float: The discrete l2-error at the final time.\n    \"\"\"\n    # 1. Grid and Time Step Setup\n    dx = 1.0 / N\n    dt_ideal = nu * dx / a\n    # Ensure an integer number of steps to reach T exactly\n    num_steps = int(round(T / dt_ideal))\n    dt = T / num_steps\n    # Recalculate Courant number based on adjusted dt\n    nu = a * dt / dx\n\n    x = np.linspace(0.0, 1.0, N + 1)\n\n    # 2. Define Exact Solution and Boundary Conditions\n    def u_exact(x_coords, t_val):\n        return np.sin(2 * np.pi * (x_coords - a * t_val))\n\n    def g(t_val):\n        return np.sin(-2 * np.pi * a * t_val)\n\n    # 3. Initial Condition\n    u = u_exact(x, 0.0)\n    t = 0.0\n\n    # 4. Time-stepping Loop\n    for _ in range(num_steps):\n        u_old = u.copy()\n        t_next = t + dt\n\n        # --- Predictor Stage ---\n        u_star = np.zeros_like(u_old)\n\n        # Inflow boundary condition (i=0) as specified for the predicted state\n        u_star[0] = g(t_next)\n\n        # Interior nodes (i=1 to N-1) using forward difference\n        u_star[1:N] = u_old[1:N] - nu * (u_old[2:] - u_old[1:N])\n\n        # Outflow boundary condition (i=N) for the predictor stage\n        if variant == 'A':\n            # Naive constant extrapolation of the predicted value\n            u_star[N] = u_star[N-1]\n        elif variant == 'B':\n            # First-order backward-difference update\n            u_star[N] = u_old[N] - nu * (u_old[N] - u_old[N-1])\n        elif variant == 'C':\n            # Second-order backward-difference update\n            u_star[N] = u_old[N] - (nu / 2.0) * (3 * u_old[N] - 4 * u_old[N-1] + u_old[N-2])\n\n        # --- Corrector Stage ---\n        u_new = np.zeros_like(u_old)\n\n        # Inflow boundary condition (i=0) for the final state\n        u_new[0] = g(t_next)\n\n        # Interior nodes (i=1 to N-1) using backward difference\n        u_new[1:N] = 0.5 * (u_old[1:N] + u_star[1:N] - nu * (u_star[1:N] - u_star[0:N-1]))\n\n        # Outflow boundary condition (i=N) for the corrector stage\n        if variant == 'A':\n            # Naive constant extrapolation of the final value\n            u_new[N] = u_new[N-1]\n        elif variant == 'B':\n            # First-order trapezoidal update\n            u_new[N] = u_old[N] - (nu / 2.0) * ((u_old[N] - u_old[N-1]) + (u_star[N] - u_star[N-1]))\n        elif variant == 'C':\n            # Second-order trapezoidal update\n            u_new[N] = u_old[N] - (nu / 4.0) * (\n                (3 * u_old[N] - 4 * u_old[N-1] + u_old[N-2]) +\n                (3 * u_star[N] - 4 * u_star[N-1] + u_star[N-2])\n            )\n\n        u = u_new\n        t = t_next\n\n    # 5. Compute Error\n    u_e = u_exact(x, T)\n    error = np.sqrt(np.mean((u - u_e)**2))\n    return error\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and compute the order of accuracy.\n    \"\"\"\n    # Test Suite Specification\n    a = 1.0\n    nu_target = 0.8\n    T = 1.0\n    variants = ['A', 'B', 'C']\n    Ns = [256, 512]\n    \n    orders = []\n\n    for variant in variants:\n        errors = []\n        for N in Ns:\n            error = run_simulation(N, variant, a, nu_target, T)\n            errors.append(error)\n        \n        # Calculate observed order of accuracy p = log2(E(N) / E(2N))\n        # N=Ns[0], 2N=Ns[1]\n        order = np.log2(errors[0] / errors[1])\n        orders.append(order)\n\n    # Format the final output string\n    result_str = f\"[{orders[0]},{orders[1]},{orders[2]}]\"\n    print(result_str)\n\nsolve()\n```", "id": "3418379"}]}