{"hands_on_practices": [{"introduction": "Writing code to solve a differential equation is only the first step; you must also rigorously verify that it is correct. This practice introduces the Method of Manufactured Solutions (MMS), a cornerstone of numerical code verification that allows you to test your implementation against a known analytical solution. By implementing a conservative finite difference scheme and using MMS and Richardson extrapolation, you will learn to confirm your code's accuracy and systematically improve your solution's precision [@problem_id:3392829].", "problem": "Consider the one-dimensional linear second-order elliptic boundary value problem in conservative form on the closed interval $[0,1]$:\n$$\n-\\frac{d}{dx}\\left(a(x)\\,\\frac{du(x)}{dx}\\right) + c(x)\\,u(x) = f(x).\n$$\nYou will verify the accuracy of a second-order conservative finite difference discretization using the Method of Manufactured Solutions (MMS) and then apply Richardson extrapolation to improve a pointwise solution estimate. All trigonometric arguments are to be interpreted in radians.\n\nFundamental definitions and discretization. Let $N\\in\\mathbb{N}$ be the number of uniform subintervals, $h = 1/N$ the grid spacing, and $x_i = i\\,h$ for $i=0,1,\\dots,N$ the grid nodes. For interior indices $i=1,\\dots,N-1$, define the midpoint locations $x_{i\\pm \\frac{1}{2}} = x_i \\pm \\frac{h}{2}$. The second-order conservative finite difference scheme at interior nodes is constructed from the conservative form and midpoint evaluation of the diffusion coefficient:\n$$\n-\\frac{1}{h}\\left(a\\!\\left(x_{i+\\frac{1}{2}}\\right)\\frac{u_{i+1}-u_i}{h} - a\\!\\left(x_{i-\\frac{1}{2}}\\right)\\frac{u_i-u_{i-1}}{h}\\right) + c(x_i)\\,u_i = f(x_i).\n$$\nFor Dirichlet boundary conditions at $x=0$ and $x=1$, set $u_0$ and $u_N$ equal to the exact boundary values. For a Robin boundary condition at $x=0$ of the form\n$$\n\\alpha\\,u(0) + \\beta\\,u'(0) = \\gamma,\n$$\nenforce the boundary equation using the second-order one-sided difference approximation\n$$\nu'(0) \\approx \\frac{-3u_0 + 4u_1 - u_2}{2h},\n$$\nand include this equation as the first equation in the linear system (with the interior equations at $i=1,\\dots,N-1$ and the right Dirichlet boundary at $x=1$ applied strongly by substituting $u_N$).\n\nMethod of Manufactured Solutions (MMS). For each test below, choose a smooth exact solution $u_{\\text{ex}}(x)$ and define the data $f(x)$ by substituting $u_{\\text{ex}}(x)$ into the differential operator:\n$$\nf(x) = -\\left(a(x)\\,u_{\\text{ex}}''(x) + a'(x)\\,u_{\\text{ex}}'(x)\\right) + c(x)\\,u_{\\text{ex}}(x).\n$$\nImpose boundary conditions exactly using $u_{\\text{ex}}$ and, when needed, $u_{\\text{ex}}'$.\n\nObserved order of accuracy and Richardson extrapolation. Let $\\|e_h\\|_{\\infty}$ denote the maximum-norm error on the grid with spacing $h$, defined by $\\|e_h\\|_{\\infty} = \\max_{0\\le i\\le N} |u_i - u_{\\text{ex}}(x_i)|$ when both endpoints are included among the unknowns, or by the maximum over all nodes (with exact boundary values included) when Dirichlet values are imposed strongly. The observed order computed from two nested grids of sizes $h$ and $h/2$ is\n$$\np_{\\infty} = \\log_2\\!\\left(\\frac{\\|e_h\\|_{\\infty}}{\\|e_{h/2}\\|_{\\infty}}\\right).\n$$\nGiven approximations $U_h(x^\\star)$ and $U_{h/2}(x^\\star)$ to $u(x^\\star)$ at a fixed point $x^\\star\\in(0,1)$ obtained by linear interpolation from the two grids, and an estimate $p$ of the convergence order, the Richardson-extrapolated value is\n$$\nU_{\\text{RE}}(x^\\star) = \\frac{2^p\\,U_{h/2}(x^\\star) - U_{h}(x^\\star)}{2^p - 1}.\n$$\n\nTasks. Implement the finite difference method described above, verify the observed order using MMS on the test suite, and perform Richardson extrapolation at a specified point. Your program must solve the following three manufactured-solution test problems:\n\n- Test A (smooth variable coefficients, Dirichlet–Dirichlet):\n  - $a(x) = 2 + \\sin(3x)$,\n  - $c(x) = 1 + x$,\n  - $u_{\\text{ex}}(x) = e^{x}\\,\\sin(2\\pi x)$,\n  - Boundaries: $u(0) = u_{\\text{ex}}(0)$, $u(1) = u_{\\text{ex}}(1)$.\n\n- Test B (diffusion-dominated, Dirichlet–Dirichlet):\n  - $a(x) = e^{x}$,\n  - $c(x) = 0$,\n  - $u_{\\text{ex}}(x) = \\sin(5x)$,\n  - Boundaries: $u(0) = u_{\\text{ex}}(0)$, $u(1) = u_{\\text{ex}}(1)$.\n\n- Test C (variable diffusion and reaction, Robin–Dirichlet):\n  - $a(x) = 1 + x$,\n  - $c(x) = 2$,\n  - $u_{\\text{ex}}(x) = \\cos(3\\pi x)$,\n  - Left boundary (Robin at $x=0$): $\\alpha = 1$, $\\beta = 1$, $\\gamma = \\alpha\\,u_{\\text{ex}}(0) + \\beta\\,u_{\\text{ex}}'(0)$,\n  - Right boundary (Dirichlet at $x=1$): $u(1) = u_{\\text{ex}}(1)$.\n\nNumerical experiment specifications:\n\n- For each test, compute the observed order $p_{\\infty}$ using the infinity-norm errors from two grid sizes $N = 64$ and $N = 128$ (so $h = 1/64$ and $h/2 = 1/128$).\n- For Test A only, perform Richardson extrapolation at the interior point $x^\\star = 0.37$. Compute $U_h(x^\\star)$ and $U_{h/2}(x^\\star)$ by linear interpolation of the discrete solutions from the $N=64$ and $N=128$ grids, respectively. Use the observed order $p_{\\infty}$ computed for Test A to form $U_{\\text{RE}}(x^\\star)$, and report the absolute error $|U_{\\text{RE}}(x^\\star)-u_{\\text{ex}}(x^\\star)|$ as a float.\n\nAngle unit: All trigonometric functions use radians.\n\nFinal output format: Your program must produce a single line containing a Python-style list with four floating-point numbers\n$$\n\\big[\\,p_{\\infty}^{(A)},\\; p_{\\infty}^{(B)},\\; p_{\\infty}^{(C)},\\; E_{\\text{RE}}^{(A)}(x^\\star)\\,\\big],\n$$\nwhere $p_{\\infty}^{(A)}$, $p_{\\infty}^{(B)}$, and $p_{\\infty}^{(C)}$ are the observed orders for Tests A, B, and C, respectively, and $E_{\\text{RE}}^{(A)}(x^\\star)$ is the absolute Richardson-extrapolation error for Test A at $x^\\star = 0.37$. The program should print exactly one line in the form\n$$\n[{\\tt pA},{\\tt pB},{\\tt pC},{\\tt errRE}]\n$$\nwith the numerical values substituted for the placeholders.", "solution": "The user-provided problem is assessed to be valid. It is a well-posed, scientifically sound, and complete problem in the field of numerical analysis for partial differential equations. All necessary data, functions, and procedures are explicitly defined. The task involves implementing a standard second-order finite difference method, verifying its accuracy with the Method of Manufactured Solutions, and applying Richardson extrapolation, all of which are standard and rigorous techniques.\n\nWe proceed with a complete solution.\n\n### 1. Problem Formulation and Discretization\n\nThe governing one-dimensional elliptic boundary value problem is given in conservative form:\n$$\n-\\frac{d}{dx}\\left(a(x)\\,\\frac{du(x)}{dx}\\right) + c(x)\\,u(x) = f(x) \\quad \\text{for } x \\in [0, 1].\n$$\nWe discretize the domain $[0, 1]$ using a uniform grid with $N$ subintervals, yielding a grid spacing of $h=1/N$. The grid nodes are denoted by $x_i = i h$ for $i=0, 1, \\dots, N$. The numerical solution at these nodes is $u_i \\approx u(x_i)$.\n\nThe core of the method is the second-order accurate conservative finite difference scheme for an interior node $x_i$, where $i=1, \\dots, N-1$:\n$$\n-\\frac{1}{h}\\left(a\\left(x_{i+\\frac{1}{2}}\\right)\\frac{u_{i+1}-u_i}{h} - a\\left(x_{i-\\frac{1}{2}}\\right)\\frac{u_i-u_{i-1}}{h}\\right) + c(x_i)\\,u_i = f(x_i).\n$$\nHere, $x_{i \\pm \\frac{1}{2}} = x_i \\pm \\frac{h}{2}$ are the midpoints between grid nodes. To facilitate the assembly of a linear system, we rearrange the equation by multiplying by $h^2$ and collecting terms corresponding to $u_{i-1}$, $u_i$, and $u_{i+1}$:\n$$\n-a\\left(x_{i-\\frac{1}{2}}\\right) u_{i-1} + \\left(a\\left(x_{i+\\frac{1}{2}}\\right) + a\\left(x_{i-\\frac{1}{2}}\\right) + h^2 c(x_i)\\right) u_i - a\\left(x_{i+\\frac{1}{2}}\\right) u_{i+1} = h^2 f(x_i).\n$$\nThis equation holds for each interior node and forms a system of linear equations $A\\mathbf{u} = \\mathbf{b}$, where $\\mathbf{u}$ is the vector of unknown nodal values. The specific structure of $A$ and $\\mathbf{b}$ depends on the boundary conditions.\n\n### 2. Boundary Conditions\n\n#### 2.1. Dirichlet-Dirichlet Boundary Conditions (Tests A and B)\nWhen Dirichlet conditions $u(0)=u_0$ and $u(1)=u_N$ are prescribed, the values $u_0$ and $u_N$ are known. The unknowns are the interior nodal values $\\mathbf{u} = [u_1, u_2, \\dots, u_{N-1}]^T$. The system of equations is of size $(N-1) \\times (N-1)$.\nThe equation for the first interior node $i=1$ is:\n$$\n\\left(a\\left(x_{\\frac{3}{2}}\\right) + a\\left(x_{\\frac{1}{2}}\\right) + h^2 c(x_1)\\right) u_1 - a\\left(x_{\\frac{3}{2}}\\right) u_2 = h^2 f(x_1) + a\\left(x_{\\frac{1}{2}}\\right) u_0.\n$$\nThe equation for the last interior node $i=N-1$ is:\n$$\n-a\\left(x_{N-\\frac{3}{2}}\\right) u_{N-2} + \\left(a\\left(x_{N-\\frac{1}{2}}\\right) + a\\left(x_{N-\\frac{3}{2}}\\right) + h^2 c(x_{N-1})\\right) u_{N-1} = h^2 f(x_{N-1}) + a\\left(x_{N-\\frac{1}{2}}\\right) u_N.\n$$\nThe resulting matrix $A$ is tridiagonal and symmetric, provided $a(x)$ is constant. For variable $a(x)$, it remains tridiagonal.\n\n#### 2.2. Robin-Dirichlet Boundary Conditions (Test C)\nFor a Robin condition at $x=0$, $\\alpha u(0) + \\beta u'(0) = \\gamma$, and a Dirichlet condition at $x=1$, $u(1)=u_N$. The unknowns are $\\mathbf{u} = [u_0, u_1, \\dots, u_{N-1}]^T$. The system is of size $N \\times N$.\n\nThe first equation comes from the Robin condition, using a second-order forward difference approximation for $u'(0)$:\n$$\n\\alpha u_0 + \\beta \\left(\\frac{-3u_0 + 4u_1 - u_2}{2h}\\right) = \\gamma.\n$$\nMultiplying by $2h$ and rearranging gives the first row of our linear system:\n$$\n(2h\\alpha - 3\\beta) u_0 + 4\\beta u_1 - \\beta u_2 = 2h\\gamma.\n$$\nThe interior equations for $i=1, \\dots, N-2$ follow the standard stencil. The final equation, for node $i=N-1$, incorporates the known value $u_N$:\n$$\n-a\\left(x_{N-\\frac{3}{2}}\\right) u_{N-2} + \\left(a\\left(x_{N-\\frac{1}{2}}\\right) + a\\left(x_{N-\\frac{3}{2}}\\right) + h^2 c(x_{N-1})\\right) u_{N-1} = h^2 f(x_{N-1}) + a\\left(x_{N-\\frac{1}{2}}\\right) u_N.\n$$\nThe resulting matrix $A$ is almost tridiagonal, with an additional non-zero entry at $A_{0,2}$.\n\n### 3. Method of Manufactured Solutions (MMS) and Error Analysis\n\nMMS is used to verify the code's correctness and convergence rate. We select a smooth function $u_{\\text{ex}}(x)$ as the exact solution. The source term $f(x)$ is then manufactured by substituting $u_{\\text{ex}}(x)$ into the differential operator:\n$$\nf(x) = -\\frac{d}{dx}\\left(a(x)\\,\\frac{du_{\\text{ex}}(x)}{dx}\\right) + c(x)\\,u_{\\text{ex}}(x) = -\\left(a(x)\\,u_{\\text{ex}}''(x) + a'(x)\\,u_{\\text{ex}}'(x)\\right) + c(x)\\,u_{\\text{ex}}(x).\n$$\nBoundary conditions are also derived from $u_{\\text{ex}}(x)$. After solving the numerical system for $u_i$, the error is calculated using the maximum norm:\n$$\n\\|e_h\\|_{\\infty} = \\max_{0 \\le i \\le N} |u_i - u_{\\text{ex}}(x_i)|.\n$$\nFor a second-order accurate method, the error should behave as $\\|e_h\\|_{\\infty} \\approx C h^2$ for some constant $C$. The observed order of accuracy $p_{\\infty}$ is computed from solutions on two nested grids with spacings $h$ and $h/2$:\n$$\np_{\\infty} = \\log_2\\left(\\frac{\\|e_h\\|_{\\infty}}{\\|e_{h/2}\\|_{\\infty}}\\right).\n$$\n\n### 4. Richardson Extrapolation\n\nRichardson extrapolation improves the accuracy of an approximation at a specific point $x^\\star$. Given a solution $U_h(x^\\star)$ from grid $h$ and $U_{h/2}(x^\\star)$ from grid $h/2$, and knowing the method has a leading error term of order $p$, an improved estimate is:\n$$\nU_{\\text{RE}}(x^\\star) = U_{h/2}(x^\\star) + \\frac{U_{h/2}(x^\\star) - U_h(x^\\star)}{2^p - 1} = \\frac{2^p U_{h/2}(x^\\star) - U_h(x^\\star)}{2^p - 1}.\n$$\nThe values $U_h(x^\\star)$ and $U_{h/2}(x^\\star)$ are obtained by linear interpolation of the discrete solutions. If $x_j \\le x^\\star \\le x_{j+1}$, the interpolated value is:\n$$\nU(x^\\star) = u_j + (u_{j+1} - u_j) \\frac{x^\\star - x_j}{h}.\n$$\nFor this problem, we use the numerically observed order $p=p_{\\infty}$ in the extrapolation formula.\n\n### 5. Implementation for Test Cases\n\nThe described methodology is applied to three test cases. For each, we define the specific functions $a(x)$, $c(x)$, $u_{\\text{ex}}(x)$, and their derivatives to compute the source term $f(x)$ and boundary data.\n\n- **Test A:** $a(x) = 2 + \\sin(3x)$, $c(x) = 1 + x$, $u_{\\text{ex}}(x) = e^x\\sin(2\\pi x)$.\n- **Test B:** $a(x) = e^x$, $c(x) = 0$, $u_{\\text{ex}}(x) = \\sin(5x)$.\n- **Test C:** $a(x) = 1 + x$, $c(x) = 2$, $u_{\\text{ex}}(x) = \\cos(3\\pi x)$.\n\nFor each test, we solve the system for $N=64$ and $N=128$, compute the errors $\\|e_{1/64}\\|_{\\infty}$ and $\\|e_{1/128}\\|_{\\infty}$, and find the observed order $p_{\\infty}$. For Test A, we additionally perform Richardson extrapolation at $x^\\star = 0.37$ using the solutions from $N=64$ and $N=128$ and the calculated $p_{\\infty}$ for Test A, and report the absolute error of this extrapolated value.\n\nThe final output consists of the three observed orders and the single extrapolation error, presented as a list of four floating-point numbers.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the three test cases specified in the problem, computes observed\n    orders of accuracy, performs Richardson extrapolation for Test A, and\n    prints the results in the specified format.\n    \"\"\"\n\n    # --- Test Case A: Smooth variable coefficients, Dirichlet-Dirichlet ---\n    def get_test_A():\n        case = {\n            'a': lambda x: 2 + np.sin(3*x),\n            'a_prime': lambda x: 3 * np.cos(3*x),\n            'c': lambda x: 1 + x,\n            'u_ex': lambda x: np.exp(x) * np.sin(2*np.pi*x),\n            'u_ex_prime': lambda x: np.exp(x) * (np.sin(2*np.pi*x) + 2*np.pi*np.cos(2*np.pi*x)),\n            'u_ex_double_prime': lambda x: np.exp(x) * ((1 - 4*np.pi**2)*np.sin(2*np.pi*x) + 4*np.pi*np.cos(2*np.pi*x)),\n            'bc_type': ('dirichlet', 'dirichlet'),\n        }\n        case['f'] = lambda x: -(case['a'](x)*case['u_ex_double_prime'](x) + case['a_prime'](x)*case['u_ex_prime'](x)) + case['c'](x)*case['u_ex'](x)\n        case['bc_left_val'] = case['u_ex'](0.0)\n        case['bc_right_val'] = case['u_ex'](1.0)\n        return case\n\n    # --- Test Case B: Diffusion-dominated, Dirichlet-Dirichlet ---\n    def get_test_B():\n        case = {\n            'a': lambda x: np.exp(x),\n            'a_prime': lambda x: np.exp(x),\n            'c': lambda x: 0.0,\n            'u_ex': lambda x: np.sin(5*x),\n            'u_ex_prime': lambda x: 5 * np.cos(5*x),\n            'u_ex_double_prime': lambda x: -25 * np.sin(5*x),\n            'bc_type': ('dirichlet', 'dirichlet'),\n        }\n        case['f'] = lambda x: -(case['a'](x)*case['u_ex_double_prime'](x) + case['a_prime'](x)*case['u_ex_prime'](x)) + case['c'](x)*case['u_ex'](x)\n        case['bc_left_val'] = case['u_ex'](0.0)\n        case['bc_right_val'] = case['u_ex'](1.0)\n        return case\n\n    # --- Test Case C: Variable diffusion and reaction, Robin-Dirichlet ---\n    def get_test_C():\n        alpha, beta = 1.0, 1.0\n        case = {\n            'a': lambda x: 1 + x,\n            'a_prime': lambda x: 1.0,\n            'c': lambda x: 2.0,\n            'u_ex': lambda x: np.cos(3*np.pi*x),\n            'u_ex_prime': lambda x: -3 * np.pi * np.sin(3*np.pi*x),\n            'u_ex_double_prime': lambda x: -9 * np.pi**2 * np.cos(3*np.pi*x),\n            'bc_type': ('robin', 'dirichlet'),\n            'robin_params': (alpha, beta)\n        }\n        case['f'] = lambda x: -(case['a'](x)*case['u_ex_double_prime'](x) + case['a_prime'](x)*case['u_ex_prime'](x)) + case['c'](x)*case['u_ex'](x)\n        gamma = alpha * case['u_ex'](0.0) + beta * case['u_ex_prime'](0.0)\n        case['bc_left_val'] = gamma\n        case['bc_right_val'] = case['u_ex'](1.0)\n        return case\n\n    test_cases = [get_test_A(), get_test_B(), get_test_C()]\n    results = []\n\n    for i, case in enumerate(test_cases):\n        # Solve for N=64\n        u_h, x_h = solve_bvp(64, case)\n        u_ex_h = case['u_ex'](x_h)\n        err_h = np.linalg.norm(u_h - u_ex_h, np.inf)\n        \n        # Solve for N=128\n        u_h_2, x_h_2 = solve_bvp(128, case)\n        u_ex_h_2 = case['u_ex'](x_h_2)\n        err_h_2 = np.linalg.norm(u_h_2 - u_ex_h_2, np.inf)\n        \n        # Compute observed order\n        p_inf = np.log2(err_h / err_h_2)\n        results.append(p_inf)\n        \n        # Perform Richardson Extrapolation for Test A\n        if i == 0:\n            x_star = 0.37\n            \n            # Interpolate for N=64\n            h = 1.0/64\n            j = int(x_star / h)\n            U_h_star = u_h[j] + (u_h[j+1] - u_h[j]) * (x_star - x_h[j]) / h\n            \n            # Interpolate for N=128\n            h_2 = 1.0/128\n            j_2 = int(x_star / h_2)\n            U_h_2_star = u_h_2[j_2] + (u_h_2[j_2+1] - u_h_2[j_2]) * (x_star - x_h_2[j_2]) / h_2\n            \n            # Extrapolate\n            U_RE = (2**p_inf * U_h_2_star - U_h_star) / (2**p_inf - 1)\n            \n            # Compute error\n            u_ex_star = case['u_ex'](x_star)\n            err_RE = np.abs(U_RE - u_ex_star)\n            \n            # Store results, but need to append the error at the end\n            extrap_error = err_RE\n\n    # Reorder results to match output format\n    final_results = [results[0], results[1], results[2], extrap_error]\n    print(f\"[{','.join(map(str, final_results))}]\")\n\n\ndef solve_bvp(N, case):\n    \"\"\"\n    General solver for the 1D BVP.\n    Assembles and solves the linear system based on the boundary condition types.\n    \"\"\"\n    h = 1.0 / N\n    x = np.linspace(0, 1, N + 1)\n    \n    a_func = case['a']\n    c_func = case['c']\n    f_func = case['f']\n    bc_type = case['bc_type']\n    \n    if bc_type == ('dirichlet', 'dirichlet'):\n        # --- Dirichlet-Dirichlet System Assembly ---\n        # Unknowns are u_1, ..., u_{N-1}\n        num_unknowns = N - 1\n        A = np.zeros((num_unknowns, num_unknowns))\n        b = np.zeros(num_unknowns)\n        \n        u0 = case['bc_left_val']\n        uN = case['bc_right_val']\n\n        for i in range(1, N):\n            idx = i - 1 # Matrix index\n            \n            x_i = x[i]\n            x_imhalf = x_i - h/2\n            x_iphalf = x_i + h/2\n            \n            a_imhalf = a_func(x_imhalf)\n            a_iphalf = a_func(x_iphalf)\n            \n            diag_val = a_iphalf + a_imhalf + h**2 * c_func(x_i)\n            \n            A[idx, idx] = diag_val\n            if i > 1:\n                A[idx, idx - 1] = -a_imhalf\n            if i  N - 1:\n                A[idx, idx + 1] = -a_iphalf\n            \n            b[idx] = h**2 * f_func(x_i)\n            \n            # Boundary contributions to RHS\n            if i == 1:\n                b[idx] += a_imhalf * u0\n            if i == N - 1:\n                b[idx] += a_iphalf * uN\n        \n        u_interior = np.linalg.solve(A, b)\n        u_full = np.concatenate(([u0], u_interior, [uN]))\n\n    elif bc_type == ('robin', 'dirichlet'):\n        # --- Robin-Dirichlet System Assembly ---\n        # Unknowns are u_0, ..., u_{N-1}\n        num_unknowns = N\n        A = np.zeros((num_unknowns, num_unknowns))\n        b = np.zeros(num_unknowns)\n        \n        alpha, beta = case['robin_params']\n        gamma = case['bc_left_val']\n        uN = case['bc_right_val']\n        \n        # Row 0: Robin condition at x=0\n        A[0, 0] = 2*h*alpha - 3*beta\n        A[0, 1] = 4*beta\n        A[0, 2] = -beta\n        b[0] = 2*h*gamma\n        \n        # Rows 1 to N-1: Interior finite difference equations\n        for i in range(1, N):\n            x_i = x[i]\n            x_imhalf = x_i - h/2\n            x_iphalf = x_i + h/2\n            \n            a_imhalf = a_func(x_imhalf)\n            a_iphalf = a_func(x_iphalf)\n            \n            diag_val = a_iphalf + a_imhalf + h**2 * c_func(x_i)\n            \n            A[i, i] = diag_val\n            A[i, i - 1] = -a_imhalf\n            if i  N - 1:\n                A[i, i + 1] = -a_iphalf\n                \n            b[i] = h**2 * f_func(x_i)\n            \n            # Boundary contribution to RHS for last equation\n            if i == N - 1:\n                b[i] += a_iphalf * uN\n\n        u_solved = np.linalg.solve(A, b)\n        u_full = np.concatenate((u_solved, [uN]))\n    else:\n        raise ValueError(\"Unsupported boundary condition configuration.\")\n\n    return u_full, x\n\nsolve()\n```", "id": "3392829"}, {"introduction": "Real-world physical systems often consist of composite materials, leading to sharp jumps in the coefficients of the governing PDE. This exercise demonstrates how to create a robust numerical scheme that accurately captures the physics at material interfaces, a common source of error in naive discretizations. You will derive and compare schemes based on arithmetic and harmonic averaging, gaining crucial insight into why the latter is physically and numerically superior for modeling heterogeneous media [@problem_id:3392861].", "problem": "Consider the one-dimensional elliptic boundary value problem on the interval $[0,1]$ with homogeneous Dirichlet boundary conditions,\n$$\n-(a(x)\\,u'(x))' + c(x)\\,u(x) = f(x),\\qquad u(0)=0,\\quad u(1)=0,\n$$\nwhere $a(x)0$ is the diffusion coefficient, $c(x)\\ge 0$ is a reaction coefficient, and $f(x)$ is a given source term. The goal is to construct a conservative, symmetric, and $L^2$-stable finite difference discretization that remains robust when $a(x)$ has a sharp jump. You must use an interface coefficient defined by harmonic averaging to construct the discrete fluxes, and compare its performance to arithmetic averaging on problems with highly varying $a(x)$.\n\nStarting only from fundamental definitions (conservation and consistency of fluxes, symmetry, and positivity of the discrete bilinear form), derive a second-order, conservative finite difference scheme on a uniform grid with $m$ segments (so that the mesh size is $h=1/m$ and the grid points are $x_j=jh$ for $j=0,1,\\dots,m$). The unknowns are the interior nodal values $u_j\\approx u(x_j)$ for $j=1,\\dots,m-1$. For each interior $j$, construct the discrete fluxes across the interfaces at $x_{j\\pm 1/2}$ using\n- the harmonic mean $H(a_j,a_{j+1})=\\dfrac{2\\,a_j\\,a_{j+1}}{a_j+a_{j+1}}$, and\n- the arithmetic mean $A(a_j,a_{j+1})=\\dfrac{a_j+a_{j+1}}{2}$,\nwhere $a_j:=a(x_j)$.\n\nThe test problems to be used must have the form\n- domain $[0,1]$;\n- homogeneous Dirichlet boundary conditions $u(0)=u(1)=0$;\n- reaction coefficient $c(x)=0$;\n- source term $f(x)=1$ (to be interpreted in the unit consistent with the unknown $u$; since this is a purely mathematical problem statement, do not attach physical units);\n- diffusion coefficient $a(x)$ that is piecewise constant with a sharp jump at $x=0.5$,\n$$\na(x) =\n\\begin{cases}\n1,  x0.5,\\\\\n\\alpha,  x\\ge 0.5,\n\\end{cases}\n$$\nwhere $\\alpha0$ is a parameter controlling the jump size.\n\nYour derivation must justify why the harmonic averaging at interfaces yields an $L^2$-stable discrete operator, and must explain what symmetry and positivity (coercivity) mean for the resulting linear system. The derivation must not use shortcut formulas for the final discrete operator; it must proceed from the conservative flux balance and the definitions of the interface coefficients.\n\nImplement both discretizations (harmonic and arithmetic) and, for each, solve the resulting linear system on a uniform grid with $m=200$ segments (so $h=1/200$). For error assessment, use the exact solution obtained by solving the problem piecewise with continuity of $u$ and continuity of the flux $a\\,u'$ at $x=0.5$. Compute the discrete $L^2$-error\n$$\nE = \\left(h\\,\\sum_{j=1}^{m-1} \\left(u_j - u(x_j)\\right)^2\\right)^{1/2},\n$$\nfor both harmonic and arithmetic averaging.\n\nAdditionally, to quantitatively certify $L^2$-stability and symmetry, compute the smallest eigenvalue of the discrete operator for each averaging strategy and report whether it is strictly positive, which implies the matrix is Symmetric Positive Definite (SPD). You must also report the ratio of errors $E_A/E_H$ for each test case.\n\nTest suite:\n- Case $1$: $\\alpha=1$ (no jump).\n- Case $2$: $\\alpha=10^{-3}$ (very small diffusion to the right).\n- Case $3$: $\\alpha=10^{3}$ (very large diffusion to the right).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, output the following five quantities in order:\n- $E_H$: the $L^2$-error for harmonic averaging (a float),\n- $E_A$: the $L^2$-error for arithmetic averaging (a float),\n- $\\mathrm{SPD}_H$: a boolean indicating whether the harmonic-averaging matrix is SPD (true if its smallest eigenvalue is strictly positive),\n- $\\mathrm{SPD}_A$: a boolean indicating whether the arithmetic-averaging matrix is SPD,\n- $R$: the error ratio $E_A/E_H$ (a float).\n\nThus, the final output should aggregate the results for all three cases into a single list of length $15$, ordered as\n$$\n[E_H^{(1)},E_A^{(1)},\\mathrm{SPD}_H^{(1)},\\mathrm{SPD}_A^{(1)},R^{(1)},E_H^{(2)},E_A^{(2)},\\mathrm{SPD}_H^{(2)},\\mathrm{SPD}_A^{(2)},R^{(2)},E_H^{(3)},E_A^{(3)},\\mathrm{SPD}_H^{(3)},\\mathrm{SPD}_A^{(3)},R^{(3)}].\n$$", "solution": "The problem requires the derivation, implementation, and comparison of two finite difference schemes for a one-dimensional elliptic boundary value problem with a discontinuous diffusion coefficient. The validation process, detailed in the thought block, confirms the problem is scientifically sound, well-posed, and complete. We now proceed with the solution.\n\n### Derivation of the Conservative Finite Difference Scheme\n\nWe begin with the given one-dimensional elliptic boundary value problem on the interval $[0,1]$:\n$$\n-(a(x)\\,u'(x))' + c(x)\\,u(x) = f(x), \\quad u(0)=0, \\quad u(1)=0\n$$\nHere, $a(x)0$ is the diffusion coefficient, $c(x)\\ge 0$ is the reaction coefficient, and $f(x)$ is the source term.\n\nWe discretize the domain $[0,1]$ using a uniform grid with $m$ segments, yielding a mesh size of $h=1/m$. The grid points are $x_j = jh$ for $j=0, 1, \\dots, m$. The numerical solution is sought at the interior grid points, denoted by $u_j \\approx u(x_j)$ for $j=1, \\dots, m-1$.\n\nTo derive a conservative scheme, we integrate the differential equation over a control volume $V_j = [x_{j-1/2}, x_{j+1/2}]$ centered at each interior node $x_j$. The width of this volume is $h=x_{j+1/2} - x_{j-1/2}$.\n$$\n\\int_{x_{j-1/2}}^{x_{j+1/2}} \\left( -(a(x)\\,u'(x))' + c(x)\\,u(x) \\right) dx = \\int_{x_{j-1/2}}^{x_{j+1/2}} f(x) dx\n$$\nLet $F(x) = -a(x)u'(x)$ represent the physical flux. Applying the Fundamental Theorem of Calculus to the first term, we obtain the net flux across the control volume boundaries:\n$$\n\\left[ -a(x)u'(x) \\right]_{x_{j-1/2}}^{x_{j+1/2}} + \\int_{x_{j-1/2}}^{x_{j+1/2}} c(x)u(x) dx = \\int_{x_{j-1/2}}^{x_{j+1/2}} f(x) dx\n$$\n$$\nF(x_{j-1/2}) - F(x_{j+1/2}) + \\int_{x_{j-1/2}}^{x_{j+1/2}} c(x)u(x) dx = \\int_{x_{j-1/2}}^{x_{j+1/2}} f(x) dx\n$$\nWe now approximate each term. The integral terms are approximated using the midpoint rule:\n$$\n\\int_{x_{j-1/2}}^{x_{j+1/2}} c(x)u(x) dx \\approx h c(x_j)u(x_j) = h c_j u_j\n$$\n$$\n\\int_{x_{j-1/2}}^{x_{j+1/2}} f(x) dx \\approx h f(x_j) = h f_j\n$$\nThe fluxes at the cell interfaces $x_{j\\pm 1/2}$ are approximated using centered differences for the derivative:\n$$\nF_{j+1/2} = F(x_{j+1/2}) \\approx -a(x_{j+1/2}) \\frac{u(x_{j+1}) - u(x_j)}{h} \\approx -a_{j+1/2} \\frac{u_{j+1} - u_j}{h}\n$$\n$$\nF_{j-1/2} = F(x_{j-1/2}) \\approx -a(x_{j-1/2}) \\frac{u(x_j) - u(x_{j-1})}{h} \\approx -a_{j-1/2} \\frac{u_j - u_{j-1}}{h}\n$$\nThe term $a_{j\\pm 1/2}$ represents the effective diffusion coefficient at the interface. Its definition is crucial when $a(x)$ varies. Substituting these approximations into the integrated equation gives the discrete conservation law at node $j$:\n$$\n-a_{j-1/2} \\frac{u_j - u_{j-1}}{h} - \\left(-a_{j+1/2} \\frac{u_{j+1} - u_j}{h}\\right) + h c_j u_j = h f_j\n$$\nDividing by $h$ and rearranging terms, we obtain the finite difference equation for each interior node $j=1, \\dots, m-1$:\n$$\n\\frac{1}{h^2} \\left[ -a_{j-1/2}u_{j-1} + (a_{j-1/2} + a_{j+1/2})u_j - a_{j+1/2}u_{j+1} \\right] + c_j u_j = f_j\n$$\nThis set of $m-1$ linear equations, together with the boundary conditions $u_0=0$ and $u_m=0$, forms a linear system $K\\mathbf{u} = \\mathbf{f}$.\n\n### Justification of Harmonic Averaging\n\nThe accuracy of the scheme hinges on the choice of the interface coefficient $a_{j+1/2}$. A key physical principle of the continuous problem is the continuity of the flux $F(x) = -a(x)u'(x)$. For a piecewise constant $a(x)$ with a jump at an interface, say $x_{j+1/2}$, this condition must be accurately captured. Assume the flux is approximately constant on the interval $[x_j, x_{j+1}]$, i.e., $-a(x)u'(x) \\approx F_{j+1/2}$. Then $u'(x) \\approx -F_{j+1/2}/a(x)$. Integrating from $x_j$ to $x_{j+1}$:\n$$\nu(x_{j+1}) - u(x_j) = \\int_{x_j}^{x_{j+1}} u'(x) dx \\approx -F_{j+1/2} \\int_{x_j}^{x_{j+1}} \\frac{dx}{a(x)}\n$$\nThis implies that the an accurate numerical flux should satisfy:\n$$\nF_{j+1/2} \\approx -\\frac{u_{j+1} - u_j}{\\int_{x_j}^{x_{j+1}} \\frac{dx}{a(x)}}\n$$\nComparing this with our discrete flux definition $F_{j+1/2} = -a_{j+1/2} \\frac{u_{j+1}-u_j}{h}$, we identify the physically correct effective diffusion coefficient as:\n$$\na_{j+1/2} = \\frac{h}{\\int_{x_j}^{x_{j+1}} \\frac{dx}{a(x)}}\n$$\nThis is the integrated harmonic mean of $a(x)$ over the interval. If we assume $a(x)$ is piecewise constant with a jump precisely at the interface $x_{j+1/2}$, taking values $a_j=a(x_j)$ on $[x_j, x_{j+1/2}]$ and $a_{j+1}=a(x_{j+1})$ on $[x_{j+1/2}, x_{j+1}]$, the integral becomes:\n$$\n\\int_{x_j}^{x_{j+1}} \\frac{dx}{a(x)} = \\frac{h/2}{a_j} + \\frac{h/2}{a_{j+1}} = \\frac{h}{2}\\left(\\frac{1}{a_j} + \\frac{1}{a_{j+1}}\\right)\n$$\nSubstituting this back gives the interface coefficient:\n$$\na_{j+1/2} = \\frac{h}{\\frac{h}{2}\\left(\\frac{a_j+a_{j+1}}{a_j a_{j+1}}\\right)} = \\frac{2 a_j a_{j+1}}{a_j+a_{j+1}}\n$$\nThis is precisely the harmonic mean $H(a_j, a_{j+1})$. This derivation shows that using the harmonic mean for the interface coefficient correctly models the continuous flux condition for piecewise constant coefficients. The arithmetic mean, $A(a_j, a_{j+1}) = (a_j+a_{j+1})/2$, does not possess this property and is known to produce large errors at sharp jumps.\n\n### Matrix Properties: Symmetry and Positive Definiteness ($L^2$-stability)\n\nThe system of equations can be written as $K\\mathbf{u}=\\mathbf{f}$, where $\\mathbf{u}=[u_1, \\dots, u_{m-1}]^T$. The matrix $K$ is tridiagonal. The entries for row $i$ (representing unknown $u_i$) and column $j$ are denoted by $K_{ij}$. For $i=1, \\dots, m-1$:\n- Main diagonal: $K_{ii} = \\frac{1}{h^2}(a_{i-1/2} + a_{i+1/2}) + c_i$\n- Off-diagonals: $K_{i, i-1} = -\\frac{1}{h^2}a_{i-1/2}$ and $K_{i, i+1} = -\\frac{1}{h^2}a_{i+1/2}$\n\n**Symmetry**: The matrix $K$ is symmetric because $K_{i,i+1} = -\\frac{1}{h^2}a_{i+1/2}$ and $K_{i+1,i} = -\\frac{1}{h^2}a_{(i+1)-1/2} = -\\frac{1}{h^2}a_{i+1/2}$, so $K_{i,i+1}=K_{i+1,i}$. This holds for any definition of $a_{i+1/2}$.\n\n**Positive Definiteness**: A symmetric matrix is positive definite if the quadratic form $\\mathbf{v}^T K \\mathbf{v}  0$ for any non-zero vector $\\mathbf{v}$. This property ensures that the matrix is invertible and implies stability of the numerical scheme. Let $\\mathbf{u}$ be the vector of nodal values with $u_0=u_m=0$. The quadratic form is:\n$$\n\\mathbf{u}^T K \\mathbf{u} = \\sum_{j=1}^{m-1} u_j \\left( \\frac{1}{h^2} \\left[ -a_{j-1/2}u_{j-1} + (a_{j-1/2} + a_{j+1/2})u_j - a_{j+1/2}u_{j+1} \\right] + c_j u_j \\right)\n$$\nThrough summation by parts, this can be rearranged into the discrete \"energy\":\n$$\n\\mathbf{u}^T K \\mathbf{u} = \\frac{1}{h^2} \\sum_{j=0}^{m-1} a_{j+1/2} (u_{j+1}-u_j)^2 + \\sum_{j=1}^{m-1} c_j u_j^2\n$$\nSince $c(x) \\ge 0$, the second term is non-negative. For the first term to be positive, we require $a_{j+1/2}  0$. Since $a(x)0$, both harmonic and arithmetic means of positive values are positive. The sum $\\sum_{j=0}^{m-1} a_{j+1/2} (u_{j+1}-u_j)^2$ is zero if and only if $u_{j+1}-u_j=0$ for all $j$, which implies $u_0=u_1=\\dots=u_m$. The boundary condition $u_0=0$ then forces all $u_j=0$, meaning $\\mathbf{u}=\\mathbf{0}$. Therefore, for any non-zero vector $\\mathbf{u}$, we have $\\mathbf{u}^T K \\mathbf{u}  0$. Both schemes produce a Symmetric Positive Definite (SPD) matrix, which guarantees a unique solution and provides $L^2$-stability. The smallest eigenvalue of an SPD matrix is strictly positive.\n\n### Exact Solution for the Test Problem\n\nThe test problem is $-(a(x)u'(x))' = 1$ with $u(0)=u(1)=0$, $c(x)=0$, and $a(x)$ defined as:\n$$\na(x) = \\begin{cases} 1,  x0.5 \\\\ \\alpha,  x\\ge 0.5 \\end{cases}\n$$\nLet $x^*=0.5$. We solve the ODE piecewise.\nFor $x \\in [0, x^*)$: $-u_1''(x)=1 \\implies u_1(x) = -x^2/2 + C_1 x + C_2$.\nFor $x \\in (x^*, 1]$: $-\\alpha u_2''(x)=1 \\implies u_2(x) = -x^2/(2\\alpha) + C_3 x + C_4$.\n\nThe four unknown constants are determined by four conditions:\n1. Boundary condition $u_1(0)=0 \\implies C_2=0$.\n2. Boundary condition $u_2(1)=0 \\implies -1/(2\\alpha) + C_3 + C_4 = 0$.\n3. Continuity of solution $u_1(x^*) = u_2(x^*)$.\n4. Continuity of flux $1 \\cdot u_1'(x^*) = \\alpha \\cdot u_2'(x^*)$.\n\nFrom flux continuity, we find $-x^*+C_1 = \\alpha(-x^*/\\alpha+C_3)$, which simplifies to $C_1 = \\alpha C_3$.\nSolving the system of linear equations for $C_1, C_3, C_4$ with $x^*=0.5$ yields:\n$$\nC_1 = \\frac{\\alpha+3}{4(\\alpha+1)}, \\quad C_3 = \\frac{\\alpha+3}{4\\alpha(\\alpha+1)}, \\quad C_4 = \\frac{\\alpha-1}{4\\alpha(\\alpha+1)}\n$$\nThe exact solution is therefore:\n$$\nu(x) =\n\\begin{cases}\n-\\dfrac{x^2}{2} + \\dfrac{\\alpha+3}{4(\\alpha+1)}\\,x,  x  0.5 \\\\\n-\\dfrac{x^2}{2\\alpha} + \\dfrac{\\alpha+3}{4\\alpha(\\alpha+1)}\\,x + \\dfrac{\\alpha-1}{4\\alpha(\\alpha+1)},  x \\ge 0.5\n\\end{cases}\n$$\nThis solution is used to assess the accuracy of the numerical schemes.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_banded, eigvalsh_tridiagonal\n\ndef build_and_solve(m, alpha, averaging_method):\n    \"\"\"\n    Builds and solves the finite difference system for a given averaging method.\n\n    Args:\n        m (int): Number of grid segments.\n        alpha (float): Jump parameter for the diffusion coefficient.\n        averaging_method (str): 'harmonic' or 'arithmetic'.\n\n    Returns:\n        tuple: A tuple containing:\n            - np.ndarray: The numerical solution vector at interior nodes.\n            - bool: True if the resulting matrix is Symmetric Positive Definite.\n    \"\"\"\n    h = 1.0 / m\n    N = m - 1  # Number of interior unknowns\n\n    # Define diffusion coefficient a(x) at grid points x_j\n    a_vals = np.ones(m + 1)\n    jump_index = m // 2\n    a_vals[jump_index:] = alpha\n\n    # Construct interface coefficients a_{j+1/2}\n    a_half = np.zeros(m)  # a_half[j] corresponds to a_{j+1/2}\n    for j in range(m):\n        a_left = a_vals[j]\n        a_right = a_vals[j+1]\n        \n        if averaging_method == 'harmonic':\n            if a_left + a_right == 0.0:\n                 a_half[j] = 0.0\n            else:\n                 a_half[j] = 2.0 * a_left * a_right / (a_left + a_right)\n        elif averaging_method == 'arithmetic':\n            a_half[j] = 0.5 * (a_left + a_right)\n        else:\n            raise ValueError(\"Unknown averaging method\")\n\n    # Construct the tridiagonal matrix A such that A*u = h^2 * f\n    # The matrix K in the derivation is A/h^2.\n    # d: main diagonal, e: off-diagonal (for a symmetric tridiagonal matrix)\n    # The matrix size is N x N, where N = m-1.\n    # The i-th row (0-indexed) corresponds to unknown u_{i+1}.\n    # d[i] = a_{i+1/2} + a_{i+3/2}\n    # e[i] = -a_{i+3/2}\n    d = a_half[:-1] + a_half[1:]  # Main diagonal, size N\n    e = -a_half[1:-1]            # Off-diagonal, size N-1\n\n    # Right-hand side vector\n    b = h**2 * np.ones(N)\n    \n    # Use scipy's efficient banded solver.\n    # The matrix must be in a specific format for solve_banded.\n    # For a symmetric tridiagonal matrix (l=1, u=1), shape is (3, N)\n    ab = np.zeros((3, N))\n    ab[0, 1:] = e   # Super-diagonal\n    ab[1, :] = d    # Main diagonal\n    ab[2, :-1] = e  # Sub-diagonal\n    \n    u_num = solve_banded((1, 1), ab, b)\n    \n    # Compute the smallest eigenvalue to check for SPD property.\n    # eigvalsh_tridiagonal is efficient for this.\n    # A matrix is SPD if and only if all its eigenvalues are strictly positive.\n    min_eig = eigvalsh_tridiagonal(d, e, select='i', select_range=(0, 0))[0]\n    is_spd = min_eig > 0\n\n    return u_num, is_spd\n\ndef exact_solution(x_vals, alpha):\n    \"\"\"\n    Computes the exact solution of the BVP for a given alpha.\n    \"\"\"\n    # Integration constants from the derivation\n    c1 = (alpha + 3.0) / (4.0 * (alpha + 1.0))\n    c3 = (alpha + 3.0) / (4.0 * alpha * (alpha + 1.0))\n    c4 = (alpha - 1.0) / (4.0 * alpha * (alpha + 1.0))\n\n    sol = np.zeros_like(x_vals, dtype=float)\n    mask_left = x_vals  0.5\n    \n    # Function for x  0.5\n    sol[mask_left] = -0.5 * x_vals[mask_left]**2 + c1 * x_vals[mask_left]\n    # Function for x >= 0.5\n    sol[~mask_left] = -0.5 * x_vals[~mask_left]**2 / alpha + c3 * x_vals[~mask_left] + c4\n    \n    return sol\n\ndef compute_l2_error(h, u_num, u_exact_vals):\n    \"\"\"\n    Computes the discrete L2 error.\n    \"\"\"\n    return np.sqrt(h * np.sum((u_num - u_exact_vals)**2))\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        1.0,        # Case 1: alpha = 1 (no jump)\n        1e-3,       # Case 2: alpha = 10^-3\n        1e3,        # Case 3: alpha = 10^3\n    ]\n\n    results = []\n    m = 200\n    h = 1.0 / m\n    x_interior = np.linspace(0, 1, m + 1)[1:-1]\n    \n    for alpha in test_cases:\n        # Evaluate exact solution at interior grid points\n        u_exact_vals = exact_solution(x_interior, alpha)\n\n        # Harmonic averaging solution\n        u_h, spd_h = build_and_solve(m, alpha, 'harmonic')\n        E_H = compute_l2_error(h, u_h, u_exact_vals)\n\n        # Arithmetic averaging solution\n        u_a, spd_a = build_and_solve(m, alpha, 'arithmetic')\n        E_A = compute_l2_error(h, u_a, u_exact_vals)\n        \n        # Calculate the error ratio\n        if E_H == 0:\n            ratio = np.inf if E_A > 0 else 1.0\n        else:\n            ratio = E_A / E_H\n        \n        results.extend([\n            E_H,\n            E_A,\n            str(spd_h).lower(),\n            str(spd_a).lower(),\n            ratio\n        ])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3392861"}, {"introduction": "While forward problems compute a system's response from known properties, inverse problems seek to determine unknown properties from observed responses. This advanced practice introduces the core concepts of parameter identification by tasking you with recovering an unknown diffusion coefficient from simulated measurements [@problem_id:3392786]. You will use the powerful discrete adjoint method to derive the necessary sensitivity information, providing a foundational understanding of how numerical models can be used to interpret experimental data.", "problem": "Consider the one-dimensional elliptic partial differential equation (PDE) $-(a(x) u^{\\prime}(x))^{\\prime} = f(x)$ on the interval $[0,1]$ with Dirichlet boundary conditions $u(0) = g_0$ and $u(1) = g_1$. Assume that the diffusion coefficient $a(x)$ is piecewise constant with two unknown parameters: $a(x) = a_1$ on $[0,\\tfrac{1}{2}]$ and $a(x) = a_2$ on $[\\tfrac{1}{2},1]$, where $a_1  0$ and $a_2  0$.\n\nDiscretize the PDE using a uniform grid with nodes $x_0 = 0$, $x_1 = \\tfrac{1}{2}$, and $x_2 = 1$ (mesh size $h = \\tfrac{1}{2}$). Use the conservative second-order finite difference method (FDM) at the interior node $x_1$, with interface coefficients $a_{1/2} = a_1$ and $a_{3/2} = a_2$, to obtain the single interior equation relating $u_1 \\approx u(x_1)$ to the boundary data $u_0 = g_0$ and $u_2 = g_1$ and the cell-centered source $f_1 \\approx f(x_1)$.\n\nYou are to pose and analyze an inverse problem to recover the parameters $a_1$ and $a_2$ from discrete measurements of the interior state $u_1$ under multiple experiments. Proceed as follows:\n\n1. Derive the discrete forward equation at $x_1$ starting from the conservative difference approximation of $-(a u^{\\prime})^{\\prime} = f$. Express the result explicitly in terms of $a_1$, $a_2$, $u_0$, $u_1$, $u_2$, and $f_1$.\n\n2. Consider two independent experiments $k \\in \\{1,2\\}$ with distinct boundary data and source:\n   - Experiment $k=1$: $g_0^{(1)} = 0$, $g_1^{(1)} = 1$, $f_1^{(1)} = 0$.\n   - Experiment $k=2$: $g_0^{(2)} = 1$, $g_1^{(2)} = 0$, $f_1^{(2)} = 1$.\n   For each experiment, the measurement is the interior value $y^{(k)}(a_1,a_2) = u_1^{(k)}(a_1,a_2)$.\n\n3. Define the least-squares objective over the two experiments $\\Phi(a_1,a_2) = \\tfrac{1}{2} \\sum_{k=1}^{2} \\left( y^{(k)}(a_1,a_2) - d^{(k)} \\right)^2$ for given data $d^{(k)}$. Derive the Jacobian matrix $\\mathbf{J} \\in \\mathbb{R}^{2 \\times 2}$ with entries $J_{kj} = \\partial y^{(k)} / \\partial a_j$ using a discrete adjoint formulation based on the linearized discrete forward map. Your derivation must start from the discrete forward equation and use the adjoint equation corresponding to the output functional $y^{(k)} = P u^{(k)}$ with $P$ extracting the interior value.\n\n4. Using your Jacobian, form the $2 \\times 2$ Gram matrix $\\mathbf{G} = \\mathbf{J}^{\\top} \\mathbf{J}$ and compute its determinant $\\det(\\mathbf{G})$ as a closed-form analytic expression in terms of $a_1$ and $a_2$ for the two experiments specified above.\n\n5. Briefly discuss, based on your Jacobian structure, how the identifiability of $(a_1,a_2)$ depends on the choice of boundary data and source terms, contrasting the given two-experiment setup with the special case of using only Dirichlet boundary variations with zero source.\n\nYour final answer must be the analytic expression for $\\det(\\mathbf{G})$ in terms of $a_1$ and $a_2$. Do not include units. Do not approximate; an exact expression is required.", "solution": "The problem is assessed to be valid as it is scientifically grounded, well-posed, objective, and contains all necessary information for a rigorous solution. We proceed with the derivation as requested.\n\nThe one-dimensional elliptic boundary value problem is given by\n$$ -(a(x) u'(x))' = f(x) \\quad \\text{for } x \\in [0,1] $$\nwith Dirichlet boundary conditions $u(0) = g_0$ and $u(1) = g_1$. The coefficient $a(x)$ is piecewise constant: $a(x) = a_1$ for $x \\in [0, \\frac{1}{2}]$ and $a(x) = a_2$ for $x \\in [\\frac{1}{2}, 1]$, with $a_1  0$ and $a_2  0$.\n\nWe use a uniform grid with nodes $x_0=0$, $x_1=\\frac{1}{2}$, and $x_2=1$. The mesh size is $h = x_{i+1} - x_i = \\frac{1}{2}$. There is a single interior node at $x_1 = \\frac{1}{2}$.\n\n1. Derivation of the discrete forward equation.\nA conservative finite difference discretization at an interior node $x_i$ is given by\n$$ -\\frac{1}{h} \\left( F_{i+1/2} - F_{i-1/2} \\right) = f_i $$\nwhere $F = -a(x)u'(x)$ is the flux. The fluxes at the cell faces are approximated as $F_{i \\pm 1/2} \\approx -a_{i \\pm 1/2} \\frac{u_{i \\pm 1} - u_i}{h}$. Applying this at the interior node $x_1$ gives:\n$$ -\\frac{1}{h} \\left( \\left( -a_{3/2} \\frac{u_2 - u_1}{h} \\right) - \\left( -a_{1/2} \\frac{u_1 - u_0}{h} \\right) \\right) = f_1 $$\nSubstituting the given interface coefficients $a_{1/2} = a_1$ and $a_{3/2} = a_2$, we have:\n$$ \\frac{1}{h^2} \\left( a_{3/2} (u_2 - u_1) - a_{1/2} (u_1 - u_0) \\right) = f_1 $$\n$$ \\frac{1}{h^2} \\left( a_2 (u_2 - u_1) - a_1 (u_1 - u_0) \\right) = f_1 $$\nWith $h=\\frac{1}{2}$, $h^2 = \\frac{1}{4}$. The boundary values are $u_0 = g_0$ and $u_2 = g_1$. Let $u_1$ be the discrete approximation of $u(x_1)$. The equation becomes:\n$$ 4 \\left( a_2 (g_1 - u_1) - a_1 (u_1 - g_0) \\right) = f_1 $$\nRearranging the terms to solve for $u_1$:\n$$ 4 (a_2 g_1 - a_2 u_1 - a_1 u_1 + a_1 g_0) = f_1 $$\n$$ -4(a_1 + a_2) u_1 + 4(a_1 g_0 + a_2 g_1) = f_1 $$\nThis gives the discrete forward equation for the single unknown $u_1$:\n$$ 4(a_1 + a_2) u_1 = 4(a_1 g_0 + a_2 g_1) + f_1 $$\nThe problem defines the source term in the original PDE as being on the right-hand side, so we will use the formulation $-(a u')' = f$. The finite difference equation is written as $-D(u) = f_1$, where $D(u)$ is the discrete operator. The equation is thus $4(a_1+a_2)u_1 - 4(a_1 g_0 + a_2 g_1) = -f_1$. Solving for $u_1$:\n$$ u_1 = \\frac{4(a_1 g_0 + a_2 g_1) - f_1}{4(a_1 + a_2)} $$\nWait, the problem text says $-(a(x) u^{\\prime}(x))^{\\prime} = f(x)$, so $f$ is the right-hand side. My initial derivation `4(a_1 + a_2) u_1 = 4(a_1 g_0 + a_2 g_1) + f_1` was correct. Let's re-verify. `-(au')'` becomes `-1/h * (F_{i+1/2} - F_{i-1/2})`, where `F_{i+1/2} = -a_{i+1/2} * (u_{i+1}-u_i)/h`.\nSo `-1/h * (-a_{i+1/2}(u_{i+1}-u_i)/h - (-a_{i-1/2}(u_i-u_{i-1})/h)) = f_i`.\n`1/h^2 * (a_{i+1/2}(u_{i+1}-u_i) - a_{i-1/2}(u_{i-1}-u_i)) = f_i`. No, that's wrong.\n`1/h^2 * (a_{i+1/2}(u_{i+1}-u_i) + a_{i-1/2}(u_i-u_{i-1})) = f_i`.\n`1/h^2 * (-a_{i-1/2}u_{i-1} + (a_{i-1/2}+a_{i+1/2})u_i - a_{i+1/2}u_{i+1}) = f_i`.\nFor our case: `4*(-a_1 u_0 + (a_1+a_2)u_1 - a_2 u_2) = f_1`.\nSo `4(a_1+a_2)u_1 = 4(a_1 g_0 + a_2 g_1) + f_1`. This is correct. The text in the solution is a bit confusing but the resulting formula for $u_1$ is correct.\n$$ u_1 = \\frac{4(a_1 g_0 + a_2 g_1) + f_1}{4(a_1 + a_2)} $$\n\n2. Forward solutions for the two experiments.\nThe measurement in each experiment $k$ is $y^{(k)}(a_1, a_2) = u_1^{(k)}(a_1, a_2)$.\nFor experiment $k=1$: $g_0^{(1)} = 0$, $g_1^{(1)} = 1$, $f_1^{(1)} = 0$.\n$$ y^{(1)}(a_1, a_2) = \\frac{4(a_1 \\cdot 0 + a_2 \\cdot 1) + 0}{4(a_1 + a_2)} = \\frac{4a_2}{4(a_1 + a_2)} = \\frac{a_2}{a_1 + a_2} $$\nFor experiment $k=2$: $g_0^{(2)} = 1$, $g_1^{(2)} = 0$, $f_1^{(2)} = 1$.\n$$ y^{(2)}(a_1, a_2) = \\frac{4(a_1 \\cdot 1 + a_2 \\cdot 0) + 1}{4(a_1 + a_2)} = \\frac{4a_1 + 1}{4(a_1 + a_2)} $$\n\n3. Derivation of the Jacobian via the discrete adjoint method.\nLet the parameter vector be $\\mathbf{a} = (a_1, a_2)^T$. For each experiment, the discrete forward equation can be written as a residual equation $R(u_1, \\mathbf{a}) = 0$. For a generic experiment with data $(g_0, g_1, f_1)$, this is:\n$$ R(u_1, a_1, a_2) = 4(a_1 + a_2) u_1 - 4(a_1 g_0 + a_2 g_1) - f_1 = 0 $$\nThe quantity of interest (the measurement) is a linear functional of the state, $y = P u_1 = u_1$. To find the sensitivity $\\frac{\\partial y}{\\partial a_j}$, we differentiate $R=0$ with respect to $a_j$:\n$$ \\frac{\\partial R}{\\partial u_1} \\frac{\\partial u_1}{\\partial a_j} + \\frac{\\partial R}{\\partial a_j} = 0 \\implies \\frac{\\partial u_1}{\\partial a_j} = - \\left( \\frac{\\partial R}{\\partial u_1} \\right)^{-1} \\frac{\\partial R}{\\partial a_j} $$\nThe adjoint method provides an efficient way to compute this. The adjoint state $p$ is the solution to the adjoint equation:\n$$ \\left( \\frac{\\partial R}{\\partial u_1} \\right)^* p = \\left( \\frac{\\partial y}{\\partial u_1} \\right)^* $$\nSince our state $u_1$ and output $y$ are scalars, this simplifies to $\\frac{\\partial R}{\\partial u_1} p = \\frac{\\partial y}{\\partial u_1}$.\nWe have $\\frac{\\partial R}{\\partial u_1} = 4(a_1 + a_2)$ and $\\frac{\\partial y}{\\partial u_1} = \\frac{\\partial u_1}{\\partial u_1} = 1$.\nThe adjoint equation is $4(a_1 + a_2) p = 1$, so the adjoint state is $p = \\frac{1}{4(a_1 + a_2)}$.\nThe sensitivity is then given by $\\frac{\\partial y}{\\partial a_j} = - p \\frac{\\partial R}{\\partial a_j}$. We compute the partials of $R$ with respect to the parameters $a_1$ and $a_2$:\n$$ \\frac{\\partial R}{\\partial a_1} = 4u_1 - 4g_0 = 4(u_1 - g_0) $$\n$$ \\frac{\\partial R}{\\partial a_2} = 4u_1 - 4g_1 = 4(u_1 - g_1) $$\nSo, the sensitivities are:\n$$ \\frac{\\partial y}{\\partial a_1} = -p \\cdot 4(u_1 - g_0) = -\\frac{1}{4(a_1+a_2)} \\cdot 4(u_1 - g_0) = -\\frac{u_1 - g_0}{a_1 + a_2} $$\n$$ \\frac{\\partial y}{\\partial a_2} = -p \\cdot 4(u_1 - g_1) = -\\frac{1}{4(a_1+a_2)} \\cdot 4(u_1 - g_1) = -\\frac{u_1 - g_1}{a_1 + a_2} $$\nThe Jacobian matrix $\\mathbf{J}$ has entries $J_{kj} = \\partial y^{(k)} / \\partial a_j$.\nFor experiment $k=1$: $u_1^{(1)} = \\frac{a_2}{a_1+a_2}$, $g_0^{(1)}=0$, $g_1^{(1)}=1$.\n$$ J_{11} = -\\frac{\\frac{a_2}{a_1+a_2} - 0}{a_1+a_2} = -\\frac{a_2}{(a_1+a_2)^2} $$\n$$ J_{12} = -\\frac{\\frac{a_2}{a_1+a_2} - 1}{a_1+a_2} = -\\frac{a_2 - (a_1+a_2)}{(a_1+a_2)^2} = -\\frac{-a_1}{(a_1+a_2)^2} = \\frac{a_1}{(a_1+a_2)^2} $$\nFor experiment $k=2$: $u_1^{(2)} = \\frac{4a_1+1}{4(a_1+a_2)}$, $g_0^{(2)}=1$, $g_1^{(2)}=0$.\n$$ J_{21} = -\\frac{\\frac{4a_1+1}{4(a_1+a_2)} - 1}{a_1+a_2} = -\\frac{4a_1+1 - 4(a_1+a_2)}{4(a_1+a_2)^2} = -\\frac{1-4a_2}{4(a_1+a_2)^2} = \\frac{4a_2 - 1}{4(a_1+a_2)^2} $$\n$$ J_{22} = -\\frac{\\frac{4a_1+1}{4(a_1+a_2)} - 0}{a_1+a_2} = -\\frac{4a_1+1}{4(a_1+a_2)^2} $$\nThe Jacobian matrix is:\n$$ \\mathbf{J} = \\begin{pmatrix} -\\frac{a_2}{(a_1+a_2)^2}  \\frac{a_1}{(a_1+a_2)^2} \\\\ \\frac{4a_2-1}{4(a_1+a_2)^2}  -\\frac{4a_1+1}{4(a_1+a_2)^2} \\end{pmatrix} $$\n\n4. Computation of the determinant of the Gram matrix.\nThe Gram matrix is $\\mathbf{G} = \\mathbf{J}^T \\mathbf{J}$. Its determinant is $\\det(\\mathbf{G}) = \\det(\\mathbf{J}^T)\\det(\\mathbf{J}) = (\\det(\\mathbf{J}))^2$. We compute the determinant of $\\mathbf{J}$:\n$$ \\det(\\mathbf{J}) = J_{11}J_{22} - J_{12}J_{21} $$\n$$ \\det(\\mathbf{J}) = \\left(-\\frac{a_2}{(a_1+a_2)^2}\\right) \\left(-\\frac{4a_1+1}{4(a_1+a_2)^2}\\right) - \\left(\\frac{a_1}{(a_1+a_2)^2}\\right) \\left(\\frac{4a_2-1}{4(a_1+a_2)^2}\\right) $$\n$$ \\det(\\mathbf{J}) = \\frac{1}{4(a_1+a_2)^4} \\left( a_2(4a_1+1) - a_1(4a_2-1) \\right) $$\n$$ \\det(\\mathbf{J}) = \\frac{1}{4(a_1+a_2)^4} \\left( 4a_1a_2 + a_2 - 4a_1a_2 + a_1 \\right) $$\n$$ \\det(\\mathbf{J}) = \\frac{a_1+a_2}{4(a_1+a_2)^4} = \\frac{1}{4(a_1+a_2)^3} $$\nThe determinant of the Gram matrix is therefore:\n$$ \\det(\\mathbf{G}) = (\\det(\\mathbf{J}))^2 = \\left( \\frac{1}{4(a_1+a_2)^3} \\right)^2 = \\frac{1}{16(a_1+a_2)^6} $$\n\n5. Discussion on identifiability.\nThe parameters $(a_1, a_2)$ are locally identifiable if the Jacobian matrix $\\mathbf{J}$ is of full rank, which is equivalent to $\\det(\\mathbf{J}) \\neq 0$ or, equivalently, $\\det(\\mathbf{G})  0$. For the two specified experiments, $\\det(\\mathbf{G}) = \\frac{1}{16(a_1+a_2)^6}$. Since the problem states $a_1  0$ and $a_2  0$, it follows that $a_1+a_2  0$, and thus $\\det(\\mathbf{G})$ is strictly positive. This implies that the columns of $\\mathbf{J}$ are linearly independent, and the parameters $(a_1, a_2)$ are locally identifiable.\n\nContrast this with the special case of using only experiments with zero source term, i.e., $f_1=0$. In this case, the forward solution for an experiment with boundary data $(g_0, g_1)$ is $y = \\frac{a_1 g_0 + a_2 g_1}{a_1 + a_2}$. The sensitivity vector (a row of the Jacobian) can be computed as:\n$$ \\frac{\\partial y}{\\partial a_1} = \\frac{g_0(a_1+a_2) - (a_1g_0+a_2g_1)}{(a_1+a_2)^2} = \\frac{a_2(g_0-g_1)}{(a_1+a_2)^2} $$\n$$ \\frac{\\partial y}{\\partial a_2} = \\frac{g_1(a_1+a_2) - (a_1g_0+a_2g_1)}{(a_1+a_2)^2} = \\frac{a_1(g_1-g_0)}{(a_1+a_2)^2} $$\nThe sensitivity vector is $(\\frac{\\partial y}{\\partial a_1}, \\frac{\\partial y}{\\partial a_2}) = \\frac{g_0-g_1}{(a_1+a_2)^2} (a_2, -a_1)$.\nIf we perform two such experiments, one with data $(g_0^{(1)}, g_1^{(1)})$ and another with $(g_0^{(2)}, g_1^{(2)})$, the two rows of the Jacobian will be:\n$$ \\text{Row 1: } \\frac{g_0^{(1)}-g_1^{(1)}}{(a_1+a_2)^2} (a_2, -a_1) $$\n$$ \\text{Row 2: } \\frac{g_0^{(2)}-g_1^{(2)}}{(a_1+a_2)^2} (a_2, -a_1) $$\nThese two rows are scalar multiples of each other. Consequently, the Jacobian has rank $1$ (assuming at least one $g_0 \\neq g_1$) and its determinant is zero. Thus, $\\det(\\mathbf{G})=0$, and the parameters $(a_1, a_2)$ are not identifiable. Physically, when $f=0$, the measurement $y = u_1$ only depends on the ratio $a_1/a_2$, not on $a_1$ and $a_2$ individually. The inclusion of an experiment with a non-zero source term, like experiment $k=2$ in the problem setup, introduces a different source of variation in the measured data, making the sensitivity vectors linearly independent and enabling the identification of both parameters.", "answer": "$$\\boxed{\\frac{1}{16(a_1+a_2)^{6}}}$$", "id": "3392786"}]}