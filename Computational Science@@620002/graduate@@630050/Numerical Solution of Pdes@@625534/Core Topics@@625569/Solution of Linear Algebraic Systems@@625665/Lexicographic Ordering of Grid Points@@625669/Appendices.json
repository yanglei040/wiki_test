{"hands_on_practices": [{"introduction": "The choice of how to number the grid points in a computational domain may seem like a trivial implementation detail, but it has profound algebraic consequences. Every distinct ordering corresponds to a different basis for the vector space of unknowns, and the system matrix transforms accordingly. This exercise provides a concrete, first-principles exploration of this transformation by having you explicitly construct the permutation matrix that relates two common lexicographic orderings and verify the resulting similarity transform on the discrete Laplacian matrix [@problem_id:3415894]. Mastering this connection is the foundational step to understanding the deeper impacts of grid ordering.", "problem": "Consider the discrete five-point Laplacian arising from a uniform finite-difference discretization of the scalar partial differential equation (PDE) $-\\Delta u = f$ on a rectangular domain with homogeneous Dirichlet boundary conditions. Let the interior grid consist of $N_x=3$ points in the $x$-direction and $N_y=2$ points in the $y$-direction, with unit mesh spacings $h_x=h_y=1$. Index the interior grid points by coordinates $(i,j)$ with $i\\in\\{1,2,3\\}$ and $j\\in\\{1,2\\}$.\n\nDefine two lexicographic orderings of the grid points:\n- An $x$-fast (row-wise) ordering $\\mathcal{R}$ with linear index $k_{\\mathcal{R}}(i,j) = i + (j-1)N_x$.\n- A $y$-fast (column-wise) ordering $\\mathcal{C}$ with linear index $k_{\\mathcal{C}}(i,j) = j + (i-1)N_y$.\n\nLet $\\boldsymbol{u}_{\\mathcal{R}}\\in\\mathbb{R}^{N}$ and $\\boldsymbol{u}_{\\mathcal{C}}\\in\\mathbb{R}^{N}$, with $N=N_x N_y=6$, denote the vectors of nodal unknowns arranged according to $\\mathcal{R}$ and $\\mathcal{C}$, respectively. Let $A\\in\\mathbb{R}^{N\\times N}$ be the stiffness matrix of the five-point Laplacian assembled under $\\mathcal{R}$, and let $A'\\in\\mathbb{R}^{N\\times N}$ be the stiffness matrix assembled under $\\mathcal{C}$. The five-point stencil at an interior point $(i,j)$ is the linear combination $4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1}$, with absent neighbors across the boundary treated via homogeneous Dirichlet data.\n\nLet $\\{ \\boldsymbol{e}_k \\}_{k=1}^{N}$ denote the standard basis of $\\mathbb{R}^{N}$.\n\nTasks:\n1. Construct explicitly the permutation matrix $P\\in\\mathbb{R}^{N\\times N}$ that maps the $y$-fast ordering $\\mathcal{C}$ to the $x$-fast ordering $\\mathcal{R}$, so that $\\boldsymbol{u}_{\\mathcal{R}} = P\\,\\boldsymbol{u}_{\\mathcal{C}}$. Write $P$ in terms of the standard basis vectors as a concatenation of columns and also as a sum of rank-one outer products.\n2. Assemble $A$ explicitly under $\\mathcal{R}$ and $A'$ explicitly under $\\mathcal{C}$ by enumerating the neighbor couplings implied by the five-point stencil.\n3. Verify by explicit matrix multiplication that $A' = P^{\\top} A P$.\n4. Let $S = \\|A' - P^{\\top} A P\\|_{F}^{2}$, where $\\|\\cdot\\|_{F}$ denotes the Frobenius norm. Report the exact value of $S$. No rounding is required.\n\nYour final answer must be the single real number $S$.", "solution": "The solution proceeds in four parts as requested by the problem statement.\n\n**1. Construct the Permutation Matrix P**\n\nFirst, we map the six interior grid points $(i,j)$ with $i \\in \\{1,2,3\\}, j \\in \\{1,2\\}$ to their linear indices under both orderings.\n\n*   **Ordering $\\mathcal{R}$ (x-fast):** $k_{\\mathcal{R}}(i,j) = i + (j-1)N_x = i + 3(j-1)$\n    *   $k_{\\mathcal{R}}(1,1) = 1$\n    *   $k_{\\mathcal{R}}(2,1) = 2$\n    *   $k_{\\mathcal{R}}(3,1) = 3$\n    *   $k_{\\mathcal{R}}(1,2) = 4$\n    *   $k_{\\mathcal{R}}(2,2) = 5$\n    *   $k_{\\mathcal{R}}(3,2) = 6$\n    The vector of unknowns is $\\boldsymbol{u}_{\\mathcal{R}} = [u_{1,1}, u_{2,1}, u_{3,1}, u_{1,2}, u_{2,2}, u_{3,2}]^\\top$.\n\n*   **Ordering $\\mathcal{C}$ (y-fast):** $k_{\\mathcal{C}}(i,j) = j + (i-1)N_y = j + 2(i-1)$\n    *   $k_{\\mathcal{C}}(1,1) = 1$\n    *   $k_{\\mathcal{C}}(1,2) = 2$\n    *   $k_{\\mathcal{C}}(2,1) = 3$\n    *   $k_{\\mathcal{C}}(2,2) = 4$\n    *   $k_{\\mathcal{C}}(3,1) = 5$\n    *   $k_{\\mathcal{C}}(3,2) = 6$\n    The vector of unknowns is $\\boldsymbol{u}_{\\mathcal{C}} = [u_{1,1}, u_{1,2}, u_{2,1}, u_{2,2}, u_{3,1}, u_{3,2}]^\\top$.\n\nThe permutation matrix $P$ transforms $\\boldsymbol{u}_{\\mathcal{C}}$ to $\\boldsymbol{u}_{\\mathcal{R}}$: $\\boldsymbol{u}_{\\mathcal{R}} = P\\boldsymbol{u}_{\\mathcal{C}}$. The $j$-th column of $P$ is the standard basis vector $\\boldsymbol{e}_k$ where $k$ is the position of the $j$-th element of $\\boldsymbol{u}_{\\mathcal{C}}$ within the vector $\\boldsymbol{u}_{\\mathcal{R}}$.\n*   $u_{1,1}$ is 1st in $\\mathcal{C}$, 1st in $\\mathcal{R}$. Column 1 is $\\boldsymbol{e}_1$.\n*   $u_{1,2}$ is 2nd in $\\mathcal{C}$, 4th in $\\mathcal{R}$. Column 2 is $\\boldsymbol{e}_4$.\n*   $u_{2,1}$ is 3rd in $\\mathcal{C}$, 2nd in $\\mathcal{R}$. Column 3 is $\\boldsymbol{e}_2$.\n*   $u_{2,2}$ is 4th in $\\mathcal{C}$, 5th in $\\mathcal{R}$. Column 4 is $\\boldsymbol{e}_5$.\n*   $u_{3,1}$ is 5th in $\\mathcal{C}$, 3rd in $\\mathcal{R}$. Column 5 is $\\boldsymbol{e}_3$.\n*   $u_{3,2}$ is 6th in $\\mathcal{C}$, 6th in $\\mathcal{R}$. Column 6 is $\\boldsymbol{e}_6$.\n\nIn column concatenation form:\n$$\nP = \\begin{bmatrix} \\boldsymbol{e}_1  \\boldsymbol{e}_4  \\boldsymbol{e}_2  \\boldsymbol{e}_5  \\boldsymbol{e}_3  \\boldsymbol{e}_6 \\end{bmatrix} =\n\\begin{pmatrix}\n1  0  0  0  0  0 \\\\\n0  0  1  0  0  0 \\\\\n0  0  0  0  1  0 \\\\\n0  1  0  0  0  0 \\\\\n0  0  0  1  0  0 \\\\\n0  0  0  0  0  1\n\\end{pmatrix}\n$$\nThe permutation $p$ maps the index in $\\mathcal{C}$ to the index in $\\mathcal{R}$: $p(1)=1, p(2)=4, p(3)=2, p(4)=5, p(5)=3, p(6)=6$. The matrix $P$ can be written as a sum of outer products:\n$$\nP = \\sum_{j=1}^{6} \\boldsymbol{e}_{p(j)}\\boldsymbol{e}_j^\\top = \\boldsymbol{e}_1\\boldsymbol{e}_1^\\top + \\boldsymbol{e}_4\\boldsymbol{e}_2^\\top + \\boldsymbol{e}_2\\boldsymbol{e}_3^\\top + \\boldsymbol{e}_5\\boldsymbol{e}_4^\\top + \\boldsymbol{e}_3\\boldsymbol{e}_5^\\top + \\boldsymbol{e}_6\\boldsymbol{e}_6^\\top\n$$\n\n**2. Assemble Matrices A and A'**\n\nThe discrete Laplacian operator at point $(i,j)$ is $4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1} = f_{i,j}$. Using Kronecker products, the matrix $A$ under $\\mathcal{R}$ ordering is $A = I_{N_y} \\otimes L_{N_x} + L_{N_y} \\otimes I_{N_x}$, where $L_k$ is the 1D Laplacian tridiagonal matrix with 4 on the diagonal and -1 on the off-diagonals.\n\nFor our $N_x=3, N_y=2$ case:\n$A$ (under $\\mathcal{R}$ ordering) is a $2 \\times 2$ block matrix where diagonal blocks are $T_3 = \\begin{pmatrix} 4  -1  0 \\\\ -1  4  -1 \\\\ 0  -1  4 \\end{pmatrix}$ and off-diagonal blocks are $-I_3$.\n$$\nA = \\begin{pmatrix}\n  4  -1   0  -1   0   0 \\\\\n -1   4  -1   0  -1   0 \\\\\n  0  -1   4   0   0  -1 \\\\\n -1   0   0   4  -1   0 \\\\\n  0  -1   0  -1   4  -1 \\\\\n  0   0  -1   0  -1   4\n\\end{pmatrix}\n$$\n$A'$ (under $\\mathcal{C}$ ordering) is a $3 \\times 3$ block matrix where diagonal blocks are $T_2 = \\begin{pmatrix} 4  -1 \\\\ -1  4 \\end{pmatrix}$ and off-diagonal blocks are $-I_2$.\n$$\nA' = \\begin{pmatrix}\n  4  -1  -1   0   0   0 \\\\\n -1   4   0  -1   0   0 \\\\\n -1   0   4  -1  -1   0 \\\\\n  0  -1  -1   4   0  -1 \\\\\n  0   0  -1   0   4  -1 \\\\\n  0   0   0  -1  -1   4\n\\end{pmatrix}\n$$\n\n**3. Verify the Similarity Transform**\n\nThe relationship $A' = P^\\top A P$ is a fundamental result of changing basis via permutation. To verify, we compute $P^\\top A P$.\n$$\nP^\\top =\n\\begin{pmatrix}\n1  0  0  0  0  0 \\\\\n0  0  0  1  0  0 \\\\\n0  1  0  0  0  0 \\\\\n0  0  0  0  1  0 \\\\\n0  0  1  0  0  0 \\\\\n0  0  0  0  0  1\n\\end{pmatrix}\n$$\nMultiplying $P^\\top A P$ amounts to reordering the rows and columns of $A$ according to the permutation. The operation permutes the rows of $A$ by $p^{-1}$ and the columns of $A$ by $p$. The result of this reordering is precisely the matrix $A'$. A full matrix multiplication confirms the identity.\n\n**4. Compute S**\n\nSince the similarity transform holds exactly, $A' - P^\\top A P$ is a zero matrix. The Frobenius norm of a zero matrix is $0$.\n$$\nS = \\|A' - P^\\top A P\\|_{F}^{2} = \\| \\mathbf{0} \\|_{F}^{2} = 0.\n$$", "answer": "$$ \\boxed{0} $$", "id": "3415894"}, {"introduction": "Beyond the abstract algebraic structure, the choice of lexicographic ordering directly impacts the computational performance of a PDE solver. On modern computer architectures, the way data is arranged in memory dictates the efficiency of data retrieval from cache and main memory. This practice bridges the gap between numerical theory and high-performance computing by analyzing the memory access strides and cache utilization of a five-point stencil under a standard lexicographic ordering [@problem_id:3415881]. By quantifying these effects, you will gain insight into why memory layout is a critical consideration in scientific code design.", "problem": "Consider a two-dimensional uniform grid for a scalar field $u(i,j)$ with $n_x$ points along the $x$-direction and $n_y$ points along the $y$-direction. The grid is stored in a single contiguous one-dimensional array using $i$-major lexicographic ordering (that is, $i$ varies fastest), so that the linearized memory index is given by\n$$\np(i,j) = i + n_x\\,j \\quad \\text{for} \\quad 0 \\leq i \\leq n_x - 1, \\; 0 \\leq j \\leq n_y - 1.\n$$\nAssume periodic boundary conditions in both directions. Consider the five-point stencil for a standard second-order finite difference approximation to the Laplacian used in the numerical solution of partial differential equations (PDEs), evaluated at an interior point $(i,j)$:\n$$\n\\{(i,j)\\ \\text{(center)},\\ (i+1,j)\\ \\text{(east)},\\ (i-1,j)\\ \\text{(west)},\\ (i,j+1)\\ \\text{(north)},\\ (i,j-1)\\ \\text{(south)}\\}.\n$$\nSuppose the data type is of size $s$ bytes and the central processing unit (CPU) cache line size is $L$ bytes. Define the cache line capacity $c$ (in elements) by $c = L/s$, and assume the following alignment and capacity idealizations:\n- The base address of the array is aligned to a cache line boundary.\n- $n_x$ is a multiple of $c$, so that each row starts at a cache line boundary and no cache line straddles two rows.\n- The cache is fully associative with infinite capacity, and it fetches whole cache lines on demand.\n\nA row-wise sweep (inner loop in $i$, outer loop in $j$) evaluates the stencil across a fixed row $j$ for all $i = 0,1,\\dots,n_x - 1$. For this sweep, answer the following:\n\n(a) Using the linearization map $p(i,j)$, compute the element-wise memory access strides (differences in the flattened index) from the center to each of its four neighbors: east, west, north, and south. That is, compute\n$$\n\\Delta p_{\\mathrm{E}} = p(i+1,j) - p(i,j),\\quad\n\\Delta p_{\\mathrm{W}} = p(i-1,j) - p(i,j),\\quad\n\\Delta p_{\\mathrm{N}} = p(i,j+1) - p(i,j),\\quad\n\\Delta p_{\\mathrm{S}} = p(i,j-1) - p(i,j).\n$$\n\n(b) Over the entire sweep of a fixed row $j$ across all $i$, each stencil evaluation performs $5$ element reads. Under the ideal cache model above, determine the cache line reuse factor $R(c)$, defined as the average number of element reads served per distinct cache line fetched during the sweep. Express $R(c)$ as a closed-form analytic expression in terms of $c$ and $n_x$.\n\nReport your final answer as a single row matrix in the order\n$$\n\\bigl[\\Delta p_{\\mathrm{E}},\\ \\Delta p_{\\mathrm{W}},\\ \\Delta p_{\\mathrm{N}},\\ \\Delta p_{\\mathrm{S}},\\ R(c)\\bigr].\n$$\nNo numerical rounding is required, and you should leave the result as an exact symbolic expression.", "solution": "### Part (a): Compute Memory Access Strides\n\nThe memory access strides are the differences in the linearized index $p$ between the central grid point $(i,j)$ and its four cardinal neighbors. We are given the linearization map $p(i,j) = i + n_x j$.\n\nThe linearized index for the central point is:\n$$p(i,j) = i + n_x j$$\n\nThe linearized indices for the neighbors are:\n- East: $p(i+1,j) = (i+1) + n_x j$\n- West: $p(i-1,j) = (i-1) + n_x j$\n- North: $p(i,j+1) = i + n_x (j+1) = i + n_x j + n_x$\n- South: $p(i,j-1) = i + n_x (j-1) = i + n_x j - n_x$\n\nNow, we compute the strides by subtracting $p(i,j)$ from each neighbor's index.\n\n- **East Stride**:\n$$ \\Delta p_{\\mathrm{E}} = p(i+1,j) - p(i,j) = ((i+1) + n_x j) - (i + n_x j) = 1 $$\n\n- **West Stride**:\n$$ \\Delta p_{\\mathrm{W}} = p(i-1,j) - p(i,j) = ((i-1) + n_x j) - (i + n_x j) = -1 $$\n\n- **North Stride**:\n$$ \\Delta p_{\\mathrm{N}} = p(i,j+1) - p(i,j) = (i + n_x j + n_x) - (i + n_x j) = n_x $$\n\n- **South Stride**:\n$$ \\Delta p_{\\mathrm{S}} = p(i,j-1) - p(i,j) = (i + n_x j - n_x) - (i + n_x j) = -n_x $$\n\nThese strides represent the constant memory offsets to access neighbors for the given $i$-major storage scheme.\n\n### Part (b): Cache Line Reuse Factor\n\nThe cache line reuse factor $R(c)$ is defined as the average number of element reads served per distinct cache line fetched during a full sweep of one row.\n$$ R(c) = \\frac{\\text{Total element reads}}{\\text{Total distinct cache lines fetched}} $$\n\n**1. Numerator: Total element reads**\n\nThe sweep is performed for a fixed row $j$ across all $i = 0, 1, \\dots, n_x - 1$.\nThere are $n_x$ grid points in the row, so the five-point stencil is evaluated $n_x$ times.\nEach stencil evaluation requires $5$ element reads.\nTherefore, the total number of element reads is:\n$$ N_{\\text{reads}} = 5 \\times n_x $$\n\n**2. Denominator: Total distinct cache lines fetched**\n\nThe ideal cache model (infinite capacity, fully associative) means a cache line is fetched only once, on the first access to any element it contains. The total number of fetched lines is the number of unique cache lines that hold at least one accessed element.\n\nThe sweep for a fixed row $j$ involves stencil evaluations at points $(i, j)$ for all $i=0, \\dots, n_x-1$. Due to periodic boundary conditions, the stencil at $(i,j)$ accesses elements in row $j$ (center, east, west neighbors) and rows $(j\\pm1)\\pmod{n_y}$ (north, south neighbors). Over the full sweep, all elements in these three rows are accessed.\nThus, the sweep requires access to all elements of three distinct rows: the central row $j$, the north row $(j+1)\\pmod{n_y}$, and the south row $(j-1)\\pmod{n_y}$.\n\nNow we determine the number of cache lines for these three rows.\n- Each row contains $n_x$ elements.\n- The cache line capacity is $c$ elements.\n- The problem states that $n_x$ is a multiple of $c$ and that each row starts at a cache line boundary.\n- Therefore, the data for a single row occupies exactly $N_{\\text{lines per row}} = \\frac{n_x}{c}$ cache lines.\n\nSince the sweep accesses every element in all three rows, it must fetch all cache lines corresponding to these rows.\nThe total number of distinct cache lines fetched is:\n$$ N_{\\text{lines}} = 3 \\times N_{\\text{lines per row}} = 3 \\times \\frac{n_x}{c} $$\n\n**3. Compute the Reuse Factor $R(c)$**\n\nWe can now compute the ratio:\n$$ R(c) = \\frac{N_{\\text{reads}}}{N_{\\text{lines}}} = \\frac{5 n_x}{3 \\frac{n_x}{c}} = \\frac{5c}{3} $$\nThe reuse factor $R(c)$ is independent of the grid dimensions $n_x$ and $n_y$, and depends only on the cache line capacity $c$ and the stencil size (implicitly 5).\n\n### Final Answer Assembly\nThe required quantities are:\n- $\\Delta p_{\\mathrm{E}} = 1$\n- $\\Delta p_{\\mathrm{W}} = -1$\n- $\\Delta p_{\\mathrm{N}} = n_x$\n- $\\Delta p_{\\mathrm{S}} = -n_x$\n- $R(c) = \\frac{5c}{3}$\n\nThese are to be reported in a single row matrix.", "answer": "$$ \\boxed{ \\begin{pmatrix} 1  -1  n_x  -n_x  \\frac{5c}{3} \\end{pmatrix} } $$", "id": "3415881"}, {"introduction": "The influence of grid ordering extends deep into the design and effectiveness of the numerical algorithms themselves. A seemingly innocent choice of ordering can cripple an otherwise powerful iterative solver, especially for challenging problems like those with strong anisotropy. This advanced exercise uses Local Fourier Analysis (LFA) to demonstrate precisely why a standard point-wise Gauss-Seidel smoother fails under lexicographic ordering for an anisotropic problem, and guides you to analyze a more robust, ordering-aware block-line smoother that resolves the issue [@problem_id:3415932]. This practice illustrates the crucial principle that the grid ordering and the solver algorithm must be co-designed for optimal performance.", "problem": "Consider the two-dimensional anisotropic diffusion partial differential equation (PDE) with periodic boundary conditions,\n$$\n-\\left( \\alpha \\frac{\\partial^{2} u}{\\partial x^{2}} + \\frac{\\partial^{2} u}{\\partial y^{2}} \\right) = f,\n$$\nposed on a uniform infinite lattice approximation of the unit torus with grid spacing $h0$, where $\\alpha \\gg 1$ represents strong grid-aligned anisotropy in the $x$-direction. Discretize the PDE using the standard five-point second-order accurate finite difference scheme, producing a linear system $A u = f$ with stencil coefficients\n$$\nA_{i,j} = \\frac{2(\\alpha+1)}{h^{2}}, \\quad A_{i\\pm 1,j} = -\\frac{\\alpha}{h^{2}}, \\quad A_{i,j\\pm 1} = -\\frac{1}{h^{2}}.\n$$\nAdopt row-wise lexicographic ordering in the $i$-index (inner loop) within the $j$-index (outer loop), and consider forward Gauss–Seidel relaxation as a smoother in a geometric multigrid setting with standard coarsening by a factor of $2$ in each spatial direction. Perform Local Fourier Analysis (LFA) on the infinite grid, modeling the error as a superposition of Fourier modes\n$$\n\\varphi_{\\boldsymbol{\\theta}}(i,j) = \\exp\\!\\left(i (i \\theta_{x} + j \\theta_{y})\\right), \\quad \\boldsymbol{\\theta} = (\\theta_{x},\\theta_{y}) \\in [-\\pi,\\pi]^{2}.\n$$\nDefine the high-frequency set associated with $2\\times$ coarsening as\n$$\n\\Theta_{\\mathrm{HF}} = \\left\\{ (\\theta_{x},\\theta_{y}) \\in [-\\pi,\\pi]^{2} : \\text{at least one of } |\\theta_{x}| \\ge \\frac{\\pi}{2} \\text{ or } |\\theta_{y}| \\ge \\frac{\\pi}{2} \\right\\}.\n$$\nTasks:\n1. Construct and justify the above PDE as a counterexample where standard pointwise forward Gauss–Seidel under the specified lexicographic ordering is a poor smoother for large $\\alpha$, by deriving its LFA error-propagation symbol and explaining why the smoothing factor over $\\Theta_{\\mathrm{HF}}$ approaches unity as $\\alpha \\to \\infty$.\n2. Propose a lexicographic block-line Gauss–Seidel smoother that exactly inverts the strong couplings along $x$-lines (fixed $j$), ordered forward in the $j$-index, and derive its LFA error-propagation symbol.\n3. Using LFA, compute the smoothing factor of this block-line smoother, namely the supremum of the magnitude of the error-propagation symbol over $\\Theta_{\\mathrm{HF}}$, as a single closed-form analytic expression. Your final answer must be a single exact analytic expression. No rounding is required.", "solution": "The solution is divided into the three tasks specified in the problem statement.\n\n**Task 1: Analysis of Pointwise Gauss-Seidel**\n\nThe forward Gauss-Seidel iteration for an error vector $e$ is described by the splitting $A = M-N$, where $M$ contains the diagonal and lower-triangular parts of $A$ and $N$ contains the negative of the upper-triangular part. The error propagation operator is $S = M^{-1}N$. For row-wise lexicographic ordering, the update at grid point $(i,j)$ uses new error values at $(i-1,j)$ and $(i,j-1)$ and old error values at $(i+1,j)$ and $(i,j+1)$. The error update equation is:\n$$\nA_{i,j} e^{k+1}(i,j) + A_{i-1,j} e^{k+1}(i-1,j) + A_{i,j-1} e^{k+1}(i,j-1) = -A_{i+1,j} e^{k}(i+1,j) - A_{i,j+1} e^{k}(i,j+1)\n$$\nWe analyze the action of this iteration on a single Fourier mode $e(i,j) = \\varphi_{\\boldsymbol{\\theta}}(i,j)$, for which $e^{k+1} = S_{\\text{pt}}(\\boldsymbol{\\theta}) e^{k}$. Substituting the stencil coefficients and the form $\\varphi_{\\boldsymbol{\\theta}}(i',j') = \\varphi_{\\boldsymbol{\\theta}}(i,j) \\exp(i((i'-i)\\theta_x + (j'-j)\\theta_y))$ yields the LFA symbol for the smoother, $S_{\\text{pt}}(\\boldsymbol{\\theta})$:\n$$\n\\frac{2(\\alpha+1)}{h^2} S_{\\text{pt}}(\\boldsymbol{\\theta}) - \\frac{\\alpha}{h^2} S_{\\text{pt}}(\\boldsymbol{\\theta}) e^{-i\\theta_x} - \\frac{1}{h^2} S_{\\text{pt}}(\\boldsymbol{\\theta}) e^{-i\\theta_y} = \\frac{\\alpha}{h^2} e^{i\\theta_x} + \\frac{1}{h^2} e^{i\\theta_y}\n$$\nSolving for $S_{\\text{pt}}(\\boldsymbol{\\theta})$ gives:\n$$\nS_{\\text{pt}}(\\boldsymbol{\\theta}) = \\frac{\\alpha e^{i\\theta_x} + e^{i\\theta_y}}{2(\\alpha+1) - \\alpha e^{-i\\theta_x} - e^{-i\\theta_y}}\n$$\nTo demonstrate this is a poor smoother for large $\\alpha$, we show that its smoothing factor, $\\mu_{\\text{pt}} = \\sup_{\\boldsymbol{\\theta} \\in \\Theta_{\\mathrm{HF}}} |S_{\\text{pt}}(\\boldsymbol{\\theta})|$, approaches $1$ as $\\alpha \\to \\infty$. Consider the mode $\\boldsymbol{\\theta}=(0, \\pi) \\in \\Theta_{\\mathrm{HF}}$. This mode is constant in $x$ (direction of strong coupling) and maximally oscillatory in $y$.\nFor $\\boldsymbol{\\theta}=(0, \\pi)$:\n$$\nS_{\\text{pt}}(0, \\pi) = \\frac{\\alpha e^{0} + e^{i\\pi}}{2(\\alpha+1) - \\alpha e^{0} - e^{-i\\pi}} = \\frac{\\alpha - 1}{2\\alpha+2 - \\alpha - (-1)} = \\frac{\\alpha-1}{\\alpha+3}\n$$\nThe magnitude is $|S_{\\text{pt}}(0, \\pi)| = \\frac{\\alpha-1}{\\alpha+3}$. As $\\alpha \\to \\infty$:\n$$\n\\lim_{\\alpha \\to \\infty} |S_{\\text{pt}}(0, \\pi)| = \\lim_{\\alpha \\to \\infty} \\frac{\\alpha-1}{\\alpha+3} = \\lim_{\\alpha \\to \\infty} \\frac{1-1/\\alpha}{1+3/\\alpha} = 1\n$$\nSince the supremum must be at least this large, $\\lim_{\\alpha\\to\\infty} \\mu_{\\text{pt}} = 1$. A smoothing factor of $1$ means no error reduction for this high-frequency mode, rendering the smoother ineffective.\n\n**Task 2: Block-Line Gauss-Seidel Smoother**\n\nA block-line Gauss-Seidel smoother treats all points on an $x$-line (constant $j$) as a single block, processed in increasing order of $j$. The error update equation for line $j$ is:\n$$\n-\\frac{\\alpha}{h^2}e^{k+1}(i-1,j) + \\frac{2(\\alpha+1)}{h^2}e^{k+1}(i,j) - \\frac{\\alpha}{h^2}e^{k+1}(i+1,j) - \\frac{1}{h^2}e^{k+1}(i,j-1) = \\frac{1}{h^2}e^{k}(i,j+1)\n$$\nApplying LFA, we substitute $e(i,j) = \\varphi_{\\boldsymbol{\\theta}}(i,j)$ with amplification factor $S_{\\text{blk}}(\\boldsymbol{\\theta})$:\n$$\nS_{\\text{blk}}(\\boldsymbol{\\theta}) \\left( -\\frac{\\alpha}{h^2}e^{-i\\theta_x} + \\frac{2(\\alpha+1)}{h^2} - \\frac{\\alpha}{h^2}e^{i\\theta_x} - \\frac{1}{h^2}e^{-i\\theta_y} \\right) = \\frac{1}{h^2}e^{i\\theta_y}\n$$\nMultiplying by $h^2$ and simplifying:\n$$\nS_{\\text{blk}}(\\boldsymbol{\\theta}) \\left( 2(\\alpha+1) - 2\\alpha\\cos(\\theta_x) - e^{-i\\theta_y} \\right) = e^{i\\theta_y}\n$$\nSolving for the symbol $S_{\\text{blk}}(\\boldsymbol{\\theta})$:\n$$\nS_{\\text{blk}}(\\boldsymbol{\\theta}) = \\frac{e^{i\\theta_y}}{2(\\alpha+1) - 2\\alpha\\cos(\\theta_x) - e^{-i\\theta_y}}\n$$\nUsing the identity $1-\\cos(\\theta_x) = 2\\sin^2(\\theta_x/2)$, we can rewrite this as:\n$$\nS_{\\text{blk}}(\\boldsymbol{\\theta}) = \\frac{e^{i\\theta_y}}{2 + 4\\alpha\\sin^2(\\theta_x/2) - e^{-i\\theta_y}}\n$$\n\n**Task 3: Smoothing Factor of Block-Line Smoother**\n\nThe smoothing factor is $\\mu_{\\text{blk}} = \\sup_{\\boldsymbol{\\theta} \\in \\Theta_{\\mathrm{HF}}} |S_{\\text{blk}}(\\boldsymbol{\\theta})|$. The squared magnitude of the symbol is:\n$$\n|S_{\\text{blk}}(\\boldsymbol{\\theta})|^2 = \\frac{1}{|(2 + 4\\alpha\\sin^2(\\frac{\\theta_x}{2}) - \\cos(\\theta_y)) + i\\sin(\\theta_y)|^2}\n$$\nLet $C(\\theta_x) = 2 + 4\\alpha\\sin^2(\\theta_x/2)$. The denominator is $(C(\\theta_x)-\\cos\\theta_y)^2 + \\sin^2\\theta_y = C(\\theta_x)^2 - 2C(\\theta_x)\\cos\\theta_y + 1$.\n$$\n|S_{\\text{blk}}(\\boldsymbol{\\theta})|^2 = \\frac{1}{C(\\theta_x)^2 + 1 - 2C(\\theta_x)\\cos(\\theta_y)}\n$$\nTo find the supremum of $|S_{\\text{blk}}(\\boldsymbol{\\theta})|$, we must find the infimum of the denominator over $\\boldsymbol{\\theta} \\in \\Theta_{\\mathrm{HF}}$.\n\n1.  **Case 1: $|\\theta_x| \\ge \\pi/2$.**\n    Here, $\\sin^2(\\theta_x/2) \\ge \\sin^2(\\pi/4) = 1/2$. So, $C(\\theta_x) \\ge 2 + 4\\alpha(1/2) = 2+2\\alpha$.\n    Since $C(\\theta_x) \\ge 2$, the denominator is minimized for a fixed $\\theta_x$ when $\\cos(\\theta_y)$ is maximized, i.e., $\\cos(\\theta_y)=1$ (so $\\theta_y=0$). The denominator becomes $(C(\\theta_x)-1)^2$. The minimum occurs at the boundary of the region, $|\\theta_x|=\\pi/2$, where $C(\\pi/2)=2+2\\alpha$. The infimum of the denominator is $(2+2\\alpha-1)^2 = (1+2\\alpha)^2$. The supremum of $|S_{\\text{blk}}|^2$ in this region is $1/(1+2\\alpha)^2$.\n\n2.  **Case 2: $|\\theta_x|  \\pi/2$, which requires $|\\theta_y| \\ge \\pi/2$.**\n    On this domain, $\\cos(\\theta_y) \\le 0$. The denominator $C(\\theta_x)^2 + 1 - 2C(\\theta_x)\\cos(\\theta_y)$ is minimized with respect to $\\theta_x$ when $C(\\theta_x)$ is minimized, which is at $\\theta_x=0$. At $\\theta_x=0$, $C(0)=2$.\n    The expression for $|S_{\\text{blk}}(0, \\theta_y)|^2$ becomes:\n    $$\n    |S_{\\text{blk}}(0, \\theta_y)|^2 = \\frac{1}{2^2+1-2(2)\\cos(\\theta_y)} = \\frac{1}{5-4\\cos(\\theta_y)}\n    $$\n    To maximize this for $|\\theta_y| \\ge \\pi/2$, we must minimize the denominator $5-4\\cos(\\theta_y)$. Since $\\cos(\\theta_y)\\le 0$, this occurs when $\\cos(\\theta_y)$ is maximized, which is at $|\\theta_y| = \\pi/2$, where $\\cos(\\theta_y)=0$.\n    The maximum value is $|S_{\\text{blk}}(0, \\pm\\pi/2)|^2 = 1/5$. The supremum of $|S_{\\text{blk}}|$ on this part of the domain is $1/\\sqrt{5}$.\n\nThe overall smoothing factor is the maximum of the suprema over the two regions:\n$$\n\\mu_{\\text{blk}} = \\max\\left(\\frac{1}{1+2\\alpha}, \\frac{1}{\\sqrt{5}}\\right)\n$$\nFor strong anisotropy $\\alpha \\gg 1$, we have $1+2\\alpha > \\sqrt{5}$, so $1/(1+2\\alpha)  1/\\sqrt{5}$. The maximum is therefore $1/\\sqrt{5}$.", "answer": "$$\\boxed{\\frac{1}{\\sqrt{5}}}$$", "id": "3415932"}]}