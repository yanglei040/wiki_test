{"hands_on_practices": [{"introduction": "The Fast Marching Method is constructed from a fundamental building block: the local update rule that computes a node's arrival time based on its neighbors. This practice focuses on mastering this core calculation, derived directly from the discretized Eikonal equation [@problem_id:3391176]. By working through the decision logic that determines whether a one-dimensional or two-dimensional update is appropriate, you will gain a deep understanding of how the method preserves causality at the most granular level.", "problem": "Consider the isotropic Eikonal equation $|\\nabla T(\\mathbf{x})| = 1/f(\\mathbf{x})$, where $T$ is the arrival time of a front propagating with speed $f(\\mathbf{x})$. In the Fast Marching Method (FMM), the tentative update at a grid node $(i,j)$ is computed using an upwind Godunov discretization with equal grid spacing $h$ in both directions, based on the already accepted neighboring arrival times along the coordinate axes. Let the minimum accepted arrival times along the $x$- and $y$-directions be $a$ and $b$, respectively. Assume the monotonicity constraint $T \\geq \\max\\{a,b\\}$ must hold at the tentative update.\n\nStarting from the Eikonal equation and using the upwind principle, derive the local discrete relation that $T$ must satisfy in terms of $a$, $b$, $h$, and $f$, and from this relation deduce the decision logic for whether the two-dimensional update or the one-dimensional update is admissible. Then, apply your logic to compute the tentative update $T$ at the node for the values $a=0.35$, $b=0.50$, $h=0.01$, and a constant speed $f=1.8$. Express your final answer as a single number. No rounding is required.", "solution": "The problem statement is evaluated as scientifically grounded, well-posed, and objective. It is a standard problem in the numerical solution of partial differential equations, specifically concerning the Fast Marching Method for the Eikonal equation. The provided data are sufficient and consistent for a unique solution. Therefore, the problem is deemed valid and a full solution is presented below.\n\nThe isotropic Eikonal equation is given by\n$$ |\\nabla T(\\mathbf{x})|^2 = \\frac{1}{f(\\mathbf{x})^2} $$\nwhere $T(\\mathbf{x})$ is the arrival time at position $\\mathbf{x}$ and $f(\\mathbf{x})$ is the propagation speed. In a two-dimensional Cartesian grid with uniform spacing $h$, this equation can be written as\n$$ \\left(\\frac{\\partial T}{\\partial x}\\right)^2 + \\left(\\frac{\\partial T}{\\partial y}\\right)^2 = \\frac{1}{f^2} $$\nThe Fast Marching Method (FMM) uses an upwind Godunov scheme to discretize the spatial derivatives. The upwind principle ensures that information propagates from smaller arrival times to larger ones. At a grid node $(i,j)$ where we wish to compute the tentative arrival time $T$, we use the already accepted arrival times of its neighbors. Let $a$ and $b$ be the minimum accepted arrival times along the $x$ and $y$ coordinate directions, respectively. The upwind discretization for the partial derivatives is based on the idea that for the front to advance, the new time $T$ must be greater than the time at the neighbors from which the front is propagating. The general form of the first-order upwind discretization is:\n$$ \\left(\\max\\left(0, \\frac{T-a}{h}\\right)\\right)^2 + \\left(\\max\\left(0, \\frac{T-b}{h}\\right)\\right)^2 = \\frac{1}{f^2} $$\nHere, we have simplified the notation by directly using $a$ and $b$ as the relevant upwind neighbor values. The problem states the monotonicity constraint $T \\ge \\max\\{a, b\\}$, which implies that both $(T-a)$ and $(T-b)$ should be non-negative.\n\nFirst, let's derive the local discrete relation assuming a two-dimensional (2D) update is admissible. This assumption means the front propagates to the node $(i,j)$ using information from both the $x$ and $y$ directions. In this case, both terms inside the $\\max$ functions are positive, and the equation simplifies to:\n$$ \\left(\\frac{T-a}{h}\\right)^2 + \\left(\\frac{T-b}{h}\\right)^2 = \\frac{1}{f^2} $$\nThis equation is the local discrete relation that $T$ must satisfy for a 2D update. We can solve this quadratic equation for $T$:\n$$ (T-a)^2 + (T-b)^2 = \\frac{h^2}{f^2} $$\n$$ T^2 - 2aT + a^2 + T^2 - 2bT + b^2 = \\frac{h^2}{f^2} $$\n$$ 2T^2 - 2(a+b)T + \\left(a^2 + b^2 - \\frac{h^2}{f^2}\\right) = 0 $$\nUsing the quadratic formula $T = \\frac{-B \\pm \\sqrt{B^2 - 4AC}}{2A}$ with $A=2$, $B=-2(a+b)$, and $C = a^2+b^2 - (h/f)^2$:\n$$ T = \\frac{2(a+b) \\pm \\sqrt{4(a+b)^2 - 8\\left(a^2+b^2 - \\frac{h^2}{f^2}\\right)}}{4} $$\n$$ T = \\frac{a+b \\pm \\sqrt{(a+b)^2 - 2(a^2+b^2) + \\frac{2h^2}{f^2}}}{2} $$\n$$ T = \\frac{a+b \\pm \\sqrt{a^2+2ab+b^2 - 2a^2-2b^2 + \\frac{2h^2}{f^2}}}{2} $$\n$$ T = \\frac{a+b \\pm \\sqrt{\\frac{2h^2}{f^2} - (a-b)^2}}{2} $$\nSince we require $T \\ge \\max\\{a, b\\}$, we must choose the larger root, corresponding to the `+` sign:\n$$ T_{2D} = \\frac{a+b + \\sqrt{\\frac{2h^2}{f^2} - (a-b)^2}}{2} $$\nThis is the candidate solution for a 2D update.\n\nNext, we deduce the decision logic. A real solution for $T_{2D}$ exists only if the discriminant is non-negative: $\\frac{2h^2}{f^2} - (a-b)^2 \\ge 0$, which implies $|a-b| \\le \\frac{\\sqrt{2}h}{f}$. More importantly, the assumption that this 2D update is valid depends on the result satisfying the monotonicity constraint $T \\ge \\max\\{a,b\\}$. Let's assume without loss of generality that $b \\ge a$, so $\\max\\{a,b\\}=b$. The condition for validity is $T_{2D} \\ge b$.\n$$ \\frac{a+b + \\sqrt{\\frac{2h^2}{f^2} - (a-b)^2}}{2} \\ge b $$\n$$ a+b + \\sqrt{\\frac{2h^2}{f^2} - (a-b)^2} \\ge 2b $$\n$$ \\sqrt{\\frac{2h^2}{f^2} - (a-b)^2} \\ge b-a $$\nSince $b-a \\ge 0$, we can square both sides:\n$$ \\frac{2h^2}{f^2} - (a-b)^2 \\ge (b-a)^2 $$\n$$ \\frac{2h^2}{f^2} \\ge 2(a-b)^2 $$\n$$ \\frac{h^2}{f^2} \\ge (a-b)^2 \\implies \\frac{h}{f} \\ge |a-b| $$\nThis provides the decision logic. The 2D update is admissible if and only if $|a-b| \\le \\frac{h}{f}$.\n\nIf this condition is not met, i.e., $|a-b| > \\frac{h}{f}$, then the 2D formula would yield $T_{2D} < \\max\\{a,b\\}$, violating the causality principle. This implies that our initial assumption was wrong; specifically, the update is not influenced by both neighbors. The general discrete equation must be used, where one of the $\\max$ terms becomes zero. If $b \\ge a$ and $|a-b| > h/f$, then $T < b$, so $\\max(0, (T-b)/h) = 0$. The governing equation reduces to a one-dimensional (1D) update determined by the neighbor with the smaller arrival time, in this case $a$:\n$$ \\left(\\frac{T-a}{h}\\right)^2 + 0 = \\frac{1}{f^2} $$\nSolving for $T$ yields:\n$$ T_{1D} = a + \\frac{h}{f} $$\nMore generally, the 1D update uses the minimum of the neighbor values: $T = \\min(a,b) + \\frac{h}{f}$.\n\nThe decision logic is as follows:\n1.  Calculate $|a-b|$ and $\\frac{h}{f}$.\n2.  If $|a-b| \\le \\frac{h}{f}$, the update is 2D and $T = \\frac{a+b + \\sqrt{2(h/f)^2 - (a-b)^2}}{2}$.\n3.  If $|a-b| > \\frac{h}{f}$, the update is 1D and $T = \\min(a,b) + \\frac{h}{f}$.\n\nNow, we apply this logic to the given values: $a=0.35$, $b=0.50$, $h=0.01$, and $f=1.8$.\nWe express these values as exact fractions to avoid rounding errors:\n$a = 0.35 = \\frac{35}{100} = \\frac{7}{20}$\n$b = 0.50 = \\frac{50}{100} = \\frac{1}{2}$\n$h = 0.01 = \\frac{1}{100}$\n$f = 1.8 = \\frac{18}{10} = \\frac{9}{5}$\n\nFirst, we check the condition for the decision logic:\n$$ |a-b| = \\left|\\frac{7}{20} - \\frac{1}{2}\\right| = \\left|\\frac{7}{20} - \\frac{10}{20}\\right| = \\left|-\\frac{3}{20}\\right| = \\frac{3}{20} $$\n$$ \\frac{h}{f} = \\frac{1/100}{9/5} = \\frac{1}{100} \\cdot \\frac{5}{9} = \\frac{5}{900} = \\frac{1}{180} $$\nNow we compare $|a-b|$ with $\\frac{h}{f}$:\n$$ \\frac{3}{20} \\quad \\text{vs.} \\quad \\frac{1}{180} $$\nTo compare, we can use a common denominator or cross-multiply:\n$$ 3 \\times 180 = 540 $$\n$$ 20 \\times 1 = 20 $$\nSince $540 > 20$, we have $\\frac{3}{20} > \\frac{1}{180}$.\nThe condition $|a-b| \\le \\frac{h}{f}$ is false.\n\nTherefore, the one-dimensional (1D) update is admissible. The tentative update $T$ is computed using the smaller of the two neighbor values, which is $T_{\\min} = \\min(a,b) = a = \\frac{7}{20}$.\n$$ T = T_{\\min} + \\frac{h}{f} $$\n$$ T = \\frac{7}{20} + \\frac{1}{180} $$\nTo add these fractions, we find a common denominator, which is $180$:\n$$ T = \\frac{7 \\times 9}{20 \\times 9} + \\frac{1}{180} = \\frac{63}{180} + \\frac{1}{180} = \\frac{64}{180} $$\nFinally, we simplify the fraction:\n$$ T = \\frac{64 \\div 4}{180 \\div 4} = \\frac{16}{45} $$\nThe tentative update for the arrival time $T$ at the node is $\\frac{16}{45}$.", "answer": "$$ \\boxed{\\frac{16}{45}} $$", "id": "3391176"}, {"introduction": "With the local update rule understood, the next step is to assemble the full Fast Marching Method and verify its performance. This practice guides you through implementing the FMM algorithm and conducting a formal grid refinement study to measure its observed order of accuracy [@problem_id:3391181]. This process of comparing a numerical solution against an analytic one on successively finer grids is a cornerstone of computational science, providing essential skills for validating code and confirming theoretical convergence rates.", "problem": "Consider the isotropic Eikonal equation, a Hamilton–Jacobi partial differential equation that models front propagation with spatially varying speed. The unknown arrival time field $T(x)$ satisfies the equation $|\\nabla T(x)| = \\frac{1}{f(x)}$, where $f(x)$ denotes the local front speed. For a constant speed $f(x) \\equiv f_0$ and a single point source at $x_s$, the solution is radially symmetric and determined by the geometry of the shortest path. For this setting, design and implement a grid refinement study to assess the numerical accuracy and observed order of accuracy of a Fast Marching Method (FMM) discretization of the Eikonal equation on uniform two-dimensional grids.\n\nYour task is to write a complete program that:\n- Implements a two-dimensional Fast Marching Method on a uniform Cartesian grid with spacing $h$ on the square domain $[0,1] \\times [0,1]$ using first-order upwind, monotone discretization. The discretization must be derived from the Eikonal equation and must respect causality via an acceptance mechanism that proceeds from smaller to larger arrival times.\n- Uses a constant speed $f(x) \\equiv f_0$ and a single point source with zero arrival time located exactly on a grid node to avoid subgrid projection error. The source location must be chosen so that it is present on all grid resolutions in the test suite.\n- Derives the analytic solution $T_{\\text{exact}}(x)$ from the governing equation and the geometry of shortest paths for the constant speed case with a point source, and uses it to compute grid-based error norms.\n\nThe grid refinement study must adhere to the following:\n- Grids: Use uniform grids with $N \\in \\{33,65,129,257\\}$ points per dimension, so the grid spacing is $h = \\frac{1}{N-1}$. This ensures that the coordinate $x = 0.5$ is always a grid node when $N$ is odd.\n- Error norms: For each $N$, compute the discrete $L_1$, $L_2$, and $L_\\infty$ error norms between the numerical solution $T_h$ and the analytic solution $T_{\\text{exact}}$ over all grid nodes. Use the discrete approximations consistent with integral norms:\n  - $L_1$ error: $E_{1}(h) = h^2 \\sum_{i,j} |T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j})|$.\n  - $L_2$ error: $E_{2}(h) = \\sqrt{h^2 \\sum_{i,j} (T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j}))^2}$.\n  - $L_\\infty$ error: $E_{\\infty}(h) = \\max_{i,j} |T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j})|$.\n- Observed order of accuracy: For a sequence of grid spacings $h_1 > h_2 > \\dots$, define the observed order $p$ for a given norm by the slope of the error trend in log–log space computed between successive grid levels:\n  $$p_{k} = \\frac{\\log\\left(\\frac{E(h_{k+1})}{E(h_{k})}\\right)}{\\log\\left(\\frac{h_{k+1}}{h_{k}}\\right)}.$$\n  Report a single robustness-enhanced estimate per norm by taking the median of $\\{p_{k}\\}$ across all successive pairs of grids in the test suite.\n\nTest suite specification:\n- Case A (happy path): $f_0 = 1$, source at the domain center $x_s = (0.5,0.5)$.\n- Case B (speed variation): $f_0 = 2$, source at the domain center $x_s = (0.5,0.5)$.\n- Case C (geometric edge case): $f_0 = 1$, source at the domain corner $x_s = (0,0)$.\n\nAnalytic solution requirement: You must determine $T_{\\text{exact}}(x)$ for constant $f_0$ and a single source $x_s$ from first principles using the Eikonal equation and the geometry of shortest paths. This analytic solution must be used for error computation.\n\nFinal output format:\n- For each case, compute the median observed orders for the three norms $L_1$, $L_2$, and $L_\\infty$ across the four grids. Aggregate the results for the three cases into a single list of nine floating-point numbers in the order $[p_{L_1}^{\\text{A}}, p_{L_2}^{\\text{A}}, p_{L_\\infty}^{\\text{A}}, p_{L_1}^{\\text{B}}, p_{L_2}^{\\text{B}}, p_{L_\\infty}^{\\text{B}}, p_{L_1}^{\\text{C}}, p_{L_2}^{\\text{C}}, p_{L_\\infty}^{\\text{C}}]$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots,result_9]$).\nAll quantities are dimensionless; no physical units are required. Angles are not involved. Express all final numeric outputs as floating-point numbers.", "solution": "The problem requires the implementation of a grid refinement study to determine the observed order of accuracy for a first-order Fast Marching Method (FMM) solving the Eikonal equation. The study will be conducted on a two-dimensional square domain for a constant wave speed and a single point source.\n\n### 1. Underlying Principles and Analytic Solution\n\nThe governing equation is the isotropic Eikonal equation:\n$$\n|\\nabla T(x)| = \\frac{1}{f(x)}\n$$\nwhere $T(x)$ is the arrival time field of a propagating front and $f(x)$ is the local speed of the front. In this problem, the speed is constant, $f(x) \\equiv f_0$. The equation describes the shortest travel time from a source region. With a constant speed $f_0$, the medium is homogeneous, and the shortest path between two points is a straight line. The time taken to travel this path is its Euclidean length divided by the speed.\n\nGiven a single point source at $x_s$ with an initial arrival time $T(x_s) = 0$, the arrival time at any other point $x$ is determined by the length of the shortest path from $x_s$ to $x$. For a constant speed, this path is the straight line segment connecting them. The analytic solution is therefore the Euclidean distance from the source, scaled by the slowness $S_0 = 1/f_0$:\n$$\nT_{\\text{exact}}(x) = \\frac{\\|x - x_s\\|_2}{f_0}\n$$\nFor a point $x = (x, y)$ and a source $x_s = (x_s, y_s)$, this is explicitly:\n$$\nT_{\\text{exact}}(x, y) = \\frac{\\sqrt{(x-x_s)^2 + (y-y_s)^2}}{f_0}\n$$\nThis exact solution will serve as the ground truth for computing numerical errors. It is smooth everywhere except for a conical singularity at the source $x=x_s$.\n\n### 2. Numerical Discretization and The Fast Marching Method\n\nWe discretize the domain $[0,1] \\times [0,1]$ using a uniform Cartesian grid with $N$ points in each dimension, giving a grid spacing of $h = 1/(N-1)$. Let $T_{i,j}$ be the numerical approximation of $T(ih, jh)$.\n\nThe Eikonal equation, when squared, is $(\\frac{\\partial T}{\\partial x})^2 + (\\frac{\\partial T}{\\partial y})^2 = S^2$, where $S = 1/f_0$ is the constant slowness. A first-order, upwind, monotone discretization must be used. This means the value $T_{i,j}$ is computed using only the values of its neighbors that have smaller arrival times. The FMM algorithm naturally enforces this causality. The upwind discretization for the partial derivatives is:\n$$\n\\left(\\max\\left(\\frac{T_{i,j}-T_{i-1,j}}{h}, -\\frac{T_{i+1,j}-T_{i,j}}{h}, 0\\right)\\right)^2 + \\left(\\max\\left(\\frac{T_{i,j}-T_{i,j-1}}{h}, -\\frac{T_{i,j+1}-T_{i,j}}{h}, 0\\right)\\right)^2 = S^2\n$$\nWithin the FMM framework, at the moment of updating $T_{i,j}$, its upwind neighbors have already been assigned their final, smaller arrival times. Let $T_x = \\min(T_{i-1,j}, T_{i+1,j})$ and $T_y = \\min(T_{i,j-1}, T_{i,j+1})$. The equation for $T_{i,j}$ simplifies based on two regimes:\n\n1.  **One-Dimensional Update**: If the front arrives at $(i,j)$ primarily from one direction (e.g., $x$), the update mimics a 1D problem. This occurs if $|T_x - T_y| \\ge hS$. In this case, the update is:\n    $$\n    T_{i,j} = \\min(T_x, T_y) + hS\n    $$\n\n2.  **Two-Dimensional Update**: If the front arrives from a direction incorporating both $x$ and $y$ components, a quadratic equation must be solved. This occurs if $|T_x - T_y| < hS$. The underlying equation is $(T_{i,j} - T_x)^2 + (T_{i,j} - T_y)^2 = (hS)^2$. Solving for $T_{i,j}$ and taking the larger root (which corresponds to the viscosity solution) yields:\n    $$\n    T_{i,j} = \\frac{T_x + T_y + \\sqrt{2(hS)^2 - (T_x - T_y)^2}}{2}\n    $$\n\nThe **Fast Marching Method (FMM)** is an efficient algorithm for solving the discretized Eikonal equation in the correct order. It uses a min-priority queue to systematically advance the front from smaller to larger arrival times.\n- **Node States**: Each grid node is in one of three states: `KNOWN` (final time computed), `TRIAL` (tentative time computed, on the propagation front), or `UNSEEN` (far from the front).\n- **Initialization**: All nodes are `UNSEEN` with $T=\\infty$, except the source node, which has $T=0$ and is marked as `TRIAL`.\n- **Algorithm**:\n    1. A min-priority queue stores all `TRIAL` nodes, ordered by their arrival times.\n    2. Repeatedly extract the `TRIAL` node $(i,j)$ with the minimum arrival time from the queue.\n    3. Mark this node as `KNOWN`.\n    4. For each `UNSEEN` or `TRIAL` neighbor of $(i,j)$, calculate a new arrival time using the upwind discretization scheme described above.\n    5. If the newly calculated time is smaller than the neighbor's current time, update the neighbor's time and add it to the priority queue.\n\n### 3. Grid Refinement Study and Error Analysis\n\nA grid refinement study is performed to assess the numerical accuracy. The theoretical order of accuracy $p$ relates the error $E$ to the grid spacing $h$ by $E(h) \\approx C h^p$. By computing the error on a sequence of successively finer grids, we can estimate $p$.\n\n- **Grids**: Uniform grids with $N \\in \\{33, 65, 129, 257\\}$ points per dimension, yielding grid spacings $h_k = 1/(N_k-1)$ that are successively halved.\n- **Error Norms**: For each grid, the discrete $L_1$, $L_2$, and $L_\\infty$ error norms are computed by comparing the numerical solution $T_h$ to the analytic solution $T_{\\text{exact}}$ evaluated at the grid nodes.\n    - $L_1$ error: $E_{1}(h) = h^2 \\sum_{i,j} |T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j})|$\n    - $L_2$ error: $E_{2}(h) = \\sqrt{h^2 \\sum_{i,j} (T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j}))^2}$\n    - $L_\\infty$ error: $E_{\\infty}(h) = \\max_{i,j} |T_h(x_{i,j}) - T_{\\text{exact}}(x_{i,j})|$\n- **Observed Order of Accuracy**: For each norm, the order $p_k$ is computed between successive grid levels $h_k$ and $h_{k+1}$:\n    $$\n    p_{k} = \\frac{\\log\\left(E(h_{k+1})/E(h_{k})\\right)}{\\log\\left(h_{k+1}/h_{k}\\right)}\n    $$\nSince $h_{k+1}/h_k = 1/2$, this simplifies to $p_k = -\\log_2(E(h_{k+1})/E(h_k))$. A single robust estimate for the order $p$ is obtained by taking the median of the sequence $\\{p_k\\}$. The procedure is executed for all three specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport heapq\n\ndef fast_marching(N, h, f0, source_idx):\n    \"\"\"\n    Implements the Fast Marching Method on a 2D uniform grid.\n\n    Args:\n        N (int): Number of grid points per dimension.\n        h (float): Grid spacing.\n        f0 (float): Constant wave speed.\n        source_idx (tuple): (row, col) indices of the source point.\n\n    Returns:\n        numpy.ndarray: A (N, N) array of arrival times.\n    \"\"\"\n    # 1. Initialization\n    T = np.full((N, N), np.inf, dtype=np.float64)\n    # States: 0=UNSEEN, 1=TRIAL, 2=KNOWN\n    states = np.zeros((N, N), dtype=np.uint8)\n    UNSEEN, TRIAL, KNOWN = 0, 1, 2\n    \n    pq = []  # Min-priority queue\n\n    slowness_h = h / f0\n\n    # Set source node\n    isrc, jsrc = source_idx\n    T[isrc, jsrc] = 0.0\n    states[isrc, jsrc] = TRIAL\n    heapq.heappush(pq, (0.0, isrc, jsrc))\n\n    # 2. Main loop\n    while pq:\n        time, i, j = heapq.heappop(pq)\n\n        # If a better time has been found since this entry was added, skip.\n        if time > T[i, j]:\n            continue\n\n        states[i, j] = KNOWN\n\n        # 3. Update neighbors\n        # Iterate over neighbors (_ni, _nj) of the current node (i, j)\n        for _ni, _nj in [(i - 1, j), (i + 1, j), (i, j - 1), (i, j + 1)]:\n            # Check if neighbor is within grid and not already finalized\n            if 0 <= _ni < N and 0 <= _nj < N and states[_ni, _nj] != KNOWN:\n                \n                # Calculate new tentative time for the neighbor (_ni, _nj)\n                # by solving its local Eikonal equation.\n                \n                # Get minimum arrival time from x-direction neighbors of (_ni, _nj)\n                t_x_min = np.inf\n                if _ni > 0:\n                    t_x_min = min(t_x_min, T[_ni - 1, _nj])\n                if _ni < N - 1:\n                    t_x_min = min(t_x_min, T[_ni + 1, _nj])\n                \n                # Get minimum arrival time from y-direction neighbors of (_ni, _nj)\n                t_y_min = np.inf\n                if _nj > 0:\n                    t_y_min = min(t_y_min, T[_ni, _nj - 1])\n                if _nj < N - 1:\n                    t_y_min = min(t_y_min, T[_ni, _nj + 1])\n                \n                # If neither neighbor has a finite time, we can't update yet.\n                if not (np.isfinite(t_x_min) or np.isfinite(t_y_min)):\n                    continue\n\n                # Determine whether to use 1D or 2D update\n                if abs(t_x_min - t_y_min) >= slowness_h:\n                    t_new = min(t_x_min, t_y_min) + slowness_h\n                else:\n                    # Quadratic update\n                    discriminant = 2 * slowness_h**2 - (t_x_min - t_y_min)**2\n                    # Discriminant should be non-negative due to the condition above,\n                    # but floating point arithmetic may cause small negative values.\n                    discriminant = max(0, discriminant)\n                    t_new = (t_x_min + t_y_min + np.sqrt(discriminant)) / 2.0\n\n                # If the new time is an improvement, update and add to queue\n                if t_new < T[_ni, _nj]:\n                    T[_ni, _nj] = t_new\n                    if states[_ni, _nj] == UNSEEN:\n                        states[_ni, _nj] = TRIAL\n                    heapq.heappush(pq, (t_new, _ni, _nj))\n    \n    return T\n\ndef run_refinement_study(f0, source_coords):\n    \"\"\"\n    Performs a grid refinement study for a given case.\n\n    Args:\n        f0 (float): Constant wave speed.\n        source_coords (tuple): (x, y) coordinates of the source.\n\n    Returns:\n        list: A list of three median observed orders for L1, L2, Linf norms.\n    \"\"\"\n    grid_sizes = [33, 65, 129, 257]\n    errors = { \"l1\": [], \"l2\": [], \"linf\": [] }\n    h_values = []\n\n    for N in grid_sizes:\n        h = 1.0 / (N - 1)\n        h_values.append(h)\n\n        # Create grid\n        x = np.linspace(0.0, 1.0, N)\n        y = np.linspace(0.0, 1.0, N)\n        xx, yy = np.meshgrid(x, y, indexing='ij')\n\n        # Source index must be exactly on a node\n        isrc = int(round(source_coords[0] / h))\n        jsrc = int(round(source_coords[1] / h))\n\n        # Compute numerical solution\n        T_numerical = fast_marching(N, h, f0, (isrc, jsrc))\n        \n        # Compute analytic solution\n        T_analytic = np.sqrt((xx - source_coords[0])**2 + (yy - source_coords[1])**2) / f0\n        \n        # Compute errors\n        diff = np.abs(T_numerical - T_analytic)\n        \n        # L_infinity error\n        errors[\"linf\"].append(np.max(diff))\n        \n        # L1 error\n        errors[\"l1\"].append(h**2 * np.sum(diff))\n        \n        # L2 error\n        errors[\"l2\"].append(np.sqrt(h**2 * np.sum(diff**2)))\n\n    # Compute observed orders of accuracy\n    orders = []\n    log_h_ratio = np.log(0.5)\n    for norm in [\"l1\", \"l2\", \"linf\"]:\n        p_k = []\n        for i in range(len(grid_sizes) - 1):\n            # p_k = log(E_k+1 / E_k) / log(h_k+1 / h_k)\n            # handle cases where error is zero\n            if errors[norm][i+1] > 0 and errors[norm][i] > 0:\n                log_err_ratio = np.log(errors[norm][i+1] / errors[norm][i])\n                p_k.append(log_err_ratio / log_h_ratio)\n        \n        if not p_k:\n             # This can happen if error is consistently zero, implying perfect accuracy\n             # on the test grids. The theoretical order is then irrelevant.\n             # Or if there are not enough data points.\n             orders.append(np.nan)\n        else:\n             orders.append(np.median(p_k))\n\n    return orders\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Test suite specification\n    test_cases = [\n        {'f0': 1.0, 'source_coords': (0.5, 0.5)},  # Case A\n        {'f0': 2.0, 'source_coords': (0.5, 0.5)},  # Case B\n        {'f0': 1.0, 'source_coords': (0.0, 0.0)},  # Case C\n    ]\n\n    all_results = []\n    for case in test_cases:\n        orders = run_refinement_study(case['f0'], case['source_coords'])\n        all_results.extend(orders)\n    \n    # Format a string for the final output\n    result_str = \",\".join([f\"{r:.7f}\" for r in all_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3391181"}, {"introduction": "A theoretically correct algorithm can exhibit unexpected behavior due to the finite precision of floating-point arithmetic. This advanced practice explores a subtle yet critical implementation challenge in the FMM: the handling of near-identical arrival times that arise in symmetric scenarios [@problem_id:3391151]. By contrasting a naive tie-breaking strategy with a robust $\\varepsilon$-based grouping policy, you will learn to design algorithms that are resilient to numerical artifacts and produce reliable, symmetric results for symmetric problems.", "problem": "Consider the isotropic Eikonal equation arising in distance computation,\n$$\n\\|\\nabla T(\\mathbf{x})\\| = \\frac{1}{F(\\mathbf{x})},\n$$\nwhere $T(\\mathbf{x})$ is the arrival time of a front moving with speed $F(\\mathbf{x})$. The Fast Marching Method (FMM) is a single-pass algorithm that solves the discretized Eikonal equation on a regular grid by maintaining a narrow band of tentative arrival times and accepting the smallest tentative $T$ at each step to enforce causality and monotonicity. You will explore how floating-point roundoff and tie-breaking in the priority queue affect the order of acceptance when many tentative values are nearly equal, and you will design a robust comparison policy using an $\\varepsilon$-based grouping threshold.\n\nStarting from the fundamental definition of the Eikonal equation and the principle of monotone upwinding on a Cartesian grid with spacing $h$ in each coordinate direction, derive the local update rule for the tentative arrival time at a grid point using only already accepted neighbor values. Then implement two variants of FMM:\n\n- Variant A (Naive): Use a min-heap keyed only by tentative $T$ and break ties lexicographically by grid coordinates. At each iteration, accept exactly one grid point: the one with the smallest tentative $T$.\n- Variant B (Robust $\\varepsilon$-policy): Use a min-heap keyed by tentative $T$ and a stable insertion index, and introduce an $\\varepsilon$-based grouping criterion. At each iteration, pop the smallest tentative value $T_{\\min}$ and accept all grid points whose current tentative value $T$ satisfies\n$$\n|T - T_{\\min}| \\le \\varepsilon \\cdot \\max\\left(1, |T_{\\min}|\\right).\n$$\nAssign acceptance order numbers in the order they are popped under this grouping and then update neighbors. Justify the choice of a relative threshold of the form $\\varepsilon \\cdot \\max(1, |T_{\\min}|)$ based on floating-point rounding analysis.\n\nUse a two-dimensional square grid of size $N \\times N$ with $N = 61$, uniform spacing $h = 1$, and uniform speed $F(\\mathbf{x}) \\equiv 1$. Initialize a single source at the grid center with arrival time $T = 0$. For both variants, run FMM to completion and record, for a symmetric set of eight target points at index radius $r = 8$ from the center (the four axial points and the four points with index offsets $(\\pm 4, \\pm 7)$), the acceptance order index when each is accepted. Let $\\mathcal{I}$ denote the multiset of acceptance indices for these eight targets, and define the spread metric\n$$\nS = \\max(\\mathcal{I}) - \\min(\\mathcal{I}).\n$$\nAdditionally, define a tie-event count $C$ as follows:\n- For Variant A, at each iteration after identifying the current minimum tentative value $T_{\\min}$, count one tie event if the next heap minimum (without removing it) has a tentative value within a tolerance band\n$$\n|T_{\\text{next}} - T_{\\min}| \\le \\varepsilon_{\\text{count}} \\cdot \\max\\left(1, |T_{\\min}|\\right)\n$$\nwith $\\varepsilon_{\\text{count}} = 10^{-12}$.\n- For Variant B, count one tie event whenever the grouping at an iteration accepts more than one grid point.\n\nYour task is to implement a complete, runnable program that:\n1. Derives the upwind discrete update rule for the tentative $T$ from the Eikonal equation and applies it at each trial grid point using already accepted neighbors only.\n2. Implements Variant A and Variant B as described.\n3. Constructs and runs the following three test cases, all on the same grid and source configuration:\n   - Test Case 1: Variant A (Naive), $\\varepsilon_{\\text{count}} = 10^{-12}$.\n   - Test Case 2: Variant B (Robust) with $\\varepsilon = 10^{-16}$.\n   - Test Case 3: Variant B (Robust) with $\\varepsilon = 10^{-12}$.\nFor each test case, compute the spread $S$ over the eight symmetric targets and the tie-event count $C$ as defined above.\n\nScientific realism requirements:\n- Base your implementation on the isotropic Eikonal equation and monotone upwinding. Do not use any shortcut formulas that bypass derivation from these principles.\n- All quantities are dimensionless; no physical units are required.\n- Angles are not involved; do not use radians or degrees.\n\nFinal output specification:\n- Your program should produce a single line of output containing the six results in the order\n$$\n[S_1, C_1, S_2, C_2, S_3, C_3],\n$$\nwhere $S_k$ and $C_k$ are the spread and tie-event count for Test Case $k$, respectively. The output must be a comma-separated list enclosed in square brackets, for example, $[1,2,3,4,5,6]$.\n\nTest suite coverage justification:\n- Test Case $1$ exercises the naive acceptance under near-equality and captures lexicographic bias.\n- Test Case $2$ demonstrates that a too-small $\\varepsilon$ behaves similarly to the naive case.\n- Test Case $3$ demonstrates robust grouping with a practically chosen $\\varepsilon$, reducing acceptance-order asymmetry across symmetric targets.", "solution": "The problem requires the implementation and comparison of two variants of the Fast Marching Method (FMM) for solving the Eikonal equation, focusing on the effects of floating-point precision and tie-breaking on the algorithm's behavior.\n\n### Derivation of the Upwind Discretization\n\nThe isotropic Eikonal equation relates the magnitude of the gradient of an arrival time function $T(\\mathbf{x})$ to the local speed of propagation $F(\\mathbf{x})$:\n$$\n\\|\\nabla T(\\mathbf{x})\\| = \\frac{1}{F(\\mathbf{x})}\n$$\nOn a two-dimensional Cartesian grid with uniform spacing $h$, this equation can be written as:\n$$\n\\left(\\frac{\\partial T}{\\partial x}\\right)^2 + \\left(\\frac{\\partial T}{\\partial y}\\right)^2 = \\frac{1}{F^2}\n$$\nThe Fast Marching Method solves this equation by systematically advancing a front from a source. It relies on an upwind discretization, meaning the value of $T$ at a grid point $(i,j)$, denoted $T_{i,j}$, is computed using only information from neighboring points that the front has already passed, i.e., those with smaller arrival times. These \"passed\" points are tagged as `Accepted`.\n\nTo compute a new tentative arrival time $T$ for a point, we approximate the partial derivatives using one-sided finite differences involving its already `Accepted` neighbors. Let's consider the update for a point $(i,j)$. In the x-direction, its neighbors are $(i-1,j)$ and $(i+1,j)$. Let the minimum arrival time among its `Accepted` neighbors in the x-direction be $T_x = \\min(T_{i-1,j}, T_{i+1,j})$, where the minimum is taken only over `Accepted` points. Similarly, let $T_y$ be the minimum from the y-direction. The upwind scheme models the derivatives as:\n$$\n\\frac{\\partial T}{\\partial x} \\approx \\frac{T - T_x}{h}, \\quad \\frac{\\partial T}{\\partial y} \\approx \\frac{T - T_y}{h}\n$$\nSubstituting these into the Eikonal equation gives a discrete version:\n$$\n\\left(\\frac{T - T_x}{h}\\right)^2 + \\left(\\frac{T - T_y}{h}\\right)^2 = \\frac{1}{F^2}\n$$\nThis is a quadratic equation for the new arrival time $T$. Rearranging terms, we get:\n$$\n2T^2 - 2(T_x + T_y)T + (T_x^2 + T_y^2 - (h/F)^2) = 0\n$$\nSolving for $T$ using the quadratic formula yields:\n$$\nT = \\frac{2(T_x + T_y) \\pm \\sqrt{4(T_x + T_y)^2 - 8(T_x^2 + T_y^2 - (h/F)^2)}}{4} = \\frac{T_x + T_y \\pm \\sqrt{2(h/F)^2 - (T_x - T_y)^2}}{2}\n$$\nSince the arrival time must be greater than that of its upwind neighbors ($T > T_x$ and $T > T_y$), we take the positive root:\n$$\nT_{\\text{update}} = \\frac{T_x + T_y + \\sqrt{2(h/F)^2 - (T_x - T_y)^2}}{2}\n$$\nThis two-dimensional update is only physically meaningful if the discriminant is non-negative, i.e., $2(h/F)^2 \\ge (T_x - T_y)^2$. If this condition is not met, it implies the front is too steep to be accurately captured by a two-dimensional stencil, and the update is dominated by the neighbor with the globally smaller arrival time. Assuming, without loss of generality, that $T_x \\le T_y$, the update reduces to a one-dimensional problem:\n$$\n\\left(\\frac{T - T_x}{h}\\right)^2 = \\frac{1}{F^2} \\implies T_{\\text{update}} = T_x + \\frac{h}{F}\n$$\nThis also applies if an `Accepted` neighbor exists in only one of the two directions. For the specific parameters of this problem, $h=1$ and $F=1$, the update rules simplify to:\n1.  Let $T_a$ and $T_b$ be the minimum `Accepted` neighbor times in orthogonal directions, with $T_a \\le T_b$.\n2.  If only one direction provides an `Accepted` neighbor (time $T_a$), the update is $T = T_a + 1$.\n3.  If both are available, check the condition $2 \\ge (T_b - T_a)^2$.\n    - If true, use the 2D update: $T = \\frac{T_a + T_b + \\sqrt{2 - (T_b - T_a)^2}}{2}$.\n    - If false, use the 1D update: $T = T_a + 1$.\n\n### Justification of the Robust $\\varepsilon$-Policy\n\nThe acceptance criterion $|T - T_{\\min}| \\le \\varepsilon \\cdot \\max(1, |T_{\\min}|)$ provides a robust way to group nearly-equal floating-point values. It combines absolute and relative error tolerances.\n\n-   **Relative Tolerance**: For large values of $T_{\\min}$ (i.e., $|T_{\\min}| > 1$), the condition becomes $|T - T_{\\min}| \\le \\varepsilon |T_{\\min}|$, or $\\frac{|T - T_{\\min}|}{|T_{\\min}|} \\le \\varepsilon$. This is a standard relative error test. It is appropriate because floating-point numbers have precision relative to their magnitude. Due to the accumulation of roundoff errors during computation, values that are theoretically identical (e.g., for symmetrically located points) may differ by a tiny relative amount. This part of the criterion correctly groups them.\n\n-   **Absolute Tolerance**: For small values of $T_{\\min}$ (i.e., $|T_{\\min}| \\le 1$), including $T_{\\min}=0$ at the source, the condition simplifies to $|T - T_{\\min}| \\le \\varepsilon$. This sets a fixed absolute tolerance band. A purely relative tolerance would shrink towards zero as $T_{\\min} \\to 0$, failing to group any values and making the policy ineffective near the source.\n\nBy using $\\max(1, |T_{\\min}|)$, the policy gracefully transitions between an absolute tolerance for small arrival times and a relative tolerance for large ones, ensuring robust behavior across the entire computational domain.\n\n### Algorithmic Implementation\n\nThe FMM algorithm is implemented using a priority queue (min-heap) to manage `Trial` points, those on the narrow band of the advancing front. Points are categorized as `Far` (untouched), `Trial` (in the heap with a tentative $T$), or `Accepted` (finalized $T$).\n\n-   **Variant A (Naive)**: The heap stores tuples of `(T, i, j)`. Python's `heapq` naturally breaks ties on `T` by using the next elements in the tuple, `i` and then `j`, implementing a lexicographical tie-breaking rule. At each iteration, exactly one point is accepted. A tie-event is counted if the value just popped, $T_{\\min}$, and the new head of the heap, $T_{\\text{next}}$, are close within a given tolerance.\n\n-   **Variant B (Robust $\\varepsilon$-policy)**: The heap stores tuples of `(T, insertion_idx, i, j)`. The `insertion_idx` is a unique, incrementing counter that ensures stability: for identical $T$ values, the one inserted first is popped first. At each iteration, the point with minimum time $T_{\\min}$ is popped. Then, the algorithm continues to pop all other points from the heap whose time $T$ falls within the $\\varepsilon$-based tolerance band of $T_{\\min}$. All points in this group are accepted in the same logical step. A tie-event is counted if this group contains more than one point. After all points in the group are marked as `Accepted`, their neighbors are updated. This two-pass process (accept group, then update neighbors) ensures that the updates are based on the complete set of simultaneously accepted points, preventing the processing order within the group from affecting subsequent calculations.\n\nThe simulation is run for the three specified test cases, and the spread metric $S$ and tie-event count $C$ are computed for each.", "answer": "```python\nimport numpy as np\nimport heapq\n\n# Define constants for grid states to improve readability\nSTATE_FAR = 0\nSTATE_TRIAL = 1\nSTATE_ACCEPTED = 2\n\ndef get_update(h, F, state, T, i, j, N):\n    \"\"\"\n    Calculates the upwind discretized Eikonal update for T at grid point (i, j).\n    This function implements the derived update rule.\n    \"\"\"\n    \n    # Find minimum T values among accepted neighbors in x and y directions\n    tx_vals = []\n    if i > 0 and state[i - 1, j] == STATE_ACCEPTED:\n        tx_vals.append(T[i - 1, j])\n    if i < N - 1 and state[i + 1, j] == STATE_ACCEPTED:\n        tx_vals.append(T[i + 1, j])\n        \n    ty_vals = []\n    if j > 0 and state[i, j - 1] == STATE_ACCEPTED:\n        ty_vals.append(T[i, j - 1])\n    if j < N - 1 and state[i, j + 1] == STATE_ACCEPTED:\n        ty_vals.append(T[i, j + 1])\n\n    tx_min = min(tx_vals) if tx_vals else np.inf\n    ty_min = min(ty_vals) if ty_vals else np.inf\n\n    h_over_F = h / F\n    \n    # Determine which update rule to apply based on available neighbors\n    if tx_min == np.inf and ty_min == np.inf:\n        return np.inf\n\n    if tx_min == np.inf or ty_min == np.inf:\n        # 1D update if neighbors are only in one dimension\n        t_min_overall = min(tx_min, ty_min)\n        return t_min_overall + h_over_F\n    \n    # Potentially 2D update\n    ta, tb = sorted([tx_min, ty_min])\n    discriminant_term = 2 * (h_over_F**2) - (tb - ta)**2\n    \n    if discriminant_term < 0:\n        # Discriminant is negative, indicating a 1D update is more appropriate\n        return ta + h_over_F\n    else:\n        # 2D update\n        return (ta + tb + np.sqrt(discriminant_term)) / 2.0\n\n\ndef run_fmm(variant, N, h, F, eps=None, eps_count=None):\n    \"\"\"\n    Executes the Fast Marching Method for a given variant and parameters.\n    \"\"\"\n    T = np.full((N, N), np.inf, dtype=np.float64)\n    state = np.zeros((N, N), dtype=np.int8)\n    \n    center_x, center_y = N // 2, N // 2\n    \n    # Define the 8 symmetric target points for metric calculation\n    targets = {\n        (center_x + 8, center_y), (center_x - 8, center_y),\n        (center_x, center_y + 8), (center_x, center_y - 8),\n        (center_x + 4, center_y + 7), (center_x - 4, center_y + 7),\n        (center_x + 4, center_y - 7), (center_x - 4, center_y - 7),\n    }\n\n    # Initialize heap and source point\n    heap = []\n    insertion_idx = 0\n    T[center_x, center_y] = 0.0\n    state[center_x, center_y] = STATE_TRIAL\n    \n    if variant == 'A':\n        # Heap item: (T, i, j) for lexicographical tie-breaking\n        heapq.heappush(heap, (T[center_x, center_y], center_x, center_y))\n    else: # Variant B\n        # Heap item: (T, insertion_idx, i, j) for stable tie-breaking\n        heapq.heappush(heap, (T[center_x, center_y], insertion_idx, center_x, center_y))\n        insertion_idx += 1\n\n    # Metric-tracking variables\n    acceptance_order = 0\n    target_acceptance_orders = []\n    tie_count = 0\n    \n    while heap:\n        accepted_this_iter = []\n\n        if variant == 'A':\n            t_min, i, j = heapq.heappop(heap)\n            if state[i, j] == STATE_ACCEPTED:\n                continue\n\n            if heap:\n                t_next = heap[0][0]\n                if abs(t_next - t_min) <= eps_count * max(1.0, abs(t_min)):\n                    tie_count += 1\n            \n            accepted_this_iter.append((i, j))\n        else: # Variant B\n            t_min, _, i_min, j_min = heapq.heappop(heap)\n            if state[i_min, j_min] == STATE_ACCEPTED:\n                continue\n\n            accepted_this_iter.append((i_min, j_min))\n            \n            # Epsilon-grouping logic\n            while heap and (heap[0][0] - t_min) <= eps * max(1.0, t_min):\n                _, _, i_pop, j_pop = heapq.heappop(heap)\n                if state[i_pop, j_pop] != STATE_ACCEPTED:\n                    accepted_this_iter.append((i_pop, j_pop))\n            \n            if len(accepted_this_iter) > 1:\n                tie_count += 1\n\n        # Process all accepted nodes for this iteration in two passes\n        # Pass 1: Mark states and assign acceptance orders\n        nodes_to_update_neighbors_of = []\n        for i, j in accepted_this_iter:\n            state[i, j] = STATE_ACCEPTED\n            acceptance_order += 1\n            if (i, j) in targets:\n                target_acceptance_orders.append(acceptance_order)\n            nodes_to_update_neighbors_of.append((i, j))\n\n        # Pass 2: Update all neighbors of the newly accepted nodes\n        for i, j in nodes_to_update_neighbors_of:\n            for di, dj in [(-1, 0), (1, 0), (0, -1), (0, 1)]:\n                ni, nj = i + di, j + dj\n                \n                if not (0 <= ni < N and 0 <= nj < N) or state[ni, nj] == STATE_ACCEPTED:\n                    continue\n\n                t_new = get_update(h, F, state, T, ni, nj, N)\n                \n                if t_new < T[ni, nj]:\n                    T[ni, nj] = t_new\n                    if state[ni, nj] == STATE_FAR:\n                        state[ni, nj] = STATE_TRIAL\n                    \n                    if variant == 'A':\n                        heapq.heappush(heap, (t_new, ni, nj))\n                    else: # Variant B\n                        heapq.heappush(heap, (t_new, insertion_idx, ni, nj))\n                        insertion_idx += 1\n                        \n    # Final metric calculation\n    spread = max(target_acceptance_orders) - min(target_acceptance_orders) if len(target_acceptance_orders) == 8 else -1\n    return spread, tie_count\n\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print results.\n    \"\"\"\n    test_cases = [\n        {'variant': 'A', 'eps_count': 1e-12}, # Test Case 1\n        {'variant': 'B', 'eps': 1e-16},       # Test Case 2\n        {'variant': 'B', 'eps': 1e-12},       # Test Case 3\n    ]\n\n    results = []\n    for params in test_cases:\n        spread, count = run_fmm(N=61, h=1.0, F=1.0, **params)\n        results.extend([spread, count])\n\n    # Print the final output in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3391151"}]}