{"hands_on_practices": [{"introduction": "To solidify the theoretical concepts of body-fitted coordinates, we begin with a foundational practice. A coordinate transformation is only useful if it is non-degenerate, meaning that the grid lines do not cross and grid cells do not fold over themselves. This essential property is governed by the sign of the Jacobian determinant, $J$. This exercise [@problem_id:3367212] provides direct practice in calculating the Jacobian for a given transformation and analyzing the conditions required to ensure its positivity, the mathematical guarantee of a valid grid.", "problem": "Consider a two-dimensional body-fitted mapping from a computational domain to a physical domain, as commonly used in the numerical solution of partial differential equations (PDEs) on curved geometries. Let the computational coordinates be $(\\xi,\\eta)\\in[0,1]^{2}$ and the physical coordinates be $(x,y)$ defined by the smooth transformation\n$$\nx(\\xi,\\eta)=\\xi+\\alpha\\,\\xi\\,\\eta,\\qquad y(\\xi,\\eta)=\\eta+\\beta\\,\\xi^{2},\n$$\nwhere $\\alpha$ and $\\beta$ are real constants. The Jacobian determinant $J(\\xi,\\eta)$ of the map is defined by the determinant of the $2\\times 2$ matrix of partial derivatives of $(x,y)$ with respect to $(\\xi,\\eta)$, and positivity of $J$ on $[0,1]^{2}$ is a necessary condition for the mapping to be orientation-preserving and nondegenerate (grid cells do not fold).\n\nStarting from the fundamental definition of the Jacobian determinant in coordinate transformations, derive $J(\\xi,\\eta)$ for the given map and determine the parameter ranges on $(\\alpha,\\beta)$ that ensure $J(\\xi,\\eta)>0$ for all $(\\xi,\\eta)\\in[0,1]^{2}$. Your derivation must proceed from first principles and justify all steps in the minimization needed to certify positivity on the entire square.\n\nAnswer specification:\n- Provide your final answer as a single closed-form analytic expression for the minimum value of $J(\\xi,\\eta)$ over $[0,1]^{2}$ in terms of $\\alpha$ and $\\beta$ only. This expression characterizes the positivity condition $J>0$ by requiring the minimum to be strictly positive.\n- Do not include inequalities or equations in the final answer.\n- No units are required. No rounding is required.", "solution": "The problem is to determine the range of parameters $(\\alpha, \\beta)$ for which the Jacobian determinant $J(\\xi, \\eta)$ of a given coordinate transformation is strictly positive over the computational domain $(\\xi, \\eta) \\in [0, 1]^2$. This is equivalent to finding the global minimum of $J(\\xi, \\eta)$ on this domain and requiring it to be greater than zero. The problem explicitly asks for the analytical expression for this minimum value.\n\nFirst, we define the Jacobian matrix of the transformation from computational coordinates $(\\xi, \\eta)$ to physical coordinates $(x, y)$. The transformation is given by:\n$$\nx(\\xi, \\eta) = \\xi + \\alpha \\xi \\eta \\\\\ny(\\xi, \\eta) = \\eta + \\beta \\xi^2\n$$\nThe Jacobian matrix $\\mathbf{J}$ is defined as:\n$$\n\\mathbf{J}(\\xi, \\eta) = \\begin{pmatrix} \\frac{\\partial x}{\\partial \\xi} & \\frac{\\partial x}{\\partial \\eta} \\\\ \\frac{\\partial y}{\\partial \\xi} & \\frac{\\partial y}{\\partial \\eta} \\end{pmatrix}\n$$\nWe compute the necessary partial derivatives:\n$$\n\\frac{\\partial x}{\\partial \\xi} = \\frac{\\partial}{\\partial \\xi} (\\xi + \\alpha \\xi \\eta) = 1 + \\alpha \\eta \\\\\n\\frac{\\partial x}{\\partial \\eta} = \\frac{\\partial}{\\partial \\eta} (\\xi + \\alpha \\xi \\eta) = \\alpha \\xi \\\\\n\\frac{\\partial y}{\\partial \\xi} = \\frac{\\partial}{\\partial \\xi} (\\eta + \\beta \\xi^2) = 2 \\beta \\xi \\\\\n\\frac{\\partial y}{\\partial \\eta} = \\frac{\\partial}{\\partial \\eta} (\\eta + \\beta \\xi^2) = 1\n$$\nThe Jacobian determinant, $J(\\xi, \\eta) = \\det(\\mathbf{J})$, is therefore:\n$$\nJ(\\xi, \\eta) = \\left(\\frac{\\partial x}{\\partial \\xi}\\right) \\left(\\frac{\\partial y}{\\partial \\eta}\\right) - \\left(\\frac{\\partial x}{\\partial \\eta}\\right) \\left(\\frac{\\partial y}{\\partial \\xi}\\right)\n$$\nSubstituting the partial derivatives, we obtain:\n$$\nJ(\\xi, \\eta) = (1 + \\alpha \\eta)(1) - (\\alpha \\xi)(2 \\beta \\xi) = 1 + \\alpha \\eta - 2 \\alpha \\beta \\xi^2\n$$\nOur task is to find the minimum value of this function, $J_{min}$, on the compact domain $[0,1]^2 = \\{(\\xi, \\eta) \\mid 0 \\le \\xi \\le 1, 0 \\le \\eta \\le 1\\}$.\n\nThe expression for $J(\\xi, \\eta)$ is a polynomial in $\\xi$ and $\\eta$ and is therefore continuous on the closed, bounded domain $[0,1]^2$. By the Extreme Value Theorem, a global minimum exists and must be attained either at a critical point in the interior of the domain, $(0,1)^2$, or on its boundary.\n\nThe partial derivatives of $J$ with respect to $\\xi$ and $\\eta$ are:\n$$\n\\frac{\\partial J}{\\partial \\xi} = -4 \\alpha \\beta \\xi \\\\\n\\frac{\\partial J}{\\partial \\eta} = \\alpha\n$$\nFor an interior critical point, we would need $\\frac{\\partial J}{\\partial \\eta} = 0$, which implies $\\alpha = 0$. If $\\alpha=0$, then $J(\\xi, \\eta) = 1$ for all $(\\xi, \\eta)$, and its minimum is $1$. In the case where $\\alpha \\neq 0$, there are no critical points in the interior of the domain. Therefore, the minimum value of $J(\\xi, \\eta)$ must be attained on the boundary of the square $[0,1]^2$.\n\nA more direct approach is to analyze the structure of $J(\\xi, \\eta) = 1 + \\alpha \\eta - 2 \\alpha \\beta \\xi^2$. Let us define new variables $u = \\eta$ and $v = \\xi^2$. As $(\\xi, \\eta)$ sweeps the domain $[0,1]^2$, the point $(u, v)$ also sweeps the unit square $[0,1]^2$. In terms of these new variables, the Jacobian becomes a linear function:\n$$\nL(u, v) = 1 + \\alpha u - 2 \\alpha \\beta v\n$$\nThe problem is transformed into finding the minimum of a linear function $L(u,v)$ over the unit square $(u,v) \\in [0,1]^2$. The minimum (and maximum) of a linear function over a convex polygon must occur at one of its vertices. The vertices of the unit square in the $(u,v)$-plane are $(0,0)$, $(1,0)$, $(0,1)$, and $(1,1)$.\n\nWe evaluate $L(u,v)$ at these four vertices:\n1. At $(u,v) = (0,0)$ (corresponding to $(\\xi,\\eta)=(0,0)$): $L(0,0) = 1$.\n\n2. At $(u,v) = (1,0)$ (corresponding to $(\\xi,\\eta)=(0,1)$): $L(1,0) = 1 + \\alpha$.\n\n3. At $(u,v) = (0,1)$ (corresponding to $(\\xi,\\eta)=(1,0)$): $L(0,1) = 1 - 2 \\alpha \\beta$.\n\n4. At $(u,v) = (1,1)$ (corresponding to $(\\xi,\\eta)=(1,1)$): $L(1,1) = 1 + \\alpha - 2 \\alpha \\beta$.\n\nThe global minimum of $J(\\xi, \\eta)$ on $[0,1]^2$ is the minimum of these four values:\n$$\nJ_{min} = \\min \\{1, 1+\\alpha, 1-2\\alpha\\beta, 1+\\alpha-2\\alpha\\beta\\}\n$$\nThis expression can be simplified into a single closed-form analytic expression. We can group the terms:\n$$\nJ_{min} = \\min \\left( \\min\\{1, 1+\\alpha\\}, \\min\\{1-2\\alpha\\beta, 1+\\alpha-2\\alpha\\beta\\} \\right)\n$$\nThe first inner minimum is $\\min\\{1, 1+\\alpha\\} = 1 + \\min\\{0, \\alpha\\}$.\nThe second inner minimum is $\\min\\{1-2\\alpha\\beta, (1-2\\alpha\\beta)+\\alpha\\} = 1-2\\alpha\\beta + \\min\\{0, \\alpha\\}$.\nSo, the expression becomes:\n$$\nJ_{min} = \\min \\left( 1 + \\min\\{0, \\alpha\\}, 1-2\\alpha\\beta + \\min\\{0, \\alpha\\} \\right)\n$$\nFactoring out the common term $1 + \\min\\{0, \\alpha\\}$ gives:\n$$\nJ_{min} = 1 + \\min\\{0, \\alpha\\} + \\min\\{0, -2\\alpha\\beta\\}\n$$\nTo express this using elementary functions and absolute values, we use the identities $\\min\\{0, x\\} = \\frac{x - |x|}{2}$ and $|xy| = |x||y|$.\n$$\n\\min\\{0, \\alpha\\} = \\frac{\\alpha - |\\alpha|}{2}\n$$\n$$\n\\min\\{0, -2\\alpha\\beta\\} = \\frac{-2\\alpha\\beta - |-2\\alpha\\beta|}{2} = \\frac{-2\\alpha\\beta - 2|\\alpha\\beta|}{2} = - \\alpha\\beta - |\\alpha\\beta|\n$$\nSubstituting these into the expression for $J_{min}$:\n$$\nJ_{min} = 1 + \\frac{\\alpha - |\\alpha|}{2} - \\alpha\\beta - |\\alpha\\beta|\n$$\nThis is the single closed-form analytic expression for the minimum value of the Jacobian determinant over the specified domain. The condition for a valid, non-degenerate mapping is $J_{min} > 0$.", "answer": "$$\n\\boxed{1 + \\frac{\\alpha - |\\alpha|}{2} - \\alpha\\beta - |\\alpha\\beta|}\n$$", "id": "3367212"}, {"introduction": "Moving from continuous theory to discrete computation requires careful handling of geometric information. It is not enough for the continuous mapping to be valid; the discrete representation of the grid's metric terms must be consistent with the discrete differential operators. This principle is encapsulated in the Geometric Conservation Law (GCL), a discrete identity that ensures a uniform flow field remains uniform on the curvilinear grid. This computational practice [@problem_id:3367290] guides you through constructing discrete metrics that satisfy the GCL and verifying the crucial property of free-stream preservation.", "problem": "Consider a two-dimensional body-fitted coordinate transformation mapping computational coordinates $(\\xi,\\eta)\\in[0,1]\\times[0,1]$ (with periodic boundary conditions) to physical coordinates $(x,y)$ via smooth functions $x(\\xi,\\eta)$ and $y(\\xi,\\eta)$. Let the Jacobian determinant be defined by $J = \\det\\left(\\frac{\\partial(x,y)}{\\partial(\\xi,\\eta)}\\right)$, and let $\\boldsymbol{a}^{i}$ denote the contravariant basis vectors associated with the transformation. The conservative linear advection equation for a scalar field $q(x,y,t)$ with constant velocity $(u,v)$ in the physical domain can be written in the computational domain in a flux-divergence form using transformed fluxes and geometric metrics built from $J\\boldsymbol{a}^{i}$.\n\nYour task is to design and implement a discrete approximation for $J\\boldsymbol{a}^{i}$ on a structured, collocated, uniform grid in $(\\xi,\\eta)$ using second-order centered finite differences, such that the discrete metric identity $D_{\\xi}\\left(J\\boldsymbol{a}^{1}\\right) + D_{\\eta}\\left(J\\boldsymbol{a}^{2}\\right) = \\boldsymbol{0}$ is satisfied exactly under periodic boundary conditions, where $D_{\\xi}$ and $D_{\\eta}$ are the discrete partial derivative operators with respect to $\\xi$ and $\\eta$. Starting from the chain rule and the definition of the Jacobian determinant and contravariant basis, derive how to assemble $J\\boldsymbol{a}^{i}$ from discrete spatial derivatives in a manner that enforces the discrete metric identity. Then, using the resulting metrics, demonstrate free-stream preservation for the discrete conservative linear advection operator: for a constant field $q(\\xi,\\eta)=q_{0}$ and constant velocity $(u,v)$, show that the semi-discrete operator applied to $q$ produces a zero residual when constructed consistently with the same difference operators used in the metric approximation.\n\nUse the following test suite in your program. For each test, define the mapping by\n$$\nx(\\xi,\\eta) = \\xi + \\alpha \\sin(2\\pi \\xi)\\sin(2\\pi \\eta),\\qquad\ny(\\xi,\\eta) = \\eta + \\beta \\cos(2\\pi \\xi)\\sin(2\\pi \\eta),\n$$\nwith periodicity in both directions, and discretize the domain with a uniform, periodic grid of size $N_{\\xi}\\times N_{\\eta}$ and spacings $\\Delta \\xi = \\tfrac{1}{N_{\\xi}}$, $\\Delta \\eta = \\tfrac{1}{N_{\\eta}}$. Use a centered difference stencil with periodic wrapping for $D_{\\xi}$ and $D_{\\eta}$. For each case, set $q_{0} = 1$ (dimensionless), and compute:\n- The maximum absolute value of each component of $D_{\\xi}\\left(J\\boldsymbol{a}^{1}\\right) + D_{\\eta}\\left(J\\boldsymbol{a}^{2}\\right)$ over the grid.\n- The maximum absolute value of the discrete conservative advection residual $D_{\\xi}(F^{\\xi}) + D_{\\eta}(F^{\\eta})$, where the fluxes $F^{\\xi}$ and $F^{\\eta}$ are the transformed fluxes built consistently from $J\\boldsymbol{a}^{i}$ and the constant velocity $(u,v)$.\n\nDeclare success for the discrete metric identity if the maximum absolute value of both components is less than a tolerance $\\varepsilon = 10^{-12}$, and declare free-stream preservation success if the maximum absolute value of the residual is less than the same tolerance $\\varepsilon = 10^{-12}$.\n\nTest suite:\n- Case $1$: $N_{\\xi} = 64$, $N_{\\eta} = 64$, $\\alpha = 0.2$, $\\beta = 0.15$, $u = 0.8$, $v = -0.3$.\n- Case $2$: $N_{\\xi} = 32$, $N_{\\eta} = 48$, $\\alpha = 0.0$, $\\beta = 0.0$, $u = 1.0$, $v = 0.4$.\n- Case $3$: $N_{\\xi} = 33$, $N_{\\eta} = 33$, $\\alpha = 0.25$, $\\beta = 0.05$, $u = 0.0$, $v = 0.0$.\n- Case $4$: $N_{\\xi} = 5$, $N_{\\eta} = 7$, $\\alpha = 0.1$, $\\beta = -0.08$, $u = -0.5$, $v = 0.9$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as $[\\text{metric\\_ok\\_case1},\\text{free\\_ok\\_case1},\\text{metric\\_ok\\_case2},\\text{free\\_ok\\_case2},\\ldots]$, where each entry is a boolean indicating whether the corresponding check passed under the tolerance $\\varepsilon = 10^{-12}$. No physical units or angle units are involved, and all quantities are dimensionless.", "solution": "The problem requires the design of a discrete approximation for the geometric metrics of a curvilinear coordinate system, specifically the quantities $J\\boldsymbol{a}^{1}$ and $J\\boldsymbol{a}^{2}$, such that the discrete geometric identity is satisfied exactly. This property is then used to demonstrate free-stream preservation for a conservative advection scheme.\n\nLet the physical coordinates $(x, y)$ be functions of the computational coordinates $(\\xi, \\eta)$. The position vector is $\\boldsymbol{r}(\\xi, \\eta) = x(\\xi, \\eta)\\boldsymbol{i} + y(\\xi, \\eta)\\boldsymbol{j}$. The covariant basis vectors are defined as the partial derivatives of the position vector with respect to the computational coordinates:\n$$\n\\boldsymbol{e}_{1} = \\frac{\\partial \\boldsymbol{r}}{\\partial \\xi} = \\frac{\\partial x}{\\partial \\xi}\\boldsymbol{i} + \\frac{\\partial y}{\\partial \\xi}\\boldsymbol{j}\n$$\n$$\n\\boldsymbol{e}_{2} = \\frac{\\partial \\boldsymbol{r}}{\\partial \\eta} = \\frac{\\partial x}{\\partial \\eta}\\boldsymbol{i} + \\frac{\\partial y}{\\partial \\eta}\\boldsymbol{j}\n$$\nThe contravariant basis vectors, $\\boldsymbol{a}^{1}$ and $\\boldsymbol{a}^{2}$, are defined by the relation $\\boldsymbol{a}^{i} \\cdot \\boldsymbol{e}_{j} = \\delta^{i}_{j}$, where $\\delta^{i}_{j}$ is the Kronecker delta. The Jacobian determinant of the transformation is $J = x_{\\xi}y_{\\eta} - x_{\\eta}y_{\\xi}$.\nSolving for the contravariant basis vectors yields:\n$$\n\\boldsymbol{a}^{1} = \\frac{1}{J}\\left( y_{\\eta}\\boldsymbol{i} - x_{\\eta}\\boldsymbol{j} \\right)\n$$\n$$\n\\boldsymbol{a}^{2} = \\frac{1}{J}\\left( -y_{\\xi}\\boldsymbol{i} + x_{\\xi}\\boldsymbol{j} \\right)\n$$\nThe quantities of interest are the contravariant basis vectors scaled by the Jacobian, $J\\boldsymbol{a}^{i}$:\n$$\nJ\\boldsymbol{a}^{1} = y_{\\eta}\\boldsymbol{i} - x_{\\eta}\\boldsymbol{j} = \\begin{pmatrix} y_{\\eta} \\\\ -x_{\\eta} \\end{pmatrix}\n$$\n$$\nJ\\boldsymbol{a}^{2} = -y_{\\xi}\\boldsymbol{i} + x_{\\xi}\\boldsymbol{j} = \\begin{pmatrix} -y_{\\xi} \\\\ x_{\\xi} \\end{pmatrix}\n$$\nIn the continuous case, these metrics satisfy the identity $\\frac{\\partial}{\\partial \\xi}(J\\boldsymbol{a}^{1}) + \\frac{\\partial}{\\partial \\eta}(J\\boldsymbol{a}^{2}) = \\boldsymbol{0}$. This is a direct consequence of the equality of mixed partial derivatives for smooth functions (Clairaut's theorem):\n$$\n\\frac{\\partial}{\\partial \\xi}(J\\boldsymbol{a}^{1}) + \\frac{\\partial}{\\partial \\eta}(J\\boldsymbol{a}^{2}) = \\frac{\\partial}{\\partial \\xi}\\begin{pmatrix} y_{\\eta} \\\\ -x_{\\eta} \\end{pmatrix} + \\frac{\\partial}{\\partial \\eta}\\begin{pmatrix} -y_{\\xi} \\\\ x_{\\xi} \\end{pmatrix} = \\begin{pmatrix} y_{\\eta\\xi} - y_{\\xi\\eta} \\\\ -x_{\\eta\\xi} + x_{\\xi\\eta} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\boldsymbol{0}\n$$\n\nThe goal is to preserve this identity in the discrete sense. We discretize the computational domain $[0,1]\\times[0,1]$ with a uniform grid of $N_{\\xi} \\times N_{\\eta}$ points, with grid spacings $\\Delta\\xi = 1/N_{\\xi}$ and $\\Delta\\eta = 1/N_{\\eta}$. We define second-order centered difference operators, $D_{\\xi}$ and $D_{\\eta}$, for any grid function $f_{i,j} = f(i\\Delta\\xi, j\\Delta\\eta)$:\n$$\n(D_{\\xi} f)_{i,j} = \\frac{f_{i+1,j} - f_{i-1,j}}{2\\Delta\\xi}\n$$\n$$\n(D_{\\eta} f)_{i,j} = \\frac{f_{i,j+1} - f_{i,j-1}}{2\\Delta\\eta}\n$$\nwhere indices are handled periodically. The crucial insight is to construct the discrete metrics by directly replacing the partial derivatives in the expressions for $J\\boldsymbol{a}^{i}$ with these difference operators. Let $(\\tilde{G}^{1})_{i,j}$ and $(\\tilde{G}^{2})_{i,j}$ be the discrete approximations of $(J\\boldsymbol{a}^{1})_{i,j}$ and $(J\\boldsymbol{a}^{2})_{i,j}$.\n$$\n(\\tilde{G}^{1})_{i,j} = \\begin{pmatrix} (D_{\\eta} y)_{i,j} \\\\ -(D_{\\eta} x)_{i,j} \\end{pmatrix}\n$$\n$$\n(\\tilde{G}^{2})_{i,j} = \\begin{pmatrix} -(D_{\\xi} y)_{i,j} \\\\ (D_{\\xi} x)_{i,j} \\end{pmatrix}\n$$\nNow, we apply the discrete divergence operator to these discrete metrics:\n$$\nD_{\\xi}(\\tilde{G}^{1}) + D_{\\eta}(\\tilde{G}^{2}) = D_{\\xi}\\begin{pmatrix} D_{\\eta} y \\\\ -D_{\\eta} x \\end{pmatrix} + D_{\\eta}\\begin{pmatrix} -D_{\\xi} y \\\\ D_{\\xi} x \\end{pmatrix} = \\begin{pmatrix} D_{\\xi}D_{\\eta}y - D_{\\eta}D_{\\xi}y \\\\ -D_{\\xi}D_{\\eta}x + D_{\\eta}D_{\\xi}x \\end{pmatrix}\n$$\nThe standard second-order centered difference operators commute, meaning $D_{\\xi}D_{\\eta}f = D_{\\eta}D_{\\xi}f$ for any grid function $f$. This can be shown by writing out the stencils. Therefore, each component of the resulting vector is identically zero. This proves that this specific construction of the discrete metrics satisfies the metric identity $D_{\\xi}(\\tilde{G}^{1}) + D_{\\eta}(\\tilde{G}^{2}) = \\boldsymbol{0}$ exactly (up to machine precision).\n\nNext, we demonstrate free-stream preservation. The conservative linear advection equation for a scalar $q$ with constant velocity $\\boldsymbol{v} = (u,v)$ in physical space, $\\frac{\\partial q}{\\partial t} + \\nabla \\cdot (\\boldsymbol{v}q) = 0$, transforms to computational space as:\n$$\n\\frac{\\partial (Jq)}{\\partial t} + \\frac{\\partial F^{\\xi}}{\\partial \\xi} + \\frac{\\partial F^{\\eta}}{\\partial \\eta} = 0\n$$\nwhere the transformed fluxes are $F^{\\xi} = q (\\boldsymbol{v} \\cdot J\\boldsymbol{a}^{1})$ and $F^{\\eta} = q (\\boldsymbol{v} \\cdot J\\boldsymbol{a}^{2})$.\nIn semi-discrete form, the spatial operator (residual) at grid point $(i,j)$ is $R_{i,j} = D_{\\xi}(F^{\\xi})_{i,j} + D_{\\eta}(F^{\\eta})_{i,j}$. For the free-stream condition, the scalar field is constant, $q=q_0$, and the velocity $(u,v)$ is constant. The discrete fluxes are constructed consistently with the metrics:\n$$\n(F^{\\xi})_{i,j} = q_{0} \\left( u (\\tilde{G}^{1}_{x})_{i,j} + v (\\tilde{G}^{1}_{y})_{i,j} \\right) = q_0 \\left( u (D_{\\eta}y)_{i,j} - v (D_{\\eta}x)_{i,j} \\right)\n$$\n$$\n(F^{\\eta})_{i,j} = q_{0} \\left( u (\\tilde{G}^{2}_{x})_{i,j} + v (\\tilde{G}^{2}_{y})_{i,j} \\right) = q_0 \\left( -u (D_{\\xi}y)_{i,j} + v (D_{\\xi}x)_{i,j} \\right)\n$$\nThe discrete residual is the divergence of these fluxes:\n$$\nR_{i,j} = D_{\\xi} \\left( q_0 ( u D_{\\eta}y - v D_{\\eta}x ) \\right)_{i,j} + D_{\\eta} \\left( q_0 ( -u D_{\\xi}y + v D_{\\xi}x ) \\right)_{i,j}\n$$\nSince $q_0$, $u$, and $v$ are constants, they can be factored out of the difference operators:\n$$\nR_{i,j} = q_0 u \\left( D_{\\xi}D_{\\eta}y - D_{\\eta}D_{\\xi}y \\right)_{i,j} - q_0 v \\left( D_{\\xi}D_{\\eta}x - D_{\\eta}D_{\\xi}x \\right)_{i,j}\n$$\nAs established before, the operators commute, so $(D_{\\xi}D_{\\eta}y - D_{\\eta}D_{\\xi}y)_{i,j} = 0$ and $(D_{\\xi}D_{\\eta}x - D_{\\eta}D_{\\xi}x)_{i,j} = 0$. Consequently, the residual $R_{i,j}=0$ for all $(i,j)$. This demonstrates that a constant initial field remains constant, a property known as free-stream preservation. This is a crucial property for a numerical scheme to accurately simulate uniform flows on curvilinear grids without introducing artificial sources or sinks. The implementation below follows this derivation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and implements discrete geometric metrics for a body-fitted coordinate system\n    that satisfy the discrete metric identity and demonstrates free-stream preservation for\n    a conservative linear advection operator.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N_xi, N_eta, alpha, beta, u, v)\n        (64, 64, 0.2, 0.15, 0.8, -0.3),\n        (32, 48, 0.0, 0.0, 1.0, 0.4),\n        (33, 33, 0.25, 0.05, 0.0, 0.0),\n        (5, 7, 0.1, -0.08, -0.5, 0.9),\n    ]\n\n    tolerance = 1e-12\n    results = []\n\n    for case in test_cases:\n        N_xi, N_eta, alpha, beta, u, v = case\n        \n        # 1. Grid Generation\n        d_xi = 1.0 / N_xi\n        d_eta = 1.0 / N_eta\n        \n        # Create computational coordinate grid\n        xi_vec = np.linspace(0.0, 1.0, N_xi, endpoint=False)\n        eta_vec = np.linspace(0.0, 1.0, N_eta, endpoint=False)\n        \n        # Use 'xy' indexing for (N_eta, N_xi) shaped arrays,\n        # where xi varies along axis 1 (columns) and eta along axis 0 (rows).\n        xi_grid, eta_grid = np.meshgrid(xi_vec, eta_vec, indexing='xy')\n        \n        # Compute physical coordinates using the mapping functions\n        x_grid = xi_grid + alpha * np.sin(2 * np.pi * xi_grid) * np.sin(2 * np.pi * eta_grid)\n        y_grid = eta_grid + beta * np.cos(2 * np.pi * xi_grid) * np.sin(2 * np.pi * eta_grid)\n        \n        # 2. Discrete Operators and Metric Calculation\n        def diff_xi(f):\n            \"\"\"Second-order centered difference in xi (axis=1) with periodic BC.\"\"\"\n            return (np.roll(f, -1, axis=1) - np.roll(f, 1, axis=1)) / (2 * d_xi)\n        \n        def diff_eta(f):\n            \"\"\"Second-order centered difference in eta (axis=0) with periodic BC.\"\"\"\n            return (np.roll(f, -1, axis=0) - np.roll(f, 1, axis=0)) / (2 * d_eta)\n        \n        # Calculate discrete partial derivatives of coordinates\n        dx_dxi = diff_xi(x_grid)\n        dx_deta = diff_eta(x_grid)\n        dy_dxi = diff_xi(y_grid)\n        dy_deta = diff_eta(y_grid)\n        \n        # Assemble the discrete metrics J*a^i\n        # G1 corresponds to tilde{G}^1 = J*a^1\n        G1_x = dy_deta\n        G1_y = -dx_deta\n        \n        # G2 corresponds to tilde{G}^2 = J*a^2\n        G2_x = -dy_dxi\n        G2_y = dx_dxi\n        \n        # 3. Check Metric Identity\n        # This is D_xi(J*a^1) + D_eta(J*a^2)\n        metric_identity_x = diff_xi(G1_x) + diff_eta(G2_x)\n        metric_identity_y = diff_xi(G1_y) + diff_eta(G2_y)\n        \n        # Find the maximum absolute error over the grid\n        max_err_x = np.max(np.abs(metric_identity_x))\n        max_err_y = np.max(np.abs(metric_identity_y))\n        \n        metric_ok = max_err_x  tolerance and max_err_y  tolerance\n        results.append(metric_ok)\n        \n        # 4. Check Free-Stream Preservation\n        q0 = 1.0  # Constant scalar field\n        \n        # Compute transformed fluxes F^xi and F^eta\n        flux_xi = q0 * (u * G1_x + v * G1_y)\n        flux_eta = q0 * (u * G2_x + v * G2_y)\n        \n        # Compute the discrete divergence of the fluxes (the residual)\n        residual = diff_xi(flux_xi) + diff_eta(flux_eta)\n        \n        # Find the maximum absolute residual over the grid\n        max_residual = np.max(np.abs(residual))\n        \n        free_ok = max_residual  tolerance\n        results.append(free_ok)\n\n    # Final print statement in the exact required format.\n    # The map to str converts booleans to 'True'/'False'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3367290"}, {"introduction": "Real-world geometries are often too complex to be meshed with a single structured block. The multi-block approach resolves this by decomposing the domain into simpler quadrilaterals, but introduces the new challenge of ensuring continuity and smoothness across block interfaces. In this comprehensive exercise [@problem_id:3367293], you will use the powerful technique of Transfinite Interpolation (TFI) to build a two-block grid around a curved interface. You will then perform a critical analysis of the interface's continuity and smoothness ($C^0$ and $C^1$ properties) and quantify how grid quality directly impacts the accuracy of numerical gradient calculations.", "problem": "Construct a two-dimensional multi-block body-fitted grid using transfinite interpolation and quantify interface smoothness and its impact on numerical gradient accuracy. The computational domain in each block is the unit square with computational coordinates $(\\xi,\\eta)\\in[0,1]\\times[0,1]$. The physical domain is the unit square in $(x,y)$, but with a wavy internal interface that separates the domain into two quadrilateral blocks. The interface is defined by the curve $x=\\tfrac{1}{2}+a\\sin(\\pi\\eta)$ and $y=\\eta$, where $a\\in[0,1)$ is an amplitude parameter and the sine function takes its argument in radians.\n\nBlock definitions in physical space, given a fixed amplitude $a$, are as follows:\n- Left block: bounded by the left vertical line $x=0$ for $y\\in[0,1]$, the bottom horizontal line $y=0$ for $x\\in[0,\\tfrac{1}{2}]$, the top horizontal line $y=1$ for $x\\in[0,\\tfrac{1}{2}]$, and the wavy interface $x=\\tfrac{1}{2}+a\\sin(\\pi\\eta)$ for $\\eta\\in[0,1]$.\n- Right block: bounded by the right vertical line $x=1$ for $y\\in[0,1]$, the bottom horizontal line $y=0$ for $x\\in[\\tfrac{1}{2},1]$, the top horizontal line $y=1$ for $x\\in[\\tfrac{1}{2},1]$, and the same wavy interface $x=\\tfrac{1}{2}+a\\sin(\\pi\\eta)$ for $\\eta\\in[0,1]$.\n\nStarting from the fundamental definition of transfinite interpolation for quadrilateral patches, derive a mapping for each block from $(\\xi,\\eta)$ to $(x(\\xi,\\eta),y(\\xi,\\eta))$ that exactly interpolates the four boundary curves of that block. Construct both blocks’ mappings so that the physical positions on the shared interface are identical for all $\\eta$. Use a uniform tensor-product grid in $(\\xi,\\eta)$ with $N_\\xi$ points in the $\\xi$-direction and $N_\\eta$ points in the $\\eta$-direction, where $(N_\\xi,N_\\eta)$ is specified per test case.\n\nDefine the covariant base vectors and Jacobian using the core differential geometric definitions for curvilinear coordinates:\n- $x_\\xi=\\partial x/\\partial \\xi$, $y_\\xi=\\partial y/\\partial \\xi$, $x_\\eta=\\partial x/\\partial \\eta$, $y_\\eta=\\partial y/\\partial \\eta$,\n- $J=x_\\xi y_\\eta - x_\\eta y_\\xi$.\n\nAll derivatives with respect to $\\xi$ and $\\eta$ must be approximated by second-order accurate finite differences on the uniform grid: use centered differences for interior points and one-sided second-order approximations at the boundaries.\n\nLet the analytic scalar field be $u(x,y)=\\sin(\\pi x)\\cos(\\pi y)$. Denoting $u_\\xi$ and $u_\\eta$ as the derivatives of $u$ with respect to computational coordinates, the physical gradient $(u_x,u_y)$ is obtained by the chain rule using the inverse Jacobian:\n- $u_x=(u_\\xi y_\\eta - u_\\eta y_\\xi)/J$,\n- $u_y=(-u_\\xi x_\\eta + u_\\eta x_\\xi)/J$.\n\nAngles are in radians. No physical units are involved.\n\nFor each test case with parameters $(a,N_\\xi,N_\\eta)$, perform the following evaluations on the interface:\n1. Metric position continuity: compute the maximum pointwise Euclidean mismatch of interface positions between the left and right blocks, i.e., the maximum over all interface grid points of $\\sqrt{(x_\\mathrm{L}-x_\\mathrm{R})^2+(y_\\mathrm{L}-y_\\mathrm{R})^2}$ at $(\\xi,\\eta)=(1,\\eta)$ in the left block and $(\\xi,\\eta)=(0,\\eta)$ in the right block.\n2. Metric $C^1$ smoothness at the interface: define the tangential derivative jump as the maximum over the interface of the Euclidean norm of the difference between $(x_\\eta,y_\\eta)$ evaluated from the left and right blocks at the same physical interface location. Define the oriented normal derivative jump as the maximum over the interface of the Euclidean norm of $\\big((x_\\xi,y_\\xi)_\\mathrm{L}+ (x_\\xi,y_\\xi)_\\mathrm{R}\\big)$, where the right block’s $(x_\\xi,y_\\xi)$ is added with a positive sign to account for opposite parameter orientation across the interface. Report the overall metric $C^1$ jump as the maximum of these two maxima.\n3. Gradient error at the interface: at the interface line, approximate $(u_x,u_y)$ in each block using second-order accurate finite differences for $u_\\xi$ and $u_\\eta$, with one-sided second-order differences in the $\\xi$-direction at the interface and centered differences in the $\\eta$-direction away from the end points. Compare to the exact gradient $\\nabla u=(\\pi\\cos(\\pi x)\\cos(\\pi y),-\\pi\\sin(\\pi x)\\sin(\\pi y))$. Exclude the interface end points at $\\eta=0$ and $\\eta=1$ from the error evaluation to avoid boundary stencils in $\\eta$. Report the maximum absolute componentwise error over the interface for both blocks and then report the larger of the two maxima.\n\nTest Suite. Your program must compute and output the following for each test case:\n- $(a=0.15,N_\\xi=41,N_\\eta=41)$,\n- $(a=0.45,N_\\xi=61,N_\\eta=61)$,\n- $(a=0.30,N_\\xi=11,N_\\eta=23)$,\n- $(a=0.00,N_\\xi=31,N_\\eta=31)$.\n\nFor each test case, produce a list with three floating-point numbers:\n- the maximum interface position mismatch,\n- the metric $C^1$ jump (maximum of tangential and oriented-normal jumps),\n- the maximum interface gradient error as defined above.\n\nFinal Output Format. Your program should produce a single line of output containing the results as a comma-separated list of three-element lists, each inner list corresponding to one test case in the order listed above. Use scientific notation with ten significant digits for all floating-point numbers and no spaces. For example: \"[[1.2345678900e-03,2.3456789000e-04,3.4567890000e-05],[...],...]\".", "solution": "The solution is constructed in four main steps: 1) Derivation of the grid-generating mappings using Transfinite Interpolation (TFI), 2) Calculation of grid metrics via finite differences, 3) Evaluation of continuity, smoothness, and gradient error at the block interface, and 4) Algorithmic implementation.\n\n#### 1. Grid Generation via Transfinite Interpolation (TFI)\nThe core of the problem is to map the computational unit square $(\\xi, \\eta) \\in [0,1] \\times [0,1]$ to a physical quadrilateral block $(x,y)$. We use the linear bidirectional TFI formula for a vector-valued function $\\vec{r}(\\xi, \\eta) = (x(\\xi, \\eta), y(\\xi, \\eta))$:\n$$ \\vec{r}(\\xi, \\eta) = (1-\\xi)\\vec{C}_1(\\eta) + \\xi\\vec{C}_2(\\eta) + (1-\\eta)\\vec{C}_3(\\xi) + \\eta\\vec{C}_4(\\xi) - \\vec{B}(\\xi, \\eta) $$\nwhere $\\vec{C}_1, \\vec{C}_2, \\vec{C}_3, \\vec{C}_4$ are the four boundary curves, and $\\vec{B}(\\xi, \\eta)$ is a blending function correcting for the corners:\n$$ \\vec{B}(\\xi, \\eta) = (1-\\xi)(1-\\eta)\\vec{P}_{13} + \\xi(1-\\eta)\\vec{P}_{23} + (1-\\xi)\\eta\\vec{P}_{14} + \\xi\\eta\\vec{P}_{24} $$\nHere, $\\vec{P}_{13}=\\vec{r}(0,0)$, $\\vec{P}_{23}=\\vec{r}(1,0)$, $\\vec{P}_{14}=\\vec{r}(0,1)$, and $\\vec{P}_{24}=\\vec{r}(1,1)$ are the corner points.\n\n**Left Block:**\nThe boundaries are parameterized as functions of $\\xi$ or $\\eta$:\n- Left boundary ($\\xi=0$): $\\vec{C}_{1,L}(\\eta) = (0, \\eta)$\n- Right boundary ($\\xi=1$, interface): $\\vec{C}_{2,L}(\\eta) = (\\frac{1}{2} + a\\sin(\\pi\\eta), \\eta)$\n- Bottom boundary ($\\eta=0$): $\\vec{C}_{3,L}(\\xi) = (\\frac{1}{2}\\xi, 0)$\n- Top boundary ($\\eta=1$): $\\vec{C}_{4,L}(\\xi) = (\\frac{1}{2}\\xi, 1)$\n\nApplying the TFI formula, the mapping for the left block is:\n$$ x_L(\\xi, \\eta) = (1-\\xi)(0) + \\xi(\\tfrac{1}{2} + a\\sin(\\pi\\eta)) + (1-\\eta)(\\tfrac{1}{2}\\xi) + \\eta(\\tfrac{1}{2}\\xi) - [\\xi(1-\\eta)(\\tfrac{1}{2}) + \\xi\\eta(\\tfrac{1}{2})] = \\tfrac{1}{2}\\xi + a\\xi\\sin(\\pi\\eta) $$\n$$ y_L(\\xi, \\eta) = (1-\\xi)\\eta + \\xi\\eta + (1-\\eta)(0) + \\eta(1) - [(1-\\xi)\\eta(1) + \\xi\\eta(1)] = \\eta $$\n\n**Right Block:**\nThe boundaries are:\n- Left boundary ($\\xi=0$, interface): $\\vec{C}_{1,R}(\\eta) = (\\frac{1}{2} + a\\sin(\\pi\\eta), \\eta)$\n- Right boundary ($\\xi=1$): $\\vec{C}_{2,R}(\\eta) = (1, \\eta)$\n- Bottom boundary ($\\eta=0$): $\\vec{C}_{3,R}(\\xi) = (\\frac{1}{2} + \\frac{1}{2}\\xi, 0)$\n- Top boundary ($\\eta=1$): $\\vec{C}_{4,R}(\\xi) = (\\frac{1}{2} + \\frac{1}{2}\\xi, 1)$\n\nApplying the TFI formula, the mapping for the right block is:\n$$ x_R(\\xi, \\eta) = (1-\\xi)(\\tfrac{1}{2} + a\\sin(\\pi\\eta)) + \\xi(1) + (1-\\eta)(\\tfrac{1}{2}+\\tfrac{1}{2}\\xi) + \\eta(\\tfrac{1}{2}+\\tfrac{1}{2}\\xi) - [(1-\\xi)(1-\\eta)(\\tfrac{1}{2}) + \\xi(1-\\eta)(1) + (1-\\xi)\\eta(\\tfrac{1}{2}) + \\xi\\eta(1)] = \\tfrac{1}{2} + \\tfrac{1}{2}\\xi + a(1-\\xi)\\sin(\\pi\\eta) $$\n$$ y_R(\\xi, \\eta) = (1-\\xi)\\eta + \\xi\\eta + (1-\\eta)(0) + \\eta(1) - [(1-\\xi)\\eta(1) + \\xi\\eta(1)] = \\eta $$\n\nThese mappings are used to generate the $(x,y)$ coordinates for each block on a uniform tensor-product grid in $(\\xi,\\eta)$.\n\n#### 2. Numerical Differentiation and Metric Calculation\nThe problem requires computing derivatives with respect to the computational coordinates $(\\xi, \\eta)$ using second-order finite differences. For a function $f(\\xi_i, \\eta_j)$ on a uniform grid with spacing $\\Delta\\xi$ and $\\Delta\\eta$:\n- **Centered difference (interior points):**\n$$ \\frac{\\partial f}{\\partial \\xi}\\bigg|_{i,j} \\approx \\frac{f_{i+1,j} - f_{i-1,j}}{2\\Delta\\xi} $$\n- **One-sided forward difference (at boundary $i=0$):**\n$$ \\frac{\\partial f}{\\partial \\xi}\\bigg|_{0,j} \\approx \\frac{-3f_{0,j} + 4f_{1,j} - f_{2,j}}{2\\Delta\\xi} $$\n- **One-sided backward difference (at boundary $i=N-1$):**\n$$ \\frac{\\partial f}{\\partial \\xi}\\bigg|_{N-1,j} \\approx \\frac{3f_{N-1,j} - 4f_{N-2,j} + f_{N-3,j}}{2\\Delta\\xi} $$\nAnalogous formulas apply for $\\partial/\\partial\\eta$. These stencils are applied to the grid coordinates $(x,y)$ to compute the metric terms, also known as the components of the covariant base vectors: $x_\\xi = \\partial x/\\partial\\xi$, $y_\\xi = \\partial y/\\partial\\xi$, $x_\\eta = \\partial x/\\partial\\eta$, and $y_\\eta = \\partial y/\\partial\\eta$.\n\n#### 3. Evaluation of Interface Properties\nAll evaluations are performed on the shared patch interface, which corresponds to $\\xi=1$ for the left block and $\\xi=0$ for the right block.\n\n**1. Metric Position ($C^0$) Continuity:**\nThe derived mappings $x_L(1, \\eta) = \\frac{1}{2} + a\\sin(\\pi\\eta)$ and $x_R(0, \\eta) = \\frac{1}{2} + a\\sin(\\pi\\eta)$ are analytically identical, as are $y_L(1, \\eta) = \\eta$ and $y_R(0, \\eta) = \\eta$. The position mismatch is computed as the maximum pointwise Euclidean distance $\\sqrt{(x_L-x_R)^2+(y_L-y_R)^2}$ along the interface. This value is expected to be near machine precision.\n\n**2. Metric $C^1$ Smoothness:**\nThis measures the continuity of the grid lines' derivatives across the interface.\n- The **tangential derivative jump** is the maximum norm of the difference between the tangential vectors from each block: $\\max ||(\\vec{t}_L - \\vec{t}_R)||_2$, where $\\vec{t} = (x_\\eta, y_\\eta)$. Since the analytical tangential vectors are identical, this jump arises from finite difference error.\n- The **oriented normal derivative jump** is the maximum norm of the sum of the normal-direction vectors: $\\max ||(\\vec{n}_L + \\vec{n}_R)||_2$, where $\\vec{n} = (x_\\xi, y_\\xi)$. The sum is used because the $\\xi$ coordinate increases away from the interface in opposite physical directions for each block. A perfectly smooth grid would have $\\vec{n}_L = -\\vec{n}_R$, making this jump zero. However, our TFI mappings yield an analytical jump of magnitude $1$.\nThe final $C^1$ jump is the maximum of these two jump values.\n\n**3. Gradient Error at the Interface:**\nThe gradient of a scalar field $u(x,y)$ is computed using the chain rule, which in matrix form is $\\begin{pmatrix} u_\\xi \\\\ u_\\eta \\end{pmatrix} = \\begin{pmatrix} x_\\xi  y_\\xi \\\\ x_\\eta  y_\\eta \\end{pmatrix} \\begin{pmatrix} u_x \\\\ u_y \\end{pmatrix}$. Inverting gives the physical gradient:\n$$ u_x = \\frac{1}{J}(u_\\xi y_\\eta - u_\\eta y_\\xi) \\quad \\text{and} \\quad u_y = \\frac{1}{J}(-u_\\xi x_\\eta + u_\\eta x_\\xi) $$\nwhere the Jacobian is $J = x_\\xi y_\\eta - x_\\eta y_\\xi$.\n\nThe procedure is as follows:\n- The scalar field $u(x,y)=\\sin(\\pi x)\\cos(\\pi y)$ is evaluated on both grids.\n- The computational derivatives $u_\\xi$ and $u_\\eta$ are computed using the finite difference schemes. At the interface, this requires one-sided differences for $u_\\xi$ (backward for the left block, forward for the right) and centered differences for $u_\\eta$.\n- The numerical gradient $(u_x, u_y)$ is calculated for each block at the interface points (excluding endpoints at $\\eta=0,1$).\n- The analytical gradient $\\nabla u = (\\pi\\cos(\\pi x)\\cos(\\pi y), -\\pi\\sin(\\pi x)\\sin(\\pi y))$ is evaluated at the same interface points.\n- The error is the maximum absolute component-wise difference between the numerical and analytical gradients, maximized over the interface points and then over the two blocks.\n\n#### 4. Algorithmic Implementation\nThe algorithm proceeds by iterating through each test case. For each case, it generates the left and right physical grids, computes all necessary derivatives using the specified finite difference schemes, and then performs the three evaluations as described above. The results are collected and formatted into the required output string.", "answer": "```python\nimport numpy as np\n\ndef diff_xi(F, d_xi):\n    \"\"\"Computes second-order derivative w.r.t. xi.\"\"\"\n    dF_dxi = np.zeros_like(F)\n    # Centered difference for interior\n    dF_dxi[1:-1, :] = (F[2:, :] - F[:-2, :]) / (2 * d_xi)\n    # One-sided forward for first row (xi=0)\n    dF_dxi[0, :] = (-3 * F[0, :] + 4 * F[1, :] - F[2, :]) / (2 * d_xi)\n    # One-sided backward for last row (xi=1)\n    dF_dxi[-1, :] = (3 * F[-1, :] - 4 * F[-2, :] + F[-3, :]) / (2 * d_xi)\n    return dF_dxi\n\ndef diff_eta(F, d_eta):\n    \"\"\"Computes second-order derivative w.r.t. eta.\"\"\"\n    dF_deta = np.zeros_like(F)\n    # Centered difference for interior\n    dF_deta[:, 1:-1] = (F[:, 2:] - F[:, :-2]) / (2 * d_eta)\n    # One-sided forward for first col (eta=0)\n    dF_deta[:, 0] = (-3 * F[:, 0] + 4 * F[:, 1] - F[:, 2]) / (2 * d_eta)\n    # One-sided backward for last col (eta=1)\n    dF_deta[:, -1] = (3 * F[:, -1] - 4 * F[:, -2] + F[:, -3]) / (2 * d_eta)\n    return dF_deta\n\ndef run_case(a, N_xi, N_eta):\n    \"\"\"\n    Performs all computations for a single test case.\n    \"\"\"\n    # 1. Generate grids\n    xi_pts = np.linspace(0, 1, N_xi)\n    eta_pts = np.linspace(0, 1, N_eta)\n    d_xi = 1.0 / (N_xi - 1)\n    d_eta = 1.0 / (N_eta - 1)\n    \n    xi_grid, eta_grid = np.meshgrid(xi_pts, eta_pts, indexing='ij')\n\n    # Left block TFI mapping\n    x_L = 0.5 * xi_grid + a * xi_grid * np.sin(np.pi * eta_grid)\n    y_L = eta_grid\n    \n    # Right block TFI mapping\n    x_R = 0.5 + 0.5 * xi_grid + a * (1 - xi_grid) * np.sin(np.pi * eta_grid)\n    y_R = eta_grid\n\n    # 2. Evaluation 1: Metric position continuity\n    pos_L_interface = np.stack((x_L[-1, :], y_L[-1, :]), axis=-1)\n    pos_R_interface = np.stack((x_R[0, :], y_R[0, :]), axis=-1)\n    pos_mismatch = np.linalg.norm(pos_L_interface - pos_R_interface, axis=1)\n    max_pos_mismatch = np.max(pos_mismatch)\n\n    # 3. Evaluation 2: Metric C1 smoothness\n    # Compute metrics for left block\n    xL_xi = diff_xi(x_L, d_xi)\n    yL_xi = diff_xi(y_L, d_xi)\n    xL_eta = diff_eta(x_L, d_eta)\n    yL_eta = diff_eta(y_L, d_eta)\n    \n    # Compute metrics for right block\n    xR_xi = diff_xi(x_R, d_xi)\n    yR_xi = diff_xi(y_R, d_xi)\n    xR_eta = diff_eta(x_R, d_eta)\n    yR_eta = diff_eta(y_R, d_eta)\n\n    # Interface is from j=1 to N_eta-2\n    s = slice(1, -1)\n\n    # Tangential jump\n    t_L = np.stack((xL_eta[-1, s], yL_eta[-1, s]), axis=-1)\n    t_R = np.stack((xR_eta[0, s], yR_eta[0, s]), axis=-1)\n    tangential_jump = np.linalg.norm(t_L - t_R, axis=1)\n    max_tangential_jump = np.max(tangential_jump)\n\n    # Oriented normal jump\n    n_L = np.stack((xL_xi[-1, s], yL_xi[-1, s]), axis=-1)\n    n_R = np.stack((xR_xi[0, s], yR_xi[0, s]), axis=-1)\n    normal_jump = np.linalg.norm(n_L + n_R, axis=1)\n    max_normal_jump = np.max(normal_jump)\n    \n    metric_c1_jump = max(max_tangential_jump, max_normal_jump)\n\n    # 4. Evaluation 3: Gradient error\n    # Scalar field\n    u_L = np.sin(np.pi * x_L) * np.cos(np.pi * y_L)\n    u_R = np.sin(np.pi * x_R) * np.cos(np.pi * y_R)\n\n    # Computational derivatives of u\n    uL_xi = diff_xi(u_L, d_xi)\n    uL_eta = diff_eta(u_L, d_eta)\n    uR_xi = diff_xi(u_R, d_xi)\n    uR_eta = diff_eta(u_R, d_eta)\n\n    # --- Left Block Gradient Error ---\n    xL_xi_int, yL_xi_int = xL_xi[-1, s], yL_xi[-1, s]\n    xL_eta_int, yL_eta_int = xL_eta[-1, s], yL_eta[-1, s]\n    uL_xi_int, uL_eta_int = uL_xi[-1, s], uL_eta[-1, s]\n    J_L = xL_xi_int * yL_eta_int - xL_eta_int * yL_xi_int\n    \n    ux_L_num = (uL_xi_int * yL_eta_int - uL_eta_int * yL_xi_int) / J_L\n    uy_L_num = (-uL_xi_int * xL_eta_int + uL_eta_int * xL_xi_int) / J_L\n    \n    # --- Right Block Gradient Error ---\n    xR_xi_int, yR_xi_int = xR_xi[0, s], yR_xi[0, s]\n    xR_eta_int, yR_eta_int = xR_eta[0, s], yR_eta[0, s]\n    uR_xi_int, uR_eta_int = uR_xi[0, s], uR_eta[0, s]\n    J_R = xR_xi_int * yR_eta_int - xR_eta_int * yR_xi_int\n    \n    ux_R_num = (uR_xi_int * yR_eta_int - uR_eta_int * yR_xi_int) / J_R\n    uy_R_num = (-uR_xi_int * xR_eta_int + uR_eta_int * xR_xi_int) / J_R\n    \n    # --- Exact Gradient and Error ---\n    x_int = x_L[-1, s]\n    y_int = y_L[-1, s]\n\n    ux_exact = np.pi * np.cos(np.pi * x_int) * np.cos(np.pi * y_int)\n    uy_exact = -np.pi * np.sin(np.pi * x_int) * np.sin(np.pi * y_int)\n\n    error_L = np.max(np.maximum(np.abs(ux_L_num - ux_exact), np.abs(uy_L_num - uy_exact)))\n    error_R = np.max(np.maximum(np.abs(ux_R_num - ux_exact), np.abs(uy_R_num - uy_exact)))\n\n    max_gradient_error = max(error_L, error_R)\n\n    return [max_pos_mismatch, metric_c1_jump, max_gradient_error]\n\n\ndef solve():\n    \"\"\"Main function to run test cases and print results.\"\"\"\n    test_cases = [\n        (0.15, 41, 41),\n        (0.45, 61, 61),\n        (0.30, 11, 23),\n        (0.00, 31, 31),\n    ]\n\n    results = []\n    for case in test_cases:\n        a, N_xi, N_eta = case\n        result = run_case(a, N_xi, N_eta)\n        results.append(result)\n\n    formatted_cases = []\n    for case_result in results:\n        formatted_numbers = [f\"{num:.10e}\" for num in case_result]\n        formatted_cases.append(f\"[{','.join(formatted_numbers)}]\")\n    \n    final_output = f\"[{','.join(formatted_cases)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3367293"}]}