{"hands_on_practices": [{"introduction": "Before we can meaningfully compare the iterative performance of different pressure-velocity coupling algorithms, we must first build confidence in the underlying spatial discretization. This practice lays the groundwork by using the Method of Manufactured Solutions (MMS), a powerful verification technique in computational science. By constructing a known analytical solution, we can precisely measure the error of our numerical scheme and verify that it achieves the expected order of accuracy as the grid is refined [@problem_id:3362285].", "problem": "Consider steady, two-dimensional, incompressible flow of a Newtonian fluid with constant density $\\rho$ and kinematic viscosity $\\nu$ on the unit square $\\Omega = (0,1)\\times(0,1)$. The governing equations are the steady incompressible Navier–Stokes equations,\n$$\n\\nabla\\cdot \\mathbf{u} = 0,\\quad\n\\rho\\,(\\mathbf{u}\\cdot\\nabla)\\mathbf{u} = -\\nabla p + \\rho\\,\\nu\\,\\nabla^2 \\mathbf{u} + \\mathbf{f},\n$$\nwith no-slip velocity boundary conditions and Dirichlet boundary conditions for the pressure correction on $\\partial\\Omega$ as specified below. Here $\\mathbf{u} = (u,v)$ is the velocity field and $p$ is the pressure.\n\nYou will employ the Method of Manufactured Solutions to construct an exact analytical solution and use it to verify the spatial convergence order of the pressure correction $p'$ computed by three Pressure–Velocity Coupling algorithms: Semi-Implicit Method for Pressure-Linked Equations (SIMPLE), Semi-Implicit Method for Pressure-Linked Equations Revised (SIMPLER), and Semi-Implicit Method for Pressure-Linked Equations Consistent (SIMPLEC).\n\nManufactured analytical solution:\n- Choose the velocity field\n$$\nu(x,y) = \\sin(\\pi x)\\,\\cos(\\pi y),\\qquad v(x,y) = -\\cos(\\pi x)\\,\\sin(\\pi y),\n$$\nwhich satisfies $\\nabla\\cdot\\mathbf{u}=0$ for all $(x,y)\\in\\Omega$. Choose the pressure field\n$$\np(x,y) = \\sin(\\pi x)\\,\\sin(\\pi y),\n$$\nwhich satisfies $p(x,y)=0$ on $\\partial\\Omega$. Using these, a body force $\\mathbf{f}(x,y)$ can be constructed that makes $(\\mathbf{u},p)$ an exact solution of the steady equations.\n\nPressure correction equation in the SIMPLE family:\n- In the pressure–velocity coupling framework, the pressure correction $p'$ satisfies a pressure-correction Poisson-type equation that arises from enforcing mass conservation on the predicted mass fluxes. On a uniform grid with central differencing and constant momentum equation diagonals, the pressure correction equation reduces to\n$$\n\\nabla^2 p'(x,y) = s(x,y),\n$$\nwith homogeneous Dirichlet boundary condition $p'(x,y)=0$ on $\\partial\\Omega$. For verification purposes, take the manufactured pressure correction to be $p'(x,y) = p(x,y)$ with a guessed pressure equal to zero, and define the source term consistently by\n$$\ns(x,y) = -\\nabla^2 p'(x,y) = 2\\pi^2 \\sin(\\pi x)\\,\\sin(\\pi y),\n$$\nso that the exact solution of the pressure-correction equation is $p'(x,y) = \\sin(\\pi x)\\,\\sin(\\pi y)$.\n\nYour tasks:\n- Starting from the steady incompressible Navier–Stokes equations and the definition of the pressure correction equation in the SIMPLE family, justify that, under the stated manufactured assumptions (uniform grid, constant coefficients, central differencing, Dirichlet boundary data), the discretized pressure correction equations for SIMPLE, SIMPLER, and SIMPLEC collapse to the same second-order central difference approximation of the scalar Poisson problem for $p'(x,y)$.\n\n- Implement a solver that approximates $p'(x,y)$ on a sequence of uniform Cartesian grids covering $\\Omega$ using second-order central differences. The grids are specified by the number of equal subdivisions per coordinate direction $N\\in\\{8,16,32,64\\}$, so the mesh spacing is $h=1/N$, and the unknowns are located at the $N-1$ interior points in each direction with $p'=0$ on the boundary. Assemble the standard five-point discrete Laplacian and solve the resulting linear system for each $N$.\n\n- For each $N$, compute the discrete $\\ell^2$ error of the numerical solution $p'_h$ with respect to the exact manufactured solution $p'(x,y)$. The discrete $\\ell^2$ error must be defined as\n$$\nE(h) = \\left(\\sum_{i=1}^{N-1}\\sum_{j=1}^{N-1} \\left(p'_h(x_i,y_j) - p'(x_i,y_j)\\right)^2\\right)^{1/2}\\,h,\n$$\nwhere $x_i=i\\,h$ and $y_j=j\\,h$ for $i=1,\\dots,N-1$ and $j=1,\\dots,N-1$.\n\n- For each algorithm variant (SIMPLE, SIMPLER, SIMPLEC), compute the observed convergence order $r$ of $p'$ using the two finest grids by\n$$\nr = \\frac{\\log\\left(E(h)/E(h/2)\\right)}{\\log(2)},\n$$\nwith $h=1/32$ and $h/2=1/64$. In this manufactured setting, all three algorithms use the same spatial discretization of the pressure correction equation, hence the observed $r$ values should be equal and close to $2$.\n\nTest suite and output specification:\n- Use the grid sizes $N\\in\\{8,16,32,64\\}$ as the test suite to cover a coarse-grid edge case and progressively refined grids.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the order $[\\text{SIMPLE},\\text{SIMPLER},\\text{SIMPLEC}]$, where each entry is the floating-point value of $r$ computed as above, for example $[r_{\\text{SIMPLE}},r_{\\text{SIMPLER}},r_{\\text{SIMPLEC}}]$.", "solution": "The governing equations are the steady incompressible Navier–Stokes equations,\n$$\n\\nabla\\cdot \\mathbf{u} = 0,\\qquad\n\\rho\\,(\\mathbf{u}\\cdot\\nabla)\\mathbf{u} = -\\nabla p + \\rho\\,\\nu\\,\\nabla^2 \\mathbf{u} + \\mathbf{f}.\n$$\nWe select the manufactured fields\n$$\nu(x,y) = \\sin(\\pi x)\\,\\cos(\\pi y),\\quad v(x,y) = -\\cos(\\pi x)\\,\\sin(\\pi y),\\quad p(x,y) = \\sin(\\pi x)\\,\\sin(\\pi y),\n$$\nwhich satisfy incompressibility because\n$$\n\\frac{\\partial u}{\\partial x} + \\frac{\\partial v}{\\partial y}\n= \\pi\\cos(\\pi x)\\,\\cos(\\pi y) - \\pi\\cos(\\pi x)\\,\\cos(\\pi y) = 0.\n$$\nGiven $\\rho$ and $\\nu$, one can substitute $(\\mathbf{u},p)$ into the momentum equations and compute the body force $\\mathbf{f}(x,y)$ that makes $(\\mathbf{u},p)$ an exact solution; this uses the fundamental base of the governing laws.\n\nPressure–velocity coupling in the Semi-Implicit Method for Pressure-Linked Equations family introduces an intermediate velocity $\\mathbf{u}^*$ computed from a guessed pressure, followed by a pressure correction $p'$ used to correct mass fluxes to satisfy continuity. The correction step satisfies a pressure correction equation derived from the discrete continuity equation and the discrete momentum equations. In general finite-volume form, the discrete pressure correction equation can be written as\n$$\n\\sum_{f\\in \\text{faces}} \\rho\\,d_f\\,\\left(p'_N - p'_P\\right) = \\sum_{f\\in \\text{faces}} \\dot{m}^*_f,\n$$\nwhere $d_f$ are coefficients representative of inverse momentum diagonals and geometric factors, $P$ denotes the cell under consideration, $N$ denotes a neighbor, and $\\dot{m}^*_f$ are the predicted mass fluxes violating continuity. On a uniform grid with constant properties and central differencing, the momentum equation diagonal $a_P$ is constant across cells, the face coefficients $d_f$ become constant, and the discrete divergence of the predicted mass flux reduces to a uniform scaling of the discrete Laplacian of $p'$. Thus, the correction equation simplifies to the scalar Poisson problem\n$$\n\\nabla^2 p'(x,y) = s(x,y)\n$$\nwith homogeneous Dirichlet boundary conditions for $p'$ on $\\partial\\Omega$ when the guessed pressure is zero and the exact pressure vanishes at the boundary. This simplification uses only the core definitions and structure of the algorithms without invoking shortcut formulas. The differences between Semi-Implicit Method for Pressure-Linked Equations (SIMPLE), Semi-Implicit Method for Pressure-Linked Equations Revised (SIMPLER), and Semi-Implicit Method for Pressure-Linked Equations Consistent (SIMPLEC) occur in how the intermediate velocity $\\mathbf{u}^*$ and the coupling coefficients are formed, but in the manufactured uniform-coefficient setting, the spatial discretization of the pressure correction equation is identical among them.\n\nTo manufacture the source term, we take $p'(x,y) = p(x,y) = \\sin(\\pi x)\\,\\sin(\\pi y)$ (consistent with a guessed pressure equal to zero), so that\n$$\n\\nabla^2 p'(x,y) = \\frac{\\partial^2}{\\partial x^2}\\sin(\\pi x)\\,\\sin(\\pi y) + \\frac{\\partial^2}{\\partial y^2}\\sin(\\pi x)\\,\\sin(\\pi y)\n= -\\pi^2\\sin(\\pi x)\\,\\sin(\\pi y) - \\pi^2\\sin(\\pi x)\\,\\sin(\\pi y) = -2\\pi^2\\sin(\\pi x)\\,\\sin(\\pi y),\n$$\nand therefore\n$$\ns(x,y) = -\\nabla^2 p'(x,y) = 2\\pi^2\\sin(\\pi x)\\,\\sin(\\pi y).\n$$\n\nWe discretize the Poisson equation on a uniform grid with spacing $h=1/N$ and interior points $(x_i,y_j) = (i h, j h)$ for $i=1,\\dots,N-1$ and $j=1,\\dots,N-1$. The standard second-order central difference approximation to $\\nabla^2 p'$ on a Cartesian grid yields the five-point stencil,\n$$\n\\left(\\nabla^2 p'\\right)_{i,j} \\approx \\frac{p'_{i+1,j} - 2 p'_{i,j} + p'_{i-1,j}}{h^2} + \\frac{p'_{i,j+1} - 2 p'_{i,j} + p'_{i,j-1}}{h^2},\n$$\nwhich provides a second-order approximation in $h$. Applying homogeneous Dirichlet boundary conditions $p'=0$ on $\\partial\\Omega$, the discrete system takes the matrix form\n$$\n\\mathbf{L}\\,\\mathbf{p} = h^2\\,\\mathbf{s},\n$$\nwhere $\\mathbf{L}$ is the discrete two-dimensional Laplacian with the five-point stencil and $\\mathbf{p}$ and $\\mathbf{s}$ are the vectors of unknowns and source values at interior nodes.\n\nThe discrete $\\ell^2$ error is defined by\n$$\nE(h) = \\left(\\sum_{i=1}^{N-1}\\sum_{j=1}^{N-1} \\left(p'_h(x_i,y_j) - p'(x_i,y_j)\\right)^2\\right)^{1/2}\\,h,\n$$\nwhich is a consistent quadrature for the continuum $L^2$ norm. For second-order central differences, the truncation error is $\\mathcal{O}(h^2)$, and for smooth solutions on uniform grids, the discrete solution converges with order $2$ in $h$ under Dirichlet boundary conditions, so we expect\n$$\nE(h) \\approx C\\,h^2\n$$\nfor some constant $C$, leading to the observed convergence order\n$$\nr = \\frac{\\log\\left(E(h)/E(h/2)\\right)}{\\log(2)} \\approx 2.\n$$\n\nIn the manufactured setting described, Semi-Implicit Method for Pressure-Linked Equations (SIMPLE), Semi-Implicit Method for Pressure-Linked Equations Revised (SIMPLER), and Semi-Implicit Method for Pressure-Linked Equations Consistent (SIMPLEC) share the same spatial discretization for the pressure correction equation and hence produce identical $p'$ solutions when the linear system is solved to convergence. Therefore, computing $E(h)$ for $h=1/32$ and $h/2=1/64$ and forming $r$ as above should yield three equal values close to $2$. The implementation uses the Kronecker-sum construction of the two-dimensional discrete Laplacian and a direct sparse linear solver to eliminate iterative effects and isolate the spatial discretization error, aligning with the principle-based derivation and verification task.\n\nThe program evaluates the errors for $N\\in\\{8,16,32,64\\}$ and reports the three observed orders $[r_{\\text{SIMPLE}}, r_{\\text{SIMPLER}}, r_{\\text{SIMPLEC}}]$ computed from the two finest grids, thereby verifying second-order convergence of $p'$ under grid refinement for all three algorithms in this manufactured, uniform-coefficient limit.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import diags, kron, identity\nfrom scipy.sparse.linalg import spsolve\n\ndef build_poisson_matrix(m):\n    \"\"\"\n    Build the 2D Poisson matrix with Dirichlet boundary conditions\n    on an m x m interior grid using the 5-point Laplacian.\n    \"\"\"\n    # 1D Laplacian (Dirichlet interior nodes): tridiagonal [-1, 2, -1]\n    main = -2.0 * np.ones(m)\n    off = 1.0 * np.ones(m - 1)\n    L1 = diags([off, main, off], offsets=[-1, 0, 1], format='csr')\n    I = identity(m, format='csr')\n    # 2D Laplacian via Kronecker sum\n    L2 = kron(I, L1) + kron(L1, I)\n    return L2\n\ndef manufactured_source_and_exact(N):\n    \"\"\"\n    Compute source term s(x,y) = 2*pi^2*sin(pi*x)*sin(pi*y)\n    and exact p'(x,y) at interior points for grid size N (spacing h=1/N).\n    Returns (s_flat, p_exact_flat).\n    \"\"\"\n    h = 1.0 / N\n    m = N - 1\n    x = np.linspace(h, 1.0 - h, m)\n    y = np.linspace(h, 1.0 - h, m)\n    X, Y = np.meshgrid(x, y, indexing='ij')\n    p_exact = np.sin(np.pi * X) * np.sin(np.pi * Y)\n    s = 2.0 * (np.pi ** 2) * p_exact\n    return s.ravel(), p_exact.ravel()\n\ndef solve_poisson(N):\n    \"\"\"\n    Solve L p = h^2 * s for p on interior grid for given N,\n    with exact source manufactured from p'(x,y) = sin(pi*x)*sin(pi*y).\n    Returns L2 error E(h) with discrete quadrature.\n    \"\"\"\n    h = 1.0 / N\n    m = N - 1\n    L = build_poisson_matrix(m)\n    s_flat, p_exact_flat = manufactured_source_and_exact(N)\n    rhs = (h ** 2) * s_flat\n    p_num = spsolve(L, rhs)\n    # Discrete L2 error: sqrt(sum((error)^2)) * h\n    err = p_num - p_exact_flat\n    E = np.sqrt(np.sum(err ** 2)) * h\n    return E\n\ndef observed_order(e_h, e_h2):\n    \"\"\"\n    Compute observed order r = log(e_h/e_h2)/log(2),\n    where h2 = h/2 (i.e., N doubled).\n    \"\"\"\n    return np.log(e_h / e_h2) / np.log(2.0)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    grid_sizes = [8, 16, 32, 64]\n\n    # Compute errors for each grid size.\n    errors = {}\n    for N in grid_sizes:\n        errors[N] = solve_poisson(N)\n\n    # Compute observed order using the two finest grids N=32 and N=64.\n    e32 = errors[32]\n    e64 = errors[64]\n    r = observed_order(e32, e64)\n\n    # In this manufactured uniform-coefficient setting, SIMPLE, SIMPLER, and SIMPLEC\n    # produce identical spatial discretizations for the pressure correction equation,\n    # hence identical observed orders.\n    results = [r, r, r]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3362285"}, {"introduction": "A correct spatial discretization is necessary, but not sufficient, for a robust solver. When assembling the linear system for the pressure correction, practical implementations often encounter matrix singularity, which can halt the solution process. This practice equips you with a powerful diagnostic toolkit to detect and understand the origins of this singularity, whether it stems from the physical indeterminacy of pressure or from numerical artifacts like checkerboard modes [@problem_id:3443047]. By leveraging singular value decomposition (SVD), you will learn to programmatically identify these issues and select the appropriate remedy.", "problem": "Consider the Semi-Implicit Method for Pressure-Linked Equations (SIMPLE) and its variant SIMPLE Revised (SIMPLER) for solving incompressible flow. The underlying mathematical base is the incompressible Navier–Stokes equations and mass conservation, written as $ \\rho \\left( \\frac{\\partial \\mathbf{u}}{\\partial t} + \\mathbf{u}\\cdot\\nabla \\mathbf{u} \\right) = -\\nabla p + \\mu \\nabla^2 \\mathbf{u} + \\mathbf{f} $ and $ \\nabla \\cdot \\mathbf{u} = 0 $, where $ \\rho $ is the density, $ \\mathbf{u} $ is the velocity, $ p $ is the pressure, $ \\mu $ is the dynamic viscosity, and $ \\mathbf{f} $ represents body forces. In SIMPLE, a pressure correction equation arises by enforcing mass conservation using a discretized continuity equation and provisional velocities from the momentum equation. This pressure correction equation can be written as a sparse linear system $ A p = b $ over the pressure unknowns $ p $, where $ A $ is assembled from discretized flux coefficients. In many practical scenarios, such as with homogeneous Neumann boundary conditions, the matrix $ A $ is singular with a nullspace containing the constant vector, reflecting that pressure is only defined up to an additive constant. In collocated grid arrangements without appropriate momentum interpolation, there may also be a spurious \"checkerboard\" pressure mode that leaks into the nullspace.\n\nYour task is to construct a programmatic test to detect inadvertent nullspace leakage in an assembled pressure system $ A $ and to suggest remedies based on constraint enforcement. The detection must be rooted in first principles: identify singularity through the spectrum of $ A $ via singular value decomposition, classify the type of nullspace mode using structural diagnostics, and return an actionable remedy code based on the diagnosis.\n\nThe fundamental base you must use includes:\n- The incompressibility condition $ \\nabla \\cdot \\mathbf{u} = 0 $ implying a pressure correction equation that is often equivalent to a discrete Poisson operator on $ p $, subject to boundary conditions, which yields a linear system $ A p = b $.\n- The property that for a graph Laplacian representing a discrete Poisson operator with homogeneous Neumann boundaries on a connected domain, $ A \\mathbf{1} = \\mathbf{0} $ where $ \\mathbf{1} $ is the constant vector, making the matrix singular with a one-dimensional nullspace.\n- In collocated arrangements without momentum interpolation, the discretization can admit an alternating-sign \"checkerboard\" mode in pressure. This can be revealed by near-zero singular values whose associated singular vectors have strong correlation with the parity pattern $ (-1)^{i+j} $ on a Cartesian grid.\n\nDesign and implement a single program that:\n1. Assembles representative pressure system matrices $ A $ for a two-dimensional $ m \\times n $ grid using a graph Laplacian model for the discrete Poisson operator. All quantities in this problem are dimensionless.\n2. Performs singular value decomposition on each assembled $ A $ and detects nullspace leakage by counting singular values below a numerically meaningful tolerance.\n3. Diagnoses the nature of the nullspace by checking row-sum properties and correlating the right-singular vector corresponding to the smallest singular value with the parity pattern $ p_{i,j} = (-1)^{i+j} $.\n4. Returns, for each test case, a list of four numbers $ [\\text{nullity}, s_{\\min}, \\text{is\\_singular}, \\text{remedy\\_code}] $, where $ \\text{nullity} $ is the integer dimension of the detected nullspace, $ s_{\\min} $ is the smallest singular value as a float, $ \\text{is\\_singular} $ is a boolean indicating whether any singular values are below tolerance, and $ \\text{remedy\\_code} $ is an integer indicating a recommended remedy.\n\nUse the following remedy code definitions:\n- $ 0 $: No action required.\n- $ 1 $: Enforce a single reference pressure (pin one degree of freedom) to remove the constant nullspace.\n- $ 2 $: Enforce a zero-mean pressure constraint via a Lagrange multiplier or consistent penalty to remove the constant nullspace while preserving conservation.\n- $ 3 $: Enforce constraints per connected component (e.g., one pin per component or blockwise mean-zero constraints) to remove multi-component nullspaces.\n- $ 4 $: Apply momentum interpolation consistent with Rhie–Chow, or use a staggered grid, to suppress the checkerboard pressure mode.\n\nDetection logic requirements grounded in the base principles:\n- Use singular value decomposition to compute singular values $ s_k $ of $ A $. Define a tolerance $ \\tau $ and detect nullspace leakage by counting the number of singular values $ s_k \\le \\tau $.\n- Diagnose a constant-mode nullspace by verifying that the absolute infinity norm of the row sums of $ A $ is small relative to a characteristic diagonal magnitude, indicating $ A \\mathbf{1} \\approx \\mathbf{0} $.\n- Diagnose a checkerboard mode by computing the normalized parity vector $ q $ with components $ q_{i,j} = (-1)^{i+j}/\\|q\\|_2 $ and checking whether the smallest right-singular vector $ v_{\\min} $ satisfies $ |\\langle v_{\\min}, q \\rangle| \\ge 0.9 $.\n- Diagnose multi-component nullspaces by counting $ \\text{nullity} > 1 $.\n\nConstruct the following test suite with dimensionless parameters that stress distinct failure modes and remedies:\n- Test case 1 (connected homogeneous Neumann): $ m=6 $, $ n=6 $. Assemble $ A $ as the graph Laplacian of the $ 6 \\times 6 $ grid with unit weights and no pins or penalties. Expected: one-dimensional constant nullspace, recommend remedy code $ 1 $ or $ 2 $ based on constraint preference.\n- Test case 2 (reference pressure pin): $ m=6 $, $ n=6 $. Assemble $ A $ as in test case 1, then pin the node at coordinates $ (0,0) $ by setting the corresponding row and column to zero and placing a $ 1 $ on the diagonal at that location. Expected: no nullspace leakage.\n- Test case 3 (disconnected domain): $ m=6 $, $ n=6 $. Assemble $ A $ as the graph Laplacian but remove edges across the vertical cut between columns $ 2 $ and $ 3 $ (zero-based indices), producing two disconnected components. Expected: two-dimensional nullspace spanned by constants on each component, recommend remedy code $ 3 $.\n- Test case 4 (checkerboard nullspace): $ m=6 $, $ n=6 $. Assemble a nonsingular base matrix $ A_{\\text{base}} $ by pinning $ (0,0) $ as in test case 2, then construct $ A = A_{\\text{base}} - (A_{\\text{base}} q) q^{\\top} $ using the normalized parity vector $ q $, which induces an exact nullspace in the checkerboard direction. Expected: one-dimensional nullspace with strong parity correlation, recommend remedy code $ 4 $.\n- Test case 5 (mean-zero penalty): $ m=6 $, $ n=6 $. Assemble $ A $ as in test case 1, then add a rank-one mean penalty $ A \\leftarrow A + \\alpha \\,\\mathbf{1}\\mathbf{1}^{\\top} $ with $ \\alpha = 10^{-2} $. Expected: no nullspace leakage.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the four-entry list for a test case. For example, the output format must be $ [\\text{case1\\_result},\\text{case2\\_result},\\dots] $, and each $ \\text{caseX\\_result} $ must be of the form $ [\\text{nullity}, s_{\\min}, \\text{is\\_singular}, \\text{remedy\\_code}] $. All quantities are dimensionless, and no physical units or angle units are used in this problem. The program must be self-contained, require no user input, and use only the specified libraries.", "solution": "The derivation begins from the incompressibility condition $ \\nabla \\cdot \\mathbf{u} = 0 $ and the momentum equation $ \\rho \\left( \\frac{\\partial \\mathbf{u}}{\\partial t} + \\mathbf{u}\\cdot\\nabla \\mathbf{u} \\right) = -\\nabla p + \\mu \\nabla^2 \\mathbf{u} + \\mathbf{f} $. In the Semi-Implicit Method for Pressure-Linked Equations (SIMPLE), provisional velocities $ \\mathbf{u}^{*} $ are obtained by discretizing the momentum equation while using a guessed pressure field $ p^{*} $. The continuity residual $ r = \\nabla \\cdot \\mathbf{u}^{*} $ is then driven to zero by solving a pressure correction equation. The algebraic form follows from discretizing mass conservation and momentum coupling, yielding a sparse linear system $ A \\mathbf{p}' = \\mathbf{b} $ for the pressure correction $ \\mathbf{p}' $, where $ A $ is assembled from flux coupling coefficients and $ \\mathbf{b} $ arises from divergence of the provisional velocity and boundary terms. The SIMPLE Revised (SIMPLER) algorithm modifies the coupling to improve pressure and velocity updates but retains the need to solve a pressure-like equation.\n\nFor a connected domain with homogeneous Neumann boundary conditions on the pressure correction, the resulting operator $ A $ is a discrete analogue of the Laplacian with zero normal derivative boundary conditions. The discrete structure can be represented as a graph Laplacian: for each interior node, $ A_{ii} $ equals the number of neighbor connections, and $ A_{ij} = -1 $ for each neighbor $ j $. This construction satisfies $ A \\mathbf{1} = \\mathbf{0} $ because each row sums to zero, revealing a one-dimensional nullspace spanned by the constant vector $ \\mathbf{1} $. The matrix is thus singular, consistent with the physical statement that pressure is only defined up to an additive constant.\n\nConstraints remove singularity in different ways. Pinning a single pressure degree of freedom sets one row and column to zero with a unit diagonal, which breaks the constant-mode nullspace and produces a nonsingular system. Enforcing a zero-mean constraint can be done by a Lagrange multiplier introducing an augmented saddle-point system or by adding a small rank-one penalty $ \\alpha \\, \\mathbf{1} \\mathbf{1}^{\\top} $; both lead to $ A \\mathbf{1} \\ne \\mathbf{0} $. For domains with multiple disconnected components, the graph Laplacian has a nullspace spanned by the constants on each component, leading to a nullspace dimension greater than one. This requires constraints per component, such as one pin per block or blockwise mean-zero constraints. In collocated grid arrangements without appropriate momentum interpolation, the pressure equation assembled in SIMPLE may admit a spurious checkerboard mode. The parity pattern $ \\mathbf{q} $ defined by $ q_{i,j} = (-1)^{i+j} $ captures the two-color alternation often associated with this spurious mode. A matrix that admits $ \\mathbf{q} $ in the nullspace can be constructed by starting from a nonsingular base $ A_{\\text{base}} $ (for example, with a pin) and applying a rank-one modification $ A = A_{\\text{base}} - (A_{\\text{base}} \\mathbf{q}) \\mathbf{q}^{\\top} $, which ensures $ A \\mathbf{q} = \\mathbf{0} $ because $ A \\mathbf{q} = A_{\\text{base}} \\mathbf{q} - (A_{\\text{base}} \\mathbf{q}) (\\mathbf{q}^{\\top} \\mathbf{q}) = \\mathbf{0} $ for normalized $ \\mathbf{q} $.\n\nDetection via singular value decomposition (SVD) is principled. Compute $ U \\Sigma V^{\\top} = A $, where $ \\Sigma $ contains singular values $ s_1 \\ge s_2 \\ge \\dots \\ge s_N \\ge 0 $. Define a numerical tolerance $ \\tau $ to classify singular values as effectively zero, for example $ \\tau = \\max( \\epsilon \\, s_{\\max} \\, N \\, c, \\tau_{\\min} ) $ where $ \\epsilon $ is machine precision (for double precision $ \\epsilon \\approx 2.22 \\times 10^{-16} $), $ s_{\\max} = s_1 $, $ N $ is the dimension, $ c $ is a modest constant like $ 10 $, and $ \\tau_{\\min} $ is a floor such as $ 10^{-14} $. The nullity is the count of singular values $ s_k \\le \\tau $. The smallest singular value $ s_{\\min} = s_N $ indicates the degree of singularity.\n\nTo classify the nullspace mode, two diagnostics are used. First, check the row-sum property: compute $ r_i = \\sum_j A_{ij} $ and its infinity norm $ \\| r \\|_{\\infty} $. If $ \\| r \\|_{\\infty} $ is extremely small relative to a characteristic diagonal magnitude $ d = \\frac{1}{N} \\sum_i |A_{ii}| $, then $ A \\mathbf{1} \\approx \\mathbf{0} $ and the singularity reflects a constant-mode nullspace typical of homogeneous Neumann boundaries. Second, check for a checkerboard mode by constructing the normalized parity vector $ \\mathbf{q} $ and measuring the correlation $ \\gamma = |\\langle v_{\\min}, \\mathbf{q} \\rangle| $ where $ v_{\\min} $ is the right-singular vector associated with $ s_{\\min} $. If $ \\gamma \\ge 0.9 $, the smallest mode is strongly aligned with the parity pattern and the recommended remedy is to apply momentum interpolation such as Rhie–Chow or adopt a staggered grid.\n\nRemedies are suggested by the diagnosis:\n- If the matrix is nonsingular ($ \\text{nullity} = 0 $), propose code $ 0 $.\n- If row sums indicate a constant nullspace and $ \\text{nullity} = 1 $, propose code $ 1 $ (reference pressure pin) or code $ 2 $ (zero-mean constraint); here we choose code $ 1 $ as the minimal fix.\n- If $ \\text{nullity} > 1 $ and row sums indicate a constant-mode per component (as with a disconnected graph), propose code $ 3 $.\n- If the parity correlation exceeds the threshold, propose code $ 4 $ even if other diagnostics apply, because suppressing the checkerboard mode is paramount.\n\nThe test suite exercises distinct regimes:\n- Connected homogeneous Neumann pressure operator yields $ \\text{nullity} = 1 $ and suggests pinning.\n- Pinning a node yields a nonsingular system and suggests no action.\n- Disconnected domain yields $ \\text{nullity} = 2 $ and suggests component-wise constraints.\n- Checkerboard nullspace yields $ \\text{nullity} = 1 $ with strong parity correlation and suggests Rhie–Chow style interpolation.\n- Mean-zero penalty yields a nonsingular system and suggests no action.\n\nThe program assembles matrices using a graph Laplacian model for a $ m \\times n $ grid, applies the specified modifications, runs SVD to compute $ s_{\\min} $ and nullity, diagnoses the mode via row sums and parity correlation, and emits one list per case in the required format $ [\\text{nullity}, s_{\\min}, \\text{is\\_singular}, \\text{remedy\\_code}] $, aggregated as a single line of comma-separated lists within brackets. All variables are dimensionless, and the output contains booleans and floats without units, satisfying the requirements.", "answer": "```python\nimport numpy as np\n\ndef grid_index(i, j, n_cols):\n    return i * n_cols + j\n\ndef build_graph_laplacian(m, n, disconnected=False):\n    \"\"\"\n    Build the graph Laplacian for an m x n grid with unit weights.\n    If disconnected=True, remove edges across a vertical cut between columns c and c+1,\n    where c = n//2 - 1, to create two disconnected components.\n    \"\"\"\n    N = m * n\n    A = np.zeros((N, N), dtype=float)\n    cut_col = n // 2 - 1  # vertical cut between cut_col and cut_col+1\n    for i in range(m):\n        for j in range(n):\n            idx = grid_index(i, j, n)\n            degree = 0\n            # Up\n            if i - 1 >= 0:\n                nidx = grid_index(i - 1, j, n)\n                A[idx, nidx] -= 1.0\n                degree += 1\n            # Down\n            if i + 1  m:\n                nidx = grid_index(i + 1, j, n)\n                A[idx, nidx] -= 1.0\n                degree += 1\n            # Left\n            if j - 1 >= 0:\n                # Edge across cut between cut_col and cut_col+1\n                if not (disconnected and j - 1 == cut_col and j == cut_col + 1):\n                    nidx = grid_index(i, j - 1, n)\n                    A[idx, nidx] -= 1.0\n                    degree += 1\n            # Right\n            if j + 1  n:\n                # Edge across cut between cut_col and cut_col+1\n                if not (disconnected and j == cut_col and j + 1 == cut_col + 1):\n                    nidx = grid_index(i, j + 1, n)\n                    A[idx, nidx] -= 1.0\n                    degree += 1\n            A[idx, idx] = degree\n    return A\n\ndef apply_pin(A, pin_idx):\n    \"\"\"\n    Enforce a reference pressure at index pin_idx by zeroing its row and column\n    and setting the diagonal to 1.\n    \"\"\"\n    Ap = A.copy()\n    Ap[pin_idx, :] = 0.0\n    Ap[:, pin_idx] = 0.0\n    Ap[pin_idx, pin_idx] = 1.0\n    return Ap\n\ndef parity_vector(m, n):\n    \"\"\"\n    Construct the normalized parity vector q with entries q_{i,j} = (-1)^{i+j}.\n    \"\"\"\n    N = m * n\n    q = np.zeros(N, dtype=float)\n    for i in range(m):\n        for j in range(n):\n            idx = grid_index(i, j, n)\n            q[idx] = 1.0 if ((i + j) % 2 == 0) else -1.0\n    norm = np.linalg.norm(q)\n    if norm == 0:\n        return q\n    return q / norm\n\ndef induce_checkerboard_nullspace(A_base, m, n):\n    \"\"\"\n    Construct A = A_base - (A_base q) q^T so that A q = 0 exactly,\n    where q is the normalized parity vector.\n    \"\"\"\n    q = parity_vector(m, n)\n    y = A_base @ q\n    # A_new = A_base - y q^T\n    A_new = A_base - np.outer(y, q)\n    return A_new\n\ndef add_mean_zero_penalty(A, alpha):\n    \"\"\"\n    Add a rank-one penalty alpha * 11^T to enforce mean-zero pressure weakly.\n    \"\"\"\n    N = A.shape[0]\n    ones = np.ones((N, N), dtype=float)\n    return A + alpha * ones\n\ndef detect_nullspace_and_remedy(A, m, n):\n    \"\"\"\n    Detect nullspace leakage via SVD, diagnose mode, and suggest remedies.\n    Returns [nullity, s_min, is_singular, remedy_code].\n    \"\"\"\n    # Compute full SVD for diagnostics\n    U, S, Vh = np.linalg.svd(A, full_matrices=False)\n    s_max = S[0] if S.size > 0 else 0.0\n    s_min = S[-1] if S.size > 0 else 0.0\n    # Numerical tolerance for singular values\n    eps = np.finfo(float).eps\n    N = A.shape[0]\n    tau = max(eps * s_max * N * 10.0, 1e-14)\n    nullity = int(np.sum(S = tau))\n    is_singular = nullity > 0\n\n    # Default remedy\n    remedy_code = 0\n\n    if is_singular:\n        # Row-sum diagnostic for constant-mode nullspace\n        row_sums = np.sum(A, axis=1)\n        rs_norm_inf = np.linalg.norm(row_sums, ord=np.inf)\n        diag_mean = float(np.mean(np.abs(np.diag(A))))\n        approx_zero_rowsum = (rs_norm_inf = 1e-12) or (diag_mean > 0 and rs_norm_inf / diag_mean  1e-8)\n\n        # Checkerboard diagnostic via correlation with smallest right-singular vector\n        q = parity_vector(m, n)\n        vmin = Vh[-1, :]\n        vmin_norm = np.linalg.norm(vmin)\n        corr = 0.0\n        if vmin_norm > 0:\n            vmin_unit = vmin / vmin_norm\n            corr = abs(float(np.dot(vmin_unit, q)))\n\n        # Decision logic\n        if corr >= 0.9:\n            remedy_code = 4\n        elif approx_zero_rowsum:\n            if nullity == 1:\n                remedy_code = 1  # single reference pressure\n            else:\n                remedy_code = 3  # per-component constraints\n        else:\n            # Fallback: suggest pinning a degree of freedom\n            remedy_code = 1\n\n    return [nullity, float(s_min), bool(is_singular), int(remedy_code)]\n\ndef solve():\n    # Define test cases (dimensionless)\n    m, n = 6, 6\n    test_cases = [\n        (\"connected_neumann\",),              # Test case 1\n        (\"pinned_reference\",),               # Test case 2\n        (\"disconnected_neumann\",),           # Test case 3\n        (\"checkerboard_nullspace\",),         # Test case 4\n        (\"mean_zero_penalty\",),              # Test case 5\n    ]\n\n    results = []\n    for case in test_cases:\n        kind = case[0]\n        if kind == \"connected_neumann\":\n            A = build_graph_laplacian(m, n, disconnected=False)\n            res = detect_nullspace_and_remedy(A, m, n)\n        elif kind == \"pinned_reference\":\n            A = build_graph_laplacian(m, n, disconnected=False)\n            pin_idx = grid_index(0, 0, n)\n            A = apply_pin(A, pin_idx)\n            res = detect_nullspace_and_remedy(A, m, n)\n        elif kind == \"disconnected_neumann\":\n            A = build_graph_laplacian(m, n, disconnected=True)\n            res = detect_nullspace_and_remedy(A, m, n)\n        elif kind == \"checkerboard_nullspace\":\n            A_base = build_graph_laplacian(m, n, disconnected=False)\n            pin_idx = grid_index(0, 0, n)\n            A_base = apply_pin(A_base, pin_idx)\n            A = induce_checkerboard_nullspace(A_base, m, n)\n            res = detect_nullspace_and_remedy(A, m, n)\n        elif kind == \"mean_zero_penalty\":\n            A = build_graph_laplacian(m, n, disconnected=False)\n            A = add_mean_zero_penalty(A, alpha=1e-2)\n            res = detect_nullspace_and_remedy(A, m, n)\n        else:\n            res = [0, 0.0, False, 0]\n        results.append(res)\n\n    # Final print statement in the exact required format: single line, comma-separated list enclosed in brackets.\n    print(\"[\" + \",\".join(str(r) for r in results) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3443047"}, {"introduction": "With a verified and robust solver for the core equations, we can now turn our attention to the central theme: the comparative performance of the SIMPLE and SIMPLER algorithms. This final practice moves from spatial accuracy to iterative efficiency, which is the key differentiator between these methods. You will implement a set of quantitative metrics to analyze synthetic, but realistic, convergence histories, allowing for a direct comparison of the algorithms' speed and stability under various conditions [@problem_id:3442976].", "problem": "Consider the steady, incompressible, laminar lid-driven cavity problem on a unit square domain. The governing equations are the incompressible Navier–Stokes equations: conservation of mass, given by $\\nabla \\cdot \\mathbf{u} = 0$, and conservation of momentum, given by $\\rho (\\mathbf{u} \\cdot \\nabla) \\mathbf{u} = -\\nabla p + \\mu \\nabla^2 \\mathbf{u}$, where $\\mathbf{u}$ is the velocity field and $p$ is the pressure field. In iterative pressure–velocity coupling schemes such as the Semi-Implicit Method for Pressure-Linked Equations (SIMPLE) and SIMPLE Revised (SIMPLER), the outer fixed-point process produces a sequence of residual vectors $\\{\\mathbf{r}_k\\}_{k \\geq 0}$ associated with the discrete equations, where each $\\mathbf{r}_k$ is the stacked residual of the coupled momentum and continuity equations. Under consistent linearization and under-relaxation, the outer iteration can be modeled as a fixed-point iteration $\\mathbf{r}_{k+1} \\approx \\mathbf{M} \\mathbf{r}_k$ with iteration matrix $\\mathbf{M}$ that depends on the algorithmic coupling strategy. For sufficiently large $k$, the norm of the residual typically exhibits geometric decay characterized by an asymptotic convergence factor related to the spectral radius $\\rho(\\mathbf{M})$.\n\nYou are asked to implement a diagnostic plan that, given synthetic but scientifically plausible residual histories for the lid-driven cavity constructed under identical discretization choices, linear solvers, and relaxation parameters, compares the Semi-Implicit Method for Pressure-Linked Equations (SIMPLE) and SIMPLE Revised (SIMPLER) in terms of iteration counts and residual decay. The synthetic histories are designed so that any observed differences are attributable to the algorithmic coupling differences alone, while holding the discretization and linear solver choices fixed.\n\nTo ensure universal applicability and a purely mathematical specification, the residual norm histories for each algorithm $A \\in \\{\\text{SIMPLE}, \\text{SIMPLER}\\}$ are defined by a controlled parametric model:\n$$\nr_k^{(A)} \\;=\\; r_0 \\,\\frac{\\left(c_A\\right)^k \\left(1 + a \\cos(\\pi k)\\right)}{1+a}, \\quad k = 0,1,2,\\dots,K,\n$$\nwhere $r_0  0$ is the initial residual norm (the same for both algorithms), $c_A \\in (0,1)$ is the base contraction factor modeling the asymptotic linear convergence rate, $a \\in [0,1)$ is an oscillation amplitude that mimics transient non-normal effects and possible checkerboard pressure–velocity coupling artifacts under identical spatial discretization and linear solver choices, and $K \\in \\mathbb{N}$ is the maximum number of stored iterations. The normalization by $(1+a)$ ensures $r_0^{(A)} = r_0$. This model is consistent with fixed-point theory for linear stationary iterations with mild transient modulation and preserves positivity of $r_k^{(A)}$ for all $k$ as long as $a  1$.\n\nYour program must implement the following diagnostics for each algorithm and each test case:\n\n- Iteration-to-target count $N_\\tau^{(A)}$: the smallest $k \\in \\{0,1,\\dots,K\\}$ such that $r_k^{(A)} \\le r_0 \\,\\tau$, where $\\tau \\in (0,1)$ is a prescribed reduction target. If no such $k$ exists within $\\{0,1,\\dots,K\\}$, report $N_\\tau^{(A)} = K+1$.\n\n- Estimated asymptotic convergence factor $\\widehat{c}^{(A)}$: define $\\Delta_k^{(A)} = \\log r_{k+1}^{(A)} - \\log r_k^{(A)}$ and estimate \n$$\n\\widehat{c}^{(A)} \\;=\\; \\exp\\!\\left( \\frac{1}{m} \\sum_{k=K-m}^{K-1} \\Delta_k^{(A)} \\right),\n$$\nwhere $m = \\min\\{M, K\\}$ and $M \\in \\mathbb{N}$ is a prescribed window length. This estimator targets the geometric mean contraction factor over the last $m$ steps and converges to the asymptotic factor under standard fixed-point assumptions.\n\n- Monotonicity violation count $V^{(A)}$: the number of indices $k \\in \\{0,1,\\dots,K-1\\}$ such that $r_{k+1}^{(A)}  r_k^{(A)}$.\n\nUsing these diagnostics, define a dominance predicate for SIMPLER over SIMPLE as a boolean:\n$$\n\\text{Dominates} \\;=\\; \\Big( N_\\tau^{(\\text{SIMPLER})}  N_\\tau^{(\\text{SIMPLE})} \\Big) \\;\\wedge\\; \\Big( \\widehat{c}^{(\\text{SIMPLER})}  \\widehat{c}^{(\\text{SIMPLE})} - \\delta \\Big),\n$$\nwhere $\\delta  0$ is a prescribed margin that enforces a meaningful gap in the estimated asymptotic factors. This predicate operationalizes the claim that SIMPLER reduces residuals faster both in finite iteration-to-target and in asymptotic convergence behavior, holding all else constant.\n\nImplement a complete, runnable program that:\n- Generates residual histories from the parametric model above for both algorithms and for each test case.\n- Computes $N_\\tau^{(A)}$, $\\widehat{c}^{(A)}$, and $V^{(A)}$ for $A \\in \\{\\text{SIMPLE}, \\text{SIMPLER}\\}$.\n- Evaluates the dominance predicate for SIMPLER using the margin $\\delta$.\n- Produces the final output containing, for each test case, the list \n$$\n\\left[\\, N_\\tau^{(\\text{SIMPLE})},\\; N_\\tau^{(\\text{SIMPLER})},\\; \\widehat{c}^{(\\text{SIMPLE})},\\; \\widehat{c}^{(\\text{SIMPLER})},\\; V^{(\\text{SIMPLE})},\\; V^{(\\text{SIMPLER})},\\; \\text{Dominates} \\,\\right],\n$$\nin that exact order.\n\nGlobal parameters common to all test cases:\n- Target reduction factor $\\tau = 10^{-6}$.\n- Estimation window length $M = 20$.\n- Asymptotic gap margin $\\delta = 10^{-2}$.\n\nTest suite specification, covering a general case, a boundary case, an oscillatory case, and a near-stagnation edge case:\n- Case $1$ (general): $r_0 = 1.0$, $K = 200$, $a = 0.0$, $c_{\\text{SIMPLE}} = 0.85$, $c_{\\text{SIMPLER}} = 0.65$.\n- Case $2$ (boundary equal rates): $r_0 = 1.0$, $K = 200$, $a = 0.0$, $c_{\\text{SIMPLE}} = 0.70$, $c_{\\text{SIMPLER}} = 0.70$.\n- Case $3$ (oscillatory transients): $r_0 = 1.0$, $K = 200$, $a = 0.15$, $c_{\\text{SIMPLE}} = 0.80$, $c_{\\text{SIMPLER}} = 0.75$.\n- Case $4$ (near-stagnation for SIMPLE): $r_0 = 1.0$, $K = 500$, $a = 0.02$, $c_{\\text{SIMPLE}} = 0.99$, $c_{\\text{SIMPLER}} = 0.90$.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list of per-case lists enclosed in square brackets, for example, \n$[ [\\dots], [\\dots], [\\dots], [\\dots] ]$.", "solution": "The problem statement has been meticulously validated and is determined to be sound. It is scientifically grounded in the principles of computational fluid dynamics and numerical analysis, specifically concerning the iterative solution of the incompressible Navier-Stokes equations. The problem is well-posed, providing a complete and consistent set of definitions, parameters, and objectives. All terms are formally defined, enabling a unique and verifiable solution. The use of a parametric model for residual histories is a valid and common technique for creating a controlled, synthetic environment to test and compare the performance of numerical algorithms.\n\nThe task is to implement a set of diagnostics to compare the convergence behavior of the SIMPLE and SIMPLER algorithms based on synthetic residual histories. The comparison is formalized through three metrics and a final dominance predicate. The solution proceeds by implementing these diagnostics for each of the four specified test cases.\n\nThe core of the problem is the parametric model for the residual norm history $r_k^{(A)}$ for an algorithm $A \\in \\{\\text{SIMPLE}, \\text{SIMPLER}\\}$ at iteration $k$:\n$$\nr_k^{(A)} \\;=\\; r_0 \\,\\frac{\\left(c_A\\right)^k \\left(1 + a \\cos(\\pi k)\\right)}{1+a}, \\quad k = 0,1,2,\\dots,K\n$$\nHere, $r_0$ is the initial residual, $c_A$ is the asymptotic convergence factor, and the term involving the oscillation amplitude $a$ and $\\cos(\\pi k) = (-1)^k$ models transient, non-monotonic behavior often observed in practice. The denominator $1+a$ ensures the normalization $r_0^{(A)} = r_0$. For each algorithm and test case, we first generate a vector of residual norms $\\{r_k^{(A)}\\}_{k=0}^K$.\n\nBased on this history, we compute the following diagnostics:\n\n1.  **Iteration-to-target count $N_\\tau^{(A)}$**: This metric quantifies the practical speed of convergence. It is defined as the minimum number of iterations $k$ required for the residual norm to fall below a target threshold, $r_k^{(A)} \\le r_0 \\tau$. The target reduction factor is given as $\\tau = 10^{-6}$. We search for the smallest $k \\in \\{0, 1, \\dots, K\\}$ that satisfies this condition. If the condition is not met within the maximum of $K$ iterations, the count is reported as $K+1$.\n\n2.  **Estimated asymptotic convergence factor $\\widehat{c}^{(A)}$**: This metric estimates the underlying linear convergence rate of the algorithm, which governs its long-term behavior. It is calculated using the final $m = \\min\\{M, K\\}$ iterations of the residual history, where $M=20$ is the estimation window length. The formula is:\n    $$\n    \\widehat{c}^{(A)} \\;=\\; \\exp\\!\\left( \\frac{1}{m} \\sum_{k=K-m}^{K-1} \\left( \\log r_{k+1}^{(A)} - \\log r_k^{(A)} \\right) \\right)\n    $$\n    This is the geometric mean of the single-step reduction factors $r_{k+1}^{(A)}/r_k^{(A)}$ over the specified window. For the given residual model, the term $\\log r_{k+1}^{(A)} - \\log r_k^{(A)}$ can be expanded as $\\log(c_A) + \\log((1+a(-1)^{k+1})/(1+a(-1)^k))$. When the window size $m$ is an even number (as is the case here since $M=20$ and all $K \\ge 20$), the oscillatory terms form a telescoping product that evaluates to $1$, and its logarithm is $0$. Thus, the estimator is designed to precisely recover the true base contraction factor, $\\widehat{c}^{(A)} = c_A$, under these specific conditions.\n\n3.  **Monotonicity violation count $V^{(A)}$**: This metric counts the number of times the residual increases from one iteration to the next, i.e., $r_{k+1}^{(A)}  r_k^{(A)}$ for $k \\in \\{0, 1, \\dots, K-1\\}$. This serves as a measure of the non-monotonicity or oscillatory nature of the convergence. A non-zero value is expected when the oscillation amplitude $a$ is sufficiently large relative to the contraction factor $c_A$.\n\nFinally, these diagnostics are synthesized into a single boolean **Dominance Predicate**:\n$$\n\\text{Dominates} \\;=\\; \\Big( N_\\tau^{(\\text{SIMPLER})}  N_\\tau^{(\\text{SIMPLE})} \\Big) \\;\\wedge\\; \\Big( \\widehat{c}^{(\\text{SIMPLER})}  \\widehat{c}^{(\\text{SIMPLE})} - \\delta \\Big)\n$$\nThis predicate is true if and only if the SIMPLER algorithm is superior to SIMPLE both in terms of reaching the target residual in fewer iterations and in having a significantly smaller asymptotic convergence factor. The margin $\\delta = 10^{-2}$ ensures the difference in asymptotic rates is meaningful.\n\nThe implementation will process cach of the four test cases by generating the two residual histories (one for SIMPLE, one for SIMPLER), calculating the three diagnostics for each, evaluating the dominance predicate, and collecting the results as specified.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the diagnostic plan for all test cases and print results.\n    \"\"\"\n    \n    # Global parameters common to all test cases\n    tau = 1e-6\n    M = 20\n    delta = 1e-2\n\n    # Test suite specification\n    test_cases = [\n        # Case 1 (general)\n        {'r0': 1.0, 'K': 200, 'a': 0.0, 'c_simple': 0.85, 'c_simpler': 0.65},\n        # Case 2 (boundary equal rates)\n        {'r0': 1.0, 'K': 200, 'a': 0.0, 'c_simple': 0.70, 'c_simpler': 0.70},\n        # Case 3 (oscillatory transients)\n        {'r0': 1.0, 'K': 200, 'a': 0.15, 'c_simple': 0.80, 'c_simpler': 0.75},\n        # Case 4 (near-stagnation for SIMPLE)\n        {'r0': 1.0, 'K': 500, 'a': 0.02, 'c_simple': 0.99, 'c_simpler': 0.90},\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        r0 = case['r0']\n        K = case['K']\n        a = case['a']\n        c_simple = case['c_simple']\n        c_simpler = case['c_simpler']\n        \n        params = {\n            'SIMPLE': c_simple,\n            'SIMPLER': c_simpler,\n        }\n        \n        results_per_algo = {}\n\n        for algo_name, c_A in params.items():\n            # Generate residual history\n            k_range = np.arange(K + 1)\n            # The term cos(pi*k) is equivalent to (-1)^k\n            oscillation_term = 1 + a * (-1)**k_range\n            r_k = r0 * (c_A**k_range * oscillation_term) / (1 + a)\n            \n            # --- Diagnostic 1: Iteration-to-target count N_tau ---\n            target_residual = r0 * tau\n            indices_below_target = np.where(r_k = target_residual)[0]\n            if indices_below_target.size  0:\n                N_tau = indices_below_target[0]\n            else:\n                N_tau = K + 1\n\n            # --- Diagnostic 2: Estimated asymptotic convergence factor c_hat ---\n            m = min(M, K)\n            if m  0:\n                # Log of residuals in the estimation window [K-m, K]\n                log_r_window = np.log(r_k[K - m : K + 1])\n                # Differences of consecutive log residuals\n                delta_k = log_r_window[1:] - log_r_window[:-1]\n                c_hat = np.exp(np.mean(delta_k))\n            else: # Edge case for K=0, although problem constraints imply K=1\n                c_hat = np.nan\n\n            # --- Diagnostic 3: Monotonicity violation count V ---\n            # Count where r_{k+1}  r_k for k in [0, K-1]\n            V = np.sum(r_k[1:]  r_k[:-1])\n\n            results_per_algo[algo_name] = {\n                'N_tau': N_tau,\n                'c_hat': c_hat,\n                'V': V,\n            }\n\n        # --- Dominance Predicate ---\n        N_tau_simple = results_per_algo['SIMPLE']['N_tau']\n        N_tau_simpler = results_per_algo['SIMPLER']['N_tau']\n        c_hat_simple = results_per_algo['SIMPLE']['c_hat']\n        c_hat_simpler = results_per_algo['SIMPLER']['c_hat']\n        \n        dominates = (N_tau_simpler  N_tau_simple) and \\\n                    (c_hat_simpler  c_hat_simple - delta)\n\n        # Assemble final list for the case\n        case_result = [\n            N_tau_simple,\n            N_tau_simpler,\n            c_hat_simple,\n            c_hat_simpler,\n            results_per_algo['SIMPLE']['V'],\n            results_per_algo['SIMPLER']['V'],\n            dominates\n        ]\n        all_results.append(case_result)\n\n    # Format the final output string as specified\n    # The str() of a list automatically includes spaces, e.g., '[1, 2, 3]'\n    # Joining these with a comma produces '...,[...],[...],...'\n    # The final wrapping brackets gives '[[...],[...],...]'\n    final_output_string = f\"[{','.join(map(str, all_results))}]\"\n    print(final_output_string)\n\nsolve()\n```", "id": "3442976"}]}