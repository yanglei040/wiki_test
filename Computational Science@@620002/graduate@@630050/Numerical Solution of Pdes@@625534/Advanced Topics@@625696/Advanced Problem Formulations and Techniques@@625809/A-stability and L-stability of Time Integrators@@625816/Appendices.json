{"hands_on_practices": [{"introduction": "The first step in analyzing any time integrator is to determine its stability function, $R(z)$. This function encapsulates how the numerical scheme amplifies or damps different components of the solution. This practice provides a foundational exercise in deriving $R(z)$ for a specific implicit Runge-Kutta method and then rigorously assessing its A- and L-stability properties directly from their definitions, a critical skill for evaluating a method's suitability for stiff problems like the heat equation. [@problem_id:3360286]", "problem": "Consider the one-dimensional heat equation with homogeneous Dirichlet boundary conditions,\n$$\nu_{t}(x,t) = \\nu\\,u_{xx}(x,t), \\quad x \\in (0,1), \\quad t \\geq 0, \\quad u(0,t) = u(1,t) = 0,\n$$\nwhere $\\nu  0$ is the thermal diffusivity. Let a standard second-order central difference semi-discretization in space on a uniform grid of $N$ interior points with mesh width $h = \\frac{1}{N+1}$ be used, yielding the system of ordinary differential equations\n$$\n\\frac{d}{dt}\\mathbf{u}(t) = A_{h}\\,\\mathbf{u}(t),\n$$\nwhere $\\mathbf{u}(t) \\in \\mathbb{R}^{N}$ collects the nodal values and $A_{h} = \\frac{\\nu}{h^{2}}L$ with $L \\in \\mathbb{R}^{N \\times N}$ the tridiagonal matrix with entries $L_{jj} = -2$, $L_{j,j+1} = L_{j+1,j} = 1$, and zeros otherwise. It is known that the spectrum of $A_{h}$ satisfies $\\sigma(A_{h}) \\subset (-\\infty,0)$ and, for each eigenvalue $\\lambda \\in \\sigma(A_{h})$, the corresponding mode satisfies the scalar test equation $\\frac{d}{dt}y(t) = \\lambda\\,y(t)$.\n\nTime-integrate this semi-discrete system with the following two-stage singly diagonally implicit Runge–Kutta (SDIRK) method (the Alexander second-order method), whose Butcher coefficients are\n$$\n\\begin{array}{c|cc}\n\\gamma  \\gamma  0 \\\\\n1  1-\\gamma  \\gamma \\\\\n\\hline\n  1-\\gamma  \\gamma\n\\end{array}\n\\quad \\text{with} \\quad \\gamma = 1 - \\frac{1}{\\sqrt{2}}.\n$$\nApply the method to the scalar test equation $\\frac{d}{dt}y(t) = \\lambda\\,y(t)$ and define $z = \\Delta t\\,\\lambda$, where $\\Delta t  0$ is the time step. Derive the stability function $R(z)$ of this method, expressed as a single closed-form analytic function of $z$ with $\\gamma$ substituted by $1 - \\frac{1}{\\sqrt{2}}$.\n\nThen, using only the spectral characterization of $A_{h}$ together with your derived $R(z)$, assess whether the method is $A$-stable and whether it is $L$-stable for this semi-discrete heat equation. Base your reasoning on fundamental definitions: $A$-stability means $|R(z)| \\leq 1$ for all $z$ with $\\operatorname{Re}(z) \\leq 0$, and $L$-stability means $A$-stability together with $\\lim_{z \\to -\\infty} R(z) = 0$. You must not invoke any canned stability theorems; reason directly from the definitions and the spectrum of $A_{h}$.\n\nYour final answer must be the derived closed-form expression for $R(z)$. No rounding is required.", "solution": "The problem statement is valid as it describes a standard, well-posed problem in numerical analysis concerning the stability of a time integration scheme for a partial differential equation. It is scientifically sound, objective, and contains all necessary information.\n\nThe task is to derive the stability function $R(z)$ for the given two-stage singly diagonally implicit Runge–Kutta (SDIRK) method and subsequently analyze its $A$-stability and $L$-stability properties.\n\nThe Butcher tableau for the method is:\n$$\n\\begin{array}{c|cc}\n\\gamma  \\gamma  0 \\\\\n1  1-\\gamma  \\gamma \\\\\n\\hline\n  1-\\gamma  \\gamma\n\\end{array}\n$$\nwith $\\gamma = 1 - \\frac{1}{\\sqrt{2}}$.\n\nWe apply this method to the scalar test equation $\\frac{d}{dt}y(t) = \\lambda y(t)$. A single step of the Runge-Kutta method from $y_n$ to $y_{n+1}$ is given by computing the stage values $Y_1, Y_2$ and then the final result.\n\nThe stage values $Y_i$ are approximations to $y(t_n + c_i \\Delta t)$. For an implicit method, they are defined by:\n$$\nY_i = y_n + \\Delta t \\sum_{j=1}^{2} a_{ij} f(Y_j)\n$$\nwhere $f(Y_j) = \\lambda Y_j$. Let $z = \\Delta t \\lambda$. The stage equations become:\n$$\nY_i = y_n + z \\sum_{j=1}^{2} a_{ij} Y_j\n$$\nFor the given method ($a_{11}=\\gamma$, $a_{12}=0$, $a_{21}=1-\\gamma$, $a_{22}=\\gamma$):\n\nStage $1$:\n$$\nY_1 = y_n + z a_{11} Y_1 = y_n + z \\gamma Y_1\n$$\nSolving for $Y_1$:\n$$\nY_1(1 - z\\gamma) = y_n \\implies Y_1 = \\frac{y_n}{1 - z\\gamma}\n$$\n\nStage $2$:\n$$\nY_2 = y_n + z(a_{21}Y_1 + a_{22}Y_2) = y_n + z(1-\\gamma)Y_1 + z\\gamma Y_2\n$$\nSolving for $Y_2$:\n$$\nY_2(1 - z\\gamma) = y_n + z(1-\\gamma)Y_1\n$$\nSubstitute the expression for $Y_1$:\n$$\nY_2(1 - z\\gamma) = y_n + z(1-\\gamma)\\frac{y_n}{1 - z\\gamma}\n$$\n$$\nY_2 = \\frac{y_n}{1 - z\\gamma} + \\frac{z(1-\\gamma)y_n}{(1 - z\\gamma)^2} = \\frac{y_n(1 - z\\gamma) + z(1-\\gamma)y_n}{(1 - z\\gamma)^2}\n$$\n$$\nY_2 = \\frac{y_n(1 - z\\gamma + z - z\\gamma)}{(1 - z\\gamma)^2} = y_n \\frac{1 + z(1-2\\gamma)}{(1 - z\\gamma)^2}\n$$\nThe update step is given by:\n$$\ny_{n+1} = y_n + \\Delta t \\sum_{i=1}^{2} b_i f(Y_i) = y_n + z \\sum_{i=1}^{2} b_i Y_i\n$$\nWith $b_1 = 1-\\gamma$ and $b_2 = \\gamma$:\n$$\ny_{n+1} = y_n + z(1-\\gamma)Y_1 + z\\gamma Y_2\n$$\nThe stability function $R(z)$ is defined by $y_{n+1} = R(z)y_n$.\nThe method's update is $y_{n+1} = y_n + \\Delta t((1-\\gamma) f(Y_1) + \\gamma f(Y_2))$. For this method, the coefficients are $b_i = a_{2i}$. Such a method is called stiffly accurate, and $y_{n+1} = Y_2$.\nLet's verify this from the Butcher tableau: $b_1 = 1-\\gamma = a_{21}$ and $b_2 = \\gamma = a_{22}$. This is correct.\nTherefore, $y_{n+1} = Y_2$.\nThe stability function is simply:\n$$\nR(z) = \\frac{y_{n+1}}{y_n} = \\frac{Y_2}{y_n} = \\frac{1 + z(1-2\\gamma)}{(1 - z\\gamma)^2}\n$$\nThis is a much more direct derivation.\nNow we substitute the given value $\\gamma = 1 - \\frac{1}{\\sqrt{2}} = 1 - \\frac{\\sqrt{2}}{2}$:\n$$\n1-2\\gamma = 1 - 2\\left(1 - \\frac{\\sqrt{2}}{2}\\right) = 1 - 2 + \\sqrt{2} = \\sqrt{2}-1\n$$\nSo, the stability function is:\n$$\nR(z) = \\frac{1 + (\\sqrt{2}-1)z}{\\left(1 - \\left(1-\\frac{\\sqrt{2}}{2}\\right)z\\right)^2}\n$$\nThis is the required closed-form expression.\n\nNext, we assess the stability properties.\n**A-stability**: A method is $A$-stable if its region of absolute stability contains the entire left half of the complex plane, i.e., $|R(z)| \\le 1$ for all $z \\in \\mathbb{C}$ with $\\operatorname{Re}(z) \\le 0$.\nThe stability function $R(z)$ is a rational function of $z$.\nThe poles of $R(z)$ are given by the roots of the denominator, $1 - z\\gamma = 0$, which gives $z = 1/\\gamma$.\nSince $\\gamma = 1 - \\frac{1}{\\sqrt{2}} \\approx 1 - 0.707 = 0.293  0$, the pole $z = 1/\\gamma$ is in the right-half plane, $\\operatorname{Re}(z)  0$.\nThus, $R(z)$ is analytic for all $z$ with $\\operatorname{Re}(z) \\le 0$.\nBy the Maximum Modulus Principle, if $|R(z)| \\le 1$ on the boundary of this region (i.e., the imaginary axis, $z=iy$ for $y \\in \\mathbb{R}$) and at infinity, then $|R(z)| \\le 1$ throughout the region.\nLet's check the imaginary axis, $z = iy$:\n$$\n|R(iy)|^2 = \\frac{|1 + iy(\\sqrt{2}-1)|^2}{|(1 - iy(1-\\frac{\\sqrt{2}}{2}))^2|^2} = \\frac{1^2 + y^2(\\sqrt{2}-1)^2}{(1^2 + y^2(1-\\frac{\\sqrt{2}}{2})^2)^2}\n$$\nLet's simplify the coefficients: $\\gamma=1-\\frac{\\sqrt{2}}{2}$.\n$1-2\\gamma = \\sqrt{2}-1$. Also, $2\\gamma-\\gamma^2 = \\gamma(2-\\gamma) = (1-\\frac{\\sqrt{2}}{2})(2-(1-\\frac{\\sqrt{2}}{2})) = (1-\\frac{\\sqrt{2}}{2})(1+\\frac{\\sqrt{2}}{2}) = 1 - (\\frac{\\sqrt{2}}{2})^2 = 1 - \\frac{2}{4} = \\frac{1}{2}$.\nThe Taylor expansion of $R(z)$ around $z=0$ is $R(z) = \\frac{1+z(1-2\\gamma)}{(1-z\\gamma)^2} = (1+z(1-2\\gamma))(1+2z\\gamma+3z^2\\gamma^2+\\dots) = 1+z(1-2\\gamma+2\\gamma) + z^2(2\\gamma(1-2\\gamma)+3\\gamma^2) + \\dots = 1+z+z^2(2\\gamma-4\\gamma^2+3\\gamma^2)+\\dots=1+z+z^2(2\\gamma-\\gamma^2)+\\dots = 1+z+\\frac{1}{2}z^2+\\dots$, which confirms second-order accuracy.\nGoing back to $|R(iy)|^2$:\nThe condition $|R(iy)| \\le 1$ is equivalent to $|R(iy)|^2 \\le 1$:\n$$\n1 + y^2(\\sqrt{2}-1)^2 \\le \\left(1 + y^2\\left(1-\\frac{\\sqrt{2}}{2}\\right)^2\\right)^2\n$$\nNotice that $\\left(1-\\frac{\\sqrt{2}}{2}\\right)^2 = \\left(\\frac{2-\\sqrt{2}}{2}\\right)^2 = \\frac{4-4\\sqrt{2}+2}{4} = \\frac{6-4\\sqrt{2}}{4} = \\frac{3-2\\sqrt{2}}{2}$, and $(\\sqrt{2}-1)^2 = 2-2\\sqrt{2}+1 = 3-2\\sqrt{2}$.\nLet $a = y^2(3-2\\sqrt{2})$. Since $3-2\\sqrt{2}  0$, we have $a \\ge 0$. The inequality becomes:\n$$\n1 + a \\le \\left(1 + \\frac{a}{2}\\right)^2\n$$\n$$\n1 + a \\le 1 + a + \\frac{a^2}{4}\n$$\n$$\n0 \\le \\frac{a^2}{4}\n$$\nThis inequality is true for all real $a$, and therefore for all $y \\in \\mathbb{R}$. So, $|R(iy)| \\le 1$.\nNow we check the limit as $|z| \\to \\infty$ in the left-half plane:\n$$\n\\lim_{|z|\\to\\infty, \\operatorname{Re}(z)\\le 0} |R(z)| = \\lim_{|z|\\to\\infty} \\left|\\frac{1 + z(1-2\\gamma)}{1-2z\\gamma+z^2\\gamma^2}\\right| = \\lim_{|z|\\to\\infty} \\left|\\frac{z(1-2\\gamma)}{z^2\\gamma^2}\\right| = \\lim_{|z|\\to\\infty} \\left|\\frac{1-2\\gamma}{\\gamma^2 z}\\right| = 0\n$$\nSince $|R(z)| \\le 1$ on the boundary and goes to $0$ at infinity, by the Maximum Modulus Principle, $|R(z)| \\le 1$ for all $\\operatorname{Re}(z) \\le 0$. The method is $A$-stable.\n\n**L-stability**: A method is $L$-stable if it is $A$-stable and, in addition, $\\lim_{z \\to -\\infty} R(z) = 0$.\nThe problem concerns the semi-discrete heat equation, for which the eigenvalues $\\lambda$ are real and negative. Thus, the relevant limit is for $z$ approaching $-\\infty$ along the negative real axis.\nWe have already shown that the method is $A$-stable. We now check the limit:\n$$\n\\lim_{z \\to -\\infty} R(z) = \\lim_{z \\to -\\infty} \\frac{1 + z(1-2\\gamma)}{(1 - z\\gamma)^2}\n$$\nThis is a rational function where the degree of the numerator is $1$ and the degree of the denominator is $2$.\n$$\n\\lim_{z \\to -\\infty} \\frac{z(1-2\\gamma)}{z^2\\gamma^2} = \\lim_{z \\to -\\infty} \\frac{1-2\\gamma}{z\\gamma^2} = 0\n$$\nSince the method is $A$-stable and $\\lim_{z \\to -\\infty} R(z) = 0$, the method is $L$-stable. This property is highly desirable for stiff problems like the semi-discretized heat equation, as it ensures that very stiff (highly oscillatory or rapidly decaying) modes are strongly damped by the numerical scheme.", "answer": "$$\\boxed{\\frac{1 + \\left(\\sqrt{2}-1\\right)z}{\\left(1 - \\left(1-\\frac{\\sqrt{2}}{2}\\right)z\\right)^2}}$$", "id": "3360286"}, {"introduction": "Theoretical stability properties have tangible consequences. This computational exercise demonstrates the practical difference between A-stability and the stricter L-stability by solving a linear convection-diffusion equation, a classic model for stiff systems. You will compare the L-stable Backward Euler scheme with the merely A-stable Crank-Nicolson scheme, using Fourier analysis to directly observe and quantify the non-physical oscillations that arise from Crank-Nicolson's failure to damp the stiffest modes of the solution. [@problem_id:3360288]", "problem": "Consider the one-dimensional linear convection–diffusion partial differential equation (PDE) on a periodic domain,\n$$\nu_t(x,t) + b\\,u_x(x,t) = \\kappa\\,u_{xx}(x,t),\n$$\nfor $x \\in [0,L]$, with period $L$, constant convection speed $b \\in \\mathbb{R}$, and diffusion coefficient $\\kappa  0$. Assume a spatial semi-discretization on a uniform grid with $N$ points and grid spacing $h = L/N$, periodic boundary conditions, and the following standard second-order central differences for the spatial operators:\n- For the first derivative, use $(u_{j+1} - u_{j-1})/(2h)$, which has discrete Fourier symbol $i\\,\\sin(\\theta)/h$.\n- For the second derivative, use $(u_{j+1} - 2u_j + u_{j-1})/h^2$, which has discrete Fourier symbol $-4\\,\\sin^2(\\theta/2)/h^2$.\nHere, $\\theta = 2\\pi m/N$ for Fourier mode index $m \\in \\{0,1,\\dots,N-1\\}$.\n\nThe semi-discrete system can therefore be written as $\\partial_t u = \\mathcal{L} u$, where $\\mathcal{L}$ is the discrete linear spatial operator whose action on the discrete Fourier mode corresponding to $\\theta$ has eigenvalue\n$$\n\\lambda(\\theta) = -i\\,b\\,\\frac{\\sin(\\theta)}{h} - \\kappa\\,\\frac{4\\sin^2(\\theta/2)}{h^2}.\n$$\n\nTwo implicit time integrators are to be contrasted:\n1. Backward Euler (implicit Euler), defined by $(I - \\Delta t\\,\\mathcal{L})\\,u^{n+1} = u^{n}$.\n2. Crank–Nicolson, defined by $\\left(I - \\frac{\\Delta t}{2}\\,\\mathcal{L}\\right) u^{n+1} = \\left(I + \\frac{\\Delta t}{2}\\,\\mathcal{L}\\right) u^{n}$.\n\nStarting from the widely used linear test equation $y'(t) = \\lambda\\,y(t)$ and the definitions of the schemes above, derive the corresponding scalar stability functions $R(z)$, where $z = \\Delta t\\,\\lambda$, for backward Euler and Crank–Nicolson. Then, using the discrete Fourier symbols for $\\lambda(\\theta)$ specified above, design a one-step Fourier-space propagator for each scheme so that $\\widehat{u}^{n+1}(\\theta) = R\\!\\left(\\Delta t\\,\\lambda(\\theta)\\right)\\,\\widehat{u}^{n}(\\theta)$, where $\\widehat{u}$ denotes the discrete Fourier transform of $u$.\n\nDefine the measure of oscillations as follows, using the single-step update from $t=0$ to $t=\\Delta t$:\n- Consider the initial condition\n$$\nu(x,0) = \n\\begin{cases}\n1,  0 \\le x  L/2, \\\\\n0,  L/2 \\le x  L,\n\\end{cases}\n$$\ninterpreted on the periodic grid. This is a discontinuous step function that excites a wide spectrum of Fourier modes, including the stiffest high-frequency components.\n- For each scheme (backward Euler and Crank–Nicolson), compute $u(x,\\Delta t)$ via the Fourier-space one-step update.\n- Define the undershoot amplitude for a scheme as the minimum value of $u(x,\\Delta t)$, which quantifies oscillations producing values below $0$. Define the overshoot amplitude for a scheme as $\\max\\{u(x,\\Delta t)-1,\\,0\\}$, which quantifies values above $1$.\n\nAdditionally, to connect oscillations to non–$L$-stability, quantify the high-frequency stiff-mode amplification using the magnitude of the stability function evaluated at the Nyquist mode $\\theta_{\\mathrm{nyq}} = \\pi$ (i.e., $m = N/2$), namely\n$$\nG_{\\mathrm{nyq}}^{\\mathrm{scheme}} = \\left|R\\big(\\Delta t\\,\\lambda(\\pi)\\big)\\right|.\n$$\nRecall that for $L$-stability (stiff decay), one requires $R(\\infty) = 0$, meaning that infinitely stiff modes are completely damped; otherwise, nonzero $R(\\infty)$ implies persistent (or alternating-sign) high-frequency components that manifest as oscillations.\n\nYour task is to:\n- Derive the stability functions $R(z)$ for backward Euler and Crank–Nicolson from the scheme definitions applied to $y'=\\lambda y$.\n- Construct the one-step Fourier-space propagators using the given discrete symbols.\n- Implement a complete program that:\n  1. Sets $L = 2\\pi$, $N = 256$, and builds the step-function initial condition on the grid.\n  2. For each specified test case, computes the one-step update for both schemes by multiplying Fourier coefficients with $R\\!\\left(\\Delta t\\,\\lambda(\\theta)\\right)$ and transforming back to physical space.\n  3. Measures the undershoot and overshoot amplitudes as defined above.\n  4. Computes $G_{\\mathrm{nyq}}^{\\mathrm{scheme}}$ for both schemes.\n  5. Outputs, for each test case, a list of six floats\n     $$\n     \\big[\\min(u_{\\mathrm{CN}}),\\,\\min(u_{\\mathrm{BE}}),\\,\\max\\{u_{\\mathrm{CN}}-1,0\\},\\,\\max\\{u_{\\mathrm{BE}}-1,0\\},\\,G_{\\mathrm{nyq}}^{\\mathrm{CN}},\\,G_{\\mathrm{nyq}}^{\\mathrm{BE}}\\big],\n     $$\n     in that order.\n\nAll quantities are dimensionless; no physical units are required.\n\nTest suite:\n- Case 1 (stiff diffusion, no convection): $b = 0.0$, $\\kappa = 100.0$, $\\Delta t = 0.5$.\n- Case 2 (stiff diffusion with convection): $b = 3.0$, $\\kappa = 100.0$, $\\Delta t = 0.5$.\n- Case 3 (moderately diffusive, small time step): $b = 0.0$, $\\kappa = 1.0$, $\\Delta t = 10^{-4}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is itself a six-element list for one test case, with no spaces. For example: \n$$\n[\\,[a_1,b_1,c_1,d_1,e_1,f_1],[a_2,b_2,c_2,d_2,e_2,f_2],[a_3,b_3,c_3,d_3,e_3,f_3]\\,].\n$$", "solution": "The problem statement is a well-posed and scientifically grounded exercise in the numerical analysis of partial differential equations. It concerns the stability and oscillatory properties of two common time integration schemes, backward Euler and Crank-Nicolson, when applied to a semi-discretized convection-diffusion equation. All definitions, parameters, and objectives are stated clearly and are consistent with standard theory in the field. The problem is therefore valid.\n\nThe solution proceeds in two main parts: first, a theoretical derivation of the necessary components (stability functions and propagators), and second, a description of the numerical implementation to compute the required metrics.\n\n**1. Derivation of Stability Functions and Propagators**\n\nTo analyze the stability of time integration schemes, we apply them to the linear test equation $y'(t) = \\lambda y(t)$, where $\\lambda \\in \\mathbb{C}$ is a complex number with $\\text{Re}(\\lambda) \\le 0$. A single step of a numerical scheme updates the solution from time $t_n$ to $t_{n+1} = t_n + \\Delta t$ as $y^{n+1} = R(z) y^n$, where $z = \\lambda \\Delta t$. The function $R(z)$ is the scalar stability function of the scheme.\n\n**1.1. Backward Euler (BE)**\nThe backward Euler scheme is defined by the implicit relation:\n$$\n\\frac{u^{n+1} - u^n}{\\Delta t} = \\mathcal{L} u^{n+1}\n$$\nApplying this to the test equation, where $\\mathcal{L}$ corresponds to multiplication by $\\lambda$:\n$$\ny^{n+1} - y^n = \\Delta t \\lambda y^{n+1}\n$$\nSolving for $y^{n+1}$:\n$$\ny^{n+1} (1 - \\Delta t \\lambda) = y^n\n$$\n$$\ny^{n+1} = \\frac{1}{1 - \\Delta t \\lambda} y^n\n$$\nThus, the stability function for backward Euler is:\n$$\nR_{\\mathrm{BE}}(z) = \\frac{1}{1-z}\n$$\n\n**1.2. Crank-Nicolson (CN)**\nThe Crank-Nicolson scheme is defined by the implicit relation:\n$$\n\\frac{u^{n+1} - u^n}{\\Delta t} = \\frac{1}{2} (\\mathcal{L} u^n + \\mathcal{L} u^{n+1})\n$$\nApplying this to the test equation:\n$$\ny^{n+1} - y^n = \\frac{\\Delta t}{2} (\\lambda y^n + \\lambda y^{n+1})\n$$\nSolving for $y^{n+1}$:\n$$\ny^{n+1} \\left(1 - \\frac{\\Delta t \\lambda}{2}\\right) = y^n \\left(1 + \\frac{\\Delta t \\lambda}{2}\\right)\n$$\n$$\ny^{n+1} = \\frac{1 + \\Delta t \\lambda / 2}{1 - \\Delta t \\lambda / 2} y^n\n$$\nThus, the stability function for Crank-Nicolson is:\n$$\nR_{\\mathrm{CN}}(z) = \\frac{1 + z/2}{1 - z/2}\n$$\n\n**1.3. L-Stability and Connection to Oscillations**\nA scheme is $A$-stable if $|R(z)| \\le 1$ for all $z$ with $\\text{Re}(z) \\le 0$. A scheme is $L$-stable if it is $A$-stable and additionally satisfies $\\lim_{|z| \\to \\infty} |R(z)| = 0$ for $\\text{Re}(z) \\le 0$. This latter condition is critical for damping infinitely stiff modes, which correspond to high-frequency spatial components such as discontinuities.\n- For backward Euler: $\\lim_{|z| \\to \\infty} |R_{\\mathrm{BE}}(z)| = \\lim_{|z| \\to \\infty} \\left|\\frac{1}{1-z}\\right| = 0$. Backward Euler is $L$-stable. It effectively damps stiff components.\n- For Crank-Nicolson: $\\lim_{|z| \\to \\infty} |R_{\\mathrm{CN}}(z)| = \\lim_{|z| \\to \\infty} \\left|\\frac{1+z/2}{1-z/2}\\right| = \\lim_{|z| \\to \\infty} \\left|\\frac{1/z+1/2}{1/z-1/2}\\right| = \\left|\\frac{1/2}{-1/2}\\right| = 1$. Crank-Nicolson is $A$-stable but not $L$-stable. It fails to damp stiff components, which can manifest as persistent, non-physical oscillations in the numerical solution, particularly near sharp gradients.\n\n**1.4. Fourier-Space Propagator**\nThe semi-discrete system $\\partial_t u = \\mathcal{L}u$ is a system of coupled ordinary differential equations (ODEs) for the grid point values $u_j(t)$. By applying a discrete Fourier transform (DFT), this system is diagonalized. Each Fourier mode $\\widehat{u}(\\theta)$ evolves independently according to the ODE:\n$$\n\\frac{d}{dt}\\widehat{u}(\\theta, t) = \\lambda(\\theta)\\,\\widehat{u}(\\theta, t)\n$$\nwhere $\\lambda(\\theta)$ is the eigenvalue of the operator $\\mathcal{L}$ for the mode corresponding to $\\theta = 2\\pi m/N$. This is an instance of the scalar test equation. Therefore, a single time step from $t_n$ to $t_{n+1}$ updates each Fourier coefficient as:\n$$\n\\widehat{u}^{n+1}(\\theta) = R(\\Delta t\\,\\lambda(\\theta))\\,\\widehat{u}^{n}(\\theta)\n$$\nThe one-step Fourier propagator is the array of values $R(\\Delta t\\,\\lambda(\\theta))$ for all discrete modes $\\theta$.\n\n**2. Numerical Implementation and Metrics**\n\nThe algorithm to solve the problem is as follows:\n1.  Set the physical and numerical parameters: $L=2\\pi$, $N=256$. From these, calculate the grid spacing $h=L/N$.\n2.  Define the spatial grid $x_j = j h$ for $j=0, 1, \\dots, N-1$.\n3.  Construct the initial condition array $u_0$, representing the step function on the grid. $u_j(0) = 1$ for $j=0, \\dots, N/2-1$ and $u_j(0)=0$ otherwise.\n4.  Construct the array of dimensionless wavenumbers $\\theta_m = 2\\pi m/N$. For use with `numpy.fft`, the effective mode indices $m$ are ordered as $0, 1, \\dots, N/2-1, -N/2, \\dots, -1$. This is conveniently generated using `np.fft.fftfreq`.\n5.  For each test case $(b, \\kappa, \\Delta t)$:\n    a. Calculate the array of eigenvalues $\\lambda(\\theta)$ for all modes using the given formula:\n    $$\n    \\lambda(\\theta) = -i\\,b\\,\\frac{\\sin(\\theta)}{h} - \\kappa\\,\\frac{4\\sin^2(\\theta/2)}{h^2}\n    $$\n    b. Compute the array $z = \\Delta t\\,\\lambda(\\theta)$.\n    c. Compute the propagator arrays for both schemes: $R_{\\mathrm{BE}}(z)$ and $R_{\\mathrm{CN}}(z)$.\n    d. Compute the DFT of the initial condition: $\\widehat{u}^0 = \\text{DFT}(u_0)$.\n    e. Propagate for one step in Fourier space: $\\widehat{u}^1_{\\mathrm{BE}} = R_{\\mathrm{BE}}(z) \\odot \\widehat{u}^0$ and $\\widehat{u}^1_{\\mathrm{CN}} = R_{\\mathrm{CN}}(z) \\odot \\widehat{u}^0$, where $\\odot$ is element-wise multiplication.\n    f. Compute the solution at time $\\Delta t$ by applying the inverse DFT: $u^1_{\\mathrm{scheme}} = \\text{IDFT}(\\widehat{u}^1_{\\mathrm{scheme}})$. Since the initial data is real, we take the real part of the result to discard negligible imaginary components from numerical round-off.\n    g. Calculate the oscillation metrics:\n        - Undershoot: $\\min(u^1_{\\mathrm{scheme}})$.\n        - Overshoot: $\\max\\{0, \\max(u^1_{\\mathrm{scheme}}) - 1\\}$.\n    h. Calculate the stiff-mode amplification at the Nyquist frequency, $G_{\\mathrm{nyq}}$. The Nyquist mode corresponds to $\\theta = \\pi$. The eigenvalue is purely real and diffusive:\n    $$\n    \\lambda(\\pi) = -i\\,b\\,\\frac{\\sin(\\pi)}{h} - \\kappa\\,\\frac{4\\sin^2(\\pi/2)}{h^2} = - \\frac{4\\kappa}{h^2}\n    $$\n    Let $z_{\\mathrm{nyq}} = \\Delta t \\lambda(\\pi) = -4\\kappa\\Delta t/h^2$. Then:\n    $$\n    G_{\\mathrm{nyq}}^{\\mathrm{BE}} = |R_{\\mathrm{BE}}(z_{\\mathrm{nyq}})| = \\left|\\frac{1}{1 - z_{\\mathrm{nyq}}}\\right|\n    $$\n    $$\n    G_{\\mathrm{nyq}}^{\\mathrm{CN}} = |R_{\\mathrm{CN}}(z_{\\mathrm{nyq}})| = \\left|\\frac{1 + z_{\\mathrm{nyq}}/2}{1 - z_{\\mathrm{nyq}}/2}\\right|\n    $$\n6.  Collect the six specified floating-point numbers for each test case and format the final output as a list of lists.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of comparing backward Euler and Crank-Nicolson schemes\n    for a convection-diffusion equation, focusing on stability and oscillations.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (stiff diffusion, no convection)\n        (0.0, 100.0, 0.5),\n        # Case 2 (stiff diffusion with convection)\n        (3.0, 100.0, 0.5),\n        # Case 3 (moderately diffusive, small time step)\n        (0.0, 1.0, 1e-4),\n    ]\n\n    # Global parameters\n    L = 2.0 * np.pi\n    N = 256\n    h = L / N\n\n    # Spatial grid and initial condition\n    x = np.arange(N) * h\n    u0 = np.zeros(N)\n    # The condition is u(x,0)=1 for 0 = x  L/2.\n    # On the grid x_j = j*h, this means j*h  L/2 = j  L/(2*h) = N/2.\n    # Indices are 0, 1, ..., N/2 - 1.\n    u0[0:N//2] = 1.0\n\n    # Fourier space setup\n    # theta = 2*pi*m/N, where m are the DFT mode numbers\n    # np.fft.fftfreq(N) gives m/N for the standard FFT ordering\n    theta = 2.0 * np.pi * np.fft.fftfreq(N)\n    u0_hat = np.fft.fft(u0)\n    \n    results = []\n    for b, kappa, dt in test_cases:\n        # 1. Compute eigenvalues and stability function arguments\n        # Eigenvalue of the semi-discrete operator for each mode theta\n        # lambda(theta) = -i*b*sin(theta)/h - kappa*4*sin^2(theta/2)/h^2\n        # Use 2*(1-cos(theta)) for 4*sin^2(theta/2) to avoid creating theta/2 array\n        lambda_theta = (-1j * b * np.sin(theta) / h\n                        - kappa * 2.0 * (1.0 - np.cos(theta)) / h**2)\n        \n        # Stability function argument z = dt * lambda\n        z = dt * lambda_theta\n\n        # 2. Compute the one-step Fourier propagators (R(z))\n        # Backward Euler: R_BE(z) = 1 / (1 - z)\n        R_BE = 1.0 / (1.0 - z)\n        # Crank-Nicolson: R_CN(z) = (1 + z/2) / (1 - z/2)\n        R_CN = (1.0 + 0.5 * z) / (1.0 - 0.5 * z)\n\n        # 3. Propagate one step in Fourier space\n        u1_hat_BE = R_BE * u0_hat\n        u1_hat_CN = R_CN * u0_hat\n\n        # 4. Transform back to physical space and take the real part\n        u1_BE = np.real(np.fft.ifft(u1_hat_BE))\n        u1_CN = np.real(np.fft.ifft(u1_hat_CN))\n\n        # 5. Measure undershoot and overshoot amplitudes\n        # Undershoot is defined as the minimum value of u\n        min_u_cn = np.min(u1_CN)\n        min_u_be = np.min(u1_BE)\n        \n        # Overshoot is defined as max{u-1, 0}\n        overshoot_cn = np.max([np.max(u1_CN) - 1.0, 0.0])\n        overshoot_be = np.max([np.max(u1_BE) - 1.0, 0.0])\n\n        # 6. Compute stiff-mode amplification at Nyquist mode (theta=pi)\n        # lambda_nyq = -4*kappa/h^2, since sin(pi)=0 and sin(pi/2)=1\n        lambda_nyq = -4.0 * kappa / h**2\n        z_nyq = dt * lambda_nyq\n        \n        # G_nyq for BE\n        g_nyq_be = np.abs(1.0 / (1.0 - z_nyq))\n        \n        # G_nyq for CN\n        g_nyq_cn = np.abs((1.0 + 0.5 * z_nyq) / (1.0 - 0.5 * z_nyq))\n\n        # 7. Collect results for the current case\n        case_results = [\n            min_u_cn,\n            min_u_be,\n            overshoot_cn,\n            overshoot_be,\n            g_nyq_cn,\n            g_nyq_be\n        ]\n        results.append(case_results)\n\n    # Final print statement in the exact required format.\n    # Create '[a,b,c],[d,e,f]' string\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    # Enclose in outer '[]'\n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3360288"}, {"introduction": "The true test of a stiff integrator lies in its performance on nonlinear problems, where stiffness can change dynamically with the solution itself. This final practice extends our analysis to a stiff, nonlinear reaction ODE, highlighting the critical importance of L-stability beyond the linear world. By implementing both Backward Euler and the Implicit Midpoint method, you will confront the need for a nonlinear solver and see firsthand how the L-stable method robustly captures the decaying solution while the A-stable method can produce dramatic, non-physical overshoots. [@problem_id:3360266]", "problem": "Consider the scalar initial value problem arising from a semidiscrete reaction term in a partial differential equation, posed abstractly as\n$$\n\\frac{du}{dt} = -p\\big(u + f(u)\\big), \\qquad f(u)=u^p, \\qquad p1,\\qquad u(0)=1,\n$$\nwhere $p$ is a dimensionless stiffness parameter as well as the nonlinearity exponent. The exact solution for $u(t)$ remains nonnegative and monotonically decaying to the stable equilibrium $u^\\star=0$. You will study the qualitative behavior of two implicit, one-step time integrators applied to this problem:\n- Backward Euler (an $L$-stable method),\n- Implicit Midpoint, also known as Crank–Nicolson for ordinary differential equations (an $A$-stable but not $L$-stable method).\n\nYou must start from the following foundational bases:\n- Definitions of $A$-stability and $L$-stability in terms of the linear test equation $\\frac{dy}{dt}=\\lambda y$ and the associated linear stability function for a time integrator, without assuming any specific formula beforehand.\n- The concept that for stiff problems, local linearization of a nonlinear right-hand side around the current state can faithfully capture stiff decay in the limit of large stiffness, and that this reduces analysis locally to the linear test equation with a large negative real parameter.\n\nYou will not be given any method-specific stability formula in the problem statement. Instead, you must reason from first principles and implement both methods directly on the nonlinear problem using their defining implicit update equations.\n\nFor a time step size $h0$ and a current value $u_n$, the two methods are defined by the implicit equations for $u_{n+1}$:\n- Backward Euler: find $u_{n+1}$ such that\n$$\nu_{n+1} = u_n + h\\Big(-p\\big(u_{n+1} + u_{n+1}^p\\big)\\Big).\n$$\n- Implicit Midpoint: find $u_{n+1}$ such that\n$$\nu_{n+1} = u_n + h\\Big(-p\\big(\\tfrac{1}{2}(u_n+u_{n+1}) + \\big(\\tfrac{1}{2}(u_n+u_{n+1})\\big)^p\\big)\\Big).\n$$\n\nDefine the overshoot indicator for a given method and parameter set as follows: simulate $N$ steps starting from $u_0=1$ and declare “overshoot” if at any step the numerical solution becomes negative, that is, if $\\min_{0\\leq n\\leq N} u_n  0$. This indicator is a boolean that you must report as an integer, where $1$ means “overshoot occurred” and $0$ means “no overshoot occurred.”\n\nDesign and implement a robust nonlinear solver for the above implicit equations per step that guarantees convergence to the physically relevant solution branch. Do not make any assumptions that bypass solving the nonlinear equations.\n\nTest Suite. Use the following parameter sets $(p, h, N)$:\n- Test $1$: $p=10$, $h=0.5$, $N=3$.\n- Test $2$: $p=10$, $h=0.05$, $N=20$.\n- Test $3$: $p=100$, $h=0.1$, $N=3$.\n- Test $4$: $p=2$, $h=0.9$, $N=3$.\n- Test $5$: $p=1000$, $h=0.01$, $N=3$.\n\nYour program must output a single line containing a comma-separated list enclosed in square brackets with the overshoot indicators, flattened in the order “Implicit Midpoint then Backward Euler” for each test, i.e.,\n$$\n[\\mathrm{IM}_1,\\mathrm{BE}_1,\\mathrm{IM}_2,\\mathrm{BE}_2,\\mathrm{IM}_3,\\mathrm{BE}_3,\\mathrm{IM}_4,\\mathrm{BE}_4,\\mathrm{IM}_5,\\mathrm{BE}_5],\n$$\nwhere each entry is either $0$ or $1$. No additional text should be printed. All quantities are dimensionless, so no physical units are required or permitted in the output. The angle unit is not applicable. Percentages are not used; any fractional quantities must be represented as decimal numbers in intermediate computations, but the final reported indicators are integers in $\\{0,1\\}$.\n\nYour solution must justify, from first principles, why an $L$-stable method avoids overshoot whereas a merely $A$-stable method can exhibit overshoot as $p\\to\\infty$, and how the provided numerical experiment operationalizes this distinction without relying on any shortcut formulas.", "solution": "The problem is a valid and well-constructed exercise in numerical analysis. It requires analyzing two common implicit integrators on a stiff nonlinear ODE, connecting theoretical stability properties to observed numerical behavior. All components are clearly defined and scientifically sound.\n\nThe core of the problem lies in the distinction between A-stability and L-stability for time integration methods when applied to stiff ODEs. We begin by defining these concepts from first principles.\n\n**A-stability and L-stability**\nThe stability of numerical methods for ODEs is analyzed using Dahlquist's linear test problem:\n$$\n\\frac{dy}{dt} = \\lambda y, \\qquad y(0)=y_0\n$$\nwhere $\\lambda$ is a complex number. For a stable physical system, $\\text{Re}(\\lambda) \\le 0$. A one-step numerical method applied to this equation yields a recurrence relation of the form $y_{n+1} = R(z) y_n$, where $z = h\\lambda$ and $R(z)$ is the method-specific stability function.\n\n- **A-stability**: A method is A-stable if its region of absolute stability, $S = \\{z \\in \\mathbb{C} : |R(z)| \\le 1\\}$, contains the entire left-half of the complex plane, $\\mathbb{C}^- = \\{z \\in \\mathbb{C} : \\text{Re}(z) \\le 0\\}$. This ensures that the numerical solution does not grow for any stable linear problem, regardless of the time step size $h$.\n\n- **L-stability**: A method is L-stable if it is A-stable and its stability function additionally satisfies:\n$$\n\\lim_{|z| \\to \\infty, \\, \\text{Re}(z)0} |R(z)| = 0\n$$\nFor practical purposes with stiff systems where $\\lambda$ is large and negative real, this simplifies to $\\lim_{z \\to -\\infty} R(z) = 0$. This property is crucial for stiff problems, as it ensures that components corresponding to very large negative eigenvalues are strongly damped in a single time step, mimicking the rapid decay of the true solution.\n\n**Analysis of the Specified Methods**\n\n1.  **Backward Euler (BE)**: Applying the method to the test equation gives $y_{n+1} = y_n + h\\lambda y_{n+1}$. Solving for $y_{n+1}$ yields $y_{n+1} = \\frac{1}{1 - h\\lambda} y_n$. The stability function is:\n    $$\n    R_{\\text{BE}}(z) = \\frac{1}{1-z}\n    $$\n    - **A-stability**: For any $z=x+iy$ with $x \\le 0$, $|R_{\\text{BE}}(z)|^2 = \\frac{1}{(1-x)^2 + y^2} \\le 1$ since $1-x \\ge 1$. Thus, BE is A-stable.\n    - **L-stability**: As $z \\to -\\infty$, $R_{\\text{BE}}(z) \\to 0$. Therefore, the Backward Euler method is L-stable.\n\n2.  **Implicit Midpoint (IM)**: Applying the method to the test equation gives $y_{n+1} = y_n + h\\lambda \\frac{y_n+y_{n+1}}{2}$. Solving for $y_{n+1}$ yields $y_{n+1} = \\frac{1+h\\lambda/2}{1-h\\lambda/2} y_n$. The stability function is:\n    $$\n    R_{\\text{IM}}(z) = \\frac{1+z/2}{1-z/2}\n    $$\n    - **A-stability**: For any $z=x+iy$ with $x \\le 0$, $|R_{\\text{IM}}(z)|^2 = \\frac{(1+x/2)^2 + (y/2)^2}{(1-x/2)^2 + (y/2)^2} \\le 1$ since $|1+x/2| \\le |1-x/2|$. Thus, IM is A-stable.\n    - **L-stability**: As $z \\to -\\infty$, $R_{\\text{IM}}(z) = \\frac{1/z + 1/2}{1/z - 1/2} \\to \\frac{1/2}{-1/2} = -1$. Since the limit is not $0$, the Implicit Midpoint method is not L-stable.\n\n**Connection to a Nonlinear Stiff Problem and Overshoot**\nThe given problem $\\frac{du}{dt} = -p(u+u^p)$ is stiff for large $p$. The local dynamics are governed by the Jacobian of the right-hand side $F(u)=-p(u+u^p)$, which is $J(u) = -p(1+pu^{p-1})$. For $u_0=1$, the initial \"eigenvalue\" is effectively $\\lambda \\approx J(1) = -p(1+p)$, a large negative number. For a coarse time step $h$, the product $z=h\\lambda$ can be large and negative.\n\n- The **L-stable** Backward Euler method, with $R_{\\text{BE}}(z) \\to 0$ as $z \\to -\\infty$, will heavily damp the solution in the first step, yielding a small positive $u_1 \\approx 0$. This behavior prevents non-physical oscillations and overshoot.\n\n- The **A-stable but not L-stable** Implicit Midpoint method, with $R_{\\text{IM}}(z) \\to -1$ as $z \\to -\\infty$, will cause the stiff component of the solution to flip its sign without significant decay, leading to $u_1 \\approx -u_0 = -1$. This is a numerical artifact known as overshoot, where the solution becomes negative, violating the physics of the original problem (where $u \\ge 0$).\n\n**Rigorous Analysis of Overshoot for the Given Problem**\nTo find $u_{n+1}$ (denoted as $x$ for clarity) from $u_n$, we must solve a nonlinear equation $G(x)=0$. An overshoot from a positive state $u_n  0$ occurs if the computed root $x=u_{n+1}$ is negative.\n\n- **Backward Euler**: The residual is $G_{\\text{BE}}(x) = x - u_n + hp(x+x^p) = 0$. For $x \\ge 0$, the derivative $G'_{\\text{BE}}(x) = 1+hp+hp^2x^{p-1}$ is strictly positive. Since $G_{\\text{BE}}(0) = -u_n \\le 0$ (as we start with $u_0=1$ and the solution decays), the unique, physically relevant root for $x$ must be non-negative. Therefore, by induction, if $u_n \\ge 0$, then $u_{n+1} \\ge 0$. Backward Euler will not overshoot.\n\n- **Implicit Midpoint**: The residual is $G_{\\text{IM}}(x) = x - u_n + hp\\left(\\frac{u_n+x}{2} + \\left(\\frac{u_n+x}{2}\\right)^p\\right) = 0$. The derivative $G'_{\\text{IM}}(x) = 1 + \\frac{hp}{2} + \\frac{hp^2}{2}\\left(\\frac{u_n+x}{2}\\right)^{p-1}$ is positive for $x$ near the expected solution. The function $G_{\\text{IM}}(x)$ is thus monotonic. An overshoot in the first step ($u_0=1$) occurs if the root $u_1=x$ is negative. This is guaranteed by the Intermediate Value Theorem if $G_{\\text{IM}}(0)  0$.\n$$\nG_{\\text{IM}}(0) = -1 + hp\\left(\\frac{1}{2} + \\left(\\frac{1}{2}\\right)^p\\right)\n$$\nOvershoot occurs if $hp\\left(\\frac{1}{2} + 2^{-p}\\right)  1$. For large integer $p$, this condition approaches $hp  2$. We note that for an overshoot to occur, we may need to evaluate powers of negative numbers; the integer values of $p$ in the test suite ensure this is well-defined.\n\n**Numerical Implementation**\nAt each time step, the implicit equation for $u_{n+1}$ is solved using Newton's method. This requires defining the residual function $G(x)$ and its derivative $G'(x)$ for each integrator. The simulation starts with $u_0=1$ and proceeds for $N$ steps, checking at each step if the solution becomes negative.\n\nTesting the condition $hp\\left(\\frac{1}{2} + 2^{-p}\\right)  1$ for IM:\n- T1: $p=10, h=0.5 \\implies hp=5$. $5(0.5+2^{-10}) \\approx 2.5  1$ (Overshoot).\n- T2: $p=10, h=0.05 \\implies hp=0.5$. $0.5(0.5+2^{-10}) \\approx 0.25  1$ (No overshoot).\n- T3: $p=100, h=0.1 \\implies hp=10$. $10(0.5+2^{-100}) \\approx 5  1$ (Overshoot).\n- T4: $p=2, h=0.9 \\implies hp=1.8$. $1.8(0.5+2^{-2}) = 1.35  1$ (Overshoot).\n- T5: $p=1000, h=0.01 \\implies hp=10$. $10(0.5+2^{-1000}) \\approx 5  1$ (Overshoot).\nThis analysis predicts that IM will overshoot in all cases except Test 2, and BE will never overshoot. The implementation will confirm this behavior.", "answer": "```python\nimport numpy as np\n\ndef newton_solver(g, g_prime, x0, tol=1e-12, max_iter=50):\n    \"\"\"\n    Solves the scalar nonlinear equation g(x) = 0 using Newton's method.\n    \"\"\"\n    x = float(x0)\n    for _ in range(max_iter):\n        try:\n            gx = g(x)\n            if abs(gx)  tol:\n                return x\n            gpx = g_prime(x)\n        except (ValueError, OverflowError):\n            # Handles cases like non-integer power of a negative number or overflow\n            return float('nan')\n\n        if gpx == 0:\n            return float('nan')\n        \n        x = x - gx / gpx\n    return x\n\ndef run_simulation(method, p, h, N):\n    \"\"\"\n    Runs a time integration for N steps and reports if overshoot occurs.\n    \n    Returns:\n        1 if overshoot occurred, 0 otherwise.\n    \"\"\"\n    u = 1.0\n    for _ in range(N):\n        u_n = u\n        \n        if method == 'BE':\n            # Residual g(x) = x - u_n - h * F(x) = 0\n            # F(x) = -p * (x + x**p)\n            g = lambda x: x * (1.0 + h * p) + h * p * np.power(x, p) - u_n\n            # Derivative g'(x) = 1 - h * F'(x)\n            # F'(x) = -p * (1 + p * x**(p-1))\n            g_prime = lambda x: 1.0 + h * p + h * p * p * np.power(x, p - 1)\n        \n        elif method == 'IM':\n            # Residual g(x) = x - u_n - h * F((u_n+x)/2) = 0\n            def g(x):\n                mid = (u_n + x) / 2.0\n                return x - u_n + h * p * (mid + np.power(mid, p))\n            \n            # Derivative g'(x) = 1 - h/2 * F'((u_n+x)/2)\n            def g_prime(x):\n                mid = (u_n + x) / 2.0\n                return 1.0 + h * p * (0.5 + 0.5 * p * np.power(mid, p - 1))\n        \n        else:\n            raise ValueError(\"Unknown method specified.\")\n            \n        u_next = newton_solver(g, g_prime, u_n)\n        \n        # Check for overshoot. Also catches solver failure (nan).\n        if not np.isfinite(u_next) or u_next  0:\n            return 1\n        \n        u = u_next\n           \n    return 0\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (10, 0.5, 3),    # Test 1\n        (10, 0.05, 20),  # Test 2\n        (100, 0.1, 3),   # Test 3\n        (2, 0.9, 3),     # Test 4\n        (1000, 0.01, 3), # Test 5\n    ]\n\n    results = []\n    for p, h, N in test_cases:\n        # Implicit Midpoint simulation\n        im_res = run_simulation('IM', float(p), float(h), N)\n        results.append(im_res)\n        \n        # Backward Euler simulation\n        be_res = run_simulation('BE', float(p), float(h), N)\n        results.append(be_res)\n        \n    # Format and print the final output as a single line\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3360266"}]}