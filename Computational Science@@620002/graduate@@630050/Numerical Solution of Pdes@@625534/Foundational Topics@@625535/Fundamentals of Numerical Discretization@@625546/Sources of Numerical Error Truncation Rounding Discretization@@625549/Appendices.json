{"hands_on_practices": [{"introduction": "A central challenge in numerical simulation is balancing the competing demands of truncation and rounding error. This analytical exercise models this fundamental trade-off, allowing you to derive the optimal grid spacing $h$ and time step $\\Delta t$ that minimize the total error. By working through this problem ([@problem_id:3445194]), you will gain a first-principles understanding of how decreasing step sizes to reduce one error source can amplify another, revealing the existence of a theoretical \"best\" resolution limited by machine precision.", "problem": "Consider a scalar field $v(x,t)$ governed by a linear parabolic partial differential equation (PDE) on a one-dimensional domain with a smooth solution. Suppose $v$ is approximated numerically on a uniform spatial grid with spacing $h>0$ using a second-order (order $2$) central difference for spatial derivatives, and advanced in time with an explicit first-order (order $1$) forward Euler method with time step $\\Delta t \\ge 0$. Working in floating-point arithmetic with machine precision sufficiently small that the leading-order rounding behavior is well-approximated by a linear model, one may combine three dominant error sources into a single error envelope: spatial truncation, temporal truncation, and rounding amplified by differencing. Using Taylor expansion for truncation errors and a standard rounding amplification for second derivatives, the total error as a function of $h$ and $\\Delta t$ can be modeled as\n$$\nE(h,\\Delta t) \\;=\\; C_{1}\\,h^{2} \\;+\\; C_{2}\\,\\Delta t \\;+\\; C_{3}\\,\\frac{u}{h^{2}},\n$$\nwhere $C_{1}>0$, $C_{2}>0$, and $C_{3}>0$ are problem-dependent constants reflecting smoothness of $v$ and algorithmic details, and $u>0$ is a characteristic magnitude of the solution (for example, a bound on $|v|$ or a representative scale of its second derivative). Assume $h>0$ and $\\Delta t \\ge 0$ are unconstrained by stability for the purpose of this optimization.\n\nStarting from first principles—Taylor expansion of truncation errors for the second-order central difference and first-order forward Euler method, and propagation of floating-point rounding error through the discrete second derivative—justify the scaling of each term in $E(h,\\Delta t)$ and then analytically minimize $E(h,\\Delta t)$ over $h>0$ and $\\Delta t \\ge 0$.\n\nProvide the optimal mesh spacing $h^{\\ast}$ and time step $\\Delta t^{\\ast}$ as closed-form expressions in terms of $u$, $C_{1}$, $C_{2}$, and $C_{3}$. Express your final answer as a single row matrix $\\begin{pmatrix} h^{\\ast} & \\Delta t^{\\ast} \\end{pmatrix}$. No numerical evaluation or rounding is required.", "solution": "The problem asks for two main tasks: first, to justify the components of the given error model for the numerical solution of a one-dimensional linear parabolic partial differential equation (PDE), and second, to find the optimal grid spacing $h^{\\ast}$ and time step $\\Delta t^{\\ast}$ that minimize this total error.\n\nThe total error model is given by:\n$$\nE(h,\\Delta t) = C_{1}\\,h^{2} + C_{2}\\,\\Delta t + C_{3}\\,\\frac{u}{h^{2}}\n$$\nwhere $h > 0$ is the spatial grid spacing, $\\Delta t \\ge 0$ is the time step, and $C_{1}$, $C_{2}$, $C_{3}$, and $u$ are positive constants.\n\n**Part 1: Justification of the Error Model Terms**\n\nWe will justify the scaling of each term with respect to $h$ and $\\Delta t$ from first principles.\n\n**1. Spatial Truncation Error ($C_{1}h^{2}$):**\nThe problem states that a second-order central difference is used to approximate spatial derivatives. For a sufficiently smooth scalar field $v(x)$, the second derivative $\\frac{\\partial^2 v}{\\partial x^2}$ at a grid point $x_j$ is approximated as:\n$$\n\\frac{\\partial^2 v}{\\partial x^2}\\bigg|_{x_j} \\approx \\frac{v(x_j+h) - 2v(x_j) + v(x_j-h)}{h^2}\n$$\nThe truncation error of this approximation is found by using Taylor series expansions for $v(x_j+h)$ and $v(x_j-h)$ around $x_j$:\n$$\nv(x_j+h) = v(x_j) + h \\frac{\\partial v}{\\partial x}\\bigg|_{x_j} + \\frac{h^2}{2!} \\frac{\\partial^2 v}{\\partial x^2}\\bigg|_{x_j} + \\frac{h^3}{3!} \\frac{\\partial^3 v}{\\partial x^3}\\bigg|_{x_j} + \\frac{h^4}{4!} \\frac{\\partial^4 v}{\\partial x^4}\\bigg|_{x_j} + O(h^5)\n$$\n$$\nv(x_j-h) = v(x_j) - h \\frac{\\partial v}{\\partial x}\\bigg|_{x_j} + \\frac{h^2}{2!} \\frac{\\partial^2 v}{\\partial x^2}\\bigg|_{x_j} - \\frac{h^3}{3!} \\frac{\\partial^3 v}{\\partial x^3}\\bigg|_{x_j} + \\frac{h^4}{4!} \\frac{\\partial^4 v}{\\partial x^4}\\bigg|_{x_j} - O(h^5)\n$$\nSubstituting these expansions into the finite difference formula:\n$$\n\\frac{v(x_j+h) - 2v(x_j) + v(x_j-h)}{h^2} = \\frac{1}{h^2} \\left[ \\left(2v(x_j) + h^2 \\frac{\\partial^2 v}{\\partial x^2}\\bigg|_{x_j} + \\frac{2h^4}{24} \\frac{\\partial^4 v}{\\partial x^4}\\bigg|_{x_j} + O(h^6) \\right) - 2v(x_j) \\right]\n$$\n$$\n= \\frac{\\partial^2 v}{\\partial x^2}\\bigg|_{x_j} + \\frac{h^2}{12} \\frac{\\partial^4 v}{\\partial x^4}\\bigg|_{x_j} + O(h^4)\n$$\nThe local truncation error for the spatial derivative, $\\tau_{space}$, is the difference between the discrete approximation and the exact derivative:\n$$\n\\tau_{space} = \\left(\\frac{v(x_j+h) - 2v(x_j) + v(x_j-h)}{h^2}\\right) - \\frac{\\partial^2 v}{\\partial x^2}\\bigg|_{x_j} = \\frac{h^2}{12} \\frac{\\partial^4 v}{\\partial x^4}\\bigg|_{x_j} + O(h^4)\n$$\nThe leading-order error is proportional to $h^2$. The accumulation of this local error over the domain and time evolution results in a global spatial truncation error component that scales as $h^2$. The constant $C_1$ incorporates factors like the magnitude of the fourth derivative of the solution, $\\frac{\\partial^4 v}{\\partial x^4}$, and the specific structure of the PDE. Thus, the term $C_1 h^2$ is justified.\n\n**2. Temporal Truncation Error ($C_{2}\\Delta t$):**\nThe problem is advanced in time using the explicit first-order forward Euler method. A generic linear parabolic PDE can be written as $\\frac{\\partial v}{\\partial t} = \\mathcal{L} v$, where $\\mathcal{L}$ is a linear spatial differential operator. The forward Euler method discretizes this as:\n$$\n\\frac{v^{n+1} - v^n}{\\Delta t} = \\mathcal{L}_h v^n\n$$\nwhere $v^n$ represents the solution at time $t_n$ and $\\mathcal{L}_h$ is the discrete spatial operator. The local truncation error is found by substituting the exact solution $v(x,t)$ into the discrete scheme. The Taylor series for $v(x, t_n + \\Delta t)$ around $t_n$ is:\n$$\nv(x, t_n + \\Delta t) = v(x, t_n) + \\Delta t \\frac{\\partial v}{\\partial t}\\bigg|_{t_n} + \\frac{(\\Delta t)^2}{2!} \\frac{\\partial^2 v}{\\partial t^2}\\bigg|_{t_n} + O((\\Delta t)^3)\n$$\nThe local truncation error in time, $\\tau_{time}$, is given by the residual:\n$$\n\\tau_{time} = \\frac{v(x, t_n + \\Delta t) - v(x, t_n)}{\\Delta t} - \\mathcal{L} v(x, t_n)\n$$\nUsing the PDE, $\\mathcal{L}v = \\frac{\\partial v}{\\partial t}$. Substituting the Taylor expansion gives:\n$$\n\\tau_{time} = \\frac{1}{\\Delta t} \\left[ \\left( v(x, t_n) + \\Delta t \\frac{\\partial v}{\\partial t}\\bigg|_{t_n} + \\frac{(\\Delta t)^2}{2} \\frac{\\partial^2 v}{\\partial t^2}\\bigg|_{t_n} + \\dots \\right) - v(x, t_n) \\right] - \\frac{\\partial v}{\\partial t}\\bigg|_{t_n}\n$$\n$$\n\\tau_{time} = \\left( \\frac{\\partial v}{\\partial t}\\bigg|_{t_n} + \\frac{\\Delta t}{2} \\frac{\\partial^2 v}{\\partial t^2}\\bigg|_{t_n} + O((\\Delta t)^2) \\right) - \\frac{\\partial v}{\\partial t}\\bigg|_{t_n} = \\frac{\\Delta t}{2} \\frac{\\partial^2 v}{\\partial t^2}\\bigg|_{t_n} + O((\\Delta t)^2)\n$$\nThe leading-order local error is proportional to $\\Delta t$. The global temporal truncation error thus scales as $\\Delta t$. The constant $C_2$ captures the magnitude of the second time derivative of the solution, $\\frac{\\partial^2 v}{\\partial t^2}$. Thus, the term $C_2 \\Delta t$ is justified.\n\n**3. Rounding Error Amplification ($C_{3}u/h^{2}$):**\nIn floating-point arithmetic, the stored value of $v(x_j)$ at a grid point is $\\hat{v}_j = v_j + \\epsilon_j$, where $\\epsilon_j$ is the rounding error. The magnitude of this error is typically bounded by a value proportional to the machine precision, $\\epsilon_{mach}$, and the magnitude of the number being stored. Let's assume $|\\epsilon_j| \\le \\delta$, where $\\delta$ is a characteristic rounding error scale, often modeled as $\\delta \\approx u \\cdot \\epsilon_{mach}$ with $u$ being a characteristic scale of the solution $v$.\nThe computed second derivative is:\n$$\n\\widehat{\\mathcal{D}_h^2 v_j} = \\frac{\\hat{v}_{j+1} - 2\\hat{v}_j + \\hat{v}_{j-1}}{h^2} = \\frac{(v_{j+1}+\\epsilon_{j+1}) - 2(v_j+\\epsilon_j) + (v_{j-1}+\\epsilon_{j-1})}{h^2}\n$$\nThe error due to rounding, $E_{round}$, is the difference between the computed value and the exact discrete operator acting on the exact function values:\n$$\nE_{round} = \\widehat{\\mathcal{D}_h^2 v_j} - \\frac{v_{j+1} - 2v_j + v_{j-1}}{h^2} = \\frac{\\epsilon_{j+1} - 2\\epsilon_j + \\epsilon_{j-1}}{h^2}\n$$\nThe worst-case magnitude of this error can be bounded using the triangle inequality:\n$$\n|E_{round}| \\le \\frac{|\\epsilon_{j+1}| + 2|\\epsilon_j| + |\\epsilon_{j-1}|}{h^2} \\le \\frac{\\delta + 2\\delta + \\delta}{h^2} = \\frac{4\\delta}{h^2}\n$$\nSince $\\delta$ is proportional to $u \\cdot \\epsilon_{mach}$, the rounding error scales as $\\frac{u}{h^2}$. The constant $C_3$ absorbs the numerical factor $4$ and the machine precision $\\epsilon_{mach}$. This justifies the term $C_3 \\frac{u}{h^2}$.\n\n**Part 2: Minimization of the Error Function**\n\nWe seek to minimize the total error function $E(h, \\Delta t)$ over the domain $h > 0$ and $\\Delta t \\ge 0$.\n$$\nE(h, \\Delta t) = C_{1}\\,h^{2} + C_{2}\\,\\Delta t + C_{3}\\,\\frac{u}{h^{2}}\n$$\nThe function is separable, meaning it can be written as a sum of functions of independent variables: $E(h, \\Delta t) = f(h) + g(\\Delta t)$, where $f(h) = C_1 h^2 + C_3 \\frac{u}{h^2}$ and $g(\\Delta t) = C_2 \\Delta t$. We can minimize each part separately.\n\n**Minimization with respect to $\\Delta t$:**\nWe need to minimize $g(\\Delta t) = C_2 \\Delta t$ subject to $\\Delta t \\ge 0$. Since $C_2 > 0$ is given, $g(\\Delta t)$ is a linearly increasing function of $\\Delta t$. Therefore, its minimum value on the domain $\\Delta t \\ge 0$ occurs at the boundary, i.e., at $\\Delta t = 0$.\nSo, the optimal time step is $\\Delta t^{\\ast} = 0$.\n\n**Minimization with respect to $h$:**\nWe need to minimize $f(h) = C_1 h^2 + C_3 u h^{-2}$ for $h > 0$. We find critical points by setting the first derivative with respect to $h$ equal to zero.\n$$\n\\frac{\\mathrm{d}f}{\\mathrm{d}h} = \\frac{\\mathrm{d}}{\\mathrm{d}h} \\left( C_1 h^2 + C_3 u h^{-2} \\right) = 2C_1 h - 2C_3 u h^{-3}\n$$\nSetting the derivative to zero:\n$$\n2C_1 h - 2C_3 u h^{-3} = 0\n$$\n$$\n2C_1 h = \\frac{2C_3 u}{h^3}\n$$\n$$\nh^4 = \\frac{C_3 u}{C_1}\n$$\nSince $h>0$, we take the principal (positive real) fourth root:\n$$\nh^{\\ast} = \\left( \\frac{C_3 u}{C_1} \\right)^{1/4}\n$$\nTo confirm this is a minimum, we examine the second derivative:\n$$\n\\frac{\\mathrm{d}^2 f}{\\mathrm{d}h^2} = \\frac{\\mathrm{d}}{\\mathrm{d}h} \\left( 2C_1 h - 2C_3 u h^{-3} \\right) = 2C_1 + 6C_3 u h^{-4}\n$$\nGiven that $C_1 > 0$, $C_3 > 0$, $u > 0$, and $h > 0$, we have $\\frac{\\mathrm{d}^2 f}{\\mathrm{d}h^2} > 0$ for all $h$ in the domain. This proves that $f(h)$ is strictly convex, and thus the critical point $h^{\\ast}$ is a unique global minimum.\n\nCombining the results, the optimal parameters that minimize the total error $E(h, \\Delta t)$ are $h^{\\ast} = \\left(\\frac{C_3 u}{C_1}\\right)^{1/4}$ and $\\Delta t^{\\ast} = 0$.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\left( \\frac{C_3 u}{C_1} \\right)^{1/4} & 0\n\\end{pmatrix}\n}\n$$", "id": "3445194"}, {"introduction": "Theoretical guarantees for numerical methods, such as the discrete maximum principle for the heat equation, are derived assuming exact arithmetic. This computational exercise ([@problem_id:3445163]) demonstrates how these guarantees can fail in practice when floating-point rounding errors perturb coefficients near a stability boundary, leading to unphysical oscillations. By implementing a simple stabilization, you will learn a practical technique to build more robust schemes that respect physical laws even in the face of finite-precision arithmetic.", "problem": "Consider the parabolic partial differential equation known as the heat equation, given by $u_t = \\kappa \\nabla^2 u$ on a one-dimensional spatial domain with homogeneous Dirichlet boundary conditions. Starting from the definitions of forward Euler time stepping and central finite differences in space, construct a three-point linear stencil update for interior grid points. Explain how the discrete maximum principle arises from the requirement that the update is a convex combination of neighboring values under a suitable constraint that depends on the time step, the diffusion coefficient, and the grid spacing. Then, investigate how rounding at the level of floating-point arithmetic can perturb the computed update coefficients near the stability threshold and lead to a violation of the discrete maximum principle, even when the exact mathematical coefficients satisfy the condition.\n\nYour program must implement the following:\n\n- A one-dimensional grid with $N$ nodes over a domain of length $L$, with grid spacing $h = L/(N-1)$ and homogeneous Dirichlet boundary conditions enforced at the endpoints $x=0$ and $x=L$.\n- A forward Euler explicit update using a central second-order finite difference stencil for the interior nodes.\n- Two arithmetic modes, one using double precision and one using single precision as defined by the Institute of Electrical and Electronics Engineers (IEEE) 754 standard.\n- A detector for the discrete maximum principle that asserts, at every time step, that the global minimum does not decrease below its initial value and the global maximum does not increase above its initial value. The detector should return a boolean indicating whether monotonicity was preserved across all steps.\n\nPropose and implement a stabilization that provably preserves monotonicity in the presence of rounding by modifying the computed weights to ensure they are nonnegative and renormalized to sum to $1$ before applying the update. This stabilization must be applied pointwise to the stencil coefficients prior to each update.\n\nUse the following test suite. All quantities are dimensionless.\n\n- Test A (double precision, happy path): $N=101$, $L=1$, number of steps $T=50$, $\\kappa=1$, initial condition $u(x)$ is zero everywhere except a single interior spike with amplitude $A=1$ at the midpoint. Use double precision arithmetic for all operations. Choose the time step $dt$ as $dt = 0.49 h^2$, where $h=L/(N-1)$.\n- Test B (single precision, rounding-induced violation at threshold): $N=3$, $L=1$, $T=1$, $\\kappa=1$, $A=1$, and single precision arithmetic. Use a time step $dt = 0.125000015$ (in single precision). Note that with $N=3$ one has $h=0.5$, so the computed stencil weight factor is effectively at the threshold and will be perturbed by rounding.\n- Test C (single precision, near machine epsilon amplitude): Same as Test B, but with $A = \\varepsilon_{32}$ where $\\varepsilon_{32}$ is the single precision machine epsilon.\n- Test D (single precision, slightly below threshold): $N=3$, $L=1$, $T=1$, $\\kappa=1$, $A=1$, single precision arithmetic, and $dt = 0.124999985$.\n\nFor each test, run both the naive explicit scheme and the stabilized scheme. Your program should produce a single line of output containing eight booleans in the following order: monotonicity preservation for the naive scheme in Tests A, B, C, and D, followed by monotonicity preservation for the stabilized scheme in Tests A, B, C, and D. The output must be a comma-separated list enclosed in square brackets, for example, \"[true,false,true,false,true,true,true,true]\". The boolean values must be printed using Python's default boolean formatting (\"True\" or \"False\").", "solution": "The problem as stated is scientifically sound, well-posed, and based on established principles of numerical analysis for partial differential equations. All necessary conditions and parameters are provided for a unique and meaningful solution. The central theme—the interplay between theoretical stability criteria and their practical implementation in finite-precision arithmetic—is a valid and important topic in computational science. Therefore, we proceed with a full solution.\n\nThe problem asks for an analysis of a numerical scheme for the one-dimensional heat equation, $u_t = \\kappa u_{xx}$, in one spatial dimension. We are to construct a numerical update rule and analyze its stability properties, particularly concerning the discrete maximum principle and the effects of floating-point rounding errors.\n\nFirst, we derive the numerical stencil. We discretize the partial differential equation on a uniform grid where $u_j^n$ approximates the true solution $u(x_j, t_n)$, with spatial grid points $x_j = j h$ and discrete time levels $t_n = n \\, dt$. The spatial step size is $h = L/(N-1)$ for a domain of length $L$ with $N$ grid nodes.\n\nThe time derivative $u_t$ is approximated using the forward Euler method, a first-order accurate explicit scheme:\n$$\nu_t \\approx \\frac{u_j^{n+1} - u_j^n}{dt}\n$$\nThe spatial second derivative $u_{xx}$ is approximated using a second-order accurate central finite difference:\n$$\nu_{xx} \\approx \\frac{u_{j+1}^n - 2u_j^n + u_{j-1}^n}{h^2}\n$$\nSubstituting these approximations into the heat equation $u_t = \\kappa u_{xx}$ yields:\n$$\n\\frac{u_j^{n+1} - u_j^n}{dt} = \\kappa \\left( \\frac{u_{j+1}^n - 2u_j^n + u_{j-1}^n}{h^2} \\right)\n$$\nTo find the update rule, we solve for $u_j^{n+1}$:\n$$\nu_j^{n+1} = u_j^n + \\frac{\\kappa \\, dt}{h^2} (u_{j+1}^n - 2u_j^n + u_{j-1}^n)\n$$\nWe introduce the dimensionless diffusion number, $s = \\frac{\\kappa \\, dt}{h^2}$. By substituting $s$ and rearranging terms based on their spatial location at time level $n$, we obtain the three-point linear stencil update for all interior grid points ($j=1, \\dots, N-2$):\n$$\nu_j^{n+1} = s u_{j-1}^n + (1 - 2s) u_j^n + s u_{j+1}^n\n$$\nThis equation shows that the solution at a grid point $(j, n+1)$ is a linear combination of the solutions at points $(j-1, n)$, $(j, n)$, and $(j+1, n)$.\n\nNext, we analyze the discrete maximum principle (DMP). The DMP states that for the homogeneous heat equation, the maximum value of the solution in the entire space-time domain is achieved on the initial or boundary data. Numerically, a scheme satisfies the DMP if the global maximum of the solution on the grid does not increase and the global minimum does not decrease over time.\n\nThe update rule $u_j^{n+1} = w_{j-1}u_{j-1}^n + w_j u_j^n + w_{j+1}u_{j+1}^n$ with weights $w_{j-1}=s$, $w_j=1-2s$, and $w_{j+1}=s$ is a convex combination if two conditions are met:\n1.  The weights are non-negative: $w_k \\ge 0$.\n2.  The weights sum to unity: $\\sum_k w_k = 1$.\n\nLet's check the sum: $s + (1 - 2s) + s = 1$. This condition is always satisfied.\nFor non-negativity, we require:\n-   $s = \\frac{\\kappa \\, dt}{h^2} \\ge 0$. Since $\\kappa$, $dt$, and $h^2$ are non-negative physical or discretization parameters, this is satisfied.\n-   $1 - 2s \\ge 0$. This is the critical constraint, which implies $s \\le \\frac{1}{2}$.\n\nSubstituting the definition of $s$, we get the well-known stability constraint for this explicit scheme:\n$$\n\\frac{\\kappa \\, dt}{h^2} \\le \\frac{1}{2}\n$$\nIf this condition holds, the update is a convex combination. Consequently, the value of $u_j^{n+1}$ must lie within the range of its neighbors at the previous time step:\n$$\n\\min(u_{j-1}^n, u_j^n, u_{j+1}^n) \\le u_j^{n+1} \\le \\max(u_{j-1}^n, u_j^n, u_{j+1}^n)\n$$\nThis local property implies a global one. The maximum value on the grid at time $n+1$ cannot exceed the maximum value at time $n$: $\\max_j u_j^{n+1} \\le \\max_j u_j^n$. Similarly, $\\min_j u_j^{n+1} \\ge \\min_j u_j^n$. This ensures the DMP is satisfied. The homogeneous Dirichlet boundary conditions ($u_0^n = u_{N-1}^n = 0$) are consistent with this principle.\n\nThe core of the problem lies in the interaction between this mathematical condition and finite-precision computer arithmetic. Let's analyze Test B: $N=3, L=1, \\kappa=1$, using single-precision (float32) arithmetic. The grid spacing is $h = L/(N-1) = 1/(3-1) = 0.5$, so $h^2 = 0.25$. The stability threshold $s=1/2$ corresponds to $dt = s h^2 / \\kappa = 0.5 \\times 0.25 / 1.0 = 0.125$. The value $dt=0.125$ is exactly representable in binary floating-point.\nTest B uses a time step $dt_{raw} = 0.125000015$. When this is stored as a single-precision float, it is rounded to the nearest representable number, which is $dt_{comp} \\approx 0.12500001$. This value is strictly greater than $0.125$.\nThe computed diffusion number is $s_{comp} = \\kappa \\frac{dt_{comp}}{h^2} = 1.0 \\times \\frac{0.12500001}{0.25} = 0.50000004$. This value is strictly greater than $0.5$.\nThe central stencil weight is then computed as $w_j = 1 - 2s_{comp} = 1.0 - 2.0 \\times 0.50000004 = 1.0 - 1.0000001 = -1.1920929 \\times 10^{-7}$, which is approximately the negative of the machine epsilon for single precision.\nSince the central coefficient is negative, the condition for a convex combination is violated. For the initial condition of a single spike ($u_1^0 = 1$, with $u_0^0=u_2^0=0$), the update is $u_1^1=(1-2s)u_1^0$. With a negative coefficient, $u_1^1$ becomes negative. The initial minimum was $0$; the new minimum is negative, thus violating the DMP. This demonstrates how a mathematically stable choice of parameters (if one were to use arbitrary-precision arithmetic) can become unstable due to rounding in standard floating-point implementations. Test C shows the same violation, while Test D uses a $dt$ slightly below the threshold, which rounds to a value that maintains $s < 1/2$, thus preserving the DMP.\n\nTo remedy this, we implement a stabilization scheme. The issue is that the computed coefficients $[s, 1-2s, s]$ may fail the non-negativity test. The stabilization enforces this property directly:\n1.  Compute the theoretical weights $w = [s, 1-2s, s]$.\n2.  Apply a pointwise non-negativity clamp: $w'_k = \\max(0, w_k)$ for each component $k$.\n3.  Renormalize the weights to ensure they sum to $1$: $W = \\sum_k w'_k$. If $W > 0$, the final weights are $w''_k = w'_k / W$.\n\nThis procedure guarantees that the resulting weights $[w''_{j-1}, w''_{j}, w''_{j+1}]$ are non-negative and sum to unity. The update is therefore forced to be a convex combination, and the discrete maximum principle is provably preserved, robustly protecting the scheme against rounding-induced sign flips in the coefficients near the stability boundary. For cases well within the stable region (like Test A) or well-behaved cases near the boundary (like Test D), this stabilization has no effect as the initial weights are already non-negative and sum to $1$. However, for pathological cases like Tests B and C, it correctly clips the small negative coefficient to zero, preventing the violation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(N: int, L: float, T: int, kappa: float, A: float, dt: float, dtype: np.dtype, stabilized: bool) -> bool:\n    \"\"\"\n    Runs a 1D heat equation simulation and checks for discrete maximum principle preservation.\n\n    Args:\n        N: Number of grid nodes.\n        L: Length of the spatial domain.\n        T: Number of time steps.\n        kappa: Diffusion coefficient.\n        A: Amplitude of the initial spike.\n        dt: Time step size.\n        dtype: Numpy data type (np.float64 or np.float32) for precision.\n        stabilized: If True, uses the stabilized stencil weights.\n\n    Returns:\n        A boolean indicating if the discrete maximum principle was preserved (True) or not (False).\n    \"\"\"\n    # Cast parameters to the specified data type for consistent precision\n    _L = dtype(L)\n    _kappa = dtype(kappa)\n    _A = dtype(A)\n    _dt = dtype(dt)\n\n    # Initialize grid and initial condition\n    h = _L / dtype(N - 1)\n    u = np.zeros(N, dtype=dtype)\n    if N > 1:\n        mid_idx = (N - 1) // 2\n        u[mid_idx] = _A\n\n    # Store initial min/max for DMP check\n    min_initial = u.min()\n    max_initial = u.max()\n\n    # Calculate stencil parameter s\n    s = _kappa * _dt / (h**2)\n\n    # Time-stepping loop\n    for _ in range(T):\n        u_old = u.copy()\n        \n        # Update interior nodes\n        for j in range(1, N - 1):\n            # Calculate theoretical weights\n            w_left = s\n            w_center = dtype(1.0) - dtype(2.0) * s\n            w_right = s\n\n            if stabilized:\n                weights = [w_left, w_center, w_right]\n                # 1. Pointwise non-negativity\n                weights = [max(dtype(0.0), w) for w in weights]\n                # 2. Renormalize to sum to 1\n                w_sum = sum(weights)\n                if w_sum > dtype(0.0):\n                    weights = [w / w_sum for w in weights]\n                \n                w_left, w_center, w_right = weights\n\n            # Apply update\n            u[j] = w_left * u_old[j - 1] + w_center * u_old[j] + w_right * u_old[j + 1]\n\n        # Check for discrete maximum principle violation\n        # The principle states that the min should not decrease and the max should not increase.\n        if u.min() < min_initial or u.max() > max_initial:\n            return False\n\n    return True\n\ndef solve():\n    \"\"\"\n    Sets up and runs the test suite, printing the results in the required format.\n    \"\"\"\n    # Test A: L=1, N=101 => h = 1/100 = 0.01. kappa=1.\n    # dt = 0.49 * h^2 / kappa = 0.49 * (0.01)^2 = 0.000049.\n    h_A = 1.0 / (101 - 1)\n    dt_A = 0.49 * h_A**2\n\n    # Define test cases as specified in the problem statement\n    test_cases = [\n        {'N': 101, 'L': 1.0, 'T': 50, 'kappa': 1.0, 'A': 1.0,   'dt': dt_A, 'dtype': np.float64},\n        {'N': 3,   'L': 1.0, 'T': 1,  'kappa': 1.0, 'A': 1.0,   'dt': 0.125000015, 'dtype': np.float32},\n        {'N': 3,   'L': 1.0, 'T': 1,  'kappa': 1.0, 'A': np.finfo(np.float32).eps, 'dt': 0.125000015, 'dtype': np.float32},\n        {'N': 3,   'L': 1.0, 'T': 1,  'kappa': 1.0, 'A': 1.0,   'dt': 0.124999985, 'dtype': np.float32}\n    ]\n\n    results_naive = []\n    for params in test_cases:\n        res = run_simulation(stabilized=False, **params)\n        results_naive.append(res)\n        \n    results_stabilized = []\n    for params in test_cases:\n        res = run_simulation(stabilized=True, **params)\n        results_stabilized.append(res)\n\n    final_results = results_naive + results_stabilized\n    \n    # Format the final output exactly as required\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3445163"}, {"introduction": "Many physical laws are fundamentally conservative, and numerical schemes are often designed to mimic this by preserving discrete quantities like energy. This property is typically tied to algebraic symmetries in the discretization operator, which can be broken by floating-point rounding. This practice ([@problem_id:3445225]) guides you through a numerical experiment to precisely measure the artificial dissipation caused by this broken symmetry, separating it from the dissipation inherent to the time-stepping scheme.", "problem": "Consider the linear advection partial differential equation (PDE) $u_t + a u_x = 0$ on the periodic interval $[0,1)$, discretized on a uniform grid with $N$ points and grid spacing $\\Delta x = 1/N$. Let $x_i = i \\Delta x$ for $i \\in \\{0,1,\\dots,N-1\\}$, and define a discrete state vector $u \\in \\mathbb{R}^N$ by $u_i \\approx u(x_i,t)$. The centered, second-order finite difference for the spatial derivative is\n$$\n(Du)_i = \\frac{u_{i+1} - u_{i-1}}{2 \\Delta x},\n$$\nwith periodic indexing $u_{-1} \\equiv u_{N-1}$ and $u_N \\equiv u_0$. The semi-discrete system is\n$$\n\\frac{d u}{dt} = L(u), \\quad \\text{where} \\quad L(u) = -a\\, D u.\n$$\nIn exact arithmetic with a perfectly skew-symmetric representation of $L$, the discrete energy $E(u) = \\tfrac{1}{2} \\|u\\|_2^2$ would be conserved by the ordinary differential equation. However, when $L(u)$ is computed using floating-point arithmetic, rounding breaks the exact skew-symmetry at the level of computed bilinear forms and inner products, and a nonzero energy change can be observed over a single forward Euler step.\n\nYour task is to quantify, for one forward Euler step,\n$$\nu^{n+1} = u^n + \\Delta t\\, L(u^n),\n$$\nthe relative size of the rounding-induced component of the one-step energy change versus the truncation component. Work in purely mathematical terms, no physical units are involved. Angles used in initial conditions must be interpreted in radians.\n\nImplement the following steps:\n\n1. Use the uniform grid points $x_i = i \\Delta x$ and the periodic, centered spatial difference as specified above. Use the forward Euler time-stepping method with time step $\\Delta t = \\text{CFL} \\cdot \\Delta x / |a|$, where $\\text{CFL}$ is a given Courant–Friedrichs–Lewy (CFL) number.\n\n2. For each specified test case, construct the initial condition $u^0$ as:\n$$\nu^0_i = \\sin(2\\pi k\\, x_i),\n$$\nwith integer wavenumber $k \\ge 0$ interpreted in radians.\n\n3. Let $\\langle \\cdot,\\cdot \\rangle$ denote the standard Euclidean inner product and $\\|\\cdot\\|_2$ the associated norm, both computed in floating-point arithmetic. Define the discrete energy $E(u) = \\tfrac{1}{2} \\|u\\|_2^2$. Over one forward Euler step, compute:\n   - The rounding-induced one-step energy contribution\n     $$\n     R := \\Delta t\\, \\langle u^0, L(u^0) \\rangle,\n     $$\n     which would be exactly zero if $L$ were applied and paired in exact arithmetic as a skew-symmetric linear operator.\n   - The truncation contribution\n     $$\n     T := \\tfrac{1}{2}\\, \\Delta t^2\\, \\|L(u^0)\\|_2^2,\n     $$\n     which arises from the discrete time-stepping of a norm-preserving continuous flow.\n\n4. Compute the actual one-step energy change\n$$\n\\Delta E := E\\big(u^0 + \\Delta t\\, L(u^0)\\big) - E(u^0),\n$$\nand the predictor $\\widehat{\\Delta E} := R + T$. Report the ratio $r := |R|/T$ (define $r := 0$ if $T = 0$) and the relative consistency error\n$$\ne := \\frac{|\\Delta E - \\widehat{\\Delta E}|}{\\max\\{|\\Delta E|, \\varepsilon\\}},\n$$\nwith $\\varepsilon = 10^{-300}$ to avoid division by zero. All sums and inner products used to form $R$, $T$, and $\\Delta E$ must be evaluated in a deterministic, compensated manner using compensated summation (for example, the Kahan summation algorithm) to minimize dependence on summation order and to isolate rounding effects inherent to the spatial operator and the one-step update.\n\nTest suite and parameter coverage:\n\n- Case $1$ (happy path): $N = 1024$, $a = 1$, $\\text{CFL} = 0.1$, $k = 8$.\n- Case $2$ (small time step, rounding-dominated): $N = 1024$, $a = 1$, $\\text{CFL} = 10^{-6}$, $k = 8$.\n- Case $3$ (high wavenumber, near-Nyquist content): $N = 1024$, $a = 1$, $\\text{CFL} = 0.9$, $k = 256$.\n- Case $4$ (coarse grid boundary case): $N = 16$, $a = 1$, $\\text{CFL} = 0.1$, $k = 3$.\n- Case $5$ (zero mode edge case): $N = 64$, $a = 1$, $\\text{CFL} = 0.1$, $k = 0$.\n\nYour program must produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, for each case in the order given above, the pair of floats $[r,e]$ concatenated in sequence, resulting in a single flat list of length $10$. For example, the output format must be\n$$\n[\\;r_1,\\;e_1,\\;r_2,\\;e_2,\\;r_3,\\;e_3,\\;r_4,\\;e_4,\\;r_5,\\;e_5\\;].\n$$", "solution": "The problem statement has been meticulously reviewed and is determined to be valid. It presents a well-posed and scientifically grounded exercise in numerical analysis, concerning the sources of error in the numerical integration of a partial differential equation. The problem is self-contained, with all parameters and functions defined unambiguously. It addresses the subtle but important distinction between truncation error, inherent to the discretization method, and rounding error, which arises from floating-point arithmetic.\n\nThe core of the problem is to analyze the change in a conserved quantity, the discrete energy, over a single time step. The PDE is the linear advection equation, $u_t + a u_x = 0$. The semi-discretization on a periodic domain with $N$ points $x_i = i \\Delta x$ (where $\\Delta x=1/N$) is given by\n$$\n\\frac{d u}{dt} = L(u), \\quad \\text{where} \\quad (L(u))_i = -a (D u)_i = -a \\frac{u_{i+1} - u_{i-1}}{2 \\Delta x}.\n$$\nThe vector $u(t) \\in \\mathbb{R}^N$ has components $u_i(t) \\approx u(x_i, t)$.\n\nIn exact arithmetic, the discrete operator $D$ is skew-symmetric with respect to the standard Euclidean inner product $\\langle v, w \\rangle = \\sum_i v_i w_i$. This property, $\\langle v, D w \\rangle = - \\langle D v, w \\rangle$, can be proven by summation by parts with periodic boundary conditions. Consequently, the operator $L = -a D$ is also skew-symmetric for any real constant $a$.\nA direct consequence of skew-symmetry is that the flow generated by this semi-discrete system conserves the discrete energy $E(u) = \\frac{1}{2} \\|u\\|_2^2 = \\frac{1}{2} \\langle u, u \\rangle$. The rate of change of energy is\n$$\n\\frac{dE}{dt} = \\frac{d}{dt} \\left( \\frac{1}{2} \\langle u, u \\rangle \\right) = \\langle u, \\frac{du}{dt} \\rangle = \\langle u, L(u) \\rangle.\n$$\nSince $L$ is skew-symmetric, $\\langle u, L(u) \\rangle = 0$, so energy is conserved.\n\nThe problem then introduces a time discretization, the forward Euler method:\n$$\nu^{n+1} = u^n + \\Delta t L(u^n).\n$$\nThis method does not conserve energy even in exact arithmetic. The one-step change in energy, $\\Delta E = E(u^{n+1}) - E(u^n)$, can be calculated as:\n$$\n\\Delta E = \\frac{1}{2} \\langle u^n + \\Delta t L(u^n), u^n + \\Delta t L(u^n) \\rangle - \\frac{1}{2} \\langle u^n, u^n \\rangle\n$$\n$$\n\\Delta E = \\frac{1}{2} \\left( \\langle u^n, u^n \\rangle + 2 \\Delta t \\langle u^n, L(u^n) \\rangle + \\Delta t^2 \\langle L(u^n), L(u^n) \\rangle \\right) - \\frac{1}{2} \\langle u^n, u^n \\rangle\n$$\n$$\n\\Delta E = \\Delta t \\langle u^n, L(u^n) \\rangle + \\frac{1}{2} \\Delta t^2 \\|L(u^n)\\|_2^2.\n$$\nThis algebraic identity partitions the energy change into two components.\nThe first term, $R := \\Delta t \\langle u^n, L(u^n) \\rangle$, should be exactly zero in exact arithmetic due to the skew-symmetry of $L$. However, when computed using floating-point arithmetic, the cancellation is imperfect, leaving a small residual. This term thus captures the effect of rounding error in the evaluation of $L(u^n)$ and the subsequent inner product.\nThe second term, $T := \\frac{1}{2} \\Delta t^2 \\|L(u^n)\\|_2^2$, is the leading-order term in the Taylor expansion of the energy change with respect to $\\Delta t$. It represents the energy growth inherent to the forward Euler method and is a manifestation of the method's truncation error.\n\nThe problem requires the computation of these quantities and their relationship. To accurately resolve the small rounding errors contributing to $R$, it is crucial to use a high-precision summation method. The Kahan summation algorithm is specified for this purpose. For an array of floating-point numbers $x_i$, this algorithm computes the sum $S = \\sum_i x_i$ as follows:\nInitialize sum $s=0.0$ and compensation $c=0.0$.\nFor each element $x_i$:\n\\begin{enumerate}\n    \\item $y = x_i - c$\n    \\item $t = s + y$\n    \\item $c = (t - s) - y$\n    \\item $s = t$\n\\end{enumerate}\nThis algorithm will be used for all inner products and squared norms involved in the calculation of $R$, $T$, and the direct computation of $\\Delta E$.\n\nThe overall procedure for each test case is as follows:\n1.  Set up the computational grid with $N$ points and calculate parameters $\\Delta x$ and $\\Delta t$.\n2.  Construct the initial state vector $u^0$ using the formula $u^0_i = \\sin(2\\pi k x_i)$.\n3.  Compute the vector $L(u^0)$ using the centered difference operator with periodic boundary conditions.\n4.  Compute the rounding contribution $R = \\Delta t \\langle u^0, L(u^0) \\rangle$ using compensated summation for the inner product.\n5.  Compute the truncation contribution $T = \\frac{1}{2} \\Delta t^2 \\|L(u^0)\\|_2^2$ using compensated summation for the squared norm.\n6.  Compute the next state $u^1 = u^0 + \\Delta t L(u^0)$.\n7.  Compute the actual energy change $\\Delta E = \\frac{1}{2}\\|u^1\\|_2^2 - \\frac{1}{2}\\|u^0\\|_2^2$, using compensated summation for both squared norms.\n8.  Calculate the predictor $\\widehat{\\Delta E} = R + T$.\n9.  Calculate the final metrics: the ratio $r = |R|/T$ (defined as $0$ if $T=0$) and the relative consistency error $e = |\\Delta E - \\widehat{\\Delta E}| / \\max\\{|\\Delta E|, \\varepsilon\\}$. The error $e$ quantifies the discrepancy between the two algebraically equivalent methods of computing the energy change, a discrepancy that arises purely from the different ordering of floating-point operations.\n\nThe following Python code implements this procedure.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that processes test cases and prints the results.\n    \"\"\"\n\n    test_cases = [\n        # Case 1 (happy path)\n        (1024, 1.0, 0.1, 8),\n        # Case 2 (small time step, rounding-dominated)\n        (1024, 1.0, 1e-6, 8),\n        # Case 3 (high wavenumber, near-Nyquist content)\n        (1024, 1.0, 0.9, 256),\n        # Case 4 (coarse grid boundary case)\n        (16, 1.0, 0.1, 3),\n        # Case 5 (zero mode edge case)\n        (64, 1.0, 0.1, 0),\n    ]\n\n    results = []\n    for params in test_cases:\n        N, a, CFL, k = params\n        r, e = calculate_errors(N, a, CFL, k)\n        results.extend([r, e])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef kahan_sum(a):\n    \"\"\"\n    Computes the sum of an array of floats using the Kahan summation algorithm.\n    All variables are explicitly cast to np.float64 to ensure consistent arithmetic.\n    \"\"\"\n    s = np.float64(0.0)\n    c = np.float64(0.0)\n    for x_val in a:\n        x = np.float64(x_val)\n        y = x - c\n        t = s + y\n        c = (t - s) - y\n        s = t\n    return s\n\ndef calculate_errors(N, a, CFL, k):\n    \"\"\"\n    Calculates the error metrics r and e for a given set of parameters.\n    \"\"\"\n    # 1. Setup parameters and initial condition\n    # Ensure all calculations are done with np.float64\n    N_f = np.float64(N)\n    a_f = np.float64(a)\n    CFL_f = np.float64(CFL)\n    k_f = np.float64(k)\n    \n    dx = np.float64(1.0) / N_f\n    dt = CFL_f * dx / np.abs(a_f)\n    \n    x = np.arange(N_f) * dx\n    u0 = np.sin(np.float64(2.0) * np.pi * k_f * x)\n\n    # 2. Define and apply the spatial operator L\n    def apply_L(u_vec, a_val, dx_val):\n        u_plus_1 = np.roll(u_vec, -1)\n        u_minus_1 = np.roll(u_vec, 1)\n        Du = (u_plus_1 - u_minus_1) / (np.float64(2.0) * dx_val)\n        return -a_val * Du\n\n    Lu0 = apply_L(u0, a_f, dx)\n\n    # 3. Compute R, T, and Delta_E using compensated summation for all sums\n    \n    # R: Rounding-induced contribution\n    inner_prod_u0_Lu0 = kahan_sum(u0 * Lu0)\n    R = dt * inner_prod_u0_Lu0\n\n    # T: Truncation contribution\n    norm_sq_Lu0 = kahan_sum(Lu0 * Lu0)\n    T = np.float64(0.5) * dt**2 * norm_sq_Lu0\n    \n    # Delta_E: Actual one-step energy change\n    u1 = u0 + dt * Lu0\n    \n    norm_sq_u1 = kahan_sum(u1 * u1)\n    E_u1 = np.float64(0.5) * norm_sq_u1\n\n    norm_sq_u0 = kahan_sum(u0 * u0)\n    E_u0 = np.float64(0.5) * norm_sq_u0\n\n    Delta_E = E_u1 - E_u0\n\n    # 4. Compute final metrics r and e\n    \n    # Predictor for energy change\n    Delta_E_hat = R + T\n\n    # r: Ratio of rounding to truncation effects\n    if T == 0.0:\n        r = 0.0\n    else:\n        r = np.abs(R) / T\n        \n    # e: Relative consistency error\n    epsilon = np.float64(1e-300)\n    numerator_e = np.abs(Delta_E - Delta_E_hat)\n    denominator_e = np.maximum(np.abs(Delta_E), epsilon)\n    e = numerator_e / denominator_e\n    \n    return r, e\n\nsolve()\n```", "id": "3445225"}]}