{"hands_on_practices": [{"introduction": "We begin our hands-on exploration with the foundational application of the superposition principle to linear source terms. This exercise demonstrates how the solution to a linear system with a composite forcing function can be found by summing the solutions from each component function. By both deriving this principle for the discrete Poisson equation and verifying it with code, you will solidify your understanding of how linearity translates from continuous theory to discrete numerical practice [@problem_id:3434960].", "problem": "Let a linear partial differential equation (PDE) be discretized on the unit square domain $(0,1)\\times(0,1)$ with homogeneous Dirichlet boundary conditions $u=0$ on the boundary. Consider the discrete model of the Poisson equation $-\\Delta u = f$, where the discrete unknowns are the values at interior grid points, and the discrete right-hand side is a vector of forcing values. The interior grid uses $n$ points per spatial direction, with spacing $h = \\frac{1}{n+1}$ and interior coordinates $x_i = i h$, $y_j = j h$ for $i,j \\in \\{1,2,\\dots,n\\}$. Using the standard five-point stencil for the Laplacian, the discrete linear system is\n$$\nA u = f,\n$$\nwhere $A \\in \\mathbb{R}^{n^2 \\times n^2}$ is the symmetric positive definite matrix\n$$\nA = \\frac{1}{h^2}\\left(I_n \\otimes K_n + K_n \\otimes I_n\\right),\n$$\nwith $I_n$ the $n\\times n$ identity, $\\otimes$ the Kronecker product, and $K_n \\in \\mathbb{R}^{n \\times n}$ the tridiagonal matrix with diagonal entries $2$ and off-diagonal entries $-1$. The discrete vector $f \\in \\mathbb{R}^{n^2}$ aggregates the forcing values $f_{i,j}$ over the interior grid in any consistent lexicographic order.\n\nUsing only the fundamental definition that a matrix is a linear operator and the criteria for invertibility of symmetric positive definite matrices, derive that for any decomposition $f = f^{(1)} + f^{(2)}$, the unique solutions to $A u^{(1)} = f^{(1)}$, $A u^{(2)} = f^{(2)}$, and $A u = f$ satisfy the superposition identity\n$$\nu = u^{(1)} + u^{(2)}.\n$$\nAngles used in trigonometric functions must be in radians.\n\nThen, verify this identity numerically for the following test suite. For each test case, construct $A$ and vectors $f^{(1)}$, $f^{(2)}$ as specified, compute $u$, $u^{(1)}$, and $u^{(2)}$ via solving the corresponding linear systems, and test whether $\\| u - (u^{(1)} + u^{(2)}) \\|_2 \\le \\varepsilon$ for tolerance $\\varepsilon = 10^{-12}$. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,\\dots]$), where each entry is a boolean indicating whether the test passed.\n\nTest suite:\n- Case $1$: $n=3$. Define $f^{(1)}_{i,j} = \\sin(\\pi x_i) \\sin(\\pi y_j)$ and $f^{(2)}_{i,j} = \\sin(2\\pi x_i) \\sin(\\pi y_j)$, with angles in radians.\n- Case $2$: $n=4$. Define $f^{(1)}_{i,j} = 1$ and $f^{(2)}_{i,j} = -1$ for all interior indices $i,j$.\n- Case $3$: $n=5$. Define $f^{(1)}_{i,j}$ to be $1$ at the discrete center $(i^*,j^*)$ with $i^* = \\lceil \\frac{n}{2} \\rceil$ and $j^* = \\lceil \\frac{n}{2} \\rceil$, and $0$ elsewhere; define $f^{(2)}_{i,j} = 0$ everywhere.\n- Case $4$: $n=4$. Define $f^{(1)}$ and $f^{(2)}$ as independent realizations of uniformly distributed random numbers in $[0,1)$ over the grid, with fixed seeds $42$ and $43$, respectively, for reproducibility.\n- Case $5$: $n=3$. Define $f^{(1)}_{i,j} = 0$ for all interior indices, and $f^{(2)}_{i,j} = \\sin(\\pi x_i)\\sin(\\pi y_j)$, with angles in radians.\n\nAll trigonometric functions must use angles in radians. The final output must be a single line of the form $[b_1,b_2,b_3,b_4,b_5]$ where $b_k$ is either $\\text{True}$ or $\\text{False}$ for the corresponding case.", "solution": "The problem statement is valid. It is scientifically grounded in the principles of numerical linear algebra and the discretization of partial differential equations. The problem is well-posed, objective, and contains all necessary information for both the theoretical derivation and the numerical verification.\n\n### Part 1: Derivation of the Superposition Principle\n\nThe goal is to prove that for the linear system $A u = f$, if the forcing term is decomposed as $f = f^{(1)} + f^{(2)}$, then the solution $u$ is the sum of the solutions to the individual problems, i.e., $u = u^{(1)} + u^{(2)}$, where $A u^{(1)} = f^{(1)}$ and $A u^{(2)} = f^{(2)}$. The derivation rests on two fundamental properties mentioned in the problem: the linearity of the matrix operator $A$ and the invertibility of a symmetric positive definite (SPD) matrix.\n\nLet $A \\in \\mathbb{R}^{n^2 \\times n^2}$ be the matrix representing the discrete linear operator. The relationship between the discrete solution vector $u$ and the discrete forcing vector $f$ is given by the linear system:\n$$\nA u = f\n$$\nWe are given that the forcing vector $f$ is decomposed into two components, $f^{(1)}$ and $f^{(2)}$, such that:\n$$\nf = f^{(1)} + f^{(2)}\n$$\nLet $u^{(1)}$ and $u^{(2)}$ be the solutions to the linear systems with forcing terms $f^{(1)}$ and $f^{(2)}$, respectively:\n$$\nA u^{(1)} = f^{(1)}\n$$\n$$\nA u^{(2)} = f^{(2)}\n$$\nThe problem requires us to use the fact that a matrix represents a linear operator. The property of linearity for the operator $A$ states that for any vectors $v_1, v_2$ in its domain and any scalars $c_1, c_2$, the following holds:\n$$\nA(c_1 v_1 + c_2 v_2) = c_1 A v_1 + c_2 A v_2\n$$\nWe can apply this property to the sum of the vectors $u^{(1)}$ and $u^{(2)}$ by setting $c_1=1$ and $c_2=1$:\n$$\nA (u^{(1)} + u^{(2)}) = A u^{(1)} + A u^{(2)}\n$$\nNow, we substitute the expressions for $A u^{(1)}$ and $A u^{(2)}$ from their defining equations:\n$$\nA (u^{(1)} + u^{(2)}) = f^{(1)} + f^{(2)}\n$$\nSince we are given that $f = f^{(1)} + f^{(2)}$, we can substitute this into the right-hand side of the equation:\n$$\nA (u^{(1)} + u^{(2)}) = f\n$$\nThis equation shows that the vector $(u^{(1)} + u^{(2)})$ is a solution to the original linear system $A u = f$.\n\nThe second crucial piece of information is that the matrix $A$ is symmetric positive definite (SPD). A fundamental theorem in linear algebra states that an SPD matrix is always invertible. The invertibility of $A$ implies that for any right-hand side vector $f$, the linear system $A x = f$ has a unique solution given by $x = A^{-1}f$.\n\nWe have established two vectors that satisfy the equation for the forcing term $f$:\n1. The vector $u$, by its definition: $A u = f$.\n2. The vector $(u^{(1)} + u^{(2)})$, as derived above: $A(u^{(1)} + u^{(2)}) = f$.\n\nSince the solution to the system is unique, these two vectors must be identical. Therefore, we conclude that:\n$$\nu = u^{(1)} + u^{(2)}\n$$\nThis completes the derivation of the superposition principle for this discrete linear system.\n\n### Part 2: Numerical Verification\n\nTo verify this principle numerically, we will implement the test cases described. For each case, we will:\n1.  Construct the matrix $A = \\frac{1}{h^2}(I_n \\otimes K_n + K_n \\otimes I_n)$ for the given dimension $n$, where $h = \\frac{1}{n+1}$, $I_n$ is the $n \\times n$ identity matrix, and $K_n$ is the $n \\times n$ tridiagonal matrix with entries $2$ on the main diagonal and $-1$ on the super- and sub-diagonals.\n2.  Construct the right-hand side vectors $f^{(1)}$ and $f^{(2)}$ of size $n^2 \\times 1$ according to the specifications for each test case. This involves creating a grid of coordinates $(x_i, y_j)$ and evaluating the given functions, then flattening the resulting $n \\times n$ matrices into vectors using a consistent lexicographical ordering.\n3.  Calculate the total forcing vector $f = f^{(1)} + f^{(2)}$.\n4.  Solve the three linear systems $A u^{(1)} = f^{(1)}$, $A u^{(2)} = f^{(2)}$, and $A u = f$ for the solution vectors $u^{(1)}$, $u^{(2)}$, and $u$ using a standard linear solver.\n5.  Compute the L2-norm of the difference vector: $\\| u - (u^{(1)} + u^{(2)}) \\|_2$.\n6.  Compare this norm against the specified tolerance $\\varepsilon = 10^{-12}$. The test passes if the norm is less than or equal to the tolerance.\nThe results from all test cases will be collected and presented as a boolean list. Due to the nature of floating-point arithmetic, the difference will not be exactly zero but will be on the order of machine precision, which is significantly smaller than the given tolerance for these well-conditioned systems. Thus, we expect all tests to pass.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and numerically verifies the principle of superposition for the\n    discrete Poisson equation.\n    \"\"\"\n    \n    test_suite = [\n        {'case_id': 1, 'n': 3},\n        {'case_id': 2, 'n': 4},\n        {'case_id': 3, 'n': 5},\n        {'case_id': 4, 'n': 4},\n        {'case_id': 5, 'n': 3},\n    ]\n\n    results = []\n    epsilon = 1e-12\n\n    for test in test_suite:\n        n = test['n']\n        case_id = test['case_id']\n        \n        # 1. Construct the matrix A\n        h = 1.0 / (n + 1)\n        \n        # K_n is the tridiagonal matrix [-1, 2, -1]\n        k_n = (2 * np.identity(n) - \n               np.diag(np.ones(n - 1), k=1) - \n               np.diag(np.ones(n - 1), k=-1))\n               \n        # I_n is the n x n identity matrix\n        i_n = np.identity(n)\n        \n        # A is the discrete Laplacian using Kronecker products\n        A = (1 / h**2) * (np.kron(i_n, k_n) + np.kron(k_n, i_n))\n        \n        # 2. Construct the vectors f^(1) and f^(2)\n        \n        # Grid coordinates\n        # i, j in {1, ..., n}\n        coords = np.arange(1, n + 1) * h\n        X, Y = np.meshgrid(coords, coords, indexing='ij')\n\n        f1 = np.zeros(n * n)\n        f2 = np.zeros(n * n)\n\n        if case_id == 1:\n            # Case 1: n=3, trigonometric functions\n            f1_mat = np.sin(np.pi * X) * np.sin(np.pi * Y)\n            f2_mat = np.sin(2 * np.pi * X) * np.sin(np.pi * Y)\n            f1 = f1_mat.flatten()\n            f2 = f2_mat.flatten()\n        elif case_id == 2:\n            # Case 2: n=4, constant functions\n            f1 = np.ones(n * n)\n            f2 = -np.ones(n * n)\n        elif case_id == 3:\n            # Case 3: n=5, delta function\n            i_star = int(np.ceil(n / 2.0))\n            j_star = int(np.ceil(n / 2.0))\n            # Lexicographic index (row-major) for (i*, j*)\n            # where i,j are 1-based indices\n            k = (i_star - 1) * n + (j_star - 1)\n            f1[k] = 1.0\n            # f2 is already a zero vector\n        elif case_id == 4:\n            # Case 4: n=4, random vectors\n            rng1 = np.random.default_rng(42)\n            f1 = rng1.uniform(0, 1, size=n * n)\n            rng2 = np.random.default_rng(43)\n            f2 = rng2.uniform(0, 1, size=n * n)\n        elif case_id == 5:\n            # Case 5: n=3, zero and trigonometric function\n            # f1 is already a zero vector\n            f2_mat = np.sin(np.pi * X) * np.sin(np.pi * Y)\n            f2 = f2_mat.flatten()\n\n        # 3. Calculate the total forcing vector f\n        f = f1 + f2\n        \n        # 4. Solve the three linear systems\n        u1 = np.linalg.solve(A, f1)\n        u2 = np.linalg.solve(A, f2)\n        u = np.linalg.solve(A, f)\n        \n        # 5. Compute the L2-norm of the error\n        error_norm = np.linalg.norm(u - (u1 + u2), 2)\n        \n        # 6. Compare with tolerance and store result\n        results.append(error_norm <= epsilon)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3434960"}, {"introduction": "Building on the concept of source term superposition, we now turn our attention to boundary conditions, another area where linearity plays a crucial role. This practice involves an analytical verification of superposition for the Laplace equation with non-homogeneous Dirichlet data, linking the principle to the trace operator. You will also explore how advanced finite element techniques, such as penalty and Nitsche's methods, are designed to preserve this essential linear property in the discrete setting [@problem_id:3434956].", "problem": "Consider the homogeneous Laplace equation on the unit square domain $\\Omega = (0,1) \\times (0,1)$,\n$$\n-\\Delta u = 0 \\quad \\text{in } \\Omega,\n$$\nwith Dirichlet boundary condition $u = g$ on $\\partial \\Omega$, where the boundary data $g$ is the trace of a function defined on $\\overline{\\Omega}$. The principle of superposition states that for a linear partial differential equation with linear boundary conditions, the sum of solutions associated with boundary data $g_{1}$ and $g_{2}$ yields a solution associated with boundary data $g_{1} + g_{2}$. Starting from the linearity of the Laplace operator and the definition of the Dirichlet boundary condition, address the following tasks, ensuring that all angles are expressed in radians:\n\n1. Define two functions\n$$\nu_{1}(x,y) = \\sinh(\\pi x)\\,\\sin(\\pi y), \\qquad u_{2}(x,y) = \\sinh(2\\pi x)\\,\\sin(2\\pi y),\n$$\nand let $g_{1}$ and $g_{2}$ be their traces on the boundary $\\partial \\Omega$, i.e., $g_{1} = u_{1}|_{\\partial \\Omega}$ and $g_{2} = u_{2}|_{\\partial \\Omega}$. Using only fundamental properties of the Laplace operator and the Dirichlet boundary condition, verify that $u_{1}$ and $u_{2}$ are valid solutions to the Dirichlet problems with boundary data $g_{1}$ and $g_{2}$ respectively.\n\n2. Using the linearity of $-\\Delta$ and the definition of the trace, prove that $u = u_{1} + u_{2}$ solves the Dirichlet problem with boundary data $g = g_{1} + g_{2}$, and explain precisely why the principle of superposition applies in this case.\n\n3. Consider a conforming Finite Element Method (FEM) discretization on a shape-regular triangulation of $\\Omega$ with meshsize $h$, using a continuous piecewise polynomial space $V_{h} \\subset H^{1}(\\Omega)$ without imposing the boundary condition strongly. Starting from the weak formulation and the definition of the outward unit normal $\\boldsymbol{n}$ on $\\partial \\Omega$, derive:\n   - A penalty enforcement scheme for Dirichlet data $g$ by augmenting the energy with a boundary penalty of the form $\\frac{\\gamma}{h}\\int_{\\partial \\Omega}(u_{h}-g)^{2}\\,ds$, where $\\gamma>0$ is a fixed penalty parameter.\n   - A symmetric Nitsche method for Dirichlet data $g$ by adding consistent boundary terms involving normal fluxes and a stabilization term $\\frac{\\beta}{h}\\int_{\\partial \\Omega}(u_{h}-g)v\\,ds$, where $\\beta>0$ is chosen sufficiently large to ensure coercivity.\n\n   In both cases, justify carefully, using only linearity of the bilinear and linear forms, why the discrete solution mapping $g \\mapsto u_{h}(g)$ is linear and thus preserves superposition, i.e., $u_{h}(g_{1}+g_{2}) = u_{h}(g_{1}) + u_{h}(g_{2})$.\n\n4. Evaluate the exact superposed solution from part 2 at the point $(x,y) = \\left(\\frac{1}{2}, \\frac{1}{3}\\right)$ and provide the result as a single closed-form analytic expression. No numerical rounding is required.\n\nYour final answer must be a single closed-form analytic expression.", "solution": "The problem statement is found to be valid as it is scientifically grounded in the theory of partial differential equations and numerical analysis, well-posed, objective, and internally consistent.\n\n**Part 1: Verification of individual solutions**\n\nWe are asked to verify that $u_{1}(x,y) = \\sinh(\\pi x)\\sin(\\pi y)$ and $u_{2}(x,y) = \\sinh(2\\pi x)\\sin(2\\pi y)$ are valid solutions to their respective Dirichlet problems. A function $u$ is a solution to the Dirichlet problem with boundary data $g$ if it satisfies $-\\Delta u = 0$ in the domain $\\Omega$ and $u = g$ on the boundary $\\partial \\Omega$.\n\nFor the function $u_1$:\nFirst, we check if it satisfies the homogeneous Laplace equation, $-\\Delta u_1 = 0$. The Laplace operator is $\\Delta = \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}$. We compute the second partial derivatives of $u_1$:\n$$ \\frac{\\partial u_1}{\\partial x} = \\pi \\cosh(\\pi x)\\sin(\\pi y) \\implies \\frac{\\partial^2 u_1}{\\partial x^2} = \\pi^2 \\sinh(\\pi x)\\sin(\\pi y) = \\pi^2 u_1(x,y) $$\n$$ \\frac{\\partial u_1}{\\partial y} = \\pi \\sinh(\\pi x)\\cos(\\pi y) \\implies \\frac{\\partial^2 u_1}{\\partial y^2} = -\\pi^2 \\sinh(\\pi x)\\sin(\\pi y) = -\\pi^2 u_1(x,y) $$\nThe Laplacian of $u_1$ is the sum of these second partial derivatives:\n$$ \\Delta u_1 = \\frac{\\partial^2 u_1}{\\partial x^2} + \\frac{\\partial^2 u_1}{\\partial y^2} = \\pi^2 u_1(x,y) - \\pi^2 u_1(x,y) = 0 $$\nSince $\\Delta u_1 = 0$, it follows immediately that $-\\Delta u_1 = 0$. Thus, $u_1$ satisfies the PDE in $\\Omega$.\nThe boundary condition is $u_1 = g_1$ on $\\partial\\Omega$. The problem defines $g_1$ as the trace of $u_1$ on the boundary, i.e., $g_1 = u_1|_{\\partial\\Omega}$. By this definition, $u_1$ satisfies its own boundary condition. Therefore, $u_1$ is a valid solution to the Dirichlet problem with boundary data $g_1$.\n\nFor the function $u_2$:\nThe procedure is identical. We compute the second partial derivatives of $u_2$:\n$$ \\frac{\\partial u_2}{\\partial x} = 2\\pi \\cosh(2\\pi x)\\sin(2\\pi y) \\implies \\frac{\\partial^2 u_2}{\\partial x^2} = (2\\pi)^2 \\sinh(2\\pi x)\\sin(2\\pi y) = (2\\pi)^2 u_2(x,y) $$\n$$ \\frac{\\partial u_2}{\\partial y} = 2\\pi \\sinh(2\\pi x)\\cos(2\\pi y) \\implies \\frac{\\partial^2 u_2}{\\partial y^2} = -(2\\pi)^2 \\sinh(2\\pi x)\\sin(2\\pi y) = -(2\\pi)^2 u_2(x,y) $$\nThe Laplacian of $u_2$ is:\n$$ \\Delta u_2 = \\frac{\\partial^2 u_2}{\\partial x^2} + \\frac{\\partial^2 u_2}{\\partial y^2} = (2\\pi)^2 u_2(x,y) - (2\\pi)^2 u_2(x,y) = 0 $$\nThus, $-\\Delta u_2 = 0$, and $u_2$ satisfies the PDE.\nThe boundary condition is $u_2 = g_2$ on $\\partial\\Omega$, where $g_2$ is defined as $g_2 = u_2|_{\\partial\\Omega}$. As with $u_1$, the function $u_2$ satisfies its boundary condition by definition. Therefore, $u_2$ is also a valid solution to its respective Dirichlet problem.\n\n**Part 2: Verification of the superposed solution**\n\nWe need to prove that $u = u_1 + u_2$ is the solution to the Dirichlet problem with boundary data $g = g_1 + g_2$. This requires showing that $u$ satisfies both the PDE and the boundary condition.\n\nThe principle of superposition applies precisely because the defining operators of the problem are linear.\n1.  **Linearity of the differential operator**: The operator $L = -\\Delta$ is linear. This means that for any two functions $f$ and $h$ in its domain and any scalar constants $c_1, c_2$, $L(c_1 f + c_2 h) = c_1 L(f) + c_2 L(h)$. For our case with $c_1=c_2=1$:\n    $$ -\\Delta u = -\\Delta(u_1 + u_2) = -\\Delta u_1 - \\Delta u_2 $$\n    From Part 1, we know that $-\\Delta u_1 = 0$ and $-\\Delta u_2 = 0$. Therefore,\n    $$ -\\Delta u = 0 + 0 = 0 $$\n    The superposed function $u$ satisfies the Laplace equation.\n\n2.  **Linearity of the boundary condition operator**: The boundary condition is defined by the trace operator, which maps a function defined on $\\Omega$ to its values on the boundary $\\partial\\Omega$. The trace operator is also linear. For our case:\n    $$ u|_{\\partial \\Omega} = (u_1 + u_2)|_{\\partial \\Omega} = u_1|_{\\partial \\Omega} + u_2|_{\\partial \\Omega} $$\n    By definition, $g_1 = u_1|_{\\partial\\Omega}$ and $g_2 = u_2|_{\\partial\\Omega}$. So,\n    $$ u|_{\\partial \\Omega} = g_1 + g_2 = g $$\n    The superposed function $u$ satisfies the new, summed boundary condition.\n\nSince $u = u_1 + u_2$ satisfies both the PDE $-\\Delta u = 0$ in $\\Omega$ and the boundary condition $u = g_1 + g_2$ on $\\partial\\Omega$, it is the solution to the specified Dirichlet problem. The applicability of the superposition principle is a direct consequence of the linearity of both the differential operator $-\\Delta$ and the trace operator for the boundary condition.\n\n**Part 3: Linearity of discrete solution mappings in FEM**\n\nThe weak formulation of $-\\Delta u=0$ is obtained by multiplying by a test function $v$ and integrating over $\\Omega$. Using Green's first identity, $\\int_\\Omega (-\\Delta u) v \\, d\\boldsymbol{x} = \\int_\\Omega \\nabla u \\cdot \\nabla v \\, d\\boldsymbol{x} - \\int_{\\partial\\Omega} \\frac{\\partial u}{\\partial \\boldsymbol{n}} v \\, ds$, and the fact that $-\\Delta u = 0$, we have the identity $\\int_\\Omega \\nabla u \\cdot \\nabla v \\, d\\boldsymbol{x} = \\int_{\\partial \\Omega} \\frac{\\partial u}{\\partial \\boldsymbol{n}} v \\, ds$ for the exact solution $u$. We seek a discrete solution $u_h \\in V_h$.\n\n**Penalty Method:**\nThe penalty method seeks $u_h \\in V_h$ by minimizing a modified energy functional. This leads to the variational problem: Find $u_h \\in V_h$ such that for all $v \\in V_h$,\n$$ \\int_\\Omega \\nabla u_h \\cdot \\nabla v \\, d\\boldsymbol{x} + \\frac{\\gamma}{h} \\int_{\\partial \\Omega} u_h v \\, ds = \\frac{\\gamma}{h} \\int_{\\partial \\Omega} g v \\, ds $$\nThis can be written in the abstract form $a_h(u_h, v) = L_h(v; g)$, where:\n- The bilinear form $a_h(u_h, v) = \\int_\\Omega \\nabla u_h \\cdot \\nabla v \\, d\\boldsymbol{x} + \\frac{\\gamma}{h} \\int_{\\partial \\Omega} u_h v \\, ds$ is independent of the boundary data $g$.\n- The linear form $L_h(v; g) = \\frac{\\gamma}{h} \\int_{\\partial \\Omega} g v \\, ds$ depends on the boundary data $g$.\n\nTo show the mapping $g \\mapsto u_h(g)$ is linear, let $u_h(g_1)$ and $u_h(g_2)$ be the solutions for data $g_1$ and $g_2$. They satisfy:\n$a_h(u_h(g_1), v) = L_h(v; g_1)$ for all $v \\in V_h$.\n$a_h(u_h(g_2), v) = L_h(v; g_2)$ for all $v \\in V_h$.\nThe form $L_h(v; g)$ is linear in $g$ because integration is a linear operation:\n$L_h(v; g_1+g_2) = \\frac{\\gamma}{h} \\int_{\\partial \\Omega} (g_1+g_2)v \\, ds = \\frac{\\gamma}{h} \\int_{\\partial \\Omega} g_1 v \\, ds + \\frac{\\gamma}{h} \\int_{\\partial \\Omega} g_2 v \\, ds = L_h(v; g_1) + L_h(v; g_2)$.\nThe form $a_h(u,v)$ is linear in its first argument. Thus, for the sum of solutions $u_h(g_1)+u_h(g_2)$:\n$a_h(u_h(g_1)+u_h(g_2), v) = a_h(u_h(g_1), v) + a_h(u_h(g_2), v) = L_h(v; g_1) + L_h(v; g_2) = L_h(v; g_1+g_2)$.\nThis shows that $u_h(g_1)+u_h(g_2)$ is the solution corresponding to boundary data $g_1+g_2$. By uniqueness of the solution (guaranteed by coercivity of $a_h$), we have $u_h(g_1+g_2) = u_h(g_1)+u_h(g_2)$.\n\n**Symmetric Nitsche Method:**\nThe symmetric Nitsche's method is given by: Find $u_h \\in V_h$ such that for all $v \\in V_h$,\n$$ \\int_\\Omega \\nabla u_h \\cdot \\nabla v \\, d\\boldsymbol{x} - \\int_{\\partial \\Omega} (\\nabla u_h \\cdot \\boldsymbol{n}) v \\, ds - \\int_{\\partial \\Omega} (u_h - g) (\\nabla v \\cdot \\boldsymbol{n}) \\, ds + \\frac{\\beta}{h} \\int_{\\partial \\Omega} (u_h-g)v \\, ds = 0 $$\nRearranging terms yields the abstract form $a_h(u_h, v) = L_h(v;g)$:\n$$ \\underbrace{\\int_\\Omega \\!\\nabla u_h\\!\\cdot\\!\\nabla v d\\boldsymbol{x} \\!-\\! \\int_{\\partial \\Omega} \\!(\\nabla u_h\\!\\cdot\\!\\boldsymbol{n})v ds \\!-\\! \\int_{\\partial \\Omega}\\! u_h (\\nabla v\\!\\cdot\\!\\boldsymbol{n}) ds \\!+\\! \\frac{\\beta}{h}\\! \\int_{\\partial \\Omega} \\!u_h v ds}_{a_h(u_h,v)} = \\underbrace{-\\!\\int_{\\partial \\Omega}\\! g (\\nabla v\\!\\cdot\\!\\boldsymbol{n}) ds \\!+\\! \\frac{\\beta}{h}\\! \\int_{\\partial \\Omega}\\! g v ds}_{L_h(v;g)} $$\nThe bilinear form $a_h(u, v)$ is independent of $g$. The linear form $L_h(v; g)$ is linear in $g$ because integration is linear:\n$L_h(v; g_1+g_2) = -\\int_{\\partial \\Omega} (g_1+g_2)(\\nabla v\\cdot \\boldsymbol{n})ds + \\frac{\\beta}{h}\\int_{\\partial \\Omega} (g_1+g_2)v ds = L_h(v;g_1) + L_h(v;g_2)$.\nThe argument for superposition is identical to the penalty method. The structure of the problem is $a_h(u_h,v)=L_h(v;g)$, where $a_h$ is bilinear and $L_h$ is linear in $g$. Due to the linearity of $a_h$ in its first argument and the linearity of $L_h$ in $g$, the discrete solution map $g \\mapsto u_h(g)$ is linear. Thus, superposition is preserved in the discrete setting.\n\n**Part 4: Evaluation of the superposed solution**\n\nWe are asked to evaluate the exact superposed solution $u(x,y) = u_1(x,y) + u_2(x,y)$ at the point $(x,y) = (\\frac{1}{2}, \\frac{1}{3})$.\nThe solution is:\n$$ u(x,y) = \\sinh(\\pi x)\\sin(\\pi y) + \\sinh(2\\pi x)\\sin(2\\pi y) $$\nSubstituting the coordinates $x = \\frac{1}{2}$ and $y = \\frac{1}{3}$:\n$$ u\\left(\\frac{1}{2}, \\frac{1}{3}\\right) = \\sinh\\left(\\pi \\cdot \\frac{1}{2}\\right)\\sin\\left(\\pi \\cdot \\frac{1}{3}\\right) + \\sinh\\left(2\\pi \\cdot \\frac{1}{2}\\right)\\sin\\left(2\\pi \\cdot \\frac{1}{3}\\right) $$\n$$ u\\left(\\frac{1}{2}, \\frac{1}{3}\\right) = \\sinh\\left(\\frac{\\pi}{2}\\right)\\sin\\left(\\frac{\\pi}{3}\\right) + \\sinh(\\pi)\\sin\\left(\\frac{2\\pi}{3}\\right) $$\nThe exact values of the trigonometric functions are:\n$$ \\sin\\left(\\frac{\\pi}{3}\\right) = \\frac{\\sqrt{3}}{2} $$\n$$ \\sin\\left(\\frac{2\\pi}{3}\\right) = \\sin\\left(\\pi - \\frac{\\pi}{3}\\right) = \\sin\\left(\\frac{\\pi}{3}\\right) = \\frac{\\sqrt{3}}{2} $$\nSubstituting these values back into the expression:\n$$ u\\left(\\frac{1}{2}, \\frac{1}{3}\\right) = \\sinh\\left(\\frac{\\pi}{2}\\right) \\cdot \\frac{\\sqrt{3}}{2} + \\sinh(\\pi) \\cdot \\frac{\\sqrt{3}}{2} $$\nFactoring out the common term $\\frac{\\sqrt{3}}{2}$ gives the final closed-form analytic expression:\n$$ u\\left(\\frac{1}{2}, \\frac{1}{3}\\right) = \\frac{\\sqrt{3}}{2} \\left( \\sinh\\left(\\frac{\\pi}{2}\\right) + \\sinh(\\pi) \\right) $$", "answer": "$$\n\\boxed{\\frac{\\sqrt{3}}{2}\\left(\\sinh\\left(\\frac{\\pi}{2}\\right) + \\sinh(\\pi)\\right)}\n$$", "id": "3434956"}, {"introduction": "The principle of superposition is powerful, but its limits are just as important to understand. This final exercise delves into a more advanced and subtle topic: how numerical schemes can introduce nonlinearity, even when discretizing a linear partial differential equation. By implementing a discontinuous Galerkin method with a slope limiter, you will directly observe and quantify how this stabilization technique violates superposition, providing a crucial lesson on the interplay between the underlying physics and the numerical method itself [@problem_id:3434972].", "problem": "Consider the linear advection partial differential equation (PDE) $u_t + a\\,u_x = 0$ with constant advection speed $a>0$ on the periodic spatial domain $x \\in [0,1]$. The discontinuous Galerkin method with piecewise polynomial degree $1$ (denoted as $P^1$) represents a function $u(x)$ on a uniform mesh of $N$ cells using the local Legendre basis on each cell. For cell index $i$ with center $x_i$ and width $h=1/N$, the local coordinate is $\\xi \\in [-1,1]$ defined by $x = x_i + \\tfrac{h}{2}\\,\\xi$, and the local representation is $u_i(\\xi) = a_{0,i}\\,P_0(\\xi) + a_{1,i}\\,P_1(\\xi)$, where $P_0(\\xi) = 1$ and $P_1(\\xi) = \\xi$. The $L^2$ projection of a smooth function $f(x)$ onto this $P^1$ space has coefficients given by the orthogonality relations of Legendre polynomials:\n$$\na_{0,i} = \\frac{1}{2}\\int_{-1}^{1} f\\!\\left(x_i + \\frac{h}{2}\\,\\xi\\right)\\,d\\xi,\\qquad\na_{1,i} = \\frac{3}{2}\\int_{-1}^{1} f\\!\\left(x_i + \\frac{h}{2}\\,\\xi\\right)\\,\\xi\\,d\\xi.\n$$\nA slope limiter is applied to the $a_{1,i}$ coefficients to prevent spurious oscillations. Define the neighbor cell-average differences\n$$\n\\Delta_{i-\\frac{1}{2}} = a_{0,i} - a_{0,i-1},\\qquad \\Delta_{i+\\frac{1}{2}} = a_{0,i+1} - a_{0,i},\n$$\nwith periodic indexing. Let $T = M h^2$ be the total variation bounded (TVB) threshold with parameter $M>0$. The TVB-modified minmod limiter replaces $a_{1,i}$ by\n$$\n\\tilde{a}_{1,i} = \n\\begin{cases}\n\\operatorname{minmod}\\!\\left(a_{1,i},\\,\\Delta_{i-\\frac{1}{2}},\\,\\Delta_{i+\\frac{1}{2}}\\right), & \\text{if } \\left(|\\Delta_{i-\\frac{1}{2}}|>T\\right)\\ \\text{and}\\ \\left(|\\Delta_{i+\\frac{1}{2}}|>T\\right),\\\\\na_{1,i}, & \\text{otherwise,}\n\\end{cases}\n$$\nwhere\n$$\n\\operatorname{minmod}(z_1,z_2,z_3) =\n\\begin{cases}\n\\operatorname{sign}(z_1)\\,\\min\\{|z_1|,|z_2|,|z_3|\\}, & \\text{if } \\operatorname{sign}(z_1)=\\operatorname{sign}(z_2)=\\operatorname{sign}(z_3),\\\\\n0, & \\text{otherwise.}\n\\end{cases}\n$$\nThis defines the nonlinear mapping $S:f\\mapsto u^{\\text{DG}}$, where $u^{\\text{DG}}$ is the limited $P^1$ representation determined by $\\{a_{0,i},\\tilde{a}_{1,i}\\}_{i=0}^{N-1}$.\n\nThe principle of superposition for linear operators would require $S(f_1 + f_2) = S(f_1) + S(f_2)$ for all inputs. In this problem, you will demonstrate and quantify the violation of superposition introduced solely by the slope limiter (without performing any time stepping for $u_t + a\\,u_x = 0$). You will:\n\n- Implement the projection formulas to compute $\\{a_{0,i}, a_{1,i}\\}$ from a given $f(x)$.\n- Apply the TVB-modified minmod limiter to obtain $\\tilde{a}_{1,i}$ for each cell.\n- For smooth inputs $f_1(x)$ and $f_2(x)$, construct $S(f_1)$, $S(f_2)$, and $S(f_1+f_2)$, and verify whether limiting triggers only for $S(f_1+f_2)$.\n- Quantify superposition violation by computing the global $L^2$ norm of the difference $S(f_1)+S(f_2)-S(f_1+f_2)$ and scaling by the global $L^2$ norm of $S(f_1)+S(f_2)$:\n$$\n\\mathcal{V} = \\frac{\\left\\|S(f_1)+S(f_2)-S(f_1+f_2)\\right\\|_{L^2([0,1])}}{\\left\\|S(f_1)+S(f_2)\\right\\|_{L^2([0,1])}},\n$$\nwith the convention that $\\mathcal{V}=0$ if the denominator is $0$. Using the local Legendre basis, the squared $L^2$ norm of a representation on one cell with coefficients $(b_{0},b_{1})$ is $h\\left(b_{0}^2 + \\frac{1}{3}b_{1}^2\\right)$, and the global squared norm is the sum over cells.\n\nUse smooth trigonometric inputs with specified parameters:\n$$\nf_k(x) = A_k \\sin\\!\\left(2\\pi m_k x + \\phi_k\\right),\\qquad k\\in\\{1,2\\},\n$$\nwhere $A_k>0$ is amplitude, $m_k\\in\\mathbb{N}$ is spatial mode number, and $\\phi_k$ is the phase. Angles $\\phi_k$ must be interpreted in radians.\n\nTest Suite. Implement your program to evaluate the following three test cases, each defined by the tuple $(N,M,A_1,m_1,\\phi_1,A_2,m_2,\\phi_2)$:\n\n- Case $1$ (designed so that limiting triggers only for $f_1+f_2$): $(N,M,A_1,m_1,\\phi_1,A_2,m_2,\\phi_2) = (100,150,0.02,6,0.0,0.015,9,0.0)$.\n- Case $2$ (boundary case with no limiting for any input): $(N,M,A_1,m_1,\\phi_1,A_2,m_2,\\phi_2) = (100,1000,0.005,4,0.3,0.004,5,1.2)$.\n- Case $3$ (edge case where limiting triggers for both $f_1$ and $f_2$ as well as $f_1+f_2$): $(N,M,A_1,m_1,\\phi_1,A_2,m_2,\\phi_2) = (100,50,0.04,12,0.0,0.03,10,0.5)$.\n\nFor each case, compute and return four quantities:\n- $n_1$: the number of cells in which limiting modified $a_{1,i}$ for $S(f_1)$,\n- $n_2$: the number of cells in which limiting modified $a_{1,i}$ for $S(f_2)$,\n- $n_{12}$: the number of cells in which limiting modified $a_{1,i}$ for $S(f_1+f_2)$,\n- $\\mathcal{V}$: the superposition violation metric as defined above.\n\nFinal Output Format. Your program should produce a single line of output containing the results for the three cases as a comma-separated list enclosed in square brackets, with the four quantities for Case $1$ followed by the four for Case $2$, followed by the four for Case $3$. For example, the output format must be exactly like $[n_1^{(1)},n_2^{(1)},n_{12}^{(1)},\\mathcal{V}^{(1)},n_1^{(2)},n_2^{(2)},n_{12}^{(2)},\\mathcal{V}^{(2)},n_1^{(3)},n_2^{(3)},n_{12}^{(3)},\\mathcal{V}^{(3)}]$, where all numbers are printed and angles are in radians.", "solution": "The problem requires an analysis of the violation of the principle of superposition by a nonlinear slope limiter used in the Discontinuous Galerkin (DG) method. We are given the definition of a mapping $S$ from a function $f(x)$ to its DG representation with a TVB-modified minmod slope limiter applied. We must compute the number of cells where the limiter is active for functions $f_1$, $f_2$, and their sum $f_1+f_2$, and quantify the superposition violation $\\mathcal{V} = \\|S(f_1)+S(f_2)-S(f_1+f_2)\\|_{L^2} / \\|S(f_1)+S(f_2)\\|_{L^2}$.\n\nThe process involves three main steps:\n1.  Projecting a given function $f(x)$ onto the $P^1$ DG space to find the coefficients $\\{a_{0,i}, a_{1,i}\\}$.\n2.  Applying the nonlinear TVB-modified minmod limiter to the slope coefficients $\\{a_{1,i}\\}$ to obtain the limited coefficients $\\{\\tilde{a}_{1,i}\\}$.\n3.  Calculating the required quantities ($n_1, n_2, n_{12}, \\mathcal{V}$) using the properties of the DG representation and the provided $L^2$ norm definition.\n\n**Step 1: Analytical Projection of the Input Function**\n\nThe input functions are of the form $f(x) = A \\sin(2\\pi m x + \\phi)$. The coefficients $a_{0,i}$ and $a_{1,i}$ for the $i$-th cell are found by integrating against the Legendre basis functions $P_0(\\xi)=1$ and $P_1(\\xi)=\\xi$ over the local domain $\\xi \\in [-1,1]$. The coordinate transformation is $x = x_i + \\frac{h}{2}\\xi$, where $x_i = (i+0.5)h$ is the cell center and $h=1/N$ is the cell width.\n\nFor $a_{0,i}$:\n$$\na_{0,i} = \\frac{1}{2}\\int_{-1}^{1} A \\sin\\!\\left(2\\pi m \\left(x_i + \\frac{h}{2}\\xi\\right) + \\phi\\right) d\\xi\n$$\nLet $\\theta_i = 2\\pi m x_i + \\phi$ and $k = \\pi m h$. The integral becomes:\n$$\na_{0,i} = \\frac{A}{2} \\int_{-1}^{1} \\sin(\\theta_i + k\\xi) d\\xi = \\frac{A}{2} \\left[-\\frac{\\cos(\\theta_i + k\\xi)}{k}\\right]_{-1}^{1} = \\frac{A}{2k} (\\cos(\\theta_i - k) - \\cos(\\theta_i + k))\n$$\nUsing the identity $\\cos(B) - \\cos(A) = 2\\sin(\\frac{A+B}{2})\\sin(\\frac{A-B}{2})$, we get:\n$$\na_{0,i} = A \\frac{\\sin(k)}{k} \\sin(\\theta_i) = A \\frac{\\sin(\\pi m h)}{\\pi m h} \\sin(2\\pi m x_i + \\phi)\n$$\n\nFor $a_{1,i}$:\n$$\na_{1,i} = \\frac{3}{2}\\int_{-1}^{1} A \\sin\\!\\left(2\\pi m \\left(x_i + \\frac{h}{2}\\xi\\right) + \\phi\\right) \\xi\\,d\\xi\n$$\nThe integral is $\\int_{-1}^1 \\xi \\sin(\\theta_i + k\\xi) d\\xi$. Using integration by parts, we find:\n$$\n\\int_{-1}^{1} \\xi \\sin(\\theta_i + k\\xi) d\\xi = \\left[-\\frac{\\xi}{k}\\cos(\\theta_i + k\\xi) + \\frac{1}{k^2}\\sin(\\theta_i + k\\xi)\\right]_{-1}^{1} = 2\\cos(\\theta_i)\\left(\\frac{\\sin k - k\\cos k}{k^2}\\right)\n$$\nTherefore, the coefficient $a_{1,i}$ is:\n$$\na_{1,i} = 3A \\cos(2\\pi m x_i + \\phi) \\frac{\\sin(\\pi m h) - \\pi m h \\cos(\\pi m h)}{(\\pi m h)^2}\n$$\nThese analytical formulas allow for precise and efficient computation of the coefficients without numerical quadrature. Note that since $m \\in \\mathbb{N}$ (i.e., $m \\ge 1$), the denominators $\\pi m h$ are non-zero for $h>0$.\n\n**Step 2: Application of the TVB-Modified Minmod Limiter**\n\nThe limiter modifies the slope coefficient $a_{1,i}$ based on the cell average values in neighboring cells. First, we compute the differences in cell averages:\n$\\Delta_{i-\\frac{1}{2}} = a_{0,i} - a_{0,i-1}$ and $\\Delta_{i+\\frac{1}{2}} = a_{0,i+1} - a_{0,i}$. Periodicity is handled by wrapping around the indices (e.g., for $i=0$, the \"left\" neighbor $i-1$ is $N-1$).\n\nThe TVB threshold is $T = M h^2$. The limiter is only \"active\" if the local variation is large enough, i.e., $|\\Delta_{i-\\frac{1}{2}}| > T$ and $|\\Delta_{i+\\frac{1}{2}}| > T$. If this condition is met, $a_{1,i}$ is replaced by $\\tilde{a}_{1,i} = \\operatorname{minmod}(a_{1,i}, \\Delta_{i-\\frac{1}{2}}, \\Delta_{i+\\frac{1}{2}})$. Otherwise, $\\tilde{a}_{1,i} = a_{1,i}$.\n\nThe minmod function is defined as:\n$$\n\\operatorname{minmod}(z_1,z_2,z_3) =\n\\begin{cases}\n\\operatorname{sign}(z_1)\\,\\min\\{|z_1|,|z_2|,|z_3|\\}, & \\text{if } \\operatorname{sign}(z_1)=\\operatorname{sign}(z_2)=\\operatorname{sign}(z_3),\\\\\n0, & \\text{otherwise.}\n\\end{cases}\n$$\nThis function is inherently nonlinear. The number of limited cells, $n$, for a given function is the count of indices $i$ for which $\\tilde{a}_{1,i} \\neq a_{1,i}$.\n\n**Step 3: Calculating Superposition Violation**\n\nThe core of the problem is to analyze the operator $S: f \\mapsto u^{\\text{DG}}$, where $u^{\\text{DG}}$ is defined by coefficients $\\{a_{0,i}, \\tilde{a}_{1,i}\\}$. The projection step (finding $a_{0,i}, a_{1,i}$) is linear. Thus, for $f_{1+2} = f_1 + f_2$, the initial coefficients are $a_{0,i}^{(1+2)} = a_{0,i}^{(1)} + a_{0,i}^{(2)}$ and $a_{1,i}^{(1+2)} = a_{1,i}^{(1)} + a_{1,i}^{(2)}$. nonlinearity arises entirely from the limiter.\n\nThe superposition violation $\\mathcal{V}$ is the ratio of two $L^2$ norms. Let's analyze the terms:\n-   $S(f_1)$ is the DG function with coefficients $\\{a_{0,i}^{(1)}, \\tilde{a}_{1,i}^{(1)}\\}$.\n-   $S(f_2)$ is the DG function with coefficients $\\{a_{0,i}^{(2)}, \\tilde{a}_{1,i}^{(2)}\\}$.\n-   $S(f_1) + S(f_2)$ is the sum of these two functions. Its coefficients are $\\{a_{0,i}^{(1)} + a_{0,i}^{(2)}, \\tilde{a}_{1,i}^{(1)} + \\tilde{a}_{1,i}^{(2)}\\}$.\n-   $S(f_1+f_2)$ is obtained by first finding coefficients for $f_1+f_2$, which are $\\{a_{0,i}^{(1)} + a_{0,i}^{(2)}, a_{1,i}^{(1)} + a_{1,i}^{(2)}\\}$, and then applying the limiter to get $\\{a_{0,i}^{(1)} + a_{0,i}^{(2)}, \\tilde{a}_{1,i}^{(1+2)}\\}$.\n\nThe difference function $D = S(f_1)+S(f_2)-S(f_1+f_2)$ has coefficients:\n    $d_{0,i} = (a_{0,i}^{(1)} + a_{0,i}^{(2)}) - (a_{0,i}^{(1)} + a_{0,i}^{(2)}) = 0$.\n    $d_{1,i} = (\\tilde{a}_{1,i}^{(1)} + \\tilde{a}_{1,i}^{(2)}) - \\tilde{a}_{1,i}^{(1+2)}$.\nThe squared norm of $D$ (the numerator of $\\mathcal{V}$) is given by:\n$$\n\\|D\\|_{L^2}^2 = \\sum_{i=0}^{N-1} h\\left(d_{0,i}^2 + \\frac{1}{3}d_{1,i}^2\\right) = \\frac{h}{3} \\sum_{i=0}^{N-1} \\left( (\\tilde{a}_{1,i}^{(1)} + \\tilde{a}_{1,i}^{(2)}) - \\tilde{a}_{1,i}^{(1+2)} \\right)^2\n$$\nThe squared norm of the sum $S(f_1)+S(f_2)$ (the denominator of $\\mathcal{V}$) is:\n$$\n\\|S(f_1)+S(f_2)\\|_{L^2}^2 = \\sum_{i=0}^{N-1} h\\left( (a_{0,i}^{(1)} + a_{0,i}^{(2)})^2 + \\frac{1}{3}(\\tilde{a}_{1,i}^{(1)} + \\tilde{a}_{1,i}^{(2)})^2 \\right)\n$$\nThe violation metric $\\mathcal{V}$ is the square root of the ratio of these two quantities. For each test case, we follow this procedure to calculate $n_1$ (for $f_1$), $n_2$ (for $f_2$), $n_{12}$ (for $f_1+f_2$), and $\\mathcal{V}$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # (N, M, A1, m1, phi1, A2, m2, phi2)\n        (100, 150, 0.02, 6, 0.0, 0.015, 9, 0.0),\n        (100, 1000, 0.005, 4, 0.3, 0.004, 5, 1.2),\n        (100, 50, 0.04, 12, 0.0, 0.03, 10, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, M, A1, m1, phi1, A2, m2, phi2 = case\n\n        # Project f1 and f2 onto the P1 space\n        a0_1, a1_1 = project_sinusoid(A1, m1, phi1, N)\n        a0_2, a1_2 = project_sinusoid(A2, m2, phi2, N)\n\n        # Apply limiter to f1 and f2\n        a1_tilde_1, n1 = apply_limiter(a0_1, a1_1, N, M)\n        a1_tilde_2, n2 = apply_limiter(a0_2, a1_2, N, M)\n\n        # Coefficients for f1+f2 are the sum of coefficients (linearity of projection)\n        a0_12 = a0_1 + a0_2\n        a1_12 = a1_1 + a1_2\n\n        # Apply limiter to f1+f2\n        a1_tilde_12, n12 = apply_limiter(a0_12, a1_12, N, M)\n\n        # Calculate superposition violation V\n        h = 1.0 / N\n        \n        # Numerator calculation\n        # Coefficients of the difference function D = S(f1)+S(f2)-S(f1+f2)\n        d1 = (a1_tilde_1 + a1_tilde_2) - a1_tilde_12\n        # d0 is zero due to linearity of projection for cell averages\n        num_norm_sq = (h / 3.0) * np.sum(d1**2)\n\n        # Denominator calculation\n        # Coefficients of the sum function S(f1)+S(f2)\n        b0 = a0_1 + a0_2\n        b1 = a1_tilde_1 + a1_tilde_2\n        den_norm_sq = h * np.sum(b0**2 + (1.0 / 3.0) * b1**2)\n\n        if den_norm_sq == 0:\n            V = 0.0\n        else:\n            V = np.sqrt(num_norm_sq / den_norm_sq)\n\n        results.extend([n1, n2, n12, V])\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef project_sinusoid(A, m, phi, N):\n    \"\"\"\n    Computes the DG-P1 coefficients a0 and a1 for a function f(x) = A*sin(2*pi*m*x + phi).\n    \n    Args:\n        A (float): Amplitude.\n        m (int): Spatial mode number.\n        phi (float): Phase in radians.\n        N (int): Number of cells.\n        \n    Returns:\n        tuple: (a0, a1) numpy arrays of coefficients.\n    \"\"\"\n    h = 1.0 / N\n    x_i = (np.arange(N) + 0.5) * h\n    \n    # Use analytical formulas for the projection integrals\n    theta_i = 2.0 * np.pi * m * x_i + phi\n    k = np.pi * m * h\n\n    if k == 0: # Note: problem states m is in N, so m>=1, k>0. This is just for safety.\n        a0 = A * np.sin(phi) * np.ones(N)\n        a1 = np.zeros(N)\n        return a0, a1\n\n    sinc_k = np.sin(k) / k\n    a0 = A * sinc_k * np.sin(theta_i)\n\n    # Factor for a1: 3 * (sin(k) - k*cos(k)) / k^2\n    factor_a1 = 3.0 * (np.sin(k) - k * np.cos(k)) / (k**2)\n    a1 = A * factor_a1 * np.cos(theta_i)\n\n    return a0, a1\n\ndef minmod_vec(z1, z2, z3):\n    \"\"\"\n    Vectorized implementation of the minmod function for three arguments.\n    \"\"\"\n    s1, s2, s3 = np.sign(z1), np.sign(z2), np.sign(z3)\n    mask = (s1 == s2) & (s2 == s3)\n    \n    result = np.zeros_like(z1, dtype=np.float64)\n    \n    z_stack = np.stack([np.abs(z1), np.abs(z2), np.abs(z3)], axis=0)\n    min_abs = np.min(z_stack, axis=0)\n    \n    result[mask] = s1[mask] * min_abs[mask]\n    return result\n\ndef apply_limiter(a0, a1, N, M):\n    \"\"\"\n    Applies the TVB-modified minmod limiter to the slope coefficients a1.\n    \n    Args:\n        a0 (np.ndarray): Cell average coefficients.\n        a1 (np.ndarray): Original slope coefficients.\n        N (int): Number of cells.\n        M (float): TVB parameter.\n    \n    Returns:\n        tuple: (a1_tilde, n_limited)\n               a1_tilde: The limited slope coefficients.\n               n_limited: The number of cells where limiting was applied.\n    \"\"\"\n    h = 1.0 / N\n    T = M * h**2\n\n    # Calculate neighbor differences with periodic boundaries\n    a0_im1 = np.roll(a0, 1)  # a0_{i-1}\n    a0_ip1 = np.roll(a0, -1) # a0_{i+1}\n    \n    delta_imhalf = a0 - a0_im1\n    delta_iphalf = a0_ip1 - a0\n\n    # Apply TVB condition to find which cells to limit\n    limit_mask = (np.abs(delta_imhalf) > T) & (np.abs(delta_iphalf) > T)\n    \n    # Initialize modified slopes as the original ones\n    a1_tilde = np.copy(a1)\n    \n    # Apply minmod only where the TVB condition is met\n    if np.any(limit_mask):\n        a1_to_limit = a1[limit_mask]\n        delta_imhalf_to_limit = delta_imhalf[limit_mask]\n        delta_iphalf_to_limit = delta_iphalf[limit_mask]\n\n        limited_slopes = minmod_vec(a1_to_limit, delta_imhalf_to_limit, delta_iphalf_to_limit)\n        a1_tilde[limit_mask] = limited_slopes\n\n    # Count number of limited cells\n    n_limited = np.sum(a1_tilde != a1)\n    \n    return a1_tilde, n_limited\n\nsolve()\n```", "id": "3434972"}]}