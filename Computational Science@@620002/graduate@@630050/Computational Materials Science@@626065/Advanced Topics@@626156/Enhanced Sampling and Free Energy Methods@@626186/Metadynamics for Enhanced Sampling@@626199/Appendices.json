{"hands_on_practices": [{"introduction": "The heart of metadynamics lies in constructing a history-dependent bias potential from a sum of localized kernels. While standard Gaussian kernels are suitable for non-periodic collective variables (CVs), many important CVs in materials science, such as dihedral angles describing molecular conformations or framework rotations, are periodic. This practice challenges you to adapt the standard Gaussian kernel to a periodic domain by correctly defining the distance on a circle, a crucial first step for applying metadynamics to a vast class of systems [@problem_id:3466111].", "problem": "A single torsional collective variable (CV) on a circle is modeled as an angle $\\theta \\in [0,2\\pi)$ measured in radians. In metadynamics for enhanced sampling, one constructs a bias potential by depositing localized kernels centered at previously visited CV values to discourage revisitation and accelerate exploration. Starting from the standard Euclidean Gaussian kernel in one dimension, and from the definition of the geodesic distance on the circle (the minimal arc length between two angles), derive a periodic Gaussian kernel $K_{\\mathrm{per}}(\\theta,\\theta_i;\\sigma)$ that respects the $2\\pi$ periodicity of the angular CV by replacing the Euclidean distance with a wrapped angular distance. Demonstrate that the resulting kernel is invariant under $\\theta \\mapsto \\theta + 2\\pi$ and hence suitable for bias deposition on a periodic domain.\n\nLet the instantaneous metadynamics bias be the sum of deposited kernels,\n$$\nV(\\theta) = \\sum_{i=1}^{N} w_i K_{\\mathrm{per}}(\\theta,\\theta_i;\\sigma),\n$$\nwhere $w_i$ is the height (an energy parameter) of the $i$-th deposited kernel at center $\\theta_i$, and $\\sigma$ is a common angular width (in radians). Consider three kernels with heights $w_1=2.5\\,\\mathrm{kJ\\,mol^{-1}}$, $w_2=1.8\\,\\mathrm{kJ\\,mol^{-1}}$, and $w_3=2.2\\,\\mathrm{kJ\\,mol^{-1}}$, all sharing width $\\sigma=0.15\\,\\mathrm{rad}$, deposited at angular positions $\\theta_1=0.12\\,\\mathrm{rad}$, $\\theta_2=6.20\\,\\mathrm{rad}$, and $\\theta_3=3.40\\,\\mathrm{rad}$. Using your derived periodic Gaussian kernel, evaluate the bias potential $V(\\theta^{\\star})$ at the query angle $\\theta^{\\star}=6.25\\,\\mathrm{rad}$.\n\nAll angles must be treated in radians. Express the final energy in $\\mathrm{kJ\\,mol^{-1}}$ and round your answer to four significant figures.", "solution": "The problem is scientifically grounded, well-posed, and contains all necessary information for a unique solution. It is a standard exercise in the field of computational materials science, specifically concerning enhanced sampling methods. We may therefore proceed with a solution.\n\n**Part 1: Derivation and Validation of the Periodic Gaussian Kernel**\n\nA standard one-dimensional Gaussian kernel centered at a point $x_i$ with width $\\sigma$ is given by:\n$$\nK(x, x_i; \\sigma) = \\exp\\left(-\\frac{(x - x_i)^2}{2\\sigma^2}\\right)\n$$\nThe term $(x - x_i)^2$ is the squared Euclidean distance between points $x$ and $x_i$ on a line. For a collective variable $\\theta$ defined on a circle, i.e., a periodic domain with period $2\\pi$, the Euclidean distance is inappropriate as it does not recognize that $\\theta = 0$ and $\\theta = 2\\pi$ represent the same point.\n\nWe must replace the Euclidean distance with the geodesic distance on the circle. The geodesic distance is the shortest arc length between two angles, say $\\theta$ and $\\theta_i$. On the circle, there are two paths connecting these points. The lengths of these paths are given by the absolute difference $|\\theta - \\theta_i|$ and the complementary arc length $2\\pi - |\\theta - \\theta_i|$. The geodesic distance, which we denote as $d_{\\mathrm{circ}}(\\theta, \\theta_i)$, is the minimum of these two lengths:\n$$\nd_{\\mathrm{circ}}(\\theta, \\theta_i) = \\min(|\\theta - \\theta_i|, 2\\pi - |\\theta - \\theta_i|)\n$$\nThis definition is valid for angles $\\theta, \\theta_i \\in [0, 2\\pi)$.\n\nBy substituting the squared geodesic distance $d^2_{\\mathrm{circ}}(\\theta, \\theta_i)$ for the squared Euclidean distance $(x - x_i)^2$ in the standard Gaussian formula, we obtain the periodic Gaussian kernel $K_{\\mathrm{per}}$:\n$$\nK_{\\mathrm{per}}(\\theta, \\theta_i; \\sigma) = \\exp\\left(-\\frac{d^2_{\\mathrm{circ}}(\\theta, \\theta_i)}{2\\sigma^2}\\right) = \\exp\\left(-\\frac{\\left(\\min(|\\theta - \\theta_i|, 2\\pi - |\\theta - \\theta_i|)\\right)^2}{2\\sigma^2}\\right)\n$$\n\nNext, we must demonstrate that this kernel is periodic, i.e., $K_{\\mathrm{per}}(\\theta + 2\\pi, \\theta_i; \\sigma) = K_{\\mathrm{per}}(\\theta, \\theta_i; \\sigma)$. The most rigorous way to demonstrate this is to consider the distance between an angle $\\theta$ and all periodic images of $\\theta_i$, which are located at $\\theta_i + 2\\pi k$ for any integer $k \\in \\mathbb{Z}$. The geodesic distance is the minimum of all these distances on the real line:\n$$\nd_{\\mathrm{circ}}(\\theta, \\theta_i) = \\min_{k \\in \\mathbb{Z}} |\\theta - (\\theta_i + 2\\pi k)|\n$$\nNow, let us replace $\\theta$ with $\\theta + 2\\pi$:\n$$\nd_{\\mathrm{circ}}(\\theta + 2\\pi, \\theta_i) = \\min_{k \\in \\mathbb{Z}} |(\\theta + 2\\pi) - (\\theta_i + 2\\pi k)| = \\min_{k \\in \\mathbb{Z}} |\\theta - \\theta_i - 2\\pi (k - 1)|\n$$\nLet us introduce a new integer variable $j = k-1$. As $k$ spans all integers ($\\mathbb{Z}$), $j$ also spans all integers. Thus, we can rewrite the expression by summing over $j$:\n$$\nd_{\\mathrm{circ}}(\\theta + 2\\pi, \\theta_i) = \\min_{j \\in \\mathbb{Z}} |\\theta - \\theta_i - 2\\pi j| = d_{\\mathrm{circ}}(\\theta, \\theta_i)\n$$\nSince the distance function $d_{\\mathrm{circ}}$ is invariant under a shift of $2\\pi$ in its first argument, and the kernel $K_{\\mathrm{per}}$ is a function of $d^2_{\\mathrm{circ}}$, the kernel itself is also periodic with period $2\\pi$. The derivation and validation are complete.\n\n**Part 2: Calculation of the Bias Potential**\n\nThe total bias potential $V(\\theta)$ is the sum of the individual kernels:\n$$\nV(\\theta) = \\sum_{i=1}^{N} w_i K_{\\mathrm{per}}(\\theta, \\theta_i; \\sigma)\n$$\nWe need to evaluate $V(\\theta^\\star)$ at $\\theta^\\star = 6.25 \\text{ rad}$ with $N=3$ kernels. The shared width is $\\sigma = 0.15 \\text{ rad}$, so the denominator in the exponent is $2\\sigma^2 = 2(0.15)^2 = 2(0.0225) = 0.045 \\text{ rad}^2$.\n\nThe potential is:\n$$\nV(\\theta^\\star) = w_1 K_{\\mathrm{per}}(\\theta^\\star, \\theta_1; \\sigma) + w_2 K_{\\mathrm{per}}(\\theta^\\star, \\theta_2; \\sigma) + w_3 K_{\\mathrm{per}}(\\theta^\\star, \\theta_3; \\sigma)\n$$\nWe calculate each term separately.\n\n**Term 1:** $w_1 = 2.5 \\text{ kJ mol}^{-1}$, $\\theta_1 = 0.12 \\text{ rad}$.\nThe angular difference is $|\\theta^\\star - \\theta_1| = |6.25 - 0.12| = 6.13 \\text{ rad}$.\nThe geodesic distance is $d_1 = \\min(6.13, 2\\pi - 6.13) \\approx \\min(6.13, 6.2832 - 6.13) = \\min(6.13, 0.1532) = 0.1532 \\text{ rad}$.\nThe contribution to the potential is:\n$$\nV_1 = w_1 \\exp\\left(-\\frac{d_1^2}{2\\sigma^2}\\right) \\approx 2.5 \\exp\\left(-\\frac{(0.153185...)^2}{0.045}\\right) \\approx 2.5 \\exp(-0.521457) \\approx 2.5 \\times 0.59365 = 1.48413 \\text{ kJ mol}^{-1}\n$$\n\n**Term 2:** $w_2 = 1.8 \\text{ kJ mol}^{-1}$, $\\theta_2 = 6.20 \\text{ rad}$.\nThe angular difference is $|\\theta^\\star - \\theta_2| = |6.25 - 6.20| = 0.05 \\text{ rad}$.\nThe geodesic distance is $d_2 = \\min(0.05, 2\\pi - 0.05) = 0.05 \\text{ rad}$.\nThe contribution to the potential is:\n$$\nV_2 = w_2 \\exp\\left(-\\frac{d_2^2}{2\\sigma^2}\\right) = 1.8 \\exp\\left(-\\frac{(0.05)^2}{0.045}\\right) = 1.8 \\exp\\left(-\\frac{0.0025}{0.045}\\right) = 1.8 \\exp(-0.0555...) \\approx 1.8 \\times 0.94593 = 1.70268 \\text{ kJ mol}^{-1}\n$$\n\n**Term 3:** $w_3 = 2.2 \\text{ kJ mol}^{-1}$, $\\theta_3 = 3.40 \\text{ rad}$.\nThe angular difference is $|\\theta^\\star - \\theta_3| = |6.25 - 3.40| = 2.85 \\text{ rad}$.\nThe geodesic distance is $d_3 = \\min(2.85, 2\\pi - 2.85) \\approx \\min(2.85, 6.2832 - 2.85) = \\min(2.85, 3.4332) = 2.85 \\text{ rad}$ (since $2.85 < \\pi$).\nThe contribution to the potential is:\n$$\nV_3 = w_3 \\exp\\left(-\\frac{d_3^2}{2\\sigma^2}\\right) = 2.2 \\exp\\left(-\\frac{(2.85)^2}{0.045}\\right) = 2.2 \\exp\\left(-\\frac{8.1225}{0.045}\\right) = 2.2 \\exp(-180.5)\n$$\nThe value of $\\exp(-180.5)$ is exceedingly small (on the order of $10^{-79}$), so this term's contribution is functionally zero: $V_3 \\approx 0$.\n\n**Total Potential:**\nThe total bias potential at $\\theta^\\star$ is the sum of the individual contributions:\n$$\nV(\\theta^\\star) = V_1 + V_2 + V_3 \\approx 1.48413 + 1.70268 + 0 = 3.18681 \\text{ kJ mol}^{-1}\n$$\nThe problem requires rounding the final answer to four significant figures.\n$$\nV(\\theta^\\star) \\approx 3.187 \\text{ kJ mol}^{-1}\n$$", "answer": "$$\n\\boxed{3.187}\n$$", "id": "3466111"}, {"introduction": "A practical challenge in enhanced sampling is preventing the simulation from exploring physically irrelevant or unphysical regions of configuration space, such as atomic clashes or unrealistic material densities. A common and effective strategy is to supplement the metadynamics bias with a static \"wall\" potential that confines the sampling to a desired range of the CV. This exercise will guide you through the crucial task of deriving and implementing the correct reweighting scheme to recover unbiased thermodynamic averages from a trajectory that includes both a time-dependent metadynamics bias and a static restraining potential [@problem_id:3466145].", "problem": "You are studying enhanced sampling by metadynamics in computational materials science, focusing on avoiding unphysical densification during zeolite framework rearrangements. Consider a simulation in the canonical ensemble where the system configuration is denoted by $\\mathbf{x}$ and a single collective variable (CV) $s = s(\\mathbf{x})$ encodes the relevant framework-rearrangement coordinate. The unbiased target distribution is the canonical distribution with potential energy $U_0(\\mathbf{x})$, that is $p_0(\\mathbf{x}) \\propto \\exp(-\\beta U_0(\\mathbf{x}))$, where $\\beta = 1/(k_{\\mathrm{B}} T)$, $k_{\\mathrm{B}}$ is the Boltzmann constant, and $T$ is the absolute temperature. In metadynamics, a time-dependent bias $V(s,t)$ is added, and to restrict sampling into physically meaningful regions of the CV that avoid densification, a soft-wall restraint potential $U_{\\mathrm{wall}}(s)$ is added to the Hamiltonian. The simulation therefore samples from a time-dependent biased distribution $p_b(\\mathbf{x},t) \\propto \\exp\\left(-\\beta\\left[U_0(\\mathbf{x}) + V'(s(\\mathbf{x}),t) + U_{\\mathrm{wall}}(s(\\mathbf{x}))\\right]\\right)$, where $V'(s,t)$ denotes the actually applied metadynamics bias as it enters the Hamiltonian. In well-tempered metadynamics, there is a time-dependent offset $c(t)$ such that $V'(s,t) = V(s,t) - c(t)$.\n\nTask 1 (derivation): Starting from the canonical ensemble definition $p_0(\\mathbf{x}) \\propto \\exp(-\\beta U_0(\\mathbf{x}))$ and the concept of importance sampling (i.e., changing the sampling distribution and compensating by a weight equal to the ratio of target to proposal densities), derive the normalized reweighting estimator for an arbitrary observable $A(\\mathbf{x})$ that recovers the unbiased expectation $\\langle A \\rangle_0$ from a trajectory sampled under the time-dependent bias $V'(s,t)$ and the soft wall $U_{\\mathrm{wall}}(s)$. Your derivation must explicitly account for the presence of the offset $c(t)$ in well-tempered metadynamics and for the additional restraint $U_{\\mathrm{wall}}(s)$. Express your final estimator in terms of sample values $\\{A_i, s_i, V(s_i,t_i), c(t_i)\\}$ and the wall potential $U_{\\mathrm{wall}}(s_i)$ evaluated at those samples.\n\nTask 2 (algorithm and implementation): Design and implement a program that computes the unbiased estimate of $\\langle A \\rangle_0$ using the estimator derived in Task 1 for the observable $A(s) = s^2$ for each of the following test cases. In all cases, take $k_{\\mathrm{B}} = 0.00831446261815324$ in $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$ and $T = 300$ in $\\mathrm{K}$, so that $\\beta = 1/(k_{\\mathrm{B}} T)$ is computed in $\\mathrm{mol}\\,\\mathrm{kJ}^{-1}$. All energies ($V$, $c$, $U_{\\mathrm{wall}}$) are given or must be computed in $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$, and $s$ is dimensionless. Use the soft-wall restraint\n$$\nU_{\\mathrm{wall}}(s) = \\frac{1}{2} k_{\\mathrm{w}} \\left[\\max\\left(0, s - s_{\\max}\\right)\\right]^2 + \\frac{1}{2} k_{\\mathrm{w}} \\left[\\max\\left(0, s_{\\min} - s\\right)\\right]^2,\n$$\nwith stiffness $k_{\\mathrm{w}}$ in $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$, and bounds $s_{\\min}$ and $s_{\\max}$. For each test case, compute the unbiased estimate of $\\langle s^2 \\rangle_0$ from the provided samples using your derived weights. Express all final results as dimensionless floats.\n\nTest Suite:\n- Test Case 1 (no walls, constant offset): $s_{\\min} = -1.0$, $s_{\\max} = 1.0$, $k_{\\mathrm{w}} = 0.0$. Samples: $s = [-1.2, -0.8, -0.1, 0.3, 0.9, 1.4]$, $V = [1.0, 0.6, -0.2, -0.5, 0.4, 1.2]$, $c = [0.5, 0.5, 0.5, 0.5, 0.5, 0.5]$.\n- Test Case 2 (moderate soft walls, varying offset): $s_{\\min} = -1.0$, $s_{\\max} = 1.0$, $k_{\\mathrm{w}} = 50.0$. Samples: $s = [-1.5, -1.0, -0.2, 0.7, 1.05, 1.2]$, $V = [0.9, 0.3, -0.1, -0.4, 0.2, 1.1]$, $c = [0.4, 0.4, 0.4, 0.45, 0.5, 0.5]$.\n- Test Case 3 (stiff soft walls, increasing offset): $s_{\\min} = -1.0$, $s_{\\max} = 1.0$, $k_{\\mathrm{w}} = 1000.0$. Samples: $s = [-1.3, -1.05, -0.5, 0.0, 1.0, 1.3]$, $V = [0.8, 0.5, 0.0, -0.3, 0.2, 0.9]$, $c = [0.3, 0.35, 0.4, 0.45, 0.5, 0.55]$.\n- Test Case 4 (no walls, strongly varying offset): $s_{\\min} = -1.0$, $s_{\\max} = 1.0$, $k_{\\mathrm{w}} = 0.0$. Samples: $s = [-0.9, -0.4, 0.2, 0.8, 1.1]$, $V = [-0.5, -0.1, 0.3, 0.6, 0.9]$, $c = [0.0, 0.2, 0.4, 0.6, 0.8]$.\n\nYour program must:\n- Compute $\\beta = 1/(k_{\\mathrm{B}} T)$ using the given $k_{\\mathrm{B}}$ and $T$.\n- Compute $U_{\\mathrm{wall}}(s_i)$ for each sample in each test case.\n- Compute the correct reweighting factor for each sample derived in Task 1.\n- Output the unbiased estimate of $\\langle s^2 \\rangle_0$ for each test case as a single line containing a comma-separated list enclosed in square brackets, for example, $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4\\right]$. The values must be plain decimal floats with no units attached.\n\nDesign for coverage:\n- The first case tests the baseline without walls.\n- The second case tests moderate walls that slightly penalize excursions beyond bounds.\n- The third case tests stiff walls that heavily penalize boundary violations, challenging numerical stability of weights.\n- The fourth case tests the effect of varying $c(t)$ without walls.\n\nFinal output format requirement:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4\\right]$). All numerical answers must be dimensionless floats.", "solution": "The problem is valid as it is scientifically grounded in the principles of statistical mechanics and computational science, well-posed with a clear objective and sufficient data, and free of any logical contradictions or ambiguities.\n\n### Task 1: Derivation of the Reweighting Estimator\n\nThe objective is to derive an estimator for the unbiased canonical expectation value of an observable, $\\langle A \\rangle_0$, using data from a biased simulation. The unbiased expectation value is defined as:\n$$\n\\langle A \\rangle_0 = \\frac{\\int A(\\mathbf{x}) p_0(\\mathbf{x}) \\, d\\mathbf{x}}{\\int p_0(\\mathbf{x}) \\, d\\mathbf{x}}\n$$\nwhere $p_0(\\mathbf{x})$ is the probability density of the target unbiased canonical ensemble, given by $p_0(\\mathbf{x}) \\propto \\exp(-\\beta U_0(\\mathbf{x}))$. Here, $U_0(\\mathbf{x})$ is the unbiased potential energy, and $\\beta = 1/(k_{\\mathrm{B}} T)$ is the inverse temperature.\n\nThe simulation trajectory is sampled from a time-dependent biased distribution $p_b(\\mathbf{x}, t)$, which includes both the metadynamics bias and the soft-wall restraint. The probability density for this biased ensemble is:\n$$\np_b(\\mathbf{x}, t) \\propto \\exp\\left(-\\beta\\left[U_0(\\mathbf{x}) + V'(s(\\mathbf{x}),t) + U_{\\mathrm{wall}}(s(\\mathbf{x}))\\right]\\right)\n$$\nwhere $V'(s(\\mathbf{x}),t) = V(s(\\mathbf{x}),t) - c(t)$ is the applied metadynamics potential and $U_{\\mathrm{wall}}(s(\\mathbf{x}))$ is the static wall potential.\n\nThe principle of importance sampling allows us to re-express the integrals over the target distribution $p_0(\\mathbf{x})$ as integrals over the sampling distribution $p_b(\\mathbf{x}, t)$. This is achieved by multiplying the integrand by a reweighting factor $w(\\mathbf{x},t) = p_0(\\mathbf{x}) / p_b(\\mathbf{x},t)$.\n$$\n\\langle A \\rangle_0 = \\frac{\\int A(\\mathbf{x}) \\frac{p_0(\\mathbf{x})}{p_b(\\mathbf{x},t)} p_b(\\mathbf{x},t) \\, d\\mathbf{x}}{\\int \\frac{p_0(\\mathbf{x})}{p_b(\\mathbf{x},t)} p_b(\\mathbf{x},t) \\, d\\mathbf{x}}\n$$\nLet us explicitly write out the reweighting factor $w(\\mathbf{x}, t)$. The normalization constants (partition functions) for the two distributions are $Z_0 = \\int \\exp(-\\beta U_0(\\mathbf{x})) \\, d\\mathbf{x}$ and $Z_b(t) = \\int \\exp\\left(-\\beta\\left[U_0(\\mathbf{x}) + V'(s,t) + U_{\\mathrm{wall}}(s)\\right]\\right) \\, d\\mathbf{x}$.\n$$\nw(\\mathbf{x}, t) = \\frac{p_0(\\mathbf{x})}{p_b(\\mathbf{x},t)} = \\frac{Z_b(t) \\cdot \\exp(-\\beta U_0(\\mathbf{x}))}{Z_0 \\cdot \\exp\\left(-\\beta\\left[U_0(\\mathbf{x}) + V'(s(\\mathbf{x}),t) + U_{\\mathrm{wall}}(s(\\mathbf{x}))\\right]\\right)}\n$$\nThe term $\\exp(-\\beta U_0(\\mathbf{x}))$ cancels, yielding:\n$$\nw(\\mathbf{x}, t) = \\frac{Z_b(t)}{Z_0} \\exp\\left(\\beta\\left[V'(s(\\mathbf{x}),t) + U_{\\mathrm{wall}}(s(\\mathbf{x}))\\right]\\right)\n$$\nSubstituting the expression for the applied bias, $V'(s,t) = V(s,t) - c(t)$, we get:\n$$\nw(\\mathbf{x}, t) = \\frac{Z_b(t)}{Z_0} \\exp\\left(\\beta\\left[V(s(\\mathbf{x}),t) - c(t) + U_{\\mathrm{wall}}(s(\\mathbf{x}))\\right]\\right)\n$$\nIn a simulation, we obtain a discrete trajectory of $N$ configurations $\\{\\mathbf{x}_i\\}$ at discrete times $\\{t_i\\}$. The integrals for the expectation value are thus replaced by sums over these samples. Each sample $\\mathbf{x}_i$ is drawn from the distribution $p_b(\\mathbf{x}, t_i)$ and must be weighted by $w(\\mathbf{x}_i, t_i)$. The estimator for $\\langle A \\rangle_0$ becomes a weighted average over the trajectory:\n$$\n\\langle A \\rangle_0 \\approx \\frac{\\sum_{i=1}^{N} A(\\mathbf{x}_i) w(\\mathbf{x}_i, t_i)}{\\sum_{i=1}^{N} w(\\mathbf{x}_i, t_i)}\n$$\nThe ratio of partition functions $Z_b(t_i)/Z_0$ in each $w(\\mathbf{x}_i, t_i)$ varies with time. However, for a sufficiently long simulation that converges, the average of any observable over the time-dependent bias should converge to the ensemble average. A common and practical assumption in reweighting metadynamics trajectories is that a single reweighting expression can be used across the whole trajectory. The factor containing the partition functions cancels out in the normalized estimator. Let $w_i$ be the un-normalized weight for sample $i$.\n$$\nw_i \\propto \\exp\\left(\\beta\\left[V(s(\\mathbf{x}_i),t_i) - c(t_i) + U_{\\mathrm{wall}}(s(\\mathbf{x}_i))\\right]\\right)\n$$\nThe problem provides sampled values of the collective variable $s_i = s(\\mathbf{x}_i)$, the metadynamics potential at those points $V_i = V(s_i, t_i)$, and the time-dependent offset $c_i = c(t_i)$. The observable $A$ is also a function of $s$, so $A_i = A(s_i)$. The final normalized reweighting estimator for $\\langle A \\rangle_0$ is:\n$$\n\\langle A \\rangle_0 \\approx \\frac{\\sum_{i=1}^{N} A_i \\exp\\left(\\beta\\left[V_i - c_i + U_{\\mathrm{wall}}(s_i)\\right]\\right)}{\\sum_{i=1}^{N} \\exp\\left(\\beta\\left[V_i - c_i + U_{\\mathrm{wall}}(s_i)\\right]\\right)}\n$$\nThis is the required expression. For numerical implementation, to prevent overflow or underflow issues with the exponential function, we define the total biasing energy for each sample as $E_i = V_i - c_i + U_{\\mathrm{wall}}(s_i)$, find the maximum value $E_{\\max} = \\max_i\\{E_i\\}$, and rewrite the estimator in a numerically stable form:\n$$\n\\langle A \\rangle_0 \\approx \\frac{\\sum_{i=1}^{N} A_i \\exp(\\beta (E_i - E_{\\max}))}{\\sum_{i=1}^{N} \\exp(\\beta (E_i - E_{\\max}))}\n$$\nThis form will be used for the implementation in Task 2.\n\n### Task 2: Algorithm and Implementation\n\nThe algorithm proceeds as follows for each test case:\n1.  Define the constants $k_{\\mathrm{B}} = 0.00831446261815324 \\, \\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\,\\mathrm{K}^{-1}$ and $T = 300 \\, \\mathrm{K}$. Compute $\\beta = 1/(k_{\\mathrm{B}} T)$.\n2.  For a given set of samples $\\{s_i, V_i, c_i\\}$ and wall parameters $\\{k_{\\mathrm{w}}, s_{\\min}, s_{\\max}\\}$, compute the value of the observable $A_i = s_i^2$ for each sample.\n3.  Compute the wall potential energy $U_{\\mathrm{wall}}(s_i)$ for each sample using the formula:\n$$\nU_{\\mathrm{wall}}(s_i) = \\frac{1}{2} k_{\\mathrm{w}} \\left[\\max\\left(0, s_i - s_{\\max}\\right)\\right]^2 + \\frac{1}{2} k_{\\mathrm{w}} \\left[\\max\\left(0, s_{\\min} - s_i\\right)\\right]^2\n$$\n4.  For each sample $i$, calculate the argument of the exponent, which is the total biasing energy: $E_i = V_i - c_i + U_{\\mathrm{wall}}(s_i)$.\n5.  To ensure numerical stability, find the maximum value among all exponents, $E_{\\max} = \\max_i\\{E_i\\}$.\n6.  Calculate the stabilized (un-normalized) weights for each sample: $w'_i = \\exp(\\beta (E_i - E_{\\max}))$.\n7.  Compute the numerator of the estimator: $\\text{Num} = \\sum_{i=1}^{N} A_i w'_i$.\n8.  Compute the denominator of the estimator: $\\text{Den} = \\sum_{i=1}^{N} w'_i$.\n9.  The final unbiased estimate is $\\langle s^2 \\rangle_0 = \\text{Num} / \\text{Den}$.\nThis procedure is repeated for all test cases. The implementation will use the `numpy` library for efficient vectorized computations.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the unbiased estimate of <s^2>_0 from metadynamics trajectories\n    with soft-wall restraints using a reweighting method.\n    \"\"\"\n    # Define constants\n    k_B = 0.00831446261815324  # kJ mol^-1 K^-1\n    T = 300.0  # K\n    beta = 1.0 / (k_B * T)  # mol kJ^-1\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"s_min\": -1.0, \"s_max\": 1.0, \"k_w\": 0.0,\n            \"s\": np.array([-1.2, -0.8, -0.1, 0.3, 0.9, 1.4]),\n            \"V\": np.array([1.0, 0.6, -0.2, -0.5, 0.4, 1.2]),\n            \"c\": np.array([0.5, 0.5, 0.5, 0.5, 0.5, 0.5]),\n        },\n        {\n            \"s_min\": -1.0, \"s_max\": 1.0, \"k_w\": 50.0,\n            \"s\": np.array([-1.5, -1.0, -0.2, 0.7, 1.05, 1.2]),\n            \"V\": np.array([0.9, 0.3, -0.1, -0.4, 0.2, 1.1]),\n            \"c\": np.array([0.4, 0.4, 0.4, 0.45, 0.5, 0.5]),\n        },\n        {\n            \"s_min\": -1.0, \"s_max\": 1.0, \"k_w\": 1000.0,\n            \"s\": np.array([-1.3, -1.05, -0.5, 0.0, 1.0, 1.3]),\n            \"V\": np.array([0.8, 0.5, 0.0, -0.3, 0.2, 0.9]),\n            \"c\": np.array([0.3, 0.35, 0.4, 0.45, 0.5, 0.55]),\n        },\n        {\n            \"s_min\": -1.0, \"s_max\": 1.0, \"k_w\": 0.0,\n            \"s\": np.array([-0.9, -0.4, 0.2, 0.8, 1.1]),\n            \"V\": np.array([-0.5, -0.1, 0.3, 0.6, 0.9]),\n            \"c\": np.array([0.0, 0.2, 0.4, 0.6, 0.8]),\n        }\n    ]\n\n    def U_wall(s, k_w, s_min, s_max):\n        \"\"\"Computes the soft-wall restraint potential.\"\"\"\n        term1 = 0.5 * k_w * np.maximum(0, s - s_max)**2\n        term2 = 0.5 * k_w * np.maximum(0, s_min - s)**2\n        return term1 + term2\n\n    results = []\n    for case in test_cases:\n        # Extract data for the current case\n        s_vals = case[\"s\"]\n        V_vals = case[\"V\"]\n        c_vals = case[\"c\"]\n        s_min = case[\"s_min\"]\n        s_max = case[\"s_max\"]\n        k_w = case[\"k_w\"]\n        \n        # 1. Compute the observable A = s^2 for each sample\n        A_vals = s_vals**2\n        \n        # 2. Compute the wall potential U_wall for each sample\n        U_wall_vals = U_wall(s_vals, k_w, s_min, s_max)\n        \n        # 3. Compute the total biasing energy (argument of the exponential)\n        # E_i = V_i - c_i + U_wall(s_i)\n        E_vals = V_vals - c_vals + U_wall_vals\n        \n        # 4. Use a numerically stable formulation for the weights\n        # Find the maximum energy to subtract from the exponent\n        if E_vals.size &gt; 0:\n            E_max = np.max(E_vals)\n        else:\n            # Handle empty sample case, though not in test data\n            results.append(np.nan)\n            continue\n            \n        # 5. Calculate weights: w'_i = exp(beta * (E_i - E_max))\n        weights = np.exp(beta * (E_vals - E_max))\n        \n        # 6. Compute the numerator and denominator of the estimator\n        numerator = np.sum(A_vals * weights)\n        denominator = np.sum(weights)\n        \n        # 7. Calculate the final unbiased estimate\n        if denominator == 0:\n            # Avoid division by zero, although unlikely with exp\n            result = np.nan\n        else:\n            result = numerator / denominator\n            \n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3466145"}, {"introduction": "The efficiency of metadynamics can be highly sensitive to the choice of the Gaussian kernel width, especially on free energy surfaces with complex, anisotropic features. Using a single, isotropic kernel shape can lead to inefficient filling in landscapes that are narrow in one direction and broad in another. This advanced practice explores an adaptive scheme where the kernel's shape is determined by a local metric tensor, allowing it to conform to the landscape's anisotropy and significantly accelerate convergence, a technique demonstrated here with the example of octahedral tilts in a perovskite material [@problem_id:3466169].", "problem": "Consider a two-dimensional collective variable (CV) space for octahedral tilts in a perovskite-like material, with CVs defined as tilt angles $s = (\\theta_x,\\theta_y)$ measured in radians. The free energy surface $F(s)$ is defined by a Landau-like expansion that captures anisotropic stiffness and quartic stabilization:\n$$\nF(\\theta_x,\\theta_y) = -a_x \\,\\theta_x^2 + b_x \\,\\theta_x^4 + a_y \\,\\theta_y^2 + b_y \\,\\theta_y^4 + c \\,\\theta_x^2 \\,\\theta_y^2,\n$$\nwhere the constants $a_x$, $b_x$, $a_y$, $b_y$, and $c$ are strictly positive and set such that the system exhibits a double-well along $\\theta_x$ and a single-well along $\\theta_y$. The global minima occur at $s_A = (\\theta_x^\\star,0)$ and $s_{A'} = (-\\theta_x^\\star,0)$, and the symmetry-related saddle is at $s_S = (0,0)$.\n\nIn metadynamics, a bias potential $B(s)$ is constructed as a sum of Gaussian kernels deposited along the trajectory in CV space. The bias at a point $s$ is\n$$\nB(s) = \\sum_{k=1}^{N} h_k \\exp\\left(-\\tfrac{1}{2} \\,(s-s_k)^\\top \\, C_k^{-1} \\,(s-s_k)\\right),\n$$\nwhere $s_k$ are deposition centers, $h_k$ are deposition heights, and $C_k$ are covariance matrices. The isotropic scheme uses $C_k = \\sigma^2 I$ with a scalar Gaussian width $\\sigma$ and identity matrix $I$. The anisotropic adaptive scheme uses a symmetric positive-definite metric $g_{ij}(s)$ to choose covariances,\n$$\nC_k = \\sigma^2 \\left(\\det g(s_k)\\right)^{1/d} \\, g(s_k)^{-1},\n$$\nwith $d=2$ the dimension of the CV space, ensuring constant kernel volume $\\det C_k = \\sigma^{2d}$ while adapting shape to the local metric. In geometry-adapted metadynamics, $g_{ij}(s)$ reflects local anisotropy of the CVs; here, assume a diagonal metric\n$$\ng(s) = \\begin{pmatrix}\n1 + \\eta_x \\,\\theta_x^2 & 0 \\\\\n0 & r \\,\\big(1 + \\eta_y \\,\\theta_y^2\\big)\n\\end{pmatrix},\n$$\nwhere $r>0$ encodes stiffness anisotropy between $\\theta_x$ and $\\theta_y$, and $\\eta_x,\\eta_y \\ge 0$ control the variation of the metric with $s$. All energies must be treated as dimensionless in units of Boltzmannâ€™s constant times temperature, $k_\\mathrm{B} T$.\n\nAssume $N$ Gaussian centers are deposited along a straight path in CV space from the minimum $s_A$ to the saddle $s_S$, with equally spaced $s_k$ along the line segment from $s_A$ to $s_S$. Let the deposition heights be constant $h_k = h$ for all $k$. One way to estimate the barrier using the accumulated bias is to use $F_\\mathrm{est}(s) = \\mathrm{const} - B(s)$, so that the barrier estimate between $s_A$ and $s_S$ is\n$$\n\\Delta F_\\mathrm{est} = F_\\mathrm{est}(s_S) - F_\\mathrm{est}(s_A) = -\\big(B(s_S) - B(s_A)\\big).\n$$\nThe true barrier for this model, between $s_A$ and $s_S$, can be derived from $F(s)$ without using the bias.\n\nYour task is to:\n- Derive the true barrier $\\Delta F_\\mathrm{true}$ for the given $F(s)$.\n- Implement the isotropic and anisotropic bias constructions described above and compute $\\Delta F_\\mathrm{est}$ for both schemes using deposition along the straight path between $s_A$ and $s_S$.\n- Evaluate the absolute error between the predicted barrier for each scheme and the true barrier, defined as $|\\Delta F_\\mathrm{est} - \\Delta F_\\mathrm{true}|$.\n\nUse the following fixed free energy parameters: $a_x = 1.0$, $b_x = 1.0$, $a_y = 0.8$, $b_y = 1.0$, $c = 0.5$. Use $N = 41$ deposition centers $s_k$ uniformly spaced on the line from $s_A$ to $s_S$ in CV space. Set the constant deposition height to $h = \\Delta F_\\mathrm{true}$. The CV angles must be handled in radians, and all energies must be treated as unitless values in $k_\\mathrm{B} T$ units.\n\nDefine the metric as above, and use the dimension $d=2$ in the anisotropic covariance definition. For each covariance $C_k$, ensure it is positive definite by construction via the given metric; do not add any regularization beyond what is implied by the metric.\n\nTest Suite:\n- Case 1 (happy path): $r = 4.0$, $\\sigma = 0.20$ radians, $\\eta_x = 1.5$, $\\eta_y = 1.5$.\n- Case 2 (boundary, narrow kernels): $r = 4.0$, $\\sigma = 0.05$ radians, $\\eta_x = 1.5$, $\\eta_y = 1.5$.\n- Case 3 (edge, wide kernels): $r = 4.0$, $\\sigma = 0.40$ radians, $\\eta_x = 1.5$, $\\eta_y = 1.5$.\n\nYour program must compute, for each case, the absolute error of the barrier estimate for the isotropic scheme and for the anisotropic scheme. The final output must be a single line containing these six floating-point errors in a comma-separated list enclosed in square brackets, ordered as\n$[\\text{err\\_iso\\_1},\\text{err\\_aniso\\_1},\\text{err\\_iso\\_2},\\text{err\\_aniso\\_2},\\text{err\\_iso\\_3},\\text{err\\_aniso\\_3}]$.\n\nAngles must be treated in radians, and the energies must be unitless in $k_\\mathrm{B} T$. No other units are involved. The program must be a complete, runnable implementation in a modern programming language, and it must not require user input. The output must exactly follow the described single-line format.", "solution": "The problem is valid as it is scientifically grounded in the principles of computational statistical mechanics, specifically the metadynamics method, is well-posed, and all necessary parameters and conditions are provided for a unique solution.\n\nThe task is to compute the absolute error in the free energy barrier estimate provided by isotropic and anisotropic metadynamics schemes against the true analytical barrier for a model potential.\n\n### 1. True Free Energy Barrier ($\\Delta F_\\mathrm{true}$)\n\nThe free energy surface is given by:\n$$\nF(\\theta_x,\\theta_y) = -a_x \\,\\theta_x^2 + b_x \\,\\theta_x^4 + a_y \\,\\theta_y^2 + b_y \\,\\theta_y^4 + c \\,\\theta_x^2 \\,\\theta_y^2\n$$\nThe stationary points are found by setting the gradient $\\nabla F(s) = (\\partial F/\\partial \\theta_x, \\partial F/\\partial \\theta_y)$ to zero.\n$$\n\\frac{\\partial F}{\\partial \\theta_x} = -2 a_x \\theta_x + 4 b_x \\theta_x^3 + 2 c \\theta_x \\theta_y^2 = 2\\theta_x(-a_x + 2b_x\\theta_x^2 + c\\theta_y^2) = 0\n$$\n$$\n\\frac{\\partial F}{\\partial \\theta_y} = 2 a_y \\theta_y + 4 b_y \\theta_y^3 + 2 c \\theta_x^2 \\theta_y = 2\\theta_y(a_y + 2b_y\\theta_y^2 + c\\theta_x^2) = 0\n$$\nThe problem states the saddle point is at $s_S = (0,0)$. At this point, $F(s_S) = F(0,0) = 0$.\n\nThe global minima are at $s_A = (\\theta_x^\\star, 0)$ and $s_{A'} = (-\\theta_x^\\star, 0)$. To find $\\theta_x^\\star$, we set $\\theta_y=0$ in the gradient equations and solve for a non-zero $\\theta_x$:\n$$\n2\\theta_x(-a_x + 2b_x\\theta_x^2) = 0 \\implies \\theta_x^2 = \\frac{a_x}{2b_x}\n$$\nThus, $\\theta_x^\\star = \\sqrt{\\frac{a_x}{2b_x}}$. The free energy at the minimum $s_A$ is:\n$$\nF(s_A) = F(\\theta_x^\\star, 0) = -a_x (\\theta_x^\\star)^2 + b_x (\\theta_x^\\star)^4 = -a_x \\left(\\frac{a_x}{2b_x}\\right) + b_x \\left(\\frac{a_x}{2b_x}\\right)^2 = -\\frac{a_x^2}{2b_x} + \\frac{a_x^2}{4b_x} = -\\frac{a_x^2}{4b_x}\n$$\nThe true free energy barrier between the minimum $s_A$ and the saddle $s_S$ is:\n$$\n\\Delta F_\\mathrm{true} = F(s_S) - F(s_A) = 0 - \\left(-\\frac{a_x^2}{4b_x}\\right) = \\frac{a_x^2}{4b_x}\n$$\nUsing the provided parameters $a_x = 1.0$ and $b_x = 1.0$:\n$$\n\\Delta F_\\mathrm{true} = \\frac{(1.0)^2}{4(1.0)} = 0.25\n$$\nThe minimum is located at $\\theta_x^\\star = \\sqrt{1.0 / (2 \\cdot 1.0)} = \\sqrt{0.5}$ radians. So, $s_A = (\\sqrt{0.5}, 0)$.\n\n### 2. Metadynamics Deposition and Barrier Estimation\n\nThe deposition path is a straight line in CV space from $s_A = (\\sqrt{0.5}, 0)$ to $s_S = (0,0)$. We deposit $N=41$ Gaussian kernels at equally spaced centers $s_k$ along this path, for $k=1, \\dots, N$:\n$$\ns_k = s_A + \\frac{k-1}{N-1}(s_S - s_A) = \\left(1 - \\frac{k-1}{N-1}\\right)s_A\n$$\nSince $s_A = (\\theta_x^\\star, 0)$, each deposition center is $s_k = (\\theta_{x,k}, 0)$, where $\\theta_{x,k} = (1 - \\frac{k-1}{40})\\theta_x^\\star$.\nThe deposition height is constant, $h_k = h = \\Delta F_\\mathrm{true} = 0.25$. The estimated barrier is $\\Delta F_\\mathrm{est} = -(B(s_S) - B(s_A))$, where $B(s)$ is the total bias potential.\n\n### 3. Isotropic Metadynamics Scheme\n\nThe covariance matrix is $C_k = \\sigma^2 I$, where $I$ is the $2 \\times 2$ identity matrix. Its inverse is $C_k^{-1} = \\frac{1}{\\sigma^2}I$. The bias potential is:\n$$\nB(s) = \\sum_{k=1}^{N} h \\exp\\left(-\\frac{1}{2\\sigma^2} \\|s-s_k\\|^2\\right)\n$$\nWe evaluate the bias at the path endpoints, $s_A$ and $s_S$:\n$$\nB_{\\mathrm{iso}}(s_A) = \\sum_{k=1}^{N} h \\exp\\left(-\\frac{1}{2\\sigma^2} \\|s_A - s_k\\|^2\\right)\n$$\n$$\nB_{\\mathrm{iso}}(s_S) = \\sum_{k=1}^{N} h \\exp\\left(-\\frac{1}{2\\sigma^2} \\|s_S - s_k\\|^2\\right)\n$$\nThe squared distances are:\n$$\n\\|s_A - s_k\\|^2 = \\left\\|\\left(\\frac{k-1}{N-1}\\right)s_A\\right\\|^2 = \\left(\\frac{k-1}{N-1}\\right)^2 (\\theta_x^\\star)^2\n$$\n$$\n\\|s_S - s_k\\|^2 = \\left\\|-\\left(1 - \\frac{k-1}{N-1}\\right)s_A\\right\\|^2 = \\left(1 - \\frac{k-1}{N-1}\\right)^2 (\\theta_x^\\star)^2\n$$\nLet $\\lambda_k = (k-1)/(N-1)$. The set of values $\\{\\lambda_k\\}$ for $k=1, \\dots, N$ is $\\{0, \\frac{1}{N-1}, \\dots, 1\\}$. The set of values $\\{1-\\lambda_k\\}$ is $\\{1, \\frac{N-2}{N-1}, \\dots, 0\\}$, which contains the same values as $\\{\\lambda_k\\}$ but in reverse order. Since the summation is over all $k$, the resulting sums are identical:\n$$\nB_{\\mathrm{iso}}(s_A) = \\sum_{k=1}^{N} h \\exp\\left(-\\frac{(\\theta_x^\\star)^2}{2\\sigma^2} \\lambda_k^2 \\right) = \\sum_{k=1}^{N} h \\exp\\left(-\\frac{(\\theta_x^\\star)^2}{2\\sigma^2} (1-\\lambda_k)^2 \\right) = B_{\\mathrm{iso}}(s_S)\n$$\nTherefore, $B_{\\mathrm{iso}}(s_S) - B_{\\mathrm{iso}}(s_A) = 0$, and the estimated barrier is $\\Delta F_\\mathrm{est, iso} = 0$. The absolute error is:\n$$\n|\\Delta F_\\mathrm{est, iso} - \\Delta F_\\mathrm{true}| = |0 - 0.25| = 0.25\n$$\nThis error is independent of the Gaussian width $\\sigma$ and other parameters for this specific deposition protocol.\n\n### 4. Anisotropic Metadynamics Scheme\n\nThe covariance matrix $C_k$ depends on the local metric $g(s_k)$. Since the deposition path lies on the $\\theta_y=0$ axis, we have $\\theta_{y,k}=0$ for all $k$. The metric at $s_k=(\\theta_{x,k}, 0)$ simplifies to a diagonal matrix:\n$$\ng(s_k) = \\begin{pmatrix} 1 + \\eta_x \\,\\theta_{x,k}^2 & 0 \\\\ 0 & r \\end{pmatrix}\n$$\nThe determinant is $\\det g(s_k) = r(1 + \\eta_x \\theta_{x,k}^2)$. The covariance matrix for $d=2$ is:\n$$\nC_k = \\sigma^2 \\left(\\det g(s_k)\\right)^{1/2} g(s_k)^{-1} = \\sigma^2 \\sqrt{r(1 + \\eta_x \\theta_{x,k}^2)} \\begin{pmatrix} (1 + \\eta_x \\theta_{x,k}^2)^{-1} & 0 \\\\ 0 & r^{-1} \\end{pmatrix}\n$$\nThe inverse covariance matrix is:\n$$\nC_k^{-1} = \\frac{1}{\\sigma^2} \\left[r(1 + \\eta_x \\theta_{x,k}^2)\\right]^{-1/2} \\begin{pmatrix} 1 + \\eta_x \\theta_{x,k}^2 & 0 \\\\ 0 & r \\end{pmatrix}\n$$\nThe bias is calculated at $s_A=(\\theta_x^\\star, 0)$ and $s_S=(0,0)$. The quadratic form in the exponential is $(s-s_k)^\\top C_k^{-1} (s-s_k)$. Since the $y$-components of $s_A$, $s_S$, and $s_k$ are all zero, only the $(1,1)$ component of $C_k^{-1}$ contributes:\n$$\n(C_k^{-1})_{11} = c_{xx,k}^{-1} = \\frac{1}{\\sigma^2} \\frac{1+\\eta_x\\theta_{x,k}^2}{\\sqrt{r(1+\\eta_x\\theta_{x,k}^2)}} = \\frac{1}{\\sigma^2\\sqrt{r}}\\sqrt{1+\\eta_x\\theta_{x,k}^2}\n$$\nThe bias evaluations are:\n$$\nB_{\\mathrm{aniso}}(s_A) = \\sum_{k=1}^{N} h \\exp\\left(-\\frac{1}{2} (\\theta_x^\\star - \\theta_{x,k})^2 c_{xx,k}^{-1}\\right)\n$$\n$$\nB_{\\mathrm{aniso}}(s_S) = \\sum_{k=1}^{N} h \\exp\\left(-\\frac{1}{2} (0 - \\theta_{x,k})^2 c_{xx,k}^{-1}\\right) = \\sum_{k=1}^{N} h \\exp\\left(-\\frac{1}{2} \\theta_{x,k}^2 c_{xx,k}^{-1}\\right)\n$$\nUnlike the isotropic case, the term $c_{xx,k}^{-1}$ depends on the position $\\theta_{x,k}$, breaking the symmetry. Thus, $B_{\\mathrm{aniso}}(s_A) \\neq B_{\\mathrm{aniso}}(s_S)$, and the resulting barrier estimate $\\Delta F_\\mathrm{est, aniso}$ will be non-zero. The calculation must be performed numerically for each test case.\n\nThe final error is $|\\Delta F_\\mathrm{est, aniso} - \\Delta F_\\mathrm{true}|$.\n\nThe implementation will proceed by calculating $\\Delta F_\\mathrm{true}$ and the location of $s_A$, then generating the deposition centers $s_k$. For each test case, the biases $B(s_A)$ and $B(s_S)$ are computed for both schemes, from which the estimated barriers and their absolute errors are found.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the metadynamics barrier estimation problem for three test cases.\n    \"\"\"\n    \n    # --- 1. Define Fixed Parameters and True Barrier ---\n    \n    # Free energy parameters\n    a_x = 1.0\n    b_x = 1.0\n    # a_y, b_y, c are not needed for barrier calculation or path on theta_x axis\n    \n    # Metadynamics parameters\n    N = 41\n    \n    # Calculate true barrier and minimum location\n    # F(theta_x, 0) = -a_x * theta_x^2 + b_x * theta_x^4\n    # dF/d(theta_x) = -2*a_x*theta_x + 4*b_x*theta_x^3 = 0\n    # => theta_x^2 = a_x / (2*b_x) for the minimum\n    theta_star_sq = a_x / (2.0 * b_x)\n    theta_star = np.sqrt(theta_star_sq)\n    \n    # F(s_A) at theta_star\n    F_sA = -a_x * theta_star_sq + b_x * theta_star_sq**2\n    # F(s_S) at 0 is 0\n    F_sS = 0.0\n    delta_F_true = F_sS - F_sA\n    \n    # Deposition height\n    h = delta_F_true\n\n    # Path definition\n    s_A = np.array([theta_star, 0.0])\n    s_S = np.array([0.0, 0.0])\n    \n    # Deposition centers s_k = (theta_xk, 0)\n    # s_k = s_A + (k-1)/(N-1) * (s_S - s_A)\n    # Using np.linspace is more direct for the x-coordinates\n    theta_x_k_vals = np.linspace(theta_star, 0.0, N)\n    \n    # Test cases\n    test_cases = [\n        # Case 1 (happy path)\n        {'r': 4.0, 'sigma': 0.20, 'eta_x': 1.5, 'eta_y': 1.5},\n        # Case 2 (boundary, narrow kernels)\n        {'r': 4.0, 'sigma': 0.05, 'eta_x': 1.5, 'eta_y': 1.5},\n        # Case 3 (edge, wide kernels)\n        {'r': 4.0, 'sigma': 0.40, 'eta_x': 1.5, 'eta_y': 1.5},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        r = case['r']\n        sigma = case['sigma']\n        eta_x = case['eta_x']\n        # eta_y is not used as the path is on theta_y = 0\n\n        # --- 2. Isotropic Scheme Calculation ---\n        \n        # Due to the symmetric placement of kernels and evaluation points,\n        # B_iso(s_A) == B_iso(s_S), so delta_F_est_iso = 0 always.\n        delta_F_est_iso = 0.0\n        err_iso = np.abs(delta_F_est_iso - delta_F_true)\n        results.append(err_iso)\n\n        # --- 3. Anisotropic Scheme Calculation ---\n        \n        # Argument of exp: -0.5 * (s-s_k)^T * C_k^-1 * (s-s_k)\n        # s and s_k are on theta_x axis, so only (C_k^-1)_11 matters.\n        # (C_k^-1)_11 = (1/sigma^2 * sqrt(r)) * sqrt(1 + eta_x * theta_xk^2)\n        \n        # Precompute position-dependent part of inverse covariance\n        c_inv_xx_k_vals = (1.0 / (sigma**2 * np.sqrt(r))) * np.sqrt(1.0 + eta_x * theta_x_k_vals**2)\n        \n        # Calculate bias at s_A\n        dist_sq_A = (theta_star - theta_x_k_vals)**2\n        exp_arg_A = -0.5 * dist_sq_A * c_inv_xx_k_vals\n        B_aniso_sA = h * np.sum(np.exp(exp_arg_A))\n        \n        # Calculate bias at s_S\n        dist_sq_S = theta_x_k_vals**2 # (0 - theta_x_k_vals)^2\n        exp_arg_S = -0.5 * dist_sq_S * c_inv_xx_k_vals\n        B_aniso_sS = h * np.sum(np.exp(exp_arg_S))\n        \n        delta_F_est_aniso = -(B_aniso_sS - B_aniso_sA)\n        err_aniso = np.abs(delta_F_est_aniso - delta_F_true)\n        results.append(err_aniso)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3466169"}]}