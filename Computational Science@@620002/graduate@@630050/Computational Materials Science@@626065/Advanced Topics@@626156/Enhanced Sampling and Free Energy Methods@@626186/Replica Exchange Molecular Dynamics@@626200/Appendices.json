{"hands_on_practices": [{"introduction": "The effectiveness of Replica Exchange Molecular Dynamics (REMD) hinges on a carefully constructed swap mechanism that maintains thermodynamic consistency. This first practice takes you to the heart of the algorithm by deriving the acceptance probability for a temperature exchange from the first principles of statistical mechanics. By applying the principle of detailed balance to the joint canonical ensemble of two replicas, you will see how the exchange criterion elegantly depends on the energy difference and the temperature gap, providing a fundamental pillar for enhanced sampling [@problem_id:3442046].", "problem": "Consider two independent replicas of a molecular system, each governed by the same Hamiltonian and coupled to a thermostat so that the system in each replica is in the canonical ensemble at temperature $T$. In Replica Exchange Molecular Dynamics (REMD) and Parallel Tempering (PT), one constructs a joint ensemble for two replicas at temperatures $T_1$ and $T_2$ with the joint equilibrium density proportional to the product of the Boltzmann factors. A temperature-swap move is proposed that exchanges the temperatures of the two replicas while leaving their microscopic configurations unchanged. Assume the proposal mechanism for the swap is symmetric. Starting from the definition of the canonical distribution and the principle of detailed balance, derive the Metropolis–Hastings acceptance probability for this temperature-swap move as a function of the instantaneous potential energies $E_1$ and $E_2$ associated with the two configurations at the moment of the proposed swap.\n\nThen, evaluate this acceptance probability for the following specific case: $T_1 = 300\\,\\mathrm{K}$, $T_2 = 450\\,\\mathrm{K}$, $E_1 = -25.0\\,\\mathrm{kJ\\,mol^{-1}}$, and $E_2 = -20.0\\,\\mathrm{kJ\\,mol^{-1}}$. Use the molar gas constant $R = 8.314462618\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$ and the inverse temperature definition $\\beta_i = 1/(R T_i)$ appropriate for energies expressed per mole. Express the final acceptance probability as a dimensionless number. Round your final numerical answer to four significant figures.", "solution": "The canonical equilibrium distribution for a single replica with configuration $x$ and potential energy $E(x)$ at inverse temperature $\\beta$ is proportional to $\\exp(-\\beta E(x))$. For two independent replicas at inverse temperatures $\\beta_1$ and $\\beta_2$, with configurations $x_1$ and $x_2$ and corresponding energies $E_1 = E(x_1)$ and $E_2 = E(x_2)$, the joint equilibrium density is\n$$\n\\pi_{\\mathrm{old}}(x_1, x_2 \\mid \\beta_1, \\beta_2) \\propto \\exp(-\\beta_1 E_1)\\,\\exp(-\\beta_2 E_2).\n$$\nA proposed temperature-swap move produces the new state $(x_1, x_2 \\mid \\beta_2, \\beta_1)$, i.e., the temperatures are exchanged while the configurations are unchanged. The corresponding joint equilibrium density of the swapped state is\n$$\n\\pi_{\\mathrm{new}}(x_1, x_2 \\mid \\beta_2, \\beta_1) \\propto \\exp(-\\beta_2 E_1)\\,\\exp(-\\beta_1 E_2).\n$$\nBy the Metropolis–Hastings construction with a symmetric proposal, the acceptance probability $a$ is\n$$\na = \\min\\left(1, \\frac{\\pi_{\\mathrm{new}}}{\\pi_{\\mathrm{old}}}\\right) = \\min\\left(1, \\exp\\big[-\\beta_2 E_1 - \\beta_1 E_2 + \\beta_1 E_1 + \\beta_2 E_2\\big]\\right).\n$$\nCollecting terms yields\n$$\na = \\min\\left(1, \\exp\\big[(\\beta_1 - \\beta_2)(E_1 - E_2)\\big]\\right).\n$$\nThis is the acceptance criterion consistent with detailed balance in the joint canonical ensemble.\n\nWe now evaluate this expression for the specified values. The inverse temperatures are defined for molar energies by\n$$\n\\beta_1 = \\frac{1}{R T_1}, \\qquad \\beta_2 = \\frac{1}{R T_2}.\n$$\nThe energy difference is\n$$\n\\Delta E \\equiv E_1 - E_2 = -25.0\\,\\mathrm{kJ\\,mol^{-1}} - \\left(-20.0\\,\\mathrm{kJ\\,mol^{-1}}\\right) = -5.0\\,\\mathrm{kJ\\,mol^{-1}} = -5000\\,\\mathrm{J\\,mol^{-1}}.\n$$\nHence the exponent in the acceptance factor is\n$$\n(\\beta_1 - \\beta_2)\\,\\Delta E = \\left(\\frac{1}{R T_1} - \\frac{1}{R T_2}\\right)(-5000).\n$$\nWith $T_1 = 300\\,\\mathrm{K}$, $T_2 = 450\\,\\mathrm{K}$, and $R = 8.314462618\\,\\mathrm{J\\,mol^{-1}\\,K^{-1}}$,\n$$\n\\beta_1 = \\frac{1}{8.314462618 \\times 300}, \\qquad \\beta_2 = \\frac{1}{8.314462618 \\times 450},\n$$\nso that\n$$\n\\beta_1 - \\beta_2 = \\frac{1}{8.314462618 \\times 300} - \\frac{1}{8.314462618 \\times 450} = \\frac{T_2 - T_1}{R T_1 T_2}.\n$$\nNumerically,\n$$\n\\beta_1 - \\beta_2 = \\frac{150}{8.314462618 \\times 300 \\times 450} \\approx 1.33636 \\times 10^{-4},\n$$\nand therefore\n$$\n(\\beta_1 - \\beta_2)\\,\\Delta E \\approx (1.33636 \\times 10^{-4}) \\times (-5000) \\approx -0.66818.\n$$\nThe acceptance probability is then\n$$\na = \\min\\left(1, \\exp(-0.66818)\\right) \\approx \\exp(-0.66818).\n$$\nUsing $\\exp(-0.66818) = \\exp(-0.69314718 + 0.02496743) = \\exp(-0.69314718)\\,\\exp(0.02496743) = \\frac{1}{2}\\,\\exp(0.02496743)$ and $\\exp(0.02496743) \\approx 1.02528$, we obtain\n$$\na \\approx \\frac{1}{2} \\times 1.02528 \\approx 0.51264.\n$$\nRounded to four significant figures, the acceptance probability is\n$$\n0.5126.\n$$", "answer": "$$\\boxed{0.5126}$$", "id": "3442046"}, {"introduction": "An efficient REMD simulation requires a well-designed temperature ladder, ensuring that replicas can travel smoothly across the temperature range. This practice moves from the single-swap event to the macroscopic design of the simulation, challenging you to estimate the *expected* swap acceptance rate based on the overlap of potential energy distributions between adjacent replicas. This exercise is crucial for developing the practical skill of optimizing temperature spacing to achieve a desired level of replica exchange, a common task in preparing any serious REMD study [@problem_id:3485799].", "problem": "You are tasked with building a program that, starting from first principles of the canonical ensemble and the Metropolis–Hastings criterion, estimates the expected replica-exchange swap acceptance between two canonical replicas and diagnoses whether the temperature ladder spacing is adequate for a metallic glass. Consider two replicas that independently sample potential energies from empirical histograms at temperatures $T_i$ and $T_j$. The acceptance of a proposed swap should be derived from the requirement of detailed balance for the joint canonical distribution of the two replicas. The expected acceptance is defined as the joint expectation of the Metropolis–Hastings acceptance over the product measure formed by the two energy histograms. Your derivation must start from the canonical ensemble probability measure and the principle of detailed balance, without stating the target acceptance formula.\n\nGiven discretized energy histograms on a uniform energy grid, you must numerically estimate the expected acceptance using discrete summation that correctly accounts for bin widths, and then diagnose temperature ladder adequacy for a metallic glass using a scientifically justified criterion that is explicitly stated in terms of a numerical range. All quantities must be expressed in consistent physical units. Use energy in electronvolts (eV) and temperature in Kelvin (K). The Boltzmann constant $k_{\\mathrm{B}}$ must be used in electronvolt per Kelvin, where $k_{\\mathrm{B}} = 8.617333262 \\times 10^{-5}\\,\\mathrm{eV/K}$. Angles are not involved in this task.\n\nThe test suite below provides parameterized synthetic but scientifically plausible histogram specifications that emulate empirical potential energy histograms of a metallic glass. For each test case, you must construct the histogram $p_i(U)$ and $p_j(U)$ on the specified uniform energy grid, normalize them so that the integral over energy is $1$ using numerical integration consistent with the grid, and then compute the expected swap acceptance. You must output, for each case, a list consisting of the acceptance value and a boolean indicating whether the ladder spacing is adequate for a metallic glass according to the criterion that the acceptance should be within the window $[\\alpha_{\\min}, \\alpha_{\\max}]$, with $\\alpha_{\\min} = 0.2$ and $\\alpha_{\\max} = 0.4$. The temperature ladder is deemed adequate if and only if the acceptance lies within this closed interval.\n\nHistogram construction rules:\n- For a single Gaussian component, define the probability density function on energy $U$ by $f(U; \\mu, \\sigma) = \\dfrac{1}{\\sigma \\sqrt{2\\pi}} \\exp\\!\\left(-\\dfrac{(U - \\mu)^2}{2\\sigma^2}\\right)$.\n- For a mixture of $M$ Gaussian components, define $p(U) = \\sum_{m=1}^{M} w_m f(U; \\mu_m, \\sigma_m)$, where the nonnegative weights $\\{w_m\\}$ sum to $1$.\n- Discretize $U$ on a uniform grid $U_k$ with $k = 0, 1, \\dots, N-1$, where $U_k$ spans the specified range using $N$ points.\n- Normalize the discrete histogram so that $\\sum_{k=0}^{N-1} p(U_k) \\,\\Delta U = 1$, where $\\Delta U$ is the uniform bin width.\n\nExpected acceptance estimation requirement:\n- Compute the expected acceptance as the discrete double sum over the joint product of the two normalized histograms, using the Metropolis–Hastings acceptance implied by detailed balance for swapping two independently sampled energies at inverse temperatures $\\beta_i$ and $\\beta_j$, where $\\beta = 1/(k_{\\mathrm{B}} T)$.\n\nAdequacy criterion:\n- Use $\\alpha_{\\min} = 0.2$ and $\\alpha_{\\max} = 0.4$. If the expected acceptance is within $[\\alpha_{\\min}, \\alpha_{\\max}]$, return the boolean $true$; otherwise return $false$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results for all test cases as a comma-separated list enclosed in square brackets, where each item is a two-element list of the form $[\\text{acceptance}, \\text{adequate}]$. For example: $[[a_1,b_1],[a_2,b_2],\\dots]$. Each acceptance must be a floating-point number, and each adequacy must be a boolean.\n\nTest suite (construct the histograms and compute the results for these cases):\n- Case $1$ (moderate ladder spacing, unimodal):\n  - Temperatures: $T_i = 600\\,\\mathrm{K}$, $T_j = 660\\,\\mathrm{K}$.\n  - Energy grid: $U \\in [-3100\\,\\mathrm{eV}, -2900\\,\\mathrm{eV}]$ with $N = 801$ points.\n  - Replica $i$: unimodal Gaussian with $\\mu_i = -3000\\,\\mathrm{eV}$, $\\sigma_i = 18\\,\\mathrm{eV}$.\n  - Replica $j$: unimodal Gaussian with $\\mu_j = -2990\\,\\mathrm{eV}$, $\\sigma_j = 22\\,\\mathrm{eV}$.\n- Case $2$ (near-adjacent temperatures, unimodal):\n  - Temperatures: $T_i = 600\\,\\mathrm{K}$, $T_j = 602\\,\\mathrm{K}$.\n  - Energy grid: $U \\in [-3100\\,\\mathrm{eV}, -2900\\,\\mathrm{eV}]$ with $N = 801$ points.\n  - Replica $i$: unimodal Gaussian with $\\mu_i = -3000\\,\\mathrm{eV}$, $\\sigma_i = 18\\,\\mathrm{eV}$.\n  - Replica $j$: unimodal Gaussian with $\\mu_j = -2999.7\\,\\mathrm{eV}$, $\\sigma_j = 18.7\\,\\mathrm{eV}$.\n- Case $3$ (widely spaced temperatures, unimodal):\n  - Temperatures: $T_i = 600\\,\\mathrm{K}$, $T_j = 900\\,\\mathrm{K}$.\n  - Energy grid: $U \\in [-3100\\,\\mathrm{eV}, -2900\\,\\mathrm{eV}]$ with $N = 801$ points.\n  - Replica $i$: unimodal Gaussian with $\\mu_i = -3000\\,\\mathrm{eV}$, $\\sigma_i = 18\\,\\mathrm{eV}$.\n  - Replica $j$: unimodal Gaussian with $\\mu_j = -2950\\,\\mathrm{eV}$, $\\sigma_j = 35\\,\\mathrm{eV}$.\n- Case $4$ (bimodal mixture representing glassy heterogeneity):\n  - Temperatures: $T_i = 700\\,\\mathrm{K}$, $T_j = 770\\,\\mathrm{K}$.\n  - Energy grid: $U \\in [-3040\\,\\mathrm{eV}, -2920\\,\\mathrm{eV}]$ with $N = 601$ points.\n  - Replica $i$: mixture with two components:\n    - Weights: $w_{i,1} = 0.6$, $w_{i,2} = 0.4$.\n    - Means: $\\mu_{i,1} = -2995\\,\\mathrm{eV}$, $\\mu_{i,2} = -2970\\,\\mathrm{eV}$.\n    - Standard deviations: $\\sigma_{i,1} = 18\\,\\mathrm{eV}$, $\\sigma_{i,2} = 12\\,\\mathrm{eV}$.\n  - Replica $j$: mixture with two components:\n    - Weights: $w_{j,1} = 0.5$, $w_{j,2} = 0.5$.\n    - Means: $\\mu_{j,1} = -2988\\,\\mathrm{eV}$, $\\mu_{j,2} = -2960\\,\\mathrm{eV}$.\n    - Standard deviations: $\\sigma_{j,1} = 22\\,\\mathrm{eV}$, $\\sigma_{j,2} = 15\\,\\mathrm{eV}$.\n- Case $5$ (identical temperatures, unimodal; boundary condition):\n  - Temperatures: $T_i = 650\\,\\mathrm{K}$, $T_j = 650\\,\\mathrm{K}$.\n  - Energy grid: $U \\in [-3050\\,\\mathrm{eV}, -2930\\,\\mathrm{eV}]$ with $N = 601$ points.\n  - Replica $i$: unimodal Gaussian with $\\mu_i = -2995\\,\\mathrm{eV}$, $\\sigma_i = 20\\,\\mathrm{eV}$.\n  - Replica $j$: unimodal Gaussian with $\\mu_j = -2995\\,\\mathrm{eV}$, $\\sigma_j = 20\\,\\mathrm{eV}$.\n\nYour program must implement the above, compute the expected acceptance for each case, and output a single line in the exact format $[[a_1,b_1],[a_2,b_2],[a_3,b_3],[a_4,b_4],[a_5,b_5]]$, where each $a_k$ is a floating-point value and each $b_k$ is a boolean.", "solution": "The problem requires the estimation of the expected replica-exchange swap acceptance probability between two canonical replicas, $i$ and $j$, at temperatures $T_i$ and $T_j$, whose potential energies are sampled from given distributions. The derivation must originate from the first principles of statistical mechanics.\n\nLet the state of the two-replica system be defined by the potential energies of their respective configurations, $(U_i, U_j)$. In the extended canonical ensemble used for replica-exchange simulations, the joint probability density for this state is the product of the individual canonical probabilities. Assuming the density of states $\\Omega(U)$ is the same for both systems (as they represent the same physical system), the probability is proportional to the Boltzmann factors:\n$$\nP(U_i, U_j) \\propto \\Omega(U_i) e^{-\\beta_i U_i} \\cdot \\Omega(U_j) e^{-\\beta_j U_j}\n$$\nwhere $\\beta_k = 1/(k_{\\mathrm{B}} T_k)$ is the inverse temperature for replica $k$, and $k_{\\mathrm{B}}$ is the Boltzmann constant.\n\nA swap move between replicas $i$ and $j$ proposes a transition from state $(U_i, U_j)$ to $(U_j, U_i)$, where the configurations are exchanged. The replica at temperature $T_i$ now has energy $U_j$, and the one at $T_j$ has energy $U_i$. The probability of this new state is:\n$$\nP(U_j, U_i) \\propto \\Omega(U_j) e^{-\\beta_i U_j} \\cdot \\Omega(U_i) e^{-\\beta_j U_i}\n$$\n\nThe principle of detailed balance must be satisfied for the swap moves to maintain the equilibrium of the extended ensemble. This principle states:\n$$\nP(U_i, U_j) W((U_i, U_j) \\to (U_j, U_i)) = P(U_j, U_i) W((U_j, U_i) \\to (U_i, U_j))\n$$\nwhere $W(A \\to B)$ is the total transition probability from state $A$ to state $B$. This is a product of the proposal probability $g(A \\to B)$ and the acceptance probability $\\alpha(A \\to B)$. Since the proposal to swap is symmetric, $g((U_i, U_j) \\to (U_j, U_i)) = g((U_j, U_i) \\to (U_i, U_j))$, the detailed balance condition simplifies to a ratio of the acceptance probabilities:\n$$\n\\frac{\\alpha(U_i \\leftrightarrow U_j)}{\\alpha(U_j \\leftrightarrow U_i)} = \\frac{P(U_j, U_i)}{P(U_i, U_j)} = \\frac{\\Omega(U_j) e^{-\\beta_i U_j} \\Omega(U_i) e^{-\\beta_j U_i}}{\\Omega(U_i) e^{-\\beta_i U_i} \\Omega(U_j) e^{-\\beta_j U_j}} = \\frac{e^{-\\beta_i U_j - \\beta_j U_i}}{e^{-\\beta_i U_i - \\beta_j U_j}}\n$$\nNotice that the density of states terms $\\Omega(U)$ cancel. Simplifying the exponential term yields:\n$$\n\\frac{\\alpha(U_i \\leftrightarrow U_j)}{\\alpha(U_j \\leftrightarrow U_i)} = e^{-(\\beta_i U_j + \\beta_j U_i) + (\\beta_i U_i + \\beta_j U_j)} = e^{(\\beta_i - \\beta_j)U_i - (\\beta_i - \\beta_j)U_j} = e^{-(\\beta_j - \\beta_i)(U_j - U_i)}\n$$\nThe Metropolis-Hastings criterion provides a common and valid choice for the acceptance probability that satisfies this relation:\n$$\n\\alpha(U_i \\leftrightarrow U_j) = \\min\\left(1, \\frac{P(U_j, U_i)}{P(U_i, U_j)}\\right) = \\min\\left(1, e^{-(\\beta_j - \\beta_i)(U_j - U_i)}\\right)\n$$\nThis is the acceptance probability for a single proposed swap involving energies $U_i$ and $U_j$.\n\nThe problem states that replicas $i$ and $j$ independently sample potential energies from empirical histograms, which we represent as continuous probability density functions $p_i(U)$ and $p_j(U)$. The expected acceptance probability, $\\langle \\alpha \\rangle$, is the average of $\\alpha(U_i \\leftrightarrow U_j)$ over all possible pairs of energies $(U_i, U_j)$, weighted by the joint probability density $p_i(U_i)p_j(U_j)$:\n$$\n\\langle \\alpha \\rangle = \\int_{-\\infty}^{\\infty} dU_i \\int_{-\\infty}^{\\infty} dU_j \\, p_i(U_i) p_j(U_j) \\, \\alpha(U_i \\leftrightarrow U_j)\n$$\nSubstituting the derived expression for $\\alpha(U_i \\leftrightarrow U_j)$:\n$$\n\\langle \\alpha \\rangle = \\int_{-\\infty}^{\\infty} dU_i \\int_{-\\infty}^{\\infty} dU_j \\, p_i(U_i) p_j(U_j) \\, \\min\\left(1, e^{-(\\beta_j - \\beta_i)(U_j - U_i)}\\right)\n$$\n\nFor numerical computation, this double integral is discretized over a uniform energy grid. Let the grid consist of $N$ points $\\{U_k\\}_{k=0}^{N-1}$ with a uniform spacing of $\\Delta U$. The integral is approximated by a double Riemann sum. The probability of finding replica $i$ in the energy bin centered at $U_k$ is $P_i(k) = p_i(U_k) \\Delta U$. The sum is:\n$$\n\\langle \\alpha \\rangle \\approx \\sum_{k=0}^{N-1} \\sum_{l=0}^{N-1} (p_i(U_k) \\Delta U) (p_j(U_l) \\Delta U) \\min\\left(1, e^{-(\\beta_j - \\beta_i)(U_l - U_k)}\\right)\n$$\nThe problem specifies that the histograms are constructed from (mixtures of) Gaussian distributions. Let $h_i(U_k)$ be the value of the unnormalized Gaussian mixture function evaluated at grid point $U_k$. The normalization condition is $\\sum_{k=0}^{N-1} p_i(U_k) \\Delta U = 1$. This means the normalized density $p_i(U_k)$ is related to the unnormalized values $h_i(U_k)$ by $p_i(U_k) = h_i(U_k) / C_i$, where the normalization constant is $C_i = \\sum_{k=0}^{N-1} h_i(U_k) \\Delta U$. Substituting this into the expression for $\\langle \\alpha \\rangle$ and simplifying demonstrates that the bin width $\\Delta U$ cancels:\n$$\n\\langle \\alpha \\rangle \\approx \\frac{\\sum_{k=0}^{N-1} \\sum_{l=0}^{N-1} h_i(U_k) h_j(U_l) \\min\\left(1, e^{-(\\beta_j - \\beta_i)(U_l - U_k)}\\right)}{\\left(\\sum_{k=0}^{N-1} h_i(U_k)\\right) \\left(\\sum_{l=0}^{N-1} h_j(U_l)\\right)}\n$$\nThis expression is robust and is used for the implementation. The algorithm proceeds by:\n$1$. Constructing the uniform energy grid $\\{U_k\\}$.\n$2$. Evaluating the unnormalized histogram functions $h_i(U_k)$ and $h_j(U_k)$ on this grid based on the provided Gaussian parameters.\n$3$. Computing the double summation in the numerator and the product of sums in the denominator. Vectorized array operations are used for efficiency.\n$4$. Dividing the two results to obtain the estimated expected acceptance $\\langle \\alpha \\rangle$.\n\nFinally, the temperature ladder spacing is diagnosed. The criterion for an adequate ladder spacing for a metallic glass simulation is given as an acceptance rate within the closed interval $[\\alpha_{\\min}, \\alpha_{\\max}]$, where $\\alpha_{\\min} = 0.2$ and $\\alpha_{\\max} = 0.4$. The computed $\\langle \\alpha \\rangle$ is checked against this range, and a boolean value is returned accordingly.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the replica exchange problem for all test cases.\n    \"\"\"\n    \n    # Constants\n    KB_EV_K = 8.617333262e-5  # Boltzmann constant in eV/K\n    ALPHA_MIN = 0.2\n    ALPHA_MAX = 0.4\n\n    test_cases = [\n        # Case 1\n        {\n            \"temps\": (600, 660), \"N\": 801, \"U_range\": (-3100, -2900),\n            \"h_i\": [{\"w\": 1.0, \"mu\": -3000, \"sigma\": 18}],\n            \"h_j\": [{\"w\": 1.0, \"mu\": -2990, \"sigma\": 22}],\n        },\n        # Case 2\n        {\n            \"temps\": (600, 602), \"N\": 801, \"U_range\": (-3100, -2900),\n            \"h_i\": [{\"w\": 1.0, \"mu\": -3000, \"sigma\": 18}],\n            \"h_j\": [{\"w\": 1.0, \"mu\": -2999.7, \"sigma\": 18.7}],\n        },\n        # Case 3\n        {\n            \"temps\": (600, 900), \"N\": 801, \"U_range\": (-3100, -2900),\n            \"h_i\": [{\"w\": 1.0, \"mu\": -3000, \"sigma\": 18}],\n            \"h_j\": [{\"w\": 1.0, \"mu\": -2950, \"sigma\": 35}],\n        },\n        # Case 4\n        {\n            \"temps\": (700, 770), \"N\": 601, \"U_range\": (-3040, -2920),\n            \"h_i\": [\n                {\"w\": 0.6, \"mu\": -2995, \"sigma\": 18},\n                {\"w\": 0.4, \"mu\": -2970, \"sigma\": 12},\n            ],\n            \"h_j\": [\n                {\"w\": 0.5, \"mu\": -2988, \"sigma\": 22},\n                {\"w\": 0.5, \"mu\": -2960, \"sigma\": 15},\n            ],\n        },\n        # Case 5\n        {\n            \"temps\": (650, 650), \"N\": 601, \"U_range\": (-3050, -2930),\n            \"h_i\": [{\"w\": 1.0, \"mu\": -2995, \"sigma\": 20}],\n            \"h_j\": [{\"w\": 1.0, \"mu\": -2995, \"sigma\": 20}],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        acceptance, is_adequate = compute_case(case, KB_EV_K, ALPHA_MIN, ALPHA_MAX)\n        results.append(f\"[{acceptance},{str(is_adequate).lower()}]\")\n        \n    print(f\"[{','.join(results)}]\")\n\n\ndef gaussian_pdf(x, mu, sigma):\n    \"\"\"\n    Computes the value of a Gaussian probability density function.\n    No scipy dependency used as per strict interpretation.\n    \"\"\"\n    return (1 / (sigma * np.sqrt(2 * np.pi))) * np.exp(-0.5 * ((x - mu) / sigma) ** 2)\n\ndef build_histogram(U, components):\n    \"\"\"\n    Builds an unnormalized histogram from a Gaussian mixture model.\n    \"\"\"\n    h = np.zeros_like(U)\n    for comp in components:\n        h += comp[\"w\"] * gaussian_pdf(U, comp[\"mu\"], comp[\"sigma\"])\n    return h\n\ndef compute_case(case, kb, alpha_min, alpha_max):\n    \"\"\"\n    Computes the expected acceptance and adequacy for a single test case.\n    \"\"\"\n    T_i, T_j = case[\"temps\"]\n    N = case[\"N\"]\n    U_min, U_max = case[\"U_range\"]\n    \n    # 1. Construct the energy grid\n    U = np.linspace(U_min, U_max, N)\n    \n    # 2. Build unnormalized histograms\n    h_i = build_histogram(U, case[\"h_i\"])\n    h_j = build_histogram(U, case[\"h_j\"])\n    \n    # 3. Calculate inverse temperatures\n    # Use a small epsilon to avoid division by zero if T=0, though not expected here.\n    beta_i = 1.0 / (kb * (T_i + 1e-12))\n    beta_j = 1.0 / (kb * (T_j + 1e-12))\n    delta_beta = beta_j - beta_i\n\n    # Handle the trivial case of identical temperatures\n    if np.isclose(delta_beta, 0.0):\n        acceptance = 1.0\n        is_adequate = alpha_min <= acceptance <= alpha_max\n        return acceptance, is_adequate\n\n    # 4. Compute the double summation using vectorized operations\n    \n    # Denominator computation\n    sum_h_i = np.sum(h_i)\n    sum_h_j = np.sum(h_j)\n    denominator = sum_h_i * sum_h_j\n\n    if denominator == 0:\n        return 0.0, False\n\n    # Numerator computation\n    # Create matrices for broadcasting\n    U_k = U[:, np.newaxis]  # Column vector for U_i\n    U_l = U[np.newaxis, :]  # Row vector for U_j\n\n    h_i_col = h_i[:, np.newaxis]\n    h_j_row = h_j[np.newaxis, :]\n    \n    # Calculate matrix of energy differences\n    delta_U_matrix = U_l - U_k\n    \n    # Calculate acceptance probability for each pair (U_k, U_l)\n    exponent_matrix = -delta_beta * delta_U_matrix\n    alpha_matrix = np.minimum(1.0, np.exp(exponent_matrix))\n    \n    # Calculate the joint unnormalized probability matrix\n    joint_h_matrix = h_i_col * h_j_row\n    \n    # Compute the numerator sum\n    numerator = np.sum(joint_h_matrix * alpha_matrix)\n    \n    # 5. Calculate final expected acceptance\n    acceptance = numerator / denominator\n    \n    # 6. Diagnose adequacy\n    is_adequate = alpha_min <= acceptance <= alpha_max\n    \n    return acceptance, is_adequate\n\nsolve()\n\n```", "id": "3485799"}, {"introduction": "High replica exchange rates are a necessary, but not sufficient, condition for successful enhanced sampling. This final practice sharpens your diagnostic skills by presenting a common yet perplexing scenario: a simulation with excellent temperature diffusion that still fails to explore the relevant conformational landscape. By analyzing potential hidden pitfalls, you will learn to look beyond simple metrics and develop a deeper, more critical understanding of the complex interplay between solvent effects, relaxation timescales, and effective sampling in REMD [@problem_id:2455419].", "problem": "A protein is simulated in explicit solvent using Replica Exchange Molecular Dynamics (REMD), where multiple replicas at different temperatures exchange temperatures to maintain detailed balance in the extended ensemble. The measured average exchange acceptance rates between all neighboring temperature pairs are uniformly high, yet over a long wall-clock time the protein in the lowest-temperature replica shows no folding transitions and remains trapped in a misfolded ensemble. Which of the following could plausibly explain this outcome without contradicting the observed high acceptance rates? Select all that apply.\n\nA. In explicit solvent, the total potential energy $U_\\text{tot}$ is dominated by solvent degrees of freedom, so neighboring replicas have strong overlap in $U_\\text{tot}$ and exchange readily; however, the protein’s conformational energy $U_\\text{prot}$ overlaps poorly across temperatures, so exchanges do not translate into effective heating of the protein conformational degrees of freedom.\n\nB. High exchange acceptance implies ergodic sampling by itself; therefore, the lack of folding must indicate a coding error in the Metropolis acceptance test.\n\nC. The exchange attempt interval $ \\tau_\\text{ex}$ is much shorter than the protein’s structural relaxation time $ \\tau_\\text{relax}$ at a given temperature, so after a temperature swap there is insufficient intrareplica time for conformations to equilibrate at the new temperature before the next swap, leading to temperature-space diffusion without configurational barrier crossing.\n\nD. Because the Metropolis rule in temperature REMD depends on kinetic energy, imposing holonomic constraints (for example, bond constraints) artificially inflates acceptance while suppressing barrier crossing.\n\nE. Using more replicas than necessary always decreases sampling efficiency by preventing temperature diffusion, which explains the lack of folding despite high acceptance.", "solution": "The problem statement will now be subjected to rigorous validation.\n\n### Step 1: Extract Givens\n-   A protein is simulated in explicit solvent.\n-   The simulation method is Replica Exchange Molecular Dynamics (REMD).\n-   Multiple replicas exist at different temperatures.\n-   Replicas exchange temperatures to maintain detailed balance in the extended ensemble.\n-   The measured average exchange acceptance rates between all neighboring temperature pairs are \"uniformly high\".\n-   Over a long wall-clock time, the protein in the lowest-temperature replica shows no folding transitions.\n-   The protein remains trapped in a misfolded ensemble.\n-   The question asks for a plausible explanation for this outcome that does not contradict the high acceptance rates.\n\n### Step 2: Validate Using Extracted Givens\n-   **Scientifically Grounded**: The problem describes a scenario in computational chemistry using a standard and widely-used enhanced sampling technique, Replica Exchange Molecular Dynamics (REMD). The concepts of explicit solvent, potential energy, temperature, folding transitions, and acceptance rates are all fundamental to the fields of molecular dynamics and statistical mechanics. The scenario presented—high exchange rates coupled with poor conformational sampling—is a known and frequently discussed challenge in the practical application of REMD. The problem is firmly based on established scientific principles.\n-   **Well-Posed**: The problem is well-posed. It presents a specific observation (high exchange rates, poor sampling) and asks for possible physical causes from a set of options. A definite logical analysis can be performed to evaluate the validity of each proposed cause.\n-   **Objective**: The language is precise and quantitative where needed (e.g., \"uniformly high\" acceptance rates). It does not contain subjective or opinion-based statements. It describes a physical observation and asks for a scientific explanation.\n\n### Step 3: Verdict and Action\nThe problem statement is scientifically sound, well-posed, and objective. It describes a realistic and non-trivial puzzle in the application of a major computational method. The problem is valid. We will proceed with the derivation of the solution.\n\nThe core of the problem lies in the apparent contradiction between an efficient random walk in temperature space (indicated by \"uniformly high\" exchange acceptance rates) and an inefficient random walk in the protein's conformational space (indicated by the lack of folding transitions).\n\nThe fundamental formula for the acceptance probability of a temperature exchange between two replicas, $i$ and $j$, at inverse temperatures $\\beta_i = 1/(k_B T_i)$ and $\\beta_j = 1/(k_B T_j)$ with potential energies $U_i$ and $U_j$, is given by the Metropolis criterion for the extended ensemble:\n$$ P_{\\text{acc}} = \\min\\left(1, e^{(\\beta_i - \\beta_j)(U_i - U_j)}\\right) = \\min\\left(1, e^{\\Delta\\beta \\Delta U}\\right) $$\nA \"high\" acceptance rate, for example between neighboring replicas $i$ and $i+1$ where $\\beta_i > \\beta_{i+1}$, implies that the exponent, $(\\beta_i - \\beta_{i+1})(U_i - U_{i+1})$, is frequently close to zero or negative. This facilitates the diffusion of replicas through temperature space. The goal of this diffusion is to allow a configuration at a low temperature to travel to a high temperature, overcome a potential energy barrier, and then return to the low temperature in a new conformational basin. The problem states this second part—the overcoming of conformational barriers—is not happening. We must analyze why.\n\nNow, we evaluate each option.\n\n**A. In explicit solvent, the total potential energy $U_\\text{tot}$ is dominated by solvent degrees of freedom, so neighboring replicas have strong overlap in $U_\\text{tot}$ and exchange readily; however, the protein’s conformational energy $U_\\text{prot}$ overlaps poorly across temperatures, so exchanges do not translate into effective heating of the protein conformational degrees of freedom.**\n\nThis statement describes a well-known pathology of REMD in explicit solvent. The total potential energy of the system is the sum of terms: $U_\\text{tot} = U_\\text{protein} + U_\\text{protein-solvent} + U_\\text{solvent-solvent}$. In a typical simulation box, the number of solvent molecules vastly exceeds the number of atoms in the protein. Consequently, the potential energy and its fluctuations are dominated by the solvent-solvent interactions. The acceptance probability $P_\\text{acc}$ depends on $U_\\text{tot}$. It is possible for the energy distributions $P(U_\\text{tot})$ of adjacent temperatures to have significant overlap, leading to high acceptance rates, simply due to the large fluctuations of the solvent energy. However, the energy distribution of the solute alone, $P(U_\\text{protein})$, may have very poor overlap between the same two temperatures. In such a scenario, an exchange may be accepted because of a favorable configuration of solvent molecules, not because the protein has entered a conformation that is more thermally accessible at the higher temperature. The protein's conformation effectively \"hides\" within the vast energy landscape of the solvent. The temperature random walk becomes decoupled from the desired conformational random walk. This is a correct and plausible explanation.\n\n**Verdict: Correct**\n\n**B. High exchange acceptance implies ergodic sampling by itself; therefore, the lack of folding must indicate a coding error in the Metropolis acceptance test.**\n\nThis statement is fundamentally incorrect. High exchange acceptance merely implies that replicas are efficiently traversing the ladder of temperatures. It is a necessary but not sufficient condition for achieving ergodic sampling of the conformational space. Ergodicity requires that the system is able to visit all accessible microstates over time. REMD is designed to accelerate this process, but a high exchange rate does not guarantee its success. The failure to sample conformations can arise from physical reasons, as described in option A and C, not just a bug in the code. To claim that high acceptance *implies* ergodicity is a gross oversimplification and is factually wrong.\n\n**Verdict: Incorrect**\n\n**C. The exchange attempt interval $ \\tau_\\text{ex}$ is much shorter than the protein’s structural relaxation time $ \\tau_\\text{relax}$ at a given temperature, so after a temperature swap there is insufficient intrareplica time for conformations to equilibrate at the new temperature before the next swap, leading to temperature-space diffusion without configurational barrier crossing.**\n\nThis statement describes another classic inefficiency in REMD. For REMD to be effective, a conformation that swaps to a higher temperature must have sufficient time to evolve and cross an energy barrier before it swaps back to a lower temperature. The characteristic time for such a conformational change is the relaxation time, $\\tau_\\text{relax}$. If the time between exchange attempts, $\\tau_\\text{ex}$, is much smaller than $\\tau_\\text{relax}$ (i.e., $\\tau_\\text{ex} \\ll \\tau_\\text{relax}$), the configuration does not have enough time to change significantly. The system will diffuse rapidly in temperature space, but the configurations will remain \"frozen\" or \"stuck\" to their respective temperature indices. The random walk in temperature is not productively coupled to exploration of the conformational landscape. This leads to the exact scenario described in the problem: high acceptance rates but no conformational progress.\n\n**Verdict: Correct**\n\n**D. Because the Metropolis rule in temperature REMD depends on kinetic energy, imposing holonomic constraints (for example, bond constraints) artificially inflates acceptance while suppressing barrier crossing.**\n\nThe premise of this statement is false. The standard temperature REMD acceptance probability, $P_{\\text{acc}} = \\min(1, \\exp(\\Delta\\beta \\Delta U))$, depends explicitly on the difference in *potential energy* ($\\Delta U$) and the difference in inverse temperatures ($\\Delta\\beta$). It does not depend on the kinetic energy of the replicas. The kinetic energy terms, which are assumed to be functions only of temperature and the number of degrees of freedom, cancel out during the derivation of the exchange probability from the canonical partition function. Since the premise that the rule \"depends on kinetic energy\" is incorrect, the entire argument is invalid.\n\n**Verdict: Incorrect**\n\n**E. Using more replicas than necessary always decreases sampling efficiency by preventing temperature diffusion, which explains the lack of folding despite high acceptance.**\n\nThis claim is the opposite of the truth. Temperature diffusion is the random walk of a given replica through the set of temperatures. The efficiency of this diffusion is limited by the acceptance rate between adjacent temperatures. Increasing the number of replicas for a fixed temperature range means the temperature difference $\\Delta T$ between adjacent replicas becomes smaller. A smaller $\\Delta T$ leads to a greater overlap between the potential energy distributions $P(U)$ of neighboring replicas, which in turn *increases* the exchange acceptance rate. Therefore, using more replicas generally *improoves* temperature diffusion, it does not prevent it. While using an excessive number of replicas is computationally wasteful, it does not \"prevent temperature diffusion\" and would not explain the observed problem. Poor temperature diffusion is caused by using too *few* replicas, leading to low acceptance rates.\n\n**Verdict: Incorrect**\n\nIn summary, options A and C present two distinct and well-documented physical reasons why a REMD simulation can exhibit high exchange acceptance rates while failing to enhance conformational sampling.", "answer": "$$\\boxed{AC}$$", "id": "2455419"}]}