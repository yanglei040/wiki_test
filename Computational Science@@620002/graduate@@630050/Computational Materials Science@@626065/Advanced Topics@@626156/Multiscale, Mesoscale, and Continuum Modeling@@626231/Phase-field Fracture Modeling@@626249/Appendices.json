{"hands_on_practices": [{"introduction": "Understanding any field begins with its fundamental solutions. This first practice invites you to derive the cornerstone analytical solution for a phase-field fracture model from first principles [@problem_id:3550298]. By minimizing the Ambrosio-Tortorelli (AT2) energy functional, you will solve the Euler-Lagrange equation to find the equilibrium shape of a one-dimensional regularized crack and verify a crucial property: that the total energy of this diffuse crack correctly integrates to the material's fracture toughness, $G_c$.", "problem": "Consider a one-dimensional infinite domain $\\mathbb{R}$ within the framework of phase-field modeling of fracture for a stationary straight crack centered at $x=0$. Let $d(x)$ denote the scalar phase-field variable, with $d=1$ representing fully broken material and $d=0$ representing intact material. Assume the Ambrosio-Tortorelli type 2 (AT2) crack surface density functional, a regularization length scale $\\ell>0$, critical energy release rate $G_c>0$, and a vanishing residual stiffness parameter $\\kappa \\to 0$, so that there is no elastic driving energy and the only energetic contribution is the fracture surface energy. \n\nStarting from the principle of minimum potential energy and the AT2 fracture surface functional expressed in one dimension as\n$$\n\\Psi[d] \\;=\\; \\int_{-\\infty}^{\\infty} G_c \\left( \\frac{d(x)^{2}}{2\\,\\ell} \\;+\\; \\frac{\\ell}{2}\\left(\\frac{\\mathrm{d}d}{\\mathrm{d}x}\\right)^{2} \\right)\\,\\mathrm{d}x,\n$$\ndetermine the equilibrium phase-field profile $d(x)$ corresponding to a stationary straight crack by solving the associated Euler–Lagrange equation subject to the physically motivated conditions $d(0)=1$ and $d(x)\\to 0$ as $|x|\\to\\infty$. Then, using that profile, verify analytically that the total fracture surface energy per unit area of the crack equals $G_c$ by evaluating the integral $\\Psi[d]$.\n\nYour final answer must provide:\n- the closed-form expression of the equilibrium profile $d(x)$, and\n- the value of the fracture surface energy per unit area, expressed symbolically in terms of $G_c$.\n\nDo not substitute any numerical values and do not include units in your final boxed answer. Express the energy symbolically in terms of $G_c$ only. If you use any angular quantities, they must be in radians; however, no rounding is required in this problem.", "solution": "The user wants to solve for a phase-field fracture problem, here is a step-by-step procedure for this task.\n\n### Step 1: Problem Validation\n\nThe problem statement describes a standard, albeit simplified, scenario in the phase-field modeling of fracture.\n\n**Extracted Givens:**\n*   **Domain:** One-dimensional infinite domain $\\mathbb{R}$.\n*   **Physical Setup:** A stationary straight crack centered at $x=0$.\n*   **Phase-Field Variable:** $d(x)$, with $d=1$ for broken material and $d=0$ for intact material.\n*   **Fracture Surface Functional (AT2):** $\\Psi[d] = \\int_{-\\infty}^{\\infty} G_c \\left( \\frac{d(x)^{2}}{2\\,\\ell} + \\frac{\\ell}{2}\\left(\\frac{\\mathrm{d}d}{\\mathrm{d}x}\\right)^{2} \\right)\\,\\mathrm{d}x$.\n*   **Parameters:** Regularization length scale $\\ell>0$ and critical energy release rate $G_c>0$.\n*   **Assumption:** No elastic driving energy (equivalent to vanishing residual stiffness $\\kappa \\to 0$).\n*   **Boundary Conditions:** $d(0)=1$ and $d(x)\\to 0$ as $|x|\\to\\infty$.\n*   **Objective 1:** Find the equilibrium phase-field profile $d(x)$ by solving the Euler–Lagrange equation for the functional $\\Psi[d]$.\n*   **Objective 2:** Analytically verify that the total fracture surface energy $\\Psi[d]$ evaluates to $G_c$ using the derived profile $d(x)$.\n\n**Validation Verdict:**\nThe problem is **valid**.\n1.  **Scientifically Grounded:** The problem uses the Ambrosio-Tortorelli (AT2) functional, a cornerstone of variational fracture mechanics. The use of the Euler-Lagrange equation to find the equilibrium profile by minimizing the potential energy functional is a standard method in physics and mechanics.\n2.  **Well-Posed:** The problem is a well-defined boundary value problem for a second-order ordinary differential equation. The givens are sufficient and consistent, leading to a unique, stable, and meaningful solution.\n3.  **Objective:** The language is formal and precise, with all terms defined within the context of computational geomechanics and phase-field theory.\n\n### Step 2: Solution Derivation\n\nThe equilibrium profile $d(x)$ is the function that minimizes the potential energy functional $\\Psi[d]$. Since there is no elastic energy, we only need to minimize the fracture surface functional. This is a classic problem in the calculus of variations.\n\nThe integrand of the functional is the Lagrangian, $L$:\n$$\nL\\left(d, \\frac{\\mathrm{d}d}{\\mathrm{d}x}\\right) = G_c \\left( \\frac{d^{2}}{2\\,\\ell} + \\frac{\\ell}{2}\\left(\\frac{\\mathrm{d}d}{\\mathrm{d}x}\\right)^{2} \\right)\n$$\nThe function $d(x)$ that minimizes $\\Psi[d]$ must satisfy the Euler–Lagrange equation:\n$$\n\\frac{\\partial L}{\\partial d} - \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left(\\frac{\\partial L}{\\partial (\\mathrm{d}d/\\mathrm{d}x)}\\right) = 0\n$$\nFirst, we compute the partial derivatives of $L$:\n$$\n\\frac{\\partial L}{\\partial d} = G_c \\left(\\frac{2d}{2\\ell}\\right) = \\frac{G_c d}{\\ell}\n$$\n$$\n\\frac{\\partial L}{\\partial (\\mathrm{d}d/\\mathrm{d}x)} = G_c \\left(\\frac{\\ell}{2} \\cdot 2 \\frac{\\mathrm{d}d}{\\mathrm{d}x}\\right) = G_c \\ell \\frac{\\mathrm{d}d}{\\mathrm{d}x}\n$$\nSubstituting these into the Euler-Lagrange equation gives:\n$$\n\\frac{G_c d}{\\ell} - \\frac{\\mathrm{d}}{\\mathrm{d}x}\\left(G_c \\ell \\frac{\\mathrm{d}d}{\\mathrm{d}x}\\right) = 0\n$$\nSince $G_c$ and $\\ell$ are non-zero constants, we can simplify the equation:\n$$\n\\frac{d}{\\ell} - \\ell \\frac{\\mathrm{d}^2 d}{\\mathrm{d}x^2} = 0\n$$\n$$\n\\frac{\\mathrm{d}^2 d}{\\mathrm{d}x^2} - \\frac{1}{\\ell^2} d = 0\n$$\nThis is a second-order linear homogeneous ordinary differential equation with constant coefficients. The characteristic equation is $r^2 - 1/\\ell^2 = 0$, which has roots $r_1 = 1/\\ell$ and $r_2 = -1/\\ell$.\nThe general solution is therefore:\n$$\nd(x) = C_1 \\exp\\left(\\frac{x}{\\ell}\\right) + C_2 \\exp\\left(-\\frac{x}{\\ell}\\right)\n$$\nwhere $C_1$ and $C_2$ are constants to be determined by the boundary conditions.\n\nThe boundary conditions are $d(x) \\to 0$ as $|x| \\to \\infty$ and $d(0)=1$.\n1.  For the condition $d(x) \\to 0$ as $x \\to \\infty$, the term $C_1 \\exp(x/\\ell)$ would grow infinitely unless $C_1=0$. So, for $x>0$, we must have $C_1=0$.\n2.  For the condition $d(x) \\to 0$ as $x \\to -\\infty$, the term $C_2 \\exp(-x/\\ell)$ would grow infinitely unless $C_2=0$. So, for $x<0$, we must have $C_2=0$.\n\nThis suggests we should consider the solution piecewise, or more elegantly, combine the decay conditions using the absolute value function, which is also consistent with the physical symmetry of the problem around the crack center at $x=0$. The solution that decays for both $x \\to \\infty$ and $x \\to -\\infty$ must have the form:\n$$\nd(x) = C \\exp\\left(-\\frac{|x|}{\\ell}\\right)\n$$\nNow, we apply the condition at the crack center, $d(0)=1$:\n$$\nd(0) = C \\exp\\left(-\\frac{|0|}{\\ell}\\right) = C \\exp(0) = C = 1\n$$\nThus, the equilibrium phase-field profile is:\n$$\nd(x) = \\exp\\left(-\\frac{|x|}{\\ell}\\right)\n$$\n\nNext, we verify that the total fracture surface energy $\\Psi[d]$ for this profile equals $G_c$. We substitute $d(x)$ and its derivative into the functional.\nThe derivative of $d(x)$ for $x \\neq 0$ is:\n$$\n\\frac{\\mathrm{d}d}{\\mathrm{d}x} = -\\frac{\\mathrm{sgn}(x)}{\\ell} \\exp\\left(-\\frac{|x|}{\\ell}\\right)\n$$\nwhere $\\mathrm{sgn}(x)$ is the sign function.\nThe square of the derivative is:\n$$\n\\left(\\frac{\\mathrm{d}d}{\\mathrm{d}x}\\right)^2 = \\frac{1}{\\ell^2} \\exp\\left(-\\frac{2|x|}{\\ell}\\right)\n$$\nThe square of the profile itself is:\n$$\nd(x)^2 = \\exp\\left(-\\frac{2|x|}{\\ell}\\right)\n$$\nNow, substitute these into the integral for $\\Psi[d]$:\n$$\n\\Psi[d] = \\int_{-\\infty}^{\\infty} G_c \\left( \\frac{\\exp(-2|x|/\\ell)}{2\\ell} + \\frac{\\ell}{2} \\left(\\frac{1}{\\ell^2} \\exp(-2|x|/\\ell)\\right) \\right)\\,\\mathrm{d}x\n$$\n$$\n\\Psi[d] = \\int_{-\\infty}^{\\infty} G_c \\left( \\frac{\\exp(-2|x|/\\ell)}{2\\ell} + \\frac{\\exp(-2|x|/\\ell)}{2\\ell} \\right)\\,\\mathrm{d}x\n$$\nThe two terms in the integrand are identical. This is a manifestation of the principle of equipartition of energy for this type of variational problem.\n$$\n\\Psi[d] = \\int_{-\\infty}^{\\infty} G_c \\frac{\\exp(-2|x|/\\ell)}{\\ell} \\,\\mathrm{d}x = \\frac{G_c}{\\ell} \\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{2|x|}{\\ell}\\right) \\,\\mathrm{d}x\n$$\nThe integrand is an even function, so we can write the integral as twice the integral from $0$ to $\\infty$:\n$$\n\\Psi[d] = \\frac{G_c}{\\ell} \\left( 2 \\int_{0}^{\\infty} \\exp\\left(-\\frac{2x}{\\ell}\\right) \\,\\mathrm{d}x \\right)\n$$\nWe now evaluate the definite integral:\n$$\n\\int_{0}^{\\infty} \\exp\\left(-\\frac{2x}{\\ell}\\right) \\,\\mathrm{d}x = \\left[ -\\frac{\\ell}{2} \\exp\\left(-\\frac{2x}{\\ell}\\right) \\right]_{0}^{\\infty}\n$$\n$$\n= \\left( \\lim_{x\\to\\infty} -\\frac{\\ell}{2} \\exp\\left(-\\frac{2x}{\\ell}\\right) \\right) - \\left( -\\frac{\\ell}{2} \\exp(0) \\right)\n$$\n$$\n= (0) - \\left(-\\frac{\\ell}{2}\\right) = \\frac{\\ell}{2}\n$$\nSubstituting this result back into the expression for $\\Psi[d]$:\n$$\n\\Psi[d] = \\frac{G_c}{\\ell} \\left( 2 \\cdot \\frac{\\ell}{2} \\right) = \\frac{G_c}{\\ell} (\\ell) = G_c\n$$\nThis analytically verifies that the total fracture surface energy per unit area for the regularized crack profile is indeed equal to the critical energy release rate $G_c$, as required by the theory.\n\nThe two parts of the final answer are the profile $d(x)$ and the energy value $\\Psi[d]$.\n1.  Profile: $d(x) = \\exp(-|x|/\\ell)$\n2.  Energy: $\\Psi = G_c$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\exp\\left(-\\frac{|x|}{\\ell}\\right) & G_c \\end{pmatrix}}\n$$", "id": "3550298"}, {"introduction": "While elegant, basic phase-field models can predict unphysical behavior if not carefully formulated. This exercise tackles a critical issue: the response of a cracked body under compression, where naive models can allow for the interpenetration of crack faces [@problem_id:3476034]. By analyzing a simple one-dimensional bar, you will compare a naive formulation with a contact-aware model based on a tension-compression energy split, quantitatively demonstrating why such a split is essential for robust and physically meaningful simulations.", "problem": "Consider a one-dimensional linear elastic bar under uniaxial compression, split into two serial segments representing a cracked interface in a phase-field fracture formulation. The left segment models the damaged zone with a phase-field variable $d \\in [0,1]$, and the right segment models intact material. Let the bar have uniform cross-sectional area $A$ and Young's modulus $E$ in both segments. The left and right segment lengths are $L_L$ and $L_R$, respectively. A total imposed end-shortening displacement $\\Delta < 0$ (compression) is applied to the bar, and the axial force is uniform in the series system.\n\nThe constitutive base is the small-strain, linear elastic strain energy density $W(\\varepsilon)$ for uniaxial strain $\\varepsilon$, together with a tension-compression split used in phase-field fracture:\n$$\nW(\\varepsilon) = \\tfrac{1}{2}E\\,\\varepsilon^2,\\quad\nW^+(\\varepsilon) = \\tfrac{1}{2}E\\,\\max(\\varepsilon,0)^2,\\quad\nW^-(\\varepsilon) = \\tfrac{1}{2}E\\,\\min(\\varepsilon,0)^2.\n$$\nA contact-aware formulation degrades only the tensile portion $W^+(\\varepsilon)$ via a degradation function $g(d)$ while leaving the compressive portion $W^-(\\varepsilon)$ undegraded to avoid interpenetration under compression. The degradation function includes a residual stiffness parameter $\\kappa > 0$:\n$$\ng(d) = (1-d)^2 + \\kappa.\n$$\nUnder compressive loading ($\\varepsilon<0$), the contact-aware formulation uses the undegraded compressive stiffness, whereas a naive formulation that degrades the total energy uses the degraded stiffness in both tension and compression.\n\nYour tasks are:\n- From the constitutive base above, derive the effective axial stiffness of each segment under compressive loading for the two formulations:\n    1. Naive total-energy degradation: the left segment stiffness uses $g(d)$ even in compression.\n    2. Contact-aware split: the left segment stiffness in compression is not degraded; compression is excluded from degradation via $W^-(\\varepsilon)$.\n- Using equilibrium and compatibility for two linear elastic springs in series, derive how the imposed displacement $\\Delta$ partitions into the left segment compression $\\delta_L$ and the right segment compression $\\delta_R$ for each formulation.\n- Define the interpenetration amplification factor as the ratio\n$$\n\\mathcal{A} := \\frac{\\lvert \\delta_L^{\\text{naive}} \\rvert}{\\lvert \\delta_L^{\\text{contact}} \\rvert},\n$$\nand evaluate whether the naive formulation leads to excessive interpenetration compared to the contact-aware formulation for the provided test suite.\n- Define a decision rule for interpenetration avoidance under compression using a dimensionless threshold ratio $\\tau$ comparing the naive left-segment compression to the intact (contact-aware) left-segment compression. Let the naive formulation be marked as interpenetration-prone when $\\mathcal{A} > \\tau$, and the contact-aware formulation be marked as avoiding interpenetration when $\\lvert \\delta_L^{\\text{contact}} \\rvert \\le \\tau \\,\\lvert \\delta_L^{\\text{intact}} \\rvert$, where $\\delta_L^{\\text{intact}}$ is the left-segment compression with undegraded stiffness in compression.\n\nAll physical quantities are to be expressed in the following units: $E$ in pascals (Pa), $A$ in square meters ($\\mathrm{m}^2$), lengths in meters ($\\mathrm{m}$), and imposed displacement $\\Delta$ in meters ($\\mathrm{m}$). The angle unit does not apply. Report the interpenetration amplification factor $\\mathcal{A}$ as a dimensionless float. Report interpenetration avoidance decisions as booleans.\n\nTest suite:\n- Case $1$: $E = 70\\times 10^{9}\\ \\mathrm{Pa}$, $A = 1\\times 10^{-4}\\ \\mathrm{m}^2$, $L_L = 5\\times 10^{-3}\\ \\mathrm{m}$, $L_R = 9.5\\times 10^{-2}\\ \\mathrm{m}$, $d = 0.999$, $\\kappa = 1\\times 10^{-6}$, $\\Delta = -1\\times 10^{-4}\\ \\mathrm{m}$.\n- Case $2$: $E = 70\\times 10^{9}\\ \\mathrm{Pa}$, $A = 1\\times 10^{-4}\\ \\mathrm{m}^2$, $L_L = 5\\times 10^{-3}\\ \\mathrm{m}$, $L_R = 9.5\\times 10^{-2}\\ \\mathrm{m}$, $d = 0.0$, $\\kappa = 1\\times 10^{-6}$, $\\Delta = -1\\times 10^{-4}\\ \\mathrm{m}$.\n- Case $3$: $E = 210\\times 10^{9}\\ \\mathrm{Pa}$, $A = 5\\times 10^{-5}\\ \\mathrm{m}^2$, $L_L = 1\\times 10^{-2}\\ \\mathrm{m}$, $L_R = 9\\times 10^{-2}\\ \\mathrm{m}$, $d = 0.9999$, $\\kappa = 1\\times 10^{-8}$, $\\Delta = -5\\times 10^{-5}\\ \\mathrm{m}$.\n- Case $4$: $E = 30\\times 10^{9}\\ \\mathrm{Pa}$, $A = 2\\times 10^{-4}\\ \\mathrm{m}^2$, $L_L = 2\\times 10^{-2}\\ \\mathrm{m}$, $L_R = 8\\times 10^{-2}\\ \\mathrm{m}$, $d = 0.995$, $\\kappa = 1\\times 10^{-5}$, $\\Delta = -1\\times 10^{-6}\\ \\mathrm{m}$.\n\nUse a threshold $\\tau = 4.0$ (dimensionless). For each case, compute:\n- The interpenetration amplification factor $\\mathcal{A}$ (float).\n- A boolean for naive formulation interpenetration-prone decision.\n- A boolean for contact-aware formulation interpenetration avoidance decision.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, ordered as\n$$\n[\\mathcal{A}_1, b^{\\text{naive}}_1, b^{\\text{contact}}_1, \\ \\mathcal{A}_2, b^{\\text{naive}}_2, b^{\\text{contact}}_2, \\ \\mathcal{A}_3, b^{\\text{naive}}_3, b^{\\text{contact}}_3, \\ \\mathcal{A}_4, b^{\\text{naive}}_4, b^{\\text{contact}}_4].\n$$\nEach $\\mathcal{A}_i$ must be a float and each $b^{\\text{naive}}_i$, $b^{\\text{contact}}_i$ must be booleans.", "solution": "The problem requires a validation of two different phase-field fracture formulations under uniaxial compression by analyzing the displacement partitioning in a simplified one-dimensional bar model. The bar consists of two segments in series: a left segment of length $L_L$ representing a potential crack zone described by a phase-field variable $d$, and an intact right segment of length $L_R$. Both segments have the same Young's modulus $E$ and cross-sectional area $A$. A total compressive displacement $\\Delta < 0$ is applied.\n\nOur analysis will proceed by first establishing the constitutive laws and corresponding axial stiffness for each segment under the specified loading conditions. We will then use the principles of static equilibrium and kinematic compatibility for a series system to determine how the total displacement $\\Delta$ is partitioned. Finally, we will derive and evaluate the requested metrics: the interpenetration amplification factor $\\mathcal{A}$ and the boolean decisions for interpenetration proneness.\n\n### 1. Constitutive Relations and Axial Stiffness\n\nThe axial stiffness $k$ of a linear elastic bar of length $L$, area $A$, and effective Young's modulus $E'$ is given by $k = E'A/L$. The effective modulus $E'$ is determined from the second derivative of the strain energy density $W$ with respect to strain $\\varepsilon$, i.e., $E' = \\partial^2 W / \\partial \\varepsilon^2$.\n\nThe problem is set under uniaxial compression, which implies the axial strain $\\varepsilon$ is negative ($\\varepsilon < 0$). This is a critical observation for evaluating the energy expressions.\n\n**Intact Material (Right Segment):**\nFor the intact right segment, the strain energy density is $W(\\varepsilon) = \\frac{1}{2}E\\varepsilon^2$.\nThe effective modulus is $E' = E$.\nThe stiffness of the right segment is therefore constant:\n$$\nk_R = \\frac{EA}{L_R}\n$$\n\n**Damaged Material (Left Segment):**\nWe consider two formulations for the left segment.\n\n**a. Contact-Aware Formulation:**\nThe strain energy density is $W_{\\text{contact}}(\\varepsilon) = g(d)W^+(\\varepsilon) + W^-(\\varepsilon)$, where $W^+(\\varepsilon) = \\frac{1}{2}E\\max(\\varepsilon,0)^2$ and $W^-(\\varepsilon) = \\frac{1}{2}E\\min(\\varepsilon,0)^2$. The degradation function is $g(d) = (1-d)^2 + \\kappa$.\nUnder compression, $\\varepsilon < 0$, which means $\\max(\\varepsilon,0)=0$ and $\\min(\\varepsilon,0)=\\varepsilon$.\nThe energy contributions are $W^+(\\varepsilon) = 0$ and $W^-(\\varepsilon) = \\frac{1}{2}E\\varepsilon^2$.\nThus, for compressive loading, the strain energy density becomes:\n$$\nW_{\\text{contact}}(\\varepsilon < 0) = g(d) \\cdot 0 + \\frac{1}{2}E\\varepsilon^2 = \\frac{1}{2}E\\varepsilon^2\n$$\nThis is identical to the undegraded strain energy. The effective modulus is $E'_{\\text{contact}} = \\partial^2 W_{\\text{contact}} / \\partial \\varepsilon^2 = E$.\nThe stiffness of the left segment in the contact-aware formulation under compression is:\n$$\nk_L^{\\text{contact}} = \\frac{EA}{L_L}\n$$\nThis stiffness is that of an intact material, correctly representing that a closed crack should transmit compressive stress without loss of stiffness. This is also the stiffness we would associate with the term \"intact\" in compression, so $k_L^{\\text{contact}} = k_L^{\\text{intact}}$.\n\n**b. Naive Formulation:**\nThis formulation degrades the total strain energy: $W_{\\text{naive}}(\\varepsilon) = g(d)W(\\varepsilon) = g(d)\\frac{1}{2}E\\varepsilon^2$.\nThe degradation applies regardless of the sign of the strain.\nThe effective modulus is $E'_{\\text{naive}} = \\partial^2 W_{\\text{naive}} / \\partial \\varepsilon^2 = g(d)E$.\nThe stiffness of the left segment in the naive formulation is:\n$$\nk_L^{\\text{naive}} = \\frac{g(d)EA}{L_L} = \\frac{((1-d)^2 + \\kappa)EA}{L_L}\n$$\nFor a highly damaged state where $d \\to 1$, $g(d) \\to \\kappa$. Since $\\kappa$ is a small parameter, the naive stiffness becomes extremely low even in compression, which is physically incorrect as it implies material interpenetration.\n\n### 2. Displacement Partitioning in a Series System\n\nFor two springs with stiffnesses $k_L$ and $k_R$ connected in series, the total stiffness is $k_{\\text{tot}} = (1/k_L + 1/k_R)^{-1}$. The force $F$ is uniform throughout the system, $F = k_{\\text{tot}}\\Delta$, and the individual displacements are $\\delta_L = F/k_L$ and $\\delta_R = F/k_R$.\n\nThe displacement of the left segment, $\\delta_L$, can be expressed as a fraction of the total displacement $\\Delta$. From the compatibility condition $\\Delta = \\delta_L + \\delta_R = \\delta_L + F/k_R = \\delta_L + (k_L\\delta_L)/k_R = \\delta_L(1 + k_L/k_R)$, we derive:\n$$\n\\delta_L = \\Delta \\left( \\frac{1}{1 + k_L/k_R} \\right) = \\Delta \\left( \\frac{k_R}{k_R + k_L} \\right)\n$$\nWe now apply this general result to our two formulations.\n\n**a. Contact-Aware Displacement Partition:**\nUsing $k_L = k_L^{\\text{contact}} = EA/L_L$ and $k_R = EA/L_R$:\n$$\n\\delta_L^{\\text{contact}} = \\Delta \\left( \\frac{EA/L_R}{EA/L_R + EA/L_L} \\right) = \\Delta \\left( \\frac{1/L_R}{1/L_R + 1/L_L} \\right) = \\Delta \\frac{L_L}{L_L + L_R}\n$$\n\n**b. Naive Displacement Partition:**\nUsing $k_L = k_L^{\\text{naive}} = g(d)EA/L_L$ and $k_R = EA/L_R$:\n$$\n\\delta_L^{\\text{naive}} = \\Delta \\left( \\frac{EA/L_R}{EA/L_R + g(d)EA/L_L} \\right) = \\Delta \\left( \\frac{1/L_R}{1/L_R + g(d)/L_L} \\right) = \\Delta \\frac{L_L}{L_L + g(d)L_R}\n$$\n\n### 3. Interpenetration Amplification Factor and Decision Rules\n\nThe interpenetration amplification factor $\\mathcal{A}$ measures the excess compression in the damaged zone predicted by the naive model compared to the physically correct contact-aware model.\n$$\n\\mathcal{A} := \\frac{\\lvert \\delta_L^{\\text{naive}} \\rvert}{\\lvert \\delta_L^{\\text{contact}} \\rvert} = \\frac{-\\delta_L^{\\text{naive}}}{-\\delta_L^{\\text{contact}}} = \\frac{\\Delta \\frac{L_L}{L_L + g(d)L_R}}{\\Delta \\frac{L_L}{L_L + L_R}}\n$$\nThe terms $\\Delta$ and $L_L$ cancel, yielding a simplified expression that notably does not depend on $E$, $A$, or $\\Delta$:\n$$\n\\mathcal{A} = \\frac{L_L + L_R}{L_L + g(d)L_R} \\quad \\text{where} \\quad g(d) = (1-d)^2 + \\kappa\n$$\nThis is the expression we will evaluate for each test case.\n\nThe decision rules are as follows, with threshold $\\tau = 4.0$:\n1.  **Naive formulation interpenetration-prone decision ($b^{\\text{naive}}$):** This is true if $\\mathcal{A} > \\tau$.\n2.  **Contact-aware formulation interpenetration avoidance decision ($b^{\\text{contact}}$):** This is true if $\\lvert \\delta_L^{\\text{contact}} \\rvert \\le \\tau \\,\\lvert \\delta_L^{\\text{intact}} \\rvert$. As established, under compression, the contact-aware formulation is identical to the intact one, hence $\\delta_L^{\\text{contact}} = \\delta_L^{\\text{intact}}$. The condition simplifies to $\\lvert \\delta_L^{\\text{intact}} \\rvert \\le \\tau \\,\\lvert \\delta_L^{\\text{intact}} \\rvert$. Since the bar undergoes non-zero compression, $\\lvert \\delta_L^{\\text{intact}} \\rvert > 0$, and we can divide by it to obtain $1 \\le \\tau$. Given $\\tau=4.0$, this condition is always satisfied. Therefore, for all test cases, $b^{\\text{contact}}$ will be true.\n\nThe calculation for each test case involves computing $g(d)$, then $\\mathcal{A}$, and finally applying the decision rule for $b^{\\text{naive}}$. The value of $b^{\\text{contact}}$ is invariably true.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the phase-field fracture interpenetration problem for the given test suite.\n    \"\"\"\n    \n    # Test suite parameters provided in the problem statement.\n    # Each case is a dictionary for clarity.\n    test_cases = [\n        # Case 1\n        {\"E\": 70e9, \"A\": 1e-4, \"L_L\": 5e-3, \"L_R\": 9.5e-2, \"d\": 0.999, \"kappa\": 1e-6, \"Delta\": -1e-4},\n        # Case 2\n        {\"E\": 70e9, \"A\": 1e-4, \"L_L\": 5e-3, \"L_R\": 9.5e-2, \"d\": 0.0, \"kappa\": 1e-6, \"Delta\": -1e-4},\n        # Case 3\n        {\"E\": 210e9, \"A\": 5e-5, \"L_L\": 1e-2, \"L_R\": 9e-2, \"d\": 0.9999, \"kappa\": 1e-8, \"Delta\": -5e-5},\n        # Case 4\n        {\"E\": 30e9, \"A\": 2e-4, \"L_L\": 2e-2, \"L_R\": 8e-2, \"d\": 0.995, \"kappa\": 1e-5, \"Delta\": -1e-6},\n    ]\n\n    # Interpenetration threshold\n    tau = 4.0\n\n    results = []\n\n    for case in test_cases:\n        # Extract relevant parameters for the calculation.\n        # Note that E, A, and Delta are not needed for the amplification factor A\n        # and the boolean decisions as they cancel out in the derivation.\n        L_L = case[\"L_L\"]\n        L_R = case[\"L_R\"]\n        d_val = case[\"d\"]\n        kappa = case[\"kappa\"]\n\n        # 1. Calculate the degradation function g(d)\n        g_d = (1.0 - d_val)**2 + kappa\n\n        # 2. Calculate the interpenetration amplification factor, A\n        # A = (L_L + L_R) / (L_L + g(d) * L_R)\n        amplification_factor = (L_L + L_R) / (L_L + g_d * L_R)\n\n        # 3. Apply the decision rules\n        # a. Naive formulation: interpenetration-prone if A > tau\n        b_naive = amplification_factor > tau\n\n        # b. Contact-aware formulation: avoids interpenetration if |delta_L_contact| = tau * |delta_L_intact|\n        # As derived in the solution, delta_L_contact = delta_L_intact for compression.\n        # The condition simplifies to 1 = tau, which is True since tau = 4.0.\n        b_contact = 1.0 = tau\n        \n        # Append the triplet of results for the current case\n        results.extend([amplification_factor, b_naive, b_contact])\n\n    # Format the final output string as a comma-separated list of values inside square brackets.\n    # str() of a boolean yields 'True' or 'False' with capital letters, which is standard.\n    results_str = [f\"{val:.12f}\" if isinstance(val, float) else str(val).lower() for val in results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "3476034"}, {"introduction": "The power of phase-field models is realized through numerical simulation, but their multiscale nature poses a significant computational challenge. This advanced practice delves into adaptive meshing, a crucial technique for efficiently resolving the sharp gradients at the crack tip without prohibitive computational cost [@problem_id:3476039]. You will implement and compare two powerful adaptive strategies, $h$-refinement and $hp$-refinement, driven by an error indicator to see firsthand how they optimize computational resources to accurately capture the crack profile.", "problem": "You are to implement and compare two adaptive strategies for resolving a one-dimensional proxy of a phase-field crack-tip profile using a polynomial Finite Element Method (FEM). The phase-field variable is denoted by $\\,d(x;\\ell)\\,$ and represents a smooth damage field that transitions between fully broken ($\\,d=1\\,$) and intact ($\\,d=0\\,$) material over a length scale $\\,\\ell0\\,$. The aim is to quantify how the number of degrees of freedom scales with the regularization length $\\,\\ell\\,$ under $\\,h\\,$-refinement (mesh subdivision at fixed polynomial degree) and $\\,hp\\,$-refinement (combined mesh subdivision and polynomial enrichment).\n\nThe modeling base must start from fundamental principles in phase-field fracture modeling. In an isotropic regularized brittle fracture model, the fracture energy density is often written as a sum of a gradient penalty and a local crack density term, such as\n$$\n\\Psi_{\\mathrm{frac}}(d,\\nabla d) \\;=\\; G_c\\left(\\frac{\\ell}{2}\\,|\\nabla d|^2 \\;+\\; \\frac{1}{4\\ell}\\,w(d)\\right),\n$$\nwhere $\\,G_c\\,$ is the critical energy release rate (a material constant), $\\,\\ell\\,$ is the regularization length, and $\\,w(d)\\,$ is a double-well crack density function. The Euler–Lagrange equation for the damage field $\\,d\\,$ derived from minimizing a suitable total potential energy contains a diffusion-like operator $\\,\\ell^2\\Delta d\\,$ that sets a characteristic width of the damage transition zone proportional to $\\,\\ell\\,$. In one spatial dimension, this implies that the crack tip transition layer has a thickness of order $\\,\\mathcal{O}(\\ell)\\,$, and typical gradients scale like $\\,\\mathcal{O}(1/\\ell)\\,$ through the tip region.\n\nTo decouple mechanical coupling from mesh resolution logic and to enforce an analytically controlled ground truth, approximate the crack-tip phase-field by the analytic, smooth proxy\n$$\nd(x;\\ell)\\;=\\;1 - \\exp\\left(-\\frac{|x|}{\\ell}\\right),\n$$\non the domain $\\,\\Omega = [-1,1]\\,$. This proxy respects the expected boundary-layer behavior and gradient scaling near $\\,x=0\\,$ in a regularized crack-tip transition.\n\nDefine the element-wise error indicator\n$$\n\\eta_K \\;\\equiv\\; \\left(\\int_K \\bigl|\\nabla d(x;\\ell)\\bigr|^2\\,dx\\right)^{1/2},\n$$\nand use it to drive adaptive refinement. You must implement two strategies:\n\n- $\\,h\\,$-strategy: refine by bisecting marked elements; keep the polynomial degree fixed at $\\,p=1\\,$.\n- $\\,hp\\,$-strategy: on marked elements, decide between $\\,h\\,$-refinement or $\\,p\\,$-enrichment using the rule below.\n\nYour FEM surrogate is a piecewise polynomial interpolant of degree $\\,p_K\\,$ on each element $\\,K\\,$, constructed by interpolating $\\,d(x;\\ell)\\,$ at the Chebyshev–Lobatto nodes on each element. For quadrature, use Gauss–Legendre with $\\,n_q=\\max(8,2p_K+4)\\,$ points per element. For $\\,hp\\,$-adaptivity, use the following deterministic policy with maximum degree $\\,p_{\\max}=8\\,$:\n- On each marked element $\\,K\\,$ with length $\\,h_K\\,$ and current degree $\\,p_K\\,$, compute the under-resolution indicator\n$$\nr_K \\;=\\; \\frac{h_K\\,p_K}{c_{\\mathrm{res}}\\,\\ell}, \\quad \\text{with } c_{\\mathrm{res}} = 0.5.\n$$\nIf $\\,r_K  1\\,$, perform $\\,h\\,$-refinement (bisect $\\,K\\,$, keep $\\,p_K\\,$ on the children). Otherwise, if $\\,p_K  p_{\\max}\\,$, perform $\\,p\\,$-refinement by setting $\\,p_K \\leftarrow p_K + 1\\,$; if $\\,p_K = p_{\\max}\\,$ and $\\,r_K \\le 1\\,$, perform $\\,h\\,$-refinement.\n\nUse Dörfler marking with parameter $\\,\\theta=0.5\\,$ on the set of squared indicators $\\,\\{\\eta_K^2\\}\\,$ each iteration: pick a minimal subset of elements whose squared indicators sum to at least a fraction $\\,\\theta\\,$ of the total squared indicator.\n\nMeasure crack-tip resolution by the relative $\\,L^2\\,$-error restricted to the window $\\,\\omega_\\ell = \\{ x\\in\\Omega : |x|\\le 3\\ell \\}\\,$:\n$$\nE_{\\mathrm{tip}}(\\ell) \\;=\\; \\frac{\\left(\\int_{\\omega_\\ell} \\left(d(x;\\ell) - \\Pi_h d(x;\\ell)\\right)^2 dx\\right)^{1/2}}{\\left(\\int_{\\omega_\\ell} d(x;\\ell)^2 dx\\right)^{1/2}},\n$$\nwhere $\\,\\Pi_h d\\,$ denotes the piecewise polynomial interpolant defined above.\n\nInitialize the mesh as $\\,8\\,$ uniform elements on $\\,[-1,1]\\,$ with $\\,p=1\\,$. On each refinement iteration, apply Dörfler marking, then refine according to the strategy. Stop when either $\\,E_{\\mathrm{tip}}(\\ell) \\le 2\\times 10^{-3}\\,$ or after $\\,12\\,$ refinement iterations, whichever occurs first. Count the global number of degrees of freedom as $\\,\\mathrm{DoF}=1+\\sum_K p_K\\,$ (for $\\,C^0\\,$ continuity in one dimension). Define computational cost by the resulting $\\,\\mathrm{DoF}\\,$ required to meet the stopping criterion.\n\nYour program must do the following:\n\n- Implement the above adaptive interpolation-based surrogate FEM, the element-wise indicator $\\,\\eta_K\\,$, Dörfler marking with $\\,\\theta=0.5\\,$, and the refinement policies for both $\\,h\\,$ and $\\,hp\\,$ strategies.\n- For each given $\\,\\ell\\,$, run both strategies starting from the same initial mesh. Record the final $\\,\\mathrm{DoF}\\,$ when the stopping criterion is satisfied (or at iteration cap).\n- The analytic reference is $\\,d(x;\\ell) = 1 - \\exp(-|x|/\\ell)\\,$. Use $\\,d'(x;\\ell) = \\frac{1}{\\ell}\\exp(-|x|/\\ell)\\,\\mathrm{sign}(x)\\,$ wherever needed for computing $\\,\\eta_K\\,$. Note that $\\,d'\\,$ is undefined at $\\,x=0\\,$, but this does not affect the integrals.\n\nTest Suite:\n- Use the following set of $\\,\\ell\\,$ values: $\\,\\ell\\in\\{0.2,\\,0.05,\\,0.01\\}\\,$.\n- For each $\\,\\ell\\,$, run both strategies and output the final $\\,\\mathrm{DoF}\\,$ as integers.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets.\n- The list must contain the $\\,\\mathrm{DoF}\\,$ for the $\\,h\\,$-strategy followed by the $\\,\\mathrm{DoF}\\,$ for the $\\,hp\\,$-strategy for each $\\,\\ell\\,$ in the given order. Concretely, the output format is\n$$\n[\\mathrm{DoF}_h(\\ell{=}0.2),\\mathrm{DoF}_{hp}(\\ell{=}0.2),\\mathrm{DoF}_h(\\ell{=}0.05),\\mathrm{DoF}_{hp}(\\ell{=}0.05),\\mathrm{DoF}_h(\\ell{=}0.01),\\mathrm{DoF}_{hp}(\\ell{=}0.01)].\n$$\n\nAll quantities here are dimensionless, so no physical unit conversion is required. Ensure numerical integration is sufficiently accurate as specified. Avoid any external input. The program must be deterministic and reproducible.", "solution": "The problem requires the implementation and comparison of two adaptive finite element strategies, $h$-refinement and $hp$-refinement, for resolving a one-dimensional proxy of a phase-field crack-tip profile. The solution involves developing a complete adaptive loop based on an interpolation-based error analysis. The core components of the solution are the mathematical model, the finite element discretization, the adaptive refinement algorithm, and the final implementation.\n\n### 1. Mathematical and Discretization Principles\n\nThe foundation of the problem is the one-dimensional proxy for the phase-field crack profile, given by the function:\n$$\nd(x;\\ell) = 1 - \\exp\\left(-\\frac{|x|}{\\ell}\\right) \\quad \\text{on} \\quad \\Omega = [-1, 1]\n$$\nThis function models a smooth transition from a broken state ($d \\approx 1$) to an intact state ($d=0$) over a characteristic length scale $\\ell$. The sharpness of this transition is governed by the gradient, $\\nabla d$. The squared magnitude of the gradient, used to drive adaptivity, is:\n$$\n|\\nabla d(x;\\ell)|^2 = \\left|\\frac{1}{\\ell}e^{-|x|/\\ell}\\,\\mathrm{sign}(x)\\right|^2 = \\frac{1}{\\ell^2} e^{-2|x|/\\ell}\n$$\nThis function is continuous and sharply peaked at $x=0$, indicating that mesh resolution must be finest around this point, especially for small $\\ell$.\n\nThe continuous function $d(x;\\ell)$ is approximated by a piecewise polynomial interpolant, $\\Pi_h d$. On each element $K = [x_{\\min}, x_{\\max}]$ of the mesh, $\\Pi_h d$ is a polynomial of degree $p_K$. This polynomial is constructed by interpolating the exact function $d(x;\\ell)$ at $p_K+1$ specific points within the element, known as the Chebyshev-Lobatto nodes. These nodes are the extrema of the Chebyshev polynomial of degree $p_K$ and are known to yield excellent approximation properties, forming the basis of so-called spectral element methods. The resulting global approximation $\\Pi_h d$ is continuous ($C^0$) across element boundaries. In one dimension, the total number of degrees of freedom (DoF) for such a discretization is correctly given by $\\mathrm{DoF} = 1 + \\sum_K p_K$.\n\n### 2. Numerical Integration\n\nAll integrals required for the error indicator and the stopping criterion are computed using numerical quadrature. The problem specifies Gauss-Legendre quadrature with a high number of points, $n_q = \\max(8, 2p_K+4)$, for each element $K$. A Gauss-Legendre rule with $n_q$ points integrates polynomials of degree up to $2n_q-1$ exactly. Since our integrands are not polynomials (e.g., they involve exponential terms), a high-order rule is necessary to ensure that the quadrature error is negligible compared to the discretization error we aim to measure. The quadrature points and weights, defined on the reference interval $[-1, 1]$, are mapped to each physical element $K$.\n\n### 3. Adaptive Refinement Algorithm\n\nThe core of the solution is the adaptive loop, which iteratively refines the mesh to reduce the approximation error. This process consists of a sequence of `SOLVE - ESTIMATE - MARK - REFINE`.\n\n**Error Indicator ($\\eta_K$):** The refinement process is driven by the element-wise error indicator:\n$$\n\\eta_K = \\left(\\int_K |\\nabla d(x;\\ell)|^2\\,dx\\right)^{1/2}\n$$\nThis indicator effectively measures the \"activity\" or \"energy\" of the gradient within element $K$. A large value of $\\eta_K$ suggests that the function $d$ changes rapidly within $K$, and therefore the element is a candidate for refinement.\n\n**Dörfler Marking:** Once $\\eta_K$ is computed for all elements, a subset of elements is marked for refinement. We use Dörfler marking with parameter $\\theta=0.5$. This strategy consists of sorting the elements in descending order of their squared indicators, $\\eta_K^2$, and selecting the minimal set of elements $\\mathcal{M}$ such that the sum of their indicators meets a certain fraction of the total:\n$$\n\\sum_{K \\in \\mathcal{M}} \\eta_K^2 \\geq \\theta \\sum_{\\text{all } K} \\eta_K^2\n$$\nThis ensures that a fixed portion of the total estimated error is targeted for reduction in each refinement step.\n\n**Refinement Strategies:**\nTwo strategies are implemented for the marked elements:\n\n1.  **$h$-strategy:** The polynomial degree is held constant at $p=1$. Each marked element is bisected into two children of equal size, which inherit the same polynomial degree. This strategy increases resolution by reducing the element size $h_K$.\n\n2.  **$hp$-strategy:** This is a more sophisticated strategy that decides between reducing element size ($h$-refinement) or increasing polynomial degree ($p$-refinement). The decision for a marked element $K$ is based on the under-resolution indicator:\n    $$\n    r_K = \\frac{h_K p_K}{c_{\\mathrm{res}}\\,\\ell}\n    $$\n    where $c_{\\mathrm{res}}=0.5$. This indicator compares the effective resolution of the element, $h_K/p_K$, to the physical length scale $\\ell$.\n    - If $r_K  1$, the element is too large to resolve the feature scale $\\ell$; thus, an $h$-refinement is performed (bisection).\n    - If $r_K \\leq 1$, the element size is adequate. The approximation can be improved more efficiently by increasing the polynomial degree, so a $p$-refinement is performed ($p_K \\to p_K+1$), provided the degree does not exceed a prescribed maximum, $p_{\\max}=8$. If $p_K$ is already at its maximum, an $h$-refinement is performed as a fallback.\n\n### 4. Stopping Criterion and Cost Measurement\n\nThe adaptive loop terminates when the approximation is deemed sufficiently accurate or a maximum number of iterations is reached. Accuracy is measured by the relative $L^2$-error, $E_{\\mathrm{tip}}$, restricted to the \"crack-tip\" window $\\omega_\\ell = \\{x : |x| \\le 3\\ell\\}$:\n$$\nE_{\\mathrm{tip}}(\\ell) = \\frac{\\|d - \\Pi_h d\\|_{L^2(\\omega_\\ell)}}{\\|d\\|_{L^2(\\omega_\\ell)}}\n$$\nThe loop stops if $E_{\\mathrm{tip}}(\\ell) \\le 2\\times 10^{-3}$ or after $12$ iterations. The computational cost is defined as the total number of degrees of freedom, $\\mathrm{DoF}$, in the final mesh. This provides a basis for comparing the efficiency of the $h$- and $hp$-strategies.\n\n### 5. Algorithmic Implementation\n\nThe algorithm is implemented in Python using the `numpy` and `scipy` libraries.\n- An `Element` class stores the properties of each element: its spatial interval $[x_{\\min}, x_{\\max}]$ and its polynomial degree $p$.\n- An `AdaptiveFEMSimulator` class orchestrates the entire process. It manages the mesh (a list of `Element` objects), computes error indicators and tip error, and applies the marking and refinement logic according to the selected strategy (`h` or `hp`).\n- For efficient evaluation of the polynomial interpolant $\\Pi_h d$, `scipy.interpolate.BarycentricInterpolator` is used. This is significantly faster than a naive implementation of the Lagrange formula, especially within the nested quadrature loops.\n- Helper functions are used for standard tasks like generating quadrature rules (`numpy.polynomial.legendre.leggauss`) and interpolation nodes (`numpy.polynomial.chebyshev.chebpts2`).\n- The main `solve` function iterates through the prescribed $\\ell$ values, runs both adaptive strategies for each, collects the resulting DoF counts, and formats the final output.\n\nThis structured approach ensures a correct and verifiable implementation of the specified adaptive finite element procedure.", "answer": "```python\nimport numpy as np\nfrom scipy.interpolate import BarycentricInterpolator\n\n# GLOBAL PARAMETERS (from problem statement)\nP_MAX = 8\nC_RES = 0.5\nTHETA = 0.5\nTOLERANCE = 2e-3\nMAX_ITERATIONS = 12\n\ndef d_field(x, ell):\n    \"\"\"Analytic proxy function for the phase-field.\"\"\"\n    return 1.0 - np.exp(-np.abs(x) / ell)\n\ndef d_d_field_sq(x, ell):\n    \"\"\"Squared magnitude of the gradient of the phase-field proxy.\"\"\"\n    return (1.0 / ell**2) * np.exp(-2.0 * np.abs(x) / ell)\n\nclass Element:\n    \"\"\"Represents a 1D finite element.\"\"\"\n    def __init__(self, x_min, x_max, p):\n        self.x_min = float(x_min)\n        self.x_max = float(x_max)\n        self.h = self.x_max - self.x_min\n        self.p = int(p)\n\nclass AdaptiveFEMSimulator:\n    \"\"\"Manages the adaptive simulation for a given strategy.\"\"\"\n\n    def __init__(self, ell, strategy):\n        if strategy not in ['h', 'hp']:\n            raise ValueError(\"Strategy must be 'h' or 'hp'\")\n        self.ell = ell\n        self.strategy = strategy\n        self.mesh = self._create_initial_mesh()\n\n    def _create_initial_mesh(self):\n        \"\"\"Creates the initial uniform mesh of 8 elements with p=1.\"\"\"\n        nodes = np.linspace(-1.0, 1.0, 9)\n        return [Element(nodes[i], nodes[i+1], 1) for i in range(8)]\n\n    def _get_quadrature(self, n_q, x_min, x_max):\n        \"\"\"Returns Gauss-Legendre quadrature points and weights on [x_min, x_max].\"\"\"\n        ref_pts, ref_wts = np.polynomial.legendre.leggauss(n_q)\n        h = x_max - x_min\n        pts = x_min + (ref_pts + 1.0) * 0.5 * h\n        wts = ref_wts * 0.5 * h\n        return pts, wts\n\n    def _get_chebyshev_lobatto_nodes(self, p, x_min, x_max):\n        \"\"\"Returns Chebyshev-Lobatto nodes on [x_min, x_max].\"\"\"\n        # chebpts2(p+1) gives p+1 nodes on [-1, 1] including endpoints.\n        ref_nodes = np.polynomial.chebyshev.chebpts2(p + 1)\n        h = x_max - x_min\n        return x_min + (ref_nodes + 1.0) * 0.5 * h\n\n    def calculate_tip_error(self):\n        \"\"\"Calculates the relative L2 error in the tip window.\"\"\"\n        tip_window_min = max(-1.0, -3.0 * self.ell)\n        tip_window_max = min(1.0, 3.0 * self.ell)\n\n        numerator_sq = 0.0\n        denominator_sq = 0.0\n\n        for element in self.mesh:\n            intersect_min = max(element.x_min, tip_window_min)\n            intersect_max = min(element.x_max, tip_window_max)\n\n            if intersect_min  intersect_max:\n                n_q = max(8, 2 * element.p + 4)\n                quad_pts, quad_wts = self._get_quadrature(n_q, intersect_min, intersect_max)\n\n                interp_nodes = self._get_chebyshev_lobatto_nodes(element.p, element.x_min, element.x_max)\n                d_at_nodes = d_field(interp_nodes, self.ell)\n                interpolator = BarycentricInterpolator(interp_nodes, d_at_nodes)\n\n                d_exact_vals = d_field(quad_pts, self.ell)\n                d_interp_vals = interpolator(quad_pts)\n                \n                numerator_sq += np.sum((d_exact_vals - d_interp_vals)**2 * quad_wts)\n                denominator_sq += np.sum(d_exact_vals**2 * quad_wts)\n        \n        return np.sqrt(numerator_sq / denominator_sq) if denominator_sq > 0 else 0.0\n\n    def calculate_indicators(self):\n        \"\"\"Calculates the error indicator eta_K for each element.\"\"\"\n        indicators = np.zeros(len(self.mesh))\n        for i, element in enumerate(self.mesh):\n            n_q = max(8, 2 * element.p + 4)\n            quad_pts, quad_wts = self._get_quadrature(n_q, element.x_min, element.x_max)\n            integrand_vals = d_d_field_sq(quad_pts, self.ell)\n            integral = np.sum(integrand_vals * quad_wts)\n            indicators[i] = np.sqrt(integral)\n        return indicators\n\n    def mark_elements(self, indicators):\n        \"\"\"Performs Dörfler marking.\"\"\"\n        indicators_sq = indicators**2\n        total_indicator_sq = np.sum(indicators_sq)\n        \n        if total_indicator_sq == 0:\n            return []\n            \n        sorted_indices = np.argsort(indicators_sq)[::-1]\n        \n        marked_indices = []\n        current_sum = 0.0\n        theta_sum = THETA * total_indicator_sq\n        \n        for idx in sorted_indices:\n            current_sum += indicators_sq[idx]\n            marked_indices.append(idx)\n            if current_sum >= theta_sum:\n                break\n        return marked_indices\n\n    def refine_mesh(self, marked_indices):\n        \"\"\"Creates a new mesh by refining marked elements.\"\"\"\n        new_mesh = []\n        marked_indices_set = set(marked_indices)\n        for i, element in enumerate(self.mesh):\n            if i not in marked_indices_set:\n                new_mesh.append(element)\n                continue\n\n            if self.strategy == 'h':\n                mid_point = (element.x_min + element.x_max) / 2.0\n                new_mesh.append(Element(element.x_min, mid_point, element.p))\n                new_mesh.append(Element(mid_point, element.x_max, element.p))\n            elif self.strategy == 'hp':\n                r_k = (element.h * element.p) / (C_RES * self.ell)\n                \n                perform_h_refinement = False\n                if r_k > 1.0:\n                    perform_h_refinement = True\n                else: \n                    if element.p  P_MAX:\n                        new_mesh.append(Element(element.x_min, element.x_max, element.p + 1))\n                    else:\n                        perform_h_refinement = True\n                \n                if perform_h_refinement:\n                    mid_point = (element.x_min + element.x_max) / 2.0\n                    new_mesh.append(Element(element.x_min, mid_point, element.p))\n                    new_mesh.append(Element(mid_point, element.x_max, element.p))\n        self.mesh = sorted(new_mesh, key=lambda el: el.x_min)\n\n    def get_dof(self):\n        \"\"\"Calculates the total number of degrees of freedom.\"\"\"\n        return 1 + sum(el.p for el in self.mesh)\n\n    def run_adaptive_loop(self):\n        \"\"\"Executes the main adaptive refinement loop.\"\"\"\n        for _ in range(MAX_ITERATIONS):\n            error = self.calculate_tip_error()\n            if error = TOLERANCE:\n                break\n            \n            indicators = self.calculate_indicators()\n            marked_indices = self.mark_elements(indicators)\n            \n            if not marked_indices:\n                break\n\n            self.refine_mesh(marked_indices)\n            \n        return self.get_dof()\n\ndef solve():\n    \"\"\"Main function to run the test suite and print results.\"\"\"\n    test_cases = [0.2, 0.05, 0.01]\n    results = []\n\n    for ell_val in test_cases:\n        # H-strategy\n        simulator_h = AdaptiveFEMSimulator(ell=ell_val, strategy='h')\n        dof_h = simulator_h.run_adaptive_loop()\n        results.append(dof_h)\n\n        # HP-strategy\n        simulator_hp = AdaptiveFEMSimulator(ell=ell_val, strategy='hp')\n        dof_hp = simulator_hp.run_adaptive_loop()\n        results.append(dof_hp)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3476039"}]}