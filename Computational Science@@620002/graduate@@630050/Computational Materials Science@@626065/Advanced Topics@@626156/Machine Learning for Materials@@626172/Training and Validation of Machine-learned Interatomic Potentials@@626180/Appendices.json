{"hands_on_practices": [{"introduction": "A cornerstone of physics is that the laws of nature are the same everywhere and in every direction. This translates to a requirement that the potential energy of an isolated system of atoms must be invariant under rigid rotations and translations, transformations that form the Euclidean group $E(3)$. This exercise [@problem_id:3498502] guides you through constructing a test to verify this fundamental symmetry, ensuring that a potential's predicted energy does not change when the system is moved or reoriented, and that its forces transform consistently.", "problem": "Construct a synthetic dataset to probe equivariance and invariance properties relevant to training and validation of machine-learned interatomic potentials. The goal is to verify that for an isotropic, differentiable, pairwise potential, the total energy is invariant under rotations and translations in the Euclidean group in three dimensions (E(3)), and forces are equivariant under the Special Orthogonal group in three dimensions (SO(3)), i.e., they rotate consistently with the configuration. Begin from the following fundamental base: a rigid motion is defined by a rotation matrix $R \\in SO(3)$ satisfying $R^{\\top} R = I$ and a translation vector $t \\in \\mathbb{R}^{3}$; atomic positions $x_i \\in \\mathbb{R}^{3}$ transform as $x'_i = R x_i + t$. Interatomic distances $r_{ij} = \\lVert x_i - x_j \\rVert$ are invariant under such rigid motions, and a scalar potential energy that depends only on pairwise distances must be invariant under $E(3)$. Forces defined as $F_i = -\\nabla_{x_i} E$ transform under rotations by $F'_i = R F_i$ when applied to the rotated configuration. The program must implement a specific isotropic pair potential to make the test fully quantitative and reproducible: use the Lennard–Jones $12$-$6$ potential with energy\n$$\nE_{\\mathrm{LJ}}(X;\\epsilon,\\sigma) = \\sum_{1 \\le i < j \\le N} 4 \\epsilon \\left[\\left(\\frac{\\sigma}{r_{ij}}\\right)^{12} - \\left(\\frac{\\sigma}{r_{ij}}\\right)^{6}\\right],\n$$\nwhere $X = (x_1,\\dots,x_N)$, $N$ is the number of atoms, $\\epsilon$ is the depth parameter in $\\mathrm{eV}$, $\\sigma$ is the length scale in $\\text{\\AA}$, and $r_{ij} = \\lVert x_i - x_j \\rVert$ in $\\text{\\AA}$. Forces must be computed as $F_i = -\\nabla_{x_i} E_{\\mathrm{LJ}}$ in $\\mathrm{eV}/\\text{\\AA}$.\n\nTo probe violations, optionally augment the energy with an orientation-dependent, translation-invariant term\n$$\nE_{\\mathrm{orient}}(X; \\alpha, n) = \\alpha \\sum_{i=1}^{N} \\left((x_i - \\bar{x}) \\cdot n\\right)^2,\n$$\nwhere $\\bar{x} = \\frac{1}{N} \\sum_{k=1}^{N} x_k$ is the centroid, $n \\in \\mathbb{R}^{3}$ is a fixed unit vector in the laboratory frame, and $\\alpha$ has units $\\mathrm{eV}/\\text{\\AA}^2$. The total energy is then $E_{\\mathrm{tot}} = E_{\\mathrm{LJ}} + E_{\\mathrm{orient}}$ and the total force is $F_i = -\\nabla_{x_i} E_{\\mathrm{tot}}$.\n\nDataset construction and evaluation must follow logically from the base definitions. For a given base configuration $X$, generate a set of configurations by applying random rigid motions $(R,t)$ sampled as follows: rotations must be sampled uniformly on $SO(3)$ using normalized quaternions generated from independent standard normal components (normalize the quaternion to unit length before conversion to a rotation matrix), and translations must be sampled componentwise uniformly from an interval $[-A,A]$ (in $\\text{\\AA}$) for a specified amplitude $A \\ge 0$. For rotation-only tests, set $A=0$. For translation-only tests, set $R=I$. For fixed-angle rotation tests, use Rodrigues' rotation formula with a specified axis and angle, where angles must be expressed in radians.\n\nFor each transformed configuration $X'$, compute the energy invariance error\n$$\n\\delta_E = \\frac{\\left|E_{\\mathrm{tot}}(X') - E_{\\mathrm{tot}}(X)\\right|}{\\max\\left(\\lvert E_{\\mathrm{tot}}(X)\\rvert, 10^{-12}\\right)},\n$$\nand the force equivariance error\n$$\n\\delta_F = \\frac{\\left\\lVert F(X') - R F(X)\\right\\rVert_F}{\\max\\left(\\lVert F(X)\\rVert_F, 10^{-12}\\right)},\n$$\nwhere $\\lVert \\cdot \\rVert_F$ denotes the Frobenius norm over the $N \\times 3$ force matrix. Aggregate errors over all motions in the dataset by taking the maximum values $\\max \\delta_E$ and $\\max \\delta_F$. A test case passes if both $\\max \\delta_E \\le \\tau_E$ and $\\max \\delta_F \\le \\tau_F$ for specified tolerances $\\tau_E$ and $\\tau_F$.\n\nAll distances must be computed in $\\text{\\AA}$, energies in $\\mathrm{eV}$, and forces in $\\mathrm{eV}/\\text{\\AA}$. Angles must be in radians. The program must output booleans indicating pass or fail per test case.\n\nImplement the following test suite to ensure coverage, scientific realism, and edge cases. For each case, set the Lennard–Jones parameters to $\\epsilon = 0.0103\\,\\mathrm{eV}$ and $\\sigma = 3.4\\,\\text{\\AA}$:\n\nCase $1$ (general $E(3)$ invariance/equivariance): $N = 8$, base positions sampled uniformly in a cube of side $L = 10.0\\,\\text{\\AA}$ using a random seed $1234$, motions count $25$, rotation type “random” on $SO(3)$, translation amplitude $A = 5.0\\,\\text{\\AA}$, motion seed $5678$, no orientation term (set $\\alpha = 0$), tolerances $\\tau_E = 10^{-12}$ and $\\tau_F = 10^{-11}$.\n\nCase $2$ (pure translation boundary): $N = 6$, base positions sampled uniformly in a cube of side $L = 12.0\\,\\text{\\AA}$ with seed $42$, motions count $10$, rotation set to identity $R = I$, translation amplitude $A = 10.0\\,\\text{\\AA}$, motion seed $101$, no orientation term, tolerances $\\tau_E = 10^{-12}$ and $\\tau_F = 10^{-11}$.\n\nCase $3$ (pure rotation boundary): $N = 7$, base positions sampled uniformly in a cube of side $L = 8.0\\,\\text{\\AA}$ with seed $7$, motions count $12$, rotation set to a fixed angle $\\theta = \\pi/3$ around the axis $a = (1,1,2)$ using Rodrigues' formula, translation amplitude $A = 0.0\\,\\text{\\AA}$, motion seed $77$, no orientation term, tolerances $\\tau_E = 10^{-12}$ and $\\tau_F = 10^{-11}$.\n\nCase $4$ (violation with orientation-dependent term): $N = 8$, base positions sampled uniformly in a cube of side $L = 9.0\\,\\text{\\AA}$ with seed $99$, motions count $15$, rotation type “random” on $SO(3)$, translation amplitude $A = 3.0\\,\\text{\\AA}$, motion seed $123$, include the orientation-dependent term with $\\alpha = 1.0\\,\\mathrm{eV}/\\text{\\AA}^2$ and fixed unit vector $n = (0,0,1)$, tolerances $\\tau_E = 10^{-12}$ and $\\tau_F = 10^{-11}$.\n\nCase $5$ (near-degenerate distances): $N = 3$, positions explicitly defined as $x_1 = (0,0,0)$, $x_2 = (0.9\\,\\sigma, 0, 0)$, and $x_3 = (6\\,\\sigma, 6\\,\\sigma, 0)$ in $\\text{\\AA}$, motions count $5$, rotation type “random” on $SO(3)$, translation amplitude $A = 2.0\\,\\text{\\AA}$, motion seed $909$, no orientation term, tolerances $\\tau_E = 10^{-12}$ and $\\tau_F = 10^{-11}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[r_1,r_2,r_3,r_4,r_5]$, where each $r_k$ is a boolean indicating whether Case $k$ passes given its tolerances. No other output is permitted.", "solution": "The user has provided a well-defined problem in computational materials science. The problem is scientifically grounded, requires rigorous implementation of physical principles, and is free of fatal flaws. It is therefore deemed **valid**.\n\n### Principle-Based Design\n\nThe core of the problem is to construct a computational test to verify the geometric symmetries of an interatomic potential. For any system of interacting particles in a homogeneous and isotropic space, fundamental physical laws dictate that the total potential energy $E$ must be invariant under rigid-body motions (translations and rotations), which constitute the Euclidean group $E(3)$. Consequently, the forces $F_i = -\\nabla_{x_i} E$ on each particle $i$ must be equivariant under these transformations. This means that if the entire system of atomic positions $x_i$ is rotated by a matrix $R \\in SO(3)$, each force vector $F_i$ must also rotate by the same matrix $R$, i.e., $F'_i = R F_i$. These properties are essential for any physically realistic interatomic potential, including those generated by machine learning methods.\n\nOur solution implements a direct test of these properties using a well-known, isotropic, pairwise potential—the Lennard-Jones ($12$-$6$) potential—as a ground truth. An optional, non-isotropic term is also implemented to serve as a negative control, demonstrating how the test correctly identifies potentials that violate these fundamental symmetries.\n\n#### 1. Potential Energy and Force Calculation\n\nThe total energy $E_{\\mathrm{tot}}$ is the sum of the Lennard-Jones potential $E_{\\mathrm{LJ}}$ and an optional orientation-dependent term $E_{\\mathrm{orient}}$.\n\n**Lennard-Jones (LJ) Term:** The LJ potential is defined as:\n$$\nE_{\\mathrm{LJ}}(X) = \\sum_{1 \\le i < j \\le N} 4 \\epsilon \\left[\\left(\\frac{\\sigma}{r_{ij}}\\right)^{12} - \\left(\\frac{\\sigma}{r_{ij}}\\right)^{6}\\right]\n$$\nwhere $r_{ij} = \\lVert x_i - x_j \\rVert$ is the distance between atoms $i$ and $j$. Since $E_{\\mathrm{LJ}}$ depends only on interatomic distances, which are invariant under $E(3)$ transformations, $E_{\\mathrm{LJ}}$ is itself invariant. The force on atom $i$ is derived by taking the negative gradient of the energy with respect to its position $x_i$:\n$$\nF_i^{\\mathrm{LJ}} = -\\nabla_{x_i} E_{\\mathrm{LJ}} = \\sum_{j \\neq i} \\frac{24\\epsilon}{r_{ij}^2} \\left[2\\left(\\frac{\\sigma}{r_{ij}}\\right)^{12} - \\left(\\frac{\\sigma}{r_{ij}}\\right)^{6}\\right] (x_i - x_j)\n$$\nThis expression is implemented by iterating over all unique pairs of atoms, calculating the pairwise force, and accumulating the results for each atom according to Newton's third law ($F_{ij} = -F_{ji}$).\n\n**Orientation-Dependent Term:** To test the framework's ability to detect violations, a non-isotropic term is added:\n$$\nE_{\\mathrm{orient}}(X) = \\alpha \\sum_{i=1}^{N} \\left((x_i - \\bar{x}) \\cdot n\\right)^2\n$$\nwhere $\\bar{x}$ is the geometric center of the atoms and $n$ is a fixed vector in the lab frame. This term is invariant under translations but not under rotations, as a rotation of the system changes the dot products $(x_i - \\bar{x}) \\cdot n$. The corresponding force is:\n$$\nF_i^{\\mathrm{orient}} = -\\nabla_{x_i} E_{\\mathrm{orient}} = -2\\alpha \\left( (x_i - \\bar{x}) \\cdot n \\right) n\n$$\nThe total force is $F_i = F_i^{\\mathrm{LJ}} + F_i^{\\mathrm{orient}}$.\n\n#### 2. Geometric Transformations\n\nThe test involves applying rigid motions $(R, t)$ to a base atomic configuration $X$ to generate a new configuration $X'$:\n$$\nx'_i = R x_i + t\n$$\nA key part of the implementation is the generation of the rotation matrix $R \\in SO(3)$.\n-   **Uniform Random Rotations:** To sample uniformly from $SO(3)$, we generate a quaternion from four independent random numbers drawn from a standard normal distribution. This $4$D vector is normalized to produce a unit quaternion, which is then converted into a $3 \\times 3$ rotation matrix. This is a standard and robust method for unbiased sampling.\n-   **Fixed-Axis Rotations:** For specific deterministic tests, we use Rodrigues' rotation formula to construct the rotation matrix $R$ corresponding to a given rotation axis $u$ and angle $\\theta$:\n    $$\n    R(\\theta, u) = I \\cos\\theta + (1-\\cos\\theta) u u^\\top + [u]_\\times \\sin\\theta\n    $$\n    where $I$ is the identity matrix, $u u^\\top$ is the outer product of the axis with itself, and $[u]_\\times$ is its cross-product matrix.\n\n#### 3. Error Metrics and Verification\n\nFor each transformed configuration $X'$, we quantify the breakdown of symmetry using two relative error metrics.\n\n**Energy Invariance Error ($\\delta_E$):**\n$$\n\\delta_E = \\frac{\\left|E_{\\mathrm{tot}}(X') - E_{\\mathrm{tot}}(X)\\right|}{\\max\\left(\\lvert E_{\\mathrm{tot}}(X)\\rvert, 10^{-12}\\right)}\n$$\nFor a perfectly invariant potential, this error should be zero, limited only by floating-point precision.\n\n**Force Equivariance Error ($\\delta_F$):**\n$$\n\\delta_F = \\frac{\\left\\lVert F(X') - R F(X)\\right\\rVert_F}{\\max\\left(\\lVert F(X)\\rVert_F, 10^{-12}\\right)}\n$$\nHere, $F(X)$ is the $N \\times 3$ matrix of force vectors for the base configuration. $R F(X)$ represents the matrix of correctly rotated forces, which is computed as $F(X) R^\\top$. The error measures the deviation of the forces computed on the rotated structure, $F(X')$, from the rotated forces of the original structure. A small $\\delta_F$ indicates that forces are equivariant. The Frobenius norm $\\lVert \\cdot \\rVert_F$ is used to aggregate the error over all atoms.\n\nThe denominators include a small constant ($10^{-12}$) to prevent division by zero for cases with zero total energy or force. The final test result is determined by comparing the maximum errors observed over a set of transformations against user-specified tolerances, $\\tau_E$ and $\\tau_F$.\n\n#### 4. Algorithmic Implementation\n\nThe solution is structured as a loop over a predefined set of test cases. For each case:\n1.  An initial atomic configuration $X$ is generated, either from a uniform distribution within a cube or from explicitly defined coordinates.\n2.  The base energy $E_{\\mathrm{tot}}(X)$ and forces $F(X)$ are computed.\n3.  A loop runs for a specified number of motions. In each iteration, a rigid motion $(R, t)$ is generated according to the case's specifications.\n4.  The motion is applied to create $X'$, and its energy $E_{\\mathrm{tot}}(X')$ and forces $F(X')$ are calculated.\n5.  The errors $\\delta_E$ and $\\delta_F$ are computed and used to update the maximum observed errors.\n6.  Finally, these maximum errors are compared to the thresholds $\\tau_E$ and $\\tau_F$ to yield a boolean `pass` or `fail` result.\n\nThis structured approach ensures that the fundamental principles of symmetry in physical laws are rigorously and quantitatively tested for the given potential models, adhering to the problem's exacting requirements.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_system_properties(positions, epsilon, sigma, alpha, n_vec):\n    \"\"\"\n    Calculates total energy and forces for a system of atoms.\n    \n    Args:\n        positions (np.ndarray): Nx3 array of atomic positions in Angstroms.\n        epsilon (float): LJ energy depth in eV.\n        sigma (float): LJ length scale in Angstroms.\n        alpha (float): Strength of the orientation-dependent term in eV/Angstrom^2.\n        n_vec (np.ndarray or None): 3-element unit vector for the orientation term.\n\n    Returns:\n        tuple: A tuple containing:\n            - total_energy (float): Total potential energy in eV.\n            - total_forces (np.ndarray): Nx3 array of forces in eV/Angstrom.\n    \"\"\"\n    n_atoms = positions.shape[0]\n    total_energy = 0.0\n    total_forces = np.zeros_like(positions)\n\n    # Lennard-Jones part\n    for i in range(n_atoms):\n        for j in range(i + 1, n_atoms):\n            r_ij_vec = positions[i, :] - positions[j, :]\n            r_ij_sq = np.dot(r_ij_vec, r_ij_vec)\n            \n            if r_ij_sq == 0:\n                continue\n\n            r_ij = np.sqrt(r_ij_sq)\n            \n            sig_over_r = sigma / r_ij\n            sr6 = sig_over_r ** 6\n            sr12 = sr6 ** 2\n\n            total_energy += 4.0 * epsilon * (sr12 - sr6)\n\n            f_magnitude_over_r = (24.0 * epsilon / r_ij_sq) * (2.0 * sr12 - sr6)\n            f_vec = f_magnitude_over_r * r_ij_vec\n            \n            total_forces[i, :] += f_vec\n            total_forces[j, :] -= f_vec\n\n    # Orientation-dependent part\n    if alpha > 0 and n_vec is not None:\n        centroid = np.mean(positions, axis=0)\n        positions_centered = positions - centroid\n        \n        projections = positions_centered @ n_vec\n        \n        total_energy += alpha * np.sum(projections**2)\n        \n        # F_i = -2 * alpha * n * ((x_i - x_bar) . n)\n        force_orient = -2.0 * alpha * np.outer(projections, n_vec)\n        total_forces += force_orient\n\n    return total_energy, total_forces\n\ndef generate_random_rotation(rng):\n    \"\"\"Generates a random SO(3) rotation matrix from a uniform distribution.\"\"\"\n    q = rng.standard_normal(4)\n    q /= np.linalg.norm(q)\n    w, x, y, z = q\n    \n    return np.array([\n        [1 - 2*(y*y + z*z), 2*(x*y - w*z),     2*(x*z + w*y)],\n        [2*(x*y + w*z),     1 - 2*(x*x + z*z), 2*(y*z - w*x)],\n        [2*(x*z - w*y),     2*(y*z + w*x),     1 - 2*(x*x + y*y)]\n    ])\n\ndef rodrigues_rotation(axis, angle):\n    \"\"\"Generates a rotation matrix using Rodrigues' formula.\"\"\"\n    axis = axis / np.linalg.norm(axis)\n    ux, uy, uz = axis\n    c = np.cos(angle)\n    s = np.sin(angle)\n    c1 = 1 - c\n\n    return np.array([\n        [c + ux*ux*c1,         ux*uy*c1 - uz*s,    ux*uz*c1 + uy*s],\n        [uy*ux*c1 + uz*s,      c + uy*uy*c1,       uy*uz*c1 - ux*s],\n        [uz*ux*c1 - uy*s,      uz*uy*c1 + ux*s,    c + uz*uz*c1]\n    ])\n\ndef solve():\n    # Define the test cases from the problem statement.\n    epsilon = 0.0103  # eV\n    sigma = 3.4      # Angstrom\n\n    test_cases = [\n        # Case 1\n        {'N': 8, 'pos_type': 'uniform', 'L': 10.0, 'pos_seed': 1234,\n         'motions_count': 25, 'rot_type': 'random', 'A': 5.0, 'motion_seed': 5678,\n         'alpha': 0.0, 'n': None, 'tau_E': 1e-12, 'tau_F': 1e-11},\n        # Case 2\n        {'N': 6, 'pos_type': 'uniform', 'L': 12.0, 'pos_seed': 42,\n         'motions_count': 10, 'rot_type': 'identity', 'A': 10.0, 'motion_seed': 101,\n         'alpha': 0.0, 'n': None, 'tau_E': 1e-12, 'tau_F': 1e-11},\n        # Case 3\n        {'N': 7, 'pos_type': 'uniform', 'L': 8.0, 'pos_seed': 7,\n         'motions_count': 12, 'rot_type': 'fixed', 'rot_axis': np.array([1.0, 1.0, 2.0]),\n         'rot_angle': np.pi/3, 'A': 0.0, 'motion_seed': 77,\n         'alpha': 0.0, 'n': None, 'tau_E': 1e-12, 'tau_F': 1e-11},\n        # Case 4\n        {'N': 8, 'pos_type': 'uniform', 'L': 9.0, 'pos_seed': 99,\n         'motions_count': 15, 'rot_type': 'random', 'A': 3.0, 'motion_seed': 123,\n         'alpha': 1.0, 'n': np.array([0.0, 0.0, 1.0]), 'tau_E': 1e-12, 'tau_F': 1e-11},\n        # Case 5\n        {'N': 3, 'pos_type': 'explicit',\n         'base_pos_values': np.array([[0.0, 0.0, 0.0], [0.9, 0.0, 0.0], [6.0, 6.0, 0.0]]),\n         'motions_count': 5, 'rot_type': 'random', 'A': 2.0, 'motion_seed': 909,\n         'alpha': 0.0, 'n': None, 'tau_E': 1e-12, 'tau_F': 1e-11}\n    ]\n\n    results = []\n    for case in test_cases:\n        pos_rng = np.random.default_rng(case.get('pos_seed'))\n        motion_rng = np.random.default_rng(case['motion_seed'])\n\n        # Generate base configuration\n        if case['pos_type'] == 'uniform':\n            side = case['L']\n            X_base = pos_rng.uniform(-side / 2, side / 2, size=(case['N'], 3))\n        else: # explicit\n            X_base = case['base_pos_values'] * sigma\n\n        # Calculate properties for the base configuration\n        E_base, F_base = calculate_system_properties(\n            X_base, epsilon, sigma, case['alpha'], case['n']\n        )\n\n        max_delta_E = 0.0\n        max_delta_F = 0.0\n\n        for _ in range(case['motions_count']):\n            # Generate transformation (R, t)\n            if case['rot_type'] == 'random':\n                R = generate_random_rotation(motion_rng)\n            elif case['rot_type'] == 'identity':\n                R = np.identity(3)\n            else: # fixed\n                R = rodrigues_rotation(case['rot_axis'], case['rot_angle'])\n            \n            translation_amp = case['A']\n            if translation_amp > 0:\n                t = motion_rng.uniform(-translation_amp, translation_amp, size=3)\n            else:\n                t = np.zeros(3)\n\n            # Apply transformation\n            X_prime = X_base @ R.T + t\n\n            # Calculate properties for the transformed configuration\n            E_prime, F_prime = calculate_system_properties(\n                X_prime, epsilon, sigma, case['alpha'], case['n']\n            )\n\n            # Calculate errors\n            # Energy invariance error\n            denom_E = np.maximum(np.abs(E_base), 1e-12)\n            delta_E = np.abs(E_prime - E_base) / denom_E\n            max_delta_E = np.maximum(max_delta_E, delta_E)\n            \n            # Force equivariance error\n            F_base_rotated = F_base @ R.T\n            denom_F = np.maximum(np.linalg.norm(F_base, 'fro'), 1e-12)\n            delta_F = np.linalg.norm(F_prime - F_base_rotated, 'fro') / denom_F\n            max_delta_F = np.maximum(max_delta_F, delta_F)\n\n        # Check against tolerances\n        passed = (max_delta_E = case['tau_E']) and (max_delta_F = case['tau_F'])\n        results.append(str(passed))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results).lower()}]\")\n\nsolve()\n```", "id": "3498502"}, {"introduction": "Beyond geometric symmetries, any valid potential must also respect the quantum mechanical principle of particle indistinguishability. This means the system's energy cannot depend on the arbitrary labels we assign to chemically identical atoms. In this practice [@problem_id:3498423], you will implement a direct test for this permutation invariance by systematically relabeling atoms of the same species and verifying that the potential energy remains unchanged, a critical check for any multi-atom potential.", "problem": "You are given a task in computational materials science concerning the training and validation of Machine-Learned Interatomic Potentials (MLIP). A fundamental physical requirement for any interatomic potential is that the predicted total energy be invariant under permutations of chemically identical atoms, because the potential energy of a system depends only on atomic positions and chemical identities, not on arbitrary labeling. In particular, consider a system of $N$ atoms with positions $\\mathbf{r}_i \\in \\mathbb{R}^3$ and species labels $s_i \\in \\{\\text{A}, \\text{B}, \\dots\\}$ for $i \\in \\{1,\\dots,N\\}$. The objective is to construct and implement a test that verifies permutation invariance of the predicted energy $E$ under relabeling within groups of chemically identical atoms.\n\nStart from the Newtonian mechanics and classical potential energy framework: the total potential energy is a function of the set of positions and species, $E = E(\\{\\mathbf{r}_i\\}, \\{s_i\\})$, that must respect the indistinguishability of identical atoms. From this base, formalize an algorithmic test that:\n- Identifies groups of indices corresponding to chemically identical atoms (same $s_i$),\n- Applies deterministic permutations within each group (i.e., reorders the indices among atoms of identical species while leaving other indices unchanged),\n- Computes the energy before and after each permutation,\n- Checks whether the energy remains unchanged within a prescribed tolerance, thereby determining permutation invariance.\n\nTo make the test executable and numerically concrete, use two toy MLIP energy models on the same configurations:\n- A permutation-invariant model $E_{\\mathrm{PI}}$ defined by\n$$\nE_{\\mathrm{PI}}(\\{\\mathbf{r}_i\\}, \\{s_i\\}) = \\sum_{i=1}^N w_{s_i} \\left( \\sum_{\\substack{j=1 \\\\ j \\neq i}}^N \\exp\\!\\left(-\\frac{\\|\\mathbf{r}_i - \\mathbf{r}_j\\|^2}{\\sigma^2}\\right) \\right)^2,\n$$\nwhere $w_{s}$ is a species-dependent weight and $\\sigma$ is a positive length scale. This construction uses a sum over neighbors and a species-dependent weight, and is symmetric with respect to reordering of atoms within identical species.\n- A deliberately non-permutation-invariant model $E_{\\mathrm{NPI}}$ defined by\n$$\nE_{\\mathrm{NPI}}(\\{\\mathbf{r}_i\\}, \\{s_i\\}) = \\sum_{i=1}^N \\alpha_i \\left( \\sum_{\\substack{j=1 \\\\ j \\neq i}}^N \\exp\\!\\left(-\\frac{\\|\\mathbf{r}_i - \\mathbf{r}_j\\|^2}{\\sigma^2}\\right) \\right),\n$$\nwhere $\\alpha_i$ is an index-dependent coefficient that depends only on the atom index $i$ and not on the species; this breaks permutation invariance when atoms of the same species are relabeled among indices.\n\nUse the following parameter values for all test cases:\n- Species weights: $w_{\\text{A}} = 0.7$, $w_{\\text{B}} = 1.2$,\n- Length scale: $\\sigma = 0.8$,\n- Tolerance for invariance check: $\\varepsilon = 10^{-10}$,\n- Index weights: $\\alpha_i = i$ (using $1$-based indexing for $i$ in $\\{1,\\dots,N\\}$).\n\nThe atomic positions are specified in angstroms, but energies are dimensionless by construction in these toy models. Because the outputs are booleans, no unit conversion is required for the final answer.\n\nConstruct a test suite of configurations that are scientifically plausible (interatomic separations on the order of a few angstroms) and cover diverse cases. For each configuration, you must test multiple deterministic permutations within each species group, specifically:\n- Identity permutation within each group,\n- Reversal of the index order within each group,\n- Cyclic rotation by one position within each group (when the group size is at least $2$).\n\nA configuration is permutation invariant for a given model if and only if the energies computed for all such permuted configurations are equal to the original energy within the tolerance $\\varepsilon$.\n\nTest suite:\n- Case $1$ (happy path): $N = 4$, species $[\\text{A}, \\text{A}, \\text{B}, \\text{B}]$, positions\n  - $\\mathbf{r}_1 = (0.00, 0.00, 0.00)$,\n  - $\\mathbf{r}_2 = (1.10, 0.00, 0.00)$,\n  - $\\mathbf{r}_3 = (0.50, 0.80, 0.00)$,\n  - $\\mathbf{r}_4 = (1.60, 1.25, 0.30)$.\n- Case $2$ (all identical species, non-symmetric geometry): $N = 3$, species $[\\text{A}, \\text{A}, \\text{A}]$, positions\n  - $\\mathbf{r}_1 = (0.00, 0.00, 0.00)$,\n  - $\\mathbf{r}_2 = (1.00, 0.20, 0.10)$,\n  - $\\mathbf{r}_3 = (0.30, 0.70, 0.40)$.\n- Case $3$ (two identical species close, third different): $N = 3$, species $[\\text{B}, \\text{B}, \\text{A}]$, positions\n  - $\\mathbf{r}_1 = (0.00, 0.00, 0.00)$,\n  - $\\mathbf{r}_2 = (0.30, 0.00, 0.00)$,\n  - $\\mathbf{r}_3 = (0.10, 0.40, 0.20)$.\n- Case $4$ (mixed groups, varying counts): $N = 5$, species $[\\text{A}, \\text{B}, \\text{A}, \\text{B}, \\text{A}]$, positions\n  - $\\mathbf{r}_1 = (0.00, 0.00, 0.00)$,\n  - $\\mathbf{r}_2 = (0.90, 0.10, 0.00)$,\n  - $\\mathbf{r}_3 = (0.30, 1.10, 0.20)$,\n  - $\\mathbf{r}_4 = (1.30, 0.80, 0.20)$,\n  - $\\mathbf{r}_5 = (0.60, 0.40, 1.00)$.\n\nYour program must:\n- Implement the two energy models $E_{\\mathrm{PI}}$ and $E_{\\mathrm{NPI}}$,\n- For each test case, generate the specified permutations within each species group,\n- Compute energies for the original configuration and for the permuted configurations,\n- Determine two booleans per case: whether the configuration is permutation invariant for $E_{\\mathrm{PI}}$ and whether it is permutation invariant for $E_{\\mathrm{NPI}}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is a two-element list of booleans $[b_{\\mathrm{PI}}, b_{\\mathrm{NPI}}]$. For example, the output should look like $[[\\text{True},\\text{False}],[\\text{True},\\text{False}],\\dots]$ with no spaces.", "solution": "The problem requires the creation and implementation of a computational test to verify a fundamental physical principle: the permutation invariance of potential energy. In any system governed by classical or quantum mechanics, the total potential energy $E$ depends on an assembly of particles, defined by their properties (e.g., mass, charge, species) and their state variables (e.g., position, momentum). It must be independent of the arbitrary labels or indices assigned to identical particles. For a system of $N$ atoms with positions $\\{\\mathbf{r}_i\\}$ and chemical species $\\{s_i\\}$, where $i \\in \\{1, \\dots, N\\}$, this means that if we apply a permutation $P$ to the indices that only swaps atoms of the same species, the energy must remain unchanged. Formally, if for all $i$, $s_{P(i)} = s_i$, then the energy function must satisfy $E(\\{\\mathbf{r}_{P(i)}\\}, \\{s_{P(i)}\\}) = E(\\{\\mathbf{r}_i\\}, \\{s_i\\})$. This is a critical symmetry constraint that any physically realistic interatomic potential, including machine-learned models, must satisfy.\n\nThe task is to formalize an algorithmic test for this principle using two provided toy energy models, $E_{\\mathrm{PI}}$ and $E_{\\mathrm{NPI}}$, on a given set of atomic configurations.\n\nThe validation algorithm proceeds as follows:\n1.  **Identify Species Groups**: For a given configuration of $N$ atoms with species $\\{s_1, s_2, \\dots, s_N\\}$, the first step is to partition the set of atom indices $\\{0, 1, \\dots, N-1\\}$ into disjoint subsets, where each subset contains the indices of atoms of a single chemical species. For example, for species $[\\text{A}, \\text{B}, \\text{A}]$, the groups would be $I_{\\text{A}} = \\{0, 2\\}$ and $I_{\\text{B}} = \\{1\\}$.\n\n2.  **Generate Permutations**: For each species group containing at least two atoms, we generate a set of deterministic, non-trivial permutations. The problem specifies three types of permutations to consider for each group: identity, reversal, and cyclic rotation. The identity permutation serves as the baseline. The test permutations are those that reorder indices within one species group while leaving all other indices unchanged. Specifically, for each species group $I_s$:\n    *   A reversal permutation map is created by reversing the order of indices in $I_s$.\n    *   A cyclic permutation map is created by shifting each index in $I_s$ to the position of the previous one, with the first index moving to the last position. For a group of size $2$, this is identical to reversal.\n\n3.  **Compute and Compare Energies**: The core of the test involves comparing the energy of the original configuration with the energies of the permuted configurations.\n    *   First, the energy of the original, un-permuted configuration, $E_0$, is computed.\n    *   Then, for each generated permutation map $p$, a new configuration is constructed by reordering the atoms' positions and species arrays according to $p$. Let the permuted positions be $\\{\\mathbf{r}'_i\\}$ and species be $\\{s'_i\\}$. The energy of this new configuration, $E_p$, is computed.\n    *   The invariance check is performed by testing if the absolute difference between the original and permuted energies is within a given numerical tolerance $\\varepsilon$: $|E_p - E_0| \\le \\varepsilon$.\n    *   A model is considered permutation-invariant for the given configuration if this condition holds for *all* generated test permutations. If even one permutation results in a significant energy change, the model fails the test for that configuration.\n\nThe two energy models are designed to demonstrate this principle:\n\n-   **Permutation-Invariant Model ($E_{\\mathrm{PI}}$)**:\n    $$E_{\\mathrm{PI}}(\\{\\mathbf{r}_i\\}, \\{s_i\\}) = \\sum_{i=1}^N w_{s_i} \\left( \\sum_{\\substack{j=1 \\\\ j \\neq i}}^N \\exp\\!\\left(-\\frac{\\|\\mathbf{r}_i - \\mathbf{r}_j\\|^2}{\\sigma^2}\\right) \\right)^2$$\n    This model's invariance stems from the fact that the weight factor $w_{s_i}$ depends on the atom's species $s_i$, which is a physical property. When identical atoms are permuted (e.g., indices $k$ and $l$ are swapped, where $s_k=s_l$), their corresponding weights are also identical ($w_{s_k} = w_{s_l}$). The energy contribution from an atom depends on its species and its geometric environment. A permutation merely reorders the terms in the outer sum $\\sum_{i=1}^N$, leaving the total sum unchanged because the set of geometric environments being summed over is preserved. This model is expected to pass the invariance test for all configurations.\n\n-   **Non-Permutation-Invariant Model ($E_{\\mathrm{NPI}}$)**:\n    $$E_{\\mathrm{NPI}}(\\{\\mathbf{r}_i\\}, \\{s_i\\}) = \\sum_{i=1}^N \\alpha_i \\left( \\sum_{\\substack{j=1 \\\\ j \\neq i}}^N \\exp\\!\\left(-\\frac{\\|\\mathbf{r}_i - \\mathbf{r}_j\\|^2}{\\sigma^2}\\right) \\right)$$\n    This model is deliberately constructed to violate permutation invariance. The coefficient $\\alpha_i = i$ depends directly on the arbitrary numerical index $i$ assigned to an atom, not on its intrinsic physical properties (like species) or its position. When two atoms with indices $k$ and $l$ are permuted, their geometric environments are swapped, but the index-dependent coefficients $\\alpha_k$ and $\\alpha_l$ remain at their original indices. The energy contribution from the atom now at index $k$ becomes $\\alpha_k$ times the environment sum that was originally associated with index $l$. Unless the geometric environments of the two swapped atoms are identical by coincidence (which is not the case for the given asymmetric configurations) or $\\alpha_k = \\alpha_l$ (a trivial permutation), the total energy will change. This model is expected to fail the invariance test.\n\nThe implementation will apply this logic to each of the four test cases, evaluating both $E_{\\mathrm{PI}}$ and $E_{\\mathrm{NPI}}$ and producing a pair of booleans indicating the test outcome for each model.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import cdist\n\ndef solve():\n    \"\"\"\n    Main function to run the permutation invariance tests.\n    \"\"\"\n    # Define parameters from the problem statement.\n    params = {\n        'w': {'A': 0.7, 'B': 1.2},\n        'sigma': 0.8,\n        'epsilon': 1e-10\n    }\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple of (positions, species).\n    test_cases = [\n        (\n            [[0.00, 0.00, 0.00], [1.10, 0.00, 0.00], [0.50, 0.80, 0.00], [1.60, 1.25, 0.30]],\n            ['A', 'A', 'B', 'B']\n        ),\n        (\n            [[0.00, 0.00, 0.00], [1.00, 0.20, 0.10], [0.30, 0.70, 0.40]],\n            ['A', 'A', 'A']\n        ),\n        (\n            [[0.00, 0.00, 0.00], [0.30, 0.00, 0.00], [0.10, 0.40, 0.20]],\n            ['B', 'B', 'A']\n        ),\n        (\n            [[0.00, 0.00, 0.00], [0.90, 0.10, 0.00], [0.30, 1.10, 0.20], [1.30, 0.80, 0.20], [0.60, 0.40, 1.00]],\n            ['A', 'B', 'A', 'B', 'A']\n        )\n    ]\n    \n    def energy_pi(positions: np.ndarray, species: np.ndarray, p: dict) - float:\n        \"\"\"Computes energy using the permutation-invariant model.\"\"\"\n        n_atoms = len(positions)\n        if n_atoms  2:\n            return 0.0\n        \n        dist_sq = cdist(positions, positions, 'sqeuclidean')\n        gauss_terms = np.exp(-dist_sq / (p['sigma']**2))\n        np.fill_diagonal(gauss_terms, 0)\n        \n        local_env_sums = np.sum(gauss_terms, axis=1)\n        weights = np.array([p['w'][s] for s in species])\n        \n        energy = np.sum(weights * (local_env_sums**2))\n        return energy\n\n    def energy_npi(positions: np.ndarray, species: np.ndarray, p: dict) - float:\n        \"\"\"Computes energy using the non-permutation-invariant model.\"\"\"\n        n_atoms = len(positions)\n        if n_atoms  2:\n            return 0.0\n            \n        alphas = np.arange(1, n_atoms + 1)\n        \n        dist_sq = cdist(positions, positions, 'sqeuclidean')\n        gauss_terms = np.exp(-dist_sq / (p['sigma']**2))\n        np.fill_diagonal(gauss_terms, 0)\n        \n        local_env_sums = np.sum(gauss_terms, axis=1)\n        \n        energy = np.sum(alphas * local_env_sums)\n        return energy\n\n    def get_permutation_maps(species: np.ndarray) - list:\n        \"\"\"Generates permutation maps for reversal and cyclic shifts within species groups.\"\"\"\n        n_atoms = len(species)\n        species_groups = {}\n        for i, s_atom in enumerate(species):\n            species_groups.setdefault(s_atom, []).append(i)\n        \n        perm_maps = []\n        original_map = list(range(n_atoms))\n        \n        for group_indices in species_groups.values():\n            if len(group_indices)  2:\n                continue\n            \n            # Reversal permutation for this group\n            p_map_rev = original_map[:]\n            rev_indices = group_indices[::-1]\n            for i in range(len(group_indices)):\n                p_map_rev[group_indices[i]] = rev_indices[i]\n            if p_map_rev != original_map:\n                perm_maps.append(p_map_rev)\n            \n            # Cyclic permutation for this group\n            p_map_cyc = original_map[:]\n            cyc_indices = [group_indices[-1]] + group_indices[:-1]\n            for i in range(len(group_indices)):\n                p_map_cyc[group_indices[i]] = cyc_indices[i]\n            if p_map_cyc != original_map and p_map_cyc not in perm_maps:\n                perm_maps.append(p_map_cyc)\n                \n        return perm_maps\n\n    def check_invariance_for_case(positions: np.ndarray, species: np.ndarray, p: dict) - list:\n        \"\"\"Checks permutation invariance for a single case for both models.\"\"\"\n        # Calculate original energies\n        e0_pi = energy_pi(positions, species, p)\n        e0_npi = energy_npi(positions, species, p)\n\n        perm_maps = get_permutation_maps(species)\n        \n        is_pi_invariant = True\n        is_npi_invariant = True\n        \n        for p_map in perm_maps:\n            perm_pos = positions[p_map]\n            perm_species = species[p_map]\n            \n            # Test PI model\n            e_pi = energy_pi(perm_pos, perm_species, p)\n            if abs(e_pi - e0_pi)  p['epsilon']:\n                is_pi_invariant = False\n                \n            # Test NPI model\n            e_npi = energy_npi(perm_pos, perm_species, p)\n            if abs(e_npi - e0_npi)  p['epsilon']:\n                is_npi_invariant = False\n        \n        return [is_pi_invariant, is_npi_invariant]\n\n    results = []\n    for pos_list, species_list in test_cases:\n        positions_np = np.array(pos_list)\n        species_np = np.array(species_list)\n        result = check_invariance_for_case(positions_np, species_np, params)\n        results.append(result)\n\n    # Format output string as [[Bool,Bool],[Bool,Bool],...] with no spaces\n    result_str = \",\".join([str(r).replace(\" \", \"\") for r in results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3498423"}, {"introduction": "While satisfying exact symmetries is crucial, a practical MLIP must also be robust enough for use in long-timescale molecular dynamics (MD) simulations. Minor imperfections in the potential energy surface, such as discontinuities arising from numerical quantization, can violate energy conservation and introduce non-physical artifacts like spurious friction. This exercise [@problem_id:3498461] explores these effects in a controlled setting, teaching you how to quantify energy drift and assess a model's suitability for reliable dynamical simulations.", "problem": "You will investigate, in a controlled one-dimensional setting, how quantization of a machine-learned interatomic potential’s model coefficients and input descriptors affects force continuity and induces non-conservative artifacts such as spurious friction and energy drift during microcanonical dynamics. The task is to implement a complete, runnable program that constructs a simple linear potential model trained on data from a known analytic potential, applies specified quantization schemes, derives forces from quantized energies via finite differences, and then measures three quantitative metrics along a trajectory.\n\nBase the construction on the following fundamental definitions and well-tested formulas. Consider a single particle of mass $m$ evolving in one spatial dimension under a true analytic potential energy $U(x)$ and its corresponding true conservative force $F_{\\mathrm{true}}(x) = -\\frac{dU}{dx}$. Microcanonical dynamics (constant energy Molecular Dynamics (MD)) with a conservative and sufficiently smooth force field admits bounded energy error under symplectic integration. In contrast, a non-conservative force $F_{\\mathrm{ml}}(x)$ used to propagate the trajectory generally causes an energy drift for the true Hamiltonian $H(x,v) = \\frac{1}{2} m v^{2} + U(x)$. The instantaneous rate of change of $H$ along a trajectory $(x(t), v(t))$ driven by $F_{\\mathrm{ml}}$ satisfies\n$$\n\\frac{dH}{dt} = \\frac{d}{dt}\\left(\\frac{1}{2} m v^{2} + U(x)\\right) = v \\left( F_{\\mathrm{ml}}(x) - F_{\\mathrm{true}}(x) \\right).\n$$\nIn addition, when force errors project systematically opposite to the velocity, the dynamics experience an effective spurious friction, which can be quantified by projecting the force error onto a linear friction model $F_{\\mathrm{diss}}(t) = -\\gamma_{\\mathrm{eff}} v(t)$ and matching average power:\n$$\n\\gamma_{\\mathrm{eff}} = - \\frac{\\langle v \\, (F_{\\mathrm{ml}} - F_{\\mathrm{true}}) \\rangle}{\\langle v^{2} \\rangle},\n$$\nwhere $\\langle \\cdot \\rangle$ denotes a time average along the trajectory.\n\nSetup a true potential and a machine-learned linear energy model as follows.\n\n1. True potential. Use the dimensionless analytic potential\n$$\nU(x) = \\tfrac{1}{2} k x^{2} + a \\cos(2 \\pi x),\n$$\nwith parameters $m = 1$, $k = 1$, $a = 2 \\times 10^{-1}$. Angles in trigonometric functions are in radians. The corresponding true force is\n$$\nF_{\\mathrm{true}}(x) = -\\frac{dU}{dx} = -k x + 2 \\pi a \\sin(2 \\pi x).\n$$\n\n2. Linear machine-learned energy model. Define a descriptor vector\n$$\nd(x) = \\begin{bmatrix} x \\\\ x^{2} \\\\ \\cos(2 \\pi x) \\\\ \\sin(2 \\pi x) \\\\ 1 \\end{bmatrix}.\n$$\nFit a weight vector $w \\in \\mathbb{R}^{5}$ by least squares to minimize the empirical error $\\sum_{j} \\left(w^{\\top} d(x_{j}) - U(x_{j})\\right)^{2}$ over a training grid. Use a uniformly spaced training grid of $N_{\\mathrm{train}} = 2001$ points spanning $x \\in [-x_{\\max}, x_{\\max}]$ with $x_{\\max} = 3 \\times 10^{-1} \\times 5 = 1.5$. The unquantized model is $E_{\\mathrm{ml}}(x) = w^{\\top} d(x)$.\n\n3. Quantization. For a quantization step size $\\Delta > 0$, define the uniform mid-tread quantizer $q_{\\Delta}(z) = \\Delta \\, \\mathrm{round}(z/\\Delta)$, applied elementwise. Two independent quantization mechanisms are considered:\n   - Descriptor quantization with step $\\Delta_{d}$: $d_{q}(x) = q_{\\Delta_{d}}(d(x))$.\n   - Model weight quantization with step $\\Delta_{w}$: $w_{q} = q_{\\Delta_{w}}(w)$.\nWith both applied, define the quantized energy\n$$\nE_{q}(x) = w_{q}^{\\top} d_{q}(x).\n$$\nDefine the model force via a symmetric finite-difference derivative of the quantized energy\n$$\nF_{\\mathrm{ml}}(x) = -\\frac{E_{q}(x+\\delta) - E_{q}(x-\\delta)}{2 \\delta},\n$$\nwith a finite-difference step $\\delta = 10^{-4}$. To maintain numerical stability in the presence of discontinuities, cap the force magnitude by $|F_{\\mathrm{ml}}(x)| \\le F_{\\max}$ with $F_{\\max} = 5 \\times 10^{1}$.\n\n4. Trajectory generation. For each specified $(\\Delta_{d}, \\Delta_{w})$, run a microcanonical trajectory using velocity-Verlet with time step $\\Delta t = 10^{-3}$ for $N_{\\mathrm{steps}} = 5000$ steps, starting from $x_{0} = 3 \\times 10^{-1}$ and $v_{0} = 5 \\times 10^{-1}$. Evolve dynamics using only $F_{\\mathrm{ml}}$, but evaluate $H(t) = \\frac{1}{2} m v(t)^{2} + U(x(t))$ with the true potential and compute $F_{\\mathrm{true}}(x(t))$ for diagnostics.\n\n5. Metrics to report per test case:\n   - Effective spurious friction:\n   $$\n   \\gamma_{\\mathrm{eff}} = - \\frac{\\frac{1}{N}\\sum_{n=1}^{N} v_{n} \\left(F_{\\mathrm{ml}}(x_{n}) - F_{\\mathrm{true}}(x_{n})\\right)}{\\frac{1}{N}\\sum_{n=1}^{N} v_{n}^{2}},\n   $$\n   where $(x_{n}, v_{n})$ are the phase-space samples at each full time step and $N = N_{\\mathrm{steps}}$.\n   - Energy drift rate (per unit time):\n   $$\n   r_{E} = \\frac{H(T) - H(0)}{T}, \\quad T = N_{\\mathrm{steps}} \\, \\Delta t.\n   $$\n   - Mean force jump magnitude:\n   $$\n   J = \\frac{1}{N-1} \\sum_{n=1}^{N-1} \\left| F_{\\mathrm{ml}}(x_{n+1}) - F_{\\mathrm{ml}}(x_{n}) \\right|.\n   $$\n\nAll quantities are dimensionless.\n\nImplement the above and evaluate the following test suite of descriptor and weight quantization step sizes $(\\Delta_{d}, \\Delta_{w})$:\n- Case $1$: $(0, 0)$.\n- Case $2$: $(0, 10^{-3})$.\n- Case $3$: $(10^{-3}, 0)$.\n- Case $4$: $(10^{-3}, 10^{-3})$.\n- Case $5$: $(5 \\times 10^{-2}, 10^{-2})$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each case contributes a list of three decimal numbers $[\\gamma_{\\mathrm{eff}}, r_{E}, J]$ with six digits after the decimal point. For example, the overall output format must be\n$$\n[[\\gamma_{1},r_{1},J_{1}],[\\gamma_{2},r_{2},J_{2}],[\\gamma_{3},r_{3},J_{3}],[\\gamma_{4},r_{4},J_{4}],[\\gamma_{5},r_{5},J_{5}]],\n$$\nprinted on a single line with no spaces after commas.", "solution": "The problem statement is parsed and validated. It is found to be scientifically grounded, well-posed, and objective. All parameters, definitions, and procedures are provided in a complete and consistent manner, allowing for a unique and meaningful solution. The problem, rooted in computational materials science, presents a rigorous investigation into the effects of quantization on machine-learned interatomic potentials, which is a relevant and non-trivial topic. All physical and mathematical formulations are sound. The problem is therefore deemed **valid**.\n\nThe solution is constructed by following the sequence of tasks outlined in the problem statement. The implementation is divided into four main stages: model training, formulation of the quantized force model, trajectory generation via molecular dynamics simulation, and calculation of diagnostic metrics.\n\nFirst, the machine-learned linear potential model is trained. The true analytic potential is given by $U(x) = \\frac{1}{2} k x^{2} + a \\cos(2 \\pi x)$ with parameters $k=1$ and $a=0.2$. A training set is generated using $N_{\\mathrm{train}} = 2001$ uniformly spaced points $x_j$ in the interval $[-1.5, 1.5]$. At each point $x_j$, we compute the true potential energy $y_j = U(x_j)$ and the descriptor vector $d(x_j) = [x_j, x_j^2, \\cos(2\\pi x_j), \\sin(2\\pi x_j), 1]^{\\top}$. The goal is to find the weight vector $w \\in \\mathbb{R}^{5}$ that minimizes the sum of squared errors, $\\sum_{j} (w^{\\top} d(x_j) - y_j)^2$. This is a standard linear least-squares problem, which can be expressed in matrix form as minimizing $\\|Dw - y\\|^2$, where $D$ is the design matrix with rows $d(x_j)^{\\top}$. The optimal weight vector $w$ is found using a numerical least-squares solver, specifically `numpy.linalg.lstsq`. This trained vector $w$ constitutes the high-precision reference model.\n\nSecond, the quantized energy and force models are implemented. The core of the quantization is the function $q_{\\Delta}(z) = \\Delta \\cdot \\mathrm{round}(z/\\Delta)$, which maps a real number $z$ to the nearest multiple of a given step size $\\Delta$. For the case where $\\Delta=0$, this function acts as the identity, $q_0(z)=z$. For each test case defined by a pair of quantization step sizes $(\\Delta_d, \\Delta_w)$, the quantized energy is calculated as $E_q(x) = w_q^{\\top} d_q(x)$. Here, the weights are quantized, $w_q = q_{\\Delta_w}(w)$, and the descriptor vector is also quantized, $d_q(x) = q_{\\Delta_d}(d(x))$. The force exerted by the machine-learned potential, $F_{\\mathrm{ml}}(x)$, is derived from this quantized energy using a symmetric finite-difference scheme with a step size of $\\delta = 10^{-4}$:\n$$\nF_{\\mathrm{ml}}(x) = -\\frac{E_q(x+\\delta) - E_q(x-\\delta)}{2\\delta}.\n$$\nThe quantization of energy can lead to sharp, step-like features, which result in very large, unphysical forces when differentiated. To ensure numerical stability during the simulation, the magnitude of the calculated force is capped at $F_{\\max} = 50$.\n\nThird, a molecular dynamics simulation is performed for each test case. A single particle of mass $m=1$ is evolved in one dimension under the action of the force $F_{\\mathrm{ml}}(x)$. The trajectory is propagated using the velocity-Verlet integration algorithm with a time step of $\\Delta t = 10^{-3}$ for a total of $N_{\\mathrm{steps}} = 5000$ steps. The simulation starts from the initial condition $(x_0, v_0) = (0.3, 0.5)$. The algorithm proceeds as follows for each step $n$:\n1. $v_{n+1/2} = v_n + \\frac{1}{m} F_{\\mathrm{ml}}(x_n) \\frac{\\Delta t}{2}$\n2. $x_{n+1} = x_n + v_{n+1/2} \\Delta t$\n3. $v_{n+1} = v_{n+1/2} + \\frac{1}{m} F_{\\mathrm{ml}}(x_{n+1}) \\frac{\\Delta t}{2}$\nThe full trajectory of positions $\\{x_n\\}_{n=0}^{N_{\\mathrm{steps}}}$ and velocities $\\{v_n\\}_{n=0}^{N_{\\mathrm{steps}}}$ is stored for subsequent analysis.\n\nFinally, the three specified metrics are calculated from the generated trajectory data. These metrics quantify the non-conservative artifacts introduced by the quantization. Let $N = N_{\\mathrm{steps}}$.\n1. The effective spurious friction, $\\gamma_{\\mathrm{eff}}$, measures the systematic component of the force error that opposes the velocity. It is calculated as:\n$$\n\\gamma_{\\mathrm{eff}} = - \\frac{\\sum_{n=1}^{N} v_{n} (F_{\\mathrm{ml}}(x_{n}) - F_{\\mathrm{true}}(x_{n}))}{\\sum_{n=1}^{N} v_{n}^{2}},\n$$\nwhere $F_{\\mathrm{true}}(x) = -x + 0.4\\pi \\sin(2\\pi x)$ is the analytical force derived from the true potential $U(x)$. The sums run over the trajectory points from step $n=1$ to $n=N$.\n2. The energy drift rate, $r_E$, quantifies the rate at which the true total energy $H(t) = \\frac{1}{2}mv(t)^2 + U(x(t))$ changes due to the non-conservative nature of $F_{\\mathrm{ml}}$. It is computed over the total simulation time $T = N \\Delta t$:\n$$\nr_E = \\frac{H(t=T) - H(t=0)}{T}.\n$$\n3. The mean force jump magnitude, $J$, measures the discontinuity in the force profile between successive time steps, which is a direct consequence of the piece-wise constant nature of the quantized energy surface. It is calculated as:\n$$\nJ = \\frac{1}{N-1} \\sum_{n=1}^{N-1} |F_{\\mathrm{ml}}(x_{n+1}) - F_{\\mathrm{ml}}(x_n)|.\n$$\nThis procedure is repeated for each of the five test cases $(\\Delta_d, \\Delta_w)$, and the resulting triplet of metrics $[\\gamma_{\\mathrm{eff}}, r_E, J]$ for each case is compiled for the final output.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of analyzing quantization effects in a 1D machine-learned potential.\n    The process involves:\n    1. Training a linear model on an analytic potential.\n    2. Looping through test cases with different quantization parameters.\n    3. For each case, running a molecular dynamics simulation using the quantized force.\n    4. Calculating metrics (spurious friction, energy drift, force jumps) from the trajectory.\n    5. Formatting and printing the results.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    m = 1.0\n    k = 1.0\n    a = 2.0e-1\n    pi = np.pi\n\n    N_train = 2001\n    x_max = 3.0e-1 * 5.0\n    delta = 1.0e-4\n    F_max = 5.0e1\n\n    dt = 1.0e-3\n    N_steps = 5000\n    x0 = 3.0e-1\n    v0 = 5.0e-1\n\n    test_cases = [\n        (0.0, 0.0),             # Case 1\n        (0.0, 1.0e-3),          # Case 2\n        (1.0e-3, 0.0),          # Case 3\n        (1.0e-3, 1.0e-3),       # Case 4\n        (5.0e-2, 1.0e-2)        # Case 5\n    ]\n\n    # --- Helper Functions ---\n    def U_true(x):\n        return 0.5 * k * x**2 + a * np.cos(2.0 * pi * x)\n\n    def F_true(x):\n        return -k * x + 2.0 * pi * a * np.sin(2.0 * pi * x)\n\n    def descriptor_vec(x):\n        return np.array([x, x**2, np.cos(2.0 * pi * x), np.sin(2.0 * pi * x), 1.0])\n\n    def descriptor_matrix(x_vals):\n        return np.vstack([descriptor_vec(x).T for x in x_vals])\n    \n    def quantizer(z, q_step):\n        if q_step == 0.0:\n            return z\n        return q_step * np.round(z / q_step)\n\n    # --- 1. Model Training ---\n    x_train = np.linspace(-x_max, x_max, N_train)\n    U_train = U_true(x_train)\n    D_train = descriptor_matrix(x_train)\n    w_fit, _, _, _ = np.linalg.lstsq(D_train, U_train, rcond=None)\n\n    # --- Main Loop over Test Cases ---\n    all_results = []\n    for delta_d, delta_w in test_cases:\n\n        # --- 2. Define Quantized Force Model for the current case ---\n        w_q = quantizer(w_fit, delta_w)\n\n        def E_q(x):\n            d_x = descriptor_vec(x)\n            d_q = quantizer(d_x, delta_d)\n            return np.dot(w_q, d_q)\n\n        def F_ml(x):\n            force = -(E_q(x + delta) - E_q(x - delta)) / (2.0 * delta)\n            return np.clip(force, -F_max, F_max)\n\n        # --- 3. Trajectory Generation ---\n        x_traj = np.zeros(N_steps + 1)\n        v_traj = np.zeros(N_steps + 1)\n        x_traj[0], v_traj[0] = x0, v0\n        \n        # Velocity-Verlet Integration\n        F_current = F_ml(x_traj[0])\n        for n in range(N_steps):\n            v_half_step = v_traj[n] + (F_current / m) * (dt / 2.0)\n            x_traj[n+1] = x_traj[n] + v_half_step * dt\n            F_next = F_ml(x_traj[n+1])\n            v_traj[n+1] = v_half_step + (F_next / m) * (dt / 2.0)\n            F_current = F_next\n            \n        # --- 4. Metric Calculation ---\n        # Select trajectory points from step 1 to N_steps\n        x_eval = x_traj[1:]\n        v_eval = v_traj[1:]\n\n        # Calculate forces along trajectory for metric computation\n        F_ml_eval = np.array([F_ml(x) for x in x_eval])\n        F_true_eval = F_true(x_eval)\n\n        # a) Effective spurious friction (gamma_eff)\n        force_error = F_ml_eval - F_true_eval\n        numerator_gamma = np.sum(v_eval * force_error)\n        denominator_gamma = np.sum(v_eval**2)\n        gamma_eff = -numerator_gamma / denominator_gamma if denominator_gamma != 0 else 0.0\n\n        # b) Energy drift rate (r_E)\n        H0 = 0.5 * m * v_traj[0]**2 + U_true(x_traj[0])\n        H_final = 0.5 * m * v_traj[-1]**2 + U_true(x_traj[-1])\n        T = N_steps * dt\n        r_E = (H_final - H0) / T\n\n        # c) Mean force jump magnitude (J)\n        # We need forces at steps 1 through N_steps\n        F_ml_all_steps = np.array([F_ml(x) for x in x_traj])\n        F_ml_for_J = F_ml_all_steps[1:] # steps 1...N_steps\n        force_jumps = np.abs(np.diff(F_ml_for_J)) # |F(n+1)-F(n)| for n=1..N-1\n        J = np.mean(force_jumps) if len(force_jumps) > 0 else 0.0\n        \n        all_results.append([gamma_eff, r_E, J])\n    \n    # --- Final Output Formatting ---\n    formatted_cases = []\n    for res_case in all_results:\n        formatted_cases.append(f\"[{res_case[0]:.6f},{res_case[1]:.6f},{res_case[2]:.6f}]\")\n    \n    print(f\"[{','.join(formatted_cases)}]\")\n\nsolve()\n```", "id": "3498461"}]}