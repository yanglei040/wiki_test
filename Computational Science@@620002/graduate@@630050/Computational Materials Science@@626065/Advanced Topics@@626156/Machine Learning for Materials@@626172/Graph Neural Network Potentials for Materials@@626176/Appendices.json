{"hands_on_practices": [{"introduction": "A cornerstone of any physical theory is that its predictions must be independent of the arbitrary coordinate system chosen by the observer. For interatomic potentials, this translates to the principles of rotational invariance for scalar quantities like energy, and rotational equivariance for vector quantities like forces. This hands-on practice [@problem_id:3455845] allows you to computationally verify these fundamental symmetries, which are essential for the reliability and physical realism of graph neural network potentials. By contrasting a correctly designed invariant potential with an incorrect one, you will gain a concrete understanding of why these symmetries are so crucial.", "problem": "Design and implement a program to empirically quantify rotational equivariance and invariance properties of two energy-based interatomic potentials used in graph neural network potentials for materials. The program must start from the principles that a scalar energy should be rotationally invariant and that forces, being the negative gradient of energy with respect to positions, should transform as vectors, that is, if a rotation $R \\in \\mathrm{SO}(3)$ is applied to atomic positions, then the energy satisfies $E(R\\mathbf{r}) = E(\\mathbf{r})$ for a rotationally invariant potential and the forces satisfy $\\mathbf{F}(R\\mathbf{r}) = R \\mathbf{F}(\\mathbf{r})$. Use dimensionless reduced units for all quantities, and use angles in radians. All computations must be deterministic as specified below.\n\nYou must implement two energy models defined on a set of $N$ atoms with positions $\\mathbf{r} = \\{\\mathbf{r}_i\\}_{i=1}^N$, where each $\\mathbf{r}_i \\in \\mathbb{R}^3$:\n\n- Model A (rotationally invariant pair potential): The total energy is a pairwise sum $E_{\\text{pair}}(\\mathbf{r}) = \\sum_{1 \\le i < j \\le N} g(d_{ij})$, where $d_{ij} = \\|\\mathbf{r}_i - \\mathbf{r}_j\\|_2$ and the radial function is\n$$\ng(d) = a_1 e^{-b_1 d} + a_2 e^{-b_2 d^2} + c \\frac{d^3}{1 + d^2}.\n$$\nUse the fixed constants $a_1 = 1.5$, $b_1 = 1.1$, $a_2 = -0.9$, $b_2 = 0.7$, and $c = 0.04$. Forces must be computed from the definition $\\mathbf{F}_i(\\mathbf{r}) = -\\nabla_{\\mathbf{r}_i} E_{\\text{pair}}(\\mathbf{r})$ without introducing any non-rotational terms.\n\n- Model B (intentionally non-invariant anisotropic energy): The total energy is\n$$\nE_{\\text{ani}}(\\mathbf{r}) = \\sum_{i=1}^N \\left( \\mathbf{w} \\cdot \\mathbf{r}_i \\right) + \\frac{1}{2} \\sum_{i=1}^N \\mathbf{r}_i^\\top A \\mathbf{r}_i,\n$$\nwhere $\\mathbf{w} = [0.3,\\,-0.5,\\,0.2]^\\top$ and\n$$\nA = \\begin{bmatrix}\n1.2 & 0.1 & 0.0 \\\\\n0.1 & 0.8 & 0.05 \\\\\n0.0 & 0.05 & 0.6\n\\end{bmatrix}.\n$$\nForces must be computed from $\\mathbf{F}_i(\\mathbf{r}) = -\\nabla_{\\mathbf{r}_i} E_{\\text{ani}}(\\mathbf{r})$.\n\nDefine the following error metrics for a given rotation $R \\in \\mathrm{SO}(3)$ and positions $\\mathbf{r}$:\n\n- Energy invariance error:\n$$\n\\Delta_E = \\left| E(R\\mathbf{r}) - E(\\mathbf{r}) \\right|.\n$$\n- Force equivariance root-mean-square (RMS) error:\n$$\n\\Delta_F = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N \\left\\| \\mathbf{F}_i(R\\mathbf{r}) - R \\mathbf{F}_i(\\mathbf{r}) \\right\\|_2^2 }.\n$$\n\nRotation generation must be axis-angle with a uniformly random axis on the unit sphere and an angle uniformly sampled in $[0,2\\pi)$, built via Rodriguesâ€™ formula. Given a nonnegative integer seed $s$, initialize a pseudorandom number generator deterministically and use it to produce the axis and angle as specified. The identity rotation must be represented explicitly when required.\n\nTest suite. Evaluate the metrics $(\\Delta_E,\\Delta_F)$ on the following cases; all positions are given as lists of triples $(x,y,z)$ in dimensionless units:\n\n- Case $1$: Model A, positions $\\left[(0.0,0.0,0.0),(1.1,0.2,-0.3),(-0.4,1.3,0.7)\\right]$, random rotation with seed $7$.\n- Case $2$: Model A, same positions as Case $1$, identity rotation.\n- Case $3$: Model A, positions $\\left[(0.5,-0.8,0.9),(1.7,1.1,-0.4),(-1.2,0.3,0.6),(0.2,-1.5,1.3)\\right]$, random rotation with seed $12345$.\n- Case $4$: Model A, positions $\\left[(0.0,0.0,0.0)\\right]$, random rotation with seed $99$.\n- Case $5$: Model B, positions from Case $1$, random rotation with seed $202$.\n- Case $6$: Model B, positions $\\left[(0.0,0.0,0.0)\\right]$, random rotation with seed $7$.\n\nAlgorithmic requirements and constraints:\n\n- All computations must be performed in double precision floating point. Handle any pair with separation $d_{ij}$ smaller than a safe threshold (for example $10^{-12}$) by excluding its contribution to the force direction to avoid division by zero, while keeping the energy well-defined.\n- Angles are in radians. All units are dimensionless. No external data or user input is permitted.\n- For each case, compute $(\\Delta_E,\\Delta_F)$ and round each value to $10$ decimal places.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the flattened order\n$$\n[\\Delta_{E,1}, \\Delta_{F,1}, \\Delta_{E,2}, \\Delta_{F,2}, \\ldots, \\Delta_{E,6}, \\Delta_{F,6}],\n$$\nwith each floating-point value rounded to $10$ decimal places as specified above.", "solution": "The problem is valid as it is scientifically grounded, well-posed, and contains a complete and consistent set of definitions and constraints. I will now provide a full solution.\n\nThe objective is to empirically quantify the rotational symmetry properties of two distinct interatomic potential energy models. A physical system's energy $E$ is rotationally invariant if it remains unchanged when the entire system is rotated. A force field $\\mathbf{F}$ is rotationally equivariant if, upon rotating the system, the new force vectors are the original force vectors subjected to the same rotation. These fundamental principles are expressed mathematically for a rotation $R \\in \\mathrm{SO}(3)$ applied to a set of atomic positions $\\mathbf{r} = \\{\\mathbf{r}_i\\}_{i=1}^N$ as:\n- Invariance (for scalar energy): $E(R\\mathbf{r}) = E(\\mathbf{r})$\n- Equivariance (for vector forces): $\\mathbf{F}_i(R\\mathbf{r}) = R \\mathbf{F}_i(\\mathbf{r})$ for each atom $i$.\n\nThe provided error metrics, $\\Delta_E = \\left| E(R\\mathbf{r}) - E(\\mathbf{r}) \\right|$ and $\\Delta_F = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N \\left\\| \\mathbf{F}_i(R\\mathbf{r}) - R \\mathbf{F}_i(\\mathbf{r}) \\right\\|_2^2 }$, serve as direct computational measures of any deviation from these ideal symmetry properties.\n\n**Rotation Matrix Generation**\n\nA rotation in three-dimensional Euclidean space can be specified by an axis of rotation, represented by a unit vector $\\mathbf{u} = [u_x, u_y, u_z]^\\top$, and an angle of rotation $\\theta$. The problem specifies a deterministic procedure for generating a random rotation matrix $R$. First, a pseudorandom number generator is seeded. Then, a random axis $\\mathbf{u}$ is sampled uniformly from the unit sphere $S^2$, and a random angle $\\theta$ is sampled uniformly from $[0, 2\\pi)$. The rotation matrix $R$ is constructed using Rodrigues' formula:\n$$\nR(\\mathbf{u}, \\theta) = I + (\\sin \\theta) K + (1 - \\cos \\theta) K^2\n$$\nwhere $I$ is the $3 \\times 3$ identity matrix and $K$ is the cross-product matrix associated with $\\mathbf{u}$:\n$$\nK = \\begin{bmatrix} 0 & -u_z & u_y \\\\ u_z & 0 & -u_x \\\\ -u_y & u_x & 0 \\end{bmatrix}\n$$\nFor cases requiring the identity rotation, we simply use $R=I$.\n\n**Model A: Rotationally Invariant Pair Potential**\n\nThe energy for Model A is given by:\n$$\nE_{\\text{pair}}(\\mathbf{r}) = \\sum_{1 \\le i < j \\le N} g(d_{ij}), \\quad \\text{where } d_{ij} = \\|\\mathbf{r}_i - \\mathbf{r}_j\\|_2\n$$\nThe radial function is $g(d) = a_1 e^{-b_1 d} + a_2 e^{-b_2 d^2} + c \\frac{d^3}{1 + d^2}$.\nThis potential is inherently rotationally invariant. A rigid rotation preserves all interatomic distances $d_{ij}$ because the Euclidean norm is invariant under orthogonal transformations:\n$$\nd_{ij}' = \\|R\\mathbf{r}_i - R\\mathbf{r}_j\\|_2 = \\|R(\\mathbf{r}_i - \\mathbf{r}_j)\\|_2 = \\|\\mathbf{r}_i - \\mathbf{r}_j\\|_2 = d_{ij}\n$$\nSince $E_{\\text{pair}}$ depends only on these distances, $E_{\\text{pair}}(R\\mathbf{r}) = E_{\\text{pair}}(\\mathbf{r})$, and we expect $\\Delta_E$ to be zero, up to floating-point numerical error.\n\nThe force on atom $i$ is the negative gradient of the energy with respect to its position $\\mathbf{r}_i$:\n$$\n\\mathbf{F}_i(\\mathbf{r}) = -\\nabla_{\\mathbf{r}_i} E_{\\text{pair}}(\\mathbf{r}) = -\\sum_{j \\ne i} \\nabla_{\\mathbf{r}_i} g(d_{ij})\n$$\nUsing the chain rule, $\\nabla_{\\mathbf{r}_i} g(d_{ij}) = g'(d_{ij}) \\nabla_{\\mathbf{r}_i} d_{ij}$, where $g'(d) = \\frac{dg}{dd}$. The gradient of the distance is $\\nabla_{\\mathbf{r}_i} d_{ij} = \\frac{\\mathbf{r}_i - \\mathbf{r}_j}{d_{ij}}$. Thus, the force on atom $i$ from atom $j$ is:\n$$\n\\mathbf{F}_{ij} = -g'(d_{ij}) \\frac{\\mathbf{r}_i - \\mathbf{r}_j}{d_{ij}}\n$$\nand the total force on atom $i$ is $\\mathbf{F}_i = \\sum_{j \\ne i} \\mathbf{F}_{ij}$. The derivative of the radial function is:\n$$\ng'(d) = -a_1 b_1 e^{-b_1 d} - 2 a_2 b_2 d e^{-b_2 d^2} + c \\frac{d^2(3+d^2)}{(1+d^2)^2}\n$$\nFor numerical stability, if $d_{ij}$ is below a threshold ($10^{-12}$), its contribution to the force is excluded to avoid division by a near-zero number. The energy contribution is still included as $g(d)$ is well-defined at $d=0$. Since the potential is invariant, we expect the forces to be equivariant, and thus $\\Delta_F$ should also be nearly zero.\n\n**Model B: Non-Invariant Anisotropic Potential**\n\nThe energy for Model B is:\n$$\nE_{\\text{ani}}(\\mathbf{r}) = \\sum_{i=1}^N \\left( \\mathbf{w} \\cdot \\mathbf{r}_i \\right) + \\frac{1}{2} \\sum_{i=1}^N \\mathbf{r}_i^\\top A \\mathbf{r}_i\n$$\nwith constant vector $\\mathbf{w}$ and constant symmetric matrix $A$. This potential is not rotationally invariant. Applying a rotation $R$ to the positions yields:\n$$\nE_{\\text{ani}}(R\\mathbf{r}) = \\sum_{i=1}^N \\left( \\mathbf{w} \\cdot (R\\mathbf{r}_i) \\right) + \\frac{1}{2} \\sum_{i=1}^N (R\\mathbf{r}_i)^\\top A (R\\mathbf{r}_i)\n$$\nUsing properties of dot products and matrix transposes, this becomes:\n$$\nE_{\\text{ani}}(R\\mathbf{r}) = \\sum_{i=1}^N \\left( (R^\\top\\mathbf{w}) \\cdot \\mathbf{r}_i \\right) + \\frac{1}{2} \\sum_{i=1}^N \\mathbf{r}_i^\\top (R^\\top A R) \\mathbf{r}_i\n$$\nThis expression is not equal to $E_{\\text{ani}}(\\mathbf{r})$ unless $R^\\top\\mathbf{w}=\\mathbf{w}$ and $R^\\top A R = A$, which is not true for a general rotation $R$. Therefore, we expect a non-zero energy invariance error $\\Delta_E$.\n\nThe force on atom $i$ is found by taking the gradient with respect to $\\mathbf{r}_i$. The energy terms for different atoms are uncoupled. Using standard vector calculus identities, $\\nabla_{\\mathbf{v}} (\\mathbf{c} \\cdot \\mathbf{v}) = \\mathbf{c}$ and $\\nabla_{\\mathbf{v}} (\\frac{1}{2}\\mathbf{v}^\\top M \\mathbf{v}) = M\\mathbf{v}$ for a symmetric matrix $M$, we find:\n$$\n\\nabla_{\\mathbf{r}_i} E_{\\text{ani}}(\\mathbf{r}) = \\mathbf{w} + A\\mathbf{r}_i\n$$\nThe force on atom $i$ is therefore:\n$$\n\\mathbf{F}_i(\\mathbf{r}) = -(\\mathbf{w} + A\\mathbf{r}_i)\n$$\nThe force on the rotated system is $\\mathbf{F}_i(R\\mathbf{r}) = -(\\mathbf{w} + A R\\mathbf{r}_i)$. The transformed original force is $R\\mathbf{F}_i(\\mathbf{r}) = -R(\\mathbf{w} + A\\mathbf{r}_i)$. These two quantities are not equal in general, so we expect a non-zero force equivariance error $\\Delta_F$.\n\n**Computational Procedure**\n\nFor each test case, the algorithm proceeds as follows:\n1.  Identify the model (A or B), atomic positions $\\mathbf{r}$, and rotation seed.\n2.  Generate the rotation matrix $R$. If the seed is for an identity rotation, $R=I$. Otherwise, a random rotation is generated deterministically from the seed.\n3.  Calculate the initial energy $E(\\mathbf{r})$ and forces $\\mathbf{F}(\\mathbf{r})$ using the appropriate model's equations.\n4.  Apply the rotation to the positions to get $R\\mathbf{r} = \\{R\\mathbf{r}_i\\}$.\n5.  Calculate the energy $E(R\\mathbf{r})$ and forces $\\mathbf{F}(R\\mathbf{r})$ on the rotated system.\n6.  Apply the rotation to the original force vectors to get the equivariance target $R\\mathbf{F}(\\mathbf{r}) = \\{R\\mathbf{F}_i(\\mathbf{r})\\}$.\n7.  Compute the errors $\\Delta_E$ and $\\Delta_F$ using their definitions. For the singular case of a single atom ($N=1$) in Model A, the energy and forces are identically zero, resulting in zero error. For Model B, even with $N=1$, energy and forces can be non-zero.\n8.  Round the computed errors to $10$ decimal places as required. The results from all cases are then aggregated and formatted into the final output string.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# from scipy import ... is not needed\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # Model A constants\n    A1 = 1.5\n    B1 = 1.1\n    A2 = -0.9\n    B2 = 0.7\n    C = 0.04\n\n    # Model B constants\n    W = np.array([0.3, -0.5, 0.2])\n    A_matrix = np.array([[1.2, 0.1, 0.0],\n                         [0.1, 0.8, 0.05],\n                         [0.0, 0.05, 0.6]])\n\n    # Numerical threshold for distance\n    DIST_THRESHOLD = 1e-12\n\n    def generate_rotation_matrix(seed):\n        \"\"\"Generates a 3x3 rotation matrix from a seed.\"\"\"\n        if seed is None:  # Identity rotation\n            return np.identity(3)\n\n        rng = np.random.default_rng(seed)\n        \n        # Generate a random axis uniformly on the unit sphere\n        axis = rng.normal(size=3)\n        norm = np.linalg.norm(axis)\n        if norm  DIST_THRESHOLD:\n            # Fallback for the exceedingly rare case of a zero vector\n            axis = np.array([0.0, 0.0, 1.0])\n        else:\n            axis /= norm\n        \n        # Generate a random angle\n        theta = rng.uniform(0, 2 * np.pi)\n\n        # Rodrigues' formula\n        K = np.array([[0, -axis[2], axis[1]],\n                      [axis[2], 0, -axis[0]],\n                      [-axis[1], axis[0], 0]])\n        \n        R = np.identity(3) + np.sin(theta) * K + (1 - np.cos(theta)) * (K @ K)\n        return R\n\n    def model_a_energy_forces(positions):\n        \"\"\"Calculates energy and forces for Model A.\"\"\"\n        pos = np.asarray(positions, dtype=np.float64)\n        n_atoms = pos.shape[0]\n        if n_atoms = 1:\n            return 0.0, np.zeros((n_atoms, 3))\n\n        total_energy = 0.0\n        forces = np.zeros_like(pos)\n\n        for i in range(n_atoms):\n            for j in range(i + 1, n_atoms):\n                rij_vec = pos[i] - pos[j]\n                d = np.linalg.norm(rij_vec)\n\n                if d  DIST_THRESHOLD:\n                    continue\n\n                # Energy contribution\n                d2 = d * d\n                d3 = d2 * d\n                g_d = A1 * np.exp(-B1 * d) + A2 * np.exp(-B2 * d2) + C * d3 / (1.0 + d2)\n                total_energy += g_d\n\n                # Force contribution\n                g_prime_d = -A1 * B1 * np.exp(-B1 * d) - 2 * A2 * B2 * d * np.exp(-B2 * d2) \\\n                            + C * (d2 * (3 + d2)) / ((1 + d2)**2)\n                \n                force_scalar = -g_prime_d / d\n                force_vec = force_scalar * rij_vec\n                forces[i] += force_vec\n                forces[j] -= force_vec\n        \n        return total_energy, forces\n\n    def model_b_energy_forces(positions):\n        \"\"\"Calculates energy and forces for Model B.\"\"\"\n        pos = np.asarray(positions, dtype=np.float64)\n        n_atoms = pos.shape[0]\n        if n_atoms == 0:\n            return 0.0, np.zeros((0, 3))\n            \n        total_energy = 0.0\n        forces = np.zeros_like(pos)\n        \n        # Term 1: w dot r\n        total_energy += np.sum(pos @ W)\n        \n        # Term 2: 1/2 r^T A r\n        for i in range(n_atoms):\n            total_energy += 0.5 * (pos[i] @ A_matrix @ pos[i])\n        \n        # Forces: F_i = -(w + A*r_i)\n        for i in range(n_atoms):\n            forces[i] = -(W + A_matrix @ pos[i])\n            \n        return total_energy, forces\n\n    def calculate_errors(model_func, positions, rotation_seed):\n        \"\"\"Computes Delta_E and Delta_F for a given model, positions, and rotation.\"\"\"\n        pos = np.asarray(positions, dtype=np.float64)\n        n_atoms = pos.shape[0]\n\n        # 1. Generate rotation\n        R = generate_rotation_matrix(rotation_seed)\n\n        # 2. Calculate initial energy and forces\n        E_orig, F_orig = model_func(pos)\n\n        # 3. Calculate rotated positions\n        pos_rot = (R @ pos.T).T\n\n        # 4. Calculate energy and forces on rotated system\n        E_rot, F_rot = model_func(pos_rot)\n        \n        # 5. Transform original forces\n        F_orig_rot = (R @ F_orig.T).T\n        \n        # 6. Compute errors\n        delta_E = np.abs(E_rot - E_orig)\n        \n        if n_atoms == 0:\n            delta_F = 0.0\n        else:\n            diff_F = F_rot - F_orig_rot\n            sum_sq_diff = np.sum(np.linalg.norm(diff_F, axis=1)**2)\n            delta_F = np.sqrt(sum_sq_diff / n_atoms)\n            \n        return round(delta_E, 10), round(delta_F, 10)\n\n    # Test suite definition\n    test_cases = [\n        # Case 1\n        {'model': 'A', 'pos': [(0.0,0.0,0.0),(1.1,0.2,-0.3),(-0.4,1.3,0.7)], 'seed': 7},\n        # Case 2\n        {'model': 'A', 'pos': [(0.0,0.0,0.0),(1.1,0.2,-0.3),(-0.4,1.3,0.7)], 'seed': None},\n        # Case 3\n        {'model': 'A', 'pos': [(0.5,-0.8,0.9),(1.7,1.1,-0.4),(-1.2,0.3,0.6),(0.2,-1.5,1.3)], 'seed': 12345},\n        # Case 4\n        {'model': 'A', 'pos': [(0.0,0.0,0.0)], 'seed': 99},\n        # Case 5\n        {'model': 'B', 'pos': [(0.0,0.0,0.0),(1.1,0.2,-0.3),(-0.4,1.3,0.7)], 'seed': 202},\n        # Case 6\n        {'model': 'B', 'pos': [(0.0,0.0,0.0)], 'seed': 7},\n    ]\n\n    results = []\n    for case in test_cases:\n        model_function = model_a_energy_forces if case['model'] == 'A' else model_b_energy_forces\n        delta_E, delta_F = calculate_errors(model_function, case['pos'], case['seed'])\n        results.extend([f\"{delta_E:.10f}\", f\"{delta_F:.10f}\"])\n    \n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3455845"}, {"introduction": "Graph neural network potentials must be trained to accurately reproduce multiple physical quantities at once, most commonly the total energy, atomic forces, and system stress. Since these quantities have different units and magnitudes, training involves minimizing a weighted loss function that balances the errors across them. This exercise [@problem_id:3455782] guides you through a simplified training scenario to explore how adjusting the loss weights creates a trade-off, or a \"Pareto frontier,\" between the accuracy of energy and force predictions, a central challenge in fitting any machine-learned potential.", "problem": "You are given a simplified linearized Graph Neural Network (GNN) potential model for atomic materials where the total energy of a structure is modeled as a linear function of differentiable features, and forces are the negative gradient of the energy with respect to atomic positions. The model uses a parameter vector $w \\in \\mathbb{R}^p$ shared across energy, force, and stress predictions. You will implement weighted empirical risk minimization using a training dataset and evaluate mean absolute errors (MAE) on a validation dataset. Your goal is to tune the loss weights for energy and force to explore the trade-off and compute the Pareto frontier between energy and force validation MAEs.\n\nBase definitions and principles:\n- For a structure with feature vector $\\Phi(R) \\in \\mathbb{R}^p$, the energy is modeled as $E = \\Phi(R)^\\top w$.\n- The force vector (concatenated over atoms and Cartesian components) is modeled as $F = -G(R) w$, where $G(R) \\in \\mathbb{R}^{m \\times p}$ is the Jacobian of the features with respect to positions (negative sign from the definition $F = -\\nabla_R E$).\n- The Cauchy stress (represented here as a $6$-component Voigt vector) is modeled as $\\sigma = H(R) w$, with $H(R) \\in \\mathbb{R}^{6 \\times p}$ the derivative of features with respect to strain.\n\nTraining objective:\nYou will minimize a weighted least-squares objective\n$$\n\\mathcal{L}(w; \\lambda_E, \\lambda_F) = \\lambda_E \\left\\|X_E^{(\\mathrm{tr})} w - y_E^{(\\mathrm{tr})}\\right\\|_2^2 + \\lambda_F \\left\\|X_F^{(\\mathrm{tr})} w - y_F^{(\\mathrm{tr})}\\right\\|_2^2 + \\lambda_S \\left\\|X_S^{(\\mathrm{tr})} w - y_S^{(\\mathrm{tr})}\\right\\|_2^2 + \\gamma \\left\\|w\\right\\|_2^2,\n$$\nwhere $\\lambda_E  0$ and $\\lambda_F  0$ are the tunable energy and force loss weights, $\\lambda_S  0$ is a fixed stress loss weight, and $\\gamma  0$ is an $\\ell_2$ regularization coefficient. Under independent Gaussian noise assumptions on the targets, this objective corresponds to maximum likelihood estimation, and its minimizer is given by the normal equations:\n$$\n\\left(\\lambda_E {X_E^{(\\mathrm{tr})}}^\\top X_E^{(\\mathrm{tr})} + \\lambda_F {X_F^{(\\mathrm{tr})}}^\\top X_F^{(\\mathrm{tr})} + \\lambda_S {X_S^{(\\mathrm{tr})}}^\\top X_S^{(\\mathrm{tr})} + \\gamma I\\right) w^\\star =\n\\lambda_E {X_E^{(\\mathrm{tr})}}^\\top y_E^{(\\mathrm{tr})} + \\lambda_F {X_F^{(\\mathrm{tr})}}^\\top y_F^{(\\mathrm{tr})} + \\lambda_S {X_S^{(\\mathrm{tr})}}^\\top y_S^{(\\mathrm{tr})}.\n$$\n\nDataset and units:\n- Energies are expressed in electronvolts ($\\mathrm{eV}$).\n- Forces are expressed in electronvolts per Angstrom ($\\mathrm{eV}/\\mathrm{\\AA}$).\n- Stresses are expressed in gigapascals ($\\mathrm{GPa}$).\n\nModel dimensionality:\n- Number of features $p = 3$.\n- Each structure has $m = 6$ force components (two atoms times three Cartesian directions), and $6$ stress components in Voigt notation.\n\nTraining dataset ($3$ structures):\nEnergy features matrix $X_E^{(\\mathrm{tr})} \\in \\mathbb{R}^{3 \\times 3}$:\n$$\nX_E^{(\\mathrm{tr})} =\n\\begin{bmatrix}\n1.2  0.5  -0.1 \\\\\n0.9  -0.2  0.4 \\\\\n1.5  0.1  0.2\n\\end{bmatrix}.\n$$\nForce Jacobians per structure $G_1, G_2, G_3 \\in \\mathbb{R}^{6 \\times 3}$:\n$$\nG_1 =\n\\begin{bmatrix}\n0.2  -0.1  0.0 \\\\\n-0.3  0.2  0.1 \\\\\n0.1  0.0  -0.2 \\\\\n-0.1  0.3  0.2 \\\\\n0.0  -0.2  0.1 \\\\\n0.2  0.1  -0.1\n\\end{bmatrix},\\quad\nG_2 =\n\\begin{bmatrix}\n0.1  0.2  -0.1 \\\\\n-0.2  0.1  0.0 \\\\\n0.0  -0.1  0.2 \\\\\n0.3  -0.2  0.1 \\\\\n-0.1  0.0  0.3 \\\\\n0.2  -0.3  0.0\n\\end{bmatrix},\\quad\nG_3 =\n\\begin{bmatrix}\n0.2  -0.2  0.1 \\\\\n0.1  0.0  -0.1 \\\\\n-0.3  0.2  0.0 \\\\\n0.0  -0.1  0.3 \\\\\n0.1  0.3  -0.2 \\\\\n-0.2  0.1  0.2\n\\end{bmatrix}.\n$$\nStacked force mapping $X_F^{(\\mathrm{tr})} \\in \\mathbb{R}^{18 \\times 3}$ is the vertical concatenation of $-G_1$, $-G_2$, $-G_3$:\n$$\nX_F^{(\\mathrm{tr})} =\n\\begin{bmatrix}\n-G_1 \\\\\n-G_2 \\\\\n-G_3\n\\end{bmatrix}.\n$$\nStress mapping per structure $H_1, H_2, H_3 \\in \\mathbb{R}^{6 \\times 3}$:\n$$\nH_1 =\n\\begin{bmatrix}\n0.05  -0.02  0.01 \\\\\n0.01  0.03  -0.02 \\\\\n0.02  -0.01  0.04 \\\\\n0.03  0.01  -0.03 \\\\\n-0.02  0.04  0.01 \\\\\n0.01  -0.03  0.02\n\\end{bmatrix},\\quad\nH_2 =\n\\begin{bmatrix}\n0.04  0.02  -0.01 \\\\\n-0.01  0.03  0.02 \\\\\n0.02  0.01  -0.03 \\\\\n0.03  -0.02  0.01 \\\\\n0.01  -0.01  0.04 \\\\\n-0.02  0.02  0.03\n\\end{bmatrix},\\quad\nH_3 =\n\\begin{bmatrix}\n0.03  -0.01  0.02 \\\\\n0.02  0.04  -0.01 \\\\\n-0.01  0.03  0.01 \\\\\n0.04  -0.02  0.02 \\\\\n0.01  0.02  -0.03 \\\\\n-0.03  0.01  0.04\n\\end{bmatrix}.\n$$\nStacked stress mapping $X_S^{(\\mathrm{tr})} \\in \\mathbb{R}^{18 \\times 3}$ is the vertical concatenation of $H_1$, $H_2$, $H_3$:\n$$\nX_S^{(\\mathrm{tr})} =\n\\begin{bmatrix}\nH_1 \\\\\nH_2 \\\\\nH_3\n\\end{bmatrix}.\n$$\n\nValidation dataset ($2$ structures):\nEnergy features matrix $X_E^{(\\mathrm{val})} \\in \\mathbb{R}^{2 \\times 3}$:\n$$\nX_E^{(\\mathrm{val})} =\n\\begin{bmatrix}\n1.1  0.3  0.0 \\\\\n0.7  -0.1  0.5\n\\end{bmatrix}.\n$$\nForce Jacobians $G_4, G_5 \\in \\mathbb{R}^{6 \\times 3}$:\n$$\nG_4 =\n\\begin{bmatrix}\n0.1  -0.1  0.2 \\\\\n-0.1  0.2  0.0 \\\\\n0.2  0.0  -0.2 \\\\\n-0.2  0.1  0.2 \\\\\n0.0  -0.2  0.1 \\\\\n0.1  0.3  -0.1\n\\end{bmatrix},\\quad\nG_5 =\n\\begin{bmatrix}\n0.2  0.1  -0.2 \\\\\n-0.3  0.2  0.1 \\\\\n0.1  -0.2  0.0 \\\\\n0.0  0.1  0.3 \\\\\n0.3  -0.1  0.2 \\\\\n-0.2  0.0  -0.1\n\\end{bmatrix}.\n$$\nStacked force mapping $X_F^{(\\mathrm{val})} \\in \\mathbb{R}^{12 \\times 3}$ is the vertical concatenation of $-G_4$, $-G_5$:\n$$\nX_F^{(\\mathrm{val})} =\n\\begin{bmatrix}\n-G_4 \\\\\n-G_5\n\\end{bmatrix}.\n$$\n\nGround truth parameter and targets:\nDefine the ground truth parameter vector\n$$\nw_{\\mathrm{true}} = \\begin{bmatrix} 0.8 \\\\ -0.3 \\\\ 0.5 \\end{bmatrix}.\n$$\nNoiseless energy targets are $E^{(\\mathrm{tr})}_{\\mathrm{true}} = X_E^{(\\mathrm{tr})} w_{\\mathrm{true}}$ and $E^{(\\mathrm{val})}_{\\mathrm{true}} = X_E^{(\\mathrm{val})} w_{\\mathrm{true}}$. Noiseless force targets are $F^{(\\mathrm{tr})}_{\\mathrm{true}} = X_F^{(\\mathrm{tr})} w_{\\mathrm{true}}$ and $F^{(\\mathrm{val})}_{\\mathrm{true}} = X_F^{(\\mathrm{val})} w_{\\mathrm{true}}$. Noiseless stress targets are $\\sigma^{(\\mathrm{tr})}_{\\mathrm{true}} = X_S^{(\\mathrm{tr})} w_{\\mathrm{true}}$. The training measurements include small additive noise:\nEnergy noise vector (in $\\mathrm{eV}$):\n$$\n\\delta_E^{(\\mathrm{tr})} = \\begin{bmatrix} 0.01 \\\\ -0.02 \\\\ 0.015 \\end{bmatrix}.\n$$\nForce noise vector (in $\\mathrm{eV}/\\mathrm{\\AA}$), concatenated per structure:\n$$\n\\delta_F^{(\\mathrm{tr})} = \\begin{bmatrix}\n0.01 \\\\ -0.008 \\\\ 0.005 \\\\ -0.006 \\\\ 0.004 \\\\ -0.007 \\\\\n0.006 \\\\ -0.005 \\\\ 0.003 \\\\ 0.0 \\\\ -0.004 \\\\ 0.005 \\\\\n-0.002 \\\\ 0.004 \\\\ -0.006 \\\\ 0.005 \\\\ -0.003 \\\\ 0.007\n\\end{bmatrix}.\n$$\nStress noise vector (in $\\mathrm{GPa}$), concatenated per structure:\n$$\n\\delta_S^{(\\mathrm{tr})} = \\begin{bmatrix}\n0.002 \\\\ -0.001 \\\\ 0.002 \\\\ -0.001 \\\\ 0.0005 \\\\ -0.002 \\\\\n0.001 \\\\ 0.002 \\\\ -0.001 \\\\ 0.0015 \\\\ -0.0005 \\\\ 0.002 \\\\\n-0.001 \\\\ 0.001 \\\\ 0.002 \\\\ -0.0015 \\\\ 0.0025 \\\\ -0.001\n\\end{bmatrix}.\n$$\nObserved training targets are\n$$\ny_E^{(\\mathrm{tr})} = E^{(\\mathrm{tr})}_{\\mathrm{true}} + \\delta_E^{(\\mathrm{tr})},\\quad\ny_F^{(\\mathrm{tr})} = F^{(\\mathrm{tr})}_{\\mathrm{true}} + \\delta_F^{(\\mathrm{tr})},\\quad\ny_S^{(\\mathrm{tr})} = \\sigma^{(\\mathrm{tr})}_{\\mathrm{true}} + \\delta_S^{(\\mathrm{tr})}.\n$$\nValidation targets are noiseless:\n$$\ny_E^{(\\mathrm{val})} = E^{(\\mathrm{val})}_{\\mathrm{true}},\\quad\ny_F^{(\\mathrm{val})} = F^{(\\mathrm{val})}_{\\mathrm{true}}.\n$$\n\nHyperparameters:\nThe fixed stress loss weight is\n$$\n\\lambda_S = 0.1,\n$$\nand the regularization coefficient is\n$$\n\\gamma = 10^{-4}.\n$$\n\nLoss-weight grid and test suite:\nYou will explore the grid\n$$\n\\lambda_E \\in \\{0.1, 1.0, 10.0\\},\\quad \\lambda_F \\in \\{0.1, 1.0, 10.0\\}.\n$$\nFor evaluation, define the validation MAEs\n$$\n\\mathrm{MAE}_E = \\frac{1}{n_{\\mathrm{val}}} \\sum_{i=1}^{n_{\\mathrm{val}}} \\left| \\left(X_E^{(\\mathrm{val})} w^\\star\\right)_i - \\left(y_E^{(\\mathrm{val})}\\right)_i \\right| \\quad \\text{in } \\mathrm{eV},\n$$\n$$\n\\mathrm{MAE}_F = \\frac{1}{m_{\\mathrm{val}}} \\sum_{j=1}^{m_{\\mathrm{val}}} \\left| \\left(X_F^{(\\mathrm{val})} w^\\star\\right)_j - \\left(y_F^{(\\mathrm{val})}\\right)_j \\right| \\quad \\text{in } \\mathrm{eV}/\\mathrm{\\AA},\n$$\nwhere $n_{\\mathrm{val}} = 2$ and $m_{\\mathrm{val}} = 12$.\n\nDefine three scalarization test cases using weights $\\alpha$ to form a single validation objective\n$$\nJ(\\alpha; \\lambda_E, \\lambda_F) = \\alpha \\,\\mathrm{MAE}_E + (1 - \\alpha)\\,\\mathrm{MAE}_F.\n$$\nUse the test suite $\\alpha \\in \\{0.0, 0.5, 1.0\\}$ to represent pure force focus, balanced trade-off, and pure energy focus.\n\nPareto frontier:\nThe Pareto frontier is the set of non-dominated points among $(\\mathrm{MAE}_E, \\mathrm{MAE}_F)$ produced by the grid over $(\\lambda_E,\\lambda_F)$: a point is non-dominated if there is no other point with both $\\mathrm{MAE}_E$ less than or equal and $\\mathrm{MAE}_F$ less than or equal, with at least one strict inequality.\n\nTasks:\n- For each pair $(\\lambda_E,\\lambda_F)$ in the specified grid, compute $w^\\star$ using the normal equations above.\n- Evaluate $\\mathrm{MAE}_E$ (in $\\mathrm{eV}$) and $\\mathrm{MAE}_F$ (in $\\mathrm{eV}/\\mathrm{\\AA}$) on the validation set.\n- Compute the Pareto frontier among the set of $(\\mathrm{MAE}_E, \\mathrm{MAE}_F)$.\n- For each $\\alpha \\in \\{0.0, 0.5, 1.0\\}$, find the $(\\lambda_E,\\lambda_F)$ pair that minimizes $J(\\alpha; \\lambda_E, \\lambda_F)$. In case of ties, break ties by choosing the smallest $\\lambda_E$, and then the smallest $\\lambda_F$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain $7$ values in the following order: the best $\\lambda_E$ and $\\lambda_F$ for $\\alpha = 0.0$, then for $\\alpha = 0.5$, then for $\\alpha = 1.0$, followed by the integer number of Pareto frontier points. All $\\lambda$ values must be printed as floats rounded to three decimal places, and the Pareto count as an integer. For example:\n$$\n[\\lambda_{E,\\alpha=0.0},\\lambda_{F,\\alpha=0.0},\\lambda_{E,\\alpha=0.5},\\lambda_{F,\\alpha=0.5},\\lambda_{E,\\alpha=1.0},\\lambda_{F,\\alpha=1.0},N_{\\mathrm{Pareto}}].\n$$", "solution": "The user wants to solve a problem based on a simplified linearized Graph Neural Network (GNN) potential for materials. The task involves performing weighted empirical risk minimization (a form of linear regression), evaluating model performance, and exploring the trade-off between energy and force prediction accuracy.\n\n### Step 1: Problem Validation\n\n**1.1. Extract Givens**\n\n*   **Model Definitions**:\n    *   Energy: $E = \\Phi(R)^\\top w$\n    *   Force: $F = -G(R) w$, where $G(R) = \\nabla_R \\Phi(R)$\n    *   Stress: $\\sigma = H(R) w$\n*   **Parameter Vector**: $w \\in \\mathbb{R}^p$ with $p=3$.\n*   **Training Objective**: $\\mathcal{L}(w; \\lambda_E, \\lambda_F) = \\lambda_E \\left\\|X_E^{(\\mathrm{tr})} w - y_E^{(\\mathrm{tr})}\\right\\|_2^2 + \\lambda_F \\left\\|X_F^{(\\mathrm{tr})} w - y_F^{(\\mathrm{tr})}\\right\\|_2^2 + \\lambda_S \\left\\|X_S^{(\\mathrm{tr})} w - y_S^{(\\mathrm{tr})}\\right\\|_2^2 + \\gamma \\left\\|w\\right\\|_2^2$.\n*   **Normal Equations**: $\\left(\\lambda_E {X_E^{(\\mathrm{tr})}}^\\top X_E^{(\\mathrm{tr})} + \\lambda_F {X_F^{(\\mathrm{tr})}}^\\top X_F^{(\\mathrm{tr})} + \\lambda_S {X_S^{(\\mathrm{tr})}}^\\top X_S^{(\\mathrm{tr})} + \\gamma I\\right) w^\\star = \\lambda_E {X_E^{(\\mathrm{tr})}}^\\top y_E^{(\\mathrm{tr})} + \\lambda_F {X_F^{(\\mathrm{tr})}}^\\top y_F^{(\\mathrm{tr})} + \\lambda_S {X_S^{(\\mathrm{tr})}}^\\top y_S^{(\\mathrm{tr})}$.\n*   **Training Data (3 structures)**:\n    *   $X_E^{(\\mathrm{tr})} \\in \\mathbb{R}^{3 \\times 3}$, $G_1, G_2, G_3 \\in \\mathbb{R}^{6 \\times 3}$, $H_1, H_2, H_3 \\in \\mathbb{R}^{6 \\times 3}$ (matrices provided).\n    *   $X_F^{(\\mathrm{tr})} = [ -G_1^\\top, -G_2^\\top, -G_3^\\top ]^\\top \\in \\mathbb{R}^{18 \\times 3}$.\n    *   $X_S^{(\\mathrm{tr})} = [ H_1^\\top, H_2^\\top, H_3^\\top ]^\\top \\in \\mathbb{R}^{18 \\times 3}$.\n*   **Validation Data (2 structures)**:\n    *   $X_E^{(\\mathrm{val})} \\in \\mathbb{R}^{2 \\times 3}$, $G_4, G_5 \\in \\mathbb{R}^{6 \\times 3}$ (matrices provided).\n    *   $X_F^{(\\mathrm{val})} = [ -G_4^\\top, -G_5^\\top ]^\\top \\in \\mathbb{R}^{12 \\times 3}$.\n*   **Ground Truth and Targets**:\n    *   $w_{\\mathrm{true}} = [0.8, -0.3, 0.5]^\\top$.\n    *   Noise vectors $\\delta_E^{(\\mathrm{tr})}, \\delta_F^{(\\mathrm{tr})}, \\delta_S^{(\\mathrm{tr})}$ are provided.\n    *   Training targets: $y^{(\\mathrm{tr})} = X^{(\\mathrm{tr})}w_{\\mathrm{true}} + \\delta^{(\\mathrm{tr})}$.\n    *   Validation targets: $y^{(\\mathrm{val})} = X^{(\\mathrm{val})}w_{\\mathrm{true}}$ (noiseless).\n*   **Hyperparameters**: $\\lambda_S = 0.1$, $\\gamma = 10^{-4}$.\n*   **Loss-weight Grid**: $\\lambda_E \\in \\{0.1, 1.0, 10.0\\}$, $\\lambda_F \\in \\{0.1, 1.0, 10.0\\}$.\n*   **Evaluation Metrics**: Mean Absolute Error for energy ($\\mathrm{MAE}_E$) and force ($\\mathrm{MAE}_F$) on the validation set. $n_{\\mathrm{val}}=2$, $m_{\\mathrm{val}}=12$.\n*   **Scalarization Test**: $J(\\alpha) = \\alpha \\,\\mathrm{MAE}_E + (1 - \\alpha)\\,\\mathrm{MAE}_F$ for $\\alpha \\in \\{0.0, 0.5, 1.0\\}$.\n*   **Pareto Frontier**: Defined as the set of non-dominated $(\\mathrm{MAE}_E, \\mathrm{MAE}_F)$ pairs.\n*   **Tasks**:\n    1.  Compute $w^\\star$ for each $(\\lambda_E, \\lambda_F)$ pair.\n    2.  Evaluate $\\mathrm{MAE}_E$ and $\\mathrm{MAE}_F$.\n    3.  Find the Pareto frontier.\n    4.  Find the optimal $(\\lambda_E, \\lambda_F)$ for each $\\alpha$, with specified tie-breaking rules.\n*   **Final Output Format**: A comma-separated list of $7$ values: $[\\lambda_{E,\\alpha=0.0},\\lambda_{F,\\alpha=0.0},...,N_{\\mathrm{Pareto}}]$.\n\n**1.2. Validate Using Extracted Givens**\n\n*   **Scientifically Grounded**: The problem is a well-defined application of linear least-squares regression, a fundamental statistical method, to a simplified but physically motivated model for interatomic potentials. The concepts of energy, forces as energy gradients, and stress are standard in materials physics. The formulation is a linearized approximation of more complex non-linear GNN potentials, which is a valid and common simplification for analysis and teaching.\n*   **Well-Posed**: All necessary data, equations, and parameters are explicitly provided. The normal equations define a linear system $A w^\\star = b$. The matrix $A$ is a sum of positive semi-definite matrices (${X}^\\top X$) and a positive definite matrix ($\\gamma I$ with $\\gamma  0$). Therefore, $A$ is positive definite and invertible, guaranteeing a unique solution $w^\\star$ for any given set of hyperparameters. The task is structured to yield a unique, stable, and meaningful result.\n*   **Objective**: The problem is stated using precise mathematical notation and objective, unambiguous language.\n*   **Flaw Checklist**: The problem does not violate any of the specified criteria for invalidity. It is scientifically sound, formalizable, complete, realistic within its simplified context, well-posed, and non-trivial.\n\n**1.3. Verdict and Action**\n\nThe problem is **valid**. I will proceed to develop a complete solution.\n\n### Step 2: Solution Derivation\n\nThe solution will be implemented by following a systematic procedure based on the provided mathematical framework.\n\n**2.1. Data Preparation and Target Generation**\nFirst, we construct the full training and validation matrices from the given components.\nThe training force feature matrix $X_F^{(\\mathrm{tr})}$ is formed by vertically stacking $-G_1, -G_2, -G_3$. The training stress feature matrix $X_S^{(\\mathrm{tr})}$ is formed by stacking $H_1, H_2, H_3$. Similarly, the validation force feature matrix $X_F^{(\\mathrm{val})}$ is formed by stacking $-G_4, -G_5$.\n\nNext, we generate the ground truth targets and the observed (noisy) training targets.\nThe true (noiseless) targets are computed using the ground truth parameter vector $w_{\\mathrm{true}}$:\n$$ y_E^{(\\mathrm{tr})}_{\\mathrm{true}} = X_E^{(\\mathrm{tr})} w_{\\mathrm{true}}, \\quad y_F^{(\\mathrm{tr})}_{\\mathrm{true}} = X_F^{(\\mathrm{tr})} w_{\\mathrm{true}}, \\quad y_S^{(\\mathrm{tr})}_{\\mathrm{true}} = X_S^{(\\mathrm{tr})} w_{\\mathrm{true}} $$\nThe observed training targets are then found by adding the provided noise vectors:\n$$ y_E^{(\\mathrm{tr})} = y_E^{(\\mathrm{tr})}_{\\mathrm{true}} + \\delta_E^{(\\mathrm{tr})}, \\quad y_F^{(\\mathrm{tr})} = y_F^{(\\mathrm{tr})}_{\\mathrm{true}} + \\delta_F^{(\\mathrm{tr})}, \\quad y_S^{(\\mathrm{tr})} = y_S^{(\\mathrm{tr})}_{\\mathrm{true}} + \\delta_S^{(\\mathrm{tr})} $$\nThe validation targets are noiseless, as specified:\n$$ y_E^{(\\mathrm{val})} = X_E^{(\\mathrm{val})} w_{\\mathrm{true}}, \\quad y_F^{(\\mathrm{val})} = X_F^{(\\mathrm{val})} w_{\\mathrm{true}} $$\n\n**2.2. Training via Normal Equations**\nFor each pair of $(\\lambda_E, \\lambda_F)$ from the specified grid $\\{0.1, 1.0, 10.0\\} \\times \\{0.1, 1.0, 10.0\\}$, we solve for the optimal parameter vector $w^\\star$. The normal equations are a linear system $A w^\\star = b$, where:\n*   The matrix $A \\in \\mathbb{R}^{3 \\times 3}$ is given by:\n    $$ A = \\lambda_E \\left({X_E^{(\\mathrm{tr})}}^\\top X_E^{(\\mathrm{tr})}\\right) + \\lambda_F \\left({X_F^{(\\mathrm{tr})}}^\\top X_F^{(\\mathrm{tr})}\\right) + \\lambda_S \\left({X_S^{(\\mathrm{tr})}}^\\top X_S^{(\\mathrm{tr})}\\right) + \\gamma I $$\n*   The vector $b \\in \\mathbb{R}^{3}$ is given by:\n    $$ b = \\lambda_E \\left({X_E^{(\\mathrm{tr})}}^\\top y_E^{(\\mathrm{tr})}\\right) + \\lambda_F \\left({X_F^{(\\mathrm{tr})}}^\\top y_F^{(\\mathrm{tr})}\\right) + \\lambda_S \\left({X_S^{(\\mathrm{tr})}}^\\top y_S^{(\\mathrm{tr})}\\right) $$\nTo optimize computation, the matrix products ${X}^\\top X$ and vector products ${X}^\\top y$ can be pre-calculated. The system is then solved for $w^\\star = A^{-1}b$.\n\n**2.3. Validation and Performance Evaluation**\nWith the optimal $w^\\star$ for each $(\\lambda_E, \\lambda_F)$ pair, we predict the energy and force values for the validation set:\n$$ \\hat{y}_E^{(\\mathrm{val})} = X_E^{(\\mathrm{val})} w^\\star, \\quad \\hat{y}_F^{(\\mathrm{val})} = X_F^{(\\mathrm{val})} w^\\star $$\nThe validation mean absolute errors are then calculated:\n$$ \\mathrm{MAE}_E = \\frac{1}{n_{\\mathrm{val}}} \\sum_{i=1}^{n_{\\mathrm{val}}} |\\hat{y}_{E,i}^{(\\mathrm{val})} - y_{E,i}^{(\\mathrm{val})}|, \\quad \\mathrm{MAE}_F = \\frac{1}{m_{\\mathrm{val}}} \\sum_{j=1}^{m_{\\mathrm{val}}} |\\hat{y}_{F,j}^{(\\mathrm{val})} - y_{F,j}^{(\\mathrm{val})}| $$\nWe will store the tuple $(\\lambda_E, \\lambda_F, \\mathrm{MAE}_E, \\mathrm{MAE}_F)$ for each of the $9$ hyperparameter settings.\n\n**2.4. Pareto Frontier Identification**\nFrom the set of $9$ calculated points $(\\mathrm{MAE}_E, \\mathrm{MAE}_F)$, we identify the Pareto frontier. A point $(e_i, f_i)$ is on the Pareto frontier if there is no other point $(e_j, f_j)$ in the set such that $e_j \\le e_i$ and $f_j \\le f_i$, with at least one of these inequalities being strict. We will iterate through all pairs of points to check for this dominance relationship and count the number of non-dominated points.\n\n**2.5. Optimal Hyperparameter Selection**\nFor each value of $\\alpha \\in \\{0.0, 0.5, 1.0\\}$, we find the $(\\lambda_E, \\lambda_F)$ pair from our grid that minimizes the scalarized objective $J(\\alpha) = \\alpha \\,\\mathrm{MAE}_E + (1 - \\alpha)\\,\\mathrm{MAE}_F$. We will compute $J(\\alpha)$ for all $9$ stored results. To find the optimal pair, we will sort the results first by their $J(\\alpha)$ value, then by $\\lambda_E$, and finally by $\\lambda_F$ (all in ascending order) to handle ties as specified. The first element of this sorted list gives the desired $(\\lambda_E, \\lambda_F)$ pair.\n\nThis comprehensive procedure correctly addresses all aspects of the problem, from data processing and model training to performance analysis and result reporting. The final implementation will package these steps into a single, self-contained program.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the GNN potential problem by performing weighted linear regression,\n    evaluating on a validation set, and analyzing the trade-off frontier.\n    \"\"\"\n\n    # --- Step 1: Define all given data and hyperparameters ---\n    p = 3  # Number of features\n    n_train_struct = 3\n    n_val_struct = 2\n    n_force_comp_per_struct = 6\n    n_stress_comp_per_struct = 6\n\n    # Hyperparameters\n    lambda_S = 0.1\n    gamma = 1e-4\n\n    # Grid for tuning\n    lambda_E_grid = [0.1, 1.0, 10.0]\n    lambda_F_grid = [0.1, 1.0, 10.0]\n    alpha_suite = [0.0, 0.5, 1.0]\n    \n    # Ground truth parameter vector\n    w_true = np.array([0.8, -0.3, 0.5])\n\n    # Training dataset features\n    X_E_tr = np.array([\n        [1.2, 0.5, -0.1],\n        [0.9, -0.2, 0.4],\n        [1.5, 0.1, 0.2]\n    ])\n    G1 = np.array([\n        [0.2, -0.1, 0.0], [-0.3, 0.2, 0.1], [0.1, 0.0, -0.2],\n        [-0.1, 0.3, 0.2], [0.0, -0.2, 0.1], [0.2, 0.1, -0.1]\n    ])\n    G2 = np.array([\n        [0.1, 0.2, -0.1], [-0.2, 0.1, 0.0], [0.0, -0.1, 0.2],\n        [0.3, -0.2, 0.1], [-0.1, 0.0, 0.3], [0.2, -0.3, 0.0]\n    ])\n    G3 = np.array([\n        [0.2, -0.2, 0.1], [0.1, 0.0, -0.1], [-0.3, 0.2, 0.0],\n        [0.0, -0.1, 0.3], [0.1, 0.3, -0.2], [-0.2, 0.1, 0.2]\n    ])\n    X_F_tr = -np.vstack([G1, G2, G3])\n\n    H1 = np.array([\n        [0.05, -0.02, 0.01], [0.01, 0.03, -0.02], [0.02, -0.01, 0.04],\n        [0.03, 0.01, -0.03], [-0.02, 0.04, 0.01], [0.01, -0.03, 0.02]\n    ])\n    H2 = np.array([\n        [0.04, 0.02, -0.01], [-0.01, 0.03, 0.02], [0.02, 0.01, -0.03],\n        [0.03, -0.02, 0.01], [0.01, -0.01, 0.04], [-0.02, 0.02, 0.03]\n    ])\n    H3 = np.array([\n        [0.03, -0.01, 0.02], [0.02, 0.04, -0.01], [-0.01, 0.03, 0.01],\n        [0.04, -0.02, 0.02], [0.01, 0.02, -0.03], [-0.03, 0.01, 0.04]\n    ])\n    X_S_tr = np.vstack([H1, H2, H3])\n\n    # Validation dataset features\n    X_E_val = np.array([\n        [1.1, 0.3, 0.0],\n        [0.7, -0.1, 0.5]\n    ])\n    G4 = np.array([\n        [0.1, -0.1, 0.2], [-0.1, 0.2, 0.0], [0.2, 0.0, -0.2],\n        [-0.2, 0.1, 0.2], [0.0, -0.2, 0.1], [0.1, 0.3, -0.1]\n    ])\n    G5 = np.array([\n        [0.2, 0.1, -0.2], [-0.3, 0.2, 0.1], [0.1, -0.2, 0.0],\n        [0.0, 0.1, 0.3], [0.3, -0.1, 0.2], [-0.2, 0.0, -0.1]\n    ])\n    X_F_val = -np.vstack([G4, G5])\n    \n    # Noise vectors\n    delta_E_tr = np.array([0.01, -0.02, 0.015])\n    delta_F_tr = np.array([\n        0.01, -0.008, 0.005, -0.006, 0.004, -0.007,\n        0.006, -0.005, 0.003, 0.0, -0.004, 0.005,\n        -0.002, 0.004, -0.006, 0.005, -0.003, 0.007\n    ])\n    delta_S_tr = np.array([\n        0.002, -0.001, 0.002, -0.001, 0.0005, -0.002,\n        0.001, 0.002, -0.001, 0.0015, -0.0005, 0.002,\n        -0.001, 0.001, 0.002, -0.0015, 0.0025, -0.001\n    ])\n\n    # --- Step 2: Generate target vectors ---\n    # Observed training targets (true + noise)\n    y_E_tr = X_E_tr @ w_true + delta_E_tr\n    y_F_tr = X_F_tr @ w_true + delta_F_tr\n    y_S_tr = X_S_tr @ w_true + delta_S_tr\n    \n    # Noiseless validation targets\n    y_E_val = X_E_val @ w_true\n    y_F_val = X_F_val @ w_true\n\n    # --- Step 3: Train models on the grid and evaluate ---\n    # Pre-compute matrix products for efficiency\n    XtX_E = X_E_tr.T @ X_E_tr\n    XtX_F = X_F_tr.T @ X_F_tr\n    XtX_S = X_S_tr.T @ X_S_tr\n    \n    Xty_E = X_E_tr.T @ y_E_tr\n    Xty_F = X_F_tr.T @ y_F_tr\n    Xty_S = X_S_tr.T @ y_S_tr\n    \n    gammaI = gamma * np.identity(p)\n    \n    results = []\n    \n    for lambda_E in lambda_E_grid:\n        for lambda_F in lambda_F_grid:\n            # Form the normal equations: A w* = b\n            A = lambda_E * XtX_E + lambda_F * XtX_F + lambda_S * XtX_S + gammaI\n            b = lambda_E * Xty_E + lambda_F * Xty_F + lambda_S * Xty_S\n            \n            # Solve for the optimal weights\n            w_star = np.linalg.solve(A, b)\n            \n            # Predict on validation set\n            E_pred = X_E_val @ w_star\n            F_pred = X_F_val @ w_star\n            \n            # Calculate validation MAEs\n            mae_E = np.mean(np.abs(E_pred - y_E_val))\n            mae_F = np.mean(np.abs(F_pred - y_F_val))\n            \n            results.append({\n                \"lambda_E\": lambda_E, \"lambda_F\": lambda_F,\n                \"mae_E\": mae_E, \"mae_F\": mae_F\n            })\n\n    # --- Step 4: Find the Pareto frontier ---\n    pareto_points = []\n    for i, p1 in enumerate(results):\n        is_dominated = False\n        for j, p2 in enumerate(results):\n            if i == j:\n                continue\n            # Check if p2 dominates p1\n            if (p2[\"mae_E\"] = p1[\"mae_E\"] and p2[\"mae_F\"] = p1[\"mae_F\"]) and \\\n               (p2[\"mae_E\"]  p1[\"mae_E\"] or p2[\"mae_F\"]  p1[\"mae_F\"]):\n                is_dominated = True\n                break\n        if not is_dominated:\n            pareto_points.append(p1)\n    \n    N_Pareto = len(pareto_points)\n\n    # --- Step 5: Find best lambdas for each alpha ---\n    final_output_list = []\n    for alpha in alpha_suite:\n        # Calculate scalarized objective J for each result\n        for res in results:\n            res[\"J\"] = alpha * res[\"mae_E\"] + (1 - alpha) * res[\"mae_F\"]\n            \n        # Sort results based on J, then lambda_E, then lambda_F to find the best\n        # This handles the specified tie-breaking rule.\n        best_res = sorted(results, key=lambda x: (x[\"J\"], x[\"lambda_E\"], x[\"lambda_F\"]))[0]\n        \n        final_output_list.append(best_res[\"lambda_E\"])\n        final_output_list.append(best_res[\"lambda_F\"])\n    \n    final_output_list.append(N_Pareto)\n    \n    # --- Step 6: Format and print the final output ---\n    formatted_results = []\n    for i, val in enumerate(final_output_list):\n        if i  6: # The lambda values\n            formatted_results.append(f\"{val:.3f}\")\n        else: # The Pareto count\n            formatted_results.append(str(val))\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n\n```", "id": "3455782"}, {"introduction": "The true power of a trained GNN potential lies in its ability to predict complex material properties that emerge from atomistic interactions. A prime example is the calculation of a material's elastic response, encapsulated by the fourth-order elastic stiffness tensor $C_{ijkl}$. In this advanced practice [@problem_id:3455813], you will use a surrogate GNN potential to compute this tensor by applying small, finite strains to a crystal lattice and numerically calculating the second derivative of the energy, bridging the scale from individual atoms to continuum mechanics.", "problem": "You will implement a program that computes the fourth-order elastic stiffness tensor for a periodic crystalline system by numerically differentiating the total energy predicted by a simplified graph neural network potential surrogate, then verifies the major symmetry $C_{ijkl} = C_{klij}$ numerically. Use the following fundamental definitions and constraints.\n\nYou must start from the fundamental definition that the elastic stiffness tensor is the second derivative of the total energy with respect to the Lagrangian small-strain tensor, that is, $C_{ijkl} = \\frac{1}{V_{0}} \\frac{\\partial^{2} E}{\\partial \\epsilon_{ij} \\partial \\epsilon_{kl}}$ evaluated at zero strain, where $V_{0}$ is the reference volume. Use homogeneous small strains so that the deformation gradient is $F = I + \\epsilon$ with $\\epsilon$ symmetric. Use periodic boundary conditions and affine deformation of lattice vectors.\n\nYou will compute the total energy using a simplified one-layer message-passing style graph neural network potential surrogate that preserves translational and rotational invariance by depending only on pairwise distances under periodic boundary conditions. The total energy is given by\n$$\nE = \\sum_{i=1}^{N} u\\!\\left( s_{i} \\right), \\quad s_{i} = \\sum_{j \\neq i} g\\!\\left(r_{ij}\\right) f_{c}\\!\\left(r_{ij}\\right),\n$$\nwhere $r_{ij}$ is the minimum-image distance under the strained lattice, $f_{c}(r)$ is a smooth cosine cutoff, $g(r)$ is a radial message function, and $u(s)$ is a nonlinear atomic energy head:\n$$\nf_{c}(r) = \\begin{cases}\n\\frac{1}{2}\\left(\\cos\\!\\left(\\pi r / r_{c}\\right) + 1\\right),  r  r_{c},\\\\\n0,  r \\ge r_{c},\n\\end{cases}\n\\quad\ng(r) = \\left(\\sum_{m=0}^{M} a_{m} r^{m}\\right) \\exp\\!\\left(- \\left(\\frac{r}{c_{r}}\\right)^{2}\\right),\n\\quad\nu(s) = b_{0} + b_{1} s + b_{2} s^{2} + b_{3} \\tanh(s).\n$$\nAll atoms are identical and the graph is defined implicitly by the cutoff. The periodic supercell is a $2 \\times 2 \\times 2$ replication of a body-centered cubic cell with lattice constant $a$ and basis at fractional coordinates $\\{(0,0,0), (1/2,1/2,1/2)\\}$. The reference lattice vectors are $L_{0} = \\operatorname{diag}(2a, 2a, 2a)$, and fractional coordinates are held fixed while the lattice vectors are affinely deformed, so that the strained lattice is $L(\\epsilon) = (I + \\epsilon) L_{0}$.\n\nTo compute the second derivatives, parameterize the six independent components of the symmetric strain tensor by a vector $x \\in \\mathbb{R}^{6}$ via\n$$\n\\epsilon(x) = \\sum_{\\alpha=1}^{6} x_{\\alpha} S^{(\\alpha)},\n$$\nwith symmetric basis matrices $S^{(1)} = \\begin{bmatrix}100\\\\000\\\\000\\end{bmatrix}$, $S^{(2)} = \\begin{bmatrix}000\\\\010\\\\000\\end{bmatrix}$, $S^{(3)} = \\begin{bmatrix}000\\\\000\\\\001\\end{bmatrix}$, $S^{(4)} = \\frac{1}{2}(e_{23}+e_{32})$, $S^{(5)} = \\frac{1}{2}(e_{13}+e_{31})$, $S^{(6)} = \\frac{1}{2}(e_{12}+e_{21})$, where $e_{ij}$ is the matrix with a $1$ in the $(i,j)$ entry and $0$ elsewhere. Let $H \\in \\mathbb{R}^{6 \\times 6}$ denote the Hessian matrix of $E$ with respect to the components of $x$ at $x=0$, computed by the central mixed-difference formula derived from the Taylor expansion:\n$$\n\\frac{\\partial^{2} E}{\\partial x_{\\alpha} \\partial x_{\\beta}} \\approx \\frac{E(x_{\\alpha}{+}h, x_{\\beta}{+}h) - E(x_{\\alpha}{+}h, x_{\\beta}{-}h) - E(x_{\\alpha}{-}h, x_{\\beta}{+}h) + E(x_{\\alpha}{-}h, x_{\\beta}{-}h)}{4 h^{2}},\n$$\nwith all other components of $x$ held at $0$, and a finite difference step size $h$ provided in each test case.\n\nRecover the fourth-order stiffness tensor $C_{ijkl}$ using the dual basis $P^{(\\alpha)}$ defined by $\\sum_{i,j} P^{(\\alpha)}_{ij} S^{(\\beta)}_{ij} = \\delta_{\\alpha\\beta}$, which here is $P^{(1)}_{11}=1$, $P^{(2)}_{22}=1$, $P^{(3)}_{33}=1$, $P^{(4)}_{23}=P^{(4)}_{32}=1$, $P^{(5)}_{13}=P^{(5)}_{31}=1$, $P^{(6)}_{12}=P^{(6)}_{21}=1$, and zero otherwise. Then\n$$\nC_{ijkl} = \\frac{1}{V_{0}} \\sum_{\\alpha=1}^{6} \\sum_{\\beta=1}^{6} H_{\\alpha \\beta}\\, P^{(\\alpha)}_{ij}\\, P^{(\\beta)}_{kl}.\n$$\nThe units are: total energy in electronvolts ($\\mathrm{eV}$), lengths in angstroms ($\\mathrm{\\AA}$), and volume in $\\mathrm{\\AA}^{3}$. Convert $C_{ijkl}$ to gigapascals ($\\mathrm{GPa}$) using $1\\,\\mathrm{eV}/\\mathrm{\\AA}^{3} = 160.21766208\\,\\mathrm{GPa}$.\n\nYour task is to write a complete program that implements the above and, for each test case below, computes the maximum absolute deviation from the major symmetry,\n$$\n\\Delta_{\\max} = \\max_{i,j,k,l \\in \\{1,2,3\\}} \\left| C_{ijkl} - C_{klij} \\right| \\quad \\text{in} \\ \\mathrm{GPa},\n$$\nevaluated at zero strain. Report each $\\Delta_{\\max}$ for the provided test cases in a single list.\n\nTest suite and parameters:\n- Crystal and cell: body-centered cubic with lattice constant $a = 3.3\\,\\mathrm{\\AA}$; use a $2 \\times 2 \\times 2$ supercell, so $L_{0} = \\operatorname{diag}(2a,2a,2a)$ and $V_{0} = \\det(L_{0})$.\n- Neighbor detection: minimum-image convention with the strained lattice $L(\\epsilon)$.\n- Cutoff: $r_{c} = 3.2\\,\\mathrm{\\AA}$; in $g(r)$ use $c_{r} = r_{c}$; $M=3$ in $g(r)$.\n- Three independent test cases, each specified by a tuple $(h, \\{a_{m}\\}_{m=0}^{3}, \\{b_{n}\\}_{n=0}^{3})$:\n    1. Test $1$: $h = 1.0 \\times 10^{-3}$, $a_{0} = 0.8$, $a_{1} = -0.4$, $a_{2} = 0.05$, $a_{3} = -0.005$, $b_{0} = 0.0$, $b_{1} = 1.2$, $b_{2} = 0.15$, $b_{3} = 0.2$.\n    2. Test $2$: $h = 1.0 \\times 10^{-5}$, $a_{0} = 0.5$, $a_{1} = 0.1$, $a_{2} = -0.03$, $a_{3} = 0.002$, $b_{0} = 0.0$, $b_{1} = 0.9$, $b_{2} = 0.25$, $b_{3} = 0.1$.\n    3. Test $3$: $h = 5.0 \\times 10^{-2}$, $a_{0} = 1.0$, $a_{1} = -0.6$, $a_{2} = 0.08$, $a_{3} = 0.0$, $b_{0} = 0.0$, $b_{1} = 0.7$, $b_{2} = 0.05$, $b_{3} = 0.3$.\n\nYour program must:\n- Build the $2 \\times 2 \\times 2$ body-centered cubic supercell fractional coordinates and the reference lattice $L_{0}$.\n- For each test case, compute the Hessian $H$ by central mixed differences at zero strain using step size $h$ for the six independent strain parameters, reconstruct $C_{ijkl}$ in $\\mathrm{GPa}$, and compute $\\Delta_{\\max}$.\n- Final output format: print a single line containing a Python-style list of three floats corresponding to $\\Delta_{\\max}$ for the three test cases in the order listed, e.g., \"[x1,x2,x3]\". Each value must be expressed in $\\mathrm{GPa}$.\n\nExpress the final answers in $\\mathrm{GPa}$ as plain floats in the list. No additional text should be printed.", "solution": "The problem requires the implementation of a program to compute the fourth-order elastic stiffness tensor, $C_{ijkl}$, for a periodic crystal. The calculation is based on numerically differentiating a simplified graph neural network (GNN) potential with respect to strain. The final step is to numerically verify the major symmetry of the computed tensor, $C_{ijkl} = C_{klij}$. The process is a standard energy-strain methodology applied to a surrogate model. The solution is implemented in a series of logical steps.\n\nFirst, the crystalline system is defined. The structure is body-centered cubic (BCC) with a lattice constant of $a = 3.3\\,\\mathrm{\\AA}$. A $2 \\times 2 \\times 2$ supercell is used for the calculation. The reference (undeformed) lattice vectors are given by $L_{0} = \\operatorname{diag}(2a, 2a, 2a)$, defining a cubic simulation box of side $6.6\\,\\mathrm{\\AA}$. The reference volume is $V_{0} = \\det(L_{0}) = (2a)^3$. The conventional BCC cell contains two atoms at fractional coordinates $(0,0,0)$ and $(1/2, 1/2, 1/2)$. Replicating this cell $2 \\times 2 \\times 2$ times results in a supercell containing $N=16$ atoms. The fractional coordinates of these $16$ atoms with respect to the supercell lattice $L_0$ are systematically generated.\n\nSecond, the total energy $E$ of the system is calculated using the provided GNN potential surrogate for a given strain state. The strain is described by a symmetric second-order tensor $\\epsilon$. The deformation is affine, meaning the lattice vectors are transformed as $L(\\epsilon) = (I + \\epsilon)L_{0}$, where $I$ is the $3 \\times 3$ identity matrix. The atomic positions in the strained configuration are given by $\\vec{r}'_i = L(\\epsilon)\\vec{f}_i$, where $\\vec{f}_i$ are the reference fractional coordinates. The total energy is a sum of atomic contributions, $E = \\sum_{i=1}^{N} u(s_i)$. Each atomic feature $s_i$ is a sum over neighboring atoms $j$, $s_i = \\sum_{j \\neq i} g(r_{ij}) f_{c}(r_{ij})$. The term $r_{ij}$ is the minimum image distance between atoms $i$ and $j$ in the strained periodic cell, computed as $r_{ij} = \\min_{n \\in \\mathbb{Z}^3} || \\vec{r}'_j - \\vec{r}'_i + L\\vec{n} ||$. This is implemented by first finding the displacement vector in fractional coordinates, $\\Delta\\vec{f} = L^{-1}(\\vec{r}'_j - \\vec{r}'_i)$, applying the minimum image convention to its components, $\\Delta f_k' = \\Delta f_k - \\operatorname{round}(\\Delta f_k)$, and transforming back to a Cartesian vector, whose norm is $r_{ij}$. The functions involved are the smooth cosine cutoff $f_c(r)$, the radial message function $g(r)$, and the atomic energy head $u(s)$, defined as:\n$$\nf_{c}(r) = \\begin{cases}\n\\frac{1}{2}\\left(\\cos\\!\\left(\\pi r / r_{c}\\right) + 1\\right),  r  r_{c},\\\\\n0,  r \\ge r_{c},\n\\end{cases}\n$$\n$$\ng(r) = \\left(\\sum_{m=0}^{M} a_{m} r^{m}\\right) \\exp\\!\\left(- \\left(\\frac{r}{c_{r}}\\right)^{2}\\right),\n$$\n$$\nu(s) = b_{0} + b_{1} s + b_{2} s^{2} + b_{3} \\tanh(s).\n$$\nThe parameters $r_c$, $c_r$, $M$, and the coefficients $\\{a_m\\}$ and $\\{b_n\\}$ are provided for each test case.\n\nThird, the second derivatives of the energy with respect to strain are computed numerically to find the elastic tensor, defined as $C_{ijkl} = \\frac{1}{V_{0}} \\frac{\\partial^{2} E}{\\partial \\epsilon_{ij} \\partial \\epsilon_{kl}}|_{\\epsilon=0}$. To facilitate this, the $3 \\times 3$ symmetric strain tensor $\\epsilon$ is parameterized by a $6$-dimensional vector $x$ using a basis of symmetric matrices $\\{S^{(\\alpha)}\\}_{\\alpha=1}^6$: $\\epsilon(x) = \\sum_{\\alpha=1}^{6} x_{\\alpha} S^{(\\alpha)}$. The second derivatives are then computed with respect to these parameters, forming a $6 \\times 6$ Hessian matrix $H_{\\alpha\\beta} = \\frac{\\partial^2 E}{\\partial x_\\alpha \\partial x_\\beta} |_{x=0}$. The computation uses the central mixed-difference formula:\n$$\nH_{\\alpha\\beta} \\approx \\frac{E(\\epsilon_{\\alpha\\beta}^{++}) - E(\\epsilon_{\\alpha\\beta}^{+-}) - E(\\epsilon_{\\alpha\\beta}^{-+}) + E(\\epsilon_{\\alpha\\beta}^{--})}{4 h^{2}},\n$$\nwhere $\\epsilon_{\\alpha\\beta}^{\\sigma_1\\sigma_2} = (\\sigma_1 h) S^{(\\alpha)} + (\\sigma_2 h) S^{(\\beta)}$ for $\\sigma_1, \\sigma_2 \\in \\{+,-\\}$. This requires four energy evaluations for each of the $36$ components of the Hessian.\n\nFourth, the full fourth-order tensor $C_{ijkl}$ is reconstructed from the Hessian matrix $H$. This requires a transformation from the $6$-dimensional component space back to the tensor space. The transformation is achieved using the dual basis $\\{P^{(\\alpha)}\\}_{\\alpha=1}^6$, which satisfies $\\sum_{i,j} P^{(\\alpha)}_{ij} S^{(\\beta)}_{ij} = \\delta_{\\alpha\\beta}$. The reconstruction formula is:\n$$\nC_{ijkl} = \\frac{1}{V_{0}} \\sum_{\\alpha=1}^{6} \\sum_{\\beta=1}^{6} H_{\\alpha \\beta}\\, P^{(\\alpha)}_{ij}\\, P^{(\\beta)}_{kl}.\n$$\nThe resulting tensor has units of energy per volume ($\\mathrm{eV}/\\mathrm{\\AA}^{3}$), which is converted to gigapascals (GPa) using the provided factor $1\\,\\mathrm{eV}/\\mathrm{\\AA}^{3} = 160.21766208\\,\\mathrm{GPa}$.\n\nFinally, the major symmetry of the elastic tensor is verified. The major symmetry requires that $C_{ijkl} = C_{klij}$. Due to the numerical approximation in the finite difference method, this equality may not hold perfectly. The program calculates the maximum absolute deviation over all possible indices:\n$$\n\\Delta_{\\max} = \\max_{i,j,k,l \\in \\{1,2,3\\}} \\left| C_{ijkl} - C_{klij} \\right|.\n$$\nThis value, $\\Delta_{\\max}$, is the final result computed for each test case provided in the problem statement. The algorithm is implemented following these steps for each set of input parameters.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to compute and print the results for the given test cases.\n    \"\"\"\n    \n    # --- Problem Constants ---\n    EV_A3_TO_GPA = 160.21766208\n    A_LATTICE = 3.3\n    RC_CUTOFF = 3.2\n    CR_G = RC_CUTOFF\n    \n    # --- Test Cases ---\n    test_cases = [\n        (1.0e-3, [0.8, -0.4, 0.05, -0.005], [0.0, 1.2, 0.15, 0.2]),\n        (1.0e-5, [0.5, 0.1, -0.03, 0.002], [0.0, 0.9, 0.25, 0.1]),\n        (5.0e-2, [1.0, -0.6, 0.08, 0.0], [0.0, 0.7, 0.05, 0.3]),\n    ]\n    \n    results = []\n\n    # --- Pre-computation of static structures ---\n    \n    def get_bcc_supercell():\n        \"\"\"Generates the BCC supercell coordinates, lattice, and volume.\"\"\"\n        lattice_const = A_LATTICE\n        L0 = np.diag([2 * lattice_const, 2 * lattice_const, 2 * lattice_const])\n        V0 = np.linalg.det(L0)\n        \n        frac_coords = []\n        for i in range(2):\n            for j in range(2):\n                for k in range(2):\n                    frac_coords.append([i / 2.0, j / 2.0, k / 2.0])\n                    frac_coords.append([(i + 0.5) / 2.0, (j + 0.5) / 2.0, (k + 0.5) / 2.0])\n        return np.array(frac_coords), L0, V0\n\n    def get_basis_tensors():\n        \"\"\"Generates the strain basis S and dual basis P.\"\"\"\n        S = np.zeros((6, 3, 3))\n        S[0, 0, 0] = 1.0\n        S[1, 1, 1] = 1.0\n        S[2, 2, 2] = 1.0\n        S[3, 1, 2] = S[3, 2, 1] = 0.5\n        S[4, 0, 2] = S[4, 2, 0] = 0.5\n        S[5, 0, 1] = S[5, 1, 0] = 0.5\n\n        P = np.zeros((6, 3, 3))\n        P[0, 0, 0] = 1.0\n        P[1, 1, 1] = 1.0\n        P[2, 2, 2] = 1.0\n        P[3, 1, 2] = P[3, 2, 1] = 1.0\n        P[4, 0, 2] = P[4, 2, 0] = 1.0\n        P[5, 0, 1] = P[5, 1, 0] = 1.0\n        \n        return S, P\n\n    frac_coords, L0, V0 = get_bcc_supercell()\n    S_basis, P_basis = get_basis_tensors()\n    num_atoms = frac_coords.shape[0]\n\n    # --- GNN Potential Functions ---\n    \n    def f_c_func(r):\n        \"\"\"Smooth cosine cutoff function.\"\"\"\n        if r >= RC_CUTOFF:\n            return 0.0\n        return 0.5 * (np.cos(np.pi * r / RC_CUTOFF) + 1.0)\n\n    def g_func(r, a_params):\n        \"\"\"Radial message function g(r).\"\"\"\n        # np.polyval requires coefficients in decreasing order of power.\n        poly = np.polyval(a_params[::-1], r) \n        exp_term = np.exp(-(r / CR_G)**2)\n        return poly * exp_term\n\n    def u_func(s, b_params):\n        \"\"\"Atomic energy head u(s).\"\"\"\n        b0, b1, b2, b3 = b_params\n        return b0 + b1 * s + b2 * s**2 + b3 * np.tanh(s)\n\n    # --- Energy Calculation ---\n\n    def compute_total_energy(epsilon, a_params, b_params):\n        \"\"\"Computes the total energy of the system for a given strain.\"\"\"\n        L = (np.eye(3) + epsilon) @ L0\n        \n        try:\n            L_inv = np.linalg.inv(L)\n        except np.linalg.LinAlgError:\n            return np.inf\n\n        cart_coords = frac_coords @ L.T\n        atomic_s = np.zeros(num_atoms)\n        \n        for i in range(num_atoms):\n            for j in range(i + 1, num_atoms):\n                d_cart = cart_coords[j] - cart_coords[i]\n                \n                # Minimum Image Convention\n                d_frac = d_cart @ L_inv.T\n                d_frac_mic = d_frac - np.round(d_frac)\n                d_cart_mic = d_frac_mic @ L.T\n                \n                r_ij = np.linalg.norm(d_cart_mic)\n                \n                if r_ij  RC_CUTOFF:\n                    val = g_func(r_ij, a_params) * f_c_func(r_ij)\n                    atomic_s[i] += val\n                    atomic_s[j] += val\n\n        total_energy = np.sum(u_func(atomic_s, b_params))\n        return total_energy\n\n    # --- Main Calculation Loop ---\n    for h, a_params, b_params in test_cases:\n        \n        # 1. Compute Hessian H\n        H = np.zeros((6, 6))\n        for alpha in range(6):\n            for beta in range(alpha, 6): # Exploit symmetry H_ab = H_ba\n                e1 = h * S_basis[alpha] + h * S_basis[beta]\n                e2 = h * S_basis[alpha] - h * S_basis[beta]\n                e3 = -h * S_basis[alpha] + h * S_basis[beta]\n                e4 = -h * S_basis[alpha] - h * S_basis[beta]\n                \n                E1 = compute_total_energy(e1, a_params, b_params)\n                E2 = compute_total_energy(e2, a_params, b_params)\n                E3 = compute_total_energy(e3, a_params, b_params)\n                E4 = compute_total_energy(e4, a_params, b_params)\n\n                val = (E1 - E2 - E3 + E4) / (4 * h**2)\n                H[alpha, beta] = val\n                if alpha != beta:\n                    H[beta, alpha] = val\n\n        # 2. Reconstruct elastic tensor C\n        C = np.zeros((3, 3, 3, 3))\n        for i in range(3):\n            for j in range(3):\n                for k in range(3):\n                    for l in range(3):\n                        val = 0.0\n                        for alpha in range(6):\n                            for beta in range(6):\n                                val += H[alpha, beta] * P_basis[alpha, i, j] * P_basis[beta, k, l]\n                        C[i, j, k, l] = val\n        \n        C /= V0\n        C *= EV_A3_TO_GPA\n\n        # 3. Check major symmetry\n        max_deviation = 0.0\n        for i in range(3):\n            for j in range(3):\n                for k in range(3):\n                    for l in range(3):\n                        deviation = np.abs(C[i, j, k, l] - C[k, l, i, j])\n                        if deviation > max_deviation:\n                            max_deviation = deviation\n        \n        results.append(max_deviation)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3455813"}]}