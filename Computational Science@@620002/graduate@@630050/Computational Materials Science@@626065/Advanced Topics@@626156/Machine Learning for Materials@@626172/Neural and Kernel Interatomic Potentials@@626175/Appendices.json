{"hands_on_practices": [{"introduction": "A central challenge in developing interatomic potentials is choosing a representation, or descriptor, of a local atomic environment that is both computationally efficient and sufficiently informative. This exercise directly confronts this challenge by exploring the limitations of the simplest possible descriptor: a histogram of pairwise distances. By constructing two geometrically distinct atomic configurations that share an identical distance histogram but possess different true energies, you will gain a firsthand understanding of why angular information is indispensable and why more sophisticated, many-body descriptors are necessary for accurate materials modeling [@problem_id:3468348].", "problem": "You are given two representations of atomic configurations: a full coordinate set in Euclidean space and a reduced feature vector given by a histogram of pairwise distances. Consider a three-body potential energy that depends on bond angles and radial decays, which cannot, in general, be reconstructed from pairwise histograms alone. Your task is to construct explicit counterexamples demonstrating this insufficiency and to quantify the irreducible bias any model restricted to pairwise distance histograms must incur.\n\nDefinitions and fundamental base:\n- Let there be $N$ atoms with positions $\\{\\mathbf{r}_i\\}_{i=1}^N$ in $\\mathbb{R}^3$. The unordered pairwise distances are $r_{ij} = \\|\\mathbf{r}_i - \\mathbf{r}_j\\|$ for $1 \\le i < j \\le N$.\n- Fix a bin edge vector $\\mathbf{b} = (b_0,b_1,\\dots,b_B)$ with $b_0 < b_1 < \\cdots < b_B$. Define the pairwise distance histogram feature $\\mathbf{H} \\in \\mathbb{Z}_{\\ge 0}^B$ by counting, for each bin index $m \\in \\{1,\\dots,B\\}$,\n$$\nH_m = \\left|\\left\\{(i,j) \\,\\middle|\\, 1 \\le i < j \\le N,\\, r_{ij} \\in [b_{m-1}, b_m) \\right\\}\\right|.\n$$\n- Define a three-body energy with angular dependence using the second Legendre polynomial. For a given radial scale $\\sigma > 0$, radial function $f(r) = \\exp\\!\\left(-\\left(\\frac{r}{\\sigma}\\right)^2\\right)$, and $P_2(x) = \\frac{1}{2}\\left(3x^2 - 1\\right)$, set\n$$\nE_3(\\{\\mathbf{r}_i\\}; \\sigma) = \\sum_{i=1}^N \\ \\sum_{\\substack{j<k \\\\ j \\ne i,\\, k \\ne i}} f(r_{ij})\\, f(r_{ik})\\, P_2\\!\\left(\\cos \\theta_{jik}\\right),\n$$\nwhere $\\theta_{jik}$ is the angle at atom $i$ formed by vectors $\\mathbf{r}_j - \\mathbf{r}_i$ and $\\mathbf{r}_k - \\mathbf{r}_i$, i.e.,\n$$\n\\cos \\theta_{jik} = \\frac{(\\mathbf{r}_j - \\mathbf{r}_i)\\cdot(\\mathbf{r}_k - \\mathbf{r}_i)}{\\|\\mathbf{r}_j - \\mathbf{r}_i\\|\\, \\|\\mathbf{r}_k - \\mathbf{r}_i\\|}.\n$$\nThis energy is a simplified moment-tensor-like three-body term: it depends on both distances and angles and is rotationally and translationally invariant.\n\nIrreducible bias definition:\n- Consider any learned model restricted to the pairwise histogram, that is, any mapping $\\widehat{E}(\\mathbf{H})$ that uses only $\\mathbf{H}$ as input. If two configurations $\\mathcal{A}$ and $\\mathcal{B}$ have identical histograms $\\mathbf{H}(\\mathcal{A}) = \\mathbf{H}(\\mathcal{B})$, then $\\widehat{E}(\\mathbf{H}(\\mathcal{A})) = \\widehat{E}(\\mathbf{H}(\\mathcal{B}))$. Let the true three-body energies be $E_3(\\mathcal{A};\\sigma)$ and $E_3(\\mathcal{B};\\sigma)$. Then any such histogram-only model must incur, on at least one member of the pair, an absolute error no less than\n$$\n\\frac{1}{2}\\,\\left|E_3(\\mathcal{A};\\sigma) - E_3(\\mathcal{B};\\sigma)\\right|.\n$$\nWe call this quantity the irreducible bias lower bound for the pair.\n\nYour tasks:\n1. For each test case below, compute the pairwise distance histograms $\\mathbf{H}(\\mathcal{A})$ and $\\mathbf{H}(\\mathcal{B})$ using the specified bin edges and verify that they are identical. You do not need to output this verification; your program must rely on exact integer counts under the half-open interval convention $[b_{m-1}, b_m)$.\n2. Compute the three-body energies $E_3(\\mathcal{A};\\sigma)$ and $E_3(\\mathcal{B};\\sigma)$ using the definition above.\n3. Report the irreducible bias lower bound for each test case, defined as $\\frac{1}{2}\\,\\left|E_3(\\mathcal{A};\\sigma) - E_3(\\mathcal{B};\\sigma)\\right|$.\n\nUnits and numerical instructions:\n- Treat energy as dimensionless in arbitrary but consistent units; no physical unit conversion is required.\n- Use radians for all angular computations.\n- Output each bias as a floating-point number rounded to $6$ decimal places.\n\nTest suite:\nProvide results for the following three cases. Each case is a tuple specifying $(\\mathcal{A}, \\mathcal{B}, \\mathbf{b}, \\sigma)$.\n\n- Case $1$ (happy path, two-dimensional square versus rectangle with matching histograms under moderate binning):\n  - $\\mathcal{A}$ has $N=4$ atoms at positions $\\{(0,0,0),\\ (1,0,0),\\ (1,1,0),\\ (0,1,0)\\}$.\n  - $\\mathcal{B}$ has $N=4$ atoms at positions $\\{(0,0,0),\\ (0.9,0,0),\\ (0.9,1.1,0),\\ (0,1.1,0)\\}$.\n  - Bin edges $\\mathbf{b} = (0.0,\\, 1.2,\\, 2.0)$.\n  - Radial scale $\\sigma = 1.0$.\n\n- Case $2$ (significant degeneracy, coarse single-bin histogram equating very different structures):\n  - $\\mathcal{A}$ is a regular tetrahedron with side length $1$ at positions\n    $\\{(0,0,0),\\ (1,0,0),\\ (0.5, \\sqrt{3}/2, 0),\\ (0.5, \\sqrt{3}/6, \\sqrt{6}/3)\\}$.\n  - $\\mathcal{B}$ is the square from Case $1$: $\\{(0,0,0),\\ (1,0,0),\\ (1,1,0),\\ (0,1,0)\\}$.\n  - Bin edges $\\mathbf{b} = (0.0,\\, 2.0)$.\n  - Radial scale $\\sigma = 1.0$.\n\n- Case $3$ (edge case, vanishing interactions due to very small $\\sigma$):\n  - $\\mathcal{A}$ and $\\mathcal{B}$ are as in Case $1$.\n  - Bin edges $\\mathbf{b} = (0.0,\\, 1.2,\\, 2.0)$.\n  - Radial scale $\\sigma = 0.01$.\n\nRequired final output format:\n- Your program should produce a single line of output containing the three irreducible bias lower bounds, in order for Cases $1,2,3$, as a comma-separated list enclosed in square brackets, for example, $[x_1,x_2,x_3]$, where each $x_i$ is rounded to $6$ decimal places.", "solution": "The problem requires the construction and analysis of counterexamples to demonstrate that a feature vector based on a pairwise distance histogram is insufficient to uniquely determine a three-body interaction energy that depends on angles. We are tasked with quantifying the minimum unavoidable error, termed the irreducible bias, for any model restricted to such a histogram representation.\n\nThe core principle is that of information loss during featurization. The full geometric information of atomic positions $\\{\\mathbf{r}_i\\}_{i=1}^N$ in $\\mathbb{R}^3$ is projected onto a lower-dimensional feature space, in this case, the histogram of pairwise distances $\\mathbf{H}$. While this projection preserves some information (specifically, the distribution of interatomic distances), it discards other information, such as the angular correlations between triplets of atoms. A potential energy function, like the three-body term $E_3$ provided, that depends on this discarded information cannot be perfectly represented by a model $\\widehat{E}(\\mathbf{H})$ that only has access to the histogram.\n\nThe methodology to demonstrate this is as follows:\n1.  Define two distinct atomic configurations, $\\mathcal{A}$ and $\\mathcal{B}$, with atomic coordinates $\\{\\mathbf{r}_i^\\mathcal{A}\\}$ and $\\{\\mathbf{r}_i^\\mathcal{B}\\}$.\n2.  Choose bin edges $\\mathbf{b}$ such that the pairwise distance histograms of the two configurations are identical, i.e., $\\mathbf{H}(\\mathcal{A}) = \\mathbf{H}(\\mathcal{B})$. This creates a degeneracy or \"collision\" in the feature space.\n3.  Calculate the true three-body energies, $E_3(\\mathcal{A};\\sigma)$ and $E_3(\\mathcal{B};\\sigma)$, using the provided formula, which is sensitive to the three-dimensional geometry, including bond angles.\n4.  If $E_3(\\mathcal{A};\\sigma) \\ne E_3(\\mathcal{B};\\sigma)$, it proves that the histogram $\\mathbf{H}$ is an insufficient descriptor. Any model $\\widehat{E}$ that maps from $\\mathbf{H}$ to an energy prediction must assign the same value to both, $\\widehat{E}(\\mathbf{H}(\\mathcal{A})) = \\widehat{E}(\\mathbf{H}(\\mathcal{B}))$, leading to an error for at least one configuration. The lower bound on this error for the pair is the irreducible bias, given by $\\frac{1}{2}|E_3(\\mathcal{A};\\sigma) - E_3(\\mathcal{B};\\sigma)|$.\n\nThe algorithmic procedure to solve this for each test case is:\n\nFirst, we implement a function to compute the pairwise distances for a given set of $N$ atomic coordinates $\\{\\mathbf{r}_i\\}$. This involves iterating through all unique pairs of atoms $(i,j)$ with $1 \\le i < j \\le N$ and calculating the Euclidean norm $r_{ij} = \\|\\mathbf{r}_i - \\mathbf{r}_j\\|$.\n\nSecond, we implement a function to generate the histogram $\\mathbf{H}$. This function takes the list of pairwise distances and the bin edge vector $\\mathbf{b} = (b_0, b_1, \\dots, b_B)$ as input. For each bin $m \\in \\{1, \\dots, B\\}$, it counts the number of distances $r_{ij}$ that fall into the half-open interval $[b_{m-1}, b_m)$. This procedure must be executed for both configurations $\\mathcal{A}$ and $\\mathcal{B}$ to verify that their histograms are indeed identical, as stipulated by the problem.\n\nThird, we implement the calculation of the three-body energy, $E_3$. The formula is:\n$$\nE_3(\\{\\mathbf{r}_i\\}; \\sigma) = \\sum_{i=1}^N \\ \\sum_{\\substack{j<k \\\\ j \\ne i,\\, k \\ne i}} f(r_{ij})\\, f(r_{ik})\\, P_2\\!\\left(\\cos \\theta_{jik}\\right)\n$$\nThe sum is over all unique triplets of atoms, where for each triplet, each atom takes a turn as the central vertex $i$. The function iterates through each atom $i$ from $1$ to $N$. For each $i$, it then iterates through all unique pairs of other atoms, $\\{j, k\\}$. For each such triplet, it calculates the constituent terms:\n- The distances $r_{ij}$ and $r_{ik}$.\n- The radial decay function $f(r) = \\exp(-(r/\\sigma)^2)$.\n- The cosine of the angle $\\theta_{jik}$, computed from the dot product of the vectors from the central atom $i$ to its neighbors: $\\cos \\theta_{jik} = \\frac{(\\mathbf{r}_j - \\mathbf{r}_i)\\cdot(\\mathbf{r}_k - \\mathbf{r}_i)}{r_{ij} r_{ik}}$.\n- The second Legendre polynomial $P_2(x) = \\frac{1}{2}(3x^2 - 1)$.\nThe product of these terms is added to a running total, which yields $E_3$ after all triplets have been considered.\n\nFinally, for each test case, we compute $E_3(\\mathcal{A})$ and $E_3(\\mathcal{B})$ and then the irreducible bias lower bound: $\\frac{1}{2}|E_3(\\mathcal{A}) - E_3(\\mathcal{B})|$.\n\nFor the specific cases:\n- Case 1: A square ($\\mathcal{A}$) and a slightly distorted rectangle ($\\mathcal{B}$) are constructed to have identical distance histograms under a specific binning scheme $\\mathbf{b} = (0.0, 1.2, 2.0)$. $\\mathcal{A}$ has four distances of $1.0$ and two of $\\sqrt{2} \\approx 1.414$. $\\mathcal{B}$ has two of $0.9$, two of $1.1$, and two of $\\sqrt{2.02} \\approx 1.421$. With the given bins, both result in $\\mathbf{H} = [4, 2]$. However, the bond angles in $\\mathcal{A}$ are $90^\\circ$ and $45^\\circ$, while in $\\mathcal{B}$ they are $90^\\circ$ and other angles determined by the rectangle's geometry. This difference in angular information leads to $E_3(\\mathcal{A}) \\ne E_3(\\mathcal{B})$, resulting in a non-zero bias.\n\n- Case 2: A regular tetrahedron ($\\mathcal{A}$) and a square ($\\mathcal{B}$) are compared. Using a very coarse binning $\\mathbf{b} = (0.0, 2.0)$, their vastly different distance distributions are aliased into the same histogram. The tetrahedron has six equal-length bonds of $1.0$. The square has four bonds of $1.0$ and two of $\\sqrt{2}$. All twelve distances are less than $2.0$, so both yield $\\mathbf{H} = [6]$. The geometries are fundamentally different (bond angles of $60^\\circ$ in the tetrahedron vs. $90^\\circ$ and $45^\\circ$ in the square), leading to a significant difference in their three-body energies and a correspondingly larger irreducible bias.\n\n- Case 3: The same configurations as in Case 1 are used, but with a very small radial scale $\\sigma = 0.01$. The radial function $f(r) = \\exp(-(r/\\sigma)^2)$ decays extremely rapidly. Since all interatomic distances in both configurations are on the order of $1.0$, the value of $f(r)$ for any relevant distance is numerically indistinguishable from zero (e.g., $f(0.9) = \\exp(-(0.9/0.01)^2) = \\exp(-8100) \\approx 0$). Consequently, every term in the $E_3$ summation is zero for both configurations. Thus, $E_3(\\mathcal{A}) = E_3(\\mathcal{B}) = 0$, and the irreducible bias is $0.0$. This case illustrates that the significance of the three-body term, and thus the information loss, depends on the parameters of the potential itself.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main solver function to compute irreducible bias for the given test cases.\n    \"\"\"\n\n    def calculate_pairwise_distances(coords: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Calculates all unique pairwise distances for a set of atomic coordinates.\n        \"\"\"\n        num_atoms = coords.shape[0]\n        distances = []\n        for i in range(num_atoms):\n            for j in range(i + 1, num_atoms):\n                dist = np.linalg.norm(coords[i] - coords[j])\n                distances.append(dist)\n        return np.array(distances)\n\n    def calculate_histogram(distances: np.ndarray, bins: np.ndarray) -> np.ndarray:\n        \"\"\"\n        Computes the histogram of distances based on given bin edges.\n        The interval is [left, right), matching the problem spec.\n        \"\"\"\n        hist, _ = np.histogram(distances, bins=bins)\n        return hist\n\n    def calculate_three_body_energy(coords: np.ndarray, sigma: float) -> float:\n        \"\"\"\n        Calculates the three-body energy for a configuration.\n        \"\"\"\n        num_atoms = coords.shape[0]\n        total_energy = 0.0\n\n        if num_atoms < 3:\n            return 0.0\n\n        f = lambda r: np.exp(-(r / sigma)**2) if sigma > 0 else 0.0\n        p2 = lambda x: 0.5 * (3 * x**2 - 1)\n\n        # Iterate over all unique triples of atoms (i, j, k),\n        # with i being the central atom.\n        indices = range(num_atoms)\n        for i in indices:\n            # Create a list of neighbors for atom i\n            neighbors = list(indices)\n            neighbors.remove(i)\n            \n            # Iterate over all unique pairs of neighbors {j, k}\n            if len(neighbors) < 2:\n                continue\n            \n            for j, k in combinations(neighbors, 2):\n                # Vectors from central atom i to j and k\n                v_ij = coords[j] - coords[i]\n                v_ik = coords[k] - coords[i]\n\n                # Distances\n                r_ij = np.linalg.norm(v_ij)\n                r_ik = np.linalg.norm(v_ik)\n\n                # Avoid division by zero if atoms are on top of each other\n                if r_ij == 0.0 or r_ik == 0.0:\n                    continue\n\n                # Cosine of the angle\n                cos_theta = np.dot(v_ij, v_ik) / (r_ij * r_ik)\n                # Clamp to handle potential floating point inaccuracies\n                cos_theta = np.clip(cos_theta, -1.0, 1.0)\n                \n                # Energy term for this triplet\n                term = f(r_ij) * f(r_ik) * p2(cos_theta)\n                total_energy += term\n\n        return total_energy\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        (\n            np.array([[0.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 1.0, 0.0], [0.0, 1.0, 0.0]]),\n            np.array([[0.0, 0.0, 0.0], [0.9, 0.0, 0.0], [0.9, 1.1, 0.0], [0.0, 1.1, 0.0]]),\n            np.array([0.0, 1.2, 2.0]),\n            1.0\n        ),\n        # Case 2\n        (\n            np.array([\n                [0.0, 0.0, 0.0],\n                [1.0, 0.0, 0.0],\n                [0.5, np.sqrt(3)/2.0, 0.0],\n                [0.5, np.sqrt(3)/6.0, np.sqrt(6)/3.0]\n            ]),\n            np.array([[0.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 1.0, 0.0], [0.0, 1.0, 0.0]]),\n            np.array([0.0, 2.0]),\n            1.0\n        ),\n        # Case 3\n        (\n            np.array([[0.0, 0.0, 0.0], [1.0, 0.0, 0.0], [1.0, 1.0, 0.0], [0.0, 1.0, 0.0]]),\n            np.array([[0.0, 0.0, 0.0], [0.9, 0.0, 0.0], [0.9, 1.1, 0.0], [0.0, 1.1, 0.0]]),\n            np.array([0.0, 1.2, 2.0]),\n            0.01\n        )\n    ]\n\n    results = []\n    for case in test_cases:\n        coords_a, coords_b, bins, sigma = case\n\n        # 1. Verify that histograms are identical (internal check).\n        distances_a = calculate_pairwise_distances(coords_a)\n        distances_b = calculate_pairwise_distances(coords_b)\n        hist_a = calculate_histogram(distances_a, bins)\n        hist_b = calculate_histogram(distances_b, bins)\n        assert np.array_equal(hist_a, hist_b), f\"Histograms do not match for case {len(results)+1}\"\n\n        # 2. Compute three-body energies.\n        energy_a = calculate_three_body_energy(coords_a, sigma)\n        energy_b = calculate_three_body_energy(coords_b, sigma)\n\n        # 3. Report the irreducible bias.\n        irreducible_bias = 0.5 * np.abs(energy_a - energy_b)\n        results.append(irreducible_bias)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "3468348"}, {"introduction": "Having established the need for descriptors that capture many-body angular information, we now turn to the practical task of constructing them. This practice guides you through the implementation of a simplified Moment Tensor Potential (MTP), a physically-motivated framework for systematically building a complete basis of rotationally invariant descriptors. By explicitly calculating moment tensors from atomic positions and contracting them to form scalar invariants, you will demystify how these powerful representations work and validate your implementation with a linear fitting exercise [@problem_id:3468372].", "problem": "You are to implement a minimal, fully specified Moment Tensor Potential (MTP) for atomic local environments at level $2$, construct a rotationally invariant basis explicitly, assemble the design matrix for a given set of environments, and solve a linear least squares problem for the energy coefficients. All calculations must be carried out in three-dimensional Cartesian coordinates and must use the following fundamental definitions.\n\nDefinitions and constraints:\n- A local environment is a finite set of neighbor vectors $\\{\\mathbf{r}_j\\}_{j=1}^{N}$ in $\\mathbb{R}^3$ relative to a central atom. Distances are in ångström.\n- The cutoff function is $f_{\\mathrm{cut}}(r) = \\tfrac{1}{2}\\big(\\cos(\\pi r / r_c) + 1\\big)$ for $r < r_c$ and $f_{\\mathrm{cut}}(r) = 0$ for $r \\ge r_c$, where $r = \\|\\mathbf{r}\\|$ and $r_c$ is the cutoff radius (in ångström).\n- The radial basis functions are $R_1(r) = r_c - r$ and $R_2(r) = (r_c - r)^2$ for $r < r_c$, and their contribution is implicitly zero when $r \\ge r_c$ because $f_{\\mathrm{cut}}(r)=0$ there.\n- For $\\mu \\in \\{1,2\\}$, define the moment tensors\n  $$M_{\\mu,0} = \\sum_{j=1}^{N} f_{\\mathrm{cut}}(r_j)\\, R_{\\mu}(r_j),$$\n  $$M_{\\mu,1} = \\sum_{j=1}^{N} f_{\\mathrm{cut}}(r_j)\\, R_{\\mu}(r_j)\\, \\mathbf{r}_j \\in \\mathbb{R}^3,$$\n  $$M_{\\mu,2} = \\sum_{j=1}^{N} f_{\\mathrm{cut}}(r_j)\\, R_{\\mu}(r_j)\\, \\mathbf{r}_j \\otimes \\mathbf{r}_j \\in \\mathbb{R}^{3 \\times 3}.$$\n- Construct the scalar, rotationally invariant basis functions up to level $2$ by the following contractions:\n  1. $B_1 = M_{1,0}$,\n  2. $B_2 = M_{2,0}$,\n  3. $B_3 = \\mathrm{Tr}(M_{1,2})$,\n  4. $B_4 = \\mathrm{Tr}(M_{2,2})$,\n  5. $B_5 = M_{1,1} \\cdot M_{1,1}$,\n  6. $B_6 = M_{1,1} \\cdot M_{2,1}$,\n  7. $B_7 = M_{2,1} \\cdot M_{2,1}$,\n  where $\\mathrm{Tr}(\\cdot)$ is the matrix trace and $\\cdot$ denotes the Euclidean dot product in $\\mathbb{R}^3$.\n- The energy of a local environment is modeled as a linear combination of these invariants:\n  $$E = \\sum_{k=1}^{7} c_k\\, B_k,$$\n  where $c_k$ are constant coefficients (in electronvolts).\n\nUse the following fixed parameters and data:\n- Cutoff radius $r_c = 4.5$ ångström.\n- Ground-truth coefficients (in electronvolts): $c = \\big[c_1,\\dots,c_7\\big] = \\big[0.5, -0.3, 0.1, 0.05, 0.2, -0.15, 0.08\\big]$.\n- Test suite of $9$ local environments, each given as an explicit list of neighbor vectors $\\mathbf{r}_j = (x_j, y_j, z_j)$ in ångström:\n  1. Environment $1$: no neighbors, $\\{\\}$.\n  2. Environment $2$: $\\{(2.0, 0.0, 0.0)\\}$.\n  3. Environment $3$: $\\{(2.5, 0.0, 0.0),\\, (-2.5, 0.0, 0.0)\\}$.\n  4. Environment $4$: $\\{(2.0, 0.0, 0.0),\\, (0.0, 2.0, 0.0)\\}$.\n  5. Environment $5$: $\\{(1.8, 0.0, 0.0),\\, (0.0, 2.2, 0.0),\\, (0.0, 0.0, 2.5)\\}$.\n  6. Environment $6$: equilateral triangle in the $xy$-plane with radius $2.4$, i.e., $\\{(2.4, 0.0, 0.0),\\, (-1.2, 2.4\\cdot \\sqrt{3}/2, 0.0),\\, (-1.2, -2.4\\cdot \\sqrt{3}/2, 0.0)\\}$.\n  7. Environment $7$: regular tetrahedral directions scaled to length $2.8$, i.e., $\\{ \\tfrac{2.8}{\\sqrt{3}}(1,1,1),\\, \\tfrac{2.8}{\\sqrt{3}}(1,-1,-1),\\, \\tfrac{2.8}{\\sqrt{3}}(-1,1,-1),\\, \\tfrac{2.8}{\\sqrt{3}}(-1,-1,1)\\}$.\n  8. Environment $8$: $\\{(1.9, 0.5, 0.2),\\, (-0.3, 2.4, 0.1),\\, (0.4, -0.2, 2.6),\\, (-1.1, -0.8, 2.0)\\}$.\n  9. Environment $9$: out of cutoff single neighbor, $\\{(5.0, 0.0, 0.0)\\}$.\n\nTasks to implement:\n1. For each environment, compute the $7$-dimensional invariant vector $\\mathbf{B} = [B_1,\\dots,B_7]$ using the definitions above.\n2. Assemble the design matrix $X \\in \\mathbb{R}^{9 \\times 7}$ with rows $\\mathbf{B}^{\\top}$ for each environment in the order $1$ through $9$.\n3. Generate the observed energies $\\mathbf{y} \\in \\mathbb{R}^{9}$ from the ground-truth coefficients via $\\mathbf{y} = X\\, \\mathbf{c}$.\n4. Solve the linear least squares problem to estimate $\\widehat{\\mathbf{c}}$ from $(X,\\mathbf{y})$ as the minimizer of $\\|\\!|X \\mathbf{c} - \\mathbf{y}\\|\\!|_2^2$.\n5. Using $\\widehat{\\mathbf{c}}$, compute the predicted energies $\\widehat{\\mathbf{y}} = X\\, \\widehat{\\mathbf{c}}$ and report the absolute errors for each environment, $e_i = |y_i - \\widehat{y}_i|$.\n\nPhysical and numerical units:\n- Distances must be treated in ångström; the cutoff radius is given in ångström.\n- Energies and energy errors must be expressed in electronvolts (eV) as decimal numbers.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, listing the absolute energy errors for the $9$ environments in order, i.e., $[e_1,e_2,\\dots,e_9]$, where each $e_i$ is in $\\mathrm{eV}$. Round each $e_i$ to at least $10$ decimal places.\n\nDesign for coverage:\n- Environment $1$ tests the boundary case with no neighbors (all invariants zero and energy $0$).\n- Environment $9$ tests the cutoff boundary with a neighbor outside the cutoff (all invariants zero and energy $0$).\n- Environments $3$ and $4$ test symmetry effects that cancel $M_{\\mu,1}$ while leaving higher moments nonzero.\n- Environments $6$ and $7$ test nontrivial multi-neighbor configurations leading to diverse invariant values.", "solution": "The problem requires the implementation and validation of a simplified Moment Tensor Potential (MTP) model. The process involves calculating rotationally invariant basis functions for a given set of atomic environments, assembling a design matrix, and performing a linear regression to verify the model's implementation.\n\nThe core of the MTP framework is to represent a local atomic environment, defined by a set of neighbor vectors $\\{\\mathbf{r}_j\\}_{j=1}^{N}$ around a central atom, through a set of descriptors that are invariant under rotation. This ensures that the predicted energy of the environment does not change if the entire system is rotated, a fundamental physical requirement.\n\nThe procedure is broken down into the following steps:\n\n1.  **Computation of Moment Tensors**:\n    For each local environment, we first compute moment tensors, which are weighted sums over the atoms in the environment. The weighting involves a smooth cutoff function $f_{\\mathrm{cut}}(r)$ and a set of radial basis functions $R_{\\mu}(r)$.\n\n    - The cutoff function, $f_{\\mathrm{cut}}(r) = \\tfrac{1}{2}\\big(\\cos(\\pi r / r_c) + 1\\big)$ for $r < r_c$ and $0$ otherwise, ensures that the influence of an atom smoothly goes to zero as its distance $r$ from the central atom approaches the cutoff radius $r_c = 4.5$ Å. This locality is crucial for computational efficiency in large-scale simulations.\n\n    - The radial basis functions, $R_1(r) = r_c - r$ and $R_2(r) = (r_c - r)^2$, encode distance information into the model.\n\n    For each radial basis function index $\\mu \\in \\{1,2\\}$, we define moment tensors of increasing rank (level):\n    - Level $0$ (scalar): $M_{\\mu,0} = \\sum_{j} f_{\\mathrm{cut}}(r_j)\\, R_{\\mu}(r_j)$\n    - Level $1$ (vector): $M_{\\mu,1} = \\sum_{j} f_{\\mathrm{cut}}(r_j)\\, R_{\\mu}(r_j)\\, \\mathbf{r}_j$\n    - Level $2$ (matrix): $M_{\\mu,2} = \\sum_{j} f_{\\mathrm{cut}}(r_j)\\, R_{\\mu}(r_j)\\, (\\mathbf{r}_j \\otimes \\mathbf{r}_j)$\n\n    Here, $\\mathbf{r}_j \\otimes \\mathbf{r}_j$ denotes the outer product of the vector $\\mathbf{r}_j$ with itself, resulting in a $3 \\times 3$ matrix. These tensors capture increasingly complex information about the geometry of the atomic neighborhood. For an empty environment or an environment where all atoms are outside the cutoff radius $r_c$, all moment tensors are zero.\n\n2.  **Construction of Rotationally Invariant Basis Functions**:\n    The moment tensors themselves are not rotationally invariant (e.g., $M_{\\mu,1}$ is a vector and will rotate with the coordinate system). To achieve rotational invariance, we form scalar quantities by contracting these tensors. The problem specifies seven such basis functions, $B_k$:\n    - $B_1 = M_{1,0}$ and $B_2 = M_{2,0}$: These are already scalars and thus inherently invariant. They represent a weighted count of neighbors.\n    - $B_3 = \\mathrm{Tr}(M_{1,2})$ and $B_4 = \\mathrm{Tr}(M_{2,2})$: The trace of a matrix, $\\mathrm{Tr}(\\cdot)$, is invariant under rotations. These invariants are related to the weighted sum of squared distances of the neighbors.\n    - $B_5 = M_{1,1} \\cdot M_{1,1}$, $B_6 = M_{1,1} \\cdot M_{2,1}$, and $B_7 = M_{2,1} \\cdot M_{2,1}$: The dot product of two vectors results in a scalar, which is also rotationally invariant. These capture information about the asymmetry of the environment. For environments with high point-group symmetry (like a regular tetrahedron or equilateral triangle centered at the origin), the vector moments $M_{\\mu,1}$ sum to zero, causing these invariants to vanish.\n\n    For each of the $9$ provided environments, we compute the corresponding $7$-dimensional vector of invariants $\\mathbf{B} = [B_1, B_2, B_3, B_4, B_5, B_6, B_7]$.\n\n3.  **Assembly of the Design Matrix and Energy Vector**:\n    The energy of an environment is modeled as a linear combination of the basis invariants: $E = \\sum_{k=1}^{7} c_k\\, B_k$. This can be written in vector form as $E = \\mathbf{B} \\cdot \\mathbf{c}$.\n    We assemble a design matrix $X \\in \\mathbb{R}^{9 \\times 7}$, where each row $i$ is the invariant vector $\\mathbf{B}^{(i)}$ for the $i$-th environment.\n    The \"observed\" energies for all $9$ environments are then generated using the ground-truth coefficients $\\mathbf{c} = [0.5, -0.3, 0.1, 0.05, 0.2, -0.15, 0.08]^{\\top}$. This is a matrix-vector product: $\\mathbf{y} = X\\,\\mathbf{c}$, where $\\mathbf{y} \\in \\mathbb{R}^9$ is the vector of energies.\n\n4.  **Linear Least Squares Fitting and Error Calculation**:\n    The problem constitutes a \"round-trip\" test. We have generated the data $(\\mathbf{X}, \\mathbf{y})$ from a known linear model. The next step is to solve the linear least squares problem to find the coefficients $\\widehat{\\mathbf{c}}$ that minimize the squared norm of the residual, $\\|\\!|X \\widehat{\\mathbf{c}} - \\mathbf{y}\\|\\!|_2^2$.\n    Since the data $\\mathbf{y}$ is noiseless and was generated directly from $X$ (i.e., $\\mathbf{y}$ lies exactly in the column space of $X$), the least squares solution will yield predicted energies $\\widehat{\\mathbf{y}} = X \\widehat{\\mathbf{c}}$ that are identical to the \"observed\" energies $\\mathbf{y}$. Therefore, the absolute error for each environment, $e_i = |y_i - \\widehat{y}_i|$, is expected to be zero within the limits of floating-point precision. A non-zero error would indicate an incorrect implementation of the basis function calculation.\n\n    The algorithm proceeds as follows:\n    - Solve for $\\widehat{\\mathbf{c}}$ using a standard linear least squares solver, for which `scipy.linalg.lstsq` is highly suitable.\n    - Compute the predicted energies $\\widehat{\\mathbf{y}} = X \\widehat{\\mathbf{c}}$.\n    - Compute the absolute errors $\\mathbf{e} = |\\mathbf{y} - \\widehat{\\mathbf{y}}|$.\n    - Report the components of $\\mathbf{e}$ formatted to the required precision.\n\nThis validation process ensures the correctness of the complex basis function calculation, which is a fundamental prerequisite for using the MTP model in any practical application.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import lstsq\n\ndef solve():\n    \"\"\"\n    Implements a simplified Moment Tensor Potential (MTP) model,\n    calculates invariants for given environments, and verifies the\n    implementation via a linear least squares round-trip test.\n    \"\"\"\n\n    # Define the fixed parameters from the problem statement.\n    r_c = 4.5  # Cutoff radius in angstrom\n    c_true = np.array([0.5, -0.3, 0.1, 0.05, 0.2, -0.15, 0.08]) # Ground-truth coefficients in eV\n\n    # Define the test suite of 9 local environments.\n    sqrt3 = np.sqrt(3)\n    environments = [\n        [],  # Env 1: no neighbors\n        [(2.0, 0.0, 0.0)],  # Env 2\n        [(2.5, 0.0, 0.0), (-2.5, 0.0, 0.0)],  # Env 3\n        [(2.0, 0.0, 0.0), (0.0, 2.0, 0.0)],  # Env 4\n        [(1.8, 0.0, 0.0), (0.0, 2.2, 0.0), (0.0, 0.0, 2.5)],  # Env 5\n        [(2.4, 0.0, 0.0), (-1.2, 2.4 * sqrt3 / 2.0, 0.0), (-1.2, -2.4 * sqrt3 / 2.0, 0.0)],  # Env 6\n        [\n            (2.8 / sqrt3 * v[0], 2.8 / sqrt3 * v[1], 2.8 / sqrt3 * v[2])\n            for v in [(1, 1, 1), (1, -1, -1), (-1, 1, -1), (-1, -1, 1)]\n        ],  # Env 7\n        [(1.9, 0.5, 0.2), (-0.3, 2.4, 0.1), (0.4, -0.2, 2.6), (-1.1, -0.8, 2.0)],  # Env 8\n        [(5.0, 0.0, 0.0)],  # Env 9: out of cutoff\n    ]\n\n    def calculate_invariants(neighbor_vectors, rc):\n        \"\"\"\n        Calculates the 7 MTP basis invariants for a single environment.\n        \"\"\"\n        # Initialize moment tensors\n        m_10, m_20 = 0.0, 0.0\n        m_11, m_21 = np.zeros(3), np.zeros(3)\n        m_12, m_22 = np.zeros((3, 3)), np.zeros((3, 3))\n\n        for vec in neighbor_vectors:\n            r_j = np.array(vec)\n            r = np.linalg.norm(r_j)\n\n            if r < rc and r > 1e-9:  # Check cutoff and avoid division by zero\n                # Calculate cutoff function and radial basis functions\n                f_cut = 0.5 * (np.cos(np.pi * r / rc) + 1.0)\n                r1_val = rc - r\n                r2_val = (rc - r) ** 2\n                \n                # Pre-calculate weighted radial terms\n                w1 = f_cut * r1_val\n                w2 = f_cut * r2_val\n                \n                # Accumulate moment tensors\n                m_10 += w1\n                m_20 += w2\n                \n                m_11 += w1 * r_j\n                m_21 += w2 * r_j\n                \n                m_12 += w1 * np.outer(r_j, r_j)\n                m_22 += w2 * np.outer(r_j, r_j)\n\n        # Construct the 7 scalar invariants B_k\n        b_vec = np.zeros(7)\n        b_vec[0] = m_10                # B1 = M_1,0\n        b_vec[1] = m_20                # B2 = M_2,0\n        b_vec[2] = np.trace(m_12)      # B3 = Tr(M_1,2)\n        b_vec[3] = np.trace(m_22)      # B4 = Tr(M_2,2)\n        b_vec[4] = np.dot(m_11, m_11)  # B5 = M_1,1 . M_1,1\n        b_vec[5] = np.dot(m_11, m_21)  # B6 = M_1,1 . M_2,1\n        b_vec[6] = np.dot(m_21, m_21)  # B7 = M_2,1 . M_2,1\n        \n        return b_vec\n\n    # 1. & 2. Compute invariants and assemble the design matrix X\n    num_environments = len(environments)\n    num_invariants = 7\n    X = np.zeros((num_environments, num_invariants))\n    for i, env in enumerate(environments):\n        X[i, :] = calculate_invariants(env, r_c)\n\n    # 3. Generate the \"observed\" energies y\n    y = X @ c_true\n\n    # 4. Solve the linear least squares problem for c_hat\n    c_hat, residuals, rank, s = lstsq(X, y)\n\n    # 5. Compute predicted energies and absolute errors\n    y_hat = X @ c_hat\n    errors = np.abs(y - y_hat)\n\n    # Format the final output string\n    # Using high precision formatting to show the errors are numerically zero\n    error_strs = [f\"{err:.17f}\" for err in errors]\n    print(f\"[{','.join(error_strs)}]\")\n\nsolve()\n```", "id": "3468372"}, {"introduction": "With a robust set of descriptors, the next step is to train the potential by fitting its parameters to reference data, typically from quantum mechanical calculations. This exercise delves into the statistical foundations of this fitting process, focusing on how to properly combine different types of data—namely energies, atomic forces, and virial stresses—into a single, coherent training objective. By deriving the loss function from the principle of maximum likelihood and analyzing its structure using the Fisher Information Matrix, you will understand how the assumed noise in each data type dictates its weighting and its overall contribution to the final trained model [@problem_id:3468393].", "problem": "Consider the training of an interatomic potential in computational materials science that simultaneously fits energies, forces, and virial stresses using a parametric model inspired by neural and kernel methods, such as a final linear layer in a neural network or a linear kernel expansion in a Gaussian Approximation Potential (GAP) or Moment Tensor Potential (MTP). Let the parameter vector be $\\boldsymbol{\\theta} \\in \\mathbb{R}^{2}$ and suppose for a single configuration the predicted observables are linear in $\\boldsymbol{\\theta}$ through fixed descriptors:\n$$E_{\\text{pred}}(\\boldsymbol{\\theta}) = \\boldsymbol{\\phi}_{E}^{\\top}\\boldsymbol{\\theta}, \\quad \\boldsymbol{\\phi}_{E} = \\begin{pmatrix}2 \\\\ 1 \\end{pmatrix},$$\n$$F_{x,\\text{pred}}(\\boldsymbol{\\theta}) = \\boldsymbol{\\phi}_{F_x}^{\\top}\\boldsymbol{\\theta}, \\quad \\boldsymbol{\\phi}_{F_x} = \\begin{pmatrix}-3 \\\\ 0.5 \\end{pmatrix}, \\qquad F_{y,\\text{pred}}(\\boldsymbol{\\theta}) = \\boldsymbol{\\phi}_{F_y}^{\\top}\\boldsymbol{\\theta}, \\quad \\boldsymbol{\\phi}_{F_y} = \\begin{pmatrix}1 \\\\ -2 \\end{pmatrix},$$\n$$\\sigma_{xx,\\text{pred}}(\\boldsymbol{\\theta}) = \\boldsymbol{\\phi}_{S_{xx}}^{\\top}\\boldsymbol{\\theta}, \\quad \\boldsymbol{\\phi}_{S_{xx}} = \\begin{pmatrix}4 \\\\ -1 \\end{pmatrix}, \\quad \\sigma_{yy,\\text{pred}}(\\boldsymbol{\\theta}) = \\boldsymbol{\\phi}_{S_{yy}}^{\\top}\\boldsymbol{\\theta}, \\quad \\boldsymbol{\\phi}_{S_{yy}} = \\begin{pmatrix}-1 \\\\ 3 \\end{pmatrix},$$\n$$\\sigma_{xy,\\text{pred}}(\\boldsymbol{\\theta}) = \\boldsymbol{\\phi}_{S_{xy}}^{\\top}\\boldsymbol{\\theta}, \\quad \\boldsymbol{\\phi}_{S_{xy}} = \\begin{pmatrix}0.5 \\\\ 0.5 \\end{pmatrix}.$$\nAssume independent Gaussian noise models for each observable type, with variances $\\sigma_{E}^{2} = 0.01$ for energies, $\\sigma_{F}^{2} = 0.04$ for each force component, and $\\sigma_{S}^{2} = 0.09$ for each stress component. Treat the measurements $E$, $F_{x}$, $F_{y}$, $\\sigma_{xx}$, $\\sigma_{yy}$, and $\\sigma_{xy}$ as fixed data.\n\nStarting from the principle of maximum likelihood under independent Gaussian errors and the definition of the Fisher Information Matrix (FIM), do the following:\n\n1. Derive the combined training loss $L(\\boldsymbol{\\theta})$ as the negative log-likelihood (up to an additive constant independent of $\\boldsymbol{\\theta}$) that simultaneously includes energy, force, and stress residuals. Your derivation must explicitly show how weighting arises from the noise variances.\n\n2. Derive the Fisher Information Matrix $\\mathbf{I}(\\boldsymbol{\\theta})$ for this linear model and show how the weights (determined by $\\sigma_{E}^{2}$, $\\sigma_{F}^{2}$, and $\\sigma_{S}^{2}$) determine the relative contributions from energies, forces, and stresses.\n\n3. Define the relative influence ratio $r$ to be the ratio of the trace contribution from forces to the trace contribution from energies in the Fisher Information Matrix:\n$$r = \\frac{\\operatorname{tr}(\\mathbf{I}_{F})}{\\operatorname{tr}(\\mathbf{I}_{E})},$$\nwhere $\\mathbf{I}_{F}$ and $\\mathbf{I}_{E}$ denote the additive contributions to the Fisher Information Matrix arising from force and energy observables, respectively. Using the descriptors and variances given above, compute $r$.\n\nExpress the final ratio $r$ as a dimensionless decimal number, rounded to four significant figures.", "solution": "The problem requires the derivation of a loss function, the Fisher Information Matrix (FIM), and a specific ratio of trace contributions for a linear interatomic potential model. The derivation is based on the principle of maximum likelihood estimation assuming independent Gaussian noise for each observable.\n\n### Part 1: Derivation of the Combined Training Loss $L(\\boldsymbol{\\theta})$\n\nThe training of the parameter vector $\\boldsymbol{\\theta}$ is framed as a maximum likelihood estimation problem. We are given a set of measurements (data) $\\mathcal{D} = \\{y_k\\}$ consisting of energy $E$, force components $F_x, F_y$, and stress components $\\sigma_{xx}, \\sigma_{yy}, \\sigma_{xy}$. Each measurement $y_k$ is assumed to be drawn from a Gaussian distribution with mean equal to the model's prediction $y_{k,\\text{pred}}(\\boldsymbol{\\theta})$ and a known variance $\\sigma_k^2$. The probability density function for a single observation $y_k$ is:\n$$p(y_k | \\boldsymbol{\\theta}) = \\frac{1}{\\sqrt{2\\pi\\sigma_k^2}} \\exp\\left(-\\frac{(y_k - y_{k,\\text{pred}}(\\boldsymbol{\\theta}))^2}{2\\sigma_k^2}\\right)$$\nThe observables are assumed to have independent noise. Therefore, the total likelihood of observing the entire dataset $\\mathcal{D}$ given the parameters $\\boldsymbol{\\theta}$ is the product of the individual probability densities:\n$$P(\\mathcal{D}|\\boldsymbol{\\theta}) = \\prod_{k \\in \\mathcal{D}} p(y_k | \\boldsymbol{\\theta})$$\nTo maximize the likelihood, it is computationally more convenient to maximize its logarithm, the log-likelihood $\\ln P(\\mathcal{D}|\\boldsymbol{\\theta})$:\n$$\\ln P(\\mathcal{D}|\\boldsymbol{\\theta}) = \\sum_{k \\in \\mathcal{D}} \\ln p(y_k | \\boldsymbol{\\theta}) = \\sum_{k \\in \\mathcal{D}} \\left( -\\frac{1}{2}\\ln(2\\pi\\sigma_k^2) - \\frac{(y_k - y_{k,\\text{pred}}(\\boldsymbol{\\theta}))^2}{2\\sigma_k^2} \\right)$$\nThe training loss, $L(\\boldsymbol{\\theta})$, is defined as the negative log-likelihood. Maximizing the log-likelihood is equivalent to minimizing the loss. Dropping the terms that are constant with respect to $\\boldsymbol{\\theta}$, we obtain:\n$$L(\\boldsymbol{\\theta}) = \\sum_{k \\in \\mathcal{D}} \\frac{(y_k - y_{k,\\text{pred}}(\\boldsymbol{\\theta}))^2}{2\\sigma_k^2}$$\nThis expression is the weighted sum of squared residuals, where each residual is weighted by the inverse of its noise variance, $1/\\sigma_k^2$. The factor of $1/2$ is a common convention.\n\nSubstituting the specific observables from the problem statement, the combined loss function is:\n$$L(\\boldsymbol{\\theta}) = \\frac{(E - E_{\\text{pred}})^{2}}{2\\sigma_{E}^{2}} + \\frac{(F_x - F_{x,\\text{pred}})^{2}}{2\\sigma_{F}^{2}} + \\frac{(F_y - F_{y,\\text{pred}})^{2}}{2\\sigma_{F}^{2}} + \\frac{(\\sigma_{xx} - \\sigma_{xx,\\text{pred}})^{2}}{2\\sigma_{S}^{2}} + \\frac{(\\sigma_{yy} - \\sigma_{yy,\\text{pred}})^{2}}{2\\sigma_{S}^{2}} + \\frac{(\\sigma_{xy} - \\sigma_{xy,\\text{pred}})^{2}}{2\\sigma_{S}^{2}}$$\nUsing the linear model definitions $y_{k,\\text{pred}}(\\boldsymbol{\\theta}) = \\boldsymbol{\\phi}_k^\\top\\boldsymbol{\\theta}$:\n$$L(\\boldsymbol{\\theta}) = \\frac{(E - \\boldsymbol{\\phi}_{E}^{\\top}\\boldsymbol{\\theta})^2}{2\\sigma_{E}^{2}} + \\frac{(F_x - \\boldsymbol{\\phi}_{F_x}^{\\top}\\boldsymbol{\\theta})^2}{2\\sigma_{F}^{2}} + \\frac{(F_y - \\boldsymbol{\\phi}_{F_y}^{\\top}\\boldsymbol{\\theta})^2}{2\\sigma_{F}^{2}} + \\frac{(\\sigma_{xx} - \\boldsymbol{\\phi}_{S_{xx}}^{\\top}\\boldsymbol{\\theta})^2}{2\\sigma_{S}^{2}} + \\frac{(\\sigma_{yy} - \\boldsymbol{\\phi}_{S_{yy}}^{\\top}\\boldsymbol{\\theta})^2}{2\\sigma_{S}^{2}} + \\frac{(\\sigma_{xy} - \\boldsymbol{\\phi}_{S_{xy}}^{\\top}\\boldsymbol{\\theta})^2}{2\\sigma_{S}^{2}}$$\nThis explicitly shows that the relative weighting of energy, force, and stress residuals in the loss function is determined by the inverse of their respective noise variances.\n\n### Part 2: Derivation of the Fisher Information Matrix $\\mathbf{I}(\\boldsymbol{\\theta})$\n\nThe Fisher Information Matrix (FIM) for a parameter vector $\\boldsymbol{\\theta}$ is defined as the negative expectation of the Hessian of the log-likelihood:\n$$\\mathbf{I}_{ij}(\\boldsymbol{\\theta}) = -E\\left[\\frac{\\partial^2 \\ln P(\\mathcal{D}|\\boldsymbol{\\theta})}{\\partial \\theta_i \\partial \\theta_j}\\right]$$\nFor a linear model with additive Gaussian noise, the Hessian of the log-likelihood is constant and does not depend on the data values $\\{y_k\\}$. Thus, the expectation is trivial. The FIM is simply the Hessian of our loss function $L(\\boldsymbol{\\theta})$:\n$$\\mathbf{I}(\\boldsymbol{\\theta}) = \\nabla_{\\boldsymbol{\\theta}} \\nabla_{\\boldsymbol{\\theta}}^{\\top} L(\\boldsymbol{\\theta})$$\nLet's compute the Hessian for a single term in the loss:\n$$\\frac{\\partial^2}{\\partial \\theta_j \\partial \\theta_i} \\left[ \\frac{(y_k - \\boldsymbol{\\phi}_{k}^{\\top}\\boldsymbol{\\theta})^2}{2\\sigma_k^2} \\right] = \\frac{\\partial}{\\partial \\theta_j} \\left[ \\frac{y_k - \\boldsymbol{\\phi}_{k}^{\\top}\\boldsymbol{\\theta}}{-\\sigma_k^2} (\\phi_k)_i \\right] = \\frac{(\\phi_k)_j (\\phi_k)_i}{\\sigma_k^2}$$\nHere, $(\\phi_k)_i$ is the $i$-th component of the vector $\\boldsymbol{\\phi}_k$. In matrix notation, the Hessian for this term is the outer product $\\frac{1}{\\sigma_k^2} \\boldsymbol{\\phi}_k \\boldsymbol{\\phi}_k^\\top$.\n\nSince the total loss is a sum of independent terms, the total FIM is the sum of the contributions from each observable:\n$$\\mathbf{I} = \\sum_{k \\in \\mathcal{D}} \\frac{1}{\\sigma_k^2} \\boldsymbol{\\phi}_k \\boldsymbol{\\phi}_k^\\top$$\nFor this model, the FIM is independent of $\\boldsymbol{\\theta}$. It can be decomposed into additive contributions from energies, forces, and stresses:\n$$\\mathbf{I} = \\mathbf{I}_{E} + \\mathbf{I}_{F} + \\mathbf{I}_{S}$$\nwhere:\n$$\\mathbf{I}_{E} = \\frac{1}{\\sigma_{E}^{2}} \\boldsymbol{\\phi}_{E} \\boldsymbol{\\phi}_{E}^{\\top}$$\n$$\\mathbf{I}_{F} = \\frac{1}{\\sigma_{F}^{2}} \\left( \\boldsymbol{\\phi}_{F_x} \\boldsymbol{\\phi}_{F_x}^{\\top} + \\boldsymbol{\\phi}_{F_y} \\boldsymbol{\\phi}_{F_y}^{\\top} \\right)$$\n$$\\mathbf{I}_{S} = \\frac{1}{\\sigma_{S}^{2}} \\left( \\boldsymbol{\\phi}_{S_{xx}} \\boldsymbol{\\phi}_{S_{xx}}^{\\top} + \\boldsymbol{\\phi}_{S_{yy}} \\boldsymbol{\\phi}_{S_{yy}}^{\\top} + \\boldsymbol{\\phi}_{S_{xy}} \\boldsymbol{\\phi}_{S_{xy}}^{\\top} \\right)$$\nThe weights $1/\\sigma_k^2$ determine the relative magnitude of the contribution of each observable type to the total Fisher information.\n\n### Part 3: Computation of the Relative Influence Ratio $r$\n\nThe ratio $r$ is defined as the ratio of the trace of the force contribution to the FIM to the trace of the energy contribution:\n$$r = \\frac{\\operatorname{tr}(\\mathbf{I}_{F})}{\\operatorname{tr}(\\mathbf{I}_{E})}$$\nWe utilize the property of the trace operator $\\operatorname{tr}(\\mathbf{A}+\\mathbf{B}) = \\operatorname{tr}(\\mathbf{A}) + \\operatorname{tr}(\\mathbf{B})$ and the cyclic property which implies $\\operatorname{tr}(\\mathbf{v}\\mathbf{v}^\\top) = \\mathbf{v}^\\top\\mathbf{v} = ||\\mathbf{v}||_2^2$, the squared Euclidean norm of the vector $\\mathbf{v}$.\n\nFirst, we compute the trace of the energy contribution, $\\operatorname{tr}(\\mathbf{I}_{E})$:\n$$\\operatorname{tr}(\\mathbf{I}_{E}) = \\operatorname{tr}\\left( \\frac{1}{\\sigma_{E}^2} \\boldsymbol{\\phi}_{E} \\boldsymbol{\\phi}_{E}^{\\top} \\right) = \\frac{1}{\\sigma_{E}^2} \\operatorname{tr}(\\boldsymbol{\\phi}_{E} \\boldsymbol{\\phi}_{E}^{\\top}) = \\frac{||\\boldsymbol{\\phi}_{E}||_2^2}{\\sigma_{E}^2}$$\nNext, we compute the trace of the force contribution, $\\operatorname{tr}(\\mathbf{I}_{F})$:\n$$\\operatorname{tr}(\\mathbf{I}_{F}) = \\operatorname{tr}\\left( \\frac{1}{\\sigma_{F}^2} \\left( \\boldsymbol{\\phi}_{F_x} \\boldsymbol{\\phi}_{F_x}^{\\top} + \\boldsymbol{\\phi}_{F_y} \\boldsymbol{\\phi}_{F_y}^{\\top} \\right) \\right) = \\frac{1}{\\sigma_{F}^2} \\left[ \\operatorname{tr}(\\boldsymbol{\\phi}_{F_x} \\boldsymbol{\\phi}_{F_x}^{\\top}) + \\operatorname{tr}(\\boldsymbol{\\phi}_{F_y} \\boldsymbol{\\phi}_{F_y}^{\\top}) \\right] = \\frac{||\\boldsymbol{\\phi}_{F_x}||_2^2 + ||\\boldsymbol{\\phi}_{F_y}||_2^2}{\\sigma_{F}^2}$$\nNow, we substitute the given values:\n- $\\boldsymbol{\\phi}_{E} = \\begin{pmatrix}2 \\\\ 1 \\end{pmatrix}$\n- $\\boldsymbol{\\phi}_{F_x} = \\begin{pmatrix}-3 \\\\ 0.5 \\end{pmatrix}$\n- $\\boldsymbol{\\phi}_{F_y} = \\begin{pmatrix}1 \\\\ -2 \\end{pmatrix}$\n- $\\sigma_E^2 = 0.01$\n- $\\sigma_F^2 = 0.04$\n\nCalculate the squared norms of the descriptor vectors:\n$$||\\boldsymbol{\\phi}_{E}||_2^2 = (2)^2 + (1)^2 = 4 + 1 = 5$$\n$$||\\boldsymbol{\\phi}_{F_x}||_2^2 = (-3)^2 + (0.5)^2 = 9 + 0.25 = 9.25$$\n$$||\\boldsymbol{\\phi}_{F_y}||_2^2 = (1)^2 + (-2)^2 = 1 + 4 = 5$$\n\nNow, calculate the traces:\n$$\\operatorname{tr}(\\mathbf{I}_{E}) = \\frac{5}{0.01} = 500$$\n$$\\operatorname{tr}(\\mathbf{I}_{F}) = \\frac{9.25 + 5}{0.04} = \\frac{14.25}{0.04} = 356.25$$\n\nFinally, compute the ratio $r$:\n$$r = \\frac{\\operatorname{tr}(\\mathbf{I}_{F})}{\\operatorname{tr}(\\mathbf{I}_{E})} = \\frac{356.25}{500} = 0.7125$$\nThe problem requires the answer to be a decimal number rounded to four significant figures. The value $0.7125$ already has four significant figures.", "answer": "$$\\boxed{0.7125}$$", "id": "3468393"}]}