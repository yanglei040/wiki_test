{"hands_on_practices": [{"introduction": "The quantitative application of quantum statistics hinges on the evaluation of Fermi-Dirac and Bose-Einstein integrals. This foundational exercise [@problem_id:3482692] guides you through building a numerical evaluator from first principles, starting with the basic definitions of the occupation functions and the free-particle density of states. Mastering this task involves not only implementing an integration routine but also developing the crucial skill of writing numerically robust code that gracefully handles potential overflows and loss of precision across different physical regimes.", "problem": "You will implement a program to numerically evaluate dimensionless integrals that arise from quantum statistics in computational materials science, based on first principles. Begin from the definitions of the Fermi-Dirac (FD) occupation function and the Bose-Einstein (BE) occupation function, and the three-dimensional free-particle density of states. Using these definitions only, derive dimensionless integral expressions that depend on a reduced chemical potential and a real order parameter. Specifically:\n\n- The Fermi-Dirac occupation function is defined as $f_{\\mathrm{FD}}(E; \\mu, T) = \\left[\\exp\\!\\left(\\frac{E - \\mu}{k_{\\mathrm{B}} T}\\right) + 1\\right]^{-1}$, where $E$ is energy, $\\mu$ is chemical potential, $T$ is temperature, and $k_{\\mathrm{B}}$ is the Boltzmann constant.\n\n- The Bose-Einstein occupation function is defined as $f_{\\mathrm{BE}}(E; \\mu, T) = \\left[\\exp\\!\\left(\\frac{E - \\mu}{k_{\\mathrm{B}} T}\\right) - 1\\right]^{-1}$, with the physical constraint $\\mu \\le 0$ for non-condensed bosons.\n\n- The three-dimensional free-particle density of states scales with energy as $D(E) \\propto E^{1/2}$.\n\nFrom these foundational elements, introduce the dimensionless energy variable $x = E/(k_{\\mathrm{B}} T)$ and dimensionless reduced chemical potentials $\\eta = \\mu/(k_{\\mathrm{B}} T)$ for fermions and $\\alpha = \\mu/(k_{\\mathrm{B}} T)$ for bosons. Then, by combining $f_{\\mathrm{FD}}$ or $f_{\\mathrm{BE}}$ with $D(E)$ and performing a change of variables to $x$, derive the corresponding dimensionless integrals parameterized by a real order $j > 0$. Your program must evaluate, by numerical integration, the dimensionless FD integral of order $j$ at specified values of $\\eta$, and the dimensionless BE integral of order $j$ at specified values of $\\alpha  0$. The derivation should be principle-based and should not use any pre-tabulated special-function identities.\n\nAlgorithmic requirements:\n\n- Implement adaptive numerical quadrature for integrals on the semi-infinite domain $x \\in [0, \\infty)$, with a careful treatment to avoid numerical overflow in the exponential functions. Your implementation must be robust across regimes including the degenerate limit for fermions (large positive $\\eta$), the nondegenerate limit for fermions (large negative $\\eta$), and the near-critical regime for bosons ($\\alpha \\to 0^{-}$).\n\n- Your numerical integrals should be computed to high accuracy. Design your algorithm to use stable evaluations of expressions such as $\\left[1 + \\exp\\!\\left(x - \\eta\\right)\\right]^{-1}$ and $\\left[\\exp\\!\\left(x - \\alpha\\right) - 1\\right]^{-1}$ in both the small and large argument limits.\n\nTest suite:\n\nEvaluate the following cases, each producing a single floating-point result:\n\n- Fermi-Dirac integral of order $j = 1/2$ at $\\eta = -10.0$.\n- Fermi-Dirac integral of order $j = 1/2$ at $\\eta = 0.0$.\n- Fermi-Dirac integral of order $j = 1/2$ at $\\eta = 2.0$.\n- Fermi-Dirac integral of order $j = 1/2$ at $\\eta = 10.0$.\n- Bose-Einstein integral of order $j = 3/2$ at $\\alpha = -5.0$.\n- Bose-Einstein integral of order $j = 3/2$ at $\\alpha = -1.0$.\n- Bose-Einstein integral of order $j = 3/2$ at $\\alpha = -1 \\times 10^{-6}$.\n\nAll integrals are dimensionless, so no physical unit specification is required. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the exact order listed above, with each floating-point number rounded to $8$ decimal places. For example: $[r_1,r_2,r_3,r_4,r_5,r_6,r_7]$.", "solution": "The problem as stated is scientifically grounded, well-posed, and objective. It is based on fundamental principles of quantum statistical mechanics and poses a standard, solvable problem in computational physics. All necessary definitions and parameters are provided. Therefore, the problem is valid, and a solution will be presented.\n\nThe objective is to derive and numerically evaluate dimensionless integrals central to quantum statistics. This process begins from the first principles of statistical mechanics.\n\nA macroscopic property $G$ of a system of non-interacting particles is calculated by integrating a microscopic energy-dependent quantity $g(E)$ over all available states. This involves the density of states $D(E)$ and the statistical occupation function $f(E; \\mu, T)$:\n$$\nG = \\int_0^\\infty g(E) D(E) f(E; \\mu, T) dE\n$$\nThe problem specifies that for a three-dimensional free-particle gas, the density of states scales as $D(E) \\propto E^{1/2}$. We can write this with a proportionality constant $C_D$ as $D(E) = C_D E^{1/2}$. The quantities of interest in this context, such as particle number or energy, often correspond to forms where $g(E) = C_g E^k$ for some constant $C_g$ and exponent $k$. The integral for $G$ then takes the form:\n$$\nG = C \\int_0^\\infty E^k \\cdot E^{1/2} \\cdot f(E; \\mu, T) dE = C \\int_0^\\infty E^{k+1/2} f(E; \\mu, T) dE\n$$\nwhere $C$ consolidates all proportionality constants.\n\nTo obtain the dimensionless form, we introduce the dimensionless energy variable $x = E/(k_{\\mathrm{B}} T)$, which implies $E = x k_{\\mathrm{B}} T$ and $dE = k_{\\mathrm{B}} T dx$. Substituting these into the integral gives:\n$$\nG = C \\int_0^\\infty (x k_{\\mathrm{B}} T)^{k+1/2} f(x k_{\\mathrm{B}} T; \\mu, T) (k_{\\mathrm{B}} T dx)\n$$\n$$\nG = C (k_{\\mathrm{B}} T)^{k+3/2} \\int_0^\\infty x^{k+1/2} f(x k_{\\mathrm{B}} T; \\mu, T) dx\n$$\nThe integral part is now dimensionless. The standard \"order\" of such an integral, denoted by $j$, corresponds to the exponent of the dimensionless variable $x$. We identify the order as $j = k+1/2$. Thus, a physical quantity proportional to $E^k$ gives rise to a dimensionless integral of order $j = k+1/2$. For instance, the total particle number ($k=0$) corresponds to an integral of order $j=1/2$, and total energy ($k=1$) corresponds to an integral of order $j=3/2$.\n\nThe occupation function $f$ also transforms. Its argument becomes:\n$$\n\\frac{E - \\mu}{k_{\\mathrm{B}} T} = \\frac{E}{k_{\\mathrm{B}} T} - \\frac{\\mu}{k_{\\mathrm{B}} T} = x - \\xi\n$$\nwhere $\\xi$ is the dimensionless reduced chemical potential, denoted $\\eta = \\mu/(k_{\\mathrm{B}} T)$ for fermions and $\\alpha = \\mu/(k_{\\mathrm{B}} T)$ for bosons.\n\nBased on this derivation, the dimensionless integral of order $j$ is of the general form:\n$$\nI_j(\\xi) = \\int_0^\\infty \\frac{x^j}{\\exp(x-\\xi) \\pm 1} dx\n$$\nwhere the sign in the denominator is '$+$' for Fermi-Dirac statistics and '$-$' for Bose-Einstein statistics.\n\n**Fermi-Dirac Integral**\nThe Fermi-Dirac (FD) occupation function is $f_{\\mathrm{FD}} = [\\exp((E-\\mu)/(k_{\\mathrm{B}} T)) + 1]^{-1}$. The corresponding dimensionless integral of order $j$, which we denote $\\mathcal{F}_j(\\eta)$, is:\n$$\n\\mathcal{F}_j(\\eta) = \\int_0^\\infty \\frac{x^j}{\\exp(x-\\eta)+1} dx\n$$\nFor the test cases, we must evaluate this integral for $j=1/2$ at various $\\eta$.\n\n**Bose-Einstein Integral**\nThe Bose-Einstein (BE) occupation function is $f_{\\mathrm{BE}} = [\\exp((E-\\mu)/(k_{\\mathrm{B}} T)) - 1]^{-1}$. For non-condensed bosons, $\\mu \\le 0$, which implies $\\alpha \\le 0$. The corresponding dimensionless integral of order $j$, denoted $\\mathcal{G}_j(\\alpha)$, is:\n$$\n\\mathcal{G}_j(\\alpha) = \\int_0^\\infty \\frac{x^j}{\\exp(x-\\alpha)-1} dx\n$$\nThe problem requires evaluating this for $j=3/2$ at various $\\alpha  0$. The condition $\\alpha  0$ ensures that for any $x \\ge 0$, the argument of the exponential $x-\\alpha$ is positive, preventing a singularity in the denominator for $x>0$.\n\n**Numerical Evaluation**\nThe integrals are evaluated over the semi-infinite domain $[0, \\infty)$ using adaptive numerical quadrature, for which the `scipy.integrate.quad` function is suitable. A critical aspect of the implementation is the robust evaluation of the integrand to prevent numerical overflow and loss of precision.\n\nFor the FD integrand, $g(x) = x^j / (\\exp(x-\\eta)+1)$:\n- If the argument $x-\\eta$ is a large positive number, $\\exp(x-\\eta)$ can overflow. In this regime, $\\exp(x-\\eta)+1 \\approx \\exp(x-\\eta)$, so the integrand can be accurately approximated by $g(x) \\approx x^j \\exp(-(x-\\eta))$.\n- If $x-\\eta$ is a large negative number, $\\exp(x-\\eta) \\to 0$, and the denominator approaches $1$. The integrand is simply $x^j$, which is numerically stable.\nA conditional implementation is used: if $x-\\eta$ exceeds a safe threshold (e.g., $30$), the numerically stable approximation is used. Otherwise, the direct expression is computed.\n\nFor the BE integrand, $h(x) = x^j / (\\exp(x-\\alpha)-1)$:\n- If the argument $x-\\alpha$ is large and positive, the same overflow issue occurs as in the FD case, and the same approximation $h(x) \\approx x^j \\exp(-(x-\\alpha))$ is used.\n- If $x-\\alpha$ is close to zero (which occurs for small $x$ when $\\alpha$ is close to $0^-$), the denominator $\\exp(x-\\alpha)-1$ suffers from catastrophic cancellation, leading to a significant loss of precision. This is a classic numerical pitfall, which is resolved by using the specialized function `numpy.expm1(z)`, designed to compute $e^z-1$ accurately for small $|z|$.\nThe implementation for the BE integrand will therefore use a combination of a conditional check for large arguments and the `expm1` function for all other cases, ensuring stability across all regimes.\n\nThe Python implementation will define functions for each integral type, incorporating these numerical strategies. The main `solve` function will then iterate through the specified test cases, call the appropriate integration function, and format the results to the required precision.", "answer": "```python\nimport numpy as np\nfrom scipy import integrate\n\ndef solve():\n    \"\"\"\n    Derives and numerically evaluates dimensionless Fermi-Dirac and Bose-Einstein integrals\n    based on first principles of quantum statistics.\n    \"\"\"\n\n    def _integrand_fd(x, j, eta):\n        \"\"\"\n        Numerically stable integrand for the Fermi-Dirac integral.\n        Integrand is x^j / (exp(x - eta) + 1).\n\n        Args:\n            x (float): Dimensionless energy variable.\n            j (float): Order of the integral.\n            eta (float): Reduced chemical potential.\n\n        Returns:\n            float: Value of the integrand at x.\n        \"\"\"\n        if x == 0.0 and j  0:\n            return np.inf  # Handle singularity for negative j at x=0\n        if x == 0.0 and j == 0:\n            # Special case for j=0 to avoid 0^0 issues, though not used in tests.\n            # The limit depends on eta. For eta0, limit is 1. For eta0, limit is exp(eta).\n            # Here we just compute the standard form.\n             pass \n\n        arg = x - eta\n        # For large positive arguments, exp(arg) overflows.\n        # In this regime, exp(arg) + 1 is numerically identical to exp(arg).\n        # We can rewrite the fraction as x**j * exp(-arg) to avoid overflow.\n        # A threshold of 30 is safe as exp(30) is very large but within float64 limits.\n        if arg  30.0:\n            return (x**j) * np.exp(-arg)\n        else:\n            return (x**j) / (np.exp(arg) + 1.0)\n\n    def _integrand_be(x, j, alpha):\n        \"\"\"\n        Numerically stable integrand for the Bose-Einstein integral.\n        Integrand is x^j / (exp(x - alpha) - 1).\n\n        Args:\n            x (float): Dimensionless energy variable.\n            j (float): Order of the integral.\n            alpha (float): Reduced chemical potential (must be  0).\n\n        Returns:\n            float: Value of the integrand at x.\n        \"\"\"\n        if x == 0.0:\n            # For j  1, the limit is 0.\n            # For j = 1, the limit is 1/(-alpha) if alpha is not 0.\n            # Here j=1.5, so x^1.5 / (x-alpha) - 0.\n            return 0.0\n\n        arg = x - alpha\n        # For large positive arguments, exp(arg) overflows.\n        # The approximation exp(arg) - 1 approx exp(arg) holds.\n        # We use the same stable form as in the FD case.\n        if arg  30.0:\n            return (x**j) * np.exp(-arg)\n        else:\n            # For small arguments, exp(arg) - 1 suffers from catastrophic cancellation.\n            # np.expm1(arg) is designed to compute exp(arg) - 1 accurately.\n            return (x**j) / np.expm1(arg)\n\n    def compute_fd_integral(j, eta):\n        \"\"\"\n        Computes the Fermi-Dirac integral of order j at reduced potential eta.\n        \"\"\"\n        result, _ = integrate.quad(_integrand_fd, 0, np.inf, args=(j, eta))\n        return result\n\n    def compute_be_integral(j, alpha):\n        \"\"\"\n        Computes the Bose-Einstein integral of order j at reduced potential alpha.\n        \"\"\"\n        result, _ = integrate.quad(_integrand_be, 0, np.inf, args=(j, alpha))\n        return result\n\n    # Test cases from the problem statement\n    test_cases = [\n        {'type': 'FD', 'j': 1/2, 'param': -10.0},\n        {'type': 'FD', 'j': 1/2, 'param': 0.0},\n        {'type': 'FD', 'j': 1/2, 'param': 2.0},\n        {'type': 'FD', 'j': 1/2, 'param': 10.0},\n        {'type': 'BE', 'j': 3/2, 'param': -5.0},\n        {'type': 'BE', 'j': 3/2, 'param': -1.0},\n        {'type': 'BE', 'j': 3/2, 'param': -1.0e-6},\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'FD':\n            res = compute_fd_integral(case['j'], case['param'])\n        elif case['type'] == 'BE':\n            res = compute_be_integral(case['j'], case['param'])\n        results.append(f\"{res:.8f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```", "id": "3482692"}, {"introduction": "While the free-electron model is a powerful starting point, real materials often exhibit complex electronic structures, such as the van Hove singularities common in two-dimensional systems. This practice [@problem_id:3482712] challenges you to compute the total carrier occupation in the presence of a logarithmic singularity in the density of states. You will discover how a combination of analytical insight to regularize the integrand and careful numerical integration is required to solve this physically relevant problem, a common workflow in theoretical materials science.", "problem": "Consider a single-band two-dimensional material whose electronic dispersion produces a logarithmic van Hove singularity in the density of states (DOS) near an energy $\\epsilon_s$. Assume the DOS is nonzero only on a finite symmetric interval around $\\epsilon_s$ with half-bandwidth $\\Lambda$, and is given by\n$$\ng(\\epsilon;\\epsilon_s,\\Lambda)=\\begin{cases}\n\\dfrac{1}{2\\Lambda}\\,\\ln\\!\\left(\\dfrac{\\Lambda}{|\\epsilon-\\epsilon_s|}\\right),  \\text{if } |\\epsilon-\\epsilon_s|\\Lambda \\\\\n0,  \\text{otherwise}.\n\\end{cases}\n$$\nThis DOS is integrable but has a logarithmic divergence at $\\epsilon=\\epsilon_s$. Work in dimensionless units where Boltzmann's constant is $k_{\\mathrm{B}}=1$ so that temperature $T$ and energies share the same units.\n\nYour goal is to compute the finite-temperature occupation integral\n$$\nN(\\mu,T) \\equiv \\int_{-\\infty}^{+\\infty} f(\\epsilon;\\mu,T)\\,g(\\epsilon;\\epsilon_s,\\Lambda)\\,d\\epsilon,\n$$\nfor either the Fermi-Dirac distribution (fermions)\n$$\nf_{\\mathrm{FD}}(\\epsilon;\\mu,T) = \\dfrac{1}{e^{(\\epsilon-\\mu)/T}+1},\n$$\nor the Bose-Einstein distribution (bosons)\n$$\nf_{\\mathrm{BE}}(\\epsilon;\\mu,T) = \\dfrac{1}{e^{(\\epsilon-\\mu)/T}-1},\n$$\nwith the physical constraint for bosons that $\\mu  \\epsilon_{\\min}$, where $\\epsilon_{\\min} = \\epsilon_s - \\Lambda$ is the band minimum, to avoid divergence of $f_{\\mathrm{BE}}$.\n\nYou are required to:\n- Derive, from first principles, a numerically stable quadrature strategy to evaluate $N(\\mu,T)$ that remains accurate when $\\mu$ approaches the singular energy $\\epsilon_s$ and when $T$ is small. The strategy must start from core definitions of the distributions and the given $g(\\epsilon)$, and must not assume any pre-built specialized quadrature for singular integrands.\n- Design an adaptive quadrature scheme that (i) regularizes the logarithmic singularity at $\\epsilon=\\epsilon_s$ using mathematically justified transformations or decompositions, and (ii) resolves the rapid variation of $f(\\epsilon;\\mu,T)$ near $\\epsilon=\\mu$ at low $T$.\n- Implement your algorithm as a complete, runnable program that outputs $N(\\mu,T)$ for the provided test suite below.\n\nAll numerical values are dimensionless. Express all results as decimal numbers with exactly $8$ digits after the decimal point. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[0.50000000,0.51234567]$).\n\nTest suite (each case is a tuple $(\\mathrm{stat},\\Lambda,\\epsilon_s,\\mu,T)$ where $\\mathrm{stat}\\in\\{\\text{FD},\\text{BE}\\}$ selects the distribution):\n- Case $1$ (low-temperature fermion at the singularity): $(\\text{FD},\\,1.0,\\,0.0,\\,0.0,\\,0.01)$.\n- Case $2$ (moderate-temperature fermion with $\\mu > \\epsilon_s$): $(\\text{FD},\\,1.0,\\,0.0,\\,0.2,\\,0.05)$.\n- Case $3$ (high-temperature fermion symmetry check): $(\\text{FD},\\,1.0,\\,0.0,\\,0.0,\\,1.0)$.\n- Case $4$ (ultra-low-temperature fermion with $\\mu  \\epsilon_s$): $(\\text{FD},\\,1.0,\\,0.0,\\,-0.001,\\,0.0005)$.\n- Case $5$ (boson with $\\mu$ below band minimum): $(\\text{BE},\\,1.0,\\,0.0,\\,-1.5,\\,0.2)$.\n\nFinal output format requirement:\n- The program must print a single line containing a Python-style list of the five results in the same order as the test suite, with each value rounded to exactly $8$ decimal places, no extra whitespace, and no additional text.", "solution": "The user wants me to solve a numerical integration problem in the context of computational materials science.\n\nHere's a plan:\n1.  **Validate the problem:** I need to go through the validation checklist.\n    -   **Extract Givens:** List all the provided equations, parameters, and definitions.\n    -   **Validate:** Check for scientific soundness, well-posedness, objectivity, etc.\n        -   The problem describes a single-band 2D material with a logarithmic van Hove singularity in the DOS. This is a standard model in solid-state physics, often seen in materials like graphene or high-Tc superconductors.\n        -   The DOS is given by $g(\\epsilon;\\epsilon_s,\\Lambda)=\\frac{1}{2\\Lambda}\\,\\ln\\left(\\frac{\\Lambda}{|\\epsilon-\\epsilon_s|}\\right)$ for $|\\epsilon-\\epsilon_s|\\Lambda$. This form is standard for a 2D saddle point in a band structure. Let's check if it's integrable.\n            - The integral of $g(\\epsilon)$ over the band is $\\int_{\\epsilon_s-\\Lambda}^{\\epsilon_s+\\Lambda} \\frac{1}{2\\Lambda}\\,\\ln\\left(\\frac{\\Lambda}{|\\epsilon-\\epsilon_s|}\\right) d\\epsilon$.\n            - Let $x = \\epsilon - \\epsilon_s$. The integral becomes $\\frac{1}{2\\Lambda} \\int_{-\\Lambda}^{\\Lambda} \\ln\\left(\\frac{\\Lambda}{|x|}\\right) dx$.\n            - The integrand is symmetric, so it's $\\frac{1}{\\Lambda} \\int_{0}^{\\Lambda} (\\ln \\Lambda - \\ln x) dx$.\n            - $\\int \\ln x \\,dx = x \\ln x - x$.\n            - So, $\\frac{1}{\\Lambda} [\\Lambda \\ln \\Lambda - (x \\ln x - x)]_0^{\\Lambda}$.\n            - At the lower limit, $\\lim_{x\\to 0^+} (x \\ln x - x) = 0 - 0 = 0$.\n            - At the upper limit, $(\\Lambda \\ln \\Lambda - \\Lambda)$.\n            - The integral is $\\frac{1}{\\Lambda} [(\\ln \\Lambda) \\cdot \\Lambda - (\\Lambda \\ln \\Lambda - \\Lambda)] = \\frac{1}{\\Lambda} [\\Lambda^2 \\ln \\Lambda - \\Lambda \\ln \\Lambda + \\Lambda] = \\Lambda \\ln \\Lambda - \\ln \\Lambda + 1$. This is finite. Hmm, let me re-calculate.\n            - $\\frac{1}{\\Lambda} \\int_0^\\Lambda (\\ln \\Lambda - \\ln x) dx = \\frac{1}{\\Lambda} [(\\ln \\Lambda) x - (x \\ln x - x)]_0^\\Lambda$.\n            - At $x=\\Lambda$: $(\\ln \\Lambda)\\Lambda - (\\Lambda \\ln \\Lambda - \\Lambda) = \\Lambda$.\n            - At $x\\to 0^+$: $0 - (0 - 0) = 0$.\n            - The result is $\\frac{1}{\\Lambda} [\\Lambda - 0] = 1$.\n            - So, the total number of states is normalized to 1. This is a properly normalized density of states.\n        -   The distributions are the standard Fermi-Dirac (FD) and Bose-Einstein (BE).\n        -   The integral to compute is $N(\\mu,T) = \\int_{-\\infty}^{+\\infty} f(\\epsilon;\\mu,T)\\,g(\\epsilon;\\mu,\\Lambda)\\,d\\epsilon$.\n        -   The problem highlights the numerical challenges:\n            1.  Logarithmic singularity in $g(\\epsilon)$ at $\\epsilon = \\epsilon_s$.\n            2.  Rapid change in $f(\\epsilon)$ at $\\epsilon = \\mu$ when $T$ is small (step-like behavior).\n        -   The constraint for bosons, $\\mu  \\epsilon_{\\min} = \\epsilon_s - \\Lambda$, is physically correct to ensure the BE distribution is well-defined over the entire band.\n        -   The task is to derive a numerically stable quadrature strategy. This requires careful handling of the singularities.\n        -   The test cases seem reasonable and are designed to probe the different difficult regimes:\n            -   Case 1: Low $T$, $\\mu = \\epsilon_s$. Both singularities coincide. This is the hardest case.\n            -   Case 2: Low $T$, $\\mu \\neq \\epsilon_s$. Singularities are separated.\n            -   Case 3: High $T$. The Fermi function is smooth, so the main difficulty is the log singularity. The symmetry check likely refers to particle-hole symmetry around $\\epsilon_s = 0, \\mu = 0$. In this case, $N(0,T)$ should be close to 0.5 because the DOS is symmetric and the thermal broadening is large.\n            -   Case 4: Ultra-low $T$. The Fermi function is very sharp. $\\mu$ is very close to $\\epsilon_s$.\n            -   Case 5: A standard boson case. $\\mu$ is well below the band edge. The BE distribution is smooth over the integration range, so the main challenge is the log singularity.\n        -   The problem looks valid. It's scientifically grounded, well-posed, and objective. It is also directly related to the specified topic.\n\n2.  **Develop the solution:**\n    -   The integral is $N(\\mu,T) = \\int_{\\epsilon_s-\\Lambda}^{\\epsilon_s+\\Lambda} f(\\epsilon;\\mu,T) \\frac{1}{2\\Lambda} \\ln\\left(\\frac{\\Lambda}{|\\epsilon-\\epsilon_s|}\\right) d\\epsilon$.\n    -   Let's simplify by a change of variables. Let $x = (\\epsilon - \\epsilon_s)/\\Lambda$. Then $\\epsilon = \\epsilon_s + \\Lambda x$ and $d\\epsilon = \\Lambda dx$. The integration range for $x$ is from $-1$ to $1$.\n    -   $N(\\mu,T) = \\int_{-1}^{1} f(\\epsilon_s + \\Lambda x; \\mu, T) \\frac{1}{2\\Lambda} \\ln\\left(\\frac{\\Lambda}{|\\Lambda x|}\\right) \\Lambda dx$.\n    -   $N(\\mu,T) = \\frac{1}{2} \\int_{-1}^{1} f(\\epsilon_s + \\Lambda x; \\mu, T) \\ln\\left(\\frac{1}{|x|}\\right) dx = -\\frac{1}{2} \\int_{-1}^{1} f(\\epsilon_s + \\Lambda x; \\mu, T) \\ln|x| dx$.\n    -   The argument of the Fermi/Bose function is $(\\epsilon - \\mu)/T = (\\epsilon_s + \\Lambda x - \\mu)/T$.\n    -   Let's define a new function $h(x) = f(\\epsilon_s + \\Lambda x; \\mu, T)$. The integral is $N(\\mu,T) = -\\frac{1}{2} \\int_{-1}^{1} h(x) \\ln|x| dx$.\n    -   The integrand has a logarithmic singularity at $x=0$ (corresponding to $\\epsilon=\\epsilon_s$) and potentially a sharp feature in $h(x)$ when $\\epsilon_s + \\Lambda x \\approx \\mu$, which happens at $x \\approx (\\mu - \\epsilon_s)/\\Lambda$. Let's call this point $x_\\mu = (\\mu - \\epsilon_s)/\\Lambda$.\n\n    -   **Handling the logarithmic singularity:** The standard way to handle $\\int_a^b \\phi(x) \\ln|x-c| dx$ is to use subtraction.\n        -   $\\int_a^b \\phi(x) \\ln|x-c| dx = \\int_a^b (\\phi(x) - \\phi(c)) \\ln|x-c| dx + \\phi(c) \\int_a^b \\ln|x-c| dx$.\n        -   The first integrand is now regular at $x=c$ if $\\phi(x)$ is smooth. $(\\phi(x)-\\phi(c)) \\approx \\phi'(c)(x-c)$, so the integrand behaves like $(x-c)\\ln|x-c|$, which is $0$ at $x=c$. This is numerically amenable.\n        -   The second integral can often be computed analytically. $\\int \\ln|x-c| dx = (x-c)\\ln|x-c| - (x-c)$.\n    -   Applying this to our problem: $N(\\mu,T) = -\\frac{1}{2} \\int_{-1}^{1} h(x) \\ln|x| dx$. The singularity is at $x=0$.\n    -   $N(\\mu,T) = -\\frac{1}{2} \\left[ \\int_{-1}^{1} (h(x) - h(0)) \\ln|x| dx + h(0) \\int_{-1}^{1} \\ln|x| dx \\right]$.\n    -   The analytical integral is $\\int_{-1}^{1} \\ln|x| dx = 2 \\int_0^1 \\ln(x) dx = 2 [x \\ln x - x]_0^1 = 2 ( (1 \\ln 1 - 1) - \\lim_{x\\to 0} (x \\ln x - x) ) = 2 ( (0 - 1) - (0 - 0) ) = -2$.\n    -   So, $N(\\mu,T) = -\\frac{1}{2} \\int_{-1}^{1} (h(x) - h(0)) \\ln|x| dx + h(0)$.\n    -   The value $h(0) = f(\\epsilon_s; \\mu, T)$.\n    -   The integrand is now $I(x) = (h(x) - h(0)) \\ln|x|$. For small $x$, $h(x) \\approx h(0) + h'(0)x$. So $I(x) \\approx (h'(0)x)\\ln|x|$. This is better, but still has a singularity in its derivative at $x=0$, which can be slow for standard quadratures like Gauss-Legendre.\n    -   A better way might be a change of variable. For an integral of the form $\\int_0^a g(x) dx$ where $g(x) \\sim \\ln x$, let $x=u^2$, $dx=2u du$. The integral becomes $\\int_0^{\\sqrt{a}} g(u^2) 2u du$. The term $\\ln(u^2) = 2 \\ln u$ becomes part of a new integrand that might still be singular.\n    -   Let's try a different change of variable for $\\int_0^1 G(x) \\ln(x) dx$. Let $x=e^{-t}$, $dx=-e^{-t}dt$. The integral becomes $\\int_\\infty^0 G(e^{-t}) (-t) (-e^{-t}) dt = -\\int_0^\\infty t \\, G(e^{-t}) e^{-t} dt$. This looks like something for Gauss-Laguerre quadrature, but the function $G$ (our $h(x)$) might not be polynomial-like.\n\n    -   Let's reconsider the subtraction method. The function to integrate is $G(x) = \\frac{h(x)-h(0)}{x} (x \\ln|x|)$. The first part might be smooth, but $x\\ln|x|$ still has a derivative singularity.\n    -   How about splitting the integral? $\\int_{-1}^1 = \\int_{-1}^0 + \\int_0^1$.\n    -   Consider $\\int_0^1 h(x) \\ln(x) dx$. Regularize it as $\\int_0^1 (h(x)-h(0))\\ln(x)dx + h(0)\\int_0^1 \\ln(x)dx$.\n        The second part is $h(0) * (-1)$.\n        The first part has an integrand $(h(x)-h(0))\\ln(x)$. Let's do integration by parts.\n        $\\int (h(x)-h(0))\\ln(x)dx = (h(x)-h(0))(x\\ln x - x) - \\int h'(x) (x\\ln x - x) dx$.\n        This seems to make things more complicated.\n\n    -   Let's stick to the subtraction method:\n        $N(\\mu,T) = h(0) - \\frac{1}{2} \\int_{-1}^{1} (h(x) - h(0)) \\ln|x| dx$.\n        Let's split the integral:\n        $= h(0) - \\frac{1}{2} \\int_{0}^{1} (h(x) - h(0)) \\ln x dx - \\frac{1}{2} \\int_{-1}^{0} (h(x) - h(0)) \\ln(-x) dx$.\n        In the second integral, let $u = -x$. It becomes $\\int_1^0 (h(-u)-h(0)) \\ln(u) (-du) = \\int_0^1 (h(-u)-h(0)) \\ln u du$.\n        So, $N(\\mu,T) = h(0) - \\frac{1}{2} \\int_0^1 [ (h(x)-h(0)) + (h(-x)-h(0)) ] \\ln x dx$.\n        Let $H(x) = h(x) + h(-x) - 2h(0)$.\n        $N(\\mu,T) = h(0) - \\frac{1}{2} \\int_0^1 H(x) \\ln x dx$.\n        The integrand is $H(x)\\ln x$. For small $x$, $h(x) \\approx h(0) + h'(0)x + \\frac{1}{2} h''(0)x^2$.\n        $h(-x) \\approx h(0) - h'(0)x + \\frac{1}{2} h''(0)x^2$.\n        $H(x) \\approx h''(0)x^2$.\n        The integrand near $x=0$ is $\\approx h''(0)x^2 \\ln x$. This is well-behaved. $\\lim_{x\\to 0} x^2 \\ln x = 0$. The integrand is continuous and finite everywhere on $[0, 1]$. Standard quadrature methods like Gauss-Legendre should work very well on this regularized form.\n\n    -   So, the strategy is:\n        1.  Analytically transform the integral:\n            $N(\\mu,T) = f(\\epsilon_s; \\mu, T) - \\frac{1}{2} \\int_0^1 [h(x)+h(-x)-2h(0)] \\ln x \\, dx$,\n            where $h(x) = f(\\epsilon_s + \\Lambda x; \\mu, T)$.\n        2.  The integrand is $G(x) = [h(x)+h(-x)-2h(0)] \\ln x$. This integrand is now regular and can be evaluated using standard numerical quadrature.\n\n    -   **Handling the step-like feature in $f(\\epsilon; \\mu, T)$:**\n        -   The Fermi/Bose function $f$ varies rapidly around $\\epsilon=\\mu$. This corresponds to $x = x_\\mu = (\\mu-\\epsilon_s)/\\Lambda$.\n        -   At low temperature $T$, this variation happens over a scale of a few $T$. In terms of $x$, the scale is $\\Delta x \\sim T/\\Lambda$.\n        -   If $T/\\Lambda$ is very small, a standard fixed-point quadrature rule might miss this narrow feature unless it has a very high number of points.\n        -   An adaptive quadrature scheme is necessary. The scheme should add more points in regions where the integrand varies rapidly.\n        -   A simple adaptive scheme (like the one used in `scipy.integrate.quad`) works by recursively subdividing intervals where the error estimate is large.\n        -   The function to integrate is $G(x) = [h(x)+h(-x)-2h(0)] \\ln x$. The rapid variation comes from $h(x)$ and $h(-x)$.\n        -   Specifically, $h(x)$ varies rapidly near $x=x_\\mu$, and $h(-x)$ varies rapidly near $x=-x_\\mu$.\n        -   So, the integrand $G(x)$ will vary rapidly near $x=|x_\\mu|$ (since the domain is $[0,1]$).\n        -   The adaptive quadrature should naturally handle this by placing more points near $|x_\\mu|$.\n\n    -   **Implementation:**\n        -   I will need to implement an adaptive quadrature routine. A simple one based on Simpson's rule is a good choice.\n        -   Let `integrate(func, a, b, tol)` be the adaptive quadrature function.\n        -   `S1 = simpson(func, a, b)` using one interval.\n        -   `c = (a+b)/2`.\n        -   `S2 = simpson(func, a, c) + simpson(func, c, b)` using two intervals.\n        -   If `|S1 - S2|  15 * tol`, return `S2 + (S2 - S1)/15` (error correction).\n        -   Else, return `integrate(func, a, c, tol/2) + integrate(func, c, b, tol/2)`.\n        -   `simpson(func, a, b)` is `(b-a)/6 * (func(a) + 4*func((a+b)/2) + func(b))`.\n        -   Need to handle the endpoints carefully. The integrand $G(x)$ is $0$ at $x=0$. At $x=1$, it is $G(1) = [h(1)+h(-1)-2h(0)]\\ln 1 = 0$. So the integrand is zero at both ends of $[0, 1]$.\n        -   The integrand is\n            $G(x) = [f(\\epsilon_s + \\Lambda x; \\mu, T) + f(\\epsilon_s - \\Lambda x; \\mu, T) - 2f(\\epsilon_s; \\mu, T)] \\ln x$.\n        -   For $x \\to 0$, we have $G(x) \\approx (h''(0) x^2) \\ln x$.\n            $h(x) = (e^{(\\epsilon_s+\\Lambda x - \\mu)/T} \\pm 1)^{-1}$.\n            $h'(x) = \\mp (\\Lambda/T) \\frac{e^{(\\epsilon_s+\\Lambda x - \\mu)/T}}{(e^{(\\epsilon_s+\\Lambda x - \\mu)/T} \\pm 1)^2}$.\n            $h''(x) = \\mp (\\Lambda/T)^2 e^{(\\epsilon_s+\\Lambda x - \\mu)/T} \\frac{1 - e^{(\\epsilon_s+\\Lambda x - \\mu)/T}}{(e^{(\\epsilon_s+\\Lambda x - \\mu)/T} \\pm 1)^3}$.\n            $h''(0)$ can be computed. So the integrand is well-behaved at $x=0$. When `func(0)` is called, I must return $0$.\n\n        -   Alternatively, I can use `scipy.integrate.quad`. The problem statement says \"design an adaptive quadrature scheme... not assume any pre-built specialized quadrature for singular integrands\". `scipy.integrate.quad` is a general-purpose adaptive quadrature, not one specialized for singularities. The point of the derivation was to *remove* the singularity, so the problem becomes regular. Using a standard adaptive integrator on the *regularized* integrand seems acceptable. It's part of the strategy. \"Design an adaptive quadrature scheme\" can be interpreted as designing the overall algorithm, which includes the analytical regularization step *and then* applying a standard numerical technique. I will use `scipy.integrate.quad` because it is robust and available in the `scipy` library specified. Re-implementing it from scratch is possible but error-prone and doesn't add much to the core physics/math problem. The critical part is the regularization, which I have derived.\n\n    -   Let's check the derivation again.\n        $N = -\\frac{1}{2} \\int_{-1}^1 h(x) \\ln|x| dx$\n        $= -\\frac{1}{2} \\int_{-1}^1 (h(x)-h(0)) \\ln|x| dx - \\frac{1}{2} h(0) \\int_{-1}^1 \\ln|x| dx$\n        $= -\\frac{1}{2} \\int_{-1}^1 (h(x)-h(0)) \\ln|x| dx - \\frac{1}{2} h(0) (-2)$\n        $= h(0) - \\frac{1}{2} \\int_{-1}^1 (h(x)-h(0)) \\ln|x| dx$\n        Correct.\n        Integral part:\n        $\\int_{-1}^1 (h(x)-h(0)) \\ln|x| dx = \\int_0^1 (h(x)-h(0)) \\ln x dx + \\int_{-1}^0 (h(x)-h(0)) \\ln(-x) dx$\n        Second part: $u=-x, du=-dx$. $\\int_1^0 (h(-u)-h(0)) \\ln u (-du) = \\int_0^1 (h(-u)-h(0)) \\ln u du$.\n        Summing them: $\\int_0^1 (h(x)-h(0)+h(-x)-h(0)) \\ln x dx = \\int_0^1 (h(x)+h(-x)-2h(0)) \\ln x dx$.\n        So $N(\\mu,T) = h(0) - \\frac{1}{2} \\int_0^1 (h(x)+h(-x)-2h(0)) \\ln x dx$.\n        Yes, the factor is $1/2$. My derivation seems correct now.\n\n    -   **Final Algorithm:**\n        1.  Given a test case $(\\mathrm{stat}, \\Lambda, \\epsilon_s, \\mu, T)$.\n        2.  Define the statistics function $f(\\epsilon; \\mu, T)$.\n            - If stat is 'FD', $f = 1 / (e^{(\\epsilon-\\mu)/T} + 1)$.\n            - If stat is 'BE', $f = 1 / (e^{(\\epsilon-\\mu)/T} - 1)$. Be careful with potential division by zero if $(\\epsilon-\\mu)/T$ is very small. $e^x - 1 \\approx x$ for small $x$. For FD, $e^x+1$ is never a problem. For BE, the condition $\\mu  \\epsilon_{\\min}$ ensures $\\epsilon - \\mu  0$ always in the integration domain, so argument of exp is positive.\n        3.  Define the helper function $h(x) = f(\\epsilon_s + \\Lambda x; \\mu, T)$.\n        4.  Calculate the constant term $C_0 = h(0) = f(\\epsilon_s; \\mu, T)$.\n        5.  Define the regularized integrand for $x \\in (0, 1]$:\n            $G(x) = (h(x) + h(-x) - 2C_0) \\ln x$.\n            At $x=0$, this should be $0$.\n        6.  Use `scipy.integrate.quad` to compute the integral $I = \\int_0^1 G(x) dx$.\n        7.  The final result is $N(\\mu, T) = C_0 - \\frac{1}{2} I$.\n\n    -   **Numerical Stability Considerations:**\n        -   When $T$ is very small, $(\\epsilon-\\mu)/T$ can become very large (positive or negative).\n        -   If $(\\epsilon-\\mu)/T  700$, $e^{(\\epsilon-\\mu)/T}$ will overflow. In this case, $f_{FD} \\approx 0$ and $f_{BE} \\approx 0$.\n        -   If $(\\epsilon-\\mu)/T  -700$, $e^{(\\epsilon-\\mu)/T} \\approx 0$. In this case, $f_{FD} \\approx 1$ and $f_{BE} \\approx -1$.\n        -   These limits must be handled in the implementation of $f(\\epsilon; \\mu, T)$.\n        -   The term $h(x)+h(-x)-2h(0)$ might suffer from catastrophic cancellation if $x$ is very small.\n            Let's analyze $H(x) = h(x)+h(-x)-2h(0)$.\n            $H(x) = [h(x)-h(0)] + [h(-x)-h(0)]$.\n            Using Taylor series around $x=0$:\n            $h(x)-h(0) = h'(0)x + \\frac{h''(0)}{2}x^2 + \\frac{h'''(0)}{6}x^3 + \\dots$\n            $h(-x)-h(0) = -h'(0)x + \\frac{h''(0)}{2}x^2 - \\frac{h'''(0)}{6}x^3 + \\dots$\n            $H(x) = h''(0)x^2 + O(x^4)$.\n            So for small $x$, we can compute $H(x)$ more accurately as $h''(0)x^2$.\n            $h''(0) = \\mp (\\Lambda/T)^2 e^{(\\epsilon_s - \\mu)/T} \\frac{1 - e^{(\\epsilon_s - \\mu)/T}}{(e^{(\\epsilon_s - \\mu)/T} \\pm 1)^3}$. This formula is stable.\n            When is \"small $x$\" applicable? The adaptive quadrature routine will sample at various $x$. For very small $x$, using the Taylor expansion might be better.\n            Let's see if we can do this without Taylor.\n            The expression is $(h(x)+h(-x)) - 2h(0)$.\n            The direct calculation of $H(x) = (h(x)+h(-x)) - 2h(0)$ should be fine. For small $x$, `h(x)` is very close to `h(0)`.\n            A fix: use a function that computes $h(x)-h(0)$ accurately for small $x$.\n            $h(x)-h(0) = \\frac{1}{e^{y_0+\\delta}\\pm1} - \\frac{1}{e^{y_0}\\pm1} = \\frac{e^{y_0}\\pm1 - (e^{y_0+\\delta}\\pm1)}{(e^{y_0+\\delta}\\pm1)(e^{y_0}\\pm1)} = \\frac{e^{y_0}(1-e^\\delta)}{(e^{y_0+\\delta}\\pm1)(e^{y_0}\\pm1)}$.\n            This is accurate for small $\\delta$. We can use `np.expm1` for $e^\\delta-1$.\n            $1-e^\\delta = - (e^\\delta-1) = -\\mathrm{expm1}(\\delta)$.\n            So $h(x)-h(0) = \\frac{-e^{y_0} \\mathrm{expm1}(\\delta)}{(e^{y_0+\\delta}\\pm 1)(e^{y_0}\\pm 1)}$. This is the way to go for the integrand.\n            Let's call $d(x) = h(x)-h(0)$.\n            The term I need is $H(x) = d(x) + d(-x)$.\n            $d(-x) = h(-x)-h(0) = \\frac{-e^{y_0} \\mathrm{expm1}(-\\delta)}{(e^{y_0-\\delta}\\pm 1)(e^{y_0}\\pm 1)}$.\n            So $H(x) = \\frac{-e^{y_0}}{(e^{y_0}\\pm 1)} \\left( \\frac{\\mathrm{expm1}(\\delta)}{e^{y_0+\\delta}\\pm 1} + \\frac{\\mathrm{expm1}(-\\delta)}{e^{y_0-\\delta}\\pm 1} \\right)$.\n            This form avoids the catastrophic cancellation.\n            But I'll stick to the simpler implementation as standard double precision arithmetic is likely sufficient for the given test cases. `scipy.quad`'s algorithm (QUADPACK) is quite sophisticated and can handle this.\n\n    -   **Special Case for Fermi-Dirac statistics with $\\mu = \\epsilon_s$:**\n        In this case, the argument of the Fermi function is $(\\epsilon_s + \\Lambda x - \\epsilon_s)/T = \\Lambda x / T$ for $h(x)$, and $(\\epsilon_s - \\Lambda x - \\epsilon_s)/T = -\\Lambda x / T$ for $h(-x)$.\n        Let $y = \\Lambda x / T$. The Fermi function $f_{\\mathrm{FD}}(y) = 1/(e^y+1)$ has the property $f_{\\mathrm{FD}}(y) + f_{\\mathrm{FD}}(-y) = 1$.\n        Therefore, $h(x) + h(-x) = f_{\\mathrm{FD}}(\\Lambda x / T) + f_{\\mathrm{FD}}(-\\Lambda x / T) = 1$.\n        The constant term is $h(0) = f_{\\mathrm{FD}}(0) = 1/(e^0+1) = 0.5$.\n        The term in the square brackets of the regularized integral becomes $[h(x) + h(-x) - 2h(0)] = 1 - 2(0.5) = 0$.\n        The integral is identically zero.\n        The result is $N(\\mu=\\epsilon_s, T) = h(0) - 0 = 0.5$.\n        This exact result applies to any case with Fermi-Dirac statistics where the chemical potential $\\mu$ is equal to the singularity energy $\\epsilon_s$, regardless of $\\Lambda$ or $T$. This covers test cases 1 and 3.\n\n    -   **Final structure for the code.**\n        I will implement the logic using `scipy.integrate.quad` on the regularized integrand. I will also explicitly handle the FD case where $\\mu = \\epsilon_s$.\n\nFinal check of the problem statement and constraints.\n- Problem: OK.\n- Validation: Done, problem is valid.\n- Solution derivation: Complete.\n- Code structure: planned.\n- Output format: noted.\nIt all appears correct and consistent. I will now generate the solution.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Solves the problem of calculating the occupation integral N(mu, T)\n    for a given density of states with a logarithmic singularity.\n    \"\"\"\n\n    test_cases = [\n        # Case 1 (low-temperature fermion at the singularity)\n        ('FD', 1.0, 0.0, 0.0, 0.01),\n        # Case 2 (moderate-temperature fermion with mu  eps_s)\n        ('FD', 1.0, 0.0, 0.2, 0.05),\n        # Case 3 (high-temperature fermion symmetry check)\n        ('FD', 1.0, 0.0, 0.0, 1.0),\n        # Case 4 (ultra-low-temperature fermion with mu  eps_s)\n        ('FD', 1.0, 0.0, -0.001, 0.0005),\n        # Case 5 (boson with mu below band minimum)\n        ('BE', 1.0, 0.0, -1.5, 0.2),\n    ]\n\n    results = []\n    # Set a high precision for the quadrature\n    quad_tol = 1e-12\n\n    for case in test_cases:\n        stat, Lambda, eps_s, mu, T = case\n\n        # Handle the special symmetry case for Fermi-Dirac statistics\n        # where mu coincides with the singularity energy eps_s.\n        if stat == 'FD' and np.isclose(mu, eps_s):\n            results.append(0.5)\n            continue\n\n        def f(eps, mu, T, stat):\n            \"\"\"\n            Calculates the Fermi-Dirac or Bose-Einstein distribution function.\n            Includes guards against overflow/underflow.\n            \"\"\"\n            if T == 0:\n                if stat == 'FD':\n                    return 1.0 if eps  mu else 0.0 if eps  mu else 0.5\n                else: # 'BE'\n                    # Bosons at T=0 would macroscopically occupy the lowest energy state,\n                    # but this is not relevant for the given continuous DOS and T0 cases.\n                    return 0.0\n            \n            arg = (eps - mu) / T\n            \n            # Overflow/underflow protection\n            if arg  700:  # np.exp(arg) would overflow\n                return 0.0\n            if arg  -700: # np.exp(arg) would be 0\n                if stat == 'FD':\n                    return 1.0\n                else: # 'BE'\n                    # Not strictly necessary due to mu  eps_min constraint,\n                    # but included for robustness.\n                    return -1.0\n\n            exp_arg = np.exp(arg)\n            \n            if stat == 'FD':\n                return 1.0 / (exp_arg + 1.0)\n            else: # 'BE'\n                # The constraint mu  eps_min ensures eps  mu for all relevant energies,\n                # so arg  0 and exp_arg  1. The denominator is safe.\n                return 1.0 / (exp_arg - 1.0)\n\n        # The constant term h(0) in the regularized formula\n        # h(x) = f(eps_s + Lambda*x, ...)\n        C0 = f(eps_s, mu, T, stat)\n\n        def integrand(x):\n            \"\"\"\n            The regularized integrand G(x) = [h(x) + h(-x) - 2h(0)] * ln(x)\n            for the integral from 0 to 1.\n            \"\"\"\n            # By construction, the integrand tends to 0 as x - 0.\n            if x == 0:\n                return 0.0\n            \n            # h(x) = f(eps_s + Lambda * x, ...)\n            term_p = f(eps_s + Lambda * x, mu, T, stat)\n            # h(-x) = f(eps_s - Lambda * x, ...)\n            term_n = f(eps_s - Lambda * x, mu, T, stat)\n            \n            # The expression h(x) + h(-x) - 2h(0) is numerically stable enough\n            # for standard double precision and the given test cases.\n            val = term_p + term_n - 2.0 * C0\n            \n            return val * np.log(x)\n\n        # The regularized form is N = C0 - 0.5 * integral(G(x) dx, 0, 1)\n        integral_val, _ = quad(integrand, 0, 1, epsabs=quad_tol, epsrel=quad_tol)\n        \n        result = C0 - 0.5 * integral_val\n        results.append(result)\n\n    # Format the final output string\n    formatted_results = [f\"{r:.8f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3482712"}, {"introduction": "A key question in physics is determining the boundary between classical and quantum descriptions. This final practice [@problem_id:3482724] frames this question as a computational experiment: at what temperature does the classical Maxwell-Boltzmann approximation fail for describing plasmon dispersion in an electron gas? By leveraging the tools for evaluating Fermi-Dirac integrals, you will quantify the breakdown of the classical limit and gain a deeper appreciation for when a full quantum statistical treatment is indispensable for accurately modeling material properties.", "problem": "Consider a three-dimensional, isotropic, non-relativistic free electron gas used in computational materials science. Let $n$ be the electron number density, $m$ the electron mass, $e$ the elementary charge, $\\varepsilon_0$ the vacuum permittivity, $\\hbar$ the reduced Planck constant, and $k_B$ the Boltzmann constant. Define the long-wavelength longitudinal plasmon dispersion as the solution $\\omega(q,T)$ of a linearized response theory in which the distribution enters only through its velocity second moment. In this approximation, the plasmon angular frequency at wavevector magnitude $q$ and temperature $T$ can be written in terms of the electron plasma frequency $\\omega_p$ and the velocity moment of the equilibrium distribution $f(\\epsilon)$,\n$$\n\\omega_p = \\sqrt{\\frac{n e^2}{m \\varepsilon_0}},\\quad \n\\omega^2(q,T;f) = \\omega_p^2 + q^2\\,\\langle v^2 \\rangle_f(T),\n$$\nwhere $\\langle v^2 \\rangle_f(T)$ denotes the average of $v^2$ taken over the equilibrium distribution $f(\\epsilon)$ in three dimensions.\n\nTwo choices of $f(\\epsilon)$ are to be contrasted:\n1. The Fermi-Dirac distribution for spin-$\\tfrac{1}{2}$ electrons with spin degeneracy $g_s=2$,\n$$\nf_{\\mathrm{FD}}(\\epsilon; \\mu,T) = \\frac{1}{1+\\exp\\!\\left(\\frac{\\epsilon-\\mu}{k_B T}\\right)},\n$$\nwhere the chemical potential $\\mu(T)$ is determined by the number density constraint using the three-dimensional density of states $g(\\epsilon)$ for free electrons,\n$$\nn = \\int_0^\\infty g(\\epsilon)\\, f_{\\mathrm{FD}}(\\epsilon;\\mu,T)\\, d\\epsilon,\n$$\nwhere\n$$\ng(\\epsilon) = \\frac{g_s}{2\\pi^2}\\left(\\frac{2 m}{\\hbar^2}\\right)^{3/2}\\sqrt{\\epsilon}.\n$$\n\n2. The Maxwell-Boltzmann distribution,\n$$\nf_{\\mathrm{MB}}(\\epsilon; \\mu,T) = \\exp\\!\\left(-\\frac{\\epsilon-\\mu}{k_B T}\\right),\n$$\nwith the chemical potential $\\mu(T)$ fixed by the same number density constraint $n = \\int_0^\\infty g(\\epsilon)\\, f_{\\mathrm{MB}}(\\epsilon;\\mu,T)\\, d\\epsilon$.\n\nFor an isotropic distribution $f(\\epsilon)$, the velocity second moment can be obtained from the kinetic energy per particle $\\langle \\epsilon \\rangle_f(T)$ via $\\langle v^2 \\rangle_f(T) = \\tfrac{2}{m}\\langle \\epsilon \\rangle_f(T)$, with\n$$\n\\langle \\epsilon \\rangle_f(T) = \\frac{1}{n}\\int_0^\\infty \\epsilon\\, g(\\epsilon)\\, f(\\epsilon;\\mu,T)\\, d\\epsilon.\n$$\n\nDefine the temperature-dependent Maxwell-Boltzmann and Fermi-Dirac plasmon frequencies, $\\omega_{\\mathrm{MB}}(q,T)$ and $\\omega_{\\mathrm{FD}}(q,T)$, by substituting $\\langle v^2 \\rangle_{f_{\\mathrm{MB}}}(T)$ and $\\langle v^2 \\rangle_{f_{\\mathrm{FD}}}(T)$ into the above dispersion relation for $\\omega^2(q,T;f)$.\n\nFor a fixed tolerance $\\delta$ (expressed as a decimal) and fixed $(n,q)$, define the breakdown temperature $T^\\star$ as the smallest temperature, scanned from a high value downward, at which the relative discrepancy in plasmon dispersion computed with $f_{\\mathrm{FD}}(\\epsilon)$ versus $f_{\\mathrm{MB}}(\\epsilon)$ exceeds $\\delta$:\n$$\n\\frac{\\left|\\omega_{\\mathrm{FD}}(q,T) - \\omega_{\\mathrm{MB}}(q,T)\\right|}{\\omega_{\\mathrm{FD}}(q,T)} > \\delta.\n$$\nIf no such temperature is found within a prescribed scan range, return $-1$.\n\nYou must implement a program that:\n- Solves for the Fermi-Dirac chemical potential $\\mu(T)$ from the number density constraint using the given density of states.\n- Computes $\\langle v^2 \\rangle_{f_{\\mathrm{FD}}}(T)$ and $\\langle v^2 \\rangle_{f_{\\mathrm{MB}}}(T)$ from first principles via the above integrals.\n- Constructs $\\omega_{\\mathrm{FD}}(q,T)$ and $\\omega_{\\mathrm{MB}}(q,T)$ and evaluates the relative discrepancy criterion.\n- Scans temperatures logarithmically from a high temperature down to a low temperature, both chosen proportional to the Fermi temperature $T_F$ of the electron gas, where $T_F = \\epsilon_F/k_B$ and $\\epsilon_F = \\tfrac{\\hbar^2}{2m}(3\\pi^2 n)^{2/3}$.\n- Outputs the first temperature $T^\\star$ in the scan (from high to low) that violates the tolerance, or $-1$ if none is found in the scan range.\n\nPhysical units and output requirements:\n- Use the International System of Units (SI) for all quantities and calculations.\n- Express each breakdown temperature $T^\\star$ in Kelvin, rounded to the nearest integer.\n- Angle units are not used in this problem.\n- Percentages are not to be used; tolerances must be decimals.\n\nTest suite specification:\nEvaluate the breakdown temperature for the following parameter sets, which together probe typical metallic densities, various wavevectors, and an edge case:\n1. $n = 8.5\\times 10^{28}\\ \\mathrm{m}^{-3}$, $q = 1.0\\times 10^{9}\\ \\mathrm{m}^{-1}$, $\\delta = 0.05$.\n2. $n = 8.5\\times 10^{28}\\ \\mathrm{m}^{-3}$, $q = 5.0\\times 10^{9}\\ \\mathrm{m}^{-1}$, $\\delta = 0.05$.\n3. $n = 1.0\\times 10^{26}\\ \\mathrm{m}^{-3}$, $q = 1.0\\times 10^{9}\\ \\mathrm{m}^{-1}$, $\\delta = 0.05$.\n4. $n = 1.0\\times 10^{23}\\ \\mathrm{m}^{-3}$, $q = 1.0\\times 10^{9}\\ \\mathrm{m}^{-1}$, $\\delta = 0.05$.\n5. Edge case: $n = 1.0\\times 10^{28}\\ \\mathrm{m}^{-3}$, $q = 1.0\\times 10^{8}\\ \\mathrm{m}^{-1}$, $\\delta = 0.50$.\n\nTemperature scan range:\nFor each test case, scan $T$ on a logarithmic grid of $N=64$ points from $T_{\\max} = 5\\,T_F$ down to $T_{\\min} = 0.05\\,T_F$. The algorithm must identify the smallest $T$ in this descending list at which the above inequality holds, and return that $T$ rounded to the nearest integer in Kelvin. If no such $T$ is found, return $-1$.\n\nFinal output format:\nYour program should produce a single line of output containing the results for the five test cases as a comma-separated list of integers enclosed in square brackets (e.g., \"[T1,T2,T3,T4,T5]\"), where each $T_i$ is the breakdown temperature in Kelvin for the corresponding test case or $-1$ if not found within the scan range.", "solution": "The problem requires the determination of a \"breakdown temperature\" $T^\\star$, defined as the threshold at which a classical approximation for the plasmon dispersion in a free electron gas deviates by a specified tolerance $\\delta$ from the correct quantum mechanical result. The solution necessitates a thorough analysis based on the principles of quantum statistics, specifically contrasting the Fermi-Dirac (FD) distribution with the classical Maxwell-Boltzmann (MB) limit.\n\nThe plasmon dispersion relation is given in a linearized, long-wavelength approximation as:\n$$\n\\omega^2(q,T;f) = \\omega_p^2 + q^2\\,\\langle v^2 \\rangle_f(T)\n$$\nwhere $q$ is the wavevector magnitude, $T$ is the temperature, and $\\omega_p = \\sqrt{n e^2 / (m \\varepsilon_0)}$ is the electron plasma frequency. The term $\\langle v^2 \\rangle_f(T)$ represents the mean square velocity of the electrons, which depends on the equilibrium energy distribution function $f(\\epsilon)$. For an isotropic gas, the kinetic energy is $\\epsilon = \\frac{1}{2} m v^2$, leading to the relation $\\langle v^2 \\rangle_f(T) = \\frac{2}{m}\\langle \\epsilon \\rangle_f(T)$, where $\\langle \\epsilon \\rangle_f(T)$ is the average kinetic energy per particle.\n\nThe core of the problem lies in calculating $\\langle \\epsilon \\rangle_f(T)$ for both the Fermi-Dirac and Maxwell-Boltzmann distributions. The average energy is defined by:\n$$\n\\langle \\epsilon \\rangle_f(T) = \\frac{1}{n}\\int_0^\\infty \\epsilon\\, g(\\epsilon)\\, f(\\epsilon;\\mu,T)\\, d\\epsilon\n$$\nwhere $n$ is the electron number density, $\\mu$ is the chemical potential, and $g(\\epsilon)$ is the three-dimensional density of states for a free electron gas with spin degeneracy $g_s=2$:\n$$\ng(\\epsilon) = \\frac{g_s}{2\\pi^2}\\left(\\frac{2 m}{\\hbar^2}\\right)^{3/2}\\sqrt{\\epsilon} = C \\sqrt{\\epsilon}\n$$\nThe constant $C$ is a shorthand for $C = \\frac{g_s}{2\\pi^2}\\left(\\frac{2 m}{\\hbar^2}\\right)^{3/2}$. The chemical potential $\\mu(T)$ is determined for each distribution by the number density constraint:\n$$\nn = \\int_0^\\infty g(\\epsilon)\\, f(\\epsilon;\\mu,T)\\, d\\epsilon\n$$\n\nFirst, we analyze the Maxwell-Boltzmann (classical) case. The distribution is $f_{\\mathrm{MB}}(\\epsilon) = \\exp(-(\\epsilon-\\mu)/(k_B T))$. The average energy $\\langle \\epsilon \\rangle_{\\mathrm{MB}}(T)$ is found to be $\\frac{3}{2} k_B T$, a direct consequence of the equipartition theorem. This can be derived by evaluating the integrals for $n$ and the total energy density $U_{\\mathrm{MB}} = \\int \\epsilon g(\\epsilon) f_{\\mathrm{MB}} d\\epsilon$, which are standard Gamma function integrals. The chemical potential term cancels in the ratio $U_{\\mathrm{MB}}/n$, yielding the simple result. Therefore, the classical velocity moment is:\n$$\n\\langle v^2 \\rangle_{\\mathrm{MB}}(T) = \\frac{2}{m} \\left(\\frac{3}{2} k_B T\\right) = \\frac{3 k_B T}{m}\n$$\nThe corresponding classical plasmon frequency is $\\omega_{\\mathrm{MB}}(q,T) = \\sqrt{\\omega_p^2 + q^2 \\frac{3 k_B T}{m}}$.\n\nNext, we address the Fermi-Dirac (quantum) case. The distribution is $f_{\\mathrm{FD}}(\\epsilon) = (1+\\exp((\\epsilon-\\mu)/(k_B T)))^{-1}$. The integrals involving this distribution do not generally have simple closed-form solutions and must be expressed in terms of Fermi-Dirac integrals, defined as:\n$$\nF_j(\\eta) = \\frac{1}{\\Gamma(j+1)} \\int_0^\\infty \\frac{x^j}{1+e^{x-\\eta}} dx\n$$\nwhere $\\eta = \\mu/(k_B T)$ is the reduced chemical potential and $\\Gamma(z)$ is the Gamma function.\nBy performing a change of variables $x = \\epsilon / (k_B T)$, the number density constraint becomes:\n$$\nn = C (k_B T)^{3/2} \\Gamma(3/2) F_{1/2}(\\eta)\n$$\nThe Fermi energy $\\epsilon_F = k_B T_F = \\frac{\\hbar^2}{2m}(3\\pi^2 n)^{2/3}$ is defined from the $T=0$ limit, where $n = \\frac{2}{3}C \\epsilon_F^{3/2}$. Equating the expression for $n$ at finite $T$ with the expression involving $\\epsilon_F$ yields a condition for $\\eta$:\n$$\n\\left(\\frac{T_F}{T}\\right)^{3/2} = \\frac{3\\sqrt{\\pi}}{4} F_{1/2}(\\eta)\n$$\nFor a given temperature $T$, this equation must be solved numerically for $\\eta$.\nSimilarly, the average energy per particle is found to be:\n$$\n\\langle \\epsilon \\rangle_{\\mathrm{FD}}(T) = \\frac{3}{2} k_B T \\frac{F_{3/2}(\\eta)}{F_{1/2}(\\eta)}\n$$\nThus, the quantum velocity moment is:\n$$\n\\langle v^2 \\rangle_{\\mathrm{FD}}(T) = \\frac{2}{m} \\langle \\epsilon \\rangle_{\\mathrm{FD}}(T) = \\frac{3 k_B T}{m} \\frac{F_{3/2}(\\eta)}{F_{1/2}(\\eta)}\n$$\nThe quantum plasmon frequency is $\\omega_{\\mathrm{FD}}(q,T) = \\sqrt{\\omega_p^2 + q^2 \\langle v^2 \\rangle_{\\mathrm{FD}}(T)}$.\n\nThe computational algorithm proceeds as follows:\n1.  For each test case $(n, q, \\delta)$, calculate the derived constants: Fermi energy $\\epsilon_F$, Fermi temperature $T_F$, and plasma frequency $\\omega_p$.\n2.  Establish a logarithmic temperature grid of $N=64$ points, descending from $T_{\\max} = 5\\,T_F$ to $T_{\\min} = 0.05\\,T_F$.\n3.  Iterate through the temperatures $T$ in this grid, from highest to lowest. For each $T$:\n    a.  Calculate $\\omega_{\\mathrm{MB}}(q,T)$ using its simple analytical form.\n    b.  To calculate $\\omega_{\\mathrm{FD}}(q,T)$:\n        i.   Determine the target value $C_{target} = \\frac{4}{3\\sqrt{\\pi}} (T_F/T)^{3/2}$.\n        ii.  Numerically solve the equation $F_{1/2}(\\eta) = C_{target}$ for the reduced chemical potential $\\eta$. This requires a root-finding algorithm (e.g., bisection or Brent's method) and a numerical integrator for the function $F_{1/2}(\\eta)$.\n        iii. With the obtained $\\eta$, numerically compute the integral for $F_{3/2}(\\eta)$.\n        iv.  Calculate $\\langle v^2 \\rangle_{\\mathrm{FD}}(T)$ and subsequently $\\omega_{\\mathrm{FD}}(q,T)$.\n    c.  Evaluate the relative discrepancy criterion: $\\frac{|\\omega_{\\mathrm{FD}}(q,T) - \\omega_{\\mathrm{MB}}(q,T)|}{\\omega_{\\mathrm{FD}}(q,T)} > \\delta$.\n4.  If the criterion is met, the current temperature $T$ is the breakdown temperature $T^\\star$. Record its value, rounded to the nearest integer, and proceed to the next test case.\n5.  If the loop completes without the criterion being met, no breakdown was found in the specified range. Record $-1$ for this case.\n6.  Finally, collect and present the results for all test cases in the specified list format. This procedure systematically compares the quantum and classical models, identifying the temperature regime where quantum effects, encapsulated by the Fermi-Dirac statistics, become significant for the plasmon dynamics.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import constants, optimize, integrate, special\n\ndef solve():\n    \"\"\"\n    Solves the breakdown temperature problem for a set of test cases.\n    \"\"\"\n    # Physical constants from scipy.constants in SI units\n    m_e = constants.m_e\n    e = constants.e\n    hbar = constants.hbar\n    k_B = constants.k\n    epsilon_0 = constants.epsilon_0\n    \n    # Spin degeneracy for electrons\n    g_s = 2\n\n    def fermi_dirac_integral(j, eta):\n        \"\"\"\n        Computes the complete Fermi-Dirac integral F_j(eta).\n        F_j(eta) = 1/Gamma(j+1) * integral from 0 to inf of x^j / (1 + exp(x-eta)) dx\n        \"\"\"\n        # Numerically stable integrand for the Fermi-Dirac integral\n        def integrand(x):\n            # The term exp(x - eta) can overflow for large x-eta.\n            # When x - eta is large and positive, the denominator is ~exp(x-eta),\n            # so the integrand is x^j * exp(-(x-eta)).\n            if x - eta  700: # np.log(np.finfo(float).max) ~ 709\n                return 0.0 # Effectively zero\n            return x**j / (1.0 + np.exp(x - eta))\n\n        integral_val, _ = integrate.quad(integrand, 0, np.inf)\n        return integral_val / special.gamma(j + 1)\n\n    def solve_one_case(n, q, delta):\n        \"\"\"\n        Calculates the breakdown temperature T* for a single parameter set.\n        \"\"\"\n        # Calculate derived physical quantities\n        try:\n            # Fermi energy\n            epsilon_F = (hbar**2 / (2 * m_e)) * (3 * np.pi**2 * n)**(2/3)\n            # Fermi temperature\n            T_F = epsilon_F / k_B\n            # Plasma frequency squared\n            omega_p_sq = (n * e**2) / (m_e * epsilon_0)\n        except (ValueError, ZeroDivisionError):\n            # Handles cases with non-physical n\n            return -1\n\n        # Temperature scan range parameters\n        T_max = 5.0 * T_F\n        T_min = 0.05 * T_F\n        N_pts = 64\n        \n        # Avoid issues with T_F=0 for n=0\n        if T_F == 0:\n            return -1\n        \n        # Logarithmic temperature grid, scanned from high to low\n        temp_scan = np.logspace(np.log10(T_min), np.log10(T_max), N_pts)[::-1]\n\n        # Iterate through temperatures from high to low\n        for T in temp_scan:\n            # 1. Maxwell-Boltzmann (classical) calculation\n            v2_MB = (3 * k_B * T) / m_e\n            omega_MB_sq = omega_p_sq + q**2 * v2_MB\n            omega_MB = np.sqrt(omega_MB_sq)\n\n            # 2. Fermi-Dirac (quantum) calculation\n            # Find reduced chemical potential eta = mu / (k_B * T)\n            # Target value for F_{1/2}(eta)\n            target_F_half = (4 / (3 * np.sqrt(np.pi))) * (T_F / T)**(1.5)\n\n            def root_func(eta):\n                # We need to solve F_{1/2}(eta) - target = 0\n                return fermi_dirac_integral(0.5, eta) - target_F_half\n            \n            # Find the root eta. Bracket needs to be wide enough.\n            # For low T/TF, eta is large positive. For high T/TF, eta is large negative.\n            # A bracket like [-40, 400] is robust for the given scan range.\n            try:\n                sol = optimize.root_scalar(root_func, bracket=[-40, 400], method='brentq')\n                eta = sol.root\n            except ValueError:\n                # If root is not bracketed, something is wrong, skip this temp\n                continue\n            \n            # Calculate F_{3/2}(eta) with the found eta\n            F_three_halves = fermi_dirac_integral(1.5, eta)\n\n            # Calculate average energy and velocity squared for FD\n            # epsilon_FD = 3/2 * k_B * T * (F_{3/2}/F_{1/2})\n            # We already have F_{1/2} as target_F_half\n            v2_FD = ((3 * k_B * T) / m_e) * (F_three_halves / target_F_half)\n            omega_FD_sq = omega_p_sq + q**2 * v2_FD\n            omega_FD = np.sqrt(omega_FD_sq)\n            \n            # 3. Check the breakdown criterion\n            if omega_FD  0:\n                discrepancy = np.abs(omega_FD - omega_MB) / omega_FD\n                if discrepancy  delta:\n                    return int(round(T))\n        \n        # If no temperature in the scan range satisfies the criterion\n        return -1\n\n\n    test_cases = [\n        (8.5e28, 1.0e9, 0.05), # 1. Metal, typical q\n        (8.5e28, 5.0e9, 0.05), # 2. Metal, larger q\n        (1.0e26, 1.0e9, 0.05), # 3. Lower density (doped semi)\n        (1.0e23, 1.0e9, 0.05), # 4. Very low density\n        (1.0e28, 1.0e8, 0.50), # 5. Edge case (low q, high delta)\n    ]\n    \n    results = []\n    for case in test_cases:\n        n, q, delta = case\n        result = solve_one_case(n, q, delta)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3482724"}]}