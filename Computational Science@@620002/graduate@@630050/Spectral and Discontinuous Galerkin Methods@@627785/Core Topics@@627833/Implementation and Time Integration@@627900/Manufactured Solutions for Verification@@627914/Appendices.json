{"hands_on_practices": [{"introduction": "We begin with a foundational exercise using the linear advection equation. This practice is designed to build core skills in the Method of Manufactured Solutions (MMS) by having you derive the necessary source term for a chosen smooth solution. More importantly, this problem [@problem_id:3397583] illuminates a critical pitfall in verifying spectral collocation codes: aliasing error, forcing a careful consideration of the grid resolution required to accurately represent all Fourier modes present in the solution.", "problem": "Consider the constant-coefficient linear advection equation $u_t + a\\,u_x = f$ on the periodic interval $x \\in [0,2]$ with period $2$, where $a$ is a real constant advection speed. In the method of manufactured solutions for verification of spectral and Discontinuous Galerkin (DG) discretizations, let the manufactured solution be $u(x,t) = \\cos(3\\pi x)\\,\\sin(t)$. Starting from the governing equation and the definition of the manufactured solution, derive the analytic expression for the forcing term $f(x,t)$ that makes $u(x,t)$ an exact solution. Then, discuss the aliasing implications for spectral collocation on equispaced points under periodic boundaries and outline how these considerations should enter a verification plan for both Fourier spectral collocation and modal polynomial DG discretizations. Your discussion should be rooted in fundamental definitions of aliasing and consistent with the periodic interval $[0,2]$, but it should not produce additional computed numerical outputs beyond the required forcing. Provide the final forcing $f(x,t)$ as a single closed-form analytic expression. No rounding is required for the final expression.", "solution": "The problem requires the derivation of a forcing term for a manufactured solution to the linear advection equation, followed by a discussion of the implications for numerical verification using spectral and Discontinuous Galerkin (DG) methods.\n\nThe governing equation is the constant-coefficient linear advection equation:\n$$\nu_t + a u_x = f\n$$\nwhere $u(x,t)$ is the solution variable, $t$ is time, $x$ is the spatial coordinate, $a$ is a constant advection speed, and $f(x,t)$ is a source or forcing term. The spatial domain is specified as the periodic interval $x \\in [0, 2]$.\n\nThe prescribed manufactured solution is:\n$$\nu(x,t) = \\cos(3\\pi x)\\sin(t)\n$$\n\nThe first step is to derive the forcing term $f(x,t)$ that makes this specified $u(x,t)$ an exact solution to the governing partial differential equation (PDE). This is accomplished by computing the partial derivatives of $u(x,t)$ and substituting them into the PDE.\n\nThe partial derivative of $u(x,t)$ with respect to time $t$ is:\n$$\nu_t = \\frac{\\partial}{\\partial t} \\left( \\cos(3\\pi x)\\sin(t) \\right) = \\cos(3\\pi x) \\frac{d}{dt}(\\sin(t)) = \\cos(3\\pi x)\\cos(t)\n$$\n\nThe partial derivative of $u(x,t)$ with respect to space $x$ is:\n$$\nu_x = \\frac{\\partial}{\\partial x} \\left( \\cos(3\\pi x)\\sin(t) \\right) = \\sin(t) \\frac{d}{dx}(\\cos(3\\pi x)) = \\sin(t) \\left( -3\\pi\\sin(3\\pi x) \\right) = -3\\pi\\sin(3\\pi x)\\sin(t)\n$$\n\nSubstituting these derivatives into the advection equation $u_t + a u_x = f$, we can solve for $f(x,t)$:\n$$\nf(x,t) = u_t + a u_x = \\left( \\cos(3\\pi x)\\cos(t) \\right) + a \\left( -3\\pi\\sin(3\\pi x)\\sin(t) \\right)\n$$\nThis simplifies to the final analytical expression for the forcing term:\n$$\nf(x,t) = \\cos(3\\pi x)\\cos(t) - 3a\\pi\\sin(3\\pi x)\\sin(t)\n$$\n\nThe second part of the task is to discuss the aliasing implications for verification using Fourier spectral collocation and modal polynomial DG methods.\n\nFor a Fourier spectral collocation method on the periodic interval $[0, L]$, where here $L=2$, we use a set of $N$ equispaced collocation points $x_j = j \\frac{L}{N}$ for $j=0, 1, \\dots, N-1$. A function can be represented on this grid without aliasing if all of its constituent Fourier modes are within the range of wavenumbers that the grid can resolve. The fundamental wavenumber for the domain $[0,2]$ is $k_{fund} = \\frac{2\\pi}{L} = \\frac{2\\pi}{2} = \\pi$. A general Fourier mode can be written as $\\exp(i m k_{fund} x) = \\exp(i m \\pi x)$ where $m$ is an integer mode number. The manufactured solution's spatial component is $\\cos(3\\pi x)$. Using Euler's formula, this can be written as:\n$$\n\\cos(3\\pi x) = \\frac{1}{2}\\left( \\exp(i3\\pi x) + \\exp(-i3\\pi x) \\right)\n$$\nThis reveals that the solution is composed of Fourier modes with integer mode numbers $m=3$ and $m=-3$.\nAccording to the Nyquist-Shannon sampling theorem for a real-valued signal, to resolve a mode with integer wavenumber $|m|$, the number of grid points $N$ must satisfy $N > 2|m|$. In this case, to resolve the mode $m=3$, we require $N > 2 \\times 3$, i.e., $N > 6$. If $N \\le 6$, aliasing will occur. For example, if we choose $N=4$ points, the mode $m=3$ will be aliased with the mode $m' = m - N = 3 - 4 = -1$. On the grid, the function $\\cos(3\\pi x)$ becomes indistinguishable from $\\cos(\\pi x)$. This corrupts the numerical representation of the solution and its derivatives, and the verification test would show a large error floor, preventing the observation of the expected spectral convergence rate.\nTherefore, a verification plan for a Fourier spectral code using this manufactured solution must ensure that the convergence study begins with a sufficient number of points, e.g., $N=8, 16, 32, \\dots$, to fully resolve the modes in both the solution $u(x,t)$ and the forcing term $f(x,t)$ (which contains the same spatial modes).\n\nFor a modal polynomial Discontinuous Galerkin (DG) method, the domain is partitioned into elements (cells) of size $h$. Within each element, the solution is approximated by a polynomial of degree up to $p$ from a basis set (e.g., Legendre polynomials). The weak formulation of the PDE involves integrals over each element. For the given problem, these integrands contain products of the basis polynomials and the non-polynomial manufactured solution, e.g., $\\int_{\\text{cell}} \\cos(3\\pi x) P_k(x) dx$, where $P_k(x)$ is a basis polynomial. These integrals are computed numerically using a quadrature rule, typically Gaussian quadrature, which is exact for polynomials up to a certain degree. Since the integrand is not a polynomial, any finite-order quadrature rule will introduce a quadrature error.\nIn a verification plan for a DG code, we typically perform an $h$-refinement study (fixing $p$ and decreasing $h$) to confirm the theoretical convergence rate of $O(h^{p+1})$ for the error in a suitable norm (e.g., $L^2$). For this rate to be observed, the error from the numerical quadrature must be smaller than the polynomial approximation error. If the quadrature rule is not accurate enough, the quadrature error will dominate, and the observed convergence rate will be polluted or stalled.\nTherefore, the verification plan for a DG method must specify a quadrature rule of sufficiently high order. A common practice is to use a rule that is exact for polynomials of degree $2p+1$ or higher. This ensures that the approximation of the non-polynomial parts of the manufactured solution is accurate enough to not interfere with the measurement of the convergence rate of the underlying DG polynomial approximation space. The plan must explicitly state this requirement on the quadrature order to ensure a valid verification test.", "answer": "$$\n\\boxed{\\cos(3\\pi x)\\cos(t) - 3a\\pi\\sin(3\\pi x)\\sin(t)}\n$$", "id": "3397583"}, {"introduction": "Building upon the linear case, this practice introduces the challenge of nonlinearity using the viscous Burgers' equation. While the initial step of deriving the source term is similar, the key takeaway from this exercise [@problem_id:3397542] is understanding the origin of nonlinear instability. You will explore how aliasing errors in nonlinear terms can corrupt a simulation and why specialized techniques, such as skew-symmetric or split-form discretizations, are essential for ensuring the stability and robustness of high-order methods.", "problem": "Consider the one-dimensional viscous Burgers equation on the periodic domain $x \\in [0,1]$ and time $t \\ge 0$,\n$$\nu_{t} + \\frac{1}{2}\\left(u^{2}\\right)_{x} = \\nu\\, u_{xx} + f(x,t),\n$$\nwhere $u(x,t)$ is the unknown solution, $\\nu > 0$ is a given viscosity, and $f(x,t)$ is an unknown forcing term to be determined. In the Method of Manufactured Solutions (MMS), choose the manufactured solution\n$$\nu(x,t) = \\sin\\!\\left(2\\pi x\\right)\\cos t,\n$$\nand impose periodic boundary conditions in $x$. Starting from the governing equation and the definitions of temporal and spatial derivatives, derive a closed-form expression for the forcing term $f(x,t)$ so that $u(x,t)$ is an exact solution for all $t \\ge 0$.\n\nThen, using core concepts from spectral methods and Discontinuous Galerkin (DG) methods, explain why nonlinear fluxes in MMS can suffer from aliasing errors when using polynomial bases and underintegrated quadrature, and why split-form (also called skew-symmetric or entropy-conservative) discretizations are needed to mitigate these errors. Your discussion should be rooted in first principles: how nonlinear products elevate polynomial degree, how the discrete product rule fails under collocation and underintegration, and how split forms restore a discrete analog of conservation or energy stability. You may reference the Summation-By-Parts (SBP) property and the idea of entropy-conservative two-point fluxes for Burgers, but do not assume any specific discretization details beyond standard polynomial approximation and quadrature concepts.\n\nProvide the final forcing term $f(x,t)$ in closed form as a function of $x$, $t$, and $\\nu$. No rounding is required, and no units are associated with the final answer. The final answer must be a single analytic expression.", "solution": "The problem requires two distinct tasks: first, to derive the forcing term $f(x,t)$ for a given manufactured solution to the viscous Burgers' equation; second, to explain the nature of aliasing errors for nonlinear terms in polynomial-based numerical methods and the role of split-form discretizations in mitigating them.\n\n**Part 1: Derivation of the Forcing Term $f(x,t)$**\n\nThe governing equation is the one-dimensional viscous Burgers' equation:\n$$u_{t} + \\frac{1}{2}\\left(u^{2}\\right)_{x} = \\nu\\, u_{xx} + f(x,t)$$\nThe forcing term $f(x,t)$ can be isolated by rearranging the equation:\n$$f(x,t) = u_{t} + \\frac{1}{2}\\left(u^{2}\\right)_{x} - \\nu\\, u_{xx}$$\nThe prescribed manufactured solution is:\n$$u(x,t) = \\sin(2\\pi x)\\cos t$$\nTo find $f(x,t)$, we must compute the partial derivatives of $u(x,t)$ and substitute them into the expression for $f(x,t)$.\n\nFirst, we compute the temporal derivative, $u_t$:\n$$u_t = \\frac{\\partial}{\\partial t} \\left( \\sin(2\\pi x)\\cos t \\right) = \\sin(2\\pi x) (-\\sin t) = -\\sin(2\\pi x)\\sin t$$\n\nNext, we address the nonlinear convection term, $\\frac{1}{2}(u^2)_x$. This is equivalent to $u u_x$. We first find the spatial derivative, $u_x$:\n$$u_x = \\frac{\\partial}{\\partial x} \\left( \\sin(2\\pi x)\\cos t \\right) = \\cos(2\\pi x) \\cdot 2\\pi \\cdot \\cos t = 2\\pi \\cos(2\\pi x)\\cos t$$\nNow we can form the product $u u_x$:\n$$\\frac{1}{2}(u^2)_x = u u_x = \\left( \\sin(2\\pi x)\\cos t \\right) \\left( 2\\pi \\cos(2\\pi x)\\cos t \\right) = 2\\pi \\sin(2\\pi x)\\cos(2\\pi x)\\cos^2 t$$\nUsing the trigonometric identity $\\sin(2\\theta) = 2\\sin\\theta\\cos\\theta$ with $\\theta = 2\\pi x$, we simplify this term:\n$$\\frac{1}{2}(u^2)_x = \\pi \\left( 2\\sin(2\\pi x)\\cos(2\\pi x) \\right) \\cos^2 t = \\pi \\sin(4\\pi x)\\cos^2 t$$\n\nFinally, we compute the second spatial derivative, $u_{xx}$, for the viscous term. Starting from $u_x$:\n$$u_{xx} = \\frac{\\partial}{\\partial x} u_x = \\frac{\\partial}{\\partial x} \\left( 2\\pi \\cos(2\\pi x)\\cos t \\right) = 2\\pi \\cos t \\left( -\\sin(2\\pi x) \\cdot 2\\pi \\right)$$\n$$u_{xx} = -4\\pi^2 \\sin(2\\pi x)\\cos t$$\n\nNow we substitute all the computed derivatives into the expression for $f(x,t)$:\n$$f(x,t) = u_{t} + \\frac{1}{2}\\left(u^{2}\\right)_{x} - \\nu u_{xx}$$\n$$f(x,t) = \\left( -\\sin(2\\pi x)\\sin t \\right) + \\left( \\pi \\sin(4\\pi x)\\cos^2 t \\right) - \\nu\\left( -4\\pi^2 \\sin(2\\pi x)\\cos t \\right)$$\nCombining the terms gives the final closed-form expression for the forcing term:\n$$f(x,t) = -\\sin(2\\pi x)\\sin t + \\pi \\sin(4\\pi x)\\cos^2 t + 4\\nu\\pi^2 \\sin(2\\pi x)\\cos t$$\n\n**Part 2: Aliasing Errors and Split-Form Discretizations**\n\nThe second part of the problem asks for an explanation of why nonlinear fluxes in MMS can lead to aliasing errors in polynomial-based methods and how split-form discretizations address this issue. This explanation is rooted in the interplay between polynomial approximation, quadrature rules, and the fundamental properties of differential operators.\n\nIn high-order methods such as spectral and Discontinuous Galerkin (DG) methods, the solution $u(x)$ within the domain or an element is approximated by a polynomial $u_N(x)$ of degree at most $N$. This approximation can be written as a sum over basis functions, $u_N(x) = \\sum_{j=0}^{N} \\hat{u}_j \\phi_j(x)$, where $\\phi_j$ are polynomials of degree $j$.\n\nThe nonlinearity in the Burgers' equation is the convective flux term $F(u) = \\frac{1}{2}u^2$. When we substitute the polynomial approximation $u_N(x)$, we obtain $F(u_N) = \\frac{1}{2}u_N^2(x)$. The product of two polynomials of degree $N$ is a polynomial of degree $2N$. Thus, the discrete flux $F(u_N)$ is a polynomial of degree $2N$, which lies outside the original approximation space of polynomials of degree up to $N$.\n\nNumerical methods typically evaluate integrals or enforce the differential equation at a set of discrete points, known as quadrature or collocation points. For instance, a DG method's weak form involves integrals like $\\int_K \\nabla v_N \\cdot F(u_N) dx$, which are computed using a quadrature rule. A common choice is a Gauss quadrature rule with $Q$ points, which is exact for polynomials of degree up to $2Q-1$. In many practical implementations, particularly those aiming for computational efficiency (a concept known as \"underintegration\"), a quadrature rule that is insufficient to exactly integrate the nonlinear term is used. For example, if a rule exact only up to degree $2N-1$ is used (e.g., Gauss-Lobatto with $N+1$ points), it cannot exactly represent the polynomial $u_N^2$ which is of degree $2N$.\n\nThis inability to exactly represent the high-degree polynomial $u_N^2$ leads to **aliasing**. The energy that should be in the polynomial modes of degree $N+1$ to $2N$ is incorrectly projected, or \"aliased,\" onto the lower-degree modes from $0$ to $N$ that the numerical scheme can represent. In a collocation method, the problem is that we represent the derivative of the nonlinear term, $(u_N^2)_x$, which has degree $2N-1$, using its values at the $N+1$ collocation points. This forces a representation of a high-degree polynomial by a lower-degree one, again causing aliasing.\n\nThis phenomenon is a direct consequence of the **failure of the discrete product rule**. Continuously, the chain rule states $(u^2)_x = 2 u u_x$. Discretely, if $D$ is a differentiation matrix and pointwise multiplication is used, it is generally not true that $D(u_N \\circ u_N) = 2 u_N \\circ (D u_N)$, where $\\circ$ denotes the element-wise product of vectors of function values at grid points. The aliasing error is precisely the difference between these two expressions.\n\nThe consequence of aliasing is often catastrophic: it can lead to a spurious, non-physical transfer of energy to high-frequency modes, culminating in **nonlinear instability**. At the continuous level, for the inviscid Burgers' equation, the convective term $\\frac{1}{2}(u^2)_x$ conserves the kinetic energy $\\int u^2 dx$ over a periodic domain. This is because $\\int u \\cdot \\frac{1}{2}(u^2)_x dx = \\int \\frac{1}{3}(u^3)_x dx = 0$. Aliasing breaks this conservation property at the discrete level, allowing the discrete energy to grow without bound.\n\n**Split-form discretizations** are designed to remedy this instability. The idea is to rewrite the nonlinear term in a mathematically equivalent form which possesses superior stability properties upon discretization. For Burgers' equation, the standard 'conservation' form $\\frac{1}{2}(u^2)_x$ can be rewritten in a family of 'split forms': $\\alpha(u^2)_x + (1-\\alpha)uu_x$. A particularly important version is the skew-symmetric form $\\frac{1}{3}(u^2)_x + \\frac{2}{3}uu_x$.\n\nThe key insight is that even with aliasing, such forms can be constructed to be discretely conservative or dissipative with respect to a chosen norm (like the L2-norm, corresponding to energy or entropy). This is strongly connected to the **Summation-By-Parts (SBP)** property. An SBP operator is a discrete derivative operator that mimics the integration-by-parts property. When a skew-symmetric formulation is combined with an SBP operator, the resulting discrete convective term becomes skew-symmetric as a matrix operator, i.e., $(v, \\text{Conv}(u)) = -(\\text{Conv}(v), u)$ where $(\\cdot,\\cdot)$ is the discrete inner product. This implies that $(u, \\text{Conv}(u)) = 0$, meaning the discrete energy is exactly conserved, and nonlinear stability is restored, even in the presence of aliasing from underintegration.\n\nFrom another perspective, these stable split forms often correspond to discretizations built from **entropy-conservative two-point fluxes**. For a scalar conservation law, a numerical flux is entropy-conservative if it discretely conserves a chosen entropy function. For Burgers' equation, the natural entropy is $u^2/2$. The split form given above can be derived from such a principle. By enforcing a fundamental conservation property at the discrete level, these forms prevent the unphysical energy growth that plagues standard formulations, thereby ensuring the stability and robustness of the numerical simulation.\n\nThis approach is crucial for MMS because if the numerical scheme is nonlinearly unstable, the errors due to this instability will dominate, making it impossible to observe the expected convergence rates and correctly verify the code's implementation. Using a stable split-form discretization ensures that the observed errors are due to truncation error, as intended by the MMS procedure.", "answer": "$$\n\\boxed{-\\sin(2\\pi x)\\sin t + \\pi \\sin(4\\pi x)\\cos^2 t + 4\\nu\\pi^2 \\sin(2\\pi x)\\cos t}\n$$", "id": "3397542"}, {"introduction": "This hands-on practice transitions from theory to implementation by tackling the two-dimensional anisotropic diffusion equation with a Spectral Element Method (SEM). The exercise [@problem_id:3397553] requires you to build a verification test for a problem where physical properties differ by direction, a common scenario in engineering and physics. By implementing the MMS and analyzing the resulting directional errors under $p$-refinement, you will develop practical skills in diagnosing the performance of a high-order code and understanding its interaction with anisotropic physics.", "problem": "Consider the steady two-dimensional anisotropic diffusion equation on the unit square $\\Omega = [0,1]\\times[0,1]$ with constant symmetric positive definite tensor $K = \\text{diag}(1,\\alpha)$:\n$$ -\\nabla \\cdot \\left( K \\nabla u \\right) = f \\quad \\text{in } \\Omega, \\qquad u = g \\quad \\text{on } \\partial \\Omega. $$\nYou will employ the Method of Manufactured Solutions for verification. Let the manufactured (exact) solution be\n$$ u_{\\mathrm{ex}}(x,y) = \\sin(\\pi x)\\,\\sin(\\pi y), $$\nwhere all angles are in radians. \n\nYour tasks are:\n- Derive the source term $f(x,y)$ so that $u_{\\mathrm{ex}}(x,y)$ exactly satisfies the anisotropic diffusion equation with $K = \\text{diag}(1,\\alpha)$.\n- Implement a nodal Spectral Element Method (SEM) on a single tensor-product element covering $\\Omega$ using Legendre–Gauss–Lobatto (LGL) interpolation and quadrature of polynomial degree $p$ in each coordinate, with Lagrange basis functions at the LGL nodes. Assemble the discrete collocation SEM system for the bilinear form\n$$ a(u,v) = \\int_{\\Omega} \\left( \\partial_x u\\,\\partial_x v + \\alpha\\, \\partial_y u\\,\\partial_y v \\right)\\, \\mathrm{d}\\Omega, $$\nand the linear form\n$$ \\ell(v) = \\int_{\\Omega} v\\, f\\, \\mathrm{d}\\Omega. $$\nImpose Dirichlet boundary conditions strongly by setting $u=g:=u_{\\mathrm{ex}}$ on all boundary nodes. Work with the affine mapping from the reference square $[-1,1]^2$ to $\\Omega$, and account for the geometric Jacobian in all integrals and derivatives. Specifically, if $(\\xi,\\eta)\\in[-1,1]^2$ map to $(x,y)\\in[0,1]^2$ by $(x,y) = \\left(\\tfrac{\\xi+1}{2},\\tfrac{\\eta+1}{2}\\right)$, ensure that you use $\\partial_x = 2 \\partial_\\xi$ and $\\partial_y = 2 \\partial_\\eta$, and that integrals over $\\Omega$ include the Jacobian factor $|\\det J| = \\tfrac{1}{4}$.\n- After computing the discrete solution $u_h$ at the LGL nodes, evaluate the following error metrics using the same LGL quadrature:\n  1. The discrete $L^2$ error\n  $$ \\|e\\|_{L^2(\\Omega)} \\approx \\left( \\tfrac{1}{4} \\sum_{i=0}^{p} \\sum_{j=0}^{p} w_i w_j \\, \\left[ u_h(x_i,y_j) - u_{\\mathrm{ex}}(x_i,y_j) \\right]^2 \\right)^{1/2}, $$\n  where $\\{x_i\\}_{i=0}^p$ and $\\{w_i\\}_{i=0}^p$ are the LGL nodes and weights projected to $[0,1]$ via the affine map, and analogously in $y$.\n  2. The directional gradient errors (unweighted by $\\alpha$)\n  $$ E_x \\approx \\left( \\tfrac{1}{4} \\sum_{i=0}^{p} \\sum_{j=0}^{p} w_i w_j \\, \\left[ \\partial_x u_h(x_i,y_j) - \\partial_x u_{\\mathrm{ex}}(x_i,y_j) \\right]^2 \\right)^{1/2}, $$\n  $$ E_y \\approx \\left( \\tfrac{1}{4} \\sum_{i=0}^{p} \\sum_{j=0}^{p} w_i w_j \\, \\left[ \\partial_y u_h(x_i,y_j) - \\partial_y u_{\\mathrm{ex}}(x_i,y_j) \\right]^2 \\right)^{1/2}. $$\n- Assess directional error behavior under $p$-refinement for different anisotropies by computing, for each test case defined below:\n  1. The ratio $R := E_y/E_x$ at the largest $p$ in the set.\n  2. The least-squares slopes $s_x$ and $s_y$ of $\\log_{10} E_x$ and $\\log_{10} E_y$ versus $p$ across the provided $p$-values, and their ratio $S := s_y/s_x$.\n  3. The $L^2$ error at the largest $p$.\n- Use the above to comment on whether anisotropy alters the directional error balance and decay under $p$-refinement in this manufactured setting.\n\nImplementation requirements:\n- Use the nodal Spectral Element Method (SEM), which is a spectral method. Construct one-dimensional differentiation matrices at LGL nodes via barycentric formulas, and assemble the two-dimensional operators using tensor products. Use quadrature-consistent mass and stiffness matrices with LGL weights. Impose Dirichlet boundary values by eliminating boundary degrees of freedom and shifting the right-hand side accordingly.\n- All trigonometric evaluations must be in radians.\n- No physical units are involved in this problem.\n\nTest suite:\n- You must run the following three test cases and aggregate their outputs in the specified final format:\n  1. Case A: $\\alpha = 1.0$, $p \\in \\{2,4,6,8,10\\}$.\n  2. Case B: $\\alpha = 0.01$, $p \\in \\{2,4,6,8,10\\}$.\n  3. Case C: $\\alpha = 100.0$, $p \\in \\{2,4,6,8,10\\}$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a list of three lists (one per test case), in the same order as above. Each inner list must be of the form $[R,S,L2]$ where $R$ is $E_y/E_x$ at the largest $p$, $S$ is $s_y/s_x$, and $L2$ is the $L^2$ error at the largest $p$. For example, an output line has the structure\n$$ [[R_A,S_A,L2_A],[R_B,S_B,L2_B],[R_C,S_C,L2_C]]. $$", "solution": "The problem as stated is valid. It is a well-posed problem in numerical analysis, specifically concerning the verification of a numerical method (Spectral Element Method) for a partial differential equation (anisotropic diffusion) using the Method of Manufactured Solutions. The problem is self-contained, scientifically grounded, and all parameters and objectives are clearly defined.\n\n### 1. Derivation of the Source Term\n\nThe problem considers the steady two-dimensional anisotropic diffusion equation:\n$$ -\\nabla \\cdot \\left( K \\nabla u \\right) = f \\quad \\text{in } \\Omega $$\nwith a constant, symmetric positive definite diffusion tensor $K = \\text{diag}(1, \\alpha)$. Expanding the divergence operator, the left-hand side (LHS) of the equation becomes:\n$$ -\\nabla \\cdot \\left( \\begin{pmatrix} 1 & 0 \\\\ 0 & \\alpha \\end{pmatrix} \\begin{pmatrix} \\partial_x u \\\\ \\partial_y u \\end{pmatrix} \\right) = -\\nabla \\cdot \\begin{pmatrix} \\partial_x u \\\\ \\alpha \\partial_y u \\end{pmatrix} = - \\left( \\frac{\\partial^2 u}{\\partial x^2} + \\alpha \\frac{\\partial^2 u}{\\partial y^2} \\right) $$\nThe Method of Manufactured Solutions requires us to define a solution $u_{\\mathrm{ex}}(x,y)$ and derive the corresponding source term $f(x,y)$ that satisfies the PDE. The given manufactured solution is:\n$$ u_{\\mathrm{ex}}(x,y) = \\sin(\\pi x)\\sin(\\pi y) $$\nWe compute the necessary second partial derivatives:\n$$ \\frac{\\partial u_{\\mathrm{ex}}}{\\partial x} = \\pi \\cos(\\pi x)\\sin(\\pi y) \\implies \\frac{\\partial^2 u_{\\mathrm{ex}}}{\\partial x^2} = -\\pi^2 \\sin(\\pi x)\\sin(\\pi y) = -\\pi^2 u_{\\mathrm{ex}} $$\n$$ \\frac{\\partial u_{\\mathrm{ex}}}{\\partial y} = \\pi \\sin(\\pi x)\\cos(\\pi y) \\implies \\frac{\\partial^2 u_{\\mathrm{ex}}}{\\partial y^2} = -\\pi^2 \\sin(\\pi x)\\sin(\\pi y) = -\\pi^2 u_{\\mathrm{ex}} $$\nSubstituting these into the LHS expression gives the required source term $f(x,y)$:\n$$ f(x,y) = - \\left( (-\\pi^2 u_{\\mathrm{ex}}) + \\alpha (-\\pi^2 u_{\\mathrm{ex}}) \\right) = \\pi^2 (1 + \\alpha) u_{\\mathrm{ex}} $$\n$$ f(x,y) = \\pi^2 (1 + \\alpha) \\sin(\\pi x)\\sin(\\pi y) $$\n\n### 2. Spectral Element Method (SEM) Formulation\n\nWe are tasked with solving the problem using a nodal Spectral Element Method on a single element $\\Omega = [0,1]^2$. The method is based on the weak formulation, which seeks $u \\in H^1(\\Omega)$ such that $u=g$ on $\\partial\\Omega$ and $a(u,v) = \\ell(v)$ for all test functions $v \\in H^1_0(\\Omega)$. The specified bilinear and linear forms are:\n$$ a(u,v) = \\int_{\\Omega} \\left( \\partial_x u\\,\\partial_x v + \\alpha\\, \\partial_y u\\,\\partial_y v \\right)\\,d\\Omega, \\qquad \\ell(v) = \\int_{\\Omega} v f \\,d\\Omega $$\nTo implement the SEM, we map the physical domain $\\Omega = [0,1]^2$ to the reference element $[-1,1]^2$ using the affine transformation $(x,y) = (\\frac{\\xi+1}{2}, \\frac{\\eta+1}{2})$. The derivatives and differential area element transform as:\n$$ \\partial_x = 2 \\partial_\\xi, \\quad \\partial_y = 2 \\partial_\\eta, \\quad d\\Omega = dx dy = \\frac{1}{4} \\,d\\xi d\\eta $$\nSubstituting these into the weak form gives the formulation on the reference element:\n$$ a(u,v) = \\int_{-1}^1 \\int_{-1}^1 \\left( (2\\partial_\\xi u)(2\\partial_\\xi v) + \\alpha (2\\partial_\\eta u)(2\\partial_\\eta v) \\right) \\frac{1}{4} \\,d\\xi d\\eta = \\int_{-1}^1 \\int_{-1}^1 \\left( \\partial_\\xi u \\partial_\\xi v + \\alpha \\partial_\\eta u \\partial_\\eta v \\right) \\,d\\xi d\\eta $$\n$$ \\ell(v) = \\int_{-1}^1 \\int_{-1}^1 v f \\frac{1}{4} \\,d\\xi d\\eta $$\nThe solution $u$ is approximated by a polynomial $u_h$ of degree $p$ in each direction, using a basis of tensor-product Lagrange polynomials $h_i(\\xi)h_j(\\eta)$ associated with the $(p+1) \\times (p+1)$ grid of Legendre-Gauss-Lobatto (LGL) nodes $(\\xi_i, \\eta_j)$. The discrete solution is $u_h(\\xi, \\eta) = \\sum_{k=0}^p \\sum_{l=0}^p U_{kl} h_k(\\xi) h_l(\\eta)$, where $U_{kl}$ are the unknown values of the solution at the LGL nodes.\n\nUsing the Galerkin method with test functions $v = h_i(\\xi)h_j(\\eta)$, we obtain a linear system $A \\mathbf{U} = \\mathbf{F}$. The system matrix $A$ and right-hand side vector $\\mathbf{F}$ are assembled using tensor products of one-dimensional mass ($M$) and stiffness ($K$) matrices, evaluated using LGL quadrature. The 1D matrices (here identical for $\\xi$ and $\\eta$ directions) are computed as:\n$$ (M_x)_{ik} = M_{ik} = \\int_{-1}^1 h_i(\\xi)h_k(\\xi) \\,d\\xi \\approx \\sum_{m=0}^p w_m h_i(\\xi_m)h_k(\\xi_m) = w_i \\delta_{ik} $$\n$$ (K_x)_{ik} = K_{ik} = \\int_{-1}^1 h'_i(\\xi)h'_k(\\xi) \\,d\\xi \\approx \\sum_{m=0}^p w_m h'_i(\\xi_m)h'_k(\\xi_m) $$\nHere, $w_m$ are the LGL quadrature weights and $\\delta_{ik}$ is the Kronecker delta. Thus, $M$ is a diagonal matrix of the quadrature weights, which we denote as $W$. The stiffness matrix $K$ can be expressed as $K = D^T W D$, where $D$ is the 1D LGL differentiation matrix with entries $D_{mi} = h'_i(\\xi_m)$. The global stiffness matrix for row-major ordering is then constructed using these 1D matrices:\n$$ A = K \\otimes W + \\alpha W \\otimes K $$\nThe right-hand side vector elements are computed by quadrature:\n$$ F_{ij} = \\ell(h_i h_j) \\approx \\frac{1}{4} w_i w_j f(x_i, y_j) $$\nDirichlet boundary conditions are imposed strongly. The system $A \\mathbf{U} = \\mathbf{F}$ is partitioned into interior ($I$) and boundary ($B$) degrees of freedom. The values $\\mathbf{U}_B$ are set to the exact solution $u_{\\mathrm{ex}}$ at the boundary nodes. The system for the interior unknowns $\\mathbf{U}_I$ is then solved:\n$$ A_{II} \\mathbf{U}_I = \\mathbf{F}_I - A_{IB} \\mathbf{U}_B $$\n\n### 3. Error Analysis and Metrics\n\nOnce the discrete solution $u_h$ (represented by its nodal values $U_{ij}$) is found, we evaluate its accuracy.\nThe discrete $L^2$ error is computed via LGL quadrature:\n$$ \\|e\\|_{L^2(\\Omega)} \\approx \\left( \\frac{1}{4} \\sum_{i=0}^{p} \\sum_{j=0}^{p} w_i w_j \\, (U_{ij} - u_{\\mathrm{ex}}(x_i,y_j))^2 \\right)^{1/2} $$\nThe directional gradient errors require computing the partial derivatives of the numerical solution at the LGL nodes. Using the chain rule and the 1D differentiation matrix $D$, we have:\n$$ \\partial_x u_h(x_i,y_j) = 2 \\partial_\\xi u_h(\\xi_i,\\eta_j) \\approx 2 (U D^T)_{ij} $$\n$$ \\partial_y u_h(x_i,y_j) = 2 \\partial_\\eta u_h(\\xi_i,\\eta_j) \\approx 2 (D U)_{ij} $$\nassuming $U_{ij}$ represents the solution at $(x_j, y_i)$ (row index for $y$, column for $x$). The gradient errors are then:\n$$ E_x \\approx \\left( \\frac{1}{4} \\sum_{i=0}^{p} \\sum_{j=0}^{p} w_i w_j \\, ( \\partial_x u_h(x_i,y_j) - \\partial_x u_{\\mathrm{ex}}(x_i,y_j) )^2 \\right)^{1/2} $$\n$$ E_y \\approx \\left( \\frac{1}{4} \\sum_{i=0}^{p} \\sum_{j=0}^{p} w_i w_j \\, ( \\partial_y u_h(x_i,y_j) - \\partial_y u_{\\mathrm{ex}}(x_i,y_j) )^2 \\right)^{1/2} $$\nThe assessment of anisotropy's effect involves the ratios $R = E_y/E_x$ and $S = s_y/s_x$, where $s_x$ and $s_y$ are the convergence rates (slopes of $\\log_{10} E$ vs. $p$). Since the manufactured solution is analytic, spectral convergence is expected. In an isotropic medium ($\\alpha=1$), one anticipates a balance in directional errors ($R \\approx 1$) and convergence rates ($S \\approx 1$). For anisotropic media ($\\alpha \\neq 1$), the energy norm is itself anisotropic, which may lead to an imbalance in the gradient errors ($R \\neq 1$), although the asymptotic convergence rates are governed by solution smoothness and should remain similar ($S \\approx 1$).", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_jacobi, eval_legendre\n\ndef get_lgl_nodes_weights(p):\n    \"\"\"\n    Computes Legendre-Gauss-Lobatto (LGL) nodes and weights for polynomial degree p.\n    Nodes are on [-1, 1].\n    \"\"\"\n    if p == 0:\n        return np.array([0.0]), np.array([2.0])\n    if p == 1:\n        return np.array([-1.0, 1.0]), np.array([1.0, 1.0])\n    \n    # Interior nodes are roots of P_p'(x), which are roots of Jacobi polynomial P_{p-1}^{(1,1)}(x).\n    x_interior, _ = roots_jacobi(p - 1, 1, 1)\n    x = np.concatenate([[-1.0], x_interior[::-1], [1.0]]) # Order nodes from -1 to 1\n    \n    # Weights using formula w_j = 2 / (p(p+1) [P_p(x_j)]^2)\n    P_p_vals = eval_legendre(p, x)\n    w = 2.0 / (p * (p + 1) * P_p_vals**2)\n    \n    return x, w\n\ndef get_diff_matrix(p, x):\n    \"\"\"\n    Computes the 1D differentiation matrix on LGL nodes x for polynomial degree p.\n    \"\"\"\n    N = p + 1\n    D = np.zeros((N, N))\n    P_p_vals = eval_legendre(p, x)\n\n    # Use standard formula for LGL differentiation matrix\n    for i in range(N):\n        for j in range(N):\n            if i != j:\n                D[i, j] = P_p_vals[i] / (P_p_vals[j] * (x[i] - x[j]))\n    \n    D[0, 0] = -p * (p + 1) / 4.0\n    D[N - 1, N - 1] = p * (p + 1) / 4.0\n    # Interior diagonal entries are 0, which is the default from np.zeros\n    \n    return D\n\ndef solve():\n    \"\"\"\n    Main solver function to run test cases and generate final output.\n    \"\"\"\n    test_cases = [\n        (1.0, [2, 4, 6, 8, 10]),   # Case A\n        (0.01, [2, 4, 6, 8, 10]),  # Case B\n        (100.0, [2, 4, 6, 8, 10]), # Case C\n    ]\n\n    final_results = []\n    \n    for alpha, p_values in test_cases:\n        l2_errors = []\n        ex_errors = []\n        ey_errors = []\n\n        for p in p_values:\n            N = p + 1\n            \n            # 1. Get 1D LGL nodes, weights, and differentiation matrix on [-1, 1]\n            xi, w = get_lgl_nodes_weights(p)\n            D = get_diff_matrix(p, xi)\n\n            # 2. Setup 2D grid and evaluate exact solution and source term\n            # Map nodes to physical domain [0, 1]\n            x_nodes = 0.5 * (xi + 1)\n            y_nodes = 0.5 * (xi + 1)\n\n            # Create 2D grid using 'xy' indexing for consistency with row-major flattening\n            # At grid point (i, j), coordinates are (x_nodes[j], y_nodes[i])\n            X, Y = np.meshgrid(x_nodes, y_nodes, indexing='xy')\n            \n            # Exact solution and its derivatives at nodes\n            uex = np.sin(np.pi * X) * np.sin(np.pi * Y)\n            uex_dx = np.pi * np.cos(np.pi * X) * np.sin(np.pi * Y)\n            uex_dy = np.pi * np.sin(np.pi * X) * np.cos(np.pi * Y)\n            \n            # Source term f at nodes\n            f_vals = np.pi**2 * (1 + alpha) * uex\n\n            # 3. Assemble system matrices and RHS vector\n            # 1D matrices\n            W = np.diag(w)\n            K = D.T @ W @ D # Stiffness matrix: K_ij = integral(h_i' h_j')\n\n            # 2D stiffness matrix A for row-major ordering\n            A = np.kron(K, W) + alpha * np.kron(W, K)\n            \n            # RHS vector F\n            F_matrix = 0.25 * np.outer(w, w) * f_vals\n            F_rhs = F_matrix.flatten()\n\n            # 4. Apply strong Dirichlet boundary conditions\n            # Identify interior and boundary node indices\n            b_mask = np.zeros((N, N), dtype=bool)\n            b_mask[0, :] = True; b_mask[-1, :] = True\n            b_mask[:, 0] = True; b_mask[:, -1] = True\n            i_mask = ~b_mask\n\n            b_indices = np.where(b_mask.flatten())[0]\n            i_indices = np.where(i_mask.flatten())[0]\n\n            # Partition the system\n            A_II = A[np.ix_(i_indices, i_indices)]\n            A_IB = A[np.ix_(i_indices, b_indices)]\n            F_I = F_rhs[i_indices]\n            \n            # Get boundary values from exact solution\n            U_B = uex.flatten()[b_indices]\n            \n            # 5. Solve for interior nodal values\n            F_mod = F_I - A_IB @ U_B\n            U_I = np.linalg.solve(A_II, F_mod)\n            \n            # 6. Reconstruct the full solution vector and matrix\n            U_sol_flat = np.zeros(N * N)\n            U_sol_flat[i_indices] = U_I\n            U_sol_flat[b_indices] = U_B\n            U_sol = U_sol_flat.reshape((N, N))\n\n            # 7. Calculate error metrics using LGL quadrature\n            # L2 error\n            err_l2_sq = 0.25 * np.sum(np.outer(w, w) * (U_sol - uex)**2)\n            l2_errors.append(np.sqrt(err_l2_sq))\n            \n            # Gradient errors\n            # Numerical derivatives (transformed from reference element)\n            # d/dx acts on columns (x-dir), d/dy on rows (y-dir)\n            u_h_dx = 2.0 * (U_sol @ D.T)\n            u_h_dy = 2.0 * (D @ U_sol)\n            \n            err_ex_sq = 0.25 * np.sum(np.outer(w, w) * (u_h_dx - uex_dx)**2)\n            ex_errors.append(np.sqrt(err_ex_sq))\n            \n            err_ey_sq = 0.25 * np.sum(np.outer(w, w) * (u_h_dy - uex_dy)**2)\n            ey_errors.append(np.sqrt(err_ey_sq))\n\n        # After p-refinement loop, compute final metrics for the test case\n        p_max_index = -1\n        \n        # Ratio R = E_y/E_x at largest p\n        R = ey_errors[p_max_index] / ex_errors[p_max_index]\n\n        # Slopes s_x, s_y and their ratio S\n        p_vals_arr = np.array(p_values)\n        \n        # Filter out potential zero errors before taking log\n        ex_errors_np = np.array(ex_errors)\n        ey_errors_np = np.array(ey_errors)\n        \n        valid_ex = ex_errors_np > 0\n        valid_ey = ey_errors_np > 0\n\n        sx = -np.inf\n        if np.any(valid_ex):\n            log_ex = np.log10(ex_errors_np[valid_ex])\n            sx = np.polyfit(p_vals_arr[valid_ex], log_ex, 1)[0]\n        \n        sy = -np.inf\n        if np.any(valid_ey):\n            log_ey = np.log10(ey_errors_np[valid_ey])\n            sy = np.polyfit(p_vals_arr[valid_ey], log_ey, 1)[0]\n        \n        S = sy / sx if sx != 0 else 0.0\n        \n        # L2 error at largest p\n        L2 = l2_errors[p_max_index]\n        \n        final_results.append([R, S, L2])\n\n    # Final print statement in the exact required format\n    print(str(final_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3397553"}]}