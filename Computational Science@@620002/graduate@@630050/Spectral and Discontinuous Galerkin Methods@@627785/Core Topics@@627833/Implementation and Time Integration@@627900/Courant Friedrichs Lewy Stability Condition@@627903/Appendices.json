{"hands_on_practices": [{"introduction": "The Courant-Friedrichs-Lewy (CFL) condition is the cornerstone of stability for explicit time-stepping methods. This first practice moves from theory to application, challenging you to implement a practical, nonlinear CFL estimator for the inviscid Burgers' equation discretized with the Discontinuous Galerkin (DG) method. You will explore how to handle element-wise variations in the solution, the effect of different quadrature strategies on estimating wave speeds, and how stabilization terms like artificial viscosity introduce their own, more restrictive time-step constraints.", "problem": "Consider the one-dimensional inviscid Burgers equation, a hyperbolic conservation law given by $u_t + \\left(\\frac{u^2}{2}\\right)_x = 0$, discretized using the Discontinuous Galerkin (DG) method with piecewise polynomials of degree $p$ on a partition of the domain into elements $K$ of length $h_K$. The Courant Friedrichs Lewy (CFL) condition for explicit time integration must ensure that the discrete numerical domain of dependence contains the partial differential equation’s domain of dependence. Your task is to derive a nonlinear CFL estimator for the DG discretization of the inviscid Burgers equation and then quantitatively test its sensitivity to two implementation choices: under-integrated aliasing versus oversampled exact quadrature surrogate, and the presence versus absence of shock-capturing artificial viscosity.\n\nStart from fundamental bases appropriate to hyperbolic conservation laws and DG methods:\n- The characteristic speed of inviscid Burgers is $a(u) = u$, so the advective stability limit for an explicit method must be governed by an elementwise bound involving $h_K$, $p$, and the maximum characteristic speed on each element.\n- Polynomial inverse and trace inequalities imply that DG semi-discrete operators have elementwise spectral radii that scale with $(2p+1)$ for advection-like terms.\n- Artificial viscosity used for shock capturing adds a diffusive operator; explicit stabilization of diffusion typically imposes a parabolic restriction that scales like $h_K^2$ with a polynomial-degree-dependent factor.\n\nYou must:\n1. Derive a nonlinear CFL estimator that is consistent with these fundamental facts and yields an elementwise advective time-step restriction depending on $h_K$, $p$, and a per-element bound on $|u|$.\n2. Derive an accompanying diffusive time-step restriction for artificial viscosity $\\nu_K$ based on a gradient-based sensor, with a dependence on $h_K$, $p$, and $\\nu_K$ proportional to a parabolic scaling.\n3. Implement two ways to estimate the required per-element maxima:\n   - An under-integrated aliasing estimate using $N_{\\text{alias}} = p+1$ uniformly spaced sampling points per element (including both endpoints) for the maximum of $|u|$ and $|u_x|$.\n   - An oversampled “exact quadrature surrogate” estimate using $N_{\\text{exact}} = 200p + 50$ uniformly spaced sampling points per element (including both endpoints) for the maximum of $|u|$ and $|u_x|$.\n4. Compute, for each test case, four scalars:\n   - The global advective time step using the aliasing estimate.\n   - The global advective time step using the exact quadrature surrogate estimate.\n   - The global total time step (the minimum of advective and diffusive restrictions) using the aliasing estimate.\n   - The global total time step using the exact quadrature surrogate estimate.\n\nDefinitions to use in your program:\n- The advective characteristic speed is $|u|$.\n- The artificial viscosity is defined per element as $\\nu_K = \\kappa\\, h_K \\max_{x \\in K} |u_x(x)|$, where $\\kappa$ is a prescribed constant.\n- The global total time step is the minimum over elements of the minimum of the advective and diffusive restrictions.\n\nTest suite (domain is $[0,1]$ in all cases):\n- Case 1 (smooth “happy path” without shock capturing):\n  - Mesh: four equal elements, so $h_K = 0.25$ for all $K$.\n  - Polynomial degree: $p = 3$.\n  - Field: $u(x) = \\sin(2\\pi x)$ and $u_x(x) = 2\\pi \\cos(2\\pi x)$.\n  - Constants: use $C_{\\text{adv}} = 0.5$, $C_{\\text{visc}} = 0.25$, and $\\kappa = 0$.\n  - Sampling: $N_{\\text{alias}} = p+1$ and $N_{\\text{exact}} = 200p + 50$.\n- Case 2 (near-discontinuous profile with shock capturing):\n  - Mesh: eight equal elements, so $h_K = 0.125$ for all $K$.\n  - Polynomial degree: $p = 5$.\n  - Field: $u(x) = \\tanh\\left(100(x - 0.5)\\right)$ and $u_x(x) = 100\\,\\text{sech}^2\\left(100(x - 0.5)\\right)$.\n  - Constants: use $C_{\\text{adv}} = 0.4$, $C_{\\text{visc}} = 0.25$, and $\\kappa = 0.05$.\n  - Sampling: $N_{\\text{alias}} = p+1$ and $N_{\\text{exact}} = 200p + 50$.\n- Case 3 (edge case with one very small element, without shock capturing):\n  - Mesh: two elements with $h_1 = 10^{-3}$ and $h_2 = 1 - 10^{-3}$.\n  - Polynomial degree: $p = 1$.\n  - Field: $u(x) = 10 + \\tfrac{1}{2}\\sin(2\\pi x)$ and $u_x(x) = \\pi \\cos(2\\pi x)$.\n  - Constants: use $C_{\\text{adv}} = 0.9$, $C_{\\text{visc}} = 0.25$, and $\\kappa = 0$.\n  - Sampling: $N_{\\text{alias}} = p+1$ and $N_{\\text{exact}} = 200p + 50$.\n\nOutput specification:\n- Your program should produce a single line of output containing the results for all test cases aggregated into a single comma-separated list enclosed in square brackets, ordered as:\n  [`Case 1 advective aliasing`, `Case 1 advective exact`, `Case 1 total aliasing`, `Case 1 total exact`, `Case 2 advective aliasing`, `Case 2 advective exact`, `Case 2 total aliasing`, `Case 2 total exact`, `Case 3 advective aliasing`, `Case 3 advective exact`, `Case 3 total aliasing`, `Case 3 total exact`].\n- All outputs must be real numbers (floats). No physical units are required; all quantities are dimensionless.\n\nYour program must implement the derived estimator and compute the requested outputs for the three cases above using the specified constants and sampling rules. No user input is allowed; hard-code the test suite inside the program. The program must be a complete, runnable script that prints only the single line specified above.", "solution": "The problem is valid and well-posed. It addresses the determination of a stable time-step size for the explicit Discontinuous Galerkin (DG) discretization of the inviscid Burgers equation, a canonical problem in the numerical analysis of hyperbolic conservation laws. We will first derive the necessary time-step estimators and then implement them to analyze the specified test cases.\n\n### Derivation of Time-Step Estimators\n\nThe stability of an explicit time-stepping scheme for a semi-discretized partial differential equation $\\frac{d\\mathbf{u}}{dt} = \\mathbf{L}(\\mathbf{u})$ is governed by the Courant-Friedrichs-Lewy (CFL) condition, which requires that the time step $\\Delta t$ satisfies $\\Delta t \\le \\frac{C}{\\rho(\\mathbf{L})}$, where $\\rho(\\mathbf{L})$ is the spectral radius of the spatial operator $\\mathbf{L}$ and $C$ is a constant depending on the time-integration scheme. For a system involving both advection and diffusion, $\\mathbf{L} = \\mathbf{L}_{\\text{adv}} + \\mathbf{L}_{\\text{visc}}$, the time step is typically limited by the sum of the spectral radii, leading to the restriction $\\frac{1}{\\Delta t} \\approx \\frac{1}{\\Delta t_{\\text{adv}}} + \\frac{1}{\\Delta t_{\\text{visc}}}$. A more straightforward and common practice is to take the minimum of the individual restrictions: $\\Delta t = \\min(\\Delta t_{\\text{adv}}, \\Delta t_{\\text{visc}})$.\n\nThe global time step is the minimum of the element-wise time steps over all elements $K$ in the mesh $\\mathcal{T}_h$:\n$$ \\Delta t_{\\text{global}} = \\min_{K \\in \\mathcal{T}_h} \\Delta t_K $$\n\n#### 1. Advective Time-Step Restriction ($\\Delta t_{\\text{adv}}$)\n\nFor a one-dimensional hyperbolic problem, the spectral radius of the DG spatial operator on an element $K$ is bounded by a quantity proportional to the maximum characteristic speed on that element and geometric and polynomial-degree-dependent factors. The problem states that for advection, the spectral radius scales with $(2p+1)/h_K$. The characteristic speed for the inviscid Burgers equation, $u_t + (u^2/2)_x = 0$, is $a(u) = u$.\n\nThe element-wise spectral radius for the advective part is thus modeled as:\n$$ \\rho(\\mathbf{L}_{\\text{adv}, K}) \\propto \\frac{(2p+1)}{h_K} \\max_{x \\in K} |a(u(x))| = \\frac{(2p+1)}{h_K} \\max_{x \\in K} |u(x)| $$\nThe corresponding time-step restriction is inversely proportional to this spectral radius. Including the provided dimensionless constant $C_{\\text{adv}}$, we define the element-wise advective time-step restriction as:\n$$ \\Delta t_{\\text{adv}, K} = C_{\\text{adv}} \\frac{h_K}{(2p+1) \\max_{x \\in K} |u(x)|} $$\nThis formula correctly captures the expected behavior: the stable time step must decrease for smaller elements ($h_K$), higher polynomial degrees ($p$), and larger wave speeds ($|u|$).\n\n#### 2. Diffusive Time-Step Restriction ($\\Delta t_{\\text{visc}}$)\n\nAn artificial viscosity term adds a parabolic, diffusion-like operator to the system for shock-capturing. For an explicit method, this imposes a more stringent time-step restriction that typically scales with $h_K^2$. Standard analysis of DG methods for parabolic problems shows that the spectral radius of the DG Laplacian operator scales as $\\rho(\\mathbf{L}_{\\text{visc}, K}) \\propto \\nu_K (p+1)^4 / h_K^2$ or $\\nu_K (2p+1)^2 / h_K^2$. Given the use of $(2p+1)$ in the advective scaling, it is consistent and standard to use a scaling of $(2p+1)^2$ for the diffusive term, which arises from applying a polynomial inverse inequality twice.\n\nThus, we model the element-wise spectral radius for the viscous part as:\n$$ \\rho(\\mathbf{L}_{\\text{visc}, K}) \\propto \\frac{\\nu_K (2p+1)^2}{h_K^2} $$\nThe time-step restriction is, therefore:\n$$ \\Delta t_{\\text{visc}, K} \\le C_{\\text{visc}} \\frac{h_K^2}{\\nu_K (2p+1)^2} $$\nThe problem defines the element-wise artificial viscosity as $\\nu_K = \\kappa\\, h_K \\max_{x \\in K} |u_x(x)|$. Substituting this into the restriction gives:\n$$ \\Delta t_{\\text{visc}, K} = C_{\\text{visc}} \\frac{h_K^2}{\\left(\\kappa\\, h_K \\max_{x \\in K} |u_x(x)|\\right) (2p+1)^2} = \\frac{C_{\\text{visc}} h_K}{\\kappa (2p+1)^2 \\max_{x \\in K} |u_x(x)|} $$\nThis restriction applies only when $\\kappa > 0$. If $\\kappa=0$, there is no artificial viscosity, and $\\Delta t_{\\text{visc}, K} = \\infty$.\n\n#### 3. Total Element-wise Time Step\n\nThe total time-step restriction for a single element $K$ is the minimum of the advective and diffusive limits:\n$$ \\Delta t_K = \\min(\\Delta t_{\\text{adv}, K}, \\Delta t_{\\text{visc}, K}) $$\nThe global time step for the entire simulation is then the minimum over all elements:\n$$ \\Delta t = \\min_{K \\in \\mathcal{T}_h} \\Delta t_K $$\n\n### Implementation and Analysis\n\nThe problem requires computing four scalar time steps for each test case, based on two different methods for estimating the maxima of $|u|$ and $|u_x|$ on each element: an under-integrated \"aliasing\" estimate and an oversampled \"exact surrogate\" estimate.\n\nThe procedure for each test case is as follows:\n1.  For each element $K$ in the mesh:\n    a.  Define the sampling points for both the aliasing ($N_{\\text{alias}}=p+1$) and exact surrogate ($N_{\\text{exact}}=200p+50$) methods.\n    b.  Evaluate $|u(x)|$ and $|u_x(x)|$ at these sample points to find the respective maxima for each method: $\\max_{\\text{alias}}|u|$, $\\max_{\\text{alias}}|u_x|$, $\\max_{\\text{exact}}|u|$, $\\max_{\\text{exact}}|u_x|$.\n    c.  Calculate the four element-wise time steps: $\\Delta t_{\\text{adv}, K, \\text{alias}}$, $\\Delta t_{\\text{total}, K, \\text{alias}}$, $\\Delta t_{\\text{adv}, K, \\text{exact}}$, and $\\Delta t_{\\text{total}, K, \\text{exact}}$.\n2.  Compute the global minimum across all elements for each of the four time-step categories to obtain the final required scalars.\n\nThis procedure will be encoded into a Python script to compute the values for the three specified test cases. A crucial aspect of the problem is that the global time step is the *minimum over all elements*. This means that a local error in estimating a maximum (e.g., aliasing missing a peak) might not affect the final global time step if the time step is limited by a different element where the estimate is accurate.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes nonlinear CFL estimators for a DG discretization of the\n    inviscid Burgers equation based on the specified problem statement.\n    \"\"\"\n    \n    # Helper for sech(x) = 1/cosh(x)\n    def sech(x):\n        return 1.0 / np.cosh(x)\n\n    def compute_all_time_steps(h_k, p, u_func, du_dx_func, element_bounds,\n                               C_adv, C_visc, kappa):\n        \"\"\"\n        Computes the four required global time-step scalars for a given test case.\n        \"\"\"\n        num_elements = len(h_k)\n        \n        # p is uniform across elements for all test cases\n        P = p \n        p_vals = [P] * num_elements\n        \n        N_alias_vals = [p_val + 1 for p_val in p_vals]\n        N_exact_vals = [200 * p_val + 50 for p_val in p_vals]\n\n        # Initialize lists to store element-wise time steps\n        elem_dt_adv_alias = np.zeros(num_elements)\n        elem_dt_total_alias = np.zeros(num_elements)\n        elem_dt_adv_exact = np.zeros(num_elements)\n        elem_dt_total_exact = np.zeros(num_elements)\n\n        for i in range(num_elements):\n            x_left, x_right = element_bounds[i]\n\n            # 1. Aliasing sampling\n            x_alias = np.linspace(x_left, x_right, N_alias_vals[i])\n            u_samples_alias = u_func(x_alias)\n            du_dx_samples_alias = du_dx_func(x_alias)\n            max_u_alias = np.max(np.abs(u_samples_alias)) if u_samples_alias.size > 0 else 0.0\n            max_du_dx_alias = np.max(np.abs(du_dx_samples_alias)) if du_dx_samples_alias.size > 0 else 0.0\n\n            # 2. Exact surrogate sampling\n            x_exact = np.linspace(x_left, x_right, N_exact_vals[i])\n            u_samples_exact = u_func(x_exact)\n            du_dx_samples_exact = du_dx_func(x_exact)\n            max_u_exact = np.max(np.abs(u_samples_exact))\n            max_du_dx_exact = np.max(np.abs(du_dx_samples_exact))\n\n            # --- Calculate dt for aliasing ---\n            # Advective time step\n            # Use a small tolerance to avoid division by zero\n            if max_u_alias > 1e-14:\n                dt_adv_k_alias = C_adv * h_k[i] / ((2 * P + 1) * max_u_alias)\n            else:\n                dt_adv_k_alias = np.inf\n            elem_dt_adv_alias[i] = dt_adv_k_alias\n\n            # Viscous time step\n            if kappa > 0 and max_du_dx_alias > 1e-14:\n                dt_visc_k_alias = (C_visc * h_k[i]) / (kappa * max_du_dx_alias * (2 * P + 1)**2)\n            else:\n                dt_visc_k_alias = np.inf\n            \n            elem_dt_total_alias[i] = min(dt_adv_k_alias, dt_visc_k_alias)\n\n            # --- Calculate dt for exact surrogate ---\n            # Advective time step\n            if max_u_exact > 1e-14:\n                dt_adv_k_exact = C_adv * h_k[i] / ((2 * P + 1) * max_u_exact)\n            else:\n                dt_adv_k_exact = np.inf\n            elem_dt_adv_exact[i] = dt_adv_k_exact\n\n            # Viscous time step\n            if kappa > 0 and max_du_dx_exact > 1e-14:\n                dt_visc_k_exact = (C_visc * h_k[i]) / (kappa * max_du_dx_exact * (2 * P + 1)**2)\n            else:\n                dt_visc_k_exact = np.inf\n            \n            elem_dt_total_exact[i] = min(dt_adv_k_exact, dt_visc_k_exact)\n\n        # Find global minimums\n        global_dt_adv_alias = np.min(elem_dt_adv_alias)\n        global_dt_adv_exact = np.min(elem_dt_adv_exact)\n        global_dt_total_alias = np.min(elem_dt_total_alias)\n        global_dt_total_exact = np.min(elem_dt_total_exact)\n        \n        return [global_dt_adv_alias, global_dt_adv_exact, global_dt_total_alias, global_dt_total_exact]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (smooth, no viscosity)\n        {\n            \"p\": 3, \"h_k\": [0.25, 0.25, 0.25, 0.25],\n            \"u_func\": lambda x: np.sin(2 * np.pi * x),\n            \"du_dx_func\": lambda x: 2 * np.pi * np.cos(2 * np.pi * x),\n            \"C_adv\": 0.5, \"C_visc\": 0.25, \"kappa\": 0.0,\n            \"element_bounds\": [(0, 0.25), (0.25, 0.5), (0.5, 0.75), (0.75, 1.0)]\n        },\n        # Case 2 (near-discontinuous, with viscosity)\n        {\n            \"p\": 5, \"h_k\": [0.125] * 8,\n            \"u_func\": lambda x: np.tanh(100 * (x - 0.5)),\n            \"du_dx_func\": lambda x: 100 * sech(100 * (x - 0.5))**2,\n            \"C_adv\": 0.4, \"C_visc\": 0.25, \"kappa\": 0.05,\n            \"element_bounds\": [(i * 0.125, (i + 1) * 0.125) for i in range(8)]\n        },\n        # Case 3 (small element, no viscosity)\n        {\n            \"p\": 1, \"h_k\": [1e-3, 1-1e-3],\n            \"u_func\": lambda x: 10 + 0.5 * np.sin(2 * np.pi * x),\n            \"du_dx_func\": lambda x: np.pi * np.cos(2 * np.pi * x),\n            \"C_adv\": 0.9, \"C_visc\": 0.25, \"kappa\": 0.0,\n            \"element_bounds\": [(0, 1e-3), (1e-3, 1.0)]\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        case_results = compute_all_time_steps(\n            h_k=case[\"h_k\"],\n            p=case[\"p\"],\n            u_func=case[\"u_func\"],\n            du_dx_func=case[\"du_dx_func\"],\n            element_bounds=case[\"element_bounds\"],\n            C_adv=case[\"C_adv\"],\n            C_visc=case[\"C_visc\"],\n            kappa=case[\"kappa\"]\n        )\n        all_results.extend(case_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3374433"}, {"introduction": "A robust numerical method not only respects the CFL stability limit but can also use it as a guide for optimizing computational resources. This exercise tasks you with designing and implementing a `p`-adaptive controller that dynamically adjusts the polynomial degree $p_K$ on each element to balance the local Courant numbers across the mesh. By implementing this \"water-filling\" algorithm, you will gain hands-on experience with how stability analysis directly informs advanced adaptive strategies, aiming for uniform efficiency throughout the computational domain.", "problem": "Design and implement a program that constructs an adaptive polynomial-degree controller for a one-dimensional discontinuous Galerkin method based on the Courant–Friedrichs–Lewy stability condition. Consider a mesh with elements indexed by $K$, each with characteristic size $h_K$ (in meters), local maximum characteristic speed $a_K$ (in meters per second), and a local polynomial degree $p_K$ (dimensionless). The time step is global and denoted by $\\Delta t$ (in seconds). Define the local Courant number as $C_K = \\dfrac{a_K \\,\\Delta t\\, (p_K + 1)}{h_K}$, a dimensionless quantity that measures the ratio between the numerical domain of dependence and the physical domain of dependence scaled by the local resolution. Assume an explicit time integrator that imposes a stability admissibility threshold $C_{\\mathrm{crit}}$ (dimensionless) such that a necessary linear stability condition is $C_K \\le C_{\\mathrm{crit}}$ for each element $K$. The integer polynomial degree is bounded by $p_{\\min} \\le p_K \\le p_{\\max}$.\n\nStarting from the fundamental definition of $C_K$ and the monotonic effect of $p_K$ on $C_K$ (strictly increasing in $p_K$ for $a_K \\Delta t / h_K > 0$, and constant for $a_K = 0$), design a controller that:\n- Decreases $p_K$ wherever the local stability condition is violated.\n- Increases $p_K$ wherever the local stability condition allows and $\\Delta t$ is not the limiting factor.\n- Aims to equalize the local Courant numbers across the mesh as much as possible under the constraints.\n\nTo render the task well-posed and programmatically testable, implement the following precise controller semantics, derived from the above principles and the requirement to equalize the Courant numbers:\n- Stabilization phase: For each element $K$, while $C_K > C_{\\mathrm{crit}}$ and $p_K > p_{\\min}$, decrement $p_K \\leftarrow p_K - 1$ and update $C_K$ accordingly. After this phase, every element satisfies $C_K \\le C_{\\mathrm{crit}}$ or $p_K = p_{\\min}$.\n- Equalization phase (water-filling with stability): Repeatedly perform the following step until no change is possible:\n  - Identify the set of indices $S$ of elements that are eligible to increase, meaning $p_K  p_{\\max}$ and the incremented Courant number $C_K^{\\mathrm{new}} = \\dfrac{a_K \\,\\Delta t\\, (p_K + 2)}{h_K}$ would satisfy $C_K^{\\mathrm{new}} \\le C_{\\mathrm{crit}}$.\n  - If $S$ is empty, terminate. Otherwise, among $S$, select the element with the smallest current $C_K$; break ties by the smallest index $K$.\n  - Increase its degree: $p_K \\leftarrow p_K + 1$ and update $C_K$.\nThis controller maximizes the minimum $C_K$ subject to $C_K \\le C_{\\mathrm{crit}}$ and $p_{\\min} \\le p_K \\le p_{\\max}$ and enforces a deterministic tie-breaking, thereby producing a unique outcome.\n\nYour program must implement the above controller exactly and return, for each test case, the final vector of integers $[p_1,\\dots,p_{N}]$ after convergence of both phases. All physical quantities must be used with their specified units: $h_K$ in meters, $a_K$ in meters per second, and $\\Delta t$ in seconds. The output degrees $p_K$ are dimensionless integers.\n\nUse the following test suite. For each test case, the input is given in the order: the list $[h_K]$, the list $[a_K]$, the list $[p_K^{(0)}]$ of initial degrees, the scalar $\\Delta t$, the scalar $C_{\\mathrm{crit}}$, the integers $p_{\\min}$ and $p_{\\max}$. All lists are ordered by increasing element index.\n- Test case A (heterogeneous mesh with a tight element that must decrease): $[h_K] = [0.1,\\,0.05,\\,0.2,\\,0.04,\\,0.12]$, $[a_K] = [1.0,\\,0.8,\\,1.2,\\,1.5,\\,0.5]$, $[p_K^{(0)}] = [1,\\,2,\\,1,\\,3,\\,0]$, $\\Delta t = 0.01$, $C_{\\mathrm{crit}} = 0.9$, $p_{\\min} = 0$, $p_{\\max} = 5$.\n- Test case B (elements with zero speed, testing saturation at $p_{\\max}$): $[h_K] = [0.1,\\,0.1,\\,0.1]$, $[a_K] = [0.0,\\,1.0,\\,0.0]$, $[p_K^{(0)}] = [0,\\,0,\\,0]$, $\\Delta t = 0.02$, $C_{\\mathrm{crit}} = 0.6$, $p_{\\min} = 0$, $p_{\\max} = 7$.\n- Test case C (very small elements forcing degree reduction): $[h_K] = [0.005,\\,0.01,\\,0.03]$, $[a_K] = [2.0,\\,2.0,\\,2.0]$, $[p_K^{(0)}] = [3,\\,3,\\,3]$, $\\Delta t = 0.002$, $C_{\\mathrm{crit}} = 0.9$, $p_{\\min} = 0$, $p_{\\max} = 5$.\n- Test case D (already balanced, all can be raised to the stability limit): $[h_K] = [1.0,\\,1.0,\\,1.0,\\,1.0]$, $[a_K] = [1.0,\\,1.0,\\,1.0,\\,1.0]$, $[p_K^{(0)}] = [1,\\,1,\\,1,\\,1]$, $\\Delta t = 0.1$, $C_{\\mathrm{crit}} = 0.5$, $p_{\\min} = 0$, $p_{\\max} = 4$.\n\nYour program should produce a single line of output containing the final degree lists for all test cases as a comma-separated list enclosed in square brackets (e.g., $[[p_1,\\dots,p_{N_A}],[p_1,\\dots,p_{N_B}],\\dots]$), where each sublist contains the integers for its test case. No additional text should be printed.", "solution": "The user has provided a problem that requires the design and implementation of an adaptive polynomial-degree controller for a one-dimensional discontinuous Galerkin (DG) method. The controller's logic is based on satisfying the Courant–Friedrichs–Lewy (CFL) stability condition.\n\n### Step 1: Extract Givens\n- **Mesh Elements**: Indexed by $K$.\n- **Element Size**: $h_K$ (meters).\n- **Characteristic Speed**: $a_K$ (meters/second).\n- **Polynomial Degree**: $p_K$ (dimensionless integer).\n- **Global Time Step**: $\\Delta t$ (seconds).\n- **Local Courant Number**: $C_K = \\dfrac{a_K \\,\\Delta t\\, (p_K + 1)}{h_K}$.\n- **Stability Condition**: $C_K \\le C_{\\mathrm{crit}}$ for all $K$.\n- **Stability Threshold**: $C_{\\mathrm{crit}}$ (dimensionless).\n- **Degree Bounds**: $p_{\\min} \\le p_K \\le p_{\\max}$.\n- **Controller Logic**:\n    1.  **Stabilization Phase**: For each element $K$, if $C_K  C_{\\mathrm{crit}}$ and $p_K  p_{\\min}$, repeatedly decrement $p_K$ by $1$ until the condition is met.\n    2.  **Equalization Phase**: Iteratively perform the following until no more changes occur:\n        a. Identify the set $S$ of elements where $p_K  p_{\\max}$ and incrementing $p_K$ would not violate the stability condition (i.e., $C_K^{\\mathrm{new}} = \\frac{a_K \\Delta t (p_K + 2)}{h_K} \\le C_{\\mathrm{crit}}$).\n        b. If $S$ is empty, terminate.\n        c. Otherwise, from $S$, select the element with the minimum current $C_K$. Ties are broken by choosing the element with the smallest index $K$.\n        d. Increment $p_K$ for the selected element and update its $C_K$.\n- **Inputs**: Test cases providing lists of $[h_K]$, $[a_K]$, initial $[p_K^{(0)}]$, and scalar parameters $\\Delta t$, $C_{\\mathrm{crit}}$, $p_{\\min}$, $p_{\\max}$.\n- **Output**: A list containing the final integer degree vectors $[p_1, \\dots, p_N]$ for each test case.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientific Grounding**: The problem is well-grounded in the numerical analysis of partial differential equations. The CFL condition and the concept of a p-adaptive DG method are standard and scientifically valid. The provided formula for the Courant number, $C_K$, is a common model for DG methods, which scales with polynomial degree $p_K$.\n- **Well-Posedness**: The controller logic is described by a deterministic algorithm. The stabilization phase must terminate as $p_K$ is an integer bounded below by $p_{\\min}$. The equalization phase is a greedy algorithm operating on a finite state space (since each $p_K$ is bounded), and each step monotonically increases one of the $p_K$ values. The strict tie-breaking rule ensures a unique execution path and a unique final state. Thus, a unique solution exists.\n- **Objectivity**: The problem is stated in precise, formal language. The controller's behavior is explicitly defined, leaving no room for subjectivity.\n- **Completeness and Consistency**: All necessary parameters and initial conditions are provided for each test case. The units are consistent ($a_K \\Delta t / h_K$ is dimensionless). The problem is self-contained and free of contradictions.\n\n### Step 3: Verdict and Action\nThe problem is valid. It is a well-defined computational task based on sound scientific principles. A solution will be developed based on the specified algorithm.\n\n### Algorithmic Design\n\nThe solution will be implemented as a Python program that processes a series of test cases. For each case, a function will execute the two-phase controller logic.\n\n1.  **Initialization**:\n    - The input lists for $h_K$, $a_K$, and $p_K^{(0)}$ will be converted to NumPy arrays for efficient vectorized computation. Let these be `h`, `a`, and `p`.\n    - To optimize performance, the constant factor for the Courant number calculation, $c_{\\mathrm{factor},K} = \\dfrac{a_K \\Delta t}{h_K}$, will be pre-computed for each element $K$. The Courant number is then $C_K = c_{\\mathrm{factor},K} (p_K + 1)$.\n    - The initial Courant numbers $C_K$ are calculated based on the initial degrees $p_K^{(0)}$.\n\n2.  **Phase 1: Stabilization**:\n    - The program will iterate through each element $K$.\n    - A `while` loop checks if the element violates the stability condition ($C_K  C_{\\mathrm{crit}}$) and if its degree can be reduced ($p_K  p_{\\min}$).\n    - If both are true, $p_K$ is decremented, and $C_K$ is re-computed. This loop continues until the element is stable or its degree reaches $p_{\\min}$.\n\n3.  **Phase 2: Equalization (Water-Filling)**:\n    - This phase is implemented within a main `while` loop that continues as long as at least one element's degree can be increased.\n    - In each iteration of this main loop:\n        a. A list of `eligible_candidates` is constructed. An element $K$ is eligible if its degree $p_K$ is less than $p_{\\max}$ and its potential new Courant number, upon incrementing $p_K$, does not exceed $C_{\\mathrm{crit}}$.\n        b. Each candidate is stored as a tuple `(C_K, K)` containing its current Courant number and its index.\n        c. If the list of candidates is empty, the main loop terminates, as the system has reached a stable, optimized state.\n        d. If there are candidates, the list is sorted. The primary sort key is $C_K$ (ascending), and the secondary key is the index $K$ (ascending). Python's default sort is stable, which, when applied to a list of tuples `(value, index)` created by iterating through indices in ascending order, automatically respects the tie-breaking rule.\n        e. The degree $p_K$ of the first element in the sorted list (the one with the minimum $C_K$, with ties broken by index) is incremented, and its $C_K$ is updated.\n    - This iterative process is analogous to \"water-filling,\" where we greedily \"pour\" degrees into the elements with the most \"capacity\" (lowest $C_K$) under the stability constraint.\n\n4.  **Final Output**:\n    - After the controller converges, the final NumPy array of degrees `p` is converted back to a Python list of integers.\n    - The results from all test cases are collected and formatted into a single string as specified by the problem, e.g., `[[p1,p2,...],[q1,q2,...]]`.\n\nThis design ensures a correct and efficient implementation of the specified deterministic controller.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_controller(h_k_list, a_k_list, p_k_initial_list, delta_t, c_crit, p_min, p_max):\n    \"\"\"\n    Implements the adaptive polynomial-degree controller based on the CFL condition.\n    \n    The controller operates in two phases:\n    1. Stabilization: Decrements polynomial degrees to satisfy the stability condition.\n    2. Equalization: Iteratively increases degrees for elements with the most\n       stability headroom, aiming to balance Courant numbers across the mesh.\n    \"\"\"\n    # Convert input lists to NumPy arrays for efficient vectorized operations.\n    h_k = np.array(h_k_list, dtype=np.float64)\n    a_k = np.array(a_k_list, dtype=np.float64)\n    p_k = np.array(p_k_initial_list, dtype=np.int64)\n    \n    num_elements = len(h_k)\n    \n    # Pre-calculate the constant part of the Courant number for each element.\n    # This avoids repeated floating-point divisions inside loops.\n    # Characteristic size h_k is assumed to be > 0.\n    c_factor = np.divide(a_k * delta_t, h_k, out=np.zeros_like(a_k, dtype=float), where=h_k!=0)\n\n    # Initialize local Courant numbers.\n    c_k = c_factor * (p_k.astype(np.float64) + 1.0)\n\n    # Phase 1: Stabilization\n    # For each element K, while C_K > C_crit and p_K > p_min, decrement p_K.\n    for k in range(num_elements):\n        while c_k[k] > c_crit and p_k[k] > p_min:\n            p_k[k] -= 1\n            c_k[k] = c_factor[k] * (p_k[k] + 1.0)\n\n    # Phase 2: Equalization (water-filling with stability)\n    # Repeatedly increase p_K for the most \"roomy\" eligible element.\n    while True:\n        eligible_candidates = []\n        for k in range(num_elements):\n            # Check eligibility: p_K  p_max...\n            if p_k[k]  p_max:\n                # ...and ensure the incremented Courant number is within the stability limit.\n                c_new = c_factor[k] * (p_k[k] + 2.0)\n                if c_new = c_crit:\n                    # A candidate is stored as a tuple (current C_K, index K)\n                    # for sorting according to the specified criteria.\n                    eligible_candidates.append((c_k[k], k))\n        \n        # If no elements are eligible for a degree increase, the process has converged.\n        if not eligible_candidates:\n            break\n\n        # Sort candidates to find the one with the smallest current C_K.\n        # Python's list.sort() is stable, so in case of a tie in C_K,\n        # the original order (by increasing index K) is preserved,\n        # fulfilling the tie-breaking rule.\n        eligible_candidates.sort()\n        \n        # Select the element to update (the first one after sorting).\n        k_to_increase = eligible_candidates[0][1]\n        \n        # Increase its polynomial degree and update its Courant number.\n        p_k[k_to_increase] += 1\n        c_k[k_to_increase] = c_factor[k_to_increase] * (p_k[k_to_increase] + 1.0)\n\n    return p_k.tolist()\n\ndef solve():\n    \"\"\"\n    Defines the test suite, runs the controller for each case,\n    and prints the results in the specified format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case A\n        {'h_k': [0.1, 0.05, 0.2, 0.04, 0.12], 'a_k': [1.0, 0.8, 1.2, 1.5, 0.5], 'p_k_initial': [1, 2, 1, 3, 0], 'delta_t': 0.01, 'c_crit': 0.9, 'p_min': 0, 'p_max': 5},\n        # Test Case B\n        {'h_k': [0.1, 0.1, 0.1], 'a_k': [0.0, 1.0, 0.0], 'p_k_initial': [0, 0, 0], 'delta_t': 0.02, 'c_crit': 0.6, 'p_min': 0, 'p_max': 7},\n        # Test Case C\n        {'h_k': [0.005, 0.01, 0.03], 'a_k': [2.0, 2.0, 2.0], 'p_k_initial': [3, 3, 3], 'delta_t': 0.002, 'c_crit': 0.9, 'p_min': 0, 'p_max': 5},\n        # Test Case D\n        {'h_k': [1.0, 1.0, 1.0, 1.0], 'a_k': [1.0, 1.0, 1.0, 1.0], 'p_k_initial': [1, 1, 1, 1], 'delta_t': 0.1, 'c_crit': 0.5, 'p_min': 0, 'p_max': 4}\n    ]\n\n    results = []\n    for case in test_cases:\n        final_p_k = run_controller(\n            case['h_k'],\n            case['a_k'],\n            case['p_k_initial'],\n            case['delta_t'],\n            case['c_crit'],\n            case['p_min'],\n            case['p_max']\n        )\n        results.append(final_p_k)\n\n    # Format the results into the required string format \"[[...],[...],...]\".\n    # The str() representation of a list includes brackets. Spaces are removed\n    # to match the compact output format example.\n    results_str = ','.join([str(res).replace(' ', '') for res in results])\n    print(f\"[{results_str}]\")\n\nsolve()\n```", "id": "3374373"}, {"introduction": "The nominal CFL condition, based on advective speed and mesh size, can sometimes be overly optimistic, especially for nonlinear problems. This theoretical exercise explores the subtle but critical issue of aliasing-induced instability, which arises from under-integrating nonlinear terms in the governing equations. By deriving how quadrature errors can introduce a non-physical energy growth that effectively tightens the stable time-step limit, you will develop a deeper appreciation for the hidden stability costs of certain numerical implementation choices.", "problem": "Consider the scalar conservation law $u_{t} + \\partial_{x} f(u) = 0$ on a periodic domain of length $L$, with flux $f(u) = \\alpha\\,u + \\tfrac{1}{2}u^{2}$ (nonlinear advection with a linear bias). Discretize using the nodal Discontinuous Galerkin Spectral Element Method (DGSEM) on a uniform mesh of $N_{e}$ elements of size $h=L/N_{e}$, with polynomial degree $p$ and Legendre–Gauss–Lobatto (LGL) nodes. Let the numerical surface flux be the upwind Riemann flux computed with the characteristic speed bound $a_{\\max} := \\max_{x,t} |f'(u)|$. For the semi-discrete scheme, take the volume integrals with a quadrature rule using $Q$ points per element, and consider explicit time integration by the three-stage Strong-Stability-Preserving Runge–Kutta (SSPRK(3,3)) method whose absolute stability interval on the negative real axis has radius $r_{s}=2$.\n\nYou will analyze the interplay between the Courant–Friedrichs–Lewy (CFL) stability condition and aliasing when the nonlinear volume terms are underintegrated (i.e., $Q=p+1$) and show how sufficient over-integration removes the aliasing penalty.\n\nWork in the elementwise $L^{2}$ energy, using the Summation-By-Parts (SBP) property of the LGL collocation and the upwind flux to control interface contributions. Assume the standard inverse inequality on each element $K$ holds in the mapped physical coordinate with constant one,\n$$\n\\|\\partial_{x} v\\|_{L^{2}(K)} \\le \\frac{(p+1)^{2}}{h}\\,\\|v\\|_{L^{2}(K)} \\quad \\text{for all } v \\in \\mathbb{P}_{p}(K),\n$$\nand model the integrand aliasing caused by underintegration via the orthogonal $L^{2}$ projection $\\Pi_{p}$ onto $\\mathbb{P}_{p}(K)$: for the product $g(u):=f'(u)\\,u$, the quadrature defect acts as $(I-\\Pi_{p})g(u)$ in the volume term. Let the unresolved energy fraction be $\\theta \\in [0,1]$, defined by\n$$\n\\theta := \\frac{\\sum_{K} \\|(I-\\Pi_{p})u\\|_{L^{2}(K)}^{2}}{\\sum_{K} \\|u\\|_{L^{2}(K)}^{2}},\n$$\nand suppose that, for the quadratic nonlinearity, the unresolved part of $g(u)$ can be bounded proportionally to $a_{\\max}$ and the unresolved energy of $u$, in the sense that\n$$\n\\sum_{K} \\|(I-\\Pi_{p})g(u)\\|_{L^{2}(K)} \\le a_{\\max}\\,\\theta^{1/2}\\,\\Big(\\sum_{K}\\|u\\|_{L^{2}(K)}^{2}\\Big)^{1/2}.\n$$\n\nStarting only from these assumptions and the SBP energy method for DGSEM:\n- Derive an upper bound for the nominal semi-discrete spectral radius $\\rho_{\\mathrm{nom}}$ of the advection operator in the resolved (no-aliasing) case, scaling as $(2p+1)a_{\\max}/h$, by relating interface dissipation and a discrete trace/inverse inequality.\n- Show that the underintegrated nonlinear volume term produces a non-negative energy production that can be bounded by an effective aliasing penalty term $\\sigma_{\\mathrm{alias}}$ added to the nominal spectral radius, with the bound\n$$\n\\sigma_{\\mathrm{alias}} \\le \\frac{(p+1)^{2}}{h}\\,a_{\\max}\\,\\theta.\n$$\n- Conclude a conservative explicit step-size restriction for SSPRK(3,3) of the form\n$$\n\\Delta t_{\\max} \\le \\frac{r_{s}}{\\rho_{\\mathrm{nom}}+\\sigma_{\\mathrm{alias}}}.\n$$\n- Finally, argue why over-integration with $Q\\ge 2p$ makes the projection of the quadratic product exact into $\\mathbb{P}_{p}$, i.e., $(I-\\Pi_{p})g(u)=0$, thereby restoring $\\sigma_{\\mathrm{alias}}=0$ and the nominal CFL.\n\nEvaluate the maximum stable time step for the following concrete parameters and modeling choices:\n- Domain length $L=1$ and $N_{e}=20$ elements, hence $h=1/20$.\n- Polynomial degree $p=5$ with LGL collocation for volume and surface.\n- Linear coefficient $\\alpha=1$ and a priori bound on the solution amplitude $|u(x,t)|\\le U_{\\max}=0.5$, so that $a_{\\max}=\\alpha+U_{\\max}$.\n- Underintegration with $Q=p+1$ for the volume terms.\n- Unresolved energy fraction $\\theta=0.2$.\n- SSPRK(3,3) with $r_{s}=2$.\n\nExpress your final answer as the single dimensionless number $\\Delta t_{\\max}$, rounded to four significant figures.", "solution": "The problem asks for a stability analysis of a Discontinuous Galerkin Spectral Element Method (DGSEM) for a scalar conservation law, including the effects of aliasing from underintegration, and to calculate a maximum stable time step for a specific case.\n\nThe problem statement has been validated and is deemed valid. It is scientifically grounded in the numerical analysis of partial differential equations, is well-posed as a sequence of derivations followed by a calculation, and is stated in objective, formal language. All necessary data and modeling assumptions are provided.\n\nThe analysis proceeds by following the four deductive steps outlined in the problem.\n\nFirst, we derive an upper bound for the nominal semi-discrete spectral radius, $\\rho_{\\mathrm{nom}}$, in the absence of aliasing. The semi-discrete equation is $\\frac{d}{dt}u_h = \\mathcal{L}_h(u_h)$, where $\\mathcal{L}_h$ is the spatial discretization operator. The stability of an explicit time-stepping scheme depends on the spectral radius of $\\mathcal{L}_h$. For DGSEM schemes utilizing Summation-By-Parts (SBP) properties, particularly those based on Legendre-Gauss-Lobatto (LGL) nodes, it is known that the volume contribution to the energy evolution, $\\frac{d}{dt}\\|u_h\\|^2$, can be made skew-symmetric. Stability is then governed by the numerical flux at element interfaces. For the upwind flux, this results in dissipation. The spectral radius of the complete operator, for the linear advection equation $u_t + a u_x = 0$, is bounded by the properties of the discrete differentiation operator and the interface coupling. A standard result for the DGSEM scheme on LGL nodes is that the spectral radius of the operator is bounded by the maximum wave speed $a_{\\max}$ and a factor dependent on the polynomial degree $p$ and element size $h$. This factor arises from bounding the norm of the discrete operator, which involves trace inequalities that for LGL nodal sets relate the values at the element boundaries to the norm over the element interior. A sharp estimate for the spectral radius for split-form DGSEM, which is closely related, gives a bound proportional to $(2p+1)$. As guided by the problem, we adopt this scaling. The nominal spectral radius $\\rho_{\\mathrm{nom}}$ for the resolved case is thus bounded by:\n$$\n\\rho_{\\mathrm{nom}} \\le \\frac{(2p+1)a_{\\max}}{h}\n$$\nWe take this as an equality for a conservative estimate, yielding $\\rho_{\\mathrm{nom}} = \\frac{(2p+1)a_{\\max}}{h}$.\n\nSecond, we analyze the effect of aliasing due to underintegration, where the number of quadrature points $Q=p+1$ is insufficient to exactly compute the nonlinear volume integrals. The rate of change of the discrete energy on an element $K$ is given by setting the test function to be the solution $u_h$ in the weak formulation:\n$$\n\\frac{1}{2}\\frac{d}{dt}\\|u_h\\|^2_{h,K} = (\\partial_x u_h, f(u_h))_{Q,K} - [u_h^* \\hat{f}]_{\\partial K}\n$$\nwhere $(\\cdot,\\cdot)_{Q,K}$ is the inner product based on the $Q$-point quadrature rule. In the absence of aliasing, the volume term $\\sum_K (\\partial_x u_h, f(u_h))_{\\text{exact},K}$ combines with the surface terms to ensure energy stability (or bounded growth for non-conservative fluxes). With underintegration, a quadrature error arises in the nonlinear part of the flux, $f(u) = \\alpha u + \\frac{1}{2}u^2$. This error introduces a non-physical energy production term. The problem models this by considering the term in its non-conservative form, $-\\int u_h \\partial_x f(u_h) dx = -\\int u_h f'(u_h) \\partial_x u_h dx$. Let $g(u_h) = u_h f'(u_h)$. The aliasing error in the quadrature of this term, denoted $P_{\\mathrm{alias}}$, can be bounded. Following the problem's physical intuition, this production term is modeled as the interaction between the aliased part of $g(u_h)$ and the derivative of the solution, $\\partial_x u_h$.\n$$\nP_{\\mathrm{alias}} \\approx \\sum_K \\left( (I-\\Pi_p)g(u_h), \\partial_x u_h \\right)_{Q,K}\n$$\nwhere $\\Pi_p$ is the $L^2$ projection onto the polynomial space $\\mathbb{P}_p(K)$. Using the Cauchy-Schwarz inequality, norm equivalence between the discrete quadrature norm and the continuous $L^2$ norm, and the given inverse inequality on each element, we bound this term:\n$$\nP_{\\mathrm{alias}} \\le \\sum_K \\|(I-\\Pi_p)g(u_h)\\|_{L^2(K)} \\|\\partial_x u_h\\|_{L^2(K)} \\le \\sum_K \\|(I-\\Pi_p)g(u_h)\\|_{L^2(K)} \\frac{(p+1)^2}{h} \\|u_h\\|_{L^2(K)}\n$$\nTo proceed, we apply the Cauchy-Schwarz inequality to the sum over elements $K$:\n$$\nP_{\\mathrm{alias}} \\le \\frac{(p+1)^2}{h} \\left( \\sum_K \\|(I-\\Pi_p)g(u_h)\\|_{L^2(K)}^2 \\right)^{1/2} \\left( \\sum_K \\|u_h\\|_{L^2(K)}^2 \\right)^{1/2}\n$$\nThe problem provides a specific model for the aliasing effect, bounding the sum of the norms, not the sum of the squares. Following a slightly different path by bounding the per-element solution norm by the total solution norm, $\\|u_h\\|_{L^2(K)} \\le \\|u_h\\|_{L^2(\\Omega)}$, leads to:\n$$\nP_{\\mathrm{alias}} \\le \\frac{(p+1)^2}{h} \\|u_h\\|_{L^2(\\Omega)} \\sum_K \\|(I-\\Pi_p)g(u_h)\\|_{L^2(K)}\n$$\nUsing the provided model for the aliasing term, $\\sum_{K} \\|(I-\\Pi_{p})g(u)\\|_{L^{2}(K)} \\le a_{\\max}\\,\\theta^{1/2}\\,\\left(\\sum_{K}\\|u\\|_{L^{2}(K)}^{2}\\right)^{1/2}$, we obtain:\n$$\nP_{\\mathrm{alias}} \\le \\frac{(p+1)^2}{h} \\|u_h\\|_{L^2(\\Omega)} \\left( a_{\\max} \\theta^{1/2} \\|u_h\\|_{L^2(\\Omega)} \\right) = \\frac{(p+1)^2}{h} a_{\\max} \\theta^{1/2} \\|u_h\\|_{L^2(\\Omega)}^2\n$$\nThis derivation yields a bound proportional to $\\theta^{1/2}$. Since $\\theta \\in [0,1]$, we have $\\theta \\le \\theta^{1/2}$. Therefore, the bound required by the problem, $\\sigma_{\\mathrm{alias}} \\le \\frac{(p+1)^2}{h} a_{\\max} \\theta$, represents a tighter estimate that likely relies upon a more detailed model of the aliasing mechanism for quadratic nonlinearities than assumed in this general derivation. Adhering to the problem statement, we adopt the specified bound for $\\sigma_{\\mathrm{alias}}$. This term acts as an additional energy growth rate, effectively increasing the spectral radius of the operator.\n$$\n\\sigma_{\\mathrm{alias}} = \\frac{(p+1)^{2}}{h}\\,a_{\\max}\\,\\theta\n$$\n\nThird, we formulate the CFL condition. The total effective spectral radius of the semi-discrete operator is bounded by the sum of the nominal spectral radius and the aliasing penalty term: $\\rho_{\\mathrm{eff}} \\le \\rho_{\\mathrm{nom}} + \\sigma_{\\mathrm{alias}}$. For an explicit time integration method to be stable, the product of the time step $\\Delta t$ and any eigenvalue $\\lambda$ of the discrete operator must lie within the method's absolute stability region. The problem specifies a simplified stability criterion based on the radius of the stability region on the negative real axis, $r_s$. We thus must satisfy $\\Delta t \\cdot \\rho_{\\mathrm{eff}} \\le r_s$. This yields the conservative time-step restriction:\n$$\n\\Delta t_{\\max} \\le \\frac{r_s}{\\rho_{\\mathrm{nom}} + \\sigma_{\\mathrm{alias}}}\n$$\n\nFourth, we argue why sufficient over-integration removes the aliasing penalty. The aliasing error originates from the inexact quadrature of the nonlinear volume term $(\\partial_x u_h, f(u_h))_h$. For the given flux $f(u_h) = \\alpha u_h + \\frac{1}{2}u_h^2$, the integrand is a polynomial. Since $u_h \\in \\mathbb{P}_p$, $\\partial_x u_h \\in \\mathbb{P}_{p-1}$ and $f(u_h) \\in \\mathbb{P}_{2p}$. The product $(\\partial_x u_h) f(u_h)$ is therefore a polynomial of degree at most $(p-1)+2p = 3p-1$. An LGL quadrature rule with $Q$ points integrates polynomials of degree up to $2Q-1$ exactly. To ensure the volume integral is exact, we require $2Q-1 \\ge 3p-1$, which simplifies to $Q \\ge \\frac{3}{2}p$. The condition given, $Q \\ge 2p$, is therefore sufficient for all $p \\ge 1$ to guarantee exact integration of the volume term. When the integral is computed exactly, the SBP property holds perfectly, and aliasing-induced energy production is eliminated. Consequently, $\\sigma_{\\mathrm{alias}}=0$, and the time-step restriction reverts to the nominal (resolved) CFL condition, $\\Delta t_{\\max} \\le r_s / \\rho_{\\mathrm{nom}}$. The problem's phrasing regarding $(I-\\Pi_p)g(u)=0$ is a bit imprecise; the crucial consequence of over-integration is the exactness of the volume integral, leading to $\\sigma_{\\mathrm{alias}}=0$.\n\nFinally, we evaluate the maximum stable time step for the given parameters:\n- Domain length $L=1$, number of elements $N_e=20$, so element size $h = L/N_e = 1/20 = 0.05$.\n- Polynomial degree $p=5$.\n- Flux parameters $\\alpha=1$ and solution bound $|u| \\le U_{\\max}=0.5$. The characteristic speed is $f'(u) = \\alpha+u = 1+u$. The maximum absolute value over the solution range is $a_{\\max} = \\max_{u \\in [-0.5, 0.5]} |1+u| = 1+0.5 = 1.5$.\n- Unresolved energy fraction $\\theta=0.2$.\n- SSPRK(3,3) stability radius $r_s=2$.\n\nWe calculate the nominal spectral radius bound:\n$$\n\\rho_{\\mathrm{nom}} = \\frac{(2p+1)a_{\\max}}{h} = \\frac{(2(5)+1)(1.5)}{0.05} = \\frac{11 \\times 1.5}{0.05} = \\frac{16.5}{0.05} = 330\n$$\nNext, we calculate the aliasing penalty:\n$$\n\\sigma_{\\mathrm{alias}} = \\frac{(p+1)^2}{h} a_{\\max} \\theta = \\frac{(5+1)^2}{0.05} (1.5)(0.2) = \\frac{36}{0.05} \\times 0.3 = 720 \\times 0.3 = 216\n$$\nThe maximum stable time step is then:\n$$\n\\Delta t_{\\max} = \\frac{r_s}{\\rho_{\\mathrm{nom}} + \\sigma_{\\mathrm{alias}}} = \\frac{2}{330 + 216} = \\frac{2}{546} = \\frac{1}{273} \\approx 0.00366300366...\n$$\nRounding to four significant figures gives $\\Delta t_{\\max} = 0.003663$.", "answer": "$$\\boxed{0.003663}$$", "id": "3374378"}]}