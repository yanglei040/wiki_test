{"hands_on_practices": [{"introduction": "A cornerstone of nodal methods is the ability to approximate derivatives of a function using only its values at a set of discrete nodes. This is achieved by creating a differentiation matrix that acts on the vector of nodal values. This exercise demystifies this process by guiding you through the construction of a spectral differentiation matrix from first principles, using the Lagrange polynomials that form the nodal basis. By applying this matrix to a known function, you will directly verify a key property of spectral methods: their exactness for polynomials up to a certain degree. [@problem_id:3400065]", "problem": "Consider the one-dimensional spectral collocation setting on the interval $[-1,1]$ with Gauss–Lobatto–Legendre (GLL) nodes of polynomial degree $N=3$. Let $\\{x_{j}\\}_{j=0}^{N}$ be the $N+1$ GLL nodes with $x_{0}=-1$, $x_{N}=1$, and interior nodes given by the roots of the derivative of the Legendre polynomial of degree $N$. Define the Lagrange nodal basis $\\{\\ell_{j}(x)\\}_{j=0}^{N}$ by $\\ell_{j}(x_{i})=\\delta_{ij}$, and define the nodal differentiation matrix $D\\in\\mathbb{R}^{(N+1)\\times(N+1)}$ by $D_{ij}=\\ell_{j}'(x_{i})$. \n\nStarting from the definition of $\\ell_{j}(x)$ and the properties of the GLL nodes, compute $D$ explicitly for $N=3$ on $[-1,1]$. Then, for the polynomial $u(x)=x^{3}$, form the nodal vector $u=[u(x_{0}),u(x_{1}),u(x_{2}),u(x_{3})]^{\\mathsf{T}}$ and the discrete derivative $v=Du$. Using the exact derivative $u'(x)=3x^{2}$, define the maximum nodal error \n$$\nE_{\\max}=\\max_{0\\le i\\le 3}\\left|v_{i}-u'(x_{i})\\right|.\n$$\n\nProvide $E_{\\max}$ as the final answer. No rounding is required, and no units are involved. The intermediate steps must be justified from first principles of Lagrange interpolation on the given nodes, without invoking any result that presupposes the final form of $D$.", "solution": "The problem is first validated against the specified criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n- **Domain:** One-dimensional interval $[-1, 1]$.\n- **Method:** Spectral collocation on Gauss–Lobatto–Legendre (GLL) nodes.\n- **Polynomial Degree:** $N=3$.\n- **Nodes:** $\\{x_{j}\\}_{j=0}^{3}$ are the GLL nodes. $x_{0}=-1$, $x_{3}=1$. Interior nodes are the roots of the derivative of the Legendre polynomial of degree $N=3$, $P_{3}'(x)$.\n- **Basis:** Lagrange nodal basis $\\{\\ell_{j}(x)\\}_{j=0}^{3}$ defined by the property $\\ell_{j}(x_{i})=\\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta.\n- **Differentiation Matrix:** $D\\in\\mathbb{R}^{4\\times 4}$ with entries $D_{ij}=\\ell_{j}'(x_{i})$.\n- **Function:** $u(x)=x^{3}$.\n- **Nodal Vector:** $u=[u(x_{0}),u(x_{1}),u(x_{2}),u(x_{3})]^{\\mathsf{T}}$.\n- **Discrete Derivative:** $v=Du$.\n- **Exact Derivative:** $u'(x)=3x^{2}$.\n- **Error Metric:** $E_{\\max}=\\max_{0\\le i\\le 3}\\left|v_{i}-u'(x_{i})\\right|$.\n- **Constraint:** The solution must be derived from first principles, starting from the definition of $\\ell_j(x)$ and GLL nodes, without using pre-computed formulas for the differentiation matrix $D$.\n\n**Step 2: Validate Using Extracted Givens**\n- **Scientifically Grounded:** The problem is a standard exercise in the field of spectral methods for numerical partial differential equations. All concepts (Legendre polynomials, GLL nodes, Lagrange interpolation, spectral differentiation) are fundamental and well-established in numerical analysis.\n- **Well-Posed:** The problem is clearly defined with all necessary information. The steps to compute the GLL nodes, the differentiation matrix, the discrete derivative, and the final error are unambiguous, leading to a unique solution.\n- **Objective:** The problem statement is precise, quantitative, and free of any subjective or opinion-based language.\n- **Conclusion:** The problem is self-contained, consistent, and scientifically sound. It does not violate any of the specified invalidity criteria.\n\n**Step 3: Verdict and Action**\nThe problem is **valid**. A full, reasoned solution will be provided.\n\n### Solution\n\nThe solution proceeds in several steps:\n1.  Compute the Gauss–Lobatto–Legendre (GLL) nodes $\\{x_j\\}_{j=0}^3$.\n2.  Construct the differentiation matrix $D$ from the definition of the Lagrange basis.\n3.  Evaluate the function $u(x)=x^3$ at the nodes to form the vector $u$.\n4.  Compute the discrete derivative $v=Du$.\n5.  Evaluate the exact derivative $u'(x)=3x^2$ at the nodes.\n6.  Calculate the maximum nodal error $E_{\\max}$.\n\n**Step 1: Compute GLL nodes for $N=3$**\nThe GLL nodes for polynomial degree $N$ on $[-1, 1]$ consist of the endpoints $x_0=-1$ and $x_N=1$, and the $N-1$ roots of $P_N'(x)$, where $P_N(x)$ is the Legendre polynomial of degree $N$. For $N=3$, we need the roots of $P_3'(x)$.\n\nThe Legendre polynomials are defined by the recurrence relation $(n+1)P_{n+1}(x) = (2n+1)xP_n(x) - nP_{n-1}(x)$, with $P_0(x)=1$ and $P_1(x)=x$.\n$P_2(x) = \\frac{1}{2}(3x^2-1)$\n$P_3(x) = \\frac{1}{2}(5x^3-3x)$\n\nThe derivative is $P_3'(x) = \\frac{1}{2}(15x^2-3)$.\nThe interior nodes are the roots of $P_3'(x)=0$:\n$$\n15x^2 - 3 = 0 \\implies x^2 = \\frac{3}{15} = \\frac{1}{5} \\implies x = \\pm \\frac{1}{\\sqrt{5}}\n$$\nThe set of $N+1=4$ GLL nodes, ordered from smallest to largest, is:\n$$\nx_0 = -1, \\quad x_1 = -\\frac{1}{\\sqrt{5}}, \\quad x_2 = \\frac{1}{\\sqrt{5}}, \\quad x_3 = 1\n$$\n\n**Step 2: Compute the Differentiation Matrix $D$**\nThe entries of the differentiation matrix are given by $D_{ij} = \\ell_j'(x_i)$. The Lagrange basis polynomial $\\ell_j(x)$ is defined as:\n$$\n\\ell_j(x) = \\prod_{k=0, k\\neq j}^{3} \\frac{x-x_k}{x_j-x_k}\n$$\nThe derivative $\\ell_j'(x)$ can be found using the product rule. Evaluating at a node $x_i$:\nFor $i \\neq j$:\n$$\n\\ell_j'(x_i) = \\frac{1}{\\prod_{k \\neq j}(x_j-x_k)} \\left. \\frac{d}{dx} \\prod_{k \\neq j}(x-x_k) \\right|_{x=x_i} = \\frac{\\prod_{k \\neq i,j}(x_i-x_k)}{\\prod_{k \\neq j}(x_j-x_k)}\n$$\nFor $i = j$:\n$$\n\\ell_i'(x_i) = \\sum_{k=0, k\\neq i}^{3} \\frac{1}{x_i-x_k}\n$$\nWe now compute the entries of $D$.\nDiagonal entries $D_{ii}$:\n$D_{00} = \\frac{1}{x_0-x_1} + \\frac{1}{x_0-x_2} + \\frac{1}{x_0-x_3} = \\frac{1}{-1 - (-1/\\sqrt{5})} + \\frac{1}{-1 - 1/\\sqrt{5}} + \\frac{1}{-1 - 1} = \\frac{1}{-1+1/\\sqrt{5}} + \\frac{1}{-1-1/\\sqrt{5}} - \\frac{1}{2} = \\frac{\\sqrt{5}}{1-\\sqrt{5}} - \\frac{\\sqrt{5}}{1+\\sqrt{5}} - \\frac{1}{2} = \\sqrt{5}\\frac{(1+\\sqrt{5})-(1-\\sqrt{5})}{1-5} - \\frac{1}{2} = \\frac{\\sqrt{5}(2\\sqrt{5})}{-4} - \\frac{1}{2} = -\\frac{10}{4} - \\frac{1}{2} = -3$.\n$D_{11} = \\frac{1}{x_1-x_0} + \\frac{1}{x_1-x_2} + \\frac{1}{x_1-x_3} = \\frac{1}{-1/\\sqrt{5}-(-1)} + \\frac{1}{-1/\\sqrt{5}-1/\\sqrt{5}} + \\frac{1}{-1/\\sqrt{5}-1} = \\frac{\\sqrt{5}}{\\sqrt{5}-1} - \\frac{\\sqrt{5}}{2} - \\frac{\\sqrt{5}}{\\sqrt{5}+1} = \\sqrt{5}\\left(\\frac{1}{\\sqrt{5}-1} - \\frac{1}{\\sqrt{5}+1}\\right) - \\frac{\\sqrt{5}}{2} = \\sqrt{5}\\frac{(\\sqrt{5}+1)-(\\sqrt{5}-1)}{5-1} - \\frac{\\sqrt{5}}{2} = \\sqrt{5}\\frac{2}{4} - \\frac{\\sqrt{5}}{2} = 0$.\nBy symmetry of the nodes ($x_2 = -x_1, x_0 = -x_3$), we can infer $D_{22}=0$.\n$D_{33} = \\frac{1}{x_3-x_0} + \\frac{1}{x_3-x_1} + \\frac{1}{x_3-x_2} = \\frac{1}{1-(-1)} + \\frac{1}{1-(-1/\\sqrt{5})} + \\frac{1}{1-1/\\sqrt{5}} = \\frac{1}{2} + \\frac{\\sqrt{5}}{\\sqrt{5}+1} + \\frac{\\sqrt{5}}{\\sqrt{5}-1} = \\frac{1}{2} + \\sqrt{5}\\frac{(\\sqrt{5}-1)+(\\sqrt{5}+1)}{5-1} = \\frac{1}{2} + \\frac{\\sqrt{5}(2\\sqrt{5})}{4} = \\frac{1}{2} + \\frac{10}{4} = 3$.\nThe diagonal of $D$ is $(-3, 0, 0, 3)$.\n\nA detailed calculation of the off-diagonal entries (not shown here for brevity, but following the stated formula) would yield the matrix:\n$$\nD = \\begin{pmatrix}\n-3 & \\frac{5(1+\\sqrt{5})}{4} & \\frac{5(1-\\sqrt{5})}{4} & \\frac{1}{2} \\\\\n-\\frac{1+\\sqrt{5}}{4} & 0 & \\frac{\\sqrt{5}}{2} & -\\frac{\\sqrt{5}-1}{4} \\\\\n\\frac{\\sqrt{5}-1}{4} & -\\frac{\\sqrt{5}}{2} & 0 & \\frac{1+\\sqrt{5}}{4} \\\\\n-\\frac{1}{2} & \\frac{5(\\sqrt{5}-1)}{4} & -\\frac{5(\\sqrt{5}+1)}{4} & 3\n\\end{pmatrix}\n$$\n\n**Step 3: Form Nodal Vector $u$**\nThe function is $u(x)=x^3$. The nodal vector $u$ is formed by evaluating $u(x)$ at the GLL nodes:\n$u_0 = u(x_0) = u(-1) = (-1)^3 = -1$.\n$u_1 = u(x_1) = u(-1/\\sqrt{5}) = (-1/\\sqrt{5})^3 = -1/(5\\sqrt{5})$.\n$u_2 = u(x_2) = u(1/\\sqrt{5}) = (1/\\sqrt{5})^3 = 1/(5\\sqrt{5})$.\n$u_3 = u(x_3) = u(1) = 1^3 = 1$.\nSo, $u = [-1, -1/(5\\sqrt{5}), 1/(5\\sqrt{5}), 1]^{\\mathsf{T}}$.\n\n**Step 4: Compute the Discrete Derivative $v=Du$**\nWe perform the matrix-vector multiplication $v=Du$.\n$v_0 = (-3)(-1) + \\frac{5(1+\\sqrt{5})}{4}\\left(-\\frac{1}{5\\sqrt{5}}\\right) + \\frac{5(1-\\sqrt{5})}{4}\\left(\\frac{1}{5\\sqrt{5}}\\right) + \\frac{1}{2}(1) = 3 - \\frac{1+\\sqrt{5}}{4\\sqrt{5}} + \\frac{1-\\sqrt{5}}{4\\sqrt{5}} + \\frac{1}{2} = 3 + \\frac{(1-\\sqrt{5})-(1+\\sqrt{5})}{4\\sqrt{5}} + \\frac{1}{2} = 3 + \\frac{-2\\sqrt{5}}{4\\sqrt{5}} + \\frac{1}{2} = 3 - \\frac{1}{2} + \\frac{1}{2} = 3$.\n\n$v_1 = \\left(-\\frac{1+\\sqrt{5}}{4}\\right)(-1) + (0)\\left(-\\frac{1}{5\\sqrt{5}}\\right) + \\left(\\frac{\\sqrt{5}}{2}\\right)\\left(\\frac{1}{5\\sqrt{5}}\\right) + \\left(-\\frac{\\sqrt{5}-1}{4}\\right)(1) = \\frac{1+\\sqrt{5}}{4} + \\frac{1}{10} - \\frac{\\sqrt{5}-1}{4} = \\frac{(1+\\sqrt{5})-(\\sqrt{5}-1)}{4} + \\frac{1}{10} = \\frac{2}{4} + \\frac{1}{10} = \\frac{1}{2} + \\frac{1}{10} = \\frac{6}{10} = \\frac{3}{5}$.\n\n$v_2 = \\left(\\frac{\\sqrt{5}-1}{4}\\right)(-1) + \\left(-\\frac{\\sqrt{5}}{2}\\right)\\left(-\\frac{1}{5\\sqrt{5}}\\right) + (0)\\left(\\frac{1}{5\\sqrt{5}}\\right) + \\left(\\frac{1+\\sqrt{5}}{4}\\right)(1) = -\\frac{\\sqrt{5}-1}{4} + \\frac{1}{10} + \\frac{1+\\sqrt{5}}{4} = \\frac{(1+\\sqrt{5})-(\\sqrt{5}-1)}{4} + \\frac{1}{10} = \\frac{2}{4} + \\frac{1}{10} = \\frac{3}{5}$.\n\n$v_3 = \\left(-\\frac{1}{2}\\right)(-1) + \\frac{5(\\sqrt{5}-1)}{4}\\left(-\\frac{1}{5\\sqrt{5}}\\right) + \\left(-\\frac{5(\\sqrt{5}+1)}{4}\\right)\\left(\\frac{1}{5\\sqrt{5}}\\right) + (3)(1) = \\frac{1}{2} - \\frac{\\sqrt{5}-1}{4\\sqrt{5}} - \\frac{\\sqrt{5}+1}{4\\sqrt{5}} + 3 = \\frac{7}{2} - \\frac{(\\sqrt{5}-1)+(\\sqrt{5}+1)}{4\\sqrt{5}} = \\frac{7}{2} - \\frac{2\\sqrt{5}}{4\\sqrt{5}} = \\frac{7}{2} - \\frac{1}{2} = 3$.\n\nThe vector of discrete derivatives is $v = [3, 3/5, 3/5, 3]^{\\mathsf{T}}$.\n\n**Step 5: Compute Exact Derivative at Nodes**\nThe exact derivative of $u(x)=x^3$ is $u'(x)=3x^2$. We evaluate this at the nodes:\n$u'(x_0) = u'(-1) = 3(-1)^2 = 3$.\n$u'(x_1) = u'(-1/\\sqrt{5}) = 3(-1/\\sqrt{5})^2 = 3(1/5) = 3/5$.\n$u'(x_2) = u'(1/\\sqrt{5}) = 3(1/\\sqrt{5})^2 = 3(1/5) = 3/5$.\n$u'(x_3) = u'(1) = 3(1)^2 = 3$.\nThe vector of exact derivative values is $[3, 3/5, 3/5, 3]^{\\mathsf{T}}$.\n\n**Step 6: Compute Maximum Nodal Error $E_{\\max}$**\nThe error at each node is given by $v_i - u'(x_i)$:\n$v_0 - u'(x_0) = 3 - 3 = 0$.\n$v_1 - u'(x_1) = 3/5 - 3/5 = 0$.\n$v_2 - u'(x_2) = 3/5 - 3/5 = 0$.\n$v_3 - u'(x_3) = 3 - 3 = 0$.\nThe error is zero at all nodes. Therefore, the maximum nodal error is:\n$$\nE_{\\max} = \\max\\{|0|, |0|, |0|, |0|\\} = 0\n$$\n\nThis result is expected. The spectral collocation method involves interpolating the function $u(x)$ with a polynomial of degree at most $N$ that passes through the function values at the $N+1$ nodes. Here, $N=3$. The function being differentiated, $u(x)=x^3$, is a polynomial of degree $3$. Thus, the interpolating polynomial is exactly $u(x)$ itself. The spectral differentiation process computes the exact derivative of the interpolant at the nodes. Since the interpolant is exact, its derivative is also exact, and the computed derivative values at the nodes match the exact derivative values perfectly. The error is therefore identically zero.", "answer": "$$\n\\boxed{0}\n$$", "id": "3400065"}, {"introduction": "While nodal bases are convenient for applying boundary conditions and handling nonlinearities, modal bases built from orthogonal polynomials offer advantages in analysis and stability. The two representations are linked by a linear transformation, captured by the Vandermonde matrix. This practice focuses on explicitly constructing this matrix and its inverse, providing a concrete link between nodal values and modal coefficients. By verifying the transformation rule for the mass matrix, you will solidify your understanding of how fundamental operators are represented and connected across these different but equivalent bases. [@problem_id:3400113]", "problem": "On the reference element $\\Omega=[-1,1]$, consider the polynomial space $\\mathbb{P}_3$ with the Legendre modal basis $\\{P_0(x),P_1(x),P_2(x),P_3(x)\\}$, where $P_n(x)$ denotes the $n$th Legendre polynomial normalized by the classical orthogonality relation $\\int_{-1}^{1} P_m(x) P_n(x)\\,dx = \\frac{2}{2n+1}\\,\\delta_{mn}$. Let the nodal set be the Gauss–Lobatto–Legendre (GLL) nodes for $N=3$, i.e., the roots of $(1-x^2)P_3'(x)$ together with the endpoints, which are $x_1=-1$, $x_2=-\\frac{1}{\\sqrt{5}}$, $x_3=\\frac{1}{\\sqrt{5}}$, $x_4=1$. Define the Vandermonde matrix $V\\in\\mathbb{R}^{4\\times 4}$ by $V_{ij}=P_{j-1}(x_i)$ for $1\\leq i,j\\leq 4$. The modal mass matrix is $M_{\\text{modal}}\\in\\mathbb{R}^{4\\times 4}$ with entries $(M_{\\text{modal}})_{mn}=\\int_{-1}^{1} P_{m-1}(x)P_{n-1}(x)\\,dx$, and the nodal mass matrix is $M_{\\text{nodal}}\\in\\mathbb{R}^{4\\times 4}$ with entries $(M_{\\text{nodal}})_{ij}=\\int_{-1}^{1} \\ell_i(x)\\ell_j(x)\\,dx$, where $\\{\\ell_i(x)\\}_{i=1}^{4}$ are the Lagrange nodal basis polynomials associated with the GLL nodes.\n\nTasks:\n- Compute the matrices $V$ and $V^{-1}$ explicitly in exact form.\n- Using only fundamental definitions of modal and nodal bases and the $L^2(\\Omega)$ inner product, verify the identity $V^{-T} M_{\\text{modal}} V^{-1}=M_{\\text{nodal}}$ when all integrals are evaluated exactly (i.e., not approximated by a numerical quadrature rule).\n- As your final reported quantity, compute the Frobenius norm $\\|V^{-T} M_{\\text{modal}} V^{-1}-M_{\\text{nodal}}\\|_{F}$.\n\nExpress the final value using exact arithmetic. No rounding is required. The final answer must be a single real number.", "solution": "The problem is deemed valid as it is scientifically grounded, well-posed, and objective. It is a standard problem in the field of spectral and discontinuous Galerkin methods.\n\nThe problem requires the verification of a fundamental identity relating modal and nodal representations of functions in a polynomial space and the computation of a resulting norm. We will proceed by first defining all quantities, computing the required matrices, theoretically verifying the identity, and finally computing the specified norm.\n\nThe polynomial space is $\\mathbb{P}_3$ on the reference element $\\Omega=[-1,1]$.\nThe modal basis consists of the first four Legendre polynomials, which are:\n$$ P_0(x) = 1 $$\n$$ P_1(x) = x $$\n$$ P_2(x) = \\frac{1}{2}(3x^2 - 1) $$\n$$ P_3(x) = \\frac{1}{2}(5x^3 - 3x) $$\nThese polynomials are orthogonal with respect to the $L^2$ inner product, satisfying the given normalization:\n$$ \\int_{-1}^{1} P_m(x) P_n(x) dx = \\frac{2}{2n+1}\\delta_{mn} $$\n\nThe nodal basis is defined by the set of $N+1=4$ Gauss–Lobatto–Legendre (GLL) nodes for $N=3$. These are the roots of $(1-x^2)P_3'(x) = 0$. The roots of $P_3'(x) = \\frac{1}{2}(15x^2 - 3)$ are $x^2 = 3/15 = 1/5$, so $x = \\pm 1/\\sqrt{5}$. Including the endpoints $x = \\pm 1$, the GLL nodes are:\n$$ x_1 = -1, \\quad x_2 = -\\frac{1}{\\sqrt{5}}, \\quad x_3 = \\frac{1}{\\sqrt{5}}, \\quad x_4 = 1 $$\nThe nodal basis functions are the Lagrange polynomials $\\{\\ell_i(x)\\}_{i=1}^4$ such that $\\ell_i(x_j) = \\delta_{ij}$.\n\nTask 1: Compute the matrices $V$ and $V^{-1}$.\n\nThe Vandermonde matrix $V$ is defined by $V_{ij} = P_{j-1}(x_i)$. We evaluate the Legendre polynomials at the GLL nodes:\nAt $x_1 = -1$: $P_0(-1)=1$, $P_1(-1)=-1$, $P_2(-1)=1$, $P_3(-1)=-1$.\nAt $x_2 = -1/\\sqrt{5}$: $P_0=1$, $P_1=-1/\\sqrt{5}$, $P_2=\\frac{1}{2}(3(1/5)-1)=-1/5$, $P_3=\\frac{1}{2}(5(-1/5\\sqrt{5}) - 3(-1/\\sqrt{5})) = 1/\\sqrt{5}$.\nAt $x_3 = 1/\\sqrt{5}$: $P_0=1$, $P_1=1/\\sqrt{5}$, $P_2=-1/5$, $P_3=\\frac{1}{2}(5(1/5\\sqrt{5}) - 3(1/\\sqrt{5})) = -1/\\sqrt{5}$.\nAt $x_4 = 1$: $P_0(1)=1$, $P_1(1)=1$, $P_2(1)=1$, $P_3(1)=1$.\n\nAssembling these values gives the matrix $V$:\n$$ V = \\begin{pmatrix}\n1 & -1 & 1 & -1 \\\\\n1 & -1/\\sqrt{5} & -1/5 & 1/\\sqrt{5} \\\\\n1 & 1/\\sqrt{5} & -1/5 & -1/\\sqrt{5} \\\\\n1 & 1 & 1 & 1\n\\end{pmatrix} $$\n\nThe inverse matrix $V^{-1}$ transforms nodal values to modal coefficients. The $k$-th column of $V^{-1}$ contains the modal coefficients of the $k$-th Lagrange polynomial $\\ell_k(x)$. For instance, for $\\ell_1(x)$ (associated with $x_1=-1$), we have $\\ell_1(x) = \\frac{(x-x_2)(x-x_3)(x-x_4)}{(x_1-x_2)(x_1-x_3)(x_1-x_4)}$. This can be expanded and then expressed in the Legendre basis. Performing this for all four Lagrange polynomials yields the columns of $V^{-1}$:\n$$ \\ell_1(x) = \\frac{1}{12}P_0(x) - \\frac{1}{4}P_1(x) + \\frac{5}{12}P_2(x) - \\frac{1}{4}P_3(x) $$\n$$ \\ell_2(x) = \\frac{5}{12}P_0(x) - \\frac{\\sqrt{5}}{4}P_1(x) - \\frac{5}{12}P_2(x) + \\frac{\\sqrt{5}}{4}P_3(x) $$\n$$ \\ell_3(x) = \\frac{5}{12}P_0(x) + \\frac{\\sqrt{5}}{4}P_1(x) - \\frac{5}{12}P_2(x) - \\frac{\\sqrt{5}}{4}P_3(x) $$\n$$ \\ell_4(x) = \\frac{1}{12}P_0(x) + \\frac{1}{4}P_1(x) + \\frac{5}{12}P_2(x) + \\frac{1}{4}P_3(x) $$\nThus, the inverse Vandermonde matrix is:\n$$ V^{-1} = \\begin{pmatrix}\n\\frac{1}{12} & \\frac{5}{12} & \\frac{5}{12} & \\frac{1}{12} \\\\\n-\\frac{1}{4} & -\\frac{\\sqrt{5}}{4} & \\frac{\\sqrt{5}}{4} & \\frac{1}{4} \\\\\n\\frac{5}{12} & -\\frac{5}{12} & -\\frac{5}{12} & \\frac{5}{12} \\\\\n-\\frac{1}{4} & \\frac{\\sqrt{5}}{4} & -\\frac{\\sqrt{5}}{4} & \\frac{1}{4}\n\\end{pmatrix} $$\n\nTask 2: Verify the identity $V^{-T} M_{\\text{modal}} V^{-1}=M_{\\text{nodal}}$.\n\nFirst, we define the mass matrices. The modal mass matrix $M_{\\text{modal}}$ has entries $(M_{\\text{modal}})_{mn}=\\int_{-1}^{1} P_{m-1}(x)P_{n-1}(x)\\,dx$. Due to orthogonality, it is a diagonal matrix:\n$$ (M_{\\text{modal}})_{mn} = \\frac{2}{2(m-1)+1}\\delta_{mn} $$\nSo,\n$$ M_{\\text{modal}} = \\begin{pmatrix}\n2 & 0 & 0 & 0 \\\\\n0 & \\frac{2}{3} & 0 & 0 \\\\\n0 & 0 & \\frac{2}{5} & 0 \\\\\n0 & 0 & 0 & \\frac{2}{7}\n\\end{pmatrix} $$\nThe nodal mass matrix $M_{\\text{nodal}}$ has entries $(M_{\\text{nodal}})_{ij}=\\int_{-1}^{1} \\ell_i(x)\\ell_j(x)\\,dx$.\n\nThe verification of the identity relies on the change of basis for the $L^2$ inner product. Let $u(x), v(x) \\in \\mathbb{P}_3$.\nThe inner product $(u,v) = \\int_{-1}^1 u(x)v(x)dx$.\n\nIn the modal basis, $u(x) = \\sum_{m=1}^4 \\hat{u}_m P_{m-1}(x)$ and $v(x) = \\sum_{n=1}^4 \\hat{v}_n P_{n-1}(x)$, where $\\hat{\\mathbf{u}} = (\\hat{u}_1, \\dots, \\hat{u}_4)^T$ and $\\hat{\\mathbf{v}} = (\\hat{v}_1, \\dots, \\hat{v}_4)^T$ are the vectors of modal coefficients. The inner product is:\n$$ (u,v) = \\int_{-1}^1 \\left(\\sum_m \\hat{u}_m P_{m-1}\\right) \\left(\\sum_n \\hat{v}_n P_{n-1}\\right) dx = \\sum_{m,n} \\hat{u}_m \\hat{v}_n \\int_{-1}^1 P_{m-1}P_{n-1} dx $$\nIn matrix form, this is $(u,v) = \\hat{\\mathbf{u}}^T M_{\\text{modal}} \\hat{\\mathbf{v}}$.\n\nIn the nodal basis, $u(x) = \\sum_{i=1}^4 u_i \\ell_i(x)$ and $v(x) = \\sum_{j=1}^4 v_j \\ell_j(x)$, where $u_i = u(x_i)$ and $v_j=v(x_j)$ are the nodal values, with vectors $\\mathbf{u}=(u_1, \\dots, u_4)^T$ and $\\mathbf{v}=(v_1, \\dots, v_4)^T$. The inner product is:\n$$ (u,v) = \\int_{-1}^1 \\left(\\sum_i u_i \\ell_i\\right) \\left(\\sum_j v_j \\ell_j\\right) dx = \\sum_{i,j} u_i v_j \\int_{-1}^1 \\ell_i \\ell_j dx $$\nIn matrix form, $(u,v) = \\mathbf{u}^T M_{\\text{nodal}} \\mathbf{v}$.\n\nThe transformation between the modal coefficients and nodal values is given by evaluating the modal expansion at the nodes: $u_i = u(x_i) = \\sum_{m=1}^4 \\hat{u}_m P_{m-1}(x_i) = \\sum_{m=1}^4 V_{im} \\hat{u}_m$.\nIn matrix form, $\\mathbf{u} = V \\hat{\\mathbf{u}}$. This implies the inverse transformation is $\\hat{\\mathbf{u}} = V^{-1} \\mathbf{u}$.\n\nSubstituting the transformation for modal coefficients into the modal representation of the inner product gives:\n$$ (u,v) = (V^{-1}\\mathbf{u})^T M_{\\text{modal}} (V^{-1}\\mathbf{v}) = \\mathbf{u}^T (V^{-1})^T M_{\\text{modal}} V^{-1} \\mathbf{v} = \\mathbf{u}^T (V^{-T} M_{\\text{modal}} V^{-1}) \\mathbf{v} $$\nBy equating the two expressions for the inner product in terms of nodal values, we get:\n$$ \\mathbf{u}^T M_{\\text{nodal}} \\mathbf{v} = \\mathbf{u}^T (V^{-T} M_{\\text{modal}} V^{-1}) \\mathbf{v} $$\nSince this equality must hold for all possible vectors $\\mathbf{u}, \\mathbf{v}$ corresponding to polynomials in $\\mathbb{P}_3$, the matrices themselves must be equal:\n$$ M_{\\text{nodal}} = V^{-T} M_{\\text{modal}} V^{-1} $$\nThis completes the verification of the identity. The identity holds true by definition, provided all integrals are evaluated exactly.\n\nTask 3: Compute the Frobenius norm $\\|V^{-T} M_{\\text{modal}} V^{-1}-M_{\\text{nodal}}\\|_{F}$.\n\nFrom the verification above, we have established that the matrix equality $V^{-T} M_{\\text{modal}} V^{-1} = M_{\\text{nodal}}$ is exact. Therefore, the difference matrix is the zero matrix:\n$$ V^{-T} M_{\\text{modal}} V^{-1} - M_{\\text{nodal}} = \\mathbf{0} $$\nwhere $\\mathbf{0}$ is the $4 \\times 4$ zero matrix.\n\nThe Frobenius norm of a matrix $A$ is defined as $\\|A\\|_F = \\sqrt{\\sum_{i,j} |A_{ij}|^2}$. For the zero matrix, all entries $A_{ij}$ are $0$.\nTherefore, the Frobenius norm is:\n$$ \\|\\mathbf{0}\\|_F = \\sqrt{\\sum_{i=1}^4 \\sum_{j=1}^4 |0|^2} = \\sqrt{0} = 0 $$", "answer": "$$\\boxed{0}$$", "id": "3400113"}, {"introduction": "The theoretical ability to transform between nodal and modal bases is only useful if the transformation is numerically stable. In practice, the conditioning of the Vandermonde matrix, $\\kappa(V)$, is a critical factor that determines how sensitive the modal coefficients are to small perturbations in the nodal data. This computational exercise explores this very issue, demonstrating the dramatic difference in stability between judiciously chosen nodes (like Gauss-Lobatto) and naive ones (equispaced). By implementing and analyzing the effects of basis scaling, you will gain practical insight into why specific node sets are favored in high-order methods and how to ensure robust basis transformations. [@problem_id:3400097]", "problem": "Consider the one-dimensional reference element on the interval $[-1,1]$ and polynomial approximations of degree $p$. Let $\\{P_k(x)\\}_{k=0}^{p}$ denote the Legendre polynomials on $[-1,1]$, which form a modal basis for polynomial spaces and satisfy the orthogonality relation $\\int_{-1}^{1} P_k(x) P_m(x)\\, dx = 0$ for $k \\neq m$, with squared norms $\\int_{-1}^{1} P_k(x)^2\\, dx = \\frac{2}{2k+1}$. For a set of $p+1$ distinct nodes $\\{x_i\\}_{i=0}^{p}$ in $[-1,1]$, define the nodal basis via the Lagrange polynomials $\\{\\ell_i(x)\\}_{i=0}^{p}$ such that $\\ell_i(x_j) = \\delta_{ij}$, where $\\delta_{ij}$ is the Kronecker delta. Any polynomial $u_p(x)$ of degree at most $p$ can be represented equivalently in the modal basis $u_p(x) = \\sum_{k=0}^{p} \\hat{u}_k P_k(x)$ or in the nodal basis $u_p(x) = \\sum_{i=0}^{p} u_i \\ell_i(x)$, where $u_i = u_p(x_i)$ are the nodal values and $\\hat{u}_k$ are the modal coefficients.\n\nDefine the rectangular Vandermonde matrix $V \\in \\mathbb{R}^{(p+1)\\times(p+1)}$ by $V_{ik} = P_k(x_i)$, for $i=0,\\dots,p$ and $k=0,\\dots,p$. Then the nodal and modal coefficients are related by the linear system $u = V \\hat{u}$, where $u = (u_0,\\dots,u_p)^\\top$ and $\\hat{u} = (\\hat{u}_0,\\dots,\\hat{u}_p)^\\top$. Define the basis transformation $T$ by $\\hat{u} = T u$. From the relation $u = V \\hat{u}$, it follows that $T = V^{-1}$, provided the nodes are distinct and the columns of $V$ are linearly independent, which holds for any choice of $p+1$ distinct nodes.\n\nThe goal is to:\n1. Construct the matrix $V$ for specified sets of nodes $\\{x_i\\}$ and polynomial degrees $p$, implement the transformation $T = V^{-1}$, and analyze the conditioning $\\kappa(T)$ in the spectral norm (matrix $2$-norm) as $p$ increases. Recall that $\\kappa(T) = \\|T\\|_2 \\|T^{-1}\\|_2$.\n2. Propose and implement a scaling that stabilizes $T$. Consider the column scaling $D \\in \\mathbb{R}^{(p+1)\\times(p+1)}$ defined by $D_{kk} = \\sqrt{\\frac{2k+1}{2}}$, which maps the Legendre polynomials to an $L^2$-orthonormal modal basis $\\phi_k(x) = \\sqrt{\\frac{2k+1}{2}} P_k(x)$. When quadrature weights $\\{w_i\\}$ correspond to the nodes, consider also row scaling $S \\in \\mathbb{R}^{(p+1)\\times(p+1)}$ defined by $S_{ii} = \\sqrt{w_i}$. Analyze the conditioning of the scaled operator $SVD$ and compare to that of $V$. Note that $\\kappa(T) = \\kappa(V)$ and the conditioning of the scaled transformation $T_{\\text{scaled}} = D^{-1} T S^{-1}$ is equal to $\\kappa(S V D)$.\n\nBase your derivations on the core definitions above and on the orthogonality properties of Legendre polynomials. Do not assume any heuristic \"shortcut\" formulas beyond the definitions and well-tested facts stated above.\n\nYour program must implement the following node sets and corresponding quadrature weights:\n- Equispaced nodes: $x_i = -1 + \\frac{2i}{p}$ for $i=0,\\dots,p$. No quadrature weights are to be used for row scaling in this case.\n- Gauss–Legendre nodes and weights: use the $p+1$-point Gauss–Legendre quadrature on $[-1,1]$.\n- Gauss–Lobatto nodes: $x_0=-1$, $x_p=1$, with interior nodes given by the $p-1$ roots of the Jacobi polynomial $P^{(1,1)}_{p-1}(x)$. Use the Gauss–Lobatto quadrature weights $w_i = \\dfrac{2}{p(p+1)}\\dfrac{1}{\\left(P_p(x_i)\\right)^2}$, which include the endpoint weights $w_0=w_p=\\dfrac{2}{p(p+1)}$ because $(P_p(\\pm 1))^2=1$.\n\nImplement $V$, compute $\\kappa(V)$ and $\\kappa(S V D)$ using the matrix $2$-norm (spectral norm). For numerical stability, do not explicitly form the inverse of $V$ to compute the condition number; instead, use the singular value decomposition characterization $\\kappa_2(V) = \\sigma_{\\max}(V)/\\sigma_{\\min}(V)$.\n\nTest Suite:\n- Case 1: $p=3$, equispaced nodes.\n- Case 2: $p=15$, equispaced nodes.\n- Case 3: $p=15$, Gauss–Legendre nodes and weights.\n- Case 4: $p=1$, Gauss–Lobatto nodes and weights.\n- Case 5: $p=25$, Gauss–Lobatto nodes and weights.\n\nFor each case, compute and return a list of two floating-point numbers $[\\kappa(V), \\kappa(SVD)]$. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the cases above. For example, the output format must be: \n$[\\,[\\kappa(V)_1,\\kappa(SVD)_1],\\,[\\kappa(V)_2,\\kappa(SVD)_2],\\dots]$.", "solution": "The problem requires an analysis of the conditioning of the transformation between nodal and modal representations of polynomials on the one-dimensional reference element $[-1,1]$. This analysis is fundamental in spectral and discontinuous Galerkin methods, as a poorly conditioned transformation can amplify numerical errors.\n\nA polynomial $u_p(x)$ of degree at most $p$ can be expressed in two common bases. First, the modal basis, which uses a set of orthogonal polynomials. Here, we use the Legendre polynomials $\\{P_k(x)\\}_{k=0}^p$. The representation is:\n$$u_p(x) = \\sum_{k=0}^{p} \\hat{u}_k P_k(x)$$\nwhere $\\hat{u}_k$ are the modal coefficients. Legendre polynomials are orthogonal on $[-1,1]$ with respect to the $L^2$ inner product, satisfying $\\int_{-1}^{1} P_k(x) P_m(x)\\, dx = \\frac{2}{2k+1}\\delta_{km}$, where $\\delta_{km}$ is the Kronecker delta.\n\nSecond, the nodal basis, which is defined by a set of $p+1$ distinct nodes $\\{x_i\\}_{i=0}^p$. The basis functions are the Lagrange polynomials $\\{\\ell_i(x)\\}_{i=0}^p$, which have the property $\\ell_i(x_j) = \\delta_{ij}$. The representation is:\n$$u_p(x) = \\sum_{i=0}^{p} u_i \\ell_i(x)$$\nwhere $u_i = u_p(x_i)$ are the values of the polynomial at the nodes.\n\nThe relationship between the nodal values $u = (u_0, \\dots, u_p)^\\top$ and the modal coefficients $\\hat{u} = (\\hat{u}_0, \\dots, \\hat{u}_p)^\\top$ is established by evaluating the modal expansion at each node $x_i$:\n$$u_i = u_p(x_i) = \\sum_{k=0}^{p} \\hat{u}_k P_k(x_i)$$\nThis set of linear equations can be written in matrix form as $u = V \\hat{u}$, where $V$ is the generalized Vandermonde matrix with entries $V_{ik} = P_k(x_i)$. The transformation from nodal values to modal coefficients is given by $\\hat{u} = V^{-1} u$. The numerical stability of this transformation depends on the condition number of the matrix $V$, denoted $\\kappa(V)$. Recall that $\\kappa(A) = \\|A\\|_2 \\|A^{-1}\\|_2$, which for the matrix $2$-norm is equivalent to the ratio of the largest to the smallest singular value, $\\kappa_2(A) = \\sigma_{\\max}(A) / \\sigma_{\\min}(A)$.\n\nThe problem investigates how the choice of nodes and basis scaling affects this condition number. We analyze two types of scaling:\n1.  **Column Scaling**: This corresponds to a change in the modal basis. We use the diagonal matrix $D$ with entries $D_{kk} = \\sqrt{\\frac{2k+1}{2}}$. This transforms the Legendre basis $\\{P_k(x)\\}$ into an $L^2$-orthonormal basis $\\{\\phi_k(x) = D_{kk}P_k(x)\\}$, since $\\int_{-1}^1 \\phi_k(x)\\phi_m(x)dx = \\delta_{km}$. The Vandermonde matrix for this new basis is $V D$.\n2.  **Row Scaling**: This corresponds to weighting the linear equations. We use the diagonal matrix $S$ with entries $S_{ii} = \\sqrt{w_i}$, where $\\{w_i\\}$ are quadrature weights associated with the nodes $\\{x_i\\}$.\n\nThe combined effect of these scalings leads to the matrix $SVD$. We will compare the condition number of the original Vandermonde matrix, $\\kappa(V)$, with that of the fully scaled matrix, $\\kappa(SVD)$. For certain choices of nodes and weights (specifically, Gaussian quadrature rules), the discrete inner product $\\sum_{i=0}^p w_i f(x_i) g(x_i)$ approximates the continuous inner product $\\int_{-1}^1 f(x)g(x)dx$. If this quadrature is exact for polynomials of degree up to $2p$, the matrix $SVD$ becomes orthogonal, meaning $(SVD)^T(SVD) = I$. An orthogonal matrix has a condition number of $1$, representing perfect conditioning.\n\nThe implementation will proceed as follows for each test case defined by a polynomial degree $p$ and a node set:\n\n**1. Node and Weight Generation:**\n- **Equispaced nodes:** The nodes are given by the formula $x_i = -1 + \\frac{2i}{p}$ for $i=0, \\dots, p$. This choice is simple but is known to lead to poor conditioning as $p$ increases. No quadrature weights are specified, so row scaling is not applied, which is equivalent to setting $S=I$ (the identity matrix).\n- **Gauss–Legendre nodes:** The $p+1$ nodes and corresponding weights are the points of the Gauss-Legendre quadrature rule, which is exact for polynomials of degree up to $2(p+1)-1 = 2p+1$. We will use `scipy.special.roots_legendre` to obtain them. Given this exactness property, we expect $\\kappa(SVD)$ to be very close to $1$.\n- **Gauss–Lobatto nodes:** These nodes include the endpoints $x_0=-1$ and $x_p=1$. The $p-1$ interior nodes are the roots of the derivative of the Legendre polynomial $P_p'(x)$, which are also the roots of the Jacobi polynomial $P_{p-1}^{(1,1)}(x)$. The weights are calculated using the formula $w_i = \\frac{2}{p(p+1)}\\frac{1}{(P_p(x_i))^2}$. The corresponding quadrature rule is exact for polynomials of degree up to $2p-1$. Since the product of two degree-$p$ polynomials has degree $2p$, the rule is not exact for all products of basis functions, so $\\kappa(SVD)$ will be greater than $1$, but should still be significantly smaller than $\\kappa(V)$.\n\n**2. Matrix Construction:**\n- The Vandermonde matrix $V$ of size $(p+1) \\times (p+1)$ is constructed by setting $V_{ik} = P_k(x_i)$. The Legendre polynomials $P_k(x)$ are evaluated using `scipy.special.eval_legendre`.\n- The diagonal scaling matrices $S$ and $D$ are formed using the weights and the normalization constants. The scaled matrix is computed as $SVD$. This can be performed efficiently using broadcasting operations in NumPy without explicitly creating the large diagonal matrices.\n\n**3. Condition Number Calculation:**\n- The condition numbers $\\kappa_2(V)$ and $\\kappa_2(SVD)$ are computed using `numpy.linalg.cond`, which internally uses the singular value decomposition as specified.\n\nBy executing this procedure for each test case, we can observe the dramatic impact of node choice and basis scaling on the numerical stability of the modal-nodal transformation.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import special\n\ndef solve():\n    \"\"\"\n    Computes the condition numbers for Vandermonde-like matrices based on Legendre polynomials\n    for various node sets and polynomial degrees as specified in the problem statement.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'p': 3, 'type': 'equispaced'},\n        {'p': 15, 'type': 'equispaced'},\n        {'p': 15, 'type': 'gauss-legendre'},\n        {'p': 1, 'type': 'gauss-lobatto'},\n        {'p': 25, 'type': 'gauss-lobatto'},\n    ]\n\n    results = []\n    for case in test_cases:\n        p = case['p']\n        node_type = case['type']\n        \n        # 1. Generate nodes and weights for the given p and node type.\n        if node_type == 'equispaced':\n            nodes = np.linspace(-1, 1, p + 1)\n            # Per problem, no quadrature weights are used for row scaling.\n            # This is equivalent to S=I, which is achieved with weights of 1.\n            weights = np.ones(p + 1)\n        elif node_type == 'gauss-legendre':\n            # Scipy's roots_legendre returns p+1 nodes and weights for a p-th degree polynomial space.\n            nodes, weights = special.roots_legendre(p + 1)\n        elif node_type == 'gauss-lobatto':\n            if p == 0:\n                 nodes = np.array([0.0])\n                 weights = np.array([2.0])\n            elif p==1:\n                 # Endpoints only for p=1\n                 nodes = np.array([-1.0, 1.0])\n                 # Weights from formula w_i = 2/(p(p+1)) for endpoints\n                 weights = np.array([1.0, 1.0])\n            else:\n                # Interior nodes are roots of P'_p(x), which are roots of Jacobi polynomial P_{p-1}^{(1,1)}(x)\n                interior_nodes, _ = special.roots_jacobi(p - 1, 1, 1)\n                nodes = np.concatenate(([-1.0], interior_nodes, [1.0]))\n                \n                # Weights from formula: w_i = 2 / (p*(p+1) * P_p(x_i)^2)\n                poly_vals_at_nodes = special.eval_legendre(p, nodes)\n                weights = 2 / (p * (p + 1) * poly_vals_at_nodes**2)\n        \n        # 2. Construct the Vandermonde matrix V, where V_ik = P_k(x_i).\n        V = np.zeros((p + 1, p + 1))\n        poly_degrees = np.arange(p + 1)\n        for k_idx, k in enumerate(poly_degrees):\n            V[:, k_idx] = special.eval_legendre(k, nodes)\n            \n        # 3. Compute the condition number of V using the 2-norm.\n        cond_V = np.linalg.cond(V, 2)\n        \n        # 4. Construct the scaled matrix SVD and compute its condition number.\n        # S is diagonal with S_ii = sqrt(w_i)\n        # D is diagonal with D_kk = sqrt((2k+1)/2)\n        \n        # The matrix SVD can be constructed efficiently using broadcasting.\n        S_diag_sqrt = np.sqrt(weights)\n        D_diag_sqrt = np.sqrt((2 * poly_degrees + 1) / 2)\n        \n        # SVD_matrix[i,k] = S_ii * V_ik * D_kk\n        SVD_matrix = S_diag_sqrt[:, np.newaxis] * V * D_diag_sqrt[np.newaxis, :]\n        \n        cond_SVD = np.linalg.cond(SVD_matrix, 2)\n        \n        results.append([cond_V, cond_SVD])\n\n    # 5. Format and print the final output as a single-line string.\n    # The required format is [[k(V)_1,k(SVD)_1],[k(V)_2,k(SVD)_2],...].\n    list_of_strs = []\n    for res_pair in results:\n        list_of_strs.append(f\"[{res_pair[0]},{res_pair[1]}]\")\n    final_str = f\"[{','.join(list_of_strs)}]\"\n    print(final_str)\n\nsolve()\n```", "id": "3400097"}]}