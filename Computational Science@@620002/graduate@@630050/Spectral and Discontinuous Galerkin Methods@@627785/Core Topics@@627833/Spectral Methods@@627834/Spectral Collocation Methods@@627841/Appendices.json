{"hands_on_practices": [{"introduction": "When solving nonlinear differential equations, we often encounter products of functions, such as $u^2$ or $uv$. A naive approach in a collocation method is to simply multiply the function values at the grid points. This exercise reveals the subtle but critical error, known as aliasing, that this approach introduces, where high-frequency information masquerades as low-frequency content. By working through a concrete example with Chebyshev polynomials, you will directly compare the aliased nodal product with the true orthogonal projection to build a solid intuition for this fundamental concept [@problem_id:3416558].", "problem": "Consider the Chebyshev polynomials of the first kind defined by $T_{n}(x) = \\cos(n \\arccos x)$ on the interval $[-1,1]$. Let the Chebyshev–Lobatto nodes be $x_{j} = \\cos\\left(\\frac{\\pi j}{N}\\right)$ for $j = 0,1,\\dots,N$, and define the interpolation operator $\\mathcal{I}_{N}$ as the unique polynomial of degree at most $N$ that interpolates a given function at these nodes. Let the weighted inner product be given by\n$$\\langle f,g\\rangle_{w} = \\int_{-1}^{1} f(x)\\,g(x)\\,\\frac{1}{\\sqrt{1-x^{2}}}\\,dx,$$\nwith the associated weighted $L^{2}$ norm $\\|f\\|_{w} = \\sqrt{\\langle f,f\\rangle_{w}}$. Denote by $\\mathcal{P}_{N}$ the orthogonal projection (with respect to $\\langle\\cdot,\\cdot\\rangle_{w}$) onto the space of polynomials of degree at most $N$.\n\nLet $u(x) = T_{6}(x)$ and $v(x) = T_{7}(x)$ on $[-1,1]$, and set $N=8$. Define $w(x)=u(x)v(x)$. Using only fundamental identities and definitions, do the following:\n- Derive an explicit Chebyshev basis representation for $w(x)$.\n- Determine the aliased nodal product $\\mathcal{I}_{8}(w)$ by analyzing the behavior of Chebyshev polynomials sampled on the Chebyshev–Lobatto grid $\\{x_{j}\\}_{j=0}^{8}$.\n- Determine the exact orthogonal projection $\\mathcal{P}_{8}(w)$.\n- Compute the weighted $L^{2}$ norm $\\|\\mathcal{I}_{8}(w) - \\mathcal{P}_{8}(w)\\|_{w}$.\n\nProvide your final answer as a single exact analytic expression. Do not round your answer.", "solution": "The problem requires the computation of the weighted $L^{2}$ norm of the difference between the interpolant and the orthogonal projection of a specific function $w(x)$. We will solve this by determining each required quantity in a step-by-step manner.\n\nFirst, we establish the explicit Chebyshev basis representation for the function $w(x)$. The function is defined as the product of $u(x) = T_{6}(x)$ and $v(x) = T_{7}(x)$, where $T_{n}(x)$ is the Chebyshev polynomial of the first kind of degree $n$.\n$$w(x) = u(x)v(x) = T_{6}(x)T_{7}(x)$$\nWe use the standard product-to-sum identity for Chebyshev polynomials, which states that for any non-negative integers $m$ and $n$:\n$$T_{m}(x)T_{n}(x) = \\frac{1}{2}\\left(T_{m+n}(x) + T_{|m-n|}(x)\\right)$$\nApplying this identity with $m=7$ and $n=6$, we find the expression for $w(x)$:\n$$w(x) = T_{7}(x)T_{6}(x) = \\frac{1}{2}\\left(T_{7+6}(x) + T_{7-6}(x)\\right) = \\frac{1}{2}T_{13}(x) + \\frac{1}{2}T_{1}(x)$$\nThis is the expansion of $w(x)$ in the Chebyshev basis. The degree of $w(x)$ is $13$.\n\nSecond, we determine the aliased nodal product $\\mathcal{I}_{8}(w)$. This is the unique polynomial of degree at most $N=8$ that interpolates $w(x)$ at the $N+1=9$ Chebyshev–Lobatto nodes, given by $x_{j} = \\cos\\left(\\frac{\\pi j}{N}\\right) = \\cos\\left(\\frac{\\pi j}{8}\\right)$ for $j = 0, 1, \\dots, 8$. The interpolation operator $\\mathcal{I}_{N}$ is linear.\n$$\\mathcal{I}_{8}(w) = \\mathcal{I}_{8}\\left(\\frac{1}{2}T_{13}(x) + \\frac{1}{2}T_{1}(x)\\right) = \\frac{1}{2}\\mathcal{I}_{8}(T_{13}) + \\frac{1}{2}\\mathcal{I}_{8}(T_{1})$$\nFor the term $T_{1}(x)$, its degree is $1$, which is less than or equal to $N=8$. A polynomial of degree at most $N$ is its own interpolant of degree at most $N$. Thus, $\\mathcal{I}_{8}(T_{1}) = T_{1}(x)$.\nFor the term $T_{13}(x)$, its degree $13$ is greater than $N=8$, so aliasing occurs. On the Chebyshev-Lobatto grid $\\{x_{j}\\}_{j=0}^{N}$, the values of $T_{k}(x)$ for $k$ in the range $N < k < 2N$ are identical to the values of $T_{2N-k}(x)$. For $k=13$ and $N=8$, we have $8 < 13 < 16$. The aliasing identity is:\n$$T_{13}(x_{j}) = T_{13}\\left(\\cos\\left(\\frac{\\pi j}{8}\\right)\\right) = \\cos\\left(\\frac{13\\pi j}{8}\\right) = \\cos\\left(\\frac{(16-3)\\pi j}{8}\\right) = \\cos\\left(2\\pi j - \\frac{3\\pi j}{8}\\right) = \\cos\\left(\\frac{3\\pi j}{8}\\right) = T_{3}(x_{j})$$\nThis holds for all $j=0, 1, \\dots, 8$. The unique polynomial of degree at most $8$ that interpolates the nodal values $\\{T_{13}(x_j)\\}_{j=0}^8$ is therefore $T_{3}(x)$, since its degree is $3 \\leq 8$. So, $\\mathcal{I}_{8}(T_{13}) = T_{3}(x)$.\nCombining these results, the aliased product is:\n$$\\mathcal{I}_{8}(w)(x) = \\frac{1}{2}T_{3}(x) + \\frac{1}{2}T_{1}(x)$$\n\nThird, we determine the exact orthogonal projection $\\mathcal{P}_{8}(w)$. This is the best approximation of $w(x)$ in the weighted $L^{2}$ norm from the space of polynomials of degree at most $N=8$, which we denote $\\mathbb{P}_{8}$. A function $f(x)$ with the Chebyshev series expansion $f(x) = \\sum_{k=0}^{\\infty} a_{k}T_{k}(x)$ has its orthogonal projection onto $\\mathbb{P}_{N}$ given by the truncated series $\\mathcal{P}_{N}(f)(x) = \\sum_{k=0}^{N} a_{k}T_{k}(x)$.\nThe Chebyshev expansion for $w(x)$ is $w(x) = \\frac{1}{2}T_{1}(x) + \\frac{1}{2}T_{13}(x)$. Truncating this series at degree $N=8$ means we keep only the terms with index $k \\le 8$.\n$$\\mathcal{P}_{8}(w)(x) = \\frac{1}{2}T_{1}(x)$$\nThe term involving $T_{13}(x)$ is omitted because $13 > 8$. This is a consequence of the orthogonality of Chebyshev polynomials with respect to the inner product $\\langle\\cdot,\\cdot\\rangle_{w}$, which implies $\\langle T_{13}, T_{k} \\rangle_{w} = 0$ for all $k \\leq 12$, and specifically for $k \\leq 8$.\n\nFourth, we compute the norm of the difference $\\|\\mathcal{I}_{8}(w) - \\mathcal{P}_{8}(w)\\|_{w}$. The difference between the interpolant and the projection is:\n$$\\mathcal{I}_{8}(w)(x) - \\mathcal{P}_{8}(w)(x) = \\left(\\frac{1}{2}T_{3}(x) + \\frac{1}{2}T_{1}(x)\\right) - \\frac{1}{2}T_{1}(x) = \\frac{1}{2}T_{3}(x)$$\nThe required norm is $\\|\\frac{1}{2}T_{3}(x)\\|_{w}$. Using the properties of norms, this is $\\frac{1}{2}\\|T_{3}(x)\\|_{w}$. The squared norm $\\|T_{n}\\|_{w}^{2}$ is defined by the inner product $\\langle T_{n}, T_{n} \\rangle_{w}$. We evaluate the integral using the substitution $x=\\cos(\\theta)$:\n$$ \\langle T_{n}, T_{n} \\rangle_{w} = \\int_{-1}^{1} T_{n}(x)^{2}\\,\\frac{1}{\\sqrt{1-x^{2}}}\\,dx = \\int_{\\pi}^{0} \\cos^{2}(n\\theta) \\frac{1}{\\sin(\\theta)} (-\\sin(\\theta)d\\theta) = \\int_{0}^{\\pi} \\cos^{2}(n\\theta) d\\theta$$\nFor $n > 0$, this integral evaluates to:\n$$ \\int_{0}^{\\pi} \\frac{1+\\cos(2n\\theta)}{2} d\\theta = \\left[\\frac{\\theta}{2} + \\frac{\\sin(2n\\theta)}{4n}\\right]_{0}^{\\pi} = \\frac{\\pi}{2} $$\nFor $n=3$, we have $\\|T_{3}\\|_{w}^{2} = \\langle T_{3}, T_{3} \\rangle_{w} = \\frac{\\pi}{2}$.\nThus, the norm is $\\|T_{3}\\|_{w} = \\sqrt{\\frac{\\pi}{2}}$.\nFinally, the norm of the difference is:\n$$\\|\\mathcal{I}_{8}(w) - \\mathcal{P}_{8}(w)\\|_{w} = \\frac{1}{2}\\|T_{3}\\|_{w} = \\frac{1}{2}\\sqrt{\\frac{\\pi}{2}} = \\frac{\\sqrt{\\pi}}{2\\sqrt{2}} = \\frac{\\sqrt{2\\pi}}{4}$$", "answer": "$$\\boxed{\\frac{\\sqrt{2\\pi}}{4}}$$", "id": "3416558"}, {"introduction": "Moving from concepts to practice, we now tackle the construction of discrete operators for solving differential equations with variable coefficients, such as $-(a(x) u_x)_x = f(x)$. This problem contrasts two fundamental discretization strategies: the \"strong form,\" derived from direct differentiation, and the \"weak form,\" which is based on an integration-by-parts formulation. Through a hands-on coding exercise [@problem_id:3416617], you will discover why the weak form is often superior, as it naturally preserves the critical matrix properties of symmetry and positive definiteness, leading to more robust and efficient numerical solvers.", "problem": "Consider the one-dimensional second-order elliptic operator in conservative form on the interval $[-1,1]$ with homogeneous Dirichlet boundary conditions, defined by the differential equation\n$$\n-(a(x)\\, u_x)_x = f(x), \\quad x \\in [-1,1], \\quad u(-1)=u(1)=0,\n$$\nwhere $a(x)$ is a strictly positive function on $[-1,1]$ and $u(x)$ is the unknown solution. In spectral collocation using Legendre–Gauss–Lobatto (LGL) points, let $N$ denote the polynomial degree of the global interpolant, $N+1$ the number of LGL nodes, $x_j$ the LGL nodes, $w_j$ the corresponding LGL quadrature weights, and $D$ the LGL differentiation matrix acting on nodal values. The discrete conservative weak form stiffness matrix that respects symmetry under the discrete $L^2$ inner product is\n$$\nK = D_{AI}^\\top W A D_{AI},\n$$\nwhere $A=\\mathrm{diag}(a(x_j))$, $W=\\mathrm{diag}(w_j)$, and $D_{AI}$ denotes the columns of $D$ corresponding to the interior degrees of freedom (excluding the endpoints to enforce homogeneous Dirichlet boundary conditions). The strong-form collocation matrix obtained by differentiating the nodal product $(a u_x)$ is\n$$\nL_c = -\\left[ D\\, A\\, D \\right]_{II},\n$$\nthe interior-interior submatrix of $-D A D$, which enforces the operator at the interior nodes.\n\nStarting from the following fundamental bases:\n- The definition of Lagrange interpolation at LGL points and its exactness properties for polynomials.\n- The property that LGL quadrature with $N+1$ nodes integrates any polynomial of degree up to $2N-1$ exactly.\n- The definition of the Legendre polynomials and their role in constructing LGL nodes.\n- The standard discrete weak form derived from integration by parts, yielding a symmetric positive definite bilinear form when $a(x)>0$.\n\nYour tasks are:\n- Derive, from first principles, the required exactness of the quadrature integrand so that the discrete weak-form collocation stiffness matrix $K$ coincides with the exact Galerkin stiffness matrix and is symmetric positive definite (SPD). Express this exactness as a condition on the polynomial degree of $a(x)$ relative to $N$.\n- Implement a program that constructs the LGL nodes, weights, and differentiation matrix for a given $N$, builds both $K$ and $L_c$ for specified $a(x)$, and checks for symmetry and positive definiteness of each matrix under homogeneous Dirichlet boundary conditions by removing the boundary degrees of freedom.\n- Identify and test failure cases when $a(x)$ is under-resolved by the chosen polynomial degree $N$ in the strong-form collocation $L_c$. Use radian units for any trigonometric function such as $\\cos$.\n\nUse the following test suite of parameter sets $(N, a(x), p)$, where $p$ is the polynomial degree of $a(x)$ when applicable, otherwise set to a special marker indicating nonpolynomial:\n- Case $1$: $N=8$, $a(x)=1.2 + x$, $p=1$.\n- Case $2$: $N=8$, $a(x)=1 + x^2$, $p=2$.\n- Case $3$: $N=12$, $a(x)=1 + 0.5\\cos(10 x)$ (use radians), $p$ is nonpolynomial.\n- Case $4$: $N=8$, $a(x)=1 + 0.9\\cos(20 x)$ (use radians), $p$ is nonpolynomial.\n\nFor each case, your program must compute and return a list of five values:\n- A boolean indicating whether $K$ is symmetric.\n- A boolean indicating whether $K$ is symmetric positive definite (SPD).\n- A boolean indicating whether $L_c$ is symmetric.\n- A boolean indicating whether $L_c$ is symmetric positive definite (SPD).\n- A boolean indicating whether the quadrature exactness condition derived for $K$ is satisfied, i.e., whether the integrand’s degree is at most $2N-1$ (for nonpolynomial $a(x)$, this must be returned as the boolean value for “not satisfied”).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry corresponds to one test case and is itself a list of the five boolean values in the same order as described above. For example, an output line with four test cases in the specified order should look like\n$$\n[[b_{11},b_{12},b_{13},b_{14},b_{15}],[b_{21},b_{22},b_{23},b_{24},b_{25}],[b_{31},b_{32},b_{33},b_{34},b_{35}],[b_{41},b_{42},b_{43},b_{44},b_{45}]]\n$$\nwith each $b_{ij}$ being either the literal `True` or `False`.", "solution": "The problem statement is first validated for scientific soundness, self-consistency, and objectivity.\n\n### Step 1: Extract Givens\n- **Differential Equation**: $-(a(x)\\, u_x)_x = f(x)$ for $x \\in [-1,1]$.\n- **Boundary Conditions**: Homogeneous Dirichlet, $u(-1)=u(1)=0$.\n- **Coefficient Function**: $a(x)$ is a strictly positive function on $[-1,1]$.\n- **Discretization**: Spectral collocation using Legendre–Gauss–Lobatto (LGL) points.\n- **Parameters**:\n    - $N$: Polynomial degree of the global interpolant.\n    - $N+1$: Number of LGL nodes.\n    - $x_j$: LGL nodes for $j=0, \\dots, N$.\n    - $w_j$: LGL quadrature weights for $j=0, \\dots, N$.\n    - $D$: $(N+1) \\times (N+1)$ LGL differentiation matrix.\n- **Matrix Definitions**:\n    - **Weak Form Stiffness Matrix**: $K = D_{AI}^\\top W A D_{AI}$.\n        - $A = \\mathrm{diag}(a(x_j))$.\n        - $W = \\mathrm{diag}(w_j)$.\n        - $D_{AI}$: Columns of $D$ corresponding to interior nodes (indices $1, \\dots, N-1$).\n    - **Strong Form Collocation Matrix**: $L_c = -\\left[ D\\, A\\, D \\right]_{II}$.\n        - $II$ denotes the submatrix corresponding to interior-interior indices.\n- **Fundamental Principles**: Lagrange interpolation, LGL quadrature exactness (for polynomials of degree up to $2N-1$), properties of Legendre polynomials, and standard weak form derivation via integration by parts.\n- **Test Cases**:\n    1. $N=8$, $a(x)=1.2 + x$, $p=1$.\n    2. $N=8$, $a(x)=1 + x^2$, $p=2$.\n    3. $N=12$, $a(x)=1 + 0.5\\cos(10 x)$, $p$ is nonpolynomial.\n    4. $N=8$, $a(x)=1 + 0.9\\cos(20 x)$, $p$ is nonpolynomial.\n- **Required Output**: For each test case, a list of five booleans: $[is\\_K\\_symmetric, is\\_K\\_spd, is\\_Lc\\_symmetric, is\\_Lc\\_spd, is\\_quadrature\\_exactness\\_satisfied]$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded in the well-established field of numerical analysis, specifically spectral methods for differential equations. The definitions of the operators, matrices ($K$ and $L_c$), and LGL discretization are standard and correct. The tasks—derivation of a condition and numerical verification—are objective and well-posed. The provided test cases use functions $a(x)$ that are strictly positive on $[-1,1]$, ensuring the mathematical and physical well-posedness of the underlying continuous problem. The parameters are complete and consistent. For these reasons, the problem is deemed valid.\n\n### Step 3: Verdict and Action\nThe problem is valid. A full solution will be provided.\n\n### Solution and Derivation\n\n#### Part 1: Derivation of the Quadrature Exactness Condition for $K$\n\nThe continuous weak form of the differential equation is obtained by multiplying by a test function $v(x)$ from a suitable space (here, $H_0^1(-1,1)$) and integrating over the domain $[-1,1]$.\n$$ \\int_{-1}^{1} -(a(x) u_x(x))_x v(x) \\, dx = \\int_{-1}^{1} f(x) v(x) \\, dx $$\nIntegration by parts on the left-hand side yields:\n$$ \\left[-a(x) u_x(x) v(x)\\right]_{-1}^{1} + \\int_{-1}^{1} a(x) u_x(x) v_x(x) \\, dx = \\int_{-1}^{1} f(x) v(x) \\, dx $$\nGiven the homogeneous Dirichlet boundary conditions for the solution space ($u(-1)=u(1)=0$, and we choose test functions $v$ such that $v(-1)=v(1)=0$), the boundary term vanishes. This gives the bilinear form for the Galerkin method:\n$$ B(u, v) = \\int_{-1}^{1} a(x) u_x(x) v_x(x) \\, dx $$\nThe exact Galerkin stiffness matrix entries are $K_{ij}^{\\text{Galerkin}} = B(\\phi_j, \\phi_i)$, where $\\{\\phi_i\\}$ is a set of basis functions. In the collocation context, we use Lagrange polynomials $\\ell_j(x)$ as the basis. Due to the homogeneous boundary conditions, we only consider basis functions corresponding to interior nodes, i.e., $i, j \\in \\{1, \\dots, N-1\\}$.\n$$ K_{ij}^{\\text{Galerkin}} = \\int_{-1}^{1} a(x) \\ell'_j(x) \\ell'_i(x) \\, dx $$\nThe discrete weak-form stiffness matrix $K = D_{AI}^\\top W A D_{AI}$ arises from approximating the integral $B(u,v)$ using LGL quadrature. The quadrature approximation of $B(u,v)$ is:\n$$ B(u,v) \\approx \\sum_{k=0}^{N} w_k a(x_k) u_x(x_k) v_x(x_k) = (\\mathbf{u}_x)^\\top W A \\mathbf{v}_x $$\nwhere $\\mathbf{u}_x$ and $\\mathbf{v}_x$ are vectors of the derivative values at all LGL nodes. These derivatives are obtained from the interior nodal values $\\mathbf{u}_I$ and $\\mathbf{v}_I$ via the differentiation matrix block $D_{AI}$: $\\mathbf{u}_x = D_{AI} \\mathbf{u}_I$ and $\\mathbf{v}_x = D_{AI} \\mathbf{v}_I$. Substituting these into the quadrature sum gives the quadratic form corresponding to the matrix $K$:\n$$ \\mathbf{v}_I^\\top (D_{AI}^\\top W A D_{AI}) \\mathbf{u}_I = \\mathbf{v}_I^\\top K \\mathbf{u}_I $$\nThe discrete matrix $K$ coincides with the exact Galerkin matrix $K^{\\text{Galerkin}}$ if and only if the LGL quadrature rule is exact for the integrand $I(x) = a(x) \\ell'_j(x) \\ell'_i(x)$.\nThe Lagrange basis polynomials $\\ell_j(x)$ associated with $N+1$ LGL nodes are of degree $N$. Their derivatives, $\\ell'_j(x)$, are polynomials of degree $N-1$. The product $\\ell'_j(x) \\ell'_i(x)$ is therefore a polynomial of degree at most $(N-1) + (N-1) = 2N-2$.\nLet $p$ be the polynomial degree of the coefficient function $a(x)$. The total degree of the integrand is $\\deg(I(x)) = p + 2N-2$.\nLGL quadrature with $N+1$ nodes is exact for any polynomial of degree up to $2N-1$. For the quadrature to be exact, we must have:\n$$ \\deg(I(x)) \\le 2N-1 $$\n$$ p + 2N-2 \\le 2N-1 $$\n$$ p \\le 1 $$\nThus, the discrete weak-form matrix $K$ is identical to the exact Galerkin matrix if and only if $a(x)$ is a polynomial of degree at most $1$.\n\n#### Part 2: Properties of $K$ and $L_c$\n\n**Symmetry and Positive Definiteness of $K$**:\nThe matrix $K = D_{AI}^\\top W A D_{AI}$ is always symmetric. The matrices $W$ and $A$ are diagonal and thus symmetric.\n$$ K^\\top = (D_{AI}^\\top W A D_{AI})^\\top = D_{AI}^\\top A^\\top W^\\top (D_{AI}^\\top)^\\top = D_{AI}^\\top A W D_{AI} $$\nSince diagonal matrices commute, $AW=WA$, so $K^\\top = D_{AI}^\\top W A D_{AI} = K$.\nTo check for positive definiteness, consider the quadratic form for any non-zero vector $\\mathbf{v} \\in \\mathbb{R}^{N-1}$:\n$$ \\mathbf{v}^\\top K \\mathbf{v} = \\mathbf{v}^\\top D_{AI}^\\top W A D_{AI} \\mathbf{v} = (D_{AI}\\mathbf{v})^\\top W A (D_{AI}\\mathbf{v}) $$\nLet $\\mathbf{y} = D_{AI}\\mathbf{v}$. This is the vector of derivatives at all nodes of the polynomial that has values $\\mathbf{v}$ at interior nodes and zero at the boundaries. The quadratic form is $\\sum_{j=0}^{N} w_j a(x_j) y_j^2$. Since LGL weights $w_j$ are positive and $a(x)$ is strictly positive, all $a(x_j)>0$. The sum is positive unless all $y_j=0$. If $\\mathbf{y}=0$, the derivative polynomial is zero at all $N+1$ nodes. Since the derivative is of degree $N-1$, it must be identically zero. This implies the polynomial itself is a constant. As it is zero at the boundaries, it must be the zero polynomial. This means its interior nodal values $\\mathbf{v}$ must be zero. Therefore, for $\\mathbf{v} \\neq 0$, $\\mathbf{v}^\\top K \\mathbf{v} > 0$.\nConclusion: $K$ is symmetric positive definite (SPD) for any strictly positive coefficient function $a(x)$, independent of the quadrature exactness condition. The condition $p \\le 1$ ensures equivalence to the *continuous* Galerkin formulation, not the SPD property of the *discrete* system.\n\n**Symmetry and Positive Definiteness of $L_c$**:\nThe strong-form matrix is $L_c = -[DAD]_{II}$. In general, the full LGL differentiation matrix $D$ is not symmetric. The product $DAD$ is therefore not expected to be symmetric, nor is its submatrix $L_c$. A matrix must be symmetric to be classified as symmetric positive definite. Thus, we expect $L_c$ to be neither symmetric nor SPD in general. Non-symmetry is a known drawback of the strong-form collocation method when not constructed carefully. The failure of symmetry for non-constant $a(x)$ is a key distinction from the weak-form matrix $K$. Any under-resolution of $a(x)$, as in Case 4, will lead to a poor approximation of the operator, but the fundamental lack of symmetry is present even for well-resolved, non-constant $a(x)$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import legendre\n\ndef get_lgl(N):\n    \"\"\"\n    Computes the Legendre-Gauss-Lobatto (LGL) nodes, weights, and \n    differentiation matrix for a given polynomial degree N.\n\n    Args:\n        N (int): The polynomial degree.\n\n    Returns:\n        tuple: A tuple containing:\n            - np.ndarray: The LGL nodes (x).\n            - np.ndarray: The LGL weights (w).\n            - np.ndarray: The LGL differentiation matrix (D).\n    \"\"\"\n    if N < 1:\n        raise ValueError(\"N must be at least 1.\")\n    \n    # N+1 points, degree N polynomial\n    # Interior nodes are roots of P_N'(x)\n    PN = legendre(N)\n    PN_deriv = PN.deriv(1)\n    # The .roots method on a scipy orthopoly1d object finds the roots.\n    interior_nodes = np.sort(PN_deriv.roots)\n\n    x = np.concatenate(([-1.0], interior_nodes, [1.0]))\n    \n    # Weights formula: w_j = 2 / (N(N+1) [P_N(x_j)]^2)\n    PN_vals_at_nodes = PN(x)\n    w = 2.0 / (N * (N + 1) * PN_vals_at_nodes**2)\n    \n    # Differentiation matrix D formula\n    N_plus_1 = N + 1\n    D = np.zeros((N_plus_1, N_plus_1))\n\n    # Off-diagonal elements: D_ij = P_N(x_i) / (P_N(x_j) * (x_i - x_j)) for i != j\n    for i in range(N_plus_1):\n        for j in range(N_plus_1):\n            if i != j:\n                D[i, j] = PN_vals_at_nodes[i] / (PN_vals_at_nodes[j] * (x[i] - x[j]))\n    \n    # Diagonal elements\n    D[0, 0] = -N * (N + 1) / 4.0\n    D[N, N] = N * (N + 1) / 4.0\n    for i in range(1, N):\n        D[i, i] = x[i] / (1.0 - x[i]**2)\n        \n    return x, w, D\n\ndef analyze_matrices(N, a_func, p):\n    \"\"\"\n    Constructs and analyzes matrices K and Lc for a given test case.\n\n    Args:\n        N (int): The polynomial degree.\n        a_func (callable): The function a(x).\n        p (int or str): The polynomial degree of a(x) or a nonpolynomial marker.\n\n    Returns:\n        list: A list of five boolean values:\n              [is_K_symmetric, is_K_spd, is_Lc_symmetric, is_Lc_spd, \n               is_quad_exactness_satisfied]\n    \"\"\"\n    x, w, D = get_lgl(N)\n    \n    a_vals = a_func(x)\n    if not np.all(a_vals > 0):\n        # This check is for robustness; problem statement guarantees a(x)>0\n        raise ValueError(\"a(x) must be strictly positive on [-1, 1].\")\n\n    A = np.diag(a_vals)\n    W = np.diag(w)\n    \n    # Interior indices are 1, ..., N-1. In Python slicing, this is 1:N\n    interior_slice = slice(1, N)\n    \n    # K = D_AI' * W * A * D_AI\n    # D_AI is the block of D with all rows and interior columns.\n    D_AI = D[:, interior_slice]\n    K = D_AI.T @ W @ A @ D_AI\n    \n    # Lc = -[D*A*D]_II\n    # [DAD]_II is the interior-interior block of the matrix D*A*D.\n    DAD = D @ A @ D\n    Lc = -DAD[interior_slice, interior_slice]\n    \n    tol = 1e-12\n    \n    # 1. Check if K is symmetric\n    is_K_symmetric = np.allclose(K, K.T, atol=tol)\n    \n    # 2. Check if K is SPD\n    is_K_spd = False\n    if is_K_symmetric:\n        try:\n            eigvals = np.linalg.eigvalsh(K)\n            is_K_spd = np.all(eigvals > tol)\n        except np.linalg.LinAlgError:\n            is_K_spd = False\n            \n    # 3. Check if Lc is symmetric\n    is_Lc_symmetric = np.allclose(Lc, Lc.T, atol=tol)\n    \n    # 4. Check if Lc is SPD (requires symmetry)\n    is_Lc_spd = False\n    if is_Lc_symmetric:\n        try:\n            eigvals = np.linalg.eigvalsh(Lc)\n            is_Lc_spd = np.all(eigvals > tol)\n        except np.linalg.LinAlgError:\n            is_Lc_spd = False\n\n    # 5. Check if quadrature exactness condition (p <= 1) is satisfied\n    is_quad_exactness_satisfied = (isinstance(p, int) and p <= 1)\n            \n    return [is_K_symmetric, is_K_spd, is_Lc_symmetric, is_Lc_spd, is_quad_exactness_satisfied]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1: N=8, a(x)=1.2 + x, p=1\n        (8, lambda x: 1.2 + x, 1),\n        # Case 2: N=8, a(x)=1 + x^2, p=2\n        (8, lambda x: 1.0 + x**2, 2),\n        # Case 3: N=12, a(x)=1 + 0.5cos(10x), p=nonpolynomial\n        (12, lambda x: 1.0 + 0.5 * np.cos(10 * x), \"nonpolynomial\"),\n        # Case 4: N=8, a(x)=1 + 0.9cos(20x), p=nonpolynomial\n        (8, lambda x: 1.0 + 0.9 * np.cos(20 * x), \"nonpolynomial\"),\n    ]\n\n    results = []\n    for N, a_func, p in test_cases:\n        case_results = analyze_matrices(N, a_func, p)\n        results.append(case_results)\n\n    # Format the output as specified\n    # Using str() on Python booleans gives 'True' and 'False' literals,\n    # which is what the problem asks for.\n    result_str = ','.join([str(res) for res in results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3416617"}, {"introduction": "Spectral methods are celebrated for their exceptional accuracy on smooth problems, but their performance degrades in the presence of discontinuities or \"shocks.\" This advanced practice introduces a powerful strategy for adapting spectral methods to such challenges. You will implement a \"shock sensor\" that diagnoses the smoothness of a solution by examining the decay rate of its energy across Legendre polynomial modes [@problem_id:3416549]. This sensor can then trigger a localized artificial viscosity, a key technique that enables the stable and accurate simulation of complex phenomena like shock waves in fluid dynamics.", "problem": "Implement a one-dimensional shock sensor based on modal decay using a discrete Legendre transform constructed from Legendre–Gauss–Lobatto (LGL) nodes, and trigger an element-local artificial viscosity based on this indicator. You must derive, implement, and test the following in a single program.\n\nStart from the following fundamental definitions and facts:\n- Let $\\{P_k(x)\\}_{k \\ge 0}$ denote the Legendre polynomials on $[-1,1]$, orthogonal under the standard inner product, i.e., $\\int_{-1}^{1} P_k(x) P_m(x) \\, dx = \\dfrac{2}{2k+1} \\delta_{km}$, where $\\delta_{km}$ is the Kronecker delta.\n- For a fixed polynomial degree $N$, the Legendre–Gauss–Lobatto (LGL) nodes $\\{x_i\\}_{i=0}^{N}$ on $[-1,1]$ are the union of the endpoints and the $N-1$ interior roots of $P_N'(x)$, and there exist positive quadrature weights $\\{w_i\\}_{i=0}^{N}$ such that the LGL quadrature is exact for polynomials up to degree $2N-1$:\n$$\\int_{-1}^{1} q(x) \\, dx = \\sum_{i=0}^{N} w_i \\, q(x_i), \\quad \\text{for all polynomials } q \\text{ with } \\deg(q) \\le 2N-1.$$\n- For a function $u(x)$ sampled at the LGL nodes $\\{x_i\\}_{i=0}^{N}$ with values $\\{u_i\\}_{i=0}^{N}$, define a discrete inner product\n$$\\langle f, g \\rangle_w = \\sum_{i=0}^{N} w_i \\, f(x_i) \\, g(x_i).$$\nThe discrete Legendre coefficient $a_k$ is obtained by the quadrature approximation to the continuous projection:\n$$a_k \\approx \\frac{2k+1}{2} \\sum_{i=0}^{N} w_i \\, u_i \\, P_k(x_i), \\quad k = 0,1,\\dots,N.$$\n\nDefine the modal energy $E_k = a_k^2$ and a high-mode energy ratio\n$$R = \\frac{\\sum_{k=N-r+1}^{N} E_k}{\\sum_{k=0}^{N} E_k},$$\nwhere $r$ is a small positive integer with $1 \\le r \\le N$. To avoid division by zero in degenerate cases, use a regularized ratio\n$$R_{\\mathrm{reg}} = \\frac{\\sum_{k=N-r+1}^{N} E_k + \\varepsilon}{\\sum_{k=0}^{N} E_k + \\varepsilon},$$\nwith a small regularization $\\varepsilon > 0$, and define the decay indicator\n$$S = \\log_{10} \\left( R_{\\mathrm{reg}} \\right).$$\n\nTrigger an element-local artificial viscosity $\\nu$ by a simple thresholded ramp based on $S$:\n- Given parameters $s_0$ (threshold), $\\Delta s$ (ramp width), and $\\nu_{\\max}$ (maximum viscosity), set\n$$\n\\nu =\n\\begin{cases}\n0, & S \\le s_0, \\\\\n\\nu_{\\max} \\, \\min\\left(1, \\dfrac{S - s_0}{\\Delta s}\\right), & S > s_0.\n\\end{cases}\n$$\nThis is localized because it is computed per element from the nodal samples on that element and applied only to that element.\n\nYour program must:\n- Construct LGL nodes and weights for each specified $N$.\n- Compute discrete Legendre coefficients $\\{a_k\\}_{k=0}^{N}$ from nodal samples $\\{u_i\\}_{i=0}^{N}$ using the discrete inner product with LGL weights.\n- Compute $S$ and then $\\nu$ using the definitions above with a fixed choice of $r$, $\\varepsilon$, $s_0$, $\\Delta s$, and $\\nu_{\\max}$ as specified below.\n- For validation of selectivity, apply the sensor to multiple test functions with different smoothness and steepness and report for each case a Boolean indicating whether viscosity was triggered and the corresponding viscosity value.\n\nAngle unit specification: whenever a trigonometric function such as $\\sin$ is used, angles are in radians.\n\nUse the following fixed parameters for the indicator and viscosity:\n- Polynomial order window $r = 3$ (use $r = \\min(3, N)$ to satisfy $r \\le N$ when needed).\n- Regularization $\\varepsilon = 10^{-30}$.\n- Threshold $s_0 = -2.25$.\n- Ramp width $\\Delta s = 0.75$.\n- Maximum viscosity $\\nu_{\\max} = 0.2$.\n\nTest suite:\n- Case A (smooth): $N = 21$, $u(x) = \\sin(5 x)$ with $x$ in radians.\n- Case B (discontinuous jump): $N = 21$, $u(x) = \\mathrm{sign}(x)$, with $\\mathrm{sign}(0) = 0$.\n- Case C (cusp): $N = 21$, $u(x) = |x|$.\n- Case D (low-order jump): $N = 7$, $u(x) = \\mathrm{sign}(x)$, with $\\mathrm{sign}(0) = 0$.\n- Case E (steep but continuous): $N = 21$, $u(x) = \\tanh(20 x)$.\n\nFor each case, compute the Boolean trigger $\\mathbf{1}_{\\{\\nu>0\\}}$ and the viscosity value $\\nu$. Report the viscosity value rounded to six decimal places.\n\nFinal output format:\n- Your program should produce a single line of output containing a flat, comma-separated list enclosed in square brackets, concatenating the results for all cases in the order A, B, C, D, E, where each case contributes two entries: first the Boolean, then the rounded viscosity float. For example, a valid output layout is\n$[b_A, \\nu_A, b_B, \\nu_B, b_C, \\nu_C, b_D, \\nu_D, b_E, \\nu_E]$,\nwhere $b_{\\cdot}$ is either `True` or `False`, and each $\\nu_{\\cdot}$ is a float rounded to six decimals.", "solution": "The user-provided problem statement is well-posed, scientifically grounded, and contains all necessary information for a unique solution. It specifies a clear and standard procedure from the field of numerical methods for partial differential equations, specifically a modal shock sensor for spectral methods. Therefore, the problem is deemed **valid**.\n\nThe task is to implement a shock sensor based on the decay rate of Legendre polynomial modal coefficients. This sensor is then used to trigger an artificial viscosity, a common technique for stabilizing numerical solutions of hyperbolic conservation laws in the presence of discontinuities or sharp gradients (shocks). The entire process is performed on a single one-dimensional element, represented by a set of nodal points on the reference interval $[-1, 1]$.\n\nThe implementation follows a sequence of well-defined mathematical and algorithmic steps:\n\n1.  **Legendre–Gauss–Lobatto (LGL) Quadrature Points and Weights**\n\n    For a given polynomial degree $N$, we must first establish the computational grid on the reference element $[-1, 1]$. The LGL grid is chosen, which consists of $N+1$ points $\\{x_i\\}_{i=0}^{N}$. These points are the roots of the polynomial $(1-x^2)P_N'(x)$, where $P_N(x)$ is the Legendre polynomial of degree $N$. This means the nodes are the endpoints $x_0 = -1$ and $x_N = 1$, plus the $N-1$ interior roots of the derivative $P_N'(x)$.\n\n    The corresponding quadrature weights $\\{w_i\\}_{i=0}^{N}$ are defined by the formula:\n    $$w_i = \\frac{2}{N(N+1) [P_N(x_i)]^2}$$\n    This quadrature rule is exact for all polynomials of degree up to $2N-1$. In the implementation, for a given $N$, the polynomial $P_N(x)$ is obtained using `scipy.special.legendre`, its derivative $P_N'(x)$ is computed, and the interior nodes are found by solving for its roots. The endpoints are then added. The weights are calculated using the above formula, where $P_N(x_i)$ is evaluated using `scipy.special.eval_legendre`.\n\n2.  **Discrete Legendre Transform**\n\n    Given a function $u(x)$ sampled at the LGL nodes, yielding values $\\{u_i = u(x_i)\\}_{i=0}^{N}$, its representation in the Legendre basis can be approximated. The expansion of $u(x)$ is $u(x) = \\sum_{k=0}^{\\infty} \\hat{u}_k P_k(x)$, where the continuous Legendre coefficients are given by the projection:\n    $$\\hat{u}_k = \\frac{\\int_{-1}^{1} u(x) P_k(x) \\, dx}{\\int_{-1}^{1} P_k(x)^2 \\, dx} = \\frac{2k+1}{2} \\int_{-1}^{1} u(x) P_k(x) \\, dx$$\n    The problem defines the discrete Legendre coefficients, denoted here as $a_k$, by replacing the integral with the LGL quadrature sum:\n    $$a_k = \\frac{2k+1}{2} \\sum_{i=0}^{N} w_i \\, u_i \\, P_k(x_i), \\quad k = 0, 1, \\dots, N$$\n    This is effectively a discrete Legendre transform. For each mode $k$ from $0$ to $N$, this formula is applied by sampling the values of $P_k(x)$ at the LGL nodes $\\{x_i\\}$.\n\n3.  **Modal Decay Indicator $S$**\n\n    The rate of decay of the modal coefficients $\\{a_k\\}$ provides information about the smoothness of the function $u(x)$. Smooth functions have coefficients that decay rapidly as $k$ increases, while functions with discontinuities or sharp features exhibit slow decay, meaning significant energy is present in high-frequency modes.\n\n    The modal energy is defined as $E_k = a_k^2$. The sensor quantifies the decay rate by computing the ratio of energy in the highest modes to the total energy. The regularized ratio $R_{\\mathrm{reg}}$ is used:\n    $$R_{\\mathrm{reg}} = \\frac{\\sum_{k=N-r+1}^{N} E_k + \\varepsilon}{\\sum_{k=0}^{N} E_k + \\varepsilon}$$\n    Here, $r$ defines a small window of the highest modes (e.g., $r=3$), and $\\varepsilon$ is a small regularization parameter (given as $10^{-30}$) to prevent division by zero if the function is identically zero.\n\n    The final indicator, $S$, is the base-10 logarithm of this ratio:\n    $$S = \\log_{10} (R_{\\mathrm{reg}})$$\n    - For a smooth function, the high-mode energy $\\sum_{k=N-r+1}^{N} E_k$ is very small, leading to a small $R_{\\mathrm{reg}}$ and a large-magnitude negative value for $S$.\n    - For a non-smooth function, the high-mode energy is significant, making $R_{\\mathrm{reg}}$ larger (closer to $1$) and $S$ less negative (closer to $0$).\n\n4.  **Artificial Viscosity Trigger $\\nu$**\n\n    The indicator $S$ is used to control the amount of artificial viscosity, $\\nu$, applied to the element. A simple thresholded ramp function is employed. Given a threshold $s_0$, a ramp width $\\Delta s$, and a maximum viscosity $\\nu_{\\max}$:\n    $$\n    \\nu =\n    \\begin{cases}\n    0, & S \\le s_0, \\\\\n    \\nu_{\\max} \\, \\min\\left(1, \\dfrac{S - s_0}{\\Delta s}\\right), & S > s_0.\n    \\end{cases}\n    $$\n    If the indicator $S$ is below the threshold $s_0$ (indicating a smooth solution), no viscosity is added ($\\nu=0$). If $S$ exceeds the threshold, viscosity is activated. It ramps up linearly from $0$ to $\\nu_{\\max}$ as $S$ increases from $s_0$ to $s_0 + \\Delta s$, and it is capped at $\\nu_{\\max}$ for $S \\ge s_0 + \\Delta s$. This localizes the viscosity to elements where smoothness is lost.\n\n5.  **Test Suite and Evaluation**\n\n    The algorithm is applied to a suite of test functions with varying smoothness properties to validate its selectivity:\n    - Case A: $u(x) = \\sin(5x)$ is a smooth ($C^{\\infty}$) function. Expected: $\\nu=0$.\n    - Case B: $u(x) = \\mathrm{sign}(x)$ has a jump discontinuity at $x=0$. Expected: $\\nu > 0$.\n    - Case C: $u(x) = |x|$ has a cusp (is $C^0$ but not $C^1$) at $x=0$. Expected: $\\nu > 0$.\n    - Case D: $u(x) = \\mathrm{sign}(x)$ with a lower polynomial degree $N$. The behavior is tested with coarser resolution. Expected: $\\nu > 0$.\n    - Case E: $u(x) = \\tanh(20x)$ is a steep but technically smooth ($C^{\\infty}$) function, mimicking a shock layer. Expected: $\\nu > 0$.\n\n    For each case, the Boolean indicator $\\mathbf{1}_{\\{\\nu>0\\}}$ and the calculated viscosity value $\\nu$ (rounded to six decimal places) are reported.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import legendre, eval_legendre\n\ndef solve():\n    \"\"\"\n    Implements and tests a one-dimensional shock sensor based on modal decay.\n    \"\"\"\n    \n    # Define fixed parameters from the problem statement.\n    r_fixed = 3\n    epsilon = 1e-30\n    s0 = -2.25\n    delta_s = 0.75\n    nu_max = 0.2\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (smooth)\n        (21, lambda x: np.sin(5 * x)),\n        # Case B (discontinuous jump)\n        (21, lambda x: np.sign(x)),\n        # Case C (cusp)\n        (21, lambda x: np.abs(x)),\n        # Case D (low-order jump)\n        (7, lambda x: np.sign(x)),\n        # Case E (steep but continuous)\n        (21, lambda x: np.tanh(20 * x)),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, u_func = case\n        \n        # 1. Construct LGL nodes and weights for degree N.\n        #    The N+1 LGL nodes on [-1, 1] are the endpoints {-1, 1} and the\n        #    N-1 roots of P_N'(x), where P_N is the Legendre polynomial.\n        if N == 0:\n            # Trivial case, not used in tests, but for completeness.\n            nodes = np.array([-1.0])\n            weights = np.array([2.0])\n        elif N == 1:\n            nodes = np.array([-1.0, 1.0])\n            weights = np.array([1.0, 1.0])\n        else:\n            poly_N = legendre(N)\n            poly_N_prime = poly_N.deriv()\n            interior_nodes = np.sort(poly_N_prime.roots.real) # Use real part for robustness\n            nodes = np.concatenate(([-1.0], interior_nodes, [1.0]))\n            \n            # The weights are given by w_i = 2 / (N*(N+1)*[P_N(x_i)]^2)\n            weights = 2.0 / (N * (N + 1) * (eval_legendre(N, nodes))**2)\n            \n        # 2. Compute discrete Legendre coefficients {a_k}.\n        #    a_k = (2k+1)/2 * sum(w_i * u(x_i) * P_k(x_i))\n        u_samples = u_func(nodes)\n        \n        a_k = np.zeros(N + 1)\n        for k in range(N + 1):\n            P_k_at_nodes = eval_legendre(k, nodes)\n            integral_approx = np.sum(weights * u_samples * P_k_at_nodes)\n            a_k[k] = (2 * k + 1) / 2.0 * integral_approx\n\n        # 3. Compute modal decay indicator S.\n        E_k = a_k**2\n        E_total = np.sum(E_k)\n        \n        # Use r = min(r_fixed, N) as specified for smaller N\n        r = min(r_fixed, N if N > 0 else 0)\n        \n        # Sum of high-mode energies (from k=N-r+1 to N)\n        if N > 0 and r > 0:\n            E_high = np.sum(E_k[N - r + 1:])\n        else:\n            E_high = 0.0\n            \n        # Regularized ratio and indicator S\n        R_reg = (E_high + epsilon) / (E_total + epsilon)\n        S = np.log10(R_reg)\n        \n        # 4. Compute artificial viscosity nu.\n        nu = 0.0\n        if S > s0:\n            nu = nu_max * min(1.0, (S - s0) / delta_s)\n        \n        # 5. Store results for this case.\n        triggered = nu > 0.0\n        nu_rounded = round(nu, 6)\n        \n        results.append(triggered)\n        results.append(nu_rounded)\n\n    # Final print statement in the exact required format.\n    # The map to str correctly handles Boolean and float values.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3416549"}]}