{"hands_on_practices": [{"introduction": "The three-term recurrence relation is the algebraic backbone of orthogonal polynomials. This first practice invites you to build this backbone for the canonical family of Legendre polynomials, not by looking up a formula, but by deriving it from first principles: the definition of orthogonality and the structure of the polynomials themselves. This foundational exercise [@problem_id:3423659] is crucial for demystifying the recurrence coefficients and appreciating the deep connection between the analytic property of orthogonality and the resulting algebraic structure.", "problem": "Consider the family of Legendre polynomials $\\{P_n(x)\\}_{n=0}^{\\infty}$ on the interval $[-1,1]$ with weight function $w(x)=1$. Use only fundamental definitions and properties of orthogonal polynomials to complete the following tasks.\n\n1. Starting from the Rodrigues formula $P_n(x)=\\dfrac{1}{2^n n!}\\dfrac{d^n}{dx^n}\\left(x^2-1\\right)^n$ and the fact that $\\{P_n\\}$ is orthogonal with respect to the inner product $\\langle f,g\\rangle=\\int_{-1}^{1}f(x)g(x)\\,dx$, derive the three-term recurrence relation that expresses $P_{n+1}(x)$ as a linear combination of $xP_n(x)$ and $P_{n-1}(x)$ for all integers $n\\geq 1$. Do not use any pre-established recurrence; your derivation must proceed from the Rodrigues formula and the stated orthogonality structure.\n\n2. Define the monic Legendre polynomials $\\{p_n(x)\\}_{n=0}^{\\infty}$ by $p_n(x)=\\kappa_n P_n(x)$, where $\\kappa_n$ is chosen so that the leading coefficient of $p_n(x)$ is $1$. Determine $\\kappa_n$ explicitly.\n\n3. Rewrite the recurrence from part 1 in the monic form $p_{n+1}(x)=\\left(x-\\alpha_n\\right)p_n(x)-\\beta_n p_{n-1}(x)$ and identify the recurrence coefficients $\\alpha_n$ and $\\beta_n$ as closed-form analytic expressions in $n$.\n\nExpress your final answer for the ordered pair $(\\alpha_n,\\beta_n)$ as a single row matrix. No numerical approximation is required.", "solution": "The problem is found to be valid as it is scientifically grounded, well-posed, and objective. It concerns fundamental properties of Legendre polynomials, and the derivation requested is a standard, albeit non-trivial, exercise in mathematical physics. All necessary information is provided.\n\nThe solution is presented in three parts as requested by the problem statement.\n\n**Part 1: Derivation of the three-term recurrence relation**\n\nLet $\\{P_n(x)\\}_{n=0}^{\\infty}$ be the family of Legendre polynomials, orthogonal on the interval $[-1, 1]$ with respect to the weight function $w(x)=1$. The inner product is $\\langle f, g \\rangle = \\int_{-1}^{1} f(x)g(x) \\, dx$.\nThe polynomial $xP_n(x)$ has degree $n+1$, so it can be expressed as a linear combination of the basis polynomials $\\{P_k(x)\\}$:\n$$xP_n(x) = \\sum_{k=0}^{n+1} c_k P_k(x)$$\nwhere the coefficients are given by $c_k = \\frac{\\langle xP_n, P_k \\rangle}{\\langle P_k, P_k \\rangle}$.\nBy the property of the inner product, $\\langle xP_n, P_k \\rangle = \\langle P_n, xP_k \\rangle$. Since $xP_k(x)$ is a polynomial of degree $k+1$, by the orthogonality of Legendre polynomials, this inner product is zero if $k+1  n$, i.e., $k  n-1$.\nThus, only the coefficients $c_{n+1}$, $c_n$, and $c_{n-1}$ can be non-zero. The expansion simplifies to:\n$$xP_n(x) = c_{n+1}P_{n+1}(x) + c_n P_n(x) + c_{n-1}P_{n-1}(x)$$\nThe coefficient $c_n$ is given by $c_n = \\frac{\\langle xP_n, P_n \\rangle}{\\langle P_n, P_n \\rangle}$. The integral in the numerator is $\\int_{-1}^{1} x [P_n(x)]^2 \\, dx$. The parity of a Legendre polynomial is $P_n(-x) = (-1)^n P_n(x)$. Therefore, $[P_n(-x)]^2 = ((-1)^n P_n(x))^2 = [P_n(x)]^2$, which means $[P_n(x)]^2$ is an even function for all $n$. The term $x$ is an odd function. The product $x[P_n(x)]^2$ is an odd function. The integral of an odd function over the symmetric interval $[-1, 1]$ is zero. Thus, $\\langle xP_n, P_n \\rangle = 0$, which implies $c_n=0$.\nThe recurrence becomes:\n$$xP_n(x) = c_{n+1} P_{n+1}(x) + c_{n-1} P_{n-1}(x)$$\nTo find the coefficients $c_{n+1}$ and $c_{n-1}$, we first determine the leading coefficient of $P_n(x)$ from the Rodrigues formula, $P_n(x) = \\frac{1}{2^n n!} \\frac{d^n}{dx^n} (x^2-1)^n$.\nThe term $(x^2-1)^n$ is a polynomial whose term of highest degree is $x^{2n}$.\nThe $n$-th derivative of $x^{2n}$ is $\\frac{d^n}{dx^n}x^{2n} = (2n)(2n-1)\\cdots(n+1)x^n = \\frac{(2n)!}{n!}x^n$.\nThe leading coefficient of $P_n(x)$, which we denote by $k_n$, is therefore:\n$$k_n = \\frac{1}{2^n n!} \\frac{(2n)!}{n!} = \\frac{(2n)!}{2^n (n!)^2}$$\nBy comparing the leading coefficients in the recurrence $xP_n(x) = c_{n+1}P_{n+1}(x) + c_{n-1}P_{n-1}(x)$:\n$k_n = c_{n+1} k_{n+1}$. This gives $c_{n+1} = \\frac{k_n}{k_{n+1}}$.\n$$ \\frac{k_n}{k_{n+1}} = \\frac{(2n)!}{2^n (n!)^2} \\left/ \\frac{(2(n+1))!}{2^{n+1} ((n+1)!)^2} \\right. = \\frac{(2n)!}{2^n (n!)^2} \\frac{2^{n+1} (n+1)^2 (n!)^2}{(2n+2)!} = \\frac{2(n+1)^2}{(2n+2)(2n+1)} = \\frac{n+1}{2n+1} $$\nSo, $c_{n+1} = \\frac{n+1}{2n+1}$.\n\nNext, we find $c_{n-1} = \\frac{\\langle xP_n, P_{n-1} \\rangle}{\\langle P_{n-1}, P_{n-1} \\rangle} = \\frac{\\langle P_n, xP_{n-1} \\rangle}{\\langle P_{n-1}, P_{n-1} \\rangle}$.\nThe polynomial $xP_{n-1}(x)$ is of degree $n$, and its leading coefficient is $k_{n-1}$. We can write $xP_{n-1}(x) = \\frac{k_{n-1}}{k_n}P_n(x) + (\\text{terms of degree }n)$.\nTherefore, $\\langle P_n, xP_{n-1} \\rangle = \\frac{k_{n-1}}{k_n} \\langle P_n, P_n \\rangle$.\nThe coefficient $c_{n-1}$ is then $c_{n-1} = \\frac{k_{n-1}}{k_n} \\frac{\\langle P_n, P_n \\rangle}{\\langle P_{n-1}, P_{n-1} \\rangle}$.\nTo proceed, we must derive the squared norm $\\langle P_n, P_n \\rangle = \\int_{-1}^{1} [P_n(x)]^2 \\, dx$.\n$\\langle P_n, P_n \\rangle = \\langle P_n, k_n x^n + \\dots \\rangle = k_n \\langle P_n, x^n \\rangle$, since $P_n$ is orthogonal to all polynomials of degree less than $n$.\nWe evaluate $\\langle P_n, x^n \\rangle = \\int_{-1}^1 x^n P_n(x) \\, dx$ using the Rodrigues formula and integration by parts $n$ times.\n$$ \\langle P_n, x^n \\rangle = \\frac{1}{2^n n!} \\int_{-1}^1 x^n \\left(\\frac{d^n}{dx^n} (x^2-1)^n\\right) dx $$\nEach integration by parts introduces a minus sign and reduces the order of the derivative on $(x^2-1)^n$, while differentiating $x^n$. The boundary terms vanish at each step because derivatives of $(x^2-1)^n$ up to order $n-1$ are zero at $x=\\pm 1$. After $n$ steps:\n$$ \\langle P_n, x^n \\rangle = \\frac{(-1)^n}{2^n n!} \\int_{-1}^1 \\left(\\frac{d^n}{dx^n} x^n\\right) (x^2-1)^n dx = \\frac{(-1)^n n!}{2^n n!} \\int_{-1}^1 (x^2-1)^n dx = \\frac{1}{2^n} \\int_{-1}^1 (1-x^2)^n dx $$\nThe integral is evaluated by substitution $x=\\sin\\theta$, $dx=\\cos\\theta d\\theta$:\n$$ \\int_{-1}^1 (1-x^2)^n dx = \\int_{-\\pi/2}^{\\pi/2} (\\cos^2\\theta)^n \\cos\\theta d\\theta = 2 \\int_0^{\\pi/2} \\cos^{2n+1}\\theta d\\theta $$\nThis is a standard Wallis integral, whose value is $2\\frac{(2n)!!}{(2n+1)!!} = 2 \\frac{2^n n!}{(2n+1)!!} = \\frac{2^{2n+1}(n!)^2}{(2n+1)!}$.\nSo, $\\langle P_n, x^n \\rangle = \\frac{1}{2^n} \\frac{2^{2n+1}(n!)^2}{(2n+1)!} = \\frac{2^{n+1}(n!)^2}{(2n+1)!}$.\nNow, we find the norm:\n$$ \\langle P_n, P_n \\rangle = k_n \\langle P_n, x^n \\rangle = \\frac{(2n)!}{2^n (n!)^2} \\frac{2^{n+1}(n!)^2}{(2n+1)!} = \\frac{2}{2n+1} $$\nUsing this, $\\frac{\\langle P_n, P_n \\rangle}{\\langle P_{n-1}, P_{n-1} \\rangle} = \\frac{2/(2n+1)}{2/(2(n-1)+1)} = \\frac{2n-1}{2n+1}$.\nThe ratio of leading coefficients $\\frac{k_{n-1}}{k_n}$ is $\\frac{n}{2n-1}$ (by replacing $n$ with $n-1$ in the expression for $k_n / k_{n-1} = 1 / (k_{n-1}/k_n)$ wait, in $k_{n-1} / k_n$, from $c_{n+1} = k_n/k_{n+1} = (n+1)/(2n+1)$, replace $n$ by $n-1$ to get $k_{n-1}/k_n=n/(2n-1)$). Specifically, $k_{n-1}/k_n = 1/(k_n/k_{n-1})$. $k_n/k_{n-1} = (2n-1)/n$. Therefore, $k_{n-1}/k_n=n/(2n-1)$ is correct.\nSubstituting into the expression for $c_{n-1}$:\n$$ c_{n-1} = \\frac{k_{n-1}}{k_n} \\frac{\\langle P_n, P_n \\rangle}{\\langle P_{n-1}, P_{n-1} \\rangle} = \\frac{n}{2n-1} \\frac{2n-1}{2n+1} = \\frac{n}{2n+1} $$\nThe recurrence relation is $xP_n(x) = \\frac{n+1}{2n+1} P_{n+1}(x) + \\frac{n}{2n+1} P_{n-1}(x)$.\nSolving for $P_{n+1}(x)$:\n$$ (n+1)P_{n+1}(x) = (2n+1)xP_n(x) - nP_{n-1}(x) $$\n$$ P_{n+1}(x) = \\frac{2n+1}{n+1}xP_n(x) - \\frac{n}{n+1}P_{n-1}(x) $$\nThis relation holds for all integers $n \\geq 1$.\n\n**Part 2: Determination of the monic scaling factor $\\kappa_n$**\n\nMonic polynomials $\\{p_n(x)\\}$ are defined by $p_n(x) = \\kappa_n P_n(x)$, where the leading coefficient of $p_n(x)$ is $1$. The leading coefficient of $p_n(x)$ is $\\kappa_n k_n$.\nSetting $\\kappa_n k_n = 1$ gives $\\kappa_n = \\frac{1}{k_n}$.\n$$ \\kappa_n = \\frac{2^n (n!)^2}{(2n)!} $$\n\n**Part 3: Monic recurrence relation and coefficients $\\alpha_n, \\beta_n$**\n\nWe rewrite the recurrence from Part 1 using $P_k(x) = \\frac{1}{\\kappa_k}p_k(x)$:\n$$ \\frac{1}{\\kappa_{n+1}}p_{n+1}(x) = \\frac{2n+1}{n+1}x \\frac{1}{\\kappa_n}p_n(x) - \\frac{n}{n+1}\\frac{1}{\\kappa_{n-1}}p_{n-1}(x) $$\nMultiplying by $\\kappa_{n+1}$ gives:\n$$ p_{n+1}(x) = \\frac{\\kappa_{n+1}}{\\kappa_n}\\frac{2n+1}{n+1}x p_n(x) - \\frac{\\kappa_{n+1}}{\\kappa_{n-1}}\\frac{n}{n+1}p_{n-1}(x) $$\nWe evaluate the coefficient of the $x p_n(x)$ term. We need the ratio $\\kappa_{n+1}/\\kappa_n$:\n$$ \\frac{\\kappa_{n+1}}{\\kappa_n} = \\frac{2^{n+1}((n+1)!)^2}{(2n+2)!} \\left/ \\frac{2^n (n!)^2}{(2n)!} \\right. = \\frac{2(n+1)^2}{(2n+2)(2n+1)} = \\frac{n+1}{2n+1} $$\nThe coefficient of $x p_n(x)$ is $\\frac{n+1}{2n+1} \\frac{2n+1}{n+1} = 1$.\nThe recurrence takes the form $p_{n+1}(x) = x p_n(x) - \\beta_n p_{n-1}(x)$.\nComparing this with the target form $p_{n+1}(x) = (x-\\alpha_n)p_n(x) - \\beta_n p_{n-1}(x)$, we immediately identify $\\alpha_n = 0$.\nThe coefficient $\\beta_n$ is given by:\n$$ \\beta_n = \\frac{\\kappa_{n+1}}{\\kappa_{n-1}}\\frac{n}{n+1} $$\nWe compute the ratio $\\kappa_{n+1}/\\kappa_{n-1}$:\n$$ \\frac{\\kappa_{n+1}}{\\kappa_{n-1}} = \\frac{2^{n+1}((n+1)!)^2}{(2n+2)!} \\left/ \\frac{2^{n-1}((n-1)!)^2}{(2n-2)!} \\right. = \\frac{2^2 (n+1)^2 n^2}{(2n+2)(2n+1)(2n)(2n-1)} = \\frac{4n^2(n+1)^2}{4n(n+1)(2n+1)(2n-1)} = \\frac{n(n+1)}{(2n+1)(2n-1)} $$\nSubstituting this into the expression for $\\beta_n$:\n$$ \\beta_n = \\frac{n(n+1)}{(2n+1)(2n-1)} \\frac{n}{n+1} = \\frac{n^2}{(2n+1)(2n-1)} = \\frac{n^2}{4n^2-1} $$\nThis expression for $\\beta_n$ is valid for $n \\geq 1$.\nThe recurrence coefficients for the monic Legendre polynomials are $\\alpha_n=0$ and $\\beta_n = \\frac{n^2}{4n^2-1}$.", "answer": "$$ \\boxed{ \\begin{pmatrix} 0  \\frac{n^2}{4n^2-1} \\end{pmatrix} } $$", "id": "3423659"}, {"introduction": "Beyond generating the polynomials themselves, the recurrence relation endows the entire orthonormal system with a rich structure that can be exploited for algorithmic efficiency. This exercise [@problem_id:3423649] explores a powerful application within the context of $p$-adaptive discontinuous Galerkin (DG) methods. You will derive an elegant and highly efficient update formula for quadrature weights, demonstrating how the theoretical properties of the polynomial basis can be leveraged to avoid redundant computations and design faster, more responsive adaptive schemes.", "problem": "Consider a single reference element with coordinate $x \\in [-1,1]$ and a strictly positive weight function $\\rho(x)$ defining the inner product $(f,g)_{\\rho} = \\int_{-1}^{1} f(x) g(x) \\rho(x)\\,dx$. Let $\\{\\phi_{n}\\}_{n \\ge 0}$ be the family of orthonormal polynomials with respect to $\\rho(x)$, i.e., $(\\phi_{m},\\phi_{n})_{\\rho} = \\delta_{mn}$, which satisfy the three-term recurrence\n$$\nx\\,\\phi_{n}(x) \\;=\\; a_{n+1}\\,\\phi_{n+1}(x) \\;+\\; b_{n}\\,\\phi_{n}(x) \\;+\\; a_{n}\\,\\phi_{n-1}(x),\n$$\nwith $a_{n}  0$ for all $n \\ge 1$, and the convention that $\\phi_{-1}(x) \\equiv 0$.\n\nA discontinuous Galerkin (DG) element uses a modal representation of degree $p$, $u_{p}(x) = \\sum_{n=0}^{p} c_{n}\\,\\phi_{n}(x)$, and approximates the $L^{2}$ inner product by a discrete inner product over fixed nodes $\\{x_{i}\\}_{i=1}^{M}$ with weights $\\{w_{i}^{(p)}\\}_{i=1}^{M}$. Assume the weights are chosen as Christoffel-type weights\n$$\nw_{i}^{(p)} \\;=\\; \\frac{1}{K_{p}(x_{i})}, \n\\qquad \nK_{p}(x) \\;=\\; \\sum_{k=0}^{p} \\phi_{k}(x)^{2},\n$$\nso that the discrete inner product mimics the continuous one for polynomials up to degree $p$.\n\nYou wish to perform a $p$-adaptive enrichment from degree $p$ to degree $p+1$ while:\n- updating the evaluations $\\phi_{p+1}(x_{i})$ using a single sweep of the three-term recurrence based on the already available $\\phi_{p}(x_{i})$ and $\\phi_{p-1}(x_{i})$, and\n- updating the quadrature weights $\\{w_{i}^{(p)}\\}$ to $\\{w_{i}^{(p+1)}\\}$ without recomputing from scratch.\n\nStarting only from the three-term recurrence, orthonormality, and the definition of $K_{p}(x)$, derive a closed-form expression for the updated weights $w_{i}^{(p+1)}$ in terms of $w_{i}^{(p)}$ and $\\phi_{p+1}(x_{i})$ alone, valid for each node $x_{i}$.\n\nYour final answer must be the single analytic expression for $w_{i}^{(p+1)}$ in terms of $w_{i}^{(p)}$ and $\\phi_{p+1}(x_{i})$. No numerical evaluation is required.", "solution": "The problem is validated as scientifically sound, well-posed, and self-contained. All necessary definitions for its resolution are provided. The context is that of $p$-adaptive discontinuous Galerkin (DG) methods, but the core task is a mathematical derivation based on the provided definitions of orthonormal polynomials, a summation kernel, and associated weights.\n\nThe goal is to derive a closed-form expression for the updated quadrature weight $w_{i}^{(p+1)}$ in terms of the previous weight $w_{i}^{(p)}$ and the value of the new basis function $\\phi_{p+1}(x_{i})$ at a given node $x_i$. The derivation will rely solely on the explicit definitions provided in the problem statement.\n\nThe problem provides the following key definitions for a given polynomial degree $p$:\n1.  The kernel function, $K_{p}(x)$, is defined as the sum of the squares of the orthonormal basis functions up to degree $p$:\n    $$K_{p}(x) = \\sum_{k=0}^{p} \\phi_{k}(x)^{2}$$\n2.  The Christoffel-type quadrature weight, $w_{i}^{(p)}$, at a fixed node $x_i$ is defined as the reciprocal of the kernel evaluated at that node:\n    $$w_{i}^{(p)} = \\frac{1}{K_{p}(x_{i})}$$\n\nThe problem also provides the context of a $p$-adaptive enrichment, where the approximation degree is increased from $p$ to $p+1$. This involves computing the values of the new basis function, $\\phi_{p+1}(x)$, at the existing nodes. The problem states that $\\phi_{p+1}(x_i)$ is computed using the three-term recurrence relation. This information justifies the availability of $\\phi_{p+1}(x_i)$ for the weight update procedure, but the recurrence relation itself is not directly manipulated in the derivation of the weight update formula.\n\nOur objective is to find an expression for $w_{i}^{(p+1)}$. Following the definition provided, the weight for degree $p+1$ is:\n$$w_{i}^{(p+1)} = \\frac{1}{K_{p+1}(x_{i})}$$\n\nThe kernel for degree $p+1$, $K_{p+1}(x)$, is defined as:\n$$K_{p+1}(x) = \\sum_{k=0}^{p+1} \\phi_{k}(x)^{2}$$\n\nWe can decompose this sum to relate $K_{p+1}(x)$ to $K_{p}(x)$. By splitting off the last term of the summation, we get:\n$$K_{p+1}(x) = \\left(\\sum_{k=0}^{p} \\phi_{k}(x)^{2}\\right) + \\phi_{p+1}(x)^{2}$$\n\nThe expression in the parenthesis is, by definition, the kernel for degree $p$, $K_{p}(x)$. Therefore, we have a simple recursive relationship for the kernel function:\n$$K_{p+1}(x) = K_{p}(x) + \\phi_{p+1}(x)^{2}$$\n\nThis relationship holds for any $x$, and thus it holds for each of the fixed quadrature nodes $x_i$:\n$$K_{p+1}(x_{i}) = K_{p}(x_{i}) + \\phi_{p+1}(x_{i})^{2}$$\n\nNow we can substitute the definitions of the weights into this equation. From the definition $w_{i}^{(p)} = 1/K_{p}(x_i)$, we have the inverse relationships:\n$$K_{p}(x_i) = \\frac{1}{w_{i}^{(p)}}$$\nand\n$$K_{p+1}(x_i) = \\frac{1}{w_{i}^{(p+1)}}$$\n\nSubstituting these two expressions into the kernel recurrence relation yields:\n$$\\frac{1}{w_{i}^{(p+1)}} = \\frac{1}{w_{i}^{(p)}} + \\phi_{p+1}(x_{i})^{2}$$\n\nThis equation relates the reciprocal of the new weight to the reciprocal of the old weight and the value of the new basis function. To find the final expression for $w_{i}^{(p+1)}$, we solve for it. We first combine the terms on the right-hand side by finding a common denominator:\n$$\\frac{1}{w_{i}^{(p+1)}} = \\frac{1 + w_{i}^{(p)} \\phi_{p+1}(x_{i})^{2}}{w_{i}^{(p)}}$$\n\nFinally, inverting both sides of the equation gives the desired closed-form expression for the updated weight:\n$$w_{i}^{(p+1)} = \\frac{w_{i}^{(p)}}{1 + w_{i}^{(p)} \\phi_{p+1}(x_{i})^{2}}$$\n\nThis expression provides an efficient update rule. To compute the new weights $\\{w_{i}^{(p+1)}\\}$, one does not need to re-evaluate the entire sum for the kernel $K_{p+1}(x_i)$ from scratch. Instead, one can use the already computed weights $\\{w_{i}^{(p)}\\}$ and the newly computed values of $\\{\\phi_{p+1}(x_i)\\}$, which aligns with the stated goals of an efficient $p$-adaptive enrichment procedure.", "answer": "$$\n\\boxed{\\frac{w_{i}^{(p)}}{1 + w_{i}^{(p)} \\phi_{p+1}(x_{i})^{2}}}\n$$", "id": "3423649"}, {"introduction": "A mathematical identity does not always translate into a stable numerical algorithm. This final practice delves into this critical distinction by examining the three-term recurrence as a computational tool for evaluating polynomial solutions. You will analyze the numerical stability of using the recurrence in the forward versus backward direction to compute so-called 'minimal' solutions [@problem_id:3423673]. This exploration of dominant and minimal solution behaviors is essential for any practitioner, as it provides the wisdom to avoid catastrophic error amplification and implement robust, reliable spectral algorithms.", "problem": "Consider a family of real orthogonal polynomials $\\{p_n\\}_{n \\ge 0}$ on a compact interval with respect to a positive weight, normalized so that they satisfy the three-term recurrence relation\n$$\nx\\,p_n(x) \\;=\\; a_{n+1}\\,p_{n+1}(x) \\;+\\; b_n\\,p_n(x) \\;+\\; a_n\\,p_{n-1}(x), \\qquad n \\ge 0,\n$$\nwith $a_n  0$ and $b_n \\in \\mathbb{R}$, and initial seeds $p_{-1}(x) \\equiv 0$, $p_0(x) \\equiv 1$. Assume the recurrence coefficients converge, in the sense that $a_n \\to a  0$ and $b_n \\to 0$ as $n \\to \\infty$, which holds for the classical Jacobi families after suitable normalization. Define the associated polynomials of the second kind $\\{q_n(x)\\}_{n \\ge 0}$ as the unique solution of the same homogeneous three-term recurrence with different initial seeds chosen so that, for any fixed $x$ with $|x|  2a$, the solution is minimal in the sense that $q_n(x) \\to 0$ relative to any other linearly independent solution as $n \\to \\infty$. These associated polynomials arise in boundary operator evaluations in high-order Spectral Element and Discontinuous Galerkin (DG) methods, where one often needs $\\{q_n(x)\\}_{n=0}^N$ for a fixed $x$ with $x  2a$ and large $N$.\n\nStarting only from the convergence of $(a_n,b_n)$ and the definition of minimal and dominant solutions for second-order linear difference equations, analyze the asymptotic growth factors that govern the error amplification in the forward direction (increasing $n$) and in the backward direction (decreasing $n$, as in Miller’s algorithm) when evaluating $\\{q_n(x)\\}$ for a fixed $x  2a$. Based on this analysis, which of the following statements most accurately justifies the numerically stable choice between forward and backward recurrence for computing $\\{q_n(x)\\}_{n=0}^N$ with minimal round-off amplification?\n\nA. Use forward recurrence, because $q_n(x)$ decays with $n$ for $x  2a$, so round-off errors are damped by the minimal root $|r_-|  1$; the decay of the target solution guarantees stability.\n\nB. Neither direction is generally stable when $a_n$ varies with $n$; only if $a_n$ is exactly constant can backward recurrence be stable. Otherwise one must reorthogonalize at each step.\n\nC. Use backward recurrence (Miller’s algorithm), because generic perturbations contain a component in the dominant solution, which grows by the factor $|r_+|  1$ under forward iteration; reversing the direction multiplies this unwanted component by $|r_+|^{-1}  1$ at each step, thereby damping it so that the minimal solution is recovered up to a normalization.\n\nD. Either direction is equally stable for $x  2a$, because the characteristic roots satisfy $r_+ r_- = 1$, so the growth of one solution is exactly canceled by the decay of the other in floating-point arithmetic.", "solution": "The problem statement will first be validated for scientific soundness, self-consistency, and clarity.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n- A family of real orthogonal polynomials $\\{p_n\\}_{n \\ge 0}$ satisfies the three-term recurrence relation:\n$$\nx\\,p_n(x) \\;=\\; a_{n+1}\\,p_{n+1}(x) \\;+\\; b_n\\,p_n(x) \\;+\\; a_n\\,p_{n-1}(x), \\qquad n \\ge 0\n$$\n- Initial conditions for $\\{p_n\\}$ are $p_{-1}(x) \\equiv 0$ and $p_0(x) \\equiv 1$.\n- The recurrence coefficients satisfy $a_n  0$ and $b_n \\in \\mathbb{R}$.\n- Asymptotic behavior of coefficients: $a_n \\to a  0$ and $b_n \\to 0$ as $n \\to \\infty$.\n- A second family of solutions, $\\{q_n(x)\\}_{n \\ge 0}$ (associated polynomials of the second kind), satisfies the same recurrence relation but with different initial seeds.\n- For any fixed $x$ with $|x|  2a$, the sequence $\\{q_n(x)\\}$ is defined as the minimal solution, meaning $\\lim_{n \\to \\infty} q_n(x) / y_n(x) = 0$ for any other linearly independent solution $\\{y_n(x)\\}$.\n- The task is to analyze the numerical stability of computing $\\{q_n(x)\\}_{n=0}^N$ for a fixed $x  2a$ and large $N$ using forward versus backward recurrence.\n\n**Step 2: Validate Using Extracted Givens**\n\n- **Scientifically Grounded:** The problem is rooted in the established mathematical theory of orthogonal polynomials and the numerical analysis of linear recurrence relations (difference equations). The three-term recurrence is a fundamental property of orthogonal polynomials (Favard's theorem). The concepts of minimal and dominant solutions are central to the stability theory of such recurrences, as described by Poincaré's and Perron's theorems. The condition $|x|  2a$ correctly places the evaluation point outside the interval of orthogonality $[-2a, 2a]$ where the zeros of the polynomials asymptotically accumulate, a region where one expects exponential growth/decay. The application context of Spectral Element and Discontinuous Galerkin (DG) methods is authentic.\n- **Well-Posed:** The problem provides all necessary information to determine the stability of the computation. The recurrence relation, the asymptotic behavior of its coefficients, and the defining property of the target solution (minimality) are all specified. This setup allows for a unique and meaningful analysis of error propagation.\n- **Objective:** The problem is stated using precise, unambiguous mathematical language. Terms like \"minimal solution\" and \"round-off amplification\" have clear, objective meanings in numerical analysis.\n\n**Step 3: Verdict and Action**\n\nThe problem is scientifically sound, well-posed, and objective. It represents a classic and important topic in numerical computation. Therefore, the problem is **valid**. We may proceed with the solution.\n\n### Derivation\n\nThe analysis concerns the numerical stability of computing a specific solution to the second-order linear homogeneous difference equation:\n$$\na_{n+1}\\,y_{n+1}(x) + (b_n - x)\\,y_n(x) + a_n\\,y_{n-1}(x) = 0\n$$\nThe problem specifies that the coefficients have the limits $a_n \\to a  0$ and $b_n \\to 0$ as $n \\to \\infty$. The recurrence relation asymptotically approaches the constant-coefficient form:\n$$\na\\,y_{n+1} - x\\,y_n + a\\,y_{n-1} \\approx 0\n$$\nWe analyze this limiting equation by seeking solutions of the form $y_n = r^n$. Substituting this ansatz yields the characteristic equation:\n$$\na\\,r^2 - x\\,r + a = 0 \\quad \\implies \\quad r^2 - \\frac{x}{a}\\,r + 1 = 0\n$$\nThe roots of this quadratic equation are:\n$$\nr_{\\pm} = \\frac{\\frac{x}{a} \\pm \\sqrt{(\\frac{x}{a})^2 - 4}}{2} = \\frac{x \\pm \\sqrt{x^2 - 4a^2}}{2a}\n$$\nThe problem considers a fixed $x  2a$, which implies $x^2  4a^2$. Consequently, the discriminant is positive, and the two characteristic roots $r_+$ and $r_-$ are real and distinct.\n\nFrom Vieta's formulas, the product of the roots is $r_+ r_- = 1$. Since $x  2a  0$ and $\\sqrt{x^2 - 4a^2}  0$, we can identify the magnitudes of the roots:\n- $r_+ = \\frac{x + \\sqrt{x^2 - 4a^2}}{2a}  \\frac{2a + 0}{2a} = 1$. Thus, $|r_+|  1$.\n- $r_- = \\frac{1}{r_+}$. Thus, $0  |r_-|  1$.\n\nAccording to the theory of linear difference equations (Perron-Kreuser theorem), the general solution to the original variable-coefficient recurrence is a linear combination of two fundamental solutions whose asymptotic behaviors are governed by these roots.\n- One solution, the **dominant solution**, grows asymptotically like $r_+^n$. The polynomial solution $\\{p_n(x)\\}$ is an example of a dominant solution.\n- The other solution, the **minimal solution**, decays asymptotically like $r_-^n$. The problem states that $\\{q_n(x)\\}$ is this minimal solution for $x  2a$.\n\n**Analysis of Forward Recurrence (Increasing $n$)**\nTo compute $\\{q_n(x)\\}_{n=0}^N$ using forward recurrence, one would start with $q_0(x)$ and $q_1(x)$ and iterate:\n$$\nq_{n+1}(x) = \\frac{x-b_n}{a_{n+1}}\\,q_n(x) - \\frac{a_n}{a_{n+1}}\\,q_{n-1}(x)\n$$\nLet $\\hat{q}_n$ be the value computed in floating-point arithmetic. At each step, a small round-off error is introduced. This means the computed sequence is not the pure minimal solution, but a perturbed one. A general solution can be expressed as:\n$$\n\\hat{q}_n = C_1 p_n(x) + C_2 q_n(x)\n$$\nEven if we start with exact initial values for $q_n(x)$, meaning the initial $\\hat{q}_0, \\hat{q}_1$ have $C_1=0$, subsequent floating-point operations will introduce errors that are equivalent to adding a small component of the dominant solution $p_n(x)$. Let this error component be $\\epsilon p_n(x)$.\nThe total computed solution is $\\hat{q}_n(x) = q_n(x) + \\epsilon p_n(x)$. The relative error is:\n$$\n\\frac{|\\hat{q}_n(x) - q_n(x)|}{|q_n(x)|} = \\frac{|\\epsilon p_n(x)|}{|q_n(x)|} \\sim \\frac{|\\epsilon| |A r_+^n|}{|B r_-^n|} = \\frac{|\\epsilon A|}{|B|} |r_+|^{2n}\n$$\nSince $|r_+|  1$, the relative error grows exponentially. The computation is numerically unstable because the desired decaying solution is swamped by the unavoidable, growing error component.\n\n**Analysis of Backward Recurrence (Decreasing $n$)**\nTo compute using backward recurrence, one rearranges the formula to solve for $y_{n-1}$:\n$$\ny_{n-1}(x) = \\frac{x-b_n}{a_n}\\,y_n(x) - \\frac{a_{n+1}}{a_n}\\,y_{n+1}(x)\n$$\nIn this direction, the roles of the solutions are reversed. A component that behaves like $y_n \\sim r^n$ is transformed into $y_{n-1} \\sim r^{n-1} = y_n/r$.\n- The dominant solution component $p_n(x) \\sim r_+^n$ is damped at each step by a factor of $|r_+|^{-1}  1$.\n- The minimal solution component $q_n(x) \\sim r_-^n$ is amplified at each step by a factor of $|r_-|^{-1} = |r_+|  1$.\n\nThis is the basis of Miller's algorithm. One starts the backward recurrence at an index $M \\gg N$ with arbitrary values, for instance $\\tilde{q}_{M+1} = 0$ and $\\tilde{q}_{M} = 1$. These initial values represent some linear combination of the true dominant and minimal solutions at that index. As one iterates backwards from $n=M-1$ down to $0$, the component corresponding to the original dominant solution $p_n(x)$ is exponentially damped. The component corresponding to the minimal solution $q_n(x)$ is exponentially amplified, quickly dominating the sequence. Therefore, the computed sequence $\\{\\tilde{q}_n\\}_{n=0}^N$ becomes proportional to the true minimal solution $\\{q_n(x)\\}_{n=0}^N$.\n$$\n\\tilde{q}_n \\approx C \\cdot q_n(x) \\quad \\text{for } n \\le N\n$$\nThe constant of proportionality $C$ can be found using a known property of the sequence, such as a sum rule or a known value (e.g., $q_0(x)$ if it can be determined independently). This method is numerically stable because it systematically eliminates the unwanted growing solution.\n\n### Option-by-Option Analysis\n\n**A. Use forward recurrence, because $q_n(x)$ decays with $n$ for $x  2a$, so round-off errors are damped by the minimal root $|r_-|  1$; the decay of the target solution guarantees stability.**\nThis is a fallacious argument. The stability of a recurrence is determined by the behavior of the error, not the target solution. Because the general solution includes a component that grows like $|r_+|^n$, any round-off error will excite this dominant mode, which is amplified during forward iteration, leading to instability. The decay of the target solution makes the situation worse, as the growing error rapidly overwhelms it.\n**Verdict: Incorrect.**\n\n**B. Neither direction is generally stable when $a_n$ varies with $n$; only if $a_n$ is exactly constant can backward recurrence be stable. Otherwise one must reorthogonalize at each step.**\nThis is incorrect. The stability analysis is based on the asymptotic behavior of the coefficients, as formalized by the Poincaré-Perron-Kreuser theory, which applies to variable-coefficient recurrences. The existence of limiting roots $|r_+|1$ and $|r_-|1$ is sufficient. Miller's algorithm is a standard, stable technique for variable-coefficient recurrences and does not require constant coefficients.\n**Verdict: Incorrect.**\n\n**C. Use backward recurrence (Miller’s algorithm), because generic perturbations contain a component in the dominant solution, which grows by the factor $|r_+|  1$ under forward iteration; reversing the direction multiplies this unwanted component by $|r_+|^{-1}  1$ at each step, thereby damping it so that the minimal solution is recovered up to a normalization.**\nThis statement provides a correct and complete justification. It correctly identifies that forward iteration is unstable due to the amplification of the dominant solution component in the error. It then accurately describes the mechanism of backward recurrence: the roles of the solutions are reversed, and the unwanted dominant component is damped by a factor of $|r_+|^{-1}  1$ per step, ensuring the computed sequence converges to the desired minimal solution (up to a scaling factor). This is the standard explanation for the stability of Miller's algorithm.\n**Verdict: Correct.**\n\n**D. Either direction is equally stable for $x  2a$, because the characteristic roots satisfy $r_+ r_- = 1$, so the growth of one solution is exactly canceled by the decay of the other in floating-point arithmetic.**\nThis is incorrect. The property $r_+ r_- = 1$ is true, but the conclusion is false. In floating-point arithmetic, adding a large number (the growing error) to a small number (the decaying solution) results in the small number being lost. There is no cancellation. The presence of both a growing and a decaying solution is the definitive feature of a problem where the direction of computation is critical for stability. The two directions are fundamentally different in their stability properties.\n**Verdict: Incorrect.**", "answer": "$$\\boxed{C}$$", "id": "3423673"}]}