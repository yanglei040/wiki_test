{"hands_on_practices": [{"introduction": "To truly understand how positivity-preserving limiters work, we must move from abstract theory to concrete calculation. This first practice focuses on the widely-used linear scaling limiter, which conservatively adjusts a polynomial solution to enforce physical bounds. You will compute the precise scaling factor, $\\theta$, required to eliminate unphysical negative values in a high-order polynomial on a triangular element, developing a core intuition for the limiter's mechanism of scaling the solution towards its mean value [@problem_id:3409716].", "problem": "Consider a single triangular element in a Discontinuous Galerkin (DG) method for a hyperbolic conservation law, where the elementwise approximation represents a nonnegative scalar field (e.g., a density). The element is the reference triangle with vertices at $(0,0)$, $(1,0)$, and $(0,1)$. The polynomial degree is $p=2$. The elementwise approximation is\n$$\nu_h(x,y) \\;=\\; 1 \\;-\\; \\frac{5}{2}\\,x^2.\n$$\nA linear scaling positivity-preserving limiter is applied in the canonical form of rescaling around the cell average so that for a chosen parameter $\\theta \\in [0,1]$ the limited field is\n$$\nu^{\\theta}(x,y) \\;=\\; \\bar{u} \\;+\\; \\theta\\,\\big(u_h(x,y) - \\bar{u}\\big).\n$$\nHere $\\bar{u}$ is the exact cell average of $u_h$ over the element. The limiter is required to enforce nonnegativity at the volumetric check points given by the degree-$2$ Dunavant quadrature nodes, i.e., the three barycentric permutations of $(2/3,1/6,1/6)$, which in Cartesian coordinates for this reference triangle are\n$$\n(x_1,y_1)=\\Big(\\frac{1}{6},\\frac{1}{6}\\Big),\\quad (x_2,y_2)=\\Big(\\frac{2}{3},\\frac{1}{6}\\Big),\\quad (x_3,y_3)=\\Big(\\frac{1}{6},\\frac{2}{3}\\Big).\n$$\nStarting from first principles of the linear scaling limiter, determine the largest $\\theta \\in [0,1]$ such that $u^{\\theta}(x_q,y_q)\\ge 0$ at all three Dunavant nodes $(x_q,y_q)$ listed above. Compute $\\bar{u}$ exactly from its definition as the element average and carry out all evaluations exactly. Provide your final $\\theta$ as an exact rational number. No rounding is required and no units are involved.", "solution": "The problem requires finding the largest parameter $\\theta \\in [0,1]$ for a linear scaling positivity-preserving limiter such that the limited approximation $u^{\\theta}(x,y)$ remains non-negative at a specified set of check points.\n\nThe given element is the reference triangle $K$ with vertices at $(0,0)$, $(1,0)$, and $(0,1)$. Its area is $|K| = \\frac{1}{2} \\times \\text{base} \\times \\text{height} = \\frac{1}{2}(1)(1) = \\frac{1}{2}$.\n\nThe unlimited approximation is given by the quadratic polynomial:\n$$\nu_h(x,y) = 1 - \\frac{5}{2}x^2\n$$\n\nThe limited approximation is defined as:\n$$\nu^{\\theta}(x,y) = \\bar{u} + \\theta \\left( u_h(x,y) - \\bar{u} \\right)\n$$\nwhere $\\bar{u}$ is the cell average of $u_h$ over the element $K$.\n\nThe constraint to be enforced is $u^{\\theta}(x_q,y_q) \\ge 0$ at the three specified Dunavant quadrature nodes $(x_q, y_q)$. This translates to:\n$$\n\\bar{u} + \\theta \\left( u_h(x_q, y_q) - \\bar{u} \\right) \\ge 0\n$$\nfor each check point $q \\in \\{1,2,3\\}$. This inequality can be rearranged to find a constraint on $\\theta$. The nature of the constraint depends on the sign of the term $u_h(x_q, y_q) - \\bar{u}$.\n\nLet's analyze the inequality:\n1.  If $u_h(x_q, y_q) - \\bar{u} > 0$, the inequality is $\\theta \\ge \\frac{-\\bar{u}}{u_h(x_q, y_q) - \\bar{u}}$. If we find that $\\bar{u} > 0$, this provides a non-positive lower bound for $\\theta$. Since $\\theta \\in [0,1]$, this condition is trivially satisfied and imposes no upper bound on $\\theta$.\n2.  If $u_h(x_q, y_q) - \\bar{u} < 0$, we must divide by a negative number, which reverses the inequality sign:\n    $$\n    \\theta \\le \\frac{-\\bar{u}}{u_h(x_q, y_q) - \\bar{u}} = \\frac{\\bar{u}}{\\bar{u} - u_h(x_q, y_q)}\n    $$\n    This imposes an upper bound on $\\theta$.\n\nTo satisfy the non-negativity at all check points, $\\theta$ must be less than or equal to the minimum of all such upper bounds over all relevant points. The largest permissible $\\theta\n$ is therefore:\n$$\n\\theta_{\\text{max}} = \\min\\left(1, \\min_{q \\text{ s.t. } u_h(x_q,y_q) < \\bar{u}} \\left\\{ \\frac{\\bar{u}}{\\bar{u} - u_h(x_q,y_q)} \\right\\} \\right)\n$$\n\nThe solution proceeds in three steps:\n1.  Compute the exact cell average $\\bar{u}$.\n2.  Evaluate $u_h(x,y)$ at the three check points.\n3.  Use these values to determine the constraints on $\\theta$ and find the largest possible value.\n\n**Step 1: Compute the cell average $\\bar{u}$**\nThe cell average is defined as $\\bar{u} = \\frac{1}{|K|} \\int_K u_h(x,y) \\,dA$.\n$$\n\\bar{u} = \\frac{1}{1/2} \\int_0^1 \\int_0^{1-x} \\left(1 - \\frac{5}{2}x^2\\right) \\,dy\\,dx\n$$\n$$\n\\bar{u} = 2 \\int_0^1 \\left[ \\left(1 - \\frac{5}{2}x^2\\right)y \\right]_{y=0}^{y=1-x} \\,dx = 2 \\int_0^1 \\left(1 - \\frac{5}{2}x^2\\right)(1-x) \\,dx\n$$\nExpanding the integrand:\n$$\n\\bar{u} = 2 \\int_0^1 \\left(1 - x - \\frac{5}{2}x^2 + \\frac{5}{2}x^3\\right) \\,dx\n$$\nIntegrating term by term:\n$$\n\\bar{u} = 2 \\left[ x - \\frac{x^2}{2} - \\frac{5}{2}\\frac{x^3}{3} + \\frac{5}{2}\\frac{x^4}{4} \\right]_0^1 = 2 \\left( 1 - \\frac{1}{2} - \\frac{5}{6} + \\frac{5}{8} \\right)\n$$\n$$\n\\bar{u} = 2 \\left( \\frac{1}{2} - \\frac{5}{6} + \\frac{5}{8} \\right) = 2 \\left( \\frac{12}{24} - \\frac{20}{24} + \\frac{15}{24} \\right) = 2 \\left( \\frac{12 - 20 + 15}{24} \\right) = 2 \\left( \\frac{7}{24} \\right)\n$$\n$$\n\\bar{u} = \\frac{14}{24} = \\frac{7}{12}\n$$\nSince $\\bar{u} = 7/12 > 0$, our analysis of the inequality is correct.\n\n**Step 2: Evaluate $u_h(x,y)$ at the check points**\nThe check points are $(x_1,y_1)=(1/6,1/6)$, $(x_2,y_2)=(2/3,1/6)$, and $(x_3,y_3)=(1/6,2/3)$.\nThe function is $u_h(x,y) = 1 - \\frac{5}{2}x^2$. Note that $u_h$ is independent of $y$.\n\nFor $(x_1,y_1) = (1/6, 1/6)$:\n$$\nu_{h,1} = u_h\\left(\\frac{1}{6}, \\frac{1}{6}\\right) = 1 - \\frac{5}{2}\\left(\\frac{1}{6}\\right)^2 = 1 - \\frac{5}{2}\\left(\\frac{1}{36}\\right) = 1 - \\frac{5}{72} = \\frac{67}{72}\n$$\n\nFor $(x_2,y_2) = (2/3, 1/6)$:\n$$\nu_{h,2} = u_h\\left(\\frac{2}{3}, \\frac{1}{6}\\right) = 1 - \\frac{5}{2}\\left(\\frac{2}{3}\\right)^2 = 1 - \\frac{5}{2}\\left(\\frac{4}{9}\\right) = 1 - \\frac{10}{9} = -\\frac{1}{9}\n$$\n\nFor $(x_3,y_3) = (1/6, 2/3)$:\n$$\nu_{h,3} = u_h\\left(\\frac{1}{6}, \\frac{2}{3}\\right) = 1 - \\frac{5}{2}\\left(\\frac{1}{6}\\right)^2 = 1 - \\frac{5}{72} = \\frac{67}{72}\n$$\n\n**Step 3: Determine the constraints on $\\theta$**\nWe must find the points where $u_h(x_q, y_q) < \\bar{u}$.\nWe have $\\bar{u} = \\frac{7}{12} = \\frac{42}{72}$.\nThe values at the check points are $u_{h,1} = \\frac{67}{72}$, $u_{h,2} = -\\frac{1}{9} = -\\frac{8}{72}$, and $u_{h,3} = \\frac{67}{72}$.\n\n- For points $1$ and $3$: $u_h = \\frac{67}{72} > \\frac{42}{72} = \\bar{u}$. As determined earlier, these points do not impose an upper bound on $\\theta$.\n\n- For point $2$: $u_{h,2} = -\\frac{8}{72} < \\frac{42}{72} = \\bar{u}$. This point imposes an upper bound on $\\theta$:\n$$\n\\theta \\le \\frac{\\bar{u}}{\\bar{u} - u_{h,2}}\n$$\nSubstituting the values:\n$$\n\\theta \\le \\frac{\\frac{7}{12}}{\\frac{7}{12} - \\left(-\\frac{1}{9}\\right)} = \\frac{\\frac{7}{12}}{\\frac{7}{12} + \\frac{1}{9}}\n$$\nTo evaluate the denominator, we find a common multiple of $12$ and $9$, which is $36$:\n$$\n\\frac{7}{12} + \\frac{1}{9} = \\frac{7 \\times 3}{36} + \\frac{1 \\times 4}{36} = \\frac{21+4}{36} = \\frac{25}{36}\n$$\nSubstituting this back into the inequality for $\\theta$:\n$$\n\\theta \\le \\frac{\\frac{7}{12}}{\\frac{25}{36}} = \\frac{7}{12} \\times \\frac{36}{25} = \\frac{7 \\times 3}{25} = \\frac{21}{25}\n$$\n\nThe only upper bound from the non-negativity constraints is $\\theta \\le \\frac{21}{25}$. We also have the definitional constraint $\\theta \\in [0,1]$.\nThe final condition is $\\theta \\le \\min\\left(1, \\frac{21}{25}\\right)$. Since $\\frac{21}{25} < 1$, the minimum is $\\frac{21}{25}$.\nTherefore, the largest permissible value for $\\theta$ is $\\frac{21}{25}$.", "answer": "$$ \\boxed{\\frac{21}{25}} $$", "id": "3409716"}, {"introduction": "While the previous exercise examined the correction of a single high-order state, many advanced limiting strategies rely on a provably bound-preserving low-order method as a reference. This practice delves into the properties of the local Lax-Friedrichs numerical flux, a cornerstone of such methods. By implementing this flux and observing the critical role of its numerical dissipation parameter, $\\alpha$, you will gain hands-on experience with how monotonicity is enforced at the flux level to prevent the creation of new extrema, a fundamental requirement for any robust shock-capturing scheme [@problem_id:3409629].", "problem": "Consider the one-dimensional scalar conservation law $u_t + f(u)_x = 0$ discretized by a two-cell Discontinuous Galerkin (DG) method on a uniform mesh with cell size $\\Delta x > 0$, using piecewise constant basis functions (polynomial degree $p=0$) so that cell averages evolve solely through numerical fluxes at faces. Adopt the local Lax–Friedrichs (LLF) numerical flux as the low-order monotone flux across any interface with left state $u^{-}$ and right state $u^{+}$:\n$$\nF_{\\mathrm{LLF}}(u^{-},u^{+};\\alpha) = \\frac{1}{2}\\left[f(u^{-}) + f(u^{+})\\right] - \\frac{1}{2}\\,\\alpha\\,(u^{+}-u^{-}),\n$$\nwhere the facewise dissipation parameter $\\alpha$ must be chosen to dominate the local characteristic speed across the interface. In the scalar case, the Jacobian is $f'(u)$, so a sufficient facewise choice is\n$$\n\\alpha(u^{-},u^{+}) = \\sup_{s \\in [\\min(u^{-},u^{+}),\\,\\max(u^{-},u^{+})]} \\left| f'(s) \\right|.\n$$\nYou are to implement the computation of this facewise $\\alpha$ for two fluxes:\n- Linear advection: $f(u) = a\\,u$ with constant $a \\in \\mathbb{R}$.\n- Inviscid Burgers: $f(u) = \\frac{1}{2}u^2$.\n\nUse a two-cell domain with states initialized to a Riemann step: cell $0$ has constant value $u_L$ and cell $1$ has constant value $u_R$. Assume constant far-field states equal to $u_L$ on the left boundary and $u_R$ on the right boundary. In this $p=0$ setting, the forward Euler update of cell averages over a single time step $\\Delta t$ is\n$$\n\\bar{u}_0^{n+1} = \\bar{u}_0^{n} - \\frac{\\Delta t}{\\Delta x}\\left(F_{\\mathrm{mid}} - f(u_L)\\right),\\qquad\n\\bar{u}_1^{n+1} = \\bar{u}_1^{n} - \\frac{\\Delta t}{\\Delta x}\\left(f(u_R) - F_{\\mathrm{mid}}\\right),\n$$\nwhere $F_{\\mathrm{mid}} = F_{\\mathrm{LLF}}(u_L,u_R;\\alpha_{\\mathrm{mid}})$ is the LLF flux at the internal face between the two cells with facewise $\\alpha_{\\mathrm{mid}}$. For this two-cell Riemann configuration, choose a time step from a Courant–Friedrichs–Lewy (CFL) number $0 < \\mathrm{CFL} \\le 1$ as\n$$\n\\Delta t = \\begin{cases}\n\\mathrm{CFL}\\,\\dfrac{\\Delta x}{\\alpha_{\\mathrm{mid}}}, & \\alpha_{\\mathrm{mid}} > 0, \\\\\n\\Delta x, & \\alpha_{\\mathrm{mid}} = 0,\n\\end{cases}\n$$\nnoting that if $\\alpha_{\\mathrm{mid}}=0$ then $u_L=u_R$ and $F_{\\mathrm{mid}}=f(u_L)$ so no update occurs.\n\nYour task:\n1. Implement the facewise computation $\\alpha(u^{-},u^{+})$ as the supremum of $\\left|f'(s)\\right|$ over the interval connecting $u^{-}$ and $u^{+}$ for each flux family. This must be done from first principles, based on the definition above, not by hard-coding case-specific “shortcut” values.\n2. Implement a single forward Euler update for the two-cell problem described above using the LLF flux with the computed $\\alpha_{\\mathrm{mid}}$.\n3. Investigate the effect of underestimating $\\alpha$ by a factor $0 < \\sigma < 1$ by repeating the same update with $\\tilde{\\alpha}_{\\mathrm{mid}} = \\sigma\\,\\alpha_{\\mathrm{mid}}$.\n4. For each run, verify the discrete bound-preservation of cell averages against the initial global bounds\n$$\nm_0 = \\min(u_L,u_R),\\qquad M_0 = \\max(u_L,u_R),\n$$\nby checking whether both $\\bar{u}_0^{n+1}$ and $\\bar{u}_1^{n+1}$ lie in the closed interval $[m_0,M_0]$. Report a boolean for each run.\n\nUse the following test suite of Riemann problems with $\\Delta x = 1$ and with the specified $\\mathrm{CFL}$ and underestimation factor $\\sigma$:\n- Test $1$: Burgers flux, $u_L=1.0$, $u_R=2.0$, $\\mathrm{CFL}=0.9$, $\\sigma=0.5$.\n- Test $2$: Burgers flux, $u_L=2.0$, $u_R=1.0$, $\\mathrm{CFL}=0.9$, $\\sigma=0.5$.\n- Test $3$: Linear advection with $a=1.0$, $u_L=1.0$, $u_R=0.0$, $\\mathrm{CFL}=0.9$, $\\sigma=0.5$.\n- Test $4$: Burgers flux, $u_L=-1.5$, $u_R=-0.5$, $\\mathrm{CFL}=0.9$, $\\sigma=0.5$.\n- Test $5$: Burgers flux, $u_L=1.234$, $u_R=1.234$, $\\mathrm{CFL}=0.9$, $\\sigma=0.5$.\n\nFor each test, produce two booleans in order: first using the correct $\\alpha_{\\mathrm{mid}}$ as defined above, and second using the underestimated $\\tilde{\\alpha}_{\\mathrm{mid}}=\\sigma\\,\\alpha_{\\mathrm{mid}}$. Therefore, across the five tests, your program should produce a single line of output containing ten booleans aggregated into a single list. Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[true1,false1,true2,false2,...]\"). No other output is permitted.\n\nAngles, units, and physical dimensions are not applicable to this purely mathematical task; all quantities are dimensionless real numbers. The final answers for each test are booleans.", "solution": "The problem requires the implementation and analysis of a first-order numerical scheme for the one-dimensional scalar conservation law, given by:\n$$\n\\frac{\\partial u}{\\partial t} + \\frac{\\partial f(u)}{\\partial x} = 0\n$$\nThe spatial discretization is specified as a two-cell Discontinuous Galerkin (DG) method with piecewise constant basis functions ($p=0$), which is equivalent to a first-order finite volume method. The two cells, labeled $0$ and $1$, have initial constant states $\\bar{u}_0^n = u_L$ and $\\bar{u}_1^n = u_R$, respectively. The domain is defined on a uniform mesh of cell width $\\Delta x$.\n\nThe semi-discrete finite volume formulation updates the cell average $\\bar{u}_i$ in cell $i$ according to the flux balance:\n$$\n\\frac{d\\bar{u}_i}{dt} = -\\frac{1}{\\Delta x}\\left( F_{i+1/2} - F_{i-1/2} \\right)\n$$\nwhere $F_{i\\pm1/2}$ are the numerical fluxes at the cell interfaces. For the two-cell setup, this becomes:\n- Cell $0$: $\\frac{d\\bar{u}_0}{dt} = -\\frac{1}{\\Delta x}\\left( F_{1/2} - F_{-1/2} \\right)$\n- Cell $1$: $\\frac{d\\bar{u}_1}{dt} = -\\frac{1}{\\Delta x}\\left( F_{3/2} - F_{1/2} \\right)$\n\nThe flux $F_{1/2} = F_{\\mathrm{mid}}$ is computed at the internal interface between cell $0$ and cell $1$. The boundary fluxes are given as $F_{-1/2} = f(u_L)$ and $F_{3/2} = f(u_R)$, corresponding to fixed far-field boundary conditions. The time integration is performed with a single forward Euler step. This leads to the fully discrete update equations provided in the problem statement:\n$$\n\\bar{u}_0^{n+1} = \\bar{u}_0^{n} - \\frac{\\Delta t}{\\Delta x}\\left(F_{\\mathrm{mid}} - f(u_L)\\right)\n$$\n$$\n\\bar{u}_1^{n+1} = \\bar{u}_1^{n} - \\frac{\\Delta t}{\\Delta x}\\left(f(u_R) - F_{\\mathrm{mid}}\\right)\n$$\nwhere the initial states are $\\bar{u}_0^n = u_L$ and $\\bar{u}_1^n = u_R$.\n\nThe numerical flux at the internal interface, $F_{\\mathrm{mid}}$, is the local Lax-Friedrichs (LLF) flux, which depends on the left state $u^{-} = u_L$ and the right state $u^{+} = u_R$:\n$$\nF_{\\mathrm{mid}} = F_{\\mathrm{LLF}}(u_L, u_R; \\alpha_{\\mathrm{mid}}) = \\frac{1}{2}\\left[f(u_L) + f(u_R)\\right] - \\frac{1}{2}\\,\\alpha_{\\mathrm{mid}}\\,(u_R - u_L)\n$$\nThe parameter $\\alpha_{\\mathrm{mid}}$ represents numerical dissipation. For the scheme to be monotone, and thus guarantee that no new extrema are created (i.e., to be bound-preserving), $\\alpha_{\\mathrm{mid}}$ must be sufficiently large. A sufficient condition is that $\\alpha_{\\mathrm{mid}}$ must be greater than or equal to the maximum local wave speed over the range of states interacting at the interface. For a scalar conservation law, the wave speed (characteristic speed) is $f'(u)$. Thus, the facewise dissipation parameter is defined as:\n$$\n\\alpha_{\\mathrm{mid}} = \\alpha(u_L, u_R) = \\sup_{s \\in [\\min(u_L, u_R),\\,\\max(u_L, u_R)]} \\left| f'(s) \\right|\n$$\n\nWe will now determine the expression for $\\alpha_{\\mathrm{mid}}$ for the two specified flux functions.\n1.  **Linear Advection**: The flux is $f(u) = a u$ for some constant $a \\in \\mathbb{R}$. The derivative is $f'(u) = a$. The absolute value is $|f'(u)| = |a|$, which is a constant. Therefore, the supremum over any interval is simply this constant value:\n    $$\n    \\alpha(u_L, u_R) = \\sup_{s \\in [\\min(u_L, u_R),\\,\\max(u_L, u_R)]} |a| = |a|\n    $$\n2.  **Inviscid Burgers' Equation**: The flux is $f(u) = \\frac{1}{2}u^2$. The derivative is $f'(u) = u$. We need to find the supremum of $|f'(s)| = |s|$ on the interval $I = [\\min(u_L, u_R), \\max(u_L, u_R)]$. The function $g(s) = |s|$ is convex. A property of convex functions is that their maximum over a closed interval must occur at one of the endpoints of the interval. Therefore, we only need to check the values of $|s|$ at $s = \\min(u_L, u_R)$ and $s = \\max(u_L, u_R)$, which are simply $u_L$ and $u_R$ in some order.\n    $$\n    \\alpha(u_L, u_R) = \\max\\left(\\left|\\min(u_L, u_R)\\right|, \\left|\\max(u_L, u_R)\\right|\\right) = \\max(|u_L|, |u_R|)\n    $$\nThis logic constitutes a derivation from first principles, as it relies on the fundamental mathematical properties of the function $|f'(s)|$ rather than a pre-specified formula.\n\nThe time step $\\Delta t$ is determined by a Courant–Friedrichs–Lewy (CFL) condition. For $\\alpha_{\\mathrm{mid}} > 0$, the time step is $\\Delta t = \\mathrm{CFL}\\,\\frac{\\Delta x}{\\alpha_{\\mathrm{mid}}}$. This choice ensures that the coefficient $\\frac{\\Delta t}{\\Delta x}\\alpha_{\\mathrm{mid}} = \\mathrm{CFL} \\le 1$. From the theory of monotone schemes, this condition is necessary for the forward Euler time-stepping scheme to be bound-preserving, provided the LLF flux itself is monotone (which is ensured by our choice of $\\alpha_{\\mathrm{mid}}$). If $\\alpha_{\\mathrm{mid}} = 0$, which occurs if and only if $u_L = u_R$ for the given flux functions, the update terms become zero and the solution is stationary.\n\nThe core of the task is to verify the bound-preservation property. The initial bounds are $m_0 = \\min(u_L, u_R)$ and $M_0 = \\max(u_L, u_R)$. After one time step, we check if the new cell averages $\\bar{u}_0^{n+1}$ and $\\bar{u}_1^{n+1}$ remain within these bounds, i.e., $m_0 \\le \\bar{u}_0^{n+1} \\le M_0$ and $m_0 \\le \\bar{u}_1^{n+1} \\le M_0$. This check is performed for two scenarios:\n1.  Using the correctly computed dissipation $\\alpha_{\\mathrm{mid}}$. With $\\mathrm{CFL} \\le 1$, the scheme is expected to be bound-preserving.\n2.  Using an underestimated dissipation $\\tilde{\\alpha}_{\\mathrm{mid}} = \\sigma \\alpha_{\\mathrm{mid}}$ where $0 < \\sigma < 1$. In this case, the criterion for monotonicity of the numerical flux might be violated, potentially leading to the creation of new extrema (overshoots or undershoots) that violate the initial bounds $[m_0, M_0]$. The time step $\\Delta t$ is calculated using the correct $\\alpha_{\\mathrm{mid}}$ and remains fixed for both computations to isolate the effect of the dissipation term in the flux.\n\nThe following procedure is implemented for each test case:\n1.  Identify the flux function $f(u)$ and its derivative $f'(u)$.\n2.  Given $u_L$ and $u_R$, compute the correct dissipation $\\alpha_{\\mathrm{mid}}$ by finding the supremum of $|f'(s)|$ on the interval $[\\min(u_L, u_R), \\max(u_L, u_R)]$.\n3.  Calculate the time step $\\Delta t$ using $\\alpha_{\\mathrm{mid}}$, $\\Delta x$, and $\\mathrm{CFL}$. If $\\alpha_{\\mathrm{mid}}=0$, no update occurs, and the solution is trivially bound-preserving.\n4.  **Run 1 (Correct $\\alpha$)**: Compute $F_{\\mathrm{mid}}$ using $\\alpha_{\\mathrm{mid}}$. Calculate $\\bar{u}_0^{n+1}$ and $\\bar{u}_1^{n+1}$. Check if both values are in $[m_0, M_0]$ and record the boolean result.\n5.  **Run 2 (Underestimated $\\alpha$)**: Compute $\\tilde{\\alpha}_{\\mathrm{mid}} = \\sigma \\alpha_{\\mathrm{mid}}$. Compute a new flux $\\tilde{F}_{\\mathrm{mid}}$ using $\\tilde{\\alpha}_{\\mathrm{mid}}$. Using the same $\\Delta t$ as before, calculate the new states $\\bar{u}_0^{n+1}$ and $\\bar{u}_1^{n+1}$. Check if both values are in $[m_0, M_0]$ and record the boolean result.\nThe implementation will systematically apply this procedure to all specified test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the two-cell DG-P0 problem for various test cases, checking for\n    bound-preservation with correct and underestimated numerical dissipation.\n    \"\"\"\n\n    test_cases = [\n        {'flux_type': 'burgers', 'ul': 1.0, 'ur': 2.0, 'cfl': 0.9, 'sigma': 0.5},\n        {'flux_type': 'burgers', 'ul': 2.0, 'ur': 1.0, 'cfl': 0.9, 'sigma': 0.5},\n        {'flux_type': 'linear', 'a': 1.0, 'ul': 1.0, 'ur': 0.0, 'cfl': 0.9, 'sigma': 0.5},\n        {'flux_type': 'burgers', 'ul': -1.5, 'ur': -0.5, 'cfl': 0.9, 'sigma': 0.5},\n        {'flux_type': 'burgers', 'ul': 1.234, 'ur': 1.234, 'cfl': 0.9, 'sigma': 0.5},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # Run simulation for one test case and append results\n        res1, res2 = run_test_case(case)\n        results.extend([res1, res2])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(str(r).lower() for r in results)}]\")\n\n\ndef get_flux_functions(flux_type, a=None):\n    \"\"\"Factory for flux function f and its derivative f_prime.\"\"\"\n    if flux_type == 'burgers':\n        f = lambda u: 0.5 * u**2\n        f_prime = lambda u: u\n    elif flux_type == 'linear':\n        if a is None:\n            raise ValueError(\"Parameter 'a' must be provided for linear advection.\")\n        f = lambda u: a * u\n        f_prime = lambda u: a\n    else:\n        raise ValueError(f\"Unknown flux type: {flux_type}\")\n    return f, f_prime\n\ndef compute_alpha(f_prime, u_minus, u_plus):\n    \"\"\"\n    Computes the facewise dissipation alpha from first principles.\n    alpha = sup |f'(s)| for s in [min(u-,u+), max(u-,u+)].\n    For the monotonic/convex functions |f'| used here, the supremum\n    is at one of the interval endpoints.\n    \"\"\"\n    if u_minus == u_plus:\n        return np.abs(f_prime(u_minus))\n\n    u_min = min(u_minus, u_plus)\n    u_max = max(u_minus, u_plus)\n    \n    # For linear advection, f_prime is constant.\n    # For Burgers, f_prime(s)=s, so |f_prime(s)|=|s| is convex.\n    # Its maximum on an interval [u_min, u_max] is at an endpoint.\n    # This logic is general for any f' where |f'|'s max is at an endpoint.\n    val1 = np.abs(f_prime(u_min))\n    val2 = np.abs(f_prime(u_max))\n    \n    return max(val1, val2)\n\ndef run_test_case(params):\n    \"\"\"Runs a single test case with correct and underestimated alpha.\"\"\"\n    ul, ur = params['ul'], params['ur']\n    cfl, sigma = params['cfl'], params['sigma']\n    flux_type = params['flux_type']\n    a = params.get('a')\n    dx = 1.0\n\n    f, f_prime = get_flux_functions(flux_type, a)\n\n    # Initial bounds for checking preservation\n    m0 = min(ul, ur)\n    M0 = max(ul, ur)\n\n    # Compute correct alpha and the time step\n    alpha_mid_correct = compute_alpha(f_prime, ul, ur)\n\n    if alpha_mid_correct > 0:\n        dt = cfl * dx / alpha_mid_correct\n    else:\n        # If alpha is 0, states are equal, no update occurs. Bounds are preserved.\n        return True, True\n\n    # --- Run 1: Correct alpha ---\n    alpha1 = alpha_mid_correct\n    f_mid_1 = 0.5 * (f(ul) + f(ur)) - 0.5 * alpha1 * (ur - ul)\n    \n    u0_new_1 = ul - (dt / dx) * (f_mid_1 - f(ul))\n    u1_new_1 = ur - (dt / dx) * (f(ur) - f_mid_1)\n    \n    # Check bounds for Run 1\n    # Add a small tolerance for floating point comparisons\n    tol = 1e-9\n    bound_preserved_1 = (m0 - tol <= u0_new_1 <= M0 + tol) and \\\n                        (m0 - tol <= u1_new_1 <= M0 + tol)\n\n    # --- Run 2: Underestimated alpha ---\n    alpha2 = sigma * alpha_mid_correct\n    f_mid_2 = 0.5 * (f(ul) + f(ur)) - 0.5 * alpha2 * (ur - ul)\n\n    u0_new_2 = ul - (dt / dx) * (f_mid_2 - f(ul))\n    u1_new_2 = ur - (dt / dx) * (f(ur) - f_mid_2)\n    \n    # Check bounds for Run 2\n    bound_preserved_2 = (m0 - tol <= u0_new_2 <= M0 + tol) and \\\n                        (m0 - tol <= u1_new_2 <= M0 + tol)\n\n    return bound_preserved_1, bound_preserved_2\n\nsolve()\n```", "id": "3409629"}, {"introduction": "Applying limiters to high-degree polynomials requires not only a sound theoretical basis but also an efficient computational strategy. This final practice introduces a powerful technique used in modern Discontinuous Galerkin solvers: leveraging the properties of the Bernstein polynomial basis. You will implement a change-of-basis transformation to see how the complex task of enforcing pointwise positivity on a polynomial can be reduced to the simple, efficient operation of clipping its Bernstein coefficients, providing direct insight into state-of-the-art limiter design [@problem_id:3409697].", "problem": "Consider a one-dimensional reference element with coordinate $x \\in [-1,1]$ and its affine mapping to the unit interval $t \\in [0,1]$ given by $t = (x+1)/2$. In a Discontinuous Galerkin (DG) method, an approximate solution $u_h$ on an element is represented as a degree-$n$ polynomial in a chosen basis. Three classical bases are: the Legendre polynomial basis $\\{P_k(x)\\}_{k=0}^n$, the Chebyshev polynomial basis of the first kind $\\{T_k(x)\\}_{k=0}^n$, and the Bernstein polynomial basis $\\{B_k^n(t)\\}_{k=0}^n$, where $B_k^n(t) = \\binom{n}{k} t^k (1-t)^{n-k}$. It is known that the Bernstein basis functions are nonnegative on $t \\in [0,1]$ and form a partition of unity, while Legendre and Chebyshev modal functions change sign on $x \\in [-1,1]$. A positivity preserving limiter ensures $u_h \\ge 0$, and a boundedness preserving limiter ensures $0 \\le u_h \\le U$ for a given bound $U$. Coefficient-wise constraints that enforce nonnegativity in modal bases such as Legendre or Chebyshev do not suffice to guarantee pointwise nonnegativity of $u_h$, whereas coefficient-wise constraints in the Bernstein basis do.\n\nStarting from the following fundamental bases and properties:\n- The three-term recurrence for Legendre polynomials: $P_0(x)=1$, $P_1(x)=x$, and $P_{k+1}(x) = \\frac{(2k+1)x P_k(x) - k P_{k-1}(x)}{k+1}$ for $k \\ge 1$.\n- The three-term recurrence for Chebyshev polynomials of the first kind: $T_0(x)=1$, $T_1(x)=x$, and $T_{k+1}(x)=2x T_k(x) - T_{k-1}(x)$ for $k \\ge 1$.\n- The Bernstein basis definition $B_k^n(t) = \\binom{n}{k} t^k (1-t)^{n-k}$ with $B_k^n(t) \\ge 0$ on $t \\in [0,1]$ and $\\sum_{k=0}^n B_k^n(t) = 1$.\n- The fact that evaluating a polynomial at $n+1$ distinct points uniquely determines its coefficients in any degree-$n$ basis via a change-of-basis linear system.\n\nImplement a fast change-of-basis transform to the Bernstein basis for limiting and a transform back to the original modal basis. Use the following approach:\n- Choose the $n+1$ Bernstein nodes $t_j = j/n$ for $j=0,1,\\dots,n$ (all in $[0,1]$), and map them to $x_j = 2t_j - 1 \\in [-1,1]$.\n- Build the evaluation matrix $E^{\\text{L}} \\in \\mathbb{R}^{(n+1)\\times(n+1)}$ for Legendre polynomials evaluated at $\\{x_j\\}$, and similarly $E^{\\text{C}}$ for Chebyshev polynomials at $\\{x_j\\}$, using the stated three-term recurrences.\n- Build the evaluation matrix $E^{\\text{B}} \\in \\mathbb{R}^{(n+1)\\times(n+1)}$ for Bernstein polynomials evaluated at $\\{t_j\\}$.\n- For any coefficient vector in a modal basis, compute the polynomial values at the chosen nodes by multiplying with the corresponding evaluation matrix, then solve the linear system with $E^{\\text{B}}$ to obtain Bernstein coefficients. Similarly, to transform back from Bernstein to a modal basis, multiply by $E^{\\text{B}}$ and solve with the modal evaluation matrix.\n\nUse these transforms to:\n- Demonstrate that nonnegative modal coefficients in the Legendre or Chebyshev basis do not imply $u_h \\ge 0$ on $x \\in [-1,1]$ by constructing counterexamples.\n- Demonstrate that nonnegative coefficients in the Bernstein basis do imply $u_h \\ge 0$ on $t \\in [0,1]$ (equivalently on $x \\in [-1,1]$ via the affine map).\n- Implement a positivity limiter that transforms a modal representation to Bernstein coefficients, clips all Bernstein coefficients below $0$ to $0$, and transforms back.\n- Implement a boundedness limiter that clips Bernstein coefficients to $[0,U]$ for a given bound $U$ and transforms back.\n\nConstruct the following test suite, where each test requires evaluating the resulting polynomial on a dense grid of $x$ values with $1001$ equally spaced points in $[-1,1]$:\n- Test $1$ (degree $n=1$):\n  - Legendre case: coefficients $[0,1]$ (that is, $u_h(x) = P_1(x)$). Report a boolean indicating whether $u_h(x) \\ge 0$ on $[-1,1]$.\n  - Chebyshev case: coefficients $[0,1]$ (that is, $u_h(x) = T_1(x)$). Report a boolean indicating whether $u_h(x) \\ge 0$ on $[-1,1]$.\n  - Bernstein case: coefficients $[0,1]$ (that is, $u_h(t) = B_1^1(t)$). Report a boolean indicating whether $u_h(t) \\ge 0$ on $[0,1]$.\n- Test $2$ (degree $n=3$):\n  - Legendre case: coefficients $[0,0,1,0]$ (that is, $u_h(x) = P_2(x)$). Report a boolean indicating whether $u_h(x) \\ge 0$ on $[-1,1]$.\n  - Chebyshev case: coefficients $[0,0,1,0]$ (that is, $u_h(x) = T_2(x)$). Report a boolean indicating whether $u_h(x) \\ge 0$ on $[-1,1]$.\n  - Bernstein case: coefficients $[0.2,0.3,0.4,0.5]$. Report a boolean indicating whether $u_h(t) \\ge 0$ on $[0,1]$.\n- Test $3$ (degree $n=5$): Legendre case with coefficients $[0.1,1.0,0.0,0.0,0.0,0.0]$. Compute two floats: the minimum value of $u_h(x)$ over $[-1,1]$ before limiting and the minimum value after applying the positivity limiter via Bernstein clipping. Report both floats rounded to six decimal places.\n- Test $4$ (degree $n=4$): Legendre case with coefficients $[0.3,0.9,-0.2,0.1,0.5]$ and bound $U=0.8$. Apply the boundedness limiter via Bernstein clipping to $[0,U]$, transform back, and evaluate on $x \\in [-1,1]$. Report two booleans: whether the limited polynomial satisfies $u_h(x) \\ge 0$ on $[-1,1]$, and whether it satisfies $u_h(x) \\le U$ on $[-1,1]$.\n- Test $5$ (degree $n=0$): Legendre case with coefficients $[-0.2]$. Apply the positivity limiter. Report one float: the minimum value over $[-1,1]$ after limiting, rounded to six decimal places.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following order:\n$[$Test $1$ Legendre boolean, Test $1$ Chebyshev boolean, Test $1$ Bernstein boolean, Test $2$ Legendre boolean, Test $2$ Chebyshev boolean, Test $2$ Bernstein boolean, Test $3$ minimum before limiting (float rounded to six decimal places), Test $3$ minimum after limiting (float rounded to six decimal places), Test $4$ nonnegativity boolean, Test $4$ boundedness boolean, Test $5$ minimum after limiting (float rounded to six decimal places)$]$.", "solution": "The problem statement is a valid computational exercise in the field of numerical analysis, specifically concerning Discontinuous Galerkin (DG) methods for hyperbolic partial differential equations. It is scientifically grounded, well-posed, objective, and contains all necessary information to construct a unique, verifiable solution. The underlying principles—the properties of Legendre, Chebyshev, and Bernstein polynomial bases, and the use of basis transformations for implementing property-preserving limiters—are fundamental concepts in advanced numerical methods.\n\nThe core of the problem is to implement and utilize a change-of-basis transformation between modal polynomial bases (Legendre, Chebyshev) and the Bernstein polynomial basis. This transformation is pivotal for enforcing physical constraints like positivity or boundedness on the numerical solution $u_h$.\n\nA polynomial $u_h$ of degree $n$ can be expressed in various bases. In a modal basis $\\{\\phi_k(x)\\}_{k=0}^n$ on the reference element $x \\in [-1,1]$, the representation is:\n$$\nu_h(x) = \\sum_{k=0}^n \\hat{u}_k^{\\text{M}} \\phi_k(x)\n$$\nwhere $\\hat{u}_k^{\\text{M}}$ are the modal coefficients (e.g., Legendre or Chebyshev coefficients).\n\nThe same polynomial can be expressed in the Bernstein basis $\\{B_k^n(t)\\}_{k=0}^n$ on the unit interval $t \\in [0,1]$, where $t=(x+1)/2$ is the affine mapping from $x \\in [-1,1]$. The representation is:\n$$\nu_h(t) = \\sum_{k=0}^n \\hat{u}_k^{\\text{B}} B_k^n(t)\n$$\nwhere $B_k^n(t) = \\binom{n}{k} t^k (1-t)^{n-k}$ and $\\hat{u}_k^{\\text{B}}$ are the Bernstein coefficients.\n\nThe transformation between these representations is achieved by collocating the polynomial values at a set of $n+1$ distinct points. The problem specifies using the Bernstein nodes $t_j = j/n$ for $j=0, 1, \\dots, n$, which map to $x_j = 2t_j - 1$. At these nodes, the two representations must be equal:\n$$\n\\sum_{k=0}^n \\hat{u}_k^{\\text{M}} \\phi_k(x_j) = \\sum_{k=0}^n \\hat{u}_k^{\\text{B}} B_k^n(t_j) \\quad \\text{for } j=0, \\dots, n\n$$\nThis equality for all $j$ forms a linear system of equations:\n$$\n\\mathbf{E}^{\\text{M}} \\mathbf{\\hat{u}}^{\\text{M}} = \\mathbf{E}^{\\text{B}} \\mathbf{\\hat{u}}^{\\text{B}}\n$$\nHere, $\\mathbf{\\hat{u}}^{\\text{M}}$ and $\\mathbf{\\hat{u}}^{\\text{B}}$ are the column vectors of modal and Bernstein coefficients, respectively. $\\mathbf{E}^{\\text{M}}$ and $\\mathbf{E}^{\\text{B}}$ are the $(n+1) \\times (n+1)$ evaluation matrices with entries $(\\mathbf{E}^{\\text{M}})_{jk} = \\phi_k(x_j)$ and $(\\mathbf{E}^{\\text{B}})_{jk} = B_k^n(t_j)$. These matrices are invertible. The transformations are therefore given by solving these linear systems:\n-   **Modal to Bernstein**: $\\mathbf{\\hat{u}}^{\\text{B}} = (\\mathbf{E}^{\\text{B}})^{-1} \\mathbf{E}^{\\text{M}} \\mathbf{\\hat{u}}^{\\text{M}}$\n-   **Bernstein to Modal**: $\\mathbf{\\hat{u}}^{\\text{M}} = (\\mathbf{E}^{\\text{M}})^{-1} \\mathbf{E}^{\\text{B}} \\mathbf{\\hat{u}}^{\\text{B}}$\n\nThe utility of the Bernstein basis stems from two key properties:\n$1$. **Non-negativity**: $B_k^n(t) \\ge 0$ for all $k$ and for all $t \\in [0,1]$.\n$2$. **Partition of Unity**: $\\sum_{k=0}^n B_k^n(t) = 1$ for all $t \\in [0,1]$.\n\nThese properties imply that the polynomial $u_h(t)$ is contained within the convex hull of its Bernstein coefficients $\\hat{u}_k^{\\text{B}}$. Specifically, $\\min_k(\\hat{u}_k^{\\text{B}}) \\le u_h(t) \\le \\max_k(\\hat{u}_k^{\\text{B}})$. This provides a direct way to enforce bounds on the polynomial by manipulating its Bernstein coefficients.\n\n-   **Positivity-Preserving Limiter**: To ensure $u_h(x) \\ge 0$, we transform the modal coefficients $\\mathbf{\\hat{u}}^{\\text{M}}$ to Bernstein coefficients $\\mathbf{\\hat{u}}^{\\text{B}}$. We then clip any negative coefficients to zero, creating a new set of coefficients $\\hat{u}_k^{\\text{B}'} = \\max(0, \\hat{u}_k^{\\text{B}})$. The resulting polynomial $u_h'(t) = \\sum_k \\hat{u}_k^{\\text{B}'} B_k^n(t)$ is guaranteed to be non-negative, as it is a non-negative weighted sum of non-negative basis functions. This new set of Bernstein coefficients is then transformed back to the original modal basis to obtain the limited modal coefficients $\\mathbf{\\hat{u}}^{\\text{M}'}$.\n\n-   **Boundedness-Preserving Limiter**: To ensure $0 \\le u_h(x) \\le U$ for some upper bound $U$, a similar procedure is followed. The Bernstein coefficients are clipped to the range $[0, U]$, i.e., $\\hat{u}_k^{\\text{B}'} = \\min(U, \\max(0, \\hat{u}_k^{\\text{B}}))$. The non-negativity $u_h'(t) \\ge 0$ follows as before. The upper bound is guaranteed by the partition of unity property:\n$$\nu_h'(t) = \\sum_{k=0}^n \\hat{u}_k^{\\text{B}'} B_k^n(t) \\le \\sum_{k=0}^n U \\cdot B_k^n(t) = U \\sum_{k=0}^n B_k^n(t) = U \\cdot 1 = U\n$$\n\nThe implementation will proceed by first constructing functions to evaluate the polynomials from their coefficients and generate the necessary evaluation matrices using the specified three-term recurrences. Then, for each test case, the appropriate transformations and limiting procedures will be applied, and the results evaluated on a dense grid of $1001$ points on $x \\in [-1,1]$.\n\nThe test cases are designed to systematically demonstrate these principles:\n-   **Tests $1$ and $2$**: Show that non-negative modal coefficients for Legendre and Chebyshev polynomials can produce polynomials with negative values, while non-negative Bernstein coefficients guarantee a non-negative polynomial.\n-   **Test $3$**: Quantifies the effect of the positivity limiter on a polynomial that violates the non-negativity constraint.\n-   **Test $4$**: Demonstrates that the boundedness limiter correctly enforces both the lower ($0$) and upper ($U$) bounds.\n-   **Test $5$**: A simple case for $n=0$ (a constant function) to verify the limiter's behavior in the most basic scenario.\n\nThe following Python code implements this entire procedure to solve the problem as stated.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import comb\n\ndef eval_legendre(coeffs, x):\n    \"\"\"Evaluates a polynomial in the Legendre basis.\"\"\"\n    n = len(coeffs) - 1\n    if n < 0:\n        return np.zeros_like(x)\n    \n    p_prev = np.ones_like(x)\n    val = coeffs[0] * p_prev\n    \n    if n > 0:\n        p_curr = np.copy(x)\n        val += coeffs[1] * p_curr\n    \n    for k in range(1, n):\n        # P_{k+1}(x) = ((2k+1)x P_k(x) - k P_{k-1}(x)) / (k+1)\n        p_next = ((2 * k + 1) * x * p_curr - k * p_prev) / (k + 1)\n        val += coeffs[k + 1] * p_next\n        p_prev = p_curr\n        p_curr = p_next\n        \n    return val\n\ndef eval_chebyshev(coeffs, x):\n    \"\"\"Evaluates a polynomial in the Chebyshev basis.\"\"\"\n    n = len(coeffs) - 1\n    if n < 0:\n        return np.zeros_like(x)\n    \n    t_prev = np.ones_like(x)\n    val = coeffs[0] * t_prev\n    \n    if n > 0:\n        t_curr = np.copy(x)\n        val += coeffs[1] * t_curr\n        \n    for k in range(1, n):\n        # T_{k+1}(x) = 2x T_k(x) - T_{k-1}(x)\n        t_next = 2 * x * t_curr - t_prev\n        val += coeffs[k + 1] * t_next\n        t_prev = t_curr\n        t_curr = t_next\n        \n    return val\n\ndef eval_bernstein(coeffs, t, n):\n    \"\"\"Evaluates a polynomial in the Bernstein basis.\"\"\"\n    if n < 0:\n        return np.zeros_like(t)\n    \n    val = np.zeros_like(t, dtype=float)\n    for k in range(n + 1):\n        # B_k^n(t) = comb(n, k) * t^k * (1-t)^(n-k)\n        basis_func = comb(n, k) * (t**k) * ((1 - t)**(n - k))\n        val += coeffs[k] * basis_func\n        \n    return val\n\ndef get_eval_matrix(n, basis, nodes):\n    \"\"\"Generates the evaluation matrix for a given basis at specified nodes.\"\"\"\n    num_nodes = len(nodes)\n    num_coeffs = n + 1\n    E = np.zeros((num_nodes, num_coeffs))\n    \n    if basis == 'legendre':\n        p_prev = np.ones(num_nodes)\n        E[:, 0] = p_prev\n        if n > 0:\n            p_curr = np.copy(nodes)\n            E[:, 1] = p_curr\n        for k in range(1, n):\n            p_next = ((2 * k + 1) * nodes * p_curr - k * p_prev) / (k + 1)\n            E[:, k + 1] = p_next\n            p_prev = p_curr\n            p_curr = p_next\n    elif basis == 'chebyshev':\n        t_prev = np.ones(num_nodes)\n        E[:, 0] = t_prev\n        if n > 0:\n            t_curr = np.copy(nodes)\n            E[:, 1] = t_curr\n        for k in range(1, n):\n            t_next = 2 * nodes * t_curr - t_prev\n            E[:, k + 1] = t_next\n            t_prev = t_curr\n            t_curr = t_next\n    elif basis == 'bernstein':\n        for k in range(num_coeffs):\n            E[:, k] = comb(n, k) * (nodes**k) * ((1 - nodes)**(n - k))\n            \n    return E\n\ndef solve():\n    results = []\n    x_eval = np.linspace(-1, 1, 1001)\n    t_eval = (x_eval + 1) / 2\n\n    # --- Test 1 (n=1) ---\n    n1 = 1\n    # Legendre case\n    coeffs_l1 = np.array([0.0, 1.0])\n    u_h_l1 = eval_legendre(coeffs_l1, x_eval)\n    results.append(np.all(u_h_l1 >= -1e-9))\n    # Chebyshev case\n    coeffs_c1 = np.array([0.0, 1.0])\n    u_h_c1 = eval_chebyshev(coeffs_c1, x_eval)\n    results.append(np.all(u_h_c1 >= -1e-9))\n    # Bernstein case\n    coeffs_b1 = np.array([0.0, 1.0])\n    u_h_b1 = eval_bernstein(coeffs_b1, t_eval, n1)\n    results.append(np.all(u_h_b1 >= -1e-9))\n\n    # --- Test 2 (n=3) ---\n    n2 = 3\n    # Legendre case\n    coeffs_l2 = np.array([0.0, 0.0, 1.0, 0.0])\n    u_h_l2 = eval_legendre(coeffs_l2, x_eval)\n    results.append(np.all(u_h_l2 >= -1e-9))\n    # Chebyshev case\n    coeffs_c2 = np.array([0.0, 0.0, 1.0, 0.0])\n    u_h_c2 = eval_chebyshev(coeffs_c2, x_eval)\n    results.append(np.all(u_h_c2 >= -1e-9))\n    # Bernstein case\n    coeffs_b2 = np.array([0.2, 0.3, 0.4, 0.5])\n    u_h_b2 = eval_bernstein(coeffs_b2, t_eval, n2)\n    results.append(np.all(u_h_b2 >= -1e-9))\n\n    # --- Test 3 (n=5) ---\n    n3 = 5\n    coeffs_l3 = np.array([0.1, 1.0, 0.0, 0.0, 0.0, 0.0])\n    u_h_l3_before = eval_legendre(coeffs_l3, x_eval)\n    min_before = np.min(u_h_l3_before)\n    results.append(f\"{min_before:.6f}\")\n    \n    # Limiter\n    t_nodes3 = np.linspace(0, 1, n3 + 1)\n    x_nodes3 = 2 * t_nodes3 - 1\n    E_L3 = get_eval_matrix(n3, 'legendre', x_nodes3)\n    E_B3 = get_eval_matrix(n3, 'bernstein', t_nodes3)\n    \n    u_hat_B3 = np.linalg.solve(E_B3, E_L3 @ coeffs_l3)\n    u_hat_B3_limited = np.maximum(0, u_hat_B3)\n    coeffs_l3_limited = np.linalg.solve(E_L3, E_B3 @ u_hat_B3_limited)\n    \n    u_h_l3_after = eval_legendre(coeffs_l3_limited, x_eval)\n    min_after = np.min(u_h_l3_after)\n    results.append(f\"{min_after:.6f}\")\n\n    # --- Test 4 (n=4) ---\n    n4 = 4\n    U4 = 0.8\n    coeffs_l4 = np.array([0.3, 0.9, -0.2, 0.1, 0.5])\n    \n    t_nodes4 = np.linspace(0, 1, n4 + 1)\n    x_nodes4 = 2 * t_nodes4 - 1\n    E_L4 = get_eval_matrix(n4, 'legendre', x_nodes4)\n    E_B4 = get_eval_matrix(n4, 'bernstein', t_nodes4)\n    \n    u_hat_B4 = np.linalg.solve(E_B4, E_L4 @ coeffs_l4)\n    u_hat_B4_limited = np.clip(u_hat_B4, 0, U4)\n    coeffs_l4_limited = np.linalg.solve(E_L4, E_B4 @ u_hat_B4_limited)\n    \n    u_h_l4_limited = eval_legendre(coeffs_l4_limited, x_eval)\n    is_nonnegative = np.all(u_h_l4_limited >= -1e-9)\n    is_bounded = np.all(u_h_l4_limited <= U4 + 1e-9)\n    results.append(is_nonnegative)\n    results.append(is_bounded)\n    \n    # --- Test 5 (n=0) ---\n    n5 = 0\n    coeffs_l5 = np.array([-0.2])\n    \n    # For n=0, the transformation is trivial. u_hat_B = u_hat_L\n    u_hat_B5_limited = np.maximum(0, coeffs_l5)\n    coeffs_l5_limited = u_hat_B5_limited\n\n    u_h_l5_limited = eval_legendre(coeffs_l5_limited, x_eval)\n    min_after_5 = np.min(u_h_l5_limited)\n    results.append(f\"{min_after_5:.6f}\")\n\n    # Final print statement\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3409697"}]}