{"hands_on_practices": [{"introduction": "This practice explores the theoretical limits of Strong Stability Preserving (SSP) linear multistep methods (LMMs) [@problem_id:3420318]. By formulating the search for the optimal SSP coefficient as a linear programming problem, you will engage directly with the fundamental constraints of consistency and non-negativity that define these schemes. This exercise reveals a crucial theoretical barrier and provides insight into why achieving high SSP coefficients often requires more complex formulations than simple LMMs.", "problem": "Consider a method-of-lines semi-discretization of a scalar hyperbolic conservation law by a Discontinuous Galerkin (DG) spatial discretization that is monotone under Forward Euler time stepping with time step bound $h \\leq h_{\\mathrm{FE}}$. That is, for the semi-discrete system $\\frac{\\mathrm{d}}{\\mathrm{d}t} y(t) = f(y(t))$, the Forward Euler update $y^{n+1} = y^{n} + h f(y^{n})$ is monotone for $h \\leq h_{\\mathrm{FE}}$. An explicit $3$-step linear multistep method is of the form\n$$\ny^{n+1} = a_{0} y^{n} + a_{1} y^{n-1} + a_{2} y^{n-2} + h\\big(b_{0} f(y^{n}) + b_{1} f(y^{n-1}) + b_{2} f(y^{n-2})\\big).\n$$\nThe strong stability preserving (SSP) coefficient $C$ of this method is the largest value such that the method is monotone under the CFL-like restriction $h \\leq C\\,h_{\\mathrm{FE}}$, provided the method can be written as a convex combination of Forward Euler steps applied to previously available solution values. Under the sufficient SSP conditions that the coefficients associated with convex combination and Forward Euler substeps are nonnegative, the method must satisfy $a_{j} \\geq 0$, $b_{j} \\geq 0$ for $j \\in \\{0,1,2\\}$, and there must exist $r \\geq 0$ such that $a_{j} - r b_{j} \\geq 0$ for $j \\in \\{0,1,2\\}$. Imposing first-order consistency by requiring exactness on $y(t) = 1$ and $y(t) = t$ gives the constraints $\\sum_{j=0}^{2} a_{j} = 1$ and $\\sum_{j=0}^{2} b_{j} = 1 + \\sum_{j=0}^{2} j a_{j}$.\n\nSet up the problem of finding the maximal SSP coefficient $C$ for this $3$-step, first-order explicit SSP linear multistep method as a linear program in the sense that for a fixed $r$, feasibility is determined by linear inequalities and equalities in the unknown coefficients. Then solve this optimization problem exactly to determine the maximal achievable $C$ under these nonnegativity and consistency constraints. Your final answer must be a single exact number. Do not round. Express the final answer without units.", "solution": "The problem asks for the maximal strong stability preserving (SSP) coefficient $C$ for a class of $3$-step explicit linear multistep methods. The method must be first-order consistent and satisfy a set of sufficient conditions for being SSP.\n\nFirst, we formalize the optimization problem. The variables are the method coefficients $a_0, a_1, a_2, b_0, b_1, b_2$ and the SSP coefficient $C$. We seek to maximize $C$ subject to the given constraints.\n\nThe method is given by:\n$$ y^{n+1} = \\sum_{j=0}^{2} a_{j} y^{n-j} + h\\sum_{j=0}^{2} b_{j} f(y^{n-j}) $$\n\nThe constraints are:\n1.  First-order consistency:\n    a. Exactness on $y(t) = 1$: $\\sum_{j=0}^{2} a_{j} = 1$. Let's label this (C1).\n    b. Exactness on $y(t) = t$: $\\sum_{j=0}^{2} b_{j} = 1 + \\sum_{j=0}^{2} j a_{j} = 1 + a_1 + 2a_2$. Let's label this (C2).\n\n2.  Sufficient SSP conditions:\n    a. Non-negativity of coefficients in the convex combination: $a_{j} \\geq 0$ for $j \\in \\{0,1,2\\}$. Let's label this (S1).\n    b. Non-negativity of coefficients for Forward Euler steps: $b_{j} \\geq 0$ for $j \\in \\{0,1,2\\}$. Let's label this (S2).\n    c. The existence of a parameter $r \\geq 0$ such that $a_{j} - r b_{j} \\geq 0$ for $j \\in \\{0,1,2\\}$. This parameter $r$ is the SSP coefficient, which we denote by $C$. So, $a_j - C b_j \\ge 0$ for $j \\in \\{0,1,2\\}$, and we seek to maximize $C \\geq 0$. Let's label this (S3).\n\nThe problem asks to formulate this as a linear program for a fixed value of the SSP coefficient, denoted as $r$ in the problem description. Let us fix $C = C_{\\text{fixed}} > 0$. The problem then becomes a feasibility problem: to find if there exist coefficients $\\{a_j, b_j\\}_{j=0}^2$ that satisfy all the constraints. This can be expressed as a linear program by setting an arbitrary constant objective function, e.g., maximizing $0$.\n\nThe linear program for a fixed $C_{\\text{fixed}}$ is:\nFind $a_0, a_1, a_2, b_0, b_1, b_2$.\nObjective: Maximize $0$.\nSubject to:\n- $a_0 + a_1 + a_2 = 1$\n- $b_0 + b_1 + b_2 - a_1 - 2 a_2 = 1$\n- $a_j \\geq 0$ for $j \\in \\{0, 1, 2\\}$\n- $b_j \\geq 0$ for $j \\in \\{0, 1, 2\\}$\n- $a_j - C_{\\text{fixed}} b_j \\geq 0$ for $j \\in \\{0, 1, 2\\}$\n\nThe overall goal is to find the maximum value of $C$ for which this linear program is feasible. We can solve this optimization problem analytically.\n\nLet's combine the constraints to derive an upper bound on $C$.\nFrom (S3), we have $a_j \\geq C b_j$ for each $j \\in \\{0, 1, 2\\}$.\nSumming this inequality over $j=0, 1, 2$:\n$$ \\sum_{j=0}^{2} a_j \\geq \\sum_{j=0}^{2} C b_j = C \\sum_{j=0}^{2} b_j $$\nNow, we substitute the consistency conditions (C1) and (C2) into this inequality:\n$$ 1 \\geq C (1 + a_1 + 2a_2) $$\nSince we are maximizing $C$, we can assume $C > 0$. For this inequality to hold, we must have $1 + a_1 + 2a_2 > 0$. The condition (S1) requires $a_1 \\geq 0$ and $a_2 \\geq 0$, so this is always satisfied.\nWe can rearrange the inequality to find an upper bound for $C$:\n$$ C \\leq \\frac{1}{1 + a_1 + 2a_2} $$\nThis inequality must be satisfied by any method of the given form. To find the maximum possible value of $C$, we must find the tightest possible upper bound. This is achieved by maximizing the expression on the right-hand side, which is equivalent to minimizing its denominator, $g(a_1, a_2) = 1 + a_1 + 2a_2$.\n\nThe minimization of $g(a_1, a_2)$ is subject to the constraints on the coefficients $a_j$. From (S1), we have $a_1 \\geq 0$ and $a_2 \\geq 0$. From (C1) and (S1), we have $a_0 = 1 - a_1 - a_2 \\geq 0$, which implies $a_1 + a_2 \\leq 1$.\nThe domain for the variables $(a_1, a_2)$ is a closed and bounded triangle in the plane with vertices at $(0,0)$, $(1,0)$, and $(0,1)$. The function $g(a_1, a_2)$ is a linear function of $a_1$ and $a_2$. The minimum of a linear function over a convex polygon must occur at one of its vertices. We evaluate $g$ at each vertex:\n- At $(a_1, a_2) = (0,0)$: $g(0,0) = 1 + 0 + 2(0) = 1$.\n- At $(a_1, a_2) = (1,0)$: $g(1,0) = 1 + 1 + 2(0) = 2$.\n- At $(a_1, a_2) = (0,1)$: $g(0,1) = 1 + 0 + 2(1) = 3$.\n\nThe minimum value of the denominator $1 + a_1 + 2a_2$ is $1$, which occurs when $a_1 = 0$ and $a_2 = 0$.\nSubstituting this minimum value into the inequality for $C$, we obtain the maximal possible value for the upper bound:\n$$ C \\leq \\frac{1}{1} = 1 $$\nThis demonstrates that no method within the specified class can have an SSP coefficient greater than $1$.\n\nTo prove that $1$ is indeed the maximum achievable SSP coefficient, we must show that there exists a set of coefficients $\\{a_j, b_j\\}$ that satisfies all the given conditions for $C=1$. Let's try to construct such a method using the values that yielded the upper bound:\nSet $C=1$. From our minimization, we should choose $a_1=0$ and $a_2=0$.\nFrom (C1), $a_0 = 1 - a_1 - a_2 = 1 - 0 - 0 = 1$.\nSo, we have $a_0 = 1, a_1 = 0, a_2 = 0$.\n\nNow we must find coefficients $b_j$ that satisfy the remaining constraints:\n- (S2): $b_j \\geq 0$ for $j \\in \\{0, 1, 2\\}$.\n- (S3) with $C=1$: $a_j \\geq b_j$.\n    - For $j=0$: $1 \\geq b_0$.\n    - For $j=1$: $0 \\geq b_1$.\n    - For $j=2$: $0 \\geq b_2$.\n- (C2): $\\sum_{j=0}^{2} b_j = 1 + a_1 + 2a_2 = 1 + 0 + 2(0) = 1$.\n\nFrom $b_1 \\geq 0$ and $0 \\geq b_1$, we must have $b_1 = 0$.\nSimilarly, from $b_2 \\geq 0$ and $0 \\geq b_2$, we must have $b_2 = 0$.\nSubstituting these into the sum from (C2):\n$b_0 + 0 + 0 = 1 \\implies b_0 = 1$.\n\nLet's verify this set of coefficients: $a_0=1, a_1=0, a_2=0$ and $b_0=1, b_1=0, b_2=0$, with $C=1$.\n- (C1): $1+0+0 = 1$. (OK)\n- (C2): $1+0+0 = 1$ and $1+0+2(0)=1$. (OK)\n- (S1): $a_j \\geq 0$. (OK)\n- (S2): $b_j \\geq 0$. (OK)\n- (S3): $a_0 - Cb_0 = 1 - 1(1) = 0 \\geq 0$. $a_1 - Cb_1 = 0 - 1(0) = 0 \\geq 0$. $a_2 - Cb_2 = 0 - 1(0) = 0 \\geq 0$. (OK)\n\nAll conditions are satisfied. The method corresponding to these coefficients is:\n$$ y^{n+1} = 1 \\cdot y^n + h(1 \\cdot f(y^n)) = y^n + hf(y^n) $$\nThis is the Forward Euler method. By the definition of the problem, Forward Euler is monotone for $h \\leq h_{\\mathrm{FE}}$, which means its SSP coefficient is $C=1$.\n\nSince we have shown that $C \\leq 1$ for any method in the specified class and we have explicitly constructed a method for which $C=1$, the maximal achievable SSP coefficient is $1$.", "answer": "$$\n\\boxed{1}\n$$", "id": "3420318"}, {"introduction": "This practice bridges theory with application by analyzing the stability of a discontinuous Galerkin (DG) discretization of the linear advection equation [@problem_id:3420323]. You will perform a von Neumann analysis to contrast the stability limit imposed by a classical high-order Runge-Kutta method's linear stability region with the limit dictated by the SSP property of an SSP-RK method. This comparison is critical for understanding which constraint—linear stability or monotonicity preservation—is the active one, a key consideration in choosing a time-stepper for hyperbolic problems.", "problem": "Consider the one-dimensional linear advection initial value problem $u_{t} + a\\,u_{x} = 0$ with constant advection speed $a > 0$ on a periodic domain partitioned into a uniform mesh of cells of size $h$. Discretize the spatial operator by the Discontinuous Galerkin (DG) method with piecewise constant ($p=0$) basis functions and the upwind numerical flux. Let $u_{j}(t)$ denote the cell average in cell $j$, and define the nondimensional Courant–Friedrichs–Lewy (CFL) number $\\nu = \\frac{a\\,\\Delta t}{h}$ where $\\Delta t$ is the time step.\n\n1. Starting from conservation and the DG weak form, derive the semi-discrete evolution equation for $u_{j}(t)$, and perform a von Neumann analysis with the Fourier ansatz $u_{j}(t) = \\hat{u}(t)\\,\\exp(i\\,j\\,\\theta)$ where $\\theta \\in [0,2\\pi]$ is the nondimensional wavenumber. Obtain the Fourier symbol $\\lambda(\\theta)$ of the semi-discrete operator such that $\\frac{d}{dt}\\hat{u}(t) = \\lambda(\\theta)\\,\\hat{u}(t)$.\n\n2. For time integration by the classical four-stage, fourth-order explicit Runge–Kutta method (RK$(4,4)$), whose linear stability function is the degree $4$ Taylor polynomial of the exponential,\n$$\np(z) = 1 + z + \\frac{z^{2}}{2} + \\frac{z^{3}}{6} + \\frac{z^{4}}{24},\n$$\ndetermine the maximal $\\nu$ such that $|p(\\Delta t\\,\\lambda(\\theta))| \\leq 1$ holds for all $\\theta \\in [0,2\\pi]$.\n\n3. Independently, determine the forward Euler monotonicity bound on $\\nu$ for the semi-discrete DG operator from the requirement that the update coefficients remain nonnegative. Using the definition of Strong Stability Preserving (SSP) methods, recall that the three-stage, third-order SSP Runge–Kutta method (SSP RK$(3,3)$) has SSP coefficient $C=1$, so its allowable time step is bounded by the forward Euler limit. Compute the SSP-limited maximal $\\nu$ for SSP RK$(3,3)$.\n\nReport the active CFL limit as the minimum of the two bounds:\n$$\n\\nu_{\\text{active}} = \\min\\left\\{\\nu_{\\text{RK}(4,4)},\\,\\nu_{\\text{SSP}(3,3)}\\right\\}.\n$$\nExpress $\\nu_{\\text{active}}$ as a pure number and round your answer to four significant figures.", "solution": "The solution is structured in three parts as requested:\n1.  Derivation of the semi-discrete operator and its Fourier symbol.\n2.  Calculation of the linear stability limit for the RK$(4,4)$ method.\n3.  Calculation of the Strong Stability Preserving (SSP) limit for the SSP RK$(3,3)$ method.\nFinally, the active CFL limit is determined as the minimum of these two bounds.\n\nPart 1: Semi-discretization and Fourier Symbol\n\nThe one-dimensional linear advection equation is\n$$\nu_{t} + a\\,u_{x} = 0\n$$\nwhere $a > 0$ is a constant advection speed. To derive the Discontinuous Galerkin (DG) semi-discretization, we multiply the PDE by a test function $v_h$ and integrate over a cell $I_j = [x_{j-1/2}, x_{j+1/2}]$ of size $h=x_{j+1/2}-x_{j-1/2}$.\n$$\n\\int_{I_j} \\frac{\\partial u_h}{\\partial t} v_h \\,dx + \\int_{I_j} a \\frac{\\partial u_h}{\\partial x} v_h \\,dx = 0\n$$\nHere, $u_h$ is the approximate solution from the DG function space. Integrating the spatial term by parts gives\n$$\n\\int_{I_j} \\frac{\\partial u_h}{\\partial t} v_h \\,dx + \\left[ a u_h v_h \\right]_{x_{j-1/2}}^{x_{j+1/2}} - \\int_{I_j} a u_h \\frac{\\partial v_h}{\\partial x} \\,dx = 0\n$$\nThis can be written as\n$$\n\\int_{I_j} \\frac{\\partial u_h}{\\partial t} v_h \\,dx + a u_h(x_{j+1/2}^-, t) v_h(x_{j+1/2}^-) - a u_h(x_{j-1/2}^+, t) v_h(x_{j-1/2}^+) - \\int_{I_j} a u_h \\frac{\\partial v_h}{\\partial x} \\,dx = 0\n$$\nwhere $u_h(x^\\pm)$ denotes the limit from the left/right of the interface. The discontinuous nature of $u_h$ at cell interfaces requires replacing the flux $a u_h$ with a single-valued numerical flux, denoted $\\widehat{f}(u^-, u^+)$. The weak form becomes\n$$\n\\int_{I_j} \\frac{\\partial u_h}{\\partial t} v_h \\,dx + \\widehat{f}_{j+1/2} v_h(x_{j+1/2}^-) - \\widehat{f}_{j-1/2} v_h(x_{j-1/2}^+) - \\int_{I_j} a u_h \\frac{\\partial v_h}{\\partial x} \\,dx = 0\n$$\nFor this problem, we use piecewise constant ($p=0$) basis and test functions. In cell $I_j$, the solution is $u_h(x,t) = u_j(t)$ (the cell average) and we choose the test function $v_h(x) = 1$. With constant basis functions, the derivative term $\\frac{\\partial v_h}{\\partial x}$ is zero. The weak form simplifies to\n$$\n\\int_{I_j} \\frac{d u_j(t)}{dt} (1) \\,dx + \\widehat{f}_{j+1/2} (1) - \\widehat{f}_{j-1/2} (1) = 0\n$$\n$$\nh \\frac{d u_j(t)}{dt} + \\widehat{f}_{j+1/2} - \\widehat{f}_{j-1/2} = 0\n$$\nThe problem specifies the upwind numerical flux. For $a>0$, the flux is determined by the \"upwind\" state, which is the state to the left of the interface. So, $\\widehat{f}(u^-, u^+) = a u^-$.\nAt interface $x_{j+1/2}$: $u^- = u_h(x_{j+1/2}^-) = u_j(t)$. The flux is $\\widehat{f}_{j+1/2} = a u_j(t)$.\nAt interface $x_{j-1/2}$: $u^- = u_h(x_{j-1/2}^-) = u_{j-1}(t)$. The flux is $\\widehat{f}_{j-1/2} = a u_{j-1}(t)$.\nSubstituting these fluxes into the equation yields the semi-discrete evolution equation for the cell average $u_j(t)$:\n$$\nh \\frac{d u_j(t)}{dt} + a u_j(t) - a u_{j-1}(t) = 0\n$$\n$$\n\\frac{d u_j(t)}{dt} = -\\frac{a}{h} \\left( u_j(t) - u_{j-1}(t) \\right)\n$$\nThis is the same semi-discretization as the first-order upwind finite difference method. To perform von Neumann analysis, we substitute the Fourier ansatz $u_j(t) = \\hat{u}(t)\\exp(i j \\theta)$, where $\\theta \\in [0, 2\\pi]$ is the nondimensional wavenumber.\n$$\n\\frac{d}{dt} \\left( \\hat{u}(t)\\exp(i j \\theta) \\right) = -\\frac{a}{h} \\left( \\hat{u}(t)\\exp(i j \\theta) - \\hat{u}(t)\\exp(i(j-1)\\theta) \\right)\n$$\nFactoring out common terms:\n$$\n\\exp(i j \\theta) \\frac{d\\hat{u}(t)}{dt} = -\\frac{a}{h} \\hat{u}(t)\\exp(i j \\theta) \\left( 1 - \\exp(-i\\theta) \\right)\n$$\nDividing by $\\exp(i j \\theta)$ gives the evolution equation for the Fourier mode amplitude $\\hat{u}(t)$:\n$$\n\\frac{d\\hat{u}(t)}{dt} = \\left[ -\\frac{a}{h} (1 - \\exp(-i\\theta)) \\right] \\hat{u}(t)\n$$\nThis is of the form $\\frac{d\\hat{u}(t)}{dt} = \\lambda(\\theta)\\hat{u}(t)$, where the Fourier symbol $\\lambda(\\theta)$ is:\n$$\n\\lambda(\\theta) = -\\frac{a}{h} (1 - \\exp(-i\\theta)) = -\\frac{a}{h} (1 - \\cos\\theta + i\\sin\\theta)\n$$\n\nPart 2: RK(4,4) Linear Stability Limit\n\nFor a time-stepping method to be stable, the amplification factor must have a magnitude less than or equal to $1$. For an explicit Runge-Kutta method applied to $\\frac{dy}{dt} = \\lambda y$, the update is $y^{n+1} = p(\\Delta t \\lambda) y^n$, where $p(z)$ is the stability polynomial of the method and $z = \\Delta t \\lambda$. The stability condition is $|p(z)| \\leq 1$.\nThe argument $z$ for our problem is:\n$$\nz = \\Delta t \\lambda(\\theta) = \\Delta t \\left( -\\frac{a}{h} (1 - \\exp(-i\\theta)) \\right) = -\\frac{a \\Delta t}{h} (1 - \\exp(-i\\theta)) = -\\nu (1 - \\exp(-i\\theta))\n$$\nwhere $\\nu = \\frac{a \\Delta t}{h}$ is the CFL number. The locus of $z(\\theta)$ for $\\theta \\in [0, 2\\pi]$ is a circle in the complex plane centered at $-\\nu$ with radius $\\nu$. This circle passes through the origin $z=0$ (for $\\theta=0$) and has its leftmost point at $z=-2\\nu$ (for $\\theta=\\pi$).\n\nFor the scheme to be stable, this entire circular locus must lie within the stability region of the RK$(4,4)$ method, which is the set of complex numbers $z$ where $|p(z)| \\leq 1$ for\n$$\np(z) = 1 + z + \\frac{z^{2}}{2} + \\frac{z^{3}}{6} + \\frac{z^{4}}{24}\n$$\nThe stability of the locus is typically limited by its intersection with the negative real axis. We find the extent of the RK$(4,4)$ stability region on the negative real axis. For $z=x$ real and negative, the stability condition $|p(x)| \\leq 1$ becomes $-1 \\leq p(x) \\leq 1$.\nA plot of $p(x)$ for $x0$ reveals it starts at $p(0)=1$, decreases to a minimum, and then increases. The minimum value is positive, so the condition simplifies to $p(x) \\leq 1$.\n$$\n1 + x + \\frac{x^{2}}{2} + \\frac{x^{3}}{6} + \\frac{x^{4}}{24} \\leq 1\n$$\n$$\nx + \\frac{x^{2}}{2} + \\frac{x^{3}}{6} + \\frac{x^{4}}{24} \\leq 0\n$$\n$$\nx \\left( 1 + \\frac{x}{2} + \\frac{x^{2}}{6} + \\frac{x^{3}}{24} \\right) \\leq 0\n$$\nSince $x0$, we require the term in the parenthesis to be non-negative:\n$$\n1 + \\frac{x}{2} + \\frac{x^{2}}{6} + \\frac{x^{3}}{24} \\geq 0 \\quad \\text{or} \\quad x^3 + 4x^2 + 12x + 24 \\geq 0\n$$\nLet $g(x) = x^3 + 4x^2 + 12x + 24$. We must find the root $x_0$ of $g(x)=0$. Numerical root-finding yields $x_0 \\approx -2.78529$. Thus, the stability interval on the negative real axis is approximately $[-2.78529, 0]$.\nThe locus of $z(\\theta)$ must be contained in this region. The leftmost point of the locus is $-2\\nu$. So, we must satisfy:\n$$\n-2\\nu \\geq -2.78529 \\implies \\nu \\leq \\frac{2.78529}{2} \\approx 1.3926\n$$\nTherefore, the maximal CFL number for linear stability with RK$(4,4)$ is $\\nu_{\\text{RK}(4,4)} \\approx 1.3926$.\n\nPart 3: SSP RK(3,3) Limit\n\nFirst, we determine the forward Euler monotonicity bound. The forward Euler time integration of the semi-discrete scheme is:\n$$\nu_j^{n+1} = u_j^n + \\Delta t \\left( -\\frac{a}{h} (u_j^n - u_{j-1}^n) \\right) = u_j^n - \\nu (u_j^n - u_{j-1}^n)\n$$\n$$\nu_j^{n+1} = (1 - \\nu) u_j^n + \\nu u_{j-1}^n\n$$\nFor the scheme to be monotonicity-preserving, the new value $u_j^{n+1}$ must be a convex combination of values from the previous step. This requires the coefficients to be non-negative.\n1.  $\\nu \\geq 0$: Since $a>0$, $\\Delta t>0$, $h>0$, this is satisfied.\n2.  $1 - \\nu \\geq 0$: This implies $\\nu \\leq 1$.\n\nThe forward Euler monotonicity bound is therefore $\\nu_{\\text{FE}} = 1$.\nStrong Stability Preserving (SSP) methods are designed to preserve nonlinear stability properties (like monotonicity) of the forward Euler step, provided the time step is small enough. For an SSP method with SSP coefficient $C$, the stable time step $\\Delta t_{\\text{SSP}}$ is related to the forward Euler time step limit $\\Delta t_{\\text{FE}}$ by $\\Delta t_{\\text{SSP}} \\leq C \\Delta t_{\\text{FE}}$. In terms of CFL numbers, this is $\\nu_{\\text{SSP}} \\leq C \\nu_{\\text{FE}}$.\nThe problem states that the SSP RK$(3,3)$ method has an SSP coefficient of $C=1$. Thus, its SSP-limited CFL number is:\n$$\n\\nu_{\\text{SSP}(3,3)} = C \\cdot \\nu_{\\text{FE}} = 1 \\cdot 1 = 1\n$$\n\nFinal Calculation: Active CFL Limit\n\nThe active CFL limit is the most restrictive (smallest) of the bounds derived:\n$$\n\\nu_{\\text{active}} = \\min\\left\\{\\nu_{\\text{RK}(4,4)},\\,\\nu_{\\text{SSP}(3,3)}\\right\\}\n$$\n$$\n\\nu_{\\text{active}} = \\min\\left\\{1.3926...,\\,1\\right\\} = 1\n$$\nThe problem requires the answer to be rounded to four significant figures.\n$$\n\\nu_{\\text{active}} = 1.000\n$$\nThis result highlights that while the RK$(4,4)$ method has a larger linear stability region than the forward Euler method, the requirement to preserve monotonicity, as enforced by the SSP condition on the SSP RK$(3,3)$ method, imposes a stricter constraint on the time step.", "answer": "$$\\boxed{1.000}$$", "id": "3420323"}, {"introduction": "This hands-on exercise provides a direct, numerical demonstration of the practical benefits of SSP methods [@problem_id:3420259]. You will implement and compare an SSP Runge-Kutta scheme against a classical, non-SSP counterpart for solving the advection equation, focusing on the crucial property of being Total Variation Diminishing (TVD). By tracking the total variation of the solution, you will observe firsthand how SSP methods prevent the growth of spurious oscillations, a common challenge when numerically capturing sharp features.", "problem": "Consider the scalar linear advection equation on a periodic domain,\n$u_t + a\\,u_x = 0,$\nposed on the interval $[0,1]$ with periodic boundary conditions and constant advection speed $a>0$. Discretize the spatial domain into $N$ uniform cells of width $\\Delta x = \\frac{1}{N}$ and consider the Discontinuous Galerkin (DG) formulation with polynomial degree zero (piecewise constant basis), together with the upwind numerical flux. Derive the semi-discrete ordinary differential equation for the cell averages from the DG weak form using the following fundamental elements:\n- the definition of the DG method with piecewise constant basis functions,\n- the construction of numerical fluxes at cell interfaces consistent with upwinding for $a>0$,\n- periodic boundary conditions interpreted in the flux evaluation.\n\nUsing the derived semi-discrete operator, implement two explicit time integrators:\n- the Strong Stability Preserving Runge-Kutta method of order three with three stages (SSPRK($3,3$)), based on its property that it can be expressed as a convex combination of forward Euler steps when the forward Euler method is stable under a time-step restriction,\n- a comparable non-Strong Stability Preserving method, the classical fourth-order explicit Runge-Kutta method (RK4).\n\nDefine the discrete total variation of the cell averages at time $t^n$ as\n$$TV(u^n) = \\sum_{i=0}^{N-1} \\left|u_{i+1}^n - u_i^n\\right|,$$\nwith periodic indexing so that $u_N^n = u_0^n$.\n\nYour task is to numerically verify the Total Variation Diminishing (TVD) behavior for SSPRK($3,3$) and demonstrate a violation for RK4 by integrating the semi-discrete system forward in time. For each time step, compute $TV(u^n)$ and check that the sequence $\\{TV(u^n)\\}_{n\\ge 0}$ is nonincreasing, that is, $TV(u^{n+1}) \\le TV(u^n)$ up to a small numerical tolerance.\n\nUse the following test suite, each specified by $N$, the Courant number $\\nu = \\frac{a\\,\\Delta t}{\\Delta x}$ with $a=1$, the number of time steps $n_\\text{steps}$, and the initial data:\n- Test Case 1 (happy path with sharp discontinuity at coarse resolution): $N=50$, $\\nu=0.99$, $n_\\text{steps}=12$, initial data\n  $$u(x,0) = \\begin{cases}\n  0  \\text{if } x \\in [0,0.45),\\\\\n  1  \\text{if } x \\in [0.45,0.55),\\\\\n  0  \\text{if } x \\in [0.55,1),\n  \\end{cases}$$\n  interpreted cellwise with periodic boundary conditions.\n- Test Case 2 (moderate resolution square pulse): $N=200$, $\\nu=0.90$, $n_\\text{steps}=20$, initial data\n  $$u(x,0) = \\begin{cases}\n  1  \\text{if } x \\in [0.30,0.70),\\\\\n  0  \\text{otherwise},\n  \\end{cases}$$\n  interpreted cellwise with periodic boundary conditions.\n- Test Case 3 (three-level piecewise constant): $N=100$, $\\nu=1.00$, $n_\\text{steps}=15$, initial data\n  $$u(x,0) = \\begin{cases}\n  -0.5  \\text{if } x \\in [0.00,0.20),\\\\\n  1.0  \\text{if } x \\in [0.20,0.50),\\\\\n  0.0  \\text{if } x \\in [0.50,1.00),\n  \\end{cases}$$\n  interpreted cellwise with periodic boundary conditions.\n\nFor each test case, compute two boolean outputs:\n- a boolean indicating whether the SSPRK($3,3$) method produced a nonincreasing total variation sequence over all time steps,\n- a boolean indicating whether the RK4 method produced a nonincreasing total variation sequence over all time steps.\n\nThe final time step size must satisfy $\\Delta t = \\nu\\,\\Delta x/a$. The program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test result is a two-element list $[b_\\text{SSP}, b_\\text{RK4}]$. For the three test cases above, the final output format must be\n$[[b_{1,\\text{SSP}},b_{1,\\text{RK4}}],\\,[b_{2,\\text{SSP}},b_{2,\\text{RK4}}],\\,[b_{3,\\text{SSP}},b_{3,\\text{RK4}}]],$\nwith booleans printed in the language's native boolean literals. No physical units or angles are involved in this problem; all quantities are nondimensional.", "solution": "The problem is to numerically investigate the Total Variation Diminishing (TVD) property of two time integration schemes, SSPRK($3,3$) and classical RK4, when applied to a semi-discretization of the linear advection equation. The spatial discretization is a Discontinuous Galerkin (DG) method with piecewise constant basis functions ($p=0$) and an upwind flux.\n\n**1. Semi-Discretization using the Discontinuous Galerkin Method**\n\nThe governing partial differential equation (PDE) is the linear advection equation:\n$u_t + a\\,u_x = 0$\non the domain $[0,1]$ with periodic boundary conditions and constant advection speed $a>0$.\n\nThe domain is partitioned into $N$ cells $I_i = [x_{i-1/2}, x_{i+1/2}]$ for $i=0, \\dots, N-1$, each of width $\\Delta x = 1/N$. The cell interfaces are at $x_{i+1/2} = (i+1)\\Delta x$. Within each cell $I_i$, the solution is approximated by a piecewise constant function (polynomial degree $p=0$):\n$$\nu_h(x,t) = u_i(t) \\quad \\text{for } x \\in I_i\n$$\nThe value $u_i(t)$ represents the cell average of the solution in cell $I_i$.\n\nThe DG weak formulation is obtained by multiplying the PDE by a test function $v_h$, integrating over a cell $I_i$, and performing integration by parts on the spatial term:\n$$\n\\int_{I_i} (u_h)_t v_h \\,dx - \\int_{I_i} a\\,u_h (v_h)_x \\,dx + [a\\,u_h v_h]_{x_{i-1/2}}^{x_{i+1/2}} = 0\n$$\nSince the basis and test functions are piecewise constant, $(v_h)_x=0$ inside the cell. The equation simplifies to:\n$$\n\\int_{I_i} \\frac{du_i}{dt} v_h \\,dx + \\left( a\\,u_h(x_{i+1/2}, t)v_h(x_{i+1/2}^-) - a\\,u_h(x_{i-1/2}, t)v_h(x_{i-1/2}^+) \\right) = 0\n$$\nThe term $a\\,u_h$ at the cell interfaces is discontinuous and must be replaced by a single-valued numerical flux, denoted $\\hat{f}(u_L, u_R)$, where $u_L$ and $u_R$ are the states on the left and right of the interface, respectively. For the physical flux $f(u) = au$, the weak form becomes:\n$$\n\\int_{I_i} \\frac{du_i}{dt} v_h \\,dx + \\left( \\hat{f}(u_h(x_{i+1/2}^-), u_h(x_{i+1/2}^+)) v_h(x_{i+1/2}^-) - \\hat{f}(u_h(x_{i-1/2}^-), u_h(x_{i-1/2}^+)) v_h(x_{i-1/2}^+) \\right) = 0\n$$\nChoosing the test function $v_h$ to be $1$ in cell $I_i$ and $0$ elsewhere, we have $v_h(x_{i+1/2}^-) = 1$ and $v_h(x_{i-1/2}^+) = 1$. The integral of the time derivative is $\\Delta x \\frac{du_i}{dt}$. The states at the interfaces are $u_h(x_{i+1/2}^-) = u_i$, $u_h(x_{i+1/2}^+) = u_{i+1}$, $u_h(x_{i-1/2}^-) = u_{i-1}$, and $u_h(x_{i-1/2}^+) = u_i$. This leads to:\n$$\n\\Delta x \\frac{du_i}{dt} + \\hat{f}(u_i, u_{i+1}) - \\hat{f}(u_{i-1}, u_i) = 0\n$$\nThe problem specifies an upwind flux for $a > 0$, which is $\\hat{f}(u_L, u_R) = f(u_L) = a u_L$. Applying this to our interfaces:\n- At $x_{i+1/2}$: $\\hat{f}(u_i, u_{i+1}) = a u_i$.\n- At $x_{i-1/2}$: $\\hat{f}(u_{i-1}, u_i) = a u_{i-1}$.\n\nSubstituting these fluxes into the equation gives:\n$$\n\\Delta x \\frac{du_i}{dt} + a u_i - a u_{i-1} = 0\n$$\nRearranging, we obtain the semi-discrete system of ordinary differential equations (ODEs) for the cell averages:\n$$\n\\frac{du_i}{dt} = -\\frac{a}{\\Delta x} (u_i - u_{i-1})\n$$\nwith periodic indexing such that $u_{-1} \\equiv u_{N-1}$. This is the well-known first-order upwind finite difference scheme. We can write this system in vector form as $\\frac{d\\mathbf{u}}{dt} = L(\\mathbf{u})$, where $\\mathbf{u} = [u_0, u_1, \\dots, u_{N-1}]^T$ and $(L(\\mathbf{u}))_i = -\\frac{a}{\\Delta x} (u_i - u_{i-1})$.\n\n**2. Time Integration Schemes**\n\nThe forward Euler method applied to this system, $u_i^{n+1} = u_i^n + \\Delta t L(u^n)_i$, results in:\n$$\nu_i^{n+1} = u_i^n - \\frac{a \\Delta t}{\\Delta x}(u_i^n - u_{i-1}^n) = (1-\\nu)u_i^n + \\nu u_{i-1}^n\n$$\nwhere $\\nu = \\frac{a \\Delta t}{\\Delta x}$ is the Courant number. This scheme is TVD if $0 \\le \\nu \\le 1$.\n\n**a) Strong Stability Preserving Runge-Kutta (SSPRK(3,3))**\nThis third-order, three-stage method is designed to preserve stability properties like TVD of the forward Euler method. Its formulation is:\n$$\n\\mathbf{u}^{(1)} = \\mathbf{u}^n + \\Delta t L(\\mathbf{u}^n)\n$$\n$$\n\\mathbf{u}^{(2)} = \\frac{3}{4} \\mathbf{u}^n + \\frac{1}{4} \\left( \\mathbf{u}^{(1)} + \\Delta t L(\\mathbf{u}^{(1)}) \\right)\n$$\n$$\n\\mathbf{u}^{n+1} = \\frac{1}{3} \\mathbf{u}^n + \\frac{2}{3} \\left( \\mathbf{u}^{(2)} + \\Delta t L(\\mathbf{u}^{(2)}) \\right)\n$$\nSSPRK($3,3$) can be viewed as a convex combination of forward Euler steps. It is TVD if the forward Euler method is TVD and the time step satisfies $\\Delta t \\le C \\cdot \\Delta t_{\\text{FE,TVD}}$, where $C$ is the SSP coefficient. For this scheme, $C=1$. Therefore, SSPRK($3,3$) is expected to be TVD for our semi-discretization whenever $\\nu \\le 1$. All test cases satisfy this condition.\n\n**b) Classical Fourth-Order Runge-Kutta (RK4)**\nThe standard RK4 method is given by:\n$$\n\\mathbf{k}_1 = L(\\mathbf{u}^n)\n$$\n$$\n\\mathbf{k}_2 = L(\\mathbf{u}^n + \\frac{\\Delta t}{2} \\mathbf{k}_1)\n$$\n$$\n\\mathbf{k}_3 = L(\\mathbf{u}^n + \\frac{\\Delta t}{2} \\mathbf{k}_2)\n$$\n$$\n\\mathbf{k}_4 = L(\\mathbf{u}^n + \\Delta t \\mathbf{k}_3)\n$$\n$$\n\\mathbf{u}^{n+1} = \\mathbf{u}^n + \\frac{\\Delta t}{6} (\\mathbf{k}_1 + 2\\mathbf{k}_2 + 2\\mathbf{k}_3 + \\mathbf{k}_4)\n$$\nRK4 is not an SSP method. It is not guaranteed to be TVD for nonlinear problems or even for linear problems with non-smooth solutions, as it can introduce spurious oscillations near discontinuities, which increases the total variation.\n\n**3. Total Variation and Numerical Verification**\n\nThe discrete total variation is defined as:\n$$\nTV(\\mathbf{u}^n) = \\sum_{i=0}^{N-1} |u_{i+1}^n - u_i^n|\n$$\nwhere periodic indexing implies $u_N^n = u_0^n$. A scheme is TVD if $TV(\\mathbf{u}^{n+1}) \\le TV(\\mathbf{u}^n)$ for all $n$. For the numerical verification, we will check this condition at each time step for both SSPRK($3,3$) and RK4. Due to floating-point arithmetic, the check is implemented as $TV(\\mathbf{u}^{n+1}) \\le TV(\\mathbf{u}^n) + \\epsilon$, where $\\epsilon$ is a small tolerance (e.g., $10^{-12}$). A boolean flag for each method will record whether the TVD property holds for the entire simulation.\n\nThe implementation will proceed by defining the initial conditions for each test case, setting up the spatial operator $L(\\mathbf{u})$, and then iterating for the specified number of steps with each time integration scheme, checking the total variation at each step.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by running three test cases to verify the TVD property\n    of SSPRK(3,3) and the violation of this property by RK4 for a DG-discretized\n    advection equation.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"N\": 50, \"nu\": 0.99, \"n_steps\": 12,\n            \"u0_func\": lambda x: np.where((x = 0.45)  (x  0.55), 1.0, 0.0)\n        },\n        {\n            \"N\": 200, \"nu\": 0.90, \"n_steps\": 20,\n            \"u0_func\": lambda x: np.where((x = 0.30)  (x  0.70), 1.0, 0.0)\n        },\n        {\n            \"N\": 100, \"nu\": 1.00, \"n_steps\": 15,\n            \"u0_func\": lambda x: np.select(\n                [x  0.20, (x = 0.20)  (x  0.50), x = 0.50],\n                [-0.5, 1.0, 0.0]\n            )\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        N = params[\"N\"]\n        nu = params[\"nu\"]\n        n_steps = params[\"n_steps\"]\n        u0_func = params[\"u0_func\"]\n        \n        # SSPRK(3,3) and RK4 have different stability regions for advection.\n        # However, the problem sets nu = 1, which for the first-order upwind\n        # operator is within the stability regions of both methods.\n        b_ssp, b_rk4 = run_test_case(N, nu, n_steps, u0_func)\n        results.append([b_ssp, b_rk4])\n\n    # Convert native Python bools to lowercase strings for the final output.\n    # The problem description's example `[b_SSP, b_RK4]` suggests a list of lists of booleans,\n    # which in Python's f-string formatting would be `[[True, False], ...]`.\n    # Let's adjust to match the required `print` format.\n    formatted_results = [f\"[{str(r[0])}, {str(r[1])}]\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n\ndef get_spatial_operator(a, dx):\n    \"\"\"Returns the spatial operator L(u) for the semi-discretization.\"\"\"\n    def L(u):\n        # u_i - u_{i-1} with periodic boundaries\n        diff = u - np.roll(u, 1)\n        return -a / dx * diff\n    return L\n    \ndef total_variation(u):\n    \"\"\"Computes the total variation of a 1D array with periodic boundaries.\"\"\"\n    return np.sum(np.abs(u - np.roll(u, -1)))\n\ndef run_test_case(N, nu, n_steps, u0_func):\n    \"\"\"\n    Runs a single test case for both SSPRK(3,3) and RK4, checking the TVD property.\n\n    Returns:\n        A tuple of two booleans: (ssp_is_tvd, rk4_is_tvd)\n    \"\"\"\n    a = 1.0\n    dx = 1.0 / N\n    dt = nu * dx / a\n\n    # Define cell centers and initial condition\n    x = (np.arange(N) + 0.5) * dx\n    u0 = u0_func(x)\n\n    L = get_spatial_operator(a, dx)\n    \n    # Tolerance for floating point comparison of TV\n    tolerance = 1e-12\n\n    # --- SSPRK(3,3) Simulation ---\n    u_ssp = u0.copy()\n    ssp_is_tvd = True\n    tv_old = total_variation(u_ssp)\n    for _ in range(n_steps):\n        # SSPRK(3,3) steps\n        u1 = u_ssp + dt * L(u_ssp)\n        u2 = 0.75 * u_ssp + 0.25 * (u1 + dt * L(u1))\n        u_ssp = (1/3.0) * u_ssp + (2/3.0) * (u2 + dt * L(u2))\n        \n        tv_new = total_variation(u_ssp)\n        if tv_new  tv_old + tolerance:\n            ssp_is_tvd = False\n        tv_old = tv_new\n\n    # --- RK4 Simulation ---\n    u_rk4 = u0.copy()\n    rk4_is_tvd = True\n    tv_old = total_variation(u_rk4)\n    for _ in range(n_steps):\n        # RK4 steps\n        k1 = L(u_rk4)\n        k2 = L(u_rk4 + 0.5 * dt * k1)\n        k3 = L(u_rk4 + 0.5 * dt * k2)\n        k4 = L(u_rk4 + dt * k3)\n        u_rk4 = u_rk4 + (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n        \n        tv_new = total_variation(u_rk4)\n        if tv_new  tv_old + tolerance:\n            rk4_is_tvd = False\n        tv_old = tv_new\n        \n    return ssp_is_tvd, rk4_is_tvd\n\nsolve()\n```", "id": "3420259"}]}