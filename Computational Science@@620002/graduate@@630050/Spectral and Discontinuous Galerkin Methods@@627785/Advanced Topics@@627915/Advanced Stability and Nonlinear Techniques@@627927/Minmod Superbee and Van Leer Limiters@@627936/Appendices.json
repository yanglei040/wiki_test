{"hands_on_practices": [{"introduction": "To build a solid foundation, we begin with the core mechanics of how limiters function. This practice focuses on the flux limiter function, $\\phi(r)$, which is the engine that allows a numerical scheme to adapt its behavior from diffusive to compressive. By computing values for the classic van Leer limiter at specific smoothness ratios, you will gain a tangible understanding of how these functions intelligently control numerical diffusion to preserve sharp features without introducing spurious oscillations [@problem_id:3399885].", "problem": "Consider the one-dimensional linear advection equation $u_{t} + a\\,u_{x} = 0$ for constant wave speed $a>0$, discretized by a Discontinuous Galerkin (DG) method on a uniform mesh. To suppress non-physical oscillations while preserving sharp gradients, apply a Total Variation Diminishing (TVD) slope limiter to the reconstructed linear solution in each cell. Let the slope update be defined by a flux limiter function $\\phi(r)$ acting on the ratio $r$ of successive undivided differences of the cellwise linear reconstructions, where $r$ is given by $r = \\Delta u_{i-1/2} / \\Delta u_{i+1/2}$ with $\\Delta u_{i\\pm 1/2}$ representing consistent interface differences that respect the upwind direction. Assume the limiter is the standard van Leer TVD limiter used in high-resolution finite volume and DG methods and that $r$ is computed from data in three different local neighborhoods yielding $r=0.5$, $r=1$, and $r=2$.\n\nStarting from the TVD framework for flux limiters and without assuming any ad hoc shortcut formulas, compute the values of the van Leer limiter $\\phi_{\\mathrm{VL}}(r)$ at $r=0.5$, $r=1$, and $r=2$. Then, critically interpret how these values reflect the transition between diffusive behavior (smoothing small gradients) and compressive behavior (preserving or sharpening large gradients) in the DG reconstruction, in relation to the behavior of the minmod and superbee limiters.\n\nExpress your final answer as a row matrix containing the three values $\\phi_{\\mathrm{VL}}(0.5)$, $\\phi_{\\mathrm{VL}}(1)$, and $\\phi_{\\mathrm{VL}}(2)$, in that order. No rounding is required and no units are involved.", "solution": "The user wants to solve a problem related to slope limiters in Discontinuous Galerkin (DG) methods.\n\n**1. Problem Validation**\n\nFirst, I will validate the provided problem statement.\n\n**Step 1: Extract Givens**\n\n*   **Governing Equation:** One-dimensional linear advection equation, $u_{t} + a\\,u_{x} = 0$, with constant wave speed $a>0$.\n*   **Numerical Method:** A Discontinuous Galerkin (DG) method on a uniform mesh, with a Total Variation Diminishing (TVD) slope limiter applied to a \"reconstructed linear solution in each cell.\" This implies the use of piecewise linear polynomials ($P^1$), which constitutes a second-order scheme.\n*   **Limiter Function:** The slope update is defined by a flux limiter function $\\phi(r)$.\n*   **Smoothness Ratio:** The ratio is given by $r = \\Delta u_{i-1/2} / \\Delta u_{i+1/2}$, where $\\Delta u_{i\\pm 1/2}$ are \"consistent interface differences that respect the upwind direction.\"\n*   **Specific Limiter:** The van Leer TVD limiter, denoted $\\phi_{\\mathrm{VL}}(r)$.\n*   **Input Data:** The ratio $r$ takes on three values: $r=0.5$, $r=1$, and $r=2$.\n*   **Tasks:**\n    1.  Compute the values of the van Leer limiter $\\phi_{\\mathrm{VL}}(r)$ for the given values of $r$. The computation should start from the TVD framework.\n    2.  Interpret these values in the context of diffusive vs. compressive behavior, and in relation to the minmod and superbee limiters.\n*   **Output Format:** A row matrix containing the three computed values for $\\phi_{\\mathrm{VL}}(0.5)$, $\\phi_{\\mathrm{VL}}(1)$, and $\\phi_{\\mathrm{VL}}(2)$.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientific Grounding:** The problem is firmly established in the field of numerical analysis for hyperbolic partial differential equations. The linear advection equation, Discontinuous Galerkin methods, TVD property, and slope/flux limiters (van Leer, minmod, superbee) are standard and fundamental concepts in high-resolution schemes.\n*   **Well-Posedness:** The problem is well-posed. The van Leer limiter is a uniquely defined mathematical function. The task is to evaluate this function at specific points and provide a standard interpretation based on established theory. A unique and meaningful solution exists.\n*   **Objectivity:** The problem is stated in precise, objective, and technical language, free from any subjective or biased phrasing.\n\nThe problem does not exhibit any of the invalidity flaws:\n1.  It is scientifically and factually sound.\n2.  It is directly formalizable and relevant to the specified topic.\n3.  The setup is complete. Although the explicit formula for $\\phi_{\\mathrm{VL}}(r)$ is not given, the problem directs the solver to start from the TVD framework, implying the formula is to be recalled or justified based on its properties, which is standard practice for this level of analysis. The phrase \"first-order Discontinuous Galerkin (DG) method\" combined with \"reconstructed linear solution\" is a common, if slightly imprecise, way to refer to a DG($P^1$) scheme, which is internally consistent.\n4.  The conditions are not unrealistic or infeasible.\n5.  The problem is not ill-posed.\n6.  The problem is not trivial; it requires a solid understanding of the theory of numerical schemes for conservation laws.\n7.  The results are mathematically verifiable.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. I will proceed with the solution.\n\n**2. Solution Derivation**\n\nThe problem addresses the application of a slope limiter within a high-order numerical method for the linear advection equation $u_t + a u_x = 0$. The goal of such limiters is to ensure the scheme is Total Variation Diminishing (TVD), meaning it does not introduce new spurious oscillations, while retaining high-order accuracy in smooth regions of the solution.\n\nIn the context of a DG or finite volume method using piecewise linear reconstructions, the solution in a computational cell $I_i = [x_{i-1/2}, x_{i+1/2}]$ is represented by its cell average $\\bar{u}_i$ and a slope. The scheme achieves second-order accuracy but can produce over- and undershoots near sharp gradients. To prevent this, the initially computed slope is modified or \"limited\".\n\nThis limiting process is often conveniently expressed using a flux limiter function $\\phi(r)$. The function $\\phi$ modulates the contribution of higher-order terms based on the local smoothness of the solution, which is measured by the ratio $r_i$ of successive solution gradients. For a uniform mesh and $a>0$ (upwind direction is from left to right), the ratio is typically defined using the cell averages as:\n$$r_i = \\frac{\\bar{u}_i - \\bar{u}_{i-1}}{\\bar{u}_{i+1} - \\bar{u}_i}$$\nFor a scheme to be TVD, the limiter function $\\phi(r)$ must satisfy certain conditions for $r>0$. These conditions define the \"TVD region\" in the $(\\phi, r)$ plane, first described by Sweby:\n$$0 \\le \\phi(r) \\le 2$$\n$$0 \\le \\frac{\\phi(r)}{r} \\le 2 \\quad \\implies \\quad \\phi(r) \\le 2r$$\nTo prevent the creation of new local extrema, it is also required that $\\phi(r) = 0$ for $r \\le 0$.\n\nThe van Leer limiter, $\\phi_{\\mathrm{VL}}(r)$, is a classic choice for $\\phi(r)$ that provides a smooth transition and balances accuracy with robustness. Its definition is derived to be a symmetric and smooth function that lies within the TVD region. The standard analytical form for the van Leer limiter is:\n$$\\phi_{\\mathrm{VL}}(r) = \\frac{r + |r|}{1+|r|}$$\nFor the cases specified in the problem, $r > 0$, so $|r|=r$. The formula simplifies to:\n$$\\phi_{\\mathrm{VL}}(r) = \\frac{r + r}{1+r} = \\frac{2r}{1+r} \\quad \\text{for } r > 0$$\nThis function satisfies the TVD conditions for $r>0$:\n1.  $r>0 \\implies 2r > 0$ and $1+r > 1$, so $\\phi_{\\mathrm{VL}}(r) > 0$. Also, $2r < 2(1+r) \\implies \\frac{2r}{1+r} < 2$. Thus, $0 \\le \\phi_{\\mathrm{VL}}(r) \\le 2$.\n2.  $\\frac{\\phi_{\\mathrm{VL}}(r)}{r} = \\frac{2}{1+r}$. For $r>0$, we have $1+r > 1$, which implies $0 < \\frac{2}{1+r} < 2$. Thus, $0 \\le \\frac{\\phi_{\\mathrm{VL}}(r)}{r} \\le 2$.\n\nNow, we compute the values of $\\phi_{\\mathrm{VL}}(r)$ for the given inputs.\n\nFor $r=0.5$:\n$$\\phi_{\\mathrm{VL}}(0.5) = \\frac{2 \\times 0.5}{1 + 0.5} = \\frac{1}{1.5} = \\frac{1}{3/2} = \\frac{2}{3}$$\n\nFor $r=1$:\n$$\\phi_{\\mathrm{VL}}(1) = \\frac{2 \\times 1}{1 + 1} = \\frac{2}{2} = 1$$\n\nFor $r=2$:\n$$\\phi_{\\mathrm{VL}}(2) = \\frac{2 \\times 2}{1 + 2} = \\frac{4}{3}$$\n\n**3. Interpretation and Comparison**\n\nThe value of $\\phi(r)$ determines the character of the numerical scheme at a local level.\n-   $\\phi(r)=0$ reduces the scheme to first-order (e.g., upwind), which is highly diffusive.\n-   $\\phi(r)=1$ corresponds to a \"linear\" or non-limited second-order scheme (e.g., Lax-Wendroff type), which is accuracy-preserving in smooth regions.\n-   $0 < \\phi(r) < 1$ indicates that the scheme is more diffusive than the baseline second-order scheme.\n-   $\\phi(r) > 1$ implies \"compressive\" or \"anti-diffusive\" behavior, where the limiter attempts to steepen gradients, which is desirable for resolving sharp features like contact discontinuities.\n\nLet's analyze the computed values in comparison to two other well-known limiters: the highly diffusive `minmod` limiter and the highly compressive `superbee` limiter.\n-   **Minmod:** $\\phi_{\\mathrm{min}}(r) = \\max(0, \\min(1, r))$\n-   **Superbee:** $\\phi_{\\mathrm{sup}}(r) = \\max(0, \\min(2r, 1), \\min(r, 2))$\n\n**Case 1: $r=0.5$**\nThis ratio value indicates that the upstream gradient $(\\bar{u}_i - \\bar{u}_{i-1})$ is half the size of the downstream gradient $(\\bar{u}_{i+1} - \\bar{u}_i)$. This typically occurs near a smooth extremum or where a wave is broadening.\n-   $\\phi_{\\mathrm{VL}}(0.5) = 2/3 \\approx 0.67$. This value is less than $1$, indicating diffusive behavior. The limiter reduces the slope to prevent overshoot, but not as aggressively as `minmod`.\n-   For comparison: $\\phi_{\\mathrm{min}}(0.5) = 0.5$ (more diffusive), and $\\phi_{\\mathrm{sup}}(0.5) = \\max(0, \\min(1,1), \\min(0.5,2)) = 1$ (no diffusion added relative to the second-order scheme).\n-   The van Leer limiter finds a middle ground, smoothing the profile more gently than `minmod`.\n\n**Case 2: $r=1$**\nThis corresponds to a region of constant gradient, i.e., a perfectly smooth, linear profile.\n-   $\\phi_{\\mathrm{VL}}(1) = 1$. The limiter makes no modification to the slope.\n-   This is a key property of any second-order TVD scheme: on a perfectly linear profile, the scheme must be second-order accurate. Both `minmod` ($\\phi_{\\mathrm{min}}(1)=1$) and `superbee` ($\\phi_{\\mathrm{sup}}(1)=1$) also yield $1$ at $r=1$.\n\n**Case 3: $r=2$**\nThis ratio indicates that the gradient is steepening in the direction of the flow, which is characteristic of the region at the foot of a shock or a sharp front.\n-   $\\phi_{\\mathrm{VL}}(2) = 4/3 \\approx 1.33$. This value is greater than $1$, demonstrating the **compressive** nature of the van Leer limiter. It actively steepens the wave front to counteract numerical diffusion, leading to sharper profiles for discontinuities.\n-   For comparison: $\\phi_{\\mathrm{min}}(2) = \\min(1, 2) = 1$ (non-compressive, clips at the second-order contribution), and $\\phi_{\\mathrm{sup}}(2) = \\max(0, \\min(4,1), \\min(2,2)) = 2$ (maximally compressive, sitting on the upper boundary of the TVD region).\n-   Here, the van Leer limiter is more aggressive than `minmod` in preserving sharpness but less so than `superbee`, which can sometimes lead to an overly steep, \"boxy\" representation of profiles.\n\nIn summary, the three computed values illustrate how the van Leer limiter adeptly transitions from a diffusive character $(\\phi<1)$ in regions of decreasing gradients to a compressive character $(\\phi>1)$ in areas of increasing gradients, while preserving second-order accuracy $(\\phi=1)$ in smooth, linear regions. This balanced approach is why it is a widely used and effective limiter.\n\nThe required final answer is the set of computed values for $\\phi_{\\mathrm{VL}}(r)$.\n$\\phi_{\\mathrm{VL}}(0.5) = 2/3$\n$\\phi_{\\mathrm{VL}}(1) = 1$\n$\\phi_{\\mathrm{VL}}(2) = 4/3$\n\nThese are to be presented in a row matrix.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2}{3} & 1 & \\frac{4}{3}\n\\end{pmatrix}\n}\n$$", "id": "3399885"}, {"introduction": "Moving beyond linear reconstructions, modern high-order methods like Discontinuous Galerkin (DG) represent solutions with higher-degree polynomials, and their corresponding modes must also be controlled to ensure robustness. This exercise demonstrates how to apply the limiting concept to a second-degree ($P^2$) polynomial by constraining its curvature, which is represented by the second Legendre mode [@problem_id:3399846]. You will derive the connection between the abstract modal coefficient and a physical measure of curvature from neighboring cell data, a key technique in developing limiters for high-order schemes.", "problem": "Consider a one-dimensional Discontinuous Galerkin (DG) approximation of a smooth scalar field on a uniform mesh with cell size $h = 1$. On a given cell indexed by $i$, the approximate solution in the mapped reference coordinate $\\xi \\in [-1,1]$ is represented in a hierarchical modal basis using Legendre polynomials as\n$$\nu_i(\\xi) = \\bar{u}_i + a_1 L_1(\\xi) + a_2 L_2(\\xi),\n$$\nwhere $L_0(\\xi) = 1$, $L_1(\\xi) = \\xi$, and $L_2(\\xi) = \\frac{3\\xi^2 - 1}{2}$. The given modal coefficients are $\\bar{u}_i = 1.2$, $a_1 = 0.3$, and $a_2 = -0.05$. The neighboring cell averages are $\\bar{u}_{i-1} = 0.9$ and $\\bar{u}_{i+1} = 1.35$.\n\nYou will apply a minmod-based limiter to the second mode $a_2$ only, using a curvature proxy constructed from neighboring cell averages. Specifically:\n\n1. Begin from the definition of the minmod function for two arguments $a$ and $b$,\n$$\n\\operatorname{minmod}(a,b) = \n\\begin{cases}\n\\operatorname{sign}(a)\\,\\min(|a|,|b|), & \\text{if } \\operatorname{sign}(a) = \\operatorname{sign}(b),\\\\\n0, & \\text{otherwise},\n\\end{cases}\n$$\nand the affine mapping between physical and reference coordinates $x = x_i + \\frac{h}{2}\\,\\xi$.\n\n2. Using only first principles for the chosen basis, derive the proportionality constant $\\kappa$ relating the second modal coefficient $a_2$ to the physical second derivative $u_{xx}$ on the cell, and then relate $a_2$ to the discrete second difference of neighboring cell averages\n$$\n\\Delta^2 \\bar{u}_i = \\bar{u}_{i+1} - 2\\bar{u}_i + \\bar{u}_{i-1}.\n$$\nExpress this relationship in the form $a_2 \\approx \\kappa\\,\\Delta^2 \\bar{u}_i$ and determine $\\kappa$ analytically.\n\n3. Compute the limited second-mode coefficient\n$$\na_2^{\\mathrm{lim}} = \\operatorname{minmod}\\!\\big(a_2,\\;\\kappa\\,\\Delta^2 \\bar{u}_i\\big),\n$$\nand form the limited polynomial\n$$\nu_i^{\\mathrm{lim}}(\\xi) = \\bar{u}_i + a_1 L_1(\\xi) + a_2^{\\mathrm{lim}} L_2(\\xi).\n$$\n\n4. Evaluate $u_i^{\\mathrm{lim}}(\\xi)$ at the Gauss–Lobatto points for polynomial degree $p=2$, namely at $\\xi = -1$, $\\xi = 0$, and $\\xi = 1$, and report the three values in a single row matrix.\n\nProvide your final answer as a row matrix containing the three values of the limited polynomial at the Gauss–Lobatto points. Do not include units. If you choose to express any intermediate numerical values, use exact decimals; no rounding is required.", "solution": "The problem is first validated by extracting all given information and assessing its scientific soundness and formal structure.\n\n### Step 1: Extract Givens\n- **Method:** One-dimensional Discontinuous Galerkin (DG) approximation.\n- **Mesh:** Uniform mesh with cell size $h = 1$.\n- **Cell:** Indexed by $i$.\n- **Reference Coordinate:** $\\xi \\in [-1,1]$.\n- **Basis:** Hierarchical modal basis using Legendre polynomials.\n- **Solution Representation:** $u_i(\\xi) = \\bar{u}_i + a_1 L_1(\\xi) + a_2 L_2(\\xi)$.\n- **Legendre Polynomials:** $L_0(\\xi) = 1$, $L_1(\\xi) = \\xi$, and $L_2(\\xi) = \\frac{3\\xi^2 - 1}{2}$.\n- **Modal Coefficients:** $\\bar{u}_i = 1.2$, $a_1 = 0.3$, $a_2 = -0.05$.\n- **Neighboring Cell Averages:** $\\bar{u}_{i-1} = 0.9$, $\\bar{u}_{i+1} = 1.35$.\n- **Minmod Function:** $\\operatorname{minmod}(a,b) = \\begin{cases} \\operatorname{sign}(a)\\,\\min(|a|,|b|), & \\text{if } \\operatorname{sign}(a) = \\operatorname{sign}(b),\\\\ 0, & \\text{otherwise}. \\end{cases}$\n- **Coordinate Mapping:** $x = x_i + \\frac{h}{2}\\,\\xi$, where $x_i$ is the center of cell $i$.\n- **Discrete Second Difference:** $\\Delta^2 \\bar{u}_i = \\bar{u}_{i+1} - 2\\bar{u}_i + \\bar{u}_{i-1}$.\n- **Limiter Definition:** $a_2^{\\mathrm{lim}} = \\operatorname{minmod}\\!\\big(a_2,\\;\\kappa\\,\\Delta^2 \\bar{u}_i\\big)$.\n- **Limited Polynomial:** $u_i^{\\mathrm{lim}}(\\xi) = \\bar{u}_i + a_1 L_1(\\xi) + a_2^{\\mathrm{lim}} L_2(\\xi)$.\n- **Evaluation Points:** Gauss-Lobatto points for polynomial degree $p=2$, which are $\\xi = -1, 0, 1$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is firmly based on established principles of numerical methods for partial differential equations, specifically high-order Discontinuous Galerkin methods and slope/curvature limiting techniques. The use of Legendre polynomials, minmod limiters, and finite difference approximations for derivatives are standard practices in this field.\n- **Well-Posed:** All necessary data and definitions are provided. The problem is self-contained and leads to a unique, meaningful solution.\n- **Objective:** The problem is stated using precise mathematical language, free from any subjective or ambiguous terminology.\n\n### Step 3: Verdict and Action\nThe problem is valid as it is scientifically sound, well-posed, and objective. A solution will be provided.\n\n---\n\nThe solution proceeds by first deriving the proportionality constant $\\kappa$, then applying the limiter to the second-mode coefficient $a_2$, and finally evaluating the resulting limited polynomial at the specified points.\n\n**1. Derivation of the Proportionality Constant $\\kappa$**\n\nThe goal is to find the relationship between the modal coefficient $a_2$ and the discrete second difference of cell averages, $\\Delta^2 \\bar{u}_i$. This is achieved by relating both quantities to the physical second derivative of the solution, $u_{xx}$.\n\nFirst, we relate $a_2$ to $u_{xx}$. The mapping from the reference coordinate $\\xi$ to the physical coordinate $x$ is given by $x = x_i + \\frac{h}{2}\\xi$. We use the chain rule to relate derivatives with respect to $x$ and $\\xi$:\n$$\n\\frac{d}{dx} = \\frac{d\\xi}{dx}\\frac{d}{d\\xi}\n$$\nFrom the mapping, we have $\\frac{dx}{d\\xi} = \\frac{h}{2}$, so $\\frac{d\\xi}{dx} = \\frac{2}{h}$. The second derivative is then:\n$$\n\\frac{d^2}{dx^2} = \\frac{d}{dx}\\left(\\frac{2}{h}\\frac{d}{d\\xi}\\right) = \\frac{2}{h}\\frac{d\\xi}{dx}\\frac{d}{d\\xi}\\left(\\frac{d}{d\\xi}\\right) = \\left(\\frac{2}{h}\\right)^2 \\frac{d^2}{d\\xi^2} = \\frac{4}{h^2}\\frac{d^2}{d\\xi^2}\n$$\nThe solution representation within the cell is $u_i(\\xi) = \\bar{u}_i + a_1 L_1(\\xi) + a_2 L_2(\\xi) = \\bar{u}_i + a_1 \\xi + a_2 \\frac{3\\xi^2 - 1}{2}$. We compute its second derivative with respect to $\\xi$:\n$$\n\\frac{du_i}{d\\xi} = a_1 + a_2 (3\\xi) = a_1 + 3a_2\\xi\n$$\n$$\n\\frac{d^2u_i}{d\\xi^2} = 3a_2\n$$\nSubstituting this into the expression for the physical second derivative $u_{xx}$:\n$$\nu_{xx} = \\frac{4}{h^2}\\frac{d^2u_i}{d\\xi^2} = \\frac{4}{h^2}(3a_2) = \\frac{12a_2}{h^2}\n$$\nThis gives the exact second derivative of the polynomial approximation within the cell. Solving for $a_2$:\n$$\na_2 = \\frac{h^2}{12}u_{xx}\n$$\nNext, we approximate the physical second derivative $u_{xx}$ at the cell center $x_i$ using a second-order centered finite difference on the cell-average values:\n$$\nu_{xx}(x_i) \\approx \\frac{\\bar{u}_{i-1} - 2\\bar{u}_i + \\bar{u}_{i+1}}{h^2} = \\frac{\\Delta^2 \\bar{u}_i}{h^2}\n$$\nBy equating the continuous-in-cell second derivative with its discrete approximation across cells, we establish the desired relationship for $a_2$:\n$$\na_2 \\approx \\frac{h^2}{12} \\left( \\frac{\\Delta^2 \\bar{u}_i}{h^2} \\right) = \\frac{1}{12}\\Delta^2 \\bar{u}_i\n$$\nFrom the problem statement's form $a_2 \\approx \\kappa\\,\\Delta^2 \\bar{u}_i$, we identify the proportionality constant:\n$$\n\\kappa = \\frac{1}{12}\n$$\nThe problem specifies $h=1$, which was used implicitly in the derivation. This result is independent of $h$.\n\n**2. Computation of the Limited Coefficient $a_2^{\\mathrm{lim}}$**\n\nWe now compute the two arguments for the minmod function. The first argument is the original coefficient $a_2 = -0.05$. The second argument is $\\kappa\\,\\Delta^2 \\bar{u}_i$. First, we compute $\\Delta^2 \\bar{u}_i$:\n$$\n\\Delta^2 \\bar{u}_i = \\bar{u}_{i+1} - 2\\bar{u}_i + \\bar{u}_{i-1} = 1.35 - 2(1.2) + 0.9 = 1.35 - 2.4 + 0.9 = -0.15\n$$\nNow we compute the second argument:\n$$\n\\kappa\\,\\Delta^2 \\bar{u}_i = \\frac{1}{12} (-0.15) = -\\frac{0.15}{12} = -0.0125\n$$\nNow, we apply the minmod function to find the limited coefficient $a_2^{\\mathrm{lim}}$:\n$$\na_2^{\\mathrm{lim}} = \\operatorname{minmod}(a_2, \\kappa\\,\\Delta^2 \\bar{u}_i) = \\operatorname{minmod}(-0.05, -0.0125)\n$$\nSince both arguments are negative, their signs are equal. Thus,\n$$\na_2^{\\mathrm{lim}} = \\operatorname{sign}(-0.05) \\min(|-0.05|, |-0.0125|) = -1 \\min(0.05, 0.0125) = -0.0125\n$$\n\n**3. Evaluation of the Limited Polynomial**\n\nThe limited polynomial is given by:\n$$\nu_i^{\\mathrm{lim}}(\\xi) = \\bar{u}_i + a_1 L_1(\\xi) + a_2^{\\mathrm{lim}} L_2(\\xi)\n$$\nSubstituting the known values and expressions for the Legendre polynomials:\n$$\nu_i^{\\mathrm{lim}}(\\xi) = 1.2 + 0.3\\xi -0.0125\\left(\\frac{3\\xi^2 - 1}{2}\\right)\n$$\nWe evaluate this polynomial at the Gauss-Lobatto points for $p=2$, which are $\\xi = -1, 0, 1$.\n\n- For $\\xi = -1$:\n$$\nu_i^{\\mathrm{lim}}(-1) = 1.2 + 0.3(-1) - 0.0125\\left(\\frac{3(-1)^2 - 1}{2}\\right) = 1.2 - 0.3 - 0.0125\\left(\\frac{3 - 1}{2}\\right) = 0.9 - 0.0125(1) = 0.8875\n$$\n\n- For $\\xi = 0$:\n$$\nu_i^{\\mathrm{lim}}(0) = 1.2 + 0.3(0) - 0.0125\\left(\\frac{3(0)^2 - 1}{2}\\right) = 1.2 - 0.0125\\left(-\\frac{1}{2}\\right) = 1.2 + 0.00625 = 1.20625\n$$\n\n- For $\\xi = 1$:\n$$\nu_i^{\\mathrm{lim}}(1) = 1.2 + 0.3(1) - 0.0125\\left(\\frac{3(1)^2 - 1}{2}\\right) = 1.2 + 0.3 - 0.0125\\left(\\frac{3 - 1}{2}\\right) = 1.5 - 0.0125(1) = 1.4875\n$$\n\nThe three values of the limited polynomial at the specified points are $0.8875$, $1.20625$, and $1.4875$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.8875 & 1.20625 & 1.4875 \\end{pmatrix}}\n$$", "id": "3399846"}, {"introduction": "In computational science, an effective algorithm must be not only mathematically sound but also computationally efficient. This advanced practice bridges the gap between numerical theory and high-performance computing by tasking you with reformulating TVD limiters into \"branchless\" expressions suitable for parallel architectures like GPUs [@problem_id:3399817]. By translating conditional logic into pure arithmetic, you will learn a crucial optimization technique that minimizes thread divergence and unlocks significant performance gains in large-scale simulations.", "problem": "You are asked to derive and implement branchless formulations of three Total Variation Diminishing (TVD) limiters—minmod, superbee, and van Leer—in the setting of Spectral Methods and Discontinuous Galerkin (DG) methods for one-dimensional scalar conservation laws, and to compare branch behavior against conventional branching implementations using an abstract Graphics Processing Unit (GPU) warp divergence model. Your final answer must be a complete, runnable program, which constructs the requested outputs for the specified test suite.\n\nThe fundamental base is as follows.\n\n- Consider a one-dimensional scalar conservation law $u_t + f(u)_x = 0$ with a spatial semi-discretization by a Discontinuous Galerkin method (DG). The DG scheme represents the solution by piecewise polynomials on a mesh and couples elements via numerical fluxes evaluated on interfaces. To ensure stability and prevent spurious oscillations near discontinuities, slope limiting is applied to local polynomial reconstructions using local one-sided differences.\n- A limiter $L(a,b)$ operates on two one-sided slopes $a$ and $b$ (e.g., the backward and forward difference of a reconstructed quantity at a cell center). TVD limiters enforce non-increasing total variation and are defined by monotonicity and boundedness properties consistent with the well-tested Sweby diagram constraints.\n- The minmod limiter enforces a bounded slope in the direction of increasing values while suppressing spurious oscillations. The superbee limiter is a more compressive TVD limiter that retains sharp discontinuities while remaining TVD. The van Leer limiter is a smooth TVD limiter derived from a flux-limiter function $\\phi(r)$ in terms of the slope ratio $r$.\n\nYour task is to perform the following steps:\n\n1. Starting from the TVD limiter properties for $L(a,b)$ that enforce monotonicity, sign consistency, and boundedness by the smaller of one-sided magnitudes when $a$ and $b$ have the same sign, derive branchless, arithmetic-only forms using the absolute value function $|x|$ and the sign function $\\operatorname{sign}(x)$. Your derivations must be logically consistent with the TVD monotonicity constraints and must avoid providing case-by-case branching or piecewise definitions. You are not allowed to start from or quote pre-existing branchless formulas; instead, derive them from the core TVD properties, sign-consistency, and bounding arguments.\n2. Construct a conventional branching implementation for each limiter based on fundamental monotonicity rules and logical case distinctions consistent with TVD limiters. This may involve comparisons such as $a \\, b \\le 0$ and nested selection of minima and maxima.\n3. Define an abstract GPU warp divergence metric for branching implementations. A warp has size $W$, and within a warp, divergence occurs at a branch decision if threads do not all take the same branch outcome. You must:\n   - Use warp size $W = 32$.\n   - For the minmod limiter, count a single decision point per element corresponding to whether $a \\, b \\le 0$.\n   - For the superbee limiter, count four decision points per element: the initial decision whether $a \\, b \\le 0$, two decisions to select the minima in $\\min(2|a|,|b|)$ and $\\min(|a|,2|b|)$, and one decision to select the maximum between those two minima.\n   - For the van Leer limiter, count two decision points per element: a decision whether $b=0$ and a decision on the sign of the slope ratio $r$ (equivalently, whether $r \\le 0$).\n   - Define the warp divergence fraction for a limiter as the fraction of warps that diverge on at least one of that limiter’s decision points. For decisions that are not executed by some elements in a warp due to an earlier branch outcome, restrict the divergence check to the subset of elements that reach the decision; if no elements in the warp reach a decision, that decision contributes no divergence for that warp.\n4. Performance proxy. Instead of measuring time, count the branch decision density per element, defined as the number of decision points per element for the branching implementation. The branchless implementations must have zero branch decision points. This is a deterministic proxy to compare branching versus branchless formulations.\n5. Numerical equivalence. For each limiter, compute the maximum absolute difference between the outputs of the branchless and branching implementations across each test case to quantify numerical equivalence.\n\nImplement your program to compute the above metrics for the following four test cases. In all cases, construct arrays of slopes $a_i$ and $b_i$ from a discrete field $u_i$ by backward and forward differences, respectively. Let $N = 128$ be the number of interior points so that array lengths are $N$, and define a grid of length $N+2$ for $u_i$. Use warp size $W = 32$.\n\n- Test Case 1 (Smooth): $u_i = \\sin(2\\pi x_i)$ with $x_i$ uniformly spaced in the unit interval $[0,1]$ including endpoints. Construct $a_i = u_i - u_{i-1}$ and $b_i = u_{i+1} - u_i$ for $i=1,\\dots,N$.\n- Test Case 2 (Shock): $u_i$ is a step function $u_i = 0$ for $x_i < 0.5$ and $u_i = 1$ for $x_i \\ge 0.5$ with $x_i$ as above. Construct $a_i$ and $b_i$ as in Test Case 1.\n- Test Case 3 (Mixed Random): $u_i$ drawn from a zero-mean normal distribution with unit variance, using a fixed seed to enforce determinism. Construct $a_i$ and $b_i$ as in Test Case 1.\n- Test Case 4 (Extremes): $u_i$ cyclically repeats the pattern $[0, 10^{-12}, 10^{6}, -10^{6}]$ until length $N+2$, then truncate to length $N+2$. Construct $a_i$ and $b_i$ as in Test Case 1.\n\nAngle units are not applicable. There are no physical units. All outputs must be pure numbers.\n\nFinal Output Format:\n- For each test case, you must produce a list of $15$ floating-point numbers in the following order:\n  1. $D_{\\mathrm{mm}}$: warp divergence fraction for the branching minmod limiter.\n  2. $D_{\\mathrm{sb}}$: warp divergence fraction for the branching superbee limiter.\n  3. $D_{\\mathrm{vl}}$: warp divergence fraction for the branching van Leer limiter.\n  4. $D_{\\mathrm{mm}}^{\\mathrm{bl}}$: warp divergence fraction for the branchless minmod limiter (must be $0$).\n  5. $D_{\\mathrm{sb}}^{\\mathrm{bl}}$: warp divergence fraction for the branchless superbee limiter (must be $0$).\n  6. $D_{\\mathrm{vl}}^{\\mathrm{bl}}$: warp divergence fraction for the branchless van Leer limiter (must be $0$).\n  7. $B_{\\mathrm{mm}}$: branch decision density per element for the branching minmod limiter (must be $1$).\n  8. $B_{\\mathrm{sb}}$: branch decision density per element for the branching superbee limiter (must be $4$).\n  9. $B_{\\mathrm{vl}}$: branch decision density per element for the branching van Leer limiter (must be $2$).\n  10. $B_{\\mathrm{mm}}^{\\mathrm{bl}}$: branch decision density per element for the branchless minmod limiter (must be $0$).\n  11. $B_{\\mathrm{sb}}^{\\mathrm{bl}}$: branch decision density per element for the branchless superbee limiter (must be $0$).\n  12. $B_{\\mathrm{vl}}^{\\mathrm{bl}}$: branch decision density per element for the branchless van Leer limiter (must be $0$).\n  13. $E_{\\mathrm{mm}}$: maximum absolute difference between branchless and branching minmod outputs across the test case.\n  14. $E_{\\mathrm{sb}}$: maximum absolute difference between branchless and branching superbee outputs across the test case.\n  15. $E_{\\mathrm{vl}}$: maximum absolute difference between branchless and branching van Leer outputs across the test case.\n- Your program should produce a single line of output containing the results as a comma-separated list of the four per-test-case lists, enclosed in square brackets with no spaces, for example, `[[...],[...],[...],[...]]`.", "solution": "The problem statement has been meticulously reviewed and is determined to be **valid**. It is scientifically grounded in the established theory of numerical methods for conservation laws, specifically concerning Total Variation Diminishing (TVD) limiters. The problem is well-posed, with all necessary parameters, definitions, and test cases provided. The objectives are clear, quantitative, and free from ambiguity. The proposed abstract model for GPU warp divergence is a reasonable simplification for analyzing computational performance, and the overall task is a standard exercise in high-performance scientific computing.\n\n### Derivation of Branchless Limiter Formulations\n\nA TVD limiter function $L(a, b)$ takes two adjacent slope values, $a$ and $b$, and returns a limited slope. To prevent the creation of new extrema and ensure monotonicity, the limiter must satisfy several properties. The derivation of the branchless forms for the minmod, superbee, and van Leer limiters will be based on these fundamental properties.\n\nThe two core principles are:\n1.  **Sign Consistency**: If the slopes $a$ and $b$ have opposite signs or one is zero (i.e., $ab \\le 0$), a new local extremum is imminent. To prevent this, the limited slope must be zero: $L(a, b) = 0$.\n2.  **Monotonicity Bounding**: If the slopes $a$ and $b$ have the same sign (i.e., $ab > 0$), the limited slope must also have that same sign and its magnitude must be appropriately bounded. The specific bound determines the character of the limiter.\n\nA crucial component for a branchless formulation is an arithmetic expression that is zero when signs of $a$ and $b$ differ and reproduces the common sign when they are the same. Let $s_a = \\operatorname{sign}(a)$ and $s_b = \\operatorname{sign}(b)$. The expression $\\frac{s_a + s_b}{2}$ serves this purpose perfectly:\n$$\n\\frac{\\operatorname{sign}(a) + \\operatorname{sign}(b)}{2} = \\begin{cases}\n\\operatorname{sign}(a) & \\text{if } \\operatorname{sign}(a) = \\operatorname{sign}(b) \\ne 0 \\\\\n0 & \\text{if } \\operatorname{sign}(a) = -\\operatorname{sign}(b) \\ne 0 \\\\\n\\pm 1/2 & \\text{if one is zero} \\\\\n0 & \\text{if } a=b=0\n\\end{cases}\n$$\nThis factor, which we will denote as $S(a,b)$, elegantly handles the sign-consistency requirement. A slightly more robust version that is strictly $\\{0, \\pm 1\\}$ is needed, but the principle holds. A squared version, $(\\frac{\\operatorname{sign}(a) + \\operatorname{sign}(b)}{2})^2$ or equivalently $\\frac{1+\\operatorname{sign}(ab)}{2}$ for non-zero $a,b$, can serve as a switch, being $1$ if signs match and $0$ otherwise.\n\n**1. Minmod Limiter**\n\nThe minmod limiter is defined to select the slope with the minimum magnitude when signs are consistent, to be the most dissipative (least compressive) TVD limiter.\n-   **Definition**: $L_{\\text{mm}}(a, b) = \\begin{cases} \\operatorname{sign}(a) \\min(|a|, |b|) & \\text{if } ab > 0 \\\\ 0 & \\text{if } ab \\le 0 \\end{cases}$.\n-   **Derivation**: We can combine the cases using the sign-factor $S(a,b)$. The magnitude part is given by $\\min(|a|, |b|)$. The full limiter can be expressed as the product of the sign factor and the magnitude.\n    $$\n    L_{\\text{mm}}(a, b) = S(a,b) \\cdot \\text{magnitude} = \\frac{\\operatorname{sign}(a) + \\operatorname{sign}(b)}{2} \\min(|a|, |b|)\n    $$\n    This formula is branchless, relying only on arithmetic operations, the sign function, the absolute value function, and the minimum function, which is typically implemented as a branchless conditional move instruction on modern processors.\n\n**2. Superbee Limiter**\n\nThe superbee limiter is more compressive than minmod, aiming to preserve sharp features. It selects a slope magnitude that is the maximum of two minimum-bounded values.\n-   **Definition**: $L_{\\text{sb}}(a, b) = \\begin{cases} \\operatorname{sign}(a) \\max(\\min(2|a|, |b|), \\min(|a|, 2|b|)) & \\text{if } ab > 0 \\\\ 0 & \\text{if } ab \\le 0 \\end{cases}$.\n-   **Derivation**: The derivation is analogous to that of the minmod limiter. The same sign-handling factor $S(a,b)$ is used to enforce the $L(a,b)=0$ condition for $ab \\le 0$. The magnitude part is simply replaced with the superbee-specific term.\n    $$\n    L_{\\text{sb}}(a, b) = \\frac{\\operatorname{sign}(a) + \\operatorname{sign}(b)}{2} \\max(\\min(2|a|, |b|), \\min(|a|, 2|b|))\n    $$\n    This formulation is also branchless, using the same set of arithmetic and intrinsic functions.\n\n**3. Van Leer Limiter**\n\nThe van Leer limiter is a smooth limiter. Its symmetric form is the harmonic mean of the two slopes.\n-   **Definition**: $L_{\\text{vl}}(a, b) = \\begin{cases} \\frac{2ab}{a+b} & \\text{if } ab > 0 \\\\ 0 & \\text{if } ab \\le 0 \\end{cases}$.\n-   **Derivation**: We need a branchless formula that calculates $\\frac{2ab}{a+b}$ when $ab>0$ and $0$ otherwise, while being robust against division by zero. The condition $ab > 0$ implies $a$ and $b$ share the same sign, so $a+b \\neq 0$ unless $a=b=0$. Let's construct a formula that works for all cases.\n    Consider the expression $\\frac{ab(\\operatorname{sign}(a)+\\operatorname{sign}(b))}{|a|+|b|}$.\n    - If $a > 0$ and $b > 0$: $\\frac{ab(1+1)}{a+b} = \\frac{2ab}{a+b}$. Correct.\n    - If $a < 0$ and $b < 0$: $\\frac{ab(-1-1)}{-a-b} = \\frac{-2ab}{-(a+b)} = \\frac{2ab}{a+b}$. Correct.\n    - If $ab \\le 0$: At least one of $\\operatorname{sign}(a)$ and $\\operatorname{sign}(b)$ is not equal to the other. If they are opposite, $\\operatorname{sign}(a)+\\operatorname{sign}(b)=0$, yielding a result of $0$. If one is zero, say $a=0$, the numerator is $0$, again yielding $0$. Correct.\n    The only point of failure is if $|a|+|b|=0$, which happens only if $a=0$ and $b=0$. In this case, the numerator is also $0$, leading to a $0/0$ indeterminacy. The correct limit is $0$. A numerically robust implementation will handle this. The derived branchless formula is:\n    $$\n    L_{\\text{vl}}(a, b) = \\frac{ab(\\operatorname{sign}(a) + \\operatorname{sign}(b))}{|a|+|b|}\n    $$\n\n### Branching Implementations and Performance Metrics\n\nFor comparison, conventional branching implementations are constructed following their standard definitions using explicit conditional logic.\n\n- **Branching Minmod**: `if a * b <= 0: return 0.0 else: return sign(a) * min(abs(a), abs(b))`\n- **Branching Superbee**: `if a * b <= 0: return 0.0 else: return sign(a) * max(min(2*abs(a), abs(b)), min(abs(a), 2*abs(b)))`\n- **Branching Van Leer**: To match the problem's divergence model, a ratio-based implementation is used: `if b_val == 0.0: return 0.0 else: r = a_val / b_val; if r <= 0.0: return 0.0 else: return b_val * (2*r / (1+r))`\n\nThe problem defines two performance-related metrics:\n- **Branch Decision Density ($B$)**: A deterministic count of the number of logical branches per element in the branching implementations, as specified in the problem ($B_{\\mathrm{mm}}=1$, $B_{\\mathrm{sb}}=4$, $B_{\\mathrm{vl}}=2$). For branchless versions, this is always $0$.\n- **Warp Divergence Fraction ($D$)**: An abstract performance metric for SIMD architectures like GPUs. A warp of size $W=32$ is a group of threads executing in lockstep. Divergence occurs at a branch if threads within the same warp take different paths. The fraction $D$ is the ratio of warps exhibiting divergence to the total number of warps. For nested branches, divergence is checked only among the subset of threads that reach the inner branch. By definition, branchless implementations have $D=0$.\n\nThe numerical equivalence ($E$) is measured by the maximum absolute difference between the outputs of the branching and branchless implementations for each test case.\n$$\nE = \\max_{i} | L_{\\text{branching}}(a_i, b_i) - L_{\\text{branchless}}(a_i, b_i) |\n$$\nThe following program implements these functions and computes the specified metrics for the given test suite.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives, implements, and compares branchless and branching TVD limiters.\n    \"\"\"\n    # --- Problem Parameters ---\n    N = 128  # Number of interior points\n    W = 32   # GPU warp size\n\n    # --- Branchless Limiter Implementations ---\n    def minmod_bl(a, b):\n        \"\"\"Branchless minmod limiter.\"\"\"\n        s = np.sign(a) + np.sign(b)\n        return 0.5 * s * np.minimum(np.abs(a), np.abs(b))\n\n    def superbee_bl(a, b):\n        \"\"\"Branchless superbee limiter.\"\"\"\n        s = np.sign(a) + np.sign(b)\n        abs_a, abs_b = np.abs(a), np.abs(b)\n        mag = np.maximum(np.minimum(2 * abs_a, abs_b), np.minimum(abs_a, 2 * abs_b))\n        return 0.5 * s * mag\n\n    def vanleer_bl(a, b):\n        \"\"\"Branchless van Leer limiter.\"\"\"\n        num = a * b * (np.sign(a) + np.sign(b))\n        den = np.abs(a) + np.abs(b)\n        # Use np.divide for safe division, returns 0 where den is 0\n        return np.divide(num, den, out=np.zeros_like(a), where=den != 0)\n\n    # --- Branching Limiter Implementations (for comparison and divergence analysis) ---\n    def minmod_br(a_val, b_val):\n        \"\"\"Branching minmod limiter (element-wise).\"\"\"\n        if a_val * b_val <= 0:\n            return 0.0\n        return np.sign(a_val) * min(abs(a_val), abs(b_val))\n\n    def superbee_br(a_val, b_val):\n        \"\"\"Branching superbee limiter (element-wise).\"\"\"\n        if a_val * b_val <= 0:\n            return 0.0\n        abs_a, abs_b = abs(a_val), abs(b_val)\n        mag = max(min(2 * abs_a, abs_b), min(abs_a, 2 * abs_b))\n        return np.sign(a_val) * mag\n\n    def vanleer_br(a_val, b_val):\n        \"\"\"Branching van Leer limiter (element-wise, ratio-based for divergence model).\"\"\"\n        if b_val == 0.0:\n            return 0.0\n        else:\n            r = a_val / b_val\n            if r <= 0.0:\n                return 0.0\n            else:\n                return b_val * (2.0 * r / (1.0 + r))\n\n    def calculate_divergence(a, b, W):\n        \"\"\"Calculates warp divergence fractions for the three branching limiters.\"\"\"\n        num_warps = a.shape[0] // W\n        div_mm, div_sb, div_vl = 0, 0, 0\n\n        for i in range(num_warps):\n            start, end = i * W, (i + 1) * W\n            a_w, b_w = a[start:end], b[start:end]\n\n            def has_diverged(decision_mask):\n                if decision_mask.size == 0:\n                    return False\n                return np.any(decision_mask) and not np.all(decision_mask)\n\n            # Minmod divergence\n            d_mm1 = (a_w * b_w) <= 0\n            if has_diverged(d_mm1):\n                div_mm += 1\n\n            # Superbee divergence\n            diverged_sb_warp = False\n            d_sb1 = (a_w * b_w) <= 0\n            if has_diverged(d_sb1):\n                diverged_sb_warp = True\n            \n            active_mask_sb = ~d_sb1\n            if np.any(active_mask_sb):\n                active_a = a_w[active_mask_sb]\n                active_b = b_w[active_mask_sb]\n                abs_a, abs_b = np.abs(active_a), np.abs(active_b)\n\n                d_sb2 = (2 * abs_a) < abs_b\n                if has_diverged(d_sb2): diverged_sb_warp = True\n                \n                d_sb3 = abs_a < (2 * abs_b)\n                if has_diverged(d_sb3): diverged_sb_warp = True\n\n                min1 = np.where(d_sb2, 2 * abs_a, abs_b)\n                min2 = np.where(d_sb3, abs_a, 2 * abs_b)\n                d_sb4 = min1 > min2 # max(min1, min2)\n                if has_diverged(d_sb4): diverged_sb_warp = True\n            \n            if diverged_sb_warp:\n                div_sb += 1\n\n            # Van Leer divergence\n            diverged_vl_warp = False\n            d_vl1 = b_w == 0\n            if has_diverged(d_vl1):\n                diverged_vl_warp = True\n\n            active_mask_vl = ~d_vl1\n            if np.any(active_mask_vl):\n                active_a = a_w[active_mask_vl]\n                active_b = b_w[active_mask_vl]\n                # To avoid division warnings for cases not executed\n                r = np.divide(active_a, active_b, out=np.zeros_like(active_a), where=active_b!=0)\n                d_vl2 = r <= 0\n                if has_diverged(d_vl2):\n                    diverged_vl_warp = True\n            \n            if diverged_vl_warp:\n                div_vl += 1\n                \n        return div_mm/num_warps, div_sb/num_warps, div_vl/num_warps\n\n    def process_test_case(u_field):\n        \"\"\"Processes a single test case and computes all 15 required metrics.\"\"\"\n        # Step 1: Compute slopes a and b\n        a = u_field[1:-1] - u_field[:-2]\n        b = u_field[2:] - u_field[1:-1]\n\n        # Step 2: Compute limiter outputs for branchless versions\n        res_mm_bl = minmod_bl(a, b)\n        res_sb_bl = superbee_bl(a, b)\n        res_vl_bl = vanleer_bl(a, b)\n        \n        # Step 3: Compute limiter outputs for branching versions\n        res_mm_br = np.array([minmod_br(a_i, b_i) for a_i, b_i in zip(a, b)])\n        res_sb_br = np.array([superbee_br(a_i, b_i) for a_i, b_i in zip(a, b)])\n        res_vl_br = np.array([vanleer_br(a_i, b_i) for a_i, b_i in zip(a, b)])\n\n        # Step 4: Calculate warp divergence fractions\n        d_mm, d_sb, d_vl = calculate_divergence(a, b, W)\n        \n        # Step 5: Calculate numerical equivalence\n        e_mm = np.max(np.abs(res_mm_bl - res_mm_br))\n        e_sb = np.max(np.abs(res_sb_bl - res_sb_br))\n        e_vl = np.max(np.abs(res_vl_bl - res_vl_br))\n        \n        # Step 6: Assemble the 15-item list\n        results = [\n            # Divergence fractions for branching limiters\n            d_mm, d_sb, d_vl,\n            # Divergence fractions for branchless limiters (always 0)\n            0.0, 0.0, 0.0,\n            # Branch decision densities for branching limiters (constants)\n            1.0, 4.0, 2.0,\n            # Branch decision densities for branchless limiters (always 0)\n            0.0, 0.0, 0.0,\n            # Numerical equivalence\n            e_mm, e_sb, e_vl\n        ]\n        return results\n\n    # --- Test Case Generation and Execution ---\n    all_results = []\n\n    # Test Case 1: Smooth\n    x = np.linspace(0, 1, N + 2)\n    u1 = np.sin(2 * np.pi * x)\n    all_results.append(process_test_case(u1))\n\n    # Test Case 2: Shock\n    x = np.linspace(0, 1, N + 2)\n    u2 = np.where(x < 0.5, 0.0, 1.0)\n    all_results.append(process_test_case(u2))\n\n    # Test Case 3: Mixed Random\n    rng = np.random.default_rng(seed=42)\n    u3 = rng.normal(0, 1, N + 2)\n    all_results.append(process_test_case(u3))\n\n    # Test Case 4: Extremes\n    pattern = np.array([0, 1e-12, 1e6, -1e6])\n    num_repeats = (N + 2 + len(pattern) - 1) // len(pattern)\n    u4 = np.tile(pattern, num_repeats)[:N+2]\n    all_results.append(process_test_case(u4))\n\n    # --- Final Output Formatting ---\n    # Construct the final string in the required format: [[...],[...],...]\n    output_str = \"[\" + \",\".join([f\"[{','.join(map(str, r))}]\" for r in all_results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3399817"}]}