{"hands_on_practices": [{"introduction": "To solve differential equations with inhomogeneous boundary conditions, a common and powerful strategy is the method of lifting. This technique involves decomposing the solution into a known lifting function that satisfies the boundary data and an unknown function that satisfies homogeneous conditions. This first exercise provides a concrete, analytical exploration of this principle, demonstrating how the choice of lifting function affects the right-hand side of the linear system but leaves the core stiffness matrix—and thus the conditioning of the problem—unchanged [@problem_id:3365735].", "problem": "Consider the one-dimensional Poisson boundary value problem on the interval $[-1,1]$ with inhomogeneous Dirichlet boundary conditions,\n$$-u''(x)=f(x)\\quad\\text{for }x\\in[-1,1],\\qquad u(-1)=\\alpha,\\quad u(1)=\\beta,$$\nwhere $f$ is a given sufficiently smooth function and $\\alpha,\\beta\\in\\mathbb{R}$ are prescribed boundary data. In a spectral Galerkin setting, one enforces the boundary conditions by basis recombination with a lifting function $w(x)$ so that $u(x)=v(x)+w(x)$ and $v(x)$ satisfies homogeneous Dirichlet conditions. The Galerkin method is defined by the bilinear form\n$$a(u,v)=\\int_{-1}^{1}u'(x)\\,v'(x)\\,\\mathrm{d}x,$$\nand the linear functional\n$$\\ell(v)=\\int_{-1}^{1}f(x)\\,v(x)\\,\\mathrm{d}x.$$\nTake the trial space to be the space of real polynomials of degree at most $3$, and enforce the boundary conditions by constructing $w(x)$ explicitly as a low-degree polynomial that satisfies $w(-1)=\\alpha$ and $w(1)=\\beta$. Then, perform basis recombination to reduce the problem to the homogeneous subspace. Specifically:\n\n- Construct a linear lifting $w_{L}(x)$ and a quadratic lifting $w_{Q}(x)$ such that $w_{L}(-1)=\\alpha$, $w_{L}(1)=\\beta$, and $w_{Q}(-1)=\\alpha$, $w_{Q}(1)=\\beta$.\n- Use the homogeneous subspace spanned by the two basis functions $\\phi_{1}(x)=x^{2}-1$ and $\\phi_{2}(x)=x^{3}-x$, which both satisfy $\\phi_{j}(-1)=\\phi_{j}(1)=0$ for $j\\in\\{1,2\\}$.\n- Derive the $2\\times 2$ Galerkin stiffness matrix $K$ with entries $K_{ij}=a(\\phi_{i},\\phi_{j})$ for $i,j\\in\\{1,2\\}$, and determine its Euclidean condition number $\\kappa_{2}(K)$.\n\nAnalyze whether the choice of $w(x)$ affects the conditioning of the reduced Galerkin system on the homogeneous subspace, and compute the exact value of $\\kappa_{2}(K)$ in closed form. Express your final answer as a single exact number or a single closed-form analytic expression. No rounding is required.", "solution": "The problem asks for the analysis of a spectral Galerkin method for the one-dimensional Poisson equation with inhomogeneous Dirichlet boundary conditions. The core tasks are to determine if the choice of a lifting function affects the conditioning of the reduced system's stiffness matrix, and to compute the condition number of said matrix for a specific polynomial basis.\n\nFirst, let us analyze the structure of the Galerkin system. The problem is given by\n$$-u''(x)=f(x)\\quad\\text{for }x\\in[-1,1],\\qquad u(-1)=\\alpha,\\quad u(1)=\\beta.$$\nWe decompose the solution $u(x)$ into $u(x) = v(x) + w(x)$, where $w(x)$ is a lifting function that satisfies the inhomogeneous boundary conditions, $w(-1)=\\alpha$ and $w(1)=\\beta$, and $v(x)$ belongs to a function space where functions satisfy homogeneous boundary conditions, i.e., $v(-1)=v(1)=0$.\n\nThe weak formulation is to find $u(x)$ such that $a(u, \\phi) = \\ell(\\phi)$ for all suitable test functions $\\phi$ that vanish at the boundaries. Substituting $u=v+w$ gives:\n$$a(v+w, \\phi) = \\ell(\\phi)$$\nBy the linearity of the bilinear form $a(\\cdot, \\cdot)$, we have:\n$$a(v, \\phi) + a(w, \\phi) = \\ell(\\phi)$$\nThis can be rearranged to find the unknown function $v(x)$:\n$$a(v, \\phi) = \\ell(\\phi) - a(w, \\phi)$$\nWe seek an approximate solution for $v(x)$ in a finite-dimensional subspace spanned by basis functions $\\{\\phi_j\\}_{j=1}^N$ which satisfy homogeneous boundary conditions. Let $v(x) = \\sum_{j=1}^{N} c_j \\phi_j(x)$. Using the Galerkin method, we test against each basis function $\\phi_i(x)$ for $i=1, \\dots, N$:\n$$\\sum_{j=1}^{N} c_j a(\\phi_j, \\phi_i) = \\ell(\\phi_i) - a(w, \\phi_i)$$\nThis forms a linear system of equations $K C = F$, where:\n- The stiffness matrix $K$ has entries $K_{ij} = a(\\phi_i, \\phi_j)$.\n- The vector of unknowns $C$ has entries $C_j = c_j$.\n- The right-hand side vector $F$ has entries $F_i = \\ell(\\phi_i) - a(w, \\phi_i) = \\int_{-1}^{1}f(x)\\phi_i(x)\\,\\mathrm{d}x - \\int_{-1}^{1}w'(x)\\phi_i'(x)\\,\\mathrm{d}x$.\n\nThe conditioning of the reduced Galerkin system is determined by the condition number of the stiffness matrix $K$. As shown by its definition, $K_{ij} = a(\\phi_i, \\phi_j)$, the entries of $K$ depend only on the bilinear form $a(\\cdot, \\cdot)$ and the basis functions $\\{\\phi_j\\}$ for the homogeneous subspace. The choice of the lifting function $w(x)$ only affects the right-hand side vector $F$. Therefore, the stiffness matrix $K$ and its condition number are independent of the specific choice of $w(x)$, whether it be linear like $w_L(x)$, quadratic like $w_Q(x)$, or any other valid lifting.\n\nAs requested by the problem, we can construct examples of such lifting functions.\nA linear lifting function $w_L(x) = ax+b$ must satisfy:\n$$w_L(-1) = -a+b = \\alpha$$\n$$w_L(1) = a+b = \\beta$$\nSolving this system yields $a = \\frac{\\beta-\\alpha}{2}$ and $b = \\frac{\\alpha+\\beta}{2}$. So, $w_L(x) = \\frac{\\beta-\\alpha}{2}x + \\frac{\\alpha+\\beta}{2}$.\nA quadratic lifting function $w_Q(x)$ can be constructed by adding a quadratic term to $w_L(x)$ that vanishes at the boundaries $x=\\pm 1$. A simple choice is to add a multiple of $x^2-1$:\n$$w_Q(x) = w_L(x) + C(x^2-1) = \\left(\\frac{\\beta-\\alpha}{2}\\right)x + \\frac{\\alpha+\\beta}{2} + C(x^2-1)$$\nfor any non-zero constant $C \\in \\mathbb{R}$, which ensures the polynomial is truly quadratic. This satisfies $w_Q(-1)=\\alpha$ and $w_Q(1)=\\beta$.\n\nNow, we compute the stiffness matrix $K$ for the homogeneous subspace spanned by the basis functions $\\phi_{1}(x)=x^{2}-1$ and $\\phi_{2}(x)=x^{3}-x$.\nThe bilinear form is $a(g,h)=\\int_{-1}^{1}g'(x)h'(x)\\,\\mathrm{d}x$.\nThe derivatives of the basis functions are:\n$$\\phi_{1}'(x) = 2x$$\n$$\\phi_{2}'(x) = 3x^{2}-1$$\nThe entries of the $2\\times 2$ stiffness matrix $K$ are $K_{ij} = a(\\phi_i, \\phi_j)$.\n\n$K_{11} = a(\\phi_1, \\phi_1) = \\int_{-1}^{1} \\phi_1'(x) \\phi_1'(x) \\,\\mathrm{d}x = \\int_{-1}^{1} (2x)^2 \\,\\mathrm{d}x = \\int_{-1}^{1} 4x^2 \\,\\mathrm{d}x$\n$$K_{11} = 4 \\left[ \\frac{x^3}{3} \\right]_{-1}^{1} = \\frac{4}{3} (1^3 - (-1)^3) = \\frac{4}{3} (1 - (-1)) = \\frac{8}{3}$$\n\n$K_{12} = a(\\phi_1, \\phi_2) = \\int_{-1}^{1} \\phi_1'(x) \\phi_2'(x) \\,\\mathrm{d}x = \\int_{-1}^{1} (2x)(3x^2-1) \\,\\mathrm{d}x = \\int_{-1}^{1} (6x^3 - 2x) \\,\\mathrm{d}x$\nThe integrand is an odd function, and the integral is over a symmetric interval $[-1, 1]$, so the integral is zero.\n$$K_{12} = 0$$\nSince the bilinear form is symmetric, $K_{21} = K_{12} = 0$.\n\n$K_{22} = a(\\phi_2, \\phi_2) = \\int_{-1}^{1} \\phi_2'(x) \\phi_2'(x) \\,\\mathrm{d}x = \\int_{-1}^{1} (3x^2-1)^2 \\,\\mathrm{d}x = \\int_{-1}^{1} (9x^4 - 6x^2 + 1) \\,\\mathrm{d}x$\nThe integrand is an even function.\n$$K_{22} = \\left[ \\frac{9x^5}{5} - \\frac{6x^3}{3} + x \\right]_{-1}^{1} = \\left[ \\frac{9}{5}x^5 - 2x^3 + x \\right]_{-1}^{1}$$\n$$K_{22} = \\left( \\frac{9}{5}(1)^5 - 2(1)^3 + 1 \\right) - \\left( \\frac{9}{5}(-1)^5 - 2(-1)^3 + (-1) \\right)$$\n$$K_{22} = \\left( \\frac{9}{5} - 2 + 1 \\right) - \\left( -\\frac{9}{5} + 2 - 1 \\right) = \\left( \\frac{4}{5} \\right) - \\left( -\\frac{4}{5} \\right) = \\frac{8}{5}$$\nThus, the stiffness matrix is:\n$$K = \\begin{pmatrix} \\frac{8}{3} & 0 \\\\ 0 & \\frac{8}{5} \\end{pmatrix}$$\nThe problem asks for the Euclidean condition number $\\kappa_2(K)$. For a symmetric positive definite matrix, $\\kappa_2(K) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}}$, where $\\lambda_{\\max}$ and $\\lambda_{\\min}$ are the maximum and minimum eigenvalues of $K$.\nSince $K$ is a diagonal matrix, its eigenvalues are its diagonal entries: $\\lambda_1 = \\frac{8}{3}$ and $\\lambda_2 = \\frac{8}{5}$.\nComparing the two eigenvalues: $\\frac{8}{3} = \\frac{40}{15}$ and $\\frac{8}{5} = \\frac{24}{15}$.\nSo, $\\lambda_{\\max} = \\frac{8}{3}$ and $\\lambda_{\\min} = \\frac{8}{5}$.\nThe condition number is:\n$$\\kappa_2(K) = \\frac{\\lambda_{\\max}}{\\lambda_{\\min}} = \\frac{8/3}{8/5} = \\frac{8}{3} \\cdot \\frac{5}{8} = \\frac{5}{3}$$\nThe final result is independent of the lifting functions $w_L(x)$ and $w_Q(x)$, as predicted by our initial analysis.", "answer": "$$\\boxed{\\frac{5}{3}}$$", "id": "3365735"}, {"introduction": "Moving from analytical examples to practical computation requires a systematic way to construct basis functions that satisfy specific constraints. This practice guides you through the complete workflow of basis recombination for mixed boundary conditions using a general Legendre polynomial basis. You will implement the construction of the constraint matrix, compute the null space to define the homogeneous basis, and analyze the conditioning of the resulting mass matrix, culminating in an M-orthonormalization procedure to ensure numerical stability [@problem_id:3365793]. This exercise is designed to bridge the gap between the theory of basis recombination and its robust implementation in code.", "problem": "Consider the classical Legendre polynomials $\\{P_n(x)\\}_{n=0}^N$ on the interval $[-1,1]$ with the standard normalization $P_n(1)=1$. Let the $L^2([-1,1])$ mass matrix $M \\in \\mathbb{R}^{(N+1)\\times(N+1)}$ in the Legendre basis be defined by\n$$\nM_{ij} \\equiv \\int_{-1}^{1} P_i(x) P_j(x) \\, dx.\n$$\nYou are to construct, by linear recombination of the Legendre basis, a basis that enforces the mixed boundary conditions $u(-1)=0$ and $u'(1)=\\alpha$. Because the condition $u'(1)=\\alpha$ is inhomogeneous, use the standard lifting idea: write $u(x) = \\ell(x) + w(x)$, where the lifting $\\ell(x)$ satisfies the boundary data and the correction $w(x)$ satisfies homogeneous conditions. Specifically, impose:\n- $\\ell(-1)=0$ and $\\ell'(1)=\\alpha$,\n- $w(-1)=0$ and $w'(1)=0$.\n\nStarting base and well-tested facts:\n- Orthogonality: $\\displaystyle \\int_{-1}^{1} P_m(x) P_n(x)\\, dx = \\frac{2}{2n+1}\\,\\delta_{mn}$ for all integers $m,n \\ge 0$.\n- Endpoint values: $P_n(-1) = (-1)^n$ for all integers $n \\ge 0$.\n- Endpoint derivative: $P_n'(1) = \\frac{n(n+1)}{2}$ for all integers $n \\ge 0$.\n\nTasks to perform:\n1. Represent any polynomial $v(x)$ of degree at most $N$ as $v(x) = \\sum_{n=0}^{N} c_n P_n(x)$ with coefficient vector $c \\in \\mathbb{R}^{N+1}$. Encode the boundary operator $A \\in \\mathbb{R}^{2 \\times (N+1)}$ acting on $c$ via\n   $$\n   A\\,c \\equiv \\begin{bmatrix}\n   \\sum_{n=0}^{N} c_n P_n(-1) \\\\\n   \\sum_{n=0}^{N} c_n P_n'(1)\n   \\end{bmatrix}\n   = \\begin{bmatrix}\n   u(-1) \\\\\n   u'(1)\n   \\end{bmatrix}.\n   $$\n   Use the facts above to construct $A$ explicitly in closed form.\n\n2. Compute a lifting $\\ell(x)$ of minimal degree that satisfies $\\ell(-1)=0$ and $\\ell'(1)=\\alpha$. Show that one valid choice is $\\ell(x) = \\alpha(1+x)$, and express it in the Legendre basis. Verify by direct evaluation that $A\\,c_{\\text{lift}} = [0,\\alpha]^T$ holds exactly, where $c_{\\text{lift}}$ are the Legendre coefficients of $\\ell(x)$.\n\n3. Construct a recombined basis for the homogeneous subspace\n   $$\n   \\mathcal{V}_H \\equiv \\left\\{ v(x) = \\sum_{n=0}^{N} c_n P_n(x) \\;:\\; A\\,c = \\begin{bmatrix}0\\\\0\\end{bmatrix} \\right\\}.\n   $$\n   Compute a coefficient matrix $Z \\in \\mathbb{R}^{(N+1)\\times K}$ whose columns form a basis of $\\ker(A)$, where $K = N-1$ for $N \\ge 2$. The corresponding homogeneous basis functions are $\\{\\psi_k(x)\\}_{k=1}^{K}$ with $\\psi_k(x) = \\sum_{n=0}^{N} Z_{n,k} P_n(x)$.\n\n4. With respect to the $L^2$ inner product, the mass matrix in the homogeneous basis is $M_Z = Z^T M Z \\in \\mathbb{R}^{K \\times K}$. Compute its $2$-norm condition number $\\kappa(M_Z)$.\n\n5. Perform orthonormalization with respect to the $L^2$ mass matrix. Let $W = \\operatorname{diag}\\!\\big(\\sqrt{2/(2n+1)}\\big)_{n=0}^{N}$ so that $M = W^2$. Define $Y = W Z$, perform a thin $\\mathbb{R}$-valued $QR$ factorization $Y = Q R$ with $Q \\in \\mathbb{R}^{(N+1)\\times K}$ having orthonormal columns, and set the $M$-orthonormal coefficient matrix $Z_{\\text{ortho}} = W^{-1} Q$. The orthonormalized recombined basis is $\\{\\phi_k(x)\\}_{k=1}^K$ with $\\phi_k(x) = \\sum_{n=0}^{N} (Z_{\\text{ortho}})_{n,k} P_n(x)$. Verify that $Z_{\\text{ortho}}^T M Z_{\\text{ortho}} = I_K$ and that each $\\phi_k$ satisfies the homogeneous boundary conditions.\n\n6. Compare the following condition numbers:\n   - $\\kappa(M)$ for the original Legendre basis of size $(N+1)$, i.e., the condition number of $M \\in \\mathbb{R}^{(N+1)\\times(N+1)}$,\n   - $\\kappa(M_Z)$ before orthonormalization,\n   - $\\kappa(Z_{\\text{ortho}}^T M Z_{\\text{ortho}})$ after orthonormalization.\n\n7. Quantify the boundary-condition enforcement error by computing\n   $$\n   \\varepsilon_{\\text{bc}} \\equiv \\max\\left\\{ \\max_{k} |\\phi_k(-1)| ,\\; \\max_{k} |\\phi_k'(1)| \\right\\},\n   $$\n   and the lifting residual\n   $$\n   \\varepsilon_{\\text{lift}} \\equiv \\left\\|A\\,c_{\\text{lift}} - \\begin{bmatrix}0\\\\ \\alpha\\end{bmatrix}\\right\\|_{\\infty}.\n   $$\n\nYour program must implement the above steps and produce numeric outputs for the following test suite of parameter pairs $(N,\\alpha)$:\n- Test case $1$: $(N,\\alpha)=(3,1.5)$,\n- Test case $2$: $(N,\\alpha)=(6,0.0)$,\n- Test case $3$: $(N,\\alpha)=(10,-2.0)$,\n- Test case $4$: $(N,\\alpha)=(2,0.7)$.\n\nFor each test case, output a list of $5$ floating-point values in the order\n$[\\kappa(M),\\;\\kappa(M_Z),\\;\\kappa(Z_{\\text{ortho}}^T M Z_{\\text{ortho}}),\\;\\varepsilon_{\\text{bc}},\\;\\varepsilon_{\\text{lift}}]$.\nAggregate the lists for all test cases into a single list, in the same order as listed above.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list of lists enclosed in square brackets (e.g., $[[r_{1,1},\\dots,r_{1,5}],[r_{2,1},\\dots,r_{2,5}],\\dots]$).\n- No additional text or whitespace beyond what is needed for valid Python list formatting should be printed.", "solution": "The problem is subjected to validation and is determined to be valid. It is a well-posed problem in numerical analysis, specifically within the field of spectral methods, and all provided data and mathematical relations are correct and self-consistent. We now proceed with the solution.\n\nThe core task is to construct a polynomial basis of degree at most $N$ on the interval $[-1, 1]$ that incorporates the mixed boundary conditions $u(-1)=0$ and $u'(1)=\\alpha$. This is achieved by decomposing the solution $u(x)$ into a lifting part $\\ell(x)$ and a homogeneous part $w(x)$, such that $u(x)=\\ell(x)+w(x)$. The lifting satisfies the inhomogeneous boundary data, $\\ell(-1)=0$ and $\\ell'(1)=\\alpha$, while the correction $w(x)$ satisfies the corresponding homogeneous conditions, $w(-1)=0$ and $w'(1)=0$.\n\nLet any polynomial $v(x)$ of degree at most $N$ be represented in the Legendre basis $\\{P_n(x)\\}_{n=0}^N$ as $v(x) = \\sum_{n=0}^{N} c_n P_n(x)$, with coefficient vector $c = [c_0, c_1, \\dots, c_N]^T$.\n\n**1. Boundary Operator $A$**\n\nThe boundary operator $A$ maps the coefficient vector $c$ to the values of the function and its derivative at the boundaries.\n$$\nA\\,c = \\begin{bmatrix}\n   v(-1) \\\\\n   v'(1)\n   \\end{bmatrix} = \\begin{bmatrix}\n   \\sum_{n=0}^{N} c_n P_n(-1) \\\\\n   \\sum_{n=0}^{N} c_n P_n'(1)\n   \\end{bmatrix}\n$$\nUsing the provided identities $P_n(-1) = (-1)^n$ and $P_n'(1) = \\frac{n(n+1)}{2}$, we can construct the matrix $A \\in \\mathbb{R}^{2 \\times (N+1)}$ explicitly. Its rows are formed by the values of these functions for $n=0, \\dots, N$.\nThe first row of $A$, corresponding to the evaluation at $x=-1$, is:\n$$\nA_{0,n} = P_n(-1) = (-1)^n \\quad \\text{for } n=0, \\dots, N\n$$\nThe second row of $A$, corresponding to the derivative evaluation at $x=1$, is:\n$$\nA_{1,n} = P_n'(1) = \\frac{n(n+1)}{2} \\quad \\text{for } n=0, \\dots, N\n$$\nThus, the matrix $A$ is:\n$$\nA = \\begin{bmatrix}\n    1 & -1 & 1 & -1 & \\dots & (-1)^N \\\\\n    0 & 1 & 3 & 6 & \\dots & \\frac{N(N+1)}{2}\n\\end{bmatrix}\n$$\n\n**2. Lifting Function $\\ell(x)$**\n\nWe seek a lifting function $\\ell(x)$ of minimal polynomial degree satisfying $\\ell(-1)=0$ and $\\ell'(1)=\\alpha$. The proposed function is $\\ell(x) = \\alpha(1+x)$.\nLet's verify the boundary conditions:\n- $\\ell(-1) = \\alpha(1+(-1)) = 0$.\n- $\\ell'(x) = \\alpha$, so $\\ell'(1) = \\alpha$.\nThe conditions are met. A polynomial of degree $0$ cannot satisfy these conditions (unless $\\alpha=0$), so degree $1$ is minimal.\n\nTo express $\\ell(x)$ in the Legendre basis, we use the fact that $P_0(x)=1$ and $P_1(x)=x$.\n$$\n\\ell(x) = \\alpha \\cdot 1 + \\alpha \\cdot x = \\alpha P_0(x) + \\alpha P_1(x)\n$$\nThe corresponding coefficient vector $c_{\\text{lift}} \\in \\mathbb{R}^{N+1}$ is therefore:\n$$\nc_{\\text{lift}} = [\\alpha, \\alpha, 0, \\dots, 0]^T\n$$\nWe verify that $A c_{\\text{lift}} = [0, \\alpha]^T$ by direct computation:\n$$\nA c_{\\text{lift}} = \\begin{bmatrix}\n    \\sum_{n=0}^{N} (c_{\\text{lift}})_n (-1)^n \\\\\n    \\sum_{n=0}^{N} (c_{\\text{lift}})_n \\frac{n(n+1)}{2}\n\\end{bmatrix} = \\begin{bmatrix}\n    \\alpha (-1)^0 + \\alpha (-1)^1 \\\\\n    \\alpha \\frac{0(1)}{2} + \\alpha \\frac{1(2)}{2}\n\\end{bmatrix} = \\begin{bmatrix}\n    \\alpha - \\alpha \\\\\n    0 + \\alpha\n\\end{bmatrix} = \\begin{bmatrix}\n    0 \\\\\n    \\alpha\n\\end{bmatrix}\n$$\nThe verification is exact. The lifting residual $\\varepsilon_{\\text{lift}}$ is analytically zero.\n\n**3. Homogeneous Basis Construction**\n\nThe homogeneous basis functions $\\{\\psi_k(x)\\}_{k=1}^K$ span the subspace $\\mathcal{V}_H$ where the boundary conditions are zero. The coefficient vectors of these functions must lie in the null space (kernel) of the operator $A$.\n$$\n\\ker(A) = \\{ c \\in \\mathbb{R}^{N+1} \\;:\\; A\\,c = \\mathbf{0} \\}\n$$\nThe space of polynomials of degree at most $N$ has dimension $N+1$. The two rows of $A$ are linearly independent for $N \\ge 1$. Therefore, they impose two independent linear constraints, and the dimension of $\\ker(A)$ is $K = (N+1)-2 = N-1$. We compute a basis for this null space, forming the columns of a matrix $Z \\in \\mathbb{R}^{(N+1)\\times K}$. This can be done numerically using, for instance, a singular value decomposition of $A$. The columns of $Z$ are the coefficient vectors of the homogeneous basis functions $\\psi_k(x) = \\sum_{n=0}^{N} Z_{n,k} P_n(x)$.\n\n**4. Mass Matrix and Condition Number**\n\nThe $L^2$ mass matrix $M$ in the standard Legendre basis is diagonal due to orthogonality:\n$$\nM_{ij} = \\int_{-1}^{1} P_i(x) P_j(x) \\, dx = \\frac{2}{2i+1} \\delta_{ij}\n$$\nSo, $M = \\operatorname{diag}(2, 2/3, 2/5, \\dots, 2/(2N+1))$.\nThe mass matrix in the new homogeneous basis $\\{\\psi_k\\}$ is given by $M_Z = Z^T M Z$. We compute this matrix and its $2$-norm condition number, $\\kappa(M_Z) = \\sigma_{\\max}(M_Z) / \\sigma_{\\min}(M_Z)$.\n\n**5. Orthonormalization**\n\nTo improve the conditioning of the mass matrix, we orthonormalize the homogeneous basis with respect to the $L^2$ inner product, which is equivalent to the $M$-inner product on the coefficient vectors. Let $M=W^2$, where $W=\\operatorname{diag}(\\sqrt{2/(2n+1)})$. We form the weighted basis matrix $Y=WZ$ and perform a thin QR factorization $Y=QR$. The new, $M$-orthonormal coefficient matrix is $Z_{\\text{ortho}} = W^{-1}Q$.\nBy construction, the new mass matrix is the identity:\n$$\nZ_{\\text{ortho}}^T M Z_{\\text{ortho}} = (W^{-1}Q)^T (W^2) (W^{-1}Q) = Q^T W^{-T} W^2 W^{-1} Q = Q^T Q = I_K\n$$\nThis holds because $W$ is symmetric ($W=W^T$, so $W^{-T}=W^{-1}$) and $Q$ has orthonormal columns ($Q^T Q=I_K$). The basis functions $\\phi_k(x) = \\sum_{n=0}^{N} (Z_{\\text{ortho}})_{n,k} P_n(x)$ are $L^2$-orthonormal and satisfy the homogeneous boundary conditions, since the columns of $Z_{\\text{ortho}}$ are linear combinations of the columns of $Z$ and thus lie in $\\ker(A)$.\n\n**6. Condition Number Comparison**\nWe will compute and compare three condition numbers:\n- $\\kappa(M)$: For the diagonal matrix $M$, this is the ratio of its largest to smallest diagonal entry. $\\kappa(M) = \\max_n(M_{nn})/\\min_n(M_{nn}) = (2/1) / (2/(2N+1)) = 2N+1$.\n- $\\kappa(M_Z)$: The condition number of the mass matrix in the recombined, but not orthonormalized, basis. This is expected to be larger than $1$.\n- $\\kappa(Z_{\\text{ortho}}^T M Z_{\\text{ortho}})$: By construction, this is $\\kappa(I_K) = 1$. This serves as a numerical verification of the orthonormalization process. Deviations from $1$ will be due to floating-point error.\n\n**7. Error Quantification**\nWe compute two error metrics to assess the numerical stability and accuracy of the basis construction.\n- Boundary condition error $\\varepsilon_{\\text{bc}}$: This measures how well the orthonormalized basis functions $\\{\\phi_k\\}$ satisfy the zero boundary conditions. We compute $A Z_{\\text{ortho}}$ and find the maximum absolute value among all its entries.\n$$\n\\varepsilon_{\\text{bc}} = \\max\\left\\{ \\max_{k} |\\phi_k(-1)| ,\\; \\max_{k} |\\phi_k'(1)| \\right\\} = \\|A Z_{\\text{o_ortho}}\\|_{\\max}\n$$\n- Lifting residual $\\varepsilon_{\\text{lift}}$: This measures the error in satisfying the inhomogeneous boundary conditions for the lifting function.\n$$\n\\varepsilon_{\\text{lift}} = \\left\\|A\\,c_{\\text{lift}} - \\begin{bmatrix}0\\\\ \\alpha\\end{bmatrix}\\right\\|_{\\infty}\n$$\nTheoretically, both errors should be zero. In practice, they will be on the order of machine precision, reflecting the accumulation of floating-point errors during the linear algebra computations.\nThe following code implements these steps for the given test cases.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (3, 1.5),\n        (6, 0.0),\n        (10, -2.0),\n        (2, 0.7),\n    ]\n\n    all_results = []\n    for N, alpha in test_cases:\n        result = _compute_basis_properties(N, alpha)\n        all_results.append(result)\n\n    # Format the final output as a single list of lists string.\n    # e.g., [[r1, r2, ...], [s1, s2, ...]]\n    # Using a simple string build to avoid extra spaces from standard list repr.\n    output_str = \"[\" + \",\".join([\"[\" + \",\".join(map(str, res)) + \"]\" for res in all_results]) + \"]\"\n    print(output_str)\n\ndef _compute_basis_properties(N, alpha):\n    \"\"\"\n    Performs the calculations for a single test case (N, alpha).\n\n    Args:\n        N (int): The maximum polynomial degree.\n        alpha (float): The value for the inhomogeneous derivative boundary condition.\n\n    Returns:\n        list: A list of 5 floating-point values:\n              [cond(M), cond(M_Z), cond(Z_ortho^T M Z_ortho), eps_bc, eps_lift].\n    \"\"\"\n    if N  2:\n        raise ValueError(\"N must be >= 2 for the kernel dimension to be N-1.\")\n\n    N_plus_1 = N + 1\n    K = N - 1\n\n    # Task 1: Construct the boundary operator matrix A\n    n_vals = np.arange(N_plus_1, dtype=float)\n    row1 = (-1.0)**n_vals  # P_n(-1)\n    row2 = n_vals * (n_vals + 1) / 2.0  # P_n'(1)\n    A = np.vstack([row1, row2])\n\n    # Task 2: Define the lifting coefficient vector c_lift\n    c_lift = np.zeros(N_plus_1)\n    if N_plus_1 > 1:\n        c_lift[0] = alpha\n        c_lift[1] = alpha\n\n    # Task 3: Compute the kernel of A to get the homogeneous basis coefficient matrix Z\n    # scipy.linalg.null_space returns an orthonormal basis for the null space.\n    Z = linalg.null_space(A)\n\n    # Define the L2 mass matrix M for the Legendre basis\n    diag_M = 2.0 / (2.0 * n_vals + 1.0)\n    M = np.diag(diag_M)\n\n    # Task 4: Compute the mass matrix M_Z in the new basis and its condition number\n    # For N=2, K=1, M_Z is a scalar, so its condition number is 1.\n    if K > 0:\n        M_Z = Z.T @ M @ Z\n        cond_M_Z = np.linalg.cond(M_Z)\n    else: # Should not happen based on N>=2\n        cond_M_Z = 1.0\n\n    # Task 5: Orthonormalize the basis with respect to the M inner product\n    W = np.diag(np.sqrt(diag_M))\n    W_inv = np.diag(1.0 / np.sqrt(diag_M))\n    \n    Z_ortho = np.zeros_like(Z)\n    if K > 0:\n        Y = W @ Z\n        # Thin QR decomposition\n        Q, R = np.linalg.qr(Y, mode='reduced')\n        Z_ortho = W_inv @ Q\n\n    # Task 6: Compare condition numbers\n    # Analytical condition number for the diagonal matrix M\n    cond_M = (2.0 / 1.0) / (2.0 / (2.0 * N + 1.0))\n\n    # Condition number of the mass matrix in the M-orthonormal basis (should be ~1)\n    if K > 0:\n        M_ortho = Z_ortho.T @ M @ Z_ortho\n        cond_M_ortho = np.linalg.cond(M_ortho)\n    else:\n        cond_M_ortho = 1.0\n\n    # Task 7: Quantify errors\n    # Boundary condition enforcement error for the orthonormal basis\n    if K > 0:\n        bc_error_matrix = A @ Z_ortho\n        eps_bc = np.max(np.abs(bc_error_matrix))\n    else:\n        eps_bc = 0.0\n\n    # Lifting residual error\n    lift_residual = A @ c_lift - np.array([0.0, alpha])\n    eps_lift = np.max(np.abs(lift_residual))\n\n    return [cond_M, cond_M_Z, cond_M_ortho, eps_bc, eps_lift]\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3365793"}, {"introduction": "While basis recombination enforces boundary conditions strongly by embedding them directly into the function space, an important alternative is weak enforcement via penalty methods. This approach is central to discontinuous Galerkin and other modern high-order schemes. This final practice challenges you to perform a theoretical analysis, using first principles to derive the necessary scaling law for the penalty parameter $\\eta$ that ensures stability [@problem_id:3365782]. Successfully completing this exercise will deepen your understanding of numerical stability and the subtle interplay between quadrature rules and penalty terms in high-order spectral methods.", "problem": "Consider the one-dimensional second-order elliptic boundary value problem on the interval $\\Omega = [-1,1]$, for an unknown function $u(x)$, with homogeneous Dirichlet boundary conditions $u(-1)=0$ and $u(1)=0$. A spectral Galerkin approximation on a single reference element uses the polynomial space $\\mathbb{P}_p$ of all real polynomials of degree at most $p$, with the standard Legendre–Gauss–Lobatto (LGL) nodal basis $\\{\\ell_i(x)\\}_{i=0}^{p}$ at the LGL nodes $\\{-1=x_0x_1\\cdotsx_p=1\\}$ and weights $\\{w_i\\}_{i=0}^{p}$, where the endpoint weights satisfy $w_0=w_p=\\frac{2}{p(p+1)}$. Two approaches to enforce the boundary conditions are considered:\n\n1. Strong enforcement via basis recombination: replace $\\mathbb{P}_p$ by the subspace $\\mathbb{P}_p^0=\\{v\\in\\mathbb{P}_p : v(-1)=v(1)=0\\}$, for instance by recombining the nodal basis $\\{\\ell_i\\}$ to obtain a basis of $\\mathbb{P}_p^0$ that vanishes at both endpoints. The resulting bilinear form is the Dirichlet form\n$$\na_0(v,v)=\\int_{-1}^{1} v'(x)^2\\,dx \\quad \\text{for } v\\in \\mathbb{P}_p^0.\n$$\n\n2. Weak enforcement by a spectral penalty method: retain $\\mathbb{P}_p$ and add a symmetric boundary penalty term with parameter $\\eta0$ to the bilinear form,\n$$\na_{\\eta}(v,v)=\\int_{-1}^{1} v'(x)^2\\,dx \\;+\\; \\eta\\big(v(-1)^2+v(1)^2\\big) \\quad \\text{for } v\\in \\mathbb{P}_p.\n$$\n\nAssume the right-hand side and solution are analytic so that spectral convergence is governed by stability and approximation properties. Take as a fundamental base the following well-tested facts:\n\n- The Legendre–Gauss–Lobatto quadrature is exact for polynomials of degree up to $2p-1$, and its endpoint weights are $w_0=w_p=\\frac{2}{p(p+1)}$.\n- For the nodal basis function $\\ell_i$, one has $\\ell_i(x_j)=\\delta_{ij}$, and the discrete $L^2$ norm induced by LGL quadrature is $\\|v\\|_{\\mathrm{GLL}}^2=\\sum_{i=0}^{p} w_i\\,v(x_i)^2$. In particular, the squared \"mass\" carried by endpoint degrees of freedom in this discrete norm is scaled by $w_0=w_p$.\n- Asymptotic stability of high-order spectral and discontinuous Galerkin methods under penalty enforcement of Dirichlet boundary conditions requires that the penalty parameter scale with the polynomial degree to balance the growth of modal condition numbers; more precisely, the penalty should counteract the endpoint underweighting due to $w_0=w_p\\sim \\frac{2}{p^2}$.\n\nDefine \"equivalence in stability\" between the penalty and strong recombination approaches to mean that the penalized bilinear form $a_{\\eta}(\\cdot,\\cdot)$ on $\\mathbb{P}_p$ yields (to leading order as $p\\to\\infty$) a uniform coercivity constant and conditioning comparable to the Dirichlet bilinear form $a_0(\\cdot,\\cdot)$ on $\\mathbb{P}_p^0$, in the sense that the boundary degrees of freedom are suppressed at the same asymptotic scale as if they had been eliminated by recombination.\n\nUsing first principles and the fundamental base above, compare the asymptotic error behavior of the two approaches and derive the explicit leading-order scaling law for the penalty parameter $\\eta$ as a function of $p$ that is necessary for equivalence in stability. Express your final answer as a single closed-form analytic expression for $\\eta(p)$, not an inequality or a condition. No rounding is required, and no units are involved. Your answer must be a calculation.", "solution": "The problem asks for the derivation of the leading-order scaling law for the penalty parameter $\\eta(p)$ that ensures \"equivalence in stability\" between a weak penalty-based enforcement of Dirichlet boundary conditions and a strong enforcement via basis recombination. The solution can be deduced from first principles by carefully interpreting the provided \"fundamental base,\" especially the key hint about counteracting endpoint underweighting.\n\n1.  **Interpreting \"Equivalence in Stability\" and the Core Hint**\n\n    The strong method enforces $v(-1)=v(1)=0$ by eliminating the boundary degrees of freedom from the function space. The weak method, using the bilinear form $a_{\\eta}(v,v)$, retains these degrees of freedom but adds a penalty term $\\eta(v(-1)^2 + v(1)^2)$ to discourage non-zero boundary values. \"Equivalence in stability\" implies that the penalty must be chosen to make the boundary degrees of freedom so \"stiff\" that they are effectively suppressed, mimicking their explicit removal in the strong method without introducing excessive ill-conditioning.\n\n    The problem provides a crucial hint: \"the penalty should counteract the endpoint underweighting due to $w_0=w_p\\sim \\frac{2}{p^2}$.\" This points directly to the properties of the Legendre–Gauss–Lobatto (LGL) quadrature rule. In spectral methods using a nodal basis, the discrete $L^2$ inner product (and its associated mass matrix) is defined by the LGL quadrature sum: $(u,v)_{\\mathrm{GLL}} = \\sum_{i=0}^{p} w_i u(x_i) v(x_i)$. The \"underweighting\" refers to the fact that the endpoint weights, $w_0=w_p=\\frac{2}{p(p+1)}$, are of order $O(p^{-2})$, while interior weights are of order $O(p^{-1})$. This means that in the discrete norm $\\|v\\|_{\\mathrm{GLL}}^2$, the contribution from boundary values is naturally diminished as the polynomial degree $p$ increases.\n\n2.  **Derivation from First Principles**\n\n    To \"counteract\" this underweighting, the penalty parameter $\\eta$ must compensate for the smallness of the endpoint weights $w_0$ and $w_p$. The most direct way to achieve this is to choose $\\eta$ to be proportional to the reciprocal of the endpoint weight. This choice is intended to balance the scales in the numerical system, ensuring that the penalty is strong enough to enforce the boundary condition but not so strong as to cause catastrophic ill-conditioning.\n\n    Let's set the penalty parameter $\\eta(p)$ to be proportional to $1/w_0$:\n    $$ \\eta(p) \\propto \\frac{1}{w_0} = \\frac{1}{2/(p(p+1))} = \\frac{p(p+1)}{2} $$\n    This scaling ensures that in the generalized eigenvalue problem $(\\mathbf{K}+\\eta\\mathbf{P})\\mathbf{v} = \\lambda \\mathbf{M}_{\\mathrm{GLL}}\\mathbf{v}$ (which governs stability, with $\\mathbf{K}$ being the stiffness matrix, $\\mathbf{P}$ the boundary projection, and $\\mathbf{M}_{\\mathrm{GLL}}$ the diagonal LGL mass matrix), the penalty term and the stiffness term have a comparable effect on the boundary nodes when viewed relative to the mass matrix. The contribution to the diagonal of the system matrix from the penalty is $\\eta$, while the corresponding mass matrix entry is $w_0$. By choosing $\\eta \\propto 1/w_0$, we ensure that the ratio $\\eta/w_0$ is of a sufficiently large order, $O(p^4)$, matching the scale of the largest eigenvalues of the differential operator itself and thus effectively penalizing boundary modes without overwhelming the physical modes.\n\n3.  **Final Expression**\n\n    The problem asks for an explicit closed-form expression, not just the asymptotic order. The most natural interpretation of the hint, which suggests a direct counteraction, implies a proportionality constant of 1. This leads to the final expression:\n    $$ \\eta(p) = \\frac{p(p+1)}{2} $$\n    This result aligns with standard choices for penalty parameters in the literature on discontinuous Galerkin and Nitsche's methods, where stability analysis based on trace inequalities yields a required scaling of $\\eta \\sim O(p^2/h)$, where $h$ is the element size. For our single element on $[-1,1]$, $h=2$, giving an expected scaling of $O(p^2)$, which is consistent with our derived expression $\\frac{p(p+1)}{2} \\approx \\frac{p^2}{2}$. The problem's hint provides a direct path to this well-established result using first principles.", "answer": "$$ \\boxed{ \\frac{p(p+1)}{2} } $$", "id": "3365782"}]}