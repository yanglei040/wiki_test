{"hands_on_practices": [{"introduction": "Residual-based error estimators are built from local components that measure how poorly the discrete solution satisfies the governing partial differential equation. This exercise provides direct practice in computing one of the most important components in solid mechanics: the jump in the traction vector across an element interface [@problem_id:3541963]. Mastering this calculation, which involves working with discrete displacement gradients, strain tensors, and stress tensors, is a crucial first step in understanding how these estimators are constructed and implemented.", "problem": "Consider a two-dimensional cantilever beam under a tip load, modeled in plane strain, discretized by the Finite Element Method (FEM) using linear Lagrange elements ($P_1$). Focus on a local interior edge $e$ that is the common edge of two adjacent triangles arising from splitting the unit square with coordinates (in meters) $A=(0,0)$, $B=(1,0)$, $C=(0,1)$, and $D=(1,1)$ along the diagonal from $B$ to $C$. Let $T^{+}=\\triangle ABC$ and $T^{-}=\\triangle BDC$, and let $e$ be the edge connecting $B$ and $C$. The discrete displacement field $u_h=(u_{h,x},u_{h,y})$ is piecewise affine over each triangle and is given at the mesh vertices (in meters) by\n- $u_h(A)=(0,0)$,\n- $u_h(B)=(1.0\\times 10^{-4},\\,2.0\\times 10^{-4})$,\n- $u_h(C)=(-5.0\\times 10^{-5},\\,3.0\\times 10^{-4})$,\n- $u_h(D)=(9.0\\times 10^{-5},\\,4.7\\times 10^{-4})$.\nAssume an isotropic, homogeneous, linear elastic material in plane strain with Lamé parameters $(\\lambda,\\mu)$ equal to $\\lambda=1.2\\times 10^{9}\\,\\mathrm{Pa}$ and $\\mu=0.8\\times 10^{9}\\,\\mathrm{Pa}$. The Cauchy stress tensor is defined by $\\sigma(u_h)=2\\mu\\,\\varepsilon(u_h)+\\lambda\\,\\mathrm{tr}(\\varepsilon(u_h))\\,I$, where $\\varepsilon(u_h)=(\\nabla u_h+(\\nabla u_h)^{\\top})/2$ is the symmetric gradient and $I$ is the identity tensor. On an interior edge $e$ shared by elements $T^{+}$ and $T^{-}$ with outward unit normals along $e$ denoted by $n^{+}$ (for $T^{+}$) and $n^{-}$ (for $T^{-}$) satisfying $n^{-}=-n^{+}$, define the traction jump vector by $\\llbracket \\sigma(u_h)n \\rrbracket := \\sigma(u_h)|_{T^{+}}\\,n^{+}+\\sigma(u_h)|_{T^{-}}\\,n^{-}$. The edge norm is $\\|v\\|_{0,e}=\\left(\\int_{e}|v|^{2}\\,\\mathrm{d}s\\right)^{1/2}$ with $|\\,\\cdot\\,|$ the Euclidean norm in $\\mathbb{R}^{2}$. Using these data and definitions, compute the interior edge jump contribution $\\|\\llbracket \\sigma(u_h)n\\rrbracket\\|_{0,e}$ for the edge $e=\\overline{BC}$. Express your final answer in $\\mathrm{N}\\,\\mathrm{m}^{-3/2}$ and round your answer to four significant figures.", "solution": "### Validation of Problem Integrity\nThe problem is a standard exercise in a posteriori error estimation for the Finite Element Method in computational solid mechanics. It is scientifically grounded in the principles of linear elasticity and continuum mechanics. All terms are standard and precisely defined. All required data (geometry, nodal displacements, material constants) are provided and are physically plausible. The problem is well-posed and objective, with a single, verifiable numerical answer.\n\n### Detailed Solution\n\nThe solution proceeds by first computing the constant displacement gradient on each triangular element, then the strain and stress tensors, followed by the traction jump vector, and finally the required edge norm.\n\n**1. Displacement Gradients**\nSince the displacement field $u_h$ is affine (linear) on each triangle, its gradient, $\\nabla u_h$, is a constant matrix on each element.\n\nFor element $T^{+} = \\triangle ABC$ with vertices $A(0,0)$, $B(1,0)$, and $C(0,1)$, the displacement field is of the form $u_h(x,y) = u_h(A) + \\mathbf{B}^T \\begin{pmatrix}x \\\\ y\\end{pmatrix}$. The gradient is $\\nabla u_h = \\mathbf{B}^T$. The matrix $\\mathbf{B}$ is formed by the displacement vectors at vertices B and C relative to A: $\\mathbf{B} = \\begin{pmatrix} u_{h,x}(B) & u_{h,y}(B) \\\\ u_{h,x}(C) & u_{h,y}(C) \\end{pmatrix} = \\begin{pmatrix} 1.0 \\times 10^{-4} & 2.0 \\times 10^{-4} \\\\ -5.0 \\times 10^{-5} & 3.0 \\times 10^{-4} \\end{pmatrix}$.\nThe gradient on $T^{+}$ is:\n$$ \\nabla u_h|_{T^{+}} = \\mathbf{B} = \\begin{pmatrix} 1.0 \\times 10^{-4} & -5.0 \\times 10^{-5} \\\\ 2.0 \\times 10^{-4} & 3.0 \\times 10^{-4} \\end{pmatrix} $$\n\nFor element $T^{-} = \\triangle BDC$ with vertices $B(1,0)$, $D(1,1)$, and $C(0,1)$, we find the gradient by considering the affine mapping $u_h(x,y) = \\mathbf{a} + \\mathbf{M} \\begin{pmatrix}x \\\\ y\\end{pmatrix}$, where $\\nabla u_h = \\mathbf{M}$. Solving for the coefficients yields $\\mathbf{M}_{col1} = u_h(D) - u_h(C)$ and $\\mathbf{M}_{col2} = u_h(C) - u_h(B)$. A more direct method is to solve for the linear system defined by the vertices. This gives:\n$$ \\nabla u_h|_{T^{-}} = \\begin{pmatrix} 1.4 \\times 10^{-4} & 1.7 \\times 10^{-4} \\\\ -1.0 \\times 10^{-5} & 2.7 \\times 10^{-4} \\end{pmatrix} $$\n\n**2. Strain and Stress Tensors**\nThe strain tensor is $\\varepsilon = \\frac{1}{2}(\\nabla u_h + (\\nabla u_h)^T)$.\nOn $T^{+}$:\n$$ \\varepsilon^{+} = \\frac{1}{2}\\left(\\begin{pmatrix} 1.0 \\times 10^{-4} & -5.0 \\times 10^{-5} \\\\ 2.0 \\times 10^{-4} & 3.0 \\times 10^{-4} \\end{pmatrix} + \\begin{pmatrix} 1.0 \\times 10^{-4} & 2.0 \\times 10^{-4} \\\\ -5.0 \\times 10^{-5} & 3.0 \\times 10^{-4} \\end{pmatrix}\\right) = \\begin{pmatrix} 1.0 \\times 10^{-4} & 7.5 \\times 10^{-5} \\\\ 7.5 \\times 10^{-5} & 3.0 \\times 10^{-4} \\end{pmatrix} $$\nThe trace is $\\mathrm{tr}(\\varepsilon^{+}) = (1.0 + 3.0) \\times 10^{-4} = 4.0 \\times 10^{-4}$.\nThe stress tensor $\\sigma^{+} = 2\\mu\\varepsilon^{+} + \\lambda\\,\\mathrm{tr}(\\varepsilon^{+})I$:\n$$ \\sigma^{+} = 1.6 \\times 10^9 \\varepsilon^{+} + (1.2 \\times 10^9)(4.0 \\times 10^{-4})I = \\begin{pmatrix} 1.6 \\times 10^5 & 1.2 \\times 10^5 \\\\ 1.2 \\times 10^5 & 4.8 \\times 10^5 \\end{pmatrix} + \\begin{pmatrix} 4.8 \\times 10^5 & 0 \\\\ 0 & 4.8 \\times 10^5 \\end{pmatrix} $$\n$$ \\sigma^{+} = \\begin{pmatrix} 6.4 \\times 10^5 & 1.2 \\times 10^5 \\\\ 1.2 \\times 10^5 & 9.6 \\times 10^5 \\end{pmatrix}\\,\\mathrm{Pa} $$\n\nOn $T^{-}$:\n$$ \\varepsilon^{-} = \\frac{1}{2}\\left(\\begin{pmatrix} 1.4 \\times 10^{-4} & 1.7 \\times 10^{-4} \\\\ -1.0 \\times 10^{-5} & 2.7 \\times 10^{-4} \\end{pmatrix} + \\begin{pmatrix} 1.4 \\times 10^{-4} & -1.0 \\times 10^{-5} \\\\ 1.7 \\times 10^{-4} & 2.7 \\times 10^{-4} \\end{pmatrix}\\right) = \\begin{pmatrix} 1.4 \\times 10^{-4} & 8.0 \\times 10^{-5} \\\\ 8.0 \\times 10^{-5} & 2.7 \\times 10^{-4} \\end{pmatrix} $$\nThe trace is $\\mathrm{tr}(\\varepsilon^{-}) = (1.4 + 2.7) \\times 10^{-4} = 4.1 \\times 10^{-4}$.\nThe stress tensor $\\sigma^{-} = 2\\mu\\varepsilon^{-} + \\lambda\\,\\mathrm{tr}(\\varepsilon^{-})I$:\n$$ \\sigma^{-} = 1.6 \\times 10^9 \\varepsilon^{-} + (1.2 \\times 10^9)(4.1 \\times 10^{-4})I = \\begin{pmatrix} 2.24 \\times 10^5 & 1.28 \\times 10^5 \\\\ 1.28 \\times 10^5 & 4.32 \\times 10^5 \\end{pmatrix} + \\begin{pmatrix} 4.92 \\times 10^5 & 0 \\\\ 0 & 4.92 \\times 10^5 \\end{pmatrix} $$\n$$ \\sigma^{-} = \\begin{pmatrix} 7.16 \\times 10^5 & 1.28 \\times 10^5 \\\\ 1.28 \\times 10^5 & 9.24 \\times 10^5 \\end{pmatrix}\\,\\mathrm{Pa} $$\n\n**3. Traction Jump Vector**\nThe edge $e$ is the segment $\\overline{BC}$ connecting $B(1,0)$ and $C(0,1)$. The vector along the edge is $C-B = (-1,1)$. An orthogonal vector is $(1,1)$. For $T^+ = \\triangle ABC$, the vertex $A(0,0)$ is on one side of the line $x+y-1=0$. The outward normal points away from $A$, so its components are positive. The outward unit normal from $T^{+}$ is:\n$$ n^{+} = \\frac{1}{\\sqrt{1^2+1^2}}(1,1)^T = \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix} $$\nThe traction jump is defined as $\\llbracket \\sigma(u_h)n \\rrbracket = \\sigma^{+}n^{+} + \\sigma^{-}n^{-}$. Since $n^{-} = -n^{+}$, this simplifies to $\\llbracket \\sigma(u_h)n \\rrbracket = (\\sigma^{+} - \\sigma^{-})n^{+}$. We compute the difference in stress tensors:\n$$ \\sigma^{+} - \\sigma^{-} = 10^5 \\left( \\begin{pmatrix} 6.4 & 1.2 \\\\ 1.2 & 9.6 \\end{pmatrix} - \\begin{pmatrix} 7.16 & 1.28 \\\\ 1.28 & 9.24 \\end{pmatrix} \\right) = 10^5 \\begin{pmatrix} -0.76 & -0.08 \\\\ -0.08 & 0.36 \\end{pmatrix} $$\nThe traction jump vector $J = \\llbracket \\sigma(u_h)n \\rrbracket$ is:\n$$ J = 10^5 \\begin{pmatrix} -0.76 & -0.08 \\\\ -0.08 & 0.36 \\end{pmatrix} \\frac{1}{\\sqrt{2}}\\begin{pmatrix}1 \\\\ 1\\end{pmatrix} = \\frac{10^5}{\\sqrt{2}} \\begin{pmatrix} -0.76 - 0.08 \\\\ -0.08 + 0.36 \\end{pmatrix} = \\frac{10^5}{\\sqrt{2}}\\begin{pmatrix} -0.84 \\\\ 0.28 \\end{pmatrix} $$\nSince $\\sigma^{+}$ and $\\sigma^{-}$ are constant on their respective elements, the jump vector $J$ is constant along the edge $e$.\n\n**4. Edge Norm Calculation**\nThe norm is $\\|J\\|_{0,e} = \\left(\\int_e |J|^2 \\mathrm{d}s\\right)^{1/2}$. As $J$ is constant, this simplifies to $\\|J\\|_{0,e} = \\sqrt{|J|^2 \\cdot \\mathrm{length}(e)} = |J| \\sqrt{\\mathrm{length}(e)}$.\nThe length of edge $e$ is $L_e = \\sqrt{(1-0)^2 + (0-1)^2} = \\sqrt{2}\\,\\mathrm{m}$.\nThe Euclidean norm of the jump vector is:\n$$ |J| = \\left| \\frac{10^5}{\\sqrt{2}}\\begin{pmatrix} -0.84 \\\\ 0.28 \\end{pmatrix} \\right| = \\frac{10^5}{\\sqrt{2}} \\sqrt{(-0.84)^2 + (0.28)^2} = \\frac{10^5}{\\sqrt{2}} \\sqrt{0.7056 + 0.0784} = \\frac{10^5}{\\sqrt{2}} \\sqrt{0.784} $$\n$$ |J| \\approx \\frac{10^5}{1.4142} \\times 0.88544 = 6.261 \\times 10^4 \\,\\mathrm{N}\\,\\mathrm{m}^{-2} $$\nFinally, we compute the edge norm:\n$$ \\|J\\|_{0,e} = |J| \\sqrt{L_e} = (6.261 \\times 10^4) \\sqrt{\\sqrt{2}} = (6.261 \\times 10^4) \\times (1.1892) \\approx 7.4456 \\times 10^4 $$\nThe units are $(\\mathrm{N}\\,\\mathrm{m}^{-2}) \\cdot \\mathrm{m}^{1/2} = \\mathrm{N}\\,\\mathrm{m}^{-3/2}$.\n\n**5. Final Numerical Value**\nRounding the result to four significant figures gives $7.446 \\times 10^4$.", "answer": "$$\\boxed{7.446 \\times 10^{4}}$$", "id": "3541963"}, {"introduction": "Beyond estimating the global error, it is often more important in practice to control the error in a specific engineering quantity of interest, such as the stress or displacement at a critical point. This practice introduces the Dual-Weighted Residual (DWR) method, a powerful and general framework for such goal-oriented error estimation [@problem_id:3361410]. By solving for both a primal solution and a discrete adjoint (dual) solution associated with a specific goal functional, you will assemble a complete error estimator and see how this technique provides targeted information to guide adaptive refinement efficiently.", "problem": "Consider the one-dimensional Poisson problem on the open interval $\\Omega=(0,1)$ with homogeneous Dirichlet boundary conditions,\n$$\n- u'' = f \\quad \\text{in } \\Omega, \\qquad u(0)=0,\\quad u(1)=0,\n$$\nwhere the source term is $f(x)=1$. We discretize the problem using the Symmetric Interior Penalty Galerkin (SIPG) Discontinuous Galerkin method. The mesh $\\mathcal{T}_h$ consists of two elements $K_1=(0, 1/2)$ and $K_2=(1/2, 1)$. We use a finite element space of piecewise polynomials of degree at most one on each element, with a penalty parameter $\\sigma=2$.\n\nThe SIPG bilinear form $a(\\cdot,\\cdot)$ and linear form $L(\\cdot)$ are defined as:\n$$\na(u,v) = \\sum_{K\\in \\mathcal{T}_h}\\int_K u' v'\\,dx - \\sum_{F\\in \\mathcal{F}_h^{\\mathrm{int}}}\\Big( \\{u'\\}[v] + \\{v'\\}[u] \\Big) + \\sum_{F\\in \\mathcal{F}_h}\\frac{\\sigma}{h_F}[u][v]\n$$\n$$\nL(v) = \\int_\\Omega f v \\, dx\n$$\nwhere $\\mathcal{F}_h^{\\mathrm{int}}$ is the set of interior faces, $\\{v\\} = (v^+ + v^-)/2$ is the average, $[v]=v^+-v^-$ is the jump, and the penalty term is applied over all faces $\\mathcal{F}_h$, including boundary faces where the jump is defined as $[v]=v$. The element size is $h_K=1/2$.\n\nThe goal functional is the point evaluation of the solution at $x_0 = 3/4$, i.e., $J(u)=u(3/4)$.\n\n**Tasks:**\n1. Compute the discrete primal solution $u_h$ that satisfies $a(u_h, v_h) = L(v_h)$ for all test functions $v_h$ in the discrete space.\n2. Compute the discrete adjoint solution $z_h$ that satisfies $a(v_h, z_h) = J(v_h)$ for all test functions $v_h$ in the discrete space.\n3. The exact error in the functional, $J(u)-J(u_h)$, can be shown to be equal to the quantity $\\eta = (f,z) - a(u_h,z)$, where $z$ is the continuous adjoint solution satisfying $-z''=\\delta_{x_0}$ with homogeneous Dirichlet boundary conditions.\nEvaluate this quantity $\\eta$. Express your final answer as an exact fraction.", "solution": "### Validation of Problem Integrity\nThe problem is a standard academic exercise in goal-oriented error estimation for Discontinuous Galerkin methods. It is scientifically sound, self-contained after minor clarification of the bilinear form from standard literature, and well-posed. The SIPG bilinear form is coercive for a sufficiently large penalty parameter, ensuring unique solutions. All necessary data are provided.\n\n### Detailed Solution\n\nThe solution involves setting up and solving two linear systems for the primal and adjoint discrete solutions, and then evaluating the error estimator identity.\n\n**1. Preliminaries: Basis Functions and SIPG Form**\nThe discrete space is spanned by four basis functions:\n- On $K_1=(0, 1/2)$: $b_1(x) = 1$, $b_2(x) = 4x-1$. Their derivatives are $b_1'=0, b_2'=4$.\n- On $K_2=(1/2, 1)$: $b_3(x) = 1$, $b_4(x) = 4x-3$. Their derivatives are $b_3'=0, b_4'=4$.\n\nThe provided bilinear form has a slight ambiguity. The standard symmetric (SIPG) form for Dirichlet problems also includes terms from the boundary conditions. The full form is:\n$$\na(u,v) = \\sum_{K}\\int_K u' v'\\,dx - \\sum_{F_{int}}(\\{u'\\}[v] + \\{v'\\}[u]) + \\frac{\\sigma}{h}[u][v] - \\sum_{F_{bdy}}(u'nv+v'nu) + \\frac{\\sigma}{h}uv\n$$\nWith $\\sigma=2$ and element size $h=1/2$, the penalty coefficient is $\\sigma/h = 4$.\n\n**2. Stiffness Matrix**\nThe entries of the $4 \\times 4$ stiffness matrix $A$ are $A_{ij} = a(b_i, b_j)$. Calculating each entry using the full SIPG form gives:\n$$ A = \\begin{pmatrix} 8 & 6 & -4 & 6 \\\\ 6 & 12 & -6 & 8 \\\\ -4 & -6 & 8 & -6 \\\\ 6 & 8 & -6 & 12 \\end{pmatrix} $$\n\n**3. Primal Solution $u_h$**\nThe primal problem is $A\\mathbf{u} = \\mathbf{F}$, where $\\mathbf{u}$ is the vector of coefficients for $u_h$ and $F_i = \\int_\\Omega f b_i dx$. With $f(x)=1$:\n- $F_1 = \\int_0^{1/2} 1 \\cdot b_1 dx = 1/2$.\n- $F_2 = \\int_0^{1/2} 1 \\cdot b_2 dx = \\int_0^{1/2} (4x-1) dx = 0$.\n- $F_3 = \\int_{1/2}^1 1 \\cdot b_3 dx = 1/2$.\n- $F_4 = \\int_{1/2}^1 1 \\cdot b_4 dx = \\int_{1/2}^1 (4x-3) dx = 0$.\nSo, $\\mathbf{F} = (1/2, 0, 1/2, 0)^T$.\nThe system is $A\\mathbf{u} = (1/2, 0, 1/2, 0)^T$. By symmetry of the problem, we expect $u_1=u_3$ and $u_2=-u_4$. This reduces the system, yielding the solution:\n$$ \\mathbf{u} = (1/8, 0, 1/8, 0)^T $$\nThis means the primal solution is $u_h(x) = 1/8$ on both elements.\n\n**4. Adjoint Solution $z_h$**\nThe discrete adjoint problem is $A\\mathbf{z} = \\mathbf{J}$, where $J_i = J(b_i) = b_i(x_0)$ with $x_0=3/4$.\nSince $x_0=3/4$ is in element $K_2$, only $b_3$ and $b_4$ are non-zero there.\n- $J_1 = b_1(3/4) = 0$.\n- $J_2 = b_2(3/4) = 0$.\n- $J_3 = b_3(3/4) = 1$.\n- $J_4 = b_4(3/4) = 4(3/4) - 3 = 0$.\nSo, $\\mathbf{J} = (0, 0, 1, 0)^T$. Solving the system $A\\mathbf{z} = (0, 0, 1, 0)^T$ gives:\n$$ \\mathbf{z} = (-1/24, 1/8, 7/24, 1/8)^T $$\n\n**5. Error Estimator Evaluation**\nThe estimator is $\\eta = (f,z) - a(u_h, z)$.\n\n**a) Continuous Adjoint Solution $z$:**\nThe continuous adjoint problem is $-z'' = \\delta_{3/4}$ with $z(0)=z(1)=0$. The solution is the Green's function:\n$$ z(x) = \\begin{cases} (1-3/4)x = x/4 & \\text{if } x \\le 3/4 \\\\ (1-x)(3/4) & \\text{if } x > 3/4 \\end{cases} $$\n\n**b) First Term $(f,z)$:**\nWith $f(x)=1$, this is the integral of $z(x)$ over the domain.\n$$ (f,z) = \\int_0^1 z(x) dx = \\int_0^{3/4} \\frac{x}{4} dx + \\int_{3/4}^1 \\frac{3}{4}(1-x) dx $$\n$$ = \\left[\\frac{x^2}{8}\\right]_0^{3/4} + \\frac{3}{4}\\left[x - \\frac{x^2}{2}\\right]_{3/4}^1 = \\frac{(3/4)^2}{8} + \\frac{3}{4}\\left( (1-\\frac{1}{2}) - (\\frac{3}{4}-\\frac{(3/4)^2}{2}) \\right) $$\n$$ = \\frac{9}{128} + \\frac{3}{4}\\left(\\frac{1}{2} - \\frac{15}{32}\\right) = \\frac{9}{128} + \\frac{3}{4}\\left(\\frac{1}{32}\\right) = \\frac{9}{128} + \\frac{3}{128} = \\frac{12}{128} = \\frac{3}{32} $$\n\n**c) Second Term $a(u_h, z)$:**\nWe evaluate the bilinear form with the discrete primal solution $u_h=1/8$ and the continuous adjoint solution $z$.\nSince $u_h$ is piecewise constant, $u_h'=0$ and $[u_h]=0$ at the interior face. As $z$ is continuous, $[z]=0$. All terms in the bilinear form involving derivatives of $u_h$ or jumps are zero, except for the boundary terms.\n$$ a(u_h, z) = - (z'(0)n u_h(0) + z'(1)n u_h(1)) $$\nHere we use the portion of the SIPG form involving the continuous function $z$, where boundary terms do not include penalties as $z=0$ on the boundary.\n- At $x=0$: $n=-1$, $u_h(0)=1/8$, $z'(0)=1/4$. Term is $-(1/4)(-1)(1/8) = 1/32$.\n- At $x=1$: $n=1$, $u_h(1)=1/8$, $z'(1)=-3/4$. Term is $-(-3/4)(1)(1/8) = 3/32$.\n$$ a(u_h, z) = \\frac{1}{32} + \\frac{3}{32} = \\frac{4}{32} = \\frac{1}{8} $$\n\n**d) Final Estimator Value $\\eta$:**\n$$ \\eta = (f,z) - a(u_h, z) = \\frac{3}{32} - \\frac{1}{8} = \\frac{3}{32} - \\frac{4}{32} = -\\frac{1}{32} $$\nThis value is the exact error in the goal functional, $J(u) - J(u_h)$, as can be verified by computing the exact value $J(u) = u(3/4) = \\frac{1}{2}(\\frac{3}{4})(1-\\frac{3}{4}) = 3/32$ and the approximate value $J(u_h) = u_h(3/4)=1/8$. The error is $3/32 - 1/8 = -1/32$.", "answer": "$$\n\\boxed{-\\frac{1}{32}}\n$$", "id": "3361410"}, {"introduction": "The ultimate purpose of a posteriori error estimators is to drive adaptive mesh refinement (AMR), creating a feedback loop where the simulation automatically refines the mesh in regions of high error. This programming exercise brings the entire theory to life by having you implement a complete `mark-refine` cycle for a canonical benchmark problem with a stress singularity [@problem_id:3542038]. By applying the renowned Dörfler marking strategy to a set of local error indicators, you will witness firsthand how an adaptive algorithm can overcome the limitations of uniform meshes and restore optimal rates of convergence.", "problem": "Consider small-strain linear elasticity in two dimensions on an L-shaped domain with a re-entrant corner. Let the body be modeled in plane strain with Lamé parameters $\\lambda$ and $\\mu$, and displacement field $\\mathbf{u}$ governed by the strong form $-\\nabla \\cdot \\boldsymbol{\\sigma} = \\mathbf{f}$ in $\\Omega$, with $\\boldsymbol{\\sigma} = \\lambda (\\nabla \\cdot \\mathbf{u}) \\mathbf{I} + 2 \\mu \\, \\boldsymbol{\\varepsilon}(\\mathbf{u})$ and $\\boldsymbol{\\varepsilon}(\\mathbf{u}) = \\tfrac{1}{2}(\\nabla \\mathbf{u} + (\\nabla \\mathbf{u})^{\\top})$, subject to mixed boundary conditions. In domains with re-entrant corners, solutions exhibit singular stress states and reduced regularity near the corner. Adaptive mesh refinement guided by a posteriori error estimation is used to restore optimal convergence rates in the energy norm.\n\nA residual-jump-based estimator partitions the global error surrogate into local indicators $\\eta_K$ per element $K$, and is known to be both reliable and efficient under standard assumptions in the Finite Element Method (FEM). A bulk-chasing strategy selects elements to refine so that a fixed fraction of the global estimator is addressed at each step. One such strategy is known as Dörfler marking. You must implement this marking in a minimal-cardinality sense: among all subsets of elements that capture a prescribed fraction of the total squared indicator, select one with the smallest number of elements.\n\nTo make this implementable without solving the linear elasticity equations, use a scalar surrogate consistent with the singularity class of re-entrant corners (as widely employed in analysis of adaptive methods). Specifically, on the L-shaped domain $\\Omega = [-1,1]^2 \\setminus \\big([0,1]\\times[-1,0]\\big)$ with a re-entrant corner at the origin, model the local indicator scaling near the corner by the power-law\n$$\n\\eta_K \\approx c \\, \\sqrt{h_K} \\, r_K^{\\alpha - 1},\n$$\nwhere $c$ is a positive constant (set $c=1$), $h_K$ is the element size, $r_K$ is the Euclidean distance from the element center to the origin, and $\\alpha = 0.544483736782$ is the L-shaped singularity exponent associated with a homogeneous scalar elliptic model. This surrogate is consistent with the behavior of residual-jump error estimators for problems with corner singularities and captures the necessary near-corner refinement bias.\n\nYour task is to:\n- Construct an initial uniform square tessellation over $\\Omega$ by subdividing $[-1,1]^2$ into $n_x \\times n_y$ equal squares and discarding those whose centers lie in the excised square $[0,1]\\times[-1,0]$. Use $n_x = n_y = 12$.\n- For each element $K$, compute $r_K$ and $\\eta_K$ using the above surrogate. Avoid division by zero by taking $r_K \\leftarrow \\max(r_K, 10^{-6})$.\n- Implement the minimal-cardinality bulk-chasing marking strategy that, for a given parameter $\\theta \\in (0,1)$, selects a set $\\mathcal{M}$ so that the selected elements’ squared indicators capture at least a fraction of the total squared estimator, while the number of marked elements is as small as possible.\n- Refine marked elements by subdividing each selected square into four child squares of half size. Children whose centers fall outside $\\Omega$ must be discarded; those inside replace their parent in the mesh. Recompute indicators on the refined mesh.\n- Repeat the mark-refine cycle for a fixed number of refinement steps, using the same $\\theta$ each time. Use $N_{\\text{steps}} = 7$.\n- At each step $k$, compute the global estimator $E_k = \\left(\\sum_{K} \\eta_K^2\\right)^{1/2}$ and the number of elements $N_k$ currently in the mesh.\n- Estimate the convergence rate $p(\\theta)$ by fitting a line to $(\\log N_k, \\log E_k)$ over the last five refinement steps and taking $p(\\theta) = -\\text{slope}$. This approximates the rate in the model $E(N) \\approx C N^{-p}$ for large $N$.\n\nImplement the above in a single program that evaluates several values of $\\theta$ and reports the estimated convergence rates. You must ensure numerical stability and scientific plausibility of the surrogate and the refinement procedure.\n\nTest suite:\n- Use the following values of $\\theta$: $0.15$, $0.3$, $0.5$, $0.7$, $0.9$.\n- For each $\\theta$, run the full refinement loop and compute $p(\\theta)$ as specified.\n\nAnswer specification:\n- The final output of your program must be a single line containing the list of estimated rates for all $\\theta$ values in the test suite, in the order provided.\n- The format must be a comma-separated list enclosed in square brackets, for example $[p(0.15),p(0.3),p(0.5),p(0.7),p(0.9)]$.\n- Each entry must be a floating-point number. No physical units are required and no angles are involved.\n\nYour program must be self-contained and runnable without any external inputs or files.", "solution": "### Description of the Method\n\nThe problem requires the implementation of an adaptive mesh refinement (AMR) simulation to analyze convergence rates for a problem with a singularity. The core of the solution is a Python script that performs a `solve-estimate-mark-refine` loop, where the `solve` step is replaced by a surrogate error indicator.\n\n**1. Domain and Initial Mesh**\nThe L-shaped domain $\\Omega = [-1,1]^2 \\setminus ([0,1]\\times[-1,0])$ is discretized. The initial mesh is a uniform grid of $12 \\times 12$ squares on $[-1,1]^2$, from which elements whose centers are in the excised quadrant are removed. This creates an initial mesh of $144 - 36 = 108$ elements. Each element is stored as a record containing its center coordinates and side length.\n\n**2. Surrogate Error Indicator**\nFor each element $K$, a local error indicator $\\eta_K$ is computed using a formula that mimics the behavior of a true residual-based estimator near the re-entrant corner at the origin:\n$$\n\\eta_K = \\sqrt{h_K} \\, r_K^{\\alpha - 1}\n$$\nHere, $h_K$ is the element's side length, $r_K$ is the distance from its center to the origin, and $\\alpha \\approx 0.544$ is the singularity exponent. This formula ensures that elements closer to the singularity are assigned larger error indicators, driving refinement toward the corner.\n\n**3. The Adaptive `MARK-REFINE` Algorithm**\nThe simulation iterates for 7 steps for each specified marking parameter $\\theta$.\n\n- **COMPUTE:** In each step, the indicators $\\eta_K$ are computed for all elements in the current mesh. The global squared estimator $E^2 = \\sum_K \\eta_K^2$ is also calculated.\n- **MARK:** Dörfler marking is used to select elements for refinement. This strategy requires finding a minimal set of elements $\\mathcal{M}$ such that the sum of their squared indicators is at least a fraction $\\theta$ of the total squared estimator: $\\sum_{K \\in \\mathcal{M}} \\eta_K^2 \\ge \\theta E^2$. This is implemented efficiently by sorting the elements by their indicator values in descending order and picking elements from the top of the list until the bulk condition is met.\n- **REFINE:** Each marked element is replaced by its four children (quadrisection), each having half the side length of the parent. Child elements are kept only if their center falls within the L-shaped domain. Unmarked elements are carried over to the new mesh.\n- **RECORD:** The number of elements $N_k$ and the global estimator $E_k$ are recorded at each step $k$.\n\n**4. Convergence Rate Estimation**\nThe theory of adaptive finite element methods (AFEM) predicts a convergence rate $p$ such that $E \\approx C N^{-p}$. Taking logarithms, we get $\\log E \\approx \\log C - p \\log N$. The rate $p$ is estimated by performing a linear regression on the recorded $(\\log N_k, \\log E_k)$ data points from the last five steps of the simulation. The rate is then given by the negative of the slope of the fitted line. This entire procedure is repeated for each value of $\\theta$ in the test suite. The final output is a list of these estimated rates.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements an adaptive mesh refinement simulation for an L-shaped domain\n    to estimate the convergence rate of a surrogate error estimator.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    ALPHA = 0.544483736782\n    THETAS = [0.15, 0.3, 0.5, 0.7, 0.9]\n    N_STEPS = 7\n    NX, NY = 12, 12\n    R_CLAMP = 1e-6\n\n    def is_in_domain(center):\n        \"\"\"Checks if a point is within the L-shaped domain.\"\"\"\n        x, y = center\n        # The excised region is where x > 0 and y  0.\n        return not (x > 0 and y  0)\n\n    def generate_initial_mesh():\n        \"\"\"Creates the initial uniform mesh on the L-shaped domain.\"\"\"\n        h_initial = 2.0 / NX\n        mesh_elements = []\n        for i in range(NX):\n            for j in range(NY):\n                xc = -1.0 + h_initial / 2.0 + i * h_initial\n                yc = -1.0 + h_initial / 2.0 + j * h_initial\n                if is_in_domain((xc, yc)):\n                    # Each element is [center_x, center_y, size]\n                    mesh_elements.append([xc, yc, h_initial])\n        return np.array(mesh_elements)\n\n    def run_simulation(theta):\n        \"\"\"\n        Runs the full mark-refine simulation for a given theta value.\n        \"\"\"\n        mesh = generate_initial_mesh()\n        log_N_E_data = []\n\n        for step in range(N_STEPS):\n            # 1. COMPUTE: Indicators and global estimator\n            if mesh.shape[0] == 0:\n                # This should not happen in a valid run, but as a safeguard.\n                if len(log_N_E_data) >= 5:\n                    break\n                else: # Not enough data points to fit\n                    return np.nan \n\n            centers = mesh[:, :2]\n            sizes = mesh[:, 2]\n            \n            r_k = np.linalg.norm(centers, axis=1)\n            r_k = np.maximum(r_k, R_CLAMP)\n            \n            eta_k = np.sqrt(sizes) * r_k**(ALPHA - 1)\n            eta_k_sq = eta_k**2\n            \n            E_k_sq = np.sum(eta_k_sq)\n            E_k = np.sqrt(E_k_sq)\n            N_k = mesh.shape[0]\n\n            # 2. RECORD: Store log-log data\n            log_N_E_data.append([np.log(N_k), np.log(E_k)])\n\n            # Stop after recording the last step's data\n            if step == N_STEPS - 1:\n                break\n\n            # 3. MARK: Dörfler marking\n            total_eta_sq = E_k_sq\n            target_sum_sq = theta * total_eta_sq\n            \n            sorted_indices = np.argsort(eta_k)[::-1]\n            sorted_eta_k_sq = eta_k_sq[sorted_indices]\n            \n            cumulative_sum_sq = np.cumsum(sorted_eta_k_sq)\n            \n            # Find the number of elements to mark\n            # np.searchsorted finds the index where target would be inserted.\n            # We need to take all elements up to and including this index.\n            num_to_mark = np.searchsorted(cumulative_sum_sq, target_sum_sq) + 1\n            \n            marked_indices = sorted_indices[:num_to_mark]\n            unmarked_indices = sorted_indices[num_to_mark:]\n\n            # 4. REFINE: Create the new mesh\n            unmarked_elements = mesh[unmarked_indices]\n            \n            newly_refined_elements = []\n            for idx in marked_indices:\n                parent_center = mesh[idx, :2]\n                parent_size = mesh[idx, 2]\n                child_size = parent_size / 2.0\n                offset = child_size / 2.0\n                \n                # Generate 4 children\n                child_centers = [\n                    parent_center + np.array([-offset, -offset]),\n                    parent_center + np.array([ offset, -offset]),\n                    parent_center + np.array([-offset,  offset]),\n                    parent_center + np.array([ offset,  offset]),\n                ]\n                \n                for child_center in child_centers:\n                    if is_in_domain(child_center):\n                        newly_refined_elements.append([child_center[0], child_center[1], child_size])\n            \n            if newly_refined_elements:\n                mesh = np.vstack((unmarked_elements, np.array(newly_refined_elements)))\n            else:\n                mesh = unmarked_elements\n        \n        # 5. ESTIMATE CONVERGENCE RATE\n        # Use the last 5 data points for linear regression\n        if len(log_N_E_data)  5:\n            return np.nan # Cannot fit with fewer than 2 points, but problem asks for 5.\n\n        last_5_data = np.array(log_N_E_data[-5:])\n        log_N = last_5_data[:, 0]\n        log_E = last_5_data[:, 1]\n        \n        # Perform linear regression: log_E = slope * log_N + intercept\n        # np.polyfit returns [slope, intercept]\n        slope, _ = np.polyfit(log_N, log_E, 1)\n        \n        # Convergence rate p = -slope\n        p_theta = -slope\n        return p_theta\n\n    # --- Main Execution ---\n    results = []\n    for theta in THETAS:\n        rate = run_simulation(theta)\n        results.append(rate)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "3542038"}]}