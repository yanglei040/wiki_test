{"hands_on_practices": [{"introduction": "The foundation of anisotropic mesh refinement lies in the principle that mesh elements should be shaped and oriented to align with the features of the solution. This practice builds this concept from first principles by analyzing a function with a strong directional feature. By computing the Hessian matrix, you will quantify the function's local curvature and use its properties to determine the ideal aspect ratio of a mesh element needed to resolve it efficiently, directly connecting the analytical properties of the solution to the geometric design of the mesh [@problem_id:3363712].", "problem": "Consider the scalar field $u(x,y)=\\exp(-100x^{2}-y^{2})$ on the square domain $\\Omega=[-1,1]^{2}$. In the context of high-order Spectral Element Methods and Discontinuous Galerkin (DG) methods, anisotropic mesh refinement strategies are often guided by curvature information encoded in the Hessian, together with the principle of local error equidistribution along principal directions. Starting from Taylorâ€™s theorem and the definition of the Hessian as the matrix of second partial derivatives, do the following:\n\n1. Derive the full Hessian matrix $H_{u}(x,y)$ of $u$ at a general point $(x,y)$ by differentiating from first principles. You must write $H_{u}(x,y)$ explicitly in terms of $x$, $y$, and $u(x,y)$.\n\n2. Evaluate $H_{u}(0,0)$ and determine its eigenvalues and associated principal directions at the origin, interpreting their meaning in terms of the anisotropic curvature of $u$.\n\n3. Using the observation that, for polynomial degree $p\\geq 2$, the leading-order interpolation error of a smooth function on an element is governed by its second derivatives, construct a symmetric positive-definite metric tensor $M(x,y)$ that captures the anisotropy of $u$ by aligning with the principal directions of $H_{u}(x,y)$ and weighting according to the magnitudes of the principal curvatures. Then, at the point $(0,0)$, impose the canonical unit-metric edge-length condition in the principal frame and determine the anisotropy ratio of the optimal element edge lengths $h_{y}/h_{x}$ aligned with the principal directions at $(0,0)$.\n\nExpress your final answer as a single real number giving the ratio $h_{y}/h_{x}$ at the origin. No units are required, and no rounding is necessary.", "solution": "The problem is valid as it is scientifically grounded in the principles of numerical analysis and calculus, is well-posed, objective, and contains all necessary information for a unique solution.\n\nThe task is to analyze the scalar field $u(x,y)=\\exp(-100x^{2}-y^{2})$ for the purpose of anisotropic mesh refinement. This involves three steps: calculating the Hessian matrix, analyzing its properties at the origin, and determining the optimal element anisotropy ratio based on these properties.\n\n**Part 1: Derivation of the Hessian Matrix**\n\nThe Hessian matrix $H_{u}(x,y)$ is the matrix of second partial derivatives of the scalar field $u(x,y)$.\n$$ H_{u}(x,y) = \\begin{pmatrix} \\frac{\\partial^2 u}{\\partial x^2} & \\frac{\\partial^2 u}{\\partial x \\partial y} \\\\ \\frac{\\partial^2 u}{\\partial y \\partial x} & \\frac{\\partial^2 u}{\\partial y^2} \\end{pmatrix} $$\nThe given scalar field is $u(x,y) = \\exp(-100x^{2}-y^{2})$.\n\nFirst, we compute the first-order partial derivatives using the chain rule:\n$$ \\frac{\\partial u}{\\partial x} = \\frac{\\partial}{\\partial x} \\exp(-100x^{2}-y^{2}) = \\exp(-100x^{2}-y^{2}) \\cdot (-200x) = -200x u(x,y) $$\n$$ \\frac{\\partial u}{\\partial y} = \\frac{\\partial}{\\partial y} \\exp(-100x^{2}-y^{2}) = \\exp(-100x^{2}-y^{2}) \\cdot (-2y) = -2y u(x,y) $$\n\nNext, we compute the second-order partial derivatives using the product rule:\n$$ \\frac{\\partial^2 u}{\\partial x^2} = \\frac{\\partial}{\\partial x} \\left(-200x u(x,y)\\right) = -200 u(x,y) - 200x \\frac{\\partial u}{\\partial x} $$\nSubstituting the expression for $\\frac{\\partial u}{\\partial x}$:\n$$ \\frac{\\partial^2 u}{\\partial x^2} = -200 u(x,y) - 200x (-200x u(x,y)) = (-200 + 40000x^{2}) u(x,y) $$\n\n$$ \\frac{\\partial^2 u}{\\partial y^2} = \\frac{\\partial}{\\partial y} \\left(-2y u(x,y)\\right) = -2 u(x,y) - 2y \\frac{\\partial u}{\\partial y} $$\nSubstituting the expression for $\\frac{\\partial u}{\\partial y}$:\n$$ \\frac{\\partial^2 u}{\\partial y^2} = -2 u(x,y) - 2y (-2y u(x,y)) = (-2 + 4y^{2}) u(x,y) $$\n\nFor the mixed partial derivative, by Clairaut's theorem, we expect $\\frac{\\partial^2 u}{\\partial x \\partial y} = \\frac{\\partial^2 u}{\\partial y \\partial x}$ since $u$ is infinitely differentiable.\n$$ \\frac{\\partial^2 u}{\\partial x \\partial y} = \\frac{\\partial}{\\partial y} \\left(-200x u(x,y)\\right) = -200x \\frac{\\partial u}{\\partial y} = -200x (-2y u(x,y)) = 400xy u(x,y) $$\n\nAssembling these components, the Hessian matrix $H_{u}(x,y)$ is:\n$$ H_{u}(x,y) = \\begin{pmatrix} (40000x^{2} - 200) u(x,y) & 400xy u(x,y) \\\\ 400xy u(x,y) & (4y^{2} - 2) u(x,y) \\end{pmatrix} $$\nThis can be factored as:\n$$ H_{u}(x,y) = u(x,y) \\begin{pmatrix} 40000x^{2} - 200 & 400xy \\\\ 400xy & 4y^{2} - 2 \\end{pmatrix} $$\n\n**Part 2: Evaluation at the Origin**\n\nWe evaluate the Hessian at the point $(x,y) = (0,0)$.\nFirst, note that $u(0,0) = \\exp(-100(0)^{2}-(0)^{2}) = \\exp(0) = 1$.\nSubstituting $x=0$, $y=0$, and $u(0,0)=1$ into the Hessian matrix expression:\n$$ H_{u}(0,0) = 1 \\cdot \\begin{pmatrix} 40000(0)^{2} - 200 & 400(0)(0) \\\\ 400(0)(0) & 4(0)^{2} - 2 \\end{pmatrix} = \\begin{pmatrix} -200 & 0 \\\\ 0 & -2 \\end{pmatrix} $$\nSince $H_{u}(0,0)$ is a diagonal matrix, its eigenvalues are simply the diagonal entries:\n$$ \\lambda_{1} = -200 $$\n$$ \\lambda_{2} = -2 $$\nThe corresponding eigenvectors (principal directions) are the standard basis vectors:\nFor $\\lambda_{1} = -200$, the principal direction is $\\mathbf{v}_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, which corresponds to the $x$-axis.\nFor $\\lambda_{2} = -2$, the principal direction is $\\mathbf{v}_{2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, which corresponds to the $y$-axis.\n\nThe eigenvalues represent the principal curvatures of the function at the origin. The large negative value of $\\lambda_{1}$ indicates a very high curvature (a sharp peak) in the $x$-direction. The much smaller magnitude of $\\lambda_{2}$ indicates a significantly lower curvature in the $y$-direction. This describes a function that is highly elongated along the $y$-axis near the origin, requiring a mesh that is much finer in the $x$-direction than in the $y$-direction to resolve the feature accurately.\n\n**Part 3: Anisotropy Ratio**\n\nThe principle of error equidistribution in anisotropic mesh generation dictates that the approximation error should be constant along all principal directions. For interpolation-based error, the leading term is related to the product of the squared element size and the magnitude of the second derivative. In a multi-dimensional setting, this is expressed as $h_{i}^{2} |\\lambda_{i}| \\approx C$, where $h_{i}$ is the element edge length along the $i$-th principal direction, $\\lambda_{i}$ is the corresponding eigenvalue of the Hessian, and $C$ is a constant.\n\nThe problem asks to formalize this using a metric tensor $M(x,y)$. A suitable metric tensor is constructed from the Hessian such that isotropic elements in the transformed space correspond to anisotropic elements in the physical space, adapted to the function's features. A common choice is $M = V |\\Lambda| V^T$, where $V$ is the matrix of eigenvectors of the Hessian and $|\\Lambda|$ is the diagonal matrix of the absolute values of the eigenvalues. At the origin $(0,0)$, the eigenvectors align with the coordinate axes, so $V = I$ (the identity matrix).\n$$ M(0,0) \\propto |H_{u}(0,0)| = \\begin{pmatrix} |-200| & 0 \\\\ 0 & |-2| \\end{pmatrix} = \\begin{pmatrix} 200 & 0 \\\\ 0 & 2 \\end{pmatrix} $$\nThe \"canonical unit-metric edge-length condition\" states that the length of an optimal element edge, $\\mathbf{h}_{i}$, measured in the metric $M$, should be unity: $\\mathbf{h}_{i}^{T} M \\mathbf{h}_{i} = 1$. Let the optimal element at the origin have edge lengths $h_{x}$ and $h_{y}$ aligned with the principal directions (the axes).\nThe edge vector in the $x$-direction is $\\mathbf{h}_{x} = (h_{x}, 0)^{T}$. The condition becomes:\n$$ \\mathbf{h}_{x}^{T} M(0,0) \\mathbf{h}_{x} = \\begin{pmatrix} h_{x} & 0 \\end{pmatrix} \\begin{pmatrix} 200 & 0 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} h_{x} \\\\ 0 \\end{pmatrix} = 200 h_{x}^{2} $$\nLet's set $200 h_{x}^{2} = C_{M}$ where $C_{M}$ is some constant related to the choice of metric scaling (here, we can absorb it into the definition of \"unit length\").\n\nThe edge vector in the $y$-direction is $\\mathbf{h}_{y} = (0, h_{y})^{T}$. The condition becomes:\n$$ \\mathbf{h}_{y}^{T} M(0,0) \\mathbf{h}_{y} = \\begin{pmatrix} 0 & h_{y} \\end{pmatrix} \\begin{pmatrix} 200 & 0 \\\\ 0 & 2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ h_{y} \\end{pmatrix} = 2 h_{y}^{2} $$\nSetting this to the same constant, $2 h_{y}^{2} = C_{M}$.\n\nEquating the two expressions gives the relationship between the optimal edge lengths:\n$$ 200 h_{x}^{2} = 2 h_{y}^{2} $$\nWe are asked to find the anisotropy ratio $h_{y} / h_{x}$. We rearrange the equation to solve for this ratio:\n$$ \\frac{h_{y}^{2}}{h_{x}^{2}} = \\frac{200}{2} = 100 $$\nTaking the square root of both sides (since edge lengths $h_{x}$ and $h_{y}$ are positive):\n$$ \\frac{h_{y}}{h_{x}} = \\sqrt{100} = 10 $$\nThis result indicates that, to optimally resolve the function $u(x,y)$ at the origin, the mesh element should be $10$ times longer in the $y$-direction than in the $x$-direction.", "answer": "$$\n\\boxed{10}\n$$", "id": "3363712"}, {"introduction": "Once the desired anisotropy is determined, it must be encoded in a form that a mesh generator can use, which is typically a Riemannian metric tensor field. This metric redefines the notion of distance throughout the domain, stretching and shrinking space to reflect the solution's behavior. In this exercise, you will make this abstract concept concrete by using a given metric tensor to calculate the \"length\" of each edge of a triangular element, a critical step in algorithms that refine a mesh by splitting its longest edges [@problem_id:3363774].", "problem": "Consider a two-dimensional triangular element in a discontinuous Galerkin (DG) discretization of a scalar conservation law, where anisotropic mesh adaptation is driven by a spatially varying Riemannian metric field $M(\\mathbf{x})$. The metric is derived from a spectral reconstruction of the local solution Hessian and is guaranteed to be symmetric positive definite (SPD). The Riemannian length of a straight edge segment $\\gamma:[0,1]\\to\\mathbb{R}^{2}$ with endpoints $\\mathbf{x}_{i}$ and $\\mathbf{x}_{j}$ and constant tangent $\\dot{\\gamma}(s)=\\mathbf{e}$ is defined by the fundamental expression\n$$\nL_{M}(\\gamma)\\;=\\;\\int_{0}^{1}\\sqrt{\\dot{\\gamma}(s)^{\\top}M(\\gamma(s))\\,\\dot{\\gamma}(s)}\\,\\mathrm{d}s,\n$$\nwhich governs anisotropic refinement policies that preferentially split the longest edge in the metric to align elements with directions of high curvature in the DG solution.\n\nYou are given a specific triangular element with vertices\n$$\n\\mathbf{x}_{1}=(0,\\,0),\\quad \\mathbf{x}_{2}=(1,\\,0.5),\\quad \\mathbf{x}_{3}=(0.3,\\,1).\n$$\nThe metric is specified by $M(\\mathbf{x})=A(\\mathbf{x})^{\\top}A(\\mathbf{x})$, with\n$$\nA(x,\\,y)\\;=\\;\\begin{pmatrix}1+x & y \\\\ 0.5 & 2+0.5\\,y\\end{pmatrix}.\n$$\nTo decide the next anisotropic refinement split for this element, approximate $L_{M}(\\gamma)$ on each straight edge using a consistent two-point quadrature that evaluates the metric at the vertices and assumes constant tangent along the edge. Then select the edge with the largest discrete metric length. Use the following labeling:\n$$\n\\text{edge }1:\\ \\overline{\\mathbf{x}_{1}\\mathbf{x}_{2}},\\qquad\n\\text{edge }2:\\ \\overline{\\mathbf{x}_{2}\\mathbf{x}_{3}},\\qquad\n\\text{edge }3:\\ \\overline{\\mathbf{x}_{3}\\mathbf{x}_{1}}.\n$$\nReport the selected edge as a single integer according to this labeling. No rounding is required, and no units are to be included in the final answer.", "solution": "The problem requires the identification of the longest edge of a given triangular element, where length is measured by a spatially varying Riemannian metric $M(\\mathbf{x})$. The refinement strategy is to split the longest edge.\n\nThe vertices of the triangle are given as:\n$$\n\\mathbf{x}_{1}=(0,\\,0),\\quad \\mathbf{x}_{2}=(1,\\,0.5),\\quad \\mathbf{x}_{3}=(0.3,\\,1).\n$$\nThe Riemannian metric is defined by $M(\\mathbf{x}) = A(\\mathbf{x})^{\\top}A(\\mathbf{x})$, where $\\mathbf{x}=(x,y)$ and\n$$\nA(x,\\,y)\\;=\\;\\begin{pmatrix}1+x & y \\\\ 0.5 & 2+0.5\\,y\\end{pmatrix}.\n$$\nThe length of a straight edge $\\gamma$ with constant tangent vector $\\mathbf{e}$ is given by the integral $L_{M}(\\gamma)\\;=\\;\\int_{0}^{1}\\sqrt{\\mathbf{e}^{\\top}M(\\gamma(s))\\,\\mathbf{e}}\\,\\mathrm{d}s$.\nWe are instructed to approximate this integral using a two-point quadrature rule that evaluates the integrand at the vertices. For an edge connecting $\\mathbf{x}_i$ and $\\mathbf{x}_j$, parameterized by $\\gamma(s) = (1-s)\\mathbf{x}_i + s\\mathbf{x}_j$ for $s \\in [0,1]$, the tangent vector is $\\mathbf{e}_{ij} = \\mathbf{x}_j - \\mathbf{x}_i$. The trapezoidal rule approximation for the length is:\n$$\nL_{ij} \\approx \\frac{1}{2} \\left( \\sqrt{\\mathbf{e}_{ij}^{\\top}M(\\mathbf{x}_i)\\mathbf{e}_{ij}} + \\sqrt{\\mathbf{e}_{ij}^{\\top}M(\\mathbf{x}_j)\\mathbf{e}_{ij}} \\right).\n$$\nTo solve the problem, we will compute this approximate length for each of the three edges and identify the largest one.\n\nFirst, we compute the metric matrices at the three vertices.\nAt $\\mathbf{x}_{1}=(0,0)$:\n$$\nA(\\mathbf{x}_1) = A(0,0) = \\begin{pmatrix} 1 & 0 \\\\ 0.5 & 2 \\end{pmatrix}\n$$\n$$\nM(\\mathbf{x}_1) = A(\\mathbf{x}_1)^{\\top}A(\\mathbf{x}_1) = \\begin{pmatrix} 1 & 0.5 \\\\ 0 & 2 \\end{pmatrix}\\begin{pmatrix} 1 & 0 \\\\ 0.5 & 2 \\end{pmatrix} = \\begin{pmatrix} 1.25 & 1 \\\\ 1 & 4 \\end{pmatrix}\n$$\nAt $\\mathbf{x}_{2}=(1,0.5)$:\n$$\nA(\\mathbf{x}_2) = A(1,0.5) = \\begin{pmatrix} 1+1 & 0.5 \\\\ 0.5 & 2+0.5(0.5) \\end{pmatrix} = \\begin{pmatrix} 2 & 0.5 \\\\ 0.5 & 2.25 \\end{pmatrix}\n$$\n$$\nM(\\mathbf{x}_2) = A(\\mathbf{x}_2)^{\\top}A(\\mathbf{x}_2) = \\begin{pmatrix} 2 & 0.5 \\\\ 0.5 & 2.25 \\end{pmatrix}\\begin{pmatrix} 2 & 0.5 \\\\ 0.5 & 2.25 \\end{pmatrix} = \\begin{pmatrix} 4.25 & 2.125 \\\\ 2.125 & 5.3125 \\end{pmatrix}\n$$\nAt $\\mathbf{x}_{3}=(0.3,1)$:\n$$\nA(\\mathbf{x}_3) = A(0.3,1) = \\begin{pmatrix} 1+0.3 & 1 \\\\ 0.5 & 2+0.5(1) \\end{pmatrix} = \\begin{pmatrix} 1.3 & 1 \\\\ 0.5 & 2.5 \\end{pmatrix}\n$$\n$$\nM(\\mathbf{x}_3) = A(\\mathbf{x}_3)^{\\top}A(\\mathbf{x}_3) = \\begin{pmatrix} 1.3 & 0.5 \\\\ 1 & 2.5 \\end{pmatrix}\\begin{pmatrix} 1.3 & 1 \\\\ 0.5 & 2.5 \\end{pmatrix} = \\begin{pmatrix} 1.94 & 2.55 \\\\ 2.55 & 7.25 \\end{pmatrix}\n$$\n\nNext, we calculate the lengths of the three edges.\n\n**Edge 1: $\\overline{\\mathbf{x}_{1}\\mathbf{x}_{2}}$**\nThe tangent vector is $\\mathbf{e}_{12} = \\mathbf{x}_2 - \\mathbf{x}_1 = (1, 0.5)^{\\top}$.\nThe quadratic forms are:\n$$\nQ_{12,1} = \\mathbf{e}_{12}^{\\top}M(\\mathbf{x}_1)\\mathbf{e}_{12} = \\begin{pmatrix} 1 & 0.5 \\end{pmatrix} \\begin{pmatrix} 1.25 & 1 \\\\ 1 & 4 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix} = 3.25\n$$\n$$\nQ_{12,2} = \\mathbf{e}_{12}^{\\top}M(\\mathbf{x}_2)\\mathbf{e}_{12} = \\begin{pmatrix} 1 & 0.5 \\end{pmatrix} \\begin{pmatrix} 4.25 & 2.125 \\\\ 2.125 & 5.3125 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix} = 7.703125\n$$\nThe approximate length is $L_1 \\approx \\frac{1}{2}\\left( \\sqrt{3.25} + \\sqrt{7.703125} \\right)$.\n\n**Edge 2: $\\overline{\\mathbf{x}_{2}\\mathbf{x}_{3}}$**\nThe tangent vector is $\\mathbf{e}_{23} = \\mathbf{x}_3 - \\mathbf{x}_2 = (0.3-1, 1-0.5)^{\\top} = (-0.7, 0.5)^{\\top}$.\nThe quadratic forms are:\n$$\nQ_{23,2} = \\mathbf{e}_{23}^{\\top}M(\\mathbf{x}_2)\\mathbf{e}_{23} = \\begin{pmatrix} -0.7 & 0.5 \\end{pmatrix} \\begin{pmatrix} 4.25 & 2.125 \\\\ 2.125 & 5.3125 \\end{pmatrix} \\begin{pmatrix} -0.7 \\\\ 0.5 \\end{pmatrix} = 1.923125\n$$\n$$\nQ_{23,3} = \\mathbf{e}_{23}^{\\top}M(\\mathbf{x}_3)\\mathbf{e}_{23} = \\begin{pmatrix} -0.7 & 0.5 \\end{pmatrix} \\begin{pmatrix} 1.94 & 2.55 \\\\ 2.55 & 7.25 \\end{pmatrix} \\begin{pmatrix} -0.7 \\\\ 0.5 \\end{pmatrix} = 0.9781\n$$\nThe approximate length is $L_2 \\approx \\frac{1}{2}\\left( \\sqrt{1.923125} + \\sqrt{0.9781} \\right)$.\n\n**Edge 3: $\\overline{\\mathbf{x}_{3}\\mathbf{x}_{1}}$**\nThe tangent vector is $\\mathbf{e}_{31} = \\mathbf{x}_1 - \\mathbf{x}_3 = (-0.3, -1)^{\\top}$. The quadratic form is invariant to the sign of the vector, so we may use $-\\mathbf{e}_{31} = (0.3, 1)^{\\top}$ for convenience.\nThe quadratic forms are:\n$$\nQ_{31,3} = \\mathbf{e}_{31}^{\\top}M(\\mathbf{x}_3)\\mathbf{e}_{31} = \\begin{pmatrix} 0.3 & 1 \\end{pmatrix} \\begin{pmatrix} 1.94 & 2.55 \\\\ 2.55 & 7.25 \\end{pmatrix} \\begin{pmatrix} 0.3 \\\\ 1 \\end{pmatrix} = 8.9546\n$$\n$$\nQ_{31,1} = \\mathbf{e}_{31}^{\\top}M(\\mathbf{x}_1)\\mathbf{e}_{31} = \\begin{pmatrix} 0.3 & 1 \\end{pmatrix} \\begin{pmatrix} 1.25 & 1 \\\\ 1 & 4 \\end{pmatrix} \\begin{pmatrix} 0.3 \\\\ 1 \\end{pmatrix} = 4.7125\n$$\nThe approximate length is $L_3 \\approx \\frac{1}{2}\\left( \\sqrt{8.9546} + \\sqrt{4.7125} \\right)$.\n\nFinally, we compare the lengths $L_1$, $L_2$, and $L_3$. Since the factor of $\\frac{1}{2}$ is common, we only need to compare the sums of the square roots.\nLet $S_1 = \\sqrt{3.25} + \\sqrt{7.703125}$, $S_2 = \\sqrt{1.923125} + \\sqrt{0.9781}$, and $S_3 = \\sqrt{8.9546} + \\sqrt{4.7125}$.\n\nComparing $S_3$ and $S_1$:\nSince $8.9546 > 7.703125$, it follows that $\\sqrt{8.9546} > \\sqrt{7.703125}$.\nSince $4.7125 > 3.25$, it follows that $\\sqrt{4.7125} > \\sqrt{3.25}$.\nSumming these two inequalities of positive numbers yields $S_3 > S_1$. Thus, $L_3 > L_1$.\n\nComparing $S_1$ and $S_2$:\nSince $7.703125 > 1.923125$, it follows that $\\sqrt{7.703125} > \\sqrt{1.923125}$.\nSince $3.25 > 0.9781$, it follows that $\\sqrt{3.25} > \\sqrt{0.9781}$.\nSumming these two inequalities yields $S_1 > S_2$. Thus, $L_1 > L_2$.\n\nCombining the results, we have the ordering $L_3 > L_1 > L_2$. The edge with the largest metric length is edge 3.", "answer": "$$\n\\boxed{3}\n$$", "id": "3363774"}, {"introduction": "Effective mesh adaptation requires not just local intelligence but also a global strategy, especially when operating under a fixed computational budget. This problem elevates the concept to the level of a complete adaptive loop, framing mesh refinement as a constrained optimization problem. Using the method of Lagrange multipliers, you will derive a rule for optimally distributing a fixed number of degrees of freedom across the domain to minimize the total estimated error, providing a powerful and practical tool for resource allocation in numerical simulations [@problem_id:3363715].", "problem": "Consider a scalar, two-dimensional, time-independent problem on the unit square domain $\\Omega = [0,1] \\times [0,1]$ to be discretized using Spectral and Discontinuous Galerkin methods with fixed polynomial degree per element. The goal is to design and analyze a single iteration of an anisotropic mesh adaptation loop consisting of: solve, estimate, build metric, and generate mesh, and to compute the Lagrange multiplier that enforces a global degrees-of-freedom budget.\n\nThe adaptive loop is built from the following base principles and definitions.\n\n1. The spectral and discontinuous Galerkin discretizations use a fixed polynomial degree $p$ per element. The number of degrees of freedom (DoF) per element scales like $(p+1)^2$ for tensor-product bases.\n\n2. The anisotropic metric is built from a curvature surrogate derived from the Hessian of a known analytic solution. Let the analytic field be $u(x,y) = \\exp(\\kappa x)\\cos(\\nu \\pi y)$ on $\\Omega$, where $\\kappa > 0$ and $\\nu > 0$ are given constants. The Hessian matrix at a point $(x,y)$ is\n$$\nH(u)(x,y) = \\begin{pmatrix}\n\\frac{\\partial^2 u}{\\partial x^2}(x,y) & \\frac{\\partial^2 u}{\\partial x \\partial y}(x,y) \\\\\n\\frac{\\partial^2 u}{\\partial y \\partial x}(x,y) & \\frac{\\partial^2 u}{\\partial y^2}(x,y)\n\\end{pmatrix},\n$$\nwith entries computed analytically. Define a curvature surrogate on an element $e$ as\n$$\na_e = \\|H(u)(x_e,y_e)\\|_F \\cdot |e|,\n$$\nwhere $\\| \\cdot \\|_F$ is the Frobenius norm and $(x_e,y_e)$ is the barycenter of element $e$, and $|e|$ is the area of element $e$.\n\n3. The initial mesh is a uniform partition of $\\Omega$ into $2 \\times 2$ rectangular elements, each of area $|e| = 1/4$, with barycenters at $(x_e,y_e) \\in \\{(1/4,1/4),(3/4,1/4),(1/4,3/4),(3/4,3/4)\\}$.\n\n4. The error estimate is based on the standard interpolation theory for tensor-product spectral elements in two space dimensions: the local interpolation error on element $e$ scales as $h_e^{p+1}$, where $h_e$ is a representative element size. In two dimensions, if each coarse element $e$ is anisotropically subdivided into $m_e$ subelements (not necessarily integer in the continuous optimization model), then $h_e \\propto m_e^{-1/2}$ and the model for the local error takes the form\n$$\nE_e(m_e) = a_e \\, m_e^{-\\beta}, \\quad \\beta = \\frac{p+1}{2}.\n$$\n\n5. The global degrees-of-freedom budget $B$ is enforced through the constraint\n$$\n\\sum_{e} (p+1)^2 \\, m_e = B,\n$$\nequivalently,\n$$\n\\sum_{e} m_e = M_{\\text{target}}, \\quad M_{\\text{target}} = \\frac{B}{(p+1)^2}.\n$$\n\n6. The metric-based allocation is obtained by minimizing the total estimated error subject to the budget constraint, using the method of Lagrange multipliers. The objective is\n$$\n\\min_{\\{m_e>0\\}} \\sum_{e} a_e \\, m_e^{-\\beta}\n\\quad \\text{subject to} \\quad \\sum_{e} m_e = M_{\\text{target}}.\n$$\n\nFormulate the Lagrangian and derive the first-order optimality conditions. Show that the optimal $m_e$ can be written in terms of the Lagrange multiplier $\\lambda$ and the curvature surrogates $a_e$, and derive a closed-form expression for $\\lambda$ that enforces the degrees-of-freedom constraint. Implement one adaptive loop iteration that does the following:\n- solve: evaluate the analytic solution to define the curvature surrogate,\n- estimate: compute $a_e$ on each element $e$,\n- build metric: compute the optimal $m_e$ from the derived formula in terms of $\\lambda$ and $a_e$,\n- generate mesh: map $m_e$ to integer subelement counts by rounding (this step is not required for the output, but must be performed in the program to complete the loop logically).\n\nYour program must compute and report only the Lagrange multiplier $\\lambda$ for each of the following test cases. Use $\\kappa = 4$ and $\\nu = 8$ in all cases. The coarse mesh is fixed as described above.\n\nTest suite:\n- Case $1$: polynomial degree $p = 4$, budget $B = 400$.\n- Case $2$: polynomial degree $p = 6$, budget $B = 350$.\n- Case $3$: polynomial degree $p = 5$, budget $B = 10$.\n- Case $4$: polynomial degree $p = 3$, budget $B = 1000$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[result_1,result_2,result_3,result_4]$). The outputs must be the values of $\\lambda$ for the four test cases as decimal floats. No physical units or angles are involved, so no unit conversion is required.", "solution": "The problem is valid as it is scientifically grounded in the theory of numerical analysis for partial differential equations, specifically in the area of anisotropic mesh adaptation for spectral and discontinuous Galerkin methods. The problem is well-posed, objective, self-contained, and all terms and parameters are clearly defined.\n\nThe task is to find the Lagrange multiplier $\\lambda$ associated with a constrained optimization problem. The goal is to minimize the total estimated error, $\\sum_e E_e$, subject to a fixed budget on the total number of degrees of freedom, $B$.\n\nThe local error on an element $e$ is modeled as $E_e(m_e) = a_e \\, m_e^{-\\beta}$, where $m_e$ is the number of new sub-elements into which the coarse element $e$ is subdivided. The parameter $\\beta$ is given by $\\beta = \\frac{p+1}{2}$, where $p$ is the polynomial degree. The quantity $a_e$ is a curvature surrogate.\n\nThe total number of degrees of freedom (DoF) is given by $\\sum_e (p+1)^2 m_e$. The budget constraint is $\\sum_e (p+1)^2 m_e = B$. This can be rewritten in terms of the total number of new elements, $M_{\\text{target}}$, as $\\sum_e m_e = M_{\\text{target}}$, where $M_{\\text{target}} = \\frac{B}{(p+1)^2}$.\n\nThe optimization problem is thus:\n$$\n\\min_{\\{m_e>0\\}} \\sum_{e} a_e \\, m_e^{-\\beta}\n\\quad \\text{subject to} \\quad \\sum_{e} m_e = M_{\\text{target}}.\n$$\nTo solve this constrained optimization problem, we use the method of Lagrange multipliers. We define the Lagrangian function $\\mathcal{L}$ as:\n$$\n\\mathcal{L}(\\{m_e\\}, \\lambda) = \\sum_{e} a_e m_e^{-\\beta} + \\lambda \\left( \\left(\\sum_{e} m_e\\right) - M_{\\text{target}} \\right)\n$$\nwhere $\\lambda$ is the Lagrange multiplier. The first-order necessary conditions for optimality are obtained by setting the partial derivatives of $\\mathcal{L}$ with respect to each $m_e$ and to $\\lambda$ to zero.\n\nThe partial derivative with respect to an arbitrary $m_k$ is:\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial m_k} = \\frac{\\partial}{\\partial m_k} \\left( \\sum_{e} a_e m_e^{-\\beta} \\right) + \\frac{\\partial}{\\partial m_k} \\left( \\lambda \\left( \\left(\\sum_{e} m_e\\right) - M_{\\text{target}} \\right) \\right) = 0\n$$\n$$\n-\\beta a_k m_k^{-\\beta-1} + \\lambda = 0\n$$\nThis condition must hold for each element $k$. From this, we can express the optimal $m_k$ in terms of the Lagrange multiplier $\\lambda$:\n$$\n\\lambda = \\beta a_k m_k^{-(\\beta+1)}\n$$\n$$\nm_k^{\\beta+1} = \\frac{\\beta a_k}{\\lambda}\n$$\n$$\nm_k = \\left( \\frac{\\beta a_k}{\\lambda} \\right)^{\\frac{1}{\\beta+1}}\n$$\nThis equation represents the equi-distribution principle, where the quantity $\\beta a_k m_k^{-(\\beta+1)}$ is constant across all elements and equal to $\\lambda$.\n\nTo find the value of $\\lambda$, we enforce the budget constraint $\\sum_e m_e = M_{\\text{target}}$. We substitute the expression for $m_e$ into the constraint:\n$$\n\\sum_{e} \\left( \\frac{\\beta a_e}{\\lambda} \\right)^{\\frac{1}{\\beta+1}} = M_{\\text{target}}\n$$\nWe can factor out the terms involving $\\beta$ and $\\lambda$, as they are constant for all elements:\n$$\n\\left( \\frac{\\beta}{\\lambda} \\right)^{\\frac{1}{\\beta+1}} \\sum_{e} a_e^{\\frac{1}{\\beta+1}} = M_{\\text{target}}\n$$\nNow, we solve for $\\lambda$:\n$$\n\\left( \\frac{\\beta}{\\lambda} \\right)^{\\frac{1}{\\beta+1}} = \\frac{M_{\\text{target}}}{\\sum_{e} a_e^{\\frac{1}{\\beta+1}}}\n$$\nRaising both sides to the power of $\\beta+1$:\n$$\n\\frac{\\beta}{\\lambda} = \\left( \\frac{M_{\\text{target}}}{\\sum_{e} a_e^{\\frac{1}{\\beta+1}}} \\right)^{\\beta+1}\n$$\nFinally, we obtain the closed-form expression for $\\lambda$:\n$$\n\\lambda = \\beta \\left( \\frac{\\sum_{e} a_e^{\\frac{1}{\\beta+1}}}{M_{\\text{target}}} \\right)^{\\beta+1}\n$$\nThe value of $\\lambda$ can be computed once the curvature surrogates $a_e$ are known. The surrogate $a_e$ is defined as $a_e = \\|H(u)(x_e,y_e)\\|_F \\cdot |e|$, where $(x_e, y_e)$ is the element barycenter, $|e|$ is the element area, and $H(u)$ is the Hessian of the analytic solution $u(x,y) = \\exp(\\kappa x)\\cos(\\nu \\pi y)$.\n\nThe partial derivatives of $u(x,y)$ are:\n- $\\frac{\\partial^2 u}{\\partial x^2} = \\kappa^2 \\exp(\\kappa x) \\cos(\\nu \\pi y)$\n- $\\frac{\\partial^2 u}{\\partial y^2} = -(\\nu \\pi)^2 \\exp(\\kappa x) \\cos(\\nu \\pi y)$\n- $\\frac{\\partial^2 u}{\\partial x \\partial y} = -\\kappa \\nu \\pi \\exp(\\kappa x) \\sin(\\nu \\pi y)$\n\nThe squared Frobenius norm of the Hessian matrix $H(u)$ is:\n$$\n\\|H(u)\\|_F^2 = \\left(\\frac{\\partial^2 u}{\\partial x^2}\\right)^2 + \\left(\\frac{\\partial^2 u}{\\partial y^2}\\right)^2 + 2\\left(\\frac{\\partial^2 u}{\\partial x \\partial y}\\right)^2\n$$\n$$\n\\|H(u)(x,y)\\|_F^2 = e^{2\\kappa x} \\left[ (\\kappa^4 + (\\nu \\pi)^4) \\cos^2(\\nu \\pi y) + 2(\\kappa \\nu \\pi)^2 \\sin^2(\\nu \\pi y) \\right]\n$$\nThe initial mesh consists of $4$ elements, each of area $|e| = 1/4 = 0.25$. The barycenters are given as $\\{(1/4,1/4),(3/4,1/4),(1/4,3/4),(3/4,3/4)\\}$. For the given constants $\\kappa=4$ and $\\nu=8$, and for any barycenter coordinate $y_e \\in \\{1/4, 3/4\\}$, the term $\\nu \\pi y_e$ evaluates to $8\\pi/4 = 2\\pi$ or $8\\pi(3/4) = 6\\pi$. In both cases, $\\sin(\\nu \\pi y_e)=0$ and $\\cos(\\nu \\pi y_e)=1$. This simplifies the Frobenius norm calculation significantly:\n$$\n\\|H(u)(x_e,y_e)\\|_F = \\exp(\\kappa x_e) \\sqrt{\\kappa^4 + (\\nu \\pi)^4}\n$$\nThe algorithm to compute $\\lambda$ is as follows:\n1. For a given test case ($p, B$), calculate $\\beta = (p+1)/2$ and $M_{\\text{target}} = B/(p+1)^2$.\n2. For each of the $4$ elements, evaluate the barycenter coordinates $(x_e, y_e)$.\n3. Compute the curvature surrogate $a_e = |e| \\cdot \\exp(\\kappa x_e) \\sqrt{\\kappa^4 + (\\nu \\pi)^4}$.\n4. Compute the sum $S = \\sum_e a_e^{\\frac{1}{\\beta+1}}$.\n5. Compute $\\lambda = \\beta (S / M_{\\text{target}})^{\\beta+1}$.\nThis procedure is implemented for each test case to obtain the required results.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Lagrange multiplier for anisotropic mesh adaptation based on a given\n    analytic solution, error model, and resource budget.\n    \"\"\"\n    # Global constants from the problem statement.\n    KAPPA = 4.0\n    NU = 8.0\n    # The initial mesh is a 2x2 grid on the unit square.\n    BARYCENTERS = [(0.25, 0.25), (0.75, 0.25), (0.25, 0.75), (0.75, 0.75)]\n    ELEM_AREA = 0.25\n\n    # Test suite from the problem statement.\n    test_cases = [\n        # (polynomial degree p, DoF budget B)\n        (4, 400),\n        (6, 350),\n        (5, 10),\n        (3, 1000),\n    ]\n\n    # Pre-compute the constant part of the Frobenius norm.\n    # For the given barycenters, sin(NU*pi*y_e) is always 0.\n    # So, ||H||_F_sq = exp(2*KAPPA*x_e) * (KAPPA**4 + (NU*pi)**4)\n    norm_const = np.sqrt(KAPPA**4 + (NU * np.pi)**4)\n\n    results = []\n    # Process each test case.\n    for p, B in test_cases:\n        # Step 1: `solve` and `estimate`\n        # Compute problem-specific parameters and curvature surrogates a_e.\n        beta = (p + 1.0) / 2.0\n        dof_per_element = (p + 1.0)**2\n        M_target = B / dof_per_element\n\n        a_e_list = []\n        for x_e, y_e in BARYCENTERS:\n            # The simplified Frobenius norm at the barycenter.\n            norm_H = np.exp(KAPPA * x_e) * norm_const\n            a_e = norm_H * ELEM_AREA\n            a_e_list.append(a_e)\n        \n        a_e_array = np.array(a_e_list)\n\n        # Step 2: `build metric` (part 1: find lambda)\n        # Compute the sum term required for the Lagrange multiplier formula.\n        power = 1.0 / (beta + 1.0)\n        sum_term = np.sum(np.power(a_e_array, power))\n\n        # Compute the Lagrange multiplier lambda.\n        lambda_val = beta * np.power(sum_term / M_target, beta + 1.0)\n        results.append(lambda_val)\n\n        # The subsequent parts of the adaptive loop are included for logical completeness\n        # as per the problem description, but are not required for the final output.\n        \n        # Step 3: `build metric` (part 2: find optimal m_e)\n        # Compute the optimal number of subdivisions m_e for each element.\n        m_e_optimal = np.power(beta * a_e_array / lambda_val, power)\n        \n        # This can be used to verify the constraint is met.\n        # assert np.isclose(np.sum(m_e_optimal), M_target)\n\n        # Step 4: `generate mesh`\n        # Map the continuous m_e values to integer subelement counts, typically by rounding.\n        # These integer values would inform the actual mesh generation process.\n        m_e_integer = np.round(m_e_optimal)\n\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3363715"}]}