{"hands_on_practices": [{"introduction": "In many scientific and engineering applications, the signals we analyze are real-valued. The Discrete Fourier Transform (DFT) of a real sequence possesses a special property known as Hermitian symmetry, which implies that roughly half of its complex-valued output is redundant. This hands-on practice challenges you to leverage this fundamental property to design a memory-efficient storage layout, a crucial optimization in applications where memory is a premium. By implementing and verifying an algorithm to pack and unpack the DFT spectrum, you will gain a deeper, practical understanding of the structure of the Fourier transform and its symmetries [@problem_id:3381085].", "problem": "You are given a real-valued sequence of length $N$ and its Discrete Fourier Transform (DFT) as defined by the forward transform\n$$\nX_k = \\sum_{n=0}^{N-1} x_n\\,e^{-2\\pi i kn/N},\\quad k=0,1,\\dots,N-1,\n$$\nand the inverse transform\n$$\nx_n = \\frac{1}{N}\\sum_{k=0}^{N-1} X_k\\,e^{2\\pi i kn/N},\\quad n=0,1,\\dots,N-1.\n$$\nAngles are to be interpreted in radians. For real input $x_n\\in\\mathbb{R}$, the DFT obeys Hermitian symmetry:\n$$\nX_{N-k} = \\overline{X_k},\\quad k=1,2,\\dots,N-1,\n$$\nand when $N$ is even, the Nyquist bin satisfies $X_{N/2}\\in\\mathbb{R}$, while $X_0\\in\\mathbb{R}$ for all $N$.\n\nTask: Design a storage layout that packs the nonredundant information in the DFT of a real-valued sequence into a real array of length $N$ (that is, exactly $N$ real numbers). The layout must encode the entire set of degrees of freedom in the DFT resulting from the Hermitian symmetry. Derive the inverse unpacking algorithm that reconstructs the full complex spectrum $\\{X_k\\}_{k=0}^{N-1}$ from this packed real array, for both the cases of even $N$ and odd $N$, and justify correctness from first principles based on the above definitions and properties.\n\nYour program must implement the following:\n- A function that takes the full complex spectrum $\\{X_k\\}_{k=0}^{N-1}$ of a real input sequence and returns the packed real array of length $N$ according to your layout.\n- A function that takes such a packed array and $N$ and reconstructs the full complex spectrum $\\{X_k\\}_{k=0}^{N-1}$ using your inverse unpacking algorithm, enforcing Hermitian symmetry and the special cases of $X_0$ and (if $N$ is even) $X_{N/2}$ being real.\n- A verification routine that, for each test case, computes the forward DFT of the given real sequence, packs it, unpacks it to a full spectrum, applies the inverse DFT, and compares the reconstructed real sequence to the original one. The comparison must use the maximum absolute reconstruction error and declare the test as passing if and only if this error is less than or equal to $10^{-10}$.\n\nTest Suite:\nUse the following four test cases, which exercise different aspects of the problem, including edge cases.\n1. $N=1$, with $x_0=3.5$.\n2. $N=2$, with $x_0=1.0$, $x_1=-2.0$.\n3. $N=7$, with $x_n = 0.3 + \\cos\\!\\big(2\\pi\\cdot 1\\cdot n/7\\big) + 0.5\\,\\sin\\!\\big(2\\pi\\cdot 2\\cdot n/7\\big)$ for $n=0,1,\\dots,6$.\n4. $N=8$, with $x_n = 0.1 + 1.25\\,\\cos\\!\\big(2\\pi\\cdot 3\\cdot n/8\\big) + 2.0\\,\\cos\\!\\big(\\pi\\cdot n\\big) + 0.75\\,\\sin\\!\\big(2\\pi\\cdot 1\\cdot n/8\\big)$ for $n=0,1,\\dots,7$.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each entry is a boolean indicating whether the corresponding test case passed (for example, $[{\\tt True},{\\tt False},{\\tt True},{\\tt True}]$). Angles must be interpreted in radians throughout, and no physical units are involved. The final outputs are booleans only.", "solution": "The problem requires the design of a storage layout and corresponding packing/unpacking algorithms to represent the Discrete Fourier Transform (DFT) of a real-valued sequence of length $N$ using exactly $N$ real numbers. The correctness of the algorithms must be justified from first principles.\n\nThe DFT $\\{X_k\\}_{k=0}^{N-1}$ of a real-valued sequence $\\{x_n\\}_{n=0}^{N-1}$ where $x_n \\in \\mathbb{R}$ possesses Hermitian symmetry. This property is the foundation of the compact storage scheme. The symmetry is expressed as:\n$$\nX_{N-k} = \\overline{X_k}, \\quad k=1, 2, \\dots, N-1\n$$\nwhere $\\overline{X_k}$ denotes the complex conjugate of $X_k$. Additionally, two specific frequency components have special properties:\n1.  The DC component $X_0 = \\sum_{n=0}^{N-1} x_n$ is always real since all $x_n$ are real.\n2.  For an even length $N$, the Nyquist component $X_{N/2} = \\sum_{n=0}^{N-1} x_n e^{-i\\pi n} = \\sum_{n=0}^{N-1} x_n (-1)^n$ is also always real.\n\nThese properties imply that the $N$ complex numbers $X_k$ (representing $2N$ real values) are not all independent. The total number of independent real values (degrees of freedom) is exactly $N$, which we now demonstrate.\n\n**Analysis of Degrees of Freedom**\n\nLet's count the number of independent real values required to define the spectrum $\\{X_k\\}$. We consider two cases for the length $N$.\n\nCase 1: $N$ is even. Let $N=2M$ for some integer $M \\ge 1$.\n-   $X_0$ is real, contributing $1$ degree of freedom.\n-   $X_M = X_{N/2}$ is real, contributing $1$ degree of freedom.\n-   The remaining coefficients are paired by the symmetry relation. The pairs are $(X_k, X_{N-k})$ for $k=1, 2, \\dots, M-1$. There are $M-1$ such pairs. For each pair, $X_{N-k}$ is fully determined by $X_k$. Thus, we only need to store $X_k = \\mathrm{Re}(X_k) + i\\,\\mathrm{Im}(X_k)$, which has $2$ degrees of freedom (its real and imaginary parts).\n-   The total number of degrees of freedom is $1 \\text{ (for } X_0) + 1 \\text{ (for } X_M) + 2(M-1) \\text{ (for the pairs)} = 2 + 2M - 2 = 2M = N$.\n\nCase 2: $N$ is odd. Let $N=2M+1$ for some integer $M \\ge 0$.\n-   $X_0$ is real, contributing $1$ degree of freedom.\n-   There is no Nyquist component that is guaranteed to be real.\n-   The coefficients are paired by symmetry as $(X_k, X_{N-k})$ for $k=1, 2, \\dots, M$. There are $M$ such pairs. For each pair, we only need to store one complex coefficient, e.g., $X_k$, contributing $2$ degrees of freedom.\n-   The total number of degrees of freedom is $1 \\text{ (for } X_0) + 2M \\text{ (for the pairs)} = 1 + 2M = N$.\n\nIn both even and odd cases, the DFT of a real sequence of length $N$ is uniquely determined by exactly $N$ real numbers. Our task is to design a mapping from these degrees of freedom to a real-valued array of length $N$.\n\n**Storage Layout and Packing Algorithm**\n\nWe propose the following layout for a real-valued packed array $P$ of length $N$. This layout is efficient as it uses contiguous blocks of memory for real and imaginary parts of the low-frequency components.\n\nLet $P$ be a real array of length $N$. The packing algorithm is as follows:\n1.  The DC component $X_0$ is real. Store it in the first element of $P$:\n    $P[0] = \\mathrm{Re}(X_0)$.\n2.  For the positive frequency components up to the Nyquist frequency (or just below it), store their real and imaginary parts. The number of such complex components is $\\lfloor (N-1)/2 \\rfloor$. For $k = 1, 2, \\dots, \\lfloor (N-1)/2 \\rfloor$:\n    -   Store the real part: $P[k] = \\mathrm{Re}(X_k)$.\n    -   Store the imaginary part: $P[N-k] = \\mathrm{Im}(X_k)$.\n3.  If $N$ is even, there is one remaining degree of freedom, $\\mathrm{Re}(X_{N/2})$, and one unused slot in the array, $P[N/2]$. Store the real Nyquist component there:\n    $P[N/2] = \\mathrm{Re}(X_{N/2})$.\n\nThis scheme completely populates the array $P$ of length $N$ without any overlaps. For example, for odd $N=2M+1$, the index $N-k$ ranges from $N-1$ down to $N-M = M+1$, while $k$ ranges from $1$ to $M$. The indices used are $0, \\{1,\\dots,M\\}, \\{M+1,\\dots,N-1\\}$, which covers all indices from $0$ to $N-1$. For even $N=2M$, $k$ for the pairs goes from $1$ to $M-1$. The indices used by the pairs are $\\{1,\\dots,M-1\\}$ and $\\{N-1, \\dots, N-(M-1)\\}=\\{M+1,\\dots,2M-1\\}$. Including index $0$ and index $M=N/2$ covers all indices.\n\n**Inverse Unpacking Algorithm**\n\nTo reconstruct the full complex spectrum $\\{X_k\\}_{k=0}^{N-1}$ from the packed array $P$, we reverse the packing procedure. Let the reconstructed spectrum be $X'$.\n\n1.  Initialize $X'$ as a complex-valued array of length $N$.\n2.  Reconstruct the DC component:\n    $X'[0] = P[0] + 0i$.\n3.  Reconstruct the complex conjugate pairs. For $k=1, 2, \\dots, \\lfloor (N-1)/2 \\rfloor$:\n    -   Combine the stored real and imaginary parts to form $X'_k$:\n        $X'[k] = P[k] + i P[N-k]$.\n    -   Use Hermitian symmetry to find its conjugate pair $X'_{N-k}$:\n        $X'[N-k] = \\overline{X'[k]} = P[k] - i P[N-k]$.\n4.  If $N$ is even, reconstruct the real-valued Nyquist component:\n    $X'[N/2] = P[N/2] + 0i$.\n\n**Justification of Correctness**\n\nThe correctness of this design rests on the fact that it establishes a lossless, one-to-one correspondence (a bijection) between the set of valid DFT spectra of real signals and the packed real arrays of length $N$.\n-   **Information Preservation**: The packing algorithm stores all $N$ independent real values that define the spectrum. No information is lost.\n-   **Symmetry Enforcement**: The unpacking algorithm reconstructs a spectrum $X'$ that, by construction, strictly adheres to the necessary conditions for its inverse transform to be real-valued:\n    -   $X'[0]$ is real.\n    -   If $N$ is even, $X'[N/2]$ is real.\n    -   For all $k=1, \\dots, N-1$, the property $X'[N-k] = \\overline{X'[k]}$ is enforced.\n-   **Reversibility**: Applying the packing algorithm followed by the unpacking algorithm is an identity operation. If we start with a valid spectrum $X$, we obtain $X' = X$. Therefore, applying the inverse DFT to the reconstructed spectrum $X'$ will yield the original real-valued sequence $x_n$, up to the limits of floating-point precision. The entire process is a valid and invertible transformation. This confirms the correctness of the proposed storage layout and its associated algorithms.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef pack_dft(X: np.ndarray) -> np.ndarray:\n    \"\"\"\n    Packs the DFT of a real sequence into a real array of length N.\n    \n    The layout is:\n    - P[0] = Re(X[0])\n    - P[k] = Re(X[k]) for k=1..floor((N-1)/2)\n    - P[N-k] = Im(X[k]) for k=1..floor((N-1)/2)\n    - P[N/2] = Re(X[N/2]) if N is even\n    \n    Args:\n        X (np.ndarray): The full complex DFT spectrum of length N.\n\n    Returns:\n        np.ndarray: The packed real array of length N.\n    \"\"\"\n    N = len(X)\n    P = np.zeros(N, dtype=np.float64)\n\n    # Store the DC component (always real)\n    P[0] = X[0].real\n\n    # Store real and imaginary parts for k=1...floor((N-1)/2)\n    # This range handles both even and odd N correctly for the paired components.\n    num_pairs = (N - 1) // 2\n    for k in range(1, num_pairs + 1):\n        P[k] = X[k].real\n        P[N - k] = X[k].imag\n\n    # If N is even, store the Nyquist component (always real)\n    if N % 2 == 0:\n        if N > 0: # Guard for N=0 case, though not in test suite\n            P[N // 2] = X[N // 2].real\n            \n    return P\n\ndef unpack_dft(P: np.ndarray, N: int) -> np.ndarray:\n    \"\"\"\n    Unpacks a real array into the full complex DFT spectrum, enforcing Hermitian symmetry.\n\n    Args:\n        P (np.ndarray): The packed real array of length N.\n        N (int): The length of the spectrum to reconstruct.\n\n    Returns:\n        np.ndarray: The reconstructed full complex spectrum of length N.\n    \"\"\"\n    X_re = np.zeros(N, dtype=np.complex128)\n\n    # Reconstruct the DC component\n    if N > 0:\n        X_re[0] = P[0]\n\n    # Reconstruct complex conjugate pairs\n    num_pairs = (N - 1) // 2\n    for k in range(1, num_pairs + 1):\n        real_part = P[k]\n        imag_part = P[N - k]\n        X_re[k] = real_part + 1j * imag_part\n        # Enforce Hermitian symmetry\n        X_re[N - k] = real_part - 1j * imag_part\n\n    # If N is even, reconstruct the real Nyquist component\n    if N % 2 == 0:\n        if N > 0:\n            X_re[N // 2] = P[N // 2]\n            \n    return X_re\n\ndef solve():\n    \"\"\"\n    Main function to run the verification for all test cases.\n    \"\"\"\n    test_cases = [\n        # (N, function to generate sequence x_n)\n        (1, lambda n: np.array([3.5])),\n        (2, lambda n: np.array([1.0, -2.0])),\n        (7, lambda n: 0.3 + np.cos(2 * np.pi * 1 * n / 7) + 0.5 * np.sin(2 * np.pi * 2 * n / 7)),\n        (8, lambda n: 0.1 + 1.25 * np.cos(2 * np.pi * 3 * n / 8) + 2.0 * np.cos(np.pi * n) + 0.75 * np.sin(2 * np.pi * 1 * n / 8))\n    ]\n\n    results = []\n    error_threshold = 1e-10\n\n    for N, x_func in test_cases:\n        # Step 1: Generate the original real sequence\n        if N > 1:\n            n_vals = np.arange(N)\n            x_original = x_func(n_vals)\n        else: # Handle N=1 case where arange is not needed\n            x_original = x_func(0)\n\n        # Step 2: Compute the forward DFT\n        X_full = np.fft.fft(x_original)\n\n        # Step 3: Pack the DFT spectrum\n        P_packed = pack_dft(X_full)\n\n        # Step 4: Unpack to reconstruct the spectrum\n        X_reconstructed = unpack_dft(P_packed, N)\n\n        # Step 5: Apply the inverse DFT\n        x_reconstructed = np.fft.ifft(X_reconstructed)\n        \n        # Result of IFFT on a Hermitian-symmetric spectrum is real.\n        # Take .real to discard negligible imaginary parts from floating-point errors.\n        x_reconstructed_real = x_reconstructed.real\n\n        # Step 6: Compare reconstructed sequence to original\n        max_abs_error = np.max(np.abs(x_original - x_reconstructed_real))\n\n        # Step 7: Check if the test passes and record result\n        passed = max_abs_error <= error_threshold\n        results.append(passed)\n\n    # Final print statement in the exact required format.\n    # The map(str,...) converts boolean True/False to \"True\"/\"False\" strings.\n    # The problem asks for format like \"[True,False,...]\" not \"[true,false,...]\"\n    # so we capitalize.\n    print(f\"[{','.join(str(r) for r in results)}]\")\n\n# Calling solve() is commented out in this context.\n# When run in a suitable environment, it would be called.\n# solve()\n```", "id": "3381085"}, {"introduction": "Moving from one-dimensional signals to multidimensional fields, such as images or volumetric data, requires the use of multidimensional DFTs. While mathematically a straightforward extension, the computational implementation on modern hardware presents significant performance challenges related to data layout and memory access. This exercise explores how the separability of the 2D DFT can be exploited to create a cache-efficient algorithm by interleaving 1D FFTs with matrix transposes [@problem_id:3381024]. Implementing this common \"transpose-based\" approach will provide you with valuable insight into optimizing numerical algorithms for the memory hierarchy of modern computer architectures.", "problem": "Consider a two-dimensional Discrete Fourier Transform (DFT) on a tensor-product grid that arises in spectral methods and Discontinuous Galerkin (DG) methods. Let $X \\in \\mathbb{C}^{n_y \\times n_x}$ be a complex array stored in row-major layout, meaning that the linear memory index of the entry at $(j,i)$ with $0 \\le j < n_y$, $0 \\le i < n_x$ is $p = j\\,n_x + i$. The two-dimensional DFT of $X$ is the array $Y \\in \\mathbb{C}^{n_y \\times n_x}$ defined by\n$$\nY_{k,\\ell} = \\sum_{j=0}^{n_y-1} \\sum_{i=0}^{n_x-1} X_{j,i} \\, e^{-2\\pi \\mathrm{i} \\frac{k j}{n_y}} \\, e^{-2\\pi \\mathrm{i} \\frac{\\ell i}{n_x}}, \\quad 0 \\le k < n_y, \\; 0 \\le \\ell < n_x,\n$$\nwhere $\\mathrm{i}$ is the imaginary unit. This transform is separable and can be expressed in matrix form using one-dimensional DFT matrices $F_{n_y} \\in \\mathbb{C}^{n_y \\times n_y}$ and $F_{n_x} \\in \\mathbb{C}^{n_x \\times n_x}$ as\n$$\nY = F_{n_y} \\, X \\, F_{n_x}^{\\top}.\n$$\nEquivalently, using the Kronecker product, the vectorized mapping satisfies\n$$\n\\operatorname{vec}(Y) = \\left(F_{n_x} \\otimes F_{n_y}\\right) \\operatorname{vec}(X),\n$$\nwhere $\\operatorname{vec}(\\cdot)$ stacks columns and $\\otimes$ denotes the Kronecker product. A Fast Fourier Transform (FFT) computes the one-dimensional DFTs in $O(n \\log n)$ operations by exploiting recursive radix factorizations.\n\nIn row-major memory, a naive two-pass schedule that first applies length-$n_x$ one-dimensional FFTs along rows (unit-stride access), followed by length-$n_y$ one-dimensional FFTs along columns (stride-$n_x$ access), suffers from poor cache locality in the column pass because successive elements of a column are separated by $n_x$ in linear memory. Cache locality can be improved by interleaving transposes so that both one-dimensional FFT passes traverse memory with unit stride. Your task is to design the sequence of passes and transposes to compute an in-place two-dimensional FFT with good cache locality and justify your choice from first principles, starting from the separability of the two-dimensional DFT and the row-major memory mapping. The design should minimize non-unit-stride memory accesses in the FFT passes and should use blocked transposes to maximize spatial locality.\n\nRequirements for the program:\n- Implement the following sequence to compute $Y = F_{n_y} \\, X \\, F_{n_x}^{\\top}$:\n  $1$) Apply length-$n_x$ one-dimensional FFTs along rows of $X$ to produce $X^{(1)}$.\n  $2$) Apply a blocked transpose with tile sizes $(b_y, b_x)$ to obtain $T = \\left(X^{(1)}\\right)^{\\top}$ of shape $n_x \\times n_y$.\n  $3$) Apply length-$n_y$ one-dimensional FFTs along rows of $T$ to produce $T^{(1)}$ (which corresponds to column FFTs of $X$).\n  $4$) Apply a blocked transpose back to return to the original orientation $Y = \\left(T^{(1)}\\right)^{\\top}$.\n- Verify numerical correctness by comparing with a direct two-dimensional FFT computed by applying built-in one-dimensional FFTs along both axes of $X$.\n- For each test case, report:\n  $1$) the maximum absolute error between the designed sequence result and the direct two-dimensional FFT result as a floating-point number, and\n  $2$) a cache-locality improvement metric defined as the ratio of the maximum stride encountered in the naive two-pass schedule (row-then-column without transposes) to the maximum stride in the transpose-based schedule. In row-major layout, the naive maximum stride is $n_x$ and the improved maximum stride is $1$, hence the metric equals $n_x$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a two-element list $[\\,\\text{error},\\,\\text{improvement}\\,]$.\n\nTest Suite:\nUse the following test cases $(n_x, n_y, b_x, b_y, s)$, where $s$ is a random seed for reproducibility:\n- Case $1$: $(64, 32, 8, 8, 0)$.\n- Case $2$: $(1, 128, 16, 16, 1)$.\n- Case $3$: $(30, 45, 10, 9, 2)$.\n- Case $4$: $(17, 31, 8, 8, 3)$.\n\nAll angles in trigonometric factors are in radians. No physical units are involved. The final outputs must be floating-point numbers. Your program must be self-contained and must not read input from the user or external files. The sequence of passes and transposes should be justified in your derivation within the solution.", "solution": "The problem requires the design and implementation of a cache-efficient algorithm for computing the two-dimensional Discrete Fourier Transform (DFT) of a complex-valued matrix $X \\in \\mathbb{C}^{n_y \\times n_x}$ stored in row-major memory layout. The core of the design is to justify and implement a sequence of operations that transforms a computationally expensive non-unit stride memory access pattern into a series of unit-stride operations.\n\nThe two-dimensional DFT of $X$ is defined as the matrix $Y \\in \\mathbb{C}^{n_y \\times n_x}$ with entries:\n$$\nY_{k,\\ell} = \\sum_{j=0}^{n_y-1} \\sum_{i=0}^{n_x-1} X_{j,i} \\, e^{-2\\pi \\mathrm{i} \\frac{k j}{n_y}} \\, e^{-2\\pi \\mathrm{i} \\frac{\\ell i}{n_x}}, \\quad \\text{for } 0 \\le k < n_y, \\; 0 \\le \\ell < n_x\n$$\nwhere $\\mathrm{i}$ is the imaginary unit. The exponential kernel is separable, which allows the double summation to be split into two consecutive steps. We can first perform the summation over the index $i$ for each row $j$, and then perform the summation over the index $j$ for each column $\\ell$.\n\nLet us define an intermediate matrix $X^{(1)} \\in \\mathbb{C}^{n_y \\times n_x}$ by performing one-dimensional DFTs of length $n_x$ on each row of $X$:\n$$\nX^{(1)}_{j,\\ell} = \\sum_{i=0}^{n_x-1} X_{j,i} \\, e^{-2\\pi \\mathrm{i} \\frac{\\ell i}{n_x}}\n$$\nThis operation corresponds to the matrix product $X^{(1)} = X F_{n_x}^{\\top}$, where $F_{n_x}$ is the one-dimensional DFT matrix of size $n_x \\times n_x$ whose $(\\ell, i)$-th entry is $e^{-2\\pi \\mathrm{i} \\frac{\\ell i}{n_x}}$. Note that the problem statement uses $Y = F_{n_y} X F_{n_x}^\\top$, which implies the DFT along rows is post-multiplication by $F_{n_x}^\\top$. This is unconventional; a standard definition would be $Y = F_{n_y} X F_{n_x}$, with $X^{(1)}=F_{n_x}X$. We follow the problem's convention.\n\nThe final result $Y$ is then obtained by performing one-dimensional DFTs of length $n_y$ on each column of the intermediate matrix $X^{(1)}$:\n$$\nY_{k,\\ell} = \\sum_{j=0}^{n_y-1} X^{(1)}_{j,\\ell} \\, e^{-2\\pi \\mathrm{i} \\frac{k j}{n_y}}\n$$\nThis corresponds to the matrix product $Y = F_{n_y} X^{(1)}$. Combining these two steps confirms the expression given in the problem statement: $Y = F_{n_y} (X F_{n_x}^{\\top})$.\n\nThis separability leads to a naive two-pass algorithm:\n1.  Apply a one-dimensional Fast Fourier Transform (FFT) of length $n_x$ to each of the $n_y$ rows of $X$.\n2.  Apply a one-dimensional FFT of length $n_y$ to each of the $n_x$ columns of the resulting matrix $X^{(1)}$.\n\nNow, we analyze the memory access patterns for a matrix stored in row-major order. In this layout, the linear memory index of the element $X_{j,i}$ is $p = j \\cdot n_x + i$.\n- In the first pass (row-wise FFTs), the elements of a row $j$, $(X_{j,0}, X_{j,1}, \\dots, X_{j,n_x-1})$, are located at consecutive memory addresses. Accessing these elements involves a memory stride of $1$, which is ideal for modern CPU caches (exhibiting high spatial locality).\n- In the second pass (column-wise FFTs), the elements of a column $\\ell$, $(X^{(1)}_{0,\\ell}, X^{(1)}_{1,\\ell}, \\dots, X^{(1)}_{n_y-1,\\ell})$, are located at memory addresses separated by a stride of $n_x$. The address of $X^{(1)}_{j,\\ell}$ is $j \\cdot n_x + \\ell$, and the address of the next element in the column, $X^{(1)}_{j+1,\\ell}$, is $(j+1) \\cdot n_x + \\ell$. If $n_x$ is large, this non-unit stride access pattern leads to poor cache performance, as each memory access may fetch a different cache line, of which only a single element is used, resulting in a high rate of cache misses.\n\nTo mitigate this performance bottleneck, we can interleave matrix transpose operations to ensure that both FFT passes operate on data with unit stride. The proposed improved algorithm is as follows:\n1.  **Row-wise FFTs**: Compute $X^{(1)}$ by applying length-$n_x$ FFTs along the rows of $X$. This step has unit-stride memory access and is cache-friendly. The problem states this as $X^{(1)}=X F_{n_x}^\\top$, which means applying row FFTs.\n2.  **Transpose**: Compute the transpose of the intermediate matrix, $T = (X^{(1)})^{\\top}$. Now, the columns of $X^{(1)}$ have become the rows of $T$. The matrix $T$ has dimensions $n_x \\times n_y$.\n3.  **Row-wise FFTs on Transposed Matrix**: Apply length-$n_y$ FFTs along the rows of $T$. This corresponds to premultiplying by $F_{n_y}$ in the original column space. The result is $T^{(1)} = F_{n_y} T$. Since we are again operating along rows (of $T$), this step also has unit-stride memory access.\n4.  **Transpose Back**: Transpose the result back to the original orientation, $Y = (T^{(1)})^{\\top}$, to get the final $n_y \\times n_x$ result matrix.\n\nLet us verify the mathematical correctness of this sequence based on the problem's definition $Y = F_{n_y} X F_{n_x}^\\top$. The naive schedule is: $X^{(1)} = X F_{n_x}^\\top$, then $Y = F_{n_y} X^{(1)}$.\nOur transpose-based schedule is:\n1. $X^{(1)} = X F_{n_x}^\\top$. (Row FFTs on $X$)\n2. $T = (X^{(1)})^\\top$.\n3. $T^{(1)}$ is computed by applying column FFTs to $X^{(1)}$, which means operating on rows of $T$. A column-FFT on $X^{(1)}$ is $F_{n_y} X^{(1)}$. So this step is meant to compute $F_{n_y} X^{(1)}$. Let's see how this is achieved on $T$.\n$(F_{n_y} X^{(1)})^\\top = (X^{(1)})^\\top F_{n_y}^\\top = T F_{n_y}^\\top$. This is row-FFTs on $T$. So step 3 should be $T^{(1)} = T F_{n_y}^\\top$.\n4. $Y = (T^{(1)})^\\top = (T F_{n_y}^\\top)^\\top = (F_{n_y}^\\top)^\\top T^\\top = F_{n_y} T^\\top = F_{n_y} ((X^{(1)})^\\top)^\\top = F_{n_y} X^{(1)} = F_{n_y} (X F_{n_x}^\\top) = F_{n_y} X F_{n_x}^\\top$.\nThis confirms that the transpose-based sequence correctly computes the two-dimensional DFT. The Python implementation must match this logic.\n\nThe transpose operations themselves can also suffer from poor cache locality if implemented naively. A naive transpose of a matrix $A$ to $B$ involves reading $A_{j,i}$ and writing to $B_{i,j}$. If we iterate through $i$ in an inner loop, the reads from $A$ are unit-stride, but writes to $B$ are non-unit-stride. To optimize this, a **blocked transpose** is used. The matrix is partitioned into smaller rectangular tiles of size $b_y \\times b_x$. Each tile is ideally small enough to fit into a CPU cache. A tile from the source matrix is loaded into the cache, transposed locally (where all required data is now readily accessible), and written to its destination. This technique maximizes data reuse within the cache and significantly reduces cache misses compared to a naive full-matrix transpose.\n\nThe cache-locality improvement metric is defined as the ratio of the maximum stride in the naive schedule to that in the transpose-based schedule.\n- In the naive schedule, the maximum stride occurs in the column-wise FFT pass and is equal to $n_x$.\n- In the transpose-based schedule, both FFT passes operate along rows, so the stride for FFT computations is always $1$.\n- Therefore, the improvement metric is $\\frac{\\text{max stride (naive)}}{\\text{max stride (improved)}} = \\frac{n_x}{1} = n_x$. This metric quantifies the performance gain by restructuring the FFT computation itself to be entirely cache-friendly.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.fft import fft, fft2\n\ndef blocked_transpose(arr: np.ndarray, block_h: int, block_w: int) -> np.ndarray:\n    \"\"\"\n    Performs a blocked (tiled) transpose of a 2D numpy array.\n\n    Args:\n        arr (np.ndarray): The input 2D array to transpose.\n        block_h (int): The height of the blocks.\n        block_w (int): The width of the blocks.\n\n    Returns:\n        np.ndarray: The transposed array.\n    \"\"\"\n    h, w = arr.shape\n    transposed_arr = np.empty((w, h), dtype=arr.dtype)\n\n    for j in range(0, h, block_h):\n        for i in range(0, w, block_w):\n            # Define the slice for the source block, handling boundary cases\n            j_end = min(j + block_h, h)\n            i_end = min(i + block_w, w)\n            block = arr[j:j_end, i:i_end]\n\n            # Transpose the block and place it in the destination array\n            transposed_arr[i:i_end, j:j_end] = block.T\n            \n    return transposed_arr\n\ndef solve():\n    \"\"\"\n    Solves the 2D FFT problem for the given test cases.\n    It implements a cache-efficient 2D FFT using transposes and compares it\n    to a direct 2D FFT to verify correctness and calculate a performance metric.\n    \"\"\"\n    # Test cases: (nx, ny, bx, by, seed)\n    test_cases = [\n        (64, 32, 8, 8, 0),\n        (1, 128, 16, 16, 1),\n        (30, 45, 10, 9, 2),\n        (17, 31, 8, 8, 3),\n    ]\n\n    results = []\n    for nx, ny, bx, by, seed in test_cases:\n        # Generate a reproducible random complex array\n        rng = np.random.default_rng(seed)\n        X = rng.random((ny, nx)) + 1j * rng.random((ny, nx))\n\n        # --- Reference solution: Direct 2D FFT using scipy ---\n        # The problem defines Y = F_ny * X * F_nx^T.\n        # Scipy's fft2 computes Y_kl = sum_ji X_ji exp(-2pi*i*kj/ny)exp(-2pi*i*li/nx)\n        # This is equivalent to applying FFT along columns then along rows.\n        # Y_scipy = fft(fft(X, axis=0), axis=1).\n        # Let's verify this is what fft2 does.\n        # test1 = fft2(X)\n        # test2 = fft(fft(X, axis=0), axis=1)\n        # np.allclose(test1, test2) is True.\n        # The problem's formula Y = F_ny * X * F_nx^T means:\n        # Step 1: Row transforms: X1 = X * F_nx^T. This is not standard.\n        # Usually row transforms are F_nx * X. Let's assume the problem means\n        # apply transforms along axes.\n        # Y_kl = sum_j (sum_i X_ji exp(-i*2pi*li/nx)) exp(-i*2pi*kj/ny).\n        # Inner sum is FFT along rows (axis=1). Outer sum is FFT along columns (axis=0).\n        # So Y = fft(fft(X, axis=1), axis=0).\n        # Let's use this standard separable definition, which matches scipy.fft.fft2.\n        Y_direct = fft2(X)\n\n\n        # --- Transpose-based 2D FFT implementation ---\n        # 1. Apply length-nx 1D FFTs along rows of X\n        # axis=1 for row-wise operations in a (ny, nx) matrix\n        X1 = fft(X, axis=1)\n\n        # 2. Apply a blocked transpose with tile sizes (by, bx)\n        T = blocked_transpose(X1, by, bx)\n\n        # 3. Apply length-ny 1D FFTs along rows of T\n        # T has shape (nx, ny), so axis=1 is the correct dimension\n        # This is equivalent to column-wise FFTs on X1\n        T1 = fft(T, axis=1)\n\n        # 4. Apply a blocked transpose back. The matrix T1 has shape (nx, ny),\n        # so the blocks on it are of size (bx, by).\n        Y_computed = blocked_transpose(T1, bx, by)\n\n        # --- Calculate required metrics ---\n        # 1. Maximum absolute error between the two results\n        max_abs_error = np.max(np.abs(Y_computed - Y_direct))\n\n        # 2. Cache-locality improvement metric\n        # Naive max stride = nx (column FFTs on row-major data)\n        # Improved max stride = 1 (all FFTs are row-wise)\n        # Ratio = nx / 1 = nx\n        improvement_metric = float(nx)\n        \n        results.append([max_abs_error, improvement_metric])\n\n    # Final print statement in the exact required format.\n    # The format needs lists inside a list, e.g., [[err1, imp1],[err2,imp2],...]\n    print(f\"[{','.join(f'[{e},{i}]' for e, i in results)}]\")\n\n# Calling solve() is commented out in this context.\n# When run in a suitable environment, it would be called.\n# solve()\n```", "id": "3381024"}, {"introduction": "The Fast Fourier Transform is not just an analysis tool; it is a cornerstone of advanced numerical methods for solving differential equations. This practice introduces the pseudo-spectral method, where spatial derivatives are computed efficiently in Fourier space, while nonlinear products are computed in physical space. You will directly confront a critical challenge in this method: aliasing error, which arises from representing a high-frequency product on a lower-resolution grid. By implementing and comparing aliased results with those from a standard dealiasing technique, you will learn why managing these errors is essential for the accuracy and stability of nonlinear simulations [@problem_id:3381044].", "problem": "Consider a real-valued, $2\\pi$-periodic function $u(x)$ sampled at $N$ equidistant collocation points $x_j = 2\\pi j/N$ for $j = 0,1,\\dots,N-1$. Let the discrete Fourier transform (DFT) pair be defined by\n$$\n\\widehat{u}_k = \\sum_{j=0}^{N-1} u(x_j)\\, e^{-2\\pi i\\, j k/N}, \\quad\nu(x_j) = \\frac{1}{N} \\sum_{k=0}^{N-1} \\widehat{u}_k\\, e^{2\\pi i\\, j k/N}.\n$$\nThe wavenumber associated with the $k$-th DFT bin corresponds to the integer $k$ interpreted on the $2\\pi$-periodic domain, i.e., the angular wavenumber is $2\\pi$ times the frequency returned by the standard mapping of the discrete Fourier transform indices under the above convention. For even $N$, the integer wavenumbers are $k \\in \\{0,1,\\dots,N/2-1,-N/2,\\dots,-1\\}$.\n\nSpectral differentiation is defined by transforming to Fourier space, multiplying by $i k$, and transforming back:\n$$\n\\mathcal{D}_x[u](x) \\approx \\mathcal{F}^{-1}\\left\\{ i\\,k\\,\\widehat{u}_k \\right\\}(x).\n$$\nFor nonlinear products, the pseudo-spectral method computes the product in physical space and transforms back to Fourier space. This introduces aliasing when the convolution of Fourier modes exceeds the resolvable range of the grid. Two classical dealiasing strategies are:\n- The \"$3/2$-rule\" zero-padding: temporarily increase the spectral resolution by a factor of $3/2$, compute the product at the higher resolution, and truncate back to $N$ modes.\n- The \"$2/3$-rule\" truncation: zero all modes with $|k| > \\lfloor N/3 \\rfloor$ before computing quadratic products on the original grid.\n\nStarting from the DFT pair above and the $2\\pi$-periodic Fourier series interpretation, implement:\n1. Spectral differentiation via the DFT, and verify its accuracy against an analytic derivative.\n2. Pseudo-spectral evaluation of $u(x)^2$ and demonstrate aliasing versus $3/2$-rule dealiasing at the level of Fourier coefficients.\n3. Equivalence of the $3/2$-rule and the $2/3$-rule on the resolved low modes for a quadratic product when the initial spectrum is contained within the $2/3$ bandwidth.\n4. Pseudo-spectral evaluation of the nonlinear flux derivative $\\partial_x\\left(\\tfrac{1}{2}u(x)^2\\right) = u(x)\\,u_x(x)$, comparing an aliased computation against a properly dealiased one, using an analytic expression for the exact result.\n\nYour program must implement the following test suite and produce the requested outputs. Angles are in radians, and there are no physical units involved.\n\nTest Suite:\n- Test A (Spectral differentiation accuracy):\n  - Domain $[0,2\\pi)$, $N \\in \\{16, 32, 64\\}$.\n  - Function $u(x) = \\sin(3x) + 0.5 \\cos(5x)$.\n  - Compute the spectral derivative $\\mathcal{D}_x[u](x)$ and the analytic derivative $u_x(x)$ at the collocation points.\n  - Output the maximum absolute error $\\max_j | \\mathcal{D}_x[u](x_j) - u_x(x_j) |$ for each $N$ as three separate floats.\n\n- Test B (Aliasing in $u^2$ and $3/2$-rule dealiasing at the level of Fourier coefficients):\n  - Domain $[0,2\\pi)$, $N = 16$.\n  - Function $u(x) = \\cos(6x) + \\cos(7x)$.\n  - Compute Fourier coefficients of $u^2$ via:\n    - Aliased pseudo-spectral: compute $u(x_j)^2$ on the $N$-point grid, then apply the DFT to obtain $\\widehat{(u^2)}^{\\mathrm{alias}}_k$.\n    - Dealiased $3/2$-rule: construct a zero-padded spectrum by a factor of $3/2$, compute $u^2$ on the padded grid, transform back, and truncate to $N$ modes to obtain $\\widehat{(u^2)}^{3/2}_k$. The padding and truncation must preserve the Fourier series normalization consistent with the given DFT pair.\n  - Output the Euclidean norm of the difference of the $N$-length coefficient vectors, i.e., $\\left\\| \\widehat{(u^2)}^{\\mathrm{alias}} - \\widehat{(u^2)}^{3/2} \\right\\|_2$, as a single float.\n\n- Test C ($3/2$-rule versus $2/3$-rule equivalence on low modes for a quadratic product):\n  - Domain $[0,2\\pi)$, $N = 24$.\n  - Function $u(x) = \\cos(7x) + 0.5 \\sin(6x)$.\n  - Let $K_c = \\lfloor N/3 \\rfloor$.\n  - Compute the Fourier coefficients of $u^2$ using:\n    - The $3/2$-rule zero-padding method, truncated back to $N$ modes.\n    - The $2/3$-rule: zero modes with $|k| > K_c$ in $\\widehat{u}_k$ on the original grid, inverse transform to physical space, square, and transform back; then zero modes with $|k| > K_c$ in the result.\n  - Compare only the low modes with $|k| \\le K_c$. Output the maximum absolute difference across these modes as a single float.\n\n- Test D (Aliased versus dealiased nonlinear flux derivative):\n  - Domain $[0,2\\pi)$, $N = 32$.\n  - Function $u(x) = \\sin(9x) + 0.4 \\cos(8x)$.\n  - Exact flux derivative: $u(x)\\,u_x(x)$ where $u_x(x)$ is the analytic derivative.\n  - Aliased computation: compute $u_x$ spectrally on the $N$-grid, form $u\\,u_x$ in physical space, and compare to the exact value at the collocation points. Output the root-mean-square error $\\sqrt{\\frac{1}{N}\\sum_{j=0}^{N-1} \\left( u(x_j)u_x(x_j) - [u\\,u_x]^{\\mathrm{alias}}(x_j)\\right)^2}$ as a single float.\n  - Dealiased $3/2$-rule computation: perform a $3/2$-rule dealiased product for $u\\,u_x$ by padding to $3N/2$, taking the derivative spectrally on the padded grid, forming the product on the padded grid, transforming back, truncating to $N$ modes, and inverse transforming to the $N$-grid. Compare to the exact value and output the root-mean-square error as a single float.\n\nFinal Output Format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the following order:\n  - Test A error for $N=16$\n  - Test A error for $N=32$\n  - Test A error for $N=64$\n  - Test B coefficient-vector difference norm\n  - Test C maximum low-mode difference\n  - Test D aliased root-mean-square error\n  - Test D dealiased root-mean-square error\n- Each number must be printed in scientific notation with twelve significant digits, and there must be no additional text before or after the list.", "solution": "The problem presents a clear, well-posed, and scientifically sound set of numerical exercises on the topic of spectral methods for partial differential equations. All necessary definitions, parameters, and evaluation criteria are provided. The tasks involve the implementation and verification of standard, fundamental techniques in the field, such as spectral differentiation, the pseudo-spectral method for nonlinearities, and common dealiasing strategies like the $3/2$ and $2/3$ rules.\n\nThe core of the problem lies in the properties of the Discrete Fourier Transform (DFT) when used to approximate derivatives and nonlinear products of periodic functions. On a grid of $N$ equidistant points $x_j = 2\\pi j/N$ over a $2\\pi$-periodic domain, a function $u(x)$ is represented by its values $u(x_j)$. The provided DFT pair is:\n$$ \\widehat{u}_k = \\sum_{j=0}^{N-1} u(x_j)\\, e^{-2\\pi i\\, j k/N} $$\n$$ u(x_j) = \\frac{1}{N} \\sum_{k=0}^{N-1} \\widehat{u}_k\\, e^{2\\pi i\\, j k/N} $$\nThese definitions correspond directly to the `numpy.fft.fft` and `numpy.fft.ifft` functions, respectively, simplifying implementation.\n\nThe integer wavenumbers $k$ are mapped from the DFT indices. For an even number of points $N$, the wavenumbers are $k \\in \\{0, 1, \\dots, N/2-1, -N/2, \\dots, -1\\}$. This set represents the frequencies that can be resolved by the grid. The highest magnitude wavenumber is the Nyquist frequency, $|k| = N/2$.\n\n**1. Spectral Differentiation**\nThe derivative of a Fourier series term $e^{ikx}$ is $ik e^{ikx}$. This property extends to the DFT. The spectral derivative $\\mathcal{D}_x[u]$ is computed by transforming $u$ to Fourier space to get coefficients $\\widehat{u}_k$, multiplying each coefficient by its corresponding effective wavenumber $ik$, and transforming back to physical space:\n$$ (\\mathcal{D}_x[u])_j = \\mathcal{F}^{-1}\\left\\{ i k \\widehat{u}_k \\right\\}_j $$\nFor a function whose Fourier series contains only wavenumbers $k$ such that $|k| < N/2$, the spectral derivative is exact up to machine precision. This is because all component waves are well-resolved by the grid.\n\n**2. Pseudo-Spectral Method and Aliasing**\nNonlinear terms, like $u(x)^2$, are challenging in Fourier space. The product of two functions corresponds to the convolution of their Fourier coefficients:\n$$ \\widehat{(uv)}_k = (\\widehat{u} * \\widehat{v})_k = \\sum_{m=-\\infty}^{\\infty} \\widehat{u}_m \\widehat{v}_{k-m} $$\nDirectly computing this convolution is computationally expensive ($O(N^2)$). The pseudo-spectral method offers an efficient alternative:\n1. Transform $\\widehat{u}_k$ and $\\widehat{v}_k$ to physical space to get $u(x_j)$ and $v(x_j)$ ($O(N\\log N)$).\n2. Compute the product pointwise in physical space: $w(x_j) = u(x_j) v(x_j)$ ($O(N)$).\n3. Transform $w(x_j)$ back to Fourier space to get $\\widehat{w}_k$ ($O(N\\log N)$).\n\nThis method, however, introduces aliasing errors. If $u(x)$ has modes up to wavenumber $K_{\\max}$, the product $u(x)^2$ will have modes up to $2K_{\\max}$. If $2K_{\\max}$ exceeds the grid's Nyquist limit ($N/2$), higher-frequency components are \"folded\" back onto lower-frequency wavenumbers, corrupting the computed spectrum. Specifically, a mode with true wavenumber $k_{\\text{true}}$ is aliased to $k_{\\text{alias}} = k_{\\text{true}} \\pmod N$.\n\n**3. Dealiasing Strategies**\nTo prevent aliasing, the grid must be fine enough to resolve the highest wavenumber in the nonlinear product.\n- **The $3/2$-Rule (Zero-Padding):** This is a general-purpose dealiasing method. If the original function $u$ is band-limited such that its spectrum $\\widehat{u}_k$ is zero for $|k| > K$, the product $u^2$ will have a spectrum non-zero only for $|k| \\le 2K$. To compute this product without aliasing, we need a grid with a Nyquist frequency greater than $2K$, i.e., $N_{\\text{padded}}/2 > 2K$. The $3/2$-rule involves temporarily increasing the grid size to $N' = \\lfloor 3N/2 \\rfloor$. The original spectrum $\\widehat{u}_k$ is padded with zeros to create a high-resolution spectrum $\\widehat{u}^{\\text{pad}}_k$. The product is then computed on this padded grid. Finally, the resulting spectrum is truncated back to the original $N$ modes. This method is effective if the original signal's energy is contained within $|k| < N/3$, because then the product's energy is within $|k|<2N/3$, which is resolvable on the padded grid since $N'/2 \\approx 3N/4 > 2N/3$. When padding coefficients from an $N$-point transform to an $N'$-point one, they must be scaled by $N'/N$ to preserve the amplitude of the underlying continuous function. When truncating back, they are scaled by $N/N'$.\n\n- **The $2/3$-Rule (Truncation):** This rule applies specifically to quadratic or cubic nonlinearities. For a quadratic product $u^2$, if the input spectrum $\\widehat{u}_k$ is first truncated by setting all modes with $|k| > N/3$ to zero, the pseudo-spectral product computed on the original $N$-point grid will have the correct, unaliased coefficients for all modes $|k| \\le N/3$. The aliasing errors are confined to the higher, truncated part of the spectrum. For initial spectra that are already band-limited to $|k| \\le N/3$, this method is equivalent to the $3/2$-rule for the preserved low-frequency modes.\n\nThe problem requires implementing these concepts across four test cases.\n\n**Test A: Spectral Differentiation Accuracy**\nFor $u(x) = \\sin(3x) + 0.5 \\cos(5x)$, the highest wavenumber is $k=5$. For grid sizes $N=16, 32, 64$, the Nyquist frequency is $N/2=8, 16, 32$ respectively. In all cases, $5 < N/2$. Therefore, the function is well-resolved, and the spectral derivative $\\mathcal{D}_x[u]$ should match the analytic derivative $u_x(x) = 3\\cos(3x) - 2.5\\sin(5x)$ to machine precision. The maximum absolute error is expected to be very small, on the order of $10^{-14}$ or less.\n\n**Test B: Aliasing in $u^2$**\nFor $u(x) = \\cos(6x) + \\cos(7x)$ with $N=16$, the input wavenumbers are $k=6,7$. The Nyquist frequency is $N/2=8$. The quadratic product $u^2(x)$ will generate modes with wavenumbers $k=0, 1, 12, 13, 14$ via trigonometric identities. The modes $k=12, 13, 14$ are all greater than the Nyquist frequency of $8$. They will alias to $k=12-16=-4$, $k=13-16=-3$, and $k=14-16=-2$ respectively. The aliased pseudo-spectral computation will thus have non-zero coefficients at these negative wavenumbers, which should be zero in the exact result. The $3/2$-rule dealiasing, performed on a padded grid of size $N' = 3/2 \\cdot 16 = 24$, will compute a more accurate spectrum. The product's highest wavenumber, $14$, exceeds the padded grid's Nyquist limit of $12$. Aliasing will persist ($k=14$ aliases to $14-24=-10$). However, the aliasing pattern is different and the result is more accurate for the low modes than the computation on the $N=16$ grid. The norm of the difference between the coefficient vectors from the two methods will be non-zero, quantifying the effect of aliasing.\n\n**Test C: $3/2$-Rule vs. $2/3$-Rule Equivalence**\nFor $N=24$, the cutoff wavenumber for the $2/3$-rule is $K_c = \\lfloor 24/3 \\rfloor = 8$. The function is $u(x) = \\cos(7x) + 0.5 \\sin(6x)$. All its wavenumbers ($k=6,7$) are within the annulus $|k| \\le K_c$. According to the theory, for such a band-limited input, both the $3/2$-rule and the $2/3$-rule should yield the exact Fourier coefficients for the product $u^2$ within the range $|k| \\le K_c$. The maximum absolute difference between the coefficients computed by the two methods in this range should therefore be near machine precision.\n\n**Test D: Aliased vs. Dealiased Nonlinear Flux Derivative**\nThe nonlinear flux is $\\frac{1}{2}u(x)^2$, and its derivative is $u(x)u_x(x)$. For $u(x) = \\sin(9x) + 0.4 \\cos(8x)$ with $N=32$, the Nyquist frequency is $16$. The wavenumbers in both $u$ and its derivative $u_x$ are $8, 9$. The product $u u_x$ will contain wavenumbers up to $9+9=18$. Since $18 > 16$, the aliased pseudo-spectral computation (multiplying $u$ and its spectral derivative on the $N=32$ grid) will be incorrect due to the aliasing of the $k=18$ mode to $k=18-32=-14$. The RMS error compared to the analytic result will be significant. In contrast, the dealiased computation using the $3/2$-rule on a grid of $N' = 3/2 \\cdot 32 = 48$ will be accurate. The padded grid's Nyquist frequency is $24$, which is greater than the product's maximum wavenumber of $18$. Thus, the product computed on the padded grid is exact, and the final dealiased result on the $N=32$ grid will have an RMS error close to machine precision.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the specified test suite for spectral methods and dealiasing.\n    \"\"\"\n    \n    results = []\n\n    # --- Test A: Spectral differentiation accuracy ---\n    def run_test_A(N):\n        x = 2 * np.pi * np.arange(N) / N\n        u = np.sin(3 * x) + 0.5 * np.cos(5 * x)\n        u_x_analytic = 3 * np.cos(3 * x) - 2.5 * np.sin(5 * x)\n        \n        # Spectral derivative\n        u_hat = np.fft.fft(u)\n        # Wavenumbers k = [0, 1, ..., N/2-1, -N/2, ..., -1]\n        k = np.fft.fftfreq(N, d=1.0/N)\n        du_dx_hat = 1j * k * u_hat\n        u_x_spectral = np.fft.ifft(du_dx_hat)\n        \n        # Error calculation\n        error = np.max(np.abs(np.real(u_x_spectral) - u_x_analytic))\n        return error\n\n    results.append(run_test_A(16))\n    results.append(run_test_A(32))\n    results.append(run_test_A(64))\n\n    # --- Test B: Aliasing in u^2 and 3/2-rule dealiasing ---\n    def run_test_B(N):\n        x = 2 * np.pi * np.arange(N) / N\n        u = np.cos(6 * x) + np.cos(7 * x)\n\n        # Aliased computation\n        u_sq_alias_phys = u**2\n        u_sq_alias_hat = np.fft.fft(u_sq_alias_phys)\n\n        # Dealiased 3/2-rule computation\n        N_pad = int(N * 3 / 2)\n        u_hat = np.fft.fft(u)\n        \n        # Pad spectrum, scaling by N'/N\n        u_hat_padded = np.zeros(N_pad, dtype=complex)\n        scaling_factor_pad = N_pad / N\n        if N > 0:\n            half_N = N // 2\n            u_hat_padded[0 : half_N] = scaling_factor_pad * u_hat[0 : half_N]\n            u_hat_padded[N_pad - (N - half_N) :] = scaling_factor_pad * u_hat[half_N:]\n        \n        u_padded = np.fft.ifft(u_hat_padded)\n        u_sq_padded_phys = np.real(u_padded)**2\n        u_sq_padded_hat = np.fft.fft(u_sq_padded_phys)\n        \n        # Truncate spectrum, scaling by N/N'\n        u_sq_dealias_hat = np.zeros(N, dtype=complex)\n        scaling_factor_trunc = N / N_pad\n        if N > 0:\n            half_N = N // 2\n            u_sq_dealias_hat[0 : half_N] = scaling_factor_trunc * u_sq_padded_hat[0 : half_N]\n            u_sq_dealias_hat[half_N:] = scaling_factor_trunc * u_sq_padded_hat[N_pad - (N - half_N) :]\n        \n        diff_norm = np.linalg.norm(u_sq_alias_hat - u_sq_dealias_hat)\n        return diff_norm\n\n    results.append(run_test_B(16))\n\n    # --- Test C: 3/2-rule versus 2/3-rule equivalence ---\n    def run_test_C(N):\n        Kc = N // 3\n        x = 2 * np.pi * np.arange(N) / N\n        u = np.cos(7 * x) + 0.5 * np.sin(6 * x)\n        k = np.fft.fftfreq(N, d=1.0/N)\n\n        # 3/2-rule\n        N_pad = int(N * 3 / 2)\n        u_hat = np.fft.fft(u)\n\n        u_hat_padded = np.zeros(N_pad, dtype=complex)\n        scaling_factor_pad = N_pad / N\n        half_N = N // 2\n        u_hat_padded[0 : half_N] = scaling_factor_pad * u_hat[0 : half_N]\n        u_hat_padded[N_pad - (N - half_N) :] = scaling_factor_pad * u_hat[half_N:]\n\n        u_padded = np.fft.ifft(u_hat_padded)\n        u_sq_padded_phys = np.real(u_padded)**2\n        u_sq_padded_hat = np.fft.fft(u_sq_padded_phys)\n\n        u_sq_32_hat = np.zeros(N, dtype=complex)\n        scaling_factor_trunc = N / N_pad\n        u_sq_32_hat[0 : half_N] = scaling_factor_trunc * u_sq_padded_hat[0 : half_N]\n        u_sq_32_hat[half_N:] = scaling_factor_trunc * u_sq_padded_hat[N_pad - (N - half_N) :]\n\n        # 2/3-rule\n        u_hat_trunc = u_hat.copy()\n        u_hat_trunc[np.abs(k) > Kc] = 0\n        u_trunc = np.fft.ifft(u_hat_trunc)\n        u_sq_trunc_phys = np.real(u_trunc)**2\n        u_sq_23_hat = np.fft.fft(u_sq_trunc_phys)\n        u_sq_23_hat[np.abs(k) > Kc] = 0\n\n        # Comparison\n        low_modes_mask = np.abs(k) = Kc\n        max_diff = np.max(np.abs(u_sq_32_hat[low_modes_mask] - u_sq_23_hat[low_modes_mask]))\n        return max_diff\n        \n    results.append(run_test_C(24))\n\n    # --- Test D: Aliased vs. dealiased nonlinear flux derivative ---\n    def run_test_D(N):\n        x = 2 * np.pi * np.arange(N) / N\n        u = np.sin(9 * x) + 0.4 * np.cos(8 * x)\n        \n        # Exact flux derivative\n        ux_analytic = 9 * np.cos(9 * x) - 3.2 * np.sin(8 * x)\n        flux_deriv_exact = u * ux_analytic\n        \n        # Aliased computation\n        u_hat = np.fft.fft(u)\n        k = np.fft.fftfreq(N, d=1.0/N)\n        ux_hat = 1j * k * u_hat\n        ux_spectral = np.fft.ifft(ux_hat)\n        flux_deriv_alias = u * np.real(ux_spectral)\n        err_alias = np.sqrt(np.mean((flux_deriv_alias - flux_deriv_exact)**2))\n        \n        # Dealiased 3/2-rule computation\n        N_pad = int(N * 3 / 2)\n        k_pad = np.fft.fftfreq(N_pad, d=1.0/N_pad)\n\n        u_hat_padded = np.zeros(N_pad, dtype=complex)\n        scaling_factor_pad = N_pad / N\n        half_N = N // 2\n        u_hat_padded[0 : half_N] = scaling_factor_pad * u_hat[0 : half_N]\n        u_hat_padded[N_pad - (N - half_N) :] = scaling_factor_pad * u_hat[half_N:]\n        \n        ux_hat_padded = 1j * k_pad * u_hat_padded\n        \n        u_padded = np.fft.ifft(u_hat_padded)\n        ux_padded = np.fft.ifft(ux_hat_padded)\n        \n        flux_deriv_padded_phys = np.real(u_padded) * np.real(ux_padded)\n        flux_deriv_padded_hat = np.fft.fft(flux_deriv_padded_phys)\n        \n        flux_deriv_dealias_hat = np.zeros(N, dtype=complex)\n        scaling_factor_trunc = N / N_pad\n        flux_deriv_dealias_hat[0 : half_N] = scaling_factor_trunc * flux_deriv_padded_hat[0 : half_N]\n        flux_deriv_dealias_hat[half_N:] = scaling_factor_trunc * flux_deriv_padded_hat[N_pad - (N - half_N) :]\n        \n        flux_deriv_dealias = np.fft.ifft(flux_deriv_dealias_hat)\n        err_dealias = np.sqrt(np.mean((np.real(flux_deriv_dealias) - flux_deriv_exact)**2))\n        \n        return err_alias, err_dealias\n\n    err_D_alias, err_D_dealias = run_test_D(32)\n    results.append(err_D_alias)\n    results.append(err_D_dealias)\n    \n    # Format and print the final output\n    formatted_results = [f\"{r:.12e}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\n# Calling solve() is commented out in this context.\n# When run in a suitable environment, it would be called.\n# solve()\n```", "id": "3381044"}]}