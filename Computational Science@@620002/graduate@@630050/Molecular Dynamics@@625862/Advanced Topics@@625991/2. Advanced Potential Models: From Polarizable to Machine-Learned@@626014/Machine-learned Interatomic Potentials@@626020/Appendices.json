{"hands_on_practices": [{"introduction": "At the core of modern machine-learned potentials is their ability to provide not just energies but also the atomic forces that drive molecular dynamics simulations. These forces are not learned independently but are derived as the analytical gradient of the learned potential energy with respect to atomic positions. This exercise hones the essential skill of applying the chain rule through the model's descriptors, connecting the abstract mathematical architecture of a Behler-Parrinello potential to the concrete physical quantity of force [@problem_id:3422803].", "problem": "Consider a neural-network interatomic potential of the Behler–Parrinello type, where the per-atom energy for atom $i$ is modeled as $E_i = f(\\{G_i^m\\}_{m=1}^{M})$, with $f$ a differentiable function of a set of differentiable descriptors $\\{G_i^m\\}$. The total energy is $E = \\sum_{i} E_i$. Focus on the angular three-body descriptor often denoted $G_i^4$, defined for a central atom $i$ by a sum over unordered neighbor pairs $(j,k)$ as $G_i^4 = \\sum_{j \\neq i} \\sum_{k \\neq i,\\, k>j} G_i^{4,(ijk)}$, where the triplet contribution is\n$$\nG_i^{4,(ijk)} \\equiv 2^{1-\\zeta}\\,\\bigl(1+\\lambda \\cos \\theta_{ijk}\\bigr)^{\\zeta}\\,\\exp\\!\\bigl[-\\eta\\,(r_{ij}^{2}+r_{ik}^{2}+r_{jk}^{2})\\bigr]\\,f_c(r_{ij})\\,f_c(r_{ik})\\,f_c(r_{jk}).\n$$\nHere $\\zeta>0$, $\\lambda \\in \\{-1,+1\\}$, and $\\eta>0$ are hyperparameters, $\\mathbf{r}_a \\in \\mathbb{R}^3$ is the position of atom $a$, $\\mathbf{r}_{ab} \\equiv \\mathbf{r}_b-\\mathbf{r}_a$, $r_{ab} \\equiv |\\mathbf{r}_{ab}|$, and $\\cos\\theta_{ijk} \\equiv \\hat{\\mathbf{r}}_{ij}\\cdot \\hat{\\mathbf{r}}_{ik}$ with $\\hat{\\mathbf{r}}_{ab} \\equiv \\mathbf{r}_{ab}/r_{ab}$. The cutoff function $f_c(r)$ is a differentiable radial function with derivative $f_c'(r) \\equiv \\frac{d f_c}{dr}$ and compact support $r \\le r_c$.\n\nUsing only vector calculus, Newton’s second law, and the chain rule, perform the following two tasks for a fixed triplet $(i,j,k)$:\n- Compute the vector gradient $\\frac{\\partial G_i^{4,(ijk)}}{\\partial \\mathbf{r}_k}$ in closed form in terms of $\\hat{\\mathbf{r}}_{ab}$, $r_{ab}$, $f_c(r)$, $f_c'(r)$, the hyperparameters $(\\eta,\\lambda,\\zeta)$, and $\\cos\\theta_{ijk}$.\n- Then, using the definition of mechanical force $\\mathbf{F}_k \\equiv -\\frac{\\partial E}{\\partial \\mathbf{r}_k}$, use the chain rule to express $\\mathbf{F}_k$ in compact summation form in terms of $\\frac{\\partial f}{\\partial G_i^m}$ and $\\frac{\\partial G_i^m}{\\partial \\mathbf{r}_k}$.\n\nYour final answer must consist of a closed-form analytic expression. Do not provide intermediate steps in the final answer. No numerical evaluation is required, and no units are needed.", "solution": "The problem is subjected to a rigorous validation process before a solution is attempted.\n\n### Step 1: Extract Givens\n-   The per-atom energy for atom $i$ is $E_i = f(\\{G_i^m\\}_{m=1}^{M})$, where $f$ is a differentiable function and $\\{G_i^m\\}$ are differentiable descriptors.\n-   The total energy is $E = \\sum_{i} E_i$.\n-   The angular three-body descriptor $G_i^4$ for a central atom $i$ is $G_i^4 = \\sum_{j \\neq i} \\sum_{k \\neq i,\\, k>j} G_i^{4,(ijk)}$.\n-   The contribution from a single triplet $(i,j,k)$ is given by:\n    $$\n    G_i^{4,(ijk)} \\equiv 2^{1-\\zeta}\\,\\bigl(1+\\lambda \\cos \\theta_{ijk}\\bigr)^{\\zeta}\\,\\exp\\!\\bigl[-\\eta\\,(r_{ij}^{2}+r_{ik}^{2}+r_{jk}^{2})\\bigr]\\,f_c(r_{ij})\\,f_c(r_{ik})\\,f_c(r_{jk}).\n    $$\n-   Hyperparameters: $\\zeta>0$, $\\lambda \\in \\{-1,+1\\}$, $\\eta>0$.\n-   Definitions: $\\mathbf{r}_a \\in \\mathbb{R}^3$ is the position of atom $a$, $\\mathbf{r}_{ab} \\equiv \\mathbf{r}_b-\\mathbf{r}_a$, $r_{ab} \\equiv |\\mathbf{r}_{ab}|$, $\\hat{\\mathbf{r}}_{ab} \\equiv \\mathbf{r}_{ab}/r_{ab}$, and $\\cos\\theta_{ijk} \\equiv \\hat{\\mathbf{r}}_{ij}\\cdot \\hat{\\mathbf{r}}_{ik}$.\n-   The cutoff function $f_c(r)$ is differentiable with derivative $f_c'(r)$, and has compact support for $r \\le r_c$.\n-   The mechanical force on atom $k$ is defined as $\\mathbf{F}_k \\equiv -\\frac{\\partial E}{\\partial \\mathbf{r}_k}$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is assessed for validity:\n-   **Scientifically Grounded**: The problem describes the mathematical structure of a Behler-Parrinello Neural Network Potential, specifically a common angular symmetry function ($G^4$), and the calculation of atomic forces. These are standard, well-established concepts in the field of computational materials science and molecular dynamics. The formulation is based on fundamental principles of calculus and classical mechanics. The problem is scientifically sound.\n-   **Well-Posed**: The problem provides all necessary definitions and equations to perform the requested calculations. The functions are stated to be differentiable, ensuring that the required gradients exist. The tasks are to compute a specific gradient and to derive a general formula, both of which are uniquely determined by the provided information.\n-   **Objective**: The language is precise, mathematical, and free of any subjective or ambiguous terminology.\n-   **Completeness and Consistency**: The givens are self-consistent and sufficient to solve the problem.\n-   **Feasibility**: The calculations are mathematically tractable using standard vector calculus and do not involve any physically impossible conditions.\n\n### Step 3: Verdict and Action\nThe problem is deemed **valid**. It is a formal, well-defined exercise in vector calculus applied to a standard model in computational physics. A solution will be provided.\n\n### Solution Derivation\n\nThe problem consists of two distinct tasks. Each will be addressed in turn.\n\n**Task 1: Compute the vector gradient $\\frac{\\partial G_i^{4,(ijk)}}{\\partial \\mathbf{r}_k}$**\n\nWe are asked to compute the gradient of $G_i^{4,(ijk)}$ with respect to the position vector $\\mathbf{r}_k$ of atom $k$. Let us denote the gradient operator as $\\nabla_k \\equiv \\frac{\\partial}{\\partial \\mathbf{r}_k}$. The expression for $G_i^{4,(ijk)}$ is a product of three functions of atomic positions:\n$$\nG_i^{4,(ijk)} = \\underbrace{2^{1-\\zeta}\\,(1+\\lambda \\cos \\theta_{ijk})^{\\zeta}}_{A} \\cdot \\underbrace{\\exp[-\\eta\\,(r_{ij}^{2}+r_{ik}^{2}+r_{jk}^{2})]}_{B} \\cdot \\underbrace{f_c(r_{ij})\\,f_c(r_{ik})\\,f_c(r_{jk})}_{C}\n$$\nWe apply the product rule for gradients. A convenient way to do this is via the logarithmic derivative:\n$$\n\\nabla_k G_i^{4,(ijk)} = G_i^{4,(ijk)} \\left( \\frac{1}{A} \\nabla_k A + \\frac{1}{B} \\nabla_k B + \\frac{1}{C} \\nabla_k C \\right)\n$$\nWe compute each term separately. The positions $\\mathbf{r}_i$ and $\\mathbf{r}_j$ are held constant during differentiation with respect to $\\mathbf{r}_k$. Consequently, $\\mathbf{r}_{ij}$ and $r_{ij}$ are constants. We will use the following elementary gradient identities: $\\nabla_k \\mathbf{r}_{ik} = \\mathbf{I}$ (identity matrix), $\\nabla_k r_{ik} = \\hat{\\mathbf{r}}_{ik}$, $\\nabla_k r_{jk} = \\hat{\\mathbf{r}}_{jk}$, and $\\nabla_k r_{ik}^2 = 2\\mathbf{r}_{ik}$.\n\n1.  **Gradient of the angular term A:**\n    $$\n    \\nabla_k A = \\nabla_k \\left[ 2^{1-\\zeta}\\,(1+\\lambda \\cos \\theta_{ijk})^{\\zeta} \\right] = 2^{1-\\zeta} \\zeta (1+\\lambda \\cos \\theta_{ijk})^{\\zeta-1} (\\lambda \\nabla_k \\cos \\theta_{ijk})\n    $$\n    We need the gradient of $\\cos \\theta_{ijk} = \\hat{\\mathbf{r}}_{ij} \\cdot \\hat{\\mathbf{r}}_{ik}$. Since $\\hat{\\mathbf{r}}_{ij}$ is constant with respect to $\\mathbf{r}_k$:\n    $$\n    \\nabla_k \\cos \\theta_{ijk} = \\nabla_k \\left( \\frac{\\mathbf{r}_{ij} \\cdot \\mathbf{r}_{ik}}{r_{ij} r_{ik}} \\right) = \\frac{1}{r_{ij}} \\nabla_k \\left( \\frac{\\mathbf{r}_{ij} \\cdot \\mathbf{r}_{ik}}{r_{ik}} \\right)\n    $$\n    Using the quotient rule for gradients, $\\nabla(u/v) = (v\\nabla u - u\\nabla v)/v^2$, with $u = \\mathbf{r}_{ij} \\cdot \\mathbf{r}_{ik}$ and $v = r_{ik}$:\n    $$\n    \\nabla_k \\left( \\frac{\\mathbf{r}_{ij} \\cdot \\mathbf{r}_{ik}}{r_{ik}} \\right) = \\frac{r_{ik} \\nabla_k(\\mathbf{r}_{ij} \\cdot \\mathbf{r}_{ik}) - (\\mathbf{r}_{ij} \\cdot \\mathbf{r}_{ik}) \\nabla_k r_{ik}}{r_{ik}^2} = \\frac{r_{ik}\\mathbf{r}_{ij} - (\\mathbf{r}_{ij} \\cdot \\mathbf{r}_{ik})\\hat{\\mathbf{r}}_{ik}}{r_{ik}^2} = \\frac{\\mathbf{r}_{ij} - (\\mathbf{r}_{ij} \\cdot \\hat{\\mathbf{r}}_{ik})\\hat{\\mathbf{r}}_{ik}}{r_{ik}}\n    $$\n    Substituting back $\\mathbf{r}_{ij} = r_{ij}\\hat{\\mathbf{r}}_{ij}$ and $\\mathbf{r}_{ij}\\cdot\\hat{\\mathbf{r}}_{ik} = r_{ij}\\cos\\theta_{ijk}$:\n    $$\n    \\nabla_k \\cos \\theta_{ijk} = \\frac{1}{r_{ij}} \\frac{r_{ij}\\hat{\\mathbf{r}}_{ij} - r_{ij}\\cos\\theta_{ijk}\\hat{\\mathbf{r}}_{ik}}{r_{ik}} = \\frac{\\hat{\\mathbf{r}}_{ij} - \\cos\\theta_{ijk}\\hat{\\mathbf{r}}_{ik}}{r_{ik}}\n    $$\n    The first logarithmic derivative term is:\n    $$\n    \\frac{1}{A} \\nabla_k A = \\frac{2^{1-\\zeta} \\zeta (1+\\lambda \\cos \\theta_{ijk})^{\\zeta-1} \\lambda}{2^{1-\\zeta}\\,(1+\\lambda \\cos \\theta_{ijk})^{\\zeta}} \\left( \\frac{\\hat{\\mathbf{r}}_{ij} - \\cos\\theta_{ijk}\\hat{\\mathbf{r}}_{ik}}{r_{ik}} \\right) = \\frac{\\zeta\\lambda}{1+\\lambda\\cos\\theta_{ijk}} \\left( \\frac{\\hat{\\mathbf{r}}_{ij} - \\cos\\theta_{ijk}\\hat{\\mathbf{r}}_{ik}}{r_{ik}} \\right)\n    $$\n\n2.  **Gradient of the exponential term B:**\n    $$\n    \\nabla_k B = \\nabla_k \\exp[-\\eta\\,(r_{ij}^{2}+r_{ik}^{2}+r_{jk}^{2})] = B \\cdot (-\\eta) \\nabla_k (r_{ij}^{2}+r_{ik}^{2}+r_{jk}^{2})\n    $$\n    Since $r_{ij}$ is constant, this simplifies to:\n    $$\n    \\nabla_k B = B \\cdot (-\\eta) ( \\nabla_k r_{ik}^2 + \\nabla_k r_{jk}^2 ) = B \\cdot (-\\eta) (2\\mathbf{r}_{ik} + 2\\mathbf{r}_{jk})\n    $$\n    The second logarithmic derivative term is:\n    $$\n    \\frac{1}{B} \\nabla_k B = -2\\eta(\\mathbf{r}_{ik} + \\mathbf{r}_{jk}) = -2\\eta(r_{ik}\\hat{\\mathbf{r}}_{ik} + r_{jk}\\hat{\\mathbf{r}}_{jk})\n    $$\n\n3.  **Gradient of the cutoff term C:**\n    $$\n    \\nabla_k C = \\nabla_k [f_c(r_{ij})f_c(r_{ik})f_c(r_{jk})] = f_c(r_{ij}) \\nabla_k [f_c(r_{ik})f_c(r_{jk})]\n    $$\n    Applying the product rule and chain rule:\n    $$\n    \\nabla_k C = f_c(r_{ij}) \\left[ (\\nabla_k f_c(r_{ik})) f_c(r_{jk}) + f_c(r_{ik}) (\\nabla_k f_c(r_{jk})) \\right]\n    $$\n    $$\n    = f_c(r_{ij}) \\left[ (f_c'(r_{ik})\\nabla_k r_{ik}) f_c(r_{jk}) + f_c(r_{ik}) (f_c'(r_{jk})\\nabla_k r_{jk}) \\right]\n    $$\n    $$\n    = f_c(r_{ij}) [ f_c'(r_{ik})\\hat{\\mathbf{r}}_{ik}f_c(r_{jk}) + f_c(r_{ik})f_c'(r_{jk})\\hat{\\mathbf{r}}_{jk} ]\n    $$\n    The third logarithmic derivative term is:\n    $$\n    \\frac{1}{C} \\nabla_k C = \\frac{f_c(r_{ij}) [ f_c'(r_{ik})\\hat{\\mathbf{r}}_{ik}f_c(r_{jk}) + f_c(r_{ik})f_c'(r_{jk})\\hat{\\mathbf{r}}_{jk} ]}{f_c(r_{ij})f_c(r_{ik})f_c(r_{jk})} = \\frac{f_c'(r_{ik})}{f_c(r_{ik})}\\hat{\\mathbf{r}}_{ik} + \\frac{f_c'(r_{jk})}{f_c(r_{jk})}\\hat{\\mathbf{r}}_{jk}\n    $$\n\nCombining all three terms, we obtain the full gradient:\n$$\n\\nabla_k G_i^{4,(ijk)} = G_i^{4,(ijk)} \\left[ \\frac{\\zeta\\lambda}{1+\\lambda\\cos\\theta_{ijk}}\\frac{\\hat{\\mathbf{r}}_{ij} - \\cos\\theta_{ijk}\\hat{\\mathbf{r}}_{ik}}{r_{ik}} - 2\\eta(r_{ik}\\hat{\\mathbf{r}}_{ik} + r_{jk}\\hat{\\mathbf{r}}_{jk}) + \\frac{f_c'(r_{ik})}{f_c(r_{ik})}\\hat{\\mathbf{r}}_{ik} + \\frac{f_c'(r_{jk})}{f_c(r_{jk})}\\hat{\\mathbf{r}}_{jk} \\right]\n$$\nGrouping the vector coefficients for $\\hat{\\mathbf{r}}_{ij}$, $\\hat{\\mathbf{r}}_{ik}$, and $\\hat{\\mathbf{r}}_{jk}$:\n$$\n\\nabla_k G_i^{4,(ijk)} = G_i^{4,(ijk)} \\left[ \\left(\\frac{\\zeta\\lambda}{(1+\\lambda\\cos\\theta_{ijk})r_{ik}}\\right)\\hat{\\mathbf{r}}_{ij} + \\left(\\frac{f_c'(r_{ik})}{f_c(r_{ik})} - 2\\eta r_{ik} - \\frac{\\zeta\\lambda\\cos\\theta_{ijk}}{(1+\\lambda\\cos\\theta_{ijk})r_{ik}}\\right)\\hat{\\mathbf{r}}_{ik} + \\left(\\frac{f_c'(r_{jk})}{f_c(r_{jk})} - 2\\eta r_{jk}\\right)\\hat{\\mathbf{r}}_{jk} \\right]\n$$\nThis is the closed-form expression for the gradient of the triplet contribution $G_i^{4,(ijk)}$ with respect to $\\mathbf{r}_k$.\n\n**Task 2: Express the force $\\mathbf{F}_k$ in compact summation form**\n\nThe force on atom $k$ is the negative gradient of the total potential energy $E$ with respect to its position vector $\\mathbf{r}_k$:\n$$\n\\mathbf{F}_k = -\\frac{\\partial E}{\\partial \\mathbf{r}_k}\n$$\nThe total energy is the sum of per-atom energies, $E = \\sum_i E_i$, where the sum is over all atoms in the system. Thus:\n$$\n\\mathbf{F}_k = -\\frac{\\partial}{\\partial \\mathbf{r}_k} \\sum_i E_i = - \\sum_i \\frac{\\partial E_i}{\\partial \\mathbf{r}_k}\n$$\nThe energy of each atom $i$, $E_i = f(\\{G_i^m\\}_{m=1}^{M})$, is a function of its set of symmetry functions (descriptors), $\\{G_i^m\\}$. Each descriptor, in turn, depends on the positions of atom $i$ and its neighbors. The position vector $\\mathbf{r}_k$ can influence $E_i$ only through the descriptors $G_i^m$. We apply the multivariable chain rule to find the gradient of $E_i$:\n$$\n\\frac{\\partial E_i}{\\partial \\mathbf{r}_k} = \\sum_{m=1}^{M} \\frac{\\partial E_i}{\\partial G_i^m} \\frac{\\partial G_i^m}{\\partial \\mathbf{r}_k}\n$$\nAs given, $E_i = f(\\{G_i^m\\})$, so the derivative of the network output with respect to its inputs is $\\frac{\\partial E_i}{\\partial G_i^m} = \\frac{\\partial f}{\\partial G_i^m}$. The notation $\\frac{\\partial f}{\\partial G_i^m}$ signifies the partial derivative of the function $f$ with respect to its $m$-th argument, evaluated for the set of descriptors of atom $i$.\n\nSubstituting this back into the force expression gives the final compact summation form:\n$$\n\\mathbf{F}_k = - \\sum_i \\sum_{m=1}^{M} \\frac{\\partial f}{\\partial G_i^m} \\frac{\\partial G_i^m}{\\partial \\mathbf{r}_k}\n$$\nThis expression is general. The sum over $i$ includes all atoms whose descriptors $\\{G_i^m\\}$ depend on $\\mathbf{r}_k$. This occurs if atom $k$ is the central atom $i$ or one of its neighbors involved in defining $G_i^m$. The term $\\frac{\\partial G_i^m}{\\partial \\mathbf{r}_k}$ is the gradient of a specific descriptor, an example of which was calculated in Task 1.", "answer": "$$\n\\boxed{\\begin{pmatrix} G_i^{4,(ijk)} \\left[ \\left(\\frac{\\zeta \\lambda}{(1+\\lambda \\cos \\theta_{ijk})r_{ik}}\\right) \\hat{\\mathbf{r}}_{ij} + \\left( \\frac{f_c'(r_{ik})}{f_c(r_{ik})} - 2\\eta r_{ik} - \\frac{\\zeta\\lambda \\cos\\theta_{ijk}}{(1+\\lambda\\cos\\theta_{ijk})r_{ik}} \\right) \\hat{\\mathbf{r}}_{ik} + \\left( \\frac{f_c'(r_{jk})}{f_c(r_{jk})} - 2\\eta r_{jk} \\right) \\hat{\\mathbf{r}}_{jk} \\right] & - \\sum_{i} \\sum_{m=1}^{M} \\frac{\\partial f}{\\partial G_i^m} \\frac{\\partial G_i^m}{\\partial \\mathbf{r}_k} \\end{pmatrix}}\n$$", "id": "3422803"}, {"introduction": "To accurately simulate condensed-phase materials like liquids and solids, an interatomic potential must be compatible with periodic boundary conditions (PBC). This requires that interactions are calculated based on the \"minimum image convention,\" ensuring the model's predictions are invariant to the translation of atoms across simulation cell boundaries. Through a direct coding task, this practice demonstrates the critical importance of correctly implementing PBC and quantifies the severe, non-physical artifacts that arise from a naive implementation, thereby solidifying a cornerstone of practical simulation work [@problem_id:3422853].", "problem": "You are tasked with auditing periodic boundary handling for machine-learned interatomic potentials by quantifying the continuity of energy and forces under equivalent periodic representations and at small changes to the simulation cell. The focus is on whether pairwise descriptors use the minimum image convention, defined for an orthorhombic periodic simulation cell with edge lengths $\\mathbf{L} = (L_x,L_y,L_z)$ by the minimum-image vector\n$$\n\\mathbf{r}_{ij} = \\operatorname{argmin}_{\\mathbf{n}\\in\\mathbb{Z}^3} \\left\\lVert \\mathbf{r}_i - \\mathbf{r}_j + \\mathbf{n}\\odot\\mathbf{L} \\right\\rVert,\n$$\nequivalently implemented componentwise as\n$$\n\\Delta x_\\alpha \\leftarrow \\Delta x_\\alpha - L_\\alpha \\,\\operatorname{round}\\!\\left(\\frac{\\Delta x_\\alpha}{L_\\alpha}\\right)\\quad \\text{for } \\alpha\\in\\{x,y,z\\},\n$$\nwhere $\\odot$ denotes elementwise multiplication and $\\operatorname{round}(\\cdot)$ rounds to the nearest integer. A naive descriptor uses the raw difference $\\mathbf{r}_i-\\mathbf{r}_j$ without periodic wrapping.\n\nYou will implement a pairwise Neural Network (NN) potential for testing, and then measure numerical discontinuities in total energy and per-atom forces under specific perturbations that should be physically benign when descriptors are correctly minimum-imaged. Although this audit approach applies to many models including Gaussian Approximation Potential (GAP), you will instantiate only the NN model below.\n\nUse the following fundamental base:\n- Newton’s second law and the potential energy picture: the total force on atom $i$ is given by $\\mathbf{F}_i = -\\nabla_{\\mathbf{r}_i} E(\\{\\mathbf{r}_k\\})$.\n- In a pairwise additive model with a smooth cutoff, the total potential energy is\n$$\nE = \\sum_{i<j} \\phi(r_{ij}),\n$$\nwhere $r_{ij}=\\lVert\\mathbf{r}_{ij}\\rVert$ and $\\phi(r)$ is a scalar function of the scalar separation $r$.\n- The per-pair force on atom $i$ due to atom $j$ is\n$$\n\\mathbf{F}_{i\\leftarrow j} = -\\frac{d\\phi}{dr}\\bigg|_{r=r_{ij}} \\frac{\\mathbf{r}_{ij}}{r_{ij}},\n$$\nwith $\\mathbf{F}_j=-\\mathbf{F}_i$ by Newton’s third law.\n\nModel specification to implement:\n- Pairwise NN interaction with one hidden nonlinearity and a smooth cosine cutoff:\n  - Let $u(r)=w_1 r + b_1$.\n  - Define the base interaction $\\phi_{\\mathrm{base}}(r) = w_2 \\tanh(u(r)) + b_2$.\n  - Define the cutoff $f_c(r)=\\tfrac{1}{2}\\left(\\cos\\left(\\pi r / r_c\\right)+1\\right)$ for $r<r_c$ and $f_c(r)=0$ for $r\\ge r_c$.\n  - The actual pair potential is $\\phi(r) = \\phi_{\\mathrm{base}}(r)\\, f_c(r)$.\n  - Use parameters $w_1=1.7$, $b_1=-0.3$, $w_2=0.9$, $b_2=0.2$, and cutoff radius $r_c=6.0$ (all in reduced, unitless form).\n- The derivative needed for forces follows by the chain rule:\n  - $\\frac{d\\phi_{\\mathrm{base}}}{dr} = w_2\\left(1-\\tanh^2(u(r))\\right)w_1$.\n  - $\\frac{df_c}{dr} = -\\tfrac{1}{2}\\tfrac{\\pi}{r_c}\\sin\\left(\\pi r / r_c\\right)$ for $r<r_c$ and $0$ for $r\\ge r_c$.\n  - Hence $\\frac{d\\phi}{dr} = \\frac{d\\phi_{\\mathrm{base}}}{dr} f_c(r) + \\phi_{\\mathrm{base}}(r)\\frac{df_c}{dr}$ for $r<r_c$ and $\\frac{d\\phi}{dr}=0$ for $r\\ge r_c$.\n\nTwo descriptor choices must be implemented:\n- Minimum-image descriptor: compute $\\mathbf{r}_{ij}$ with the minimum image convention as above.\n- Naive descriptor: compute $\\mathbf{r}_{ij} = \\mathbf{r}_i - \\mathbf{r}_j$ without any periodic wrapping.\n\nNumerical task:\n- Implement energy $E$ and forces $\\{\\mathbf{F}_i\\}$ for a given configuration and orthorhombic cell under both descriptor choices.\n- For each test case below, compute two discontinuity measures between two “states” $A$ and $B$:\n  - Energy discontinuity: $\\Delta E = |E_A - E_B|$.\n  - Force discontinuity: $\\Delta F = \\max_i \\lVert \\mathbf{F}_i^{(A)} - \\mathbf{F}_i^{(B)} \\rVert$, the maximum Euclidean norm across atoms.\n- Report these discontinuities for both the minimum-image descriptor and the naive descriptor.\n\nTest suite to cover distinct aspects:\n- Test $1$ (periodic wrapping equivalence for a pair): cubic cell with $\\mathbf{L}=(10,10,10)$. State $A$ positions are $\\mathbf{r}_1=(0.2,0.3,0.4)$ and $\\mathbf{r}_2=(9.8,0.3,0.4)$. State $B$ positions are $\\mathbf{r}_1'=(0.2,0.3,0.4)$ and $\\mathbf{r}_2'=(-0.2,0.3,0.4)$. These two states are physically equivalent under periodic boundaries. Compute $\\Delta E$ and $\\Delta F$ for minimum-image and naive descriptors.\n- Test $2$ (cell-length change across a minimum-image flip): two atoms with positions fixed at $\\mathbf{r}_1=(0,0,0)$ and $\\mathbf{r}_2=(5.00001,0,0)$. Consider cell $A$ with $\\mathbf{L}_A=(10.0,10.0,10.0)$ and cell $B$ with $\\mathbf{L}_B=(10.00004,10.0,10.0)$. Compute $\\Delta E$ and $\\Delta F$ between cell $A$ and cell $B$, once using minimum-image descriptors and once using naive descriptors. Angles are not involved. All quantities are unitless.\n- Test $3$ (multi-atom wrap equivalence in $3$ dimensions): cubic cell with $\\mathbf{L}=(10,10,10)$. State $A$ has $\\mathbf{r}_1=(9.9,0.1,0.1)$, $\\mathbf{r}_2=(0.2,0.1,0.1)$, $\\mathbf{r}_3=(5.0,9.8,0.1)$. State $B$ has $\\mathbf{r}_1'=(-0.1,0.1,0.1)$, $\\mathbf{r}_2'=(0.2,0.1,0.1)$, $\\mathbf{r}_3'=(5.0,-0.2,0.1)$. These are physically equivalent under periodic boundaries. Compute $\\Delta E$ and $\\Delta F$ for minimum-image and naive descriptors.\n\nFinal output specification:\n- Your program must compute, for each test in order $1,2,3$, the four floating-point values $[\\Delta E_{\\text{minimg}},\\Delta F_{\\text{minimg}},\\Delta E_{\\text{naive}},\\Delta F_{\\text{naive}}]$ and then aggregate all three tests’ results into a single flat list of $12$ floats in the following order:\n  - Test $1$ then Test $2$ then Test $3$, each contributing four numbers as listed above.\n- Round each reported number to exactly $10$ decimal places.\n- Produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example $[\\ldots]$.\n\nImplementation constraints:\n- The solution must be a single, complete, runnable program.\n- No user input or external files are allowed.\n- Use double-precision arithmetic for numerical stability.\n- All computations are unitless; do not print any units.", "solution": "The task is to audit the implementation of periodic boundary conditions (PBC) for a machine-learned interatomic potential by quantifying discontinuities in energy and forces. This involves implementing a specific pairwise neural network potential and applying it to atomic configurations under two different descriptors: one that correctly uses the minimum image convention (MIC) and a \"naive\" one that does not. The evaluation is performed across three test cases designed to probe the physical correctness and numerical stability of each approach.\n\nCentral to this problem are the foundational principles of molecular simulation. First, to simulate bulk materials, PBC are employed to eliminate finite-size artifacts. In an orthorhombic simulation cell defined by edge lengths $\\mathbf{L} = (L_x, L_y, L_z)$, the interaction between two atoms $i$ and $j$ at positions $\\mathbf{r}_i$ and $\\mathbf{r}_j$ must consider all periodic images of atom $j$. The Minimum Image Convention (MIC) simplifies this by stating that the interaction is determined solely by the single closest image. The vector pointing from atom $j$ to atom $i$ under the MIC, $\\mathbf{r}_{ij}$, is mathematically defined as:\n$$\n\\mathbf{r}_{ij} = \\operatorname{argmin}_{\\mathbf{n}\\in\\mathbb{Z}^3} \\left\\lVert (\\mathbf{r}_i - \\mathbf{r}_j) + \\mathbf{n}\\odot\\mathbf{L} \\right\\rVert\n$$\nwhere $\\mathbf{n}$ is a vector of integers and $\\odot$ is elementwise multiplication. This is computationally implemented for each Cartesian component $\\alpha \\in \\{x,y,z\\}$ of the raw displacement vector $\\Delta \\mathbf{r} = \\mathbf{r}_i - \\mathbf{r}_j$ by wrapping it into the primary cell's domain $[-L_\\alpha/2, L_\\alpha/2]$:\n$$\n\\Delta x_\\alpha \\leftarrow \\Delta x_\\alpha - L_\\alpha \\operatorname{round}\\left(\\frac{\\Delta x_\\alpha}{L_\\alpha}\\right)\n$$\nA correct implementation of the MIC is essential for creating a potential energy surface that is continuous and differentiable with respect to atom positions and cell parameters, reflecting physical reality. The naive descriptor, which uses the simple difference $\\mathbf{r}_{ij} = \\mathbf{r}_i - \\mathbf{r}_j$, fails to capture this periodicity and introduces severe artifacts at the boundaries of the simulation cell.\n\nThe second principle is the relationship between potential energy and force. In a pairwise additive model, the total potential energy $E$ of a system is the sum of interaction energies over all unique pairs of atoms:\n$$\nE = \\sum_{i < j} \\phi(r_{ij})\n$$\nHere, $\\phi(r)$ is the pair potential function, and $r_{ij} = \\lVert \\mathbf{r}_{ij} \\rVert$ is the scalar distance between atoms $i$ and $j$ (computed using the chosen descriptor). The force on any atom $i$, $\\mathbf{F}_i$, is the negative gradient of the total energy with respect to its Cartesian coordinates $\\mathbf{r}_i$:\n$$\n\\mathbf{F}_i = -\\nabla_{\\mathbf{r}_i} E(\\{\\mathbf{r}_k\\})\n$$\nApplying the chain rule, the force contribution on atom $i$ from atom $j$, denoted $\\mathbf{F}_{i \\leftarrow j}$, is derived as:\n$$\n\\mathbf{F}_{i \\leftarrow j} = -\\nabla_{\\mathbf{r}_i} \\phi(r_{ij}) = -\\frac{d\\phi}{dr_{ij}} \\nabla_{\\mathbf{r}_i} r_{ij} = -\\frac{d\\phi}{dr_{ij}} \\frac{\\mathbf{r}_{ij}}{r_{ij}}\n$$\nBy Newton's third law, the force on $j$ from $i$ is equal and opposite: $\\mathbf{F}_{j \\leftarrow i} = -\\mathbf{F}_{i \\leftarrow j}$. The total force on atom $i$ is the vector sum of contributions from all other atoms $j$: $\\mathbf{F}_i = \\sum_{j \\neq i} \\mathbf{F}_{i \\leftarrow j}$.\n\nThe specific pair potential to be implemented is a simple neural network-like model with a smooth cutoff. The interaction potential $\\phi(r)$ is the product of a base potential $\\phi_{\\mathrm{base}}(r)$ and a cutoff function $f_c(r)$:\n$$\n\\phi(r) = [w_2 \\tanh(w_1 r + b_1) + b_2] \\cdot \\left[ \\tfrac{1}{2}\\left(\\cos\\left(\\pi r / r_c\\right)+1\\right) \\right]\n$$\nThis form applies for $r < r_c$; for $r \\ge r_c$, $\\phi(r) = 0$. The cosine cutoff function $f_c(r)$ ensures that both the potential and its derivative (and thus the force) go smoothly to zero at the cutoff radius $r_c$, which is crucial for energy conservation in dynamics. The parameters are given as $w_1=1.7$, $b_1=-0.3$, $w_2=0.9$, $b_2=0.2$, and $r_c=6.0$. The derivative $\\frac{d\\phi}{dr}$, required for the force calculation, is obtained using the product rule:\n$$\n\\frac{d\\phi}{dr} = \\frac{d\\phi_{\\mathrm{base}}}{dr} f_c(r) + \\phi_{\\mathrm{base}}(r) \\frac{df_c}{dr}\n$$\nwhere $\\frac{d\\phi_{\\mathrm{base}}}{dr} = w_1 w_2 (1-\\tanh^2(w_1 r + b_1))$ and $\\frac{df_c}{dr} = -\\frac{\\pi}{2r_c}\\sin(\\frac{\\pi r}{r_c})$ for $r < r_c$.\n\nThe validation procedure involves three tests, each comparing a state $A$ and a state $B$. We compute the energy discontinuity $\\Delta E = |E_A - E_B|$ and the maximum force discontinuity $\\Delta F = \\max_i \\lVert \\mathbf{F}_i^{(A)} - \\mathbf{F}_i^{(B)} \\rVert$.\n- Tests $1$ and $3$ examine translational invariance. State $B$ is constructed from state $A$ by translating one or more atoms by integer multiples of the lattice vectors. Physically, these states are identical. A correct MIC descriptor should yield $\\Delta E = 0$ and $\\Delta F = 0$ (within machine precision), as it correctly identifies the invariant relative configuration of the atoms. The naive descriptor will perceive large changes in interatomic distances, leading to significant, non-physical discontinuities.\n- Test $2$ probes the continuity of the potential energy surface. The atomic positions are fixed, but the cell length $L_x$ is infinitesimally changed. The change is specifically chosen to cause the MIC to \"flip\" which image of an atom is considered the closest. For a properly constructed smooth potential, this should lead to a correspondingly small, continuous change in energy and forces. A large jump would indicate a flaw in the potential function itself or its implementation. The naive descriptor is insensitive to cell parameters, so it will report zero discontinuity because the absolute atomic positions are unchanged.\n\nThe algorithm to be implemented will first define functions for $\\phi(r)$ and $\\frac{d\\phi}{dr}$. A central function will then compute the total energy $E$ and the force array $\\{\\mathbf{F}_i\\}$ for a given set of `positions`, `cell vectors`, and a boolean flag to select between the `MIC` and `naive` descriptors. This function iterates over all unique pairs of atoms, calculates the pair distance and vector according to the chosen descriptor, and accumulates the energy and force contributions if the distance is within the cutoff $r_c$. This computational machinery is then applied to each test case to determine the four required discontinuity metrics, which are then reported in the specified format.", "answer": "```python\nimport numpy as np\n\n# Global constants for the model\nW1 = 1.7\nB1 = -0.3\nW2 = 0.9\nB2 = 0.2\nR_C = 6.0\n\ndef phi_base(r):\n    \"\"\"Calculates the base potential phi_base(r).\"\"\"\n    # u(r) = w1*r + b1\n    u = W1 * r + B1\n    # phi_base(r) = w2*tanh(u(r)) + b2\n    return W2 * np.tanh(u) + B2\n\ndef dphi_base_dr(r):\n    \"\"\"Calculates the derivative of the base potential d(phi_base)/dr.\"\"\"\n    # u(r) = w1*r + b1\n    u = W1 * r + B1\n    # d(phi_base)/dr = w2 * (1 - tanh^2(u(r))) * w1\n    return W2 * (1 - np.tanh(u)**2) * W1\n\ndef f_c(r):\n    \"\"\"Calculates the cosine cutoff function f_c(r).\"\"\"\n    return 0.5 * (np.cos(np.pi * r / R_C) + 1)\n\ndef df_c_dr(r):\n    \"\"\"Calculates the derivative of the cutoff function df_c/dr.\"\"\"\n    return -0.5 * (np.pi / R_C) * np.sin(np.pi * r / R_C)\n\ndef phi(r):\n    \"\"\"Calculates the full pair potential phi(r).\"\"\"\n    return np.where(r < R_C, phi_base(r) * f_c(r), 0.0)\n\ndef dphi_dr(r):\n    \"\"\"Calculates the derivative of the full pair potential dphi/dr.\"\"\"\n    return np.where(\n        r < R_C,\n        dphi_base_dr(r) * f_c(r) + phi_base(r) * df_c_dr(r),\n        0.0\n    )\n\ndef minimum_image_vector(delta_r, L):\n    \"\"\"Applies the minimum image convention to a displacement vector.\"\"\"\n    return delta_r - L * np.round(delta_r / L)\n\ndef calculate_energy_and_forces(positions, L, use_min_image):\n    \"\"\"\n    Calculates the total potential energy and per-atom forces for a configuration.\n    \"\"\"\n    positions = np.asarray(positions, dtype=np.float64)\n    L = np.asarray(L, dtype=np.float64)\n    num_atoms = positions.shape[0]\n    total_energy = 0.0\n    forces = np.zeros_like(positions)\n\n    for i in range(num_atoms):\n        for j in range(i + 1, num_atoms):\n            r_i = positions[i]\n            r_j = positions[j]\n            \n            # Raw displacement vector\n            r_ij_vec = r_i - r_j\n\n            # Apply minimum image convention if required\n            if use_min_image:\n                r_ij_vec = minimum_image_vector(r_ij_vec, L)\n            \n            r_ij_mag = np.linalg.norm(r_ij_vec)\n\n            # Contributions only if within cutoff\n            if r_ij_mag < R_C:\n                # Energy\n                total_energy += phi(r_ij_mag)\n\n                # Force\n                # F_i_from_j = - (dphi/dr) * (r_ij_vec / r_ij_mag)\n                if r_ij_mag > 1e-12: # Avoid division by zero\n                    dphi_val = dphi_dr(r_ij_mag)\n                    force_vec = -dphi_val * (r_ij_vec / r_ij_mag)\n                    forces[i] += force_vec\n                    forces[j] -= force_vec\n\n    return total_energy, forces\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    \n    test_cases = [\n        {   # Test 1: Periodic wrapping equivalence for a pair\n            \"pos_A\": [[0.2, 0.3, 0.4], [9.8, 0.3, 0.4]],\n            \"L_A\": [10.0, 10.0, 10.0],\n            \"pos_B\": [[0.2, 0.3, 0.4], [-0.2, 0.3, 0.4]],\n            \"L_B\": [10.0, 10.0, 10.0]\n        },\n        {   # Test 2: Cell-length change across a minimum-image flip\n            \"pos_A\": [[0.0, 0.0, 0.0], [5.00001, 0.0, 0.0]],\n            \"L_A\": [10.0, 10.0, 10.0],\n            \"pos_B\": [[0.0, 0.0, 0.0], [5.00001, 0.0, 0.0]],\n            \"L_B\": [10.00004, 10.0, 10.0]\n        },\n        {   # Test 3: Multi-atom wrap equivalence in 3D\n            \"pos_A\": [[9.9, 0.1, 0.1], [0.2, 0.1, 0.1], [5.0, 9.8, 0.1]],\n            \"L_A\": [10.0, 10.0, 10.0],\n            \"pos_B\": [[-0.1, 0.1, 0.1], [0.2, 0.1, 0.1], [5.0, -0.2, 0.1]],\n            \"L_B\": [10.0, 10.0, 10.0]\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        pos_A = np.array(case[\"pos_A\"])\n        L_A = np.array(case[\"L_A\"])\n        pos_B = np.array(case[\"pos_B\"])\n        L_B = np.array(case[\"L_B\"])\n\n        # --- Minimum Image Descriptor ---\n        E_A_min, F_A_min = calculate_energy_and_forces(pos_A, L_A, use_min_image=True)\n        E_B_min, F_B_min = calculate_energy_and_forces(pos_B, L_B, use_min_image=True)\n        \n        delta_E_min = np.abs(E_A_min - E_B_min)\n        force_diff_norms_min = np.linalg.norm(F_A_min - F_B_min, axis=1)\n        delta_F_min = np.max(force_diff_norms_min) if force_diff_norms_min.size > 0 else 0.0\n        \n        all_results.append(delta_E_min)\n        all_results.append(delta_F_min)\n\n        # --- Naive Descriptor ---\n        # Note: The naive descriptor does not use the cell vectors L.\n        E_A_naive, F_A_naive = calculate_energy_and_forces(pos_A, L_A, use_min_image=False)\n        E_B_naive, F_B_naive = calculate_energy_and_forces(pos_B, L_B, use_min_image=False)\n\n        delta_E_naive = np.abs(E_A_naive - E_B_naive)\n        force_diff_norms_naive = np.linalg.norm(F_A_naive - F_B_naive, axis=1)\n        delta_F_naive = np.max(force_diff_norms_naive) if force_diff_norms_naive.size > 0 else 0.0\n\n        all_results.append(delta_E_naive)\n        all_results.append(delta_F_naive)\n\n    formatted_results = [\"{:.10f}\".format(res) for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3422853"}, {"introduction": "Training a robust machine-learned potential involves more than just minimizing a single error metric; it requires a strategic balance between fitting different, but related, physical observables. The total training loss is typically a weighted sum of errors in energy ($E$), forces ($\\mathbf{F}$), and the stress tensor ($\\boldsymbol{\\sigma}$), where the weights have both a rigorous statistical interpretation and profound practical consequences. This practice delves into the theoretical underpinnings of this composite loss function, exploring how the choice of weights influences the training process and the final model's ability to generalize for stable and accurate molecular dynamics simulations [@problem_id:3422810].", "problem": "You are training a machine-learned interatomic potential for use in Molecular Dynamics (MD) that enforces energy-force-stress consistency (forces and stresses are obtained as analytic derivatives of the learned energy). Consider a dataset of $N_{\\mathrm{s}}$ atomistic structures. For structure $i$, the reference energy from Density Functional Theory (DFT) is $E_{i}^{\\mathrm{DFT}}$, the reference force vector is $\\mathbf{F}_{i}^{\\mathrm{DFT}} \\in \\mathbb{R}^{3N_{i}}$ for $N_{i}$ atoms, and the reference Cauchy (virial) stress tensor is $\\boldsymbol{\\sigma}_{i}^{\\mathrm{DFT}} \\in \\mathbb{R}^{3 \\times 3}$. A parametric model $E_{i}^{\\mathrm{ML}}(\\mathbf{R}_{i};\\boldsymbol{\\theta})$ predicts energies from coordinates $\\mathbf{R}_{i}$ with parameters $\\boldsymbol{\\theta}$, and forces and stresses are obtained by differentiation, $\\mathbf{F}_{i}^{\\mathrm{ML}}(\\mathbf{R}_{i};\\boldsymbol{\\theta}) = -\\nabla_{\\mathbf{R}_{i}} E_{i}^{\\mathrm{ML}}$ and $\\boldsymbol{\\sigma}_{i}^{\\mathrm{ML}}(\\mathbf{R}_{i};\\boldsymbol{\\theta}) = \\partial E_{i}^{\\mathrm{ML}} / \\partial \\boldsymbol{\\epsilon}$ with respect to a small homogeneous strain $\\boldsymbol{\\epsilon}$.\n\nAssume the following fundamental base:\n- The residuals $E_{i}^{\\mathrm{DFT}} - E_{i}^{\\mathrm{ML}}$, $\\mathbf{F}_{i}^{\\mathrm{DFT}} - \\mathbf{F}_{i}^{\\mathrm{ML}}$, and $\\boldsymbol{\\sigma}_{i}^{\\mathrm{DFT}} - \\boldsymbol{\\sigma}_{i}^{\\mathrm{ML}}$ are independent, zero-mean Gaussian random variables across structures and components, with variances $\\sigma_{E}^{2}$, $\\sigma_{F}^{2}$, and $\\sigma_{\\sigma}^{2}$ for energy, any single Cartesian force component, and any single stress component, respectively.\n- The objective is the maximum likelihood estimate of $\\boldsymbol{\\theta}$ under these Gaussian assumptions.\n- Mean squared error (MSE) is defined per type as the average of squared residuals over all available samples and components of that type; for example, the force mean squared error averages over $3N_{i}$ components for each structure $i$, and then over structures.\n\nFrom this base, derive the combined training objective that arises from the negative log-likelihood and explain how relative weights on the energy, force, and stress terms emerge from the noise model. Then reason, using the relationships $\\mathbf{F} = -\\nabla_{\\mathbf{R}} E$ and $\\boldsymbol{\\sigma} = \\partial E / \\partial \\boldsymbol{\\epsilon}$, how these weights affect (i) the gradient magnitudes during parameter updates, (ii) the location of the optimum in the presence of model misspecification or heterogeneous noise, and (iii) downstream generalization for dynamical stability and thermodynamic properties in MD.\n\nSelect all statements that are correct:\n\nA. Under independent Gaussian observation noise for energy, force components, and stress components, maximizing likelihood is equivalent to minimizing a weighted sum of per-type mean squared errors, with the optimal relative weights proportional to the inverse noise variances, i.e., choosing $\\alpha : \\beta : \\gamma = \\sigma_{E}^{-2} : \\sigma_{F}^{-2} : \\sigma_{\\sigma}^{-2}$ yields a statistically optimal balance across types.\n\nB. If forces and stresses are obtained by exact differentiation of the learned energy, increasing the force weight $\\beta$ only rescales gradients during training and cannot change the location of the empirical risk minimizer; therefore, the final fitted parameters are invariant to the choice of $\\beta$.\n\nC. Because forces have $3N_{i}$ components per structure, even when using per-component mean squared error for forces, one must multiply the force weight $\\beta$ by $3N_{i}$ to prevent forces from under-contributing to the objective.\n\nD. In a Bayesian treatment of the Gaussian Approximation Potential (GAP), taking Gaussian likelihoods with diagonal covariance for energy, force, and stress observations makes the loss-equivalent weights $\\alpha$, $\\beta$, and $\\gamma$ proportional to the inverse observation variances; these can be treated as hyperparameters and selected by maximizing the marginal likelihood (evidence), which typically improves generalization.\n\nE. Emphasizing forces by increasing $\\beta$ tends to improve dynamical stability and local curvature learning (e.g., near-equilibrium vibrational modes), but can degrade absolute energy calibration if $\\alpha$ is reduced too far; robust model selection should validate both force and energy metrics, and, where available, derived properties such as elastic constants or phonon dispersions.", "solution": "The user has provided a problem statement regarding the training of machine-learned interatomic potentials (MLIPs) and has asked for a validation of the problem, a derivation of the solution, and an evaluation of the provided options.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n-   A dataset of $N_{\\mathrm{s}}$ atomistic structures.\n-   For each structure $i$:\n    -   Reference DFT energy: $E_{i}^{\\mathrm{DFT}}$\n    -   Reference DFT force vector: $\\mathbf{F}_{i}^{\\mathrm{DFT}} \\in \\mathbb{R}^{3N_{i}}$ ($N_{i}$ atoms).\n    -   Reference DFT Cauchy (virial) stress tensor: $\\boldsymbol{\\sigma}_{i}^{\\mathrm{DFT}} \\in \\mathbb{R}^{3 \\times 3}$.\n-   A parametric ML model for energy, $E_{i}^{\\mathrm{ML}}(\\mathbf{R}_{i};\\boldsymbol{\\theta})$.\n-   Energy-force-stress consistency is enforced:\n    -   $\\mathbf{F}_{i}^{\\mathrm{ML}}(\\mathbf{R}_{i};\\boldsymbol{\\theta}) = -\\nabla_{\\mathbf{R}_{i}} E_{i}^{\\mathrm{ML}}$\n    -   $\\boldsymbol{\\sigma}_{i}^{\\mathrm{ML}}(\\mathbf{R}_{i};\\boldsymbol{\\theta}) = \\partial E_{i}^{\\mathrm{ML}} / \\partial \\boldsymbol{\\epsilon}$ (derivative with respect to homogeneous strain $\\boldsymbol{\\epsilon}$).\n-   Fundamental assumptions:\n    1.  Residuals for energy ($E_{i}^{\\mathrm{DFT}} - E_{i}^{\\mathrm{ML}}$), force components ($F_{ijk}^{\\mathrm{DFT}} - F_{ijk}^{\\mathrm{ML}}$), and stress components ($\\sigma_{i,kl}^{\\mathrm{DFT}} - \\sigma_{i,kl}^{\\mathrm{ML}}$) are independent, zero-mean Gaussian random variables.\n    2.  The variances are constant for each type of quantity: $\\sigma_{E}^{2}$ for energy, $\\sigma_{F}^{2}$ for any single Cartesian force component, and $\\sigma_{\\sigma}^{2}$ for any single stress component.\n-   Objective: Find the maximum likelihood estimate (MLE) of the parameters $\\boldsymbol{\\theta}$.\n-   Definition: Mean squared error (MSE) is the average of squared residuals over all available samples and components of that type.\n\n**Step 2: Validate Using Extracted Givens**\n\nThe problem statement is scientifically grounded, well-posed, and objective.\n-   **Scientific Grounding**: The setup describes the standard and state-of-the-art methodology for training physics-informed MLIPs. The use of DFT as a source of reference data, the enforcement of energy conservation ($\\mathbf{F} = -\\nabla E$), the definition of virial stress, the assumption of Gaussian noise, and the use of maximum likelihood estimation are all fundamental and widely accepted principles in computational materials science and physics.\n-   **Well-Posedness**: The problem is well-defined. The assumptions provided are sufficient to derive a unique mathematical form for the objective function. The questions posed have clear, derivable answers within the given framework.\n-   **Objectivity**: The language is technical, precise, and free from subjective or ambiguous terminology.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. The solution process will now proceed.\n\n### Derivation and Analysis\n\nThe objective is to find the parameters $\\boldsymbol{\\theta}$ that maximize the likelihood of observing the training data, which consists of energies, forces, and stresses $\\{E_i^{\\mathrm{DFT}}, \\mathbf{F}_i^{\\mathrm{DFT}}, \\boldsymbol{\\sigma}_i^{\\mathrm{DFT}}\\}_{i=1}^{N_s}$.\n\nThe likelihood function $P(\\text{Data}|\\boldsymbol{\\theta})$ under the assumption of independence across structures, and also independence of energy, force, and stress measurements for a given structure, is:\n$$ P(\\text{Data}|\\boldsymbol{\\theta}) = \\prod_{i=1}^{N_s} P(E_i^{\\mathrm{DFT}}|\\boldsymbol{\\theta}) P(\\mathbf{F}_i^{\\mathrm{DFT}}|\\boldsymbol{\\theta}) P(\\boldsymbol{\\sigma}_i^{\\mathrm{DFT}}|\\boldsymbol{\\theta}) $$\n\nGiven the zero-mean Gaussian noise assumption for the residuals, the probability distributions are:\n1.  **Energy**: The residual is $r_{E,i} = E_i^{\\mathrm{DFT}} - E_i^{\\mathrm{ML}}$.\n    $$ P(E_i^{\\mathrm{DFT}}|\\boldsymbol{\\theta}) = \\frac{1}{\\sqrt{2\\pi\\sigma_E^2}} \\exp\\left(-\\frac{(E_i^{\\mathrm{DFT}} - E_i^{\\mathrm{ML}})^2}{2\\sigma_E^2}\\right) $$\n2.  **Forces**: The residuals for the $3N_i$ force components are independent, each with variance $\\sigma_F^2$.\n    $$ P(\\mathbf{F}_i^{\\mathrm{DFT}}|\\boldsymbol{\\theta}) = \\prod_{j=1}^{3N_i} \\frac{1}{\\sqrt{2\\pi\\sigma_F^2}} \\exp\\left(-\\frac{(F_{ij}^{\\mathrm{DFT}} - F_{ij}^{\\mathrm{ML}})^2}{2\\sigma_F^2}\\right) = (2\\pi\\sigma_F^2)^{-3N_i/2} \\exp\\left(-\\frac{\\|\\mathbf{F}_i^{\\mathrm{DFT}} - \\mathbf{F}_i^{\\mathrm{ML}}\\|^2}{2\\sigma_F^2}\\right) $$\n3.  **Stresses**: The residuals for the $N_{\\sigma,c}$ independent components of the stress tensor (typically $N_{\\sigma,c}=6$ for a symmetric tensor) are independent, each with variance $\\sigma_\\sigma^2$.\n    $$ P(\\boldsymbol{\\sigma}_i^{\\mathrm{DFT}}|\\boldsymbol{\\theta}) = (2\\pi\\sigma_\\sigma^2)^{-N_{\\sigma,c}/2} \\exp\\left(-\\frac{\\sum_{k,l \\in \\text{indep.}} (\\sigma_{i,kl}^{\\mathrm{DFT}} - \\sigma_{i,kl}^{\\mathrm{ML}})^2}{2\\sigma_\\sigma^2}\\right) $$\n    For simplicity, we can use the squared Frobenius norm $\\|\\cdot\\|_F^2$ over all $9$ components, which only rescales the effective variance. Let's adhere to the problem's phrasing \"any single stress component\" and sum over all relevant components.\n\nThe total log-likelihood $\\mathcal{L}(\\boldsymbol{\\theta}) = \\ln P(\\text{Data}|\\boldsymbol{\\theta})$ is:\n$$ \\mathcal{L}(\\boldsymbol{\\theta}) = \\sum_{i=1}^{N_s} \\left( \\ln P(E_i^{\\mathrm{DFT}}|\\boldsymbol{\\theta}) + \\ln P(\\mathbf{F}_i^{\\mathrm{DFT}}|\\boldsymbol{\\theta}) + \\ln P(\\boldsymbol{\\sigma}_i^{\\mathrm{DFT}}|\\boldsymbol{\\theta}) \\right) $$\n$$ \\mathcal{L}(\\boldsymbol{\\theta}) = \\text{const} - \\sum_{i=1}^{N_s} \\left( \\frac{(E_i^{\\mathrm{DFT}} - E_i^{\\mathrm{ML}})^2}{2\\sigma_E^2} + \\frac{\\|\\mathbf{F}_i^{\\mathrm{DFT}} - \\mathbf{F}_i^{\\mathrm{ML}}\\|^2}{2\\sigma_F^2} + \\frac{\\|\\boldsymbol{\\sigma}_i^{\\mathrm{DFT}} - \\boldsymbol{\\sigma}_i^{\\mathrm{ML}}\\|_F^2}{2\\sigma_\\sigma^2} \\right) $$\nHere, the Frobenius norm is a convenient notation for the sum of squared component-wise errors.\n\nMaximizing the likelihood is equivalent to minimizing the negative log-likelihood. The objective (loss) function $L(\\boldsymbol{\\theta})$ to be minimized is:\n$$ L(\\boldsymbol{\\theta}) = \\sum_{i=1}^{N_s} \\left( \\frac{1}{2\\sigma_E^2} (E_i^{\\mathrm{DFT}} - E_i^{\\mathrm{ML}})^2 + \\frac{1}{2\\sigma_F^2} \\|\\mathbf{F}_i^{\\mathrm{DFT}} - \\mathbf{F}_i^{\\mathrm{ML}}\\|^2 + \\frac{1}{2\\sigma_\\sigma^2} \\|\\boldsymbol{\\sigma}_i^{\\mathrm{DFT}} - \\boldsymbol{\\sigma}_i^{\\mathrm{ML}}\\|_F^2 \\right) $$\nThis is a weighted sum of the squared errors for energy, force, and stress. If we write this loss in the common form $L(\\boldsymbol{\\theta}) = \\alpha L_E + \\beta L_F + \\gamma L_\\sigma$, where $L_E, L_F, L_\\sigma$ represent the respective sums of squared errors, we find that the coefficients (weights) are $\\alpha = \\frac{1}{2\\sigma_E^2}$, $\\beta = \\frac{1}{2\\sigma_F^2}$, and $\\gamma = \\frac{1}{2\\sigma_\\sigma^2}$.\nThus, the relative weights emerging from the maximum likelihood principle are $\\alpha : \\beta : \\gamma = \\sigma_E^{-2} : \\sigma_F^{-2} : \\sigma_\\sigma^{-2}$.\n\nNow, we analyze the options based on this derivation and general principles.\n\n### Option-by-Option Analysis\n\n**A. Under independent Gaussian observation noise for energy, force components, and stress components, maximizing likelihood is equivalent to minimizing a weighted sum of per-type mean squared errors, with the optimal relative weights proportional to the inverse noise variances, i.e., choosing $\\alpha : \\beta : \\gamma = \\sigma_{E}^{-2} : \\sigma_{F}^{-2} : \\sigma_{\\sigma}^{-2}$ yields a statistically optimal balance across types.**\n\nOur derivation shows that maximizing the likelihood is equivalent to minimizing a loss function $L(\\boldsymbol{\\theta})$ which is a weighted sum of the total squared errors for each data type (energy, force, stress). The weights are indeed proportional to the inverse of the respective variances, $\\sigma_E^{-2}$, $\\sigma_F^{-2}$, and $\\sigma_\\sigma^{-2}$. A weighted sum of total squared errors is equivalent to a weighted sum of mean squared errors (MSEs), as the MSEs are just the total squared errors divided by the number of data points, which are constants with respect to the parameters $\\boldsymbol{\\theta}$. This choice of weights represents the statistically optimal way to combine the information from the different data sources, according to the specified noise model. The statement is a correct summary of the maximum likelihood estimation framework for this problem.\n\n**Verdict: Correct**\n\n**B. If forces and stresses are obtained by exact differentiation of the learned energy, increasing the force weight $\\beta$ only rescales gradients during training and cannot change the location of the empirical risk minimizer; therefore, the final fitted parameters are invariant to the choice of $\\beta$.**\n\nThe location of the empirical risk minimizer, $\\boldsymbol{\\theta}^*$, is found by setting the gradient of the loss function to zero: $\\nabla_{\\boldsymbol{\\theta}} L(\\boldsymbol{\\theta}^*) = 0$.\n$$ \\nabla_{\\boldsymbol{\\theta}} L(\\boldsymbol{\\theta}^*) = \\alpha \\nabla_{\\boldsymbol{\\theta}}L_E(\\boldsymbol{\\theta}^*) + \\beta \\nabla_{\\boldsymbol{\\theta}}L_F(\\boldsymbol{\\theta}^*) + \\gamma \\nabla_{\\boldsymbol{\\theta}}L_\\sigma(\\boldsymbol{\\theta}^*) = 0 $$\nThe statement claims that $\\boldsymbol{\\theta}^*$ is independent of the value of $\\beta$. This would only be true in very specific circumstances, such as if a perfect model exists (i.e., there is a $\\boldsymbol{\\theta}_0$ for which all residuals are zero, so $\\nabla_{\\boldsymbol{\\theta}}L_E = \\nabla_{\\boldsymbol{\\theta}}L_F = \\nabla_{\\boldsymbol{\\theta}}L_\\sigma = 0$ simultaneously), or if the different gradient terms were all collinear. In practice, MLIP models are subject to *model misspecification*—they are not flexible enough to perfectly describe the quantum mechanical potential energy surface. Consequently, the set of parameters that minimizes the energy error, $\\boldsymbol{\\theta}_E^*$, differs from the set that minimizes the force error, $\\boldsymbol{\\theta}_F^*$. The gradients $\\nabla_{\\boldsymbol{\\theta}}L_E$, $\\nabla_{\\boldsymbol{\\theta}}L_F$, and $\\nabla_{\\boldsymbol{\\theta}}L_\\sigma$ will generally point in different directions in the parameter space. The final solution $\\boldsymbol{\\theta}^*$ is a compromise, and its location depends on the relative weighting of these conflicting gradient contributions. Changing $\\beta$ alters this balance and thus changes the location of the minimizer $\\boldsymbol{\\theta}^*$.\n\n**Verdict: Incorrect**\n\n**C. Because forces have $3N_{i}$ components per structure, even when using per-component mean squared error for forces, one must multiply the force weight $\\beta$ by $3N_{i}$ to prevent forces from under-contributing to the objective.**\n\nThis statement misinterprets the scaling of the loss function terms. In a typical training dataset, the number of force components ($ \\sum_{i} 3N_i $) vastly exceeds the number of energy values ($N_s$). If one were to use a loss function based on the sum of squared errors, $L = \\alpha \\sum (E-E^{ML})^2 + \\beta \\sum (F-F^{ML})^2 + \\dots$, and chose naive weights like $\\alpha = \\beta = 1$, the force term would naturally dominate the loss and the gradients simply due to the sheer number of terms in its sum. The concern is typically to prevent forces from *over-contributing*, not under-contributing. When using per-component MSE, the loss function is already normalized by the number of components for each type. For example, $L = w_E \\text{MSE}_E + w_F \\text{MSE}_F + \\dots$. In this case, the factor of $3N_i$ is already incorporated into the definition of $\\text{MSE}_F$. Multiplying the weight $w_F$ by an additional factor of $3N_i$ would massively overweight the force contribution, contrary to the stated goal of preventing under-contribution. The logic is reversed.\n\n**Verdict: Incorrect**\n\n**D. In a Bayesian treatment of the Gaussian Approximation Potential (GAP), taking Gaussian likelihoods with diagonal covariance for energy, force, and stress observations makes the loss-equivalent weights $\\alpha$, $\\beta$, and $\\gamma$ proportional to the inverse observation variances; these can be treated as hyperparameters and selected by maximizing the marginal likelihood (evidence), which typically improves generalization.**\n\nThis statement accurately describes a sophisticated and standard approach within the field, particularly for methods like Gaussian Process regression, of which the Gaussian Approximation Potential (GAP) is a prime example. In a Bayesian framework, the likelihood function is the same as in MLE. Therefore, the connection between loss weights and inverse noise variances ($\\sigma_E^2$, $\\sigma_F^2$, etc.) holds. In a full Bayesian model, these noise variances are not fixed but are hyperparameters that must be determined. A principled method for setting them is to maximize the *marginal likelihood* or *evidence*, $P(\\text{Data}|\\text{hyperparameters})$. This involves integrating out the model parameters $\\boldsymbol{\\theta}$ (or, in a GP context, the latent function values). This procedure, known as Type-II MLE or evidence maximization, automatically balances data fit with model complexity and is a powerful mechanism for preventing overfitting and improving the generalization performance of the model. Every element of this statement is correct.\n\n**Verdict: Correct**\n\n**E. Emphasizing forces by increasing $\\beta$ tends to improve dynamical stability and local curvature learning (e.g., near-equilibrium vibrational modes), but can degrade absolute energy calibration if $\\alpha$ is reduced too far; robust model selection should validate both force and energy metrics, and, where available, derived properties such as elastic constants or phonon dispersions.**\n\nThis statement correctly outlines the practical trade-offs involved in tuning the loss function weights.\n-   Forces are the first derivatives of the potential energy surface ($-\\nabla_{\\mathbf{R}} E$). An accurate representation of forces is critical for stable integration of Newton's equations of motion in MD simulations. It also leads to a better description of the local curvature of the potential energy surface (Hessian matrix), which governs vibrational properties (phonons). Thus, a higher weight on forces ($\\beta$) generally improves dynamical stability and properties derived from local curvature.\n-   However, due to model misspecification, over-prioritizing force-matching can compromise the model's ability to predict absolute or relative energies accurately, which are crucial for thermodynamic properties like formation energies, cohesive energies, or reaction barriers. This is the trade-off.\n-   Given this trade-off, a robust model development and selection workflow must not rely solely on the training loss. It must include validation against a hold-out test set, assessing not only raw energy and force errors but also key physical properties the potential is intended to predict. Properties like elastic constants (related to stress and strain) and phonon dispersions (related to forces and atomic displacements) are excellent, physically meaningful validation targets that test different aspects of the potential energy surface. The statement provides an accurate and insightful summary of best practices in the field.\n\n**Verdict: Correct**", "answer": "$$\\boxed{ADE}$$", "id": "3422810"}]}