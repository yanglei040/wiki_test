{"hands_on_practices": [{"introduction": "Correlated motions in biomolecules manifest across a spectrum of timescales. While slow, large-scale conformational changes are often captured by positional correlations, rapid signal propagation can be mediated by inertial effects visible in velocity correlations. This exercise provides a foundational experience in molecular dynamics by tasking you with building a Langevin dynamics simulator from first principles. By implementing a stable and time-reversible integrator, you will gain a deeper appreciation for how thermal fluctuations and dissipation are modeled, and you will use your simulation to analyze and quantify the nature of correlated motion on fast timescales [@problem_id:3406448].", "problem": "A one-dimensional coarse-grained biomolecular segment can be idealized as a chain of $N$ point masses with nearest-neighbor harmonic couplings. In Molecular Dynamics (MD), one studies correlated motion through position-based correlations and, on fast timescales, through velocity-based correlations to assess inertial coupling. Consider the following physically consistent model governed by Newton’s second law with linear damping and thermal forcing (Langevin dynamics). The chain state is described by positions $x_i(t)$ and velocities $v_i(t)$, for $i \\in \\{1,\\dots,N\\}$. The total potential energy is harmonic with a nearest-neighbor coupling and a weak on-site anchoring to eliminate global drift. The deterministic force is linear, $F(x) = -K x$, where $K$ is a symmetric positive-definite stiffness matrix constructed from the chain Laplacian plus an on-site term. The continuous-time equations of motion are\n$$\nm \\,\\frac{d^2 x}{dt^2} \\;=\\; F(x) \\;-\\; \\gamma \\, \\frac{dx}{dt} \\;+\\; \\sqrt{2 \\gamma \\, k_{\\mathrm{B}} T} \\,\\eta(t),\n$$\nwith $m$ the mass (assumed identical for all sites), $\\gamma$ the friction coefficient per degree of freedom, $k_{\\mathrm{B}}$ the Boltzmann constant, $T$ the absolute temperature, and $\\eta(t)$ a vector of independent standard Gaussian white noises. Use reduced units with $k_{\\mathrm{B}} T$ expressed in the same energy units as the potential, and take $k_{\\mathrm{B}}=1$ so that $T$ numerically equals thermal energy. Assume the mass matrix is $m I$ and that the friction is isotropic (scalar $\\gamma$). You must simulate this system in discrete time from first principles without relying on any black-box MD library.\n\nYour tasks are:\n- Starting only from Newton’s second law, linear forces from the harmonic potential, and the fluctuation-dissipation relation, derive a stable, time-reversible splitting integrator for the Langevin dynamics that exactly treats the Ornstein–Uhlenbeck velocity substep and uses symmetric half-steps for drift and force application.\n- Implement the simulator and generate trajectories $x_i(t_n)$ and $v_i(t_n)$ sampled on a uniform time grid $t_n = n \\,\\Delta t$, with integer $n \\ge 0$ and time step $\\Delta t$.\n- From the sampled trajectories, compute the Pearson correlation matrices across sites, separately for positions and velocities, using the time samples as observations. Denote by $C$ the position-based correlation matrix with entries $C_{ij}$ and by $C^{v}$ the velocity-based correlation matrix with entries $C^{v}_{ij}$.\n- Define the inertial coupling index as the difference between the average absolute nearest-neighbor velocity correlation and the average absolute nearest-neighbor position correlation:\n$$\n\\mathcal{I} \\;=\\; \\frac{1}{N-1} \\sum_{i=1}^{N-1} \\left( \\left| C^{v}_{i,i+1} \\right| \\;-\\; \\left| C_{i,i+1} \\right| \\right).\n$$\nThis index is dimensionless. Positive $\\mathcal{I}$ indicates that, on average, nearest-neighbor velocity correlations exceed position correlations, consistent with inertial coupling dominating at fast timescales; negative $\\mathcal{I}$ indicates the opposite.\n\nConstruct the stiffness matrix $K$ for a linear chain with nearest-neighbor coupling constant $k$ and on-site anchor $k_{\\mathrm{a}}$ as\n$$\nK \\;=\\; k \\, L \\;+\\; k_{\\mathrm{a}} \\, I,\n$$\nwhere $L$ is the $N \\times N$ Laplacian matrix of the path graph: $(L)_{ii} = 2$ for $i \\in \\{2,\\dots,N-1\\}$, $(L)_{11}=(L)_{NN}=1$, and $(L)_{i,i+1}=(L)_{i+1,i}=-1$ for all nearest neighbors. Use the initial condition $x(0)=0$ and $v(0)=0$ except when an impulse is specified; if an impulse amplitude $v_0$ is given, set $v_{\\lfloor N/2 \\rfloor}(0) \\leftarrow v_{\\lfloor N/2 \\rfloor}(0) + v_0$. To ensure reproducibility, the random number generator must be initialized with seed $s=12345$.\n\nTest suite. Run exactly the following three test cases, each specified as a tuple $(N, m, k, k_{\\mathrm{a}}, \\gamma, T, \\Delta t, \\text{steps}, \\text{warmup}, v_0)$, where $\\text{steps}$ is the total number of integration steps, $\\text{warmup}$ is the number of initial steps to discard before collecting data for correlations, and $v_0$ is the impulse amplitude:\n- Case $1$ (underdamped transient with no thermal noise): $(N, m, k, k_{\\mathrm{a}}, \\gamma, T, \\Delta t, \\text{steps}, \\text{warmup}, v_0) = (6, 1, 100, 1, 0.1, 0, 0.001, 20000, 0, 8)$.\n- Case $2$ (strongly damped thermal equilibrium): $(N, m, k, k_{\\mathrm{a}}, \\gamma, T, \\Delta t, \\text{steps}, \\text{warmup}, v_0) = (6, 1, 100, 1, 5, 1, 0.001, 80000, 20000, 0)$.\n- Case $3$ (intermediate damping thermal equilibrium): $(N, m, k, k_{\\mathrm{a}}, \\gamma, T, \\Delta t, \\text{steps}, \\text{warmup}, v_0) = (6, 1, 100, 1, 1, 1, 0.001, 80000, 20000, 0)$.\n\nAll outputs are dimensionless. Your program should produce a single line of output containing the three values of $\\mathcal{I}$ for the cases above, in order, as a comma-separated list enclosed in square brackets (for example, $[\\mathcal{I}_1,\\mathcal{I}_2,\\mathcal{I}_3]$). No other text should be printed.", "solution": "The problem is valid as it presents a well-posed, scientifically grounded task in computational statistical physics. It is self-contained, with all necessary parameters, initial conditions, and definitions provided for a unique and verifiable numerical solution. The model, Langevin dynamics for a harmonic chain, is a standard and fundamental system in molecular dynamics. The validation checklist reveals no flaws.\n\nThe core of the problem is to simulate the Langevin dynamics of a one-dimensional chain of masses. The equation of motion for the positions $x(t) \\in \\mathbb{R}^N$ is a second-order stochastic differential equation:\n$$\nm \\frac{d^2 x}{dt^2} = F(x) - \\gamma \\frac{dx}{dt} + \\sqrt{2 \\gamma T} \\eta(t)\n$$\nHere, we have used the specified reduced units where the Boltzmann constant $k_{\\mathrm{B}}=1$. The variables are the mass $m$ (a scalar, as the mass matrix is $mI$), the friction coefficient $\\gamma$, the temperature $T$, and a vector of independent standard Gaussian white noises $\\eta(t)$. The deterministic force is linear, $F(x) = -Kx$, derived from a harmonic potential, where $K$ is the stiffness matrix.\n\nTo solve this numerically, we require a stable, time-reversible integrator. The problem asks for a splitting method that treats the Ornstein-Uhlenbeck (OU) part of the velocity dynamics exactly and uses symmetric half-steps for position and force updates. The BAOAB integrator perfectly matches these requirements.\n\nThe dynamics can be formally described by a Liouville operator $\\mathcal{L}$, which can be split into three components:\n1.  **Drift (A):** The evolution of positions due to velocities, $\\dot{x} = v$. The associated operator is $\\mathcal{L}_A = v \\cdot \\nabla_x$.\n2.  **Kick (B):** The evolution of velocities due to deterministic forces, $\\dot{v} = F(x)/m$. The associated operator is $\\mathcal{L}_B = (F(x)/m) \\cdot \\nabla_v$.\n3.  **OU Process (O):** The evolution of velocities due to friction and thermal noise, $\\dot{v} = -(\\gamma/m)v + \\sqrt{2 \\gamma T}/m \\, \\eta(t)$. The associated operator is $\\mathcal{L}_O$.\n\nThe BAOAB method is a symmetric Strang splitting of the form $e^{\\mathcal{L} \\Delta t} \\approx e^{\\frac{\\Delta t}{2}\\mathcal{L}_B} e^{\\frac{\\Delta t}{2}\\mathcal{L}_A} e^{\\Delta t\\mathcal{L}_O} e^{\\frac{\\Delta t}{2}\\mathcal{L}_A} e^{\\frac{\\Delta t}{2}\\mathcal{L}_B}$. This sequence of operations defines the algorithm for a single time step $\\Delta t$.\n\nLet's derive the exact propagators for each sub-step:\n- **Propagator $e^{\\tau \\mathcal{L}_A}$ (Drift):** For a time interval $\\tau$, this step updates positions assuming constant velocity: $x \\rightarrow x + v\\tau$.\n- **Propagator $e^{\\tau \\mathcal{L}_B}$ (Kick):** For a time interval $\\tau$, this step updates velocities assuming constant force: $v \\rightarrow v + (F(x)/m)\\tau$.\n- **Propagator $e^{\\tau \\mathcal{L}_O}$ (OU Process):** This step involves solving the linear stochastic differential equation for the velocity $v$ while keeping position $x$ fixed:\n$$\nd v = - \\frac{\\gamma}{m} v dt + \\frac{\\sqrt{2 \\gamma T}}{m} dW_t\n$$\nwhere $dW_t = \\eta(t)dt$ is a vector of Wiener processes. The exact solution for each component of the velocity vector over a time interval $\\tau$ is:\n$$\nv_i(\\tau) = v_i(0) e^{-(\\gamma/m)\\tau} + R_i\n$$\nwhere $R_i$ is a Gaussian random number with mean $\\mathbb{E}[R_i] = 0$ and variance:\n$$\n\\text{Var}(R_i) = \\frac{2\\gamma T}{m^2} \\int_0^\\tau e^{-2(\\gamma/m)(\\tau-s)} ds = \\frac{T}{m} \\left( 1 - e^{-2(\\gamma/m)\\tau} \\right)\n$$\nThus, the velocity update for the O-step over a full time step $\\Delta t$ can be written as:\n$$\nv \\rightarrow c_1 v + c_2 \\mathcal{N}(0, I)\n$$\nwhere $\\mathcal{N}(0, I)$ is a vector of independent standard normal random variables, and the constants are:\n$$\nc_1 = e^{-(\\gamma/m)\\Delta t} \\quad \\text{and} \\quad c_2 = \\sqrt{\\frac{T}{m}(1 - c_1^2)}\n$$\n\nCombining these propagators according to the BAOAB splitting gives the following algorithm for one integration step from time $t_n$ to $t_{n+1} = t_n + \\Delta t$, starting with state $(x_n, v_n)$:\n1.  **B-step (half kick):** Compute the force $F_n = -Kx_n$. Update the velocity:\n    $$v_{n+1/2}^{(1)} = v_n + \\frac{\\Delta t}{2m} F_n$$\n2.  **A-step (half drift):** Update the position using the new velocity:\n    $$x_{n+1/2} = x_n + \\frac{\\Delta t}{2} v_{n+1/2}^{(1)}$$\n3.  **O-step (full OU):** Update the velocity with friction and noise:\n    $$v_{n+1/2}^{(2)} = c_1 v_{n+1/2}^{(1)} + c_2 \\mathcal{N}_n$$\n    where $\\mathcal{N}_n$ is a fresh vector of standard normal randoms.\n4.  **A-step (half drift):** Update the position again with the post-OU velocity:\n    $$x_{n+1} = x_{n+1/2} + \\frac{\\Delta t}{2} v_{n+1/2}^{(2)}$$\n5.  **B-step (half kick):** Compute the force at the new position, $F_{n+1} = -Kx_{n+1}$, and complete the velocity update:\n    $$v_{n+1} = v_{n+1/2}^{(2)} + \\frac{\\Delta t}{2m} F_{n+1}$$\n\nThis algorithm is implemented to generate trajectories of positions $x(t_n)$ and velocities $v(t_n)$. After discarding an initial `warmup` period, the collected trajectories are used to compute the required correlation matrices.\n\nThe stiffness matrix $K$ is constructed as $K = k L + k_{\\mathrm{a}} I$, where $I$ is the identity matrix, and $L$ is the Laplacian for a 1D chain (path graph):\n$$\n(L)_{ij} = \\begin{cases} 1 & \\text{if } i=j \\text{ and } i \\in \\{1,N\\} \\\\ 2 & \\text{if } i=j \\text{ and } i \\in \\{2,\\dots,N-1\\} \\\\ -1 & \\text{if } |i-j|=1 \\\\ 0 & \\text{otherwise} \\end{cases}\n$$\nFrom the trajectories of positions $\\{x_i(t_n)\\}$ and velocities $\\{v_i(t_n)\\}$, stored as data matrices $X$ and $V$ where columns represent sites and rows represent time samples, the Pearson correlation matrices for positions ($C$) and velocities ($C^v$) are computed. The entry $C_{ij}$ is the correlation between the time series of site $i$ and site $j$.\n\nFinally, the inertial coupling index $\\mathcal{I}$ is calculated as the mean difference between the absolute nearest-neighbor correlations of velocity and position:\n$$\n\\mathcal{I} = \\frac{1}{N-1} \\sum_{i=1}^{N-1} \\left( | C^v_{i,i+1} | - | C_{i,i+1} | \\right)\n$$\nThis protocol is applied to each of the three test cases specified. The random number generator is seeded to ensure reproducibility.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef calculate_inertial_index(N, m, k, k_a, gamma, T, dt, steps, warmup, v0, rng):\n    \"\"\"\n    Simulates a 1D harmonic chain with Langevin dynamics and computes the inertial coupling index.\n    \"\"\"\n    \n    # 1. Build the stiffness matrix K\n    L = np.zeros((N, N))\n    if N > 1:\n        np.fill_diagonal(L, 2)\n        L[0, 0] = 1\n        L[N-1, N-1] = 1\n        np.fill_diagonal(L[1:], -1)\n        np.fill_diagonal(L[:, 1:], -1)\n    elif N == 1:\n        L[0,0] = 0 # No neighbors\n        \n    K = k * L + k_a * np.identity(N)\n    \n    # 2. Initialization\n    x = np.zeros(N)\n    v = np.zeros(N)\n    \n    if v0 != 0 and N > 0:\n        center_idx = N // 2\n        v[center_idx] += v0\n        \n    # 3. Integrator constants for BAOAB\n    c1 = np.exp(-gamma * dt / m)\n    if T > 0:\n        # k_B is 1\n        c2 = np.sqrt(T * (1 - c1**2) / m)\n    else:\n        c2 = 0.0\n\n    # 4. Simulation Loop\n    x_traj = []\n    v_traj = []\n    \n    for step in range(steps):\n        # B-step (half kick)\n        F = -K @ x\n        v_half = v + (dt / (2.0 * m)) * F\n        \n        # A-step (half drift)\n        x_half = x + (dt / 2.0) * v_half\n        \n        # O-step (full)\n        if c2 > 0:\n            R = rng.standard_normal(N)\n            v_prime_half = c1 * v_half + c2 * R\n        else:\n            v_prime_half = c1 * v_half\n\n        # A-step (half drift)\n        x_new = x_half + (dt / 2.0) * v_prime_half\n        \n        # B-step (half kick)\n        F_new = -K @ x_new\n        v_new = v_prime_half + (dt / (2.0 * m)) * F_new\n        \n        # Update state\n        x, v = x_new, v_new\n        \n        # Store trajectories after warmup\n        if step >= warmup:\n            x_traj.append(x)\n            v_traj.append(v)\n            \n    # 5. Post-processing and Analysis\n    if not x_traj or N <= 1:\n        return 0.0\n\n    X_data = np.array(x_traj)\n    V_data = np.array(v_traj)\n    \n    # Handle potential constant trajectories by checking std dev\n    # This avoids RuntimeWarning from np.corrcoef\n    if np.any(np.std(X_data, axis=0) < 1e-12) or np.any(np.std(V_data, axis=0) < 1e-12):\n        # Center data manually\n        X_data_centered = X_data - np.mean(X_data, axis=0)\n        V_data_centered = V_data - np.mean(V_data, axis=0)\n        # Compute covariance matrices\n        cov_pos = X_data_centered.T @ X_data_centered / X_data_centered.shape[0]\n        cov_vel = V_data_centered.T @ V_data_centered / V_data_centered.shape[0]\n        # Compute standard deviations, adding epsilon to avoid division by zero\n        std_pos = np.sqrt(np.diag(cov_pos)) + 1e-12\n        std_vel = np.sqrt(np.diag(cov_vel)) + 1e-12\n        # Compute correlation matrices\n        C_pos = cov_pos / np.outer(std_pos, std_pos)\n        C_vel = cov_vel / np.outer(std_vel, std_vel)\n    else:\n        C_pos = np.corrcoef(X_data, rowvar=False)\n        C_vel = np.corrcoef(V_data, rowvar=False)\n\n    abs_nn_corr_pos = np.abs(np.diag(C_pos, k=1))\n    abs_nn_corr_vel = np.abs(np.diag(C_vel, k=1))\n    \n    inertial_index = np.mean(abs_nn_corr_vel - abs_nn_corr_pos)\n    \n    return inertial_index\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, m, k, k_a, gamma, T, dt, steps, warmup, v0)\n        (6, 1, 100, 1, 0.1, 0, 0.001, 20000, 0, 8),\n        (6, 1, 100, 1, 5, 1, 0.001, 80000, 20000, 0),\n        (6, 1, 100, 1, 1, 1, 0.001, 80000, 20000, 0),\n    ]\n\n    results = []\n    # Initialize a single random number generator for reproducibility\n    rng = np.random.default_rng(seed=12345)\n\n    for case in test_cases:\n        N, m, k, k_a, gamma, T, dt, steps, warmup, v0 = case\n        result = calculate_inertial_index(N, m, k, k_a, gamma, T, dt, steps, warmup, v0, rng)\n        # Format result to a reasonable number of decimal places for consistency\n        results.append(f\"{result:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3406448"}, {"introduction": "A critical question in every molecular dynamics study is: \"How long is long enough?\" The statistical reliability of any computed average, including the elements of a covariance matrix, depends directly on the length of the simulation relative to the system's characteristic relaxation times. This practice delves into the statistical mechanics of time-series analysis to answer this question quantitatively. You will derive and apply formulas to calculate the minimum trajectory length needed to estimate a covariance with a desired level of precision, a crucial skill for designing efficient and statistically robust computational experiments [@problem_id:3406452].", "problem": "Consider a stationary molecular dynamics time series of the scalar observable defined by $Y(t) = \\left(X_i(t) - \\mu_i\\right)\\left(X_j(t) - \\mu_j\\right)$, where $X_i(t)$ and $X_j(t)$ are Cartesian coordinate components of two atoms (or sites) in a biomolecule, and $\\mu_i$ and $\\mu_j$ are their stationary means. The quantity of interest is the covariance $C_{ij} = \\mathbb{E}[Y(t)] = \\mathrm{Cov}(X_i,X_j)$. Assume the process is ergodic and mixing so that time averages converge to ensemble averages as the total trajectory duration $T$ grows, and that fluctuations of $\\left(X_i,X_j\\right)$ are jointly Gaussian with zero mean (after centering), and finite variance. Assume further that $Y(t)$ has a normalized autocorrelation function $\\rho_Y(\\tau)$ with $\\rho_Y(0)=1$.\n\nYou estimate $C_{ij}$ from a trajectory of total length $T$ by the time average $\\widehat{C}_{ij} = \\frac{1}{T}\\int_0^T Y(t)\\,dt$. For long $T$, the Central Limit Theorem for stationary mixing processes states that the distribution of $\\widehat{C}_{ij}$ is approximately normal with variance that decays with $T$. Define the integrated autocorrelation time as $\\tau_{\\mathrm{int}} = \\int_0^{\\infty} \\rho_Y(\\tau)\\,d\\tau$. Let $\\sigma_Y^2 = \\mathrm{Var}\\left(Y(t)\\right)$ denote the marginal variance of $Y(t)$. It is a well-tested fact in time-series analysis of molecular dynamics that, for large $T$, the variance of $\\widehat{C}_{ij}$ obeys $\\mathrm{Var}\\left(\\widehat{C}_{ij}\\right) \\approx \\frac{2\\,\\sigma_Y^2\\,\\tau_{\\mathrm{int}}}{T}$. The effective sample size is thus $N_{\\mathrm{eff}} \\approx \\frac{T}{2\\tau_{\\mathrm{int}}}$, and the variance reduces by a factor of $N_{\\mathrm{eff}}$ compared to independent sampling. Adopt a two-sided confidence interval with Gaussian quantile $z$ such that the half-width is $z\\sqrt{\\mathrm{Var}\\left(\\widehat{C}_{ij}\\right)}$.\n\nAssume joint Gaussianity of $\\left(X_i,X_j\\right)$ so that the fourth-order moment identity (Isserlis’ theorem) implies $E\\!\\left[X_i^2 X_j^2\\right] = \\sigma_i^2 \\sigma_j^2 + 2 C_{ij}^2$, where $\\sigma_i^2 = \\mathrm{Var}(X_i)$ and $\\sigma_j^2 = \\mathrm{Var}(X_j)$. Consequently, $\\sigma_Y^2 = \\sigma_i^2 \\sigma_j^2 + C_{ij}^2$. Let $\\rho_{ij}$ denote the Pearson correlation coefficient between $X_i$ and $X_j$, so that $C_{ij} = \\rho_{ij}\\,\\sigma_i\\,\\sigma_j$.\n\nYour task: Write a complete, runnable program that, for each specified test case, computes the minimal trajectory length $T_{\\min}$ (in nanoseconds) needed to ensure that the relative two-sided confidence half-width of $\\widehat{C}_{ij}$ does not exceed a prescribed tolerance $\\varepsilon$, that is, $z\\,\\sqrt{\\mathrm{Var}\\left(\\widehat{C}_{ij}\\right)}/\\lvert C_{ij}\\rvert \\le \\varepsilon$. Use the large-$T$ asymptotic and the above definitions. Use the following models for $\\rho_Y(\\tau)$ and compute $\\tau_{\\mathrm{int}}$ by evaluating the corresponding integrals:\n- Exponential model: $\\rho_Y(\\tau) = \\exp\\!\\left(-\\tau/\\tau_c\\right)$, with $\\tau_{\\mathrm{int}} = \\int_0^{\\infty} e^{-\\tau/\\tau_c} d\\tau$.\n- Bi-exponential model: $\\rho_Y(\\tau) = a\\,\\exp\\!\\left(-\\tau/\\tau_1\\right) + (1-a)\\,\\exp\\!\\left(-\\tau/\\tau_2\\right)$, with $a \\in (0,1)$, and $\\tau_{\\mathrm{int}} = \\int_0^{\\infty} \\left[a\\,e^{-\\tau/\\tau_1} + (1-a)\\,e^{-\\tau/\\tau_2}\\right] d\\tau$.\n- Power-law model (integrable long tail): $\\rho_Y(\\tau) = \\left(1 + \\tau/\\tau_0\\right)^{-\\alpha}$ with $\\alpha > 1$, and $\\tau_{\\mathrm{int}} = \\int_0^{\\infty} \\left(1+\\tau/\\tau_0\\right)^{-\\alpha} d\\tau$.\n\nPhysical units and reporting:\n- All times must be in nanoseconds.\n- All lengths must be in nanometers.\n- The confidence level is two-sided with $z = 1.96$ (corresponding approximately to $95$ percent).\n- Report each $T_{\\min}$ in nanoseconds, rounded to three decimal places.\n\nTest suite:\n- Case $1$ (happy path, single exponential): $\\tau_c = 5$ ns, $\\sigma_i = 0.3$ nm, $\\sigma_j = 0.3$ nm, $\\rho_{ij} = 0.5$, $\\varepsilon = 0.1$, $z = 1.96$.\n- Case $2$ (bi-exponential, strong slow mode): $a = 0.7$, $\\tau_1 = 20$ ns, $\\tau_2 = 1$ ns, $\\sigma_i = 0.2$ nm, $\\sigma_j = 0.4$ nm, $\\rho_{ij} = 0.3$, $\\varepsilon = 0.1$, $z = 1.96$.\n- Case $3$ (weak covariance, single exponential): $\\tau_c = 2$ ns, $\\sigma_i = 0.25$ nm, $\\sigma_j = 0.25$ nm, $\\rho_{ij} = 0.05$, $\\varepsilon = 0.1$, $z = 1.96$.\n- Case $4$ (integrable heavy tail): $\\tau_0 = 1$ ns, $\\alpha = 1.1$, $\\sigma_i = 0.15$ nm, $\\sigma_j = 0.35$ nm, $\\rho_{ij} = 0.2$, $\\varepsilon = 0.2$, $z = 1.96$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the four cases, with each $T_{\\min}$ rounded to three decimal places in nanoseconds. For example, the printed line must have the form [$t_1$,$t_2$,$t_3$,$t_4$] where each $t_k$ is a float rounded to three decimal places representing nanoseconds.", "solution": "The problem statement has been rigorously validated and is determined to be scientifically grounded, well-posed, and internally consistent. All provided parameters, definitions, and assumptions are standard within the field of statistical mechanics and the analysis of molecular dynamics simulations. The problem is solvable as stated.\n\nThe primary objective is to determine the minimum simulation time, $T_{\\min}$, required to estimate the covariance $C_{ij}$ between two atomic coordinates, $X_i$ and $X_j$, such that the relative half-width of the two-sided confidence interval for the estimator $\\widehat{C}_{ij}$ is no greater than a specified tolerance $\\varepsilon$.\n\nThe condition on the relative confidence half-width is given by:\n$$ \\frac{z\\sqrt{\\mathrm{Var}\\left(\\widehat{C}_{ij}\\right)}}{\\lvert C_{ij}\\rvert} \\le \\varepsilon $$\nwhere $z$ is the Gaussian quantile for the desired confidence level. To find the minimum time $T_{\\min}$, we solve this expression at the boundary of the inequality, where the left side equals $\\varepsilon$.\n\nThe problem states that for a long trajectory of duration $T$, the variance of the time-averaged estimator $\\widehat{C}_{ij}$ is given by the asymptotic formula:\n$$ \\mathrm{Var}\\left(\\widehat{C}_{ij}\\right) \\approx \\frac{2\\,\\sigma_Y^2\\,\\tau_{\\mathrm{int}}}{T} $$\nHere, $\\sigma_Y^2 = \\mathrm{Var}\\left(Y(t)\\right)$ is the variance of the observable $Y(t) = (X_i(t)-\\mu_i)(X_j(t)-\\mu_j)$, and $\\tau_{\\mathrm{int}} = \\int_0^{\\infty} \\rho_Y(\\tau)\\,d\\tau$ is its integrated autocorrelation time.\n\nSubstituting the variance expression into the condition gives:\n$$ \\frac{z\\sqrt{\\frac{2\\,\\sigma_Y^2\\,\\tau_{\\mathrm{int}}}{T}}}{\\lvert C_{ij}\\rvert} = \\varepsilon $$\nSolving for $T$ yields the minimum required time, $T_{\\min}$:\n$$ \\frac{z^2}{C_{ij}^2} \\left( \\frac{2\\,\\sigma_Y^2\\,\\tau_{\\mathrm{int}}}{T_{\\min}} \\right) = \\varepsilon^2 $$\n$$ T_{\\min} = \\frac{2\\,z^2\\,\\sigma_Y^2\\,\\tau_{\\mathrm{int}}}{\\varepsilon^2\\,C_{ij}^2} $$\nThe problem provides the relationship between $\\sigma_Y^2$, the variances of the coordinates $\\sigma_i^2$ and $\\sigma_j^2$, and the covariance $C_{ij}$, derived from Isserlis' theorem for jointly Gaussian variables:\n$$ \\sigma_Y^2 = \\sigma_i^2 \\sigma_j^2 + C_{ij}^2 $$\nThe covariance $C_{ij}$ is also related to the Pearson correlation coefficient $\\rho_{ij}$ via $C_{ij} = \\rho_{ij}\\sigma_i\\sigma_j$. We can use these relations to simplify the expression for $T_{\\min}$. The ratio $\\sigma_Y^2 / C_{ij}^2$ can be expressed as:\n$$ \\frac{\\sigma_Y^2}{C_{ij}^2} = \\frac{\\sigma_i^2 \\sigma_j^2 + C_{ij}^2}{C_{ij}^2} = \\frac{\\sigma_i^2 \\sigma_j^2}{(\\rho_{ij}\\sigma_i\\sigma_j)^2} + 1 = \\frac{\\sigma_i^2 \\sigma_j^2}{\\rho_{ij}^2\\sigma_i^2\\sigma_j^2} + 1 = \\frac{1}{\\rho_{ij}^2} + 1 $$\nSubstituting this simplified ratio back into the equation for $T_{\\min}$, we obtain a more direct formula that depends on $\\rho_{ij}$ but not explicitly on $\\sigma_i$ or $\\sigma_j$:\n$$ T_{\\min} = \\frac{2\\,z^2\\,\\tau_{\\mathrm{int}}}{\\varepsilon^2} \\left( \\frac{1}{\\rho_{ij}^2} + 1 \\right) $$\nThis is the central equation for our calculations. The next step is to find the expression for the integrated autocorrelation time $\\tau_{\\mathrm{int}}$ for each of the three models of the normalized autocorrelation function $\\rho_Y(\\tau)$.\n\n1.  **Exponential model**: $\\rho_Y(\\tau) = \\exp(-\\tau/\\tau_c)$\n    $$ \\tau_{\\mathrm{int}} = \\int_0^{\\infty} \\exp(-\\tau/\\tau_c) \\,d\\tau = \\left[-\\tau_c \\exp(-\\tau/\\tau_c)\\right]_0^{\\infty} = 0 - (-\\tau_c e^0) = \\tau_c $$\n\n2.  **Bi-exponential model**: $\\rho_Y(\\tau) = a\\,\\exp(-\\tau/\\tau_1) + (1-a)\\exp(-\\tau/\\tau_2)$\n    $$ \\tau_{\\mathrm{int}} = \\int_0^{\\infty} \\left[a\\,\\exp(-\\tau/\\tau_1) + (1-a)\\exp(-\\tau/\\tau_2)\\right] \\,d\\tau = a\\tau_1 + (1-a)\\tau_2 $$\n\n3.  **Power-law model**: $\\rho_Y(\\tau) = (1 + \\tau/\\tau_0)^{-\\alpha}$ for $\\alpha > 1$\n    $$ \\tau_{\\mathrm{int}} = \\int_0^{\\infty} (1 + \\tau/\\tau_0)^{-\\alpha} \\,d\\tau = \\tau_0 \\int_1^{\\infty} u^{-\\alpha} \\,du = \\tau_0 \\left[\\frac{u^{1-\\alpha}}{1-\\alpha}\\right]_1^{\\infty} = \\frac{\\tau_0}{\\alpha - 1} $$\n    The integral converges because $\\alpha > 1$, which makes the exponent $1-\\alpha$ negative.\n\nWith these formulas, we can now evaluate each test case.\n\n**Case 1**: Exponential model\n- Parameters: $\\tau_c = 5$ ns, $\\rho_{ij} = 0.5$, $\\varepsilon = 0.1$, $z = 1.96$.\n- $\\tau_{\\mathrm{int}} = \\tau_c = 5$ ns.\n- $T_{\\min} = \\frac{2 \\times (1.96)^2 \\times 5}{(0.1)^2} \\left( \\frac{1}{(0.5)^2} + 1 \\right) = \\frac{38.416}{0.01} (4 + 1) = 3841.6 \\times 5 = 19208.0$ ns.\n\n**Case 2**: Bi-exponential model\n- Parameters: $a = 0.7$, $\\tau_1 = 20$ ns, $\\tau_2 = 1$ ns, $\\rho_{ij} = 0.3$, $\\varepsilon = 0.1$, $z = 1.96$.\n- $\\tau_{\\mathrm{int}} = 0.7 \\times 20 + (1 - 0.7) \\times 1 = 14 + 0.3 = 14.3$ ns.\n- $T_{\\min} = \\frac{2 \\times (1.96)^2 \\times 14.3}{(0.1)^2} \\left( \\frac{1}{(0.3)^2} + 1 \\right) = \\frac{109.86736}{0.01} \\left( \\frac{1}{0.09} + 1 \\right) = 10986.736 \\times \\frac{1.09}{0.09} \\approx 133061.580$ ns.\n\n**Case 3**: Exponential model (weak covariance)\n- Parameters: $\\tau_c = 2$ ns, $\\rho_{ij} = 0.05$, $\\varepsilon = 0.1$, $z = 1.96$.\n- $\\tau_{\\mathrm{int}} = \\tau_c = 2$ ns.\n- The small value of $\\rho_{ij}$ will drastically increase the required simulation time.\n- $T_{\\min} = \\frac{2 \\times (1.96)^2 \\times 2}{(0.1)^2} \\left( \\frac{1}{(0.05)^2} + 1 \\right) = \\frac{15.3664}{0.01} (400 + 1) = 1536.64 \\times 401 = 616192.64$ ns.\n\n**Case 4**: Power-law model (integrable heavy tail)\n- Parameters: $\\tau_0 = 1$ ns, $\\alpha = 1.1$, $\\rho_{ij} = 0.2$, $\\varepsilon = 0.2$, $z = 1.96$.\n- The value of $\\alpha$ close to $1$ indicates a slowly decaying correlation, leading to a large $\\tau_{\\mathrm{int}}$.\n- $\\tau_{\\mathrm{int}} = \\frac{\\tau_0}{\\alpha - 1} = \\frac{1}{1.1 - 1} = \\frac{1}{0.1} = 10$ ns.\n- $T_{\\min} = \\frac{2 \\times (1.96)^2 \\times 10}{(0.2)^2} \\left( \\frac{1}{(0.2)^2} + 1 \\right) = \\frac{76.832}{0.04} (25 + 1) = 1920.8 \\times 26 = 49940.8$ ns.\n\nThese calculations yield the minimum simulation times required for each case, which will be implemented in the provided program.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy is not needed for this problem.\n\ndef solve():\n    \"\"\"\n    Calculates the minimum trajectory length T_min required to estimate\n    the covariance C_ij with a specified relative precision.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # The parameters sigma_i and sigma_j are not needed for the simplified\n    # final formula but are kept here for completeness relative to the problem statement.\n    test_cases = [\n        {'model': 'exponential', 'params': {'tau_c': 5.0}, 'rho_ij': 0.5, 'epsilon': 0.1, 'z': 1.96},\n        {'model': 'bi_exponential', 'params': {'a': 0.7, 'tau_1': 20.0, 'tau_2': 1.0}, 'rho_ij': 0.3, 'epsilon': 0.1, 'z': 1.96},\n        {'model': 'exponential', 'params': {'tau_c': 2.0}, 'rho_ij': 0.05, 'epsilon': 0.1, 'z': 1.96},\n        {'model': 'power_law', 'params': {'tau_0': 1.0, 'alpha': 1.1}, 'rho_ij': 0.2, 'epsilon': 0.2, 'z': 1.96},\n    ]\n\n    results = []\n    for case in test_cases:\n        model = case['model']\n        params = case['params']\n        rho_ij = case['rho_ij']\n        epsilon = case['epsilon']\n        z = case['z']\n\n        tau_int = 0.0\n        if model == 'exponential':\n            # For the exponential model, tau_int = tau_c\n            tau_int = params['tau_c']\n        elif model == 'bi_exponential':\n            # For the bi-exponential model, tau_int = a*tau_1 + (1-a)*tau_2\n            tau_int = params['a'] * params['tau_1'] + (1.0 - params['a']) * params['tau_2']\n        elif model == 'power_law':\n            # For the power-law model, tau_int = tau_0 / (alpha - 1)\n            tau_int = params['tau_0'] / (params['alpha'] - 1.0)\n\n        # The simplified analytical formula for the minimum trajectory length is:\n        # T_min = (2 * z^2 * tau_int / epsilon^2) * (1/rho_ij^2 + 1)\n        # This formula is derived in the solution text by combining the expressions for\n        # Var(C_ij_hat), sigma_Y^2, and C_ij.\n        \n        term_prefactor = (2.0 * z**2 * tau_int) / (epsilon**2)\n        term_correlation = (1.0 / rho_ij**2) + 1.0\n        T_min = term_prefactor * term_correlation\n\n        # Append the result rounded to three decimal places.\n        results.append(f\"{T_min:.3f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3406452"}, {"introduction": "Enhanced sampling techniques such as Umbrella Sampling and Metadynamics are indispensable for overcoming the timescale limitations of conventional MD. However, these powerful methods are not without trade-offs; the biasing potential used to accelerate sampling along a specific collective variable can distort the natural dynamics and correlations in other, unbiased degrees of freedom. This advanced exercise challenges you to analytically and numerically quantify these distortions within a solvable model system. This practice is essential for developing a critical understanding of your computational tools, enabling you to distinguish genuine allosteric coupling from simulation artifacts [@problem_id:3406465].", "problem": "Consider an overdamped Molecular Dynamics (MD) system with three configurational degrees of freedom, a designated collective variable (CV) $x$ and two orthogonal coordinates $y$ and $z$. Assume the stationary distribution of positions is given by the Boltzmann form with inverse thermal energy $\\beta = 1$ in dimensionless units, and the native potential energy is harmonic with bilinear couplings,\n$$\nU(x,y,z) = \\frac{1}{2} k_x x^2 + \\frac{1}{2} k_y y^2 + \\frac{1}{2} k_z z^2 + k_{yz} y z + k_{xy} x y + k_{xz} x z,\n$$\nwith a positive definite Hessian. Define the native covariance matrix in the orthogonal subspace as\n$$\n\\Sigma^{\\text{native}} = \\begin{pmatrix}\n\\mathrm{Cov}(y,y) & \\mathrm{Cov}(y,z) \\\\\n\\mathrm{Cov}(z,y) & \\mathrm{Cov}(z,z)\n\\end{pmatrix}.\n$$\nTwo biasing schemes are applied along the CV $x$:\n1. Umbrella sampling with a harmonic bias,\n$$\nV_{\\mathrm{umb}}(x) = \\frac{1}{2} k_{\\mathrm{umb}} (x - x_0)^2,\n$$\n2. Metadynamics with a static limit bias represented as a sum of Gaussian hills,\n$$\nV_{\\mathrm{meta}}(x) = \\sum_{n=1}^{N} h_n \\exp\\left(-\\frac{(x - s_n)^2}{2 w^2}\\right).\n$$\nStarting from fundamental definitions, including the Boltzmann distribution $p(\\mathbf{q}) \\propto \\exp(-U(\\mathbf{q}))$ with $\\mathbf{q} = (x,y,z)$ and the definition of covariance $C_{ij} = \\langle q_i q_j \\rangle - \\langle q_i \\rangle \\langle q_j \\rangle$, derive how adding a bias $V(x)$ alters the effective distribution of $x$ and propagates into the orthogonal covariance matrix $\\Sigma^{V}$ in terms of the harmonic parameters. Quantify the bias-induced distortion of the native covariance in the orthogonal subspace using the relative Frobenius norm,\n$$\n\\Delta(V) = \\frac{\\left\\| \\Sigma^{V} - \\Sigma^{\\text{native}} \\right\\|_F}{\\left\\| \\Sigma^{\\text{native}} \\right\\|_F},\n$$\nwhere $\\|\\cdot\\|_F$ denotes the Frobenius norm. All energies and variables are dimensionless, with $\\beta = 1$.\n\nYour task is to implement a program that, for each provided test case, computes two floats:\n- $\\Delta(V_{\\mathrm{umb}})$ for the umbrella bias,\n- $\\Delta(V_{\\mathrm{meta}})$ for the metadynamics bias,\nand outputs the results aggregated for all test cases.\n\nThe derivation must be based on:\n- The Boltzmann distribution and properties of Gaussian integrals,\n- The definition of covariance and how linear couplings in a harmonic potential affect conditional and marginal distributions.\n\nFor the umbrella bias, the variance of $x$ can be expressed analytically due to its quadratic form. For the metadynamics bias, compute the variance of $x$ numerically from one-dimensional quadrature,\n$$\n\\mathrm{Var}_{V_{\\mathrm{meta}}}(x) = \\frac{\\int_{-\\infty}^{\\infty} x^2 \\exp\\left(-U_{\\mathrm{eff}}(x) - V_{\\mathrm{meta}}(x)\\right) \\, dx}{\\int_{-\\infty}^{\\infty} \\exp\\left(-U_{\\mathrm{eff}}(x) - V_{\\mathrm{meta}}(x)\\right) \\, dx},\n$$\nwhere $U_{\\mathrm{eff}}(x)$ is the effective quadratic term in $x$ after integrating out $y$ and $z$. Use the resulting variance to compute the orthogonal covariance $\\Sigma^{V}$ via its dependence on the coupling between $x$ and $(y,z)$.\n\nTest Suite:\nProvide results for the following parameter sets, each specified as tuples $(k_x,k_y,k_z,k_{yz},k_{xy},k_{xz},k_{\\mathrm{umb}},x_0,N,\\{h_n\\},\\{s_n\\},w)$:\n\n- Case 1 (general \"happy path\"):\n  $(3.0, 2.0, 1.5, 0.2, 0.3, -0.25, 4.0, 0.5, 3, \\{0.8, 0.6, 0.4\\}, \\{-0.5, 0.0, 0.5\\}, 0.4)$\n- Case 2 (boundary, zero coupling to $x$ in orthogonal degrees):\n  $(2.2, 1.8, 1.3, 0.3, 0.0, 0.0, 3.0, -0.1, 2, \\{1.0, 0.5\\}, \\{-0.2, 0.7\\}, 0.5)$\n- Case 3 (edge case, strong orthogonal coupling and moderate $x$ coupling):\n  $(5.0, 1.5, 1.1, 0.9, 0.7, 0.6, 0.5, -0.2, 4, \\{2.0, 1.7, 1.3, 0.9\\}, \\{-1.0, -0.3, 0.3, 1.1\\}, 0.3)$\n\nAlgorithmic requirements:\n- Compute the native orthogonal covariance $\\Sigma^{\\text{native}}$.\n- Compute the umbrella-biased orthogonal covariance $\\Sigma^{V_{\\mathrm{umb}}}$ using the analytical variance of $x$ under the combined effective quadratic coefficient.\n- Compute the metadynamics-biased orthogonal covariance $\\Sigma^{V_{\\mathrm{meta}}}$ using numerical quadrature for $\\mathrm{Var}_{V_{\\mathrm{meta}}}(x)$.\n- Compute $\\Delta(V_{\\mathrm{umb}})$ and $\\Delta(V_{\\mathrm{meta}})$ for each case.\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list of lists, each inner list holding the two floats for one test case, in the form\n\"[ [delta_case1_umb, delta_case1_meta], [delta_case2_umb, delta_case2_meta], [delta_case3_umb, delta_case3_meta] ]\".\nNo units are required because all quantities are dimensionless. Angles are not involved.", "solution": "We consider a three-dimensional harmonic system with coordinates $(x,y,z)$ and energy\n$$\nU(x,y,z) = \\frac{1}{2} k_x x^2 + \\frac{1}{2} k_y y^2 + \\frac{1}{2} k_z z^2 + k_{yz} y z + k_{xy} x y + k_{xz} x z,\n$$\nand $\\beta = 1$, so the stationary distribution is $p(x,y,z) \\propto \\exp(-U(x,y,z))$. We define the orthogonal coordinates as the vector $\\mathbf{o} = (y,z)^\\top$. Let\n$$\nA = \\begin{pmatrix} k_y & k_{yz} \\\\ k_{yz} & k_z \\end{pmatrix}, \\quad b = \\begin{pmatrix} k_{xy} \\\\ k_{xz} \\end{pmatrix}.\n$$\nThen the energy can be written as a quadratic form in block notation,\n$$\nU(x,\\mathbf{o}) = \\frac{1}{2} k_x x^2 + \\frac{1}{2} \\mathbf{o}^\\top A \\mathbf{o} + x b^\\top \\mathbf{o}.\n$$\nWe require the full Hessian to be positive definite so that the integrals converge.\n\nPrinciple 1: Boltzmann distribution and Gaussian conditioning. For a joint Gaussian proportional to $\\exp\\left(-\\frac{1}{2} [x,\\mathbf{o}]^\\top H [x,\\mathbf{o}] \\right)$, the conditional distribution of $\\mathbf{o}$ given $x$ is Gaussian with covariance $A^{-1}$ and mean shifted linearly by $x$. Completing the square for $\\mathbf{o}$, we obtain\n$$\nU(x,\\mathbf{o}) = \\frac{1}{2} \\left( \\mathbf{o} + A^{-1} b x \\right)^\\top A \\left( \\mathbf{o} + A^{-1} b x \\right) + \\frac{1}{2} \\left( k_x - b^\\top A^{-1} b \\right) x^2.\n$$\nIntegrating over $\\mathbf{o}$ yields the effective energy for $x$,\n$$\nU_{\\mathrm{eff}}(x) = \\frac{1}{2} \\left( k_x - b^\\top A^{-1} b \\right) x^2 + \\text{const},\n$$\nso that the marginal distribution of $x$ in the native system is Gaussian with variance\n$$\n\\mathrm{Var}_{\\text{native}}(x) = \\frac{1}{k_x - b^\\top A^{-1} b}.\n$$\nThis identifies the effective stiffness along $x$,\n$$\nk_x^{\\mathrm{eff}} = k_x - b^\\top A^{-1} b,\n$$\nwhich must be positive for normalizability.\n\nPrinciple 2: Orthogonal covariance via law of total covariance. The conditional covariance of $\\mathbf{o}$ given $x$ is constant and equal to $A^{-1}$, because the conditional quadratic form in $\\mathbf{o}$ has matrix $A$. The conditional mean is $\\mathbb{E}[\\mathbf{o}\\mid x] = -A^{-1} b x$. Using the law of total covariance,\n$$\n\\mathrm{Cov}(\\mathbf{o}) = \\mathbb{E}[\\mathrm{Cov}(\\mathbf{o}\\mid x)] + \\mathrm{Cov}(\\mathbb{E}[\\mathbf{o}\\mid x]).\n$$\nThe first term is simply $A^{-1}$. The second term involves the variance of $x$:\n$$\n\\mathrm{Cov}(\\mathbb{E}[\\mathbf{o}\\mid x]) = \\mathrm{Cov}(-A^{-1} b x) = A^{-1} b \\, \\mathrm{Var}(x) \\, b^\\top A^{-1}.\n$$\nTherefore, for any bias $V(x)$ that modifies only the distribution of $x$, the orthogonal covariance becomes\n$$\n\\Sigma^{V} = A^{-1} + A^{-1} b \\, \\mathrm{Var}_{V}(x) \\, b^\\top A^{-1}.\n$$\nThe native orthogonal covariance is recovered when $\\mathrm{Var}_{V}(x)$ equals $\\mathrm{Var}_{\\text{native}}(x)$.\n\nUmbrella sampling. For the umbrella bias $V_{\\mathrm{umb}}(x) = \\frac{1}{2} k_{\\mathrm{umb}} (x - x_0)^2$, the effective energy along $x$ is\n$$\nU_{\\mathrm{eff}}^{\\mathrm{umb}}(x) = \\frac{1}{2} k_x^{\\mathrm{eff}} x^2 + \\frac{1}{2} k_{\\mathrm{umb}} (x - x_0)^2,\n$$\nwhich is quadratic. The variance of $x$ depends only on the total quadratic coefficient and not on the shift $x_0$:\n$$\n\\mathrm{Var}_{\\mathrm{umb}}(x) = \\frac{1}{k_x^{\\mathrm{eff}} + k_{\\mathrm{umb}}}.\n$$\nThus,\n$$\n\\Sigma^{V_{\\mathrm{umb}}} = A^{-1} + A^{-1} b \\, \\frac{1}{k_x^{\\mathrm{eff}} + k_{\\mathrm{umb}}} \\, b^\\top A^{-1}.\n$$\n\nMetadynamics. For the metadynamics bias $V_{\\mathrm{meta}}(x)$ as a sum of Gaussian hills, the effective one-dimensional distribution of $x$ is non-Gaussian:\n$$\np_{V_{\\mathrm{meta}}}(x) \\propto \\exp\\left(-U_{\\mathrm{eff}}(x) - V_{\\mathrm{meta}}(x)\\right) = \\exp\\left(-\\frac{1}{2} k_x^{\\mathrm{eff}} x^2 - \\sum_{n=1}^N h_n \\exp\\left(-\\frac{(x - s_n)^2}{2 w^2}\\right)\\right).\n$$\nThe variance is computed by one-dimensional quadrature,\n$$\n\\mathrm{Var}_{\\mathrm{meta}}(x) = \\frac{\\int_{-\\infty}^{\\infty} x^2 \\exp\\left(-\\frac{1}{2} k_x^{\\mathrm{eff}} x^2 - \\sum_{n=1}^N h_n \\exp\\left(-\\frac{(x - s_n)^2}{2 w^2}\\right)\\right) \\, dx}{\\int_{-\\infty}^{\\infty} \\exp\\left(-\\frac{1}{2} k_x^{\\mathrm{eff}} x^2 - \\sum_{n=1}^N h_n \\exp\\left(-\\frac{(x - s_n)^2}{2 w^2}\\right)\\right) \\, dx}.\n$$\nThen\n$$\n\\Sigma^{V_{\\mathrm{meta}}} = A^{-1} + A^{-1} b \\, \\mathrm{Var}_{\\mathrm{meta}}(x) \\, b^\\top A^{-1}.\n$$\n\nDistortion metric. The native orthogonal covariance is\n$$\n\\Sigma^{\\text{native}} = A^{-1} + A^{-1} b \\, \\frac{1}{k_x^{\\mathrm{eff}}} \\, b^\\top A^{-1}.\n$$\nFor each bias $V$, compute\n$$\n\\Delta(V) = \\frac{\\left\\| \\Sigma^{V} - \\Sigma^{\\text{native}} \\right\\|_F}{\\left\\| \\Sigma^{\\text{native}} \\right\\|_F}.\n$$\n\nAlgorithmic steps implemented in the program:\n1. Construct $A$ and compute $A^{-1}$.\n2. Compute $b$ and $k_x^{\\mathrm{eff}} = k_x - b^\\top A^{-1} b$; check positivity.\n3. Compute $\\Sigma^{\\text{native}}$ using $\\mathrm{Var}_{\\text{native}}(x) = 1/k_x^{\\mathrm{eff}}$.\n4. Umbrella: compute $\\mathrm{Var}_{\\mathrm{umb}}(x) = 1/(k_x^{\\mathrm{eff}} + k_{\\mathrm{umb}})$ and $\\Sigma^{V_{\\mathrm{umb}}}$.\n5. Metadynamics: compute the numerator and denominator integrals using numerical quadrature for $\\mathrm{Var}_{\\mathrm{meta}}(x)$, then $\\Sigma^{V_{\\mathrm{meta}}}$.\n6. Compute $\\Delta(V_{\\mathrm{umb}})$ and $\\Delta(V_{\\mathrm{meta}})$ via Frobenius norms.\n7. Aggregate the results as specified.\n\nEdge case analysis:\n- When $b = \\mathbf{0}$ (no coupling between $x$ and $(y,z)$), $\\Sigma^{V}$ reduces to $A^{-1}$ regardless of the variance of $x$. Hence $\\Delta(V) = 0$ for any bias, reflecting perfect preservation of native orthogonal covariance.\n- Strong orthogonal coupling (large $|k_{yz}|$ but with $A$ positive definite) increases sensitivity of $\\Sigma^{\\text{native}}$ to $b$ via $A^{-1}$, making distortions more pronounced when $\\mathrm{Var}(x)$ changes.\n\nNumerical considerations:\n- The metadynamics integrals are one-dimensional and rapidly convergent due to the Gaussian envelope set by $k_x^{\\mathrm{eff}} > 0$; we use high-accuracy quadrature tolerances.\n- All calculations are in dimensionless units with $\\beta = 1$, no angles are involved.\n\nThe final program follows these steps on the supplied test cases and prints a single line with a list of pairs $[\\Delta(V_{\\mathrm{umb}}), \\Delta(V_{\\mathrm{meta}})]$ for each case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import integrate\n\ndef frobenius_norm(mat):\n    return np.linalg.norm(mat, 'fro')\n\ndef compute_A_inverse(k_y, k_z, k_yz):\n    A = np.array([[k_y, k_yz],\n                  [k_yz, k_z]], dtype=float)\n    # Ensure positive definiteness for numerical stability\n    # Inverse via numpy\n    A_inv = np.linalg.inv(A)\n    return A, A_inv\n\ndef effective_kx(k_x, b_vec, A_inv):\n    # kx_eff = k_x - b^T A^{-1} b\n    return k_x - float(b_vec.T @ A_inv @ b_vec)\n\ndef sigma_orth(A_inv, b_vec, var_x):\n    # Sigma^V = A^{-1} + A^{-1} b var_x b^T A^{-1}\n    term = A_inv @ np.outer(b_vec, b_vec) @ A_inv\n    return A_inv + var_x * term\n\ndef umbrella_var_x(kx_eff, k_umb):\n    # Analytical variance for quadratic umbrella bias\n    return 1.0 / (kx_eff + k_umb)\n\ndef meta_var_x(kx_eff, hills, centers, width):\n    # Compute Var(x) under metadynamics bias via 1D quadrature\n    # V_meta(x) = sum h_n exp(-(x - s_n)^2 / (2 w^2))\n    def V_meta(x):\n        # Use vectorized-like sum\n        total = 0.0\n        for h, s in zip(hills, centers):\n            dx = x - s\n            total += h * np.exp(-0.5 * (dx * dx) / (width * width))\n        return total\n\n    def weight(x):\n        return np.exp(-0.5 * kx_eff * x * x - V_meta(x))\n\n    # Compute Z = ∫ w(x) dx and M2 = ∫ x^2 w(x) dx\n    # Use high accuracy; integrand decays rapidly due to quadratic term\n    Z, _ = integrate.quad(lambda x: weight(x), -np.inf, np.inf, epsabs=1e-10, epsrel=1e-10, limit=200)\n    M2, _ = integrate.quad(lambda x: x * x * weight(x), -np.inf, np.inf, epsabs=1e-10, epsrel=1e-10, limit=200)\n    return M2 / Z\n\ndef compute_distortions(case):\n    # Unpack parameters\n    (k_x, k_y, k_z, k_yz, k_xy, k_xz,\n     k_umb, x0, N, hills, centers, w) = case\n\n    # Build matrices and vectors\n    A, A_inv = compute_A_inverse(k_y, k_z, k_yz)\n    b = np.array([k_xy, k_xz], dtype=float)\n\n    # Effective stiffness along x\n    kx_eff = effective_kx(k_x, b, A_inv)\n    if kx_eff <= 0:\n        # For robustness, raise an error if parameters are not physically consistent\n        raise ValueError(\"Effective stiffness kx_eff must be positive for normalizable distribution.\")\n\n    # Native variance of x and native orthogonal covariance\n    var_x_native = 1.0 / kx_eff\n    Sigma_native = sigma_orth(A_inv, b, var_x_native)\n\n    # Umbrella variance (independent of x0) and covariance\n    var_x_umb = umbrella_var_x(kx_eff, k_umb)\n    Sigma_umb = sigma_orth(A_inv, b, var_x_umb)\n\n    # Metadynamics variance and covariance\n    # Ensure hills and centers lengths == N\n    hills = list(hills)[:N]\n    centers = list(centers)[:N]\n    var_x_meta = meta_var_x(kx_eff, hills, centers, w)\n    Sigma_meta = sigma_orth(A_inv, b, var_x_meta)\n\n    # Distortions relative to native\n    denom = frobenius_norm(Sigma_native)\n    # Handle case where b=0, so Sigma_native = A_inv, and Sigma_V = A_inv, so distortion is 0.\n    # Also, if denom is zero (unlikely), avoid division by zero.\n    if denom < 1e-12:\n        return [0.0, 0.0]\n\n    delta_umb = frobenius_norm(Sigma_umb - Sigma_native) / denom\n    delta_meta = frobenius_norm(Sigma_meta - Sigma_native) / denom\n\n    return [delta_umb, delta_meta]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: happy path\n        (3.0, 2.0, 1.5, 0.2, 0.3, -0.25, 4.0, 0.5, 3, [0.8, 0.6, 0.4], [-0.5, 0.0, 0.5], 0.4),\n        # Case 2: boundary, zero coupling to x\n        (2.2, 1.8, 1.3, 0.3, 0.0, 0.0, 3.0, -0.1, 2, [1.0, 0.5], [-0.2, 0.7], 0.5),\n        # Case 3: edge case, strong orthogonal coupling and moderate x coupling\n        (5.0, 1.5, 1.1, 0.9, 0.7, 0.6, 0.5, -0.2, 4, [2.0, 1.7, 1.3, 0.9], [-1.0, -0.3, 0.3, 1.1], 0.3),\n    ]\n\n    results = []\n    for case in test_cases:\n        deltas = compute_distortions(case)\n        results.append(deltas)\n\n    # Final print statement in the exact required format.\n    # Produce a single line of output containing the list of lists.\n    def format_inner_list(lst):\n        return \"[ \" + \", \".join(f\"{x:.10f}\" for x in lst) + \" ]\"\n    print(\"[ \" + \", \".join(format_inner_list(r) for r in results) + \" ]\")\n\nsolve()\n```", "id": "3406465"}]}