{"hands_on_practices": [{"introduction": "This practice tackles a fundamental challenge in running NPT simulations: choosing the barostat mass parameter, $W$. A poorly chosen $W$ can lead to unphysical oscillations or excessively slow pressure equilibration. This exercise guides you through analyzing a simplified dynamical model of the barostat to derive a scaling law for $W$, enabling you to maintain a consistent cell relaxation time as you change the system size [@problem_id:3432685].", "problem": "You are given a simplified, isotropic form of the Parrinello-Rahman barostat dynamics for the scalar cell strain variable $\\eta(t)$ under small fluctuations, derived from Newton's Second Law and linear response of the internal pressure. The cell mass parameter is $W$, the system volume is $V$, the bulk modulus is $K$ (assumed intensive and constant), and a linear effective damping per unit volume $c$ models the combined effect of viscous dissipation and coupling to a thermostat. The linearized equation of motion is\n$$\nW\\,\\ddot{\\eta}(t) + c\\,V\\,\\dot{\\eta}(t) + K\\,V\\,\\eta(t) = 0,\n$$\nwith initial conditions $\\eta(0)=\\eta_0$ and $\\dot{\\eta}(0)=0$. Assume reduced Lennard-Jones (dimensionless) units such that density and temperature are fixed and $V \\propto N$, where $N$ is the number of particles. Let the target cell relaxation time be $\\tau_h$, defined as the dominant exponential decay time scale of $\\eta(t)$ following a small perturbation (the inverse of the slowest decay rate).\n\nStarting from the above equation and fundamental principles:\n- Use $V \\propto N$ to propose a scaling law of the form $W(N) = k V(N)$ that aims to keep the relaxation time $\\tau_h$ constant as the system size $N$ changes, at fixed density and temperature.\n- Show that, with $W(N) = k V(N)$, the slow decay rate $\\alpha$ becomes independent of $V(N)$ and depends only on $k$, $K$, and $c$. Derive the piecewise expression for $\\alpha(k;K,c)$:\n$$\n\\alpha(k;K,c) = \n\\begin{cases}\n\\dfrac{c - \\sqrt{c^2 - 4 K k}}{2 k}, & \\text{if } c^2 - 4 K k \\ge 0 \\text{ (overdamped or critically damped)}, \\\\[8pt]\n\\dfrac{c}{2 k}, & \\text{if } c^2 - 4 K k < 0 \\text{ (underdamped)}.\n\\end{cases}\n$$\n- Explain the feasibility condition for achieving a target $\\tau_h$ with this linear model, namely $\\alpha(k;K,c) \\le K/c$ implying $\\tau_h \\ge c/K$.\n\nAlgorithmic task:\n- Implement a function to compute $\\alpha(k;K,c)$ using the piecewise formula above.\n- Given $K$, a reference system size $N_{\\mathrm{ref}}$ with volume $V(N_{\\mathrm{ref}})$, and a target $\\tau_h$, find $k$ such that $\\alpha(k;K,c(N_{\\mathrm{ref}})) = 1/\\tau_h$ using a robust one-dimensional bisection method over $k\\in(0,\\infty)$, or return infeasible if $\\tau_h  c(N_{\\mathrm{ref}})/K$.\n- For any other $N$, use $W(N) = k V(N)$ to predict the actual relaxation time $\\tau_h(N) = 1/\\alpha(k;K,c(N))$ and report deviations from the target $\\delta(N) = \\tau_h(N) - \\tau_h$.\n\nUse the following test suite. All quantities are dimensionless reduced units. Take $K=50$, $V(N)=N$, and $N_{\\mathrm{ref}}=100$ in all cases. For each scenario, the effective damping is $c(N) = \\zeta(N) + \\gamma(N)$, specified below:\n\n- Scenario A (happy path, constant damping): $\\tau_h = 2.0$; $\\zeta(N)=4$; $\\gamma(N)=2$; test $N\\in\\{50,100,200\\}$.\n- Scenario B (finite-size viscosity): $\\tau_h = 2.0$; $\\zeta(N)=4\\left(1+\\dfrac{50}{N}\\right)$; $\\gamma(N)=2$; test $N\\in\\{50,100,200\\}$.\n- Scenario C (finite-size thermostat coupling): $\\tau_h = 2.0$; $\\zeta(N)=4$; $\\gamma(N)=2\\left(1+\\dfrac{100}{N}\\right)$; test $N\\in\\{50,100,200\\}$.\n- Scenario D (boundary feasibility, near minimum time): $\\tau_h = \\dfrac{6}{50}$; $\\zeta(N)=4$; $\\gamma(N)=2$; test $N=100$ only.\n- Scenario E (infeasible target): $\\tau_h = 0.10$; $\\zeta(N)=4$; $\\gamma(N)=2$; test $N=100$ only.\n- Scenario F (large-$N$ with finite-size viscosity): $\\tau_h = 2.0$; $\\zeta(N)=4\\left(1+\\dfrac{50}{N}\\right)$; $\\gamma(N)=2$; test $N=1000$ only.\n\nYour program must:\n1. For each scenario, compute $k$ from $N_{\\mathrm{ref}}$ and the specified $\\tau_h$. If infeasible ($\\tau_h  c(N_{\\mathrm{ref}})/K$), append the boolean value False for that scenario's single test to the final results and skip further computation.\n2. For each listed test $N$ in the scenario, compute $\\delta(N)$ and append it to the final results.\n3. Produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., $[x_1,x_2,\\dots]$) where each entry is a float (rounded to six decimal places) or a boolean, in the order of the scenarios and their $N$ values as listed above.\n\nAll answers are dimensionless reduced units. Angles are not used. Percentages must not appear; use decimals. The final line must be the single required output list only.", "solution": "The posed problem concerns the dynamics of cell fluctuations under an isotropic Parrinello-Rahman barostat, described by a linearized second-order ordinary differential equation. The task is to analyze the system's relaxation behavior, propose a parameter scaling law, and implement a numerical algorithm to tune the barostat and predict its performance across different system sizes.\n\nFirst, we address the conceptual derivations requested. The equation of motion for the scalar cell strain $\\eta(t)$ is given as:\n$$\nW\\,\\ddot{\\eta}(t) + c\\,V\\,\\dot{\\eta}(t) + K\\,V\\,\\eta(t) = 0\n$$\nThis is the equation for a damped harmonic oscillator. To analyze its behavior, we seek solutions of the form $\\eta(t) \\propto e^{\\lambda t}$. Substituting this into the equation yields the characteristic polynomial for the temporal rates $\\lambda$:\n$$\nW \\lambda^2 + cV \\lambda + KV = 0\n$$\nThe problem suggests a scaling law for the cell mass parameter $W$ of the form $W(N) = k V(N)$, where $N$ is the number of particles, $V(N)$ is the system volume, and $k$ is a proportionality constant independent of $N$. This is motivated by the desire to make the characteristic dynamics independent of the explicit system volume. Substituting this scaling law into the characteristic equation, we get:\n$$\nk V(N) \\lambda^2 + c(N)V(N) \\lambda + K V(N) = 0\n$$\nSince the volume $V(N)$ is a positive quantity, we can divide the entire equation by $V(N)$ to obtain an equation for $\\lambda$ that depends only on the parameters $k$, $K$, and the damping coefficient $c(N)$:\n$$\nk \\lambda^2 + c(N) \\lambda + K = 0\n$$\nThe solutions to this quadratic equation are:\n$$\n\\lambda_{\\pm} = \\frac{-c \\pm \\sqrt{c^2 - 4 K k}}{2k}\n$$\nThe relaxation of $\\eta(t)$ to zero is governed by these rates. The dominant exponential decay time scale, $\\tau_h$, is the inverse of the slowest decay rate, $\\alpha$, where $\\alpha = -\\text{Re}(\\lambda_{\\text{slowest}})$. The slowest rate corresponds to the root $\\lambda$ with the real part closest to zero.\n\nWe analyze the two damping regimes based on the discriminant $D = c^2 - 4Kk$:\n\n1.  If $D \\ge 0$ (overdamped or critically damped), the roots $\\lambda_{\\pm}$ are real and non-positive. The slower rate is $\\lambda_{+} = (-c + \\sqrt{c^2 - 4Kk})/(2k)$. The decay rate is $\\alpha = -\\lambda_{+}$, which gives:\n    $$\n    \\alpha(k;K,c) = \\frac{c - \\sqrt{c^2 - 4Kk}}{2k}\n    $$\n2.  If $D  0$ (underdamped), the roots are a complex conjugate pair, $\\lambda_{\\pm} = -c/(2k) \\pm i\\omega$, where $\\omega = \\sqrt{4Kk-c^2}/(2k)$. The solution exhibits oscillations with an exponentially decaying envelope $e^{-(c/2k)t}$. The decay rate is determined by the real part of $\\lambda$, so $\\alpha = -(-c/2k) = c/(2k)$.\n\nThese derivations confirm the piecewise expression for $\\alpha(k;K,c)$ provided in the problem statement.\n\nNext, we explain the feasibility condition $\\tau_h \\ge c/K$, which is equivalent to $\\alpha \\le K/c$. Let us analyze the function $\\alpha(k)$ for fixed $K$ and $c$. The function $\\alpha(k)$ increases from a limiting value of $\\alpha(0^+) = K/c$ to a maximum of $\\alpha_{max} = 2K/c$ at the critical damping point $k = c^2/(4K)$, and then decreases monotonically to $0$ as $k \\to \\infty$. This non-monotonic behavior means that for a target decay rate $\\alpha_{\\text{target}}$ in the range $(K/c, 2K/c]$, there are two possible values of $k$ that achieve it. To ensure a unique and physically desirable solution (typically corresponding to a large barostat mass for slow, stable dynamics), the problem is restricted to the regime where $\\alpha_{\\text{target}} \\le K/c$. In this regime, there is a single unique root for $k$, which lies in the underdamped region. This makes the problem well-posed and justifies checking the condition $\\tau_h  c/K$ to identify \"infeasible\" targets.\n\nFor the algorithmic part, we first determine the constant $k$ by solving $\\alpha(k; K, c(N_{\\mathrm{ref}})) = 1/\\tau_h$ for a reference system of size $N_{\\mathrm{ref}}$. The feasibility condition $\\tau_h \\ge c(N_{\\mathrm{ref}})/K$ guarantees that a unique solution can be found using a bisection method. Once $k$ is determined, it is held constant. For any other system size $N$, the actual damping $c(N)$ is calculated, and from it, the actual relaxation time $\\tau_h(N) = 1/\\alpha(k; K, c(N))$ is predicted. The deviation is then $\\delta(N) = \\tau_h(N) - \\tau_h$.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Parrinello-Rahman barostat problem for all specified scenarios.\n    \"\"\"\n    \n    K_const = 50.0\n    N_ref = 100.0\n\n    scenarios = {\n        'A': {'tau_h': 2.0, 'zeta': lambda N: 4.0, 'gamma': lambda N: 2.0, 'test_N': [50, 100, 200]},\n        'B': {'tau_h': 2.0, 'zeta': lambda N: 4.0 * (1.0 + 50.0 / N), 'gamma': lambda N: 2.0, 'test_N': [50, 100, 200]},\n        'C': {'tau_h': 2.0, 'zeta': lambda N: 4.0, 'gamma': lambda N: 2.0 * (1.0 + 100.0 / N), 'test_N': [50, 100, 200]},\n        'D': {'tau_h': 6.0 / 50.0, 'zeta': lambda N: 4.0, 'gamma': lambda N: 2.0, 'test_N': [100]},\n        'E': {'tau_h': 0.10, 'zeta': lambda N: 4.0, 'gamma': lambda N: 2.0, 'test_N': [100]},\n        'F': {'tau_h': 2.0, 'zeta': lambda N: 4.0 * (1.0 + 50.0 / N), 'gamma': lambda N: 2.0, 'test_N': [1000]},\n    }\n    \n    ordered_scenarios = ['A', 'B', 'C', 'D', 'E', 'F']\n\n    def get_c(N, zeta_func, gamma_func):\n        \"\"\"Computes the damping coefficient c(N).\"\"\"\n        return zeta_func(N) + gamma_func(N)\n\n    def calculate_alpha(k, K, c):\n        \"\"\"Computes the slow decay rate alpha using the piecewise formula.\"\"\"\n        if k = 0:\n            return np.inf  # Physically k must be positive\n        \n        discriminant = c**2 - 4 * K * k\n        if discriminant = 0:\n            # Overdamped or critically damped\n            return (c - np.sqrt(discriminant)) / (2 * k)\n        else:\n            # Underdamped\n            return c / (2 * k)\n\n    def bisect(func, a, b, tol=1e-12, max_iter=100):\n        \"\"\"\n        Bisection method to find the root of func(x) = 0 in [a, b].\n        \"\"\"\n        fa = func(a)\n        fb = func(b)\n        if fa * fb = 0:\n            # Check for exact root at boundaries\n            if fa == 0: return a\n            if fb == 0: return b\n            # If no sign change, root finding might fail, indicates an issue.\n            return None\n\n        for _ in range(max_iter):\n            mid = (a + b) / 2\n            f_mid = func(mid)\n            \n            if abs(b - a) / 2  tol or f_mid == 0:\n                return mid\n            \n            if fa * f_mid  0:\n                b = mid\n            else:\n                a = mid\n                fa = f_mid # Update fa to f_mid\n        return (a + b) / 2\n\n    results = []\n    \n    for sc_key in ordered_scenarios:\n        scenario = scenarios[sc_key]\n        tau_h_target = scenario['tau_h']\n        zeta_func = scenario['zeta']\n        gamma_func = scenario['gamma']\n        \n        c_ref = get_c(N_ref, zeta_func, gamma_func)\n\n        # 1. Feasibility check\n        if tau_h_target  c_ref / K_const:\n            results.append(False)\n            continue\n            \n        # 2. Find k using bisection\n        alpha_target = 1.0 / tau_h_target\n        \n        # Function whose root we want to find: f(k) = alpha(k) - alpha_target\n        func_to_solve = lambda k: calculate_alpha(k, K_const, c_ref) - alpha_target\n\n        k_val = bisect(func_to_solve, 1e-9, 1e9)\n        \n        if k_val is None:\n            # This should not happen for a feasible problem\n            # For robustness, handle this case\n            for _ in scenario['test_N']:\n                 results.append(np.nan) # Or flag an error\n            continue\n\n        # 3. For each test N, compute the deviation delta(N)\n        for N in scenario['test_N']:\n            c_N = get_c(N, zeta_func, gamma_func)\n            alpha_actual = calculate_alpha(k_val, K_const, c_N)\n            tau_h_actual = 1.0 / alpha_actual\n            delta_N = tau_h_actual - tau_h_target\n            results.append(round(delta_N, 6))\n\n    # Final print statement in the exact required format\n    output_str = \"[\" + \",\".join(map(str, results)) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3432685"}, {"introduction": "One of the most powerful applications of the Parrinello-Rahman method is its ability to determine a material's mechanical properties from equilibrium fluctuations. This practice explores the fundamental statistical mechanics relationship connecting the covariance of the strain tensor to the elastic compliance matrix. You will implement a professional-grade protocol to estimate the full elastic stiffness tensor from simulated data, including a crucial step to remove systematic bias by extrapolating to the infinite barostat mass limit [@problem_id:3432721].", "problem": "Consider a thermodynamic ensemble of a crystalline solid under zero external stress, controlled using the Parrinello-Rahman (PR) barostat. Let $h$ be the $3 \\times 3$ cell matrix, $g = h^{\\mathrm{T}} h$ the metric tensor, and $g_0$ a reference metric. The infinitesimal Lagrangian strain is defined by $ \\epsilon = \\frac{1}{2} \\left( g g_0^{-1} - I \\right) $ in the small-strain limit, where $I$ is the identity matrix. In linear elasticity, the Helmholtz free energy density expanded around the reference state is $ f(\\epsilon) = \\frac{1}{2} \\epsilon : C : \\epsilon $, where $C$ is the fourth-rank elastic stiffness tensor with components $C_{ijkl}$, and $:$ denotes the double contraction. The PR barostat, when thermally equilibrated at temperature $T$, samples the equilibrium distribution of strain fluctuations consistent with the Boltzmann weight.\n\nStarting from these bases and ignoring dynamical details, derive the strain covariance relation\n$$\n\\langle \\epsilon_{ij} \\epsilon_{kl} \\rangle = \\frac{k_B T}{V} \\left( C^{-1} \\right)_{ijkl},\n$$\nwhere $V$ is the volume, $k_B$ is the Boltzmann constant, and $\\left( C^{-1} \\right)_{ijkl}$ denotes the components of the elastic compliance tensor (the inverse of $C$ in the sense of fourth-rank tensors). Use the Voigt engineering notation $e = [\\epsilon_{11}, \\epsilon_{22}, \\epsilon_{33}, 2\\epsilon_{23}, 2\\epsilon_{13}, 2\\epsilon_{12}]^{\\mathrm{T}}$ such that the free energy is $ F = \\frac{V}{2} e^{\\mathrm{T}} C^{(V)} e $, where $C^{(V)}$ is the $6 \\times 6$ stiffness matrix in Voigt notation and $F$ is the total free energy. Show that within this convention the covariance of $e$ is\n$$\n\\langle e e^{\\mathrm{T}} \\rangle = \\frac{k_B T}{V} \\left( C^{(V)} \\right)^{-1}.\n$$\n\nIn actual PR simulations, the barostat mass parameter $W$ sets a characteristic timescale for the cell dynamics. For finite $W$ and a finite time step, discretization and dynamical filtering can introduce a systematic bias in sampled covariances that often scales approximately as $O\\!\\left( \\frac{1}{W} \\right)$ for fixed time step. A practical protocol to estimate $C_{ijkl}$ is to run simulations at several $W$ values, compute the sample covariance matrices of $e$, convert to compliance, and extrapolate to the $W \\to \\infty$ limit by linear regression in $1/W$.\n\nYour task is to implement this protocol and test it on synthetic, scientifically consistent cases. Specifically:\n\n1. Implement a program that, given temperature $T$ (in $\\mathrm{K}$), volume $V$ (in $\\mathrm{m^3}$), a set of barostat masses $W$ (in $\\mathrm{amu \\cdot \\AA^2}$), and measured covariance matrices $\\Sigma_e(W) = \\langle e e^{\\mathrm{T}} \\rangle$ for those $W$, performs the following steps:\n   - Convert each $\\Sigma_e(W)$ to a compliance estimate $J(W)$ using $ J(W) = \\frac{V}{k_B T} \\Sigma_e(W) $.\n   - For each matrix element, regress $J(W)$ against $x = \\frac{1}{W}$ using a linear model $ J_{pq}(W) = J_{pq}^{\\ast} + A_{pq} \\frac{1}{W} $ and extract $J_{pq}^{\\ast}$ as the intercept, forming the de-biased compliance matrix $J^{\\ast}$.\n   - Invert $J^{\\ast}$ to obtain an estimate of the stiffness matrix $C^{(V)}$.\n   - Report selected components of $C^{(V)}$ in gigapascals (GPa), rounded to three decimal places.\n\n2. Use Voigt engineering notation and standard symmetry-reduced forms for the stiffness matrices in each case as described below.\n\n3. Use the following synthetic test suite. In each case, the \"measured\" covariance matrices $\\Sigma_e(W)$ are generated from a \"true\" stiffness matrix $C_{\\text{true}}^{(V)}$ by first obtaining the true compliance $J_{\\text{true}} = \\left( C_{\\text{true}}^{(V)} \\right)^{-1}$, then applying a controlled bias model $J_{\\text{meas}}(W) = J_{\\text{true}} \\left( 1 + \\frac{\\alpha}{W} \\right)$ elementwise, and finally setting $\\Sigma_e(W) = \\frac{k_B T}{V} J_{\\text{meas}}(W)$. The regression in your program must not use $\\alpha$; it should infer the intercepts from the $W$-dependence.\n\n- Constants:\n  - $k_B = 1.380649 \\times 10^{-23}$ in $\\mathrm{J/K}$.\n  - $T = 300$ in $\\mathrm{K}$.\n  - $V = 1.0 \\times 10^{-26}$ in $\\mathrm{m^3}$.\n  - $W$ values: $[10.0, 20.0, 50.0]$ in $\\mathrm{amu \\cdot \\AA^2}$.\n  - Bias amplitude $\\alpha$ is case-dependent, as specified below.\n\n- Case 1 (Cubic symmetry, happy path):\n  - True stiffness components in $\\mathrm{GPa}$: $C_{11} = 200$, $C_{12} = 120$, $C_{44} = 80$.\n  - Construct $C_{\\text{true}}^{(V)}$ as:\n    $$\n    \\begin{pmatrix}\n    C_{11}  C_{12}  C_{12}  0  0  0 \\\\\n    C_{12}  C_{11}  C_{12}  0  0  0 \\\\\n    C_{12}  C_{12}  C_{11}  0  0  0 \\\\\n    0  0  0  C_{44}  0  0 \\\\\n    0  0  0  0  C_{44}  0 \\\\\n    0  0  0  0  0  C_{44}\n    \\end{pmatrix}\n    $$\n  - Bias amplitude: $\\alpha = 0.40$.\n\n- Case 2 (Hexagonal symmetry, anisotropic coverage):\n  - True stiffness components in $\\mathrm{GPa}$: $C_{11} = 160$, $C_{12} = 80$, $C_{13} = 65$, $C_{33} = 180$, $C_{44} = 50$, and $C_{66} = \\frac{C_{11}-C_{12}}{2}$.\n  - Construct $C_{\\text{true}}^{(V)}$ as:\n    $$\n    \\begin{pmatrix}\n    C_{11}  C_{12}  C_{13}  0  0  0 \\\\\n    C_{12}  C_{11}  C_{13}  0  0  0 \\\\\n    C_{13}  C_{13}  C_{33}  0  0  0 \\\\\n    0  0  0  C_{44}  0  0 \\\\\n    0  0  0  0  C_{44}  0 \\\\\n    0  0  0  0  0  C_{66}\n    \\end{pmatrix}\n    $$\n  - Bias amplitude: $\\alpha = 0.25$.\n\n- Case 3 (Nearly isotropic, edge case with different moduli):\n  - True bulk and shear moduli in $\\mathrm{GPa}$: $K = 160$, $G = 70$. Compute $\\lambda = K - \\frac{2}{3}G$, then $C_{11} = \\lambda + 2G$, $C_{12} = \\lambda$, $C_{44} = G$, and set:\n    $$\n    C_{\\text{true}}^{(V)} =\n    \\begin{pmatrix}\n    C_{11}  C_{12}  C_{12}  0  0  0 \\\\\n    C_{12}  C_{11}  C_{12}  0  0  0 \\\\\n    C_{12}  C_{12}  C_{11}  0  0  0 \\\\\n    0  0  0  C_{44}  0  0 \\\\\n    0  0  0  0  C_{44}  0 \\\\\n    0  0  0  0  0  C_{44}\n    \\end{pmatrix}\n    $$\n  - Bias amplitude: $\\alpha = 0.50$.\n\nAll stiffness matrices $C_{\\text{true}}^{(V)}$ above are specified in $\\mathrm{GPa}$ but must be converted to $\\mathrm{Pa}$ for computations, and the final reported values must be in $\\mathrm{GPa}$.\n\nFinal output format:\n- For each case, report the estimated stiffness components as a list in the order $[C_{11}, C_{12}, C_{13}, C_{33}, C_{44}, C_{66}]$ in $\\mathrm{GPa}$, rounded to three decimal places. For cubic and isotropic cases where $C_{13}$ and $C_{33}$ are not independently specified, use $C_{13} = C_{12}$ and $C_{33} = C_{11}$; for $C_{66}$ in cubic and isotropic cases use $C_{66} = C_{44}$.\n- Your program should produce a single line of output containing the results for all three cases as a comma-separated list of lists enclosed in square brackets, for example: \"[[...],[...],[...]]\".\n\nAngles are not part of this problem. Physical units must strictly follow the specifications above. Ensure scientific realism in the calculations and use the given constants. The test suite covers a general case, an anisotropic case, and a nearly isotropic edge case, and the numerical results must be floats.", "solution": "The problem requires the implementation of a data analysis protocol to determine elastic constants from synthetically generated simulation data, accounting for systematic biases. Before implementing the protocol, we must validate the underlying physical and mathematical principles.\n\nFirst, we derive the relationship between strain fluctuations and the elastic compliance tensor in the context of the Parrinello-Rahman ensemble at constant temperature $T$ and zero external stress. The Helmholtz free energy $F$ of a solid of volume $V$ under a uniform strain $\\epsilon$ is given by $F = V f(\\epsilon)$, where $f(\\epsilon)$ is the free energy density. In the linear elastic regime, this is a quadratic function of strain:\n$$\nf(\\epsilon) = \\frac{1}{2} \\epsilon : C : \\epsilon = \\frac{1}{2} \\sum_{i,j,k,l=1}^{3} \\epsilon_{ij} C_{ijkl} \\epsilon_{kl}\n$$\nHere, $C$ is the fourth-rank elastic stiffness tensor. For computational convenience, this is expressed using the $6$-component Voigt strain vector $e = [\\epsilon_{11}, \\epsilon_{22}, \\epsilon_{33}, 2\\epsilon_{23}, 2\\epsilon_{13}, 2\\epsilon_{12}]^{\\mathrm{T}}$ and the $6 \\times 6$ Voigt stiffness matrix $C^{(V)}$. The total free energy is then:\n$$\nF(e) = \\frac{V}{2} e^{\\mathrm{T}} C^{(V)} e\n$$\nAccording to statistical mechanics, in a thermodynamic ensemble at equilibrium, the probability distribution of fluctuations of a macroscopic variable (here, the strain $e$) follows the Boltzmann distribution:\n$$\nP(e) \\propto \\exp\\left(-\\frac{F(e)}{k_B T}\\right) = \\exp\\left(-\\frac{V}{2k_B T} e^{\\mathrm{T}} C^{(V)} e\\right)\n$$\nwhere $k_B$ is the Boltzmann constant. This is the functional form of a multivariate normal distribution for the vector $e$ with a mean of zero. A general zero-mean multivariate normal distribution for a vector $\\mathbf{x}$ has a probability density function $P(\\mathbf{x}) \\propto \\exp\\left(-\\frac{1}{2} \\mathbf{x}^{\\mathrm{T}} \\Sigma^{-1} \\mathbf{x}\\right)$, where $\\Sigma = \\langle \\mathbf{x} \\mathbf{x}^{\\mathrm{T}} \\rangle$ is the covariance matrix.\n\nBy comparing the exponent of the strain distribution with the general form, we can identify the inverse of the strain covariance matrix $\\Sigma_e = \\langle e e^{\\mathrm{T}} \\rangle$:\n$$\n\\Sigma_e^{-1} = \\frac{V}{k_B T} C^{(V)}\n$$\nInverting this expression gives the desired covariance matrix of the strain fluctuations:\n$$\n\\Sigma_e = \\langle e e^{\\mathrm{T}} \\rangle = \\left(\\frac{V}{k_B T} C^{(V)}\\right)^{-1} = \\frac{k_B T}{V} \\left(C^{(V)}\\right)^{-1}\n$$\nThe matrix $J^{(V)} = (C^{(V)})^{-1}$ is the elastic compliance matrix in Voigt notation. The relation $\\langle e e^{\\mathrm{T}} \\rangle = \\frac{k_B T}{V} J^{(V)}$ is central to the problem, as it connects a measurable quantity, the strain covariance, to a fundamental material property, the elastic compliance. This a specific instance of the fluctuation-dissipation theorem. The equivalent tensorial form $\\langle \\epsilon_{ij} \\epsilon_{kl} \\rangle = \\frac{k_B T}{V} (C^{-1})_{ijkl}$ follows directly.\n\nThe problem then introduces a computational artifact: a systematic bias in the measured covariances that depends on the barostat mass parameter $W$. The proposed analysis protocol aims to correct for this bias. The \"measured\" compliance, estimated at a finite $W$ as $J(W) = \\frac{V}{k_B T} \\Sigma_e(W)$, is assumed to follow a linear relationship with $1/W$:\n$$\nJ_{pq}(W) = J_{pq}^{\\ast} + A_{pq} \\frac{1}{W}\n$$\nHere, $J_{pq}^{\\ast}$ is the true, unbiased compliance component corresponding to the limit $W \\to \\infty$, and $A_{pq}$ is a constant coefficient for the bias term. To find $J^{\\ast}$, we perform a linear regression for each matrix element $(p, q)$. By fitting a line to the data points $(x_i, y_i) = (1/W_i, J_{pq}(W_i))$ from simulations at different $W_i$, the intercept of the line provides the desired estimate $J_{pq}^{\\ast}$.\n\nThe computational task is to implement this protocol on synthetic data. For each test case:\n1.  A \"true\" stiffness matrix $C_{\\text{true}}^{(V)}$ is defined in GPa and converted to Pa ($1 \\text{ GPa} = 10^9 \\text{ Pa}$).\n2.  The true compliance $J_{\\text{true}} = (C_{\\text{true}}^{(V)})^{-1}$ is computed.\n3.  \"Measured\" compliance matrices $J_{\\text{meas}}(W)$ are generated for a given set of $W$ values using the specified bias model: $J_{\\text{meas}}(W) = J_{\\text{true}} (1 + \\alpha/W)$, applied element-wise.\n4.  For each element $(p,q)$, the values of $J_{\\text{meas}, pq}(W)$ are regressed against $1/W$. Since the synthetic data are generated from a perfectly linear model, a linear fit using two or more points will exactly determine the intercept. We use `numpy.polyfit` for this procedure.\n5.  The intercepts are collected to form the de-biased compliance matrix, $J^{\\ast}$. Since the data generation is exact, we expect $J^{\\ast} \\approx J_{\\text{true}}$.\n6.  The final estimated stiffness matrix is found by inverting the de-biased compliance: $C^{(V)}_{\\text{est}} = (J^{\\ast})^{-1}$.\n7.  The required components of $C^{(V)}_{\\text{est}}$ are converted from Pa back to GPa and reported.\n\nThe provided constants are: $k_B=1.380649 \\times 10^{-23} \\text{ J/K}$, $T=300 \\text{ K}$, and $V=1.0 \\times 10^{-26} \\text{ m}^3$. The values for $W$ are $[10.0, 20.0, 50.0]$ amu$\\cdot$Å$^2$. The units of $W$ and $\\alpha$ are consistent, making $\\alpha/W$ a dimensionless factor. The specific forms of $C_{\\text{true}}^{(V)}$ for cubic, hexagonal, and isotropic symmetries are constructed as described. The final implementation will process each case, perform the regression analysis, and format the output as specified.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final results.\n    \"\"\"\n    # Define constants\n    K_B = 1.380649e-23  # J/K\n    T = 300.0           # K\n    V = 1.0e-26         # m^3\n    W_VALUES = [10.0, 20.0, 50.0]\n\n    # --- Test Case Definitions ---\n    \n    # Case 1: Cubic symmetry\n    C11_1, C12_1, C44_1 = 200.0, 120.0, 80.0\n    C_true_1 = np.array([\n        [C11_1, C12_1, C12_1, 0, 0, 0],\n        [C12_1, C11_1, C12_1, 0, 0, 0],\n        [C12_1, C12_1, C11_1, 0, 0, 0],\n        [0, 0, 0, C44_1, 0, 0],\n        [0, 0, 0, 0, C44_1, 0],\n        [0, 0, 0, 0, 0, C44_1]\n    ])\n    alpha_1 = 0.40\n\n    # Case 2: Hexagonal symmetry\n    C11_2, C12_2, C13_2, C33_2, C44_2 = 160.0, 80.0, 65.0, 180.0, 50.0\n    C66_2 = (C11_2 - C12_2) / 2.0\n    C_true_2 = np.array([\n        [C11_2, C12_2, C13_2, 0, 0, 0],\n        [C12_2, C11_2, C13_2, 0, 0, 0],\n        [C13_2, C13_2, C33_2, 0, 0, 0],\n        [0, 0, 0, C44_2, 0, 0],\n        [0, 0, 0, 0, C44_2, 0],\n        [0, 0, 0, 0, 0, C66_2]\n    ])\n    alpha_2 = 0.25\n\n    # Case 3: Isotropic material\n    K_3, G_3 = 160.0, 70.0\n    lambda_3 = K_3 - (2.0 / 3.0) * G_3\n    C11_3 = lambda_3 + 2.0 * G_3\n    C12_3 = lambda_3\n    C44_3 = G_3\n    C_true_3 = np.array([\n        [C11_3, C12_3, C12_3, 0, 0, 0],\n        [C12_3, C11_3, C12_3, 0, 0, 0],\n        [C12_3, C12_3, C11_3, 0, 0, 0],\n        [0, 0, 0, C44_3, 0, 0],\n        [0, 0, 0, 0, C44_3, 0],\n        [0, 0, 0, 0, 0, C44_3]\n    ])\n    alpha_3 = 0.50\n\n    test_cases = [\n        (C_true_1, alpha_1),\n        (C_true_2, alpha_2),\n        (C_true_3, alpha_3)\n    ]\n\n    all_results = []\n\n    for C_true_gpa, alpha in test_cases:\n        result = process_case(C_true_gpa, alpha, W_VALUES, K_B, T, V)\n        all_results.append(result)\n\n    # Format the final output string\n    formatted_results = []\n    for res_list in all_results:\n        # Format each number to three decimal places\n        s_list = [f\"{val:.3f}\" for val in res_list]\n        formatted_results.append(f\"[{','.join(s_list)}]\")\n    \n    final_output = f\"[{','.join(formatted_results)}]\"\n    print(final_output)\n\ndef process_case(C_true_gpa, alpha, W_values, k_b, T, V):\n    \"\"\"\n    Processes a single test case: generates synthetic data, performs regression, \n    and returns the estimated stiffness components.\n    \n    Args:\n        C_true_gpa (np.ndarray): The 6x6 true stiffness matrix in GPa.\n        alpha (float): The bias amplitude.\n        W_values (list): List of barostat mass values.\n        k_b, T, V: Physical constants.\n\n    Returns:\n        list: A list of the 6 estimated stiffness components in GPa.\n    \"\"\"\n    # 1. Convert stiffness from GPa to Pa and compute true compliance\n    C_true_pa = C_true_gpa * 1e9\n    J_true = np.linalg.inv(C_true_pa)\n\n    # 2. Generate \"measured\" compliance data with bias\n    # The problem implies covariance Sigma_e is measured, and J is derived.\n    # J(W) = V/(k_B T) * Sigma_e(W).\n    # The synthetic bias model is applied directly to J.\n    J_measured_list = []\n    for W in W_values:\n        J_meas = J_true * (1 + alpha / W)\n        J_measured_list.append(J_meas)\n    \n    # 3. Perform linear regression for each matrix element to find the intercept\n    J_star = np.zeros((6, 6))\n    x_reg = [1.0 / W for W in W_values]\n\n    for p in range(6):\n        for q in range(6):\n            y_reg = [J_measured[p, q] for J_measured in J_measured_list]\n            \n            # np.polyfit(x, y, 1) returns [slope, intercept]\n            # Since the data is generated from a perfect line, the fit is exact.\n            slope, intercept = np.polyfit(x_reg, y_reg, 1)\n            J_star[p, q] = intercept\n\n    # 4. Invert the de-biased compliance matrix to get the estimated stiffness\n    C_est_pa = np.linalg.inv(J_star)\n\n    # 5. Convert stiffness from Pa to GPa\n    C_est_gpa = C_est_pa / 1e9\n\n    # 6. Extract and report the required components\n    # The required components are C11, C12, C13, C33, C44, C66\n    # corresponding to C[0,0], C[0,1], C[0,2], C[2,2], C[3,3], C[5,5]\n    report_components = [\n        C_est_gpa[0, 0],\n        C_est_gpa[0, 1],\n        C_est_gpa[0, 2],\n        C_est_gpa[2, 2],\n        C_est_gpa[3, 3],\n        C_est_gpa[5, 5]\n    ]\n    \n    return report_components\n\nsolve()\n\n```", "id": "3432721"}, {"introduction": "Beyond just calculating average properties, a detailed analysis of fluctuation distributions provides a rigorous test of our physical models. In this practice, you will compare the theoretically predicted distributions of crystal cell angles, based on a harmonic model, with histograms obtained from a Parrinello-Rahman simulation. By using the Jensen-Shannon divergence to quantify the match and inferring coupling terms from the covariance matrix, you will gain a deeper insight into the elastic behavior of anisotropic materials [@problem_id:3432725].", "problem": "A monoclinic crystal is simulated in the isothermal-isobaric ensemble with a Parrinello-Rahman barostat under a hydrostatic pressure $P$. In the small-fluctuation regime, the three cell angles $(\\alpha,\\beta,\\gamma)$ fluctuate around equilibrium angles $(\\alpha_0,\\beta_0,\\gamma_0)$ and can be modeled by harmonic elasticity. Let the angle deviation vector be $\\Delta \\boldsymbol{\\theta} = (\\Delta \\alpha,\\Delta \\beta,\\Delta \\gamma)^{\\mathsf{T}}$, and let the harmonic elastic energy be\n$$\nU(\\Delta \\boldsymbol{\\theta}) = \\frac{1}{2}\\,\\Delta \\boldsymbol{\\theta}^{\\mathsf{T}}\\,\\mathbf{K}\\,\\Delta \\boldsymbol{\\theta},\n$$\nwhere $\\mathbf{K}$ is a symmetric, positive-definite stiffness matrix with units of Joules per radian squared ($\\mathrm{J}/\\mathrm{rad}^2$). The thermal energy is $k_{\\mathrm{B}}T$, where $k_{\\mathrm{B}}$ is the Boltzmann constant and $T$ the absolute temperature. Assume angles are measured in radians.\n\nStarting from fundamental principles (Newtonian mechanics, Boltzmann distribution, and the harmonic approximation), the equilibrium distribution for $\\Delta \\boldsymbol{\\theta}$ is expected to be a multivariate normal distribution characterized by a covariance matrix that depends on $\\mathbf{K}$, $k_{\\mathrm{B}}$, and $T$. Marginals for each angle are normal distributions with means $(\\alpha_0,\\beta_0,\\gamma_0)$ and variances equal to the diagonal entries of the covariance matrix.\n\nYour task is to:\n- Compute the expected equilibrium marginal distributions for $(\\alpha,\\beta,\\gamma)$ under the harmonic model, and for given bin edges compute the predicted bin probabilities for each angle.\n- Compare these predictions to provided Parrinello-Rahman simulation histograms for each angle using the Jensen–Shannon divergence (dimensionless, natural logarithm base), defined for two discrete distributions $p$ and $q$ over the same bins as $D_{\\mathrm{JS}}(p\\|q)=\\frac{1}{2}D_{\\mathrm{KL}}(p\\|m)+\\frac{1}{2}D_{\\mathrm{KL}}(q\\|m)$ with $m=\\frac{1}{2}(p+q)$ and $D_{\\mathrm{KL}}(p\\|q)=\\sum_i p_i \\ln\\frac{p_i}{q_i}$.\n- Infer the off-diagonal elastic couplings (the entries $K_{12},K_{13},K_{23}$ of $\\mathbf{K}$ corresponding to $(\\alpha,\\beta)$, $(\\alpha,\\gamma)$, and $(\\beta,\\gamma)$ couplings) from provided simulation covariances of $(\\alpha,\\beta,\\gamma)$, using the harmonic-ensemble relation between covariance and stiffness.\n\nUse the following conventions and data:\n- Angles are in radians.\n- Off-diagonal elastic couplings must be reported in $\\mathrm{J}/\\mathrm{rad}^2$.\n- Hydrostatic pressure $P$ is provided for context and is not directly used in the computation of angular distributions in the harmonic approximation.\n- For bin probabilities, integrate the normal marginal distributions over each bin defined by consecutive edges.\n- For divergence, normalize histogram counts to a probability vector.\n\nFor numerical constants, use $k_{\\mathrm{B}}=1.380649\\times 10^{-23}\\,\\mathrm{J}/\\mathrm{K}$.\n\nTest suite of parameter sets and data:\n- Case 1 (happy path):\n  - $T=300\\,\\mathrm{K}$, $P=1.0\\times 10^{9}\\,\\mathrm{Pa}$.\n  - $(\\alpha_0,\\beta_0,\\gamma_0) = (1.570796,\\,1.100000,\\,1.570796)$.\n  - Stiffness matrix $\\mathbf{K} = \\begin{bmatrix}2.5\\times 10^{-18}0.3\\times 10^{-18}-0.1\\times 10^{-18}\\\\0.3\\times 10^{-18}3.0\\times 10^{-18}0.2\\times 10^{-18}\\\\-0.1\\times 10^{-18}0.2\\times 10^{-18}2.2\\times 10^{-18}\\end{bmatrix}\\,\\mathrm{J}/\\mathrm{rad}^2$.\n  - Bin specification for all three angles: center at the corresponding equilibrium angle; half-range $0.11\\,\\mathrm{rad}$; uniform bin width $0.02\\,\\mathrm{rad}$; resulting in $11$ bins and $12$ edges equally spaced.\n  - Provided Parrinello-Rahman histogram counts (per angle, corresponding to the $11$ bins):\n    - $\\alpha$: $[5,12,35,80,160,260,320,260,160,80,35]$.\n    - $\\beta$: $[2,5,20,60,140,260,300,260,140,60,20]$.\n    - $\\gamma$: $[4,10,28,70,150,240,280,240,150,70,28]$.\n  - Provided simulation covariance matrix for $(\\alpha,\\beta,\\gamma)$ in $\\mathrm{rad}^2$:\n    $$\n    \\boldsymbol{\\Sigma}_{\\mathrm{PR}}^{(1)}=\\begin{bmatrix}\n    1.60\\times 10^{-3}  2.00\\times 10^{-4}  -1.00\\times 10^{-4}\\\\\n    2.00\\times 10^{-4}  1.40\\times 10^{-3}  1.20\\times 10^{-4}\\\\\n    -1.00\\times 10^{-4}  1.20\\times 10^{-4}  1.90\\times 10^{-3}\n    \\end{bmatrix}.\n    $$\n- Case 2 (strong off-diagonal coupling):\n  - $T=150\\,\\mathrm{K}$, $P=2.0\\times 10^{9}\\,\\mathrm{Pa}$.\n  - $(\\alpha_0,\\beta_0,\\gamma_0) = (1.600000,\\,1.050000,\\,1.580000)$.\n  - Stiffness matrix $\\mathbf{K} = \\begin{bmatrix}3.2\\times 10^{-18}0.9\\times 10^{-18}0.6\\times 10^{-18}\\\\0.9\\times 10^{-18}2.6\\times 10^{-18}-0.5\\times 10^{-18}\\\\0.6\\times 10^{-18}-0.5\\times 10^{-18}2.4\\times 10^{-18}\\end{bmatrix}\\,\\mathrm{J}/\\mathrm{rad}^2$.\n  - Bin specification: half-range $0.11\\,\\mathrm{rad}$; bin width $0.02\\,\\mathrm{rad}$; $11$ bins for each angle centered at the corresponding equilibrium angle.\n  - Provided Parrinello-Rahman histogram counts:\n    - $\\alpha$: $[1,3,10,30,90,180,240,180,90,30,10]$.\n    - $\\beta$: $[1,2,8,25,80,160,220,160,80,25,8]$.\n    - $\\gamma$: $[1,3,9,28,85,170,230,170,85,28,9]$.\n  - Provided simulation covariance matrix in $\\mathrm{rad}^2$:\n    $$\n    \\boldsymbol{\\Sigma}_{\\mathrm{PR}}^{(2)}=\\begin{bmatrix}\n    9.00\\times 10^{-4}  3.50\\times 10^{-4}  2.50\\times 10^{-4}\\\\\n    3.50\\times 10^{-4}  1.00\\times 10^{-3}  -2.00\\times 10^{-4}\\\\\n    2.50\\times 10^{-4}  -2.00\\times 10^{-4}  1.10\\times 10^{-3}\n    \\end{bmatrix}.\n    $$\n- Case 3 (edge case with one very stiff angle):\n  - $T=600\\,\\mathrm{K}$, $P=5.0\\times 10^{8}\\,\\mathrm{Pa}$.\n  - $(\\alpha_0,\\beta_0,\\gamma_0) = (1.500000,\\,1.350000,\\,1.550000)$.\n  - Stiffness matrix $\\mathbf{K} = \\begin{bmatrix}1.0\\times 10^{-17}0.2\\times 10^{-18}0.0\\\\0.2\\times 10^{-18}1.5\\times 10^{-18}0.3\\times 10^{-18}\\\\0.00.3\\times 10^{-18}1.2\\times 10^{-18}\\end{bmatrix}\\,\\mathrm{J}/\\mathrm{rad}^2$.\n  - Bin specification: half-range $0.11\\,\\mathrm{rad}$; bin width $0.02\\,\\mathrm{rad}$; $11$ bins for each angle centered at the corresponding equilibrium angle.\n  - Provided Parrinello-Rahman histogram counts:\n    - $\\alpha$: $[3,8,20,60,140,260,320,260,140,60,20]$.\n    - $\\beta$: $[5,12,30,70,140,220,260,220,140,70,30]$.\n    - $\\gamma$: $[6,14,32,75,150,240,300,240,150,75,32]$.\n  - Provided simulation covariance matrix in $\\mathrm{rad}^2$:\n    $$\n    \\boldsymbol{\\Sigma}_{\\mathrm{PR}}^{(3)}=\\begin{bmatrix}\n    8.00\\times 10^{-4}  1.00\\times 10^{-4}  0.00\\\\\n    1.00\\times 10^{-4}  5.00\\times 10^{-3}  3.00\\times 10^{-4}\\\\\n    0.00  3.00\\times 10^{-4}  4.00\\times 10^{-3}\n    \\end{bmatrix}.\n    $$\n\nAlgorithmic tasks:\n- For each case, compute the diagonal variances from the relation between covariance and stiffness and evaluate the normal marginal distributions for $(\\alpha,\\beta,\\gamma)$.\n- For each angle, compute predicted bin probabilities by integrating the normal distribution over the bins defined by the given edges.\n- Normalize the provided histogram counts for each angle and compute the Jensen–Shannon divergence between the normalized histogram and predicted probabilities.\n- For each case, compute the estimate $\\mathbf{K}_{\\mathrm{est}}$ from the provided simulation covariance $\\boldsymbol{\\Sigma}_{\\mathrm{PR}}$ via $\\mathbf{K}_{\\mathrm{est}} = k_{\\mathrm{B}}T\\,\\boldsymbol{\\Sigma}_{\\mathrm{PR}}^{-1}$ and report the off-diagonal entries $(K_{12},K_{13},K_{23})$ in $\\mathrm{J}/\\mathrm{rad}^2$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For each case, append in order the three Jensen–Shannon divergence values $(\\alpha,\\beta,\\gamma)$ followed by the three off-diagonal couplings $(K_{12},K_{13},K_{23})$, resulting in a flat list with $6$ values per case and $18$ values total. For example: \"[d_alpha_case1,d_beta_case1,d_gamma_case1,K12_case1,K13_case1,K23_case1,d_alpha_case2,...,K23_case3]\".", "solution": "The problem is scientifically valid, well-posed, and contains all necessary information to derive a unique solution. It is grounded in the principles of statistical mechanics as applied to molecular dynamics simulations. We first validate the problem's premises and then proceed with a step-by-step solution.\n\n**Problem Validation**\n\n1.  **Givens Extraction**: All data, including temperatures ($T$), equilibrium angles ($\\alpha_0, \\beta_0, \\gamma_0$), theoretical stiffness matrices ($\\mathbf{K}$), binning specifications, histogram counts, and simulation covariance matrices ($\\boldsymbol{\\Sigma}_{\\mathrm{PR}}$) for three distinct cases, are provided explicitly. The value of the Boltzmann constant $k_{\\mathrm{B}}$ is given.\n\n2.  **Validation against Criteria**:\n    *   **Scientific Grounding**: The problem is built upon the solid foundation of the canonical or isothermal-isobaric ensemble in statistical mechanics. The core idea is that the probability of a system state is governed by the Boltzmann factor, $e^{-E/(k_{\\mathrm{B}}T)}$. For small fluctuations around a mechanical equilibrium, the potential energy can be approximated by a harmonic potential, $U(\\Delta \\boldsymbol{\\theta}) = \\frac{1}{2}\\,\\Delta \\boldsymbol{\\theta}^{\\mathsf{T}}\\,\\mathbf{K}\\,\\Delta \\boldsymbol{\\theta}$, where $\\Delta \\boldsymbol{\\theta}$ represents deviations from equilibrium. This leads to a multivariate normal distribution for the fluctuations. The relationship derived from this, $\\boldsymbol{\\Sigma} = k_{\\mathrm{B}}T\\,\\mathbf{K}^{-1}$, is a standard result in statistical physics, representing a specific instance of the fluctuation-dissipation theorem. The use of Jensen-Shannon divergence is a standard method in information theory for comparing probability distributions. All physical quantities and their units are consistent.\n    *   **Well-Posed and Consistent**: The problem requires two sets of calculations. The first is predictive: given a model ($\\mathbf{K}$), predict observables (bin probabilities) and compare them to simulation data (histograms). The second is inferential: given simulation data ($\\boldsymbol{\\Sigma}_{\\mathrm{PR}}$), infer the model parameters ($\\mathbf{K}_{\\mathrm{est}}$). These tasks are distinct, well-defined, and do not contradict each other. They represent a typical workflow in computational physics where a theoretical model is tested against simulation results. The given stiffness matrices $\\mathbf{K}$ are stated to be symmetric and positive-definite, and the simulation covariance matrices $\\boldsymbol{\\Sigma}_{\\mathrm{PR}}$, being derived from data, are also expected to be so. This ensures that the required matrix inversions are mathematically sound.\n\n3.  **Verdict**: The problem is valid.\n\n**Theoretical Framework**\n\nThe probability distribution of the angle deviation vector $\\Delta\\boldsymbol{\\theta} = (\\Delta\\alpha, \\Delta\\beta, \\Delta\\gamma)^{\\mathsf{T}}$ in the harmonic approximation is given by the Boltzmann distribution:\n$$\np(\\Delta\\boldsymbol{\\theta}) = \\frac{1}{Z} \\exp\\left(-\\frac{U(\\Delta\\boldsymbol{\\theta})}{k_{\\mathrm{B}}T}\\right)\n$$\nwhere $Z$ is the normalization constant (partition function), $k_{\\mathrm{B}}$ is the Boltzmann constant, $T$ is the absolute temperature, and $U$ is the harmonic potential energy:\n$$\nU(\\Delta \\boldsymbol{\\theta}) = \\frac{1}{2}\\,\\Delta \\boldsymbol{\\theta}^{\\mathsf{T}}\\,\\mathbf{K}\\,\\Delta \\boldsymbol{\\theta}\n$$\nSubstituting the potential energy expression, we get:\n$$\np(\\Delta\\boldsymbol{\\theta}) = \\frac{1}{Z} \\exp\\left(-\\frac{1}{2k_{\\mathrm{B}}T}\\,\\Delta \\boldsymbol{\\theta}^{\\mathsf{T}}\\,\\mathbf{K}\\,\\Delta \\boldsymbol{\\theta}\\right)\n$$\nThis is the probability density function (PDF) of a multivariate normal distribution with zero mean ($\\boldsymbol{\\mu} = \\mathbf{0}$) and a covariance matrix $\\boldsymbol{\\Sigma}$ whose inverse is $\\boldsymbol{\\Sigma}^{-1} = \\mathbf{K}/(k_{\\mathrm{B}}T)$.\nTherefore, the covariance matrix of the angle fluctuations is given by:\n$$\n\\boldsymbol{\\Sigma} = k_{\\mathrm{B}}T\\,\\mathbf{K}^{-1}\n$$\nThis fundamental relationship connects the mechanical stiffness of the system ($\\mathbf{K}$) to the statistical fluctuations ($\\boldsymbol{\\Sigma}$) at a given temperature. The distribution of the absolute angles $(\\alpha, \\beta, \\gamma)$ is also a multivariate normal distribution with mean $(\\alpha_0, \\beta_0, \\gamma_0)$ and the same covariance matrix $\\boldsymbol{\\Sigma}$.\n\nThe problem is divided into two main tasks for each case:\n\n**Task 1: Computing Jensen–Shannon Divergence**\n\n1.  **Calculate Theoretical Covariance**: Using the provided stiffness matrix $\\mathbf{K}$ and temperature $T$, we compute the theoretical covariance matrix $\\boldsymbol{\\Sigma}_{\\mathrm{th}} = k_{\\mathrm{B}}T\\,\\mathbf{K}^{-1}$.\n2.  **Marginal Distributions**: The marginal distribution for each angle (e.g., $\\alpha$) is a normal distribution with mean $\\alpha_0$ and variance $\\sigma_\\alpha^2 = (\\boldsymbol{\\Sigma}_{\\mathrm{th}})_{11}$, the first diagonal element of $\\boldsymbol{\\Sigma}_{\\mathrm{th}}$.\n3.  **Predicted Bin Probabilities**: For each angle, we define a set of bins according to the problem specification. The theoretical probability of an angle falling into a bin with edges $[e_i, e_{i+1}]$ is calculated by integrating the normal PDF over that interval. This is most efficiently computed as the difference in the cumulative distribution function (CDF): $p_i = \\mathrm{CDF}(e_{i+1}) - \\mathrm{CDF}(e_i)$. This gives a vector of predicted probabilities, $p$.\n4.  **Simulation Probabilities**: The provided histogram counts are normalized by their sum to obtain a discrete probability distribution, $q$.\n5.  **Jensen–Shannon Divergence**: The divergence between the predicted distribution $p$ and the simulation-derived distribution $q$ is calculated using the formula $D_{\\mathrm{JS}}(p\\|q)=\\frac{1}{2}D_{\\mathrm{KL}}(p\\|m)+\\frac{1}{2}D_{\\mathrm{KL}}(q\\|m)$, where $m=\\frac{1}{2}(p+q)$ and $D_{\\mathrm{KL}}(p\\|q)=\\sum_i p_i \\ln(p_i/q_i)$.\n\n**Task 2: Inferring Off-Diagonal Elastic Couplings**\n\n1.  **Estimate Stiffness Matrix**: We use the simulation-derived covariance matrix $\\boldsymbol{\\Sigma}_{\\mathrm{PR}}$ and the temperature $T$ to infer the stiffness matrix that is most consistent with the simulation data. This is done by inverting the fundamental relationship: $\\mathbf{K}_{\\mathrm{est}} = k_{\\mathrm{B}}T\\,\\boldsymbol{\\Sigma}_{\\mathrm{PR}}^{-1}$.\n2.  **Extract Couplings**: The off-diagonal elements of $\\mathbf{K}_{\\mathrm{est}}$ represent the inferred inter-angle elastic couplings. We extract $K_{12} = (\\mathbf{K}_{\\mathrm{est}})_{0,1}$, $K_{13} = (\\mathbf{K}_{\\mathrm{est}})_{0,2}$, and $K_{23} = (\\mathbf{K}_{\\mathrm{est}})_{1,2}$ (using 0-based indexing).\n\nThis procedure is applied to each of the three test cases provided.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\nfrom scipy.special import rel_entr\n\ndef solve():\n    \"\"\"\n    Solves the problem for all given test cases.\n    \"\"\"\n    k_B = 1.380649e-23  # Boltzmann constant in J/K\n\n    def analyze_case(T, means, K_theory, bin_spec, hist_counts, Sigma_sim):\n        \"\"\"\n        Performs the full analysis for a single case.\n        \n        Returns:\n            A list containing 3 JS divergence values and 3 inferred couplings.\n        \"\"\"\n        # --- Part A: Jensen-Shannon Divergence Calculation ---\n        \n        # 1. Compute theoretical covariance matrix from theoretical K\n        Sigma_theory = k_B * T * np.linalg.inv(K_theory)\n        \n        variances = np.diag(Sigma_theory)\n        stds = np.sqrt(variances)\n        \n        js_divergences = []\n        \n        for i in range(3):  # For each angle alpha, beta, gamma\n            # 2. Define bin edges\n            mean = means[i]\n            half_range = bin_spec['half_range']\n            width = bin_spec['bin_width']\n            num_bins = int(round(2 * half_range / width))\n            edges = np.linspace(mean - half_range, mean + half_range, num_bins + 1)\n            \n            # 3. Compute theoretical bin probabilities (p)\n            cdf_vals = norm.cdf(edges, loc=mean, scale=stds[i])\n            p = np.diff(cdf_vals)\n            p /= np.sum(p)  # Normalize to ensure sum is 1\n            \n            # 4. Normalize histogram counts to get simulation probabilities (q)\n            q = np.array(hist_counts[i], dtype=float)\n            q /= np.sum(q)\n            \n            # 5. Compute Jensen-Shannon divergence\n            m = 0.5 * (p + q)\n            kl_pm = np.sum(rel_entr(p, m))\n            kl_qm = np.sum(rel_entr(q, m))\n            jsd = 0.5 * kl_pm + 0.5 * kl_qm\n            js_divergences.append(jsd)\n\n        # --- Part B: Infer Off-Diagonal Couplings ---\n\n        # 1. Compute estimated stiffness matrix K_est from simulation Sigma\n        K_est = k_B * T * np.linalg.inv(Sigma_sim)\n        \n        # 2. Extract off-diagonal couplings\n        k12_est = K_est[0, 1]\n        k13_est = K_est[0, 2]\n        k23_est = K_est[1, 2]\n        couplings = [k12_est, k13_est, k23_est]\n        \n        return js_divergences + couplings\n\n    # --- Test Case Data ---\n    \n    test_cases = [\n        # Case 1\n        {\n            \"T\": 300.0,\n            \"means\": (1.570796, 1.100000, 1.570796),\n            \"K_theory\": np.array([\n                [2.5e-18, 0.3e-18, -0.1e-18],\n                [0.3e-18, 3.0e-18, 0.2e-18],\n                [-0.1e-18, 0.2e-18, 2.2e-18]\n            ]),\n            \"bin_spec\": {\"half_range\": 0.11, \"bin_width\": 0.02},\n            \"hist_counts\": [\n                [5, 12, 35, 80, 160, 260, 320, 260, 160, 80, 35],\n                [2, 5, 20, 60, 140, 260, 300, 260, 140, 60, 20],\n                [4, 10, 28, 70, 150, 240, 280, 240, 150, 70, 28]\n            ],\n            \"Sigma_sim\": np.array([\n                [1.60e-3, 2.00e-4, -1.00e-4],\n                [2.00e-4, 1.40e-3, 1.20e-4],\n                [-1.00e-4, 1.20e-4, 1.90e-3]\n            ])\n        },\n        # Case 2\n        {\n            \"T\": 150.0,\n            \"means\": (1.600000, 1.050000, 1.580000),\n            \"K_theory\": np.array([\n                [3.2e-18, 0.9e-18, 0.6e-18],\n                [0.9e-18, 2.6e-18, -0.5e-18],\n                [0.6e-18, -0.5e-18, 2.4e-18]\n            ]),\n            \"bin_spec\": {\"half_range\": 0.11, \"bin_width\": 0.02},\n            \"hist_counts\": [\n                [1, 3, 10, 30, 90, 180, 240, 180, 90, 30, 10],\n                [1, 2, 8, 25, 80, 160, 220, 160, 80, 25, 8],\n                [1, 3, 9, 28, 85, 170, 230, 170, 85, 28, 9]\n            ],\n            \"Sigma_sim\": np.array([\n                [9.00e-4, 3.50e-4, 2.50e-4],\n                [3.50e-4, 1.00e-3, -2.00e-4],\n                [2.50e-4, -2.00e-4, 1.10e-3]\n            ])\n        },\n        # Case 3\n        {\n            \"T\": 600.0,\n            \"means\": (1.500000, 1.350000, 1.550000),\n            \"K_theory\": np.array([\n                [1.0e-17, 0.2e-18, 0.0],\n                [0.2e-18, 1.5e-18, 0.3e-18],\n                [0.0, 0.3e-18, 1.2e-18]\n            ]),\n            \"bin_spec\": {\"half_range\": 0.11, \"bin_width\": 0.02},\n            \"hist_counts\": [\n                [3, 8, 20, 60, 140, 260, 320, 260, 140, 60, 20],\n                [5, 12, 30, 70, 140, 220, 260, 220, 140, 70, 30],\n                [6, 14, 32, 75, 150, 240, 300, 240, 150, 75, 32]\n            ],\n            \"Sigma_sim\": np.array([\n                [8.00e-4, 1.00e-4, 0.00],\n                [1.00e-4, 5.00e-3, 3.00e-4],\n                [0.00, 3.00e-4, 4.00e-3]\n            ])\n        }\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        results = analyze_case(**case_data)\n        all_results.extend(results)\n\n    # Final print statement in the exact required format.\n    # Using .6e for scientific notation with 6 decimal places.\n    print(f\"[{','.join(f'{x:.6e}' for x in all_results)}]\")\n\nsolve()\n```", "id": "3432725"}]}