{"hands_on_practices": [{"introduction": "The foundation of any molecular mechanics force field lies in its description of bonded interactions, which dictate the local geometry of molecules. This first practice explores how the parameters for bond stretching and angle bending are derived by fitting to a high-level potential energy surface. By approximating the complex quantum mechanical energy landscape with a simple harmonic function, we can directly relate the classical force constants, such as $k_b$ and $k_{\\theta}$, to the curvature of the surface at the equilibrium geometry, a fundamental connection demonstrated in this exercise [@problem_id:3432394].", "problem": "Consider a triatomic molecule with one bond length $r$ and one bond angle $\\theta$ as the relevant internal coordinates for a simple valence force field in Molecular Dynamics (MD). At the equilibrium geometry $(r_0,\\theta_0)$, a constrained electronic-structure scan is performed in which only one internal coordinate is displaced at a time while the other is held at its equilibrium value. The resulting potential energy differences relative to the minimum, $\\Delta E \\equiv E(r,\\theta)-E(r_0,\\theta_0)$, are reported below.\n\nBond-length scan (with $\\theta=\\theta_0$ fixed):\n- $\\Delta r = r-r_0 = \\pm 0.010$ nm gives $\\Delta E = 0.0750$ kJ mol$^{-1}$,\n- $\\Delta r = \\pm 0.020$ nm gives $\\Delta E = 0.3000$ kJ mol$^{-1}$,\n- $\\Delta r = \\pm 0.030$ nm gives $\\Delta E = 0.6750$ kJ mol$^{-1}$.\n\nAngle scan (with $r=r_0$ fixed):\n- $\\Delta \\theta = \\theta-\\theta_0 = \\pm 0.05$ rad gives $\\Delta E = 0.4375$ kJ mol$^{-1}$,\n- $\\Delta \\theta = \\pm 0.08$ rad gives $\\Delta E = 1.1200$ kJ mol$^{-1}$,\n- $\\Delta \\theta = \\pm 0.10$ rad gives $\\Delta E = 1.7500$ kJ mol$^{-1}$.\n\nStarting from the definition of a Taylor expansion of the potential energy $E(r,\\theta)$ about the minimum in internal coordinates and the condition that the gradient vanishes at the minimum, derive how the curvature along $r$ and the curvature along $\\theta$ define the harmonic valence force constants in the internal-coordinate representation used in a valence force field. Under the usual small-displacement assumptions, estimate the bond-stretch force constant $k_b$ and the angle-bend force constant $k_{\\theta}$ from the data above.\n\nDiscuss the physical approximations involved in making these estimates, including any assumptions about coupling between internal coordinates and the truncation of the Taylor series.\n\nRound your numerical estimates to four significant figures. Report $k_b$ in kJ mol$^{-1}$ nm$^{-2}$ and $k_{\\theta}$ in kJ mol$^{-1}$ rad$^{-2}$. Provide both values in your final answer as a row matrix in the order $(k_b, k_{\\theta})$, using the LaTeX $\\texttt{pmatrix}$ environment.", "solution": "The problem is first validated against the established criteria.\n\n### Problem Validation\n\n**Step 1: Extract Givens**\n\n*   **System**: A triatomic molecule with internal coordinates: one bond length $r$ and one bond angle $\\theta$.\n*   **Equilibrium Geometry**: $(r_0, \\theta_0)$.\n*   **Potential Energy Definition**: $\\Delta E \\equiv E(r,\\theta)-E(r_0,\\theta_0)$.\n*   **Bond-Length Scan Data** (at fixed $\\theta=\\theta_0$):\n    *   For displacement $\\Delta r = r-r_0 = \\pm 0.010$ nm, the energy change is $\\Delta E = 0.0750$ kJ mol$^{-1}$.\n    *   For displacement $\\Delta r = \\pm 0.020$ nm, the energy change is $\\Delta E = 0.3000$ kJ mol$^{-1}$.\n    *   For displacement $\\Delta r = \\pm 0.030$ nm, the energy change is $\\Delta E = 0.6750$ kJ mol$^{-1}$.\n*   **Angle Scan Data** (at fixed $r=r_0$):\n    *   For displacement $\\Delta \\theta = \\theta-\\theta_0 = \\pm 0.05$ rad, the energy change is $\\Delta E = 0.4375$ kJ mol$^{-1}$.\n    *   For displacement $\\Delta \\theta = \\pm 0.08$ rad, the energy change is $\\Delta E = 1.1200$ kJ mol$^{-1}$.\n    *   For displacement $\\Delta \\theta = \\pm 0.10$ rad, the energy change is $\\Delta E = 1.7500$ kJ mol$^{-1}$.\n*   **Required Tasks**:\n    1.  Derive the relationship between potential energy curvature and harmonic force constants.\n    2.  Estimate the bond-stretch force constant $k_b$ (in kJ mol$^{-1}$ nm$^{-2}$) and the angle-bend force constant $k_{\\theta}$ (in kJ mol$^{-1}$ rad$^{-2}$).\n    3.  Discuss the physical approximations involved.\n    4.  Round numerical estimates to four significant figures.\n    5.  Report the final answer as a row matrix $(k_b, k_{\\theta})$.\n\n**Step 2: Validate Using Extracted Givens**\n\n*   **Scientifically Grounded**: The problem is based on the standard and fundamental procedure for parameterizing classical molecular mechanics force fields from quantum mechanical potential energy surface scans. The concepts of Taylor expansion, harmonic approximation, and force constants are central to physical chemistry and computational modeling. The data values are physically plausible.\n*   **Well-Posed**: The problem provides sufficient, consistent data to determine the requested parameters under the specified harmonic approximation. A unique solution exists.\n*   **Objective**: The problem is stated in precise, quantitative, and unbiased language.\n\n**Step 3: Verdict and Action**\n\nThe problem is scientifically sound, well-posed, and objective. It is deemed **valid**. A full solution will be provided.\n\n### Solution\n\nThe potential energy surface $E(r, \\theta)$ of the triatomic molecule can be approximated by a Taylor series expansion around the equilibrium geometry $(r_0, \\theta_0)$. Let $\\Delta r = r-r_0$ and $\\Delta \\theta = \\theta-\\theta_0$. The expansion is:\n$$\nE(r, \\theta) = E(r_0, \\theta_0) + \\left(\\frac{\\partial E}{\\partial r}\\right)_0 \\Delta r + \\left(\\frac{\\partial E}{\\partial \\theta}\\right)_0 \\Delta \\theta + \\frac{1}{2}\\left(\\frac{\\partial^2 E}{\\partial r^2}\\right)_0 (\\Delta r)^2 + \\frac{1}{2}\\left(\\frac{\\partial^2 E}{\\partial \\theta^2}\\right)_0 (\\Delta \\theta)^2 + \\left(\\frac{\\partial^2 E}{\\partial r \\partial \\theta}\\right)_0 \\Delta r \\Delta \\theta + \\mathcal{O}(3)\n$$\nwhere the subscript $0$ denotes evaluation at the equilibrium point $(r_0, \\theta_0)$, and $\\mathcal{O}(3)$ represents terms of third order and higher in the displacements.\n\nBy definition, the equilibrium geometry corresponds to a minimum on the potential energy surface. At a minimum, the gradient of the potential energy vanishes. Therefore, the first-order derivative terms are zero:\n$$\n\\left(\\frac{\\partial E}{\\partial r}\\right)_0 = 0 \\quad \\text{and} \\quad \\left(\\frac{\\partial E}{\\partial \\theta}\\right)_0 = 0\n$$\nRearranging the Taylor series to express the energy difference $\\Delta E = E(r, \\theta) - E(r_0, \\theta_0)$ and truncating at the second-order terms (the harmonic approximation), we get:\n$$\n\\Delta E \\approx \\frac{1}{2}\\left(\\frac{\\partial^2 E}{\\partial r^2}\\right)_0 (\\Delta r)^2 + \\frac{1}{2}\\left(\\frac{\\partial^2 E}{\\partial \\theta^2}\\right)_0 (\\Delta \\theta)^2 + \\left(\\frac{\\partial^2 E}{\\partial r \\partial \\theta}\\right)_0 \\Delta r \\Delta \\theta\n$$\nA simple valence force field models the potential energy associated with bond stretching and angle bending using harmonic functions:\n$$\nE_{VFF} = E_0 + \\frac{1}{2} k_b (r-r_0)^2 + \\frac{1}{2} k_{\\theta} (\\theta-\\theta_0)^2\n$$\nor in terms of displacements, $\\Delta E_{VFF} = \\frac{1}{2} k_b (\\Delta r)^2 + \\frac{1}{2} k_{\\theta} (\\Delta \\theta)^2$.\n\nBy comparing the truncated Taylor expansion with the valence force field energy expression, we can identify the force constants as the second derivatives (curvatures) of the potential energy surface at the equilibrium geometry:\n$$\nk_b = \\left(\\frac{\\partial^2 E}{\\partial r^2}\\right)_0 \\quad \\text{and} \\quad k_{\\theta} = \\left(\\frac{\\partial^2 E}{\\partial \\theta^2}\\right)_0\n$$\nThis derivation explicitly assumes that the coupling term, characterized by the mixed partial derivative $\\left(\\frac{\\partial^2 E}{\\partial r \\partial \\theta}\\right)_0$, is negligible.\n\nWe now estimate these force constants using the provided data.\n\n**Estimation of the Bond-Stretch Force Constant, $k_b$**\n\nThe bond-length scan is performed with $\\theta = \\theta_0$, which means $\\Delta \\theta = 0$. Under this condition, the energy expression simplifies to:\n$$\n\\Delta E = \\frac{1}{2} k_b (\\Delta r)^2\n$$\nThis can be rearranged to solve for $k_b$:\n$$\nk_b = \\frac{2 \\Delta E}{(\\Delta r)^2}\n$$\nWe can use any of the provided data points to calculate $k_b$. Let's use the first data point: $\\Delta r = 0.010$ nm and $\\Delta E = 0.0750$ kJ mol$^{-1}$.\n$$\nk_b = \\frac{2 \\times (0.0750 \\text{ kJ mol}^{-1})}{(0.010 \\text{ nm})^2} = \\frac{0.1500 \\text{ kJ mol}^{-1}}{0.0001 \\text{ nm}^2} = 1500 \\text{ kJ mol}^{-1} \\text{nm}^{-2}\n$$\nChecking the other data points confirms this value:\nFor $\\Delta r = 0.020$ nm: $k_b = \\frac{2 \\times 0.3000}{0.0004} = 1500$ kJ mol$^{-1}$ nm$^{-2}$.\nFor $\\Delta r = 0.030$ nm: $k_b = \\frac{2 \\times 0.6750}{0.0009} = 1500$ kJ mol$^{-1}$ nm$^{-2}$.\nThe data perfectly fits a quadratic potential, so our estimate for $k_b$ is $1500$ kJ mol$^{-1}$ nm$^{-2}$. Expressed to four significant figures, this is $1.500 \\times 10^3$ kJ mol$^{-1}$ nm$^{-2}$.\n\n**Estimation of the Angle-Bend Force Constant, $k_{\\theta}$**\n\nThe angle scan is performed with $r = r_0$, which means $\\Delta r = 0$. The energy expression simplifies to:\n$$\n\\Delta E = \\frac{1}{2} k_{\\theta} (\\Delta \\theta)^2\n$$\nRearranging for $k_{\\theta}$:\n$$\nk_{\\theta} = \\frac{2 \\Delta E}{(\\Delta \\theta)^2}\n$$\nUsing the first data point: $\\Delta \\theta = 0.05$ rad and $\\Delta E = 0.4375$ kJ mol$^{-1}$.\n$$\nk_{\\theta} = \\frac{2 \\times (0.4375 \\text{ kJ mol}^{-1})}{(0.05 \\text{ rad})^2} = \\frac{0.875 \\text{ kJ mol}^{-1}}{0.0025 \\text{ rad}^2} = 350 \\text{ kJ mol}^{-1} \\text{rad}^{-2}\n$$\nChecking the other data points:\nFor $\\Delta \\theta = 0.08$ rad: $k_{\\theta} = \\frac{2 \\times 1.1200}{0.0064} = 350$ kJ mol$^{-1}$ rad$^{-2}$.\nFor $\\Delta \\theta = 0.10$ rad: $k_{\\theta} = \\frac{2 \\times 1.7500}{0.01} = 350$ kJ mol$^{-1}$ rad$^{-2}$.\nAgain, the data perfectly represents a harmonic potential. Our estimate for $k_{\\theta}$ is $350$ kJ mol$^{-1}$ rad$^{-2}$. To four significant figures, this is $350.0$ kJ mol$^{-1}$ rad$^{-2}$.\n\n**Discussion of Physical Approximations**\n\n1.  **Harmonic Approximation**: The primary approximation is the truncation of the Taylor series at the quadratic term. Real molecular potentials are anharmonic. For example, the bond-stretching potential is better described by functions like the Morse potential, which accounts for bond dissociation at large separations. The harmonic potential is only accurate for very small displacements from equilibrium. The fact that the provided data shows a perfect quadratic relationship ($\\Delta E \\propto (\\text{displacement})^2$) is an idealization; real electronic structure data would show deviations from this behavior, indicating the presence of higher-order (cubic, quartic, etc.) terms.\n\n2.  **Neglect of Coupling**: The simple valence force field and the calculation method assume that the bond stretch and angle bend motions are independent. This corresponds to setting the mixed-derivative term $\\left(\\frac{\\partial^2 E}{\\partial r \\partial \\theta}\\right)_0$, also known as the stretch-bend coupling constant $k_{r\\theta}$, to zero. In reality, these motions are coupled. For example, as a bond angle in a triatomic molecule decreases, the repulsion between the two terminal atoms increases, which can in turn affect the equilibrium lengths of the bonds connected to the central atom. The experimental design of scanning one coordinate while keeping the other fixed at its equilibrium value is specifically designed to probe the diagonal elements of the Hessian matrix (the matrix of second derivatives), and provides no information about the off-diagonal (coupling) terms.\n\n3.  **Idealized Data**: The problem provides data where the energy is identical for positive and negative displacements (e.g., $\\Delta r = \\pm 0.010$ nm). This implies the potential is perfectly symmetric about the minimum, which is only true if all odd-powered terms in the Taylor expansion are zero. While the first derivative is zero at the minimum, the third derivative is generally non-zero, leading to an asymmetric potential well. The provided data is thus artificially symmetric and perfectly quadratic, a convenience for this exercise that does not reflect the complexity of a true potential energy surface.", "answer": "$$\n\\boxed{\\begin{pmatrix} 1.500 \\times 10^3 & 350.0 \\end{pmatrix}}\n$$", "id": "3432394"}, {"introduction": "While bonded terms define local structure, non-bonded interactions govern molecular recognition, aggregation, and bulk properties. Parameterizing these interactions introduces new challenges, as their long-range nature makes them computationally expensive. This practice explores how the necessary truncation of these interactions can systematically bias the resulting parameters, a critical consideration in developing and applying force fields. This exercise [@problem_id:3432370] provides a direct investigation into how different truncation schemes for the Lennard-Jones potential cause the fitted parameters, $\\epsilon$ and $\\sigma$, to compensate for the missing long-range contributions.", "problem": "Consider a pairwise-additive nonbonded interaction modeled by the Lennard-Jones (LJ) potential, which is widely used in Molecular Dynamics (MD). The LJ energy for a particle pair at separation $r$ is defined as\n$$\nV_{\\mathrm{LJ}}(r;\\epsilon,\\sigma) = 4\\,\\epsilon\\left[\\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^{6}\\right],\n$$\nwhere $\\epsilon$ is the well depth and $\\sigma$ is the characteristic distance at which the potential crosses zero. In advanced parameterization strategies for force fields, applying truncation schemes to $V_{\\mathrm{LJ}}$ can bias fitted parameters $\\epsilon$ and $\\sigma$. Two widely used truncation schemes are:\n\n1. Energy shifting at cutoff $r_c$:\n$$\nV_{\\mathrm{shift}}(r;\\epsilon,\\sigma,r_c) = \n\\begin{cases}\nV_{\\mathrm{LJ}}(r;\\epsilon,\\sigma) - V_{\\mathrm{LJ}}(r_c;\\epsilon,\\sigma), & r < r_c,\\\\\n0, & r \\ge r_c,\n\\end{cases}\n$$\nwhich ensures continuity of the energy at $r_c$.\n\n2. Smooth switching between $r_s$ and $r_c$:\n$$\nV_{\\mathrm{switch}}(r;\\epsilon,\\sigma,r_s,r_c) = S(r;r_s,r_c)\\,V_{\\mathrm{LJ}}(r;\\epsilon,\\sigma),\n$$\nwhere the switching function $S(r;r_s,r_c)$ satisfies $S(r)=1$ for $r \\le r_s$, $S(r)=0$ for $r \\ge r_c$, and transitions smoothly for $r_s < r < r_c$. A commonly used quintic polynomial that guarantees continuity of the function and its first and second derivatives at $r_s$ and $r_c$ is\n$$\nS(r;r_s,r_c) = \n\\begin{cases}\n1, & r \\le r_s,\\\\\n1 - 10x^3 + 15x^4 - 6x^5, & r_s < r < r_c,\\\\\n0, & r \\ge r_c,\n\\end{cases}\n$$\nwith the reduced coordinate\n$$\nx = \\frac{r - r_s}{r_c - r_s}.\n$$\n\nSuppose that the infinite-range reference data is generated from $V_{\\mathrm{LJ}}(r;\\epsilon_0,\\sigma_0)$ with known $(\\epsilon_0,\\sigma_0)$. We wish to quantify how fitting $\\epsilon$ and $\\sigma$ using truncated models $V_{\\mathrm{shift}}$ or $V_{\\mathrm{switch}}$ on the same data range biases the parameters. Your derivation and implementation must begin from fundamental principles: pairwise-additive potential energy representation, the definition of the Lennard-Jones potential, and the formulation of parameter estimation as a Least Squares (LS) problem.\n\nYou must estimate $(\\epsilon,\\sigma)$ by minimizing the unweighted sum of squared residuals between the truncated model and the infinite-range reference energies over a training set of distances $\\{r_i\\}$,\n$$\n\\min_{\\epsilon>0,\\ \\sigma>0} \\sum_{i=1}^{N} \\left[V_{\\mathrm{trunc}}(r_i;\\epsilon,\\sigma) - V_{\\mathrm{LJ}}(r_i;\\epsilon_0,\\sigma_0)\\right]^2,\n$$\nwhere $V_{\\mathrm{trunc}}$ is either $V_{\\mathrm{shift}}$ or $V_{\\mathrm{switch}}$, depending on the truncation scheme. Use distances uniformly spaced over the interval $[r_{\\min}, r_c]$ for training. All quantities must be expressed in reduced, dimensionless units: distances in units of $\\sigma_0$ and energies in units of $\\epsilon_0$.\n\nDefine the compensation biases as the relative deviations\n$$\n\\Delta_\\epsilon = \\frac{\\epsilon^\\ast - \\epsilon_0}{\\epsilon_0},\\qquad\n\\Delta_\\sigma = \\frac{\\sigma^\\ast - \\sigma_0}{\\sigma_0},\n$$\nwhere $(\\epsilon^\\ast,\\sigma^\\ast)$ are the fitted parameters. Your program must compute $(\\Delta_\\epsilon,\\Delta_\\sigma)$ for each specified test case and report them.\n\nConstraints and implementation details:\n- Use $N=200$ training distances uniformly in $[r_{\\min}, r_c]$ with $r_{\\min}=0.9\\,\\sigma_0$.\n- Use $(\\epsilon_0,\\sigma_0)=(1.0,1.0)$ in reduced units.\n- When the switching scheme is selected, ensure $r_s < r_c$ and use the quintic switching function defined above.\n- Fit parameters $(\\epsilon,\\sigma)$ via a bound-constrained Least Squares method with positivity constraints $\\epsilon>0$ and $\\sigma>0$.\n- Compute and return $(\\Delta_\\epsilon,\\Delta_\\sigma)$ rounded to $6$ decimal places for each test case.\n\nTest suite:\n- Case $1$: Energy shifting scheme with $r_c=1.6$.\n- Case $2$: Switching scheme with $r_s=1.2$, $r_c=1.6$.\n- Case $3$: Energy shifting scheme with $r_c=3.0$ (weak truncation, near-infinite range).\n- Case $4$: Switching scheme with $r_s=2.5$, $r_c=3.0$ (late switching, weak truncation).\n- Case $5$: Energy shifting scheme with $r_c=1.3$ (strong truncation).\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case result is itself a two-element list $[\\Delta_\\epsilon,\\Delta_\\sigma]$ with each number rounded to $6$ decimal places. For example, produce an output of the form\n$$\n[[\\Delta_{\\epsilon}^{(1)},\\Delta_{\\sigma}^{(1)}],[\\Delta_{\\epsilon}^{(2)},\\Delta_{\\sigma}^{(2)}],\\dots]\n$$\nwhere the superscript denotes the case index. All outputs must be in reduced, dimensionless units as specified above.", "solution": "The problem requires the quantification of parameter-fitting bias introduced by truncating the Lennard-Jones (LJ) potential. Specifically, we are asked to fit the parameters $(\\epsilon, \\sigma)$ of a truncated LJ model to reference data generated by a full, infinite-range LJ potential, $V_{\\mathrm{LJ}}(r;\\epsilon_0,\\sigma_0)$, with known parameters $(\\epsilon_0, \\sigma_0)$. The deviation of the fitted parameters $(\\epsilon^\\ast, \\sigma^\\ast)$ from the true parameters $(\\epsilon_0, \\sigma_0)$ reveals the systematic bias introduced by the specific truncation scheme.\n\nThis problem is formulated as a non-linear least squares (NLS) optimization. The objective is to find the parameters $(\\epsilon, \\sigma)$ that minimize the sum of squared residuals between the truncated model potential and the reference potential over a discrete set of inter-particle distances $\\{r_i\\}$.\n\nThe objective function to be minimized is:\n$$\nL(\\epsilon, \\sigma) = \\sum_{i=1}^{N} \\left[ V_{\\mathrm{trunc}}(r_i; \\epsilon, \\sigma, ...) - V_{\\mathrm{ref}}(r_i) \\right]^2\n$$\nwhere $V_{\\mathrm{trunc}}$ is the truncated model potential (either $V_{\\mathrm{shift}}$ or $V_{\\mathrm{switch}}$) and $V_{\\mathrm{ref}}$ is the reference data.\n\nThe problem is defined in a system of reduced, dimensionless units. The reference parameters are $\\epsilon_0=1.0$ and $\\sigma_0=1.0$. All energies are implicitly in units of $\\epsilon_0$ and all distances in units of $\\sigma_0$.\n\nThe reference potential energy values are generated using the standard LJ formula:\n$$\nV_{\\mathrm{ref}}(r_i) = V_{\\mathrm{LJ}}(r_i; \\epsilon_0, \\sigma_0) = 4\\epsilon_0 \\left[ \\left(\\frac{\\sigma_0}{r_i}\\right)^{12} - \\left(\\frac{\\sigma_0}{r_i}\\right)^{6} \\right] = 4 \\left( r_i^{-12} - r_i^{-6} \\right)\n$$\nThe training data consists of $N=200$ distances $\\{r_i\\}$ uniformly spaced over the interval $[r_{\\min}, r_c]$, where $r_{\\min}=0.9\\sigma_0=0.9$.\n\nThe two truncated models are:\n1.  **Energy Shifting ($V_{\\mathrm{shift}}$):** This model ensures the potential is zero at the cutoff $r_c$ by subtracting the potential value at $r_c$.\n    $$\n    V_{\\mathrm{shift}}(r; \\epsilon, \\sigma, r_c) = V_{\\mathrm{LJ}}(r; \\epsilon, \\sigma) - V_{\\mathrm{LJ}}(r_c; \\epsilon, \\sigma) \\quad \\text{for } r < r_c\n    $$\n    Substituting the LJ form, we get:\n    $$\n    V_{\\mathrm{shift}}(r; \\epsilon, \\sigma, r_c) = 4\\epsilon \\left[ \\left( \\left(\\frac{\\sigma}{r}\\right)^{12} - \\left(\\frac{\\sigma}{r}\\right)^{6} \\right) - \\left( \\left(\\frac{\\sigma}{r_c}\\right)^{12} - \\left(\\frac{\\sigma}{r_c}\\right)^{6} \\right) \\right]\n    $$\n\n2.  **Smooth Switching ($V_{\\mathrm{switch}}$):** This model smoothly tapers the LJ potential to zero between distances $r_s$ and $r_c$ using a switching function $S(r)$.\n    $$\n    V_{\\mathrm{switch}}(r; \\epsilon, \\sigma, r_s, r_c) = S(r; r_s, r_c) \\cdot V_{\\mathrm{LJ}}(r; \\epsilon, \\sigma)\n    $$\n    The quintic switching function $S(r)$ is defined piecewise:\n    $$\n    S(r;r_s,r_c) =\n    \\begin{cases}\n    1 & r \\le r_s \\\\\n    1 - 10x^3 + 15x^4 - 6x^5 & r_s < r < r_c \\\\\n    0 & r \\ge r_c\n    \\end{cases}\n    \\quad \\text{with} \\quad x = \\frac{r - r_s}{r_c - r_s}\n    $$\n    This form ensures continuity of the potential and its first two derivatives.\n\nFor each test case, we solve the NLS problem to find the optimal parameters $(\\epsilon^\\ast, \\sigma^\\ast)$. The optimization is performed subject to the physical constraints $\\epsilon > 0$ and $\\sigma > 0$. We will use the `scipy.optimize.least_squares` function, which is well-suited for such bound-constrained non-linear problems. The initial guess for the optimization will be the true parameters $(\\epsilon, \\sigma) = (1.0, 1.0)$.\n\nFinally, we calculate the compensation biases, which are the relative deviations of the fitted parameters from the true values:\n$$\n\\Delta_\\epsilon = \\frac{\\epsilon^\\ast - \\epsilon_0}{\\epsilon_0} = \\epsilon^\\ast - 1.0\n$$\n$$\n\\Delta_\\sigma = \\frac{\\sigma^\\ast - \\sigma_0}{\\sigma_0} = \\sigma^\\ast - 1.0\n$$\n\nThe solution algorithm is as follows for each test case:\n1.  Define the parameters for the case (truncation type, $r_c$, and $r_s$ if applicable).\n2.  Generate the array of $N=200$ training distances, $r_i$, from $r_{\\min}=0.9$ to $r_c$.\n3.  Compute the reference energy array, $V_{\\mathrm{ref},i}$, using $V_{\\mathrm{LJ}}(r_i; 1.0, 1.0)$.\n4.  Define a residual function that takes a parameter vector $[\\epsilon, \\sigma]$ and returns the vector of differences $[V_{\\mathrm{trunc}}(r_i) - V_{\\mathrm{ref},i}]$. This function will be specific to the truncation scheme (`shift` or `switch`).\n5.  Invoke `scipy.optimize.least_squares` with the residual function, an initial guess of $[1.0, 1.0]$, and positivity bounds $([0, 0], [\\infty, \\infty])$.\n6.  Extract the optimized parameters $(\\epsilon^\\ast, \\sigma^\\ast)$ from the solver's result.\n7.  Compute $\\Delta_\\epsilon$ and $\\Delta_\\sigma$.\n8.  Store the results, rounded to $6$ decimal places.\n\nThis procedure is repeated for all five test cases, and the results are aggregated into the specified output format.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import least_squares\n\ndef V_LJ(r, epsilon, sigma):\n    \"\"\"Calculates the Lennard-Jones potential.\"\"\"\n    # Ensure r and sigma are positive to avoid errors.\n    r = np.maximum(r, 1e-12)\n    sigma = np.maximum(sigma, 1e-12)\n    \n    sig_r = sigma / r\n    sig_r6 = sig_r**6\n    sig_r12 = sig_r6**2\n    return 4.0 * epsilon * (sig_r12 - sig_r6)\n\ndef V_shift(r, epsilon, sigma, rc):\n    \"\"\"Calculates the energy-shifted Lennard-Jones potential.\"\"\"\n    v_r = V_LJ(r, epsilon, sigma)\n    v_rc = V_LJ(rc, epsilon, sigma)\n    # The potential is defined for r < rc. For r >= rc, it is 0.\n    # The training points are all r <= rc. The linspace includes rc.\n    # We must handle the endpoint where r=rc, V_shift should be 0.\n    potential = v_r - v_rc\n    potential[r >= rc] = 0.0\n    return potential\n\ndef S_quintic(r, rs, rc):\n    \"\"\"Calculates the quintic switching function S(r).\"\"\"\n    s_vals = np.zeros_like(r, dtype=float)\n    \n    # Condition: r <= rs\n    cond1 = r <= rs\n    s_vals[cond1] = 1.0\n    \n    # Condition: rs < r < rc\n    cond2 = (r > rs) & (r < rc)\n    if np.any(cond2):\n        r_middle = r[cond2]\n        x = (r_middle - rs) / (rc - rs)\n        s_vals[cond2] = 1.0 - 10 * x**3 + 15 * x**4 - 6 * x**5\n    \n    # Condition: r >= rc -> s_vals remains 0.0\n    \n    return s_vals\n\ndef V_switch(r, epsilon, sigma, rs, rc):\n    \"\"\"Calculates the smoothly switched Lennard-Jones potential.\"\"\"\n    s_r = S_quintic(r, rs, rc)\n    v_lj_r = V_LJ(r, epsilon, sigma)\n    return s_r * v_lj_r\n\ndef solve_case(case_params):\n    \"\"\"\n    Solves a single parameter fitting case.\n    \"\"\"\n    model_type = case_params['type']\n    rc = case_params['rc']\n    rs = case_params.get('rs') # Will be None if not provided\n    \n    # Constants and reference parameters\n    epsilon_0 = 1.0\n    sigma_0 = 1.0\n    N = 200\n    r_min = 0.9 * sigma_0\n\n    # Generate training data: distances and reference energies\n    r_train = np.linspace(r_min, rc, N)\n    V_ref = V_LJ(r_train, epsilon_0, sigma_0)\n\n    # Define residual function for the optimizer\n    if model_type == 'shift':\n        def residuals(params):\n            epsilon, sigma = params\n            V_model = V_shift(r_train, epsilon, sigma, rc)\n            return V_model - V_ref\n    elif model_type == 'switch':\n        if rs is None or rs >= rc:\n            raise ValueError(\"Switching scheme requires rs < rc.\")\n        def residuals(params):\n            epsilon, sigma = params\n            V_model = V_switch(r_train, epsilon, sigma, rs, rc)\n            return V_model - V_ref\n    else:\n        raise ValueError(f\"Unknown model type: {model_type}\")\n\n    # Initial guess and bounds for the parameters (epsilon, sigma)\n    p0 = [1.0, 1.0]\n    bounds = ([0, 0], [np.inf, np.inf])\n\n    # Perform the non-linear least squares optimization\n    result = least_squares(residuals, p0, bounds=bounds, method='trf')\n    \n    # Extract optimal parameters\n    epsilon_star, sigma_star = result.x\n\n    # Calculate compensation biases\n    delta_epsilon = (epsilon_star - epsilon_0) / epsilon_0\n    delta_sigma = (sigma_star - sigma_0) / sigma_0\n\n    return [round(delta_epsilon, 6), round(delta_sigma, 6)]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        {'type': 'shift', 'rc': 1.6},\n        {'type': 'switch', 'rs': 1.2, 'rc': 1.6},\n        {'type': 'shift', 'rc': 3.0},\n        {'type': 'switch', 'rs': 2.5, 'rc': 3.0},\n        {'type': 'shift', 'rc': 1.3},\n    ]\n\n    results = []\n    for case in test_cases:\n        biases = solve_case(case)\n        # The str() of a list gives the desired format, e.g., '[0.1, 0.2]'\n        results.append(str(biases))\n    \n    # Final print statement must match the required format exactly.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3432370"}, {"introduction": "Torsional parameters are often the most challenging to determine, as they govern the subtle energy differences between molecular conformers and are critical for predicting dynamics and thermodynamic equilibria. A robust parameterization frequently requires integrating data from multiple sources, such as quantum mechanical energy scans and experimental population data. This advanced practice [@problem_id:3432389] introduces the Fisher Information Matrix, a powerful statistical tool used to assess how much information each data source contributes and to diagnose the identifiability and coupling of the fitted parameters.", "problem": "Consider parameterization of torsional contributions in a classical molecular mechanics force field for a single rotatable bond. The torsional energy is modeled as a truncated Fourier series motivated by common fixed-charge force fields. Let the dihedral angle be denoted by $\\phi$ (expressed in radians), and define the torsion energy function\n$$\nE(\\phi;\\theta) = k_1 \\left(1 - \\cos(3\\phi)\\right) + k_2 \\left(1 - \\cos(\\phi - \\pi)\\right),\n$$\nwhere the parameter vector is $\\theta = (k_1,k_2)$ with $k_1$ and $k_2$ in kilojoules per mole (kJ/mol). This form uses a threefold term with zero phase and a singlefold term with phase $\\pi$, choices that are commonly employed to reflect the periodicity of chemical dihedrals.\n\nTwo complementary data types are considered for parameterization.\n\n1. Gas-phase dihedral scan energies: At $M$ scan points $\\{\\phi_j\\}_{j=1}^M$ uniformly spaced in $[0,2\\pi)$, the observed energies $\\{Y_j\\}_{j=1}^M$ are modeled as independent Gaussian measurements\n$$\nY_j \\sim \\mathcal{N}\\left(E(\\phi_j; \\theta), \\sigma_E^2\\right),\n$$\nwith known noise standard deviation $\\sigma_E$ in kilojoules per mole.\n\n2. Condensed-phase conformer populations: Consider three conformational basins centered at angles $\\phi_c \\in \\{0, 2\\pi/3, 4\\pi/3\\}$, representing the threefold symmetry typical of $sp^3\\text{--}sp^3$ torsions. At absolute temperature $T$ (in kelvin), assume the observed counts $n = (n_1,n_2,n_3)$ from $N$ independent samples are drawn from a multinomial distribution with category probabilities given by Boltzmann weights over the torsion energy evaluated at the basin centers:\n$$\np_c(\\theta) = \\frac{\\exp\\left(-\\beta E(\\phi_c;\\theta)\\right)}{\\sum_{d=1}^{3} \\exp\\left(-\\beta E(\\phi_d;\\theta)\\right)}, \\quad \\beta = \\frac{1}{k_{\\mathrm{B}} T},\n$$\nwhere $k_{\\mathrm{B}}$ is the Boltzmann constant in units of kilojoules per mole per kelvin (kJ/(mol·K)), and $n \\sim \\mathrm{Multinomial}(N; p_1(\\theta), p_2(\\theta), p_3(\\theta))$.\n\nAssume the two data sets are statistically independent given $\\theta$. The identifiability of $\\theta$ may be quantified by the Fisher information matrix, defined as\n$$\nI_{ij}(\\theta) = \\mathbb{E}\\left[\\frac{\\partial}{\\partial \\theta_i} \\log p(D \\mid \\theta) \\cdot \\frac{\\partial}{\\partial \\theta_j} \\log p(D \\mid \\theta)\\right],\n$$\nwhere $D$ denotes the joint data from both sources and the expectation is taken with respect to $p(D \\mid \\theta)$. For independent data sources, the total Fisher information is the sum of source-specific contributions.\n\nStarting from fundamental definitions of the Gaussian likelihood and the Boltzmann distribution for conformer probabilities, derive expressions for the expected Fisher information contributions from both the gas-phase dihedral scan and the condensed-phase multinomial populations. Then, construct an algorithm that computes the total Fisher information matrix $I(\\theta)$ for a given parameter vector $\\theta$, scan design $\\{\\phi_j\\}$, measurement noise $\\sigma_E$, temperature $T$, sample size $N$, and conformer centers $\\{\\phi_c\\}$.\n\nFrom the computed Fisher information matrix, evaluate two quantitative identifiability metrics:\n- The condition number $\\kappa(\\theta)$ defined as $\\kappa(\\theta) = \\lambda_{\\max}(I(\\theta)) / \\lambda_{\\min}(I(\\theta))$, where $\\lambda_{\\max}$ and $\\lambda_{\\min}$ are the largest and smallest eigenvalues of $I(\\theta)$, respectively.\n- The coupling coefficient $\\rho(\\theta)$ defined as $\\rho(\\theta) = I_{12}(\\theta) / \\sqrt{I_{11}(\\theta) I_{22}(\\theta)}$, which quantifies the degree of parameter coupling and lies in the interval $[-1,1]$ when $I(\\theta)$ is positive definite.\n\nAll angles must be treated in radians. All energies and energy-related quantities must be in kilojoules per mole. Temperature $T$ must be in kelvin. Boltzmann constant $k_{\\mathrm{B}}$ must be used in units of kilojoules per mole per kelvin so that $\\beta$ has units of per kilojoule per mole.\n\nYour program must implement the derived expressions, compute $I(\\theta)$, and report $\\kappa(\\theta)$ and $\\rho(\\theta)$ for the following test suite of three cases, each specified by $(k_1,k_2,M,\\sigma_E,T,N,\\{\\phi_c\\})$:\n- Case $1$ (happy path): $(k_1,k_2) = (2.0, 1.0)$ kJ/mol, $M = 12$ uniformly spaced in $[0,2\\pi)$, $\\sigma_E = 0.1$ kJ/mol, $T = 300$ K, $N = 1000$, $\\{\\phi_c\\} = \\{0, 2\\pi/3, 4\\pi/3\\}$.\n- Case $2$ (near-degenerate design): $(k_1,k_2) = (2.0, 1.0)$ kJ/mol, $M = 2$ uniformly spaced in $[0,2\\pi)$, $\\sigma_E = 5.0$ kJ/mol, $T = 5000$ K, $N = 10$, $\\{\\phi_c\\} = \\{0, 2\\pi/3, 4\\pi/3\\}$.\n- Case $3$ (low-temperature limit of condensed-phase populations): $(k_1,k_2) = (2.0, 1.0)$ kJ/mol, $M = 12$ uniformly spaced in $[0,2\\pi)$, $\\sigma_E = 0.5$ kJ/mol, $T = 150$ K, $N = 10000$, $\\{\\phi_c\\} = \\{0, 2\\pi/3, 4\\pi/3\\}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets where each entry corresponds to a case and is itself a two-element list $[\\kappa,\\rho]$ in that order. For example, the output format must be\n$$\n\\texttt{[[\\kappa_1,\\rho_1],[\\kappa_2,\\rho_2],[\\kappa_3,\\rho_3]]},\n$$\nwith numeric values replacing the symbols. No additional text should be printed.", "solution": "The user has provided a well-defined problem in the domain of computational chemistry and statistical inference. The task is to analyze the parameter identifiability for a torsional energy model using the Fisher Information Matrix (FIM).\n\n### Problem Validation\nThe problem statement is critically validated first.\n-   **Givens Extracted**: The torsional energy function $E(\\phi;\\theta) = k_1 \\left(1 - \\cos(3\\phi)\\right) + k_2 \\left(1 - \\cos(\\phi - \\pi)\\right)$, the parameter vector $\\theta = (k_1, k_2)$, the statistical models for gas-phase scan energies ($Y_j \\sim \\mathcal{N}(E(\\phi_j; \\theta), \\sigma_E^2)$) and condensed-phase counts ($n \\sim \\mathrm{Multinomial}(N; \\{p_c(\\theta)\\})$), the definition of the conformer probabilities $p_c(\\theta)$, the definition of the Fisher Information Matrix $I_{ij}(\\theta)$, and the definitions of the identifiability metrics $\\kappa(\\theta)$ and $\\rho(\\theta)$ have all been extracted. All parameters for the three test cases are explicitly provided.\n-   **Validation Verdict**: The problem is **valid**. It is scientifically grounded in established principles of molecular mechanics, statistical mechanics, and information theory. It is well-posed, objective, and self-contained, with all necessary data and definitions provided to derive and compute a unique solution. It does not violate any of the specified invalidity criteria.\n\n### Derivation of the Fisher Information Matrix\n\nThe total Fisher Information Matrix $I(\\theta)$ is the sum of contributions from the independent gas-phase and condensed-phase data sources:\n$$\nI(\\theta) = I^E(\\theta) + I^N(\\theta)\n$$\nwhere $I^E(\\theta)$ is from the dihedral scan and $I^N(\\theta)$ is from the conformer populations. The parameters are $\\theta_1=k_1$ and $\\theta_2=k_2$.\n\n#### Part 1: Contribution from Gas-Phase Dihedral Scan Data ($I^E(\\theta)$)\n\nThe log-likelihood for $M$ independent Gaussian measurements $\\{Y_j\\}_{j=1}^M$ is\n$$\n\\log p(D_E \\mid \\theta) = \\sum_{j=1}^M \\left( -\\frac{1}{2}\\log(2\\pi\\sigma_E^2) - \\frac{(Y_j - E(\\phi_j; \\theta))^2}{2\\sigma_E^2} \\right)\n$$\nThe Fisher Information is defined as $I_{ij}(\\theta) = -\\mathbb{E}\\left[\\frac{\\partial^2}{\\partial \\theta_i \\partial \\theta_j} \\log p(D \\mid \\theta)\\right]$. For a linear model with additive Gaussian noise (which this is, with respect to the parameters $\\theta$), this simplifies to a well-known form. Alternatively, using the gradient definition:\n$$\nI^E_{ij}(\\theta) = \\mathbb{E}\\left[ \\left(\\frac{\\partial \\log p(D_E \\mid \\theta)}{\\partial \\theta_i}\\right) \\left(\\frac{\\partial \\log p(D_E \\mid \\theta)}{\\partial \\theta_j}\\right) \\right]\n$$\nThe derivative of the log-likelihood is:\n$$\n\\frac{\\partial}{\\partial \\theta_i} \\log p(D_E \\mid \\theta) = \\sum_{j=1}^M \\frac{(Y_j - E_j)}{\\sigma_E^2} \\frac{\\partial E_j}{\\partial \\theta_i}\n$$\nwhere $E_j = E(\\phi_j; \\theta)$. Taking the expectation and using $\\mathbb{E}[Y_j - E_j] = 0$ and $\\mathbb{E}[(Y_j - E_j)(Y_k - E_k)] = \\delta_{jk} \\sigma_E^2$, we arrive at:\n$$\nI^E_{ij}(\\theta) = \\frac{1}{\\sigma_E^2} \\sum_{j=1}^M \\frac{\\partial E(\\phi_j; \\theta)}{\\partial \\theta_i} \\frac{\\partial E(\\phi_j; \\theta)}{\\partial \\theta_j}\n$$\nThe partial derivatives of the energy function $E(\\phi; k_1, k_2) = k_1(1 - \\cos(3\\phi)) + k_2(1 + \\cos(\\phi))$ are:\n$$\n\\frac{\\partial E}{\\partial k_1} = 1 - \\cos(3\\phi) \\quad\\quad \\frac{\\partial E}{\\partial k_2} = 1 + \\cos(\\phi)\n$$\nThus, the elements of the $2 \\times 2$ matrix $I^E$ are:\n$$\nI^E_{11} = \\frac{1}{\\sigma_E^2} \\sum_{j=1}^M (1 - \\cos(3\\phi_j))^2\n$$\n$$\nI^E_{22} = \\frac{1}{\\sigma_E^2} \\sum_{j=1}^M (1 + \\cos(\\phi_j))^2\n$$\n$$\nI^E_{12} = I^E_{21} = \\frac{1}{\\sigma_E^2} \\sum_{j=1}^M (1 - \\cos(3\\phi_j))(1 + \\cos(\\phi_j))\n$$\nThe scan points $\\{\\phi_j\\}_{j=1}^M$ are uniformly spaced in $[0, 2\\pi)$.\n\n#### Part 2: Contribution from Condensed-Phase Population Data ($I^N(\\theta)$)\n\nThe data follows a multinomial distribution. The FIM for a multinomial distribution with $N$ trials and $K$ categories is given by:\n$$\nI^N_{ij}(\\theta) = N \\sum_{c=1}^K \\frac{1}{p_c(\\theta)} \\frac{\\partial p_c(\\theta)}{\\partial \\theta_i} \\frac{\\partial p_c(\\theta)}{\\partial \\theta_j}\n$$\nHere, $K=3$. The probabilities are $p_c(\\theta) = \\exp(-\\beta E_c)/Z$, where $E_c = E(\\phi_c; \\theta)$ and $Z=\\sum_{d=1}^3 \\exp(-\\beta E_d)$. The derivative of $p_c$ with respect to $\\theta_i$ is:\n$$\n\\frac{\\partial p_c}{\\partial \\theta_i} = -\\beta p_c \\left( \\frac{\\partial E_c}{\\partial \\theta_i} - \\sum_{d=1}^3 p_d \\frac{\\partial E_d}{\\partial \\theta_i} \\right) = -\\beta p_c \\left( \\frac{\\partial E_c}{\\partial \\theta_i} - \\left\\langle \\frac{\\partial E}{\\partial \\theta_i} \\right\\rangle \\right)\n$$\nwhere $\\langle \\cdot \\rangle$ denotes the Boltzmann-weighted average over the conformer states. Substituting this into the FIM formula gives:\n$$\nI^N_{ij}(\\theta) = N \\beta^2 \\sum_{c=1}^3 p_c(\\theta) \\left( \\frac{\\partial E_c}{\\partial \\theta_i} - \\left\\langle \\frac{\\partial E}{\\partial \\theta_i} \\right\\rangle \\right) \\left( \\frac{\\partial E_c}{\\partial \\theta_j} - \\left\\langle \\frac{\\partial E}{\\partial \\theta_j} \\right\\rangle \\right)\n$$\nThis is $N\\beta^2$ times the covariance of the energy gradient components, evaluated over the discrete conformer distribution. Let $g_{1c} = \\partial E_c / \\partial k_1$ and $g_{2c} = \\partial E_c / \\partial k_2$. The matrix elements are:\n$$\nI^N_{11} = N\\beta^2 \\sum_{c=1}^3 p_c (g_{1c} - \\langle g_1 \\rangle)^2\n$$\n$$\nI^N_{22} = N\\beta^2 \\sum_{c=1}^3 p_c (g_{2c} - \\langle g_2 \\rangle)^2\n$$\n$$\nI^N_{12} = I^N_{21} = N\\beta^2 \\sum_{c=1}^3 p_c (g_{1c} - \\langle g_1 \\rangle)(g_{2c} - \\langle g_2 \\rangle)\n$$\nwith $\\beta=1/(k_B T)$.\n\n### Algorithm and Identifiability Metrics\n\nThe algorithm proceeds as follows:\n1.  For a given test case $(k_1, k_2, M, \\sigma_E, T, N, \\{\\phi_c\\})$, compute the matrices $I^E(\\theta)$ and $I^N(\\theta)$ using the derived formulas.\n2.  Sum them to obtain the total Fisher Information Matrix $I(\\theta) = I^E(\\theta) + I^N(\\theta)$.\n3.  Compute the eigenvalues of the symmetric matrix $I(\\theta)$, denoted $\\lambda_{\\min}$ and $\\lambda_{\\max}$.\n4.  Calculate the condition number $\\kappa(\\theta) = \\lambda_{\\max} / \\lambda_{\\min}$. A value of $\\kappa$ close to $1$ indicates that parameters are identified with similar precision, while a large $\\kappa$ indicates ill-conditioning. If $\\lambda_{\\min} \\approx 0$, the parameters are not identifiable from the data, and $\\kappa$ approaches infinity.\n5.  Calculate the coupling coefficient $\\rho(\\theta) = I_{12}(\\theta) / \\sqrt{I_{11}(\\theta) I_{22}(\\theta)}$. A value of $|\\rho|$ near $1$ signifies strong linear dependence between parameter estimates, whereas a value near $0$ indicates they are decoupled.\n\nThis procedure is implemented for each of the three specified test cases. A crucial observation for the given conformer centers $\\{\\phi_c\\} = \\{0, 2\\pi/3, 4\\pi/3\\}$ is that the derivative $\\partial E / \\partial k_1 = 1 - \\cos(3\\phi)$ is exactly zero at all three points. Consequently, the population data provides no information about $k_1$, leading to $I^N_{11}=I^N_{12}=0$. All information about $k_1$ must come from the gas-phase scan data.", "answer": "```python\nimport numpy as np\n\n# Boltzmann constant in kJ/(mol·K)\nKB_KJ_MOL_K = 8.31446261815324 / 1000.0\n\ndef energy_torsion(phi, k1, k2):\n    \"\"\"\n    Calculates the torsional energy.\n    E(phi) = k_1(1 - cos(3*phi)) + k_2(1 - cos(phi - pi))\n    cos(phi - pi) = -cos(phi), so E(phi) = k_1(1 - cos(3*phi)) + k_2(1 + cos(phi))\n    \"\"\"\n    return k1 * (1.0 - np.cos(3.0 * phi)) + k2 * (1.0 + np.cos(phi))\n\ndef energy_derivatives(phi):\n    \"\"\"\n    Calculates the partial derivatives of the energy function with respect to k1 and k2.\n    \"\"\"\n    # Partial derivative of E with respect to k1: dE/dk1 = 1 - cos(3*phi)\n    g1 = 1.0 - np.cos(3.0 * phi)\n    # Partial derivative of E with respect to k2: dE/dk2 = 1 + cos(phi)\n    g2 = 1.0 + np.cos(phi)\n    return g1, g2\n\ndef compute_fim_from_scan(M, sigma_E):\n    \"\"\"\n    Computes the Fisher Information Matrix contribution from the gas-phase dihedral scan data.\n    \"\"\"\n    if M == 0 or sigma_E <= 0:\n        return np.zeros((2, 2))\n        \n    phi_scan = np.linspace(0, 2 * np.pi, M, endpoint=False)\n    \n    g1_scan, g2_scan = energy_derivatives(phi_scan)\n    \n    I_E = np.zeros((2, 2))\n    I_E[0, 0] = np.sum(g1_scan**2)\n    I_E[1, 1] = np.sum(g2_scan**2)\n    I_E[0, 1] = I_E[1, 0] = np.sum(g1_scan * g2_scan)\n    \n    return I_E / (sigma_E**2)\n\ndef compute_fim_from_population(k1, k2, T, N, phi_c):\n    \"\"\"\n    Computes the Fisher Information Matrix contribution from the condensed-phase population data.\n    \"\"\"\n    if T <= 0 or N <= 0:\n        return np.zeros((2, 2))\n        \n    beta = 1.0 / (KB_KJ_MOL_K * T)\n    \n    E_conf = energy_torsion(phi_c, k1, k2)\n    g1_conf, g2_conf = energy_derivatives(phi_c)\n    \n    boltzmann_factors = np.exp(-beta * E_conf)\n    Z = np.sum(boltzmann_factors)\n    if Z == 0:\n        return np.zeros((2, 2))\n    p_conf = boltzmann_factors / Z\n    \n    avg_g1 = np.sum(p_conf * g1_conf)\n    avg_g2 = np.sum(p_conf * g2_conf)\n    \n    dev_g1 = g1_conf - avg_g1\n    dev_g2 = g2_conf - avg_g2\n    \n    I_N = np.zeros((2, 2))\n    I_N[0, 0] = np.sum(p_conf * dev_g1**2)\n    I_N[1, 1] = np.sum(p_conf * dev_g2**2)\n    I_N[0, 1] = I_N[1, 0] = np.sum(p_conf * dev_g1 * dev_g2)\n    \n    return N * beta**2 * I_N\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1: (k1, k2, M, sigma_E, T, N, {phi_c})\n        (2.0, 1.0, 12, 0.1, 300, 1000, [0, 2 * np.pi / 3, 4 * np.pi / 3]),\n        # Case 2\n        (2.0, 1.0, 2, 5.0, 5000, 10, [0, 2 * np.pi / 3, 4 * np.pi / 3]),\n        # Case 3\n        (2.0, 1.0, 12, 0.5, 150, 10000, [0, 2 * np.pi / 3, 4 * np.pi / 3]),\n    ]\n\n    results = []\n    for case_params in test_cases:\n        k1, k2, M, sigma_E, T, N, phi_c_list = case_params\n        phi_c = np.array(phi_c_list)\n        \n        # Compute FIM contributions\n        I_E = compute_fim_from_scan(M, sigma_E)\n        I_N = compute_fim_from_population(k1, k2, T, N, phi_c)\n        \n        # Total FIM\n        I_total = I_E + I_N\n        \n        # Calculate Identifiability Metrics\n        \n        # Condition Number (kappa)\n        try:\n            eigenvalues = np.linalg.eigvalsh(I_total)\n            lambda_min, lambda_max = eigenvalues[0], eigenvalues[1]\n            # Use a small tolerance for numerical stability\n            if lambda_min <= 1e-12 * lambda_max:\n                kappa = np.inf\n            else:\n                kappa = lambda_max / lambda_min\n        except np.linalg.LinAlgError:\n            kappa = np.inf\n\n        # Coupling Coefficient (rho)\n        denom = np.sqrt(I_total[0, 0] * I_total[1, 1])\n        if denom == 0:\n            # Undefined if diagonal elements are zero, implying complete non-identifiability.\n            rho = np.nan \n        else:\n            rho = I_total[0, 1] / denom\n            \n        results.append([kappa, rho])\n\n    # Format the final output as specified\n    print(f\"[{','.join(str(res) for res in results)}]\")\n\nsolve()\n```", "id": "3432389"}]}