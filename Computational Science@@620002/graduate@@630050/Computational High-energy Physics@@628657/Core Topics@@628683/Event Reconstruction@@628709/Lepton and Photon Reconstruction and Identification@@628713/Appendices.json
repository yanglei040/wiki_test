{"hands_on_practices": [{"introduction": "The ability to precisely measure the momentum of charged particles is a cornerstone of experimental high-energy physics. This measurement underpins everything from kinematic event reconstruction to the discovery of new particles through mass peaks. This first practice takes you back to fundamental principles, exploring how a muon's trajectory curvature in a magnetic field is translated into a measurement of its transverse momentum, $p_T$. By deriving the momentum resolution from the geometric properties of the detector and its intrinsic measurement uncertainties, you will gain a concrete understanding of the factors that limit our experimental precision and how detector design directly impacts physics capabilities [@problem_id:3520912].", "problem": "In a high-energy collider detector, muon transverse momentum reconstruction in the bending plane relies on measuring the trajectory curvature produced by the Lorentz force in a magnetic field. Consider a charged particle of charge magnitude $|q|$ and transverse momentum $p_T$ traversing a region with an approximately track-averaged magnetic field component perpendicular to the trajectory, denoted $B$. The trajectory segment between two outer precision measurement stations is approximated as a circular arc of radius $R$ subtending a chord of length $L$ in the bending plane. The maximum deviation of the arc from the chord, the sagitta $s$, is measured using a middle precision station. Assume the small-deflection limit $L \\ll R$.\n\nFoundational relations that may be taken as starting points are:\n- The balance of Lorentz force and centripetal force in the transverse plane implies a relation between $p_T$, $B$, $R$, and $|q|$.\n- The exact geometric sagitta for a circular arc of radius $R$ and chord length $L$ is $s = R - \\sqrt{R^2 - (L/2)^2}$.\n\nSuppose the sagitta measurement has a statistical uncertainty $\\sigma_s$ due to finite spatial resolution of the tracking detectors, and, in addition, the spectrometer alignment contributes an independent, configuration-stable sagitta uncertainty $\\sigma_a$ (assumed uncorrelated with $\\sigma_s$). Both uncertainties are treated as Gaussian and independent, so that they add in quadrature. Throughout, use the practical high-energy physics unit convention $p_T \\, [\\mathrm{GeV}] = c_B \\, |q| \\, B \\, [\\mathrm{T}] \\, R \\, [\\mathrm{m}]$ with $c_B \\approx 0.3$, and take $B$ to represent the track-averaged perpendicular field relevant for bending in either a solenoidal or toroidal spectrometer.\n\nStarting only from the stated fundamental relations and approximations, derive a closed-form analytic expression for the relative transverse momentum resolution $\\sigma_{p_T}/p_T$ due to the combined sagitta measurement and alignment uncertainties, expressed in terms of $p_T$, $B$, $L$, $|q|$, $c_B$, $\\sigma_s$, and $\\sigma_a$. Your final expression must make the scaling with $L$ and $B$ explicit. Provide your final answer as a single closed-form expression. The final answer is dimensionless; no numerical evaluation is required and no units should be included in the final boxed answer.", "solution": "The principles of the problem are validated as scientifically grounded, well-posed, and objective. The problem describes a standard scenario in high-energy physics for momentum reconstruction of charged particles. We shall proceed with the derivation.\n\nThe starting points are the two foundational relations provided. First, the relationship between the transverse momentum $p_T$, the magnetic field $B$, and the radius of curvature $R$ for a particle with charge magnitude $|q|$:\n$$p_T = c_B |q| B R$$\nHere, $c_B$ is a constant of proportionality that handles the unit conversions as specified in the problem, approximately equal to $0.3$.\n\nSecond, the exact geometric relationship between the sagitta $s$, the radius of curvature $R$, and the chord length $L$:\n$$s = R - \\sqrt{R^2 - \\left(\\frac{L}{2}\\right)^2}$$\n\nThe problem stipulates the use of the small-deflection limit, where $L \\ll R$. We can exploit this condition to find a simplified, approximate expression for the sagitta $s$. We factor out $R$ from the square root term:\n$$s = R - R \\sqrt{1 - \\frac{L^2}{4R^2}}$$\nSince $L \\ll R$, the term $\\frac{L^2}{4R^2}$ is much smaller than $1$. We can therefore use the binomial approximation for the square root, $\\sqrt{1-x} \\approx 1 - \\frac{x}{2}$ for small $x$. Letting $x = \\frac{L^2}{4R^2}$, we get:\n$$s \\approx R - R \\left(1 - \\frac{1}{2} \\frac{L^2}{4R^2}\\right) = R - \\left(R - \\frac{RL^2}{8R^2}\\right) = \\frac{L^2}{8R}$$\nThis gives the well-known approximate relation for the sagitta:\n$$s \\approx \\frac{L^2}{8R}$$\n\nOur goal is to find the relative momentum resolution $\\frac{\\sigma_{p_T}}{p_T}$. To do this, we must first express $p_T$ in terms of the measured quantity, which is the sagitta $s$. From the sagitta approximation, we can express the radius of curvature $R$ as:\n$$R \\approx \\frac{L^2}{8s}$$\nSubstituting this expression for $R$ into the momentum equation yields:\n$$p_T \\approx c_B |q| B \\left(\\frac{L^2}{8s}\\right) = \\frac{c_B |q| B L^2}{8s}$$\n\nNow we can determine the uncertainty in $p_T$ that arises from the uncertainty in the measurement of $s$. The problem states that the total sagitta uncertainty is the quadrature sum of the statistical uncertainty $\\sigma_s$ and the alignment uncertainty $\\sigma_a$, which are independent. Let the total sagitta uncertainty be $\\sigma_{s, \\text{tot}}$.\n$$\\sigma_{s, \\text{tot}}^2 = \\sigma_s^2 + \\sigma_a^2 \\implies \\sigma_{s, \\text{tot}} = \\sqrt{\\sigma_s^2 + \\sigma_a^2}$$\n\nTo find the uncertainty in $p_T$, we use standard error propagation. In this derivation, the quantities $c_B$, $|q|$, $B$, and $L$ are treated as known constants without uncertainty. The momentum $p_T$ is a function of the single uncertain variable $s$.\n$$p_T(s) = \\left(\\frac{c_B |q| B L^2}{8}\\right) s^{-1}$$\nThe uncertainty $\\sigma_{p_T}$ is related to the uncertainty $\\sigma_{s, \\text{tot}}$ by:\n$$\\sigma_{p_T} = \\left|\\frac{dp_T}{ds}\\right| \\sigma_{s, \\text{tot}}$$\nWe compute the derivative of $p_T$ with respect to $s$:\n$$\\frac{dp_T}{ds} = \\frac{d}{ds} \\left(\\frac{c_B |q| B L^2}{8s}\\right) = -\\frac{c_B |q| B L^2}{8s^2}$$\nWe can re-express this derivative in terms of $p_T$ itself:\n$$\\frac{dp_T}{ds} = -\\frac{1}{s} \\left(\\frac{c_B |q| B L^2}{8s}\\right) = -\\frac{p_T}{s}$$\nThe magnitude of the derivative is therefore:\n$$\\left|\\frac{dp_T}{ds}\\right| = \\frac{p_T}{s}$$\nSubstituting this into the error propagation formula gives:\n$$\\sigma_{p_T} = \\frac{p_T}{s} \\sigma_{s, \\text{tot}}$$\nThe relative transverse momentum resolution is then:\n$$\\frac{\\sigma_{p_T}}{p_T} = \\frac{\\sigma_{s, \\text{tot}}}{s} = \\frac{\\sqrt{\\sigma_s^2 + \\sigma_a^2}}{s}$$\n\nThe final step is to express this result in terms of the specified independent variables, which include $p_T$ but not $s$. We use the relationship derived earlier, $p_T \\approx \\frac{c_B |q| B L^2}{8s}$, to eliminate $s$:\n$$s \\approx \\frac{c_B |q| B L^2}{8 p_T}$$\nSubstituting this expression for $s$ into our equation for the relative resolution:\n$$\\frac{\\sigma_{p_T}}{p_T} = \\frac{\\sqrt{\\sigma_s^2 + \\sigma_a^2}}{\\frac{c_B |q| B L^2}{8 p_T}}$$\nSimplifying this expression yields the final closed-form result for the relative transverse momentum resolution:\n$$\\frac{\\sigma_{p_T}}{p_T} = \\frac{8 p_T \\sqrt{\\sigma_s^2 + \\sigma_a^2}}{c_B |q| B L^2}$$\nThis expression explicitly shows the scaling of the momentum resolution with the transverse momentum $p_T$, the magnetic field $B$, and the chord length $L$. Specifically, the resolution degrades linearly with increasing $p_T$ and improves with a stronger magnetic field ($B^{-1}$) and quadratically with a longer lever arm ($L^{-2}$).", "answer": "$$\\boxed{\\frac{8 p_T \\sqrt{\\sigma_s^2 + \\sigma_a^2}}{c_B |q| B L^2}}$$", "id": "3520912"}, {"introduction": "Modern particle detectors produce a torrent of signals in trackers and calorimeters, and the challenge of reconstruction is to assemble these disparate pieces into a coherent physical picture. The Particle Flow (PF) algorithm represents a paradigm shift in this effort, aiming to reconstruct and identify every final-state particle in an event. This exercise provides a hands-on implementation of a simplified PF logic, where you will codify the decision-making process for distinguishing electrons, converted photons, and unconverted photons by linking tracks to calorimeter energy deposits [@problem_id:3520857]. You will learn to handle crucial signatures like bremsstrahlung and photon conversions, gaining insight into the algorithmic heart of modern event reconstruction.", "problem": "You must implement, in code, a simplified but scientifically consistent Particle Flow (PF) categorization for electrons and photons in the context of lepton and photon reconstruction and identification. Start from fundamental physical and algorithmic bases and derive decision rules for linking charged-particle tracks to Electromagnetic Calorimeter (ECAL) clusters, identifying bremsstrahlung photons, recognizing photon conversions, and codifying object creation and merging. The program must process a fixed test suite and produce a single-line output aggregating the results.\n\nFoundational bases are as follows. Use energy-momentum conservation and directionality: if a charged lepton (electron) emits bremsstrahlung, the emitted photon direction is approximately along the electron’s trajectory. Let $\\vec{p}$ denote momentum, $E$ energy, $\\hat{u}$ a unit direction vector for tracks, and $\\hat{n}$ a unit direction vector for ECAL clusters. For small angles, the angular separation between a track and a cluster can be approximated by the opening angle $\\theta = \\arccos(\\hat{u} \\cdot \\hat{n})$, which in the central region is consistent with the usual $\\Delta R$ metric. Photon conversions in material yield two oppositely charged tracks of small opening angle whose initial segments have missing inner hits; their sum direction points to the ECAL energy deposit. Electrons deposit their energy predominantly in the ECAL; bremsstrahlung photons are emitted along the electron’s path and are captured by nearby ECAL clusters.\n\nImplement the following mathematically defined decision rules.\n\n1. Track–cluster angular distance: for each track $i$ and cluster $j$, compute\n$$\nd_{ij} = \\arccos\\!\\left( \\hat{u}_i \\cdot \\hat{n}_j \\right).\n$$\nA track and cluster are considered geometrically linked when $d_{ij} \\le \\Delta R_{\\mathrm{link}}$, with $\\Delta R_{\\mathrm{link}} = 0.03$ $\\mathrm{rad}$.\n\n2. Conversion identification: for any ECAL cluster $j$ linked to at least two tracks $i$ and $\\ell$, declare a converted photon if all conditions hold:\n- Opposite charges: $q_i \\cdot q_\\ell = -1$.\n- Small opening angle between the two tracks: $\\theta_{i\\ell} = \\arccos\\!\\left( \\hat{u}_i \\cdot \\hat{u}_\\ell \\right) \\le \\theta_{\\mathrm{conv}}$, with $\\theta_{\\mathrm{conv}} = 0.02$ $\\mathrm{rad}$.\n- Missing inner hits sufficient for both tracks: $h_i \\ge h_{\\mathrm{conv}}$ and $h_\\ell \\ge h_{\\mathrm{conv}}$, with $h_{\\mathrm{conv}} = 0.6$.\nIf these conditions are met, create a converted photon object with energy $E_{\\gamma}^{\\mathrm{conv}} = E_j$ and mark the two tracks and the cluster as consumed.\n\n3. Electron identification and primary cluster selection: for each remaining track $i$, among clusters $j$ not consumed, find the set with $d_{ij} \\le \\Delta R_{\\mathrm{link}}$ and choose a primary cluster $j^\\star$ as the one minimizing $d_{ij}$. A track becomes an electron if its primary cluster energy satisfies\n$$\nE_{j^\\star} \\ge \\alpha \\, p_i, \\quad \\text{with } \\alpha = 0.5.\n$$\nIf identified as an electron, mark the primary cluster as consumed.\n\n4. Bremsstrahlung cluster association and merging: for an identified electron track $i$ and its primary cluster $j^\\star$, any additional cluster $k$ not yet consumed that satisfies $d_{ik} \\le \\Delta R_{\\mathrm{brem}}$ with $\\Delta R_{\\mathrm{brem}} = 0.05$ $\\mathrm{rad}$ and is closest to track $i$ among all tracks is considered a bremsstrahlung photon cluster and is merged into the electron’s energy. The reconstructed electron energy is\n$$\nE_e = E_{j^\\star} + \\sum_{k \\in \\mathcal{B}_i} E_k,\n$$\nwhere $\\mathcal{B}_i$ is the set of bremsstrahlung clusters associated to track $i$. Mark any merged bremsstrahlung clusters as consumed.\n\n5. Unconverted photon creation: any remaining ECAL cluster not consumed by steps $2$–$4$ becomes an unconverted photon with energy $E_\\gamma = E_j$.\n\nGeometric representation of directions will use spherical coordinates to construct unit vectors. For angles $(\\theta, \\phi)$, define the unit vector\n$$\n\\hat{n}(\\theta,\\phi) = \\left( \\sin\\theta \\cos\\phi,\\; \\sin\\theta \\sin\\phi,\\; \\cos\\theta \\right).\n$$\nAngles must be provided and used in $\\mathrm{radians}$. Energies must be expressed in $\\mathrm{GeV}$.\n\nObject coding for output is as follows: electron $\\rightarrow 0$, unconverted photon $\\rightarrow 1$, converted photon $\\rightarrow 2$. Each reconstructed object must be represented as a list of the form $[\\mathrm{code}, E]$, where $E$ is the object energy in $\\mathrm{GeV}$ rounded to two decimal places.\n\nTest suite. Implement the flow on the following four cases, which test a general case, a boundary, a conversion, and an ambiguity resolution:\n\n- Case $1$ (electron with bremsstrahlung and an isolated photon):\n  - Tracks: one electron-like track with $p = 50$ $\\mathrm{GeV}$, $q = -1$, $h = 0.1$, $(\\theta, \\phi) = (1.2, 0.1)$.\n  - ECAL clusters: primary candidate $E = 45$ $\\mathrm{GeV}$ at $(\\theta, \\phi) = (1.21, 0.1)$; bremsstrahlung candidate $E = 8$ $\\mathrm{GeV}$ at $(\\theta, \\phi) = (1.23, 0.1)$; isolated photon $E = 20$ $\\mathrm{GeV}$ at $(\\theta, \\phi) = (0.3, 2.0)$.\n\n- Case $2$ (boundary failure of link: cluster just outside link threshold):\n  - Tracks: one track with $p = 20$ $\\mathrm{GeV}$, $q = +1$, $h = 0.1$, $(\\theta, \\phi) = (1.0, 0.5)$.\n  - ECAL clusters: one cluster with $E = 20$ $\\mathrm{GeV}$ at $(\\theta, \\phi) = (1.032, 0.5)$.\n\n- Case $3$ (converted photon):\n  - Tracks: two tracks with $(p, q, h, \\theta, \\phi)$ equal to $(15, +1, 0.7, 1.60, 0.2)$ and $(14, -1, 0.7, 1.61, 0.2)$.\n  - ECAL clusters: one cluster with $E = 29$ $\\mathrm{GeV}$ at $(\\theta, \\phi) = (1.605, 0.2)$.\n\n- Case $4$ (ambiguous cluster near two tracks, non-conversion, and a low-energy nearby cluster):\n  - Tracks: $(p, q, h, \\theta, \\phi)$ equal to $(40, -1, 0.1, 0.70, -1.0)$ and $(38, +1, 0.1, 0.74, -1.0)$.\n  - ECAL clusters: shared candidate $E = 42$ $\\mathrm{GeV}$ at $(\\theta, \\phi) = (0.715, -1.0)$; nearby low-energy cluster $E = 5$ $\\mathrm{GeV}$ at $(\\theta, \\phi) = (0.76, -1.0)$.\n\nRequired output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes its list of reconstructed objects. For example, the outermost list has four elements, one per case, and each element is itself a list of object lists. Energies must be in $\\mathrm{GeV}$ and rounded to two decimal places. Angles must be in $\\mathrm{radians}$. The aggregated output must be a Python-style list literal, such as $[[[0, E_1], [1, E_2]], [[1, E_3]], [[2, E_4]], [[0, E_5], [1, E_6]]]$, with all $E_k$ in $\\mathrm{GeV}$ rounded to two decimals.", "solution": "The problem statement is valid. It outlines a simplified, yet scientifically consistent, algorithmic procedure for particle identification based on the Particle Flow (PF) paradigm used in high-energy physics experiments. The problem is well-posed, providing a clear sequence of operations and a complete set of parameters and test data. The physical principles—such as energy-momentum conservation, the behavior of electrons and photons in a detector, and the signatures of processes like bremsstrahlung and pair conversion—are correctly, if simplified, represented. The mathematical formalism is explicit and sufficient for a unique solution to be algorithmically determined.\n\nThe solution proceeds by implementing the specified sequence of reconstruction steps. At the core of the algorithm is the systematic consumption of detector signals (charged-particle tracks and calorimeter energy deposits, or clusters) to form physically meaningful objects (electrons and photons). The process is sequential to resolve ambiguities, with specific, high-purity signatures like photon conversions being identified first.\n\nFirst, we define the geometric representation. A particle's trajectory or an energy cluster's position is given by spherical coordinates $(\\theta, \\phi)$. To compute angular separations, we convert these into three-dimensional Cartesian unit vectors $\\hat{n}$ using the standard transformation:\n$$\n\\hat{n}(\\theta,\\phi) = \\left( \\sin\\theta \\cos\\phi,\\; \\sin\\theta \\sin\\phi,\\; \\cos\\theta \\right)\n$$\nThe angular distance $d_{12}$ between two directions represented by unit vectors $\\hat{u}_1$ and $\\hat{u}_2$ is given by the arc-cosine of their dot product, which is derived from the spherical law of cosines:\n$$\nd_{12} = \\arccos(\\hat{u}_1 \\cdot \\hat{u}_2)\n$$\nThis distance metric is fundamental to all linking and association steps.\n\nThe reconstruction logic is executed for each test case as a sequence of mutually exclusive steps. Objects are marked as \"consumed\" once assigned to a reconstructed particle to prevent their reuse.\n\n1.  **Conversion Identification**: The first step searches for the distinct signature of a photon converting into an electron-positron pair within the detector material. A high-energy photon ($E \\gtrsim 2m_e c^2$) interacting with the electromagnetic field of an atomic nucleus can produce a pair of oppositely charged leptons. In a detector, this appears as an ECAL cluster with no associated track pointing to it from the interaction point, but with two nearby, oppositely charged tracks originating from a common vertex displaced from the primary interaction point. Our algorithm models this by seeking an ECAL cluster $j$ that is geometrically linked to two tracks, $i$ and $\\ell$, (i.e., $d_{ij}, d_{\\ell j} \\le \\Delta R_{\\mathrm{link}} = 0.03$). For such a configuration to be a valid conversion, three conditions reflecting the physics must be met:\n    - The tracks must have opposite charges: $q_i \\cdot q_\\ell = -1$.\n    - The opening angle between the tracks must be small, characteristic of a pair produced from a single energetic parent: $\\theta_{i\\ell} = \\arccos(\\hat{u}_i \\cdot \\hat{u}_\\ell) \\le \\theta_{\\mathrm{conv}} = 0.02$ rad.\n    - The tracks must show evidence of originating from a secondary vertex, which is simplified to a requirement on a \"missing hits\" variable: $h_i, h_\\ell \\ge h_{\\mathrm{conv}} = 0.6$.\n    If all conditions hold, a converted photon is created with energy equal to the cluster energy, $E_{\\gamma}^{\\mathrm{conv}} = E_j$. The constituent tracks and the cluster are then marked as consumed.\n\n2.  **Electron Identification**: After searching for conversions, the algorithm attempts to identify electrons from the remaining unconsumed tracks and clusters. An electron is a charged particle that deposits the majority of its energy in the ECAL. This is modeled by linking a track $i$ to a primary ECAL cluster $j^\\star$. The primary cluster is chosen from all unconsumed clusters linked to the track ($d_{ij} \\le \\Delta R_{\\mathrm{link}}$) as the one with the smallest angular distance $d_{ij}$. A track is confirmed as an electron if the energy of its primary cluster is a significant fraction of the track's momentum, satisfying $E_{j^\\star} \\ge \\alpha \\, p_i$, with the threshold factor $\\alpha = 0.5$. If a track is identified as an electron, it and its primary cluster $j^\\star$ are consumed. This step is performed sequentially for all tracks; the first track to claim a cluster consumes it, making it unavailable for other tracks.\n\n3.  **Bremsstrahlung Cluster Association**: An electron traversing material radiates photons in a process called bremsstrahlung. These photons travel in nearly the same direction as the electron and deposit their energy in the ECAL, often in separate clusters near the electron's primary impact point. The algorithm accounts for this by searching for additional unconsumed clusters, $k$, in the vicinity of an identified electron track $i$. A cluster $k$ is considered a bremsstrahlung photon and merged with the electron if:\n    - It lies within a larger cone around the electron track: $d_{ik} \\le \\Delta R_{\\mathrm{brem}} = 0.05$ rad.\n    - To resolve ambiguity when a cluster is near multiple tracks, the electron track $i$ must be the closest of all tracks to the cluster $k$.\n    The energy of any such associated bremsstrahlung cluster is added to the electron's energy: $E_e = E_{j^\\star} + \\sum_{k \\in \\mathcal{B}_i} E_k$, where $\\mathcal{B}_i$ is the set of associated bremsstrahlung clusters. These merged clusters are then consumed.\n\n4.  **Unconverted Photon Identification**: Finally, any ECAL cluster that has not been consumed in the previous steps—i.e., it was not part of a conversion, nor was it a primary or bremsstrahlung cluster for an electron—is interpreted as an unconverted photon. This assumes that any significant energy deposit in the ECAL not associated with a charged particle track is likely from a photon originating from the primary interaction. An unconverted photon object is created with energy $E_\\gamma = E_j$ for each such remaining cluster $j$.\n\nThis complete sequence ensures every cluster and track is considered in a logical, physically motivated order to produce a final, exclusive list of reconstructed electrons and photons.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a simplified Particle Flow (PF) categorization for electrons and photons.\n    The function processes a fixed test suite of four cases and prints the aggregated results.\n    \"\"\"\n    \n    # --- Constants from the problem statement ---\n    DELTA_R_LINK = 0.03\n    THETA_CONV = 0.02\n    H_CONV = 0.6\n    ALPHA = 0.5\n    DELTA_R_BREM = 0.05\n    \n    # --- Object codes ---\n    ELECTRON_CODE = 0\n    UNCONVERTED_PHOTON_CODE = 1\n    CONVERTED_PHOTON_CODE = 2\n\n    # --- Test Suite Data ---\n    test_cases = [\n        {\n            \"tracks\": [\n                {\"p\": 50, \"q\": -1, \"h\": 0.1, \"theta\": 1.2, \"phi\": 0.1}\n            ],\n            \"clusters\": [\n                {\"E\": 45, \"theta\": 1.21, \"phi\": 0.1},\n                {\"E\": 8, \"theta\": 1.23, \"phi\": 0.1},\n                {\"E\": 20, \"theta\": 0.3, \"phi\": 2.0}\n            ]\n        },\n        {\n            \"tracks\": [\n                {\"p\": 20, \"q\": +1, \"h\": 0.1, \"theta\": 1.0, \"phi\": 0.5}\n            ],\n            \"clusters\": [\n                {\"E\": 20, \"theta\": 1.032, \"phi\": 0.5}\n            ]\n        },\n        {\n            \"tracks\": [\n                {\"p\": 15, \"q\": +1, \"h\": 0.7, \"theta\": 1.60, \"phi\": 0.2},\n                {\"p\": 14, \"q\": -1, \"h\": 0.7, \"theta\": 1.61, \"phi\": 0.2}\n            ],\n            \"clusters\": [\n                {\"E\": 29, \"theta\": 1.605, \"phi\": 0.2}\n            ]\n        },\n        {\n            \"tracks\": [\n                {\"p\": 40, \"q\": -1, \"h\": 0.1, \"theta\": 0.70, \"phi\": -1.0},\n                {\"p\": 38, \"q\": +1, \"h\": 0.1, \"theta\": 0.74, \"phi\": -1.0}\n            ],\n            \"clusters\": [\n                {\"E\": 42, \"theta\": 0.715, \"phi\": -1.0},\n                {\"E\": 5, \"theta\": 0.76, \"phi\": -1.0}\n            ]\n        }\n    ]\n\n    def unit_vector(theta, phi):\n        \"\"\"Computes the Cartesian unit vector from spherical coordinates.\"\"\"\n        return np.array([\n            np.sin(theta) * np.cos(phi),\n            np.sin(theta) * np.sin(phi),\n            np.cos(theta)\n        ])\n\n    def angular_distance(v1, v2):\n        \"\"\"Computes the angular distance between two unit vectors.\"\"\"\n        dot_product = np.clip(np.dot(v1, v2), -1.0, 1.0)\n        return np.arccos(dot_product)\n\n    def process_case(tracks_data, clusters_data):\n        \"\"\"Applies the PF algorithm to a single case.\"\"\"\n        \n        # Initialize objects with unique IDs and consumed flags\n        tracks = [dict(t, id=i, consumed=False, vec=unit_vector(t['theta'], t['phi'])) for i, t in enumerate(tracks_data)]\n        clusters = [dict(c, id=i, consumed=False, vec=unit_vector(c['theta'], c['phi'])) for i, c in enumerate(clusters_data)]\n        \n        reco_particles = []\n\n        # 1. Conversion Identification\n        # Use a copy of cluster list to allow modification while iterating\n        for j, cluster in enumerate(clusters):\n            if cluster['consumed']:\n                continue\n            \n            linked_tracks = []\n            for i, track in enumerate(tracks):\n                if not track['consumed']:\n                    dist = angular_distance(track['vec'], cluster['vec'])\n                    if dist = DELTA_R_LINK:\n                        linked_tracks.append(track)\n            \n            if len(linked_tracks) >= 2:\n                # Find the first valid conversion pair\n                found_conversion = False\n                for i1 in range(len(linked_tracks)):\n                    for i2 in range(i1 + 1, len(linked_tracks)):\n                        t1 = linked_tracks[i1]\n                        t2 = linked_tracks[i2]\n                        \n                        if t1['q'] * t2['q'] == -1 and \\\n                           angular_distance(t1['vec'], t2['vec']) = THETA_CONV and \\\n                           t1['h'] >= H_CONV and t2['h'] >= H_CONV:\n                            \n                            energy = round(cluster['E'], 2)\n                            reco_particles.append([CONVERTED_PHOTON_CODE, energy])\n                            \n                            cluster['consumed'] = True\n                            t1['consumed'] = True\n                            t2['consumed'] = True\n                            found_conversion = True\n                            break\n                    if found_conversion:\n                        break\n\n        # 2. Electron Identification and 4. Bremsstrahlung Association\n        identified_electrons = []\n        for track in tracks:\n            if track['consumed']:\n                continue\n\n            # Find primary cluster\n            best_cluster = None\n            min_dist = float('inf')\n            \n            linked_unconsumed_clusters = []\n            for cluster in clusters:\n                if not cluster['consumed']:\n                    dist = angular_distance(track['vec'], cluster['vec'])\n                    if dist = DELTA_R_LINK:\n                        linked_unconsumed_clusters.append((dist, cluster))\n            \n            if not linked_unconsumed_clusters:\n                continue\n\n            min_dist, best_cluster = min(linked_unconsumed_clusters, key=lambda x: x[0])\n\n            # Electron check\n            if best_cluster['E'] >= ALPHA * track['p']:\n                track['consumed'] = True\n                best_cluster['consumed'] = True\n                electron_energy = best_cluster['E']\n                # identified_electrons will store electron track and its growing energy\n                identified_electrons.append({'track': track, 'energy': electron_energy})\n        \n        # Now handle bremsstrahlung for the identified electrons\n        for electron in identified_electrons:\n            electron_track = electron['track']\n            \n            brem_clusters_to_add = []\n            for cluster in clusters:\n                if cluster['consumed']:\n                    continue\n                \n                dist_to_electron = angular_distance(electron_track['vec'], cluster['vec'])\n                if dist_to_electron = DELTA_R_BREM:\n                    # Check if this electron track is the closest track to the cluster\n                    closest_track_dist = float('inf')\n                    closest_track = None\n                    for any_track in tracks:\n                        d = angular_distance(any_track['vec'], cluster['vec'])\n                        if d  closest_track_dist:\n                            closest_track_dist = d\n                            closest_track = any_track\n                    \n                    if closest_track['id'] == electron_track['id']:\n                        brem_clusters_to_add.append(cluster)\n            \n            for brem_cluster in brem_clusters_to_add:\n                electron['energy'] += brem_cluster['E']\n                brem_cluster['consumed'] = True\n            \n            energy = round(electron['energy'], 2)\n            reco_particles.append([ELECTRON_CODE, energy])\n\n        # 5. Unconverted Photon Creation\n        for cluster in clusters:\n            if not cluster['consumed']:\n                energy = round(cluster['E'], 2)\n                reco_particles.append([UNCONVERTED_PHOTON_CODE, energy])\n\n        return reco_particles\n\n    # --- Main Execution Loop ---\n    all_results = []\n    for case in test_cases:\n        result = process_case(case['tracks'], case['clusters'])\n        all_results.append(result)\n\n    # Format output as a single-line Python-style list literal string\n    # E.g., [[[0, 53.0], [1, 20.0]], [[1, 20.0]], ...]\n    # str() adds spaces, so we remove them.\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```", "id": "3520857"}, {"introduction": "Reconstructing a lepton candidate is only half the battle; identifying it as a 'prompt' lepton from an interesting electroweak decay, rather than a non-prompt lepton from a hadronic jet, is critical for nearly all major physics analyses. This identification relies heavily on the concept of 'isolation'—the requirement that the lepton be separated from other significant energy deposits. This final practice frames the choice of an isolation cone size not as a fixed value, but as a dynamic optimization problem that must adapt to the lepton's kinematics [@problem_id:3520841]. By minimizing a physically motivated cost function, you will explore the modern technique of 'mini-isolation' and understand why it is essential for identifying highly boosted leptons in searches for new physics.", "problem": "You are asked to construct and analyze a principled optimization model for the isolation of leptons in high-energy proton-proton collisions. The isolation cone is defined in terms of the separation measure $\\Delta R = \\sqrt{(\\Delta \\eta)^2 + (\\Delta \\phi)^2}$ in pseudorapidity ($\\eta$) and azimuthal angle ($\\phi$). The isolation cone size $R$ is the radius of the circular region around the lepton direction in the $\\eta$–$\\phi$ plane. Your goal is to determine the isolation cone size $R$ as a function of the lepton transverse momentum $p_T$ that optimally balances contamination from Quantum Chromodynamics (QCD) radiation and the retention of genuine signal leptons from electroweak boson or top-quark decays. You must compute a quantitative optimum by minimizing a physically motivated objective with explicit unit handling and constraints.\n\nStart from the following fundamental bases:\n- Quantum Chromodynamics (QCD) soft-collinear radiation scaling: the emission probability density for soft, collinear partons scales as $dP \\propto \\alpha_s \\, C_i \\, \\frac{d\\theta}{\\theta} \\, dz \\, P_i(z)$, where $\\alpha_s$ is the strong coupling, $C_i$ is the color factor, $z$ is the energy fraction, and $P_i(z)$ is the splitting function. This implies an enhanced radiation near small angles, and a jet angular width that becomes narrower for higher $p_T$ due to Lorentz boost and angular ordering.\n- Underlying event and pileup contamination can be modeled as a uniform transverse-momentum density $\\rho$ in units of $\\mathrm{GeV}$ per unit area in $(\\eta,\\phi)$, contributing an expected hadronic contamination inside a cone of area $A = \\pi R^2$ as $E_{\\mathrm{UE}} = \\rho \\, \\pi R^2$.\n- In boosted topologies (for example top-quark decays), the nearest hadronic jet to the lepton has a characteristic angular separation that scales inversely with $p_T$ as $\\theta_b(p_T) \\approx \\kappa \\, \\frac{m}{p_T}$, where $m$ is the characteristic mass scale of the parent system and $\\kappa$ is an $\\mathcal{O}(1)$ constant. This scaling follows from boost kinematics of two-body or quasi-two-body decays and from QCD collimation at high $p_T$.\n- Detector resolution and lepton final-state radiation place a lower practical bound on $R$, which may be modeled to increase as $p_T$ decreases due to magnetic bending and multiple scattering, and to decrease as $p_T$ increases. This motivates a resolution penalty that diverges as $R \\to 0$.\n\nDefine the relative isolation as an expectation proxy\n$$\nI_{\\mathrm{rel}}(R, p_T) \\equiv \\frac{E_{\\mathrm{UE}}(R)}{p_T} + \\beta \\, s\\!\\left(u\\right),\n$$\nwhere $E_{\\mathrm{UE}}(R) = \\rho \\, \\pi R^2$, $u \\equiv \\frac{R \\, p_T}{\\kappa \\, m}$ is the ratio of the isolation cone size to the characteristic separation scale, $\\beta$ is a dimensionless parameter encoding the scale of nearby hadronic contamination relative to $p_T$, and $s(u)$ is a smooth, monotonically increasing overlap function such that $s(u) \\to 0$ as $u \\to 0$ and $s(u) \\to 1$ as $u \\to \\infty$. Use\n$$\ns(u) = \\frac{u^n}{1 + u^n}\n$$\nwith integer $n \\geq 2$ to ensure a steep transition as the cone radius approaches the nearby jet. To model resolution and signal-retention costs that penalize overly small cones, add a regularization term\n$$\nP_{\\mathrm{res}}(R) = \\mu \\left(\\frac{R_{\\mathrm{ref}}}{R}\\right)^q,\n$$\nwith $\\mu  0$, $R_{\\mathrm{ref}}  0$, and integer $q \\geq 1$. The total objective to minimize is then\n$$\nJ(R; p_T, \\rho) = \\frac{\\rho \\, \\pi R^2}{p_T} + \\beta \\, \\frac{\\left(\\frac{R \\, p_T}{\\kappa \\, m}\\right)^n}{1 + \\left(\\frac{R \\, p_T}{\\kappa \\, m}\\right)^n} + \\mu \\left(\\frac{R_{\\mathrm{ref}}}{R}\\right)^q,\n$$\nsubject to bounds\n$$\nR_{\\min} \\le R \\le R_{\\max},\n$$\nwith $R_{\\min}  0$ set by minimal practical cone sizes and $R_{\\max}$ set by maximal isolation radii used in reconstruction.\n\nYour tasks:\n1. Implement a program that, for each test case with given $(p_T, \\rho)$, numerically minimizes $J(R; p_T, \\rho)$ over $R \\in [R_{\\min}, R_{\\max}]$ using a bounded, derivative-free method that is robust to nonconvexities, and returns the optimal cone size $R_{\\mathrm{opt}}(p_T, \\rho)$.\n2. Use the following fixed parameters: $n = 4$ (dimensionless), $\\beta = 0.1$ (dimensionless), $\\kappa = 1$ (dimensionless), $m = 173 \\, \\mathrm{GeV}$, $\\mu = 0.005$ (dimensionless), $q = 2$ (dimensionless), $R_{\\mathrm{ref}} = 0.3$ (dimensionless), $R_{\\min} = 0.05$ (dimensionless), $R_{\\max} = 0.5$ (dimensionless).\n3. The transverse momentum must be specified in $\\mathrm{GeV}$, and $\\rho$ must be specified in $\\mathrm{GeV}$ per unit area in the $(\\eta,\\phi)$ plane. The cone radius $R$ is dimensionless and should be reported as a float rounded to four decimal places.\n4. Explain, in your solution, why the high-$p_T$ behavior of the minimizer justifies a “mini-isolation” scaling, i.e., $R_{\\mathrm{opt}}(p_T)$ decreasing with increasing $p_T$.\n\nTest suite:\n- Case 1: $p_T = 25 \\, \\mathrm{GeV}$, $\\rho = 5 \\, \\mathrm{GeV}$ per unit area.\n- Case 2: $p_T = 50 \\, \\mathrm{GeV}$, $\\rho = 10 \\, \\mathrm{GeV}$ per unit area.\n- Case 3: $p_T = 200 \\, \\mathrm{GeV}$, $\\rho = 5 \\, \\mathrm{GeV}$ per unit area.\n- Case 4: $p_T = 800 \\, \\mathrm{GeV}$, $\\rho = 5 \\, \\mathrm{GeV}$ per unit area.\n- Case 5: $p_T = 25 \\, \\mathrm{GeV}$, $\\rho = 1 \\, \\mathrm{GeV}$ per unit area.\n- Case 6: $p_T = 1000 \\, \\mathrm{GeV}$, $\\rho = 20 \\, \\mathrm{GeV}$ per unit area.\n- Case 7 (edge case for low contamination): $p_T = 300 \\, \\mathrm{GeV}$, $\\rho = 0 \\, \\mathrm{GeV}$ per unit area.\n\nFinal output format:\nYour program should produce a single line of output containing a comma-separated list of the seven $R_{\\mathrm{opt}}$ values, rounded to four decimal places, enclosed in square brackets. For example: \"[0.1234,0.2345,0.3456,0.4567,0.5678,0.6789,0.7890]\".", "solution": "The problem of determining the optimal lepton isolation cone size is a well-posed optimization task grounded in the established principles of high-energy particle physics. The problem is scientifically sound, self-contained, and provides all necessary parameters and constraints to find a unique, meaningful solution for each test case. Therefore, a solution is warranted.\n\nThe core of the problem is to find the isolation cone radius, denoted by $R$, that minimizes a physically motivated objective function $J(R; p_T, \\rho)$ for a given lepton transverse momentum $p_T$ and background transverse-momentum density $\\rho$. The isolation cone is defined in the space of pseudorapidity, $\\eta$, and azimuthal angle, $\\phi$, with the distance metric $\\Delta R = \\sqrt{(\\Delta \\eta)^2 + (\\Delta \\phi)^2}$. The minimization is performed over the valid range of cone sizes $R \\in [R_{\\min}, R_{\\max}]$.\n\nThe objective function is given by:\n$$\nJ(R; p_T, \\rho) = \\frac{\\rho \\, \\pi R^2}{p_T} + \\beta \\, \\frac{\\left(\\frac{R \\, p_T}{\\kappa \\, m}\\right)^n}{1 + \\left(\\frac{R \\, p_T}{\\kappa \\, m}\\right)^n} + \\mu \\left(\\frac{R_{\\mathrm{ref}}}{R}\\right)^q\n$$\nThis function represents the sum of three competing costs, each corresponding to a distinct physical effect:\n\n$1$. **Underlying Event and Pileup Contamination Cost:** The first term, $J_1(R; p_T, \\rho) = \\frac{\\rho \\, \\pi R^2}{p_T}$, models the fractional contamination of the lepton's energy measurement by background particles. This background arises from the underlying event and from pileup (additional proton-proton collisions in the same bunch crossing). It is modeled as a uniform transverse-momentum density $\\rho$ in the $(\\eta, \\phi)$-plane. The total background momentum in a cone of radius $R$ is $E_{\\mathrm{UE}} = \\rho \\pi R^2$. The cost is the ratio of this contamination to the lepton's $p_T$. This term increases quadratically with $R$, thus penalizing large cone sizes.\n\n$2$. **Jet Overlap Cost:** The second term, $J_2(R; p_T) = \\beta \\, s(u)$ with $u = \\frac{R p_T}{\\kappa m}$ and $s(u) = \\frac{u^n}{1 + u^n}$, models the probability of the isolation cone overlapping with a nearby jet originating from the same hard-scattering process (e.g., in a top quark decay, $t \\to bW \\to b\\ell\\nu$). Due to relativistic kinematics, the characteristic angular separation between the lepton and such a jet scales inversely with the lepton's $p_T$, approximately as $m/p_T$. The variable $u$ is the ratio of the cone size $R$ to this characteristic separation scale. The smooth, steep sigmoid function $s(u)$ captures the sharp turn-on of this contamination as the cone becomes large enough to encompass the jet. This term penalizes large cone radii, and the effect is more pronounced at higher $p_T$ where the jet is more collimated with the lepton.\n\n$3$. **Resolution and Signal Loss Penalty:** The third term, $J_3(R) = \\mu \\left(\\frac{R_{\\mathrm{ref}}}{R}\\right)^q$, serves as a regularization penalty against choosing extremely small cone radii. A very small $R$ can lead to the exclusion of final-state radiation (FSR) photons from the lepton, degrading the energy measurement. Furthermore, detector resolution limitations make it impractical to define arbitrarily small cones. This term diverges as $R \\to 0$, thus penalizing small cone sizes.\n\nThe optimal cone size, $R_{\\mathrm{opt}}$, is found at the minimum of the total objective function $J(R)$, which represents the ideal balance between these competing effects. Terms $J_1$ and $J_2$ favor a small $R$, while term $J_3$ favors a large $R$.\n\nTo find the minimum, we employ a numerical optimization procedure. The function $J(R)$ is continuous on the closed and bounded interval $[R_{\\min}, R_{\\max}]$, guaranteeing the existence of a minimum. The presence of the sigmoidal term $J_2(R)$ means the function is not guaranteed to be convex, so a simple gradient-based method could potentially fail. A robust, derivative-free, bounded minimization algorithm is appropriate. The `'bounded'` method of the `scipy.optimize.minimize_scalar` function is well-suited for this one-dimensional problem. It reliably finds the global minimum on the specified interval.\n\n**High-$p_T$ Behavior and \"Mini-Isolation\" Scaling**\n\nA key aspect of this model is its prediction that the optimal cone size $R_{\\mathrm{opt}}$ should decrease as the lepton's transverse momentum $p_T$ increases. This phenomenon is known as \"mini-isolation.\"\n\nThe physical intuition is that for a highly boosted lepton originating from a massive particle decay, the associated hadronic activity (like a $b$-jet from a top quark) becomes highly collimated with the lepton. The angular separation scales as $m/p_T$. To maintain lepton isolation by avoiding this hadronic activity, the cone radius $R$ must shrink as $p_T$ grows.\n\nThis behavior can be demonstrated by an asymptotic analysis of the objective function $J(R)$ in the limit of very high $p_T$.\nIn this limit, the UE/pileup term $J_1 = \\frac{\\rho \\pi R^2}{p_T}$ becomes negligible due to the $1/p_T$ suppression. The optimization is dominated by the balance between the jet overlap term, $J_2$, and the resolution penalty term, $J_3$.\nThe objective function is approximately:\n$$\nJ(R) \\approx \\beta \\, \\frac{\\left(\\frac{R p_T}{\\kappa m}\\right)^n}{1 + \\left(\\frac{R p_T}{\\kappa m}\\right)^n} + \\mu \\left(\\frac{R_{\\mathrm{ref}}}{R}\\right)^q\n$$\nFor the overall cost to be minimized, the jet overlap term must be suppressed. This requires keeping its argument $u = \\frac{R p_T}{\\kappa m}$ small, i.e., $u \\ll 1$. In this regime, the sigmoid can be approximated as $s(u) \\approx u^n$. The objective function simplifies further to:\n$$\nJ(R) \\approx \\beta \\left(\\frac{R p_T}{\\kappa m}\\right)^n + \\mu \\left(\\frac{R_{\\mathrm{ref}}}{R}\\right)^q\n$$\nTo find the minimum, we set the derivative with respect to $R$ to zero:\n$$\n\\frac{\\partial J}{\\partial R} \\approx n \\beta \\frac{p_T^n}{(\\kappa m)^n} R^{n-1} - q \\mu \\frac{R_{\\mathrm{ref}}^q}{R^{q+1}} = 0\n$$\nSolving for $R$ yields the scaling relationship for the optimal radius $R_{\\mathrm{opt}}$:\n$$\nn \\beta \\frac{p_T^n}{(\\kappa m)^n} R^{n+q} \\approx q \\mu R_{\\mathrm{ref}}^q\n$$\n$$\nR^{n+q}_{\\mathrm{opt}} \\approx \\frac{q \\mu R_{\\mathrm{ref}}^q (\\kappa m)^n}{n \\beta} \\frac{1}{p_T^n}\n$$\n$$\nR_{\\mathrm{opt}}(p_T) \\propto p_T^{-n / (n+q)}\n$$\nUsing the specified parameters $n=4$ and $q=2$, we find the explicit scaling law:\n$$\nR_{\\mathrm{opt}}(p_T) \\propto p_T^{-4 / (4+2)} = p_T^{-2/3}\n$$\nThis result analytically confirms the physical intuition: the optimal isolation cone size must decrease with increasing transverse momentum to effectively balance the risk of jet overlap against resolution losses, which is the principle behind the mini-isolation technique. The numerical results for the test cases with increasing $p_T$ (e.g., Cases 1, 3, and 4) will validate this scaling behavior.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize_scalar\n\ndef solve():\n    \"\"\"\n    Computes the optimal lepton isolation cone size R by minimizing a\n    physically motivated objective function for several test cases.\n    \"\"\"\n    # Define fixed parameters as specified in the problem statement.\n    n = 4          # dimensionless, power for jet overlap sigmoid\n    beta = 0.1     # dimensionless, scale of jet overlap contamination\n    kappa = 1      # dimensionless, O(1) constant for jet separation\n    m = 173.0      # GeV, characteristic mass scale (top quark mass)\n    mu = 0.005     # dimensionless, scale of resolution penalty\n    q = 2          # dimensionless, power for resolution penalty\n    R_ref = 0.3    # dimensionless, reference cone size for resolution penalty\n    R_min = 0.05   # dimensionless, minimum practical cone size\n    R_max = 0.5    # dimensionless, maximum practical cone size\n\n    def objective_function(R, p_T, rho):\n        \"\"\"\n        The objective function J(R; p_T, rho) to be minimized.\n        \n        Args:\n            R (float): The isolation cone radius (dimensionless).\n            p_T (float): The lepton transverse momentum in GeV.\n            rho (float): The background transverse-momentum density in GeV per unit area.\n            \n        Returns:\n            float: The value of the objective function.\n        \"\"\"\n        # Term 1: Underlying Event / Pileup contamination\n        # Handle the case rho = 0 to avoid unnecessary computation\n        if rho == 0.0:\n            term1 = 0.0\n        else:\n            term1 = (rho * np.pi * R**2) / p_T\n        \n        # Term 2: Jet overlap contamination\n        u = (R * p_T) / (kappa * m)\n        s_u = u**n / (1.0 + u**n)\n        term2 = beta * s_u\n        \n        # Term 3: Resolution / Signal loss penalty\n        # R_min > 0 ensures R is never zero.\n        term3 = mu * (R_ref / R)**q\n        \n        return term1 + term2 + term3\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (p_T [GeV], rho [GeV/area])\n        (25.0, 5.0),   # Case 1\n        (50.0, 10.0),  # Case 2\n        (200.0, 5.0),  # Case 3\n        (800.0, 5.0),  # Case 4\n        (25.0, 1.0),   # Case 5\n        (1000.0, 20.0),# Case 6\n        (300.0, 0.0),  # Case 7\n    ]\n\n    results = []\n    for p_T, rho in test_cases:\n        # Numerically minimize the objective function for R within the specified bounds.\n        # 'bounded' method is suitable for 1-D minimization on an interval\n        # and is robust without requiring derivatives.\n        res = minimize_scalar(\n            objective_function,\n            bounds=(R_min, R_max),\n            args=(p_T, rho),\n            method='bounded'\n        )\n        \n        # The optimal R is stored in the 'x' attribute of the result object.\n        optimal_R = res.x\n        \n        # Format the result to four decimal places as requested.\n        results.append(f\"{optimal_R:.4f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3520841"}]}