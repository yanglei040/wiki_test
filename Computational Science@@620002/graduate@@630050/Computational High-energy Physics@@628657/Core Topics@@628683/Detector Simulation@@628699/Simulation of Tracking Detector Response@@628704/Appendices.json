{"hands_on_practices": [{"introduction": "A realistic simulation of a tracking detector begins with modeling the response of its most basic components. This exercise explores how to derive the \"S-curve,\" or efficiency turn-on curve, which describes the probability that a detector channel registers a hit as a function of the deposited charge. By combining the effects of Gaussian-distributed electronic noise and threshold variations, you will analytically derive and implement a fundamental model used throughout high-energy physics to characterize detector performance [@problem_id:3536201].", "problem": "Consider a binary-threshold tracking detector module where each readout channel produces a hit if the sum of the deposited charge and the electronic noise exceeds the channel’s threshold. Let the deposited charge be denoted by $q$, measured in kilo-electron charge (ke), where $1\\,\\text{ke} = 10^{3}$ electrons. The per-channel electronic noise is modeled as a Gaussian random variable $n \\sim \\mathcal{N}(0,\\sigma_{n}^{2})$, with $\\sigma_{n}$ in ke. Channel thresholds across the module are not identical; instead, they are dispersed according to a Gaussian distribution $T \\sim \\mathcal{N}(T_{0},\\sigma_{T}^{2})$, with $T_{0}$ in ke and $\\sigma_{T}$ in ke. Assume $n$ and $T$ are statistically independent.\n\nA single channel with a fixed threshold $T$ registers a hit if $q + n > T$. The per-channel response, that is, the probability of a hit given $q$ and $T$, is therefore defined by the event that the noisy signal exceeds the threshold. The mean module efficiency turn-on curve, denoted $\\bar{\\epsilon}(q)$, is the expected per-channel response averaged over the threshold dispersion, which can be written as a convolution of the per-channel response with the threshold distribution:\n$$\n\\bar{\\epsilon}(q) = \\int_{-\\infty}^{+\\infty} \\epsilon(q \\mid T)\\, p_{T}(T)\\, dT,\n$$\nwhere $\\epsilon(q \\mid T)$ is the per-channel response at threshold $T$, and $p_{T}(T)$ is the probability density function of $T$. The cumulative distribution function (CDF) refers to the integral of a probability density function from $-\\infty$ to a given value.\n\nYour task is to derive, from the fundamental definitions of Gaussian random variables and independence, a closed-form expression for $\\bar{\\epsilon}(q)$, by interpreting the convolution in terms of the probability that the sum of independent Gaussian random variables exceeds zero. Then implement a program that computes $\\bar{\\epsilon}(q)$ for specified parameter sets and charge samples.\n\nUnits and numerical specification:\n- Input parameters $q$, $T_{0}$, $\\sigma_{n}$, and $\\sigma_{T}$ are in ke.\n- The output $\\bar{\\epsilon}(q)$ is unitless and must be reported as real numbers between $0$ and $1$.\n- All reported numerical results must be rounded to $6$ decimal places.\n\nTest suite:\nCompute $\\bar{\\epsilon}(q)$ for the following three parameter sets and lists of $q$ values. Append the results across all $q$ in the order given, and across all test cases in the order listed.\n\n1. General case (happy path): $T_{0} = 20$, $\\sigma_{n} = 0.8$, $\\sigma_{T} = 2$, with $q \\in \\{15, 18, 20, 22, 25\\}$.\n2. No threshold dispersion (boundary case): $T_{0} = 20$, $\\sigma_{n} = 1$, $\\sigma_{T} = 0$, with $q \\in \\{19, 20, 21\\}$.\n3. Dominant threshold dispersion (edge case): $T_{0} = 20$, $\\sigma_{n} = 0.01$, $\\sigma_{T} = 5$, with $q \\in \\{10, 15, 20, 25, 30\\}$.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, with the elements ordered by the test cases and then by the $q$ values as specified (for example, $[r_{1},r_{2},\\dots]$). Each $r_{i}$ must be a float rounded to $6$ decimal places.", "solution": "The problem asks for a closed-form expression for the mean module efficiency, $\\bar{\\epsilon}(q)$, and its numerical evaluation for specified parameters. The analysis begins with a rigorous validation of the problem statement.\n\nThe givens are:\n- Deposited charge: $q$ (in ke).\n- Per-channel electronic noise: $n$, a Gaussian random variable with distribution $n \\sim \\mathcal{N}(0, \\sigma_{n}^{2})$.\n- Per-channel threshold: $T$, a Gaussian random variable with distribution $T \\sim \\mathcal{N}(T_{0}, \\sigma_{T}^{2})$.\n- Statistical independence: $n$ and $T$ are independent random variables.\n- Hit condition for a fixed threshold $T$: $q + n > T$.\n- Per-channel response given $T$: $\\epsilon(q \\mid T) = P(q + n > T \\mid T)$.\n- Mean module efficiency: $\\bar{\\epsilon}(q) = \\int_{-\\infty}^{+\\infty} \\epsilon(q \\mid T)\\, p_{T}(T)\\, dT$, where $p_{T}(T)$ is the probability density function (PDF) of $T$.\n\nThe problem is scientifically grounded, as this model is a standard representation of detector response. It is well-posed, with all variables, parameters, and distributions clearly defined, ensuring a unique solution can be derived. The language is objective and formal. All conditions for a valid problem are met.\n\nThe derivation proceeds as follows. The mean module efficiency $\\bar{\\epsilon}(q)$ is defined as the expectation of the per-channel response $\\epsilon(q \\mid T)$ over the distribution of thresholds $T$.\n$$\n\\bar{\\epsilon}(q) = E_{T}[\\epsilon(q \\mid T)] = E_{T}[P(q + n > T \\mid T)]\n$$\nBy the law of total probability (or iterated expectation), this is equivalent to the unconditional probability that a hit occurs:\n$$\n\\bar{\\epsilon}(q) = P(q + n > T)\n$$\nThis interpretation avoids the direct, and more complex, calculation of the convolution integral. The problem can be solved by analyzing the probability of the event $q + n > T$. To facilitate this, we rearrange the inequality to group the random variables $n$ and $T$:\n$$\nq + n - T > 0\n$$\nLet us define a new random variable $S = n - T$. The problem is now to find the probability $P(q + S > 0)$, which is equivalent to $P(S > -q)$.\n\nThe variable $S$ is a linear combination of two independent Gaussian random variables. The properties of such combinations are well-established.\n1. The random variable $n$ follows the distribution $n \\sim \\mathcal{N}(\\mu_{n}, \\sigma_{n}^{2})$ with $\\mu_{n}=0$.\n2. The random variable $T$ follows the distribution $T \\sim \\mathcal{N}(\\mu_{T}, \\sigma_{T}^{2})$ with $\\mu_{T}=T_{0}$.\n3. The random variable $-T$ is also Gaussian. If a random variable $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$, then $aX+b \\sim \\mathcal{N}(a\\mu+b, a^2\\sigma^2)$. Therefore, $-T = (-1)T + 0$ follows the distribution $-T \\sim \\mathcal{N}(-T_{0}, (-1)^2\\sigma_{T}^{2}) = \\mathcal{N}(-T_{0}, \\sigma_{T}^{2})$.\n\nSince $n$ and $T$ are independent, $n$ and $-T$ are also independent. The sum $S = n + (-T)$ is therefore a Gaussian random variable. Its mean, $\\mu_{S}$, is the sum of the means of its components:\n$$\n\\mu_{S} = E[n - T] = E[n] - E[T] = 0 - T_{0} = -T_{0}\n$$\nIts variance, $\\sigma_{S}^{2}$, is the sum of the variances of its independent components:\n$$\n\\sigma_{S}^{2} = \\mathrm{Var}(n - T) = \\mathrm{Var}(n) + \\mathrm{Var}(-T) = \\sigma_{n}^{2} + \\sigma_{T}^{2}\n$$\nThus, the random variable $S$ follows the distribution $S \\sim \\mathcal{N}(-T_{0}, \\sigma_{n}^{2} + \\sigma_{T}^{2})$. Let us define an effective total standard deviation $\\sigma_{\\mathrm{eff}} = \\sqrt{\\sigma_{n}^{2} + \\sigma_{T}^{2}}$.\n\nWe now compute the probability $P(S > -q)$. To do this, we standardize the variable $S$ by defining a new variable $Z$:\n$$\nZ = \\frac{S - \\mu_{S}}{\\sigma_{S}} = \\frac{S - (-T_{0})}{\\sigma_{\\mathrm{eff}}} = \\frac{S + T_{0}}{\\sigma_{\\mathrm{eff}}}\n$$\nThe variable $Z$ follows the standard normal distribution, $Z \\sim \\mathcal{N}(0, 1)$. We transform the inequality $S > -q$ into an inequality for $Z$:\n$$\nS > -q \\implies S + T_{0} > -q + T_{0} \\implies \\frac{S + T_{0}}{\\sigma_{\\mathrm{eff}}} > \\frac{T_{0} - q}{\\sigma_{\\mathrm{eff}}}\n$$\nSo, we have:\n$$\n\\bar{\\epsilon}(q) = P(S > -q) = P\\left(Z > \\frac{T_{0} - q}{\\sigma_{\\mathrm{eff}}}\\right)\n$$\nThe probability $P(Z > z)$ for a standard normal variable $Z$ is given by $1 - \\Phi(z)$, where $\\Phi(z)$ is the cumulative distribution function (CDF) of the standard normal distribution.\n$$\n\\bar{\\epsilon}(q) = 1 - \\Phi\\left(\\frac{T_{0} - q}{\\sigma_{\\mathrm{eff}}}\\right)\n$$\nDue to the symmetry of the standard normal distribution, $\\Phi(-z) = 1 - \\Phi(z)$. Applying this property, we obtain the final compact expression:\n$$\n\\bar{\\epsilon}(q) = \\Phi\\left(-\\frac{T_{0} - q}{\\sigma_{\\mathrm{eff}}}\\right) = \\Phi\\left(\\frac{q - T_{0}}{\\sigma_{\\mathrm{eff}}}\\right)\n$$\nSubstituting the definition of $\\sigma_{\\mathrm{eff}}$, the closed-form solution for the mean module efficiency is:\n$$\n\\bar{\\epsilon}(q) = \\Phi\\left(\\frac{q - T_{0}}{\\sqrt{\\sigma_{n}^{2} + \\sigma_{T}^{2}}}\\right)\n$$\nThis expression is known as the \"S-curve\" or turn-on curve in detector physics. The standard normal CDF is related to the error function, $\\mathrm{erf}(x)$, by $\\Phi(z) = \\frac{1}{2}\\left[1 + \\mathrm{erf}\\left(\\frac{z}{\\sqrt{2}}\\right)\\right]$. This allows for numerical computation using standard library functions.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes the mean module efficiency for given detector parameters and charge values.\n    \"\"\"\n\n    # Test suite:\n    # Each tuple contains (T0, sigma_n, sigma_T, list_of_q_values)\n    # All charge and threshold parameters are in units of kilo-electron charge (ke).\n    test_cases = [\n        # 1. General case (happy path)\n        (20.0, 0.8, 2.0, [15.0, 18.0, 20.0, 22.0, 25.0]),\n\n        # 2. No threshold dispersion (boundary case)\n        (20.0, 1.0, 0.0, [19.0, 20.0, 21.0]),\n\n        # 3. Dominant threshold dispersion (edge case)\n        (20.0, 0.01, 5.0, [10.0, 15.0, 20.0, 25.0, 30.0]),\n    ]\n\n    all_results = []\n\n    for T0, sigma_n, sigma_T, q_values in test_cases:\n        # The total effective standard deviation is the quadrature sum of the\n        # noise and threshold standard deviations.\n        # sigma_eff = sqrt(sigma_n^2 + sigma_T^2)\n        # Using np.hypot is numerically stable for cases where one term is much larger.\n        sigma_eff = np.hypot(sigma_n, sigma_T)\n\n        for q in q_values:\n            # The argument of the CDF. If sigma_eff is zero, this can lead to division by zero.\n            # However, sigma_eff can only be zero if both sigma_n and sigma_T are zero,\n            # which would make the response a step function. The test cases avoid this singularity.\n            if sigma_eff > 0:\n                z = (q - T0) / sigma_eff\n                # The mean efficiency is the CDF of the standard normal distribution\n                # evaluated at z.\n                efficiency = norm.cdf(z)\n            else:\n                # Handle the deterministic case where all noise/dispersion is zero.\n                # The response is a Heaviside step function.\n                efficiency = 1.0 if q > T0 else (0.5 if q == T0 else 0.0)\n\n            # Round the result to 6 decimal places as required.\n            all_results.append(round(efficiency, 6))\n\n    # Format the final output as a comma-separated list in brackets.\n    # Using map(str, ...) ensures float representation without scientific notation\n    # for small numbers after rounding.\n    output_str = f\"[{','.join(map(str, all_results))}]\"\n    print(output_str)\n\nsolve()\n```", "id": "3536201"}, {"introduction": "From individual hits, we build tracks, but the reconstruction software is complex and can harbor subtle bugs related to geometric conventions. This hands-on practice introduces a \"mirror geometry\" sanity test, a crucial validation technique used to uncover sign-convention errors in track fitting algorithms. By simulating hits in both a normal and a \"mirrored\" detector configuration, you will learn to quantify how such bugs can corrupt fundamental reconstructed properties like particle charge and curvature [@problem_id:3536217].", "problem": "You are tasked with building a self-contained program that performs “mirror geometry” sanity tests for a simplified two-dimensional tracking detector in the transverse plane under a uniform magnetic field. The aim is to detect sign-convention bugs that manifest in charge assignment and curvature estimation when module orientations are inverted in the simulation. The program must implement both the normal geometry and a mirrored-geometry scenario where module local coordinate orientations are inverted, and quantify the effect on the inferred charge sign and the fitted curvature.\n\nFundamental base and scenario:\n- Consider motion of a charged particle in the plane perpendicular to a uniform magnetic field. The Lorentz force law is $\\,\\mathbf{F} = q\\,\\mathbf{v} \\times \\mathbf{B}\\,$, and the transverse motion is circular with radius given by $\\,R = \\frac{p_T}{0.3\\,|q|\\,B}\\,$ where $R$ is in meters if transverse momentum $p_T$ is in $\\mathrm{GeV}/c$ and $B$ is in Tesla. Define the signed curvature as $\\,\\kappa = \\frac{q\\,0.3\\,B}{p_T}\\,$ with units of $\\mathrm{m}^{-1}$. Take the magnetic field direction as $+\\hat{z}$ and the initial velocity along $+\\hat{x}$ at the origin.\n- For $q>0$ under $\\,\\mathbf{B} \\parallel +\\hat{z}\\,$, the trajectory bends clockwise (decreasing azimuth), and for $q<0$ it bends counterclockwise (increasing azimuth).\n\nDetector and measurement model:\n- The tracker consists of $N$ thin cylindrical sensor modules at radii $\\{r_i\\}_{i=1}^N$ from the origin. Each module $i$ has a fixed azimuthal alignment angle $\\phi_i$ (in radians), and measures the local tangential coordinate $u_i$ defined by $\\,u_i = r_i\\left(\\phi_{\\text{hit},i} - \\phi_i\\right)\\,$ where $\\phi_{\\text{hit},i}$ is the true intersection azimuth of the track with the circle of radius $r_i$.\n- A mirrored geometry bug inverts the local coordinate orientation of module $i$, modeled by $\\,u_i' = -u_i\\,$. Reconstruction from local coordinates is performed as $\\,\\phi_{\\text{meas},i} = \\phi_i + \\frac{u_i}{r_i}\\,$ in the normal geometry, and $\\,\\phi_{\\text{meas},i}' = \\phi_i + \\frac{u_i'}{r_i} = 2\\phi_i - \\phi_{\\text{hit},i}\\,$ in the mirrored geometry.\n- The measured two-dimensional hit positions are $\\,\\mathbf{x}_i = \\left(r_i\\cos\\phi_{\\text{meas},i},\\, r_i\\sin\\phi_{\\text{meas},i}\\right)\\,$.\n\nInference tasks to implement:\n1. Given three or more measured points $\\,\\{\\mathbf{x}_i\\}\\,$, fit the best circle in the algebraic least-squares sense by solving $\\,x^2 + y^2 + D x + E y + F = 0\\,$ for $(D,E,F)$, then compute the center $\\,\\left(-\\frac{D}{2}, -\\frac{E}{2}\\right)\\,$ and radius $\\,R_{\\text{fit}} = \\sqrt{\\frac{D^2 + E^2}{4} - F}\\,$.\n2. Infer the charge sign $\\,q_{\\text{inf}}\\,$ using the direction of azimuthal evolution of the measured hits with increasing radius, by unwrapping the measured azimuths to a continuous sequence and evaluating the sign of their net change: decreasing azimuth implies $q_{\\text{inf}} = +1$, increasing implies $q_{\\text{inf}} = -1$.\n3. Compute the signed curvature estimate $\\,\\kappa_{\\text{fit}} = \\frac{q_{\\text{inf}}}{R_{\\text{fit}}}\\,$.\n\nYour program must:\n- Implement the above for both normal geometry and mirrored geometry (with per-module control of whether a module is mirrored).\n- Return, for each test case, three quantities:\n    - A boolean indicating whether $q_{\\text{inf}}$ from the normal geometry equals the true charge $q$.\n    - A boolean indicating whether $q_{\\text{inf}}$ from the mirrored geometry equals $-q$ (i.e., expected flip under full mirroring).\n    - A float equal to the ratio $\\,\\frac{\\kappa_{\\text{fit}}^{\\text{(mirrored)}}}{\\kappa_{\\text{fit}}^{\\text{(normal)}}}\\,$, with the convention that if $\\left|\\kappa_{\\text{fit}}^{\\text{(normal)}}\\right|$ is numerically indistinguishable from zero (use a threshold of $10^{-9}\\,\\mathrm{m}^{-1}$), define the ratio as $0.0$.\n\nTrack-circle intersection:\n- Under the initial conditions described, the trajectory lies on the circle $\\,x^2 + (y + R_s)^2 = R_s^2\\,$ where $\\,R_s = \\text{sgn}(q)\\,R\\,$. The intersection with the detector circle $\\,x^2 + y^2 = r_i^2\\,$ yields the hit coordinate\n$$\ny_i = -\\frac{r_i^2}{2 R_s},\\quad x_i = +\\sqrt{r_i^2 - y_i^2},\\quad \\phi_{\\text{hit},i} = \\operatorname{atan2}(y_i, x_i).\n$$\nUse the positive $x_i$ solution corresponding to forward motion along $+\\hat{x}$.\n\nUnits and angles:\n- Use $p_T$ in $\\mathrm{GeV}/c$, $B$ in Tesla, $r_i$ in meters, and all angles in radians.\n\nTest suite:\nProvide the following five test cases to the program, each specified by $(q, p_T, B, \\{r_i\\}, \\{\\phi_i\\}, \\{\\text{mirror}_i\\})$, where $\\text{mirror}_i$ is a boolean per module:\n1. $(+1,\\,2.0,\\,2.0,\\,[0.30,0.50,0.70],\\,[0.20,0.40,0.60],\\,[\\text{False},\\text{False},\\text{False}])$ — general “happy path”.\n2. $(+1,\\,2.0,\\,2.0,\\,[0.30,0.50,0.70],\\,[0.20,0.40,0.60],\\,[\\text{True},\\text{True},\\text{True}])$ — full mirroring to test expected sign flip.\n3. $(-1,\\,3.0,\\,2.0,\\,[0.30,0.55,0.75],\\,[0.10,0.35,0.90],\\,[\\text{False},\\text{False},\\text{False}])$ — opposite charge case.\n4. $(+1,\\,5.0,\\,2.0,\\,[0.35,0.65,0.85],\\,[0.30,0.50,1.20],\\,[\\text{True},\\text{False},\\text{True}])$ — mixed mirroring to test inconsistent module orientations.\n5. $(+1,\\,100.0,\\,2.0,\\,[0.30,0.50,0.70],\\,[0.20,0.40,0.60],\\,[\\text{True},\\text{True},\\text{True}])$ — high-momentum, near-straight boundary.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a list of lists, where each inner list corresponds to one test case and contains: $[\\text{boolean}, \\text{boolean}, \\text{float}]$. The float should be rounded to six decimal places. For example: “[ [True,False,-1.000000], [True,True,-1.000000], ... ]”.", "solution": "The problem statement is deemed valid. It is scientifically grounded in the principles of charged particle dynamics in a magnetic field and standard models of particle tracking detectors. The problem is well-posed, with all necessary physical parameters, mathematical formulae, and algorithmic procedures clearly defined to allow for a unique, deterministic solution. The language is objective and precise. The task is a relevant and non-trivial exercise in computational high-energy physics, specifically in the area of software validation for detector simulation and event reconstruction.\n\nThe solution is architected as a step-by-step simulation and reconstruction process, which is executed for each of the provided test cases. This process is performed twice for every case: once under a \"normal\" geometry assumption, and once under a \"mirrored\" geometry assumption, to quantify the effects of a simulated sign-convention bug.\n\n### 1. Generation of True Trajectory and Hit Points\n\nThe foundation of the simulation is the generation of a particle's true trajectory. A particle with charge $q$, transverse momentum $p_T$, moving in a uniform magnetic field $B$ perpendicular to its velocity, follows a circular path. The radius of this circle, $R$, is given by the Lorentz force law, which in the specified units ($\\mathrm{GeV}/c$ for $p_T$, Tesla for $B$, meters for $R$) is:\n$$\nR = \\frac{p_T}{0.3\\,|q|\\,B}\n$$\nTo account for the direction of bending, we define a signed radius, $R_s$, and a corresponding signed curvature, $\\kappa$:\n$$\nR_s = \\text{sgn}(q)R = \\frac{p_T}{0.3\\,q\\,B}, \\quad \\kappa = \\frac{1}{R_s} = \\frac{q\\,0.3\\,B}{p_T}\n$$\nGiven the initial condition that the particle originates at $(0,0)$ with velocity along the $+\\hat{x}$ direction and the magnetic field is along $+\\hat{z}$, the trajectory lies on a circle with its center at $(0, -R_s)$. The equation of this circle is $x^2 + (y + R_s)^2 = R_s^2$.\n\nThe true intersection points of this trajectory with the cylindrical detector modules at radii $\\{r_i\\}$ are found by solving the system of equations for the trajectory circle and a detector circle, $x^2 + y^2 = r_i^2$. This yields the hit coordinates $(x_i, y_i)$:\n$$\ny_i = -\\frac{r_i^2}{2 R_s}, \\quad x_i = +\\sqrt{r_i^2 - y_i^2}\n$$\nThe positive solution for $x_i$ is chosen to represent a forward-propagating particle. The true azimuth of each hit, $\\phi_{\\text{hit},i}$, is then calculated as $\\operatorname{atan2}(y_i, x_i)$.\n\n### 2. Simulation of Detector Measurement\n\nThe detector's measurement process is modeled for each module $i$. A module at radius $r_i$ is characterized by an alignment angle $\\phi_i$. It measures the local tangential coordinate $u_i$:\n$$\nu_i = r_i\\left(\\phi_{\\text{hit},i} - \\phi_i\\right)\n$$\nFrom this local coordinate, a \"measured\" azimuth is reconstructed:\n$$\n\\phi_{\\text{meas},i} = \\phi_i + \\frac{u_i}{r_i} = \\phi_i + \\left(\\phi_{\\text{hit},i} - \\phi_i\\right) = \\phi_{\\text{hit},i}\n$$\nIn the normal geometry, the reconstructed azimuth is identical to the true hit azimuth.\n\nThe \"mirrored geometry\" bug is modeled by an inversion of the local coordinate, $u_i' = -u_i$. The reconstruction of the mirrored azimuth $\\phi_{\\text{meas},i}'$ proceeds as:\n$$\n\\phi_{\\text{meas},i}' = \\phi_i + \\frac{u_i'}{r_i} = \\phi_i - \\left(\\phi_{\\text{hit},i} - \\phi_i\\right) = 2\\phi_i - \\phi_{\\text{hit},i}\n$$\nThis transformation corresponds to a reflection of the true hit's azimuth across the module's alignment azimuth. The measured Cartesian hit coordinates $\\{\\mathbf{x}_i\\}$ are then computed as $(r_i\\cos\\phi_{\\text{meas},i}, r_i\\sin\\phi_{\\text{meas},i})$ for both normal and mirrored scenarios. The program implements two reconstruction passes for each test case: one with all modules treated as normal (all mirror flags `False`), and one using the mirror flags specified in the test case.\n\n### 3. Inference of Track Parameters\n\nFrom the set of measured hit points $\\{\\mathbf{x}_i\\}$, the track parameters are inferred.\n\n**Circle Fit:** The points are fitted to the general equation of a circle, $x^2 + y^2 + D x + E y + F = 0$. This is accomplished via an algebraic least-squares method. For a set of $N$ points $(x_i, y_i)$, we form a linear system $A \\mathbf{v} = \\mathbf{b}$, where:\n$$\nA = \\begin{pmatrix} x_1 & y_1 & 1 \\\\ x_2 & y_2 & 1 \\\\ \\vdots & \\vdots & \\vdots \\\\ x_N & y_N & 1 \\end{pmatrix}, \\quad \\mathbf{v} = \\begin{pmatrix} D \\\\ E \\\\ F \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} -(x_1^2 + y_1^2) \\\\ -(x_2^2 + y_2^2) \\\\ \\vdots \\\\ -(x_N^2 + y_N^2) \\end{pmatrix}\n$$\nThis system is solved for $\\mathbf{v}$ using `numpy.linalg.lstsq`. The fitted radius, $R_{\\text{fit}}$, is then calculated from the coefficients:\n$$\nR_{\\text{fit}} = \\sqrt{\\frac{D^2 + E^2}{4} - F}\n$$\n\n**Charge Sign Inference:** The particle's charge sign, $q_{\\text{inf}}$, is inferred from the bending direction. For the given setup ($\\mathbf{B} \\parallel +\\hat{z}$, initial $\\mathbf{v} \\parallel +\\hat{x}$), a positive charge ($q>0$) results in a clockwise-bending-trajectory (decreasing azimuth), and a negative charge ($q<0$) results in a counter-clockwise bend (increasing azimuth). The sequence of measured azimuths, $\\{\\phi_{\\text{meas},i}\\}$, sorted by increasing radius, is first \"unwrapped\" to remove $2\\pi$ discontinuities. The sign of the net change in the unwrapped azimuths determines the inferred charge: a negative net change implies $q_{\\text{inf}} = +1$, and a positive net change implies $q_{\\text{inf}} = -1$.\n\n**Signed Curvature:** Finally, the estimated signed curvature, $\\kappa_{\\text{fit}}$, is computed by combining the inferred charge and fitted radius:\n$$\n\\kappa_{\\text{fit}} = \\frac{q_{\\text{inf}}}{R_{\\text{fit}}}\n$$\n\n### 4. Computation of Test Outputs\n\nFor each test case, the above simulation and reconstruction pipeline is executed for both the normal and mirrored configurations. The results are used to compute three specified outputs:\n1.  A boolean, `True` if the charge inferred from the normal geometry, $q_{\\text{inf}}^{\\text{(normal)}}$, matches the true charge, $q$.\n2.  A boolean, `True` if the charge inferred from the mirrored geometry, $q_{\\text{inf}}^{\\text{(mirrored)}}$, is the opposite of the true charge, i.e., $q_{\\text{inf}}^{\\text{(mirrored)}} = -q$.\n3.  The floating-point ratio of the signed curvatures, $\\kappa_{\\text{fit}}^{\\text{(mirrored)}} / \\kappa_{\\text{fit}}^{\\text{(normal)}}$. A special condition handles the case where the denominator $|\\kappa_{\\text{fit}}^{\\text{(normal)}}|$ is smaller than a threshold of $10^{-9}\\,\\mathrm{m}^{-1}$, in which case the ratio is defined as $0.0$.\n\nThe program iterates through all $5$ test cases, generating these three outputs for each one, and formats them into a single-line list of lists as required.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    C = 0.3  # Constant for pT to radius conversion\n\n    def algebraic_circle_fit(points):\n        \"\"\"\n        Fits a circle to a set of 2D points using algebraic least-squares.\n\n        Args:\n            points: A numpy array of shape (N, 2) with (x, y) coordinates.\n\n        Returns:\n            A tuple (D, E, F) of the circle equation x^2 + y^2 + Dx + Ey + F = 0.\n        \"\"\"\n        x = points[:, 0]\n        y = points[:, 1]\n        A = np.c_[x, y, np.ones_like(x)]\n        b = -(x**2 + y**2)\n        \n        # Use rcond=None to suppress future warnings and use the default behavior.\n        D, E, F = np.linalg.lstsq(A, b, rcond=None)[0]\n        return D, E, F\n\n    def get_reconstruction_results(q_true, pT, B, radii, phis, mirror_flags):\n        \"\"\"\n        Simulates and reconstructs a single track scenario.\n\n        Args:\n            q_true (int): True charge of the particle (+1 or -1).\n            pT (float): Transverse momentum in GeV/c.\n            B (float): Magnetic field in Tesla.\n            radii (np.array): Detector module radii in meters.\n            phis (np.array): Detector module alignment angles in radians.\n            mirror_flags (np.array): Boolean flags for mirrored modules.\n\n        Returns:\n            A tuple (q_inf, kappa_fit) containing the inferred charge and \n            the fitted signed curvature.\n        \"\"\"\n        if pT == 0:\n            return (0, 0.0)\n\n        # 1. Calculate true track parameters\n        R_true = pT / (C * abs(q_true) * B)\n        Rs_true = np.sign(q_true) * R_true\n\n        # 2. Generate true hits on detector layers\n        true_hits_y = -radii**2 / (2 * Rs_true)\n        \n        # Ensure that the particle can physically reach the radius\n        if np.any(radii**2 < true_hits_y**2):\n            # This happens if r > 2*R_true, i.e., track turns back\n            raise ValueError(\"Detector radius is larger than track diameter.\")\n            \n        true_hits_x = np.sqrt(radii**2 - true_hits_y**2)\n        true_hit_phis = np.arctan2(true_hits_y, true_hits_x)\n\n        # 3. Simulate detector measurements\n        u_local = radii * (true_hit_phis - phis)\n        u_measured = np.where(mirror_flags, -u_local, u_local)\n        phi_measured = phis + u_measured / radii\n        \n        measured_points = np.c_[radii * np.cos(phi_measured), radii * np.sin(phi_measured)]\n\n        # 4. Reconstruct parameters from measured points\n        try:\n            D, E, F = algebraic_circle_fit(measured_points)\n            R_fit = np.sqrt(D**2 / 4 + E**2 / 4 - F)\n        except (np.linalg.LinAlgError, ValueError):\n            # Handle degenerate cases (e.g., collinear points) or numerical instability\n            return (0, np.nan)\n\n        unwrapped_phis = np.unwrap(phi_measured)\n        delta_phi = unwrapped_phis[-1] - unwrapped_phis[0]\n        q_inf = -1 if delta_phi > 0 else 1\n        \n        if R_fit == 0:\n            kappa_fit = np.inf * np.sign(q_inf)\n        else:\n            kappa_fit = q_inf / R_fit\n        \n        return q_inf, kappa_fit\n\n    test_cases = [\n        (1, 2.0, 2.0, [0.30, 0.50, 0.70], [0.20, 0.40, 0.60], [False, False, False]),\n        (1, 2.0, 2.0, [0.30, 0.50, 0.70], [0.20, 0.40, 0.60], [True, True, True]),\n        (-1, 3.0, 2.0, [0.30, 0.55, 0.75], [0.10, 0.35, 0.90], [False, False, False]),\n        (1, 5.0, 2.0, [0.35, 0.65, 0.85], [0.30, 0.50, 1.20], [True, False, True]),\n        (1, 100.0, 2.0, [0.30, 0.50, 0.70], [0.20, 0.40, 0.60], [True, True, True]),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        q_true, pT, B, r_list, phi_list, mirror_list = case\n        \n        radii = np.array(r_list)\n        phis = np.array(phi_list)\n        mirror_flags_case = np.array(mirror_list)\n\n        # Normal Geometry Run (all mirror flags are False)\n        mirror_flags_normal = np.zeros_like(mirror_flags_case, dtype=bool)\n        q_inf_normal, kappa_fit_normal = get_reconstruction_results(\n            q_true, pT, B, radii, phis, mirror_flags_normal\n        )\n\n        # Mirrored Geometry Run (using mirror flags from test case)\n        q_inf_mirrored, kappa_fit_mirrored = get_reconstruction_results(\n            q_true, pT, B, radii, phis, mirror_flags_case\n        )\n        \n        # Calculate the three output quantities for the test case\n        q_normal_correct = (q_inf_normal == q_true)\n        q_mirrored_flipped = (q_inf_mirrored == -q_true)\n        \n        kappa_threshold = 1e-9\n        if abs(kappa_fit_normal) < kappa_threshold:\n            kappa_ratio = 0.0\n        else:\n            kappa_ratio = kappa_fit_mirrored / kappa_fit_normal\n\n        all_results.append([\n            q_normal_correct,\n            q_mirrored_flipped,\n            kappa_ratio\n        ])\n\n    # Format the final output string as specified\n    output_parts = []\n    for res in all_results:\n        # Format: [boolean, boolean, float]\n        # Python's str(bool) is 'True'/'False', which matches the example.\n        # The float is rounded to 6 decimal places.\n        inner_str = f\"[{res[0]},{res[1]},{res[2]:.6f}]\"\n        output_parts.append(inner_str)\n\n    print(f\"[{','.join(output_parts)}]\")\n\nsolve()\n```", "id": "3536217"}, {"introduction": "A key application of tracking is to measure a particle's displacement from its production point, quantified by impact parameters like $d_0$ and $z_0$. This measurement, however, is affected by uncertainties in the reconstructed primary vertex position, a significant source of systematic error. This exercise guides you through the analytical propagation of vertex uncertainties to the impact parameters, providing a powerful method to estimate systematic biases and resolutions without resorting to computationally expensive Monte Carlo simulations [@problem_id:3536226].", "problem": "Consider a tracking detector in a uniform magnetic field where, over small lever arms near the interaction point, charged particle trajectories can be approximated as straight lines. The true primary vertex is taken to be at the origin. The measured primary vertex position is modeled as a random vector $\\delta \\mathbf{r} = (\\delta x, \\delta y, \\delta z)$ representing the mismeasurement of the vertex position relative to the origin. The mismeasurement is modeled by a multivariate normal distribution with mean vector $\\boldsymbol{\\mu}$ (in meters) and covariance matrix $\\Sigma$ (in square meters), which may include correlations between components. In dense environments, both $\\boldsymbol{\\mu}$ and $\\Sigma$ may deviate from ideal low-density values due to reconstruction biases and degraded resolutions.\n\nA track is represented near the origin by a straight line through the origin with unit direction vector $\\hat{\\mathbf{u}}(\\phi, \\theta) = (\\cos \\phi \\sin \\theta, \\sin \\phi \\sin \\theta, \\cos \\theta)$, where $\\phi$ is the azimuthal angle in the transverse plane (in radians) and $\\theta$ is the polar angle measured from the $z$ axis (in radians). Define the transverse unit tangent and normal vectors by $\\hat{\\mathbf{t}}(\\phi) = (\\cos \\phi, \\sin \\phi)$ and $\\hat{\\mathbf{n}}(\\phi) = (-\\sin \\phi, \\cos \\phi)$, respectively.\n\nThe signed transverse impact parameter $d_0$ is defined as the signed transverse distance of closest approach between the track and the measured primary vertex, using the transverse normal $\\hat{\\mathbf{n}}(\\phi)$ for sign convention in a right-handed coordinate system. The longitudinal impact parameter $z_0$ is defined as the difference between the track’s $z$ coordinate at the transverse point of closest approach and the measured primary vertex’s $z$ coordinate.\n\nAssume small primary vertex displacements and small local track curvature so that the impact parameter biases may be linearized with respect to $\\delta \\mathbf{r}$. Treat $\\delta \\mathbf{r}$ as multivariate normal with the provided $\\boldsymbol{\\mu}$ and $\\Sigma$. For an ensemble of tracks, compute:\n1. The ensemble mean $d_0$ bias (in meters).\n2. The ensemble mean $z_0$ bias (in meters).\n3. The ensemble root-mean-square (RMS) of $d_0$ bias (in meters), defined as the square root of the ensemble average of $d_0^2$ over the primary vertex distribution and the track sample.\n4. The ensemble root-mean-square (RMS) of $z_0$ bias (in meters), defined analogously.\n\nAngles must be in radians. All distances must be expressed in meters. Your program must not perform any event-level Monte Carlo sampling; instead, you must use analytical propagation based on the linearization and properties of the multivariate normal distribution. The ensemble averages must be computed over the provided finite track sets using their specified weights.\n\nTest Suite:\nFor each test case, a set of track angles and weights is given along with $\\boldsymbol{\\mu}$ and $\\Sigma$. The covariance matrix $\\Sigma$ is symmetric and specified by its entries in meters squared. In all cases, answer in meters.\n\n- Test Case 1 (low-density baseline):\n  - $\\boldsymbol{\\mu} = (0,\\ 0,\\ 0)$.\n  - $\\Sigma$ with entries:\n    - $\\Sigma_{xx} = (20 \\times 10^{-6})^2$, $\\Sigma_{yy} = (20 \\times 10^{-6})^2$, $\\Sigma_{zz} = (40 \\times 10^{-6})^2$,\n    - $\\Sigma_{xy} = \\Sigma_{xz} = \\Sigma_{yz} = 0$.\n  - Tracks (each with weight $1$):\n    - $(\\phi,\\ \\theta) = (0.0,\\ 1.3)$,\n    - $(\\phi,\\ \\theta) = (1.0,\\ 1.0)$,\n    - $(\\phi,\\ \\theta) = (2.3,\\ 0.8)$,\n    - $(\\phi,\\ \\theta) = (3.0,\\ \\frac{\\pi}{2})$,\n    - $(\\phi,\\ \\theta) = (4.2,\\ 1.2)$.\n\n- Test Case 2 (dense environment with anisotropic transverse resolution and nonzero mean bias):\n  - $\\boldsymbol{\\mu} = (10 \\times 10^{-6},\\ -5 \\times 10^{-6},\\ 30 \\times 10^{-6})$.\n  - $\\Sigma$ with entries:\n    - $\\Sigma_{xx} = (60 \\times 10^{-6})^2$, $\\Sigma_{yy} = (40 \\times 10^{-6})^2$, $\\Sigma_{zz} = (80 \\times 10^{-6})^2$,\n    - $\\Sigma_{xy} = 0.3 \\times (60 \\times 10^{-6}) \\times (40 \\times 10^{-6})$,\n    - $\\Sigma_{xz} = \\Sigma_{yz} = 0$.\n  - Tracks (each with weight $1$):\n    - $(\\phi,\\ \\theta) = (0.2,\\ 1.4)$,\n    - $(\\phi,\\ \\theta) = (1.1,\\ 0.9)$,\n    - $(\\phi,\\ \\theta) = (2.5,\\ 1.1)$,\n    - $(\\phi,\\ \\theta) = (3.7,\\ 1.2)$,\n    - $(\\phi,\\ \\theta) = (5.0,\\ 0.7)$,\n    - $(\\phi,\\ \\theta) = (0.8,\\ 1.3)$.\n\n- Test Case 3 (forward track mix with $x$–$z$ correlation):\n  - $\\boldsymbol{\\mu} = (0,\\ 0,\\ 15 \\times 10^{-6})$.\n  - $\\Sigma$ with entries:\n    - $\\Sigma_{xx} = (50 \\times 10^{-6})^2$, $\\Sigma_{yy} = (50 \\times 10^{-6})^2$, $\\Sigma_{zz} = (70 \\times 10^{-6})^2$,\n    - $\\Sigma_{xy} = -0.2 \\times (50 \\times 10^{-6}) \\times (50 \\times 10^{-6})$,\n    - $\\Sigma_{xz} = 0.2 \\times (50 \\times 10^{-6}) \\times (70 \\times 10^{-6})$,\n    - $\\Sigma_{yz} = 0$.\n  - Tracks (each with weight $1$):\n    - $(\\phi,\\ \\theta) = (0.0,\\ 0.25)$,\n    - $(\\phi,\\ \\theta) = (1.5,\\ 0.35)$,\n    - $(\\phi,\\ \\theta) = (\\pi,\\ 0.5)$,\n    - $(\\phi,\\ \\theta) = (4.0,\\ 0.9)$.\n\n- Test Case 4 (deterministic bias, zero covariance):\n  - $\\boldsymbol{\\mu} = (30 \\times 10^{-6},\\ -30 \\times 10^{-6},\\ -20 \\times 10^{-6})$.\n  - $\\Sigma$ is the zero matrix (all entries $0$).\n  - Tracks (each with weight $1$):\n    - $(\\phi,\\ \\theta) = (0.3,\\ 1.0)$,\n    - $(\\phi,\\ \\theta) = (2.7,\\ 1.2)$,\n    - $(\\phi,\\ \\theta) = (5.5,\\ 0.8)$.\n\nComputation and Output Specification:\n- For each test case, compute the four quantities listed above: ensemble mean $d_0$, ensemble mean $z_0$, ensemble RMS $d_0$, ensemble RMS $z_0$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[result1,result2,...]\"), concatenating the four results for Test Case 1, followed by the four results for Test Case 2, then Test Case 3, then Test Case 4. All outputs must be in meters.", "solution": "The problem requires the calculation of ensemble-averaged biases and root-mean-square (RMS) values for the transverse ($d_0$) and longitudinal ($z_0$) impact parameters of particle tracks, given a statistical model for the mismeasurement of the primary vertex position. We are to perform an analytical calculation, propagating the uncertainty from the vertex measurement to the impact parameters.\n\n### Problem Formalization\n\nThe true primary vertex is at the origin, $\\mathbf{r}_{true} = (0, 0, 0)$. The measured primary vertex position, $\\mathbf{r}_v$, is offset from the true vertex by a random displacement vector $\\delta \\mathbf{r} = (\\delta x, \\delta y, \\delta z)$. This displacement is modeled as a $3$-dimensional multivariate normal distribution, $\\delta \\mathbf{r} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\Sigma)$, with mean vector $\\boldsymbol{\\mu} = (\\mu_x, \\mu_y, \\mu_z)^T$ and covariance matrix $\\Sigma$.\n\nA track is approximated as a straight line passing through the true origin with a unit direction vector $\\hat{\\mathbf{u}}(\\phi, \\theta) = (\\sin\\theta \\cos\\phi, \\sin\\theta \\sin\\phi, \\cos\\theta)$, where $\\phi$ is the azimuthal angle and $\\theta$ is the polar angle.\n\n### Derivation of Impact Parameters\n\nFirst, we express the impact parameters $d_0$ and $z_0$ as linear functions of the vertex displacement components $\\delta x$, $\\delta y$, and $\\delta z$.\n\n1.  **Transverse Impact Parameter ($d_0$)**: The signed transverse impact parameter $d_0$ is the signed distance of closest approach in the transverse ($x$-$y$) plane between the track's path (a line through the origin) and the measured vertex's transverse position $\\mathbf{r}_{v,T} = (\\delta x, \\delta y)$. The sign is determined by the projection onto the transverse normal vector $\\hat{\\mathbf{n}}(\\phi) = (-\\sin\\phi, \\cos\\phi)$.\n    $$d_0 = \\mathbf{r}_{v,T} \\cdot \\hat{\\mathbf{n}}(\\phi) = (\\delta x, \\delta y) \\cdot (-\\sin\\phi, \\cos\\phi)$$\n    $$d_0 = -\\delta x \\sin\\phi + \\delta y \\cos\\phi$$\n    This is a linear function of $\\delta \\mathbf{r}$. We can write $d_0 = \\mathbf{c}_{d_0}^T \\delta \\mathbf{r}$, where the coefficient vector is $\\mathbf{c}_{d_0} = (-\\sin\\phi, \\cos\\phi, 0)^T$.\n\n2.  **Longitudinal Impact Parameter ($z_0$)**: The longitudinal impact parameter $z_0$ is defined as $z_0 = z_{track} - z_v$, where $z_v = \\delta z$ is the measured vertex $z$-coordinate, and $z_{track}$ is the track's $z$-coordinate at the point of closest transverse approach. The transverse path length $s_T$ from the origin to this point is the projection of $\\mathbf{r}_{v,T}$ onto the transverse track direction $\\hat{\\mathbf{t}}(\\phi) = (\\cos\\phi, \\sin\\phi)$:\n    $$s_T = \\mathbf{r}_{v,T} \\cdot \\hat{\\mathbf{t}}(\\phi) = \\delta x \\cos\\phi + \\delta y \\sin\\phi$$\n    The corresponding $3$D path length along the track is $s = s_T / \\sin\\theta$, assuming $\\sin\\theta \\neq 0$. The track's $z$-coordinate at this point is $z_{track} = s \\cos\\theta = s_T \\cot\\theta$.\n    $$z_{track} = (\\delta x \\cos\\phi + \\delta y \\sin\\phi) \\cot\\theta$$\n    Therefore, $z_0$ is:\n    $$z_0 = (\\delta x \\cos\\phi + \\delta y \\sin\\phi) \\cot\\theta - \\delta z$$\n    This is also a linear function of $\\delta \\mathbf{r}$, with $z_0 = \\mathbf{c}_{z_0}^T \\delta \\mathbf{r}$ and the coefficient vector $\\mathbf{c}_{z_0} = (\\cos\\phi \\cot\\theta, \\sin\\phi \\cot\\theta, -1)^T$.\n\n### Bias and RMS Calculation\n\nFor a generic quantity $Q = \\mathbf{c}^T \\delta \\mathbf{r}$, where $\\delta \\mathbf{r} \\sim \\mathcal{N}(\\boldsymbol{\\mu}, \\Sigma)$, its expectation value (mean) and variance are given by the standard rules for affine transformations of random vectors:\n-   Mean: $E[Q] = \\mathbf{c}^T E[\\delta \\mathbf{r}] = \\mathbf{c}^T \\boldsymbol{\\mu}$\n-   Variance: $\\text{Var}(Q) = \\mathbf{c}^T \\text{Cov}(\\delta \\mathbf{r}) \\mathbf{c} = \\mathbf{c}^T \\Sigma \\mathbf{c}$\n\nThe mean square is related to the mean and variance by $E[Q^2] = \\text{Var}(Q) + (E[Q])^2$. The subscript $v$ will denote expectation over the vertex distribution.\n\n**For a single track with parameters $(\\phi, \\theta)$:**\n\n-   **Mean Biases**:\n    $$E_v[d_0] = \\mathbf{c}_{d_0}^T \\boldsymbol{\\mu} = -\\mu_x \\sin\\phi + \\mu_y \\cos\\phi$$\n    $$E_v[z_0] = \\mathbf{c}_{z_0}^T \\boldsymbol{\\mu} = (\\mu_x \\cos\\phi + \\mu_y \\sin\\phi) \\cot\\theta - \\mu_z$$\n\n-   **Variances**:\n    $$\\text{Var}_v(d_0) = \\mathbf{c}_{d_0}^T \\Sigma \\mathbf{c}_{d_0} = \\Sigma_{xx} \\sin^2\\phi + \\Sigma_{yy} \\cos^2\\phi - 2\\Sigma_{xy} \\sin\\phi \\cos\\phi$$\n    $$\\text{Var}_v(z_0) = \\mathbf{c}_{z_0}^T \\Sigma \\mathbf{c}_{z_0} = \\cot^2\\theta(\\Sigma_{xx}\\cos^2\\phi + \\Sigma_{yy}\\sin^2\\phi + 2\\Sigma_{xy}\\sin\\phi\\cos\\phi) - 2\\cot\\theta(\\Sigma_{xz}\\cos\\phi + \\Sigma_{yz}\\sin\\phi) + \\Sigma_{zz}$$\n\n-   **Mean Squares**:\n    $$E_v[d_0^2] = \\text{Var}_v(d_0) + (E_v[d_0])^2$$\n    $$E_v[z_0^2] = \\text{Var}_v(z_0) + (E_v[z_0])^2$$\n\n### Ensemble Averaging\n\nThe problem asks for quantities averaged over both the vertex distribution and a finite sample of $N$ tracks, $\\{(\\phi_i, \\theta_i)\\}_{i=1}^N$, each with a weight $w_i$. The total weight is $W = \\sum_{i=1}^N w_i$. The ensemble average of a quantity $X$, denoted $\\langle X \\rangle$, is calculated as:\n$$\\langle X \\rangle = \\frac{1}{W} \\sum_{i=1}^N w_i E_v[X_i]$$\nwhere $X_i$ is the quantity evaluated for track $i$.\n\nThe four required quantities are:\n1.  Ensemble Mean $d_0$ Bias: $\\langle d_0 \\rangle = \\frac{1}{W} \\sum_{i=1}^N w_i E_v[d_{0, i}]$\n2.  Ensemble Mean $z_0$ Bias: $\\langle z_0 \\rangle = \\frac{1}{W} \\sum_{i=1}^N w_i E_v[z_{0, i}]$\n3.  Ensemble RMS of $d_0$: $\\text{RMS}(d_0) = \\sqrt{\\langle d_0^2 \\rangle} = \\sqrt{\\frac{1}{W} \\sum_{i=1}^N w_i E_v[d_{0, i}^2]}$\n4.  Ensemble RMS of $z_0$: $\\text{RMS}(z_0) = \\sqrt{\\langle z_0^2 \\rangle} = \\sqrt{\\frac{1}{W} \\sum_{i=1}^N w_i E_v[z_{0, i}^2]}$\n\nThese formulas provide a complete analytical prescription for computing the required results for each test case without Monte Carlo simulation. The implementation involves applying these formulas to the given numerical data for $\\boldsymbol{\\mu}$, $\\Sigma$, and the track samples.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem for all test cases and prints the results.\n    \"\"\"\n\n    def build_sigma(params):\n        \"\"\"\n        Builds the 3x3 symmetric covariance matrix from a dictionary of parameters.\n        \"\"\"\n        sigma = np.zeros((3, 3))\n        sigma[0, 0] = params.get('xx', 0.0)\n        sigma[1, 1] = params.get('yy', 0.0)\n        sigma[2, 2] = params.get('zz', 0.0)\n        sigma[0, 1] = sigma[1, 0] = params.get('xy', 0.0)\n        sigma[0, 2] = sigma[2, 0] = params.get('xz', 0.0)\n        sigma[1, 2] = sigma[2, 1] = params.get('yz', 0.0)\n        return sigma\n\n    def calculate_ensemble_stats(mu, sigma, tracks):\n        \"\"\"\n        Calculates ensemble statistics for a given mu, sigma, and set of tracks.\n        \"\"\"\n        sum_mean_d0 = 0.0\n        sum_mean_z0 = 0.0\n        sum_mean_sq_d0 = 0.0\n        sum_mean_sq_z0 = 0.0\n        total_weight = 0.0\n\n        mu_x, mu_y, mu_z = mu\n        s_xx, s_xy, s_xz = sigma[0, 0], sigma[0, 1], sigma[0, 2]\n        s_yy, s_yz = sigma[1, 1], sigma[1, 2]\n        s_zz = sigma[2, 2]\n\n        for phi, theta, weight in tracks:\n            sin_phi = np.sin(phi)\n            cos_phi = np.cos(phi)\n            \n            # Handle cot(theta) carefully for theta near multiples of pi.\n            # For this problem's inputs, this is safe.\n            sin_theta = np.sin(theta)\n            if np.isclose(sin_theta, 0):\n                # For tracks along the z-axis, cot(theta) is infinite.\n                # z0 definition is ill-defined. However, test cases avoid this.\n                # If needed, a special handling would be placed here.\n                # For this problem, we can assume sin_theta is not zero.\n                cot_theta = np.inf if np.cos(theta) > 0 else -np.inf\n            else:\n                cot_theta = np.cos(theta) / sin_theta\n\n            # Mean biases for this track\n            mean_d0 = -mu_x * sin_phi + mu_y * cos_phi\n            mean_z0 = (mu_x * cos_phi + mu_y * sin_phi) * cot_theta - mu_z\n\n            # Variances for this track\n            var_d0 = s_xx * sin_phi**2 + s_yy * cos_phi**2 - 2 * s_xy * sin_phi * cos_phi\n            \n            var_z0_term1 = (s_xx * cos_phi**2 + s_yy * sin_phi**2 + 2 * s_xy * sin_phi * cos_phi) * cot_theta**2\n            var_z0_term2 = -2 * (s_xz * cos_phi + s_yz * sin_phi) * cot_theta\n            var_z0_term3 = s_zz\n            var_z0 = var_z0_term1 + var_z0_term2 + var_z0_term3\n            \n            # Mean squares for this track\n            mean_sq_d0 = var_d0 + mean_d0**2\n            mean_sq_z0 = var_z0 + mean_z0**2\n\n            # Accumulate weighted sums\n            sum_mean_d0 += weight * mean_d0\n            sum_mean_z0 += weight * mean_z0\n            sum_mean_sq_d0 += weight * mean_sq_d0\n            sum_mean_sq_z0 += weight * mean_sq_z0\n            total_weight += weight\n\n        # Final ensemble averages\n        ensemble_mean_d0 = sum_mean_d0 / total_weight\n        ensemble_mean_z0 = sum_mean_z0 / total_weight\n        ensemble_mean_sq_d0 = sum_mean_sq_d0 / total_weight\n        ensemble_mean_sq_z0 = sum_mean_sq_z0 / total_weight\n\n        # RMS values\n        ensemble_rms_d0 = np.sqrt(ensemble_mean_sq_d0)\n        ensemble_rms_z0 = np.sqrt(ensemble_mean_sq_z0)\n\n        return [ensemble_mean_d0, ensemble_mean_z0, ensemble_rms_d0, ensemble_rms_z0]\n\n    # Test Case Definitions\n    test_cases = [\n        # Test Case 1\n        {\n            \"mu\": np.array([0.0, 0.0, 0.0]),\n            \"sigma_params\": {\n                'xx': (20e-6)**2, 'yy': (20e-6)**2, 'zz': (40e-6)**2,\n                'xy': 0.0, 'xz': 0.0, 'yz': 0.0\n            },\n            \"tracks\": [\n                (0.0, 1.3, 1.0), (1.0, 1.0, 1.0), (2.3, 0.8, 1.0),\n                (3.0, np.pi/2, 1.0), (4.2, 1.2, 1.0)\n            ]\n        },\n        # Test Case 2\n        {\n            \"mu\": np.array([10e-6, -5e-6, 30e-6]),\n            \"sigma_params\": {\n                'xx': (60e-6)**2, 'yy': (40e-6)**2, 'zz': (80e-6)**2,\n                'xy': 0.3 * (60e-6) * (40e-6), 'xz': 0.0, 'yz': 0.0\n            },\n            \"tracks\": [\n                (0.2, 1.4, 1.0), (1.1, 0.9, 1.0), (2.5, 1.1, 1.0),\n                (3.7, 1.2, 1.0), (5.0, 0.7, 1.0), (0.8, 1.3, 1.0)\n            ]\n        },\n        # Test Case 3\n        {\n            \"mu\": np.array([0.0, 0.0, 15e-6]),\n            \"sigma_params\": {\n                'xx': (50e-6)**2, 'yy': (50e-6)**2, 'zz': (70e-6)**2,\n                'xy': -0.2 * (50e-6) * (50e-6), 'xz': 0.2 * (50e-6) * (70e-6), 'yz': 0.0\n            },\n            \"tracks\": [\n                (0.0, 0.25, 1.0), (1.5, 0.35, 1.0), (np.pi, 0.5, 1.0), (4.0, 0.9, 1.0)\n            ]\n        },\n        # Test Case 4\n        {\n            \"mu\": np.array([30e-6, -30e-6, -20e-6]),\n            \"sigma_params\": {\n                'xx': 0.0, 'yy': 0.0, 'zz': 0.0, 'xy': 0.0, 'xz': 0.0, 'yz': 0.0\n            },\n            \"tracks\": [\n                (0.3, 1.0, 1.0), (2.7, 1.2, 1.0), (5.5, 0.8, 1.0)\n            ]\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        mu = case['mu']\n        sigma = build_sigma(case['sigma_params'])\n        tracks = case['tracks']\n        results = calculate_ensemble_stats(mu, sigma, tracks)\n        all_results.extend(results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3536226"}]}