{"hands_on_practices": [{"introduction": "The foundation of the Feldman-Cousins method is its ordering principle, which ranks possible experimental outcomes based on a likelihood ratio. This practice provides a hands-on walk-through of this core mechanism. By explicitly calculating the likelihood ratio for a Poisson process, you will construct a single 90% confidence level acceptance region, the fundamental building block of the entire confidence belt [@problem_id:3514604].", "problem": "In a counting experiment in high-energy physics, the number of observed events $n$ in a signal region is modeled as a Poisson random variable with mean $\\mu = s + b$, where $s \\geq 0$ is the non-negative signal strength and $b$ is a known background contribution. The probability mass function is $P(n \\mid \\mu) = \\exp(-\\mu)\\,\\mu^{n} / n!$. You are to construct the Feldman-Cousins acceptance region at a specified confidence level by using the ordering principle based on the likelihood ratio test (LRT). The LRT orders the outcomes $n$ by the ratio $R(n \\mid s_{0}) = \\mathcal{L}(s_{0}; n)/\\mathcal{L}(\\hat{s}(n); n)$, where $\\mathcal{L}(s; n)$ is the likelihood of $s$ given $n$, and $\\hat{s}(n)$ is the Maximum Likelihood Estimator (MLE) of $s$ subject to the physical constraint $s \\geq 0$.\n\nConsider the case with background $b = 3.0$ and a specified test signal $s_{0} = 1.5$. The confidence level is $C = 0.9$. Starting from the Poisson model and the definition of the likelihood, and explicitly enforcing the physical constraint $s \\geq 0$ in determining $\\hat{s}(n)$, derive the likelihood ratio ordering function $R(n \\mid s_{0})$ and compute the critical likelihood-ratio threshold $R_{c}$ such that the Feldman-Cousins acceptance region for $s_{0}$ is the set of counts $\\{n\\}$ with $R(n \\mid s_{0}) \\geq R_{c}$ and total probability $\\sum_{n: R(n \\mid s_{0}) \\geq R_{c}} P(n \\mid s_{0}+b) \\geq C$, while the removal of any included $n$ with the smallest $R(n \\mid s_{0})$ would reduce the total below $C$.\n\nProvide the numerical value of the threshold $R_{c}$ for $b = 3.0$, $s_{0} = 1.5$, and $C = 0.9$. Express the final answer as a dimensionless number and round your answer to four significant figures.", "solution": "The problem requires the determination of the critical likelihood-ratio threshold, $R_c$, for constructing a Feldman-Cousins acceptance region. The experiment involves observing a number of events $n$, which is a Poisson-distributed random variable with mean $\\mu = s+b$. Here, $s$ is the signal strength ($s \\geq 0$) and $b$ is a known background.\n\n**1. Givens and Definitions**\nThe provided parameters are:\n- Background: $b = 3.0$\n- Test signal hypothesis: $s_0 = 1.5$\n- Confidence level: $C = 0.9$\n\nThe number of observed events $n$ follows a Poisson distribution with mean $\\mu = s+b$. The probability mass function (PMF) is:\n$$P(n \\mid s, b) = \\frac{(s+b)^n \\exp(-(s+b))}{n!}$$\nFor a fixed observation $n$, the likelihood function of $s$ is $\\mathcal{L}(s; n) = P(n \\mid s, b)$. The ordering of outcomes $n$ for a given test hypothesis $s_0$ is based on the likelihood ratio:\n$$R(n \\mid s_0) = \\frac{\\mathcal{L}(s_0; n)}{\\mathcal{L}(\\hat{s}(n); n)}$$\nwhere $\\hat{s}(n)$ is the maximum likelihood estimator (MLE) of $s$ under the physical constraint $s \\geq 0$.\n\n**2. Determine the Maximum Likelihood Estimator (MLE) $\\hat{s}(n)**\nTo find the MLE of $s$, we maximize the log-likelihood function, $\\ln \\mathcal{L}(s; n)$, with respect to $s$:\n$$\\ln \\mathcal{L}(s; n) = n \\ln(s+b) - (s+b) - \\ln(n!)$$\nTaking the derivative with respect to $s$ and setting it to zero gives the unconstrained maximum:\n$$\\frac{d}{ds} \\ln \\mathcal{L}(s; n) = \\frac{n}{s+b} - 1 = 0 \\implies s+b = n \\implies s = n-b$$\nWe must enforce the physical constraint $s \\geq 0$.\n- If $n-b \\geq 0$, or $n \\geq b$, the unconstrained MLE is physical, so $\\hat{s}(n) = n-b$.\n- If $n-b  0$, or $n  b$, the unconstrained maximum is in the unphysical region. The log-likelihood function is concave, so its maximum in the allowed region $s \\geq 0$ occurs at the boundary, i.e., at $\\hat{s}(n) = 0$.\nCombining these cases, the physically constrained MLE is $\\hat{s}(n) = \\max(0, n-b)$.\n\nThe value of the mean $\\mu = s+b$ corresponding to the MLE $\\hat{s}(n)$ is $\\hat{\\mu}(n) = \\hat{s}(n)+b = \\max(0, n-b) + b = \\max(b, n)$.\n\n**3. Formulate the Likelihood Ratio**\nThe likelihood ratio $R(n \\mid s_0)$ compares the likelihood of the test hypothesis $s_0$ with that of the best-fit hypothesis $\\hat{s}(n)$:\n$$R(n \\mid s_0) = \\frac{P(n \\mid s_0+b)}{P(n \\mid \\hat{s}(n)+b)}$$\nLet $\\mu_0 = s_0+b$. The ratio is:\n$$R(n \\mid s_0) = \\left(\\frac{\\mu_0}{\\hat{\\mu}(n)}\\right)^n \\exp(\\hat{\\mu}(n) - \\mu_0)$$\nSubstituting the given values, $b=3.0$ and $s_0=1.5$, we get:\n- $\\mu_0 = s_0+b = 1.5 + 3.0 = 4.5$\n- $\\hat{\\mu}(n) = \\max(3.0, n)$\nThe likelihood ratio specific to this problem is:\n$$R(n \\mid 1.5) = \\left(\\frac{4.5}{\\max(3.0, n)}\\right)^n \\exp(\\max(3.0, n) - 4.5)$$\n\n**4. Construct the Acceptance Region**\nThe acceptance region for $s_0$ is constructed by including outcomes $n$ in decreasing order of their likelihood ratio $R(n \\mid 1.5)$ until the cumulative probability reaches the confidence level $C=0.9$. The probabilities are calculated under the test hypothesis, i.e., using a Poisson PMF with mean $\\mu_0=4.5$: $P(n \\mid 4.5) = \\frac{(4.5)^n \\exp(-4.5)}{n!}$.\n\nWe compute $P(n \\mid 4.5)$ and $R(n \\mid 1.5)$ for a range of integer values of $n$:\n| $n$ | $\\hat{\\mu}(n)$ | $P(n \\mid 4.5)$ | $R(n \\mid 1.5)$ |\n|---|---|---|---|\n| 0 | 3.0 | 0.0111090 | 0.223130 |\n| 1 | 3.0 | 0.0499905 | 0.334695 |\n| 2 | 3.0 | 0.1124786 | 0.502043 |\n| 3 | 3.0 | 0.1687179 | 0.753064 |\n| 4 | 4.0 | 0.1898076 | 0.968134 |\n| 5 | 5.0 | 0.1708269 | 0.973510 |\n| 6 | 6.0 | 0.1281201 | 0.797732 |\n| 7 | 7.0 | 0.0823629 | 0.552227 |\n| 8 | 8.0 | 0.0463292 | 0.324229 |\n| 9 | 9.0 | 0.0231646 | 0.175815 |\n| ...| ... | ... | ... |\n\nNext, we rank the outcomes $n$ by decreasing value of $R(n \\mid 1.5)$ and compute the cumulative sum of their probabilities $\\sum P(n \\mid 4.5)$:\n| Rank | $n$ | $R(n \\mid 1.5)$ | $P(n \\mid 4.5)$ | Cumulative $P$ |\n|------|---|-------------|-----------------|------------------|\n| 1    | 5 | 0.973510    | 0.170827        | 0.170827         |\n| 2    | 4 | 0.968134    | 0.189808        | 0.360635         |\n| 3    | 6 | 0.797732    | 0.128120        | 0.488755         |\n| 4    | 3 | 0.753064    | 0.168718        | 0.657473         |\n| 5    | 7 | 0.552227    | 0.082363        | 0.739836         |\n| 6    | 2 | 0.502043    | 0.112479        | 0.852315         |\n| 7    | 1 | 0.334695    | 0.049990        | 0.902305         |\n| 8    | 8 | 0.324229    | 0.046329        | 0.948634         |\n\nTo achieve a confidence level of at least $C=0.9$, we must accumulate probability until the sum is $\\geq 0.9$.\n- After including the top 6 outcomes (down to $n=2$), the cumulative probability is $0.852315$, which is less than $0.9$.\n- We must include the next outcome in the ranked list, which is $n=1$ (rank 7).\n- Adding the probability for $n=1$, the cumulative sum becomes $0.852315 + 0.049990 = 0.902305$. This sum now exceeds $0.9$.\n\nThe acceptance region is the set of outcomes included: $\\{5, 4, 6, 3, 7, 2, 1\\}$.\nThe problem asks for the critical threshold $R_c$, which defines this region via the condition $R(n \\mid s_0) \\geq R_c$. This threshold is the value of the likelihood ratio for the last outcome added to the region. The last outcome added was $n=1$.\nTherefore, the critical threshold $R_c$ is the value of $R(1 \\mid 1.5)$.\n\n**5. Calculate the Final Value**\n$$R_c = R(1 \\mid 1.5) = \\left(\\frac{4.5}{\\max(3.0, 1)}\\right)^1 \\exp(\\max(3.0, 1) - 4.5)$$\n$$R_c = \\left(\\frac{4.5}{3.0}\\right) \\exp(3.0 - 4.5) = 1.5 \\exp(-1.5)$$\nNumerically, this is:\n$$R_c = 1.5 \\times 0.22313016... = 0.33469524...$$\nRounding to four significant figures, we get $R_c = 0.3347$.", "answer": "$$\\boxed{0.3347}$$", "id": "3514604"}, {"introduction": "Once the complete set of acceptance regions is determined, forming the 'confidence belt,' the final step is to invert it to find the confidence interval for a specific measurement. This exercise focuses on this crucial inversion process [@problem_id:3514615]. Using pre-computed results for the acceptance belt, you will determine the final interval for several different observed event counts and analyze how the nature of the interval changes, naturally transitioning from an upper limit to a two-sided measurement.", "problem": "In a counting experiment typical of computational high-energy physics, the observed event count $n$ is modeled as a Poisson random variable with mean $\\mu = s + b$, where $s \\geq 0$ is the unknown signal expectation and $b$ is the known background expectation. Consider the case $b = 2.5$. Using the Feldman-Cousins unified approach to interval construction, acceptance regions are defined by likelihood-ratio ordering, where for each fixed $s$ one orders integer counts $n$ by decreasing \n$$\nR(n; s) = \\frac{L(n \\mid s)}{L(n \\mid s_{\\mathrm{best}}(n))},\n$$\nwith $L(n \\mid s) = \\exp(-(s+b))\\,(s+b)^{n}/n!$ and $s_{\\mathrm{best}}(n) = \\max\\{0, n - b\\}$ the maximum likelihood estimate of the signal under the physical constraint $s \\geq 0$. For a specified confidence level (take $90\\%$), the acceptance region $\\mathcal{A}(s)$ is constructed by including outcomes $n$ starting from the largest $R(n; s)$ until the total probability under $L(n \\mid s)$ reaches $0.90$.\n\nThe Feldman-Cousins confidence interval for $s$ given an observation $n_{\\mathrm{obs}}$ is obtained by inverting this acceptance belt: it is the set of all $s$ such that $n_{\\mathrm{obs}} \\in \\mathcal{A}(s)$.\n\nAssume the acceptance regions $\\mathcal{A}(s)$ were precomputed at $90\\%$ confidence for $b=2.5$, and that, for the specific observed counts $n \\in \\{0, 1, 2, 5\\}$, the membership of each $n$ in $\\mathcal{A}(s)$ as a function of $s$ is given by the following precomputed thresholds:\n- For $n = 0$: $n \\in \\mathcal{A}(s)$ if and only if $0 \\leq s \\leq 1.320$.\n- For $n = 1$: $n \\in \\mathcal{A}(s)$ if and only if $0 \\leq s \\leq 2.930$.\n- For $n = 2$: $n \\in \\mathcal{A}(s)$ if and only if $0 \\leq s \\leq 4.500$.\n- For $n = 5$: $n \\in \\mathcal{A}(s)$ if and only if $0.9800 \\leq s \\leq 7.450$.\n\nUsing only the fundamental definitions stated above and the provided precomputed acceptance membership, invert the belt to determine the Feldman-Cousins $90\\%$ confidence interval for $s$ for each $n \\in \\{0, 1, 2, 5\\}$. Clearly identify the interval endpoints $(s_{\\mathrm{low}}(n), s_{\\mathrm{high}}(n))$ for each $n$.\n\nReturn your final numerical answer as the ordered tuple \n$$\n\\left(s_{\\mathrm{low}}(0),\\, s_{\\mathrm{high}}(0),\\, s_{\\mathrm{low}}(1),\\, s_{\\mathrm{high}}(1),\\, s_{\\mathrm{low}}(2),\\, s_{\\mathrm{high}}(2),\\, s_{\\mathrm{low}}(5),\\, s_{\\mathrm{high}}(5)\\right).\n$$\nRound your answers to four significant figures. No physical units are required.\n\nAdditionally, briefly discuss the qualitative change in the nature of the Feldman-Cousins intervals as $n$ increases from $0$ to $5$ in the presence of nonzero background $b = 2.5$, based on the provided acceptance belt.", "solution": "The central task is to determine the $90\\%$ confidence interval for the signal strength $s$ for several observed event counts $n$, by inverting a pre-computed acceptance belt.\n\nThe Feldman-Cousins confidence interval for an unknown parameter (here, the signal strength $s$) corresponding to an observation $n_{\\mathrm{obs}}$ is constructed by \"inverting\" the acceptance belt. The acceptance belt is a collection of acceptance regions $\\mathcal{A}(s)$ for each possible true value of $s$. The acceptance region $\\mathcal{A}(s)$ is the set of observable outcomes $n$ that are considered representative of that $s$, typically comprising $90\\%$ (or other specified confidence level) of the probability mass.\n\nThe inversion procedure is defined as follows: the confidence interval for $s$, given an observation $n_{\\mathrm{obs}}$, is the set of all $s$ values for which the observation $n_{\\mathrm{obs}}$ lies within the corresponding acceptance region $\\mathcal{A}(s)$. Mathematically, the confidence interval is:\n$$\n\\text{CI}(n_{\\mathrm{obs}}) = \\{s \\mid n_{\\mathrm{obs}} \\in \\mathcal{A}(s)\\}\n$$\nThe problem provides the explicit conditions for membership in $\\mathcal{A}(s)$ for the observed counts $n \\in \\{0, 1, 2, 5\\}$, effectively giving us the result of the inversion. We simply need to read off the intervals for each case. The endpoints of these intervals are denoted $(s_{\\mathrm{low}}(n), s_{\\mathrm{high}}(n))$.\n\nCase $n=0$:\nThe problem states that for an observed count of $n = 0$, its membership in the acceptance region $\\mathcal{A}(s)$ is defined by the condition $0 \\leq s \\leq 1.320$. By the definition of interval inversion, this range of $s$ precisely constitutes the $90\\%$ confidence interval for an observation $n_{\\mathrm{obs}} = 0$.\nTherefore, the interval is $[0, 1.320]$, and the endpoints are $s_{\\mathrm{low}}(0) = 0$ and $s_{\\mathrm{high}}(0) = 1.320$.\n\nCase $n=1$:\nThe membership condition for $n = 1$ is given as $0 \\leq s \\leq 2.930$. Applying the definition of interval inversion for an observation $n_{\\mathrm{obs}} = 1$, the confidence interval for $s$ is $[0, 2.930]$.\nThe endpoints are $s_{\\mathrm{low}}(1) = 0$ and $s_{\\mathrm{high}}(1) = 2.930$.\n\nCase $n=2$:\nThe membership condition for $n = 2$ is given as $0 \\leq s \\leq 4.500$. For an observation $n_{\\mathrm{obs}} = 2$, the confidence interval is $[0, 4.500]$.\nThe endpoints are $s_{\\mathrm{low}}(2) = 0$ and $s_{\\mathrm{high}}(2) = 4.500$.\n\nCase $n=5$:\nThe membership condition for $n = 5$ is given as $0.9800 \\leq s \\leq 7.450$. For an observation $n_{\\mathrm{obs}} = 5$, the confidence interval is $[0.9800, 7.450]$.\nThe endpoints are $s_{\\mathrm{low}}(5) = 0.9800$ and $s_{\\mathrm{high}}(5) = 7.450$.\n\nThe problem requires rounding the answers to four significant figures. The provided non-zero endpoints ($1.320$, $2.930$, $4.500$, $0.9800$, $7.450$) are already expressed with four significant figures. The lower endpoints for $n \\in \\{0, 1, 2\\}$ are exactly $0$ due to the physical constraint $s \\geq 0$, not a result of a calculation that is then rounded. For notational consistency in the final answer, we will represent this exact value as $0.000$, matching the decimal precision of other endpoints.\n\nSummary of endpoints:\n- $s_{\\mathrm{low}}(0) = 0.000$, $s_{\\mathrm{high}}(0) = 1.320$\n- $s_{\\mathrm{low}}(1) = 0.000$, $s_{\\mathrm{high}}(1) = 2.930$\n- $s_{\\mathrm{low}}(2) = 0.000$, $s_{\\mathrm{high}}(2) = 4.500$\n- $s_{\\mathrm{low}}(5) = 0.9800$, $s_{\\mathrm{high}}(5) = 7.450$\n\nThe ordered tuple requested is:\n$$\n\\left(s_{\\mathrm{low}}(0),\\, s_{\\mathrm{high}}(0),\\, s_{\\mathrm{low}}(1),\\, s_{\\mathrm{high}}(1),\\, s_{\\mathrm{low}}(2),\\, s_{\\mathrm{high}}(2),\\, s_{\\mathrm{low}}(5),\\, s_{\\mathrm{high}}(5)\\right)\n$$\n\nDiscussion on the qualitative nature of the intervals:\nThe obtained intervals demonstrate a cardinal feature of the Feldman-Cousins unified approach. The known background expectation is $b=2.5$.\n\nFor observed counts $n \\in \\{0, 1, 2\\}$, the number of events is less than or comparable to the background expectation. In these cases, the maximum likelihood estimate of the signal is $s_{\\mathrm{best}}(n) = \\max\\{0, n-b\\} = 0$. The data are consistent with the background-only hypothesis ($s=0$). The corresponding Feldman-Cousins confidence intervals are $[0, 1.320]$, $[0, 2.930]$, and $[0, 4.500]$, respectively. These are one-sided intervals that establish an upper limit on the signal strength $s$. This is a physically sensible result, as the observation does not provide sufficient evidence to claim a non-zero signal. The method naturally incorporates the physical boundary $s \\geq 0$ and does not produce unphysical negative intervals.\n\nIn contrast, for an observed count $n=5$, the number of events is substantially greater than the background expectation ($5 > 2.5$). Here, $s_{\\mathrm{best}}(5) = \\max\\{0, 5-2.5\\} = 2.5$. The resulting confidence interval, $[0.9800, 7.450]$, is a two-sided interval. Crucially, its lower bound is strictly greater than zero. This signifies that the background-only hypothesis ($s=0$) is excluded at the $90\\%$ confidence level, providing statistical evidence for the presence of a signal.\n\nThe qualitative change is a smooth transition from reporting an upper limit when the signal is weak or absent to reporting a two-sided measurement interval when the signal is significant. This is the \"unified\" aspect of the method, which avoids the problematic \"flip-flopping\" practice of deciding whether to report an upper limit or a two-sided interval after observing the data.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n0.000  1.320  0.000  2.930  0.000  4.500  0.9800  7.450\n\\end{pmatrix}\n}\n$$", "id": "3514615"}, {"introduction": "A key motivation for the Feldman-Cousins method is its rigorous guarantee of frequentist coverage, even near physical boundaries. This problem moves from calculation to validation, challenging you to design a correct computational procedure to empirically test this guarantee. By considering a realistic scenario with a nuisance parameter, you will learn to construct a valid pseudo-experiment study and distinguish it from flawed approaches that fail to properly test for coverage [@problem_id:3514663].", "problem": "A counting experiment in computational high-energy physics observes an event count modeled as $n \\sim \\mathrm{Poisson}(s + b)$, where $s \\ge 0$ is the signal rate of interest and $b \\ge 0$ is a background rate. An auxiliary control measurement $x$ provides a Gaussian constraint on $b$, modeled as $x \\sim \\mathcal{N}(b, \\sigma_b)$ with a known standard deviation $\\sigma_b  0$. The joint likelihood is $L(n, x; s, b) = \\mathrm{Poisson}(n \\mid s + b) \\cdot \\mathcal{N}(x \\mid b, \\sigma_b)$. You construct a Feldman-Cousins (FC) confidence interval for $s$ at a confidence level of $90\\%$ using the Neyman construction with the Likelihood Ratio (LR) ordering principle based on the joint likelihood and the profile over the nuisance parameter $b$. For each candidate $s$, the ordering quantity is the profile-likelihood ratio $R(n, x; s) = L(n, x; s, \\hat{b}_s)/L(n, x; \\hat{s}, \\hat{b})$, where $\\hat{b}_s$ is the Maximum Likelihood Estimator (MLE) of $b$ under the constraint $s$ fixed, and $(\\hat{s}, \\hat{b})$ are the unconstrained MLEs, with $s \\ge 0$ enforced.\n\nYour goal is to empirically verify, by pseudo-experiments (Monte Carlo (MC) toys), the frequentist coverage of the $90\\%$ FC interval for $s$ at specific fixed true parameters $s_\\mathrm{true} \\in \\{0, 1, 3\\}$ and $b_\\mathrm{true} = 2.5$ with a known $\\sigma_b = 0.5$. The frequentist coverage at level $1 - \\alpha$ for fixed $(s_\\mathrm{true}, b_\\mathrm{true})$ is defined as the probability, with respect to the sampling distribution of $(n, x)$ at $(s_\\mathrm{true}, b_\\mathrm{true})$, that the constructed interval for $s$ contains $s_\\mathrm{true}$, and it should equal $1 - \\alpha = 90\\%$ in the large pseudo-experiment limit if the construction has nominal coverage.\n\nWhich of the following procedures yields an unbiased empirical estimate of the coverage of the $90\\%$ FC interval for $s$ at the stated $(s_\\mathrm{true}, b_\\mathrm{true})$?\n\nA. For each $s_\\mathrm{true}$, draw a single auxiliary value $x_\\ast \\sim \\mathcal{N}(b_\\mathrm{true}, \\sigma_b)$ and fix $b$ to $x_\\ast$ for all pseudo-experiments. Then generate $N_\\mathrm{toys}$ values $n_i \\sim \\mathrm{Poisson}(s_\\mathrm{true} + x_\\ast)$, construct an FC interval for each $n_i$ using the LR ordering based on $L(n, x_\\ast; s, b)$ with $x$ held fixed to $x_\\ast$, and estimate coverage as the fraction of intervals containing $s_\\mathrm{true}$.\n\nB. For each $s_\\mathrm{true}$, fix $b_\\mathrm{true}$ and generate $N_\\mathrm{toys}$ independent pairs $(n_i, x_i)$ with $x_i \\sim \\mathcal{N}(b_\\mathrm{true}, \\sigma_b)$ and $n_i \\sim \\mathrm{Poisson}(s_\\mathrm{true} + b_\\mathrm{true})$, independently conditional on $(s_\\mathrm{true}, b_\\mathrm{true})$. Use the same FC construction as in the analysis: for each candidate $s$, define $R(n, x; s)$ from the joint likelihood with $b$ profiled, and determine the critical acceptance region in $(n, x)$ space by choosing the LR threshold so that the probability mass under the joint sampling distribution $P(n, x \\mid s, b_\\mathrm{true})$ equals $90\\%$. Invert this acceptance region to obtain the FC interval for each observed $(n_i, x_i)$, and estimate coverage as the fraction of these intervals containing $s_\\mathrm{true}$.\n\nC. For each $s_\\mathrm{true}$, specify a prior $\\pi(b)$ and in each pseudo-experiment draw $b_i \\sim \\pi(b)$, then draw $x_i \\sim \\mathcal{N}(b_i, \\sigma_b)$ and $n_i \\sim \\mathrm{Poisson}(s_\\mathrm{true} + b_i)$. Construct the interval for $s$ by the FC LR ordering using $L(n, x; s, b)$ with $b$ profiled, and estimate coverage as the fraction of intervals containing $s_\\mathrm{true}$.\n\nD. For each $s_\\mathrm{true}$, generate $N_\\mathrm{toys}$ independent pairs $(n_i, x_i)$ as in option B, but construct the interval for $s$ by inverting the asymptotic profile-likelihood test based on Wilks’ theorem for $-2 \\ln \\lambda(s)$, without building LR-ordered acceptance regions in $(n, x)$ space. Estimate coverage as the fraction of these intervals containing $s_\\mathrm{true}$.\n\nAssume $N_\\mathrm{toys}$ is large (e.g., $N_\\mathrm{toys} = 10^5$), numerical optimization for MLEs is exact, and the same interval-construction rule must be used in the pseudo-experiments as is used in the actual analysis. Select the single best option that correctly implements an unbiased frequentist coverage study for the stated FC construction with a Gaussian nuisance constraint.", "solution": "The problem asks for the correct procedure to empirically verify the frequentist coverage of a Feldman-Cousins (FC) confidence interval for a signal rate $s$. The experimental observation consists of an event count $n$ and an auxiliary measurement $x$. The model is described by the joint likelihood $L(n, x; s, b) = \\mathrm{Poisson}(n \\mid s + b) \\cdot \\mathcal{N}(x \\mid b, \\sigma_b)$, where $b$ is a nuisance parameter for the background rate.\n\nFirst, we must establish the fundamental principle of a frequentist coverage study. The frequentist coverage of a confidence interval procedure is defined with respect to fixed, true values of all parameters of the model. In this case, the parameters are the signal rate $s$ and the background rate $b$. A coverage study for a specific point $(s_\\mathrm{true}, b_\\mathrm{true})$ in the parameter space proceeds as follows:\n1.  Assume a \"true\" state of nature is defined by the fixed parameters $s = s_\\mathrm{true}$ and $b = b_\\mathrm{true}$.\n2.  Simulate a large number of independent experiments. Each experiment generates a random dataset of observables, $(n_i, x_i)$, according to their joint probability distribution conditioned on the true parameters: $n_i \\sim \\mathrm{Poisson}(s_\\mathrm{true} + b_\\mathrm{true})$ and $x_i \\sim \\mathcal{N}(b_\\mathrm{true}, \\sigma_b)$.\n3.  For each simulated dataset $(n_i, x_i)$, construct the confidence interval for the parameter of interest, $s$, using the exact statistical procedure under evaluation. In this case, it is the specified Feldman-Cousins construction with likelihood ratio ordering.\n4.  The empirical coverage is then calculated as the fraction of these constructed intervals that contain the true value, $s_\\mathrm{true}$, which was used to generate the data.\n\nFor a confidence interval procedure with a confidence level of $1-\\alpha$, the frequentist principle guarantees that the coverage will be greater than or equal to $1-\\alpha$ for all possible true values of the parameters $(s, b)$. The Feldman-Cousins method is specifically designed to avoid undercoverage and provide coverage that is nominally $1-\\alpha$. Verifying this property requires the simulation procedure outlined above.\n\nNow, we will evaluate each of the proposed options against this principle.\n\n**Option A Evaluation**\nThis option proposes to draw a single auxiliary value $x_\\ast \\sim \\mathcal{N}(b_\\mathrm{true}, \\sigma_b)$ and then hold this value fixed for all pseudo-experiments. The event counts are then generated as $n_i \\sim \\mathrm{Poisson}(s_\\mathrm{true} + x_\\ast)$. This procedure is fundamentally flawed. In the frequentist framework, the observables are random variables. Both $n$ and $x$ are observables. By fixing $x$ to a single realization $x_\\ast$, the procedure does not simulate the full experiment. It checks coverage conditional on $x = x_\\ast$, not the unconditional coverage for the experiment as a whole. The sampling distribution used is incorrect; it should be over the joint space of $(n, x)$, which means in each pseudo-experiment, a new realization of *both* $n$ and $x$ must be drawn from their respective distributions defined by $(s_\\mathrm{true}, b_\\mathrm{true})$. This procedure conflates the nuisance parameter $b$ with its measurement $x$.\n**Verdict:** **Incorrect**.\n\n**Option B Evaluation**\nThis option describes the following procedure:\n1.  For each pair of true parameters $(s_\\mathrm{true}, b_\\mathrm{true})$, generate $N_\\mathrm{toys}$ independent pairs of observables $(n_i, x_i)$.\n2.  The generation is done according to the correct sampling distributions: $x_i \\sim \\mathcal{N}(b_\\mathrm{true}, \\sigma_b)$ and $n_i \\sim \\mathrm{Poisson}(s_\\mathrm{true} + b_\\mathrm{true})$.\n3.  For each simulated pair $(n_i, x_i)$, the confidence interval for $s$ is constructed using the method specified in the problem statement (FC construction with LR ordering and profiling of $b$).\n4.  The empirical coverage is estimated as the fraction of intervals that contain $s_\\mathrm{true}$.\n\nThis procedure perfectly matches the definition of an empirical frequentist coverage study. It correctly identifies the true parameters as fixed constants, correctly simulates the random nature of both observables $(n, x)$, and uses the correct method to construct the intervals for each simulated experiment. The description of the FC construction, while slightly simplified, correctly identifies the key components (inverting acceptance regions, using the LR ordering, finding a threshold) and crucially states that the same FC construction from the analysis is used.\n**Verdict:** **Correct**.\n\n**Option C Evaluation**\nThis option introduces a prior distribution $\\pi(b)$ for the nuisance parameter $b$, and for each pseudo-experiment, draws a value $b_i \\sim \\pi(b)$. The observables are then generated as $x_i \\sim \\mathcal{N}(b_i, \\sigma_b)$ and $n_i \\sim \\mathrm{Poisson}(s_\\mathrm{true} + b_i)$. This is not a frequentist coverage study. Frequentist coverage is a property defined for *fixed* values of the parameters, including nuisance parameters. This procedure evaluates a different quantity: the coverage averaged over a distribution of the nuisance parameter $b$. While this can be a relevant study, it does not answer the question of verifying the frequentist coverage at the specific point $(s_\\mathrm{true}, b_\\mathrm{true} = 2.5)$, as required by the problem statement and the definition of frequentist coverage. It mixes Bayesian concepts (a prior on a parameter) into a frequentist test.\n**Verdict:** **Incorrect**.\n\n**Option D Evaluation**\nThis option generates the pseudo-experiment datasets $(n_i, x_i)$ correctly, just as in Option B. However, it proposes to construct the confidence intervals using a different method: \"by inverting the asymptotic profile-likelihood test based on Wilks’ theorem\". This method approximates the distribution of the test statistic $-2 \\ln R(n, x; s)$ as a chi-squared distribution with one degree of freedom, i.e., $-2 \\ln R(n, x; s) \\sim \\chi^2_1$. The Feldman-Cousins procedure, by contrast, does not rely on this asymptotic approximation. Instead, it builds acceptance regions using the likelihood ratio for ordering and determines the critical value of the ratio for a given confidence level via Monte Carlo simulations or direct calculation for each hypothesized $s$. The asymptotic method and the FC method are distinct procedures and yield different intervals, especially for low statistics or near physical boundaries, which are precisely the regimes where FC is most valuable. The problem mandates using \"the same interval-construction rule... as is used in the actual analysis,\" which is the FC method. This option violates that critical condition by substituting a different, albeit related, procedure.\n**Verdict:** **Incorrect**.", "answer": "$$\\boxed{B}$$", "id": "3514663"}]}