{"hands_on_practices": [{"introduction": "To truly understand how Recurrent Neural Networks (RNNs) capture temporal dynamics, we must first master the fundamental mechanism of the hidden state update. This initial practice breaks down the process into a single time step, allowing you to see exactly how an RNN combines a new input with its memory of the past. By performing this core calculation by hand, you will build a foundational intuition for the flow of information that underpins all recurrent architectures [@problem_id:3344978].", "problem": "In computational systems biology, recurrent neural networks (RNNs) are used to model biological time series such as gene expression dynamics. Consider a minimal two-dimensional hidden state representing the activities of two transcriptional regulatory modules. The system is a discrete-time nonlinear state-space model in which the next hidden state is produced by applying an element-wise saturating nonlinearity $\\phi$ to an affine combination of the current input and the previous hidden state, and a single scalar output is produced by a linear readout of the current hidden state. The saturating nonlinearity is the hyperbolic tangent, $\\phi(u) = \\tanh(u)$, applied element-wise.\n\nAssume the following parameterization at time index $t$:\n- Input-to-hidden matrix $W_{xh} = \\begin{pmatrix}1 & 0 \\\\ 0 & 1\\end{pmatrix}$,\n- Hidden-to-hidden matrix $W_{hh} = \\begin{pmatrix}0.5 & 0 \\\\ 0 & 0.8\\end{pmatrix}$,\n- Bias vector $b = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$,\n- Input vector $x_t = \\begin{pmatrix}0.2 \\\\ -0.1\\end{pmatrix}$,\n- Previous hidden state $h_{t-1} = \\begin{pmatrix}0.0 \\\\ 0.5\\end{pmatrix}$,\n- Hidden-to-output readout $W_{hy} = \\begin{pmatrix}1 & -1\\end{pmatrix}$,\n- Output bias $c = 0$.\n\nStarting from the core definition of a discrete-time nonlinear state-space model with an element-wise saturating activation and a linear readout, construct the hidden-state update and output mapping appropriate for this RNN. Then compute the numerical values of the current hidden state $h_t$ and the scalar output $y_t$ for the given parameters. Round each component of $h_t$ and $y_t$ to six significant figures. The values are dimensionless normalized quantities. Express your final answer as a single row vector $\\begin{pmatrix}h_{t,1} & h_{t,2} & y_t\\end{pmatrix}$.", "solution": "The problem requires the computation of the current hidden state $h_t$ and the scalar output $y_t$ of a simple Recurrent Neural Network (RNN) given a set of parameters, the previous hidden state $h_{t-1}$, and the current input $x_t$. The model is defined by a discrete-time nonlinear state-space formulation.\n\nFirst, we establish the governing equations for the RNN based on the problem description. The hidden state update rule is given by applying an element-wise activation function $\\phi$ to an affine transformation of the input $x_t$ and the previous hidden state $h_{t-1}$. The general equation is:\n$$h_t = \\phi(W_{xh}x_t + W_{hh}h_{t-1} + b)$$\nThe output $y_t$ is a linear readout of the current hidden state $h_t$:\n$$y_t = W_{hy}h_t + c$$\n\nThe problem specifies the activation function as the hyperbolic tangent, $\\phi(u) = \\tanh(u)$, applied element-wise. The given parameters are:\n- Input-to-hidden matrix: $W_{xh} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$\n- Hidden-to-hidden matrix: $W_{hh} = \\begin{pmatrix} 0.5 & 0 \\\\ 0 & 0.8 \\end{pmatrix}$\n- Bias vector: $b = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$\n- Input vector: $x_t = \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix}$\n- Previous hidden state: $h_{t-1} = \\begin{pmatrix} 0.0 \\\\ 0.5 \\end{pmatrix}$\n- Hidden-to-output readout matrix: $W_{hy} = \\begin{pmatrix} 1 & -1 \\end{pmatrix}$\n- Output bias: $c = 0$\n\nOur first step is to compute the argument of the activation function, which is the affine combination $a_t = W_{xh}x_t + W_{hh}h_{t-1} + b$.\n$$a_t = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix} + \\begin{pmatrix} 0.5 & 0 \\\\ 0 & 0.8 \\end{pmatrix} \\begin{pmatrix} 0.0 \\\\ 0.5 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\nWe compute the matrix-vector products separately:\n$$W_{xh}x_t = \\begin{pmatrix} (1)(0.2) + (0)(-0.1) \\\\ (0)(0.2) + (1)(-0.1) \\end{pmatrix} = \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix}$$\n$$W_{hh}h_{t-1} = \\begin{pmatrix} (0.5)(0.0) + (0)(0.5) \\\\ (0)(0.0) + (0.8)(0.5) \\end{pmatrix} = \\begin{pmatrix} 0.0 \\\\ 0.4 \\end{pmatrix}$$\nNow, we sum the terms to find $a_t$:\n$$a_t = \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix} + \\begin{pmatrix} 0.0 \\\\ 0.4 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0.2 + 0.0 + 0 \\\\ -0.1 + 0.4 + 0 \\end{pmatrix} = \\begin{pmatrix} 0.2 \\\\ 0.3 \\end{pmatrix}$$\n\nNext, we compute the current hidden state $h_t$ by applying the element-wise hyperbolic tangent function, $h_t = \\phi(a_t) = \\tanh(a_t)$.\n$$h_t = \\begin{pmatrix} \\tanh(0.2) \\\\ \\tanh(0.3) \\end{pmatrix}$$\nWe calculate the numerical values of the components of $h_t$:\n$$h_{t,1} = \\tanh(0.2) \\approx 0.19737532...$$\n$$h_{t,2} = \\tanh(0.3) \\approx 0.29131261...$$\nAs per the problem statement, we round these values to six significant figures:\n$$h_{t,1} \\approx 0.197375$$\n$$h_{t,2} \\approx 0.291313$$\nSo, the current hidden state is $h_t \\approx \\begin{pmatrix} 0.197375 \\\\ 0.291313 \\end{pmatrix}$.\n\nFinally, we compute the scalar output $y_t$ using the linear readout equation $y_t = W_{hy}h_t + c$.\n$$y_t = \\begin{pmatrix} 1 & -1 \\end{pmatrix} h_t + 0$$\nFor better precision, we use the unrounded values of $h_t$ in this calculation before applying the final rounding.\n$$y_t = (1) \\times h_{t,1} + (-1) \\times h_{t,2} = h_{t,1} - h_{t,2}$$\n$$y_t \\approx 0.19737532 - 0.29131261 = -0.09393729...$$\nRounding this result to six significant figures:\n$$y_t \\approx -0.0939373$$\n\nThe problem asks for the final answer to be expressed as a single row vector $\\begin{pmatrix} h_{t,1} & h_{t,2} & y_t \\end{pmatrix}$. Using the rounded values, this vector is:\n$$\\begin{pmatrix} 0.197375 & 0.291313 & -0.0939373 \\end{pmatrix}$$", "answer": "$$\\boxed{\\begin{pmatrix} 0.197375 & 0.291313 & -0.0939373 \\end{pmatrix}}$$", "id": "3344978"}, {"introduction": "While simple RNNs provide a basic model for sequences, they struggle to capture long-range dependencies common in biological processes due to issues like the vanishing gradient problem. The Long Short-Term Memory (LSTM) architecture solves this with a sophisticated system of gates that control information flow. This exercise takes you inside an LSTM cell, challenging you to compute the state update and, more importantly, to interpret how these gates enable the model to selectively remember or forget information over extended periods, a critical feature for modeling cellular memory [@problem_id:3345004].", "problem": "A research group is modeling multigene regulatory dynamics from longitudinal single-cell ribonucleic acid (RNA) sequencing time series using a Recurrent Neural Network (RNN) architecture with Long Short-Term Memory (LSTM). The cell state is used as a latent representation of transcriptional memory, and gate values are interpreted as biophysically plausible modulators of information flow over time. At a particular time step $t$, the learned gate activations are $i_t=0.3$, $f_t=0.9$, $o_t=0.8$, and the candidate update is $\\tilde{c}_t=0.5$, with previous cell state $c_{t-1}=1.0$. Using the standard definitions of LSTM gates and the principle that additive cell-state updates preserve long-timescale information in biological sequences, derive the expressions for the cell state $c_t$ and hidden state $h_t$ from first principles, compute the values at this time step, and explain the qualitative effect of increasing $f_t$ on memory retention and gradient flow in the context of slowly varying biological processes. Express $h_t$ in exact closed form without numerical approximation. Provide the numerical value of $c_t$ exactly. Your final numerical or symbolic answers must be given without units. If you choose to provide any numerical approximation in your derivation, do not round in the final answer; however, if an intermediate numerical approximation is discussed, round that intermediate quantity to four significant figures.", "solution": "The problem statement is critically validated as self-contained, scientifically grounded, and well-posed. All necessary data for the calculation are provided, the context of using Long Short-Term Memory (LSTM) networks for biological time series is a standard and active area of research in computational systems biology, and the request is for a standard derivation and computation based on established principles. The problem is therefore valid.\n\nThe core of the LSTM architecture is its ability to maintain a memory of past information over extended time sequences via a cell state, $c$. This cell state is modulated by a series of gates. The derivation of the cell state $c_t$ and the hidden state $h_t$ at time step $t$ proceeds from the standard LSTM update equations, which we present here as first principles of the model's operation.\n\nThe cell state $c_t$ is updated based on the previous cell state $c_{t-1}$ and a candidate update $\\tilde{c}_t$. The flow of this information is controlled by the forget gate $f_t$ and the input gate $i_t$. The equation for the cell state update is:\n$$c_t = f_t \\odot c_{t-1} + i_t \\odot \\tilde{c}_t$$\nHere, $\\odot$ represents the Hadamard (element-wise) product. Since the problem provides scalar values, this operation simplifies to standard multiplication. The term $f_t \\odot c_{t-1}$ represents the portion of the previous memory that is retained, while the term $i_t \\odot \\tilde{c}_t$ represents the portion of the new candidate information that is incorporated.\n\nThe hidden state $h_t$, which is the output of the LSTM cell at time step $t$, is a filtered version of the cell state. The output gate $o_t$ controls how much of the internal cell state is exposed to the rest of the network. The cell state is first passed through a hyperbolic tangent activation function, $\\tanh$, to scale the values, before being modulated by the output gate. The equation for the hidden state is:\n$$h_t = o_t \\odot \\tanh(c_t)$$\nAgain, for scalar values, the Hadamard product simplifies to standard multiplication.\n\nWe are given the following values at time step $t$:\n- Input gate activation: $i_t = 0.3$\n- Forget gate activation: $f_t = 0.9$\n- Output gate activation: $o_t = 0.8$\n- Candidate update: $\\tilde{c}_t = 0.5$\n- Previous cell state: $c_{t-1} = 1.0$\n\nFirst, we compute the value of the cell state $c_t$ by substituting the given values into the cell state equation:\n$$c_t = (f_t)(c_{t-1}) + (i_t)(\\tilde{c}_t)$$\n$$c_t = (0.9)(1.0) + (0.3)(0.5)$$\n$$c_t = 0.9 + 0.15$$\n$$c_t = 1.05$$\n\nNext, we compute the hidden state $h_t$. The problem requires an exact closed-form expression. We substitute the computed value of $c_t$ and the given value of $o_t$ into the hidden state equation:\n$$h_t = (o_t)(\\tanh(c_t))$$\n$$h_t = (0.8)(\\tanh(1.05))$$\nThis is the exact analytical expression for $h_t$. For the purpose of discussion, a numerical approximation of this value would be $h_t \\approx (0.8)(0.7817) \\approx 0.6254$.\n\nFinally, we address the qualitative effect of increasing the forget gate activation $f_t$ in the context of slowly varying biological processes.\n1.  **Memory Retention**: The forget gate $f_t$ directly multiplies the previous cell state $c_{t-1}$ in the update equation. A value of $f_t$ close to $1.0$ ensures that a large fraction of the previous cell state is carried over to the current cell state, $c_t$. Increasing $f_t$ thus strengthens the model's ability to retain long-term memory. For slowly varying biological processes such as cell differentiation or metabolic adaptation, the underlying transcriptional state changes gradually. A high $f_t$ is crucial for the model to capture these long-timescale dependencies, effectively creating a persistent memory of the cell's historical trajectory. Conversely, a low $f_t$ would cause the cell state to be rapidly overwritten, making the model only sensitive to short-term fluctuations.\n\n2.  **Gradient Flow**: During training via backpropagation through time (BPTT), the gradient of the loss function with respect to an earlier cell state $c_{k}$ (for $k < t$) is computed using the chain rule. The partial derivative of the cell state at time $j$ with respect to the state at time $j-1$ is $\\frac{\\partial c_j}{\\partial c_{j-1}} = f_j$. Consequently, the gradient signal flowing backwards from time $t$ to time $k$ is scaled by the product of the forget gate activations along the path: $\\prod_{j=k+1}^{t} f_j$. If the $f_j$ values are consistently less than $1.0$, this product can decay exponentially, leading to the vanishing gradient problem. By increasing $f_t$ (and other forget gates in the sequence) to be close to $1.0$, the gradient is allowed to flow backwards over many time steps without significant attenuation. This enables the network to learn dependencies between distant points in the time series, which is essential for modeling how early biological events can influence outcomes much later in time. The additive nature of the cell state update, combined with forget gates near $1.0$, provides a clear pathway for gradient information, effectively mitigating this fundamental problem in training RNNs on long sequences.\n\nIn summary, a high value for $f_t$, such as the $0.9$ given in the problem, is biophysically plausible and computationally necessary for modeling the long-term memory inherent in slowly evolving biological systems.", "answer": "$$\\boxed{\\begin{pmatrix} 1.05 & 0.8 \\tanh(1.05) \\end{pmatrix}}$$", "id": "3345004"}, {"introduction": "An effective model requires more than just a powerful neural network architecture; it needs an objective function that accurately reflects the statistical properties of the data and incorporates relevant domain knowledge. When modeling single-cell RNA sequencing (scRNA-seq) data, which consists of over-dispersed counts, a simple mean squared error loss is inadequate. This final practice guides you through the crucial steps of building a complete modeling objective, from deriving the Negative Binomial log-likelihood to implementing a regularization penalty that encourages biologically plausible smooth gene expression trajectories [@problem_id:3344950].", "problem": "You are modeling a single geneâ€™s count trajectory from Single-Cell Ribonucleic Acid Sequencing (scRNA-seq) using a Recurrent Neural Network (RNN). At each discrete time point indexed by $t \\in \\{1,2,\\dots,T\\}$, the RNN outputs a nonnegative mean parameter $ \\mu_t $ and a shared dispersion parameter $ r > 0 $. The observed counts are $ y_t \\in \\{0,1,2,\\dots\\} $. In scRNA-seq, a widely accepted generative model for counts is the Negative Binomial distribution, parameterized by mean and dispersion, which captures over-dispersion beyond the Poisson model.\n\nStarting from the foundational definition of the Negative Binomial distribution as a count distribution over nonnegative integers with a parameterization that yields expectation $ \\mathbb{E}[Y] = \\mu $ and variance $ \\operatorname{Var}(Y) = \\mu + \\mu^2 / r $, derive an expression for the single-time log-likelihood $ \\ell(\\mu_t, r; y_t) $ and then compute the total log-likelihood $ \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) $ for a given sequence $ \\{y_t\\}_{t=1}^{T} $. Use the representation consistent with real-valued $ r > 0 $ via the Gamma function to ensure that the dispersion $ r $ is not restricted to integer values.\n\nTo encourage biologically plausible trajectories, propose a smoothness penalty over the RNN means $ \\{\\mu_t\\}_{t=1}^{T} $ based on a discrete-time finite-difference operator rooted in classical regularization theory. Implement the second-order difference penalty\n$$\nS_2(\\mu) \\;=\\; \\sum_{t=3}^{T} \\left( \\mu_t - 2 \\mu_{t-1} + \\mu_{t-2} \\right)^2,\n$$\nwhich penalizes rapid changes in discrete curvature and favors smoothly varying $ \\mu_t $. Form the penalized objective\n$$\nJ(\\mu, r; y) \\;=\\; \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) \\;-\\; \\lambda \\, S_2(\\mu),\n$$\nwhere $ \\lambda \\ge 0 $ is a user-specified regularization strength.\n\nYour program must compute, for each test case below, the triple consisting of the total log-likelihood $ \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) $, the smoothness penalty $ S_2(\\mu) $, and the penalized objective $ J(\\mu, r; y) $. All outputs are real numbers. No physical units are involved. Angles are not used.\n\nTest suite (each case specifies $ y $, $ \\mu $, $ r $, and $ \\lambda $):\n- Case $1$ (general consistency): $ y = [3,4,5,6,7] $, $ \\mu = [3.2,3.8,4.5,5.5,6.6] $, $ r = 10.0 $, $ \\lambda = 0.1 $.\n- Case $2$ (near-Poisson limit and zero counts): $ y = [0,0,1,0,2] $, $ \\mu = [0.2,0.3,0.9,0.1,1.8] $, $ r = 100.0 $, $ \\lambda = 0.5 $.\n- Case $3$ (high over-dispersion and abrupt changes): $ y = [1,10,2,12,3] $, $ \\mu = [0.9,9.5,1.2,10.8,2.4] $, $ r = 0.7 $, $ \\lambda = 1.0 $.\n- Case $4$ (sharp spike and small mean elsewhere): $ y = [0,1,0,20,0] $, $ \\mu = [0.05,0.8,0.05,15.0,0.05] $, $ r = 2.0 $, $ \\lambda = 2.0 $.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to a test case and is itself a list $ [\\text{LL}, \\text{S}, \\text{J}] $ of three floats. For example, the output must look like $ [[\\text{LL}_1,\\text{S}_1,\\text{J}_1],[\\text{LL}_2,\\text{S}_2,\\text{J}_2],\\dots] $ with no additional text.", "solution": "The problem requires the computation of a penalized log-likelihood objective function for a time series of counts modeled by a Negative Binomial (NB) distribution. The objective function is given by $J(\\mu, r; y) = \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) - \\lambda S_2(\\mu)$. To compute this, we must first derive an explicit formula for the single-time log-likelihood $\\ell(\\mu_t, r; y_t)$ and then implement the calculation for the total log-likelihood, the smoothness penalty $S_2(\\mu)$, and the final objective $J$.\n\n**1. Derivation of the Negative Binomial Log-Likelihood $\\ell(\\mu_t, r; y_t)$**\n\nThe problem specifies the Negative Binomial distribution through its mean $\\mathbb{E}[Y] = \\mu$ and variance $\\operatorname{Var}(Y) = \\mu + \\mu^2/r$. This is a common parameterization in bioinformatics. To find the corresponding probability mass function (PMF), we relate this parameterization to a more common one defined by the number of failures, $r$, and the probability of success, $p$. The PMF for observing $k \\in \\{0, 1, 2, \\dots\\}$ successes before $r$ failures is:\n$$ P(Y=k|r, p) = \\binom{k+r-1}{k} p^k (1-p)^r $$\nFor this parameterization, the mean and variance are $\\mathbb{E}[Y] = pr/(1-p)$ and $\\operatorname{Var}(Y) = pr/(1-p)^2$, respectively.\n\nBy equating the specified mean $\\mu$ with the formula for the expectation, we can express $p$ in terms of $\\mu$ and $r$:\n$$ \\mu = \\frac{pr}{1-p} \\implies \\mu(1-p) = pr \\implies \\mu - \\mu p = pr \\implies \\mu = p(\\mu+r) \\implies p = \\frac{\\mu}{\\mu+r} $$\nFrom this, the probability of failure is $1-p = 1 - \\frac{\\mu}{\\mu+r} = \\frac{r}{\\mu+r}$.\n\nWe can verify that this reparameterization is consistent with the given variance:\n$$ \\operatorname{Var}(Y) = \\frac{pr}{(1-p)^2} = \\frac{(\\mu/(\\mu+r))r}{(r/(\\mu+r))^2} = \\frac{\\mu r}{\\mu+r} \\frac{(\\mu+r)^2}{r^2} = \\frac{\\mu(\\mu+r)}{r} = \\mu + \\frac{\\mu^2}{r} $$\nThe reparameterization is correct.\n\nThe problem requires a formulation for real-valued $r > 0$, which is achieved by expressing the binomial coefficient using the Gamma function, $\\Gamma(z)$, via the identity $\\binom{n}{k} = \\frac{\\Gamma(n+1)}{\\Gamma(k+1)\\Gamma(n-k+1)}$. For our binomial coefficient, with $n=k+r-1$ (here using $y_t$ for $k$):\n$$ \\binom{y_t+r-1}{y_t} = \\frac{\\Gamma(y_t+r-1+1)}{\\Gamma(y_t+1)\\Gamma(y_t+r-1-y_t+1)} = \\frac{\\Gamma(y_t+r)}{\\Gamma(y_t+1)\\Gamma(r)} $$\nSubstituting this and the expressions for $p$ and $1-p$ into the PMF expression for an observation $y_t$ with mean $\\mu_t$ yields:\n$$ P(Y=y_t|\\mu_t, r) = \\frac{\\Gamma(y_t+r)}{\\Gamma(y_t+1)\\Gamma(r)} \\left(\\frac{\\mu_t}{\\mu_t+r}\\right)^{y_t} \\left(\\frac{r}{\\mu_t+r}\\right)^r $$\nThe single-time log-likelihood $\\ell(\\mu_t, r; y_t) = \\log P(Y=y_t|\\mu_t, r)$ is therefore:\n$$ \\ell(\\mu_t, r; y_t) = \\log\\left(\\frac{\\Gamma(y_t+r)}{\\Gamma(y_t+1)\\Gamma(r)}\\right) + y_t\\log\\left(\\frac{\\mu_t}{\\mu_t+r}\\right) + r\\log\\left(\\frac{r}{\\mu_t+r}\\right) $$\nUsing the properties of the logarithm, we can expand this expression into a form suitable for computation. computationally, it is more stable to work with the log-gamma function, $\\log\\Gamma(z)$.\n$$ \\ell(\\mu_t, r; y_t) = \\log\\Gamma(y_t+r) - \\log\\Gamma(y_t+1) - \\log\\Gamma(r) + y_t(\\log\\mu_t - \\log(\\mu_t+r)) + r(\\log r - \\log(\\mu_t+r)) $$\nCombining the terms involving $\\log(\\mu_t+r)$ gives the final expression for a single time point:\n$$ \\ell(\\mu_t, r; y_t) = \\log\\Gamma(y_t+r) - \\log\\Gamma(y_t+1) - \\log\\Gamma(r) + y_t\\log\\mu_t + r\\log r - (y_t+r)\\log(\\mu_t+r) $$\nThe total log-likelihood for the entire time series is the sum over all time points:\n$$ \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) $$\n\n**2. The Smoothness Penalty $S_2(\\mu)$**\n\nThe problem defines a second-order finite difference penalty to encourage smoothness in the sequence of mean parameters $\\{\\mu_t\\}_{t=1}^{T}$. This penalty is given by:\n$$ S_2(\\mu) = \\sum_{t=3}^{T} \\left( \\mu_t - 2 \\mu_{t-1} + \\mu_{t-2} \\right)^2 $$\nThis term penalizes large values of the discrete analogue of the second derivative of the mean trajectory $\\mu(t)$, favoring trajectories that are close to linear. The summation starts at $t=3$, so it is defined for time series of length $T \\ge 3$. For $T < 3$, the penalty is $0$.\n\n**3. The Penalized Objective $J(\\mu, r; y)$**\n\nThe final objective function combines the total log-likelihood, which measures the goodness-of-fit to the data, and the smoothness penalty, which enforces a prior belief about the trajectory's shape. A non-negative regularization parameter $\\lambda \\ge 0$ controls the trade-off:\n$$ J(\\mu, r; y) = \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) - \\lambda S_2(\\mu) $$\nThe program will compute these three quantities for each provided test case: the total log-likelihood $\\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t)$, the smoothness penalty $S_2(\\mu)$, and the penalized objective $J(\\mu, r; y)$. The implementation will utilize a numerically stable log-gamma function from the `scipy` library.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases and print the results.\n    \"\"\"\n\n    def calculate_objective(y, mu, r, lam):\n        \"\"\"\n        Calculates the total log-likelihood, smoothness penalty, and penalized objective\n        for a single test case.\n\n        Args:\n            y (list of int): The observed counts time series.\n            mu (list of float): The mean parameters time series from the RNN.\n            r (float): The shared dispersion parameter.\n            lam (float): The regularization strength.\n\n        Returns:\n            list of float: A list containing [total_log_likelihood, smoothness_penalty, penalized_objective].\n        \"\"\"\n        # Convert lists to numpy arrays for vectorized operations\n        y = np.array(y, dtype=float)\n        mu = np.array(mu, dtype=float)\n\n        # --- Total Log-Likelihood (LL) ---\n        # The log-likelihood formula is:\n        # LL = log(Gamma(y+r)) - log(Gamma(y+1)) - log(Gamma(r))\n        #      + y*log(mu) + r*log(r) - (y+r)*log(mu+r)\n        \n        # The term y*log(mu) is 0 when y is 0. Using np.where handles this correctly\n        # and avoids potential `0 * -inf = nan` issues if mu could be 0.\n        # The test cases ensure mu > 0, but this is a robust practice.\n        y_log_mu = np.where(y > 0, y * np.log(mu), 0.0)\n\n        log_lik_terms = (gammaln(y + r) -\n                         gammaln(y + 1) -\n                         gammaln(r) +\n                         y_log_mu +\n                         r * np.log(r) -\n                         (y + r) * np.log(mu + r))\n        \n        total_ll = np.sum(log_lik_terms)\n\n        # --- Smoothness Penalty (S2) ---\n        T = len(mu)\n        if T  3:\n            s2_penalty = 0.0\n        else:\n            # S2 = sum_{t=3 to T} (mu_t - 2*mu_{t-1} + mu_{t-2})^2\n            second_diffs = mu[2:] - 2 * mu[1:-1] + mu[:-2]\n            s2_penalty = np.sum(second_diffs**2)\n\n        # --- Penalized Objective (J) ---\n        penalized_objective = total_ll - lam * s2_penalty\n        \n        return [total_ll, s2_penalty, penalized_objective]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (y, mu, r, lambda)\n        ([3, 4, 5, 6, 7], [3.2, 3.8, 4.5, 5.5, 6.6], 10.0, 0.1),\n        # Case 2\n        ([0, 0, 1, 0, 2], [0.2, 0.3, 0.9, 0.1, 1.8], 100.0, 0.5),\n        # Case 3\n        ([1, 10, 2, 12, 3], [0.9, 9.5, 1.2, 10.8, 2.4], 0.7, 1.0),\n        # Case 4\n        ([0, 1, 0, 20, 0], [0.05, 0.8, 0.05, 15.0, 0.05], 2.0, 2.0),\n    ]\n\n    results = []\n    for case in test_cases:\n        y_vals, mu_vals, r_val, lambda_val = case\n        result_triple = calculate_objective(y_vals, mu_vals, r_val, lambda_val)\n        results.append(result_triple)\n\n    # Format the final output string as specified: [[LL1,S1,J1],[LL2,S2,J2],...]\n    formatted_results = []\n    for res in results:\n        # Convert each float in the result triple to a string, join with commas,\n        # and enclose in brackets to form a string like \"[1.23,4.56,7.89]\".\n        formatted_results.append(f\"[{','.join(map(str, res))}]\")\n\n    # Join the formatted strings for each case and enclose in outer brackets.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3344950"}]}