{"hands_on_practices": [{"introduction": "To truly understand RNA velocity, it is essential to look beyond pre-packaged software and engage with the fundamental steps of the analysis. This practice guides you through building a simplified but complete RNA velocity pipeline from first principles, starting from raw messenger ribonucleic acid (mRNA) counts and culminating in a smoothed vector field. By implementing each stage—from normalization and statistical modeling to dimensionality reduction and projection—you will gain a deep, practical appreciation for how cellular state dynamics are inferred from static snapshots of gene expression. [@problem_id:3346376]", "problem": "You are given a small collection of single-cell spliced and unspliced messenger ribonucleic acid (mRNA) count matrices and asked to implement a complete, reproducible preprocessing and normalization pipeline appropriate for downstream ribonucleic acid (RNA) velocity analysis and vector field estimation. The pipeline must be built from first principles and must include the following steps: (i) cell-wise library-size normalization with a target library size, (ii) pseudocount addition to stabilize ratios and logarithms, (iii) logarithmic transformation, (iv) gene-wise standardization, (v) per-gene linear regression of unspliced on spliced to obtain residual-based velocity estimates, (vi) projection of gene-wise velocities into a two-dimensional embedding derived from principal component analysis (PCA) on the spliced data, and (vii) kernel-based smoothing of the projected velocities into a continuous vector field evaluated at a specified query point.\n\nFundamental base and definitions:\n- The Central Dogma of molecular biology specifies that Deoxyribonucleic Acid (DNA) is transcribed into RNA, which is spliced and processed to yield mature (spliced) transcripts; the observed single-cell counts of spliced and unspliced RNA per gene arise from this process and are subject to technical sampling variation.\n- We assume that each cell $i$ has observed nonnegative integer spliced counts $S_{i g}$ and unspliced counts $U_{i g}$ for each gene $g$. The cell-wise library size is defined as $L_i = \\sum_{g} \\left(S_{i g} + U_{i g}\\right)$.\n- The aim of library-size normalization is to rescale each cell so that total molecular content is on a comparable scale across cells, which is critical before fitting models of transcriptional dynamics across the population. The logarithmic transformation stabilizes variance, and gene-wise standardization ensures comparability of spliced and unspliced signals in linear modeling.\n- Residual-based RNA velocity uses a linear model for each gene relating unspliced to spliced signals, and estimates velocity as the deviation from the fitted steady-state relationship.\n\nRequired computations to implement:\n1. Cell-wise library-size normalization with pseudocount addition:\n   - For each cell $i$, compute $L_i = \\sum_{g} \\left(S_{i g} + U_{i g}\\right)$.\n   - Given a target library size $L_0$ and a small positive floor $\\varepsilon_L$ to avoid division by zero, define the size factor $s_i = \\max(L_i,\\varepsilon_L)/L_0$.\n   - Given a pseudocount $p > 0$, define pseudocount-adjusted and normalized counts\n     $$\n     \\tilde{S}_{i g} = \\frac{S_{i g} + p}{s_i}, \\quad \\tilde{U}_{i g} = \\frac{U_{i g} + p}{s_i}.\n     $$\n2. Logarithmic transformation:\n   - Define log-transformed quantities\n     $$\n     \\hat{S}_{i g} = \\log\\!\\left(1 + \\tilde{S}_{i g}\\right), \\quad \\hat{U}_{i g} = \\log\\!\\left(1 + \\tilde{U}_{i g}\\right).\n     $$\n3. Gene-wise standardization across cells:\n   - For each gene $g$, compute the means across cells $m^S_g = \\frac{1}{n}\\sum_i \\hat{S}_{i g}$ and $m^U_g = \\frac{1}{n}\\sum_i \\hat{U}_{i g}$, and the population standard deviations\n     $$\n     \\sigma^S_g = \\sqrt{\\frac{1}{n}\\sum_i \\left(\\hat{S}_{i g} - m^S_g\\right)^2}, \\quad \\sigma^U_g = \\sqrt{\\frac{1}{n}\\sum_i \\left(\\hat{U}_{i g} - m^U_g\\right)^2}.\n     $$\n   - With a small numerical stabilizer $\\delta > 0$, define standardized quantities\n     $$\n     \\bar{S}_{i g} = \\frac{\\hat{S}_{i g} - m^S_g}{\\max(\\sigma^S_g,\\delta)}, \\quad \\bar{U}_{i g} = \\frac{\\hat{U}_{i g} - m^U_g}{\\max(\\sigma^U_g,\\delta)}.\n     $$\n4. Linear regression per gene and residual-based velocities:\n   - For each gene $g$, fit a univariate linear model with intercept relating $\\bar{U}_{i g}$ to $\\bar{S}_{i g}$ across cells $i$:\n     $$\n     \\bar{U}_{i g} = \\alpha_g \\bar{S}_{i g} + \\beta_g + \\varepsilon_{i g}.\n     $$\n   - Let $x_i = \\bar{S}_{i g}$, $y_i = \\bar{U}_{i g}$, $\\mu_x = \\frac{1}{n}\\sum_i x_i$, $\\mu_y = \\frac{1}{n}\\sum_i y_i$, $\\mathrm{var}(x)=\\frac{1}{n}\\sum_i (x_i-\\mu_x)^2$, $\\mathrm{cov}(x,y)=\\frac{1}{n}\\sum_i (x_i-\\mu_x)(y_i-\\mu_y)$. If $\\mathrm{var}(x) \\ge \\delta$, set $\\alpha_g = \\mathrm{cov}(x,y)/\\mathrm{var}(x)$ and $\\beta_g = \\mu_y - \\alpha_g \\mu_x$; otherwise set $\\alpha_g = 0$ and $\\beta_g = \\mu_y$. Define the residual-based velocity per cell and gene as\n     $$\n     v_{i g} = y_i - \\left(\\alpha_g x_i + \\beta_g\\right).\n     $$\n5. Two-dimensional embedding by principal component analysis:\n   - Let $Z$ be the matrix with entries $Z_{i g} = \\bar{S}_{i g}$. Compute the singular value decomposition $Z = U \\Sigma V^\\top$. Take the first $2$ columns of $V$ to obtain the gene loadings matrix $W \\in \\mathbb{R}^{G \\times 2}$.\n   - Define the two-dimensional embedding of cells as\n     $$\n     X_i = \\sum_{g} Z_{i g} W_{g, :} \\in \\mathbb{R}^2,\n     $$\n     and the projected velocity vectors as\n     $$\n     \\mathbf{v}^{\\mathrm{emb}}_i = \\sum_{g} v_{i g} W_{g, :} \\in \\mathbb{R}^2.\n     $$\n6. Kernel smoothing of the vector field at a query point:\n   - Given a query point $\\mathbf{q} \\in \\mathbb{R}^2$, a bandwidth $h > 0$, and a Gaussian kernel with weights\n     $$\n     w_i = \\exp\\!\\left(-\\frac{\\lVert X_i - \\mathbf{q}\\rVert^2}{2 h^2}\\right),\n     $$\n     define the smoothed vector field at $\\mathbf{q}$ as\n     $$\n     \\hat{\\mathbf{V}}(\\mathbf{q}) = \\frac{\\sum_i w_i \\, \\mathbf{v}^{\\mathrm{emb}}_i}{\\sum_i w_i}.\n     $$\n\nEdge cases to handle:\n- If $L_i = 0$ for a cell, enforce the floor with $\\varepsilon_L$.\n- If $\\sigma^S_g$ or $\\sigma^U_g$ is zero, use the stabilizer $\\delta$ in the denominator for standardization.\n- If $\\mathrm{var}(x) < \\delta$ in regression, set $\\alpha_g = 0$ and $\\beta_g = \\mu_y$ to avoid division by near-zero.\n\nTest suite:\nFor each test case, you are given spliced counts $S$, unspliced counts $U$, and parameters $(L_0, p, \\varepsilon_L, \\delta, h, \\mathbf{q})$. Implement all steps $1$–$6$ above and return the smoothed vector field $\\hat{\\mathbf{V}}(\\mathbf{q})$ as a list of two floating-point numbers rounded to six decimal places.\n\n- Test case $1$ (happy path, moderate counts):\n  - $S^{(1)} = \\begin{bmatrix} 10 & 5 & 0 \\\\ 3 & 8 & 1 \\\\ 0 & 2 & 9 \\\\ 6 & 4 & 3 \\end{bmatrix}$, $U^{(1)} = \\begin{bmatrix} 4 & 2 & 0 \\\\ 1 & 3 & 0 \\\\ 0 & 1 & 5 \\\\ 2 & 1 & 1 \\end{bmatrix}$.\n  - Parameters: $L_0 = 1000.0$, $p = 1.0$, $\\varepsilon_L = 1.0$, $\\delta = 10^{-8}$, $h = 1.0$, $\\mathbf{q} = (0.0, 0.0)$.\n- Test case $2$ (boundary condition with zero-count cell and sparse genes):\n  - $S^{(2)} = \\begin{bmatrix} 0 & 0 & 0 \\\\ 2 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 3 \\end{bmatrix}$, $U^{(2)} = \\begin{bmatrix} 0 & 0 & 0 \\\\ 0 & 1 & 0 \\\\ 0 & 0 & 2 \\\\ 1 & 0 & 0 \\end{bmatrix}$.\n  - Parameters: $L_0 = 1000.0$, $p = 0.5$, $\\varepsilon_L = 1.0$, $\\delta = 10^{-8}$, $h = 0.5$, $\\mathbf{q} = (0.0, 0.0)$.\n- Test case $3$ (edge case with highly uneven library sizes and zero-variance genes):\n  - $S^{(3)} = \\begin{bmatrix} 1000 & 50 & 7 \\\\ 50 & 50 & 7 \\\\ 3000 & 50 & 7 \\\\ 10 & 50 & 7 \\end{bmatrix}$, $U^{(3)} = \\begin{bmatrix} 200 & 10 & 3 \\\\ 10 & 10 & 3 \\\\ 600 & 10 & 3 \\\\ 2 & 10 & 3 \\end{bmatrix}$.\n  - Parameters: $L_0 = 10000.0$, $p = 1.0$, $\\varepsilon_L = 1.0$, $\\delta = 10^{-8}$, $h = 2.0$, $\\mathbf{q} = (0.0, 0.0)$.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each test case contributes a two-element list corresponding to $\\hat{\\mathbf{V}}(\\mathbf{q})$ rounded to six decimal places. For example: $[\\,[v^{(1)}_x, v^{(1)}_y], [v^{(2)}_x, v^{(2)}_y], [v^{(3)}_x, v^{(3)}_y]\\,]$.", "solution": "The problem presents a well-defined and scientifically grounded task from the field of computational systems biology: to implement a simplified RNA velocity analysis pipeline. The problem is valid as it provides a complete, self-contained, and logically consistent set of instructions, definitions, and test data. It is free from scientific inaccuracies, ambiguities, or contradictions. The steps described are standard, albeit simplified, procedures in single-cell data analysis, encompassing normalization, transformation, statistical modeling, dimensionality reduction, and vector field estimation. All required mathematical formulas, parameters, and edge-case handling rules are explicitly stated, making the problem well-posed and enabling the computation of a unique, verifiable solution.\n\nThe solution proceeds by systematically implementing each of the six specified computational steps. The implementation is designed to be a direct translation of the provided mathematical formalism into executable code.\n\n1.  **Cell-wise Library-Size Normalization**: For each cell, the total RNA counts (spliced plus unspliced) are computed to determine its library size, $L_i$. A size factor, $s_i$, is then calculated by scaling this library size relative to a target library size, $L_0$, while enforcing a minimum floor, $\\varepsilon_L$, to prevent division by zero for cells with no counts. The raw spliced ($S_{ig}$) and unspliced ($U_{ig}$) counts for each gene $g$ in cell $i$ are first augmented by a pseudocount, $p$, and then divided by the cell's size factor, $s_i$. This yields normalized counts $\\tilde{S}_{ig}$ and $\\tilde{U}_{ig}$, which are adjusted for sequencing depth and cell size variations.\n\n2.  **Logarithmic Transformation**: The normalized counts, $\\tilde{S}_{ig}$ and $\\tilde{U}_{ig}$, are log-transformed using the function $\\log(1+x)$. This common technique, implemented as `np.log1p` for numerical stability, serves to stabilize the variance across the range of expression values and make the data distribution more symmetric, which is beneficial for downstream linear modeling. The resulting quantities are denoted $\\hat{S}_{ig}$ and $\\hat{U}_{ig}$.\n\n3.  **Gene-wise Standardization**: To make expression values comparable across different genes, which may have vastly different dynamic ranges, each gene's log-transformed counts are standardized. For each gene $g$, the mean ($m^S_g, m^U_g$) and population standard deviation ($\\sigma^S_g, \\sigma^U_g$) are computed across all cells. The standardized values, $\\bar{S}_{ig}$ and $\\bar{U}_{ig}$, are obtained by subtracting the mean and dividing by the standard deviation. A small stabilizer, $\\delta$, is used in the denominator to prevent division by zero for genes with no variance in their expression across the cell population.\n\n4.  **Linear Regression and Residual-based Velocities**: The core of RNA velocity estimation in this model lies in relating the unspliced and spliced mRNA abundance. For each gene $g$, a simple linear regression model, $\\bar{U}_{ig} = \\alpha_g \\bar{S}_{ig} + \\beta_g$, is fitted to predict the standardized unspliced abundance from the standardized spliced abundance. The slope $\\alpha_g$ and intercept $\\beta_g$ are computed using the ordinary least squares formulas. An edge case is handled for genes with near-zero variance in spliced counts, where the slope is set to zero. The RNA velocity, $v_{ig}$, for each cell $i$ and gene $g$ is defined as the residual from this regression—the difference between the observed standardized unspliced abundance, $\\bar{U}_{ig}$, and its predicted value from the model. This residual represents the deviation from the expected steady-state relationship between splicing and degradation, indicating whether a gene's expression is increasing or decreasing.\n\n5.  **PCA Embedding and Velocity Projection**: To visualize the developmental trajectories, cells are often embedded in a low-dimensional space. Here, Principal Component Analysis (PCA) is performed on the standardized spliced data matrix, $Z_{ig} = \\bar{S}_{ig}$. The matrix of gene loadings corresponding to the first two principal components, denoted $W$, is extracted from the singular value decomposition (SVD) of $Z$. The two-dimensional cell embedding, $X_i$, is computed by projecting the standardized spliced data onto these loadings ($X = Z W$). Similarly, the high-dimensional gene-wise velocity vectors, $v_{ig}$, are projected into the same two-dimensional space to yield embedded velocity vectors, $\\mathbf{v}^{\\mathrm{emb}}_i$.\n\n6.  **Kernel Smoothing**: The final step is to estimate a continuous vector field from the discrete velocity vectors of individual cells. Given a query point $\\mathbf{q}$ in the two-dimensional embedding, a Gaussian kernel is used to compute a weighted average of the embedded velocities, $\\mathbf{v}^{\\mathrm{emb}}_i$. Cells closer to the query point in the embedding space receive higher weights. This smoothing process provides a robust estimate, $\\hat{\\mathbf{V}}(\\mathbf{q})$, of the local velocity vector, representing the likely direction and magnitude of cellular state change at that position in the developmental landscape.\n\nEach of these steps is implemented using the `numpy` library for efficient array-based computation, carefully following the provided formulas and handling all specified edge conditions.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _calculate_rna_velocity_pipeline(S, U, params):\n    \"\"\"\n    Implements the complete RNA velocity pipeline for a single dataset.\n    \n    Args:\n        S (np.ndarray): Spliced counts matrix (cells x genes).\n        U (np.ndarray): Unspliced counts matrix (cells x genes).\n        params (tuple): A tuple of parameters (L0, p, eps_L, delta, h, q).\n\n    Returns:\n        list: The smoothed 2D vector [vx, vy], rounded to 6 decimal places.\n    \"\"\"\n    L0, p, eps_L, delta, h, q_tuple = params\n    S = np.array(S, dtype=float)\n    U = np.array(U, dtype=float)\n    q = np.array(q_tuple, dtype=float)\n    \n    n_cells, n_genes = S.shape\n\n    # Step 1: Cell-wise library-size normalization\n    L = S.sum(axis=1) + U.sum(axis=1)\n    s = np.maximum(L, eps_L) / L0\n    S_tilde = (S + p) / s[:, np.newaxis]\n    U_tilde = (U + p) / s[:, np.newaxis]\n\n    # Step 2: Logarithmic transformation\n    S_hat = np.log1p(S_tilde)\n    U_hat = np.log1p(U_tilde)\n    \n    # Step 3: Gene-wise standardization\n    m_S = S_hat.mean(axis=0)\n    m_U = U_hat.mean(axis=0)\n    # np.std computes population standard deviation (ddof=0) by default\n    sigma_S = S_hat.std(axis=0)\n    sigma_U = U_hat.std(axis=0)\n    \n    denom_S = np.maximum(sigma_S, delta)\n    denom_U = np.maximum(sigma_U, delta)\n    \n    S_bar = (S_hat - m_S) / denom_S\n    U_bar = (U_hat - m_U) / denom_U\n\n    # Step 4: Linear regression per gene and residual-based velocities\n    v = np.zeros_like(S_bar)\n    for g in range(n_genes):\n        x = S_bar[:, g]\n        y = U_bar[:, g]\n        \n        mu_x = x.mean()\n        mu_y = y.mean()\n        \n        # np.var computes population variance (ddof=0) by default\n        var_x = np.var(x)\n        \n        if var_x >= delta:\n            cov_xy = np.mean((x - mu_x) * (y - mu_y))\n            alpha_g = cov_xy / var_x\n            beta_g = mu_y - alpha_g * mu_x\n        else:\n            alpha_g = 0.0\n            beta_g = mu_y\n            \n        v[:, g] = y - (alpha_g * x + beta_g)\n\n    # Step 5: Two-dimensional embedding by PCA\n    Z = S_bar\n    # Using full_matrices=False is efficient and gives Vh of shape (min(n,G), G)\n    try:\n        _, _, Vh = np.linalg.svd(Z, full_matrices=False)\n    except np.linalg.LinAlgError:\n         return [0.0, 0.0] # Failsafe for non-finite data\n\n    # V is the transpose of Vh\n    V = Vh.T\n    \n    # Handle cases with fewer than 2 genes/principal components\n    if V.shape[1] < 2:\n        W = np.zeros((n_genes, 2))\n        W[:, :V.shape[1]] = V[:, :V.shape[1]]\n    else:\n        # W are the first 2 columns of V (gene loadings)\n        W = V[:, :2]\n\n    # Project data and velocities onto the 2D embedding space\n    X_emb = Z @ W\n    v_emb = v @ W\n    \n    # Step 6: Kernel smoothing of the vector field at a query point\n    diff = X_emb - q\n    sq_dists = np.sum(diff**2, axis=1)\n    weights = np.exp(-sq_dists / (2 * h**2))\n    \n    sum_weights = np.sum(weights)\n    \n    if sum_weights < delta: # Check for effective zero\n        V_q_hat = np.array([0.0, 0.0])\n    else:\n        weighted_v_emb = weights[:, np.newaxis] * v_emb\n        V_q_hat = np.sum(weighted_v_emb, axis=0) / sum_weights\n        \n    return [round(c, 6) for c in V_q_hat]\n\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs the pipeline for each, and prints the final output.\n    \"\"\"\n    test_cases = [\n        {\n            \"S\": np.array([[10, 5, 0], [3, 8, 1], [0, 2, 9], [6, 4, 3]]),\n            \"U\": np.array([[4, 2, 0], [1, 3, 0], [0, 1, 5], [2, 1, 1]]),\n            \"params\": (1000.0, 1.0, 1.0, 1e-8, 1.0, (0.0, 0.0))\n        },\n        {\n            \"S\": np.array([[0, 0, 0], [2, 0, 0], [0, 1, 0], [0, 0, 3]]),\n            \"U\": np.array([[0, 0, 0], [0, 1, 0], [0, 0, 2], [1, 0, 0]]),\n            \"params\": (1000.0, 0.5, 1.0, 1e-8, 0.5, (0.0, 0.0))\n        },\n        {\n            \"S\": np.array([[1000, 50, 7], [50, 50, 7], [3000, 50, 7], [10, 50, 7]]),\n            \"U\": np.array([[200, 10, 3], [10, 10, 3], [600, 10, 3], [2, 10, 3]]),\n            \"params\": (10000.0, 1.0, 1.0, 1e-8, 2.0, (0.0, 0.0))\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = _calculate_rna_velocity_pipeline(case[\"S\"], case[\"U\"], case[\"params\"])\n        results.append(result)\n\n    # The str() representation of a list of lists matches the required format structure.\n    # Ex: [[-0.0, 0.0], [1.0, 2.0]] -> str -> '[[-0.0, 0.0], [1.0, 2.0]]'\n    # The problem asks for a comma-separated list of lists.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3346376"}, {"introduction": "The estimation of a continuous vector field from discrete single-cell data relies on local averaging, typically using a $k$-nearest neighbor graph constructed in a low-dimensional embedding. However, the choice of this graph is not neutral and can introduce significant bias, especially when distinct cell lineages are close together. This exercise uses a controlled mathematical simulation to explore an adversarial scenario, allowing you to quantitatively investigate how neighbor selection can mix signals from opposing developmental paths and distort the resulting velocity field. [@problem_id:3346448]", "problem": "You are given the task of quantifying the bias introduced by the choice of a neighbor graph in estimating an RNA velocity vector field when two developmentally distinct lineages are embedded in a space where $k$-nearest neighbors (kNN) mixes them. The analysis must be grounded in first principles: RNA velocity is the time derivative of gene expression along a latent manifold, and vector field estimation from single-cell data commonly smooths local velocity estimates using a neighbor graph. You must mathematically construct an adversarial embedding and compute a quantitative bias metric as a function of the number of neighbors $k$ and the manifold curvature $\\kappa$.\n\nConstruct the following purely mathematical model:\n\n- There are two lineages (curves) embedded in two-dimensional Euclidean space. Let the shared curve shape be a parabola with curvature controlled near the origin. Define the first lineage as the parametric curve $\\alpha(t) = (x(t), y(t))$ with\n  $$\n  x(t) = t, \\quad y(t) = \\tfrac{1}{2}\\,\\kappa\\,t^2,\n  $$\n  and the second lineage as $\\beta(t) = (x(t), y(t) + \\delta)$ with the same $x(t)$ and an added vertical offset $\\delta$ so that the lineages remain distinct but close. The parameter $t$ is sampled uniformly.\n\n- The true velocity is the time derivative of the embedding along each curve. For the first lineage, define\n  $$\n  \\mathbf{v}_A(t) = \\frac{d\\alpha}{dt} = \\left(1,\\, \\kappa\\, t\\right).\n  $$\n  For the second lineage, define the opposite progression direction to create an adversarial configuration:\n  $$\n  \\mathbf{v}_B(t) = -\\mathbf{v}_A(t).\n  $$\n  For error computation, normalize the true velocities to unit vectors:\n  $$\n  \\widehat{\\mathbf{v}}_A(t) = \\frac{\\mathbf{v}_A(t)}{\\|\\mathbf{v}_A(t)\\|_2}, \\quad \\widehat{\\mathbf{v}}_B(t) = \\frac{\\mathbf{v}_B(t)}{\\|\\mathbf{v}_B(t)\\|_2}.\n  $$\n\n- The estimated velocity at a cell is obtained by averaging the true velocities of its $k$ Euclidean nearest neighbors in the embedded space (including neighbors from both lineages) and then comparing the direction to the ground truth at that cell. Let $\\mathcal{N}_k(i)$ denote the index set of the $k$ nearest neighbors of cell $i$ excluding itself, and let $\\mathbf{v}_j^{\\text{true}}$ denote the unit true velocity at neighbor $j$. Define the estimated velocity at $i$ as the unweighted mean\n  $$\n  \\mathbf{v}_i^{\\text{est}} = \\frac{1}{k}\\sum_{j \\in \\mathcal{N}_k(i)} \\mathbf{v}_j^{\\text{true}}.\n  $$\n  The per-cell directional error is defined using the cosine dissimilarity:\n  $$\n  e_i = 1 - \\frac{\\mathbf{v}_i^{\\text{est}} \\cdot \\mathbf{v}_i^{\\text{true}}}{\\|\\mathbf{v}_i^{\\text{est}}\\|_2 \\, \\|\\mathbf{v}_i^{\\text{true}}\\|_2}.\n  $$\n  If $\\|\\mathbf{v}_i^{\\text{est}}\\|_2 = 0$, define $e_i = 1$.\n\n- Quantify the average bias $E(k,\\kappa)$ in a local window near the closest approach of the two lineages (where mixing is most adversarial). Specifically, sample $N$ cells per lineage at uniformly spaced parameter values $t$ over the interval $[-T, T]$. Define $h = \\tfrac{2T}{N-1}$ and set the vertical offset to $\\delta = \\eta h$ with a constant $\\eta \\in (0,1)$ to ensure that cross-lineage points at the same parameter $t$ are closer than same-lineage neighbors. Compute the mean error over both lineages restricted to the window $|t| \\le \\tau$:\n  $$\n  E(k,\\kappa) = \\frac{1}{M}\\sum_{i: |t_i| \\le \\tau} e_i,\n  $$\n  where $M$ is the number of cells across both lineages whose parameter values satisfy $|t_i| \\le \\tau$.\n\nImplement the following algorithm:\n\n- Fix the constants $N$, $T$, $\\eta$, and $\\tau$ to the values $N = 401$, $T = 1$, $\\eta = 0.2$, and $\\tau = 0.2$.\n- For each test case $(k,\\kappa)$, construct both lineages with the specified $\\kappa$ and compute $E(k,\\kappa)$ as defined above. Use Euclidean distance in $\\mathbb{R}^2$ for $k$-nearest neighbors. Concatenate the two lineages into a single dataset before building neighbor sets so that neighbor selection can mix lineages.\n- Normalize all true velocities to unit length before neighbor averaging. The unnormalized average $\\mathbf{v}_i^{\\text{est}}$ may be non-unit; use it directly in the cosine dissimilarity formula.\n\nTest suite:\n\n- Use the following test cases to probe different regimes, including boundary and adversarial conditions:\n  - $(k,\\kappa) = (1, 0)$\n  - $(k,\\kappa) = (1, 1)$\n  - $(k,\\kappa) = (5, 0.5)$\n  - $(k,\\kappa) = (15, 0)$\n  - $(k,\\kappa) = (51, 2)$\n  - $(k,\\kappa) = (151, 1.5)$\n\nRequired output format:\n\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the same order as the test cases, for example $[r_1,r_2,\\dots,r_6]$, where each $r_i$ is the computed value of $E(k,\\kappa)$ for the corresponding test case. Each $r_i$ must be a floating-point number.", "solution": "We formalize the problem of neighbor-induced bias in RNA velocity vector field estimation using a controlled adversarial construction. The foundational principles are as follows: RNA velocity is the time derivative of gene expression along a latent cellular trajectory; in an embedding, this trajectory is a curve, and the local velocity vector aligns with the tangent. A common estimator smooths cell-wise velocities across a $k$-nearest neighbors (kNN) graph built on Euclidean distances in the embedding. If the embedding geometry causes different lineages to be closer than within-lineage neighbors, the neighbor averaging introduces a systematic bias by mixing distinct directions.\n\nWe proceed step by step.\n\n$1.$ Construct two lineages in $\\mathbb{R}^2$ as curves with tunable curvature $\\kappa$:\n- The first lineage is $\\alpha(t) = (t, \\tfrac{1}{2}\\kappa t^2)$ for $t \\in [-T,T]$.\n- The second lineage is $\\beta(t) = (t, \\delta + \\tfrac{1}{2}\\kappa t^2)$, an offset copy displaced vertically by $\\delta$.\n\nThis choice allows direct control over curvature near $t=0$. For the parabola $y = a t^2$ with $a = \\tfrac{\\kappa}{2}$, the curvature at the origin equals $\\kappa$ by the standard curvature formula for plane curves $y(x)$, which at $x=0$ reduces to $|y''(0)|$ since $y'(0)=0$.\n\n$2.$ Define true velocities as time derivatives of the embedding, consistent with the interpretation of RNA velocity:\n- For lineage $A$, $\\mathbf{v}_A(t) = \\frac{d\\alpha}{dt} = (1,\\kappa t)$.\n- For lineage $B$, enforce an adversarial opposite developmental direction $\\mathbf{v}_B(t) = -\\mathbf{v}_A(t)$.\nNormalize to unit vectors:\n$$\n\\widehat{\\mathbf{v}}_A(t) = \\frac{(1,\\kappa t)}{\\sqrt{1+(\\kappa t)^2}}, \\quad \\widehat{\\mathbf{v}}_B(t) = -\\widehat{\\mathbf{v}}_A(t).\n$$\nThis guarantees that, for cells with the same parameter $t$ drawn from different lineages, the true velocities are antiparallel, maximizing potential bias upon mixing.\n\n$3.$ Sampling and adversarial proximity. Sample $N$ cells per lineage at parameters $t_i$ uniformly spaced over $[-T,T]$. The parameter spacing is $h = \\tfrac{2T}{N-1}$. Set the vertical offset to $\\delta = \\eta h$ for a constant $\\eta \\in (0,1)$. For small $|t|$, the Euclidean distance between cross-lineage points at the same $t$ is $\\delta$, while the distance to same-lineage neighbors at $t \\pm h$ is approximately $h\\sqrt{1+(\\kappa t)^2}$. By choosing $\\delta = \\eta h$ with $\\eta < 1$, we ensure that near $t=0$ the cross-lineage neighbor at identical $t$ is closer than same-lineage neighbors, and thus the kNN graph preferentially mixes lineages in that region.\n\n$4.$ kNN-based estimator. Concatenate both lineages into a single dataset of $2N$ cells located at points $\\{\\mathbf{x}_i\\}_{i=1}^{2N}$. For each cell $i$, compute its set $\\mathcal{N}_k(i)$ of $k$ nearest neighbors in Euclidean distance, excluding itself. Estimate the local velocity by unweighted neighbor averaging:\n$$\n\\mathbf{v}_i^{\\text{est}} = \\frac{1}{k} \\sum_{j \\in \\mathcal{N}_k(i)} \\mathbf{v}_j^{\\text{true}}.\n$$\nWe let $\\mathbf{v}_j^{\\text{true}}$ be the unit true velocity of neighbor $j$ corresponding to its lineage.\n\n$5.$ Error metric. To quantify directional bias, compute the cosine dissimilarity at each cell:\n$$\ne_i = 1 - \\frac{\\mathbf{v}_i^{\\text{est}} \\cdot \\mathbf{v}_i^{\\text{true}}}{\\|\\mathbf{v}_i^{\\text{est}}\\|_2 \\, \\|\\mathbf{v}_i^{\\text{true}}\\|_2}.\n$$\nSince $\\|\\mathbf{v}_i^{\\text{true}}\\|_2 = 1$ by construction, this reduces to $1 - \\frac{\\mathbf{v}_i^{\\text{est}} \\cdot \\mathbf{v}_i^{\\text{true}}}{\\|\\mathbf{v}_i^{\\text{est}}\\|_2}$. If $\\|\\mathbf{v}_i^{\\text{est}}\\|_2 = 0$, define $e_i = 1$ (maximal dissimilarity of random orientation on average). The mean error in a window $|t|\\le \\tau$ across both lineages is\n$$\nE(k,\\kappa) = \\frac{1}{M} \\sum_{i: |t_i| \\le \\tau} e_i.\n$$\nWe focus on a localized window to measure bias where mixing is strongest and to limit curvature-induced global effects.\n\n$6.$ Parameter choices and test suite. Fix $N = 401$, $T = 1$, and choose $\\eta = 0.2$ so that $\\delta = 0.2\\,h$, where $h = \\tfrac{2}{400} = 0.005$. Thus $\\delta = 0.001$. Choose window half-width $\\tau = 0.2$. Evaluate $E(k,\\kappa)$ for the specified pairs $(k,\\kappa)$:\n- $(1,0)$: boundary case with straight, parallel lineages and maximally adversarial opposite directions. With $k=1$, the nearest neighbor of a cell near $t=0$ lies on the opposite lineage at distance $\\delta$, giving $\\mathbf{v}_i^{\\text{est}} \\approx -\\mathbf{v}_i^{\\text{true}}$ and $e_i \\approx 2$ locally.\n- $(1,1)$: curved case with $k=1$, still adversarial; curvature slightly changes neighbor geometry.\n- $(5,0.5)$: small neighbor smoothing with low curvature.\n- $(15,0)$: stronger smoothing on straight lineages.\n- $(51,2)$: high smoothing and high curvature, increasing within-lineage neighbor distances and thus cross-lineage mixing near $t=0$.\n- $(151,1.5)$: very strong smoothing, averaging over many neighbors, potentially diluting directionality and increasing the chance of cancellation.\n\n$7.$ Computational method. For each $(k,\\kappa)$:\n- Build coordinates for both lineages using the given $\\kappa$ and $\\delta$.\n- Compute pairwise Euclidean distances and obtain $\\mathcal{N}_k(i)$ by sorting distances.\n- Compute $\\mathbf{v}_i^{\\text{est}}$ and $e_i$ for all $i$.\n- Restrict to cells with $|t| \\le \\tau$ and compute the mean to obtain $E(k,\\kappa)$.\n\nThe final program implements this algorithm deterministically and outputs the list $[E(1,0), E(1,1), E(5,0.5), E(15,0), E(51,2), E(151,1.5)]$ as a single line of comma-separated floats in brackets.\n\nQualitative expectations:\n- For $k=1$, the adversarial design yields large errors near $t=0$, close to $2$ when the nearest neighbor is on the opposite lineage with opposite direction.\n- As $k$ increases, the estimator averages over mixed neighbors; depending on the proportion of opposite-lineage neighbors, $\\mathbf{v}_i^{\\text{est}}$ can be attenuated or even nearly cancel, increasing the cosine dissimilarity toward $1$ if the estimate becomes small in magnitude or misaligned.\n- Increasing $\\kappa$ can increase the within-lineage neighbor distances at fixed parameter spacing near the window edges (since points separate more in the $y$-direction), enhancing cross-lineage mixing and tending to increase $E(k,\\kappa)$ for fixed $k$ in the adversarial region.\n\nThese behaviors emerge from the interplay between the geometric embedding and the kNN graph, grounded in the definition of RNA velocity as the manifold tangent and the estimator as neighbor averaging in the embedding.", "answer": "```python\nimport numpy as np\n\ndef build_lineages_and_velocities(kappa, N=401, T=1.0, eta=0.2):\n    # Parameter grid\n    t = np.linspace(-T, T, N)\n    h = (2*T) / (N-1)\n    delta = eta * h\n\n    # Lineage A coordinates: (t, 0.5 * kappa * t^2)\n    xA = t.copy()\n    yA = 0.5 * kappa * t**2\n\n    # Lineage B coordinates: shifted vertically by delta\n    xB = t.copy()\n    yB = delta + 0.5 * kappa * t**2\n\n    # True velocities (unit vectors)\n    # v_A = (1, kappa * t) normalized\n    denom = np.sqrt(1.0 + (kappa * t)**2)\n    vAx = 1.0 / denom\n    vAy = (kappa * t) / denom\n\n    # v_B = -v_A\n    vBx = -vAx\n    vBy = -vAy\n\n    # Stack coordinates and velocities\n    X = np.vstack([np.column_stack([xA, yA]), np.column_stack([xB, yB])])  # shape (2N, 2)\n    V_true = np.vstack([np.column_stack([vAx, vAy]), np.column_stack([vBx, vBy])])  # shape (2N, 2)\n    # Parameter t replicated for both lineages\n    t_all = np.concatenate([t, t])\n\n    return X, V_true, t_all\n\ndef knn_indices(X, k):\n    # Compute pairwise distances\n    # X shape: (M, 2)\n    M = X.shape[0]\n    # Use (x^2 + y^2) - 2 X X^T + (x^2 + y^2)^T trick\n    sq = np.sum(X**2, axis=1, keepdims=True)  # (M,1)\n    d2 = sq + sq.T - 2.0 * (X @ X.T)\n    # Ensure self-distance is inf to exclude self\n    np.fill_diagonal(d2, np.inf)\n    # Get k nearest indices for each point\n    # argsort along axis 1, take first k\n    idx = np.argpartition(d2, kth=k-1, axis=1)[:, :k]\n    # For stable ordering by actual distance within the k subset\n    # Gather distances for these idx and sort within rows\n    row_indices = np.arange(M)[:, None]\n    d2_k = d2[row_indices, idx]\n    order_within = np.argsort(d2_k, axis=1)\n    idx_sorted = idx[row_indices, order_within]\n    return idx_sorted\n\ndef compute_mean_error(X, V_true, t_all, k, tau=0.2):\n    # Build kNN graph\n    k = int(k)\n    k = max(1, min(k, X.shape[0]-1))\n    nn_idx = knn_indices(X, k)\n    # Estimate velocities by averaging neighbors' true velocities\n    V_est = np.zeros_like(V_true)\n    for i in range(X.shape[0]):\n        nbrs = nn_idx[i]\n        v_mean = V_true[nbrs].mean(axis=0)\n        V_est[i] = v_mean\n\n    # Compute per-cell cosine dissimilarity\n    # Handle zero norm estimates\n    est_norm = np.linalg.norm(V_est, axis=1)\n    # True norm is 1 by construction, but compute robustly\n    true_norm = np.linalg.norm(V_true, axis=1)\n    # Avoid division by zero\n    eps = 1e-12\n    cos_sim = np.sum(V_est * V_true, axis=1) / (np.maximum(est_norm, eps) * np.maximum(true_norm, eps))\n    # Clip for numerical safety\n    cos_sim = np.clip(cos_sim, -1.0, 1.0)\n    e = 1.0 - cos_sim\n\n    # Restrict to window |t| <= tau\n    mask = np.abs(t_all) <= tau\n    if not np.any(mask):\n        return float(np.nan)\n    E = float(e[mask].mean())\n    return E\n\ndef solve():\n    # Constants per the problem statement\n    N = 401\n    T = 1.0\n    eta = 0.2\n    tau = 0.2\n\n    # Test cases: (k, kappa)\n    test_cases = [\n        (1, 0.0),\n        (1, 1.0),\n        (5, 0.5),\n        (15, 0.0),\n        (51, 2.0),\n        (151, 1.5),\n    ]\n\n    results = []\n    for k, kappa in test_cases:\n        X, V_true, t_all = build_lineages_and_velocities(kappa, N=N, T=T, eta=eta)\n        E = compute_mean_error(X, V_true, t_all, k=k, tau=tau)\n        # Round to 6 decimal places for stable output\n        results.append(f\"{E:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3346448"}, {"introduction": "A major challenge in large-scale single-cell studies is integrating data from different experiments, or \"batches,\" which often contain technical variations that can obscure the underlying biology. This practice frames batch correction in the language of differential geometry, modeling the batch effect as a transport map that distorts the state space and the associated velocity field. By deriving and implementing the transformation rules for velocity vectors, you will learn how to align vector fields across batches and assess whether the correction preserves the true underlying dynamics. [@problem_id:3346371]", "problem": "You are given a simplified mathematical model of RNA velocity analysis across experimental batches in transcriptomic state space, framed as a two-dimensional continuous vector field. The RNA velocity at a state is defined as the time derivative of the cell’s transcriptomic state, consistent with the principle that RNA velocity represents the rate of change of gene expression levels over time. Consider a base vector field in the reference batch defined by $v(x) = A x$ with $A \\in \\mathbb{R}^{2 \\times 2}$, where $x \\in \\mathbb{R}^{2}$ is the state. For batch correction, model a differentiable coordinate change from the reference batch to a target batch as a transport map $T_b : \\mathbb{R}^{2} \\to \\mathbb{R}^{2}$, which is assumed to be a bijection with a differentiable inverse.\n\nStarting from the fundamental definition of RNA velocity as the state’s time derivative, and the chain rule for differentiable changes of variables, derive an expression for how a velocity vector in the base coordinates relates to the corresponding velocity vector in the batch coordinates. Then use this relationship to implement the following computational tasks:\n\n- Construct a set of state samples in the reference batch on a regular grid in $\\mathbb{R}^{2}$, and evaluate the base velocity field at those points.\n- For each test case, define a transport map $T_b$ and generate a corresponding set of batch-space states by applying $T_b$ to the base states. Use the relationship derived above to compute the batch-space velocity field induced by the base velocity field under $T_b$.\n- Compute an alignment metric between the batch-space velocity field predicted by the transport map and a provided batch-space “observed” velocity field. The alignment metric must be the mean cosine similarity across sample points, computed only over points where both velocity vectors have norms greater than a small threshold to avoid division by zero. Express the alignment metric as a real number.\n- Compute a dynamics distortion metric by pulling the observed batch-space velocities back into the base space using the inverse differential of $T_b$, estimating a linear operator $\\hat{A}$ via ordinary least squares that maps states to velocities in the base space, and reporting the relative Frobenius norm error $\\lVert \\hat{A} - A \\rVert_F / \\lVert A \\rVert_F$ as a real number.\n- Determine whether a test case passes if and only if both the alignment metric is at least a specified alignment threshold and the dynamics distortion metric is at most a specified distortion threshold. Each pass/fail result must be a boolean.\n\nAssume the following base field and test suite with concrete parameter values:\n\n- Base field: $A = \\begin{bmatrix} -1 & 0.5 \\\\ 0 & -0.5 \\end{bmatrix}$.\n- Sample points: a regular grid of $x = (x_1, x_2)$ with $x_1, x_2 \\in [-1, 1]$ at $21$ evenly spaced values each, giving $441$ total points.\n- Cosine similarity norm threshold: exclude points with either velocity vector having Euclidean norm less than $10^{-8}$ when computing the mean cosine similarity.\n- Alignment threshold: $\\tau_{\\text{align}} = 0.97$ (unitless).\n- Distortion threshold: $\\tau_{\\text{distort}} = 0.10$ (unitless).\n- Noise model for observed batch velocities: additive independent Gaussian noise with zero mean and specified standard deviation $\\sigma$ applied to each velocity component.\n\nTest cases (angles specified in radians):\n\n$1.$ Affine, clean: $T_b(x) = M x + t$, where $M = s R(\\theta)$, $s = 1.2$, $\\theta = 0.5$, $R(\\theta) = \\begin{bmatrix} \\cos(\\theta) & -\\sin(\\theta) \\\\ \\sin(\\theta) & \\cos(\\theta) \\end{bmatrix}$, $t = \\begin{bmatrix} 0.1 \\\\ -0.05 \\end{bmatrix}$. Observed batch velocities equal those induced by the transport map with no noise, i.e., noise standard deviation $\\sigma = 0.0$.\n\n$2.$ Affine, small noise: Same $T_b$ as case $1$, observed batch velocities equal those induced by the transport map plus Gaussian noise with $\\sigma = 0.02$.\n\n$3.$ Affine, mismatched dynamics: States use the same $T_b$ as case $1$, but observed batch velocities are generated from a mismatched operator using $Q = s R(\\phi)$ with $s = 1.2$, $\\phi = 1.0$, so observed velocities are computed as $Q v(x)$ at preimage $x$ of batch points, with no noise ($\\sigma = 0.0$).\n\n$4.$ Nonlinear, clean: $T_b(x) = \\begin{bmatrix} x_1 + \\alpha \\sin(x_1) \\\\ x_2 \\end{bmatrix}$ with $\\alpha = 0.2$. Observed batch velocities equal those induced by the transport map with no noise ($\\sigma = 0.0$). The Jacobian of $T_b$ at $x$ is $J(x) = \\begin{bmatrix} 1 + \\alpha \\cos(x_1) & 0 \\\\ 0 & 1 \\end{bmatrix}$. Invert $T_b$ for the first coordinate by solving $x_1 + \\alpha \\sin(x_1) = x_{b,1}$ numerically via Newton’s method, and note that the second coordinate inverts trivially as $x_2 = x_{b,2}$.\n\n$5.$ Nonlinear, high noise: Same $T_b$ as case $4$ with observed batch velocities equal those induced by the transport map plus Gaussian noise with $\\sigma = 0.30$.\n\nFor each test case, you must:\n\n- Compute the batch-space predicted velocity field from the base field and $T_b$.\n- Compute the mean cosine similarity alignment metric between the predicted and observed batch-space velocity fields.\n- Pull observed batch velocities back to base space using the inverse differential of $T_b$ at the corresponding preimage points, estimate $\\hat{A}$ by solving the least squares problem $\\min_{\\hat{A} \\in \\mathbb{R}^{2 \\times 2}} \\sum \\lVert \\hat{A} x - v_{\\text{base,hat}}(x) \\rVert_2^2$, and compute the relative Frobenius error $\\lVert \\hat{A} - A \\rVert_F / \\lVert A \\rVert_F$.\n\nYour program should produce a single line of output containing the pass/fail booleans for the $5$ test cases as a comma-separated list enclosed in square brackets (e.g., $[r_1,r_2,r_3,r_4,r_5]$), where each $r_i$ is either $True$ or $False$. Angles must be handled in radians. No physical units are required, and all outputs must be unitless real numbers or booleans as specified.", "solution": "The problem is valid as it is scientifically grounded in vector calculus and linear algebra, well-posed with all necessary data and definitions, and objective in its formulation. We will proceed with a solution.\n\n### 1. Theoretical Derivation\n\nThe core of the problem lies in understanding how a velocity vector field transforms under a change of coordinates. Let $x \\in \\mathbb{R}^2$ be the state in the reference (base) coordinate system and $x_b \\in \\mathbb{R}^2$ be the state in the target (batch) coordinate system. The two are related by a differentiable, invertible transport map $T_b$ such that $x_b = T_b(x)$.\n\nThe RNA velocity is defined as the time derivative of the state. A trajectory of a cell in the base space is a path $x(t)$. Its velocity is $v(x) = \\frac{dx}{dt}$. The corresponding trajectory in the batch space is $x_b(t) = T_b(x(t))$. The velocity in the batch space, $v_b(x_b)$, is the time derivative of this path:\n$$ v_b(x_b) = \\frac{d x_b}{dt} = \\frac{d}{dt} T_b(x(t)) $$\nApplying the multivariable chain rule, we get:\n$$ \\frac{d}{dt} T_b(x(t)) = J_{T_b}(x(t)) \\frac{dx}{dt} $$\nwhere $J_{T_b}(x)$ is the Jacobian matrix of the map $T_b$ evaluated at state $x$. Substituting the velocity definitions, we arrive at the fundamental transformation rule for the velocity vectors:\n$$ v_b(x_b) = J_{T_b}(x) v(x) $$\nHere, $v(x)$ is the velocity at the base-space point $x$, and $v_b(x_b)$ is the corresponding velocity at the transformed batch-space point $x_b = T_b(x)$. This is the expression for the **predicted batch-space velocity field**.\n\nTo assess the distortion of the dynamics, we must \"pull back\" an observed batch velocity $v_{b, \\text{obs}}$ to the base space. This requires the inverse relationship. Rearranging the equation above gives:\n$$ v(x) = [J_{T_b}(x)]^{-1} v_b(x_b) $$\nThe term $[J_{T_b}(x)]^{-1}$ is the Jacobian of the inverse transformation, $J_{T_b^{-1}}(x_b)$, evaluated at the point $x_b = T_b(x)$, a result from the inverse function theorem. Therefore, the pulled-back velocity in the base space, which we denote $v_{\\text{base,hat}}$, is given by:\n$$ v_{\\text{base,hat}}(x) = [J_{T_b}(x)]^{-1} v_{b, \\text{obs}}(x_b) $$\nwhere $x = T_b^{-1}(x_b)$.\n\n### 2. Algorithmic Implementation\n\nWe implement a computational procedure that applies these principles to the $5$ test cases.\n\n**Step 1: Setup**\nFirst, we define the base linear dynamics operator $A = \\begin{bmatrix} -1 & 0.5 \\\\ 0 & -0.5 \\end{bmatrix}$. We then generate a regular grid of $21 \\times 21 = 441$ sample points $\\{x^{(i)}\\}$ in the domain $x_1, x_2 \\in [-1, 1]$. For each point $x^{(i)}$, we compute the ground-truth base velocity $v^{(i)} = A x^{(i)}$.\n\n**Step 2: Per-Case Analysis**\nFor each of the $5$ test cases, we perform the following calculations:\n\n**a. Velocity Prediction and Observation:**\n- For a given transport map $T_b$, we first compute its Jacobian $J_{T_b}(x)$.\n- The predicted velocity field in the batch space is computed for each point using the derived rule: $v_{b, \\text{pred}}^{(i)} = J_{T_b}(x^{(i)}) v^{(i)}$.\n- The \"observed\" batch velocity field, $v_{b, \\text{obs}}^{(i)}$, is generated according to the specific rules for each test case, which may involve adding Gaussian noise or using a mismatched transformation.\n\n**b. Alignment Metric Calculation:**\nThe alignment between the predicted field $v_{b, \\text{pred}}$ and the observed field $v_{b, \\text{obs}}$ is quantified by the mean cosine similarity. We filter out any point pair where either velocity vector has a Euclidean norm below $10^{-8}$. For the remaining $N_f$ filtered points, the metric is:\n$$ \\text{alignment} = \\frac{1}{N_f} \\sum_{i=1}^{N_f} \\frac{v_{b, \\text{pred}}^{(i)} \\cdot v_{b, \\text{obs}}^{(i)}}{\\lVert v_{b, \\text{pred}}^{(i)} \\rVert_2 \\lVert v_{b, \\text{obs}}^{(i)} \\rVert_2} $$\nThe case passes the alignment check if this metric is at least $\\tau_{\\text{align}} = 0.97$.\n\n**c. Dynamics Distortion Metric Calculation:**\n- We pull back the observed batch velocities $v_{b, \\text{obs}}^{(i)}$ to the base space to obtain estimates $v_{\\text{base,hat}}^{(i)}$ using the inverse Jacobian evaluated at the corresponding preimages $x^{(i)}$:\n$$ v_{\\text{base,hat}}^{(i)} = [J_{T_b}(x^{(i)})]^{-1} v_{b, \\text{obs}}^{(i)} $$\n- We then seek to find a linear operator $\\hat{A}$ that best explains these pulled-back velocities. This is formulated as an ordinary least squares problem: find $\\hat{A}$ that minimizes the sum of squared errors $\\sum_i \\lVert \\hat{A} x^{(i)} - v_{\\text{base,hat}}^{(i)} \\rVert_2^2$. If we assemble the points $\\{x^{(i)}\\}$ into a matrix $X$ (size $441 \\times 2$) and the velocities $\\{v_{\\text{base,hat}}^{(i)}\\}$ into a matrix $V_{\\text{hat}}$ (size $441 \\times 2$), the solution is given by $\\hat{A}^T = (X^T X)^{-1} X^T V_{\\text{hat}}$.\n- The dynamics distortion is the relative Frobenius norm error between the estimated operator $\\hat{A}$ and the true operator $A$:\n$$ \\text{distortion} = \\frac{\\lVert \\hat{A} - A \\rVert_F}{\\lVert A \\rVert_F} $$\nThe case passes the distortion check if this metric is at most $\\tau_{\\text{distort}} = 0.10$.\n\n**d. Final Verdict:**\nA test case receives a passing grade (True) if and only if it satisfies both the alignment and distortion criteria.\n\n### 3. Case-Specific Jacobians\n\n- **Affine Cases ($1, 2, 3$):** $T_b(x) = Mx + t$. The Jacobian is constant: $J_{T_b}(x) = M$. The inverse Jacobian is simply $M^{-1}$.\n- **Nonlinear Cases ($4, 5$):** $T_b(x) = \\begin{bmatrix} x_1 + \\alpha \\sin(x_1) \\\\ x_2 \\end{bmatrix}$. The Jacobian is position-dependent: $J_{T_b}(x) = \\begin{bmatrix} 1 + \\alpha \\cos(x_1) & 0 \\\\ 0 & 1 \\end{bmatrix}$. The inverse Jacobian is also diagonal: $[J_{T_b}(x)]^{-1} = \\begin{bmatrix} (1 + \\alpha \\cos(x_1))^{-1} & 0 \\\\ 0 & 1 \\end{bmatrix}$.\n\nThis systematic procedure is translated into a Python script to compute the pass/fail booleans for each case.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the RNA velocity batch correction problem for 5 test cases.\n    \"\"\"\n    # Set a seed for reproducibility of noise.\n    np.random.seed(0)\n\n    # --- Problem Setup ---\n    # Base field matrix\n    A = np.array([[-1.0, 0.5], [0.0, -0.5]])\n    norm_A_fro = np.linalg.norm(A, 'fro')\n\n    # Sample points in the base space on a regular grid\n    n_grid_points = 21\n    coords = np.linspace(-1, 1, n_grid_points)\n    x1_grid, x2_grid = np.meshgrid(coords, coords)\n    # Shape of X: (n_grid_points*n_grid_points, 2) i.e., (441, 2)\n    X = np.vstack([x1_grid.ravel(), x2_grid.ravel()]).T\n\n    # Base velocity field at sample points\n    # Shape of V_base: (441, 2)\n    V_base = X @ A.T\n\n    # Thresholds and parameters\n    norm_threshold = 1e-8\n    alignment_threshold = 0.97\n    distortion_threshold = 0.10\n\n    test_cases_params = [\n        # Case 1: Affine, clean\n        {'type': 'affine', 's': 1.2, 'theta': 0.5, 't': np.array([0.1, -0.05]), 'sigma': 0.0, 'mismatch_q': None},\n        # Case 2: Affine, small noise\n        {'type': 'affine', 's': 1.2, 'theta': 0.5, 't': np.array([0.1, -0.05]), 'sigma': 0.02, 'mismatch_q': None},\n        # Case 3: Affine, mismatched dynamics\n        {'type': 'affine', 's': 1.2, 'theta': 0.5, 't': np.array([0.1, -0.05]), 'sigma': 0.0, 'mismatch_q': {'s': 1.2, 'phi': 1.0}},\n        # Case 4: Nonlinear, clean\n        {'type': 'nonlinear', 'alpha': 0.2, 'sigma': 0.0},\n        # Case 5: Nonlinear, high noise\n        {'type': 'nonlinear', 'alpha': 0.2, 'sigma': 0.30}\n    ]\n\n    results = []\n\n    for params in test_cases_params:\n        # --- Field Transformation and Observation Generation ---\n        if params['type'] == 'affine':\n            s, theta, t = params['s'], params['theta'], params['t']\n            R = np.array([[np.cos(theta), -np.sin(theta)], [np.sin(theta), np.cos(theta)]])\n            M = s * R  # Jacobian for the affine map\n\n            # Predicted batch velocities: V_b_pred = J @ V_base\n            V_b_pred = V_base @ M.T\n\n            # Observed batch velocities\n            if params['mismatch_q'] is not None:\n                phi, s_q = params['mismatch_q']['phi'], params['mismatch_q']['s']\n                R_q = np.array([[np.cos(phi), -np.sin(phi)], [np.sin(phi), np.cos(phi)]])\n                Q = s_q * R_q\n                V_b_obs = V_base @ Q.T\n            else:\n                noise = np.random.normal(0, params['sigma'], size=V_b_pred.shape)\n                V_b_obs = V_b_pred + noise\n\n            # Pull back observed velocities for distortion metric: V_base_hat = J_inv @ V_b_obs\n            M_inv = np.linalg.inv(M)\n            V_base_hat = V_b_obs @ M_inv.T\n        \n        elif params['type'] == 'nonlinear':\n            alpha = params['alpha']\n            x1 = X[:, 0]\n\n            # Predicted batch velocities (J @ V_base)\n            # J is diagonal, so we can do this element-wise\n            J_mult_v1 = (1 + alpha * np.cos(x1)) * V_base[:, 0]\n            J_mult_v2 = V_base[:, 1]\n            V_b_pred = np.stack([J_mult_v1, J_mult_v2], axis=1)\n\n            # Observed batch velocities\n            noise = np.random.normal(0, params['sigma'], size=V_b_pred.shape)\n            V_b_obs = V_b_pred + noise\n\n            # Pull back observed velocities (J_inv @ V_b_obs)\n            J_inv_mult_v1 = (1 / (1 + alpha * np.cos(x1))) * V_b_obs[:, 0]\n            J_inv_mult_v2 = V_b_obs[:, 1]\n            V_base_hat = np.stack([J_inv_mult_v1, J_inv_mult_v2], axis=1)\n\n        # --- Metric Calculation ---\n\n        # 1. Alignment Metric (Mean Cosine Similarity)\n        norm_pred = np.linalg.norm(V_b_pred, axis=1)\n        norm_obs = np.linalg.norm(V_b_obs, axis=1)\n        \n        mask = (norm_pred > norm_threshold) & (norm_obs > norm_threshold)\n        \n        dot_product = np.sum(V_b_pred[mask] * V_b_obs[mask], axis=1)\n        cos_sim = dot_product / (norm_pred[mask] * norm_obs[mask])\n        \n        alignment_metric = np.mean(cos_sim) if cos_sim.size > 0 else 1.0\n\n        # 2. Dynamics Distortion Metric\n        # Solve least squares for A_hat: X @ A_hat.T = V_base_hat\n        A_hat_T, _, _, _ = np.linalg.lstsq(X, V_base_hat, rcond=None)\n        A_hat = A_hat_T.T\n        \n        distortion_metric = np.linalg.norm(A_hat - A, 'fro') / norm_A_fro\n\n        # 3. Pass/Fail Decision\n        is_pass = (alignment_metric >= alignment_threshold) and (distortion_metric <= distortion_threshold)\n        results.append(is_pass)\n\n    # Format the final output as a comma-separated list of booleans\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3346371"}]}