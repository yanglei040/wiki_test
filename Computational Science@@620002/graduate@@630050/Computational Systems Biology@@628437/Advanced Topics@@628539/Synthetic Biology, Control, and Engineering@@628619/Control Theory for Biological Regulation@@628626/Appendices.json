{"hands_on_practices": [{"introduction": "Before attempting to control any system, we must answer two fundamental questions: can we influence all of its internal states through our chosen input, and can we deduce all of its internal states by watching its output? This practice introduces the core concepts of controllability and observability using a simple, yet powerful, two-state model of gene expression [@problem_id:3297625]. By applying these foundational principles from linear systems theory, you will gain a concrete understanding of what it means to have full authority over a biological circuit's dynamics.", "problem": "Consider a minimal two-state model of gene expression under mass-action kinetics. Messenger ribonucleic acid (mRNA) is produced at a transcription rate controlled by an external input and degraded with a first-order rate constant, while protein is produced by translation from mRNA and degraded with a first-order rate constant. Protein fluorescence is measured and is proportional to the protein concentration.\n\nLet the states be $x_{1}(t)$ for mRNA concentration and $x_{2}(t)$ for protein concentration. The input is the transcription rate $u(t)$, and the output is fluorescence $y(t)$ proportional to protein concentration. Assume first-order degradation for mRNA and protein with positive rate constants $\\gamma_{m} > 0$ and $\\gamma_{p} > 0$, respectively, a positive translation rate $k_{t} > 0$, and a positive fluorescence gain $c > 0$. The dynamics and measurement are\n$$\n\\frac{d}{dt}\\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix}\n=\n\\begin{pmatrix}\n-\\gamma_{m} & 0 \\\\\nk_{t} & -\\gamma_{p}\n\\end{pmatrix}\n\\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix}\n+\n\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} u(t),\n\\qquad\ny(t) = \\begin{pmatrix} 0 & c \\end{pmatrix} \\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix}.\n$$\n\nUsing the definitions of controllability and observability for Linear Time-Invariant (LTI) systems, compute the ranks of the controllability and observability matrices of this system in terms of the parameters, and determine whether the system is controllable and observable under the stated conditions. Provide a brief biological interpretation of your result.\n\nExpress your final answer as a row matrix with two entries, where the first entry is the rank of the controllability matrix and the second entry is the rank of the observability matrix. No rounding is required.", "solution": "The problem presents a linear time-invariant (LTI) state-space model for gene expression. The state vector is $x(t) = \\begin{pmatrix} x_{1}(t) \\\\ x_{2}(t) \\end{pmatrix}$, where $x_{1}(t)$ is the mRNA concentration and $x_{2}(t)$ is the protein concentration. The system is described by the equations:\n$$ \\frac{dx}{dt} = Ax + Bu, \\quad y = Cx $$\nwhere the matrices $A$, $B$, and $C$ are given by:\n$$ A = \\begin{pmatrix} -\\gamma_{m} & 0 \\\\ k_{t} & -\\gamma_{p} \\end{pmatrix}, \\quad B = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad C = \\begin{pmatrix} 0 & c \\end{pmatrix} $$\nThe parameters $\\gamma_{m}$, $\\gamma_{p}$, $k_{t}$, and $c$ are all strictly positive constants. The dimension of the state space is $n=2$.\n\nFirst, we will analyze the controllability of the system. A system is controllable if and only if its controllability matrix, $\\mathcal{C}$, has full rank. For a system of dimension $n$, the rank must be equal to $n$. Here, $n=2$. The controllability matrix is constructed as:\n$$ \\mathcal{C} = \\begin{pmatrix} B & AB & \\dots & A^{n-1}B \\end{pmatrix} $$\nFor this second-order system ($n=2$), the controllability matrix is $\\mathcal{C} = \\begin{pmatrix} B & AB \\end{pmatrix}$. We must compute the product $AB$:\n$$ AB = \\begin{pmatrix} -\\gamma_{m} & 0 \\\\ k_{t} & -\\gamma_{p} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} (-\\gamma_{m})(1) + (0)(0) \\\\ (k_{t})(1) + (-\\gamma_{p})(0) \\end{pmatrix} = \\begin{pmatrix} -\\gamma_{m} \\\\ k_{t} \\end{pmatrix} $$\nNow, we can construct the controllability matrix $\\mathcal{C}$:\n$$ \\mathcal{C} = \\begin{pmatrix} B & AB \\end{pmatrix} = \\begin{pmatrix} 1 & -\\gamma_{m} \\\\ 0 & k_{t} \\end{pmatrix} $$\nThe rank of $\\mathcal{C}$ is determined by its determinant. A $2 \\times 2$ matrix has full rank ($2$) if and only if its determinant is non-zero.\n$$ \\det(\\mathcal{C}) = (1)(k_{t}) - (-\\gamma_{m})(0) = k_{t} $$\nAccording to the problem statement, the translation rate $k_{t}$ is positive, i.e., $k_{t} > 0$. Since $\\det(\\mathcal{C}) = k_{t} \\neq 0$, the matrix $\\mathcal{C}$ has full rank. Therefore, the rank of the controllability matrix is $2$. This means the system is fully controllable.\n\nNext, we will analyze the observability of the system. A system is observable if and only if its observability matrix, $\\mathcal{O}$, has full rank, which is $n=2$ in this case. The observability matrix is constructed as:\n$$ \\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\\\ \\vdots \\\\ CA^{n-1} \\end{pmatrix} $$\nFor this second-order system ($n=2$), the observability matrix is $\\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix}$. We must compute the product $CA$:\n$$ CA = \\begin{pmatrix} 0 & c \\end{pmatrix} \\begin{pmatrix} -\\gamma_{m} & 0 \\\\ k_{t} & -\\gamma_{p} \\end{pmatrix} = \\begin{pmatrix} (0)(-\\gamma_{m}) + (c)(k_{t}) & (0)(0) + (c)(-\\gamma_{p}) \\end{pmatrix} = \\begin{pmatrix} c k_{t} & -c \\gamma_{p} \\end{pmatrix} $$\nNow, we can construct the observability matrix $\\mathcal{O}$:\n$$ \\mathcal{O} = \\begin{pmatrix} C \\\\ CA \\end{pmatrix} = \\begin{pmatrix} 0 & c \\\\ c k_{t} & -c \\gamma_{p} \\end{pmatrix} $$\nThe rank of $\\mathcal{O}$ is determined by its determinant.\n$$ \\det(\\mathcal{O}) = (0)(-c \\gamma_{p}) - (c)(c k_{t}) = -c^{2}k_{t} $$\nThe problem states that the fluorescence gain $c > 0$ and the translation rate $k_{t} > 0$. Thus, $c^{2} > 0$ and their product $c^{2}k_{t}$ is strictly positive. Consequently, $\\det(\\mathcal{O}) = -c^{2}k_{t} \\neq 0$. This indicates that the matrix $\\mathcal{O}$ has full rank. Therefore, the rank of the observability matrix is $2$. This means the system is fully observable.\n\nThe biological interpretation of these results is as follows:\nControllability (Rank = $2$): The system being fully controllable means that by manipulating the transcription rate $u(t)$, it is possible to drive the concentrations of both mRNA ($x_{1}$) and protein ($x_{2}$) from any initial state to any desired final state within a finite time. The input $u(t)$ directly influences the rate of change of mRNA. Because there is a non-zero translation rate ($k_{t} > 0$), the control authority over the mRNA state is passed on to the protein state. If $k_{t}$ were zero, the protein level would be independent of the input, and the system would not be controllable as we could not influence $x_{2}$.\n\nObservability (Rank = $2$): The system being fully observable means that by measuring the fluorescence output $y(t)$ over time, it is possible to uniquely determine the initial state of the system, i.e., the initial concentrations of both mRNA ($x_{1}(0)$) and protein ($x_{2}(0)$). We directly measure protein concentration (as $y(t) = cx_{2}(t)$ and $c > 0$). The dynamics of the protein level depend on the mRNA level through the term $k_{t}x_{1}$. Since $k_{t} > 0$, the time evolution of the measured protein concentration inherently contains information about the unmeasured mRNA concentration, allowing for its reconstruction. If either $k_{t}$ or $c$ were zero, information about the mRNA state would be lost, and the system would not be observable.\n\nIn summary, the rank of the controllability matrix is $2$, and the rank of the observability matrix is $2$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 2 & 2 \\end{pmatrix}}\n$$", "id": "3297625"}, {"introduction": "Feedback is a ubiquitous design principle in biology, essential for homeostasis and robust decision-making, but it comes with a critical challenge: the potential for instability. This exercise delves into the stability analysis of a genetic feedback loop, a common motif in cellular regulation [@problem_id:3297620]. You will use the Routh-Hurwitz criterion, a classic and powerful tool from control theory, to analytically determine the maximum allowable strength of a positive feedback loop before the system loses stability.", "problem": "Consider a three-species regulatory module in a cell comprising messenger ribonucleic acid (mRNA), enzyme (protein), and a downstream metabolite. Near a steady state, linearization of the mass-action ordinary differential equation (ODE) model yields a linear time-invariant (LTI) system for deviations $\\mathbf{x}(t) = (x_{1}(t), x_{2}(t), x_{3}(t))^{\\top}$ of the form $\\dot{\\mathbf{x}}(t) = A \\mathbf{x}(t)$, with Jacobian\n$$\nA \\;=\\;\n\\begin{pmatrix}\n-\\gamma_{m} & 0 & g \\\\\n\\alpha & -\\gamma_{p} & 0 \\\\\n0 & \\nu & -\\gamma_{x}\n\\end{pmatrix},\n$$\nwhere $\\gamma_{m} > 0$, $\\gamma_{p} > 0$, and $\\gamma_{x} > 0$ are first-order degradation (or dilution) rates for mRNA, protein, and metabolite, respectively; $\\alpha > 0$ is the translation coupling rate from mRNA to protein; $\\nu > 0$ is the catalytic rate by which protein influences metabolite; and $g \\ge 0$ is the effective linearized strength of a positive transcriptional feedback of the metabolite onto mRNA synthesis. Each parameter has units of inverse time $\\mathrm{s}^{-1}$. Assume all parameters are constant and positive, and that the linearization is valid in the neighborhood of the steady state.\n\nStarting from first principles of linearized dynamics and using the Routh–Hurwitz criterion for third-order polynomials, determine the exact closed-form expression for the largest admissible positive feedback strength $g_{\\max}$ (in $\\mathrm{s}^{-1}$) in terms of $\\gamma_{m}$, $\\gamma_{p}$, $\\gamma_{x}$, $\\alpha$, and $\\nu$ that guarantees the linearized system is asymptotically stable (all eigenvalues of $A$ have strictly negative real parts). Express your final answer as a symbolic formula. No numerical evaluation is required, and no rounding is needed. Use $\\mathrm{s}^{-1}$ as the unit for $g_{\\max}$.", "solution": "The problem requires finding the maximum positive feedback strength, denoted as $g_{\\max}$, for which the given linear time-invariant (LTI) system remains asymptotically stable. The system dynamics are described by the ordinary differential equation (ODE) $\\dot{\\mathbf{x}}(t) = A \\mathbf{x}(t)$, where the Jacobian matrix is\n$$\nA \\;=\\;\n\\begin{pmatrix}\n-\\gamma_{m} & 0 & g \\\\\n\\alpha & -\\gamma_{p} & 0 \\\\\n0 & \\nu & -\\gamma_{x}\n\\end{pmatrix}\n$$\nThe parameters $\\gamma_{m}, \\gamma_{p}, \\gamma_{x}, \\alpha, \\nu$ are all strictly positive constants, and the feedback strength $g$ is non-negative, i.e., $g \\ge 0$.\n\nFor the system to be asymptotically stable, all eigenvalues of the matrix $A$ must have strictly negative real parts. The eigenvalues, denoted by $\\lambda$, are the roots of the characteristic equation, which is given by $\\det(A - \\lambda I) = 0$, where $I$ is the $3 \\times 3$ identity matrix.\n\nLet us first compute the characteristic polynomial $P(\\lambda) = \\det(A - \\lambda I)$:\n$$\nP(\\lambda) \\;=\\; \\det\n\\begin{pmatrix}\n-\\gamma_{m} - \\lambda & 0 & g \\\\\n\\alpha & -\\gamma_{p} - \\lambda & 0 \\\\\n0 & \\nu & -\\gamma_{x} - \\lambda\n\\end{pmatrix}\n$$\nExpanding the determinant along the first row gives:\n$$\nP(\\lambda) \\;=\\; (-\\gamma_{m} - \\lambda) \\begin{vmatrix} -\\gamma_{p} - \\lambda & 0 \\\\ \\nu & -\\gamma_{x} - \\lambda \\end{vmatrix} - (0) \\begin{vmatrix} \\alpha & 0 \\\\ 0 & -\\gamma_{x} - \\lambda \\end{vmatrix} + g \\begin{vmatrix} \\alpha & -\\gamma_{p} - \\lambda \\\\ 0 & \\nu \\end{vmatrix}\n$$\n$$\nP(\\lambda) \\;=\\; -(\\lambda + \\gamma_{m}) [(\\lambda + \\gamma_{p})(\\lambda + \\gamma_{x})] + g(\\alpha\\nu)\n$$\n$$\nP(\\lambda) \\;=\\; -(\\lambda + \\gamma_{m}) [\\lambda^2 + (\\gamma_{p} + \\gamma_{x})\\lambda + \\gamma_{p}\\gamma_{x}] + \\alpha\\nu g\n$$\nExpanding this further:\n$$\nP(\\lambda) \\;=\\; -[\\lambda^3 + (\\gamma_{p} + \\gamma_{x})\\lambda^2 + \\gamma_{p}\\gamma_{x}\\lambda + \\gamma_{m}\\lambda^2 + \\gamma_{m}(\\gamma_{p} + \\gamma_{x})\\lambda + \\gamma_{m}\\gamma_{p}\\gamma_{x}] + \\alpha\\nu g\n$$\n$$\nP(\\lambda) \\;=\\; -[\\lambda^3 + (\\gamma_{m} + \\gamma_{p} + \\gamma_{x})\\lambda^2 + (\\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x})\\lambda + \\gamma_{m}\\gamma_{p}\\gamma_{x}] + \\alpha\\nu g\n$$\nThe characteristic equation $P(\\lambda) = 0$ is conventionally written with a leading coefficient of $1$:\n$$\n\\lambda^3 + (\\gamma_{m} + \\gamma_{p} + \\gamma_{x})\\lambda^2 + (\\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x})\\lambda + (\\gamma_{m}\\gamma_{p}\\gamma_x - \\alpha\\nu g) = 0\n$$\nThis is a third-order polynomial of the form $a_3 \\lambda^3 + a_2 \\lambda^2 + a_1 \\lambda + a_0 = 0$, with coefficients:\n- $a_3 = 1$\n- $a_2 = \\gamma_{m} + \\gamma_{p} + \\gamma_{x}$\n- $a_1 = \\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x}$\n- $a_0 = \\gamma_{m}\\gamma_{p}\\gamma_x - \\alpha\\nu g$\n\nTo guarantee asymptotic stability, the Routh-Hurwitz criterion must be satisfied. For a third-order polynomial, the necessary and sufficient conditions are:\n1. $a_3 > 0$\n2. $a_2 > 0$\n3. $a_1 > 0$\n4. $a_0 > 0$\n5. $a_2 a_1 - a_3 a_0 > 0$\n\nLet us examine each condition based on the given parameters:\n1. $a_3 = 1 > 0$. This condition is satisfied.\n2. $a_2 = \\gamma_{m} + \\gamma_{p} + \\gamma_{x}$. Since $\\gamma_{m} > 0$, $\\gamma_{p} > 0$, and $\\gamma_{x} > 0$, their sum is strictly positive. Thus, $a_2 > 0$ is satisfied.\n3. $a_1 = \\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x}$. As all $\\gamma$ parameters are positive, each term in the sum is positive. Thus, $a_1 > 0$ is satisfied.\n4. $a_0 = \\gamma_{m}\\gamma_{p}\\gamma_x - \\alpha\\nu g > 0$. This condition imposes a constraint on $g$. Since $\\alpha > 0$ and $\\nu > 0$, we can solve for $g$:\n$$\n\\alpha\\nu g < \\gamma_{m}\\gamma_{p}\\gamma_{x} \\quad \\implies \\quad g < \\frac{\\gamma_{m}\\gamma_{p}\\gamma_{x}}{\\alpha\\nu}\n$$\n5. $a_2 a_1 - a_3 a_0 > 0$. Substituting the coefficients and $a_3 = 1$:\n$$\n(\\gamma_{m} + \\gamma_{p} + \\gamma_{x})(\\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x}) - (\\gamma_{m}\\gamma_{p}\\gamma_x - \\alpha\\nu g) > 0\n$$\nLet's analyze the product $a_2 a_1$:\n$$\na_2 a_1 = (\\gamma_{m} + \\gamma_{p} + \\gamma_{x})(\\gamma_{m}\\gamma_{p} + \\gamma_{m}\\gamma_{x} + \\gamma_{p}\\gamma_{x})\n$$\nThis expansion yields:\n$$\na_2 a_1 = (\\gamma_m^2\\gamma_p + \\gamma_m\\gamma_p^2) + (\\gamma_m^2\\gamma_x + \\gamma_m\\gamma_x^2) + (\\gamma_p^2\\gamma_x + \\gamma_p\\gamma_x^2) + 3\\gamma_m\\gamma_p\\gamma_x\n$$\nSubstituting this back into the inequality:\n$$\n[(\\gamma_m^2\\gamma_p + \\gamma_m\\gamma_p^2) + \\dots + 3\\gamma_m\\gamma_p\\gamma_x] - \\gamma_{m}\\gamma_{p}\\gamma_x + \\alpha\\nu g > 0\n$$\n$$\n(\\gamma_m^2\\gamma_p + \\gamma_m\\gamma_p^2) + (\\gamma_m^2\\gamma_x + \\gamma_m\\gamma_x^2) + (\\gamma_p^2\\gamma_x + \\gamma_p\\gamma_x^2) + 2\\gamma_m\\gamma_p\\gamma_x + \\alpha\\nu g > 0\n$$\nThe problem states that $\\gamma_m, \\gamma_p, \\gamma_x, \\alpha, \\nu$ are all positive and $g \\ge 0$. Every term in the expression on the left-hand side is therefore non-negative. In fact, the terms involving only $\\gamma$ parameters are strictly positive. The term $\\alpha\\nu g$ is non-negative. Consequently, the sum is strictly positive for any $g \\ge 0$. This means the condition $a_2 a_1 - a_3 a_0 > 0$ is always satisfied for any physically permissible value of $g$.\n\nTherefore, the only condition that constrains the value of $g$ for stability is $a_0 > 0$. For the system to be asymptotically stable, $g$ must satisfy:\n$$\ng < \\frac{\\gamma_{m}\\gamma_{p}\\gamma_{x}}{\\alpha\\nu}\n$$\nThe problem asks for the largest admissible positive feedback strength $g_{\\max}$ that *guarantees* asymptotic stability. This corresponds to the supremum of the interval of values of $g$ for which the system is stable. At the boundary $g = \\frac{\\gamma_{m}\\gamma_{p}\\gamma_{x}}{\\alpha\\nu}$, we have $a_0 = 0$, leading to one eigenvalue being $\\lambda=0$. This renders the system stable in the sense of Lyapunov, but not asymptotically stable. Thus, the strict inequality defines the region of asymptotic stability. The largest admissible value, or the stability boundary, is the supremum.\n\n$$\ng_{\\max} = \\frac{\\gamma_{m}\\gamma_{p}\\gamma_{x}}{\\alpha\\nu}\n$$\nThis expression provides the exact closed-form symbolic formula for the maximum feedback strength.\nThe units of $g_{\\max}$ are $(\\mathrm{s}^{-1} \\cdot \\mathrm{s}^{-1} \\cdot \\mathrm{s}^{-1}) / (\\mathrm{s}^{-1} \\cdot \\mathrm{s}^{-1}) = \\mathrm{s}^{-1}$, which is consistent with the problem statement.", "answer": "$$\n\\boxed{\\frac{\\gamma_{m}\\gamma_{p}\\gamma_{x}}{\\alpha\\nu}}\n$$", "id": "3297620"}, {"introduction": "This final practice integrates our journey from analysis to design, culminating in a challenge to build a complete, high-performance control system for a noisy gene circuit [@problem_id:3297551]. You will implement a Linear-Quadratic-Gaussian (LQG) controller, the gold standard for optimal control of linear systems subject to noise. This involves the dual task of designing a Kalman filter to estimate hidden states from noisy measurements and an LQR controller to regulate the system optimally, providing a powerful demonstration of how control engineering can tame biological stochasticity.", "problem": "You are given a linearized two-state gene expression circuit with process noise and a protein-only measurement corrupted by measurement shot noise. The macroscopic dynamics represent coupled birth–death processes for messenger RNA and protein, linearized around a steady operating point derived from the Central Dogma of molecular biology (deoxyribonucleic acid to messenger ribonucleic acid to protein), with intrinsic molecular fluctuations modeled by a Gaussian approximation to the Chemical Master Equation. The state vector is $x(t) \\in \\mathbb{R}^2$ with components $x_1(t)$ (messenger ribonucleic acid) and $x_2(t)$ (protein). The continuous-time linear time-invariant state equations are\n$$\n\\dot{x}(t) = A x(t) + B u(t) + w(t),\n$$\n$$\ny(t) = C x(t) + v(t),\n$$\nwhere the input $u(t) \\in \\mathbb{R}$ modulates transcription, the measured output $y(t) \\in \\mathbb{R}$ is the protein count, $w(t)$ is zero-mean Gaussian process noise with covariance matrix $Q$, and $v(t)$ is zero-mean Gaussian measurement noise with covariance matrix $R$. The measurement shot noise arises from photon counting or molecular shot noise and is approximated by a Gaussian with variance proportional to the operating protein mean. Linearization at the operating point sets $R$ to a constant positive value equal to a proportionality factor times the operating mean.\n\nThe system matrices have the structure\n$$\nA = \\begin{bmatrix} -\\gamma_m & 0 \\\\ k_p & -\\gamma_p \\end{bmatrix}, \\quad\nB = \\begin{bmatrix} k_m \\\\ 0 \\end{bmatrix}, \\quad\nC = \\begin{bmatrix} 0 & 1 \\end{bmatrix},\n$$\nwhere $\\gamma_m > 0$ and $\\gamma_p > 0$ are messenger ribonucleic acid and protein first-order degradation rates, respectively, $k_p > 0$ is the translation gain (protein synthesized per messenger ribonucleic acid per unit time), and $k_m > 0$ is the transcription actuation gain.\n\nYour tasks for each parameter set in the test suite are:\n1. Design a continuous-time Linear Quadratic Regulator (LQR) state-feedback law $u(t) = -K x(t)$ that minimizes the quadratic cost\n$$\nJ = \\int_0^\\infty \\left( x(t)^\\top W x(t) + u(t)^\\top U u(t) \\right) \\, dt,\n$$\nfor a given positive semidefinite state-weight matrix $W \\in \\mathbb{R}^{2 \\times 2}$ and positive definite control-weight matrix $U \\in \\mathbb{R}^{1 \\times 1}$. The optimal gain $K \\in \\mathbb{R}^{1 \\times 2}$ is obtained by solving the continuous-time Algebraic Riccati Equation for the regulator.\n\n2. Design the steady-state Kalman filter gain $L \\in \\mathbb{R}^{2 \\times 1}$ for the estimator\n$$\n\\dot{\\hat{x}}(t) = A \\hat{x}(t) + B u(t) + L \\big(y(t) - C \\hat{x}(t)\\big),\n$$\nby solving the continuous-time Algebraic Riccati Equation for the estimator with the given $Q$ and $R$.\n\n3. Demonstrate the separation principle by checking that the eigenvalues of the augmented estimator-based closed-loop system equal the union of the eigenvalues of the regulator closed-loop matrix and the estimator error matrix. Define the augmented dynamics for the actual state $x(t)$ and the estimation error $e(t) = x(t) - \\hat{x}(t)$:\n$$\n\\frac{d}{dt} \\begin{bmatrix} x \\\\ e \\end{bmatrix} =\n\\underbrace{\\begin{bmatrix}\nA - B K & B K \\\\\n0 & A - L C\n\\end{bmatrix}}_{A_{\\mathrm{aug}}}\n\\begin{bmatrix} x \\\\ e \\end{bmatrix}\n+\n\\underbrace{\\begin{bmatrix} I \\\\ I \\end{bmatrix}}_{\\text{process injection}} w\n-\n\\underbrace{\\begin{bmatrix} 0 \\\\ L \\end{bmatrix}}_{\\text{measurement injection}} v,\n$$\nand verify numerically that the spectrum of $A_{\\mathrm{aug}}$ equals the combined spectra of $A - B K$ and $A - L C$ to within a specified absolute tolerance of $10^{-7}$.\n\n4. Compute the steady-state open-loop state covariance $P_{\\mathrm{ol}} \\in \\mathbb{R}^{2 \\times 2}$ by solving the Lyapunov equation\n$$\nA P_{\\mathrm{ol}} + P_{\\mathrm{ol}} A^\\top + Q = 0.\n$$\n\n5. Compute the steady-state closed-loop covariance of the actual state under output-feedback control $u(t) = -K \\hat{x}(t)$ using the augmented formulation and the associated stationary covariance $P_{\\mathrm{aug}} \\in \\mathbb{R}^{4 \\times 4}$ via the Lyapunov equation\n$$\nA_{\\mathrm{aug}} P_{\\mathrm{aug}} + P_{\\mathrm{aug}} A_{\\mathrm{aug}}^\\top + S = 0,\n$$\nwhere the joint noise covariance is\n$$\nS = \\mathop{\\mathrm{Cov}}\\!\\left(\n\\begin{bmatrix} w \\\\ w - L v \\end{bmatrix}\n\\right) =\n\\begin{bmatrix}\nQ & Q \\\\\nQ & Q + L R L^\\top\n\\end{bmatrix}.\n$$\nExtract the upper-left block $P_{xx} \\in \\mathbb{R}^{2 \\times 2}$ of $P_{\\mathrm{aug}}$ that corresponds to the actual state covariance under output feedback.\n\n6. Compute the ratio\n$$\nr = \\frac{\\mathrm{trace}(P_{xx})}{\\mathrm{trace}(P_{\\mathrm{ol}})},\n$$\nwhich compares the closed-loop variance to the open-loop variance. This ratio is dimensionless; no physical units are required.\n\nTest suite and numerical data:\n- For each test case, parameters are given as tuples $(\\gamma_m, \\gamma_p, k_p, k_m, Q_{11}, Q_{22}, p_{\\mathrm{bar}}, s, W_{11}, W_{22}, U)$, where $Q = \\mathrm{diag}(Q_{11}, Q_{22})$, $R = s \\cdot p_{\\mathrm{bar}}$ (scalar), and $W = \\mathrm{diag}(W_{11}, W_{22})$.\n- Use the following three test cases:\n  1. $(0.2, 0.05, 5.0, 1.0, 0.05, 0.2, 800.0, 1.0, 1.0, 1.0, 0.5)$\n  2. $(0.2, 0.05, 5.0, 1.0, 0.05, 0.2, 800.0, 25.0, 1.0, 1.0, 0.5)$\n  3. $(0.15, 0.01, 8.0, 0.7, 0.08, 0.5, 1200.0, 1.0, 1.0, 1.0, 0.3)$\n\nFinal output specification:\n- For each test case, compute two values: a boolean indicating whether the separation principle spectrum check passes within the $10^{-7}$ tolerance, and the variance ratio $r$ as a floating-point number rounded to six decimal places.\n- Aggregate the results for all test cases into a single list in the order $[\\text{bool}_1, r_1, \\text{bool}_2, r_2, \\text{bool}_3, r_3]$.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, for example, $[\\mathrm{True},0.123456,\\mathrm{True},0.234567,\\mathrm{True},0.345678]$.\n- Angles are not involved in this problem. If any intermediate eigenvalue comparisons are needed, use radians internally. No physical units are required in the final output.", "solution": "We begin from a standard linear noise approximation for birth–death gene expression dynamics. At the macroscopic level, linearization around a steady operating point gives a linear time-invariant system with state $x(t) \\in \\mathbb{R}^2$ (messenger ribonucleic acid and protein), input $u(t) \\in \\mathbb{R}$ (transcription modulation), and measurement $y(t) \\in \\mathbb{R}$ (protein count). Intrinsic molecular fluctuations are approximated by zero-mean Gaussian white process noise $w(t)$ with covariance matrix $Q \\succeq 0$. Measurement shot noise, arising from counting statistics (Poisson-like), can be approximated near the operating point by a Gaussian noise $v(t)$ with variance $R = s \\, p_{\\mathrm{bar}} > 0$, where $p_{\\mathrm{bar}}$ is the operating protein mean and $s$ is a proportionality factor that models a Fano-like scaling.\n\nThe plant and measurement matrices are\n$$\nA = \\begin{bmatrix} -\\gamma_m & 0 \\\\ k_p & -\\gamma_p \\end{bmatrix}, \\quad\nB = \\begin{bmatrix} k_m \\\\ 0 \\end{bmatrix}, \\quad\nC = \\begin{bmatrix} 0 & 1 \\end{bmatrix}.\n$$\nGiven $W \\succeq 0$ and $U \\succ 0$, the Linear Quadratic Regulator (LQR) problem seeks $u(t) = -K x(t)$ that minimizes the cost $J = \\int_0^\\infty x^\\top W x + u^\\top U u \\, dt$. From Bellman’s principle of optimality (Hamilton–Jacobi–Bellman framework), the optimal state-feedback gain $K$ is\n$$\nK = U^{-1} B^\\top P,\n$$\nwhere $P \\succeq 0$ solves the continuous-time Algebraic Riccati Equation (ARE)\n$$\nA^\\top P + P A - P B U^{-1} B^\\top P + W = 0.\n$$\nThis ensures that $A - B K$ is Hurwitz (all eigenvalues strictly in the left half-plane) under standard stabilizability assumptions, which are satisfied here because $(A,B)$ is controllable for $k_p k_m \\neq 0$.\n\nFor state estimation, the steady-state Kalman filter is optimal among linear filters under Gaussian assumptions. The filter takes the form\n$$\n\\dot{\\hat{x}} = A \\hat{x} + B u + L \\big(y - C \\hat{x}\\big).\n$$\nFrom least squares and innovation process derivations, the steady-state error covariance $S \\succeq 0$ solves the dual ARE\n$$\nA S + S A^\\top - S C^\\top R^{-1} C S + Q = 0,\n$$\nand the Kalman gain is\n$$\nL = S C^\\top R^{-1}.\n$$\nUnder detectability of $(A,C)$, which holds for $k_p \\neq 0$, the matrix $A - L C$ is Hurwitz.\n\nSeparation principle. For output-feedback control $u = -K \\hat{x}$, consider the augmented state composed of the actual state $x$ and estimation error $e = x - \\hat{x}$. Using the plant and estimator dynamics,\n$$\n\\dot{x} = A x + B u + w = (A - B K) x + B K e + w,\n$$\n$$\n\\dot{e} = \\dot{x} - \\dot{\\hat{x}} = A x + B u + w - \\left( A \\hat{x} + B u + L (C x + v - C \\hat{x}) \\right) = (A - L C) e + w - L v.\n$$\nThis yields the augmented system\n$$\n\\frac{d}{dt} \\begin{bmatrix} x \\\\ e \\end{bmatrix} =\n\\underbrace{\\begin{bmatrix}\nA - B K & B K \\\\\n0 & A - L C\n\\end{bmatrix}}_{A_{\\mathrm{aug}}}\n\\begin{bmatrix} x \\\\ e \\end{bmatrix}\n+\n\\begin{bmatrix} I \\\\ I \\end{bmatrix} w\n-\n\\begin{bmatrix} 0 \\\\ L \\end{bmatrix} v.\n$$\nBecause $A_{\\mathrm{aug}}$ is block upper-triangular, its eigenvalues are precisely the union of the eigenvalues of $A - B K$ and $A - L C$. Numerically, we verify this by computing the spectra and matching them within an absolute tolerance of $10^{-7}$.\n\nStationary covariances. The open-loop steady-state covariance of the actual state $x$ is given by the unique solution $P_{\\mathrm{ol}}$ of\n$$\nA P_{\\mathrm{ol}} + P_{\\mathrm{ol}} A^\\top + Q = 0,\n$$\nwhich exists because $A$ is Hurwitz for $\\gamma_m > 0$ and $\\gamma_p > 0$. For the closed-loop estimator-based control, define the augmented noise vector $\\eta = \\begin{bmatrix} w \\\\ w - L v \\end{bmatrix}$ with covariance\n$$\nS = \\mathop{\\mathrm{Cov}}(\\eta) =\n\\begin{bmatrix}\nQ & Q \\\\\nQ & Q + L R L^\\top\n\\end{bmatrix},\n$$\nusing independence of $w$ and $v$ and the fact that $\\mathop{\\mathrm{Cov}}(w,w) = Q$, $\\mathop{\\mathrm{Cov}}(w,v) = 0$, and $\\mathop{\\mathrm{Cov}}(v,v) = R$. The stationary augmented covariance $P_{\\mathrm{aug}}$ satisfies\n$$\nA_{\\mathrm{aug}} P_{\\mathrm{aug}} + P_{\\mathrm{aug}} A_{\\mathrm{aug}}^\\top + S = 0,\n$$\ngiven that $A_{\\mathrm{aug}}$ is Hurwitz (which follows from the stability of both $A - B K$ and $A - L C$). Partition $P_{\\mathrm{aug}}$ as\n$$\nP_{\\mathrm{aug}} = \\begin{bmatrix} P_{xx} & P_{xe} \\\\ P_{ex} & P_{ee} \\end{bmatrix},\n$$\nand extract $P_{xx}$ as the closed-loop actual state covariance under output feedback. The variance reduction is quantified by\n$$\nr = \\frac{\\mathrm{trace}(P_{xx})}{\\mathrm{trace}(P_{\\mathrm{ol}})}.\n$$\nA value $r < 1$ indicates that estimator-based feedback reduces the overall state variance compared to the open-loop.\n\nAlgorithmic realization. For each test case:\n1. Assemble $A$, $B$, $C$, $Q = \\mathrm{diag}(Q_{11}, Q_{22})$, $W = \\mathrm{diag}(W_{11}, W_{22})$, and $U$ (scalar), and compute $R = s \\, p_{\\mathrm{bar}}$.\n2. Solve the regulator ARE for $P$ and compute $K = U^{-1} B^\\top P$.\n3. Solve the estimator ARE for $S$ and compute $L = S C^\\top R^{-1}$.\n4. Form $A_{\\mathrm{aug}}$, compute its eigenvalues, and verify spectral equality with the union of spectra of $A - B K$ and $A - L C$ within $10^{-7}$ absolute tolerance to produce a boolean result.\n5. Solve the open-loop Lyapunov equation for $P_{\\mathrm{ol}}$.\n6. Construct the augmented noise covariance $S$, solve the augmented Lyapunov equation for $P_{\\mathrm{aug}}$, extract $P_{xx}$, and compute $r = \\mathrm{trace}(P_{xx}) / \\mathrm{trace}(P_{\\mathrm{ol}})$.\n7. Round $r$ to six decimal places and output the boolean and the float as specified.\n\nThe provided program implements these steps using reliable linear algebra solvers for Riccati and Lyapunov equations. The final output is a single line containing the list $[\\text{bool}_1, r_1, \\text{bool}_2, r_2, \\text{bool}_3, r_3]$, where each boolean reflects the verified separation principle and each float is the variance ratio for the corresponding test case.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import solve_continuous_are, solve_continuous_lyapunov, eigvals\n\ndef lqr_gain(A, B, W, U):\n    # Solve continuous-time ARE: A^T P + P A - P B U^{-1} B^T P + W = 0\n    P = solve_continuous_are(A, B, W, U)\n    # K = U^{-1} B^T P\n    K = np.linalg.solve(U, B.T @ P)\n    return K, P\n\ndef kalman_gain(A, C, Q, R):\n    # Solve dual ARE for estimator: A^T S + S A - S C^T R^{-1} C S + Q = 0\n    # Using solve_continuous_are with (A^T, C^T, Q, R)\n    S = solve_continuous_are(A.T, C.T, Q, R)\n    # L = S C^T R^{-1}\n    R_inv = np.linalg.inv(R)\n    L = S @ C.T @ R_inv\n    return L, S\n\ndef open_loop_covariance(A, Q):\n    # Solve A P + P A^T + Q = 0  -> P = solve_continuous_lyapunov(A, -Q)\n    P_ol = solve_continuous_lyapunov(A, -Q)\n    return P_ol\n\ndef closed_loop_covariance(A, B, C, K, L, Q, R):\n    # Build augmented A matrix for [x; e]\n    n = A.shape[0]\n    A_cl = A - B @ K\n    A_e = A - L @ C\n    A_aug = np.block([\n        [A_cl,          B @ K],\n        [np.zeros_like(A), A_e]\n    ])\n    # Build augmented noise covariance S for [w; w - L v]\n    LRLT = L @ R @ L.T\n    S_aug = np.block([\n        [Q,    Q],\n        [Q,    Q + LRLT]\n    ])\n    # Solve augmented Lyapunov: A_aug P + P A_aug^T + S_aug = 0\n    P_aug = solve_continuous_lyapunov(A_aug, -S_aug)\n    # Extract P_xx (upper-left block)\n    n2 = n\n    P_xx = P_aug[:n2, :n2]\n    return P_xx, P_aug, A_aug\n\ndef separation_principle_ok(A, B, C, K, L, tol=1e-7):\n    A_cl = A - B @ K\n    A_e  = A - L @ C\n    A_aug = np.block([\n        [A_cl,          B @ K],\n        [np.zeros_like(A), A_e]\n    ])\n    eig_aug = eigvals(A_aug)\n    eig_combined = np.concatenate([eigvals(A_cl), eigvals(A_e)])\n    # Greedy matching within tolerance\n    unmatched = list(eig_aug)\n    used = [False] * len(unmatched)\n    for lam in eig_combined:\n        # Find closest in unmatched\n        diffs = [abs(lam - mu) if not used[j] else np.inf for j, mu in enumerate(unmatched)]\n        jmin = int(np.argmin(diffs))\n        if diffs[jmin] > tol:\n            return False\n        used[jmin] = True\n    # Also ensure no extra eigenvalues beyond those matched (lengths equal)\n    return True\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (gamma_m, gamma_p, k_p, k_m, Q11, Q22, p_bar, s, W11, W22, U_scalar)\n    test_cases = [\n        (0.2, 0.05, 5.0, 1.0, 0.05, 0.2, 800.0, 1.0, 1.0, 1.0, 0.5),\n        (0.2, 0.05, 5.0, 1.0, 0.05, 0.2, 800.0, 25.0, 1.0, 1.0, 0.5),\n        (0.15, 0.01, 8.0, 0.7, 0.08, 0.5, 1200.0, 1.0, 1.0, 1.0, 0.3),\n    ]\n\n    results = []\n    for case in test_cases:\n        gamma_m, gamma_p, k_p, k_m, Q11, Q22, p_bar, s, W11, W22, U_scalar = case\n        # Build system matrices\n        A = np.array([[-gamma_m, 0.0],\n                      [ k_p,    -gamma_p]], dtype=float)\n        B = np.array([[k_m],\n                      [0.0]], dtype=float)\n        C = np.array([[0.0, 1.0]], dtype=float)\n        Q = np.diag([Q11, Q22]).astype(float)\n        W = np.diag([W11, W22]).astype(float)\n        U = np.array([[U_scalar]], dtype=float)\n        R = np.array([[s * p_bar]], dtype=float)\n\n        # LQR gain\n        K, _ = lqr_gain(A, B, W, U)\n        # Kalman gain\n        L, _ = kalman_gain(A, C, Q, R)\n        # Separation check\n        sep_ok = separation_principle_ok(A, B, C, K, L, tol=1e-7)\n        # Covariances\n        P_ol = open_loop_covariance(A, Q)\n        P_xx, _, _ = closed_loop_covariance(A, B, C, K, L, Q, R)\n        # Ratio\n        trace_ol = float(np.trace(P_ol))\n        trace_cl = float(np.trace(P_xx))\n        ratio = trace_cl / trace_ol\n\n        # Append results: boolean then float rounded to 6 decimals\n        results.append(sep_ok)\n        # Round to six decimals for output formatting\n        ratio_rounded = round(ratio + 0.0, 6)\n        results.append(ratio_rounded)\n\n    # Final print statement in the exact required format.\n    # Booleans as True/False, floats with up to 6 decimal places (ensure fixed format).\n    out_elems = []\n    for r in results:\n        if isinstance(r, bool):\n            out_elems.append(\"True\" if r else \"False\")\n        else:\n            # Ensure representation with exactly 6 decimal places\n            out_elems.append(f\"{r:.6f}\")\n    print(f\"[{','.join(out_elems)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3297551"}]}