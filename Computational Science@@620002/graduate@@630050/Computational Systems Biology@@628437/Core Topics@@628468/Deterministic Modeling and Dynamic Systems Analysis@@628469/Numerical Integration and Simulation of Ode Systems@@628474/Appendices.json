{"hands_on_practices": [{"introduction": "Before simulating a biological model, it is often invaluable to simplify it through nondimensionalization. This analytical technique rescales variables and parameters to reveal the essential parameter groupings that govern the system's behavior and can improve the numerical conditioning of the equations. This practice [@problem_id:3334705] provides hands-on experience with this crucial preprocessing step, showing how to distill a multi-parameter gene expression model down to a simpler form controlled by a single dimensionless ratio.", "problem": "Consider a canonical two-stage gene expression model for messenger ribonucleic acid (mRNA) and protein, written as a system of ordinary differential equations (ODEs) that embody a constant transcription source and first-order decay for mRNA, and translation-driven production with first-order decay for protein: $$\\frac{dP}{dt}=k_{tl} M-\\gamma_{p} P,\\qquad \\frac{dM}{dt}=k_{t}-\\gamma_{m} M,$$ where $M(t)$ and $P(t)$ denote mRNA and protein copy numbers, $k_{t}$ is the transcription rate, $k_{tl}$ is the translation rate, and $\\gamma_{m}$ and $\\gamma_{p}$ are decay rate constants for mRNA and protein, respectively. In computational systems biology, nondimensionalization is used to reveal parameter groupings and improve the conditioning and stiffness properties of numerical integration. Introduce dimensionless variables by defining characteristic scales $M_{\\ast}$ for $M$, $P_{\\ast}$ for $P$, and a timescale $\\tau$ for $t$, and then define $$m=\\frac{M}{M_{\\ast}},\\qquad p=\\frac{P}{P_{\\ast}},\\qquad s=\\frac{t}{\\tau}.$$ Derive the nondimensionalized ODE system for $m(s)$ and $p(s)$, and identify the resulting dimensionless parameter combinations that appear. Then choose the characteristic scales $M_{\\ast}$, $P_{\\ast}$, and $\\tau$ so that the constant source and linear decay terms in the mRNA equation are of order one and the number of independent dimensionless parameters in the nondimensionalized system is minimal. Under this choice, determine the single residual dimensionless parameter grouping that controls the coupled mRNA–protein dynamics. Provide your final answer as a single closed-form analytic expression in terms of the original dimensional parameters $k_{t}$, $k_{tl}$, $\\gamma_{m}$, and $\\gamma_{p}$.", "solution": "The problem requires the nondimensionalization of a two-stage gene expression model and the identification of a key dimensionless parameter grouping under a specific choice of characteristic scales.\n\nThe given system of ordinary differential equations (ODEs) is:\n$$\n\\frac{dM}{dt} = k_{t} - \\gamma_{m} M \\\\\n\\frac{dP}{dt} = k_{tl} M - \\gamma_{p} P\n$$\nHere, $M(t)$ and $P(t)$ are the mRNA and protein copy numbers, respectively. The parameters are the transcription rate $k_{t}$, the translation rate $k_{tl}$, the mRNA decay rate $\\gamma_{m}$, and the protein decay rate $\\gamma_{p}$.\n\nWe introduce dimensionless variables $m$, $p$, and $s$ using characteristic scales $M_{\\ast}$, $P_{\\ast}$, and $\\tau$:\n$$\nm = \\frac{M}{M_{\\ast}}, \\quad p = \\frac{P}{P_{\\ast}}, \\quad s = \\frac{t}{\\tau}\n$$\nThis implies $M = M_{\\ast} m$, $P = P_{\\ast} p$, and $t = \\tau s$. To transform the time derivatives, we use the chain rule:\n$$\n\\frac{d}{dt} = \\frac{ds}{dt} \\frac{d}{ds} = \\frac{1}{\\tau} \\frac{d}{ds}\n$$\nSubstituting these expressions into the original ODEs:\nFor the mRNA equation:\n$$\n\\frac{d(M_{\\ast} m)}{dt} = k_{t} - \\gamma_{m} (M_{\\ast} m) \\\\\nM_{\\ast} \\frac{dm}{dt} = k_{t} - \\gamma_{m} M_{\\ast} m \\\\\nM_{\\ast} \\left(\\frac{1}{\\tau} \\frac{dm}{ds}\\right) = k_{t} - \\gamma_{m} M_{\\ast} m\n$$\nMultiplying by $\\frac{\\tau}{M_{\\ast}}$ yields the dimensionless mRNA equation:\n$$\n\\frac{dm}{ds} = \\left(\\frac{k_{t} \\tau}{M_{\\ast}}\\right) - (\\gamma_{m} \\tau) m\n$$\nFor the protein equation:\n$$\n\\frac{d(P_{\\ast} p)}{dt} = k_{tl} (M_{\\ast} m) - \\gamma_{p} (P_{\\ast} p) \\\\\nP_{\\ast} \\frac{dp}{dt} = k_{tl} M_{\\ast} m - \\gamma_{p} P_{\\ast} p \\\\\nP_{\\ast} \\left(\\frac{1}{\\tau} \\frac{dp}{ds}\\right) = k_{tl} M_{\\ast} m - \\gamma_{p} P_{\\ast} p\n$$\nMultiplying by $\\frac{\\tau}{P_{\\ast}}$ yields the dimensionless protein equation:\n$$\n\\frac{dp}{ds} = \\left(\\frac{k_{tl} M_{\\ast} \\tau}{P_{\\ast}}\\right) m - (\\gamma_{p} \\tau) p\n$$\nThe problem specifies that the characteristic scales should be chosen such that \"the constant source and linear decay terms in the mRNA equation are of order one\". This means we set their corresponding dimensionless coefficients to $1$:\n$$\n\\frac{k_{t} \\tau}{M_{\\ast}} = 1 \\quad \\text{and} \\quad \\gamma_{m} \\tau = 1\n$$\nFrom the second condition, we can determine the characteristic timescale $\\tau$:\n$$\n\\tau = \\frac{1}{\\gamma_{m}}\n$$\nThis choice sets the characteristic timescale of the system to the mean lifetime of an mRNA molecule. Substituting this result into the first condition allows us to determine the characteristic mRNA copy number $M_{\\ast}$:\n$$\n\\frac{k_{t} (1/\\gamma_{m})}{M_{\\ast}} = 1 \\implies M_{\\ast} = \\frac{k_{t}}{\\gamma_{m}}\n$$\nThis sets the characteristic mRNA copy number to its steady-state value. With these choices for $\\tau$ and $M_{\\ast}$, the dimensionless mRNA equation simplifies to:\n$$\n\\frac{dm}{ds} = 1 - m\n$$\nNext, we substitute the expressions for $\\tau$ and $M_{\\ast}$ into the dimensionless protein equation to determine the remaining scale $P_{\\ast}$ and the final dimensionless parameter grouping. The protein equation is:\n$$\n\\frac{dp}{ds} = \\left(\\frac{k_{tl} M_{\\ast} \\tau}{P_{\\ast}}\\right) m - (\\gamma_{p} \\tau) p\n$$\nLet's evaluate the coefficients. The coefficient of the decay term for $p$ becomes:\n$$\n\\gamma_{p} \\tau = \\gamma_{p} \\left(\\frac{1}{\\gamma_{m}}\\right) = \\frac{\\gamma_{p}}{\\gamma_{m}}\n$$\nThe coefficient of the production term for $p$ (i.e., the term involving $m$) is:\n$$\n\\frac{k_{tl} M_{\\ast} \\tau}{P_{\\ast}} = \\frac{k_{tl} \\left(\\frac{k_{t}}{\\gamma_{m}}\\right) \\left(\\frac{1}{\\gamma_{m}}\\right)}{P_{\\ast}} = \\frac{k_{tl} k_{t}}{P_{\\ast} \\gamma_{m}^{2}}\n$$\nThe problem requires that the number of independent dimensionless parameters be minimal. We have one free scale, $P_{\\ast}$, which we can choose to eliminate one of the remaining parameter groups. The standard and most effective choice is to set the coefficient of the production term for $p$ to $1$:\n$$\n\\frac{k_{tl} k_{t}}{P_{\\ast} \\gamma_{m}^{2}} = 1\n$$\nSolving for $P_{\\ast}$ gives:\n$$\nP_{\\ast} = \\frac{k_{tl} k_{t}}{\\gamma_{m}^{2}}\n$$\nWith this choice, the complete nondimensionalized system becomes:\n$$\n\\frac{dm}{ds} = 1 - m \\\\\n\\frac{dp}{ds} = m - \\left(\\frac{\\gamma_{p}}{\\gamma_{m}}\\right) p\n$$\nThis system is controlled by a single residual dimensionless parameter group, which is the coefficient of the decay term in the protein equation. This parameter represents the ratio of the protein decay rate to the mRNA decay rate, or equivalently, the ratio of the mRNA lifetime to the protein lifetime.\n\nThe single residual dimensionless parameter grouping that controls the coupled mRNA-protein dynamics is therefore $\\frac{\\gamma_{p}}{\\gamma_{m}}$.", "answer": "$$\n\\boxed{\\frac{\\gamma_{p}}{\\gamma_{m}}}\n$$", "id": "3334705"}, {"introduction": "While we often use sophisticated ODE solvers as black boxes, understanding their internal construction is key to using them wisely. Runge-Kutta methods are a cornerstone of numerical integration, built by systematically matching the Taylor series expansion of the numerical update to that of the exact solution to achieve a desired order of accuracy. In this exercise [@problem_id:3334726], you will derive a third-order Runge-Kutta method from first principles, gaining fundamental insight into how these powerful algorithms achieve their accuracy.", "problem": "You are designing a numerical solver for a non-stiff gene regulatory network governed by an autonomous ordinary differential equation (ODE) system of the form $\\dot{\\mathbf{y}} = \\mathbf{f}(\\mathbf{y})$ arising from mass-action kinetics, where $\\mathbf{y} \\in \\mathbb{R}^{n}$ denotes concentrations and $\\mathbf{f}$ collects reaction rates. To advance the simulation over a time step of size $h$, you decide to construct a three-stage explicit Runge–Kutta (RK) method of order $3$ tailored to evaluating reaction rates at a midpoint and an endpoint within the step, to reduce discretization error while retaining non-stiff stability.\n\nLet the method be specified by the Butcher coefficients $(A, \\mathbf{b}, \\mathbf{c})$, where $A \\in \\mathbb{R}^{3 \\times 3}$ is strictly lower triangular, $\\mathbf{b} \\in \\mathbb{R}^{3}$ are the weights, and $\\mathbf{c} \\in \\mathbb{R}^{3}$ are the stage abscissae. Impose the constraints $c_{1} = 0$, $c_{2} = \\frac{1}{2}$, and $c_{3} = 1$, consistent with evaluating stages at the beginning, midpoint, and end of the step. Use the core definitions of explicit Runge–Kutta methods, in particular $A \\mathbf{e} = \\mathbf{c}$ with $\\mathbf{e}$ denoting the vector of ones, and derive the order conditions required to achieve third order accuracy by matching the Taylor-series expansion of the exact solution with that of the numerical method. Then solve these order conditions to determine all nonzero entries of $A$ and all entries of $\\mathbf{b}$, and present the resulting Butcher tableau.\n\nProvide the final answer as the exact numerical value of the coefficient $a_{31}$. Do not round. No physical units are required in the final answer. In your derivation and presentation, every mathematical symbol, variable, function, operator, and number must be written in LaTeX. The tableau must be included in your solution, and your reasoning must start from fundamental definitions and well-tested formulas rather than any shortcut formulas.", "solution": "The problem requires the derivation of the coefficients for a specific three-stage, third-order explicit Runge-Kutta (RK) method for an autonomous system of ordinary differential equations (ODEs), $\\dot{\\mathbf{y}} = \\mathbf{f}(\\mathbf{y})$.\n\nA general $s$-stage explicit RK method to advance the solution from time $t_n$ to $t_{n+1} = t_n + h$ is given by:\n$$\n\\mathbf{y}_{n+1} = \\mathbf{y}_n + h \\sum_{i=1}^{s} b_i \\mathbf{k}_i\n$$\nwhere the stage vectors $\\mathbf{k}_i$ are computed as:\n$$\n\\mathbf{k}_i = \\mathbf{f}\\left(\\mathbf{y}_n + h \\sum_{j=1}^{i-1} a_{ij} \\mathbf{k}_j\\right) \\quad \\text{for } i = 1, \\dots, s\n$$\nThe method is characterized by its Butcher tableau:\n$$\n\\begin{array}{c|c}\n\\mathbf{c} & A \\\\\n\\hline\n& \\mathbf{b}^T\n\\end{array}\n=\n\\begin{array}{c|cccc}\nc_1 & a_{11} & a_{12} & \\cdots & a_{1s} \\\\\nc_2 & a_{21} & a_{22} & \\cdots & a_{2s} \\\\\n\\vdots & \\vdots & \\vdots & \\ddots & \\vdots \\\\\nc_s & a_{s1} & a_{s2} & \\cdots & a_{ss} \\\\\n\\hline\n& b_1 & b_2 & \\cdots & b_s\n\\end{array}\n$$\nFor an explicit method, the matrix $A$ is strictly lower triangular, i.e., $a_{ij} = 0$ for $j \\geq i$. The problem specifies a 3-stage method ($s=3$), so the tableau has the form:\n$$\n\\begin{array}{c|ccc}\nc_1 & 0 & 0 & 0 \\\\\nc_2 & a_{21} & 0 & 0 \\\\\nc_3 & a_{31} & a_{32} & 0 \\\\\n\\hline\n& b_1 & b_2 & b_3\n\\end{array}\n$$\nThe problem imposes the following constraints:\n1.  The stage abscissae are $\\mathbf{c} = (c_1, c_2, c_3)^T = (0, 1/2, 1)^T$.\n2.  The relationship $\\sum_{j=1}^{s} a_{ij} = c_i$ holds for all $i$.\nFor $i=1$, $c_1 = 0$ implies $a_{1j}=0$, which is consistent with the explicit nature.\nFor $i=2$, $c_2 = a_{21} = 1/2$.\nFor $i=3$, $c_3 = a_{31} + a_{32} = 1$.\n\nTo derive the remaining coefficients ($b_1, b_2, b_3, a_{31}, a_{32}$), we match the Taylor series expansion of the numerical solution $\\mathbf{y}_{n+1}$ with that of the exact solution $\\mathbf{y}(t_n+h)$ up to order $h^3$.\n\nThe Taylor series of the exact solution $\\mathbf{y}(t)$ around $t_n$ is:\n$$\n\\mathbf{y}(t_n+h) = \\mathbf{y}(t_n) + h \\mathbf{y}'(t_n) + \\frac{h^2}{2} \\mathbf{y}''(t_n) + \\frac{h^3}{6} \\mathbf{y}'''(t_n) + O(h^4)\n$$\nFor an autonomous system, the derivatives of $\\mathbf{y}$ can be expressed in terms of $\\mathbf{f}$ and its Jacobian $\\mathbf{f}' = \\frac{\\partial \\mathbf{f}}{\\partial \\mathbf{y}}$ and higher derivatives:\n$\\mathbf{y}' = \\mathbf{f}$\n$\\mathbf{y}'' = \\mathbf{f}' \\mathbf{y}' = \\mathbf{f}' \\mathbf{f}$\n$\\mathbf{y}''' = \\frac{d}{dt}(\\mathbf{f}' \\mathbf{f}) = (\\mathbf{f}''(\\mathbf{f}))\\mathbf{f} + \\mathbf{f}'(\\mathbf{f}' \\mathbf{f})$\nSubstituting these into the expansion gives:\n$$\n\\mathbf{y}(t_n+h) = \\mathbf{y}_n + h\\mathbf{f} + \\frac{h^2}{2}\\mathbf{f}'\\mathbf{f} + \\frac{h^3}{6}\\left( \\mathbf{f}''(\\mathbf{f},\\mathbf{f}) + \\mathbf{f}'(\\mathbf{f}'\\mathbf{f}) \\right) + O(h^4)\n$$\n(Here, $\\mathbf{y}_n$ stands for $\\mathbf{y}(t_n)$, and $\\mathbf{f}$ and its derivatives are evaluated at $\\mathbf{y}_n$).\n\nNext, we expand the numerical solution. The stages are:\n$\\mathbf{k}_1 = \\mathbf{f}(\\mathbf{y}_n) = \\mathbf{f}$\n$\\mathbf{k}_2 = \\mathbf{f}(\\mathbf{y}_n + h a_{21} \\mathbf{k}_1) = \\mathbf{f}(\\mathbf{y}_n + h a_{21} \\mathbf{f})$\nExpanding $\\mathbf{k}_2$ in a Taylor series around $\\mathbf{y}_n$:\n$\\mathbf{k}_2 = \\mathbf{f} + h a_{21} (\\mathbf{f}'\\mathbf{f}) + \\frac{h^2}{2} a_{21}^2 \\mathbf{f}''(\\mathbf{f},\\mathbf{f}) + O(h^3)$\n$\\mathbf{k}_3 = \\mathbf{f}(\\mathbf{y}_n + h(a_{31}\\mathbf{k}_1 + a_{32}\\mathbf{k}_2))$\nThe argument of $\\mathbf{f}$ is $\\mathbf{y}_n + h(a_{31}\\mathbf{f} + a_{32}(\\mathbf{f} + h a_{21}(\\mathbf{f}'\\mathbf{f}) + \\dots)) = \\mathbf{y}_n + h(a_{31}+a_{32})\\mathbf{f} + h^2 a_{32}a_{21}(\\mathbf{f}'\\mathbf{f}) + O(h^3)$.\nSince $a_{31}+a_{32}=c_3$, the argument is $\\mathbf{y}_n + h c_3 \\mathbf{f} + h^2 a_{32}a_{21}(\\mathbf{f}'\\mathbf{f}) + O(h^3)$.\nExpanding $\\mathbf{k}_3$ around $\\mathbf{y}_n$:\n$\\mathbf{k}_3 = \\mathbf{f} + \\mathbf{f}'(h c_3 \\mathbf{f} + h^2 a_{32}a_{21}(\\mathbf{f}'\\mathbf{f})) + \\frac{1}{2}\\mathbf{f}''(h c_3 \\mathbf{f}, h c_3 \\mathbf{f}) + O(h^3)$\n$\\mathbf{k}_3 = \\mathbf{f} + h c_3 (\\mathbf{f}'\\mathbf{f}) + h^2 \\left( a_{32}a_{21} \\mathbf{f}'(\\mathbf{f}'\\mathbf{f}) + \\frac{c_3^2}{2} \\mathbf{f}''(\\mathbf{f},\\mathbf{f}) \\right) + O(h^3)$\n\nThe numerical solution is $\\mathbf{y}_{n+1} = \\mathbf{y}_n + h(b_1\\mathbf{k}_1 + b_2\\mathbf{k}_2 + b_3\\mathbf{k}_3)$. Substituting the expansions for $\\mathbf{k}_i$:\n$$\n\\mathbf{y}_{n+1} - \\mathbf{y}_n = h\\mathbf{f}(b_1+b_2+b_3) + h^2(\\mathbf{f}'\\mathbf{f})(b_2 a_{21} + b_3 c_3) + h^3 \\left( \\mathbf{f}'(\\mathbf{f}'\\mathbf{f}) (b_3 a_{32} a_{21}) + \\mathbf{f}''(\\mathbf{f},\\mathbf{f}) \\left(\\frac{1}{2}b_2 a_{21}^2 + \\frac{1}{2}b_3 c_3^2\\right) \\right) + O(h^4)\n$$\nUsing $a_{21}=c_2$:\n$$\n\\mathbf{y}_{n+1} - \\mathbf{y}_n = h\\mathbf{f}\\sum_{i=1}^3 b_i + h^2(\\mathbf{f}'\\mathbf{f})\\sum_{i=1}^3 b_i c_i + h^3 \\left( \\mathbf{f}'(\\mathbf{f}'\\mathbf{f}) (b_3 a_{32} c_2) + \\mathbf{f}''(\\mathbf{f},\\mathbf{f}) \\sum_{i=1}^3 \\frac{1}{2}b_i c_i^2 \\right) + O(h^4)\n$$\nComparing coefficients with the exact expansion term by term gives the order conditions:\n1. $O(h^1)$: $\\sum b_i = b_1+b_2+b_3 = 1$\n2. $O(h^2)$: $\\sum b_i c_i = b_1 c_1 + b_2 c_2 + b_3 c_3 = 1/2$\n3. $O(h^3)$, term $\\mathbf{f}''(\\mathbf{f},\\mathbf{f})$: $\\sum b_i c_i^2 = b_1 c_1^2 + b_2 c_2^2 + b_3 c_3^2 = 1/3$\n4. $O(h^3)$, term $\\mathbf{f}'(\\mathbf{f}'\\mathbf{f})$: $b_3 a_{32} c_2 = 1/6$\n\nWe solve this system of equations using the given values $c_1=0$, $c_2=1/2$, $c_3=1$.\nFrom condition 2:\n$b_1(0) + b_2(1/2) + b_3(1) = 1/2 \\implies \\frac{1}{2}b_2 + b_3 = \\frac{1}{2}$\nFrom condition 3:\n$b_1(0)^2 + b_2(1/2)^2 + b_3(1)^2 = 1/3 \\implies \\frac{1}{4}b_2 + b_3 = \\frac{1}{3}$\n\nWe now have a system of two linear equations for $b_2$ and $b_3$:\n(i) $\\frac{1}{2}b_2 + b_3 = \\frac{1}{2}$\n(ii) $\\frac{1}{4}b_2 + b_3 = \\frac{1}{3}$\nSubtracting (ii) from (i):\n$(\\frac{1}{2} - \\frac{1}{4})b_2 = \\frac{1}{2} - \\frac{1}{3} \\implies \\frac{1}{4}b_2 = \\frac{1}{6} \\implies b_2 = \\frac{4}{6} = \\frac{2}{3}$.\nSubstitute $b_2 = 2/3$ into (ii):\n$\\frac{1}{4}(\\frac{2}{3}) + b_3 = \\frac{1}{3} \\implies \\frac{1}{6} + b_3 = \\frac{1}{3} \\implies b_3 = \\frac{1}{3} - \\frac{1}{6} = \\frac{1}{6}$.\nFrom condition 1, find $b_1$:\n$b_1 + b_2 + b_3 = 1 \\implies b_1 + \\frac{2}{3} + \\frac{1}{6} = 1 \\implies b_1 + \\frac{5}{6} = 1 \\implies b_1 = \\frac{1}{6}$.\nSo the weights vector is $\\mathbf{b} = (1/6, 2/3, 1/6)^T$.\n\nNow we find the remaining coefficients of $A$. We already have $a_{21}=c_2=1/2$ and the relation $a_{31}+a_{32}=c_3=1$.\nWe use the fourth order condition: $b_3 a_{32} c_2 = 1/6$.\nSubstituting the known values $b_3 = 1/6$ and $c_2 = 1/2$:\n$(\\frac{1}{6}) a_{32} (\\frac{1}{2}) = \\frac{1}{6} \\implies \\frac{a_{32}}{12} = \\frac{1}{6} \\implies a_{32} = \\frac{12}{6} = 2$.\nFinally, we find $a_{31}$ from $a_{31}+a_{32}=1$:\n$a_{31} + 2 = 1 \\implies a_{31} = -1$.\n\nAll coefficients are now determined. The resulting Butcher tableau is:\n$$\n\\begin{array}{c|ccc}\n0 & 0 & 0 & 0 \\\\\n1/2 & 1/2 & 0 & 0 \\\\\n1 & -1 & 2 & 0 \\\\\n\\hline\n& 1/6 & 2/3 & 1/6\n\\end{array}\n$$\nThis corresponds to Kutta's third-order method. The problem asks for the specific value of the coefficient $a_{31}$. Based on our derivation, $a_{31} = -1$.", "answer": "$$\n\\boxed{-1}\n$$", "id": "3334726"}, {"introduction": "A major challenge in simulating biological networks is \"stiffness,\" where dynamics occur on vastly different timescales, forcing explicit solvers to take prohibitively small time steps. The eigenvalues of the system's Jacobian matrix determine its characteristic timescales, and stiffness is directly related to the magnitude of the largest eigenvalue. The Gershgorin circle theorem provides a powerful, computationally cheap way to estimate this magnitude without explicitly computing the eigenvalues, and this practice [@problem_id:3334723] demonstrates its application to a phosphorylation cascade, allowing you to develop a practical diagnostic for stiffness and understand its direct impact on numerical stability.", "problem": "Consider a three-state phosphorylation cascade in which a protein cycles among an unphosphorylated state $M_{0}$, a monophosphorylated state $M_{1}$, and a diphosphorylated state $M_{2}$. The network is driven by a constitutive synthesis of $M_{0}$ and undergoes phosphorylation by a kinase and dephosphorylation by a phosphatase. Assume the kinase and phosphatase concentrations are constant, so the dynamics are first-order in the protein states. Let $x_{0}$, $x_{1}$, and $x_{2}$ denote the concentrations of $M_{0}$, $M_{1}$, and $M_{2}$, respectively. The ordinary differential equation (ODE) model is\n$$\n\\frac{d x_{0}}{d t} = c_{\\text{syn}} - a_{1} x_{0} - \\delta_{0} x_{0} + d_{1} x_{1}, \\quad\n\\frac{d x_{1}}{d t} = a_{1} x_{0} - a_{2} x_{1} - d_{1} x_{1} - \\delta_{1} x_{1} + d_{2} x_{2}, \\quad\n\\frac{d x_{2}}{d t} = a_{2} x_{1} - d_{2} x_{2} - \\delta_{2} x_{2}.\n$$\nHere $c_{\\text{syn}}$ is a constant synthesis rate for $M_{0}$, $a_{1}$ and $a_{2}$ are effective first-order phosphorylation rate constants, $d_{1}$ and $d_{2}$ are effective first-order dephosphorylation rate constants, and $\\delta_{0}$, $\\delta_{1}$, $\\delta_{2}$ are first-order degradation constants. The parameters are\n$$\nc_{\\text{syn}} = 1.0 \\times 10^{-3}, \\quad a_{1} = 0.10, \\quad a_{2} = 0.08, \\quad d_{1} = 12.0, \\quad d_{2} = 15.0, \\quad \\delta_{0} = 0.02, \\quad \\delta_{1} = 0.03, \\quad \\delta_{2} = 0.04,\n$$\nwith all rate constants in units of $\\text{s}^{-1}$ and $c_{\\text{syn}}$ in concentration per second. \n\nStarting from the mass-action law and the definition of the Jacobian matrix of the vector field, use the Gershgorin circle theorem to construct a conservative, computationally cheap diagnostic of stiffness based on a bound on the largest eigenvalue modulus of the Jacobian. Then, from this bound, derive a conservative estimate for the largest stable time step $h_{\\max}^{G}$ for the explicit forward Euler method, defined as\n$$\nh_{\\max}^{G} = \\frac{2}{H},\n$$\nwhere $H$ is your Gershgorin-based bound on the largest eigenvalue modulus. Compute $h_{\\max}^{G}$ for the given cascade using the specified parameters.\n\nExpress your final answer in seconds and round your final numerical value to four significant figures. Provide only the final numerical value of $h_{\\max}^{G}$ as your answer.", "solution": "The system of ODEs can be written in vector form $\\frac{d\\mathbf{x}}{dt} = \\mathbf{f}(\\mathbf{x})$, where $\\mathbf{x} = [x_{0}, x_{1}, x_{2}]^T$ and the vector field $\\mathbf{f}(\\mathbf{x})$ is given by:\n$$\n\\mathbf{f}(\\mathbf{x}) = \\begin{pmatrix} c_{\\text{syn}} - (a_{1} + \\delta_{0}) x_{0} + d_{1} x_{1} \\\\ a_{1} x_{0} - (a_{2} + d_{1} + \\delta_{1}) x_{1} + d_{2} x_{2} \\\\ a_{2} x_{1} - (d_{2} + \\delta_{2}) x_{2} \\end{pmatrix}\n$$\nThe stability of numerical methods like explicit forward Euler depends on the eigenvalues of the Jacobian matrix of the system, defined as $J_{ij} = \\frac{\\partial f_i}{\\partial x_j}$. For this system, the components of the vector field $\\mathbf{f}$ are $f_0, f_1, f_2$. The Jacobian matrix $J$ is:\n$$\nJ = \\begin{pmatrix} \\frac{\\partial f_0}{\\partial x_0} & \\frac{\\partial f_0}{\\partial x_1} & \\frac{\\partial f_0}{\\partial x_2} \\\\ \\frac{\\partial f_1}{\\partial x_0} & \\frac{\\partial f_1}{\\partial x_1} & \\frac{\\partial f_1}{\\partial x_2} \\\\ \\frac{\\partial f_2}{\\partial x_0} & \\frac{\\partial f_2}{\\partial x_1} & \\frac{\\partial f_2}{\\partial x_2} \\end{pmatrix}\n$$\nCalculating the partial derivatives yields:\n$$\nJ = \\begin{pmatrix} -(a_{1} + \\delta_{0}) & d_{1} & 0 \\\\ a_{1} & -(a_{2} + d_{1} + \\delta_{1}) & d_{2} \\\\ 0 & a_{2} & -(d_{2} + \\delta_{2}) \\end{pmatrix}\n$$\nSince the system is linear, the Jacobian matrix is constant.\n\nThe Gershgorin circle theorem states that for a complex $n \\times n$ matrix $A$, all its eigenvalues lie in the union of the Gershgorin disks $D(A_{ii}, R_i)$, where $A_{ii}$ is a diagonal entry and $R_i = \\sum_{j\\neq i} |A_{ij}|$ is the sum of the absolute values of the off-diagonal entries in the $i$-th row. Consequently, the spectral radius $\\rho(A) = \\max_i |\\lambda_i|$ is bounded by:\n$$\n\\rho(A) \\le \\max_i \\left( |A_{ii}| + R_i \\right)\n$$\nWe apply this theorem to the Jacobian matrix $J$ to find the bound $H$:\n$$\nH = \\max_i \\left( |J_{ii}| + \\sum_{j\\neq i} |J_{ij}| \\right)\n$$\nSince all rate constants are positive, the absolute values are straightforward. We calculate the sum for each row:\n- **Row 0**: $|J_{00}| + |J_{01}| + |J_{02}| = |-(a_{1} + \\delta_{0})| + |d_{1}| + |0| = a_{1} + \\delta_{0} + d_{1}$\n- **Row 1**: $|J_{11}| + |J_{10}| + |J_{12}| = |-(a_{2} + d_{1} + \\delta_{1})| + |a_{1}| + |d_{2}| = a_{2} + d_{1} + \\delta_{1} + a_{1} + d_{2}$\n- **Row 2**: $|J_{22}| + |J_{20}| + |J_{21}| = |-(d_{2} + \\delta_{2})| + |0| + |a_{2}| = d_{2} + \\delta_{2} + a_{2}$\n\nSo, the bound $H$ is:\n$$\nH = \\max( a_{1} + \\delta_{0} + d_{1}, \\quad a_{1} + a_{2} + d_{1} + d_{2} + \\delta_{1}, \\quad a_{2} + d_{2} + \\delta_{2} )\n$$\nNow we substitute the given parameter values:\n$a_{1} = 0.10$, $a_{2} = 0.08$, $d_{1} = 12.0$, $d_{2} = 15.0$, $\\delta_{0} = 0.02$, $\\delta_{1} = 0.03$, $\\delta_{2} = 0.04$.\n\nLet $H_0, H_1, H_2$ be the bounds from each row:\n- $H_0 = 0.10 + 0.02 + 12.0 = 12.12$\n- $H_1 = 0.10 + 0.08 + 12.0 + 15.0 + 0.03 = 27.21$\n- $H_2 = 0.08 + 15.0 + 0.04 = 15.12$\n\nThe maximum of these values gives the overall bound $H$:\n$$\nH = \\max(12.12, 27.21, 15.12) = 27.21 \\, \\text{s}^{-1}\n$$\nThis value $H$ serves as a conservative upper bound for the modulus of the largest eigenvalue of the Jacobian, $|\\lambda|_{\\max}$. A large value of $H$ indicates fast dynamics in the system, which is a source of numerical stiffness.\n\nThe stability of the explicit forward Euler method for a system $\\frac{d\\mathbf{x}}{dt} = J\\mathbf{x}$ requires that for every eigenvalue $\\lambda$ of $J$, the time step $h$ must satisfy $|1+h\\lambda| \\le 1$. This condition implies that $h \\le \\frac{2}{|\\lambda|_{\\max}}$ if eigenvalues are real and negative. The provided formula for the largest stable time step based on the Gershgorin bound is $h_{\\max}^{G} = \\frac{2}{H}$. This is a conservative estimate because $H \\ge |\\lambda|_{\\max}$.\n\nUsing the calculated value of $H$:\n$$\nh_{\\max}^{G} = \\frac{2}{H} = \\frac{2}{27.21} \\, \\text{s}\n$$\n$$\nh_{\\max}^{G} \\approx 0.0735023888... \\, \\text{s}\n$$\nRounding the result to four significant figures as requested:\n$$\nh_{\\max}^{G} \\approx 0.07350 \\, \\text{s}\n$$\nThis is the conservative estimate for the largest stable time step for the forward Euler method applied to the given system.", "answer": "$$\n\\boxed{0.07350}\n$$", "id": "3334723"}]}