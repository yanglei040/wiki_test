{"hands_on_practices": [{"introduction": "The principle of maximum entropy provides a powerful, objective method for constructing probability distributions based on partial information. This first exercise takes us back to fundamentals, asking us to derive a prior distribution for a non-negative quantity when only its mean is known [@problem_id:3401736]. By applying the method of Lagrange multipliers to the entropy functional, you will see how these minimal constraints uniquely give rise to the familiar exponential distribution, providing a concrete example of Jaynes's principle in action.", "problem": "Consider an inverse problem in which a scalar state variable $x$ is known to be nonnegative, $x \\in [0,\\infty)$, and only its first moment $\\mathbb{E}[x]$ is available, namely $\\mathbb{E}[x]=\\mu$ with $\\mu>0$. You are to construct a prior distribution for $x$ by applying the Maximum Entropy (MaxEnt) principle relative to the Lebesgue measure on $[0,\\infty)$. The MaxEnt principle prescribes choosing the probability density function $p(x)$ that maximizes the differential entropy subject to the constraints of nonnegativity, normalization, and the known first moment. Starting from the definition of differential entropy and the constraints, derive the form of the maximizing density $p(x)$ and determine its parameter in terms of $\\mu$. Express your final answer as a single closed-form analytic expression for $p(x)$.", "solution": "The problem is to find the probability density function $p(x)$ for a non-negative variable $x \\in [0, \\infty)$ that maximizes the differential entropy, $H[p]$, subject to a known mean, $\\mathbb{E}[x]=\\mu$.\n\n1.  **Objective Functional:** We aim to maximize the differential entropy functional:\n    $$H[p] = - \\int_0^\\infty p(x) \\ln p(x) \\, dx$$\n\n2.  **Constraints:** The maximization is subject to two constraints:\n    *   Normalization: $\\int_0^\\infty p(x) \\, dx = 1$\n    *   Known Mean: $\\int_0^\\infty x p(x) \\, dx = \\mu$\n\n3.  **Lagrangian Formulation:** We use the method of Lagrange multipliers. We construct the Lagrangian functional $\\mathcal{L}[p]$ by adding the constraints, weighted by multipliers $\\lambda_0-1$ and $\\lambda_1$, to the entropy functional:\n    $$\n    \\mathcal{L}[p] = -\\int_0^\\infty p(x) \\ln p(x) \\, dx - (\\lambda_0-1)\\left(\\int_0^\\infty p(x) \\, dx - 1\\right) - \\lambda_1\\left(\\int_0^\\infty x p(x) \\, dx - \\mu\\right)\n    $$\n    This can be written as a single integral over the Lagrangian density $L(p,x)$:\n    $$\n    \\mathcal{L}[p] = \\int_0^\\infty \\left( -p(x) \\ln p(x) - (\\lambda_0-1)p(x) - \\lambda_1 x p(x) \\right) dx + \\text{const.}\n    $$\n\n4.  **Calculus of Variations:** To find the function $p(x)$ that maximizes $\\mathcal{L}[p]$, we apply the Euler-Lagrange equation. We take the functional derivative of $\\mathcal{L}[p]$ with respect to $p(x)$ and set it to zero:\n    $$\n    \\frac{\\delta \\mathcal{L}}{\\delta p(x)} = \\frac{\\partial L}{\\partial p} = -\\ln p(x) - 1 - (\\lambda_0-1) - \\lambda_1 x = 0\n    $$\n    Solving for $\\ln p(x)$:\n    $$\n    \\ln p(x) = - \\lambda_0 - \\lambda_1 x\n    $$\n    This gives the general form of the solution:\n    $$\n    p(x) = \\exp(-\\lambda_0 - \\lambda_1 x) = C \\exp(-\\lambda_1 x)\n    $$\n    where $C = \\exp(-\\lambda_0)$ is a constant.\n\n5.  **Determining the Multipliers:** We use the constraints to find the values of the constants.\n    *   From the normalization constraint:\n        $$\n        \\int_0^\\infty C \\exp(-\\lambda_1 x) \\, dx = 1\n        $$\n        For this integral to converge, we must have $\\lambda_1 > 0$. The integral evaluates to:\n        $$\n        C \\left[ -\\frac{1}{\\lambda_1} \\exp(-\\lambda_1 x) \\right]_0^\\infty = C \\left( 0 - \\left(-\\frac{1}{\\lambda_1}\\right) \\right) = \\frac{C}{\\lambda_1}\n        $$\n        Setting this to $1$ gives $C = \\lambda_1$. So, the distribution is $p(x) = \\lambda_1 \\exp(-\\lambda_1 x)$.\n\n    *   From the mean constraint:\n        $$\n        \\mathbb{E}[x] = \\int_0^\\infty x p(x) \\, dx = \\int_0^\\infty x \\lambda_1 \\exp(-\\lambda_1 x) \\, dx = \\mu\n        $$\n        We can solve this integral using integration by parts, with $u=x$ and $dv = \\lambda_1 \\exp(-\\lambda_1 x) dx$:\n        \\begin{align*}\n        \\int_0^\\infty x \\lambda_1 \\exp(-\\lambda_1 x) \\, dx = \\left[ x (-\\exp(-\\lambda_1 x)) \\right]_0^\\infty - \\int_0^\\infty (-\\exp(-\\lambda_1 x)) \\, dx \\\\\n        = (0 - 0) + \\int_0^\\infty \\exp(-\\lambda_1 x) \\, dx \\\\\n        = \\left[ -\\frac{1}{\\lambda_1} \\exp(-\\lambda_1 x) \\right]_0^\\infty \\\\\n        = \\frac{1}{\\lambda_1}\n        \\end{align*}\n        Equating this result to the known mean gives $\\frac{1}{\\lambda_1} = \\mu$, which implies $\\lambda_1 = \\frac{1}{\\mu}$.\n\n6.  **Final Distribution:** Substituting the value of $\\lambda_1$ back into the expression for $p(x)$, we obtain the final result:\n    $$\n    p(x) = \\frac{1}{\\mu} \\exp\\left(-\\frac{x}{\\mu}\\right)\n    $$\n    This is the probability density function for the exponential distribution with mean $\\mu$.", "answer": "$$\n\\boxed{p(x) = \\frac{1}{\\mu} \\exp\\left(-\\frac{x}{\\mu}\\right)}\n$$", "id": "3401736"}, {"introduction": "While analytical derivations are foundational, real-world inverse problems often involve numerous constraints that make a closed-form solution for the model parameters intractable. This practice transitions from theory to computation, addressing how to find the Lagrange multipliers, $\\lambda_i$, that ensure the model's expectations match our target constraints [@problem_id:3401753]. You will implement the Generalized Iterative Scaling (GIS) algorithm, a classic and robust method that reveals the convex optimization problem at the heart of fitting maximum entropy models.", "problem": "A finite inverse problem is posed on a discrete sample space with a maximum entropy prior. Let the discrete space be $\\mathcal{X} = \\{1, \\dots, n\\}$. A strictly positive base measure $h : \\mathcal{X} \\to \\mathbb{R}_{0}$ and a collection of $m$ nonnegative features $f_i : \\mathcal{X} \\to \\mathbb{R}_{\\ge 0}$ for $i \\in \\{1, \\dots, m\\}$ are given. Consider the log-linear family of priors $p_\\lambda$ over $\\mathcal{X}$ indexed by $\\lambda \\in \\mathbb{R}^m$ of the form\n$$\np_\\lambda(x) = \\frac{h(x)\\exp\\left(\\sum_{i=1}^m \\lambda_i f_i(x)\\right)}{Z(\\lambda)}, \\quad Z(\\lambda) = \\sum_{x \\in \\mathcal{X}} h(x)\\exp\\left(\\sum_{i=1}^m \\lambda_i f_i(x)\\right).\n$$\nGiven target feature expectations $c_i \\in \\mathbb{R}_{0}$ for $i \\in \\{1,\\dots,m\\}$, the goal is to adjust the parameter vector $\\lambda$ so that, for each feature, the model expectation under $p_\\lambda$ satisfies\n$$\n\\mathbb{E}_{p_\\lambda}[f_i] = \\sum_{x \\in \\mathcal{X}} p_\\lambda(x) f_i(x) = c_i.\n$$\nAssume the features are bounded and their sum is constant across $\\mathcal{X}$, namely there exists a constant $C \\in \\mathbb{R}_{0}$ such that\n$$\n\\sum_{i=1}^m f_i(x) = C \\quad \\text{for all } x \\in \\mathcal{X}.\n$$\nUnder this boundedness assumption, implement the generalized iterative scaling method that updates the parameter vector $\\lambda$ in a way that enforces the expectations to approach the targets $c_i$. Your implementation must:\n- Construct $p_\\lambda$ as specified.\n- Iterate parameter updates until the maximum absolute constraint violation\n$$\nr = \\max_{1\\le i \\le m} \\left| \\mathbb{E}_{p_\\lambda}[f_i] - c_i \\right|\n$$\nis less than a tolerance or until a maximum number of iterations is reached.\n- Use numerically stable normalization for $p_\\lambda$.\n- Return, for each test case, the final value of $r$.\n\nExplain, in your solution, why the algorithm converges under convexity and boundedness assumptions, and why uniqueness of the solution holds in terms of the induced prior $p_\\lambda$, even when features are linearly dependent.\n\nImplement your program to solve the following test suite. For each test case, the program must compute the final value of $r$ and aggregate the results in a single output line as specified below.\n\nTest Case $1$ (happy path):\n- Size: $n = 5$, $m = 3$.\n- Base measure: $h(x) = 1$ for all $x$.\n- Features: a partition of $\\mathcal{X}$ into three groups with one-hot indicators, yielding constant sum $C = 1$. Concretely,\n  - $f_1(x) = 1$ for $x \\in \\{1,2\\}$ and $f_1(x) = 0$ otherwise,\n  - $f_2(x) = 1$ for $x \\in \\{3,4\\}$ and $f_2(x) = 0$ otherwise,\n  - $f_3(x) = 1$ for $x \\in \\{5\\}$ and $f_3(x) = 0$ otherwise.\n- Targets: $c = [\\,0.4,\\,0.4,\\,0.2\\,]$.\n\nTest Case $2$ (boundary with extreme target mass):\n- Size: $n = 5$, $m = 3$.\n- Base measure: $h(x) = 1$ for all $x$.\n- Features: same as Test Case $1$ so that $C = 1$.\n- Targets: $c = [\\,10^{-6},\\,0.999,\\,0.000999\\,]$.\n\nTest Case $3$ (redundant features with constant sum):\n- Size: $n = 4$, $m = 3$.\n- Base measure: $h(x) = 1$ for all $x$.\n- Features: two one-hot indicators and one redundant feature ensuring constant sum $C = 2$:\n  - $f_1(x) = 1$ for $x \\in \\{1,2\\}$ and $f_1(x) = 0$ otherwise,\n  - $f_2(x) = 1$ for $x \\in \\{3,4\\}$ and $f_2(x) = 0$ otherwise,\n  - $f_3(x) = 1$ for all $x \\in \\{1,2,3,4\\}$.\n- Targets: $c = [\\,0.5,\\,0.5,\\,1.0\\,]$.\n\nTest Case $4$ (infeasible constraints):\n- Size: $n = 5$, $m = 3$.\n- Base measure: $h(x) = 1$ for all $x$.\n- Features: same as Test Case $1$ so that $C = 1$.\n- Targets: $c = [\\,0.3,\\,0.3,\\,0.3\\,]$.\n\nImplementation details:\n- Initialize $\\lambda$ at $\\lambda = \\mathbf{0} \\in \\mathbb{R}^m$.\n- Use a stopping tolerance of $10^{-10}$ for $r$ and a maximum of $5000$ iterations.\n- Construct $p_\\lambda$ using a numerically stable normalization method to avoid overflow or underflow.\n- For each test case, compute the final $r$ after iterations.\n\nFinal output format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. For example, if there are four test cases, the output should be of the form $[r_1,r_2,r_3,r_4]$ where each $r_i$ is a floating-point number representing the final maximum absolute constraint violation for Test Case $i$.", "solution": "The problem at hand is to find the parameters $\\lambda \\in \\mathbb{R}^m$ of a maximum entropy prior distribution $p_\\lambda$ over a discrete space $\\mathcal{X} = \\{1, \\dots, n\\}$ such that the model expectations of a set of features $\\{f_i\\}_{i=1}^m$ match a set of given target expectations $\\{c_i\\}_{i=1}^m$. This is a classic inverse problem in statistical inference. The prescribed form of the distribution is\n$$\np_\\lambda(x) = \\frac{h(x)\\exp\\left(\\sum_{i=1}^m \\lambda_i f_i(x)\\right)}{Z(\\lambda)}\n$$\nwhere $h(x)$ is a base measure, and $Z(\\lambda)$ is the normalization constant or partition function. This distribution is the unique solution to the optimization problem of maximizing the relative entropy (or Kullback-Leibler divergence) $S(p \\| h) = -\\sum_{x \\in \\mathcal{X}} p(x) \\log(p(x)/h(x))$ subject to the linear constraints $\\mathbb{E}_p[f_i] = c_i$ for $i=1, \\dots, m$.\n\nThis constrained optimization problem can be solved by considering its Lagrangian dual. The task of finding the distribution $p$ is transformed into an unconstrained optimization problem for the Lagrange multipliers $\\lambda$. The objective function to be maximized in the dual problem is the log-likelihood or log-partition function, up to terms not dependent on $\\lambda$. Specifically, we seek to find $\\lambda \\in \\mathbb{R}^m$ that solves the system of $m$ nonlinear equations:\n$$\n\\mathbb{E}_{p_\\lambda}[f_i] = \\sum_{x \\in \\mathcal{X}} p_\\lambda(x) f_i(x) = c_i, \\quad \\text{for } i=1, \\dots, m.\n$$\nThe left-hand side of this equation is related to the gradient of the log-partition function, $\\log Z(\\lambda)$:\n$$\n\\frac{\\partial}{\\partial \\lambda_i} \\log Z(\\lambda) = \\mathbb{E}_{p_\\lambda}[f_i].\n$$\nThus, solving the constraint equations is equivalent to finding a stationary point of the dual potential function $\\Phi(\\lambda) = \\log Z(\\lambda) - \\sum_{i=1}^m \\lambda_i c_i$.\n\nThe uniqueness of the solution distribution $p_\\lambda$ and the convergence of iterative algorithms are guaranteed by the convexity of this potential function. The Hessian of $\\log Z(\\lambda)$ is given by:\n$$\n\\frac{\\partial^2 \\log Z(\\lambda)}{\\partial \\lambda_j \\partial \\lambda_i} = \\sum_{x \\in \\mathcal{X}} p_\\lambda(x) f_i(x) f_j(x) - \\left(\\sum_{x \\in \\mathcal{X}} p_\\lambda(x) f_i(x)\\right)\\left(\\sum_{x \\in \\mathcal{X}} p_\\lambda(x) f_j(x)\\right) = \\text{Cov}_{p_\\lambda}(f_i, f_j).\n$$\nThis Hessian matrix is the covariance matrix of the features under the distribution $p_\\lambda$. As a covariance matrix, it is always positive semi-definite. This ensures that $\\log Z(\\lambda)$ is a convex function, and therefore the dual potential $\\Phi(\\lambda)$ is also convex. This convexity guarantees that if a minimum exists, the set of minimizers is a convex set. Furthermore, any two sets of parameters $\\lambda_A$ and $\\lambda_B$ in this set will yield the same vector of expectations $(\\mathbb{E}[f_1], \\dots, \\mathbb{E}[f_m])$ and thus the same probability distribution $p_\\lambda$. Therefore, if the constraints $\\{c_i\\}$ are feasible (i.e., they lie within the convex hull of the feature vectors), a solution distribution exists and is unique.\n\nIf the features $\\{f_i\\}$ are linearly dependent, meaning there exists a non-zero vector $\\alpha$ such that $\\sum_{i=1}^m \\alpha_i f_i(x)$ is constant for all $x$, the Hessian matrix will be singular. In this case, $\\Phi(\\lambda)$ is not strictly convex, and the parameter vector $\\lambda$ that solves the system is not unique. If $\\lambda^*$ is a solution, then $\\lambda^* + t\\alpha$ is also a solution for any scalar $t$, because the change in the exponent cancels out during normalization. This is the scenario in Test Case $3$. However, the resulting distribution $p_\\lambda$ remains unique.\n\nThe problem specifies the use of the Generalized Iterative Scaling (GIS) algorithm, which is applicable under the given conditions: non-negative features $f_i(x) \\ge 0$ and a constant feature sum $\\sum_{i=1}^m f_i(x) = C  0$ for all $x \\in \\mathcal{X}$. GIS provides a multiplicative update that can be expressed as an additive update in the log-parameter space of $\\lambda$. Given the parameters $\\lambda^{(k)}$ at iteration $k$, the update for each component $\\lambda_i$ is:\n$$\n\\lambda_i^{(k+1)} = \\lambda_i^{(k)} + \\frac{1}{C} \\log\\left(\\frac{c_i}{\\mathbb{E}_{p_{\\lambda^{(k)}}}[f_i]}\\right).\n$$\nHere, $\\mathbb{E}_{p_{\\lambda^{(k)}}}[f_i]$ represents the current model expectation for feature $i$. The term $1/C$ acts as a learning rate. This iterative procedure is guaranteed to converge to the unique parameters (up to linear dependencies) that satisfy the constraints, provided the constraints are feasible. The convergence proof relies on showing that each step of the algorithm strictly reduces the Kullback-Leibler divergence from the current distribution to the unique target distribution, a property established by Darroch and Ratcliff (1972) and Csiszár (1989). If the constraints are infeasible (as in Test Case $4$), the algorithm will still converge to a well-defined distribution within the exponential family, but the final constraint violation $r$ will remain non-zero, representing the minimal possible deviation from the target constraints under the chosen divergence measure.\n\nFor numerical implementation, the computation of $p_\\lambda(x)$ requires careful handling of the exponential terms to prevent numerical overflow or underflow. The log-sum-exp trick is a standard method for this. Let $s_x = \\log h(x) + \\sum_{i=1}^m \\lambda_i f_i(x)$. We compute $S_{\\max} = \\max_{x \\in \\mathcal{X}} s_x$ and then calculate the probabilities as:\n$$\np_\\lambda(x) = \\frac{\\exp(s_x - S_{\\max})}{\\sum_{y \\in \\mathcal{X}} \\exp(s_y - S_{\\max})}.\n$$\nThis ensures that the largest argument to the exponential function is $0$, thus preventing overflow, while terms that would underflow correctly evaluate to $0$.\n\nThe algorithm proceeds by initializing $\\lambda = \\mathbf{0}$, then iteratively calculating the current distribution $p_{\\lambda^{(k)}}$, the expectations $\\mathbb{E}_{p_{\\lambda^{(k)}}}[f_i]$, the residual $r$, and updating $\\lambda^{(k+1)}$ until $r$ is below the specified tolerance or the maximum number of iterations is reached.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of maximum entropy problems using Generalized Iterative Scaling.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"n\": 5, \"m\": 3,\n            \"h\": np.ones(5),\n            \"F\": np.array([[1, 1, 0, 0, 0], [0, 0, 1, 1, 0], [0, 0, 0, 0, 1]], dtype=float),\n            \"c\": np.array([0.4, 0.4, 0.2]),\n            \"C\": 1.0,\n        },\n        {\n            \"n\": 5, \"m\": 3,\n            \"h\": np.ones(5),\n            \"F\": np.array([[1, 1, 0, 0, 0], [0, 0, 1, 1, 0], [0, 0, 0, 0, 1]], dtype=float),\n            \"c\": np.array([1e-6, 0.999, 0.000999]),\n            \"C\": 1.0,\n        },\n        {\n            \"n\": 4, \"m\": 3,\n            \"h\": np.ones(4),\n            \"F\": np.array([[1, 1, 0, 0], [0, 0, 1, 1], [1, 1, 1, 1]], dtype=float),\n            \"c\": np.array([0.5, 0.5, 1.0]),\n            \"C\": 2.0,\n        },\n        {\n            \"n\": 5, \"m\": 3,\n            \"h\": np.ones(5),\n            \"F\": np.array([[1, 1, 0, 0, 0], [0, 0, 1, 1, 0], [0, 0, 0, 0, 1]], dtype=float),\n            \"c\": np.array([0.3, 0.3, 0.3]),\n            \"C\": 1.0,\n        },\n    ]\n\n    results = []\n    tol = 1e-10\n    max_iter = 5000\n\n    for case in test_cases:\n        n, m = case[\"n\"], case[\"m\"]\n        h, F, c, C = case[\"h\"], case[\"F\"], case[\"c\"], case[\"C\"]\n\n        lambda_vec = np.zeros(m)\n        log_h = np.log(h)\n        \n        final_r = -1.0 # Placeholder\n\n        for k in range(max_iter):\n            # Calculate unnormalized log probabilities\n            # lambda_vec: (m,), F: (m, n) -> s: (n,)\n            s = lambda_vec @ F + log_h\n\n            # Numerically stable calculation of p_lambda (softmax)\n            s_max = np.max(s)\n            exp_s = np.exp(s - s_max)\n            p_lambda = exp_s / np.sum(exp_s)\n            \n            # Calculate current expectations\n            # F: (m, n), p_lambda: (n,) -> current_c: (m,)\n            current_c = F @ p_lambda\n            \n            # Calculate maximum absolute constraint violation\n            r = np.max(np.abs(current_c - c))\n            final_r = r\n\n            # Check for convergence\n            if r  tol:\n                break\n            \n            # GIS update step for lambda\n            # Note: current_c components are > 0 because h>0, f_i>=0, c_i>0,\n            # and each f_i is non-zero for at least one x.\n            delta_lambda = (1.0 / C) * np.log(c / current_c)\n            lambda_vec += delta_lambda\n\n        results.append(final_r)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3401753"}, {"introduction": "Our final practice integrates the maximum entropy framework into a complete Bayesian inverse problem, demonstrating its role in practical data assimilation. Here, we tackle the common challenge of inferring a strictly positive physical quantity by placing a MaxEnt prior on its logarithm, leading to a log-normal prior distribution [@problem_id:3401766]. You will formulate the full maximum a posteriori (MAP) objective function and implement a Newton-type optimization algorithm to find the solution, thereby combining prior knowledge with observed data to obtain the most probable estimate.", "problem": "Consider an inverse problem for a positive parameter vector where positivity is encoded by the componentwise exponential transformation. Let $y \\in \\mathbb{R}^n$ and define $x \\in \\mathbb{R}^n$ by $x_i = \\exp(y_i)$ for all $i \\in \\{1,\\dots,n\\}$. Assume that the physical forward model produces observations $d \\in \\mathbb{R}^m$ from $x$ via a linear map in $x$ with additive noise: $d = M x + e$, where $M \\in \\mathbb{R}^{m \\times n}$ is known and $e$ is an additive noise vector modeled as a realization of a Gaussian distribution with zero mean and a known, positive-definite covariance matrix $R \\in \\mathbb{R}^{m \\times m}$. The goal is to formulate a prior for $y$ using the Maximum Entropy (MaxEnt) principle under simple moment constraints and compute the Maximum A Posteriori (MAP) estimate of $y$ using a Newton-type method. Then report diagnostics that quantify the data misfit and the prior deviation at the MAP estimate, together with a representative component of the recovered positive parameter $x$.\n\nYou must proceed from a valid fundamental base appropriate for inverse problems and data assimilation:\n- The Shannon entropy of a probability density function $p$ on $\\mathbb{R}^n$ is defined by $H[p] = - \\int_{\\mathbb{R}^n} p(y) \\log p(y) \\, dy$.\n- The Maximum Entropy (MaxEnt) principle (Jaynes) prescribes choosing $p$ to maximize Shannon entropy subject to known expectation constraints and normalization.\n- A Gaussian likelihood arises from additive Gaussian noise: if $e \\sim \\mathcal{N}(0,R)$, then the likelihood for $d$ given $y$ is proportional to $\\exp\\left(-\\tfrac{1}{2}(M \\exp(y) - d)^\\top R^{-1} (M \\exp(y) - d)\\right)$, where the exponential is componentwise.\n- The Maximum A Posteriori (MAP) estimate is the minimizer of the negative log-posterior.\n\nTasks:\n- Using only the fundamentals listed above, derive the MaxEnt prior on $y$ when the only information available is $E[y] = \\mu$ and $\\mathrm{Var}(y) = \\sigma^2 I$, where $\\mu \\in \\mathbb{R}^n$ and $\\sigma^2  0$ are given and $I$ is the identity matrix. In your derivation, you must treat the constraints as componentwise moment constraints and justify the independence implied by the MaxEnt solution under these constraints. Do not assume any prior functional form for $p(y)$.\n- Using the derived prior, set up the negative log-posterior objective for the MAP problem in the variable $y$. Derive its gradient and Hessian with respect to $y$ from first principles using the chain rule and matrix calculus; all derivatives must be explicit in terms of $M$, $R$, $\\mu$, $\\sigma^2$, and $y$.\n- Design a globally convergent Newton-type algorithm with a backtracking line search and a simple positive-definiteness safeguard (such as diagonal damping) to solve for the MAP estimate $\\hat{y}$. Your algorithm must:\n  - Use the full Hessian you derived (not a Gauss–Newton approximation alone).\n  - Enforce sufficient decrease via the Armijo condition with a backtracking factor in $(0,1)$ and a small Armijo parameter in $(0,1)$.\n  - Include a safeguard that ensures the linear system for the Newton step is solved with a symmetric positive-definite matrix (e.g., add a multiple of the identity matrix to the Hessian until a Cholesky factorization succeeds).\n- After computing $\\hat{y}$, recover $\\hat{x}$ via $\\hat{x}_i = \\exp(\\hat{y}_i)$ and compute the following diagnostics:\n  - The misfit contribution $J_{\\mathrm{mis}}(\\hat{y}) = \\tfrac{1}{2} (M \\exp(\\hat{y}) - d)^\\top R^{-1} (M \\exp(\\hat{y}) - d)$.\n  - The prior contribution $J_{\\mathrm{prior}}(\\hat{y}) = \\tfrac{1}{2} (\\hat{y} - \\mu)^\\top (\\sigma^2 I)^{-1} (\\hat{y} - \\mu)$.\n  - The first component $\\hat{x}_1 = \\exp(\\hat{y}_1)$.\n\nUse the following fixed, fully specified instance of the forward model and data, which serve as a permeability inversion toy model:\n- Dimension: $n = 3$, $m = 2$.\n- Forward matrix $M \\in \\mathbb{R}^{2 \\times 3}$:\n  - $M = \\begin{bmatrix} 1.0  0.5  -0.2 \\\\ 0.0  1.0  0.3 \\end{bmatrix}$.\n- True (but unknown to the algorithm) $y_{\\mathrm{true}} = \\begin{bmatrix} 0.5 \\\\ -0.7 \\\\ 0.2 \\end{bmatrix}$, used only to construct $d$; the corresponding $x_{\\mathrm{true}} = \\exp(y_{\\mathrm{true}})$ is componentwise.\n- Deterministic noise realization $e = \\begin{bmatrix} 0.05 \\\\ -0.02 \\end{bmatrix}$ in the data.\n- Data $d = M \\, x_{\\mathrm{true}} + e$, which evaluates numerically to $d = \\begin{bmatrix} 1.702733370963799 \\\\ 0.8430061312394604 \\end{bmatrix}$.\n- Noise covariance $R = \\mathrm{diag}(1.0, 1.0)$, so that $R^{-1} = \\mathrm{diag}(1.0, 1.0)$.\n\nTest suite:\n- You must run the MAP solver for the following four cases, changing only the MaxEnt prior parameters $(\\mu, \\sigma^2)$:\n  1. Case A (happy path, moderate dispersion): $\\mu = \\begin{bmatrix} 0.0 \\\\ 0.0 \\\\ 0.0 \\end{bmatrix}$, $\\sigma^2 = 0.25$.\n  2. Case B (strong prior, small variance): $\\mu = \\begin{bmatrix} 0.0 \\\\ 0.0 \\\\ 0.0 \\end{bmatrix}$, $\\sigma^2 = 0.01$.\n  3. Case C (weak prior, large variance): $\\mu = \\begin{bmatrix} 0.0 \\\\ 0.0 \\\\ 0.0 \\end{bmatrix}$, $\\sigma^2 = 25.0$.\n  4. Case D (shifted mean, moderate dispersion): $\\mu = \\begin{bmatrix} 0.1 \\\\ -0.2 \\\\ 0.3 \\end{bmatrix}$, $\\sigma^2 = 0.25$.\n\nProgram requirements:\n- Implement the Newton-type solver described above to compute $\\hat{y}$ for each case, starting from the initial guess $y^{(0)} = \\mu$.\n- For each case, output a list $[J_{\\mathrm{mis}}(\\hat{y}), J_{\\mathrm{prior}}(\\hat{y}), \\hat{x}_1]$ of three floating-point numbers in this order.\n\nFinal output format:\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each item is itself a list of three numbers corresponding to one test case, in the order Cases A, B, C, D. For example, the output must look like $[[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3],[a_4,b_4,c_4]]$, with no spaces required and where each $a_i$, $b_i$, $c_i$ is a decimal floating-point number. No physical units apply in this problem. Angles are not used. Percentages are not used.", "solution": "The problem statement is assessed to be valid. It is scientifically grounded in the principles of Bayesian inverse theory, internally consistent, and well-posed as a computational task. We may therefore proceed with a complete solution.\n\nThe solution is presented in four parts as requested: (1) derivation of the Maximum Entropy prior, (2) formulation of the MAP objective function and derivation of its gradient and Hessian, (3) description of the numerical algorithm, and (4) computation of the required diagnostics for the specified test cases.\n\n### 1. Derivation of the Maximum Entropy Prior\n\nThe task is to find the probability density function $p(y)$ for $y \\in \\mathbb{R}^n$ that maximizes the Shannon entropy $H[p] = - \\int_{\\mathbb{R}^n} p(y) \\log p(y) \\, dy$ subject to a set of constraints. The given constraints are on the first and second moments of the components of $y$:\n1.  Normalization: $\\int_{\\mathbb{R}^n} p(y) \\, dy = 1$.\n2.  Mean: $E[y_i] = \\mu_i$ for $i \\in \\{1, \\dots, n\\}$.\n3.  Variance: $\\mathrm{Var}(y_i) = \\sigma^2  0$ for $i \\in \\{1, \\dots, n\\}$.\n4.  Covariance: $\\mathrm{Cov}(y_i, y_j) = 0$ for $i \\neq j$.\n\nThe variance and covariance constraints together are equivalent to the matrix constraint $\\mathrm{Var}(y) = \\sigma^2 I$, where $I$ is the $n \\times n$ identity matrix.\n\nThe Maximum Entropy principle states that for constraints on the expectations of a set of functions $\\{f_k(y)\\}$, i.e., $E[f_k(y)] = c_k$, the resulting probability density has the form $p(y) = \\frac{1}{Z} \\exp\\left(-\\sum_k \\lambda_k f_k(y)\\right)$, where $\\lambda_k$ are Lagrange multipliers and $Z$ is a normalization constant.\n\nOur constraints can be expressed in terms of expectations. The variance and covariance constraints are $E[(y_i - \\mu_i)^2] = \\sigma^2$ and $E[(y_i - \\mu_i)(y_j - \\mu_j)] = 0$ for $i \\neq j$. This is a complete set of constraints on the first and second central moments. The general form of the MaxEnt distribution given these moment constraints is a multivariate Gaussian. A multivariate Gaussian distribution is uniquely defined by its mean vector and covariance matrix.\n\nThe given constraints directly specify these parameters:\n- The mean vector is $E[y] = \\mu$.\n- The covariance matrix is $\\mathrm{Var}(y) = \\sigma^2 I$.\n\nTherefore, the MaxEnt prior distribution on $y$ is the multivariate normal distribution $\\mathcal{N}(\\mu, \\sigma^2 I)$. The probability density function is:\n$$\np_{\\mathrm{prior}}(y) = \\frac{1}{(2\\pi)^{n/2} |\\sigma^2 I|^{1/2}} \\exp\\left( -\\frac{1}{2} (y - \\mu)^\\top (\\sigma^2 I)^{-1} (y - \\mu) \\right)\n$$\n$$\np_{\\mathrm{prior}}(y) = \\frac{1}{(2\\pi \\sigma^2)^{n/2}} \\exp\\left( -\\frac{1}{2\\sigma^2} \\sum_{i=1}^n (y_i - \\mu_i)^2 \\right)\n$$\nThis density can be factored into a product of one-dimensional Gaussian densities:\n$$\np_{\\mathrm{prior}}(y) = \\prod_{i=1}^n \\left[ \\frac{1}{\\sqrt{2\\pi \\sigma^2}} \\exp\\left( -\\frac{(y_i - \\mu_i)^2}{2\\sigma^2} \\right) \\right] = \\prod_{i=1}^n p_i(y_i)\n$$\nwhere $p_i(y_i) = \\mathcal{N}(y_i | \\mu_i, \\sigma^2)$. The factorizable form demonstrates that the components $y_i$ are statistically independent. This independence is not an a priori assumption but a consequence of applying the MaxEnt principle to constraints where all specified cross-correlations are zero.\n\n### 2. MAP Objective Function, Gradient, and Hessian\n\nThe Maximum A Posteriori (MAP) estimate $\\hat{y}$ is found by maximizing the posterior probability density $p(y|d)$. By Bayes' theorem, $p(y|d) \\propto p(d|y)p_{\\mathrm{prior}}(y)$. Maximizing the posterior is equivalent to minimizing its negative logarithm. We define the objective function $J(y)$ as the negative log-posterior, omitting constants that do not depend on $y$.\n\n$$\nJ(y) = -\\log p(d|y) - \\log p_{\\mathrm{prior}}(y) = J_{\\mathrm{mis}}(y) + J_{\\mathrm{prior}}(y)\n$$\n\nThe likelihood term $J_{\\mathrm{mis}}(y)$ arises from the Gaussian noise model $e \\sim \\mathcal{N}(0, R)$, which gives $p(d|y) \\propto \\exp\\left(-\\frac{1}{2}(M \\exp(y) - d)^\\top R^{-1} (M \\exp(y) - d)\\right)$.\n$$\nJ_{\\mathrm{mis}}(y) = \\frac{1}{2} (M \\exp(y) - d)^\\top R^{-1} (M \\exp(y) - d)\n$$\nThe prior term $J_{\\mathrm{prior}}(y)$ is the negative logarithm of the derived MaxEnt prior:\n$$\nJ_{\\mathrm{prior}}(y) = \\frac{1}{2} (y - \\mu)^\\top (\\sigma^2 I)^{-1} (y - \\mu) = \\frac{1}{2\\sigma^2} \\|y - \\mu\\|_2^2\n$$\nThe total objective function to be minimized is:\n$$\nJ(y) = \\frac{1}{2} (M \\exp(y) - d)^\\top R^{-1} (M \\exp(y) - d) + \\frac{1}{2\\sigma^2} (y - \\mu)^\\top (y - \\mu)\n$$\n\nTo employ a Newton-type optimization method, we must compute the gradient $\\nabla J(y)$ and Hessian $\\nabla^2 J(y)$.\n\n**Gradient $\\nabla J(y)$**:\nWe compute the gradient of each term separately.\nFor the prior term: $\\nabla J_{\\mathrm{prior}}(y) = \\frac{1}{\\sigma^2} (y - \\mu)$.\nFor the misfit term, we use the chain rule. Let $g(y) = M \\exp(y) - d$. The Jacobian of $g(y)$ is $D_y g = M \\cdot D_y(\\exp(y))$. The Jacobian of the componentwise exponential function $\\exp(y)$ is a diagonal matrix $E(y) = \\mathrm{diag}(\\exp(y_1), \\dots, \\exp(y_n))$. Thus, $D_y g = M E(y)$.\nThe gradient is $\\nabla J_{\\mathrm{mis}}(y) = (D_y g)^\\top R^{-1} g(y) = (M E(y))^\\top R^{-1} (M \\exp(y) - d)$. Since $E(y)$ is diagonal, its transpose is itself.\n$$\n\\nabla J_{\\mathrm{mis}}(y) = E(y) M^\\top R^{-1} (M \\exp(y) - d)\n$$\nThe total gradient is:\n$$\n\\nabla J(y) = E(y) M^\\top R^{-1} (M \\exp(y) - d) + \\frac{1}{\\sigma^2} (y - \\mu)\n$$\n\n**Hessian $\\nabla^2 J(y)$**:\nThe Hessian of the prior term is $\\nabla^2 J_{\\mathrm{prior}}(y) = \\frac{1}{\\sigma^2} I$.\nFor the misfit term, we differentiate its gradient. Using the product rule and chain rule for matrix calculus, the Hessian of $\\frac{1}{2} g(y)^\\top A g(y)$ is $(D_y g)^\\top A (D_y g) + \\sum_{i=1}^m (A g(y))_i \\nabla^2 g_i(y)$.\nThe first part is the Gauss-Newton approximation to the Hessian:\n$$\nH_{\\mathrm{GN}} = (M E(y))^\\top R^{-1} (M E(y)) = E(y) M^\\top R^{-1} M E(y)\n$$\nFor the second part, the $i$-th component of $g(y)$ is $g_i(y) = \\sum_{j=1}^n M_{ij} \\exp(y_j) - d_i$. Its Hessian $\\nabla^2 g_i(y)$ is a diagonal matrix with entries $\\frac{\\partial^2 g_i}{\\partial y_k^2} = M_{ik} \\exp(y_k)$.\nThe full second term is a sum of matrices, which results in a single diagonal matrix whose $k$-th diagonal entry is $\\exp(y_k) \\left( M^\\top R^{-1} (M \\exp(y) - d) \\right)_k$. We denote this matrix as $\\mathrm{diag}(E(y) M^\\top R^{-1} (M \\exp(y) - d))$.\nThe total Hessian is:\n$$\n\\nabla^2 J(y) = \\underbrace{E(y) M^\\top R^{-1} M E(y)}_{\\text{Gauss-Newton}} + \\underbrace{\\mathrm{diag}\\left(E(y) M^\\top R^{-1} (M \\exp(y) - d)\\right)}_{\\text{Second-order term}} + \\underbrace{\\frac{1}{\\sigma^2} I}_{\\text{Prior Hessian}}\n$$\nThe second-order term can have negative entries, making the full Hessian indefinite. This motivates the need for a safeguard in the Newton algorithm.\n\n### 3. Newton-Type Algorithm Design\n\nWe implement a damped Newton method to find the minimizer $\\hat{y}$ of $J(y)$. The algorithm starts from an initial guess $y^{(0)} = \\mu$ and iteratively refines the estimate.\n\n**Algorithm: Damped Newton with Line Search**\n1.  **Initialization**: Set $k = 0$, $y^{(0)} \\leftarrow \\mu$. Define tolerance `tol`, Armijo parameter $c_1 \\in (0,1)$, and backtracking factor $\\rho \\in (0,1)$.\n2.  **Iteration**: For $k = 0, 1, 2, \\dots$ until convergence:\n    a.  Compute the gradient $g_k = \\nabla J(y^{(k)})$ and Hessian $H_k = \\nabla^2 J(y^{(k)})$.\n    b.  If $\\|g_k\\|  \\mathrm{tol}$, terminate and return $\\hat{y} = y^{(k)}$.\n    c.  **Safeguard Hessian**: Solve the Newton system $(H_k + \\tau I) p_k = -g_k$.\n        i.  Start with a damping parameter $\\tau = 0$.\n        ii. Attempt Cholesky factorization $L L^\\top = H_k + \\tau I$.\n        iii. If factorization fails (matrix not positive-definite), increase $\\tau$ (e.g., set $\\tau = 10^{-6}$ if it was $0$, else multiply by $10$) and repeat.\n    d.  **Solve for search direction**: Solve the linear system for $p_k$ using the computed Cholesky factors $L L^\\top$.\n    e.  **Backtracking Line Search**: Find a step size $\\alpha_k \\in (0, 1]$.\n        i.  Start with $\\alpha = 1$.\n        ii. While the Armijo condition $J(y^{(k)} + \\alpha p_k)  J(y^{(k)}) + c_1 \\alpha g_k^\\top p_k$ is not met, update $\\alpha \\leftarrow \\rho \\alpha$.\n        iii. Set $\\alpha_k = \\alpha$.\n    f.  **Update**: $y^{(k+1)} \\leftarrow y^{(k)} + \\alpha_k p_k$.\n\nThis algorithm guarantees descent at each step and convergence to a local minimum of $J(y)$.\n\n### 4. Diagnostics and Results\n\nAfter the Newton solver converges to the MAP estimate $\\hat{y}$, we compute the required diagnostics. The recovered positive parameters are $\\hat{x} = \\exp(\\hat{y})$.\n-   Misfit contribution: $J_{\\mathrm{mis}}(\\hat{y}) = \\frac{1}{2} (M \\exp(\\hat{y}) - d)^\\top R^{-1} (M \\exp(\\hat{y}) - d)$.\n-   Prior contribution: $J_{\\mathrm{prior}}(\\hat{y}) = \\frac{1}{2\\sigma^2} \\|\\hat{y} - \\mu\\|_2^2$.\n-   First component of recovered parameter: $\\hat{x}_1 = \\exp(\\hat{y}_1)$.\n\nThe implementation below computes these values for the four specified test cases. The results demonstrate the influence of the prior parameters $(\\mu, \\sigma^2)$ on the solution. A small $\\sigma^2$ (strong prior) forces the solution $\\hat{y}$ to be close to the prior mean $\\mu$, potentially at the cost of a large data misfit. A large $\\sigma^2$ (weak prior) allows the solution to be primarily driven by the data, resulting in a small misfit but a large deviation from the prior mean.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to solve the MAP estimation problem for all test cases.\n    \"\"\"\n    \n    # Define the fixed model parameters and data from the problem statement.\n    M = np.array([[1.0, 0.5, -0.2], [0.0, 1.0, 0.3]])\n    d = np.array([1.702733370963799, 0.8430061312394604])\n    R_inv = np.identity(2)  # R = I, so R_inv = I\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: Happy path, moderate dispersion\n        {'mu': np.array([0.0, 0.0, 0.0]), 'sigma2': 0.25},\n        # Case B: Strong prior, small variance\n        {'mu': np.array([0.0, 0.0, 0.0]), 'sigma2': 0.01},\n        # Case C: Weak prior, large variance\n        {'mu': np.array([0.0, 0.0, 0.0]), 'sigma2': 25.0},\n        # Case D: Shifted mean, moderate dispersion\n        {'mu': np.array([0.1, -0.2, 0.3]), 'sigma2': 0.25},\n    ]\n\n    # Newton solver parameters\n    tol = 1e-9\n    max_iter = 50\n    armijo_c1 = 1e-4\n    backtrack_rho = 0.5\n    \n    results = []\n    for case in test_cases:\n        mu = case['mu']\n        sigma2 = case['sigma2']\n        \n        # Initial guess is the prior mean\n        y0 = np.copy(mu)\n        \n        # Run the Newton solver to find the MAP estimate y_hat\n        y_hat = newton_map_solver(\n            M, d, R_inv, mu, sigma2, y0, \n            tol, max_iter, armijo_c1, backtrack_rho\n        )\n        \n        x_hat = np.exp(y_hat)\n        \n        # Compute diagnostics at the MAP estimate\n        residual = M @ x_hat - d\n        j_mis = 0.5 * residual.T @ R_inv @ residual\n        \n        prior_diff = y_hat - mu\n        j_prior = 0.5 * (prior_diff.T @ prior_diff) / sigma2\n        \n        x1_hat = x_hat[0]\n        \n        results.append([j_mis, j_prior, x1_hat])\n\n    # Final print statement in the exact required format.\n    formatted_results = \",\".join([f\"[{r[0]},{r[1]},{r[2]}]\" for r in results])\n    print(f\"[{formatted_results}]\")\n\ndef objective_function(y, M, d, R_inv, mu, sigma2):\n    \"\"\"Computes the negative log-posterior objective function J(y).\"\"\"\n    x = np.exp(y)\n    \n    residual = M @ x - d\n    j_mis = 0.5 * residual.T @ R_inv @ residual\n    \n    prior_diff = y - mu\n    j_prior = 0.5 * (prior_diff.T @ prior_diff) / sigma2\n    \n    return j_mis + j_prior\n\ndef gradient(y, M, d, R_inv, mu, sigma2):\n    \"\"\"Computes the gradient of J(y).\"\"\"\n    x = np.exp(y)\n    \n    grad_mis = np.diag(x) @ M.T @ R_inv @ (M @ x - d)\n    grad_prior = (y - mu) / sigma2\n    \n    return grad_mis + grad_prior\n\ndef hessian(y, M, d, R_inv, mu, sigma2):\n    \"\"\"Computes the Hessian of J(y).\"\"\"\n    x = np.exp(y)\n    E_y = np.diag(x)\n    \n    H_gn = E_y @ M.T @ R_inv @ M @ E_y\n    H_so = np.diag(E_y @ M.T @ R_inv @ (M @ x - d))\n    H_prior = np.identity(len(y)) / sigma2\n    \n    return H_gn + H_so + H_prior\n\ndef newton_map_solver(M, d, R_inv, mu, sigma2, y0, tol, max_iter, armijo_c1, backtrack_rho):\n    \"\"\"\n    Solves for the MAP estimate using a safeguarded Newton-type method.\n    \"\"\"\n    y = np.copy(y0)\n    n_dim = len(y)\n    \n    for _ in range(max_iter):\n        J = objective_function(y, M, d, R_inv, mu, sigma2)\n        g = gradient(y, M, d, R_inv, mu, sigma2)\n        \n        if linalg.norm(g)  tol:\n            break\n            \n        H = hessian(y, M, d, R_inv, mu, sigma2)\n        \n        # Safeguard Hessian via diagonal damping until positive-definite.\n        tau = 0.0\n        while True:\n            try:\n                H_reg = H + tau * np.identity(n_dim)\n                L = linalg.cholesky(H_reg, lower=True)\n                break\n            except linalg.LinAlgError:\n                if tau == 0.0:\n                    tau = 1e-6\n                else:\n                    tau *= 10.0\n        \n        # Solve Newton system p = -(H + tau*I)^-1 * g using Cholesky factor.\n        z = linalg.solve_triangular(L, -g, lower=True, check_finite=False)\n        p = linalg.solve_triangular(L.T, z, lower=False, check_finite=False)\n        \n        # Backtracking line search to enforce sufficient decrease (Armijo condition).\n        alpha = 1.0\n        g_dot_p = g.T @ p\n        \n        # Added a check for very small g_dot_p to prevent long loops for flat regions\n        if abs(g_dot_p)  1e-14:\n            break\n            \n        while True:\n            y_new = y + alpha * p\n            J_new = objective_function(y_new, M, d, R_inv, mu, sigma2)\n            \n            if J_new = J + armijo_c1 * alpha * g_dot_p:\n                break\n            \n            alpha *= backtrack_rho\n            # Break if step size becomes excessively small\n            if alpha  1e-12:\n                break\n        \n        y += alpha * p\n        \n    return y\n\nsolve()\n```", "id": "3401766"}]}