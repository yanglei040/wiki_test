{"hands_on_practices": [{"introduction": "In any model-based inverse problem, the forward solver is the cornerstone upon which all subsequent analysis is built. Before we can trust an inversion result, we must rigorously verify that our numerical code accurately solves the underlying physical equations. This practice guides you through building and validating a forward solver for the acoustic wave equation using the method of manufactured solutions [@problem_id:3410161], a gold standard in scientific computing for confirming the theoretical convergence rate of a numerical scheme.", "problem": "Consider the standard forward model for Photoacoustic Tomography (PAT) under the small-signal, lossless, homogeneous medium assumption. The acoustic pressure field satisfies the linear wave equation\n$$\n\\partial_{tt} p(x,t) - c^2 \\partial_{xx} p(x,t) = 0 \\quad \\text{for } x \\in [0,L], \\ t \\ge 0,\n$$\nwith periodic boundary conditions on the spatial interval, initial displacement $p(x,0) = p_0(x)$, and initial velocity $\\partial_t p(x,0) = v_0(x)$. Here $c$ is the (constant) speed of sound. In Photoacoustic Tomography, the initial pressure $p_0(x)$ is proportional to the absorbed optical energy density and $v_0(x)=0$ due to the nature of thermoelastic expansion following short-pulse illumination.\n\nYou will validate a numerical forward solver using the method of manufactured solutions. All quantities are nondimensional (unitless). The solver must be second-order accurate in both space and time. You must start from fundamental conservation laws and constitutive relations as the base for your derivations (mass conservation, momentum conservation, and a linear equation of state), not from pre-derived discretization formulas.\n\nManufactured solutions:\n\n1) Homogeneous wave equation: Choose a smooth periodic solution\n$$\np(x,t) = \\sin(k x)\\cos(c k t),\n$$\nwith $k = 2\\pi m$, where $m$ is a positive integer. This satisfies the homogeneous wave equation with initial data $p(x,0) = \\sin(k x)$ and $\\partial_t p(x,0)=0$.\n\n2) Forced wave equation: To isolate temporal convergence independently of spatial discretization error, use a spatially uniform manufactured solution\n$$\np(x,t) = \\cos(\\omega t),\n$$\nwhich satisfies\n$$\n\\partial_{tt} p(x,t) - c^2 \\partial_{xx} p(x,t) = S(x,t),\n$$\nwith manufactured source\n$$\nS(x,t) = -\\omega^2 \\cos(\\omega t).\n$$\nUse initial data $p(x,0)=\\cos(0)=1$ and $\\partial_t p(x,0)=0$.\n\nYour tasks:\n\n- Derive from the fundamental acoustic equations that the pressure field satisfies the stated wave equation with the given initial data for PAT.\n\n- Construct a consistent second-order accurate numerical method in one spatial dimension with periodic boundary conditions. The method must be explicit in time and second-order accurate in both space and time when applied to smooth data. Use a fixed spatial grid with $N$ points and a uniform time step $\\Delta t$. The final time $T$ must be exactly representable as an integer multiple of $\\Delta t$.\n\n- Implement the solver so that it can handle both the homogeneous equation and the forced equation with a general source term $S(x,t)$, and so that it supports the initial conditions stated above. The program must compute the solution at time $T$ and compare it to the exact manufactured solution to produce an error.\n\n- Use the discrete $L^2$ error defined by\n$$\nE = \\left( \\sum_{i=0}^{N-1} \\left[p_i^{\\mathrm{num}}(T) - p^{\\mathrm{exact}}(x_i,T)\\right]^2 \\Delta x \\right)^{1/2},\n$$\nwhere $\\Delta x = L/N$ and $x_i = i \\Delta x$.\n\n- Empirical convergence rates: Given two errors $E_1$ and $E_2$ corresponding to refinements by a factor of $r$ in the relevant step size (e.g., halving $\\Delta x$ or $\\Delta t$ so $r=2$), compute the observed order\n$$\nq = \\frac{\\log(E_1/E_2)}{\\log(r)}.\n$$\n\nTest suite and required output:\n\nImplement the following test suite, each test producing a float error and, where applicable, an empirical order. All quantities are nondimensional.\n\n- Test A (spatial convergence dominated): Homogeneous case with $c=1$, $L=1$, $m=3$, $k=2\\pi m$, final time $T=0.01$. Use three grids with $N \\in \\{50, 100, 200\\}$. For temporal stepping choose $\\Delta t = \\alpha (\\Delta x)^2$ with $\\alpha=0.2$. This ensures the temporal truncation error is negligible compared to the spatial truncation error at these resolutions. Compute the discrete $L^2$ errors $E_N$ for each $N$, and then compute the observed order using $q_{\\text{space}} = \\frac{1}{2}\\left( \\frac{\\log(E_{50}/E_{100})}{\\log 2} + \\frac{\\log(E_{100}/E_{200})}{\\log 2} \\right)$.\n\n- Test B (temporal convergence only via manufactured source): Forced case with $c=1$, $L=1$, uniform in space manufactured solution $p(x,t)=\\cos(\\omega t)$, $\\omega=7$. Use a fixed spatial grid $N=64$ (so that the spatial Laplacian of a constant field is exactly zero on the periodic grid, eliminating spatial error). Final time $T=0.2$. Use three time steps $\\Delta t \\in \\{0.02, 0.01, 0.005\\}$, each chosen so that $T$ is an integer multiple of $\\Delta t$. Compute the discrete $L^2$ errors $E_{\\Delta t}$ and the observed temporal order\n$$\nq_{\\text{time}} = \\frac{1}{2}\\left( \\frac{\\log(E_{0.02}/E_{0.01})}{\\log 2} + \\frac{\\log(E_{0.01}/E_{0.005})}{\\log 2} \\right).\n$$\n\n- Test C (edge case consistency): Homogeneous case with the same parameters as Test A but with $T=0$. The numerical solution must equal the initial condition, so the discrete $L^2$ error must be numerically zero. Report whether the error is less than a tolerance $\\varepsilon=10^{-12}$ as a boolean.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets in the following order:\n- The observed spatial convergence order $q_{\\text{space}}$ from Test A as a float.\n- The observed temporal convergence order $q_{\\text{time}}$ from Test B as a float.\n- A boolean indicating whether $q_{\\text{space}} \\ge 1.8$.\n- A boolean indicating whether $q_{\\text{time}} \\ge 1.8$.\n- A boolean from Test C indicating whether the $T=0$ error is less than $\\varepsilon$.\n\nFor example, the output format must be exactly like\n\"[2.01,1.99,True,True,True]\"\n\nAll computed quantities are nondimensional. Angles, where they appear in trigonometric functions, are in radians. The final answers for the observed orders must be printed as plain decimal floats (not percentages), and booleans must be Python-style True or False.", "solution": "The problem is valid. It presents a well-posed, scientifically grounded task in computational physics: to derive, implement, and validate a numerical solver for the one-dimensional acoustic wave equation as a forward model for Photoacoustic Tomography (PAT). The use of the method of manufactured solutions for verification is a standard and rigorous approach in scientific computing. All parameters and test cases are clearly defined and physically and numerically consistent.\n\n### 1. Derivation of the Governing Equation\n\nThe behavior of sound waves in a fluid is described by the fundamental principles of mass and momentum conservation, along with an equation of state relating pressure and density. For a lossless, homogeneous medium under the small-signal assumption, these are expressed as the linearized acoustic equations. In one spatial dimension, $x$, they are:\n\n1.  **Conservation of Mass (Continuity Equation):** This principle states that the rate of change of mass in a volume is equal to the net flux of mass into it. For small perturbations, this linearizes to:\n    $$ \\frac{\\partial \\rho'}{\\partial t} + \\rho_a \\frac{\\partial v}{\\partial x} = 0 $$\n    Here, $\\rho'(x,t)$ is the acoustic density perturbation, $v(x,t)$ is the fluid particle velocity, and $\\rho_a$ is the ambient fluid density.\n\n2.  **Conservation of Momentum (Euler's Equation):** This is Newton's second law applied to a fluid element. The net force due to a pressure gradient accelerates the fluid. The linearized form is:\n    $$ \\rho_a \\frac{\\partial v}{\\partial t} = -\\frac{\\partial p}{\\partial x} $$\n    Here, $p(x,t)$ is the acoustic pressure.\n\n3.  **Equation of State:** For a rapid acoustic process (which is approximately adiabatic), the pressure and density are related. For small perturbations, this relationship is linear:\n    $$ p = c^2 \\rho' $$\n    The constant of proportionality, $c^2$, is defined by the medium's properties, where $c$ is the speed of sound, given by $c = \\sqrt{(\\partial P / \\partial \\rho)_S}$ evaluated at ambient conditions.\n\nTo derive the wave equation for pressure $p$, we combine these three equations. First, we differentiate the momentum equation with respect to $x$ and the continuity equation with respect to $t$:\n$$ \\rho_a \\frac{\\partial^2 v}{\\partial t \\partial x} = -\\frac{\\partial^2 p}{\\partial x^2} $$\n$$ \\frac{\\partial^2 \\rho'}{\\partial t^2} + \\rho_a \\frac{\\partial^2 v}{\\partial x \\partial t} = 0 $$\nAssuming sufficient smoothness, the order of differentiation does not matter ($\\partial_{tx}v = \\partial_{xt}v$). We can substitute the expression for $\\rho_a \\partial_{tx}v$ from the first equation into the second:\n$$ \\frac{\\partial^2 \\rho'}{\\partial t^2} + \\left( -\\frac{\\partial^2 p}{\\partial x^2} \\right) = 0 \\implies \\frac{\\partial^2 \\rho'}{\\partial t^2} = \\frac{\\partial^2 p}{\\partial x^2} $$\nNow, using the equation of state, we replace $\\rho'$ with $p/c^2$. Since $c$ is a constant, we can write $\\partial_{tt}\\rho' = (1/c^2) \\partial_{tt}p$. Substituting this yields:\n$$ \\frac{1}{c^2} \\frac{\\partial^2 p}{\\partial t^2} = \\frac{\\partial^2 p}{\\partial x^2} $$\nRearranging gives the standard homogeneous linear wave equation:\n$$ \\frac{\\partial^2 p}{\\partial t^2} - c^2 \\frac{\\partial^2 p}{\\partial x^2} = 0 $$\nIn Photoacoustic Tomography, tissue is illuminated by a short laser pulse. The absorbed energy causes rapid, localized heating and thermoelastic expansion, which creates an initial pressure distribution $p(x,0) = p_0(x)$. Because this process is assumed to occur before any significant material motion, the initial fluid velocity is zero, i.e., $v(x,0)=0$. From the continuity equation and equation of state, we have $\\partial_t p = c^2 \\partial_t \\rho' = -c^2 \\rho_a \\partial_x v$. Evaluating at $t=0$, we get $\\partial_t p(x,0) = -c^2 \\rho_a \\partial_x v(x,0)$. Since $v(x,0)=0$ for all $x$, its spatial derivative is also zero, which leads to the initial condition $\\partial_t p(x,0) = 0$.\n\n### 2. Numerical Discretization\n\nWe are tasked with constructing a second-order accurate, explicit finite difference scheme for the wave equation, possibly including a source term $S(x,t)$:\n$$ \\partial_{tt} p - c^2 \\partial_{xx} p = S(x,t) $$\nWe define a discrete grid with points $(x_i, t_n)$ where $x_i = i \\Delta x$ for $i=0, \\dots, N-1$ and $t_n = n \\Delta t$. The numerical solution at these points is denoted $p_i^n \\approx p(x_i, t_n)$.\n\nA second-order accurate approximation for the spatial and temporal derivatives is achieved using central differences:\n$$ \\partial_{xx} p \\bigg|_{(x_i, t_n)} \\approx \\frac{p_{i+1}^n - 2p_i^n + p_{i-1}^n}{(\\Delta x)^2} + \\mathcal{O}((\\Delta x)^2) $$\n$$ \\partial_{tt} p \\bigg|_{(x_i, t_n)} \\approx \\frac{p_i^{n+1} - 2p_i^n + p_i^{n-1}}{(\\Delta t)^2} + \\mathcal{O}((\\Delta t)^2) $$\nSubstituting these into the wave equation gives the discretized form:\n$$ \\frac{p_i^{n+1} - 2p_i^n + p_i^{n-1}}{(\\Delta t)^2} - c^2 \\frac{p_{i+1}^n - 2p_i^n + p_{i-1}^n}{(\\Delta x)^2} = S_i^n $$\nSolving for the pressure at the next time step, $p_i^{n+1}$, yields the explicit time-marching formula:\n$$ p_i^{n+1} = 2p_i^n - p_i^{n-1} + \\left(\\frac{c\\Delta t}{\\Delta x}\\right)^2 (p_{i+1}^n - 2p_i^n + p_{i-1}^n) + (\\Delta t)^2 S_i^n $$\nThis is a three-level scheme, requiring data from two previous time levels, $t_n$ and $t_{n-1}$. For numerical stability, the Courant-Friedrichs-Lewy (CFL) condition must be met: $\\sigma = c\\Delta t/\\Delta x \\le 1$.\n\nTo start the simulation, we need $p^0$ and $p^1$. The initial condition $p(x,0)=p_0(x)$ gives $p_i^0 = p_0(x_i)$. To find $p_i^1$ while maintaining second-order accuracy, we use the initial condition $\\partial_t p(x,0) = 0$. A second-order central difference for this derivative at $t=0$ is $(\\frac{p_i^1 - p_i^{-1}}{2\\Delta t}) = 0$, implying $p_i^1 = p_i^{-1}$. Substituting this into the general scheme for $n=0$:\n$$ p_i^1 = 2p_i^0 - p_i^{-1} + \\sigma^2 (p_{i+1}^0 - 2p_i^0 + p_{i-1}^0) + (\\Delta t)^2 S_i^0 $$\n$$ p_i^1 = 2p_i^0 - p_i^1 + \\sigma^2 (p_{i+1}^0 - 2p_i^0 + p_{i-1}^0) + (\\Delta t)^2 S_i^0 $$\nSolving for $p_i^1$ gives the second-order accurate starter formula:\n$$ p_i^1 = p_i^0 + \\frac{1}{2} \\sigma^2 (p_{i+1}^0 - 2p_i^0 + p_{i-1}^0) + \\frac{1}{2}(\\Delta t)^2 S_i^0 $$\nPeriodic boundary conditions on $[0,L]$ imply $p(x,t) = p(x+L,t)$, which on the discrete grid means $p_N^n = p_0^n$ and $p_{-1}^n = p_{N-1}^n$. These are handled using modulo arithmetic on indices.\n\n### 3. Verification Strategy\n\nThe numerical solver is validated using the method of manufactured solutions and a test suite.\n- **Test A (Spatial Convergence):** A homogeneous case with a smooth sinusoidal initial condition is used. The time step is chosen as $\\Delta t = \\alpha (\\Delta x)^2$ with a small $\\alpha=0.2$. This makes the temporal truncation error, which scales as $(\\Delta t)^2$, much smaller than the spatial error, which scales as $(\\Delta x)^2$. This test effectively isolates and measures the spatial order of accuracy. For our scheme, we expect the error $E$ to scale as $(\\Delta x)^2$, so the observed order $q_{\\text{space}}$ should be close to $2$.\n- **Test B (Temporal Convergence):** A forced case with a spatially uniform manufactured solution $p(x,t) = \\cos(\\omega t)$ is used. Since the solution and source term are constant in space, the discrete spatial Laplacian term $(p_{i+1}^n - 2p_i^n + p_{i-1}^n)$ is identically zero for all timesteps. This eliminates spatial discretization error entirely, isolating the temporal error. It also sidesteps the CFL stability constraint, as the part of the scheme responsible for the instability is nullified. We expect the error $E$ to scale as $(\\Delta t)^2$, so the observed order $q_{\\text{time}}$ should be close to $2$.\n- **Test C (Consistency Check):** This tests the solver at $T=0$. The numerical solution must simply be the initial condition, and the error should be zero (or within machine precision). This is a basic sanity check of the implementation.\n\nThe discrete $L^2$ error norm $E = \\left( \\sum_{i=0}^{N-1} \\left[p_i^{\\mathrm{num}}(T) - p^{\\mathrm{exact}}(x_i,T)\\right]^2 \\Delta x \\right)^{1/2}$ is used to quantify the difference between numerical and exact solutions, and from this, the empirical order of convergence $q = \\log(E_1/E_2)/\\log(r)$ is computed for a refinement factor $r$.", "answer": "```python\nimport numpy as np\n\ndef wave_solver(L, N, c, T, dt, p0_func, S_func=None):\n    \"\"\"\n    Solves the 1D wave equation partial_tt p - c^2 partial_xx p = S(x,t)\n    using a second-order finite difference scheme with periodic boundary conditions.\n    \"\"\"\n    dx = L / N\n    x = np.arange(N) * dx\n\n    num_steps = int(round(T / dt))\n\n    if num_steps == 0:\n        return p0_func(x), x\n\n    # Initialize pressure fields at t=0 and t=-dt (by convention)\n    # p_curr is p^n, p_prev is p^(n-1)\n    p_curr = p0_func(x)  # p^0\n\n    # Courant number squared\n    sigma_sq = (c * dt / dx)**2\n\n    # First time step (n=0) to calculate p^1 using second-order starter.\n    # p^1 = p^0 + dt*v_0 + 0.5*dt^2*(c^2*laplacian(p^0) + S^0). Here v_0=0.\n    lap_p0 = np.roll(p_curr, -1) - 2 * p_curr + np.roll(p_curr, 1)\n    \n    S_at_0 = np.zeros(N)\n    if S_func:\n        S_at_0 = S_func(x, 0.0)\n    \n    p_next = p_curr + 0.5 * sigma_sq * lap_p0 + 0.5 * dt**2 * S_at_0\n\n    p_prev = p_curr\n    p_curr = p_next\n\n    # Main time-stepping loop (n=1 to num_steps-1)\n    for n in range(1, num_steps):\n        t = n * dt\n        \n        lap_p_curr = np.roll(p_curr, -1) - 2 * p_curr + np.roll(p_curr, 1)\n\n        S_at_t = np.zeros(N)\n        if S_func:\n            S_at_t = S_func(x, t)\n\n        p_next = 2 * p_curr - p_prev + sigma_sq * lap_p_curr + dt**2 * S_at_t\n\n        p_prev = p_curr\n        p_curr = p_next\n\n    return p_curr, x\n\ndef calculate_l2_error(p_num, p_exact, dx):\n    \"\"\"Calculates the discrete L2 error.\"\"\"\n    return np.sqrt(np.sum((p_num - p_exact)**2) * dx)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    results = []\n\n    # --- Test A: Spatial Convergence ---\n    c_A = 1.0\n    L_A = 1.0\n    m_A = 3\n    k_A = 2 * np.pi * m_A\n    T_A = 0.01\n    alpha_A = 0.2\n    Ns_A = [50, 100, 200]\n    errors_A = []\n\n    def p0_A(x):\n        return np.sin(k_A * x)\n\n    for N_val in Ns_A:\n        dx_val = L_A / N_val\n        dt_val = alpha_A * (dx_val)**2\n        \n        p_num, x_grid = wave_solver(L_A, N_val, c_A, T_A, dt_val, p0_A)\n        p_exact = np.sin(k_A * x_grid) * np.cos(c_A * k_A * T_A)\n        \n        error = calculate_l2_error(p_num, p_exact, dx_val)\n        errors_A.append(error)\n\n    # Calculate observed order of convergence\n    q_50_100 = np.log(errors_A[0] / errors_A[1]) / np.log(2)\n    q_100_200 = np.log(errors_A[1] / errors_A[2]) / np.log(2)\n    q_space = 0.5 * (q_50_100 + q_100_200)\n    \n    results.append(q_space)\n\n    # --- Test B: Temporal Convergence ---\n    c_B = 1.0\n    L_B = 1.0\n    N_B = 64\n    omega_B = 7.0\n    T_B = 0.2\n    dts_B = [0.02, 0.01, 0.005]\n    errors_B = []\n\n    def p0_B(x):\n        return np.ones_like(x)\n\n    def S_B(x, t):\n        # x is unused since source is spatially uniform\n        return -omega_B**2 * np.cos(omega_B * t) * np.ones_like(x)\n\n    for dt_val in dts_B:\n        p_num, x_grid = wave_solver(L_B, N_B, c_B, T_B, dt_val, p0_B, S_func=S_B)\n        p_exact = np.cos(omega_B * T_B) * np.ones_like(x_grid)\n        dx_val = L_B / N_B\n        \n        error = calculate_l2_error(p_num, p_exact, dx_val)\n        errors_B.append(error)\n\n    # Calculate observed order of convergence\n    q_1 = np.log(errors_B[0] / errors_B[1]) / np.log(2)\n    q_2 = np.log(errors_B[1] / errors_B[2]) / np.log(2)\n    q_time = 0.5 * (q_1 + q_2)\n\n    results.append(q_time)\n\n    # --- Append boolean checks for Test A and B ---\n    results.append(q_space >= 1.8)\n    results.append(q_time >= 1.8)\n\n    # --- Test C: Edge Case Consistency (T=0) ---\n    N_C = 50 \n    dx_C = L_A / N_C\n    dt_C = alpha_A * dx_C**2\n    \n    p_num_C, x_grid_C = wave_solver(L_A, N_C, c_A, 0.0, dt_C, p0_A)\n    p_exact_C = p0_A(x_grid_C)\n\n    error_C = calculate_l2_error(p_num_C, p_exact_C, dx_C)\n    \n    results.append(error_C < 1e-12)\n\n    # --- Final Output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3410161"}, {"introduction": "While simple models often use periodic domains, realistic photoacoustic simulations must contend with waves propagating outwards into an effectively infinite medium. A naive truncation of the computational grid creates artificial boundary reflections that contaminate the solution. This practice introduces the Perfectly Matched Layer (PML) [@problem_id:3410207], a sophisticated technique that creates a non-reflecting, absorbing boundary, allowing for accurate simulations of open-domain problems within a finite computational cost.", "problem": "Consider the forward acoustic propagation model used in Photoacoustic Tomography (PAT), with acoustic pressure field $p(x,t)$ and particle velocity $u(x,t)$ governed in one spatial dimension by the first-order system\n$$\n\\partial_{t} p(x,t) + \\kappa \\,\\partial_{x} u(x,t) = 0, \\qquad \\partial_{t} u(x,t) + \\frac{1}{\\rho} \\,\\partial_{x} p(x,t) = 0,\n$$\nwhere $\\rho$ is the mass density and $\\kappa = \\rho c^{2}$ is the bulk modulus, with $c$ the speed of sound. To truncate the computational domain and eliminate spurious boundary reflections in simulations of the forward operator for inverse problems and data assimilation, one uses a Perfectly Matched Layer (PML). Assume a one-dimensional PML occupies the interval $x \\in [0,L]$ attached to the physical domain at $x=0$, with a prescribed nonnegative damping profile $\\sigma(x)$ on $[0,L]$.\n\nTask 1: Starting from the above first-order acoustic system and the complex coordinate stretching principle in the frequency domain, derive time-domain governing equations for the PML in $x \\in [0,L]$ expressed in terms of $p(x,t)$, $u(x,t)$, $c$, $\\rho$, and the damping profile $\\sigma(x)$.\n\nTask 2: Consider a monochromatic plane wave of angular frequency $\\omega$ incident normally from the physical domain into the PML at $x=0$. Assume the PML is perfectly matched at $x=0$ (no impedance mismatch) and the far end at $x=L$ is perfectly reflecting (e.g., a termination inducing unit-amplitude reflection at $x=L$). Derive an analytic expression for the magnitude of the reflection coefficient measured back at $x=0$ in terms of the sound speed $c$, the layer thickness $L$, and the damping profile $\\sigma(x)$. Then, evaluate this expression in closed form for the polynomial profile $\\sigma(x) = \\sigma_{0} \\left(\\frac{x}{L}\\right)^{m}$ with $\\sigma_{0} > 0$ and integer $m \\geq 0$.\n\nYour final answer must be a single closed-form analytic expression for the reflection coefficient magnitude in terms of $\\sigma_{0}$, $L$, $c$, and $m$. No numerical evaluation is required, and no rounding is necessary. Express the answer without units.", "solution": "The problem is divided into two tasks. The first is to derive the governing equations for a one-dimensional Perfectly Matched Layer (PML) for an acoustic system. The second is to compute the reflection coefficient for a specific PML configuration.\n\n**Task 1: Derivation of the PML Governing Equations**\n\nWe begin with the given first-order system for the acoustic pressure $p(x,t)$ and particle velocity $u(x,t)$:\n$$\n\\partial_{t} p(x,t) + \\kappa \\,\\partial_{x} u(x,t) = 0\n$$\n$$\n\\partial_{t} u(x,t) + \\frac{1}{\\rho} \\,\\partial_{x} p(x,t) = 0\n$$\nwhere $\\kappa = \\rho c^2$ is the bulk modulus, $\\rho$ is the mass density, and $c$ is the speed of sound.\n\nTo derive the PML equations, we employ the principle of complex coordinate stretching in the frequency domain. We first apply a Fourier transform with respect to time, using the convention $f(t) = \\frac{1}{2\\pi} \\int_{-\\infty}^{\\infty} \\hat{f}(\\omega) e^{-i\\omega t} d\\omega$, which corresponds to the transform pair $\\partial_t \\leftrightarrow -i\\omega$. The system in the frequency domain becomes:\n$$\n-i\\omega \\hat{p}(x,\\omega) + \\kappa \\,\\partial_{x} \\hat{u}(x,\\omega) = 0\n$$\n$$\n-i\\omega \\hat{u}(x,\\omega) + \\frac{1}{\\rho} \\,\\partial_{x} \\hat{p}(x,\\omega) = 0\n$$\nThe complex coordinate stretching principle introduces a complex coordinate $\\tilde{x}$ such that the spatial derivative operator $\\partial_x$ is replaced by $\\frac{1}{s(x)} \\partial_x$. For a wave propagating in the $+x$ direction to be attenuated, the stretching factor $s(x)$ for the chosen Fourier convention is $s(x) = 1 + i\\frac{\\sigma(x)}{\\omega}$, where $\\sigma(x) \\geq 0$ is the prescribed damping profile. Applying this transformation to the frequency-domain equations:\n$$\n-i\\omega \\hat{p} + \\kappa \\frac{1}{1 + i\\frac{\\sigma(x)}{\\omega}} \\partial_{x} \\hat{u} = 0\n$$\n$$\n-i\\omega \\hat{u} + \\frac{1}{\\rho} \\frac{1}{1 + i\\frac{\\sigma(x)}{\\omega}} \\partial_{x} \\hat{p} = 0\n$$\nTo transform these equations back to the time domain, we first clear the denominators:\n$$\n-i\\omega \\left(1 + i\\frac{\\sigma(x)}{\\omega}\\right) \\hat{p} + \\kappa \\partial_{x} \\hat{u} = 0\n$$\n$$\n-i\\omega \\left(1 + i\\frac{\\sigma(x)}{\\omega}\\right) \\hat{u} + \\frac{1}{\\rho} \\partial_{x} \\hat{p} = 0\n$$\nExpanding the terms in parentheses gives:\n$$\n(-i\\omega + \\sigma(x)) \\hat{p} + \\kappa \\partial_{x} \\hat{u} = 0\n$$\n$$\n(-i\\omega + \\sigma(x)) \\hat{u} + \\frac{1}{\\rho} \\partial_{x} \\hat{p} = 0\n$$\nNow, we apply the inverse Fourier transform, using the correspondence $-i\\omega \\leftrightarrow \\partial_t$. This yields the time-domain PML equations:\n$$\n\\partial_{t} p(x,t) + \\sigma(x) p(x,t) + \\kappa \\partial_{x} u(x,t) = 0\n$$\n$$\n\\partial_{t} u(x,t) + \\sigma(x) u(x,t) + \\frac{1}{\\rho} \\partial_{x} p(x,t) = 0\n$$\nThese can be rewritten to highlight the modification to the original system:\n$$\n\\partial_{t} p + \\kappa \\partial_{x} u = -\\sigma(x) p\n$$\n$$\n\\partial_{t} u + \\frac{1}{\\rho} \\partial_{x} p = -\\sigma(x) u\n$$\nThese are the governing equations for the PML region $x \\in [0,L]$. A key property of this formulation is that the acoustic impedance in the PML remains matched to that of the physical domain. For a plane wave, the impedance is $Z = \\hat{p}/\\hat{u} = \\rho c$. This ensures that a wave entering the PML at $x=0$ does not generate a reflection at the interface, fulfilling the \"perfectly matched\" condition.\n\n**Task 2: Reflection Coefficient Calculation**\n\nWe consider a monochromatic plane wave of angular frequency $\\omega$ in the PML domain. The fields can be written as $p(x,t) = \\hat{p}(x) e^{-i\\omega t}$ and $u(x,t) = \\hat{u}(x) e^{-i\\omega t}$. The spatial part $\\hat{p}(x)$ is governed by a Helmholtz-type equation. We can derive this by differentiating the second PML equation with respect to $x$ and substituting the first one. Assuming $\\sigma(x)$ is not constant:\n$$\n(-i\\omega + \\sigma) \\partial_x \\hat{u} + (\\partial_x \\sigma) \\hat{u} + \\frac{1}{\\rho} \\partial_{xx} \\hat{p} = 0\n$$\nSubstituting $\\partial_x \\hat{u} = - \\frac{-i\\omega + \\sigma}{\\kappa}\\hat{p}$ and $\\hat{u} = - \\frac{1}{\\rho(-i\\omega+\\sigma)}\\partial_x \\hat{p}$:\n$$\n(-i\\omega+\\sigma) \\left( -\\frac{-i\\omega+\\sigma}{\\kappa}\\hat{p} \\right) + (\\partial_x\\sigma) \\left( - \\frac{1}{\\rho(-i\\omega+\\sigma)}\\partial_x \\hat{p} \\right) + \\frac{1}{\\rho}\\partial_{xx}\\hat{p} = 0\n$$\n$$\n\\partial_{xx}\\hat{p} - \\frac{\\partial_x\\sigma}{-i\\omega+\\sigma}\\partial_x\\hat{p} + \\frac{\\rho}{\\kappa}(-i\\omega+\\sigma)^2 \\hat{p} = 0\n$$\nThe local wavenumber $k(x)$ can be found by examining the case where $\\sigma$ is constant. The wave equation becomes $\\partial_{xx}\\hat{p} + k^2 \\hat{p} = 0$, where $k^2 = \\frac{(-i\\omega+\\sigma)^2}{c^2}$. So, $k(x) = \\frac{-i\\omega+\\sigma(x)}{c}$. For a forward-propagating wave in the $+x$ direction, its spatial dependence is $\\exp(i k x) = \\exp(i\\frac{-i\\omega+\\sigma}{c}x) = \\exp(\\frac{\\omega}{c}x) \\exp(i\\frac{\\sigma}{c}x)$. This corresponds to growth. The choice of sign for the square root of $k^2$ matters. The two solutions correspond to forward and backward propagating waves.\nLet's re-examine the impedance. For a forward wave $\\hat{p}(x) = P_0 e^{i k_{fwd}x}$, where $k_{fwd}$ is the wavenumber. From $(-i\\omega+\\sigma) \\hat{u} = -\\frac{1}{\\rho} \\partial_x \\hat{p} = -\\frac{ik_{fwd}}{\\rho} \\hat{p}$, the impedance is $Z = \\hat{p}/\\hat{u} = \\frac{-\\rho(-i\\omega+\\sigma)}{ik_{fwd}}$. To match $Z_0=\\rho c$, we need $ik_{fwd} = -\\frac{-i\\omega+\\sigma}{c}$. So $k_{fwd}(x) = i \\frac{-i\\omega+\\sigma(x)}{c} = \\frac{\\omega+i\\sigma(x)}{c}$.\nThe spatial dependence of a forward-propagating wave is $\\exp(i k_{fwd} x) = \\exp(i\\frac{\\omega}{c}x) \\exp(-\\frac{\\sigma(x)}{c}x)$, which shows the correct attenuation.\n\nThe pressure field inside the PML is a superposition of a forward wave (incident from $x=0$) and a backward wave (reflected from $x=L$):\n$$\n\\hat{p}(x) = P_{fwd}(x) + P_{bwd}(x)\n$$\nUsing the WKB approximation, the amplitude of a wave propagating through the medium with spatially varying properties is modulated by an exponential factor. The attenuation of a wave traveling from $x_1$ to $x_2$ is given by $\\exp\\left(-\\int_{x_1}^{x_2} \\text{Im}(k(x')) dx'\\right)$.\nHere, $\\text{Im}(k_{fwd}(x)) = \\frac{\\sigma(x)}{c}$.\nAn incident wave of unit amplitude at $x=0$ propagates to $x=L$. Its amplitude at $x=L$ will be:\n$$\nA_{L} = 1 \\cdot \\exp\\left(-\\int_0^L \\frac{\\sigma(x)}{c} dx\\right)\n$$\nAt $x=L$, the wave is perfectly reflected. This means the amplitude of the backward-propagating wave at $x=L$ is equal to the amplitude of the incident wave at $x=L$. Let the reflection coefficient at the boundary $x=L$ be $R_L$. A perfectly reflecting boundary implies $|R_L|=1$.\nThe reflected wave then propagates back from $x=L$ to $x=0$, undergoing the same attenuation. The amplitude of the reflected wave arriving back at $x=0$ is:\n$$\nA_{refl, 0} = (A_{L}) \\cdot |R_L| \\cdot \\exp\\left(-\\int_0^L \\frac{\\sigma(x)}{c} dx\\right)\n$$\nThe reflection coefficient measured at $x=0$, which we denote as $R_0$, is the ratio of the reflected amplitude to the incident amplitude at $x=0$. Its magnitude is:\n$$\n|R_0| = \\frac{A_{refl, 0}}{1} = \\exp\\left(-\\frac{1}{c}\\int_0^L \\sigma(x) dx\\right) \\cdot 1 \\cdot \\exp\\left(-\\frac{1}{c}\\int_0^L \\sigma(x) dx\\right)\n$$\n$$\n|R_0| = \\exp\\left(-\\frac{2}{c}\\int_0^L \\sigma(x) dx\\right)\n$$\nThis represents the round-trip attenuation through the PML. Now we evaluate this for the given polynomial profile $\\sigma(x) = \\sigma_{0} \\left(\\frac{x}{L}\\right)^{m}$ for integer $m \\geq 0$. We compute the integral:\n$$\n\\int_0^L \\sigma(x) dx = \\int_0^L \\sigma_{0} \\left(\\frac{x}{L}\\right)^{m} dx = \\frac{\\sigma_0}{L^m} \\int_0^L x^m dx\n$$\n$$\n\\int_0^L x^m dx = \\left[ \\frac{x^{m+1}}{m+1} \\right]_0^L = \\frac{L^{m+1}}{m+1}\n$$\nSo, the integral is:\n$$\n\\int_0^L \\sigma(x) dx = \\frac{\\sigma_0}{L^m} \\frac{L^{m+1}}{m+1} = \\frac{\\sigma_0 L}{m+1}\n$$\nSubstituting this result into our expression for the reflection coefficient magnitude:\n$$\n|R_0| = \\exp\\left(-\\frac{2}{c} \\cdot \\frac{\\sigma_0 L}{m+1}\\right) = \\exp\\left(-\\frac{2\\sigma_0 L}{c(m+1)}\\right)\n$$\nThis is the final closed-form expression for the magnitude of the reflection coefficient at $x=0$.", "answer": "$$\n\\boxed{\\exp\\left(-\\frac{2 \\sigma_{0} L}{c(m+1)}\\right)}\n$$", "id": "3410207"}, {"introduction": "With a robust forward model in hand, we can tackle the full inverse problem: inferring underlying physical parameters from measured data. This practice moves into the realm of Quantitative Photoacoustic Tomography (QPAT), where the relationship between the measured signal and the parameters of interest is nonlinear. You will implement a complete Bayesian inference workflow, from finding the maximum a posteriori (MAP) estimate to quantifying the uncertainty of your solution via the Laplace approximation [@problem_id:3410206].", "problem": "You are given a simplified one-dimensional model for Quantitative Photoacoustic Tomography (QPAT) that uses the steady-state diffusion approximation for light transport. The goal is to approximate the uncertainty of the inferred optical absorption field using the Laplace approximation at the Maximum A Posteriori (MAP) estimate by computing the Hessian of the negative log-posterior and relating its inverse to the approximate posterior covariance.\n\nConsider a one-dimensional spatial domain discretized into $n$ interior nodes with grid spacing $h = 1/(n+1)$ and homogeneous Dirichlet boundary conditions. The light fluence $\\Phi \\in \\mathbb{R}^n$ satisfies the discrete diffusion equation\n$$\n\\mathbf{A}(\\boldsymbol{\\theta}) \\Phi = q,\n$$\nwhere $q \\in \\mathbb{R}^n$ is a known source vector, $\\boldsymbol{\\theta} \\in \\mathbb{R}^n$ are the log-absorption parameters, and the absorption $\\boldsymbol{\\mu}_a \\in \\mathbb{R}^n$ is given by $\\boldsymbol{\\mu}_a = \\exp(\\boldsymbol{\\theta})$ element-wise. The stiffness matrix $\\mathbf{A}(\\boldsymbol{\\theta})$ is\n$$\n\\mathbf{A}(\\boldsymbol{\\theta}) = \\frac{D}{h^2}\\,\\mathbf{K} + \\operatorname{diag}(\\boldsymbol{\\mu}_a),\n$$\nwhere $D \\in \\mathbb{R}_+$ is the diffusion coefficient and $\\mathbf{K} \\in \\mathbb{R}^{n\\times n}$ is the standard tridiagonal finite-difference matrix with $2$ on the diagonal and $-1$ on the off-diagonals.\n\nThe initial acoustic pressure $p_0 \\in \\mathbb{R}^n$ is given by\n$$\np_0 = \\Gamma\\, \\boldsymbol{\\mu}_a \\odot \\Phi,\n$$\nwhere $\\Gamma \\in \\mathbb{R}_+$ is the Grüneisen parameter (assumed known) and $\\odot$ denotes the element-wise (Hadamard) product. The measurement operator selects a subset of indices $\\mathcal{S} \\subset \\{1,\\dots,n\\}$, and the measured data are\n$$\n\\mathbf{g}(\\boldsymbol{\\theta}) = \\mathbf{S}\\, p_0,\n$$\nwhere $\\mathbf{S} \\in \\{0,1\\}^{m\\times n}$ selects the $m$ sensor locations. The observed data $\\mathbf{y} \\in \\mathbb{R}^m$ are generated by the forward model at a ground-truth parameter $\\boldsymbol{\\theta}_\\text{true}$, without additional noise, and are treated as a realization of a Gaussian likelihood with covariance $\\sigma^2\\,\\mathbf{I}_m$.\n\nAssume an independent Gaussian prior for $\\boldsymbol{\\theta}$ with mean $\\boldsymbol{\\theta}_\\text{prior}$ and covariance $\\tau^2\\,\\mathbf{I}_n$. The negative log-posterior (up to an additive constant) is\n$$\n\\mathcal{L}(\\boldsymbol{\\theta}) = \\frac{1}{2\\sigma^2}\\,\\|\\mathbf{g}(\\boldsymbol{\\theta}) - \\mathbf{y}\\|_2^2 + \\frac{1}{2\\tau^2}\\,\\|\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_\\text{prior}\\|_2^2.\n$$\n\nThe Laplace approximation to the posterior near the MAP estimate $\\boldsymbol{\\theta}_\\text{MAP}$ uses a Gaussian with covariance equal to the inverse of the Hessian of $\\mathcal{L}$ at $\\boldsymbol{\\theta}_\\text{MAP}$. In practice, for nonlinear least squares with Gaussian noise, a Gauss–Newton approximation to the Hessian\n$$\n\\mathbf{H}(\\boldsymbol{\\theta}_\\text{MAP}) \\approx \\mathbf{J}(\\boldsymbol{\\theta}_\\text{MAP})^\\top \\left(\\frac{1}{\\sigma^2}\\,\\mathbf{I}_m\\right) \\mathbf{J}(\\boldsymbol{\\theta}_\\text{MAP}) + \\frac{1}{\\tau^2}\\,\\mathbf{I}_n\n$$\nis often used, where $\\mathbf{J}(\\boldsymbol{\\theta}) \\in \\mathbb{R}^{m\\times n}$ is the Jacobian of $\\mathbf{g}(\\boldsymbol{\\theta})$.\n\nTasks:\n1. Compute $\\boldsymbol{\\theta}_\\text{MAP}$ by minimizing $\\mathcal{L}(\\boldsymbol{\\theta})$ using a damped Gauss–Newton (Levenberg–Marquardt) method starting from $\\boldsymbol{\\theta}_\\text{prior}$.\n2. At $\\boldsymbol{\\theta}_\\text{MAP}$, compute the Gauss–Newton Hessian approximation $\\mathbf{H}(\\boldsymbol{\\theta}_\\text{MAP})$ as above.\n3. Compute the approximate posterior covariance $\\mathbf{C} \\approx \\mathbf{H}(\\boldsymbol{\\theta}_\\text{MAP})^{-1}$.\n4. Report the three selected marginal variances $\\{\\mathbf{C}_{i,i}\\}$ at indices $i \\in \\{1,\\lfloor n/2 \\rfloor, n\\}$ (using $1$-based indexing; in code, use $0$, $\\lfloor n/2 \\rfloor$, and $n-1$).\nAll quantities are dimensionless due to nondimensionalization; express the three reported outputs as floating-point numbers.\n\nThe Jacobian $\\mathbf{J}(\\boldsymbol{\\theta})$ must be computed by differentiating through the implicit definition of $\\Phi$ given by $\\mathbf{A}(\\boldsymbol{\\theta})\\,\\Phi = q$:\n- Use $\\boldsymbol{\\mu}_a = \\exp(\\boldsymbol{\\theta})$ element-wise,\n- Compute $\\Phi$ by solving the linear system,\n- For each component $\\theta_i$, compute $\\partial \\Phi/\\partial \\theta_i$ by solving\n$$\n\\mathbf{A}(\\boldsymbol{\\theta})\\,\\frac{\\partial \\Phi}{\\partial \\theta_i} = - \\frac{\\partial \\mathbf{A}}{\\partial \\theta_i} \\, \\Phi,\n$$\nand combine with $\\partial p_0/\\partial \\theta_i$ to form the Jacobian columns, before selecting sensor rows via $\\mathbf{S}$.\n\nTest suite:\nUse the following three test cases to exercise different regimes of the inference problem. In each case, the observed data $\\mathbf{y}$ are the forward prediction at the ground-truth parameters without added noise. The ground-truth absorption profile is defined as\n$$\n\\mu_a^\\text{true}(x_j) = \\mu_0 + \\delta\\, \\exp\\left(-\\frac{(x_j - 0.5)^2}{2\\,w^2}\\right),\n$$\nwith $x_j = j h$ for interior nodes $j=1,\\dots,n$, and $\\boldsymbol{\\theta}_\\text{true} = \\log \\big( \\mu_a^\\text{true}(x_j) \\big)$ element-wise, while the prior mean is the uniform background $\\boldsymbol{\\theta}_\\text{prior} = \\log(\\mu_0)\\,\\mathbf{1}$.\n\n- Case A (general, fully observed):\n  - $n = 20$, $D = 10^{-2}$, $\\Gamma = 1$, $q = \\mathbf{1}$,\n  - $\\mu_0 = 0.1$, $\\delta = 0.2$, $w = 0.1$,\n  - sensors: all nodes ($\\mathbf{S} = \\mathbf{I}_{n}$), $\\sigma^2 = (10^{-2})^2$, $\\tau^2 = (0.5)^2$.\n\n- Case B (low noise, strong data):\n  - same as Case A except $\\sigma^2 = (10^{-4})^2$.\n\n- Case C (partial observations, weaker prior):\n  - same as Case A except sensors are every third node starting at index $3$ (i.e., indices $\\{3,6,9,\\dots\\}$ in $1$-based indexing), $\\sigma^2 = (10^{-2})^2$, $\\tau^2 = (1.0)^2$.\n\nYour program must:\n- Implement the forward model and Jacobian computation as specified,\n- Compute $\\boldsymbol{\\theta}_\\text{MAP}$ using a damped Gauss–Newton method,\n- Form $\\mathbf{H}(\\boldsymbol{\\theta}_\\text{MAP})$ and $\\mathbf{C} \\approx \\mathbf{H}^{-1}$,\n- For each test case, output the three marginal variances $\\mathbf{C}_{i,i}$ at indices $i \\in \\{1,\\lfloor n/2 \\rfloor, n\\}$ (using zero-based indices in code),\n- Produce a single line of output containing a list of lists, one per test case, each inner list containing the three floating-point numbers in the order $[i=0, i=\\lfloor n/2 \\rfloor, i=n-1]$, with the entire output formatted as a comma-separated list enclosed in square brackets, e.g., `[[v_{A1},v_{A2},v_{A3}],[v_{B1},v_{B2},v_{B3}],[v_{C1},v_{C2},v_{C3}]]`.\n\nAll quantities are dimensionless; no physical units are required. Angles are not involved. Percentages are not involved; express all values as plain floating-point numbers.", "solution": "**Problem Validation**\n\nThe problem statement has been critically evaluated and is deemed valid.\n\n1.  **Givens Extraction**: All required parameters, equations, and conditions are explicitly provided. This includes the model for light diffusion ($\\mathbf{A}(\\boldsymbol{\\theta})\\Phi = q$), acoustic pressure generation ($p_0 = \\Gamma \\boldsymbol{\\mu}_a \\odot \\Phi$), the Bayesian statistical framework (Gaussian likelihood and prior), the negative log-posterior $\\mathcal{L}(\\boldsymbol{\\theta})$, the Gauss-Newton approximation to the Hessian $\\mathbf{H}$, and the method for calculating the Jacobian $\\mathbf{J}$ via implicit differentiation. Three distinct test cases (A, B, C) with all necessary constants ($n, D, \\Gamma, q, \\mu_0, \\delta, w, \\sigma^2, \\tau^2$) are defined.\n\n2.  **Validation Checks**:\n    - **Scientific Grounding**: The model is based on the diffusion approximation to the radiative transfer equation and standard principles of photoacoustic signal generation. The Bayesian inference approach with a Gauss-Newton optimization and Laplace approximation for uncertainty are standard and well-established methods in computational inverse problems. The model is scientifically sound.\n    - **Well-Posedness**: The forward problem is well-posed (the matrix $\\mathbf{A}(\\boldsymbol{\\theta})$ is invertible). The inverse problem is regularized by the prior, leading to a well-posed optimization problem for the MAP estimate. The Gauss-Newton Hessian, being the sum of a positive semi-definite and a positive definite matrix, is invertible, ensuring a unique solution for the approximate posterior covariance.\n    - **Objectivity**: The problem is stated in precise mathematical and algorithmic terms, free from subjective language.\n    - **Completeness**: All information required to implement the solution and reproduce the results is provided. A minor ambiguity exists regarding the indices for reporting results, between the 1-based mathematical description ($\\{1, \\lfloor n/2 \\rfloor, n\\}$) and the explicit instruction for code implementation ($\\{0, \\lfloor n/2 \\rfloor, n-1\\}$). The latter, more direct instruction will be followed.\n\nThe problem is a well-defined and standard exercise in computational inverse problems, requiring the implementation of a forward model, an optimization algorithm, and an uncertainty quantification method.\n\n**Solution Methodology**\n\nThe goal is to compute the marginal posterior variances of the log-absorption parameter field $\\boldsymbol{\\theta}$ at selected spatial locations. This is achieved by first finding the maximum a posteriori (MAP) estimate $\\boldsymbol{\\theta}_{\\text{MAP}}$ and then computing the Laplace approximation to the posterior covariance, which is given by the inverse of the Hessian of the negative log-posterior evaluated at the MAP estimate. A Gauss-Newton approximation is used for the Hessian. The solution proceeds in the following steps.\n\n**1. Forward Model and Observation**\n\nThe physical process is described by a sequence of models.\n\n- **Light Transport**: The steady-state light fluence $\\Phi \\in \\mathbb{R}^n$ for a given log-absorption field $\\boldsymbol{\\theta} \\in \\mathbb{R}^n$ is governed by the discrete diffusion equation:\n$$\n\\mathbf{A}(\\boldsymbol{\\theta}) \\Phi = q\n$$\nwhere $\\boldsymbol{\\mu}_a = \\exp(\\boldsymbol{\\theta})$ (element-wise), $\\mathbf{A}(\\boldsymbol{\\theta}) = \\frac{D}{h^2}\\mathbf{K} + \\operatorname{diag}(\\boldsymbol{\\mu}_a)$, $q$ is the source, $D$ is the diffusion coefficient, $h=\\frac{1}{n+1}$ is the grid spacing, and $\\mathbf{K}$ is the $n \\times n$ second-order finite difference matrix (tridiagonal with $2$ on the main diagonal and $-1$ on the first off-diagonals). Since $\\mathbf{K}$ is positive semi-definite and $\\operatorname{diag}(\\boldsymbol{\\mu}_a)$ is a positive definite diagonal matrix (as $\\mu_{a,i} = e^{\\theta_i} > 0$), the matrix $\\mathbf{A}(\\boldsymbol{\\theta})$ is symmetric positive definite and thus invertible. We can compute $\\Phi$ by solving this linear system:\n$$\n\\Phi(\\boldsymbol{\\theta}) = \\mathbf{A}(\\boldsymbol{\\theta})^{-1} q\n$$\n- **Acoustic Generation**: The initial acoustic pressure $p_0 \\in \\mathbb{R}^n$ is proportional to the absorbed optical energy density:\n$$\np_0(\\boldsymbol{\\theta}) = \\Gamma (\\boldsymbol{\\mu}_a \\odot \\Phi(\\boldsymbol{\\theta}))\n$$\nwhere $\\Gamma$ is the Grüneisen parameter and $\\odot$ is the element-wise product.\n- **Measurement**: The observation model $\\mathbf{g}(\\boldsymbol{\\theta})$ maps the parameter space to the measurement space via a linear selection operator $\\mathbf{S} \\in \\{0,1\\}^{m \\times n}$:\n$$\n\\mathbf{g}(\\boldsymbol{\\theta}) = \\mathbf{S} \\, p_0(\\boldsymbol{\\theta})\n$$\nThe observed data $\\mathbf{y} \\in \\mathbb{R}^m$ are synthesized noise-free from a known ground truth $\\boldsymbol{\\theta}_{\\text{true}}$: $\\mathbf{y} = \\mathbf{g}(\\boldsymbol{\\theta}_{\\text{true}})$.\n\n**2. Bayesian Inference and MAP Estimation**\n\nWe adopt a Bayesian framework. The posterior probability distribution of $\\boldsymbol{\\theta}$ given data $\\mathbf{y}$ is proportional to the product of the likelihood and the prior. Assuming a Gaussian likelihood and a Gaussian prior, the negative log-posterior $\\mathcal{L}(\\boldsymbol{\\theta})$ (our objective function to be minimized) is:\n$$\n\\mathcal{L}(\\boldsymbol{\\theta}) = \\frac{1}{2\\sigma^2} \\|\\mathbf{g}(\\boldsymbol{\\theta}) - \\mathbf{y}\\|_2^2 + \\frac{1}{2\\tau^2} \\|\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prior}}\\|_2^2\n$$\nThe MAP estimate is the minimizer of this functional: $\\boldsymbol{\\theta}_{\\text{MAP}} = \\arg\\min_{\\boldsymbol{\\theta}} \\mathcal{L}(\\boldsymbol{\\theta})$. This is a nonlinear least-squares problem. We solve it using a damped Gauss-Newton (Levenberg-Marquardt) iterative method, starting with the prior mean $\\boldsymbol{\\theta}_{\\text{prior}}$ as the initial guess.\n\nThe Gauss-Newton update step $\\delta\\boldsymbol{\\theta}$ is found by solving the linear system:\n$$\n(\\mathbf{H}(\\boldsymbol{\\theta}_k) + \\lambda \\mathbf{I}) \\delta\\boldsymbol{\\theta} = -\\nabla\\mathcal{L}(\\boldsymbol{\\theta}_k)\n$$\nwhere $\\boldsymbol{\\theta}_k$ is the estimate at iteration $k$, $\\lambda$ is a damping parameter, $\\nabla\\mathcal{L}$ is the gradient of the objective function, and $\\mathbf{H}$ is the Gauss-Newton approximation of the Hessian.\nThe gradient is:\n$$\n\\nabla\\mathcal{L}(\\boldsymbol{\\theta}) = \\mathbf{J}(\\boldsymbol{\\theta})^\\top \\frac{1}{\\sigma^2} (\\mathbf{g}(\\boldsymbol{\\theta}) - \\mathbf{y}) + \\frac{1}{\\tau^2} (\\boldsymbol{\\theta} - \\boldsymbol{\\theta}_{\\text{prior}})\n$$\nThe Gauss-Newton Hessian is:\n$$\n\\mathbf{H}(\\boldsymbol{\\theta}) = \\mathbf{J}(\\boldsymbol{\\theta})^\\top \\frac{1}{\\sigma^2} \\mathbf{I}_m \\mathbf{J}(\\boldsymbol{\\theta}) + \\frac{1}{\\tau^2} \\mathbf{I}_n\n$$\nwhere $\\mathbf{J}(\\boldsymbol{\\theta}) \\in \\mathbb{R}^{m\\times n}$ is the Jacobian of the forward model $\\mathbf{g}(\\boldsymbol{\\theta})$. The iterative process continues until the norm of the gradient falls below a tolerance.\n\n**3. Jacobian Calculation via Implicit Differentiation**\n\nThe core of the optimization is the computation of the Jacobian $\\mathbf{J}(\\boldsymbol{\\theta})$. Its elements are $J_{ij} = \\frac{\\partial g_i}{\\partial \\theta_j}$. We have $\\mathbf{g} = \\mathbf{S} p_0$, so $\\mathbf{J} = \\mathbf{S} \\frac{\\partial p_0}{\\partial \\boldsymbol{\\theta}}$, where $\\frac{\\partial p_0}{\\partial \\boldsymbol{\\theta}}$ is the full $n \\times n$ Jacobian of $p_0$. We compute the $j$-th column of this matrix, $\\frac{\\partial p_0}{\\partial \\theta_j}$.\nUsing the product rule on $p_0 = \\Gamma (\\boldsymbol{\\mu}_a \\odot \\Phi)$:\n$$\n\\frac{\\partial p_0}{\\partial \\theta_j} = \\Gamma \\left( \\frac{\\partial \\boldsymbol{\\mu}_a}{\\partial \\theta_j} \\odot \\Phi + \\boldsymbol{\\mu}_a \\odot \\frac{\\partial \\Phi}{\\partial \\theta_j} \\right)\n$$\nThe derivative of $\\boldsymbol{\\mu}_a$ is straightforward: $\\frac{\\partial \\boldsymbol{\\mu}_a}{\\partial \\theta_j} = \\mu_{a,j} \\mathbf{e}_j$, where $\\mathbf{e}_j$ is the $j$-th standard basis vector.\nThe derivative of $\\Phi$ requires implicit differentiation of the forward equation $\\mathbf{A} \\Phi = q$:\n$$\n\\frac{\\partial \\mathbf{A}}{\\partial \\theta_j} \\Phi + \\mathbf{A} \\frac{\\partial \\Phi}{\\partial \\theta_j} = 0 \\implies \\mathbf{A} \\frac{\\partial \\Phi}{\\partial \\theta_j} = - \\frac{\\partial \\mathbf{A}}{\\partial \\theta_j} \\Phi\n$$\nThe derivative of the stiffness matrix is $\\frac{\\partial \\mathbf{A}}{\\partial \\theta_j} = \\operatorname{diag}(\\frac{\\partial \\boldsymbol{\\mu}_a}{\\partial \\theta_j}) = \\mu_{a,j} \\mathbf{E}_{jj}$, where $\\mathbf{E}_{jj}$ is a matrix with $1$ at entry $(j, j)$ and $0$ elsewhere. Therefore, the right-hand side is $-\\mu_{a,j} \\Phi_j \\mathbf{e}_j$.\nThe sensitivity of the fluence is then:\n$$\n\\frac{\\partial \\Phi}{\\partial \\theta_j} = -\\mathbf{A}(\\boldsymbol{\\theta})^{-1} (\\mu_{a,j} \\Phi_j \\mathbf{e}_j)\n$$\nSubstituting this back, the $j$-th column of the full Jacobian of $p_0$ is:\n$$\n\\frac{\\partial p_0}{\\partial \\theta_j} = \\Gamma \\mu_{a,j} \\Phi_j \\left( \\mathbf{e}_j - \\boldsymbol{\\mu}_a \\odot (\\mathbf{A}^{-1} \\mathbf{e}_j) \\right)\n$$\nTo compute this efficiently, for each $j=1,\\dots,n$, we solve one linear system $\\mathbf{A}\\mathbf{z}_j = \\mathbf{e}_j$ to find $\\mathbf{z}_j=\\mathbf{A}^{-1}\\mathbf{e}_j$ (the $j$-th column of $\\mathbf{A}^{-1}$) and then form the Jacobian column. The final Jacobian is $\\mathbf{J} = \\mathbf{S} \\left[ \\frac{\\partial p_0}{\\partial \\theta_1} | \\dots | \\frac{\\partial p_0}{\\partial \\theta_n} \\right]$.\n\n**4. Uncertainty Quantification via Laplace Approximation**\n\nNear the MAP estimate, the posterior distribution $p(\\boldsymbol{\\theta}|\\mathbf{y})$ is approximated by a multivariate Gaussian:\n$$\np(\\boldsymbol{\\theta}|\\mathbf{y}) \\approx \\mathcal{N}(\\boldsymbol{\\theta}_{\\text{MAP}}, \\mathbf{C})\n$$\nThe covariance matrix $\\mathbf{C}$ is the inverse of the Hessian of the negative log-posterior evaluated at the MAP: $\\mathbf{C} \\approx \\mathbf{H}(\\boldsymbol{\\theta}_{\\text{MAP}})^{-1}$. The diagonal entries of $\\mathbf{C}$, $\\mathbf{C}_{ii}$, are the marginal posterior variances for each parameter $\\theta_i$. These values quantify the uncertainty in our estimate of each log-absorption parameter. The algorithm computes $\\mathbf{H}(\\boldsymbol{\\theta}_{\\text{MAP}})$ using the final Jacobian $\\mathbf{J}(\\boldsymbol{\\theta}_{\\text{MAP}})$, inverts it to obtain $\\mathbf{C}$, and extracts the required diagonal elements.\nSpecifically, for $n=20$, the indices requested by the directive \"in code, use $0, \\lfloor n/2 \\rfloor, n-1$\" are $0$, $10$, and $19$. We report the variances $\\mathbf{C}_{0,0}$, $\\mathbf{C}_{10,10}$, and $\\mathbf{C}_{19,19}$.", "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Solves the 1D QPAT inverse problem for three test cases and reports\n    marginal posterior variances based on the Laplace approximation.\n    \"\"\"\n\n    test_cases_params = [\n        # Case A (general, fully observed)\n        {\n            \"n\": 20, \"D\": 1e-2, \"Gamma\": 1.0, \"q_val\": 1.0,\n            \"mu0\": 0.1, \"delta\": 0.2, \"w\": 0.1,\n            \"sensor_type\": \"all\",\n            \"sigma2\": (1e-2)**2, \"tau2\": (0.5)**2\n        },\n        # Case B (low noise, strong data)\n        {\n            \"n\": 20, \"D\": 1e-2, \"Gamma\": 1.0, \"q_val\": 1.0,\n            \"mu0\": 0.1, \"delta\": 0.2, \"w\": 0.1,\n            \"sensor_type\": \"all\",\n            \"sigma2\": (1e-4)**2, \"tau2\": (0.5)**2\n        },\n        # Case C (partial observations, weaker prior)\n        {\n            \"n\": 20, \"D\": 1e-2, \"Gamma\": 1.0, \"q_val\": 1.0,\n            \"mu0\": 0.1, \"delta\": 0.2, \"w\": 0.1,\n            \"sensor_type\": \"partial\",\n            \"sigma2\": (1e-2)**2, \"tau2\": (1.0)**2\n        }\n    ]\n\n    results = []\n\n    for params in test_cases_params:\n        n = params[\"n\"]\n        D = params[\"D\"]\n        Gamma = params[\"Gamma\"]\n        q_val = params[\"q_val\"]\n        mu0 = params[\"mu0\"]\n        delta = params[\"delta\"]\n        w = params[\"w\"]\n        sensor_type = params[\"sensor_type\"]\n        sigma2 = params[\"sigma2\"]\n        tau2 = params[\"tau2\"]\n\n        h = 1.0 / (n + 1)\n        x_nodes = np.arange(1, n + 1) * h\n        q_vec = np.full(n, q_val)\n\n        # Standard 1D finite difference matrix K\n        K = 2 * np.eye(n) - np.eye(n, k=1) - np.eye(n, k=-1)\n\n        # Ground truth and prior mean\n        mu_a_true = mu0 + delta * np.exp(-(x_nodes - 0.5)**2 / (2 * w**2))\n        theta_true = np.log(mu_a_true)\n        theta_prior = np.log(mu0) * np.ones(n)\n\n        # Sensor selection matrix S\n        if sensor_type == \"all\":\n            m = n\n            S = np.eye(n)\n        elif sensor_type == \"partial\":\n            # 1-based indices {3, 6, ..., 18} -> 0-based {2, 5, ..., 17}\n            sensor_indices = np.arange(2, n, 3)\n            m = len(sensor_indices)\n            S = np.zeros((m, n))\n            S[np.arange(m), sensor_indices] = 1.0\n        \n        # --- Forward Model: g(theta) ---\n        def forward_model(theta):\n            mu_a = np.exp(theta)\n            A = (D / h**2) * K + np.diag(mu_a)\n            # Solve A * Phi = q for Phi\n            phi = linalg.solve(A, q_vec, assume_a='pos')\n            p0 = Gamma * mu_a * phi\n            g = S @ p0\n            return g\n\n        # --- Jacobian: J(theta) ---\n        def jacobian(theta):\n            mu_a = np.exp(theta)\n            A = (D / h**2) * K + np.diag(mu_a)\n            phi = linalg.solve(A, q_vec, assume_a='pos')\n            \n            # Using scipy.linalg.solve is more stable than np.linalg.inv\n            # We solve A * z_j = e_j for each column j of the inverse\n            A_inv = linalg.inv(A)\n            \n            J_full = np.zeros((n, n))\n            for j in range(n):\n                e_j = np.zeros(n)\n                e_j[j] = 1.0\n                A_inv_col_j = A_inv[:, j]\n                # Formula derived from implicit differentiation\n                # d(p0)/d(theta_j) = Gamma * mu_a_j * Phi_j * (e_j - mu_a * (A_inv * e_j))\n                jac_col = Gamma * mu_a[j] * phi[j] * (e_j - mu_a * A_inv_col_j)\n                J_full[:, j] = jac_col\n            \n            return S @ J_full\n\n        # Generate observed data y\n        y_obs = forward_model(theta_true)\n\n        # --- Damped Gauss-Newton for MAP estimate ---\n        theta_map = np.copy(theta_prior)\n        lambda_damping = 1e-3\n        max_iter = 50\n        tol = 1e-8\n\n        for _ in range(max_iter):\n            g_curr = forward_model(theta_map)\n            J_curr = jacobian(theta_map)\n            \n            residual = g_curr - y_obs\n            \n            grad_L = (1 / sigma2) * J_curr.T @ residual + (1 / tau2) * (theta_map - theta_prior)\n\n            if np.linalg.norm(grad_L) < tol:\n                break\n            \n            # Gauss-Newton Hessian\n            H = (1 / sigma2) * (J_curr.T @ J_curr) + (1 / tau2) * np.eye(n)\n            \n            # Damped step\n            H_damped = H + lambda_damping * np.eye(n)\n            \n            try:\n                # Solve (H + lambda*I) d_theta = -grad_L\n                d_theta = linalg.solve(H_damped, -grad_L, assume_a='pos')\n                theta_map += d_theta\n            except linalg.LinAlgError:\n                # In case of instability, increase damping and retry\n                lambda_damping *= 10\n                continue\n\n            # Simple damping adjustment (optional, but good practice)\n            # A full line search or trust-region method would be more robust,\n            # but a simple update is sufficient for this problem.\n            # Here we just decrease damping for next step if solve was successful.\n            lambda_damping *= 0.1\n        \n        # --- Posterior Covariance Calculation ---\n        J_map = jacobian(theta_map)\n        H_map = (1 / sigma2) * (J_map.T @ J_map) + (1 / tau2) * np.eye(n)\n        \n        # Covariance is the inverse of the Hessian\n        C = linalg.inv(H_map)\n        \n        # Extract marginal variances at specified indices\n        # Per problem: \"in code, use 0, floor(n/2), n-1\"\n        # For n=20, this is 0, 10, 19\n        idx1 = 0\n        idx2 = n // 2\n        idx3 = n - 1\n        \n        variances = [C[idx1, idx1], C[idx2, idx2], C[idx3, idx3]]\n        results.append(variances)\n\n    # Format the final output string\n    output_str = \"[\" + \",\".join([f\"[{v[0]},{v[1]},{v[2]}]\" for v in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3410206"}]}