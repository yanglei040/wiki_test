{"hands_on_practices": [{"introduction": "In any joint inversion, a fundamental challenge is to properly balance the influence of different data sources, which may have vastly different units, scales, and noise characteristics. This exercise demonstrates the principle of inverse-covariance weighting, a statistically robust method for constructing a joint objective function. By working through this calculation [@problem_id:3404765], you will see how data with higher uncertainty (larger error variance) are naturally down-weighted, ensuring that each modality contributes to the solution in proportion to its reliability.", "problem": "Consider a joint inversion problem with two data modalities indexed by $i \\in \\{1,2\\}$. The forward maps are $F_1(m)$ and $F_2(m)$, composed with linear observation operators $H_1$ and $H_2$, yielding residuals $r_i(m) = H_i F_i(m) - d_i$. Assume additive, mean-zero Gaussian data errors for each modality with covariance matrices $C_1$ and $C_2$, respectively, that are known and positive definite. Under this assumption, the data misfit part of the joint objective is constructed using proper covariance weighting implied by the Gaussian error model. \n\nAt a particular candidate model $m^\\star$, suppose that the covariances are $C_1 = 9\\,I$ and $C_2 = I$, where $I$ denotes identity matrices of compatible dimensions, and that the Euclidean residual norms are $\\|r_1(m^\\star)\\|_2 = 3$ and $\\|r_2(m^\\star)\\|_2 = 1$. Using the Gaussian-noise-based construction of the data misfit objective with a common scalar prefactor across modalities, compute the relative contributions of each modality to the total data misfit at $m^\\star$, namely the fractions $J_1(m^\\star)/J_{\\mathrm{data}}(m^\\star)$ and $J_2(m^\\star)/J_{\\mathrm{data}}(m^\\star)$, where $J_{\\mathrm{data}}(m^\\star) = J_1(m^\\star) + J_2(m^\\star)$ denotes the total data misfit.\n\nReport your final answer as a two-entry row vector containing the two relative contributions in that order. No units are required. No rounding is necessary.", "solution": "The problem requires the calculation of the relative contributions of two data modalities to a total data misfit objective function at a specific model candidate, $m^\\star$. The construction of the objective function is based on the assumption of additive, mean-zero Gaussian errors with known covariance matrices.\n\nThe probability density function for the data $d_i$ for modality $i$, given a model $m$, is based on the Gaussian distribution of the error term, which is identified with the residual $r_i(m) = H_i F_i(m) - d_i$. The likelihood function for modality $i$ is given by:\n$$L_i(m) \\propto \\exp\\left(-\\frac{1}{2} r_i(m)^T C_i^{-1} r_i(m)\\right)$$\nwhere $C_i$ is the data error covariance matrix.\n\nFor a joint inversion problem with two statistically independent data modalities, the total likelihood is the product of the individual likelihoods:\n$$L_{\\mathrm{total}}(m) = L_1(m) \\cdot L_2(m) \\propto \\exp\\left(-\\frac{1}{2} r_1(m)^T C_1^{-1} r_1(m) - \\frac{1}{2} r_2(m)^T C_2^{-1} r_2(m)\\right)$$\n\nThe data misfit objective function, $J_{\\mathrm{data}}(m)$, is typically derived from the negative log-likelihood, ignoring any constant terms that do not depend on the model $m$. This yields a sum of quadratic forms:\n$$J_{\\mathrm{data}}(m) = \\frac{1}{2} r_1(m)^T C_1^{-1} r_1(m) + \\frac{1}{2} r_2(m)^T C_2^{-1} r_2(m)$$\nThe problem statement notes \"a common scalar prefactor\", which is consistent with the factor of $\\frac{1}{2}$ appearing in both terms. We can define the individual misfit contributions as:\n$$J_1(m) = \\frac{1}{2} r_1(m)^T C_1^{-1} r_1(m)$$\n$$J_2(m) = \\frac{1}{2} r_2(m)^T C_2^{-1} r_2(m)$$\nsuch that $J_{\\mathrm{data}}(m) = J_1(m) + J_2(m)$.\n\nWe are asked to evaluate these contributions at a specific model $m^\\star$. The givens for this evaluation are:\n- Covariance for modality $1$: $C_1 = 9\\,I$\n- Covariance for modality $2$: $C_2 = I$\n- Residual norm for modality $1$: $\\|r_1(m^\\star)\\|_2 = 3$\n- Residual norm for modality $2$: $\\|r_2(m^\\star)\\|_2 = 1$\n\nFirst, we find the inverse covariance matrices:\n$$C_1^{-1} = (9\\,I)^{-1} = \\frac{1}{9}I^{-1} = \\frac{1}{9}I$$\n$$C_2^{-1} = I^{-1} = I$$\n\nNow, we compute the value of $J_1(m^\\star)$. We substitute $C_1^{-1}$ into the expression for $J_1(m)$:\n$$J_1(m^\\star) = \\frac{1}{2} r_1(m^\\star)^T \\left(\\frac{1}{9}I\\right) r_1(m^\\star)$$\nThe term $r_1(m^\\star)^T I r_1(m^\\star)$ is equivalent to the dot product $r_1(m^\\star) \\cdot r_1(m^\\star)$, which is the squared Euclidean norm, $\\|r_1(m^\\star)\\|_2^2$.\n$$J_1(m^\\star) = \\frac{1}{2} \\cdot \\frac{1}{9} \\|r_1(m^\\star)\\|_2^2 = \\frac{1}{18} \\|r_1(m^\\star)\\|_2^2$$\nSubstituting the given value $\\|r_1(m^\\star)\\|_2 = 3$:\n$$J_1(m^\\star) = \\frac{1}{18} (3^2) = \\frac{9}{18} = \\frac{1}{2}$$\n\nNext, we compute the value of $J_2(m^\\star)$. We substitute $C_2^{-1}$ into the expression for $J_2(m)$:\n$$J_2(m^\\star) = \\frac{1}{2} r_2(m^\\star)^T (I) r_2(m^\\star)$$\nThis simplifies to:\n$$J_2(m^\\star) = \\frac{1}{2} \\|r_2(m^\\star)\\|_2^2$$\nSubstituting the given value $\\|r_2(m^\\star)\\|_2 = 1$:\n$$J_2(m^\\star) = \\frac{1}{2} (1^2) = \\frac{1}{2}$$\n\nThe total data misfit at $m^\\star$ is the sum of the individual contributions:\n$$J_{\\mathrm{data}}(m^\\star) = J_1(m^\\star) + J_2(m^\\star) = \\frac{1}{2} + \\frac{1}{2} = 1$$\n\nFinally, we compute the relative contributions of each modality to the total data misfit.\nThe relative contribution of modality $1$ is:\n$$\\frac{J_1(m^\\star)}{J_{\\mathrm{data}}(m^\\star)} = \\frac{1/2}{1} = \\frac{1}{2}$$\nThe relative contribution of modality $2$ is:\n$$\\frac{J_2(m^\\star)}{J_{\\mathrm{data}}(m^\\star)} = \\frac{1/2}{1} = \\frac{1}{2}$$\n\nThe problem asks for the answer as a two-entry row vector containing these two fractions in order. The result demonstrates the principle of inverse-covariance weighting: the raw residual for modality $1$ is larger, but because its associated data errors have a larger variance ($9$ compared to $1$), its contribution to the objective function is down-weighted accordingly, resulting in an equal contribution from both modalities at the point $m^\\star$.", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{2} & \\frac{1}{2} \\end{pmatrix}}$$", "id": "3404765"}, {"introduction": "Beyond simply weighting misfit terms, we can approach joint inversion from a fully Bayesian perspective, where information from multiple sensors is used to update our prior knowledge of a system. This practice provides a complete walkthrough of this process for a linear-Gaussian model, a cornerstone of modern data assimilation. You will derive the classic Kalman update equations for a stacked multi-modal system and apply them to a numerical example [@problem_id:3404715], providing a concrete illustration of how different data sources are optimally fused to produce a single, refined posterior estimate.", "problem": "In a joint inversion setting for two complementary sensing modalities observing a common latent geophysical state, assume a linear-Gaussian model. Let the latent state be $x \\in \\mathbb{R}^{2}$ with Gaussian prior $p(x) = \\mathcal{N}(x_{0}, P_{0})$, where $x_{0} \\in \\mathbb{R}^{2}$ and $P_{0} \\in \\mathbb{R}^{2 \\times 2}$ are given. Two independent sensing modalities produce observations $y_{1} \\in \\mathbb{R}$ and $y_{2} \\in \\mathbb{R}$ with linear models $y_{1} = H_{1} x + v_{1}$ and $y_{2} = H_{2} x + v_{2}$, where $v_{1} \\sim \\mathcal{N}(0, R_{1})$, $v_{2} \\sim \\mathcal{N}(0, R_{2})$, and $v_{1}$ and $v_{2}$ are independent conditioned on $x$. Define the stacked observation model $y = \\begin{pmatrix} y_{1} \\\\ y_{2} \\end{pmatrix} = H x + v$ with $H = \\begin{pmatrix} H_{1} \\\\ H_{2} \\end{pmatrix}$, $v = \\begin{pmatrix} v_{1} \\\\ v_{2} \\end{pmatrix}$, and block-diagonal noise covariance $R = \\begin{pmatrix} R_{1} & 0 \\\\ 0 & R_{2} \\end{pmatrix}$. Starting from Bayes’ rule and the properties of multivariate Gaussian distributions, derive from first principles the closed-form expression for the posterior mean $\\hat{x}$ and the corresponding optimal linear update gain (often termed the Kalman gain in linear-Gaussian settings) that fuses both modalities in the stacked form.\n\nThen, evaluate your expressions for the following numerically specified instance:\n- Prior mean $x_{0} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$ and prior covariance $P_{0} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix}$.\n- Observation operators $H_{1} = \\begin{pmatrix} 1 & 2 \\end{pmatrix}$ and $H_{2} = \\begin{pmatrix} 2 & -1 \\end{pmatrix}$, hence $H = \\begin{pmatrix} 1 & 2 \\\\ 2 & -1 \\end{pmatrix}$.\n- Noise covariances $R_{1} = 1$ and $R_{2} = 4$, hence $R = \\begin{pmatrix} 1 & 0 \\\\ 0 & 4 \\end{pmatrix}$.\n- Observations $y_{1} = 5$ and $y_{2} = -1$, hence $y = \\begin{pmatrix} 5 \\\\ -1 \\end{pmatrix}$.\n\nProvide the exact joint gain matrix and the updated posterior mean as rational numbers. Do not round. The final answer must be given as a single expression containing both the gain matrix and the updated mean, with no units, and expressed exactly (no approximation or rounding).", "solution": "The problem requires the derivation of the posterior mean and the optimal linear update gain for a linear-Gaussian system, followed by a numerical evaluation. The derivation will start from Bayes' rule.\n\n### Part 1: Derivation from First Principles\n\nAccording to Bayes' rule, the posterior probability density function (PDF) $p(x|y)$ is proportional to the product of the likelihood $p(y|x)$ and the prior $p(x)$:\n$$\np(x|y) \\propto p(y|x) p(x)\n$$\nThe problem states a Gaussian prior for the latent state $x \\in \\mathbb{R}^2$:\n$$\np(x) = \\mathcal{N}(x_0, P_0) \\propto \\exp\\left(-\\frac{1}{2}(x - x_0)^T P_0^{-1} (x - x_0)\\right)\n$$\nThe observation model is linear with additive Gaussian noise, $y = Hx + v$, where $v \\sim \\mathcal{N}(0, R)$. This defines the likelihood function $p(y|x)$ as a Gaussian distribution for $y$ with mean $Hx$ and covariance $R$:\n$$\np(y|x) = \\mathcal{N}(Hx, R) \\propto \\exp\\left(-\\frac{1}{2}(y - Hx)^T R^{-1} (y - Hx)\\right)\n$$\nCombining these, the posterior PDF is:\n$$\np(x|y) \\propto \\exp\\left(-\\frac{1}{2}(x - x_0)^T P_0^{-1} (x - x_0)\\right) \\exp\\left(-\\frac{1}{2}(y - Hx)^T R^{-1} (y - Hx)\\right)\n$$\n$$\np(x|y) \\propto \\exp\\left(-\\frac{1}{2} \\left[ (x - x_0)^T P_0^{-1} (x - x_0) + (y - Hx)^T R^{-1} (y - Hx) \\right]\\right)\n$$\nThe term in the exponent, which we denote as the cost function $J(x)$, is a quadratic function of $x$. This implies that the posterior distribution is also Gaussian, say $p(x|y) = \\mathcal{N}(\\hat{x}, \\hat{P})$, which has a PDF proportional to $\\exp\\left(-\\frac{1}{2}(x-\\hat{x})^T \\hat{P}^{-1} (x-\\hat{x})\\right)$. To find the posterior mean $\\hat{x}$ and covariance $\\hat{P}$, we expand $J(x)$ and collect terms in powers of $x$.\n\n$J(x) = (x^T P_0^{-1} x - 2x^T P_0^{-1} x_0 + x_0^T P_0^{-1} x_0) + ((Hx)^T R^{-1} (Hx) - 2(Hx)^T R^{-1} y + y^T R^{-1} y)$\n$J(x) = x^T P_0^{-1} x - 2x^T P_0^{-1} x_0 + x^T H^T R^{-1} H x - 2x^T H^T R^{-1} y + (\\text{terms not dependent on } x)$\nGrouping terms:\n$J(x) = x^T (P_0^{-1} + H^T R^{-1} H) x - 2x^T (P_0^{-1} x_0 + H^T R^{-1} y) + \\text{const.}$\n\nThe canonical form for the exponent of a Gaussian $\\mathcal{N}(\\hat{x}, \\hat{P})$ is $(x - \\hat{x})^T \\hat{P}^{-1} (x - \\hat{x}) = x^T \\hat{P}^{-1} x - 2x^T \\hat{P}^{-1} \\hat{x} + \\hat{x}^T \\hat{P}^{-1} \\hat{x}$. By comparing the quadratic and linear terms in $x$ with $J(x)$, we can identify the posterior inverse covariance $\\hat{P}^{-1}$ and the posterior mean $\\hat{x}$:\n\n1.  From the quadratic term ($x^T(\\dots)x$):\n    $$\n    \\hat{P}^{-1} = P_0^{-1} + H^T R^{-1} H\n    $$\n    So the posterior covariance is $\\hat{P} = (P_0^{-1} + H^T R^{-1} H)^{-1}$.\n\n2.  From the linear term ($-2x^T(\\dots)$):\n    $$\n    \\hat{P}^{-1} \\hat{x} = P_0^{-1} x_0 + H^T R^{-1} y\n    $$\n    Solving for the posterior mean $\\hat{x}$:\n    $$\n    \\hat{x} = (\\hat{P}^{-1})^{-1} (P_0^{-1} x_0 + H^T R^{-1} y) = \\hat{P} (P_0^{-1} x_0 + H^T R^{-1} y)\n    $$\nTo derive the update form involving a gain matrix, we use the matrix inversion lemma (specifically, the Woodbury identity) to express $\\hat{P}$ in a different form:\n$\\hat{P} = P_0 - P_0 H^T (H P_0 H^T + R)^{-1} H P_0$.\nLet's define the optimal linear update gain matrix $K$ (also known as the Kalman gain) as:\n$$\nK = P_0 H^T (H P_0 H^T + R)^{-1}\n$$\nWith this definition, the posterior covariance becomes $\\hat{P} = P_0 - K H P_0 = (I - KH)P_0$.\n\nNow we rearrange the expression for $\\hat{x}$ to match the update form $\\hat{x} = x_0 + K(y - Hx_0)$.\nStarting from $I = \\hat{P} \\hat{P}^{-1} = \\hat{P} (P_0^{-1} + H^T R^{-1} H) = \\hat{P} P_0^{-1} + \\hat{P} H^T R^{-1} H$, we can write $\\hat{P}P_0^{-1} = I - \\hat{P} H^T R^{-1} H$.\nAn alternative expression for the gain $K$ is $K = \\hat{P} H^T R^{-1}$.\nSubstituting this gives $\\hat{P}P_0^{-1} = I - K H$.\nNow, we rewrite the posterior mean expression:\n$\\hat{x} = \\hat{P} (P_0^{-1} x_0 + H^T R^{-1} y) = (\\hat{P} P_0^{-1}) x_0 + (\\hat{P} H^T R^{-1}) y$\nSubstituting the identities we just found:\n$\\hat{x} = (I - K H) x_0 + K y = x_0 - K H x_0 + K y$\n$$\n\\hat{x} = x_0 + K(y - Hx_0)\n$$\nThis is the desired closed-form expression for the posterior mean. The residual term $(y - Hx_0)$ is called the innovation. The gain $K$ optimally blends this new information with the prior estimate $x_0$.\n\n### Part 2: Numerical Evaluation\n\nWe are given the following numerical values:\n- Prior mean: $x_{0} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$\n- Prior covariance: $P_{0} = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix}$\n- Observation operator: $H = \\begin{pmatrix} 1 & 2 \\\\ 2 & -1 \\end{pmatrix}$\n- Noise covariance: $R = \\begin{pmatrix} 1 & 0 \\\\ 0 & 4 \\end{pmatrix}$\n- Observation vector: $y = \\begin{pmatrix} 5 \\\\ -1 \\end{pmatrix}$\n\nWe will compute the gain $K = P_0 H^T (H P_0 H^T + R)^{-1}$ and the posterior mean $\\hat{x} = x_0 + K(y - Hx_0)$.\n\n1.  **Compute the innovation covariance $S = H P_0 H^T + R$:**\n    First, calculate $P_0 H^T$:\n    $$\n    P_0 H^T = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix} \\begin{pmatrix} 1 & 2 \\\\ 2 & -1 \\end{pmatrix}^T = \\begin{pmatrix} 2 & 1 \\\\ 1 & 3 \\end{pmatrix} \\begin{pmatrix} 1 & 2 \\\\ 2 & -1 \\end{pmatrix} = \\begin{pmatrix} 2 \\cdot 1 + 1 \\cdot 2 & 2 \\cdot 2 + 1 \\cdot (-1) \\\\ 1 \\cdot 1 + 3 \\cdot 2 & 1 \\cdot 2 + 3 \\cdot (-1) \\end{pmatrix} = \\begin{pmatrix} 4 & 3 \\\\ 7 & -1 \\end{pmatrix}\n    $$\n    Next, calculate $H P_0 H^T$:\n    $$\n    H (P_0 H^T) = \\begin{pmatrix} 1 & 2 \\\\ 2 & -1 \\end{pmatrix} \\begin{pmatrix} 4 & 3 \\\\ 7 & -1 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot 4 + 2 \\cdot 7 & 1 \\cdot 3 + 2 \\cdot (-1) \\\\ 2 \\cdot 4 + (-1) \\cdot 7 & 2 \\cdot 3 + (-1) \\cdot (-1) \\end{pmatrix} = \\begin{pmatrix} 18 & 1 \\\\ 1 & 7 \\end{pmatrix}\n    $$\n    Now, add $R$:\n    $$\n    S = H P_0 H^T + R = \\begin{pmatrix} 18 & 1 \\\\ 1 & 7 \\end{pmatrix} + \\begin{pmatrix} 1 & 0 \\\\ 0 & 4 \\end{pmatrix} = \\begin{pmatrix} 19 & 1 \\\\ 1 & 11 \\end{pmatrix}\n    $$\n\n2.  **Compute $S^{-1}$:**\n    The determinant of $S$ is $\\det(S) = (19)(11) - (1)(1) = 209 - 1 = 208$.\n    The inverse is:\n    $$\n    S^{-1} = \\frac{1}{208} \\begin{pmatrix} 11 & -1 \\\\ -1 & 19 \\end{pmatrix}\n    $$\n\n3.  **Compute the gain matrix $K = P_0 H^T S^{-1}$:**\n    $$\n    K = \\begin{pmatrix} 4 & 3 \\\\ 7 & -1 \\end{pmatrix} \\frac{1}{208} \\begin{pmatrix} 11 & -1 \\\\ -1 & 19 \\end{pmatrix} = \\frac{1}{208} \\begin{pmatrix} 4 \\cdot 11 + 3 \\cdot (-1) & 4 \\cdot (-1) + 3 \\cdot 19 \\\\ 7 \\cdot 11 + (-1) \\cdot (-1) & 7 \\cdot (-1) + (-1) \\cdot 19 \\end{pmatrix}\n    $$\n    $$\n    K = \\frac{1}{208} \\begin{pmatrix} 44 - 3 & -4 + 57 \\\\ 77 + 1 & -7 - 19 \\end{pmatrix} = \\frac{1}{208} \\begin{pmatrix} 41 & 53 \\\\ 78 & -26 \\end{pmatrix}\n    $$\n    Simplifying the fractions:\n    $$\n    K = \\begin{pmatrix} \\frac{41}{208} & \\frac{53}{208} \\\\ \\frac{78}{208} & \\frac{-26}{208} \\end{pmatrix} = \\begin{pmatrix} \\frac{41}{208} & \\frac{53}{208} \\\\ \\frac{3}{8} & -\\frac{1}{8} \\end{pmatrix}\n    $$\n\n4.  **Compute the posterior mean $\\hat{x} = x_0 + K(y - Hx_0)$:**\n    First, compute the innovation $(y - Hx_0)$:\n    $$\n    H x_0 = \\begin{pmatrix} 1 & 2 \\\\ 2 & -1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot 1 + 2 \\cdot (-2) \\\\ 2 \\cdot 1 + (-1) \\cdot (-2) \\end{pmatrix} = \\begin{pmatrix} -3 \\\\ 4 \\end{pmatrix}\n    $$\n    $$\n    y - Hx_0 = \\begin{pmatrix} 5 \\\\ -1 \\end{pmatrix} - \\begin{pmatrix} -3 \\\\ 4 \\end{pmatrix} = \\begin{pmatrix} 8 \\\\ -5 \\end{pmatrix}\n    $$\n    Next, compute the update term $K(y - Hx_0)$:\n    $$\n    K(y - Hx_0) = \\begin{pmatrix} \\frac{41}{208} & \\frac{53}{208} \\\\ \\frac{3}{8} & -\\frac{1}{8} \\end{pmatrix} \\begin{pmatrix} 8 \\\\ -5 \\end{pmatrix} = \\begin{pmatrix} \\frac{41}{208} \\cdot 8 + \\frac{53}{208} \\cdot (-5) \\\\ \\frac{3}{8} \\cdot 8 + (-\\frac{1}{8}) \\cdot (-5) \\end{pmatrix} = \\begin{pmatrix} \\frac{328 - 265}{208} \\\\ 3 + \\frac{5}{8} \\end{pmatrix} = \\begin{pmatrix} \\frac{63}{208} \\\\ \\frac{29}{8} \\end{pmatrix}\n    $$\n    Finally, compute the posterior mean $\\hat{x}$:\n    $$\n    \\hat{x} = x_0 + K(y - Hx_0) = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} + \\begin{pmatrix} \\frac{63}{208} \\\\ \\frac{29}{8} \\end{pmatrix} = \\begin{pmatrix} \\frac{208}{208} + \\frac{63}{208} \\\\ -\\frac{16}{8} + \\frac{29}{8} \\end{pmatrix} = \\begin{pmatrix} \\frac{271}{208} \\\\ \\frac{13}{8} \\end{pmatrix}\n    $$\n\nThe joint gain matrix is $K = \\begin{pmatrix} \\frac{41}{208} & \\frac{53}{208} \\\\ \\frac{3}{8} & -\\frac{1}{8} \\end{pmatrix}$ and the updated posterior mean is $\\hat{x} = \\begin{pmatrix} \\frac{271}{208} \\\\ \\frac{13}{8} \\end{pmatrix}$.\nThe final answer is given as a single expression containing both the gain matrix and the updated mean.\n$$\n\\begin{pmatrix}\nK & \\hat{x}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n\\frac{41}{208} & \\frac{53}{208} & \\frac{271}{208} \\\\\n\\frac{3}{8} & -\\frac{1}{8} & \\frac{13}{8}\n\\end{pmatrix}\n$$\nThe value $\\frac{13}{8}$ can also be written as $\\frac{338}{208}$ to have a common denominator for the second row. $\\frac{3}{8} = \\frac{78}{208}$ and $-\\frac{1}{8} = -\\frac{26}{208}$ was already simplified. Keeping $\\frac{13}{8}$ is simpler. The requested format is exact rational numbers, which is satisfied by the mixed-denominator form.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{41}{208} & \\frac{53}{208} & \\frac{271}{208} \\\\\n\\frac{3}{8} & -\\frac{1}{8} & \\frac{13}{8}\n\\end{pmatrix}\n}\n$$", "id": "3404715"}, {"introduction": "Joint inversion is intrinsically a multi-objective problem, as we seek a single model that best satisfies multiple, often conflicting, criteria. This introduces the concept of a trade-off, where a perfect fit to all datasets is impossible. This exercise [@problem_id:3404773] explores the theoretical foundation of multi-objective optimization by defining the Pareto set—the collection of all non-dominated, optimal trade-off solutions. Understanding the relationship between the Pareto set and the widely used weighted-sum scalarization method is crucial for correctly interpreting the meaning of an \"optimal\" solution in a multi-modal context.", "problem": "Consider a joint inversion setting in which a model vector $m \\in \\mathcal{M}$ must explain two modalities of data, producing two convex misfit objectives $\\phi_1(m)$ and $\\phi_2(m)$, where $\\mathcal{M}$ is a nonempty convex feasible set. Assume the forward operators for each modality are linear and the data fidelity terms are quadratic, so that each $\\phi_i(m)$ is convex on $\\mathcal{M}$. Define the Pareto set for the two-objective problem and analyze the relationship between this Pareto set and the scalarized optimization problems of the form\n$$\n\\min_{m \\in \\mathcal{M}} \\ \\alpha \\, \\phi_1(m) + (1-\\alpha) \\, \\phi_2(m), \\quad \\text{with } \\alpha \\in (0,1).\n$$\nYour answer should be based on first principles of convex analysis and multiobjective optimality.\n\nSelect the statement that is most accurate under the stated convexity assumptions:\n\nA. The Pareto set is the set of $m \\in \\mathcal{M}$ that simultaneously minimize both $\\phi_1(m)$ and $\\phi_2(m)$, and any choice of $\\alpha \\in (0,1)$ recovers all Pareto points (every Pareto point is a solution of the scalarized problem for some $\\alpha$), even if the attainable objective set $\\{(\\phi_1(m),\\phi_2(m)) : m \\in \\mathcal{M}\\}$ is nonconvex.\n\nB. The Pareto set is the set of nondominated $m \\in \\mathcal{M}$ such that there is no $m' \\in \\mathcal{M}$ with $\\phi_i(m') \\le \\phi_i(m)$ for $i=1,2$ and strict inequality in at least one objective; for any $\\alpha \\in (0,1)$, every minimizer of $\\alpha \\phi_1 + (1-\\alpha)\\phi_2$ is Pareto optimal, and varying $\\alpha$ recovers all supported (weakly) Pareto points. If the attainable objective set $\\{(\\phi_1(m),\\phi_2(m)) : m \\in \\mathcal{M}\\}$ is convex, then every Pareto optimal point is supported and is recovered by some $\\alpha \\in (0,1)$.\n\nC. The Pareto set consists of all $m \\in \\mathcal{M}$ such that $\\phi_1(m) + \\phi_2(m)$ is minimized, and scalarization with $\\alpha \\in (0,1)$ can return non-Pareto points even when $\\phi_1$ and $\\phi_2$ are convex on a convex $\\mathcal{M}$.\n\nD. The Pareto set equals the intersection $\\bigcap_{\\alpha \\in (0,1)} \\arg\\min_{m \\in \\mathcal{M}} \\alpha \\phi_1(m) + (1-\\alpha) \\phi_2(m)$, so the scalarized problems are equivalent to multiobjective optimality without loss, regardless of the geometry of the attainable objective set.", "solution": "The problem statement will be validated before a solution is attempted.\n\n### Step 1: Extract Givens\n\n-   Model vector: $m \\in \\mathcal{M}$\n-   Feasible set: $\\mathcal{M}$ is a nonempty convex set.\n-   Misfit objectives: $\\phi_1(m)$ and $\\phi_2(m)$, representing two data modalities.\n-   Function properties: $\\phi_1(m)$ and $\\phi_2(m)$ are convex functions on $\\mathcal{M}$. This is stated to be a consequence of linear forward operators and quadratic data fidelity terms.\n-   Scalarized optimization problem: $\\min_{m \\in \\mathcal{M}} \\ \\alpha \\, \\phi_1(m) + (1-\\alpha) \\, \\phi_2(m)$, with $\\alpha \\in (0,1)$.\n-   Task: Analyze the relationship between the Pareto set for the two-objective problem and the solutions of the scalarized problems, and select the most accurate statement among the options.\n\n### Step 2: Validate Using Extracted Givens\n\n-   **Scientifically Grounded (Critical)**: The problem is firmly rooted in the mathematical theory of multiobjective optimization and convex analysis, which are standard tools in inverse problems and data assimilation fields. The concepts of Pareto optimality, convex functions, and scalarization (weighted sum method) are well-defined and fundamental. The setup is scientifically sound.\n-   **Well-Posed**: The problem asks for a theoretical analysis of the relationship between different types of solution sets under specified mathematical conditions. The provided information (convexity of functions and the feasible set) is sufficient to perform this analysis based on established theorems. The question is well-posed.\n-   **Objective (Critical)**: The problem is stated using precise, formal mathematical language. Terms like \"convex set\", \"convex function\", and \"Pareto set\" have unambiguous definitions. The problem is objective.\n-   **Incomplete or Contradictory Setup**: The setup is self-consistent and provides the necessary assumptions (convexity) to reason about the problem. There are no contradictions.\n-   **Unrealistic or Infeasible**: The setting described is a standard and widely used model in multi-modal joint inversion, where one seeks a single model to explain data from different physical measurements (e.g., seismic and gravity data in geophysics). The assumptions are realistic within this theoretical context.\n-   **No other flaws detected**: The problem is not trivial, ill-posed, or metaphorical. It addresses a core conceptual challenge in multiobjective optimization.\n\n### Step 3: Verdict and Action\n\nThe problem statement is **valid**. A solution will be derived based on first principles.\n\n### Derivation\n\nThe core of the problem lies in the relationship between the solutions of a multiobjective optimization problem and the solutions of a related single-objective, scalarized problem.\n\n**1. Definitions**\n\n-   **Multiobjective Problem**: The problem is to conceptually \"minimize\" both $\\phi_1(m)$ and $\\phi_2(m)$ simultaneously for $m \\in \\mathcal{M}$. We can write this as:\n    $$ \\min_{m \\in \\mathcal{M}} \\ (\\phi_1(m), \\phi_2(m)) $$\n-   **Pareto Dominance**: A model $m' \\in \\mathcal{M}$ *dominates* a model $m \\in \\mathcal{M}$ if $\\phi_i(m') \\leq \\phi_i(m)$ for $i=1, 2$ and there exists at least one index $j \\in \\{1, 2\\}$ for which $\\phi_j(m') < \\phi_j(m)$.\n-   **Pareto Optimality**: A model $m^* \\in \\mathcal{M}$ is **Pareto optimal** (or nondominated, or efficient) if there is no other model $m' \\in \\mathcal{M}$ that dominates it. The set of all such points is the **Pareto set**.\n-   **Scalarized Problem (Weighted Sum Method)**: For a given weight $\\alpha \\in (0,1)$, the scalarized problem is:\n    $$ P(\\alpha): \\min_{m \\in \\mathcal{M}} \\Phi_\\alpha(m) \\text{ where } \\Phi_\\alpha(m) = \\alpha \\, \\phi_1(m) + (1-\\alpha) \\, \\phi_2(m) $$\n    The objective function $\\Phi_\\alpha(m)$ is a positive weighted sum of two convex functions ($\\phi_1, \\phi_2$), so $\\Phi_\\alpha(m)$ is also convex. The minimization is over a convex set $\\mathcal{M}$. This is a standard convex optimization problem.\n\n**2. Relationship between Scalarization and Pareto Optimality**\n\n-   **Part 1: Any solution to $P(\\alpha)$ for $\\alpha \\in (0,1)$ is Pareto optimal.**\n    Let $m^*$ be a minimizer of $\\Phi_\\alpha(m)$ for some $\\alpha \\in (0,1)$. Assume, for the sake of contradiction, that $m^*$ is not Pareto optimal. Then there exists an $m' \\in \\mathcal{M}$ that dominates $m^*$. By definition of dominance, this means:\n    1.  $\\phi_1(m') \\leq \\phi_1(m^*)$\n    2.  $\\phi_2(m') \\leq \\phi_2(m^*)$\n    3.  At least one of these inequalities is strict.\n    \n    Since $\\alpha > 0$ and $1-\\alpha > 0$, we can multiply these inequalities by the weights:\n    1.  $\\alpha \\phi_1(m') \\leq \\alpha \\phi_1(m^*)$\n    2.  $(1-\\alpha) \\phi_2(m') \\leq (1-\\alpha) \\phi_2(m^*)$\n\n    Summing these gives:\n    $$ \\alpha \\phi_1(m') + (1-\\alpha) \\phi_2(m') \\leq \\alpha \\phi_1(m^*) + (1-\\alpha) \\phi_2(m^*) $$\n    $$ \\implies \\Phi_\\alpha(m') \\leq \\Phi_\\alpha(m^*) $$\n    Furthermore, since one of the initial inequalities is strict (e.g., $\\phi_1(m') < \\phi_1(m^*)$), and its corresponding weight ($\\alpha$) is strictly positive, the final inequality must also be strict:\n    $$ \\Phi_\\alpha(m') < \\Phi_\\alpha(m^*) $$\n    This contradicts the assumption that $m^*$ is a minimizer of $\\Phi_\\alpha(m)$. Therefore, the initial assumption must be false, and $m^*$ must be Pareto optimal. This holds for any minimizer of the scalarized problem with weights in $(0,1)$.\n\n-   **Part 2: Is every Pareto optimal point a solution to $P(\\alpha)$ for some $\\alpha$?**\n    This is not guaranteed in general. The answer depends on the geometry of the **attainable objective set**, defined as $Y = \\{(\\phi_1(m), \\phi_2(m)) \\mid m \\in \\mathcal{M}\\}$. The solutions to the scalarized problems for all $\\alpha \\in [0,1]$ correspond to points on the boundary of the convex hull of $Y$. These are called **supported Pareto optimal points**.\n    Even if the model space $\\mathcal{M}$ is convex and the objective functions $\\phi_i$ are convex, the mapping $m \\mapsto (\\phi_1(m), \\phi_2(m))$ is a vector-valued function, and the image of a convex set under this mapping is **not** generally convex.\n    If $Y$ is not convex, there can be Pareto optimal points that are not supported. These \"unsupported\" points lie in the non-convex \"dents\" of the Pareto frontier and cannot be found by the weighted sum method.\n    However, there is a crucial theorem: **If the attainable objective set $Y$ is convex, then every Pareto optimal point is a supported point.** Thus, for any Pareto optimal $m^*$, there exists an $\\alpha \\in [0,1]$ such that $m^*$ is a solution to $P(\\alpha)$.\n\n### Option-by-Option Analysis\n\n-   **A. The Pareto set is the set of $m \\in \\mathcal{M}$ that simultaneously minimize both $\\phi_1(m)$ and $\\phi_2(m)$, and any choice of $\\alpha \\in (0,1)$ recovers all Pareto points (every Pareto point is a solution of the scalarized problem for some $\\alpha$), even if the attainable objective set $\\{(\\phi_1(m),\\phi_2(m)) : m \\in \\mathcal{M}\\}$ is nonconvex.**\n    The first part of the statement provides an incorrect definition of the Pareto set. The set of points that simultaneously minimize both objectives is called the \"utopia point\" in objective space, and a model achieving this is often non-existent in practice due to trade-offs. The Pareto set is the entire set of non-dominated trade-off solutions. The second part is also incorrect. If the attainable objective set is nonconvex, the weighted sum method (scalarization) is not guaranteed to recover all Pareto points; it only recovers the supported ones.\n    **Verdict: Incorrect.**\n\n-   **B. The Pareto set is the set of nondominated $m \\in \\mathcal{M}$ such that there is no $m' \\in \\mathcal{M}$ with $\\phi_i(m') \\le \\phi_i(m)$ for $i=1,2$ and strict inequality in at least one objective; for any $\\alpha \\in (0,1)$, every minimizer of $\\alpha \\phi_1 + (1-\\alpha)\\phi_2$ is Pareto optimal, and varying $\\alpha$ recovers all supported (weakly) Pareto points. If the attainable objective set $\\{(\\phi_1(m),\\phi_2(m)) : m \\in \\mathcal{M}\\}$ is convex, then every Pareto optimal point is supported and is recovered by some $\\alpha \\in (0,1)$.**\n    This statement is composed of several correct claims.\n    1. It gives the correct definition of the Pareto set via non-dominance.\n    2. It correctly states that for $\\alpha \\in (0,1)$, any minimizer of the scalarized problem is Pareto optimal (as proven above).\n    3. It correctly characterizes the set of points found by varying $\\alpha$ as the \"supported\" Pareto points.\n    4. It correctly states the fundamental result that if the attainable objective set is convex, the distinction between supported and unsupported points vanishes, and (nearly all) Pareto points can be found via scalarization. The use of $\\alpha \\in (0,1)$ technically excludes the extreme endpoints which might uniquely minimize one objective and require $\\alpha=0$ or $\\alpha=1$, but this is a minor detail, and this statement is by far the most accurate and comprehensive.\n    **Verdict: Correct.**\n\n-   **C. The Pareto set consists of all $m \\in \\mathcal{M}$ such that $\\phi_1(m) + \\phi_2(m)$ is minimized, and scalarization with $\\alpha \\in (0,1)$ can return non-Pareto points even when $\\phi_1$ and $\\phi_2$ are convex on a convex $\\mathcal{M}$.**\n    The first part is incorrect. Minimizing the sum $\\phi_1(m) + \\phi_2(m)$ corresponds to a single point (or set of points) on the Pareto frontier (specifically, for $\\alpha=1/2$). This is not the entire Pareto set. The second part is also incorrect. As demonstrated in the derivation, for the specified conditions ($\\phi_i$ convex, $\\mathcal{M}$ convex) and $\\alpha \\in (0,1)$, a minimizer is always Pareto optimal.\n    **Verdict: Incorrect.**\n\n-   **D. The Pareto set equals the intersection $\\bigcap_{\\alpha \\in (0,1)} \\arg\\min_{m \\in \\mathcal{M}} \\alpha \\phi_1(m) + (1-\\alpha) \\phi_2(m)$, so the scalarized problems are equivalent to multiobjective optimality without loss, regardless of the geometry of the attainable objective set.**\n    This statement is fundamentally flawed. The Pareto set is related to the *union* of the solution sets over different $\\alpha$, not the *intersection*. The intersection would contain only models that are optimal for all weights simultaneously, which is an extremely restrictive condition, usually yielding an empty set or a single utopia point if one exists. Furthermore, the claim that equivalence holds \"regardless of the geometry of the attainable objective set\" is false. The geometry, specifically the convexity of this set, is the critical factor determining whether scalarization can recover the entire Pareto set.\n    **Verdict: Incorrect.**", "answer": "$$\\boxed{B}$$", "id": "3404773"}]}