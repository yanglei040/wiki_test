{"hands_on_practices": [{"introduction": "The foundation of any inverse problem is a robust and accurate forward model. This first practice dives into the computational core of Electrical Impedance Tomography (EIT) by guiding you through the assembly of the system matrix for the Complete Electrode Model (CEM). By implementing the Finite Element Method (FEM) from its weak formulation, you will gain a deep, practical understanding of how physical laws are translated into the discrete algebraic systems that computers can solve [@problem_id:3378244].", "problem": "You are asked to derive, implement, and test the assembly of the global stiffness matrix for the Complete Electrode Model (CEM) in Electrical Impedance Tomography (EIT), using piecewise-linear finite elements on a two-dimensional domain. Your derivation must begin from the variational form of the governing equations for the conductivity model and CEM boundary conditions, and proceed to explicit formulas for the element-level contributions. You must implement the algorithm in a runnable program that constructs the global matrix and verifies specific properties for selected test cases.\n\nThe physical model is as follows. Let $\\Omega \\subset \\mathbb{R}^2$ be a polygonal domain with boundary $\\partial \\Omega$. The electric potential is $u: \\Omega \\to \\mathbb{R}$, the conductivity is $\\sigma: \\Omega \\to \\mathbb{R}_+$ piecewise constant, and the system has $M$ electrodes $\\{E_m\\}_{m=1}^M$ on $\\partial \\Omega$, with electrode potentials $\\{U_m\\}_{m=1}^M$. The governing equation is the steady-state conduction equation\n$$\n\\nabla \\cdot (\\sigma \\nabla u) = 0 \\quad \\text{in } \\Omega,\n$$\nwith the Complete Electrode Model (CEM) boundary conditions on each electrode $E_m$,\n$$\nu + z_m \\, \\sigma \\, \\partial_n u = U_m \\quad \\text{on } E_m,\n$$\nand $\\sigma \\, \\partial_n u = 0$ on the remaining boundary $\\partial \\Omega \\setminus \\cup_m E_m$. Here, $z_m > 0$ denotes the contact impedance for $E_m$, and $\\partial_n u$ is the normal derivative. Conservation of current on electrodes implies the net current constraint\n$$\n\\int_{E_m} \\sigma \\, \\partial_n u \\, ds = I_m,\n$$\nwhich can be rewritten using the boundary condition as\n$$\n\\int_{E_m} z_m^{-1}\\,(U_m - u) \\, ds = I_m.\n$$\nIn the finite element method with piecewise-linear basis $\\{\\phi_i\\}_{i=1}^N$, the weak form leads to the block linear system for unknown nodal coefficients $u \\in \\mathbb{R}^N$ and electrode potentials $U \\in \\mathbb{R}^M$:\n$$\n\\begin{bmatrix}\nK + \\displaystyle\\sum_{m=1}^M M^{(m)} & -C \\\\\n-C^\\top & D\n\\end{bmatrix}\n\\begin{bmatrix}\nu \\\\\nU\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 \\\\\nI\n\\end{bmatrix},\n$$\nwhere\n$$\nK_{ij} = \\int_{\\Omega} \\sigma \\, \\nabla \\phi_i \\cdot \\nabla \\phi_j \\, d\\Omega,\n\\quad\nM^{(m)}_{ij} = \\int_{E_m} z_m^{-1}\\, \\phi_i \\phi_j \\, ds,\n\\quad\nC_{i m} = \\int_{E_m} z_m^{-1}\\, \\phi_i \\, ds,\n\\quad\nD_{m m} = \\int_{E_m} z_m^{-1} \\cdot 1 \\, ds = z_m^{-1} \\, |E_m|.\n$$\nThese formulas must be derived from first principles and implemented exactly. The global matrix is symmetric. Without a gauge fixing (for example, setting one electrode potential to a reference value), the block system has a one-dimensional nullspace corresponding to a uniform shift of the potentials, i.e., $u \\mapsto u + c$ and $U_m \\mapsto U_m + c$ for constant $c$.\n\nYour implementation must:\n- Build a uniform triangular mesh of the unit square $\\Omega = [0,1]\\times[0,1]$ using a structured grid with $n_x$ subdivisions in the $x$ direction and $n_y$ subdivisions in the $y$ direction, and split each rectangular cell into two triangles.\n- Assemble $K$ from triangle areas and gradients of basis functions by exact formulas for linear triangles.\n- Assemble the electrode boundary mass matrices $M^{(m)}$, the coupling matrix $C$, and the electrode diagonal $D$ from the boundary edge integrals using exact one-dimensional piecewise-linear quadrature on boundary segments.\n- Construct the global block matrix\n$$\nA = \\begin{bmatrix}\nK + \\sum_{m=1}^M M^{(m)} & -C \\\\\n-C^\\top & D\n\\end{bmatrix}.\n$$\n\nYou must test your implementation on the following set of parameter values (the test suite). Each test case specifies $(n_x,n_y)$, the number $M$ of electrodes, the electrode intervals along the bottom boundary $y=0$, and the piecewise constant conductivity $\\sigma(\\mathbf{x})$. The contact impedance $z_m$ has units of Ohm square-meter, written as $\\mathrm{\\Omega\\, m^2}$, while potentials $u$ and $U_m$ are in volts; however, all requested outputs below are dimensionless booleans or unitless floats.\n\n- Test case $1$ (general configuration):\n  - $n_x = 10$, $n_y = 8$.\n  - Conductivity $\\sigma(\\mathbf{x}) \\equiv 1$ (uniform).\n  - Electrodes on $y=0$: $E_1: x \\in [0.0, 0.3]$ with $z_1 = 0.05$ $\\mathrm{\\Omega\\, m^2}$; $E_2: x \\in [0.5, 0.9]$ with $z_2 = 0.1$ $\\mathrm{\\Omega\\, m^2}$.\n- Test case $2$ (heterogeneous conductivity and full-length electrode):\n  - $n_x = 6$, $n_y = 4$.\n  - Conductivity $\\sigma(\\mathbf{x}) = 1$ for $x  0.5$, and $\\sigma(\\mathbf{x}) = 2$ for $x \\ge 0.5$.\n  - Single electrode on $y=0$: $E_1: x \\in [0.0, 1.0]$ with $z_1 = 0.2$ $\\mathrm{\\Omega\\, m^2}$.\n- Test case $3$ (edge case: short electrodes and contrasting impedances):\n  - $n_x = 5$, $n_y = 5$.\n  - Conductivity $\\sigma(\\mathbf{x}) \\equiv 1$ (uniform).\n  - Electrodes on $y=0$: $E_1: x \\in [0.0, 0.2]$ with $z_1 = 0.01$ $\\mathrm{\\Omega\\, m^2}$; $E_2: x \\in [0.8, 1.0]$ with $z_2 = 0.5$ $\\mathrm{\\Omega\\, m^2}$.\n\nFor each test case, your program must compute and report the following quantities:\n- A boolean indicating whether the assembled global matrix $A$ is symmetric (to numerical tolerance).\n- For each electrode $m$, the float ratio\n$$\nr_m = \\frac{D_{m m}}{z_m^{-1} \\, |E_m|},\n$$\nwhich should be close to $1$ if $D$ correctly encodes the $z_m^{-1}$ terms linking $u$ and $U_m$.\n- An integer giving the dimension of the numerically detected nullspace of $A$ (count of eigenvalues whose absolute value is below a relative threshold), expected to be $1$ in these configurations without gauge fixing.\n\nFinal output format:\n- Your program should produce a single line of output containing the concatenated results across the three test cases as a comma-separated list enclosed in square brackets. For example, for three test cases with outputs $[b_1, r^{(1)}_1, r^{(1)}_2, d_1]$, $[b_2, r^{(2)}_1, d_2]$, and $[b_3, r^{(3)}_1, r^{(3)}_2, d_3]$, your program should print\n$$\n[ b_1, r^{(1)}_1, r^{(1)}_2, d_1, b_2, r^{(2)}_1, d_2, b_3, r^{(3)}_1, r^{(3)}_2, d_3 ].\n$$\nAll booleans and floats must be standard Python primitives. All requested outputs are dimensionless.\n\nYour final answer must be a complete, runnable Python program that follows the Execution Environment specifications and produces the output in the exact format described above, with no additional text.", "solution": "The problem asks for the implementation of a Finite Element Method (FEM) assembly for the Complete Electrode Model (CEM) in EIT. The core of the task is to translate the weak formulation of the governing PDE and boundary conditions into a discrete block matrix system.\n\n### Derivation of the Finite Element System\n\nThe derivation starts from the governing PDE $\\nabla \\cdot (\\sigma \\nabla u) = 0$. We multiply by a test function $v \\in H^1(\\Omega)$ and integrate over the domain $\\Omega$. Using Green's first identity (integration by parts), we get:\n$$\n- \\int_{\\Omega} \\nabla v \\cdot (\\sigma \\nabla u) \\, d\\Omega + \\int_{\\partial \\Omega} v \\, (\\sigma \\, \\partial_n u) \\, ds = 0\n$$\nThe boundary integral is split over the electrodes $\\{E_m\\}$ and the gaps. On the gaps, $\\sigma \\, \\partial_n u = 0$. On each electrode $E_m$, the CEM boundary condition $u + z_m \\sigma \\partial_n u = U_m$ is rearranged to express the normal current density: $\\sigma \\, \\partial_n u = z_m^{-1}(U_m - u)$. Substituting this into the boundary integral yields the weak form:\n$$\n\\int_{\\Omega} \\sigma \\nabla u \\cdot \\nabla v \\, d\\Omega = \\sum_{m=1}^M \\int_{E_m} v \\, z_m^{-1}(U_m - u) \\, ds\n$$\nRearranging to group terms involving the unknowns $u$ and $\\{U_m\\}$ gives:\n$$\n\\int_{\\Omega} \\sigma \\nabla u \\cdot \\nabla v \\, d\\Omega + \\sum_{m=1}^M \\int_{E_m} z_m^{-1} u v \\, ds = \\sum_{m=1}^M \\int_{E_m} z_m^{-1} U_m v \\, ds\n$$\nThis equation forms the basis for the first block row of the final system.\n\nThe second part of the system comes from the current conservation law for each electrode: $I_m = \\int_{E_m} \\sigma \\, \\partial_n u \\, ds$. Substituting the CEM condition for $\\sigma \\partial_n u$ gives:\n$$\nI_m = \\int_{E_m} z_m^{-1}(U_m - u) \\, ds\n$$\nThese two sets of equations are then discretized using the Finite Element Method. We approximate the potential $u$ as a linear combination of basis functions, $u(x) \\approx u_h(x) = \\sum_{j=1}^N u_j \\phi_j(x)$, and use the basis functions $\\phi_i$ as test functions (Galerkin method). This process leads directly to the specified block matrix system:\n$$\n\\begin{bmatrix}\nK + \\sum_{m=1}^M M^{(m)}  -C \\\\\n-C^\\top  D\n\\end{bmatrix}\n\\begin{bmatrix}\nu \\\\\nU\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n0 \\\\\nI\n\\end{bmatrix}\n$$\nwhere the matrices $K, M^{(m)}, C, D$ correspond to the integrals of products of basis functions and their gradients, as defined in the problem statement. This confirms the validity of the target matrix structure.\n\n### Implementation Strategy\n\nThe implementation involves three main stages:\n1.  **Mesh Generation:** A structured triangular mesh is created on the unit square. This involves defining nodes and then connecting them to form triangular elements. The nodes are indexed, and the elements are defined by the indices of their three vertices.\n2.  **Matrix Assembly:**\n    - The stiffness matrix $K$ is assembled by iterating over all triangular elements. For each element, a $3 \\times 3$ local stiffness matrix is computed using exact formulas for linear basis functions (which have constant gradients). The conductivity $\\sigma$ is evaluated at the element's centroid.\n    - The boundary matrices $M_{tot} = \\sum M^{(m)}$, $C$, and $D$ are assembled by iterating over the boundary edges that lie on $y=0$. For each such edge, its intersection with each electrode's interval is determined. The contributions to the matrices are then calculated by exactly integrating the products of the 1D linear basis functions (which are polynomials of degree up to 2) over these intersection intervals.\n3.  **Analysis:** The final block matrix $A$ is constructed from its components. Its symmetry is checked using `numpy.allclose`. The ratio $r_m$ is calculated from the diagonal entries of the assembled matrix $D$. The dimension of the nullspace is found by computing the eigenvalues of the symmetric matrix $A$ and counting how many are numerically close to zero, relative to the largest eigenvalue. This is a standard and robust approach to finding the numerical rank. The Python script implements these steps for each test case and formats the output as required.", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n\n    # Test case 1: general configuration\n    test1_electrodes = [\n        {'interval': (0.0, 0.3), 'z': 0.05},\n        {'interval': (0.5, 0.9), 'z': 0.1}\n    ]\n    def sigma1(x, y):\n        return 1.0\n\n    # Test case 2: heterogeneous conductivity and full-length electrode\n    test2_electrodes = [\n        {'interval': (0.0, 1.0), 'z': 0.2}\n    ]\n    def sigma2(x, y):\n        return 2.0 if x >= 0.5 else 1.0\n\n    # Test case 3: edge case: short electrodes and contrasting impedances\n    test3_electrodes = [\n        {'interval': (0.0, 0.2), 'z': 0.01},\n        {'interval': (0.8, 1.0), 'z': 0.5}\n    ]\n    def sigma3(x, y):\n        return 1.0\n        \n    test_cases = [\n        {'nx': 10, 'ny': 8, 'sigma_func': sigma1, 'electrodes': test1_electrodes},\n        {'nx': 6, 'ny': 4, 'sigma_func': sigma2, 'electrodes': test2_electrodes},\n        {'nx': 5, 'ny': 5, 'sigma_func': sigma3, 'electrodes': test3_electrodes},\n    ]\n\n    all_results = []\n    for case in test_cases:\n        results = run_case(\n            case['nx'], case['ny'], case['sigma_func'], case['electrodes']\n        )\n        all_results.extend(results)\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, all_results))}]\")\n\n\ndef run_case(nx, ny, sigma_func, electrodes):\n    \"\"\"\n    Generates mesh, assembles matrices, and computes required validation quantities for a single test case.\n    \"\"\"\n    nodes, elements = generate_mesh(nx, ny)\n    num_nodes = len(nodes)\n    num_electrodes = len(electrodes)\n\n    K = np.zeros((num_nodes, num_nodes))\n    for elem_nodes_indices in elements:\n        p1_idx, p2_idx, p3_idx = elem_nodes_indices\n        p1, p2, p3 = nodes[p1_idx], nodes[p2_idx], nodes[p3_idx]\n        \n        # Element stiffness matrix K^e\n        area = 0.5 * abs(p1[0]*(p2[1]-p3[1]) + p2[0]*(p3[1]-p1[1]) + p3[0]*(p1[1]-p2[1]))\n        \n        # Gradients of basis functions\n        b = np.array([p2[1]-p3[1], p3[1]-p1[1], p1[1]-p2[1]]) / (2 * area)\n        c = np.array([p3[0]-p2[0], p1[0]-p3[0], p2[0]-p1[0]]) / (2 * area)\n\n        # Conductivity at element centroid\n        centroid = (p1 + p2 + p3) / 3.0\n        sigma = sigma_func(centroid[0], centroid[1])\n        \n        Ke = np.zeros((3, 3))\n        for i in range(3):\n            for j in range(3):\n                Ke[i, j] = sigma * (b[i]*b[j] + c[i]*c[j]) * area\n        \n        # Assemble into global K\n        for i in range(3):\n            for j in range(3):\n                K[elem_nodes_indices[i], elem_nodes_indices[j]] += Ke[i, j]\n\n    # Boundary matrix assembly\n    M_tot = np.zeros((num_nodes, num_nodes))\n    C = np.zeros((num_nodes, num_electrodes))\n    D = np.zeros((num_electrodes, num_electrodes))\n\n    for m, elec in enumerate(electrodes):\n        elec_start, elec_end = elec['interval']\n        z_inv = 1.0 / elec['z']\n        \n        # Iterate over boundary edges on y=0\n        for i in range(nx):\n            n1_idx, n2_idx = i, i + 1\n            x1, x2 = nodes[n1_idx][0], nodes[n2_idx][0]\n            \n            # Find intersection of edge [x1, x2] and electrode [elec_start, elec_end]\n            overlap_start = max(x1, elec_start)\n            overlap_end = min(x2, elec_end)\n\n            if overlap_start  overlap_end:\n                # Integrate basis functions over the overlap interval [a, b]\n                a, b = overlap_start, overlap_end\n                h = x2 - x1\n                \n                # Polynomials for basis functions and their products\n                # psi1(x) = (x2-x)/h\n                psi1_coeffs = [x2/h, -1/h]\n                # psi2(x) = (x-x1)/h\n                psi2_coeffs = [-x1/h, 1/h]\n                # psi1^2(x) = ((x2-x)/h)^2\n                psi1_sq_coeffs = [x2**2/h**2, -2*x2/h**2, 1/h**2]\n                # psi2^2(x) = ((x-x1)/h)^2\n                psi2_sq_coeffs = [x1**2/h**2, -2*x1/h**2, 1/h**2]\n                # psi1*psi2(x) = (x2-x)(x-x1)/h^2\n                psi12_coeffs = [-x1*x2/h**2, (x1+x2)/h**2, -1/h**2]\n                \n                I1 = poly_integrate_definite(psi1_coeffs, a, b)\n                I2 = poly_integrate_definite(psi2_coeffs, a, b)\n                I11 = poly_integrate_definite(psi1_sq_coeffs, a, b)\n                I22 = poly_integrate_definite(psi2_sq_coeffs, a, b)\n                I12 = poly_integrate_definite(psi12_coeffs, a, b)\n                \n                # Add to C\n                C[n1_idx, m] += z_inv * I1\n                C[n2_idx, m] += z_inv * I2\n\n                # Add to M_tot\n                M_tot[n1_idx, n1_idx] += z_inv * I11\n                M_tot[n2_idx, n2_idx] += z_inv * I22\n                M_tot[n1_idx, n2_idx] += z_inv * I12\n                M_tot[n2_idx, n1_idx] += z_inv * I12\n        \n        # Diagonal D matrix entry\n        D[m, m] = z_inv * (elec_end - elec_start)\n\n    # Construct global block matrix A\n    A = np.block([\n        [K + M_tot, -C],\n        [-C.T, D]\n    ])\n\n    # Perform analysis\n    # 1. Symmetry check\n    is_symmetric = bool(np.allclose(A, A.T, atol=1e-12))\n    \n    # 2. Ratio check for D\n    ratios = []\n    for m, elec in enumerate(electrodes):\n        elec_start, elec_end = elec['interval']\n        elec_len = elec_end - elec_start\n        z_inv = 1.0 / elec['z']\n        \n        Dmm_val = D[m,m]\n        ratio = Dmm_val / (z_inv * elec_len) if elec_len > 0 else 1.0\n        ratios.append(ratio)\n\n    # 3. Nullspace dimension\n    eigvals = np.linalg.eigvalsh(A)\n    max_abs_eig = np.max(np.abs(eigvals)) if eigvals.size > 0 else 0\n    if max_abs_eig  1e-15:\n        null_dim = A.shape[0]\n    else:\n        # Relative tolerance as suggested\n        tol = 1e-10 * max_abs_eig\n        null_dim = int(np.sum(np.abs(eigvals)  tol))\n        \n    return [is_symmetric, *ratios, null_dim]\n\ndef generate_mesh(nx, ny):\n    \"\"\"\n    Generates a structured triangular mesh on the unit square [0,1]x[0,1].\n    \"\"\"\n    x = np.linspace(0, 1, nx + 1)\n    y = np.linspace(0, 1, ny + 1)\n    nodes = np.array([[xi, yi] for yi in y for xi in x])\n    \n    elements = []\n    for j in range(ny):\n        for i in range(nx):\n            p00 = j * (nx + 1) + i\n            p10 = j * (nx + 1) + (i + 1)\n            p01 = (j + 1) * (nx + 1) + i\n            p11 = (j + 1) * (nx + 1) + (i + 1)\n            # Split quad into two triangles\n            elements.append([p00, p10, p11])\n            elements.append([p00, p11, p01])\n            \n    return nodes, np.array(elements)\n\n\ndef poly_integrate_definite(coeffs, a, b):\n    \"\"\"\n    Computes the definite integral of a polynomial from a to b.\n    Polynomial is given by coeffs p(x) = c0 + c1*x + c2*x^2 + ...\n    \"\"\"\n    if not coeffs:\n        return 0.0\n    \n    # Indefinite integral coeffs = [0, c0, c1/2, c2/3, ...]\n    indef_coeffs = [0.0] * (len(coeffs) + 1)\n    for i, c in enumerate(coeffs):\n        indef_coeffs[i+1] = c / (i + 1)\n    \n    def poly_eval(p_coeffs, x):\n        res = 0.0\n        # Horner's method is more stable, but direct eval is fine for low degree\n        for i, c in enumerate(p_coeffs):\n            res += c * (x**i)\n        return res\n\n    return poly_eval(indef_coeffs, b) - poly_eval(indef_coeffs, a)\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3378244"}, {"introduction": "Most powerful algorithms for solving inverse problems are gradient-based, relying on the Jacobian of the forward map to guide the reconstruction. However, an incorrect Jacobian can lead to failed or misleading results. This practice introduces a crucial validation technique: the Taylor remainder test, which serves as a numerical \"unit test\" to confirm that your implementation of the Jacobian-vector product is correct before you build a full inversion algorithm upon it [@problem_id:3378201].", "problem": "Consider the steady-state Diffuse Optical Tomography (DOT) model in the diffusion approximation on the unit square domain with homogeneous Dirichlet boundary condition. The governing partial differential equation is the scalar elliptic diffusion problem\n$$\n- \\nabla \\cdot \\left( D \\nabla u \\right) + \\mu_a(\\mathbf{r}) \\, u(\\mathbf{r}) = q(\\mathbf{r}) \\quad \\text{in } \\Omega = (0,1)^2, \\quad u|_{\\partial \\Omega} = 0,\n$$\nwhere $D$ is a constant diffusion coefficient, $\\mu_a(\\mathbf{r})$ is the spatially varying absorption coefficient, $u$ is the photon fluence (dimensionless), and $q$ is a source term. All quantities are dimensionless.\n\nWe use a finite-difference discretization on a uniform Cartesian grid with $N$ nodes per side and homogeneous Dirichlet boundary enforced at the boundary nodes. Let the interior grid have $(N-2)^2$ nodes. Let $L \\in \\mathbb{R}^{n \\times n}$ denote the standard $5$-point finite-difference discrete Laplacian on the interior with grid spacing $h = 1/(N-1)$, so that $L$ is symmetric positive definite (for the Dirichlet case). Let $D = 1$ be the constant diffusion coefficient. Let $x \\in \\mathbb{R}^K$ be a low-dimensional parameter vector that parameterizes the absorption field by piecewise-constant patches:\n$$\n\\mu = B x \\in \\mathbb{R}^n,\n$$\nwhere $B \\in \\mathbb{R}^{n \\times K}$ is a binary assignment matrix that maps each interior node to exactly one of $K$ disjoint patches. In this problem, take $K=4$ corresponding to the four quadrants of the interior grid.\n\nFor any $x \\in \\mathbb{R}^4$, define the discrete forward operator\n$$\nA(x) = D L + \\mathrm{diag}(B x) \\in \\mathbb{R}^{n \\times n},\n$$\nand the discrete fluence $u(x) \\in \\mathbb{R}^n$ solves\n$$\nA(x) \\, u(x) = q,\n$$\nwhere $q \\in \\mathbb{R}^n$ is a fixed point source at the interior node closest to the center of the domain. Define a linear measurement operator $M \\in \\mathbb{R}^{m \\times n}$ that extracts the values of $u$ at a prescribed set of interior nodes near the boundary (representing boundary-adjacent detectors). The parameter-to-data map is then\n$$\nF(x) = M \\, u(x) = M \\, A(x)^{-1} \\, q \\in \\mathbb{R}^m.\n$$\n\nYou will verify the first-order Taylor remainder test for the computed Jacobian of $F$ at various base points $x$ and perturbation directions $h \\in \\mathbb{R}^4$. For small perturbations $h$, the Taylor remainder ratio\n$$\nR(h) \\equiv \\frac{\\|F(x+h) - F(x) - J(x) h\\|_2}{\\|h\\|_2}\n$$\nshould decay linearly with $\\|h\\|_2$, where $J(x) \\in \\mathbb{R}^{m \\times 4}$ is the Jacobian of $F$ at $x$. The Jacobian-vector product can be evaluated without forming $J(x)$ explicitly using the identity\n$$\nJ(x) h \\;=\\; - M \\, A(x)^{-1} \\left( \\mathrm{diag}(B h) \\, u(x) \\right),\n$$\nwhich follows from differentiating $F(x) = M A(x)^{-1} q$ and the identity $\\mathrm{d}A^{-1} = -A^{-1} (\\mathrm{d}A) A^{-1}$.\n\nImplement the following numerical experiment to validate the linear decay of $R(t h)$ as a function of $\\|t h\\|_2$, with $t > 0$:\n\n- Discretization and operators:\n  - Use $N = 20$ nodes per side, so $n = (N-2)^2 = 324$ interior nodes. Use the standard $5$-point stencil Laplacian $L$ with grid spacing $h = 1/(N-1)$ and Dirichlet boundary values set to zero outside the interior.\n  - Use $D = 1$.\n  - Define four patches (quadrants) over the interior grid to build $B \\in \\mathbb{R}^{n \\times 4}$. Each interior node belongs to exactly one quadrant according to whether its interior indices are in the lower-left, lower-right, upper-left, or upper-right half of the interior grid.\n  - Define the source $q \\in \\mathbb{R}^n$ as a unit point source at the interior node closest to the center of the domain.\n  - Define measurement operator $M$ as a row-selector that extracts values of $u$ at a set of interior nodes near the boundary:\n    - Sensor set $\\mathcal{S}_1$: choose the interior row adjacent to the top boundary and columns $\\{2,6,10,14,17\\}$ (in interior indexing).\n    - Sensor set $\\mathcal{S}_2$: choose the interior column adjacent to the left boundary and rows $\\{2,6,10,14,17\\}$ (in interior indexing).\n    - Sensor set $\\mathcal{S}_3$: choose the interior row adjacent to the bottom boundary and columns $\\{3,7,11,15\\}$ (in interior indexing).\n  In each case, $M$ picks those nodes from $u$.\n\n- For each test case below, estimate the empirical convergence rate $\\hat{p}$ by least-squares fitting a line to the points $\\{(\\log \\|t h\\|_2, \\log R(t h))\\}$ over a geometric sequence of step sizes. Use step sizes $t_k = 10^{-1} \\cdot 2^{-k}$ for $k \\in \\{0,1,2,3,4,5\\}$. Compute $R(t_k h)$ using the exact forward solve for $F(x+t_k h)$ and the Jacobian-vector product formula given above.\n\n- Acceptance criterion: For each test case, return a boolean indicating whether the estimated slope $\\hat{p}$ satisfies $|\\hat{p} - 1| \\le 0.1$.\n\nAll quantities are dimensionless. The test suite comprises three cases:\n\n- Case A (uniform background, top sensors):\n  - Base parameter $x_A = [\\,0.02,\\, 0.02,\\, 0.02,\\, 0.02\\,]^{\\top}$.\n  - Direction $h_A = [\\,0.01,\\,-0.015,\\,0.02,\\,-0.005\\,]^{\\top}$.\n  - Measurement set $\\mathcal{S}_1$.\n\n- Case B (nonuniform background, left sensors):\n  - Base parameter $x_B = [\\,0.04,\\, 0.02,\\, 0.03,\\, 0.01\\,]^{\\top}$.\n  - Direction $h_B = [\\,-0.008,\\,0.012,\\,-0.006,\\,0.004\\,]^{\\top}$.\n  - Measurement set $\\mathcal{S}_2$.\n\n- Case C (low absorption, bottom sensors):\n  - Base parameter $x_C = [\\,0.005,\\, 0.005,\\, 0.005,\\, 0.005\\,]^{\\top}$.\n  - Direction $h_C = [\\,-0.002,\\,0.001,\\,-0.001,\\,0.001\\,]^{\\top}$.\n  - Measurement set $\\mathcal{S}_3$.\n\nYour program must construct $L$, $B$, $q$, and the specified measurement operators $M$, implement $F(x)$, implement the Jacobian-vector product $J(x) h$ via a single linear solve with $A(x)$ for each $h$, and compute the ratios $R(t_k h)$ and the estimated slope $\\hat{p}$ for each case as specified.\n\nFinal output format requirement: Your program should produce a single line of output containing a list with three booleans corresponding to Cases A, B, and C, respectively, indicating whether each case passes the acceptance criterion. The line must be formatted exactly as a Python-style list with boolean literals, for example, \"[True,False,True]\".", "solution": "The problem requires verifying the implementation of a Jacobian for a parameter-to-observation map in a Diffuse Optical Tomography (DOT) model using a first-order Taylor remainder test.\n\n### 1. Discretization of the Governing Equation\n\nThe model is the steady-state diffusion equation on a unit square, discretized using a finite-difference method on an $N \\times N$ grid ($N=20$). This results in an interior grid of $(N-2) \\times (N-2) = 18 \\times 18 = 324$ nodes.\n\nThe term $-D \\nabla^2 u$ (with $D=1$) is approximated by the 5-point stencil, leading to a sparse, symmetric positive definite (SPD) matrix $L \\in \\mathbb{R}^{324 \\times 324}$ representing the scaled negative Laplacian. The absorption term $\\mu_a(\\mathbf{r}) u(\\mathbf{r})$ is parameterized by a vector $x \\in \\mathbb{R}^4$ representing absorption in four quadrants, such that the discrete absorption operator is $\\mathrm{diag}(Bx)$, where $B$ is a binary assignment matrix.\n\nThe full discrete system is $A(x) u(x) = q$, where $A(x) = L + \\mathrm{diag}(Bx)$.\n\n### 2. Forward Model and Jacobian-Vector Product\n\nThe forward map $F(x)$ gives the simulated measurements for a parameter vector $x$:\n$$\nF(x) = M u(x) = M A(x)^{-1} q,\n$$\nwhere $M$ is a measurement operator selecting sensor locations.\n\nTo test the Jacobian, we need its action on a perturbation vector $h$. Using the identity for the derivative of a matrix inverse, the Jacobian-vector product is given by:\n$$\nJ(x)h = -M A(x)^{-1} \\left( \\mathrm{diag}(Bh) \\, u(x) \\right).\n$$\nThis is computationally efficient as it requires only two linear solves with $A(x)$: one for $u(x)$ and one for the action of $A(x)^{-1}$ on the vector $\\mathrm{diag}(Bh)u(x)$.\n\n### 3. The Taylor Remainder Test\n\nThe first-order Taylor expansion of $F(x)$ is $F(x+h) = F(x) + J(x)h + \\mathcal{O}(\\|h\\|^2)$. The test verifies that the remainder term, $F(x+h) - F(x) - J(x)h$, scales with $\\|h\\|^2$. This implies that the remainder ratio\n$$\nR(h) = \\frac{\\| F(x+h) - F(x) - J(x)h \\|_2}{\\|h\\|_2}\n$$\nshould scale linearly with $\\|h\\|_2$. Consequently, a log-log plot of $R(h)$ versus $\\|h\\|$ should yield a straight line with a slope of 1.\n\nThe numerical experiment computes $R(th)$ for a sequence of decreasing step sizes $t$. A linear least-squares fit to the points $(\\log \\|th\\|_2, \\log R(th))$ gives an empirical convergence rate $\\hat{p}$. The implementation is considered correct if this rate is close to 1, specifically $|\\hat{p}-1| \\le 0.1$.\n\n### 4. Implementation Details\n\n- **Grid and Operators:** The code first constructs the sparse Laplacian matrix $L$ for $N=20$. It then builds the absorption basis matrix $B$ by mapping each of the 324 interior nodes to one of four quadrants. The source vector $q$ is a unit vector at the interior node closest to the center. The measurement matrices $M$ for each case are implemented as selectors for the specified sensor node indices.\n- **Numerical Test:** For each test case, the implementation follows these steps:\n    1. Define the base parameter $x$ and perturbation direction $h$.\n    2. Compute the base solution $u(x)$ and the Jacobian-vector product $J(x)h$.\n    3. Loop over a geometric sequence of step sizes $t_k$.\n    4. In each iteration, compute the perturbed forward solution $F(x+t_k h)$ and the remainder ratio $R(t_k h)$.\n    5. Collect the logarithms of the norms of the steps and the remainders.\n    6. After the loop, compute the slope $\\hat{p}$ of the best-fit line through these log-log points using `numpy.polyfit`.\n    7. Check if $\\hat{p}$ satisfies the acceptance criterion.\nThe results for the three cases are collected and printed in the required format. Efficient sparse solvers are used for all matrix inversions.", "answer": "```python\nimport numpy as np\nfrom scipy.sparse import diags, csc_matrix\nfrom scipy.sparse.linalg import spsolve\n\ndef solve():\n    \"\"\"\n    Solves the DOT Jacobian verification problem.\n    \"\"\"\n    \n    # 1. Discretization and operator setup\n    N = 20\n    N_int = N - 2\n    n = N_int**2\n    h_grid = 1 / (N - 1)\n    D = 1.0\n\n    # Create the discrete negative Laplacian L corresponding to -D*nabla^2\n    # with 5-point stencil (4 on diag, -1 on off-diags), scaled by D/h^2\n    main_diag = np.full(n, 4.0)\n    side_diag = np.full(n - 1, -1.0)\n    # Periodicity for side_diag (jumps at end of rows)\n    side_diag[N_int-1::N_int] = 0\n    up_down_diag = np.full(n - N_int, -1.0)\n    \n    diagonals = [up_down_diag, side_diag, main_diag, side_diag, up_down_diag]\n    offsets = [-N_int, -1, 0, 1, N_int]\n    \n    L = (D / h_grid**2) * diags(diagonals, offsets, shape=(n, n), format='csc')\n\n    # Create the patch assignment matrix B\n    K = 4\n    B = np.zeros((n, K))\n    half_grid = N_int // 2\n    for i in range(N_int):\n        for j in range(N_int):\n            k = i * N_int + j\n            if i  half_grid and j  half_grid: # Lower-left\n                B[k, 0] = 1\n            elif i  half_grid and j >= half_grid: # Lower-right\n                B[k, 1] = 1\n            elif i >= half_grid and j  half_grid: # Upper-left\n                B[k, 2] = 1\n            else: # Upper-right\n                B[k, 3] = 1\n\n    # Create the source vector q\n    # Tie-break for the central node by picking the one with smallest indices\n    center_idx_i = half_grid - 1\n    center_idx_j = half_grid - 1\n    q_idx = center_idx_i * N_int + center_idx_j\n    q = np.zeros(n)\n    q[q_idx] = 1.0\n    q = csc_matrix(q).T # Use sparse column vector for spsolve\n\n    # Define sensor sets (1D indices)\n    # Interior indices are 0-based\n    # S1: top row (i=17), cols {2,6,10,14,17}\n    M1_indices = [17 * N_int + c for c in [2, 6, 10, 14, 17]]\n    # S2: left col (j=0), rows {2,6,10,14,17}\n    M2_indices = [r * N_int + 0 for r in [2, 6, 10, 14, 17]]\n    # S3: bottom row (i=0), cols {3,7,11,15}\n    M3_indices = [0 * N_int + c for c in [3, 7, 11, 15]]\n\n    # 2. Test case execution logic\n    def run_test_case(x_base, h_dir, M_indices):\n        \"\"\"\n        Performs the Taylor remainder test for a single case.\n        \"\"\"\n        \n        # Helper to construct A(x)\n        def get_A(x):\n            mu_vec = B @ x\n            return L + diags(mu_vec, 0, shape=(n, n), format='csc')\n\n        # Compute base quantities\n        A_base = get_A(x_base)\n        u_base = spsolve(A_base, q)\n        F_base = u_base[M_indices]\n        \n        # Compute Jacobian-vector product J(x_base) @ h_dir\n        # J(x)h = -M A(x)^{-1} (diag(B h) u(x))\n        bh_dir = B @ h_dir\n        w = bh_dir * u_base\n        v = spsolve(A_base, w)\n        Jvh_base = -v[M_indices]\n\n        log_h_norms = []\n        log_R_values = []\n        \n        for k in range(6):\n            t_k = 1e-1 * (2.0**(-k))\n            h_k = t_k * h_dir\n\n            # Compute F(x + h)\n            A_pert = get_A(x_base + h_k)\n            u_pert = spsolve(A_pert, q)\n            F_pert = u_pert[M_indices]\n            \n            # Jacobian-vector product for h_k: J(x_base) @ h_k = t_k * (J(x_base) @ h_dir)\n            Jvh_k = t_k * Jvh_base\n\n            # Compute Taylor remainder ratio R(h_k)\n            num_norm = np.linalg.norm(F_pert - F_base - Jvh_k)\n            den_norm = np.linalg.norm(h_k)\n            \n            if den_norm > 0 and num_norm > 0:\n                R_k = num_norm / den_norm\n                log_h_norms.append(np.log(den_norm))\n                log_R_values.append(np.log(R_k))\n\n        # Perform linear regression to find the convergence rate p_hat\n        if len(log_h_norms)  2:\n            return False\n\n        p_hat, _ = np.polyfit(log_h_norms, log_R_values, 1)\n\n        return abs(p_hat - 1.0) = 0.1\n\n    # 3. Define and run test cases\n    test_cases = [\n        # Case A\n        {'x': np.array([0.02, 0.02, 0.02, 0.02]),\n         'h': np.array([0.01, -0.015, 0.02, -0.005]),\n         'M': M1_indices},\n        # Case B\n        {'x': np.array([0.04, 0.02, 0.03, 0.01]),\n         'h': np.array([-0.008, 0.012, -0.006, 0.004]),\n         'M': M2_indices},\n        # Case C\n        {'x': np.array([0.005, 0.005, 0.005, 0.005]),\n         'h': np.array([-0.002, 0.001, -0.001, 0.001]),\n         'M': M3_indices}\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(case['x'], case['h'], case['M'])\n        results.append(result)\n\n    # Final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3378201"}, {"introduction": "With a verified forward model and Jacobian, we can now address the inverse problem itself. A key challenge in Tikhonov regularization is selecting the regularization parameter, $\\alpha$, which balances data fidelity against prior belief. This practice moves beyond heuristic methods and introduces a powerful Bayesian technique called evidence maximization (or type-II maximum likelihood) to determine $\\alpha$ directly from the data, leading to more objective and reproducible results [@problem_id:3378196].", "problem": "Consider a linearized inverse problem arising in Electrical Impedance Tomography (EIT), where the data misfit is modeled by a Gaussian noise model and the prior is a Tikhonov-type Gaussian prior. Specifically, let the measurement vector $y \\in \\mathbb{R}^{m}$ be related to the parameter increment $x \\in \\mathbb{R}^{n}$ via the linear model $y = A x + \\varepsilon$, where $A \\in \\mathbb{R}^{m \\times n}$ is the sensitivity matrix obtained by linearizing the forward map at a homogeneous background, and the noise $\\varepsilon \\sim \\mathcal{N}(0,\\beta^{-1} I)$ with known noise precision $\\beta > 0$. Assume a Gaussian prior $x \\sim \\mathcal{N}\\!\\left(0,\\alpha^{-1} R^{-T} R^{-1}\\right)$, where $R \\in \\mathbb{R}^{n \\times n}$ is symmetric positive definite and $\\alpha > 0$ is the Tikhonov regularization parameter to be selected by evidence maximization (type-II maximum likelihood). Introduce the variable $u = R x$, and define the transformed design matrix $\\Phi = A R^{-1}$. You may assume the properties of multivariate Gaussian distributions, Gaussian conditioning, and standard matrix differentiation under the trace.\n\nTasks:\n1) Starting from the linear-Gaussian model and the Gaussian prior, derive the posterior distribution of $u$ and the marginal likelihood (evidence) $p(y \\mid \\alpha)$ by integrating out $u$. Then, by maximizing the log-evidence with respect to $\\alpha$, derive an explicit update formula for $\\alpha$ in terms of the posterior mean of $u$ and the spectrum of $\\Phi^{T}\\Phi$. Express your update as a closed-form analytical expression that depends only on $\\alpha$, $\\beta$, $\\Phi$, and $y$ (no unknown constants). Also derive the hat matrix $H(\\alpha)$ that maps $y$ to the fitted data $\\hat{y}$, and show how the effective degrees of freedom can be computed as the trace of $H(\\alpha)$.\n\n2) Now consider the following concrete EIT linearization instance with $m = 2$ and $n = 2$. Let\n$$\nA = \\begin{pmatrix}\n1.0  0.2 \\\\\n0.3  0.9\n\\end{pmatrix}, \\quad\nR = \\begin{pmatrix}\n1  0 \\\\\n0  2\n\\end{pmatrix}, \\quad\n\\beta = 25, \\quad\ny = \\begin{pmatrix}\n0.7 \\\\\n0.1\n\\end{pmatrix}.\n$$\nUsing a single evidence-maximization update starting from the initial value $\\alpha^{(0)} = 1$, compute the updated value $\\alpha^{(1)}$ obtained from your derived update formula. Then, evaluate the effective degrees of freedom as the trace of the hat matrix $H(\\alpha)$ at $\\alpha = \\alpha^{(1)}$.\n\nRound both $\\alpha^{(1)}$ and the effective degrees of freedom to four significant figures. Provide your final answer as a row matrix containing the two numbers (in this order). No units are required.", "solution": "The problem requires deriving the evidence maximization framework for a linear-Gaussian model and applying it to a specific numerical example.\n\n### Part 1: Theoretical Derivations\n\nThe Bayesian model is defined by the likelihood and prior. After the change of variables $u = Rx$ and $\\Phi = AR^{-1}$, the model becomes:\n- Likelihood: $p(y \\mid u, \\beta) = \\mathcal{N}(y \\mid \\Phi u, \\beta^{-1}I)$\n- Prior: $p(u \\mid \\alpha) = \\mathcal{N}(u \\mid 0, \\alpha^{-1}I)$\n\n**1. Posterior Distribution:** The posterior $p(u \\mid y, \\alpha, \\beta)$ is found via Bayes' rule. Since the likelihood and prior are Gaussian, the posterior is also Gaussian, $\\mathcal{N}(u \\mid \\mu_u, \\Sigma_u)$, with precision $\\Sigma_u^{-1} = \\alpha I + \\beta\\Phi^T\\Phi$ and mean $\\mu_u = \\beta \\Sigma_u \\Phi^T y$.\n\n**2. Evidence and Maximization:** The evidence $p(y \\mid \\alpha, \\beta)$ is found by integrating out $u$. This results in another Gaussian distribution, $p(y \\mid \\alpha, \\beta) = \\mathcal{N}(y \\mid 0, \\beta^{-1}I + \\alpha^{-1}\\Phi\\Phi^T)$. To find the optimal $\\alpha$ (type-II maximum likelihood), we maximize the log-evidence, $\\mathcal{L}(\\alpha) = \\ln p(y \\mid \\alpha, \\beta)$, with respect to $\\alpha$.\nDifferentiating $\\mathcal{L}(\\alpha)$ with respect to $\\alpha$ and setting the result to zero yields the condition:\n$$ \\alpha \\|\\mu_u\\|^2 = \\sum_{i=1}^n \\frac{\\beta\\lambda_i}{\\alpha + \\beta\\lambda_i} $$\nwhere $\\{\\lambda_i\\}$ are the eigenvalues of $\\Phi^T\\Phi$. The right-hand side is often denoted as $\\gamma$, the number of effective parameters. This implicit equation is solved iteratively. Given a current estimate $\\alpha^{(k)}$, the update formula for the next estimate $\\alpha^{(k+1)}$ is:\n$$ \\alpha^{(k+1)} = \\frac{\\gamma^{(k)}}{\\|\\mu_u^{(k)}\\|^2} \\quad \\text{where} \\quad \\gamma^{(k)} = \\sum_{i=1}^n \\frac{\\beta\\lambda_i}{\\alpha^{(k)} + \\beta\\lambda_i} $$\nand $\\mu_u^{(k)}$ is the posterior mean computed with $\\alpha^{(k)}$.\n\n**3. Hat Matrix and Degrees of Freedom:** The fitted data is $\\hat{y} = \\Phi\\mu_u$. The hat matrix $H(\\alpha)$ maps $y$ to $\\hat{y}$. Substituting the expression for $\\mu_u$ gives:\n$$ H(\\alpha) = \\beta\\Phi(\\alpha I + \\beta\\Phi^T\\Phi)^{-1}\\Phi^T $$\nThe effective degrees of freedom is the trace of the hat matrix, $\\text{tr}(H(\\alpha))$. Using the cyclic property of the trace, it can be shown that this is exactly $\\gamma$:\n$$ \\text{tr}(H(\\alpha)) = \\sum_{i=1}^{n} \\frac{\\beta\\lambda_i}{\\alpha + \\beta\\lambda_i} = \\gamma $$\n\n### Part 2: Numerical Calculation\n\nGiven values are:\n$A = \\begin{pmatrix} 1.0  0.2 \\\\ 0.3  0.9 \\end{pmatrix}$, $R = \\begin{pmatrix} 1  0 \\\\ 0  2 \\end{pmatrix}$, $\\beta = 25$, $y = \\begin{pmatrix} 0.7 \\\\ 0.1 \\end{pmatrix}$, and $\\alpha^{(0)} = 1$.\n\n**1. Compute $\\Phi$ and $\\Phi^T\\Phi$:**\n$\\Phi = AR^{-1} = \\begin{pmatrix} 1.0  0.2 \\\\ 0.3  0.9 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  0.5 \\end{pmatrix} = \\begin{pmatrix} 1.0  0.1 \\\\ 0.3  0.45 \\end{pmatrix}$\n$\\Phi^T\\Phi = \\begin{pmatrix} 1.0  0.3 \\\\ 0.1  0.45 \\end{pmatrix} \\begin{pmatrix} 1.0  0.1 \\\\ 0.3  0.45 \\end{pmatrix} = \\begin{pmatrix} 1.09  0.235 \\\\ 0.235  0.2125 \\end{pmatrix}$\n\n**2. Compute eigenvalues of $\\Phi^T\\Phi$:**\nThe eigenvalues are $\\lambda_1 \\approx 1.14897$ and $\\lambda_2 \\approx 0.153529$.\n\n**3. Single update step for $\\alpha$:**\nStart with $\\alpha^{(0)} = 1$.\nFirst, compute $\\gamma^{(0)}$:\n$\\gamma^{(0)} = \\sum_{i=1}^2 \\frac{\\beta\\lambda_i}{\\alpha^{(0)} + \\beta\\lambda_i} = \\frac{25 \\cdot 1.14897}{1 + 25 \\cdot 1.14897} + \\frac{25 \\cdot 0.153529}{1 + 25 \\cdot 0.153529} \\approx 0.966358 + 0.793315 = 1.75967$.\nNext, compute $\\|\\mu_u^{(0)}\\|^2$:\n$\\mu_u^{(0)} = \\beta(\\alpha^{(0)} I + \\beta\\Phi^T\\Phi)^{-1}\\Phi^T y$.\n$\\alpha^{(0)} I + \\beta\\Phi^T\\Phi = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + 25 \\begin{pmatrix} 1.09  0.235 \\\\ 0.235  0.2125 \\end{pmatrix} = \\begin{pmatrix} 28.25  5.875 \\\\ 5.875  6.3125 \\end{pmatrix}$.\n$\\Phi^T y = \\begin{pmatrix} 0.73 \\\\ 0.115 \\end{pmatrix}$.\nSolving for $\\mu_u^{(0)}$ gives $\\mu_u^{(0)} \\approx \\begin{pmatrix} 0.683616 \\\\ -0.180791 \\end{pmatrix}$.\n$\\|\\mu_u^{(0)}\\|^2 \\approx 0.683616^2 + (-0.180791)^2 \\approx 0.500015$.\nThe updated $\\alpha^{(1)}$ is:\n$\\alpha^{(1)} = \\frac{\\gamma^{(0)}}{\\|\\mu_u^{(0)}\\|^2} \\approx \\frac{1.75967}{0.500015} \\approx 3.51922$.\nRounded to four significant figures, $\\alpha^{(1)} = 3.519$.\n\n**4. Compute effective degrees of freedom at $\\alpha = \\alpha^{(1)}$:**\nThis is $\\gamma^{(1)} = \\sum_{i=1}^2 \\frac{\\beta\\lambda_i}{\\alpha^{(1)} + \\beta\\lambda_i}$.\n$\\gamma^{(1)} = \\frac{25 \\cdot 1.14897}{3.51922 + 25 \\cdot 1.14897} + \\frac{25 \\cdot 0.153529}{3.51922 + 25 \\cdot 0.153529} \\approx 0.89085 + 0.52167 = 1.41252$.\nRounded to four significant figures, the effective degrees of freedom are $1.413$.", "answer": "$$\n\\boxed{\\begin{pmatrix} 3.519  1.413 \\end{pmatrix}}\n$$", "id": "3378196"}]}