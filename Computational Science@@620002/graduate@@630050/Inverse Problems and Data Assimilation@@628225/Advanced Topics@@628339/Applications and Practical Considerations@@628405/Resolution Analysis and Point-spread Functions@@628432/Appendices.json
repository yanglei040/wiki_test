{"hands_on_practices": [{"introduction": "This first exercise grounds the abstract theory of resolution analysis in a concrete computational task. You will explore a classic one-dimensional deconvolution problem, deriving the structure of the resolution matrix for a Tikhonov-regularized estimator [@problem_id:3417719]. By implementing this and computing the Point-Spread Function (PSF), you will gain direct, hands-on experience with how the regularization parameter $\\lambda$ mediates the fundamental trade-off between solution stability and spatial resolution, a concept quantified by the PSF's width.", "problem": "Consider a one-dimensional linear inverse problem with a discrete model vector $m \\in \\mathbb{R}^{N}$ and data vector $d \\in \\mathbb{R}^{N}$ given by the forward model $d = A m + n$, where $A$ is a discrete convolution operator with a known kernel, and $n$ is additive noise that is zero-mean Gaussian with covariance $C_{n} = \\sigma^{2} I$. Assume periodic boundary conditions so that $A$ is a circulant matrix. Consider Tikhonov regularization with a zeroth-order penalty, namely the estimator $\\hat{m}$ defined as the unique minimizer of the strictly convex functional\n$$\nJ(m) = \\| A m - d \\|_{C_{n}^{-1}}^{2} + \\lambda^{2} \\| m \\|_{2}^{2},\n$$\nwhere $\\| x \\|_{C_{n}^{-1}}^{2} = x^{\\top} C_{n}^{-1} x$, and $\\lambda > 0$ is the regularization parameter. Define the resolution matrix (also called the point-spread operator) $R$ by the exact linear relation $\\mathbb{E}[\\hat{m}] = R m$, where the expectation is taken over the data noise. The point-spread function (PSF) at grid location $j$ is defined to be the response of the estimator to a unit impulse at $j$, i.e., the $j$-th column of $R$. In other words, if the true model is $m = e_{j}$ (the standard basis vector with a $1$ at index $j$ and zeros elsewhere), then $\\mathbb{E}[\\hat{m}]$ equals the PSF centered at $j$. The Full Width at Half Maximum (FWHM) of a PSF is defined here as the distance between the two points where the PSF attains half of its maximum amplitude, computed using linear interpolation between grid samples. All widths must be expressed in grid units.\n\nYour tasks are:\n- Starting from the definitions above and the assumptions $C_{n} = \\sigma^{2} I$ and periodic boundary conditions, derive an explicit formula for the resolution matrix $R$ in terms of $A$, $\\lambda$, and $\\sigma$, and characterize the PSF as a function on the discrete grid.\n- Specialize the result to the case where $A$ is convolution with a known kernel and use the Discrete Fourier Transform (DFT) to obtain an implementable expression for the PSF.\n- Implement a program that constructs the PSF and computes its FWHM for two different regularization parameters $\\lambda$ for each test case listed below. Use grid spacing equal to $1$ so that FWHM is in grid units. Use linear interpolation between adjacent samples to determine the half-maximum crossing locations. Normalize each PSF to unit peak before computing FWHM. Round each FWHM to six decimal places.\n\nPrecise definitions and conventions to be used:\n- Point-Spread Function (PSF): the $j$-th column of $R$; due to shift-invariance under periodic boundary conditions, its shape does not depend on $j$. You must compute and report the PSF centered at the middle grid index $j = \\lfloor N/2 \\rfloor$.\n- Discrete Fourier Transform (DFT): use the standard unitary or non-unitary DFT consistently; any consistent normalization is acceptable because the PSF is recovered via the inverse DFT of a transfer function and then re-normalized to unit peak.\n- Convolution kernel for $A$: three cases are specified below. For Gaussian kernels, construct a periodic discrete Gaussian kernel $k[n] \\propto \\exp\\!\\left(-\\tfrac{1}{2} (\\mathrm{dist}(n,0)/\\sigma_{k})^{2}\\right)$, where $\\mathrm{dist}(n,0) = \\min\\{ |n|, N - |n| \\}$ is the circular distance on the grid, and normalize so that $\\sum_{n=0}^{N-1} k[n] = 1$. For the delta kernel, use $k[0]=1$ and $k[n]=0$ for $n \\neq 0$.\n- Full Width at Half Maximum (FWHM): given a symmetric, unimodal, nonnegative PSF profile $p[n]$ that is normalized to have maximum value $1$, define the half-maximum level $h = 1/2$. Let $c = \\lfloor N/2 \\rfloor$ be the center index. The FWHM is computed as the difference between the right and left half-maximum crossing locations obtained by linear interpolation between the first pair of adjacent samples on each side of $c$ that straddle $h$. Express the result in grid units, assuming a grid spacing of $1$.\n\nTest suite:\n- Case 1 (happy path): $N = 257$, noise standard deviation $\\sigma = 0.1$, Gaussian blur kernel with standard deviation $\\sigma_{k} = 2.0$ in grid units, two regularization parameters $\\lambda_{1} = 0.2$ and $\\lambda_{2} = 2.0$.\n- Case 2 (narrow kernel): $N = 257$, noise standard deviation $\\sigma = 0.1$, Gaussian blur kernel with standard deviation $\\sigma_{k} = 0.8$ in grid units, two regularization parameters $\\lambda_{1} = 0.2$ and $\\lambda_{2} = 2.0$.\n- Case 3 (boundary kernel case): $N = 257$, noise standard deviation $\\sigma = 0.1$, delta kernel (identity forward operator), two regularization parameters $\\lambda_{1} = 0.2$ and $\\lambda_{2} = 2.0$.\n\nNumerical and output requirements:\n- For each case, construct the PSF using the derived method and compute the FWHM for each of the two $\\lambda$ values. The PSF must be computed under periodic boundary conditions using the DFT-based approach implied by the circulant structure.\n- The final program output must be a single line containing a Python-style list of six floating-point numbers rounded to six decimal places and ordered as follows: \n  $[\\mathrm{FWHM}(\\lambda_{1})\\ \\text{for Case 1},\\ \\mathrm{FWHM}(\\lambda_{2})\\ \\text{for Case 1},\\ \\mathrm{FWHM}(\\lambda_{1})\\ \\text{for Case 2},\\ \\mathrm{FWHM}(\\lambda_{2})\\ \\text{for Case 2},\\ \\mathrm{FWHM}(\\lambda_{1})\\ \\text{for Case 3},\\ \\mathrm{FWHM}(\\lambda_{2})\\ \\text{for Case 3}]$.\n- All widths must be expressed in grid units as real numbers rounded to six decimal places.\n- Your program must be entirely self-contained, must not read input, and must not access external resources. It must produce only the single required output line in the exact format described.", "solution": "The problem requires the derivation and implementation of a method to compute the full width at half maximum (FWHM) of the point-spread function (PSF) for a Tikhonov-regularized linear inverse problem.\n\n### Part 1: Theoretical Derivation\n\nThe analysis begins with the Tikhonov functional to be minimized:\n$$\nJ(m) = \\| A m - d \\|_{C_{n}^{-1}}^{2} + \\lambda^{2} \\| m \\|_{2}^{2}\n$$\nGiven the noise covariance $C_{n} = \\sigma^{2} I$, the inverse is $C_{n}^{-1} = (\\sigma^{2})^{-1} I$. The functional simplifies to:\n$$\nJ(m) = \\frac{1}{\\sigma^{2}} \\| A m - d \\|_{2}^{2} + \\lambda^{2} \\| m \\|_{2}^{2} = \\frac{1}{\\sigma^{2}} (A m - d)^{\\top}(A m - d) + \\lambda^{2} m^{\\top}m\n$$\nTo find the unique minimizer $\\hat{m}$, we set the gradient of $J(m)$ with respect to $m$ to zero.\n$$\n\\nabla_{m} J(m) = \\frac{\\partial}{\\partial m} \\left( \\frac{1}{\\sigma^{2}} (m^{\\top}A^{\\top}Am - 2d^{\\top}Am + d^{\\top}d) + \\lambda^{2} m^{\\top}m \\right)\n$$\nUsing the standard matrix derivative identities $\\nabla_x(x^{\\top}Bx) = (B+B^{\\top})x$ (which simplifies to $2Bx$ for symmetric $B$) and $\\nabla_x(b^{\\top}x) = b$, we obtain the gradient:\n$$\n\\nabla_{m} J(m) = \\frac{1}{\\sigma^{2}} (2 A^{\\top} A m - 2 A^{\\top} d) + 2 \\lambda^{2} m\n$$\nSetting the gradient to zero for the optimal estimate $\\hat{m}$:\n$$\n\\frac{1}{\\sigma^{2}} (2 A^{\\top} A \\hat{m} - 2 A^{\\top} d) + 2 \\lambda^{2} \\hat{m} = 0\n$$\nMultiplying by $\\sigma^2/2$ and rearranging gives the normal equations for this regularized problem:\n$$\n(A^{\\top} A + \\sigma^{2} \\lambda^{2} I) \\hat{m} = A^{\\top} d\n$$\nSolving for $\\hat{m}$ yields the expression for the regularized solution:\n$$\n\\hat{m} = (A^{\\top} A + \\sigma^{2} \\lambda^{2} I)^{-1} A^{\\top} d\n$$\nThe resolution matrix $R$ is defined by the relationship between the expected value of the estimate, $\\mathbb{E}[\\hat{m}]$, and the true model, $m_{\\text{true}}$, such that $\\mathbb{E}[\\hat{m}] = R m_{\\text{true}}$. The expectation is taken over the noise distribution. Substituting the forward model $d = A m_{\\text{true}} + n$ into the expression for $\\hat{m}$:\n$$\n\\mathbb{E}[\\hat{m}] = \\mathbb{E}[ (A^{\\top} A + \\sigma^{2} \\lambda^{2} I)^{-1} A^{\\top} (A m_{\\text{true}} + n) ]\n$$\nUsing the linearity of expectation and the fact that the noise is zero-mean ($\\mathbb{E}[n]=0$):\n$$\n\\mathbb{E}[\\hat{m}] = (A^{\\top} A + \\sigma^{2} \\lambda^{2} I)^{-1} A^{\\top} A m_{\\text{true}} + (A^{\\top} A + \\sigma^{2} \\lambda^{2} I)^{-1} A^{\\top} \\mathbb{E}[n]\n$$\n$$\n\\mathbb{E}[\\hat{m}] = (A^{\\top} A + \\sigma^{2} \\lambda^{2} I)^{-1} A^{\\top} A m_{\\text{true}}\n$$\nBy comparing this result with the definition of the resolution matrix, we find its explicit form:\n$$\nR = (A^{\\top} A + \\sigma^{2} \\lambda^{2} I)^{-1} A^{\\top} A\n$$\nThe problem specifies periodic boundary conditions, which implies that the convolution operator $A$ is a circulant matrix. A fundamental property of circulant matrices is that they are diagonalized by the Discrete Fourier Transform (DFT). Let $F$ be the DFT matrix. We can write $A = F^{-1} \\Lambda_A F$, where $\\Lambda_A$ is a diagonal matrix whose entries are the eigenvalues of $A$. These eigenvalues are the DFT of the first column of $A$, which is the convolution kernel $k$. Let $\\tilde{k} = \\mathcal{F}(k)$ be the vector of these eigenvalues.\n\nThe transpose $A^{\\top}$ is also circulant, and its eigenvalues are the complex conjugates of the eigenvalues of $A$. Thus, $A^{\\top} = F^{-1} \\Lambda_A^* F$, where the diagonal of $\\Lambda_A^*$ contains $\\overline{\\tilde{k}}$. The product $A^{\\top}A$ becomes:\n$$\nA^{\\top} A = (F^{-1} \\Lambda_A^* F)(F^{-1} \\Lambda_A F) = F^{-1} (\\Lambda_A^* \\Lambda_A) F = F^{-1} |\\Lambda_A|^2 F\n$$\nwhere $|\\Lambda_A|^2$ is the diagonal matrix with entries $|\\tilde{k}_i|^2$. Substituting this into the expression for $R$:\n$$\nR = (F^{-1} |\\Lambda_A|^2 F + \\sigma^{2} \\lambda^{2} I)^{-1} (F^{-1} |\\Lambda_A|^2 F)\n$$\nUsing $I = F^{-1}IF$ and properties of matrix inverses:\n$$\nR = [F^{-1} (|\\Lambda_A|^2 + \\sigma^{2} \\lambda^{2}I) F]^{-1} (F^{-1} |\\Lambda_A|^2 F) = [F^{-1} (|\\Lambda_A|^2 + \\sigma^{2} \\lambda^{2}I)^{-1} F] (F^{-1} |\\Lambda_A|^2 F)\n$$\n$$\nR = F^{-1} [ (|\\Lambda_A|^2 + \\sigma^{2} \\lambda^{2}I)^{-1} |\\Lambda_A|^2 ] F\n$$\nThis demonstrates that $R$ is also a circulant matrix. Its eigenvalues, which we denote by the vector $\\tilde{r}$, are given by the resolution transfer function:\n$$\n\\tilde{r}_i = \\frac{|\\tilde{k}_{i}|^2}{|\\tilde{k}_{i}|^2 + \\sigma^2 \\lambda^2}\n$$\nThe PSF is a column of $R$. Since $R$ is circulant, its columns are shifted versions of its first column. The first column of $R$ is obtained by applying the inverse DFT to its eigenvalues $\\tilde{r}$:\n$$\n\\text{psf}_{\\text{uncentered}} = \\mathcal{F}^{-1}(\\tilde{r})\n$$\nThe kernels specified are real and symmetric, so their DFT $\\tilde{k}$ is real. This makes $\\tilde{r}$ real and symmetric, ensuring the resulting PSF is real and symmetric about index $0$. The PSF is then circularly shifted to be centered at index $j = \\lfloor N/2 \\rfloor$.\n\n### Part 2: Implementation Strategy\n\nThe FWHM is computed following these steps:\n1.  **Kernel Construction**: For a given test case, construct the discrete convolution kernel $k$ of size $N$. For a Gaussian, the periodic distance $\\mathrm{dist}(n,0) = \\min\\{ |n|, N-|n| \\}$ is used to define the kernel, which is then normalized to sum to $1$. For the delta kernel, a unit impulse at index $0$ is used.\n2.  **Fourier Transform**: Compute the DFT of the kernel, $\\tilde{k} = \\mathcal{F}(k)$, using `scipy.fft.fft`.\n3.  **Transfer Function**: Calculate the resolution transfer function $\\tilde{r}$ for each frequency component using the derived formula.\n4.  **PSF Calculation**: Compute the uncentered PSF via inverse DFT, $p = \\mathcal{F}^{-1}(\\tilde{r})$, using `scipy.fft.ifft`. The real part is taken to discard negligible imaginary components arising from numerical precision errors.\n5.  **Centering and Normalization**: The PSF is circularly shifted by $\\lfloor N/2 \\rfloor$ positions to center its peak. It is then normalized by dividing by its maximum value so that the peak amplitude is $1$.\n6.  **FWHM Calculation**: For the normalized, symmetric PSF, the right half-maximum crossing point $x_{\\text{right}}$ is found by identifying the two adjacent grid points whose values straddle $0.5$ and applying linear interpolation. The FWHM is then $2 \\times (x_{\\text{right}} - \\lfloor N/2 \\rfloor)$. This process is repeated for all test cases and parameters.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import fft\n\ndef solve():\n    \"\"\"\n    Solves the problem by calculating the FWHM for each test case.\n    The final output is a single line containing a list of FWHM values.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'N': 257, 'sigma_noise': 0.1, 'kernel_type': 'gaussian', 'sigma_k': 2.0, 'lambdas': [0.2, 2.0]},\n        {'N': 257, 'sigma_noise': 0.1, 'kernel_type': 'gaussian', 'sigma_k': 0.8, 'lambdas': [0.2, 2.0]},\n        {'N': 257, 'sigma_noise': 0.1, 'kernel_type': 'delta', 'sigma_k': None, 'lambdas': [0.2, 2.0]},\n    ]\n    \n    results = []\n    \n    for case in test_cases:\n        for lambda_reg in case['lambdas']:\n            fwhm = calculate_psf_and_fwhm(\n                N=case['N'],\n                sigma_noise=case['sigma_noise'],\n                kernel_type=case['kernel_type'],\n                sigma_k=case['sigma_k'],\n                lambda_reg=lambda_reg\n            )\n            results.append(f\"{fwhm:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_psf_and_fwhm(N, sigma_noise, kernel_type, sigma_k, lambda_reg):\n    \"\"\"\n    Constructs the PSF and computes its FWHM for a given set of parameters.\n    \n    Args:\n        N (int): Grid size.\n        sigma_noise (float): Standard deviation of the additive noise.\n        kernel_type (str): Type of convolution kernel ('gaussian' or 'delta').\n        sigma_k (float or None): Standard deviation of the Gaussian kernel.\n        lambda_reg (float): Tikhonov regularization parameter.\n        \n    Returns:\n        float: The computed FWHM in grid units.\n    \"\"\"\n    # Step 1: Construct the convolution kernel k\n    if kernel_type == 'gaussian':\n        n = np.arange(N)\n        # Circular distance from origin for periodic boundary conditions\n        dist = np.minimum(n, N - n)\n        kernel = np.exp(-0.5 * (dist / sigma_k)**2)\n        # Normalize so that the kernel sums to 1\n        kernel /= np.sum(kernel)\n    elif kernel_type == 'delta':\n        kernel = np.zeros(N)\n        kernel[0] = 1.0\n    else:\n        raise ValueError(\"Unknown kernel type specified.\")\n\n    # Step 2: Compute the DFT of the kernel\n    k_tilde = fft.fft(kernel)\n\n    # Step 3: Compute the resolution transfer function r_tilde\n    k_tilde_mag_sq = np.abs(k_tilde)**2\n    sigma_lambda_sq = (sigma_noise * lambda_reg)**2\n    r_tilde = k_tilde_mag_sq / (k_tilde_mag_sq + sigma_lambda_sq)\n\n    # Step 4: Compute the PSF via inverse DFT\n    # For a real and symmetric r_tilde, the ifft is real. We take np.real to handle\n    # potential floating point inaccuracies.\n    psf_uncentered = np.real(fft.ifft(r_tilde))\n\n    # Step 5: Center the PSF at index N // 2\n    center_index = N // 2\n    psf_centered = np.roll(psf_uncentered, center_index)\n\n    # Step 6: Normalize the PSF to have a peak value of 1\n    psf_max = np.max(psf_centered)\n    if psf_max > 0:\n        psf_normalized = psf_centered / psf_max\n    else:\n        # Handle the case of a zero PSF, though unlikely\n        psf_normalized = psf_centered\n\n    # Step 7: Compute the FWHM\n    fwhm = compute_fwhm_from_psf(psf_normalized)\n    \n    return fwhm\n\ndef compute_fwhm_from_psf(psf):\n    \"\"\"\n    Computes the Full Width at Half Maximum for a normalized, centered PSF.\n    \n    Args:\n        psf (np.ndarray): A 1D array representing the centered, normalized PSF.\n        \n    Returns:\n        float: The FWHM value.\n    \"\"\"\n    N = len(psf)\n    center_index = N // 2\n    half_max = 0.5\n    \n    # Check if PSF is a delta function (only one non-zero point at the center)\n    if psf[center_index] == 1.0 and np.sum(psf) == 1.0:\n        # By our linear interpolation definition between grid points [c] and [c+1]\n        # with values 1.0 and 0.0, the half-max is crossed at c+0.5.\n        # FWHM = 2 * ((c+0.5) - c) = 1.0\n        return 1.0\n\n    # Search for the crossing on the right side of the center\n    # Find the index of the first point that drops below half_max\n    try:\n        # `[0]` accesses the array from the tuple, `[0]` gets the first index\n        first_idx_below_rel = np.where(psf[center_index:]  half_max)[0][0]\n    except IndexError:\n        # This occurs if the PSF never drops below 0.5, e.g., if it's broad and flat.\n        #  In this case, the FWHM is arguably the width of the domain.\n        return float(N)\n\n    # The point just before this one is above or at half_max\n    idx_above_rel = first_idx_below_rel - 1\n    \n    # Get absolute indices in the full PSF array\n    idx_above_abs = center_index + idx_above_rel\n    idx_below_abs = center_index + first_idx_below_rel\n\n    # Get values and coordinates for linear interpolation\n    y1 = psf[idx_above_abs]  # Value = 0.5\n    y2 = psf[idx_below_abs]  # Value  0.5\n    \n    x1 = float(idx_above_abs)\n    x2 = float(idx_below_abs)\n\n    # Linear interpolation to find x_right where y = half_max\n    # x = x1 + (y - y1) * (x2 - x1) / (y2 - y1)\n    if (y2 - y1) == 0:\n         # Avoid division by zero, though unlikely if y1  0.5 and y2  0.5\n         x_right = (x1 + x2) / 2.0\n    else:\n         x_right = x1 + (half_max - y1) * (x2 - x1) / (y2 - y1)\n         \n    # Due to symmetry, FWHM is twice the distance from the center to the right crossing\n    fwhm = 2.0 * (x_right - float(center_index))\n    \n    return fwhm\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3417719"}, {"introduction": "Building on the foundational understanding of the PSF, this practice applies resolution analysis to a practical scenario in data assimilation and observing system design. You will compute the averaging kernel and its associated diagnostic metrics for different hypothetical sensor networks [@problem_id:3417773]. This exercise demonstrates how the abstract machinery of resolution analysis provides a powerful quantitative framework for evaluating and comparing the effectiveness of different measurement strategies, a crucial task in many scientific fields.", "problem": "You are given a one-dimensional linear Gaussian data assimilation setting with a spatial state on a line segment and two distinct sensor networks represented by different observation operators. For each scenario, the background error covariance and observation error covariance are identical for the two networks. Your task is to compute, for each sensor network in each scenario, the degrees of freedom for signal (DFS) and the full width at half maximum (FWHM) of a representative point-spread function (PSF), then aggregate the results as specified.\n\nFundamental base and definitions:\n- The data assimilation update is linear Gaussian with additive errors. The spatial state is denoted by $x \\in \\mathbb{R}^N$, the observation vector by $y \\in \\mathbb{R}^M$, the observation operator by $H \\in \\mathbb{R}^{M \\times N}$, the background error covariance by $B \\in \\mathbb{R}^{N \\times N}$, and the observation error covariance by $R \\in \\mathbb{R}^{M \\times M}$.\n- The Kalman gain $K \\in \\mathbb{R}^{N \\times M}$ is defined by the well-tested formula $K = B H^\\top (H B H^\\top + R)^{-1}$.\n- The averaging kernel (also called the resolution matrix) $A \\in \\mathbb{R}^{N \\times N}$ is defined by $A = K H$ and quantifies how the analysis responds linearly to the true state perturbations.\n- The degrees of freedom for signal (DFS) is defined as $\\mathrm{DFS} = \\mathrm{trace}(A)$.\n- A point-spread function (PSF) for a location $j$ is the column $j$ of the matrix $A$, which represents the spatial distribution of the analysis response to a unit impulse at index $j$ in the true state. The representative PSF is taken at the central grid index $j_0 = \\lfloor N/2 \\rfloor$.\n- The full width at half maximum (FWHM) is the width of the PSF measured in physical units at half of its maximum amplitude. It must be computed in kilometers.\n\nSpatial domain and discretization:\n- The spatial domain is the one-dimensional interval $[0,L]$ with $L$ in kilometers. The state is discretized on $N$ grid points with uniform spacing, $x_i$ at positions $p_i = i \\,\\Delta x$ for $i = 0,1,\\dots,N-1$, where $\\Delta x = L/(N-1)$ in kilometers.\n\nCovariances:\n- The background error covariance $B$ is constructed using a Gaussian correlation model with variance $\\sigma_b^2$ and correlation length $L_b$ in kilometers: $B_{ij} = \\sigma_b^2 \\exp\\!\\left(-\\frac{(p_i - p_j)^2}{2 L_b^2}\\right)$.\n- The observation error covariance $R$ is diagonal with entries $\\sigma_r^2$ (homoscedastic), that is, $R = \\sigma_r^2 I_M$.\n\nObservation operators:\n- Each sensor network is defined by a set of sensor positions $\\{s_m\\}_{m=1}^M$ along $[0,L]$, and each sensor measures a Gaussian-weighted local average of the state with a footprint width parameter $L_h$ (standard deviation) in kilometers. The observation operator $H$ has rows $H_{m,:}$ defined by\n$$\nH_{m,i} = \\frac{\\exp\\!\\left(-\\frac{(p_i - s_m)^2}{2 L_h^2}\\right)}{\\sum_{k=0}^{N-1} \\exp\\!\\left(-\\frac{(p_k - s_m)^2}{2 L_h^2}\\right)},\n$$\nso that each row sums to $1$.\n\nComputation tasks for each scenario:\n1. Construct $B$ and $R$ using the specified $L$, $N$, $\\sigma_b^2$, $L_b$, and $\\sigma_r^2$.\n2. Construct the two distinct observation operators $H^{(1)}$ and $H^{(2)}$ using their respective sensor positions and footprint widths.\n3. Compute the Kalman gain $K$ for each $H$ using the formula $K = B H^\\top (H B H^\\top + R)^{-1}$.\n4. Compute the averaging kernel $A = K H$ for each network.\n5. Compute $\\mathrm{DFS} = \\mathrm{trace}(A)$ for each network.\n6. Extract the representative PSF as the column $j_0 = \\lfloor N/2 \\rfloor$ of $A$ and compute its FWHM in kilometers. The FWHM must be computed from the PSF sampled at the grid positions $p_i$ via linear interpolation to identify the left and right half-maximum crossing points. If the PSF maximum is non-positive or the half-maximum crossings are not both present within the domain, return the FWHM as a not-a-number value.\n\nTest suite:\nFor each scenario, two sensor networks are provided that differ only in their observation operator $H$ while sharing the same $B$ and $R$.\n\n- Scenario $1$:\n  - $L = 100$, $N = 50$, $\\sigma_b^2 = 1.0$, $L_b = 10$, $\\sigma_r^2 = 0.04$.\n  - Network $1$: $M_1 = 25$ sensors with positions uniformly spaced including endpoints on $[0,L]$ and footprint width $L_{h,1} = 4$.\n  - Network $2$: $M_2 = 8$ sensors with positions uniformly spaced including endpoints on $[0,L]$ and footprint width $L_{h,2} = 6$.\n\n- Scenario $2$:\n  - $L = 100$, $N = 50$, $\\sigma_b^2 = 1.0$, $L_b = 5$, $\\sigma_r^2 = 0.01$.\n  - Network $1$: $M_1 = 50$ sensors with positions uniformly spaced including endpoints on $[0,L]$ and footprint width $L_{h,1} = 2$.\n  - Network $2$: $M_2 = 4$ sensors with positions uniformly spaced including endpoints on $[0,L]$ and footprint width $L_{h,2} = 8$.\n\n- Scenario $3$:\n  - $L = 100$, $N = 50$, $\\sigma_b^2 = 1.0$, $L_b = 15$, $\\sigma_r^2 = 1.0$.\n  - Network $1$: $M_1 = 20$ sensors with positions uniformly spaced including endpoints on $[0,L]$ and footprint width $L_{h,1} = 4$.\n  - Network $2$: $M_2 = 20$ sensors with positions uniformly spaced on $[0,L]$ but shifted by half of the nominal sensor spacing (clipped to remain in $[0,L]$), and footprint width $L_{h,2} = 4$.\n\nRequired outputs and units:\n- For each sensor network in each scenario, compute:\n  - The DFS as a float (unitless).\n  - The FWHM of the representative PSF in kilometers as a float.\n- The final program output must be a single line containing a comma-separated list, enclosed in square brackets, aggregating the results in the following order:\n  $[$$\\mathrm{DFS}_{1,1}$,$\\mathrm{FWHM}_{1,1}$,$\\mathrm{DFS}_{1,2}$,$\\mathrm{FWHM}_{1,2}$,$\\mathrm{DFS}_{2,1}$,$\\mathrm{FWHM}_{2,1}$,$\\mathrm{DFS}_{2,2}$,$\\mathrm{FWHM}_{2,2}$,$\\mathrm{DFS}_{3,1}$,$\\mathrm{FWHM}_{3,1}$,$\\mathrm{DFS}_{3,2}$,$\\mathrm{FWHM}_{3,2}$$]$, where the first index denotes the scenario number and the second index denotes the network number within the scenario. The FWHM values must be expressed in kilometers. If a FWHM cannot be determined as specified, output its value as a not-a-number float.\n\nYour program must produce exactly one line in the specified format with no additional text. No input is required; all parameter values are provided above.", "solution": "The problem is assessed to be valid. It is scientifically grounded in the principles of linear Gaussian data assimilation, is well-posed with all necessary parameters and definitions provided, and is stated objectively. The computational tasks are clearly specified and are feasible.\n\nThe solution proceeds by implementing the defined computational steps for each of the three scenarios, each with two sensor networks.\n\nThe core of the problem lies in computing the averaging kernel matrix, $A \\in \\mathbb{R}^{N \\times N}$, which describes how the estimated state (the analysis) is a spatially weighted average of the true state. The analysis $x_a$ is related to the background state $x_b$ and the observation vector $y$ by the equation $x_a = x_b + K(y - Hx_b)$, where $K$ is the Kalman gain. When considering the relationship between the analysis and the true state $x_t$, assuming $y = Hx_t + \\epsilon_r$ and $x_b = x_t + \\epsilon_b$ (where $\\epsilon_r$ and $\\epsilon_b$ are the observation and background errors), the expected analysis is $\\mathbb{E}[x_a] = (I - KH)x_b + KHy$. Assuming an unbiased background $\\mathbb{E}[x_b] = x_t$ and unbiased observations $\\mathbb{E}[y] = Hx_t$, the analysis is also unbiased: $\\mathbb{E}[x_a] = x_t$. The matrix $A = KH$ is the averaging kernel, relating the analysis perturbation to the true state perturbation.\n\nThe procedure for each network is as follows:\n\n1.  **Discretize the Spatial Domain**: The one-dimensional domain of length $L$ is discretized into $N$ grid points. The positions of these points are given by $p_i = i \\cdot \\Delta x$ for $i \\in \\{0, 1, \\dots, N-1\\}$, where the grid spacing is $\\Delta x = L/(N-1)$.\n\n2.  **Construct Covariance Matrices**:\n    *   The background error covariance matrix $B \\in \\mathbb{R}^{N \\times N}$ is constructed using a Gaussian correlation function. The element $B_{ij}$ represents the covariance between the background errors at grid points $i$ and $j$.\n        $$\n        B_{ij} = \\sigma_b^2 \\exp\\!\\left(-\\frac{(p_i - p_j)^2}{2 L_b^2}\\right)\n        $$\n        where $\\sigma_b^2$ is the background error variance and $L_b$ is the correlation length.\n    *   The observation error covariance matrix $R \\in \\mathbb{R}^{M \\times M}$ is assumed to be diagonal, indicating uncorrelated observation errors. With homoscedastic errors, the matrix is a scaled identity matrix:\n        $$\n        R = \\sigma_r^2 I_M\n        $$\n        where $\\sigma_r^2$ is the observation error variance and $I_M$ is the $M \\times M$ identity matrix.\n\n3.  **Construct the Observation Operator**: The observation operator $H \\in \\mathbb{R}^{M \\times N}$ maps the state space to the observation space. Each row $m$ of $H$ corresponds to a sensor and is defined as a normalized Gaussian-weighted average of the state variables.\n    $$\n    H_{m,i} = \\frac{\\exp\\!\\left(-\\frac{(p_i - s_m)^2}{2 L_h^2}\\right)}{\\sum_{k=0}^{N-1} \\exp\\!\\left(-\\frac{(p_k - s_m)^2}{2 L_h^2}\\right)}\n    $$\n    Here, $s_m$ is the position of the $m$-th sensor and $L_h$ is the footprint width parameter. The denominator ensures that each row of $H$ sums to $1$, making each observation a proper weighted average. Sensor positions are determined according to the configuration specified for each network.\n\n4.  **Compute the Averaging Kernel**:\n    *   First, the Kalman gain matrix $K \\in \\mathbb{R}^{N \\times M}$ is computed. It provides the optimal weighting between the background information and the new observations.\n        $$\n        K = B H^\\top (H B H^\\top + R)^{-1}\n        $$\n    *   Next, the averaging kernel matrix $A \\in \\mathbb{R}^{N \\times N}$ is calculated.\n        $$\n        A = K H\n        $$\n\n5.  **Calculate Resolution Metrics**:\n    *   **Degrees of Freedom for Signal (DFS)**: This scalar quantity measures the number of independent signals in the state that can be constrained by the observations. It is the trace of the averaging kernel.\n        $$\n        \\mathrm{DFS} = \\mathrm{trace}(A)\n        $$\n    *   **Full Width at Half Maximum (FWHM)**: This metric quantifies the spatial resolution of the analysis. A point-spread function (PSF) is a column of the averaging kernel, $A_{:,j}$, representing the analysis response to a delta function perturbation in the true state at grid point $j$. We use the representative PSF at the central grid index $j_0 = \\lfloor N/2 \\rfloor$. The FWHM is the width of this PSF profile at half of its maximum amplitude. Its computation involves:\n        1.  Extracting the column vector $A_{:,j_0}$.\n        2.  Finding its maximum value, $A_{\\max}$.\n        3.  Determining the half-maximum value, $A_{\\max}/2$.\n        4.  Using linear interpolation on the PSF profile (sampled at positions $p_i$) to find the two spatial positions, $x_{\\text{left}}$ and $x_{\\text{right}}$, where the PSF value equals $A_{\\max}/2$.\n        5.  The FWHM is then calculated as $x_{\\text{right}} - x_{\\text{left}}$ in kilometers. If the maximum is non-positive or if both half-maximum crossings cannot be found within the domain, the FWHM is considered undefined and represented as not-a-number (NaN).\n\nThese steps are systematically applied to each of the six specified network configurations (two for each of the three scenarios). The resulting twelve values ($\\mathrm{DFS}$ and $\\mathrm{FWHM}$ for each) are aggregated into a single list as required.", "answer": "```python\nimport numpy as np\n\ndef calculate_fwhm(psf: np.ndarray, p: np.ndarray) - float:\n    \"\"\"\n    Computes the Full Width at Half Maximum (FWHM) of a point-spread function.\n\n    Args:\n        psf: The point-spread function values at grid points.\n        p: The spatial positions of the grid points (in km).\n\n    Returns:\n        The FWHM in kilometers, or np.nan if it cannot be determined.\n    \"\"\"\n    if psf.size != p.size:\n        raise ValueError(\"psf and p must have the same size.\")\n    \n    n = psf.shape[0]\n    max_val = np.max(psf)\n\n    if max_val = 0:\n        return np.nan\n\n    half_max_val = max_val / 2.0\n    max_idx = np.argmax(psf)\n\n    # Find left crossing\n    # Find indices on the left of the peak where psf is below half_max\n    left_indices = np.where(psf[:max_idx] = half_max_val)[0]\n    if left_indices.size == 0:\n        return np.nan  # No crossing on the left side\n    \n    i_left = left_indices[-1]\n    p1, p2 = p[i_left], p[i_left + 1]\n    v1, v2 = psf[i_left], psf[i_left + 1]\n    left_pos = p1 + (p2 - p1) * (half_max_val - v1) / (v2 - v1)\n\n    # Find right crossing\n    # Find indices on the right of the peak where psf is below half_max\n    # We search in psf[max_idx+1:] and then adjust the index\n    right_indices = np.where(psf[max_idx+1:] = half_max_val)[0]\n    if right_indices.size == 0:\n        return np.nan  # No crossing on the right side\n    \n    i_right = right_indices[0] + max_idx + 1\n    p1, p2 = p[i_right - 1], p[i_right]\n    v1, v2 = psf[i_right - 1], psf[i_right]\n    right_pos = p1 + (p2 - p1) * (half_max_val - v1) / (v2 - v1)\n\n    return right_pos - left_pos\n\ndef compute_metrics(L, N, sigma_b2, L_b, sigma_r2, M, sensor_config, L_h):\n    \"\"\"\n    Computes DFS and FWHM for a given data assimilation setup.\n    \"\"\"\n    # 1. Setup Domain\n    p = np.linspace(0, L, N)\n    delta_x = L / (N - 1)\n\n    # 2. Construct Covariance Matrices\n    # B matrix: Background Error Covariance\n    dist_sq = (p[:, None] - p[None, :])**2\n    B = sigma_b2 * np.exp(-dist_sq / (2 * L_b**2))\n    \n    # R matrix: Observation Error Covariance\n    R = sigma_r2 * np.eye(M)\n\n    # 3. Construct Observation Operator H\n    # Sensor positions\n    if sensor_config[0] == 'uniform':\n        s = np.linspace(0, L, M)\n    elif sensor_config[0] == 'shifted':\n        if M  1:\n            nominal_spacing = L / (M - 1)\n            shift = nominal_spacing / 2.0\n            s_nominal = np.linspace(0, L, M)\n            s_shifted = s_nominal + shift\n            s = np.clip(s_shifted, 0, L)\n        else: # Handle M=1 case\n             s = np.array([L/2.0])\n    else:\n        raise ValueError(f\"Unknown sensor_config: {sensor_config}\")\n\n    H = np.zeros((M, N))\n    for m in range(M):\n        weights = np.exp(-(p - s[m])**2 / (2 * L_h**2))\n        H[m, :] = weights / np.sum(weights)\n\n    # 4. Data Assimilation Calculations\n    HBHt = H @ B @ H.T\n    S_inv = np.linalg.inv(HBHt + R)\n    K = B @ H.T @ S_inv\n    A = K @ H\n\n    # 5. Calculate Metrics\n    dfs = np.trace(A)\n    \n    j0 = N // 2\n    psf = A[:, j0]\n    fwhm = calculate_fwhm(psf, p)\n    \n    return dfs, fwhm\n\ndef solve():\n    \"\"\"\n    Main function to run all test scenarios and print results.\n    \"\"\"\n    test_cases = [\n        # Scenario 1, Net 1\n        {'L': 100, 'N': 50, 'sigma_b2': 1.0, 'L_b': 10, 'sigma_r2': 0.04, 'M': 25, 'sensor_config': ('uniform',), 'L_h': 4},\n        # Scenario 1, Net 2\n        {'L': 100, 'N': 50, 'sigma_b2': 1.0, 'L_b': 10, 'sigma_r2': 0.04, 'M': 8, 'sensor_config': ('uniform',), 'L_h': 6},\n        # Scenario 2, Net 1\n        {'L': 100, 'N': 50, 'sigma_b2': 1.0, 'L_b': 5, 'sigma_r2': 0.01, 'M': 50, 'sensor_config': ('uniform',), 'L_h': 2},\n        # Scenario 2, Net 2\n        {'L': 100, 'N': 50, 'sigma_b2': 1.0, 'L_b': 5, 'sigma_r2': 0.01, 'M': 4, 'sensor_config': ('uniform',), 'L_h': 8},\n        # Scenario 3, Net 1\n        {'L': 100, 'N': 50, 'sigma_b2': 1.0, 'L_b': 15, 'sigma_r2': 1.0, 'M': 20, 'sensor_config': ('uniform',), 'L_h': 4},\n        # Scenario 3, Net 2\n        {'L': 100, 'N': 50, 'sigma_b2': 1.0, 'L_b': 15, 'sigma_r2': 1.0, 'M': 20, 'sensor_config': ('shifted',), 'L_h': 4},\n    ]\n\n    all_results = []\n    for params in test_cases:\n        dfs, fwhm = compute_metrics(**params)\n        all_results.append(dfs)\n        all_results.append(fwhm)\n    \n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3417773"}, {"introduction": "Our final practice tackles a critical issue encountered in nearly all real-world applications: model error. Here, you will investigate the consequences of performing a deconvolution using a forward model that is mis-specifiedâ€”a common situation where the instrument's true point-spread function is not perfectly known [@problem_id:3417750]. This advanced exercise will reveal how such a mismatch can create misleading results, including over-sharpening and spurious artifacts, underscoring the importance of understanding the *true* resolution operator, not just the one implied by the inversion algorithm.", "problem": "Consider a one-dimensional periodic grid of length $N$ with unit grid spacing. Let the forward operator $H$ be the circular convolution by a point-spread function (PSF) $P$, so that for a true model $m_{\\text{true}}$ and data $d$,\n$$\nd = H\\,m_{\\text{true}} + n,\n$$\nwith $n$ representing additive noise that is white and has been pre-whitened to unit variance. Suppose an analyst builds a quadratic-penalty (Tikhonov) estimator using an assumed PSF $\\tilde{P}$ and an identity regularization operator, seeking an estimate $\\hat{m}$ that minimizes\n$$\n\\| \\tilde{H}\\,m - d \\|_2^2 + \\alpha^2 \\| m \\|_2^2,\n$$\nwhere $\\tilde{H}$ is circular convolution by $\\tilde{P}$ and $\\alpha>0$ is the regularization parameter. The linear estimator can be written as $\\hat{m} = W\\,d$ for some operator $W$ determined by $(\\tilde{H},\\alpha)$. The resolution operator (also called the averaging kernel) with respect to the true forward map $H$ is defined by\n$$\nA = W\\,H,\n$$\nso that the mean estimate (in the absence of noise) satisfies $\\hat{m} = A\\,m_{\\text{true}}$.\n\nYou will work in the discrete Fourier domain under periodic boundary conditions, using only the fundamental facts that circular convolution is diagonalized by the discrete Fourier transform, and that quadratic-penalty estimators obtained by minimizing a strictly convex quadratic functional are linear. You will:\n- Derive expressions for the frequency response of $A$ for the correctly specified case $\\tilde{P}=P$ and for the mis-specified case $\\tilde{P}\\neq P$, starting from the normal equations of the quadratic minimization problem and the diagonalization of circular convolution by the discrete Fourier transform.\n- Implement these expressions numerically for discrete PSFs $P$ and $\\tilde{P}$ that are circularly wrapped discrete Gaussians of standard deviations $\\sigma$ and $\\tilde{\\sigma}$ (measured in grid units), normalized to have unit sum. Explicitly, define the discrete PSF on indices $n\\in\\{0,1,\\dots,N-1\\}$ by\n$$\nP[n] \\propto \\exp\\!\\left(-\\frac{1}{2}\\left(\\frac{\\min(n,\\,N-n)}{\\sigma}\\right)^2\\right),\n$$\nwith normalization to enforce $\\sum_{n=0}^{N-1} P[n] = 1$, and analogously for $\\tilde{P}$ with $\\tilde{\\sigma}$.\n- Compute the discrete resolution kernels (the first row of $A$ under periodic boundary conditions) in the spatial domain for both the correctly specified and mis-specified cases by inverse transforming their frequency responses.\n\nQuantify resolution and artifacts as follows:\n- Let $a_{\\text{cor}}[n]$ denote the correct-case resolution kernel and $a_{\\text{mis}}[n]$ denote the mis-specified-case resolution kernel. For any even kernel $a[n]$ with its global maximum at index $0$, define the full width at half maximum (FWHM) in grid units as $2x_{1/2}$, where $x_{1/2}\\ge 0$ is the smallest nonnegative real number for which the kernel, interpolated linearly between grid points, first crosses half its peak value when moving from $n=0$ to positive indices. Use linear interpolation between the first pair of consecutive indices bracketing the half-maximum crossing.\n- Define the oversharpening ratio as\n$$\nr = \\frac{\\text{FWHM}(a_{\\text{mis}})}{\\text{FWHM}(a_{\\text{cor}})}.\n$$\nValues $r1$ indicate over-sharpening relative to the correctly specified case.\n- Define the artifact ratio outside the main lobe for a kernel $a[n]$ as\n$$\n\\eta(a) = \\frac{\\sum_{n=0}^{N-1} |a[n]| - \\sum_{|n|\\le \\lfloor x_{1/2}\\rfloor} |a[n]|}{\\sum_{n=0}^{N-1} |a[n]|},\n$$\nwhere the index interval $|n|\\le \\lfloor x_{1/2}\\rfloor$ denotes the set $\\{0,1,\\dots,\\lfloor x_{1/2}\\rfloor\\}$ and their symmetric counterparts modulo $N$. Use periodic symmetry and evenness to account for both sides. Define the artifact increase under mis-specification as\n$$\n\\Delta \\eta = \\eta(a_{\\text{mis}}) - \\eta(a_{\\text{cor}}).\n$$\n- Define the most negative sidelobe amplitude for a kernel $a[n]$ as $\\min_n a[n]$.\n\nYour program must implement the above steps using the discrete Fourier transform to obtain the correct-case and mis-specified-case resolution kernels for the given test suite. For each test case, compute and return the triple $[r, \\Delta\\eta, \\min_n a_{\\text{mis}}[n]]$ as floating-point numbers.\n\nTest suite (each case is $(N,\\sigma,\\tilde{\\sigma},\\alpha)$):\n- Case $1$: $(512, 3.0, 3.0, 0.1)$.\n- Case $2$: $(512, 3.0, 2.0, 0.1)$.\n- Case $3$: $(512, 3.0, 4.5, 0.1)$.\n- Case $4$: $(512, 3.0, 2.0, 0.5)$.\n- Case $5$: $(512, 3.0, 2.0, 0.01)$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each item is itself a list of three comma-separated floats in the order $[r, \\Delta\\eta, \\min a_{\\text{mis}}]$ for the corresponding test case, for example:\n[[r1,DeltaEta1,minMis1],[r2,DeltaEta2,minMis2],...].\nNo external input is permitted, and all computations must assume periodic boundary conditions and the definitions above. All angles, if any appear, must be in radians, but no angles are present here. No physical units are involved; all grid units are dimensionless.", "solution": "The problem statement has been meticulously reviewed and is determined to be valid. It is scientifically grounded in the principles of inverse problem theory, specifically Tikhonov regularization and resolution analysis. The problem is well-posed, objective, and provides a complete and consistent set of definitions and data for a unique, verifiable solution.\n\nThe core of the problem is to derive and compute the resolution operator for a linear inverse problem, both when the model of the system's point-spread function (PSF) is correct and when it is mis-specified. We will work in the discrete Fourier domain, where circular convolution becomes simple multiplication.\n\n### Derivation of the Resolution Operator's Frequency Response\n\nWe are given a Tikhonov-regularized cost functional to be minimized:\n$$\nJ(m) = \\| \\tilde{H}m - d \\|_2^2 + \\alpha^2 \\| m \\|_2^2\n$$\nHere, $m$ is the model vector we seek, $d$ is the data vector, $\\tilde{H}$ is the forward operator based on an assumed PSF $\\tilde{P}$, and $\\alpha > 0$ is the regularization parameter. The norm $\\| \\cdot \\|_2$ is the Euclidean norm. The operator $\\tilde{H}$ represents circular convolution with $\\tilde{P}$.\n\nTo find the model estimate $\\hat{m}$ that minimizes $J(m)$, we compute the gradient of $J(m)$ with respect to $m$ and set it to zero. For real-valued models and operators, this gives:\n$$\n\\nabla_m J(m) = 2 \\tilde{H}^T (\\tilde{H}m - d) + 2 \\alpha^2 m = 0\n$$\nwhere $\\tilde{H}^T$ is the transpose of $\\tilde{H}$. In the more general complex case, the transpose is replaced by the conjugate transpose $\\tilde{H}^*$. Rearranging the terms to solve for $m$ yields the normal equations:\n$$\n(\\tilde{H}^T \\tilde{H} + \\alpha^2 I) m = \\tilde{H}^T d\n$$\nwhere $I$ is the identity operator. The solution $\\hat{m}$ is thus given by:\n$$\n\\hat{m} = (\\tilde{H}^T \\tilde{H} + \\alpha^2 I)^{-1} \\tilde{H}^T d\n$$\nThis expresses the estimate $\\hat{m}$ as a linear transformation of the data $d$. We are given that $\\hat{m} = Wd$, so the estimator operator $W$ is:\n$$\nW = (\\tilde{H}^T \\tilde{H} + \\alpha^2 I)^{-1} \\tilde{H}^T\n$$\nThe resolution operator (or averaging kernel) $A$ relates the mean estimate to the true model $m_{\\text{true}}$ via $\\hat{m} = A m_{\\text{true}}$ (in the absence of noise, where $d = H m_{\\text{true}}$).  The definition is $A = WH$. Substituting the expressions for $W$ and $d$:\n$$\n\\hat{m} = Wd = W(H m_{\\text{true}}) = (WH) m_{\\text{true}}\n$$\nThus, the resolution operator is:\n$$\nA = W H = (\\tilde{H}^T \\tilde{H} + \\alpha^2 I)^{-1} \\tilde{H}^T H\n$$\nThe problem is set on a periodic grid, so circular convolution operators are diagonalized by the Discrete Fourier Transform (DFT). Let $\\mathcal{F}$ denote the DFT operator. Any circular convolution operator $C$ with kernel $c$ is diagonalized as $C = \\mathcal{F}^{-1} D_c \\mathcal{F}$, where $D_c$ is a diagonal matrix whose entries are the DFT of the kernel $c$, denoted $\\hat{c}$. The frequency response of the operator is this set of diagonal entries.\n\nThe operators $H$ and $\\tilde{H}$ correspond to diagonal matrices in the Fourier domain with diagonal entries given by $\\hat{P}[k]$ and $\\hat{P}_{\\text{tilde}}[k]$, the DFTs of the true PSF $P$ and the assumed PSF $\\tilde{P}$, respectively. The conjugate transpose $\\tilde{H}^*$ (which for real kernels is just $\\tilde{H}^T$) corresponds to a diagonal matrix with entries $\\hat{P}_{\\text{tilde}}[k]^*$.\n\nTransforming the expression for $A$ into the Fourier domain, each operator is replaced by its corresponding diagonal matrix of frequency responses. The $k$-th component of the frequency response of $A$, denoted $\\hat{A}[k]$, is:\n$$\n\\hat{A}[k] = \\frac{1}{|\\hat{P}_{\\text{tilde}}[k]|^2 + \\alpha^2} \\cdot \\hat{P}_{\\text{tilde}}[k]^* \\cdot \\hat{P}[k]\n$$\nThe given PSFs are real and symmetric ($P[n] = P[N-n]$ for $n \\neq 0$), so their DFTs $\\hat{P}[k]$ and $\\hat{P}_{\\text{tilde}}[k]$ are real-valued. The expression simplifies to:\n$$\n\\hat{A}[k] = \\frac{\\hat{P}_{\\text{tilde}}[k] \\hat{P}[k]}{\\hat{P}_{\\text{tilde}}[k]^2 + \\alpha^2}\n$$\nThis is the general frequency response of the resolution operator. We now consider the two specified cases.\n\n1.  **Correctly Specified Case ($\\tilde{P} = P$):**\n    If the assumed PSF is correct, $\\tilde{P} = P$, which implies $\\hat{P}_{\\text{tilde}}[k] = \\hat{P}[k]$. The frequency response of the resolution operator, $\\hat{A}_{\\text{cor}}$, becomes:\n    $$\n    \\hat{A}_{\\text{cor}}[k] = \\frac{\\hat{P}[k]^2}{\\hat{P}[k]^2 + \\alpha^2}\n    $$\n\n2.  **Mis-specified Case ($\\tilde{P} \\neq P$):**\n    If the assumed PSF is incorrect, the general formula applies directly for the frequency response $\\hat{A}_{\\text{mis}}$:\n    $$\n    \\hat{A}_{\\text{mis}}[k] = \\frac{\\hat{P}_{\\text{tilde}}[k] \\hat{P}[k]}{\\hat{P}_{\\text{tilde}}[k]^2 + \\alpha^2}\n    $$\n\n### Numerical Implementation\n\nThe implementation proceeds as follows:\n1.  **PSF Generation:** For given parameters $(N, \\sigma)$, a discrete, circularly wrapped Gaussian PSF is generated using the formula $P[n] \\propto \\exp(-\\frac{1}{2}(\\frac{\\min(n, N-n)}{\\sigma})^2)$ for $n \\in \\{0, 1, ..., N-1\\}$. The resulting vector is normalized to have a sum of $1$. This is done for both $(\\sigma)$ to get $P$ and $(\\tilde{\\sigma})$ to get $\\tilde{P}$.\n2.  **Fourier Transformation:** The DFTs of $P$ and $\\tilde{P}$ are computed using `numpy.fft.fft`. As discussed, the resulting frequency-domain representations, $\\hat{P}$ and $\\hat{P}_{\\text{tilde}}$, are real-valued.\n3.  **Resolution Kernels:** The frequency responses $\\hat{A}_{\\text{cor}}[k]$ and $\\hat{A}_{\\text{mis}}[k]$ are calculated using the derived formulas. The spatial-domain resolution kernels, $a_{\\text{cor}}[n]$ and $a_{\\text{mis}}[n]$, are then obtained by applying the inverse DFT (`numpy.fft.ifft`). The resulting kernels are real and symmetric, centered at index $n=0$.\n4.  **Metric Calculation:** The required metrics are computed from the spatial kernels:\n    - **FWHM:** The full width at half-maximum is calculated for each kernel. Since the kernels are centered at $n=0$, we find the smallest non-negative value $x_{1/2}$ where the linearly interpolated kernel value equals half its peak value, $a[0]/2$. The FWHM is $2x_{1/2}$. This involves finding the first grid interval $[i, i+1]$ where $a[i] \\ge a[0]/2$ and $a[i+1]  a[0]/2$, followed by linear interpolation.\n    - **Oversharpening Ratio ($r$):** The ratio $\\text{FWHM}(a_{\\text{mis}}) / \\text{FWHM}(a_{\\text{cor}})$ is computed.\n    - **Artifact Ratio ($\\eta$):** For each kernel, the artifact ratio $\\eta(a)$ is computed as the fraction of the total absolute mass lying outside a central main lobe. The main lobe is defined by the integer indices $|n| \\le \\lfloor x_{1/2} \\rfloor$.\n    - **Artifact Increase ($\\Delta\\eta$):** The difference $\\eta(a_{\\text{mis}}) - \\eta(a_{\\text{cor}})$ is computed.\n    - **Most Negative Sidelobe:** The minimum value of the $a_{\\text{mis}}$ kernel is found.\n\nThis procedure is applied to each test case to generate the required output triplets $[r, \\Delta\\eta, \\min_n a_{\\text{mis}}[n]]$.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef create_psf(N, sigma):\n    \"\"\"\n    Creates a normalized, circularly wrapped 1D discrete Gaussian PSF.\n    \"\"\"\n    if sigma == 0:\n        psf = np.zeros(N)\n        psf[0] = 1.0\n        return psf\n    n_indices = np.arange(N)\n    distances = np.minimum(n_indices, N - n_indices)\n    psf = np.exp(-0.5 * (distances / sigma)**2)\n    psf /= np.sum(psf)\n    return psf\n\ndef calculate_x_half(kernel):\n    \"\"\"\n    Calculates the half-width at half-maximum (x_1/2) for a centered kernel.\n    Uses linear interpolation to find the crossing point.\n    \"\"\"\n    N = len(kernel)\n    peak_value = kernel[0]\n    \n    if peak_value = 0:\n        return float('inf') # FWHM is not well-defined\n\n    half_peak = peak_value / 2.0\n\n    # Search for the first crossing of the half-peak value on the positive index side\n    for i in range(N // 2):\n        if kernel[i] >= half_peak and kernel[i+1]  half_peak:\n            y1, y2 = kernel[i], kernel[i+1]\n            x1 = i\n            # Avoid division by zero if kernel is flat\n            if (y1 - y2) == 0:\n                return float(i)\n            # Linear interpolation to find x_half\n            x_half = x1 + (y1 - half_peak) / (y1 - y2)\n            return x_half\n            \n    # If no crossing is found, kernel is wider than half the domain\n    return float(N // 2)\n\ndef calculate_eta(kernel, x_half):\n    \"\"\"\n    Calculates the artifact ratio eta for a given kernel and its x_1/2.\n    \"\"\"\n    N = len(kernel)\n    total_abs_sum = np.sum(np.abs(kernel))\n    if total_abs_sum == 0:\n        return 0.0\n\n    main_lobe_limit = int(np.floor(x_half))\n    \n    # Sum absolute values over the main lobe, defined by |n| = floor(x_1/2)\n    main_lobe_abs_sum = np.abs(kernel[0])\n    if main_lobe_limit > 0:\n        # Sum for positive indices: 1, ..., limit\n        main_lobe_abs_sum += np.sum(np.abs(kernel[1:main_lobe_limit + 1]))\n        # Sum for negative indices (periodic): N-limit, ..., N-1\n        main_lobe_abs_sum += np.sum(np.abs(kernel[N - main_lobe_limit:]))\n\n    eta = (total_abs_sum - main_lobe_abs_sum) / total_abs_sum\n    return eta\n\ndef analyze_resolution(N, sigma, sigma_tilde, alpha):\n    \"\"\"\n    Performs the full resolution analysis for a single test case.\n    \"\"\"\n    # 1. Generate true and assumed PSFs\n    P = create_psf(N, sigma)\n    P_tilde = create_psf(N, sigma_tilde)\n\n    # 2. Compute their DFTs.\n    # Since PSFs are real and symmetric, their FFTs will be real.\n    hat_p = np.fft.fft(P).real\n    hat_p_tilde = np.fft.fft(P_tilde).real\n\n    # 3. Compute frequency responses of resolution operators\n    # Correctly specified case\n    hat_A_cor = (hat_p**2) / (hat_p**2 + alpha**2)\n    # Mis-specified case\n    hat_A_mis = (hat_p_tilde * hat_p) / (hat_p_tilde**2 + alpha**2)\n\n    # 4. Compute spatial resolution kernels via inverse DFT\n    # Resulting kernels are real and symmetric (centered at index 0)\n    a_cor = np.fft.ifft(hat_A_cor).real\n    a_mis = np.fft.ifft(hat_A_mis).real\n\n    # 5. Calculate metrics for both kernels\n    # Correct case\n    x_half_cor = calculate_x_half(a_cor)\n    fwhm_cor = 2.0 * x_half_cor\n    eta_cor = calculate_eta(a_cor, x_half_cor)\n\n    # Mis-specified case\n    x_half_mis = calculate_x_half(a_mis)\n    fwhm_mis = 2.0 * x_half_mis\n    eta_mis = calculate_eta(a_mis, x_half_mis)\n    min_a_mis = np.min(a_mis)\n\n    # 6. Compute final quantities\n    if fwhm_cor == 0:  # Avoid division by zero\n        r = float('inf') if fwhm_mis > 0 else 1.0\n    else:\n        r = fwhm_mis / fwhm_cor\n\n    delta_eta = eta_mis - eta_cor\n\n    return [r, delta_eta, min_a_mis]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (512, 3.0, 3.0, 0.1),\n        (512, 3.0, 2.0, 0.1),\n        (512, 3.0, 4.5, 0.1),\n        (512, 3.0, 2.0, 0.5),\n        (512, 3.0, 2.0, 0.01),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, sigma, sigma_tilde, alpha = case\n        result = analyze_resolution(N, sigma, sigma_tilde, alpha)\n        results.append(result)\n\n    # Prepare the output string in the exact required format\n    # Example: [[r1,d1,m1],[r2,d2,m2]]\n    result_strings = []\n    for res in results:\n        # Format each triplet [r, delta_eta, min_a_mis]\n        # to ensure no spaces and standard float representation\n        triplet_str = f\"[{res[0]},{res[1]},{res[2]}]\"\n        result_strings.append(triplet_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "3417750"}]}