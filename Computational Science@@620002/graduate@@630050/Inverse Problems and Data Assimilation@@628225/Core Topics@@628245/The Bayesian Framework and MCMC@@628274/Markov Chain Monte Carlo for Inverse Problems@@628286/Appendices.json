{"hands_on_practices": [{"introduction": "The heart of any Metropolis-Hastings algorithm is the acceptance probability, which ensures the Markov chain converges to the desired posterior distribution. This first exercise provides a concrete, step-by-step calculation of this probability for a practical inverse problem. By working with a non-Gaussian (Laplace) noise model, you will see how the choice of data misfit, in this case the $\\ell_1$ norm, directly influences the posterior landscape and the sampler's behavior [@problem_id:3400306].", "problem": "Consider a linear inverse problem in which the observed data vector $y \\in \\mathbb{R}^{2}$ is related to an unknown parameter vector $x \\in \\mathbb{R}^{2}$ through a forward operator $G \\in \\mathbb{R}^{2 \\times 2}$ and additive noise, $y = G x + \\varepsilon$. Assume the noise components $\\varepsilon_{i}$ are independent and identically distributed according to the Laplace distribution with zero mean and known scale parameter $b > 0$, so that each component has density $p(\\varepsilon_{i}) = \\frac{1}{2 b} \\exp\\!\\big(-|\\varepsilon_{i}|/b\\big)$. Assume a Gaussian prior $x \\sim \\mathcal{N}(m, C)$, where $m \\in \\mathbb{R}^{2}$ and $C \\in \\mathbb{R}^{2 \\times 2}$ is symmetric positive definite. You will use the Bayesian posterior to construct a Metropolis–Hastings (MH) step with a symmetric random-walk proposal.\n\nUse the following concrete specification:\n- $G = \\begin{pmatrix} 2 & -1 \\\\ 0.5 & 1 \\end{pmatrix}$,\n- $y = \\begin{pmatrix} 1.2 \\\\ -0.3 \\end{pmatrix}$,\n- $b = 0.25$,\n- $m = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$,\n- $C = \\begin{pmatrix} 1 & 0 \\\\ 0 & 4 \\end{pmatrix}$,\n- current state $x^{(k)} = \\begin{pmatrix} 0.2 \\\\ -0.4 \\end{pmatrix}$,\n- proposed state $x' = \\begin{pmatrix} 0.5 \\\\ -0.7 \\end{pmatrix}$,\n- the proposal is symmetric in the sense that $q(x' \\mid x^{(k)}) = q(x^{(k)} \\mid x')$.\n\nTasks:\n1. Starting from the Laplace density and the independence of $\\varepsilon_{i}$, derive the data-dependent negative log-likelihood $\\Phi(x)$ (defined up to an additive constant independent of $x$), and then evaluate $\\Phi(x^{(k)})$ and $\\Phi(x')$ numerically for the given values.\n2. Using Bayes’ rule and the Gaussian prior, define the prior potential $\\Psi(x) = \\frac{1}{2} (x - m)^{\\top} C^{-1} (x - m)$, and derive an explicit expression for the Metropolis–Hastings acceptance ratio $r = \\frac{\\pi(x' \\mid y)}{\\pi(x^{(k)} \\mid y)}$ in terms of $\\Phi$ and $\\Psi$. Evaluate $r$ numerically for the given values and compute the acceptance probability $\\alpha = \\min\\{1, r\\}$.\n\nExpress the final acceptance probability $\\alpha$ as a decimal and round your answer to four significant figures. No units are required.", "solution": "The user has provided a well-defined Bayesian inverse problem and asks for the computation of the Metropolis-Hastings acceptance probability for a specific state transition. The problem is scientifically and mathematically sound, self-contained, and all necessary data and definitions are provided. We proceed with the solution.\n\n### Task 1: Negative Log-Likelihood\n\nThe problem specifies that the noise components $\\varepsilon_i$ are independent and identically distributed according to a Laplace distribution with zero mean and scale parameter $b$. The probability density for a single noise component is $p(\\varepsilon_i) = \\frac{1}{2b}\\exp(-|\\varepsilon_i|/b)$. Given the independence, the joint probability density for the noise vector $\\varepsilon = \\begin{pmatrix} \\varepsilon_1 & \\varepsilon_2 \\end{pmatrix}^\\top$ is the product of the individual densities:\n$$ p(\\varepsilon) = p(\\varepsilon_1) p(\\varepsilon_2) = \\left(\\frac{1}{2b}\\exp\\left(-\\frac{|\\varepsilon_1|}{b}\\right)\\right) \\left(\\frac{1}{2b}\\exp\\left(-\\frac{|\\varepsilon_2|}{b}\\right)\\right) = \\frac{1}{4b^2}\\exp\\left(-\\frac{|\\varepsilon_1| + |\\varepsilon_2|}{b}\\right) $$\nIn terms of the $L_1$ norm, where $\\|\\varepsilon\\|_1 = |\\varepsilon_1| + |\\varepsilon_2|$, this is:\n$$ p(\\varepsilon) = \\frac{1}{4b^2}\\exp\\left(-\\frac{\\|\\varepsilon\\|_1}{b}\\right) $$\nThe likelihood function $p(y|x)$ is the probability density of the observation $y$ given the parameter $x$. This is equivalent to the probability density of the noise $\\varepsilon = y - Gx$:\n$$ p(y|x) = \\frac{1}{4b^2}\\exp\\left(-\\frac{\\|y - Gx\\|_1}{b}\\right) $$\nThe negative log-likelihood is $-\\ln(p(y|x))$:\n$$ -\\ln(p(y|x)) = -\\ln\\left(\\frac{1}{4b^2}\\right) - \\ln\\left(\\exp\\left(-\\frac{\\|y - Gx\\|_1}{b}\\right)\\right) = \\ln(4b^2) + \\frac{1}{b}\\|y - Gx\\|_1 $$\nThe problem defines the negative log-likelihood $\\Phi(x)$ up to an additive constant that is independent of $x$. We can therefore drop the term $\\ln(4b^2)$ and define $\\Phi(x)$ as:\n$$ \\Phi(x) = \\frac{1}{b}\\|y - Gx\\|_1 $$\nNow we evaluate $\\Phi(x)$ for the current state $x^{(k)}$ and the proposed state $x'$. The given values are $G = \\begin{pmatrix} 2 & -1 \\\\ 0.5 & 1 \\end{pmatrix}$, $y = \\begin{pmatrix} 1.2 \\\\ -0.3 \\end{pmatrix}$, $b = 0.25$, $x^{(k)} = \\begin{pmatrix} 0.2 \\\\ -0.4 \\end{pmatrix}$, and $x' = \\begin{pmatrix} 0.5 \\\\ -0.7 \\end{pmatrix}$.\n\nFor the current state $x^{(k)}$:\n$$ Gx^{(k)} = \\begin{pmatrix} 2 & -1 \\\\ 0.5 & 1 \\end{pmatrix} \\begin{pmatrix} 0.2 \\\\ -0.4 \\end{pmatrix} = \\begin{pmatrix} 2(0.2) - 1(-0.4) \\\\ 0.5(0.2) + 1(-0.4) \\end{pmatrix} = \\begin{pmatrix} 0.8 \\\\ -0.3 \\end{pmatrix} $$\n$$ y - Gx^{(k)} = \\begin{pmatrix} 1.2 \\\\ -0.3 \\end{pmatrix} - \\begin{pmatrix} 0.8 \\\\ -0.3 \\end{pmatrix} = \\begin{pmatrix} 0.4 \\\\ 0 \\end{pmatrix} $$\n$$ \\|y - Gx^{(k)}\\|_1 = |0.4| + |0| = 0.4 $$\n$$ \\Phi(x^{(k)}) = \\frac{1}{0.25} \\|y - Gx^{(k)}\\|_1 = 4 \\times 0.4 = 1.6 $$\n\nFor the proposed state $x'$:\n$$ Gx' = \\begin{pmatrix} 2 & -1 \\\\ 0.5 & 1 \\end{pmatrix} \\begin{pmatrix} 0.5 \\\\ -0.7 \\end{pmatrix} = \\begin{pmatrix} 2(0.5) - 1(-0.7) \\\\ 0.5(0.5) + 1(-0.7) \\end{pmatrix} = \\begin{pmatrix} 1.7 \\\\ -0.45 \\end{pmatrix} $$\n$$ y - Gx' = \\begin{pmatrix} 1.2 \\\\ -0.3 \\end{pmatrix} - \\begin{pmatrix} 1.7 \\\\ -0.45 \\end{pmatrix} = \\begin{pmatrix} -0.5 \\\\ 0.15 \\end{pmatrix} $$\n$$ \\|y - Gx'\\|_1 = |-0.5| + |0.15| = 0.5 + 0.15 = 0.65 $$\n$$ \\Phi(x') = \\frac{1}{0.25} \\|y - Gx'\\|_1 = 4 \\times 0.65 = 2.6 $$\n\n### Task 2: Prior Potential and Acceptance Probability\n\nThe prior potential is given as $\\Psi(x) = \\frac{1}{2}(x - m)^{\\top}C^{-1}(x - m)$. The prior mean is $m = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ and the prior covariance is $C = \\begin{pmatrix} 1 & 0 \\\\ 0 & 4 \\end{pmatrix}$. The inverse of the covariance matrix is:\n$$ C^{-1} = \\begin{pmatrix} 1^{-1} & 0 \\\\ 0 & 4^{-1} \\end{pmatrix} = \\begin{pmatrix} 1 & 0 \\\\ 0 & 0.25 \\end{pmatrix} $$\nWith $m = 0$, the prior potential simplifies to $\\Psi(x) = \\frac{1}{2}x^{\\top}C^{-1}x$. For $x = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$:\n$$ \\Psi(x) = \\frac{1}{2} \\begin{pmatrix} x_1 & x_2 \\end{pmatrix} \\begin{pmatrix} 1 & 0 \\\\ 0 & 0.25 \\end{pmatrix} \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix} = \\frac{1}{2}(x_1^2 + 0.25x_2^2) $$\nWe evaluate $\\Psi(x)$ for $x^{(k)}$ and $x'$.\n\nFor the current state $x^{(k)} = \\begin{pmatrix} 0.2 \\\\ -0.4 \\end{pmatrix}$:\n$$ \\Psi(x^{(k)}) = \\frac{1}{2}((0.2)^2 + 0.25(-0.4)^2) = \\frac{1}{2}(0.04 + 0.25(0.16)) = \\frac{1}{2}(0.04 + 0.04) = 0.04 $$\n\nFor the proposed state $x' = \\begin{pmatrix} 0.5 \\\\ -0.7 \\end{pmatrix}$:\n$$ \\Psi(x') = \\frac{1}{2}((0.5)^2 + 0.25(-0.7)^2) = \\frac{1}{2}(0.25 + 0.25(0.49)) = \\frac{1}{2}(0.25 + 0.1225) = \\frac{1}{2}(0.3725) = 0.18625 $$\n\nThe posterior distribution $\\pi(x|y)$ is, by Bayes' rule, proportional to the product of the likelihood and the prior: $\\pi(x|y) \\propto p(y|x)p(x)$. In terms of the negative potentials, $p(y|x) \\propto \\exp(-\\Phi(x))$ and $p(x) \\propto \\exp(-\\Psi(x))$. Therefore:\n$$ \\pi(x|y) \\propto \\exp(-\\Phi(x))\\exp(-\\Psi(x)) = \\exp(-(\\Phi(x) + \\Psi(x))) $$\nThe Metropolis-Hastings acceptance ratio $r$ for a symmetric proposal distribution is the ratio of the posterior probabilities:\n$$ r = \\frac{\\pi(x'|y)}{\\pi(x^{(k)}|y)} = \\frac{\\exp(-(\\Phi(x') + \\Psi(x')))}{\\exp(-(\\Phi(x^{(k)}) + \\Psi(x^{(k)})))} = \\exp((\\Phi(x^{(k)}) + \\Psi(x^{(k)})) - (\\Phi(x') + \\Psi(x'))) $$\nSubstituting the numerical values we computed:\n$$ \\Phi(x^{(k)}) = 1.6 \\quad , \\quad \\Psi(x^{(k)}) = 0.04 $$\n$$ \\Phi(x') = 2.6 \\quad , \\quad \\Psi(x') = 0.18625 $$\nThe exponent of $r$ is:\n$$ (1.6 + 0.04) - (2.6 + 0.18625) = 1.64 - 2.78625 = -1.14625 $$\nSo, the acceptance ratio is:\n$$ r = \\exp(-1.14625) \\approx 0.31780517 $$\nThe acceptance probability $\\alpha$ is defined as $\\alpha = \\min\\{1, r\\}$. Since $r < 1$:\n$$ \\alpha = r = \\exp(-1.14625) \\approx 0.31780517 $$\nRounding to four significant figures as requested gives $\\alpha \\approx 0.3178$.", "answer": "$$\n\\boxed{0.3178}\n$$", "id": "3400306"}, {"introduction": "In many complex scientific models, the likelihood function $p(y|\\theta)$ is intractable, meaning it cannot be evaluated directly. This exercise introduces a powerful, modern technique for such scenarios: Approximate Bayesian Computation (ABC). You will implement a full ABC-MCMC algorithm, which replaces the likelihood evaluation with model simulation and comparison via summary statistics, providing a hands-on experience with likelihood-free inference [@problem_id:3400280].", "problem": "Consider an inverse problem in which a parameter vector $\\theta = (\\mu,\\phi,b)$ governs a stochastic autoregressive simulator of order $1$ with Laplace innovations, defined by the recurrence\n$$\ny_t = \\mu + \\phi\\,(y_{t-1}-\\mu) + \\varepsilon_t,\\quad \\varepsilon_t \\sim \\text{Laplace}(0,b),\\quad t=2,\\dots,T,\n$$\nwith initialization $y_1$ drawn from a normal distribution $y_1 \\sim \\mathcal{N}(\\mu,b^2)$ and a fixed length $T$. The goal is to infer $\\theta$ from a single observed trajectory $y_{\\text{obs}} \\in \\mathbb{R}^T$ when the likelihood $p(y_{\\text{obs}} \\mid \\theta)$ is intractable. Use Approximate Bayesian Computation (ABC) embedded in a Markov chain Monte Carlo (MCMC) algorithm, known as ABC-MCMC, which replaces evaluation of the intractable likelihood by comparing simulated summaries against observed summaries.\n\nStart from the foundational Bayesian relation\n$$\n\\pi(\\theta \\mid y) \\propto \\pi(\\theta)\\,p(y\\mid\\theta),\n$$\nand the principle that the Metropolis-Hastings algorithm targets a posterior distribution by constructing a Markov chain with acceptance probability that corrects proposal bias by a Radon-Nikodym derivative of target and proposal densities. In the ABC setting, replace $p(y\\mid\\theta)$ by a simulated-data comparison using summary statistics and a distance threshold.\n\nImplement the following:\n\n$1.$ Define two summary statistic designs for a time series $y=(y_1,\\dots,y_T)$.\n\n$\\,\\,\\,\\,$(a) Basic summaries $s_{\\text{basic}}(y) = \\big(\\bar{y},\\,\\widehat{\\mathrm{Var}}(y),\\,\\widehat{\\rho}_1(y)\\big)$, where $\\bar{y}$ is the sample mean, $\\widehat{\\mathrm{Var}}(y)$ is the unbiased sample variance, and $\\widehat{\\rho}_1(y)$ is the lag-$1$ sample autocorrelation computed as the Pearson correlation of $(y_1,\\dots,y_{T-1})$ with $(y_2,\\dots,y_T)$.\n\n$\\,\\,\\,\\,$(b) Robust summaries $s_{\\text{robust}}(y) = \\big(\\mathrm{med}(y),\\,\\mathrm{MAD}(y),\\,\\widehat{\\rho}^{\\mathrm{S}}_1(y)\\big)$, where $\\mathrm{med}(y)$ is the sample median, $\\mathrm{MAD}(y)$ is the median absolute deviation from the median, and $\\widehat{\\rho}^{\\mathrm{S}}_1(y)$ is the lag-$1$ Spearman rank correlation between $(y_1,\\dots,y_{T-1})$ and $(y_2,\\dots,y_T)$.\n\n$2.$ Define a weighted Euclidean distance between summary vectors,\n$$\nd\\big(s(y), s(y_{\\text{obs}})\\big) = \\left\\| w \\odot \\big(s(y) - s(y_{\\text{obs}})\\big) \\right\\|_2,\n$$\nwhere $\\odot$ denotes elementwise multiplication and $w$ is the weight vector given by\n$$\nw_i = \\frac{1}{\\left|s_i\\big(y_{\\text{obs}}\\big)\\right| + c_i},\\quad \\text{with}\\quad c=(0.5,\\,0.5,\\,0.1).\n$$\n\n$3.$ Use a prior $\\pi(\\theta)$ with independent components:\n$$\n\\mu \\sim \\mathcal{N}(0,1^2),\\quad \\phi \\sim \\mathrm{Uniform}(-0.95,0.95),\\quad b \\sim \\text{Half-Normal}(\\sigma_b),\\ \\sigma_b=0.5,\n$$\nwith hard constraints $\\mu \\in [-3,3]$, $\\phi \\in [-0.95,0.95]$, and $b>0$.\n\n$4.$ Implement ABC-MCMC with a symmetric Gaussian random-walk proposal $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta,\\mathrm{diag}(\\sigma_\\mu^2,\\sigma_\\phi^2,\\sigma_b^2))$ and hard-threshold kernel $K_\\epsilon(d) = \\mathbf{1}\\{d \\le \\epsilon\\}$. At each iteration, propose $\\theta'$, simulate $y'$ from the simulator given $\\theta'$, compute $s(y')$ and $d\\big(s(y'),s(y_{\\text{obs}})\\big)$; if $d \\le \\epsilon$, accept with Metropolis-Hastings probability\n$$\n\\alpha(\\theta,\\theta')=\\min\\left\\{1,\\ \\frac{\\pi(\\theta')}{\\pi(\\theta)}\\right\\},\n$$\notherwise reject (stay at $\\theta$). Discard an initial burn-in and compute posterior summaries from the retained chain.\n\n$5.$ Generate a single observed trajectory $y_{\\text{obs}}$ using the simulator with the true parameter $\\theta^\\star=(\\mu^\\star,\\phi^\\star,b^\\star)$ and a fixed seed for reproducibility. Use $\\theta^\\star=(0.5,0.6,0.3)$ and $T=250$.\n\n$6.$ Test suite. For each test case, run ABC-MCMC and return posterior mean estimates of $(\\mu,\\phi,b)$ and the acceptance rate as a decimal. Use the following parameter sets:\n\n$\\,\\,\\,\\,$Test case $1$: summary type = \"basic\", threshold $\\epsilon=0.5$, chain length $N=2000$, burn-in $B=500$, proposal scales $(\\sigma_\\mu,\\sigma_\\phi,\\sigma_b)=(0.1,0.05,0.05)$, initial state $\\theta_0=(0.0,0.0,0.3)$, chain seed $123$.\n\n$\\,\\,\\,\\,$Test case $2$: summary type = \"basic\", threshold $\\epsilon=0.2$, chain length $N=2000$, burn-in $B=500$, proposal scales $(\\sigma_\\mu,\\sigma_\\phi,\\sigma_b)=(0.1,0.05,0.05)$, initial state $\\theta_0=(0.0,0.0,0.3)$, chain seed $124$.\n\n$\\,\\,\\,\\,$Test case $3$: summary type = \"robust\", threshold $\\epsilon=0.2$, chain length $N=2000$, burn-in $B=500$, proposal scales $(\\sigma_\\mu,\\sigma_\\phi,\\sigma_b)=(0.1,0.05,0.05)$, initial state $\\theta_0=(0.0,0.0,0.3)$, chain seed $125$.\n\nFix the observation-generation seed to $999$ so that $y_{\\text{obs}}$ is the same across all test cases.\n\nYour program should produce a single line of output containing the results for the three test cases as a comma-separated list enclosed in square brackets, where each element is itself a list of four floats $[\\widehat{\\mu},\\widehat{\\phi},\\widehat{b},\\widehat{r}]$ capturing the posterior mean estimates of $\\mu$, $\\phi$, $b$ and the acceptance rate $r$. For example, the output format must be of the form $[[x_{11},x_{12},x_{13},x_{14}],[x_{21},x_{22},x_{23},x_{24}],[x_{31},x_{32},x_{33},x_{34}]]$, with all $x_{ij}$ being decimal numbers.", "solution": "The user wants to solve an inverse problem using an Approximate Bayesian Computation Markov chain Monte Carlo (ABC-MCMC) algorithm. The problem is to infer the parameters $\\theta = (\\mu, \\phi, b)$ of a stochastic first-order autoregressive process, AR($1$), given a single observed time series $y_{\\text{obs}}$.\n\n### Step 1: Extract Givens\n- **Generative Model**: An AR($1$) process defined by the recurrence $y_t = \\mu + \\phi\\,(y_{t-1}-\\mu) + \\varepsilon_t$ for $t=2,\\dots,T$.\n  - Parameter vector: $\\theta = (\\mu,\\phi,b)$.\n  - Innovations: $\\varepsilon_t$ are drawn from a Laplace distribution, $\\varepsilon_t \\sim \\text{Laplace}(0,b)$.\n  - Initialization: $y_1$ is drawn from a normal distribution, $y_1 \\sim \\mathcal{N}(\\mu,b^2)$.\n  - Time series length: A fixed value $T$.\n- **Inference Method**: ABC-MCMC, used because the likelihood $p(y_{\\text{obs}} \\mid \\theta)$ is intractable.\n- **Summary Statistics**: Two designs are specified for a time series $y$:\n  1. **Basic**: $s_{\\text{basic}}(y) = \\big(\\bar{y},\\,\\widehat{\\mathrm{Var}}(y),\\,\\widehat{\\rho}_1(y)\\big)$, where $\\bar{y}$ is the sample mean, $\\widehat{\\mathrm{Var}}(y)$ is the unbiased sample variance, and $\\widehat{\\rho}_1(y)$ is the lag-$1$ Pearson correlation.\n  2. **Robust**: $s_{\\text{robust}}(y) = \\big(\\mathrm{med}(y),\\,\\mathrm{MAD}(y),\\,\\widehat{\\rho}^{\\mathrm{S}}_1(y)\\big)$, where $\\mathrm{med}(y)$ is the sample median, $\\mathrm{MAD}(y)$ is the median absolute deviation, and $\\widehat{\\rho}^{\\mathrm{S}}_1(y)$ is the lag-$1$ Spearman rank correlation.\n- **Distance Metric**: A weighted Euclidean distance $d\\big(s(y), s(y_{\\text{obs}})\\big) = \\left\\| w \\odot \\big(s(y) - s(y_{\\text{obs}})\\big) \\right\\|_2$.\n  - Weights are defined as $w_i = \\frac{1}{\\left|s_i\\big(y_{\\text{obs}}\\big)\\right| + c_i}$, with the constant vector $c=(0.5,\\,0.5,\\,0.1)$.\n- **Prior Distribution** $\\pi(\\theta)$:\n  - $\\mu \\sim \\mathcal{N}(0,1^2)$ with a hard constraint $\\mu \\in [-3,3]$.\n  - $\\phi \\sim \\mathrm{Uniform}(-0.95,0.95)$.\n  - $b \\sim \\text{Half-Normal}(\\sigma_b)$ with $\\sigma_b=0.5$ and a hard constraint $b>0$.\n- **ABC-MCMC Algorithm Details**:\n  - **Proposal distribution**: A symmetric Gaussian random-walk, $q(\\theta' \\mid \\theta) = \\mathcal{N}(\\theta,\\mathrm{diag}(\\sigma_\\mu^2,\\sigma_\\phi^2,\\sigma_b^2))$.\n  - **Kernel**: A hard-threshold kernel, $K_\\epsilon(d) = \\mathbf{1}\\{d \\le \\epsilon\\}$.\n  - **Acceptance probability**: If the distance $d$ for a proposal $\\theta'$ is less than or equal to $\\epsilon$, it is accepted with probability $\\alpha(\\theta,\\theta')=\\min\\left\\{1,\\ \\frac{\\pi(\\theta')}{\\pi(\\theta)}\\right\\}$. Otherwise, it is rejected.\n- **Observation Generation**: $y_{\\text{obs}}$ is generated once using the simulator.\n  - True parameters: $\\theta^\\star=(\\mu^\\star,\\phi^\\star,b^\\star)=(0.5,0.6,0.3)$.\n  - Time series length: $T=250$.\n  - Seed for generation: $999$.\n- **Test Suite**: Three test cases are defined with specific settings for summary type, $\\epsilon$, chain length $N$, burn-in $B$, proposal scales $(\\sigma_\\mu,\\sigma_\\phi,\\sigma_b)$, initial state $\\theta_0$, and MCMC chain seed.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is subjected to rigorous validation.\n- **Scientifically Grounded**: The problem is well-grounded in statistics and time series analysis. The AR($1$) model is a standard stochastic process. ABC-MCMC is a widely used and accepted algorithm for Bayesian inference with intractable likelihoods. All mathematical and statistical definitions are standard.\n- **Well-Posed**: The problem is fully specified. It provides all necessary components: the generative model, prior distributions, summary statistics, distance metric, algorithm parameters, and test cases with fixed seeds. This ensures a unique and reproducible computational result.\n- **Objective**: The problem statement is objective, using precise mathematical and algorithmic language, free of any subjective or ambiguous terminology.\n- **Consistency and Completeness**: The parameters for the priors, the model, the algorithm, and the test cases are all explicitly provided. There are no missing definitions or contradictory constraints. The initial state $\\theta_0=(0.0,0.0,0.3)$ is within the support of the prior distribution.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. It is a well-defined computational statistics problem that can be solved as specified. We will proceed to design and implement the solution.\n\n### Principle-Based Solution Design\n\nThe core of the problem is to implement an ABC-MCMC sampler to approximate the posterior distribution $\\pi(\\theta | y_{\\text{obs}})$. The fundamental relationship is Bayes' theorem:\n$$\n\\pi(\\theta \\mid y_{\\text{obs}}) \\propto p(y_{\\text{obs}} \\mid \\theta) \\pi(\\theta)\n$$\nwhere $\\pi(\\theta | y_{\\text{obs}})$ is the posterior, $p(y_{\\text{obs}} \\mid \\theta)$ is the likelihood, and $\\pi(\\theta)$ is the prior.\n\n**1. The Generative Model (Simulator)**\nThe model that generates data is a first-order autoregressive process:\n$$\ny_t = \\mu + \\phi(y_{t-1} - \\mu) + \\varepsilon_t, \\quad t=2, \\dots, T\n$$\nThe innovations $\\varepsilon_t$ are i.i.d. draws from a Laplace distribution with probability density function:\n$$\np(\\varepsilon_t | b) = \\frac{1}{2b} \\exp\\left(-\\frac{|\\varepsilon_t|}{b}\\right)\n$$\nThe process is initialized by drawing $y_1$ from a Normal distribution $y_1 \\sim \\mathcal{N}(\\mu, b^2)$, which approximates the stationary distribution's variance for $\\phi$ not close to $1$. The likelihood $p(y_{\\text{obs}} \\mid \\theta)$ involves a product of these Laplace densities, which is analytically and computationally intractable for standard MCMC methods.\n\n**2. Approximate Bayesian Computation (ABC)**\nABC methods circumvent the evaluation of the intractable likelihood. Instead of targeting $\\pi(\\theta | y_{\\text{obs}})$, we target an approximate posterior distribution defined by:\n$$\n\\pi_{\\text{ABC}}(\\theta | y_{\\text{obs}}) \\propto \\pi(\\theta) \\int_{\\mathbb{R}^T} K_\\epsilon(d(s(y), s(y_{\\text{obs}}))) p(y \\mid \\theta) \\, dy\n$$\nwhere $s(\\cdot)$ are summary statistics, $d(\\cdot, \\cdot)$ is a distance metric, $K_\\epsilon$ is a kernel function, and $\\epsilon$ is a tolerance threshold. The problem specifies a uniform kernel $K_\\epsilon(d) = \\mathbf{1}\\{d \\le \\epsilon\\}$, which simplifies the process. Sampling from this target is achieved by simulating data from the model and accepting the corresponding parameter proposal if the summary statistics of the simulated data are \"close enough\" to those of the observed data.\n\n**3. The ABC-MCMC Algorithm**\nWe use a Metropolis-Hastings algorithm to construct a Markov chain whose stationary distribution is $\\pi_{\\text{ABC}}(\\theta | y_{\\text{obs}})$. For a given state $\\theta^{(i)}$ at iteration $i$:\n1.  **Propose**: A new parameter vector $\\theta'$ is proposed from a symmetric random-walk proposal distribution $q(\\theta'|\\theta^{(i)}) = \\mathcal{N}(\\theta^{(i)}, \\Sigma_p)$, where $\\Sigma_p = \\mathrm{diag}(\\sigma_\\mu^2, \\sigma_\\phi^2, \\sigma_b^2)$.\n2.  **Simulate**: A synthetic dataset $y'$ is generated from the model using the proposed parameters $\\theta'$, i.e., $y' \\sim p(y|\\theta')$.\n3.  **Compare**: The summary statistics $s(y')$ are computed and the distance $d(s(y'), s(y_{\\text{obs}}))$ is calculated.\n4.  **Accept/Reject**:\n    - If $d(s(y'), s(y_{\\text{obs}})) > \\epsilon$, the proposal $\\theta'$ is rejected, and $\\theta^{(i+1)} = \\theta^{(i)}$.\n    - If $d(s(y'), s(y_{\\text{obs}})) \\le \\epsilon$, the proposal is accepted with the Metropolis-Hastings probability:\n      $$\n      \\alpha(\\theta^{(i)}, \\theta') = \\min\\left(1, \\frac{\\pi_{\\text{ABC}}(\\theta'|y_{\\text{obs}})}{\\pi_{\\text{ABC}}(\\theta^{(i)}|y_{\\text{obs}})} \\frac{q(\\theta^{(i)}|\\theta')}{q(\\theta'|\\theta^{(i)})}\\right)\n      $$\n      Since the proposal $q$ is symmetric and the approximate likelihood term is constant (either $1$ or $0$) for proposals that pass the $\\epsilon$ threshold, the acceptance probability simplifies to the prior ratio:\n      $$\n      \\alpha(\\theta^{(i)}, \\theta') = \\min\\left(1, \\frac{\\pi(\\theta')}{\\pi(\\theta^{(i)})}\\right)\n      $$\n      If the move is accepted, $\\theta^{(i+1)} = \\theta'$. Otherwise, it is rejected, and $\\theta^{(i+1)} = \\theta^{(i)}$.\n\n**4. Priors, Summaries, and Distance**\n- **Priors**: The joint prior $\\pi(\\theta)$ is a product of its independent components. For computational stability, we work with the log-prior: $\\log\\pi(\\theta)=\\log\\pi(\\mu)+\\log\\pi(\\phi)+\\log\\pi(b)$.\n  - $\\log\\pi(\\mu) = \\log\\left(\\mathcal{N}(\\mu|0, 1^2)\\right)$ for $\\mu \\in [-3, 3]$, and $-\\infty$ otherwise.\n  - $\\log\\pi(\\phi) = \\log\\left(\\mathrm{Uniform}(\\phi|-0.95, 0.95)\\right)$ which is a constant for $\\phi$ in its domain, and $-\\infty$ otherwise.\n  - $\\log\\pi(b) = \\log\\left(\\text{Half-Normal}(b|0.5)\\right)$ for $b>0$ and $-\\infty$ otherwise.\n- **Summary Statistics**:\n  - Basic: $s_{\\text{basic}} = (\\frac{1}{T}\\sum y_t, \\frac{1}{T-1}\\sum(y_t-\\bar{y})^2, \\text{Corr}(y_{1:T-1}, y_{2:T}))$.\n  - Robust: $s_{\\text{robust}} = (\\text{median}(y), \\text{median}(|y_i - \\text{median}(y)|), \\text{SpearmanCorr}(y_{1:T-1}, y_{2:T}))$.\n- **Distance**: The weighted Euclidean distance is $d = \\sqrt{\\sum_{i=1}^3 w_i^2 (s_i' - s_{i, \\text{obs}})^2}$, where weights $w_i = (|\\ s_{i, \\text{obs}}\\ | + c_i)^{-1}$ down-weight dimensions with large magnitudes, with $c=(0.5, 0.5, 0.1)$.\n\n**5. Implementation Plan**\nThe overall procedure is as follows:\n1.  Generate the single observed data trajectory $y_{\\text{obs}}$ of length $T=250$ using the simulator with the true parameters $\\theta^\\star=(0.5, 0.6, 0.3)$ and a fixed seed ($999$).\n2.  For each of the three test cases:\n    a. Calculate the summary statistics $s(y_{\\text{obs}})$ and the corresponding weight vector $w$. These are fixed for the duration of the MCMC run.\n    b. Initialize the MCMC chain at $\\theta_0$ with length $N$ and the specified chain seed.\n    c. Run the ABC-MCMC algorithm as described above for $N$ iterations.\n    d. Discard the first $B$ samples as burn-in.\n    e. Compute the posterior mean for each parameter $(\\mu, \\phi, b)$ by averaging the retained $N-B$ samples.\n    f. Compute the acceptance rate as the number of accepted proposals divided by the total number of proposals ($N-1$).\n3.  Collect the results (posterior means and acceptance rate) for each test case and format them as required.", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm, uniform, halfnorm, spearmanr, median_abs_deviation\n\ndef log_prior_pdf(theta):\n    \"\"\"\n    Computes the log of the prior probability density for a parameter vector theta.\n    Returns -inf if theta is outside the defined support.\n    \"\"\"\n    mu, phi, b = theta\n    # Hard constraints from the problem statement\n    if not (-3.0 <= mu <= 3.0 and -0.95 <= phi <= 0.95 and b > 0.0):\n        return -np.inf\n    \n    # Prior for mu: N(0, 1^2) truncated to [-3, 3]\n    log_p_mu = norm.logpdf(mu, loc=0.0, scale=1.0)\n    \n    # Prior for phi: Uniform(-0.95, 0.95)\n    log_p_phi = uniform.logpdf(phi, loc=-0.95, scale=1.9) # scale = upper - lower\n    \n    # Prior for b: HalfNormal(scale=0.5)\n    log_p_b = halfnorm.logpdf(b, loc=0.0, scale=0.5)\n    \n    return log_p_mu + log_p_phi + log_p_b\n\ndef ar1_simulator(theta, T, rng):\n    \"\"\"\n    Simulates a time series from the AR(1) model with Laplace innovations.\n    \"\"\"\n    mu, phi, b = theta\n    y = np.zeros(T)\n    \n    # Initialization: y_1 ~ N(mu, b^2)\n    y[0] = rng.normal(loc=mu, scale=b)\n    \n    # Innovations: eps_t ~ Laplace(0, b)\n    eps = rng.laplace(loc=0.0, scale=b, size=T - 1)\n    \n    # AR(1) recurrence relation\n    for t in range(1, T):\n        y[t] = mu + phi * (y[t-1] - mu) + eps[t-1]\n        \n    return y\n\ndef calculate_summaries(y, summary_type):\n    \"\"\"\n    Calculates summary statistics for a given time series.\n    \"\"\"\n    if summary_type == \"basic\":\n        s_mean = np.mean(y)\n        # Unbiased sample variance (ddof=1)\n        s_var = np.var(y, ddof=1)\n        # Lag-1 Pearson autocorrelation\n        s_rho1 = np.corrcoef(y[:-1], y[1:])[0, 1]\n        return np.array([s_mean, s_var, s_rho1])\n    elif summary_type == \"robust\":\n        s_med = np.median(y)\n        # Median Absolute Deviation (un-normalized as per problem context)\n        s_mad = median_abs_deviation(y, scale=1.0)\n        # Lag-1 Spearman rank correlation\n        s_spearman = spearmanr(y[:-1], y[1:]).correlation\n        return np.array([s_med, s_mad, s_spearman])\n    else:\n        raise ValueError(f\"Invalid summary type: {summary_type}\")\n\ndef calculate_distance(s_sim, s_obs, w):\n    \"\"\"\n    Computes the weighted Euclidean distance between summary vectors.\n    \"\"\"\n    return np.linalg.norm(w * (s_sim - s_obs))\n\ndef abc_mcmc(y_obs, summary_type, epsilon, N, B, proposal_scales, theta0, chain_seed):\n    \"\"\"\n    Performs ABC-MCMC to infer parameters of the AR(1) model.\n    \"\"\"\n    T = len(y_obs)\n    rng = np.random.default_rng(chain_seed)\n\n    # Calculate observed summaries and weights (these are fixed)\n    s_obs = calculate_summaries(y_obs, summary_type)\n    c = np.array([0.5, 0.5, 0.1])\n    w = 1.0 / (np.abs(s_obs) + c)\n\n    # Initialize the Markov chain\n    thetas = np.zeros((N, 3))\n    thetas[0, :] = theta0\n    \n    accept_count = 0\n    \n    current_log_prior = log_prior_pdf(thetas[0, :])\n    if np.isneginf(current_log_prior):\n        raise ValueError(\"Initial state theta0 is outside the prior support.\")\n\n    # MCMC sampling loop\n    for i in range(1, N):\n        current_theta = thetas[i-1, :]\n        \n        # Propose a new state using a symmetric Gaussian random-walk\n        proposal_delta = rng.normal(loc=0.0, scale=proposal_scales)\n        theta_prime = current_theta + proposal_delta\n        \n        prime_log_prior = log_prior_pdf(theta_prime)\n        \n        # Immediately reject if the proposal is outside the prior's support\n        if np.isneginf(prime_log_prior):\n            thetas[i, :] = current_theta\n            continue\n\n        # Simulate data from the model with the proposed parameters\n        y_prime = ar1_simulator(theta_prime, T, rng)\n        \n        # Calculate summary statistics and distance\n        s_prime = calculate_summaries(y_prime, summary_type)\n        dist = calculate_distance(s_prime, s_obs, w)\n        \n        # ABC's hard threshold kernel\n        if dist <= epsilon:\n            # Metropolis-Hastings acceptance step (on prior ratio)\n            log_alpha = prime_log_prior - current_log_prior\n            if np.log(rng.uniform()) < log_alpha:\n                # Accept the proposal\n                thetas[i, :] = theta_prime\n                current_log_prior = prime_log_prior\n                accept_count += 1\n            else:\n                # Reject (MH step)\n                thetas[i, :] = current_theta\n        else:\n            # Reject (distance is too large)\n            thetas[i, :] = current_theta\n            \n    # Post-processing\n    posterior_samples = thetas[B:]\n    posterior_means = np.mean(posterior_samples, axis=0)\n    acceptance_rate = accept_count / (N - 1)\n    \n    return list(posterior_means) + [acceptance_rate]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Parameters for generating the observed data\n    theta_star = (0.5, 0.6, 0.3)\n    T = 250\n    seed_obs = 999\n    \n    # Generate the single observed trajectory (y_obs)\n    rng_obs = np.random.default_rng(seed_obs)\n    y_obs = ar1_simulator(theta_star, T, rng_obs)\n    \n    # Test cases as defined in the problem\n    test_cases = [\n        {\"summary_type\": \"basic\", \"epsilon\": 0.5, \"N\": 2000, \"B\": 500, \n         \"proposal_scales\": (0.1, 0.05, 0.05), \"theta0\": (0.0, 0.0, 0.3), \"chain_seed\": 123},\n        {\"summary_type\": \"basic\", \"epsilon\": 0.2, \"N\": 2000, \"B\": 500, \n         \"proposal_scales\": (0.1, 0.05, 0.05), \"theta0\": (0.0, 0.0, 0.3), \"chain_seed\": 124},\n        {\"summary_type\": \"robust\", \"epsilon\": 0.2, \"N\": 2000, \"B\": 500, \n         \"proposal_scales\": (0.1, 0.05, 0.05), \"theta0\": (0.0, 0.0, 0.3), \"chain_seed\": 125},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = abc_mcmc(y_obs=y_obs, **case)\n        results.append(result)\n    \n    # Format the output exactly as required\n    print(f\"[{','.join(str(res) for res in results)}]\")\n\nsolve()\n```", "id": "3400280"}, {"introduction": "Generating a long Markov chain is not enough; we must also assess its statistical efficiency to ensure our posterior estimates are reliable. This final practice focuses on the crucial post-processing step of analyzing the MCMC output. By deriving the integrated autocorrelation time, $\\tau_{\\mathrm{int}}$, from fundamental principles, you will learn how to quantify the correlation between samples and determine the effective sample size of your chain—an essential skill for any rigorous application of MCMC [@problem_id:3400386].", "problem": "Consider a linear Gaussian inverse problem with unknown parameter field $u \\in \\mathbb{R}^{d}$, data $y \\in \\mathbb{R}^{m}$, forward operator $A \\in \\mathbb{R}^{m \\times d}$, and additive noise $y = A u + \\eta$, where $\\eta \\sim \\mathcal{N}(0, \\Gamma_{\\eta})$ and $u \\sim \\mathcal{N}(m_{0}, \\Gamma_{0})$. A Markov chain Monte Carlo (MCMC) method is used to sample from the posterior distribution of $u$ given $y$. Consider a scalar summary $f(u)$, such as a linear functional $f(u) = \\ell^{\\top} u$ with $\\ell \\in \\mathbb{R}^{d}$. Assume the Markov chain for $f(u)$ is strictly stationary and ergodic and, for the purpose of analysis, can be approximated by a Gaussian autoregressive process of order one, $\\text{AR}(1)$, with autoregressive parameter $\\phi \\in (-1,1)$:\n$$\nx_{n} = \\phi \\, x_{n-1} + \\epsilon_{n}, \\quad \\epsilon_{n} \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^{2}), \\quad n \\geq 1,\n$$\nwhere $x_{n} := f(u_{n})$ denotes the scalar summary along the Markov chain in stationarity.\n\nYou are told that for the chain under consideration, the autoregressive coefficient is $\\phi = 0.75$ and the stationary variance $\\mathrm{Var}(x_{n}) = \\sigma_{x}^{2}$ is finite and positive. Starting from the fundamental definitions of autocovariance and variance of the sample mean of a correlated stationary sequence, and without assuming any target formulas:\n\n1. Define the lag-$k$ autocorrelation function for the scalar summary $f(u)$ along the chain, and, under the $\\text{AR}(1)$ approximation, derive the exact expression for the lag-$k$ autocorrelation in terms of $\\phi$.\n\n2. Starting from the variance of the sample mean $\\bar{x}_{N} = \\frac{1}{N} \\sum_{n=1}^{N} x_{n}$ for a stationary correlated sequence, derive the concept of an integrated autocorrelation time, denoted by $\\tau_{\\mathrm{int}}$, such that the variance of $\\bar{x}_{N}$ can be written as $\\mathrm{Var}(\\bar{x}_{N}) \\approx \\sigma_{x}^{2} \\, \\tau_{\\mathrm{int}} / N$ for large $N$, and express $\\tau_{\\mathrm{int}}$ in terms of the lag-$k$ autocorrelations.\n\n3. Propose a finite-sample, bias-corrected estimator for $\\tau_{\\mathrm{int}}$ based on the unbiased sample autocovariances\n$$\n\\hat{\\gamma}_{k} := \\frac{1}{N-k} \\sum_{n=1}^{N-k} \\big(x_{n} - \\bar{x}_{N}\\big)\\big(x_{n+k} - \\bar{x}_{N}\\big), \\quad k \\geq 0,\n$$\nthe sample autocorrelations $\\hat{\\rho}_{k} := \\hat{\\gamma}_{k}/\\hat{\\gamma}_{0}$, and a compactly supported window $w_{k}$, for example the Bartlett window $w_{k} := 1 - \\frac{k}{m+1}$ for $0 \\leq k \\leq m$ and $w_{k} := 0$ for $k > m$, where $m$ is a truncation lag chosen as a function of $N$. Derive the corresponding windowed estimator $\\hat{\\tau}_{\\mathrm{int}}^{\\mathrm{win}}$ and explain qualitatively how this reduces finite-sample bias relative to the naive unwindowed sum.\n\nFinally, for the given $\\phi = 0.75$, compute the exact value of $\\tau_{\\mathrm{int}}$ implied by the $\\text{AR}(1)$ approximation. Your final answer must be a single real-valued number, and no rounding is required. No units should be used.", "solution": "The problem is validated as self-contained, scientifically grounded, and well-posed. It presents a standard, albeit detailed, exercise in the statistical analysis of Markov chain Monte Carlo (MCMC) output, which is central to a rigorous application of MCMC for inverse problems. We proceed with the solution, which is broken down into the three requested derivations followed by the final numerical computation.\n\nLet $\\{x_n\\}_{n=1}^N$ be the sequence of the scalar summary $f(u_n)$ from a stationary MCMC run. The process is assumed to be strictly stationary and ergodic, with mean $E[x_n] = \\mu$ and finite variance $\\mathrm{Var}(x_n) = \\sigma_x^2$. For the purpose of covariance and correlation calculations, we can analyze the centered process $x'_n = x_n - \\mu$, which has zero mean, without loss of generality. Hereafter, we will assume $\\mu=0$ to simplify notation.\n\n**1. Lag-$k$ Autocorrelation for an AR(1) Process**\n\nThe lag-$k$ autocovariance function, $\\gamma_k$, of a stationary process $\\{x_n\\}$ is defined as the covariance between observations separated by $k$ time steps:\n$$\n\\gamma_k := \\mathrm{Cov}(x_n, x_{n+k}) = E[x_n x_{n+k}]\n$$\nThe lag-$k$ autocorrelation function, $\\rho_k$, is the normalized autocovariance:\n$$\n\\rho_k := \\frac{\\gamma_k}{\\gamma_0} = \\frac{\\mathrm{Cov}(x_n, x_{n+k})}{\\mathrm{Var}(x_n)}\n$$\nwhere $\\gamma_0 = \\mathrm{Var}(x_n) = \\sigma_x^2$.\n\nWe are given that the process is approximated by a Gaussian autoregressive process of order one, AR($1$):\n$$\nx_n = \\phi x_{n-1} + \\epsilon_n, \\quad \\epsilon_n \\sim \\mathcal{N}(0, \\sigma_{\\epsilon}^2)\n$$\nwhere the noise terms $\\epsilon_n$ are independent and identically distributed, and are also independent of past values of the process, i.e., $E[x_{n-j} \\epsilon_n] = 0$ for $j>0$.\n\nTo find $\\gamma_k$, we multiply the AR($1$) equation for $x_{n+k}$ by $x_n$ and take the expectation:\n$$\nE[x_n x_{n+k}] = E[x_n (\\phi x_{n+k-1} + \\epsilon_{n+k})] = \\phi E[x_n x_{n+k-1}] + E[x_n \\epsilon_{n+k}]\n$$\nFor $k > 0$, $x_n$ is a function of noise terms up to time $n$, so it is independent of $\\epsilon_{n+k}$. Thus, $E[x_n \\epsilon_{n+k}] = E[x_n]E[\\epsilon_{n+k}] = 0$. This yields the Yule-Walker equation for an AR($1$) process:\n$$\n\\gamma_k = \\phi \\gamma_{k-1}, \\quad \\text{for } k \\geq 1\n$$\nThis is a recursive relationship. Starting with $k=1$, we get $\\gamma_1 = \\phi \\gamma_0$. For $k=2$, $\\gamma_2 = \\phi \\gamma_1 = \\phi^2 \\gamma_0$. By induction, the general solution is:\n$$\n\\gamma_k = \\phi^k \\gamma_0, \\quad \\text{for } k \\geq 0\n$$\nDividing by $\\gamma_0$, we obtain the lag-$k$ autocorrelation:\n$$\n\\rho_k = \\frac{\\gamma_k}{\\gamma_0} = \\phi^k\n$$\n\n**2. Derivation of the Integrated Autocorrelation Time**\n\nThe sample mean of the sequence is $\\bar{x}_N = \\frac{1}{N} \\sum_{n=1}^{N} x_n$. We start by deriving its variance:\n$$\n\\mathrm{Var}(\\bar{x}_N) = \\mathrm{Var}\\left(\\frac{1}{N} \\sum_{n=1}^{N} x_n\\right) = \\frac{1}{N^2} \\mathrm{Var}\\left(\\sum_{n=1}^{N} x_n\\right)\n$$\nUsing the linearity of the covariance operator:\n$$\n\\mathrm{Var}(\\bar{x}_N) = \\frac{1}{N^2} \\sum_{n=1}^{N} \\sum_{m=1}^{N} \\mathrm{Cov}(x_n, x_m)\n$$\nDue to stationarity, $\\mathrm{Cov}(x_n, x_m) = \\gamma_{|n-m|}$. We can rewrite the double summation by grouping terms with the same lag $k = |n-m|$:\n$$\n\\sum_{n=1}^{N} \\sum_{m=1}^{N} \\gamma_{|n-m|} = N\\gamma_0 + \\sum_{k=1}^{N-1} 2(N-k) \\gamma_k\n$$\nThe factor $2(N-k)$ is the number of pairs $(n,m)$ in the $N \\times N$ grid of indices such that $|n-m|=k$. Substituting this back into the variance expression:\n$$\n\\mathrm{Var}(\\bar{x}_N) = \\frac{1}{N^2} \\left[ N\\gamma_0 + 2 \\sum_{k=1}^{N-1} (N-k) \\gamma_k \\right]\n$$\nFactoring out $N\\gamma_0$:\n$$\n\\mathrm{Var}(\\bar{x}_N) = \\frac{\\gamma_0}{N} \\left[ 1 + 2 \\sum_{k=1}^{N-1} \\frac{N-k}{N} \\frac{\\gamma_k}{\\gamma_0} \\right] = \\frac{\\sigma_x^2}{N} \\left[ 1 + 2 \\sum_{k=1}^{N-1} \\left(1 - \\frac{k}{N}\\right) \\rho_k \\right]\n$$\nFor a large number of samples $N$, and for a process where the autocorrelations $\\rho_k$ decay sufficiently quickly, the summation can be approximated. For $k \\ll N$, the term $(1 - k/N) \\approx 1$. If the sum converges, we can extend the limit to infinity:\n$$\n\\mathrm{Var}(\\bar{x}_N) \\approx \\frac{\\sigma_x^2}{N} \\left( 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k \\right) \\quad \\text{for large } N\n$$\nThe integrated autocorrelation time, $\\tau_{\\mathrm{int}}$, is defined such that $\\mathrm{Var}(\\bar{x}_N) \\approx \\frac{\\sigma_x^2 \\tau_{\\mathrm{int}}}{N}$. Comparing this definition with our derived approximation, we identify $\\tau_{\\mathrm{int}}$ as:\n$$\n\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k\n$$\nThis quantity relates the variance of the sample mean of a correlated sequence to the variance of the sample mean of an i.i.d. sequence of the same length. The effective sample size is often defined as $N_{\\mathrm{eff}} = N/\\tau_{\\mathrm{int}}$.\n\n**3. Finite-Sample Windowed Estimator for $\\tau_{\\mathrm{int}}$**\n\nIn practice, $\\tau_{\\mathrm{int}}$ must be estimated from a finite sample of length $N$. A naive estimator would truncate the infinite sum and plug in sample autocorrelations: $\\hat{\\tau}_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{m} \\hat{\\rho}_k$. This estimator suffers from high variance because sample autocorrelations $\\hat{\\rho}_k$ are themselves noisy estimates, especially for large $k$. The sum can be dominated by this noise, leading to poor and even negative estimates of $\\tau_{\\mathrm{int}}$.\n\nA better approach is to use a windowed, bias-corrected estimator. We are given the unbiased sample autocovariance estimator:\n$$\n\\hat{\\gamma}_{k} := \\frac{1}{N-k} \\sum_{n=1}^{N-k} \\big(x_{n} - \\bar{x}_{N}\\big)\\big(x_{n+k} - \\bar{x}_{N}\\big)\n$$\nThe corresponding sample autocorrelation is $\\hat{\\rho}_{k} := \\hat{\\gamma}_{k} / \\hat{\\gamma}_{0}$. A windowed estimator for $\\tau_{\\mathrm{int}}$ is constructed by weighting the sample autocorrelations with a window function $w_k$ that decays to zero. This reduces the contribution of the noisy, high-lag terms.\nThe general form of the windowed estimator is:\n$$\n\\hat{\\tau}_{\\mathrm{int}}^{\\mathrm{win}} = 1 + 2 \\sum_{k=1}^{N-1} w_k \\hat{\\rho}_k\n$$\nUsing the specified Bartlett window, $w_k = 1 - \\frac{k}{m+1}$ for $0 \\leq k \\leq m$ and $w_k=0$ for $k > m$, the estimator becomes:\n$$\n\\hat{\\tau}_{\\mathrm{int}}^{\\mathrm{win}} = 1 + 2 \\sum_{k=1}^{m} \\left(1 - \\frac{k}{m+1}\\right) \\hat{\\rho}_k\n$$\nHere, $m$ is a truncation lag, chosen such that $m \\ll N$.\n\nThe windowing procedure reduces the finite-sample bias and variance of the estimator. The naive summation $\\sum_{k=1}^m \\hat{\\rho}_k$ has a positive bias because the noise in the $\\hat{\\rho}_k$ terms does not average to zero, and can accumulate. By down-weighting the $\\hat{\\rho}_k$ for larger $k$, which are the most uncertain, the window function systematically reduces the variance of the final estimate. While this introduces a deterministic bias (by altering the weights from unity), it often leads to a substantial reduction in the mean squared error of the estimator. The Bartlett window, in particular, corresponds to a specific method of spectral density estimation and guarantees a non-negative estimate for $\\tau_{\\mathrm{int}}$, which is a physically necessary property.\n\n**Final Calculation**\n\nWe need to compute the exact value of $\\tau_{\\mathrm{int}}$ for an AR($1$) process with $\\phi = 0.75$.\nFrom Part 1, we have $\\rho_k = \\phi^k$. From Part 2, the expression for $\\tau_{\\mathrm{int}}$ is:\n$$\n\\tau_{\\mathrm{int}} = 1 + 2 \\sum_{k=1}^{\\infty} \\rho_k = 1 + 2 \\sum_{k=1}^{\\infty} \\phi^k\n$$\nThe sum is an infinite geometric series. Since $|\\phi| = 0.75 < 1$, the series converges to:\n$$\n\\sum_{k=1}^{\\infty} \\phi^k = \\frac{\\phi}{1-\\phi}\n$$\nSubstituting this into the expression for $\\tau_{\\mathrm{int}}$:\n$$\n\\tau_{\\mathrm{int}} = 1 + 2 \\left( \\frac{\\phi}{1-\\phi} \\right) = \\frac{1-\\phi}{1-\\phi} + \\frac{2\\phi}{1-\\phi} = \\frac{1-\\phi+2\\phi}{1-\\phi} = \\frac{1+\\phi}{1-\\phi}\n$$\nNow, we substitute the given value $\\phi = 0.75$:\n$$\n\\tau_{\\mathrm{int}} = \\frac{1+0.75}{1-0.75} = \\frac{1.75}{0.25} = \\frac{7/4}{1/4} = 7\n$$\nThe exact integrated autocorrelation time for this process is $7$.", "answer": "$$\n\\boxed{7}\n$$", "id": "3400386"}]}