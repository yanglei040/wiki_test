{"hands_on_practices": [{"introduction": "The directional derivative test, often called a Taylor test, is the single most important sanity check for any gradient-based optimization code. Before you can trust the results of an inversion or training process, you must verify that the computed gradient is correct. This practice [@problem_id:3364135] challenges you to reason from first principles about how this test works, analyzing the fundamental trade-off between numerical truncation error and floating-point round-off error, and how this interplay affects your ability to debug an adjoint implementation.", "problem": "Consider an inverse problem in which a parameter vector $p \\in \\mathbb{R}^n$ is estimated by minimizing a differentiable cost functional $J(p)$ that depends on the solution of a numerical model. An adjoint method is implemented to compute the gradient $\\nabla J(p)$ with respect to $p$. To assess the correctness of the adjoint-based gradient, a directional derivative test is performed by selecting a direction $\\delta p \\in \\mathbb{R}^n$ and comparing the inner product $\\nabla J(p) \\cdot \\delta p$ against a finite difference approximation of the directional derivative of $J$ along $\\delta p$.\n\nUsing the definition of the directional derivative and the Taylor expansion of $J$ about $p$, reason from first principles about the expected behavior of such a test. In particular, analyze how the choice of the step size $\\epsilon > 0$ affects truncation error and floating-point round-off error, and explain how these error mechanisms influence accuracy and the ability to detect adjoint implementation errors.\n\nWhich of the following statements about the directional derivative test and the role of $\\epsilon$ are correct? Select all that apply.\n\nA. If $J$ is twice continuously differentiable, the mismatch\n$$E_{\\mathrm{fwd}}(\\epsilon) = \\left\\lvert \\nabla J(p)\\cdot \\delta p - \\frac{J(p+\\epsilon\\,\\delta p)-J(p)}{\\epsilon} \\right\\rvert$$\ndecreases proportionally to $\\epsilon$ as $\\epsilon \\to 0$ until floating-point round-off dominates, so a log-log plot of $E_{\\mathrm{fwd}}(\\epsilon)$ versus $\\epsilon$ exhibits slope $1$ in the truncation-dominated regime. Using the central difference\n$$\\frac{J(p+\\epsilon\\,\\delta p)-J(p-\\epsilon\\,\\delta p)}{2\\epsilon}$$\ninstead yields a truncation-dominated slope of $2$.\n\nB. If the numerical evaluation of $J$ incurs floating-point round-off on the order of the machine precision $\\varepsilon_{\\mathrm{mach}}$, the round-off component of the finite difference error scales like $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$, so choosing $\\epsilon$ too small causes the test error to grow due to catastrophic cancellation.\n\nC. Balancing truncation error against round-off error yields an optimal step size of $\\epsilon \\sim \\sqrt{\\varepsilon_{\\mathrm{mach}}}$ (after appropriate scaling to the magnitudes of $p$ and $\\delta p$) for the forward difference, whereas for the central difference the optimal step size is $\\epsilon \\sim \\varepsilon_{\\mathrm{mach}}^{1/3}$.\n\nD. A sign error in the adjoint implementation (i.e., returning $-\\nabla J(p)$) will be invisible to the central difference test but detectable by the forward difference test.\n\nE. For robustness, $\\delta p$ should be scaled so that $\\lVert \\delta p \\rVert = 1$ in the chosen parameter norm and multiple random directions should be tested; if the adjoint is correct, the mismatch exhibits the expected $\\mathcal{O}(\\epsilon)$ or $\\mathcal{O}(\\epsilon^2)$ decay with $\\epsilon$ in the truncation-dominated regime, whereas a lack of such decay across directions suggests an adjoint error.\n\nF. If the model solver employs adaptive tolerances that vary with $p$ and with the perturbation $\\epsilon\\,\\delta p$, the directional derivative test remains valid because solver tolerances do not affect differentiability and therefore cannot distort the error behavior.\n\nG. Using the central difference eliminates truncation error completely, so the only remaining error source is round-off; therefore, smaller $\\epsilon$ always improves the accuracy of the test.\n\nH. If $J$ contains nondifferentiable components with respect to $p$, such as exact thresholding or a pointwise maximum, the directional derivative test may not exhibit the expected truncation-rate behavior with $\\epsilon$; in such cases, smoothing or reformulation is required for a reliable adjoint test.", "solution": "The problem statement is a valid and well-posed question in the field of numerical optimization and inverse problems. It asks for a first-principles analysis of the directional derivative test, a standard method for verifying the implementation of an adjoint-based gradient computation.\n\n### **Problem Validation**\n\n**Step 1: Extract Givens**\n- The parameter to be estimated is a vector $p \\in \\mathbb{R}^n$.\n- The objective is to minimize a differentiable cost functional $J(p)$.\n- The gradient $\\nabla J(p)$ is computed using an adjoint method.\n- A directional derivative test is used for verification.\n- A direction vector is chosen: $\\delta p \\in \\mathbb{R}^n$.\n- The test compares the inner product $\\nabla J(p) \\cdot \\delta p$ with a finite difference approximation of the directional derivative of $J$ along $\\delta p$.\n- The finite difference step size is $\\epsilon > 0$.\n- The task is to analyze the expected behavior of this test, focusing on the roles of truncation error and round-off error as functions of $\\epsilon$.\n\n**Step 2: Validate Using Extracted Givens**\nThe problem is scientifically grounded, well-posed, and objective. It describes a fundamental sanity check for gradient-based optimization codes, known as a Taylor test or finite difference check. The concepts of Taylor expansion, directional derivatives, truncation error, and floating-point round-off error are cornerstone principles of calculus and numerical analysis. The setup is self-contained and free of contradictions or ambiguities.\n\n**Step 3: Verdict and Action**\nThe problem is valid. We will proceed with the derivation and analysis.\n\n### **First-Principles Derivation**\n\nThe core of the analysis rests on Taylor's theorem. The directional derivative of a differentiable functional $J(p)$ at a point $p$ in the direction $\\delta p$ is defined as:\n$$ D_{\\delta p}J(p) = \\lim_{\\epsilon \\to 0} \\frac{J(p+\\epsilon\\,\\delta p) - J(p)}{\\epsilon} $$\nFor a differentiable functional, this is equivalent to the inner product of the gradient and the direction vector:\n$$ D_{\\delta p}J(p) = \\nabla J(p) \\cdot \\delta p $$\nThe adjoint method provides a computed value for $\\nabla J(p)$, and thus for $\\nabla J(p) \\cdot \\delta p$. The directional derivative test validates this computed value against a finite difference approximation of the derivative.\n\nLet us analyze the two most common finite difference schemes. We assume $J$ is at least three times continuously differentiable ($C^3$) for this analysis.\n\n**1. Forward Difference Approximation:**\nThe approximation is given by:\n$$ D_{\\mathrm{fwd}}(\\epsilon) = \\frac{J(p+\\epsilon\\,\\delta p) - J(p)}{\\epsilon} $$\nTo analyze the error, we use the Taylor expansion of $J(p+\\epsilon\\,\\delta p)$ around $p$:\n$$ J(p+\\epsilon\\,\\delta p) = J(p) + \\epsilon (\\nabla J(p) \\cdot \\delta p) + \\frac{\\epsilon^2}{2} (\\delta p^T H(p) \\delta p) + \\mathcal{O}(\\epsilon^3) $$\nwhere $H(p)$ is the Hessian matrix of $J$ at $p$. Rearranging and dividing by $\\epsilon$ gives:\n$$ \\frac{J(p+\\epsilon\\,\\delta p) - J(p)}{\\epsilon} = \\nabla J(p) \\cdot \\delta p + \\frac{\\epsilon}{2} (\\delta p^T H(p) \\delta p) + \\mathcal{O}(\\epsilon^2) $$\nThe mismatch defined in option A is the absolute difference between the adjoint-based result and this approximation. If the adjoint is correct, the mismatch is purely the approximation error:\n$$ E_{\\mathrm{fwd}}(\\epsilon) = \\left\\lvert \\nabla J(p)\\cdot \\delta p - D_{\\mathrm{fwd}}(\\epsilon) \\right\\rvert = \\left\\lvert -\\frac{\\epsilon}{2} (\\delta p^T H(p) \\delta p) - \\mathcal{O}(\\epsilon^2) \\right\\rvert $$\nThis is the **truncation error**, and it is of order $\\mathcal{O}(\\epsilon)$.\n\n**2. Central Difference Approximation:**\nThe approximation is given by:\n$$ D_{\\mathrm{cen}}(\\epsilon) = \\frac{J(p+\\epsilon\\,\\delta p) - J(p-\\epsilon\\,\\delta p)}{2\\epsilon} $$\nTo analyze this, we need the Taylor expansions for both $J(p+\\epsilon\\,\\delta p)$ and $J(p-\\epsilon\\,\\delta p)$:\n$$ J(p+\\epsilon\\,\\delta p) = J(p) + \\epsilon (\\nabla J \\cdot \\delta p) + \\frac{\\epsilon^2}{2} (\\delta p^T H \\delta p) + \\frac{\\epsilon^3}{6} T(p)(\\delta p, \\delta p, \\delta p) + \\mathcal{O}(\\epsilon^4) $$\n$$ J(p-\\epsilon\\,\\delta p) = J(p) - \\epsilon (\\nabla J \\cdot \\delta p) + \\frac{\\epsilon^2}{2} (\\delta p^T H \\delta p) - \\frac{\\epsilon^3}{6} T(p)(\\delta p, \\delta p, \\delta p) + \\mathcal{O}(\\epsilon^4) $$\nwhere $T(p)$ represents the third-order tensor of derivatives. Subtracting the second from the first:\n$$ J(p+\\epsilon\\,\\delta p) - J(p-\\epsilon\\,\\delta p) = 2\\epsilon (\\nabla J \\cdot \\delta p) + \\frac{\\epsilon^3}{3} T(p)(\\delta p, \\delta p, \\delta p) + \\mathcal{O}(\\epsilon^5) $$\nDividing by $2\\epsilon$ gives:\n$$ \\frac{J(p+\\epsilon\\,\\delta p) - J(p-\\epsilon\\,\\delta p)}{2\\epsilon} = \\nabla J(p) \\cdot \\delta p + \\frac{\\epsilon^2}{6} T(p)(\\delta p, \\delta p, \\delta p) + \\mathcal{O}(\\epsilon^4) $$\nThe **truncation error** for the central difference is therefore of order $\\mathcal{O}(\\epsilon^2)$.\n\n**3. Round-off Error:**\nNumerical evaluation of $J(p)$ using floating-point arithmetic introduces an error. Let $\\tilde{J}(p)$ be the computed value. The error is typically on the order of machine precision, $\\varepsilon_{\\mathrm{mach}}$, times the magnitude of the function value. Thus, $\\tilde{J}(p) \\approx J(p) + \\mathcal{O}(\\varepsilon_{\\mathrm{mach}})$.\nFor the forward difference, the error in the numerator is $\\tilde{J}(p+\\epsilon\\,\\delta p) - \\tilde{J}(p)$. As $\\epsilon \\to 0$, these two values become very close. The subtraction of nearly equal numbers results in a loss of significant digits, an effect known as catastrophic cancellation. The resulting error in the numerator is dominated by the floating-point errors, which are of magnitude $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}})$. Propagating this through the division by $\\epsilon$, the round-off error contribution to the total error is:\n$$ E_{\\mathrm{round}}(\\epsilon) \\sim \\frac{\\mathcal{O}(\\varepsilon_{\\mathrm{mach}})}{\\epsilon} $$\nThis analysis holds for both forward and central differences.\n\n**4. Optimal Step Size:**\nThe total error $E(\\epsilon)$ is the sum of the truncation and round-off errors.\n- For forward differences: $E_{\\mathrm{fwd}}(\\epsilon) \\approx C_1 \\epsilon + C_2 \\frac{\\varepsilon_{\\mathrm{mach}}}{\\epsilon}$. Minimizing this with respect to $\\epsilon$ yields $C_1 \\approx C_2 \\varepsilon_{\\mathrm{mach}} / \\epsilon^2$, which implies $\\epsilon_{\\mathrm{opt}} \\sim \\sqrt{\\varepsilon_{\\mathrm{mach}}}$.\n- For central differences: $E_{\\mathrm{cen}}(\\epsilon) \\approx C_3 \\epsilon^2 + C_4 \\frac{\\varepsilon_{\\mathrm{mach}}}{\\epsilon}$. Minimizing this yields $2C_3\\epsilon \\approx C_4 \\varepsilon_{\\mathrm{mach}} / \\epsilon^2$, which implies $\\epsilon_{\\mathrm{opt}} \\sim \\varepsilon_{\\mathrm{mach}}^{1/3}$.\n\n### **Option-by-Option Analysis**\n\n**A.** If $J$ is twice continuously differentiable, the mismatch $E_{\\mathrm{fwd}}(\\epsilon) = \\left\\lvert \\nabla J(p)\\cdot \\delta p - \\frac{J(p+\\epsilon\\,\\delta p)-J(p)}{\\epsilon} \\right\\rvert$ decreases proportionally to $\\epsilon$ as $\\epsilon \\to 0$ until floating-point round-off dominates, so a log-log plot of $E_{\\mathrm{fwd}}(\\epsilon)$ versus $\\epsilon$ exhibits slope $1$ in the truncation-dominated regime. Using the central difference instead yields a truncation-dominated slope of $2$.\n- **Analysis:** Our first-principles derivation shows that the truncation error for the forward difference is $\\mathcal{O}(\\epsilon)$, which corresponds to a slope of $1$ on a log-log plot ($\\log E \\approx \\log C + 1 \\cdot \\log \\epsilon$). The derivation also shows that for the central difference, the truncation error is $\\mathcal{O}(\\epsilon^2)$, corresponding to a slope of $2$ ($\\log E \\approx \\log C' + 2 \\cdot \\log \\epsilon$). This statement is entirely consistent with the derivation.\n- **Verdict:** **Correct**.\n\n**B.** If the numerical evaluation of $J$ incurs floating-point round-off on the order of the machine precision $\\varepsilon_{\\mathrm{mach}}$, the round-off component of the finite difference error scales like $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$, so choosing $\\epsilon$ too small causes the test error to grow due to catastrophic cancellation.\n- **Analysis:** Our derivation of the round-off error confirms this behavior. The subtraction of nearly equal numbers $J(p+\\epsilon\\delta p)$ and $J(p)$ or $J(p-\\epsilon\\delta p)$ leads to catastrophic cancellation, causing the round-off error in the numerator to be roughly constant at $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}})$. When divided by $\\epsilon$, this yields an error contribution that scales as $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$ and grows without bound as $\\epsilon \\to 0$.\n- **Verdict:** **Correct**.\n\n**C.** Balancing truncation error against round-off error yields an optimal step size of $\\epsilon \\sim \\sqrt{\\varepsilon_{\\mathrm{mach}}}$ (after appropriate scaling to the magnitudes of $p$ and $\\delta p$) for the forward difference, whereas for the central difference the optimal step size is $\\epsilon \\sim \\varepsilon_{\\mathrm{mach}}^{1/3}$.\n- **Analysis:** Our analysis of the optimal step size by balancing the competing error terms confirms these dependencies. For the forward difference, balancing $\\mathcal{O}(\\epsilon)$ against $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$ gives $\\epsilon_{\\mathrm{opt}} \\propto \\varepsilon_{\\mathrm{mach}}^{1/2}$. For the central difference, balancing $\\mathcal{O}(\\epsilon^2)$ against $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$ gives $\\epsilon_{\\mathrm{opt}} \\propto \\varepsilon_{\\mathrm{mach}}^{1/3}$. The scaling note is also appropriate.\n- **Verdict:** **Correct**.\n\n**D.** A sign error in the adjoint implementation (i.e., returning $-\\nabla J(p)$) will be invisible to the central difference test but detectable by the forward difference test.\n- **Analysis:** A sign error means the computed quantity is $-\\nabla J(p) \\cdot \\delta p$. The test compares this to the finite difference approximation, which approximates the true value, $+\\nabla J(p) \\cdot \\delta p$. The mismatch for the central difference test would be $|(-\\nabla J \\cdot \\delta p) - (\\nabla J \\cdot \\delta p + \\mathcal{O}(\\epsilon^2))| \\approx | -2 \\nabla J \\cdot \\delta p |$. This is a large, $\\mathcal{O}(1)$ error that does not vanish as $\\epsilon \\to 0$. The same holds for the forward difference. A sign error is one of the most glaring errors and is easily detected by both methods. The statement is false.\n- **Verdict:** **Incorrect**.\n\n**E.** For robustness, $\\delta p$ should be scaled so that $\\lVert \\delta p \\rVert = 1$ in the chosen parameter norm and multiple random directions should be tested; if the adjoint is correct, the mismatch exhibits the expected $\\mathcal{O}(\\epsilon)$ or $\\mathcal{O}(\\epsilon^2)$ decay with $\\epsilon$ in the truncation-dominated regime, whereas a lack of such decay across directions suggests an adjoint error.\n- **Analysis:** This statement describes standard best practices for conducting a directional derivative test. Scaling $\\delta p$ ensures the magnitude of the perturbation is controlled. Testing multiple random directions is crucial because an error in the gradient computation might be orthogonal to a single, chosen $\\delta p$, thus being missed by the test. Observing the theoretically-predicted convergence rate (slope on a log-log plot) is the primary indicator of a correct implementation. A failure to observe this rate is a strong indication of an error.\n- **Verdict:** **Correct**.\n\n**F.** If the model solver employs adaptive tolerances that vary with $p$ and with the perturbation $\\epsilon\\,\\delta p$, the directional derivative test remains valid because solver tolerances do not affect differentiability and therefore cannot distort the error behavior.\n- **Analysis:** This statement is fundamentally incorrect. If the solver's behavior (e.g., mesh refinement, number of time steps) changes discretely as $p$ varies, the numerically evaluated functional $J(p)$ is no longer a smooth function of $p$. It acquires a \"numerical noise\" or fine-scale non-smoothness. When a finite difference is taken across one of these discrete changes, the result does not approximate a derivative and will not converge as predicted by Taylor's theorem. This is a well-known and serious issue in practice that can invalidate the test.\n- **Verdict:** **Incorrect**.\n\n**G.** Using the central difference eliminates truncation error completely, so the only remaining error source is round-off; therefore, smaller $\\epsilon$ always improves the accuracy of the test.\n- **Analysis:** This statement contains multiple falsehoods. First, the central difference does not eliminate truncation error; it reduces it to a higher order, $\\mathcal{O}(\\epsilon^2)$. Second, because truncation error is not zero, round-off is not the only error source. Third, because of the $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$ round-off component, making $\\epsilon$ arbitrarily small will eventually cause the total error to increase, not improve accuracy indefinitely.\n- **Verdict:** **Incorrect**.\n\n**H.** If $J$ contains nondifferentiable components with respect to $p$, such as exact thresholding or a pointwise maximum, the directional derivative test may not exhibit the expected truncation-rate behavior with $\\epsilon$; in such cases, smoothing or reformulation is required for a reliable adjoint test.\n- **Analysis:** The directional derivative test is predicated on the validity of the Taylor series expansion, which requires the functional to be sufficiently smooth (differentiable). At points of non-differentiability (kinks or jumps), the gradient is not uniquely defined, and the Taylor approximation breaks down. A finite difference stencil that straddles such a non-differentiability will not converge at the expected rate. The standard remedy is to replace the non-differentiable component with a smooth approximation (e.g., replacing $\\max(x, 0)$ with a softplus function) before applying the test. This statement accurately captures this critical limitation and its solution.\n- **Verdict:** **Correct**.", "answer": "$$\\boxed{ABCEH}$$", "id": "3364135"}, {"introduction": "Real-world data is rarely perfect, and outliers can catastrophically corrupt parameter estimates derived from standard least-squares objectives. This practice [@problem_id:3364157] moves from verification to derivation, asking you to derive the adjoint-based gradient for an objective function that incorporates a robust pseudo-Huber loss. By working through the analytical derivation, you will see precisely how the influence of large observation errors is managed and gain a deeper understanding of how to design objective functions for robust data assimilation.", "problem": "Consider a discrete-time linear dynamical model for state estimation over an assimilation window with indices $k = 0, 1, \\ldots, N$. The model maps $x_{k} \\in \\mathbb{R}^{n}$ to $x_{k+1} \\in \\mathbb{R}^{n}$ via $x_{k+1} = M x_{k}$, where $M \\in \\mathbb{R}^{n \\times n}$ is a known matrix, and the initial condition $x_{0}$ is the decision variable. Observations $y_{k} \\in \\mathbb{R}^{p}$ are related to the state by a linear operator $H \\in \\mathbb{R}^{p \\times n}$, and the observation error covariance is $R \\in \\mathbb{R}^{p \\times p}$, symmetric positive definite. The background (prior) mean is $x_{b} \\in \\mathbb{R}^{n}$ and the background covariance is $B \\in \\mathbb{R}^{n \\times n}$, symmetric positive definite.\n\nTo improve robustness under heavy-tailed observation errors (such as might arise from a Student’s $t$-distributed noise), replace the usual quadratic observation misfit by an isotropic pseudo-Huber loss. Define the whitened residual at time $k$ by $s_{k}(x_{0}) = R^{-1/2}\\!\\left(H M^{k} x_{0} - y_{k}\\right)$, where $R^{-1/2} \\in \\mathbb{R}^{p \\times p}$ is the unique symmetric matrix such that $(R^{-1/2})^{\\top} R^{-1/2} = R^{-1}$. The assimilation objective is\n$$\nJ(x_{0}) = \\frac{1}{2}\\,(x_{0} - x_{b})^{\\top} B^{-1} (x_{0} - x_{b}) + \\sum_{k=0}^{N} \\rho\\!\\left(s_{k}(x_{0})\\right),\n$$\nwith the isotropic pseudo-Huber penalty\n$$\n\\rho(s) = \\delta^{2} \\left(\\sqrt{1 + \\frac{\\|s\\|^{2}}{\\delta^{2}}}\\; - 1\\right),\n$$\nwhere $\\delta > 0$ is a robustness parameter that tunes the transition between quadratic behavior for small residuals and linear behavior for large residuals.\n\nStarting from first principles of constrained optimization and the chain rule (introducing adjoint variables as Lagrange multipliers for the discrete dynamics), derive the adjoint-based gradient $\\nabla_{x_{0}} J(x_{0})$ as a closed-form analytic expression in terms of $M$, $H$, $B$, $R$, $\\delta$, $x_{0}$, $x_{b}$, and $\\{y_{k}\\}_{k=0}^{N}$. Express the result explicitly without leaving an unrolled recursion, and write it in a form that displays how each time-indexed residual contributes to the gradient through powers of $M^{\\top}$.\n\nThen, using the derived expression, analyze the per-time contribution’s influence function to discuss robustness versus sensitivity: compute the limiting forms of the contribution as $\\|s_{k}(x_{0})\\|/\\delta \\to 0$ and $\\|s_{k}(x_{0})\\|/\\delta \\to \\infty$, and qualitatively compare these limits to the least-squares (quadratic loss) and Tukey’s biweight loss cases. Your final answer must be the exact analytic expression for the adjoint-based gradient $\\nabla_{x_{0}} J(x_{0})$ in closed form. No numerical evaluation is required.", "solution": "The problem is valid. It is a well-posed and scientifically grounded task in the field of data assimilation, concerning the derivation and analysis of a gradient for a variational cost function with a non-quadratic, robust loss function. All terms are mathematically well-defined, and the premises are consistent.\n\nThe objective is to derive the gradient of the cost function $J(x_0)$ with respect to the initial state $x_0$. The cost function is given by\n$$\nJ(x_{0}) = J_b(x_0) + J_o(x_0) = \\frac{1}{2}\\,(x_{0} - x_{b})^{\\top} B^{-1} (x_{0} - x_{b}) + \\sum_{k=0}^{N} \\rho\\!\\left(s_{k}(x_{0})\\right)\n$$\nThe gradient is the sum of the gradients of the background term $J_b(x_0)$ and the observation term $J_o(x_0)$. We will compute each part separately.\n\nFirst, we compute the gradient of the background term, $J_b(x_0)$. This is a standard quadratic form in $x_0$. Its gradient is\n$$\n\\nabla_{x_0} J_b(x_0) = B^{-1} (x_{0} - x_{b})\n$$\nThe matrix $B^{-1}$ is symmetric, as $B$ is symmetric.\n\nNext, we compute the gradient of the observation term, $J_o(x_0) = \\sum_{k=0}^{N} \\rho(s_{k}(x_{0}))$. By linearity of the gradient operator, we have\n$$\n\\nabla_{x_0} J_o(x_0) = \\sum_{k=0}^{N} \\nabla_{x_0} \\rho(s_{k}(x_{0}))\n$$\nTo compute the gradient of each term in the sum, we apply the chain rule. For a scalar function $\\phi(v(u))$ of a vector variable $u$, the gradient is $\\nabla_u \\phi = (\\frac{\\partial v}{\\partial u})^\\top \\nabla_v \\phi$.\nHere, the outer function is $\\rho(s)$ and the inner function is $s_k(x_0)$.\n\nLet's first find the gradient of the pseudo-Huber penalty $\\rho(s)$ with respect to its argument $s \\in \\mathbb{R}^p$.\n$$\n\\rho(s) = \\delta^{2} \\left(\\sqrt{1 + \\frac{\\|s\\|^{2}}{\\delta^{2}}} - 1\\right)\n$$\nUsing the chain rule, $\\nabla_s \\rho(s) = \\frac{d\\rho}{d(\\|s\\|)} \\frac{\\partial \\|s\\|}{\\partial s}$. A more direct approach is to write $\\|s\\|^2=s^\\top s$ and its gradient with respect to $s$ is $2s$.\n$$\n\\nabla_s \\rho(s) = \\delta^2 \\cdot \\frac{1}{2} \\left(1 + \\frac{s^\\top s}{\\delta^2}\\right)^{-1/2} \\cdot \\frac{2s}{\\delta^2} = \\frac{s}{\\sqrt{1 + \\frac{\\|s\\|^2}{\\delta^2}}}\n$$\nThis vector-valued function is often denoted as the influence function, $\\psi(s)$.\n\nNext, we find the Jacobian of the inner function, $s_k(x_0)$, with respect to $x_0$.\n$$\ns_k(x_0) = R^{-1/2} (H M^k x_0 - y_k)\n$$\nThis is an affine transformation of $x_0$. The Jacobian matrix of $s_k$ with respect to $x_0$ is the matrix of partial derivatives $\\frac{\\partial s_k}{\\partial x_0}$, which is given by\n$$\n\\frac{\\partial s_k}{\\partial x_0} = R^{-1/2} H M^k\n$$\nThis is a $p \\times n$ matrix.\n\nNow we can combine these results using the chain rule to find the gradient of one term of the observation cost:\n$$\n\\nabla_{x_0} \\rho(s_k(x_0)) = \\left(\\frac{\\partial s_k}{\\partial x_0}\\right)^{\\top} \\nabla_s \\rho(s) \\Big|_{s=s_k(x_0)}\n$$\n$$\n\\nabla_{x_0} \\rho(s_k(x_0)) = (R^{-1/2} H M^k)^{\\top} \\frac{s_k(x_0)}{\\sqrt{1 + \\frac{\\|s_k(x_0)\\|^2}{\\delta^2}}}\n$$\nUsing the transpose property $(ABC)^\\top = C^\\top B^\\top A^\\top$ and the fact that $R^{-1/2}$ is symmetric (i.e., $(R^{-1/2})^\\top=R^{-1/2}$), we get\n$$\n\\nabla_{x_0} \\rho(s_k(x_0)) = (M^k)^\\top H^\\top (R^{-1/2})^\\top \\frac{s_k(x_0)}{\\sqrt{1 + \\frac{\\|s_k(x_0)\\|^2}{\\delta^2}}} = (M^k)^\\top H^\\top R^{-1/2} \\frac{s_k(x_0)}{\\sqrt{1 + \\frac{\\|s_k(x_0)\\|^2}{\\delta^2}}}\n$$\nTo obtain a fully explicit expression, we substitute $s_k(x_0) = R^{-1/2}(H M^k x_0 - y_k)$.\nThe numerator part becomes $(M^k)^\\top H^\\top R^{-1/2} R^{-1/2}(H M^k x_0 - y_k) = (M^k)^\\top H^\\top R^{-1}(H M^k x_0 - y_k)$.\nThe squared norm in the denominator becomes $\\|s_k(x_0)\\|^2 = s_k(x_0)^\\top s_k(x_0) = (H M^k x_0 - y_k)^\\top (R^{-1/2})^\\top R^{-1/2} (H M^k x_0 - y_k) = (H M^k x_0 - y_k)^\\top R^{-1} (H M^k x_0 - y_k)$.\nSo, the gradient contribution from time $k$ is\n$$\n\\nabla_{x_0} \\rho(s_k(x_0)) = \\frac{(M^\\top)^k H^\\top R^{-1}(H M^k x_0 - y_k)}{\\sqrt{1 + \\frac{(H M^k x_0 - y_k)^\\top R^{-1} (H M^k x_0 - y_k)}{\\delta^2}}}\n$$\nThis form shows that the gradient is a product of the standard least-squares gradient contribution and a scalar weight that depends on the magnitude of the whitened residual.\n\nSumming over all time steps $k=0, \\ldots, N$ and adding the gradient of the background term gives the final expression for the total gradient:\n$$\n\\nabla_{x_{0}} J(x_{0}) = B^{-1}(x_{0} - x_{b}) + \\sum_{k=0}^{N} \\frac{(M^\\top)^k H^\\top R^{-1}(H M^k x_0 - y_k)}{\\sqrt{1 + \\frac{\\|s_k(x_0)\\|^2}{\\delta^2}}}\n$$\nwhere $\\|s_k(x_0)\\|^2 = (H M^k x_0 - y_k)^\\top R^{-1} (H M^k x_0 - y_k)$. This is the demanded closed-form expression.\n\nThe problem also requires an analysis of the robustness and sensitivity. This is characterized by the influence function, $\\psi(s) = \\nabla_s \\rho(s)$, which determines how a residual $s$ influences the gradient. For the pseudo-Huber loss, this is $\\psi(s) = s / \\sqrt{1 + \\|s\\|^2/\\delta^2}$.\n\nLet's analyze the limiting forms of this function's magnitude, $\\|\\psi(s)\\| = \\|s\\| / \\sqrt{1 + \\|s\\|^2/\\delta^2}$.\n1.  **Small residuals**: As $\\|s_k(x_0)\\|/\\delta \\to 0$, we have $\\sqrt{1 + \\|s_k(x_0)\\|^2/\\delta^2} \\approx 1$. Thus, $\\psi(s_k(x_0)) \\approx s_k(x_0)$. In this limit, the penalty function $\\rho(s_k)$ approximates a quadratic, $\\rho(s_k) \\approx \\frac{1}{2}\\|s_k\\|^2$, which is the standard least-squares penalty. The influence of the residual on the gradient is linear and unbounded.\n\n2.  **Large residuals**: As $\\|s_k(x_0)\\|/\\delta \\to \\infty$, we have $\\sqrt{1 + \\|s_k(x_0)\\|^2/\\delta^2} \\approx \\|s_k(x_0)\\|/\\delta$. Thus, the influence function approaches\n$$\n\\psi(s_k(x_0)) \\approx \\frac{s_k(x_0)}{\\|s_k(x_0)\\|/\\delta} = \\delta \\, \\frac{s_k(x_0)}{\\|s_k(x_0)\\|}\n$$\nThe magnitude of the influence function saturates at a constant value, $\\|\\psi(s_k(x_0))\\| \\to \\delta$. This means that the influence of very large residuals (outliers) is bounded, preventing them from dominating the gradient. This property is the source of the method's robustness. The penalty function $\\rho(s_k)$ behaves like $\\delta\\|s_k\\| - \\delta^2$, which corresponds to an L1-norm penalty on the residual, known for promoting robustness.\n\n**Qualitative comparison**:\n-   **Least-Squares (Quadratic) Loss**: The influence function is $\\psi_{LS}(s) = s$. The influence grows linearly and without bound as $\\|s\\|$ increases. This makes estimates highly sensitive to outliers.\n-   **Pseudo-Huber Loss**: The influence function $\\psi_{PH}(s)$ transitions from linear growth, $\\psi_{PH}(s) \\approx s$, for small $\\|s\\|$ to a saturated magnitude, $\\|\\psi_{PH}(s)\\| \\to \\delta$, for large $\\|s\\|$. This provides robustness by down-weighting the effect of outliers.\n-   **Tukey's Biweight Loss**: This is a redescending estimator. Its influence function, e.g., $\\psi_{Tukey}(s) = s (1 - \\|s\\|^2/c^2)^2$ for $\\|s\\| \\le c$ and $0$ otherwise, not only bounds the influence of outliers but actively suppresses it, sending it to zero for residuals larger than a cutoff $c$. This provides even stronger robustness by completely rejecting gross outliers, whereas the pseudo-Huber loss still assigns them a constant, non-zero influence.\n\nIn summary, the pseudo-Huber loss offers a compromise, retaining the desirable properties of least-squares for small, well-behaved residuals while providing a cap on the influence of large, outlying residuals, thereby ensuring robustness.", "answer": "$$\n\\boxed{\nB^{-1}(x_{0} - x_{b}) + \\sum_{k=0}^{N} \\frac{(M^\\top)^k H^\\top R^{-1}(H M^k x_0 - y_k)}{\\sqrt{1 + \\frac{(H M^k x_0 - y_k)^\\top R^{-1} (H M^k x_0 - y_k)}{\\delta^2}}}\n}\n$$", "id": "3364157"}, {"introduction": "Many physical systems are characterized by non-smooth dynamics, where \"events\" like state transitions or contact create kinks in the system's response. Propagating gradients through these non-differentiabilities is a critical challenge in building adjoint models. This hands-on coding exercise [@problem_id:3364071] uses a simplified hydrological model to demonstrate how to implement a discrete adjoint that correctly handles such events, specifically those arising from wetting-and-drying dynamics modeled with $\\max()$ functions.", "problem": "Consider a minimal one-cell semi-discrete shallow-water mass-balance model with wetting and drying represented through a non-smooth projection. Let $h(t)$ denote the water depth above a bed elevation parameter $z$, and let the upstream free-surface forcing be $H_{u}(t)$. The flux into the cell at time $t$ is modeled as $F_{\\text{in}}(t) = \\alpha \\max(H_{u}(t) - z - h(t), 0)$, and the outflow is modeled as $F_{\\text{out}}(t) = \\beta h(t)$ when the cell is wet. The local mass balance ordinary differential equation is\n$$\n\\frac{dh}{dt} = \\alpha \\max(H_{u}(t) - z - h(t), 0) - \\beta h(t).\n$$\nTo enforce non-negativity of the depth, the forward time stepping applies a projection at each step. Use an explicit forward Euler integrator with time step $\\Delta t$ and define $t_n = n \\Delta t$ for $n=0,1,\\dots,N$. For $h_n \\approx h(t_n)$, perform the following update:\n$$\nh_{n+1}^{\\star} = h_{n} + \\Delta t \\left(\\alpha \\max(H_{u}(t_n) - z - h_n, 0) - \\beta h_n \\right), \\quad h_{n+1} = \\max(h_{n+1}^{\\star}, 0).\n$$\nDefine the activation indicator for the projection as\n$$\na_{n+1} = \\begin{cases}\n1 & \\text{if } h_{n+1}^{\\star} > 0,\\\\\n0 & \\text{if } h_{n+1}^{\\star} \\le 0,\n\\end{cases}\n$$\nand the inflow activation as\n$$\nm_n = \\begin{cases}\n1 & \\text{if } H_{u}(t_n) - z - h_n > 0,\\\\\n0 & \\text{if } H_{u}(t_n) - z - h_n \\le 0.\n\\end{cases}\n$$\nAssume the upstream free-surface is given by\n$H_{u}(t) = H_0 + A \\sin(\\omega t),$\nwith $H_0$, $A$, and $\\omega$ specified constants. Let the observation model be direct depth sampling $y_n = h(t_n)$, and let the target observations be identically zero, $y_n^{\\text{obs}} = 0$ for all $n$. Consider the quadratic objective (with Tikhonov quadratic prior on $z$)\n$$\nJ(z) = \\frac{1}{2}\\sum_{n=0}^{N} \\left(h_n - y_n^{\\text{obs}}\\right)^2 + \\frac{\\gamma}{2}\\left(z - z_{\\text{prior}}\\right)^2.\n$$\nYour task is to compute the gradient $\\frac{dJ}{dz}$ via an adjoint method that exactly matches the discrete time-stepping and the projection (wetting/drying) event handling. Specifically, implement the discrete adjoint for the one-step map $h_n \\mapsto h_{n+1} = \\max\\!\\left(h_n + \\Delta t f_n(h_n, z), 0\\right)$ with\n$$\nf_n(h_n, z) = \\alpha \\max(H_u(t_n) - z - h_n, 0) - \\beta h_n,\n$$\nby applying the chain rule with the generalized derivative of the projection. Use the event-handling strategy\n$$\n\\frac{\\partial h_{n+1}}{\\partial h_n} = a_{n+1}\\left(1 + \\Delta t \\frac{\\partial f_n}{\\partial h_n}\\right), \\quad \\frac{\\partial h_{n+1}}{\\partial z} = a_{n+1}\\left(\\Delta t \\frac{\\partial f_n}{\\partial z}\\right),\n$$\ntogether with\n$$\n\\frac{\\partial f_n}{\\partial h_n} = -\\alpha m_n - \\beta, \\quad \\frac{\\partial f_n}{\\partial z} = -\\alpha m_n.\n$$\nAt the non-differentiable kink points, use the definition of $a_{n+1}$ and $m_n$ above, which assigns $0$ when the corresponding pre-activation is non-positive. This constitutes an event-handling strategy for adjoint propagation consistent with wetting and drying transitions in the discrete dynamics.\n\nDefine the discrete adjoint sequence $\\lambda_n$ by reverse-time recursion aligned with the objective. Let\n$$\n\\lambda_N = \\frac{\\partial}{\\partial h_N}\\left(\\frac{1}{2}(h_N - y_N^{\\text{obs}})^2\\right) = h_N - y_N^{\\text{obs}},\n$$\nand, for $n = N-1, \\dots, 0$,\n$$\n\\lambda_n = \\frac{\\partial}{\\partial h_n}\\left(\\frac{1}{2}(h_n - y_n^{\\text{obs}})^2\\right) + \\left(\\frac{\\partial h_{n+1}}{\\partial h_n}\\right) \\lambda_{n+1} = (h_n - y_n^{\\text{obs}}) + a_{n+1}\\left(1 + \\Delta t \\frac{\\partial f_n}{\\partial h_n}\\right)\\lambda_{n+1}.\n$$\nThen the gradient is\n$$\n\\frac{dJ}{dz} = \\gamma (z - z_{\\text{prior}}) + \\sum_{n=0}^{N-1} \\lambda_{n+1}\\, a_{n+1}\\left(\\Delta t \\frac{\\partial f_n}{\\partial z}\\right).\n$$\nImplement a program that:\n- Integrates the forward model using the specified explicit scheme and projection.\n- Computes $J(z)$.\n- Computes $\\frac{dJ}{dz}$ using the discrete adjoint with the event-handling strategy defined above.\n- Computes a central finite-difference approximation\n$$\n\\left.\\frac{dJ}{dz}\\right|_{\\text{FD}} \\approx \\frac{J(z+\\epsilon) - J(z-\\epsilon)}{2\\epsilon},\n$$\nfor a sufficiently small $\\epsilon$, using the same forward solver and projection for the perturbed $z$ values.\n- Returns, for each test case below, the absolute error\n$$\ne = \\left|\\left.\\frac{dJ}{dz}\\right|_{\\text{adj}} - \\left.\\frac{dJ}{dz}\\right|_{\\text{FD}}\\right|.\n$$\n\nAll quantities are non-dimensional; no physical units are required. Angles used in $\\sin(\\cdot)$ are in radians. Do not use percentage signs anywhere; any ratios should be expressed as decimals.\n\nTest suite (each case defines $\\alpha$, $\\beta$, $H_0$, $A$, $\\omega$, $\\Delta t$, $N$, $h_0$, $\\gamma$, $z_{\\text{prior}}$, and the evaluation point $z$):\n- Case $1$ (always dry): $\\alpha = 3.0$, $\\beta = 0.5$, $H_0 = 0.2$, $A = 0.0$, $\\omega = 1.0$, $\\Delta t = 0.01$, $N = 500$, $h_0 = 0.0$, $\\gamma = 0.1$, $z_{\\text{prior}} = 0.0$, $z = 0.6$.\n- Case $2$ (sustained inundation): $\\alpha = 2.0$, $\\beta = 0.2$, $H_0 = 1.0$, $A = 0.3$, $\\omega = 1.5$, $\\Delta t = 0.01$, $N = 1000$, $h_0 = 0.0$, $\\gamma = 0.1$, $z_{\\text{prior}} = 0.0$, $z = 0.2$.\n- Case $3$ (intermittent wetting and drying): $\\alpha = 1.5$, $\\beta = 0.1$, $H_0 = 0.55$, $A = 0.35$, $\\omega = 2.0$, $\\Delta t = 0.01$, $N = 1200$, $h_0 = 0.0$, $\\gamma = 0.1$, $z_{\\text{prior}} = 0.0$, $z = 0.6$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets (e.g., \"[r1,r2,r3]\"), where each entry is the absolute error $e$ for the corresponding test case, represented as a floating-point number.", "solution": "The user's request is to compute the gradient of an objective function with respect to a model parameter using a discrete adjoint method, and to verify this gradient against a finite-difference approximation. The model is a simplified one-cell hydrological system with non-smooth dynamics due to wetting-drying and inflow conditions, which are represented by `max` functions.\n\nThe problem is computationally well-defined, scientifically sound, and internally consistent. It poses a standard task in the field of data assimilation and inverse problems: the verification of an adjoint model via a gradient check. The provided equations for the forward model, objective function, and the discrete adjoint are complete and correctly formulated for a specific subgradient-based approach to handle non-differentiability. Therefore, the problem is valid, and we may proceed with the solution.\n\nThe solution process involves three primary stages:\n$1$. Implementing the forward model to simulate the water depth $h_n$ over time for a given bed elevation $z$. This model also computes the objective function $J(z)$.\n$2$. Implementing the discrete adjoint model, which involves a backward-in-time recursion to compute the adjoint variables $\\lambda_n$, followed by a summation to assemble the gradient $\\frac{dJ}{dz}$.\n$3$. Computing a numerical gradient using the central finite-difference method to serve as a benchmark for verifying the adjoint-derived gradient.\n\n### 1. Forward Model and Objective Function\n\nThe state of the system is the water depth $h_n$ at discrete time steps $t_n = n \\Delta t$. The evolution of the state is governed by the explicit forward Euler scheme with a non-negativity projection:\n$$\nh_{n+1}^{\\star} = h_{n} + \\Delta t \\left(\\alpha \\max(H_{u}(t_n) - z - h_n, 0) - \\beta h_n \\right)\n$$\n$$\nh_{n+1} = \\max(h_{n+1}^{\\star}, 0)\n$$\nwhere $H_{u}(t_n) = H_0 + A \\sin(\\omega t_n)$ is the external forcing. The simulation starts from a given initial condition $h_0$ and is run for $N$ steps to produce the state trajectory $\\{h_n\\}_{n=0}^{N}$.\n\nDuring this forward pass, we must also compute and store the history of two indicator variables which are crucial for the adjoint computation. These variables represent the generalized derivatives of the `max` functions at each time step.\nThe inflow activation indicator $m_n$ is:\n$$\nm_n = \\begin{cases}\n1 & \\text{if } H_{u}(t_n) - z - h_n > 0 \\\\\n0 & \\text{if } H_{u}(t_n) - z - h_n \\le 0\n\\end{cases}\n$$\nThe projection activation indicator $a_{n+1}$ is:\n$$\na_{n+1} = \\begin{cases}\n1 & \\text{if } h_{n+1}^{\\star} > 0 \\\\\n0 & \\text{if } h_{n+1}^{\\star} \\le 0\n\\end{cases}\n$$\nThese choices correspond to selecting a specific subgradient at the points of non-differentiability.\n\nOnce the full trajectory $\\{h_n\\}_{n=0}^{N}$ is computed, the objective function $J(z)$ is calculated. Given that the target observations are $y_n^{\\text{obs}} = 0$, the objective function is:\n$$\nJ(z) = \\frac{1}{2}\\sum_{n=0}^{N} h_n^2 + \\frac{\\gamma}{2}\\left(z - z_{\\text{prior}}\\right)^2\n$$\nThis function, which we denote `forward_model`, will be the fundamental building block for both the adjoint and finite-difference calculations.\n\n### 2. Discrete Adjoint Gradient Computation\n\nThe adjoint method provides an efficient way to compute the gradient of a scalar objective function with respect to a large number of parameters by reversing the flow of information through the computational graph of the forward model. The derivation relies on the chain rule, applied systematically to each step of the discrete-time simulation.\n\nThe process consists of two passes:\na. **Forward Pass:** Run the forward model as described above for a given parameter $z$. Store the full time histories of the state $h_n$ and the indicators $m_n$ and $a_{n+1}$.\n\nb. **Backward Pass:** Compute the adjoint variables (or costate variables) $\\lambda_n$, which represent the sensitivity of the final objective function $J$ to perturbations in the state $h_n$. The calculation proceeds backward in time, from $n=N$ to $n=0$.\n\nThe terminal condition for the adjoint variable at time $t_N$ is the derivative of the objective function with respect to the final state $h_N$:\n$$\n\\lambda_N = \\frac{\\partial J}{\\partial h_N} = h_N - y_N^{\\text{obs}} = h_N\n$$\nThe recursion for $n = N-1, \\dots, 0$ is derived from the chain rule, propagating sensitivities from step $n+1$ back to step $n$:\n$$\n\\lambda_n = \\frac{\\partial J}{\\partial h_n} + \\frac{\\partial h_{n+1}}{\\partial h_n} \\lambda_{n+1}\n$$\nHere, $\\frac{\\partial J}{\\partial h_n} = h_n - y_n^{\\text{obs}} = h_n$ is the direct contribution to the objective function at time $n$. The term $\\frac{\\partial h_{n+1}}{\\partial h_n}$ is the Jacobian of the one-step map $h_n \\mapsto h_{n+1}$. Using the provided event-handling strategy:\n$$\n\\frac{\\partial h_{n+1}}{\\partial h_n} = a_{n+1}\\left(1 + \\Delta t \\frac{\\partial f_n}{\\partial h_n}\\right) = a_{n+1}\\left(1 + \\Delta t (-\\alpha m_n - \\beta)\\right)\n$$\nThus, the backward recursion becomes:\n$$\n\\lambda_n = h_n + a_{n+1}\\left(1 - \\Delta t (\\alpha m_n + \\beta)\\right)\\lambda_{n+1}\n$$\n\nc. **Gradient Assembly:** Once the adjoint variables $\\lambda_n$ have been computed for $n=N, \\dots, 1$, the total gradient $\\frac{dJ}{dz}$ is assembled. It consists of the derivative of the regularization term plus the sum of contributions from each time step, which are propagated via the adjoint variables:\n$$\n\\frac{dJ}{dz} = \\frac{\\partial J}{\\partial z} + \\sum_{n=0}^{N-1} \\lambda_{n+1} \\frac{\\partial h_{n+1}}{\\partial z}\n$$\nThe direct partial derivative $\\frac{\\partial J}{\\partial z}$ is simply the derivative of the regularization term, $\\gamma(z - z_{\\text{prior}})$. The sensitivity of the state transition, $\\frac{\\partial h_{n+1}}{\\partial z}$, is given as:\n$$\n\\frac{\\partial h_{n+1}}{\\partial z} = a_{n+1}\\left(\\Delta t \\frac{\\partial f_n}{\\partial z}\\right) = a_{n+1}\\left(\\Delta t (-\\alpha m_n)\\right)\n$$\nSubstituting these expressions yields the final formula for the adjoint gradient:\n$$\n\\left.\\frac{dJ}{dz}\\right|_{\\text{adj}} = \\gamma (z - z_{\\text{prior}}) - \\Delta t \\alpha \\sum_{n=0}^{N-1} \\lambda_{n+1}\\, a_{n+1}\\, m_n\n$$\nIn implementation, we will use the stored histories of $m_n$ and $a_{n+1}$ (as `m[n]` and `a[n]` respectively) and the computed adjoint variables $\\lambda_{n+1}$ (`lam[n+1]`) to evaluate this sum.\n\n### 3. Finite-Difference Gradient and Verification\n\nTo verify the correctness of the adjoint implementation, we compute the gradient using the central finite-difference formula, which provides a reliable numerical approximation for differentiable functions. For a small perturbation $\\epsilon$:\n$$\n\\left.\\frac{dJ}{dz}\\right|_{\\text{FD}} \\approx \\frac{J(z+\\epsilon) - J(z-\\epsilon)}{2\\epsilon}\n$$\nThis requires two separate executions of the full forward model: one with the parameter $z+\\epsilon$ and another with $z-\\epsilon$. A sufficiently small $\\epsilon$, such as $10^{-7}$, is chosen to balance truncation error and floating-point round-off error.\n\nThe final step is to compute the absolute error between the adjoint-derived gradient and the finite-difference approximation:\n$$\ne = \\left|\\left.\\frac{dJ}{dz}\\right|_{\\text{adj}} - \\left.\\frac{dJ}{dz}\\right|_{\\text{FD}}\\right|\n$$\nA small error provides high confidence in the correctness of the adjoint model and its implementation. This procedure will be repeated for each of the three test cases provided.", "answer": "```python\nimport numpy as np\n\ndef run_simulation(params, z_eval):\n    \"\"\"\n    Runs the forward simulation and computes the objective function J.\n\n    Args:\n        params (dict): A dictionary containing all model parameters.\n        z_eval (float): The value of the bed elevation parameter z to use.\n\n    Returns:\n        tuple: A tuple containing:\n            - h_hist (np.ndarray): History of water depth h_n of size N+1.\n            - m_hist (np.ndarray): History of inflow indicator m_n of size N.\n            - a_hist (np.ndarray): History of projection indicator a_{n+1} of size N.\n            - J (float): The value of the objective function.\n    \"\"\"\n    alpha = params['alpha']\n    beta = params['beta']\n    H0 = params['H0']\n    A = params['A']\n    omega = params['omega']\n    dt = params['dt']\n    N = params['N']\n    h0 = params['h0']\n    gamma = params['gamma']\n    z_prior = params['z_prior']\n\n    h_hist = np.zeros(N + 1)\n    m_hist = np.zeros(N)\n    a_hist = np.zeros(N)\n\n    h_hist[0] = h0\n\n    for n in range(N):\n        t_n = n * dt\n        H_u_n = H0 + A * np.sin(omega * t_n)\n        \n        # Inflow activation\n        inflow_arg = H_u_n - z_eval - h_hist[n]\n        m_hist[n] = 1.0 if inflow_arg > 0.0 else 0.0\n        \n        # Flux calculation\n        f_n = alpha * max(inflow_arg, 0.0) - beta * h_hist[n]\n        \n        # Euler step\n        h_star = h_hist[n] + dt * f_n\n        \n        # Projection activation\n        a_hist[n] = 1.0 if h_star > 0.0 else 0.0\n        \n        # State update with projection\n        h_hist[n + 1] = max(h_star, 0.0)\n\n    # Objective function\n    # Note: y_n^obs = 0 for all n\n    J_obs = 0.5 * np.sum(h_hist**2)\n    J_reg = 0.5 * gamma * (z_eval - z_prior)**2\n    J = J_obs + J_reg\n    \n    return h_hist, m_hist, a_hist, J\n\ndef compute_adjoint_gradient(params, z_eval, h_hist, m_hist, a_hist):\n    \"\"\"\n    Computes the gradient dJ/dz using the discrete adjoint method.\n    \"\"\"\n    alpha = params['alpha']\n    beta = params['beta']\n    dt = params['dt']\n    N = params['N']\n    gamma = params['gamma']\n    z_prior = params['z_prior']\n\n    lam = np.zeros(N + 1)\n    \n    # Terminal condition for adjoint variable (y_N^obs = 0)\n    lam[N] = h_hist[N]\n    \n    # Backward recursion for adjoint variables\n    for n in range(N - 1, -1, -1):\n        # Propagated part\n        df_dhn = -alpha * m_hist[n] - beta\n        dhnp1_dhn = a_hist[n] * (1.0 + dt * df_dhn)\n        \n        # Direct part from objective function (y_n^obs = 0)\n        dJ_dhn = h_hist[n]\n        \n        lam[n] = dJ_dhn + dhnp1_dhn * lam[n + 1]\n\n    # Assemble the gradient\n    grad_sum = 0.0\n    for n in range(N):\n        df_dzn = -alpha * m_hist[n]\n        dhnp1_dz = a_hist[n] * (dt * df_dzn)\n        grad_sum += lam[n + 1] * dhnp1_dz\n\n    grad_adj = gamma * (z_eval - z_prior) + grad_sum\n    \n    return grad_adj\n\ndef compute_fd_gradient(params, z_eval, epsilon=1e-7):\n    \"\"\"\n    Computes the gradient dJ/dz using the central finite-difference method.\n    \"\"\"\n    _, _, _, J_plus = run_simulation(params, z_eval + epsilon)\n    _, _, _, J_minus = run_simulation(params, z_eval - epsilon)\n    \n    grad_fd = (J_plus - J_minus) / (2.0 * epsilon)\n    return grad_fd\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and compute errors.\n    \"\"\"\n    test_cases = [\n        # Case 1 (always dry)\n        {\n            'alpha': 3.0, 'beta': 0.5, 'H0': 0.2, 'A': 0.0, 'omega': 1.0, \n            'dt': 0.01, 'N': 500, 'h0': 0.0, 'gamma': 0.1, \n            'z_prior': 0.0, 'z_eval': 0.6\n        },\n        # Case 2 (sustained inundation)\n        {\n            'alpha': 2.0, 'beta': 0.2, 'H0': 1.0, 'A': 0.3, 'omega': 1.5,\n            'dt': 0.01, 'N': 1000, 'h0': 0.0, 'gamma': 0.1, \n            'z_prior': 0.0, 'z_eval': 0.2\n        },\n        # Case 3 (intermittent wetting and drying)\n        {\n            'alpha': 1.5, 'beta': 0.1, 'H0': 0.55, 'A': 0.35, 'omega': 2.0,\n            'dt': 0.01, 'N': 1200, 'h0': 0.0, 'gamma': 0.1, \n            'z_prior': 0.0, 'z_eval': 0.6\n        },\n    ]\n\n    results = []\n    \n    epsilon_fd = 1e-7\n\n    for case_params in test_cases:\n        z = case_params['z_eval']\n        \n        # 1. Run forward model to get states and indicators\n        h_hist, m_hist, a_hist, _ = run_simulation(case_params, z)\n        \n        # 2. Compute adjoint gradient\n        grad_adj = compute_adjoint_gradient(case_params, z, h_hist, m_hist, a_hist)\n        \n        # 3. Compute finite-difference gradient for verification\n        grad_fd = compute_fd_gradient(case_params, z, epsilon=epsilon_fd)\n        \n        # 4. Calculate absolute error\n        error = abs(grad_adj - grad_fd)\n        results.append(error)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3364071"}]}