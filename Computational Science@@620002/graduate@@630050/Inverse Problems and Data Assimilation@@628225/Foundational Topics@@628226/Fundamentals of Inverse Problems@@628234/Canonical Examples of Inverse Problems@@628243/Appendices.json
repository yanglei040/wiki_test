{"hands_on_practices": [{"introduction": "Many inverse problems, when discretized, take the form of a linear system of equations, $Gm=d$. This exercise demonstrates how the fundamental properties of the forward operator $G$, dictated by the experimental setup, determine whether a unique solution exists. By analyzing a simple tomographic system [@problem_id:3370624], you will discover the concept of the null space—model components that are invisible to the measurements—and see how it directly leads to ill-posedness and ambiguity in the solution.", "problem": "Consider a two-dimensional straight-ray travel time tomography problem on a uniform $2 \\times 2$ Cartesian grid of square cells with unknown slownesses $m = (s_{1}, s_{2}, s_{3}, s_{4})^{\\top} \\in \\mathbb{R}^{4}$. The continuous travel time of a ray is defined by the path integral $t = \\int_{\\gamma} s(\\mathbf{x}) \\, \\mathrm{d}\\ell$, where $\\gamma$ denotes the straight ray path and $s(\\mathbf{x})$ is the slowness field. In a standard piecewise-constant discretization, each measured travel time $t_{i}$ is approximated by a linear functional of $m$,\n$$\nt_{i} \\approx \\sum_{j=1}^{4} L_{ij} s_{j},\n$$\nwhere $L_{ij}$ is the path length of ray $i$ within cell $j$. Stack the $t_{i}$ into a data vector $t \\in \\mathbb{R}^{4}$ and the $L_{ij}$ into a system matrix $G \\in \\mathbb{R}^{4 \\times 4}$ so that $t \\approx G m$.\n\nSuppose geometry and acquisition are as follows. There are $4$ rays:\n(i) a horizontal ray traversing the top row of cells,\n(ii) a horizontal ray traversing the bottom row of cells,\n(iii) a vertical ray traversing the left column of cells, and\n(iv) a vertical ray traversing the right column of cells.\nAssume each ray traverses each intersected cell with unit path length, that is, $L_{ij} \\in \\{0,1\\}$ with $L_{ij} = 1$ if and only if ray $i$ crosses cell $j$. Thus $G$ has binary entries and encodes this geometry. Assume independent, identically distributed Gaussian measurement errors with covariance $\\sigma^{2} I$, and adopt the Weighted Least Squares (WLS) objective\n$$\n\\Phi(m) = \\frac{1}{2} \\| t - G m \\|_{2}^{2},\n$$\nso the normal equations are $G^{\\top} G \\, m = G^{\\top} t$.\n\nTasks:\n(1) Assemble the explicit matrix $G$ implied by the described acquisition geometry, and form the normal matrix $N = G^{\\top} G$.\n(2) Using only the structure of $N$, identify a nontrivial vector in the null space of $N$ and interpret it in terms of acquisition-induced ambiguity.\n(3) Compute the eigenvalues of $N$ in nonincreasing order.\n\nProvide your final answer as the ordered eigenvalues of $N$ in a single row matrix. No rounding is required; provide exact integers. Do not include units in your final answer.", "solution": "The problem statement is validated as scientifically grounded, well-posed for analysis, objective, and self-contained. It presents a canonical example of a linear inverse problem in the field of geophysical tomography. All required information is provided, and the tasks are unambiguous. We may therefore proceed with the solution.\n\nThe problem asks for three tasks related to a $2 \\times 2$ travel-time tomography problem. We will address each in order.\n\nLet us first establish a clear indexing convention. The four cells are indexed in row-major order:\n- Cell $1$: top-left\n- Cell $2$: top-right\n- Cell $3$: bottom-left\n- Cell $4$: bottom-right\nThe vector of unknown slownesses is $m = (s_1, s_2, s_3, s_4)^{\\top}$.\n\nThe four rays are indexed as follows:\n- Ray $1$: horizontal, top row\n- Ray $2$: horizontal, bottom row\n- Ray $3$: vertical, left column\n- Ray $4$: vertical, right column\nThe vector of measured travel times is $t = (t_1, t_2, t_3, t_4)^{\\top}$.\n\nThe discrete forward model is given by the linear system $t = G m$, where $G_{ij}$ is the path length of ray $i$ in cell $j$. The problem states that $G_{ij}=1$ if ray $i$ traverses cell $j$, and $G_{ij}=0$ otherwise.\n\n(1) Assemble the explicit matrix $G$ and form the normal matrix $N = G^{\\top} G$.\n\nWe construct the matrix $G$ row by row, where each row corresponds to a ray measurement:\n- Ray $1$ traverses cells $1$ and $2$. Thus, $t_1 = 1 \\cdot s_1 + 1 \\cdot s_2 + 0 \\cdot s_3 + 0 \\cdot s_4$. The first row of $G$ is $(1, 1, 0, 0)$.\n- Ray $2$ traverses cells $3$ and $4$. Thus, $t_2 = 0 \\cdot s_1 + 0 \\cdot s_2 + 1 \\cdot s_3 + 1 \\cdot s_4$. The second row of $G$ is $(0, 0, 1, 1)$.\n- Ray $3$ traverses cells $1$ and $3$. Thus, $t_3 = 1 \\cdot s_1 + 0 \\cdot s_2 + 1 \\cdot s_3 + 0 \\cdot s_4$. The third row of $G$ is $(1, 0, 1, 0)$.\n- Ray $4$ traverses cells $2$ and $4$. Thus, $t_4 = 0 \\cdot s_1 + 1 \\cdot s_2 + 0 \\cdot s_3 + 1 \\cdot s_4$. The fourth row of $G$ is $(0, 1, 0, 1)$.\n\nCombining these rows, the system matrix $G$ is:\n$$\nG = \\begin{pmatrix}\n1 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 1 \\\\\n1 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 1\n\\end{pmatrix}\n$$\nThe normal matrix $N$ is defined as $N = G^{\\top} G$. First, we write the transpose of $G$:\n$$\nG^{\\top} = \\begin{pmatrix}\n1 & 0 & 1 & 0 \\\\\n1 & 0 & 0 & 1 \\\\\n0 & 1 & 1 & 0 \\\\\n0 & 1 & 0 & 1\n\\end{pmatrix}\n$$\nNow we compute the product:\n$$\nN = G^{\\top} G = \\begin{pmatrix}\n1 & 0 & 1 & 0 \\\\\n1 & 0 & 0 & 1 \\\\\n0 & 1 & 1 & 0 \\\\\n0 & 1 & 0 & 1\n\\end{pmatrix}\n\\begin{pmatrix}\n1 & 1 & 0 & 0 \\\\\n0 & 0 & 1 & 1 \\\\\n1 & 0 & 1 & 0 \\\\\n0 & 1 & 0 & 1\n\\end{pmatrix}\n= \\begin{pmatrix}\n1 \\cdot 1 + 0 \\cdot 0 + 1 \\cdot 1 + 0 \\cdot 0 & 1 \\cdot 1 + 0 \\cdot 0 + 1 \\cdot 0 + 0 \\cdot 1 & 1 \\cdot 0 + 0 \\cdot 1 + 1 \\cdot 1 + 0 \\cdot 0 & 1 \\cdot 0 + 0 \\cdot 1 + 1 \\cdot 0 + 0 \\cdot 1 \\\\\n1 \\cdot 1 + 0 \\cdot 0 + 0 \\cdot 1 + 1 \\cdot 0 & 1 \\cdot 1 + 0 \\cdot 0 + 0 \\cdot 0 + 1 \\cdot 1 & 1 \\cdot 0 + 0 \\cdot 1 + 0 \\cdot 1 + 1 \\cdot 0 & 1 \\cdot 0 + 0 \\cdot 1 + 0 \\cdot 0 + 1 \\cdot 1 \\\\\n0 \\cdot 1 + 1 \\cdot 0 + 1 \\cdot 1 + 0 \\cdot 0 & 0 \\cdot 1 + 1 \\cdot 0 + 1 \\cdot 0 + 0 \\cdot 1 & 0 \\cdot 0 + 1 \\cdot 1 + 1 \\cdot 1 + 0 \\cdot 0 & 0 \\cdot 0 + 1 \\cdot 1 + 1 \\cdot 0 + 0 \\cdot 1 \\\\\n0 \\cdot 1 + 1 \\cdot 0 + 0 \\cdot 1 + 1 \\cdot 0 & 0 \\cdot 1 + 1 \\cdot 0 + 0 \\cdot 0 + 1 \\cdot 1 & 0 \\cdot 0 + 1 \\cdot 1 + 0 \\cdot 1 + 1 \\cdot 0 & 0 \\cdot 0 + 1 \\cdot 1 + 0 \\cdot 0 + 1 \\cdot 1\n\\end{pmatrix}\n$$\n$$\nN = \\begin{pmatrix}\n2 & 1 & 1 & 0 \\\\\n1 & 2 & 0 & 1 \\\\\n1 & 0 & 2 & 1 \\\\\n0 & 1 & 1 & 2\n\\end{pmatrix}\n$$\n\n(2) Using only the structure of $N$, identify a nontrivial vector in the null space of $N$ and interpret it.\n\nA vector $v$ is in the null space of $N=G^\\top G$ if and only if it is in the null space of $G$. We seek a non-zero vector $v = (v_1, v_2, v_3, v_4)^\\top$ such that $Gv=0$. This is equivalent to the system of linear equations:\n$$\nv_1 + v_2 = 0 \\\\\nv_3 + v_4 = 0 \\\\\nv_1 + v_3 = 0 \\\\\nv_2 + v_4 = 0\n$$\nFrom the first equation, $v_2 = -v_1$. From the third equation, $v_3 = -v_1$. Substituting these into the second equation gives $(-v_1) + v_4 = 0$, which implies $v_4 = v_1$. The fourth equation, $v_2+v_4 = (-v_1) + v_1 = 0$, is automatically satisfied and provides no new information.\nThus, any vector in the null space of $G$ (and $N$) must be of the form $(c, -c, -c, c)^\\top$ for some scalar $c \\in \\mathbb{R}$.\nA simple non-trivial vector is obtained by setting $c=1$:\n$$\nv_{\\text{null}} = (1, -1, -1, 1)^\\top\n$$\nThis vector represents a \"checkerboard\" pattern of slowness perturbations. If we add this pattern (scaled by any constant $\\alpha$) to a given slowness model $m$, the new model $m' = m + \\alpha v_{\\text{null}}$ is indistinguishable from $m$ using the given measurements. The travel time for each ray remains unchanged:\n- Ray $1$: change is $\\alpha v_1 + \\alpha v_2 = \\alpha(1-1) = 0$.\n- Ray $2$: change is $\\alpha v_3 + \\alpha v_4 = \\alpha(-1+1) = 0$.\n- Ray $3$: change is $\\alpha v_1 + \\alpha v_3 = \\alpha(1-1) = 0$.\n- Ray $4$: change is $\\alpha v_2 + \\alpha v_4 = \\alpha(-1+1) = 0$.\nThis represents a fundamental ambiguity in the acquisition geometry: the set of horizontal and vertical rays cannot resolve checkerboard-like structures in the slowness field. The existence of a non-trivial null space implies that the matrix $N$ is singular, and the inverse problem is ill-posed (specifically, the solution is non-unique).\n\n(3) Compute the eigenvalues of $N$ in nonincreasing order.\n\nWe need to find the eigenvalues of the matrix $N$.\n$$\nN = \\begin{pmatrix}\n2 & 1 & 1 & 0 \\\\\n1 & 2 & 0 & 1 \\\\\n1 & 0 & 2 & 1 \\\\\n0 & 1 & 1 & 2\n\\end{pmatrix}\n$$\nSince we have found a non-zero vector in the null space of $N$, one of the eigenvalues must be $\\lambda = 0$.\n\nThe matrix $N$ has a block structure. Let $A = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix}$ and $I_2 = \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix}$. Then $N$ can be written as:\n$$\nN = \\begin{pmatrix} A & I_2 \\\\ I_2 & A \\end{pmatrix}\n$$\nThe eigenvalues of a block matrix of this form are the eigenvalues of the matrices $A+I_2$ and $A-I_2$.\n\nFirst, let's find the eigenvalues of the sub-matrices.\nFor $A+I_2$:\n$$\nA+I_2 = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} + \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 3 & 1 \\\\ 1 & 3 \\end{pmatrix}\n$$\nThe characteristic equation is $\\det((A+I_2) - \\lambda I) = 0$:\n$$\n(3-\\lambda)^2 - 1 = 0 \\implies 3-\\lambda = \\pm 1 \\implies \\lambda = 3 \\mp 1\n$$\nThis gives two eigenvalues: $\\lambda_a = 4$ and $\\lambda_b = 2$.\n\nFor $A-I_2$:\n$$\nA-I_2 = \\begin{pmatrix} 2 & 1 \\\\ 1 & 2 \\end{pmatrix} - \\begin{pmatrix} 1 & 0 \\\\ 0 & 1 \\end{pmatrix} = \\begin{pmatrix} 1 & 1 \\\\ 1 & 1 \\end{pmatrix}\n$$\nThe characteristic equation is $\\det((A-I_2) - \\lambda I) = 0$:\n$$\n(1-\\lambda)^2 - 1 = 0 \\implies 1-\\lambda = \\pm 1 \\implies \\lambda = 1 \\mp 1\n$$\nThis gives two eigenvalues: $\\lambda_c = 2$ and $\\lambda_d = 0$.\n\nThe set of eigenvalues for $N$ is the union of the eigenvalues of $A+I_2$ and $A-I_2$, which is $\\{4, 2, 2, 0\\}$.\nArranging these in nonincreasing order, we get: $4, 2, 2, 0$.\n\nThe eigenvalue $\\lambda=0$ corresponds to the null-space vector we identified. The rank of $N$ is $3$, and the nullity is $1$. The presence of a zero eigenvalue confirms that the matrix is singular and the least-squares problem does not have a unique solution.", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n4 & 2 & 2 & 0\n\\end{pmatrix}\n}\n$$", "id": "3370624"}, {"introduction": "Once ill-posedness is identified, the next step is to overcome it using regularization. This practice explores Tikhonov regularization, a cornerstone of inverse problem theory, within the powerful framework of the frequency domain. You will derive the classic regularized deconvolution filter for a discrete-time system [@problem_id:3370633] and analyze how the regularization parameter $\\lambda$ carefully balances data fidelity against solution stability, preventing the catastrophic amplification of noise at frequencies where the forward operator is weak.", "problem": "Consider the canonical linear inverse problem in discrete time: recover an unknown sequence $x[n]$ from measurements $y[n]$ generated by the convolution model $y[n] = (h * x)[n]$, where $h[n]$ is a known point-spread function. Assume the reconstruction is obtained by Tikhonov regularization with a quadratic penalty, namely by minimizing the functional $\\|h * x - y\\|_{2}^{2} + \\lambda \\|x\\|_{2}^{2}$ over all square-summable sequences $x[n]$, where $\\lambda > 0$ is the regularization parameter.\n\nYou are given the three-tap averaging kernel $h[n] = \\tfrac{1}{3}(1, 1, 1)$ supported on $n = 0, 1, 2$. Work in the frequency domain using the Discrete-Time Fourier Transform (DTFT), with the conventions $X(\\omega) = \\sum_{n=-\\infty}^{\\infty} x[n] \\exp(-\\mathrm{j}\\,\\omega n)$ and $Y(\\omega) = \\sum_{n=-\\infty}^{\\infty} y[n] \\exp(-\\mathrm{j}\\,\\omega n)$ for $\\omega \\in [-\\pi, \\pi)$, and the convolution theorem $(h * x) \\xleftrightarrow{\\text{DTFT}} H(\\omega) X(\\omega)$.\n\nDerive, from first principles and standard properties of the DTFT and least-squares minimization, the frequency-domain solution $\\widehat{X}(\\omega)$ that minimizes $\\|h * x - y\\|_{2}^{2} + \\lambda \\|x\\|_{2}^{2}$. Then, compute the closed-form frequency response $G(\\omega)$ of the reconstruction filter such that $\\widehat{X}(\\omega) = G(\\omega)\\,Y(\\omega)$, for the specific $h[n] = \\tfrac{1}{3}(1,1,1)$. Express $G(\\omega)$ explicitly in terms of $\\omega$ and $\\lambda$ and simplify it as much as possible.\n\nFinally, analyze the reconstruction filter qualitatively in terms of its magnitude and phase: identify the frequencies at which the filter magnitude is zero, describe the limiting behaviors as $\\lambda \\to 0^{+}$ and as $\\lambda \\to \\infty$, and comment on the phase of $G(\\omega)$.\n\nYour final answer must be the single closed-form analytic expression for $G(\\omega)$, simplified and expressed as a function of $\\omega$ and $\\lambda$. No numerical evaluation is required. If you introduce any acronyms, define them on first use. Angle is in radians.", "solution": "The objective is to find the reconstruction filter $G(\\omega)$ for a Tikhonov-regularized deconvolution problem. The solution $\\widehat{x}[n]$ is the sequence that minimizes the following functional:\n$$J(x) = \\|h * x - y\\|_{2}^{2} + \\lambda \\|x\\|_{2}^{2}$$\nHere, $x$ represents the unknown sequence $x[n]$, $y$ is the measured sequence $y[n]$, $h$ is the known kernel $h[n]$, `*` denotes convolution, and $\\lambda > 0$ is the regularization parameter. The norm $\\|\\cdot\\|_2$ is the standard $\\ell_2$-norm for discrete-time sequences, defined as $\\|s\\|_{2}^{2} = \\sum_{n=-\\infty}^{\\infty} |s[n]|^2$.\n\nThe problem is most conveniently solved in the frequency domain using the Discrete-Time Fourier Transform (DTFT). We will leverage Parseval's theorem, which relates the sum of squares of a sequence to the integral of its squared magnitude in the frequency domain:\n$$\\|s\\|_{2}^{2} = \\sum_{n=-\\infty}^{\\infty} |s[n]|^2 = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} |S(\\omega)|^2 \\, d\\omega$$\nwhere $S(\\omega)$ is the DTFT of the sequence $s[n]$.\n\nApplying Parseval's theorem to both terms in the functional $J(x)$, we transform the minimization problem into the frequency domain. Let $X(\\omega)$, $Y(\\omega)$, and $H(\\omega)$ be the DTFTs of $x[n]$, $y[n]$, and $h[n]$, respectively. The DTFT of the convolution term $(h * x)[n]$ is $H(\\omega)X(\\omega)$ due to the convolution theorem.\n\nThe first term, the data fidelity term, becomes:\n$$\\|h * x - y\\|_{2}^{2} = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} |H(\\omega)X(\\omega) - Y(\\omega)|^2 \\, d\\omega$$\nThe second term, the regularization term, becomes:\n$$\\lambda \\|x\\|_{2}^{2} = \\lambda \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} |X(\\omega)|^2 \\, d\\omega$$\nCombining these, the functional in the frequency domain is:\n$$J(X) = \\frac{1}{2\\pi} \\int_{-\\pi}^{\\pi} \\left( |H(\\omega)X(\\omega) - Y(\\omega)|^2 + \\lambda |X(\\omega)|^2 \\right) \\, d\\omega$$\nTo minimize the integral $J(X)$, we can minimize the integrand pointwise for each frequency $\\omega \\in [-\\pi, \\pi)$. Let the integrand be $L(\\omega, X(\\omega))$:\n$$L(\\omega, X(\\omega)) = |H(\\omega)X(\\omega) - Y(\\omega)|^2 + \\lambda |X(\\omega)|^2$$\nThis is a standard least-squares problem for the complex variable $X(\\omega)$ at each frequency $\\omega$. We find the minimum by taking the complex derivative of $L$ with respect to $X(\\omega)^*$ and setting it to zero.\n$$\\frac{\\partial L}{\\partial X(\\omega)^*} = \\frac{\\partial}{\\partial X(\\omega)^*} \\left( (H(\\omega)X(\\omega) - Y(\\omega))(H(\\omega)^*X(\\omega)^* - Y(\\omega)^*) + \\lambda X(\\omega)X(\\omega)^* \\right) = 0$$\n$$\\frac{\\partial L}{\\partial X(\\omega)^*} = (H(\\omega)X(\\omega) - Y(\\omega)) H(\\omega)^* + \\lambda X(\\omega) = 0$$\n$$(|H(\\omega)|^2 + \\lambda) X(\\omega) - H(\\omega)^* Y(\\omega) = 0$$\nSolving for the optimal frequency-domain representation $\\widehat{X}(\\omega)$:\n$$(|H(\\omega)|^2 + \\lambda) \\widehat{X}(\\omega) = H(\\omega)^* Y(\\omega)$$\n$$\\widehat{X}(\\omega) = \\frac{H(\\omega)^*}{|H(\\omega)|^2 + \\lambda} Y(\\omega)$$\nThis is the general form of the solution in the frequency domain. The reconstruction filter $G(\\omega)$ is defined by the relation $\\widehat{X}(\\omega) = G(\\omega)Y(\\omega)$, so we can identify:\n$$G(\\omega) = \\frac{H(\\omega)^*}{|H(\\omega)|^2 + \\lambda}$$\nNow, we must compute this for the specific point-spread function $h[n] = \\frac{1}{3}(1, 1, 1)$, supported on $n = 0, 1, 2$. The DTFT $H(\\omega)$ is:\n$$H(\\omega) = \\sum_{n=0}^{2} \\frac{1}{3} \\exp(-\\mathrm{j}\\omega n) = \\frac{1}{3} (1 + \\exp(-\\mathrm{j}\\omega) + \\exp(-\\mathrm{j}2\\omega))$$\nThis is a geometric series. We can simplify it by factoring out a center phase term:\n$$H(\\omega) = \\frac{1}{3} \\exp(-\\mathrm{j}\\omega) (\\exp(\\mathrm{j}\\omega) + 1 + \\exp(-\\mathrm{j}\\omega))$$\nUsing the identity $2\\cos(\\omega) = \\exp(\\mathrm{j}\\omega) + \\exp(-\\mathrm{j}\\omega)$, we get:\n$$H(\\omega) = \\frac{1}{3} \\exp(-\\mathrm{j}\\omega) (1 + 2\\cos(\\omega))$$\nFrom this expression, we compute its complex conjugate $H(\\omega)^*$ and squared magnitude $|H(\\omega)|^2$:\n$$H(\\omega)^* = \\frac{1}{3} \\exp(\\mathrm{j}\\omega) (1 + 2\\cos(\\omega))$$\n$$|H(\\omega)|^2 = H(\\omega)H(\\omega)^* = \\left( \\frac{1}{3} \\exp(-\\mathrm{j}\\omega) (1 + 2\\cos(\\omega)) \\right) \\left( \\frac{1}{3} \\exp(\\mathrm{j}\\omega) (1 + 2\\cos(\\omega)) \\right) = \\frac{1}{9} (1 + 2\\cos(\\omega))^2$$\nSubstituting these into the expression for $G(\\omega)$:\n$$G(\\omega) = \\frac{\\frac{1}{3} \\exp(\\mathrm{j}\\omega) (1 + 2\\cos(\\omega))}{\\frac{1}{9}(1 + 2\\cos(\\omega))^2 + \\lambda}$$\nTo simplify, we multiply the numerator and denominator by $9$:\n$$G(\\omega) = \\frac{3 \\exp(\\mathrm{j}\\omega) (1 + 2\\cos(\\omega))}{(1+2\\cos(\\omega))^2 + 9\\lambda}$$\nThis is the final closed-form expression for the reconstruction filter $G(\\omega)$.\n\nFinally, we perform a qualitative analysis of this filter.\n\nMagnitude: The magnitude of the filter is:\n$$|G(\\omega)| = \\frac{3 |1 + 2\\cos(\\omega)|}{(1+2\\cos(\\omega))^2 + 9\\lambda}$$\nThe magnitude is zero when $1 + 2\\cos(\\omega) = 0$, which occurs at frequencies $\\omega = \\pm 2\\pi/3$. These are the frequencies where the forward filter $H(\\omega)$ has zeros, and no information about the signal at these frequencies can be recovered. The regularization correctly ensures the inverse filter also has zero gain at these frequencies.\n\nPhase: The phase of $G(\\omega)$ is determined by the term $ \\exp(\\mathrm{j}\\omega) (1 + 2\\cos(\\omega)) $. The denominator is always real and positive for $\\lambda > 0$.\nThe term $(1 + 2\\cos(\\omega))$ is real but can be negative.\n- When $1+2\\cos(\\omega) > 0$, which is for $|\\omega| < 2\\pi/3$, the phase of $G(\\omega)$ is $\\omega$.\n- When $1+2\\cos(\\omega) < 0$, which is for $2\\pi/3 < |\\omega| \\leq \\pi$, the term is negative, contributing a phase shift of $\\pi$. The phase of $G(\\omega)$ is $\\omega + \\pi$ (or $\\omega - \\pi$ to keep it in the principal range).\nThus, the filter exhibits phase reversals at the frequencies $\\omega = \\pm 2\\pi/3$.\n\nLimiting behaviors:\n- As $\\lambda \\to 0^{+}$ (no regularization):\n$$G(\\omega) \\to \\frac{3 \\exp(\\mathrm{j}\\omega) (1 + 2\\cos(\\omega))}{(1+2\\cos(\\omega))^2} = \\frac{3 \\exp(\\mathrm{j}\\omega)}{1+2\\cos(\\omega)} = \\frac{1}{H(\\omega)}$$\nThe filter approaches the naive inverse filter, which is unstable and amplifies noise infinitely at frequencies where $H(\\omega)$ is zero.\n- As $\\lambda \\to \\infty$ (strong regularization):\n$$G(\\omega) \\to 0$$\nThe filter gain tends to zero for all frequencies. This means the reconstructed signal $\\widehat{X}(\\omega) = G(\\omega)Y(\\omega)$ tends to zero, which gives $\\widehat{x}[n] = 0$. This is expected, as an infinite penalty on the signal's energy forces the solution to be the zero signal, irrespective of the measurements.", "answer": "$$\\boxed{\\frac{3 \\exp(\\mathrm{j}\\omega) (1 + 2\\cos(\\omega))}{(1+2\\cos(\\omega))^{2} + 9\\lambda}}$$", "id": "3370633"}, {"introduction": "While classic Tikhonov regularization favors smooth solutions, many physical phenomena are inherently sparse. This computational exercise introduces $\\ell_1$ regularization, a powerful tool for recovering sparse signals, applied to a wave-based source localization problem. You will implement the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA) [@problem_id:3370666] to solve the resulting LASSO optimization problem, gaining practical experience in bridging physical modeling with modern convex optimization techniques.", "problem": "Consider the one-dimensional wave propagation model in a homogeneous medium of constant wave speed $c$ on the interval $[0,L]$, with point sensors at the boundary locations $x=0$ and $x=L$. The unknown source distribution is assumed to be sparse and modeled as a sum of Dirac point sources $s(x) = \\sum_{j=1}^{J} a_j \\,\\delta(x - x_j)$, where the amplitudes $a_j$ are complex-valued and the positions $x_j$ lie on a given discrete spatial grid. The measured quantity is the frequency-domain trace at the boundary sensors obtained by applying a time-Fourier transform to the recorded time-domain signals. Let the angular frequency be denoted by $\\omega$ (expressed in radians per second). In the frequency domain, the field $u(x,\\omega)$ satisfies the one-dimensional Helmholtz equation with source term. For the purposes of this problem, model the mapping from the sparse source distribution to boundary sensor measurements using the free-space one-dimensional Green's function for the Helmholtz operator. For a given angular frequency $\\omega$, define $k = \\omega/c$. The frequency-domain measurement at a sensor location $x_m \\in \\{0,L\\}$ can then be modeled as the linear superposition\n$$\ny(x_m,\\omega) \\;=\\; \\sum_{j=1}^{J} a_j \\, G_\\omega\\left(|x_m - x_j|\\right),\n$$\nwhere\n$$\nG_\\omega(r) \\;=\\; \\frac{i}{2k}\\, e^{i k r},\n$$\nand $r$ is the distance from the source position to the sensor location. Under this model, stacking multiple angular frequencies $\\{\\omega_\\ell\\}_{\\ell=1}^{F}$ and both sensor locations into a single complex-valued measurement vector yields a linear system of the form\n$$\n\\mathbf{y} \\;=\\; \\mathbf{A}\\,\\mathbf{x} \\;+\\; \\boldsymbol{\\varepsilon},\n$$\nwhere $\\mathbf{x} \\in \\mathbb{C}^{N}$ is the unknown sparse vector of source amplitudes aligned to the $N$-point spatial grid, $\\mathbf{A} \\in \\mathbb{C}^{MF \\times N}$ is the forward operator with entries $A_{(\\ell,m),j} = G_{\\omega_\\ell}(|x_m - x_j|)$, $M=2$ is the number of sensors, and $\\boldsymbol{\\varepsilon}$ models additive complex noise in the measurements. The phase in $e^{i k r}$ is to be interpreted in radians.\n\nThe inverse source localization task is to recover the sparse vector $\\mathbf{x}$ and hence infer the support (grid positions) where the sources are located, together with their amplitudes, from noisy boundary measurements $\\mathbf{y}$. To stabilize the inversion and promote sparsity, use a Least Absolute Shrinkage and Selection Operator (LASSO) formulation, which seeks $\\widehat{\\mathbf{x}}$ by minimizing a convex penalized least-squares objective:\n$$\n\\widehat{\\mathbf{x}} \\;=\\; \\arg\\min_{\\mathbf{z}\\in\\mathbb{C}^{N}} \\;\\frac{1}{2}\\,\\|\\mathbf{A}\\,\\mathbf{z} - \\mathbf{y}\\|_2^2 \\;+\\; \\lambda \\,\\|\\mathbf{z}\\|_1,\n$$\nwhere $\\lambda > 0$ is the regularization parameter, $\\|\\cdot\\|_2$ is the Euclidean norm, and $\\|\\cdot\\|_1$ is the entrywise $\\ell_1$ norm defined for complex vectors by $\\|\\mathbf{z}\\|_1 = \\sum_{j=1}^{N} |z_j|$.\n\nImplement a solver based on the proximal gradient principle (using the Fast Iterative Shrinkage-Thresholding Algorithm (FISTA)) for the above objective. Use multiple angular frequencies to improve conditioning (multi-frequency stabilization), and estimate the largest eigenvalue of $\\mathbf{A}^*\\mathbf{A}$, where $\\mathbf{A}^*$ denotes the conjugate transpose, via power iteration to set the gradient step size. Use a complex-valued soft-thresholding operator $S_\\tau(z)$ acting entrywise, defined by $S_\\tau(0)=0$ and\n$$\nS_\\tau(z) \\;=\\; \\max\\{ |z| - \\tau, \\, 0 \\}\\,\\frac{z}{|z|} \\quad \\text{for } z\\neq 0.\n$$\n\nNoise model: add independent identically distributed complex Gaussian noise to $\\mathbf{y}$, where the real and imaginary parts of each component have standard deviation $\\sigma$ determined by a relative noise level parameter $\\eta$ via $\\sigma = \\eta \\cdot \\operatorname{median}(|\\mathbf{y}_\\text{clean}|)$, with $\\mathbf{y}_\\text{clean} = \\mathbf{A}\\,\\mathbf{x}_\\text{true}$ denoting the noiseless measurement vector; if $\\operatorname{median}(|\\mathbf{y}_\\text{clean}|) = 0$, then set $\\sigma = \\eta$.\n\nDetection and scoring: declare a recovered source at grid index $j$ if $|\\widehat{x}_j| \\ge \\tau_\\text{det}$ for a specified detection threshold $\\tau_\\text{det}$. A recovered source is counted as a match to a true source if the grid index differs by at most $1$ from a true source index. For matched sources, compute the mean absolute position error in meters and the mean absolute amplitude error using $|\\,|\\widehat{x}_j| - |x^\\text{true}_j|\\,|$, where $x^\\text{true}_j$ is the true amplitude at the matched grid index. Also compute the number of false positives, defined as the number of recovered sources that do not match any true source under the above criterion. Report the integer count of matched sources, the mean position error in meters, the mean amplitude error (unitless), and the integer count of false positives, in that order, for each test case.\n\nUnits: express positions in meters, wave speed in meters per second, angular frequencies in radians per second, and time in seconds. The mean position error must be reported in meters. The amplitude error is unitless. No angles other than the phase $k r$ appear, and they are interpreted in radians.\n\nYour program must implement the above model and solver and run the following test suite. For each test case, use a uniform spatial grid with $N=101$ points spanning $[0,L]$ inclusive, two sensors at $x=0$ and $x=L$, and the specified parameters. Use a maximum of $T=800$ FISTA iterations, initialize the algorithm at the zero vector, and use a fixed random seed of $12345$ for noise generation to ensure reproducibility.\n\nTest Suite:\n- Case $1$ (two well-separated sources, moderate noise, multi-frequency):\n  - $L = 1.0$ meters, $c = 1.0$ meters per second.\n  - Angular frequencies $\\omega \\in \\{10.0,\\,20.0,\\,30.0,\\,40.0,\\,50.0\\}$ radians per second.\n  - True source positions $x_1 = 0.25$ meters, $x_2 = 0.75$ meters; amplitudes $a_1 = 1.0$, $a_2 = 0.7$ (unitless), aligned to the nearest grid points.\n  - Noise level $\\eta = 0.05$, regularization parameter $\\lambda = 0.05$, detection threshold $\\tau_\\text{det} = 0.20$.\n- Case $2$ (single near-boundary source, fewer frequencies, higher noise):\n  - $L = 1.0$ meters, $c = 1.0$ meters per second.\n  - Angular frequencies $\\omega \\in \\{5.0,\\,10.0,\\,15.0\\}$ radians per second.\n  - True source position $x_1 = 0.02$ meters; amplitude $a_1 = 1.0$ (unitless), aligned to the nearest grid point.\n  - Noise level $\\eta = 0.10$, regularization parameter $\\lambda = 0.08$, detection threshold $\\tau_\\text{det} = 0.25$.\n- Case $3$ (no sources, moderate noise, stronger regularization):\n  - $L = 1.0$ meters, $c = 1.0$ meters per second.\n  - Angular frequencies $\\omega \\in \\{10.0,\\,20.0,\\,30.0\\}$ radians per second.\n  - No sources (i.e., $\\mathbf{x}_\\text{true} = \\mathbf{0}$).\n  - Noise level $\\eta = 0.05$, regularization parameter $\\lambda = 0.10$, detection threshold $\\tau_\\text{det} = 0.25$.\n- Case $4$ (two closely spaced sources, higher frequencies, low noise):\n  - $L = 1.0$ meters, $c = 1.0$ meters per second.\n  - Angular frequencies $\\omega \\in \\{60.0,\\,80.0,\\,100.0,\\,120.0\\}$ radians per second.\n  - True source positions $x_1 = 0.49$ meters, $x_2 = 0.51$ meters; amplitudes $a_1 = 1.0$, $a_2 = 0.8$ (unitless), aligned to the nearest grid points.\n  - Noise level $\\eta = 0.02$, regularization parameter $\\lambda = 0.04$, detection threshold $\\tau_\\text{det} = 0.15$.\n\nFor each test case, compute and return a list containing four quantities: the integer number of matched sources, the mean absolute position error in meters (as a float), the mean absolute amplitude error (as a float), and the integer number of false positives. Your program should produce a single line of output containing the results for all four test cases as a comma-separated list of these per-case lists, enclosed in square brackets, with no embedded spaces. For example, a valid output format would be $[[1,0.01,0.05,0],[\\dots]]$ (numbers shown only for illustration and not as the actual answers).", "solution": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the inverse source localization problem.\n    \"\"\"\n\n    test_cases = [\n        # Case 1\n        {\n            \"L\": 1.0, \"c\": 1.0, \"N\": 101,\n            \"omegas\": [10.0, 20.0, 30.0, 40.0, 50.0],\n            \"true_sources\": [(0.25, 1.0), (0.75, 0.7)],\n            \"eta\": 0.05, \"lambda_reg\": 0.05, \"tau_det\": 0.20,\n            \"T\": 800, \"seed\": 12345\n        },\n        # Case 2\n        {\n            \"L\": 1.0, \"c\": 1.0, \"N\": 101,\n            \"omegas\": [5.0, 10.0, 15.0],\n            \"true_sources\": [(0.02, 1.0)],\n            \"eta\": 0.10, \"lambda_reg\": 0.08, \"tau_det\": 0.25,\n            \"T\": 800, \"seed\": 12345\n        },\n        # Case 3\n        {\n            \"L\": 1.0, \"c\": 1.0, \"N\": 101,\n            \"omegas\": [10.0, 20.0, 30.0],\n            \"true_sources\": [],\n            \"eta\": 0.05, \"lambda_reg\": 0.10, \"tau_det\": 0.25,\n            \"T\": 800, \"seed\": 12345\n        },\n        # Case 4\n        {\n            \"L\": 1.0, \"c\": 1.0, \"N\": 101,\n            \"omegas\": [60.0, 80.0, 100.0, 120.0],\n            \"true_sources\": [(0.49, 1.0), (0.51, 0.8)],\n            \"eta\": 0.02, \"lambda_reg\": 0.04, \"tau_det\": 0.15,\n            \"T\": 800, \"seed\": 12345\n        }\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = run_case(params)\n        all_results.append(result)\n\n    list_of_strings = [str(r).replace(' ', '') for r in all_results]\n    print(f\"[{','.join(list_of_strings)}]\")\n\ndef run_case(params):\n    \"\"\"\n    Executes a single test case for the source localization problem.\n    \"\"\"\n    L, c, N = params[\"L\"], params[\"c\"], params[\"N\"]\n    omegas = np.array(params[\"omegas\"])\n    true_sources = params[\"true_sources\"]\n    eta, lambda_reg, tau_det = params[\"eta\"], params[\"lambda_reg\"], params[\"tau_det\"]\n    T_max = params[\"T\"]\n    seed = params[\"seed\"]\n    \n    # Setup grid and sensors\n    grid = np.linspace(0, L, N)\n    sensor_pos = np.array([0.0, L])\n    M = len(sensor_pos)\n    F = len(omegas)\n\n    # Construct true source vector x_true\n    x_true = np.zeros(N, dtype=complex)\n    for pos, amp in true_sources:\n        idx = np.argmin(np.abs(grid - pos))\n        x_true[idx] = amp\n\n    # Construct forward operator A\n    A = np.zeros((M * F, N), dtype=complex)\n    for i_f, omega in enumerate(omegas):\n        k = omega / c\n        if k == 0: continue\n        \n        G_func = lambda r: (1j / (2 * k)) * np.exp(1j * k * r)\n        \n        for i_m, xm in enumerate(sensor_pos):\n            row_idx = i_f * M + i_m\n            r_vec = np.abs(xm - grid)\n            A[row_idx, :] = G_func(r_vec)\n    \n    # Generate noisy measurement vector y\n    y_clean = A @ x_true\n    \n    median_abs_y = np.median(np.abs(y_clean)) if len(y_clean) > 0 else 0.0\n    sigma = eta * median_abs_y if median_abs_y > 0 else eta\n        \n    rng = np.random.RandomState(seed)\n    noise = sigma * (rng.randn(M * F) + 1j * rng.randn(M * F))\n    y = y_clean + noise\n\n    # Solve with FISTA\n    x_hat = fista_solver(A, y, lambda_reg, T_max, rng)\n\n    # Evaluate results\n    true_indices = np.where(np.abs(x_true) > 1e-9)[0]\n    detected_indices = np.where(np.abs(x_hat) >= tau_det)[0]\n\n    matched_pairs = []\n    used_detections = set()\n\n    for jt in sorted(list(true_indices)):\n        candidates = [jd for jd in detected_indices if abs(jd - jt) = 1 and jd not in used_detections]\n        if candidates:\n            # Find the best match (closest in index) and mark it as used\n            closest_jd = min(candidates, key=lambda jd: abs(jd - jt))\n            matched_pairs.append((jt, closest_jd))\n            used_detections.add(closest_jd)\n            \n    num_matched = len(matched_pairs)\n    num_fp = len(detected_indices) - len(used_detections)\n\n    pos_errors = []\n    amp_errors = []\n    if num_matched > 0:\n        for jt, jd in matched_pairs:\n            pos_errors.append(np.abs(grid[jd] - grid[jt]))\n            amp_errors.append(np.abs(np.abs(x_hat[jd]) - np.abs(x_true[jt])))\n\n    mean_pos_err = np.mean(pos_errors) if pos_errors else 0.0\n    mean_amp_err = np.mean(amp_errors) if amp_errors else 0.0\n\n    return [num_matched, mean_pos_err, mean_amp_err, num_fp]\n\ndef soft_thresholding(z, tau):\n    \"\"\"Complex-valued soft-thresholding operator.\"\"\"\n    abs_z = np.abs(z)\n    shrunk_abs = np.maximum(abs_z - tau, 0.0)\n    \n    # Handle division by zero for elements where abs_z is 0\n    unit_z = np.divide(z, abs_z, out=np.zeros_like(z, dtype=complex), where=abs_z != 0)\n    \n    return shrunk_abs * unit_z\n\ndef fista_solver(A, y, lambda_reg, T_max, rng):\n    \"\"\"\n    Solves the LASSO problem using the FISTA algorithm.\n    \"\"\"\n    N = A.shape[1]\n\n    # Estimate Lipschitz constant via power iteration\n    B = A.conj().T @ A\n    v = rng.randn(N) + 1j * rng.randn(N)\n    v /= np.linalg.norm(v)\n    for _ in range(20): # Power iterations\n        Bv = B @ v\n        v = Bv / np.linalg.norm(Bv)\n    \n    L_f = np.real(v.conj().T @ B @ v)\n    alpha = 1.0 / L_f if L_f > 0 else 1.0\n\n    # FISTA iteration\n    x_k = np.zeros(N, dtype=complex)\n    x_km1 = np.zeros(N, dtype=complex)\n    t_k = 1.0\n    t_km1 = 1.0\n    \n    for _ in range(T_max):\n        y_k = x_k + ((t_km1 - 1.0) / t_k) * (x_k - x_km1)\n        grad_y_k = A.conj().T @ (A @ y_k - y)\n        x_kp1 = soft_thresholding(y_k - alpha * grad_y_k, lambda_reg * alpha)\n        \n        t_kp1 = (1.0 + np.sqrt(1.0 + 4.0 * t_k**2)) / 2.0\n        \n        # Update state for next iteration\n        x_km1 = x_k\n        x_k = x_kp1\n        t_km1 = t_k\n        t_k = t_kp1\n        \n    return x_k\n\nif __name__ == '__main__':\n    solve()\n```", "answer": "[[2,0.0,0.0827299003507008,0],[1,0.0,0.05739371755106889,0],[0,0.0,0.0,0],[2,0.0,0.03828994511516805,0]]", "id": "3370666"}]}