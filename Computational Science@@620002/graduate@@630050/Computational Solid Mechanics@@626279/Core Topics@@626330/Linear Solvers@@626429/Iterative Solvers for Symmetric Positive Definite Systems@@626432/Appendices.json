{"hands_on_practices": [{"introduction": "This first practice is a fundamental, code-based exercise designed to build a Preconditioned Conjugate Gradient (PCG) solver from first principles. By constructing the classic 5-point Laplacian matrix and implementing an Incomplete Cholesky (IC(0)) preconditioner, you will gain direct experience with the core mechanics of one of the most important iterative methods in computational mechanics [@problem_id:3576531]. This exercise solidifies the step-by-step logic of the PCG algorithm and the process of applying a preconditioner.", "problem": "Consider the linear system arising in computational solid mechanics from the discrete Poisson operator with homogeneous Dirichlet boundary conditions on a two-dimensional grid. The discrete problem is symmetric positive definite, as it results from minimizing the quadratic potential energy over a finite-dimensional subspace. Let $n$ denote the number of interior points per coordinate direction and let $N = n^2$ denote the total number of degrees of freedom. Use $n = 4$, so $N = 16$. Adopt lexicographic (row-major) ordering: for grid indices $(i,j)$ with $i \\in \\{0,1,2,3\\}$ and $j \\in \\{0,1,2,3\\}$, map to a vector index $k = j \\cdot n + i$. Assemble the $N \\times N$ stiffness matrix $A$ corresponding to the $5$-point stencil for the negative Laplacian without the mesh-size scaling, that is, for each interior node, the discrete operator is $4$ times the node value minus the values of its immediate neighbors in the $\\pm x$ and $\\pm y$ directions (when those neighbors exist). Explicitly, for all $k$, set $A_{k,k} = 4$, and for each pair of neighboring nodes in the grid graph, set the corresponding off-diagonal entries to $-1$; all other entries are $0$. This $A$ is symmetric positive definite.\n\nDefine the incomplete Cholesky preconditioner with zero fill, denoted $\\mathrm{IC}(0)$, computed in natural ordering, as follows. Seek a lower triangular matrix $L$ such that $L L^\\top \\approx A$, with the constraint that for each $i > j$, the entry $L_{i,j}$ is nonzero if and only if $A_{i,j} \\neq 0$, and $L_{i,i} > 0$ for all $i$. The factor $L$ is computed by the recurrence obtained from exact Cholesky while discarding all fill that is not present in the lower-triangular sparsity pattern of $A$:\n- For $i = 0,1,\\dots,N-1$ and for each $j < i$ with $A_{i,j} \\neq 0$,\n$$\nL_{i,j} = \\frac{1}{L_{j,j}} \\left(A_{i,j} - \\sum_{k=0}^{j-1} \\mathbf{1}_{A_{i,k} \\neq 0} \\, \\mathbf{1}_{A_{j,k} \\neq 0} \\, L_{i,k} L_{j,k}\\right),\n$$\nand the diagonal is\n$$\nL_{i,i} = \\sqrt{A_{i,i} - \\sum_{k=0}^{i-1} \\mathbf{1}_{A_{i,k} \\neq 0} \\, L_{i,k}^2}.\n$$\nHere $\\mathbf{1}_{\\cdot}$ denotes the indicator function.\n\nConsider the preconditioned conjugate gradient (PCG) method applied to $A \\mathbf{x} = \\mathbf{b}$ with preconditioner $M = L L^\\top$ and the initial guess $\\mathbf{x}_0 = \\mathbf{0}$. One step of PCG is defined by:\n- Residual: $\\mathbf{r}_0 = \\mathbf{b} - A \\mathbf{x}_0 = \\mathbf{b}$.\n- Preconditioned residual: solve $M \\mathbf{z}_0 = \\mathbf{r}_0$ for $\\mathbf{z}_0$ using forward substitution with $L$ followed by backward substitution with $L^\\top$.\n- Search direction: $\\mathbf{p}_0 = \\mathbf{z}_0$.\n- Step length:\n$$\n\\alpha_0 = \\frac{\\mathbf{r}_0^\\top \\mathbf{z}_0}{\\mathbf{p}_0^\\top A \\mathbf{p}_0}.\n$$\n- Updated iterate: $\\mathbf{x}_1 = \\mathbf{x}_0 + \\alpha_0 \\mathbf{p}_0$.\n- Updated residual: $\\mathbf{r}_1 = \\mathbf{r}_0 - \\alpha_0 A \\mathbf{p}_0$.\n- Updated preconditioned residual: solve $M \\mathbf{z}_1 = \\mathbf{r}_1$ for $\\mathbf{z}_1$.\n\nYour task is to compute the ratio of preconditioned residual norms after one PCG iteration, namely $||\\mathbf{z}_1||_2 / ||\\mathbf{z}_0||_2$, for each right-hand side vector $\\mathbf{b}$ in the following test suite. In all cases, use the $A$ and $\\mathrm{IC}(0)$ described above and the initial guess $\\mathbf{x}_0 = \\mathbf{0}$. No physical units are required. All angles appearing in trigonometric definitions are in radians.\n\nTest suite (with $n = 4$, $N = 16$ and the index mapping $k = j \\cdot n + i$):\n- Case A (general behavior): $\\mathbf{b}^{(A)}$ is the all-ones vector in $\\mathbb{R}^{16}$, i.e., $b^{(A)}_k = 1$ for all $k \\in \\{0,1,\\dots,15\\}$.\n- Case B (localized load): $\\mathbf{b}^{(B)}$ is the unit vector at the index corresponding to $(i,j) = (1,1)$, i.e., $b^{(B)}_k = 1$ if $k = 5$ and $b^{(B)}_k = 0$ otherwise.\n- Case C (harmonic load): $\\mathbf{b}^{(C)}$ is defined pointwise by\n$$\nb^{(C)}_{j \\cdot n + i} = \\sin\\!\\left(\\pi \\frac{i+1}{n+1}\\right)\\, \\sin\\!\\left(2\\pi \\frac{j+1}{n+1}\\right),\n$$\nfor $i,j \\in \\{0,1,2,3\\}$.\n- Case D (deterministic oscillatory sequence): $\\mathbf{b}^{(D)}$ has entries\n$$\nb^{(D)}_{k} = \\sin\\!\\left(\\frac{k+1}{3}\\right) + \\frac{1}{2}\\cos\\!\\left(\\frac{k+1}{5}\\right),\n$$\nfor $k \\in \\{0,1,2,\\dots,15\\}$.\n\nYour program must:\n- Construct $A$ exactly as specified (with $4$ on the diagonal, $-1$ on nearest-neighbor off-diagonals, and no $1/h^2$ scaling).\n- Compute the $\\mathrm{IC}(0)$ preconditioner $L$ in natural ordering using the formulas given.\n- For each case, perform exactly one PCG iteration starting from $\\mathbf{x}_0 = \\mathbf{0}$ and compute the ratio $||\\mathbf{z}_1||_2 / ||\\mathbf{z}_0||_2$.\n- Round each ratio to $12$ decimal places.\n\nFinal output format:\n- Produce a single line of output containing the four rounded ratios for Cases A, B, C, and D, in that order, as a comma-separated list enclosed in square brackets, for example, `[r_A,r_B,r_C,r_D]`, where each $r_{\\cdot}$ is a decimal numeral with exactly $12$ digits after the decimal point.", "solution": "The user has provided a well-defined computational problem in the field of numerical linear algebra, specifically concerning iterative solvers for systems arising from the discretization of partial differential equations. The problem is to be validated for correctness and solvability before a solution is presented.\n\n### Problem Validation\n\n**Step 1: Extracted Givens**\n\n-   **Problem Domain**: Computational solid mechanics, discrete Poisson operator on a 2D grid with homogeneous Dirichlet boundary conditions. The resulting linear system is symmetric positive definite (SPD).\n-   **Grid and System Size**: $n=4$ interior points per direction, leading to a total of $N = n^2 = 16$ degrees of freedom.\n-   **Node Indexing**: Lexicographic (row-major) ordering: $k = j \\cdot n + i$ for grid indices $i, j \\in \\{0, 1, 2, 3\\}$.\n-   **Stiffness Matrix $A$ ($16 \\times 16$)**:\n    -   $A_{k,k} = 4$ for all $k$.\n    -   $A_{k,m} = -1$ if nodes $k$ and $m$ are immediate neighbors in the grid.\n    -   All other entries are $0$.\n-   **Preconditioner**: Incomplete Cholesky factorization with zero fill-in, $\\mathrm{IC}(0)$, given by $M = LL^\\top$. The lower triangular factor $L$ must satisfy:\n    -   Sparsity Pattern: For $i > j$, $L_{i,j} \\neq 0$ if and only if $A_{i,j} \\neq 0$.\n    -   Off-Diagonal Computation ($i > j, A_{i,j} \\neq 0$): $L_{i,j} = \\frac{1}{L_{j,j}} \\left(A_{i,j} - \\sum_{k=0}^{j-1} \\mathbf{1}_{A_{i,k} \\neq 0} \\, \\mathbf{1}_{A_{j,k} \\neq 0} \\, L_{i,k} L_{j,k}\\right)$.\n    -   Diagonal Computation: $L_{i,i} = \\sqrt{A_{i,i} - \\sum_{k=0}^{i-1} \\mathbf{1}_{A_{i,k} \\neq 0} \\, L_{i,k}^2}$.\n-   **Solver**: One iteration of the Preconditioned Conjugate Gradient (PCG) method for $A \\mathbf{x} = \\mathbf{b}$, starting with $\\mathbf{x}_0 = \\mathbf{0}$.\n-   **PCG Step-by-Step Definition**:\n    1.  $\\mathbf{r}_0 = \\mathbf{b} - A \\mathbf{x}_0 = \\mathbf{b}$.\n    2.  Solve $M \\mathbf{z}_0 = \\mathbf{r}_0$ for $\\mathbf{z}_0$ (via forward and backward substitution with $L, L^\\top$).\n    3.  $\\mathbf{p}_0 = \\mathbf{z}_0$.\n    4.  $\\alpha_0 = (\\mathbf{r}_0^\\top \\mathbf{z}_0) / (\\mathbf{p}_0^\\top A \\mathbf{p}_0)$.\n    5.  $\\mathbf{x}_1 = \\mathbf{x}_0 + \\alpha_0 \\mathbf{p}_0$.\n    6.  $\\mathbf{r}_1 = \\mathbf{r}_0 - \\alpha_0 A \\mathbf{p}_0$.\n    7.  Solve $M \\mathbf{z}_1 = \\mathbf{r}_1$ for $\\mathbf{z}_1$.\n-   **Objective**: Compute the ratio of preconditioned residual norms $||\\mathbf{z}_1||_2 / ||\\mathbf{z}_0||_2$.\n-   **Test Suite of Right-Hand Sides $\\mathbf{b}$**:\n    -   **Case A**: $b^{(A)}_k = 1$ for all $k$.\n    -   **Case B**: $b^{(B)}_k = \\delta_{k,5}$ where $k=5$ corresponds to grid point $(i,j)=(1,1)$.\n    -   **Case C**: $b^{(C)}_{j \\cdot 4 + i} = \\sin(\\pi \\frac{i+1}{5}) \\sin(2\\pi \\frac{j+1}{5})$.\n    -   **Case D**: $b^{(D)}_k = \\sin((k+1)/3) + 0.5 \\cos((k+1)/5)$.\n-   **Output Requirement**: A single line with a list of four ratios (for cases A, B, C, D), each rounded to $12$ decimal places.\n\n**Step 2: Validation of Extracted Givens**\n\n-   **Scientific Groundedness**: The problem is fundamentally sound. It involves the numerical solution of a discretized elliptic PDE using standard, well-established methods (finite differences, PCG, IC(0) preconditioning). These techniques are cornerstones of computational science and engineering.\n-   **Well-Posedness**: The problem is well-posed. The matrix $A$ corresponding to the 5-point discrete Laplacian on a regular grid with Dirichlet conditions is a symmetric, weakly chained diagonally dominant M-matrix. For such matrices, it is a known result that the $\\mathrm{IC}(0)$ factorization exists and yields a positive definite preconditioner $M$. The PCG algorithm is deterministic, and all inputs are defined without ambiguity, ensuring a unique computable result.\n-   **Objectivity**: The problem is stated using precise, formal mathematical language. It is free from subjective claims or interpretations.\n\nThe problem does not exhibit any of the invalidity flaws. It is scientifically sound, fully specified, self-contained, and computationally feasible.\n\n**Step 3: Verdict and Action**\n\nThe problem is **valid**. A solution will be provided.\n\n### Principle-Based Design of the Solution\n\nThe solution is a direct, systematic implementation of the algorithms and definitions provided in the problem statement. The process is broken down into four main stages:\n\n1.  **Assembly of the Stiffness Matrix $A$**:\n    The $N \\times N$ matrix $A$ with $N=16$ is constructed according to the 5-point stencil rule and lexicographic indexing. For each node $k$ corresponding to grid point $(i,j)$, the diagonal entry $A_{k,k}$ is set to $4$. Off-diagonal entries $A_{k,m}$ are set to $-1$ if node $m$ corresponds to one of the valid grid neighbors $(i \\pm 1, j)$ or $(i, j \\pm 1)$. All other entries are zero. This results in a sparse, symmetric, block-tridiagonal matrix.\n\n2.  **Computation of the IC(0) Preconditioner Factor $L$**:\n    The lower triangular matrix $L$ is computed row-by-row, from $i=0$ to $N-1$. A key insight simplifies the computation of off-diagonal elements $L_{i,j}$. The formula is:\n    $$L_{i,j} = \\frac{1}{L_{j,j}} \\left(A_{i,j} - \\sum_{k=0}^{j-1} \\mathbf{1}_{A_{i,k} \\neq 0} \\, \\mathbf{1}_{A_{j,k} \\neq 0} \\, L_{i,k} L_{j,k}\\right)$$\n    The summation term is non-zero only if nodes $i$ and $j$ share a common neighbor $k$ (where the \"neighbor\" relationship is defined by the non-zero pattern of $A$). For the 5-point stencil on a rectangular grid, the corresponding graph is bipartite and contains no odd cycles, specifically no cycles of length 3 (triangles). If $A_{i,j} \\neq 0$, nodes $i$ and $j$ are neighbors and cannot have a common neighbor. Therefore, the summation term is always zero. This simplifies the formula for off-diagonal elements significantly:\n    $$L_{i,j} = \\frac{A_{i,j}}{L_{j,j}} \\quad (\\text{for } i>j, A_{i,j} \\neq 0)$$\n    The diagonal elements are computed using the provided formula, where the sum is taken over the non-zero entries in the current row of $L$ that have already been computed:\n    $$L_{i,i} = \\sqrt{A_{i,i} - \\sum_{k=0}^{i-1, A_{i,k} \\neq 0} L_{i,k}^2}$$\n    The computation proceeds by iterating through rows $i=0, \\dots, N-1$ and, for each row, computing the non-zero off-diagonals $L_{i,j}$ ($j<i$) first, followed by the diagonal $L_{i,i}$.\n\n3.  **Execution of One PCG Iteration**:\n    For each of the four test cases, specified by the vector $\\mathbf{b}$, a single iteration of the PCG algorithm is performed.\n    -   The initial residual is $\\mathbf{r}_0 = \\mathbf{b}$ since $\\mathbf{x}_0 = \\mathbf{0}$.\n    -   The preconditioned residual $\\mathbf{z}_0$ is found by solving the system $M\\mathbf{z}_0 = \\mathbf{r}_0$, which is $LL^\\top \\mathbf{z}_0 = \\mathbf{r}_0$. This is done in two steps: first, solve $L\\mathbf{y}_0 = \\mathbf{r}_0$ for $\\mathbf{y}_0$ using forward substitution; second, solve $L^\\top\\mathbf{z}_0 = \\mathbf{y}_0$ for $\\mathbf{z}_0$ using backward substitution.\n    -   The search direction is set to $\\mathbf{p}_0 = \\mathbf{z}_0$.\n    -   The step length $\\alpha_0$ and the updated residual $\\mathbf{r}_1$ are computed as per the specified formulas.\n    -   Finally, the new preconditioned residual $\\mathbf{z}_1$ is computed by solving $M\\mathbf{z}_1 = \\mathbf{r}_1$, again using forward and backward substitution.\n\n4.  **Calculation of the Final Ratio**:\n    After one full iteration, the Euclidean norms (L2 norms) of the vectors $\\mathbf{z}_0$ and $\\mathbf{z}_1$ are computed. The final result for each case is the ratio $||\\mathbf{z}_1||_2 / ||\\mathbf{z}_0||_2$, which is then rounded to $12$ decimal places as required. The four results are collected and formatted into the specified output string.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef create_A_matrix(n, N):\n    \"\"\"\n    Assembles the stiffness matrix A for the 2D Poisson problem.\n    \"\"\"\n    A = np.zeros((N, N), dtype=float)\n    for k in range(N):\n        A[k, k] = 4.0\n        i, j = k % n, k // n\n        # Neighbor to the left\n        if i > 0:\n            A[k, k - 1] = -1.0\n        # Neighbor to the right\n        if i < n - 1:\n            A[k, k + 1] = -1.0\n        # Neighbor above\n        if j > 0:\n            A[k, k - n] = -1.0\n        # Neighbor below\n        if j < n - 1:\n            A[k, k + n] = -1.0\n    return A\n\ndef compute_ic0_factor(A, N):\n    \"\"\"\n    Computes the Incomplete Cholesky factorization with zero fill-in (IC(0)).\n    \"\"\"\n    L = np.zeros((N, N), dtype=float)\n    for i in range(N):\n        # Calculate off-diagonal values in row i first\n        for j in range(i):\n            if A[i, j] != 0:\n                # The summation term in the problem's formula for L_ij is zero\n                # for a 5-point stencil grid graph, as adjacent nodes (where A_ij != 0)\n                # do not share a common neighbor.\n                sum_term = 0.0\n                L[i, j] = (A[i, j] - sum_term) / L[j, j]\n        \n        # Calculate diagonal value for row i\n        sum_diag_sq = 0.0\n        for k in range(i):\n            if A[i, k] != 0:\n                sum_diag_sq += L[i,k]**2\n        \n        val_under_sqrt = A[i, i] - sum_diag_sq\n        L[i, i] = np.sqrt(val_under_sqrt)\n    return L\n\ndef solve_forward_sub(L, b):\n    \"\"\"\n    Solves the lower triangular system Lx = b using forward substitution.\n    \"\"\"\n    n = L.shape[0]\n    x = np.zeros(n)\n    for i in range(n):\n        s = np.dot(L[i, :i], x[:i])\n        x[i] = (b[i] - s) / L[i, i]\n    return x\n\ndef solve_backward_sub(Lt, b):\n    \"\"\"\n    Solves the upper triangular system L^T x = b using backward substitution.\n    \"\"\"\n    n = Lt.shape[0]\n    x = np.zeros(n)\n    for i in range(n - 1, -1, -1):\n        s = np.dot(Lt[i, i + 1:], x[i + 1:])\n        x[i] = (b[i] - s) / Lt[i, i]\n    return x\n\ndef solve_preconditioner(L, r):\n    \"\"\"\n    Solves the preconditioner system Mz = r, where M = LL^T.\n    \"\"\"\n    # Step 1: Solve Ly = r for y (forward substitution)\n    y = solve_forward_sub(L, r)\n    # Step 2: Solve L^T z = y for z (backward substitution)\n    z = solve_backward_sub(L.T, y)\n    return z\n\ndef run_pcg_one_step_and_get_ratio(A, L, b):\n    \"\"\"\n    Performs one PCG iteration and computes the ratio of preconditioned residual norms.\n    \"\"\"\n    N = A.shape[0]\n    \n    # Initial guess x_0 = 0\n    x0 = np.zeros(N)\n    \n    # r_0 = b - A x_0 = b\n    r0 = b\n    \n    # Solve M z_0 = r_0\n    z0 = solve_preconditioner(L, r0)\n    \n    # p_0 = z_0\n    p0 = z0\n    \n    # alpha_0 = (r_0^T z_0) / (p_0^T A p_0)\n    Ap0 = A @ p0\n    alpha0 = np.dot(r0, z0) / np.dot(p0, Ap0)\n    \n    # r_1 = r_0 - alpha_0 A p_0\n    r1 = r0 - alpha0 * Ap0\n    \n    # Solve M z_1 = r_1\n    z1 = solve_preconditioner(L, r1)\n    \n    # Compute the ratio ||z_1||_2 / ||z_0||_2\n    norm_z0 = np.linalg.norm(z0)\n    norm_z1 = np.linalg.norm(z1)\n    \n    if norm_z0 == 0:\n        return 0.0\n\n    return norm_z1 / norm_z0\n\ndef solve():\n    # Define problem parameters\n    n = 4\n    N = n**2\n\n    # Assemble the stiffness matrix A\n    A = create_A_matrix(n, N)\n    \n    # Compute the IC(0) preconditioner factor L\n    L = compute_ic0_factor(A, N)\n\n    # Define the test cases (right-hand side vectors b)\n    # Case A: All-ones vector\n    b_A = np.ones(N)\n    \n    # Case B: Localized load at (i=1, j=1) -> k = 1*4+1 = 5\n    b_B = np.zeros(N)\n    b_B[n * 1 + 1] = 1.0\n    \n    # Case C: Harmonic load\n    b_C = np.zeros(N)\n    for j in range(n):\n        for i in range(n):\n            k = j * n + i\n            b_C[k] = np.sin(np.pi * (i + 1) / (n + 1)) * \\\n                     np.sin(2 * np.pi * (j + 1) / (n + 1))\n                     \n    # Case D: Deterministic oscillatory sequence\n    k_vals = np.arange(N)\n    b_D = np.sin((k_vals + 1) / 3.0) + 0.5 * np.cos((k_vals + 1) / 5.0)\n    \n    test_cases = [b_A, b_B, b_C, b_D]\n\n    # Calculate the ratio for each test case\n    results = []\n    for b in test_cases:\n        ratio = run_pcg_one_step_and_get_ratio(A, L, b)\n        results.append(ratio)\n\n    # Format and print the final output\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```", "id": "3576531"}, {"introduction": "Moving from pure algorithmics to application, this exercise explores the crucial link between the properties of a physical system and the performance of an iterative solver. You will investigate how augmenting a finite element stiffness matrix with a mass regularization term—a technique often used in quasi-static and dynamic analyses—affects the convergence of the Conjugate Gradient (CG) method [@problem_id:3576538]. This practice provides a concrete illustration of how modifying a matrix's spectral properties, specifically its condition number, directly impacts solver efficiency.", "problem": "Construct a quasi-static one-dimensional linear elasticity model for a bar using the Finite Element Method (FEM) with linear shape functions. Let the bar have nondimensionalized parameters: Young's modulus $E=1$, cross-sectional area $A=1$, mass density $\\rho=1$, and length $L=1$. Discretize the bar into $n_e$ equal linear elements of size $h=L/n_e$ with nodes indexed from $0$ to $n_e$. Impose a Dirichlet boundary condition at node $0$ such that the displacement $u(0)=0$. Apply a uniform nondimensionalized body force $q=1$ along the bar by assembling its consistent nodal load contributions.\n\nThe fundamental base is the quasi-static balance of linear momentum in one dimension with small strains, which in strong form is given by the equilibrium equation\n$$\n\\frac{d}{dx}\\left( E A \\frac{du}{dx} \\right) + q = 0.\n$$\nIn the standard Galerkin finite element discretization with linear shape functions, the element stiffness matrix and element consistent mass matrix are\n$$\n\\mathbf{k}_e = \\frac{E A}{h} \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}, \\quad\n\\mathbf{m}_e = \\frac{\\rho A h}{6} \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix},\n$$\nand the element consistent nodal load vector under a uniform body force $q$ is\n$$\n\\mathbf{f}_e = \\frac{q A h}{2} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}.\n$$\nAfter assembly and application of the Dirichlet boundary condition at node $0$, the global stiffness matrix $\\mathbf{K}$ and global mass matrix $\\mathbf{M}$ are symmetric positive definite (SPD) on the free degrees of freedom. Consider augmenting the quasi-static operator with a nondimensional mass regularization term $\\alpha \\mathbf{M}$ and define\n$$\n\\mathbf{K}_\\alpha = \\mathbf{K} + \\alpha \\mathbf{M},\n$$\nwhere $\\alpha \\ge 0$ is a scalar parameter. You must show that $\\mathbf{K}_\\alpha \\succ 0$ (i.e., $\\mathbf{K}_\\alpha$ is SPD) for all $\\alpha \\ge 0$ under the stated conditions.\n\nThen, for the linear system\n$$\n\\mathbf{K}_\\alpha \\mathbf{u} = \\mathbf{b},\n$$\ncompare the convergence behavior of the Conjugate Gradient (CG) method by measuring the number of iterations needed to reach a prescribed relative residual tolerance when varying $\\alpha$. Use the standard definition of relative residual\n$$\n\\frac{\\|\\mathbf{b} - \\mathbf{K}_\\alpha \\mathbf{u}_k\\|_2}{\\|\\mathbf{b}\\|_2},\n$$\nwhere $\\mathbf{u}_k$ is the CG iterate at iteration $k$.\n\nImplement the following in a complete, runnable program:\n1. Assemble the global matrices $\\mathbf{K}$, $\\mathbf{M}$ and the global load vector $\\mathbf{b}$ for the described bar using the nondimensional parameters above.\n2. Apply the Dirichlet boundary condition at node $0$ by removing the corresponding row and column from $\\mathbf{K}$ and $\\mathbf{M}$ and the entry from $\\mathbf{b}$.\n3. For each specified $\\alpha$, form $\\mathbf{K}_\\alpha$, compute its smallest eigenvalue to numerically confirm the SPD property, and solve $\\mathbf{K}_\\alpha \\mathbf{u}=\\mathbf{b}$ using the Conjugate Gradient method implemented from first principles. Record the number of iterations required to reach a relative residual tolerance of $10^{-10}$ starting from the zero initial guess.\n4. Use $n_e=64$ elements.\n\nTest Suite:\n- Use $\\alpha$ values $\\{0.0, 10^{-6}, 10^{-3}, 10^{-1}, 1.0, 10.0\\}$ to span the baseline, small augmentation, moderate augmentation, and large augmentation regimes.\n\nAnswer specification:\n- For each $\\alpha$ in the order listed, produce two outputs: the integer CG iteration count and the smallest eigenvalue of $\\mathbf{K}_\\alpha$ as a float. Since the model is nondimensionalized, these outputs are unitless numerical values.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain the values in the exact order: $\\left[\\text{iters}_{\\alpha_1}, \\lambda_{\\min}(\\mathbf{K}_{\\alpha_1}), \\text{iters}_{\\alpha_2}, \\lambda_{\\min}(\\mathbf{K}_{\\alpha_2}), \\ldots \\right]$ corresponding to the $\\alpha$ values $\\{0.0, 10^{-6}, 10^{-3}, 10^{-1}, 1.0, 10.0\\}$.", "solution": "The problem requires the construction and analysis of a quasi-static one-dimensional linear elasticity model of a bar using the Finite Element Method (FEM). The model is augmented with a mass regularization term, and the convergence behavior of the Conjugate Gradient (CG) iterative solver is to be investigated as a function of the regularization parameter $\\alpha$.\n\nThe first step is a theoretical validation of the problem's core premise: that the matrix $\\mathbf{K}_\\alpha = \\mathbf{K} + \\alpha \\mathbf{M}$ is symmetric positive definite (SPD) for all $\\alpha \\ge 0$, given the specified boundary conditions.\n\nA matrix $\\mathbf{A}$ is SPD if it is symmetric ($\\mathbf{A} = \\mathbf{A}^T$) and for any non-zero vector $\\mathbf{x}$, the quadratic form $\\mathbf{x}^T \\mathbf{A} \\mathbf{x} > 0$. The global stiffness matrix $\\mathbf{K}$ and mass matrix $\\mathbf{M}$ are assembled from their symmetric element-level counterparts ($\\mathbf{k}_e$, $\\mathbf{m}_e$), and thus they are also symmetric. Consequently, $\\mathbf{K}_\\alpha$ is symmetric.\n\nTo establish positive definiteness, we consider the physical interpretation of the quadratic forms.\nThe term $\\frac{1}{2}\\mathbf{u}^T \\mathbf{K} \\mathbf{u}$ represents the elastic strain energy stored in the discretized bar for a given nodal displacement vector $\\mathbf{u}$. For the system to be stable, this energy must be positive for any possible deformation. Without any boundary conditions, a rigid body translation of the bar ($\\mathbf{u} = c[1, 1, \\dots, 1]^T$ for a constant $c \\ne 0$) results in zero strain and zero strain energy, meaning $\\mathbf{K}$ is only positive semi-definite. The problem specifies a Dirichlet boundary condition $u(0)=0$, which is applied by removing the first row and column of the global matrices. This constraint eliminates the rigid body mode. For any non-zero displacement vector $\\mathbf{u}$ on the remaining free degrees of freedom, there must be non-zero strain, and thus the strain energy $\\frac{1}{2}\\mathbf{u}^T \\mathbf{K} \\mathbf{u} > 0$. Therefore, the reduced stiffness matrix $\\mathbf{K}$ is SPD.\n\nThe term $\\frac{1}{2}\\mathbf{u}^T \\mathbf{M} \\mathbf{u}$ corresponds to the kinetic energy of the system (if $\\mathbf{u}$ were a velocity vector). The element mass matrix $\\mathbf{m}_e$ is SPD, and the assembled global mass matrix $\\mathbf{M}$ (both before and after applying the boundary condition) is also SPD because mass is an intrinsically positive quantity. For any non-zero displacement (or velocity) field, the kinetic energy must be positive. Thus, for any non-zero vector $\\mathbf{u}$ on the free degrees of freedom, $\\mathbf{u}^T \\mathbf{M} \\mathbf{u} > 0$.\n\nNow, consider the quadratic form of $\\mathbf{K}_\\alpha$ for any non-zero vector $\\mathbf{u}$ of appropriate dimension:\n$$\n\\mathbf{u}^T \\mathbf{K}_\\alpha \\mathbf{u} = \\mathbf{u}^T (\\mathbf{K} + \\alpha \\mathbf{M}) \\mathbf{u} = \\mathbf{u}^T \\mathbf{K} \\mathbf{u} + \\alpha (\\mathbf{u}^T \\mathbf{M} \\mathbf{u})\n$$\nSince $\\mathbf{K}$ and $\\mathbf{M}$ are SPD, we have $\\mathbf{u}^T \\mathbf{K} \\mathbf{u} > 0$ and $\\mathbf{u}^T \\mathbf{M} \\mathbf{u} > 0$. For $\\alpha \\ge 0$, the term $\\alpha (\\mathbf{u}^T \\mathbf{M} \\mathbf{u})$ is non-negative. The sum of a strictly positive number and a non-negative number is strictly positive. Therefore, $\\mathbf{u}^T \\mathbf{K}_\\alpha \\mathbf{u} > 0$ for all $\\alpha \\ge 0$, confirming that $\\mathbf{K}_\\alpha$ is SPD. This is a critical prerequisite for the successful application of the Conjugate Gradient method.\n\nThe numerical implementation proceeds as follows.\nFirst, we define the nondimensionalized physical and discretization parameters: $E=1$, $A=1$, $\\rho=1$, $L=1$, $q=1$, and $n_e=64$. This yields an element length of $h = L/n_e = 1/64$.\nThe element stiffness matrix $\\mathbf{k}_e$, mass matrix $\\mathbf{m}_e$, and force vector $\\mathbf{f}_e$ are computed:\n$$\n\\mathbf{k}_e = \\frac{1 \\cdot 1}{1/64} \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix} = 64 \\begin{bmatrix} 1 & -1 \\\\ -1 & 1 \\end{bmatrix}\n$$\n$$\n\\mathbf{m}_e = \\frac{1 \\cdot 1 \\cdot (1/64)}{6} \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix} = \\frac{1}{384} \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix}\n$$\n$$\n\\mathbf{f}_e = \\frac{1 \\cdot 1 \\cdot (1/64)}{2} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} = \\frac{1}{128} \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}\n$$\nGlobal matrices $\\mathbf{K}$, $\\mathbf{M}$ (size $(n_e+1) \\times (n_e+1)$) and vector $\\mathbf{b}$ (size $n_e+1$) are initialized to zero. We then iterate through each of the $n_e$ elements. For element $i$ (connecting nodes $i$ and $i+1$), the entries of $\\mathbf{k}_e$, $\\mathbf{m}_e$, and $\\mathbf{f}_e$ are added to the corresponding locations in the global system. This standard assembly procedure results in banded global matrices.\n\nThe Dirichlet boundary condition $u(0)=0$ is enforced by removing the row and column corresponding to node $0$ from $\\mathbf{K}$ and $\\mathbf{M}$, and the entry corresponding to node $0$ from $\\mathbf{b}$. This reduces the system size from $(n_e+1) \\times (n_e+1)$ to $n_e \\times n_e$. Let the reduced system be denoted by $\\mathbf{K}_{red}$, $\\mathbf{M}_{red}$, and $\\mathbf{b}_{red}$.\n\nFor each value of $\\alpha$ in the test suite, the augmented matrix $\\mathbf{K}_\\alpha = \\mathbf{K}_{red} + \\alpha \\mathbf{M}_{red}$ is formed. Its smallest eigenvalue, $\\lambda_{\\min}(\\mathbf{K}_\\alpha)$, is computed to numerically verify the SPD property (a positive smallest eigenvalue confirms this for a symmetric matrix).\n\nThe linear system $\\mathbf{K}_\\alpha \\mathbf{u} = \\mathbf{b}_{red}$ is then solved using a from-scratch implementation of the Conjugate Gradient algorithm. The algorithm is initialized with a zero vector guess, $\\mathbf{u}_0 = \\mathbf{0}$. The iterative process is as follows:\n1.  Initialize: $\\mathbf{u}_0 = \\mathbf{0}$, residual $\\mathbf{r}_0 = \\mathbf{b}_{red}$, search direction $\\mathbf{p}_0 = \\mathbf{r}_0$.\n2.  For $k=0, 1, 2, \\dots$:\n    a. Calculate step size: $\\gamma_k = (\\mathbf{r}_k^T \\mathbf{r}_k) / (\\mathbf{p}_k^T \\mathbf{K}_\\alpha \\mathbf{p}_k)$.\n    b. Update solution: $\\mathbf{u}_{k+1} = \\mathbf{u}_k + \\gamma_k \\mathbf{p}_k$.\n    c. Update residual: $\\mathbf{r}_{k+1} = \\mathbf{r}_k - \\gamma_k \\mathbf{K}_\\alpha \\mathbf{p}_k$.\n    d. Check for convergence: If $\\|\\mathbf{r}_{k+1}\\|_2 / \\|\\mathbf{b}_{red}\\|_2 \\le 10^{-10}$, stop. The number of iterations is $k+1$.\n    e. Update search direction: $\\beta_k = (\\mathbf{r}_{k+1}^T \\mathbf{r}_{k+1}) / (\\mathbf{r}_k^T \\mathbf{r}_k)$, then $\\mathbf{p}_{k+1} = \\mathbf{r}_{k+1} + \\beta_k \\mathbf{p}_k$.\n\nThe performance of the CG method is intrinsically linked to the condition number of the system matrix, $\\kappa(\\mathbf{K}_\\alpha) = \\lambda_{\\max}(\\mathbf{K}_\\alpha) / \\lambda_{\\min}(\\mathbf{K}_\\alpha)$. For $\\alpha=0$, the stiffness matrix $\\mathbf{K}_{red}$ is known to be ill-conditioned for a fine mesh, with $\\kappa(\\mathbf{K}_{red}) \\propto n_e^2$. Adding the mass matrix term ($\\alpha > 0$) increases all eigenvalues, but it has a more significant relative impact on the smaller eigenvalues, thus generally reducing the condition number. This is expected to lead to a reduction in the number of CG iterations required for convergence as $\\alpha$ increases from zero. For large $\\alpha$, $\\mathbf{K}_\\alpha \\approx \\alpha \\mathbf{M}_{red}$, and the condition number will approach that of the mass matrix, $\\kappa(\\mathbf{M}_{red})$, which is a small constant independent of $n_e$. Thus, the iteration count should stabilize for large $\\alpha$. The following program implements this procedure and measures the iteration count and minimal eigenvalue for the specified set of $\\alpha$ values.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and solves a 1D linear elasticity problem using FEM,\n    analyzing the convergence of the Conjugate Gradient method with\n    mass regularization.\n    \"\"\"\n\n    # 1. Define problem parameters and test suite\n    E = 1.0\n    A = 1.0\n    rho = 1.0\n    L = 1.0\n    q = 1.0\n    n_e = 64\n    h = L / n_e\n    \n    alpha_values = [0.0, 1e-6, 1e-3, 1e-1, 1.0, 10.0]\n    tolerance = 1e-10\n\n    # 2. Assemble global matrices and vector\n    n_nodes = n_e + 1\n    K_global = np.zeros((n_nodes, n_nodes))\n    M_global = np.zeros((n_nodes, n_nodes))\n    b_global = np.zeros(n_nodes)\n\n    # Element matrices and vector\n    k_e = (E * A / h) * np.array([[1, -1], [-1, 1]])\n    m_e = (rho * A * h / 6) * np.array([[2, 1], [1, 2]])\n    f_e = (q * A * h / 2) * np.array([1, 1])\n\n    # Assembly loop\n    for i in range(n_e):\n        # Global DOFs for element i are i and i+1\n        dofs = np.array([i, i + 1])\n        ix_ = np.ix_(dofs, dofs)\n        K_global[ix_] += k_e\n        M_global[ix_] += m_e\n        b_global[dofs] += f_e\n\n    # 3. Apply Dirichlet boundary condition (u(0) = 0)\n    # This involves removing the first row and column (DOF 0)\n    free_dofs = np.arange(1, n_nodes)\n    K_reduced = K_global[np.ix_(free_dofs, free_dofs)]\n    M_reduced = M_global[np.ix_(free_dofs, free_dofs)]\n    b_reduced = b_global[free_dofs]\n\n    def conjugate_gradient(A_mat, b_vec, tol):\n        \"\"\"\n        Solves Ax=b using the Conjugate Gradient method from first principles.\n        \"\"\"\n        n = len(b_vec)\n        x = np.zeros(n)\n        r = b_vec - A_mat @ x\n        p = r.copy()\n        rs_old = r @ r\n        \n        b_norm = np.linalg.norm(b_vec)\n        if b_norm == 0:\n            return 0 # Trivial solution\n\n        # The problem asks for a maximum number of iterations, but for a \n        # well-posed problem, setting it to the system size is sufficient\n        # as CG is guaranteed to converge in at most n steps (in exact arithmetic).\n        for i in range(n):\n            Ap = A_mat @ p\n            alpha_cg = rs_old / (p @ Ap)\n            \n            x += alpha_cg * p\n            r -= alpha_cg * Ap\n            \n            # Check for convergence\n            residual_norm = np.linalg.norm(r)\n            if residual_norm / b_norm < tol:\n                return i + 1\n            \n            rs_new = r @ r\n            p = r + (rs_new / rs_old) * p\n            rs_old = rs_new\n            \n        return n # Return max iterations if tolerance not met\n\n    results = []\n    for alpha in alpha_values:\n        # 4. Form augmented matrix and solve\n        K_alpha = K_reduced + alpha * M_reduced\n\n        # 5. Compute smallest eigenvalue to confirm SPD\n        # eigvalsh is efficient for symmetric matrices and returns sorted eigenvalues\n        min_eigenvalue = np.linalg.eigvalsh(K_alpha)[0]\n\n        # 6. Solve system with CG and record iteration count\n        iterations = conjugate_gradient(K_alpha, b_reduced, tolerance)\n\n        results.extend([iterations, min_eigenvalue])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3576538"}, {"introduction": "To solve real-world problems at scale, we must consider performance on parallel computing architectures. This final practice shifts the focus from algorithmic implementation to performance modeling, examining the trade-offs between computation, communication, and iteration count [@problem_id:3576532]. By applying a principled performance model, you will quantify why a more complex (and computationally expensive) two-level preconditioner can lead to a faster overall solution time than a simple CG method, especially when accounting for network latency and global communication costs on a distributed cluster.", "problem": "Consider a symmetric positive definite (SPD) linear system arising from a finite element discretization in computational solid mechanics. You will estimate the wall-clock time per solve when using the Conjugate Gradient (CG) method, with and without a two-level preconditioner, on a distributed-memory cluster. Your estimation must follow a principled performance model that separates computation and communication, with a focus on the contribution of global reductions.\n\nFundamental base and modeling assumptions:\n- The Conjugate Gradient (CG) method for SPD systems performs, per iteration, one sparse matrix-vector product and a small number of vector updates and inner products. Classical Preconditioned Conjugate Gradient (PCG) requires $2$ global dot products per iteration (each realized as a global reduction).\n- The communication model uses the latency-bandwidth (also known as Hockney) model. A point-to-point message of size $m$ bytes takes time $T_{\\text{ptp}} = \\alpha + m/\\beta$, where $\\alpha$ is the network latency per message and $\\beta$ is the per-link bandwidth in bytes per second. A global reduction over $p$ nodes uses a tree with $\\lceil \\log_{2}(p) \\rceil$ stages, so the time for one reduction of a message of size $m$ bytes is\n$$\nT_{\\text{red}}(p,m) = \\lceil \\log_{2}(p) \\rceil \\left( \\alpha + \\frac{m}{\\beta} \\right).\n$$\n- The compute time is modeled as floating-point operations divided by sustained floating-point rate. With $N$ unknowns, average nonzeros per row $z$, and $p$ identical nodes each sustaining $R_{\\text{node}}$ floating-point operations per second, the total sustained rate is $R_{\\text{tot}} = p \\, R_{\\text{node}}$. A sparse matrix-vector product (SpMV) costs approximately $2 z N$ floating-point operations, vector updates per iteration cost $6 N$ floating-point operations, and local parts of two dot products cost $2 N$ floating-point operations. Hence the per-iteration local compute work (excluding any preconditioner work) is\n$$\nW_{\\text{iter,local}} = 2 z N + 8 N,\n$$\nand its time is $T_{\\text{iter,comp}} = W_{\\text{iter,local}} / R_{\\text{tot}}$.\n- The number of CG iterations without preconditioning is modeled as $K_{0} = \\lceil c_{k} \\, N^{1/3} \\rceil$, where $c_{k}$ is a dimensionless constant. The two-level preconditioner yields an iteration count $K_{\\text{pc}} = \\lceil K_{0} / \\rho \\rceil$, where $\\rho > 1$ is the iteration reduction factor.\n- The two-level preconditioner has a coarse space of size $N_{c} = \\alpha_{c} \\, p$, where $\\alpha_{c}$ is a dimensionless constant denoting coarse unknowns per subdomain. The extra per-iteration cost of the coarse correction includes:\n    - A dense coarse solve time modeled as\n    $$\n    T_{\\text{coarse,comp}} = \\frac{c_{\\text{chol}} \\, N_{c}^{3}}{R_{\\text{node}}},\n    $$\n    where $c_{\\text{chol}} = 1/3$ models dense Cholesky complexity, executed effectively on one node.\n    - An additional global reduction of the coarse vector of size $8 N_{c}$ bytes (one extra reduction per preconditioned iteration), so an extra per-iteration reduction time of $T_{\\text{red}}(p, 8 N_{c})$.\n- The preconditioner setup includes a local setup cost of $s_{\\text{setup}} N / R_{\\text{tot}}$ seconds, where $s_{\\text{setup}}$ is the local setup floating-point operations per unknown, and one global reduction of the coarse vector of size $8 N_{c}$ bytes. There is no preconditioner overhead in the unpreconditioned case.\n- Reductions for dot products use a message size of $8$ bytes (one floating-point scalar).\n- The total wall-clock time without preconditioning is\n$$\nT_{\\text{noPC}} = K_{0} \\left( T_{\\text{iter,comp}} + 2 \\, T_{\\text{red}}(p, 8) \\right),\n$$\nand the total wall-clock time with the two-level preconditioner is\n$$\nT_{\\text{PC}} = \\underbrace{\\frac{s_{\\text{setup}} N}{R_{\\text{tot}}} + T_{\\text{red}}(p, 8 N_{c})}_{T_{\\text{setup,PC}}} + K_{\\text{pc}} \\left( T_{\\text{iter,comp}} + T_{\\text{coarse,comp}} + 2 \\, T_{\\text{red}}(p, 8) + T_{\\text{red}}(p, 8 N_{c}) \\right).\n$$\n- To highlight the impact of global reductions, also report the time attributable solely to global reductions. For the unpreconditioned case,\n$$\nT_{\\text{red,noPC}} = K_{0} \\cdot 2 \\, T_{\\text{red}}(p, 8),\n$$\nand for the preconditioned case,\n$$\nT_{\\text{red,PC}} = \\underbrace{T_{\\text{red}}(p, 8 N_{c})}_{\\text{setup}} + K_{\\text{pc}} \\left( 2 \\, T_{\\text{red}}(p, 8) + T_{\\text{red}}(p, 8 N_{c}) \\right).\n$$\n\nYour task:\n- Implement a program that evaluates $T_{\\text{noPC}}$, $K_{0}$, $T_{\\text{red,noPC}}$, $T_{\\text{PC}}$, $K_{\\text{pc}}$, and $T_{\\text{red,PC}}$ for the test suite below. All times must be in seconds, rounded to $6$ decimals. Iteration counts are integers.\n- Use the constants $c_{k} = 0.5$, $c_{\\text{chol}} = 1/3$, and $s_{\\text{setup}} = 200$ (floating-point operations per unknown).\n- Assume that $R_{\\text{tot}} = p \\, R_{\\text{node}}$ and use $\\lceil \\log_{2}(p) \\rceil = 0$ when $p = 1$.\n\nTest suite (each case is a tuple of parameters $(p, \\alpha, \\beta, N, z, R_{\\text{node}}, \\rho, \\alpha_{c})$):\n- Case A (happy path): $(16, 1.0 \\times 10^{-6}, 12.0 \\times 10^{9}, 1.0 \\times 10^{7}, 27, 1.0 \\times 10^{11}, 4, 8)$.\n- Case B (high-latency, many nodes): $(64, 5.0 \\times 10^{-5}, 1.0 \\times 10^{9}, 2.0 \\times 10^{7}, 27, 8.0 \\times 10^{10}, 6, 16)$.\n- Case C (small problem, moderate nodes): $(32, 2.0 \\times 10^{-6}, 25.0 \\times 10^{9}, 1.0 \\times 10^{6}, 15, 1.2 \\times 10^{11}, 3, 4)$.\n- Case D (single node boundary): $(1, 1.0 \\times 10^{-6}, 12.0 \\times 10^{9}, 5.0 \\times 10^{6}, 27, 1.0 \\times 10^{11}, 2, 8)$.\n\nFinal output specification:\n- For each test case, produce a list $[T_{\\text{noPC}}, K_{0}, T_{\\text{red,noPC}}, T_{\\text{PC}}, K_{\\text{pc}}, T_{\\text{red,PC}}]$, with times in seconds rounded to $6$ decimals and iteration counts as integers.\n- Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element is the list for a test case, in the same order as provided (for example, $[[\\cdot],[\\cdot],[\\cdot],[\\cdot]]$).", "solution": "The problem provides a detailed performance model to estimate the wall-clock time for solving a symmetric positive definite (SPD) linear system using the Conjugate Gradient (CG) method, both with and without a two-level preconditioner. The task is to implement this model and calculate specific performance metrics for a given set of test cases. The solution proceeds by systematically implementing the provided formulas.\n\nThe process for each test case, defined by the parameter set $(p, \\alpha, \\beta, N, z, R_{\\text{node}}, \\rho, \\alpha_{c})$, is as follows:\n\nFirst, we define the provided constants:\n- Iteration count constant, $c_{k} = 0.5$.\n- Cholesky complexity constant, $c_{\\text{chol}} = 1/3$.\n- Preconditioner local setup work, $s_{\\text{setup}} = 200$ floating-point operations per unknown.\n- Message size for a dot product reduction, $m_{\\text{dot}} = 8$ bytes.\n\nNext, we calculate several intermediate quantities derived from the input parameters:\n- Total sustained floating-point rate across all nodes: $R_{\\text{tot}} = p \\cdot R_{\\text{node}}$.\n- Coarse space size for the preconditioner: $N_{c} = \\alpha_{c} \\cdot p$.\n- Message size for the coarse vector reduction: $m_{\\text{coarse}} = 8 \\cdot N_{c}$ bytes.\n- The term $\\lceil \\log_{2}(p) \\rceil$ for the reduction model, which is taken to be $0$ for $p=1$ as specified. This is computed as $\\lceil \\log_{2}(p) \\rceil$ for $p > 1$ and $0$ for $p=1$.\n\nUsing these quantities, we compute the fundamental time components of the model.\nThe time for a single global reduction of a message of size $m$ is given by the Hockney-style model:\n$$ T_{\\text{red}}(p,m) = \\lceil \\log_{2}(p) \\rceil \\left( \\alpha + \\frac{m}{\\beta} \\right) $$\nWe apply this formula to find the time for a dot product reduction, $T_{\\text{red,dot}} = T_{\\text{red}}(p, m_{\\text{dot}})$, and for a coarse vector reduction, $T_{\\text{red,coarse}} = T_{\\text{red}}(p, m_{\\text{coarse}})$.\n\nThe per-iteration computational time (excluding preconditioner-specific work) is based on the floating-point operations for one SpMV ($2zN$), vector updates ($6N$), and local dot products ($2N$):\n$$ W_{\\text{iter,local}} = 2 z N + 8 N $$\n$$ T_{\\text{iter,comp}} = \\frac{W_{\\text{iter,local}}}{R_{\\text{tot}}} $$\n\nThe number of iterations is estimated next. For the unpreconditioned case:\n$$ K_{0} = \\lceil c_{k} \\, N^{1/3} \\rceil $$\nFor the preconditioned case, this is reduced by a factor $\\rho$:\n$$ K_{\\text{pc}} = \\lceil K_{0} / \\rho \\rceil $$\nThese values must be integers.\n\nWith these components, we can assemble the total time and reduction time for the unpreconditioned case. The total time per iteration is the sum of computation and two dot product reductions.\n$$ T_{\\text{noPC}} = K_{0} \\left( T_{\\text{iter,comp}} + 2 \\, T_{\\text{red,dot}} \\right) $$\nThe time attributable solely to global reductions is:\n$$ T_{\\text{red,noPC}} = K_{0} \\cdot 2 \\, T_{\\text{red,dot}} $$\n\nFor the preconditioned case, additional costs for the preconditioner setup and application must be included.\nThe setup consists of local computations and one global reduction of the coarse vector:\n$$ T_{\\text{setup,PC}} = \\frac{s_{\\text{setup}} N}{R_{\\text{tot}}} + T_{\\text{red}}(p, 8 N_{c}) $$\nThe per-iteration cost now includes the standard CG work, the coarse solve, and three global reductions (two for dot products, one for the preconditioner):\n$$ T_{\\text{iter-total,PC}} = T_{\\text{iter,comp}} + T_{\\text{coarse,comp}} + 2 \\, T_{\\text{red}}(p, 8) + T_{\\text{red}}(p, 8 N_{c}) $$\nwhere the coarse solve time is modeled as a dense Cholesky factorization on a single node:\n$$ T_{\\text{coarse,comp}} = \\frac{c_{\\text{chol}} \\, N_{c}^{3}}{R_{\\text{node}}} $$\nThe total time for the preconditioned solve is the sum of the setup time and the total time for all iterations:\n$$ T_{\\text{PC}} = T_{\\text{setup,PC}} + K_{\\text{pc}} \\cdot T_{\\text{iter-total,PC}} $$\nFinally, the total time attributable to reductions in the preconditioned case includes the setup reduction and the reductions within each of the $K_{\\text{pc}}$ iterations:\n$$ T_{\\text{red,PC}} = T_{\\text{red}}(p, 8 N_{c}) + K_{\\text{pc}} \\left( 2 \\, T_{\\text{red}}(p, 8) + T_{\\text{red}}(p, 8 N_{c}) \\right) $$\n\nBy implementing these formulas for each test case, we can compute the required set of six values: $T_{\\text{noPC}}$, $K_{0}$, $T_{\\text{red,noPC}}$, $T_{\\text{PC}}$, $K_{\\text{pc}}$, and $T_{\\text{red,PC}}$. All time values are rounded to $6$ decimal places.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the performance model to estimate wall-clock time for CG and PCG methods.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (p, alpha, beta, N, z, R_node, rho, alpha_c)\n    test_cases = [\n        (16, 1.0e-6, 12.0e9, 1.0e7, 27, 1.0e11, 4, 8),   # Case A\n        (64, 5.0e-5, 1.0e9, 2.0e7, 27, 8.0e10, 6, 16),   # Case B\n        (32, 2.0e-6, 25.0e9, 1.0e6, 15, 1.2e11, 3, 4),   # Case C\n        (1, 1.0e-6, 12.0e9, 5.0e6, 27, 1.0e11, 2, 8),    # Case D\n    ]\n\n    # Constants from the problem statement\n    c_k = 0.5\n    c_chol = 1.0 / 3.0\n    s_setup = 200.0\n    m_dot = 8.0 # bytes\n\n    results = []\n    \n    for case in test_cases:\n        p, alpha, beta, N, z, R_node, rho, alpha_c = case\n\n        # Calculate intermediate quantities\n        R_tot = p * R_node\n        N_c = alpha_c * p\n        m_coarse = 8.0 * N_c\n        \n        # Per the spec, log2p_ceil is 0 for p=1.\n        log2p_ceil = np.ceil(np.log2(p)) if p > 1 else 0.0\n\n        # Define T_red function based on the model\n        def T_red(p_val, m_val, alpha_val, beta_val, log2p_val):\n            if p_val == 1:\n                return 0.0\n            return log2p_val * (alpha_val + m_val / beta_val)\n\n        # Calculate fundamental time components\n        T_red_dot = T_red(p, m_dot, alpha, beta, log2p_ceil)\n        T_red_coarse = T_red(p, m_coarse, alpha, beta, log2p_ceil)\n        \n        W_iter_local = 2.0 * z * N + 8.0 * N\n        T_iter_comp = W_iter_local / R_tot\n\n        # Calculate iteration counts\n        K0 = int(np.ceil(c_k * (N**(1.0/3.0))))\n        K_pc = int(np.ceil(float(K0) / rho))\n\n        # --- Unpreconditioned case ---\n        T_noPC = K0 * (T_iter_comp + 2.0 * T_red_dot)\n        T_red_noPC = K0 * 2.0 * T_red_dot\n\n        # --- Preconditioned case ---\n        # Setup time\n        T_setup_comp = (s_setup * N) / R_tot\n        T_setup_PC = T_setup_comp + T_red_coarse\n\n        # Per-iteration costs\n        T_coarse_comp = (c_chol * (N_c**3)) / R_node\n        T_iter_total_PC = T_iter_comp + T_coarse_comp + 2.0 * T_red_dot + T_red_coarse\n\n        # Total time\n        T_PC = T_setup_PC + K_pc * T_iter_total_PC\n        \n        # Total reduction time\n        T_red_PC = T_red_coarse + K_pc * (2.0 * T_red_dot + T_red_coarse)\n\n        # Store results, rounded as specified\n        case_results = [\n            round(T_noPC, 6),\n            K0,\n            round(T_red_noPC, 6),\n            round(T_PC, 6),\n            K_pc,\n            round(T_red_PC, 6)\n        ]\n        results.append(case_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3576532"}]}