{"hands_on_practices": [{"introduction": "In computational mechanics, it is common to see the double dot product $A:B$ equated with the trace of the matrix product, $\\mathrm{tr}(AB)$. While this identity is a powerful shortcut, it hinges on a crucial, and sometimes implicit, assumption of symmetry. This first exercise provides a hands-on counterexample that reinforces the fundamental definitions and clarifies the precise conditions under which this important equality holds [@problem_id:3604877].", "problem": "Consider second-order tensors $A$ and $B$ defined on a three-dimensional Euclidean body with an orthonormal basis. The double contraction of $A$ and $B$ is defined by $A:B = \\sum_{i=1}^{3}\\sum_{j=1}^{3} A_{ij} B_{ij}$, and the trace of their product is defined by $\\mathrm{tr}(AB) = \\sum_{i=1}^{3} (AB)_{ii} = \\sum_{i=1}^{3}\\sum_{j=1}^{3} A_{ij} B_{ji}$. In computational solid mechanics, the equality $A:B = \\mathrm{tr}(AB)$ is often used under symmetry assumptions. Starting from the above core definitions, and without assuming symmetry, provide a componentwise counterexample that demonstrates $A:B \\neq \\mathrm{tr}(AB)$.\n\nUse the specific tensors\n$$\nA = \\begin{pmatrix}\n0 & 2 & 0 \\\\\n0 & 0 & 0 \\\\\n0 & 0 & 0\n\\end{pmatrix},\\qquad\nB = \\begin{pmatrix}\n0 & 0 & 0 \\\\\n3 & 0 & 0 \\\\\n0 & 0 & 0\n\\end{pmatrix}.\n$$\nCompute $A:B$ and $\\mathrm{tr}(AB)$ directly from the definitions and report the scalar difference $A:B - \\mathrm{tr}(AB)$ as a single real number. Express the final answer without units.", "solution": "The problem is validated as self-contained, scientifically sound, and well-posed. The objective is to compute the scalar difference $A:B - \\mathrm{tr}(AB)$ for the given non-symmetric second-order tensors $A$ and $B$.\n\nThe specific tensors provided are:\n$$\nA = \\begin{pmatrix}\n0 & 2 & 0 \\\\\n0 & 0 & 0 \\\\\n0 & 0 & 0\n\\end{pmatrix},\\qquad\nB = \\begin{pmatrix}\n0 & 0 & 0 \\\\\n3 & 0 & 0 \\\\\n0 & 0 & 0\n\\end{pmatrix}.\n$$\nIn component form, the only non-zero component of tensor $A$ is $A_{12} = 2$. The only non-zero component of tensor $B$ is $B_{21} = 3$. All other components $A_{ij}$ and $B_{ij}$ for $(i,j) \\in \\{1, 2, 3\\} \\times \\{1, 2, 3\\}$ are equal to $0$.\n\nFirst, we compute the double contraction $A:B$ using the provided definition:\n$$\nA:B = \\sum_{i=1}^{3}\\sum_{j=1}^{3} A_{ij} B_{ij}\n$$\nThis operation, also known as the Frobenius inner product, involves summing the products of corresponding components of the two tensors. We can expand the sum:\n$$\nA:B = A_{11}B_{11} + A_{12}B_{12} + A_{13}B_{13} + A_{21}B_{21} + A_{22}B_{22} + A_{23}B_{23} + A_{31}B_{31} + A_{32}B_{32} + A_{33}B_{33}\n$$\nSubstituting the component values of $A$ and $B$:\n$$\nA:B = (0)(0) + (2)(0) + (0)(0) + (0)(3) + (0)(0) + (0)(0) + (0)(0) + (0)(0) + (0)(0)\n$$\nEvery term in the summation is zero. For example, the term involving the non-zero component $A_{12}=2$ is $A_{12}B_{12}$, but $B_{12}=0$. Similarly, the term involving the non-zero component $B_{21}=3$ is $A_{21}B_{21}$, but $A_{21}=0$.\nTherefore, the double contraction is:\n$$\nA:B = 0\n$$\n\nNext, we compute the trace of the tensor product $AB$, denoted as $\\mathrm{tr}(AB)$. The definition provided is:\n$$\n\\mathrm{tr}(AB) = \\sum_{i=1}^{3}\\sum_{j=1}^{3} A_{ij} B_{ji}\n$$\nThis sum involves multiplying the component $A_{ij}$ by the component $B_{ji}$ (note the transposed indices for $B$) and summing over all $i$ and $j$. Let's examine the terms in this summation. The only non-zero component of $A$ is $A_{12} = 2$. Therefore, the only potentially non-zero term in the entire double summation is the one where $i=1$ and $j=2$. This term is $A_{12}B_{21}$. All other terms will be zero because $A_{ij}=0$ for $(i,j) \\neq (1,2)$.\n\nLet's evaluate the single non-zero term:\n$$\nA_{12}B_{21} = (2)(3) = 6\n$$\nSince all other terms in the sum are zero, the value of the trace is determined entirely by this term:\n$$\n\\mathrm{tr}(AB) = \\sum_{i=1}^{3}\\sum_{j=1}^{3} A_{ij} B_{ji} = A_{12}B_{21} + \\sum_{(i,j) \\neq (1,2)} A_{ij}B_{ji} = 6 + 0 = 6\n$$\nAlternatively, one can first compute the matrix product $C = AB$:\n$$\nC = AB = \\begin{pmatrix} 0 & 2 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} \\begin{pmatrix} 0 & 0 & 0 \\\\ 3 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix} = \\begin{pmatrix} (0)(0)+(2)(3)+(0)(0) & (0)(0)+(2)(0)+(0)(0) & (0)(0)+(2)(0)+(0)(0) \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\n$$\nC = \\begin{pmatrix} 6 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0 \\end{pmatrix}\n$$\nThe trace is the sum of the diagonal elements of $C$:\n$$\n\\mathrm{tr}(AB) = \\mathrm{tr}(C) = C_{11} + C_{22} + C_{33} = 6 + 0 + 0 = 6\n$$\nBoth methods yield the same result.\n\nFinally, we compute the required scalar difference $A:B - \\mathrm{tr}(AB)$:\n$$\nA:B - \\mathrm{tr}(AB) = 0 - 6 = -6\n$$\nThis counterexample demonstrates that for non-symmetric tensors, the double contraction $A:B$ is not, in general, equal to the trace of their product $\\mathrm{tr}(AB)$. The equality holds if at least one of the tensors is symmetric, which is not the case here.", "answer": "$$\\boxed{-6}$$", "id": "3604877"}, {"introduction": "The double dot product provides a natural inner product for the space of tensors, allowing us to define geometric concepts like norms, orthogonality, and projections. This exercise applies these ideas to the fundamental decomposition of a stress tensor $\\sigma$ into its spherical and deviatoric parts. You will implement the deviatoric projection operator and use it to compute the deviatoric energy, gaining insight into how tensor contractions are used to quantify physically meaningful quantities in continuum mechanics [@problem_id:3604892].", "problem": "Design and implement a complete algorithm in a modern programming language to compute a scalar deviatoric energy measure and to verify the idempotence of the deviatoric projection for a given second-order tensor. Use the following core definitions from continuum mechanics, with all calculations restricted to three-dimensional second-order tensors.\n\nLet the Cauchy stress tensor be denoted by $\\sigma \\in \\mathbb{R}^{3 \\times 3}$. The second-order identity tensor is denoted by $I \\in \\mathbb{R}^{3 \\times 3}$, with the double contraction $I:I=3$. The double dot product (also called double contraction) of two second-order tensors $A$ and $B$ is defined as $A:B=\\sum_{i=1}^{3}\\sum_{j=1}^{3}A_{ij}B_{ij}$. The deviatoric operator is defined by $dev(\\sigma)=\\sigma-\\frac{1}{3}(\\sigma:I)I$, which maps $\\sigma$ to its trace-free part.\n\nStarting from these fundamental definitions, you must:\n\n1. Derive from first principles why $dev(dev(\\sigma))=dev(\\sigma)$, explicitly using $I:I=3$ and properties of the double dot product, and design an algorithmic test that verifies idempotence numerically for given inputs by measuring the Frobenius norm $||A||_{F}=\\sqrt{A:A}$ of the difference $dev(dev(\\sigma))-dev(\\sigma)$ against a small tolerance (use $10^{-10}$ as the tolerance).\n2. Define the deviatoric energy measure $E_{dev}(\\sigma)$ as the scalar $E_{dev}(\\sigma)=\\dfrac{1}{2}\\,dev(\\sigma):dev(\\sigma)$ and implement its computation. All inputs and outputs are dimensionless; express the output energy values as floating-point numbers.\n\nYour implementation must be fully self-contained and produce results for the following test suite of stress tensors (each is symmetric and $3 \\times 3$), specified numerically:\n\n- General case (nonzero trace and shear): \n  $\\sigma_{A}=\\begin{bmatrix}120 & -30 & 45 \\\\ -30 & 80 & 0 \\\\ 45 & 0 & -10\\end{bmatrix}$.\n- Pure hydrostatic case: $\\sigma_{B}=50\\,I=\\begin{bmatrix}50 & 0 & 0 \\\\ 0 & 50 & 0 \\\\ 0 & 0 & 50\\end{bmatrix}$.\n- Pure deviatoric case (zero trace with shear): \n  $\\sigma_{C}=\\begin{bmatrix}30 & -6 & 0 \\\\ -6 & -15 & 0 \\\\ 0 & 0 & -15\\end{bmatrix}$.\n- Zero tensor (boundary case): \n  $\\sigma_{D}=\\begin{bmatrix}0 & 0 & 0 \\\\ 0 & 0 & 0 \\\\ 0 & 0 & 0\\end{bmatrix}$.\n- Tiny-magnitude deviatoric case (edge case): \n  $\\sigma_{E}=\\begin{bmatrix}10^{-12} & 2\\cdot 10^{-12} & -3\\cdot 10^{-12} \\\\ 2\\cdot 10^{-12} & -10^{-12} & 4\\cdot 10^{-12} \\\\ -3\\cdot 10^{-12} & 4\\cdot 10^{-12} & 0\\end{bmatrix}$.\n\nFor each test case, compute:\n- The scalar deviatoric energy $E_{dev}(\\sigma)$ as a floating-point number.\n- A boolean flag indicating whether idempotence holds numerically, defined as $||dev(dev(\\sigma))-dev(\\sigma)||_{F} < 10^{-10}$.\n\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, where each element corresponds to one test case and is itself a two-element list containing the floating-point deviatoric energy and the boolean idempotence flag. For example, the output format must be of the form \n$[[E_{A},\\text{flag}_{A}],[E_{B},\\text{flag}_{B}],\\dots]$, \nwith no extra text before or after the bracketed list.", "solution": "The problem statement is evaluated to be **valid**. It is scientifically grounded in the principles of continuum mechanics, is well-posed with all necessary definitions and data, and is expressed in objective, formal language. There are no contradictions, ambiguities, or factual unsoundness. We may therefore proceed with a solution.\n\nThe solution requires two main components: a formal derivation of the idempotence property of the deviatoric operator, and the design of an algorithm to compute the required quantities for a given set of test cases.\n\n### Part 1: Derivation of the Idempotence of the Deviatoric Operator\n\nThe deviatoric operator, $dev(\\cdot)$, maps a second-order tensor $\\sigma$ to its trace-free part. It is defined as:\n$$\ndev(\\sigma) = \\sigma - \\frac{1}{3}(\\sigma:I)I\n$$\nwhere $\\sigma$ is a second-order tensor, $I$ is the second-order identity tensor, and $A:B$ denotes the double dot product (or double contraction) of two tensors $A$ and $B$, defined as $A:B = \\sum_{i}\\sum_{j}A_{ij}B_{ij}$. The term $\\sigma:I$ is the trace of $\\sigma$, denoted $\\operatorname{tr}(\\sigma)$.\n\nAn operator $P$ is idempotent if applying it twice has the same effect as applying it once, i.e., $P(P(x)) = P(x)$. For the deviatoric operator, we must prove that $dev(dev(\\sigma)) = dev(\\sigma)$.\n\nLet us define a tensor $\\sigma'$ as the result of applying the deviatoric operator to $\\sigma$:\n$$\n\\sigma' = dev(\\sigma) = \\sigma - \\frac{1}{3}(\\sigma:I)I\n$$\nNow, we apply the deviatoric operator to $\\sigma'$:\n$$\ndev(\\sigma') = \\sigma' - \\frac{1}{3}(\\sigma':I)I\n$$\nTo proceed, we must evaluate the term $\\sigma':I$, which is the trace of the deviatoric tensor $\\sigma'$. We substitute the definition of $\\sigma'$ into this expression:\n$$\n\\sigma':I = \\left(\\sigma - \\frac{1}{3}(\\sigma:I)I\\right):I\n$$\nThe double dot product is a bilinear form, so we can distribute it across the subtraction:\n$$\n\\sigma':I = (\\sigma:I) - \\left(\\frac{1}{3}(\\sigma:I)I\\right):I\n$$\nThe term $\\frac{1}{3}(\\sigma:I)$ is a scalar. Scalars can be factored out of the double dot product operation:\n$$\n\\sigma':I = (\\sigma:I) - \\frac{1}{3}(\\sigma:I)(I:I)\n$$\nThe problem statement provides the fundamental identity that for a second-order identity tensor in three dimensions, $I:I=3$. We can also verify this from the definition: $I:I = \\sum_{i,j} \\delta_{ij}\\delta_{ij} = \\sum_{i} \\delta_{ii} = \\delta_{11} + \\delta_{22} + \\delta_{33} = 1 + 1 + 1 = 3$. Substituting this result into our equation:\n$$\n\\sigma':I = (\\sigma:I) - \\frac{1}{3}(\\sigma:I)(3)\n$$\n$$\n\\sigma':I = (\\sigma:I) - (\\sigma:I) = 0\n$$\nThis demonstrates a key property: any tensor resulting from the deviatoric operator is traceless.\n\nNow we substitute this result, $\\sigma':I = 0$, back into the expression for $dev(\\sigma')$:\n$$\ndev(\\sigma') = \\sigma' - \\frac{1}{3}(0)I\n$$\n$$\ndev(\\sigma') = \\sigma' - 0 = \\sigma'\n$$\nSince we initially defined $\\sigma' = dev(\\sigma)$, we have successfully shown that:\n$$\ndev(dev(\\sigma)) = dev(\\sigma)\n$$\nThis completes the proof. The deviatoric operator is indeed an idempotent operator, which is characteristic of a projection operator. It projects a tensor from the general space of second-order tensors onto the subspace of trace-free (deviatoric) tensors.\n\n### Part 2: Algorithmic Design and Implementation\n\nBased on the validated principles and the derivation above, we design an algorithm to perform the required computations.\n\n**1. Data Representation:**\nAll second-order tensors, such as the Cauchy stress $\\sigma$ and the identity tensor $I$, are represented as $3 \\times 3$ numerical arrays.\n\n**2. Core Operations:**\n\n*   **Double Dot Product:** A function will compute the double dot product $A:B = \\sum_{i,j} A_{ij}B_{ij}$. This corresponds to an element-wise multiplication of the two arrays followed by a sum of all elements in the resulting array.\n\n*   **Deviatoric Operator:** A function `dev(tensor)` will implement the formula $dev(\\sigma) = \\sigma - \\frac{1}{3}(\\sigma:I)I$. It will use the double dot product function to compute the trace, $\\operatorname{tr}(\\sigma) = \\sigma:I$.\n\n**3. Required Computations:**\n\n*   **Deviatoric Energy Measure:** The scalar deviatoric energy, $E_{dev}(\\sigma) = \\frac{1}{2}dev(\\sigma):dev(\\sigma)$, is calculated. First, the deviatoric tensor $\\sigma' = dev(\\sigma)$ is computed. Then, its double dot product with itself, $\\sigma':\\sigma'$, is calculated and multiplied by $\\frac{1}{2}$.\n\n*   **Idempotence Verification:** To numerically test the property $dev(dev(\\sigma)) = dev(\\sigma)$, we compute the difference between the two sides of the equation: $D = dev(dev(\\sigma)) - dev(\\sigma)$. Due to floating-point arithmetic, this difference may not be exactly zero. Therefore, we quantify its magnitude using the Frobenius norm, $||D||_F = \\sqrt{D:D}$. The idempotence property is considered to hold numerically if this norm is less than a small tolerance, which is specified as $10^{-10}$. The result is a boolean flag.\n\n**4. Overall Procedure:**\nThe main algorithm will execute the following steps for each of the provided input stress tensors:\n1.  Receive the input tensor $\\sigma$.\n2.  Compute its deviatoric part: $\\sigma' = dev(\\sigma)$.\n3.  Compute the deviatoric energy: $E_{dev} = \\frac{1}{2} (\\sigma':\\sigma')$.\n4.  Compute the second application of the deviatoric operator: $\\sigma'' = dev(\\sigma')$.\n5.  Calculate the difference tensor for the idempotence check: $D = \\sigma'' - \\sigma'$.\n6.  Calculate the Frobenius norm of the difference: $||D||_F = \\sqrt{D:D}$.\n7.  Compare the norm to the tolerance to get the boolean flag: $\\text{flag} = (||D||_F < 10^{-10})$.\n8.  Store the pair $[E_{dev}, \\text{flag}]$.\n\nAfter processing all test cases, the collected results will be formatted into a single string as specified by the problem, e.g., `[[E_A, flag_A], [E_B, flag_B], ...]`, and printed to standard output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes a scalar deviatoric energy measure and verifies the idempotence\n    of the deviatoric projection for a given suite of second-order stress tensors.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # sigma_A: General case\n        np.array([[120.0, -30.0, 45.0], \n                  [-30.0, 80.0, 0.0], \n                  [45.0, 0.0, -10.0]]),\n        \n        # sigma_B: Pure hydrostatic case\n        np.array([[50.0, 0.0, 0.0], \n                  [0.0, 50.0, 0.0], \n                  [0.0, 0.0, 50.0]]),\n        \n        # sigma_C: Pure deviatoric case\n        np.array([[30.0, -6.0, 0.0], \n                  [-6.0, -15.0, 0.0], \n                  [0.0, 0.0, -15.0]]),\n        \n        # sigma_D: Zero tensor\n        np.array([[0.0, 0.0, 0.0], \n                  [0.0, 0.0, 0.0], \n                  [0.0, 0.0, 0.0]]),\n\n        # sigma_E: Tiny-magnitude deviatoric case\n        np.array([[1e-12, 2e-12, -3e-12],\n                  [2e-12, -1e-12, 4e-12],\n                  [-3e-12, 4e-12, 0.0]])\n    ]\n\n    results = []\n    \n    # Define the second-order identity tensor in 3D\n    identity_tensor = np.identity(3)\n    \n    # Define tolerance for the idempotence check\n    tolerance = 1e-10\n\n    def double_dot_product(tensor_A, tensor_B):\n        \"\"\"\n        Computes the double dot product A:B = sum(A_ij * B_ij).\n        \"\"\"\n        return np.sum(tensor_A * tensor_B)\n\n    def deviatoric_operator(tensor):\n        \"\"\"\n        Computes the deviatoric part of a tensor: dev(T) = T - 1/3 * tr(T) * I.\n        \"\"\"\n        trace = double_dot_product(tensor, identity_tensor)\n        return tensor - (trace / 3.0) * identity_tensor\n\n    for sigma in test_cases:\n        # 1. Compute the deviatoric part of the stress tensor\n        dev_sigma = deviatoric_operator(sigma)\n        \n        # 2. Compute the scalar deviatoric energy\n        # E_dev = 1/2 * dev(sigma):dev(sigma)\n        deviatoric_energy = 0.5 * double_dot_product(dev_sigma, dev_sigma)\n        \n        # 3. Verify the idempotence property: dev(dev(sigma)) = dev(sigma)\n        # We compute dev(dev(sigma))\n        dev_dev_sigma = deviatoric_operator(dev_sigma)\n        \n        # Calculate the difference tensor D = dev(dev(sigma)) - dev(sigma)\n        difference_tensor = dev_dev_sigma - dev_sigma\n        \n        # Calculate the Frobenius norm of the difference: ||D||_F = sqrt(D:D)\n        norm_of_difference = np.sqrt(double_dot_product(difference_tensor, difference_tensor))\n        \n        # Check if the norm is within the specified tolerance\n        idempotence_holds = norm_of_difference < tolerance\n        \n        # Append the result pair to the list\n        results.append([deviatoric_energy, idempotence_holds])\n\n    # Convert each two-element list result into its string representation\n    # e.g., [7358.333, True] becomes \"[7358.333333333333, True]\"\n    # Using python's boolean string representation 'True'/'False' directly.\n    string_results = [str(res) for res in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(string_results)}]\")\n\nsolve()\n```", "id": "3604892"}, {"introduction": "Beyond component-based calculations, the double dot product has a profound geometric meaning related to the intrinsic properties of tensors. By using spectral decomposition, we can express the double dot product in terms of the tensors' eigenvalues and the relative alignment of their principal directions (eigenvectors). This practice will guide you through deriving this spectral representation, revealing the conditions under which the interaction between two tensorial fields simplifies to a direct pairing of their principal values [@problem_id:3604862].", "problem": "Consider two second-order tensors, represented as real symmetric matrices $A \\in \\mathbb{R}^{3 \\times 3}$ and $B \\in \\mathbb{R}^{3 \\times 3}$, as they arise in computational solid mechanics for stress, strain, or stiffness tensors. The double dot product of $A$ and $B$ is defined as $A:B = \\sum_{i=1}^{3}\\sum_{j=1}^{3} A_{ij} B_{ij}$, which equals $\\mathrm{tr}(A^{\\mathsf{T}}B)$ and, for symmetric $A$ and $B$, equals $\\mathrm{tr}(AB)$. The spectral decomposition for a real symmetric tensor $A$ is $A = Q \\Lambda Q^{\\mathsf{T}}$, where $Q$ is an orthogonal matrix of eigenvectors and $\\Lambda$ is a diagonal matrix of real eigenvalues. Two tensors are said to be co-axial if they share the same eigenvectors, that is, if they are simultaneously diagonalizable by the same orthogonal matrix. \n\nStarting from these definitions and properties, derive an algorithm that uses spectral decomposition to compute the double dot product $A:B$ when the tensors are co-axial, and rigorously determine the conditions under which the simplified expression $A:B = \\sum_{i=1}^{3} \\lambda_i \\mu_i$ is valid or invalid, where $\\lambda_i$ and $\\mu_i$ are the eigenvalues of $A$ and $B$, respectively. Your derivation and algorithm must rely only on the above fundamental bases: the definition of the double dot product for second-order tensors, spectral decomposition of real symmetric tensors, and orthogonal invariance of the trace. No other shortcut formulas may be assumed a priori.\n\nImplement your derivation as a complete, runnable program that:\n- Computes $A:B$ directly from components.\n- Computes $A:B$ via spectral decomposition in a basis-free manner using eigenpairs, without assuming co-axiality, by expressing the result in terms of eigenvalues and the orthogonal alignment of eigenvectors.\n- Detects co-axiality and, when this condition holds, computes $A:B$ via the simplified eigenvalue pairing formula.\n- Reports whether $A:B = \\sum_{i=1}^{3} \\lambda_i \\mu_i$ holds for each test case within a numerical tolerance of $10^{-12}$.\n- Uses angles specified below in radians.\n\nTest suite. Use the following four $3 \\times 3$ symmetric tensor pairs:\n1. $A_1 = \\mathrm{diag}(3,2,1)$ and $B_1 = \\mathrm{diag}(5,-1,4)$.\n2. Let $R_z(\\theta)$ be the rotation about the $z$-axis by angle $\\theta$. With $\\theta = \\pi/4$, define $A_2 = R_z(\\theta)\\,\\mathrm{diag}(7,0,-2)\\,R_z(\\theta)^{\\mathsf{T}}$ and $B_2 = R_z(\\theta)\\,\\mathrm{diag}(1,3,4)\\,R_z(\\theta)^{\\mathsf{T}}$.\n3. Let $R_x(\\phi)$ be the rotation about the $x$-axis by angle $\\phi$. With $\\phi = \\pi/6$, define $A_3 = \\mathrm{diag}(2,-1,3)$ and $B_3 = R_x(\\phi)\\,\\mathrm{diag}(4,6,-2)\\,R_x(\\phi)^{\\mathsf{T}}$.\n4. Let $R_y(\\alpha)$ be the rotation about the $y$-axis by angle $\\alpha$. With $\\alpha = \\pi/7$, define $A_4 = 5 I$ and $B_4 = R_y(\\alpha)\\,\\mathrm{diag}(10,-2,1)\\,R_y(\\alpha)^{\\mathsf{T}}$, where $I$ is the identity matrix.\n\nAngle unit: radians.\n\nNumerical tolerance: $10^{-12}$.\n\nFor each case $k = 1,2,3,4$, your program must produce a list containing:\n- The direct value of $A_k:B_k$ computed componentwise.\n- The spectral-decomposition value of $A_k:B_k$ expressed basis-independently using eigenpairs and orthogonal invariance.\n- The co-axial-eigenvalue-pairing value $\\sum_{i=1}^{3} \\lambda_i \\mu_i$ computed by matching eigenvectors via an optimal pairing when co-axial is detected; otherwise, computed as the pairing that maximizes the diagonal alignment of eigenvectors.\n- A boolean indicating whether $A_k:B_k = \\sum_{i=1}^{3} \\lambda_i \\mu_i$ holds within the stated tolerance.\n\nFinal output format. Your program should produce a single line of output containing the results as a comma-separated list of four per-case lists, with no spaces, enclosed in square brackets. For example: \"[[case1_values],[case2_values],[case3_values],[case4_values]]\". Each per-case list must be of the form \"[direct,spectral,paired_sum,boolean]\". No physical units are involved in this problem, and all angles are in radians.", "solution": "The problem requires the derivation of an algorithm to compute the double dot product of two second-order symmetric tensors, $A$ and $B$, using spectral decomposition and an analysis of the conditions under which the simplified expression $A:B = \\sum_{i=1}^{3} \\lambda_i \\mu_i$ is valid. The derivation must be founded on first principles.\n\nLet $A, B \\in \\mathbb{R}^{3 \\times 3}$ be real, symmetric second-order tensors. The double dot product is defined component-wise as $A:B = \\sum_{i=1}^{3}\\sum_{j=1}^{3} A_{ij} B_{ij}$. An equivalent definition using the trace operator is $A:B = \\mathrm{tr}(A^{\\mathsf{T}}B)$. Since $A$ is symmetric, $A^{\\mathsf{T}} = A$, and the expression becomes $A:B = \\mathrm{tr}(AB)$.\n\nThe spectral theorem for real symmetric matrices guarantees that any such tensor $X$ can be decomposed as $X = Q \\Lambda Q^{\\mathsf{T}}$, where $Q$ is an orthogonal matrix whose columns are the eigenvectors of $X$, and $\\Lambda$ is a diagonal matrix containing the corresponding real eigenvalues. Let the spectral decompositions of $A$ and $B$ be:\n$$ A = Q_A \\Lambda_A Q_A^{\\mathsf{T}} \\quad \\text{and} \\quad B = Q_B \\Lambda_B Q_B^{\\mathsf{T}} $$\nHere, $\\Lambda_A = \\mathrm{diag}(\\lambda_1, \\lambda_2, \\lambda_3)$ and $\\Lambda_B = \\mathrm{diag}(\\mu_1, \\mu_2, \\mu_3)$ contain the eigenvalues of $A$ and $B$, respectively. The columns of $Q_A$ are the eigenvectors of $A$, denoted $\\mathbf{q}_{Aj}$, and similarly for $Q_B$ and its columns $\\mathbf{q}_{Bi}$.\n\nTo derive the spectral form of the double dot product, we substitute these decompositions into the trace expression:\n$$ A:B = \\mathrm{tr}( (Q_A \\Lambda_A Q_A^{\\mathsf{T}}) (Q_B \\Lambda_B Q_B^{\\mathsf{T}}) ) $$\nWe leverage the cyclic property of the trace, $\\mathrm{tr}(WXYZ) = \\mathrm{tr}(ZWXY)$. By cyclically permuting $Q_B^{\\mathsf{T}}$ to the front of the product inside the trace, we obtain:\n$$ A:B = \\mathrm{tr}( Q_B^{\\mathsf{T}} Q_A \\Lambda_A Q_A^{\\mathsf{T}} Q_B \\Lambda_B ) $$\nLet us define an orthogonal matrix $C = Q_A^{\\mathsf{T}} Q_B$. This matrix represents the transformation from the eigenbasis of $B$ to that of $A$. Its transpose is $C^{\\mathsf{T}} = (Q_A^{\\mathsf{T}} Q_B)^{\\mathsf{T}} = Q_B^{\\mathsf{T}} Q_A$. The expression for the double dot product simplifies to:\n$$ A:B = \\mathrm{tr}( C^{\\mathsf{T}} \\Lambda_A C \\Lambda_B ) $$\nThis formula is basis-independent, as it depends only on the eigenvalues and the relative orientation of the eigenvectors. To make this explicit, we expand the trace. The $(i, m)$-th element of the matrix product inside the trace is:\n$$ (C^{\\mathsf{T}} \\Lambda_A C \\Lambda_B)_{im} = \\sum_{j,k,l} (C^{\\mathsf{T}})_{ij} (\\Lambda_A)_{jk} C_{kl} (\\Lambda_B)_{lm} $$\nSince $\\Lambda_A$ and $\\Lambda_B$ are diagonal, $(\\Lambda_A)_{jk} = \\delta_{jk} \\lambda_k$ and $(\\Lambda_B)_{lm} = \\delta_{lm} \\mu_m$. The transpose element is $(C^{\\mathsf{T}})_{ij} = C_{ji}$. The expression becomes:\n$$ (C^{\\mathsf{T}} \\Lambda_A C \\Lambda_B)_{im} = \\sum_{j,k,l} C_{ji} (\\delta_{jk} \\lambda_k) C_{kl} (\\delta_{lm} \\mu_m) = \\sum_{j} C_{ji} \\lambda_j C_{jm} \\mu_m $$\nThe trace is the sum of the diagonal elements ($i=m$):\n$$ A:B = \\sum_{i=1}^{3} \\left( \\sum_{j=1}^{3} C_{ji} \\lambda_j C_{ji} \\mu_i \\right) = \\sum_{i=1}^{3} \\sum_{j=1}^{3} \\lambda_j \\mu_i C_{ji}^2 $$\nThe matrix element $C_{ji} = (\\mathbf{q}_{Aj})^{\\mathsf{T}} (\\mathbf{q}_{Bi}) = \\mathbf{q}_{Aj} \\cdot \\mathbf{q}_{Bi}$ is the dot product between the $j^{th}$ eigenvector of $A$ and the $i^{th}$ eigenvector of $B$. Its square, $C_{ji}^2$, represents the geometric alignment between these two principal directions. This formula provides the exact value of $A:B$ from spectral data and serves as the \"spectral-decomposition value\".\n\nNext, we establish the validity condition for the simplified expression $A:B = \\sum_{i=1}^{3} \\lambda_i \\mu_i$. This form suggests a direct pairing of eigenvalues, which is only physically meaningful if the principal directions of the tensors are aligned. This condition is known as co-axiality. Two symmetric tensors are co-axial if and only if they are simultaneously diagonalizable by the same orthogonal matrix $Q$. An equivalent necessary and sufficient condition is that the tensors commute, i.e., $AB=BA$.\nIf $A$ and $B$ are co-axial, we can set $Q_A = Q_B = Q$. The alignment matrix becomes $C = Q_A^{\\mathsf{T}} Q_B = Q^{\\mathsf{T}}Q = I$, the identity matrix. The elements are thus $C_{ji} = \\delta_{ji}$ (Kronecker delta). Substituting this into the general spectral formula yields:\n$$ A:B = \\sum_{i,j} \\lambda_j \\mu_i (\\delta_{ji})^2 = \\sum_{i,j} \\lambda_j \\mu_i \\delta_{ji} = \\sum_{i=1}^{3} \\lambda_i \\mu_i $$\nThis proves that the simplified formula is valid if and only if the tensors are co-axial and the eigenvalues $\\lambda_i, \\mu_i$ are paired according to their shared eigenvectors. An isotropic tensor of the form $kI$ is co-axial with any other symmetric tensor, as any set of orthonormal vectors forms a valid eigenbasis for it.\n\nThe algorithmic implementation is as follows:\n$1$. The direct value is computed as $A:B = \\sum_{ij} A_{ij}B_{ij}$.\n$2$. The spectral value is computed using the general formula $A:B = \\sum_{i,j} \\lambda_j \\mu_i C_{ji}^2$, where $(\\lambda, Q_A)$ and $(\\mu, Q_B)$ are the eigenpairs of $A$ and $B$, and $C=Q_A^{\\mathsf{T}}Q_B$. This value must numerically match the direct value.\n$3$. The \"paired sum\" requires establishing an optimal correspondence between the eigenvalues. Standard numerical eigensolvers sort eigenvalues, which may decorrelate the pairings. A robust method is to find the permutation $\\pi$ of the indices $\\{1,2,3\\}$ that maximizes the total eigenvector alignment, $\\sum_{i=1}^3 |C_{i, \\pi(i)}|$. This is a classic assignment problem, which can be solved efficiently. The paired sum is then $\\sum_{i=1}^3 \\lambda_i \\mu_{\\pi(i)}$.\n$4$. The boolean check for the validity of the simplified formula compares the direct value against this paired sum within a given numerical tolerance. The equality holds if and only if the tensors are co-axial.", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef solve():\n    \"\"\"\n    Derives, implements, and tests an algorithm for computing the double dot\n    product of two second-order tensors using spectral decomposition.\n    \"\"\"\n    \n    # Numerical tolerance for comparisons\n    TOLERANCE = 1e-12\n\n    def R_x(phi):\n        \"\"\"Rotation matrix about the x-axis.\"\"\"\n        c, s = np.cos(phi), np.sin(phi)\n        return np.array([[1, 0, 0], [0, c, -s], [0, s, c]])\n\n    def R_y(alpha):\n        \"\"\"Rotation matrix about the y-axis.\"\"\"\n        c, s = np.cos(alpha), np.sin(alpha)\n        return np.array([[c, 0, s], [0, 1, 0], [-s, 0, c]])\n\n    def R_z(theta):\n        \"\"\"Rotation matrix about the z-axis.\"\"\"\n        c, s = np.cos(theta), np.sin(theta)\n        return np.array([[c, -s, 0], [s, c, 0], [0, 0, 1]])\n\n    def compute_metrics(A, B):\n        \"\"\"\n        Computes the double dot product using three methods and checks equality.\n\n        Args:\n            A (np.ndarray): A 3x3 real symmetric tensor.\n            B (np.ndarray): A 3x3 real symmetric tensor.\n        \n        Returns:\n            list: [direct_val, spectral_val, paired_sum_val, is_equal_bool]\n        \"\"\"\n        # 1. Direct component-wise computation: A:B = sum(A_ij * B_ij)\n        # This is the ground truth value.\n        direct_val = np.sum(A * B)\n\n        # 2. Spectral decomposition\n        # np.linalg.eigh is used for real symmetric matrices.\n        # It returns eigenvalues in ascending order and corresponding eigenvectors.\n        lambda_vals, Q_A = np.linalg.eigh(A)\n        mu_vals, Q_B = np.linalg.eigh(B)\n\n        # 3. General spectral formula computation: A:B = sum_{i,j} lambda_j * mu_i * C_ji^2\n        # C is the alignment matrix C = Q_A^T @ Q_B.\n        C = Q_A.T @ Q_B\n        C_sq = C**2\n        \n        # Create outer products of eigenvalues and multiply element-wise with C_sq\n        # The sum is over j (rows) and i (columns): sum_{j,i} lambda_j mu_i C_ji^2\n        # `lambda_vals[:, None]` is a column vector (3,1) of eigenvalues of A\n        # `mu_vals[None, :]` is a row vector (1,3) of eigenvalues of B\n        lambda_mu_matrix = lambda_vals[:, np.newaxis] * mu_vals[np.newaxis, :]\n        spectral_val = np.sum(lambda_mu_matrix * C_sq)\n\n        # 4. Paired eigenvalue sum: sum_i lambda_i * mu_pi(i)\n        # We must find the optimal pairing of eigenvectors that maximizes alignment.\n        # This is an assignment problem. We want to maximize sum(|C_ij|) for a permutation.\n        # linear_sum_assignment finds a minimum cost assignment.\n        # Cost is set to -|C| to maximize |C|.\n        cost_matrix = -np.abs(C)\n        row_ind, col_ind = linear_sum_assignment(cost_matrix)\n        \n        # 'col_ind' contains the permutation of B's eigenvalues that best aligns\n        # with A's eigenvalues (which are in sorted order, indices 0,1,2).\n        paired_sum_val = np.sum(lambda_vals * mu_vals[col_ind])\n\n        # 5. Check if the simplified co-axial formula holds\n        is_equal_bool = np.isclose(direct_val, paired_sum_val, atol=TOLERANCE, rtol=0)\n\n        return [direct_val, spectral_val, paired_sum_val, is_equal_bool]\n\n    # --- Test Suite ---\n    test_cases = []\n\n    # Case 1: Co-axial, diagonal tensors\n    A1 = np.diag([3., 2., 1.])\n    B1 = np.diag([5., -1., 4.])\n    test_cases.append((A1, B1))\n\n    # Case 2: Co-axial tensors, rotated eigenbasis\n    theta = np.pi / 4.\n    Rz = R_z(theta)\n    L_A2 = np.diag([7., 0., -2.])\n    L_B2 = np.diag([1., 3., 4.])\n    A2 = Rz @ L_A2 @ Rz.T\n    B2 = Rz @ L_B2 @ Rz.T\n    test_cases.append((A2, B2))\n\n    # Case 3: Non-co-axial tensors\n    phi = np.pi / 6.\n    Rx = R_x(phi)\n    A3 = np.diag([2., -1., 3.])\n    L_B3 = np.diag([4., 6., -2.])\n    B3 = Rx @ L_B3 @ Rx.T\n    test_cases.append((A3, B3))\n\n    # Case 4: Isotropic tensor with another tensor (always co-axial)\n    alpha = np.pi / 7.\n    Ry = R_y(alpha)\n    A4 = 5. * np.identity(3)\n    L_B4 = np.diag([10., -2., 1.])\n    B4 = Ry @ L_B4 @ Ry.T\n    test_cases.append((A4, B4))\n\n    # --- Execution and Output ---\n    results_list = []\n    for A, B in test_cases:\n        case_results = compute_metrics(A, B)\n        results_list.append(case_results)\n\n    # Format output string exactly as required.\n    # Eg: [[case1_val1,case1_val2,...],[case2_val1,case2_val2,...]]\n    def format_list(lst):\n        items = []\n        for item in lst:\n            if isinstance(item, bool):\n                items.append(str(item))\n            else:\n                items.append(f\"{item:.14g}\") # Use general format for precision\n        return f\"[{','.join(items)}]\"\n\n    output_str = f\"[{','.join(map(format_list, results_list))}]\"\n    print(output_str)\n\nsolve()\n\n```", "id": "3604862"}]}