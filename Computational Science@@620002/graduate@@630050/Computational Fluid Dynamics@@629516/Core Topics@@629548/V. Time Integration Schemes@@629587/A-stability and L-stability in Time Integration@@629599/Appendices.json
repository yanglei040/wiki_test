{"hands_on_practices": [{"introduction": "The first step in analyzing any time integration scheme is to derive its stability function, $R(z)$, which governs how numerical solutions grow or decay. This practice provides a foundational exercise in this technique by applying the Backward Euler method, a cornerstone L-stable scheme, to the scalar test equation. By connecting the abstract parameter $z=h\\lambda$ to the properties of a discretized diffusion problem, you will see how theoretical stability analysis directly relates to physical systems [@problem_id:3287261].", "problem": "Consider the one-dimensional heat equation $u_{t}=\\nu u_{xx}$ on a periodic domain, discretized in space using second-order central finite differences on a uniform grid with spacing $\\Delta x>0$. This yields a semi-discrete linear system $\\frac{d\\mathbf{u}}{dt}=\\mathbf{A}\\mathbf{u}$, where $\\mathbf{A}$ is the discrete diffusion operator. For this operator, the largest (least negative) eigenvalue in magnitude that controls the fastest-decaying Fourier mode is well-approximated by $\\lambda_{\\max}\\approx -\\frac{4\\nu}{\\Delta x^{2}}$. Let $h>0$ denote the time step. \n\nChoose the one-stage Singly Diagonally Implicit Runge-Kutta (SDIRK) scheme (Backward Euler), which is L-stable and defined by the Butcher tableau with $c=[1]$, $A=[1]$, and $b=[1]$. For a single eigenmode governed by the scalar test equation $y'(t)=\\lambda\\,y(t)$, the one-step update of this method can be written in the form $y_{n+1}=R(h\\lambda)\\,y_{n}$, where $R$ is the amplification factor (stability function). \n\nStarting from the definition of the Backward Euler method and the semi-discrete linear evolution for a single eigenmode, derive the amplification factor $R(z)$ for $z=h\\lambda$, and then evaluate it at the diffusive extreme $z=h\\lambda_{\\max}$ with $\\lambda_{\\max}\\approx -\\frac{4\\nu}{\\Delta x^{2}}$. Provide your final result as a single simplified analytic expression in terms of $h$, $\\nu$, and $\\Delta x$. Do not include units and do not round.", "solution": "The problem requires the derivation of the amplification factor for the Backward Euler method and its evaluation for a specific case related to the one-dimensional heat equation. The process is comprised of two main steps: first, deriving the stability function $R(z)$, and second, substituting the given value of $z$ into this function.\n\nThe Backward Euler method is a one-stage Singly Diagonally Implicit Runge-Kutta (SDIRK) method. For a general initial value problem of the form $\\frac{dy}{dt} = f(t,y)$, the update from time step $n$ to $n+1$ is given by:\n$$y_{n+1} = y_n + h f(t_{n+1}, y_{n+1})$$\nwhere $h$ is the time step size.\n\nThe problem specifies the application of this method to the scalar linear test equation:\n$$\\frac{dy}{dt} = \\lambda y$$\nFor this equation, the function $f$ is $f(t,y) = \\lambda y$. Substituting this into the Backward Euler formula yields:\n$$y_{n+1} = y_n + h (\\lambda y_{n+1})$$\n\nThe amplification factor, or stability function, $R(z)$, is defined by the relation $y_{n+1} = R(z) y_n$, where $z = h\\lambda$. To find $R(z)$, we must solve the update equation for $y_{n+1}$ in terms of $y_n$.\nRearranging the equation to group terms with $y_{n+1}$:\n$$y_{n+1} - h\\lambda y_{n+1} = y_n$$\nFactoring out $y_{n+1}$ from the left-hand side:\n$$y_{n+1} (1 - h\\lambda) = y_n$$\nDividing by $y_n$ and by $(1-h\\lambda)$ gives the ratio $\\frac{y_{n+1}}{y_n}$:\n$$\\frac{y_{n+1}}{y_n} = \\frac{1}{1 - h\\lambda}$$\nBy definition, this ratio is the amplification factor $R(z)$. Substituting $z = h\\lambda$, we have:\n$$R(z) = \\frac{1}{1 - z}$$\nThis completes the first part of the derivation.\n\nNext, we must evaluate this amplification factor for the specific case given. The problem concerns the semi-discretized heat equation, $u_t = \\nu u_{xx}$, where the largest magnitude eigenvalue of the spatial discretization operator is approximated as:\n$$\\lambda_{\\max} \\approx -\\frac{4\\nu}{\\Delta x^{2}}$$\nThis eigenvalue corresponds to the fastest-decaying mode and imposes the most stringent stability constraint on explicit methods. The argument $z$ of the stability function is $z = h\\lambda$. For this specific mode, we have:\n$$z = h \\lambda_{\\max} \\approx h \\left( -\\frac{4\\nu}{\\Delta x^{2}} \\right) = -\\frac{4h\\nu}{\\Delta x^{2}}$$\nNow, we substitute this specific expression for $z$ into the derived stability function $R(z)$:\n$$R\\left(-\\frac{4h\\nu}{\\Delta x^{2}}\\right) = \\frac{1}{1 - \\left(-\\frac{4h\\nu}{\\Delta x^{2}}\\right)}$$\nSimplifying the denominator:\n$$R = \\frac{1}{1 + \\frac{4h\\nu}{\\Delta x^{2}}}$$\nTo obtain a single simplified fraction, we find a common denominator for the expression in the denominator of the main fraction:\n$$1 + \\frac{4h\\nu}{\\Delta x^{2}} = \\frac{\\Delta x^{2}}{\\Delta x^{2}} + \\frac{4h\\nu}{\\Delta x^{2}} = \\frac{\\Delta x^{2} + 4h\\nu}{\\Delta x^{2}}$$\nSubstituting this back into the expression for $R$:\n$$R = \\frac{1}{\\frac{\\Delta x^{2} + 4h\\nu}{\\Delta x^{2}}}$$\nFinally, inverting the denominator gives the simplified analytic expression:\n$$R = \\frac{\\Delta x^{2}}{\\Delta x^{2} + 4h\\nu}$$\nThis is the final result, expressed in terms of the given parameters $h$, $\\nu$, and $\\Delta x$.", "answer": "$$\\boxed{\\frac{\\Delta x^{2}}{\\Delta x^{2} + 4h\\nu}}$$", "id": "3287261"}, {"introduction": "Beyond analyzing existing methods, a deeper understanding comes from exploring their design, where stability and accuracy are often competing objectives. This exercise delves into a two-stage Singly Diagonally Implicit Runge-Kutta (SDIRK) method, where a parameter $\\gamma$ controls its properties. By finding the conditions on $\\gamma$ that ensure both A-stability and second-order accuracy, you will gain insight into the compromises and constraints inherent in constructing effective numerical integrators [@problem_id:3287209].", "problem": "In computational fluid dynamics, implicit time integrators are used to handle stiffness in semi-discrete systems arising from spatial discretization of conservation laws. Consider the linear test equation $y^{\\prime} = \\lambda y$ with $z = h \\lambda$, where $h$ is the time step. A Runge–Kutta discretization of this equation yields an amplification factor $R(z)$ such that $y_{n+1} = R(z) y_n$. A method is said to be A-stable (absolute stability) if $|R(z)| \\le 1$ for all $z$ with $\\Re(z) \\le 0$, and L-stable if it is A-stable and additionally satisfies $\\lim_{z \\to -\\infty} R(z) = 0$.\n\nAnalyze the following two-stage singly diagonally implicit Runge–Kutta (SDIRK) method with a common diagonal coefficient $\\gamma$ and stiff accuracy (the weights equal the last row of the Butcher matrix). Its Butcher tableau is\n$$\n\\begin{array}{c|cc}\n\\gamma  \\gamma  0 \\\\\n1  1-\\gamma  \\gamma \\\\\n\\hline\n 1-\\gamma  \\gamma\n\\end{array}\n$$\nThis corresponds to $s=2$ stages, coefficient matrix $A = \\begin{pmatrix} \\gamma  0 \\\\ 1-\\gamma  \\gamma \\end{pmatrix}$, weights $b = \\begin{pmatrix} 1-\\gamma \\\\ \\gamma \\end{pmatrix}$, and abscissae $c = \\begin{pmatrix} \\gamma \\\\ 1 \\end{pmatrix}$.\n\nStarting from the definition of $R(z)$ for Runge–Kutta methods applied to $y^{\\prime}=\\lambda y$, and using only fundamental properties of matrices and complex arithmetic, do the following:\n- Derive an explicit closed-form expression for the stability function $R(z)$ in terms of $z$ and $\\gamma$.\n- Determine the complete set of real $\\gamma$ values for which the method is A-stable.\n- Impose the additional requirement that the method has classical order $p=2$ and determine the unique real $\\gamma$ in the interval $(0,1)$ that satisfies this order condition together with stiff accuracy.\n\nFor grading, report only the exact value of the unique $\\gamma$ in $(0,1)$ that yields classical order $p=2$. Your final answer must be a single closed-form expression with no units.", "solution": "The problem asks for an analysis of a two-stage singly diagonally implicit Runge–Kutta (SDIRK) method applied to the linear test equation $y^{\\prime} = \\lambda y$. The method is defined by the Butcher tableau:\n$$\n\\begin{array}{c|cc}\n\\gamma  \\gamma  0 \\\\\n1  1-\\gamma  \\gamma \\\\\n\\hline\n 1-\\gamma  \\gamma\n\\end{array}\n$$\nThe coefficient matrix is $A = \\begin{pmatrix} \\gamma  0 \\\\ 1-\\gamma  \\gamma \\end{pmatrix}$, the weights vector is $\\mathbf{b} = \\begin{pmatrix} 1-\\gamma \\\\ \\gamma \\end{pmatrix}$, and the vector of ones is $\\mathbf{1} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$.\n\n**Part 1: Derivation of the Stability Function $R(z)$**\n\nThe stability function $R(z)$ for a Runge-Kutta method applied to $y^{\\prime} = \\lambda y$ is given by the relation $y_{n+1} = R(z) y_n$, where $z = h \\lambda$. The general form for $R(z)$ for an implicit Runge-Kutta method is:\n$$R(z) = 1 + z \\mathbf{b}^T (\\mathbf{I} - zA)^{-1} \\mathbf{1}$$\nwhere $\\mathbf{I}$ is the identity matrix.\n\nFirst, we compute the matrix $(\\mathbf{I} - zA)$:\n$$ \\mathbf{I} - zA = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} - z \\begin{pmatrix} \\gamma  0 \\\\ 1-\\gamma  \\gamma \\end{pmatrix} = \\begin{pmatrix} 1 - z\\gamma  0 \\\\ -z(1-\\gamma)  1 - z\\gamma \\end{pmatrix} $$\nThis is a lower triangular matrix. Its determinant is $\\det(\\mathbf{I} - zA) = (1 - z\\gamma)^2$. The inverse is:\n$$ (\\mathbf{I} - zA)^{-1} = \\frac{1}{(1-z\\gamma)^2} \\begin{pmatrix} 1 - z\\gamma  0 \\\\ z(1-\\gamma)  1 - z\\gamma \\end{pmatrix} $$\nNext, we compute the product $(\\mathbf{I} - zA)^{-1} \\mathbf{1}$:\n$$ (\\mathbf{I} - zA)^{-1} \\mathbf{1} = \\frac{1}{(1-z\\gamma)^2} \\begin{pmatrix} 1 - z\\gamma  0 \\\\ z(1-\\gamma)  1 - z\\gamma \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{(1-z\\gamma)^2} \\begin{pmatrix} 1 - z\\gamma \\\\ z(1-\\gamma) + 1 - z\\gamma \\end{pmatrix} = \\frac{1}{(1-z\\gamma)^2} \\begin{pmatrix} 1 - z\\gamma \\\\ 1 + z(1-2\\gamma) \\end{pmatrix} $$\nNow, we pre-multiply by $z \\mathbf{b}^T$:\n\\begin{align*} z \\mathbf{b}^T (\\mathbf{I} - zA)^{-1} \\mathbf{1} = \\frac{z}{(1-z\\gamma)^2} \\begin{pmatrix} 1-\\gamma  \\gamma \\end{pmatrix} \\begin{pmatrix} 1 - z\\gamma \\\\ 1 + z(1-2\\gamma) \\end{pmatrix} \\\\ = \\frac{z}{(1-z\\gamma)^2} \\left[ (1-\\gamma)(1-z\\gamma) + \\gamma(1 + z(1-2\\gamma)) \\right] \\\\ = \\frac{z}{(1-z\\gamma)^2} \\left[ (1 - z\\gamma - \\gamma + z\\gamma^2) + (\\gamma + z\\gamma - 2z\\gamma^2) \\right] \\\\ = \\frac{z}{(1-z\\gamma)^2} \\left[ 1 - z\\gamma^2 \\right] \\end{align*}\nFinally, we substitute this back into the expression for $R(z)$:\n$$ R(z) = 1 + \\frac{z(1 - z\\gamma^2)}{(1-z\\gamma)^2} = \\frac{(1-z\\gamma)^2 + z - z^2\\gamma^2}{(1-z\\gamma)^2} = \\frac{1 - 2z\\gamma + z^2\\gamma^2 + z - z^2\\gamma^2}{(1-z\\gamma)^2} $$\nThe explicit closed-form expression for the stability function is:\n$$ R(z) = \\frac{1 + z(1-2\\gamma)}{(1-z\\gamma)^2} $$\n\n**Part 2: A-stability Analysis**\n\nA method is A-stable if $|R(z)| \\le 1$ for all complex numbers $z$ with $\\Re(z) \\le 0$. For $R(z)$ to be analytic in the left-half complex plane, its pole at $z = 1/\\gamma$ must not be in this region. This requires $\\gamma > 0$. Under this condition, the Maximum Modulus Principle applies, and we only need to check the boundary, i.e., the imaginary axis, where $z=iy$ for $y \\in \\mathbb{R}$.\nWe require $|R(iy)|^2 \\le 1$:\n$$ |R(iy)|^2 = \\left| \\frac{1 + iy(1-2\\gamma)}{(1-iy\\gamma)^2} \\right|^2 = \\frac{|1 + iy(1-2\\gamma)|^2}{|(1-iy\\gamma)^2|^2} = \\frac{1^2 + (y(1-2\\gamma))^2}{(|1-iy\\gamma|^2)^2} = \\frac{1 + y^2(1-2\\gamma)^2}{(1+y^2\\gamma^2)^2} \\le 1 $$\nThis inequality must hold for all $y \\in \\mathbb{R}$.\n$$ 1 + y^2(1-2\\gamma)^2 \\le (1+y^2\\gamma^2)^2 = 1 + 2y^2\\gamma^2 + y^4\\gamma^4 $$\n$$ y^2(1-4\\gamma+4\\gamma^2) \\le 2y^2\\gamma^2 + y^4\\gamma^4 $$\nFor $y \\neq 0$, we can divide by $y^2$:\n$$ 1-4\\gamma+4\\gamma^2 \\le 2\\gamma^2 + y^2\\gamma^4 $$\nRearranging the terms, we get:\n$$ 2\\gamma^2 - 4\\gamma + 1 \\le y^2\\gamma^4 $$\nSince the term $y^2\\gamma^4$ is always non-negative for real $y$ and $\\gamma$, this inequality holds for all $y \\in \\mathbb{R}$ if and only if the left-hand side is less than or equal to the minimum value of the right-hand side, which is $0$. Thus, the condition for A-stability becomes:\n$$ 2\\gamma^2 - 4\\gamma + 1 \\le 0 $$\nThe roots of the quadratic equation $2\\gamma^2 - 4\\gamma + 1 = 0$ are found using the quadratic formula:\n$$ \\gamma = \\frac{4 \\pm \\sqrt{16 - 4(2)(1)}}{4} = \\frac{4 \\pm \\sqrt{8}}{4} = 1 \\pm \\frac{2\\sqrt{2}}{4} = 1 \\pm \\frac{\\sqrt{2}}{2} $$\nThe quadratic $2\\gamma^2 - 4\\gamma + 1$ is a parabola opening upwards, so it is non-positive between its roots. The complete set of real $\\gamma$ values for which the method is A-stable is:\n$$ \\gamma \\in \\left[ 1 - \\frac{\\sqrt{2}}{2}, 1 + \\frac{\\sqrt{2}}{2} \\right] $$\nThis range consists of positive values, confirming our earlier assumption $\\gamma>0$.\n\n**Part 3: Order Condition for $p=2$**\n\nThe problem specifies that the method is stiffly accurate. The order conditions for a Runge-Kutta method are as follows:\n- Order $p=1$: $\\sum_{i} b_i = 1$.\n- Order $p=2$: $\\sum_{i} b_i c_i = \\frac{1}{2}$.\n\nFirst, we check the order $1$ condition. The weights are $b_1 = 1-\\gamma$ and $b_2 = \\gamma$.\n$$ \\sum_{i} b_i = (1-\\gamma) + \\gamma = 1 $$\nThis condition is satisfied for any value of $\\gamma$, so the method is at least of order $1$.\n\nNext, we impose the order $2$ condition. The abscissae are $c_1 = \\gamma$ and $c_2 = 1$.\n$$ \\sum_{i} b_i c_i = b_1 c_1 + b_2 c_2 = (1-\\gamma)(\\gamma) + (\\gamma)(1) = \\gamma - \\gamma^2 + \\gamma = 2\\gamma - \\gamma^2 $$\nSetting this equal to $\\frac{1}{2}$:\n$$ 2\\gamma - \\gamma^2 = \\frac{1}{2} $$\n$$ 4\\gamma - 2\\gamma^2 = 1 $$\n$$ 2\\gamma^2 - 4\\gamma + 1 = 0 $$\nThis is the same quadratic equation encountered in the A-stability analysis. The solutions are $\\gamma = 1 \\pm \\frac{\\sqrt{2}}{2}$.\nThe problem asks for the unique real value of $\\gamma$ in the interval $(0, 1)$.\nLet's evaluate the two solutions:\n- $\\gamma_1 = 1 - \\frac{\\sqrt{2}}{2} \\approx 1 - 0.7071 = 0.2929$. This value lies in the interval $(0, 1)$.\n- $\\gamma_2 = 1 + \\frac{\\sqrt{2}}{2} \\approx 1 + 0.7071 = 1.7071$. This value is outside the interval $(0, 1)$.\n\nTherefore, the unique real value of $\\gamma$ in $(0, 1)$ that yields a method of classical order $p=2$ is $1 - \\frac{\\sqrt{2}}{2}$. This value is one of the endpoints of the A-stability interval, meaning the method is A-stable for this choice of $\\gamma$.", "answer": "$$ \\boxed{1 - \\frac{\\sqrt{2}}{2}} $$", "id": "3287209"}, {"introduction": "The theoretical distinction between A-stability and the stronger condition of L-stability has critical practical consequences, especially for stiff problems common in CFD which contain fast-decaying transients. This capstone exercise demonstrates this by analyzing the modern, L-stable TR-BDF2 method and pitting it against the merely A-stable Crank-Nicolson method in a numerical experiment. By quantifying the reduction in non-physical oscillations, you will gain a tangible appreciation for why L-stability is a crucial property for robustly solving problems with sharp gradients or boundary layers [@problem_id:3287222].", "problem": "Consider the initial value problem for an Ordinary Differential Equation (ODE) $y'(t) = f(y(t))$ with a sufficiently smooth function $f$, and its linearization on the scalar test equation $y'(t) = \\lambda y(t)$ where $\\lambda \\in \\mathbb{C}$. The Trapezoidal Rule–Backward Differentiation Formula of order $2$ (TR-BDF2) method uses two substeps per timestep of size $h$: a Trapezoidal Rule (TR) substep of size $\\gamma h$ followed by a Backward Differentiation Formula of order $2$ (BDF2) substep of size $(1 - \\gamma) h$. In computational fluid dynamics, time integration schemes are assessed using Absolute stability (A-stability) and $L$-stability. A-stability means the method is stable for all $\\lambda$ with $\\operatorname{Re}(\\lambda) \\le 0$ for any stepsize $h > 0$; $L$-stability further requires the stability function $R(z)$ to satisfy $\\lim_{z \\to -\\infty} R(z) = 0$ for $z = h \\lambda$, guaranteeing strong damping of fast modes.\n\nYour tasks are:\n\n- Construct the stability function $R(z)$ for the TR-BDF2 method applied to the test equation $y'(t) = \\lambda y(t)$, with parameter $\\gamma \\in (0,1)$. Prove that TR-BDF2 is $L$-stable for any fixed $\\gamma \\in (0,1)$; that is, show $\\lim_{z \\to -\\infty} R(z) = 0$ along the negative real axis.\n- Implement the TR-BDF2 method with the standard parameter choice $\\gamma = 1 - 1/\\sqrt{2}$ and compare it against the Crank–Nicolson method (which is A-stable but not $L$-stable) on a semi-discrete boundary layer model. The model is the one-dimensional diffusion Partial Differential Equation (PDE) $u_t = \\nu u_{xx}$ on the domain $x \\in (0,1)$ with Dirichlet boundary conditions $u(0,t) = 1$ and $u(1,t) = 0$, and initial condition $u(x,0) = 0$. After uniform second-order central differencing in space on $N$ interior points (grid spacing $\\Delta x = 1/(N+1)$), the semi-discrete system is $y'(t) = A y(t) + b$, where $A$ is the standard tridiagonal discrete Laplacian scaled by $\\nu/\\Delta x^2$ and $b$ encodes the boundary values. This semi-discrete system is stiff for small $\\Delta x$. The physically admissible solution satisfies $u(x,t) \\in [0,1]$ for all $x,t$. Numerical overshoot is any violation of these bounds.\n\nDefine the overshoot magnitude at time step $n$ as the largest magnitude of bound violation across the grid, i.e., if the reconstructed full state (including boundaries) is $u^{(n)} \\in \\mathbb{R}^{N+2}$, then\n$$\n\\mathrm{overshoot}(n) = \\max\\left\\{ \\max_i \\left(u^{(n)}_i - 1,\\, 0\\right),\\; \\max_i \\left(0 - u^{(n)}_i,\\, 0\\right) \\right\\}.\n$$\nDefine the global overshoot magnitude over a run as\n$$\n\\mathrm{Overshoot} = \\max_n \\mathrm{overshoot}(n).\n$$\n\nNumerically quantify the reduction of overshoot achieved by TR-BDF2 relative to Crank–Nicolson as the nonnegative difference\n$$\n\\mathrm{Reduction} = \\mathrm{Overshoot}_{\\text{CN}} - \\mathrm{Overshoot}_{\\text{TR-BDF2}}.\n$$\n\nAll quantities are dimensionless. Angles do not appear. Your program must construct $A$ and $b$ for the semi-discrete model and time-advance both methods over a fixed number of time steps, tracking the global overshoot for each method and computing the reduction.\n\nUse the following test suite, where each test case is a tuple $(N, \\nu, \\alpha, M)$ with $N$ interior points, diffusivity $\\nu$, timestep $h = \\alpha \\Delta x^2 / \\nu$, and $M$ the number of timesteps:\n\n- Test Case $1$: $(N, \\nu, \\alpha, M) = (64, 1.0, 5.0, 20)$.\n- Test Case $2$: $(N, \\nu, \\alpha, M) = (64, 1.0, 50.0, 20)$.\n- Test Case $3$: $(N, \\nu, \\alpha, M) = (64, 1.0, 200.0, 20)$.\n\nThese cases explore a moderate timestep, a large timestep that induces noticeable stiffness, and a very large timestep approaching the regime where Crank–Nicolson exhibits severe nonphysical oscillations.\n\nFinal output format: Your program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets, in the order of the test cases, e.g., $[r_1,r_2,r_3]$, where each $r_i$ is a float equal to $\\mathrm{Reduction}$ for the corresponding test case.", "solution": "### Part 1: Theoretical Analysis of TR-BDF2\n\nThe TR-BDF2 method is a composite, one-step, two-stage scheme. For a given time step of size $h$, it consists of a Trapezoidal Rule (TR) substep of size $\\gamma h$ and a Backward Differentiation Formula of order 2 (BDF2) substep of size $(1-\\gamma)h$, where $\\gamma \\in (0,1)$. We analyze its stability by applying the method to the scalar test equation $y'(t) = \\lambda y(t)$, where $\\lambda \\in \\mathbb{C}$. Let $z = h\\lambda$.\n\n**1. Derivation of the Stability Function $R(z)$**\n\nWe denote the numerical solution at time $t_n$ as $y_n$. The first substep computes an intermediate solution $y_{n+\\gamma}$ at time $t_n + \\gamma h$. The second substep computes the final solution $y_{n+1}$ at time $t_n + h$. We use the formulation presented in standard literature (e.g., Hundsdorfer  Verwer, \"Numerical Solution of Time-Dependent Advection-Diffusion-Reaction Equations\").\n\n**Substep 1: Trapezoidal Rule (TR)**\nThe TR A-stable scheme is applied over the interval $[t_n, t_n + \\gamma h]$:\n$$\n\\frac{y_{n+\\gamma} - y_n}{\\gamma h} = \\frac{1}{2} (\\lambda y_n + \\lambda y_{n+\\gamma})\n$$\nRearranging and substituting $z = h\\lambda$:\n$$\ny_{n+\\gamma} - y_n = \\frac{\\gamma z}{2} (y_n + y_{n+\\gamma})\n$$\n$$\ny_{n+\\gamma} \\left(1 - \\frac{\\gamma z}{2}\\right) = y_n \\left(1 + \\frac{\\gamma z}{2}\\right)\n$$\nThis gives the intermediate solution in terms of the previous solution:\n$$\ny_{n+\\gamma} = \\frac{1 + \\gamma z/2}{1 - \\gamma z/2} y_n\n$$\n\n**Substep 2: Backward Differentiation Formula of order 2 (BDF2)**\nThe second substep uses the three time levels $t_n$, $t_n+\\gamma h$, and $t_n+h$ to advance the solution. The one-leg formulation of the variable-step BDF2 method is:\n$$\ny_{n+1} = \\frac{1}{\\gamma(2-\\gamma)}y_{n+\\gamma} - \\frac{(1-\\gamma)^2}{\\gamma(2-\\gamma)}y_n + \\frac{h(1-\\gamma)}{2-\\gamma} f(y_{n+1})\n$$\nFor the test equation $f(y_{n+1}) = \\lambda y_{n+1}$, this becomes:\n$$\ny_{n+1} = \\frac{1}{\\gamma(2-\\gamma)}y_{n+\\gamma} - \\frac{(1-\\gamma)^2}{\\gamma(2-\\gamma)}y_n + \\frac{z(1-\\gamma)}{2-\\gamma}y_{n+1}\n$$\nCollecting terms in $y_{n+1}$:\n$$\ny_{n+1}\\left(1 - \\frac{z(1-\\gamma)}{2-\\gamma}\\right) = \\frac{1}{\\gamma(2-\\gamma)}\\left(y_{n+\\gamma} - (1-\\gamma)^2 y_n\\right)\n$$\n$$\ny_{n+1}\\left(\\frac{2-\\gamma - z(1-\\gamma)}{2-\\gamma}\\right) = \\frac{1}{\\gamma(2-\\gamma)}\\left(y_{n+\\gamma} - (1-\\gamma)^2 y_n\\right)\n$$\nNow, we substitute the expression for $y_{n+\\gamma}$ from the TR step:\n$$\ny_{n+1}\\left(\\frac{2-\\gamma - z(1-\\gamma)}{2-\\gamma}\\right) = \\frac{1}{\\gamma(2-\\gamma)}\\left(\\frac{1 + \\gamma z/2}{1 - \\gamma z/2} y_n - (1-\\gamma)^2 y_n\\right)\n$$\nFactoring out $y_n$ and combining terms on the right-hand side:\n$$\ny_{n+1}\\left(\\dots\\right) = \\frac{y_n}{\\gamma(2-\\gamma)(1-\\gamma z/2)} \\left[ (1 + \\gamma z/2) - (1-\\gamma)^2(1 - \\gamma z/2) \\right]\n$$\nThe term in the square brackets simplifies to:\n$$\n1 + \\frac{\\gamma z}{2} - (1-2\\gamma+\\gamma^2) + (1-2\\gamma+\\gamma^2)\\frac{\\gamma z}{2} = (2\\gamma - \\gamma^2) + \\frac{\\gamma z}{2}(2-2\\gamma+\\gamma^2)\n$$\nSubstituting this back and simplifying the equation for $y_{n+1}$:\n$$\ny_{n+1}\\left(\\frac{2-\\gamma - z(1-\\gamma)}{2-\\gamma}\\right) = \\frac{y_n}{\\gamma(2-\\gamma)(1-\\gamma z/2)} \\left[ \\gamma(2-\\gamma) + \\frac{\\gamma z}{2}(2-2\\gamma+\\gamma^2) \\right]\n$$\n$$\ny_{n+1}\\left(\\frac{2-\\gamma - z(1-\\gamma)}{2-\\gamma}\\right) = \\frac{y_n}{(2-\\gamma)(1-\\gamma z/2)} \\left[ (2-\\gamma) + \\frac{z}{2}(2-2\\gamma+\\gamma^2) \\right]\n$$\nThe stability function $R(z) = y_{n+1}/y_n$ is therefore:\n$$\nR(z) = \\frac{2-\\gamma}{2-\\gamma - (1-\\gamma)z} \\cdot \\frac{(2-\\gamma) + \\frac{z}{2}(2-2\\gamma+\\gamma^2)}{(2-\\gamma)(1-\\gamma z/2)}\n$$\n$$\nR(z) = \\frac{(2-\\gamma) + \\frac{1}{2}(2-2\\gamma+\\gamma^2)z}{\\left(2-\\gamma - (1-\\gamma)z\\right)\\left(1-\\frac{\\gamma}{2}z\\right)}\n$$\n\n**2. Proof of L-stability**\n\nA method is L-stable if it is A-stable and its stability function satisfies $\\lim_{z \\to -\\infty} R(z) = 0$ for real $z$. To demonstrate L-stability, we evaluate this limit for the derived $R(z)$. For $z \\in \\mathbb{R}$ and $z \\to -\\infty$, the highest power of $z$ in the numerator and denominator determines the limit.\nThe numerator is a polynomial of degree $1$ in $z$: $P_1(z) = \\frac{1}{2}(2-2\\gamma+\\gamma^2)z + (2-\\gamma)$.\nThe denominator is a polynomial of degree $2$ in $z$: $P_2(z) = \\left(-(1-\\gamma)z + (2-\\gamma)\\right)\\left(-\\frac{\\gamma}{2}z+1\\right) = \\frac{\\gamma(1-\\gamma)}{2}z^2 + \\dots$.\nThe limit is the ratio of the coefficients of the highest powers of $z$:\n$$\n\\lim_{z \\to -\\infty} R(z) = \\lim_{z \\to -\\infty} \\frac{\\frac{1}{2}(2-2\\gamma+\\gamma^2)z}{\\frac{\\gamma(1-\\gamma)}{2}z^2} = \\lim_{z \\to -\\infty} \\frac{2-2\\gamma+\\gamma^2}{\\gamma(1-\\gamma)z}\n$$\nThe parameter $\\gamma$ is in the open interval $(0,1)$, so $\\gamma > 0$ and $1-\\gamma > 0$. Thus, the denominator term $\\gamma(1-\\gamma)$ is strictly positive.\nThe numerator term $2-2\\gamma+\\gamma^2 = (1-\\gamma)^2 + 1$ is also strictly positive for any real $\\gamma$.\nThe limit is therefore of the form $\\lim_{z \\to -\\infty} \\frac{C}{z}$ where $C = \\frac{2-2\\gamma+\\gamma^2}{\\gamma(1-\\gamma)} > 0$. This limit is $0$.\nSince $\\lim_{z \\to -\\infty} R(z) = 0$, the TR-BDF2 method is L-stable for any choice of $\\gamma \\in (0,1)$. This property ensures that high-frequency modes (corresponding to eigenvalues with large negative real parts) are strongly damped, which is crucial for solving stiff problems.\n\n### Part 2: Numerical Implementation and Comparison\n\nThe numerical task is to compare the L-stable TR-BDF2 method with the merely A-stable Crank-Nicolson (CN) method on a stiff semi-discrete diffusion problem.\n\n**1. Semi-discretization of the Diffusion PDE**\nThe one-dimensional diffusion equation is $u_t = \\nu u_{xx}$ on $x \\in (0,1)$, with boundary conditions $u(0,t)=1$, $u(1,t)=0$, and initial condition $u(x,0)=0$.\nWe use a uniform grid with $N$ interior points $x_i = i\\Delta x$ for $i=1, \\dots, N$, where $\\Delta x = 1/(N+1)$. The state vector of unknowns is $y(t) = [u_1(t), \\dots, u_N(t)]^T$, where $u_i(t) \\approx u(x_i, t)$.\nThe second spatial derivative $u_{xx}$ at $x_i$ is approximated using a second-order central difference:\n$$\nu_{xx}(x_i, t) \\approx \\frac{u_{i-1}(t) - 2u_i(t) + u_{i+1}(t)}{\\Delta x^2}\n$$\nThis results in a system of $N$ coupled Ordinary Differential Equations (ODEs), $y'(t) = Ay(t) + b$:\n$$\n\\frac{du_i}{dt} = \\frac{\\nu}{\\Delta x^2} (u_{i-1} - 2u_i + u_{i+1})\n$$\nThe matrix $A$ is the scaled discrete Laplacian, an $N \\times N$ tridiagonal matrix:\n$$\nA = \\frac{\\nu}{\\Delta x^2} \\begin{pmatrix} -2  1   \\\\ 1  -2  1  \\\\  \\ddots  \\ddots  \\ddots \\\\   1  -2  1 \\\\    1  -2 \\end{pmatrix}\n$$\nThe vector $b$ incorporates the non-homogeneous Dirichlet boundary conditions:\n$$\nb = \\frac{\\nu}{\\Delta x^2} [u_0, 0, \\dots, 0, u_{N+1}]^T = \\frac{\\nu}{\\Delta x^2} [1, 0, \\dots, 0]^T\n$$\nwhere $u_0 = u(0,t) = 1$ and $u_{N+1} = u(1,t) = 0$.\n\n**2. Time Integration Schemes**\nFor the general linear system $y' = Ay+b$, the implicit schemes require solving a linear system at each time step.\n\n**Crank-Nicolson (CN):**\n$$\n\\frac{y_{n+1} - y_n}{h} = \\frac{1}{2}\\left((Ay_n + b) + (Ay_{n+1} + b)\\right)\n$$\nRearranging gives the linear system for $y_{n+1}$:\n$$\n\\left(I - \\frac{h}{2}A\\right) y_{n+1} = \\left(I + \\frac{h}{2}A\\right) y_n + h b\n$$\n\n**TR-BDF2 with $\\gamma = 1 - 1/\\sqrt{2}$:**\n**Substep 1 (TR):**\n$$\n\\left(I - \\frac{\\gamma h}{2}A\\right) y_{n+\\gamma} = \\left(I + \\frac{\\gamma h}{2}A\\right) y_n + \\gamma h b\n$$\n**Substep 2 (BDF2):**\n$$\n\\left(I - \\frac{h(1-\\gamma)}{2-\\gamma}A\\right) y_{n+1} = \\frac{1}{\\gamma(2-\\gamma)}y_{n+\\gamma} - \\frac{(1-\\gamma)^2}{\\gamma(2-\\gamma)}y_n + \\frac{h(1-\\gamma)}{2-\\gamma}b\n$$\nFor both methods, the matrix on the left-hand side is constant throughout the simulation, so LU factorization is performed once to enable efficient back-substitution at each step.\n\n**3. Overshoot Quantification and Implementation**\nThe physically admissible solution is bounded: $u(x,t) \\in [0,1]$. Numerical solutions may violate these bounds, an effect known as overshoot (for $u_i > 1$) or undershoot (for $u_i  0$). The global overshoot magnitude for a simulation is the maximum violation observed over all time steps and all grid points. For a computed interior solution $y_n$ at step $n$, the overshoot is calculated as $\\max(\\max(y_n) - 1, -\\min(y_n), 0)$. The program computes this for both methods and calculates the reduction, $\\mathrm{Overshoot}_{\\text{CN}} - \\mathrm{Overshoot}_{\\text{TR-BDF2}}$, which is expected to be positive and to increase with the problem stiffness (controlled by the parameter $\\alpha$).\n\nThe implementation of this procedure is provided in the following Python code.\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import linalg\n\ndef solve_diffusion_system(N, nu, alpha, M, method):\n    \"\"\"\n    Solves the semi-discretized 1D diffusion equation using a specified time\n    integration method and calculates the global overshoot magnitude.\n\n    Args:\n        N (int): Number of interior spatial points.\n        nu (float): Diffusivity constant.\n        alpha (float): Timestep parameter (Courant-like number).\n        M (int): Number of time steps.\n        method (str): Time integration method, 'CN' or 'TR-BDF2'.\n\n    Returns:\n        float: The global overshoot magnitude over the simulation.\n    \"\"\"\n    # 1. Setup grid, time step, matrix A, and vector b\n    dx = 1.0 / (N + 1)\n    h = alpha * dx**2 / nu\n    \n    # Construct the discrete Laplacian matrix A\n    scale = nu / dx**2\n    diag = np.full(N, -2.0)\n    off_diag = np.full(N - 1, 1.0)\n    A = scale * (np.diag(diag) + np.diag(off_diag, k=1) + np.diag(off_diag, k=-1))\n    \n    # Construct the boundary condition vector b\n    b = np.zeros(N)\n    b[0] = scale\n\n    # Initial condition y(0) = 0 for all interior points\n    y = np.zeros(N)\n    \n    global_overshoot = 0.0\n\n    if method == 'CN':\n        # 2a. Setup for Crank-Nicolson method\n        LHS_mat = np.identity(N) - (h / 2.0) * A\n        RHS_mat = np.identity(N) + (h / 2.0) * A\n        lu_piv = linalg.lu_factor(LHS_mat)\n\n        for _ in range(M):\n            RHS_vec = RHS_mat @ y + h * b\n            y = linalg.lu_solve(lu_piv, RHS_vec)\n            \n            # Calculate and update the global overshoot\n            current_overshoot = max(np.max(y) - 1.0, -np.min(y), 0.0)\n            if current_overshoot > global_overshoot:\n                global_overshoot = current_overshoot\n\n    elif method == 'TR-BDF2':\n        # 2b. Setup for TR-BDF2 method\n        gamma = 1.0 - 1.0 / np.sqrt(2.0)\n        \n        # Pre-factorize matrices for both substeps\n        LHS_TR = np.identity(N) - (gamma * h / 2.0) * A\n        lu_piv_tr = linalg.lu_factor(LHS_TR)\n        RHS_TR_mat = np.identity(N) + (gamma * h / 2.0) * A\n        \n        c1 = h * (1.0 - gamma) / (2.0 - gamma)\n        LHS_BDF2 = np.identity(N) - c1 * A\n        lu_piv_bdf2 = linalg.lu_factor(LHS_BDF2)\n        \n        y_prev = y.copy()\n        \n        for _ in range(M):\n            # TR substep to find y_intermediate\n            RHS_vec_TR = RHS_TR_mat @ y_prev + gamma * h * b\n            y_intermediate = linalg.lu_solve(lu_piv_tr, RHS_vec_TR)\n            \n            # BDF2 substep to find y\n            c2 = 1.0 / ((2.0 - gamma) * gamma)\n            c3 = (1.0 - gamma)**2 / ((2.0 - gamma) * gamma)\n            RHS_vec_BDF2 = c2 * y_intermediate - c3 * y_prev + c1 * b\n            y = linalg.lu_solve(lu_piv_bdf2, RHS_vec_BDF2)\n            \n            # Calculate and update the global overshoot\n            current_overshoot = max(np.max(y) - 1.0, -np.min(y), 0.0)\n            if current_overshoot > global_overshoot:\n                global_overshoot = current_overshoot\n            \n            y_prev = y.copy()\n\n    return global_overshoot\n```", "answer": "[0.05739832484089069,0.3060206121703649,0.4678121666838385]", "id": "3287222"}]}