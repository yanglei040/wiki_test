{"hands_on_practices": [{"introduction": "To truly master floating-point arithmetic, we must look under the hood at its binary representation. This first practice challenges you to dissect an IEEE $754$ number and extract one of its key components—the exponent—using only integer bitwise operations [@problem_id:3678233]. Mastering this skill is not just an academic exercise; it builds a foundational understanding of how a number's magnitude is encoded and is essential for low-level data manipulation and performance optimization.", "problem": "You are given the binary layout of the Institute of Electrical and Electronics Engineers (IEEE) Standard for Floating-Point Arithmetic (IEEE $754$) formats and asked to design and implement a bit-level method to extract the unbiased exponent $e$ of a floating-point number from its raw bit pattern, without using any floating-point instructions or operations. Work in purely integer and bitwise terms.\n\nFundamental base to use:\n- IEEE $754$ single-precision ($32$-bit) format uses $1$ sign bit, $8$ exponent bits, and $23$ fraction bits. Let $E$ denote the encoded exponent field interpreted as an unsigned integer. The exponent bias is $127$. For normalized values where $1 \\le E \\le 254$, the unbiased exponent is $e = E - 127$. For $E = 0$ (subnormal or zero), the effective exponent used in the value definition is $e = 1 - 127 = -126$. For $E = 255$ (all ones), the value is either infinity or not-a-number (NaN), and the unbiased exponent is not finite.\n- IEEE $754$ double-precision ($64$-bit) format uses $1$ sign bit, $11$ exponent bits, and $52$ fraction bits. Let $E$ denote the encoded exponent field interpreted as an unsigned integer. The exponent bias is $1023$. For normalized values where $1 \\le E \\le 2046$, the unbiased exponent is $e = E - 1023$. For $E = 0$ (subnormal or zero), the effective exponent used in the value definition is $e = 1 - 1023 = -1022$. For $E = 2047$ (all ones), the value is either infinity or not-a-number (NaN), and the unbiased exponent is not finite.\n\nTask:\n- Design integer-only bit-hacks to extract $E$ from a raw bit pattern and map it to $e$ as specified above, without performing any operations on values of type float or double. You must ignore the sign and fraction fields except for detecting whether the exponent field is all zeros or all ones. For the “not finite” cases where the exponent field is all ones, return a sentinel integer $S = 2147483647$ to indicate an undefined unbiased exponent. For $E = 0$ (including both subnormals and zeros), return the effective exponent $e = 1 - \\text{bias}$ as defined above.\n\nConstraints:\n- Use only integer types and bitwise operations to isolate and interpret the exponent fields.\n- Do not use any arithmetic on floating-point types, and do not cast integers to floating-point types.\n- Treat all inputs as raw unsigned integers encoding IEEE $754$ bit patterns.\n\nTest suite:\nApply your extraction to the following raw bit patterns, in the exact order given. For each, compute and return the integer $e$ according to the rules above.\n\nSingle-precision ($32$-bit) inputs, given as hexadecimal constants:\n- $0x3F800000$  (represents $+1.0$)\n- $0x3F400000$  (represents $+0.75$)\n- $0x00000001$  (smallest positive subnormal)\n- $0x00000000$  ($+0.0$)\n- $0x7F800000$  ($+\\infty$)\n- $0x7FC00001$  (a quiet NaN)\n- $0x7F7FFFFF$  (largest finite positive)\n- $0x00800000$  (smallest positive normal)\n- $0xBF800000$  (represents $-1.0$)\n\nDouble-precision ($64$-bit) inputs, given as hexadecimal constants:\n- $0x3FF0000000000000$  (represents $+1.0$)\n- $0xC000000000000000$  (represents $-2.0$)\n- $0x0000000000000001$  (smallest positive subnormal)\n- $0x8000000000000000$  ($-0.0$)\n- $0x7FF0000000000000$  ($+\\infty$)\n- $0x7FF8000000000001$  (a quiet NaN)\n- $0x7FEFFFFFFFFFFFFF$  (largest finite positive)\n- $0x0010000000000000$  (smallest positive normal)\n\nRequired final output format:\n- Your program must produce a single line of output containing all results as a comma-separated list of integers enclosed in square brackets and with no spaces. The results must appear in the order listed above: first all $9$ single-precision results in the given order, then all $8$ double-precision results in the given order. For example, the output should look like $[r_1,r_2,\\dots,r_{17}]$ where each $r_i$ is an integer.\n\nYour program must be a complete, runnable program that computes these values using only integer and bitwise operations and prints the results in the exact format described. No user input is involved. The outputs are pure integers; no physical units, angles, or percentages apply.", "solution": "The problem of extracting the unbiased exponent from an IEEE $754$ floating-point number using only integer and bitwise operations is a classic exercise in understanding low-level data representation. The solution relies on the fixed-bit-width layout of the floating-point formats specified in the standard.\n\nThe general principle is to use bitwise operations to isolate the exponent field, interpret its value as an unsigned integer, and then apply the rules of the IEEE $754$ standard to convert this encoded exponent into the true, unbiased exponent value.\n\nLet $b$ be the raw bit pattern of the floating-point number, represented as an unsigned integer. Let $E$ be the value of the exponent field when interpreted as an unsigned integer, and let $e$ be the final unbiased exponent.\n\n**Method for Single-Precision ($32$-bit) Format**\n\nThe IEEE $754$ single-precision format allocates $32$ bits as follows: $1$ sign bit, $8$ exponent bits, and $23$ fraction bits. The exponent bias is $127$.\n\n1.  **Isolate the Encoded Exponent ($E$)**: The $8$ exponent bits are located at bit positions $23$ through $30$. To extract these bits from a $32$-bit unsigned integer $b$, we perform two operations:\n    *   First, a bitwise right shift by $23$ positions ($b \\gg 23$). This operation moves the exponent bits into the least significant $8$ bit positions of the integer.\n    *   Second, a bitwise AND operation with a mask that isolates these $8$ bits. The mask is $2^8 - 1 = 255$, which in hexadecimal is $0x\\text{FF}$.\n    The complete operation is: $E = (b \\gg 23) \\text{ & } 255$.\n\n2.  **Compute the Unbiased Exponent ($e$)**: The value of $E$ determines the class of the number (normalized, subnormal, zero, infinity, or NaN) and the rule for computing $e$.\n    *   **Special Case ($E = 255$):** If the exponent field is all ones, $E = 255$. This pattern signifies either infinity or a Not-a-Number (NaN). For these cases, the problem specifies returning a sentinel integer value, $S = 2147483647$.\n    *   **Special Case ($E = 0$):** If the exponent field is all zeros, $E = 0$. This pattern signifies either a subnormal number or zero. For these values, the standard defines an effective exponent for calculation purposes. This effective exponent is $e = 1 - \\text{bias} = 1 - 127 = -126$.\n    *   **Normalized Case ($1 \\le E \\le 254$):** For all other values of $E$, the number is a normalized value. The unbiased exponent is calculated by subtracting the bias from the encoded exponent: $e = E - \\text{bias} = E - 127$.\n\n**Method for Double-Precision ($64$-bit) Format**\n\nThe IEEE $754$ double-precision format allocates $64$ bits as follows: $1$ sign bit, $11$ exponent bits, and $52$ fraction bits. The exponent bias is $1023$.\n\n1.  **Isolate the Encoded Exponent ($E$)**: The $11$ exponent bits are located at bit positions $52$ through $62$. To extract these bits from a $64$-bit unsigned integer $b$:\n    *   First, a bitwise right shift by $52$ positions ($b \\gg 52$).\n    *   Second, a bitwise AND with an $11$-bit mask. The mask is $2^{11} - 1 = 2047$, which in hexadecimal is $0x\\text{7FF}$.\n    The complete operation is: $E = (b \\gg 52) \\text{ & } 2047$.\n\n2.  **Compute the Unbiased Exponent ($e$)**: The rules are analogous to the single-precision case, but with different parameters.\n    *   **Special Case ($E = 2047$):** If $E = 2047$ (all $11$ bits are ones), the value is infinity or NaN. The sentinel value $S = 2147483647$ is returned.\n    *   **Special Case ($E = 0$):** If $E = 0$ (all $11$ bits are zeros), the value is subnormal or zero. The effective exponent is $e = 1 - \\text{bias} = 1 - 1023 = -1022$.\n    *   **Normalized Case ($1 \\le E \\le 2046$):** For all other values of $E$, the number is normalized. The unbiased exponent is $e = E - \\text{bias} = E - 1023$.\n\nThis bitwise-only approach allows for the correct extraction and interpretation of the exponent field in strict compliance with the problem constraints, without using any floating-point instructions or data types.", "answer": "```c\n#include <stdio.h>\n#include <stdlib.h>\n\n// Note: The problem assumes an environment where 'unsigned int' is 32 bits\n// and 'unsigned long long' is 64 bits, which is standard on most modern systems.\n\n// Constants for single-precision (32-bit) floats\n#define SINGLE_EXP_SHIFT 23\n#define SINGLE_EXP_MASK 0xFF\n#define SINGLE_BIAS 127\n#define SINGLE_MAX_EXP 255\n#define SINGLE_SUBNORMAL_EXP (1 - SINGLE_BIAS)\n\n// Constants for double-precision (64-bit) floats\n#define DOUBLE_EXP_SHIFT 52\n#define DOUBLE_EXP_MASK 0x7FF\n#define DOUBLE_BIAS 1023\n#define DOUBLE_MAX_EXP 2047\n#define DOUBLE_SUBNORMAL_EXP (1 - DOUBLE_BIAS)\n\n// Sentinel value for non-finite exponents (Inf/NaN)\n#define SENTINEL_NON_FINITE 2147483647\n\n/**\n * @brief Extracts the unbiased exponent from a 32-bit single-precision float pattern.\n * @param bits The raw 32-bit integer representing the float.\n * @return The unbiased exponent as an integer.\n */\nint get_exponent_single(unsigned int bits) {\n    // Isolate the 8-bit encoded exponent field.\n    int encoded_exp = (bits >> SINGLE_EXP_SHIFT) & SINGLE_EXP_MASK;\n\n    if (encoded_exp == SINGLE_MAX_EXP) {\n        // Case: Infinity or NaN\n        return SENTINEL_NON_FINITE;\n    } else if (encoded_exp == 0) {\n        // Case: Subnormal or Zero\n        return SINGLE_SUBNORMAL_EXP;\n    } else {\n        // Case: Normalized number\n        return encoded_exp - SINGLE_BIAS;\n    }\n}\n\n/**\n * @brief Extracts the unbiased exponent from a 64-bit double-precision float pattern.\n * @param bits The raw 64-bit integer representing the double.\n * @return The unbiased exponent as an integer.\n */\nint get_exponent_double(unsigned long long bits) {\n    // Isolate the 11-bit encoded exponent field.\n    int encoded_exp = (bits >> DOUBLE_EXP_SHIFT) & DOUBLE_EXP_MASK;\n    \n    if (encoded_exp == DOUBLE_MAX_EXP) {\n        // Case: Infinity or NaN\n        return SENTINEL_NON_FINITE;\n    } else if (encoded_exp == 0) {\n        // Case: Subnormal or Zero\n        return DOUBLE_SUBNORMAL_EXP;\n    } else {\n        // Case: Normalized number\n        return encoded_exp - DOUBLE_BIAS;\n    }\n}\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    unsigned int single_cases[] = {\n        0x3F800000, 0x3F400000, 0x00000001, 0x00000000, 0x7F800000,\n        0x7FC00001, 0x7F7FFFFF, 0x00800000, 0xBF800000\n    };\n\n    unsigned long long double_cases[] = {\n        0x3FF0000000000000ULL, 0xC000000000000000ULL, 0x0000000000000001ULL,\n        0x8000000000000000ULL, 0x7FF0000000000000ULL, 0x7FF8000000000001ULL,\n        0x7FEFFFFFFFFFFFFFULL, 0x0010000000000000ULL\n    };\n\n    // Calculate the number of test cases.\n    int num_single_cases = sizeof(single_cases) / sizeof(single_cases[0]);\n    int num_double_cases = sizeof(double_cases) / sizeof(double_cases[0]);\n    int total_cases = num_single_cases + num_double_cases;\n    int results[total_cases];\n\n    int result_idx = 0;\n\n    // Calculate the result for each single-precision test case.\n    for (int i = 0; i < num_single_cases; ++i) {\n        results[result_idx++] = get_exponent_single(single_cases[i]);\n    }\n\n    // Calculate the result for each double-precision test case.\n    for (int i = 0; i < num_double_cases; ++i) {\n        results[result_idx++] = get_exponent_double(double_cases[i]);\n    }\n\n    // Print the results in the EXACT REQUIRED format before the final return statement.\n    printf(\"[\");\n    for (int i = 0; i < total_cases; ++i) {\n        printf(\"%d\", results[i]);\n        if (i < total_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n```", "id": "3678233"}, {"introduction": "Building on our understanding of the binary layout, this practice explores a remarkable property of the IEEE $754$ standard. For numbers of a given sign, their floating-point values are ordered in the same way as their raw integer bit patterns [@problem_id:3678203]. This exercise asks you to leverage this property to find the immediate successor or predecessor of a number, effectively \"walking\" along the discrete floating-point number line using simple integer arithmetic.", "problem": "Consider the Institute of Electrical and Electronics Engineers (IEEE) 754 binary64 (double-precision) floating-point format. A binary64 number has a total of $64$ bits partitioned as follows: one sign bit $s$, an $11$-bit exponent field $E$ encoded with a bias $B = 1023$, and a $52$-bit fraction (also called significand or mantissa) field $F$. The encoded real value is determined by the following well-tested facts:\n- For $0 < E < 2047$ (normal numbers), the value is\n$$\n(-1)^s \\cdot \\left(1 + \\frac{F}{2^{52}}\\right) \\cdot 2^{E - B}.\n$$\n- For $E = 0$ and $F \\neq 0$ (subnormal numbers), the value is\n$$\n(-1)^s \\cdot \\left(\\frac{F}{2^{52}}\\right) \\cdot 2^{1 - B}.\n$$\n- For $E = 2047$ and $F = 0$, the value is $\\pm \\infty$ depending on $s$.\n- For $E = 2047$ and $F \\neq 0$, the value is Not-a-Number (NaN), which is unordered with all real numbers.\n\nDefine the immediate successor $\\operatorname{succ}(x)$ of a representable real $x$ as the least representable real $y$ such that $y > x$, and the immediate predecessor $\\operatorname{pred}(x)$ as the greatest representable real $y$ such that $y < x$. For NaN (unordered) values, neither $\\operatorname{succ}$ nor $\\operatorname{pred}$ is defined in the real order; in that case, treat the successor and predecessor as the same NaN bit pattern (i.e., unchanged).\n\nStarting from the core definition of the IEEE 754 encoding above, derive the minimal integer operation needed on the $64$-bit bit pattern to compute $\\operatorname{succ}(x)$ and $\\operatorname{pred}(x)$ for all inputs, including correct handling of signed zeros and infinities. Your derivation must explicitly justify the direction of the integer step from the real-number ordering and the sign-magnitude structure of the encoding, without resorting to any shortcut formulas not derived from the given definitions.\n\nThen implement a program that:\n1. Reinterprets a given double-precision number $x$ as an unsigned $64$-bit integer $u$ representing its raw bit pattern.\n2. Computes the raw bit patterns of $\\operatorname{pred}(x)$ and $\\operatorname{succ}(x)$ by a single integer increment or decrement of $u$ in the correct direction, with the following boundary conditions justified from first principles:\n   - If $x$ is NaN, both outputs are the unchanged NaN bit pattern.\n   - If $x = +\\infty$, then $\\operatorname{succ}(x) = +\\infty$ and $\\operatorname{pred}(x)$ equals the largest finite positive number.\n   - If $x = -\\infty$, then $\\operatorname{pred}(x) = -\\infty$ and $\\operatorname{succ}(x)$ equals the largest finite negative number.\n   - If $x = 0$ (either $+0$ or $-0$), then $\\operatorname{succ}(x)$ equals the smallest positive subnormal number with raw bit pattern $\\mathtt{0x0000000000000001}$ and $\\operatorname{pred}(x)$ equals the smallest (in magnitude) negative subnormal with raw bit pattern $\\mathtt{0x8000000000000001}$.\n3. Outputs, for each test case, the pair consisting of the raw bit patterns of $\\operatorname{pred}(x)$ and $\\operatorname{succ}(x)$, expressed as unsigned integers.\n\nAnalyze the behavior at the subnormal boundary where $E = 0$. In particular, explain the transitions at:\n- The smallest positive subnormal value $x = 2^{-1074}$.\n- The largest positive subnormal value $x = 2^{-1022} - 2^{-1074}$.\n- The smallest positive normal value $x = 2^{-1022}$.\n\nEnsure scientific realism by working strictly from the encoding structure, showing why a single integer step of the correctly oriented raw bit pattern corresponds to the immediate predecessor or successor in the real-number ordering.\n\nTest Suite:\nUse exactly the following $11$ test cases, each specified by its raw bit pattern as a $64$-bit hexadecimal literal:\n1. $\\mathtt{0x0000000000000000}$ (positive zero $+0$).\n2. $\\mathtt{0x8000000000000000}$ (negative zero $-0$).\n3. $\\mathtt{0x0000000000000001}$ (smallest positive subnormal $x = 2^{-1074}$).\n4. $\\mathtt{0x000FFFFFFFFFFFFF}$ (largest positive subnormal $x = 2^{-1022} - 2^{-1074}$).\n5. $\\mathtt{0x0010000000000000}$ (smallest positive normal $x = 2^{-1022}$).\n6. $\\mathtt{0x3FF0000000000000}$ ($x = 1$).\n7. $\\mathtt{0xBFF0000000000000}$ ($x = -1$).\n8. $\\mathtt{0x7FEFFFFFFFFFFFFF}$ (largest finite positive number).\n9. $\\mathtt{0xFFF0000000000000}$ (negative infinity).\n10. $\\mathtt{0x7FF0000000000000}$ (positive infinity).\n11. $\\mathtt{0x7FF8000000000000}$ (a quiet NaN).\n\nFinal Output Format:\nYour program should produce a single line of output containing the results as a comma-separated list enclosed in square brackets. The list must contain, in the order of the test suite above, for each test case, first the predecessor raw bit pattern and then the successor raw bit pattern, both printed as unsigned decimal integers. For example, the output format is\n$$\n[\\text{pred}_1,\\text{succ}_1,\\text{pred}_2,\\text{succ}_2,\\dots,\\text{pred}_{11},\\text{succ}_{11}]\n$$\nwhere each $\\text{pred}_i$ and $\\text{succ}_i$ is an unsigned integer representing the $64$-bit bit pattern.", "solution": "The problem requires the derivation of a method to find the immediate successor, $\\operatorname{succ}(x)$, and immediate predecessor, $\\operatorname{pred}(x)$, of a double-precision floating-point number $x$ by performing integer operations on its $64$-bit binary representation. The derivation must be based on the provided IEEE 754 definitions.\n\nA `binary64` number is represented by a $64$-bit pattern, which we can interpret as a $64$-bit unsigned integer, $u$. This integer is composed of three fields: a $1$-bit sign $s$, an $11$-bit biased exponent $E$, and a $52$-bit fraction $F$. The integer representation is $u = s \\cdot 2^{63} + E \\cdot 2^{52} + F$.\n\nThe core of the derivation relies on analyzing the relationship between the ordering of the real values $x$ and the integer ordering of their representations $u$.\n\n**1. Analysis for Positive Numbers ($s=0$)**\n\nFor positive numbers, the sign bit $s$ is $0$. The integer representation is $u = E \\cdot 2^{52} + F$.\nThe value of the number $x$ is determined by $E$ and $F$.\n- If $x$ is a normal number ($0 < E < 2047$), its value is $x = (1 + F/2^{52}) \\cdot 2^{E - 1023}$.\n- If $x$ is a subnormal number ($E = 0, F \\neq 0$), its value is $x = (F/2^{52}) \\cdot 2^{1 - 1023}$.\n\nIn both cases, for a fixed exponent $E$, the value of $x$ is a monotonically increasing function of the fraction $F$. An increase in $F$ by $1$ increases $x$ by a small amount (the Unit in the Last Place, or ULP). Similarly, the value of $x$ increases significantly with an increase in the exponent $E$.\n\nThe integer representation for positive numbers, $u = E \\cdot 2^{52} + F$, is also a monotonically increasing function of both $E$ and $F$. An increase in $F$ results in a direct increase in $u$. An increase in $E$ results in a much larger increase in $u$. Therefore, for any two positive representable numbers $x_1$ and $x_2$ with integer representations $u_1$ and $u_2$, the ordering is preserved: $x_1 > x_2 \\iff u_1 > u_2$.\n\nThis direct correspondence implies that finding the immediate successor or predecessor in the real domain is equivalent to finding the immediate successor or predecessor in the integer domain.\n- To find $\\operatorname{succ}(x)$, the smallest representable number greater than $x$, we must find the smallest integer representation greater than $u$. This is simply $u+1$.\n- To find $\\operatorname{pred}(x)$, the largest representable number smaller than $x$, we must find the largest integer representation smaller than $u$. This is simply $u-1$.\n\n**2. Analysis for Negative Numbers ($s=1$)**\n\nFor negative numbers, the sign bit $s$ is $1$. The value of $x$ is the negation of its magnitude, $x = -|x|$. Let's consider two negative numbers, $x_1$ and $x_2$. The real number ordering is $x_1 > x_2 \\iff -|x_1| > -|x_2| \\iff |x_1| < |x_2|$. The ordering of negative numbers is the reverse of the ordering of their magnitudes.\n\nThe integer representation for negative numbers, $u = 1 \\cdot 2^{63} + E \\cdot 2^{52} + F$, is an increasing function of the magnitude's components $E$ and $F$. A larger magnitude $|x|$ corresponds to a larger value of $E$ or $F$, which in turn corresponds to a larger integer representation $u$.\nTherefore, for any two negative representable numbers $x_1$ and $x_2$ with integer representations $u_1$ and $u_2$:\n$x_1 > x_2 \\iff |x_1| < |x_2| \\iff u_1 < u_2$.\n\nThis inverse correspondence implies that finding the successor or predecessor in the real domain is equivalent to moving in the opposite direction in the integer domain.\n- To find $\\operatorname{succ}(x)$, a larger (less negative) real value, we need a smaller magnitude, which corresponds to a smaller integer representation. Thus, we compute $u-1$.\n- To find $\\operatorname{pred}(x)$, a smaller (more negative) real value, we need a larger magnitude, which corresponds to a larger integer representation. Thus, we compute $u+1$.\n\n**3. Analysis of Boundary and Special Cases**\n\nThe simple integer arithmetic derived above must be examined at the boundaries of the number system.\n\n- **Zero ($+0$ and $-0$)**:\n  - For $x = +0$, the representation is $u = \\mathtt{0x0000000000000000}$.\n    - $\\operatorname{succ}(+0)$ should be the smallest positive number. Our rule for positive numbers gives $u+1 = 1$, which is the correct representation for the smallest positive subnormal, $2^{-1074}$.\n    - $\\operatorname{pred}(+0)$ should be the number just smaller than $0$, which is the largest negative number (closest to zero), i.e., the smallest-magnitude negative number. Its representation is $\\mathtt{0x8000000000000001}$. Our rule $u-1$ gives $\\mathtt{0xFFFFFFFFFFFFFFFF}$ (due to unsigned wraparound), which is a NaN. This is a specific boundary case that must be handled explicitly.\n  - For $x = -0$, the representation is $u = \\mathtt{0x8000000000000000}$.\n    - $\\operatorname{pred}(-0)$ should be the smallest-magnitude negative number. Our rule for negative numbers gives $u+1 = \\mathtt{0x8000000000000001}$, which is correct.\n    - $\\operatorname{succ}(-0)$ should be the number just larger than $0$, i.e., the smallest positive number. Its representation is $1$. Our rule $u-1$ gives $\\mathtt{0x7FFFFFFFFFFFFFFF}$, a NaN. This is the other specific boundary case at zero.\n  - The problem defines $\\operatorname{pred}(0)$ and $\\operatorname{succ}(0)$ across the sign boundary. Thus, for both $x=+0$ and $x=-0$, $\\operatorname{succ}(x)$ is the smallest positive subnormal ($\\mathtt{0x...1}$) and $\\operatorname{pred}(x)$ is the smallest-magnitude negative subnormal ($\\mathtt{0x8...1}$).\n\n- **Infinities ($+\\infty$ and $-\\infty$)**:\n  - For $x = +\\infty$, $u = \\mathtt{0x7FF0000000000000}$. It is the maximal representable value.\n    - $\\operatorname{succ}(+\\infty) = +\\infty$. The representation is unchanged. Our rule $u+1$ would yield a NaN, so this must be handled as a special case.\n    - $\\operatorname{pred}(+\\infty)$ is the largest finite positive number. Its representation is $\\mathtt{0x7FEFFFFFFFFFFFFF}$, which is exactly $u-1$. The general rule for positive predecessors works here.\n  - For $x = -\\infty$, $u = \\mathtt{0xFFF0000000000000}$. It is the minimal representable value.\n    - $\\operatorname{pred}(-\\infty) = -\\infty$. The representation is unchanged. Our rule $u+1$ would yield a NaN, so this is a special case.\n    - $\\operatorname{succ}(-\\infty)$ is the largest-magnitude finite negative number. Its representation is $\\mathtt{0xFFEFFFFFFFFFFFFF}$, which is $u-1$. The general rule for negative successors works here.\n\n- **Not-a-Number (NaN)**:\n  - NaN values have $E=2047$ and $F \\neq 0$. They are unordered. The problem states that $\\operatorname{succ}(\\text{NaN})$ and $\\operatorname{pred}(\\text{NaN})$ should result in the same NaN bit pattern. This requires an explicit check.\n\n**4. Analysis of the Subnormal-Normal Boundary**\n\nThe problem requires analyzing the transition across the subnormal range.\n- **Smallest positive subnormal**: $x = 2^{-1074}$, with $u = \\mathtt{0x0000000000000001}$.\n  - $\\operatorname{pred}(x)$ corresponds to $u-1=0$, which is $+0$. Correct.\n  - $\\operatorname{succ}(x)$ corresponds to $u+1=2$, which represents $2 \\cdot 2^{-1074}$. Correct.\n- **Largest positive subnormal**: $x = 2^{-1022} - 2^{-1074}$, with $u = \\mathtt{0x000FFFFFFFFFFFFF}$.\n  - $\\operatorname{pred}(x)$ corresponds to $u-1 = \\mathtt{0x000FFFFFFFFFFFFE}$, the second-largest subnormal. Correct.\n  - $\\operatorname{succ}(x)$ corresponds to $u+1 = \\mathtt{0x0010000000000000}$. This representation has $E=1, F=0$, which is the smallest positive normal number, $2^{-1022}$. This demonstrates the seamless transition achieved by the integer increment operation.\n- **Smallest positive normal**: $x = 2^{-1022}$, with $u = \\mathtt{0x0010000000000000}$.\n  - $\\operatorname{pred}(x)$ corresponds to $u-1 = \\mathtt{0x000FFFFFFFFFFFFF}$, the largest subnormal. Correct.\n  - $\\operatorname{succ}(x)$ corresponds to $u+1 = \\mathtt{0x0010000000000001}$, the next normal number. Correct.\n\nThis analysis confirms that the simple integer arithmetic correctly handles the crucial boundary between subnormal and normal numbers, a key feature of the IEEE 754 standard.\n\n**Summary of the Algorithm**\n\nBased on this derivation, the following algorithm finds the predecessor and successor representations.\nLet $u$ be the $64$-bit unsigned integer representation of the input number $x$.\n1.  If $x$ is a NaN (i.e., `(u >> 52  0x7FF) == 0x7FF` and `(u  0x000FFFFFFFFFFFFFULL) != 0`), both successor and predecessor representations are $u$.\n2.  If $u = \\mathtt{0x0000000000000000}$ (for $+0$), the successor is $1$ and the predecessor is $\\mathtt{0x8000000000000001}$.\n3.  If $u = \\mathtt{0x8000000000000000}$ (for $-0$), the successor is $1$ and the predecessor is $\\mathtt{0x8000000000000001}$.\n4.  If $u = \\mathtt{0x7FF0000000000000}$ (for $+\\infty$), the successor is $u$ and the predecessor is $u-1$.\n5.  If $u = \\mathtt{0xFFF0000000000000}$ (for $-\\infty$), the successor is $u-1$ and the predecessor is $u$.\n6.  For any other positive number ($u \\gg 63 == 0$), the successor is $u+1$ and the predecessor is $u-1$.\n7.  For any other negative number ($u \\gg 63 == 1$), the successor is $u-1$ and the predecessor is $u+1$.\nThis case-based logic correctly implements the derived principles. Combining the zero cases simplifies the implementation.", "answer": "```c\n#include stdio.h\n#include stdlib.h\n\n// On a C23-compliant compiler, stdint.h would be preferred, but it is not in the\n// list of allowed headers. We use 'unsigned long long', which is guaranteed by\n// the C standard to be at least 64 bits. On all common modern 64-bit platforms,\n// it is exactly 64 bits, which is sufficient and necessary for this problem.\ntypedef unsigned long long uint64_t;\n\n// A struct to hold the parameters for a single test case.\ntypedef struct {\n    uint64_t u;\n} TestCase;\n\n// A struct to hold the results for a single test case.\ntypedef struct {\n    uint64_t pred;\n    uint64_t succ;\n} Result;\n\n// This function computes the predecessor and successor of a double-precision\n// floating-point number given its 64-bit integer representation.\nResult compute_pred_succ(uint64_t u) {\n    Result res;\n\n    // Constants for IEEE 754 double-precision format.\n    const uint64_t EXP_MASK = 0x7FF0000000000000ULL;\n    const uint64_t FRAC_MASK = 0x000FFFFFFFFFFFFFULL;\n    const uint64_t SIGN_MASK = 0x8000000000000000ULL;\n\n    const uint64_t POS_INF = 0x7FF0000000000000ULL;\n    const uint64_t NEG_INF = 0xFFF0000000000000ULL;\n    const uint64_t POS_ZERO = 0x0000000000000000ULL;\n    const uint64_t NEG_ZERO = 0x8000000000000000ULL;\n\n    const uint64_t SMALLEST_POS_SUBNORMAL = 1ULL;\n    const uint64_t SMALLEST_NEG_SUBNORMAL = 0x8000000000000001ULL;\n\n    // 1. Handle NaN: Exponent is all 1s, fraction is non-zero.\n    if ((u  EXP_MASK) == EXP_MASK  (u  FRAC_MASK) != 0) {\n        res.pred = u;\n        res.succ = u;\n        return res;\n    }\n\n    // 2. Handle Infinities\n    if (u == POS_INF) {\n        res.pred = u - 1; // Largest finite positive number\n        res.succ = u;     // Successor of +inf is +inf\n        return res;\n    }\n    if (u == NEG_INF) {\n        res.pred = u;     // Predecessor of -inf is -inf\n        res.succ = u - 1; // Largest magnitude finite negative number\n        return res;\n    }\n\n    // 3. Handle Zeros (covers the discontinuity in the integer mapping)\n    if (u == POS_ZERO) {\n        res.pred = SMALLEST_NEG_SUBNORMAL;\n        res.succ = SMALLEST_POS_SUBNORMAL;\n        return res;\n    }\n    if (u == NEG_ZERO) {\n        res.pred = SMALLEST_NEG_SUBNORMAL;\n        res.succ = SMALLEST_POS_SUBNORMAL;\n        return res;\n    }\n\n    // 4. Handle all other finite numbers based on the sign.\n    if ((u  SIGN_MASK) == 0) { // Positive numbers\n        // Real value order matches integer order.\n        res.pred = u - 1;\n        res.succ = u + 1;\n    } else { // Negative numbers\n        // Real value order is reverse of integer order.\n        res.pred = u + 1;\n        res.succ = u - 1;\n    }\n\n    return res;\n}\n\nint main(void) {\n    // Define the test cases from the problem statement.\n    TestCase test_cases[] = {\n        {0x0000000000000000ULL}, // 1. Positive zero (+0)\n        {0x8000000000000000ULL}, // 2. Negative zero (-0)\n        {0x0000000000000001ULL}, // 3. Smallest positive subnormal\n        {0x000FFFFFFFFFFFFFULL}, // 4. Largest positive subnormal\n        {0x0010000000000000ULL}, // 5. Smallest positive normal\n        {0x3FF0000000000000ULL}, // 6. x = 1.0\n        {0xBFF0000000000000ULL}, // 7. x = -1.0\n        {0x7FEFFFFFFFFFFFFFULL}, // 8. Largest finite positive number\n        {0xFFF0000000000000ULL}, // 9. Negative infinity\n        {0x7FF0000000000000ULL}, // 10. Positive infinity\n        {0x7FF8000000000000ULL}  // 11. A quiet NaN\n    };\n\n    // Calculate the number of test cases.\n    int num_cases = sizeof(test_cases) / sizeof(test_cases[0]);\n    Result results[num_cases];\n\n    // Calculate the result for each test case.\n    for (int i = 0; i  num_cases; ++i) {\n        results[i] = compute_pred_succ(test_cases[i].u);\n    }\n\n    // Print the results in the EXACT REQUIRED format before the final return statement.\n    printf(\"[\");\n    for (int i = 0; i  num_cases; ++i) {\n        printf(\"%llu,%llu\", results[i].pred, results[i].succ);\n        if (i  num_cases - 1) {\n            printf(\",\");\n        }\n    }\n    printf(\"]\");\n\n    return EXIT_SUCCESS;\n}\n```", "id": "3678203"}, {"introduction": "We now shift from bit-level mechanics to the practical consequences of using different floating-point formats in a real-world scenario. This final practice simulates a database equi-join where keys are stored in both single-precision and double-precision formats [@problem_id:3678173]. You will discover how casting from a higher precision to a lower one can cause distinct values to collapse into the same representation due to rounding, leading to incorrect results and demonstrating a critical pitfall in numerical software.", "problem": "Consider a system that performs an equi-join on floating-point keys under two different implementation choices. The keys are compliant with the Institute of Electrical and Electronics Engineers (IEEE) 754 standard for binary floating-point, specifically binary32 (single precision) and binary64 (double precision). The implementation uses the round-to-nearest, ties-to-even mode for converting between formats.\n\nTwo tables are defined as follows. Table $\\mathcal{A}$ stores its keys in binary64; Table $\\mathcal{B}$ stores its keys in binary32. Let\n$$\nS = 1 + 100 \\cdot 2^{-23}.\n$$\nTable $\\mathcal{A}$ has three rows with keys\n$$\na_1 = S - 0.4 \\cdot 2^{-23}, \\quad a_2 = S + 0.4 \\cdot 2^{-23}, \\quad a_3 = 2.0,\n$$\nand Table $\\mathcal{B}$ has two rows with keys\n$$\nb_1 = S, \\quad b_2 = 2.0.\n$$\n\nThe system considers two equi-join strategies:\n1. Strategy D: Cast the binary32 keys of Table $\\mathcal{B}$ to binary64 and compare in binary64 equality.\n2. Strategy S: Cast the binary64 keys of Table $\\mathcal{A}$ to binary32 and compare in binary32 equality.\n\nUsing only the foundational definitions of IEEE 754 formats and rounding behavior, determine the difference in correctness between Strategy S and Strategy D by counting the number of equi-join pairs that Strategy S produces but Strategy D does not. Express your final answer as a single real number equal to the total count of such incorrect pairs. No rounding is required for your final result.", "solution": "The problem statement is critically evaluated and deemed valid. It is scientifically grounded in the IEEE 754 standard for floating-point arithmetic, is well-posed with all necessary information provided, and is expressed in objective, formal language. There are no contradictions, ambiguities, or factual unsoundness.\n\nThe task is to determine the number of equi-join pairs produced by Strategy S but not by Strategy D. An equi-join pair is of the form $(a_i, b_j)$, where $a_i$ is a key from Table $\\mathcal{A}$ and $b_j$ is a key from Table $\\mathcal{B}$.\n\nFirst, let us analyze the properties of the specified IEEE 754 formats.\n- **binary32 (single precision):** This format uses $1$ sign bit, $8$ exponent bits, and $23$ bits for the fractional part of the significand. This implies a total precision of $24$ bits (including the implicit leading bit). For numbers in the range $[1.0, 2.0)$, where the exponent is $0$, the value of the least significant bit of the mantissa, or the unit in the last place (ULP), is $2^{-23}$.\n- **binary64 (double precision):** This format uses $1$ sign bit, $11$ exponent bits, and $52$ bits for the fractional part of the significand, giving a total precision of $53$ bits.\n\nThe rounding mode is specified as round-to-nearest, ties-to-even. A real number is rounded to the nearest representable floating-point value. If it is exactly halfway between two representable values, it is rounded to the one whose least significant bit of the mantissa is $0$.\n\nThe keys are given as:\n- Table $\\mathcal{A}$ (binary64): $a_1 = S - 0.4 \\cdot 2^{-23}$, $a_2 = S + 0.4 \\cdot 2^{-23}$, $a_3 = 2.0$.\n- Table $\\mathcal{B}$ (binary32): $b_1 = S$, $b_2 = 2.0$, where $S = 1 + 100 \\cdot 2^{-23}$.\n\nLet's examine the representation of the key $b_1 = S$.\n$S = 1 + 100 \\cdot 2^{-23}$. The integer $100$ in binary is $64 + 32 + 4$, which is $2^6 + 2^5 + 2^2$.\nSo, $S = 1 + (2^6 + 2^5 + 2^2) \\cdot 2^{-23} = 1 + 2^{-17} + 2^{-18} + 2^{-21}$.\nSince the fractional part of $S$ is a sum of negative powers of $2$ where the largest denominator is $2^{21}$, and $21 \\le 23$, the value $S$ is exactly representable in the binary32 format. The key $b_2 = 2.0$ is also exactly representable in binary32.\n\nNow, we evaluate the two join strategies.\n\n**Strategy D: Cast binary32 to binary64, then compare.**\nIn this strategy, a pair $(a_i, b_j)$ is formed if $a_i = \\text{cast}_{\\text{binary64}}(b_j)$.\nCasting from a lower-precision format (binary32) to a higher-precision format (binary64) is always an exact operation; there is no loss of information.\nTherefore, $\\text{cast}_{\\text{binary64}}(b_j)$ is simply the exact value of $b_j$.\nWe test the $3 \\times 2 = 6$ possible pairs:\n1.  Comparisons with $b_1 = S$:\n    - $a_1 = S - 0.4 \\cdot 2^{-23} \\neq S$. No pair $(a_1, b_1)$.\n    - $a_2 = S + 0.4 \\cdot 2^{-23} \\neq S$. No pair $(a_2, b_1)$.\n    - $a_3 = 2.0 \\neq S$. No pair $(a_3, b_1)$.\n2.  Comparisons with $b_2 = 2.0$:\n    - $a_1 = 1 + 99.6 \\cdot 2^{-23} \\neq 2.0$. No pair $(a_1, b_2)$.\n    - $a_2 = 1 + 100.4 \\cdot 2^{-23} \\neq 2.0$. No pair $(a_2, b_2)$.\n    - $a_3 = 2.0$. The values are equal. A pair $(a_3, b_2)$ is formed.\n\nStrategy D produces exactly one pair: $(a_3, b_2)$.\n\n**Strategy S: Cast binary64 to binary32, then compare.**\nIn this strategy, a pair $(a_i, b_j)$ is formed if $\\text{cast}_{\\text{binary32}}(a_i) = b_j$.\nCasting from binary64 to binary32 involves rounding, as it is a conversion to a lower-precision format.\nFor a value $x$, $\\text{cast}_{\\text{binary32}}(x)$ will be the nearest representable binary32 value. A value $v$ is rounded to a neighboring representable value $v_r$ if the distance $|v-v_r|$ is less than half the ULP. The ULP for numbers in the range $[1.0, 2.0)$ is $2^{-23}$. The rounding boundary is therefore at a distance of $0.5 \\cdot 2^{-23}$ from a representable number.\n\n1.  Comparisons with $b_1 = S$:\n    - Consider $a_1 = S - 0.4 \\cdot 2^{-23}$. The value $S$ is representable in binary32. The distance between $a_1$ and $S$ is $|(S - 0.4 \\cdot 2^{-23}) - S| = 0.4 \\cdot 2^{-23}$. This distance is less than the rounding threshold of $0.5 \\cdot 2^{-23}$. Therefore, $a_1$ rounds to $S$.\n    $\\text{cast}_{\\text{binary32}}(a_1) = S = b_1$. A pair $(a_1, b_1)$ is formed.\n    - Consider $a_2 = S + 0.4 \\cdot 2^{-23}$. The distance between $a_2$ and $S$ is $|(S + 0.4 \\cdot 2^{-23}) - S| = 0.4 \\cdot 2^{-23}$. This is also less than $0.5 \\cdot 2^{-23}$. Therefore, $a_2$ also rounds to $S$.\n    $\\text{cast}_{\\text{binary32}}(a_2) = S = b_1$. A pair $(a_2, b_1)$ is formed.\n    - Consider $a_3 = 2.0$. The value $2.0$ is exactly representable in binary32, so $\\text{cast}_{\\text{binary32}}(a_3) = 2.0$. Since $2.0 \\neq S$, no pair $(a_3, b_1)$ is formed.\n\n2.  Comparisons with $b_2 = 2.0$:\n    - $\\text{cast}_{\\text{binary32}}(a_1)$ rounds to $S$, which is not $2.0$. No pair $(a_1, b_2)$.\n    - $\\text{cast}_{\\text{binary32}}(a_2)$ rounds to $S$, which is not $2.0$. No pair $(a_2, b_2)$.\n    - $\\text{cast}_{\\text{binary32}}(a_3) = \\text{cast}_{\\text{binary32}}(2.0) = 2.0$. This equals $b_2$. A pair $(a_3, b_2)$ is formed.\n\nStrategy S produces three pairs: $(a_1, b_1)$, $(a_2, b_1)$, and $(a_3, b_2)$.\n\n**Conclusion**\nLet $P_D$ be the set of pairs found by Strategy D, and $P_S$ be the set of pairs found by Strategy S.\n$P_D = \\{ (a_3, b_2) \\}$\n$P_S = \\{ (a_1, b_1), (a_2, b_1), (a_3, b_2) \\}$\n\nThe problem asks for the number of pairs that Strategy S produces but Strategy D does not. This is the cardinality of the set difference $P_S \\setminus P_D$.\n$P_S \\setminus P_D = \\{ (a_1, b_1), (a_2, b_1), (a_3, b_2) \\} \\setminus \\{ (a_3, b_2) \\} = \\{ (a_1, b_1), (a_2, b_1) \\}$.\nThe number of such pairs is the cardinality of this set, which is $2$. These pairs, $(a_1, b_1)$ and $(a_2, b_1)$, are found by Strategy S due to loss of precision during casting, whereas Strategy D correctly identifies that the keys are not equal.\n\nThe total count of such pairs is $2$.", "answer": "$$\\boxed{2}$$", "id": "3678173"}]}