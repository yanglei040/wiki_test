{"hands_on_practices": [{"introduction": "Before delving into the complex mechanics of paging, we must first understand why we manage memory so carefully. The concept of Effective Access Time ($EAT$) provides a powerful mathematical tool to quantify the performance impact of not having a piece of data in main memory. This exercise [@problem_id:3668071] guides you through deriving the fundamental $EAT$ formula, making the relationship between the page fault rate and overall system speed crystal clear.", "problem": "A computer employs demand paging to support virtual memory, using paging as a non-contiguous allocation method. Consider a single memory reference performed by the Central Processing Unit (CPU). Let the time to complete a memory reference when the referenced page is present in main memory be $t_m$. When a page fault occurs, the operating system must service the fault, incurring a total page fault service time $t_f$ (including Input/Output (I/O) transfer, operating system overhead, and process restart). After the fault is serviced, the original memory reference is retried and completes in $t_m$. Assume the page fault rate, defined as the probability that a random memory reference incurs a page fault, is $\\epsilon \\in [0,1]$. \n\nStarting from the law of total expectation for random variables, derive the Effective Access Time (EAT) as a function of $\\epsilon$, $t_m$, and $t_f$. Using your derived expression, solve for the largest $\\epsilon$ such that the Effective Access Time satisfies $EAT \\leq 2t_m$. Express your final answer as a closed-form symbolic expression for the maximal allowable $\\epsilon$. No numerical evaluation is required.", "solution": "The problem is first assessed for validity.\n\n### Step 1: Extract Givens\n-   A computer uses demand paging and paging as a non-contiguous allocation method.\n-   The time to complete a memory reference when the page is in main memory is $t_m$.\n-   When a page fault occurs, the total page fault service time is $t_f$.\n-   After a page fault is serviced, the original memory reference is retried and completes in time $t_m$.\n-   The page fault rate, which is the probability of a page fault, is $\\epsilon$, where $\\epsilon \\in [0,1]$.\n-   The derivation of the Effective Access Time (EAT) must start from the law of total expectation.\n-   The final objective is to solve for the largest $\\epsilon$ such that $EAT \\leq 2t_m$.\n\n### Step 2: Validate Using Extracted Givens\nThe problem is scientifically grounded, being a standard performance analysis model in the study of operating systems. All terms such as \"demand paging\", \"page fault\", \"effective access time\" are well-defined within the field. The problem is well-posed, providing all necessary variables ($t_m$, $t_f$, $\\epsilon$) and a clear objective. It is also objective, using precise, technical language. The setup is complete and consistent, leading to a unique and meaningful solution. The problem does not violate any of the invalidity criteria.\n\n### Step 3: Verdict and Action\nThe problem is valid. A complete solution will be provided.\n\n### Solution Derivation\nThe problem requires the derivation of the Effective Access Time (EAT) for a demand-paged memory system. We must start from the law of total expectation for random variables.\n\nLet $T$ be the random variable representing the total time to complete a single memory reference. The EAT is, by definition, the expected value of this random variable, $EAT = E[T]$.\n\nLet $F$ be the event that the memory reference causes a page fault. Let $F^c$ be the complementary event, that the referenced page is present in main memory (a page hit). The problem provides the probability of a page fault as the page fault rate $\\epsilon$.\n$$ P(F) = \\epsilon $$\nThe probability of a page hit is therefore:\n$$ P(F^c) = 1 - P(F) = 1 - \\epsilon $$\n\nThe law of total expectation for the random variable $T$, conditioned on the mutually exclusive and exhaustive events $F$ and $F^c$, is given by:\n$$ E[T] = E[T|F] P(F) + E[T|F^c] P(F^c) $$\nwhere $E[T|A]$ is the conditional expectation of $T$ given that event $A$ has occurred.\n\nWe must determine the values of the two conditional expectations from the problem statement.\n\n1.  $E[T|F^c]$: This is the expected access time given that a page fault does *not* occur (a page hit). The problem states that the time to complete a memory reference when the page is in main memory is $t_m$. Thus:\n    $$ E[T|F^c] = t_m $$\n\n2.  $E[T|F]$: This is the expected access time given that a page fault *does* occur. The problem describes the sequence of events upon a fault:\n    - The operating system services the fault, which takes a total time of $t_f$.\n    - After the fault is serviced, the original memory reference is retried. Since the page is now guaranteed to be in main memory, this retry operation will complete in a time of $t_m$.\n    The total time in the case of a page fault is the sum of the service time and the time for the successful retry.\n    $$ E[T|F] = t_f + t_m $$\n\nNow, we substitute these components back into the formula for the law of total expectation:\n$$ EAT = E[T] = (t_f + t_m) \\cdot P(F) + (t_m) \\cdot P(F^c) $$\n$$ EAT = (t_f + t_m) \\epsilon + t_m (1 - \\epsilon) $$\n\nWe simplify this expression for EAT:\n$$ EAT = t_f \\epsilon + t_m \\epsilon + t_m - t_m \\epsilon $$\n$$ EAT = t_m + t_f \\epsilon $$\nThis is the derived expression for the Effective Access Time as a function of $\\epsilon$, $t_m$, and $t_f$.\n\nThe second part of the problem requires finding the largest value of the page fault rate $\\epsilon$ such that the EAT is no more than twice the memory access time $t_m$. This is expressed by the inequality:\n$$ EAT \\leq 2t_m $$\n\nSubstituting our derived expression for EAT into this inequality:\n$$ t_m + t_f \\epsilon \\leq 2t_m $$\n\nTo solve for $\\epsilon$, we first isolate the term containing it by subtracting $t_m$ from both sides of the inequality:\n$$ t_f \\epsilon \\leq 2t_m - t_m $$\n$$ t_f \\epsilon \\leq t_m $$\n\nThe quantities $t_m$ and $t_f$ represent time durations and are thus physically positive real numbers. Specifically, $t_f > 0$. We can therefore divide both sides of the inequality by $t_f$ without altering the direction of the inequality sign:\n$$ \\epsilon \\leq \\frac{t_m}{t_f} $$\n\nThe problem asks for the *largest* value of $\\epsilon$ that satisfies this condition. The set of all valid $\\epsilon$ values is the interval $[0, \\frac{t_m}{t_f}]$, also respecting the inherent physical constraint $\\epsilon \\geq 0$. The maximum value in this interval is $\\frac{t_m}{t_f}$. The problem also states that $\\epsilon \\in [0,1]$. In any practical computer system, the page fault service time $t_f$, which involves mechanical disk I/O, is several orders of magnitude larger than the main memory access time $t_m$ (e.g., milliseconds vs. nanoseconds). Therefore, the ratio $\\frac{t_m}{t_f}$ is a small positive number much less than $1$, so the constraint $\\epsilon \\leq 1$ is implicitly satisfied.\n\nThe maximal allowable page fault rate is the upper bound of the derived inequality.", "answer": "$$ \\boxed{\\frac{t_m}{t_f}} $$", "id": "3668071"}, {"introduction": "Paging elegantly solves the problem of external fragmentation by introducing a layer of indirection through page tables. However, this powerful abstraction is not without cost, as the page table data structures themselves consume physical memory. This practice [@problem_id:3668035] challenges you to calculate this \"hidden cost\" by determining the total size of a multi-level page table hierarchy for a given process, revealing an important design trade-off inherent in all virtual memory systems.", "problem": "A system implements hierarchical paging for virtual memory with the following properties grounded in standard definitions. Each virtual address has width $48$ bits. A page is of size $4$ KiB, meaning $4 \\times 2^{10}$ bytes, and each page table entry occupies $8$ bytes. Each page table itself occupies exactly one physical page. Only standard $4$ KiB pages are used (no larger pages are employed). Each process owns its page table hierarchy exclusively; no page table pages are shared across processes. Consider a single process that allocates exactly $64$ MiB of user-space virtual memory, and nothing else. The $64$ MiB region is page-aligned, contiguous, aligned to a $2$ MiB boundary, and lies entirely within a single $1$ GiB range and a single $512$ GiB range of the virtual address space.\n\nStarting only from the core definitions that the page offset width equals $\\log_{2}$ of the page size in bytes, that the number of entries per page table equals the page size divided by the entry size, and that a level with $n$ entries consumes $\\log_{2}(n)$ index bits of the virtual address, derive the total memory overhead of the page tables for this process and the actual count of page table pages instantiated across all levels. Express the memory overhead in KiB and the page table page count as a pure number. Provide exact integer values; do not round. Report your final answer as a row vector $\\big[$overhead in KiB, page table page count$\\big]$.", "solution": "We begin from fundamental paging definitions. Let the page size be $P$ bytes and let each page table entry have size $E$ bytes. Then the number of entries per page table is\n$$\nN \\;=\\; \\frac{P}{E}.\n$$\nThe page offset requires\n$$\nb_{\\text{off}} \\;=\\; \\log_{2}(P)\n$$\nbits of the virtual address. If each page table has $N$ entries, the index width per level is\n$$\nb_{\\ell} \\;=\\; \\log_{2}(N) \\;=\\; \\log_{2}\\!\\left(\\frac{P}{E}\\right).\n$$\nGiven a virtual address width of $B$ bits, the number of index bits across all levels is $B - b_{\\text{off}}$, which determines the number of levels\n$$\nL \\;=\\; \\frac{B - b_{\\text{off}}}{b_{\\ell}}.\n$$\n\nInstantiate parameters. The page size is $P = 4 \\text{ KiB} = 4 \\times 2^{10} \\text{ bytes} = 2^{12} \\text{ bytes}$. The entry size is $E = 8 \\text{ bytes} = 2^{3} \\text{ bytes}$. Hence\n$$\nN \\;=\\; \\frac{2^{12}}{2^{3}} \\;=\\; 2^{9} \\;=\\; 512,\n$$\nand\n$$\nb_{\\text{off}} \\;=\\; \\log_{2}(2^{12}) \\;=\\; 12,\\quad b_{\\ell} \\;=\\; \\log_{2}(2^{9}) \\;=\\; 9.\n$$\nWith $B = 48$, the number of index bits is $48 - 12 = 36$, so the number of levels is\n$$\nL \\;=\\; \\frac{36}{9} \\;=\\; 4.\n$$\nThus we have a standard four-level hierarchy, where each lower-level page table (level $1$) maps $N$ pages, i.e., $N \\times P$ bytes:\n$$\n\\text{coverage per level-1 table} \\;=\\; N \\cdot P \\;=\\; 2^{9} \\cdot 2^{12} \\;=\\; 2^{21} \\text{ bytes} \\;=\\; 2 \\text{ MiB}.\n$$\n\nThe process allocates a single contiguous region of size $S = 64 \\text{ MiB} = 64 \\times 2^{20} \\text{ bytes} = 2^{26} \\text{ bytes}$. The number of pages needed at the leaf level is\n$$\nn_{\\text{pages}} \\;=\\; \\frac{S}{P} \\;=\\; \\frac{2^{26}}{2^{12}} \\;=\\; 2^{14} \\;=\\; 16384.\n$$\nEach level-$1$ page table maps $2 \\text{ MiB}$, which is $512$ pages. Therefore, the number of level-$1$ page tables required is\n$$\nn_{L1} \\;=\\; \\frac{n_{\\text{pages}}}{N} \\;=\\; \\frac{2^{14}}{2^{9}} \\;=\\; 2^{5} \\;=\\; 32.\n$$\nBecause the $64$ MiB region is aligned to a $2$ MiB boundary and its size is an integer multiple of $2$ MiB, exactly $32$ level-$1$ tables suffice without any partially filled extra tables.\n\nNow consider level-$2$. Each level-$2$ table has $512$ entries, each pointing to a level-$1$ table, so a single level-$2$ table covers up to\n$$\n512 \\times (2 \\text{ MiB}) \\;=\\; 1 \\text{ GiB}.\n$$\nBy assumption, the $64$ MiB region lies entirely within a single $1$ GiB range. Therefore,\n$$\nn_{L2} \\;=\\; 1.\n$$\n\nConsider level-$3$. Each level-$3$ table has $512$ entries, each pointing to a level-$2$ table, so one level-$3$ table can cover up to $512 \\text{ GiB}$. Our region lies within a single $512$ GiB range, so the number of level-$3$ tables needed is\n$$\nn_{L3} \\;=\\; 1.\n$$\n\nAt level-$4$ (the top level), each process has its own top-level table by assumption, hence\n$$\nn_{L4} \\;=\\; 1.\n$$\n\nTherefore, the total number of page table pages instantiated is the sum across levels:\n$$\nn_{\\text{pt-pages}} \\;=\\; n_{L1} + n_{L2} + n_{L3} + n_{L4} \\;=\\; 32 + 1 + 1 + 1 \\;=\\; 35.\n$$\n\nEach page table occupies one physical page of size $P = 4 \\text{ KiB}$. Thus the memory overhead due to page tables is\n$$\n\\text{overhead} \\;=\\; n_{\\text{pt-pages}} \\times 4 \\text{ KiB} \\;=\\; 35 \\times 4 \\text{ KiB} \\;=\\; 140 \\text{ KiB}.\n$$\n\nPer the instructions, we report the memory overhead in KiB and the page table page count as a row vector. Hence the final pair is\n$$\n\\big[140,\\, 35\\big].\n$$", "answer": "$$\\boxed{\\begin{pmatrix}140 & 35\\end{pmatrix}}$$", "id": "3668035"}, {"introduction": "The performance of a paged memory system is not solely the operating system's responsibility; it is a partnership between the OS and the applications it runs. This final exercise [@problem_id:3668050] vividly demonstrates how an application's design can dramatically influence paging performance. By analyzing how different data access patterns interact with the memory system, you will see how a simple change in code can prevent system thrashing and unlock massive performance improvements.", "problem": "Consider a two-level memory system with demand paging in an operating system. A matrix $A$ of dimensions $M \\times N$ is stored in row-major order in a single contiguous virtual address range. Each element occupies $E$ bytes. The system uses a page size of $P$ bytes and maintains $F$ physical page frames. The page replacement policy is Least Recently Used (LRU). The Central Processing Unit (CPU) cache line size is $L$ bytes. Assume the following:\n- All page frames are initially empty and only the data pages of $A$ cause page faults.\n- There is no prefetching and no read-ahead at the page level.\n- Once a page is resident in a frame, further accesses to that page do not cause a page fault unless it has been evicted.\n- Ignore Translation Lookaside Buffer (TLB) effects and any cache misses below the page level; only count operating system page faults.\n- The program executes one of two nested-loop traversals of $A$ that each touch every element exactly once:\n  1. Row-major-friendly order: for $i$ from $0$ to $M-1$ (outer), for $j$ from $0$ to $N-1$ (inner), access $A[i][j]$.\n  2. Column-major order: for $j$ from $0$ to $N-1$ (outer), for $i$ from $0$ to $M-1$ (inner), access $A[i][j]$.\n\nStart from the fundamental definitions of paging, virtual-to-physical page mapping, and the address mapping of row-major matrices. Using those principles, reason about the sequence of virtual page numbers touched under each traversal and the reuse distance of those pages under LRU. Then compute the exact total number of page faults for each traversal and the reduction obtained by interchanging the loops from column-major to row-major under the following concrete parameters:\n- $M = 1500$, $N = 1024$, $E = 8$ bytes, $P = 4096$ bytes, $F = 512$ frames, and $L = 64$ bytes.\n\nExpress your final answer as a single integer equal to the reduction in page faults achieved by interchanging the loops from column-major order to row-major-friendly order. No rounding is required. State the integer only (no units) in your final boxed answer.", "solution": "We begin from the core definitions:\n\n- In demand paging, virtual memory is divided into fixed-size pages of size $P$ bytes, which are mapped to physical page frames. A page fault occurs when the process references a virtual page that is not currently in any physical frame.\n- Under Least Recently Used (LRU) replacement, the page whose most recent access is farthest in the past is evicted upon a new page fault when no free frames exist.\n- A row-major matrix of size $M \\times N$ with element size $E$ bytes has element $A[i][j]$ stored at linear index $k = iN + j$ and virtual byte address $a(i,j) = a_{0} + E(iN + j)$, where $a_{0}$ is the base address of $A$.\n- The virtual page number touched by accessing $A[i][j]$ is $v(i,j) = \\left\\lfloor \\dfrac{a(i,j)}{P} \\right\\rfloor = \\left\\lfloor \\dfrac{a_{0}}{P} + \\dfrac{E(iN + j)}{P} \\right\\rfloor$. Since only differences in $v(i,j)$ matter, we can ignore the constant $\\left\\lfloor \\dfrac{a_{0}}{P} \\right\\rfloor$ and focus on $\\left\\lfloor \\dfrac{E(iN + j)}{P} \\right\\rfloor$.\n\nWe will count page faults for each traversal order, starting from an empty set of resident frames and tracking reuse patterns under LRU, with the given parameters:\n- $M = 1500$, $N = 1024$, $E = 8$, $P = 4096$, $F = 512$, $L = 64$.\n\nNote that the CPU cache line size $L$ does not alter page fault counts under the stated assumptions because page faults occur at page granularity $P$, and once a page is present, intra-page spatial locality (even if spread across multiple cache lines of size $L$) does not induce additional page faults. We nevertheless keep $L$ explicit to highlight that subpage locality does not affect the page fault count in this model.\n\nStep 1: Compute total size and total number of distinct pages in $A$.\n\nThe total number of bytes in $A$ is\n$$\nB = M N E = 1500 \\times 1024 \\times 8 = 12{,}288{,}000.\n$$\nThe total number of distinct virtual pages occupied by $A$ is\n$$\nT = \\left\\lceil \\frac{B}{P} \\right\\rceil = \\left\\lceil \\frac{12{,}288{,}000}{4096} \\right\\rceil = \\left\\lceil 3000 \\right\\rceil = 3000.\n$$\nBecause $A$ occupies a contiguous virtual region and the row-major-friendly traversal scans that region in essentially contiguous order, each of these $T$ pages will be touched exactly once and never reused later in that traversal.\n\nStep 2: Page faults for the row-major-friendly order (outer $i$, inner $j$).\n\nIn row-major-friendly traversal, the inner loop increases $j$ so that $A[i][j]$ touches consecutive addresses $a(i,j) = a_{0} + E(iN + j)$ for fixed $i$. Across the whole traversal, the address stream is monotonically increasing through the contiguous array.\n\nKey consequence: Since no virtual page is ever revisited (monotone sweep through a contiguous region), the number of page faults equals the number of distinct pages of $A$ that are touched, regardless of $F$ or the replacement policy. That is,\n$$\n\\text{PF}_{\\text{row}} = T = 3000.\n$$\n\nStep 3: Structure of pages per row and reuse opportunities for column-major order (outer $j$, inner $i$).\n\nFirst, determine how many pages each row of $N$ elements spans. The number of elements per page is\n$$\n\\alpha = \\frac{P}{E} = \\frac{4096}{8} = 512 \\text{ elements per page}.\n$$\nThus, each row of length $N = 1024$ elements occupies\n$$\nq = \\left\\lceil \\frac{N}{\\alpha} \\right\\rceil = \\left\\lceil \\frac{1024}{512} \\right\\rceil = 2 \\text{ pages per row}.\n$$\nFor fixed column $j$, as $i$ increases by $1$, the linear index increases by $N$, so the byte stride is\n$$\nS = E N = 8 \\times 1024 = 8192 \\text{ bytes} = 2P.\n$$\nTherefore, within a single column, successive accesses jump by exactly $2$ pages; the sequence of virtual page numbers $v(i,j)$ for $i=0,1,2,\\dots$ is strictly increasing by $2$ each time (modulo a base offset determined by $j$). Consequently, within a single column $j$, no virtual page is revisited; each access in that column touches a new virtual page.\n\nHowever, across columns, there is potential reuse: for $0 \\leq j \\leq 511$, the element $A[i][j]$ lies in the first of the $2$ pages of row $i$, while for $512 \\leq j \\leq 1023$, it lies in the second page of row $i$. Thus, for all columns in the first half ($j \\in [0,511]$), the access for row $i$ always targets the same page for that row (its first page); similarly for the second half ($j \\in [512,1023]$), the access targets the second page for that row.\n\nTherefore, if the system could retain all $M$ pages corresponding to the current half (one page per row) in physical memory between consecutive columns, the first half would incur $M$ initial page faults in column $j=0$ and then zero faults for columns $j=1,\\dots,511$; the second half would analogously incur $M$ initial page faults at $j=512$ and then zero thereafter. In total, the best-case page faults for column-major would be $2M$.\n\nStep 4: Page faults for the column-major order under $F = 512$ frames and LRU.\n\nWe now consider feasibility of retaining those $M$ pages between columns under LRU. During column $j$, the inner loop visits $M$ distinct pages (one per row) and does not revisit any of them within the column. The recency order at the end of column $j$ under LRU is such that the most recently used pages are those corresponding to the largest $i$ values. When moving to column $j+1$ and restarting the inner loop at $i=0$, the access to row $i=0$ attempts to reuse the page that was last referenced roughly $M$ page references ago. To avoid a fault on that reuse, the number of frames $F$ would need to be at least $M$ so that none of the $M$ distinct row pages from the current half were evicted. If $F < M$, then by the end of a column, at least $M - F$ of those pages have been evicted, and specifically the earliest ones (smallest $i$) will no longer be resident. Thus, at the start of the next column, the page for $i=0$ will fault, and similarly for $i=1$, and so on. In fact, with $F \\ll M$, every access in every column faults because reuse distances are approximately $M$ and exceed the frame budget, causing complete thrashing.\n\nGiven $F = 512$ and $M = 1500$, we have $F < M$. Therefore, under the column-major order:\n- Within each column $j$, each of the $M$ accesses touches a distinct page for the first time in that column, so each access faults.\n- Across columns, no reuse is captured due to $F < M$ under LRU, so every access continues to fault.\n\nTotal page faults for column-major are thus\n$$\n\\text{PF}_{\\text{col}} = M N = 1500 \\times 1024 = 1{,}536{,}000.\n$$\n\nStep 5: Reduction in page faults due to loop interchange from column-major to row-major.\n\nThe reduction is\n$$\n\\Delta = \\text{PF}_{\\text{col}} - \\text{PF}_{\\text{row}} = 1{,}536{,}000 - 3000 = 1{,}533{,}000.\n$$\n\nStep 6: Interpret the role of $P$ and $L$ and the condition for when interchange helps.\n\n- The page size $P$ governs $\\alpha = P/E$ and therefore determines $q = \\lceil N / \\alpha \\rceil$, the number of pages per row. In our parameters, $q = 2$, which implies that the optimal column-major page fault count, when sufficient frames are available, is $qM = 2M$, matching the row-major count $\\lceil M N E / P \\rceil = qM$ for a contiguous sweep.\n- The cache line size $L$ affects processor cache behavior but not the number of operating system page faults under the given assumptions. Hence $L$ does not enter the page fault counts.\n- In general, for a row-major stored matrix and column-major traversal under LRU, interchange reduces page faults when $F < M$ because the working set per column-half is $M$ pages and cannot be retained; with $F \\geq M$, the column-major traversal can capture inter-column reuse within each half, yielding $qM$ faults, equal to the row-major count.\n\nFor the concrete numerical parameters requested, the exact reduction is the integer computed above.", "answer": "$$\\boxed{1533000}$$", "id": "3668050"}]}