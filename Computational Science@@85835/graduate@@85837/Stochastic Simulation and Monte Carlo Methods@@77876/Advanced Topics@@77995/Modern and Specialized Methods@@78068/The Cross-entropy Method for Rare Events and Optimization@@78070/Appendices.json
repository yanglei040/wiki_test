{"hands_on_practices": [{"introduction": "To build a solid foundation, our first practice involves deriving the Cross-Entropy (CE) method's update rule from first principles for the canonical case of a one-dimensional Gaussian distribution. This exercise connects the theoretical concept of minimizing Kullback-Leibler divergence to a concrete Maximum Likelihood Estimation problem on an elite set of samples. You will then translate this theory into practice by implementing the complete algorithm in code to estimate a rare-event probability, solidifying your understanding of the entire CE workflow [@problem_id:3351653].", "problem": "Consider a rare-event probability estimation problem under a standard normal reference model. Let $X$ be a real-valued random variable with $X \\sim \\mathcal{N}(0,1)$, and let the rare event be the exceedance set $\\{X \\ge \\gamma\\}$ for a large threshold $\\gamma$. You will develop and implement a cross-entropy method iteratively over a mean-shifted Gaussian family $g_\\mu = \\mathcal{N}(\\mu,1)$ to construct an efficient importance sampling estimator for the probability $p(\\gamma) = \\mathbb{P}(X \\ge \\gamma)$, and derive the corresponding parameter update rule from first principles.\n\nTasks:\n\n1) Derive the cross-entropy update. Start from the following foundational base:\n- The Kullback–Leibler divergence (KLD) from a distribution with density $h(x)$ to a parametric family member with density $g_\\mu(x)$ is $D_{\\mathrm{KL}}(h \\,\\|\\, g_\\mu) = \\int h(x) \\log\\!\\big(\\frac{h(x)}{g_\\mu(x)}\\big) \\, dx$, and minimizing $D_{\\mathrm{KL}}(h \\,\\|\\, g_\\mu)$ over $\\mu$ is equivalent to maximizing $\\int h(x) \\log g_\\mu(x) \\, dx$ over $\\mu$.\n- The zero-variance importance distribution for estimating $p(\\gamma)$ has density proportional to $\\mathbb{1}\\{x \\ge \\gamma\\} f(x)$, where $f(x)$ is the density of the standard normal $\\mathcal{N}(0,1)$, and $\\mathbb{1}\\{\\cdot\\}$ denotes the indicator function.\n- In the cross-entropy approach for rare-event estimation, one replaces the intractable zero-variance distribution by a sequence of tractable parametric distributions $g_{\\mu_t}$ and at each iteration $t$, maximizes a sample-based surrogate of $\\int h_t(x) \\log g_\\mu(x)\\,dx$, where $h_t$ is a level-distribution concentrating on a high-performance level set. A standard and numerically stable construction for the level set at iteration $t$ is to use the empirical $(1-\\rho)$-quantile of the current samples under $g_{\\mu_t}$ to define a data-driven threshold $c_t$, and then focus on the elite set $\\{x \\ge c_t\\}$.\n\nUsing only the above base, derive the iteration rule that for the family $g_\\mu=\\mathcal{N}(\\mu,1)$ with fixed unit variance, the updated parameter $\\mu_{t+1}$ equals the empirical mean of the elite samples drawn from $g_{\\mu_t}$. Your derivation must explicitly show how the Kullback–Leibler divergence objective reduces to a maximum likelihood problem over the elite set, and why fixing the variance to one leads to the elite-sample mean as the maximizer.\n\n2) Specify and implement the following algorithm to estimate $p(\\gamma)$ by importance sampling with the final proposal $g_{\\mu_T}$:\n- Inputs: threshold $\\gamma$, sample size per iteration $n$, elite fraction $\\rho \\in (0,1)$, number of iterations $T$, and a random seed $s$.\n- Initialization: $\\mu_0 \\leftarrow 0$ and $c_0 \\leftarrow -\\infty$.\n- For each iteration $t \\in \\{0,1,\\dots,T-1\\}$:\n  - Draw $n$ independent samples $X_1,\\dots,X_n \\sim \\mathcal{N}(\\mu_t,1)$.\n  - Let $q_t$ be the empirical $(1-\\rho)$-quantile of $\\{X_i\\}_{i=1}^n$.\n  - Set the level $c_t \\leftarrow \\min\\{\\gamma, q_t\\}$.\n  - Define the elite set $\\mathcal{E}_t = \\{i \\in \\{1,\\dots,n\\}: X_i \\ge c_t\\}$. Update $\\mu_{t+1}$ to be the empirical mean over $\\{X_i: i \\in \\mathcal{E}_t\\}$.\n- After $T$ iterations, set $\\mu^\\star \\leftarrow \\mu_T$. Using a fresh set of $n$ independent samples $Y_1,\\dots,Y_n \\sim \\mathcal{N}(\\mu^\\star,1)$, compute the importance sampling estimator\n  $$\\widehat{p}(\\gamma) \\;=\\; \\frac{1}{n} \\sum_{j=1}^n \\left[\\frac{f(Y_j)}{g_{\\mu^\\star}(Y_j)} \\, \\mathbb{1}\\{Y_j \\ge \\gamma\\}\\right],$$\n  where $f$ is the $\\mathcal{N}(0,1)$ density and $g_{\\mu^\\star}$ is the $\\mathcal{N}(\\mu^\\star,1)$ density. Express the likelihood ratio in closed form as a function of $\\mu^\\star$ and $Y_j$.\n\n3) Implement the above algorithm as a complete, runnable program that:\n- Uses the provided test suite below.\n- Produces a single line of output containing the results as a comma-separated list enclosed in square brackets, i.e., in the format $[r_1,r_2,\\dots]$.\n- For numerical stability, if at any iteration the elite set is empty, replace $\\mu_{t+1}$ by the maximum of the current samples.\n- Round each returned probability estimate to $12$ decimal places before output, but the printed objects must be floating-point numbers.\n\nTest suite:\n- Case $1$: $(\\gamma, n, \\rho, T, s) = (2.0, 5000, 0.1, 7, 42)$.\n- Case $2$: $(\\gamma, n, \\rho, T, s) = (4.0, 8000, 0.2, 10, 314159)$.\n- Case $3$: $(\\gamma, n, \\rho, T, s) = (0.0, 4000, 0.1, 4, 7)$.\n- Case $4$: $(\\gamma, n, \\rho, T, s) = (5.5, 12000, 0.2, 12, 2023)$.\n\nYour program must hard-code these cases, use the specified seeds for reproducibility, and output a single line with the list $[\\widehat{p}_1, \\widehat{p}_2, \\widehat{p}_3, \\widehat{p}_4]$, where each $\\widehat{p}_k$ is the rounded importance sampling estimate for Case $k$. No user input is allowed. No physical units or angle units are involved. Percentages must not be used anywhere; all outputs are real-valued floats.", "solution": "The problem is validated as self-contained, scientifically grounded, and well-posed. We proceed with the solution, which consists of two parts: a theoretical derivation of the cross-entropy parameter update rule and the implementation of the specified algorithm.\n\n**Part 1: Derivation of the Cross-Entropy Update Rule**\n\nThe objective of the cross-entropy method at each iteration $t$ is to find a parameter $\\mu$ for our sampling distribution $g_\\mu(x)$ that minimizes the Kullback-Leibler (KL) divergence from an \"ideal\" target distribution $h_t(x)$ to $g_\\mu(x)$. The ideal target distribution $h_t(x)$ is defined to be concentrated on the set of \"high-performance\" samples.\n\nAs stated in the problem, minimizing the KL divergence $D_{\\mathrm{KL}}(h_t \\,\\|\\, g_\\mu)$ over $\\mu$ is equivalent to maximizing the cross-entropy term $\\int h_t(x) \\log g_\\mu(x) \\, dx$. The parameter update is thus given by:\n$$ \\mu_{t+1} = \\arg\\max_{\\mu} \\int h_t(x) \\log g_\\mu(x) \\, dx $$\n\nIn this problem, we sample from the current distribution $f_{\\mu_t}(x) = \\mathcal{N}(\\mu_t, 1)$. The high-performance region is defined by an exceedance level $c_t$, and the ideal distribution $h_t(x)$ has a density proportional to the original density, but conditioned on being in this high-performance region. That is, $h_t(x) \\propto \\mathbb{1}\\{x \\ge c_t\\} f_{\\mu_t}(x)$. More formally, its density is:\n$$ h_t(x) = \\frac{\\mathbb{1}\\{x \\ge c_t\\} f_{\\mu_t}(x)}{\\int \\mathbb{1}\\{y \\ge c_t\\} f_{\\mu_t}(y) \\, dy} $$\nThe denominator is a normalization constant with respect to $x$ and does not depend on the parameter $\\mu$ being optimized. Therefore, maximizing the cross-entropy is equivalent to maximizing:\n$$ \\mathcal{L}(\\mu) = \\int \\mathbb{1}\\{x \\ge c_t\\} f_{\\mu_t}(x) \\log g_\\mu(x) \\, dx $$\n\nThis integral is generally intractable. The cross-entropy method approximates it using a Monte Carlo sample. We draw $n$ independent samples $X_1, \\dots, X_n$ from the current distribution $f_{\\mu_t}(x) = \\mathcal{N}(\\mu_t, 1)$. The empirical, or sample-based, version of the objective becomes:\n$$ \\widehat{\\mathcal{L}}(\\mu) = \\frac{1}{n} \\sum_{i=1}^n \\mathbb{1}\\{X_i \\ge c_t\\} \\log g_\\mu(X_i) $$\nMaximizing this expression is equivalent to maximizing the sum without the $\\frac{1}{n}$ factor. The indicator function $\\mathbb{1}\\{X_i \\ge c_t\\}$ selects only the samples that belong to the elite set, $\\mathcal{E}_t = \\{i \\mid X_i \\ge c_t\\}$. Thus, the optimization problem for the next parameter $\\mu_{t+1}$ is:\n$$ \\mu_{t+1} = \\arg\\max_{\\mu} \\sum_{i \\in \\mathcal{E}_t} \\log g_\\mu(X_i) $$\n\nThis objective is precisely the log-likelihood function for the parameter $\\mu$ of the family $g_\\mu$, given the elite samples $\\{X_i \\mid i \\in \\mathcal{E}_t\\}$ as the observed data. The problem of updating the cross-entropy parameter is therefore reduced to a Maximum Likelihood Estimation (MLE) problem on the elite set.\n\nFor the parametric family $g_\\mu(x) = \\mathcal{N}(\\mu, 1)$, the probability density function is:\n$$ g_\\mu(x) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left( -\\frac{(x-\\mu)^2}{2} \\right) $$\nThe corresponding log-density is:\n$$ \\log g_\\mu(x) = -\\frac{1}{2}\\log(2\\pi) - \\frac{(x-\\mu)^2}{2} $$\nThe log-likelihood function for the elite samples is:\n$$ L(\\mu; \\{X_i\\}_{i \\in \\mathcal{E}_t}) = \\sum_{i \\in \\mathcal{E}_t} \\log g_\\mu(X_i) = \\sum_{i \\in \\mathcal{E}_t} \\left( -\\frac{1}{2}\\log(2\\pi) - \\frac{(X_i-\\mu)^2}{2} \\right) $$\nTo find the value of $\\mu$ that maximizes $L(\\mu)$, we take its derivative with respect to $\\mu$ and set it to zero. Terms not depending on $\\mu$ can be ignored.\n$$ \\frac{\\partial L}{\\partial \\mu} = \\frac{\\partial}{\\partial \\mu} \\sum_{i \\in \\mathcal{E}_t} \\left( - \\frac{(X_i-\\mu)^2}{2} \\right) = - \\sum_{i \\in \\mathcal{E}_t} \\frac{1}{2} \\cdot 2(X_i - \\mu) \\cdot (-1) = \\sum_{i \\in \\mathcal{E}_t} (X_i - \\mu) $$\nSetting the derivative to zero to find the critical point:\n$$ \\sum_{i \\in \\mathcal{E}_t} (X_i - \\mu) = 0 $$\n$$ \\left(\\sum_{i \\in \\mathcal{E}_t} X_i\\right) - |\\mathcal{E}_t|\\mu = 0 $$\n$$ \\mu = \\frac{1}{|\\mathcal{E}_t|} \\sum_{i \\in \\mathcal{E}_t} X_i $$\nThe second derivative, $\\frac{\\partial^2 L}{\\partial \\mu^2} = -|\\mathcal{E}_t|$, is negative (assuming the elite set is not empty, i.e., $|\\mathcal{E}_t| > 0$), which confirms that this critical point is a maximum.\n\nTherefore, the cross-entropy update rule for the mean parameter $\\mu$ of a Gaussian family with fixed unit variance is to set the new parameter $\\mu_{t+1}$ to be the sample mean of the elite samples from iteration $t$. This completes the derivation.\n\n**Part 2: Algorithm Specification and Likelihood Ratio**\n\nThe algorithm is implemented as specified in the problem statement. A key component of the final estimation step is the importance sampling weight, or likelihood ratio, $\\frac{f(y)}{g_{\\mu^\\star}(y)}$. Here, $f$ is the density of the standard normal distribution $\\mathcal{N}(0,1)$ and $g_{\\mu^\\star}$ is the density of the importance sampling distribution $\\mathcal{N}(\\mu^\\star, 1)$.\n\nLet $Y_j$ be a sample drawn from $g_{\\mu^\\star}$. The densities are:\n$$ f(Y_j) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{Y_j^2}{2}\\right) $$\n$$ g_{\\mu^\\star}(Y_j) = \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{(Y_j-\\mu^\\star)^2}{2}\\right) $$\nThe likelihood ratio is their quotient:\n$$ \\frac{f(Y_j)}{g_{\\mu^\\star}(Y_j)} = \\frac{\\exp\\left(-\\frac{Y_j^2}{2}\\right)}{\\exp\\left(-\\frac{(Y_j-\\mu^\\star)^2}{2}\\right)} = \\exp\\left(-\\frac{Y_j^2}{2} - \\left(-\\frac{(Y_j-\\mu^\\star)^2}{2}\\right)\\right) $$\n$$ = \\exp\\left(\\frac{1}{2} \\left[ -Y_j^2 + (Y_j - \\mu^\\star)^2 \\right] \\right) $$\n$$ = \\exp\\left(\\frac{1}{2} \\left[ -Y_j^2 + Y_j^2 - 2Y_j\\mu^\\star + (\\mu^\\star)^2 \\right] \\right) $$\n$$ = \\exp\\left(\\frac{1}{2} \\left[ -2Y_j\\mu^\\star + (\\mu^\\star)^2 \\right] \\right) = \\exp\\left(-Y_j\\mu^\\star + \\frac{(\\mu^\\star)^2}{2}\\right) $$\nThis is the closed-form expression used in the implementation for the final importance sampling estimator:\n$$ \\widehat{p}(\\gamma) = \\frac{1}{n} \\sum_{j=1}^n \\mathbb{1}\\{Y_j \\ge \\gamma\\} \\exp\\left(-Y_j\\mu^\\star + \\frac{(\\mu^\\star)^2}{2}\\right) $$\n\nThe implementation follows the procedural steps laid out in the problem, including the specified handling for empty elite sets.", "answer": "```python\nimport numpy as np\n\ndef cross_entropy_is(gamma, n, rho, T, s):\n    \"\"\"\n    Estimates P(X >= gamma) for X ~ N(0,1) using the cross-entropy method.\n\n    Args:\n        gamma (float): The exceedance threshold.\n        n (int): The sample size per iteration.\n        rho (float): The elite fraction (0 < rho < 1).\n        T (int): The number of iterations.\n        s (int): The random seed.\n\n    Returns:\n        float: The importance sampling estimate of the probability.\n    \"\"\"\n    rng = np.random.default_rng(s)\n    \n    # Initialization\n    mu_t = 0.0\n    \n    # Iterative update of the mean parameter\n    for _ in range(T):\n        # Draw samples from the current proposal distribution N(mu_t, 1)\n        samples = rng.normal(loc=mu_t, scale=1.0, size=n)\n        \n        # Determine the level for the elite set\n        q_t = np.quantile(samples, 1 - rho)\n        c_t = min(gamma, q_t)\n        \n        # Identify the elite samples\n        elite_samples = samples[samples >= c_t]\n        \n        # Update mu for the next iteration\n        if elite_samples.size == 0:\n            # Fallback as specified: use the maximum of the current samples\n            mu_t_plus_1 = np.max(samples)\n        else:\n            # Update mu to be the mean of the elite samples\n            mu_t_plus_1 = np.mean(elite_samples)\n            \n        mu_t = mu_t_plus_1\n\n    # Final parameter for importance sampling\n    mu_star = mu_t\n    \n    # Final estimation using importance sampling\n    # Draw a fresh set of n samples from the final proposal N(mu_star, 1)\n    y_samples = rng.normal(loc=mu_star, scale=1.0, size=n)\n    \n    # Calculate the likelihood ratio f(Y)/g_mu*(Y)\n    # f is N(0,1) density, g_mu* is N(mu_star,1) density.\n    # The ratio simplifies to exp(-mu*Y + mu*^2/2)\n    likelihood_ratio = np.exp(-mu_star * y_samples + (mu_star**2) / 2.0)\n    \n    # Indicator function for the rare event {Y >= gamma}\n    indicators = (y_samples >= gamma)\n    \n    # Importance sampling estimator\n    p_hat = np.mean(likelihood_ratio * indicators)\n    \n    return p_hat\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # (gamma, n, rho, T, s)\n        (2.0, 5000, 0.1, 7, 42),\n        (4.0, 8000, 0.2, 10, 314159),\n        (0.0, 4000, 0.1, 4, 7),\n        (5.5, 12000, 0.2, 12, 2023),\n    ]\n\n    results = []\n    for gamma, n, rho, T, s in test_cases:\n        p_estimate = cross_entropy_is(gamma, n, rho, T, s)\n        # Round to 12 decimal places as required.\n        # The result of round() is a float.\n        rounded_result = round(p_estimate, 12)\n        results.append(rounded_result)\n\n    # Print the final output in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3351653"}, {"introduction": "A crucial aspect of successfully applying the Cross-Entropy method is tuning its core hyperparameter, the elite fraction $\\rho$. This practice challenges you to analyze the profound impact of $\\rho$ on the algorithm's behavior, exploring the trade-off between selection pressure and estimation variance [@problem_id:3351702]. By understanding how $\\rho$ governs convergence speed and stability, you will develop the practical wisdom needed to configure the CE method for robust and efficient performance on different problems.", "problem": "Consider the Cross-Entropy (CE) method for rare-event estimation and optimization. Let $X \\in \\mathbb{R}^d$ be drawn from a base distribution with density $f(x)$, and let $S:\\mathbb{R}^d \\to \\mathbb{R}$ be a performance function. For a rare-event threshold $\\gamma \\in \\mathbb{R}$, define the rare-event set $A = \\{x \\in \\mathbb{R}^d : S(x) \\ge \\gamma\\}$ and the rare-event probability $p = \\mathbb{P}_f(S(X) \\ge \\gamma)$, assumed to be small. The CE method uses a parametric family of importance sampling densities $\\{g_\\theta : \\theta \\in \\Theta\\}$ and iteratively updates $\\theta$ using an elite-sample selection rule based on a quantile level parameter $\\rho \\in (0,1)$. Specifically, at iteration $k$, the method draws $N$ independent samples $X_1,\\dots,X_N \\sim g_{\\theta_k}$, sets $\\gamma_k$ equal to the empirical $(1-\\rho)$-quantile of $\\{S(X_i)\\}_{i=1}^N$ under $g_{\\theta_k}$, and updates $\\theta_{k+1}$ by maximizing the truncated log-likelihood restricted to the elite set $\\{i : S(X_i) \\ge \\gamma_k\\}$:\n$$\n\\theta_{k+1} \\in \\arg\\max_{\\theta \\in \\Theta} \\sum_{i=1}^N \\mathbf{1}\\{S(X_i) \\ge \\gamma_k\\} \\log g_\\theta(X_i).\n$$\nThis update is equivalent to minimizing the Kullback–Leibler (KL) divergence between $g_\\theta$ and the zero-variance importance distribution projected onto the parametric family over the elite set. The parameter $\\rho$ determines the fraction of elite samples, which we denote by $m = \\rho N$ (in expectation), and thereby controls the selection pressure, convergence speed, and the risk of premature convergence or degeneracy in the parameter update.\n\nStarting from the foundational facts that (i) the CE update is a maximum likelihood estimator based on $m$ effective samples and its asymptotic covariance scales like the inverse Fisher information divided by $m$, and (ii) the empirical quantile $\\hat{\\gamma}_k$ at level $(1-\\rho)$ has asymptotic variance governed by the density of $S(X)$ at the true quantile, analyze how the choice of $\\rho$ affects selection pressure, convergence speed, and the risk of premature convergence. Then, propose scientifically grounded guidelines for choosing $\\rho$ in rare-event estimation that balance these effects.\n\nSelect all statements below that are correct given this analysis.\n\nA. Decreasing $\\rho$ (with fixed $N$) increases selection pressure because the elite set shrinks toward higher $S(x)$ values, typically accelerating movement toward the rare-event region. However, this also increases estimator variance, since parameter estimation is based on $m = \\rho N$ effective samples and quantile noise grows with smaller $\\rho$, thereby increasing the risk of premature convergence. A practical guideline is to ensure $\\rho N$ is comfortably larger than the number of free parameters of $g_\\theta$ and to use smoothing of parameter updates to counter high-variance steps.\n\nB. Increasing $\\rho$ increases selection pressure and reduces the risk of premature convergence, so for rare events one should set $\\rho$ as large as possible (e.g., $\\rho \\approx 1$) to move quickly into the tail.\n\nC. For a multivariate Gaussian importance sampler $g_\\theta = \\mathcal{N}(\\mu, \\Sigma)$ in dimension $d$ with both mean and full covariance updated from elites, one must ensure $\\rho N \\ge d+1$ to avoid a singular covariance estimate, and preferably choose $\\rho N \\gg d$ to reduce variance in $\\widehat{\\Sigma}$. Regularization such as exponential smoothing and adding a positive diagonal floor to $\\widehat{\\Sigma}$ further mitigates degeneracy when $\\rho$ is small.\n\nD. The asymptotic variance of the empirical $(1-\\rho)$-quantile $\\hat{\\gamma}_k$ of $S(X)$ under $g_{\\theta_k}$ equals $\\rho/N$, independently of the distribution of $S(X)$, so choosing smaller $\\rho$ always reduces quantile noise.\n\nE. An adaptive schedule that starts with a larger $\\rho$ (e.g., $\\rho$ in $[0.2, 0.5]$) to maintain stability when the sampler is far from the rare-event region, and then decreases $\\rho$ as the distribution approaches the tail to increase selection pressure, is consistent with controlling both parameter-estimation variance (via $\\rho N$) and the difficulty of quantile estimation (via the local density of $S(X)$ at the moving threshold). This strikes a balance between convergence speed and robustness.", "solution": "The problem statement is a valid and well-posed query in the field of stochastic simulation and Monte Carlo methods. It accurately describes the Cross-Entropy (CE) method for rare-event simulation and poses a question regarding the role of the quantile parameter $\\rho$ that requires a standard but nuanced analysis of statistical trade-offs. The premises are scientifically sound and the terminology is correct. We proceed with the analysis.\n\nThe core of the Cross-Entropy (CE) method is an iterative scheme to find an optimal importance sampling (IS) density $g_\\theta(x)$ for estimating a rare-event probability $p = \\mathbb{P}_f(S(X) \\ge \\gamma)$. The ideal, zero-variance IS density is $g^*(x) \\propto f(x) \\mathbf{1}\\{S(x) \\ge \\gamma\\}$. The CE method iteratively refines a parametric density $g_\\theta$ to approximate $g^*(x)$ by minimizing the Kullback–Leibler (KL) divergence. The update rule at iteration $k$ is given as:\n$$\n\\theta_{k+1} \\in \\arg\\max_{\\theta \\in \\Theta} \\sum_{i=1}^N \\mathbf{1}\\{S(X_i) \\ge \\gamma_k\\} \\log g_\\theta(X_i)\n$$\nwhere $X_i \\sim g_{\\theta_k}$ and $\\gamma_k$ is the empirical $(1-\\rho)$-quantile of the performance scores $\\{S(X_i)\\}$. This is a Maximum Likelihood Estimation (MLE) of $\\theta$ based on the \"elite\" samples, i.e., those for which $S(X_i) \\ge \\gamma_k$. The parameter $\\rho \\in (0,1)$ dictates the size of this elite set, which is approximately $m = \\rho N$ samples.\n\nWe analyze the effects of the choice of $\\rho$:\n\n1.  **Selection Pressure and Convergence Speed**: The parameter $\\rho$ controls the selection threshold $\\gamma_k$. A smaller value of $\\rho$ corresponds to a higher quantile $1-\\rho$, which means $\\gamma_k$ will be larger. A higher threshold makes the elite set $\\{X_i : S(X_i) \\ge \\gamma_k\\}$ more \"elite\" — it consists of samples that are deeper within the tail of the distribution of $S(X)$, closer to the target rare-event region. The parameter update $\\theta_{k+1}$ is based solely on these elite samples. Therefore, a smaller $\\rho$ exerts a stronger \"pull\" on the sampling distribution $g_\\theta$, directing it more aggressively towards regions of high performance. This is termed higher **selection pressure**. Higher selection pressure generally leads to larger steps in the parameter space and thus **faster convergence** towards the optimal IS density. Conversely, a larger $\\rho$ leads to a lower threshold $\\gamma_k$, a less selective elite set, lower selection pressure, and slower convergence.\n\n2.  **Estimation Variance and Risk of Premature Convergence**: The choice of $\\rho$ introduces a critical trade-off between convergence speed and stability.\n    -   **Parameter Variance**: As stated in the problem, the update for $\\theta_{k+1}$ is an MLE based on an effective sample size of $m \\approx \\rho N$. A fundamental result in statistics is that the variance of an MLE is inversely proportional to the sample size. Thus, the variance of the estimator $\\hat{\\theta}_{k+1}$ scales with $1/m = 1/(\\rho N)$. A small $\\rho$ leads to a small elite set, which in turn causes high variance in the parameter update. These noisy, high-variance updates can cause the algorithm to be unstable, overshooting the optimal parameters or getting trapped in a suboptimal local maximum. This is known as **premature convergence**.\n    -   **Quantile Variance**: The threshold $\\gamma_k$ is itself a random variable, the empirical $(1-\\rho)$-quantile. The asymptotic variance of a sample $p$-quantile $\\hat{q}_p$ from a sample of size $N$ is given by $\\frac{p(1-p)}{N [f(q_p)]^2}$, where $f$ is the probability density function of the underlying random variable. In our context, this is the density of $S(X)$ under $g_{\\theta_k}$, let's call it $f_{S,k}$. The variance of $\\hat{\\gamma}_k$ is thus approximately $\\frac{\\rho(1-\\rho)}{N [f_{S,k}(\\gamma_k)]^2}$. When $\\rho$ is small, the quantile $1-\\rho$ is in the far tail. For most distributions, the density $f_{S,k}$ is smaller in the tails. If $f_{S,k}(\\gamma_k)$ is very small, the variance of the quantile estimate can become very large. This \"quantile noise\" adds another source of randomness and instability to the algorithm.\n\n**Guidelines for Choosing $\\rho$**:\nBased on this analysis, the choice of $\\rho$ must balance the desire for rapid convergence (small $\\rho$) against the need for stable estimation (large $\\rho$).\n-   A primary guideline is to ensure the elite sample size $m = \\rho N$ is large enough for a stable MLE. This typically means $\\rho N$ should be substantially larger than the number of parameters being estimated.\n-   To mitigate the high variance associated with small $\\rho$, smoothing of the parameter updates (e.g., exponential smoothing: $\\theta_{k+1}^{\\text{new}} = \\alpha \\theta_{k+1}^{\\text{MLE}} + (1-\\alpha)\\theta_k^{\\text{old}}$ for some $\\alpha \\in (0,1]$) is a common and effective technique.\n-   Adaptive schedules for $\\rho$ are often recommended. One might start with a larger $\\rho$ (e.g., $\\rho \\in [0.1, 0.5]$) to ensure stability and robust exploration in the early stages. As the iterator $\\theta_k$ approaches a good region, $\\rho$ can be gradually decreased to increase selection pressure and accelerate convergence to a refined solution.\n\nNow, we evaluate each statement.\n\n**A. Decreasing $\\rho$ (with fixed $N$) increases selection pressure because the elite set shrinks toward higher $S(x)$ values, typically accelerating movement toward the rare-event region. However, this also increases estimator variance, since parameter estimation is based on $m = \\rho N$ effective samples and quantile noise grows with smaller $\\rho$, thereby increasing the risk of premature convergence. A practical guideline is to ensure $\\rho N$ is comfortably larger than the number of free parameters of $g_\\theta$ and to use smoothing of parameter updates to counter high-variance steps.**\n\n-   **Analysis**: This statement perfectly captures the trade-off. Decreasing $\\rho$ shrinks the elite set to higher-performing samples (increased selection pressure, faster convergence). It correctly identifies that this increases the variance of the parameter estimator due to the smaller effective sample size $m = \\rho N$. It also correctly mentions the growth of quantile noise (as the density at the tail quantile is often smaller) and the ultimate risk of premature convergence. The proposed guidelines (ensuring $\\rho N$ is sufficiently large and using smoothing) are standard best practices for the CE method.\n-   **Verdict**: **Correct**.\n\n**B. Increasing $\\rho$ increases selection pressure and reduces the risk of premature convergence, so for rare events one should set $\\rho$ as large as possible (e.g., $\\rho \\approx 1$) to move quickly into the tail.**\n\n-   **Analysis**: This statement contains multiple errors. Increasing $\\rho$ *decreases* selection pressure by making the selection criterion less stringent. While it is true that increasing $\\rho$ reduces the risk of premature convergence by increasing the stability of the parameter estimates, the advice to set $\\rho$ as large as possible (e.g., $\\rho \\approx 1$) is counterproductive. A value of $\\rho$ close to $1$ would mean almost no selection, causing the algorithm to converge extremely slowly or not at all.\n-   **Verdict**: **Incorrect**.\n\n**C. For a multivariate Gaussian importance sampler $g_\\theta = \\mathcal{N}(\\mu, \\Sigma)$ in dimension $d$ with both mean and full covariance updated from elites, one must ensure $\\rho N \\ge d+1$ to avoid a singular covariance estimate, and preferably choose $\\rho N \\gg d$ to reduce variance in $\\widehat{\\Sigma}$. Regularization such as exponential smoothing and adding a positive diagonal floor to $\\widehat{\\Sigma}$ further mitigates degeneracy when $\\rho$ is small.**\n\n-   **Analysis**: This statement gives specific, correct advice for a common parametric family. The MLE for a covariance matrix from $m$ samples in $\\mathbb{R}^d$ requires $m > d$ (i.e., $m \\ge d+1$) for the resulting sample covariance matrix to be non-singular (positive definite). Therefore, the condition on the elite sample size, $\\rho N \\ge d+1$, is a necessary mathematical constraint. The recommendation to have $\\rho N \\gg d$ is a sound statistical principle to ensure a low-variance, reliable estimate. The mentioned regularization techniques (smoothing and adding a diagonal floor like $\\epsilon I$) are standard practice to prevent the covariance matrix from becoming singular or ill-conditioned, especially when the number of elite samples is small.\n-   **Verdict**: **Correct**.\n\n**D. The asymptotic variance of the empirical $(1-\\rho)$-quantile $\\hat{\\gamma}_k$ of $S(X)$ under $g_{\\theta_k}$ equals $\\rho/N$, independently of the distribution of $S(X)$, so choosing smaller $\\rho$ always reduces quantile noise.**\n\n-   **Analysis**: This statement is based on a false statistical premise. As derived earlier, the asymptotic variance of the empirical $(1-\\rho)$-quantile is approximately $\\frac{\\rho(1-\\rho)}{N [f_{S,k}(\\gamma_k)]^2}$. This formula explicitly depends on $f_{S,k}$, the probability density function of the performance scores, evaluated at the quantile $\\gamma_k$. The claim of independence from the distribution is false. The formula $\\rho/N$ is incorrect. Consequently, the conclusion that smaller $\\rho$ always reduces quantile noise is also unfounded and often false in practice, as the term $f_{S,k}(\\gamma_k)$ in the denominator can become very small for extreme quantiles.\n-   **Verdict**: **Incorrect**.\n\n**E. An adaptive schedule that starts with a larger $\\rho$ (e.g., $\\rho$ in $[0.2, 0.5]$) to maintain stability when the sampler is far from the rare-event region, and then decreases $\\rho$ as the distribution approaches the tail to increase selection pressure, is consistent with controlling both parameter-estimation variance (via $\\rho N$) and the difficulty of quantile estimation (via the local density of $S(X)$ at the moving threshold). This strikes a balance between convergence speed and robustness.**\n\n-   **Analysis**: This statement describes a sophisticated and widely recommended strategy for applying the CE method. Starting with a larger $\\rho$ prioritizes stability and exploration. As the algorithm progresses and the sampling distribution improves, decreasing $\\rho$ increases selection pressure for faster final convergence. This adaptive approach is a direct implementation of the trade-off we analyzed, aiming to achieve both robustness in the initial exploratory phase and speed in the final exploitation phase. The reasoning provided is sound.\n-   **Verdict**: **Correct**.", "answer": "$$\\boxed{ACE}$$", "id": "3351702"}, {"introduction": "Many real-world problems feature complex, multimodal landscapes that a single Gaussian distribution cannot effectively model. This advanced practice extends our sampling toolkit to Gaussian Mixture Models (GMMs), a far more flexible and powerful parametric family. You will derive the update rules for a GMM within the CE framework by applying the Expectation-Maximization (EM) algorithm to the elite sample set, gaining proficiency in a technique essential for tackling sophisticated rare-event and optimization challenges [@problem_id:3351674].", "problem": "Consider the Cross-Entropy Method (CEM) for rare-event simulation and continuous optimization, where one iteratively updates a parametric sampling distribution to concentrate mass on high-performing regions. Let the sampling family at iteration $t$ be a $K$-component Gaussian mixture with parameters $\\Theta^{(t)}=\\{\\pi_{k}^{(t)},\\mu_{k}^{(t)},\\Sigma_{k}^{(t)}\\}_{k=1}^{K}$ and density \n$$\nq_{\\Theta^{(t)}}(x)=\\sum_{k=1}^{K}\\pi_{k}^{(t)}\\,\\mathcal{N}\\!\\left(x\\mid \\mu_{k}^{(t)},\\Sigma_{k}^{(t)}\\right),\n$$\nwhere $\\sum_{k=1}^{K}\\pi_{k}^{(t)}=1$, $\\pi_{k}^{(t)}\\geq 0$ for all $k$, and each $\\Sigma_{k}^{(t)}$ is symmetric positive definite. Draw $n$ independent samples $\\{X_{i}\\}_{i=1}^{n}$ from $q_{\\Theta^{(t)}}$, evaluate a performance score $S(X_{i})$, and construct the elite set $\\mathcal{E}_{t}\\subset\\{1,\\dots,n\\}$ of cardinality $|\\mathcal{E}_{t}|=m$ by selecting the $m$ indices with the largest scores (equivalently, all $i$ such that $S(X_{i})\\geq \\gamma_{t}$ for an adaptive threshold $\\gamma_{t}$ defining the top $\\rho$ fraction, with $\\rho\\in(0,1)$ and $m=\\lfloor \\rho n\\rfloor$). Define uniform elite weights $w_{i}=m^{-1}$ if $i\\in \\mathcal{E}_{t}$ and $w_{i}=0$ otherwise. The next iteration parameters $\\Theta^{(t+1)}$ are obtained by maximizing the elite-weighted log-likelihood \n$$\n\\mathcal{L}(\\Theta)=\\sum_{i=1}^{n}w_{i}\\,\\ln\\!\\Bigg(\\sum_{k=1}^{K}\\pi_{k}\\,\\mathcal{N}\\!\\left(X_{i}\\mid \\mu_{k},\\Sigma_{k}\\right)\\Bigg)\n$$\nover the mixture parameters $\\{\\pi_{k},\\mu_{k},\\Sigma_{k}\\}_{k=1}^{K}$, subject to $\\sum_{k=1}^{K}\\pi_{k}=1$, $\\pi_{k}\\geq 0$, and positive definiteness of $\\Sigma_{k}$.\n\nStarting from the standard latent-variable representation for mixture models and the Expectation-Maximization (EM) algorithm (Expectation-Maximization (EM)), derive the elite-weighted responsibilities for $i\\in\\mathcal{E}_{t}$ and the corresponding maximizers (M-step updates) for the mixture weights, component means, and component covariances. Express each requested quantity explicitly as an analytic expression in terms of $\\{X_{i}\\}_{i\\in\\mathcal{E}_{t}}$, $\\{\\pi_{k}^{(t)},\\mu_{k}^{(t)},\\Sigma_{k}^{(t)}\\}_{k=1}^{K}$, and $K$, without introducing any approximations beyond the elite weighting defined above.\n\nYour final answer must consist of the four expressions, ordered as:\n$($i$)$ the responsibilities for $i\\in\\mathcal{E}_{t}$,\n$($ii$)$ the updated mixture weights,\n$($iii$)$ the updated component means, and\n$($iv$)$ the updated component covariances,\nwritten together as a single row matrix. No numerical evaluation is required.", "solution": "The user wants to find the M-step update rules for the parameters of a Gaussian Mixture Model (GMM) within the context of the Cross-Entropy Method (CEM). The updates are derived by maximizing a weighted log-likelihood function using the Expectation-Maximization (EM) algorithm.\n\nFirst, the problem is validated and found to be valid. It is a well-posed problem in the field of computational statistics and machine learning, grounded in established mathematical principles. All necessary information is provided, and the definitions are consistent.\n\nThe objective is to find the parameters $\\Theta = \\{\\pi_{k}, \\mu_{k}, \\Sigma_{k}\\}_{k=1}^{K}$ that maximize the elite-weighted log-likelihood function:\n$$\n\\mathcal{L}(\\Theta)=\\sum_{i=1}^{n}w_{i}\\,\\ln\\!\\Bigg(\\sum_{k=1}^{K}\\pi_{k}\\,\\mathcal{N}\\!\\left(X_{i}\\mid \\mu_{k},\\Sigma_{k}\\right)\\Bigg)\n$$\nThe weights are defined as $w_{i}=m^{-1}$ for indices $i$ in the elite set $\\mathcal{E}_{t}$ (where $m = |\\mathcal{E}_t|$), and $w_{i}=0$ otherwise. The summation can thus be restricted to the elite set:\n$$\n\\mathcal{L}(\\Theta)=\\frac{1}{m}\\sum_{i\\in\\mathcal{E}_{t}}\\ln\\!\\Bigg(\\sum_{k=1}^{K}\\pi_{k}\\,\\mathcal{N}\\!\\left(X_{i}\\mid \\mu_{k},\\Sigma_{k}\\right)\\Bigg)\n$$\nMaximizing $\\mathcal{L}(\\Theta)$ is equivalent to maximizing the sum without the constant factor $1/m$. Let the objective function for the EM algorithm be the log-likelihood of the elite data:\n$$\n\\mathcal{L}_{\\mathcal{E}}(\\Theta) = \\sum_{i\\in\\mathcal{E}_{t}}\\ln\\!\\Bigg(\\sum_{k=1}^{K}\\pi_{k}\\,\\mathcal{N}\\!\\left(X_{i}\\mid \\mu_{k},\\Sigma_{k}\\right)\\Bigg)\n$$\nWe use the EM algorithm to maximize this function. The algorithm introduces latent variables $Z_{i}$, where $Z_i=k$ indicates that sample $X_i$ was generated by the $k$-th component of the mixture.\n\n**E-Step (Expectation-Step)**\n\nIn the E-step, we compute the expectation of the complete-data log-likelihood, conditioned on the observed data $\\{X_i\\}_{i\\in\\mathcal{E}_t}$ and the current parameter estimates $\\Theta^{(t)} = \\{\\pi_{k}^{(t)}, \\mu_{k}^{(t)}, \\Sigma_{k}^{(t)}\\}_{k=1}^{K}$. This expectation is the Q-function, $Q(\\Theta|\\Theta^{(t)})$.\n\nThe central quantity to compute is the posterior probability that sample $X_i$ belongs to component $k$, which is known as the responsibility, and we denote it by $\\gamma_{ik}$. This quantity represents $P(Z_i=k \\mid X_i, \\Theta^{(t)})$. For any sample $X_i$ with $i \\in \\mathcal{E}_t$, using Bayes' theorem:\n$$\n\\gamma_{ik} = \\frac{P(X_i \\mid Z_i=k, \\Theta^{(t)}) P(Z_i=k \\mid \\Theta^{(t)})}{P(X_i \\mid \\Theta^{(t)})} = \\frac{\\pi_{k}^{(t)}\\,\\mathcal{N}\\!\\left(X_{i}\\mid \\mu_{k}^{(t)},\\Sigma_{k}^{(t)}\\right)}{\\sum_{j=1}^{K}\\pi_{j}^{(t)}\\,\\mathcal{N}\\!\\left(X_{i}\\mid \\mu_{j}^{(t)},\\Sigma_{j}^{(t)}\\right)}\n$$\nThis expression is the answer to part (i), the \"elite-weighted responsibilities\". The term \"elite-weighted\" here signifies that these responsibilities are calculated for the samples in the elite set, over which the likelihood is defined.\n\nThe Q-function to be maximized in the M-step is:\n$$\nQ(\\Theta|\\Theta^{(t)}) = \\sum_{i\\in\\mathcal{E}_{t}}\\sum_{k=1}^{K} \\gamma_{ik} \\ln\\left( \\pi_k \\mathcal{N}(X_i | \\mu_k, \\Sigma_k) \\right)\n$$\n$$\nQ(\\Theta|\\Theta^{(t)}) = \\sum_{i\\in\\mathcal{E}_{t}}\\sum_{k=1}^{K} \\gamma_{ik} \\ln(\\pi_k) + \\sum_{i\\in\\mathcal{E}_{t}}\\sum_{k=1}^{K} \\gamma_{ik} \\ln(\\mathcal{N}(X_i | \\mu_k, \\Sigma_k))\n$$\n\n**M-Step (Maximization-Step)**\n\nIn the M-step, we find the parameters $\\Theta^{(t+1)}$ that maximize $Q(\\Theta|\\Theta^{(t)})$ with respect to $\\Theta = \\{\\pi_k, \\mu_k, \\Sigma_k\\}$.\n\n**1. Update for Mixture Weights ($\\pi_k$)**\n\nWe maximize $\\sum_{i\\in\\mathcal{E}_{t}}\\sum_{k=1}^{K} \\gamma_{ik} \\ln(\\pi_k)$ subject to the constraint $\\sum_{k=1}^{K} \\pi_k = 1$. Using a Lagrange multiplier $\\lambda$, we have:\n$$\n\\Lambda = \\sum_{i\\in\\mathcal{E}_{t}}\\sum_{k=1}^{K} \\gamma_{ik} \\ln(\\pi_k) + \\lambda\\left(\\sum_{k=1}^{K}\\pi_k - 1\\right)\n$$\nTaking the derivative with respect to $\\pi_k$ and setting it to zero yields:\n$$\n\\frac{\\partial \\Lambda}{\\partial \\pi_k} = \\frac{1}{\\pi_k}\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} + \\lambda = 0 \\implies \\pi_k = -\\frac{1}{\\lambda} \\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik}\n$$\nSumming over $k$ and using the constraint $\\sum_k \\pi_k=1$:\n$$\n1 = -\\frac{1}{\\lambda} \\sum_{k=1}^{K}\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} = -\\frac{1}{\\lambda} \\sum_{i\\in\\mathcal{E}_{t}}\\sum_{k=1}^{K} \\gamma_{ik}\n$$\nSince $\\sum_{k=1}^K \\gamma_{ik} = 1$ for each $i$, the sum becomes $\\sum_{i\\in\\mathcal{E}_{t}} 1 = m$. Thus, $1 = -m/\\lambda$, which implies $\\lambda = -m$.\nSubstituting $\\lambda$ back, we get the updated mixture weights:\n$$\n\\pi_{k}^{(t+1)} = \\frac{1}{m}\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik}\n$$\nThis is the expression for part (ii).\n\n**2. Update for Component Means ($\\mu_k$)**\n\nWe maximize the part of the Q-function that depends on $\\mu_k$:\n$$\n\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} \\ln(\\mathcal{N}(X_i | \\mu_k, \\Sigma_k)) = \\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} \\left(-\\frac{d}{2}\\ln(2\\pi) - \\frac{1}{2}\\ln|\\Sigma_k| - \\frac{1}{2}(X_i-\\mu_k)^T\\Sigma_k^{-1}(X_i-\\mu_k)\\right)\n$$\nTo maximize this with respect to $\\mu_k$, we only need to minimize $\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} (X_i-\\mu_k)^T\\Sigma_k^{-1}(X_i-\\mu_k)$. Taking the derivative with respect to $\\mu_k$ and setting to zero:\n$$\n\\frac{\\partial}{\\partial \\mu_k} \\left( \\dots \\right) = \\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} (2\\Sigma_k^{-1}(X_i - \\mu_k)) = 0\n$$\n$$\n\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} (X_i - \\mu_k) = 0 \\implies \\left(\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik}\\right)\\mu_k = \\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} X_i\n$$\nThe update for the mean of component $k$ is:\n$$\n\\mu_{k}^{(t+1)} = \\frac{\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} X_i}{\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik}}\n$$\nThis is the expression for part (iii).\n\n**3. Update for Component Covariances ($\\Sigma_k$)**\n\nWe maximize the Q-function with respect to $\\Sigma_k$, using the new mean $\\mu_{k}^{(t+1)}$:\n$$\n\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} \\left(-\\frac{1}{2}\\ln|\\Sigma_k| - \\frac{1}{2}(X_i-\\mu_k^{(t+1)})^T\\Sigma_k^{-1}(X_i-\\mu_k^{(t+1)})\\right)\n$$\nLet $N_k = \\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik}$. The expression to maximize is:\n$$\n-\\frac{N_k}{2}\\ln|\\Sigma_k| - \\frac{1}{2} \\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} (X_i-\\mu_k^{(t+1)})^T\\Sigma_k^{-1}(X_i-\\mu_k^{(t+1)})\n$$\nThe solution to this standard maximization problem is the weighted sample covariance matrix:\n$$\n\\Sigma_{k}^{(t+1)} = \\frac{1}{N_k} \\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} (X_i - \\mu_{k}^{(t+1)})(X_i - \\mu_{k}^{(t+1)})^T\n$$\nSubstituting $N_k$ back:\n$$\n\\Sigma_{k}^{(t+1)} = \\frac{\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} (X_i - \\mu_{k}^{(t+1)})(X_i - \\mu_{k}^{(t+1)})^T}{\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik}}\n$$\nThis is the expression for part (iv). The four requested expressions are collected in the final answer. Note that $\\mu_k^{(t+1)}$ in the fourth expression refers to the result from the third expression.", "answer": "$$\n\\boxed{\n\\pmatrix{\n\\frac{\\pi_{k}^{(t)}\\,\\mathcal{N}\\!\\left(X_{i}\\mid \\mu_{k}^{(t)},\\Sigma_{k}^{(t)}\\right)}{\\sum_{j=1}^{K}\\pi_{j}^{(t)}\\,\\mathcal{N}\\!\\left(X_{i}\\mid \\mu_{j}^{(t)},\\Sigma_{j}^{(t)}\\right)}\n& \\frac{1}{m}\\sum_{i\\in\\mathcal{E}_{t}} \\frac{\\pi_{k}^{(t)}\\,\\mathcal{N}\\!\\left(X_{i}\\mid \\mu_{k}^{(t)},\\Sigma_{k}^{(t)}\\right)}{\\sum_{j=1}^{K}\\pi_{j}^{(t)}\\,\\mathcal{N}\\!\\left(X_{i}\\mid \\mu_{j}^{(t)},\\Sigma_{j}^{(t)}\\right)}\n& \\frac{\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} X_i}{\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik}}\n& \\frac{\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik} \\left(X_i - \\mu_{k}^{(t+1)}\\right)\\left(X_i - \\mu_{k}^{(t+1)}\\right)^T}{\\sum_{i\\in\\mathcal{E}_{t}} \\gamma_{ik}}\n}\n}\n$$\nwhere $\\gamma_{ik}$ in the third and fourth elements denotes the responsibility expression given as the first element, and $\\mu_{k}^{(t+1)}$ in the fourth element denotes the updated mean expression given as the third element.", "id": "3351674"}]}