{"hands_on_practices": [{"introduction": "The primary motivation for using Locally One-Dimensional (LOD) methods is their exceptional computational efficiency. This practice moves beyond qualitative statements by guiding you through a detailed floating-point operation (flop) analysis to quantify this advantage [@problem_id:3417697]. By comparing the cost of a naive implementation to one that leverages pre-computation, you will derive the significant speedup factor that makes LOD schemes so powerful for problems with constant coefficients.", "problem": "Consider the two-dimensional heat equation with constant diffusivity on a square domain, discretized on a uniform grid with $n$ interior points in each spatial direction and advanced in time using a Locally One-Dimensional (LOD) splitting method. Denote by $A_{x}$ and $A_{y}$ the one-dimensional second-difference matrices in the $x$- and $y$-directions, respectively, arising from standard central differencing with Dirichlet boundary conditions. In one implicit LOD sweep at each time step, you solve $n$ independent tridiagonal systems of length $n$ in the $x$-direction with coefficient matrix $(I - \\theta \\Delta t A_{x})$, and $n$ independent tridiagonal systems of length $n$ in the $y$-direction with coefficient matrix $(I - \\theta \\Delta t A_{y})$, where $I$ is the identity matrix, $\\theta \\in (0,1]$ is a fixed method parameter, and $\\Delta t$ is the time-step size. Assume there are $m$ time steps.\n\nUse the following foundations:\n- The LOD splitting method reduces the multidimensional implicit step to a sequence of one-dimensional implicit solves along grid lines, and for constant coefficients on a uniform grid, the tridiagonal coefficient matrices along all lines in a given direction are identical at every time step.\n- A floating-point operation (flop) is one addition, subtraction, multiplication, or division, each counted as $1$.\n- The Thomas algorithm (tridiagonal LU decomposition followed by forward and backward substitution) is used for solving tridiagonal systems, and you must derive the flop counts of its factorization and solve phases from first principles.\n\nTasks:\n1. Derive the flop count to factorize a single $n \\times n$ tridiagonal matrix via the Thomas algorithm into lower and upper bidiagonal factors, and the flop count to solve for one right-hand side using those precomputed factors.\n2. Using these counts, derive the total flop cost over $m$ time steps for:\n   - The case where LU factorizations of $(I - \\theta \\Delta t A_{\\alpha})$ (with $\\alpha \\in \\{x,y\\}$) are precomputed once per direction and reused for all lines and all time steps (constant-coefficient case).\n   - The case where LU factorizations are recomputed for every line solve at every time step (no reuse).\n3. Define the speedup factor $S(n,m)$ as the ratio of the total flop count in the no-reuse case to the total flop count in the precompute-and-reuse case. Provide $S(n,m)$ in closed form.\n4. Briefly explain, within your derivation, what changes when the coefficients are spatially variable so that line matrices differ across lines and/or time steps.\n\nYour final answer must be the closed-form analytical expression for $S(n,m)$. No numerical rounding is required, and no physical units are needed.", "solution": "The problem statement is evaluated as valid. It is scientifically grounded in the fields of numerical linear algebra and the numerical solution of partial differential equations. The premises are accurate, and its components—the Locally One-Dimensional (LOD) method, the Thomas algorithm, and the definition of a floating-point operation (flop)—are well-defined and standard. The problem is self-contained, objective, and well-posed, admitting a unique analytical solution based on the provided information.\n\nWe proceed with the derivation.\n\n### Task 1: Flop Count for the Thomas Algorithm\n\nThe Thomas algorithm solves an $n \\times n$ tridiagonal linear system $T\\mathbf{u}=\\mathbf{d}$. The process consists of two stages: a factorization of the matrix $T$ (equivalent to forward elimination) and a solve (forward and backward substitution) using the computed factors. We will derive the flop count for each stage based on the Crout factorization $T=LU$, where $L$ is a lower bidiagonal matrix and $U$ is a unit upper bidiagonal matrix.\n\nLet the tridiagonal matrix $T$ have lower diagonal elements $a_i$ ($i=2, \\dots, n$), main diagonal elements $b_i$ ($i=1, \\dots, n$), and upper diagonal elements $c_i$ ($i=1, \\dots, n-1$). The factorization $T = LU$ yields:\n$$\nL = \\begin{pmatrix}\n\\alpha_1 & & & \\\\\na_2 & \\alpha_2 & & \\\\\n& \\ddots & \\ddots & \\\\\n& & a_n & \\alpha_n\n\\end{pmatrix}, \\quad\nU = \\begin{pmatrix}\n1 & \\beta_1 & & \\\\\n& 1 & \\beta_2 & \\\\\n& & \\ddots & \\ddots \\\\\n& & & 1\n\\end{pmatrix}\n$$\nEquating the entries of $T$ with those of $LU$ provides the recurrence relations for the elements of the factors, $\\alpha_i$ and $\\beta_i$:\n- $\\alpha_1 = b_1$\n- $\\alpha_i \\beta_i = c_i \\implies \\beta_i = c_i / \\alpha_i$ for $i=1, \\dots, n-1$.\n- $a_i \\beta_{i-1} + \\alpha_i = b_i \\implies \\alpha_i = b_i - a_i \\beta_{i-1}$ for $i=2, \\dots, n$.\n\n**1. A. Factorization Cost ($C_{fact}(n)$):**\nThis phase computes the $n$ values of $\\alpha_i$ and $n-1$ values of $\\beta_i$.\n- For $i=1$:\n  - $\\alpha_1 = b_1$ (0 flops)\n  - $\\beta_1 = c_1 / \\alpha_1$ (1 division)\n- For $i=2, \\dots, n-1$:\n  - $\\alpha_i = b_i - a_i \\beta_{i-1}$ (1 multiplication, 1 subtraction = $2$ flops)\n  - $\\beta_i = c_i / \\alpha_i$ (1 division)\n  This loop runs for $n-2$ iterations, costing $3$ flops each. Total: $3(n-2)$ flops.\n- For $i=n$:\n  - $\\alpha_n = b_n - a_n \\beta_{n-1}$ (1 multiplication, 1 subtraction = $2$ flops)\n\nThe total factorization cost is the sum of these:\n$C_{fact}(n) = 1 + 3(n-2) + 2 = 1 + 3n - 6 + 2 = 3n - 3$.\nSo, the cost to factor a single $n \\times n$ tridiagonal matrix is $C_{fact}(n) = 3(n-1)$ flops.\n\n**1. B. Solve Cost ($C_{solve}(n)$):**\nThis phase solves $T\\mathbf{u}=LU\\mathbf{u}=\\mathbf{d}$ for a given right-hand side $\\mathbf{d}$ using the precomputed factors $L$ and $U$. It is a two-step process:\n1.  Solve $L\\mathbf{y} = \\mathbf{d}$ (Forward substitution):\n    - $y_1 = d_1 / \\alpha_1$ (1 division)\n    - For $i=2, \\dots, n$: $a_i y_{i-1} + \\alpha_i y_i = d_i \\implies y_i = (d_i - a_i y_{i-1}) / \\alpha_i$. This costs $1$ multiplication, $1$ subtraction, and $1$ division, for a total of $3$ flops per iteration. The loop runs for $n-1$ iterations.\n    Cost of forward substitution: $1 + 3(n-1) = 3n-2$ flops.\n\n2.  Solve $U\\mathbf{u} = \\mathbf{y}$ (Backward substitution):\n    - $u_n = y_n$ (0 flops, since the last equation is $1 \\cdot u_n = y_n$)\n    - For $i=n-1, \\dots, 1$: $u_i + \\beta_i u_{i+1} = y_i \\implies u_i = y_i - \\beta_i u_{i+1}$. This costs $1$ multiplication and $1$ subtraction, for a total of $2$ flops per iteration. The loop runs for $n-1$ iterations.\n    Cost of backward substitution: $2(n-1)$ flops.\n\nThe total cost to solve a system with precomputed factors is:\n$C_{solve}(n) = (3n-2) + 2(n-1) = 3n-2 + 2n-2 = 5n-4$.\n\nIn summary:\n- Factorization cost: $C_{fact}(n) = 3n-3$\n- Solve cost (with factors): $C_{solve}(n) = 5n-4$\n\n### Task 2: Total Flop Cost for the LOD Method\n\nThe LOD method involves two sweeps per time step: one in the $x$-direction and one in the $y$-direction. Each sweep requires solving $n$ independent tridiagonal systems of size $n \\times n$. The simulation runs for $m$ time steps.\n\n**Case A: Precompute-and-Reuse**\nIn this case, the coefficient matrices $(I - \\theta \\Delta t A_{x})$ and $(I - \\theta \\Delta t A_{y})$ are constant for all grid lines and for all time steps. This allows for maximum reuse of the LU factorizations. We only need to factor two matrices for the entire simulation: one for the x-direction and one for the y-direction.\n\n- **Total Factorization Cost:**\n  $C_{fact, \\text{total}} = 2 \\times C_{fact}(n) = 2(3n-3) = 6n-6$.\n\n- **Total Solve Cost:**\n  At each time step, we solve $n$ systems in the x-direction and $n$ systems in the y-direction, for a total of $2n$ systems. This is repeated for $m$ time steps.\n  $C_{solve, \\text{total}} = m \\times (2n) \\times C_{solve}(n) = 2mn(5n-4)$.\n\n- **Total Cost (Reuse):**\n  $C_{\\text{reuse}} = C_{fact, \\text{total}} + C_{solve, \\text{total}} = (6n-6) + 2mn(5n-4)$.\n\n**Case B: No Reuse**\nIn this case, the LU factorization is recomputed for every single system solve. This corresponds to solving each system \"from scratch\".\n\n- **Cost per System (from Scratch):**\n  $C_{\\text{scratch}}(n) = C_{fact}(n) + C_{solve}(n) = (3n-3) + (5n-4) = 8n-7$.\n\n- **Total Cost (No Reuse):**\n  The total number of systems to solve over the entire simulation is $m \\times 2n = 2mn$.\n  $C_{\\text{no-reuse}} = (2mn) \\times C_{\\text{scratch}}(n) = 2mn(8n-7)$.\n\n### Task 4: Impact of Variable Coefficients\n\nThe \"no reuse\" case is not merely a theoretical construct. It models important physical scenarios. If the PDE coefficients, such as the thermal diffusivity, are spatially variable (i.e., depend on $x$ and $y$), the matrices $A_x$ and $A_y$ become dependent on the grid line. For example, the matrix $(I - \\theta \\Delta t A_x)$ for the grid line at $y_j$ would be different from the one at $y_k$ for $j \\neq k$. In this scenario, one must compute $n$ different factorizations for the x-sweep and $n$ for the y-sweep. If the coefficients are also time-dependent, these $2n$ factorizations must be recomputed at each of the $m$ time steps. This latter case of spatially and temporally variable coefficients corresponds exactly to the cost model $C_{\\text{no-reuse}}$, as factorization cannot be reused across lines or time steps.\n\n### Task 3: Speedup Factor $S(n,m)$\n\nThe speedup factor $S(n,m)$ is the ratio of the total flop count in the no-reuse case to the total flop count in the precompute-and-reuse case.\n\n$$S(n,m) = \\frac{C_{\\text{no-reuse}}}{C_{\\text{reuse}}}$$\nSubstituting the derived expressions:\n$$S(n,m) = \\frac{2mn(8n-7)}{(6n-6) + 2mn(5n-4)}$$\nWe can simplify this expression by dividing the numerator and the denominator by $2$:\n$$S(n,m) = \\frac{mn(8n-7)}{3(n-1) + mn(5n-4)}$$\nThis is the final closed-form expression for the speedup factor.", "answer": "$$\n\\boxed{\\frac{mn(8n-7)}{3(n-1) + mn(5n-4)}}\n$$", "id": "3417697"}, {"introduction": "Operator splitting provides a powerful framework for tackling complex multiphysics problems, such as reaction-diffusion equations. This exercise explores the crucial stability properties of an LOD scheme where implicit diffusion steps are combined with an implicit solve for a nonlinear reaction term [@problem_id:3417655]. You will demonstrate that while the diffusion substeps are unconditionally stable, the stiffness of the reaction term can reintroduce a time-step constraint, a critical insight for the practical application of splitting methods.", "problem": "Consider the two-dimensional reaction–diffusion equation on the unit square with homogeneous Dirichlet boundary conditions,\n$$\nu_{t} \\;=\\; u_{xx} \\,+\\, u_{yy} \\,+\\, R(u), \\quad (x,y)\\in(0,1)^{2}, \\quad t>0,\n$$\nwith an initial condition $u(x,y,0)=u_{0}(x,y)\\ge 0$. Assume $R:\\mathbb{R}\\to\\mathbb{R}$ is nonnegative and nondecreasing, with $R(u)\\ge 0$ for all $u\\in\\mathbb{R}$, and globally Lipschitz on $[0,\\infty)$ with Lipschitz constant $L>0$ so that $|R(u)-R(v)|\\le L\\,|u-v|$ for all $u,v\\ge 0$.\n\nDiscretize $(0,1)^{2}$ by a uniform Cartesian grid with spacing $h$ in both directions and second-order central differences for $u_{xx}$ and $u_{yy}$. Let $A_{x}$ and $A_{y}$ denote the one-dimensional discrete Laplacian operators along the $x$- and $y$-directions, acting on the grid function over interior points with homogeneous Dirichlet boundary values incorporated into the right-hand side. Consider a Locally One-Dimensional (LOD) Lie splitting over a single time step of size $\\Delta t>0$, consisting of the three substeps\n$$\n\\text{(x-diffusion)}\\quad (I \\,-\\, \\Delta t\\,A_{x})\\,u^{(1)} \\;=\\; u^{n},\n$$\n$$\n\\text{(y-diffusion)}\\quad (I \\,-\\, \\Delta t\\,A_{y})\\,u^{(2)} \\;=\\; u^{(1)},\n$$\n$$\n\\text{(reaction)}\\quad u^{n+1} \\,-\\, \\Delta t\\,R\\!\\left(u^{n+1}\\right) \\;=\\; u^{(2)},\n$$\nwhere each equation is solved over the interior grid points, and the reaction substep is solved pointwise.\n\nStarting from the definitions and properties of the discrete diffusion operators and nonnegative, nondecreasing reaction terms, derive conditions under which the full LOD scheme preserves positivity and is stable in the $L^{1}$ norm in the sense that the diffusion substeps are $L^{1}$-contractive and the reaction substep has a finite $L^{1}$ amplification factor. Determine the largest allowable time step $\\Delta t_{\\max}$, expressed in terms of the global Lipschitz constant $L$, that guarantees uniqueness and monotonicity of the implicit reaction substep and thus well-posedness and $L^{1}$ stability of the overall LOD step. Provide your final answer as a single closed-form analytic expression for $\\Delta t_{\\max}$.", "solution": "The problem statement is analyzed to be scientifically grounded, well-posed, objective, and self-contained. It represents a standard problem in the numerical analysis of partial differential equations. The solution proceeds as follows.\n\nLet the computational domain be a grid of points $(x_i, y_j) = (ih, jh)$ for $i, j \\in \\{1, \\dots, N-1\\}$, where $h$ is the grid spacing in both directions. Let $u^n_{ij}$ denote the numerical approximation of $u(x_i, y_j, t_n)$. The discrete $L^1$ norm of a grid function $v$ is given by $\\|v\\|_1 = \\sum_{i,j} |v_{ij}|h^2$.\n\nThe Locally One-Dimensional (LOD) scheme consists of three substeps to advance from time $t_n$ to $t_{n+1} = t_n + \\Delta t$. We analyze each substep for positivity preservation and $L^1$ stability, assuming the initial data $u^n$ is non-negative, i.e., $u^n_{ij} \\ge 0$ for all $i,j$.\n\n### Substep 1: x-diffusion\n\nThe first substep is given by $(I - \\Delta t A_x) u^{(1)} = u^n$. This is a system of linear equations to be solved for the intermediate solution $u^{(1)}$. The operator $A_x$ represents the standard second-order central difference approximation to the second partial derivative with respect to $x$:\n$$(A_x v)_{ij} = \\frac{v_{i+1,j} - 2v_{ij} + v_{i-1,j}}{h^2}$$\nFor each fixed row index $j$, this equation forms a linear system for the vector of unknowns $(u^{(1)}_{1j}, \\dots, u^{(1)}_{N-1,j})$. The matrix form of this system is $M_x \\mathbf{u}^{(1)}_j = \\mathbf{u}^n_j$, where $\\mathbf{u}_j$ is a vector representing the grid function values along row $j$, and the matrix $M_x = I - \\Delta t \\mathbf{A}_x$. Here, $\\mathbf{A}_x$ is the $(N-1) \\times (N-1)$ matrix representing the operator $A_x$ on a single row with homogeneous Dirichlet boundary conditions ($u_{0j} = u_{Nj} = 0$). The matrix $M_x$ is a symmetric tridiagonal matrix with diagonal entries $1 + 2\\Delta t/h^2$ and off-diagonal entries $-\\Delta t/h^2$.\n\n**Positivity Preservation:** The matrix $M_x$ has positive diagonal entries and non-positive off-diagonal entries. It is also strictly diagonally dominant since $|1 + 2\\Delta t/h^2| > |-\\Delta t/h^2| + |-\\Delta t/h^2|$ (for interior rows) and $|1 + 2\\Delta t/h^2| > |-\\Delta t/h^2|$ (for boundary rows), as this simplifies to $1 > 0$. A strictly diagonally dominant matrix with non-positive off-diagonals is an M-matrix. A key property of an M-matrix is that its inverse, $M_x^{-1}$, has all non-negative entries.\nSince $u^{(1)} = (I - \\Delta t A_x)^{-1} u^n$, and assuming $u^n_{ij} \\ge 0$ for all $i,j$, it follows that $u^{(1)}_{ij} \\ge 0$. Thus, this substep is unconditionally positivity-preserving for any $\\Delta t > 0$.\n\n**$L^1$-contractivity:** We need to show that $\\|u^{(1)}\\|_1 \\le \\|u^n\\|_1$.\nLet $S_x = (I - \\Delta t A_x)^{-1}$ be the solution operator for this substep. We have shown $S_x$ is a non-negative matrix (element-wise). Let's analyze the column sums of its matrix representation on a row, $M_x^{-1}$. Let $\\mathbf{1}$ be the vector of all ones. The sum of the entries in the $k$-th column of $M_x^{-1}$ is given by $\\mathbf{1}^T M_x^{-1} \\mathbf{e}_k$.\nAlternatively, consider the sum of the elements in a row of the solution vector $w_i = u^{(1)}_{ij}$ for a fixed $j$. Summing the equation $(w - \\Delta t A_x w)_{i} = v_i$ (where $v_i = u^n_{ij}$) over $i = 1, \\dots, N-1$:\n$$ \\sum_{i=1}^{N-1} w_i - \\Delta t \\sum_{i=1}^{N-1} (A_x w)_i = \\sum_{i=1}^{N-1} v_i $$\nThe sum of the discrete Laplacian terms, incorporating $w_0=w_N=0$, is:\n$$ \\sum_{i=1}^{N-1} (A_x w)_i = \\frac{1}{h^2} \\sum_{i=1}^{N-1} (w_{i+1} - 2w_i + w_{i-1}) = \\frac{1}{h^2} (-w_1 - w_{N-1}) $$\nSince $v_i = u^n_{ij} \\ge 0$, we have $w_i = u^{(1)}_{ij} \\ge 0$. Therefore, $-w_1-w_{N-1} \\le 0$, which implies $\\sum_i (A_x w)_i \\le 0$.\nSo, $\\sum_i w_i = \\sum_i v_i + \\Delta t \\sum_i (A_x w)_i \\le \\sum_i v_i$.\nAs this holds for each row $j$, we can sum over $j$: $\\sum_j \\sum_i u^{(1)}_{ij} \\le \\sum_j \\sum_i u^n_{ij}$.\nSince $u^n$ and $u^{(1)}$ are non-negative, this is equivalent to $\\sum_{i,j} |u^{(1)}_{ij}| \\le \\sum_{i,j} |u^n_{ij}|$, which implies $\\|u^{(1)}\\|_1 \\le \\|u^n\\|_1$.\nThis substep is unconditionally $L^1$-contractive for non-negative data. A more general proof for any data also shows this unconditionally.\n\n### Substep 2: y-diffusion\n\nThe second substep is $(I - \\Delta t A_y) u^{(2)} = u^{(1)}$. The analysis is identical to the first substep, with the roles of indices $i$ and $j$ interchanged. The operator $A_y$ acts on columns. The step is unconditionally positivity-preserving and $L^1$-contractive. Therefore, if $u^n \\ge 0$, we have $u^{(2)} \\ge 0$ and $\\|u^{(2)}\\|_1 \\le \\|u^{(1)}\\|_1 \\le \\|u^n\\|_1$.\n\n### Substep 3: Reaction\n\nThe third substep is the pointwise nonlinear equation for $u^{n+1}$:\n$$ u^{n+1}_{ij} - \\Delta t R(u^{n+1}_{ij}) = u^{(2)}_{ij} $$\nLet $w = u^{n+1}_{ij}$ and $v = u^{(2)}_{ij}$. We need to solve $f(w) = w - \\Delta t R(w) = v$. From the previous steps, we know $v \\ge 0$.\n\n**Positivity Preservation:** We must show that $w \\ge 0$. Assume for contradiction that $w < 0$. The problem states that $R(u) \\ge 0$ for all $u \\in \\mathbb{R}$. Therefore, if $w < 0$, then $R(w) \\ge 0$. It follows that $f(w) = w - \\Delta t R(w) < 0$. However, we are solving $f(w) = v$, and we know $v \\ge 0$. This is a contradiction. Thus, $w$ must be non-negative. This step is unconditionally positivity-preserving.\n\n**Well-posedness (Uniqueness and Monotonicity):** For a unique solution $w$ to exist for any given $v$, the function $f(w)$ must be a bijection. A sufficient condition is that $f(w)$ is strictly increasing. We analyze its derivative (or slope). Since we have established $w \\ge 0$, we can use the properties of $R(u)$ on $[0, \\infty)$. The reaction term $R(u)$ is nondecreasing and globally Lipschitz with constant $L > 0$ for $u \\ge 0$. This means for any $w_1, w_2 \\ge 0$ with $w_1 \\ne w_2$, we have $0 \\le \\frac{R(w_1) - R(w_2)}{w_1 - w_2} \\le L$.\nThe slope of $f(w)$ is given by:\n$$ \\frac{f(w_1) - f(w_2)}{w_1 - w_2} = 1 - \\Delta t \\frac{R(w_1) - R(w_2)}{w_1 - w_2} $$\nFor $f(w)$ to be strictly increasing, we require its slope to be strictly positive.\n$$ 1 - \\Delta t \\frac{R(w_1) - R(w_2)}{w_1 - w_2} > 0 $$\nSince the quotient involving $R$ is bounded by $L$, a sufficient condition to guarantee this for all $w_1, w_2$ is $1 - \\Delta t L > 0$. This yields the condition on the time step:\n$$ \\Delta t < \\frac{1}{L} $$\nIf this condition holds, $f(w)$ is strictly increasing, which guarantees the existence of a unique solution $w$ for any $v$. This also guarantees monotonicity: if $v_a > v_b$, then the corresponding solutions $w_a > w_b$. If $\\Delta t = 1/L$, uniqueness can be lost (e.g., if $R(u)=Lu$).\n\n**$L^1$ Stability:** We examine the amplification factor for this substep. Let $w_a$ and $w_b$ be solutions corresponding to inputs $v_a$ and $v_b$.\n$$ |v_a - v_b| = |f(w_a) - f(w_b)| = \\left| 1 - \\Delta t \\frac{R(w_a) - R(w_b)}{w_a - w_b} \\right| |w_a - w_b| $$\nUnder the condition $\\Delta t < 1/L$, we have $1 - \\Delta t L > 0$ and the term in the absolute value is bounded below by $1 - \\Delta t L$. So:\n$$ |v_a - v_b| \\ge (1 - \\Delta t L)|w_a - w_b| $$\n$$ |w_a - w_b| \\le \\frac{1}{1 - \\Delta t L} |v_a - v_b| $$\nThis inequality holds pointwise for each grid location. Summing over all grid points and multiplying by $h^2$, we obtain a stability estimate for the difference of two solutions in the $L^1$ norm:\n$$ \\|w_a - w_b\\|_1 \\le \\frac{1}{1 - \\Delta t L} \\|v_a - v_b\\|_1 $$\nThe amplification factor for perturbations is $(1 - \\Delta t L)^{-1}$. For this factor to be finite, we require $\\Delta t < 1/L$. This ensures the $L^1$ stability of the reaction substep.\n\n### Synthesis and Conclusion\n\nThe diffusion substeps are unconditionally positivity-preserving and $L^1$-contractive. The reaction substep is unconditionally positivity-preserving. However, for the overall LOD scheme to be well-posed and $L^1$-stable, the reaction substep must be well-posed (guarantee uniqueness) and have a finite $L^1$ amplification factor. Both of these properties lead to the same constraint on the time step: $\\Delta t < 1/L$.\n\nThe problem asks for the largest allowable time step $\\Delta t_{\\max}$ that guarantees these properties. The set of valid time steps is the interval $(0, 1/L)$. The supremum of this set is $1/L$. Therefore, the largest allowable time step is $\\Delta t_{\\max} = 1/L$. Any practical implementation must use a time step $\\Delta t$ strictly smaller than this value.", "answer": "$$\\boxed{\\frac{1}{L}}$$", "id": "3417655"}, {"introduction": "The true potential of LOD methods is unlocked when solving large-scale problems on parallel computers, where the algorithm's structure allows for massive concurrency. However, achieving high performance depends critically on the chosen domain decomposition and the resulting communication overhead [@problem_id:3417642]. This practice challenges you to analyze different parallelization strategies and, using a simple performance model, identify the optimal approach that maximizes computational throughput by minimizing costly data exchange between processors.", "problem": "Consider the three-dimensional heat equation $u_t = \\kappa \\left(u_{xx} + u_{yy} + u_{zz}\\right)$ on a uniform Cartesian grid with $N_x = N_y = N_z = 512$, discretized in space by second-order centered differences and advanced in time by a Locally One-Dimensional (LOD) splitting scheme. In each time step, the LOD method performs three implicit one-dimensional substeps (one per spatial direction), and each substep reduces to solving independent tridiagonal systems along straight lines parallel to the corresponding axis. Assume each tridiagonal system is solved by the Thomas algorithm, with a per-unknown compute time of $t_c = 8\\,\\mathrm{ns}$ per sweep. You have $P = 512$ processors available.\n\nAssume the following parallel performance model:\n- For a given sweep, if all tridiagonal systems are local to each processor (no cross-processor coupling), the total compute time per sweep is proportional to the total number of unknowns per processor, and communication is only needed when redistributing data layouts between sweeps. A data redistribution (global transpose) has a per-unknown communication time of $t_m = 4\\,\\mathrm{ns}$ and requires moving the entire global dataset.\n- If a sweep requires solving tridiagonal systems that span multiple processors (distributed line solves), the resulting inter-processor communication along those lines has an effective per-unknown time of $t_{\\ell} = 20\\,\\mathrm{ns}$ and cannot be overlapped with computation.\n- Ignore latency, startup costs, and cache effects. Assume perfect load balancing and that all processors participate equally.\n\nYour task is to estimate the parallel efficiency and identify a domain decomposition strategy that maximizes concurrency of independent one-dimensional solves. Parallel efficiency is defined as $E = T_1/(P\\,T_P)$, and under the above model with perfect load balance, this reduces to $E \\approx T_{\\mathrm{comp}}/(T_{\\mathrm{comp}} + T_{\\mathrm{comm}})$, where $T_{\\mathrm{comp}}$ is the total compute time across all three LOD sweeps and $T_{\\mathrm{comm}}$ is the total communication time incurred in the time step.\n\nWhich option is most accurate under the stated model?\n\nA. Use a static three-dimensional block (brick) decomposition into $512$ equal subdomains. Each of the three sweeps requires distributed tridiagonal solves across block boundaries, incurring communication for all three directions. The efficiency is $E \\approx \\frac{3 t_c}{3 t_c + 3 t_{\\ell}}$, yielding $E \\approx \\frac{24}{24 + 60} \\approx 0.286$. Concurrency is limited because each one-dimensional line is split across blocks.\n\nB. Use a static $z$-slab decomposition into $512$ slabs, so each processor owns full $x$-$y$ planes but only a fraction of the $z$ levels. The $x$- and $y$-direction sweeps are purely local, while the $z$-direction sweep requires distributed tridiagonal solves along $z$. The efficiency is $E \\approx \\frac{3 t_c}{3 t_c + t_{\\ell}}$, yielding $E \\approx \\frac{24}{24 + 20} \\approx 0.750$. Concurrency is maximized in two sweeps and reduced in the $z$ sweep.\n\nC. Use a rotating two-dimensional pencil decomposition: store pencils aligned with the current sweep direction and perform two global transposes per time step to realign pencils for the subsequent sweeps. All tridiagonal solves are local in each sweep, and communication is only the two transposes. The efficiency is $E \\approx \\frac{3 t_c}{3 t_c + 2 t_m}$, yielding $E \\approx \\frac{24}{24 + 8} = 0.750$. Concurrency is maximized in all three sweeps since all one-dimensional lines in the active direction are independent and local.\n\nD. Use an orientation-cycling scheme that performs three global transposes per time step (before each sweep) so that all sweeps are local. The efficiency is $E \\approx \\frac{3 t_c}{3 t_c + 3 t_m}$, yielding $E \\approx \\frac{24}{24 + 12} \\approx 0.667$. Concurrency is maximized in all sweeps, but the extra transpose degrades efficiency compared to two transposes.\n\nSelect the option that correctly estimates the parallel efficiency and proposes the domain decomposition that maximizes concurrency of independent one-dimensional solves across lines or planes for the LOD method under this model.", "solution": "The problem statement is a well-posed exercise in the analysis of parallel algorithms for solving partial differential equations. The parameters, models, and methods described are standard in the field of scientific computing. The problem is scientifically grounded, self-contained, and objective. It is therefore valid.\n\nThe core of the problem is to evaluate different parallel domain decomposition strategies for a Locally One-Dimensional (LOD) time-stepping scheme applied to the three-dimensional heat equation, $u_t = \\kappa (\\nabla^2 u)$. The grid has dimensions $N_x = N_y = N_z = 512$, and we have $P = 512$ processors. The total number of grid points is $N_{total} = 512^3$, so each processor is responsible for $N_{proc} = N_{total}/P = 512^2$ grid points, assuming perfect load balancing.\n\nThe LOD method involves three sequential sweeps per time step, one for each spatial dimension ($x, y, z$). In each sweep, a set of one-dimensional problems (tridiagonal systems) is solved. The efficiency of a parallel implementation depends critically on whether these tridiagonal systems are local to a processor or are distributed across multiple processors.\n\nThe problem provides a simplified performance model with per-unknown time costs for computation and communication:\n-   Compute time per unknown per sweep: $t_c = 8\\,\\mathrm{ns}$.\n-   Communication time for a global transpose per unknown: $t_m = 4\\,\\mathrm{ns}$.\n-   Communication time for a distributed line solve per unknown: $t_{\\ell} = 20\\,\\mathrm{ns}$.\n\nThe total compute time per unknown for a full time step (three sweeps) is $T_{\\mathrm{comp}} = 3\\,t_c = 3 \\times 8\\,\\mathrm{ns} = 24\\,\\mathrm{ns}$.\nThe parallel efficiency is estimated as $E \\approx T_{\\mathrm{comp}} / (T_{\\mathrm{comp}} + T_{\\mathrm{comm}})$, where $T_{\\mathrm{comm}}$ is the total communication time per unknown per time step, which depends on the decomposition strategy. Maximizing the concurrency of independent one-dimensional solves means choosing a decomposition where the tridiagonal systems are, as much as possible, not distributed across processors.\n\nLet's evaluate each option:\n\n**A. Use a static three-dimensional block (brick) decomposition...**\n-   **Decomposition:** The $512 \\times 512 \\times 512$ domain is divided into $P=512$ blocks. A logical processor arrangement would be $P_x \\times P_y \\times P_z = 8 \\times 8 \\times 8 = 512$. Each processor holds a $64 \\times 64 \\times 64$ sub-grid.\n-   **Analysis:**\n    -   In the $x$-sweep, the tridiagonal systems are along the $x$-axis. Since the domain is partitioned in $x$ ($P_x=8$), each $x$-line is split across $8$ processors. This requires distributed line solves.\n    -   Similarly, the $y$-sweep and $z$-sweep also require distributed line solves.\n-   **Concurrency:** The Thomas algorithm is sequential along a line. When lines are distributed, processors must communicate to solve them, severely limiting the concurrency of independent solves. This strategy does not maximize concurrency.\n-   **Communication & Efficiency:** Each of the three sweeps incurs the distributed line-solve communication cost $t_{\\ell}$.\n    $$T_{\\mathrm{comm}} = t_{\\ell} + t_{\\ell} + t_{\\ell} = 3\\,t_{\\ell} = 3 \\times 20\\,\\mathrm{ns} = 60\\,\\mathrm{ns}$$\n    The efficiency is:\n    $$E \\approx \\frac{3\\,t_c}{3\\,t_c + 3\\,t_{\\ell}} = \\frac{24}{24 + 60} = \\frac{24}{84} \\approx 0.2857$$\n-   **Verdict:** **Incorrect**. The calculation is correct, but the statement that this strategy maximizes concurrency is false; it minimizes it for this type of algorithm.\n\n**B. Use a static $z$-slab decomposition...**\n-   **Decomposition:** The domain is partitioned along the $z$-axis into $P=512$ slabs. Each processor holds a full $512 \\times 512$ plane of data for a single $z$-index. The processor grid is $P_x \\times P_y \\times P_z = 1 \\times 1 \\times 512$.\n-   **Analysis:**\n    -   In the $x$-sweep, the tridiagonal systems are along the $x$-axis. Since the domain is not partitioned in $x$ ($P_x=1$), each $x$-line is fully contained within one processor's slab. The solves are local.\n    -   Similarly, in the $y$-sweep, the solves are local.\n    -   In the $z$-sweep, the tridiagonal systems are along the $z$-axis. Since the domain is partitioned into $512$ slabs in $z$ ($P_z=512$), each $z$-line is distributed across all $512$ processors. This requires distributed line solves.\n-   **Concurrency:** Concurrency is high for the $x$- and $y$-sweeps (many independent lines per processor) but low for the $z$-sweep. This strategy does not maximize concurrency across all three sweeps.\n-   **Communication & Efficiency:** Communication cost is incurred only for the $z$-sweep.\n    $$T_{\\mathrm{comm}} = t_{\\ell} = 20\\,\\mathrm{ns}$$\n    The efficiency is:\n    $$E \\approx \\frac{3\\,t_c}{3\\,t_c + t_{\\ell}} = \\frac{24}{24 + 20} = \\frac{24}{44} \\approx 0.545$$\n-   **Verdict:** **Incorrect**. The option states the final efficiency is $\\approx 0.750$, which is a gross arithmetic error ($24/44 \\neq 0.75$). Furthermore, this strategy does not maximize concurrency for all sweeps.\n\n**C. Use a rotating two-dimensional pencil decomposition... two global transposes per time step...**\n-   **Decomposition:** This dynamic strategy realigns the data layout to match the sweep direction.\n    1.  **$x$-sweep:** Data is arranged in $x$-pencils (partitioned in the $y$-$z$ plane). All $x$-lines are local. No communication during the sweep.\n    2.  **Transpose 1:** A global data transpose ($y$-$z$ to $x$-$z$ planes) rearranges the data into $y$-pencils. Cost: $t_m$.\n    3.  **$y$-sweep:** All $y$-lines are now local. No communication during the sweep.\n    4.  **Transpose 2:** Another transpose ($x$-$z$ to $x$-$y$ planes) rearranges data into $z$-pencils. Cost: $t_m$.\n    5.  **$z$-sweep:** All $z$-lines are now local. No communication during the sweep.\n-   **Concurrency:** This strategy ensures that for every sweep, the corresponding one-dimensional systems are fully local to processors. This allows all processors to solve their set of independent tridiagonal systems in parallel, thus maximizing the concurrency of independent solves.\n-   **Communication & Efficiency:** The communication consists of the two transposes.\n    $$T_{\\mathrm{comm}} = t_m + t_m = 2\\,t_m = 2 \\times 4\\,\\mathrm{ns} = 8\\,\\mathrm{ns}$$\n    The efficiency is:\n    $$E \\approx \\frac{3\\,t_c}{3\\,t_c + 2\\,t_m} = \\frac{24}{24 + 8} = \\frac{24}{32} = 0.750$$\n    This scheme is achievable, for instance, by alternating the order of sweeps in consecutive time steps, resulting in an average of two transposes per step.\n-   **Verdict:** **Correct**. This option correctly identifies the strategy that maximizes concurrency (pencil decomposition). It describes a valid, high-performance implementation using two transposes, and its efficiency calculation is arithmetically and conceptually correct based on the premises stated in the option.\n\n**D. Use an orientation-cycling scheme that performs three global transposes per time step...**\n-   **Decomposition:** This is also a rotating pencil decomposition, but it performs a third transpose to return the data to its original layout (e.g., $x$-pencils) at the end of each time step. The sequence is: $x$-solve (local) $\\rightarrow$ transpose $\\rightarrow$ $y$-solve (local) $\\rightarrow$ transpose $\\rightarrow$ $z$-solve (local) $\\rightarrow$ transpose.\n-   **Concurrency:** Like option C, this strategy maximizes the concurrency of independent solves because all line solves are local in every sweep.\n-   **Communication & Efficiency:** The communication cost is for three transposes.\n    $$T_{\\mathrm{comm}} = t_m + t_m + t_m = 3\\,t_m = 3 \\times 4\\,\\mathrm{ns} = 12\\,\\mathrm{ns}$$\n    The efficiency is:\n    $$E \\approx \\frac{3\\,t_c}{3\\,t_c + 3\\,t_m} = \\frac{24}{24 + 12} = \\frac{24}{36} = \\frac{2}{3} \\approx 0.667$$\n-   **Verdict:** **Incorrect**. While this describes a valid and widely used high-concurrency strategy, and the calculation is correct, the strategy in Option C achieves the same maximal concurrency with higher efficiency ($E=0.750 > E\\approx0.667$). Therefore, Option C represents a more optimal and accurate answer to the problem of finding the best strategy. The question asks for the single most accurate option, and C describes a superior approach.\n\n**Conclusion:**\nOptions A and B fail because they do not maximize concurrency. Option B also contains a numerical error. Options C and D both describe strategies that maximize concurrency. However, the two-transpose scheme in C is more efficient than the three-transpose scheme in D. As the two-transpose scheme is a valid and superior implementation, Option C is the most accurate and best answer to the problem.", "answer": "$$\\boxed{C}$$", "id": "3417642"}]}