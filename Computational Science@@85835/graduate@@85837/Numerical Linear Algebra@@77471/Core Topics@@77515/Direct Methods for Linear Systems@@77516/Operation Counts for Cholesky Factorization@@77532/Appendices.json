{"hands_on_practices": [{"introduction": "Before appreciating the efficiency gains from sparsity, we must first rigorously quantify the cost of the standard dense Cholesky factorization. This exercise [@problem_id:3370813] walks you through a first-principles derivation of the exact floating-point operation (flop) count. Mastering this foundational analysis is crucial for understanding the computational complexity of matrix algorithms and provides the baseline $O(n^3)$ benchmark against which all sparse methods are compared.", "problem": "Consider the symmetric positive-definite linear system $A x = b$ that arises from a finite difference discretization of a uniformly elliptic partial differential equation (PDE) such as the two-dimensional Poisson equation on a uniform grid. Suppose $A \\in \\mathbb{R}^{n \\times n}$ is treated as dense and factored by the Cholesky factorization $A = L L^{\\top}$, where $L$ is lower triangular with positive diagonal. Adopt the following arithmetic cost model: each floating-point addition, subtraction, multiplication, division, and square root counts as $1$ floating-point operation (flop).\n\nTasks:\n- Starting from the standard unblocked Cholesky algorithm that computes $L$ column-by-column using inner products, derive from first principles the exact total flop count to factor $A$ as a polynomial in $n$, and thereby show that it is $n^{3}/3 + O(n^{2})$.\n- Using the standard forward substitution for solving $L y = b$ and backward substitution for solving $L^{\\top} x = y$, derive the exact flop count of each triangular solve.\n- Combine your results to obtain a single simplified closed-form expression in $n$ for the exact total number of flops required to factor $A$ by Cholesky and then solve $A x = b$ for a single right-hand side by forward and backward substitution.\n\nReport as your final answer only the exact total flop count from the combined step, simplified to a single polynomial in $n$. No rounding is required.", "solution": "The problem statement is scrutinized for validity according to the specified criteria.\n\n### Step 1: Extract Givens\n- The system of equations is a linear system $A x = b$.\n- The matrix $A \\in \\mathbb{R}^{n \\times n}$ is symmetric and positive-definite (SPD), and is treated as dense.\n- The system is to be solved using Cholesky factorization, $A = L L^{\\top}$, where $L$ is a lower triangular matrix with positive diagonal entries.\n- The solution process consists of three stages:\n    1.  Cholesky factorization: $A \\to L$.\n    2.  Forward substitution: Solve $L y = b$ for $y$.\n    3.  Backward substitution: Solve $L^{\\top} x = y$ for $x$.\n- The arithmetic cost model defines a floating-point operation (flop) as one addition, subtraction, multiplication, division, or square root.\n- The tasks are:\n    1.  Derive the exact total flop count for the Cholesky factorization using a standard column-by-column algorithm based on inner products, expressing the result as a polynomial in $n$.\n    2.  Derive the exact flop count for both the forward and backward substitution steps.\n    3.  Combine all counts into a single simplified closed-form expression for the total number of flops to solve $A x = b$.\n\n### Step 2: Validate Using Extracted Givens\n- **Scientifically Grounded:** The problem is based on fundamental and standard concepts in numerical linear algebraâ€”Cholesky factorization and triangular solves. The flop count analysis is a canonical exercise in scientific computing.\n- **Well-Posed:** The problem clearly specifies the algorithms, the cost model, and the desired form of the output. This structure ensures that a unique and meaningful solution exists.\n- **Objective:** The problem is stated using precise, unambiguous mathematical language and is free of subjective content.\n\nThe problem does not exhibit any of the flaws listed in the instructions, such as scientific unsoundness, incompleteness, contradiction, or ambiguity. It is a well-defined problem in numerical analysis.\n\n### Step 3: Verdict and Action\nThe problem is **valid**. A detailed solution will be provided.\n\n### Solution Derivation\n\nLet $A = (a_{ij})$ and $L = (l_{ij})$ be $n \\times n$ matrices, with $l_{ij}=0$ for $j > i$. The Cholesky factorization is defined by the matrix equation $A = L L^{\\top}$. This corresponds to the scalar equations:\n$$a_{ij} = \\sum_{k=1}^{\\min(i,j)} l_{ik} l_{jk}$$\nWe will derive the flop counts for each of the three required stages.\n\n**1. Flop Count for Cholesky Factorization ($A = L L^{\\top}$)**\n\nThe problem specifies a column-by-column algorithm using inner products. For each column $j = 1, 2, \\dots, n$, we compute the elements $l_{jj}$ and $l_{ij}$ for $i > j$.\n\nFor the diagonal element $l_{jj}$:\nFrom $a_{jj} = \\sum_{k=1}^{j} l_{jk}^2 = \\sum_{k=1}^{j-1} l_{jk}^2 + l_{jj}^2$, we solve for $l_{jj}$:\n$$l_{jj} = \\sqrt{a_{jj} - \\sum_{k=1}^{j-1} l_{jk}^2}$$\n- The summation $\\sum_{k=1}^{j-1} l_{jk}^2$ involves $j-1$ multiplications and $j-2$ additions. (For $j=1$, the sum is empty and its cost is $0$).\n- The calculation of $l_{jj}$ requires one subtraction and one square root in addition to the sum.\n- Thus, the flop count to compute $l_{jj}$ is $(j-1) + (j-2) + 1 + 1 = 2j-1$ flops for $j>1$. For $j=1$, the cost is $1$ flop (a square root). The formula $2j-1$ also yields $1$ for $j=1$, so it is generally applicable.\n\nFor the off-diagonal elements $l_{ij}$ with $i > j$:\nFrom $a_{ij} = \\sum_{k=1}^{j} l_{ik} l_{jk} = \\sum_{k=1}^{j-1} l_{ik} l_{jk} + l_{ij} l_{jj}$, we solve for $l_{ij}$:\n$$l_{ij} = \\frac{1}{l_{jj}} \\left( a_{ij} - \\sum_{k=1}^{j-1} l_{ik} l_{jk} \\right)$$\n- The summation $\\sum_{k=1}^{j-1} l_{ik} l_{jk}$ is an inner product of two vectors of length $j-1$. It requires $j-1$ multiplications and $j-2$ additions, for a total of $2j-3$ flops (for $j>1$).\n- The calculation of $l_{ij}$ then requires one subtraction and one division.\n- The flop count to compute a single $l_{ij}$ is $(2j-3) + 1 + 1 = 2j-1$ flops for $j>1$. For $j=1$, the cost is $1$ flop (a division), which is also given by the formula $2j-1$.\n\nThe total flop count for column $j$ is the sum of costs for $l_{jj}$ and the $n-j$ elements $l_{ij}$ for $i=j+1, \\dots, n$.\nCost for column $j$:\n$$C_j = (2j-1) + (n-j)(2j-1) = (1+n-j)(2j-1)$$\n\nThe total flop count for the factorization, $C_{fact}$, is the sum of costs for all columns:\n$$C_{fact} = \\sum_{j=1}^{n} C_j = \\sum_{j=1}^{n} (n-j+1)(2j-1)$$\nLet's expand the term in the sum:\n$(n-j+1)(2j-1) = 2nj - n + 2j - 1 -2j^2 + j = -2j^2 + (2n+3)j - (n+1)$.\nLet's perform the summation:\n$$C_{fact} = \\sum_{j=1}^{n} \\left( -2j^2 + (2n+3)j - (n+1) \\right)$$\n$$C_{fact} = -2\\sum_{j=1}^{n} j^2 + (2n+3)\\sum_{j=1}^{n} j - (n+1)\\sum_{j=1}^{n} 1$$\nUsing the standard formulas for sums of powers: $\\sum_{j=1}^{n} 1 = n$, $\\sum_{j=1}^{n} j = \\frac{n(n+1)}{2}$, $\\sum_{j=1}^{n} j^2 = \\frac{n(n+1)(2n+1)}{6}$.\n$$C_{fact} = -2 \\left( \\frac{n(n+1)(2n+1)}{6} \\right) + (2n+3) \\left( \\frac{n(n+1)}{2} \\right) - n(n+1)$$\nFactor out the common term $n(n+1)$:\n$$C_{fact} = n(n+1) \\left[ -\\frac{2n+1}{3} + \\frac{2n+3}{2} - 1 \\right]$$\n$$C_{fact} = n(n+1) \\left[ \\frac{-2(2n+1) + 3(2n+3) - 6}{6} \\right]$$\n$$C_{fact} = n(n+1) \\left[ \\frac{-4n - 2 + 6n + 9 - 6}{6} \\right]$$\n$$C_{fact} = n(n+1) \\left[ \\frac{2n+1}{6} \\right] = \\frac{n(n+1)(2n+1)}{6}$$\nExpanding this polynomial gives:\n$$C_{fact} = \\frac{n(2n^2 + 3n + 1)}{6} = \\frac{2n^3 + 3n^2 + n}{6} = \\frac{n^3}{3} + \\frac{n^2}{2} + \\frac{n}{6}$$\nThis shows that the factorization cost is indeed $\\frac{n^3}{3} + O(n^2)$.\n\n**2. Flop Count for Triangular Solves**\n\n**Forward Substitution ($L y = b$):**\nWe solve for $y_i$ for $i=1, \\dots, n$:\n$$y_i = \\frac{1}{l_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} l_{ij} y_j \\right)$$\nTo find the total flop count, $C_{fwd}$, we sum the operations for each $i$:\n- For $i=1$, $y_1 = b_1 / l_{11}$ requires $1$ division.\n- For each $i > 1$, the sum $\\sum_{j=1}^{i-1} l_{ij} y_j$ requires $i-1$ multiplications and $i-2$ additions. Then, we perform $1$ subtraction and $1$ division.\n- The total cost for computing $y_i$ is $(i-1) + (i-2) + 1 + 1 = 2i-1$ flops for $i > 1$.\nThe total count for forward substitution is:\n$$C_{fwd} = 1 + \\sum_{i=2}^{n} (2i-1) = 1 + \\left( 2\\sum_{i=2}^{n} i - \\sum_{i=2}^{n} 1 \\right)$$\n$$C_{fwd} = 1 + 2\\left(\\frac{n(n+1)}{2} - 1\\right) - (n-1) = 1 + n(n+1) - 2 - n + 1 = n^2+n-n = n^2$$\nAlternatively, counting operation types:\n- Multiplications: $\\sum_{i=2}^{n} (i-1) = \\sum_{k=1}^{n-1} k = \\frac{n(n-1)}{2}$ flops.\n- Additions/Subtractions: $\\sum_{i=2}^{n} ((i-2)+1) = \\frac{n(n-1)}{2}$ flops.\n- Divisions: $\\sum_{i=1}^{n} 1 = n$ flops.\nTotal $C_{fwd} = \\frac{n(n-1)}{2} + \\frac{n(n-1)}{2} + n = n(n-1) + n = n^2-n+n = n^2$.\n\n**Backward Substitution ($L^{\\top} x = y$):**\nWe solve for $x_i$ for $i=n, \\dots, 1$:\n$$x_i = \\frac{1}{l_{ii}} \\left( y_i - \\sum_{j=i+1}^{n} l_{ji} x_j \\right)$$\nThe structure is identical to forward substitution. The number of operations for each row $i$ depends on the number of non-zero entries to the right of the diagonal, which is $n-i$.\nThe total flop count, $C_{bwd}$, is identical by symmetry to the forward substitution case.\n$$C_{bwd} = n^2$$\n\n**3. Total Flop Count**\n\nThe total number of flops to factor $A$ and solve $A x = b$ is the sum of the costs of the three stages:\n$$C_{total} = C_{fact} + C_{fwd} + C_{bwd}$$\n$$C_{total} = \\left( \\frac{2n^3 + 3n^2 + n}{6} \\right) + n^2 + n^2$$\n$$C_{total} = \\frac{2n^3 + 3n^2 + n}{6} + 2n^2$$\nTo combine these into a single expression, we find a common denominator:\n$$C_{total} = \\frac{2n^3 + 3n^2 + n + 12n^2}{6}$$\n$$C_{total} = \\frac{2n^3 + 15n^2 + n}{6}$$\nThis is the simplified closed-form polynomial expression for the exact total number of floating-point operations.", "answer": "$$\\boxed{\\frac{2n^3 + 15n^2 + n}{6}}$$", "id": "3370813"}, {"introduction": "Real-world problems often yield large, sparse matrices where most entries are zero. This practice [@problem_id:3561942] introduces a simplified model for the Cholesky factorization of matrices with a \"skyline\" structure, allowing us to explore the connection between matrix profile and computational work. By solving this optimization puzzle, you will gain an intuitive understanding of why the *arrangement* of non-zero elements is critical and how reordering a matrix can drastically change the factorization cost, even when the number of non-zeros remains the same.", "problem": "Consider a symmetric positive definite (SPD) matrix of order $n=10$ stored in a variable-bandwidth (skyline) format. Let the lower-triangular Cholesky factor be $L$, and let the per-column \"profile height\" be defined as $h_{j}$, the number of entries in column $j$ of $L$ strictly below the diagonal. The envelope size is the total profile height $E=\\sum_{j=1}^{n} h_{j}$. Because column $j$ requires computing a triangular set of inner products of dimension comparable to $h_{j}$ and applying updates on $h_{j}$ entries, the work per column scales quadratically with the profile height. For the purpose of comparing profiles with equal envelope size, adopt the model in which the floating-point operation (flop) count contributed by column $j$ is exactly $h_{j}^{2}$, and the total flop count is $F=\\sum_{j=1}^{n} h_{j}^{2}$.\n\nAssume the following constraints hold:\n- $h_{j}\\in\\mathbb{Z}_{\\ge 0}$ for all $j$,\n- $0\\le h_{j}\\le n-j$ for all $j$ (no column can have more entries below the diagonal than there are rows below it),\n- The envelope size is fixed at $E=\\sum_{j=1}^{n} h_{j}=24$.\n\nAmong all such feasible profiles $\\{h_{j}\\}_{j=1}^{n}$ with $n=10$ and $E=24$, determine the ratio\n$$\nR=\\frac{F_{\\max}}{F_{\\min}},\n$$\nwhere $F_{\\max}$ is the largest possible value of $F=\\sum_{j=1}^{n} h_{j}^{2}$ and $F_{\\min}$ is the smallest possible value of $F=\\sum_{j=1}^{n} h_{j}^{2}$, both subject to the stated constraints. Express your final answer as a single reduced fraction. No rounding is required.", "solution": "The problem asks for the ratio of the maximum to the minimum possible value of the function $F = \\sum_{j=1}^{n} h_{j}^{2}$ for a vector of integer profile heights $\\{h_j\\}_{j=1}^{n}$, subject to a set of constraints.\n\nFirst, we formalize the problem by stating the objective function and all constraints.\nThe objective function to be maximized and minimized is:\n$$F = \\sum_{j=1}^{10} h_{j}^{2}$$\nThe constraints are:\n1.  The variables $h_j$ are non-negative integers: $h_j \\in \\mathbb{Z}_{\\ge 0}$ for $j=1, \\dots, 10$.\n2.  The total sum is fixed: $E = \\sum_{j=1}^{10} h_{j} = 24$.\n3.  Each $h_j$ is bounded from above: $0 \\le h_j \\le n-j$. With $n=10$, this gives:\n    $h_1 \\le 9$\n    $h_2 \\le 8$\n    $h_3 \\le 7$\n    $h_4 \\le 6$\n    $h_5 \\le 5$\n    $h_6 \\le 4$\n    $h_7 \\le 3$\n    $h_8 \\le 2$\n    $h_9 \\le 1$\n    $h_{10} \\le 0$, which implies $h_{10} = 0$.\n\nThe problem is a constrained integer optimization problem. The function $f(x) = x^2$ is a convex function. The objective function $F$ is a sum of convex functions, and is therefore itself a convex function of the variables $\\{h_j\\}$.\n\n**Maximization of $F$**\n\nFor a convex function, the maximum over a compact domain is attained at the extreme points of the domain. In the context of the constraint $\\sum h_j = 24$, maximizing $\\sum h_j^2$ requires making the values of $h_j$ as unequal as possible. That is, we should concentrate the sum $24$ into as few $h_j$ terms as possible, making those terms as large as possible.\n\nThe constraints $h_j \\le 10-j$ limit how large each term can be. The largest possible values are permitted for small indices $j$. To maximize $F$, we should therefore populate the $h_j$ with the smallest indices first, setting them to their maximum allowed values until the sum of $24$ is reached. This is a greedy strategy.\n\n1.  Set $h_1$ to its maximum value: $h_1 = 9$. The remaining sum required is $24 - 9 = 15$.\n2.  Set $h_2$ to its maximum value: $h_2 = 8$. The remaining sum required is $15 - 8 = 7$.\n3.  Set $h_3$ to its maximum value: $h_3 = 7$. The remaining sum required is $7 - 7 = 0$.\n4.  Set all other $h_j$ to $0$: $h_j = 0$ for $j \\ge 4$.\n\nThis yields the profile $\\{h_j\\}_{\\text{max}} = \\{9, 8, 7, 0, 0, 0, 0, 0, 0, 0\\}$.\nLet's verify this profile is feasible:\n-   All $h_j$ are non-negative integers.\n-   $\\sum h_j = 9 + 8 + 7 = 24$.\n-   The bounds are satisfied: $h_1=9 \\le 9$, $h_2=8 \\le 8$, $h_3=7 \\le 7$, and $h_j=0$ for $j \\ge 4$ are all within their bounds.\n\nThe maximum value of $F$ is:\n$$F_{\\max} = 9^2 + 8^2 + 7^2 + \\sum_{j=4}^{10} 0^2 = 81 + 64 + 49 = 194$$\n\n**Minimization of $F$**\n\nTo minimize the convex function $F = \\sum h_j^2$ subject to $\\sum h_j = 24$, we should make the components $h_j$ as equal to one another as possible. Their average value is $24/9 = 2.\\overline{6}$ (since $h_{10}=0$, there are effectively $9$ variables, $h_1, ..., h_9$). This suggests the optimal integer values should be close to this average, i.e., a mix of $2$s and $3$s, while respecting the upper-bound constraints $h_j \\le 10-j$.\n\nThis suggests a \"smoothing\" process. If we have a profile with two values $h_i$ and $h_j$ such that $h_i > h_j+1$, we can reduce the sum of squares by transforming them to $h_i-1$ and $h_j+1$, provided this new profile is feasible. The change in $F$ would be $(h_i-1)^2 + (h_j+1)^2 - (h_i^2+h_j^2) = 2(h_j - h_i + 1) < 0$. This process continues until no such pair can be found, or a boundary of the feasible set is reached.\n\nThe optimal profile, therefore, should be non-increasing to the extent possible, i.e., $h_i \\ge h_j$ for $i<j$, to avoid situations where a swap $h_j \\to h_j-1, h_i \\to h_i+1$ would reduce $F$. Also, for any $i<j$, we must have $h_i \\le h_j+1$ unless increasing $h_j$ is forbidden by its upper bound $h_j = 10-j$.\n\nLet's construct a profile that satisfies these conditions. We aim for values around $2$ and $3$.\nThe constraints $h_9 \\le 1$ and $h_8 \\le 2$ force some values to be small.\nLet's build a non-increasing profile $\\{h_j\\}$ that sums to $24$.\nLet's try to use as many $3$s as possible. The slots that can accommodate a value of $3$ are $h_1, \\dots, h_7$. There are $7$ such slots.\nIf we set $h_1=\\dots=h_7=3$, the sum is $7 \\times 3 = 21$.\nWe need a total sum of $24$, so we need $3$ more. The remaining slots are $h_8$ and $h_9$.\nTheir capacities are $h_8 \\le 2$ and $h_9 \\le 1$.\n$2+1=3$. So we can set $h_8=2$ and $h_9=1$.\n\nThis gives the profile $\\{h_j\\}_{\\text{min}} = \\{3, 3, 3, 3, 3, 3, 3, 2, 1, 0\\}$.\nLet's verify this profile is feasible:\n-   All $h_j$ are non-negative integers.\n-   $\\sum h_j = 7 \\times 3 + 2 + 1 = 21+2+1=24$.\n-   Bounds: $h_j=3$ for $j \\le 7$ is valid since $h_7 \\le 3$. $h_8=2 \\le 2$ is valid. $h_9=1 \\le 1$ is valid. The profile is feasible.\n\nThis profile is non-increasing ($h_i \\ge h_j$ for $i<j$), so no swap of the form $h_j \\to h_j-1, h_i \\to h_i+1$ can be made.\nLet's check for swaps of the form $h_i \\to h_i-1, h_j \\to h_j+1$ for $i<j$ where $h_i > h_j+1$.\n- Consider $i \\in \\{1,..,7\\}$ and $j=9$. Here $h_i=3, h_j=1$. So $h_i > h_j+1$. Can we modify $h_i \\to 2, h_j \\to 2$? No, because $h_9$ cannot be larger than $1$.\n- Consider $i \\in \\{1,..,7\\}$ and $j=8$. Here $h_i=3, h_j=2$. So $h_i = h_j+1$. No reduction is possible.\n- Consider $i=8, j=9$. Here $h_i=2, h_j=1$. So $h_i = h_j+1$. No reduction is possible.\n\nThe profile $\\{3, 3, 3, 3, 3, 3, 3, 2, 1, 0\\}$ is optimal.\nThe minimum value of $F$ is:\n$$F_{\\min} = \\sum_{j=1}^{7} 3^2 + 2^2 + 1^2 + 0^2 = 7 \\times 9 + 4 + 1 = 63 + 4 + 1 = 68$$\n\n**Calculation of the Ratio**\n\nThe desired ratio is $R = \\frac{F_{\\max}}{F_{\\min}}$.\n$$R = \\frac{194}{68}$$\nTo express this as a reduced fraction, we find the greatest common divisor of the numerator and the denominator. Both are even.\n$$R = \\frac{194 \\div 2}{68 \\div 2} = \\frac{97}{34}$$\nThe number $97$ is a prime number. The number $34 = 2 \\times 17$. Since $97$ is not divisible by $2$ or $17$, the fraction is irreducible.", "answer": "$$\\boxed{\\frac{97}{34}}$$", "id": "3561942"}, {"introduction": "Building on the idea that matrix ordering is key, we now explore nested dissection, a powerful algorithm that dramatically reduces Cholesky factorization costs for matrices arising from grid-based problems. This exercise [@problem_id:3561956] guides you in setting up and solving a recurrence relation that models the computational cost of this divide-and-conquer approach. Solving this recurrence reveals the celebrated $O(n^{3/2})$ complexity, providing a striking example of how theoretical insights from graph theory lead to profound practical speedups in scientific computing.", "problem": "Consider a two-dimensional discretization on a square grid graph with $n$ unknowns, where $n$ is assumed to be a power of two, $n = 2^{k}$ for some integer $k \\geq 0$. The underlying matrix is symmetric positive definite (SPD). A nested dissection ordering based on planar graph separators partitions the graph into two subgraphs of size $n/2$ each by removing a separator of size $s = \\alpha \\sqrt{n}$ for some fixed constant $\\alpha \\in (0,\\infty)$. Assume that after eliminating the interior of each subgraph, the separator block is dense of dimension $s \\times s$, and that its Cholesky factorization costs $(1/3) s^{3}$ floating-point operations (flops), consistent with the well-tested dense Cholesky cost model for SPD matrices. All other separator-related operations (such as updating the Schur complement restricted to the separator) are assumed to be of lower order and can be subsumed into the same constant multiple.\n\n1. Using only the separator property $s = \\alpha \\sqrt{n}$ and the dense Cholesky cost model, set up a recurrence of the form\n$$\nT(n) \\;=\\; 2\\,T\\!\\left(\\frac{n}{2}\\right) \\;+\\; c\\,n^{3/2},\n$$\nfor the total flop count $T(n)$ of the sparse Cholesky factorization under nested dissection, and express the constant $c$ explicitly in terms of $\\alpha$.\n\n2. With the base condition $T(1) = 0$, solve the recurrence exactly for $n = 2^{k}$ and simplify your result into a single closed-form expression in terms of $n$ and $c$. Your final answer must be given as this single closed-form analytic expression for $T(n)$; no numerical approximation is required or permitted.", "solution": "The problem asks for two tasks: first, to set up a recurrence relation for the total floating-point operation (flop) count of a sparse Cholesky factorization using nested dissection on a specific problem class, and second, to solve this recurrence. The validation of the problem statement confirms that it is scientifically grounded, well-posed, objective, and internally consistent. It presents a standard, albeit simplified, model for analyzing the complexity of nested dissection.\n\nPart 1: Setting up the recurrence relation.\n\nThe total flop count for a problem of size $n$, denoted by $T(n)$, is determined by a divide-and-conquer strategy. The nested dissection algorithm partitions the graph of unknowns into two subgraphs of size $n/2$ and a separator. The total computational cost is the sum of the costs of processing the two subgraphs recursively and the cost of processing the separator.\n\nThe recursive calls contribute $2 T(n/2)$ to the total cost.\n\nThe cost associated with the separator at a given level of recursion is stated to be dominated by the Cholesky factorization of a dense matrix corresponding to the separator nodes. This matrix arises after the interior nodes of the subgraphs are eliminated, a process that forms a Schur complement on the separator variables.\n\nThe problem provides the following givens for determining this cost:\n1.  The size of the separator is $s = \\alpha \\sqrt{n}$, where $\\alpha$ is a positive constant.\n2.  The cost of the dense Cholesky factorization for the $s \\times s$ separator block is $(1/3) s^3$ flops.\n3.  All other costs related to the separator are of lower order and can be disregarded in the leading-order analysis, as per the problem statement's simplifications.\n\nLet $W(n)$ be the work done at the top level of recursion for a problem of size $n$. Based on the provided model, this work is the cost of factoring the dense separator block:\n$$\nW(n) = \\frac{1}{3}s^3\n$$\nSubstituting the expression for the separator size $s$ in terms of $n$:\n$$\nW(n) = \\frac{1}{3} (\\alpha \\sqrt{n})^3 = \\frac{1}{3} \\alpha^3 (n^{1/2})^3 = \\frac{1}{3} \\alpha^3 n^{3/2}\n$$\nThe total cost $T(n)$ is the sum of the costs from the recursive calls and the work at the current level:\n$$\nT(n) = 2 T\\left(\\frac{n}{2}\\right) + W(n) = 2 T\\left(\\frac{n}{2}\\right) + \\frac{\\alpha^3}{3} n^{3/2}\n$$\nThe problem requires this recurrence to be in the form $T(n) = 2 T(n/2) + c n^{3/2}$. By direct comparison, we can identify the constant $c$:\n$$\nc = \\frac{\\alpha^3}{3}\n$$\n\nPart 2: Solving the recurrence relation.\n\nWe are asked to solve the recurrence relation\n$$\nT(n) = 2 T\\left(\\frac{n}{2}\\right) + c n^{3/2}\n$$\nwith the base condition $T(1) = 0$ for $n = 2^k$, where $k$ is a non-negative integer.\n\nLet $n = 2^k$. Then $k = \\log_2 n$. The recurrence can be rewritten in terms of $k$:\n$$\nT(2^k) = 2 T(2^{k-1}) + c (2^k)^{3/2} = 2 T(2^{k-1}) + c 2^{3k/2}\n$$\nWe solve this by unrolling the recurrence (also known as the method of iteration):\n$$\n\\begin{aligned}\nT(n) = T(2^k) &= 2 T(2^{k-1}) + c (2^k)^{3/2} \\\\\n&= 2 \\left[ 2 T(2^{k-2}) + c (2^{k-1})^{3/2} \\right] + c (2^k)^{3/2} \\\\\n&= 2^2 T(2^{k-2}) + 2 c (2^{k-1})^{3/2} + c (2^k)^{3/2} \\\\\n&= 2^3 T(2^{k-3}) + 2^2 c (2^{k-2})^{3/2} + 2 c (2^{k-1})^{3/2} + c (2^k)^{3/2} \\\\\n&\\;\\;\\vdots \\\\\n&= 2^i T(2^{k-i}) + \\sum_{j=0}^{i-1} 2^j c (2^{k-j})^{3/2}\n\\end{aligned}\n$$\nWe unroll until we reach the base case, which occurs at $n=1$, or $2^0$. This corresponds to setting $i=k$:\n$$\nT(n) = T(2^k) = 2^k T(2^0) + \\sum_{j=0}^{k-1} 2^j c (2^{k-j})^{3/2}\n$$\nGiven the base condition $T(1) = T(2^0) = 0$, the first term vanishes. We are left with the summation:\n$$\nT(n) = \\sum_{j=0}^{k-1} 2^j c (2^{k-j})^{3/2}\n$$\nLet's simplify the term inside the summation:\n$$\n2^j c (2^{k-j})^{3/2} = c \\cdot 2^j \\cdot (2^k)^{3/2} \\cdot (2^{-j})^{3/2} = c \\cdot n^{3/2} \\cdot 2^j \\cdot 2^{-3j/2} = c \\cdot n^{3/2} \\cdot 2^{-j/2}\n$$\nSubstituting this back into the sum:\n$$\nT(n) = \\sum_{j=0}^{k-1} c n^{3/2} 2^{-j/2} = c n^{3/2} \\sum_{j=0}^{k-1} \\left(2^{-1/2}\\right)^j = c n^{3/2} \\sum_{j=0}^{k-1} \\left(\\frac{1}{\\sqrt{2}}\\right)^j\n$$\nThe summation is a finite geometric series with first term $a=1$, ratio $r = 1/\\sqrt{2}$, and $k$ terms. The sum is given by the formula $\\sum_{j=0}^{k-1} r^j = \\frac{1-r^k}{1-r}$.\n$$\n\\sum_{j=0}^{k-1} \\left(\\frac{1}{\\sqrt{2}}\\right)^j = \\frac{1 - (1/\\sqrt{2})^k}{1 - 1/\\sqrt{2}}\n$$\nWe express $(1/\\sqrt{2})^k$ in terms of $n$. Since $k = \\log_2 n$:\n$$\n\\left(\\frac{1}{\\sqrt{2}}\\right)^k = (2^{-1/2})^k = 2^{-k/2} = (2^k)^{-1/2} = n^{-1/2}\n$$\nSubstituting this into the sum's formula:\n$$\n\\text{Sum} = \\frac{1 - n^{-1/2}}{1 - 1/\\sqrt{2}}\n$$\nNow, substitute this back into the expression for $T(n)$:\n$$\nT(n) = c n^{3/2} \\left( \\frac{1 - n^{-1/2}}{1 - 1/\\sqrt{2}} \\right)\n$$\nTo obtain the requested single closed-form expression, we simplify this result.\nFirst, simplify the constant factor:\n$$\n\\frac{1}{1 - 1/\\sqrt{2}} = \\frac{1}{\\frac{\\sqrt{2}-1}{\\sqrt{2}}} = \\frac{\\sqrt{2}}{\\sqrt{2}-1}\n$$\nTo rationalize the denominator, we multiply the numerator and denominator by the conjugate $(\\sqrt{2}+1)$:\n$$\n\\frac{\\sqrt{2}}{\\sqrt{2}-1} \\times \\frac{\\sqrt{2}+1}{\\sqrt{2}+1} = \\frac{\\sqrt{2}(\\sqrt{2}+1)}{(\\sqrt{2})^2 - 1^2} = \\frac{2+\\sqrt{2}}{2-1} = 2+\\sqrt{2}\n$$\nNow, we can write $T(n)$ as:\n$$\nT(n) = c (2+\\sqrt{2}) n^{3/2} (1 - n^{-1/2})\n$$\nDistributing the $n^{3/2}$ term:\n$$\nT(n) = c (2+\\sqrt{2}) (n^{3/2} \\cdot 1 - n^{3/2} \\cdot n^{-1/2}) = c (2+\\sqrt{2}) (n^{3/2} - n^1)\n$$\nThis gives the final closed-form expression for the total flop count in terms of $n$ and $c$:\n$$\nT(n) = c(2+\\sqrt{2})(n^{3/2} - n)\n$$", "answer": "$$\n\\boxed{c(2+\\sqrt{2})(n^{3/2}-n)}\n$$", "id": "3561956"}]}