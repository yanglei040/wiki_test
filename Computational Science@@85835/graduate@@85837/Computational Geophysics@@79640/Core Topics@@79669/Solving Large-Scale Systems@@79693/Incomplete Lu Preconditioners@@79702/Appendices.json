{"hands_on_practices": [{"introduction": "The Incomplete LU with Threshold (ILUT) algorithm is a powerful and widely used preconditioning strategy. Its effectiveness stems from a sophisticated dual-criteria approach to dropping fill-in entries, which balances the density of the factors against their accuracy. This practice [@problem_id:3604446] provides a focused, hands-on calculation of a single ILUT factorization step, allowing you to master the interplay between the drop tolerance $\\tau$ and the fill-in limit $p$. Understanding this mechanism is fundamental to effectively tuning ILUT preconditioners for complex geophysical simulations.", "problem": "In constructing an Incomplete Lower-Upper factorization with threshold (ILUT) preconditioner for a sparse linear system arising from a finite-difference discretization of the acoustic wave equation in a heterogeneous crustal model, consider a single elimination step for row $i$ of the upper factor $U$. After applying the current pivot update, the intermediate fill candidates for row $i$ are represented by the set $\\{(j, a_{j})\\}$, where $j$ indexes column positions and $a_{j}$ are the corresponding candidate entry values. The ILUT selection rule is defined as follows: compute the Euclidean (two-)norm of the candidate values, form a threshold $\\theta = \\tau \\|\\mathbf{a}\\|_{2}$ with drop tolerance $\\tau$, retain at most $p$ entries with the largest absolute values among those satisfying $|a_{j}| \\ge \\theta$, and drop the rest. The dropped values collectively form the residual vector for the row, and its two-norm is referred to here as the “row norm of the dropped residual.”\n\nFor a specific row $i$, the intermediate fill candidate set is\n$$\n\\{(4,\\, 0.036),\\ (8,\\,-0.204),\\ (11,\\, 0.011),\\ (14,\\, 0.158),\\ (17,\\,-0.072),\\ (19,\\, 0.005),\\ (21,\\,-0.119),\\ (25,\\, 0.033),\\ (27,\\,-0.002)\\}.\n$$\nUse ILUT with parameters $p=3$ and $\\tau=0.1$, and execute one ILUT selection step as defined above. Compute the Euclidean norm of the dropped residual vector for this row. Express your answer as a pure number with no units, and round your result to four significant figures.", "solution": "The problem is validated as being scientifically grounded, well-posed, objective, and self-contained. It describes a standard procedure in numerical linear algebra (Incomplete LU factorization with thresholding) applied within a plausible scientific computing context (computational geophysics). All necessary data and parameters are provided, and the objective is clearly defined. No flaws are identified.\n\nThe task is to execute one step of the ILUT (Incomplete LU with threshold) selection process for a given row and compute the Euclidean norm of the vector of dropped entries.\n\nThe given intermediate fill candidate set for row $i$ is:\n$$\nS = \\{(4,\\, 0.036),\\ (8,\\,-0.204),\\ (11,\\, 0.011),\\ (14,\\, 0.158),\\ (17,\\,-0.072),\\ (19,\\, 0.005),\\ (21,\\,-0.119),\\ (25,\\, 0.033),\\ (27,\\,-0.002)\\}\n$$\nThe ILUT parameters are the fill-in limit $p=3$ and the drop tolerance $\\tau=0.1$.\n\nThe ILUT selection rule involves two criteria: a threshold based on the norm of the candidate row and a limit on the number of non-zero entries to keep.\n\nFirst, we define the vector $\\mathbf{a}$ of candidate entry values:\n$$\n\\mathbf{a} = \\begin{pmatrix} 0.036 & -0.204 & 0.011 & 0.158 & -0.072 & 0.005 & -0.119 & 0.033 & -0.002 \\end{pmatrix}\n$$\nNext, we compute the Euclidean (two-)norm of this vector, $\\|\\mathbf{a}\\|_{2}$:\n$$\n\\|\\mathbf{a}\\|_{2} = \\sqrt{0.036^2 + (-0.204)^2 + 0.011^2 + 0.158^2 + (-0.072)^2 + 0.005^2 + (-0.119)^2 + 0.033^2 + (-0.002)^2}\n$$\nThe sum of the squares is:\n$$\n\\sum a_j^2 = 0.001296 + 0.041616 + 0.000121 + 0.024964 + 0.005184 + 0.000025 + 0.014161 + 0.001089 + 0.000004 = 0.08846\n$$\nSo, the norm is:\n$$\n\\|\\mathbf{a}\\|_{2} = \\sqrt{0.08846} \\approx 0.29742226\n$$\nNow, we compute the threshold $\\theta$ using the drop tolerance $\\tau=0.1$:\n$$\n\\theta = \\tau \\|\\mathbf{a}\\|_{2} = 0.1 \\times \\sqrt{0.08846} \\approx 0.029742226\n$$\nThe selection rule states that we retain entries $(j, a_j)$ that satisfy $|a_j| \\ge \\theta$ and, among those, we keep at most $p=3$ entries with the largest absolute values. All other entries are dropped.\n\nLet's compute the absolute value for each candidate entry:\n\\begin{itemize}\n    \\item $|a_4| = |0.036| = 0.036$\n    \\item $|a_8| = |-0.204| = 0.204$\n    \\item $|a_{11}| = |0.011| = 0.011$\n    \\item $|a_{14}| = |0.158| = 0.158$\n    \\item $|a_{17}| = |-0.072| = 0.072$\n    \\item $|a_{19}| = |0.005| = 0.005$\n    \\item $|a_{21}| = |-0.119| = 0.119$\n    \\item $|a_{25}| = |0.033| = 0.033$\n    \\item $|a_{27}| = |-0.002| = 0.002$\n\\end{itemize}\nWe identify the entries that satisfy the threshold condition $|a_j| \\ge \\theta \\approx 0.02974$:\n\\begin{itemize}\n    \\item $|a_4| = 0.036 \\ge \\theta$\n    \\item $|a_8| = 0.204 \\ge \\theta$\n    \\item $|a_{11}| = 0.011 < \\theta$\n    \\item $|a_{14}| = 0.158 \\ge \\theta$\n    \\item $|a_{17}| = 0.072 \\ge \\theta$\n    \\item $|a_{19}| = 0.005 < \\theta$\n    \\item $|a_{21}| = 0.119 \\ge \\theta$\n    \\item $|a_{25}| = 0.033 \\ge \\theta$\n    \\item $|a_{27}| = 0.002 < \\theta$\n\\end{itemize}\nThe set of candidates satisfying the threshold condition contains $6$ entries. We must select at most $p=3$ of these, specifically those with the largest absolute values. Let's sort their absolute values in descending order:\n$0.204 > 0.158 > 0.119 > 0.072 > 0.036 > 0.033$.\n\nThe top $p=3$ entries to be kept are those corresponding to the absolute values $0.204$, $0.158$, and $0.119$.\nThe set of kept entries is:\n$$\nS_{\\text{kept}} = \\{(8, -0.204), (14, 0.158), (21, -0.119)\\}\n$$\nThe dropped entries are all other entries from the original candidate set $S$. The set of dropped entries is $S_{\\text{dropped}} = S \\setminus S_{\\text{kept}}$:\n$$\nS_{\\text{dropped}} = \\{(4, 0.036), (11, 0.011), (17, -0.072), (19, 0.005), (25, 0.033), (27, -0.002)\\}\n$$\nThe \"row norm of the dropped residual\" is the Euclidean norm of the vector formed by the values of these dropped entries. Let this vector be $\\mathbf{r}_{\\text{dropped}}$:\n$$\n\\mathbf{r}_{\\text{dropped}} = \\begin{pmatrix} 0.036 & 0.011 & -0.072 & 0.005 & 0.033 & -0.002 \\end{pmatrix}\n$$\nWe compute its Euclidean norm:\n$$\n\\|\\mathbf{r}_{\\text{dropped}}\\|_{2} = \\sqrt{0.036^2 + 0.011^2 + (-0.072)^2 + 0.005^2 + 0.033^2 + (-0.002)^2}\n$$\nThe sum of the squares is:\n$$\n\\sum r_{\\text{dropped},j}^2 = 0.001296 + 0.000121 + 0.005184 + 0.000025 + 0.001089 + 0.000004 = 0.007719\n$$\nThe norm is:\n$$\n\\|\\mathbf{r}_{\\text{dropped}}\\|_{2} = \\sqrt{0.007719} \\approx 0.0878578396\n$$\nThe problem requires the answer to be rounded to four significant figures.\nThe number is $0.0878578...$. The first four significant figures are $8, 7, 8, 5$. The fifth significant figure is $7$, which is $\\ge 5$, so we round up the fourth significant figure.\n$$\n0.08786\n$$", "answer": "$$\n\\boxed{0.08786}\n$$", "id": "3604446"}, {"introduction": "Geophysical models frequently feature high-contrast material properties, such as conductivity contrasts of several orders of magnitude, which result in poorly conditioned linear systems. Applying a standard Incomplete LU factorization with zero fill-in (ILU(0)) to such systems can lead to numerical instability and breakdowns. This coding exercise [@problem_id:3604435] demonstrates a crucial technique to combat this issue: Jacobi scaling, a form of matrix equilibration that improves robustness. By implementing both the ILU(0) factorization and diagnostic tools from first principles, you will gain practical skills and a deeper appreciation for how pre-processing can dramatically enhance preconditioner stability.", "problem": "Consider sparse linear systems that arise from the two-dimensional discretization of the heterogeneous diffusion operator in the form $-\\nabla \\cdot \\left( \\sigma \\nabla u \\right) = f$ on the unit square with homogeneous Dirichlet boundary conditions, where $\\sigma$ is a spatially varying, positive conductivity. Such systems are central in computational electromagnetics for low-frequency (diffusive) regimes in computational geophysics. Let $A \\in \\mathbb{R}^{n \\times n}$ denote the resulting sparse symmetric positive definite stiffness matrix from a standard five-point finite difference approximation with harmonic averaging at faces and grid spacing $h = 1$. Jacobi scaling refers to the diagonal equilibration $A_s = D^{-1/2} A D^{-1/2}$, where $D = \\mathrm{diag}(A)$ and $D^{-1/2} = \\mathrm{diag}(A)^{-1/2}$. An incomplete lower-upper factorization of level zero (Incomplete LU with zero fill, ILU(0)) is obtained by applying Gaussian elimination restricted to the sparsity pattern of $A$ without pivoting. The growth factor is defined as the ratio $g = \\max_{i,j} \\left( \\max\\{ |L_{ij}|, |U_{ij}| \\} \\right) / \\max_{i,j} |A_{ij}|$, excluding the implicit unit diagonal of $L$. For stability diagnostics, define an estimated breakdown count $b$ as the sum over all rows of the following events: a pivot risk if $U_{ii} \\le \\epsilon_{\\mathrm{abs}}$ or $U_{ii} \\le \\epsilon_{\\mathrm{rel}} A_{ii}$, a dominance risk if $U_{ii} \\le \\theta \\sum_{j>i} |U_{ij}|$ where the sum is over strictly upper triangular entries in the same row, and a multiplier growth risk if any $|L_{ij}| \\ge \\lambda$ in that row. The constants are fixed as $\\epsilon_{\\mathrm{abs}} = 10^{-14}$, $\\epsilon_{\\mathrm{rel}} = 10^{-8}$, $\\theta = 0.5$, and $\\lambda = 5$.\n\nFrom first principles, the five-point discretization with harmonic averaging on a uniform grid with node-based conductivity assigns, for every interior node $(i,j)$ with index mapping $\\kappa(i,j) = i + j n_x$, the matrix entries\n$$\nA_{\\kappa(i,j),\\kappa(i,j)} = \\sum_{(p,q) \\in \\mathcal{N}(i,j)} w_{(i,j)\\leftrightarrow(p,q)}, \\quad\nA_{\\kappa(i,j),\\kappa(p,q)} = - w_{(i,j)\\leftrightarrow(p,q)},\n$$\nwhere $\\mathcal{N}(i,j)$ lists the four nearest neighbors on the grid and $w_{(i,j)\\leftrightarrow(p,q)}$ is the harmonic mean across the shared face. Dirichlet boundary nodes are enforced by $A_{\\kappa(i,j),\\kappa(i,j)} = 1$ and all other entries in that row equal to $0$.\n$$\nw_{(i,j)\\leftrightarrow(p,q)} = \\left( \\frac{2}{\\sigma_{i,j}^{-1} + \\sigma_{p,q}^{-1}} \\right)\n$$\nStarting from the above core definitions, write a program that:\n- Assembles $A$ for given conductivity fields $\\sigma$ according to the specified discretization and boundary conditions.\n- Applies Jacobi scaling to form $A_s = D^{-1/2} A D^{-1/2}$ with $D = \\mathrm{diag}(A)$.\n- Implements ILU(0) with natural ordering and zero fill, defined by restricting the Gaussian elimination update to the sparsity pattern of $A$. For row $i$, compute $L_{ij}$ for $j < i$ that are present in $A$ using previously computed pivots $U_{jj}$ and rows of $U$, and then compute $U_{ij}$ for $j \\ge i$ that are present in $A$ using the already computed $L_{ik}$ and $U_{kj}$ with $k < i$.\n- Computes the growth factor $g$ and the estimated breakdown count $b$ as defined above.\n\nUsing the above, evaluate the effect of Jacobi scaling on growth and breakdowns by comparing unscaled and scaled ILU(0) for the following test suite of conductivity fields, each defined on a uniform grid of size $n_x \\times n_y$:\n1. Baseline uniform case (happy path): $n_x = 8$, $n_y = 8$, uniform $\\sigma = 1$. This tests the no-contrast, well-conditioned baseline.\n2. Central conductive block in a resistive background: $n_x = 16$, $n_y = 16$, background $\\sigma = 1$, with a centered block occupying indices $i \\in [5,10]$, $j \\in [5,10]$ set to $\\sigma_{\\mathrm{block}} = 10^6$. This tests a localized high-contrast inclusion.\n3. Checkerboard extreme contrast: $n_x = 16$, $n_y = 16$, with $\\sigma_{i,j} = 1$ if $(i+j)$ is even and $\\sigma_{i,j} = 10^{-6}$ if $(i+j)$ is odd. This tests pervasive high contrast alternating at the grid scale.\n4. Conductive channel across a resistive medium: $n_x = 32$, $n_y = 8$, background $\\sigma = 10^{-6}$, and a channel at row $j = \\lfloor n_y/2 \\rfloor$ with $\\sigma = 1$ along all $i$. This tests a thin, extended conductive feature.\n\nFor each test case $t$, compute:\n- $b_{\\mathrm{unscaled}}^{(t)}$ from ILU(0) on $A$,\n- $b_{\\mathrm{scaled}}^{(t)}$ from ILU(0) on $A_s$,\n- the reduction in estimated breakdowns $r^{(t)} = b_{\\mathrm{unscaled}}^{(t)} - b_{\\mathrm{scaled}}^{(t)}$.\n\nYour program should produce a single line of output containing the list $[r^{(1)}, r^{(2)}, r^{(3)}, r^{(4)}]$ as a comma-separated list enclosed in square brackets, with each element printed as an integer. No physical units are required for the output. No angles are involved. Percentages are not used.\n\nAll computations must be performed in double precision floating point arithmetic. The code must be self-contained and must not read any input or write any files. The ILU(0) implementation must adhere to the pattern-restricted Gaussian elimination as described above without any pivoting or fill beyond the original sparsity structure.", "solution": "The provided Python code implements the required analysis from first principles.\n1.  **Matrix Assembly:** The `assemble_matrix` function constructs the sparse stiffness matrix `A` for a given conductivity field `sigma` on an `nx` by `ny` grid. It iterates through each grid node, applying Dirichlet boundary conditions (identity row) or, for interior nodes, a five-point stencil using the specified harmonic averaging for conductivity between adjacent cells.\n2.  **ILU(0) Factorization:** The `ilu0` function performs an in-place incomplete LU factorization with zero fill-in. It iterates through the matrix rows, performing Gaussian elimination updates only for entries that exist in the original sparsity pattern of `A`.\n3.  **Jacobi Scaling:** The main analysis function calculates the scaled matrix $A_s = D^{-1/2} A D^{-1/2}$ by extracting the diagonal `D` of `A` and using sparse matrix multiplications.\n4.  **Diagnostics:** The `compute_breakdown_count` function evaluates the stability of a given factorization. It iterates through the rows of the `LU` factors and tallies the occurrences of three risk conditions: small pivots, loss of diagonal dominance, and large multiplier growth, as defined in the problem.\n5.  **Execution:** The main script runs this entire pipeline for each of the four test cases, once for the original unscaled matrix and once for the Jacobi-scaled matrix. It calculates the reduction in the breakdown count ($r^{(t)} = b_{\\mathrm{unscaled}}^{(t)} - b_{\\mathrm{scaled}}^{(t)}$) for each case and prints the final results.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.sparse import lil_matrix, csr_matrix, diags, triu, tril\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the assembly, factorization, and analysis\n    for the specified test cases.\n    \"\"\"\n    \n    # Define constants from the problem description\n    EPS_ABS = 1e-14\n    EPS_REL = 1e-8\n    THETA = 0.5\n    LAMBDA = 5.0\n\n    def assemble_matrix(sigma, nx, ny):\n        \"\"\"Assembles the sparse stiffness matrix A for a given conductivity field.\"\"\"\n        n = nx * ny\n        mat = lil_matrix((n, n), dtype=np.float64)\n        \n        for j in range(ny):\n            for i in range(nx):\n                k = i + j * nx\n                \n                # Enforce homogeneous Dirichlet boundary conditions\n                is_boundary = (i == 0) or (i == nx - 1) or (j == 0) or (j == ny - 1)\n                if is_boundary:\n                    mat[k, k] = 1.0\n                    continue\n                \n                # Handle interior nodes using a five-point stencil with harmonic averaging\n                diag_sum = 0.0\n                neighbors = [(i - 1, j), (i + 1, j), (i, j - 1), (i, j + 1)]\n                \n                for p, q in neighbors:\n                    k_neighbor = p + q * nx\n                    \n                    sigma_ij = sigma[j, i]\n                    sigma_pq = sigma[q, p]\n                    \n                    # Harmonic mean of conductivity\n                    # Note: sigma is guaranteed to be positive in the test cases\n                    w = 2.0 / (1.0 / sigma_ij + 1.0 / sigma_pq)\n                    \n                    mat[k, k_neighbor] = -w\n                    diag_sum += w\n                \n                mat[k, k] = diag_sum\n                \n        return mat.tocsr()\n\n    def ilu0(A_csr):\n        \"\"\"\n        Performs ILU(0) factorization on a CSR matrix A.\n        The factorization is done in-place on a copy of A.\n        \"\"\"\n        n = A_csr.shape[0]\n        LU = A_csr.copy()\n\n        for i in range(1, n):\n            i_start, i_end = LU.indptr[i], LU.indptr[i+1]\n            i_indices = LU.indices[i_start:i_end]\n            i_data = LU.data[i_start:i_end]\n            \n            i_cols_map = {col: k for k, col in enumerate(i_indices)}\n            \n            # For each structurally non-zero element A(i, k) with k < i\n            for k_idx_in_row_i, k in enumerate(i_indices):\n                if k >= i:\n                    break  # Process only the lower triangular part of the row\n                \n                k_start, k_end = LU.indptr[k], LU.indptr[k+1]\n                k_indices = LU.indices[k_start:k_end]\n                \n                diag_pos_in_k = np.searchsorted(k_indices, k)\n                \n                pivot = 0.0\n                if diag_pos_in_k < len(k_indices) and k_indices[diag_pos_in_k] == k:\n                    pivot = LU.data[k_start + diag_pos_in_k]\n\n                if abs(pivot) < 1e-99:\n                    continue  # A zero pivot is encountered; diagnostics will capture this\n                \n                multiplier = i_data[k_idx_in_row_i] / pivot\n                i_data[k_idx_in_row_i] = multiplier\n\n                k_data = LU.data[k_start:k_end]\n                \n                for j_idx_in_row_k, j in enumerate(k_indices):\n                    if j <= k:\n                        continue\n                    \n                    if j in i_cols_map:\n                        j_idx_in_row_i = i_cols_map[j]\n                        i_data[j_idx_in_row_i] -= multiplier * k_data[j_idx_in_row_k]\n        return LU\n\n    def compute_breakdown_count(A_orig, LU):\n        \"\"\"Computes the estimated breakdown count b based on stability diagnostics.\"\"\"\n        n = A_orig.shape[0]\n        b = 0\n\n        U = triu(LU, format='csr')\n        L = tril(LU, k=-1, format='csr')\n        diag_A = A_orig.diagonal()\n        diag_U = U.diagonal()\n\n        for i in range(n):\n            U_ii = diag_U[i]\n            A_ii = diag_A[i]\n\n            # 1. Pivot risk\n            if U_ii <= EPS_ABS or (A_ii > 1e-99 and U_ii <= EPS_REL * A_ii):\n                b += 1\n            \n            # 2. Dominance risk\n            u_row_start, u_row_end = U.indptr[i], U.indptr[i+1]\n            u_row_indices = U.indices[u_row_start:u_row_end]\n            u_row_data = U.data[u_row_start:u_row_end]\n            \n            sum_abs_Uij = 0.0\n            for j_idx, j in enumerate(u_row_indices):\n                if j > i:\n                    sum_abs_Uij += abs(u_row_data[j_idx])\n            \n            if U_ii <= THETA * sum_abs_Uij:\n                b += 1\n                \n            # 3. Multiplier growth risk\n            l_row_start, l_row_end = L.indptr[i], L.indptr[i+1]\n            if l_row_end > l_row_start:\n                l_row_data = L.data[l_row_start:l_row_end]\n                if np.max(np.abs(l_row_data)) >= LAMBDA:\n                    b += 1\n        return b\n\n    def run_analysis_for_case(nx, ny, sigma_func):\n        \"\"\"Runs the unscaled and scaled analysis for a single test case.\"\"\"\n        sigma = sigma_func(nx, ny)\n        \n        # Unscaled analysis\n        A_unscaled = assemble_matrix(sigma, nx, ny)\n        LU_unscaled = ilu0(A_unscaled)\n        b_unscaled = compute_breakdown_count(A_unscaled, LU_unscaled)\n        \n        # Scaled analysis\n        diag_A = A_unscaled.diagonal()\n        diag_A[diag_A <= 0] = 1.0 \n        D_inv_sqrt = diags(1.0 / np.sqrt(diag_A))\n        A_scaled = (D_inv_sqrt @ A_unscaled @ D_inv_sqrt).tocsr()\n        \n        LU_scaled = ilu0(A_scaled)\n        b_scaled = compute_breakdown_count(A_scaled, LU_scaled)\n        \n        return b_unscaled - b_scaled\n\n    # Define the conductivity generation functions for each test case\n    def sigma_1(nx, ny):\n        return np.ones((ny, nx), dtype=np.float64)\n\n    def sigma_2(nx, ny):\n        sigma = np.ones((ny, nx), dtype=np.float64)\n        sigma[5:11, 5:11] = 1e6\n        return sigma\n\n    def sigma_3(nx, ny):\n        sigma = np.ones((ny, nx), dtype=np.float64)\n        rows, cols = np.indices((ny, nx))\n        sigma[(rows + cols) % 2 != 0] = 1e-6\n        return sigma\n\n    def sigma_4(nx, ny):\n        sigma = np.full((ny, nx), 1e-6, dtype=np.float64)\n        channel_row = ny // 2\n        sigma[channel_row, :] = 1.0\n        return sigma\n\n    test_cases = [\n        (8, 8, sigma_1),\n        (16, 16, sigma_2),\n        (16, 16, sigma_3),\n        (32, 8, sigma_4),\n    ]\n\n    results = []\n    for nx, ny, sigma_func in test_cases:\n        reduction = run_analysis_for_case(nx, ny, sigma_func)\n        results.append(int(reduction))\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3604435"}, {"introduction": "When numerically solving PDEs that describe conservation laws, such as the advection-diffusion equation, it is often critical that the solver preserves global invariants like mass or energy. While the exact solution of the discretized system may be conservative, the intermediate steps of an iterative solver may not be, depending on the preconditioner. This practice [@problem_id:3604408] delves into this subtle but vital issue by contrasting the standard ILU(0) preconditioner with its Modified (MILU) counterpart. By implementing both and tracking the global mass error, you will discover how a small change in the factorization algorithm allows MILU to enforce conservation at every iteration, a crucial property for physically meaningful simulations.", "problem": "You must write a complete and runnable program that constructs a linear system arising from a backward-Euler implicit time step for a two-dimensional advection-diffusion problem on a periodic rectangular grid, then compares the per-iteration global mass error produced by a standard Incomplete Lower-Upper (ILU) factorization and a Modified Incomplete Lower-Upper (MILU) factorization when used as left preconditioners in a stationary Richardson iteration. The purpose is to explicitly demonstrate a scenario in which standard ILU breaks conservation at the iteration level, while MILU reduces this defect by preserving a discrete row-sum property.\n\nThe construction must begin from the following foundational, well-tested ingredients and definitions.\n\n1) Conservation under discrete fluxes. Consider a uniform rectangular grid with $N_x$ cells in the $x$-direction and $N_y$ cells in the $y$-direction; denote by $n = N_x N_y$ the total number of cells, by $\\Delta x = 1/N_x$ and $\\Delta y = 1/N_y$ the grid spacings, and by $i \\in \\{0,\\dots,N_x-1\\}$, $j \\in \\{0,\\dots,N_y-1\\}$ the cell indices. Define a discrete operator $L \\in \\mathbb{R}^{n \\times n}$ through conservative flux balances with periodic boundary conditions, using constant velocity components $u_x$ and $u_y$, and constant diffusivity $\\kappa \\ge 0$:\n- Let the outflow rates from a cell to its four direct neighbors be $w_E = \\kappa/\\Delta x^2 + \\max(u_x,0)/\\Delta x$, $w_W = \\kappa/\\Delta x^2 + \\max(-u_x,0)/\\Delta x$, $w_N = \\kappa/\\Delta y^2 + \\max(u_y,0)/\\Delta y$, $w_S = \\kappa/\\Delta y^2 + \\max(-u_y,0)/\\Delta y$.\n- For the linear operator, set off-diagonal entries corresponding to east, west, north, and south neighbors as $-w_E$, $-w_W$, $-w_N$, and $-w_S$, respectively, and the diagonal entry as $w_E + w_W + w_N + w_S$. For periodicity, the east neighbor of $(N_x-1,j)$ is $(0,j)$, the west neighbor of $(0,j)$ is $(N_x-1,j)$, the north neighbor of $(i,N_y-1)$ is $(i,0)$, and the south neighbor of $(i,0)$ is $(i,N_y-1)$.\n- By construction, this yields $L \\mathbf{1} = \\mathbf{0}$, equivalently $\\mathbf{1}^\\top L = \\mathbf{0}^\\top$, where $\\mathbf{1}$ is the vector of all ones.\n\n2) Backward-Euler implicit step. Define the system matrix $B \\in \\mathbb{R}^{n \\times n}$ for a time step of size $\\Delta t > 0$ as $B = I + \\Delta t \\, L$, where $I$ is the identity matrix. Since $\\mathbf{1}^\\top L = \\mathbf{0}^\\top$, this implies the row-sum property $\\mathbf{1}^\\top B = \\mathbf{1}^\\top$.\n\n3) Mass conservation in the discrete system. For a given right-hand side vector $b \\in \\mathbb{R}^n$, the exact solution $x^\\star$ of $B x = b$ satisfies $\\mathbf{1}^\\top x^\\star = \\mathbf{1}^\\top b$. This is a direct consequence of $\\mathbf{1}^\\top B = \\mathbf{1}^\\top$.\n\n4) Iterative solution with left preconditioning. Consider the stationary Richardson iteration with a left preconditioner $P \\approx B$:\n$$\nx^{(k+1)} \\;=\\; x^{(k)} + P^{-1}\\left(b - B x^{(k)}\\right),\n$$\nwith initial guess $x^{(0)} = \\mathbf{0}$. Define the per-iteration global mass error after iteration $k$ as\n$$\nE^{(k)}(P) \\;=\\; \\left| \\mathbf{1}^\\top x^{(k)} - \\mathbf{1}^\\top b \\right|.\n$$\nBecause $\\mathbf{1}^\\top B = \\mathbf{1}^\\top$, $E^{(k)}(P)$ quantifies the defect in mass conservation at the iterate level.\n\n5) Preconditioners. Construct two drop-tolerant factorizations of $B$ with zero fill beyond the original nonzero pattern (also called level-$0$ fill).\n- Standard Incomplete Lower-Upper factorization (ILU($0$)): Perform Gaussian elimination restricted to the original sparsity pattern (the five-point stencil with periodic wrap), dropping fill-in entries outside the pattern without compensation.\n- Modified Incomplete Lower-Upper factorization (MILU($0$)): Use the same operation ordering as ILU($0$), but whenever a fill-in update $d$ to an entry outside the allowed pattern would have occurred, drop it and add its value to the diagonal entry of the current row instead. This diagonal absorption preserves the row-sum of the approximate factorization $P = LU$ so that $\\mathbf{1}^\\top P = \\mathbf{1}^\\top B$.\n\nProgram requirements.\n\nA) System assembly. For each specified parameter set $(N_x,N_y,u_x,u_y,\\kappa,\\Delta t)$, assemble $B = I + \\Delta t\\, L$ exactly as above. Construct a right-hand side $b$ by drawing an initial state $x^{(0)}_{\\text{phys}}$ with independent samples from the uniform distribution on $[0,1]$ using a fixed seed, and then setting $b = x^{(0)}_{\\text{phys}}$. This ensures $\\mathbf{1}^\\top b$ is known and fixed.\n\nB) Preconditioners and iteration. Build $P_{\\text{ILU}}$ by ILU($0$) and $P_{\\text{MILU}}$ by MILU($0$) with diagonal absorption of dropped updates. For each preconditioner, run exactly $K=3$ Richardson iterations with relaxation parameter $\\omega = 1$ as written above (i.e., no additional scaling), and after each iteration report $E^{(k)}(P)$ for $k \\in \\{1,2,3\\}$.\n\nC) Test suite. Your program must run the following four test cases and aggregate their results. All quantities are dimensionless, so no physical units are required. Use the specified random seeds for reproducibility. The test suite is:\n- Case A (happy path): $N_x = 10$, $N_y = 10$, $u_x = 1.0$, $u_y = 0.3$, $\\kappa = 0.02$, $\\Delta t = 0.1$, seed=42.\n- Case B (symmetric diffusion): $N_x = 8$, $N_y = 8$, $u_x = 0.0$, $u_y = 0.0$, $\\kappa = 0.1$, $\\Delta t = 0.2$, seed=7.\n- Case C (advection-dominated, anisotropic grid): $N_x = 16$, $N_y = 4$, $u_x = 3.0$, $u_y = -1.0$, $\\kappa = 0.005$, $\\Delta t = 0.05$, seed=123.\n- Case D (counter-flow, moderate diffusion): $N_x = 12$, $N_y = 6$, $u_x = -2.0$, $u_y = 2.5$, $\\kappa = 0.01$, $\\Delta t = 0.08$, seed=2024.\n\nD) Output. For each case, produce a flat list of length $6$ containing the three per-iteration global mass errors for standard ILU($0$) interleaved with those for MILU($0$), in the order\n$$\n\\left[ E^{(1)}(P_{\\text{ILU}}), \\; E^{(1)}(P_{\\text{MILU}}), \\; E^{(2)}(P_{\\text{ILU}}), \\; E^{(2)}(P_{\\text{MILU}}), \\; E^{(3)}(P_{\\text{ILU}}), \\; E^{(3)}(P_{\\text{MILU}}) \\right].\n$$\nYour program should produce a single line of output containing the results across all four test cases as a comma-separated list of these lists, enclosed in square brackets. Each floating-point number must be formatted in scientific notation with exactly six digits after the decimal point (for example, $1.234567 \\times 10^{-3}$ must be printed as `1.234567e-03`).\n\nIn summary, you must implement the discrete operator assembly for $B = I + \\Delta t \\, L$, the ILU($0$) and MILU($0$) factorizations with level-$0$ fill on the resulting five-point periodic stencil, execute $K=3$ preconditioned Richardson iterations for each preconditioner, and report the per-iteration global mass error as specified. The output must be a single line representing a list of four lists, one per test case, each of length $6$ with the order and formatting described above.", "solution": "The Python program implements a direct comparison between ILU(0) and MILU(0) preconditioners to demonstrate their differing effects on mass conservation.\n1.  **System Assembly:** The `assemble_system` function creates the linear system matrix $B = I + \\Delta t L$ for the 2D advection-diffusion equation on a periodic grid. The operator `L` is built using upwind-biased fluxes for advection and central fluxes for diffusion, ensuring the column sums of `L` are zero ($\\mathbf{1}^\\top L = \\mathbf{0}^\\top$), which in turn guarantees the column sums of `B` are one ($\\mathbf{1}^\\top B = \\mathbf{1}^\\top$). A right-hand side `b` is generated from a random initial state.\n2.  **ILU/MILU Factorization:** The `perform_factorization` function implements both factorization types. It performs an in-place, pattern-restricted Gaussian elimination. For MILU (when `is_milu=True`), any fill-in update that would be dropped is instead added to the diagonal element of the current row, preserving the row-sum property.\n3.  **Richardson Iteration:** The `run_richardson_iterations` function executes `K=3` steps of the stationary Richardson iteration. In each step, it applies the preconditioner by performing forward and backward substitution using the `L` and `U` factors. After each iteration, it computes the global mass error $E^{(k)} = |\\mathbf{1}^\\top x^{(k)} - \\mathbf{1}^\\top b|$.\n4.  **Execution and Output:** The main script cycles through the four test cases. For each case, it runs the analysis for both `P_ILU` and `P_MILU`, collects the three per-iteration mass errors for each, and formats them into the specified interleaved list for final output.", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport scipy.sparse as sp\nfrom scipy.sparse.linalg import spsolve_triangular\n\ndef assemble_system(Nx, Ny, ux, uy, kappa, dt, seed):\n    \"\"\"\n    Assembles the system matrix B and the right-hand side vector b for the\n    2D advection-diffusion problem on a periodic grid.\n    \"\"\"\n    n = Nx * Ny\n    dx = 1.0 / Nx\n    dy = 1.0 / Ny\n\n    # Define outflow rates based on upwind scheme for advection\n    w_E = kappa / dx**2 + max(ux, 0) / dx\n    w_W = kappa / dx**2 + max(-ux, 0) / dx\n    w_N = kappa / dy**2 + max(uy, 0) / dy\n    w_S = kappa / dy**2 + max(-uy, 0) / dy\n    diag_val = w_E + w_W + w_N + w_S\n\n    # Assemble the spatial operator matrix L using LIL format for efficiency\n    L = sp.lil_matrix((n, n))\n    for j in range(Ny):\n        for i in range(Nx):\n            k = i + j * Nx\n            \n            # Neighbor indices with periodic boundary conditions\n            k_E = ((i + 1) % Nx) + j * Nx\n            k_W = ((i - 1 + Nx) % Nx) + j * Nx\n            k_N = i + ((j + 1) % Ny) * Nx\n            k_S = i + ((j - 1 + Ny) % Ny) * Nx\n            \n            L[k, k] = diag_val\n            L[k, k_E] = -w_E\n            L[k, k_W] = -w_W\n            L[k, k_N] = -w_N\n            L[k, k_S] = -w_S\n\n    # The system matrix for Backward-Euler is B = I + dt*L\n    B = sp.identity(n, format='csc') + dt * L.tocsc()\n    \n    # Generate the right-hand side vector b\n    np.random.seed(seed)\n    b = np.random.uniform(0, 1, size=n)\n    \n    return B, b\n\ndef perform_factorization(A_lil, is_milu):\n    \"\"\"\n    Performs ILU(0) or MILU(0) factorization on matrix A.\n    The input matrix A_lil must be in LIL format for efficient modification.\n    The factorization is performed in-place.\n    \"\"\"\n    n = A_lil.shape[0]\n    \n    # Generate sparsity pattern from the original matrix.\n    rows, cols = A_lil.nonzero()\n    pattern = set(zip(rows, cols))\n\n    # In-place Gaussian elimination for ILU(0)/MILU(0) (i-k-j variant)\n    for i in range(1, n):\n        row_sum_correction = 0.0\n        \n        # Identify pivot columns k < i that affect row i\n        pivot_cols_k = sorted([k for k in A_lil.rows[i] if k < i])\n        \n        for k in pivot_cols_k:\n            pivot_val = A_lil[k, k]\n            if pivot_val == 0.0:\n                continue\n            \n            # Compute multiplier and store it in the L part of the matrix\n            factor = A_lil[i, k] / pivot_val\n            A_lil[i, k] = factor\n            \n            # Update row i based on row k (for entries j > k)\n            update_cols_j = [j for j in A_lil.rows[k] if j > k]\n            \n            for j in update_cols_j:\n                update_val = factor * A_lil[k, j]\n                \n                if (i, j) in pattern:\n                    # Update entry if it's in the original sparsity pattern\n                    A_lil[i, j] -= update_val\n                elif is_milu:\n                    # For MILU, accumulate dropped fill-in for row sum correction\n                    row_sum_correction += update_val\n\n        # For MILU, add the accumulated correction to the diagonal of row i\n        if is_milu and row_sum_correction != 0.0:\n            A_lil[i, i] += row_sum_correction\n            \n    return A_lil\n\ndef run_richardson_iterations(B, b, P_fact, K):\n    \"\"\"\n    Runs K preconditioned Richardson iterations and computes global mass error.\n    \"\"\"\n    n = B.shape[0]\n    \n    # Extract L and U factors from the in-place factorized matrix P_fact\n    P_csr = P_fact.tocsr()\n    U = sp.triu(P_csr, format='csr')\n    L = sp.tril(P_csr, k=-1, format='csr') + sp.identity(n, format='csr')\n\n    x = np.zeros(n)\n    mass_b = np.sum(b)\n    mass_errors = []\n\n    for _ in range(K):\n        # Calculate residual: r = b - Bx\n        residual = b - B.dot(x)\n        \n        # Solve P * delta_x = r, which implies LU * delta_x = residual\n        # 1. Solve Lz = residual (forward substitution)\n        z = spsolve_triangular(L, residual, lower=True)\n        # 2. Solve U * delta_x = z (backward substitution)\n        delta_x = spsolve_triangular(U, z, lower=False)\n\n        # Update solution: x_{k+1} = x_k + delta_x (omega=1)\n        x += delta_x\n\n        # Calculate and store the global mass error for this iteration\n        mass_x = np.sum(x)\n        error = np.abs(mass_x - mass_b)\n        mass_errors.append(error)\n\n    return mass_errors\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and generate the final output.\n    \"\"\"\n    test_cases = [\n        # (Nx, Ny, ux, uy, kappa, dt, seed)\n        (10, 10, 1.0, 0.3, 0.02, 0.1, 42),\n        (8, 8, 0.0, 0.0, 0.1, 0.2, 7),\n        (16, 4, 3.0, -1.0, 0.005, 0.05, 123),\n        (12, 6, -2.0, 2.5, 0.01, 0.08, 2024),\n    ]\n\n    all_results = []\n    \n    for params in test_cases:\n        Nx, Ny, ux, uy, kappa, dt, seed = params\n        \n        # 1. Assemble the linear system\n        B, b = assemble_system(Nx, Ny, ux, uy, kappa, dt, seed)\n        \n        # 2. Perform ILU(0) factorization and run iterations\n        P_ilu_lil = B.copy().tolil()\n        P_ilu_fact = perform_factorization(P_ilu_lil, is_milu=False)\n        errors_ilu = run_richardson_iterations(B, b, P_ilu_fact, K=3)\n        \n        # 3. Perform MILU(0) factorization and run iterations\n        P_milu_lil = B.copy().tolil()\n        P_milu_fact = perform_factorization(P_milu_lil, is_milu=True)\n        errors_milu = run_richardson_iterations(B, b, P_milu_fact, K=3)\n        \n        # 4. Interleave results and format for output\n        case_results = []\n        for i in range(3):\n            case_results.append(errors_ilu[i])\n            case_results.append(errors_milu[i])\n        \n        formatted_results = [f\"{x:.6e}\" for x in case_results]\n        all_results.append(f\"[{','.join(formatted_results)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3604408"}]}