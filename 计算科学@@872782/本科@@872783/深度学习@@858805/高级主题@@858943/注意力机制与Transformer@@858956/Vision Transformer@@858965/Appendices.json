{"hands_on_practices": [{"introduction": "与原始Vision Transformer的单一分辨率tokens网格不同，现代的层次化ViT通过在网络的不同阶段合并tokens来构建多尺度特征，从而提高效率。本练习旨在通过计算分析这种架构，让你亲手推导tokens数量、注意力范围和计算成本在各阶段如何变化。这有助于你深入理解像Swin Transformer这样的模型是如何在性能和效率之间取得平衡的。[@problem_id:3199139]", "problem": "一个分层视觉变换器（ViT）处理图像时，首先将非重叠的图像块嵌入为令牌（token），然后在不同阶段通过图像块合并来降低令牌的空间分辨率。假设输入图像的高度为 $H$，宽度为 $W$，初始方形图像块大小为 $p$，并采用一个具有 $S=3$ 个阶段的分层架构，其中阶段 $s=0$ 是初始令牌化阶段，阶段 $s=1$ 和 $s=2$ 执行图像块合并。在每个合并阶段，一个 $2\\times 2$ 的令牌组被合并成一个单一的令牌，从而使令牌网格的高度和宽度维度都减半。设 $N_h^{(0)}=\\frac{H}{p}$ 和 $N_w^{(0)}=\\frac{W}{p}$ 表示初始令牌网格的维度，并假设对于所有相关的 $s$， $H$ 和 $W$ 都能被 $p\\cdot 2^s$ 整除，以确保所有令牌计数均为整数。\n\n多头自注意力（MHSA）可以在全局范围内计算，也可以在局部窗口内计算。对于阶段 $s\\in\\{0,1,2\\}$，假设注意力被限制在阶段 $s$ 网格中的一个 $a_s\\times b_s$ 令牌的局部窗口内（假设所有令牌的窗口大小统一，并通过使用窗口面积和阶段令牌计数之间的较小值来忽略边界效应）。将阶段 $s$ 的令牌数量定义为 $L_s = N_h^{(s)}\\cdot N_w^{(s)}$，其中 $N_h^{(s)}=\\frac{N_h^{(0)}}{2^s}$ 且 $N_w^{(s)}=\\frac{N_w^{(0)}}{2^s}$。将阶段 $s$ 每个查询的有效键数定义为 $W_s=\\min\\{L_s,\\,a_s\\cdot b_s\\}$。将阶段 $s$ 的注意力范围收缩比定义为 $r_s=\\frac{W_s}{L_s}$，并将相对注意力计算量（以阶段 $s=0$ 的全局全注意力计算量为基准进行归一化）定义为 $c_s=\\frac{L_s\\cdot W_s}{L_0^2}$。\n\n从上述关于图像块嵌入、分层图像块合并和注意力窗口化的基础知识出发，推导出各阶段的令牌计数和注意力指标，并实现一个程序，为每个测试用例计算列表 $[L_0, L_1, L_2, r_0, r_1, r_2, c_0, c_1, c_2]$。\n\n使用以下测试套件，其中每个用例由 $(H, W, p, (a_0,b_0), (a_1,b_1), (a_2,b_2))$ 给出：\n- 用例 1：$(H,W,p)=(224,224,8)$，窗口大小 $(a_0,b_0)=(7,7)$，$(a_1,b_1)=(7,7)$，$(a_2,b_2)=(7,7)$。\n- 用例 2：$(H,W,p)=(128,128,8)$，窗口大小 $(a_0,b_0)=(9,9)$，$(a_1,b_1)=(9,9)$，$(a_2,b_2)=(9,9)$。\n- 用例 3：$(H,W,p)=(96,96,8)$，窗口大小 $(a_0,b_0)=(4,6)$，$(a_1,b_1)=(4,6)$，$(a_2,b_2)=(4,6)$。\n\n你的程序应生成单行输出，其中包含一个由方括号括起来的、逗号分隔的结果列表。具体来说，输出一个包含三个子列表的列表，每个测试用例对应一个子列表，其中每个子列表为 $[L_0, L_1, L_2, r_0, r_1, r_2, c_0, c_1, c_2]$，因此最终输出格式形如 $[[\\dots],[\\dots],[\\dots]]$。输出必须是数值（整数或浮点数），且程序不得读取任何输入或文件。", "solution": "该问题已经过验证，被认为是具有科学依据、定义明确且内容自洽的。其定义和参数建模了一个简化但标准的分层视觉变换器（ViT），所需的计算基于清晰且无矛盾的数学公式。\n\n任务是为一个分层 ViT 在其 $S=3$ 个阶段（由 $s \\in \\{0, 1, 2\\}$ 索引）中计算一组指标。每个阶段 $s$ 的指标包括令牌数 $L_s$、注意力范围收缩比 $r_s$ 以及相对注意力计算量 $c_s$。这些指标需要为三个不同的测试用例进行计算。\n\n我们首先根据给定的信息，形式化推导每个指标。每个用例的输入参数是图像维度 $(H, W)$、初始图像块大小 $p$ 以及各阶段的注意力窗口大小 $((a_0, b_0), (a_1, b_1), (a_2, b_2))$。\n\n**1. 各阶段令牌数 ($L_s$):**\n该过程从阶段 $s=0$ 开始，将大小为 $H \\times W$ 的输入图像分割成大小为 $p \\times p$ 的非重叠图像块。这会产生一个初始的令牌网格。\n沿高度和宽度的初始令牌数分别为：\n$$N_h^{(0)} = \\frac{H}{p}$$\n$$N_w^{(0)} = \\frac{W}{p}$$\n因此，阶段 $s=0$ 的总令牌数为：\n$$L_0 = N_h^{(0)} \\cdot N_w^{(0)}$$\n对于后续的阶段 $s=1$ 和 $s=2$，会执行图像块合并操作。来自阶段 $s-1$ 的一个 $2 \\times 2$ 的令牌组被合并为阶段 $s$ 的一个单一令牌。这使得在每个合并阶段，令牌网格的维度在每个轴向上都减少一半。阶段 $s$ 的令牌网格维度由以下递推关系给出：\n$$N_h^{(s)} = \\frac{N_h^{(s-1)}}{2}, \\quad N_w^{(s)} = \\frac{N_w^{(s-1)}}{2}$$\n这可以用初始网格维度表示为：\n$$N_h^{(s)} = \\frac{N_h^{(0)}}{2^s}, \\quad N_w^{(s)} = \\frac{N_w^{(0)}}{2^s}$$\n阶段 $s$ 的总令牌数 $L_s$ 是其网格维度的乘积：\n$$L_s = N_h^{(s)} \\cdot N_w^{(s)} = \\left(\\frac{N_h^{(0)}}{2^s}\\right) \\cdot \\left(\\frac{N_w^{(0)}}{2^s}\\right) = \\frac{N_h^{(0)} N_w^{(0)}}{4^s} = \\frac{L_0}{4^s}$$\n\n**2. 注意力指标 ($W_s, r_s, c_s$):**\n多头自注意力（MHSA）机制在一个大小为 $a_s \\times b_s$ 令牌的窗口内局部应用。每个查询令牌所关注的键值对数量受此窗口大小的限制。\n每个查询的有效键数 $W_s$ 是注意力窗口的面积 $a_s \\cdot b_s$，除非该窗口大于该阶段的整个令牌网格。在这种情况下，注意力在该阶段变为全局性的，每个令牌关注所有 $L_s$ 个令牌。这由以下定义捕获：\n$$W_s = \\min\\{L_s, a_s \\cdot b_s\\}$$\n注意力范围收缩比 $r_s$ 量化了注意力的局部化程度。它是有效键数与该阶段总令牌数的比率：\n$$r_s = \\frac{W_s}{L_s}$$\n$r_s=1$ 的值表示阶段 $s$ 的注意力是全局的。\n\n相对注意力计算量 $c_s$ 将阶段 $s$ 的窗口化注意力的计算成本（与 $L_s \\cdot W_s$ 成正比）通过阶段 $s=0$ 的全局注意力成本（与 $L_0^2$ 成正比）进行归一化。这提供了一个相对于最昂贵基线的各阶段计算负荷的度量。\n$$c_s = \\frac{L_s \\cdot W_s}{L_0^2}$$\n请注意，对于 $s=0$，这可以简化为 $c_0 = \\frac{L_0 \\cdot W_0}{L_0^2} = \\frac{W_0}{L_0} = r_0$。\n\n**用例 1 的计算示例：**\n让我们将这些公式应用于第一个测试用例：$(H,W,p)=(224, 224, 8)$ 且所有阶段 $s \\in \\{0, 1, 2\\}$ 的窗口大小为 $(a_s,b_s)=(7,7)$。\n\n**阶段 $s=0$：**\n- 初始网格：$N_h^{(0)} = \\frac{224}{8} = 28$， $N_w^{(0)} = \\frac{224}{8} = 28$。\n- 令牌数：$L_0 = 28 \\cdot 28 = 784$。\n- 窗口面积：$a_0 \\cdot b_0 = 7 \\cdot 7 = 49$。\n- 有效键数：$W_0 = \\min\\{784, 49\\} = 49$。\n- 收缩比：$r_0 = \\frac{49}{784} = 0.0625$。\n- 相对计算量：$c_0 = r_0 = 0.0625$。\n\n**阶段 $s=1$：**\n- 令牌数：$L_1 = \\frac{L_0}{4^1} = \\frac{784}{4} = 196$。\n- 窗口面积：$a_1 \\cdot b_1 = 7 \\cdot 7 = 49$。\n- 有效键数：$W_1 = \\min\\{196, 49\\} = 49$。\n- 收缩比：$r_1 = \\frac{49}{196} = 0.25$。\n- 相对计算量：$c_1 = \\frac{L_1 \\cdot W_1}{L_0^2} = \\frac{196 \\cdot 49}{784^2} = \\frac{9604}{614656} = 0.015625$。\n\n**阶段 $s=2$：**\n- 令牌数：$L_2 = \\frac{L_0}{4^2} = \\frac{784}{16} = 49$。\n- 窗口面积：$a_2 \\cdot b_2 = 7 \\cdot 7 = 49$。\n- 有效键数：$W_2 = \\min\\{49, 49\\} = 49$。\n- 收缩比：$r_2 = \\frac{49}{49} = 1.0$。\n- 相对计算量：$c_2 = \\frac{L_2 \\cdot W_2}{L_0^2} = \\frac{49 \\cdot 49}{784^2} = \\frac{2401}{614656} = 0.00390625$。\n\n用例 1 的最终向量是 $[L_0, L_1, L_2, r_0, r_1, r_2, c_0, c_1, c_2]$，即 $[784, 196, 49, 0.0625, 0.25, 1.0, 0.0625, 0.015625, 0.00390625]$。对所有测试用例重复此过程以生成最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# No other libraries are used.\n\ndef solve():\n    \"\"\"\n    Calculates and prints hierarchical ViT metrics for a suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (H, W, p, (a0, b0), (a1, b1), (a2, b2))\n    test_cases = [\n        (224, 224, 8, (7, 7), (7, 7), (7, 7)),\n        (128, 128, 8, (9, 9), (9, 9), (9, 9)),\n        (96, 96, 8, (4, 6), (4, 6), (4, 6)),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack the parameters for the current test case.\n        H, W, p, win0, win1, win2 = case\n        all_windows = [win0, win1, win2]\n\n        # Use numpy types for precision and to adhere to the specified environment.\n        H, W, p = np.int64(H), np.int64(W), np.int64(p)\n\n        # --- Stage 0 Calculations ---\n        # Initial token grid dimensions.\n        Nh0 = H / p\n        Nw0 = W / p\n        # Initial total number of tokens.\n        L0_val = Nh0 * Nw0\n\n        # Lists to store the 9 metrics to be calculated.\n        Ls = []\n        rs = []\n        cs = []\n\n        # --- Stagewise Calculation Loop (s = 0, 1, 2) ---\n        for s in range(3):\n            # Calculate L_s: Total tokens at stage s.\n            # L_s = L_0 / 4^s\n            ls_val = L0_val / np.power(4, s, dtype=np.int64)\n            Ls.append(int(ls_val))\n\n            # Calculate W_s: Effective number of keys per query.\n            # W_s = min(L_s, a_s * b_s)\n            a_s, b_s = all_windows[s]\n            window_area = np.int64(a_s * b_s)\n            ws_val = np.min([ls_val, window_area])\n            \n            # Calculate r_s: Attention range shrinkage ratio.\n            # r_s = W_s / L_s\n            rs_val = ws_val / ls_val\n            rs.append(rs_val)\n            \n            # Calculate c_s: Relative attention compute.\n            # c_s = (L_s * W_s) / L_0^2\n            cs_val = (ls_val * ws_val) / np.power(L0_val, 2)\n            cs.append(cs_val)\n\n        # Combine the lists into a single result vector for the current case.\n        # Format: [L0, L1, L2, r0, r1, r2, c0, c1, c2]\n        current_result = Ls + rs + cs\n        results.append(current_result)\n\n    # Final print statement in the exact required format.\n    # e.g., [[val1, val2, ...], [val1, val2, ...], ...]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3199139"}, {"introduction": "直接训练Vision Transformer需要大量数据，而知识蒸馏是一种有效的解决方案，它借助一个强大的“教师”模型来指导“学生”ViT的学习。本练习将让你实践DeiT模型中的核心思想，通过计算结合了交叉熵和KL散度的蒸馏损失，来理解模型如何同时学习硬标签和教师模型的软知识。此外，你还将分析注意力图谱，以洞察这种训练策略对模型内部机制的影响。[@problem_id:3199218]", "problem": "要求您从第一性原理出发，对从卷积神经网络 (CNN) 教师网络中蒸馏出的数据高效图像 Transformer (DeiT) 进行推理，并实现一个程序来计算基于原理的蒸馏损失并分析学习到的注意力模式。重点是视觉 Transformer (ViT)、Kullback-Leibler 散度 (KL)、交叉熵 (CE) 和多头自注意力。从概率论和优化的基本定义和经过充分检验的事实出发，不要依赖这些定义之外的快捷公式。\n\n场景如下：一个视觉 Transformer (ViT) 学生网络生成类别 logits，一个卷积神经网络 (CNN) 教师网络生成类别 logits，并且有一个独热编码的真实标签。蒸馏结合了一个使学生网络的预测分布与教师网络的预测分布对齐的项，以及一个强制忠实于真实标签的项。注意力模式表示为每个头和层中对 token 的行随机矩阵，您必须从中计算信息论和对齐度量，以表征注意力的分布方式及其与教师提供的空间引导分布的对齐情况。\n\n您的任务是：\n- 从第一性原理出发，推导由两个基于基本定义构建的目标的加权和定义的复合蒸馏损失：Kullback-Leibler 散度和交叉熵。证明这将产生一个标量目标，形式为 $\\mathcal{L} = \\lambda \\, \\mathrm{KL}(p_{\\text{ViT}} \\| p_{\\text{teacher}}) + (1-\\lambda) \\, \\mathcal{L}_{\\text{CE}}$，其中 $p_{\\text{ViT}}$ 和 $p_{\\text{teacher}}$ 是通过将 softmax 函数应用于各自 logits 得到的预测分布，$\\lambda \\in [0,1]$，而 $\\mathcal{L}_{\\text{CE}}$ 是与独热编码的真实标签之间的交叉熵。\n- 实现以下计算：\n  1. 对学生和教师的 logits 计算 softmax 分布 $p_i = \\exp(z_i) / \\sum_j \\exp(z_j)$。\n  2. 使用 $p = p_{\\text{ViT}}$ 和 $q = p_{\\text{teacher}}$ 计算 Kullback-Leibler 散度 $\\mathrm{KL}(p \\| q) = \\sum_i p_i \\big( \\log p_i - \\log q_i \\big)$。\n  3. 使用独热编码的真实标签向量 $y$ 和 $p = p_{\\text{ViT}}$ 计算交叉熵 $\\mathcal{L}_{\\text{CE}} = - \\sum_i y_i \\log p_i$。\n  4. 按上述规定计算蒸馏损失 $\\mathcal{L}$。\n  5. 注意力分析：\n     - 给定每个层 $l$ 和头 $h$ 的多头自注意力矩阵 $A^{(l,h)} \\in \\mathbb{R}^{N \\times N}$，其中 $N$ 是 token 的数量，每一行是目标 token 上的一个概率分布。提取类别 token 的注意力行（行索引为 0），并将其限制在图像块 token 上（列索引从 1 到 N-1）。将这个受限向量重新归一化，使其总和为 1。\n     - 计算这些受限的类别 token 注意力分布在所有层和头上的平均香农熵：$H = - \\sum_{i} a_i \\log a_i$，在所有头和层上取平均值。\n     - 计算平均类别 token 图像块注意力向量（在各层和各头上取平均，然后重新归一化使其总和为 1）与教师提供的图像块级引导向量 $g$（重新归一化使其总和为 1）之间的余弦相似度对齐：$\\mathrm{cos}(\\theta) = \\dfrac{\\langle a, g \\rangle}{\\|a\\|_2 \\, \\|g\\|_2}$。\n\n角度单位不适用。没有物理单位。所有输出必须是实数。\n\n测试套件：\n提供以下四个测试用例。在每个用例中，类别数为 3，token 数量为 $N=5$（一个类别 token 加四个图像块 token），注意力矩阵有 $L=2$ 个层和 $H=2$ 个头。为简单起见，对于类别 token 行以外的行，可以假设为均匀分布。\n\n- 测试用例 1 (正常路径):\n  - 学生网络 logits $z_{\\text{ViT}} = [2.0, 0.5, -1.0]$\n  - 教师网络 logits $z_{\\text{teacher}} = [3.0, -0.5, -2.0]$\n  - 真实独热标签 $y = [1, 0, 0]$\n  - 权重 $\\lambda = 0.5$\n  - 教师图像块引导 $g = [0.4, 0.4, 0.1, 0.1]$\n  - 注意力矩阵 $A^{(l,h)}$，$L=2$, $H=2$, $N=5$:\n    - 第 1 层，第 1 个头，各行：\n      - 第 0 行：$[0.1, 0.5, 0.3, 0.05, 0.05]$\n      - 第 1 行：$[0.2, 0.2, 0.2, 0.2, 0.2]$\n      - 第 2 行：$[0.2, 0.2, 0.2, 0.2, 0.2]$\n      - 第 3 行：$[0.2, 0.2, 0.2, 0.2, 0.2]$\n      - 第 4 行：$[0.2, 0.2, 0.2, 0.2, 0.2]$\n    - 第 1 层，第 2 个头，各行：\n      - 第 0 行：$[0.15, 0.45, 0.25, 0.10, 0.05]$\n      - 其他行为相同的均匀分布 $[0.2, 0.2, 0.2, 0.2, 0.2]$\n    - 第 2 层，第 1 个头，各行：\n      - 第 0 行：$[0.12, 0.55, 0.20, 0.08, 0.05]$\n      - 其他行：均匀分布 $[0.2, 0.2, 0.2, 0.2, 0.2]$\n    - 第 2 层，第 2 个头，各行：\n      - 第 0 行：$[0.10, 0.50, 0.25, 0.10, 0.05]$\n      - 其他行：均匀分布 $[0.2, 0.2, 0.2, 0.2, 0.2]$\n\n- 测试用例 2 (边界条件 $\\lambda = 1$ 且预测相同):\n  - 学生网络 logits $z_{\\text{ViT}} = [1.2, -0.1, 0.0]$\n  - 教师网络 logits $z_{\\text{teacher}} = [1.2, -0.1, 0.0]$\n  - 真实独热标签 $y = [0, 1, 0]$\n  - 权重 $\\lambda = 1.0$\n  - 教师图像块引导 $g = [0.7, 0.1, 0.1, 0.1]$\n  - 注意力矩阵 $A^{(l,h)}$，类别 token 注意力分散（所有类别 token 行为均匀分布）：\n    - 对于所有 $l \\in \\{1,2\\}$ 和 $h \\in \\{1,2\\}$，第 0 行：$[0.2, 0.2, 0.2, 0.2, 0.2]$\n    - 其他行：均匀分布 $[0.2, 0.2, 0.2, 0.2, 0.2]$\n\n- 测试用例 3 (边界条件 $\\lambda = 0$ 且学生网络为均匀分布):\n  - 学生网络 logits $z_{\\text{ViT}} = [0.0, 0.0, 0.0]$\n  - 教师网络 logits $z_{\\text{teacher}} = [0.5, -0.2, 0.1]$\n  - 真实独热标签 $y = [0, 0, 1]$\n  - 权重 $\\lambda = 0.0$\n  - 教师图像块引导 $g = [0.2, 0.3, 0.3, 0.2]$\n  - 注意力矩阵 $A^{(l,h)}$，类别 token 注意力集中在一个图像块上：\n    - 第 1 层，第 1 个头，第 0 行：$[0.05, 0.10, 0.80, 0.03, 0.02]$\n    - 第 1 层，第 2 个头，第 0 行：$[0.04, 0.12, 0.78, 0.04, 0.02]$\n    - 第 2 层，第 1 个头，第 0 行：$[0.06, 0.08, 0.80, 0.04, 0.02]$\n    - 第 2 层，第 2 个头，第 0 行：$[0.05, 0.10, 0.75, 0.06, 0.04]$\n    - 其他行：均匀分布 $[0.2, 0.2, 0.2, 0.2, 0.2]$\n\n- 测试用例 4 (空间引导错位的边缘情况):\n  - 学生网络 logits $z_{\\text{ViT}} = [0.3, 1.0, -0.7]$\n  - 教师网络 logits $z_{\\text{teacher}} = [-0.2, 2.5, -1.0]$\n  - 真实独热标签 $y = [0, 1, 0]$\n  - 权重 $\\lambda = 0.8$\n  - 教师图像块引导 $g = [0.50, 0.20, 0.20, 0.10]$\n  - 注意力矩阵 $A^{(l,h)}$，类别 token 注意力偏向于后面的图像块：\n    - 第 1 层，第 1 个头，第 0 行：$[0.05, 0.10, 0.20, 0.30, 0.35]$\n    - 第 1 层，第 2 个头，第 0 行：$[0.05, 0.15, 0.20, 0.25, 0.35]$\n    - 第 2 层，第 1 个头，第 0 行：$[0.04, 0.12, 0.18, 0.30, 0.36]$\n    - 第 2 层，第 2 个头，第 0 行：$[0.06, 0.10, 0.22, 0.28, 0.34]$\n    - 其他行：均匀分布 $[0.2, 0.2, 0.2, 0.2, 0.2]$\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果。每个条目必须是 $[\\mathcal{L}, H, \\mathrm{cos}(\\theta)]$ 顺序的三元素列表，其中 $\\mathcal{L}$ 是蒸馏损失，H 是类别 token 在图像块 token 上的平均注意力熵，$\\mathrm{cos}(\\theta)$ 是与 $g$ 的余弦相似度对齐。例如，输出格式必须类似于 $[[l_1,h_1,c_1],[l_2,h_2,c_2],[l_3,h_3,c_3],[l_4,h_4,c_4]]$，其中包含从 1 到 4 的每个测试用例的数值。", "solution": "用户提供的问题是有效的，因为它具有科学依据、问题明确且客观。它植根于深度学习的既定原则，特别是视觉 Transformer (ViT) 中的知识蒸馏，并使用标准的信息论度量。所有必要的数据和定义都已提供，以确保得出唯一且有意義的解决方案。\n\n### 第 1 部分：从第一性原理推导蒸馏损失\n\n目标是从基本原理推导出复合损失函数 $\\mathcal{L} = \\lambda \\, \\mathrm{KL}(p_{\\text{ViT}} \\| p_{\\text{teacher}}) + (1-\\lambda) \\, \\mathcal{L}_{\\text{CE}}$。该损失函数旨在通过结合两个目标来训练一个学生模型（ViT）：匹配教师模型（CNN）的预测，以及基于真实标签正确分类输入。\n\n1.  **从 Logits 生成概率分布**：\n    一个用于 $K$ 类分类问题的神经网络通常会输出一个原始分数向量，即 logits，记为 $z \\in \\mathbb{R}^K$。为了将这些分数解释为类别上的概率分布，会应用 softmax 函数。对于 logits 向量 $z = [z_1, z_2, \\ldots, z_K]$，第 $i$ 类的概率由下式给出：\n    $$\n    p_i = \\frac{\\exp(z_i)}{\\sum_{j=1}^K \\exp(z_j)}\n    $$\n    设 $p_{\\text{ViT}}$ 是学生 ViT 从其 logits $z_{\\text{ViT}}$ 生成的概率分布，而 $p_{\\text{teacher}}$ 是教师 CNN 从其 logits $z_{\\text{teacher}}$ 生成的分布。\n\n2.  **目标 1：忠于真实标签（交叉熵损失）**：\n    分类模型的主要目标是准确预测真实类别。对于给定的输入，真实标签表示为一个独热向量 $y \\in \\{0, 1\\}^K$，其中对于真实类别 $k$，$y_k=1$，$i \\neq k$ 时 $y_i=0$。训练目标是最大化分配给真实类别的概率 $(p_{\\text{ViT}})_k$。这等同于最大化对数似然 $\\log((p_{\\text{ViT}})_k)$，或者更常见地，最小化负对数似然 $-\\log((p_{\\text{ViT}})_k)$。\n    将其推广到独热向量 $y$，损失为：\n    $$\n    \\mathcal{L}_{\\text{CE}} = - \\sum_{i=1}^K y_i \\log((p_{\\text{ViT}})_i)\n    $$\n    这是真实分布 $y$ 和预测分布 $p_{\\text{ViT}}$ 之间的交叉熵损失的定义。它衡量模型预测与“硬”真实标签之间的不相似性。\n\n3.  **目标 2：知识蒸馏（Kullback-Leibler 散度）**：\n    知识蒸馏旨在将“知识”从一个较大的、预训练的教师模型转移到一个较小的学生模型。教师的知识封装在其输出分布 $p_{\\text{teacher}}$ 中，该分布通过指示不正确类别的相对概率（例如，“猫比汽车更像狗”），提供了比独热标签更丰富的信息。学生模型被训练来模仿这种“软”目标分布。\n    衡量两个概率分布 $P$ 和 $Q$ 之间差异的一个有原则的方法是 Kullback-Leibler (KL) 散度。问题指定了最小化从学生分布到教师分布的 KL 散度，其定义如下：\n    $$\n    \\mathrm{KL}(p_{\\text{ViT}} \\| p_{\\text{teacher}}) = \\sum_{i=1}^K (p_{\\text{ViT}})_i \\log\\left(\\frac{(p_{\\text{ViT}})_i}{(p_{\\text{teacher}})_i}\\right) = \\sum_{i=1}^K (p_{\\text{ViT}})_i \\left( \\log((p_{\\text{ViT}})_i) - \\log((p_{\\text{teacher}})_i) \\right)\n    $$\n    最小化此项会促使 $p_{\\text{ViT}}$ 变得与 $p_{\\text{teacher}}$ 相似。当且仅当分布完全相同时，散度为零。\n\n4.  **复合蒸馏损失**：\n    最终的损失函数是这两个目标的凸组合，由超参数 $\\lambda \\in [0, 1]$ 平衡。权重 $\\lambda$ 控制着从教师的软目标学习与从硬真实标签学习之间的权衡。\n    复合损失 $\\mathcal{L}$ 的公式为：\n    $$\n    \\mathcal{L} = \\lambda \\cdot (\\text{蒸馏目标}) + (1-\\lambda) \\cdot (\\text{保真度目标})\n    $$\n    代入每个目标的推导表达式，得到最终形式：\n    $$\n    \\mathcal{L} = \\lambda \\, \\mathrm{KL}(p_{\\text{ViT}} \\| p_{\\text{teacher}}) + (1-\\lambda) \\, \\mathcal{L}_{\\text{CE}}\n    $$\n    推导至此完成。\n\n### 第 2 部分：计算的实现\n\n实现将遵循推导出的原理和问题陈述中概述的步骤。\n\n1.  **Softmax**: 对于给定的 logits $z$，计算 $p_i = \\exp(z_i) / \\sum_j \\exp(z_j)$。使用数值稳定版本。\n2.  **Kullback-Leibler 散度**: 计算 $\\mathrm{KL}(p \\| q) = \\sum_i p_i (\\log p_i - \\log q_i)$。\n3.  **交叉熵损失**: 计算 $\\mathcal{L}_{\\text{CE}} = - \\sum_i y_i \\log p_i$。鉴于 $y$ 是独热编码，这简化为 $-\\log p_k$，其中 $y_k=1$。\n4.  **蒸馏损失**: 将上述组合为 $\\mathcal{L} = \\lambda \\cdot \\mathrm{KL}(p_{\\text{ViT}} \\| p_{\\text{teacher}}) + (1-\\lambda) \\cdot \\mathcal{L}_{\\text{CE}}$。\n5.  **注意力分析**：\n    - **类别 Token 注意力**: 对于每个注意力矩阵 $A^{(l,h)}$，提取第一行（索引为 0）。该行表示从类别 token 到所有其他 token 的注意力。\n    - **图像块注意力**: 此向量被限制为其对应于图像块 token 的分量（索引从 1 到 N-1）。\n    - **重新归一化**: 受限向量被重新归一化，使其总和为 1，从而在图像块 token 上产生一个概率分布 $a^{(l,h)}$。\n    - **平均熵**: 对 $L \\times H$ 个重新归一化的图像块注意力向量中的每一个计算香农熵 $H(a) = -\\sum_i a_i \\log a_i$（使用自然对数）。最终度量 $H$ 是这些单个熵的平均值。\n    - **对齐**: 通过对所有 $a^{(l,h)}$ 向量进行逐元素平均，然后重新歸一化，计算出平均图像块注意力向量 $\\bar{a}$。教师引导向量 $g$ 也被重新归一化为概率分布 $g'$。计算余弦相似度 $\\mathrm{cos}(\\theta) = \\frac{\\langle \\bar{a}, g' \\rangle}{\\|\\bar{a}\\|_2 \\, \\|g'\\|_2}$ 以衡量学生模型的平均空间注意力焦点与教师指导之间的一致性。\n\n将为所提供的四个测试用例中的每一个执行这些计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the DeiT distillation and attention analysis problem for the given test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test Case 1 (happy path)\n        {\n            \"z_vit\": np.array([2.0, 0.5, -1.0]),\n            \"z_teacher\": np.array([3.0, -0.5, -2.0]),\n            \"y_true\": np.array([1, 0, 0]),\n            \"lambda_val\": 0.5,\n            \"g_guidance\": np.array([0.4, 0.4, 0.1, 0.1]),\n            \"attention_matrices\": [\n                # Layer 1\n                np.array([ # Head 1\n                    [0.1, 0.5, 0.3, 0.05, 0.05],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2]\n                ]),\n                np.array([ # Head 2\n                    [0.15, 0.45, 0.25, 0.10, 0.05],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2]\n                ]),\n                # Layer 2\n                np.array([ # Head 1\n                    [0.12, 0.55, 0.20, 0.08, 0.05],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2]\n                ]),\n                np.array([ # Head 2\n                    [0.10, 0.50, 0.25, 0.10, 0.05],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2],\n                    [0.2, 0.2, 0.2, 0.2, 0.2]\n                ]),\n            ]\n        },\n        # Test Case 2 (boundary lambda=1 and identical predictions)\n        {\n            \"z_vit\": np.array([1.2, -0.1, 0.0]),\n            \"z_teacher\": np.array([1.2, -0.1, 0.0]),\n            \"y_true\": np.array([0, 1, 0]),\n            \"lambda_val\": 1.0,\n            \"g_guidance\": np.array([0.7, 0.1, 0.1, 0.1]),\n            \"attention_matrices\": [\n                # Uniform class-token attention for all L=2, H=2\n                np.array([[0.2, 0.2, 0.2, 0.2, 0.2]] * 5)\n            ] * 4\n        },\n        # Test Case 3 (boundary lambda=0 and a uniform student)\n        {\n            \"z_vit\": np.array([0.0, 0.0, 0.0]),\n            \"z_teacher\": np.array([0.5, -0.2, 0.1]),\n            \"y_true\": np.array([0, 0, 1]),\n            \"lambda_val\": 0.0,\n            \"g_guidance\": np.array([0.2, 0.3, 0.3, 0.2]),\n            \"attention_matrices\": [\n                # L1H1\n                 np.array([[0.05, 0.10, 0.80, 0.03, 0.02], [0.2]*5, [0.2]*5, [0.2]*5, [0.2]*5]),\n                # L1H2\n                 np.array([[0.04, 0.12, 0.78, 0.04, 0.02], [0.2]*5, [0.2]*5, [0.2]*5, [0.2]*5]),\n                # L2H1\n                 np.array([[0.06, 0.08, 0.80, 0.04, 0.02], [0.2]*5, [0.2]*5, [0.2]*5, [0.2]*5]),\n                # L2H2\n                 np.array([[0.05, 0.10, 0.75, 0.06, 0.04], [0.2]*5, [0.2]*5, [0.2]*5, [0.2]*5]),\n            ]\n        },\n        # Test Case 4 (edge case with misaligned spatial guidance)\n        {\n            \"z_vit\": np.array([0.3, 1.0, -0.7]),\n            \"z_teacher\": np.array([-0.2, 2.5, -1.0]),\n            \"y_true\": np.array([0, 1, 0]),\n            \"lambda_val\": 0.8,\n            \"g_guidance\": np.array([0.50, 0.20, 0.20, 0.10]),\n            \"attention_matrices\": [\n                # L1H1\n                np.array([[0.05, 0.10, 0.20, 0.30, 0.35], [0.2]*5, [0.2]*5, [0.2]*5, [0.2]*5]),\n                # L1H2\n                np.array([[0.05, 0.15, 0.20, 0.25, 0.35], [0.2]*5, [0.2]*5, [0.2]*5, [0.2]*5]),\n                # L2H1\n                np.array([[0.04, 0.12, 0.18, 0.30, 0.36], [0.2]*5, [0.2]*5, [0.2]*5, [0.2]*5]),\n                # L2H2\n                np.array([[0.06, 0.10, 0.22, 0.28, 0.34], [0.2]*5, [0.2]*5, [0.2]*5, [0.2]*5]),\n            ]\n        }\n    ]\n\n    def softmax(z):\n        \"\"\"Computes a numerically stable softmax distribution.\"\"\"\n        e_z = np.exp(z - np.max(z))\n        return e_z / e_z.sum()\n\n    def kl_divergence(p, q):\n        \"\"\"Computes KL-divergence KL(p || q).\"\"\"\n        return np.sum(p * (np.log(p) - np.log(q)))\n\n    def cross_entropy(y_true, p_pred):\n        \"\"\"Computes cross-entropy loss.\"\"\"\n        # Since y_true is one-hot, find the index of the true class\n        true_class_idx = np.argmax(y_true)\n        # Loss is the negative log probability of the true class\n        return -np.log(p_pred[true_class_idx])\n\n    def shannon_entropy(p):\n        \"\"\"Computes Shannon entropy H(p) using natural logarithm.\"\"\"\n        # Filter out zero probabilities to avoid log(0)\n        p_nz = p[p > 0]\n        return -np.sum(p_nz * np.log(p_nz))\n\n    def cosine_similarity(v1, v2):\n        \"\"\"Computes cosine similarity between two vectors.\"\"\"\n        dot_product = np.dot(v1, v2)\n        norm_v1 = np.linalg.norm(v1)\n        norm_v2 = np.linalg.norm(v2)\n        if norm_v1 == 0 or norm_v2 == 0:\n            return 0.0\n        return dot_product / (norm_v1 * norm_v2)\n\n    results = []\n    # Process each test case\n    for case in test_cases:\n        # --- Loss Calculation ---\n        p_vit = softmax(case[\"z_vit\"])\n        p_teacher = softmax(case[\"z_teacher\"])\n        \n        l_kl = kl_divergence(p_vit, p_teacher)\n        l_ce = cross_entropy(case[\"y_true\"], p_vit)\n        \n        distillation_loss = case[\"lambda_val\"] * l_kl + (1 - case[\"lambda_val\"]) * l_ce\n\n        # --- Attention Analysis ---\n        entropies = []\n        renormalized_attentions = []\n        \n        for A in case[\"attention_matrices\"]:\n            # Extract class token attention row (index 0)\n            class_token_attn = A[0, :]\n            # Restrict to patch tokens (indices 1 to N-1)\n            patch_attn_raw = class_token_attn[1:]\n            \n            # Renormalize to sum to 1\n            patch_attn_sum = patch_attn_raw.sum()\n            if patch_attn_sum > 0:\n                renormalized_patch_attn = patch_attn_raw / patch_attn_sum\n            else: # Handle case of zero sum to avoid division by zero\n                # If all patch attentions are 0, create a uniform distribution\n                n_patches = len(patch_attn_raw)\n                renormalized_patch_attn = np.ones(n_patches) / n_patches\n                \n            renormalized_attentions.append(renormalized_patch_attn)\n            entropies.append(shannon_entropy(renormalized_patch_attn))\n\n        # Calculate average entropy\n        avg_entropy = np.mean(entropies)\n        \n        # Calculate mean patch attention vector\n        # This is already a probability distribution as it's a convex combination\n        # of probability distributions. Renormalizing again for formal correctness.\n        mean_patch_attn_unnorm = np.mean(renormalized_attentions, axis=0)\n        mean_patch_attn = mean_patch_attn_unnorm / mean_patch_attn_unnorm.sum()\n        \n        # Renormalize teacher guidance vector\n        g_guidance = case[\"g_guidance\"]\n        g_norm = g_guidance / g_guidance.sum()\n        \n        # Calculate cosine similarity\n        alignment = cosine_similarity(mean_patch_attn, g_norm)\n        \n        results.append([distillation_loss, avg_entropy, alignment])\n        \n    # Final print statement in the exact required format.\n    # The str() representation of a list includes spaces after commas, which matches\n    # the implicit formatting in the problem description's LaTeX examples.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3199218"}, {"introduction": "Vision Transformer的一个优势是其架构对输入图像尺寸的灵活性，但这带来了一个实际挑战：如何调整在特定分辨率下学习到的绝对位置编码以适应新的分辨率。本练习探讨了两种常见的位置编码插值策略——最近邻选择和双线性插值。你将通过计算“位置漂移”这一指标，来量化不同插值方法引入的几何误差，从而深刻理解模型输入的几何变换及其对性能的潜在影响。[@problem_id:3199247]", "problem": "给定一个基于视觉Transformer (ViT) 的模型族。视觉Transformer将输入图像切分为一个不重叠图像块组成的网格，并为每个图像块嵌入增加一个绝对位置嵌入。设预训练图像分辨率产生一个 $G_{0}^{(h)} \\times G_{0}^{(w)}$ 的图像块中心网格，其中 $G_{0}^{(h)} \\in \\mathbb{N}$ 和 $G_{0}^{(w)} \\in \\mathbb{N}$ 分别表示沿高度和宽度的图像块数量。在测试时，图像可能会被调整大小，从而产生一个不同的 $G_{1}^{(h)} \\times G_{1}^{(w)}$ 图像块中心网格。绝对位置嵌入仅在预训练网格上定义；因此，在测试时，必须将测试时网格的位置映射到预训练网格，以便为新的令牌构建位置嵌入。考虑两种策略：\n\n- 最近邻选择（无插值）：对于测试时网格索引为 $(i,j)$（其中 $i \\in \\{0,\\dots,G_{1}^{(h)}-1\\}$ 且 $j \\in \\{0,\\dots,G_{1}^{(w)}-1\\}$）的每个令牌，通过对从测试网格到预训练网格的连续映射进行四舍五入，来选择一个单一的预训练网格索引 $(u,v)$。这将产生一个单一的预训练中心，其绝对嵌入被直接重用。\n- 带边界钳位的双线性插值：对于每个位于 $(i,j)$ 的测试时令牌，计算其在预训练网格中的一个连续坐标，然后使用四个最近的预训练中心进行双线性插值。当邻近点的索引超出了有效的预训练索引范围时，将其钳位（clamp）到最近的有效边界索引。\n\n定义一个大小为 $G^{(h)} \\times G^{(w)}$ 的网格中，网格索引 $(i,j)$ 的归一化中心坐标为 $c(i,j;G^{(h)},G^{(w)}) = \\left(\\frac{i+\\frac{1}{2}}{G^{(h)}}, \\frac{j+\\frac{1}{2}}{G^{(w)}}\\right) \\in [0,1]^{2}$。定义与测试时索引 $(i,j)$ 对应的连续预训练网格坐标为 $(\\tilde{u},\\tilde{v}) \\in \\mathbb{R}^{2}$，其满足中心对齐约束 $\\left(\\frac{\\tilde{u}+\\frac{1}{2}}{G_{0}^{(h)}}, \\frac{\\tilde{v}+\\frac{1}{2}}{G_{0}^{(w)}}\\right) = \\left(\\frac{i+\\frac{1}{2}}{G_{1}^{(h)}}, \\frac{j+\\frac{1}{2}}{G_{1}^{(w)}}\\right)$。当在不同网格间移动时，此映射保留了在 $[0,1]^{2}$ 空间中的相对中心位置。\n\n对于给定的策略，将测试时索引 $(i,j)$ 的令牌位置漂移定义为测试时中心 $c(i,j;G_{1}^{(h)},G_{1}^{(w)})$ 与该策略所使用的预训练位置所隐含的中心在 $[0,1]^{2}$ 空间中的欧几里得距离。对于最近邻选择，隐含中心是所选的单个预训练中心。对于双线性插值，隐含中心是在边界钳位下，起作用的预训练中心的双线性重心。通过均方根漂移来聚合所有测试时令牌的漂移，即每个令牌距离平方的均值的平方根。\n\n从坐标归一化和网格重采样的基本原理出发，推导出一个在这两种策略下计算均方根漂移的可计算过程。然后，将其实现为一个程序，对下面的每个测试用例，计算两个浮点数：最近邻选择的均方根漂移和带边界钳位的双线性插值的均方根漂移，并按此顺序排列。\n\n使用以下测试套件，涵盖标称、放大、缩小、矩形变化和极端折叠情况。每个元组列出 $(G_{0}^{(h)}, G_{0}^{(w)}, G_{1}^{(h)}, G_{1}^{(w)})$：\n- 情况 1：$(14, 14, 14, 14)$。\n- 情况 2：$(14, 14, 16, 16)$。\n- 情况 3：$(14, 14, 10, 10)$。\n- 情况 4：$(14, 20, 16, 10)$。\n- 情况 5：$(14, 14, 1, 1)$。\n\n您的程序应生成单行输出，包含一个由方括号括起来的逗号分隔列表，其中数字按 $[\\text{nn}_{1}, \\text{bi}_{1}, \\text{nn}_{2}, \\text{bi}_{2}, \\dots, \\text{nn}_{5}, \\text{bi}_{5}]$ 的顺序排列，每个值都是一个浮点数。此任务不涉及物理单位、角度或百分比。程序不得读取任何输入，且必须能直接运行。", "solution": "该问题定义明确，具有科学依据，并包含足够的信息来推导出唯一、可验证的解决方案。网格重采样、坐标归一化和插值的概念是计算机视觉和数值分析中的标准方法。该问题是将这些原理直接应用于深度学习中的一个特定场景，即视觉Transformer位置嵌入的自适应调整。我们将进行形式化推导。\n\n核心任务是为两种自适应策略计算均方根漂移（RMSD），这两种策略用于将绝对位置嵌入从大小为 $G_{0}^{(h)} \\times G_{0}^{(w)}$ 的预训练网格调整到大小为 $G_{1}^{(h)} \\times G_{1}^{(w)}$ 的测试时网格。该漂移量化了在归一化的 $[0,1]^2$ 空间中，测试令牌的几何中心与其被分配的预训练位置嵌入的有效中心之间的差异。\n\n### 1. 坐标系与映射\n\n设一个网格的大小为 $G^{(h)} \\times G^{(w)}$。对于整数索引为 $(k, l)$（其中 $k \\in \\{0, \\dots, G^{(h)}-1\\}$ 且 $l \\in \\{0, \\dots, G^{(w)}-1\\}$）的令牌，其归一化中心坐标定义为：\n$$\nc(k,l; G^{(h)}, G^{(w)}) = \\left( \\frac{k+0.5}{G^{(h)}}, \\frac{l+0.5}{G^{(w)}} \\right)\n$$\n一个位于 $G_{1}^{(h)} \\times G_{1}^{(w)}$ 网格中索引为 $(i,j)$ 的测试时令牌，其归一化中心为：\n$$\nc_{test}(i,j) = c(i,j; G_{1}^{(h)}, G_{1}^{(w)}) = \\left( \\frac{i+0.5}{G_{1}^{(h)}}, \\frac{j+0.5}{G_{1}^{(w)}} \\right)\n$$\n该问题通过保留此归一化中心，定义了一个到预训练网格坐标 $(\\tilde{u}, \\tilde{v}) \\in \\mathbb{R}^2$ 的连续映射。这给出了以下约束：\n$$\n\\left( \\frac{\\tilde{u}+0.5}{G_{0}^{(h)}}, \\frac{\\tilde{v}+0.5}{G_{0}^{(w)}} \\right) = \\left( \\frac{i+0.5}{G_{1}^{(h)}}, \\frac{j+0.5}{G_{1}^{(w)}} \\right)\n$$\n求解 $\\tilde{u}$ 和 $\\tilde{v}$ 可得显式映射：\n$$\n\\tilde{u}(i) = G_{0}^{(h)} \\left( \\frac{i+0.5}{G_{1}^{(h)}} \\right) - 0.5\n$$\n$$\n\\tilde{v}(j) = G_{0}^{(w)} \\left( \\frac{j+0.5}{G_{1}^{(w)}} \\right) - 0.5\n$$\n这些连续坐标构成了两种重采样策略的基础。\n\n### 2. 策略1：最近邻（NN）选择\n\n在此策略中，将连续坐标 $(\\tilde{u}, \\tilde{v})$ 四舍五入到最近的整数，以选择单个预训练网格索引 $(u, v)$：\n$$\nu = \\text{round}(\\tilde{u})\n$$\n$$\nv = \\text{round}(\\tilde{v})\n$$\n隐含中心是这个单一预训练令牌的归一化中心：\n$$\nc_{implied, NN}(i,j) = c(u,v; G_{0}^{(h)}, G_{0}^{(w)}) = \\left( \\frac{u+0.5}{G_{0}^{(h)}}, \\frac{v+0.5}{G_{0}^{(w)}} \\right)\n$$\n令牌 $(i,j)$ 的平方位置漂移是测试中心与隐含中心之间的平方欧几里得距离：\n$$\nd_{NN}^2(i,j) = || c_{test}(i,j) - c_{implied, NN}(i,j) ||_2^2\n$$\n使用中心对齐约束，我们可以简化此表达式。第一个坐标的差值为：\n$$\nc_{test}^{(h)}(i,j) - c_{implied, NN}^{(h)}(i,j) = \\frac{\\tilde{u}+0.5}{G_{0}^{(h)}} - \\frac{u+0.5}{G_{0}^{(h)}} = \\frac{\\tilde{u}-u}{G_{0}^{(h)}}\n$$\n第二个坐标也存在类似关系。因此，平方漂移为：\n$$\nd_{NN}^2(i,j) = \\left(\\frac{\\tilde{u}-u}{G_{0}^{(h)}}\\right)^2 + \\left(\\frac{\\tilde{v}-v}{G_{0}^{(w)}}\\right)^2\n$$\n总RMSD是所有 $G_{1}^{(h)} \\times G_{1}^{(w)}$ 个测试令牌的这些平方漂移的均值的平方根：\n$$\n\\text{RMSD}_{NN} = \\sqrt{ \\frac{1}{G_{1}^{(h)} G_{1}^{(w)}} \\sum_{i=0}^{G_{1}^{(h)}-1} \\sum_{j=0}^{G_{1}^{(w)}-1} d_{NN}^2(i,j) }\n$$\n\n### 3. 策略2：带边界钳位的双线性插值（BI）\n\n此策略使用围绕连续坐标 $(\\tilde{u}, \\tilde{v})$ 的4个预训练网格中心。设 $u_0 = \\lfloor \\tilde{u} \\rfloor$，$u_1 = u_0+1$，$v_0 = \\lfloor \\tilde{v} \\rfloor$，$v_1 = v_0+1$。设小数部分为 $\\Delta u = \\tilde{u} - u_0$ 和 $\\Delta v = \\tilde{v} - v_0$。\n\n关键步骤是边界钳位。预训练索引必须位于 $[0, G_{0}^{(h)}-1]$ 和 $[0, G_{0}^{(w)}-1]$ 范围内。4个角点索引按如下方式进行钳位：\n$$\nu'_0 = \\text{clamp}(u_0, 0, G_0^{(h)}-1) \\quad u'_1 = \\text{clamp}(u_1, 0, G_0^{(h)}-1)\n$$\n$$\nv'_0 = \\text{clamp}(v_0, 0, G_0^{(w)}-1) \\quad v'_1 = \\text{clamp}(v_1, 0, G_0^{(w)}-1)\n$$\n隐含中心是这4个被钳位的预训练中心的归一化坐标的双线性重心。权重由 $\\Delta u$ 和 $\\Delta v$ 决定。隐含中心的高度分量为：\n$$\nc_{implied, BI}^{(h)}(i,j) = \\frac{(1-\\Delta u)(u'_0+0.5) + \\Delta u(u'_1+0.5)}{G_0^{(h)}}\n$$\n宽度分量同理：\n$$\nc_{implied, BI}^{(w)}(i,j) = \\frac{(1-\\Delta v)(v'_0+0.5) + \\Delta v(v'_1+0.5)}{G_0^{(w)}}\n$$\n如果钳位未激活（即 $u'_0=u_0$, $u'_1=u_1$ 等），则高度分量的分子简化为 $\\tilde{u}+0.5$。在这种情况下，$c_{implied, BI}^{(h)}(i,j) = \\frac{\\tilde{u}+0.5}{G_0^{(h)}} = c_{test}^{(h)}(i,j)$，导致零漂移。因此，此策略下的位置漂移完全由边界钳位的非线性效应引起。这在放大（$G_1 > G_0$）时发生，因为 $(\\tilde{u}, \\tilde{v})$ 的范围超出了有效索引范围 $[0, G_0-1]$。\n\n令牌 $(i,j)$ 的平方位置漂移为：\n$$\nd_{BI}^2(i,j) = || c_{test}(i,j) - c_{implied, BI}(i,j) ||_2^2\n$$\n$$\nd_{BI}^2(i,j) = \\left( c_{test}^{(h)}(i,j) - c_{implied, BI}^{(h)}(i,j) \\right)^2 + \\left( c_{test}^{(w)}(i,j) - c_{implied, BI}^{(w)}(i,j) \\right)^2\n$$\n总RMSD通过对所有测试令牌进行平均计算得出：\n$$\n\\text{RMSD}_{BI} = \\sqrt{ \\frac{1}{G_{1}^{(h)} G_{1}^{(w)}} \\sum_{i=0}^{G_{1}^{(h)}-1} \\sum_{j=0}^{G_{1}^{(w)}-1} d_{BI}^2(i,j) }\n$$\n\n### 4. 计算过程\n\n使用NumPy进行向量化计算是高效的。对于每个测试用例 $(G_{0}^{(h)}, G_{0}^{(w)}, G_{1}^{(h)}, G_{1}^{(w)})$：\n1.  创建形状为 $(G_{1}^{(h)}, G_{1}^{(w)})$ 的测试索引 $i$ 和 $j$ 的二维数组。\n2.  以向量化方式计算所有测试令牌的连续预训练坐标 $(\\tilde{u}, \\tilde{v})$。\n3.  对于NN策略，对 $(\\tilde{u}, \\tilde{v})$ 进行四舍五入得到 $(u, v)$，计算隐含中心，计算平方距离，并求其均值的平方根。\n4.  对于BI策略，计算 $\\lfloor \\tilde{u} \\rfloor$、$\\lfloor \\tilde{v} \\rfloor$ 和小数部分 $\\Delta u$、$\\Delta v$。钳位角点索引，计算隐含的重心中心，计算平方距离，并求其均值的平方根。\n5.  存储两个得到的RMSD值。对所有测试用例重复此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Vision Transformer positional drift problem for a suite of test cases.\n    \"\"\"\n\n    # Test suite: each tuple is (G0h, G0w, G1h, G1w)\n    test_cases = [\n        (14, 14, 14, 14),\n        (14, 14, 16, 16),\n        (14, 14, 10, 10),\n        (14, 20, 16, 10),\n        (14, 14, 1, 1),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        G0h, G0w, G1h, G1w = case\n\n        if G1h == 0 or G1w == 0:\n            # Handle trivial case with no tokens to avoid division by zero.\n            results.extend([0.0, 0.0])\n            continue\n            \n        # 1. Create grids of test indices\n        # Generate 1D arrays for i and j coordinates\n        i_coords = np.arange(G1h)\n        j_coords = np.arange(G1w)\n        # Create 2D grids for vectorized computation\n        ii, jj = np.meshgrid(i_coords, j_coords, indexing='ij')\n\n        # 2. Coordinate Mapping\n        # Calculate continuous pretraining coordinates (u_tilde, v_tilde)\n        u_tilde = G0h * (ii + 0.5) / G1h - 0.5\n        v_tilde = G0w * (jj + 0.5) / G1w - 0.5\n\n        # Normalized coordinates of the test tokens\n        c_test_h = (ii + 0.5) / G1h\n        c_test_w = (jj + 0.5) / G1w\n\n        # -------- Strategy 1: Nearest-Neighbor (NN) Selection --------\n        \n        # Round to get nearest pretraining indices. np.round rounds .5 to nearest even.\n        u_nn = np.round(u_tilde)\n        v_nn = np.round(v_tilde)\n\n        # Implied centers from the selected pretraining indices\n        c_implied_nn_h = (u_nn + 0.5) / G0h\n        c_implied_nn_w = (v_nn + 0.5) / G0w\n\n        # Squared Euclidean distance for each token\n        dist_sq_nn = (c_test_h - c_implied_nn_h)**2 + (c_test_w - c_implied_nn_w)**2\n\n        # Root-mean-square drift\n        rmsd_nn = np.sqrt(np.mean(dist_sq_nn))\n        results.append(rmsd_nn)\n\n        # -------- Strategy 2: Bilinear Interpolation (BI) with Border Clamping --------\n\n        # Get floor indices for interpolation\n        u0 = np.floor(u_tilde)\n        v0 = np.floor(v_tilde)\n\n        # Get fractional parts for interpolation weights\n        delta_u = u_tilde - u0\n        delta_v = v_tilde - v0\n\n        # Clamp the four corner indices to the valid pretraining index range\n        u0_clamped = np.clip(u0, 0, G0h - 1)\n        u1_clamped = np.clip(u0 + 1, 0, G0h - 1)\n        v0_clamped = np.clip(v0, 0, G0w - 1)\n        v1_clamped = np.clip(v0 + 1, 0, G0w - 1)\n        \n        # Compute the implied center coordinates (barycenter of clamped indices)\n        # This is a linear interpolation between the centers of the clamped indices\n        implied_center_coord_h = (1 - delta_u) * (u0_clamped + 0.5) + delta_u * (u1_clamped + 0.5)\n        implied_center_coord_w = (1 - delta_v) * (v0_clamped + 0.5) + delta_v * (v1_clamped + 0.5)\n\n        # Normalize the implied center for BI\n        c_implied_bi_h = implied_center_coord_h / G0h\n        c_implied_bi_w = implied_center_coord_w / G0w\n\n        # Squared Euclidean distance for each token\n        dist_sq_bi = (c_test_h - c_implied_bi_h)**2 + (c_test_w - c_implied_bi_w)**2\n\n        # Root-mean-square drift\n        rmsd_bi = np.sqrt(np.mean(dist_sq_bi))\n        results.append(rmsd_bi)\n\n    # Format the final output string as a list of floats\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3199247"}]}