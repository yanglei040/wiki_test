{"hands_on_practices": [{"introduction": "扩张卷积的核心优势在于其能够以较低的计算成本高效地扩大感受野。本练习将引导你定量地理解这一现象，通过推导堆叠扩张卷积层的感受野公式，并将其应用于基因组学中的一个实际场景。通过这个实践[@problem_id:3116399]，你将亲手计算出如何通过调整网络深度来捕捉长距离依赖关系。", "problem": "一个基因组学实验室正在设计一种卷积神经网络（CNN）内的一维扩张卷积架构，用于检测脱氧核糖核酸（DNA）序列中跨越千碱基范围的启动子-增强子相互作用。输入是长度为 $N$（碱基对）的单通道一维信号。该网络由 $L$ 个扩张卷积层堆叠而成，每个卷积层的核大小为 $k=5$，步长为 $s=1$，选择零填充以保持空间长度不变，并且没有池化层。第 $\\ell$ 层的扩张率为 $d_{\\ell} = 2^{\\ell}$，其中 $\\ell = 0, 1, \\dots, L-1$。\n\n从离散卷积的定义和扩张（核抽头的atrous间距）的定义出发，推导出经过 $L$ 层后单个输出位置的感受野 $R_{L}$ 关于 $k$ 和 $\\{d_{\\ell}\\}$ 的表达式。然后，施加要求：感受野必须至少达到预设的上下文长度 $L_{c} = 10^{4}$（碱基对），以捕捉千碱基尺度上的启动子-增强子相互作用。确定满足此要求的最小整数 $L$。最终答案必须是单个整数。除了精确计算外，不需要进行舍入。", "solution": "所述问题具有科学依据、问题明确、客观且自洽。在将深度学习模型应用于基因组学的背景下，所提供的参数是一致且切合实际的。该问题要求对堆叠的扩张卷积的感受野进行标准推导，然后进行直接计算。因此，该问题是有效的，并且可以推导出解决方案。\n\n主要任务是确定一维卷积神经网络的感受野。设 $r_\\ell$ 为经过第 $\\ell$ 层后输出单元的感受野大小，其中层的索引为 $\\ell=0, 1, \\dots, L-1$。输入信号本身可以被认为具有 $r_{-1} = 1$ 的感受野。问题指定了恒定的核大小 $k$、恒定的步长 $s=1$ 和随层变化的扩张率 $d_\\ell$。\n\n一个核大小为 $k$、步长为 $s=1$、扩张率为 $d$ 的单一卷积层会扩大前一层的感受野。第 $\\ell$ 层后的感受野大小 $r_\\ell$ 关于第 $\\ell-1$ 层后的感受野大小 $r_{\\ell-1}$ 的递推关系由下式给出：\n$$r_\\ell = r_{\\ell-1} + (k-1) d_\\ell$$\n这个关系源于第 $\\ell$ 层核中的 $k$ 个抽头中的每一个都“看到”来自第 $\\ell-1$ 层的大小为 $r_{\\ell-1}$ 的感受野。在所有先前层中 $s=1$ 的步长确保了第 $\\ell-1$ 层输出中的相邻单元在输入中具有移动一个位置的感受野。第 $\\ell$ 层的 $k$ 个抽头被一个距离 $d_\\ell$ 分隔。因此，由核增加的总跨度（超出第一个抽头感受野的部分）是 $(k-1)d_\\ell$。\n\n为了求出经过 $L$ 层后的总感受野，我们记为 $R_L$（在我们的记法中对应于 $r_{L-1}$），我们可以从 $r_{-1}=1$ 开始展开递推关系：\n$$r_{L-1} = r_{L-2} + (k-1)d_{L-1}$$\n$$r_{L-1} = \\left( r_{L-3} + (k-1)d_{L-2} \\right) + (k-1)d_{L-1}$$\n$$...$$\n$$r_{L-1} = r_{-1} + \\sum_{i=0}^{L-1} (k-1)d_i$$\n代入 $r_{-1}=1$，我们得到经过 $L$ 层后感受野 $R_L$ 的通用公式：\n$$R_L = 1 + (k-1) \\sum_{\\ell=0}^{L-1} d_\\ell$$\n这就完成了问题的第一部分：推导感受野关于 $k$ 和 $\\{d_\\ell\\}$ 的表达式。\n\n接下来，我们代入问题中提供的具体值。第 $\\ell$ 层的扩张率由 $d_\\ell = 2^\\ell$ 给出。该求和变成一个等比数列：\n$$\\sum_{\\ell=0}^{L-1} d_\\ell = \\sum_{\\ell=0}^{L-1} 2^\\ell = \\frac{2^L - 1}{2-1} = 2^L - 1$$\n将此结果代回 $R_L$ 的表达式，我们得到感受野关于 $k$ 和 $L$ 的表达式：\n$$R_L = 1 + (k-1)(2^L - 1)$$\n问题给出了核大小 $k=5$，并要求感受野 $R_L$ 必须至少为上下文长度 $L_c = 10^4$。我们必须找到满足此条件的最小整数 $L$。\n不等式为：\n$$R_L \\ge L_c$$\n代入表达式和值：\n$$1 + (5-1)(2^L - 1) \\ge 10^4$$\n$$1 + 4(2^L - 1) \\ge 10000$$\n现在我们求解 $L$：\n$$4(2^L - 1) \\ge 9999$$\n$$2^L - 1 \\ge \\frac{9999}{4}$$\n$$2^L - 1 \\ge 2499.75$$\n$$2^L \\ge 2500.75$$\n为了找到满足此不等式的最小整数 $L$，我们可以对两边取以 2 为底的对数：\n$$L \\ge \\log_2(2500.75)$$\n我们可以使用换底公式 $\\log_b(x) = \\frac{\\ln(x)}{\\ln(b)}$ 来计算这个对数：\n$$L \\ge \\frac{\\ln(2500.75)}{\\ln(2)}$$\n对右侧进行数值计算：\n$$L \\ge \\frac{7.824310...}{0.693147...} \\approx 11.28801...$$\n由于层数 $L$ 必须是整数，因此 $L$ 的最小整数值是大于或等于 $11.28801...$ 的最小整数，即 $12$。\n\n我们可以通过检查 $L=11$ 和 $L=12$ 来验证这个结果：\n对于 $L=11$：\n$$R_{11} = 1 + (4)(2^{11} - 1) = 1 + 4(2048-1) = 1 + 4(2047) = 1 + 8188 = 8189$$\n由于 $8189  10000$，所以 $L=11$ 是不够的。\n对于 $L=12$：\n$$R_{12} = 1 + (4)(2^{12} - 1) = 1 + 4(4096-1) = 1 + 4(4095) = 1 + 16380 = 16381$$\n由于 $16381 \\ge 10000$，所以 $L=12$ 是足够的。\n因此，最小整数层数为 $12$。", "answer": "$$ \\boxed{12} $$", "id": "3116399"}, {"introduction": "在实际应用卷积网络时，如何处理信号的边界是一个关键问题，特别是当感受野很大时。标准的零填充（zero padding）会在边界处引入不必要的偏差，影响模型性能。本练习[@problem_id:3116389]将通过编程实践，让你直观地对比零填充和反射填充（reflective padding）对边界效应的影响，从而加深对这些实现细节重要性的理解。", "problem": "给定一个卷积神经网络（CNN）层的一维离散信号模型。设信号为一个序列 $\\{x[n]\\}_{n=0}^{N-1}$，有限脉冲响应核为 $\\{w[m]\\}_{m=0}^{K-1}$，其中核长度为 $K$，扩张因子为 $d \\in \\mathbb{Z}_{0}$。在索引 $i \\in \\{0,1,\\ldots,N-1\\}$ 处，采用“相同”对齐方式的扩张卷积，由卷积的线性、位移不变性以及按扩张因子间隔的样本选择共同定义为\n$$\ny[i] \\triangleq \\sum_{m=0}^{K-1} w[m] \\, x\\big(i + m \\cdot d - o\\big),\n$$\n其中 $o \\triangleq \\left\\lfloor \\frac{(K-1)d}{2} \\right\\rfloor$ 是对齐偏移量。索引 $i + m \\cdot d - o$ 可能会落在有效输入范围 $\\{0,\\ldots,N-1\\}$ 之外，这种情况下需要一个边界扩展规则（填充）来定义 $x[\\cdot]$ 在所有位置上的值。\n\n考虑两种填充规则：\n- 零填充：对于任何整数 $j$，定义 $x_{\\text{zero}}[j] \\triangleq x[j]$（如果 $0 \\le j \\le N-1$），否则 $x_{\\text{zero}}[j] \\triangleq 0$。\n- 反射填充：对于任何整数 $j$，定义反射映射 $r(j)$，它通过在不包含边缘复制的情况下跨越边界反复反射，将任何整数 $j$ 映射到有效范围 $\\{0, \\dots, N-1\\}$ 内。该过程通过迭代应用以下变换直至结果落在 $[0, N-1]$ 内来定义：\n$$\nj' = \n\\begin{cases}\n-j-1,  \\text{if } j  0 \\\\\n2N - j - 1,  \\text{if } j \\ge N\n\\end{cases}\n$$\n并设置 $x_{\\text{refl}}[j] \\triangleq x\\big(r(j)\\big)$，其中 $r(j)$ 是通过反复应用上述变换直到结果在 $[0, N-1]$ 区间内得到的值。\n\n对于给定的扩张因子 $d$，定义“边界索引集”为感受野延伸到信号支撑集之外的索引集合：\n$$\n\\mathcal{B}(d) \\triangleq \\left\\{ i \\in \\{0,\\ldots,N-1\\} \\;\\middle|\\; \\exists\\, m \\in \\{0,\\ldots,K-1\\} \\text{ such that } i + m \\cdot d - o \\notin \\{0,\\ldots,N-1\\} \\right\\}.\n$$\n对于恒定输入 $x[n] \\equiv c$（其中 $c \\in \\mathbb{R}$），定义内部参考输出（即感受野完全位于信号支撑集内部时的输出）为\n$$\ny_{\\text{center}} \\triangleq c \\sum_{m=0}^{K-1} w[m].\n$$\n定义在填充规则 $p \\in \\{\\text{zero}, \\text{refl}\\}$ 下的平均边界偏差为\n$$\nb_p(d) \\triangleq \\frac{1}{|\\mathcal{B}(d)|} \\sum_{i \\in \\mathcal{B}(d)} \\left( y_p[i] - y_{\\text{center}} \\right),\n$$\n其中 $y_p[i]$ 是使用所选填充规则的 $x_p[\\cdot]$ 计算得出的。\n\n任务：实现一个完整、可运行的程序，该程序：\n1. 将每个测试信号构建为 $x[n] \\equiv 1$（无单位的常数1）。\n2. 根据上述定义，计算所有 $i \\in \\{0,\\ldots,N-1\\}$ 的 $y_{\\text{zero}}[i]$ 和 $y_{\\text{refl}}[i]$。\n3. 精确地按规定识别 $\\mathcal{B}(d)$。\n4. 对于每个测试案例，计算 $b_{\\text{zero}}(d)$ 和 $b_{\\text{refl}}(d)$，以及差值 $b_{\\text{zero}}(d) - b_{\\text{refl}}(d)$。\n5. 生成单行输出，其中包含所有结果，格式为方括号括起的逗号分隔列表，顺序如下文所述。本问题不涉及单位、角度或百分比，所有数值输出必须是实数。\n\n使用以下 $(N, K, w, d)$ 参数的测试套件：\n- 案例 $1$：$N = 21$, $K = 5$, $w = [0.25, 0.5, 1.0, 0.5, 0.25]$, $d = 1$。\n- 案例 $2$：$N = 21$, $K = 5$, $w = [0.25, 0.5, 1.0, 0.5, 0.25]$, $d = 2$。\n- 案例 $3$：$N = 21$, $K = 5$, $w = [0.25, 0.5, 1.0, 0.5, 0.25]$, $d = 3$。\n- 案例 $4$（感受野显著超出信号长度的边缘案例）：$N = 5$, $K = 7$, $w = [1, 1, 1, 1, 1, 1, 1]$, $d = 2$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个由方括号括起来的、以逗号分隔的结果列表。\n- 对于每个案例 $j \\in \\{1,2,3,4\\}$，按顺序包含三个数字：$b_{\\text{zero}}(d_j)$、$b_{\\text{refl}}(d_j)$ 和 $b_{\\text{zero}}(d_j) - b_{\\text{refl}}(d_j)$。\n- 因此，总输出列表必须按案例顺序包含 $12$ 个数字，例如，$\\big[ \\text{案例1的三元组}, \\text{案例2的三元组}, \\text{案例3的三元组}, \\text{案例4的三元组} \\big]$。", "solution": "该问题已经过验证，被确定为是良定的、有科学依据且内部一致的。我们可以开始进行形式化求解。\n\n核心任务是计算在扩张卷积操作下，两种填充方案（零填充和反射填充）的平均边界偏差。由于输入信号被特定选择为 $x[n] \\equiv 1$，问题得到了一个关键的简化。\n\n我们首先分析给出的定义。在索引 $i \\in \\{0, 1, \\ldots, N-1\\}$ 处的扩张卷积由下式给出：\n$$\ny[i] \\triangleq \\sum_{m=0}^{K-1} w[m] \\, x\\big(i + m \\cdot d - o\\big)\n$$\n其中对齐偏移量为 $o \\triangleq \\left\\lfloor \\frac{(K-1)d}{2} \\right\\rfloor$。\n对于恒定信号 $x[n] \\equiv c$ 的内部参考输出为：\n$$\ny_{\\text{center}} \\triangleq c \\sum_{m=0}^{K-1} w[m]\n$$\n问题指定了一个单位恒定信号，所以 $c=1$。因此，$y_{\\text{center}} = \\sum_{m=0}^{K-1} w[m]$。对于填充规则 $p$ 的平均边界偏差为：\n$$\nb_p(d) \\triangleq \\frac{1}{|\\mathcal{B}(d)|} \\sum_{i \\in \\mathcal{B}(d)} \\left( y_p[i] - y_{\\text{center}} \\right)\n$$\n\n**反射填充分析（$b_{\\text{refl}}(d)$）**\n\n反射填充规则将任何整数索引 $j$ 映射到索引 $r(j) \\in \\{0, \\ldots, N-1\\}$。填充后的信号值为 $x_{\\text{refl}}[j] \\triangleq x[r(j)]$。\n鉴于输入信号是恒定的，$x[n] = 1$ 对所有 $n \\in \\{0, \\ldots, N-1\\}$ 成立，因此在任何有效的反射索引 $r(j)$ 处的值也将是 $1$。所以，对于任何整数 $j$，$x_{\\text{refl}}[j] = x[r(j)] = 1$。\n使用反射填充的输出 $y_{\\text{refl}}[i]$ 可以对任何索引 $i$ 计算：\n$$\ny_{\\text{refl}}[i] = \\sum_{m=0}^{K-1} w[m] \\, x_{\\text{refl}}\\big(i + m \\cdot d - o\\big) = \\sum_{m=0}^{K-1} w[m] \\cdot 1 = \\sum_{m=0}^{K-1} w[m]\n$$\n将其与参考输出进行比较，我们发现对于所有 $i \\in \\{0, \\ldots, N-1\\}$，$y_{\\text{refl}}[i] = y_{\\text{center}}$。\n因此，偏差计算中的差值项始终为零：\n$$\ny_{\\text{refl}}[i] - y_{\\text{center}} = 0 \\quad \\forall i\n$$\n这直接意味着，对于所有测试案例，只要 $|\\mathcal{B}(d)| \\neq 0$，反射填充的平均边界偏差就为零：\n$$\nb_{\\text{refl}}(d) = \\frac{1}{|\\mathcal{B}(d)|} \\sum_{i \\in \\mathcal{B}(d)} 0 = 0\n$$\n\n**零填充分析（$b_{\\text{zero}}(d)$）**\n\n对于零填充，$x_{\\text{zero}}[j] = 1$（如果 $0 \\le j \\le N-1$），否则 $x_{\\text{zero}}[j] = 0$。\n对于索引 $i$ 的差值项 $(y_{\\text{zero}}[i] - y_{\\text{center}})$ 可以表示为：\n$$\ny_{\\text{zero}}[i] - y_{\\text{center}} = \\sum_{m=0}^{K-1} w[m] \\, x_{\\text{zero}}\\big(i + m \\cdot d - o\\big) - \\sum_{m=0}^{K-1} w[m] \\cdot 1\n$$\n$$\n= \\sum_{m=0}^{K-1} w[m] \\left( x_{\\text{zero}}\\big(i + m \\cdot d - o\\big) - 1 \\right)\n$$\n令 $j(m) = i + m \\cdot d - o$。如果 $j(m)$ 在信号边界 $[0, N-1]$ 内（此时 $x_{\\text{zero}}[j(m)] = 1$），则 $(x_{\\text{zero}}[j(m)] - 1)$ 项为 $0$；如果 $j(m)$ 越界（此时 $x_{\\text{zero}}[j(m)] = 0$），则该项为 $-1$。\n因此，该求和仅包含其对应输入样本越界的那些核系数的贡献：\n$$\ny_{\\text{zero}}[i] - y_{\\text{center}} = \\sum_{m \\text{ s.t. } j(m) \\notin [0, N-1]} w[m] \\cdot (-1) = - \\sum_{m \\text{ s.t. } i + m \\cdot d - o \\notin [0, N-1]} w[m]\n$$\n这为计算每个边界索引 $i \\in \\mathcal{B}(d)$ 的差值提供了一种直接方法：该差值是那些“超出”信号边缘的核权重的负和。\n\n**算法**\n\n对于每个测试案例 $(N, K, w, d)$，将通过以下步骤实现该解法：\n\n1. 读取参数 $N$、$K$、$w$ 和 $d$。\n2. 计算对齐偏移量 $o = \\lfloor \\frac{(K-1)d}{2} \\rfloor$。\n3. 计算参考输出 $y_{\\text{center}} = \\sum_{m=0}^{K-1} w[m]$。\n4. 设置 $b_{\\text{refl}}(d) = 0.0$。\n5. 识别边界索引集 $\\mathcal{B}(d)$。如果索引 $i \\in \\{0, \\ldots, N-1\\}$ 的感受野的任何部分落在 $[0, N-1]$ 之外，则该索引属于 $\\mathcal{B}(d)$。如果访问的最小索引 $i-o$ 小于 $0$，或者最大索引 $i+(K-1)d-o$ 大于或等于 $N$，则条件成立。\n6. 初始化变量 `sum_of_differences_zero` 为 $0$。\n7. 对于每个索引 $i \\in \\mathcal{B}(d)$：\n    a. 通过对访问索引 $i + m \\cdot d - o$ 位于 $[0, N-1]$ 之外的权重 $w[m]$求和并取反，来计算差值 $y_{\\text{zero}}[i] - y_{\\text{center}}$。\n    b. 将此差值加到 `sum_of_differences_zero`。\n8. 计算偏差 $b_{\\text{zero}}(d) = \\frac{\\text{sum\\_of\\_differences\\_zero}}{|\\mathcal{B}(d)|}$。\n9. 该测试案例的最终结果是 $b_{\\text{zero}}(d)$、$b_{\\text{refl}}(d)$ 和差值 $b_{\\text{zero}}(d) - b_{\\text{refl}}(d) = b_{\\text{zero}}(d)$。\n\n该算法将应用于所提供的全部四个测试案例。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the dilated convolution border bias problem for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        {'N': 21, 'K': 5, 'w': [0.25, 0.5, 1.0, 0.5, 0.25], 'd': 1},\n        {'N': 21, 'K': 5, 'w': [0.25, 0.5, 1.0, 0.5, 0.25], 'd': 2},\n        {'N': 21, 'K': 5, 'w': [0.25, 0.5, 1.0, 0.5, 0.25], 'd': 3},\n        {'N': 5, 'K': 7, 'w': [1.0] * 7, 'd': 2}\n    ]\n\n    def calculate_biases(N, K, w_list, d):\n        \"\"\"\n        Calculates the average border biases for a single test case.\n        \"\"\"\n        w = np.array(w_list, dtype=np.float64)\n        \n        # Calculate alignment offset.\n        o = (K - 1) * d // 2\n\n        # For a constant input signal x[n] = 1, reflective padding always samples the value 1.\n        # This makes the output y_refl[i] equal to the sum of kernel weights for all i.\n        # The reference output y_center is also the sum of kernel weights.\n        # Thus, the difference (y_refl[i] - y_center) is always 0.\n        # Consequently, the average border bias for reflective padding is 0.\n        b_refl = 0.0\n\n        # Identify the border index set B(d).\n        border_indices = set()\n        for i in range(N):\n            # The receptive field for output 'i' spans input indices from i - o to i + (K-1)*d - o.\n            # An index is on the border if any part of its receptive field is out of bounds.\n            rf_min_idx = i - o\n            rf_max_idx = i + (K - 1) * d - o\n            if rf_min_idx  0 or rf_max_idx >= N:\n                border_indices.add(i)\n\n        if not border_indices:\n            # If there are no border indices, the bias is 0.\n            b_zero = 0.0\n        else:\n            sum_of_differences_zero = 0.0\n            for i in border_indices:\n                # The difference (y_zero[i] - y_center) is the negative sum of weights that\n                # correspond to out-of-bounds input samples (padded with 0).\n                lost_weight_sum = 0.0\n                for m in range(K):\n                    j = i + m * d - o\n                    if not (0 = j  N):\n                        lost_weight_sum += w[m]\n                \n                diff = -lost_weight_sum\n                sum_of_differences_zero += diff\n            \n            b_zero = sum_of_differences_zero / len(border_indices)\n\n        b_diff = b_zero - b_refl\n        return b_zero, b_refl, b_diff\n\n    results = []\n    for case in test_cases:\n        b_zero, b_refl, b_diff = calculate_biases(case['N'], case['K'], case['w'], case['d'])\n        results.extend([b_zero, b_refl, b_diff])\n        \n    # Format the final output string exactly as required.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3116389"}, {"introduction": "扩张卷积的威力不止在于扩大感受野的尺寸，更在于能够灵活地塑造其形状。本项高级实践将探索各向异性扩张（anisotropic dilation），即在不同轴上使用不同的扩张率$d_x$和$d_y$。通过完成这个练习[@problem_id:3116423]，你将实现该技术并亲眼见证，如何通过使感受野的形状与图像中的特征方向对齐，来显著提升边缘检测等任务的性能。", "problem": "要求您实现并分析二维各向异性扩张（atrous）卷积，以研究感受野伸长对定向纹理上边缘检测的影响。该设定纯粹是数学和算法层面的。所有图像都是离散数组，所有操作都在有限网格上进行。角度必须以弧度为单位指定。不涉及物理单位。\n\n使用的基本原理：\n- 对于离散图像 $I:\\mathbb{Z}^2\\to\\mathbb{R}$ 和有限离散核 $K:\\{-\\lfloor k_y/2\\rfloor,\\ldots,\\lfloor k_y/2\\rfloor\\}\\times\\{-\\lfloor k_x/2\\rfloor,\\ldots,\\lfloor k_x/2\\rfloor\\}\\to\\mathbb{R}$，二维离散卷积定义为 $I$ 和 $K$ 的移位乘积之和。\n- 扩张（atrous）卷积将核的抽头（taps）放置在一个网格上，其间距由每个轴上的扩张因子决定，从而在保持核权重固定的同时有效地跳过抽头之间的像素。\n- 卷积算子的感受野（RF）是影响单个输出位置的输入位置集合。在各向异性扩张中，核抽头的间距沿不同轴是不同的，这使得感受野在一个轴上的伸长程度大于另一个轴。\n\n任务概述：\n1. 在大小为 $N\\times N$（$N=64$）的方形网格上构建合成的定向条纹纹理。设 $(x,y)$ 为像素坐标索引，其中 $x\\in\\{0,\\ldots,N-1\\}$ 表示列， $y\\in\\{0,\\ldots,N-1\\}$ 表示行。通过 $x_c=x-\\frac{N}{2}$ 和 $y_c=y-\\frac{N}{2}$ 将坐标中心化。对于一个角度 $\\theta$（以弧度为单位）和条纹周期 $p=8$，定义投影 $u(x,y)=x_c\\cos\\theta+y_c\\sin\\theta$。通过以下公式定义一个二值条纹纹理：\n$$\nI(x,y)=\\begin{cases}\n1  \\text{if } \\left\\lfloor \\frac{u(x,y)}{p}\\right\\rfloor \\bmod 2 = 1,\\\\\n0  \\text{otherwise.}\n\\end{cases}\n$$\n2. 使用4-连通邻接定义基准边缘掩码 $E_{\\text{gt}}(x,y)$。如果一个像素 $(x,y)$ 的4个邻居中至少有一个具有不同的强度，即对于任何在边界内的邻居，满足 $I(x,y)\\neq I(x\\pm1,y)$ 或 $I(x,y)\\neq I(x,y\\pm1)$，则该像素是一个基准边缘。\n3. 实现具有“相同”输出形状的各向异性扩张卷积。对于扩张因子 $(d_y,d_x)$ 和大小为 $k_y\\times k_x$ 的核 $K$，位置 $(y,x)$ 处的输出是核权重与输入样本相乘的总和，这些输入样本的位置在垂直方向上以 $d_y$ 为间距，在水平方向上以 $d_x$ 为间距。使用足够的零填充以保持“相同”的输出形状。\n4. 使用 Sobel 核对计算水平和垂直梯度：\n$$\nK_x=\\begin{bmatrix}-1  0  1\\\\-2  0  2\\\\-1  0  1\\end{bmatrix},\\quad\nK_y=\\begin{bmatrix}-1  -2  -1\\\\0  0  0\\\\1  2  1\\end{bmatrix}.\n$$\n将带有扩张因子 $(d_y,d_x)$ 的各向异性扩张卷积应用于 $K_x$ 和 $K_y$，并计算梯度幅度：\n$$\nM(x,y)=\\sqrt{\\big( (I*K_x)_{d_y,d_x}(x,y)\\big)^2+\\big( (I*K_y)_{d_y,d_x}(x,y)\\big)^2}.\n$$\n5. 对幅度图进行阈值处理以预测边缘。使用最大响应值的固定相对阈值 $\\tau=0.3$：\n$$\nE_{\\text{pred}}(x,y)=\\begin{cases}\n1  \\text{if } M(x,y)\\ge \\tau\\cdot \\max_{x',y'} M(x',y'),\\\\\n0  \\text{otherwise.}\n\\end{cases}\n$$\n6. 使用标准定义计算 $E_{\\text{pred}}$ 和 $E_{\\text{gt}}$ 之间的 F1 分数（F1）。设 $T_P$ 为真阳性（true positives）的数量，$F_P$ 为假阳性（false positives）的数量，$F_N$ 为假阴性（false negatives）的数量。定义精确率 $P=T_P/(T_P+F_P)$（约定分母为0时$P=0$），召回率 $R=T_P/(T_P+F_N)$（约定分母为0时$R=0$），以及：\n$$\n\\text{F1}=\\begin{cases}\n\\frac{2PR}{P+R}  \\text{if } P+R0,\\\\\n0  \\text{otherwise.}\n\\end{cases}\n$$\n\n测试套件：\n在以下参数集 $(\\theta,d_x,d_y)$ 上运行程序，其中角度以弧度为单位：\n- 情况1：$\\theta=0.0$, $d_x=3$, $d_y=1$（在垂直条纹上，感受野水平伸长）。\n- 情况2：$\\theta=0.0$, $d_x=1$, $d_y=3$（在垂直条纹上，感受野垂直伸长）。\n- 情况3：$\\theta=\\frac{\\pi}{4}$, $d_x=3$, $d_y=1$（在对角条纹上，伸长方向未对齐）。\n- 情况4：$\\theta=\\frac{\\pi}{2}$, $d_x=1$, $d_y=3$（在水平条纹上，伸长方向对齐）。\n- 情况5：$\\theta=0.0$, $d_x=1$, $d_y=1$（各向同性基线）。\n- 情况6：$\\theta=0.0$, $d_x=7$, $d_y=1$（在垂直条纹上，极端伸长边界情况）。\n\n要求的最终输出格式：\n您的程序应生成单行输出，其中包含按上述顺序排列的各情况的 F1 分数，每个分数四舍五入到4位小数，形式为用方括号括起来的逗号分隔列表，例如 $\\big[$$0.8123,0.6456,0.5021,0.9000,0.7801,0.4200$$\\big]$。", "solution": "该问题是有效的。它是一个在数字图像处理和深度学习领域内定义明确、有科学依据且客观的算法任务。为获得唯一解所需的所有参数、定义和过程均已提供。\n\n目标是研究卷积滤波器感受野的伸长和方向如何影响其在定向纹理中检测边缘的能力。这通过实现一个各向异性扩张卷积流水线，并在一组合成纹理上使用 F1 分数评估其性能来实现。\n\n解决方案按以下步骤进行：\n\n1.  **合成纹理生成**：对于每个测试用例，我们首先生成一个大小为 $N \\times N$ 的合成方形图像，其中 $N=64$。像素坐标 $(x,y)$ 定义在网格 $\\{0, 1, \\ldots, N-1\\} \\times \\{0, 1, \\ldots, N-1\\}$ 上。通过 $x_c = x - \\frac{N}{2}$ 和 $y_c = y - \\frac{N}{2}$ 将这些坐标中心化。对于给定的方向角 $\\theta$（以弧度为单位），计算投影坐标 $u(x,y) = x_c\\cos\\theta + y_c\\sin\\theta$。该投影有效地旋转了坐标系。然后基于此投影和条纹周期 $p=8$，使用以下规则生成二值条纹纹理 $I(x,y)$：\n    $$\n    I(x,y)=\\begin{cases}\n    1  \\text{if } \\left\\lfloor \\frac{u(x,y)}{p}\\right\\rfloor \\bmod 2 = 1,\\\\\n    0  \\text{otherwise.}\n    \\end{cases}\n    $$\n    该公式创建了宽度恒为 $p$ 的平行条纹，其方向由角度 $\\theta$ 决定。\n\n2.  **基准边缘掩码**：基准边缘掩码 $E_{\\text{gt}}$ 表示边缘检测器的理想输出。如果一个像素 $(x,y)$ 的值 $I(x,y)$ 与其在图像边界内的任何一个 4-连通邻居（上、下、左、右）的值不同，则该像素被定义为边缘点。这是在离散网格上定义边缘的标准方法。生成的二值掩码 $E_{\\text{gt}}$ 在边缘位置为 1，其他位置为 0。\n\n3.  **各向异性扩张卷积**：这是所研究的核心操作。标准的二维卷积是一种将核（一个小的权重矩阵）在输入图像上滑动的操作。扩张（或 atrous）卷积在核的权重之间引入间隙。这些间隙的大小由扩张因子控制。在各向异性扩张卷积中，垂直和水平轴的扩张因子 $(d_y, d_x)$ 可以不同。这会改变操作的感受野（RF）——即影响单个输出值的输入图像区域。对于一个 $k_y \\times k_x$ 的核，有效感受野大小近似变为 $(k_y-1)d_y+1 \\times (k_x-1)d_x+1$。通过选择 $d_y \\ne d_x$，我们创建了一个伸长的感受野。\n    为实现此操作，我们对输入图像 $I$ 和核 $K$ 执行二维互相关（深度学习库中的标准做法）。在 $(y,x)$ 处的输出计算如下：\n    $$\n    (I*K)_{d_y,d_x}(y,x) = \\sum_{j=-\\lfloor k_y/2 \\rfloor}^{\\lfloor k_y/2 \\rfloor} \\sum_{i=-\\lfloor k_x/2 \\rfloor}^{\\lfloor k_x/2 \\rfloor} K_{j,i} \\cdot I(y+j\\cdot d_y, x+i\\cdot d_x)\n    $$\n    其中 $K_{j,i}$ 是在相对位置 $(j,i)$ 处的核权重。为确保输出与输入具有“相同”的形状，输入图像 $I$ 首先用零进行填充。对于一个 $3 \\times 3$ 的核，顶部和底部需要 $d_y$ 的填充，左侧和右侧需要 $d_x$ 的填充。\n\n4.  **梯度幅度计算**：为了检测边缘，我们估计图像梯度。Sobel 算子提供了一对 $3 \\times 3$ 的核 $K_x$ 和 $K_y$，用于近似关于 $x$ 和 $y$ 的偏导数。\n    $$\n    K_x=\\begin{bmatrix}-1  0  1\\\\-2  0  2\\\\-1  0  1\\end{bmatrix},\\quad\n    K_y=\\begin{bmatrix}-1  -2  -1\\\\0  0  0\\\\1  2  1\\end{bmatrix}\n    $$\n    我们使用指定的扩张因子 $(d_y, d_x)$，将图像 $I$ 与这两个核分别进行各向异性扩张卷积，得到梯度分量图 $G_x = (I*K_x)_{d_y,d_x}$ 和 $G_y = (I*K_y)_{d_y,d_x}$。然后，每个像素的总梯度幅度 $M(x,y)$ 计算为梯度向量的欧几里得范数：\n    $$\n    M(x,y)=\\sqrt{G_x(x,y)^2 + G_y(x,y)^2}\n    $$\n\n5.  **通过阈值处理进行边缘预测**：将连续值的梯度幅度图 $M(x,y)$ 通过应用阈值转换为二值预测边缘掩码 $E_{\\text{pred}}$。问题指定了一个相对阈值 $\\tau=0.3$。阈值为 $T = \\tau \\cdot \\max_{x',y'} M(x',y')$。预测的边缘掩码则为：\n    $$\n    E_{\\text{pred}}(x,y)=\\begin{cases}\n    1  \\text{if } M(x,y)\\ge T,\\\\\n    0  \\text{otherwise.}\n    \\end{cases}\n    $$\n\n6.  **性能评估**：通过将预测 $E_{\\text{pred}}$ 与基准 $E_{\\text{gt}}$ 进行比较，使用 F1 分数来衡量预测的质量。这需要计算真阳性（$T_P$）、假阳性（$F_P$）和假阴性（$F_N$）的数量。\n    -   $T_P = \\sum_{y,x} [E_{\\text{pred}}(y,x) = 1 \\text{ and } E_{\\text{gt}}(y,x) = 1]$\n    -   $F_P = \\sum_{y,x} [E_{\\text{pred}}(y,x) = 1 \\text{ and } E_{\\text{gt}}(y,x) = 0]$\n    -   $F_N = \\sum_{y,x} [E_{\\text{pred}}(y,x) = 0 \\text{ and } E_{\\text{gt}}(y,x) = 1]$\n    根据这些计数，我们计算精确率 $P = T_P / (T_P + F_P)$ 和召回率 $R = T_P / (T_P + F_N)$。F1 分数是精确率和召回率的调和平均值：\n    $$\n    \\text{F1}=\\frac{2PR}{P+R}\n    $$\n    如规范中所述，对分母为零的情况进行特殊处理。F1 分数提供了一个平衡的性能度量，同时惩罚漏检的边缘（低召回率）和虚假的检测（低精确率）。\n\n对测试套件中的每个参数集 $(\\theta, d_x, d_y)$ 执行这个完整的流水线，为每个配置生成一个 F1 分数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and analyzes anisotropic dilated convolutions for edge detection.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (theta, d_x, d_y)\n        (0.0, 3, 1),\n        (0.0, 1, 3),\n        (np.pi / 4, 3, 1),\n        (np.pi / 2, 1, 3),\n        (0.0, 1, 1),\n        (0.0, 7, 1),\n    ]\n\n    results = []\n    \n    N = 64\n    p = 8.0\n    tau = 0.3\n    \n    K_x = np.array([[-1, 0, 1], [-2, 0, 2], [-1, 0, 1]], dtype=np.float64)\n    K_y = np.array([[-1, -2, -1], [0, 0, 0], [1, 2, 1]], dtype=np.float64)\n\n    def dilated_convolution(image, kernel, d_y, d_x):\n        \"\"\"\n        Computes 2D dilated cross-correlation with zero padding for 'same' output.\n        \"\"\"\n        img_h, img_w = image.shape\n        k_h, k_w = kernel.shape\n        \n        # Center of the 3x3 kernel is at (1,1)\n        k_h_center, k_w_center = k_h // 2, k_w // 2\n        \n        # Required padding on each side to maintain 'same' shape\n        pad_y = k_h_center * d_y\n        pad_x = k_w_center * d_x\n\n        padded_image = np.pad(image, ((pad_y, pad_y), (pad_x, pad_x)), mode='constant', constant_values=0)\n        output = np.zeros_like(image, dtype=np.float64)\n\n        for y in range(img_h):\n            for x in range(img_w):\n                val = 0.0\n                for ky in range(k_h):\n                    for kx in range(k_w):\n                        # Kernel indices relative to center, e.g., -1, 0, 1\n                        j = ky - k_h_center\n                        i = kx - k_w_center\n                        \n                        # Corresponding image coordinates in the padded image\n                        img_y = y + pad_y + j * d_y\n                        img_x = x + pad_x + i * d_x\n                        \n                        val += padded_image[img_y, img_x] * kernel[ky, kx]\n                output[y, x] = val\n        return output\n\n    for case in test_cases:\n        theta, d_x, d_y = case\n\n        # 1. Generate synthetic oriented stripe texture I\n        coords = np.arange(N)\n        x_c = coords - N / 2.0\n        y_c = coords - N / 2.0\n        xx_c, yy_c = np.meshgrid(x_c, y_c)\n        \n        u = xx_c * np.cos(theta) + yy_c * np.sin(theta)\n        I = (np.floor(u / p) % 2 == 1).astype(np.float64)\n\n        # 2. Generate ground-truth edge mask E_gt\n        E_gt = np.zeros_like(I, dtype=int)\n        for y in range(N):\n            for x in range(N):\n                current_val = I[y, x]\n                is_edge = False\n                # Check 4-connected neighbors\n                if y > 0 and I[y - 1, x] != current_val: is_edge = True\n                if y  N - 1 and I[y + 1, x] != current_val: is_edge = True\n                if x > 0 and I[y, x - 1] != current_val: is_edge = True\n                if x  N - 1 and I[y, x + 1] != current_val: is_edge = True\n                if is_edge:\n                    E_gt[y, x] = 1\n        \n        # 4. Apply kernels and compute gradient magnitude M\n        G_x = dilated_convolution(I, K_x, d_y, d_x)\n        G_y = dilated_convolution(I, K_y, d_y, d_x)\n        M = np.sqrt(G_x**2 + G_y**2)\n\n        # 5. Threshold magnitude map to get predicted edges E_pred\n        M_max = np.max(M)\n        if M_max > 0:\n            threshold = tau * M_max\n            E_pred = (M >= threshold).astype(int)\n        else:\n            E_pred = np.zeros_like(M, dtype=int)\n\n        # 6. Compute F1 score\n        TP = np.sum((E_pred == 1)  (E_gt == 1))\n        FP = np.sum((E_pred == 1)  (E_gt == 0))\n        FN = np.sum((E_pred == 0)  (E_gt == 1))\n        \n        # Precision\n        if (TP + FP) == 0:\n            P = 0.0\n        else:\n            P = TP / (TP + FP)\n        \n        # Recall\n        if (TP + FN) == 0:\n            R = 0.0\n        else:\n            R = TP / (TP + FN)\n        \n        # F1 Score\n        if (P + R) == 0:\n            F1 = 0.0\n        else:\n            F1 = (2 * P * R) / (P + R)\n            \n        results.append(round(F1, 4))\n\n    # Format and print the final output as specified\n    print(f\"[{','.join(f'{r:.4f}' for r in results)}]\")\n\nsolve()\n```", "id": "3116423"}]}