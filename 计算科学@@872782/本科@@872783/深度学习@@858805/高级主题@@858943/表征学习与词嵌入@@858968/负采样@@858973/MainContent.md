## 引言
负采样（Negative Sampling）是现代[表示学习](@entry_id:634436)（Representation Learning）领域的一项基石性技术，尤其在自然语言处理、推荐系统和图学习等场景中发挥着不可或缺的作用。当模型需要从数以万计甚至百万计的类别中进行预测时，标准`softmax`函数的巨大计算开销成为了训练的瓶颈。负采样正是为了解决这一难题而提出的高效解决方案，它巧妙地将问题转化，从而在保证模型性能的同时，极大地提升了训练效率。

本文将分为三个核心部分，带领读者全面掌握负采样。在“原理与机制”一章中，我们将深入其核心，从`softmax`的挑战出发，剖析噪声对比估计（NCE）与[InfoNCE损失](@entry_id:634431)的数学框架，并探讨负样本数量、质量和温度等关键设计抉择。接下来，在“应用与跨学科连接”一章中，我们将展示负采样如何作为一种灵活的建模思想，跨越语言、图、生物信息等多个领域，解决各类实际问题。最后，通过“动手实践”部分，读者将有机会通过解决具体问题，将理论知识转化为深刻的理解。让我们首先从其基本原理与工作机制开始探索。

## 原理与机制

在深入探讨负采样的具体应用之前，我们必须首先理解其核心原理与工作机制。本章将系统性地剖析负采样技术，从其诞生的动因——解决大规模`softmax`计算瓶颈，到其核心的概率框架，再到影响其性能的关键设计抉择，如负样本的数量、质量与[采样分布](@entry_id:269683)等。我们将揭示，负采样不仅是一种计算上的近似技巧，更是一种深刻影响模型学习动态与表征质量的强大机制。

### 计算瓶颈：大规模[Softmax](@entry_id:636766)的挑战

在深度学习的许多领域，尤其是在自然语言处理和推荐系统中，模型常常需要在一个极大的类别集合上进行预测。例如，在语言模型中，词汇表的大小（$V$）可以轻易达到数十万甚至数百万。标准的多[分类任务](@entry_id:635433)通常以 **softmax** 函数收尾，该函数为每个类别 $i$ 计算其概率：

$$
P(y=i | x) = \frac{\exp(s_i)}{\sum_{j=1}^{V} \exp(s_j)}
$$

其中，$s_i$ 是模型为类别 $i$ 输出的“得分”（logit），通常是某个高维向量的[内积](@entry_id:158127)。这个公式的计算瓶颈在于分母中的归一化项 $Z = \sum_{j=1}^{V} \exp(s_j)$。为了计算一个样本的损失函数（如[交叉熵损失](@entry_id:141524)），模型必须计算并加总词汇表中 *所有* 类别的得分，这在 $V$ 非常大时是极其耗时和计算昂贵的。每次梯度更新都需要这样的计算，使得训练过程变得不切实际。

负采样的提出，正是为了绕开这个计算瓶颈。其核心思想是，用一个更易于计算的替代目标函数来近似原始的`softmax`目标。

### 负采样：从多分类到[二元分类](@entry_id:142257)的转化

负采样的精髓在于将一个复杂的多[分类问题](@entry_id:637153)转化为一系列简单的[二元分类](@entry_id:142257)问题。其基本思路是：对于一个给定的“正样本”（例如，在[词嵌入](@entry_id:633879)中，一个中心词和它的一个上下文词），我们不要求模型能从整个词汇表中精确地计算出它的概率，而是只要求模型能够区分这个正样本和一小部分随机抽取的“负样本”（或称为“噪声样本”）。

#### 噪声对比估计（NCE）框架

这一思想在形式上可以通过**噪声对比估计**（Noise-Contrastive Estimation, NCE）来理解。NCE将问题重新构建为一个[二元分类](@entry_id:142257)任务：判断一个样本是来自真实数据[分布](@entry_id:182848) $p_{data}$ 还是来自某个已知的“噪声”[分布](@entry_id:182848) $q$。对于每个正样本 $(x, y^+)$，我们从噪声[分布](@entry_id:182848) $q$ 中抽取 $k$ 个负样本 $\{y^-_1, \dots, y^-_k\}$。然后，模型的目标是最大化正样本的概率，同时最小化负样本的概率。这等价于最小化一个 logistic 回归式的[损失函数](@entry_id:634569)。

NCE的理论一致性，即在样本量趋于无穷时，模型参数能否收敛到真实参数，依赖于几个关键假设。其中最重要的一条是，噪声[分布](@entry_id:182848) $q$ 必须是固定的，并且与模型参数 $\theta$ 无关。如果噪声[分布](@entry_id:182848)本身也依赖于模型参数（记作 $q_\theta$），那么NCE的[目标函数](@entry_id:267263)会发生改变，其梯度会包含额外的项，这通常会破坏[参数辨识](@entry_id:275549)的论证，导致估计不一致。一个极端的例子是，如果噪声[分布](@entry_id:182848)被设定为与模型[分布](@entry_id:182848)完全相同，即 $q_\theta(x) = p_\theta(x)$，那么分类器将无法从数据和噪声中获得任何区分信号，导致参数 $\theta$ 完全无法学习 [@problem_id:3156740]。因此，理解这些理论基础对于正确设计和评估基于负采样的模型至关重要。一个稳健的经验性测试方法是在一个已知真实参数 $\theta^\star$ 的模拟环境中，比较使用固定 $q$ 和依赖参数的 $q_\theta$ 两种情况下，训练得到的参数 $\hat{\theta}_n$ 与真实参数 $\theta^\star$ 的误差是否随着数据量的增加而减小 [@problem_id:3156740]。

### 提案[分布](@entry_id:182848) $q(x)$：负样本的质量与来源

负采样的效果在很大程度上取决于我们如何选择负样本，即**提案[分布](@entry_id:182848)**（proposal distribution）$q(x)$ 的设计。一个好的提案[分布](@entry_id:182848)应该能够提供“有信息量”的负样本，即那些能够挑战模型、促使其学习更精细特征的样本。

#### 基于频率的采样及其修正

在实践中，尤其是在`[Word2Vec](@entry_id:634267)`等[词嵌入](@entry_id:633879)模型中，最常见的提案[分布](@entry_id:182848)是基于词频的。一个简单的想法是按照词语在语料库中的出现频率进行采样。然而，高频词（如“的”、“一个”）会被频繁抽中，但它们通常提供的学习信号很弱。而低频词很难被抽中，导致它们的[表示学习](@entry_id:634436)不足。

为了修正这个问题，`[Word2Vec](@entry_id:634267)`提出对词频进行平滑处理，使用一个指数 $\alpha \in [0, 1]$ 来调整原始[频率分布](@entry_id:176998)：

$$
q(w) \propto \text{freq}(w)^{\alpha}
$$

其中 $\text{freq}(w)$ 是词 $w$ 的频率。当 $\alpha=1$ 时，这就是原始的[频率分布](@entry_id:176998)。当 $\alpha=0$ 时，所有词被抽中的概率相同（[均匀分布](@entry_id:194597)）。一个常用的经验值是 $\alpha=0.75$，这能在高频词和低频词之间取得一个很好的平衡，适度提升了稀有词被采样的概率。

#### 处理[类别不平衡](@entry_id:636658)与[采样偏差](@entry_id:193615)

在许多现实世界的应用中，数据存在严重的**[类别不平衡](@entry_id:636658)**。如果直接使用[频率分布](@entry_id:176998)进行负采样，模型在训练时将很少见到来自少数类的负样本，从而导致对这些类的辨别能力较差。我们可以通过显式地调整提案[分布](@entry_id:182848)来缓解这个问题。例如，我们可以设定一个目标，即希望少数类的总采样概率达到某个阈值 $t$，然后通过调整平滑指数 $\alpha$ 来实现这个目标。这种方法允许我们主动地提升对少数类的“关注度”，从而改善模型在[不平衡数据](@entry_id:177545)上的鲁棒性 [@problem_id:3156731]。

另一个重要的问题是**伪负样本**（false negatives）。在某些场景下，尤其是[自监督学习](@entry_id:173394)中，一个通过随机采样得到的“负样本”实际上可能是一个潜在的正样本。例如，在视频理解任务中，一个锚点帧附近的帧很可能包含相同或相似的内容。如果我们将这些帧作为负样本，就会向模型传递错误的信号，阻碍学习。一个有效的策略是利用领域知识来设计采样方案，比如定义一个**时间排斥窗口** $\Delta t$，在采样时明确排除与锚点帧在时间上过于接近的帧。通过系统地分析伪负样本概率与排斥窗口大小的关系，我们可以选择一个最优的 $\Delta t$，在确保有足够多负样本候选的同时，将伪负样本的期望数量控制在可接受的范围内 [@problem_id:3156751]。

### [InfoNCE损失](@entry_id:634431)与现代[对比学习](@entry_id:635684)

近年来，负采样在**[对比学习](@entry_id:635684)**（Contrastive Learning）领域焕发了新的生机，其核心是 **InfoNCE**（Information Noise-Contrastive Estimation）[损失函数](@entry_id:634569)。对于一个锚点样本 $x$，其正样本 $x^+$ 和一组 $K$ 个负样本 $\{x^-_j\}_{j=1}^K$，[InfoNCE损失](@entry_id:634431)的定义如下：

$$
L_{\text{InfoNCE}} = -\ln \left( \frac{\exp(s(x, x^+)/\tau)}{\exp(s(x, x^+)/\tau) + \sum_{j=1}^{K} \exp(s(x, x^-_j)/\tau)} \right)
$$

其中 $s(\cdot, \cdot)$ 是一个度量样本相似度的函数（如余弦相似度或[点积](@entry_id:149019)），$\tau$ 是一个称为**温度**（temperature）的正超参数。这个损失函数的形式可以看作是一个 $(K+1)$ 类的[交叉熵损失](@entry_id:141524)，其目标是从 $K$ 个负样本中正确地识别出唯一的正样本。

#### 温度 $\tau$ 的作用：调节学习难度

温度 $\tau$ 在[对比学习](@entry_id:635684)中扮演着至关重要的角色。它调节了模型对不同难度负样本的关注程度。
- 当 $\tau$ 很低时，$\exp(s/\tau)$ 的值对相似度 $s$ 的变化非常敏感。模型会将绝大部分注意力放在那些与锚点最相似的“硬”负样本上。
- 当 $\tau$ 很高时，相似度得分的差异会被“平滑”掉，损失函数会鼓励模型将正样本与所有负样本都拉开距离，而不是仅仅关注最难区分的那些。

我们可以用信息熵 $H(\tau)$ 来量化由温度决定的负样本[分布](@entry_id:182848)的“硬度”。一个更集中的[分布](@entry_id:182848)（熵低）意味着模型聚焦于少数硬负样本，而一个更均匀的[分布](@entry_id:182848)（熵高）意味着模型平等对待所有负样本。一个优雅的数学结论是，熵对温度的导数与相似度得分的[方差](@entry_id:200758)成正比：$\frac{dH}{d\tau} = \frac{\mathrm{Var}(s)}{\tau^3}$。这个关系表明，熵是温度的单调非减函数，并为我们提供了一种自适应调节温度的理论依据，以在训练过程中将学习的“难度”维持在一个理想的区间内 [@problem_id:3156758]。

#### 负样本数量 $K$ 的作用：提供可靠的对比

负样本的数量 $K$ 同样关键。更多的负样本可以提供对完整`softmax`分母更精确的[蒙特卡洛估计](@entry_id:637986)，从而使梯度更稳定。更重要的是，足够大的 $K$ 可以增加在样本中包含“硬”负样本的概率，而这些硬负样本是模型提升表征能力的关键。我们可以通过一个简单的[概率模型](@entry_id:265150)来量化这一点：假设每次采样有 $\rho$ 的概率抽到一个与正样本语义重叠的“硬”负样本，那么为了保证一次采样中至少包含一个硬负样本的概率不低于 $q$，我们需要的最小负样本数量 $k_{\min}$ 可以通过求解 $1 - (1-\rho)^k \ge q$ 来得到 [@problem_id:3156685]。

### 与边界损失的深刻联系

InfoNCE 损失与经典的[度量学习](@entry_id:636905)损失（如**三元组损失**，Triplet Loss）之间存在深刻的联系。三元组损失的目标是让一个锚点 $a$ 与一个正样本 $p$ 之间的距离 $d(a, p)$ 比它与一个负样本 $n$ 之间的距离 $d(a, n)$ 至少小一个**边界**（margin）$m$：

$$
L_{\text{triplet}} = \max(0, d(a,p) - d(a,n) + m)
$$

在三元组损失的框架下，发展出了多种负样本挖掘策略，如**硬负样本挖掘**（选择 $d(a,n)$ 最小的负样本）和**半硬负样本挖掘**（选择满足 $d(a,p)  d(a,n)  d(a,p)+m$ 的负样本），以提供更有效的学习信号 [@problem_id:3156784]。

令人惊讶的是，在特定条件下，[InfoNCE损失](@entry_id:634431)会退化为一个类似三元组损失的边界损失。可以证明，当负样本数量 $K$ 很大且这些负样本都相对“简单”（即它们与锚点的相似度 $\beta$ 远低于正样本的相似度 $\alpha$）时，[InfoNCE损失](@entry_id:634431)近似于一个带有**有效边界**（effective margin）的线性[铰链损失](@entry_id:168629)。这个有效边界为：

$$
m_{\text{eff}} = \beta + \tau \ln(K)
$$

这个结论 [@problem_id:3156757] 揭示了[InfoNCE损失](@entry_id:634431)的内在机制：温度 $\tau$ 和负样本数量 $K$ 共同决定了模型学习中隐式的排斥边界。它优美地统一了现代[对比学习](@entry_id:635684)和经典的[度量学习](@entry_id:636905)框架。

### 实践策略与权衡

在实际应用中，我们还需要考虑如何高效地实现和组织负采样。

#### 高效采样算法

从一个大规模的非[均匀分布](@entry_id:194597) $q(x)$ 中进行采样本身就是一个挑战。简单的“轮盘赌”算法（基于[累积分布函数](@entry_id:143135)和二分搜索）的单次采样复杂度为 $O(\log V)$，在需要大量采样时仍然效率不高。更高效的**[别名](@entry_id:146322)采样**（Alias Method）算法可以在 $O(V)$ 的预处理后，以 $O(1)$ 的时间复杂度进行单次采样，这对于大规模训练至关重要 [@problem_id:3156753]。

#### 批内负样本 vs. 全局负样本池

负样本的来源主要有两种策略：
1.  **批内负样本（In-batch Negatives）**：这是现代[对比学习](@entry_id:635684)中最常见的策略。它直接将一个批次（mini-batch）内的其他样本用作当前锚点样本的负样本。这种方法计算效率极高，因为它复用了已在GPU内存中的嵌入向量，并能利用高度优化的[矩阵乘法](@entry_id:156035)操作。然而，其缺点是负样本的数量受限于批次大小，且样本的多样性有限。
2.  **全局负样本池（Shared Negative Pool）**：该策略维护一个独立的、更大的负样本队列或内存库。这可以提供更多样化、更具挑战性的负样本。但它需要额外的内存来存储这个池，并且可能引入更复杂的计算流程。

这两种策略之间存在明显的权衡。我们可以通过一个量化模型来分析这种权衡：全局池策略通常能以更高的概率发现“硬”负样本，从而可能带来更好的模型性能，但这是以牺牲内存占用和计算[吞吐量](@entry_id:271802)为代价的 [@problem_id:3156703]。选择哪种策略取决于具体的应用场景、硬件限制以及对模型性能的要求。

#### 基于模型的负采样

最后，一个更前沿的方向是让提案[分布](@entry_id:182848) $q$ 本身也具有学习能力。静态的、基于频率的[分布](@entry_id:182848)可能并非最优。我们可以使用一个辅助模型来预测哪些样本可能是“语义上困难”的负样本——即那些与正样本在语义上相近但在表示空间中需要被推开的样本。通过这种方式，模型可以动态地为自己生成更高质量的训练数据，从而加速收敛并提升最终性能 [@problem_id:3156761]。这开启了自适应和智能[采样策略](@entry_id:188482)的大门，是负采样技术发展的一个重要方向。