{"hands_on_practices": [{"introduction": "我们如何训练一个模型来学习新任务，同时又不覆盖掉从旧任务中学到的关键知识呢？本练习将探索弹性权重巩固（Elastic Weight Consolidation, EWC），一种核心的基于正则化的策略。通过识别对旧任务至关重要的参数，并对它们的改变施加二次惩罚，EWC 有效地减缓了灾难性遗忘。通过亲手实现 EWC 并衡量其对梯度更新的影响，你将具体理解正规化是如何帮助模型在持续学习中“记住”过去知识的 [@problem_id:3109267]。", "problem": "您必须编写一个完整的程序，构建并分析一个用于线性神经网络的合成持续学习场景。该网络包含一个嵌入层和一个分类器。该网络通过一个嵌入矩阵 $\\mathbf{E} \\in \\mathbb{R}^{m \\times d}$ 将输入向量 $\\mathbf{x} \\in \\mathbb{R}^d$ 映射到一个嵌入向量 $\\mathbf{z} = \\mathbf{E}\\mathbf{x}$，然后应用一个分类器矩阵 $\\mathbf{C} \\in \\mathbb{R}^{K \\times m}$ 来生成对数几率（logits） $\\mathbf{s} = \\mathbf{C}\\mathbf{z}$。在 $K$ 个类别上的预测分布是 softmax $\\mathbf{p} = \\operatorname{softmax}(\\mathbf{s})$，其中 $p_k = \\exp(s_k)/\\sum_{j=1}^K \\exp(s_j)$。对于一个带有独热（one-hot）标签 $\\mathbf{y} \\in \\{0,1\\}^K$ 的单一-样本 $(\\mathbf{x}, \\mathbf{y})$，训练损失是交叉熵 $L(\\mathbf{C};\\mathbf{z},\\mathbf{y}) = -\\sum_{k=1}^K y_k \\log p_k$。关于分类器的梯度是 $\\nabla_{\\mathbf{C}} L = (\\mathbf{p}-\\mathbf{y})\\mathbf{z}^\\top$。我们将在整个过程中使用全批量梯度下降。\n\n在持续学习中，在一个旧任务上训练并获得参数 $\\mathbf{C}^\\star$ 后，弹性权重巩固（Elastic Weight Consolidation, EWC）策略会增加一个二次惩罚项，以抑制在对旧任务重要的方向上的参数移动。令旧任务的经验费雪信息（对角线近似）定义为\n$$\n\\mathbf{F}_{\\text{diag}} = \\frac{1}{N} \\sum_{i=1}^N \\operatorname{vec}\\!\\left(\\nabla_{\\mathbf{C}} \\ell_i\\right) \\odot \\operatorname{vec}\\!\\left(\\nabla_{\\mathbf{C}} \\ell_i\\right),\n$$\n其中 $\\ell_i = L(\\mathbf{C}^\\star;\\mathbf{z}_i,\\mathbf{y}_i)$，$\\operatorname{vec}(\\cdot)$ 将矩阵展平为向量，$\\odot$ 表示逐元素乘法。EWC 惩罚项是\n$$\nR(\\mathbf{C}) = \\frac{\\lambda}{2} \\sum_{j} F_{\\text{diag},j}\\left(\\theta_j - \\theta_j^\\star\\right)^2,\n$$\n其中 $\\theta = \\operatorname{vec}(\\mathbf{C})$ 且 $\\theta^\\star = \\operatorname{vec}(\\mathbf{C}^\\star)$。在训练新任务时，基线目标是 $J_{\\text{base}}(\\mathbf{C}) = \\frac{1}{N'}\\sum_{i=1}^{N'} L(\\mathbf{C};\\mathbf{z}_i',\\mathbf{y}_i')$，而 EWC 目标是 $J_{\\text{ewc}}(\\mathbf{C}) = J_{\\text{base}}(\\mathbf{C}) + R(\\mathbf{C})$。惩罚项关于 $\\theta$ 的梯度是 $\\nabla_\\theta R(\\mathbf{C}) = \\lambda\\,\\mathbf{F}_{\\text{diag}} \\odot (\\theta - \\theta^\\star)$。\n\n将旧任务子空间 $\\mathcal{S}_r$ 定义为 $\\theta$ 中与 $\\mathbf{F}_{\\text{diag}}$ 的前 $r$ 个最大值条目相对应的 $r$ 个坐标所张成的空间。令 $\\mathcal{P}_{\\mathcal{S}_r}$ 表示一个投影算子，它将这 $r$ 个索引之外的所有坐标置零。对于学习率为 $\\eta$ 的梯度下降，第 $t$ 步的更新向量是 $\\Delta_t = -\\eta \\nabla_\\theta J(\\mathbf{C}_t)$，其中 $J$ 是 $J_{\\text{base}}$ 或 $J_{\\text{ewc}}$。在 $T$ 个步骤中，流入 $\\mathcal{S}_r$ 的累积梯度流幅度为\n$$\nM = \\sum_{t=1}^T \\left\\|\\mathcal{P}_{\\mathcal{S}_r}(\\Delta_t)\\right\\|_2.\n$$\n\n您的程序必须：\n- 在嵌入空间中完全通过设置 $\\mathbf{E} = \\mathbf{I}_m$（$m \\times m$ 的单位矩阵）来构建一个合成的旧任务和一个合成的新任务。令旧任务生成具有类别相关高斯均值 $\\boldsymbol{\\mu}_k^{\\text{old}} \\in \\mathbb{R}^m$ 和协方差 $\\sigma^2 \\mathbf{I}_m$ 的样本。令新任务的均值通过一个随机正交旋转矩阵 $\\mathbf{R} \\in \\mathbb{R}^{m \\times m}$ 应用于旧任务的均值得到：$\\boldsymbol{\\mu}_k^{\\text{new}} = \\mathbf{R}\\boldsymbol{\\mu}_k^{\\text{old}}$。标签对于 $K$ 个类别保持为独热编码。\n- 在旧任务上使用全批量梯度下降训练 $\\mathbf{C}$ 以获得 $\\mathbf{C}^\\star$，同时保持 $\\mathbf{E}$ 固定，然后在 $\\mathbf{C}^\\star$ 处计算旧任务的 $\\mathbf{F}_{\\text{diag}}$。\n- 对于新任务，比较两种策略：(i) 冻结嵌入并使用 $J_{\\text{base}}$ 微调分类器，以及 (ii) 冻结嵌入并使用 $J_{\\text{ewc}}$ 微调分类器，其中 EWC 惩罚仅应用于分类器。在这两种策略中，都从 $\\mathbf{C}^\\star$ 开始，并使用相同的步数和学习率。\n- 对于每种策略，计算流入旧任务子空间 $\\mathcal{S}_r$ 的累积梯度流幅度 $M$，并输出一个布尔值，指示 EWC 策略是否比基线策略减小了该幅度，即 $M_{\\text{ewc}}  M_{\\text{base}}$ 是否成立。\n\n所有计算都是纯数学的，并且必须使用上述定义。不涉及物理单位或角度。不得使用百分比。\n\n测试套件：\n- 使用 $d=m=6$，$K=3$，每个旧任务类别 $N_{\\text{old}}=120$ 个样本，每个新任务类别 $N_{\\text{new}}=120$ 个样本，$\\sigma=0.6$，旧任务学习率 $\\eta_{\\text{old}}=0.1$ 迭代 $200$ 步，新任务学习率 $\\eta_{\\text{new}}$ 和步数如下面每个案例指定。旧任务的类别均值必须是 $\\boldsymbol{\\mu}_k^{\\text{old}} = a\\,\\mathbf{e}_k$（对于 $k=1,2,3$），其中 $\\mathbf{e}_k$ 是 $\\mathbb{R}^m$ 中的第 $k$ 个标准基向量，$a=2.5$，每个 $\\boldsymbol{\\mu}_k^{\\text{old}}$ 的其余坐标为零。\n- 将四个测试案例定义为元组 $(\\text{seed}, r, \\lambda, \\eta_{\\text{new}}, T)$：\n    1. $(42, 8, 20.0, 0.08, 100)$，一般情况。\n    2. $(7, 0, 20.0, 0.08, 100)$，$r=0$ 的边界情况（空子空间）。\n    3. $(123, 8, 0.0, 0.08, 100)$，$\\lambda=0$ 的边缘情况（无 EWC 效应）。\n    4. $(2024, 18, 50.0, 0.06, 80)$，全维子空间 $r=K\\cdot m$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个逗号分隔的布尔值列表，用方括号括起来，按所列测试案例的顺序排列（例如，“[True,False,False,True]”）。", "solution": "问题陈述已经过分析，并被认为是有效的。它在科学上基于深度学习中持续学习的原理，所有必要的常数和定义都已提供，问题阐述清晰，并且其表述是客观的。任务是实现一个数值模拟，以根据指定的度量标准比较两种持续学习策略：基线微调和弹性权重巩固（EWC）。\n\n解决方案通过一系列计算步骤进行：\n\n### 1. 合成任务生成\n\n问题在嵌入空间中定义，其中嵌入矩阵是单位矩阵 $\\mathbf{E} = \\mathbf{I}_m$。因此，输入向量 $\\mathbf{x}$ 等同于嵌入向量 $\\mathbf{z} \\in \\mathbb{R}^m$。\n\n**旧任务：** 旧任务包含 $K=3$ 个类别。对于每个类别 $k \\in \\{0, 1, 2\\}$，我们通过从多元高斯分布 $\\mathcal{N}(\\boldsymbol{\\mu}_k^{\\text{old}}, \\sigma^2 \\mathbf{I}_m)$ 中采样来生成 $N_{\\text{old}}=120$ 个数据点 $\\mathbf{z}_i$。指定的参数为 $m=6$，$\\sigma=0.6$，均值由 $\\boldsymbol{\\mu}_k^{\\text{old}} = a\\,\\mathbf{e}_{k+1}$ 给出，其中 $a=2.5$，$\\mathbf{e}_{j}$ 是 $\\mathbb{R}^m$ 中的第 $j$ 个标准基向量。旧任务样本总数为 $N = K \\times N_{\\text{old}} = 360$。每个样本 $(\\mathbf{z}_i, \\mathbf{y}_i)$ 都包含一个独热编码的标签向量 $\\mathbf{y}_i \\in \\{0,1\\}^K$。\n\n**新任务：** 生成一个随机正交矩阵 $\\mathbf{R} \\in \\mathbb{R}^{m \\times m}$。通过旋转旧任务的均值来创建新任务的均值：$\\boldsymbol{\\mu}_k^{\\text{new}} = \\mathbf{R}\\boldsymbol{\\mu}_k^{\\text{old}}$。然后通过从 $\\mathcal{N}(\\boldsymbol{\\mu}_k^{\\text{new}}, \\sigma^2 \\mathbf{I}_m)$ 中为每个类别采样 $N_{\\text{new}}=120$ 个点来生成新任务数据。这种构造确保了类别分离的内在结构得以保留，但在嵌入空间中方向不同，从而创造了一个模型必须适应的场景。\n\n### 2. 在旧任务上进行训练\n\n分类器矩阵 $\\mathbf{C} \\in \\mathbb{R}^{K \\times m}$ 在旧任务数据的全批量上进行训练。从初始矩阵 $\\mathbf{C}_0 = \\mathbf{0}$ 开始，我们使用学习率 $\\eta_{\\text{old}}=0.1$ 执行 $T_{\\text{old}}=200$ 步梯度下降。目标函数是数据集上的平均交叉熵损失。每一步分类器的更新规则是：\n$$\n\\mathbf{C}_{t+1} = \\mathbf{C}_t - \\eta_{\\text{old}} \\nabla_{\\mathbf{C}} J(\\mathbf{C}_t)\n$$\n其中，全批量损失 $J(\\mathbf{C}) = \\frac{1}{N} \\sum_{i=1}^N L(\\mathbf{C}; \\mathbf{z}_i, \\mathbf{y}_i)$ 的梯度由下式给出：\n$$\n\\nabla_{\\mathbf{C}} J(\\mathbf{C}) = \\frac{1}{N} \\sum_{i=1}^N (\\mathbf{p}_i - \\mathbf{y}_i)\\mathbf{z}_i^\\top = \\frac{1}{N}(\\mathbf{P} - \\mathbf{Y})\\mathbf{Z}^\\top\n$$\n这里，$\\mathbf{P}$ 是 softmax 概率矩阵，$\\mathbf{Y}$ 是独热标签矩阵，$\\mathbf{Z}$ 是数据点矩阵，每个样本作为一列。最终训练好的分类器表示为 $\\mathbf{C}^\\star$。\n\n### 3. 费雪信息计算\n\n经验费雪信息矩阵的对角线 $\\mathbf{F}_{\\text{diag}}$ 量化了模型输出对其参数变化的敏感度，这是在旧任务上评估的。它在最优参数 $\\mathbf{C}^\\star$ 处计算：\n$$\n\\mathbf{F}_{\\text{diag}} = \\frac{1}{N} \\sum_{i=1}^N \\operatorname{vec}\\!\\left(\\nabla_{\\mathbf{C}} \\ell_i\\right) \\odot \\operatorname{vec}\\!\\left(\\nabla_{\\mathbf{C}} \\ell_i\\right)\n$$\n其中 $\\ell_i = L(\\mathbf{C}^\\star;\\mathbf{z}_i,\\mathbf{y}_i)$ 是第 $i$ 个旧任务样本的损失，$\\operatorname{vec}(\\cdot)$ 将 $K \\times m$ 的梯度矩阵展平为大小为 $Km$ 的向量，$\\odot$ 是逐元素乘积。这个向量 $\\mathbf{F}_{\\text{diag}}$ 识别出哪些参数对旧任务的性能最重要。\n\n### 4. 在新任务上进行微调\n\n我们比较两种使分类器适应新任务的策略，两者都从 $\\mathbf{C}^\\star$ 开始。\n\n**旧任务子空间：** 我们首先定义‘重要的’旧任务子空间 $\\mathcal{S}_r$。该子空间由与 $\\mathbf{F}_{\\text{diag}}$ 中 $r$ 个最大值相对应的 $r$ 个参数坐标所张成。我们定义一个投影算子 $\\mathcal{P}_{\\mathcal{S}_r}$，当应用于一个向量时，它会保留其在 $\\mathcal{S}_r$ 中的分量，并将所有其他分量置零。\n\n**策略和度量：**\n对于基线和 EWC 策略，我们都使用学习率 $\\eta_{\\text{new}}$ 在新任务数据上运行 $T$ 步梯度下降。令 $\\theta_t = \\operatorname{vec}(\\mathbf{C}_t)$ 为第 $t$ 步的向量化分类器参数。更新向量为 $\\Delta_t = -\\eta_{\\text{new}} \\nabla_\\theta J(\\mathbf{C}_t)$。我们跟踪投影到旧任务子空间上的更新的累积幅度：\n$$\nM = \\sum_{t=1}^T \\left\\|\\mathcal{P}_{\\mathcal{S}_r}(\\Delta_t)\\right\\|_2\n$$\n\n- **基线微调：** 目标函数就是新任务的损失 $J_{\\text{base}}$。梯度为 $\\nabla_\\theta J_{\\text{base}} = \\operatorname{vec}(\\frac{1}{N'}\\sum_{i=1}^{N'} (\\mathbf{p}'_i - \\mathbf{y}'_i)(\\mathbf{z}'_i)^\\top)$。累积流表示为 $M_{\\text{base}}$。\n\n- **EWC 微调：** 目标函数包含 EWC 惩罚项，$J_{\\text{ewc}}(\\mathbf{C}) = J_{\\text{base}}(\\mathbf{C}) + R(\\mathbf{C})$。梯度是基线梯度和惩罚项梯度之和：\n$$\n\\nabla_\\theta J_{\\text{ewc}} = \\nabla_\\theta J_{\\text{base}} + \\nabla_\\theta R(\\mathbf{C})\n$$\n其中 $\\nabla_\\theta R(\\mathbf{C}) = \\lambda\\,\\mathbf{F}_{\\text{diag}} \\odot (\\theta - \\theta^\\star)$。惩罚项将参数 $\\theta$ 拉回其在旧任务上的最优值 $\\theta^\\star$，其强度与参数的重要性（$\\mathbf{F}_{\\text{diag}}$）和超参数 $\\lambda$ 成正比。累积流表示为 $M_{\\text{ewc}}$。\n\n### 5. 评估\n\n对于每个测试案例，我们计算 $M_{\\text{base}}$ 和 $M_{\\text{ewc}}$。最终输出是一个布尔值，指示与基线相比，EWC 是否减少了在重要的旧任务子空间中的参数更新，即 $M_{\\text{ewc}}  M_{\\text{base}}$ 是否成立。预期 EWC 通过其设计会惩罚对重要的旧任务参数的更改，从而降低此度量值。边界情况（$r=0$ 和 $\\lambda=0$）用作健全性检查：如果子空间为空或惩罚为零，则预计不会有减少，两种策略应产生相等的幅度。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import ortho_group\n\ndef solve():\n    \"\"\"\n    Main function to run the continual learning simulation for all test cases.\n    \"\"\"\n\n    # --- Problem Constants ---\n    d_dim = 6\n    m_dim = 6\n    K_classes = 3\n    N_old_per_class = 120\n    N_new_per_class = 120\n    sigma = 0.6\n    a_mean_scale = 2.5\n    eta_old = 0.1\n    T_old = 200\n\n    test_cases = [\n        (42, 8, 20.0, 0.08, 100),\n        (7, 0, 20.0, 0.08, 100),\n        (123, 8, 0.0, 0.08, 100),\n        (2024, 18, 50.0, 0.06, 80),\n    ]\n\n    results = []\n\n    def stable_softmax(x, axis=None):\n        \"\"\"Numerically stable softmax function.\"\"\"\n        s = x - np.max(x, axis=axis, keepdims=True)\n        e_s = np.exp(s)\n        return e_s / np.sum(e_s, axis=axis, keepdims=True)\n\n    def generate_data(means, n_per_class, sigma_val, rng_gen):\n        \"\"\"Generates synthetic data for a task.\"\"\"\n        k, m = means.shape\n        n_total = k * n_per_class\n        Z_list = []\n        Y_list = []\n        for class_idx in range(k):\n            # Data: (m, n_per_class)\n            Z_class = rng_gen.normal(loc=means[class_idx, :], scale=sigma_val, size=(n_per_class, m)).T\n            Z_list.append(Z_class)\n            # Labels: (k, n_per_class)\n            y_vec = np.zeros((k, 1))\n            y_vec[class_idx] = 1\n            Y_class = np.tile(y_vec, (1, n_per_class))\n            Y_list.append(Y_class)\n        Z = np.hstack(Z_list)\n        Y = np.hstack(Y_list)\n        return Z, Y\n\n    def run_finetuning(C_init, Z_new, Y_new, eta, T, F_diag, lamb, projector_mask):\n        \"\"\"Runs the fine-tuning loop for a given strategy and computes M.\"\"\"\n        C = C_init.copy()\n        theta_star = C_init.ravel()\n        N_new = Z_new.shape[1]\n        M = 0.0\n        param_shape = C.shape\n\n        for _ in range(T):\n            theta = C.ravel()\n            \n            # Gradients\n            S_new = C @ Z_new\n            P_new = stable_softmax(S_new, axis=0)\n            grad_C_base = (P_new - Y_new) @ Z_new.T / N_new\n            grad_theta_base = grad_C_base.ravel()\n            \n            grad_theta_penalty = lamb * F_diag * (theta - theta_star)\n            grad_theta_total = grad_theta_base + grad_theta_penalty\n            \n            # Cumulative magnitude calculation\n            delta_t = -eta * grad_theta_total\n            delta_t_proj = delta_t * projector_mask\n            M += np.linalg.norm(delta_t_proj)\n            \n            # Parameter update\n            C -= eta * grad_theta_total.reshape(param_shape)\n        \n        return M\n\n    for case in test_cases:\n        seed, r_dim, lamb, eta_new, T_new = case\n        rng = np.random.default_rng(seed)\n\n        # --- 1. Old Task ---\n        N_old_total = K_classes * N_old_per_class\n        \n        # Generate data\n        mus_old = np.zeros((K_classes, m_dim))\n        for k in range(K_classes):\n            mus_old[k, k] = a_mean_scale\n        Z_old, Y_old = generate_data(mus_old, N_old_per_class, sigma, rng)\n\n        # Train on old task to find C_star\n        C = np.zeros((K_classes, m_dim))\n        for _ in range(T_old):\n            S_old = C @ Z_old\n            P_old = stable_softmax(S_old, axis=0)\n            grad_C = (P_old - Y_old) @ Z_old.T / N_old_total\n            C -= eta_old * grad_C\n        C_star = C\n\n        # --- 2. Calculate Fisher Information ---\n        vec_grads_sq_sum = np.zeros(K_classes * m_dim)\n        for i in range(N_old_total):\n            z_i = Z_old[:, i:i+1]\n            y_i = Y_old[:, i:i+1]\n            s_i = C_star @ z_i\n            p_i = stable_softmax(s_i, axis=0)\n            grad_C_i = (p_i - y_i) @ z_i.T\n            vec_grad_i = grad_C_i.ravel()\n            vec_grads_sq_sum += vec_grad_i**2\n        F_diag = vec_grads_sq_sum / N_old_total\n\n        # --- 3. New Task ---\n        N_new_total = K_classes * N_new_per_class\n        \n        # Generate Data\n        R_ortho = ortho_group.rvs(m_dim, random_state=rng)\n        mus_new = (R_ortho @ mus_old.T).T\n        Z_new, Y_new = generate_data(mus_new, N_new_per_class, sigma, rng)\n\n        # --- 4. Define Subspace Projector ---\n        # Get indices of the r largest values in F_diag\n        if r_dim > 0:\n            top_r_indices = np.argsort(F_diag)[-r_dim:]\n        else:\n            top_r_indices = []\n        \n        projector_mask = np.zeros_like(F_diag)\n        projector_mask[top_r_indices] = 1.0\n\n        # --- 5. Run and Compare Strategies ---\n        # Baseline (lambda = 0)\n        M_base = run_finetuning(C_star, Z_new, Y_new, eta_new, T_new, F_diag, 0.0, projector_mask)\n        \n        # EWC\n        M_ewc = run_finetuning(C_star, Z_new, Y_new, eta_new, T_new, F_diag, lamb, projector_mask)\n\n        results.append(M_ewc  M_base)\n\n    # --- Final Output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3109267"}, {"introduction": "除了对模型参数的改变进行惩罚，我们是否能完全“保护”旧任务的“记忆”呢？本练习介绍了一种基于投影的方法，它通过奇异值分解（Singular Value Decomposition, SVD）识别出对旧任务至关重要的权重“子空间”。随后，我们将新任务的学习更新量投影到与该子空间正交的零空间中，从而有效隔离任务间的干扰。这个动手实践将通过一个清晰、可分析的线性模型，展示投影方法的几何直觉，并让你理解如何精确地防止任务间的知识冲突 [@problem_id:3109216]。", "problem": "要求您实现并分析一种用于线性模型的持续学习策略，该策略通过将新任务的更新投影到一个通过奇异值分解（SVD）识别出的零空间上，来保护对先前学习任务至关重要的权重方向。目标是基于线性最小二乘法、平方损失的梯度以及源自奇异值分解（SVD）的正交投影的基本定义进行推理。您将量化这种保护在多大程度上减少了遗忘，遗忘程度以在新任务上执行一步梯度下降后旧任务损失的增加量来衡量。\n\n定义和框架：\n- 考虑一个线性模型，其权重为 $w \\in \\mathbb{R}^{d}$，平方损失为 $L(X,y;w) = \\frac{1}{2n}\\lVert Xw - y \\rVert_{2}^{2}$，其中 $X \\in \\mathbb{R}^{n \\times d}$ 且 $y \\in \\mathbb{R}^{n}$。\n- 对于旧任务，将数据表示为 $(X_{\\mathrm{old}}, y_{\\mathrm{old}})$，其中 $X_{\\mathrm{old}} \\in \\mathbb{R}^{n_{\\mathrm{old}} \\times d}$ 且 $y_{\\mathrm{old}} \\in \\mathbb{R}^{n_{\\mathrm{old}}}$。通过最小化岭回归正则化目标函数 $\\frac{1}{2n_{\\mathrm{old}}}\\lVert X_{\\mathrm{old}} w - y_{\\mathrm{old}} \\rVert_{2}^{2} + \\frac{\\lambda}{2}\\lVert w \\rVert_{2}^{2}$ 进行预训练，以获得 $w_{\\mathrm{old}}$。当 $\\lambda  0$ 时，这具有闭式解 $w_{\\mathrm{old}} = \\left(\\frac{1}{n_{\\mathrm{old}}}X_{\\mathrm{old}}^{\\top}X_{\\mathrm{old}} + \\lambda I\\right)^{-1}\\left(\\frac{1}{n_{\\mathrm{old}}}X_{\\mathrm{old}}^{\\top}y_{\\mathrm{old}}\\right)$。\n- 对于具有数据 $(X_{\\mathrm{new}}, y_{\\mathrm{new}})$ 的新任务，新损失在 $w_{\\mathrm{old}}$ 处的梯度为 $g = \\nabla_{w} \\left(\\frac{1}{2n_{\\mathrm{new}}}\\lVert X_{\\mathrm{new}}w - y_{\\mathrm{new}} \\rVert^{2}\\right)\\big\\rvert_{w=w_{\\mathrm{old}}} = \\frac{1}{n_{\\mathrm{new}}}X_{\\mathrm{new}}^{\\top}\\left(X_{\\mathrm{new}}w_{\\mathrm{old}} - y_{\\mathrm{new}}\\right)$。\n\n通过奇异值分解（SVD）识别重要子空间并加以保护：\n- 计算 $X_{\\mathrm{old}}$ 的奇异值分解（SVD）为 $X_{\\mathrm{old}} = U\\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{n_{\\mathrm{old}} \\times d}$ 具有标准正交列，$\\Sigma \\in \\mathbb{R}^{d \\times d}$ 为对角矩阵且其元素非负，$V \\in \\mathbb{R}^{d \\times d}$ 为正交矩阵。右奇异向量（$V$ 的列）是权重空间中的方向，而相应的奇异值量化了旧任务输出对沿这些方向移动的敏感度。前 $k$ 个右奇异向量 $V_{k} \\in \\mathbb{R}^{d \\times k}$ 的张成空间定义了需要保护的重要子空间。\n- 到与 $\\mathrm{span}(V_{k})$ 正交的子空间上的正交投影算子是 $P = I - V_{k}V_{k}^{\\top}$。将新任务的梯度 $g$ 投影为 $g_{\\perp} = Pg$，并通过 $w_{\\mathrm{proj}} = w_{\\mathrm{old}} - \\eta g_{\\perp}$ 更新 $w$，其中 $\\eta  0$ 是学习率。作为对比，朴素的无保护更新是 $w_{\\mathrm{naive}} = w_{\\mathrm{old}} - \\eta g$。\n\n量化遗忘：\n- 将旧任务损失定义为 $L_{\\mathrm{old}}(w) = \\frac{1}{2n_{\\mathrm{old}}}\\lVert X_{\\mathrm{old}}w - y_{\\mathrm{old}} \\rVert_{2}^{2}$。由更新 $w \\mapsto w'$ 引起的遗忘是 $\\Delta L_{\\mathrm{old}} = L_{\\mathrm{old}}(w') - L_{\\mathrm{old}}(w_{\\mathrm{old}})$。\n- 对于每个测试用例，根据各自的更新计算 $\\Delta L_{\\mathrm{naive}}$ 和 $\\Delta L_{\\mathrm{proj}}$，并报告比率 $r = \\frac{\\Delta L_{\\mathrm{proj}}}{\\Delta L_{\\mathrm{naive}}}$。如果 $\\Delta L_{\\mathrm{naive}}$ 在数值上为零（小于一个小的容差），则定义 $r = 0.0$。\n\n用于确定性、无单位实验的数据生成：\n- 使用由指定的整数种子 $s$ 初始化的伪随机数生成器来生成测试用例中的所有随机量。对于每个测试用例，使用以下固定的超参数：维度 $d = 6$，旧任务样本量 $n_{\\mathrm{old}} = 60$，新任务样本量 $n_{\\mathrm{new}} = 50$，岭系数 $\\lambda = 10^{-6}$，以及学习率 $\\eta = 0.5$。\n- 旧任务：从独立标准正态分布中抽取 $X_{\\mathrm{old}} \\in \\mathbb{R}^{60 \\times 6}$ 和 $w_{\\ast,\\mathrm{old}} \\in \\mathbb{R}^{6}$。设置 $y_{\\mathrm{old}} = X_{\\mathrm{old}} w_{\\ast,\\mathrm{old}}$（无观测噪声）。\n- 新任务：从独立标准正态分布中抽取 $X_{\\mathrm{new}} \\in \\mathbb{R}^{50 \\times 6}$。为精确控制新任务的梯度方向，首先计算SVD分解 $X_{\\mathrm{old}} = U\\Sigma V^{\\top}$。然后根据测试用例的模式（如下定义）选择一个目标方向 $a \\in \\mathbb{R}^{6}$。求解 $(X_{\\mathrm{new}}^{\\top}X_{\\mathrm{new}})v = a$ 得到 $v \\in \\mathbb{R}^{6}$，并设置 $y_{\\mathrm{new}} = X_{\\mathrm{new}} w_{\\mathrm{old}} - X_{\\mathrm{new}} v$。这种构造精确地得到 $g = \\frac{1}{n_{\\mathrm{new}}}a$，确保了新任务梯度与 $a$ 的确定性对齐。\n- 选择 $a$ 的模式：\n  - top：将 $a$ 设置为 $X_{\\mathrm{old}}$ 的第一个右奇异向量（$V$ 的第一列，在 Python 中为 `V[:,0]`）。\n  - orth：如果 $k  d$，将 $a$ 设置为第 $k+1$ 个右奇异向量（$V$ 的第 $k$ 列，在 Python 中为 `V[:,k]`）。\n  - mix：将 $a$ 设置为一个受保护方向和一个未受保护方向的归一化凸组合，具体为 $a \\propto \\alpha V[:,0] + (1-\\alpha) V[:,j]$，其中 $V[:,i]$ 是 $V$ 的第 $i$ 列（0-索引），当 $k  d$ 时 $j = k$，否则 $j = 1$，且 $\\alpha = 0.6$。\n  - random：抽取一个标准正态向量并将其归一化为单位长度。\n\n测试套件：\n为以下五个测试用例实现上述流程，每个测试用例由一个三元组 $(s,k,\\text{mode})$ 指定：\n- $(7, 0, \\text{top})$\n- $(11, 6, \\text{top})$\n- $(5, 2, \\text{top})$\n- $(13, 2, \\text{orth})$\n- $(17, 3, \\text{mix})$\n\n要求的输出：\n- 对于每个测试用例，计算如上定义的比率 $r = \\frac{\\Delta L_{\\mathrm{proj}}}{\\Delta L_{\\mathrm{naive}}}$。输出是无单位的实数。您的程序应生成单行输出，其中包含按上述测试用例顺序排列的结果，格式为方括号括起来的逗号分隔列表（例如，“[0.5,0.0,1.0]”）。", "solution": "该问题要求实现并分析一种旨在减轻线性模型中灾难性遗忘的持续学习策略。其核心原则是在学习新任务的同时，保护从先前任务（“旧任务”）中获得的知识。这种保护是通过识别对旧任务性能至关重要的模型权重子空间，然后将新任务的更新限制在该子空间的正交空间内来实现的。该方法利用奇异值分解（SVD）来识别关键子空间，并利用正交投影来强制施加学习约束。\n\n首先，我们建立数学框架。我们考虑一个线性模型 $f(x; w) = x^{\\top}w$，其权重为 $w \\in \\mathbb{R}^{d}$。对于一个数据集 $(X, y)$，其中 $X \\in \\mathbb{R}^{n \\times d}$ 且 $y \\in \\mathbb{R}^{n}$，其性能由均方误差（或称平方损失）来衡量，$L(X,y;w) = \\frac{1}{2n}\\lVert Xw - y \\rVert_{2}^{2}$。\n\n该过程始于在由数据 $(X_{\\mathrm{old}}, y_{\\mathrm{old}})$ 定义的“旧任务”上训练模型。为获得初始权重 $w_{\\mathrm{old}}$，我们最小化一个岭回归正则化目标函数，以确保问题是适定的（well-posed）并防止权重过大：\n$$\n\\min_{w} \\left( \\frac{1}{2n_{\\mathrm{old}}}\\lVert X_{\\mathrm{old}} w - y_{\\mathrm{old}} \\rVert_{2}^{2} + \\frac{\\lambda}{2}\\lVert w \\rVert_{2}^{2} \\right)\n$$\n这个凸优化问题的解有闭式形式：\n$$\nw_{\\mathrm{old}} = \\left(\\frac{1}{n_{\\mathrm{old}}}X_{\\mathrm{old}}^{\\top}X_{\\mathrm{old}} + \\lambda I\\right)^{-1}\\left(\\frac{1}{n_{\\mathrm{old}}}X_{\\mathrm{old}}^{\\top}y_{\\mathrm{old}}\\right)\n$$\n其中 $I$ 是 $d \\times d$ 的单位矩阵，$\\lambda  0$ 是正则化系数。\n\n接下来，为了识别权重空间中对旧任务最重要的方向，我们对数据矩阵执行奇异值分解（SVD）$X_{\\mathrm{old}} = U\\Sigma V^{\\top}$。这里，$V \\in \\mathbb{R}^{d \\times d}$ 的列是右奇异向量，它们构成了权重空间 $\\mathbb{R}^d$ 的一个标准正交基。$\\Sigma$ 对角线上的相应奇异值表示旧任务的预测对沿这些方向的权重扰动的敏感度。由前 $k$ 个右奇异向量张成的子空间 $\\mathrm{span}(V_{k})$（其中 $V_k \\in \\mathbb{R}^{d \\times k}$ 包含 $V$ 的前 $k$ 列）被认为是需要保护的“重要子空间”。\n\n当从数据 $(X_{\\mathrm{new}}, y_{\\mathrm{new}})$ 学习一个“新任务”时，标准方法是使用梯度步骤更新权重，$w_{\\mathrm{naive}} = w_{\\mathrm{old}} - \\eta g$，其中 $\\eta$ 是学习率，$g$ 是在 $w_{\\mathrm{old}}$ 处评估的新任务损失的梯度：\n$$\ng = \\nabla_{w} L_{\\mathrm{new}}(w)\\rvert_{w=w_{\\mathrm{old}}} = \\frac{1}{n_{\\mathrm{new}}}X_{\\mathrm{new}}^{\\top}\\left(X_{\\mathrm{new}}w_{\\mathrm{old}} - y_{\\mathrm{new}}\\right)\n$$\n为了保护旧任务，我们将此梯度投影到与重要子空间正交的子空间上。到这个“安全”零空间上的正交投影算子是 $P = I - V_{k}V_{k}^{\\top}$。投影后的梯度是 $g_{\\perp} = Pg$，相应的权重更新是 $w_{\\mathrm{proj}} = w_{\\mathrm{old}} - \\eta g_{\\perp}$。根据构造，更新步骤 $-\\eta g_{\\perp}$ 在受保护的子空间内没有分量，从而最大限度地减少了对旧任务知识的干扰。\n\n为了量化该策略的有效性，我们衡量每种更新类型引起的“遗忘”。遗忘被定义为更新后旧任务损失的增加量，$\\Delta L_{\\mathrm{old}} = L_{\\mathrm{old}}(w') - L_{\\mathrm{old}}(w_{\\mathrm{old}})$，其中 $w'$ 是更新后的权重向量。我们可以为这个变化推导出一个解析表达式。设 $w' = w_{\\mathrm{old}} + \\delta w$。\n$$\nL_{\\mathrm{old}}(w') = \\frac{1}{2n_{\\mathrm{old}}}\\lVert X_{\\mathrm{old}}(w_{\\mathrm{old}} + \\delta w) - y_{\\mathrm{old}} \\rVert_{2}^{2} = \\frac{1}{2n_{\\mathrm{old}}}\\lVert (X_{\\mathrm{old}}w_{\\mathrm{old}} - y_{\\mathrm{old}}) + X_{\\mathrm{old}}\\delta w \\rVert_{2}^{2}\n$$\n展开范数并减去 $L_{\\mathrm{old}}(w_{\\mathrm{old}})$ 得到：\n$$\n\\Delta L_{\\mathrm{old}} = \\frac{1}{n_{\\mathrm{old}}}(X_{\\mathrm{old}}w_{\\mathrm{old}} - y_{\\mathrm{old}})^{\\top}X_{\\mathrm{old}}\\delta w + \\frac{1}{2n_{\\mathrm{old}}}\\delta w^{\\top}X_{\\mathrm{old}}^{\\top}X_{\\mathrm{old}}\\delta w\n$$\n根据 $w_{\\mathrm{old}}$ 的岭回归最优性条件，我们知道 $\\nabla_{w}L_{\\mathrm{old}}(w_{\\mathrm{old}}) + \\lambda w_{\\mathrm{old}} = 0$，这意味着 $\\frac{1}{n_{\\mathrm{old}}}X_{\\mathrm{old}}^{\\top}(X_{\\mathrm{old}}w_{\\mathrm{old}} - y_{\\mathrm{old}}) = -\\lambda w_{\\mathrm{old}}$。将此代入上述表达式，并设 $\\delta w = -\\eta \\Delta w$（其中 $\\Delta w$ 是 $g$ 或 $g_{\\perp}$），我们得到一个计算上更高效的公式：\n$$\n\\Delta L_{\\mathrm{old}} = \\eta \\lambda w_{\\mathrm{old}}^{\\top}\\Delta w + \\frac{\\eta^2}{2n_{\\mathrm{old}}} \\Delta w^{\\top}X_{\\mathrm{old}}^{\\top}X_{\\mathrm{old}}\\Delta w\n$$\n使用这个公式，我们计算 $\\Delta L_{\\mathrm{naive}}$（其中 $\\Delta w = g$）和 $\\Delta L_{\\mathrm{proj}}$（其中 $\\Delta w = g_{\\perp}$）。最终的度量指标是比率 $r = \\frac{\\Delta L_{\\mathrm{proj}}}{\\Delta L_{\\mathrm{naive}}}$，它衡量了遗忘的减少程度。\n\n实验设置经过精心设计，以探究该方法的行为。新任务的数据 $(X_{\\mathrm{new}}, y_{\\mathrm{new}})$ 的构造方式使得最终的梯度 $g$ 与选定的方向 $a$ 精确对齐，从而确保了对梯度与受保护子空间的对齐方式如何影响遗忘进行确定性分析。不同的模式（`top`、`orth`、`mix`）代表了相对于旧任务的关键方向，新任务是最大程度冲突、完全不冲突或两者混合的场景。\n\n实现过程如下：\n1.  使用给定的种子初始化随机数生成器以确保可复现性。\n2.  生成旧任务数据，并通过岭回归的闭式解计算 $w_{\\mathrm{old}}$。\n3.  对 $X_{\\mathrm{old}}$ 执行SVD以获得基 $V$。\n4.  根据测试用例的模式和 $V$ 的列来构造新任务的梯度方向 $a$。梯度则为 $g=a/n_{\\mathrm{new}}$。\n5.  计算投影梯度 $g_{\\perp} = (I - V_k V_k^{\\top})g$，其中 $V_k$ 由 $V$ 的前 $k$ 列组成。\n6.  使用推导出的解析公式计算 $\\Delta L_{\\mathrm{naive}}$ 和 $\\Delta L_{\\mathrm{proj}}$。\n7.  计算最终比率 $r$。\n对提供的每个测试用例重复此过程。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import svd, solve\n\ndef solve_problem():\n    \"\"\"\n    Implements and analyzes a continual learning strategy based on SVD and gradient projection.\n    \"\"\"\n\n    def run_one_case(s: int, k: int, mode: str) -> float:\n        \"\"\"\n        Runs a single test case for the continual learning simulation.\n\n        Args:\n            s: The seed for the pseudo-random number generator.\n            k: The number of top singular vectors to protect.\n            mode: The mode for generating the new task's gradient direction.\n\n        Returns:\n            The ratio of forgetting with projection to naive forgetting.\n        \"\"\"\n        rng = np.random.default_rng(s)\n\n        d = 6\n        n_old = 60\n        n_new = 50\n        lambda_reg = 1e-6\n        eta = 0.5\n        tolerance = 1e-12\n\n        # 1. Generate old task and compute optimal weights w_old\n        X_old = rng.standard_normal((n_old, d))\n        w_star_old = rng.standard_normal((d, 1))\n        y_old = X_old @ w_star_old\n\n        C = (1 / n_old) * (X_old.T @ X_old) + lambda_reg * np.identity(d)\n        b = (1 / n_old) * (X_old.T @ y_old)\n        w_old = solve(C, b, assume_a='pos')\n\n        # 2. SVD of old task data matrix\n        _, _, Vt = svd(X_old, full_matrices=False)\n        V = Vt.T\n\n        # 3. Construct new task gradient direction 'a'\n        a = np.zeros(d)\n        if mode == 'top':\n            a = V[:, 0]\n        elif mode == 'orth':\n            if k  d:\n                a = V[:, k]\n            else: # Should not happen with test cases, but handle gracefully\n                a = V[:, -1]\n        elif mode == 'mix':\n            j_idx = k if k  d else 1\n            a_unnorm = 0.6 * V[:, 0] + 0.4 * V[:, j_idx]\n            a = a_unnorm / np.linalg.norm(a_unnorm)\n        \n        g = a.reshape(-1, 1) / n_new\n\n        # 4. Project the gradient\n        if k > 0 and k = d:\n            Vk = V[:, :k]\n            P = np.identity(d) - Vk @ Vk.T\n            g_perp = P @ g\n        else: # k=0 means no protection\n            g_perp = g\n\n        # 5. Calculate forgetting\n        def calculate_forgetting(grad_update):\n            term1 = eta * lambda_reg * (w_old.T @ grad_update)\n            term2 = (eta**2 / (2 * n_old)) * (grad_update.T @ (X_old.T @ X_old) @ grad_update)\n            return (term1 + term2).item()\n\n        delta_L_naive = calculate_forgetting(g)\n        delta_L_proj = calculate_forgetting(g_perp)\n\n        # 6. Compute and return the ratio\n        if abs(delta_L_naive)  tolerance:\n            return 0.0\n        \n        return delta_L_proj / delta_L_naive\n\n    test_cases_spec = [\n        (7, 0, 'top'),\n        (11, 6, 'top'),\n        (5, 2, 'top'),\n        (13, 2, 'orth'),\n        (17, 3, 'mix')\n    ]\n\n    results = [run_one_case(*params) for params in test_cases_spec]\n    \n    print(f\"[{','.join([f'{r:.8f}' for r in results])}]\")\n\nsolve_problem()\n```", "id": "3109216"}, {"introduction": "让模型记住旧知识的另一种有效方法是让它进行“自我复习”。本练习深入探讨了知识蒸馏（Knowledge Distillation），一种基于重放的策略，其中学习新任务的“学生”模型需要同时模仿“教师”模型（即旧任务模型）的行为。我们将比较两种主要的蒸馏方式：模仿最终的输出概率（输出空间蒸馏）与模仿内部的特征表示（特征空间蒸馏）。通过实现并比较这两种方法，你将探索模型如何保留如决策边界位置等细粒度知识的微妙之处 [@problem_id:3109241]。", "problem": "给定一个深度学习中的二分类持续学习场景，其中一个先前在旧任务上训练好的模型在学习新任务时必须被保留。该模型架构是一个带双曲正切激活函数的单隐藏层神经网络和一个 softmax 输出层。需要实现并比较两种持续学习策略：输出空间蒸馏和特征空间蒸馏。目标是确定哪种策略在学习新任务的同时，能更好地保留旧任务的精细决策边界。\n\n您必须使用的基本依据包括以下定义和事实：\n- 对于 logits $\\mathbf{z} \\in \\mathbb{R}^C$，softmax 函数为 $p_k(\\mathbf{z}) = \\dfrac{\\exp(z_k)}{\\sum_{j=1}^C \\exp(z_j)}$，其中 $k \\in \\{1,\\dots,C\\}$，$C$ 是类别数。\n- one-hot 目标 $\\mathbf{y} \\in \\{0,1\\}^C$ 和预测概率 $\\mathbf{p} \\in [0,1]^C$ 之间的交叉熵损失为 $\\mathcal{L}_{\\mathrm{CE}}(\\mathbf{y},\\mathbf{p}) = -\\sum_{k=1}^C y_k \\log p_k$。\n- 从分布 $\\mathbf{q}$到 $\\mathbf{p}$ 的 Kullback–Leibler 散度是 $D_{\\mathrm{KL}}(\\mathbf{q}\\|\\mathbf{p}) = \\sum_{k=1}^C q_k \\log\\left(\\dfrac{q_k}{p_k}\\right)$，它可作为一种相异性度量。\n- 对于特征空间蒸馏，一个常见的对齐目标是教师和学生隐藏表示之间的均方误差 $\\mathcal{L}_{\\mathrm{MSE}}(\\mathbf{h}^{\\mathrm{old}},\\mathbf{h}^{\\mathrm{new}}) = \\|\\mathbf{h}^{\\mathrm{old}}-\\mathbf{h}^{\\mathrm{new}}\\|_2^2$。\n- 双曲正切激活函数为 $\\tanh(a) = \\dfrac{e^a - e^{-a}}{e^a + e^{-a}}$，其导数为 $\\dfrac{d}{da}\\tanh(a) = 1 - \\tanh^2(a)$。\n\n该网络的输入维度为 $d=2$，隐藏维度为 $H$，输出维度为 $C=2$。设隐藏表示为 $\\mathbf{h} = \\tanh(\\mathbf{x}\\mathbf{W}_1 + \\mathbf{b}_1)$，logits 为 $\\mathbf{z} = \\mathbf{h}\\mathbf{W}_2 + \\mathbf{b}_2$，概率为 $\\mathbf{p} = \\mathrm{softmax}(\\mathbf{z})$。对于二分类问题，精细决策边界可以通过有符号间隔 $m(\\mathbf{x}) = z_1(\\mathbf{x}) - z_0(\\mathbf{x})$ 来表征，边界位于 $m(\\mathbf{x})=0$ 处。精细决策边界的保留程度通过在旧任务边界附近的探测点上，间隔的平均绝对变化来衡量。\n\n您必须实现两种持续学习策略：\n- 输出空间蒸馏：在学习新任务的同时，惩罚教师模型在旧任务上的软化输出与学生模型的输出在温度 $T$ 下的散度。使用 Kullback–Leibler 散度和软化目标 $q^{(T)}(\\mathbf{z}/T)$，并包含标准的温度缩放因子以确保梯度被适当缩放。\n- 特征空间蒸馏：在学习新任务的同时，使用均方误差惩罚教师模型在旧数据上的隐藏特征与学生模型在相同数据上的隐藏特征之间的差异。\n\n需遵循的实验协议：\n1. 使用旧任务数据上的交叉熵损失训练一个教师模型（旧任务模型）。\n2. 为两种策略初始化一个具有相同架构和相同初始参数的学生模型，以确保公平比较。\n3. 分别在每种策略下，于新任务上训练学生模型：\n   - 输出空间蒸馏：最小化新任务交叉熵与旧任务数据上输出空间蒸馏 Kullback–Leibler 散度之和，该散度由蒸馏权重 $\\lambda_{\\mathrm{out}}$ 和温度 $T$ 缩放。\n   - 特征空间蒸馏：最小化新任务交叉熵与旧任务数据上特征空间均方误差之和，该误差由蒸馏权重 $\\lambda_{\\mathrm{feat}}$ 缩放。\n4. 通过选择教师模型的有符号间隔 $m_{\\mathrm{old}}(\\mathbf{x})$ 最接近 $0$ 的旧任务样本来构建探测点，这表示它们接近决策边界。在这些探测点上，为每种策略计算平均绝对间隔变化 $\\Delta = \\dfrac{1}{K} \\sum_{i=1}^K \\left| m_{\\mathrm{student}}(\\mathbf{x}_i) - m_{\\mathrm{old}}(\\mathbf{x}_i) \\right|$。\n5. 对于每个测试用例，输出一个布尔值，指示输出空间蒸馏是否产生严格小于特征空间蒸馏的 $\\Delta$。\n\n数据生成细节：\n- 旧任务：二分类，其类条件分布为：标签 $0$ 对应 $\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0^{\\mathrm{old}}, \\sigma_{\\mathrm{old}}^2 \\mathbf{I})$，标签 $1$ 对应 $\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1^{\\mathrm{old}}, \\sigma_{\\mathrm{old}}^2 \\mathbf{I})$。\n- 新任务：二分类，其类条件分布为：标签 $0$ 对应 $\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0^{\\mathrm{new}}, \\sigma_{\\mathrm{new}}^2 \\mathbf{I})$，标签 $1$ 对应 $\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1^{\\mathrm{new}}, \\sigma_{\\mathrm{new}}^2 \\mathbf{I})$。\n\n测试套件：\n- 用例 1：种子 $0$，$n_{\\mathrm{old}}=200$，$n_{\\mathrm{new}}=200$，$\\boldsymbol{\\mu}_0^{\\mathrm{old}}=(-1.0,0.0)$，$\\boldsymbol{\\mu}_1^{\\mathrm{old}}=(1.0,0.0)$，$\\sigma_{\\mathrm{old}}=0.4$，$\\boldsymbol{\\mu}_0^{\\mathrm{new}}=(0.0,-1.0)$，$\\boldsymbol{\\mu}_1^{\\mathrm{new}}=(0.0,1.0)$，$\\sigma_{\\mathrm{new}}=0.4$，隐藏层大小 $H=16$，学习率 $\\eta=0.05$，教师迭代次数 $300$，学生迭代次数 $300$，蒸馏权重 $\\lambda_{\\mathrm{out}}=0.5$，$\\lambda_{\\mathrm{feat}}=0.5$，温度 $T=2.0$，探测点数量 $K=40$。\n- 用例 2：种子 $1$，$n_{\\mathrm{old}}=240$，$n_{\\mathrm{new}}=240$，$\\boldsymbol{\\mu}_0^{\\mathrm{old}}=(-0.3,0.0)$，$\\boldsymbol{\\mu}_1^{\\mathrm{old}}=(0.3,0.0)$，$\\sigma_{\\mathrm{old}}=0.35$，$\\boldsymbol{\\mu}_0^{\\mathrm{new}}=(0.0,-0.6)$，$\\boldsymbol{\\mu}_1^{\\mathrm{new}}=(0.0,0.6)$，$\\sigma_{\\mathrm{new}}=0.35$，隐藏层大小 $H=24$，学习率 $\\eta=0.05$，教师迭代次数 $400$，学生迭代次数 $350$，蒸馏权重 $\\lambda_{\\mathrm{out}}=0.4$，$\\lambda_{\\mathrm{feat}}=0.8$，温度 $T=2.5$，探测点数量 $K=60$。\n- 用例 3：种子 $2$，$n_{\\mathrm{old}}=220$，$n_{\\mathrm{new}}=220$，$\\boldsymbol{\\mu}_0^{\\mathrm{old}}=(-0.8,-0.2)$，$\\boldsymbol{\\mu}_1^{\\mathrm{old}}=(0.8,0.2)$，$\\sigma_{\\mathrm{old}}=0.45$，$\\boldsymbol{\\mu}_0^{\\mathrm{new}}=(0.2,-0.8)$，$\\boldsymbol{\\mu}_1^{\\mathrm{new}}=(-0.2,0.8)$，$\\sigma_{\\mathrm{new}}=0.45$，隐藏层大小 $H=20$，学习率 $\\eta=0.05$，教师迭代次数 $350$，学生迭代次数 $320$，蒸馏权重 $\\lambda_{\\mathrm{out}}=0.0$，$\\lambda_{\\mathrm{feat}}=0.6$，温度 $T=2.0$，探测点数量 $K=50$。\n\n您的程序必须：\n- 实现上述训练和评估过程。\n- 对于每个测试用例，计算输出空间蒸馏在探测点上是否获得了比特征空间蒸馏严格更小的平均绝对间隔变化 $\\Delta$，并返回一个布尔值。\n- 生成单行输出，包含方括号括起来的逗号分隔的结果列表（例如，$\\left[\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3\\right]$）。本问题无需物理单位、角度单位或百分比。", "solution": "用户提供了一个问题陈述，要求在一个双层神经网络的背景下，实现并比较两种持续学习策略——输出空间蒸馏和特征空间蒸馏。该问题定义明确，科学上基于深度学习的原理，并且计算上是可行的。所有必要的参数、数据生成过程和评估指标都已指定，使得该问题有效。\n\n解决方案将首先概述数学框架，包括网络架构和损失函数，然后描述训练和评估协议。\n\n### 1. 模型和数据规范\n\n该模型是一个为二分类（$C=2$）设计的单隐藏层神经网络。输入 $\\mathbf{x} \\in \\mathbb{R}^d$（其中 $d=2$）按以下方式处理：\n- 隐藏层的预激活值为 $\\mathbf{a}_1 = \\mathbf{x}\\mathbf{W}_1 + \\mathbf{b}_1$，其中 $\\mathbf{W}_1 \\in \\mathbb{R}^{d \\times H}$ 和 $\\mathbf{b}_1 \\in \\mathbb{R}^{H}$ 分别是第一层的权重和偏置，$H$ 是隐藏维度。\n- 通过应用双曲正切激活函数获得隐藏表示：$\\mathbf{h} = \\tanh(\\mathbf{a}_1)$。\n- logits（输出层的预激活值）为 $\\mathbf{z} = \\mathbf{h}\\mathbf{W}_2 + \\mathbf{b}_2$，其中 $\\mathbf{W}_2 \\in \\mathbb{R}^{H \\times C}$ 和 $\\mathbf{b}_2 \\in \\mathbb{R}^{C}$。\n- 最终的类别概率通过 softmax 函数计算：$\\mathbf{p} = \\mathrm{softmax}(\\mathbf{z})$，其中 $p_k(\\mathbf{z}) = \\frac{\\exp(z_k)}{\\sum_{j=1}^C \\exp(z_j)}$。\n\n旧任务和新任务的数据都从二维高斯分布生成。对于给定任务，类别 0 的样本从 $\\mathcal{N}(\\boldsymbol{\\mu}_0, \\sigma^2 \\mathbf{I})$ 中抽取，类别 1 的样本从 $\\mathcal{N}(\\boldsymbol{\\mu}_1, \\sigma^2 \\mathbf{I})$ 中抽取。\n\n### 2. 教师模型训练\n\n首先，一个“教师”模型专门在旧任务数据上进行训练。训练目标是最小化 one-hot 编码的真实标签 $\\mathbf{y}$ 与模型预测概率 $\\mathbf{p}$ 之间的标准交叉熵损失 $\\mathcal{L}_{\\mathrm{CE}}$：\n$$\n\\mathcal{L}_{\\mathrm{CE}}(\\mathbf{y}, \\mathbf{p}) = -\\frac{1}{N} \\sum_{i=1}^N \\sum_{k=1}^C y_{ik} \\log p_{ik}\n$$\n其中 $N$ 是样本数量。参数 $\\theta_{\\text{old}} = \\{\\mathbf{W}_1, \\mathbf{b}_1, \\mathbf{W}_2, \\mathbf{b}_2\\}$ 使用梯度下降进行更新。对于单个样本，损失关于 logits $\\mathbf{z}$ 的梯度是 $\\mathbf{p} - \\mathbf{y}$。这个梯度然后通过网络反向传播，以计算所有参数的梯度。\n\n### 3. 学生模型训练策略\n\n然后，一个具有相同架构和一套全新初始随机权重的“学生”模型在新任务上进行训练。为防止对旧任务的灾难性遗忘，训练目标中增加了一个蒸馏损失。比较了两种策略。\n\n#### 3.1. 输出空间蒸馏\n\n在这种策略中，训练学生模型以匹配教师模型在旧任务数据上的软化输出。总损失函数是新任务数据上的交叉熵损失与旧任务数据上的蒸馏损失的加权和：\n$$\n\\mathcal{L}_{\\text{out}} = \\mathcal{L}_{\\mathrm{CE}}(\\text{新数据}) + \\lambda_{\\mathrm{out}} \\mathcal{L}_{\\mathrm{distill}}(\\text{旧数据})\n$$\n蒸馏损失 $\\mathcal{L}_{\\mathrm{distill}}$ 是教师和学生软化概率分布之间的 Kullback-Leibler 散度，并由温度因子 $T^2$ 缩放：\n$$\n\\mathcal{L}_{\\mathrm{distill}} = T^2 D_{\\mathrm{KL}}(\\mathbf{q}^{(T)} \\| \\mathbf{p}^{(T)})\n$$\n其中 $\\mathbf{p}^{(T)} = \\mathrm{softmax}(\\mathbf{z}_{\\text{student}}/T)$ 和 $\\mathbf{q}^{(T)} = \\mathrm{softmax}(\\mathbf{z}_{\\text{teacher}}/T)$ 是分别用温度 $T$ 计算的学生和教师的概率。最小化 $D_{\\mathrm{KL}}$ 等价于最小化 $\\mathbf{q}^{(T)}$ 和 $\\mathbf{p}^{(T)}$ 之间的交叉熵，因为 $\\mathbf{q}^{(T)}$ 的熵对于学生模型的参数是常数。\n$\\mathcal{L}_{\\mathrm{distill}}$ 关于学生 logits $\\mathbf{z}_{\\text{student}}$ 的梯度是：\n$$\n\\frac{\\partial \\mathcal{L}_{\\mathrm{distill}}}{\\partial \\mathbf{z}_{\\text{student}}} = \\mathbf{p}^{(T)} - \\mathbf{q}^{(T)}\n$$\n学生参数 $\\theta_{\\text{student}}$ 的总梯度是源自新数据上 $\\mathcal{L}_{\\mathrm{CE}}$ 的梯度和源自旧数据上 $\\lambda_{\\mathrm{out}} \\mathcal{L}_{\\mathrm{distill}}$ 的梯度的总和。\n\n#### 3.2. 特征空间蒸馏\n\n在这里，鼓励学生学习与教师相似的隐藏表示。损失函数是：\n$$\n\\mathcal{L}_{\\text{feat}} = \\mathcal{L}_{\\mathrm{CE}}(\\text{新数据}) + \\lambda_{\\mathrm{feat}} \\mathcal{L}_{\\mathrm{MSE}}(\\text{旧数据})\n$$\n特征空间蒸馏损失 $\\mathcal{L}_{\\mathrm{MSE}}$ 是教师和学生在旧任务数据上的隐藏层激活值（$\\mathbf{h}_{\\text{teacher}}$ 和 $\\mathbf{h}_{\\text{student}}$）之间的均方误差：\n$$\n\\mathcal{L}_{\\mathrm{MSE}} = \\|\\mathbf{h}_{\\text{student}} - \\mathbf{h}_{\\text{teacher}}\\|_2^2 = \\sum_{j=1}^H (h_{\\text{student}, j} - h_{\\text{teacher}, j})^2\n$$\n该损失关于学生隐藏激活值 $\\mathbf{h}_{\\text{student}}$ 的梯度是 $2(\\mathbf{h}_{\\text{student}} - \\mathbf{h}_{\\text{teacher}})$。这个梯度通过第一层的激活函数和权重进行反向传播。最后一层的参数 $(\\mathbf{W}_2, \\mathbf{b}_2)$ 不受此蒸馏损失的影响，仅根据新任务的 $\\mathcal{L}_{\\mathrm{CE}}$ 进行更新。第一层的参数 $(\\mathbf{W}_1, \\mathbf{b}_1)$ 使用来自两个损失分量的组合梯度进行更新。\n\n### 4. 评估方法\n\n旧任务决策边界的保留情况通过在特定的“探测点”测量模型的有符号间隔的变化来量化。有符号间隔定义为 $m(\\mathbf{x}) = z_1(\\mathbf{x}) - z_0(\\mathbf{x})$，其中决策边界位于 $m(\\mathbf{x}) = 0$ 处。\n\n探测点是旧任务训练集中教师模型的绝对间隔 $|m_{\\text{old}}(\\mathbf{x})|$ 最小的 $K$ 个样本。根据定义，这些点最接近教师学习到的决策边界。\n\n对于每个学生模型（每种策略一个），在这 $K$ 个探测点上计算平均绝对间隔变化 $\\Delta$：\n$$\n\\Delta = \\frac{1}{K} \\sum_{i=1}^K |m_{\\text{student}}(\\mathbf{x}_i) - m_{\\text{old}}(\\mathbf{x}_i)|\n$$\n较小的 $\\Delta$ 表示对精细决策边界的保留效果更好。每个测试用例的最终输出是一个布尔值，指示输出空间蒸馏是否实现了比特征空间蒸馏严格更小的 $\\Delta$ ($\\Delta_{\\text{out}}  \\Delta_{\\text{feat}}$)。", "answer": "```python\nimport numpy as np\n\ndef softmax(z):\n    \"\"\"Computes softmax for a batch of logits.\"\"\"\n    # Subtract max for numerical stability\n    exp_z = np.exp(z - np.max(z, axis=-1, keepdims=True))\n    return exp_z / np.sum(exp_z, axis=-1, keepdims=True)\n\ndef tanh(a):\n    \"\"\"Hyperbolic tangent activation.\"\"\"\n    return np.tanh(a)\n\ndef one_hot(y, C):\n    \"\"\"Converts a vector of labels to one-hot encoding.\"\"\"\n    return np.eye(C)[y]\n\nclass NeuralNetwork:\n    \"\"\"A one-hidden-layer neural network.\"\"\"\n\n    def __init__(self, d, H, C, seed):\n        \"\"\"Initializes network parameters.\"\"\"\n        rng = np.random.default_rng(seed)\n        # Xavier/Glorot initialization for tanh activation\n        self.W1 = rng.normal(0, np.sqrt(1.0 / d), (d, H))\n        self.b1 = np.zeros((1, H))\n        self.W2 = rng.normal(0, np.sqrt(1.0 / H), (H, C))\n        self.b2 = np.zeros((1, C))\n\n    def get_params(self):\n        \"\"\"Returns a copy of the model parameters.\"\"\"\n        return self.W1.copy(), self.b1.copy(), self.W2.copy(), self.b2.copy()\n\n    def set_params(self, W1, b1, W2, b2):\n        \"\"\"Sets the model parameters.\"\"\"\n        self.W1, self.b1, self.W2, self.b2 = W1, b1, W2, b2\n\n    def forward(self, X):\n        \"\"\"Performs a forward pass.\"\"\"\n        a1 = X @ self.W1 + self.b1\n        h = tanh(a1)\n        z = h @ self.W2 + self.b2\n        p = softmax(z)\n        return z, p, h, a1\n\n    def get_margin(self, X):\n        \"\"\"Computes the signed margin for binary classification.\"\"\"\n        z, _, _, _ = self.forward(X)\n        return z[:, 1] - z[:, 0]\n\n    def train_teacher(self, X_old, y_old_one_hot, eta, iterations):\n        \"\"\"Trains the teacher model using standard gradient descent.\"\"\"\n        n_samples = X_old.shape[0]\n        for _ in range(iterations):\n            z, p, h, a1 = self.forward(X_old)\n            \n            # Gradient of CE loss w.r.t logits\n            dz = (p - y_old_one_hot) / n_samples\n            \n            # Backpropagate gradients\n            dW2 = h.T @ dz\n            db2 = np.sum(dz, axis=0, keepdims=True)\n            \n            dh = dz @ self.W2.T\n            da1 = dh * (1 - h**2)\n            \n            dW1 = X_old.T @ da1\n            db1 = np.sum(da1, axis=0, keepdims=True)\n            \n            # Update parameters\n            self.W1 -= eta * dW1\n            self.b1 -= eta * db1\n            self.W2 -= eta * dW2\n            self.b2 -= eta * db2\n\n    def train_student_output_distill(self, X_new, y_new_one_hot, X_old, teacher_model, eta, iterations, lambda_out, T):\n        \"\"\"Trains a student using output-space distillation.\"\"\"\n        n_new, n_old = X_new.shape[0], X_old.shape[0]\n        for _ in range(iterations):\n            # Gradients from new task (Cross-Entropy)\n            z_new, p_new, h_new, _ = self.forward(X_new)\n            dz_ce = (p_new - y_new_one_hot) / n_new\n            dW2_ce = h_new.T @ dz_ce\n            db2_ce = np.sum(dz_ce, axis=0, keepdims=True)\n            dh_ce = dz_ce @ self.W2.T\n            da1_ce = dh_ce * (1 - h_new**2)\n            dW1_ce = X_new.T @ da1_ce\n            db1_ce = np.sum(da1_ce, axis=0, keepdims=True)\n            \n            # Gradients from old task (Distillation)\n            if lambda_out > 0:\n                z_old_student, _, h_old_student, _ = self.forward(X_old)\n                z_old_teacher, _, _, _ = teacher_model.forward(X_old)\n                \n                p_student_soft = softmax(z_old_student / T)\n                p_teacher_soft = softmax(z_old_teacher / T)\n                \n                # Gradient of T^2 * D_KL w.r.t logits\n                dz_kl = (p_student_soft - p_teacher_soft) / n_old\n                \n                dW2_kl = h_old_student.T @ dz_kl\n                db2_kl = np.sum(dz_kl, axis=0, keepdims=True)\n                dh_kl = dz_kl @ self.W2.T\n                da1_kl = dh_kl * (1 - h_old_student**2)\n                dW1_kl = X_old.T @ da1_kl\n                db1_kl = np.sum(da1_kl, axis=0, keepdims=True)\n            else:\n                dW1_kl, db1_kl, dW2_kl, db2_kl = 0, 0, 0, 0\n                \n            # Combine gradients and update\n            self.W1 -= eta * (dW1_ce + lambda_out * dW1_kl)\n            self.b1 -= eta * (db1_ce + lambda_out * db1_kl)\n            self.W2 -= eta * (dW2_ce + lambda_out * dW2_kl)\n            self.b2 -= eta * (db2_ce + lambda_out * db2_kl)\n\n    def train_student_feature_distill(self, X_new, y_new_one_hot, X_old, teacher_model, eta, iterations, lambda_feat):\n        \"\"\"Trains a student using feature-space distillation.\"\"\"\n        n_new, n_old = X_new.shape[0], X_old.shape[0]\n        for _ in range(iterations):\n            # Gradients from new task (Cross-Entropy)\n            z_new, p_new, h_new, _ = self.forward(X_new)\n            dz_ce = (p_new - y_new_one_hot) / n_new\n            dW2_ce = h_new.T @ dz_ce\n            db2_ce = np.sum(dz_ce, axis=0, keepdims=True)\n            dh_ce = dz_ce @ self.W2.T\n            da1_ce = dh_ce * (1 - h_new**2)\n            dW1_ce = X_new.T @ da1_ce\n            db1_ce = np.sum(da1_ce, axis=0, keepdims=True)\n            \n            # Gradients from old task (Feature MSE)\n            if lambda_feat > 0:\n                _, _, h_old_student, _ = self.forward(X_old)\n                _, _, h_old_teacher, _ = teacher_model.forward(X_old)\n                \n                # Gradient of MSE loss w.r.t student's hidden activations\n                dh_mse = 2 * (h_old_student - h_old_teacher) / n_old\n                da1_mse = dh_mse * (1 - h_old_student**2)\n                dW1_mse = X_old.T @ da1_mse\n                db1_mse = np.sum(da1_mse, axis=0, keepdims=True)\n                dW2_mse, db2_mse = 0, 0\n            else:\n                dW1_mse, db1_mse, dW2_mse, db2_mse = 0, 0, 0, 0\n\n            # Combine gradients and update\n            self.W1 -= eta * (dW1_ce + lambda_feat * dW1_mse)\n            self.b1 -= eta * (db1_ce + lambda_feat * db1_mse)\n            self.W2 -= eta * (dW2_ce + lambda_feat * dW2_mse)\n            self.b2 -= eta * (db2_ce + lambda_feat * db2_mse)\n\ndef generate_data(n_samples, mu0, mu1, sigma, seed):\n    \"\"\"Generates 2D Gaussian data for binary classification.\"\"\"\n    rng = np.random.default_rng(seed)\n    n0 = n_samples // 2\n    n1 = n_samples - n0\n    X0 = rng.normal(loc=mu0, scale=sigma, size=(n0, 2))\n    X1 = rng.normal(loc=mu1, scale=sigma, size=(n1, 2))\n    X = np.vstack((X0, X1))\n    y = np.array([0] * n0 + [1] * n1)\n    return X, y\n\ndef solve():\n    \"\"\"Main function to run the experiment for all test cases.\"\"\"\n    test_cases = [\n        {'seed': 0, 'n_old': 200, 'n_new': 200, 'mu0_old': (-1.0, 0.0), 'mu1_old': (1.0, 0.0), 'sigma_old': 0.4, 'mu0_new': (0.0, -1.0), 'mu1_new': (0.0, 1.0), 'sigma_new': 0.4, 'H': 16, 'eta': 0.05, 'teacher_iterations': 300, 'student_iterations': 300, 'lambda_out': 0.5, 'lambda_feat': 0.5, 'T': 2.0, 'K': 40},\n        {'seed': 1, 'n_old': 240, 'n_new': 240, 'mu0_old': (-0.3, 0.0), 'mu1_old': (0.3, 0.0), 'sigma_old': 0.35, 'mu0_new': (0.0, -0.6), 'mu1_new': (0.0, 0.6), 'sigma_new': 0.35, 'H': 24, 'eta': 0.05, 'teacher_iterations': 400, 'student_iterations': 350, 'lambda_out': 0.4, 'lambda_feat': 0.8, 'T': 2.5, 'K': 60},\n        {'seed': 2, 'n_old': 220, 'n_new': 220, 'mu0_old': (-0.8, -0.2), 'mu1_old': (0.8, 0.2), 'sigma_old': 0.45, 'mu0_new': (0.2, -0.8), 'mu1_new': (-0.2, 0.8), 'sigma_new': 0.45, 'H': 20, 'eta': 0.05, 'teacher_iterations': 350, 'student_iterations': 320, 'lambda_out': 0.0, 'lambda_feat': 0.6, 'T': 2.0, 'K': 50}\n    ]\n\n    results = []\n    for case in test_cases:\n        p = case # Use shorter alias for params\n        \n        # 1. Generate seeds and data\n        rng = np.random.default_rng(p['seed'])\n        seed_data_old = rng.integers(1e9)\n        seed_data_new = rng.integers(1e9)\n        seed_model = rng.integers(1e9)\n\n        X_old, y_old = generate_data(p['n_old'], p['mu0_old'], p['mu1_old'], p['sigma_old'], seed_data_old)\n        X_new, y_new = generate_data(p['n_new'], p['mu0_new'], p['mu1_new'], p['sigma_new'], seed_data_new)\n        y_old_one_hot = one_hot(y_old, 2)\n        y_new_one_hot = one_hot(y_new, 2)\n\n        # 2. Train teacher model\n        teacher_model = NeuralNetwork(d=2, H=p['H'], C=2, seed=seed_model)\n        teacher_model.train_teacher(X_old, y_old_one_hot, p['eta'], p['teacher_iterations'])\n\n        # 3. Identify probe points and get teacher margins\n        teacher_margins = teacher_model.get_margin(X_old)\n        probe_indices = np.argsort(np.abs(teacher_margins))[:p['K']]\n        X_probe = X_old[probe_indices]\n        old_margins_at_probes = teacher_model.get_margin(X_probe)\n        \n        # 4. Train and evaluate student with output-space distillation\n        student_out = NeuralNetwork(d=2, H=p['H'], C=2, seed=seed_model) # Re-use seed for identical init\n        student_out.train_student_output_distill(X_new, y_new_one_hot, X_old, teacher_model, p['eta'], p['student_iterations'], p['lambda_out'], p['T'])\n        student_out_margins = student_out.get_margin(X_probe)\n        delta_out = np.mean(np.abs(student_out_margins - old_margins_at_probes))\n\n        # 5. Train and evaluate student with feature-space distillation\n        student_feat = NeuralNetwork(d=2, H=p['H'], C=2, seed=seed_model) # Re-use seed for identical init\n        student_feat.train_student_feature_distill(X_new, y_new_one_hot, X_old, teacher_model, p['eta'], p['student_iterations'], p['lambda_feat'])\n        student_feat_margins = student_feat.get_margin(X_probe)\n        delta_feat = np.mean(np.abs(student_feat_margins - old_margins_at_probes))\n\n        # 6. Compare and store result\n        results.append(delta_out  delta_feat)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3109241"}]}