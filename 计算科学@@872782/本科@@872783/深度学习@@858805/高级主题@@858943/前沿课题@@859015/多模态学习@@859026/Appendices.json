{"hands_on_practices": [{"introduction": "多模态学习的核心任务之一是将来自不同来源的信息融合成一个统一、连贯的表示。本练习将深入探讨这一过程的概率基础。我们将通过一个思想实验，学习如何将两个高斯分布所代表的“信念”进行数学融合，从而得到一个更精确、更可靠的估计。通过亲手推导和计算，你将从第一性原理理解在融合证据时不确定性是如何降低的，这是贝叶斯推断和多模态融合中的一个基石概念 [@problem_id:3156180]。", "problem": "考虑一个多模态学习场景，其中潜表征 $x \\in \\mathbb{R}^{d}$ 描述了一个从两个条件独立的模态（视觉模态 $v$ 和文本模态 $t$）推断出的共享概念。每个模态都提供了关于 $x$ 的高斯置信度：视觉模态产生一个密度 $p_{v}(x)$，建模为均值为 $\\mu_{v} \\in \\mathbb{R}^{d}$、协方差矩阵为 $\\Sigma_{v} \\in \\mathbb{R}^{d \\times d}$ 的多元正态分布；文本模态产生一个密度 $p_{t}(x)$，建模为均值为 $\\mu_{t} \\in \\mathbb{R}^{d}$、协方差矩阵为 $\\Sigma_{t} \\in \\mathbb{R}^{d \\times d}$ 的多元正态分布。假设 $x$ 上的先验是无信息的（均匀分布），并且在给定 $x$ 的条件下，$v$ 和 $t$ 是条件独立的。\n\n仅使用基础的概率定义和代数知识，推导通过将两个高斯置信度相乘得到的融合后验密度 $p(x \\mid v, t)$ 的闭式表达式。您的推导必须从多元正态分布的标准概率密度函数开始，并通过显式的代数操作来确定融合后的均值和协方差。\n\n然后，在标量情况 $d=1$ 下，通过计算当特定模态的参数为 $\\mu_{v} = 0.8$, $\\sigma_{v}^{2} = 0.09$, $\\mu_{t} = 0.5$ 和 $\\sigma_{t}^{2} = 0.25$ 时融合后的均值，来对推导进行数值验证。其中 $\\sigma_{v}^{2}$ 和 $\\sigma_{t}^{2}$ 表示与 $\\Sigma_{v}$ 和 $\\Sigma_{t}$ 对应的标量方差。将您的最终数值答案（标量情况下的融合均值）四舍五入到四位有效数字。以单个不带单位的实数形式提供您的最终答案。", "solution": "题目要求我们在无信息先验和模态条件独立的条件下，融合关于同一潜变量 $x$ 的两个高斯置信度。我们使用的基本依据包括：\n- 贝叶斯定理：对于条件独立的观测 $v$ 和 $t$，在 $x$ 上具有均匀先验的情况下，融合后的后验概率正比于关于 $x$ 的特定模态似然函数的乘积。\n- 多元正态分布的概率密度函数。\n\n令 $p_{v}(x) = \\mathcal{N}(\\mu_{v}, \\Sigma_{v})$ 和 $p_{t}(x) = \\mathcal{N}(\\mu_{t}, \\Sigma_{t})$。在均匀先验和条件独立的条件下，融合后的后验满足\n$$\np(x \\mid v, t) \\propto p_{v}(x) \\, p_{t}(x).\n$$\n我们将每个高斯密度以其标准形式表示。对于 $x \\in \\mathbb{R}^{d}$，\n$$\np_{v}(x) = \\frac{1}{(2\\pi)^{d/2} |\\Sigma_{v}|^{1/2}} \\exp\\!\\left( -\\frac{1}{2} (x - \\mu_{v})^{\\top} \\Sigma_{v}^{-1} (x - \\mu_{v}) \\right),\n$$\n$$\np_{t}(x) = \\frac{1}{(2\\pi)^{d/2} |\\Sigma_{t}|^{1/2}} \\exp\\!\\left( -\\frac{1}{2} (x - \\mu_{t})^{\\top} \\Sigma_{t}^{-1} (x - \\mu_{t}) \\right).\n$$\n它们的乘积是\n$$\np_{v}(x) \\, p_{t}(x) = C \\, \\exp\\!\\left( -\\frac{1}{2} (x - \\mu_{v})^{\\top} \\Sigma_{v}^{-1} (x - \\mu_{v}) - \\frac{1}{2} (x - \\mu_{t})^{\\top} \\Sigma_{t}^{-1} (x - \\mu_{t}) \\right),\n$$\n其中\n$$\nC = \\frac{1}{(2\\pi)^{d} |\\Sigma_{v}|^{1/2} |\\Sigma_{t}|^{1/2}}\n$$\n是一个关于 $x$ 的常数。我们关注指数部分，并展开两个二次型：\n\n$$\n\\begin{aligned}\n-\\frac{1}{2} \\Big[ (x - \\mu_{v})^{\\top} \\Sigma_{v}^{-1} (x - \\mu_{v}) + (x - \\mu_{t})^{\\top} \\Sigma_{t}^{-1} (x - \\mu_{t}) \\Big] \\\\\n= -\\frac{1}{2} \\Big[ x^{\\top} \\Sigma_{v}^{-1} x - 2 \\mu_{v}^{\\top} \\Sigma_{v}^{-1} x + \\mu_{v}^{\\top} \\Sigma_{v}^{-1} \\mu_{v} + x^{\\top} \\Sigma_{t}^{-1} x - 2 \\mu_{t}^{\\top} \\Sigma_{t}^{-1} x + \\mu_{t}^{\\top} \\Sigma_{t}^{-1} \\mu_{t} \\Big] \\\\\n= -\\frac{1}{2} \\Big[ x^{\\top} (\\Sigma_{v}^{-1} + \\Sigma_{t}^{-1}) x - 2 (\\Sigma_{v}^{-1} \\mu_{v} + \\Sigma_{t}^{-1} \\mu_{t})^{\\top} x + \\mu_{v}^{\\top} \\Sigma_{v}^{-1} \\mu_{v} + \\mu_{t}^{\\top} \\Sigma_{t}^{-1} \\mu_{t} \\Big].\n\\end{aligned}\n$$\n\n定义融合后的精度矩阵\n$$\n\\Lambda = \\Sigma_{v}^{-1} + \\Sigma_{t}^{-1}\n$$\n和融合后的自然参数\n$$\n\\eta = \\Sigma_{v}^{-1} \\mu_{v} + \\Sigma_{t}^{-1} \\mu_{t}.\n$$\n于是指数部分变为\n$$\n-\\frac{1}{2} \\Big[ x^{\\top} \\Lambda x - 2 \\eta^{\\top} x + \\text{constant} \\Big].\n$$\n我们通过配方法将此二次型表示为中心化的高斯形式。令融合后的协方差和均值为\n$$\n\\Sigma = \\Lambda^{-1}, \\quad \\mu = \\Sigma \\eta.\n$$\n注意到\n\n$$\n\\begin{aligned}\nx^{\\top} \\Lambda x - 2 \\eta^{\\top} x\n= (x - \\mu)^{\\top} \\Lambda (x - \\mu) - \\mu^{\\top} \\Lambda \\mu \\\\\n= (x - \\mu)^{\\top} \\Sigma^{-1} (x - \\mu) - \\eta^{\\top} \\Sigma \\eta,\n\\end{aligned}\n$$\n\n其中我们使用了 $\\mu = \\Sigma \\eta$ 和 $\\Lambda = \\Sigma^{-1}$。因此，\n\n$$\n-\\frac{1}{2} \\Big[ x^{\\top} \\Lambda x - 2 \\eta^{\\top} x + \\text{constant} \\Big]\n= -\\frac{1}{2} (x - \\mu)^{\\top} \\Sigma^{-1} (x - \\mu) + \\text{new constant}.\n$$\n\n因此，$p_{v}(x) \\, p_{t}(x)$ 正比于一个协方差为 $\\Sigma = (\\Sigma_{v}^{-1} + \\Sigma_{t}^{-1})^{-1}$、均值为 $\\mu = \\Sigma (\\Sigma_{v}^{-1} \\mu_{v} + \\Sigma_{t}^{-1} \\mu_{t})$ 的多元正态密度。归一化后，融合的后验 $p(x \\mid v, t)$ 就是一个具有这些参数的高斯分布。\n\n在标量情况 $d=1$ 下进行数值验证。用 $\\sigma_{v}^{2}$ 和 $\\sigma_{t}^{2}$ 表示标量方差。融合后参数的标量等价形式是：\n$$\n\\sigma^{2} = \\left( \\sigma_{v}^{-2} + \\sigma_{t}^{-2} \\right)^{-1}, \\quad\n\\mu = \\sigma^{2} \\left( \\sigma_{v}^{-2} \\mu_{v} + \\sigma_{t}^{-2} \\mu_{t} \\right).\n$$\n给定 $\\mu_{v} = 0.8$, $\\sigma_{v}^{2} = 0.09$, $\\mu_{t} = 0.5$ 和 $\\sigma_{t}^{2} = 0.25$：\n首先计算各模态的精度（方差的倒数）：\n$$\n\\sigma_{v}^{-2} = \\frac{1}{0.09} = \\frac{100}{9}, \\quad\n\\sigma_{t}^{-2} = \\frac{1}{0.25} = 4.\n$$\n融合后的精度是各精度的和：\n$$\n\\sigma^{-2} = \\sigma_{v}^{-2} + \\sigma_{t}^{-2} = \\frac{100}{9} + 4 = \\frac{100}{9} + \\frac{36}{9} = \\frac{136}{9}.\n$$\n融合后的均值是各均值的精度加权平均：\n$$\n\\mu = \\frac{\\sigma_{v}^{-2} \\mu_{v} + \\sigma_{t}^{-2} \\mu_{t}}{\\sigma_{v}^{-2} + \\sigma_{t}^{-2}} = \\frac{(\\frac{100}{9})(0.8) + (4)(0.5)}{\\frac{136}{9}} = \\frac{\\frac{80}{9} + 2}{\\frac{136}{9}} = \\frac{\\frac{98}{9}}{\\frac{136}{9}} = \\frac{98}{136} = \\frac{49}{68} \\approx 0.7205882353\\ldots\n$$\n四舍五入到四位有效数字，融合后的均值为 $0.7206$。作为额外检验（非最终答案要求），融合后的方差为\n$$\n\\sigma^{2} = \\left( \\frac{136}{9} \\right)^{-1} = \\frac{9}{136} \\approx 0.06617647,\n$$\n该值低于 $0.09$ 和 $0.25$，这与融合独立高斯信息源时精度会增加的结论是一致的。融合后的均值 $0.7206$ 位于 $0.5$ 和 $0.8$ 之间，且更接近 $0.8$，这反映了视觉模态（$\\sigma_{v}^{-2} \\approx 11.1$）相对于文本模态（$\\sigma_{t}^{-2} = 4$）具有更高的精度。", "answer": "$$\\boxed{0.7206}$$", "id": "3156180"}, {"introduction": "在了解了如何融合信息之后，我们自然会问：仅仅将各个模态的独立预测结果结合起来就足够了吗？本练习将引导你探索一种特殊情况，即目标概念本质上是“组合式”的，它源于不同模态之间的特有*交互*。你将通过编程实践，构建并比较几个单模态模型和一个跨模态模型，并亲眼见证只有后者才能解决需要理解“红色立方体”这类组合关系的问题。这个动手练习为现代多模态架构中交叉注意力（cross-attention）等交互机制的必要性提供了清晰而有力的证明 [@problem_id:3156162]。", "problem": "给定一个合成的多模态学习场景，其中两种模态，即符号化的“形状”模态和符号化的“颜色”模态，均被编码为独热向量 (one-hot vectors)。目标标签仅依赖于跨模态关系（例如，组合描述“红色立方体”），而不依赖于任何单一模态。您的任务是使用基于梯度的优化方法，实现并训练三个模型：一个仅使用形状的单模态逻辑回归分类器，一个仅使用颜色的单模态逻辑回归分类器，以及一个实现简单形式交叉注意力 (cross-attention) 的跨模态双线性分类器。您必须证明单模态分类器无法恢复组合标签，而交叉注意力模型能够成功。\n\n使用的基础原理：\n- 使用 sigmoid (logistic) 函数和二元交叉熵 (BCE) 损失的逻辑回归分类器。\n- 独热特征编码和基础线性代数恒等式。\n- 在类别组合上的均匀数据分布，以及定义在模态对上的确定性标签函数。\n\n定义：\n- 设形状模态由独热向量 $x_{s} \\in \\{0,1\\}^{n_{s}}$ 表示，颜色模态由独热向量 $x_{c} \\in \\{0,1\\}^{n_{c}}$ 表示，其中 $n_{s}$ 和 $n_{c}$ 分别是不同形状和颜色的数量。\n- 标签 $y \\in \\{0,1\\}$ 由一个确定性映射 $g: \\{1,\\dots,n_{s}\\} \\times \\{1,\\dots,n_{c}\\} \\to \\{0,1\\}$ 定义，该映射作用于对应形状和颜色类别的索引对 $(i,j)$。数据分布在所有 $(i,j)$ 对上是均匀的。\n- Sigmoid 函数为 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$。\n- 对于预测值 $\\hat{y} \\in (0,1)$ 和标签 $y \\in \\{0,1\\}$，二元交叉熵 (BCE) 损失为 $L = -\\left(y \\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})\\right)$。\n\n模型：\n- 仅形状的逻辑回归：$\\hat{y} = \\sigma\\left(w_{s}^{\\top} x_{s} + b_{s}\\right)$，其参数为 $w_{s} \\in \\mathbb{R}^{n_{s}}$ 和 $b_{s} \\in \\mathbb{R}$。\n- 仅颜色的逻辑回归：$\\hat{y} = \\sigma\\left(w_{c}^{\\top} x_{c} + b_{c}\\right)$，其参数为 $w_{c} \\in \\mathbb{R}^{n_{c}}$ 和 $b_{c} \\in \\mathbb{R}$。\n- 带交叉注意力门的跨模态双线性分类器：$\\hat{y} = \\sigma\\left(x_{s}^{\\top} W x_{c} + b\\right)$，其参数为 $W \\in \\mathbb{R}^{n_{s} \\times n_{c}}$ 和 $b \\in \\mathbb{R}$。此处，$x_{s}^{\\top} W x_{c}$ 为形状-颜色对选择标量兼容性权重，作为交叉注意力分数，通过 sigmoid 函数门控后产生一个概率。\n\n训练目标：\n- 使用梯度下降更新每个模型的参数，以最小化数据集上的平均 BCE 损失。\n\n您的程序必须实现以下数据集测试套件并报告准确率：\n- 测试用例 $1$：$n_{s} = 2$， $n_{c} = 2$。定义索引为形状 $1$ 等于“立方体”，形状 $2$ 等于“球体”，颜色 $1$ 等于“红色”，颜色 $2$ 等于“蓝色”。设 $g(1,1) = 1$ 和 $g(2,2) = 1$，同时 $g(1,2) = 0$ 和 $g(2,1) = 0$。这编码了“红色立方体”和“蓝色球体”为正例。\n- 测试用例 $2$：$n_{s} = 2$， $n_{c} = 3$。设若 $(i \\bmod 2) = (j \\bmod 2)$，则 $g(i,j) = 1$，否则 $g(i,j) = 0$。索引为 $i \\in \\{1,2\\}$ 和 $j \\in \\{1,2,3\\}$。\n- 测试用例 $3$：$n_{s} = 3$， $n_{c} = 3$。设若 $i = j$，则 $g(i,j) = 1$，否则 $g(i,j) = 0$。这仅在形状-颜色匹配的对角线上编码正例。\n\n科学真实性和推导要求：\n- 您必须论证为什么当映射 $g(i,j)$ 不能简化为仅与 $i$ 相关或仅与 $j$ 相关的函数时，单模态分类器通常无法表示该映射。\n- 您必须证明跨模态双线性分类器通过适当的参数设置可以表示任何在配对上的确定性映射，因为每个 $(i,j)$ 对都有其自己的参数 $W_{ij}$ 对 logit 做出线性贡献。\n- 训练必须使用基于 BCE 损失的梯度下降来生成模型参数，评估指标必须是在 $\\hat{y}$ 上使用 $0.5$ 作为阈值计算的准确率。\n\n数值规格：\n- 不涉及物理单位。\n- 不涉及角度。\n- 准确率必须表示为小数（例如，$0.750$），并四舍五入到小数点后 $3$ 位。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序如下：\n$[$shape\\_only\\_accuracy\\_test1, color\\_only\\_accuracy\\_test1, cross\\_attention\\_accuracy\\_test1, shape\\_only\\_accuracy\\_test2, color\\_only\\_accuracy\\_test2, cross\\_attention\\_accuracy\\_test2, shape\\_only\\_accuracy\\_test3, color\\_only\\_accuracy\\_test3, cross\\_attention\\_accuracy\\_test3$]$。\n每个准确率必须是四舍五入到小数点后 $3$ 位的小数。", "solution": "该问题要求在一个合成的多模态学习情境中，分析和展示不同模型架构的表征能力。具体来说，我们必须展示为什么单模态逻辑回归分类器在学习两个符号模态之间的组合关系时会失败，而跨模态双线性分类器会成功。解决方案既包括理论论证，也包括使用基于梯度的优化的数值实现。\n\n### 模型能力的理论论证\n\n问题的核心在于模型是否有能力表示目标函数 $g(i,j)$，该函数根据形状类别 $i \\in \\{1, \\dots, n_s\\}$ 和颜色类别 $j \\in \\{1, \\dots, n_c\\}$ 的组合来定义标签 $y \\in \\{0,1\\}$。输入是用于形状的独热向量 $x_s \\in \\{0,1\\}^{n_s}$ 和用于颜色的独热向量 $x_c \\in \\{0,1\\}^{n_c}$。\n\n**1. 单模态逻辑回归模型**\n\n考虑仅使用形状的逻辑回归模型：$\\hat{y} = \\sigma(w_s^\\top x_s + b_s)$。\n当输入对应第 $i$ 个形状时，独热向量 $x_s$ 在第 $i$ 个位置为 $1$，其他位置为 $0$。设该向量为 $e_i$。此输入的 logit (sigmoid 函数 $\\sigma$ 的输入) 为：\n$$z_i = w_s^\\top e_i + b_s = w_{s,i} + b_s$$\n其中 $w_{s,i}$ 是权重向量 $w_s$ 的第 $i$ 个分量。预测值为 $\\hat{y}_i = \\sigma(w_{s,i} + b_s)$。\n\n关键在于，这个预测*只*依赖于形状索引 $i$。当同一个形状 $i$ 与不同的颜色 $j_1, j_2, \\dots, j_{n_c}$ 配对时，该模型从根本上无法产生不同的预测。然而，对于固定的 $i$，目标标签 $y=g(i,j)$ 会随着 $j$ 的变化而变化。\n\n在使用二元交叉熵 (BCE) 损失进行梯度下降优化时，模型将调整其参数 $w_s$ 和 $b_s$ 以最小化在均匀分布数据集上的总损失。对于给定的形状 $i$，最小化期望 BCE 损失的最优预测 $\\hat{y}_i$ 是所有颜色上真实标签的平均值：\n$$\\hat{y}_i \\to \\mathbb{E}_{j}[g(i,j)] = \\frac{1}{n_c} \\sum_{j=1}^{n_c} g(i,j)$$\n模型学习的是边际概率 $P(y=1 | \\text{shape}=i)$。如果对于 $y=1$ 的情况，这个边际概率不能稳定地高于 $0.5$，而对于 $y=0$ 的情况，不能稳定地低于 $0.5$，那么模型就会失败。例如，在测试用例1中，对于形状1（“立方体”），标签为 $g(1,1)=1$ 和 $g(1,2)=0$。边际概率是 $(1+0)/2 = 0.5$。模型的最优预测是 $\\hat{y}=0.5$，这导致准确率为 $0.5$（随机猜测），因为它位于决策边界上。\n\n同样的论证也适用于仅使用颜色的模型 $\\hat{y} = \\sigma(w_c^\\top x_c + b_c)$。它只能学习边际概率 $P(y=1 | \\text{color}=j)$，如果真实标签函数 $g(i,j)$ 不能简化为仅与 $j$ 相关的函数，那么它也会失败。\n\n**2. 跨模态双线性分类器**\n\n现在考虑跨模态双线性分类器：$\\hat{y} = \\sigma(x_s^\\top W x_c + b)$。\n当输入对应第 $i$ 个形状 ($x_s = e_i$) 和第 $j$ 个颜色 ($x_c = e_j$) 的配对时，logit 为：\n$$z_{ij} = e_i^\\top W e_j + b$$\n项 $e_i^\\top W e_j$ 是线性代数中的一个基本操作，它选取矩阵 $W$ 中第 $i$ 行和第 $j$ 列的标量元素。因此，logit 简化为：\n$$z_{ij} = W_{ij} + b$$\n对 $(i,j)$ 配对的预测为 $\\hat{y}_{ij} = \\sigma(W_{ij} + b)$。\n\n这种架构为每个唯一的形状-颜色对 $(i,j)$ 提供了一个独立的、可学习的参数 $W_{ij}$。这使得模型能够表示任意映射 $g: \\{1,\\dots,n_s\\} \\times \\{1,\\dots,n_c\\} \\to \\{0,1\\}$。为了实现完美分类（准确率为 $1.0$），模型的参数必须设置得当，使得当 $g(i,j)=1$ 时 logit $z_{ij}$ 为正，当 $g(i,j)=0$ 时 logit $z_{ij}$ 为负。这总是可以实现的。例如，可以将偏置 $b$ 设置为 $0$，并将权重矩阵的元素设置为：\n$$W_{ij} = \\begin{cases} C  \\text{if } g(i,j) = 1 \\\\ -C  \\text{if } g(i,j) = 0 \\end{cases}$$\n其中 $C$ 是任意正常数。梯度下降将找到满足这些符号条件的 $W$ 和 $b$ 的值，从而将 BCE 损失推向 $0$，并在训练数据上达到 $100\\%$ 的准确率。\n\n### 通过梯度下降的算法实现\n\n为了训练这些模型，我们最小化数据集中所有 $N = n_s \\times n_c$ 个数据点的平均 BCE 损失。对于单个预测 $\\hat{y}$ 和标签 $y$，损失为 $L = -(y \\log(\\hat{y}) + (1-y)\\log(1-\\hat{y}))$。关键的梯度分量是 $\\frac{\\partial L}{\\partial z} = \\hat{y} - y$，其中 $z$ 是 logit。对于学习率 $\\alpha$，参数更新遵循以下规则：$\\theta \\leftarrow \\theta - \\alpha \\frac{1}{N} \\sum_{k=1}^N \\frac{\\partial L_k}{\\partial \\theta}$。\n\n每个模型的具体梯度为：\n- **仅形状的模型：**\n  $$ \\frac{\\partial L}{\\partial w_s} = (\\hat{y}-y)x_s \\quad ; \\quad \\frac{\\partial L}{\\partial b_s} = \\hat{y}-y $$\n- **仅颜色的模型：**\n  $$ \\frac{\\partial L}{\\partial w_c} = (\\hat{y}-y)x_c \\quad ; \\quad \\frac{\\partial L}{\\partial b_c} = \\hat{y}-y $$\n- **跨模态双线性模型：**\n  $$ \\frac{\\partial L}{\\partial W} = (\\hat{y}-y) x_s x_c^\\top \\quad ; \\quad \\frac{\\partial L}{\\partial b} = \\hat{y}-y $$\n其中 $x_s x_c^\\top$ 是两个独热向量的外积，结果是一个零矩阵，仅在对应于当前活动的形状-颜色对的位置上有一个 $1$。\n\n通过使用这些梯度实现批量梯度下降，我们可以训练每个模型，并数值验证关于其性能的理论预测。评估是通过计算准确率来执行的，其中如果预测值 $\\hat{y} > 0.5$，则分类为 $1$，否则分类为 $0$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and trains three models on three synthetic multimodal learning tasks,\n    reporting the final classification accuracy for each.\n    \"\"\"\n\n    def sigmoid(z):\n        \"\"\"The sigmoid function.\"\"\"\n        # Using np.exp is numerically stable for large inputs.\n        return 1.0 / (1.0 + np.exp(-z))\n\n    def generate_dataset(n_s, n_c, g_func):\n        \"\"\"Generates the full dataset for a given configuration.\"\"\"\n        dataset = []\n        for i in range(1, n_s + 1):\n            for j in range(1, n_c + 1):\n                x_s = np.zeros(n_s)\n                x_s[i-1] = 1.0\n                x_c = np.zeros(n_c)\n                x_c[j-1] = 1.0\n                y = g_func(i, j)\n                dataset.append((x_s, x_c, y))\n        return dataset\n\n    def train_and_evaluate(model_type, dataset, n_s, n_c, learning_rate=1.0, epochs=1000):\n        \"\"\"Trains a specified model and evaluates its accuracy.\"\"\"\n        n_samples = len(dataset)\n        \n        # Epsilon for numerical stability in log\n        epsilon = 1e-9\n\n        # Initialize parameters\n        if model_type == 'shape_only':\n            w = np.zeros(n_s)\n            b = 0.0\n        elif model_type == 'color_only':\n            w = np.zeros(n_c)\n            b = 0.0\n        elif model_type == 'cross_attention':\n            W = np.zeros((n_s, n_c))\n            b = 0.0\n        else:\n            raise ValueError(\"Unknown model type\")\n\n        # Batch Gradient Descent\n        for epoch in range(epochs):\n            grad_w_sum = 0\n            grad_b_sum = 0\n            \n            # Aggregate gradients over the whole dataset\n            for x_s, x_c, y in dataset:\n                if model_type == 'shape_only':\n                    z = w.T @ x_s + b\n                    x = x_s\n                elif model_type == 'color_only':\n                    z = w.T @ x_c + b\n                    x = x_c\n                else: # cross_attention\n                    z = x_s.T @ W @ x_c + b\n\n                y_hat = sigmoid(z)\n                \n                # Common gradient part for BCE loss\n                d_loss_d_z = y_hat - y\n\n                if model_type in ['shape_only', 'color_only']:\n                    grad_w_sum += d_loss_d_z * x\n                    grad_b_sum += d_loss_d_z\n                else: # cross_attention\n                    grad_w_sum += d_loss_d_z * np.outer(x_s, x_c)\n                    grad_b_sum += d_loss_d_z\n            \n            # Update parameters\n            if model_type in ['shape_only', 'color_only']:\n                w -= learning_rate * (grad_w_sum / n_samples)\n                b -= learning_rate * (grad_b_sum / n_samples)\n            else: # cross_attention\n                W -= learning_rate * (grad_w_sum / n_samples)\n                b -= learning_rate * (grad_b_sum / n_samples)\n\n        # Evaluate accuracy\n        correct_predictions = 0\n        for x_s, x_c, y in dataset:\n            if model_type == 'shape_only':\n                z = w.T @ x_s + b\n            elif model_type == 'color_only':\n                z = w.T @ x_c + b\n            else: # cross_attention\n                z = x_s.T @ W @ x_c + b\n                \n            y_hat = sigmoid(z)\n            prediction = 1 if y_hat > 0.5 else 0\n            if prediction == y:\n                correct_predictions += 1\n        \n        accuracy = correct_predictions / n_samples\n        return accuracy\n\n    # Define test cases\n    test_cases = [\n        {\n            \"name\": \"Test Case 1\",\n            \"n_s\": 2, \"n_c\": 2,\n            \"g_func\": lambda i, j: 1.0 if (i, j) in [(1, 1), (2, 2)] else 0.0\n        },\n        {\n            \"name\": \"Test Case 2\",\n            \"n_s\": 2, \"n_c\": 3,\n            \"g_func\": lambda i, j: 1.0 if (i % 2) == (j % 2) else 0.0\n        },\n        {\n            \"name\": \"Test Case 3\",\n            \"n_s\": 3, \"n_c\": 3,\n            \"g_func\": lambda i, j: 1.0 if i == j else 0.0\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        dataset = generate_dataset(case[\"n_s\"], case[\"n_c\"], case[\"g_func\"])\n        \n        # Shape-only model\n        acc_shape = train_and_evaluate('shape_only', dataset, case[\"n_s\"], case[\"n_c\"])\n        all_results.append(f\"{acc_shape:.3f}\")\n\n        # Color-only model\n        acc_color = train_and_evaluate('color_only', dataset, case[\"n_s\"], case[\"n_c\"])\n        all_results.append(f\"{acc_color:.3f}\")\n\n        # Cross-attention model\n        acc_cross = train_and_evaluate('cross_attention', dataset, case[\"n_s\"], case[\"n_c\"])\n        all_results.append(f\"{acc_cross:.3f}\")\n\n    # Print results in the specified format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3156162"}, {"introduction": "在真实世界的应用中，尤其是在资源受限的设备上，模型的性能不仅仅取决于准确率，效率同样至关重要。本练习将带你应对在准确性与计算成本之间进行权衡的实际挑战。你将实现一个动态门控机制，该机制会根据一个低成本模态（如视觉）的预测置信度，来动态决定是否启用一个高成本的模态（如文本）。通过构建准确率-能耗的帕累托前沿（Pareto frontier），你将掌握一项关键的系统设计技能：如何分析和驾驭不同性能目标之间的权衡，从而构建出实用且高效的多模态系统 [@problem_id:3156166]。", "problem": "给定一个多模态分类场景，其中包含一个视觉特征向量 $x_v$ 和一个文本特征向量 $x_t$。分类器可以仅使用视觉信息进行预测，或者在付出额外能量成本的情况下，融合两种模态。令 $p(y \\mid x_v)$ 表示仅使用视觉的预测分布，而 $p(y \\mid x_v, x_t)$ 表示融合后的预测分布。对于每个输入，一个门控策略会根据 $p(y \\mid x_v)$ 的置信度来决定是否跳过对 $x_t$ 的处理。目标是通过扫描一系列置信度阈值并形成一条准确率-能耗帕累托曲线，来研究分类准确率和能耗之间的权衡关系。\n\n基本原理：\n- 决策理论中的风险最小化原则：对于一个分类决策 $\\hat{y}$ 和真实标签 $y$，$0$-$1$ 损失为 $L(\\hat{y}, y) = \\mathbb{I}[\\hat{y} \\neq y]$，而概率分类器的交叉熵损失定义为 $-\\log p(y \\mid \\cdot)$。\n- 在能量感知系统中，每次使用高成本模态的线性能量惩罚被建模为一个加法项 $\\lambda \\cdot u$，其中 $\\lambda \\ge 0$ 是一个标量成本参数，而 $u \\in \\{0,1\\}$ 指示是否使用了高成本模态（此处为 $x_t$）。\n\n门控的设计条件：\n- 一种确定性阈值策略是：当 $p(y \\mid x_v)$ 的置信度（即最大类别概率）低于阈值 $\\tau \\in [0,1]$ 时，使用 $x_t$；否则，跳过 $x_t$。在此策略下，对于满足 $\\max_c p(y=c \\mid x_v) < \\tau$ 的输入，将调用融合模型。\n- 准确率是在该策略下被正确分类的样本比例（以小数形式表示），其中如果跳过 $x_t$，预测类别为 $\\arg\\max_c p(y=c \\mid x_v)$；如果使用 $x_t$，预测类别为 $\\arg\\max_c p(y=c \\mid x_v, x_t)$。\n- 对于一个阈值 $\\tau$ 和成本参数 $\\lambda$，能耗定义为 $\\lambda$ 乘以使用 $x_t$ 的样本比例。\n\n你必须实现一个程序，该程序：\n1. 为每个测试用例扫描一组阈值 $\\tau$。\n2. 对于每个 $\\tau$，计算准确率和能耗对 $[\\text{准确率}, \\text{能耗}]$。\n3. 通过移除被支配点来提取帕累托前沿，其中如果 $\\text{acc}_1 \\ge \\text{acc}_2$ 且 $\\text{eng}_1 \\le \\text{eng}_2$ 并至少有一个严格不等式成立，则点 $[\\text{acc}_1, \\text{eng}_1]$ 支配 $[\\text{acc}_2, \\text{eng}_2]$。\n4. 为每个测试用例输出帕累托前沿，形式为由双元素列表组成的列表。\n\n测试套件：\n- 对于所有测试用例，类别是从0开始索引的整数，并且所有概率都是总和为1的有效分布。\n\n测试用例 $1$（理想情况）：\n- 类别数 $K = 3$，样本数 $N = 8$。\n- 每个样本仅使用视觉的分布 $p(y \\mid x_v)$：\n  $[0.85, 0.10, 0.05]$,\n  $[0.40, 0.45, 0.15]$,\n  $[0.60, 0.35, 0.05]$,\n  $[0.55, 0.30, 0.15]$,\n  $[0.45, 0.30, 0.25]$,\n  $[0.33, 0.33, 0.34]$,\n  $[0.51, 0.49, 0.00]$,\n  $[0.35, 0.25, 0.40]$.\n- 每个样本的融合分布 $p(y \\mid x_v, x_t)$：\n  $[0.80, 0.15, 0.05]$,\n  $[0.20, 0.75, 0.05]$,\n  $[0.20, 0.10, 0.70]$,\n  $[0.65, 0.20, 0.15]$,\n  $[0.10, 0.80, 0.10]$,\n  $[0.10, 0.15, 0.75]$,\n  $[0.10, 0.85, 0.05]$,\n  $[0.20, 0.10, 0.70]$.\n- 真实标签 $y$：\n  $0, 1, 2, 0, 1, 2, 1, 2$.\n- 能耗成本参数 $\\lambda = 0.2$。\n- 阈值 $\\tau$：$[0.0, 0.3, 0.6, 0.8, 0.95, 1.0]$。\n\n测试用例 $2$（视觉高置信度边界，显著能耗）：\n- 类别数 $K = 3$，样本数 $N = 6$。\n- 每个样本仅使用视觉的分布 $p(y \\mid x_v)$：\n  $[0.97, 0.02, 0.01]$,\n  $[0.96, 0.03, 0.01]$,\n  $[0.10, 0.05, 0.85]$,\n  $[0.94, 0.03, 0.03]$,\n  $[0.95, 0.04, 0.01]$,\n  $[0.90, 0.05, 0.05]$.\n- 每个样本的融合分布 $p(y \\mid x_v, x_t)$：\n  $[0.90, 0.05, 0.05]$,\n  $[0.10, 0.85, 0.05]$,\n  $[0.05, 0.10, 0.85]$,\n  $[0.20, 0.75, 0.05]$,\n  $[0.95, 0.03, 0.02]$,\n  $[0.05, 0.10, 0.85]$.\n- 真实标签 $y$：\n  $0, 1, 2, 1, 0, 2$.\n- 能耗成本参数 $\\lambda = 1.0$。\n- 阈值 $\\tau$：$[0.0, 0.9, 0.95, 0.99, 1.0]$。\n\n测试用例 $3$（视觉过分自信但易于出错，零能耗）：\n- 类别数 $K = 3$，样本数 $N = 6$。\n- 每个样本仅使用视觉的分布 $p(y \\mid x_v)$：\n  $[0.80, 0.15, 0.05]$,\n  $[0.85, 0.10, 0.05]$,\n  $[0.60, 0.30, 0.10]$,\n  $[0.70, 0.10, 0.20]$,\n  $[0.55, 0.40, 0.05]$,\n  $[0.40, 0.30, 0.30]$.\n- 每个样本的融合分布 $p(y \\mid x_v, x_t)$：\n  $[0.10, 0.80, 0.10]$,\n  $[0.10, 0.10, 0.80]$,\n  $[0.70, 0.20, 0.10]$,\n  $[0.10, 0.15, 0.75]$,\n  $[0.20, 0.75, 0.05]$,\n  $[0.65, 0.25, 0.10]$.\n- 真实标签 $y$：\n  $1, 2, 0, 2, 1, 0$.\n- 能耗成本参数 $\\lambda = 0.0$。\n- 阈值 $\\tau$：$[0.0, 0.5, 0.8, 1.0]$。\n\n需要计算的量：\n- 对于每个测试用例和每个阈值 $\\tau$，将准确率计算为小数，能耗计算为 $\\lambda$ 乘以需要 $x_t$ 的样本比例。\n- 为每个测试用例提取 $[\\text{准确率}, \\text{能耗}]$ 点的帕累托前沿。\n\n最终输出格式：\n- 你的程序应生成单行输出，包含一个顶层列表，每个测试用例对应其中一个条目。每个条目是该测试用例的帕累托前沿，编码为一个由双元素列表 $[\\text{准确率}, \\text{能耗}]$ 组成的列表。\n- 所有浮点数必须四舍五入到三位小数。\n- 输出不得包含任何空格，例如：$[[[0.875,0.100],[0.900,0.200]],[[0.833,0.167]],[[1.000,0.000]]]$。", "solution": "该问题定义明确且科学合理，设置在为实现资源效率而进行条件计算的常见机器学习范式中。任务是通过识别可实现性能点的帕累托前沿，来分析多模态系统中分类准确率和能耗之间的权衡。\n\n对于每个测试用例，方法论途径包括三个主要步骤：在一系列阈值上模拟门控策略，计算性能指标，以及提取帕累托最优点。\n\n**1. 门控策略与预测**\n\n该系统采用基于置信度阈值 $\\tau \\in [0, 1]$ 的确定性门控策略。对于 $N$ 个数据样本中的每一个，我们首先计算仅视觉模型的置信度，定义为最大类别概率：\n$$\nc_{v,i} = \\max_c p(y=c \\mid x_{v,i})\n$$\n其中 $x_{v,i}$ 是第 $i$ 个样本的视觉特征向量。\n\n仅当视觉模型的置信度不足时，才会处理带有特征向量 $x_{t,i}$ 的文本模态。使用融合模型的决策规则是：\n$$\nu_i(\\tau) =\n\\begin{cases}\n1  \\text{if } c_{v,i} < \\tau \\\\\n0  \\text{if } c_{v,i} \\ge \\tau\n\\end{cases}\n$$\n其中 $u_i(\\tau)=1$ 表示在阈值 $\\tau$ 下对样本 $i$ 使用融合模型。\n\n给定样本的最终预测 $\\hat{y}_i$ 取决于此决策：\n$$\n\\hat{y}_i(\\tau) =\n\\begin{cases}\n\\arg\\max_c p(y=c \\mid x_{v,i}, x_{t,i})  \\text{if } u_i(\\tau) = 1 \\\\\n\\arg\\max_c p(y=c \\mid x_{v,i})  \\text{if } u_i(\\tau) = 0\n\\end{cases}\n$$\n\n**2. 准确率与能耗指标**\n\n对于每个阈值 $\\tau$，我们使用两个指标评估系统性能：准确率（$\\mathcal{A}$）和能耗（$\\mathcal{E}$）。\n\n**准确率 ($\\mathcal{A}$)** 是被正确分类的样本比例。给定真实标签 $y_i$，阈值 $\\tau$ 下的准确率为：\n$$\n\\mathcal{A}(\\tau) = \\frac{1}{N} \\sum_{i=1}^{N} \\mathbb{I}[\\hat{y}_i(\\tau) = y_i]\n$$\n其中 $\\mathbb{I}[\\cdot]$ 是指示函数。\n\n**能耗 ($\\mathcal{E}$)** 定义为所有样本的平均能量成本。每次使用文本模态的成本参数为 $\\lambda$，则能耗为：\n$$\n\\mathcal{E}(\\tau) = \\lambda \\cdot \\frac{1}{N} \\sum_{i=1}^{N} u_i(\\tau)\n$$\n\n通过在一组预定义值上扫描 $\\tau$，我们获得一个 $(\\mathcal{A}(\\tau), \\mathcal{E}(\\tau))$ 对的集合。\n\n**3. 帕累托前沿提取**\n\n帕累托前沿代表了最优权衡的集合。如果一个点 $(\\mathcal{A}_1, \\mathcal{E}_1)$ 在所有目标上（更高准确率，更低能耗）都提供更好或相等的性能，并且在至少一个目标上严格更优，则称其帕累托支配另一个点 $(\\mathcal{A}_2, \\mathcal{E}_2)$。形式上，如果满足以下条件，则 $(\\mathcal{A}_1, \\mathcal{E}_1)$ 支配 $(\\mathcal{A}_2, \\mathcal{E}_2)$：\n$$\n(\\mathcal{A}_1 \\ge \\mathcal{A}_2 \\land \\mathcal{E}_1 \\le \\mathcal{E}_2) \\land (\\mathcal{A}_1 > \\mathcal{A}_2 \\lor \\mathcal{E}_1 < \\mathcal{E}_2)\n$$\n帕累托前沿是集合中所有不被任何其他点支配的点的集合。\n\n寻找前沿的算法如下：\n1.  通过扫描所有给定的阈值 $\\tau$ 来生成唯一的 $(\\mathcal{A}, \\mathcal{E})$ 点集。\n2.  对于集合中的每个点 $p_1$，将其与所有其他的点 $p_2$ 进行比较。\n3.  如果发现任何点 $p_2$ 支配 $p_1$，则丢弃 $p_1$。\n4.  所有非支配点的集合构成了帕累托前沿。然后将得到的点按准确率排序，以获得一致的输出格式。\n\n所实现的程序封装了这一逻辑，通过计算 $(\\mathcal{A}, \\mathcal{E})$ 点并对其进行筛选来处理每个测试用例，从而生成最终的帕累托前沿。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the multimodal gating problem for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"K\": 3, \"N\": 8,\n            \"p_v\": [\n                [0.85, 0.10, 0.05], [0.40, 0.45, 0.15], [0.60, 0.35, 0.05],\n                [0.55, 0.30, 0.15], [0.45, 0.30, 0.25], [0.33, 0.33, 0.34],\n                [0.51, 0.49, 0.00], [0.35, 0.25, 0.40]\n            ],\n            \"p_f\": [\n                [0.80, 0.15, 0.05], [0.20, 0.75, 0.05], [0.20, 0.10, 0.70],\n                [0.65, 0.20, 0.15], [0.10, 0.80, 0.10], [0.10, 0.15, 0.75],\n                [0.10, 0.85, 0.05], [0.20, 0.10, 0.70]\n            ],\n            \"y\": [0, 1, 2, 0, 1, 2, 1, 2],\n            \"lambda\": 0.2,\n            \"tau\": [0.0, 0.3, 0.6, 0.8, 0.95, 1.0]\n        },\n        {\n            \"K\": 3, \"N\": 6,\n            \"p_v\": [\n                [0.97, 0.02, 0.01], [0.96, 0.03, 0.01], [0.10, 0.05, 0.85],\n                [0.94, 0.03, 0.03], [0.95, 0.04, 0.01], [0.90, 0.05, 0.05]\n            ],\n            \"p_f\": [\n                [0.90, 0.05, 0.05], [0.10, 0.85, 0.05], [0.05, 0.10, 0.85],\n                [0.20, 0.75, 0.05], [0.95, 0.03, 0.02], [0.05, 0.10, 0.85]\n            ],\n            \"y\": [0, 1, 2, 1, 0, 2],\n            \"lambda\": 1.0,\n            \"tau\": [0.0, 0.9, 0.95, 0.99, 1.0]\n        },\n        {\n            \"K\": 3, \"N\": 6,\n            \"p_v\": [\n                [0.80, 0.15, 0.05], [0.85, 0.10, 0.05], [0.60, 0.30, 0.10],\n                [0.70, 0.10, 0.20], [0.55, 0.40, 0.05], [0.40, 0.30, 0.30]\n            ],\n            \"p_f\": [\n                [0.10, 0.80, 0.10], [0.10, 0.10, 0.80], [0.70, 0.20, 0.10],\n                [0.10, 0.15, 0.75], [0.20, 0.75, 0.05], [0.65, 0.25, 0.10]\n            ],\n            \"y\": [1, 2, 0, 2, 1, 0],\n            \"lambda\": 0.0,\n            \"tau\": [0.0, 0.5, 0.8, 1.0]\n        }\n    ]\n\n    all_pareto_frontiers = []\n\n    for case in test_cases:\n        p_v = np.array(case[\"p_v\"])\n        p_f = np.array(case[\"p_f\"])\n        y = np.array(case[\"y\"])\n        lambda_cost = case[\"lambda\"]\n        thresholds = case[\"tau\"]\n        n_samples = case[\"N\"]\n\n        vision_confidences = np.max(p_v, axis=1)\n        vision_preds = np.argmax(p_v, axis=1)\n        fused_preds = np.argmax(p_f, axis=1)\n\n        points = set()\n        for tau in thresholds:\n            correct_count = 0\n            fused_count = 0\n            for i in range(n_samples):\n                if vision_confidences[i] < tau:\n                    fused_count += 1\n                    if fused_preds[i] == y[i]:\n                        correct_count += 1\n                else:\n                    if vision_preds[i] == y[i]:\n                        correct_count += 1\n            \n            accuracy = correct_count / n_samples\n            energy = lambda_cost * (fused_count / n_samples)\n            points.add((accuracy, energy))\n            \n        unique_points = [list(p) for p in points]\n\n        pareto_frontier = []\n        for p1 in unique_points:\n            is_dominated = False\n            for p2 in unique_points:\n                if p1 == p2:\n                    continue\n                \n                acc1, eng1 = p1\n                acc2, eng2 = p2\n                \n                # Check if p2 dominates p1\n                if acc2 >= acc1 and eng2 <= eng1:\n                    if acc2 > acc1 or eng2 < eng1:\n                        is_dominated = True\n                        break\n            if not is_dominated:\n                pareto_frontier.append(p1)\n        \n        # Sort for consistent output order\n        pareto_frontier.sort(key=lambda p: (p[0], p[1]))\n        all_pareto_frontiers.append(pareto_frontier)\n\n    # Format the final output string exactly as specified\n    frontier_strings = []\n    for frontier in all_pareto_frontiers:\n        point_strings = []\n        for point in frontier:\n            point_strings.append(f\"[{point[0]:.3f},{point[1]:.3f}]\")\n        frontier_strings.append(f\"[{','.join(point_strings)}]\")\n    \n    final_output = f\"[{','.join(frontier_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3156166"}]}