{"hands_on_practices": [{"introduction": "要真正掌握双降现象，眼见为实是最好的方法。这个练习将指导你通过实验来复现完整的双降曲线，你会训练一个简单的随机特征模型，并绘制测试误差随模型参数数量变化的图像。通过这个实践 [@problem_id:3151120]，你将亲眼见证模型从欠参数化区域过渡到过参数化区域时，测试误差先上升后再次下降的惊人现象，从而对这一概念建立直观的理解。", "problem": "您的任务是通过扫描参数-样本比，并将插值阈值与测试误差的峰值联系起来，以经验性地展示前馈多层感知机（MLP）中的双下降现象。核心设置如下。\n\n从平方损失下的经验风险最小化的基础出发。设输入空间为 $\\mathbb{R}^d$。考虑一个带有修正线性单元（ReLU）非线性的双层前馈多层感知机（MLP），其中隐藏层权重是固定的，只有输出层权重被训练。对于一个输入向量 $x \\in \\mathbb{R}^d$，该 MLP 计算\n$$\n\\phi(x) = \\big(\\sigma(w_1^\\top x + b_1), \\ldots, \\sigma(w_m^\\top x + b_m)\\big) \\in \\mathbb{R}^m,\n$$\n其中 $\\sigma(z) = \\max\\{0, z\\}$ 是 ReLU 激活函数，$w_j \\in \\mathbb{R}^d$ 和 $b_j \\in \\mathbb{R}$ 是固定的隐藏层参数，$m$ 是隐藏单元的数量。预测输出为\n$$\n\\hat{y}(x) = a^\\top \\phi(x),\n$$\n其中 $a \\in \\mathbb{R}^m$ 是训练的输出层权重。给定训练数据 $\\{(x_i, y_i)\\}_{i=1}^n$，定义设计矩阵\n$$\n\\Phi \\in \\mathbb{R}^{n \\times m}, \\quad \\Phi_{ij} = \\sigma(w_j^\\top x_i + b_j).\n$$\n平方损失下的经验风险最小化问题旨在寻找最小化 $\\sum_{i=1}^n (\\hat{y}(x_i) - y_i)^2$ 的 $a$，这是一个线性最小二乘问题。最小范数解由 Moore–Penrose 伪逆给出：\n$$\na^\\star = \\Phi^+ y,\n$$\n其中 $y = (y_1, \\ldots, y_n)^\\top$ 且 $\\Phi^+$ 表示 $\\Phi$ 的伪逆。当训练均方误差变为零时，达到插值阈值，这通常在 $m$ 增长使得 $\\Phi$ 达到满行秩时发生，从而系统 $\\Phi a = y$ 有解。参数-样本比定义为 $p/n$，其中 $p$ 是训练参数的数量。在此设置中，$p = m$。\n\n双下降现象指的是一种典型行为，即测试误差作为模型容量的函数，最初减少，然后在插值阈值（训练误差降至零的位置）附近增加，之后随着容量进一步增加，在超过该阈值后再次减少。您的程序将从一个教师网络构建合成数据，并在一系列对应不同参数-样本比的 $m$ 值上测量测试均方误差。\n\n数据生成与评估协议：\n- 从标准正态分布中独立抽取输入 $x \\in \\mathbb{R}^d$。\n- 使用一个具有少量 ReLU 单元的固定教师网络生成标签：\n$$\ny = \\sum_{k=1}^{m_{\\text{teacher}}} \\beta_k \\, \\sigma(u_k^\\top x + c_k) + \\varepsilon,\n$$\n其中 $u_k \\in \\mathbb{R}^d$、$c_k \\in \\mathbb{R}$ 和 $\\beta_k \\in \\mathbb{R}$ 是固定的教师参数，$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 是标准差为 $\\sigma$ 的独立高斯噪声。使用 $m_{\\text{teacher}} = 5$。\n- 通过为每个选定的 $m$ 计算 $a^\\star = \\Phi^+ y$ 来训练学生 MLP。\n- 计算训练均方误差\n$$\n\\mathrm{MSE}_{\\text{train}}(m) = \\frac{1}{n} \\sum_{i=1}^n \\left(\\hat{y}(x_i) - y_i \\right)^2,\n$$\n以及在大小为 $n_{\\text{test}}$ 的独立测试集上的测试均方误差\n$$\n\\mathrm{MSE}_{\\text{test}}(m) = \\frac{1}{n_{\\text{test}}} \\sum_{i=1}^{n_{\\text{test}}} \\left(\\hat{y}(x_i^{\\text{test}}) - y_i^{\\text{test}} \\right)^2.\n$$\n设置 $n_{\\text{test}} = \\max\\{3n, 200\\}$。\n\n插值阈值与峰值检测：\n- 定义插值容差 $\\epsilon = 10^{-10}$ 和峰值边际 $\\delta = 0.1$（意为 $10\\%$）。\n- 对于给定的 $n$ 和一系列 $m$ 值，将插值阈值 $m_{\\text{interp}}$ 定义为该系列中使得 $\\mathrm{MSE}_{\\text{train}}(m) \\le \\epsilon$ 的最小 $m$。\n- 如果在插值阈值处的 $\\mathrm{MSE}_{\\text{test}}(m_{\\text{interp}})$ 超过所有其他 $m$ 值的 $\\mathrm{MSE}_{\\text{test}}(m)$ 的中位数至少 $(1+\\delta)$ 倍，则定义为出现一个峰值。形式上，如果\n$$\n\\mathrm{MSE}_{\\text{test}}(m_{\\text{interp}}) > (1 + \\delta) \\cdot \\operatorname{median}\\left(\\{\\mathrm{MSE}_{\\text{test}}(m) : m \\in \\mathcal{M}, m \\neq m_{\\text{interp}}\\}\\right),\n$$\n则输出布尔值 $\\mathrm{True}$；否则输出 $\\mathrm{False}$。如果扫描范围内的 $m$ 值均未达到插值，则输出 $\\mathrm{False}$。\n\n扫描设计：\n- 对于每个测试用例，通过将 $n$ 与比率 $\\{0.5, 0.8, 1.0, 1.2, 1.5\\}$ 相乘并四舍五入到最近的整数来构建隐藏单元数列表 $\\mathcal{M}$，确保 $m \\ge 1$。即，\n$$\n\\mathcal{M} = \\left\\{ \\max\\left(1, \\left\\lfloor r \\cdot n \\right\\rceil \\right) : r \\in \\{0.5, 0.8, 1.0, 1.2, 1.5\\} \\right\\}.\n$$\n在单个测试用例中，确保所有学生网络的隐藏层参数 $\\{(w_j, b_j)\\}_{j=1}^{m_{\\max}}$ 在最大的 $m_{\\max} = \\max \\mathcal{M}$ 处一次性固定，并且较小的 $m$ 的模型重用前 $m$ 个特征，以使扫描具有可比性。\n\n测试套件：\n在以下四个测试用例上运行您的程序。对于每个用例，根据上述规则报告一个布尔值，指示是否在插值阈值处检测到峰值。每个用例使用独立的随机种子来确定性地固定所有随机性。\n\n- 用例 1：$n = 60$, $d = 20$, $\\sigma = 0.5$, $\\text{seed} = 0$。\n- 用例 2：$n = 60$, $d = 20$, $\\sigma = 0.0$, $\\text{seed} = 1$。\n- 用例 3：$n = 24$, $d = 8$, $\\sigma = 0.5$, $\\text{seed} = 2$。\n- 用例 4：$n = 80$, $d = 30$, $\\sigma = 0.8$, $\\text{seed} = 3$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，例如 $\\left[\\mathrm{result}_1,\\mathrm{result}_2,\\mathrm{result}_3,\\mathrm{result}_4\\right]$，其中每个 $\\mathrm{result}_i$ 是对应于用例 $i$ 的峰值检测结果的 $\\mathrm{True}$ 或 $\\mathrm{False}$。", "solution": "问题陈述是有效的。它具有科学依据，问题定义明确，客观，并为在随机特征模型中对双下降现象进行经验性研究提供了一套完整且一致的指令。其中没有矛盾、歧义或事实错误。因此，我们可以着手解决。\n\n目标是经验性地研究一个简化的多层感知机（MLP）中的双下降现象。该现象描述了测试误差作为模型容量的函数，呈现出先是 U 形，然后向下倾斜的曲线。最初的下降对应于欠参数化区域中经典的偏差-方差权衡。然后测试误差在插值阈值附近达到峰值，此时模型刚好有足够的容量来完美拟合训练数据。超过此点，在过参数化区域中，测试误差出人意料地再次下降。\n\n该方法论是基于教师-学生框架构建的受控数值实验。\n\n**1. 模型规格与训练**\n\n该模型是一个双层前馈网络，使用修正线性单元（ReLU）作为激活函数，$\\sigma(z) = \\max\\{0, z\\}$。对于输入 $x \\in \\mathbb{R}^d$，输出为 $\\hat{y}(x) = a^\\top \\phi(x)$，其中 $\\phi(x) = (\\sigma(w_1^\\top x + b_1), \\ldots, \\sigma(w_m^\\top x + b_m))$ 是一个特征激活向量。此问题的一个关键方面是，隐藏层参数 $\\{w_j, b_j\\}_{j=1}^m$ 在随机初始化后是固定的。只有输出层权重 $a \\in \\mathbb{R}^m$ 被训练。这将非线性神经网络问题转化为高维特征空间中的线性回归问题，即所谓的随机特征模型。隐藏单元的数量 $m$ 直接对应于可训练参数的数量，并作为我们衡量模型容量的标准。\n\n给定 $n$ 个训练样本 $\\{(x_i, y_i)\\}_{i=1}^n$，我们构成设计矩阵 $\\Phi \\in \\mathbb{R}^{n \\times m}$，其中每个元素为 $\\Phi_{ij} = \\sigma(w_j^\\top x_i + b_j)$。目标是找到最小化平方损失 $\\mathcal{L}(a) = \\sum_{i=1}^n (y_i - a^\\top \\phi(x_i))^2 = \\|y - \\Phi a\\|_2^2$ 的权重向量 $a$。\n\n这个线性最小二乘问题的解，同时具有最小欧几里得范数 $\\|a\\|_2$，由 $a^\\star = \\Phi^+ y$ 给出。这里，$\\Phi^+$ 是设计矩阵 $\\Phi$ 的 Moore-Penrose 伪逆，而 $y = (y_1, \\ldots, y_n)^\\top$ 是训练标签的向量。伪逆为任何形状的 $\\Phi$ 提供了唯一、稳定的解，正确处理了欠参数化（$m  n$，通常为满列秩）和过参数化（$m  n$，通常为满行秩）两种情况。\n\n**2. 数据生成与评估**\n\n我们采用教师-学生设置来创建一个具有已知真实标签的合成数据集。\n- 一个固定的“教师”网络，拥有 $m_{\\text{teacher}} = 5$ 个隐藏单元，生成标签：$y = \\sum_{k=1}^{m_{\\text{teacher}}} \\beta_k \\, \\sigma(u_k^\\top x + c_k) + \\varepsilon$。输入向量 $x \\in \\mathbb{R}^d$ 从标准正态分布中抽取。高斯噪声 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 被加到输出上，以模拟固有的测量误差或未建模效应。\n- 然后，一个“学生”模型（我们的可训练模型）在 $n$ 个这样的数据点集上进行训练。\n- 训练后的学生模型的性能使用均方误差（MSE）进行评估，评估分别在训练集和一个独立的、更大的测试集上进行，测试集大小为 $n_{\\text{test}} = \\max\\{3n, 200\\}$。\n  - $\\mathrm{MSE}_{\\text{train}}(m) = \\frac{1}{n} \\|\\Phi a^\\star - y\\|^2$\n  - $\\mathrm{MSE}_{\\text{test}}(m) = \\frac{1}{n_{\\text{test}}} \\| \\Phi_{\\text{test}} a^\\star - y_{\\text{test}}\\|^2$\n\n**3. 实验过程与峰值检测**\n\n实验的核心是随着我们扫描模型容量 $m$ 来跟踪 $\\mathrm{MSE}_{\\text{test}}(m)$。问题定义了一个特定的扫描协议：容量集合 $\\mathcal{M}$ 是通过将样本数量 $n$ 乘以比率 $\\{0.5, 0.8, 1.0, 1.2, 1.5\\}$ 生成的。这组比率旨在探究模型在欠参数化区域（$m/n  1$）、插值阈值附近（$m/n \\approx 1$）和过参数化区域（$m/n  1$）的行为。为确保扫描结果具有可比性，最大模型（$m_{\\max} = \\max \\mathcal{M}$）的随机特征只生成一次，而较小的模型仅使用这些特征的一个子集。\n\n双下降假说预测，在模型首次完美拟合训练数据的点附近，$\\mathrm{MSE}_{\\text{test}}$ 会出现一个峰值。这个点被形式化为插值阈值 $m_{\\text{interp}}$，定义为集合 $\\mathcal{M}$ 中使得 $\\mathrm{MSE}_{\\text{train}}(m) \\le \\epsilon$ 的最小 $m$，其中有一个小容差 $\\epsilon = 10^{-10}$。\n\n如果在此阈值处的测试误差显著高于其他容量下的典型测试误差，则称检测到“峰值”。该条件由以下不等式给出：\n$$\n\\mathrm{MSE}_{\\text{test}}(m_{\\text{interp}}) > (1 + \\delta) \\cdot \\operatorname{median}\\left(\\{\\mathrm{MSE}_{\\text{test}}(m) : m \\in \\mathcal{M}, m \\neq m_{\\text{interp}}\\}\\right)\n$$\n其中峰值边际为 $\\delta = 0.1$。如果满足此条件，则该测试用例的结果为 $\\mathrm{True}$；否则为 $\\mathrm{False}$。如果扫描中没有 $m$ 达到插值，结果也为 $\\mathrm{False}$。\n\n该实现将为四个指定的测试用例中的每一个执行此完整过程，使用给定的随机种子以确保可复现性，并报告峰值检测测试的布尔结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_single_case(n, d, sigma, seed):\n    \"\"\"\n    Runs a single simulation case for the double descent experiment.\n    \n    Args:\n        n (int): Number of training samples.\n        d (int): Input dimension.\n        sigma (float): Standard deviation of label noise.\n        seed (int): Random seed for reproducibility.\n\n    Returns:\n        bool: True if a spike is detected, False otherwise.\n    \"\"\"\n    np.random.seed(seed)\n\n    # 1. Generate Teacher Network\n    m_teacher = 5\n    u_teacher = np.random.randn(m_teacher, d)\n    c_teacher = np.random.randn(m_teacher)\n    beta_teacher = np.random.randn(m_teacher)\n    \n    def teacher_model(X):\n        activations = np.maximum(0, X @ u_teacher.T + c_teacher)\n        return activations @ beta_teacher\n\n    # 2. Generate Training and Test Data\n    X_train = np.random.randn(n, d)\n    noise_train = sigma * np.random.randn(n)\n    y_train = teacher_model(X_train) + noise_train\n\n    n_test = max(3 * n, 200)\n    X_test = np.random.randn(n_test, d)\n    noise_test = sigma * np.random.randn(n_test)\n    y_test = teacher_model(X_test) + noise_test\n\n    # 3. Define Model Sweep\n    ratios = [0.5, 0.8, 1.0, 1.2, 1.5]\n    m_values = sorted(list(set([max(1, int(np.round(r * n))) for r in ratios])))\n    m_max = m_values[-1]\n\n    # 4. Generate Student Network's Fixed Features\n    W_student = np.random.randn(m_max, d)\n    b_student = np.random.randn(m_max)\n\n    train_mses = []\n    test_mses = []\n\n    # 5. Sweep through model capacities (m)\n    for m in m_values:\n        # Select the first m features\n        W_m = W_student[:m, :]\n        b_m = b_student[:m]\n        \n        # Construct design matrix for training\n        Phi_train = np.maximum(0, X_train @ W_m.T + b_m)\n        \n        # Train model using Moore-Penrose pseudoinverse\n        # a_star = pinv(Phi_train) @ y_train\n        a_star = np.linalg.pinv(Phi_train) @ y_train\n        \n        # Evaluate Training MSE\n        y_train_pred = Phi_train @ a_star\n        train_mse = np.mean((y_train_pred - y_train) ** 2)\n        train_mses.append(train_mse)\n        \n        # Evaluate Test MSE\n        Phi_test = np.maximum(0, X_test @ W_m.T + b_m)\n        y_test_pred = Phi_test @ a_star\n        test_mse = np.mean((y_test_pred - y_test) ** 2)\n        test_mses.append(test_mse)\n\n    # 6. Analyze Results for Spike Detection\n    epsilon = 1e-10\n    delta = 0.1\n    \n    np_train_mses = np.array(train_mses)\n    np_test_mses = np.array(test_mses)\n    \n    # Find interpolation threshold m_interp\n    interp_indices = np.where(np_train_mses = epsilon)[0]\n    \n    if len(interp_indices) == 0:\n        # No model achieved interpolation\n        return False\n        \n    idx_interp = interp_indices[0]\n    # m_interp = m_values[idx_interp] # not needed for calculation\n    mse_test_at_interp = np_test_mses[idx_interp]\n\n    # Get test MSEs for all other m values\n    other_indices = np.arange(len(m_values)) != idx_interp\n    other_test_mses = np_test_mses[other_indices]\n\n    if len(other_test_mses) == 0:\n        return False\n\n    median_other_mses = np.median(other_test_mses)\n    \n    # Check for spike condition\n    is_spike = mse_test_at_interp > (1 + delta) * median_other_mses\n    \n    return is_spike\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (n, d, sigma, seed)\n        (60, 20, 0.5, 0),\n        (60, 20, 0.0, 1),\n        (24, 8, 0.5, 2),\n        (80, 30, 0.8, 3),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, d, sigma, seed = case\n        result = run_single_case(n, d, sigma, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3151120"}, {"introduction": "观察到插值峰后，一个自然的问题是：哪些因素会影响峰值的高度？这个练习 [@problem_id:3183597] 旨在挑战你探究两种不同噪声来源——标签噪声与输入噪声——对峰值大小的独特影响。通过从基本原理出发进行推导，并用实验加以验证，你将发现为何在插值点附近，模型对这两种噪声的敏感度有天壤之别，从而深化对插值峰形成机制的理解。", "problem": "你需要从第一性原理出发并通过实验来研究，在线性回归的双下降现象中，训练时输入噪声与训练时标签噪声如何影响插值阈值附近出现的测试风险曲线峰值的高度。你必须预测哪种类型的噪声会产生更高的峰值，并通过模拟一个教师-学生线性模型来验证你的预测。该模型具有各向同性高斯特征，你需要在模型复杂度增加时计算样本外均方误差。\n\n基本基础和设定：\n- 考虑一个固定但未知的参数向量 $\\beta \\in \\mathbb{R}^m$ 和一个输入向量 $x \\in \\mathbb{R}^m$，其坐标是独立同分布的标准正态随机变量。无噪声的教师函数为 $f^\\star(x) = x^\\top \\beta$。\n- 你将通过最小化训练误差来训练一个线性预测器 $\\hat{f}(x) = x^\\top \\hat{w}$，并在所有插值解中选择欧几里得范数最小的解（即最小范数插值线性回归器）。你将在一个范围内改变模型参数的数量 $m$，该范围会扫过 $m \\approx n$ 附近的插值阈值，其中 $n$ 是训练样本的数量。\n- 必须在相同条件下比较两种训练时噪声模型，噪声标准差均为 $\\sigma$：\n  1. 标签噪声：干净的输入和带噪声的标签，训练标签为 $y = f^\\star(x) + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0,\\sigma^2)$ 且独立于 $x$。\n  2. 输入噪声：带噪声的输入和干净的标签，观测到的训练输入为 $x_{\\text{obs}} = x + \\xi$，其中 $\\xi \\sim \\mathcal{N}(0,\\sigma^2 I_m)$ 且独立于 $x$，训练标签为 $y = f^\\star(x)$。\n- 在这两种情况下，都使用干净的测试输入，并对照无噪声的教师函数 $f^\\star$ 来评估样本外均方误差。也就是说，对于一个学习到的 $\\hat{w}$ 和一个新的干净测试输入矩阵 $X_{\\text{test}}$，将测试风险计算为 $(x^\\top \\hat{w} - x^\\top \\beta)^2$ 在所有测试输入 $x$ 上的经验平均值。\n\n设计要求：\n- 从以下基础开始你的推导：均方误差的偏差-方差分解、线性模型 $f^\\star(x)=x^\\top \\beta$ 以及线性回归的最小范数插值解的性质。不要引用任何专门针对双下降的捷径公式；相反，应从这些原理出发，解释为什么在插值阈值附近会出现一个峰值，以及两种噪声机制如何不同地影响峰值高度。\n- 你的程序必须模拟这两种噪声模型，在指定的网格上扫描 $m$，为每个 $m$ 计算多次独立试验的平均测试均方误差，并为每个测试用例报告标签噪声下的峰值测试误差是否高于输入噪声下的峰值测试误差。\n\n测试套件：\n对于下面的每个测试用例，使用相应的参数 $(n, \\{m\\text{-grid}\\}, \\sigma, T, s)$，其中 $n$ 是训练样本数，$\\{m\\text{-grid}\\}$ 是要评估的模型大小集合，$\\sigma$ 是噪声标准差， $T$ 是用于平均的独立试验次数， $s$ 是用于初始化随机数生成器的随机种子。对于网格中的每个 $m$，抽取一个新的 $\\beta \\in \\mathbb{R}^m$，其独立坐标 $\\beta_j \\sim \\mathcal{N}(0, 1/m)$（因此 $\\mathbb{E}[f^\\star(x)^2] \\approx 1$），生成一个有 $n$ 行的训练设计矩阵和一个有 $n_{\\text{test}}$ 行的测试设计矩阵，其中 $n_{\\text{test}} = 1000$。在标签噪声条件下，仅向训练标签添加标准差为 $\\sigma$ 的标签噪声；在输入噪声条件下，仅向训练输入添加标准差为 $\\sigma$ 的输入噪声。评估时，始终使用干净的测试输入和无噪声的教师函数 $f^\\star$。\n\n你必须完全按照以下方式实现最小范数插值线性回归器：对于训练矩阵 $X \\in \\mathbb{R}^{n \\times m}$ 和训练标签 $y \\in \\mathbb{R}^n$，如果 $m \\le n$，通过正规方程 $\\hat{w} = (X^\\top X)^{-1} X^\\top y$ 计算 $\\hat{w}$（为确保数值稳定性，加入一个小的岭回归正则项）；如果 $m > n$，通过 $\\hat{w} = X^\\top (X X^\\top)^{-1} y$ 计算最小范数插值器（同样为确保稳定性加入一个小的岭回归项）。岭回归项必须是一个极小的正标量（例如 $10^{-9}$），仅用于确保数值稳定性，而不是为了进行有意义的正则化。\n\n为以下三个测试用例提供结果：\n- 测试用例 A: $n = 100$, $\\{m\\text{-grid}\\} = \\{10, 20, 30, \\dotsc, 200\\}$, $\\sigma = 0.5$, $T = 6$, $s = 1729$.\n- 测试用例 B: $n = 60$, $\\{m\\text{-grid}\\} = \\{6, 12, 18, \\dotsc, 120\\}$, $\\sigma = 1.0$, $T = 6$, $s = 2027$.\n- 测试用例 C: $n = 120$, $\\{m\\text{-grid}\\} = \\{12, 24, 36, \\dotsc, 240\\}$, $\\sigma = 0.25$, $T = 6$, $s = 9811$.\n\n预测与验证：\n- 根据你的推导，预测哪种噪声类型应该在插值阈值附近产生更高的峰值。然后，对于每个测试用例，计算在标签噪声和输入噪声下，整个 $m$-grid 上的最大测试均方误差。为每个测试用例输出一个整数指示符，如果标签噪声峰值严格高于输入噪声峰值，则为 $1$，否则为 $0$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[1,0,1]”），按 A、B、C 的顺序对应三个测试用例的结果。不应打印任何其他文本。", "solution": "该问题要求从第一性原理出发，对标签噪声与输入噪声在线性回归双下降现象背景下对测试风险曲线峰值的相对影响进行分析。必须先做出预测，然后通过数值实验进行验证。\n\n### 理论推导\n\n我们首先建立分析框架。对于一个学习到的权重向量 $\\hat{w} \\in \\mathbb{R}^m$ 和一个真实的参数向量 $\\beta \\in \\mathbb{R}^m$，样本外均方误差（或称测试风险）由在干净测试数据 $x \\sim \\mathcal{N}(0, I_m)$ 上的期望给出：\n$$\nR(\\hat{w}) = \\mathbb{E}_{x} \\left[ (x^\\top \\hat{w} - x^\\top \\beta)^2 \\right]\n$$\n鉴于输入特征是各向同性的，即 $\\mathbb{E}[x x^\\top] = I_m$，风险简化为估计权重向量与真实权重向量之间欧几里得距离平方的期望，其中期望是针对训练数据 $\\mathcal{D}$ 的分布计算的：\n$$\nR(\\hat{w}) = \\mathbb{E}_{\\mathcal{D}} \\left[ (\\hat{w} - \\beta)^\\top \\mathbb{E}[x x^\\top] (\\hat{w} - \\beta) \\right] = \\mathbb{E}_{\\mathcal{D}} \\left[ \\|\\hat{w} - \\beta\\|^2 \\right]\n$$\n该风险可以分解为偏差平方和方差。令 $\\bar{w} = \\mathbb{E}_{\\mathcal{D}}[\\hat{w}]$ 为平均估计权重向量。分解如下：\n$$\nR(\\hat{w}) = \\underbrace{\\|\\bar{w} - \\beta\\|^2}_{\\text{偏差}^2} + \\underbrace{\\mathbb{E}_{\\mathcal{D}}\\left[\\|\\hat{w} - \\bar{w}\\|^2\\right]}_{\\text{方差}}\n$$\n“双下降”曲线描述了当模型复杂度（由特征数量 $m$ 相对于训练样本数量 $n$ 参数化）增加时，此风险的非单调行为。一个特征性的峰值出现在插值阈值处，即 $m \\approx n$。这个峰值主要是一个由方差驱动的现象，源于训练数据矩阵的病态性。我们的分析将集中于每种噪声模型如何影响这个方差项。\n\n指定的估计器是最小范数线性回归器。对于训练数据矩阵 $A \\in \\mathbb{R}^{n \\times m}$ 和标签 $y \\in \\mathbb{R}^n$，估计的权重 $\\hat{w}$ 为：\n$$\n\\hat{w} =\n\\begin{cases}\n    (A^\\top A)^{-1} A^\\top y  \\text{若 } m \\le n \\text{ (欠参数化)} \\\\\n    A^\\top (A A^\\top)^{-1} y  \\text{若 } m > n \\text{ (过参数化)}\n\\end{cases}\n$$\n在数值上，一个小的岭回归正则项 $\\lambda I$（其中 $\\lambda \\to 0^+$）被加到待求逆的矩阵中以确保稳定性。\n\n#### 情况 1：标签噪声\n\n在这种情况下，训练数据由干净的输入 $X \\in \\mathbb{R}^{n \\times m}$ 和带噪声的标签 $y = X\\beta + \\eta$ 组成，其中 $\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_n)$。回归器在 $(A, y) = (X, X\\beta + \\eta)$ 上进行训练。\n\n对于 $m \\le n$：\n$$\n\\hat{w}_{\\text{label}} = (X^\\top X)^{-1} X^\\top (X\\beta + \\eta) = \\beta + (X^\\top X)^{-1} X^\\top \\eta\n$$\n该估计器对于噪声是无偏的，即 $\\mathbb{E}_{\\eta}[\\hat{w}_{\\text{label}}] = \\beta$。风险完全由方差引起：\n$$\nR(\\hat{w}_{\\text{label}}) = \\mathbb{E}_{X, \\eta} \\left[ \\|(X^\\top X)^{-1} X^\\top \\eta\\|^2 \\right] = \\mathbb{E}_{X} \\left[ \\text{Tr}\\left( (X^\\top X)^{-1} X^\\top \\mathbb{E}_{\\eta}[\\eta\\eta^\\top] X (X^\\top X)^{-1} \\right) \\right]\n$$\n由于 $\\mathbb{E}_{\\eta}[\\eta\\eta^\\top] = \\sigma^2 I_n$，上式简化为：\n$$\nR(\\hat{w}_{\\text{label}}) = \\sigma^2 \\mathbb{E}_{X} \\left[ \\text{Tr}\\left( (X^\\top X)^{-1} \\right) \\right]\n$$\n矩阵 $X^\\top X$ 是一个Wishart矩阵。当 $m \\to n^-$ 时，其最小特征值趋近于零，导致其逆矩阵的迹（trace）激增。这导致了测试风险的特征性峰值。对 $m > n$ 的类似分析得出的风险贡献与 $\\sigma^2 \\mathbb{E}_{X} \\left[ \\text{Tr}\\left( (X X^\\top)^{-1} \\right) \\right]$ 成正比，当 $m \\to n^+$ 时该项也会发散。因此，峰值与噪声方差 $\\sigma^2$ 以及一个与数据矩阵病态性相关的放大因子成正比。\n\n#### 情况 2：输入噪声\n\n在这里，训练数据由带噪声的输入 $X_{\\text{obs}} = X_{\\text{true}} + \\Xi$ 和干净的标签 $y = X_{\\text{true}}\\beta$ 组成。随机矩阵 $\\Xi \\in \\mathbb{R}^{n \\times m}$ 包含独立同分布的噪声元素 $\\Xi_{ij} \\sim \\mathcal{N}(0, \\sigma^2)$。回归器在 $(A, y) = (X_{\\text{obs}}, X_{\\text{true}}\\beta)$ 上进行训练。\n\n我们可以将此问题重新表述为一个等效的标签噪声问题。目标标签可以用观测到的输入来表示：\n$$\ny = X_{\\text{true}}\\beta = (X_{\\text{obs}} - \\Xi)\\beta = X_{\\text{obs}}\\beta - \\Xi\\beta\n$$\n这表明，在 $(X_{\\text{obs}}, y)$ 上训练线性模型等效于在数据 $(X_{\\text{obs}}, X_{\\text{obs}}\\beta + \\eta')$ 上进行训练，其中“等效”标签噪声为 $\\eta' = -\\Xi\\beta$。\n\n让我们分析这个等效噪声 $\\eta'$。它是一个在 $\\mathbb{R}^n$ 中的向量。其第 $i$ 个分量是 $\\eta'_i = -\\xi_i^\\top \\beta$，其中 $\\xi_i^\\top$ 是 $\\Xi$ 的第 $i$ 行。行向量 $\\xi_i$ 是独立的，所以噪声项 $\\eta'_i$ 也是独立的。每个项的方差为：\n$$\n\\text{Var}(\\eta'_i) = \\mathbb{E}_{\\Xi} [(\\xi_i^\\top \\beta)^2] = \\beta^\\top \\mathbb{E}_{\\Xi}[\\xi_i \\xi_i^\\top] \\beta = \\beta^\\top (\\sigma^2 I_m) \\beta = \\sigma^2 \\|\\beta\\|^2\n$$\n问题规定，真实权重 $\\beta$ 的抽取方式使得 $\\mathbb{E}[\\|\\beta\\|^2] = \\mathbb{E}[\\sum_{j=1}^m \\beta_j^2] = \\sum_{j=1}^m (1/m) = 1$。因此，平均而言，等效标签噪声的方差为 $\\sigma^2$。这与情况1中显式标签噪声的方差相同。\n\n然而，关键的区别在于回归器使用的数据矩阵。对于 $m \\le n$ 的估计器是：\n$$\n\\hat{w}_{\\text{input}} = (X_{\\text{obs}}^\\top X_{\\text{obs}})^{-1} X_{\\text{obs}}^\\top y\n$$\n被求逆的矩阵是 $X_{\\text{obs}}^\\top X_{\\text{obs}}$，而不是 $X_{\\text{true}}^\\top X_{\\text{true}}$。$X_{\\text{true}}$ 的元素是从 $\\mathcal{N}(0, 1)$ 中抽取的，而 $\\Xi$ 的元素是从 $\\mathcal{N}(0, \\sigma^2)$ 中抽取的。由于它们是独立的，观测矩阵 $X_{\\text{obs}} = X_{\\text{true}} + \\Xi$ 的元素是从 $\\mathcal{N}(0, 1+\\sigma^2)$ 中抽取的。\n\n这意味着我们可以写出 $X_{\\text{obs}} = \\sqrt{1+\\sigma^2} Z$，其中 $Z$ 是一个具有独立同分布 $\\mathcal{N}(0, 1)$ 元素的矩阵，就像 $X_{\\text{true}}$ 一样。待求逆的矩阵变为：\n$$\nX_{\\text{obs}}^\\top X_{\\text{obs}} = (1+\\sigma^2) Z^\\top Z\n$$\n因此，$X_{\\text{obs}}^\\top X_{\\text{obs}}$ 的特征值比一个标准Wishart矩阵 $Z^\\top Z$（其谱分布与 $X_{\\text{true}}^\\top X_{\\text{true}}$ 相同）的特征值大一个因子 $(1+\\sigma^2)$。\n\n输入噪声的方差放大因子，类似于情况1，将与 $\\text{Tr}((X_{\\text{obs}}^\\top X_{\\text{obs}})^{-1})$ 成正比。\n$$\n\\text{Tr}\\left( (X_{\\text{obs}}^\\top X_{\\text{obs}})^{-1} \\right) = \\text{Tr}\\left( ((1+\\sigma^2) Z^\\top Z)^{-1} \\right) = \\frac{1}{1+\\sigma^2} \\text{Tr}\\left( (Z^\\top Z)^{-1} \\right)\n$$\n比较峰值处风险的方差贡献：\n-   **标签噪声峰值高度** $\\propto \\sigma^2 \\cdot \\mathbb{E}[\\text{Tr}((X^\\top X)^{-1})]$\n-   **输入噪声峰值高度** $\\propto (\\sigma^2 \\mathbb{E}[\\|\\beta\\|^2]) \\cdot \\mathbb{E}[\\text{Tr}((X_{\\text{obs}}^\\top X_{\\text{obs}})^{-1})] \\approx \\sigma^2 \\cdot \\frac{1}{1+\\sigma^2} \\mathbb{E}[\\text{Tr}((Z^\\top Z)^{-1})]$\n\n由于 $\\sigma^2 > 0$，因子 $\\frac{1}{1+\\sigma^2}$ 严格小于 $1$。输入噪声具有自正则化效应：它增加了输入特征的方差，这使得样本协方差矩阵的条件更好，从而减少了伪逆对噪声的放大。虽然更详细的分析还会考虑偏差项（输入噪声会引入变量含误差偏误），但插值阈值处的峰值主要由方差爆炸主导，而我们的分析表明，在输入噪声的情况下，这种爆炸受到了显著的抑制。\n\n### 预测\n\n基于此推导，在给定相同噪声标准差 $\\sigma$ 的情况下，插值阈值 $m \\approx n$ 附近的测试风险峰值对于**标签噪声**将比对于输入噪声**更高**。问题中指定的数值实验将用于验证这一预测。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_w_hat(X, y, ridge_lambda):\n    \"\"\"\n    Computes the minimum-norm interpolating linear regressor.\n    - If m = n, computes via normal equations.\n    - If m > n, computes via dual form (minimum L2 norm solution).\n    A small ridge is added for numerical stability.\n    \"\"\"\n    n, m = X.shape\n    \n    if m = n:\n        # Under-parameterized or exactly determined case\n        # Solve (X.T @ X + lambda*I) w = X.T @ y\n        A = X.T @ X + ridge_lambda * np.identity(m)\n        b = X.T @ y\n        try:\n            w_hat = np.linalg.solve(A, b)\n        except np.linalg.LinAlgError:\n            # Fallback to pseudoinverse if solve fails despite ridge\n            w_hat = np.linalg.pinv(X) @ y\n    else:\n        # Over-parameterized case (minimum norm solution)\n        # Solve (X @ X.T + lambda*I) z = y, then w = X.T @ z\n        A = X @ X.T + ridge_lambda * np.identity(n)\n        try:\n            z = np.linalg.solve(A, y)\n            w_hat = X.T @ z\n        except np.linalg.LinAlgError:\n            w_hat = np.linalg.pinv(X) @ y\n            \n    return w_hat\n\ndef run_experiment(n, m_grid, sigma, T, s):\n    \"\"\"\n    Runs one full experiment for a given test case configuration.\n    \"\"\"\n    n_test = 1000\n    ridge_lambda = 1e-9\n    rng = np.random.default_rng(s)\n\n    mse_label_noise = np.zeros(len(m_grid))\n    mse_input_noise = np.zeros(len(m_grid))\n\n    for i, m in enumerate(m_grid):\n        trial_mses_label = []\n        trial_mses_input = []\n\n        for _ in range(T):\n            # Generate new data for each trial\n            \n            # 1. Generate true parameters and clean data\n            beta = rng.normal(0, 1 / np.sqrt(m), size=(m, 1))\n            X_true_train = rng.normal(0, 1, size=(n, m))\n            y_true_train = X_true_train @ beta\n            X_test = rng.normal(0, 1, size=(n_test, m))\n            y_test = X_test @ beta\n\n            # 2. Label Noise Simulation\n            eta = rng.normal(0, sigma, size=(n, 1))\n            y_train_label = y_true_train + eta\n            X_train_label = X_true_train\n            \n            w_hat_label = compute_w_hat(X_train_label, y_train_label, ridge_lambda)\n            mse_label = np.mean((X_test @ w_hat_label - y_test)**2)\n            trial_mses_label.append(mse_label)\n\n            # 3. Input Noise Simulation\n            Xi = rng.normal(0, sigma, size=(n, m))\n            X_train_input = X_true_train + Xi\n            y_train_input = y_true_train\n            \n            w_hat_input = compute_w_hat(X_train_input, y_train_input, ridge_lambda)\n            mse_input = np.mean((X_test @ w_hat_input - y_test)**2)\n            trial_mses_input.append(mse_input)\n\n        # Average MSE over trials for the current m\n        mse_label_noise[i] = np.mean(trial_mses_label)\n        mse_input_noise[i] = np.mean(trial_mses_input)\n\n    # Find the peak MSE for each noise type\n    peak_label = np.max(mse_label_noise)\n    peak_input = np.max(mse_input_noise)\n\n    return 1 if peak_label > peak_input else 0\n\ndef solve():\n    \"\"\"\n    Defines and runs the test cases, then prints the final result.\n    \"\"\"\n    test_cases = [\n        # (n, m-grid, sigma, T, s)\n        (100, list(range(10, 201, 10)), 0.5, 6, 1729),   # Test Case A\n        (60, list(range(6, 121, 6)), 1.0, 6, 2027),      # Test Case B\n        (120, list(range(12, 241, 12)), 0.25, 6, 9811),  # Test Case C\n    ]\n\n    results = []\n    for n, m_grid, sigma, T, s in test_cases:\n        result = run_experiment(n, m_grid, sigma, T, s)\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3183597"}, {"introduction": "双降现象不仅限于模型大小的变化，它同样可以出现在训练过程的时间维度上。这个更进一步的实践 [@problem_id:3183606] 探索了所谓的“轮次双降”（epoch-wise double descent），即测试误差在训练过程中会先上升，然后再次下降。通过构建一个同时学习“泛化特征”和“记忆特征”的模型，你将观察到模型在训练的不同阶段如何切换学习重点，从而导致一个暂时的过拟合峰并最终实现性能恢复，这使得该现象与现代深度学习的训练动态紧密相连。", "problem": "你的任务是构建一个科学严谨的仿真，用于检验在一个小型语言建模任务的 Transformer 代理模型中的世代双下降（epoch-wise double descent）现象。目标是将训练动态与插值（interpolation）联系起来，并量化测试交叉熵在各个世代（epoch）中的行为。你的实现必须是一个完整的、可运行的程序，能够根据给定的测试套件产生指定的最终输出，无需用户输入。\n\n请从以下定义和事实的基本框架开始：\n- 监督学习的经验风险最小化（Empirical risk minimization）考虑一个数据集 $\\{(x_i, y_i)\\}_{i=1}^{n}$ 和一个带有参数 $\\theta$ 的模型，该模型输出类别概率 $p_\\theta(y \\mid x)$。在多类交叉熵下的经验风险为\n$$\n\\mathcal{L}_{\\text{emp}}(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} -\\log\\left( p_\\theta(y_i \\mid x_i) \\right).\n$$\n- 对于 logits $z \\in \\mathbb{R}^K$ 的 softmax 函数定义为\n$$\n\\text{softmax}(z)_k = \\frac{e^{z_k}}{\\sum_{j=1}^{K} e^{z_j}} \\quad \\text{for } k \\in \\{1,\\dots,K\\}.\n$$\n- 对于一个带有权重矩阵 $W \\in \\mathbb{R}^{K \\times F}$ 和特征向量 $x \\in \\mathbb{R}^F$ 的线性 softmax 分类器，其 logits 为 $z = W x$，预测的类别概率为 $p(y \\mid x) = \\text{softmax}(W x)$。\n- 对于单个样本 $(x,y)$（其 one-hot 类别向量为 $e_y \\in \\mathbb{R}^K$），交叉熵损失关于 $W$ 的梯度为\n$$\n\\nabla_W \\ell(W; x,y) = \\left( p - e_y \\right) x^\\top, \\quad \\text{where } p = \\text{softmax}(W x).\n$$\n- 当训练分类准确率达到 $1.0$（或实际上达到一个近乎完美的阈值）时，即发生插值。这意味着模型完全拟合了所有训练标签；在交叉熵损失的背景下，这对应于 logits 能够将训练数据分开，使得每个样本的预测类别都与 $y_i$ 匹配。\n\n你将使用一阶马尔可夫（二元）过程（first-order Markov (bigram) process）来生成序列，从而仿真一个词汇表大小为 $V$ 的下一词元语言建模任务。设 $P \\in \\mathbb{R}^{V \\times V}$ 是一个二元矩阵，其中 $P_{ij} = \\Pr(\\text{token at time } t = i \\mid \\text{token at time } t-1 = j)$，且每一列 $j$ 的总和为 $1$。\n\n定义一个代理的“类 Transformer”模型，它具有两组特征：\n- 可泛化特征（Generalizable features）$x^{\\text{gen}} \\in \\mathbb{R}^{V}$，由前一个词元的 one-hot 编码给出。\n- 记忆特征（Memorization features）$x^{\\text{mem}} \\in \\mathbb{R}^{M}$，是与每个训练样本唯一绑定的 one-hot 特征；这些特征存在于训练样本中，但在测试样本中为零。完整的特征向量是 $x = \\left[ x^{\\text{gen}}, x^{\\text{mem}} \\right] \\in \\mathbb{R}^{V+M}$。\n\n使用全批量梯度下降（full-batch gradient descent）在交叉熵上训练一个带有权重 $W \\in \\mathbb{R}^{V \\times (V+M)}$ 的线性 softmax 分类器，共训练 $T$ 个世代。使用一个分段常数逐世代学习率方案，该方案为两个参数块 $W^{\\text{gen}} \\in \\mathbb{R}^{V \\times V}$ 和 $W^{\\text{mem}} \\in \\mathbb{R}^{V \\times M}$ 分配不同的学习率：\n- 早期阶段（世代比例 $t/T \\in [0,1/3)$）：为 $W^{\\text{gen}}$ 设置较大的学习率，为 $W^{\\text{mem}}$ 设置较小的学习率。\n- 中期阶段（$t/T \\in [1/3,2/3)$）：为 $W^{\\text{gen}}$ 设置较小的学习率，为 $W^{\\text{mem}}$ 设置较大的学习率，以通过记忆特征驱动插值。\n- 后期阶段（$t/T \\in [2/3,1]$）：为 $W^{\\text{gen}}$ 设置较大的学习率，并将 $W^{\\text{mem}}$ 的学习率设为 $0$；在后期阶段对 $W^{\\text{mem}}$ 应用更强的 $\\ell_2$ 权重衰减，以减少对记忆特征的依赖，并重新为 $W^{\\text{gen}}$ 引入梯度信号。为清晰起见，权重衰减对应于在损失中增加一个惩罚项 $\\frac{\\lambda}{2} \\lVert W \\rVert_2^2$，这会对权重产生一个逐世代的收缩因子。\n\n数据生成：\n- 通过从狄利克雷分布（Dirichlet distribution）中抽取每一列来采样一个二元矩阵 $P$，以确保列的随机性。使用该二元过程生成 $n_{\\text{train}}$ 个训练对 $(x_i, y_i)$ 和 $n_{\\text{test}}$ 个测试对 $(\\tilde{x}_j, \\tilde{y}_j)$，其中 $x_i^{\\text{gen}}$ 和 $\\tilde{x}_j^{\\text{gen}}$ 是 one-hot 形式的前一个词元，$y_i$ 和 $\\tilde{y}_j$ 是下一个词元。在训练标签中注入一小部分比例为 $\\rho$ 的标签噪声，即为 $\\rho$ 比例的训练样本随机替换 $y_i$，以模拟记忆特征可以拟合的伪相关（spurious correlations）。\n\n训练、跟踪与检测：\n- 在每个世代 $t$，计算平均训练交叉熵和训练准确率，以及测试交叉熵和测试准确率。\n- 将插值世代 $t_\\star$ 定义为训练准确率 $\\ge 0.99$ 的最早世代。如果不存在这样的世代，则声明未发生插值。\n- 定义一个早期检查点 $t_a = \\lfloor 0.2 T \\rfloor$ 和最终世代 $T$。\n- 将世代双下降检测定义为以下条件：插值世代的测试交叉熵 $L_{\\text{test}}(t_\\star)$ 严格大于 $L_{\\text{test}}(t_a)$ 和 $L_{\\text{test}}(T)$，并且 $L_{\\text{test}}(T)$ 严格小于 $L_{\\text{test}}(t_a)$。形式上，如果满足\n$$\nL_{\\text{test}}(t_\\star) > \\max\\left( L_{\\text{test}}(t_a), L_{\\text{test}}(T) \\right) \\quad \\text{and} \\quad L_{\\text{test}}(T)  L_{\\text{test}}(t_a),\n$$\n则报告 True，否则报告 False；如果未发生插值，则报告 False。\n\n你的程序必须实现以上内容并运行以下测试套件，每个套件由 $(V, n_{\\text{train}}, n_{\\text{test}}, M, T)$ 指定：\n1. $(8, 150, 500, 0, 180)$: 欠参数化的基线，没有记忆特征；不应发生插值。\n2. $(8, 150, 500, 150, 180)$: 平衡的过参数化，其中记忆特征数量与训练样本数相匹配。\n3. $(8, 100, 500, 300, 180)$: 严重过参数化的记忆特征；具有更强的插值倾向。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如：\"[result1,result2,result3]\"），每个结果是一个布尔值，指示相应测试用例是否检测到世代双下降。此任务不需要单位。输出必须是精确的一行，不含任何额外文本。", "solution": "用户问题要求在一个简化的语言模型设置中，仿真世代双下降现象。该过程涉及生成合成数据，使用特定的特征和训练方案来训练一个线性模型，然后分析测试损失曲线以寻找双下降的特定特征。\n\n### 步骤 1：问题验证\n\n首先，我将验证问题陈述。\n\n#### 提取的已知信息\n- **损失函数**：多类交叉熵，$\\mathcal{L}_{\\text{emp}}(\\theta) = \\frac{1}{n} \\sum_{i=1}^{n} -\\log\\left( p_\\theta(y_i \\mid x_i) \\right)$。\n- **模型**：线性 softmax 分类器，$p(y \\mid x) = \\text{softmax}(W x)$。\n- **梯度**：$\\nabla_W \\ell(W; x,y) = \\left( p - e_y \\right) x^\\top$。\n- **数据生成**：使用一个 $V \\times V$ 的二元矩阵 $P$ 的一阶马尔可夫过程。$P$ 的列从狄利克雷分布中抽取。$n_{\\text{train}}$ 个训练样本，$n_{\\text{test}}$ 个测试样本。一小部分比例为 $\\rho$ 的训练标签是带噪声的。\n- **特征空间**：$x = [x^{\\text{gen}}, x^{\\text{mem}}]$。\n    - $x^{\\text{gen}} \\in \\mathbb{R}^V$：前一个词元的 one-hot 编码。\n    - $x^{\\text{mem}} \\in \\mathbb{R}^M$：与每个训练样本唯一对应的 one-hot 特征，对测试样本为零。\n- **训练**：全批量梯度下降，共 $T$ 个世代。权重矩阵 $W$ 被分为 $W^{\\text{gen}}$ 和 $W^{\\text{mem}}$，采用三阶段的分段常数学习率方案：\n    1.  **早期 ($t/T \\in [0, 1/3)$)**：$W^{\\text{gen}}$ 的学习率高，$W^{\\text{mem}}$ 的学习率低。\n    2.  **中期 ($t/T \\in [1/3, 2/3)$)**：$W^{\\text{gen}}$ 的学习率低，$W^{\\text{mem}}$ 的学习率高。\n    3.  **后期 ($t/T \\in [2/3, 1]$)**：$W^{\\text{gen}}$ 的学习率高，$W^{\\text{mem}}$ 的学习率为零。\n- **正则化**：$\\ell_2$ 权重衰减，在后期阶段对 $W^{\\text{mem}}$ 施加更强的衰减。\n- **检测标准**：\n    - **插值世代 $t_\\star$**：训练准确率 $\\ge 0.99$ 的第一个世代 $t$。如果未发生，则未检测到双下降。\n    - **检查点**：$t_a = \\lfloor 0.2 T \\rfloor$ 和最终世代 $T$。\n    - **双下降条件**：$L_{\\text{test}}(t_\\star) > \\max\\left( L_{\\text{test}}(t_a), L_{\\text{test}}(T) \\right)$ 且 $L_{\\text{test}}(T)  L_{\\text{test}}(t_a)$。\n- **测试套件**：\n    1. $(V, n_{\\text{train}}, n_{\\text{test}}, M, T) = (8, 150, 500, 0, 180)$\n    2. $(V, n_{\\text{train}}, n_{\\text{test}}, M, T) = (8, 150, 500, 150, 180)$\n    3. $(V, n_{\\text{train}}, n_{\\text{test}}, M, T) = (8, 100, 500, 300, 180)$\n\n#### 验证结论\n该问题是科学严谨、定义明确且客观的。它提供了一个形式化的、尽管简化的框架来研究双下降现象，这是深度学习研究中一个备受关注的课题。使用不同类型的特征（“可泛化”与“记忆”）和分阶段的训练方案，是诱导和分离感兴趣动态的合理方法选择。\n\n问题没有指定所有超参数的具体值（例如，学习率、权重衰减系数、噪声水平）。这不应被视为使问题无效的遗漏，而是将选择科学上合理的值以使仿真能够展示预期现象的责任委托给了解决者。我将选择适当的值来完成仿真的目标。因此，该问题被认为是**有效的**。\n\n### 步骤 2：解决方案设计\n\n解决方案将以一个 Python 程序实现，该程序会遍历提供的测试用例。对每个用例，它将执行以下步骤。\n\n#### 数据生成\n通过从具有均匀先验（所有浓度参数等于 $1$）的狄利克雷分布中抽取其 $V$ 列，构建一个二元概率矩阵 $P \\in \\mathbb{R}^{V \\times V}$。这确保了每一列都代表一个有效的概率分布。使用该矩阵，我们通过模拟马尔可夫链生成 $n_{\\text{train}}$ 个训练和 $n_{\\text{test}}$ 个测试词元对 $(x, y)$。对于一小部分比例为 $\\rho$ 的训练数据，标签 $y$ 被替换为随机词元以模拟标签噪声，这对于观察过拟合及其后续恢复的效果至关重要。\n\n#### 特征工程\n每个样本的特征向量 $x$ 是两部分的拼接：\n1.  $x^{\\text{gen}} \\in \\mathbb{R}^V$：表示输入词元的 one-hot 向量。其对应的权重 $W^{\\text{gen}}$ 旨在学习来自 $P$ 的一般转移概率。\n2.  $x^{\\text{mem}} \\in \\mathbb{R}^M$：对每个训练样本唯一的 one-hot 向量。对于第 $i$ 个训练样本，$x^{\\text{mem}}_i$ 是第 $i$ 个标准基向量 $e_i \\in \\mathbb{R}^M$。对于所有测试样本，$x^{\\text{mem}}$ 是零向量。这些特征允许模型记忆特定的训练样本，包括带噪声的样本。\n\n#### 模型与训练动态\n模型是一个线性 softmax 分类器。权重矩阵 $W \\in \\mathbb{R}^{V \\times (V+M)}$ 使用全批量梯度下降进行训练。训练过程分为三个阶段，以精心安排学习动态：\n1.  **早期阶段 ($t/T \\in [0, 1/3)$)**：$W^{\\text{gen}}$ 的高学习率和 $W^{\\text{mem}}$ 的低学习率鼓励模型首先学习数据中存在的可泛化二元结构。测试误差预计会下降。\n2.  **中期阶段 ($t/T \\in [1/3, 2/3)$)**：学习率反转。$W^{\\text{mem}}$ 的高学习率驱动模型通过使用记忆特征来完美拟合训练数据。这导致插值（训练准确率 $\\to 1.0$），通常是通过拟合带噪声的标签。这种过拟合导致测试误差增加，形成 U 型曲线的“上升”部分。\n3.  **后期阶段 ($t/T \\in [2/3, 1]$)**：$W^{\\text{mem}}$ 的学习率设为 $0$，停止基于梯度的更新。同时，对 $W^{\\text{mem}}$ 应用强 $\\ell_2$ 权重衰减，使其权重向零收缩。这迫使模型“忘记”它记忆的噪声模式。随着 $W^{\\text{gen}}$ 再次以高学习率进行训练，模型重新学习可泛化结构，导致测试误差再次下降——即“第二次下降”。\n\n权重更新规则实现为解耦权重衰减。对于每个权重块 $W_p \\in \\{W^{\\text{gen}}, W^{\\text{mem}}\\}$，一个世代的更新为：\n1.  梯度步骤：$W_p \\leftarrow W_p - \\eta_p \\nabla_{W_p} \\mathcal{L}_{\\text{emp}}$\n2.  衰减步骤：$W_p \\leftarrow W_p (1 - \\alpha_p)$，其中 $\\alpha_p$ 是逐世代的权重衰减率。\n这种形式确保了即使当学习率 $\\eta_{\\text{mem}}$ 为零时，$W^{\\text{mem}}$ 的衰减步骤仍然有效。\n\n#### 检测逻辑\n在整个训练过程中，记录每个世代的测试交叉熵损失。训练完成后，对记录的数据进行分析：\n1.  将插值世代 $t_\\star$ 确定为训练准确率首次超过 $0.99$ 的世代。如果从未发生，则结果为 `False`。\n2.  比较三个关键世代的测试损失：一个早期检查点 $t_a = \\lfloor 0.2 T \\rfloor$、插值世代 $t_\\star$ 和最后一个世代 $T-1$（在从 0 开始的索引中）。\n3.  检查双下降条件——$L_{\\text{test}}(t_\\star)$ 是一个高于 $L_{\\text{test}}(t_a)$ 和 $L_{\\text{test}}(T-1)$ 的峰值，并且 $L_{\\text{test}}(T-1)$ 相对于 $L_{\\text{test}}(t_a)$ 有所改善。如果条件成立，结果为 `True`，否则为 `False`。\n\n这个结构化的仿真通过仔细操纵模型容量和训练动态，提供了一个清晰、可验证的世代双下降演示。", "answer": "```python\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef _run_simulation(params, seed):\n    \"\"\"\n    Runs a single simulation for a given set of parameters.\n    \"\"\"\n    V, n_train, n_test, M, T = params\n    rng = np.random.default_rng(seed)\n\n    # --- Hyperparameters ---\n    # These values are chosen to be reasonable for demonstrating the phenomenon.\n    dirichlet_alpha = 1.0\n    label_noise_rho = 0.1\n    # Learning rates for the three phases\n    lr_gen_large, lr_gen_small = 1.0, 0.01\n    lr_mem_large, lr_mem_small = 1.0, 0.01\n    # Decoupled weight decay rates\n    wd_rate_gen = 1e-4\n    wd_rate_mem_base = 1e-4\n    wd_rate_mem_late = 1e-1  # Stronger late-phase decay for memorization weights\n\n    # --- Data Generation ---\n    P_bigram = np.zeros((V, V))\n    for j in range(V):\n        P_bigram[:, j] = rng.dirichlet(np.ones(V) * dirichlet_alpha)\n\n    def generate_samples(num_samples, P_matrix):\n        xs, ys = [], []\n        current_token = rng.choice(V)\n        for _ in range(num_samples):\n            prev_token = current_token\n            probs = P_matrix[:, prev_token]\n            current_token = rng.choice(V, p=probs)\n            xs.append(prev_token)\n            ys.append(current_token)\n        return np.array(xs), np.array(ys)\n\n    x_train_tokens, y_train_tokens = generate_samples(n_train, P_bigram)\n    x_test_tokens, y_test_tokens = generate_samples(n_test, P_bigram)\n    \n    noise_indices = rng.choice(n_train, size=int(n_train * label_noise_rho), replace=False)\n    y_train_tokens[noise_indices] = rng.choice(V, size=len(noise_indices))\n\n    y_train_onehot = np.eye(V)[y_train_tokens].T\n    y_test_onehot = np.eye(V)[y_test_tokens].T\n\n    # --- Feature Construction ---\n    X_gen_train = np.eye(V)[x_train_tokens].T\n    X_gen_test = np.eye(V)[x_test_tokens].T\n\n    X_mem_train = np.eye(M, n_train) if M > 0 else np.empty((0, n_train))\n    X_mem_test = np.zeros((M, n_test))\n\n    X_train = np.vstack([X_gen_train, X_mem_train])\n    X_test = np.vstack([X_gen_test, X_mem_test])\n    \n    # --- Model and Training ---\n    F = V + M  # Total feature dimension\n    limit = np.sqrt(6 / (V + F)) # Glorot/Xavier initialization\n    W_gen = rng.uniform(-limit, limit, (V, V))\n    W_mem = rng.uniform(-limit, limit, (V, M)) if M > 0 else np.empty((V, 0))\n\n    test_losses = []\n    t_star = -1\n\n    def cross_entropy_loss(logits, y_onehot_targets):\n        log_probs = logits - logsumexp(logits, axis=0, keepdims=True)\n        # Use a small epsilon to avoid log(0)\n        return -np.sum(y_onehot_targets * log_probs) / y_onehot_targets.shape[1]\n\n    for t in range(T):\n        phase_frac = t / T\n        if phase_frac  1/3:  # Early phase\n            lr_gen, lr_mem = lr_gen_large, lr_mem_small\n            wd_rate_mem = wd_rate_mem_base\n        elif phase_frac  2/3:  # Middle phase\n            lr_gen, lr_mem = lr_gen_small, lr_mem_large\n            wd_rate_mem = wd_rate_mem_base\n        else:  # Late phase\n            lr_gen, lr_mem = lr_gen_large, 0.0\n            wd_rate_mem = wd_rate_mem_late\n        \n        W = np.hstack([W_gen, W_mem])\n        logits_train = W @ X_train\n        probs_train = np.exp(logits_train - logsumexp(logits_train, axis=0, keepdims=True))\n\n        grad_W = (probs_train - y_train_onehot) @ X_train.T / n_train\n        \n        # Gradient update step\n        W_gen -= lr_gen * grad_W[:, :V]\n        if M > 0:\n            W_mem -= lr_mem * grad_W[:, V:]\n        \n        # Decoupled weight decay step\n        W_gen *= (1 - wd_rate_gen)\n        if M > 0:\n            W_mem *= (1 - wd_rate_mem)\n\n        W_eval = np.hstack([W_gen, W_mem])\n        \n        # Find interpolation epoch t_star\n        if t_star == -1:\n            preds_train = np.argmax(W_eval @ X_train, axis=0)\n            train_acc = np.mean(preds_train == y_train_tokens)\n            if train_acc >= 0.99:\n                t_star = t\n\n        # Record test loss\n        logits_test = W_eval @ X_test\n        test_loss = cross_entropy_loss(logits_test, y_test_onehot)\n        test_losses.append(test_loss)\n    \n    # --- Analysis for Double Descent ---\n    if t_star == -1:  # Interpolation did not occur\n        return False\n        \n    t_a = int(np.floor(0.2 * T))\n    L_test_ta = test_losses[t_a]\n    L_test_tstar = test_losses[t_star]\n    L_test_T = test_losses[T-1]\n\n    is_peak = L_test_tstar > max(L_test_ta, L_test_T)\n    is_recovery = L_test_T  L_test_ta\n    \n    return is_peak and is_recovery\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (8, 150, 500, 0, 180),   # Case 1: Underparameterized\n        (8, 150, 500, 150, 180), # Case 2: Balanced overparameterization\n        (8, 100, 500, 300, 180)  # Case 3: Heavily overparameterized\n    ]\n\n    results = []\n    # Use a fixed seed for reproducibility of each simulation run\n    seed = 42 \n    for case in test_cases:\n        result = _run_simulation(case, seed)\n        results.append(result)\n\n    # Format output exactly as required\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the solution\nsolve()\n```", "id": "3183606"}]}