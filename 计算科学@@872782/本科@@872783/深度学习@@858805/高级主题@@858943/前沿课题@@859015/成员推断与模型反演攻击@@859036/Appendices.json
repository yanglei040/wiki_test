{"hands_on_practices": [{"introduction": "要理解成员推断攻击的原理，我们首先从一个清晰的理想化数学模型入手。本练习将指导你从第一性原理出发，推导出一个最优攻击策略。通过将过拟合现象建模为模型输出中的一个简单偏差，你将运用贝叶斯决策理论，找到一个精确的阈值，以最佳方式区分训练集成员与非成员 [@problem_id:3149406]。这个基础练习揭示了此类隐私漏洞的统计学核心。", "problem": "考虑一个二元分类问题，其标签为 $y \\in \\{-1,+1\\}$，特征向量为 $x \\in \\mathbb{R}^2$。数据由一个共享协方差的高斯判别模型生成：$x \\mid y \\sim \\mathcal{N}(\\mu_y,\\Sigma)$，且类别先验概率为 $\\mathbb{P}(y=+1)=\\mathbb{P}(y=-1)=\\tfrac{1}{2}$。发布的分类器在真实参数 $(\\mu_{+},\\mu_{-},\\Sigma)$ 下计算 Bayes 后验概率 $p_{\\theta}(y \\mid x)$，在共享协方差的情况下，这对应于一个 logit 为 $s(x) = w^{\\top}x + b$ 的 logistic 函数，其中 $w = \\Sigma^{-1}(\\mu_{+}-\\mu_{-})$ 且 $b = -\\tfrac{1}{2}\\left(\\mu_{+}^{\\top}\\Sigma^{-1}\\mu_{+} - \\mu_{-}^{\\top}\\Sigma^{-1}\\mu_{-}\\right)$。\n\n假设训练集成员上存在一种简单的过拟合效应：对于一个真实标签为 $y$ 的数据点，模型报告的真实类别的后验概率为 $q(y \\mid x) = \\sigma\\!\\left(s(x) + b_M\\right)$，其中 $\\sigma(z) = \\tfrac{1}{1+\\exp(-z)}$ 是 logistic 函数，如果该数据点是训练集的成员，则 $b_M = \\beta$；如果不是成员，则 $b_M=0$。攻击者知道 $(\\mu_{+},\\mu_{-},\\Sigma)$、偏置参数 $\\beta  0$、被查询点的真实标签 $y$，并观察到标量 $q(y \\mid x)$。攻击者的目标是在等先验概率 $\\mathbb{P}(M=\\text{member})=\\mathbb{P}(M=\\text{non-member})=\\tfrac{1}{2}$ 的条件下，判断成员身份 $M \\in \\{\\text{member},\\text{non-member}\\}$。\n\n从 Bayes 决策理论和高斯判别模型的基本原理出发，对于一个固定的标签 $y$，推导出最优（Bayes）成员推断决策，其形式为对观测到的 logit $r = \\ln\\!\\left(\\tfrac{q(y \\mid x)}{1-q(y \\mid x)}\\right)$ 的单一阈值。然后将此阈值转换到后验概率域，$t_p^{\\ast} = \\sigma(t^{\\ast})$。\n\n最后，使用特定参数\n- $\\mu_{+} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$，$\\mu_{-} = \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix}$，\n- $\\Sigma = I_2$（$2 \\times 2$ 单位矩阵），\n- $\\beta = 0.8$，\n- 以及已知的真实标签 $y=+1$\n来评估您的表达式，并报告 $t_p^{\\ast}$ 的数值。将您的答案四舍五入至四位有效数字。\n\n为了进行经验验证，考虑以下六个观测值，它们的真实标签均为 $y=+1$，及其成员身份状态 $M$：\n- $x^{(1)} = \\begin{pmatrix}1.1 \\\\ -0.2\\end{pmatrix}$，$M=\\text{member}$，\n- $x^{(2)} = \\begin{pmatrix}0.8 \\\\ 0.3\\end{pmatrix}$，$M=\\text{member}$，\n- $x^{(3)} = \\begin{pmatrix}1.2 \\\\ -0.1\\end{pmatrix}$，$M=\\text{member}$，\n- $x^{(4)} = \\begin{pmatrix}0.6 \\\\ -0.4\\end{pmatrix}$，$M=\\text{non-member}$，\n- $x^{(5)} = \\begin{pmatrix}1.1 \\\\ 0.2\\end{pmatrix}$，$M=\\text{non-member}$，\n- $x^{(6)} = \\begin{pmatrix}0.7 \\\\ 0.0\\end{pmatrix}$，$M=\\text{non-member}$。\n\n使用推导出的最优阈值规则和已知参数，计算经验攻击决策以及由此产生的经验准确率，作为一致性检验。您最终报告的答案必须仅为数字 $t_p^{\\ast}$，四舍五入到四位有效数字，且不带单位。", "solution": "用户希望我通过推导一个最优 Bayes 决策规则来解决一个成员推断问题。\n\n### 问题验证\n\n**第 1 步：提取已知条件**\n-   二元分类标签：$y \\in \\{-1,+1\\}$\n-   特征向量：$x \\in \\mathbb{R}^2$\n-   数据生成模型：$x \\mid y \\sim \\mathcal{N}(\\mu_y,\\Sigma)$\n-   类别先验：$\\mathbb{P}(y=+1)=\\mathbb{P}(y=-1)=\\tfrac{1}{2}$\n-   分类器的 logit：$s(x) = w^{\\top}x + b$\n-   logit 参数：$w = \\Sigma^{-1}(\\mu_{+}-\\mu_{-})$ 且 $b = -\\tfrac{1}{2}\\left(\\mu_{+}^{\\top}\\Sigma^{-1}\\mu_{+} - \\mu_{-}^{\\top}\\Sigma^{-1}\\mu_{-}\\right)$\n-   报告的真实类别 $y$ 的后验概率：$q(y \\mid x) = \\sigma\\!\\left(s(x) + b_M\\right)$，其中 $\\sigma(z) = \\tfrac{1}{1+\\exp(-z)}$\n-   成员偏置：$b_M = \\beta$ (成员)，$b_M=0$ (非成员)，其中 $\\beta  0$\n-   攻击者知识：$(\\mu_{+},\\mu_{-},\\Sigma)$、$\\beta$ 以及真实标签 $y$\n-   攻击者观测值：$q(y \\mid x)$ 或等价的观测 logit $r = \\ln\\!\\left(\\tfrac{q(y \\mid x)}{1-q(y \\mid x)}\\right)$\n-   攻击者目标：判断成员身份 $M \\in \\{\\text{member},\\text{non-member}\\}$\n-   成员先验：$\\mathbb{P}(M=\\text{member})=\\mathbb{P}(M=\\text{non-member})=\\tfrac{1}{2}$\n-   用于评估的特定参数：$\\mu_{+} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$，$\\mu_{-} = \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix}$，$\\Sigma = I_2$，$\\beta = 0.8$，$y=+1$。\n-   经验验证数据（全部 $y=+1$）：\n    -   $x^{(1)} = \\begin{pmatrix}1.1 \\\\ -0.2\\end{pmatrix}$，$M=\\text{member}$\n    -   $x^{(2)} = \\begin{pmatrix}0.8 \\\\ 0.3\\end{pmatrix}$，$M=\\text{member}$\n    -   $x^{(3)} = \\begin{pmatrix}1.2 \\\\ -0.1\\end{pmatrix}$，$M=\\text{member}$\n    -   $x^{(4)} = \\begin{pmatrix}0.6 \\\\ -0.4\\end{pmatrix}$，$M=\\text{non-member}$\n    -   $x^{(5)} = \\begin{pmatrix}1.1 \\\\ 0.2\\end{pmatrix}$，$M=\\text{non-member}$\n    -   $x^{(6)} = \\begin{pmatrix}0.7 \\\\ 0.0\\end{pmatrix}$，$M=\\text{non-member}$\n\n**第 2 步：使用提取的已知条件进行验证**\n该问题在统计决策理论和机器学习安全领域内是良定义的。\n-   **科学依据：** 该设置使用了标准模型：用于分类的高斯判别分析和用于过拟合的简化偏置模型，这是成员推断理论研究中一种常见且合理的方法。\n-   **良态性：** 所有必要信息（分布、参数、先验和攻击者目标）都已提供，足以推导出唯一的 Bayes 最优决策规则。\n-   **客观性：** 问题使用形式化数学语言陈述，没有歧义或主观性。\n-   **完整性：** 问题是自洽的，没有矛盾。\n\n**第 3 步：结论与行动**\n问题有效。将提供完整解答。\n\n### 解题推导\n\n攻击者的任务是在两个假设之间做出决策：$H_1: M=\\text{member}$ 和 $H_0: M=\\text{non-member}$。攻击者观察一个已知真实标签 $y$ 的数据点 $(x,y)$ 的 logit $r = \\ln\\!\\left(\\tfrac{q(y \\mid x)}{1-q(y \\mid x)}\\right)$。根据问题定义，$q(y \\mid x) = \\sigma(s(x) + b_M)$，这意味着观测到的 logit 是 $r = s(x) + b_M$。\n在这两个假设下：\n-   $H_1: M=\\text{member} \\implies b_M = \\beta \\implies r = s(x) + \\beta$\n-   $H_0: M=\\text{non-member} \\implies b_M = 0 \\implies r = s(x)$\n\n根据 Bayes 决策理论，最优决策规则是选择后验概率较高的假设。鉴于先验概率相等 $\\mathbb{P}(H_1) = \\mathbb{P}(H_0) = \\frac{1}{2}$，这等同于选择似然度较高的假设。决策规则是：如果 $p(r \\mid H_1)  p(r \\mid H_0)$，则判定为‘成员’（即选择 $H_1$）。\n\n为了找到似然 $p(r \\mid H_i)$，我们必须确定随机变量 $r$ 的分布。这取决于真实 logit $s(x)$ 的分布。$s(x)$ 中的随机性源于数据点 $x$ 是从其类别条件分布 $x \\mid y \\sim \\mathcal{N}(\\mu_y, \\Sigma)$ 中抽取的。\n\nlogit $s(x) = w^\\top x + b$ 是高斯随机向量 $x$ 的仿射变换，因此它本身是一个高斯随机变量。我们需要找出在已知标签 $y$ 条件下它的均值和方差。\n\n给定 $y$ 时 $s(x)$ 的均值为 $\\mathbb{E}[s(x) \\mid y] = w^\\top \\mathbb{E}[x \\mid y] + b = w^\\top \\mu_y + b$。\n我们将类别均值之间的 Mahalanobis 距离的平方定义为 $\\Delta^2 = (\\mu_{+} - \\mu_{-})^\\top \\Sigma^{-1} (\\mu_{+} - \\mu_{-})$。\n对于 $y=+1$ 的均值为：\n$$ \\mathbb{E}[s(x) \\mid y=+1] = w^\\top \\mu_{+} + b = (\\mu_{+}-\\mu_{-})^\\top \\Sigma^{-1} \\mu_{+} - \\frac{1}{2}(\\mu_{+}^\\top\\Sigma^{-1}\\mu_{+} - \\mu_{-}^\\top\\Sigma^{-1}\\mu_{-}) $$\n$$ = \\frac{1}{2}(\\mu_{+}^\\top\\Sigma^{-1}\\mu_{+} - 2\\mu_{+}^\\top\\Sigma^{-1}\\mu_{-} + \\mu_{-}^\\top\\Sigma^{-1}\\mu_{-}) = \\frac{1}{2}(\\mu_{+}-\\mu_{-})^\\top\\Sigma^{-1}(\\mu_{+}-\\mu_{-}) = \\frac{1}{2}\\Delta^2 $$\n类似地，对于 $y=-1$：\n$$ \\mathbb{E}[s(x) \\mid y=-1] = w^\\top \\mu_{-} + b = -\\frac{1}{2}\\Delta^2 $$\n我们可以将其紧凑地写为 $\\eta_y = \\mathbb{E}[s(x) \\mid y] = y \\frac{\\Delta^2}{2}$。\n\n给定 $y$ 时 $s(x)$ 的方差与 $x$ 的均值无关：\n$$ \\text{Var}[s(x) \\mid y] = \\text{Var}[w^\\top x \\mid y] = w^\\top \\text{Cov}(x \\mid y) w = w^\\top \\Sigma w $$\n$$ = ((\\mu_{+}-\\mu_{-})^\\top \\Sigma^{-1}) \\Sigma (\\Sigma^{-1}(\\mu_{+}-\\mu_{-})) = (\\mu_{+}-\\mu_{-})^\\top \\Sigma^{-1} (\\mu_{+}-\\mu_{-}) = \\Delta^2 $$\n所以，对于一个已知的标签 $y$，真实 logit 的分布是 $s(x) \\mid y \\sim \\mathcal{N}(y \\frac{\\Delta^2}{2}, \\Delta^2)$。\n\n现在我们可以写出在两种假设下观测到的 logit $r$ 的分布：\n-   $H_0$: $r = s(x) \\sim \\mathcal{N}\\left(y \\frac{\\Delta^2}{2}, \\Delta^2\\right)$\n-   $H_1$: $r = s(x) + \\beta \\sim \\mathcal{N}\\left(y \\frac{\\Delta^2}{2} + \\beta, \\Delta^2\\right)$\n\n似然函数是高斯概率密度函数：\n$$ p(r \\mid H_0) = \\frac{1}{\\sqrt{2\\pi\\Delta^2}} \\exp\\left(-\\frac{(r - y\\frac{\\Delta^2}{2})^2}{2\\Delta^2}\\right) $$\n$$ p(r \\mid H_1) = \\frac{1}{\\sqrt{2\\pi\\Delta^2}} \\exp\\left(-\\frac{(r - (y\\frac{\\Delta^2}{2} + \\beta))^2}{2\\Delta^2}\\right) $$\n决策规则 $p(r \\mid H_1)  p(r \\mid H_0)$ 变为：\n$$ \\exp\\left(-\\frac{(r - y\\frac{\\Delta^2}{2} - \\beta)^2}{2\\Delta^2}\\right)  \\exp\\left(-\\frac{(r - y\\frac{\\Delta^2}{2})^2}{2\\Delta^2}\\right) $$\n对两边取自然对数：\n$$ -\\frac{(r - y\\frac{\\Delta^2}{2} - \\beta)^2}{2\\Delta^2}  -\\frac{(r - y\\frac{\\Delta^2}{2})^2}{2\\Delta^2} $$\n两边乘以 $-2\\Delta^2$（并翻转不等号）：\n$$ (r - y\\frac{\\Delta^2}{2} - \\beta)^2  (r - y\\frac{\\Delta^2}{2})^2 $$\n这个不等式成立的充要条件是 $r$ 比起 $H_0$ 下的均值 $y\\frac{\\Delta^2}{2}$ 更接近 $H_1$ 下的均值 $y\\frac{\\Delta^2}{2} + \\beta$。决策阈值是这两个均值的中点：\n$$ t^* = \\frac{(y\\frac{\\Delta^2}{2}) + (y\\frac{\\Delta^2}{2} + \\beta)}{2} = y\\frac{\\Delta^2}{2} + \\frac{\\beta}{2} $$\n如果观测到的 logit $r$ 满足 $r  t^*$，攻击者就判定为‘成员’。\n\n问题要求将阈值转换到概率域：\n$$ t_p^* = \\sigma(t^*) = \\sigma\\left(y\\frac{\\Delta^2}{2} + \\frac{\\beta}{2}\\right) $$\n\n### 数值评估\n我们给定的参数是：\n-   $\\mu_{+} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix}$，$\\mu_{-} = \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix}$\n-   $\\Sigma = I_2 = \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix}$，所以 $\\Sigma^{-1} = I_2$\n-   $\\beta = 0.8$\n-   真实标签 $y=+1$\n\n首先，我们计算 $\\Delta^2$：\n$$ \\mu_{+} - \\mu_{-} = \\begin{pmatrix}1 \\\\ 0\\end{pmatrix} - \\begin{pmatrix}-1 \\\\ 0\\end{pmatrix} = \\begin{pmatrix}2 \\\\ 0\\end{pmatrix} $$\n$$ \\Delta^2 = (\\mu_{+} - \\mu_{-})^\\top \\Sigma^{-1} (\\mu_{+} - \\mu_{-}) = \\begin{pmatrix}2  0\\end{pmatrix} \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix} \\begin{pmatrix}2 \\\\ 0\\end{pmatrix} = 4 $$\n接下来，我们计算 $y=+1$ 时的 logit 阈值 $t^*$：\n$$ t^* = (+1) \\cdot \\frac{4}{2} + \\frac{0.8}{2} = 2 + 0.4 = 2.4 $$\n对于攻击者而言，最优决策规则是：如果观测到的 logit $r$ 大于 $2.4$，则推断为‘成员’。\n\n最后，我们将此阈值转换到概率域：\n$$ t_p^* = \\sigma(2.4) = \\frac{1}{1 + \\exp(-2.4)} $$\n$$ t_p^* \\approx \\frac{1}{1 + 0.09071795} \\approx \\frac{1}{1.09071795} \\approx 0.916830005 $$\n四舍五入到四位有效数字，我们得到 $t_p^* \\approx 0.9168$。\n\n### 经验验证\n作为一致性检验，我们将推导出的规则应用于所提供的数据。真实 logit 是 $s(x) = w^\\top x + b$。使用给定参数，$w = \\Sigma^{-1}(\\mu_+ - \\mu_-) = \\begin{pmatrix}2 \\\\ 0\\end{pmatrix}$ 且 $b = 0$。所以，$s(x) = 2x_1$。观测到的 logit 是 $r = s(x) + b_M = 2x_1 + b_M$。\n对于给定的点（所有点的 $y=+1$），决策规则是：如果 $r  2.4$ 则预测为‘成员’。\n\n1.  $x^{(1)} = (1.1, -0.2)$，$M=\\text{member} \\implies b_M=0.8$。$r_1=2(1.1)+0.8=3.0$。$3.0  2.4 \\implies$ 预测为‘成员’。（正确）\n2.  $x^{(2)} = (0.8, 0.3)$，$M=\\text{member} \\implies b_M=0.8$。$r_2=2(0.8)+0.8=2.4$。$2.4 \\ngtr 2.4 \\implies$ 预测为‘非成员’。（错误）\n3.  $x^{(3)} = (1.2, -0.1)$，$M=\\text{member} \\implies b_M=0.8$。$r_3=2(1.2)+0.8=3.2$。$3.2  2.4 \\implies$ 预测为‘成员’。（正确）\n4.  $x^{(4)} = (0.6, -0.4)$，$M=\\text{non-member} \\implies b_M=0$。$r_4=2(0.6)+0=1.2$。$1.2 \\ngtr 2.4 \\implies$ 预测为‘非成员’。（正确）\n5.  $x^{(5)} = (1.1, 0.2)$，$M=\\text{non-member} \\implies b_M=0$。$r_5=2(1.1)+0=2.2$。$2.2 \\ngtr 2.4 \\implies$ 预测为‘非成员’。（正确）\n6.  $x^{(6)} = (0.7, 0.0)$，$M=\\text{non-member} \\implies b_M=0$。$r_6=2(0.7)+0=1.4$。$1.4 \\ngtr 2.4 \\implies$ 预测为‘非成员’。（正确）\n\n攻击在 $6$ 次预测中作出了 $5$ 次正确预测，经验准确率为 $\\frac{5}{6}$。唯一的错误发生在决策边界上，这是预料之中的，并且不会使推导出的最优阈值无效。", "answer": "$$\\boxed{0.9168}$$", "id": "3149406"}, {"introduction": "在现实世界中，我们通常无法得到关于模型信息泄露的完美生成模型。一种更实用的方法是，将多个与成员身份相关的直观信号组合成一个综合风险评分。本练习将演示如何利用模型置信度、预测熵和梯度范数等常见启发式指标来构建这样一个评分，并使用标准的ROC AUC指标来验证其有效性 [@problem_id:3149361]。这项动手任务模拟了在实践中许多先进攻击的设计与评估方式。", "problem": "给定一个多分类分类器，其参数为每个输入实例隐式地定义了一个条件类别概率分布。对于一个输入向量 $x$，其原始 logits 为 $z(x) \\in \\mathbb{R}^C$，预测分布由 softmax 函数给出，该函数通过 $p_\\theta(k \\mid x) = \\exp(z_k(x)) \\big/ \\sum_{j=1}^C \\exp(z_j(x))$ 将 logits 映射为概率。考虑从 $p_\\theta(\\cdot \\mid x)$ 和作为输入的每个实例的梯度范数派生出的三个信号：前两大概率差值（margin）、置信度熵和归一化梯度范数。您的任务是定义一个组合了这些信号的复合隐私风险评分 $r(x)$，并通过计算使用 $r(x)$ 作为成员分数的基于阈值的成员推断攻击的受试者工作特征曲线下面积（ROC AUC）来验证其作为成员推断脆弱性预测指标的有效性。\n\n推导的基本依据：\n- Softmax 定义 $p_\\theta(k \\mid x) = \\exp(z_k(x)) \\big/ \\sum_{j=1}^C \\exp(z_j(x))$。\n- 以自然单位（奈特）计的香农熵：$H(p) = -\\sum_{k=1}^C p_k \\log p_k$。\n- 归一化熵 $H_{\\mathrm{norm}}(p) = H(p) / \\log C$，其值在 $[0,1]$ 区间内。\n- 前两大概率差值 (margin) $m(x) = p_{(1)}(x) - p_{(2)}(x)$，其中 $p_{(1)}(x) \\ge p_{(2)}(x)$ 是 $p_\\theta(\\cdot \\mid x)$ 的最大和第二大项；因此 $m(x) \\in [0,1]$。\n- 关于模型参数的每个实例的梯度范数 $g(x) \\ge 0$ 作为输入给定。通过最小-最大值变换在每个测试用例内对其进行归一化：如果 $g_{\\max} = g_{\\min}$，则 $g_{\\mathrm{norm}}(x) = 0$，否则 $g_{\\mathrm{norm}}(x) = \\big(g(x) - g_{\\min}\\big) \\big/ \\big(g_{\\max} - g_{\\min}\\big)$。\n\n将隐私风险评分定义为非负加权组合\n$$\nr(x) = \\alpha \\cdot \\big(1 - m(x)\\big) + \\beta \\cdot H_{\\mathrm{norm}}\\!\\big(p_\\theta(\\cdot \\mid x)\\big) + \\gamma \\cdot g_{\\mathrm{norm}}(x),\n$$\n其中 $\\alpha, \\beta, \\gamma \\ge 0$ 是在测试用例中提供的固定权重。直观上，较大的 $r(x)$ 表示更高的成员推断脆弱性，因为小差值、高熵和大的梯度范数都与较低的置信度和潜在的过拟合行为相关。\n\n验证协议：\n- 给定标签 $y_{\\mathrm{mem}}(x) \\in \\{0,1\\}$，其指示非成员（$0$）或成员（$1$）状态，将 $r(x)$ 作为预测指标进行验证，方法是计算使用 $r(x)$ 作为成员分数的受试者工作特征（ROC）曲线下面积（AUC），其中较高的 $r(x)$ 意味着是成员的可能性更高。使用 ROC AUC 与 Mann–Whitney $U$ 统计量之间的等价关系：如果 $n_1$ 是成员数量，$n_0$ 是非成员数量，并且如果 $\\mathrm{rank}(r_i)$ 是所有实例分数的平均排名（从最小分数的排名 $1$ 开始），并对平局情况进行适当的平均处理，那么\n$$\n\\mathrm{AUC} = \\frac{U}{n_0 n_1}, \\quad \\text{其中} \\quad U = \\sum_{i:\\, y_{\\mathrm{mem},i} = 1} \\mathrm{rank}(r_i) - \\frac{n_1 (n_1 + 1)}{2}。\n$$\n这将得到 $\\mathrm{AUC} \\in [0,1]$，其中 $\\mathrm{AUC} = 0.5$ 表示随机水平的区分能力。\n\n实现要求：\n- 对于下面的每个测试用例，从 logits 通过 softmax 计算概率，然后使用提供的 $\\alpha$、$\\beta$ 和 $\\gamma$ 计算 $m(x)$、$H_{\\mathrm{norm}}(p)$、$g_{\\mathrm{norm}}(x)$ 和 $r(x)$。\n- 使用基于排名的公式计算 ROC AUC，对平局情况使用平均排名，并将较高的 $r(x)$ 视为较高的成员可能性。\n- 您的程序应生成单行输出，其中包含所有测试用例的 AUC 结果，格式为方括号括起来的逗号分隔列表，每个 AUC 值四舍五入到六位小数，例如 $[0.945000,0.731234,0.500000]$。\n\n测试套件：\n- 测试用例 1（清晰分离，三分类）：\n  - 类别数 $C = 3$。\n  - 权重：$\\alpha = 0.5$, $\\beta = 0.3$, $\\gamma = 0.2$。\n  - 六个样本，包含 logits、梯度范数和成员标签：\n    1. Logits $[3.0, 0.2, -1.0]$，梯度范数 $0.10$，$y_{\\mathrm{mem}} = 0$。\n    2. Logits $[2.5, -0.5, 0.0]$，梯度范数 $0.15$，$y_{\\mathrm{mem}} = 0$。\n    3. Logits $[-1.0, 0.0, 3.0]$，梯度范数 $0.05$，$y_{\\mathrm{mem}} = 0$。\n    4. Logits $[0.5, 0.4, 0.3]$，梯度范数 $0.90$，$y_{\\mathrm{mem}} = 1$。\n    5. Logits $[0.0, 0.1, 0.2]$，梯度范数 $0.70$，$y_{\\mathrm{mem}} = 1$。\n    6. Logits $[0.2, 0.1, 0.2]$，梯度范数 $1.20$，$y_{\\mathrm{mem}} = 1$。\n- 测试用例 2（存在重叠，三分类）：\n  - 类别数 $C = 3$。\n  - 权重：$\\alpha = 0.5$, $\\beta = 0.3$, $\\gamma = 0.2$。\n  - 六个样本，包含 logits、梯度范数和成员标签：\n    1. Logits $[1.5, 1.4, 1.3]$，梯度范数 $0.60$，$y_{\\mathrm{mem}} = 0$。\n    2. Logits $[2.0, 0.0, 0.0]$，梯度范数 $0.40$，$y_{\\mathrm{mem}} = 0$。\n    3. Logits $[0.5, -0.2, 1.0]$，梯度范数 $0.55$，$y_{\\mathrm{mem}} = 0$。\n    4. Logits $[0.8, 0.7, 0.1]$，梯度范数 $0.50$，$y_{\\mathrm{mem}} = 1$。\n    5. Logits $[1.8, 0.9, 0.7]$，梯度范数 $0.45$，$y_{\\mathrm{mem}} = 1$。\n    6. Logits $[0.2, 0.2, 0.2]$，梯度范数 $0.65$，$y_{\\mathrm{mem}} = 1$。\n- 测试用例 3（有平局的边界条件）：\n  - 类别数 $C = 3$。\n  - 权重：$\\alpha = 0.5$, $\\beta = 0.3$, $\\gamma = 0.2$。\n  - 四个具有相同 logits 和梯度范数的样本，导致风险评分相同：\n    1. Logits $[0.0, 0.0, 0.0]$，梯度范数 $0.30$，$y_{\\mathrm{mem}} = 1$。\n    2. Logits $[0.0, 0.0, 0.0]$，梯度范数 $0.30$，$y_{\\mathrm{mem}} = 0$。\n    3. Logits $[0.0, 0.0, 0.0]$，梯度范数 $0.30$，$y_{\\mathrm{mem}} = 1$。\n    4. Logits $[0.0, 0.0, 0.0]$，梯度范数 $0.30$，$y_{\\mathrm{mem}} = 0$。\n\n您的程序必须实现上述定义，并输出包含三个 ROC AUC 值的单行，格式为 $[a_1,a_2,a_3]$，其中每个 $a_i$ 是一个四舍五入到六位小数的浮点数。", "solution": "用户提供的问题陈述已经过严格验证，被认为是**有效的**。它在机器学习隐私领域具有科学依据，问题定义明确、客观且自包含。所有定义、常数和数据都已提供，从而可以得到唯一且可验证的解。\n\n该问题要求实现并验证一个隐私风险评分 $r(x)$，该评分旨在量化数据实例 $x$ 对成员推断攻击的脆弱性。对于每个给定的测试用例，解决方案涉及一个多步骤过程。我们将系统地推导计算受试者工作特征曲线下面积（ROC AUC）所需的量，该面积用作风险评分的验证指标。\n\n**步骤 1：计算概率分布**\n\n对于每个数据实例，我们都给出了一个来自 $C$ 类分类器的原始 logits 向量 $z(x) \\in \\mathbb{R}^C$。相应的预测概率分布 $p_\\theta(\\cdot \\mid x)$ 是通过 softmax 函数获得的：\n$$\np_\\theta(k \\mid x) = \\frac{\\exp(z_k(x))}{\\sum_{j=1}^C \\exp(z_j(x))}.\n$$\n为确保在 logit 值较大时数值稳定性以防止潜在的上溢或下溢，我们使用恒等式 $p_\\theta(k \\mid x) = \\frac{\\exp(z_k(x) - z_{\\max})}{\\sum_{j=1}^C \\exp(z_j(x) - z_{\\max})}$，其中 $z_{\\max} = \\max_j z_j(x)$。\n\n**步骤 2：计算各实例的信号分量**\n\n隐私风险评分 $r(x)$ 是三个信号的复合。对于每个实例 $x$，我们计算：\n\n1.  **前两大概率差值, $m(x)$**：该信号衡量模型对其最高预测的置信度。较小的差值表示模糊性。令 $p_{(1)}(x)$ 和 $p_{(2)}(x)$ 为分布 $p_\\theta(\\cdot \\mid x)$ 中的最大和第二大概率。该差值为：\n    $$\n    m(x) = p_{(1)}(x) - p_{(2)}(x).\n    $$\n    风险评分中使用的项是 $1 - m(x)$，对于置信度较低的预测，该值更大。\n\n2.  **归一化置信度熵, $H_{\\mathrm{norm}}(p)$**：该信号衡量预测分布的不确定性。熵越高意味着不确定性越大。香Shannon熵以自然单位（奈特）计算：\n    $$\n    H(p) = -\\sum_{k=1}^C p_k \\log p_k,\n    $$\n    其中 $p_k = p_\\theta(k \\mid x)$ 并且我们定义 $0 \\log 0 = 0$。然后将此熵通过除以 $C$ 类分布的最大可能熵 $\\log C$ 来归一化到 $[0, 1]$ 范围：\n    $$\n    H_{\\mathrm{norm}}(p) = \\frac{H(p)}{\\log C}.\n    $$\n\n3.  **归一化梯度范数, $g_{\\mathrm{norm}}(x)$**：对于每个实例，都提供了一个初始梯度范数 $g(x)$。该值在单个测试用例的所有实例中使用最小-最大值缩放进行归一化。设 $\\{g_i\\}_{i=1}^N$ 是一个包含 $N$ 个样本的测试用例的梯度范数集合。令 $g_{\\min} = \\min_i g_i$ 和 $g_{\\max} = \\max_i g_i$。实例 $i$ 的归一化范数为：\n    $$\n    g_{\\mathrm{norm}}(x_i) = \\begin{cases}\n    0  \\text{if } g_{\\max} = g_{\\min} \\\\\n    \\frac{g(x_i) - g_{\\min}}{g_{\\max} - g_{\\min}}  \\text{otherwise}\n    \\end{cases}.\n    $$\n    这将每个测试用例的梯度范数置于 $[0, 1]$ 的公共尺度上。\n\n**步骤 3：计算复合隐私风险评分 $r(x)$**\n\n这三个信号通过加权求和组合成一个单一的风险评分 $r(x)$，其中非负权重 $\\alpha, \\beta, \\gamma$ 在每个测试用例中提供：\n$$\nr(x) = \\alpha \\cdot \\big(1 - m(x)\\big) + \\beta \\cdot H_{\\mathrm{norm}}\\!\\big(p_\\theta(\\cdot \\mid x)\\big) + \\gamma \\cdot g_{\\mathrm{norm}}(x).\n$$\n较高的评分 $r(x)$ 被假设为表示 $x$ 属于训练集（一个“成员”）的可能性更大，这对应于更高的成员推断脆弱性。\n\n**步骤 4：使用 ROC AUC 进行验证**\n\n$r(x)$ 作为成员分数的有效性通过计算 ROC AUC 来评估。该指标量化了分数区分成员（$y_{\\mathrm{mem}}=1$）和非成员（$y_{\\mathrm{mem}}=0$）的能力。我们使用基于排名的 AUC 公式，该公式等价于用各类样本数量的乘积进行归一化的 Mann-Whitney $U$ 统计量。\n\n设 $\\{r_i\\}_{i=1}^N$ 是一个测试用例中所有 $N$ 个实例的风险评分集合。\n1.  **排名**：我们首先在所有分数的组合列表中计算每个分数 $r_i$ 的排名。排名从 $1$ 开始。如果出现平局，所有平局的分数都将获得它们本应占据的排名的平均值。例如，如果两个分数并列第 2 和第 3 位，则它们都获得排名 $(2+3)/2 = 2.5$。\n2.  **U 统计量**：设 $n_1$ 为成员数量，$n_0$ 为非成员数量。Mann-Whitney $U$ 统计量的计算方法是：将成员实例对应分数的排名相加，然后减去一个修正项：\n    $$\n    U = \\sum_{i:\\, y_{\\mathrm{mem},i} = 1} \\mathrm{rank}(r_i) - \\frac{n_1 (n_1 + 1)}{2}.\n    $$\n3.  **AUC 计算**：AUC 接着由以下公式给出：\n    $$\n    \\mathrm{AUC} = \\frac{U}{n_0 n_1}.\n    $$\n该值范围从 $0$ 到 $1$，其中 $1.0$ 表示完美分离（所有成员的得分都高于所有非成员），$0.5$ 表示性能不优于随机猜测，而 $0.0$ 表示完美的反向分离。\n\n将此完整过程应用于三个测试用例中的每一个，以得出最终的 AUC 值列表。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the ROC AUC for a membership inference attack based on a composite privacy risk score.\n    \"\"\"\n    test_cases = [\n        {\n            \"C\": 3,\n            \"weights\": (0.5, 0.3, 0.2),  # alpha, beta, gamma\n            \"samples\": [\n                {\"logits\": [3.0, 0.2, -1.0], \"grad_norm\": 0.10, \"y_mem\": 0},\n                {\"logits\": [2.5, -0.5, 0.0], \"grad_norm\": 0.15, \"y_mem\": 0},\n                {\"logits\": [-1.0, 0.0, 3.0], \"grad_norm\": 0.05, \"y_mem\": 0},\n                {\"logits\": [0.5, 0.4, 0.3], \"grad_norm\": 0.90, \"y_mem\": 1},\n                {\"logits\": [0.0, 0.1, 0.2], \"grad_norm\": 0.70, \"y_mem\": 1},\n                {\"logits\": [0.2, 0.1, 0.2], \"grad_norm\": 1.20, \"y_mem\": 1},\n            ]\n        },\n        {\n            \"C\": 3,\n            \"weights\": (0.5, 0.3, 0.2),\n            \"samples\": [\n                {\"logits\": [1.5, 1.4, 1.3], \"grad_norm\": 0.60, \"y_mem\": 0},\n                {\"logits\": [2.0, 0.0, 0.0], \"grad_norm\": 0.40, \"y_mem\": 0},\n                {\"logits\": [0.5, -0.2, 1.0], \"grad_norm\": 0.55, \"y_mem\": 0},\n                {\"logits\": [0.8, 0.7, 0.1], \"grad_norm\": 0.50, \"y_mem\": 1},\n                {\"logits\": [1.8, 0.9, 0.7], \"grad_norm\": 0.45, \"y_mem\": 1},\n                {\"logits\": [0.2, 0.2, 0.2], \"grad_norm\": 0.65, \"y_mem\": 1},\n            ]\n        },\n        {\n            \"C\": 3,\n            \"weights\": (0.5, 0.3, 0.2),\n            \"samples\": [\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 1},\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 0},\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 1},\n                {\"logits\": [0.0, 0.0, 0.0], \"grad_norm\": 0.30, \"y_mem\": 0},\n            ]\n        }\n    ]\n\n    def rankdata(data):\n        \"\"\"\n        Assigns ranks to data, dealing with ties by averaging. Ranks are 1-based.\n        Equivalent to scipy.stats.rankdata(method='average').\n        \"\"\"\n        n = len(data)\n        indexed_data = sorted([(data[i], i) for i in range(n)])\n        \n        ranks = [0.0] * n\n        i = 0\n        while i  n:\n            j = i\n            while j  n - 1 and indexed_data[j][0] == indexed_data[j+1][0]:\n                j += 1\n            \n            # Indices of tied items in the sorted list are from i to j.\n            # Ranks are 1-based, so they would occupy ranks from i+1 to j+1.\n            sum_ranks = sum(range(i + 1, j + 2))\n            avg_rank = sum_ranks / (j - i + 1)\n            \n            for k in range(i, j + 1):\n                original_index = indexed_data[k][1]\n                ranks[original_index] = avg_rank\n            \n            i = j + 1\n            \n        return ranks\n\n    all_results = []\n    for case in test_cases:\n        C = case[\"C\"]\n        alpha, beta, gamma = case[\"weights\"]\n        samples = case[\"samples\"]\n        \n        # Lists to store intermediate computed values for each sample\n        margins = []\n        norm_entropies = []\n        raw_grad_norms = []\n        labels = []\n\n        log_C = np.log(C)\n\n        for sample in samples:\n            logits = np.array(sample[\"logits\"])\n            \n            # 1. Compute probabilities using stable softmax\n            z_stable = logits - np.max(logits)\n            p = np.exp(z_stable) / np.sum(np.exp(z_stable))\n            \n            # 2. Compute margin\n            p_sorted = np.sort(p)[::-1]\n            margin = p_sorted[0] - p_sorted[1] if len(p_sorted) > 1 else p_sorted[0]\n            margins.append(margin)\n            \n            # 3. Compute normalized entropy\n            # Take log only of non-zero probabilities to avoid -inf from log(0)\n            non_zero_p = p[p > 0]\n            entropy = -np.sum(non_zero_p * np.log(non_zero_p))\n            norm_entropy = entropy / log_C\n            norm_entropies.append(norm_entropy)\n            \n            raw_grad_norms.append(sample[\"grad_norm\"])\n            labels.append(sample[\"y_mem\"])\n\n        # 4. Normalize gradient norms for the entire test case\n        g = np.array(raw_grad_norms)\n        g_min, g_max = np.min(g), np.max(g)\n        if g_max == g_min:\n            g_norm = np.zeros_like(g, dtype=float)\n        else:\n            g_norm = (g - g_min) / (g_max - g_min)\n\n        # 5. Compute the final risk score for each sample\n        risk_scores = [\n            alpha * (1 - m) + beta * h_norm + gamma * gn\n            for m, h_norm, gn in zip(margins, norm_entropies, g_norm)\n        ]\n        \n        # 6. Compute ROC AUC using the Mann-Whitney U statistic\n        n0 = labels.count(0)\n        n1 = labels.count(1)\n        \n        if n0 == 0 or n1 == 0:\n            # Although test cases prevent this, handle the edge case.\n            # AUC is typically defined as 0.5 if one class is missing.\n            auc = 0.5  \n        else:\n            ranks = rankdata(risk_scores)\n            sum_ranks_members = sum(ranks[i] for i, label in enumerate(labels) if label == 1)\n            \n            U = sum_ranks_members - (n1 * (n1 + 1) / 2.0)\n            auc = U / (float(n0) * float(n1))\n            \n        all_results.append(auc)\n\n    print(f\"[{','.join(f'{r:.6f}' for r in all_results)}]\")\n\nsolve()\n```", "id": "3149361"}, {"introduction": "隐私攻击的有效性并非唯一重要的衡量标准；其影响在不同个体或数据群体之间可能并不均等。本练习深入探讨了成员推断攻击中至关重要的公平性概念，揭示了单一攻击阈值如何对代表性不足的类别造成不成比例的伤害。你将探索如何设计一个“更公平”的攻击，以均衡不同类别间的误报率，从而突显攻击效能与平等隐私保护之间的关键权衡 [@problem_id:3149384]。", "problem": "考虑一个分类场景中的二元成员推断决策规则，其中攻击者观察到输入 $x$ 在其类别标签 $y \\in \\{0,1,\\dots,K-1\\}$ 条件下的一个标量分数 $S$，如果 $S$ 超过一个阈值，则判定为“成员”。对于每个类别 $y$，假设在给定成员身份 $M \\in \\{0,1\\}$ 的情况下，攻击者的分数 $S$ 服从一个按类别条件的高斯（正态）分布：\n- 对于非成员（$M=0$），$S \\mid (y, M=0) \\sim \\mathcal{N}(\\mu_{0,y}, \\sigma_{0,y}^2)$。\n- 对于成员（$M=1$），$S \\mid (y, M=1) \\sim \\mathcal{N}(\\mu_{1,y}, \\sigma_{1,y}^2)$。\n\n令 $p(y)$ 表示类别先验概率，满足 $\\sum_{y=0}^{K-1} p(y) = 1$。使用单一全局阈值 $t$ 的基于阈值的攻击者在 $S  t$ 时声明为“成员”。逐类攻击者使用依赖于 $y$ 的阈值 $t_y$，并在 $S  t_y$ 时声明为“成员”。定义：\n- 类别 $y$ 在阈值 $\\tau$ 下的假阳性率（FPR）定义为 $\\mathrm{FPR}_y(\\tau) = \\mathbb{P}(S  \\tau \\mid y, M=0)$。\n- 类别 $y$ 在阈值 $\\tau$ 下的真阳性率（TPR）定义为 $\\mathrm{TPR}_y(\\tau) = \\mathbb{P}(S  \\tau \\mid y, M=1)$。\n- 全局阈值 $t$ 下的总体FPR定义为 $\\mathrm{FPR}_{\\mathrm{overall}}(t) = \\sum_{y=0}^{K-1} p(y)\\,\\mathrm{FPR}_y(t)$，类似地，总体TPR定义为 $\\mathrm{TPR}_{\\mathrm{overall}}(t) = \\sum_{y=0}^{K-1} p(y)\\,\\mathrm{TPR}_y(t)$。\n\n假设指定了一个以小数形式表示的目标假阳性率水平 $q \\in (0,1)$。类别不平衡 $p(y)$ 对阈值选择的影响可能导致单一全局阈值引起不相等的逐类假阳性率。在此背景下，“公平”攻击者被定义为能够使各类别间的假阳性率相等的攻击者，即对每个类别 $y$ 强制执行 $\\mathrm{FPR}_y(t_y) = q$。\n\n任务：\n- 实现两种攻击者：\n  1. 全局阈值攻击者，选择 $t$ 以满足 $\\mathrm{FPR}_{\\mathrm{overall}}(t) = q$。\n  2. 公平的逐类攻击者，设置 $t_y$ 以满足每个类别 $y$ 的 $\\mathrm{FPR}_y(t_y) = q$。\n- 对每种攻击者，计算：\n  - 总体优势 $\\mathrm{Adv} = \\mathrm{TPR}_{\\mathrm{overall}} - \\mathrm{FPR}_{\\mathrm{overall}}$。\n  - 公平性违规度量 $\\Delta_{\\mathrm{FPR}} = \\max_y \\mathrm{FPR}_y - \\min_y \\mathrm{FPR}_y$。\n\n你的程序必须：\n- 使用正态累积分布函数精确计算尾部概率（而不是通过采样）。\n- 对于全局阈值攻击者，通过一种在高斯混合模型下保证收敛的数值方法求解 $t$，并报告找到的阈值。\n- 对于逐类攻击者，计算在高斯模型下能使类别假阳性率精确等于 $q$ 的阈值 $t_y$。\n\n测试套件：\n使用以下五个案例（所有列表均按类别索引 $y=0,1,2$ 排序）：\n1. 案例 A（平衡）：\n   - $K = 3$\n   - $p(y) = [0.3333333333, 0.3333333333, 0.3333333333]$\n   - $\\mu_{0} = [0.4, 0.5, 0.45]$\n   - $\\sigma_{0} = [0.1, 0.1, 0.1]$\n   - $\\mu_{1} = [0.8, 0.85, 0.75]$\n   - $\\sigma_{1} = [0.1, 0.1, 0.1]$\n   - $q = 0.1$\n2. 案例 B（中度不平衡）：\n   - $K = 3$\n   - $p(y) = [0.7, 0.2, 0.1]$\n   - $\\mu_{0} = [0.4, 0.5, 0.45]$\n   - $\\sigma_{0} = [0.1, 0.1, 0.1]$\n   - $\\mu_{1} = [0.8, 0.85, 0.75]$\n   - $\\sigma_{1} = [0.1, 0.1, 0.1]$\n   - $q = 0.1$\n3. 案例 C（极端不平衡和异构方差）：\n   - $K = 3$\n   - $p(y) = [0.95, 0.04, 0.01]$\n   - $\\mu_{0} = [0.45, 0.5, 0.6]$\n   - $\\sigma_{0} = [0.12, 0.08, 0.15]$\n   - $\\mu_{1} = [0.8, 0.85, 0.7]$\n   - $\\sigma_{1} = [0.1, 0.1, 0.12]$\n   - $q = 0.05$\n4. 案例 D（成员和非成员之间的高度重叠）：\n   - $K = 3$\n   - $p(y) = [0.5, 0.3, 0.2]$\n   - $\\mu_{0} = [0.5, 0.52, 0.48]$\n   - $\\sigma_{0} = [0.15, 0.15, 0.15]$\n   - $\\mu_{1} = [0.6, 0.62, 0.58]$\n   - $\\sigma_{1} = [0.15, 0.15, 0.15]$\n   - $q = 0.2$\n5. 案例 E（异构分布和倾斜先验）：\n   - $K = 3$\n   - $p(y) = [0.2, 0.3, 0.5]$\n   - $\\mu_{0} = [0.49, 0.49, 0.49]$\n   - $\\sigma_{0} = [0.05, 0.01, 0.2]$\n   - $\\mu_{1} = [0.9, 0.9, 0.9]$\n   - $\\sigma_{1} = [0.05, 0.05, 0.05]$\n   - $q = 0.1$\n\n输出规范：\n- 对于每个测试案例，返回一个包含五个小数值的列表（四舍五入到 $4$ 位小数）：\n  - $[\\mathrm{Adv}_{\\mathrm{global}}, \\mathrm{Adv}_{\\mathrm{fair}}, \\Delta_{\\mathrm{FPR}}^{\\mathrm{global}}, \\Delta_{\\mathrm{FPR}}^{\\mathrm{fair}}, t_{\\mathrm{global}}]$。\n- 你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个元素对应一个测试案例。例如，最终输出必须类似于 $[[a_1],[a_2],[a_3],[a_4],[a_5]]$，其中包含数值条目，所有数值均四舍五入到 $4$ 位小数，且不含任何额外文本。", "solution": "用户提供的问题是有效的，因为它具有科学依据、问题明确、客观，并包含推导出唯一解所需的所有必要信息。任务是基于两种成员推断攻击者——全局阈值攻击者和公平的逐类攻击者——的性能（优势）和公平性（FPR差异）对其进行分析和比较。该分析在一个模型下进行，其中攻击者的分数来自按类别条件的高斯分布。\n\n### 数学公式\n令 $\\Phi(z)$ 代表标准正态分布 $\\mathcal{N}(0, 1)$ 的累积分布函数（CDF），其互补累积分布函数（或生存函数）为 $1-\\Phi(z)$。\n\n具有类别标签 $y$ 和成员身份 $M \\in \\{0, 1\\}$ 的输入的分数 $S$ 服从正态分布：\n- 对于非成员（$M=0$）：$S \\mid (y, M=0) \\sim \\mathcal{N}(\\mu_{0,y}, \\sigma_{0,y}^2)$。\n- 对于成员（$M=1$）：$S \\mid (y, M=1) \\sim \\mathcal{N}(\\mu_{1,y}, \\sigma_{1,y}^2)$。\n\n如果分数 $S$ 超过阈值 $\\tau$，攻击者判定为“成员”。\n\n逐类假阳性率（FPR）和真阳性率（TPR）分别是此事件对非成员和成员发生的概率：\n- $\\mathrm{FPR}_y(\\tau) = \\mathbb{P}(S  \\tau \\mid y, M=0) = \\mathbb{P}\\left(\\frac{S - \\mu_{0,y}}{\\sigma_{0,y}}  \\frac{\\tau - \\mu_{0,y}}{\\sigma_{0,y}}\\right) = 1 - \\Phi\\left(\\frac{\\tau - \\mu_{0,y}}{\\sigma_{0,y}}\\right)$。\n- $\\mathrm{TPR}_y(\\tau) = \\mathbb{P}(S  \\tau \\mid y, M=1) = \\mathbb{P}\\left(\\frac{S - \\mu_{1,y}}{\\sigma_{1,y}}  \\frac{\\tau - \\mu_{1,y}}{\\sigma_{1,y}}\\right) = 1 - \\Phi\\left(\\frac{\\tau - \\mu_{1,y}}{\\sigma_{1,y}}\\right)$。\n\n总体比率是通过对所有类别进行加权平均计算得出的，权重为类别先验概率 $p(y)$：\n- $\\mathrm{FPR}_{\\mathrm{overall}}(\\tau) = \\sum_{y=0}^{K-1} p(y)\\,\\mathrm{FPR}_y(\\tau)$。\n- $\\mathrm{TPR}_{\\mathrm{overall}}(\\tau) = \\sum_{y=0}^{K-1} p(y)\\,\\mathrm{TPR}_y(\\tau)$。\n\n### 1. 公平的逐类攻击者\n该攻击者通过确保每个类别的假阳性率都等于目标值 $q$ 来强制实现公平性。这意味着对于每个类别 $y$，选择一个特定的阈值 $t_y$ 使得 $\\mathrm{FPR}_y(t_y) = q$。\n\n为了找到 $t_y$，我们求解方程：\n$$1 - \\Phi\\left(\\frac{t_y - \\mu_{0,y}}{\\sigma_{0,y}}\\right) = q$$\n整理这些项，我们得到：\n$$\\Phi\\left(\\frac{t_y - \\mu_{0,y}}{\\sigma_{0,y}}\\right) = 1 - q$$\n应用逆正态累积分布函数 $\\Phi^{-1}$（也称为分位数函数或百分点函数），我们得到 $t_y$ 的解析解：\n$$t_y = \\mu_{0,y} + \\sigma_{0,y} \\cdot \\Phi^{-1}(1 - q)$$\n\n在确定了逐类阈值 $t_y$ 后，我们可以计算所需的度量：\n- **总体FPR**：$\\mathrm{FPR}_{\\mathrm{overall}}^{\\mathrm{fair}} = \\sum_{y=0}^{K-1} p(y)\\,\\mathrm{FPR}_y(t_y) = \\sum_{y=0}^{K-1} p(y) \\cdot q = q \\sum_{y=0}^{K-1} p(y) = q$。\n- **总体TPR**：$\\mathrm{TPR}_{\\mathrm{overall}}^{\\mathrm{fair}} = \\sum_{y=0}^{K-1} p(y) \\cdot \\mathrm{TPR}_y(t_y)$，其中 $\\mathrm{TPR}_y(t_y)$ 使用推导出的 $t_y$ 计算。\n- **优势**：$\\mathrm{Adv}_{\\mathrm{fair}} = \\mathrm{TPR}_{\\mathrm{overall}}^{\\mathrm{fair}} - \\mathrm{FPR}_{\\mathrm{overall}}^{\\mathrm{fair}} = \\mathrm{TPR}_{\\mathrm{overall}}^{\\mathrm{fair}} - q$。\n- **公平性违规**：$\\Delta_{\\mathrm{FPR}}^{\\mathrm{fair}} = \\max_y \\mathrm{FPR}_y(t_y) - \\min_y \\mathrm{FPR}_y(t_y) = q - q = 0$。根据构造，该攻击者在FPR度量上实现了完美的公平性。\n\n### 2. 全局阈值攻击者\n该攻击者对所有类别使用单一阈值 $t_{\\mathrm{global}}$，该阈值被选择以满足总体FPR约束：\n$$\\mathrm{FPR}_{\\mathrm{overall}}(t_{\\mathrm{global}}) = \\sum_{y=0}^{K-1} p(y)\\,\\mathrm{FPR}_y(t_{\\mathrm{global}}) = q$$\n代入 $\\mathrm{FPR}_y$ 的定义，我们必须在以下方程中求解 $t$：\n$$\\left(\\sum_{y=0}^{K-1} p(y) \\left[1 - \\Phi\\left(\\frac{t - \\mu_{0,y}}{\\sigma_{0,y}}\\right)\\right]\\right) - q = 0$$\n这个方程通常没有关于 $t$ 的解析解。然而，函数 $g(t) = \\mathrm{FPR}_{\\mathrm{overall}}(t)$ 是关于 $t$ 的连续单调递减函数的和。因此，$g(t)$ 也是连续且单调递减的。其值域从 $1$（当 $t \\to -\\infty$）到 $0$（当 $t \\to +\\infty$）。由于目标 $q \\in (0, 1)$，保证存在唯一的解 $t$。\n\n这个求根问题可以使用数值方法（如**二分法**）可靠地解决。\n算法如下：\n1. 定义目标函数 $f(t) = \\mathrm{FPR}_{\\mathrm{overall}}(t) - q$。\n2. 找到一个区间 $[a, b]$，使得 $f(a)$ 和 $f(b)$ 异号。可以选择一个足够大的区间，例如，基于 $\\mu_{0,y}$ 和 $\\sigma_{0,y}$ 的最小值和最大值。\n3. 迭代地缩小区间：\n   a. 计算中点 $c = (a+b)/2$。\n   b. 如果 $f(c)$ 与 $f(a)$ 同号，则令 $a=c$；否则，令 $b=c$。\n4. 重复固定次数的迭代，或直到区间 $[a, b]$ 小于期望的容差。最终的中点即为解 $t_{\\mathrm{global}}$。\n\n一旦找到 $t_{\\mathrm{global}}$，即可计算各项度量：\n- **总体FPR**：$\\mathrm{FPR}_{\\mathrm{overall}}^{\\mathrm{global}} = q$（根据所解方程的定义）。\n- **逐类FPR**：对于每个 $y$，$\\mathrm{FPR}_y^{\\mathrm{global}} = 1 - \\Phi\\left(\\frac{t_{\\mathrm{global}} - \\mu_{0,y}}{\\sigma_{0,y}}\\right)$。\n- **公平性违规**：$\\Delta_{\\mathrm{FPR}}^{\\mathrm{global}} = \\max_y \\mathrm{FPR}_y^{\\mathrm{global}} - \\min_y \\mathrm{FPR}_y^{\\mathrm{global}}$。当类别分布不同时，该值预计为非零。\n- **总体TPR**：$\\mathrm{TPR}_{\\mathrm{overall}}^{\\mathrm{global}} = \\sum_{y=0}^{K-1} p(y) \\cdot \\mathrm{TPR}_y(t_{\\mathrm{global}})$。\n- **优势**：$\\mathrm{Adv}_{\\mathrm{global}} = \\mathrm{TPR}_{\\mathrm{overall}}^{\\mathrm{global}} - \\mathrm{FPR}_{\\mathrm{overall}}^{\\mathrm{global}} = \\mathrm{TPR}_{\\mathrm{overall}}^{\\mathrm{global}} - q$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the membership inference attacker problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A (balanced)\n        {\n            \"K\": 3,\n            \"p_y\": np.array([0.3333333333, 0.3333333333, 0.3333333333]),\n            \"mu_0\": np.array([0.4, 0.5, 0.45]),\n            \"sigma_0\": np.array([0.1, 0.1, 0.1]),\n            \"mu_1\": np.array([0.8, 0.85, 0.75]),\n            \"sigma_1\": np.array([0.1, 0.1, 0.1]),\n            \"q\": 0.1,\n        },\n        # Case B (moderate imbalance)\n        {\n            \"K\": 3,\n            \"p_y\": np.array([0.7, 0.2, 0.1]),\n            \"mu_0\": np.array([0.4, 0.5, 0.45]),\n            \"sigma_0\": np.array([0.1, 0.1, 0.1]),\n            \"mu_1\": np.array([0.8, 0.85, 0.75]),\n            \"sigma_1\": np.array([0.1, 0.1, 0.1]),\n            \"q\": 0.1,\n        },\n        # Case C (extreme imbalance and heterogeneous variances)\n        {\n            \"K\": 3,\n            \"p_y\": np.array([0.95, 0.04, 0.01]),\n            \"mu_0\": np.array([0.45, 0.5, 0.6]),\n            \"sigma_0\": np.array([0.12, 0.08, 0.15]),\n            \"mu_1\": np.array([0.8, 0.85, 0.7]),\n            \"sigma_1\": np.array([0.1, 0.1, 0.12]),\n            \"q\": 0.05,\n        },\n        # Case D (high overlap between members and non-members)\n        {\n            \"K\": 3,\n            \"p_y\": np.array([0.5, 0.3, 0.2]),\n            \"mu_0\": np.array([0.5, 0.52, 0.48]),\n            \"sigma_0\": np.array([0.15, 0.15, 0.15]),\n            \"mu_1\": np.array([0.6, 0.62, 0.58]),\n            \"sigma_1\": np.array([0.15, 0.15, 0.15]),\n            \"q\": 0.2,\n        },\n        # Case E (heterogeneous spreads and skewed priors)\n        {\n            \"K\": 3,\n            \"p_y\": np.array([0.2, 0.3, 0.5]),\n            \"mu_0\": np.array([0.49, 0.49, 0.49]),\n            \"sigma_0\": np.array([0.05, 0.01, 0.2]),\n            \"mu_1\": np.array([0.9, 0.9, 0.9]),\n            \"sigma_1\": np.array([0.05, 0.05, 0.05]),\n            \"q\": 0.1,\n        },\n    ]\n\n    all_results = []\n    for case in test_cases:\n        p_y = case[\"p_y\"]\n        mu_0 = case[\"mu_0\"]\n        sigma_0 = case[\"sigma_0\"]\n        mu_1 = case[\"mu_1\"]\n        sigma_1 = case[\"sigma_1\"]\n        q = case[\"q\"]\n\n        # --- 1. Fair Per-Class Attacker ---\n        # The threshold t_y for each class is found by inverting the FPR equation.\n        # FPR_y(t_y) = q  =>  1 - CDF((t_y - mu_0y) / sigma_0y) = q\n        # => t_y = mu_0y + sigma_0y * PPF(1-q)\n        t_y_fair = norm.ppf(1 - q, loc=mu_0, scale=sigma_0)\n\n        # Calculate TPR for each class using its specific threshold t_y\n        tpr_y_fair = norm.sf(t_y_fair, loc=mu_1, scale=sigma_1)\n        \n        # Calculate overall TPR\n        tpr_overall_fair = np.sum(p_y * tpr_y_fair)\n        \n        # Calculate advantage\n        adv_fair = tpr_overall_fair - q\n        \n        # Fairness violation is 0 by definition\n        delta_fpr_fair = 0.0\n\n        # --- 2. Global-Threshold Attacker ---\n        # Define the function whose root we need to find\n        def overall_fpr(t):\n            return np.sum(p_y * norm.sf(t, loc=mu_0, scale=sigma_0))\n        \n        def objective_func(t):\n            return overall_fpr(t) - q\n\n        # Bisection method to find the global threshold t\n        low = np.min(mu_0) - 10 * np.max(sigma_0)\n        high = np.max(mu_0) + 10 * np.max(sigma_0)\n        \n        # Check if the initial bracket is valid\n        if objective_func(low) * objective_func(high) >= 0:\n            # Fallback to a very wide, safe bracket if the initial one fails\n            low, high = -100.0, 100.0\n\n        for _ in range(100):  # 100 iterations for high precision\n            mid = (low + high) / 2\n            if objective_func(mid) > 0: # our function is decreasing\n                low = mid\n            else:\n                high = mid\n        t_global = (low + high) / 2\n\n        # Calculate per-class FPRs at the global threshold\n        fpr_y_global = norm.sf(t_global, loc=mu_0, scale=sigma_0)\n        \n        # Calculate fairness violation\n        delta_fpr_global = np.max(fpr_y_global) - np.min(fpr_y_global)\n        \n        # Calculate per-class TPRs at the global threshold\n        tpr_y_global = norm.sf(t_global, loc=mu_1, scale=sigma_1)\n        \n        # Calculate overall TPR\n        tpr_overall_global = np.sum(p_y * tpr_y_global)\n        \n        # Calculate advantage\n        adv_global = tpr_overall_global - q\n\n        # Assemble result list for the case\n        result = [adv_global, adv_fair, delta_fpr_global, delta_fpr_fair, t_global]\n        all_results.append(result)\n\n    # Format the final output as specified\n    formatted_case_results = []\n    for res in all_results:\n        formatted_numbers = [f'{num:.4f}' for num in res]\n        formatted_case_results.append(f\"[{','.join(formatted_numbers)}]\")\n    \n    print(f\"[{','.join(formatted_case_results)}]\")\n\nsolve()\n```", "id": "3149384"}]}