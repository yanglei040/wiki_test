{"hands_on_practices": [{"introduction": "损失函数是驱动深度学习模型训练的核心引擎，它量化了模型预测与真实标签之间的误差。本练习将指导您从第一性原理出发，推导并实现三种图像分割中的基础损失函数——像素级交叉熵损失、Focal Loss 和 Dice Loss，并深入分析它们在类别不平衡等挑战性场景下的梯度行为。通过这项实践，您将深刻理解不同损失函数的工作机制，这对于诊断训练问题和为特定任务选择合适的损失函数至关重要。[@problem_id:\"3136332\"]", "problem": "您的任务是推导、分析和实现三种用于像素级二元语义分割的损失函数，这些函数需适用于前景类别稀少的高度不平衡数据。考虑一个分割场景，其中每个像素被建模为一个独立的伯努利随机变量，其目标值为 $y \\in \\{0,1\\}$，预测概率为 $p \\in (0,1)$，该概率由 logistic 函数 $p = \\sigma(z)$ 生成，其中 $z \\in \\mathbb{R}$ 且 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$。从独立伯努利变量的最大似然估计原理以及作为损失的负对数似然的定义出发。推导以下三种损失函数及其关于 logit $z$ 的梯度：\n\n1. 基于伯努利负对数似然的像素级交叉熵损失 $L_{CE}$。\n2. 用于二元分类的 Focal loss $L_{focal}$，其聚焦参数为 $\\gamma \\ge 0$，类别平衡因子为 $\\alpha \\in (0,1)$。\n3. 基于软 Sørensen–Dice 系数的 Dice 损失 $L_{Dice}$，其平滑常数 $s$ 为严格正值以确保数值稳定性。\n\n对于每种损失，您必须：\n- 使用伯努利似然和适当的定义，从第一性原理推导损失的解析表达式，而不是直接使用已知的最终公式。\n- 假设 $p = \\sigma(z)$ 且 $\\frac{dp}{dz} = p(1-p)$，使用链式法则推导关于 logit $z$ 的梯度。\n- 分析并解释在严重类别不平衡情况下，当正类别的预测概率满足 $p \\ll 1$ 时梯度幅值的行为，并对比 $y=1$（正像素）和 $y=0$（负像素）两种情况下的行为。\n\n实现要求：\n- 为像素数组实现这三种损失函数及其关于 $z$ 的梯度的数值稳定版本。通过将概率裁剪在一个很小的 $\\epsilon$ 值来避免未定义的对数。\n- 对每个测试用例，计算每像素的平均损失，以及针对正像素（$y=1$）和负像素（$y=0$）分别计算的关于 $z$ 的平均绝对梯度幅值。\n\n测试套件：\n- 构建具有指定总像素数 $N$、正类别比例 $r$、以及为正像素指定的恒定预测概率 $p_{pos}$ 和为负像素指定的 $p_{neg}$ 的合成（或人造）分割数据集。使用以下四个测试用例：\n    1. 用例 1：$N = 100$, $r = 0.2$, $p_{pos} = 0.6$, $p_{neg} = 0.4$, focal 参数 $\\gamma = 2$, $\\alpha = 0.25$, dice 平滑 $s = 1.0$。\n    2. 用例 2（严重类别不平衡且 $p \\ll 1$）：$N = 1000$, $r = 0.01$, $p_{pos} = 0.01$, $p_{neg} = 0.01$, focal 参数 $\\gamma = 2$, $\\alpha = 0.25$, dice 平滑 $s = 1.0$。\n    3. 用例 3（近乎完美的预测）：$N = 500$, $r = 0.1$, $p_{pos} = 0.999$, $p_{neg} = 0.001$, focal 参数 $\\gamma = 2$, $\\alpha = 0.25$, dice 平滑 $s = 1.0$。\n    4. 用例 4（focal 参数 $\\gamma = 0$，用于与加权交叉熵比较）：$N = 200$, $r = 0.3$, $p_{pos} = 0.7$, $p_{neg} = 0.3$, focal 参数 $\\gamma = 0$, $\\alpha = 0.25$, dice 平滑 $s = 1.0$。\n\n输出规范：\n- 对每个测试用例，计算一个嵌套列表，其中包含三个子列表，每个子列表对应一种损失，顺序为 $[L_{CE}, L_{focal}, L_{Dice}]$。每个子列表必须采用 $[\\text{平均损失}, y=1\\text{时的平均绝对梯度}, y=0\\text{时的平均绝对梯度}]$ 的形式，所有值均为浮点数。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的、逗号分隔的结果列表，且不含空格。顶层列表必须为每个测试用例包含一个元素，顺序与上述相同。例如，对于三个测试用例，格式必须是 $[[l_{11},g_{11}^+,g_{11}^-],[l_{12},g_{12}^+,g_{12}^-],[l_{13},g_{13}^+,g_{13}^-]]$, 并为四个用例作相应扩展。\n\n不涉及物理单位；所有结果均为无量纲浮点数。请将所有量表示为小数。", "solution": "该问题是有效的，因为它在科学上基于统计学习理论，定义明确，提供了所有必要的数据和定义，并以客观、正式的语言表述。我们继续进行推导、分析和实现。\n\n本分析的基础是将二元语义分割任务中的每个像素建模为一个独立的伯努利试验。一个像素的真实标签是 $y \\in \\{0, 1\\}$，模型对正类别（$y=1$）的预测概率是 $p \\in (0,1)$。该概率是对一个 logit $z \\in \\mathbb{R}$ 应用 logistic sigmoid 函数的输出，即 $p = \\sigma(z) = (1 + e^{-z})^{-1}$。sigmoid 函数的一个关键特性是它相对于其输入的导数形式简单：$\\frac{dp}{dz} = \\frac{d\\sigma(z)}{dz} = \\sigma(z)(1-\\sigma(z)) = p(1-p)$。\n\n单个像素观测的似然由伯努利概率质量函数给出：$P(y|p) = p^y(1-p)^{1-y}$。对于一幅有 $N$ 个像素的图像，假设像素之间相互独立，总似然是各个似然的乘积：$\\mathcal{L} = \\prod_{i=1}^{N} p_i^{y_i}(1-p_i)^{1-y_i}$。\n\n在机器学习中，标准做法是最大化对数似然，或等效地，最小化负对数似然（NLL）。整幅图像的 NLL 为：\n$$ \\text{NLL} = -\\log(\\mathcal{L}) = -\\sum_{i=1}^{N} \\left[ y_i \\log(p_i) + (1-y_i) \\log(1-p_i) \\right] $$\n每个像素对 NLL 的贡献构成了交叉熵损失的基础。\n\n### 1. 像素级交叉熵损失 ($L_{CE}$)\n\n#### 推导\n单个像素的交叉熵损失直接从单个伯 nuov li 试验的负对数似然推导而来。\n$$ L_{CE}(y, p) = -[y \\log(p) + (1-y) \\log(1-p)] $$\n该损失惩罚模型对错误预测的置信度。例如，如果 $y=1$，损失为 $-\\log(p)$，当预测概率 $p$ 趋近于 $0$ 时，损失趋近于无穷大。\n\n#### 梯度推导\n我们求解损失关于 logit $z$ 的梯度 $\\frac{dL_{CE}}{dz}$。使用链式法则，$\\frac{dL_{CE}}{dz} = \\frac{dL_{CE}}{dp} \\frac{dp}{dz}$。\n首先，我们求关于 $p$ 的导数：\n$$ \\frac{dL_{CE}}{dp} = -\\left[ \\frac{y}{p} - \\frac{1-y}{1-p} \\right] = -\\frac{y(1-p) - p(1-y)}{p(1-p)} = -\\frac{y - yp - p + py}{p(1-p)} = -\\frac{y-p}{p(1-p)} $$\n现在，乘以 $\\frac{dp}{dz} = p(1-p)$：\n$$ \\frac{dL_{CE}}{dz} = \\left( -\\frac{y-p}{p(1-p)} \\right) \\cdot p(1-p) = -(y-p) = p-y $$\n这个非常简洁的结果表明，交叉熵损失关于 logit 的梯度就是预测值与目标值之间的差。\n\n#### 梯度分析 ($p \\ll 1$)\n在严重类别不平衡的情况下，正类别是稀少的。我们分析当模型（通常情况下）预测正类别的概率很低（$p \\ll 1$）时的梯度。\n- **对于正像素（$y=1$）：** 梯度为 $\\frac{dL_{CE}}{dz} = p-1$。当 $p \\to 0$ 时，梯度趋近于 $-1$。梯度幅值为 $|\\frac{dL_{CE}}{dz}| \\approx 1$。这些稀少的正像素，即使以低概率被错误分类，也会产生一个强大的、恒定的误差信号来更新模型。\n- **对于负像素（$y=0$）：** 梯度为 $\\frac{dL_{CE}}{dz} = p-0 = p$。当 $p \\to 0$ 时，梯度趋近于 $0$。梯度幅值为 $|\\frac{dL_{CE}}{dz}| \\approx 0$。这些常见的负像素，当以低概率被正确分类时，只产生一个非常小的误差信号。\n在不平衡场景下，$L_{CE}$ 的问题在于，来自大量“简单”负样本的许多小梯度的总和，可能会压倒来自少数“困难”正样本的少数大梯度的总和。\n\n### 2. Focal Loss ($L_{focal}$)\n\n#### 推导\nFocal loss 旨在通过修改交叉熵损失来解决类别不平衡问题，它引入了一个调制因子，以减少来自被良好分类样本的损失贡献。聚焦参数 $\\gamma \\ge 0$ 控制降权的速率。该损失还包含一个权重因子 $\\alpha \\in (0,1)$ 以平衡正/负类别的重要性。\n\n单个像素的损失定义为：\n$$ L_{focal}(y, p) = -y \\alpha (1-p)^\\gamma \\log(p) - (1-y)(1-\\alpha) p^\\gamma \\log(1-p) $$\n当 $\\gamma=0$ 时，这退化为加权交叉熵。随着 $\\gamma$ 的增加，调制因子（对于 $y=1$ 是 $(1-p)^\\gamma$，对于 $y=0$ 是 $p^\\gamma$）会更积极地降权简单样本（例如，$y=0, p \\to 0$ 或 $y=1, p \\to 1$）。\n\n#### 梯度推导\n我们对 $L_{focal}$ 关于 $z$ 分别就 $y=1$ 和 $y=0$ 的情况进行分段求导。\n情况 $y=1$：$L = -\\alpha (1-p)^\\gamma \\log(p)$。\n$$ \\frac{dL}{dz} = \\frac{dL}{dp} \\frac{dp}{dz} = \\left(-\\alpha \\left[ -\\gamma(1-p)^{\\gamma-1} \\log(p) + \\frac{(1-p)^\\gamma}{p} \\right] \\right) \\cdot (p(1-p)) $$\n$$ = -\\alpha [-\\gamma p (1-p)^\\gamma \\log(p) + (1-p)^{\\gamma+1}] = \\alpha (1-p)^\\gamma [\\gamma p \\log(p) - (1-p)] $$\n$$ = \\alpha (1-p)^\\gamma (\\gamma p \\log(p) + p - 1) $$\n情况 $y=0$：$L = -(1-\\alpha) p^\\gamma \\log(1-p)$。\n$$ \\frac{dL}{dz} = \\frac{dL}{dp} \\frac{dp}{dz} = \\left(-(1-\\alpha) \\left[ \\gamma p^{\\gamma-1} \\log(1-p) + p^\\gamma \\frac{-1}{1-p} \\right] \\right) \\cdot (p(1-p)) $$\n$$ = -(1-\\alpha) [\\gamma p^\\gamma(1-p) \\log(1-p) - p^{\\gamma+1}] = (1-\\alpha) p^\\gamma [p - \\gamma(1-p)\\log(1-p)] $$\n将它们组合起来得到完整的梯度表达式：\n$$ \\frac{dL_{focal}}{dz} = y \\cdot \\left[ \\alpha (1-p)^\\gamma (\\gamma p \\log(p) + p - 1) \\right] + (1-y) \\cdot \\left[ (1-\\alpha) p^\\gamma (p - \\gamma(1-p)\\log(1-p)) \\right] $$\n\n#### 梯度分析 ($p \\ll 1$)\n- **对于正像素（$y=1$）：** 梯度为 $\\frac{dL_{focal}}{dz} = \\alpha (1-p)^\\gamma (\\gamma p \\log(p) + p - 1)$。当 $p \\to 0$ 时，我们利用 $\\lim_{p\\to 0} p\\log(p) = 0$。梯度趋近于 $\\alpha(1-0)^\\gamma(0 + 0 - 1) = -\\alpha$。梯度幅值为 $|\\frac{dL_{focal}}{dz}| \\approx \\alpha$。与交叉熵类似，这提供了一个恒定的学习信号，但按 $\\alpha$ 进行了缩放。\n- **对于负像素（$y=0$）：** 梯度为 $\\frac{dL_{focal}}{dz} = (1-\\alpha) p^\\gamma (p - \\gamma(1-p)\\log(1-p))$。当 $p \\to 0$ 时，我们使用泰勒展开 $\\log(1-p) \\approx -p$。括号中的项变为 $p - \\gamma(1-p)(-p) = p(1 + \\gamma(1-p)) \\approx p(1+\\gamma)$。梯度近似为 $(1-\\alpha) p^\\gamma \\cdot p(1+\\gamma) = (1-\\alpha)(1+\\gamma)p^{\\gamma+1}$。对于 $\\gamma > 0$，此梯度比交叉熵梯度（$p$）快得多地衰减到零。对于 $\\gamma=2$，梯度是 $O(p^3)$，有效地消除了大量简单负样本的贡献。\n\n### 3. Dice 损失 ($L_{Dice}$)\n\n#### 推导\nDice 损失基于 Sørensen–Dice 系数，这是一个衡量两个集合重叠度的度量。它并非从伯努利负对数似然推导而来，但作为一种常见且有效的分割方法替代方案被包含在此。对于所有 $N$ 个像素的预测概率 $p_i$ 和真实标签 $y_i$，软 Dice 系数为：\n$$ D(y, p) = \\frac{2 \\sum_{i=1}^N y_i p_i + s}{\\sum_{i=1}^N y_i + \\sum_{i=1}^N p_i + s} $$\n其中 $s>0$ 是一个平滑常数，用于防止除以零并提高稳定性。Dice 损失定义为 $L_{Dice} = 1 - D$。\n$$ L_{Dice} = 1 - \\frac{2 \\sum_{i=1}^N y_i p_i + s}{\\sum_{i=1}^N y_i + \\sum_{i=1}^N p_i + s} $$\n与 CE 和 Focal loss 不同，Dice 损失是一个全局度量；损失值是基于整幅图像计算的，而不是逐像素计算。\n\n#### 梯度推导\n$L_{Dice}$ 关于单个 logit $z_j$ 的梯度是 $\\frac{\\partial L_{Dice}}{\\partial z_j} = \\frac{\\partial L_{Dice}}{\\partial p_j} \\frac{dp_j}{dz_j}$。令 $U = 2 \\sum_i y_i p_i + s$ 且 $V = \\sum_i y_i + \\sum_i p_i + s$。\n$$ \\frac{\\partial L_{Dice}}{\\partial p_j} = -\\frac{\\partial}{\\partial p_j}\\left(\\frac{U}{V}\\right) = - \\frac{\\frac{\\partial U}{\\partial p_j}V - U\\frac{\\partial V}{\\partial p_j}}{V^2} $$\n和的偏导数是 $\\frac{\\partial U}{\\partial p_j} = 2y_j$ 和 $\\frac{\\partial V}{\\partial p_j} = 1$。\n$$ \\frac{\\partial L_{Dice}}{\\partial p_j} = - \\frac{2y_j V - U}{V^2} = - \\frac{2y_j (\\sum_i y_i + \\sum_i p_i + s) - (2 \\sum_i y_i p_i + s)}{(\\sum_i y_i + \\sum_i p_i + s)^2} $$\n乘以 $\\frac{dp_j}{dz_j} = p_j(1-p_j)$ 得到最终梯度：\n$$ \\frac{\\partial L_{Dice}}{\\partial z_j} = -p_j(1-p_j) \\frac{2y_j (\\sum_i y_i + \\sum_i p_i + s) - (2 \\sum_i y_i p_i + s)}{(\\sum_i y_i + \\sum_i p_i + s)^2} $$\n\n#### 梯度分析（所有 i 的 $p_i \\ll 1$）\n假设所有预测 $p_i$ 都很小。\n- **对于正像素（$y_j=1$）：** 分子中的项 $2y_j V$ 不为零。梯度取决于全局总和 $\\sum y_i$、$\\sum p_i$ 等。即使 $p_j \\to 0$，梯度也不一定消失，因为这个大的分数项（取决于像正像素总数 $\\sum y_i$ 这样的全局统计数据）提供了一个可观的信号。正像素的梯度信号得以保持。\n- **对于负像素（$y_j=0$）：** 分子中的项 $2y_j V$ 为零。梯度表达式变为 $\\frac{\\partial L_{Dice}}{\\partial z_j} = p_j(1-p_j) \\frac{U}{V^2}$。当 $p_j \\to 0$ 时，因子 $p_j(1-p_j)$ 会使梯度趋于零。简单负样本的梯度被抑制了。\n\nDice 损失能够自然地平衡类别，因为其梯度结构内在地考虑了正像素的全局数量，使其在没有像 $\\alpha$ 这样的显式重加权参数的情况下也能对不平衡问题保持鲁棒性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Global constant for numerical stability in log operations\nEPSILON = 1e-7\n\ndef compute_ce(y_true, p_pred):\n    \"\"\"\n    Computes pixel-wise Cross-Entropy loss and its gradient statistics.\n\n    Args:\n        y_true (np.ndarray): Array of true binary labels {0, 1}.\n        p_pred (np.ndarray): Array of predicted probabilities (0, 1).\n\n    Returns:\n        list: [mean_loss, mean_abs_grad_pos, mean_abs_grad_neg]\n    \"\"\"\n    # Clamp probabilities to avoid log(0)\n    p_clamped = np.clip(p_pred, EPSILON, 1 - EPSILON)\n    \n    # 1. Compute mean loss per pixel\n    loss_ce = -(y_true * np.log(p_clamped) + (1 - y_true) * np.log(1 - p_clamped))\n    mean_loss = np.mean(loss_ce)\n    \n    # 2. Compute gradient with respect to the logit z\n    grad_z = p_pred - y_true\n    \n    # 3. Separate gradients for positive (y=1) and negative (y=0) pixels\n    pos_mask = y_true == 1\n    neg_mask = y_true == 0\n    \n    grad_abs_pos = np.abs(grad_z[pos_mask])\n    mean_grad_abs_pos = np.mean(grad_abs_pos) if grad_abs_pos.size > 0 else 0.0\n    \n    grad_abs_neg = np.abs(grad_z[neg_mask])\n    mean_grad_abs_neg = np.mean(grad_abs_neg) if grad_abs_neg.size > 0 else 0.0\n    \n    return [mean_loss, mean_grad_abs_pos, mean_grad_abs_neg]\n\ndef compute_focal(y_true, p_pred, gamma, alpha):\n    \"\"\"\n    Computes pixel-wise Focal loss and its gradient statistics.\n\n    Args:\n        y_true (np.ndarray): Array of true binary labels {0, 1}.\n        p_pred (np.ndarray): Array of predicted probabilities (0, 1).\n        gamma (float): The focusing parameter.\n        alpha (float): The class-balancing factor.\n\n    Returns:\n        list: [mean_loss, mean_abs_grad_pos, mean_abs_grad_neg]\n    \"\"\"\n    p_clamped = np.clip(p_pred, EPSILON, 1 - EPSILON)\n    \n    # 1. Compute mean loss per pixel\n    loss_pos = -alpha * ((1 - p_clamped)**gamma) * np.log(p_clamped)\n    loss_neg = -(1 - alpha) * (p_clamped**gamma) * np.log(1 - p_clamped)\n    loss_focal = y_true * loss_pos + (1 - y_true) * loss_neg\n    mean_loss = np.mean(loss_focal)\n    \n    # 2. Compute gradient with respect to the logit z\n    # Note: Use p_clamped for log terms in gradient to maintain numerical stability.\n    grad_pos = alpha * ((1 - p_pred)**gamma) * (gamma * p_pred * np.log(p_clamped) + p_pred - 1)\n    grad_neg = (1 - alpha) * (p_pred**gamma) * (p_pred - gamma * (1 - p_pred) * np.log(1 - p_clamped))\n    grad_z = y_true * grad_pos + (1 - y_true) * grad_neg\n    \n    # 3. Separate gradients\n    pos_mask = y_true == 1\n    neg_mask = y_true == 0\n    \n    grad_abs_pos = np.abs(grad_z[pos_mask])\n    mean_grad_abs_pos = np.mean(grad_abs_pos) if grad_abs_pos.size > 0 else 0.0\n    \n    grad_abs_neg = np.abs(grad_z[neg_mask])\n    mean_grad_abs_neg = np.mean(grad_abs_neg) if grad_abs_neg.size > 0 else 0.0\n    \n    return [mean_loss, mean_grad_abs_pos, mean_grad_abs_neg]\n    \ndef compute_dice(y_true, p_pred, s):\n    \"\"\"\n    Computes Dice loss and its gradient statistics.\n\n    Args:\n        y_true (np.ndarray): Array of true binary labels {0, 1}.\n        p_pred (np.ndarray): Array of predicted probabilities (0, 1).\n        s (float): The smoothing constant.\n\n    Returns:\n        list: [loss_value, mean_abs_grad_pos, mean_abs_grad_neg]\n    \"\"\"\n    # 1. Compute global loss value\n    intersection = np.sum(y_true * p_pred)\n    total_sum = np.sum(y_true) + np.sum(p_pred)\n    dice_coeff = (2. * intersection + s) / (total_sum + s)\n    loss_dice = 1. - dice_coeff  # This is the single loss value for the whole image.\n    \n    # 2. Compute gradient with respect to the logit z (per-pixel)\n    U = 2. * intersection + s\n    V = total_sum + s\n    \n    grad_p = - (2 * y_true * V - U) / (V**2)\n    grad_z = grad_p * p_pred * (1 - p_pred)\n    \n    # 3. Separate gradients\n    pos_mask = y_true == 1\n    neg_mask = y_true == 0\n    \n    grad_abs_pos = np.abs(grad_z[pos_mask])\n    mean_grad_abs_pos = np.mean(grad_abs_pos) if grad_abs_pos.size > 0 else 0.0\n    \n    grad_abs_neg = np.abs(grad_z[neg_mask])\n    mean_grad_abs_neg = np.mean(grad_abs_neg) if grad_abs_neg.size > 0 else 0.0\n    \n    return [loss_dice, mean_grad_abs_pos, mean_grad_abs_neg]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'N': 100, 'r': 0.2, 'p_pos': 0.6, 'p_neg': 0.4, 'gamma': 2, 'alpha': 0.25, 's': 1.0},\n        {'N': 1000, 'r': 0.01, 'p_pos': 0.01, 'p_neg': 0.01, 'gamma': 2, 'alpha': 0.25, 's': 1.0},\n        {'N': 500, 'r': 0.1, 'p_pos': 0.999, 'p_neg': 0.001, 'gamma': 2, 'alpha': 0.25, 's': 1.0},\n        {'N': 200, 'r': 0.3, 'p_pos': 0.7, 'p_neg': 0.3, 'gamma': 0, 'alpha': 0.25, 's': 1.0},\n    ]\n\n    all_results = []\n    for params in test_cases:\n        N = params['N']\n        r = params['r']\n        p_pos = params['p_pos']\n        p_neg = params['p_neg']\n        gamma = params['gamma']\n        alpha = params['alpha']\n        s = params['s']\n\n        n_pos = int(round(N * r))\n        n_neg = N - n_pos\n\n        y_true = np.array([1] * n_pos + [0] * n_neg, dtype=np.float64)\n        p_pred = np.array([p_pos] * n_pos + [p_neg] * n_neg, dtype=np.float64)\n\n        case_results = []\n        # L_CE\n        case_results.append(compute_ce(y_true, p_pred))\n        # L_focal\n        case_results.append(compute_focal(y_true, p_pred, gamma, alpha))\n        # L_Dice\n        case_results.append(compute_dice(y_true, p_pred, s))\n        \n        all_results.append(case_results)\n\n    # Format the final output string exactly as specified in the problem statement\n    all_case_strings = []\n    for case_result in all_results:\n        loss_strings = []\n        for loss_result in case_result:\n            # Format each sublist of floats into \"[v1,v2,v3]\"\n            loss_strings.append(f\"[{','.join(f'{v:.10f}'.rstrip('0').rstrip('.') if v != 0 else '0.0' for v in loss_result)}]\")\n        # Join the sublists for a single test case\n        case_string = f\"[{','.join(loss_strings)}]\"\n        all_case_strings.append(case_string)\n    \n    # Join all test case results into the final string\n    final_output = f\"[{','.join(all_case_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3136332"}, {"introduction": "在图像分割领域，Dice 系数和 Jaccard 指数（IoU）都是衡量重叠度的常用指标，但它们对应的损失函数在训练过程中展现出不同的梯度特性。本练习聚焦于在受控条件下对这两种损失函数进行直接的数学比较，特别是当模型处理小尺寸目标时。通过分析它们的梯度，您将揭示为何在训练初期某种损失可能比另一种更稳定或更具“侵略性”，并学会如何平衡它们的贡献以实现更稳健的优化。[@problem_id:\"3136290\"]", "problem": "在图像分割任务中——包括语义分割、实例分割和全景分割——基于集合重叠的损失函数很常见，特别是 Dice 系数和 Jaccard 指数（也称为交并比，IoU）。考虑将二元前景-背景语义分割作为一个基本案例，它同时也是实例分割中逐实例掩码学习和全景分割中逐类别掩码的基础。\n\n假设在一个小批量（mini-batch）中，预测初始是均匀的：对于 $N$ 个像素，每个像素的预测前景概率均为 $c \\in (0,1)$。真实标签的前景集为 $Y \\subset \\{1,\\dots,N\\}$，其大小为 $|Y| = m$，并假设 $m/N$ 很小（小目标情况）。设 $p_i = c$ 且 $y_i \\in \\{0,1\\}$。定义软 Dice 系数\n$$\nD \\;=\\; \\frac{2 \\sum_{i=1}^{N} p_i y_i}{\\sum_{i=1}^{N} p_i + \\sum_{i=1}^{N} y_i},\n$$\n和软 Jaccard 指数（交并比，IoU）\n$$\nJ \\;=\\; \\frac{\\sum_{i=1}^{N} p_i y_i}{\\sum_{i=1}^{N} p_i + \\sum_{i=1}^{N} y_i - \\sum_{i=1}^{N} p_i y_i}.\n$$\n定义相应的损失 $L_{D} = 1 - D$ 和 $L_{J} = 1 - J$，并考虑一个退火复合损失\n$$\nL_{\\alpha} \\;=\\; \\alpha\\, L_{D} \\;+\\; (1 - \\alpha)\\, L_{J},\n$$\n其中 $\\alpha \\in [0,1]$。\n\n从这些核心定义和第一性原理出发，完成以下任务：\n\n1. 在均匀预测假设 $p_i = c$ 下，将 $D$ 和 $J$ 表示为 $m$、$N$ 和 $c$ 的函数。\n2. 推导 $\\frac{d L_{D}}{d c}$ 和 $\\frac{d L_{J}}{d c}$，简化它们的大小，并定义比率\n$$\nr(m,c,N) \\;=\\; \\frac{\\left|\\frac{d L_{D}}{d c}\\right|}{\\left|\\frac{d L_{J}}{d c}\\right|}.\n$$\n3. 为了通过均衡 Dice 和 Jaccard 分量的梯度贡献来稳定初始化阶段的优化，选择 $\\alpha$ 使得\n$$\n\\alpha \\left|\\frac{d L_{D}}{d c}\\right| \\;=\\; (1 - \\alpha)\\left|\\frac{d L_{J}}{d c}\\right|.\n$$\n求解 $\\alpha^{\\ast}(m,c,N)$ 关于 $r(m,c,N)$ 的闭式表达式，然后计算极限值\n$$\n\\lim_{m \\to 0} \\alpha^{\\ast}(m,c,N)\n$$\n其中 $N$ 固定且 $c \\in (0,1)$ 固定。将此极限值作为您的最终答案，并进行精确简化。\n\n此外，根据您的推导，简要提出一个有原则的 $\\alpha$ 退火策略，该策略在训练迭代中使用 $m$ 的小批量估计值，以在目标尺寸变化时保持梯度的平衡。您的提议应科学合理且自洽，但您最终报告的答案必须仅为当 $m \\to 0$ 时 $\\alpha^{\\ast}$ 的唯一精确极限值。", "solution": "所述问题具有科学依据，定义明确且客观。所有定义在计算机视觉的深度学习领域都是标准的，所需的推导在数学上是合理的。该问题是有效的，并且可以构建解决方案。\n\n任务是分析复合损失函数 $L_{\\alpha} = \\alpha L_{D} + (1 - \\alpha) L_{J}$ 在图像中所有 $N$ 个像素的预测均为均匀值 $p_i = c$ 的条件下的行为。我们已知真实标签的前景掩码大小为 $|Y| = m$。\n\n首先，我们将软 Dice 系数 $D$ 和软 Jaccard 指数 $J$ 表示为 $m$、$N$ 和 $c$ 的函数。它们定义中的求和项可以在给定条件下进行计算。\n真实标签的总和是前景像素的数量：\n$$\n\\sum_{i=1}^{N} y_i = m\n$$\n预测概率的总和是：\n$$\n\\sum_{i=1}^{N} p_i = \\sum_{i=1}^{N} c = Nc\n$$\n交集项，即在真实标签为前景的像素上的预测概率之和，是：\n$$\n\\sum_{i=1}^{N} p_i y_i = \\sum_{i \\in Y} p_i y_i + \\sum_{i \\notin Y} p_i y_i = \\sum_{i \\in Y} c \\cdot 1 + \\sum_{i \\notin Y} c \\cdot 0 = mc\n$$\n将这些代入 $D$ 和 $J$ 的定义中：\n$$\nD(m, N, c) = \\frac{2 \\sum p_i y_i}{\\sum p_i + \\sum y_i} = \\frac{2mc}{Nc + m}\n$$\n$$\nJ(m, N, c) = \\frac{\\sum p_i y_i}{\\sum p_i + \\sum y_i - \\sum p_i y_i} = \\frac{mc}{Nc + m - mc} = \\frac{mc}{Nc + m(1-c)}\n$$\n\n接下来，我们推导相应损失 $L_D = 1 - D$ 和 $L_J = 1 - J$ 相对于 $c$ 的梯度。损失的导数是系数导数的负数：$\\frac{d L_D}{d c} = -\\frac{d D}{d c}$ 和 $\\frac{d L_J}{d c} = -\\frac{d J}{d c}$。\n\n我们使用商法则进行微分，$\\frac{d}{dx} \\left( \\frac{u}{v} \\right) = \\frac{u'v - uv'}{v^2}$。\n对于 Dice 系数 $D$：\n$$\n\\frac{d D}{d c} = \\frac{d}{dc} \\left( \\frac{2mc}{Nc + m} \\right) = \\frac{(2m)(Nc + m) - (2mc)(N)}{(Nc + m)^2} = \\frac{2mNc + 2m^2 - 2mNc}{(Nc + m)^2} = \\frac{2m^2}{(Nc + m)^2}\n$$\n因此，Dice 损失的梯度为：\n$$\n\\frac{d L_D}{d c} = -\\frac{2m^2}{(Nc + m)^2}\n$$\n对于 Jaccard 指数 $J$：\n$$\n\\frac{d J}{d c} = \\frac{d}{dc} \\left( \\frac{mc}{Nc + m(1-c)} \\right) = \\frac{d}{dc} \\left( \\frac{mc}{c(N-m) + m} \\right)\n$$\n$$\n\\frac{d J}{d c} = \\frac{(m)(c(N-m) + m) - (mc)(N-m)}{(c(N-m) + m)^2} = \\frac{mc(N-m) + m^2 - mc(N-m)}{(c(N-m) + m)^2} = \\frac{m^2}{(c(N-m) + m)^2}\n$$\n因此，Jaccard 损失的梯度为：\n$$\n\\frac{d L_J}{d c} = -\\frac{m^2}{(c(N-m) + m)^2}\n$$\n对于 $m > 0$，两个梯度均为负值，这是符合预期的，因为增加前景目标的预测概率 $c$ 应该会减少分割损失。\n\n这些梯度的大小为：\n$$\n\\left|\\frac{d L_D}{d c}\\right| = \\frac{2m^2}{(Nc + m)^2}\n$$\n$$\n\\left|\\frac{d L_J}{d c}\\right| = \\frac{m^2}{(c(N-m) + m)^2}\n$$\n比率 $r(m,c,N)$ 定义为：\n$$\nr(m,c,N) = \\frac{\\left|\\frac{d L_{D}}{d c}\\right|}{\\left|\\frac{d L_{J}}{d c}\\right|} = \\frac{2m^2 / (Nc + m)^2}{m^2 / (c(N-m) + m)^2} = 2 \\left( \\frac{c(N-m) + m}{Nc + m} \\right)^2\n$$\n这可以重写为：\n$$\nr(m,c,N) = 2 \\left( \\frac{Nc - mc + m}{Nc + m} \\right)^2 = 2 \\left( \\frac{Nc + m(1-c)}{Nc + m} \\right)^2\n$$\n现在，我们寻找能够平衡梯度贡献的 $\\alpha$ 值，记为 $\\alpha^{\\ast}$。条件是：\n$$\n\\alpha \\left|\\frac{d L_{D}}{d c}\\right| = (1 - \\alpha)\\left|\\frac{d L_{J}}{d c}\\right|\n$$\n假设 $m \\neq 0$，梯度的大小非零，我们可以除以 $|\\frac{d L_J}{d c}|$：\n$$\n\\alpha \\frac{\\left|\\frac{d L_{D}}{d c}\\right|}{\\left|\\frac{d L_{J}}{d c}\\right|} = 1 - \\alpha\n$$\n$$\n\\alpha \\, r(m,c,N) = 1 - \\alpha\n$$\n解出 $\\alpha$：\n$$\n\\alpha (r + 1) = 1 \\implies \\alpha^{\\ast}(m,c,N) = \\frac{1}{r(m,c,N) + 1}\n$$\n代入 $r$ 的表达式：\n$$\n\\alpha^{\\ast}(m,c,N) = \\frac{1}{1 + 2 \\left( \\frac{Nc + m(1-c)}{Nc + m} \\right)^2}\n$$\n最后，我们计算当目标尺寸 $m$ 趋近于 $0$ 时 $\\alpha^{\\ast}$ 的极限值。我们首先求 $r(m,c,N)$ 的极限：\n$$\n\\lim_{m \\to 0} r(m,c,N) = \\lim_{m \\to 0} 2 \\left( \\frac{Nc + m(1-c)}{Nc + m} \\right)^2\n$$\n当 $m \\to 0$ 时，分子趋近于 $Nc + 0 = Nc$，分母趋近于 $Nc + 0 = Nc$。\n$$\n\\lim_{m \\to 0} r(m,c,N) = 2 \\left( \\frac{Nc}{Nc} \\right)^2 = 2(1)^2 = 2\n$$\n现在我们可以计算 $\\alpha^{\\ast}$ 的极限：\n$$\n\\lim_{m \\to 0} \\alpha^{\\ast}(m,c,N) = \\frac{1}{\\left(\\lim_{m \\to 0} r(m,c,N)\\right) + 1} = \\frac{1}{2 + 1} = \\frac{1}{3}\n$$\n该结果表明，对于非常小的目标，当 Jaccard 损失的权重是 Dice 损失的两倍时（即 $1-\\alpha = 2/3$ 对比 $\\alpha = 1/3$），复合损失的梯度是平衡的。\n\n作为简要补充，一个有原则的 $\\alpha$ 退火策略可以直接从 $\\alpha^{\\ast}(m,c,N)$ 的表达式中推导出来。在训练过程中，对于每个小批量，可以从真实标签掩码中计算平均目标尺寸的估计值 $\\hat{m}$。类似地，可以从网络的输出中计算平均预测置信度的估计值 $\\hat{c}$。将这些值代入 $\\alpha^{\\ast}(\\hat{m}, \\hat{c}, N)$ 的公式中，可以为每个训练步骤动态更新权重参数 $\\alpha$。这种自适应策略将确保 Dice 和 Jaccard 分量的梯度贡献在目标尺寸不同的小批量之间以及随着网络预测的演变而保持平衡，从而稳定训练。对于以微小目标为主的批量，$\\alpha$ 将自然趋近于 $\\frac{1}{3}$。", "answer": "$$\\boxed{\\frac{1}{3}}$$", "id": "3136290"}, {"introduction": "从训练转向评估，一个强大的评估指标对于理解和改进模型至关重要。全景分割（Panoptic Segmentation）任务的黄金标准——全景质量（$PQ$）通过将其分解为识别质量（$RQ$）和分割质量（$SQ$），提供了一个全面的性能视角。本练习旨在通过具体的编码实践来揭示 $PQ$ 指标的内在机理。您将通过设计可控的失败场景（如实例的过度合并与过度分割），親眼观察不同类型的预测错误如何独立地影响 $RQ$ 和 $SQ$ 这两个分量，从而获得比单一精度数字更深刻、更细致的性能洞察。[@problem_id:\"3136328\"]", "problem": "你的任务是形式化并测试标准的全景分割度量如何分解为能够区分识别质量与分割质量的分量，然后设计受控的失效案例，在这些案例中，语义准确率保持不变，而实例级划分则不同。在单一语义类别中完成全部工作，并在合成的二值掩码上进行评估，这些掩码的并集等于真值语义区域，从而确保在所有设计案例中语义准确率都相同。所有计算必须由你的程序实现，不得读取输入。\n\n使用的基本原理和定义如下：\n- 使用交并比 (IoU) 定义真值实例和预测实例之间的按类别匹配。对于每个真值实例掩码 $g$ 和预测实例掩码 $p$，将 IoU 定义为 $|g \\cap p| / |g \\cup p|$，其中 $|\\cdot|$ 表示以像素为单位测量的集合基数。\n- 通过最大化总 IoU 在实例之间构建一对一匹配，约束条件是只有 IoU 严格大于 $0.5$ 的配对才有资格。未匹配的真值实例计为假阴性，未匹配的预测实例计为假阳性，匹配对计为真阳性。\n- 将分割质量 (SQ) 定义为所有匹配对的平均 IoU，并约定如果真阳性数量 $|TP|$ 为 $0$，则 $SQ=0$。\n- 将识别质量 (RQ) 定义为 $2|TP|/(2|TP| + |FP| + |FN|)$，这是在上述带阈值的匹配协议下，实例识别的 F1 风格项。\n- 从第一性原理出发，将全景质量 (PQ) 定义为一个“每个匹配的质量分量”和一个“识别分量”的乘积。为此，从其标准定义开始，即匹配对的 IoU 总和除以一个带惩罚的检测计数，即分母 $|TP| + 0.5|FP| + 0.5|FN|$。展示该定义如何得出一个乘法分解，而无需先验地陈述它。\n\n你的程序必须：\n1. 使用上述 IoU 定义和 IoU 严格大于 $0.5$ 的阈值，实现按类别的实例匹配。匹配必须是一对一的，并且必须最大化所有接受配对的 IoU 之和。\n2. 计算 $SQ$、$RQ$ 及其乘积 $PQ$，并计算语义准确率，即预测与真值之间语义类别标签相匹配的像素比例。使用约定：背景标签为 $0$，单一前景语义类别由任何正整数实例标识符编码。对于语义准确率，合并所有实例，只考虑前景与背景，而不考虑实例身份。本问题中没有物理单位。\n3. 使用以下测试套件，每个案例都在一个 $10 \\times 10$ 像素的图像上进行。本说明中的所有数字和索引，在区间表示法中均包含起始索引，不包含结束索引，且行和列索引从 $0$ 开始。\n   - 案例 A (完美预测):\n     - 真值: 一个覆盖全部 $10 \\times 10$ 像素的实例。该实例使用标签值 $1$，实例外的背景使用 $0$ (此处没有背景)。\n     - 预测: 与真值相同。\n   - 案例 B (过度合并，语义相同):\n     - 真值: 两个不相交的实例，大小分别为 $60$ 和 $40$ 像素，通过在所有列 $[0,10)$ 上，用实例标签 $1$ 填充行 $[0,6)$，用实例标签 $2$ 填充行 $[6,10)$ 创建。\n     - 预测: 一个合并的实例，用标签 $1$ 覆盖全部 $10 \\times 10$ 像素。\n   - 案例 C (过度分割，语义相同):\n     - 真值: 一个用标签 $1$ 覆盖全部 $10 \\times 10$ 像素的实例。\n     - 预测: 两个不相交的实例，大小分别为 $60$ 和 $40$ 像素，通过在所有列 $[0,10)$ 上，用实例标签 $1$ 填充行 $[0,6)$，用实例标签 $2$ 填充行 $[6,10)$ 创建。\n   - 案例 D (极端过度分割，语义相同):\n     - 真值: 一个用标签 $1$ 覆盖全部 $10 \\times 10$ 像素的实例。\n     - 预测: 四个不相交的实例，每个大小为 $25$ 像素，分布为四个 $5 \\times 5$ 的象限：左上角行 $[0,5)$、列 $[0,5)$ 标签为 $1$；右上角行 $[0,5)$、列 $[5,10)$ 标签为 $2$；左下角行 $[5,10)$、列 $[0,5)$ 标签为 $3$；右下角行 $[5,10)$、列 $[5,10)$ 标签为 $4$。\n\n要求：\n- 匹配必须使用严格大于 $0.5$ 的 IoU 阈值。\n- 对于每个案例，计算 $PQ$、$SQ$、$RQ$ 和语义准确率。所有值必须是四舍五入到 $6$ 位小数的浮点数。\n- 最终输出格式：你的程序应生成单行输出，其中包含一个由四元素列表组成的逗号分隔列表，按 A、B、C、D 的案例顺序排列，其中每个内部列表为 $[PQ,SQ,RQ,SA]$，$SA$ 为语义准确率。例如：\"[[vA1,vA2,vA3,vA4],[vB1,vB2,vB3,vB4],[vC1,vC2,vC3,vC4],[vD1,vD2,vD3,vD4]]\"。\n- 输出必须与所述测试套件和上述定义一致，并且必须说明过度合并和过度分割如何在语义相同的情况下产生相同的语义准确率，同时突显出识别分量与分割分量对此的敏感性。", "solution": "用户提供的问题经评估为 **有效**。它在科学上植根于计算机视觉评估指标的原理，特别是全景分割。该问题是适定的，提供了一套自洽的定义、约束和测试数据，可得出一个唯一且可验证的解决方案。所有术语的定义都客观且无歧义。该任务要求进行形式化推导和具体实现，是科学计算领域一个实质性且结构良好的练习。\n\n### 理论基础与度量分解\n\n该问题围绕全景质量 ($PQ$) 展开，这是一种用于评估全景分割任务的度量。全景分割统一了语义分割（为每个像素分配一个类别标签）和实例分割（检测并分割单个对象实例）。$PQ$ 度量巧妙地分解为两个分量：分割质量 ($SQ$) 和识别质量 ($RQ$)。\n\n设一组真值实例掩码表示为 $\\{g_i\\}$，一组预测实例掩码表示为 $\\{p_j\\}$。基本度量定义如下：\n\n1.  **交并比 (IoU)**：对于一个真值实例 $g$ 和一个预测实例 $p$，IoU 由下式给出：\n    $$ \\text{IoU}(g, p) = \\frac{|g \\cap p|}{|g \\cup p|} $$\n    其中 $|\\cdot|$ 表示集合的基数（像素数）。\n\n2.  **实例匹配**：在真值实例和预测实例之间建立一对一匹配。只有当一对 $(g, p)$ 的 $\\text{IoU}(g, p) > 0.5$ 时，才被视为一个潜在的匹配。在所有潜在配对的可能一对一匹配中，选择使 IoU 总和最大化的那一个。这构成了一个最大权二分图匹配问题。\n    -   **真阳性 ($TP$)**：通过此过程产生的匹配对 $(g, p)$ 的集合。\n    -   **假阴性 ($FN$)**：保持未匹配状态的真值实例的集合。\n    -   **假阳性 ($FP$)**：保持未匹配状态的预测实例的集合。\n\n根据这些计数，定义质量度量：\n\n-   **分割质量 ($SQ$)**：该指标衡量所有正确匹配实例（真阳性）的平均 IoU。它反映了检测到的对象的像素被分割得有多好。\n    $$ SQ = \\frac{\\sum_{(g,p) \\in TP} \\text{IoU}(g,p)}{|TP|} $$\n    按照约定，如果 $|TP|=0$，则 $SQ=0$。\n\n-   **识别质量 ($RQ$)**：这是一个在实例检测层面上计算的 F1 分数。它衡量模型检测对象的好坏，而不管分割的准确性如何。\n    $$ RQ = \\frac{|TP|}{|TP| + \\frac{1}{2}|FP| + \\frac{1}{2}|FN|} = \\frac{2|TP|}{2|TP|+|FP|+|FN|} $$\n\n-   **全景质量 ($PQ$)**：该问题提供了 $PQ$ 的基本定义，即匹配对的总 IoU，并受错误检测数量的惩罚。\n    $$ PQ = \\frac{\\sum_{(g,p) \\in TP} \\text{IoU}(g,p)}{|TP| + \\frac{1}{2}|FP| + \\frac{1}{2}|FN|} $$\n\n**$PQ$ 的分解**：我们可以证明 $PQ$ 是 $SQ$ 和 $RQ$ 的乘积。从 $PQ$ 的定义出发，我们可以将其重写为：\n$$ PQ = \\left( \\frac{\\sum_{(g,p) \\in TP} \\text{IoU}(g,p)}{|TP|} \\right) \\times \\left( \\frac{|TP|}{|TP| + \\frac{1}{2}|FP| + \\frac{1}{2}|FN|} \\right) $$\n此操作在 $|TP| > 0$ 时有效。第一项正是 $SQ$ 的定义，第二项是 $RQ$ 的定义。因此：\n$$ PQ = SQ \\times RQ $$\n如果 $|TP|=0$，那么根据定义 $SQ=0$ 且 $PQ$ 的分子为 $0$，使得 $PQ=0$。$RQ$ 的分子也为 $0$，使得 $RQ=0$。等式 $PQ = SQ \\times RQ$ 成立，因为 $0 = 0 \\times 0$。这种乘法分解表明，$PQ$ 联合衡量了分割和识别质量。$PQ=1$ 的完美得分要求完美的识别（$RQ=1$，意味着没有未匹配的实例）和完美的分割（$SQ=1$，意味着所有匹配的实例的 IoU 均为 $1$）。\n\n-   **语义准确率 ($SA$)**：这是一个更简单的、忽略实例信息的像素级度量。所有正的实例标签都被合并成一个单一的“前景”类别。$SA$ 是预测和真值中语义标签（前景 vs. 背景）相同的像素所占的比例。\n\n### 算法实现与案例分析\n\n实现的核心涉及一个函数，该函数接收真值和预测掩码，识别唯一实例，计算成对的 IoU 矩阵，解决分配问题以找到最优匹配，然后计算各项度量。\n\n-   **匹配**：通过解决最大权二分图匹配问题来找到匹配。我们构建一个成本矩阵，其中将真值实例 $i$ 与预测实例 $j$ 匹配的成本是 $-\\text{IoU}(g_i, p_j)$（如果 $\\text{IoU}(g_i, p_j) > 0.5$），否则为一个大的正数（以防止匹配）。使用 `scipy.optimize.linear_sum_assignment` 来找到最小成本分配，这对应于最大 IoU 总和。\n\n分析是在一个 $10 \\times 10$ 图像上的四个测试案例上进行的。\n\n**案例 A：完美预测**\n-   真值 ($GT$)：1 个实例，大小为 100。\n-   预测 ($Pred$)：1 个实例，大小为 100。\n-   IoU 矩阵：一个值为 $1.0$ 的 $1 \\times 1$ 矩阵。\n-   匹配：单个 $GT$ 实例与单个 $Pred$ 实例匹配，$\\text{IoU}=1.0$。\n-   计数：$|TP|=1$，$|FP|=0$，$|FN|=0$。\n-   度量：\n    -   $SQ = 1.0 / 1 = 1.0$\n    -   $RQ = (2 \\times 1) / (2 \\times 1 + 0 + 0) = 1.0$\n    -   $PQ = SQ \\times RQ = 1.0 \\times 1.0 = 1.0$\n    -   $SA = (100 \\text{ 匹配像素}) / 100 = 1.0$\n-   结果：$[1.0, 1.0, 1.0, 1.0]$\n\n**案例 B：过度合并**\n-   $GT$：2 个实例，$g_1$（大小 60）和 $g_2$（大小 40）。\n-   $Pred$：1 个实例，$p_1$（大小 100）。\n-   IoU：$\\text{IoU}(g_1, p_1) = 60/100 = 0.6$。$\\text{IoU}(g_2, p_1) = 40/100 = 0.4$。\n-   匹配：由于 $\\text{IoU}(g_2, p_1) \\le 0.5$，它不是一个有效的匹配候选。$p_1$ 只能与 $g_1$ 匹配。\n-   计数：$|TP|=1$（对于配对 $(g_1, p_1)$），$|FP|=0$（单个预测实例被匹配），$|FN|=1$（$g_2$ 未匹配）。\n-   度量：\n    -   $SQ = 0.6 / 1 = 0.6$\n    -   $RQ = (2 \\times 1) / (2 \\times 1 + 0 + 1) = 2/3 \\approx 0.666667$\n    -   $PQ = SQ \\times RQ = 0.6 \\times (2/3) = 0.4$\n    -   $SA$：$GT$ 和 $Pred$ 都覆盖了所有 100 个像素，因此它们在语义上是相同的。$SA=1.0$。\n-   结果：$[0.4, 0.6, 0.666667, 1.0]$\n\n**案例 C：过度分割**\n-   $GT$：1 个实例，$g_1$（大小 100）。\n-   $Pred$：2 个实例，$p_1$（大小 60）和 $p_2$（大小 40）。\n-   IoU：$\\text{IoU}(g_1, p_1) = 60/100 = 0.6$。$\\text{IoU}(g_1, p_2) = 40/100 = 0.4$。\n-   匹配：$g_1$ 只能与一个预测匹配。它与 $p_1$ 匹配，因为 $\\text{IoU}(g_1, p_1) > 0.5$。\n-   计数：$|TP|=1$（对于配对 $(g_1, p_1)$），$|FP|=1$（$p_2$ 未匹配），$|FN|=0$（单个 $GT$ 实例被匹配）。\n-   度量：\n    -   $SQ = 0.6 / 1 = 0.6$\n    -   $RQ = (2 \\times 1) / (2 \\times 1 + 1 + 0) = 2/3 \\approx 0.666667$\n    -   $PQ = SQ \\times RQ = 0.6 \\times (2/3) = 0.4$\n    -   $SA$：语义上与 $GT$ 相同，所以 $SA=1.0$。\n-   结果：$[0.4, 0.6, 0.666667, 1.0]$。值得注意的是，这与案例 B 的结果相同，表明 $PQ$ 对一个假合并（1个 $FN$）和一个假分割（1个 $FP$）的惩罚是对称的。\n\n**案例 D：极端过度分割**\n-   $GT$：1 个实例，$g_1$（大小 100）。\n-   $Pred$：4 个实例，$p_1, p_2, p_3, p_4$（每个大小为 25）。\n-   IoU：对于任何 $p_i$，$\\text{IoU}(g_1, p_i) = 25/100 = 0.25$。\n-   匹配：由于所有 IoU 值均为 $0.25$，不严格大于 $0.5$，因此不可能有匹配。\n-   计数：$|TP|=0$，$|FP|=4$（所有四个预测实例都未匹配），$|FN|=1$（$g_1$ 未匹配）。\n-   度量：\n    -   $SQ$：由于 $|TP|=0$，根据定义 $SQ=0.0$。\n    -   $RQ$：由于 $|TP|=0$，$RQ = 0 / (0+4+1) = 0.0$。\n    -   $PQ = SQ \\times RQ = 0.0 \\times 0.0 = 0.0$。\n    -   $SA$：语义上与 $GT$ 相同，所以 $SA=1.0$。\n-   结果：$[0.0, 0.0, 0.0, 1.0]$。这突显了识别中的灾难性失败（$RQ=0$），它将整体 $PQ$ 推向零，尽管单个（但未被识别的）部分的分割质量可能很高，且语义准确率是完美的。\n\n这些案例正确地展示了 $PQ$ 及其分量如何对实例级错误提供细致的评估，而这是语义准确率完全忽略的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import linear_sum_assignment\n\ndef get_test_cases():\n    \"\"\"Generates the four test cases as pairs of (gt_mask, pred_mask).\"\"\"\n    cases = []\n    \n    # Case A: Perfect prediction\n    gt_a = np.ones((10, 10), dtype=int)\n    pred_a = np.ones((10, 10), dtype=int)\n    cases.append(('A', gt_a, pred_a))\n\n    # Case B: Over-merge\n    gt_b = np.zeros((10, 10), dtype=int)\n    gt_b[0:6, :] = 1\n    gt_b[6:10, :] = 2\n    pred_b = np.ones((10, 10), dtype=int)\n    cases.append(('B', gt_b, pred_b))\n\n    # Case C: Over-split\n    gt_c = np.ones((10, 10), dtype=int)\n    pred_c = np.zeros((10, 10), dtype=int)\n    pred_c[0:6, :] = 1\n    pred_c[6:10, :] = 2\n    cases.append(('C', gt_c, pred_c))\n\n    # Case D: Extreme over-split\n    gt_d = np.ones((10, 10), dtype=int)\n    pred_d = np.zeros((10, 10), dtype=int)\n    pred_d[0:5, 0:5] = 1\n    pred_d[0:5, 5:10] = 2\n    pred_d[5:10, 0:5] = 3\n    pred_d[5:10, 5:10] = 4\n    cases.append(('D', gt_d, pred_d))\n    \n    return cases\n\ndef calculate_metrics(gt_mask, pred_mask, iou_threshold=0.5):\n    \"\"\"\n    Computes PQ, SQ, RQ, and SA for a given pair of masks.\n    \"\"\"\n    # 1. Semantic Accuracy (SA)\n    gt_semantic = gt_mask > 0\n    pred_semantic = pred_mask > 0\n    sa = np.mean(gt_semantic == pred_semantic)\n\n    # 2. Instance Extraction\n    gt_ids = np.unique(gt_mask[gt_mask > 0])\n    pred_ids = np.unique(pred_mask[pred_mask > 0])\n    \n    num_gt = len(gt_ids)\n    num_pred = len(pred_ids)\n    \n    if num_gt == 0 and num_pred == 0:\n        return 1.0, 1.0, 1.0, sa # PQ, SQ, RQ, SA\n\n    # 3. IoU Matrix Calculation\n    iou_matrix = np.zeros((num_gt, num_pred))\n    for i, gt_id in enumerate(gt_ids):\n        g_mask = (gt_mask == gt_id)\n        for j, pred_id in enumerate(pred_ids):\n            p_mask = (pred_mask == pred_id)\n            intersection = np.sum(np.logical_and(g_mask, p_mask))\n            union = np.sum(np.logical_or(g_mask, p_mask))\n            iou = intersection / union if union > 0 else 0\n            iou_matrix[i, j] = iou\n\n    # 4. Instance Matching (Maximum Weight Bipartite Matching)\n    # We want to maximize sum of IoUs, which is equivalent to minimizing sum of -IoUs.\n    # Set costs for invalid matches (IoU = threshold) to a high value.\n    cost_matrix = -iou_matrix\n    cost_matrix[iou_matrix = iou_threshold] = 1.0 # high cost for non-matchable pairs\n    \n    gt_ind, pred_ind = linear_sum_assignment(cost_matrix)\n    \n    # Filter matches to only include those above the threshold\n    matched_pairs = []\n    sum_iou = 0.0\n    for r, c in zip(gt_ind, pred_ind):\n        if iou_matrix[r, c] > iou_threshold:\n            matched_pairs.append((r, c))\n            sum_iou += iou_matrix[r, c]\n            \n    # 5. Calculate TP, FP, FN\n    tp = len(matched_pairs)\n    fp = num_pred - tp\n    fn = num_gt - tp\n    \n    # 6. Calculate SQ, RQ, PQ\n    # Segmentation Quality\n    sq = sum_iou / tp if tp > 0 else 0.0\n\n    # Recognition Quality\n    denominator_rq = 2 * tp + fp + fn\n    rq = (2 * tp) / denominator_rq if denominator_rq > 0 else 0.0\n    \n    # Panoptic Quality\n    # Using the product form, which is equivalent to the first-principles definition\n    pq = sq * rq\n    \n    # Round all values to 6 decimal places\n    pq = round(pq, 6)\n    sq = round(sq, 6)\n    rq = round(rq, 6)\n    sa = round(sa, 6)\n    \n    return [pq, sq, rq, sa]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = get_test_cases()\n    \n    all_results = []\n    for name, gt, pred in test_cases:\n        result = calculate_metrics(gt, pred)\n        all_results.append(result)\n\n    # Format the final output string\n    result_strings = []\n    for res in all_results:\n        result_strings.append(f\"[{','.join(map(str, res))}]\")\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3136328"}]}