{"hands_on_practices": [{"introduction": "训练能量模型（EBMs）的基础在于理解其对数似然梯度。本练习 [@problem_id:3122263] 旨在揭示该梯度的基本结构，它由数据驱动的“正相”（positive phase）和模型驱动的“负相”（negative phase）两部分构成。通过解决一个简化的、可解析求解的案例，你将为这个核心概念建立坚实的直观理解。", "problem": "考虑一个能量模型 (Energy-Based Model, EBM)，其输入为二维实值向量 $x \\in \\mathbb{R}^{2}$，其密度 $p_{\\theta}(x)$ 由核心 EBM 原理 $p_{\\theta}(x) = Z(\\theta)^{-1} \\exp(-E_{\\theta}(x))$ 定义，其中配分函数 $Z(\\theta)$ 由 $Z(\\theta) = \\int_{\\mathbb{R}^{2}} \\exp(-E_{\\theta}(x)) \\, dx$ 给出，能量指定为 $E_{\\theta}(x) = \\frac{1}{2} \\|x\\|^{2} - \\theta^{\\top} x$，参数为 $\\theta \\in \\mathbb{R}^{2}$。给定一个包含 $N = 3$ 个二维样本的玩具数据集，\n$$\nx^{(1)} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad\nx^{(2)} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}, \\quad\nx^{(3)} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}.\n$$\n从第一性原理出发，即对数似然和配分函数的定义，推导平均对数似然 $\\ell(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\ln p_{\\theta}(x^{(i)})$ 关于 $\\theta$ 的精确梯度，并明确分离出来自数据期望（常称为正相）的贡献和来自模型期望（常称为负相）的贡献。然后，在参数\n$$\n\\theta = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{3}{2} \\end{pmatrix}\n$$\n处计算得到的精确梯度。\n将最终梯度表示为单个精确的行向量，适当时使用有理数，不要四舍五入。", "solution": "用户希望找到能量模型 (EBM) 的平均对数似然的梯度，并在特定点进行求值。解题过程将分为三个主要阶段：首先，推导梯度的一般形式；其次，通过识别由给定能量函数定义的特定概率分布来简化梯度；最后，使用所提供的数据在指定的参数值处计算该梯度。\n\n对于一个包含 $N$ 个样本 $\\{x^{(i)}\\}_{i=1}^{N}$ 的数据集，平均对数似然 $\\ell(\\theta)$ 由下式给出：\n$$\n\\ell(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\ln p_{\\theta}(x^{(i)})\n$$\n概率密度函数 $p_{\\theta}(x)$ 定义为 $p_{\\theta}(x) = \\frac{1}{Z(\\theta)} \\exp(-E_{\\theta}(x))$，其中 $E_{\\theta}(x)$ 是能量函数，$Z(\\theta)$ 是配分函数。将此代入对数似然表达式可得：\n$$\n\\ell(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( \\ln\\left(\\frac{1}{Z(\\theta)}\\right) + \\ln(\\exp(-E_{\\theta}(x^{(i)}))) \\right)\n$$\n$$\n\\ell(\\theta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left( - \\ln Z(\\theta) - E_{\\theta}(x^{(i)}) \\right)\n$$\n由于 $\\ln Z(\\theta)$ 不依赖于求和索引 $i$，我们可以将其简化为：\n$$\n\\ell(\\theta) = - \\left( \\frac{1}{N} \\sum_{i=1}^{N} E_{\\theta}(x^{(i)}) \\right) - \\ln Z(\\theta)\n$$\n为了求关于参数向量 $\\theta$ 的梯度，我们对 $\\ell(\\theta)$ 求导：\n$$\n\\nabla_{\\theta} \\ell(\\theta) = - \\frac{1}{N} \\sum_{i=1}^{N} \\nabla_{\\theta} E_{\\theta}(x^{(i)}) - \\nabla_{\\theta} \\ln Z(\\theta)\n$$\n该表达式将梯度分为两个部分。我们来逐一分析。\n\n第一部分涉及能量函数 $E_{\\theta}(x) = \\frac{1}{2} \\|x\\|^{2} - \\theta^{\\top} x$ 的梯度。关于 $\\theta$ 求导：\n$$\n\\nabla_{\\theta} E_{\\theta}(x) = \\nabla_{\\theta} \\left( \\frac{1}{2} x^{\\top}x - \\theta^{\\top} x \\right) = -x\n$$\n将此代入对数似然梯度的第一部分：\n$$\n- \\frac{1}{N} \\sum_{i=1}^{N} \\nabla_{\\theta} E_{\\theta}(x^{(i)}) = - \\frac{1}{N} \\sum_{i=1}^{N} (-x^{(i)}) = \\frac{1}{N} \\sum_{i=1}^{N} x^{(i)}\n$$\n这一项是数据的经验均值，通常表示为 $\\mathbb{E}_{\\text{data}}[x]$ 或 $\\bar{x}$。这是来自数据期望的贡献，称为**正相 (positive phase)**。\n\n第二部分是对数配分函数的梯度 $-\\nabla_{\\theta} \\ln Z(\\theta)$。我们使用对数导数技巧：$\\nabla_{\\theta} \\ln Z(\\theta) = \\frac{1}{Z(\\theta)} \\nabla_{\\theta} Z(\\theta)$。配分函数为 $Z(\\theta) = \\int_{\\mathbb{R}^{2}} \\exp(-E_{\\theta}(x)) \\, dx$。使用莱布尼茨积分法则在积分号下求导：\n$$\n\\nabla_{\\theta} Z(\\theta) = \\int_{\\mathbb{R}^{2}} \\nabla_{\\theta} \\exp(-E_{\\theta}(x)) \\, dx = \\int_{\\mathbb{R}^{2}} \\exp(-E_{\\theta}(x)) (-\\nabla_{\\theta} E_{\\theta}(x)) \\, dx\n$$\n使用我们之前的结果 $\\nabla_{\\theta} E_{\\theta}(x) = -x$，我们得到：\n$$\n\\nabla_{\\theta} Z(\\theta) = \\int_{\\mathbb{R}^{2}} x \\exp(-E_{\\theta}(x)) \\, dx\n$$\n因此，对数似然梯度的第二部分是：\n$$\n-\\nabla_{\\theta} \\ln Z(\\theta) = - \\frac{1}{Z(\\theta)} \\int_{\\mathbb{R}^{2}} x \\exp(-E_{\\theta}(x)) \\, dx = - \\int_{\\mathbb{R}^{2}} x \\left( \\frac{\\exp(-E_{\\theta}(x))}{Z(\\theta)} \\right) \\, dx\n$$\n识别出括号中的项是模型的概率密度 $p_{\\theta}(x)$，此积分是在模型分布下 $x$ 的期望值的定义：\n$$\n-\\nabla_{\\theta} \\ln Z(\\theta) = - \\mathbb{E}_{x \\sim p_{\\theta}(x)}[x]\n$$\n这一项是来自模型期望的贡献，称为**负相 (negative phase)**。\n\n结合正相和负相，平均对数似然的完整梯度为：\n$$\n\\nabla_{\\theta} \\ell(\\theta) = \\underbrace{\\frac{1}{N} \\sum_{i=1}^{N} x^{(i)}}_{\\text{正相}} - \\underbrace{\\mathbb{E}_{x \\sim p_{\\theta}(x)}[x]}_{\\text{负相}}\n$$\n为了计算这个值，我们必须找到模型期望 $\\mathbb{E}_{x \\sim p_{\\theta}(x)}[x]$。这需要识别分布 $p_{\\theta}(x)$。我们通过对 $x$ 配方来分析能量函数 $E_{\\theta}(x) = \\frac{1}{2}\\|x\\|^2 - \\theta^{\\top}x$：\n$$\nE_{\\theta}(x) = \\frac{1}{2} (x^{\\top}x) - \\theta^{\\top}x = \\frac{1}{2} (x^{\\top}x - 2\\theta^{\\top}x)\n$$\n$$\n= \\frac{1}{2} (x^{\\top}x - 2\\theta^{\\top}x + \\theta^{\\top}\\theta - \\theta^{\\top}\\theta) = \\frac{1}{2} ( (x-\\theta)^{\\top}(x-\\theta) - \\theta^{\\top}\\theta )\n$$\n$$\n= \\frac{1}{2}\\|x-\\theta\\|^2 - \\frac{1}{2}\\|\\theta\\|^2\n$$\n因此，概率密度为：\n$$\np_{\\theta}(x) = \\frac{1}{Z(\\theta)} \\exp\\left( -\\left(\\frac{1}{2}\\|x-\\theta\\|^2 - \\frac{1}{2}\\|\\theta\\|^2\\right) \\right) = \\frac{\\exp(\\frac{1}{2}\\|\\theta\\|^2)}{Z(\\theta)} \\exp\\left(-\\frac{1}{2} (x-\\theta)^{\\top} I^{-1} (x-\\theta)\\right)\n$$\n其中 $I$ 是 $2 \\times 2$ 的单位矩阵。这是均值为 $\\mu = \\theta$、协方差矩阵为 $\\Sigma = I$ 的二元高斯分布的函数形式。对于 $\\mathbb{R}^d$ 中的一般多元高斯分布 $\\mathcal{N}(\\mu, \\Sigma)$，其归一化常数是 $(2\\pi)^{d/2} |\\det(\\Sigma)|^{1/2}$。在我们的例子中，$d=2$，$\\mu=\\theta$，$\\Sigma=I$，所以归一化常数是 $(2\\pi)^{2/2} |\\det(I)|^{1/2} = 2\\pi$。\n因此，$p_{\\theta}(x) = \\mathcal{N}(x | \\theta, I)$。\n服从高斯分布 $\\mathcal{N}(\\mu, \\Sigma)$ 的随机变量 $x$ 的期望是其均值 $\\mu$。因此：\n$$\n\\mathbb{E}_{x \\sim p_{\\theta}(x)}[x] = \\theta\n$$\n梯度表达式显著简化：\n$$\n\\nabla_{\\theta} \\ell(\\theta) = \\bar{x} - \\theta\n$$\n现在我们可以使用给定的数据和参数值来计算这个梯度。首先，我们计算样本均值 $\\bar{x}$：\n$$\nx^{(1)} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad x^{(2)} = \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix}, \\quad x^{(3)} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n$$\n\\bar{x} = \\frac{1}{3} \\left( x^{(1)} + x^{(2)} + x^{(3)} \\right) = \\frac{1}{3} \\left( \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} + \\begin{pmatrix} 2 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right) = \\frac{1}{3} \\begin{pmatrix} 0+2+1 \\\\ 1+0+1 \\end{pmatrix} = \\frac{1}{3} \\begin{pmatrix} 3 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\frac{2}{3} \\end{pmatrix}\n$$\n在 $\\theta = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{3}{2} \\end{pmatrix}$ 处计算梯度：\n$$\n\\nabla_{\\theta} \\ell(\\theta) = \\begin{pmatrix} 1 \\\\ \\frac{2}{3} \\end{pmatrix} - \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} 1 - \\frac{1}{2} \\\\ \\frac{2}{3} - \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{4}{6} - \\frac{9}{6} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{5}{6} \\end{pmatrix}\n$$\n题目要求最终梯度为单个精确的行向量。这是我们计算出的列向量的转置。\n$$\n\\left( \\nabla_{\\theta} \\ell(\\theta) \\right)^{\\top} = \\begin{pmatrix} \\frac{1}{2} & -\\frac{5}{6} \\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{1}{2} & -\\frac{5}{6} \\end{pmatrix}}\n$$", "id": "3122263"}, {"introduction": "仅仅训练模型是不够的，我们还必须验证学到的能量函数是否准确地反映了数据的分布。本实践 [@problem_id:3122243] 介绍了一种在小型离散数据集上评估 EBM 校准度的稳健方法。它演示了如何运用秩相关指标，来比较模型基于能量的排序与经验数据的排序之间的一致性，这是验证和调试 EBM 的一项关键技能。", "problem": "给定一个离散结果的有限集和一个基于能量的模型（Energy-Based Model, EBM）。EBM 通过一个由 $\\theta$ 参数化的能量函数 $E_\\theta(x)$ 为每个结果分配一个标量能量。对于一个离散样本空间 $\\mathcal{X}$，该模型定义了一个在 $\\mathcal{X}$ 上与 $\\exp(-E_\\theta(x))$ 成正比的概率分布。您的任务是设计并实现一个小型、自包含的实验，通过使用基于秩的度量来验证 $E_\\theta(x)$ 是否与经验数据分布一致，从而评估 $E_\\theta(x)$ 在小数据集上的校准情况。\n\n从基于能量的模型（EBM）在有限集 $\\mathcal{X}$ 上的基本定义出发，仅使用基于秩的度量来检验是否能量越低对应越高的经验概率。为此，请根据提供的能量计算配分函数 $Z_\\theta$，并将向量 $E_\\theta(x)+\\log Z_\\theta$ 与使用加性（Laplace）平滑从数据中计算出的向量 $-\\log \\hat{p}_{\\text{data}}(x)$ 进行比较。所有对数必须是自然对数。请使用以下精确的实验设计和计算规则。\n\n基本原理和定义：\n- 一个基于能量的模型（EBM）在有限集 $\\mathcal{X}$ 上为每个 $x \\in \\mathcal{X}$ 分配一个能量 $E_\\theta(x) \\in \\mathbb{R}$，并定义一个在 $\\mathcal{X}$ 上与 $\\exp(-E_\\theta(x))$ 成正比的概率分布 $p_\\theta(x)$。\n- 配分函数 $Z_\\theta$ 是通过在 $\\mathcal{X}$ 上求有限和得到的归一化常数。\n- 经验数据分布 $\\hat{p}_{\\text{data}}(x)$ 是从观测计数通过强度为 $\\alpha$ 的加性（Laplace）平滑估计得出的，定义为 $\\hat{p}_{\\text{data}}(x) = \\dfrac{n_x + \\alpha}{N + \\alpha K}$，其中 $n_x$ 是结果 $x$ 的计数，$N = \\sum_{x \\in \\mathcal{X}} n_x$ 是观测总数，$K = |\\mathcal{X}|$ 是不同结果的数量。\n\n计算协议：\n- 使用数值稳定的 log-sum-exp 方法对向量 $-E_\\theta(x)$ 进行计算，以获得 $\\log Z_\\theta$。\n- 计算向量 $v_{\\text{model}}(x) = E_\\theta(x) + \\log Z_\\theta$。\n- 使用加性平滑 $\\alpha = 1$ 计算平滑后的经验分布 $\\hat{p}_{\\text{data}}(x)$，然后计算 $v_{\\text{data}}(x) = -\\log \\hat{p}_{\\text{data}}(x)$。\n- 评估比较由 $v_{\\text{model}}$ 和 $v_{\\text{data}}$ 导出的排序的基于秩的校准度量：\n  1. $v_{\\text{model}}$ 和 $v_{\\text{data}}$ 之间的 Spearman 秩相关系数 $\\rho_S$。\n  2. $v_{\\text{model}}$ 和 $v_{\\text{data}}$ 之间的 Kendall 秩相关系数 $\\tau$。\n  3. Top-1 一致性，作为一个布尔值，指示在指定的平局打破规则下，$v_{\\text{model}}$ 的最小元素是否与 $v_{\\text{data}}$ 的最小元素匹配。\n  4. Top-2 重叠度，定义为在指定的平局打破规则下，$v_{\\text{model}}$ 的两个最小元素集合与 $v_{\\text{data}}$ 的两个最小元素集合之间的重叠部分的分数（以小数表示）。\n  5. 成对一致性率，定义为无序索引对中，其排序（或相等关系）在使用成对差异的符号进行比较时，在 $v_{\\text{model}}$ 和 $v_{\\text{data}}$ 之间保持一致的分数（以小数表示）。\n\n平局打破规则：\n- 在排序以识别 top-k 元素时，按值升序对索引进行排序，并按索引升序打破平局（即，按序对 $(\\text{值}, \\text{索引})$ 进行字典序排序）。这确保了恰好选择 $k$ 个索引。\n\nNaN 处理：\n- 如果 $\\rho_S$ 或 $\\tau$ 因退化输入（例如，常数向量）而不是数字，则将相应的度量值设置为 $0.0$。\n\n四舍五入：\n- 将所有浮点度量输出四舍五入到 $6$ 位小数。Top-1 一致性必须是布尔值。\n\n测试套件：\n实现您的程序以评估以下四个测试用例。在所有情况下，结果空间为 $\\mathcal{X} = \\{0,1,2,3,4\\}$，因此 $K = 5$。\n- 测试用例 1（通过构造实现的近乎完美的校准）：\n  - 计数：$\\mathbf{c}^{(1)} = [\\,50,\\,30,\\,10,\\,7,\\,3\\,]$。\n  - 能量构造：令 $N^{(1)} = \\sum_i c^{(1)}_i = 100$，定义 $p^{(1)}_i = c^{(1)}_i / N^{(1)}$，并为 $i \\in \\{0,1,2,3,4\\}$ 设置 $E^{(1)}_i = -\\log p^{(1)}_i + 0.3$。\n- 测试用例 2（带有受控噪声的中度不匹配）：\n  - 计数：$\\mathbf{c}^{(2)} = [\\,40,\\,25,\\,20,\\,10,\\,5\\,]$。\n  - 能量构造：令 $N^{(2)} = \\sum_i c^{(2)}_i = 100$，定义 $p^{(2)}_i = c^{(2)}_i / N^{(2)}$，并设置 $E^{(2)}_i = -\\log p^{(2)}_i + 0.2 + \\epsilon_i$，其中 $\\boldsymbol{\\epsilon} = [\\,0.05,\\,-0.02,\\,0.1,\\,-0.05,\\,-0.08\\,]$。\n- 测试用例 3（均匀数据和恒定能量；退化排名）：\n  - 计数：$\\mathbf{c}^{(3)} = [\\,20,\\,20,\\,20,\\,20,\\,20\\,]$。\n  - 能量：$E^{(3)} = [\\,2,\\,2,\\,2,\\,2,\\,2\\,]$。\n- 测试用例 4（带有零计数的极端偏斜和未校准的能量）：\n  - 计数：$\\mathbf{c}^{(4)} = [\\,0,\\,1,\\,0,\\,0,\\,99\\,]$。\n  - 能量：$E^{(4)} = [\\,1.0,\\,2.0,\\,3.0,\\,4.0,\\,5.0\\,]$。\n\n输出规范：\n- 对于每个测试用例，按顺序 $[\\,\\rho_S,\\,\\tau,\\,\\text{top1},\\,\\text{top2overlap},\\,\\text{pairwiseConcordance}\\,]$ 计算度量。\n- 您的程序应生成单行输出，其中包含一个类似 Python 的列表的列表，每个内部列表对应一个测试用例，其中的值按上述顺序排列，并根据指定进行四舍五入或作为布尔值。例如，输出必须看起来像单行的 $[[\\dots],[\\dots],[\\dots],[\\dots]]$。\n\n本问题不涉及任何物理单位或角度。所有计算必须是纯数学的，并遵循上述定义和规则。程序必须完全自包含，不得要求任何用户输入或外部文件。", "solution": "我们从基于能量的模型（EBM）在有限集 $\\mathcal{X}$ 上的基本定义开始。EBM 为每个 $x \\in \\mathcal{X}$ 分配一个能量 $E_\\theta(x)$，并定义一个与 $\\exp(-E_\\theta(x))$ 成正比的概率分布 $p_\\theta(x)$。具体来说，对于有限的 $\\mathcal{X}$，我们有\n$$\np_\\theta(x) = \\frac{\\exp(-E_\\theta(x))}{Z_\\theta},\n$$\n其中配分函数 $Z_\\theta$ 定义为\n$$\nZ_\\theta = \\sum_{x' \\in \\mathcal{X}} \\exp\\big(-E_\\theta(x')\\big).\n$$\n通过对模型分布取负对数，我们得到\n$$\n-\\log p_\\theta(x) = -\\log \\left( \\frac{\\exp(-E_\\theta(x))}{Z_\\theta} \\right)\n= - \\big( -E_\\theta(x) - \\log Z_\\theta \\big)\n= E_\\theta(x) + \\log Z_\\theta.\n$$\n这表明模型下的负对数概率可以分解为能量和对数配分函数。在这种情况下，校准意味着 $E_\\theta(x) + \\log Z_\\theta$ 与 $-\\log p_{\\text{data}}(x)$ 一致，其中 $p_{\\text{data}}(x)$ 是真实的数据分布。在小数据集上，我们使用平滑的经验分布来近似 $p_{\\text{data}}(x)$。\n\n为了稳健地估计数据分布，我们采用强度为 $\\alpha = 1$ 的加性（Laplace）平滑。对于计数 $\\{n_x\\}_{x \\in \\mathcal{X}}$，总计数 $N = \\sum_{x \\in \\mathcal{X}} n_x$，以及 $K = |\\mathcal{X}|$，我们设置\n$$\n\\hat{p}_{\\text{data}}(x) = \\frac{n_x + \\alpha}{N + \\alpha K}.\n$$\n这避免了零概率，并使得即使某些 $n_x$ 为零时，$-\\log \\hat{p}_{\\text{data}}(x)$ 也是有限的。\n\n目标是检验由 $E_\\theta(x) + \\log Z_\\theta$ 导出的排序是否与由 $-\\log \\hat{p}_{\\text{data}}(x)$ 导出的排序相匹配。基于秩的度量对于加性常数和单调重缩放是不变的，这使其适合于评估校准，而无需达到完美的尺度相等。我们使用以下基于秩的度量：\n- Spearman 秩相关系数 $\\rho_S$，它是秩变量的 Pearson 相关系数，用于衡量单调关系的强度。如果任一输入为常数，$\\rho_S$ 未定义；在这种情况下，我们将其设置为 $0.0$。\n- Kendall 秩相关系数 $\\tau$，它衡量一致对数和不一致对数之差，并由总对数归一化。如果由于退化而未定义，我们将其设置为 $0.0$。\n- Top-1 一致性，一个布尔值，如果 $v_{\\text{model}}(x) = E_\\theta(x) + \\log Z_\\theta$ 中最小值的索引与 $v_{\\text{data}}(x) = -\\log \\hat{p}_{\\text{data}}(x)$ 中最小值的索引匹配（使用确定性的平局打破规则），则为 $\\mathrm{True}$。\n- Top-2 重叠度，即 $v_{\\text{model}}$ 和 $v_{\\text{data}}$ 中两个最小元素索引集合之间共享的索引的分数（小数），同样使用确定性的平局打破规则。计算公式为 $\\frac{|S_{\\text{model}} \\cap S_{\\text{data}}|}{2}$，其中两个集合的大小均为 $2$。\n- 成对一致性率，即在 $v_{\\text{model}}$ 和 $v_{\\text{data}}$ 中相对顺序相同的无序对的分数（小数）。对于索引 $i \\neq j$，定义 $\\operatorname{sgn}(a) \\in \\{-1,0,1\\}$ 为 $a$ 的符号。如果 $\\operatorname{sgn}\\big(v_{\\text{model}}(i) - v_{\\text{model}}(j)\\big) = \\operatorname{sgn}\\big(v_{\\text{data}}(i) - v_{\\text{data}}(j)\\big)$，则一对 $(i,j)$ 是一致的。\n\n算法细节：\n1. 对每个测试用例，构造能量向量 $\\{E_i\\}_{i=0}^{K-1}$ 和计数向量 $\\{c_i\\}_{i=0}^{K-1}$，其中 $K = 5$。\n2. 使用数值稳定的 log-sum-exp 方法对 $-E$ 计算 $\\log Z_\\theta$：\n   - 令 $a_i = -E_i$ 和 $m = \\max_i a_i$。则\n     $$\n     \\log Z_\\theta = m + \\log\\left( \\sum_{i=0}^{K-1} \\exp(a_i - m) \\right).\n     $$\n   这通过重新中心化来避免上溢和下溢。\n3. 构造 $v_{\\text{model}}$ 为 $v_{\\text{model},i} = E_i + \\log Z_\\theta$。\n4. 使用 $\\alpha = 1$ 计算平滑的经验概率：\n   $$\n   \\hat{p}_i = \\frac{c_i + 1}{N + 5}, \\quad \\text{其中 } N = \\sum_{i=0}^{4} c_i.\n   $$\n   然后设置 $v_{\\text{data},i} = -\\log \\hat{p}_i$。\n5. 计算 $v_{\\text{model}}$ 和 $v_{\\text{data}}$ 之间的 $\\rho_S$ 和 $\\tau$。如果其中任何一个不是数字，则将其设置为 $0.0$。\n6. 使用在 $(\\text{值}, \\text{索引})$ 上的字典序平局打破规则来识别 top-k 索引。对于 top-1，比较两个向量中的单个最小索引是否相等以生成布尔值。对于 top-2，计算两个索引集合的交集大小，然后除以 $2$ 以生成小数。\n7. 通过迭代所有无序对 $\\{(i,j) \\mid 0 \\le i  j \\le 4\\}$ 来计算成对一致性，按定义比较差异的符号，并将一致对的数量除以总对数 $\\binom{5}{2} = 10$。\n8. 将所有浮点度量四舍五入到 $6$ 位小数；将 top-1 一致性作为布尔值输出。\n\n测试用例说明：\n- 测试用例 1 被构造成近乎完美校准：$E_i = -\\log p_i + 0.3$，其中 $p_i = c_i / 100$。由于在此构造中配分函数满足 $\\log Z_\\theta = -0.3$，我们精确得到 $E_i + \\log Z_\\theta = -\\log p_i$，因此秩匹配。基于秩的度量应显示出强一致性。\n- 测试用例 2 在校准的能量上添加了受控噪声 $\\epsilon_i$ 和一个常数偏移，造成了适度的偏差。排名应大体一致，但不会完美。\n- 测试用例 3 具有均匀的计数和恒定的能量。$v_{\\text{model}}$ 和 $v_{\\text{data}}$ 都是常数，导致相关性度量未定义，我们按规则将其设置为 $0.0$。Top-k 度量由平局打破规则确定。\n- 测试用例 4 具有高度偏斜的零计数和一个严重未校准的能量排序。使用 $\\alpha = 1$ 的平滑避免了无穷大。基于秩的度量应反映出较差的一致性。\n\n最终程序为四个测试用例实现了这些步骤，为每个用例按顺序 $[\\,\\rho_S,\\,\\tau,\\,\\text{top1},\\,\\text{top2overlap},\\,\\text{pairwiseConcordance}\\,]$ 计算度量，将浮点值四舍五入到 $6$ 位小数，并打印包含这些列表的 Python 风格列表的单行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import spearmanr, kendalltau\n\ndef stable_logsumexp(a: np.ndarray) - float:\n    \"\"\"\n    Compute log(sum(exp(a))) in a numerically stable way.\n    \"\"\"\n    m = np.max(a)\n    return float(m + np.log(np.sum(np.exp(a - m))))\n\ndef lex_top_k_indices(values: np.ndarray, k: int) - np.ndarray:\n    \"\"\"\n    Return indices of the k smallest values using lexicographic tie-breaking:\n    first by value ascending, then by index ascending.\n    \"\"\"\n    idx = np.arange(values.shape[0])\n    # np.lexsort sorts by last key first; we want to sort by values then index.\n    order = np.lexsort((idx, values))\n    return order[:k]\n\ndef pairwise_concordance(v1: np.ndarray, v2: np.ndarray) - float:\n    \"\"\"\n    Compute the fraction of unordered pairs whose ordering (or equality) is consistent\n    between v1 and v2 using sign of pairwise differences.\n    \"\"\"\n    n = v1.shape[0]\n    total_pairs = n * (n - 1) // 2\n    concordant = 0\n    for i in range(n):\n        for j in range(i + 1, n):\n            d1 = v1[i] - v1[j]\n            d2 = v2[i] - v2[j]\n            s1 = 0\n            if d1  0:\n                s1 = 1\n            elif d1  0:\n                s1 = -1\n            s2 = 0\n            if d2  0:\n                s2 = 1\n            elif d2  0:\n                s2 = -1\n            if s1 == s2:\n                concordant += 1\n    return concordant / total_pairs if total_pairs  0 else 0.0\n\ndef metrics_for_case(energies: np.ndarray, counts: np.ndarray, alpha: float = 1.0, top_k: int = 2):\n    \"\"\"\n    Compute v_model = E + logZ and v_data = -log p_hat with Laplace smoothing alpha,\n    then compute rank-based metrics:\n      - Spearman rho_S\n      - Kendall tau\n      - Top-1 agreement (boolean)\n      - Top-k overlap fraction (decimal)\n      - Pairwise concordance fraction (decimal)\n    Returns a list: [rho_S, tau, top1_bool, topk_overlap, pairwise_conc].\n    \"\"\"\n    # Compute log Z via stable log-sum-exp on -energies\n    logZ = stable_logsumexp(-energies)\n\n    # Model negative log values\n    v_model = energies + logZ\n\n    # Smoothed empirical probabilities\n    N = np.sum(counts)\n    K = counts.shape[0]\n    p_hat = (counts.astype(float) + alpha) / (N + alpha * K)\n\n    # Data negative log values\n    v_data = -np.log(p_hat)\n\n    # Spearman correlation\n    spearman_corr = spearmanr(v_model, v_data).correlation\n    if np.isnan(spearman_corr):\n        spearman_corr = 0.0\n\n    # Kendall tau\n    kendall_corr = kendalltau(v_model, v_data).correlation\n    if np.isnan(kendall_corr):\n        kendall_corr = 0.0\n\n    # Top-1 agreement using deterministic tie-breaking\n    top1_model_idx = lex_top_k_indices(v_model, 1)[0]\n    top1_data_idx = lex_top_k_indices(v_data, 1)[0]\n    top1_agree = (int(top1_model_idx) == int(top1_data_idx))\n\n    # Top-k overlap\n    k = top_k\n    topk_model = set(lex_top_k_indices(v_model, k).tolist())\n    topk_data = set(lex_top_k_indices(v_data, k).tolist())\n    overlap_fraction = len(topk_model.intersection(topk_data)) / k\n\n    # Pairwise concordance\n    conc_fraction = pairwise_concordance(v_model, v_data)\n\n    # Round float metrics to 6 decimals\n    rho_S = round(float(spearman_corr), 6)\n    tau = round(float(kendall_corr), 6)\n    topk_overlap = round(float(overlap_fraction), 6)\n    conc_fraction = round(float(conc_fraction), 6)\n\n    return [rho_S, tau, top1_agree, topk_overlap, conc_fraction]\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    # Case 1: near-perfect calibration by construction\n    counts1 = np.array([50, 30, 10, 7, 3], dtype=float)  # N=100\n    p1 = counts1 / np.sum(counts1)\n    c_shift1 = 0.3\n    energies1 = -np.log(p1) + c_shift1\n\n    # Case 2: moderate mismatch with controlled noise\n    counts2 = np.array([40, 25, 20, 10, 5], dtype=float)  # N=100\n    p2 = counts2 / np.sum(counts2)\n    c_shift2 = 0.2\n    noise2 = np.array([0.05, -0.02, 0.1, -0.05, -0.08], dtype=float)\n    energies2 = -np.log(p2) + c_shift2 + noise2\n\n    # Case 3: uniform data, constant energies\n    counts3 = np.array([20, 20, 20, 20, 20], dtype=float)  # N=100\n    energies3 = np.array([2, 2, 2, 2, 2], dtype=float)\n\n    # Case 4: extreme skew with zeros, miscalibrated energies\n    counts4 = np.array([0, 1, 0, 0, 99], dtype=float)  # N=100\n    energies4 = np.array([1.0, 2.0, 3.0, 4.0, 5.0], dtype=float)\n\n    test_cases = [\n        (energies1, counts1),\n        (energies2, counts2),\n        (energies3, counts3),\n        (energies4, counts4),\n    ]\n\n    results = []\n    for E, c in test_cases:\n        res = metrics_for_case(E, c, alpha=1.0, top_k=2)\n        results.append(res)\n\n    # Final print statement in the exact required format: single line list of lists.\n    print(str(results))\n\nsolve()\n```", "id": "3122243"}, {"introduction": "能量模型最强大的特性之一，是通过其能量函数的简单算术运算来进行组合。本练习 [@problem_id:3122280] 探索了这种“可组合性”（compositionality）的概念，展示了如何通过叠加两个类别条件模型的能量，来在它们之间创造出平滑的插值。你将推导所得插值模型的属性，并通过数值测试来理解 EBM 这一优雅而实用的特性。", "problem": "考虑一个基于能量的模型（Energy-Based Model, EBM），即一个为数据分配能量函数并通过指数化和归一化将其转换为概率密度的模型。对于手写数字的类条件设置，假设我们有一个能量函数 $E_{\\theta}(x \\mid y)$，它作用于以类别标签 $y$ 为条件的特征向量 $x \\in \\mathbb{R}^d$，其中 $\\theta$ 表示参数。$x$ 在给定类别 $y$ 下的概率密度定义为\n$$\np_{\\theta}(x \\mid y) = \\frac{\\exp\\left(-E_{\\theta}(x \\mid y)\\right)}{Z_{\\theta}(y)},\n$$\n其中 $Z_{\\theta}(y)$ 是确保归一化的配分函数。\n\n从基于能量模型的核心定义出发，提出一种二次型形式的类条件能量，该形式适用于手写数字的中维特征（例如，圆度和倾斜度），即\n$$\nE_{\\theta}(x \\mid y) = \\frac{1}{2} \\left(x - \\mu_y\\right)^{\\top} \\Sigma_y^{-1} \\left(x - \\mu_y\\right),\n$$\n其中 $\\mu_y \\in \\mathbb{R}^d$ 是一个依赖于类别的均值，$\\Sigma_y \\in \\mathbb{R}^{d \\times d}$ 是一个对称正定协方差矩阵。这一选择确保了有限的配分函数和明确定义的概率密度。\n\n通过加性能量定义两个类别 $y_0$ 和 $y_1$ 的插值\n$$\nE_{\\alpha}(x) = \\alpha \\, E_{\\theta}(x \\mid y_0) + (1 - \\alpha) \\, E_{\\theta}(x \\mid y_1),\n$$\n其中插值权重为 $\\alpha \\in [0,1]$。证明 $E_{\\alpha}(x)$ 同样是二次型，因此在 $x$ 上导出高斯密度，并从第一性原理推导其均值和协方差的闭式解。\n\n实现一个程序，在给定特定的类别参数和插值权重的情况下，计算插值后高斯分布的均值和协方差，然后根据以下量化标准测试“能量相加是否能产生有意义的类别插值”：\n- 边界一致性：当 $\\alpha = 0$ 时，插值分布与类别 $y_1$ 的分布一致；当 $\\alpha = 1$ 时，与类别 $y_0$ 的分布一致。\n- 等协方差下的线性均值插值：如果 $\\Sigma_{y_0} = \\Sigma_{y_1}$，那么插值均值等于线性插值 $\\alpha \\mu_{y_0} + (1-\\alpha)\\mu_{y_1}$。\n- 不等协方差下的精度加权偏差：如果 $\\Sigma_{y_1}$ 在连接 $\\mu_{y_0}$ 和 $\\mu_{y_1}$ 的直线方向上的方差小于 $\\Sigma_{y_0}$，那么插值均值会比朴素的线性插值所建议的更偏向于 $\\mu_{y_1}$。\n- 平稳性：在插值均值处计算的 $E_{\\alpha}(x)$ 的梯度为零向量。\n- 方差边界：当 $\\Sigma_{y_0}$ 和 $\\Sigma_{y_1}$ 均为对角矩阵时，插值协方差的每个坐标都位于 $\\Sigma_{y_0}$ 和 $\\Sigma_{y_1}$ 相应坐标之间。\n\n使用以下测试套件，其中 $d = 2$，参数如下所示。在所有情况下，将 $y_0$ 和 $y_1$ 视为两个数字类别：\n\n- 测试 $1$（$\\alpha = 0$ 时的边界）：$\\mu_{y_0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_0} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$；$\\mu_{y_1} = \\begin{bmatrix} 2 \\\\ 1 \\end{bmatrix}$，$\\Sigma_{y_1} = \\begin{bmatrix} 0.5  0 \\\\ 0  0.5 \\end{bmatrix}$；$\\alpha = 0$。检查 $\\mu_{\\alpha} = \\mu_{y_1}$ 和 $\\Sigma_{\\alpha} = \\Sigma_{y_1}$ 是否都成立。\n- 测试 $2$（等协方差且 $\\alpha = 0.3$）：$\\mu_{y_0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_0} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$；$\\mu_{y_1} = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_1} = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix}$；$\\alpha = 0.3$。检查 $\\mu_{\\alpha} = \\alpha \\mu_{y_0} + (1 - \\alpha)\\mu_{y_1}$ 是否成立。\n- 测试 $3$（不等协方差且 $\\alpha = 0.5$ 时的偏差）：$\\mu_{y_0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_0} = \\begin{bmatrix} 1.0  0 \\\\ 0  0.5 \\end{bmatrix}$；$\\mu_{y_1} = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_1} = \\begin{bmatrix} 0.25  0 \\\\ 0  0.5 \\end{bmatrix}$；$\\alpha = 0.5$。设 $t$ 为标量，使得 $\\mu_{\\alpha}$ 在从 $\\mu_{y_0}$ 到 $\\mu_{y_1}$ 的直线上的投影满足 $\\mu_{\\alpha} = \\mu_{y_0} + t(\\mu_{y_1} - \\mu_{y_0})$。检查 $t > \\alpha$ 和 $0 \\le t \\le 1$ 是否成立。\n- 测试 $4$（非对角协方差且 $\\alpha = 0.4$ 时的平稳性）：$\\mu_{y_0} = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}$，$\\Sigma_{y_0} = \\begin{bmatrix} 1.0  0.3 \\\\ 0.3  1.0 \\end{bmatrix}$；$\\mu_{y_1} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$，$\\Sigma_{y_1} = \\begin{bmatrix} 1.5  -0.2 \\\\ -0.2  1.0 \\end{bmatrix}$；$\\alpha = 0.4$。检查 $\\nabla E_{\\alpha}(\\mu_{\\alpha}) = \\mathbf{0}$ 是否成立。\n- 测试 $5$（对角协方差且 $\\alpha = 0.75$ 时的方差边界）：$\\mu_{y_0} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_0} = \\begin{bmatrix} 1.0  0 \\\\ 0  4.0 \\end{bmatrix}$；$\\mu_{y_1} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$，$\\Sigma_{y_1} = \\begin{bmatrix} 9.0  0 \\\\ 0  0.25 \\end{bmatrix}$；$\\alpha = 0.75$。检查 $\\Sigma_{\\alpha}$ 的每个对角线元素是否都位于 $\\Sigma_{y_0}$ 和 $\\Sigma_{y_1}$ 相应元素之间。\n\n你的程序应该生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4,\\text{result}_5\\right]$），其中每个条目都是一个布尔值，指示相应的测试是否通过。", "solution": "问题陈述已经过验证，被认为是合理的。它在科学上基于能量模型和多元统计的原理，问题提法清晰，提供了所有必要的信息，并使用客观、正式的语言进行阐述。这些任务在数学上是可处理和可验证的。\n\n该问题要求我们分析由两个二次能量函数（对应于两个类条件高斯分布）的线性组合所形成的插值能量函数的性质。主要任务是推导所得分布的参数，然后通过一系列数值测试来验证该插值方案的几个关键属性。\n\n### 基于原理的插值高斯参数推导\n\n基于能量的模型通过能量函数 $E(x)$ 定义了变量 $x$ 上的概率分布，即 $p(x) \\propto \\exp(-E(x))$。给定的类条件能量函数是：\n$$\nE_{\\theta}(x \\mid y) = \\frac{1}{2} (x - \\mu_y)^{\\top} \\Sigma_y^{-1} (x - \\mu_y)\n$$\n这在相差一个加性常数的情况下，是多元高斯分布 $N(x; \\mu_y, \\Sigma_y)$ 的负对数似然。矩阵 $\\Sigma_y^{-1}$ 被称为精度矩阵。\n\n两个类别 $y_0$ 和 $y_1$ 的插值能量定义为：\n$$\nE_{\\alpha}(x) = \\alpha E_{\\theta}(x \\mid y_0) + (1 - \\alpha) E_{\\theta}(x \\mid y_1)\n$$\n其中 $\\alpha \\in [0,1]$ 是插值权重。\n\n为了证明 $E_{\\alpha}(x)$ 也是二次型的，并找到其对应高斯分布的参数，我们首先代入能量函数的显式形式：\n$$\nE_{\\alpha}(x) = \\frac{\\alpha}{2} (x - \\mu_{y_0})^{\\top} \\Sigma_{y_0}^{-1} (x - \\mu_{y_0}) + \\frac{1-\\alpha}{2} (x - \\mu_{y_1})^{\\top} \\Sigma_{y_1}^{-1} (x - \\mu_{y_1})\n$$\n我们展开二次项。假设 $P$ 是对称的（精度矩阵就是对称的），一个通用的二次型 $(x - \\mu)^{\\top}P(x - \\mu)$ 可以展开为 $x^{\\top}Px - 2\\mu^{\\top}Px + \\mu^{\\top}P\\mu$。应用此公式，我们得到：\n$$\n2E_{\\alpha}(x) = \\alpha (x^{\\top}\\Sigma_{y_0}^{-1}x - 2\\mu_{y_0}^{\\top}\\Sigma_{y_0}^{-1}x + C_0) + (1-\\alpha) (x^{\\top}\\Sigma_{y_1}^{-1}x - 2\\mu_{y_1}^{\\top}\\Sigma_{y_1}^{-1}x + C_1)\n$$\n其中 $C_0$ 和 $C_1$ 是相对于 $x$ 的常数。我们可以根据各项对 $x$ 的依赖性进行分组：\n$$\n2E_{\\alpha}(x) = x^{\\top} \\left( \\alpha\\Sigma_{y_0}^{-1} + (1-\\alpha)\\Sigma_{y_1}^{-1} \\right) x - 2 \\left( \\alpha\\mu_{y_0}^{\\top}\\Sigma_{y_0}^{-1} + (1-\\alpha)\\mu_{y_1}^{\\top}\\Sigma_{y_1}^{-1} \\right) x + C_{total}\n$$\n这个表达式显然是 $x$ 的一个二次函数。我们可以将此形式与高斯分布 $N(x; \\mu_{\\alpha}, \\Sigma_{\\alpha})$ 的通用能量函数 $E(x) = \\frac{1}{2}(x - \\mu_{\\alpha})^{\\top}\\Sigma_{\\alpha}^{-1}(x - \\mu_{\\alpha}) + \\text{const}$ 进行匹配。展开后得到：\n$$\n2E(x) = x^{\\top}\\Sigma_{\\alpha}^{-1}x - 2\\mu_{\\alpha}^{\\top}\\Sigma_{\\alpha}^{-1}x + \\text{const}\n$$\n通过比较能量的两个表达式中二次项 ($x^{\\top}(\\cdot)x$) 和线性项 ($(\\cdot)x$) 的系数，我们可以确定插值分布的参数 $\\mu_{\\alpha}$ 和 $\\Sigma_{\\alpha}$。\n\n1.  **插值协方差**：比较二次项，我们找到插值分布的逆协方差（精度矩阵）$\\Sigma_{\\alpha}^{-1}$：\n    $$\n    \\Sigma_{\\alpha}^{-1} = \\alpha \\Sigma_{y_0}^{-1} + (1 - \\alpha) \\Sigma_{y_1}^{-1}\n    $$\n    这表明“能量相加”对应于精度矩阵的线性插值。新的协方差矩阵是该结果的逆：\n    $$\n    \\Sigma_{\\alpha} = \\left( \\alpha \\Sigma_{y_0}^{-1} + (1 - \\alpha) \\Sigma_{y_1}^{-1} \\right)^{-1}\n    $$\n    由于 $\\Sigma_{y_0}$ 和 $\\Sigma_{y_1}$ 是正定的且 $\\alpha \\in [0,1]$，$\\Sigma_{y_0}^{-1}$ 和 $\\Sigma_{y_1}^{-1}$ 也是正定的。它们的加权和 $\\Sigma_{\\alpha}^{-1}$ 也是正定的，这确保了 $\\Sigma_{\\alpha}$ 是良定义且正定的。\n\n2.  **插值均值**：比较线性项，我们有：\n    $$\n    \\mu_{\\alpha}^{\\top}\\Sigma_{\\alpha}^{-1} = \\alpha\\mu_{y_0}^{\\top}\\Sigma_{y_0}^{-1} + (1-\\alpha)\\mu_{y_1}^{\\top}\\Sigma_{y_1}^{-1}\n    $$\n    为了求解 $\\mu_{\\alpha}$，我们可以对两边进行转置，然后前乘以 $\\Sigma_{\\alpha}$：\n    $$\n    (\\mu_{\\alpha}^{\\top}\\Sigma_{\\alpha}^{-1})^{\\top} = (\\alpha\\mu_{y_0}^{\\top}\\Sigma_{y_0}^{-1} + (1-\\alpha)\\mu_{y_1}^{\\top}\\Sigma_{y_1}^{-1})^{\\top}\n    $$\n    $$\n    (\\Sigma_{\\alpha}^{-1})^{\\top} \\mu_{\\alpha} = (\\alpha\\Sigma_{y_0}^{-1})^{\\top}\\mu_{y_0} + ((1-\\alpha)\\Sigma_{y_1}^{-1})^{\\top}\\mu_{y_1}\n    $$\n    由于精度矩阵是对称的，这可以简化为：\n    $$\n    \\Sigma_{\\alpha}^{-1} \\mu_{\\alpha} = \\alpha\\Sigma_{y_0}^{-1}\\mu_{y_0} + (1-\\alpha)\\Sigma_{y_1}^{-1}\\mu_{y_1}\n    $$\n    最后，前乘以 $\\Sigma_{\\alpha}$：\n    $$\n    \\mu_{\\alpha} = \\Sigma_{\\alpha} \\left( \\alpha\\Sigma_{y_0}^{-1}\\mu_{y_0} + (1-\\alpha)\\Sigma_{y_1}^{-1}\\mu_{y_1} \\right)\n    $$\n    插值分布的均值是各分量均值的精度加权平均。\n\n### 算法设计与测试验证\n\n实现将使用推导出的闭式表达式来计算 $\\mu_{\\alpha}$ 和 $\\Sigma_{\\alpha}$。这五个测试验证了该插值方案的重要行为。\n\n-   **测试1（边界一致性）**：在公式中设置 $\\alpha=0$ 会得到 $\\Sigma_{\\alpha}^{-1} = \\Sigma_{y_1}^{-1} \\implies \\Sigma_{\\alpha} = \\Sigma_{y_1}$ 和 $\\mu_{\\alpha} = \\Sigma_{y_1}(\\Sigma_{y_1}^{-1}\\mu_{y_1}) = \\mu_{y_1}$。$\\alpha=1$ 的情况是对称的。此测试确认了实现在插值边界处能正确恢复原始分布。\n-   **测试2（等协方差下的线性均值插值）**：如果 $\\Sigma_{y_0} = \\Sigma_{y_1} = \\Sigma$，那么 $\\Sigma_{\\alpha}^{-1} = (\\alpha + 1-\\alpha)\\Sigma^{-1} = \\Sigma^{-1}$，因此 $\\Sigma_{\\alpha} = \\Sigma$。均值变为 $\\mu_{\\alpha} = \\Sigma(\\alpha\\Sigma^{-1}\\mu_{y_0} + (1-\\alpha)\\Sigma^{-1}\\mu_{y_1}) = \\alpha\\mu_{y_0} + (1-\\alpha)\\mu_{y_1}$。该测试确认了这种特殊情况，其中精度加权简化为均值的简单线性插值。\n-   **测试3（精度加权偏差）**：当协方差不相等时，均值会被拉向具有更高精度（更低方差）的分布的均值。方差较小的分量具有“更强”的影响力，因为其能量函数从其最小值处上升得更陡峭。该测试量化了这种偏差。\n-   **测试4（平稳性）**：分布的均值也是其众数（概率最大点），这对应于能量函数的极值点（最小值）。极值点的一个必要条件是梯度为零。该测试验证了 $\\nabla E_{\\alpha}(\\mu_{\\alpha}) = \\mathbf{0}$，从而确认我们推导出的 $\\mu_{\\alpha}$ 确实是插值能量函数的最小值点。梯度为 $\\nabla E_{\\alpha}(x) = \\alpha\\Sigma_{y_0}^{-1}(x-\\mu_{y_0}) + (1-\\alpha)\\Sigma_{y_1}^{-1}(x-\\mu_{y_1})$。代入 $x=\\mu_\\alpha$ 并使用推导出的公式可以证明其解析上为零。\n-   **测试5（方差边界）**：插值精度 $\\Sigma_{\\alpha,ii}^{-1}$ 是分量精度的线性插值。由于函数 $f(v) = 1/v$ 在 $v > 0$ 时是凸函数，插值方差 $(\\Sigma_{\\alpha,ii}^{-1})^{-1}$ 位于分量方差之间。这是加权调和平均数性质的结果。该测试验证了对角协方差矩阵的此边界属性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by performing five tests on the interpolation of two \n    Gaussian distributions defined via an energy-based model formulation.\n    \"\"\"\n    \n    test_cases = [\n        # Test 1: Boundary at alpha = 0\n        {\n            \"id\": 1,\n            \"mu0\": np.array([0., 0.]),\n            \"S0\": np.array([[1., 0.], [0., 1.]]),\n            \"mu1\": np.array([2., 1.]),\n            \"S1\": np.array([[0.5, 0.], [0., 0.5]]),\n            \"alpha\": 0.0\n        },\n        # Test 2: Equal covariances and alpha = 0.3\n        {\n            \"id\": 2,\n            \"mu0\": np.array([0., 0.]),\n            \"S0\": np.array([[1., 0.], [0., 1.]]),\n            \"mu1\": np.array([2., 0.]),\n            \"S1\": np.array([[1., 0.], [0., 1.]]),\n            \"alpha\": 0.3\n        },\n        # Test 3: Bias with unequal covariances and alpha = 0.5\n        {\n            \"id\": 3,\n            \"mu0\": np.array([0., 0.]),\n            \"S0\": np.array([[1.0, 0.], [0., 0.5]]),\n            \"mu1\": np.array([2., 0.]),\n            \"S1\": np.array([[0.25, 0.], [0., 0.5]]),\n            \"alpha\": 0.5\n        },\n        # Test 4: Stationarity with off-diagonal covariances and alpha = 0.4\n        {\n            \"id\": 4,\n            \"mu0\": np.array([-1., 1.]),\n            \"S0\": np.array([[1.0, 0.3], [0.3, 1.0]]),\n            \"mu1\": np.array([1., -1.]),\n            \"S1\": np.array([[1.5, -0.2], [-0.2, 1.0]]),\n            \"alpha\": 0.4\n        },\n        # Test 5: Variance bounds with diagonal covariances and alpha = 0.75\n        {\n            \"id\": 5,\n            \"mu0\": np.array([0., 0.]),\n            \"S0\": np.array([[1.0, 0.], [0., 4.0]]),\n            \"mu1\": np.array([0., 0.]),\n            \"S1\": np.array([[9.0, 0.], [0., 0.25]]),\n            \"alpha\": 0.75\n        }\n    ]\n\n    def compute_interpolated_params(mu0, S0, mu1, S1, alpha):\n        \"\"\"\n        Computes the mean and covariance of the interpolated Gaussian distribution.\n        \"\"\"\n        S0_inv = np.linalg.inv(S0)\n        S1_inv = np.linalg.inv(S1)\n        \n        Sa_inv = alpha * S0_inv + (1 - alpha) * S1_inv\n        Sa = np.linalg.inv(Sa_inv)\n        \n        # Note: Sa is pre-multiplied\n        mu_a_term = alpha * (S0_inv @ mu0) + (1 - alpha) * (S1_inv @ mu1)\n        mu_a = Sa @ mu_a_term\n        \n        return mu_a, Sa\n\n    results = []\n    for case in test_cases:\n        mu0, S0, mu1, S1, alpha = case[\"mu0\"], case[\"S0\"], case[\"mu1\"], case[\"S1\"], case[\"alpha\"]\n        mu_a, Sa = compute_interpolated_params(mu0, S0, mu1, S1, alpha)\n        \n        test_id = case[\"id\"]\n        result = False\n        \n        if test_id == 1:\n            check_mu = np.allclose(mu_a, mu1)\n            check_S = np.allclose(Sa, S1)\n            result = check_mu and check_S\n        \n        elif test_id == 2:\n            mu_linear_interp = alpha * mu0 + (1 - alpha) * mu1\n            result = np.allclose(mu_a, mu_linear_interp)\n\n        elif test_id == 3:\n            # We calculated that mu_a lies on the line connecting mu0 and mu1 for this case.\n            # So the projection is mu_a itself.\n            # We solve mu_a = mu0 + t * (mu1-mu0) for t.\n            #  mu_a - mu0 = t * (mu1-mu0)\n            # Take dot product with (mu1-mu0) to solve for t\n            v = mu1 - mu0\n            w = mu_a - mu0\n            t = (w @ v) / (v @ v) if (v @ v) != 0 else 0\n            result = (t > alpha) and (0 = t = 1)\n\n        elif test_id == 4:\n            # Check stationarity: grad E_alpha(mu_a) == 0\n            S0_inv = np.linalg.inv(S0)\n            S1_inv = np.linalg.inv(S1)\n            grad = alpha * S0_inv @ (mu_a - mu0) + (1 - alpha) * S1_inv @ (mu_a - mu1)\n            result = np.allclose(grad, np.zeros_like(grad))\n\n        elif test_id == 5:\n            # Check variance bounds for diagonal matrices\n            Sa_diag = np.diag(Sa)\n            S0_diag = np.diag(S0)\n            S1_diag = np.diag(S1)\n            \n            lower_bounds = np.minimum(S0_diag, S1_diag)\n            upper_bounds = np.maximum(S0_diag, S1_diag)\n            \n            check_lower = np.all(Sa_diag >= lower_bounds)\n            check_upper = np.all(Sa_diag = upper_bounds)\n            result = check_lower and check_upper\n            \n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3122280"}]}