{"hands_on_practices": [{"introduction": "在我们将学习率热身付诸实践之前，理解其背后的数学原理至关重要。这个练习提供了一个理论视角，通过推导一个精确的解析表达式，来揭示线性热身如何抑制优化器在训练初期的动量累积。通过完成这个练习 [@problem_id:3143226]，你将深入理解为什么一个逐渐增大的学习率能够有效防止由初始大梯度引起的训练不稳定，尤其是在使用动量（momentum）的情况下。", "problem": "考虑在一个曲率为 $\\lambda  0$ 的严格凸二次损失 $L(w) = \\tfrac{\\lambda}{2} (w - w^{\\star})^{2}$ 上对参数 $w_t$ 进行一维训练。设误差为 $e_t = w_t - w^{\\star}$，梯度为 $g_t = \\nabla L(w_t) = \\lambda e_t$。优化器使用经典动量法，其速度更新和参数更新规则为\n$$\nv_{t+1} = \\beta v_t + \\eta(t)\\, g_t, \\qquad w_{t+1} = w_t - v_{t+1},\n$$\n其中动量系数为 $0 \\le \\beta  1$，初始速度为 $v_0 = 0$，初始误差为 $e_0 \\ne 0$。在前 $T_w \\in \\mathbb{N}$ 个步骤中，使用线性学习率预热：\n$$\n\\eta(t) = \\eta_{\\max}\\,\\frac{t}{T_w} \\quad \\text{for } 0 \\le t \\le T_w,\n$$\n此后，学习率保持在 $\\eta_{\\max}$。在预热阶段，我们假设存在一个经验上观察到的小步长区间，在此区间内，前 $T_w+1$ 次迭代的误差变化可以忽略不计，因此对于 $0 \\le t \\le T_w$ 有 $e_t \\approx e_0$。当学习率仍然很小时，这个近似被广泛用于分析预热期间的最早期的动态。\n\n仅从这些定义和这个近似出发：\n\n1) 推导预热结束时的速度 $v_{T_w+1}$ 的精确闭式表达式（在所述近似下），用 $\\beta$、$\\lambda$、$e_0$、$\\eta_{\\max}$ 和 $T_w$ 表示。\n\n2) 令 $v^{\\mathrm{const}}_{T_w+1}$ 表示在 $0 \\le t \\le T_w$ 的所有时间内，学习率恒定为 $\\eta(t) \\equiv \\eta_{\\max}$ 时所获得的预热结束时的速度。使用相同的近似，推导比率的简化闭式表达式\n$$\nR(\\beta,T_w) \\equiv \\frac{v^{\\mathrm{warm}}_{T_w+1}}{v^{\\mathrm{const}}_{T_w+1}},\n$$\n该表达式仅作为 $\\beta$ 和 $T_w$ 的函数（所有其他参数必须抵消）。\n\n解释性说明：$v_{T_w+1}$ 相对于 $|e_0|$ 的大小控制了预热结束时初始过冲的风险，因此比率 $R(\\beta,T_w)$ 量化了与恒定学习率相比，线性预热如何抑制初始动量的累积。\n\n你的最终答案必须是 $R(\\beta,T_w)$ 的简化闭式表达式，形式为单个解析表达式。不需要也不允许进行数值计算，也无需四舍五入。假设 $\\beta \\ne 1$ 且 $T_w \\ge 1$ 是整数，但你的表达式可以符号化地处理 $T_w$。", "solution": "用户提供了一个来自深度学习优化理论领域的有效且适定的问题。任务是推导在两种不同学习率方案下，预热结束时速度之比 $R(\\beta, T_w)$ 的简化闭式表达式。\n\n该问题由以下几个部分定义：\n- 损失函数：$L(w) = \\frac{\\lambda}{2} (w - w^{\\star})^{2}$，其中 $\\lambda  0$。\n- 误差和梯度：$e_t = w_t - w^{\\star}$ 和 $g_t = \\nabla L(w_t) = \\lambda e_t$。\n- 优化器更新规则：$v_{t+1} = \\beta v_t + \\eta(t) g_t$ 和 $w_{t+1} = w_t - v_{t+1}$。\n- 初始条件：$v_0 = 0$ 和 $e_0 \\neq 0$。\n- 动量参数：$0 \\le \\beta  1$。\n- 核心近似：在预热阶段 $0 \\le t \\le T_w$ 期间，假设误差是恒定的，$e_t \\approx e_0$。这意味着梯度也是恒定的，$g_t \\approx g_0 = \\lambda e_0$。\n\n求解过程分为三个步骤：\n1. 推导线性预热阶段结束时的速度 $v^{\\mathrm{warm}}_{T_w+1}$。\n2. 推导由恒定学习率产生的速度 $v^{\\mathrm{const}}_{T_w+1}$。\n3. 计算并简化比率 $R(\\beta, T_w) = v^{\\mathrm{warm}}_{T_w+1} / v^{\\mathrm{const}}_{T_w+1}$。\n\n**步骤 1：推导线性预热下的速度 ($v^{\\mathrm{warm}}_{T_w+1}$)**\n\n线性预热方案由 $\\eta(t) = \\eta_{\\max} \\frac{t}{T_w}$ 给出，适用于 $0 \\le t \\le T_w$。\n在恒定梯度近似 $g_t \\approx g_0$ 下，速度更新规则是一个线性递推关系：\n$$\nv_{t+1} = \\beta v_t + \\eta(t) g_0 = \\beta v_t + \\left(\\frac{\\eta_{\\max} g_0}{T_w}\\right) t\n$$\n从 $v_0 = 0$ 开始，我们可以展开这个递推关系来找到 $v_{k+1}$：\n$$\nv_{k+1} = \\beta^{k+1} v_0 + \\sum_{j=0}^{k} \\beta^{k-j} \\eta(j) g_0 = g_0 \\sum_{j=0}^{k} \\beta^{k-j} \\eta(j)\n$$\n我们需要第 $T_w+1$ 步的速度，这意味着我们对 $k=T_w$ 计算此表达式，并使用 $j \\in \\{0, 1, \\dots, T_w\\}$ 的方案：\n$$\nv^{\\mathrm{warm}}_{T_w+1} = g_0 \\sum_{j=0}^{T_w} \\beta^{T_w-j} \\left(\\eta_{\\max} \\frac{j}{T_w}\\right) = \\frac{g_0 \\eta_{\\max}}{T_w} \\sum_{j=0}^{T_w} j \\beta^{T_w-j}\n$$\n当 $j=0$ 时，项为零，所以求和范围是 $j=1, \\dots, T_w$。我们来分析这个和 $S = \\sum_{j=1}^{T_w} j \\beta^{T_w-j}$。我们可以通过令 $k = T_w - j$ 来重新索引。当 $j$ 从 $1$ 变为 $T_w$ 时，$k$ 从 $T_w-1$ 变为 $0$。\n$$\nS = \\sum_{k=0}^{T_w-1} (T_w - k) \\beta^k = T_w \\sum_{k=0}^{T_w-1} \\beta^k - \\sum_{k=0}^{T_w-1} k \\beta^k\n$$\n第一项是标准的几何级数：$\\sum_{k=0}^{T_w-1} \\beta^k = \\frac{1 - \\beta^{T_w}}{1 - \\beta}$。\n第二项是等差-等比级数。我们可以用微积分来计算它。对于 $|x|1$，我们知道 $\\sum_{k=0}^{n} x^k = \\frac{1-x^{n+1}}{1-x}$。对 $x$ 求导得到 $\\sum_{k=1}^{n} kx^{k-1} = \\frac{d}{dx}\\left(\\frac{1-x^{n+1}}{1-x}\\right)$。因此，$\\sum_{k=0}^{n} kx^k = x \\frac{d}{dx}\\left(\\frac{1-x^{n+1}}{1-x}\\right)$。\n对于我们的求和，有 $n = T_w-1$ 和 $x=\\beta$：\n$$\n\\sum_{k=0}^{T_w-1} k \\beta^k = \\beta \\frac{d}{d\\beta} \\left(\\frac{1-\\beta^{T_w}}{1-\\beta}\\right) = \\beta \\frac{-T_w\\beta^{T_w-1}(1-\\beta) - (1-\\beta^{T_w})(-1)}{(1-\\beta)^2} = \\frac{\\beta(1 - T_w\\beta^{T_w-1} + (T_w-1)\\beta^{T_w})}{(1-\\beta)^2}\n$$\n合并 $S$ 的各项：\n$$\nS = T_w \\frac{1-\\beta^{T_w}}{1-\\beta} - \\frac{\\beta - T_w\\beta^{T_w} + (T_w-1)\\beta^{T_w+1}}{(1-\\beta)^2}\n$$\n将所有项通分到共同分母 $(1-\\beta)^2$ 下：\n$$\nS = \\frac{T_w(1-\\beta^{T_w})(1-\\beta) - (\\beta - T_w\\beta^{T_w} + (T_w-1)\\beta^{T_w+1})}{(1-\\beta)^2}\n$$\n分子简化为：\n$$\n(T_w - T_w\\beta - T_w\\beta^{T_w} + T_w\\beta^{T_w+1}) - (\\beta - T_w\\beta^{T_w} + T_w\\beta^{T_w+1} - \\beta^{T_w+1})\n= T_w - T_w\\beta - \\beta + \\beta^{T_w+1} = T_w - (T_w+1)\\beta + \\beta^{T_w+1}\n$$\n所以，$S = \\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{(1-\\beta)^2}$。\n将此结果代回 $v^{\\mathrm{warm}}_{T_w+1}$ 的表达式中：\n$$\nv^{\\mathrm{warm}}_{T_w+1} = \\frac{g_0 \\eta_{\\max}}{T_w} \\left( \\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{(1-\\beta)^2} \\right)\n$$\n\n**步骤 2：推导恒定学习率下的速度 ($v^{\\mathrm{const}}_{T_w+1}$)**\n\n如果学习率在 $0 \\le t \\le T_w$ 期间保持恒定为 $\\eta(t) = \\eta_{\\max}$，则速度更新将是：\n$$\nv_{t+1} = \\beta v_t + \\eta_{\\max} g_0\n$$\n从 $v_0 = 0$ 展开此递推关系：\n$$\nv_{k+1} = \\eta_{\\max} g_0 \\sum_{j=0}^{k} \\beta^j\n$$\n我们需要第 $T_w+1$ 步的速度，所以我们设 $k=T_w$：\n$$\nv^{\\mathrm{const}}_{T_w+1} = \\eta_{\\max} g_0 \\sum_{j=0}^{T_w} \\beta^j\n$$\n该和是一个几何级数：$\\sum_{j=0}^{T_w} \\beta^j = \\frac{1 - \\beta^{T_w+1}}{1-\\beta}$。\n因此，\n$$\nv^{\\mathrm{const}}_{T_w+1} = \\eta_{\\max} g_0 \\left( \\frac{1 - \\beta^{T_w+1}}{1-\\beta} \\right)\n$$\n\n**步骤 3：计算比率 $R(\\beta, T_w)$**\n\n比率定义为 $R(\\beta, T_w) = \\frac{v^{\\mathrm{warm}}_{T_w+1}}{v^{\\mathrm{const}}_{T_w+1}}$。代入步骤 1 和步骤 2 的表达式：\n$$\nR(\\beta, T_w) = \\frac{\\frac{g_0 \\eta_{\\max}}{T_w} \\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{(1-\\beta)^2}}{\\eta_{\\max} g_0 \\frac{1 - \\beta^{T_w+1}}{1-\\beta}}\n$$\n项 $g_0$ 和 $\\eta_{\\max}$ 按要求抵消。我们得到一个仅依赖于 $\\beta$ 和 $T_w$ 的表达式：\n$$\nR(\\beta, T_w) = \\frac{1}{T_w} \\cdot \\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{(1-\\beta)^2} \\cdot \\frac{1-\\beta}{1 - \\beta^{T_w+1}}\n$$\n通过消去一个因子 $(1-\\beta)$ 来简化：\n$$\nR(\\beta, T_w) = \\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{T_w(1-\\beta)(1 - \\beta^{T_w+1})}\n$$\n这就是该比率的最终简化闭式表达式。", "answer": "$$\n\\boxed{\\frac{T_w - (T_w+1)\\beta + \\beta^{T_w+1}}{T_w(1-\\beta)(1 - \\beta^{T_w+1})}}\n$$", "id": "3143226"}, {"introduction": "理论分析告诉我们热身为何有效，但实际应用中如何选择合适的热身长度呢？这个练习将理论与实践联系起来，要求你通过编写一个简单的训练模拟器，直观地观察不同热身长度带来的影响。通过分析生成的学习曲线 [@problem_id:3115472]，你将学会诊断“热身不足”（under-warmup）导致的初始发散和“热身过度”（over-warmup）导致的训练迟缓，从而培养起调试这一关键超参数的实践直觉。", "problem": "您将实现并使用一个简单的、确定性的训练动态模拟器，利用学习曲线来诊断学习率预热（warmup）问题。设定是在严格凸二次函数上进行一维梯度下降，学习率采用线性增加的预热策略，之后保持恒定。您的程序必须模拟训练损失随轮次（epoch）的变化，对学习曲线的早期部分进行原则性诊断，并将每种情况分类为预热不足（under-warmup）、预热过度（over-warmup）或可接受的预热（acceptable warmup）。\n\n基本原理：\n- 考虑损失函数 $L(x) = \\frac{1}{2} a x^{2}$，其曲率 $a \\gt 0$。其梯度为 $\\nabla L(x) = a x$。学习率为 $\\eta_{t}$ 的梯度下降法按 $x_{t+1} = x_{t} - \\eta_{t} \\nabla L(x_{t})$ 更新参数。\n- 一个预热长度为 $w$、最大学习率为 $\\eta_{\\max}$ 的线性预热学习率策略由下式给出\n  - $\\eta_{t} = \\eta_{\\max} \\cdot \\min\\!\\left(\\frac{t}{w}, 1\\right)$，其中整数轮次 $t \\in \\{1, 2, \\dots, T\\}$。\n- 观测到的训练损失被确定性地建模为 $y_{t} = L(x_{t}) + \\sigma \\sin\\!\\left( \\frac{2 \\pi t}{P} \\right)$，其中 $\\sigma \\ge 0$ 且周期参数 $P \\ge 1$。对于 $t = 0$，定义 $y_{0} = L(x_{0})$。\n\n需要从第一性原理实现的诊断方法：\n- 早期稳定性：定义一个长度为 $K = \\min(5, T)$ 的早期窗口。通过检查是否存在某个 $t \\in \\{1, \\dots, K\\}$ 使得 $y_{t} \\gt (1 + \\tau) \\, y_{t-1}$ 来检测初始发散，阈值 $\\tau = 0.1$。\n- 进展迟缓：将第 $K$ 轮时达到的总损失减少量占总体的比例量化为\n  $$f_{\\text{early}} = \\frac{y_{0} - y_{K}}{\\max(y_{0} - y_{T}, \\varepsilon)},$$\n  其中 $\\varepsilon = 10^{-12}$。如果 $f_{\\text{early}} \\lt \\rho$（$\\rho = 0.2$），则判断为进展迟缓。\n- 分类规则，按此顺序应用：\n  - 如果在早期窗口检测到初始发散，则分类为预热不足（under-warmup），并输出 $-1$。\n  - 否则，如果检测到进展迟缓，则分类为预热过度（over-warmup），并输出 $1$。\n  - 否则，分类为可接受的预热（acceptable warmup），并输出 $0$。\n\n模拟细节：\n- 用 $x_{0}$ 初始化，并计算 $y_{0} = L(x_{0})$。\n- 对于每个轮次 $t = 1, 2, \\dots, T$：\n  - 计算 $\\eta_{t} = \\eta_{\\max} \\cdot \\min\\!\\left(\\frac{t}{w}, 1\\right)$。\n  - 更新 $x_{t} = x_{t-1} - \\eta_{t} a x_{t-1}$。\n  - 计算 $y_{t} = \\frac{1}{2} a x_{t}^{2} + \\sigma \\sin\\!\\left( \\frac{2 \\pi t}{P} \\right)$。\n\n测试套件：\n为以下参数集提供输出。每个案例是一个元组 $(a, \\eta_{\\max}, w, T, x_{0}, \\sigma, P)$：\n- 案例A（预期通过极短的预热来探查初始发散）：$(10.0, 0.25, 1, 40, 1.0, 0.0, 7)$。\n- 案例B（预期在安全的最大学习率和较短预热下为可接受的预热）：$(10.0, 0.15, 3, 40, 1.0, 0.0, 7)$。\n- 案例C（预期在非常长的预热下出现进展迟缓）：$(10.0, 0.18, 300, 500, 1.0, 0.0, 7)$。\n- 案例D（预热后处于经典步长稳定性极限边缘的边界稳定性）：$(10.0, 0.20, 5, 40, 1.0, 0.0, 7)$。\n- 案例E（预期在预热结束时因最大学习率过高而出现初始发散）：$(12.0, 0.25, 5, 50, 1.0, 0.0, 7)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为上述测试套件的结果，顺序保持一致。每个条目必须是 $\\{-1, 0, 1\\}$ 中的一个整数，代表该案例的分类，因此输出必须类似于 $[r_{A}, r_{B}, r_{C}, r_{D}, r_{E}]$。\n\n注意：\n- 本问题中不涉及物理单位。\n- 根据参数 $\\frac{2 \\pi t}{P}$ 的构造，正弦项中的角度以弧度为单位。\n- 百分比必须表示为小数，所有阈值 $\\tau$、$\\rho$ 和 $\\varepsilon$ 均以数值形式提供。", "solution": "问题陈述已经过验证，并被确定为是合理的。它在科学上基于数值优化的原理，特别是凸二次函数上的梯度下降法。该问题是适定的（well-posed），所有参数、方程和诊断标准都得到了明确无误的定义。整个设定是自洽且内部一致的，可以得出一个唯一且有意义的解。\n\n任务是模拟一维参数 $x$ 在梯度下降下的训练动态，并对学习率预热策略的行为进行分类。该过程涉及几个相互关联的组成部分：优化的数学模型、学习率策略、训练损失的模拟以及一套诊断规则。\n\n首先，我们建立核心的优化模型。损失函数是一个简单的凸二次函数，$L(x) = \\frac{1}{2} a x^2$，其中 $a  0$ 是曲率。该损失函数关于参数 $x$ 的梯度是 $\\nabla L(x) = a x$。梯度下降更新规则在每个轮次 $t$ 根据方程 $x_{t} = x_{t-1} - \\eta_{t} \\nabla L(x_{t-1})$ 修改参数 $x$，其中 $\\eta_t$ 是第 $t$ 轮的学习率。代入梯度后，具体的更新规则是：\n$$x_{t} = x_{t-1} - \\eta_{t} a x_{t-1} = x_{t-1}(1 - \\eta_{t} a)$$\n此更新在轮次 $t = 1, 2, \\dots, T$ 中执行。\n\n学习率 $\\eta_t$ 遵循线性预热策略。对于总共 $w$ 轮的预热时长和目标最大学习率 $\\eta_{\\max}$，第 $t$ 轮的学习率由下式给出：\n$$\\eta_{t} = \\eta_{\\max} \\cdot \\min\\left(\\frac{t}{w}, 1\\right)$$\n这意味着当 $t \\le w$ 时，$\\eta_t$ 从 $\\eta_1 = \\eta_{\\max}/w$ 线性增加到 $\\eta_w = \\eta_{\\max}$。对于所有后续轮次 $t  w$，学习率保持恒定在 $\\eta_t = \\eta_{\\max}$。\n\n模拟必须跟踪训练损失随轮次的变化。问题定义了一个观测损失 $y_t$，它由真实损失 $L(x_t)$ 加上一个确定性的正弦噪声项组成。初始损失为 $y_0 = L(x_0)$。对于后续轮次 $t \\in \\{1, 2, \\dots, T\\}$，观测损失为：\n$$y_t = L(x_t) + \\sigma \\sin\\left(\\frac{2 \\pi t}{P}\\right) = \\frac{1}{2} a x_t^2 + \\sigma \\sin\\left(\\frac{2 \\pi t}{P}\\right)$$\n模拟过程如下：\n1. 初始化参数 $x_0$ 并计算初始损失 $y_0 = \\frac{1}{2} a x_0^2$。将所有损失值 $y_t$ 存储在一个数组中。\n2. 对于从 $1$ 到 $T$ 的每个轮次 $t$：\n   a. 使用预热策略计算学习率 $\\eta_t$。\n   b. 使用梯度下降规则更新参数得到 $x_t$。\n   c. 计算观测损失 $y_t$ 并存储它。\n\n模拟完成后，我们对生成的学习曲线 $\\{y_t\\}_{t=0}^T$ 应用一系列诊断测试。\n\n第一个诊断是针对**早期稳定性**。该测试检查初始发散，这是学习率过于激进（即预热不足）的常见症状。我们定义一个 $K = \\min(5, T)$ 轮的早期窗口。如果在该窗口内的任何点，损失的增加超过了相对阈值 $\\tau = 0.1$，则检测到初始发散。也就是说，如果存在任何 $t \\in \\{1, \\dots, K\\}$ 使得：\n$$y_t  (1 + \\tau) y_{t-1}$$\n如果满足此条件，则将预热分类为`预热不足`（$-1$）。\n\n如果没有发现初始发散，第二个诊断是针对**进展迟缓**。该测试检查学习率是否过于保守（即预热过度），这会导致模型在开始时学习得太慢。我们将早期 $K$ 轮窗口内发生的总损失减少量所占的比例量化为：\n$$f_{\\text{early}} = \\frac{y_0 - y_K}{\\max(y_0 - y_T, \\varepsilon)}$$\n此处，$\\varepsilon = 10^{-12}$ 是一个很小的常数，用于防止在损失从第 $0$ 轮到第 $T$ 轮没有减少时出现除以零的情况。如果该比例低于阈值 $\\rho = 0.2$，我们则判断为进展迟缓。然后将预热分类为`预热过度`（$1$）。\n\n最终的分类遵循严格的顺序。\n1. 如果检测到初始发散，结果为 $-1$。\n2. 否则，如果检测到进展迟缓，结果为 $1$。\n3. 否则，预热被认为是`可接受的`，结果为 $0$。\n\n此过程将应用于提供的每个测试案例。实现将系统地执行模拟并应用定义的诊断方法，为每组参数生成最终分类。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Simulates training dynamics to diagnose learning rate warmup for several test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case A: (a, eta_max, w, T, x0, sigma, P)\n        (10.0, 0.25, 1, 40, 1.0, 0.0, 7),\n        # Case B:\n        (10.0, 0.15, 3, 40, 1.0, 0.0, 7),\n        # Case C:\n        (10.0, 0.18, 300, 500, 1.0, 0.0, 7),\n        # Case D:\n        (10.0, 0.20, 5, 40, 1.0, 0.0, 7),\n        # Case E:\n        (12.0, 0.25, 5, 50, 1.0, 0.0, 7),\n    ]\n\n    results = []\n\n    # Diagnostic thresholds and constants\n    tau = 0.1\n    rho = 0.2\n    epsilon = 1e-12\n\n    for case in test_cases:\n        a, eta_max, w, T, x0, sigma, P = case\n\n        # --- Simulation ---\n        # Initialize arrays for parameter and loss history\n        x_history = np.zeros(T + 1)\n        y_history = np.zeros(T + 1)\n\n        # Initial conditions\n        x_history[0] = x0\n        y_history[0] = 0.5 * a * x_history[0]**2\n\n        # Run the simulation loop for T epochs\n        for t in range(1, T + 1):\n            # Calculate learning rate with linear warmup\n            eta_t = eta_max * min(t / w, 1.0)\n            \n            # Update parameter using gradient descent\n            x_prev = x_history[t-1]\n            x_curr = x_prev * (1 - eta_t * a)\n            x_history[t] = x_curr\n            \n            # Calculate observed loss\n            true_loss = 0.5 * a * x_curr**2\n            noise = sigma * np.sin(2 * np.pi * t / P) if sigma > 0 else 0.0\n            y_history[t] = true_loss + noise\n\n        # --- Diagnostics ---\n        K = min(5, T)\n        y0 = y_history[0]\n        yK = y_history[K]\n        yT = y_history[T]\n\n        # 1. Check for early-epoch stability (under-warmup)\n        initial_divergence = False\n        for t in range(1, K + 1):\n            if y_history[t] > (1 + tau) * y_history[t-1]:\n                initial_divergence = True\n                break\n\n        # 2. Check for delayed progress (over-warmup)\n        # This is only checked if no divergence was found.\n        delayed_progress = False\n        if not initial_divergence:\n            denominator = max(y0 - yT, epsilon)\n            f_early = (y0 - yK) / denominator\n            if f_early  rho:\n                delayed_progress = True\n        \n        # 3. Apply classification rule\n        if initial_divergence:\n            results.append(-1)  # Under-warmup\n        elif delayed_progress:\n            results.append(1)   # Over-warmup\n        else:\n            results.append(0)   # Acceptable warmup\n\n    # Print results in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3115472"}, {"introduction": "标准的学习率热身依赖于一个预先设定的、固定的计划。然而，更高级的方法可以根据训练的实时动态来调整学习率。这个练习 [@problem_id:3143236] 将引导你设计并实现一个自适应热身策略。该策略通过监控梯度范数（gradient norm）的近期历史，仅在模型显示出稳定迹象（即梯度范数减小）时才提升学习率，从而实现更智能、更自动化的热身过程。", "problem": "给定一个非负实数序列，表示随机梯度下降 (SGD) 中损失函数每次迭代的梯度范数。设参数向量表示为 $\\theta_t \\in \\mathbb{R}^d$，损失为 $L(\\theta)$，梯度为 $g_t = \\nabla_{\\theta} L(\\theta_t)$，学习率为 $\\eta(t)$。核心 SGD 更新规则是其基础：$$\\theta_{t+1} = \\theta_t - \\eta(t)\\,g_t.$$ 目标是构建并应用一个自适应预热方案，该方案仅在当前梯度范数 $\\lVert \\nabla L(\\theta_t) \\rVert_2$ 低于其近期历史记录的指定经验百分位数时才增加 $\\eta(t)$。该自适应预热必须遵循以下原则和定义：\n\n1. 初始化与单调性约束：从一个最小学习率 $\\eta_{\\min}$ 开始，并允许 $\\eta(t)$ 随时间非递减，其上限为目标学习率 $\\eta_{\\text{target}}$。\n2. 百分位数阈值法：在迭代 $t \\ge 2$ 时，定义一个大小为 $n_t = \\min(W, t-1)$ 的历史窗口 $H_t = \\left\\{ \\lVert g_j \\rVert_2 \\mid j \\in \\{\\max(1, t-W), \\dots, t-1\\} \\right\\}$。对于一个选定的百分位数 $p \\in [0,100]$，通过对排序后的历史记录进行线性插值来定义经验百分位数阈值 $q_p(H_t)$。如果 $H_t$ 按升序排列为 $x_{(1)} \\le x_{(2)} \\le \\dots \\le x_{(n_t)}$，则设置 $$\\text{pos} = \\frac{p}{100}\\,(n_t - 1), \\quad \\ell = \\lfloor \\text{pos} \\rfloor, \\quad u = \\lceil \\text{pos} \\rceil,$$ 且 $$q_p(H_t) = \n\\begin{cases}\nx_{(\\ell+1)}  \\text{if } \\ell = u, \\\\\nx_{(\\ell+1)} + (x_{(u+1)} - x_{(\\ell+1)})\\,(\\text{pos} - \\ell)  \\text{if } \\ell  u.\n\\end{cases}$$\n对于 $n_t = 1$ 的情况，将 $q_p(H_t)$ 解释为 $x_{(1)}$。\n3. 自适应预热规则：对于 $t = 1$，设置 $\\eta(1) = \\eta_{\\min}$。对于 $t \\ge 2$，计算当前梯度范数 $g_t^{\\text{norm}} = \\lVert g_t \\rVert_2$ 和阈值 $q_p(H_t)$。仅当 $g_t^{\\text{norm}}  q_p(H_t)$ 时，将学习率乘以一个因子 $(1+\\alpha)$，但绝不超过 $\\eta_{\\text{target}}$。形式上，\n$$\\eta(t) = \n\\begin{cases}\n\\min\\left(\\eta(t-1)\\,(1+\\alpha),\\,\\eta_{\\text{target}}\\right)  \\text{if } g_t^{\\text{norm}}  q_p(H_t), \\\\\n\\eta(t-1)  \\text{otherwise.}\n\\end{cases}$$\n一旦 $\\eta(t)$ 达到 $\\eta_{\\text{target}}$，它将在此后的迭代中保持为 $\\eta_{\\text{target}}$。\n\n你的任务是实现一个程序，对每个测试用例，将其梯度范数序列应用于上述自适应预热方案，并返回两个输出：最后一次迭代后的最终学习率值 $\\eta(T)$ 和实际执行增加的总次数（即满足 $\\eta(t)  \\eta(t-1)$ 的迭代次数 $t$ 的数量）。\n\n所有量都是无量纲的，并以实数表示。不涉及物理单位。百分位数必须以区间 $[0,100]$ 内的数字形式提供，且不得使用百分号。\n\n测试套件：\n- 案例 1（普遍递减的梯度范数）：\n  - 梯度范数：$[5.0,\\,4.5,\\,4.0,\\,3.5,\\,3.0,\\,2.6,\\,2.3,\\,2.1,\\,1.9,\\,1.8]$\n  - 窗口大小：$W=3$\n  - 百分位数：$p=40.0$\n  - 乘法增加参数：$\\alpha=0.5$\n  - 最小学习率：$\\eta_{\\min}=0.001$\n  - 目标学习率：$\\eta_{\\text{target}}=0.01$\n- 案例 2（测试相等边界的近似恒定范数）：\n  - 梯度范数：$[3.0,\\,3.0,\\,3.0,\\,3.0,\\,3.0,\\,3.0,\\,3.0,\\,3.0]$\n  - 窗口大小：$W=4$\n  - 百分位数：$p=50.0$\n  - 乘法增加参数：$\\alpha=0.5$\n  - 最小学习率：$\\eta_{\\min}=0.001$\n  - 目标学习率：$\\eta_{\\text{target}}=0.005$\n- 案例 3（测试短窗口和平局情况的零值和小值）：\n  - 梯度范数：$[1.0,\\,0.0,\\,0.0,\\,0.05,\\,0.0,\\,0.0]$\n  - 窗口大小：$W=2$\n  - 百分位数：$p=50.0$\n  - 乘法增加参数：$\\alpha=0.8$\n  - 最小学习率：$\\eta_{\\min}=0.0001$\n  - 目标学习率：$\\eta_{\\text{target}}=0.002$\n- 案例 4（测试较大窗口并触及上限的振荡范数）：\n  - 梯度范数：$[5.0,\\,10.0,\\,6.0,\\,4.0,\\,9.0,\\,3.0,\\,8.0,\\,2.0,\\,7.0,\\,1.0]$\n  - 窗口大小：$W=5$\n  - 百分位数：$p=60.0$\n  - 乘法增加参数：$\\alpha=0.5$\n  - 最小学习率：$\\eta_{\\min}=0.0005$\n  - 目标学习率：$\\eta_{\\text{target}}=0.002$\n\n输出规格：\n- 对于每个测试用例，生成一个列表 $[\\eta(T),\\,\\text{count}]$，其中 $\\eta(T)$ 是最后一次迭代后的最终学习率，$\\text{count}$ 是在此过程中实际增加的总次数。\n- 你的程序应生成单行输出，其中包含所有测试用例的结果，形式为一个用方括号括起来的逗号分隔列表，格式为 $[[\\eta_1(T),\\text{count}_1],[\\eta_2(T),\\text{count}_2],[\\eta_3(T),\\text{count}_3],[\\eta_4(T),\\text{count}_4]]$，不含任何附加文本。", "solution": "该问题陈述是有效的。它在深度学习优化这一成熟领域具有科学依据，特别是关于学习率调度方面。该问题是适定的，为确定性算法提供了一套完整且明确的规则和参数。所有术语都得到了清晰的定义，测试套件中提供的数据对于计算模拟而言是一致且现实的。\n\n任务是为给定的梯度范数序列实现一个自适应学习率预热方案。该方案根据一套预定义的规则，为每次迭代 $t$ 确定学习率 $\\eta(t)$。每个测试用例的主要输出包括最后一次迭代 $T$ 之后的最终学习率 $\\eta(T)$，以及学习率被增加的总次数。\n\n算法按以下步骤进行：\n\n1.  **状态变量与初始化**：核心状态变量是学习率 $\\eta(t)$ 和一个用于记录增加次数的计数器。在初始迭代 $t=1$ 时，学习率被设置为指定的最小值 $\\eta(1) = \\eta_{\\min}$，增加计数器被初始化为 $0$。\n\n2.  **迭代更新**：对于从 $2$ 到 $T$ 的每次后续迭代 $t$（其中 $T$ 是总迭代次数，即梯度范数序列的长度），学习率 $\\eta(t)$ 是基于 $\\eta(t-1)$、当前梯度范数 $\\lVert g_t \\rVert_2$ 以及从近期历史记录计算出的一个基于百分位数的阈值来确定的。\n\n3.  **历史记录与阈值计算**：在给定的迭代 $t \\ge 2$ 时，定义一个历史窗口 $H_t$，它是最近 $n_t = \\min(W, t-1)$ 个梯度范数的集合，其中 $W$ 是最大窗口大小。形式上，$H_t = \\{ \\lVert g_j \\rVert_2 \\mid j \\in \\{\\max(1, t-W), \\dots, t-1\\} \\}$。然后计算一个阈值 $q_p(H_t)$，作为 $H_t$ 中值的第 $p$ 经验百分位数。问题为此计算指定了一种线性插值方法：\n    设 $H_t$ 中的排序值为 $x_{(1)} \\le x_{(2)} \\le \\dots \\le x_{(n_t)}$。百分位数的位置计算为 $\\text{pos} = \\frac{p}{100}(n_t - 1)$。设 $\\ell = \\lfloor \\text{pos} \\rfloor$ 和 $u = \\lceil \\text{pos} \\rceil$，则阈值为：\n    $$q_p(H_t) = \n    \\begin{cases}\n    x_{(\\ell+1)}  \\text{if } \\ell = u \\\\\n    x_{(\\ell+1)} + (x_{(u+1)} - x_{(\\ell+1)})\\,(\\text{pos} - \\ell)  \\text{if } \\ell  u\n    \\end{cases}$$\n    对于历史记录只包含一个值的特殊情况（$n_t=1$），阈值就是该值本身，$q_p(H_t) = x_{(1)}$。此计算等同于 `numpy` 等数值库中的标准百分位数计算方法。\n\n4.  **学习率更新规则**：自适应方案的核心是 $\\eta(t)$ 的更新规则：\n    $$\\eta(t) = \n    \\begin{cases}\n    \\min\\left(\\eta(t-1)\\cdot(1+\\alpha), \\eta_{\\text{target}}\\right)  \\text{if } \\lVert g_t \\rVert_2  q_p(H_t) \\\\\n    \\eta(t-1)  \\text{otherwise}\n    \\end{cases}$$\n    此处，$\\alpha$ 是乘法增加因子，$\\eta_{\\text{target}}$ 是最大允许学习率。仅当当前梯度范数严格小于历史百分位数阈值时，才会执行增加操作。如果一次更新导致 $\\eta(t)  \\eta(t-1)$，则增加计数器递增。\n\n5.  **饱和**：一个关键的约束是学习率非递减且上限为 $\\eta_{\\text{target}}$。一旦学习率达到 $\\eta_{\\text{target}}$，它将在所有后续迭代中保持该值，更新逻辑实际上被绕过。\n\n该实现将为每个测试用例的整个梯度范数序列逐步模拟此过程。然后收集学习率的最终值和增加的总次数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the adaptive learning rate warmup problem for all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general decreasing gradient norms):\n        {\n            \"grad_norms\": [5.0, 4.5, 4.0, 3.5, 3.0, 2.6, 2.3, 2.1, 1.9, 1.8],\n            \"W\": 3,\n            \"p\": 40.0,\n            \"alpha\": 0.5,\n            \"eta_min\": 0.001,\n            \"eta_target\": 0.01\n        },\n        # Case 2 (near-constant norms testing equality boundary):\n        {\n            \"grad_norms\": [3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0],\n            \"W\": 4,\n            \"p\": 50.0,\n            \"alpha\": 0.5,\n            \"eta_min\": 0.001,\n            \"eta_target\": 0.005\n        },\n        # Case 3 (zeros and small values testing short windows and ties):\n        {\n            \"grad_norms\": [1.0, 0.0, 0.0, 0.05, 0.0, 0.0],\n            \"W\": 2,\n            \"p\": 50.0,\n            \"alpha\": 0.8,\n            \"eta_min\": 0.0001,\n            \"eta_target\": 0.002\n        },\n        # Case 4 (oscillatory norms testing larger window and hitting the cap):\n        {\n            \"grad_norms\": [5.0, 10.0, 6.0, 4.0, 9.0, 3.0, 8.0, 2.0, 7.0, 1.0],\n            \"W\": 5,\n            \"p\": 60.0,\n            \"alpha\": 0.5,\n            \"eta_min\": 0.0005,\n            \"eta_target\": 0.002\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_schedule(case)\n        results.append(result)\n\n    # Format the output as specified: [[eta1,count1],[eta2,count2],...]\n    inner_strings = [f'[{r[0]},{r[1]}]' for r in results]\n    output_string = f\"[{','.join(inner_strings)}]\"\n    print(output_string)\n\ndef run_schedule(params):\n    \"\"\"\n    Applies the adaptive warmup schedule for a single test case.\n\n    Args:\n        params (dict): A dictionary containing all parameters for the case.\n\n    Returns:\n        list: A list containing the final learning rate and the total increase count.\n    \"\"\"\n    grad_norms = params[\"grad_norms\"]\n    W = params[\"W\"]\n    p = params[\"p\"]\n    alpha = params[\"alpha\"]\n    eta_min = params[\"eta_min\"]\n    eta_target = params[\"eta_target\"]\n\n    current_eta = eta_min\n    increase_count = 0\n    T = len(grad_norms)\n\n    # Iterations are 1-based in the problem, t = 1, ..., T.\n    # Python indices are 0-based, i = 0, ..., T-1.\n    # The loop for updates starts at t=2, so index i=1.\n    for i in range(1, T):\n        # If LR has reached target, it stays there.\n        if current_eta == eta_target:\n            continue\n\n        # Current gradient norm (at time t = i + 1)\n        current_g_norm = grad_norms[i]\n\n        # History window H_t for t = i + 1\n        # History consists of norms from j=max(1, t-W) to t-1.\n        # In 0-based indices, this is a slice from max(0, i-W) to i-1.\n        history_start_idx = max(0, i - W)\n        history = grad_norms[history_start_idx:i]\n\n        # Calculate percentile threshold q_p(H_t)\n        # The problem defines linear interpolation, which is the default for\n        # np.percentile in the specified version.\n        # It also handles the n=1 case correctly.\n        if not history:\n            # This case occurs only if i=0, but loop starts at i=1.\n            # As a safeguard, use a threshold that prevents updates.\n            q_p_threshold = float('inf')\n        else:\n            q_p_threshold = np.percentile(history, p, interpolation='linear')\n        \n        # Apply the adaptive warmup rule\n        if current_g_norm  q_p_threshold:\n            prev_eta = current_eta\n            current_eta = min(current_eta * (1 + alpha), eta_target)\n            if current_eta > prev_eta:\n                increase_count += 1\n    \n    return [current_eta, increase_count]\n\nsolve()\n```", "id": "3143236"}]}