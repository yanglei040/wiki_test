## 应用与跨学科联系

在前面的章节中，我们深入探讨了[卷积神经网络](@entry_id:178973)（CNN）中[平移等变性](@entry_id:636340)的核心原理和机制。我们了解到，一个操作如果具有[平移等变性](@entry_id:636340)，意味着对输入进行平移与对输出进行平移所得到的结果是相同的。这一特性主要源于卷积层中[权重共享](@entry_id:633885)的设计。然而，理论上的完美[等变性](@entry_id:636671)在实际应用中常常会因为各种架构选择而被打破或近似。

本章的目标是[超越理论](@entry_id:203777)，探索[平移等变性](@entry_id:636340)这一核心原则如何在广泛的现实世界问题和跨学科学术领域中发挥关键作用。我们将通过一系列应用导向的实例，展示[平移等变性](@entry_id:636340)不仅是CNN成功的基石，更是指导我们设计、分析和优化复杂深度学习系统的强大思想工具。我们关注的重点将从“是什么”转向“为什么重要”以及“如何应用”，揭示这一概念在解决从[计算机视觉](@entry_id:138301)到[计算生物学](@entry_id:146988)，再到[机器人学](@entry_id:150623)等多样化挑战中的实用价值和深远影响。

### [计算机视觉](@entry_id:138301)中的核心应用

[平移等变性](@entry_id:636340)在[计算机视觉](@entry_id:138301)领域，尤其是在需要对图像中每个像素进行密集预测（dense prediction）的任务中，扮演着至关重要的角色。这类任务的共同目标是生成一个与输入图像在空间上对齐的输出图，例如[语义分割](@entry_id:637957)图或关键点[热图](@entry_id:273656)。

#### [语义分割](@entry_id:637957)

在[语义分割](@entry_id:637957)任务中，模型需要为输入图像中的每一个像素分配一个类别标签。直观上，如果我们将输入图像向右平移若干像素，我们期望输出的分割图也相应地向右平移相同的距离。然而，现代的分割网络，如[U-Net](@entry_id:635895)或[全卷积网络](@entry_id:636216)（FCN），通常采用[编码器-解码器](@entry_id:637839)结构。编码器通过带步幅的卷积（strided convolution）或[池化层](@entry_id:636076)来逐步减小[特征图](@entry_id:637719)的空间分辨率，以增大感受野并提取高级语义信息。解码器则负责将这些低分辨率的语义[特征图](@entry_id:637719)[上采样](@entry_id:275608)回原始输入尺寸，以实现像素级的预测。

正是这个下采样和[上采样](@entry_id:275608)的过程，破坏了网络完美的[平移等变性](@entry_id:636340)。当一个带有步幅 $s > 1$ 的卷积层处理输入时，一个微小的、非步幅整数倍的输入平移可能会导致[下采样](@entry_id:265757)网格采样到完全不同的特征点，这一现象与[信号处理中的混叠](@entry_id:186681)（aliasing）密切相关。随后，解码器中的[上采样](@entry_id:275608)操作，如最近邻插值或[双线性插值](@entry_id:170280)，也无法完全恢复这种由[采样偏差](@entry_id:193615)造成的信息损失。例如，一个简单的实验可以量化这种错位误差：通过一个简化的、仅包含卷积、步幅下采样和[上采样](@entry_id:275608)操作的线性管线，我们可以测量当输入图像被平移一个像素时，最终输出与理想平移输出之间的像素级偏差。实验表明，更大的步幅会导致更严重的错位。同时，相较于产生块状效应的最近邻插值，更平滑的[双线性插值](@entry_id:170280)通常能更好地处理微小位移，从而产生更小的[等变性](@entry_id:636671)误差。这揭示了在设计分割网络时，[感受野大小](@entry_id:634995)和定位精度之间存在的根本性权衡。[@problem_id:3196067]

#### [关键点检测](@entry_id:636749)与定位

在需要亚像素级精度的任务中，例如人体姿态估计或人脸[关键点检测](@entry_id:636749)，[平移等变性](@entry_id:636340)的破坏会直接影响模型的定位精度。这类任务通常通过回归一个高斯[热图](@entry_id:273656)来预测关键点的位置，[热图](@entry_id:273656)的峰值对应着关键点的坐标。

理想情况下，输入图像中关键点的亚像素位移应该导致输出[热图](@entry_id:273656)峰值的相应亚像素位移。然而，与分割任务类似，网络中的下采样和[上采样](@entry_id:275608)模块是[等变性](@entry_id:636671)损失的主要来源。特别是解码器中的[上采样](@entry_id:275608)层，其设计对最终的定位精度有显著影响。研究表明，虽然[双线性插值](@entry_id:170280)相对稳健，但许多网络采用“学习式”的[上采样](@entry_id:275608)，如[转置卷积](@entry_id:636519)（transposed convolution）。如果一个[转置卷积](@entry_id:636519)核在学习过程中变得不对称，它就会在重建高分辨率特征图时引入一个固有的空间偏差。这意味着即使输入发生了一个精确的平移，输出的偏移量也可能不完全匹配，从而导致定位误差。我们可以通过一个实验来量化这种效应：首先生成一个以[亚像素精度](@entry_id:637328)定位的合成高斯[热图](@entry_id:273656)作为输入，然后让其通过一个包含下采样和不同上[采样方法](@entry_id:141232)（如标准[双线性插值](@entry_id:170280)和非对称[转置卷积](@entry_id:636519)）的管线，最后通过计算质心来读出预测的关键点位置。结果显示，非对称的[转置卷积](@entry_id:636519)核会导致预测位置与真实位置之间产生一个依赖于输入位移的系统性误差，直接降低了模型的定位精度。[@problem_id:3196042]

#### [目标检测](@entry_id:636829)

在[目标检测](@entry_id:636829)任务中，[平移等变性](@entry_id:636340)的概念同样至关重要，尤其是在处理感兴趣区域（Region of Interest, ROI）时。早期的[目标检测](@entry_id:636829)器，如Fast [R-CNN](@entry_id:637627)，使用了一种名为“ROI池化”（ROI Pooling）的操作，将不同大小的候选区域转换为固定大小的[特征图](@entry_id:637719)。然而，ROI池化涉及两次空间量化：一次是将[浮点](@entry_id:749453)坐标的ROI边界对齐到特征图的整数网格上，另一次是在ROI内部进行分块池化。

这种强制的量化操作严重破坏了[平移等变性](@entry_id:636340)。当一个物体在输入图像上发生微小的、亚像素级别的平移时，量化后的ROI边界可能会发生剧烈的跳变（例如，从一个像素跳到另一个像素），导致最终提取的特征产生显著变化。这使得模型对物体位置的微小变化非常敏感，降低了检测的准确性。为了解决这个问题，后续的研究提出了“ROI对齐”（ROI Align）。与ROI池化不同，ROI对齐避免了任何硬性量化。它通过[双线性插值](@entry_id:170280)在特征图的非整数坐标上精确地采样，从而更好地保持了亚像素级别的空间信息。一个简化的1D模型可以清晰地揭示两者的区别：在一个线性变化的[特征图](@entry_id:637719)上，ROI池化由于其边界的取整操作（依赖于 `floor` 和 `ceil` 函数），其输出值会随着ROI的亚像素平移呈现出阶跃式变化；而ROI对齐的输出则平滑地、线性地随着平移而变化。这证明了ROI对齐具有更好的[平移等变性](@entry_id:636340)，这也是其能够在现代[目标检测](@entry_id:636829)和[实例分割](@entry_id:634371)模型中取得巨大成功的一个关键原因。[@problem_id:3196035]

### 跨学科的[科学计算](@entry_id:143987)

[平移等变性](@entry_id:636340)的原理不仅限于传统的计算机视觉任务，它同样是CNN在各类[科学计算](@entry_id:143987)领域取得成功的关键[归纳偏置](@entry_id:137419)（inductive bias）。

#### 天文学：[点源](@entry_id:196698)检测

在天文学图像分析中，一个常见的任务是检测恒星、星系等点状或近点状的天体源。这些源在图像中可以被建模为离散的脉冲信号（delta function）。一个理想的[点源](@entry_id:196698)检测算法应该具备[平移等变性](@entry_id:636340)：如果一个恒星在天空中的位置移动了，它在探测器图像上的位置也随之移动，我们的算法应该能在新的位置上以同样的方式检测到它。

CNN非常适合这项任务，因为一个经过训练的[卷积核](@entry_id:635097)可以充当一个[匹配滤波器](@entry_id:137210)，当它扫过一个类似其形状的天体源时会产生强烈的响应。在一个仅包含步幅为1的卷积层的简单网络中，输入图像中的一个脉冲信号经过卷积后，会在输出[特征图](@entry_id:637719)的相同位置产生一个以该[卷积核](@entry_id:635097)形状为模式的响应。通过寻找[特征图](@entry_id:637719)的峰值（[argmax](@entry_id:634610)），我们可以精确地定位原始[点源](@entry_id:196698)。然而，当网络中引入[步幅卷积](@entry_id:637216)或[池化层](@entry_id:636076)以扩大感受野和降低计算成本时，定位的保真度就会受到影响。如果一个[点源](@entry_id:196698)的平移量不是[下采样](@entry_id:265757)步幅的整数倍，那么在[下采样](@entry_id:265757)后的特征图上，其峰值位置会发生偏移，产生所谓的“[混叠误差](@entry_id:637691)”。同样，[最大池化](@entry_id:636121)（max pooling）操作虽然能提供局部的[不变性](@entry_id:140168)，但它通过将一个区域内的信息压缩为单个值，也丢弃了精确的位置信息。我们可以通过脉冲响应测试来量化这种定位误差：将一个脉冲信号置于输入图像中，将其平移，然后通过包含不同步幅和池化配置的网络，最后测量预测位置与真实平移后位置之间的欧氏距离。这样的分析清楚地表明，虽然下采样有助于[模型识别](@entry_id:139651)更大范围的结构，但它牺牲了宝贵的[等变性](@entry_id:636671)，从而降低了定位精度。[@problem_id:3196049]

#### 计算生物学：基因组序列分析

在计算生物学中，一个核心任务是在DNA序列中寻找特定的功能模式，例如[转录因子](@entry_id:137860)（Transcription Factor, TF）的结合基序（motif）。一个TF通常可以结合到基因组中任何出现其偏好序列模式的地方，这意味着基序的识别是一个位置无关的任务。

对于这个任务，1D CNN的[平移等变性](@entry_id:636340)提供了一个完美的[归纳偏置](@entry_id:137419)。将DNA序列（通常进行one-hot编码）输入1D CNN，一个卷积核就像一个移动的扫描器，在序列的每个位置寻找与特定模式的匹配。由于[权重共享](@entry_id:633885)，同一个[卷积核](@entry_id:635097)被应用于所有位置。这意味着网络只需要学习一个能够识别TF结合基序的“模板”（即[卷积核](@entry_id:635097)的权重），而不需要为该基序可能出现的每一个位置都学习一个单独的检测器。这极大地减少了模型的参数数量（从与序列长度$N$相关的 $\mathcal{O}(NF)$ 减少到仅与卷积核大小$F$相关的 $\mathcal{O}(F)$），从而提高了样本效率并降低了[过拟合](@entry_id:139093)的风险。

更进一步，一个典型的基序发现网络的架构设计巧妙地利用了[等变性](@entry_id:636671)与[不变性](@entry_id:140168)。网络的前几层是具有[平移等变性](@entry_id:636340)的卷积层，它们负责在序列的每个位置上计算出是否存在基序的“分数”。网络的最后一层通常是一个全局[最大池化](@entry_id:636121)层（global max pooling），它取所有位置上的最大分数。这个池化操作是平移不变的（translation-invariant），因为它只关心是否存在至少一个高分匹配，而不关心这个匹配发生在哪里。这种“等变[特征提取器](@entry_id:637338)”与“不变分类器”的组合，完美地匹配了任务的内在结构：检测一个位置无关的模式的存在性。[@problem_id:2373385]

#### 气候科学：天气模式预测

在[气候科学](@entry_id:161057)中，CNN被广泛用于分析和预测基于网格的地理空间数据，如温度、压力或降水场。这些数据通常被组织在规则的经纬度网格上。地球的几何形状为我们如何处理边界和[平移等变性](@entry_id:636340)提供了直接的物理约束。

经度是周期性的：沿赤道向东移动360度会回到起点。这种拓扑结构天然地对应于“循环填充”（circular padding）。当一个[卷积核](@entry_id:635097)在经度方向上移动到数据网格的边缘时，循环填充允许它“环绕”到另一端，从而无缝地处理跨越国际日期变更线的天气模式（如风暴系统）。在这种设置下，如果输入的天气图沿经度方向平移，使用了循环填充的CNN能够产生一个同样沿经度平移的预测图，保持了完美的[平移等变性](@entry_id:636340)。

相比之下，纬度不是周期性的；南北两极是物理边界。因此，在纬度方向上使用循环填充是不符合物理现实的。更合适的选择是“[零填充](@entry_id:637925)”（zero padding）或“反射填充”（reflective padding）。这种混合填充策略——经度方向循环，纬度方向非循环——是利用领域知识来指导模型架构设计的典型例子。一个实验可以验证这一点：在一个同时具有周期性和[非周期性](@entry_id:275873)边界的数据上，我们可以测试沿不同轴平移时的[等变性](@entry_id:636671)。结果表明，只有当平移方向和填充策略的周期性相匹配时，完美的[平移等变性](@entry_id:636340)才能得到保持。例如，在经度方向（循环填充）进行平移可以保持[等变性](@entry_id:636671)，而在纬度方向（零填充）进行平移则会在边界处破坏[等变性](@entry_id:636671)。这说明，正确地建模数据的边界条件对于维持有意义的[等变性](@entry_id:636671)至关重要。[@problem_id:3196051]

### 信号处理与[机器人学](@entry_id:150623)中的应用

[平移等变性](@entry_id:636340)的概念源于信号处理，并在机器人感知等领域有着直接的应用。

#### 信号超分辨率

在信号处理中，超分辨率任务旨在从一个低分辨率信号重建一个高分辨率版本。这本质上是一个[上采样](@entry_id:275608)问题。CNN中常见的两种上[采样方法](@entry_id:141232)是[转置卷积](@entry_id:636519)和基于插值的[上采样](@entry_id:275608)。

从[等变性](@entry_id:636671)的角度看，这两种方法有着根本的区别。步幅[转置卷积](@entry_id:636519)（strided transposed convolution）在代数上是一个真正的卷积操作，它通过在低分辨率信号的样本之间插入零点，然后应用一个[卷积核](@entry_id:635097)来生成高分辨率输出。由于其卷积的本质，该操作对于与其步幅因子$s$相匹配的平移是等变的。也就是说，将低分辨率输入平移1个单位，等同于将高分辨率输出平移$s$个单位。[@problem_id:3196112]

与此相反，许多基于插值的上[采样方法](@entry_id:141232)，例如线性插值，其行为取决于特定的[坐标映射](@entry_id:747874)方案。一些方案（如PyTorch中的 `align_corners=True`）将插值网格的端点与输入/输出信号的端点对齐。这种对齐方式使得插值权重依赖于样本在整个网格中的绝对位置，从而破坏了[平移等变性](@entry_id:636340)。对输入信号进行平移，并不会导致输出信号发生一个简单的、一致的平移。这个例子清楚地说明，看似相似的[上采样](@entry_id:275608)操作，其底层的数学结构决定了它们是否能保持[等变性](@entry_id:636671)这一重要的信号处理属性。[@problem_id:3196112]

#### 计算摄影：图像去马赛克

在数码相机中，传感器上的彩色滤光阵列（CFA），如常见的拜耳滤光阵列（Bayer pattern），使得每个像素只捕捉红、绿、蓝三种颜色中的一种。去马赛克（Demosaicing）是从这种不完整的、带有马赛克模式的原始传感器数据中重建全彩色图像的过程。

这是一个精妙的[平移等变性](@entry_id:636340)应用场景。拜耳滤光阵列具有$2 \times 2$的周期性结构。当原始传感器数据发生一个像素的平移时，不仅图像内容被平移，每个像素对应的颜色通道（R, G, B）也会发生改变。例如，一个向右平移一格的操作可能会将一个原本捕捉红色光的像素位置变成一个捕捉绿色光的像素位置。

一个简单的CNN无法直接处理这种复杂的变换。然而，通过一个名为“[相位提升](@entry_id:753386)”（phase-lifting）或“[空洞卷积](@entry_id:636365)的逆操作”（space-to-depth）的技巧，我们可以将问题转化。我们将$2 \times 2$的拜耳块中的四个像素（例如，RGGB）重新[排列](@entry_id:136432)到四个独立的通道中，从而将一个$H \times W$的单通道马赛克图像转换为一个 $(H/2) \times (W/2)$ 的四通道特征图。在这个“相位”空间中，原先的一个像素平移现在分解为一个在粗糙网格上的平移和四个相位通道之间的[置换](@entry_id:136432)。因此，一个真正具有[平移等变性](@entry_id:636340)的去马赛克网络，必须对其内部特征表示同时具有空间[平移等变性](@entry_id:636340)和通道[置换](@entry_id:136432)[等变性](@entry_id:636671)。这可以通过在相位空间中应用[权重共享](@entry_id:633885)的卷积来实现。最终，网络输出每个相位的全彩预测，再通过一个“相位重组”（phase-shuffle）操作（depth-to-space）将其拼接回一个全分辨率的彩色图像。这种精心设计的架构，通过将复杂的平移分解为更简单的对称性，保证了最终的去马赛克过程对于输入平移的鲁棒性。[@problem_id:3196066]

#### 机器人学：触觉感知

在机器人学中，触觉传感器（或电子皮肤）阵列可以生成一个“触觉图”，表示施加在机器人表面各处的[压力分布](@entry_id:275409)。CNN可以被用来解释这些触觉图，以识别接触物体的形状、纹理或姿态。

在许多场景中，物体接触的位置可能是未知的或变化的。因此，一个理想的触觉处理模型应该能够以同样的方式识别一个物体，无论它接触在传感器的哪个位置。这正是[平移等变性](@entry_id:636340)的用武之地。它使得一个在仿真环境中（例如，物体在中心位置接触）训练的模型能够被直接迁移（sim-to-real transfer）到真实世界中，并能很好地泛化到物体在不同位置接触的场景，因为模型的核心[特征提取器](@entry_id:637338)是位置无关的。

与气候数据类似，触觉传感器的物理边界也对如何实现[等变性](@entry_id:636671)提出了要求。使用“零填充”会导致在传感器边缘的计算结果不准确，从而在边界附近破坏[等变性](@entry_id:636671)。一个更合理的做法是仅在能够确保卷积核完全位于传感器有效区域内的“安全”内部区域进行分析。或者，如果传感器阵列具有某种周期性（例如，在一个圆柱形手指上），“循环填充”将是更合适的选择。此外，如果在触觉处理CNN中使用了带步幅的卷积，那么对于非步幅整数倍的微小接触位置变化，模型同样会表现出定位误差，这对于需要精确接触定位的抓取任务来说是一个重要的考量因素。[@problem_id:3196034]

### 先进与混合架构中的[平移等变性](@entry_id:636340)

[平移等变性](@entry_id:636340)的思想也贯穿于更现代、更复杂的[神经网络架构](@entry_id:637524)的设计中，并常常成为理解其行为和性能的关键。

#### 架构的组成部分：填充、步幅与归一化

一个CNN的整体[等变性](@entry_id:636671)是由其各个组成部分的性质共同决定的。
- **卷积与激活函数**：步幅为1的卷积（或互相关）是平移等变算子的原型。[空洞卷积](@entry_id:636365)（Dilated convolution）通过扩大[卷积核](@entry_id:635097)的采样间隔来增加感受野，但由于其仍然是线性移不变的滤波器，只要步幅为1，它同样保持[平移等变性](@entry_id:636340)。逐点[非线性激活函数](@entry_id:635291)（如ReLU）由于其操作在每个空间位置上是独立的，因此也完美地保持了[平移等变性](@entry_id:636340)。[@problem_id:3196103]
- **填充**：如前所述，填充策略对于在有限尺寸的信号上保持[等变性](@entry_id:636671)至关重要。在自然语言处理（NLP）的字符级CNN中，通常会对短句进行“零填充”以达到固定长度。这种做法在序列的边界处破坏了[等变性](@entry_id:636671)，因为平移会将有意义的字符移入或移出填充区域。相比之下，“循环填充”虽然在数学上能保持完美的[等变性](@entry_id:636671)，但它会引入人为的“环绕”效应，即让序列的结尾与开头相互作用，这在大多数NLP任务中是不符合语义逻辑的。因此，选择填充策略是在维持数学上的理想属性和符合领域知识之间的权衡。[@problem_id:3196115]
- **下采样**：带步幅的[卷积和](@entry_id:263238)[池化层](@entry_id:636076)是破坏完美[等变性](@entry_id:636671)的主要因素，它们将严格的[等变性](@entry_id:636671)降级为仅对步幅整数倍的平移近似等变。[@problem_id:3196103]
- **[归一化层](@entry_id:636850)**：某些[归一化层](@entry_id:636850)，如[实例归一化](@entry_id:638027)（Instance Normalization），通过计算并归一化单个样本在所有空间位置上的特征统计量（均值和[标准差](@entry_id:153618)）。由于这些统计量是在整个空间范围内计算的，它们本身是平移不变的。因此，对一个等变的特征图应用[实例归一化](@entry_id:638027)，会得到一个同样等变的输出[特征图](@entry_id:637719)。这表明这类归一化方法与[平移等变性](@entry_id:636340)的设计目标是兼容的。[@problem_id:3196103]

#### [混合模型](@entry_id:266571)：注意力增强的CNN

为了结合CNN的局部[归纳偏置](@entry_id:137419)和[注意力机制](@entry_id:636429)的全局依赖建模能力，研究者们提出了多种[混合模型](@entry_id:266571)。在一个注意力增强的CNN模块中，通常会有一个标准的卷积分支和一个并行的注意力分支，两者的输出最终被结合起来。

卷积分支自然是平移等变的。然而，注意力分支的设计可能会引入位置依赖性。例如，一种注意力机制可能会计算输入特征图的全局平均值，然后用这个全局信息去调制一个固定的、绝对位置编码的模式，从而生成一个内容相关但位置敏感的注意力图。这个注意力图再与卷积分支的输出进行逐元素相乘。在这种设计下，尽管卷积部分是等变的，但与一个位置依赖的注意力图相乘后，整个模块就不再具有[平移等变性](@entry_id:636340)了。这是为了获得全局上下文信息而有意识地牺牲部分局部[等变性](@entry_id:636671)的一种设计权衡。只有在一些特殊情况下，例如当输入信号为零时，[等变性](@entry_id:636671)才可能偶然成立。[@problem_id:3196044]

#### [多任务学习](@entry_id:634517)

在[多任务学习](@entry_id:634517)（multi-task learning）中，多个相关任务通常会共享一个共同的“主干”网络（backbone），用于提取通用特征。如果这些任务都受益于位置无关的[特征检测](@entry_id:265858)，那么采用一个具有强[平移等变性](@entry_id:636340)的共享主干网络将是一个非常有效的设计。

共享一个严格等变的[特征提取器](@entry_id:637338)，相比于为每个任务单独设计一个可能存在微小非[等变性](@entry_id:636671)（例如，由位置相关的噪声或扰动引起）的[特征提取器](@entry_id:637338)，能够带来“跨任务一致性”的好处。这个共享的、受约束的表示空间鼓励模型学习更鲁棒、更可迁移的特征。我们可以设计一个实验来量化这种“跨任务效益”：比较两种设置下的模型在输入平移时的表现。第一种设置是多个任务共享一个完美的等变主干；第二种是每个任务使用一个被轻微位置[相关噪声](@entry_id:137358)破坏的独立主干。结果表明，共享主干的设置在所有任务上都表现出更强的平移一致性，其总误差远小于独立模型的误差之和。这证明了通过共享一个严格遵循对称性（如[平移等变性](@entry_id:636340)）的模块，可以提升整个多任务系统的鲁棒性和泛化能力。[@problem_id:3196027]

#### 类[Transformer架构](@entry_id:635198)：Patch化模型

近年来，以Vision Transformer (ViT)为代表的架构在计算机视觉领域取得了巨大成功。这类模型通常首先将输入[图像分割](@entry_id:263141)成一系列不重叠的小块（patch），然后将这些小块线性嵌入后送入一个Transformer编码器。这种“patch化”的预处理步骤改变了我们思考[平移等变性](@entry_id:636340)的方式。

对于这类模型，我们关心的是一种“块[平移等变性](@entry_id:636340)”（patch-shift equivariance）：当输入图像的平移量恰好是patch大小的整数倍时，模型的输出是否也相应地在patch网格上发生平移？答案取决于模型后续的操作。如果模型对每个patch应用共享的线性嵌入，并且在patch网格上应用标准的卷积操作（如ConvNeXt架构所做的那样），那么这种块[平移等变性](@entry_id:636340)是能够保持的。这是因为将图像平移一个patch的距离，等价于对patch序列进行一次[循环移位](@entry_id:177315)，而后续的共享权重操作对于这种[移位](@entry_id:145848)是等变的。

然而，标准的ViT架构通过引入“绝对位置编码”（absolute positional encoding）来为每个patch注入其在图像中的位置信息。这种做法显式地破坏了[平移等变性](@entry_id:636340)，因为模型现在可以直接“看到”每个patch的绝对位置。同样，如果模型为每个patch位置使用不同的、非共享的嵌入权重，也会破坏[等变性](@entry_id:636671)。因此，现代视觉架构的设计，正是在CNN固有的强大[平移等变性](@entry_id:636340)偏置和Transformer提供的灵活全局依赖建模能力之间进行探索和权衡。[@problem_id:3196104]

### 结论

本章通过一系列来自不同领域的应用案例，揭示了[平移等变性](@entry_id:636340)作为一个核心概念的广度和深度。我们看到，它不仅仅是CNN内部的一个数学属性，更是一种强大的[归纳偏置](@entry_id:137419)，使得网络能够高效地学习到位置无关的特征，从而在[图像分割](@entry_id:263141)、[目标检测](@entry_id:636829)、基因序列分析和天气预测等任务中表现出色。

同时，我们也系统地探讨了[平移等变性](@entry_id:636340)在实践中是如何被打破的。步幅、池化、特定的插值方法以及对绝对位置的依赖（如位置编码）都会将完美的[等变性](@entry_id:636671)降级为近似的、或在特定条件下才成立的属性。理解这些破坏[等变性](@entry_id:636671)的机制，以及它们带来的利弊（例如，扩大感受野但牺牲定位精度），是设计和调试高级神经[网络模型](@entry_id:136956)的关键技能。

从经典的CNN到现代的混合架构和Vision Transformer，[平移等变性](@entry_id:636340)的思想始终贯穿其中，并持续启发着新一代模型的创新。它提醒我们，深刻理解并善用数据与任务中的内在对称性，是通往构建更高效、更鲁棒、更具泛化能力的人工智能系统的重要途径。