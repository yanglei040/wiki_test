{"hands_on_practices": [{"introduction": "分类模型的输出分数本身并不构成最终决策。我们需要设定一个决策阈值，以将分数转化为具体的类别预测。这个阈值的选择对模型的性能至关重要，通常我们会根据特定指标（如$F1$分数）在验证集上进行优化。然而，当模型部署到真实世界后，数据的分布可能发生变化（即分布偏移），导致原先最优的阈值不再适用。[@problem_id:3178377]这个实践将指导你模拟一种常见的分布偏移——类别先验概率变化（prior shift），并学习如何使用重要性加权方法来重新校准决策阈值，这是确保模型在动态环境中保持鲁棒性的核心技能。", "problem": "给定一个多标签分类场景，其中每个类别的决策是相互独立的。对于每个类别标签 $y \\in \\{0,1,2\\}$，一个模型会生成一个校准分数 $s \\in [0,1]$，该分数可以解释为后验概率 $p(y=1 \\mid x)$。一个逐类决策规则对某个实例的类别 $y$ 预测为正，当且仅当 $s \\ge \\tau_y$，其中 $\\tau_y \\in [0,1]$ 是一个为最大化 F1 分数而选择的阈值。F1 分数是精确率和召回率的调和平均数，对于一个固定的类别，其定义如下\n$$\n\\text{precision} = \\frac{\\text{TP}}{\\text{TP} + \\text{FP}}, \\quad \\text{recall} = \\frac{\\text{TP}}{\\text{TP} + \\text{FN}}, \\quad \\text{F1} = \\frac{2 \\cdot \\text{precision} \\cdot \\text{recall}}{\\text{precision} + \\text{recall}} = \\frac{2 \\cdot \\text{TP}}{2 \\cdot \\text{TP} + \\text{FP} + \\text{FN}},\n$$\n其中 $\\text{TP}$、$\\text{FP}$、$\\text{FN}$ 分别表示真阳性、伪阳性、伪阴性，所有这些都是相对于阈值 $\\tau_y$ 计算的。\n\n您将分析在先验漂移（也称标签漂移）下的阈值校准稳定性，其中类别先验概率 $\\pi_y = p(y=1)$ 变为一个新值 $\\pi_y'$，而类条件分数分布 $p(s \\mid y)$ 保持不变。在此假设下，可以通过对每个正实例赋予权重 $w_{+} = \\pi_y' / \\pi_y$ 和对每个负实例赋予权重 $w_{-} = (1-\\pi_y')/(1-\\pi_y)$ 的重要性加权方法，来获得新先验下的期望混淆计数。对于一个候选阈值 $\\tau$，加权计数为\n$$\n\\text{TP}_w(\\tau) = \\sum_{i} w_{+} \\cdot \\mathbf{1}\\{y_i=1\\} \\cdot \\mathbf{1}\\{s_i \\ge \\tau\\}, \\quad\n\\text{FP}_w(\\tau) = \\sum_{i} w_{-} \\cdot \\mathbf{1}\\{y_i=0\\} \\cdot \\mathbf{1}\\{s_i \\ge \\tau\\},\n$$\n$$\n\\text{FN}_w(\\tau) = \\sum_{i} w_{+} \\cdot \\mathbf{1}\\{y_i=1\\} \\cdot \\mathbf{1}\\{s_i  \\tau\\},\n$$\n加权 F1 为\n$$\n\\text{F1}_w(\\tau) = \\frac{2 \\cdot \\text{TP}_w(\\tau)}{2 \\cdot \\text{TP}_w(\\tau) + \\text{FP}_w(\\tau) + \\text{FN}_w(\\tau)}.\n$$\n\n任务：编写一个程序，对于每个类别 $y \\in \\{0,1,2\\}$，在验证集上计算 F1 最优阈值，然后使用重要性加权计算指定先验漂移下的 F1 最优阈值，最后量化漂移下的稳定性和性能。\n\n在您的推理和实现中使用的基本依据：精确率、召回率、F1的定义；指示函数 $\\mathbf{1}\\{\\cdot\\}$；以及标签漂移假设，即 $p(s \\mid y)$ 是不变的，而 $\\pi_y$ 改变，这允许使用 $w_{+} = \\pi_y'/\\pi_y$ 和 $w_{-} = (1-\\pi_y')/(1-\\pi_y)$ 进行重要性加权。\n\n验证数据（针对每个类别 $y$）是固定的，如下所示。对于类别 $y=0$，\n$$\n\\mathbf{s}^{(0)} = [0.95, 0.80, 0.60, 0.55, 0.52, 0.50, 0.40, 0.30, 0.20, 0.10, 0.05, 0.01], \\\\\n\\mathbf{y}^{(0)} = [1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0].\n$$\n对于类别 $y=1$，\n$$\n\\mathbf{s}^{(1)} = [0.90, 0.88, 0.70, 0.65, 0.60, 0.55, 0.50, 0.49, 0.35, 0.33, 0.25, 0.15], \\\\\n\\mathbf{y}^{(1)} = [1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0].\n$$\n对于类别 $y=2$，\n$$\n\\mathbf{s}^{(2)} = [0.99, 0.85, 0.75, 0.60, 0.45, 0.40, 0.35, 0.32, 0.20, 0.18, 0.10, 0.02], \\\\\n\\mathbf{y}^{(2)} = [1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0].\n$$\n\n设类别 $y$ 的经验先验是验证集中的比例 $\\pi_y = \\frac{1}{n}\\sum_{i=1}^{n} \\mathbf{1}\\{y_i=1\\}$。给定漂移后环境的目标先验 $\\pi_y'$ 如下\n$$\n\\pi_0' = 0.70, \\quad \\pi_1' = 0.20, \\quad \\pi_2' = \\frac{1}{6}.\n$$\n\n每个类别 $y$ 的计算要求：\n- 从验证标签中计算 $\\pi_y$。\n- 通过搜索一个有限的候选阈值集合来找到未加权的 F1 最优阈值 $\\tau_y$。使用 $\\mathbf{s}^{(y)}$ 中所有唯一值以及 0 和一个严格大于最大分数的值（例如 $\\max(\\mathbf{s}^{(y)}) + 10^{-12}$）作为候选值。当 $s \\ge \\tau$ 时预测为正。如果多个阈值得出相同的最大 F1，则选择这些最大化阈值中的最小值来打破平局。\n- 在漂移后的先验 $\\pi_y'$ 下，计算 $w_{+} = \\pi_y'/\\pi_y$ 和 $w_{-} = (1-\\pi_y')/(1-\\pi_y)$。使用相同的候选集和打破平局规则，找到使 $\\text{F1}_w(\\tau)$ 最大化的加权 F1 最优阈值 $\\tau_y^{\\text{shift}}$。\n- 计算绝对阈值变化 $\\Delta \\tau_y = |\\tau_y^{\\text{shift}} - \\tau_y|$。\n- 计算在使用原始阈值 $\\text{F1}_w(\\tau_y)$ 和使用漂移后最优阈值 $\\text{F1}_w(\\tau_y^{\\text{shift}})$ 时，在漂移后先验下的加权 F1。\n\n测试套件：使用上述指定的三个类别及其各自的 $\\pi_y'$ 值。您的程序必须输出单行，其中包含按 $y=0$、$y=1$、$y=2$ 的顺序排列的跨类别结果的扁平化列表，每个类别的五个指标按以下顺序排列：\n$$\n[\\tau_0, \\ \\tau_0^{\\text{shift}}, \\ \\Delta \\tau_0, \\ \\text{F1}_w(\\tau_0), \\ \\text{F1}_w(\\tau_0^{\\text{shift}}), \\ \\tau_1, \\ \\tau_1^{\\text{shift}}, \\ \\Delta \\tau_1, \\ \\text{F1}_w(\\tau_1), \\ \\text{F1}_w(\\tau_1^{\\text{shift}}), \\ \\tau_2, \\ \\tau_2^{\\text{shift}}, \\ \\Delta \\tau_2, \\ \\text{F1}_w(\\tau_2), \\ \\text{F1}_w(\\tau_2^{\\text{shift}})].\n$$\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，每个数字四舍五入到恰好6位小数。例如，输出应类似于 $[0.123456,0.234567, \\dots]$，不含多余的空格或文本。不应读取用户输入；所有数据均如上所述并嵌入程序中。此问题不涉及物理单位或角度，因此无需进行单位转换。", "solution": "该问题定义明确，科学上合理，并为得出唯一解提供了所有必要信息。这是一个关于分类器评估和适应标签分布漂移的标准练习，是应用机器学习中的一个核心课题。因此，我们可以着手求解。\n\n任务是分析一个二元分类器的 F1 最优决策阈值在类别先验概率发生特定变化（即先验或标签漂移）下的稳定性。对于三个类别中的每一个，我们首先将在验证集上确定最优阈值 $\\tau_y$。然后，我们将模拟先验从经验先验 $\\pi_y$ 到目标先验 $\\pi_y'$ 的漂移，并通过最大化一个重要性加权的 F1 分数 $\\text{F1}_w(\\tau)$ 来找到新的最优阈值 $\\tau_y^{\\text{shift}}$。最后，我们将量化阈值的不稳定性以及对性能的影响。\n\n基本原理是，F1 分数（定义为 $\\text{F1} = \\frac{2 \\cdot \\text{TP}}{2 \\cdot \\text{TP} + \\text{FP} + \\text{FN}}$）平衡了精确率和召回率。对于给定的分数分布和类别先验，最优阈值 $\\tau_y$ 代表了这种平衡被最大化的点。当先验 $\\pi_y = p(y=1)$ 改变时，伪阳性（$\\text{FP}$）与伪阴性（$\\text{FN}$）的相对成本也随之改变。重要性加权是一种无需重新训练模型或重新收集标记数据，即可估计分类器在新先验下性能的技术。每个原始的正实例被赋予权重 $w_{+} = \\pi_y' / \\pi_y$，每个负实例被赋予权重 $w_{-} = (1-\\pi_y') / (1-\\pi_y)$。这会对混淆矩阵的计数进行重新加权，以反映它们在目标分布中的期望频率。\n\n加权 F1 分数的计算公式如下：\n$$\n\\text{F1}_w(\\tau) = \\frac{2 \\cdot \\text{TP}_w(\\tau)}{2 \\cdot \\text{TP}_w(\\tau) + \\text{FP}_w(\\tau) + \\text{FN}_w(\\tau)}\n$$\n其中 $\\text{TP}_w(\\tau) = w_{+} \\cdot \\text{TP}(\\tau)$，$\\text{FP}_w(\\tau) = w_{-} \\cdot \\text{FP}(\\tau)$，以及 $\\text{FN}_w(\\tau) = w_{+} \\cdot \\text{FN}(\\tau)$。未加权的计数 $\\text{TP}(\\tau)$、$\\text{FP}(\\tau)$ 和 $\\text{FN}(\\tau)$ 是在原始验证数据上针对给定阈值 $\\tau$ 计算的。\n\n对最优阈值 $\\tau_y$ 和 $\\tau_y^{\\text{shift}}$ 的搜索是在一个候选集上进行的，该候选集由验证数据中所有唯一的分数，加上 0 和一个比最大分数略大的值组成。这确保我们评估了数据所有可能的分区，以及预测全为负或全为正的平凡分类器。\n\n我们现在将对每个类别执行此过程。\n\n**类别 $y=0$**\n\n提供的数据如下：\n$\\mathbf{s}^{(0)} = [0.95, 0.80, 0.60, 0.55, 0.52, 0.50, 0.40, 0.30, 0.20, 0.10, 0.05, 0.01]$\n$\\mathbf{y}^{(0)} = [1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]$\n\n1.  **计算经验先验 $\\pi_0$**：在 $n=12$ 个实例中，有 $P=5$ 个正实例和 $N=7$ 个负实例。\n    经验先验为 $\\pi_0 = P/n = 5/12$。\n\n2.  **找到未加权的 F1 最优阈值 $\\tau_0$**：我们遍历所有候选阈值 $\\tau$ 并计算 $\\text{F1}(\\tau) = \\frac{2 \\cdot \\text{TP}(\\tau)}{2 \\cdot \\text{TP}(\\tau) + \\text{FP}(\\tau) + \\text{FN}(\\tau)}$。\n    发现在 $\\tau = 0.52$ 时 F1 分数达到最大值，约为 $0.8$。在此阈值下，$\\text{TP}=4$，$\\text{FP}=1$，$\\text{FN}=1$，得出 $\\text{F1} = (2 \\cdot 4)/(2 \\cdot 4 + 1 + 1) = 8/10 = 0.8$。\n    因此，$\\tau_0 = 0.52$。\n\n3.  **计算重要性权重**：给定的目标先验为 $\\pi_0' = 0.70$。\n    $w_{+} = \\frac{\\pi_0'}{\\pi_0} = \\frac{0.70}{5/12} = \\frac{7/10}{5/12} = \\frac{84}{50} = 1.68$。\n    $w_{-} = \\frac{1-\\pi_0'}{1-\\pi_0} = \\frac{0.30}{7/12} = \\frac{3/10}{7/12} = \\frac{36}{70} \\approx 0.514286$。\n    由于 $\\pi_0'  \\pi_0$，正样本变得更重要（$w_+  1$），而负样本则不那么重要（$w_-  1$）。这将倾向于使用更低的阈值以提高召回率。\n\n4.  **找到加权的 F1 最优阈值 $\\tau_0^{\\text{shift}}$**：我们遍历相同的候选阈值，这次是最大化 $\\text{F1}_w(\\tau)$。发现最大加权 F1 分数约为 $0.890909$，这出现在 $\\tau=0.20$ 处。在此阈值下，我们有 $\\text{TP}=5$ 和 $\\text{FP}=4$。加权计数为 $\\text{TP}_w = 1.68 \\cdot 5 = 8.4$，$\\text{FP}_w = (36/70) \\cdot 4 \\approx 2.057143$，以及 $\\text{FN}_w = 1.68 \\cdot 0 = 0$。这得出 $\\text{F1}_w = (2 \\cdot 8.4) / (2 \\cdot 8.4 + 2.057143 + 0) \\approx 0.890909$。\n    因此，$\\tau_0^{\\text{shift}} = 0.20$。\n\n5.  **计算类别 0 的最终指标**：\n    - $\\tau_0 = 0.52$\n    - $\\tau_0^{\\text{shift}} = 0.20$\n    - $\\Delta \\tau_0 = |\\tau_0^{\\text{shift}} - \\tau_0| = |0.20 - 0.52| = 0.32$\n    - $\\text{F1}_w(\\tau_0) = \\text{F1}_w(0.52)$: 当 $\\text{TP}=4, \\text{FP}=1, \\text{FN}=1$ 时, 加权 F1 为 $\\text{F1}_w = (2 \\cdot 1.68 \\cdot 4) / (2 \\cdot 1.68 \\cdot 4 + (36/70) \\cdot 1 + 1.68 \\cdot 1) \\approx 0.859654$。\n    - $\\text{F1}_w(\\tau_0^{\\text{shift}}) = \\text{F1}_w(0.20) \\approx 0.890909$。调整阈值可以提高新先验下的 F1 分数。\n\n**类别 $y=1$**\n\n对类别 $y=1$ 的数据遵循相同的步骤：\n$\\mathbf{s}^{(1)} = [0.90, ..., 0.15]$, $\\mathbf{y}^{(1)} = [1, ..., 0]$\n$\\pi_1 = 5/12$, 目标 $\\pi_1' = 0.20$。\n$w_{+} = \\frac{0.20}{5/12} = 0.48$。\n$w_{-} = \\frac{0.80}{7/12} \\approx 1.371429$。\n在这里，正例的先验概率降低，使得伪阳性的相对成本更高。我们预计最优阈值会增加。\n- 未加权优化得出的最大 F1 分数为 $2/3 \\approx 0.666667$，这出现在阈值 $\\tau \\in \\{0.33, 0.50, 0.65\\}$。应用打破平局规则（最小阈值），我们得到 $\\tau_1 = 0.33$。\n- 加权优化在 $\\tau=0.65$ 处得出最大加权 F1 分数约为 $0.552632$。因此，$\\tau_1^{\\text{shift}} = 0.65$。\n- 最终指标为：$\\tau_1 = 0.33$, $\\tau_1^{\\text{shift}} = 0.65$, $\\Delta \\tau_1 = 0.32$, $\\text{F1}_w(\\tau_1) \\approx 0.411765$, 以及 $\\text{F1}_w(\\tau_1^{\\text{shift}}) \\approx 0.552632$。\n\n**类别 $y=2$**\n\n对类别 $y=2$ 的数据遵循相同的步骤：\n$\\mathbf{s}^{(2)} = [0.99, ..., 0.02]$, $\\mathbf{y}^{(2)} = [1, ..., 0]$\n$\\pi_2 = 2/12 = 1/6$, 目标 $\\pi_2' = 1/6$。\n在这个特殊情况下，先验没有改变，$\\pi_2' = \\pi_2$。\n这意味着重要性权重为 $w_{+} = 1$ 和 $w_{-} = 1$。加权 F1 分数与未加权 F1 分数相同，即对于所有 $\\tau$ 都有 $\\text{F1}_w(\\tau) = \\text{F1}(\\tau)$。因此，优化问题保持不变。\n- 未加权优化得出的最大 F1 分数为 $2/3 \\approx 0.666667$，这出现在阈值 $\\tau \\in \\{0.60, 0.99\\}$。应用打破平局规则，我们得到 $\\tau_2 = 0.60$。\n- 由于问题未变，$\\tau_2^{\\text{shift}} = \\tau_2 = 0.60$。\n- 最终指标为：$\\tau_2 = 0.60$, $\\tau_2^{\\text{shift}} = 0.60$, $\\Delta \\tau_2 = 0.0$, $\\text{F1}_w(\\tau_2) \\approx 0.666667$, 以及 $\\text{F1}_w(\\tau_2^{\\text{shift}}) \\approx 0.666667$。\n\n这些计算出的值将通过编程计算并按要求格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to perform the analysis for all three classes and print the final results.\n    \"\"\"\n    \n    # Define the datasets and target priors for each class as per the problem statement.\n    problem_data = [\n        {\n            \"class_id\": 0,\n            \"scores\": np.array([0.95, 0.80, 0.60, 0.55, 0.52, 0.50, 0.40, 0.30, 0.20, 0.10, 0.05, 0.01]),\n            \"labels\": np.array([1, 1, 1, 0, 1, 0, 0, 0, 1, 0, 0, 0]),\n            \"pi_prime\": 0.70\n        },\n        {\n            \"class_id\": 1,\n            \"scores\": np.array([0.90, 0.88, 0.70, 0.65, 0.60, 0.55, 0.50, 0.49, 0.35, 0.33, 0.25, 0.15]),\n            \"labels\": np.array([1, 0, 1, 1, 0, 0, 1, 0, 0, 1, 0, 0]),\n            \"pi_prime\": 0.20\n        },\n        {\n            \"class_id\": 2,\n            \"scores\": np.array([0.99, 0.85, 0.75, 0.60, 0.45, 0.40, 0.35, 0.32, 0.20, 0.18, 0.10, 0.02]),\n            \"labels\": np.array([1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0]),\n            \"pi_prime\": 1/6\n        }\n    ]\n\n    all_results = []\n\n    for data in problem_data:\n        scores = data[\"scores\"]\n        labels = data[\"labels\"]\n        pi_y_prime = data[\"pi_prime\"]\n\n        n = len(labels)\n        positives_count = np.sum(labels)\n        \n        # Guard against zero positive instances\n        if positives_count == 0:\n            pi_y = 0.0\n        else:\n            pi_y = positives_count / n\n\n        # Define candidate thresholds according to the problem specification\n        candidate_thresholds = np.unique(scores)\n        candidate_thresholds = np.append(candidate_thresholds, 0)\n        candidate_thresholds = np.append(candidate_thresholds, np.max(scores) + 1e-12)\n        candidate_thresholds = np.unique(candidate_thresholds) # Ensure no duplicates\n\n        # Calculate importance weights, handle edge case if pi_y is 0 or 1\n        w_plus, w_minus = 1.0, 1.0\n        if pi_y > 0 and pi_y  1:\n            w_plus = pi_y_prime / pi_y\n            w_minus = (1 - pi_y_prime) / (1 - pi_y)\n        elif pi_y == 0 and pi_y_prime > 0:\n            # Undefined case, but won't happen with given data\n            pass\n        elif pi_y == 1 and pi_y_prime  1:\n            # Undefined case, but won't happen with given data\n            pass\n\n        unweighted_f1_results = []\n        weighted_f1_results = []\n\n        for tau in candidate_thresholds:\n            predictions = (scores >= tau).astype(int)\n            \n            tp = np.sum((predictions == 1)  (labels == 1))\n            fp = np.sum((predictions == 1)  (labels == 0))\n            fn = positives_count - tp\n\n            # Calculate unweighted F1\n            f1_denom = 2 * tp + fp + fn\n            f1 = (2 * tp) / f1_denom if f1_denom > 0 else 0.0\n            unweighted_f1_results.append((f1, tau))\n\n            # Calculate weighted F1\n            tp_w = w_plus * tp\n            fp_w = w_minus * fp\n            fn_w = w_plus * fn\n            \n            f1_w_denom = 2 * tp_w + fp_w + fn_w\n            f1_w = (2 * tp_w) / f1_w_denom if f1_w_denom > 0 else 0.0\n            weighted_f1_results.append((f1_w, tau))\n\n        # Find optimal thresholds by sorting.\n        # Primary sort key: F1 score (descending), Secondary sort key: threshold (ascending)\n        unweighted_f1_results.sort(key=lambda x: (-x[0], x[1]))\n        weighted_f1_results.sort(key=lambda x: (-x[0], x[1]))\n\n        tau_y = unweighted_f1_results[0][1]\n        tau_y_shift = weighted_f1_results[0][1]\n        max_weighted_f1 = weighted_f1_results[0][0]\n\n        # Find the weighted F1 at the original optimal threshold\n        f1_w_at_tau_y = 0.0\n        for f1_w, tau in weighted_f1_results:\n            if np.isclose(tau, tau_y):\n                f1_w_at_tau_y = f1_w\n                break\n        \n        delta_tau_y = np.abs(tau_y_shift - tau_y)\n\n        class_results = [\n            tau_y,\n            tau_y_shift,\n            delta_tau_y,\n            f1_w_at_tau_y,\n            max_weighted_f1\n        ]\n        all_results.extend(class_results)\n    \n    # Format the final output string\n    formatted_results = [f\"{x:.6f}\" for x in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3178377"}, {"introduction": "除了优化训练过程，我们还能在模型推理阶段提升其性能和鲁棒性。测试时数据增强（Test-Time Augmentation, TTA）就是一种强大而无需重新训练的技巧，它通过对单个测试样本生成多个增强版本并聚合其预测结果来实现。[@problem_id:3178424]这个实践将带你深入探索TTA奏效的数学原理，通过将其与凸损失函数（如交叉熵）和Jensen不等式联系起来，你将亲手计算并理解“Jensen间隔”（Jensen gap），从而量化TTA聚合预测而非聚合损失所带来的收益。", "problem": "在深度学习的监督学习分类场景中，给定一个使用测试时增强 (TTA) 的设置。考虑一个带有 softmax 激活函数的线性分类器，由函数 $f_\\theta:\\mathbb{R}^d\\to\\Delta^{C-1}$ 定义，其中 $\\Delta^{C-1}$ 表示 $(C-1)$-单纯形，参数 $\\theta$ 由一个权重矩阵 $W\\in\\mathbb{R}^{C\\times d}$ 组成。对于一个输入 $x\\in\\mathbb{R}^d$，模型产生类别概率 $p=f_\\theta(x)=\\text{softmax}(Wx)$，其中 softmax 函数定义为\n$$\n\\text{softmax}(z)_i=\\frac{\\exp(z_i)}{\\sum_{j=1}^C \\exp(z_j)}\\quad\\text{for }i=1,\\dots,C.\n$$\n设分类损失为多类别交叉熵，用于一个 one-hot 标签 $y\\in\\mathbb{R}^C$，\n$$\n\\ell(p,y)=-\\sum_{i=1}^C y_i \\log p_i.\n$$\n定义 $x$ 上的一个测试时增强有限集 $\\{t_1,\\dots,t_n\\}$ 和一组总和为 $1$ 的非负权重 $\\{w_1,\\dots,w_n\\}$。测试时增强 (TTA) 的预测估计值是各增强下预测的加权平均值，即\n$$\n\\bar{p}=\\mathbb{E}_t\\big[f_\\theta(t(x))\\big]=\\sum_{j=1}^n w_j\\,f_\\theta\\big(t_j(x)\\big).\n$$\n增强下的期望损失为\n$$\n\\mathbb{E}_t\\big[\\ell(f_\\theta(t(x)),y)\\big]=\\sum_{j=1}^n w_j\\,\\ell\\big(f_\\theta(t_j(x)),y\\big).\n$$\nJensen 间隙定义为以下差值\n$$\nJ=\\mathbb{E}_t\\big[\\ell(f_\\theta(t(x)),y)\\big]-\\ell\\big(\\mathbb{E}_t[f_\\theta(t(x))],y\\big),\n$$\n当 $\\ell$ 对于 $p$ 是凸函数时，该值量化了在应用损失函数前对预测进行平均所带来的好处。\n\n从监督学习中期望风险、softmax 函数和负对数函数凸性的基本定义出发，实现一个程序来为几个测试用例计算 Jensen 间隙 $J$。所有数学实体必须被精确处理，并且计算必须是数值稳定的。\n\n使用以下增强函数，每个函数都作用于 $x\\in\\mathbb{R}^d$：\n- 恒等：$t_{\\text{id}}(x)=x$。\n- 加性噪声：$t_{\\text{noise}}(x)=x+\\epsilon$，其中 $\\epsilon\\in\\mathbb{R}^d$ 是指定的。\n- 特征掩码：$t_{\\text{mask}}(x)=m\\odot x$，其中 $m\\in\\mathbb{R}^d$ 且 $\\odot$ 表示逐元素乘法。\n- 缩放：$t_{\\text{scale}}(x)=s\\,x$，其中 $s\\in\\mathbb{R}$。\n\n您的程序必须为每个测试用例实现以下计算：\n1. 对于每个增强 $t_j$，计算 $p^{(j)}=f_\\theta\\big(t_j(x)\\big)=\\text{softmax}\\big(W\\,t_j(x)\\big)$。\n2. 计算 $\\bar{p}=\\sum_{j=1}^n w_j\\,p^{(j)}$。\n3. 计算期望损失 $\\mathbb{E}_t[\\ell(f_\\theta(t(x)),y)]=\\sum_{j=1}^n w_j\\,\\ell\\big(p^{(j)},y\\big)$。\n4. 计算 Jensen 间隙 $J=\\mathbb{E}_t[\\ell(f_\\theta(t(x)),y)]-\\ell(\\bar{p},y)$。\n\n将每个 Jensen 间隙表示为一个实数（浮点数）。为保证数值稳定性，任何对数运算都应适当处理接近于零的概率，以避免出现未定义值。\n\n测试套件：\n- 案例 1 (一般情况；均匀权重):\n  - $C=3$, $d=4$。\n  - $W=\\begin{bmatrix}1.2  -0.9  0.3  0.0\\\\ -0.5  1.1  0.7  0.8\\\\ 0.0  0.4  1.0  -0.7\\end{bmatrix}$。\n  - $x=\\begin{bmatrix}0.6  -0.2  1.0  0.5\\end{bmatrix}$。\n  - $y=\\begin{bmatrix}0  1  0\\end{bmatrix}$。\n  - 增强：$t_{\\text{id}}$，$t_{\\text{noise}}$ (其中 $\\epsilon=\\begin{bmatrix}0.05  -0.03  0.02  -0.01\\end{bmatrix}$)，$t_{\\text{mask}}$ (其中 $m=\\begin{bmatrix}1.0  0.7  0.9  1.0\\end{bmatrix}$)，$t_{\\text{scale}}$ (其中 $s=1.1$)。\n  - 权重：$w_j=\\frac{1}{4}$ (对于 $j=1,2,3,4$)。\n- 案例 2 (边界情况；相同的预测导致间隙为零，取决于数值精度；均匀权重):\n  - $C=3$, $d=4$。\n  - $W=\\begin{bmatrix}1.2  -0.9  0.3  0.0\\\\ -0.5  1.1  0.7  0.8\\\\ 0.0  0.4  1.0  -0.7\\end{bmatrix}$。\n  - $x=\\begin{bmatrix}0.3  -0.1  0.2  0.5\\end{bmatrix}$。\n  - $y=\\begin{bmatrix}1  0  0\\end{bmatrix}$。\n  - 增强：$t_{\\text{id}}$，$t_{\\text{noise}}$ (其中 $\\epsilon=\\begin{bmatrix}0  0  0  0\\end{bmatrix}$)，$t_{\\text{mask}}$ (其中 $m=\\begin{bmatrix}1  1  1  1\\end{bmatrix}$)，$t_{\\text{scale}}$ (其中 $s=1.0$)。\n  - 权重：$w_j=\\frac{1}{4}$ (对于 $j=1,2,3,4$)。\n- 案例 3 (边缘情况；高度多样化的增强；均匀权重):\n  - $C=3$, $d=4$。\n  - $W=\\begin{bmatrix}2.0  -1.5  0.0  0.5\\\\ -1.0  2.0  0.5  -0.5\\\\ 0.0  -0.5  2.0  -1.0\\end{bmatrix}$。\n  - $x=\\begin{bmatrix}1.0  -2.0  0.5  1.5\\end{bmatrix}$。\n  - $y=\\begin{bmatrix}0  0  1\\end{bmatrix}$。\n  - 增强：$t_{\\text{id}}$，$t_{\\text{noise}}$ (其中 $\\epsilon=\\begin{bmatrix}0.8  -0.8  0.8  -0.8\\end{bmatrix}$)，$t_{\\text{mask}}$ (其中 $m=\\begin{bmatrix}0.1  1.5  0.2  2.0\\end{bmatrix}$)，$t_{\\text{scale}}$ (其中 $s=0.3$)。\n  - 权重：$w_j=\\frac{1}{4}$ (对于 $j=1,2,3,4$)。\n- 案例 4 (加权期望；非均匀权重):\n  - $C=3$, $d=3$。\n  - $W=\\begin{bmatrix}1.0  -0.5  0.0\\\\ 0.0  1.0  0.5\\\\ -0.5  0.0  1.5\\end{bmatrix}$。\n  - $x=\\begin{bmatrix}0.5  0.8  -0.3\\end{bmatrix}$。\n  - $y=\\begin{bmatrix}0  1  0\\end{bmatrix}$。\n  - 增强：$t_{\\text{id}}$，$t_{\\text{noise}}$ (其中 $\\epsilon=\\begin{bmatrix}0.2  -0.1  0.05\\end{bmatrix}$)，$t_{\\text{scale}}$ (其中 $s=0.7$)。\n  - 权重：$w=\\begin{bmatrix}0.1  0.4  0.5\\end{bmatrix}$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含四个测试用例的 Jensen 间隙，格式为方括号内的逗号分隔列表，每个间隙值四舍五入到六位小数（例如，“[0.012345,0.000000,0.056789,0.004321]”）。不应打印任何额外文本。", "solution": "问题陈述是有效的。它在科学上基于监督学习和信息论的原理，定义清晰（所有必要参数均已定义），并且在计算上是可行的。其组成部分——线性分类器、softmax 激活函数、交叉熵损失和测试时增强 (TTA)——都是深度学习中的标准概念。待计算的量，即 Jensen 间隙，是 Jensen 不等式在凸交叉熵损失函数上的直接应用，为平均预测的效果提供了一种理论上合理的度量。\n\n目标是计算线性分类器在各种测试时增强下的 Jensen 间隙，记为 $J$。Jensen 间隙量化了增强后预测的期望损失与平均预测的损失之间的差异。\n\n我们首先定义核心组件。该模型是一个线性分类器，由函数 $f_\\theta: \\mathbb{R}^d \\to \\Delta^{C-1}$ 描述，其中 $\\theta$ 代表模型参数。对于一个输入向量 $x \\in \\mathbb{R}^d$，模型首先通过使用权重矩阵 $W \\in \\mathbb{R}^{C \\times d}$ 的线性变换计算 logits $z \\in \\mathbb{R}^C$：\n$$\nz = Wx\n$$\n然后，使用 softmax 函数将这些 logits 转换为 $C$ 个类别上的概率分布 $p \\in \\Delta^{C-1}$：\n$$\np = \\text{softmax}(z)\n$$\n其中输出向量的第 $i$ 个分量由下式给出\n$$\np_i = \\text{softmax}(z)_i = \\frac{\\exp(z_i)}{\\sum_{j=1}^C \\exp(z_j)}\n$$\n对于给定的输入 $x$ 及其对应的真实类别标签（表示为 one-hot 向量 $y \\in \\{0, 1\\}^C$，其中对于真实类别 $k$ 有 $y_k=1$，而对于 $i \\neq k$ 有 $y_i=0$），分类性能由多类别交叉熵损失来衡量：\n$$\n\\ell(p, y) = -\\sum_{i=1}^C y_i \\log(p_i)\n$$\n由于 $y$ 是 one-hot 向量，这可以简化为真实类别 $k$ 的预测概率的负对数：\n$$\n\\ell(p, y) = -\\log(p_k)\n$$\n函数 $\\phi(v) = -\\log(v)$ 对于 $v \\in (0, 1]$ 是一个严格凸函数。这种凸性是 Jensen 间隙的数学基础。\n\n测试时增强 (TTA) 涉及使用一组变换 $\\{t_1, \\dots, t_n\\}$ 来创建测试输入 $x$ 的多个版本。对每个增强后的输入 $t_j(x)$ 进行预测，然后将这些预测聚合起来。聚合后的预测 $\\bar{p}$ 是各个预测的加权平均值：\n$$\n\\bar{p} = \\mathbb{E}_t\\big[f_\\theta(t(x))\\big] = \\sum_{j=1}^n w_j f_\\theta\\big(t_j(x)\\big) = \\sum_{j=1}^n w_j p^{(j)}\n$$\n其中 $p^{(j)} = f_\\theta(t_j(x))$ 且 $\\{w_1, \\dots, w_n\\}$ 是总和为 $1$ 的非负权重。\n\n在此增强方案下的期望损失是每个单独预测损失的加权平均值：\n$$\n\\mathbb{E}_t\\big[\\ell(f_\\theta(t(x)),y)\\big] = \\sum_{j=1}^n w_j \\ell\\big(p^{(j)}, y\\big)\n$$\nJensen 间隙 $J$ 由凸损失函数 $\\ell$ 的 Jensen 不等式定义。它是函数值的期望与期望处的函数值之差：\n$$\nJ = \\mathbb{E}_t\\big[\\ell(f_\\theta(t(x)), y)\\big] - \\ell\\big(\\mathbb{E}_t[f_\\theta(t(x))], y\\big)\n$$\n将 TTA 上下文的表达式代入，我们得到：\n$$\nJ = \\left(\\sum_{j=1}^n w_j \\ell\\big(p^{(j)}, y\\big)\\right) - \\ell(\\bar{p}, y)\n$$\n由于负对数函数的凸性，这个间隙 $J$ 保证是非负的，$J \\ge 0$。如果预测值 $p^{(j)}$ 不全相同，则它为严格正值。该间隙表示在计算损失之前对概率向量（预测的“集成”）进行平均，与对损失本身进行平均相比，所实现的损失减少量。\n\n每个测试用例的计算都遵循以下顺序：\n1.  **增强与预测**：对于集合中的每个增强 $t_j$，我们首先计算增强后的输入 $x^{(j)} = t_j(x)$。然后，我们计算相应的 logits $z^{(j)} = W x^{(j)}$ 和概率向量 $p^{(j)} = \\text{softmax}(z^{(j)})$。为确保数值稳定性，softmax 函数使用 log-sum-exp 技巧实现，即在进行指数运算之前，从所有 logits 中减去 logit 向量的最大值，以防止溢出。\n\n2.  **平均预测**：TTA 预测 $\\bar{p}$ 计算为各个概率向量的加权和：$\\bar{p} = \\sum_{j=1}^n w_j p^{(j)}$。\n\n3.  **期望损失计算**：对于每个 $p^{(j)}$，计算交叉熵损失 $\\ell_j = \\ell(p^{(j)}, y) = -\\log(p^{(j)}_k)$，其中 $k$ 是真实类别的索引。期望损失则是这些单独损失的加权和：$\\mathbb{E}_t[\\ell] = \\sum_{j=1}^n w_j \\ell_j$。在计算对数时，会向概率值添加一个小的 epsilon（对应于机器精度），以防止出现未定义的 $\\log(0)$。\n\n4.  **Jensen 间隙计算**：计算平均预测的损失 $\\bar{\\ell} = \\ell(\\bar{p}, y) = -\\log(\\bar{p}_k)$。最终的 Jensen 间隙是差值 $J = \\mathbb{E}_t[\\ell] - \\bar{\\ell}$。\n\n此过程将应用于所提供的四个测试用例中的每一个。\n- **案例 1** 代表具有多样化增强的一般场景。\n- **案例 2**作为一个合理性检查：所有增强都是恒等变换，这应该导致相同的预测 $p^{(j)}$、一个恒定的 TTA 预测 $\\bar{p} = p^{(1)}$，因此 Jensen 间隙为 $J=0$。\n- **案例 3** 使用更极端的增强，预计会产生高度多样化的预测，从而产生更大的 Jensen 间隙。\n- **案例 4** 演示了在 TTA 期望中使用非均匀权重的情况。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Jensen gap for Test-Time Augmentation (TTA) in a linear\n    classification setting for a series of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: General case; uniform weights\n        {\n            \"W\": np.array([[1.2, -0.9, 0.3, 0.0],\n                           [-0.5, 1.1, 0.7, 0.8],\n                           [0.0, 0.4, 1.0, -0.7]]),\n            \"x\": np.array([0.6, -0.2, 1.0, 0.5]),\n            \"y\": np.array([0, 1, 0]),\n            \"augmentations\": [\n                {\"type\": \"id\"},\n                {\"type\": \"noise\", \"params\": {\"epsilon\": np.array([0.05, -0.03, 0.02, -0.01])}},\n                {\"type\": \"mask\", \"params\": {\"m\": np.array([1.0, 0.7, 0.9, 1.0])}},\n                {\"type\": \"scale\", \"params\": {\"s\": 1.1}},\n            ],\n            \"weights\": np.array([0.25, 0.25, 0.25, 0.25]),\n        },\n        # Case 2: Boundary case; identical predictions\n        {\n            \"W\": np.array([[1.2, -0.9, 0.3, 0.0],\n                           [-0.5, 1.1, 0.7, 0.8],\n                           [0.0, 0.4, 1.0, -0.7]]),\n            \"x\": np.array([0.3, -0.1, 0.2, 0.5]),\n            \"y\": np.array([1, 0, 0]),\n            \"augmentations\": [\n                {\"type\": \"id\"},\n                {\"type\": \"noise\", \"params\": {\"epsilon\": np.array([0.0, 0.0, 0.0, 0.0])}},\n                {\"type\": \"mask\", \"params\": {\"m\": np.array([1.0, 1.0, 1.0, 1.0])}},\n                {\"type\": \"scale\", \"params\": {\"s\": 1.0}},\n            ],\n            \"weights\": np.array([0.25, 0.25, 0.25, 0.25]),\n        },\n        # Case 3: Edge case; highly diverse augmentations\n        {\n            \"W\": np.array([[2.0, -1.5, 0.0, 0.5],\n                           [-1.0, 2.0, 0.5, -0.5],\n                           [0.0, -0.5, 2.0, -1.0]]),\n            \"x\": np.array([1.0, -2.0, 0.5, 1.5]),\n            \"y\": np.array([0, 0, 1]),\n            \"augmentations\": [\n                {\"type\": \"id\"},\n                {\"type\": \"noise\", \"params\": {\"epsilon\": np.array([0.8, -0.8, 0.8, -0.8])}},\n                {\"type\": \"mask\", \"params\": {\"m\": np.array([0.1, 1.5, 0.2, 2.0])}},\n                {\"type\": \"scale\", \"params\": {\"s\": 0.3}},\n            ],\n            \"weights\": np.array([0.25, 0.25, 0.25, 0.25]),\n        },\n        # Case 4: Weighted expectation; nonuniform weights\n        {\n            \"W\": np.array([[1.0, -0.5, 0.0],\n                           [0.0, 1.0, 0.5],\n                           [-0.5, 0.0, 1.5]]),\n            \"x\": np.array([0.5, 0.8, -0.3]),\n            \"y\": np.array([0, 1, 0]),\n            \"augmentations\": [\n                {\"type\": \"id\"},\n                {\"type\": \"noise\", \"params\": {\"epsilon\": np.array([0.2, -0.1, 0.05])}},\n                {\"type\": \"scale\", \"params\": {\"s\": 0.7}},\n            ],\n            \"weights\": np.array([0.1, 0.4, 0.5]),\n        },\n    ]\n\n    def softmax(z):\n        # Numerically stable softmax using the log-sum-exp trick\n        z_stable = z - np.max(z)\n        exps = np.exp(z_stable)\n        return exps / np.sum(exps)\n\n    def cross_entropy_loss(p, y):\n        # Since y is one-hot, find the index of the true class\n        true_class_idx = np.argmax(y)\n        # Add a small epsilon for numerical stability to avoid log(0)\n        epsilon = np.finfo(float).eps\n        return -np.log(p[true_class_idx] + epsilon)\n\n    results = []\n    for case in test_cases:\n        W, x, y = case[\"W\"], case[\"x\"], case[\"y\"]\n        augmentations, weights = case[\"augmentations\"], case[\"weights\"]\n        \n        predictions = []\n        for aug_info in augmentations:\n            aug_type = aug_info[\"type\"]\n            if aug_type == \"id\":\n                x_aug = x\n            elif aug_type == \"noise\":\n                x_aug = x + aug_info[\"params\"][\"epsilon\"]\n            elif aug_type == \"mask\":\n                x_aug = x * aug_info[\"params\"][\"m\"]\n            elif aug_type == \"scale\":\n                x_aug = x * aug_info[\"params\"][\"s\"]\n            \n            # 1. Compute prediction for the augmented input\n            logits = W @ x_aug\n            p = softmax(logits)\n            predictions.append(p)\n        \n        predictions = np.array(predictions)\n        \n        # 2. Compute the average prediction (bar_p)\n        # p_bar = np.average(predictions, axis=0, weights=weights) would also work\n        p_bar = np.einsum('i,ij-j', weights, predictions)\n\n        # 3. Compute the expected loss\n        individual_losses = np.array([cross_entropy_loss(p, y) for p in predictions])\n        expected_loss = np.sum(weights * individual_losses)\n        \n        # 4. Compute the loss of the average prediction and the Jensen gap\n        loss_of_avg = cross_entropy_loss(p_bar, y)\n        jensen_gap = expected_loss - loss_of_avg\n        \n        results.append(jensen_gap)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "3178424"}]}