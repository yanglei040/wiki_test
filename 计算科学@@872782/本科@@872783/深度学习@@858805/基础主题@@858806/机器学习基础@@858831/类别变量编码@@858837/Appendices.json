{"hands_on_practices": [{"introduction": "哑变量（或独热编码）是处理名义分类变量的默认方法。一个常见的困惑是，“参照”类别的选择如何影响模型的系数及其解释。本练习将引导你通过计算来证明一个关键原则：虽然单个系数会改变，但变量的整体显著性保持不变，这一特性由 F 检验来体现。[@problem_id:3130441]", "problem": "一个包含 $n=60$ 个观测值的数据集使用普通最小二乘法 (OLS) 进行分析。响应变量 $Y$ 被建模为一个中心化连续协变量 $X$（含截距）和一个具有三个水平 $A$、$B$ 和 $C$ 的分类因子 $G$ 的线性函数。在一个包含截距、$X$ 和指示变量的全模型中，因子 $G$ 由两个指示变量表示。一个简化模型仅包含截距和 $X$。\n\n使用了两种等价的 $G$ 的编码方案：\n\n- 方案 S1（参考水平为 $A$）：分别为水平 $B$ 和 $C$ 设置指示变量 $I_{B}$ 和 $I_{C}$。\n- 方案 S2（参考水平为 $C$）：分别为水平 $A$ 和 $B$ 设置指示变量 $J_{A}$ 和 $J_{B}$。\n\n从模型拟合中，您获得了以下信息：\n\n- 简化模型（仅含截距和 $X$）得到的残差平方和为 $RSS_{R}=820$，估计了 $p_{R}=2$ 个参数。\n- 全模型（含截距、$X$ 和 $G$ 的两个指示变量）得到的残差平方和为 $RSS_{F}=760$，估计了 $p_{F}=4$ 个参数。\n- 在方案 S1 下，两个组指示变量的 OLS 估计值及其标准误为：$\\hat{\\beta}_{B}=-3.0$，标准误为 $1.8$；$\\hat{\\beta}_{C}=-1.5$，标准误为 $1.9$。\n- 在方案 S2 下，两个组指示变量的 OLS 估计值及其标准误为：$\\hat{\\gamma}_{A}=+1.5$，标准误为 $1.6$；$\\hat{\\gamma}_{B}=-1.5$，标准误为 $1.7$。\n\n任务：\n\n1) 仅使用一般线性模型的定义，判断改变 $G$ 的参考水平是否会改变全模型的拟合值或残差平方和，并解释这对将 $G$ 作为一个整体进行联合检验意味着什么。\n\n2) 计算在 S1 和 S2 方案下组指示变量的各自的 $t$-统计量，并说明它们是否随编码方式的改变而改变。\n\n3) 在给定截距和 $X$ 的情况下，计算检验原假设“$G$ 没有效应”（即检验两个指示变量的系数联合为零）的 $F$-统计量的共同值。将您的最终数值答案四舍五入到四位有效数字。", "solution": "该问题被验证为自洽的，科学上基于线性模型理论，并且是适定问题。所有提供的数据都是一致的，足以完成这些任务。\n\n### 任务1：拟合值、RSS 的不变性及其对联合检验的启示\n\n一般线性模型用矩阵形式表示为 $\\mathbf{Y} = \\mathbf{X}\\boldsymbol{\\beta} + \\boldsymbol{\\epsilon}$，其中 $\\mathbf{Y}$ 是响应向量，$\\mathbf{X}$ 是设计矩阵，$\\boldsymbol{\\beta}$ 是参数向量，$\\boldsymbol{\\epsilon}$ 是误差向量。$\\boldsymbol{\\beta}$ 的普通最小二乘 (OLS) 估计量是 $\\hat{\\boldsymbol{\\beta}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y}$。拟合值向量由 $\\mathbf{Y}$ 在 $\\mathbf{X}$ 的列空间（记为 $C(\\mathbf{X})$）上的正交投影给出。这个投影是 $\\hat{\\mathbf{Y}} = \\mathbf{X}\\hat{\\boldsymbol{\\beta}} = \\mathbf{X}(\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Y} = \\mathbf{H}\\mathbf{Y}$，其中 $\\mathbf{H}$ 是投影矩阵，通常称为“帽子矩阵”。\n\n分类因子 $G$ 的两种编码方案 S1 和 S2 代表了全模型的一种再参数化。设方案 S1 的设计矩阵为 $\\mathbf{X}_1$，方案 S2 的设计矩阵为 $\\mathbf{X}_2$。\n对于 S1（参考水平 A），设计矩阵的列是 $[\\mathbf{1}, \\mathbf{X}_{\\text{cov}}, \\mathbf{I}_B, \\mathbf{I}_C]$，其中 $\\mathbf{1}$ 是代表截距的全一向量，$\\mathbf{X}_{\\text{cov}}$ 是连续协变量 $X$ 的向量，$\\mathbf{I}_B, \\mathbf{I}_C$ 是水平 $B$ 和 $C$ 的指示向量。\n对于 S2（参考水平 C），设计矩阵的列是 $[\\mathbf{1}, \\mathbf{X}_{\\text{cov}}, \\mathbf{J}_A, \\mathbf{J}_B]$。\n\n这些指示向量通过恒等式 $\\mathbf{I}_A + \\mathbf{I}_B + \\mathbf{I}_C = \\mathbf{1}$ 相关联。两种方案中使用的向量也直接相关：$\\mathbf{J}_A = \\mathbf{I}_A$ 且 $\\mathbf{J}_B = \\mathbf{I}_B$。\n在 S1 中，与因子 $G$ 相关的子空间的基向量是 $\\{\\mathbf{I}_B, \\mathbf{I}_C\\}$（在有截距的情况下），而在 S2 中它们是 $\\{\\mathbf{J}_A, \\mathbf{J}_B\\}$。我们来证明这两组向量与截距和协变量结合后，张成的是同一个空间。\n列空间 $C(\\mathbf{X}_1)$ 的基向量是 $\\{\\mathbf{1}, \\mathbf{X}_{\\text{cov}}, \\mathbf{I}_B, \\mathbf{I}_C\\}$。\n列空间 $C(\\mathbf{X}_2)$ 的基向量是 $\\{\\mathbf{1}, \\mathbf{X}_{\\text{cov}}, \\mathbf{J}_A, \\mathbf{J}_B\\}$。\n我们可以用 S1 的基向量来表示 S2 的基向量：\n$\\mathbf{J}_A = \\mathbf{I}_A = \\mathbf{1} - \\mathbf{I}_B - \\mathbf{I}_C$。\n$\\mathbf{J}_B = \\mathbf{I}_B$。\n因为 $C(\\mathbf{X}_2)$ 的每个基向量都是 $C(\\mathbf{X}_1)$ 基向量的线性组合，所以 $C(\\mathbf{X}_2) \\subseteq C(\\mathbf{X}_1)$。同样，我们可以用 S2 的基来表示 S1 的基向量：\n$\\mathbf{I}_C = \\mathbf{1} - \\mathbf{I}_A - \\mathbf{I}_B = \\mathbf{1} - \\mathbf{J}_A - \\mathbf{J}_B$。\n$\\mathbf{I}_B = \\mathbf{J}_B$。\n这表明 $C(\\mathbf{X}_1) \\subseteq C(\\mathbf{X}_2)$。\n因此，这两个列空间是相同的：$C(\\mathbf{X}_1) = C(\\mathbf{X}_2)$。\n\n由于列空间相同，两种方案的投影矩阵 $\\mathbf{H}$ 是相同的。因此，拟合值 $\\hat{\\mathbf{Y}} = \\mathbf{H}\\mathbf{Y}$ 对于参考水平的选择是不变的。因此，残差向量 $\\mathbf{e} = \\mathbf{Y} - \\hat{\\mathbf{Y}}$ 也是不变的。所以，残差平方和 $RSS_F = \\mathbf{e}^T\\mathbf{e}$ 不会因为再参数化而改变。问题陈述通过提供一个单一的值 $RSS_{F}=760$ 来证实这一点。\n\n这种不变性对于 $G$ 的联合检验至关重要。检验代表 $G$ 的变量块显著性的 $F$-检验，比较的是全模型（含 $G$）与简化模型（不含 $G$）。$F$-统计量是 $RSS_R$、$RSS_F$、$n$、$p_R$ 和 $p_F$ 的函数。由于这些量都不依赖于为全模型选择的具体编码方案，因此对于联合原假设 $H_0: \\beta_B = \\beta_C = 0$（在 S1 下）或 $H_0: \\gamma_A = \\gamma_B = 0$（在 S2 下）得到的 $F$-统计量将是相同的。联合检验为因子 $G$ 对模型的整体贡献提供了一个明确的评估。\n\n### 任务2：单个 t-统计量\n\n系数估计值 $\\hat{\\beta}$ 的 $t$-统计量计算公式为 $t = \\frac{\\hat{\\beta}}{SE(\\hat{\\beta})}$。\n\n对于方案 S1（参考水平 A）：\n指示变量 $I_B$ 的 $t$-统计量为：\n$$ t_{B, S1} = \\frac{\\hat{\\beta}_{B}}{SE(\\hat{\\beta}_{B})} = \\frac{-3.0}{1.8} = -1.666... $$\n指示变量 $I_C$ 的 $t$-统计量为：\n$$ t_{C, S1} = \\frac{\\hat{\\beta}_{C}}{SE(\\hat{\\beta}_{C})} = \\frac{-1.5}{1.9} \\approx -0.78947... $$\n\n对于方案 S2（参考水平 C）：\n指示变量 $J_A$ 的 $t$-统计量为：\n$$ t_{A, S2} = \\frac{\\hat{\\gamma}_{A}}{SE(\\hat{\\gamma}_{A})} = \\frac{+1.5}{1.6} = 0.9375 $$\n指示变量 $J_B$ 的 $t$-统计量为：\n$$ t_{B, S2} = \\frac{\\hat{\\gamma}_{B}}{SE(\\hat{\\gamma}_{B})} = \\frac{-1.5}{1.7} \\approx -0.88235... $$\n\n单个 $t$-统计量在不同编码方案下显然是改变的。这是因为它们检验的是不同的假设。例如，$t_{B, S1}$ 检验的是 B 组的平均响应是否与参考组 A 不同，而 $t_{B, S2}$ 检验的是 B 组是否与参考组 C 不同。\n\n### 任务3：共同的 F-统计量\n\n用于检验一个系数块为零的原假设的 $F$-统计量是通过比较全模型（$RSS_F$）和简化模型（$RSS_R$）的残差平方和来计算的。公式为：\n$$ F = \\frac{(RSS_R - RSS_F) / (p_F - p_R)}{RSS_F / (n - p_F)} $$\n其中，$p_F$ 和 $p_R$ 分别是全模型和简化模型中的参数数量，$n$ 是观测值的数量。\n\n已知条件是：\n- 简化模型 RSS: $RSS_{R} = 820$\n- 全模型 RSS: $RSS_{F} = 760$\n- 简化模型中的参数数量: $p_{R} = 2$（截距和 $X$）\n- 全模型中的参数数量: $p_{F} = 4$（截距、$X$ 和 $G$ 的两个指示变量）\n- 观测值数量: $n = 60$\n\n被检验的参数数量（即 $G$ 的指示变量数量）是 $p_F - p_R = 4 - 2 = 2$。\n分子的自由度是 $df_1 = p_F - p_R = 2$。\n分母的自由度是 $df_2 = n - p_F = 60 - 4 = 56$。\n\n将这些值代入公式：\n$$ F = \\frac{(820 - 760) / (4 - 2)}{760 / (60 - 4)} $$\n$$ F = \\frac{60 / 2}{760 / 56} $$\n$$ F = \\frac{30}{760 / 56} $$\n$$ F = \\frac{30 \\times 56}{760} = \\frac{1680}{760} = \\frac{168}{76} = \\frac{42}{19} $$\n$$ F \\approx 2.2105263... $$\n\n四舍五入到四位有效数字，该值为 $2.211$。\n该 $F$-统计量检验了因子 $G$ 没有效应的原假设，即其两个指示变量的系数联合为零。如任务1中所解释的，该值对于参考水平的选择是不变的。", "answer": "$$\\boxed{2.211}$$", "id": "3130441"}, {"introduction": "并非所有分类变量都是名义的；有些具有自然顺序（例如，“低”、“中”、“高”）。一种简单的方法是将它们映射为整数（如 0, 1, 2, 3），但这强加了等间距的假设。本练习探讨了当此假设不正确时其带来的后果，并引入了对比编码作为一种将领域知识中关于类别真实间距的信息嵌入模型的方法。[@problem_id:3164649]", "problem": "一项实验室研究评估了一个有序分类预测变量对一个连续响应变量的影响。现有 $4$ 个有序处理类别 $C \\in \\{C_1,C_2,C_3,C_4\\}$，在一个均衡设计中实施，每个类别有 $n$ 个观测值。尽管这些类别是定性标记的，但领域知识为每个类别提供了一个潜在的定量间距 $s(C)$，该间距在一个有意义的尺度上测量：$s(C_1)=0$, $s(C_2)=1$, $s(C_3)=4$, $s(C_4)=5$。响应的真实条件期望与此间距呈线性关系：\n$$\n\\mathbb{E}[Y \\mid C] = \\alpha + \\beta\\, s(C),\n$$\n其中 $\\alpha$ 和 $\\beta$ 是未知常数，并且在每个类别内，观测噪声的均值为 $0$ 且方差恒定。\n\n一位分析师考虑使用两种对该分类预测变量的编码方式来拟合一个带截距的简单线性回归模型。在第一种编码中，他们根据顺序 $C_1,C_2,C_3,C_4$ 将各类别映射到等间距的数值编码 $z(C) \\in \\{0,1,2,3\\}$，并对 $z(C)$ 进行带有截距的 $Y$ 的回归。在第二种编码中，他们构建了一个单一的对比预测变量 $x(C)$，旨在反映特定领域的间距，并对 $x(C)$ 进行带有截距的 $Y$ 的回归。\n\n下列哪些陈述是正确的？选择所有适用的选项。\n\nA. 当间距 $s(C)$ 不相等时，对等间距编码 $z(C)$ 进行 $Y$ 的回归所产生的斜率与 $\\beta$ 不同。在此设置中，$s(C) \\in \\{0,1,4,5\\}$ 且类别是均衡的，对 $z(C)$ 进行 $Y$ 的回归所得的期望斜率等于 $1.8\\,\\beta$，并且对于 $(C_1,C_2,C_3,C_4)$，拟合的类别均值与真实均值的差异分别为 $(-0.2\\,\\beta,\\,0.6\\,\\beta,\\,-0.6\\,\\beta,\\,0.2\\,\\beta)$。\n\nB. 将有序类别映射到等间距数值编码 $z(C) \\in \\{0,1,2,3\\}$，无论真实间距 $s(C)$如何，都能得到 $\\beta$ 的一个无偏估计。\n\nC. 使用带截距的独热指示（虚拟）变量，但不施加额外结构，只要类别是有序的，就会自动产生一个等于 $\\beta$ 的单一标量“趋势”系数。\n\nD. 一种对特定领域间距进行编码的合理方法是设置 $x(C)=s(C)-\\bar{s}$，其中 $\\bar{s}$ 是 $s(C)$ 在所有类别上的平均值，然后对 $x(C)$ 进行带有截距的 $Y$ 的回归。在所述的真实模型下，这种方法会产生 $\\beta$ 的一个无偏估计，并且截距项估计的是总均值 $\\mathbb{E}[Y]$。", "solution": "问题陈述已经过验证并且是合理的。它提出了一个关于有序分类预测变量编码的清晰、设定合理的统计建模场景。所有提供的信息在内部是一致的，并有科学依据。\n\n让我们定义一些关键量。\n有序类别的数量为 $k=4$，标记为 $C_1, C_2, C_3, C_4$。\n设计是均衡的，每个类别有 $n$ 个观测值，因此总观测数为 $N=4n$。\n各类别的真实定量间距由函数 $s(C)$ 给出，其值为 $s_1 = s(C_1) = 0$, $s_2 = s(C_2) = 1$, $s_3 = s(C_3) = 4$ 和 $s_4 = s(C_4) = 5$。\n响应 $Y$ 的条件期望的真实模型由下式给出：\n$$\n\\mathbb{E}[Y \\mid C_i] = \\mu_i = \\alpha + \\beta s_i\n$$\n四个类别的真实平均响应为：\n$\\mu_1 = \\alpha + \\beta s_1 = \\alpha + \\beta(0) = \\alpha$\n$\\mu_2 = \\alpha + \\beta s_2 = \\alpha + \\beta(1) = \\alpha + \\beta$\n$\\mu_3 = \\alpha + \\beta s_3 = \\alpha + \\beta(4) = \\alpha + 4\\beta$\n$\\mu_4 = \\alpha + \\beta s_4 = \\alpha + \\beta(5) = \\alpha + 5\\beta$\n\n分析师考虑了两个模型。第一个模型使用值为 $z_1=0, z_2=1, z_3=2, z_4=3$ 的等间距编码 $z(C)$。第二个模型使用基于真实间距 $s(C)$ 的预测变量 $x(C)$。\n\n### 对第一种编码的分析（$Y$ 对 $z(C)$ 的回归）\n\n第一个模型是 $Y$ 对 $z(C)$ 的简单线性回归：$Y = a_z + b_z z + \\text{error}$。斜率的普通最小二乘（OLS）估计量是 $\\hat{b}_z$。我们关心它的期望值 $\\mathbb{E}[\\hat{b}_z]$。\n对于这样一个均衡设计，斜率估计量的期望值是对真实均值 $(\\mu_i)$ 与预测变量值 $(z_i)$ 拟合的直线的斜率。\n$$\n\\mathbb{E}[\\hat{b}_z] = \\frac{\\sum_{i=1}^4 (z_i - \\bar{z})(\\mu_i - \\bar{\\mu})}{\\sum_{i=1}^4 (z_i - \\bar{z})^2} = \\frac{\\sum_{i=1}^4 (z_i - \\bar{z})\\mu_i}{\\sum_{i=1}^4 (z_i - \\bar{z})^2}\n$$\n$z_i$ 的值为 $\\{0, 1, 2, 3\\}$。均值为 $\\bar{z} = \\frac{0+1+2+3}{4} = 1.5$。\n分母是 $z$ 的离差平方和：\n$S_{zz} = \\sum_{i=1}^4 (z_i - \\bar{z})^2 = (0-1.5)^2 + (1-1.5)^2 + (2-1.5)^2 + (3-1.5)^2 = 2.25 + 0.25 + 0.25 + 2.25 = 5$。\n分子是交叉乘积之和 $\\sum (z_i - \\bar{z})\\mu_i$：\n$S_{z\\mu} = (0-1.5)\\mu_1 + (1-1.5)\\mu_2 + (2-1.5)\\mu_3 + (3-1.5)\\mu_4$\n$S_{z\\mu} = -1.5\\mu_1 - 0.5\\mu_2 + 0.5\\mu_3 + 1.5\\mu_4$\n代入真实均值 $\\mu_i$：\n$S_{z\\mu} = -1.5\\alpha - 0.5(\\alpha+\\beta) + 0.5(\\alpha+4\\beta) + 1.5(\\alpha+5\\beta)$\n$S_{z\\mu} = \\alpha(-1.5 - 0.5 + 0.5 + 1.5) + \\beta(-0.5(1) + 0.5(4) + 1.5(5))$\n$S_{z\\mu} = \\alpha(0) + \\beta(-0.5 + 2 + 7.5) = 9\\beta$。\n因此，期望斜率为 $\\mathbb{E}[\\hat{b}_z] = \\frac{9\\beta}{5} = 1.8\\beta$。\n\n接下来，我们计算每个类别的期望拟合均值 $\\mathbb{E}[\\hat{\\mu}_i] = \\mathbb{E}[\\hat{a}_z + \\hat{b}_z z_i]$。\n首先，我们需要期望截距 $\\mathbb{E}[\\hat{a}_z] = \\mathbb{E}[\\bar{Y} - \\hat{b}_z \\bar{z}] = \\mathbb{E}[\\bar{Y}] - \\mathbb{E}[\\hat{b}_z]\\bar{z}$。\n样本均值的期望是真实类别均值的平均值：\n$\\mathbb{E}[\\bar{Y}] = \\bar{\\mu} = \\frac{1}{4}(\\mu_1+\\mu_2+\\mu_3+\\mu_4) = \\frac{1}{4}(\\alpha + (\\alpha+\\beta) + (\\alpha+4\\beta) + (\\alpha+5\\beta)) = \\frac{1}{4}(4\\alpha + 10\\beta) = \\alpha + 2.5\\beta$。\n$\\mathbb{E}[\\hat{a}_z] = (\\alpha + 2.5\\beta) - (1.8\\beta)(1.5) = \\alpha + 2.5\\beta - 2.7\\beta = \\alpha - 0.2\\beta$。\n现在我们计算每个类别的期望拟合均值及其与真实均值的差异：\n$\\mathbb{E}[\\hat{\\mu}_1] = \\mathbb{E}[\\hat{a}_z] + \\mathbb{E}[\\hat{b}_z] z_1 = (\\alpha - 0.2\\beta) + (1.8\\beta)(0) = \\alpha - 0.2\\beta$。\n差异： $(\\alpha - 0.2\\beta) - \\mu_1 = (\\alpha - 0.2\\beta) - \\alpha = -0.2\\beta$。\n$\\mathbb{E}[\\hat{\\mu}_2] = \\mathbb{E}[\\hat{a}_z] + \\mathbb{E}[\\hat{b}_z] z_2 = (\\alpha - 0.2\\beta) + (1.8\\beta)(1) = \\alpha + 1.6\\beta$。\n差异： $(\\alpha + 1.6\\beta) - \\mu_2 = (\\alpha + 1.6\\beta) - (\\alpha+\\beta) = 0.6\\beta$。\n$\\mathbb{E}[\\hat{\\mu}_3] = \\mathbb{E}[\\hat{a}_z] + \\mathbb{E}[\\hat{b}_z] z_3 = (\\alpha - 0.2\\beta) + (1.8\\beta)(2) = \\alpha + 3.4\\beta$。\n差异： $(\\alpha + 3.4\\beta) - \\mu_3 = (\\alpha + 3.4\\beta) - (\\alpha+4\\beta) = -0.6\\beta$。\n$\\mathbb{E}[\\hat{\\mu}_4] = \\mathbb{E}[\\hat{a}_z] + \\mathbb{E}[\\hat{b}_z] z_4 = (\\alpha - 0.2\\beta) + (1.8\\beta)(3) = \\alpha + 5.2\\beta$。\n差异： $(\\alpha + 5.2\\beta) - \\mu_4 = (\\alpha + 5.2\\beta) - (\\alpha+5\\beta) = 0.2\\beta$。\n\n### 对选项的评估\n\n**A. 当间距 $s(C)$ 不相等时，对等间距编码 $z(C)$ 进行 $Y$ 的回归所产生的斜率与 $\\beta$ 不同。在此设置中，$s(C) \\in \\{0,1,4,5\\}$ 且类别是均衡的，对 $z(C)$ 进行 $Y$ 的回归所得的期望斜率等于 $1.8\\,\\beta$，并且对于 $(C_1,C_2,C_3,C_4)$，拟合的类别均值与真实均值的差异分别为 $(-0.2\\,\\beta,\\,0.6\\,\\beta,\\,-0.6\\,\\beta,\\,0.2\\,\\beta)$。**\n我们的推导表明期望斜率确实是 $1.8\\beta$。期望的拟合类别均值与真实均值之间的差异精确地为 $(-0.2\\beta, 0.6\\beta, -0.6\\beta, 0.2\\beta)$。这些计算证实了该陈述的每一部分。\n结论：**正确**。\n\n**B. 将有序类别映射到等间距数值编码 $z(C) \\in \\{0,1,2,3\\}$，无论真实间距 $s(C)$如何，都能得到 $\\beta$ 的一个无偏估计。**\n如果一个估计量的期望值等于真实参数，那么它就是无偏的。这里，我们用对 $z(C)$ 回归得到的斜率系数（我们称之为 $\\hat{b}_z$）来估计 $\\beta$。从我们对选项A的分析中，我们发现 $\\mathbb{E}[\\hat{b}_z] = 1.8\\beta$。由于 $1.8\\beta \\neq \\beta$（对于任何非零的 $\\beta$），该估计量是有偏的。这个特例是该一般性论断的一个反例。只有当真实间距 $s(C)$ 恰好是编码 $z(C)$ 的一个斜率为1的完美线性函数时，该估计量才是无偏的，而在这里情况并非如此，并且肯定不是“无论真实的间距如何”都成立。\n结论：**错误**。\n\n**C. 使用带截距的独热指示（虚拟）变量，但不施加额外结构，只要类别是有序的，就会自动产生一个等于 $\\beta$ 的单一标量“趋势”系数。**\n对于一个带截距的 k 水平分类预测变量，独热（或虚拟）编码涉及创建 $k-1$ 个二元预测变量。对于本问题，$k=4$，若以 $C_1$ 为参考类别，模型将是：\n$Y = \\gamma_0 + \\gamma_2 D_2 + \\gamma_3 D_3 + \\gamma_4 D_4 + \\text{error}$\n其中如果类别是 $C_i$ 则 $D_i=1$，否则为 $0$。\n此模型中的参数对应于类别均值：\n$\\mathbb{E}[\\hat{\\gamma}_0] = \\mu_1 = \\alpha$\n$\\mathbb{E}[\\hat{\\gamma}_2] = \\mu_2 - \\mu_1 = (\\alpha+\\beta) - \\alpha = \\beta$\n$\\mathbb{E}[\\hat{\\gamma}_3] = \\mu_3 - \\mu_1 = (\\alpha+4\\beta) - \\alpha = 4\\beta$\n$\\mathbb{E}[\\hat{\\gamma}_4] = \\mu_4 - \\mu_1 = (\\alpha+5\\beta) - \\alpha = 5\\beta$\n这个模型产生了三个系数（$\\gamma_2, \\gamma_3, \\gamma_4$），而不是一个“单一标量‘趋势’系数”。这些系数代表了相对于基线的差异，而不是一个贯穿所有类别的单一趋势。虽然在这个特殊情况下（其中 $s_2-s_1 = 1$），其中一个系数的期望恰好是 $\\beta$，但其他的不是，并且模型本身并不估计一个单一的趋势参数。这种建模方法等同于方差分析（ANOVA），并将类别视为名义变量，忽略了任何顺序性。\n结论：**错误**。\n\n**D. 一种对特定领域间距进行编码的合理方法是设置 $x(C)=s(C)-\\bar{s}$，其中 $\\bar{s}$ 是 $s(C)$ 在所有类别上的平均值，然后对 $x(C)$ 进行带有截距的 $Y$ 的回归。在所述的真实模型下，这种方法会产生 $\\beta$ 的一个无偏估计，并且截距项估计的是总均值 $\\mathbb{E}[Y]$。**\n让我们分析这个提议。新的预测变量是 $x(C) = s(C) - \\bar{s}$。根据给定的间距 $\\{0, 1, 4, 5\\}$，平均值为 $\\bar{s} = \\frac{0+1+4+5}{4} = 2.5$。\n真实模型是 $\\mathbb{E}[Y \\mid C] = \\alpha + \\beta s(C)$。我们可以用 $x(C)$ 来重新表达这个模型。由于 $s(C) = x(C) + \\bar{s}$，我们有：\n$\\mathbb{E}[Y \\mid C] = \\alpha + \\beta (x(C) + \\bar{s}) = (\\alpha + \\beta\\bar{s}) + \\beta x(C)$。\n这表明 $Y$ 的真实条件期望在所提出的预测变量 $x(C)$ 上是完全线性的。模型是 $Y = a_x + b_x x(C) + \\text{error}$。因为模型被正确设定，斜率和截距的 OLS 估计量是无偏的。\n真实斜率是 $\\beta$，所以 OLS 估计量 $\\hat{b}_x$ 的期望值为 $\\mathbb{E}[\\hat{b}_x] = \\beta$。陈述的第一部分是正确的。\n真实截距是 $\\alpha + \\beta\\bar{s}$。OLS 估计量 $\\hat{a}_x$ 的期望值为 $\\mathbb{E}[\\hat{a}_x] = \\alpha + \\beta\\bar{s}$。\n陈述声称截距估计的是“总均值 $\\mathbb{E}[Y]$”。对于均衡设计，总均值是各个类别均值的平均值：\n$\\mathbb{E}[Y] = \\frac{1}{4} \\sum_{i=1}^4 \\mu_i = \\frac{1}{4} \\sum_{i=1}^4 (\\alpha + \\beta s_i) = \\alpha + \\beta (\\frac{1}{4}\\sum_{i=1}^4 s_i) = \\alpha + \\beta\\bar{s}$。\n这与截距估计量的期望值 $\\mathbb{E}[\\hat{a}_x]$ 相匹配。这是简单线性回归的一个普遍性质：当预测变量是中心化的（即其样本均值为0）时，截距是响应变量均值的无偏估计量。对于均衡设计，预测变量 $x(C)=s(C)-\\bar{s}$ 根据其构造就是中心化的。因此，陈述的第二部分也是正确的。\n结论：**正确**。", "answer": "$$\\boxed{AD}$$", "id": "3164649"}, {"introduction": "某些分类变量，如一年中的月份或一天中的小时，是周期性的。将它们视为名义变量（独热编码）或简单的有序变量，都无法捕捉到最后一个类别与第一个类别相邻这一事实。本编码练习介绍傅里叶特征，这是一种将周期性归纳偏置嵌入模型的强大技术，并要求你测试该方法在哪些场景下表现优异，又在哪些场景下可能失效。[@problem_id:3121725]", "problem": "给定一个表示季节的循环分类变量，周期为 $12$，由索引 $c \\in \\{0,1,2,\\dots,11\\}$ 标记。考虑类别 $c$ 的两种编码方式：(i) 独热编码 (one-hot encoding) $e(c) \\in \\mathbb{R}^{12}$，在索引 $c$ 处有一个值为 $1$ 的条目，其他位置为 $0$；(ii) 傅里叶特征编码 (Fourier feature encoding) $\\phi(c) \\in \\mathbb{R}^{1+2|M|}$，由一组谐波 $M = \\{1,2\\}$ 构建，形式为 $\\phi(c) = [1,\\sin(2\\pi m c / 12),\\cos(2\\pi m c / 12)]_{m \\in M}$，其中所有角度均以弧度为单位。你将通过最小化均方误差 (Mean Squared Error, MSE) 来拟合一个线性模型 $f(x) = w^\\top x$，并使用 Moore–Penrose 伪逆计算普通最小二乘 (Ordinary Least Squares, OLS) 解。目标是测试在存在循环分类变量的情况下，周期性傅里叶特征是否对模型有益。\n\n使用的基本定义：\n- 对于数据集 $\\{(x_i,y_i)\\}_{i=1}^n$ 上的模型 $f$，其均方误差 (MSE) 为 $\\frac{1}{n}\\sum_{i=1}^n (y_i - f(x_i))^2$。\n- 普通最小二乘 (OLS) 选择 $w$ 以最小化 MSE，其最小范数解由 $w = X^+ y$ 给出，其中 $X^+$ 是设计矩阵 $X$ 的 Moore–Penrose 伪逆，$y$ 是目标向量。\n\n构建一个玩具场景，其中目标是类别索引 $c$ 的确定性函数，不含噪声。对于每个测试用例，你将：\n1. 通过按指定枚举类别来生成训练集和测试集。\n2. 使用独热编码 $e(c)$ 和谐波为 $M = \\{1,2\\}$ 的傅里叶特征 $\\phi(c)$ 对输入进行编码。\n3. 对两种编码方式，在训练集上使用 OLS 拟合线性模型。\n4. 在指定的测试类别上评估两个模型的测试 MSE。\n5. 输出一个布尔值，指示傅里叶特征模型的测试 MSE 是否严格低于独热模型的测试 MSE。\n\n角度单位说明：三角函数中的所有角度都必须以弧度表示。\n\n测试套件：\n- 案例 $1$（理想周期路径）：目标 $y(c) = \\sin\\!\\left(\\frac{2\\pi c}{12}\\right)$；训练类别 $S_{\\text{train}} = \\{0,2,4,6,8,10\\}$；测试类别 $S_{\\text{test}} = \\{1,3,5,7,9,11\\}$。\n- 案例 $2$（对抗性周期，不在所选谐波中）：目标 $y(c) = \\cos(\\pi c)$，等价于 $y(c) = (-1)^c$，对应于周期为 $12$ 的谐波 $m=6$；训练类别 $S_{\\text{train}} = \\{0,2,4,6,8,10\\}$；测试类别 $S_{\\text{test}} = \\{1,3,5,7,9,11\\}$。\n- 案例 $3$（特征覆盖的谐波混合，类别有缺失）：目标 $y(c) = \\sin\\!\\left(\\frac{2\\pi c}{12}\\right) + \\frac{1}{2}\\cos\\!\\left(\\frac{4\\pi c}{12}\\right)$；训练类别 $S_{\\text{train}} = \\{0,1,2,4,5,6,8,9,10\\}$；测试类别 $S_{\\text{test}} = \\{3,7,11\\}$。\n- 案例 $4$（边界情况，类别完全覆盖）：目标 $y(c) = \\sin\\!\\left(\\frac{2\\pi c}{12}\\right) + \\frac{1}{2}\\cos\\!\\left(\\frac{4\\pi c}{12}\\right)$；训练类别 $S_{\\text{train}} = \\{0,1,2,3,4,5,6,7,8,9,10,11\\}$；测试类别 $S_{\\text{test}} = \\{0,1,2,3,4,5,6,7,8,9,10,11\\}$。\n\n模型和评估细节：\n- 对于每个案例，通过堆叠训练类别的编码形成训练设计矩阵 $X_{\\text{one-hot}}$ 和 $X_{\\text{fourier}}$，并通过将指定的 $y(c)$ 应用于每个训练类别来形成目标向量 $y_{\\text{train}}$。\n- 计算 $w_{\\text{one-hot}} = X_{\\text{one-hot}}^+ y_{\\text{train}}$ 和 $w_{\\text{fourier}} = X_{\\text{fourier}}^+ y_{\\text{train}}$。\n- 使用相应的编码形成 $X_{\\text{test}}$，在测试类别上评估预测，并计算每个模型的测试 MSE。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，列表中的每个元素是一个布尔值，按顺序对应案例 1 到 4，如果傅里叶特征模型的测试 MSE 严格低于独热模型，则为 $True$，否则为 $False$。例如，输出应类似于 $[True,False,True,False]$。", "solution": "该问题要求对循环分类变量的两种编码方案进行比较分析：独热编码和傅里叶特征编码。性能评估基于普通最小二乘 (OLS) 线性模型在测试集上的均方误差 (MSE)。该问题是有效的，因为它在科学上基于线性代数和机器学习原理，问题设定良好并提供了所有必要信息，并且其评估标准是客观的。\n\n分析的核心在于理解每种编码方法的隐含假设（归纳偏置）。独热编码创建了一个特征空间，其中每个类别由一个正交基向量表示。此空间中的线性模型 $f(e(c)) = w^\\top e(c) = w_c$ 为每个类别 $c$ 分配一个独立的权重 $w_c$。这使得模型能够在类别集上表示任何任意函数，但它没有提供泛化到未见类别的机制。相比之下，傅里叶特征编码通过一组正弦基函数的值构成的向量 $\\phi(c)$ 来表示每个类别 $c$。线性模型 $f(\\phi(c)) = w^\\top \\phi(c)$ 被约束为将目标函数表示为这些基函数的线性组合。这提供了一个很强的归纳偏置，即假设目标函数是周期性和平滑的，这有助于泛化，但将模型的表达能力限制在所选谐波的生成空间内。\n\n问题指定了周期 $P=12$ 和一组谐波 $M = \\{1,2\\}$。对于类别 $c \\in \\{0, 1, \\dots, 11\\}$，其傅里叶特征向量为 $\\phi(c) \\in \\mathbb{R}^{5}$：\n$$\n\\phi(c) = \\left[1, \\sin\\left(\\frac{2\\pi \\cdot 1 \\cdot c}{12}\\right), \\cos\\left(\\frac{2\\pi \\cdot 1 \\cdot c}{12}\\right), \\sin\\left(\\frac{2\\pi \\cdot 2 \\cdot c}{12}\\right), \\cos\\left(\\frac{2\\pi \\cdot 2 \\cdot c}{12}\\right)\\right]^\\top\n$$\n独热编码 $e(c) \\in \\mathbb{R}^{12}$ 是一个在索引 $c$ 处为 $1$，其他位置为 $0$ 的向量。\n\n对于每个案例，我们通过堆叠训练集 $S_{\\text{train}}$ 中所有 $c$ 的行向量 $e(c)^\\top$ 和 $\\phi(c)^\\top$ 来构建训练设计矩阵 $X_{\\text{one-hot}}$ 和 $X_{\\text{fourier}}$。目标向量 $y_{\\text{train}}$ 是通过将给定的目标函数应用于每个 $c \\in S_{\\text{train}}$ 而形成的。OLS 权重向量使用 Moore-Penrose 伪逆求得，$w = X^+ y_{\\text{train}}$。这提供了最小化平方误差和的唯一最小范数解。然后我们为测试集 $S_{\\text{test}}$ 形成测试矩阵 $X_{\\text{test}}$，计算预测值 $y_{\\text{pred}} = X_{\\text{test}} w$，并计算测试 MSE：$\\text{MSE} = \\frac{1}{|S_{\\text{test}}|} \\sum_{i \\in S_{\\text{test}}} (y_i - y_{\\text{pred},i})^2$。\n\n**案例 1：周期性目标，数据不完整**\n- 目标：$y(c) = \\sin(\\frac{2\\pi c}{12})$。该函数是傅里叶编码中的基函数之一（对应于谐波 $m=1$）。\n- 训练集：$S_{\\text{train}} = \\{0,2,4,6,8,10\\}$。测试集：$S_{\\text{test}} = \\{1,3,5,7,9,11\\}$。\n- **傅里叶模型**：由于目标函数完全位于傅里叶特征的生成空间内，模型可以完美地表示它。训练数据足够多样化，使得 OLS 能够识别出正确的权重，主要是为 $\\sin(\\frac{2\\pi c}{12})$ 特征分配权重 $1$，其他权重接近于零。这个学到的函数能够完美地泛化到未见的测试类别上。因此，测试 MSE 将约等于 $0$。\n- **独热模型**：模型在偶数索引的类别上进行训练。对于任何训练类别 $c_{\\text{train}} \\in S_{\\text{train}}$，权重 $w_{c_{\\text{train}}}$ 会学习到目标值 $y(c_{\\text{train}})$。对于未见的类别 $c_{\\text{test}} \\in S_{\\text{test}}$，其在训练设计矩阵中对应的列全为零。伪逆解的最小范数性质会将这些未见类别的权重 $w_{c_{\\text{test}}}$ 设置为 $0$。因此，模型对所有测试点的预测为 $f(e(c_{\\text{test}})) = 0$。而真实的测试目标 $y(c_{\\text{test}})$ 是非零的，导致了显著的测试 MSE。\n- **结论**：$\\text{MSE}_{\\text{fourier}} \\approx 0  \\text{MSE}_{\\text{one-hot}}$。结果为 **True**。\n\n**案例 2：不匹配的周期性目标**\n- 目标：$y(c) = \\cos(\\pi c) = \\cos(\\frac{2\\pi \\cdot 6 \\cdot c}{12})$。该函数对应于谐波 $m=6$，这不在模型的特征集 $M=\\{1,2\\}$ 中。\n- 训练集/测试集与案例 1 相同。\n- 对于偶数类别的训练集，目标是 $y(c) = \\cos(\\pi c) = (-1)^c = 1$ 对所有 $c \\in S_{\\text{train}}$。\n- **傅里叶模型**：训练目标向量是一个全为一的常数向量。这个向量与傅里叶设计矩阵的第一列（偏置项）完全相同。因此，OLS 解将是 $w = [1,0,0,0,0]^\\top$，导致模型对所有输入都预测 $f(c)=1$。对于测试集（奇数类别），真实目标是 $y(c) = -1$。模型预测值为 $1$，导致每个测试样本的误差为 $(-1 - 1)^2 = 4$。因此，$\\text{MSE}_{\\text{fourier}} = 4$。\n- **独热模型**：与案例 1 一样，模型对所有未见的测试类别预测为 $0$。真实的测试目标是 $-1$。每个测试样本的误差是 $(-1 - 0)^2 = 1$。因此，$\\text{MSE}_{\\text{one-hot}} = 1$。\n- **结论**：$\\text{MSE}_{\\text{fourier}} = 4$，$\\text{MSE}_{\\text{one-hot}} = 1$。条件 $4  1$ 不成立。结果为 **False**。\n\n**案例 3：混合谐波目标，数据不完整**\n- 目标：$y(c) = \\sin(\\frac{2\\pi c}{12}) + \\frac{1}{2}\\cos(\\frac{4\\pi c}{12})$。该函数是 $m=1$ 和 $m=2$ 基函数的线性组合，这两者都包含在傅里叶特征集中。\n- 训练集：$S_{\\text{train}} = \\{0,1,2,4,5,6,8,9,10\\}$。测试集：$S_{\\text{test}} = \\{3,7,11\\}$。\n- **傅里叶模型**：推理与案例 1 相同。模型的归纳偏置与目标函数完美对齐。用 $9$ 个训练样本拟合 $5$ 个参数，OLS 拟合将精确地恢复底层函数，然后完美地泛化到测试集。测试 MSE 将约等于 $0$。\n- **独热模型**：模型没有在类别 $\\{3,7,11\\}$ 上进行训练。它将对这些测试点预测为 $0$。而真实目标是非零的，导致了正的测试 MSE。\n- **结论**：$\\text{MSE}_{\\text{fourier}} \\approx 0  \\text{MSE}_{\\text{one-hot}}$。结果为 **True**。\n\n**案例 4：完整数据覆盖**\n- 目标：与案例 3 相同。\n- 训练集和测试集相同且完整：$S_{\\text{train}} = S_{\\text{test}} = \\{0, 1, \\dots, 11\\}$。\n- **独热模型**：当训练集中包含所有 $12$ 个类别时，设计矩阵 $X_{\\text{one-hot}}$ 是 $12 \\times 12$ 的单位矩阵 $I_{12}$。其伪逆也是 $I_{12}$。权重为 $w_{\\text{one-hot}} = I_{12} y_{\\text{train}} = y_{\\text{train}}$，意味着每个类别的 $w_c = y(c)$。该模型完美地记住了训练数据。由于测试集与训练集相同，预测是完美的，因此 $\\text{MSE}_{\\text{one-hot}} = 0$。\n- **傅里叶模型**：与案例 3 一样，目标函数在特征的生成空间内。使用完整数据集，OLS 拟合保证能找到精确的权重以完美地复现该函数。该模型在训练/测试集上也将实现零误差。因此，$\\text{MSE}_{\\text{fourier}} = 0$。\n- **结论**：由于 $\\text{MSE}_{\\text{fourier}} = 0$ 且 $\\text{MSE}_{\\text{one-hot}} = 0$，严格不等式 $\\text{MSE}_{\\text{fourier}}  \\text{MSE}_{\\text{one-hot}}$（即 $0  0$）不成立。结果为 **False**。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n\n    def solve_case(target_func, s_train, s_test, P, M):\n        \"\"\"\n        Solves a single test case for the problem.\n\n        Args:\n            target_func (callable): The function generating the target values y(c).\n            s_train (list): The list of training categories.\n            s_test (list): The list of test categories.\n            P (int): The period of the cyclic variable.\n            M (list): The set of harmonics for Fourier features.\n        \n        Returns:\n            bool: True if the Fourier model's MSE is strictly less than the one-hot model's MSE.\n        \"\"\"\n        # Convert category lists to numpy arrays for vectorized operations\n        c_train = np.array(s_train)\n        c_test = np.array(s_test)\n        \n        # 1. Generate target values for training and test sets\n        y_train = target_func(c_train)\n        y_test = target_func(c_test)\n\n        # 2. Encode inputs for both training and test sets\n        \n        # One-hot encoding\n        num_classes = P\n        X_train_onehot = np.zeros((len(c_train), num_classes))\n        # Use advanced indexing to set the '1's in the one-hot vectors\n        X_train_onehot[np.arange(len(c_train)), c_train] = 1\n        \n        X_test_onehot = np.zeros((len(c_test), num_classes))\n        X_test_onehot[np.arange(len(c_test)), c_test] = 1\n\n        # Fourier feature encoding\n        num_features_fourier = 1 + 2 * len(M)\n        X_train_fourier = np.ones((len(c_train), num_features_fourier))\n        X_test_fourier = np.ones((len(c_test), num_features_fourier))\n        \n        feature_idx = 1\n        for m in M:\n            # Training set features\n            angle_train = 2.0 * np.pi * m * c_train / P\n            X_train_fourier[:, feature_idx] = np.sin(angle_train)\n            X_train_fourier[:, feature_idx + 1] = np.cos(angle_train)\n            \n            # Test set features\n            angle_test = 2.0 * np.pi * m * c_test / P\n            X_test_fourier[:, feature_idx] = np.sin(angle_test)\n            X_test_fourier[:, feature_idx + 1] = np.cos(angle_test)\n            \n            feature_idx += 2\n\n        # 3. Fit linear models using OLS with the Moore-Penrose pseudoinverse\n        w_onehot = np.linalg.pinv(X_train_onehot) @ y_train\n        w_fourier = np.linalg.pinv(X_train_fourier) @ y_train\n        \n        # 4. Evaluate test MSE for both models\n        \n        # Predictions\n        y_pred_onehot = X_test_onehot @ w_onehot\n        y_pred_fourier = X_test_fourier @ w_fourier\n        \n        # Mean Squared Error calculation\n        mse_onehot = np.mean((y_test - y_pred_onehot)**2)\n        mse_fourier = np.mean((y_test - y_pred_fourier)**2)\n        \n        # 5. Return boolean indicating if Fourier MSE is strictly lower\n        return mse_fourier  mse_onehot\n\n    # Define the test cases from the problem statement.\n    P = 12\n    M = [1, 2]\n    \n    test_cases = [\n        # Case 1\n        {'target_func': lambda c: np.sin(2.0 * np.pi * c / P),\n         's_train': [0, 2, 4, 6, 8, 10],\n         's_test': [1, 3, 5, 7, 9, 11]},\n        # Case 2\n        {'target_func': lambda c: np.cos(np.pi * c),\n         's_train': [0, 2, 4, 6, 8, 10],\n         's_test': [1, 3, 5, 7, 9, 11]},\n        # Case 3\n        {'target_func': lambda c: np.sin(2.0 * np.pi * c / P) + 0.5 * np.cos(4.0 * np.pi * c / P),\n         's_train': [0, 1, 2, 4, 5, 6, 8, 9, 10],\n         's_test': [3, 7, 11]},\n        # Case 4\n        {'target_func': lambda c: np.sin(2.0 * np.pi * c / P) + 0.5 * np.cos(4.0 * np.pi * c / P),\n         's_train': list(range(P)),\n         's_test': list(range(P))},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(case['target_func'], case['s_train'], case['s_test'], P, M)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3121725"}]}