{"hands_on_practices": [{"introduction": "我们经常使用一种损失函数（如均方误差 $MSE$，因其良好的数学性质）来训练模型，但用另一种指标（如平均绝对误差 $MAE$，更易于解释）来评估模型。本练习将探讨在这种情况下可能出现的“优化-评估”不匹配问题，尤其是在数据包含异常值时。你将通过一个受控实验，亲手实现并比较一个对异常值更鲁棒、与 $MAE$ 更为一致的损失函数 ($\\log(\\cosh(\\cdot))$)，看看它在以 $MAE$ 为最终目标的场景下如何超越 $MSE$ [@problem_id:3168805]。这项实践提供了从第一性原理实现和比较不同损失函数的宝贵经验，揭示了数据特性、训练目标和评估结果之间的关键联系。", "problem": "给定一个经验风险最小化框架下的监督回归问题。设数据集为 $D = \\{(\\mathbf{x}_i, y_i)\\}_{i=1}^n$，其中 $\\mathbf{x}_i \\in \\mathbb{R}^d$。对于一个参数为 $(\\mathbf{w}, b)$ 的线性模型，其预测值为 $\\hat{y}_i = \\mathbf{w}^\\top \\mathbf{x}_i + b$，定义残差为 $r_i = y_i - \\hat{y}_i$。任务是设计并实现一个受控实验，量化在使用均方误差 (MSE) 进行训练但使用平均绝对误差 (MAE) 进行评估时，优化指标与评估指标之间的不匹配程度，并将其与使用基于双曲余弦对数的 MAE 可微代理进行训练的情况进行比较。\n\n使用的基本依据和定义：\n- 经验风险最小化 (ERM) 旨在最小化残差 $r_i$ 上某个非负损失的经验平均值。\n- 均方误差 (MSE) 是指在训练集上由 $r_i^2$ 的平均值给出的经验风险。\n- 平均绝对误差 (MAE) 是指在数据集上由 $|r_i|$ 的平均值给出的经验风险。\n- 提出的 MAE 可微代理是双曲余弦的对数，即函数 $r \\mapsto \\log(\\cosh(r / \\tau))$，其中 $\\tau$ 是一个正尺度参数，用于控制从二次行为到线性行为的过渡。\n\n实验设计及所需步骤：\n1. 从第一性原理生成数据：\n   - 固定一个 $d=3$ 维的真实线性数据生成过程，其确定性参数向量为 $\\mathbf{w}^\\star = [2.0, -3.0, 0.5]^\\top$，截距为 $b^\\star = 0.7$。对每个样本，独立抽取 $\\mathbf{x}_i$，其坐标为独立的标准正态分布。计算干净目标值 $y_i^{\\text{clean}} = (\\mathbf{w}^\\star)^\\top \\mathbf{x}_i + b^\\star$。\n   - 向每个干净目标值添加独立噪声 $\\epsilon_i$ 以生成 $y_i = y_i^{\\text{clean}} + \\epsilon_i$。该噪声从一个模拟离群点的混合分布中抽取：以 $1 - p_{\\text{out}}$ 的概率，抽取 $\\epsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$；以 $p_{\\text{out}}$ 的概率，抽取 $\\epsilon_i \\sim \\mathcal{N}(0, (\\sigma \\cdot s_{\\text{out}})^2)$。此处 $p_{\\text{out}} \\in [0, 1)$ 是离群点率，$\\sigma > 0$ 是基础噪声尺度，而 $s_{\\text{out}} \\ge 1$ 是离群点尺度因子。\n   - 将独立生成的数据分割成大小为 $n_{\\text{train}}$ 的训练集和大小为 $n_{\\text{test}}$ 的测试集，两者均由相同的过程和相同的参数生成。\n2. 需要通过梯度下降实现和最小化的训练目标：\n   - 训练一个线性模型 $(\\mathbf{w}, b)$，通过梯度下降最小化训练集上的经验 MSE。模型从零初始化，使用固定的学习率和固定次数的全批量迭代。仅使用 ERM 原理和微积分来推导参数更新所需的梯度。\n   - 训练另一个线性模型 $(\\tilde{\\mathbf{w}}, \\tilde{b})$，通过梯度下降最小化训练集上 $\\log(\\cosh(r / \\tau))$ 的经验平均值。使用相同的初始化和相同的优化超参数，并给定一个正数 $\\tau$。同样，仅使用 ERM 原理和微积分来推导参数更新所需的梯度。\n3. 评估指标与不匹配的量化：\n   - 对于每个训练好的模型，计算其在测试集上的 MAE，即测试集上 $|r_i|$ 的经验平均值。将使用均方误差训练的模型所得的 MAE 记为 $\\text{MAE}_{\\text{MSE}}$，将使用 $\\log(\\cosh(\\cdot))$ 代理训练的模型所得的 MAE 记为 $\\text{MAE}_{\\log\\cosh}$。\n   - 通过两种方式量化优化-评估不匹配：绝对差距 $\\Delta = \\text{MAE}_{\\text{MSE}} - \\text{MAE}_{\\log\\cosh}$ 和比率 $\\rho = \\text{MAE}_{\\text{MSE}} / \\text{MAE}_{\\log\\cosh}$。如果 $\\text{MAE}_{\\log\\cosh} = 0$，则定义 $\\rho = 1.0$ 以避免除以零的错误。\n4. 实现约束：\n   - 将整个实验实现为一个确定性程序，使用下方指定的种子初始化伪随机数生成器。使用全批量梯度下降，而非随机方法。仅使用 ERM 所蕴含的基础线性代数和微积分；不要依赖外部优化库。\n   - 为每个测试用例输出一个包含4个浮点数的列表 $[\\text{MAE}_{\\text{MSE}}, \\text{MAE}_{\\log\\cosh}, \\Delta, \\rho]$，每个浮点数四舍五入到6位小数。\n\n测试套件：\n在以下参数集上运行你的程序，每个参数集都使用如上所述独立生成的训练和测试数据：\n- 情况 A (理想路径，无离群点)：随机种子 $0$，训练集大小 $n_{\\text{train}} = 512$，测试集大小 $n_{\\text{test}} = 2048$，基础噪声 $\\sigma = 0.5$，离群点率 $p_{\\text{out}} = 0.0$，离群点尺度 $s_{\\text{out}} = 10.0$，学习率 $\\eta = 0.05$，迭代次数 $300$，代理尺度 $\\tau = 1.0$。\n- 情况 B (中度离群点)：随机种子 $1$，训练集大小 $n_{\\text{train}} = 512$，测试集大小 $n_{\\text{test}} = 2048$，基础噪声 $\\sigma = 0.5$，离群点率 $p_{\\text{out}} = 0.2$，离群点尺度 $s_{\\text{out}} = 8.0$，学习率 $\\eta = 0.05$，迭代次数 $300$，代理尺度 $\\tau = 1.0$。\n- 情况 C (更多离群点，不同尺度)：随机种子 $2$，训练集大小 $n_{\\text{train}} = 256$，测试集大小 $n_{\\text{test}} = 4096$，基础噪声 $\\sigma = 0.2$，离群点率 $p_{\\text{out}} = 0.3$，离群点尺度 $s_{\\text{out}} = 12.0$，学习率 $\\eta = 0.05$，迭代次数 $400$，代理尺度 $\\tau = 0.5$。\n- 情况 D (小样本边缘情况)：随机种子 $3$，训练集大小 $n_{\\text{train}} = 16$，测试集大小 $n_{\\text{test}} = 4096$，基础噪声 $\\sigma = 0.5$，离群点率 $p_{\\text{out}} = 0.25$，离群点尺度 $s_{\\text{out}} = 10.0$，学习率 $\\eta = 0.03$，迭代次数 $600$，代理尺度 $\\tau = 1.0$。\n\n最终输出格式：\n你的程序应生成单行内容，其中包含每个情况的结果列表，每个情况的结果是一个包含四个按序排列的四舍五入浮点数 $[\\text{MAE}_{\\text{MSE}}, \\text{MAE}_{\\log\\cosh}, \\Delta, \\rho]$ 的列表。顶层列表必须按 A、B、C、D 的顺序连接各情况的结果，并使用逗号且不带空格。例如，一个有效的形状和格式为\n$[[a_1,a_2,a_3,a_4],[b_1,b_2,b_3,b_4],[c_1,c_2,c_3,c_4],[d_1,d_2,d_3,d_4]]$\n其中每个 $a_j, b_j, c_j, d_j$ 都是四舍五入到6位小数的浮点数。", "solution": "用户提供的问题是有效的，因为它具有科学依据、问题明确且客观。它概述了监督机器学习领域一个详尽且可形式化的数值实验，并指定了所有必要的参数和条件。该问题是一项实质性任务，要求基于经验风险最小化的第一性原理实现数据生成、基于梯度的优化和评估。\n\n该问题要求进行一个受控实验，以研究优化指标（均方误差，MSE）和评估指标（平均绝对误差，MAE）之间的不匹配，特别是在存在离群点的情况下。这种情况将与使用 MAE 的可微代理——双曲余弦的对数（$\\log(\\cosh)$）作为优化指标进行对比。所测试的核心原理是，将优化目标与评估指标更紧密地对齐可以带来更好的性能，特别是当数据的噪声特性违反了标准目标的隐含假设时。\n\n### 1. 实验设计与数据生成\n\n实验基于一个从已知线性过程生成的合成数据集，这允许进行受控分析。基准模型由参数 $\\mathbf{w}^\\star \\in \\mathbb{R}^d$ 和 $b^\\star \\in \\mathbb{R}$ 定义，维度 $d=3$。数据点 $(\\mathbf{x}_i, y_i)$ 生成如下：\n- 特征 $\\mathbf{x}_i \\in \\mathbb{R}^3$ 从标准正态分布中抽取，即每个分量 $x_{ij} \\sim \\mathcal{N}(0, 1)$。\n- 真实目标值计算为 $y_i^{\\text{clean}} = (\\mathbf{w}^\\star)^\\top \\mathbf{x}_i + b^\\star$。\n- 通过向干净目标值添加噪声 $\\epsilon_i$ 来创建观测目标值 $y_i$：$y_i = y_i^{\\text{clean}} + \\epsilon_i$。\n- 噪声 $\\epsilon_i$ 从一个混合模型中抽取，以模拟离群点。以 $1 - p_{\\text{out}}$ 的概率，噪声来自基线正态分布 $\\mathcal{N}(0, \\sigma^2)$。以 $p_{\\text{out}}$ 的概率，噪声来自高方差正态分布 $\\mathcal{N}(0, (\\sigma \\cdot s_{\\text{out}})^2)$，代表离群点。参数 $p_{\\text{out}}$、$\\sigma$ 和 $s_{\\text{out}}$ 分别控制这些离群点的比率、基础尺度和量级。\n\n此过程用于生成一个大小为 $n_{\\text{train}}$ 的独立训练集和一个大小为 $n_{\\text{test}}$ 的测试集。\n\n### 2. 通过经验风险最小化进行优化\n\n一个带有参数 $(\\mathbf{w}, b)$ 的线性模型提供预测 $\\hat{y}_i = \\mathbf{w}^\\top \\mathbf{x}_i + b$。目标是通过最小化所选损失函数在训练集上的经验平均值来找到最优参数。这通过全批量梯度下降来完成，其中参数根据总损失的梯度进行迭代更新。\n\n#### 场景1：使用均方误差 (MSE) 训练\nMSE 损失由残差的平方定义，$L_{\\text{MSE}}(r_i) = r_i^2 = (y_i - \\hat{y}_i)^2$。总经验风险为：\n$$J_{\\text{MSE}}(\\mathbf{w}, b) = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} (y_i - (\\mathbf{w}^\\top \\mathbf{x}_i + b))^2$$\n为了使用梯度下降最小化这个函数，我们需要它关于参数 $\\mathbf{w}$ 和 $b$ 的偏导数。令 $\\mathbf{r} = \\mathbf{y} - (\\mathbf{X}\\mathbf{w} + b)$ 为残差向量。\n梯度为：\n$$ \\nabla_{\\mathbf{w}} J_{\\text{MSE}} = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} 2(y_i - \\hat{y}_i)(-\\mathbf{x}_i) = -\\frac{2}{n_{\\text{train}}}\\sum_{i=1}^{n_{\\text{train}}} r_i \\mathbf{x}_i = -\\frac{2}{n_{\\text{train}}} \\mathbf{X}^\\top \\mathbf{r} $$\n$$ \\nabla_{b} J_{\\text{MSE}} = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} 2(y_i - \\hat{y}_i)(-1) = -\\frac{2}{n_{\\text{train}}}\\sum_{i=1}^{n_{\\text{train}}} r_i $$\nMSE 损失函数中的平方项使其对大残差高度敏感，这意味着离群点可以不成比例地影响最终的模型参数。\n\n#### 场景2：使用 Log-Cosh 代理训练\nlog-cosh 损失是 MAE 损失的一个平滑近似，定义为 $L_{\\log\\cosh}(r_i) = \\log(\\cosh(r_i / \\tau))$，其中 $\\tau > 0$ 是一个尺度参数。经验风险是：\n$$J_{\\log\\cosh}(\\tilde{\\mathbf{w}}, \\tilde{b}) = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\log\\left(\\cosh\\left(\\frac{y_i - (\\tilde{\\mathbf{w}}^\\top \\mathbf{x}_i + \\tilde{b})}{\\tau}\\right)\\right)$$\n对于小残差（$|r_i| \\ll \\tau$），该函数的行为类似于 MSE（二次），而对于大残差（$|r_i| \\gg \\tau$），其行为类似于 MAE（线性），这使其对离群点更具鲁棒性。梯度使用链式法则和恒等式 $\\frac{d}{dz}\\log(\\cosh(z)) = \\tanh(z)$ 推导得出：\n$$ \\nabla_{\\tilde{\\mathbf{w}}} J_{\\log\\cosh} = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\tanh\\left(\\frac{r_i}{\\tau}\\right) \\frac{1}{\\tau} (-\\mathbf{x}_i) = -\\frac{1}{n_{\\text{train}}\\tau} \\sum_{i=1}^{n_{\\text{train}}} \\tanh\\left(\\frac{r_i}{\\tau}\\right) \\mathbf{x}_i $$\n$$ \\nabla_{\\tilde{b}} J_{\\log\\cosh} = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\tanh\\left(\\frac{r_i}{\\tau}\\right) \\frac{1}{\\tau} (-1) = -\\frac{1}{n_{\\text{train}}\\tau} \\sum_{i=1}^{n_{\\text{train}}} \\tanh\\left(\\frac{r_i}{\\tau}\\right) $$\n使用双曲正切函数 $\\tanh(\\cdot)$“压缩”了大残差的影响，提供了所期望的鲁棒性。\n\n对于这两种场景，参数都初始化为零，并使用学习率为 $\\eta$ 的梯度下降规则进行固定次数的迭代更新：$\\boldsymbol{\\theta}_{t+1} \\leftarrow \\boldsymbol{\\theta}_t - \\eta \\nabla_{\\boldsymbol{\\theta}} J$，其中 $\\boldsymbol{\\theta}$ 代表参数对 $(\\mathbf{w}, b)$ 或 $(\\tilde{\\mathbf{w}}, \\tilde{b})$。\n\n### 3. 评估与不匹配量化\n\n训练后，两个模型都在独立生成的测试集上进行评估。性能指标是平均绝对误差（MAE），这是最终关注的指标。\n$$ \\text{MAE} = \\frac{1}{n_{\\text{test}}} \\sum_{i=1}^{n_{\\text{test}}} |y_i - \\hat{y}_i| $$\n我们计算用 MSE 训练的模型的 $\\text{MAE}_{\\text{MSE}}$ 和用 log-cosh 代理训练的模型的 $\\text{MAE}_{\\log\\cosh}$。然后，通过两个指标量化优化和评估目标之间的不匹配：\n1.  绝对差距：$\\Delta = \\text{MAE}_{\\text{MSE}} - \\text{MAE}_{\\log\\cosh}$\n2.  比率：$\\rho = \\text{MAE}_{\\text{MSE}} / \\text{MAE}_{\\log\\cosh}$\n\n正的 $\\Delta$ 和大于 1 的比率 $\\rho$ 表明，使用鲁棒的 log-cosh 代理进行训练产生的模型在 MAE 评估指标上表现更好，从而减轻了优化-评估不匹配。预计这种效应在存在离群点时（即当 $p_{\\text{out}} > 0$ 时）会更加明显。\n\n实验将以编程方式实现，遵守每个测试用例的指定参数，通过使用带种子的伪随机数生成器确保结果的确定性和可复现性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the series of experiments and print the final results.\n    \"\"\"\n    # Define the true parameters for data generation\n    w_star = np.array([2.0, -3.0, 0.5])\n    b_star = 0.7\n    d = 3\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: happy path, no outliers\n        {'seed': 0, 'n_train': 512, 'n_test': 2048, 'sigma': 0.5, 'p_out': 0.0, 's_out': 10.0, 'eta': 0.05, 'epochs': 300, 'tau': 1.0},\n        # Case B: moderate outliers\n        {'seed': 1, 'n_train': 512, 'n_test': 2048, 'sigma': 0.5, 'p_out': 0.2, 's_out': 8.0, 'eta': 0.05, 'epochs': 300, 'tau': 1.0},\n        # Case C: heavier outliers, different scale\n        {'seed': 2, 'n_train': 256, 'n_test': 4096, 'sigma': 0.2, 'p_out': 0.3, 's_out': 12.0, 'eta': 0.05, 'epochs': 400, 'tau': 0.5},\n        # Case D: small-sample edge case\n        {'seed': 3, 'n_train': 16, 'n_test': 4096, 'sigma': 0.5, 'p_out': 0.25, 's_out': 10.0, 'eta': 0.03, 'epochs': 600, 'tau': 1.0},\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = run_experiment(w_star, b_star, d, **params)\n        all_results.append(result)\n\n    # Format the final output string exactly as required.\n    # e.g., [[val1,val2,val3,val4],[val1,val2,val3,val4],...]\n    results_str = ','.join([f\"[{','.join(map(str, [round(v, 6) for v in res]))}]\" for res in all_results])\n    print(f\"[{results_str}]\")\n\ndef generate_data(n_samples, d, w_star, b_star, sigma, p_out, s_out, rng):\n    \"\"\"\n    Generates synthetic data from a linear model with mixed Gaussian noise.\n    \"\"\"\n    X = rng.standard_normal(size=(n_samples, d))\n    y_clean = X @ w_star + b_star\n\n    # Generate noise from the mixture model\n    is_outlier = rng.uniform(size=n_samples)  p_out\n    noise_std = np.where(is_outlier, sigma * s_out, sigma)\n    noise = rng.normal(loc=0.0, scale=noise_std)\n    \n    y = y_clean + noise\n    return X, y\n\ndef train(X_train, y_train, loss_type, eta, epochs, tau=None):\n    \"\"\"\n    Trains a linear model using full-batch gradient descent.\n    \"\"\"\n    n_train, d = X_train.shape\n    w = np.zeros(d)\n    b = 0.0\n\n    for _ in range(epochs):\n        predictions = X_train @ w + b\n        residuals = y_train - predictions\n\n        if loss_type == 'mse':\n            grad_w = (-2 / n_train) * (X_train.T @ residuals)\n            grad_b = (-2 / n_train) * np.sum(residuals)\n        elif loss_type == 'logcosh':\n            if tau is None:\n                raise ValueError(\"tau must be provided for logcosh loss\")\n            tanh_term = np.tanh(residuals / tau)\n            grad_w = (-1 / (n_train * tau)) * (X_train.T @ tanh_term)\n            grad_b = (-1 / (n_train * tau)) * np.sum(tanh_term)\n        else:\n            raise ValueError(f\"Unknown loss type: {loss_type}\")\n\n        w -= eta * grad_w\n        b -= eta * grad_b\n    \n    return w, b\n\ndef evaluate_mae(X_test, y_test, w, b):\n    \"\"\"\n    Evaluates the Mean Absolute Error of a model on the test set.\n    \"\"\"\n    y_pred = X_test @ w + b\n    mae = np.mean(np.abs(y_test - y_pred))\n    return mae\n\ndef run_experiment(w_star, b_star, d, seed, n_train, n_test, sigma, p_out, s_out, eta, epochs, tau):\n    \"\"\"\n    Runs a single experimental case: data generation, training, and evaluation.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Generate training and test data\n    X_train, y_train = generate_data(n_train, d, w_star, b_star, sigma, p_out, s_out, rng)\n    X_test, y_test = generate_data(n_test, d, w_star, b_star, sigma, p_out, s_out, rng)\n\n    # Train model 1: Minimize MSE\n    w_mse, b_mse = train(X_train, y_train, loss_type='mse', eta=eta, epochs=epochs)\n    \n    # Train model 2: Minimize LogCosh loss\n    w_logcosh, b_logcosh = train(X_train, y_train, loss_type='logcosh', eta=eta, epochs=epochs, tau=tau)\n\n    # Evaluate both models on the test set using MAE\n    mae_mse = evaluate_mae(X_test, y_test, w_mse, b_mse)\n    mae_logcosh = evaluate_mae(X_test, y_test, w_logcosh, b_logcosh)\n\n    # Quantify the mismatch\n    delta = mae_mse - mae_logcosh\n    \n    if mae_logcosh == 0:\n        rho = 1.0\n    else:\n        rho = mae_mse / mae_logcosh\n        \n    return [mae_mse, mae_logcosh, delta, rho]\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3168805"}, {"introduction": "现实世界的决策通常需要理解可能结果的范围，而不仅仅是一个单一的最佳猜测，这使得用于构建预测区间的 quantile regression 变得至关重要。本练习将超越像 $MSE$ 这样的点估计指标，转向对概率性预测的评估。你将从其非对称成本这一基本原则出发，推导并实现分位数预测的标准评分规则——弹球损失函数 (pinball loss) [@problem_id:3168892]。通过完成这项练习，你将学会如何评估模型对不确定性的估计，并理解覆盖率和区间宽度等关键诊断指标，这对于风险管理、金融和供应链预测等应用至关重要。", "problem": "给定多个观测值在水平 $\\tau \\in \\{0.1, 0.5, 0.9\\}$ 下的预测条件分位数。您的任务是构建一个完整、可运行的程序，使用非对称线性损失原则和基于区间的覆盖率诊断来评估分位数回归预测。\n\n使用的基本原理：\n- $\\tau$-分位数被刻画为可加、正齐次、非对称线性损失期望值的最小化子，该损失函数对正残差和负残差施加由 $\\tau$ 决定的不同斜率的惩罚。具体来说，低估和高估会产生不同的线性成本，其比率取决于 $\\tau$。\n- 经验风险将每个观测的损失在一个数据集上进行可加聚合。\n\n基于此，您必须推导出对于给定残差 $u = y - \\hat{q}_\\tau(x)$ 的确切单样本损失表达式，并实现它。不要假设或使用任何预先封装的公式；从所述的非对称性原则出发进行推导，并直接实现推导出的表达式。\n\n需要从第一性原理实现的定义：\n- 对于每个分位数水平 $\\tau$，单样本损失是 $u$ 的一个非对称线性函数，其斜率取决于 $u$ 的符号和参数 $\\tau$。\n- 对于给定的 $\\tau$，平均损失是所有样本的单样本损失的算术平均值。\n- 为了研究非对称成本，将给定 $\\tau$ 的总损失分解为正残差和负残差的贡献，并计算正残差贡献的份额。如果总损失为零，则将此份额定义为 $0.0$。\n- 中心预测区间由 $\\tau = 0.1$ 的下分位数和 $\\tau = 0.9$ 的上分位数定义。如果一个样本的预测分位数不满足有序性，则通过取两者中的较小值作为下端点、较大值作为上端点来构造区间。经验覆盖率是目标值 $y$ 落在所构造区间内（包含端点）的样本比例。平均区间宽度是两个端点之间绝对差值的平均值。交叉计数是原始预测的下分位数超过原始预测的上分位数的样本数量。\n- 聚合分位数得分定义为所有样本在 $\\tau \\in \\{0.1, 0.5, 0.9\\}$ 上的单样本损失之和的平均值。\n\n程序要求：\n1. 从非对称性原则出发，推导出作为残差 $u$ 和参数 $\\tau$ 函数的显式单样本非对称线性损失，并实现它。\n2. 对每个测试用例和每个 $\\tau \\in \\{0.1, 0.5, 0.9\\}$，计算：\n   - 平均损失。\n   - 正残差贡献的损失份额（如果总损失为 $0$，则约定为 $0.0$）。\n3. 对每个测试用例，使用预测的 $\\tau = 0.1$ 和 $\\tau = 0.9$ 分位数，计算：\n   - 中心预测区间的经验覆盖率。\n   - 平均区间宽度。\n   - 交叉计数（在重新排序前，下分位数严格大于上分位数的样本数）。\n4. 对每个测试用例，计算聚合分位数得分，定义为所有样本在 $\\tau \\in \\{0.1, 0.5, 0.9\\}$ 上的单样本损失之和的平均值。\n5. 将所有浮点输出四舍五入到 $6$ 位小数。\n\n测试套件（精确实现以下三个测试用例；每个用例提供目标值和预测分位数的数组）：\n\n- 测试用例 1 (正常情况，有序分位数):\n  - 目标值 $y$: $[1.0, 2.0, 3.0, 4.0, 5.0, 6.0]$。\n  - 预测的 $\\hat{q}_{0.1}$: $[0.5, 1.5, 2.7, 3.0, 4.2, 5.5]$。\n  - 预测的 $\\hat{q}_{0.5}$: $[0.9, 1.8, 3.1, 3.9, 4.9, 6.2]$。\n  - 预测的 $\\hat{q}_{0.9}$: $[1.6, 2.5, 3.6, 4.8, 5.7, 6.8]$。\n\n- 测试用例 2 (边界情况，完美预测，零宽度):\n  - 目标值 $y$: $[2.5, -1.0, 0.0, 3.3]$。\n  - 预测的 $\\hat{q}_{0.1}$: $[2.5, -1.0, 0.0, 3.3]$。\n  - 预测的 $\\hat{q}_{0.5}$: $[2.5, -1.0, 0.0, 3.3]$。\n  - 预测的 $\\hat{q}_{0.9}$: $[2.5, -1.0, 0.0, 3.3]$。\n\n- 测试用例 3 (边缘情况，分位数交叉):\n  - 目标值 $y$: $[10.0, 0.0, -2.0, 5.0, 1.0]$。\n  - 预测的 $\\hat{q}_{0.1}$: $[12.0, 1.0, -1.0, 7.0, 3.0]$。\n  - 预测的 $\\hat{q}_{0.5}$: $[11.0, 0.5, -2.5, 6.0, 1.5]$。\n  - 预测的 $\\hat{q}_{0.9}$: $[9.0, -1.0, -3.0, 4.0, 0.0]$。\n\n最终输出格式：\n- 对于每个测试用例，按以下顺序输出一个包含十个值的列表：\n  $[\\text{mean\\_loss\\_0.1}, \\text{mean\\_loss\\_0.5}, \\text{mean\\_loss\\_0.9}, \\text{aggregate\\_quantile\\_score}, \\text{coverage\\_rate}, \\text{mean\\_interval\\_width}, \\text{crossing\\_count}, \\text{pos\\_loss\\_share\\_0.1}, \\text{pos\\_loss\\_share\\_0.5}, \\text{pos\\_loss\\_share\\_0.9}]$ 其中除交叉计数外的所有条目都是四舍五入到 $6$ 位小数的浮点数，交叉计数是一个整数。\n- 您的程序应生成单行输出，其中包含所有三个测试用例的结果，形式为一个用方括号括起来的逗号分隔列表，其中每个元素是单个测试用例的列表。例如：$[[\\dots],[\\dots],[\\dots]]$。\n- 此问题不涉及任何物理单位或角度。", "solution": "问题陈述已经过严格验证，并被确定为有效。它在科学上是合理的、自洽的、适定的，基于分位数回归评估的既定原则，提供了一个清晰客观的任务。提供了唯一解所需的所有必要数据和定义。\n\n问题的核心是根据第一性原理推导并实现分位数损失函数。\n\n**1. 单样本分位数损失函数的推导**\n\n问题指明，$\\tau$-分位数损失是残差 $u = y - \\hat{q}_\\tau$ 的一个非对称线性函数，其中 $y$ 是真实目标值，$\\hat{q}_\\tau$ 是在水平 $\\tau$ 上的预测分位数。设该损失函数为 $\\rho_\\tau(u)$。\n\n非对称性意味着对低估（$u  0$，即 $y  \\hat{q}_\\tau$）的惩罚与对高估（$u  0$，即 $y  \\hat{q}_\\tau$）的惩罚不同。损失是线性的，因此我们可以写成：\n$$\n\\rho_\\tau(u) =\n\\begin{cases}\na_{pos} \\cdot u  \\text{if } u  0 \\\\\n0  \\text{if } u = 0 \\\\\na_{neg} \\cdot (-u)  \\text{if } u  0\n\\end{cases}\n$$\n其中 $a_{pos}$ 和 $a_{neg}$ 是非负斜率。\n\n分位数预测的一个基本属性是它应该平衡高估和低估的成本。$\\tau$-分位数是这样一个值，观测值小于它的概率为 $\\tau$。最小化期望损失 $E[\\rho_\\tau(y - \\hat{q}_\\tau)]$ 关于预测 $\\hat{q}_\\tau$ 的一阶条件要求损失函数关于 $\\hat{q}_\\tau$ 的导数的期望值为零。其导数为：\n$$\n\\frac{\\partial \\rho_\\tau(y - \\hat{q}_\\tau)}{\\partial \\hat{q}_\\tau} =\n\\begin{cases}\n-a_{pos}  \\text{if } y  \\hat{q}_\\tau \\\\\na_{neg}  \\text{if } y  \\hat{q}_\\tau\n\\end{cases}\n$$\n将期望设为零可得：\n$$ E\\left[\\frac{\\partial \\rho_\\tau(y - \\hat{q}_\\tau)}{\\partial \\hat{q}_\\tau}\\right] = (-a_{pos}) \\cdot P(y  \\hat{q}_\\tau) + (a_{neg}) \\cdot P(y  \\hat{q}_\\tau) = 0 $$\n$$ a_{neg} \\cdot P(y  \\hat{q}_\\tau) = a_{pos} \\cdot P(y  \\hat{q}_\\tau) $$\n对于一个理想的预测，其中 $\\hat{q}_\\tau$ 是 $y$ 的条件分布的真实 $\\tau$-分位数，我们有 $P(y  \\hat{q}_\\tau) = \\tau$ 和 $P(y  \\hat{q}_\\tau) = 1 - \\tau$。将这些代入平衡条件可得：\n$$ a_{neg} \\cdot \\tau = a_{pos} \\cdot (1 - \\tau) $$\n这个方程决定了斜率的比率。满足此关系的一个标准且方便的选择是设 $a_{pos} = \\tau$ 和 $a_{neg} = 1 - \\tau$。这导出了广泛使用的分位数损失（或称弹球损失）函数。\n\n将这些斜率代回分段定义中，并将 $u=0$ 的情况（损失为 $0$）并入 $u0$ 的情况，我们得到单样本损失的解析表达式：\n$$\n\\rho_\\tau(u) =\n\\begin{cases}\n\\tau \\cdot u  \\text{if } u \\ge 0 \\\\\n(1-\\tau) \\cdot (-u)  \\text{if } u  0\n\\end{cases}\n$$\n其中 $u = y - \\hat{q}_\\tau$。此公式按要求直接从非对称性原则推导而来，并构成了所有基于损失的计算的基础。\n\n**2. 评估指标的定义**\n\n给定一个包含 $N$ 个观测值的数据集，索引为 $i=1, \\dots, N$，其目标值为 $y_i$，分位数预测为 $\\hat{q}_{i, \\tau}$，评估指标定义如下。\n\n- **平均损失**：对于给定的分位数水平 $\\tau$，单样本损失的算术平均值：\n$$ \\text{MeanLoss}_\\tau = \\frac{1}{N} \\sum_{i=1}^N \\rho_\\tau(y_i - \\hat{q}_{i, \\tau}) $$\n\n- **正残差贡献的损失份额**：总损失中来自 $y_i  \\hat{q}_{i, \\tau}$ 的样本所占的比例。令 $u_{i, \\tau} = y_i - \\hat{q}_{i, \\tau}$。\n$$ \\text{PositiveLossShare}_\\tau = \\frac{\\sum_{i=1}^N \\rho_\\tau(u_{i, \\tau}) \\cdot \\mathbb{I}(u_{i, \\tau}  0)}{\\sum_{i=1}^N \\rho_\\tau(u_{i, \\tau})} $$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。如果总损失（分母）为 $0$，则份额定义为 $0.0$。\n\n- **基于区间的指标**：使用 $\\tau=0.1$ 和 $\\tau=0.9$ 的分位数预测：\n  - **交叉计数**：预测的下分位数大于预测的上分位数的样本数量。\n  $$ \\text{CrossingCount} = \\sum_{i=1}^N \\mathbb{I}(\\hat{q}_{i, 0.1}  \\hat{q}_{i, 0.9}) $$\n  - **预测区间**：对于每个样本 $i$，区间为 $[l_i, u_i]$，其中 $l_i = \\min(\\hat{q}_{i, 0.1}, \\hat{q}_{i, 0.9})$ 且 $u_i = \\max(\\hat{q}_{i, 0.1}, \\hat{q}_{i, 0.9})$。\n  - **经验覆盖率**：观测值 $y_i$ 落在构造的区间 $[l_i, u_i]$ 内的比例。\n  $$ \\text{CoverageRate} = \\frac{1}{N} \\sum_{i=1}^N \\mathbb{I}(l_i \\le y_i \\le u_i) $$\n  - **平均区间宽度**：构造区间的平均宽度。\n  $$ \\text{MeanWidth} = \\frac{1}{N} \\sum_{i=1}^N (u_i - l_i) = \\frac{1}{N} \\sum_{i=1}^N |\\hat{q}_{i, 0.9} - \\hat{q}_{i, 0.1}| $$\n\n- **聚合分位数得分**：所有样本在所有指定分位数水平上的单样本损失之和的平均值。\n$$ \\text{AggregateScore} = \\frac{1}{N} \\sum_{i=1}^N \\left( \\rho_{0.1}(u_{i, 0.1}) + \\rho_{0.5}(u_{i, 0.5}) + \\rho_{0.9}(u_{i, 0.9}) \\right) $$\n这等价于平均损失之和：$\\text{MeanLoss}_{0.1} + \\text{MeanLoss}_{0.5} + \\text{MeanLoss}_{0.9}$。\n\n实现将通过将这些推导出的公式应用于提供的测试数据来进行。", "answer": "```python\nimport numpy as np\n\ndef calculate_metrics(y_true, q_pred_01, q_pred_05, q_pred_09):\n    \"\"\"\n    Computes quantile regression evaluation metrics from first principles.\n\n    Args:\n        y_true (np.ndarray): Array of true target values.\n        q_pred_01 (np.ndarray): Array of predicted 0.1-quantiles.\n        q_pred_05 (np.ndarray): Array of predicted 0.5-quantiles.\n        q_pred_09 (np.ndarray): Array of predicted 0.9-quantiles.\n\n    Returns:\n        list: A list of 10 computed metrics, rounded as required.\n    \"\"\"\n    y = np.array(y_true, dtype=float)\n    q01 = np.array(q_pred_01, dtype=float)\n    q05 = np.array(q_pred_05, dtype=float)\n    q09 = np.array(q_pred_09, dtype=float)\n\n    taus = [0.1, 0.5, 0.9]\n    quantiles = [q01, q05, q09]\n    \n    mean_losses = []\n    pos_loss_shares = []\n\n    for tau, q_pred in zip(taus, quantiles):\n        # Calculate per-sample quantile loss from the derived formula\n        u = y - q_pred\n        # rho(u) = tau * u if u >= 0 else (1 - tau) * (-u)\n        losses = np.where(u >= 0, tau * u, (1 - tau) * -u)\n        \n        # Calculate mean loss\n        mean_loss = np.mean(losses)\n        mean_losses.append(mean_loss)\n        \n        # Calculate share of loss from positive residuals\n        total_loss = np.sum(losses)\n        if total_loss == 0.0:\n            pos_share = 0.0\n        else:\n            # Positive residuals are strictly u > 0.\n            # Loss for u > 0 is tau * u.\n            pos_losses_sum = np.sum(np.where(u > 0, tau * u, 0.0))\n            pos_share = pos_losses_sum / total_loss\n        pos_loss_shares.append(pos_share)\n\n    # Interval-based metrics for tau=0.1 and tau=0.9\n    \n    # Crossing count\n    crossing_count = np.sum(q01 > q09)\n\n    # Construct intervals, handling crossings\n    interval_lower = np.minimum(q01, q09)\n    interval_upper = np.maximum(q01, q09)\n    \n    # Empirical coverage rate\n    covered = (y >= interval_lower)  (y = interval_upper)\n    coverage_rate = np.mean(covered)\n    \n    # Mean interval width\n    # Width is max - min, which is equivalent to |q09 - q01|\n    widths = interval_upper - interval_lower\n    mean_interval_width = np.mean(widths)\n    \n    # Aggregate quantile score\n    aggregate_score = sum(mean_losses)\n    \n    # Assemble results in the specified order and format\n    results = [\n        round(mean_losses[0], 6),\n        round(mean_losses[1], 6),\n        round(mean_losses[2], 6),\n        round(aggregate_score, 6),\n        round(coverage_rate, 6),\n        round(mean_interval_width, 6),\n        int(crossing_count),\n        round(pos_loss_shares[0], 6),\n        round(pos_loss_shares[1], 6),\n        round(pos_loss_shares[2], 6),\n    ]\n    \n    return results\n\ndef solve():\n    \"\"\"\n    Defines test cases, runs the metric calculations, and prints the final output.\n    \"\"\"\n    test_cases = [\n        {\n            \"y\": [1.0, 2.0, 3.0, 4.0, 5.0, 6.0],\n            \"q_0.1\": [0.5, 1.5, 2.7, 3.0, 4.2, 5.5],\n            \"q_0.5\": [0.9, 1.8, 3.1, 3.9, 4.9, 6.2],\n            \"q_0.9\": [1.6, 2.5, 3.6, 4.8, 5.7, 6.8],\n        },\n        {\n            \"y\": [2.5, -1.0, 0.0, 3.3],\n            \"q_0.1\": [2.5, -1.0, 0.0, 3.3],\n            \"q_0.5\": [2.5, -1.0, 0.0, 3.3],\n            \"q_0.9\": [2.5, -1.0, 0.0, 3.3],\n        },\n        {\n            \"y\": [10.0, 0.0, -2.0, 5.0, 1.0],\n            \"q_0.1\": [12.0, 1.0, -1.0, 7.0, 3.0],\n            \"q_0.5\": [11.0, 0.5, -2.5, 6.0, 1.5],\n            \"q_0.9\": [9.0, -1.0, -3.0, 4.0, 0.0],\n        },\n    ]\n\n    all_results = []\n    for case in test_cases:\n        y_true = case[\"y\"]\n        q_pred_01 = case[\"q_0.1\"]\n        q_pred_05 = case[\"q_0.5\"]\n        q_pred_09 = case[\"q_0.9\"]\n        \n        result = calculate_metrics(y_true, q_pred_01, q_pred_05, q_pred_09)\n        all_results.append(result)\n\n    # Format the final output string exactly as required.\n    # The default str() for floats might not show trailing zeros,\n    # so we use a format specifier.\n    result_str = \"[\"\n    for i, res_list in enumerate(all_results):\n        res_list_str = \"[\"\n        for j, item in enumerate(res_list):\n            if isinstance(item, float):\n                res_list_str += f\"{item:.6f}\"\n            else:\n                res_list_str += str(item)\n            if j  len(res_list) - 1:\n                res_list_str += \",\"\n        res_list_str += \"]\"\n        result_str += res_list_str\n        if i  len(all_results) - 1:\n            result_str += \",\"\n    result_str += \"]\"\n    \n    print(result_str)\n\nsolve()\n```", "id": "3168892"}, {"introduction": "当我们在测试集上比较两个模型，发现模型 A 的 $MSE$ 略低于模型 B 时，我们能在多大程度上确信模型 A 真的更好？这个单一的评估结果可能仅仅是由于我们特定数据样本中的随机性造成的。本练习引入了一种强大的统计技术——非参数自举法 (nonparametric bootstrap)，用于评估模型排序的稳定性 [@problem_id:3168825]。通过对数据进行重采样，你将模拟性能指标的采样分布，并估计一个模型持续优于另一个模型的概率 $P(\\mathrm{MSE}_A  \\mathrm{MSE}_B)$，从而学会量化模型评估中的不确定性，从简单的点值比较转向更稳健的概率性结论。", "problem": "考虑一个监督回归情景，其中有从一个固定但未知的数据生成过程中抽取的独立同分布 (i.i.d.) 样本 $\\{(x_i,y_i)\\}_{i=1}^n$。假设一个模型为每个输入 $x_i$ 生成预测值 $\\hat{y}_i$，且单样本平方误差为 $(y_i - \\hat{y}_i)^2$。模型在数据集上的均方误差 (MSE) 是平方误差的经验平均值。为了评估两个模型之间的排序在抽样可变性下的稳定性，请使用对数据集的非参数自助法重抽样，为每个模型构建 MSE 的抽样分布，然后估计概率 $P(\\mathrm{MSE}_A  \\mathrm{MSE}_B)$，其中 $\\mathrm{MSE}_A$ 和 $\\mathrm{MSE}_B$ 是模型 A 和模型 B 在原始数据集的同一次自助法重抽样样本上计算出的 MSE 值。通过严格比较来处理平局情况，即当 $\\mathrm{MSE}_A = \\mathrm{MSE}_B$ 时，该自助法重复样本对概率估计的贡献为 $0$。\n\n从“回归损失是独立同分布样本的经验平均值”以及“非参数自助法通过对观测数据集进行有放回的重抽样来近似抽样分布”这两个基本定义出发，实现一个程序，对下述每个测试用例执行以下操作：\n- 通过抽取 $x_i \\sim \\mathrm{Uniform}([-1,1])$ 和噪声 $\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ 来生成一个数据集，然后设置 $y_i = a_{\\text{true}} x_i + b_{\\text{true}} + \\varepsilon_i$。\n- 定义两个确定性模型 A 和 B，它们将 $x_i$ 映射到 $\\hat{y}_i^{(A)}$ 和 $\\hat{y}_i^{(B)}$。\n- 对索引集 $\\{1,\\dots,n\\}$ 进行有放回的自助法重抽样，使用恰好 $R$ 次重复，并在每个重抽样样本上计算 $\\mathrm{MSE}_A$ 和 $\\mathrm{MSE}_B$。\n- 将 $\\mathrm{MSE}_A$ 严格小于 $\\mathrm{MSE}_B$ 的重复样本所占的比例，作为 $P(\\mathrm{MSE}_A  \\mathrm{MSE}_B)$ 的估计值。\n- 为了可复现性，使用指定的随机种子：用于抽取 $x_i$ 和 $\\varepsilon_i$ 的数据生成种子 $s_{\\text{data}}$，以及用于抽取重抽样索引的自助法种子 $s_{\\text{boot}}$。所有随机性必须严格按照每个测试用例的规定设置种子。\n\n不涉及物理单位。不使用角度。概率必须以小数形式表示。\n\n具有全覆盖的测试套件规范：\n- 案例 1（一般情况）：$n = 128$，$\\sigma = 0.2$，$a_{\\text{true}} = 2.0$，$b_{\\text{true}} = 1.0$，模型 A：$\\hat{y}_i^{(A)} = 2.0 x_i + 1.0$，模型 B：$\\hat{y}_i^{(B)} = 1.7 x_i + 1.1$，$R = 2000$，$s_{\\text{data}} = 11$，$s_{\\text{boot}} = 101$。\n- 案例 2（平局边界）：$n = 128$，$\\sigma = 0.2$，$a_{\\text{true}} = 2.0$，$b_{\\text{true}} = 1.0$，模型 A：$\\hat{y}_i^{(A)} = 2.0 x_i + 1.0$，模型 B：$\\hat{y}_i^{(B)} = 2.0 x_i + 1.0$，$R = 2000$，$s_{\\text{data}} = 12$，$s_{\\text{boot}} = 102$。\n- 案例 3（小样本，高噪声）：$n = 8$，$\\sigma = 0.8$，$a_{\\text{true}} = 1.0$，$b_{\\text{true}} = -0.5$，模型 A：$\\hat{y}_i^{(A)} = 1.0 x_i - 0.5$，模型 B：$\\hat{y}_i^{(B)} = 0.7 x_i - 0.4$，$R = 5000$，$s_{\\text{data}} = 13$，$s_{\\text{boot}} = 103$。\n- 案例 4（离群点敏感性）：$n = 64$，$\\sigma = 0.15$，$a_{\\text{true}} = 1.5$，$b_{\\text{true}} = 0.0$，模型 A：$\\hat{y}_i^{(A)} = \\mathrm{clip}(1.5 x_i, -1.5, 1.5)$，其中 $\\mathrm{clip}(u, \\ell, r)$ 将 $u$ 饱和到区间 $[\\ell,r]$ 内，模型 B：$\\hat{y}_i^{(B)} = 1.5 x_i$，$R = 3000$，$s_{\\text{data}} = 14$，$s_{\\text{boot}} = 104$。在此案例中，在为所有 i 生成 y_i 后，通过将 $y_1$（第一个样本，索引从 1 开始）替换为 $y_1 \\leftarrow y_1 + 30.0$ 来创建一个离群点。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 `[r_1,r_2,r_3,r_4]`），其中 $r_j$ 是案例 $j$ 的小数形式概率估计值，按上述案例的顺序排列，并四舍五入到四位小数。不应打印任何其他文本。", "solution": "这个问题的核心是通过模拟抽样可变性的影响，来估计一个模型（A）在均方误差方面优于另一个模型（B）的概率，即 $P(\\mathrm{MSE}_A  \\mathrm{MSE}_B)$。非参数自助法是用于此目的的一种强大且广泛使用的技术。它通过从观测数据集中重复进行有放回的重抽样，来近似一个统计量（本例中为 MSE）的抽样分布。这使我们能够量化我们性能估计中的不确定性，而无需对数据生成过程做出强参数假设。\n\n每个测试用例的步骤如下：\n\n1.  **数据生成**：\n    *   首先，我们建立一个可复现的随机过程。实例化两个独立的随机数生成器：一个用于数据生成，以 $s_{\\text{data}}$ 为种子；另一个用于自助法重抽样过程，以 $s_{\\text{boot}}$ 为种子。这种分离至关重要，以确保自助法过程的随机性独立于数据样本本身的随机性。\n    *   使用数据生成器，我们从均匀分布 $\\mathrm{Uniform}([-1, 1])$ 中抽取 $n$ 个自变量 $x_i$ 的样本。\n    *   然后，我们从正态分布 $\\mathcal{N}(0, \\sigma^2)$ 中生成 $n$ 个高斯噪声 $\\varepsilon_i$ 的样本。\n    *   接着根据真实线性模型构建因变量 $y_i$：$y_i = a_{\\text{true}} x_i + b_{\\text{true}} + \\varepsilon_i$。\n    *   对于案例 4，通过修改第一个数据点引入一个显著的离群点：$y_0 \\leftarrow y_0 + 30.0$（使用基于0的索引）。\n\n2.  **模型预测和单样本误差计算**：\n    *   对于已生成的固定 $x_i$ 值集合，我们根据各自的定义计算两个模型的预测值 $\\hat{y}_i^{(A)}$ 和 $\\hat{y}_i^{(B)}$。这些模型是 $x_i$ 的确定性函数。\n    *   然后计算每个模型的单样本平方误差，并将其存储在两个向量 $\\mathbf{e}^{(A)}$ 和 $\\mathbf{e}^{(B)}$ 中，其中第 $i$ 个元素是 $e_i^{(A)} = (y_i - \\hat{y}_i^{(A)})^2$ 和 $e_i^{(B)} = (y_i - \\hat{y}_i^{(B)})^2$。这项预计算是一项重要的优化；原始样本上的误差是固定的，我们将要重抽样的正是这些误差。\n\n3.  **自助法重抽样和 MSE 比较**：\n    *   我们执行一个循环，共进行 $R$ 次迭代，其中 $R$ 是自助法重复的次数。\n    *   在每次迭代 $k \\in \\{1, \\dots, R\\}$ 中：\n        a. 通过从 $\\{0, 1, \\dots, n-1\\}$ 中有放回地抽取 $n$ 个整数，创建一个索引的自助法样本。设这组索引为 $I_k$。\n        b. 通过取与 $I_k$ 中索引对应的预计算平方误差的平均值，来计算此自助法样本上每个模型的 MSE。\n        $$ \\mathrm{MSE}_A^{(k)} = \\frac{1}{n} \\sum_{j \\in I_k} e_j^{(A)} \\quad \\text{和} \\quad \\mathrm{MSE}_B^{(k)} = \\frac{1}{n} \\sum_{j \\in I_k} e_j^{(B)} $$\n        c. 然后我们比较这两个 MSE 值。如果满足严格不等式 $\\mathrm{MSE}_A^{(k)}  \\mathrm{MSE}_B^{(k)}$，则一个计数器加一。\n\n4.  **概率估计**：\n    *   完成所有 $R$ 次重复后，估计的概率 $P(\\mathrm{MSE}_A  \\mathrm{MSE}_B)$ 是模型 A “获胜”的总次数除以总重复次数 $R$。\n    *   最终结果按要求四舍五入到四位小数。\n\n对于模型 A 和模型 B 相同的情况（案例 2 和案例 4），它们对所有 i 的预测值 $\\hat{y}^{(A)}_i$ 和 $\\hat{y}^{(B)}_i$ 都是相同的。因此，它们的单样本平方误差 $e_i^{(A)}$ 和 $e_i^{(B)}$ 也相同。这意味着对于任何自助法重抽样样本，得到的 $\\mathrm{MSE}_A$ 和 $\\mathrm{MSE}_B$ 都将严格相等。条件 $\\mathrm{MSE}_A  \\mathrm{MSE}_B$ 永远不会被满足，估计的概率将恰好为 $0$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by running the bootstrap comparison for each specified test case.\n    \"\"\"\n    # Test suite specification:\n    # (n, sigma, a_true, b_true, model_A_spec, model_B_spec, R, s_data, s_boot, outlier_spec)\n    # model_spec is a tuple: ('type', params_dict)\n    # outlier_spec is a tuple: (index_1_based, value_to_add) or None\n    test_cases = [\n        # Case 1 (general case)\n        (128, 0.2, 2.0, 1.0, ('linear', {'a': 2.0, 'b': 1.0}), ('linear', {'a': 1.7, 'b': 1.1}), 2000, 11, 101, None),\n        # Case 2 (tie boundary)\n        (128, 0.2, 2.0, 1.0, ('linear', {'a': 2.0, 'b': 1.0}), ('linear', {'a': 2.0, 'b': 1.0}), 2000, 12, 102, None),\n        # Case 3 (small sample, higher noise)\n        (8, 0.8, 1.0, -0.5, ('linear', {'a': 1.0, 'b': -0.5}), ('linear', {'a': 0.7, 'b': -0.4}), 5000, 13, 103, None),\n        # Case 4 (outlier sensitivity)\n        (64, 0.15, 1.5, 0.0, ('clip', {'a': 1.5, 'b': 0.0, 'lower': -1.5, 'upper': 1.5}), ('linear', {'a': 1.5, 'b': 0.0}), 3000, 14, 104, (1, 30.0))\n    ]\n\n    results = []\n    for case in test_cases:\n        n, sigma, a_true, b_true, model_A_spec, model_B_spec, R, s_data, s_boot, outlier_spec = case\n\n        # 1. Data Generation\n        rng_data = np.random.default_rng(s_data)\n        rng_boot = np.random.default_rng(s_boot)\n\n        x = rng_data.uniform(-1, 1, size=n)\n        noise = rng_data.normal(0, sigma, size=n)\n        y = a_true * x + b_true + noise\n\n        if outlier_spec:\n            idx, value = outlier_spec\n            y[idx - 1] += value  # Adjust for 0-based indexing\n\n        # 2. Model Prediction and Per-Sample Error Calculation\n        def get_predictions(spec, x_vals):\n            model_type, params = spec\n            if model_type == 'linear':\n                return params['a'] * x_vals + params['b']\n            elif model_type == 'clip':\n                return np.clip(params['a'] * x_vals + params['b'], params['lower'], params['upper'])\n            return None\n        \n        y_hat_A = get_predictions(model_A_spec, x)\n        y_hat_B = get_predictions(model_B_spec, x)\n\n        errors_A = (y - y_hat_A)**2\n        errors_B = (y - y_hat_B)**2\n\n        # 3. Bootstrap Resampling and MSE Comparison\n        win_count_A = 0\n        indices = np.arange(n)\n        for _ in range(R):\n            boot_indices = rng_boot.choice(indices, size=n, replace=True)\n            \n            mse_A = np.mean(errors_A[boot_indices])\n            mse_B = np.mean(errors_B[boot_indices])\n\n            if mse_A  mse_B:\n                win_count_A += 1\n\n        # 4. Probability Estimation\n        prob = win_count_A / R\n        results.append(round(prob, 4))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3168825"}]}