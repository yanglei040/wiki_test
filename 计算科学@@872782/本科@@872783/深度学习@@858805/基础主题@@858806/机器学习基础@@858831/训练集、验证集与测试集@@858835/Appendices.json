{"hands_on_practices": [{"introduction": "数据划分的核心原则是确保测试集完全独立，以提供对模型泛化能力的无偏估计。然而，信息泄露的途径可能非常微妙，甚至发生在数据预处理阶段。本练习将通过一个自然语言处理（NLP）中的具体案例，即子词（subword）分词，向您展示当分词器的词汇表在包含测试数据的整个语料库上学习时，会如何无意中“记住”测试集中的罕见短语，从而导致对模型性能的评估过于乐观。[@problem_id:3194860]", "problem": "要求您通过计算来演示，在朴素训练的情况下，一个数据依赖的子词词汇表如何导致测试集信息泄漏到模型中，以及冻结词汇表如何缓解这种效应。您将在自然语言处理（NLP）的背景下进行操作，其中文本被分词为由无监督算法（如字节对编码 BPE）学习到的子词单元。您将实现一个简化的 BPE 过程，并针对指定的测试用例计算一个对泄漏敏感的指标。\n\n基本前提与假设：\n- 分词被视为一个由拟合好的子词词汇表所导出的确定性预处理函数 $ \\tau $。当测试集不用于拟合影响学习模型的任何管道组件（包括 $ \\tau $）时，对训练集、验证集和测试集的数据划分是有效的。\n- 数据泄漏是指从测试集到训练管道的任何信息流动。在整个数据集（包括测试部分）上拟合的分词器违反了训练和测试之间的独立性假设，并可能降低测试集中罕见短语的表观复杂性（例如，分词长度）。\n- 字节对编码（BPE）是一种无监督过程，它从字符级分词开始，并重复合并整个语料库中最频繁的相邻分词对。经过 $M$ 次合并后，学习到的合并列表决定了如何通过按顺序重复应用学习到的合并规则来将任何输入字符串分割成子词。\n\n您的任务：\n1) 按如下方式实现一个简化的 BPE，不使用词尾符号，也不使用续行标记：\n   - 从分割为字符的单词开始。对于一个表示为带有整数频率的词的多重集的语料库，计算每个相邻符号对的频率，并按词频加权。\n   - 在每个合并步骤中，选择全局最频繁的相邻对，并将其在所有单词中合并为单个符号。通过选择字典序最小的符号对（作为字符串元组）来确定性地解决平局。重复 $M$ 步或直到没有剩余的词对。\n   - 要使用学习到的合并规则编码一个单词，从其字符序列开始，并按照学习到的顺序应用合并规则，贪婪地替换当前合并对的出现，直到没有更多出现为止，然后处理下一个合并规则。\n\n2) 两种模式：\n   - 泄漏模式：在来自训练句和测试句的组合词多重集上拟合 BPE 合并规则。\n   - 冻结模式：仅使用训练句拟合 BPE 合并规则，然后保持合并列表固定（即，不使用来自测试句的任何信息重新拟合或扩展它）。\n\n3) 对于下面的每个测试用例，为一组罕见的目​​标短语计算以下指标：\n   - 令 $T_{\\text{leaky}}$ 为泄漏模式下每个目标短语的平均分词数，令 $T_{\\text{frozen}}$ 为冻结模式下每个目标短语的平均分词数。定义泄漏增益为\n     $$ g \\;=\\; \\frac{T_{\\text{frozen}} - T_{\\text{leaky}}}{T_{\\text{frozen}}}. $$\n     将 $g$ 报告为四舍五入到 $3$ 位小数的小数。\n   - 定义指示变量 $I_{\\text{leaky}}$ 和 $I_{\\text{frozen}}$，如果在相应的模式下至少有一个目标短语被编码为单个分词，则其值等于 $1$，否则等于 $0$。\n\n4) 输出格式：\n   - 您的程序应生成单行输出，包含一个结果列表，每个测试用例一个结果，其中每个结果本身就是一个列表 $[g,I_{\\text{leaky}},I_{\\text{frozen}}]$，其中 $g$ 四舍五入到 $3$ 位小数，指示变量为整数 $0$ 或 $1$。\n   - 最终输出必须是以下形式的单行：\n     $$[[g_1,I_{\\text{leaky},1},I_{\\text{frozen},1}],[g_2,I_{\\text{leaky},2},I_{\\text{frozen},2}],\\ldots]$$\n     无任何额外文本。\n\n测试套件：\n根据句子模板和重复次数构建语料库。每个句子按空格分割成单词。对于每种情况，训练语料库是训练句重复 $r_{\\text{train}}$ 次，测试语料库是测试句重复 $r_{\\text{test}}$ 次。\n\n- 情况 A（正常路径：泄漏增加了对罕见测试短语的子词记忆）：\n  - 训练句：\"alpha beta gamma delta epsilon\"\n  - 测试句：\"quantumflux\"\n  - 重复次数：$r_{\\text{train}} = 5$, $r_{\\text{test}} = 20$\n  - 目标短语：[\"quantumflux\"]\n  - 合并次数：$M = 10$\n\n- 情况 B（边界情况：零次合并消除了泄漏效应）：\n  - 训练句：\"abc def\"\n  - 测试句：\"ghij\"\n  - 重复次数：$r_{\\text{train}} = 5$, $r_{\\text{test}} = 10$\n  - 目标短语：[\"ghij\"]\n  - 合并次数：$M = 0$\n\n- 情况 C（边缘情况：严重泄漏可将罕见的测试短语压缩为单个分词）：\n  - 训练句：\"alpha beta gamma\"\n  - 测试句：\"quantumflux\"\n  - 重复次数：$r_{\\text{train}} = 5$, $r_{\\text{test}} = 100$\n  - 目标短语：[\"quantumflux\"]\n  - 合并次数：$M = 12$\n\n答案规范：\n- 所有输出都是无量纲的，必须以小数或整数形式报告。不要使用百分号。\n- 您的程序应精确生成一行，其中包含一个列表，其元素是 A、B 和 C 三种情况的三元组 $[g,I_{\\text{leaky}},I_{\\text{frozen}}]$，按此顺序排列，$g$ 四舍五入到 $3$ 位小数，且打印的列表中没有空格。", "solution": "用户的要求是演示一种自然语言处理（NLP）管道中的数据泄漏形式，即在一个包含训练和测试数据的组合上拟合的分词器可以人为地提高测试集上的性能指标。这一现象将通过实现一个简化的字节对编码（BPE）算法，并比较其在两种不同模式下的行为来加以说明：一种是“泄漏”模式，其中 BPE 词汇表是从训练和测试语料库的组合中学习的；另一种是“冻结”模式，其中词汇表仅从训练语料库中学习。该问题在科学上是有效的、定义明确的，并且所有术语和过程的定义都足够严谨，可以进行计算求解。\n\n解决方案首先按规定实现必要的组件：\n1.  一个函数，用于根据输入句子和重复次数构建一个语料库，该语料库表示为词及其频率的多重集（或字典）。\n2.  一个 BPE 拟合函数 `fit_bpe`，用于学习子词合并的词汇表。\n3.  一个 BPE 编码函数 `encode_word`，用于在给定学习到的词汇表的情况下对单词进行分词。\n4.  一个主程序，用于处理每个测试用例的两种模式并计算所需的指标。\n\n**BPE 拟合过程 (`fit_bpe`)**\n\n`fit_bpe` 函数接收一个语料库（一个将词映射到其频率的字典）和合并次数 $M$ 作为输入。\n1.  **初始化**：语料库内部通过将其中的每个词分割成其构成字符来表示。例如，频率为 $5$ 的单词 \"alpha\" 最初表示为与频率 $5$ 相关联的分词序列 `('a', 'l', 'p', 'h', 'a')`。\n2.  **迭代合并**：算法迭代 $M$ 次或直到无法再进行合并。在每一步中：\n    a.  **词对频率计算**：计算整个语料库中所有相邻分词对的频率，并按它们出现的词的频率进行加权。\n    b.  **最佳词对选择**：识别出最频繁的词对。通过选择字典序最小的词对来解决平局问题，其中词对作为字符串元组进行比较（例如，`('a', 'b')` 在 `('a', 'c')` 之前）。\n    c.  **词汇表更新**：将最佳词对（例如 $(s_1, s_2)$）记录为新的合并规则。\n    d.  **语料库更新**：在分词后的语料库表示中，所有出现的相邻序列 `$s_1 s_2$` 都被替换为新的单个分词 `$s_1s_2$`。此更新后的表示用于下一次迭代。\n3.  **输出**：该函数返回一个包含 $M$ 个学习到的合并规则的有序列表。\n\n**BPE 编码过程 (`encode_word`)**\n\n`encode_word` 函数接收一个单词字符串和一个有序的合并规则列表，以生成一个子词分词序列。\n1.  **初始化**：输入单词首先被分割成一个字符序列。\n2.  **应用合并规则**：函数按照合并规则被学习的顺序进行迭代。对于每个规则 $(s_1, s_2)$：\n    a.  算法重复扫描当前分词序列，以查找相邻对 $(s_1, s_2)$ 的首次出现。\n    b.  找到出现后，它将被替换为合并后的分词 $s_1s_2$。然后从修改后的分词序列的开头重新开始扫描。\n    c.  这个过程一直持续到在序列中再也找不到 $(s_1, s_2)$ 对的出现为止。\n    d.  然后算法继续处理列表中的下一个合并规则。\n3.  **输出**：返回单词的最终分词序列。此序列的长度即为分词的数量。\n\n**指标计算**\n\n对于每个测试用例，都会对冻结模式和泄漏模式进行分析：\n-   **冻结模式**：仅使用训练语料库通过 `fit_bpe` 学习 BPE 合并规则。然后使用这些合并规则对目标短语进行编码，从而得出每个短语的平均分词数 $T_{\\text{frozen}}$。\n-   **泄漏模式**：从结合了训练和测试数据的语料库中学习 BPE 合并规则。使用这些合并规则对目标短语进行编码，得出平均分词数 $T_{\\text{leaky}}$。\n\n然后计算泄漏增益 $g$ 为 $g = (T_{\\text{frozen}} - T_{\\text{leaky}}) / T_{\\text{frozen}}$。$g$ 的正值表明，在分词器拟合过程中包含测试数据，导致目标短语的分词结果更压缩（更短），这是信息泄漏的直接后果。如果任何目标短语在相应模式下被分词为单个分词，则指示变量 $I_{\\text{leaky}}$ 和 $I_{\\text{frozen}}$ 设置为 $1$，否则为 $0$。这捕捉了极端泄漏的情况，即一个罕见词被作为单个单元记在词汇表中。\n\n然后，将所有测试用例的结果汇总并格式化为指定的列表的列表结构。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\ndef get_pair_freqs(word_segs: dict[str, int]) - collections.Counter:\n    \"\"\"\n    Calculates the frequency of adjacent token pairs in a segmented corpus representation.\n    The corpus representation is a dictionary mapping a space-separated token string to its frequency.\n    \"\"\"\n    pair_freqs = collections.Counter()\n    for seg_word, freq in word_segs.items():\n        tokens = seg_word.split(' ')\n        if len(tokens)  2:\n            continue\n        for i in range(len(tokens) - 1):\n            pair = (tokens[i], tokens[i+1])\n            pair_freqs[pair] += freq\n    return pair_freqs\n\ndef fit_bpe(corpus: dict[str, int], M: int) - list[tuple[str, str]]:\n    \"\"\"\n    Fits a simplified BPE model by learning M merge operations from a corpus.\n    \n    Args:\n        corpus: A dictionary mapping words to their frequencies.\n        M: The number of merges to perform.\n\n    Returns:\n        An ordered list of M merge rules, where each rule is a tuple of strings.\n    \"\"\"\n    if M == 0:\n        return []\n    \n    # Initialize the corpus representation with character-level tokenization.\n    word_segs = {' '.join(word): freq for word, freq in corpus.items() if word}\n    \n    merges = []\n    for _ in range(M):\n        pair_freqs = get_pair_freqs(word_segs)\n        if not pair_freqs:\n            break\n        \n        # Find the best pair: highest frequency, with lexicographical tie-breaking.\n        max_freq = max(pair_freqs.values())\n        # Filter pairs with max frequency and sort them to find the lexicographically smallest.\n        candidate_pairs = sorted([p for p, f in pair_freqs.items() if f == max_freq])\n        best_pair = candidate_pairs[0]\n        \n        merges.append(best_pair)\n        \n        # Apply the merge to the entire corpus representation for the next iteration.\n        p1, p2 = best_pair\n        merged_token = p1 + p2\n        \n        new_word_segs = {}\n        for seg_word, freq in word_segs.items():\n            # Using string replacement on the space-separated representation.\n            new_seg_word = seg_word.replace(f'{p1} {p2}', merged_token)\n            new_word_segs[new_seg_word] = freq\n        word_segs = new_word_segs\n        \n    return merges\n\ndef encode_word(word: str, merges: list[tuple[str, str]]) - list[str]:\n    \"\"\"\n    Encodes a word into subword tokens using a pre-computed list of BPE merges.\n    \n    Args:\n        word: The string to encode.\n        merges: An ordered list of BPE merge rules.\n\n    Returns:\n        A list of subword tokens.\n    \"\"\"\n    if not word:\n        return []\n        \n    tokens = list(word)\n    \n    for p1, p2 in merges:\n        merged_token = p1 + p2\n        while True:\n            # Repeatedly find the first occurrence of the pair and merge it.\n            # The scan restarts after each merge until no more merges for this rule are possible.\n            first_occurrence_idx = -1\n            for i in range(len(tokens) - 1):\n                if tokens[i] == p1 and tokens[i+1] == p2:\n                    first_occurrence_idx = i\n                    break\n            \n            if first_occurrence_idx != -1:\n                i = first_occurrence_idx\n                tokens = tokens[:i] + [merged_token] + tokens[i+2:]\n            else:\n                break # No more occurrences of this pair, move to the next merge rule.\n    return tokens\n\ndef process_case(train_sent: str, test_sent: str, r_train: int, r_test: int, targets: list[str], M: int) - list:\n    \"\"\"\n    Processes a single test case, calculating metrics for leaky and frozen regimes.\n    \"\"\"\n    # Create corpora from sentence templates and repetitions\n    train_corpus = collections.Counter(train_sent.split(' '))\n    for word in list(train_corpus): train_corpus[word] *= r_train\n    \n    test_corpus = collections.Counter(test_sent.split(' '))\n    for word in list(test_corpus): test_corpus[word] *= r_test\n\n    # --- Frozen Regime ---\n    # Fit BPE on the training data only\n    frozen_merges = fit_bpe(dict(train_corpus), M)\n    # Encode target phrases and calculate metrics\n    frozen_token_counts = [len(encode_word(phrase, frozen_merges)) for phrase in targets]\n    T_frozen = np.mean(frozen_token_counts)\n    I_frozen = 1 if any(c == 1 for c in frozen_token_counts) else 0\n\n    # --- Leaky Regime ---\n    # Fit BPE on the combined training and test data\n    combined_corpus = train_corpus + test_corpus\n    leaky_merges = fit_bpe(dict(combined_corpus), M)\n    # Encode target phrases and calculate metrics\n    leaky_token_counts = [len(encode_word(phrase, leaky_merges)) for phrase in targets]\n    T_leaky = np.mean(leaky_token_counts)\n    I_leaky = 1 if any(c == 1 for c in leaky_token_counts) else 0\n\n    # Calculate final leakage gain metric\n    if T_frozen == 0:\n        g = 0.0 # Avoid division by zero\n    else:\n        g = (T_frozen - T_leaky) / T_frozen\n\n    return [g, I_leaky, I_frozen]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"train_sent\": \"alpha beta gamma delta epsilon\", \"test_sent\": \"quantumflux\",\n            \"r_train\": 5, \"r_test\": 20, \"targets\": [\"quantumflux\"], \"M\": 10\n        },\n        {\n            \"train_sent\": \"abc def\", \"test_sent\": \"ghij\",\n            \"r_train\": 5, \"r_test\": 10, \"targets\": [\"ghij\"], \"M\": 0\n        },\n        {\n            \"train_sent\": \"alpha beta gamma\", \"test_sent\": \"quantumflux\",\n            \"r_train\": 5, \"r_test\": 100, \"targets\": [\"quantumflux\"], \"M\": 12\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        # Main logic to calculate the result for one case goes here.\n        g, i_leaky, i_frozen = process_case(**case)\n        \n        # Format the result as a string '[g,I_leaky,I_frozen]' with no spaces.\n        # g is rounded to 3 decimal places implicitly by the format specifier.\n        result_str = f\"[{g:.3f},{i_leaky},{i_frozen}]\"\n        results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3194860"}, {"introduction": "在确保数据集划分的“洁净”之后，下一个挑战是如何最有效地利用验证集来指导训练过程。在现实世界中，计算资源是有限的，这意味着我们必须在更长的训练时间和更频繁的验证之间做出权衡。本练习模拟了这一经典场景，要求您在一个固定的计算预算下，通过数学建模来确定最佳的验证频率，以最小化由于过早停止（early stopping）策略的离散性而导致的预期测试风险。[@problem_id:3194810]", "problem": "一个团队使用随机梯度下降 (SGD) 在固定的训练数据集上训练一个深度神经网络，并使用一个独立的验证数据集通过提前停止来选择最终的检查点。假设训练步骤 $s$ 的预期测试风险由一条学习曲线建模，该曲线在最优停止点 $S^{\\star}$ 之前严格递减，之后因过拟合而严格递增。具体来说，假设在 $s=S^{\\star}$ 时达到最小预期测试风险 $R_{\\min}$，并且对于 $s>S^{\\star}$，每增加一个训练步骤，预期测试风险近似线性增加，斜率为 $\\lambda$；而对于$s  S^{\\star}$，预期测试风险以斜率$-\\lambda$近似线性增加（即，风险随着步骤数增加而减小）。由于验证是离散进行的，每 $k$ 个训练步骤执行一次，因此提前停止总是在已验证的某个检查点处发生。假设最优停止点 $S^{\\star}$ 相对于其周围的两个已验证检查点的位置是均匀随机的，那么 $S^{\\star}$ 与最近的已验证检查点之间的预期差异为 $k/2$。因此，由于离散验证而导致的预期额外测试风险约为 $\\lambda \\cdot (k/2)$。\n\n一个训练步骤的成本为 $c_t$ 个计算单位，而一次完整验证的成本为 $c_v$ 个计算单位。团队的总计算预算为 $B$ 个计算单位，且他们必须训练至少 $S^{\\star}$ 步以达到过拟合区域。总成本是训练成本与验证成本之和，即 $c_{t}N + c_{v}\\cdot(N/k)$，其中 $N$ 是总训练步数。\n\n您的任务是找到最优的验证间隔 $k^{\\star}$，以最小化预期额外测试风险，同时满足预算约束 $c_{t}N + c_{v}\\cdot(N/k) \\leq B$ 和训练完成约束 $N \\geq S^{\\star}$。\n\n参数：\n-   $S^{\\star} = 6.0 \\times 10^{5}$ 步\n-   $B = 8.0 \\times 10^{5}$ 步等效单位\n-   $c_t = 1$ 步等效单位/每训练步\n-   $c_v = 1.5224 \\times 10^{3}$ 步等效单位/每次验证\n-   $\\lambda = 1.0 \\times 10^{-6}$ 风险单位/每步\n\n将您的答案 $k^{\\star}$ 四舍五入到四位有效数字。", "solution": "该问题要求推导在固定计算预算下最小化预期测试风险的最优验证间隔 $k^{\\star}$。解题过程首先对问题陈述进行形式化验证。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n\n从问题陈述中逐字提取已知条件：\n-   预期测试风险在训练步骤 $s=S^{\\star}$ 处有唯一最小值 $R_{\\min}$。\n-   对于 $s  S^{\\star}$，预期测试风险以斜率 $\\lambda$ 近似线性增加。\n-   每 $k$ 个训练步骤执行一次验证。\n-   $S^{\\star}$ 与最近的已验证检查点之间的预期差异为 $k/2$。\n-   预期额外测试风险约为 $\\lambda \\cdot (k/2)$。\n-   一个训练步骤的成本为 $c_{t}$。\n-   一次完整验证的成本为 $c_{v}$。\n-   总训练步数为 $N$。\n-   总计算预算为 $B$。\n-   总成本为 $c_{t}N + c_{v}\\cdot(N/k)$。\n-   预算约束：$c_{t}N + c_{v}\\cdot(N/k) \\leq B$。\n-   训练完成约束：$N \\geq S^{\\star}$。\n-   参数：\n    -   $S^{\\star} = 6.0 \\times 10^{5}$ 步\n    -   $B = 8.0 \\times 10^{5}$ 步等效单位\n    -   $c_{t} = 1$ 步等效单位/每训练步\n    -   $c_{v} = 1.5224 \\times 10^{3}$ 步等效单位/每次验证\n    -   $\\lambda = 1.0 \\times 10^{-6}$ 风险单位/每步\n\n**步骤 2：使用提取的已知条件进行验证**\n\n根据指定标准对问题进行评估：\n-   **科学依据**：该问题基于机器学习中已确立的概念，包括提前停止、过拟合和计算预算管理。学习曲线的模型（U形）和最优后风险增加的线性近似是标准的简化假设。训练和验证的成本模型也是一个标准公式。预期步数差异为 $k/2$ 的明确前提是问题陈述中提供的一个特定建模选择；它没有违反任何基本原则，并定义了必须在其中执行优化的上下文。\n-   **适定性**：该问题是一个适定的优化任务。它要求在一个代数不等式约束集下最小化一个明确定义的目标函数（与 $k$ 成正比）。所有必要的参数都已提供，以找到唯一解。\n-   **客观性**：问题以精确、定量和无偏见的语言陈述。\n\n发现该问题没有科学上的不健全性、模糊性和内部矛盾。它提出了一个可解的、自洽的优化问题。\n\n**步骤 3：结论与行动**\n\n问题被判定为**有效**。将提供完整的解决方案。\n\n### 解题推导\n\n目标是最小化预期额外测试风险，该风险是验证间隔 $k$ 的函数：\n$$\nR_{\\text{excess}}(k) = \\frac{\\lambda k}{2}\n$$\n由于斜率 $\\lambda$ 是一个正常数，最小化 $R_{\\text{excess}}(k)$ 等同于最小化验证间隔 $k$。我们的目标是找到满足所有约束的 $k$ 的最小可能值。\n\n约束条件是：\n1.  总计算成本不得超过预算 $B$。训练 $N$ 步并验证 $\\frac{N}{k}$ 次的成本为：\n    $$\n    C(N, k) = c_{t}N + c_{v}\\frac{N}{k}\n    $$\n    因此，预算约束为：\n    $$\n    N \\left(c_{t} + \\frac{c_{v}}{k}\\right) \\leq B\n    $$\n2.  总训练步数 $N$ 必须至少为最优停止点 $S^{\\star}$：\n    $$\n    N \\geq S^{\\star}\n    $$\n\n从预算约束中，我们可以表示出 $N$ 的一个上界：\n$$\nN \\leq \\frac{B}{c_{t} + \\frac{c_{v}}{k}}\n$$\n将其与训练时长约束相结合，我们得到：\n$$\nS^{\\star} \\leq N \\leq \\frac{B}{c_{t} + \\frac{c_{v}}{k}}\n$$\n对于给定的 $k$，要使 $N$ 存在可行解， $N$ 的下界必须小于或等于上界：\n$$\nS^{\\star} \\leq \\frac{B}{c_{t} + \\frac{c_{v}}{k}}\n$$\n这个不等式建立了验证间隔 $k$ 与问题的固定参数之间的关系。我们必须重新整理这个不等式以找到对 $k$ 的约束。\n$$\nS^{\\star} \\left(c_{t} + \\frac{c_{v}}{k}\\right) \\leq B\n$$\n$$\nS^{\\star}c_{t} + \\frac{S^{\\star}c_{v}}{k} \\leq B\n$$\n$$\n\\frac{S^{\\star}c_{v}}{k} \\leq B - S^{\\star}c_{t}\n$$\n在继续之前，我们验证项 $B - S^{\\star}c_{t}$ 是否为正。使用给定值：\n$$\nB - S^{\\star}c_{t} = (8.0 \\times 10^{5}) - (6.0 \\times 10^{5})(1) = 2.0 \\times 10^{5} > 0\n$$\n由于右侧为正，我们可以安全地反转不等式（注意 $k > 0$）：\n$$\nk \\geq \\frac{S^{\\star}c_{v}}{B - S^{\\star}c_{t}}\n$$\n这个不等式为验证间隔 $k$ 提供了一个下界。由于我们的目标是最小化 $k$，最优值 $k^{\\star}$ 将是这个最小可能值：\n$$\nk^{\\star} = \\frac{S^{\\star}c_{v}}{B - S^{\\star}c_{t}}\n$$\n这个最优值 $k^{\\star}$ 对应于以最小要求时长 $N=S^{\\star}$ 进行训练，并将全部剩余预算用于验证的策略。\n\n现在我们代入给定的数值来计算 $k^{\\star}$：\n-   $S^{\\star} = 6.0 \\times 10^{5}$\n-   $B = 8.0 \\times 10^{5}$\n-   $c_{t} = 1$\n-   $c_{v} = 1.5224 \\times 10^{3}$\n\n$$\nk^{\\star} = \\frac{(6.0 \\times 10^{5}) \\cdot (1.5224 \\times 10^{3})}{8.0 \\times 10^{5} - (1) \\cdot (6.0 \\times 10^{5})}\n$$\n$$\nk^{\\star} = \\frac{9.1344 \\times 10^{8}}{2.0 \\times 10^{5}}\n$$\n$$\nk^{\\star} = 4.5672 \\times 10^{3} = 4567.2\n$$\n问题要求将答案四舍五入到四位有效数字。$4567.2$ 的前四位有效数字是 $4$、$5$、$6$ 和 $7$。第五位数字是 $2$，小于 $5$，因此我们向下取整。\n$$\nk^{\\star} \\approx 4567\n$$\n最优验证间隔是 $4567$ 步。", "answer": "$$\n\\boxed{4567}\n$$", "id": "3194810"}, {"introduction": "模型的输出（例如，分类概率）本身并不是最终决策，如何将这些概率转化为最优的行动，对于模型的实际应用至关重要。在许多应用场景中，不同类型的错误（如假阳性和假阴性）会带来截然不同的代价。本练习将指导您如何使用验证集来选择一个最佳决策阈值，以最小化与特定业务成本相关的经验风险，并探讨当验证和测试阶段的成本结构不一致时该如何做出更稳健的决策。[@problem_id:3194809]", "problem": "给定一个二元分类器，它在一个验证数据集和一个测试数据集上为正类输出经过校准的后验概率。目标是在验证数据集上选择一个决策阈值，以在给定的验证成本下最小化经验期望成本，分析当测试成本不同时出现的不匹配情况，并使用最小最大准则构建一个能够对冲测试成本比率不确定性的鲁棒阈值。\n\n基本原理：使用标准的经验风险（期望成本）框架和贝叶斯决策规则。对于一个概率为 $p$ 的实例，如果 $p \\ge t$，则其预测为正，否则为负。在一个大小为 $n$ 的数据集 $D$ 上，给定假阳性成本 $C_{\\mathrm{FP}}$ 和假阴性成本 $C_{\\mathrm{FN}}$，经验期望成本由假阳性率和假阴性率构建。设 $\\hat{y}_i(t)$ 表示在阈值为 $t$ 时对第 $i$ 个实例的预测，该实例的标签为 $y_i \\in \\{0,1\\}$，预测概率为 $p_i$。定义经验假阳性率为\n$$\n\\mathrm{FP\\_rate}(t) = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{1}\\big(\\hat{y}_i(t)=1, y_i=0\\big),\n$$\n定义经验假阴性率为\n$$\n\\mathrm{FN\\_rate}(t) = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{1}\\big(\\hat{y}_i(t)=0, y_i=1\\big).\n$$\n经验期望成本为\n$$\nR_D(t; C_{\\mathrm{FP}}, C_{\\mathrm{FN}}) = C_{\\mathrm{FP}} \\cdot \\mathrm{FP\\_rate}(t) + C_{\\mathrm{FN}} \\cdot \\mathrm{FN\\_rate}(t).\n$$\n从这些定义出发，您的程序必须：\n- 通过在 $t$ 上最小化 $R_{\\mathrm{val}}(t; C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}})$ 来选择一个验证最优阈值。\n- 纯粹从 $C_{\\mathrm{FP}}$ 和 $C_{\\mathrm{FN}}$ 推导出贝叶斯决策阈值，而不使用数据驱动的计数。\n- 当使用验证集上选择的阈值时，评估其在测试数据集上的经验期望成本，并与最小化 $R_{\\mathrm{test}}(t; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}})$ 的测试最优阈值进行比较。\n- 在测试成本比率不确定的情况下构建一个鲁棒阈值。假设测试成本不确定，但经过归一化以满足 $C_{\\mathrm{FP}} + C_{\\mathrm{FN}} = 1$，其中 $C_{\\mathrm{FP}} \\in [r_{\\min}, r_{\\max}]$ 且 $C_{\\mathrm{FN}} = 1 - C_{\\mathrm{FP}}$。选择 $t$ 以最小化验证数据集上的最坏情况经验期望成本：\n$$\nt_{\\mathrm{robust}} = \\arg\\min_t \\ \\sup_{r \\in [r_{\\min}, r_{\\max}]} \\left( r \\cdot \\mathrm{FP\\_rate}(t) + (1-r) \\cdot \\mathrm{FN\\_rate}(t) \\right).\n$$\n\n算法约束：\n- 必须选择阈值搜索空间，以确保经验成本被精确最小化。使用由数据集上观察到的已排序的唯一概率值，以及 $0$ 和 $1+\\varepsilon$（其中 $\\varepsilon$ 为一个小的正数）组成的候选阈值集合，确保覆盖所有分类区间。使用决策规则 $\\hat{y}=1$ 如果 $p \\ge t$，否则 $\\hat{y}=0$。如果出现平局（多个阈值产生相同的最小经验期望成本），选择最小的阈值。\n- 贝叶斯决策阈值必须从第一性原理推导，并仅表示为 $C_{\\mathrm{FP}}$ 和 $C_{\\mathrm{FN}}$ 的函数。\n\n测试套件：\n对于以下每个参数集，您的程序必须计算：\n- 最小化 $R_{\\mathrm{val}}(t; C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}})$ 的验证最优阈值 $t_{\\mathrm{val}}$。\n- 从 $C_{\\mathrm{FP}}^{\\mathrm{val}}$ 和 $C_{\\mathrm{FN}}^{\\mathrm{val}}$ 推导出的贝叶斯阈值 $t_{\\mathrm{Bayes}}$。\n- 最小化 $R_{\\mathrm{test}}(t; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}})$ 的测试最优阈值 $t_{\\mathrm{test}}$。\n- 在 $r \\in [r_{\\min}, r_{\\max}]$ 范围内，当 $C_{\\mathrm{FP}}=r$ 和 $C_{\\mathrm{FN}}=1-r$ 时，最小化最坏情况验证成本的鲁棒阈值 $t_{\\mathrm{robust}}$。\n- 经验期望测试成本的差异 $\\Delta_{\\mathrm{test}} = R_{\\mathrm{test}}(t_{\\mathrm{val}}; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) - R_{\\mathrm{test}}(t_{\\mathrm{test}}; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}})$。\n\n参数集：\n- 情况1（平衡，中度不匹配）：\n    - 验证概率 $[0.05, 0.10, 0.15, 0.20, 0.30, 0.40, 0.60, 0.70, 0.80, 0.90]$ 和标签 $[0, 0, 0, 0, 0, 0, 1, 1, 1, 1]$。\n    - 测试概率 $[0.02, 0.12, 0.18, 0.25, 0.35, 0.45, 0.55, 0.68, 0.78, 0.88]$ 和标签 $[0, 0, 0, 0, 0, 0, 1, 1, 1, 1]$。\n    - 验证成本 $(C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}}) = (1, 2)$。\n    - 测试成本 $(C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) = (2, 1)$。\n    - 鲁棒比率区间 $[r_{\\min}, r_{\\max}] = [0.3, 0.7]$。\n- 情况2（高度不平衡，高假阴性测试成本）：\n    - 验证概率 $[0.05, 0.07, 0.09, 0.12, 0.18, 0.22, 0.27, 0.35, 0.42, 0.50, 0.62, 0.75]$ 和标签 $[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]$。\n    - 测试概率 $[0.03, 0.08, 0.10, 0.13, 0.19, 0.25, 0.28, 0.33, 0.41, 0.52, 0.60, 0.78]$ 和标签 $[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1]$。\n    - 验证成本 $(C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}}) = (1, 5)$。\n    - 测试成本 $(C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) = (1, 10)$。\n    - 鲁棒比率区间 $[r_{\\min}, r_{\\max}] = [0.1, 0.4]$。\n- 情况3（近乎完美分离，成本相等）：\n    - 验证概率 $[0.01, 0.02, 0.05, 0.95, 0.97, 0.99]$ 和标签 $[0, 0, 0, 1, 1, 1]$。\n    - 测试概率 $[0.02, 0.03, 0.06, 0.94, 0.96, 0.98]$ 和标签 $[0, 0, 0, 1, 1, 1]$。\n    - 验证成本 $(C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}}) = (1, 1)$。\n    - 测试成本 $(C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) = (1, 1)$。\n    - 鲁棒比率区间 $[r_{\\min}, r_{\\max}] = [0.5, 0.5]$。\n- 情况4（退化的相同概率，冲突的成本）：\n    - 验证概率 $[0.5, 0.5, 0.5, 0.5, 0.5, 0.5]$ 和标签 $[0, 0, 1, 1, 0, 1]$。\n    - 测试概率 $[0.5, 0.5, 0.5, 0.5, 0.5, 0.5]$ 和标签 $[0, 0, 1, 1, 0, 1]$。\n    - 验证成本 $(C_{\\mathrm{FP}}^{\\mathrm{val}}, C_{\\mathrm{FN}}^{\\mathrm{val}}) = (3, 1)$。\n    - 测试成本 $(C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) = (1, 3)$。\n    - 鲁棒比率区间 $[r_{\\min}, r_{\\max}] = [0.2, 0.8]$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个元素对应一个案例，并且本身必须是包含五个十进制数的列表，顺序为 $[t_{\\mathrm{val}},t_{\\mathrm{Bayes}},t_{\\mathrm{test}},t_{\\mathrm{robust}},\\Delta_{\\mathrm{test}}]$。例如，两个案例的有效输出行将类似于 $[[0.333333,0.333333,0.666667,0.500000,0.050000],[\\dots]]$，不包含任何附加文本。角度和物理单位不适用；所有输出都是无量纲的实数。", "solution": "该问题要求对二元分类器的决策阈值进行多方面的分析。我们必须在不同准则下确定最优阈值，并评估验证集和测试集之间的性能不匹配情况。解决方案将基于统计决策理论和经验风险最小化的原则系统地构建。\n\n### 步骤1：理论基础\n\n让我们首先对问题的各个组成部分进行形式化定义。\n\n**1.1. 经验风险（期望成本）**\n二元分类器为每个具有特征 $\\mathbf{x}_i$ 的实例 $i$ 分配一个后验概率 $p_i = P(Y=1 | \\mathbf{x}_i)$。决策阈值 $t$ 用于做出最终预测 $\\hat{y}_i(t) \\in \\{0, 1\\}$。决策规则如下：\n$$\n\\hat{y}_i(t) =\n\\begin{cases}\n1  \\text{if } p_i \\ge t \\\\\n0  \\text{if } p_i  t\n\\end{cases}\n$$\n问题将一个大小为 $n$ 的数据集 $D$ 上的经验假阳性和假阴性率定义为：\n$$\n\\mathrm{FP\\_rate}(t) = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{1}\\big(\\hat{y}_i(t)=1, y_i=0\\big) = \\frac{1}{n} \\left| \\{ i \\mid p_i \\ge t, y_i=0 \\} \\right|\n$$\n$$\n\\mathrm{FN\\_rate}(t) = \\frac{1}{n}\\sum_{i=1}^n \\mathbb{1}\\big(\\hat{y}_i(t)=0, y_i=1\\big) = \\frac{1}{n} \\left| \\{ i \\mid p_i  t, y_i=1 \\} \\right|\n$$\n这里，$\\mathbb{1}(\\cdot)$ 是指示函数。请注意，这些率是由总样本量 $n$ 归一化的，而不是由实际的负类或正类实例数量归一化。给定假阳性成本（$C_{\\mathrm{FP}}$）和假阴性成本（$C_{\\mathrm{FN}}$），经验期望成本（或风险）为：\n$$\nR_D(t; C_{\\mathrm{FP}}, C_{\\mathrm{FN}}) = C_{\\mathrm{FP}} \\cdot \\mathrm{FP\\_rate}(t) + C_{\\mathrm{FN}} \\cdot \\mathrm{FN\\_rate}(t)\n$$\n在验证集上通过最小化此风险来找到 $t$，即可得到验证最优阈值 $t_{\\mathrm{val}}$。在测试集上进行类似的最小化可得到测试最优阈值 $t_{\\mathrm{test}}$。\n\n**1.2. 贝叶斯决策阈值**\n贝叶斯决策规则最小化单个实例的期望成本。对于一个预测概率为 $p = P(Y=1)$ 的实例，预测为正（$\\hat{y}=1$）的期望成本是 $E[\\text{Cost}|\\hat{y}=1] = C_{\\mathrm{FP}} \\cdot (1-p)$。预测为负（$\\hat{y}=0$）的期望成本是 $E[\\text{Cost}|\\hat{y}=0] = C_{\\mathrm{FN}} \\cdot p$。最优决策是当 $E[\\text{Cost}|\\hat{y}=1] \\le E[\\text{Cost}|\\hat{y}=0]$ 时预测为正，这导致：\n$$\nC_{\\mathrm{FP}}(1-p) \\le C_{\\mathrm{FN}} p \\implies C_{\\mathrm{FP}} \\le (C_{\\mathrm{FP}} + C_{\\mathrm{FN}})p \\implies p \\ge \\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FP}} + C_{\\mathrm{FN}}}\n$$\n因此，假设分类器的输出 $p$ 是真实的后验概率，贝叶斯最优阈值为：\n$$\nt_{\\mathrm{Bayes}} = \\frac{C_{\\mathrm{FP}}}{C_{\\mathrm{FP}} + C_{\\mathrm{FN}}}\n$$\n这提供了一个纯粹从成本推导出的理论基准。\n\n**1.3. 鲁棒最小最大阈值**\n成本的不确定性可以使用最小最大方法来处理。在这里，测试集上的成本是未知的，但假定它们被归一化，使得 $C_{\\mathrm{FP}} + C_{\\mathrm{FN}} = 1$。不确定性由 $C_{\\mathrm{FP}} = r$ 在区间 $[r_{\\min}, r_{\\max}]$ 内变化来体现。目标是找到一个阈值 $t$，它能最小化验证数据上的最坏情况风险：\n$$\nt_{\\mathrm{robust}} = \\arg\\min_t \\left( \\sup_{r \\in [r_{\\min}, r_{\\max}]} R_{\\mathrm{val}}(t; r, 1-r) \\right)\n$$\n对于一个固定的阈值 $t$，风险 $R_{\\mathrm{val}}(t; r, 1-r) = r \\cdot \\mathrm{FP\\_rate}^{\\mathrm{val}}(t) + (1-r) \\cdot \\mathrm{FN\\_rate}^{\\mathrm{val}}(t)$ 是 $r$ 的线性函数。一个线性函数在闭区间 $[r_{\\min}, r_{\\max}]$ 上的上确界（最大值）必然在其中一个端点处取得。因此，对于给定的 $t$，最坏情况风险是：\n$$\n\\sup_{r \\in [r_{\\min}, r_{\\max}]} R_{\\mathrm{val}}(t; r, 1-r) = \\max \\left( R_{\\mathrm{val}}(t; r_{\\min}, 1-r_{\\min}), R_{\\mathrm{val}}(t; r_{\\max}, 1-r_{\\max}) \\right)\n$$\n然后，我们可以通过搜索最小化此最大值的阈值 $t$ 来找到 $t_{\\mathrm{robust}}$。\n\n### 步骤2：算法实现\n\n**2.1. 阈值候选与搜索**\n经验风险 $R_D(t)$ 是一个阶梯函数，其值仅在阈值 $t$ 等于数据集中的概率分数 $p_i$ 时发生变化。因此，为了精确找到最小值，只需在一组离散的候选阈值处评估成本。问题规定该集合为数据中出现的唯一概率分数，并增补 $t=0$ 和 $t > 1$（例如，$1+\\varepsilon$，将所有实例分类为负）。我们将使用 $\\{0.0\\} \\cup \\{p_i\\}_{\\text{unique}} \\cup \\{1.0+\\varepsilon\\}$。通过遍历这些排序后的候选值，我们可以找到最小成本。指定的平局决胜规则是选择产生最小成本的最小阈值。这可以通过遍历排序后的候选值并在找到严格更低的成本时才更新最佳阈值来实现。\n\n**2.2. 量值计算**\n1.  **$t_{\\mathrm{val}}$ 和 $t_{\\mathrm{test}}$**：我们将实现一个函数，该函数接收一个数据集（概率和标签）和成本（$C_{\\mathrm{FP}}$, $C_{\\mathrm{FN}}$），并执行2.1节中描述的搜索，通过最小化 $R_D(t)$ 来找到最优阈值。\n2.  **$t_{\\mathrm{Bayes}}$**：这直接使用公式 $t_{\\mathrm{Bayes}} = C_{\\mathrm{FP}}^{\\mathrm{val}} / (C_{\\mathrm{FP}}^{\\mathrm{val}} + C_{\\mathrm{FN}}^{\\mathrm{val}})$ 计算。\n3.  **$t_{\\mathrm{robust}}$**：我们将实现一个函数，该函数接收验证数据集和区间 $[r_{\\min}, r_{\\max}]$。对于每个候选阈值 $t$，它计算最坏情况风险作为在 $r_{\\min}$ 和 $r_{\\max}$ 处的风险的最大值，然后找到最小化此最坏情况风险的 $t$，并遵守平局决胜规则。\n4.  **$\\Delta_{\\mathrm{test}}$**：这是测试集上的性能差距。它的计算方式为 $\\Delta_{\\mathrm{test}} = R_{\\mathrm{test}}(t_{\\mathrm{val}}; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}}) - R_{\\mathrm{test}}(t_{\\mathrm{test}}; C_{\\mathrm{FP}}^{\\mathrm{test}}, C_{\\mathrm{FN}}^{\\mathrm{test}})$。我们首先找到 $t_{\\mathrm{val}}$ 和 $t_{\\mathrm{test}}$，然后在两个阈值下评估风险函数 $R_{\\mathrm{test}}$ 并计算差值。第二项 $R_{\\mathrm{test}}(t_{\\mathrm{test}}, \\dots)$ 根据定义是测试集上可能达到的最小经验风险。\n\n以下 Python 程序实现了这一逻辑，以解决给定的测试用例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: balanced, moderate mismatch\n        {\n            \"val_probs\": [0.05, 0.10, 0.15, 0.20, 0.30, 0.40, 0.60, 0.70, 0.80, 0.90],\n            \"val_labels\": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n            \"test_probs\": [0.02, 0.12, 0.18, 0.25, 0.35, 0.45, 0.55, 0.68, 0.78, 0.88],\n            \"test_labels\": [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n            \"val_costs\": (1, 2),\n            \"test_costs\": (2, 1),\n            \"robust_interval\": (0.3, 0.7),\n        },\n        # Case 2: highly imbalanced, heavy false negative test cost\n        {\n            \"val_probs\": [0.05, 0.07, 0.09, 0.12, 0.18, 0.22, 0.27, 0.35, 0.42, 0.50, 0.62, 0.75],\n            \"val_labels\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n            \"test_probs\": [0.03, 0.08, 0.10, 0.13, 0.19, 0.25, 0.28, 0.33, 0.41, 0.52, 0.60, 0.78],\n            \"test_labels\": [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1],\n            \"val_costs\": (1, 5),\n            \"test_costs\": (1, 10),\n            \"robust_interval\": (0.1, 0.4),\n        },\n        # Case 3: near-perfect separation, equal costs\n        {\n            \"val_probs\": [0.01, 0.02, 0.05, 0.95, 0.97, 0.99],\n            \"val_labels\": [0, 0, 0, 1, 1, 1],\n            \"test_probs\": [0.02, 0.03, 0.06, 0.94, 0.96, 0.98],\n            \"test_labels\": [0, 0, 0, 1, 1, 1],\n            \"val_costs\": (1, 1),\n            \"test_costs\": (1, 1),\n            \"robust_interval\": (0.5, 0.5),\n        },\n        # Case 4: degenerate identical probabilities, conflicting costs\n        {\n            \"val_probs\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n            \"val_labels\": [0, 0, 1, 1, 0, 1],\n            \"test_probs\": [0.5, 0.5, 0.5, 0.5, 0.5, 0.5],\n            \"test_labels\": [0, 0, 1, 1, 0, 1],\n            \"val_costs\": (3, 1),\n            \"test_costs\": (1, 3),\n            \"robust_interval\": (0.2, 0.8),\n        },\n    ]\n\n    results = []\n    \n    epsilon_threshold = np.nextafter(1.0, 2.0)\n\n    def calculate_cost(t, probs, labels, cfp, cfn):\n        \"\"\"Calculates the empirical expected cost for a given threshold.\"\"\"\n        n = len(labels)\n        if n == 0:\n            return 0.0\n        \n        predictions = (probs >= t).astype(int)\n        \n        fp_count = np.sum((predictions == 1)  (labels == 0))\n        fn_count = np.sum((predictions == 0)  (labels == 1))\n        \n        cost = (cfp * fp_count + cfn * fn_count) / n\n        return cost\n\n    def find_optimal_threshold(probs, labels, cfp, cfn):\n        \"\"\"Finds the threshold that minimizes empirical cost.\"\"\"\n        unique_probs = np.unique(probs)\n        candidate_thresholds = np.concatenate(([0.0], unique_probs, [epsilon_threshold]))\n        \n        min_cost = float('inf')\n        best_t = -1.0\n        \n        for t in sorted(candidate_thresholds):\n            cost = calculate_cost(t, probs, labels, cfp, cfn)\n            if cost  min_cost:\n                min_cost = cost\n                best_t = t\n                \n        return best_t, min_cost\n\n    def find_robust_threshold(probs, labels, r_min, r_max):\n        \"\"\"Finds the threshold that minimizes the worst-case empirical cost.\"\"\"\n        n = len(labels)\n        if n == 0:\n            return -1.0\n            \n        unique_probs = np.unique(probs)\n        candidate_thresholds = np.concatenate(([0.0], unique_probs, [epsilon_threshold]))\n        \n        min_worst_case_cost = float('inf')\n        best_t = -1.0\n        \n        for t in sorted(candidate_thresholds):\n            predictions = (probs >= t).astype(int)\n            fp_count = np.sum((predictions == 1)  (labels == 0))\n            fn_count = np.sum((predictions == 0)  (labels == 1))\n            \n            fp_rate = fp_count / n\n            fn_rate = fn_count / n\n            \n            cost_at_rmin = r_min * fp_rate + (1 - r_min) * fn_rate\n            cost_at_rmax = r_max * fp_rate + (1 - r_max) * fn_rate\n            \n            worst_case_cost = max(cost_at_rmin, cost_at_rmax)\n            \n            if worst_case_cost  min_worst_case_cost:\n                min_worst_case_cost = worst_case_cost\n                best_t = t\n                \n        return best_t\n\n    for case in test_cases:\n        val_probs = np.array(case[\"val_probs\"])\n        val_labels = np.array(case[\"val_labels\"])\n        test_probs = np.array(case[\"test_probs\"])\n        test_labels = np.array(case[\"test_labels\"])\n        cfp_val, cfn_val = case[\"val_costs\"]\n        cfp_test, cfn_test = case[\"test_costs\"]\n        r_min, r_max = case[\"robust_interval\"]\n\n        # Calculate t_val\n        t_val, _ = find_optimal_threshold(val_probs, val_labels, cfp_val, cfn_val)\n\n        # Calculate t_bayes\n        t_bayes = cfp_val / (cfp_val + cfn_val)\n\n        # Calculate t_test and min_test_cost\n        t_test, min_test_cost = find_optimal_threshold(test_probs, test_labels, cfp_test, cfn_test)\n\n        # Calculate t_robust\n        t_robust = find_robust_threshold(val_probs, val_labels, r_min, r_max)\n\n        # Calculate Delta_test\n        cost_at_t_val_on_test = calculate_cost(t_val, test_probs, test_labels, cfp_test, cfn_test)\n        delta_test = cost_at_t_val_on_test - min_test_cost\n\n        case_results = [t_val, t_bayes, t_test, t_robust, delta_test]\n        results.append(case_results)\n\n    # Format output as specified\n    final_output_list = []\n    for res in results:\n        # The problem example has 6 decimal places. Let's adhere to that for consistency.\n        formatted_res = f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f},{res[3]:.6f},{res[4]:.6f}]\"\n        final_output_list.append(formatted_res)\n    print(f\"[{','.join(final_output_list)}]\")\n\nsolve()\n```", "id": "3194809"}]}