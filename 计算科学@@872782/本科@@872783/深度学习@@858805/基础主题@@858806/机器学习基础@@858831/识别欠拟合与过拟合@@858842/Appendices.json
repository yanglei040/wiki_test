{"hands_on_practices": [{"introduction": "多项式回归是探索偏差-方差权衡的经典沙盒，因为我们可以通过改变多项式的阶数来精确地控制模型容量。本练习将指导您不仅直观地识别欠拟合与过拟合，而且还使用均方误差（MSE）以及一种新颖的残差频域分析方法来量化它们，从而学会检测高阶模型产生的振荡。通过这个实践，您将从根本上理解模型容量、正则化和泛化能力之间的动态关系[@problem_id:3135788]。", "problem": "给定一个一维回归的监督学习场景，该场景根据经验风险最小化（ERM）进行建模。设输入为 $x \\in [-1,1]$，真实目标函数为一个已知阶数 $d^\\star$ 的多项式，并受到零均值、方差为 $\\sigma^2$ 的高斯噪声污染。具体来说，数据通过 $y = f^\\star(x) + \\varepsilon$ 生成，其中 $f^\\star(x) = \\sum_{k=0}^{d^\\star} a_k x^k$，$d^\\star = 4$，系数为 $a_0 = 0.3$，$a_1 = -0.8$，$a_2 = 0.5$，$a_3 = 0.0$，$a_4 = 0.7$，噪声为 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$，且 $\\sigma = 0.1$（因此 $\\sigma^2 = 0.01$）。数据集大小为 $N = 200$ 个点，其输入 $x$ 从 $[-1,1]$ 区间内均匀抽取。使用 $N_{\\text{train}} = 120$ 个样本进行训练，使用 $N_{\\text{valid}} = 80$ 个样本进行验证。使用固定的随机种子 $42$ 来确保可复现性。\n\n您的任务是实现带岭正则化（也称为 $\\ell_2$ 正则化）的多项式回归。对于选定的模型阶数 $d$ 和正则化强度 $\\lambda \\ge 0$，构建设计矩阵 $\\Phi \\in \\mathbb{R}^{m \\times (d+1)}$，其元素为 $\\Phi_{i,k} = x_i^k$。给定训练数据 $(\\Phi_{\\text{train}}, y_{\\text{train}})$，使用以下闭式解计算岭估计器的系数 $w \\in \\mathbb{R}^{d+1}$\n$$\nw = \\left(\\Phi_{\\text{train}}^\\top \\Phi_{\\text{train}} + \\lambda I\\right)^{-1} \\Phi_{\\text{train}}^\\top y_{\\text{train}},\n$$\n其中 $I$ 是 $(d+1) \\times (d+1)$ 的单位矩阵。使用该估计器在训练集和验证集上进行预测，并计算残差 $r_{\\text{train}} = y_{\\text{train}} - \\hat{y}_{\\text{train}}$ 和 $r_{\\text{valid}} = y_{\\text{valid}} - \\hat{y}_{\\text{valid}}$。\n\n根据第一性原理，使用以下定义和度量来识别欠拟合和过拟合：\n\n- 均方误差 (MSE) 定义为 $ \\text{MSE} = \\frac{1}{m} \\sum_{i=1}^m (y_i - \\hat{y}_i)^2 $。令 $\\text{MSE}_{\\text{train}}$ 和 $\\text{MSE}_{\\text{valid}}$ 分别表示训练和验证均方误差。\n- 残差中的振荡在频域中进行量化。计算按相应输入 $x$ 升序排序的验证残差序列的离散傅里叶变换 (DFT)（首次出现：离散傅里叶变换 (DFT)）。使用实值 DFT $R = \\text{rfft}(r_{\\text{valid-sorted}})$，并将高频能量比定义为\n$$\n\\rho_{\\text{HF}} = \\frac{\\sum_{k \\in \\mathcal{H}} |R_k|^2}{\\sum_{k \\in \\mathcal{P}} |R_k|^2},\n$$\n其中 $\\mathcal{P}$ 索引除零频段外的所有正频段，$\\mathcal{H}$ 索引正频段中最高四分位数部分（即 $\\mathcal{P}$ 中频率最高的 $25\\%$）。如果分母为零，则定义 $\\rho_{\\text{HF}} = 0$。\n\n使用以下带有固定阈值的分类规则来判断模型是欠拟合、良好拟合还是过拟合。已知噪声方差为 $\\sigma^2 = 0.01$，阈值设为 $t_u = 1.3$，$t_o = 0.9$，$t_o' = 1.2$，$h_u = 0.35$ 和 $h_o = 0.45$。\n\n- 欠拟合（代码 $0$）：如果 $d  d^\\star$，或者 $\\text{MSE}_{\\text{train}} \\ge t_u \\sigma^2$ 且 $\\text{MSE}_{\\text{valid}} \\ge t_u \\sigma^2$ 且 $\\rho_{\\text{HF}} \\le h_u$，则判定为欠拟合。\n- 过拟合（代码 $2$）：如果 $d > d^\\star$ 且 $\\text{MSE}_{\\text{train}} \\le t_o \\sigma^2$ 且 $\\text{MSE}_{\\text{valid}} \\ge t_o' \\sigma^2$ 且 $\\rho_{\\text{HF}} \\ge h_o$，则判定为过拟合。\n- 良好拟合（代码 $1$）：如果以上两个条件都不满足，则判定为良好拟合。\n\n实现以上逻辑，并评估以下改变 $d$ 和 $\\lambda$ 的测试套件：\n\n- 情况1：$d = 2$，$\\lambda = 0.001$。\n- 情况2：$d = 4$，$\\lambda = 0.05$。\n- 情况3：$d = 12$，$\\lambda = 0.0$。\n- 情况4：$d = 12$，$\\lambda = 10.0$。\n- 情况5：$d = 4$，$\\lambda = 0.0$。\n\n您的程序必须按照规定生成数据集，为每种情况拟合模型，计算指标，并按给定顺序输出这些情况的分类代码。您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，$[0,1,2,0,1]$）。本问题不需要任何物理单位、角度单位或百分比。最终输出值为如上指定的整数。程序必须是完整且可直接运行的，无需外部输入或文件。请使用指定的确定性种子，以便任何人运行程序时都能复现结果。", "solution": "问题陈述已经过仔细验证，并被确定为有效。它在科学上是合理的，内容自洽，且问题定义明确，为计算统计学和机器学习领域提供了一个清晰且可形式化的任务。\n\n该任务是基于一组精确的量化标准，将多项式回归模型分类为欠拟合、良好拟合或过拟合。解决方案涉及为多个测试案例生成数据、拟合模型、计算指标和进行分类。由于指定了随机种子，整个过程是确定性的。\n\n### 步骤1：数据生成与准备\n\n此回归问题的基础是一个合成数据集。输入 $x$ 和输出 $y$ 之间的真实关系由一个已知的 $d^\\star=4$ 阶多项式函数 $f^\\star(x)$ 定义：\n$$\nf^\\star(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + a_4 x^4\n$$\n其系数为 $a_0 = 0.3$，$a_1 = -0.8$，$a_2 = 0.5$，$a_3 = 0.0$ 和 $a_4 = 0.7$。\n\n观测数据受到加性高斯白噪声 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 的干扰，其中噪声方差为 $\\sigma^2 = 0.01$。因此，每个数据点 $(x_i, y_i)$ 根据以下模型生成：\n$$\ny_i = f^\\star(x_i) + \\varepsilon_i\n$$\n总共创建 $N=200$ 个数据点。输入值 $x_i$ 从区间 $[-1, 1]$ 上的均匀分布中抽取。为确保可复现性，随机数生成器使用固定的种子 $42$ 进行初始化。\n\n生成的包含 $N=200$ 个点的数据集随后被确定性地打乱，并分割成大小为 $N_{\\text{train}} = 120$ 的训练集和大小为 $N_{\\text{valid}} = 80$ 的验证集。这种划分使我们能够训练模型并独立评估其泛化性能。\n\n### 步骤2：带岭正则化的多项式回归\n\n对于每个测试案例，我们将一个指定阶数 $d$ 的多项式模型拟合到训练数据上。模型假设的形式如下：\n$$\n\\hat{y}(x) = \\sum_{k=0}^d w_k x^k = \\mathbf{w}^\\top \\phi(x)\n$$\n其中 $\\mathbf{w} \\in \\mathbb{R}^{d+1}$ 是待学习的模型系数向量，$\\phi(x) = [1, x, x^2, \\dots, x^d]^\\top$ 是特征向量。\n\n对于一个包含 $m$ 个训练样本的集合，我们构建设计矩阵 $\\Phi_{\\text{train}} \\in \\mathbb{R}^{m \\times (d+1)}$，其中每个元素为 $(\\Phi_{\\text{train}})_{i,k} = x_i^k$，对于 $i \\in \\{1, \\dots, m\\}$ 和 $k \\in \\{0, \\dots, d\\}$。\n\n系数 $\\mathbf{w}$ 使用岭回归进行估计，该方法最小化正则化的平方误差和：\n$$\n\\mathcal{L}(\\mathbf{w}) = \\|\\mathbf{y}_{\\text{train}} - \\Phi_{\\text{train}}\\mathbf{w}\\|_2^2 + \\lambda \\|\\mathbf{w}\\|_2^2\n$$\n这里，$\\lambda \\ge 0$ 是正则化参数，用于控制对系数大小的惩罚。最优权重向量 $\\mathbf{w}$ 的闭式解由以下正规方程给出：\n$$\n\\mathbf{w} = \\left(\\Phi_{\\text{train}}^\\top \\Phi_{\\text{train}} + \\lambda I\\right)^{-1} \\Phi_{\\text{train}}^\\top \\mathbf{y}_{\\text{train}}\n$$\n其中 $I$ 是 $(d+1) \\times (d+1)$ 的单位矩阵。为了数值稳定性，这个线性系统使用 `numpy.linalg.solve` 求解，而不是显式地计算矩阵的逆。\n\n### 步骤3：模型评估指标\n\n一旦模型训练完成（即 $\\mathbf{w}$ 被计算出来），其性能将使用两个关键指标进行评估。\n\n**均方误差 (MSE):** MSE 衡量预测值 $\\hat{y}_i$ 与实际值 $y_i$ 之间平方差的平均值。它分别在训练集和验证集上计算：\n$$\n\\text{MSE}_{\\text{train}} = \\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} (y_{\\text{train},i} - \\hat{y}_{\\text{train},i})^2\n$$\n$$\n\\text{MSE}_{\\text{valid}} = \\frac{1}{N_{\\text{valid}}} \\sum_{i=1}^{N_{\\text{valid}}} (y_{\\text{valid},i} - \\hat{y}_{\\text{valid},i})^2\n$$\n\n**高频能量比 ($\\rho_{\\text{HF}}$):** 该指标量化了模型在验证集上误差的振荡特性，这是过拟合的一个常见症状。其计算过程如下：\n1.  计算验证残差：$\\mathbf{r}_{\\text{valid}} = \\mathbf{y}_{\\text{valid}} - \\hat{\\mathbf{y}}_{\\text{valid}}$。\n2.  根据其对应输入值 $x_{\\text{valid}}$ 的升序对这些残差进行排序。令此排序后的序列为 $\\mathbf{r}_{\\text{valid-sorted}}$。\n3.  计算排序后残差的实值离散傅里叶变换 (DFT)：$R = \\text{rfft}(\\mathbf{r}_{\\text{valid-sorted}})$。对于 $N_{\\text{valid}} = 80$，输出 $R$ 是一个长度为 $41$ 的复值数组。\n4.  正频段集合 $\\mathcal{P}$ 由除零频（直流）分量外的所有频段组成。对于 RFFT 输出 $R$，这些对应于索引 $k \\in \\{1, 2, \\dots, 40\\}$。\n5.  高频段集合 $\\mathcal{H}$ 定义为 $\\mathcal{P}$ 中频率最高的四分位数（最高的 $25\\%$）。这对应于最后的 $40 \\times 0.25 = 10$ 个频段，其索引为 $k \\in \\{31, 32, \\dots, 40\\}$。\n6.  高频能量比即为 $\\mathcal{H}$ 中的能量与 $\\mathcal{P}$ 中总能量之比：\n    $$\n    \\rho_{\\text{HF}} = \\frac{\\sum_{k \\in \\mathcal{H}} |R_k|^2}{\\sum_{k \\in \\mathcal{P}} |R_k|^2}\n    $$\n    如果分母为零，$\\rho_{\\text{HF}}$ 定义为 $0$。\n\n### 步骤4：分类逻辑\n\n计算出的指标根据一组固定规则用于将每个模型分类为欠拟合、良好拟合或过拟合。真实噪声方差为 $\\sigma^2 = 0.01$，阈值为 $t_u = 1.3$，$t_o = 0.9$，$t_o' = 1.2$，$h_u = 0.35$ 和 $h_o = 0.45$。\n\n- **欠拟合（代码 $0$）：** 如果一个模型的阶数 $d$ 小于真实阶数 $d^\\star$，*或者*它在训练集和验证集上都表现出高误差，同时伴有低残差振荡，则被判定为欠拟合。形式上：\n  $$\n  (d  d^\\star) \\lor (\\text{MSE}_{\\text{train}} \\ge t_u \\sigma^2 \\land \\text{MSE}_{\\text{valid}} \\ge t_u \\sigma^2 \\land \\rho_{\\text{HF}} \\le h_u)\n  $$\n\n- **过拟合（代码 $2$）：** 如果一个模型的阶数 $d$ 大于 $d^\\star$，*并且*它表现出较低的训练误差、显著较高的验证误差以及其残差中的高频振荡，则被判定为过拟合。形式上：\n  $$\n  (d > d^\\star) \\land (\\text{MSE}_{\\text{train}} \\le t_o \\sigma^2 \\land \\text{MSE}_{\\text{valid}} \\ge t_o' \\sigma^2 \\land \\rho_{\\text{HF}} \\ge h_o)\n  $$\n\n- **良好拟合（代码 $1$）：** 如果一个模型既不满足欠拟合也不满足过拟合的标准，则被分类为良好拟合。\n\n这些规则为偏差-方差权衡概念提供了具体、算法化的定义。程序为每个指定的测试案例实现此逻辑，生成最终的分类代码列表。", "answer": "```python\nimport numpy as np\nimport scipy.fft\n\ndef solve():\n    \"\"\"\n    Main function to execute the polynomial regression analysis and classification.\n    \"\"\"\n    #\n    # Step 0: Define constants and problem parameters\n    #\n    RANDOM_SEED = 42\n    D_STAR = 4\n    A_COEFFS = np.array([0.3, -0.8, 0.5, 0.0, 0.7])\n    SIGMA = 0.1\n    SIGMA_SQUARED = SIGMA**2\n    N_TOTAL = 200\n    N_TRAIN = 120\n    N_VALID = 80\n\n    # Classification thresholds\n    T_U = 1.3\n    T_O = 0.9\n    T_O_PRIME = 1.2\n    H_U = 0.35\n    H_O = 0.45\n\n    # Test cases to evaluate\n    test_cases = [\n        {'d': 2, 'lambda': 0.001},  # Case 1\n        {'d': 4, 'lambda': 0.05},   # Case 2\n        {'d': 12, 'lambda': 0.0},    # Case 3\n        {'d': 12, 'lambda': 10.0},   # Case 4\n        {'d': 4, 'lambda': 0.0},    # Case 5\n    ]\n    \n    #\n    # Step 1: Generate dataset\n    #\n    rng = np.random.default_rng(RANDOM_SEED)\n\n    # Generate x values\n    x = rng.uniform(-1, 1, size=N_TOTAL)\n\n    # Generate true function values y_star\n    def f_star(x_in):\n        return A_COEFFS[0] + A_COEFFS[1] * x_in + A_COEFFS[2] * x_in**2 + \\\n               A_COEFFS[3] * x_in**3 + A_COEFFS[4] * x_in**4\n\n    y_star = f_star(x)\n\n    # Add Gaussian noise\n    noise = rng.normal(0, SIGMA, size=N_TOTAL)\n    y = y_star + noise\n\n    # Split into training and validation sets\n    indices = np.arange(N_TOTAL)\n    rng.shuffle(indices)\n    \n    train_indices = indices[:N_TRAIN]\n    valid_indices = indices[N_TRAIN:]\n\n    x_train, y_train = x[train_indices], y[train_indices]\n    x_valid, y_valid = x[valid_indices], y[valid_indices]\n\n    #\n    # Helper functions\n    #\n    def construct_design_matrix(x_data, degree):\n        \"\"\"Constructs the polynomial design matrix Phi.\"\"\"\n        return np.vander(x_data, degree + 1, increasing=True)\n\n    results = []\n\n    #\n    # Step 2-4: Process each test case\n    #\n    for case in test_cases:\n        d = case['d']\n        lambda_reg = case['lambda']\n\n        # Construct design matrices\n        phi_train = construct_design_matrix(x_train, d)\n        phi_valid = construct_design_matrix(x_valid, d)\n\n        # Fit the model using ridge regression (numerically stable)\n        d_plus_1 = d + 1\n        A = phi_train.T @ phi_train + lambda_reg * np.eye(d_plus_1)\n        b = phi_train.T @ y_train\n        w = np.linalg.solve(A, b)\n\n        # Make predictions\n        y_hat_train = phi_train @ w\n        y_hat_valid = phi_valid @ w\n\n        # Calculate metrics\n        # a) MSE\n        mse_train = np.mean((y_train - y_hat_train)**2)\n        mse_valid = np.mean((y_valid - y_hat_valid)**2)\n        \n        # b) High-frequency energy ratio rho_HF\n        residuals_valid = y_valid - y_hat_valid\n        \n        # Sort residuals according to x_valid\n        sort_indices = np.argsort(x_valid)\n        residuals_valid_sorted = residuals_valid[sort_indices]\n        \n        # Compute RFFT\n        R = scipy.fft.rfft(residuals_valid_sorted)\n        \n        # Calculate energies\n        # P: positive frequencies (indices 1 to end)\n        # H: top quartile of P (last 10 for N_valid=80)\n        # N_valid = 80 -> rfft length = 41. P_indices = 1..40. H_indices = 31..40.\n        num_positive_freqs = len(R) - 1\n        top_quartile_size = int(np.ceil(0.25 * num_positive_freqs))\n        \n        energy_P = np.sum(np.abs(R[1:])**2)\n        energy_H = np.sum(np.abs(R[-top_quartile_size:])**2)\n        \n        rho_hf = energy_H / energy_P if energy_P > 0 else 0.0\n        \n        # Apply classification rules\n        code = 1 # Default to well-fit\n\n        # Underfitting rule\n        is_underfit_by_degree = (d  D_STAR)\n        is_underfit_by_metrics = (mse_train >= T_U * SIGMA_SQUARED and \\\n                                  mse_valid >= T_U * SIGMA_SQUARED and \\\n                                  rho_hf = H_U)\n        if is_underfit_by_degree or is_underfit_by_metrics:\n            code = 0\n\n        # Overfitting rule\n        is_overfit_by_metrics = (d > D_STAR and \\\n                                 mse_train = T_O * SIGMA_SQUARED and \\\n                                 mse_valid >= T_O_PRIME * SIGMA_SQUARED and \\\n                                 rho_hf >= H_O)\n        if is_overfit_by_metrics:\n            code = 2\n            \n        results.append(code)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3135788"}, {"introduction": "在深度学习中，糟糕的性能并非总是简单的欠拟合或过拟合。本练习将场景从简单模型转向更复杂的卷积神经网络（CNN），要求您仅根据原始的学习曲线（$L_{\\text{train}}$ 和 $L_{\\text{val}}$）来区分两种不同的失败模式：模型因学习训练数据过于“出色”而导致的过拟合，以及模型因优化过程本身失败而导致的欠拟合。掌握这种诊断技能对于任何深度学习从业者都至关重要[@problem_id:3135765]。", "problem": "给定一个卷积神经网络（CNN）在移除了批量归一化后于CIFAR-10数据集上训练得到的经验训练损失和验证损失的时间序列。对于每种情况，您必须判断观察到的差的泛化能力是源于优化失败导致的欠拟合，还是源于过拟合。您的决策必须仅基于分析训练损失（表示为 $L_{\\text{train}}(t)$）和验证损失（表示为 $L_{\\text{val}}(t)$）在各个周期 $t \\in \\{1,2,\\dots,T\\}$ 上的轨迹。没有其他可用的指标。\n\n使用以下基本依据：\n- 经验风险最小化：经验风险（训练损失）$L_{\\text{train}}$ 估计了训练样本上的期望风险，而验证损失 $L_{\\text{val}}$ 估计了对未见数据的泛化能力。\n- 过拟合的特征是较小的 $L_{\\text{train}}$ 和显著较大的 $L_{\\text{val}}$，这表明存在很大的泛化差距。\n- 因优化失败导致的欠拟合的特征是持续较高的 $L_{\\text{train}}$ 和微弱的优化进展，这表明优化器未能有效最小化经验风险。\n\n您的程序必须实现一个基于这些定义的原则性决策过程，以便为每种情况输出：\n- 如果模式与过拟合一致，则输出 $0$。\n- 如果模式与因优化失败导致的欠拟合一致，则输出 $1$。\n\n测试套件（每个案例提供按周期排序的 $L_{\\text{train}}$ 和 $L_{\\text{val}}$ 列表）：\n- 案例 $1$：\n  - $L_{\\text{train}}$: $[1.6, 1.2, 0.8, 0.4, 0.2, 0.1, 0.08, 0.06, 0.05]$\n  - $L_{\\text{val}}$: $[1.7, 1.3, 0.9, 0.7, 0.65, 0.6, 0.58, 0.6, 0.62]$\n- 案例 $2$：\n  - $L_{\\text{train}}$: $[2.0, 1.95, 1.9, 1.88, 1.87, 1.865, 1.86, 1.859, 1.858]$\n  - $L_{\\text{val}}$: $[2.0, 1.98, 1.96, 1.95, 1.94, 1.94, 1.93, 1.93, 1.93]$\n- 案例 $3$：\n  - $L_{\\text{train}}$: $[1.2, 1.0, 0.8, 0.6, 0.5, 0.48, 0.47, 0.46, 0.45]$\n  - $L_{\\text{val}}$: $[1.2, 1.1, 0.95, 0.9, 0.92, 0.95, 1.0, 1.05, 1.1]$\n- 案例 $4$：\n  - $L_{\\text{train}}$: $[1.5, 1.3, 1.2, 1.25, 1.22, 1.21, 1.2, 1.19, 1.18]$\n  - $L_{\\text{val}}$: $[1.6, 1.5, 1.45, 1.5, 1.48, 1.47, 1.47, 1.46, 1.46]$\n- 案例 $5$：\n  - $L_{\\text{train}}$: $[1.8, 1.5, 1.1, 0.9, 0.7, 0.5, 0.3, 0.2, 0.15]$\n  - $L_{\\text{val}}$: $[1.9, 1.6, 1.3, 1.1, 1.1, 1.15, 1.2, 1.25, 1.3]$\n\n约束和要求：\n- 您必须根据上述基本定义，通过对 $L_{\\text{train}}$ 和 $L_{\\text{val}}$ 轨迹的第一性原理进行推理来构建决策规则，不得使用任何外部数据或非从这些定义中推导出的启发式方法。\n- 最终输出必须是单行，包含一个与案例顺序对应的整数列表。\n- 唯一允许的输出是如上定义的 $0$ 和 $1$。不涉及物理单位。\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，$[0,1,0]$）。", "solution": "该问题具有科学依据，定义明确，客观，并包含足够的信息来制定一个有原则的解决方案。训练损失、验证损失、过拟合和欠拟合的概念是机器学习中的基本概念。所提供的数据对于所描述的场景是真实的。任务是将给定的定性定义形式化为一个定量的、确定性的算法。\n\n核心目标是区分两种泛化失败模式：过拟合和因优化失败导致的欠拟合。这种区分取决于分析优化器在最小化经验风险方面的成功程度，经验风险由训练损失 $L_{\\text{train}}(t)$ 表示。\n\n所提供的定义指导了决策过程的制定：\n1.  **因优化失败导致的欠拟合** 被定义为“持续较高的 $L_{\\text{train}}$”和“微弱的优化进展”。这意味着模型甚至未能学习训练数据中的模式。\n2.  **过拟合** 被定义为“较小的 $L_{\\text{train}}$”和“显著较大的 $L_{\\text{val}}$”。这意味着模型已经很好地学习了训练数据（达到了较低的经验风险），以至于它也学习了训练集中的噪声和特定伪影，从而导致在未见数据上表现不佳（即存在一个大的泛化差距，$G(t) = L_{\\text{val}}(t) - L_{\\text{train}}(t)$）。\n\n基于这些第一性原理，可以建立一个顺序决策逻辑。首要问题是优化过程是否成功。如果训练损失没有被有效最小化，诊断必然是欠拟合。如果它被成功最小化，那么观察到的差的泛化能力就归因于过拟合。\n\n**决策规则的形式化**\n\n设训练损失值的序列为 $\\mathcal{L}_{\\text{train}} = \\{L_{\\text{train}}(t)\\}_{t=1}^{T}$，历经 $T$ 个周期。\n\n**1. 欠拟合评估（优化失败）**\n我们将定性定义转化为两个必须同时满足的定量条件。\n-   **“持续较高的 $L_{\\text{train}}$”**：这通过检查最终训练损失 $L_{\\text{train}}(T)$ 来评估。对于像 CIFAR-10 这样的10类分类问题，随机猜测的分类交叉熵损失为 $-\\ln(1/10) \\approx 2.3$。一个训练良好的模型应能达到远低于 $1.0$ 的训练损失。因此，我们设定一个阈值 $\\theta_{\\text{loss}} = 1.0$。高于此阈值的最终训练损失被认为是“高”的。\n    $$ \\text{条件 1: } L_{\\text{train}}(T) > \\theta_{\\text{loss}} = 1.0 $$\n-   **“微弱的优化进展”**：这通过训练开始到结束的总训练损失减少量来衡量，即 $\\Delta L_{\\text{train}} = L_{\\text{train}}(1) - L_{\\text{train}}(T)$。一个小的减少量表明优化器已停滞或无效。我们设定一个阈值 $\\theta_{\\text{progress}} = 0.5$。总损失减少量小于或等于此值被认为是“进展微弱”。\n    $$ \\text{条件 2: } \\Delta L_{\\text{train}} \\le \\theta_{\\text{progress}} = 0.5 $$\n\n当且仅当两个条件都满足时，一个案例被分类为**欠拟合（标签 $1$）**。这对应于模型最终处于高训练误差状态，并且在减少误差方面进展甚微的场景。\n\n**2. 过拟合评估**\n在这个问题的二元分类方案中，任何未被识别为欠拟合的案例，通过排除法，被分类为**过拟合（标签 $0$）**。这个逻辑是合理的，因为未能满足欠拟合标准意味着训练损失已成功最小化（无论是 $L_{\\text{train}}(T)$ 低，还是进展显著，或两者兼有），这是过拟合的前提条件。这些案例的特征是最终训练损失较低，但泛化差距 $G(T) = L_{\\text{val}}(T) - L_{\\text{train}}(T)$ 较大且常常在增长，这是过拟合的标志。通常，验证损失 $L_{\\text{val}}(t)$ 会达到一个最小值然后开始增加，这是一个明确的迹象。\n\n**应用于测试案例**\n\n我们将此形式化过程应用于每个案例。\n\n- **案例 1**：\n  - $L_{\\text{train}} = [1.6, 1.2, 0.8, 0.4, 0.2, 0.1, 0.08, 0.06, 0.05]$\n  - $L_{\\text{train}}(1) = 1.6$, $L_{\\text{train}}(T) = 0.05$。\n  - 条件 1：$L_{\\text{train}}(T) = 0.05 \\ngtr 1.0$。未满足欠拟合条件。\n  - **分类：$0$（过拟合）**。\n  - 理由：训练损失被最小化到一个非常低的值（$0.05$）。验证损失 $L_{\\text{val}}$ 在 $0.58$ 处触底然后开始增加，并产生了一个大的泛化差距（$0.62 - 0.05 = 0.57$）。这是典型的过拟合。\n\n- **案例 2**：\n  - $L_{\\text{train}} = [2.0, 1.95, 1.9, 1.88, 1.87, 1.865, 1.86, 1.859, 1.858]$\n  - $L_{\\text{train}}(1) = 2.0$, $L_{\\text{train}}(T) = 1.858$。\n  - 条件 1：$L_{\\text{train}}(T) = 1.858 > 1.0$。（成立）\n  - $\\Delta L_{\\text{train}} = 2.0 - 1.858 = 0.142$。\n  - 条件 2：$\\Delta L_{\\text{train}} = 0.142 \\le 0.5$。（成立）\n  - 两个欠拟合条件都满足。\n  - **分类：$1$（欠拟合）**。\n  - 理由：训练损失仍然非常高，接近随机猜测的值，并且在各个周期中几乎没有改善。这是一个明显的优化失败案例。\n\n- **案例 3**：\n  - $L_{\\text{train}} = [1.2, 1.0, 0.8, 0.6, 0.5, 0.48, 0.47, 0.46, 0.45]$\n  - $L_{\\text{train}}(1) = 1.2$, $L_{\\text{train}}(T) = 0.45$。\n  - 条件 1：$L_{\\text{train}}(T) = 0.45 \\ngtr 1.0$。未满足欠拟合条件。\n  - **分类：$0$（过拟合）**。\n  - 理由：训练损失被最小化到一个较低的值（$0.45$）。验证损失 $L_{\\text{val}}$ 在第四个周期后开始增加，最终的泛化差距很大（$1.1 - 0.45 = 0.65$）。这是过拟合。\n\n- **案例 4**：\n  - $L_{\\text{train}} = [1.5, 1.3, 1.2, 1.25, 1.22, 1.21, 1.2, 1.19, 1.18]$\n  - $L_{\\text{train}}(1) = 1.5$, $L_{\\text{train}}(T) = 1.18$。\n  - 条件 1：$L_{\\text{train}}(T) = 1.18 > 1.0$。（成立）\n  - $\\Delta L_{\\text{train}} = 1.5 - 1.18 = 0.32$。\n  - 条件 2：$\\Delta L_{\\text{train}} = 0.32 \\le 0.5$。（成立）\n  - 两个欠拟合条件都满足。\n  - **分类：$1$（欠拟合）**。\n  - 理由：训练损失仍然很高，且优化进展甚微。损失甚至在某个点上有所增加，表明存在不稳定性。\n\n- **案例 5**：\n  - $L_{\\text{train}} = [1.8, 1.5, 1.1, 0.9, 0.7, 0.5, 0.3, 0.2, 0.15]$\n  - $L_{\\text{train}}(1) = 1.8$, $L_{\\text{train}}(T) = 0.15$。\n  - 条件 1：$L_{\\text{train}}(T) = 0.15 \\ngtr 1.0$。未满足欠拟合条件。\n  - **分类：$0$（过拟合）**。\n  - 理由：训练损失成功地被最小化到一个较低的值（$0.15$）。然而，验证损失 $L_{\\text{val}}$ 发生分歧并开始增加，导致最终的泛化差距非常大（$1.3 - 0.15 = 1.15$）。这是一个明显的过拟合案例。\n\n最终的分类序列是 $[0, 1, 0, 1, 0]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the problem of classifying learning behavior as overfitting or underfitting.\n    \n    The function iterates through a predefined set of test cases, each containing\n    time series for training loss and validation loss. It applies a principled \n    decision rule to classify each case and prints the results in the required format.\n    \"\"\"\n    \n    # Test suite with training and validation loss trajectories.\n    test_cases = [\n        # Case 1: Overfitting\n        ([1.6, 1.2, 0.8, 0.4, 0.2, 0.1, 0.08, 0.06, 0.05],\n         [1.7, 1.3, 0.9, 0.7, 0.65, 0.6, 0.58, 0.6, 0.62]),\n        # Case 2: Underfitting\n        ([2.0, 1.95, 1.9, 1.88, 1.87, 1.865, 1.86, 1.859, 1.858],\n         [2.0, 1.98, 1.96, 1.95, 1.94, 1.94, 1.93, 1.93, 1.93]),\n        # Case 3: Overfitting\n        ([1.2, 1.0, 0.8, 0.6, 0.5, 0.48, 0.47, 0.46, 0.45],\n         [1.2, 1.1, 0.95, 0.9, 0.92, 0.95, 1.0, 1.05, 1.1]),\n        # Case 4: Underfitting\n        ([1.5, 1.3, 1.2, 1.25, 1.22, 1.21, 1.2, 1.19, 1.18],\n         [1.6, 1.5, 1.45, 1.5, 1.48, 1.47, 1.47, 1.46, 1.46]),\n        # Case 5: Overfitting\n        ([1.8, 1.5, 1.1, 0.9, 0.7, 0.5, 0.3, 0.2, 0.15],\n         [1.9, 1.6, 1.3, 1.1, 1.1, 1.15, 1.2, 1.25, 1.3])\n    ]\n\n    results = []\n    for l_train, l_val in test_cases:\n        # The validation loss (l_val) is provided but not strictly needed for the\n        # primary classification logic, which focuses on the success of empirical\n        # risk minimization (analyzing l_train).\n        result = classify_behavior(l_train)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef classify_behavior(l_train):\n    \"\"\"\n    Applies a principled decision rule to classify a learning trajectory.\n\n    Args:\n        l_train (list): A time series of training loss values.\n\n    Returns:\n        int: 0 for overfitting, 1 for underfitting due to optimization failure.\n    \"\"\"\n    # Convert list to a numpy array for efficient indexing.\n    l_train_np = np.array(l_train)\n\n    # Thresholds derived from first principles for a 10-class problem:\n    # A final training loss > 1.0 is considered high, indicating failure to fit the training set.\n    theta_loss = 1.0\n    # A total loss reduction = 0.5 is considered weak progress, indicating optimization failure.\n    theta_progress = 0.5\n\n    # Extract key metrics from the training loss trajectory:\n    # Final training loss, L_train(T)\n    final_train_loss = l_train_np[-1]\n    # Initial training loss, L_train(1)\n    initial_train_loss = l_train_np[0]\n    # Total progress in optimization, L_train(1) - L_train(T)\n    progress = initial_train_loss - final_train_loss\n\n    # Apply the decision rule for underfitting due to optimization failure.\n    # This is defined as having a persistently high training loss AND making weak progress.\n    if final_train_loss > theta_loss and progress = theta_progress:\n        # Pattern is consistent with underfitting due to optimization failure.\n        return 1\n    else:\n        # If the underfitting criteria are not met, it implies the optimizer succeeded\n        # in reducing the training loss. Therefore, poor generalization is due to overfitting.\n        return 0\n\nsolve()\n```", "id": "3135765"}, {"introduction": "现在，让我们探讨一种更微妙但普遍存在的过拟合形式，即模型学习了“捷径特征”。有时，模型即使在验证集上表现良好，也可能只是因为它学会了利用数据中存在的、但不具备鲁棒性的虚假相关性。这项高级练习将引导您创建一个包含鲁棒特征和捷径特征的合成数据集，亲身体验并诊断这种现象。通过在评估时移除捷径特征，我们将学会识别这种更隐蔽的过拟合形式，并理解构建真正鲁棒模型的重要性[@problem_id:3135726]。", "problem": "您必须编写一个完整、可运行的程序，该程序构建一个混合了鲁棒特征和捷径特征的合成二元分类数据集，使用经验风险最小化训练一个单隐藏层神经网络，在两种受控条件下（捷径特征可见和捷径特征被抑制）评估验证准确率，并从第一性原理出发诊断过拟合或欠拟合。程序必须实现以下场景，并为指定的测试套件生成单行输出，其中包含一个整数列表。\n\n基本原理。考虑在假设类别 $\\mathcal{F}$ 上的经验风险最小化，其中分类器 $f \\in \\mathcal{F}$ 将输入 $x \\in \\mathbb{R}^d$ 映射到二元标签 $y \\in \\{0,1\\}$ 的预测概率 $\\hat{y} \\in [0,1]$。设在数据集 $S = \\{(x_i, y_i)\\}_{i=1}^n$ 上的经验风险为\n$$\nR_S(f) = \\frac{1}{n} \\sum_{i=1}^n \\ell(f(x_i), y_i),\n$$\n其中使用二元交叉熵损失 $\\ell(\\hat{y}, y) = -\\left[y \\log(\\hat{y}) + (1-y)\\log(1-\\hat{y})\\right]$。在分布 $\\mathcal{D}$ 下的期望风险为 $R_{\\mathcal{D}}(f) = \\mathbb{E}_{(x,y)\\sim\\mathcal{D}}[\\ell(f(x),y)]$。泛化差距为 $\\Gamma(f) = R_{\\mathcal{D}}(f) - R_S(f)$。过拟合的特征是训练误差小而验证误差大，而欠拟合的特征是由于模型容量不足或优化不佳，导致训练和验证误差都很大。\n\n使用鲁棒特征和捷径特征生成数据。对于每个样本，设输入为 $x = [r; s] \\in \\mathbb{R}^{p+q}$，其中 $r \\in \\mathbb{R}^p$ 是鲁棒特征，$s \\in \\mathbb{R}^q$ 是捷径特征。标签为 $y \\in \\{0,1\\}$，并记 $y' = 2y - 1 \\in \\{-1, +1\\}$。鲁棒特征服从\n$$\nr \\sim \\mathcal{N}\\left(m \\, y' \\, \\mathbf{1}_p, \\, \\sigma_r^2 I_p\\right),\n$$\n而捷径特征服从\n$$\ns \\sim \\mathcal{N}\\left(\\alpha \\, y' \\, \\mathbf{1}_q, \\, \\sigma_s^2 I_q\\right).\n$$\n一种称为“捷径抑制”的数据增强方法，通过独立于 $y$ 的噪声替换 $s$：\n$$\nA(x) = [r; \\tilde{s}], \\quad \\tilde{s} \\sim \\mathcal{N}\\left(0, \\sigma_s^2 I_q\\right).\n$$\n这种增强保留了鲁棒信号，同时抑制了捷径。当捷径可见时，在 $x$ 上进行验证；当被抑制时，在 $A(x)$ 上进行验证。\n\n模型与训练。使用一个单隐藏层神经网络 $f_\\theta$，其参数为 $\\theta = (W_1, b_1, W_2, b_2)$，\n$$\nh = \\phi(W_1 x + b_1), \\quad \\hat{y} = \\sigma(W_2^\\top h + b_2),\n$$\n其中 $\\phi$ 是修正线性单元（ReLU），$\\sigma$ 是逻辑S型函数（logistic sigmoid）。使用随机梯度下降在训练集上最小化 $R_S(f_\\theta)$ 来进行训练；可选择性地对训练输入应用捷径抑制，以阻止模型学习捷径。\n\n诊断规则。设捷径可见时的验证准确率为 $a_{\\mathrm{vis}}$，被抑制时的验证准确率为 $a_{\\mathrm{sup}}$。使用阈值 $\\tau_h = 0.9$（高准确率）、$\\tau_\\ell = 0.7$（低准确率）和下降阈值 $\\Delta = 0.25$。诊断：\n-   如果 $a_{\\mathrm{vis}} \\ge \\tau_h$，$a_{\\mathrm{sup}} \\le \\tau_\\ell$，且 $a_{\\mathrm{vis}} - a_{\\mathrm{sup}} \\ge \\Delta$，则为对捷径的过拟合。\n-   如果 $a_{\\mathrm{vis}}  \\tau_\\ell$ 且 $a_{\\mathrm{sup}}  \\tau_\\ell$，则为欠拟合。\n-   否则，既不属于欠拟合也不属于过拟合。\n\n将诊断编码为整数：过拟合 $\\to 1$，欠拟合 $\\to -1$，其他情况 $\\to 0$。\n\n程序要求。您的程序必须：\n-   为每个测试用例生成独立的训练和验证数据集，每个用例使用固定的随机种子以确保可复现性。\n-   实现指定神经网络的训练，使用二元交叉熵和随机梯度下降。\n-   评估 $a_{\\mathrm{vis}}$ 和 $a_{\\mathrm{sup}}$ 并应用上述诊断规则。\n-   生成单行输出，其中包含所有测试用例的诊断结果，格式为逗号分隔的列表并用方括号括起，例如 `[1,0,-1,0]`。\n\n测试套件。使用以下测试用例，每个用例指定为一个元组 $(p, q, m, \\alpha, \\sigma_r, \\sigma_s, H, E, \\eta, \\text{train\\_suppress}, \\text{seed})$，其中 $p$ 和 $q$ 是特征维度，$m$ 和 $\\alpha$ 是信号强度，$\\sigma_r$ 和 $\\sigma_s$ 是噪声尺度，$H$ 是隐藏层宽度，$E$ 是训练轮数，$\\eta$ 是学习率，$\\text{train\\_suppress} \\in \\{0,1\\}$ 指示训练期间是否应用捷径抑制，$\\text{seed}$ 是随机种子。数据集大小必须固定：训练集大小 $n_{\\mathrm{train}} = 3000$，验证集大小 $n_{\\mathrm{val}} = 3000$。\n\n-   用例1（预期过拟合）：$(5, 3, 0.2, 4.0, 1.0, 1.0, 32, 50, 0.05, 0, 1337)$。\n-   用例2（预期鲁棒泛化）：$(5, 3, 0.6, 4.0, 1.0, 1.0, 32, 50, 0.05, 1, 2027)$。\n-   用例3（预期欠拟合）：$(5, 3, 0.6, 4.0, 1.0, 1.0, 2, 5, 0.01, 1, 3037)$。\n-   用例4（由于鲁棒信号强，即使没有抑制也预期能鲁棒泛化）：$(5, 3, 1.5, 1.0, 1.0, 1.0, 32, 50, 0.05, 0, 4047)$。\n\n最终输出格式。您的程序应生成单行输出，其中包含结果，格式为逗号分隔的列表并用方括号括起（例如 `[r_1,r_2,r_3,r_4]`），其中每个 $r_i \\in \\{-1,0,1\\}$ 是根据上述规则对用例 $i$ 的诊断结果。不应打印任何其他文本。", "solution": "该问题要求实现一个计算实验，以诊断在一个具有鲁棒特征和捷径特征两种类型特征的合成数据集上训练的神经网络的过拟合和欠拟合问题。解决方案涉及四个主要阶段：数据生成、模型实现、训练和诊断。\n\n### 1. 数据生成\n\n对于每个测试用例，会生成一个大小为 $n_{\\mathrm{train}} = 3000$ 的训练集和一个大小为 $n_{\\mathrm{val}} = 3000$ 的验证集。每个数据点 $(x, y)$ 由一个输入向量 $x \\in \\mathbb{R}^{p+q}$ 和一个二元标签 $y \\in \\{0,1\\}$ 组成。输入向量 $x$ 是鲁棒特征 $r \\in \\mathbb{R}^p$ 和捷径特征 $s \\in \\mathbb{R}^q$ 的拼接，即 $x = [r; s]$。\n\n标签 $y$ 从参数为 0.5 的伯努利分布中抽取。为了数学上的便利，标签被转换为 $y' = 2y - 1$，因此 $y' \\in \\{-1, +1\\}$。然后从均值依赖于 $y'$ 的多元正态分布中生成特征：\n-   鲁棒特征：$r \\sim \\mathcal{N}\\left(m \\, y' \\, \\mathbf{1}_p, \\, \\sigma_r^2 I_p\\right)$\n-   捷径特征：$s \\sim \\mathcal{N}\\left(\\alpha \\, y' \\, \\mathbf{1}_q, \\, \\sigma_s^2 I_q\\right)$\n\n在这里，$m$ 和 $\\alpha$ 分别控制鲁棒特征和捷径特征的信号强度。$\\sigma_r^2$ 和 $\\sigma_s^2$ 是它们的方差。为了效率，此过程使用向量化的 `numpy` 操作实现。为每个测试用例设置一个特定的随机种子，以确保数据及后续结果的可复现性。\n\n### 2. 模型架构\n\n分类器是一个单隐藏层神经网络 $f_\\theta$。输入维度为 $d = p+q$。其架构定义如下：\n$$\nh = \\phi(W_1 x + b_1)\n$$\n$$\n\\hat{y} = \\sigma(W_2^\\top h + b_2)\n$$\n其中：\n-   $x \\in \\mathbb{R}^d$ 是输入向量。\n-   $W_1 \\in \\mathbb{R}^{H \\times d}$ 和 $b_1 \\in \\mathbb{R}^{H}$ 分别是隐藏层的权重矩阵和偏置向量，其中 $H$ 是隐藏单元的数量。\n-   $\\phi(\\cdot)$ 是修正线性单元（ReLU）激活函数，$\\phi(z) = \\max(0, z)$。\n-   $h \\in \\mathbb{R}^{H}$ 是隐藏层的激活值。\n-   $W_2 \\in \\mathbb{R}^{H}$ 和 $b_2 \\in \\mathbb{R}$ 分别是输出层的权重向量和标量偏置。\n-   $\\sigma(\\cdot)$ 是逻辑S型函数（logistic sigmoid），$\\sigma(z) = (1 + e^{-z})^{-1}$，它将对数几率（logit）映射到概率 $\\hat{y} \\in [0,1]$。\n-   模型的参数为 $\\theta = (W_1, b_1, W_2, b_2)$。权重用小的随机值初始化，偏置初始化为零。\n\n### 3. 训练过程\n\n通过最小化经验风险来训练模型，即在训练集 $S = \\{(x_i, y_i)\\}_{i=1}^{n_{\\mathrm{train}}}$ 上的平均二元交叉熵损失：\n$$\nR_S(f_\\theta) = \\frac{1}{n_{\\mathrm{train}}} \\sum_{i=1}^{n_{\\mathrm{train}}} \\ell(\\sigma(W_2^\\top \\phi(W_1 x_i + b_1) + b_2), y_i)\n$$\n优化使用小批量随机梯度下降（SGD）进行。对于每个训练轮次（epoch），将训练数据打乱并分成多个小批量。对每个小批量：\n1.  **增强（有条件）**：如果 `train_suppress` 标志设置为 $1$，则对输入批次应用捷径抑制。这包括将捷径特征 $s$ 替换为从 $\\mathcal{N}(0, \\sigma_s^2 I_q)$ 抽取的噪声，从而迫使模型依赖鲁棒特征。\n2.  **前向传播**：将小批量数据通过网络以计算预测概率 $\\hat{y}$。\n3.  **损失计算**：计算二元交叉熵损失。在对数中加入一个小的 epsilon 项（$10^{-9}$），以确保数值稳定性。\n4.  **反向传播**：使用链式法则计算损失函数相对于所有参数的梯度（$\\nabla_{W_1} R_S$, $\\nabla_{b_1} R_S$, $\\nabla_{W_2} R_S$, $\\nabla_{b_2} R_S$）。ReLU 函数的导数对于正输入为 $1$，否则为 $0$。\n5.  **参数更新**：通过在负梯度方向上迈出一步来更新模型参数，步长由学习率 $\\eta$ 缩放：\n    $$\n    \\theta \\leftarrow \\theta - \\eta \\nabla_\\theta R_S(f_\\theta)\n    $$\n此过程重复指定的训练轮数 $E$。\n\n### 4. 评估与诊断\n\n训练后，在两种条件下评估模型在验证集上的性能：\n1.  **捷径可见 ($a_{\\mathrm{vis}}$)**：在原始验证集上计算模型的准确率。如果 $\\hat{y} \\ge 0.5$，则预测标签为 $1$，否则为 $0$。\n2.  **捷径被抑制 ($a_{\\mathrm{sup}}$)**：通过对每个样本应用捷径抑制增强 $A(x) = [r; \\tilde{s}]$（其中 $\\tilde{s} \\sim \\mathcal{N}(0, \\sigma_s^2 I_q)$）来创建一个修改后的验证集。然后在这个被抑制的数据集上计算模型的准确率。\n\n最终的诊断基于一组预定义的规则，使用阈值 $\\tau_h = 0.9$、$\\tau_\\ell = 0.7$ 和 $\\Delta = 0.25$：\n-   如果 $a_{\\mathrm{vis}} \\ge \\tau_h$ 且 $a_{\\mathrm{sup}} \\le \\tau_\\ell$ 且 $a_{\\mathrm{vis}} - a_{\\mathrm{sup}} \\ge \\Delta$，则模型被诊断为**对捷径的过拟合**（编码为 $1$）。这表明模型高度依赖不鲁棒的捷径。\n-   如果 $a_{\\mathrm{vis}}  \\tau_\\ell$ 且 $a_{\\mathrm{sup}}  \\tau_\\ell$，则模型被诊断为**欠拟合**（编码为 $-1$）。这表明模型未能从任何一种特征类型中学习到有意义的模式。\n-   否则，模型的行为被归类为**以上两者皆非**，通常表示鲁棒的泛化（编码为 $0$）。\n\n程序遍历每个测试用例，执行这些步骤，并将整数编码的诊断结果整理成一个最终列表。", "answer": "```python\nimport numpy as np\nfrom scipy.special import expit\n\nclass NeuralNetwork:\n    \"\"\"A one-hidden-layer neural network for binary classification.\"\"\"\n    def __init__(self, input_dim, hidden_dim):\n        \"\"\"\n        Initializes the parameters of the neural network.\n        \n        Args:\n            input_dim (int): Dimension of the input features (p+q).\n            hidden_dim (int): Number of units in the hidden layer (H).\n        \"\"\"\n        # Problem statement: W2 is a column vector, so W2.T is a row vector\n        self.W1 = np.random.randn(hidden_dim, input_dim) * 0.01\n        self.b1 = np.zeros((hidden_dim, 1))\n        self.W2 = np.random.randn(hidden_dim, 1) * 0.01\n        self.b2 = np.zeros((1, 1))\n        self.cache = {}\n\n    @staticmethod\n    def relu(z):\n        return np.maximum(0, z)\n\n    def forward(self, X):\n        \"\"\"\n        Performs the forward pass.\n        \n        Args:\n            X (np.ndarray): Input data of shape (input_dim, num_samples).\n        \n        Returns:\n            np.ndarray: Predicted probabilities of shape (1, num_samples).\n        \"\"\"\n        Z1 = self.W1 @ X + self.b1\n        A1 = self.relu(Z1)\n        Z2 = self.W2.T @ A1 + self.b2\n        A2 = expit(Z2) # Numerically stable sigmoid\n\n        self.cache = {'X': X, 'Z1': Z1, 'A1': A1, 'Z2': Z2, 'A2': A2}\n        return A2\n\n    def backward(self, Y):\n        \"\"\"\n        Performs the backward pass and computes gradients.\n        \n        Args:\n            Y (np.ndarray): True labels of shape (1, num_samples).\n        \"\"\"\n        num_samples = Y.shape[1]\n        X, A1, A2, Z1 = self.cache['X'], self.cache['A1'], self.cache['A2'], self.cache['Z1']\n\n        dZ2 = A2 - Y\n        self.dW2 = (1 / num_samples) * (A1 @ dZ2.T)\n        self.db2 = (1 / num_samples) * np.sum(dZ2, axis=1, keepdims=True)\n\n        dA1 = self.W2 @ dZ2\n        dZ1 = dA1 * (Z1 > 0)\n        self.dW1 = (1 / num_samples) * (dZ1 @ X.T)\n        self.db1 = (1 / num_samples) * np.sum(dZ1, axis=1, keepdims=True)\n\n    def update_params(self, learning_rate):\n        \"\"\"Updates parameters using computed gradients.\"\"\"\n        self.W1 -= learning_rate * self.dW1\n        self.b1 -= learning_rate * self.db1\n        self.W2 -= learning_rate * self.dW2\n        self.b2 -= learning_rate * self.db2\n\ndef generate_data(n_samples, p, q, m, alpha, sigma_r, sigma_s):\n    \"\"\"Generates synthetic data with robust and shortcut features.\"\"\"\n    y = np.random.randint(0, 2, size=(n_samples, 1))\n    y_prime = 2 * y - 1\n\n    # Generate robust features\n    mean_r_mat = y_prime @ np.ones((1, p)) * m\n    r = np.random.randn(n_samples, p) * sigma_r + mean_r_mat\n\n    # Generate shortcut features\n    mean_s_mat = y_prime @ np.ones((1, q)) * alpha\n    s = np.random.randn(n_samples, q) * sigma_s + mean_s_mat\n    \n    X = np.hstack((r, s))\n    return X, y\n\ndef apply_shortcut_suppression(X, q, sigma_s):\n    \"\"\"Applies shortcut suppression augmentation to data.\"\"\"\n    n_samples, _ = X.shape\n    p = X.shape[1] - q\n    r_features = X[:, :p]\n    noise = np.random.randn(n_samples, q) * sigma_s\n    return np.hstack((r_features, noise))\n\ndef solve():\n    \"\"\"Main function to run the test suite and produce the final output.\"\"\"\n    test_cases = [\n        (5, 3, 0.2, 4.0, 1.0, 1.0, 32, 50, 0.05, 0, 1337),\n        (5, 3, 0.6, 4.0, 1.0, 1.0, 32, 50, 0.05, 1, 2027),\n        (5, 3, 0.6, 4.0, 1.0, 1.0, 2, 5, 0.01, 1, 3037),\n        (5, 3, 1.5, 1.0, 1.0, 1.0, 32, 50, 0.05, 0, 4047),\n    ]\n\n    n_train = 3000\n    n_val = 3000\n    batch_size = 32\n    \n    tau_h = 0.9\n    tau_l = 0.7\n    delta = 0.25\n\n    results = []\n    \n    for case in test_cases:\n        p, q, m, alpha, sigma_r, sigma_s, H, E, eta, train_suppress, seed = case\n        \n        np.random.seed(seed)\n        \n        # 1. Generate Data\n        X_train, y_train = generate_data(n_train, p, q, m, alpha, sigma_r, sigma_s)\n        X_val, y_val = generate_data(n_val, p, q, m, alpha, sigma_r, sigma_s)\n\n        # 2. Initialize Model\n        input_dim = p + q\n        model = NeuralNetwork(input_dim, H)\n\n        # 3. Train Model\n        n_batches = int(np.ceil(n_train / batch_size))\n        for epoch in range(E):\n            permutation = np.random.permutation(n_train)\n            X_train_shuffled = X_train[permutation, :]\n            y_train_shuffled = y_train[permutation, :]\n\n            for i in range(n_batches):\n                start = i * batch_size\n                end = min(start + batch_size, n_train)\n                X_batch = X_train_shuffled[start:end, :]\n                y_batch = y_train_shuffled[start:end, :]\n                \n                # Apply shortcut suppression if required\n                if train_suppress == 1:\n                    X_batch = apply_shortcut_suppression(X_batch, q, sigma_s)\n                \n                # Transpose for model's expected shape (dim, samples)\n                X_batch_T = X_batch.T\n                y_batch_T = y_batch.T\n\n                # Forward, backward, update\n                _ = model.forward(X_batch_T)\n                model.backward(y_batch_T)\n                model.update_params(eta)\n\n        # 4. Evaluate Model\n        # a_vis: accuracy on validation set with shortcuts visible\n        y_hat_vis = model.forward(X_val.T)\n        predictions_vis = (y_hat_vis >= 0.5).astype(int)\n        a_vis = np.mean(predictions_vis == y_val.T)\n\n        # a_sup: accuracy on validation set with shortcuts suppressed\n        X_val_sup = apply_shortcut_suppression(X_val, q, sigma_s)\n        y_hat_sup = model.forward(X_val_sup.T)\n        predictions_sup = (y_hat_sup >= 0.5).astype(int)\n        a_sup = np.mean(predictions_sup == y_val.T)\n\n        # 5. Diagnose\n        diagnosis = 0 # Default: Neither\n        if a_vis >= tau_h and a_sup = tau_l and (a_vis - a_sup) >= delta:\n            diagnosis = 1 # Overfitting to shortcuts\n        elif a_vis  tau_l and a_sup  tau_l:\n            diagnosis = -1 # Underfitting\n            \n        results.append(diagnosis)\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3135726"}]}