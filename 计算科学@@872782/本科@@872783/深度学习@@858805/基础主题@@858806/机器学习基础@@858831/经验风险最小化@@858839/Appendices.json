{"hands_on_practices": [{"introduction": "理论学习的最佳补充是动手实践。理解经验风险最小化（ERM）最直观的方法，莫过于在一个简单的数据集上亲手计算。这个练习将引导你找到一个能使训练错误数量最小化的决策边界，即经验风险最小化的解。同时，你将发现这个解有时会与一个更稳健的模型（例如最大化决策边界间隔的模型）相冲突，这揭示了机器学习中一个核心的权衡。[@problem_id:3121461]", "problem": "你将设计并分析一个从重叠高斯类中抽取的一维玩具数据集，并计算线性分类器在 0-1 损失下的经验风险最小化器。然后，你将把这个解与间隔最大化阈值进行对比，以说明经验风险最小化和间隔最大化之间的张力关系。\n\n一位数据科学家对两个二元类进行如下建模。对于标签 $y = +1$，特征 $x \\in \\mathbb{R}$ 从高斯分布 $\\mathcal{N}(\\mu_{+}, \\sigma_{+}^{2})$ 中独立抽取；对于标签 $y = -1$，特征从 $\\mathcal{N}(\\mu_{-}, \\sigma_{-}^{2})$ 中独立抽取。由于 $\\mu_{+}$ 和 $\\mu_{-}$ 很接近且 $\\sigma_{+}, \\sigma_{-}  0$，类条件分布会发生重叠。观测到一个包含 $n = 6$ 个带标签样本的数据集：\n- 对于 $y = +1$：三个样本 $x = -0.8, \\; 0.2, \\; 0.3$。\n- 对于 $y = -1$：三个样本 $x = -1.1, \\; 0.5, \\; 1.0$。\n\n考虑由阈值 $s \\in \\mathbb{R}$ 参数化的一维线性分类器族：\n$$\nh_{s}(x) = \\operatorname{sign}(x - s),\n$$\n如果 $x \\ge s$，该分类器预测为 $+1$，否则预测为 $-1$。在 0-1 损失下的经验风险为\n$$\n\\hat{R}(s) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}\\!\\left\\{ y_{i} \\ne h_{s}(x_{i}) \\right\\}。\n$$\n任务：\n1. 仅使用上述定义，确定在 $s \\in \\mathbb{R}$ 上最小化 $\\hat{R}(s)$ 的经验风险最小化器 $s^{\\star}$。如果存在一个 $s$ 值的区间都能达到相同的最小经验风险，则选择该区间的中点作为规范最小化器。\n2. 在你的推理过程中（而非最终报告的值中），通过找出在一维空间中最大化几何间隔的阈值 $s_{\\mathrm{m}}$（定义为 $w = 1$ 和 $b = -s$，因此间隔等于 $\\min_{i} |x_{i} - s|$），并比较 $\\hat{R}(s^{\\star})$ 和 $\\hat{R}(s_{\\mathrm{m}})$，来展示经验风险和间隔最大化之间的张力关系。\n\n只需以精确形式报告 $s^{\\star}$ 的值作为你的最终答案；无需四舍五入。", "solution": "问题需要经过验证。\n1.  **提取已知条件**：\n    -   带有标签 $y \\in \\{+1, -1\\}$ 的二元类。\n    -   类条件分布：$y=+1 \\implies x \\sim \\mathcal{N}(\\mu_{+}, \\sigma_{+}^{2})$；$y=-1 \\implies x \\sim \\mathcal{N}(\\mu_{-}, \\sigma_{-}^{2})$。\n    -   $n=6$ 个样本的数据集：\n        -   $y=+1$: $x \\in \\{-0.8, 0.2, 0.3\\}$。\n        -   $y=-1$: $x \\in \\{-1.1, 0.5, 1.0\\}$。\n    -   分类器族：$h_{s}(x) = \\operatorname{sign}(x-s)$，并明确说明如果 $x \\ge s$ 则预测为 $+1$，否则预测为 $-1$。\n    -   经验风险（0-1 损失）：$\\hat{R}(s) = \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{1}\\!\\left\\{ y_{i} \\ne h_{s}(x_{i}) \\right\\}$。\n    -   任务 1：找到经验风险最小化器 $s^{\\star}$，如果最小值是在一个区间上达到的，则选择该区间的中点。\n    -   任务 2：在推理过程中，找到间隔最大化的阈值 $s_{\\mathrm{m}}$，并比较 $\\hat{R}(s^{\\star})$ 与 $\\hat{R}(s_{\\mathrm{m}})$。\n\n2.  **验证**：\n    -   该问题在统计学习理论的既定原则（特别是经验风险最小化和间隔理论）上具有**科学依据**。\n    -   该问题是**提法恰当的**，所有必要的数据和定义都已提供。数据集是有限的，分类器族是明确的，目标函数有清晰的定义。选择唯一最小化器（区间中点）的规则确保了唯一解的存在。\n    -   该问题是**客观的**，并使用了精确的数学语言。\n    -   它没有违反任何无效性标准。这是机器学习基础中的一个标准、可形式化的练习。\n\n3.  **结论**：该问题有效且自洽。\n\n我们开始解题。\n\n目标是找到一个阈值 $s \\in \\mathbb{R}$，以最小化经验风险 $\\hat{R}(s)$。由于样本量 $n=6$ 是一个常数，最小化 $\\hat{R}(s)$ 等价于最小化错分样本的数量 $N_{err}(s) = n \\cdot \\hat{R}(s)$。\n\n分类器定义为：如果 $x \\ge s$，则 $h_s(x) = +1$；如果 $x  s$，则 $h_s(x) = -1$。一个点 $(x_i, y_i)$ 被错分，如果：\n-   $y_i = +1$ 且 $h_s(x_i) = -1$，这发生在 $x_i  s$ 时。\n-   $y_i = -1$ 且 $h_s(x_i) = +1$，这发生在 $x_i \\ge s$ 时。\n\n令 $X_{+} = \\{-0.8, 0.2, 0.3\\}$ 为标签 $y=+1$ 的点集，令 $X_{-} = \\{-1.1, 0.5, 1.0\\}$ 为标签 $y=-1$ 的点集。对于给定的阈值 $s$，错分数量为：\n$$\nN_{err}(s) = \\sum_{x_i \\in X_{+}} \\mathbf{1}\\{x_i  s\\} + \\sum_{x_j \\in X_{-}} \\mathbf{1}\\{x_j \\ge s\\}\n$$\n$N_{err}(s)$ 的值是一个阶跃函数，其值仅在 $s$ 取值为数据点 $x_i$ 时才会发生变化。我们通过考虑由排序后的数据点定义的区间来分析错误数量。\n排序后的数据点为：$p_1 = -1.1\\;(y=-1)$, $p_2 = -0.8\\;(y=+1)$, $p_3 = 0.2\\;(y=+1)$, $p_4 = 0.3\\;(y=+1)$, $p_5 = 0.5\\;(y=-1)$, $p_6 = 1.0\\;(y=-1)$。\n\n我们针对不同的 $s$ 范围来评估 $N_{err}(s)$：\n-   对于 $s \\le -1.1$：所有数据点 $x_i$ 都满足 $x_i \\ge s$，因此对所有 $i$ 都有 $h_s(x_i) = +1$。$X_{-}$ 中的三个点被错分。$X_{+}$ 中的三个点被正确分类。因此，$N_{err}(s) = 3$。\n-   对于 $s \\in (-1.1, -0.8]$：\n    -   点 $x=-1.1 \\in X_{-}$ 被正确分类为 $h_s(-1.1)=-1$，因为 $-1.1  s$。\n    -   点 $x=\\{0.5, 1.0\\} \\in X_{-}$ 被错分为 $h_s(x)=+1$，因为 $x > s$。\n    -   所有 $x \\in X_{+}$ 的点都满足 $x > s$ (except at s=-0.8)，因此它们被正确分类为 $h_s(x)=+1$。\n    -   错分总数为 $N_{err}(s) = 0 + 2 = 2$。\n    -   这对于半开区间 $(-1.1, -0.8]$ 中的任何 $s$ 都成立。当 $s=-0.8$ 时，点 $x=-0.8 \\in X_+$ 被正确分类，因为 $-0.8 \\ge s$。错误仍然是来自 $X_-$ 的那两个点。\n-   对于 $s \\in (-0.8, 0.2]$：\n    -   点 $x=-0.8 \\in X_{+}$ 现在被错分为 $h_s(-0.8)=-1$，因为 $-0.8  s$。\n    -   点 $x=\\{0.2, 0.3\\} \\in X_{+}$ 被正确分类。\n    -   点 $x=\\{0.5, 1.0\\} \\in X_{-}$ 被错分。点 $x=-1.1 \\in X_{-}$ 被正确分类。\n    -   错分总数为 $N_{err}(s) = 1 + 2 = 3$。\n-   对于 $s \\in (0.2, 0.3]$: $N_{err}(s) = 2$ (来自 $X_+$) $+ 2$ (来自 $X_-$) $= 4$。\n-   对于 $s \\in (0.3, 0.5]$: $N_{err}(s) = 3$ (来自 $X_+$) $+ 2$ (来自 $X_-$) $= 5$。\n-   对于 $s \\in (0.5, 1.0]$: $N_{err}(s) = 3$ (来自 $X_+$) $+ 1$ (来自 $X_-$) $= 4$。\n-   对于 $s > 1.0$: $N_{err}(s) = 3$ (来自 $X_+$) $+ 0$ (来自 $X_-$) $= 3$。\n\n经检查，最小错误数为 $N_{err, min} = 2$。对于区间 $(-1.1, -0.8]$ 中的任何阈值 $s$ 都可以达到这个最小值。\n题目要求选择该区间的中点作为规范最小化器 $s^{\\star}$。\n$$\ns^{\\star} = \\frac{-1.1 + (-0.8)}{2} = \\frac{-1.9}{2} = -0.95\n$$\n最小经验风险为 $\\hat{R}(s^{\\star}) = \\frac{2}{6} = \\frac{1}{3}$。\n\n接下来，我们找出间隔最大化阈值 $s_{\\mathrm{m}}$，以展示经验风险和间隔之间的张力关系。间隔定义为 $\\min_{i} |x_i - s|$。为了最大化这个最小距离，阈值 $s$ 必须位于排序后列表中任意两个连续数据点之间最大间隙的中点。\n排序后的数据点为 $\\{-1.1, -0.8, 0.2, 0.3, 0.5, 1.0\\}$。\n连续点之间的间隙为：\n-   $-0.8 - (-1.1) = 0.3$\n-   $0.2 - (-0.8) = 1.0$\n-   $0.3 - 0.2 = 0.1$\n-   $0.5 - 0.3 = 0.2$\n-   $1.0 - 0.5 = 0.5$\n\n最大的间隙是 $1.0$，位于点 $x=-0.8$ 和 $x=0.2$ 之间。间隔最大化阈值 $s_{\\mathrm{m}}$ 是该区间的中点：\n$$\ns_{\\mathrm{m}} = \\frac{-0.8 + 0.2}{2} = \\frac{-0.6}{2} = -0.3\n$$\n最大间隔为 $\\frac{1.0}{2} = 0.5$。\n\n现在我们计算这个间隔最大化阈值 $s_{\\mathrm{m}} = -0.3$ 的经验风险：\n$N_{err}(s_{\\mathrm{m}}) = N_{err}(-0.3)$。\n-   来自 $X_{+}=\\{-0.8, 0.2, 0.3\\}$ 的错分点：\n    -   $x=-0.8  -0.3 \\implies$ 分类为 $-1$。错分。\n-   来自 $X_{-}=\\{-1.1, 0.5, 1.0\\}$ 的错分点：\n    -   $x=0.5 \\ge -0.3 \\implies$ 分类为 $+1$。错分。\n    -   $x=1.0 \\ge -0.3 \\implies$ 分类为 $+1$。错分。\n$s_{\\mathrm{m}}$ 的总错分数量为 $1 + 2 = 3$。经验风险为 $\\hat{R}(s_{\\mathrm{m}}) = \\frac{3}{6} = \\frac{1}{2}$。\n\n现在的张力关系就很明显了：\n-   经验风险最小化器 $s^{\\star} = -0.95$ 达到了最低的可能训练误差 ($\\hat{R}(s^{\\star}) = \\frac{1}{3}$)，但它定义的决策边界非常接近数据点 $x=-1.1$ 和 $x=-0.8$。其间隔为 $|-0.95 - (-1.1)| = 0.15$。小间隔可能意味着过拟合和差的泛化能力。\n-   间隔最大化阈值 $s_{\\mathrm{m}} = -0.3$ 通过将边界置于特征空间中最大的空白区域，得到了 $0.5$ 的更大间隔。这是一个更鲁棒的解，但代价是在训练数据上有更高的经验风险 ($\\hat{R}(s_{\\mathrm{m}}) = \\frac{1}{2}$)。\n\n这说明了统计学习中最小化训练误差与为更好的泛化能力而最大化间隔之间的基本权衡，这是支持向量机（Support Vector Machines）背后的核心概念。纯粹最小化经验风险的解 ($s^{\\star}$) 与最大化间隔的解 ($s_{\\mathrm{m}}$) 是不同的。\n\n最终答案仅为 $s^{\\star}$ 的值。\n$s^{\\star} = -0.95 = -\\frac{95}{100} = -\\frac{19}{20}$。", "answer": "$$\n\\boxed{-\\frac{19}{20}}\n$$", "id": "3121461"}, {"introduction": "在深度学习中，我们通常不依赖手动检查所有可能的解，而是使用梯度下降等优化算法来最小化经验风险。这个练习将向你展示为何模型的数学属性，特别是激活函数的光滑性，对于梯度下降法的成功至关重要。通过比较阶跃函数和光滑近似函数（如Softplus和ELU）的效果，你将亲眼见证不可微的激活函数如何阻碍学习过程，而光滑函数又是如何使其成为可能。[@problem_id:3121425]", "problem": "考虑一个在经验风险最小化（ERM）框架下的深度学习一维二元分类任务。使用的基本要素是经验风险的定义、平方误差损失和批量梯度下降。设数据集为 $$\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^n$$，其中 $$x_i \\in \\mathbb{R}$$ 且 $$y_i \\in \\{0,1\\}$$。定义 $$n = 21$$，$$x_i$$ 为从 $$-2$$ 到 $$2$$ 且间距为 $$0.2$$ 的等间距点，即 $$x_i \\in \\{-2.0,-1.8,-1.6,\\dots,1.8,2.0\\}$$。令 $$y_i = \\mathbb{1}[x_i \\ge 0.5]$$，其中 $$\\mathbb{1}[\\cdot]$$ 表示指示函数。考虑一个单神经元模型 $$f(x) = a(w x + b)$$，其中标量参数 $$w \\in \\mathbb{R}$$ 和 $$b \\in \\mathbb{R}$$，激活函数 $$a(\\cdot)$$ 选自：\n- Heaviside 阶跃函数 $$H(z)$$，当 $$z \\ge 0$$ 时 $$H(z) = 1$$，否则 $$H(z) = 0$$，\n- Softplus 函数 $$s(z) = \\log(1 + e^{z})$$，\n- 指数线性单元（ELU）$$e_{\\alpha}(z) = \\begin{cases} z   \\text{if } z  0 \\\\ \\alpha(\\exp(z) - 1)   \\text{if } z \\le 0 \\end{cases}$$，其中 $$\\alpha = 1$$。\n\n需要最小化的经验风险是均方误差 $$\\hat{R}(f) = \\frac{1}{n} \\sum_{i=1}^{n} \\left(f(x_i) - y_i\\right)^2$$。仅从这些定义出发，推导基于 $$\\hat{R}(f)$$ 以及所选激活函数的数学性质的批量梯度下降的参数更新规则。分析 $$H(z)$$ 的非光滑性如何影响优化器的敏感性，并展示通过 $$s(z)$$ 或 $$e_{\\alpha}(z)$$ 进行平滑处理如何改变经验风险曲面，从而使基于梯度的优化更加有效。\n\n实现一个完整、可运行的程序，该程序：\n- 完全按照规定构建 $$\\mathcal{D}$$，\n- 针对给定的激活函数选择、学习率和初始化，执行固定迭代次数的批量梯度下降，\n- 返回每个测试用例训练后的最终经验风险 $$\\hat{R}(f)$$。\n\n使用以下参数元组的测试套件 $$\\left(a,\\eta,w_0,b_0,T\\right)$$，其中 $$a$$ 是激活函数名称，$$\\eta$$ 是学习率，$$w_0$$ 和 $$b_0$$ 是初始参数，$$T$$ 是迭代次数：\n1. $$\\left(\\text{step},\\,0.1,\\,0.1,\\,0.0,\\,200\\right)$$\n2. $$\\left(\\text{softplus},\\,0.1,\\,0.1,\\,0.0,\\,200\\right)$$\n3. $$\\left(\\text{elu},\\,0.1,\\,0.1,\\,0.0,\\,200\\right)$$\n4. $$\\left(\\text{softplus},\\,0.001,\\,0.1,\\,0.0,\\,2000\\right)$$\n5. $$\\left(\\text{softplus},\\,1.0,\\,0.1,\\,0.0,\\,50\\right)$$\n6. $$\\left(\\text{step},\\,0.1,\\,0.0,\\,0.0,\\,200\\right)$$\n\n你的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个条目是对应测试用例的最终经验风险 $$\\hat{R}(f)$$，以十进制形式表示。例如，输出格式必须严格为 $$[r_1,r_2,r_3,r_4,r_5,r_6]$$，其中每个 $$r_j$$ 是一个浮点数。", "solution": "该问题要求对指定一维数据集上的单神经元二元分类器进行经验风险最小化（ERM）的分析和实现。我们将首先验证问题的有效性，然后推导批量梯度下降所需的数学公式，分析不同激活函数的作用，最后展示实现代码。\n\n问题陈述提供了以下已知条件：\n- 数据集 $\\mathcal{D} = \\{(x_i, y_i)\\}_{i=1}^n$，其中 $n = 21$。\n- 输入 $x_i$ 是从 $-2$ 到 $2$ 且间距为 $0.2$ 的等间距点。\n- 标签 $y_i$ 由指示函数 $y_i = \\mathbb{1}[x_i \\ge 0.5]$ 定义。\n- 单神经元模型 $f(x) = a(w x + b)$，其中标量参数 $w, b \\in \\mathbb{R}$。\n- 提供了三种激活函数 $a(\\cdot)$ 的选择：Heaviside 阶跃函数 $H(z)$、Softplus 函数 $s(z) = \\log(1 + e^{z})$ 和指数线性单元（ELU）$e_{\\alpha}(z)$（其中 $\\alpha=1$）。\n- 经验风险是均方误差（MSE）：$\\hat{R}(f) = \\frac{1}{n} \\sum_{i=1}^{n} \\left(f(x_i) - y_i\\right)^2$。\n- 优化算法是批量梯度下降。\n- 为实现提供了一个参数 $(a, \\eta, w_0, b_0, T)$ 的测试套件。\n\n该问题具有科学依据，定义明确且客观。这是机器学习中的一个标准练习，旨在探讨基于梯度的优化对可微性的基本要求。包含不可微的 Heaviside 函数是一个有意的教学选择，目的是将其行为与 Softplus 和 ELU 等平滑激活函数的行为进行对比。该问题是自包含的，并为获得唯一解提供了所有必要信息。因此，该问题被认为是有效的。\n\n我们接下来推导批量梯度下降的参数更新规则。目标是相对于参数 $w$ 和 $b$ 最小化经验风险 $\\hat{R}(w, b)$。\n令 $z_i = w x_i + b$ 为第 $i$ 个数据点的预激活值。经验风险为：\n$$\n\\hat{R}(w, b) = \\frac{1}{n} \\sum_{i=1}^{n} \\left(a(z_i) - y_i\\right)^2\n$$\n为了应用梯度下降，我们需要 $\\hat{R}$ 关于 $w$ 和 $b$ 的偏导数。根据链式法则：\n$$\n\\frac{\\partial \\hat{R}}{\\partial w} = \\frac{\\partial}{\\partial w} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} \\left(a(z_i) - y_i\\right)^2 \\right] = \\frac{1}{n} \\sum_{i=1}^{n} 2 \\left(a(z_i) - y_i\\right) \\frac{\\partial a(z_i)}{\\partial w}\n$$\n激活项的导数是 $\\frac{\\partial a(z_i)}{\\partial w} = \\frac{d a}{d z_i} \\frac{\\partial z_i}{\\partial w} = a'(z_i) \\cdot x_i$。将其代入，我们得到：\n$$\n\\frac{\\partial \\hat{R}}{\\partial w} = \\frac{2}{n} \\sum_{i=1}^{n} \\left(a(z_i) - y_i\\right) a'(z_i) x_i\n$$\n类似地，对于参数 $b$，我们有 $\\frac{\\partial z_i}{\\partial b} = 1$。其偏导数为：\n$$\n\\frac{\\partial \\hat{R}}{\\partial b} = \\frac{\\partial}{\\partial b} \\left[ \\frac{1}{n} \\sum_{i=1}^{n} \\left(a(z_i) - y_i\\right)^2 \\right] = \\frac{2}{n} \\sum_{i=1}^{n} \\left(a(z_i) - y_i\\right) a'(z_i)\n$$\n对于学习率为 $\\eta$ 的迭代 $t$，批量梯度下降的更新规则是：\n$$\nw_{t+1} = w_t - \\eta \\frac{\\partial \\hat{R}}{\\partial w} \\bigg|_{w_t, b_t}\n$$\n$$\nb_{t+1} = b_t - \\eta \\frac{\\partial \\hat{R}}{\\partial b} \\bigg|_{w_t, b_t}\n$$\n这个过程的可行性关键取决于激活函数的导数 $a'(z)$。我们现在分析每种情况。\n\n1.  **Heaviside 阶跃函数**：$H(z) = \\mathbb{1}[z \\ge 0]$。\n    Heaviside 函数的导数是 Dirac delta 函数 $\\delta(z)$，它对于所有 $z \\ne 0$ 等于 $0$，并在 $z=0$ 处无定义。在任何实际实现中，点不太可能恰好落在 $z=0$ 上。即使如此，梯度也是未定义的。一种常见的做法是使用次梯度，而对所有点的导数最直接的选择是 $H'(z) = 0$。这样一来，无论误差 $(a(z_i) - y_i)$ 是多少，梯度 $\\frac{\\partial \\hat{R}}{\\partial w}$ 和 $\\frac{\\partial \\hat{R}}{\\partial b}$ 都变为零。\n    **分析**：经验风险曲面 $\\hat{R}(w, b)$ 变成一个分段常数函数，由平坦的高台组成。在这些高台上，梯度处处为零。因此，梯度下降无法取得进展；参数 $w$ 和 $b$ 保持其初始值不变。这说明了基于梯度的方法的一个基本局限性：它们在几乎处处梯度为零的非光滑曲面上是无效的。\n\n2.  **Softplus**：$s(z) = \\log(1 + e^z)$。\n    其导数是 $s'(z) = \\frac{e^z}{1 + e^z}$，即逻辑 Sigmoid 函数 $\\sigma(z)$。\n    **分析**：导数 $s'(z)$ 在所有 $z \\in \\mathbb{R}$ 上都有良好定义、连续且严格为正。这确保了经验风险曲面 $\\hat{R}(w, b)$ 是光滑的（无限可微）。$w$ 和 $b$ 的梯度有良好定义且通常不为零，为优化器向最小值下降提供了路径。Softplus 函数有效地“平滑”了阶跃函数的硬阈值，使得损失景观适用于基于梯度的优化。\n\n3.  **ELU (当 $\\alpha=1$ 时)**：$e_1(z) = \\begin{cases} z   \\text{if } z > 0 \\\\ e^z - 1   \\text{if } z \\le 0 \\end{cases}$。\n    其导数为 $e'_1(z) = \\begin{cases} 1   \\text{if } z > 0 \\\\ e^z   \\text{if } z \\le 0 \\end{cases}$。\n    在 $z=0$ 处，导数的左极限是 $\\lim_{z \\to 0^-} e^z = 1$，右极限是 $1$。因此，该函数处处连续可微（C1光滑），且 $e'_1(0) = 1$。\n    **分析**：与 Softplus 类似，ELU 提供了光滑的风险曲面。其导数是连续且非零的（除了 $z \\to -\\infty$），使得梯度下降能够有效运作。对于 $z > 0$，导数恒为 $1$ 可以防止梯度消失，这个特性在更深层的网络中很有用。与 Softplus 一样，它作为不连续激活函数的光滑替代品，使成功的优化成为可能。\n\n实现部分将展示这些理论性质。对于 Heaviside 函数，我们预期最终风险将与初始风险相同。对于 Softplus 和 ELU，我们预期风险会随着迭代而降低。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates batch gradient descent for a single-neuron model\n    with different activation functions as specified in the problem.\n    \"\"\"\n\n    # --- 1. Dataset Construction ---\n    n = 21\n    x = np.linspace(-2.0, 2.0, n)\n    y = (x = 0.5).astype(float)\n\n    # --- 2. Activation Functions and Their Derivatives ---\n    def heaviside(z):\n        return (z = 0).astype(float)\n\n    def heaviside_prime(z):\n        # The derivative is 0 almost everywhere. We define the subgradient to be 0\n        # at z=0 for numerical stability, which reflects the failure of\n        # gradient descent with step functions.\n        return np.zeros_like(z)\n\n    def softplus(z):\n        # Clip to avoid overflow for large z in np.exp(z)\n        z = np.clip(z, -500, 500)\n        return np.log(1 + np.exp(z))\n\n    def softplus_prime(z):\n        # Sigmoid function. Clip to avoid overflow/underflow.\n        z = np.clip(z, -500, 500)\n        exp_z = np.exp(z)\n        return exp_z / (1 + exp_z)\n\n    def elu(z, alpha=1.0):\n        return np.where(z  0, z, alpha * (np.exp(z) - 1))\n\n    def elu_prime(z, alpha=1.0):\n        return np.where(z  0, 1.0, alpha * np.exp(z))\n\n\n    activations = {\n        'step': (heaviside, heaviside_prime),\n        'softplus': (softplus, softplus_prime),\n        'elu': (lambda z: elu(z, 1.0), lambda z: elu_prime(z, 1.0))\n    }\n\n    # --- 3. Test Cases ---\n    test_cases = [\n        ('step', 0.1, 0.1, 0.0, 200),\n        ('softplus', 0.1, 0.1, 0.0, 200),\n        ('elu', 0.1, 0.1, 0.0, 200),\n        ('softplus', 0.001, 0.1, 0.0, 2000),\n        ('softplus', 1.0, 0.1, 0.0, 50),\n        ('step', 0.1, 0.0, 0.0, 200)\n    ]\n\n    results = []\n\n    # --- 4. Main Loop for Batch Gradient Descent ---\n    for case in test_cases:\n        act_name, eta, w0, b0, T = case\n        w, b = w0, b0\n        \n        activation_func, activation_prime = activations[act_name]\n\n        for _ in range(T):\n            # Forward pass\n            z = w * x + b\n            f_x = activation_func(z)\n            \n            # Calculate error\n            error = f_x - y\n\n            # Calculate derivative of activation\n            a_prime = activation_prime(z)\n\n            # Calculate gradients for w and b\n            grad_w = (2 / n) * np.sum(error * a_prime * x)\n            grad_b = (2 / n) * np.sum(error * a_prime)\n\n            # Update parameters\n            w -= eta * grad_w\n            b -= eta * grad_b\n            \n        # After training, calculate the final empirical risk\n        final_predictions = activation_func(w * x + b)\n        final_risk = np.mean((final_predictions - y)**2)\n        results.append(final_risk)\n\n    # --- 5. Output Formatting ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3121425"}, {"introduction": "最后一个练习将探讨一个更高级的场景，其中对经验风险最小化的朴素应用可能适得其反。我们将进入半监督学习的领域，通过“自训练”方法，让模型从自身的预测中学习。这个模拟将揭示“确认偏差”现象：模型对其最初的错误变得过度自信，导致增强数据集上的经验风险下降，但真实测试风险反而上升。这个练习强调了批判性地评估用于经验风险最小化的数据来源的重要性。[@problem_id:3121468]", "problem": "给定一个二元分类场景，其中经验风险最小化（ERM）与通过伪标签进行的自训练相结合。您的任务是实现一个确定性模拟，以展示在由伪标签增强的数据集上最小化经验风险 $\\hat{R}(f)$ 如何导致确认偏差，并评估使用置信度阈值和熵惩罚的缓解策略。\n\n需要使用的基本原理和定义：\n- 经验风险最小化（ERM）旨在最小化经验风险 $\\hat{R}(f)$，该风险定义为点态损失 $\\ell$ 在样本上的平均值。对于标签 $y \\in \\{0,1\\}$ 的二元分类问题和一个产生概率 $p = f(x) \\in [0,1]$ 的分类器 $f$，使用交叉熵损失 $\\ell(f(x), y)$。\n- 逻辑回归将概率建模为 $p = \\sigma(z)$，其中 $z = \\mathbf{w}^{\\top}\\mathbf{x} + b$，$\\mathbf{w} \\in \\mathbb{R}^{d}$ 是权重向量，$b \\in \\mathbb{R}$ 是偏置，$\\sigma(u) = \\frac{1}{1 + e^{-u}}$ 是 sigmoid 函数。\n- 使用伪标签的自训练通过为未标记样本分配标签来扩充已标记数据集，分配依据是当前模型的预测，且这些预测被认为具有足够的置信度。\n- 当模型自身的有偏预测被伪标签强化时，就会出现确认偏差，导致增强训练集上的经验风险下降，而真实风险（在带有真实标签的独立测试集上评估）却上升。\n\n数据生成与模拟设置：\n- 生成一个具有类条件高斯分布的二维二元分类数据集。对于类别 $0$，从 $\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_0, \\boldsymbol{\\Sigma})$ 中采样，其中 $\\boldsymbol{\\mu}_0 = [-1, 0]$ 且 $\\boldsymbol{\\Sigma} = \\operatorname{diag}([1, 1])$。对于类别 $1$，从 $\\mathbf{x} \\sim \\mathcal{N}(\\boldsymbol{\\mu}_1, \\boldsymbol{\\Sigma})$ 中采样，其中 $\\boldsymbol{\\mu}_1 = [1, 0]$ 且协方差矩阵相同。为保证可复现性，使用固定的随机种子 $42$。\n- 构建三个数据集：一个大小为 $n_L = 20$ 的已标记集 $\\mathcal{D}_L$，其构成不平衡（类别 $0$ 有 $18$ 个样本，类别 $1$ 有 $2$ 个样本）；一个大小为 $n_U = 1000$ 的未标记样本池 $\\mathcal{D}_U$，其类别比例均等，但标签对学习器隐藏；以及一个大小为 $n_T = 200$ 的测试集 $\\mathcal{D}_T$，其类别比例均等，且标签可用于评估。\n- 仅在 $\\mathcal{D}_L$ 上通过梯度下降训练一个逻辑回归分类器，最小化平均交叉熵损失，并对 $\\mathbf{w}$ 使用 $\\ell_2$ 正则化器，系数为 $\\lambda = 0.01$。使用学习率 $\\eta = 0.1$ 和 $200$ 个轮次。将此初始分类器记为 $f_0$，其参数为 $(\\mathbf{w}_0, b_0)$。\n\n每个测试用例的自训练协议：\n- 给定 $f_0$，为所有 $\\mathbf{x} \\in \\mathcal{D}_U$ 计算概率 $p = f_0(\\mathbf{x})$。选择置信度超过阈值 $\\tau \\in (0.5, 1)$ 的样本作为伪标签样本，即满足 $\\max(p, 1-p) \\ge \\tau$ 的样本。为选定的样本分配伪标签 $\\tilde{y} = \\mathbb{I}[p \\ge 0.5]$。令 $\\mathcal{D}_P \\subseteq \\mathcal{D}_U$ 为此选定的子集。\n- 构建增强数据集 $\\mathcal{D}_A = \\mathcal{D}_L \\cup \\mathcal{D}_P$，并使用以下目标函数，从 $(\\mathbf{w}_0, b_0)$ 开始训练一个分类器 $f_1$，额外进行 $200$ 个轮次：\n  - 最小化损失之和，该损失由 $\\mathcal{D}_L$ 上的平均交叉熵与 $\\mathcal{D}_P$ 上带权重 $\\alpha \\ge 0$ 的加权平均交叉熵组成。\n  - 对 $\\mathcal{D}_P$ 上的预测添加一个熵惩罚项，其系数为 $\\gamma \\ge 0$，定义为 $-\\gamma \\cdot \\frac{1}{|\\mathcal{D}_P|} \\sum_{\\mathbf{x} \\in \\mathcal{D}_P} H(f(\\mathbf{x}))$，其中 $H(p) = -[p \\log p + (1-p)\\log(1-p)]$ 是伯努利分布的熵；此项鼓励更高的熵（即减少预测的过分自信）。\n  - 保持对 $\\mathbf{w}$ 的 $\\ell_2$ 正则化，系数为 $\\lambda$。\n- 计算自训练前的经验训练风险为 $\\hat{R}_{\\text{before}} = \\frac{1}{|\\mathcal{D}_L|} \\sum_{(\\mathbf{x}, y) \\in \\mathcal{D}_L} \\ell(f_0(\\mathbf{x}), y)$，以及自训练后的经验训练风险为 $\\hat{R}_{\\text{after}} = \\frac{1}{|\\mathcal{D}_A|} \\sum_{(\\mathbf{x}, y) \\in \\mathcal{D}_A} \\ell(f_1(\\mathbf{x}), y)$，其中对于 $\\mathcal{D}_P$ 使用的是伪标签 $\\tilde{y}$。\n- 计算自训练前后的测试风险，分别为 $R^{\\text{test}}_{\\text{before}} = \\frac{1}{|\\mathcal{D}_T|} \\sum_{(\\mathbf{x}, y) \\in \\mathcal{D}_T} \\ell(f_0(\\mathbf{x}), y)$ 和 $R^{\\text{test}}_{\\text{after}} = \\frac{1}{|\\mathcal{D}_T|} \\sum_{(\\mathbf{x}, y) \\in \\mathcal{D}_T} \\ell(f_1(\\mathbf{x}), y)$，使用 $\\mathcal{D}_T$ 的真实标签。\n- 为该测试用例定义一个确认偏差的布尔指标为 $\\text{CB} = [\\hat{R}_{\\text{after}}  \\hat{R}_{\\text{before}}] \\wedge [R^{\\text{test}}_{\\text{after}} > R^{\\text{test}}_{\\text{before}}]$。\n\n测试套件：\n对于以下每个参数三元组 $(\\tau, \\alpha, \\gamma)$，运行自训练协议并计算 $\\text{CB}$：\n1. $(\\tau = 0.5, \\alpha = 3.0, \\gamma = 0.0)$: 一个宽松的阈值，伪标签影响强，预计会加剧确认偏差。\n2. $(\\tau = 0.9, \\alpha = 1.0, \\gamma = 0.0)$: 一个更严格的阈值，影响适中，预计会缓解确认偏差。\n3. $(\\tau = 0.95, \\alpha = 1.0, \\gamma = 0.2)$: 一个高阈值，并带有熵惩罚以鼓励减少过分自信，预计会缓解确认偏差。\n4. $(\\tau = 0.7, \\alpha = 5.0, \\gamma = 0.0)$: 一个中等阈值，伪标签影响非常强，用于测试偏差放大的边缘情况。\n5. $(\\tau = 0.999, \\alpha = 1.0, \\gamma = 0.1)$: 一个近乎退化的阈值，几乎不选择任何伪标签，用于测试无增强的边界情况。\n\n答案规范：\n- 您的程序必须实现上述确定性模拟，并针对有序测试套件 $(1)$ 到 $(5)$，生成一行输出。该输出包含一个布尔值列表 $\\text{CB}$，格式为方括号内以逗号分隔的列表，例如 $[\\text{True},\\text{False},\\dots]$。\n- 不涉及物理单位或角度单位。所有报告的值均为布尔值。", "solution": "用户要求在二元分类背景下，对使用伪标签的自训练进行确定性模拟，以展示和分析确认偏差。该问题具有科学依据，定义明确，并为完整实现提供了所有必要的参数和定义。\n\n解决方案首先实现指定的数据生成协议，然后开发一个能够通过梯度下降进行训练的逻辑回归模型。根据问题描述，训练过程分为两个阶段：在小的、不平衡的已标记数据集上进行初始训练阶段，以及在增强数据集上进行第二次自训练阶段。增强数据集是通过将初始已标记数据与来自未标记池的新数据点相结合而构建的，这些新数据点根据初始模型的预测被赋予“伪标签”。\n\n模拟的核心在于第二训练阶段的目标函数。该目标函数是一个复合函数，旨在评估针对确认偏差的不同缓解策略。它包括：\n1.  原始已标记数据 $\\mathcal{D}_L$ 上的标准交叉熵损失。\n2.  伪标签数据 $\\mathcal{D}_P$ 上的加权交叉熵损失，由参数 $\\alpha$ 控制。高 $\\alpha$ 值会迫使模型高度信任其自身的（可能有偏的）伪标签。\n3.  对模型在伪标签数据上的预测施加的熵惩罚，由参数 $\\gamma$ 控制。此惩罚项鼓励模型对其在 $\\mathcal{D}_P$ 上的预测降低置信度，从而起到防止对伪标签过拟合的正则化作用。\n4.  对模型权重 $\\mathbf{w}$ 的标准 $\\ell_2$ 正则化，由 $\\lambda$ 控制。\n\n必须推导并实现这个复合目标函数相对于模型参数 $(\\mathbf{w}, b)$ 的梯度，以用于梯度下降优化。设 $p_i = \\sigma(\\mathbf{w}^\\top\\mathbf{x}_i + b)$ 为模型对样本 $\\mathbf{x}_i$ 的预测概率。\n\n需要最小化的总目标函数 $J(\\mathbf{w}, b)$ 为：\n$$J(\\mathbf{w}, b) = \\frac{1}{|\\mathcal{D}_L|} \\sum_{i \\in \\mathcal{D}_L} \\ell(p_i, y_i) + \\frac{\\alpha}{|\\mathcal{D}_P|} \\sum_{j \\in \\mathcal{D}_P} \\ell(p_j, \\tilde{y}_j) - \\frac{\\gamma}{|\\mathcal{D}_P|} \\sum_{j \\in \\mathcal{D}_P} H(p_j) + \\lambda \\|\\mathbf{w}\\|_2^2$$\n其中 $\\ell(p, y)$ 是交叉熵损失，$\\tilde{y}_j$ 是伪标签，$H(p)$ 是香农熵。\n\n每个分量相对于 logit $z_i = \\mathbf{w}^\\top\\mathbf{x}_i + b$ 的梯度是：\n-   交叉熵: $\\frac{\\partial \\ell}{\\partial z_i} = p_i - y_i$。\n-   熵: $\\frac{\\partial H}{\\partial z_j} = -z_j p_j(1-p_j)$。\n-   权重的 $\\ell_2$ 正则化: $\\nabla_{\\mathbf{w}}(\\lambda \\|\\mathbf{w}\\|^2_2) = 2\\lambda\\mathbf{w}$。\n\n使用链式法则，通过将各分量的贡献相加来计算批量更新的完整梯度，这些贡献由 $\\alpha$ 和 $\\gamma$ 进行适当加权，并按数据集大小进行缩放。\n\n对于由 $(\\tau, \\alpha, \\gamma)$ 三元组定义的每个测试用例，模拟将执行以下操作：\n1.  在不平衡的已标记集 $\\mathcal{D}_L$ 上训练一个初始模型 $f_0$。\n2.  在 $\\mathcal{D}_L$ 上计算初始经验风险 $\\hat{R}_{\\text{before}}$，并在留出的测试集 $\\mathcal{D}_T$ 上计算测试风险 $R^{\\text{test}}_{\\text{before}}$。\n3.  使用 $f_0$ 为 $\\mathcal{D}_U$ 中预测置信度 $\\max(p, 1-p)$ 超过阈值 $\\tau$ 的未标记数据点生成伪标签。这构成了集合 $\\mathcal{D}_P$。\n4.  在增强数据集 $\\mathcal{D}_A = \\mathcal{D}_L \\cup \\mathcal{D}_P$ 上，使用复合目标函数训练一个新模型 $f_1$，其初始参数来自 $f_0$。\n5.  计算最终的经验风险 $\\hat{R}_{\\text{after}}$（在 $\\mathcal{D}_A$ 上）和测试风险 $R^{\\text{test}}_{\\text{after}}$（在 $\\mathcal{D}_T$ 上）。\n6.  通过检查是否满足 $\\hat{R}_{\\text{after}}  \\hat{R}_{\\text{before}}$ 且 $R^{\\text{test}}_{\\text{after}} > R^{\\text{test}}_{\\text{before}}$ 来判断是否发生了确认偏差。\n\n由于数据生成使用固定的随机种子和训练使用固定的协议，该模拟是确定性的。对于没有生成伪标签（即 $|\\mathcal{D}_P| = 0$）的边缘情况，通过确保相应的损失项和梯度为零来处理。通过将概率裁剪到一个小的安全范围 $[\\epsilon, 1-\\epsilon]$ 内，确保了交叉熵和熵计算中对数运算的数值稳定性。\n\n最终输出将是一个布尔值列表，每个值对应一个测试用例，指示是否观察到确认偏差。", "answer": "```python\nimport numpy as np\n\nclass LogisticRegression:\n    \"\"\"\n    A Logistic Regression classifier trained with gradient descent.\n    \"\"\"\n    def __init__(self, lr=0.1, epochs=200, lambda_reg=0.01, random_state=None):\n        self.lr = lr\n        self.epochs = epochs\n        self.lambda_reg = lambda_reg\n        self.w = None\n        self.b = None\n        self.epsilon = 1e-9  # For numerical stability\n\n    def _sigmoid(self, z):\n        return 1 / (1 + np.exp(-z))\n\n    def _loss(self, y, p):\n        p_clipped = np.clip(p, self.epsilon, 1 - self.epsilon)\n        # Cross-entropy loss\n        ce_loss = - (y * np.log(p_clipped) + (1 - y) * np.log(1 - p_clipped))\n        return np.mean(ce_loss)\n\n    def _entropy(self, p):\n        p_clipped = np.clip(p, self.epsilon, 1 - self.epsilon)\n        return - (p_clipped * np.log(p_clipped) + (1 - p_clipped) * np.log(1 - p_clipped))\n\n    def predict_proba(self, X):\n        z = X @ self.w + self.b\n        return self._sigmoid(z)\n\n    def train(self, X_l, y_l, X_p=None, y_p=None, alpha=0.0, gamma=0.0):\n        \"\"\"\n        Trains the logistic regression model using batch gradient descent.\n        \"\"\"\n        n_samples, n_features = X_l.shape\n        if self.w is None:\n            self.w = np.zeros(n_features)\n        if self.b is None:\n            self.b = 0.0\n\n        for _ in range(self.epochs):\n            # === Gradients for labeled data D_L ===\n            z_l = X_l @ self.w + self.b\n            p_l = self._sigmoid(z_l)\n            n_l = len(y_l)\n            \n            dw_l = (1 / n_l) * X_l.T @ (p_l - y_l)\n            db_l = (1 / n_l) * np.sum(p_l - y_l)\n\n            # === Gradients for pseudo-labeled data D_P ===\n            dw_p, db_p = 0, 0\n            dw_h, db_h = 0, 0 # Entropy penalty gradients\n\n            n_p = len(X_p) if X_p is not None else 0\n            if n_p  0:\n                # Cross-entropy on D_p\n                z_p = X_p @ self.w + self.b\n                p_p = self._sigmoid(z_p)\n                dw_p = alpha * (1 / n_p) * X_p.T @ (p_p - y_p)\n                db_p = alpha * (1 / n_p) * np.sum(p_p - y_p)\n                \n                # Entropy penalty on D_p\n                if gamma  0:\n                    # Gradient of H(p) w.r.t z is -z*p*(1-p)\n                    # We minimize -gamma*H, so gradient of obj is -gamma * dH/dz\n                    # dH/dz = -z*p*(1-p), so we add gamma * (-z*p*(1-p)) to the loss gradient\n                    grad_H_z = -z_p * p_p * (1 - p_p)\n                    dw_h = -gamma * (1 / n_p) * X_p.T @ grad_H_z\n                    db_h = -gamma * (1 / n_p) * np.sum(grad_H_z)\n\n            # === Regularization Gradient ===\n            dw_reg = 2 * self.lambda_reg * self.w\n\n            # === Total Gradient and Update ===\n            dw = dw_l + dw_p + dw_h + dw_reg\n            db = db_l + db_p + db_h\n            \n            self.w -= self.lr * dw\n            self.b -= self.lr * db\n\ndef solve():\n    # --- Data Generation and Simulation Setup ---\n    random_seed = 42\n    np.random.seed(random_seed)\n\n    mu0, mu1 = np.array([-1, 0]), np.array([1, 0])\n    Sigma = np.diag([1, 1])\n    d = 2\n\n    n_L, n_U, n_T = 20, 1000, 200\n    lambda_reg, eta, epochs = 0.01, 0.1, 200\n    \n    # D_L: Labeled set (imbalanced)\n    X_L = np.vstack([\n        np.random.multivariate_normal(mu0, Sigma, 18),\n        np.random.multivariate_normal(mu1, Sigma, 2)\n    ])\n    y_L = np.array([0]*18 + [1]*2)\n    \n    # D_U: Unlabeled pool (balanced)\n    X_U = np.vstack([\n        np.random.multivariate_normal(mu0, Sigma, n_U // 2),\n        np.random.multivariate_normal(mu1, Sigma, n_U // 2)\n    ])\n    \n    # D_T: Test set (balanced)\n    X_T = np.vstack([\n        np.random.multivariate_normal(mu0, Sigma, n_T // 2),\n        np.random.multivariate_normal(mu1, Sigma, n_T // 2)\n    ])\n    y_T = np.array([0]*(n_T // 2) + [1]*(n_T // 2))\n\n    # --- Initial Training (f0) ---\n    f0 = LogisticRegression(lr=eta, epochs=epochs, lambda_reg=lambda_reg)\n    f0.train(X_L, y_L)\n    \n    # --- Evaluation Before Self-Training ---\n    p_L_before = f0.predict_proba(X_L)\n    R_hat_before = f0._loss(y_L, p_L_before)\n\n    p_T_before = f0.predict_proba(X_T)\n    R_test_before = f0._loss(y_T, p_T_before)\n    \n    w0, b0 = np.copy(f0.w), f0.b\n\n    # --- Test Suite ---\n    test_cases = [\n        (0.5, 3.0, 0.0),\n        (0.9, 1.0, 0.0),\n        (0.95, 1.0, 0.2),\n        (0.7, 5.0, 0.0),\n        (0.999, 1.0, 0.1),\n    ]\n\n    results = []\n    \n    for tau, alpha, gamma in test_cases:\n        # --- Self-Training Protocol ---\n        # 1. Generate pseudo-labels\n        p_U = f0.predict_proba(X_U)\n        confidence = np.maximum(p_U, 1 - p_U)\n        \n        pseudo_indices = np.where(confidence = tau)[0]\n        \n        X_p = X_U[pseudo_indices]\n        p_p_selected = p_U[pseudo_indices]\n        y_p = (p_p_selected = 0.5).astype(int)\n        \n        # 2. Train f1 on augmented data\n        f1 = LogisticRegression(lr=eta, epochs=epochs, lambda_reg=lambda_reg)\n        f1.w, f1.b = np.copy(w0), b0  # Start from f0's parameters\n        \n        f1.train(X_L, y_L, X_p, y_p, alpha, gamma)\n        \n        # 3. Evaluation After Self-Training\n        # R_hat_after\n        X_A = np.vstack([X_L, X_p]) if len(X_p)  0 else X_L\n        y_A = np.concatenate([y_L, y_p]) if len(y_p)  0 else y_L\n        p_A_after = f1.predict_proba(X_A)\n        R_hat_after = f1._loss(y_A, p_A_after)\n        \n        # R_test_after\n        p_T_after = f1.predict_proba(X_T)\n        R_test_after = f1._loss(y_T, p_T_after)\n        \n        # 4. Check for Confirmation Bias\n        confirmation_bias = (R_hat_after  R_hat_before) and (R_test_after > R_test_before)\n        results.append(confirmation_bias)\n\n    # --- Final Output ---\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3121468"}]}