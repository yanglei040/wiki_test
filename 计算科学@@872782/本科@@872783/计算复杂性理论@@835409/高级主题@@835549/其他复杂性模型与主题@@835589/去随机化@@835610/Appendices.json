{"hands_on_practices": [{"introduction": "在许多算法中，我们需要的随机性并非完全独立，而是一种更弱的“有限独立性”。成对独立是其中最基本的形式，它要求任何两个随机变量都是独立的，这大大减少了生成和存储随机比特所需的资源。这个练习将通过一个具体的例子，让你亲手验证并理解如何用一个极小的样本空间来构造一组满足成对独立性的随机比特 [@problem_id:1420514]。", "problem": "在理论计算机科学领域，尤其是在随机算法的研究中，两两独立的概念是去随机化的一个强大工具。完全独立的随机变量需要一个大的样本空间，这在计算上可能是昂贵的。两两独立的随机变量是一个较弱的概念，通常可以用一个显著更小的样本空间来替代。\n\n设 $S$ 是一个样本空间，由四个长度为三的不同字符串组成。我们在 $S$ 上定义一个均匀概率分布，这意味着每个字符串被选中的概率为 $\\frac{1}{4}$。设 $X_1, X_2,$ 和 $X_3$ 是随机变量，分别表示从 $S$ 中均匀随机选择的一个字符串的第一、第二和第三位。\n\n为了使这些变量在许多应用中有用，它们必须满足两个条件：\n1.  **均匀性**：对于 $i \\in \\{1, 2, 3\\}$，每个变量 $X_i$ 都必须是均匀分布的，即它取值为0的概率等于取值为1的概率。也就是说，$P(X_i=0) = P(X_i=1) = \\frac{1}{2}$。\n2.  **两两独立性**：对于每对不同的下标 $i, j \\in \\{1, 2, 3\\}$，随机变量 $X_i$ 和 $X_j$ 必须是独立的。这意味着对于所有值 $b_1, b_2 \\in \\{0, 1\\}$，联合概率满足 $P(X_i=b_1, X_j=b_2) = P(X_i=b_1)P(X_j=b_2)$。\n\n以下哪个样本空间 $S$ 满足随机变量 $X_1, X_2, X_3$ 的均匀性和两两独立性两个条件？\n\nA. $S = \\{000, 001, 010, 100\\}$\n\nB. $S = \\{000, 011, 100, 111\\}$\n\nC. $S = \\{000, 011, 101, 110\\}$\n\nD. $S = \\{000, 111, 001, 110\\}$", "solution": "我们在一个包含四个字符串的样本空间上使用均匀分布，因此每个字符串的概率为 $\\frac{1}{4}$。为了使 $X_{i}$ 是均匀的，对于每个 $i \\in \\{1,2,3\\}$，我们需要 $P(X_{i}=0)=P(X_{i}=1)=\\frac{1}{2}$。由于分布为四个字符串分配了相同的权重，这要求在 $S$ 中所有字符串的第 $i$ 个坐标组成的多重集中，恰好有两个0和两个1。对于 $X_i$ 和 $X_j$ 的两两独立性，因为边际分布必须是均匀的，我们需要对每个 $b_{1},b_{2} \\in \\{0,1\\}$ 都有\n$$\nP(X_{i}=b_{1},X_{j}=b_{2})=P(X_{i}=b_{1})P(X_{j}=b_{2})=\\frac{1}{2}\\cdot\\frac{1}{2}=\\frac{1}{4}.\n$$\n在四个字符串上的均匀分布下，这个条件成立当且仅当在这四个字符串中，每个有序对 $(b_{1},b_{2})$ 作为 $(i,j)$ 坐标恰好出现一次。\n\n检查选项 A：$S=\\{000,001,010,100\\}$。第一列的比特是 $\\{0,0,0,1\\}$，因此\n$$\nP(X_{1}=0)=\\frac{3}{4} \\neq \\frac{1}{2},\n$$\n所以均匀性不成立，因此 A 是无效的。\n\n检查选项 B：$S=\\{000,011,100,111\\}$。首先，我们检查均匀性。第一、二、三列的比特分别是 $\\{0,0,1,1\\}$、$\\{0,1,0,1\\}$ 和 $\\{0,1,0,1\\}$。每一列都有两个0和两个1，因此每个变量 $X_i$ 都是均匀的。接下来，我们检查两两独立性。以变量对 $(X_2, X_3)$ 为例，从 $S$ 中的四个字符串得到的比特对分别是 $(0,0), (1,1), (0,0), (1,1)$。这里只出现了 $(0,0)$ 和 $(1,1)$ 两种组合，而 $(0,1)$ 和 $(1,0)$ 并未出现。因此，$P(X_2=0, X_3=1) = 0$，但这不等于 $P(X_2=0)P(X_3=1) = \\frac{1}{2} \\cdot \\frac{1}{2} = \\frac{1}{4}$。所以 $X_2$ 和 $X_3$ 不是独立的。因此，两两独立性不成立，B 是无效的。\n\n检查选项 D：$S=\\{000,111,001,110\\}$。每个位置都有两个0和两个1，所以每个 $X_{i}$ 都是均匀的。对于 $(X_{1},X_{2})$，这些对是：从 000 得到 (0,0)；从 111 得到 (1,1)；从 001 得到 (0,0)；从 110 得到 (1,1)。因此\n$$\nP(X_{1}=0,X_{2}=1)=0 \\neq \\frac{1}{4},\n$$\n所以两两独立性不成立；D 是无效的。\n\n检查选项 C：$S=\\{000,011,101,110\\}$。$S$ 中第一、第二和第三个坐标都各有是两个0和两个1，所以对于每个 $i$，\n$$\nP(X_{i}=0)=P(X_{i}=1)=\\frac{1}{2}.\n$$\n对于两两独立性，我们枚举所有的对：\n- 对于 $(X_{1},X_{2})$：从 000 得到 (0,0)；从 011 得到 (0,1)；从 101 得到 (1,0)；从 110 得到 (1,1)。因此对于每个 $(b_{1},b_{2}) \\in \\{0,1\\}^{2}$，\n$$\nP(X_{1}=b_{1},X_{2}=b_{2})=\\frac{1}{4}=\\frac{1}{2}\\cdot\\frac{1}{2}.\n$$\n- 对于 $(X_{1},X_{3})$：从 000 得到 (0,0)；从 011 得到 (0,1)；从 101 得到 (1,1)；从 110 得到 (1,0)，同样每个对都出现一次，所以\n$$\nP(X_{1}=b_{1},X_{3}=b_{2})=\\frac{1}{4}=\\frac{1}{2}\\cdot\\frac{1}{2}.\n$$\n- 对于 $(X_{2},X_{3})$：从 000 得到 (0,0)；从 011 得到 (1,1)；从 101 得到 (0,1)；从 110 得到 (1,0)，每个对都出现一次，所以\n$$\nP(X_{2}=b_{1},X_{3}=b_{2})=\\frac{1}{4}=\\frac{1}{2}\\cdot\\frac{1}{2}.\n$$\n因此，所有的边际分布都是均匀的，并且所有的对都是独立的。\n\n因此，在给定选项中，唯一有效的选择是 C。", "answer": "$$\\boxed{C}$$", "id": "1420514"}, {"introduction": "成对独立性不仅是一个理论概念，它在算法设计中有着广泛的应用，尤其是在哈希函数的设计中。一个成对独立的哈希函数族能以很小的随机性代价，保证哈希冲突的概率足够低，从而为数据结构和算法的性能提供理论保障。在这个练习中，你将使用模运算这一经典方法，为一个特定的映射要求找到唯一的哈希函数，从而深入了解这种结构是如何保证其强大特性的 [@problem_id:1420528]。", "problem": "在设计随机算法和数据结构时，2-wise 独立的哈希函数族是一个基本工具，用于在有限的随机性下提供理论保证。一个函数族 $H$（其中每个函数 $h \\in H$ 将一个域 $U$ 映射到一个值域 $V$）被称为 2-wise 独立的，如果对于任意两个不同的元素 $x_1, x_2 \\in U$ 和任意两个（不一定不同的）元素 $y_1, y_2 \\in V$，从 $H$ 中随机选择一个函数 $h$ 同时满足 $h(x_1) = y_1$ 和 $h(x_2) = y_2$ 的概率恰好是 $1/|V|^2$。\n\n构造此类函数族的一个常用方法涉及模算术。考虑一个由整数组成的键的域 $U = \\{0, 1, ..., 99\\}$。我们希望将这些键映射到一个哈希表中。为此，我们选择满足 $p \\ge |U|$ 的最小素数 $p$，即 $p = 101$。\n\n该哈希函数族 $H$ 被定义为所有从集合 $\\{0, 1, ..., 100\\}$ 到其自身，形式如下的函数 $h_{a,b}$ 的集合：\n$$h_{a,b}(x) = (ax + b) \\pmod{101}$$\n其中系数 $a$ 和 $b$ 可以是集合 $\\{0, 1, ..., 100\\}$ 中的任意整数。\n\n这种构造的一个关键特性是，对于任意两个不同的键 $x_1, x_2$ 和任意两个哈希值 $y_1, y_2$，在函数族 $H$ 中都存在且仅存在一个函数 $h_{a,b}$，它同时满足 $h_{a,b}(x_1) = y_1$ 和 $h_{a,b}(x_2) = y_2$ 这两个条件。\n\n你的任务是找到唯一的哈希函数 $h_{a,b}$ 的特定系数 `a`，该函数需同时满足以下两个映射要求：\n1. 将键 $x_1 = 10$ 映射到哈希值 $y_1 = 50$。\n2. 将键 $x_2 = 20$ 映射到哈希值 $y_2 = 70$。\n\n提供系数 $a$ 的值。答案必须是一个整数。", "solution": "我们正在素数 $101$ 的模整数有限域中进行运算。哈希函数族为 $h_{a,b}(x) \\equiv ax + b \\pmod{101}$。这两个映射要求给出了以下联立同余方程：\n$$10a + b \\equiv 50 \\pmod{101},$$\n$$20a + b \\equiv 70 \\pmod{101}.$$\n\n用第二个同余方程减去第一个，以消去 $b$：\n$$\\left(20a + b\\right) - \\left(10a + b\\right) \\equiv 70 - 50 \\pmod{101},$$\n化简得\n$$10a \\equiv 20 \\pmod{101}.$$\n\n由于 $101$ 是素数且 $10 \\not\\equiv 0 \\pmod{101}$，所以 $10$ 在模 $101$ 下存在乘法逆元。为了找到 $10^{-1} \\pmod{101}$，使用扩展欧几里得算法：\n$$101 = 10 \\cdot 10 + 1 \\implies 1 = 101 - 10 \\cdot 10.$$\n模 $101$ 约简后得到\n$$10 \\cdot (-10) \\equiv 1 \\pmod{101},$$\n所以\n$$10^{-1} \\equiv -10 \\equiv 91 \\pmod{101}.$$\n\n将 $10a \\equiv 20 \\pmod{101}$ 两边同乘以 $10^{-1}$ 来求解 $a$：\n$$a \\equiv 20 \\cdot 10^{-1} \\equiv 20 \\cdot 91 \\pmod{101}.$$\n计算模 $101$ 下的乘积：\n$$20 \\cdot 91 = 1820 \\equiv 1820 - 101 \\cdot 18 = 1820 - 1818 = 2 \\pmod{101}.$$\n\n因此，所需的系数为 $a \\equiv 2 \\pmod{101}$。在集合 $\\{0,1,\\ldots,100\\}$ 中取代表元，得到 $a = 2$。快速检验：当 $a=2$ 时，从 $10a + b \\equiv 50$ 我们得到 $b \\equiv 50 - 20 \\equiv 30$，然后 $20a + b \\equiv 40 + 30 \\equiv 70$，符合要求。", "answer": "$$\\boxed{2}$$", "id": "1420528"}, {"introduction": "对于更复杂的随机化算法，我们如何系统地将其转化为确定性算法呢？条件期望方法提供了一个强大的通用框架。其核心思想是，将随机选择的过程分解为一系列决策步骤，在每一步都选择能使最终结果的“期望值”最优化的选项。这个练习将引导你应用此方法解决一个计算几何问题，通过逐步确定一个向量的各个分量，来找到一个近似平分点集的超平面，从而直观地感受这一高级去随机化技术的威力 [@problem_id:1420518]。", "problem": "在计算几何和机器学习中，一项基本任务是使用一个超平面来划分一个点集。给定 $\\mathbb{R}^d$ 中的一组 $n$ 个数据向量 $v_1, v_2, \\dots, v_n$，我们希望找到一个由法向量 $u$ 定义、通过原点的分离超平面，该超平面能尽可能均匀地平分该点集。这两个划分分别由与 $u$ 的点积为正的点和点积为负的点构成。一个划分的“不平衡度”是两侧点数之差的绝对值。\n\n我们将法向量的搜索范围限制在离散集合 $u \\in \\{-1, 1\\}^d$。一个简单的随机方法是从该集合中均匀随机地选择一个向量 $u$。然而，我们寻求一种确定性算法。条件期望法为这类过程提供了一种去随机化的方法。\n\n直接处理不平衡度很困难，因此我们使用一个代理“势函数”$W(u)$。我们将从 $k=1$ 到 $d$ 逐一选择 $u = (\\epsilon_1, \\epsilon_2, \\dots, \\epsilon_d)$ 的分量。在每一步 $k$，我们选择 $\\epsilon_k \\in \\{-1, 1\\}$ 以在给定迄今为止所做选择的条件下，最小化 $W(u)$ 的条件期望。如果出现平局，我们选择 $\\epsilon_k = 1$。\n\n你的任务是应用此算法，为以下特定情况找到向量 $u \\in \\{-1, 1\\}^3$：\n维度为 $d=3$。\n向量集合包含 $n=2$ 个向量：\n$v_1 = (2, -1, 2)$\n$v_2 = (1, 3, -1)$\n\n势函数由 $W(u) = \\sum_{i=1}^{2} \\cosh(\\lambda (v_i \\cdot u))$ 给出，其中 $\\lambda$ 是一个给定的正常数。你可以假设对于 $u$ 的任何选择，点积 $v_i \\cdot u$ 均不为零。\n\n该确定性算法找到的是下列哪个向量 $u$？\n\nA. $(1, 1, 1)$\n\nB. $(1, 1, -1)$\n\nC. $(1, -1, 1)$\n\nD. $(1, -1, -1)$\n\nE. $(-1, 1, 1)$\n\nF. $(-1, 1, -1)$\n\nG. $(-1, -1, 1)$\n\nH. $(-1, -1, -1)$", "solution": "我们使用条件期望法，其对应的随机过程是每个坐标从 $\\{-1,1\\}$ 中独立均匀地选取。令 $u=(\\epsilon_1, \\epsilon_2, \\epsilon_3)$，并且对于 $i\\in\\{1,2\\}$，定义 $s_i=v_i \\cdot u$。势函数为 $W(u)=\\sum_{i=1}^{2}\\cosh(\\lambda s_i)$，其中 $\\lambda>0$。对于独立的拉德马赫(Rademacher)变量 $\\delta_{j}$，有一个关键的恒等式\n$$\n\\mathbb{E}\\!\\left[\\cosh\\!\\left(\\lambda\\left(a+\\sum_{j}b_{j}\\delta_{j}\\right)\\right)\\right]\n=\\frac{\\mathbb{E}\\!\\left[\\exp\\!\\left(\\lambda\\left(a+\\sum_{j}b_{j}\\delta_{j}\\right)\\right)\\right]+\\mathbb{E}\\!\\left[\\exp\\!\\left(-\\lambda\\left(a+\\sum_{j}b_{j}\\delta_{j}\\right)\\right)\\right]}{2}\n=\\cosh(\\lambda a)\\prod_{j}\\cosh(\\lambda b_{j}),\n$$\n此式可由独立性以及 $\\mathbb{E}[\\exp(t b \\delta)]=\\cosh(t b)$ 推导得出。\n\n第 $k=1$ 步。我们选择 $\\epsilon_1$ 以最小化 $\\mathbb{E}[W\\mid \\epsilon_1]$，这里的期望是关于 $\\epsilon_2, \\epsilon_3$ 计算的。这里 $v_1=(2,-1,2)$ 且 $v_2=(1,3,-1)$。对于 $i=1$，$s_1=2\\epsilon_1-\\epsilon_2+2\\epsilon_3$；对于 $i=2$，$s_2=\\epsilon_1+3\\epsilon_2-\\epsilon_3$。使用该恒等式，其中 $a=v_{i,1}\\epsilon_1$，随机项为 $b_2=v_{i,2}$、$b_3=v_{i,3}$，\n$$\n\\mathbb{E}\\!\\left[\\cosh(\\lambda s_i)\\mid \\epsilon_1\\right]=\\cosh(\\lambda v_{i,1}\\epsilon_1)\\cosh(\\lambda v_{i,2})\\cosh(\\lambda v_{i,3}).\n$$\n由于 $\\cosh$ 是偶函数，$\\cosh(\\lambda v_{i,1}\\epsilon_1)=\\cosh(\\lambda v_{i,1})$，因此 $\\mathbb{E}[W\\mid \\epsilon_1]$ 与 $\\epsilon_1$ 无关。根据平局规则，我们设定 $\\epsilon_1=1$。\n\n第 $k=2$ 步。固定 $\\epsilon_1=1$，选择 $\\epsilon_2$ 以最小化 $\\mathbb{E}[W\\mid \\epsilon_1=1,\\epsilon_2]$，此时仅对 $\\epsilon_3$ 求期望。对每个 $i$：\n$$\n\\mathbb{E}\\!\\left[\\cosh(\\lambda s_i)\\mid \\epsilon_1=1,\\epsilon_2\\right]=\\cosh\\!\\left(\\lambda(v_{i,1}\\cdot 1+v_{i,2}\\epsilon_2)\\right)\\cosh(\\lambda v_{i,3}).\n$$\n因此\n$$\nF(\\epsilon_2)=\\cosh(\\lambda(2-\\epsilon_2))\\cosh(2\\lambda)+\\cosh(\\lambda(1+3\\epsilon_2))\\cosh(\\lambda).\n$$\n评估两种选择：\n$$\nF(1)=\\cosh(\\lambda)\\cosh(2\\lambda)+\\cosh(4\\lambda)\\cosh(\\lambda),\\quad\nF(-1)=\\cosh(3\\lambda)\\cosh(2\\lambda)+\\cosh(2\\lambda)\\cosh(\\lambda).\n$$\n它们的差可以使用 $\\cosh x\\cosh y=\\frac{\\cosh(x+y)+\\cosh(x-y)}{2}$ 进行简化：\n$$\nF(1)-F(-1)=\\cosh(4\\lambda)\\cosh(\\lambda)-\\cosh(3\\lambda)\\cosh(2\\lambda)\n=\\frac{\\cosh(5\\lambda)+\\cosh(3\\lambda)-\\cosh(5\\lambda)-\\cosh(\\lambda)}{2}\n=\\frac{\\cosh(3\\lambda)-\\cosh(\\lambda)}{2}>0,\n$$\n因为 $\\lambda>0$。因此 $F(-1)$ 更小，我们选择 $\\epsilon_2=-1$。\n\n第 $k=3$ 步。在 $\\epsilon_1=1, \\epsilon_2=-1$ 的条件下，我们选择 $\\epsilon_3$ 以最小化实际的 $W$ 值（此时已无期望运算）。计算\n$$\ns_1=2\\cdot 1-(-1)+2\\epsilon_3=3+2\\epsilon_3,\\quad s_2=1+3(-1)-\\epsilon_3=-2-\\epsilon_3.\n$$\n因此\n$$\nW(\\epsilon_3=1)=\\cosh(5\\lambda)+\\cosh(3\\lambda),\\quad\nW(\\epsilon_3=-1)=\\cosh(\\lambda)+\\cosh(\\lambda)=2\\cosh(\\lambda).\n$$\n因为对于 $\\lambda>0$，有 $\\cosh(5\\lambda)+\\cosh(3\\lambda)>2\\cosh(\\lambda)$，所以最小值在 $\\epsilon_3=-1$ 时取得。\n\n因此，该确定性算法得出的结果是 $u=(1,-1,-1)$，对应选项D。", "answer": "$$\\boxed{D}$$", "id": "1420518"}]}