## 引言
在日益互联的计算世界中，信息在不同实体间的流动是所有协作任务的核心。无论是大型数据中心内的服务器协同处理海量数据，还是简单的两个程序交换信息，理解和量化通信的成本都至关重要。双人通信模型正是为解决这一根本问题而生的强大数学框架，它使我们能够精确研究分布式系统中信息流的基本限制。然而，对于一个给定的计算任务，我们如何才能知道完成它所必需的最少通信量是多少？又有哪些技术可以帮助我们设计出最高效的通信协议呢？

本文旨在系统性地回答这些问题，为读者全面解析双人通信模型。我们将从三个维度展开：
*   在“原理与机制”一章中，我们将深入探讨模型的基础定义、确定性、[非确定性](@entry_id:273591)和[随机化](@entry_id:198186)等不同类型的协议，并介绍包括[愚弄集](@entry_id:276010)和秩下界在内的核心下界证明技术。
*   接着，在“应用与跨学科关联”一章，我们将展示这些理论如何在算法设计、流计算、密码学和机器学习等多个领域中发挥作用，揭示通信成本作为衡量计算难度的统一尺度。
*   最后，通过一系列“动手实践”练习，您将有机会亲自运用所学知识，为具体问题构建通信协议并证明其复杂性下界，从而巩固和深化理解。

通过本文的学习，您将不仅掌握一个抽象的理论模型，更将获得一种分析信息在计算中作用的深刻视角。让我们首先深入其核心，探索双人通信的原理与机制。

## 原理与机制

在上一章中，我们介绍了双人通信模型的宏观背景，它作为研究[分布式系统](@entry_id:268208)中信息流基本限制的数学框架。本章将深入探讨该模型的核心原理与机制。我们将从基本定义开始，建立一个坚实的基础，然后逐步引入用于分析通信成本的各种复杂性度量和强大的下界证明技术。

### 基础概念：通信游戏

从最核心的层面来看，双人通信模型可以被看作一个由两方参与的游戏。我们通常称这两方为 Alice 和 Bob。Alice 接收一个输入 $x$，它来自某个集合 $X$；同时，Bob 接收一个输入 $y$，它来自某个集合 $Y$。他们的共同目标是计算某个预先定义的函数 $f: X \times Y \to Z$ 的值。为了实现这个目标，他们可以根据一个预先商定的**协议（protocol）**来交换信息。

一个协议本质上是一棵二叉树。树的每个内部节点都属于 Alice 或 Bob 中的一方。如果一个节点属于 Alice，她会根据她的输入 $x$ 和到目前为止收到的所有信息，来决定是向 Bob 发送一个 `0` 还是一个 `1`。这个决定将决定通信路径走向该节点的左子节点还是右子节点。Bob 的节点也类似。树的叶子节点则包含了函数 $f(x,y)$ 的输出值。对于任何一对输入 $(x,y)$，Alice 和 Bob 的交互会确定一条从根节点到某个叶子节点的唯一路径。这条路径的长度，即他们之间交换的比特数，就是这对特定输入的**通信成本（communication cost）**，我们记为 $c(x,y)$。

在分析一个协议的效率时，我们通常关心它在所有可能输入下的表现。这引出了两种主要的复杂性度量：

1.  **最坏情况复杂性（Worst-Case Complexity）**：这是在所有可能的输入对中，一个协议所需的最大通信比特数。一个函数 $f$ 的确定性通信复杂性，记为 $D(f)$，是在所有能够正确计算 $f$ 的确定性协议中，最坏情况复杂性最小的那个值。形式上，$D(f) = \min_{P} \max_{x,y} c_P(x,y)$，其中 $P$ 代表一个协议。

2.  **平均情况复杂性（Average-Case Complexity）**：这指的是在某个特定输入[分布](@entry_id:182848)下，协议的期望通信成本。它衡量了协议的“典型”性能。

为了清晰地理解这两者的区别，让我们考虑一个具体的场景[@problem_id:1465099]。假设 Alice 和 Bob 各自持有一个 $n$ 比特的字符串 $x$ 和 $y$。他们想检查 $x$ 和 $y$ 是否完全相同。一个简单的协议是：Alice 逐个发送她的比特 $x_1, x_2, \dots$ 给 Bob。Bob 在收到每个比特后，就与自己的对应比特进行比较。一旦发现不匹配（例如，在第 $i$ 个位置 $x_i \neq y_i$），协议就立即停止。如果所有比特都匹配，Alice 会发送完所有 $n$ 个比特。

这个协议的通信成本 $c(x,y)$ 是第一个不匹配位置的索引；如果 $x=y$，则成本为 $n$。其最坏情况下的通信成本显然是 $n$，因为当 $x=y$ 时，Alice 必须发送所有 $n$ 个比特。然而，其平均情况性能可能要好得多。假设 Alice 的字符串是固定的 $x=0^n$，而 Bob 的字符串 $y$ 是从所有 $2^n$ 个 $n$ 比特字符串中均匀随机选取的。在这种情况下，期望成本可以通过对所有可能的通信成本求和来计算，但一个更简洁的方法是利用公式 $E[C] = \sum_{k=1}^n P(C \ge k)$。通信成本 $C$ 至少为 $k$ 的事件（$k \le n$）等价于前 $k-1$ 个比特完全匹配，这在[均匀分布](@entry_id:194597)下发生的概率是 $(1/2)^{k-1}$。因此，平均成本为 $\sum_{k=1}^{n} (1/2)^{k-1} = \frac{1-(1/2)^n}{1-1/2} = 2 - 2^{1-n}$。这个值随着 $n$ 的增大迅速趋近于 2。这个例子生动地说明，一个在最坏情况下看起来效率不高的协议，在平均情况下可能非常高效。

### 确定性通信复杂性

确定性协议是通信模型中最简单、最基础的形式。为了分析其固有的复杂性，[计算理论](@entry_id:273524)学家们发展出了一系列精妙的工具。

#### 通信矩阵与[单色矩形](@entry_id:269454)

理解确定性复杂性的一个强大视角是**通信矩阵（communication matrix）**。对于一个函数 $f: X \times Y \to \{0,1\}$，我们可以构建一个 $|X| \times |Y|$ 的矩阵 $M_f$，其中行由 Alice 的输入 $x$ 索引，列由 Bob 的输入 $y$ 索引，矩阵的条目为 $M_f(x,y) = f(x,y)$。这个矩阵包含了关于函数 $f$ 的全部信息。

当 Alice 和 Bob 执行一个确定性协议时，他们交换的每一条消息都将可能的输入空间划分为更小的[子集](@entry_id:261956)。例如，如果 Alice 的第一条消息是 $m$，那么所有让 Alice 发送 $m$ 的输入 $x$ 构成了行的一个[子集](@entry_id:261956) $A \subseteq X$。同样，Bob 的回应将所有可能的 $y$ 划分为一个[子集](@entry_id:261956) $B \subseteq Y$。经过一轮或多轮通信，他们到达协议树的一个叶子节点。这个叶子节点对应于一个特定的输入[子集](@entry_id:261956) $A' \times B' \subseteq X \times Y$，我们称之为一个**组合矩形（combinatorial rectangle）**。由于协议在叶子节点上必须给出一个唯一的答案，所以对于这个矩形内的所有输入对 $(x,y) \in A' \times B'$，函数值 $f(x,y)$ 必须是相同的。这样的矩形被称为**[单色矩形](@entry_id:269454)（monochromatic rectangle）**。

因此，任何确定性协议都对应着一种用[单色矩形](@entry_id:269454)对通信矩阵 $M_f$ 进行的划分。一个交换 $c$ 比特的协议最多可以产生 $2^c$ 个叶子节点，也就是最多 $2^c$ 个[单色矩形](@entry_id:269454)。这意味着，要覆盖整个通信矩阵，至少需要 $C(f)$ 个[单色矩形](@entry_id:269454)，其中 $C(f)$ 是划分 $M_f$ 所需的最少[单色矩形](@entry_id:269454)数。由此我们得到了一个基本的下界：$D(f) \ge \lceil \log_2(C(f)) \rceil$。

#### 单向通信与信息论下界

一个特别重要的[子模](@entry_id:148922)型是**单向通信模型（one-way communication model）**，其中只有 Alice 可以向 Bob 发送一条消息。这种模型的分析通常依赖于经典的信息论思想。

考虑一个函数 $f(x,y)$，如果它的值只取决于 Alice 的输入 $x$，比如计算 $x$ 的奇偶性的 `PARITY_A` 函数[@problem_id:1465113]。如果 Bob 必须知道这个结果，Alice 至少需要发送一些信息。Alice 可以简单地计算出 `PARITY(x)` 的值（0 或 1），然后把这个比特发送给 Bob。这只需要 1 比特。由于 Bob 无法凭空猜出这个值，所以 1 比特也是必要的。因此，对于这类函数，通信复杂性 $D(f)=1$。

当函数同时依赖于双方的输入时，情况就变得复杂了。一个经典的例子是[@problem_id:1465069]，Alice 持有一个对集合 $\{0, \dots, n-1\}$ 的[排列](@entry_id:136432) $\pi$，Bob 持有一个索引 $i$，他们需要计算 $\pi(i)$。在单向模型中，Alice 必须发送一条消息 $M(\pi)$，使得 Bob 收到后，对于他可能持有的 *任何* 索引 $i$，都能计算出 $\pi(i)$。这意味着 Bob 必须能够从消息 $M(\pi)$ 中恢复出关于 $\pi$ 的足够信息。

让我们来分析一下。如果对于两个不同的[排列](@entry_id:136432) $\pi_1 \neq \pi_2$，Alice 发送了相同的消息 $M(\pi_1) = M(\pi_2)$，会发生什么？因为 $\pi_1$ 和 $\pi_2$ 是不同的[排列](@entry_id:136432)，必然存在某个索引 $i^*$ 使得 $\pi_1(i^*) \neq \pi_2(i^*)$。如果 Bob 恰好持有这个 $i^*$，他收到相同的消息，却需要输出两个不同的值，这是不可能的。因此，协议必须为每一个不同的[排列](@entry_id:136432) $\pi$ 分配一个唯一的消息。Alice 的输入集合大小为 $n!$（所有可能[排列](@entry_id:136432)的数量），所以至少需要 $n!$ 个不同的消息。如果消息的最大长度是 $c$ 比特，那么最多只能有 $2^c$ 个不同的消息。所以，$2^c \ge n!$，这意味着 $c \ge \log_2(n!)$。由于比特数必须是整数，我们得到下界 $D(f) \ge \lceil \log_2(n!) \rceil$。这个下界可以通过 Alice 发送其[排列](@entry_id:136432)的唯一编码来实现，证明了该界是紧的。这个例子展示了一个核心原则：在单向模型中，Alice 的消息必须能区分所有可能导致不同输出的输入。

#### 双向通信的下界技术

对于双向通信，矩形划分的想法虽然基础，但直接计算最小划分数通常很困难。因此，我们需要更易于应用的下界证明方法。

**1. [愚弄集](@entry_id:276010)（Fooling Set）方法**

[愚弄集](@entry_id:276010)是一种非常直观且强大的下界技术。一个函数的**[愚弄集](@entry_id:276010)** $S = \{(x_1, y_1), \dots, (x_k, y_k)\}$ 是一系列输入对，它们满足两个条件：
*   所有这些输入对的函数值都相同，即 $f(x_i, y_i) = c$ 对所有 $i$ 成立（[单色性](@entry_id:175510)）。
*   对于任何两个不同的对 $(x_i, y_i)$ 和 $(x_j, y_j)$，交换它们的输入后，至少有一个“交叉”对的函数值会改变，即 $f(x_i, y_j) \neq c$ 或 $f(x_j, y_i) \neq c$。

这个方法背后的思想是：假设一个协议对于 $(x_i, y_i)$ 和 $(x_j, y_j)$ 产生了完全相同的通信记录（比特交换序列）。由于协议是确定性的，它在处理 $(x_i, y_j)$ 时，Alice 的行为会和处理 $(x_i, y_i)$ 时一样，而 Bob 的行为会和处理 $(x_j, y_j)$ 时一样。因此，协议在 $(x_i, y_j)$ 上产生的通信记录也会是同一个。这意味着协议在 $(x_i, y_j)$ 上的输出也必须是 $c$。然而，[愚弄集](@entry_id:276010)的定义保证了 $f(x_i, y_j)$ 或 $f(x_j, y_i)$ 不等于 $c$。这就“愚弄”了协议，导致了矛盾。因此，一个正确的协议必须为[愚弄集](@entry_id:276010)中的每一个输入对生成一个独一无二的通信记录。如果通信成本为 $c$，最多有 $2^c$ 种不同的通信记录，所以我们得到下界 $D(f) \ge \log_2(|S|)$。

[集合不相交性](@entry_id:276256)问题（Set Disjointness, $\text{DISJ}_n$）是应用[愚弄集](@entry_id:276010)的经典范例[@problem_id:1413371]。在该问题中，Alice 和 Bob 各持有一个宇宙 $U=\{1, \dots, n\}$ 的[子集](@entry_id:261956) $X$ 和 $Y$，他们需要判断 $X \cap Y = \emptyset$ 是否成立。我们可以构造一个大小为 $2^n$ 的[愚弄集](@entry_id:276010)。对于 $U$ 的每个[子集](@entry_id:261956) $S \subseteq U$，我们考虑输入对 $(S, U \setminus S)$。对于这样的对，交集为空，所以函数值为 1（不相交）。对于任意两个不同的[子集](@entry_id:261956) $S \neq T$，[交叉](@entry_id:147634)输入 $(S, U \setminus T)$ 的交集 $S \setminus T$ 不会为空（除非 $S \subseteq T$），且 $(T, U \setminus S)$ 的交集 $T \setminus S$ 也不会为空（除非 $T \subseteq S$）。因为 $S \neq T$，两者不可能同时为空，所以至少有一个交叉输入的函数值为 0。这个构造满足[愚弄集](@entry_id:276010)的条件，其大小为 $2^n$（因为有 $2^n$ 个[子集](@entry_id:261956) $S$）。因此，我们得到 $D(\text{DISJ}_n) \ge \log_2(2^n) = n$。这个下界是紧的，因为 Alice 可以简单地把她的集合（用一个 $n$ 比特的[特征向量](@entry_id:151813)表示）发送给 Bob。

**2. 秩下界（Rank Lower Bound）**

秩下界是一种源于线性代数的强大技术。它不直接分析协议，而是分析通信矩阵的代数性质。对于一个布尔函数 $f: X \times Y \to \{0,1\}$，我们不直接使用 $M_f$，而是构造一个在[实数域](@entry_id:151347) $\mathbb{R}$ 上的[相关矩阵](@entry_id:262631)，通常定义为 $M'_f(x,y) = (-1)^{f(x,y)}$。

关键的定理是：$D(f) \ge \log_2(\text{rank}(M'_f))$，其中 $\text{rank}$ 是矩阵在实数域上的秩。这个定理的直觉在于，任何一个通信成本为 $c$ 的协议都可以将 $M'_f$ 分解为最多 $2^c$ 个秩为 1 的[单色矩形](@entry_id:269454)矩阵之和。由于[矩阵的秩](@entry_id:155507)是次可加的（$\text{rank}(A+B) \le \text{rank}(A) + \text{rank}(B)$），$M'_f$ 的秩不会超过这些秩 1 矩阵的数量，即 $\text{rank}(M'_f) \le 2^c$。

模 2 [内积](@entry_id:158127)函数（Inner Product Modulo 2, IP）是展示秩方法威力的标准例子[@problem_id:1465095]。Alice 和 Bob 各有 $n$ 比特串 $x, y \in \{0,1\}^n$，他们要计算 $f(x,y) = (\sum_{i=1}^n x_i y_i) \pmod 2$。我们构造一个 $2^n \times 2^n$ 的矩阵 $M$，其条目为 $M(x,y) = (-1)^{x \cdot y}$。通过计算 $M M^\mathsf{T}$，可以证明 $M M^\mathsf{T} = 2^n I$，其中 $I$ 是[单位矩阵](@entry_id:156724)。这意味着 $M$ 的行（和列）是正交的，因此[线性无关](@entry_id:148207)。一个 $2^n \times 2^n$ 矩阵有 $2^n$ 个[线性无关](@entry_id:148207)的行，说明它的秩是满的，即 $\text{rank}(M) = 2^n$。应用秩下界，我们得到 $D(\text{IP}) \ge \log_2(2^n) = n$。这个结果同样是紧的。

### 非确定性通信复杂性

除了确定性协议，我们还可以考虑**[非确定性](@entry_id:273591)（nondeterministic）**模型。想象一个拥有无限计算能力但不可信的“证明者”（有时称为 Merlin）。对于一个输入 $(x,y)$，如果 $f(x,y)=1$，证明者会提供一个“证书”或“证明”给 Alice 和 Bob。他们只需交换少量信息来验证这个证书的有效性。

**非确定性复杂性（Nondeterministic Complexity）**，记为 $N(f)$，是验证一个 $f(x,y)=1$ 的实例所需的最短证书的长度（以比特为单位）。从通信矩阵的角度看，$N(f) = \lceil \log_2(C^1(f)) \rceil$，其中 $C^1(f)$ 是用值为 1 的[单色矩形](@entry_id:269454)覆盖所有 $M_f$ 中值为 1 的条目所需的最小矩形数。类似地，**余非确定性复杂性（Co-nondeterministic Complexity）**，记为 $coN(f)$，是验证 $f(x,y)=0$ 所需的证书长度，对应于用值为 0 的[单色矩形](@entry_id:269454)覆盖。

[集合不相交性](@entry_id:276256)问题再次提供了一个绝佳的例子。我们已经知道 $D(\text{DISJ}_n) = n$。但如果我们想证明两个集合 *相交*（即 $X \cap Y \neq \emptyset$，对应 $\text{DISJ}_n=0$），情况会怎样？[@problem_id:1465121] 此时，一个完美的证书就是它们交集中的任意一个元素 $z \in X \cap Y$。证明者可以将元素 $z$ 的标识（需要 $\lceil \log_2 n \rceil$ 比特）提供给 Alice 和 Bob。Alice 验证 $z \in X$，Bob 验证 $z \in Y$。他们只需交换 1 比特来确认双方的验证都通过了。因此，验证相交性的成本非常低。这表明 $coN(\text{DISJ}_n) = O(\log n)$。这种确定性复杂性（$n$）与非确定性复杂性（$O(\log n)$）之间的巨大差距是通信复杂性理论中的一个核心主题。

一个著名的定理（由 Aho, Ullman, 和 Yannakakis 提出）表明，任何函数的这三种复杂性度量之间存在关系：$D(f) = O(N(f) \cdot coN(f))$。然而，这个关系并不总是紧的。存在一些函数，其确定性复杂性远小于非确定性和余[非确定性](@entry_id:273591)复杂性的乘积。反之，也存在一些函数，其确定性复杂性远大于这个乘积[@problem_id:1465126]，显示了这些复杂性度量之间可能存在的指数级分离。

### [随机化](@entry_id:198186)通信复杂性

就像在算法设计中一样，引入**随机性（randomness）**可以极大地提高通信效率，代价是允许协议有微小的失败概率。我们主要区分两种随机模型：

*   **私有硬币模型（Private-Coin Model）**：Alice 和 Bob 各自有自己独立的随机比特串。
*   **公共硬币模型（Public-Coin Model）**：Alice 和 Bob 共享一个对双方都可见的随机比特串。

公共硬币模型通常更强大，但任何[公共硬币协议](@entry_id:261274)都可以用少量额外通信（用于生成共享随机性）在私有硬币模型中模拟。

**1. [随机化](@entry_id:198186)指纹（Randomized Fingerprinting）**

[随机化协议](@entry_id:269010)的经典范例是用于**等价性测试（EQUALITY）**的指纹协议。我们已知 $D(\text{EQ}_n) = n$。但在随机化设定下，我们可以做得更好。

考虑[@problem_id:1465138]中的场景：Alice 和 Bob 共享一个随机的素数 $p$（从一个足够大的素数集合中选取）。Alice 计算她输入 $x$ 的“指纹” $f_x = I(x) \pmod p$，其中 $I(x)$ 是 $x$ 的整数表示，然后将这个指纹（一个远小于 $x$ 本身的数）发送给 Bob。Bob 同样计算 $f_y = I(y) \pmod p$ 并进行比较。如果指纹不同，那么 $x \neq y$。如果指纹相同，他们就猜测 $x=y$。

这个协议可能出错的唯一情况是当 $x \neq y$ 但 $I(x) \equiv I(y) \pmod p$。这等价于 $p$ 整除差值 $|I(x) - I(y)|$。通过精心[选择素](@entry_id:184160)数 $p$ 的范围，我们可以将这种“坏”素数的[比例控制](@entry_id:272354)得非常小。例如，如果差值最多有 $k$ 个素因子，而我们从 $m \gg k$ 个素数中随机选择一个，那么出错的概率大约是 $k/m$。这使得我们能够用 $O(\log n)$ 比特的通信（发送指纹）以极高的概率解决一个确定性需要 $O(n)$ 比特的问题。

类似的思想也适用于[集合不相交性](@entry_id:276256)问题[@problem_id:1465077]。Alice 和 Bob 可以共享一个随机哈希函数 $h: U \to \{1, \dots, k\}$。Alice 计算一个 $k$ 比特的指纹向量 $v_A$，其中第 $j$ 位为 1 当且仅当她的集合 $X$ 中有元素被哈希到 $j$。Bob 也做同样的事情。Alice 把她的指纹发送给 Bob。如果他们的指纹向量在任何位置上都同时为 1（即 $(v_A)_j = (v_B)_j = 1$），他们就猜测集合相交。当集合确实相交时，这个协议永远不会出错（因为交集中的元素会保证至少有一个位置 j 使得 $(v_A)_j = (v_B)_j = 1$）。当集合不相交时，它可能因为哈希碰撞（即存在 $x \in X, y \in Y$ 使得 $h(x)=h(y)$）而出错，从而错误地报告相交。通过调整 $k$ 的大小，可以在通信成本（$k$ 比特）和[错误概率](@entry_id:267618)之间进行权衡。

**2. 随机化下界：偏差（Discrepancy）**

要证明[随机化协议](@entry_id:269010)的下界，我们需要更精细的工具，因为协议不再需要对每个输入都正确。**偏差方法**是用于此目的的标准技术。

回顾通信矩阵 $M'_f(x,y) = (-1)^{f(x,y)}$。一个组合矩形 $R = A \times B$ 的**偏差**被定义为矩阵条目在该矩形内求和的[绝对值](@entry_id:147688)：$\text{Disc}(f, R) = |\sum_{x \in A, y \in B} (-1)^{f(x,y)}|$。函数 $f$ 的**偏差** $\text{Disc}(f)$ 是所有可能矩形中最大的偏差值。

偏差的直觉是：如果一个函数在任何大矩形内的值（+1 和 -1）都混合得非常好，导致和的[绝对值](@entry_id:147688)很小（低偏差），那么任何短的通信协议都无法可靠地计算它。这是因为协议的任何一步（对应于一个矩形）都无法给 Alice 或 Bob 提供关于最终结果的太多信息。一个关键的定理将随机化复杂性 $R(f)$ 与偏差联系起来：$R(f) = \Omega(\log(|X||Y|/\text{Disc}(f)))$。

计算偏差本身可能很复杂，但我们可以通过分析特定矩形来获得一些洞察[@problem_id:1465075]。例如，对于唯一交集函数（Unique Intersection），我们可以构造一个特定的矩形，并精确计算其中的 +1 和 -1 条目是如何相互抵消的，从而得到该矩形上的偏差值。

### 超越经典模型：量子通信

通信复杂性的研究并不局限于经典比特。引入量子力学资源，如[量子比特](@entry_id:137928)（qubit）和纠缠（entanglement），可以从根本上改变通信的规则。

一个引人注目的例子是**[超密编码](@entry_id:137220)（Superdense Coding）**[@problem_id:1465073]。假设 Alice 和 Bob 事先共享一对处于纠缠状态的[量子比特](@entry_id:137928)（一个 EPR 对）。现在，Alice 想要发送两个经典比特 $c_1, c_2$ 给 Bob。在经典世界里，这显然需要 2 比特的通信。

然而，利用纠缠，Alice 可以通过只向 Bob 发送她手中的那 *一个* [量子比特](@entry_id:137928)来完成任务。协议如下：根据她想发送的两位经典比特 `00`, `01`, `10`, 或 `11`，Alice 对她自己的[量子比特](@entry_id:137928)执行四种特定幺正操作中的一种（例如，泡利-X门或泡利-Z门）。这个操作会改变整个[双量子比特系统](@entry_id:203437)的纠缠状态，将其转换为四个相互正交的贝尔态之一。然后，Alice 将她的[量子比特](@entry_id:137928)发送给 Bob。Bob 现在拥有了这对[量子比特](@entry_id:137928)的全部，他可以执行一个贝尔基测量，这种测量能够完美地区分这四种正交状态。测量的结果直接告诉他 Alice 执行了哪种操作，从而让他能够恢复 $c_1$ 和 $c_2$ 两个经典比特。

这个惊人的结果表明，量子通信复杂性 $Q(f)$ 可以比确定性复杂性 $D(f)$ 更低。它揭示了信息在物理世界中的表示和传输可以遵循比经典直觉更丰富的规则，为[通信理论](@entry_id:272582)开辟了全新的前沿。