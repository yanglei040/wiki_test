{"hands_on_practices": [{"introduction": "样本平均近似 (SAA) 方法的解质量直接取决于样本量 $n$。本练习旨在引导你探索增加样本所带来的“边际效益递减”现象，并建立一个权衡解精度与采样成本的实用决策框架，以确定最佳样本量。这是将 SAA 应用于实际问题的核心考量之一 [@problem_id:3174778]。", "problem": "考虑一个随机优化问题，其中选择一个决策变量 $x \\in \\mathbb{R}$ 以最小化期望目标函数 $F(x) = \\mathbb{E}\\left[ \\phi(x,\\xi) \\right]$，其中 $\\phi(x,\\xi) = (x - \\xi)^2$，$\\xi$ 是一个具有有限二阶矩的实值随机变量。样本均值近似 (SAA) 方法基于 $n$ 个独立同分布的样本 $\\xi_1, \\dots, \\xi_n$ 构建估计量 $\\hat{x}_n$，该估计量是样本均值 $\\frac{1}{n} \\sum_{i=1}^{n} \\phi(x, \\xi_i)$ 的最小化子。目标是从经验上和理论上刻画函数 $n \\mapsto \\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$ 中的收益递减现象，并利用此特性来确定何时增加一个额外样本是不划算的。\n\n需要使用的基本依据和定义：\n- 样本均值近似 (SAA) 估计量 $\\hat{x}_n$ 定义为随机函数 $x \\mapsto \\frac{1}{n}\\sum_{i=1}^n \\phi(x, \\xi_i)$ 的任意最小化子。\n- 期望算子满足线性性，随机变量 $\\xi$ 的方差为 $\\operatorname{Var}(\\xi) = \\mathbb{E}\\left[(\\xi - \\mathbb{E}[\\xi])^2\\right]$。\n- 对于独立同分布的样本，样本均值 $\\bar{\\xi}_n = \\frac{1}{n}\\sum_{i=1}^n \\xi_i$ 满足 $\\mathbb{E}[\\bar{\\xi}_n] = \\mathbb{E}[\\xi]$ 和 $\\operatorname{Var}(\\bar{\\xi}_n) = \\operatorname{Var}(\\xi)/n$。\n\n任务：\n1. 经验刻画。对于下述每个测试用例，通过蒙特卡罗模拟构建函数 $n \\mapsto \\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$ 的经验估计。使用一个固定的样本量网格 $\\mathcal{N} = \\{1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144\\}$，并且对于每个 $n \\in \\mathcal{N}$，执行固定次数的独立蒙特卡罗重复实验，通过对每次重复实验计算出的 $F(\\hat{x}_n)$ 进行平均，来估计 $\\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$。在每次重复实验中，抽取 $n$ 个独立样本以构建 $\\hat{x}_n$，并使用 $\\xi$ 的一个独立实现或基于上述定义的等效无偏计算来评估 $F(\\hat{x}_n)$。在所有测试用例中使用固定的重复实验次数以确保可比性。\n2. 理论刻画。基于基本依据，推导 $\\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$ 作为 $n$ 和 $\\operatorname{Var}(\\xi)$ 的函数的闭式表达式，并随着 $n$ 增加，解析地刻画 $n \\mapsto \\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$ 的斜率。\n3. 模型拟合与决策规则。对于 $n \\in \\mathcal{N}$，通过最小二乘法将参数模型 $m(n) = a + \\frac{b}{n}$ 拟合到经验估计曲线上，以获得估计值 $(\\hat{a}, \\hat{b})$。然后，对于给定的非负样本成本 $c$（单位与目标值相同），考虑总期望损失 $L(n) = \\mathbb{E}\\left[ F(\\hat{x}_n) \\right] + c \\, n$，并通过最小化拟合模型 $m(n) + c \\, n$（在整数 $n \\geq 1$ 上），使用从拟合参数导出的解析近似来确定一个具成本效益的样本量 $\\hat{n}$。\n4. 理论基准。对于每个测试用例，结合任务2的解析刻画和上述决策规则 $L(n)$，计算理论最优整数样本量 $n^\\star$。\n5. 输出规范。对于每个测试用例，按下文列出的顺序返回配对 $(\\hat{n}, n^\\star)$。将所有测试用例的输出按指定顺序汇总到一个列表中：$\\left[\\hat{n}_1, n^\\star_1, \\hat{n}_2, n^\\star_2, \\hat{n}_3, n^\\star_3, \\hat{n}_4, n^\\star_4\\right]$，其中下标表示测试用例。您的程序应生成包含此列表的单行输出，格式为方括号内以逗号分隔的列表（例如，$\\left[\\text{result}_1, \\text{result}_2, \\text{result}_3\\right]$）。\n\n测试套件：\n- 测试用例 1：$\\xi \\sim \\mathcal{N}(\\mu, \\sigma^2)$，其中 $\\mu = 5$，$\\sigma = 2$，样本成本 $c = 0.05$。\n- 测试用例 2：$\\xi \\sim \\text{Uniform}[a,b]$，其中 $a = 0$，$b = 10$，样本成本 $c = 0.1$。\n- 测试用例 3：$\\xi \\sim \\text{Laplace}(\\mu, s)$，其中 $\\mu = 0$，尺度 $s = 1$，样本成本 $c = 3$。\n- 测试用例 4：$\\xi \\sim \\mathcal{N}(\\mu, \\sigma^2)$，其中 $\\mu = 0$，$\\sigma = 5$，样本成本 $c = 0.001$。\n\n所有数值答案应为无单位的实数或整数（视情况而定），且不涉及角度。最终答案必须是整数；基于模型拟合的决策 $\\hat{n}$ 和理论基准 $n^\\star$ 应四舍五入到最近的整数，并约束为至少为 $1$。", "solution": "该问题要求分析用于随机优化问题的样本均值近似 (SAA) 方法，并基于理论推导和经验模拟来确定一个具成本效益的样本量。\n\n问题陈述为最小化期望目标函数 $F(x) = \\mathbb{E}\\left[ \\phi(x,\\xi) \\right]$，其中 $\\phi(x,\\xi) = (x - \\xi)^2$，$x \\in \\mathbb{R}$ 是决策变量，$\\xi$ 是一个具有有限二阶矩的实值随机变量。SAA 估计量 $\\hat{x}_n$ 是样本量为 $n$ 时样本均值目标函数 $\\frac{1}{n} \\sum_{i=1}^{n} \\phi(x, \\xi_i)$ 的最小化子。\n\n解决方案首先推导估计量和期望目标值的理论性质，然后详细说明经验模拟和拟合过程。\n\n### 1. 理论刻画\n\n首先，我们推导 $\\mathbb{E}\\left[ F(\\hat{x}_n) \\right]$ 作为样本量 $n$ 的函数的闭式表达式。这对应于任务2。\n\n真实目标函数是 $F(x) = \\mathbb{E}[(x-\\xi)^2]$。令 $\\mu = \\mathbb{E}[\\xi]$ 且 $\\sigma^2 = \\operatorname{Var}(\\xi)$。展开期望可得：\n$$F(x) = \\mathbb{E}[x^2 - 2x\\xi + \\xi^2] = x^2 - 2x\\mathbb{E}[\\xi] + \\mathbb{E}[\\xi^2] = x^2 - 2x\\mu + (\\mu^2 + \\sigma^2)$$\n这是一个关于 $x$ 的凸二次函数。通过将其一阶导数设为零，可以找到最小化子 $x^\\star$：\n$$\\frac{dF(x)}{dx} = 2x - 2\\mu = 0 \\implies x^\\star = \\mu$$\n真实目标的最小值为 $F(x^\\star) = F(\\mu) = (\\mu-\\mu)^2 + \\sigma^2 = \\sigma^2 = \\operatorname{Var}(\\xi)$。\n\nSAA 估计量 $\\hat{x}_n$ 最小化样本均值目标函数 $\\hat{F}_n(x) = \\frac{1}{n}\\sum_{i=1}^n (x - \\xi_i)^2$。将其导数设为零可得：\n$$\\frac{d\\hat{F}_n(x)}{dx} = \\frac{1}{n}\\sum_{i=1}^n 2(x - \\xi_i) = 2x - \\frac{2}{n}\\sum_{i=1}^n \\xi_i = 0$$\n这得到了 SAA 估计量 $\\hat{x}_n = \\frac{1}{n}\\sum_{i=1}^n \\xi_i$，即样本均值，记作 $\\bar{\\xi}_n$。\n\n我们关心的是该估计量的期望性能，即 $\\mathbb{E}[F(\\hat{x}_n)]$。这里的期望是关于决定 $\\hat{x}_n$ 的样本 $\\{\\xi_1, \\dots, \\xi_n\\}$ 的分布来计算的。\n函数 $F(\\cdot)$ 在随机点 $\\hat{x}_n$ 处的取值为：\n$$F(\\hat{x}_n) = (\\hat{x}_n - \\mu)^2 + \\sigma^2$$\n这个表达式本身就是一个随机变量，因为 $\\hat{x}_n$ 依赖于样本。为了求其期望值，我们对所有可能的样本取期望：\n$$\\mathbb{E}[F(\\hat{x}_n)] = \\mathbb{E}\\left[ (\\hat{x}_n - \\mu)^2 + \\sigma^2 \\right]$$\n利用期望的线性性，这变为：\n$$\\mathbb{E}[F(\\hat{x}_n)] = \\mathbb{E}\\left[ (\\hat{x}_n - \\mu)^2 \\right] + \\sigma^2$$\n项 $\\mathbb{E}\\left[ (\\hat{x}_n - \\mu)^2 \\right]$ 是 $\\hat{x}_n$ 的方差的定义，因为 $\\mathbb{E}[\\hat{x}_n] = \\mathbb{E}[\\bar{\\xi}_n] = \\mu$。对于独立同分布的样本，样本均值的方差为：\n$$\\operatorname{Var}(\\hat{x}_n) = \\operatorname{Var}(\\bar{\\xi}_n) = \\frac{\\operatorname{Var}(\\xi)}{n} = \\frac{\\sigma^2}{n}$$\n将其代回，我们得到理论刻画：\n$$\\mathbb{E}[F(\\hat{x}_n)] = \\sigma^2 + \\frac{\\sigma^2}{n} = \\operatorname{Var}(\\xi)\\left(1 + \\frac{1}{n}\\right)$$\n该表达式的形式为 $a+b/n$，其中 $a = b = \\operatorname{Var}(\\xi)$。关于 $n$ 的斜率为 $-\\operatorname{Var}(\\xi)/n^2$，这表明随着 $n$ 的增加，收益递减。\n\n### 2. 最优样本量确定\n\n问题定义了总期望损失 $L(n) = \\mathbb{E}\\left[ F(\\hat{x}_n) \\right] + c \\, n$，其中 $c$ 是每个样本的成本。目标是找到最小化此总损失的样本量 $n$。\n\n**理论基准 ($n^\\star$)**\n使用推导出的 $\\mathbb{E}[F(\\hat{x}_n)]$ 的闭式表达式 (任务 4)：\n$$L(n) = \\operatorname{Var}(\\xi) + \\frac{\\operatorname{Var}(\\xi)}{n} + cn$$\n为了找到最小值，我们将 $n$ 视为 $n > 0$ 的连续变量，并将其导数设为零：\n$$\\frac{dL(n)}{dn} = -\\frac{\\operatorname{Var}(\\xi)}{n^2} + c = 0$$\n这得到 $n^2 = \\frac{\\operatorname{Var}(\\xi)}{c}$，因此最优连续样本量为 $n = \\sqrt{\\frac{\\operatorname{Var}(\\xi)}{c}}$。由于样本量必须是正整数，理论最优样本量 $n^\\star$ 通过将此值四舍五入到最近的整数并确保其至少为 1 来找到：\n$$n^\\star = \\max\\left(1, \\left\\lfloor \\sqrt{\\frac{\\operatorname{Var}(\\xi)}{c}} + 0.5 \\right\\rfloor\\right)$$\n\n**经验估计 ($\\hat{n}$)**\n经验过程（任务1和3）包括三个步骤：\n1.  蒙特卡罗模拟：对于每个样本量 $n_j \\in \\mathcal{N}$，我们通过对大量独立重复实验进行平均来估计 $\\mathbb{E}[F(\\hat{x}_n)]$。在每次重复实验中，我们抽取一个样本 $\\{\\xi_i\\}_{i=1}^n$，计算 $\\hat{x}_n = \\bar{\\xi}_n$，然后计算 $F(\\hat{x}_n) = (\\hat{x}_n - \\mu)^2 + \\sigma^2$。这些值在所有重复实验中的平均值提供了一个经验估计 $y_j \\approx \\mathbb{E}[F(\\hat{x}_n)]$。这将为 $n_j \\in \\mathcal{N}$ 生成一组数据点 $(n_j, y_j)$。\n2.  模型拟合：我们将参数模型 $m(n) = a + b/n$ 拟合到经验数据 $(n_j, y_j)_{j=1}^{|\\mathcal{N}|}$。如果我们令 $z_j = 1/n_j$，这就是一个线性回归问题。我们寻求参数 $(\\hat{a}, \\hat{b})$ 来最小化平方误差和 $\\sum (y_j - (a + b/n_j))^2$。\n3.  决策规则：使用拟合模型，我们定义一个近似总损失函数 $\\hat{L}(n) = m(n) + cn = \\hat{a} + \\frac{\\hat{b}}{n} + cn$。相对于 $n$ 最小化此函数（假设 $\\hat{b} > 0$）得到最优连续样本量 $n = \\sqrt{\\frac{\\hat{b}}{c}}$。通过四舍五入获得整数值估计 $\\hat{n}$：\n$$\\hat{n} = \\max\\left(1, \\left\\lfloor \\sqrt{\\frac{\\hat{b}}{c}} + 0.5 \\right\\rfloor\\right)$$\n\n### 3. 应用于测试用例\n\n该过程应用于每个测试用例。\n-   测试用例 1：$\\xi \\sim \\mathcal{N}(\\mu=5, \\sigma=2)$。$\\operatorname{Var}(\\xi) = 2^2=4$。成本 $c=0.05$。\n    $n^\\star = \\max(1, \\text{round}(\\sqrt{4/0.05})) = \\max(1, \\text{round}(\\sqrt{80})) = \\max(1, \\text{round}(8.944)) = 9$。\n-   测试用例 2：$\\xi \\sim \\text{Uniform}[0, 10]$。$\\operatorname{Var}(\\xi) = (10-0)^2/12 = 100/12$。成本 $c=0.1$。\n    $n^\\star = \\max(1, \\text{round}(\\sqrt{(100/12)/0.1})) = \\max(1, \\text{round}(\\sqrt{83.333})) = \\max(1, \\text{round}(9.129)) = 9$。\n-   测试用例 3：$\\xi \\sim \\text{Laplace}(\\mu=0, s=1)$。$\\operatorname{Var}(\\xi) = 2s^2=2$。成本 $c=3$。\n    $n^\\star = \\max(1, \\text{round}(\\sqrt{2/3})) = \\max(1, \\text{round}(\\sqrt{0.667})) = \\max(1, \\text{round}(0.816)) = 1$。\n-   测试用例 4：$\\xi \\sim \\mathcal{N}(\\mu=0, \\sigma=5)$。$\\operatorname{Var}(\\xi) = 5^2=25$。成本 $c=0.001$。\n    $n^\\star = \\max(1, \\text{round}(\\sqrt{25/0.001})) = \\max(1, \\text{round}(\\sqrt{25000})) = \\max(1, \\text{round}(158.114)) = 158$。\n\n$\\hat{n}$ 的值取决于蒙特卡罗模拟的结果，并在随附的代码中计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the SAA problem by performing theoretical calculations and empirical simulations\n    to find the optimal sample sizes.\n    \"\"\"\n    \n    # Set a seed for reproducibility of random number generation.\n    np.random.seed(42)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'name': 'Case 1', 'dist': 'normal', 'params': {'mu': 5.0, 'sigma': 2.0}, 'c': 0.05},\n        {'name': 'Case 2', 'dist': 'uniform', 'params': {'a': 0.0, 'b': 10.0}, 'c': 0.1},\n        {'name': 'Case 3', 'dist': 'laplace', 'params': {'mu': 0.0, 's': 1.0}, 'c': 3.0},\n        {'name': 'Case 4', 'dist': 'normal', 'params': {'mu': 0.0, 'sigma': 5.0}, 'c': 0.001},\n    ]\n\n    # Fixed parameters for the Monte Carlo simulation.\n    N_GRID = np.array([1, 2, 3, 5, 8, 13, 21, 34, 55, 89, 144])\n    N_REPS = 50000  # Number of Monte Carlo replicates.\n\n    results = []\n    for case in test_cases:\n        c = case['c']\n        \n        # Determine distribution parameters and variance\n        if case['dist'] == 'normal':\n            mu = case['params']['mu']\n            sigma = case['params']['sigma']\n            var_xi = sigma**2\n            def sample_generator(size):\n                return np.random.normal(loc=mu, scale=sigma, size=size)\n        elif case['dist'] == 'uniform':\n            a, b = case['params']['a'], case['params']['b']\n            mu = (a + b) / 2.0\n            var_xi = (b - a)**2 / 12.0\n            def sample_generator(size):\n                return np.random.uniform(low=a, high=b, size=size)\n        elif case['dist'] == 'laplace':\n            mu = case['params']['mu']\n            s = case['params']['s']\n            var_xi = 2.0 * s**2\n            def sample_generator(size):\n                return np.random.laplace(loc=mu, scale=s, size=size)\n\n        # Task 1: Empirical characterization\n        empirical_y = []\n        for n in N_GRID:\n            # Vectorized computation for efficiency\n            # Generate all samples for all replicates at once\n            samples = sample_generator(size=(N_REPS, n))\n            # Compute SAA estimator (x_hat_n) for each replicate\n            x_hat_n_reps = np.mean(samples, axis=1)\n            # Compute F(x_hat_n) for each replicate using the analytical formula\n            F_x_hat_n_reps = (x_hat_n_reps - mu)**2 + var_xi\n            # Estimate E[F(x_hat_n)] by averaging over replicates\n            estimated_E_F_xn = np.mean(F_x_hat_n_reps)\n            empirical_y.append(estimated_E_F_xn)\n        \n        empirical_y = np.array(empirical_y)\n\n        # Task 3: Model fitting and decision rule\n        # Fit model m(n) = a + b/n, which is linear in 1/n\n        z = 1.0 / N_GRID\n        # Design matrix for least squares: y = a*1 + b*z\n        A = np.vstack([np.ones(len(z)), z]).T\n        \n        # Solve for [a, b] using least squares\n        # The result gives [intercept, slope], which corresponds to [a, b]\n        a_hat, b_hat = np.linalg.lstsq(A, empirical_y, rcond=None)[0]\n\n        # Determine empirically-derived optimal sample size n_hat\n        # Minimize L(n) = a_hat + b_hat/n + c*n\n        if b_hat = 0:\n            # If b_hat is non-positive, the cost function L(n) is monotonically increasing for n > 0.\n            # The minimum occurs at the smallest possible integer n.\n            n_hat = 1\n        else:\n            # From dL/dn = 0, we get n = sqrt(b_hat/c)\n            n_hat_continuous = np.sqrt(b_hat / c)\n            # Round to the nearest integer, with a minimum of 1.\n            n_hat = max(1, int(np.round(n_hat_continuous)))\n        \n        results.append(n_hat)\n\n        # Task 4: Theoretical benchmark\n        # Optimal n is derived from minimizing L(n) = var_xi + var_xi/n + c*n\n        # This gives n = sqrt(var_xi / c)\n        n_star_continuous = np.sqrt(var_xi / c)\n        # Round to the nearest integer, with a minimum of 1.\n        n_star = max(1, int(np.round(n_star_continuous)))\n        \n        results.append(n_star)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3174778"}, {"introduction": "在优化实践中，我们常常需要比较不同决策或策略的优劣。本练习将介绍一种强大的方差缩减技术——“公共随机数” (CRN)，它通过引入正相关性来显著提高决策比较的统计效率。理解并掌握此方法将帮助你设计出更高效的模拟实验 [@problem_id:3174809]。", "problem": "考虑使用样本均值近似 (SAA) 方法来估计两个决策之间期望损失的差异。设期望损失定义为 $F(x) = \\mathbb{E}[g(x,\\xi)]$，SAA 估计量定义为\n$$\n\\hat{F}(x) = \\frac{1}{N} \\sum_{i=1}^{N} g(x,\\xi_i),\n$$\n其中 $\\xi_1,\\dots,\\xi_N$ 是随机输入 $\\xi$ 的独立同分布实现。对于决策 $x_1$，假设其损失为 $g(x_1,\\xi) = 2\\xi + \\varepsilon_1$；对于决策 $x_2$，假设其损失为 $g(x_2,\\xi) = 3\\xi + \\varepsilon_2$，其中 $\\xi \\sim \\mathcal{N}(0,1)$，$\\varepsilon_1 \\sim \\mathcal{N}(0,2)$，且 $\\varepsilon_2 \\sim \\mathcal{N}(0,3)$。假设 $\\xi$、$\\varepsilon_1$ 和 $\\varepsilon_2$ 相互独立，并且对于每个 $i=1,\\dots,N$，三元组 $(\\xi_i,\\varepsilon_{1,i},\\varepsilon_{2,i})$ 是 $(\\xi,\\varepsilon_1,\\varepsilon_2)$ 的独立同分布副本。\n\n比较用于估计差异 $\\hat{F}(x_1) - \\hat{F}(x_2)$ 的两种抽样方案：\n1. 使用公共随机数 (CRN)，即对于每个 $i$，在 $g(x_1,\\xi_i)$ 和 $g(x_2,\\xi_i)$ 中使用相同的 $\\xi_i$，而 $\\varepsilon_{1,i}$ 和 $\\varepsilon_{2,i}$ 在所有 $i$ 上保持独立且相互独立。\n2. 使用独立抽样，即分别为 $x_1$ 和 $x_2$ 使用独立的序列 $\\{\\xi_i^{(1)}\\}_{i=1}^{N}$ 和 $\\{\\xi_i^{(2)}\\}_{i=1}^{N}$，每个序列都与 $\\xi$ 同分布，并且所有噪声项在不同决策和样本间都是独立的。\n\n从期望、方差和协方差的定义以及独立随机变量和的性质出发，推导两种方案下 $\\operatorname{Var}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)$ 作为 $N$ 的函数的表达式。然后，对于 $N=100$，计算精确比率\n$$\n\\rho = \\frac{\\operatorname{Var}_{\\text{indep}}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)}{\\operatorname{Var}_{\\text{CRN}}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)}.\n$$\n将你的最终答案表示为一个精确的数值。", "solution": "### 步骤 1：提取已知条件\n- 期望损失：$F(x) = \\mathbb{E}[g(x,\\xi)]$\n- SAA 估计量：$\\hat{F}(x) = \\frac{1}{N} \\sum_{i=1}^{N} g(x,\\xi_i)$\n- 决策 $x_1$ 的损失函数：$g(x_1,\\xi) = 2\\xi + \\varepsilon_1$\n- 决策 $x_2$ 的损失函数：$g(x_2,\\xi) = 3\\xi + \\varepsilon_2$\n- 随机变量分布：\n    - $\\xi \\sim \\mathcal{N}(0,1)$，意味着 $\\mathbb{E}[\\xi] = 0$ 且 $\\operatorname{Var}(\\xi) = 1$。\n    - $\\varepsilon_1 \\sim \\mathcal{N}(0,2)$，意味着 $\\mathbb{E}[\\varepsilon_1] = 0$ 且 $\\operatorname{Var}(\\varepsilon_1) = 2$。\n    - $\\varepsilon_2 \\sim \\mathcal{N}(0,3)$，意味着 $\\mathbb{E}[\\varepsilon_2] = 0$ 且 $\\operatorname{Var}(\\varepsilon_2) = 3$。\n- 独立性假设：\n    - $\\xi$、$\\varepsilon_1$ 和 $\\varepsilon_2$ 相互独立。\n    - 对于每个 $i=1,\\dots,N$，三元组 $(\\xi_i, \\varepsilon_{1,i}, \\varepsilon_{2,i})$ 是独立同分布 (i.i.d.) 副本。\n- 用于估计 $\\hat{F}(x_1) - \\hat{F}(x_2)$ 的比较抽样方案：\n    1.  公共随机数 (CRN)：对 $g(x_1,\\cdot)$ 和 $g(x_2,\\cdot)$ 使用相同的 $\\xi_i$。\n    2.  独立抽样：独立的序列 $\\{\\xi_i^{(1)}\\}_{i=1}^{N}$ 和 $\\{\\xi_i^{(2)}\\}_{i=1}^{N}$。\n- 目标：推导两种方案的 $\\operatorname{Var}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)$，然后计算 $N=100$ 时的比率 $\\rho = \\frac{\\operatorname{Var}_{\\text{indep}}}{\\operatorname{Var}_{\\text{CRN}}}$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，植根于概率论、统计学和模拟的原理，特别是在样本均值近似 (SAA) 和方差缩减技术的背景下。这是一个适定问题，提供了推导唯一确定性解所需的所有信息。损失函数、随机变量及其分布的定义清晰无歧义。问题设置内部一致，不包含任何矛盾的陈述或科学上不合理的条件。目标陈述清晰且可形式化。该问题没有表现出验证清单中列出的任何缺陷。\n\n### 步骤 3：结论与行动\n问题有效。现在开始求解过程。\n\n目标是在两种不同的抽样方案下，计算并比较期望损失差异的估计量 $\\hat{F}(x_1) - \\hat{F}(x_2)$ 的方差。我们感兴趣的量是 $\\operatorname{Var}(\\hat{F}(x_1) - \\hat{F}(x_2))$。根据方差的性质，我们有：\n$$\n\\operatorname{Var}(\\hat{F}(x_1) - \\hat{F}(x_2)) = \\operatorname{Var}(\\hat{F}(x_1)) + \\operatorname{Var}(\\hat{F}(x_2)) - 2\\operatorname{Cov}(\\hat{F}(x_1), \\hat{F}(x_2))\n$$\n首先，我们计算单个 SAA 估计量的方差，即 $\\operatorname{Var}(\\hat{F}(x_1))$ 和 $\\operatorname{Var}(\\hat{F}(x_2))$。这些方差与用于估计差异的抽样方案无关。\n\nSAA 估计量是 $N$ 个独立同分布随机变量的均值。因此，其方差是单个项方差的 $\\frac{1}{N}$ 倍。\n$$\n\\operatorname{Var}(\\hat{F}(x)) = \\operatorname{Var}\\left(\\frac{1}{N} \\sum_{i=1}^{N} g(x,\\xi_i)\\right) = \\frac{1}{N^2} \\sum_{i=1}^{N} \\operatorname{Var}(g(x,\\xi_i)) = \\frac{N \\operatorname{Var}(g(x,\\xi))}{N^2} = \\frac{\\operatorname{Var}(g(x,\\xi))}{N}\n$$\n我们需要计算每个损失函数的方差。\n对于决策 $x_1$，损失函数为 $g(x_1,\\xi,\\varepsilon_1) = 2\\xi + \\varepsilon_1$。由于 $\\xi$ 和 $\\varepsilon_1$ 是独立的，其方差为：\n$$\n\\operatorname{Var}(g(x_1,\\xi,\\varepsilon_1)) = \\operatorname{Var}(2\\xi + \\varepsilon_1) = \\operatorname{Var}(2\\xi) + \\operatorname{Var}(\\varepsilon_1) = 2^2 \\operatorname{Var}(\\xi) + \\operatorname{Var}(\\varepsilon_1) = 4(1) + 2 = 6\n$$\n对于决策 $x_2$，损失函数为 $g(x_2,\\xi,\\varepsilon_2) = 3\\xi + \\varepsilon_2$。由于 $\\xi$ 和 $\\varepsilon_2$ 是独立的，其方差为：\n$$\n\\operatorname{Var}(g(x_2,\\xi,\\varepsilon_2)) = \\operatorname{Var}(3\\xi + \\varepsilon_2) = \\operatorname{Var(3\\xi)} + \\operatorname{Var}(\\varepsilon_2) = 3^2 \\operatorname{Var}(\\xi) + \\operatorname{Var}(\\varepsilon_2) = 9(1) + 3 = 12\n$$\n因此，单个 SAA 估计量的方差为：\n$$\n\\operatorname{Var}(\\hat{F}(x_1)) = \\frac{\\operatorname{Var}(g(x_1,\\xi,\\varepsilon_1))}{N} = \\frac{6}{N}\n$$\n$$\n\\operatorname{Var}(\\hat{F}(x_2)) = \\frac{\\operatorname{Var}(g(x_2,\\xi,\\varepsilon_2))}{N} = \\frac{12}{N}\n$$\n\n现在我们来分析两种抽样方案。\n\n**方案 1：独立抽样**\n在此方案下，使用独立的随机数集来评估 $\\hat{F}(x_1)$ 和 $\\hat{F}(x_2)$。具体来说，$\\hat{F}(x_1) = \\frac{1}{N}\\sum_{i=1}^{N} (2\\xi_i^{(1)} + \\varepsilon_{1,i})$ 且 $\\hat{F}(x_2) = \\frac{1}{N}\\sum_{i=1}^{N} (3\\xi_i^{(2)} + \\varepsilon_{2,i})$。所有随机变量 $\\{\\xi_i^{(1)}\\}$, $\\{\\xi_i^{(2)}\\}$, $\\{\\varepsilon_{1,i}\\}$, $\\{\\varepsilon_{2,i}\\}$ 都是相互独立的。因此，两个估计量 $\\hat{F}(x_1)$ 和 $\\hat{F}(x_2)$ 是独立的随机变量。对于独立变量，协方差为零：\n$$\n\\operatorname{Cov}_{\\text{indep}}(\\hat{F}(x_1), \\hat{F}(x_2)) = 0\n$$\n差的方差是方差之和：\n$$\n\\operatorname{Var}_{\\text{indep}}(\\hat{F}(x_1) - \\hat{F}(x_2)) = \\operatorname{Var}(\\hat{F}(x_1)) + \\operatorname{Var}(\\hat{F}(x_2)) = \\frac{6}{N} + \\frac{12}{N} = \\frac{18}{N}\n$$\n\n**方案 2：公共随机数 (CRN)**\n在 CRN 方案下，两个估计量使用相同的随机数流 $\\xi_i$。令 $g_{1,i} = 2\\xi_i + \\varepsilon_{1,i}$ 且 $g_{2,i} = 3\\xi_i + \\varepsilon_{2,i}$。估计量的差为：\n$$\n\\hat{F}(x_1) - \\hat{F}(x_2) = \\frac{1}{N}\\sum_{i=1}^{N} g_{1,i} - \\frac{1}{N}\\sum_{i=1}^{N} g_{2,i} = \\frac{1}{N}\\sum_{i=1}^{N} (g_{1,i} - g_{2,i})\n$$\n对于 $i=1, \\dots, N$，项 $(g_{1,i} - g_{2,i})$ 是独立同分布的。因此，其和的方差为：\n$$\n\\operatorname{Var}_{\\text{CRN}}(\\hat{F}(x_1) - \\hat{F}(x_2)) = \\operatorname{Var}\\left(\\frac{1}{N}\\sum_{i=1}^{N} (g_{1,i} - g_{2,i})\\right) = \\frac{1}{N}\\operatorname{Var}(g_1 - g_2)\n$$\n其中 $g_1 = 2\\xi + \\varepsilon_1$ 且 $g_2 = 3\\xi + \\varepsilon_2$。我们来计算差 $g_1 - g_2$ 的方差：\n$$\ng_1 - g_2 = (2\\xi + \\varepsilon_1) - (3\\xi + \\varepsilon_2) = -\\xi + \\varepsilon_1 - \\varepsilon_2\n$$\n由于 $\\xi$、$\\varepsilon_1$ 和 $\\varepsilon_2$ 相互独立，这个和的方差是各项方差之和：\n$$\n\\operatorname{Var}(g_1 - g_2) = \\operatorname{Var}(-\\xi + \\varepsilon_1 - \\varepsilon_2) = \\operatorname{Var}(-\\xi) + \\operatorname{Var}(\\varepsilon_1) + \\operatorname{Var}(-\\varepsilon_2)\n$$\n使用性质 $\\operatorname{Var}(aX) = a^2\\operatorname{Var}(X)$：\n$$\n\\operatorname{Var}(g_1 - g_2) = (-1)^2\\operatorname{Var}(\\xi) + \\operatorname{Var}(\\varepsilon_1) + (-1)^2\\operatorname{Var}(\\varepsilon_2) = \\operatorname{Var}(\\xi) + \\operatorname{Var}(\\varepsilon_1) + \\operatorname{Var}(\\varepsilon_2)\n$$\n代入给定的方差：\n$$\n\\operatorname{Var}(g_1 - g_2) = 1 + 2 + 3 = 6\n$$\n因此，在 CRN 方案下，差估计量的方差为：\n$$\n\\operatorname{Var}_{\\text{CRN}}(\\hat{F}(x_1) - \\hat{F}(x_2)) = \\frac{\\operatorname{Var}(g_1 - g_2)}{N} = \\frac{6}{N}\n$$\n这个结果是正数，与方差是非负的这一性质相符。由公共随机数 $\\xi$ 引起的 $g_1$ 和 $g_2$ 之间的正协方差成功地减小了差的方差。\n\n最后，我们计算所要求的比率 $\\rho$。问题指定了 $N=100$，但我们可以看到，该比率与 $N$ 无关。\n$$\n\\rho = \\frac{\\operatorname{Var}_{\\text{indep}}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)}{\\operatorname{Var}_{\\text{CRN}}\\!\\left(\\hat{F}(x_1) - \\hat{F}(x_2)\\right)} = \\frac{18/N}{6/N} = \\frac{18}{6} = 3\n$$\n$N=100$ 的值不影响最终的比率。该比率是一个精确的数值。", "answer": "$$\\boxed{3}$$", "id": "3174809"}, {"introduction": "SAA 为真实问题提供了无偏的近似，但其解本身可能因为样本的随机性而具有高方差。本练习将探索如何通过引入“岭正则化”来主动增加微小的偏差，以换取解方差的显著降低，从而获得整体更优的解。这个过程深刻揭示了统计学与机器学习中的核心概念——“偏差-方差权衡” [@problem_id:3174756]。", "problem": "考虑最小化期望平方偏差的随机优化问题，其中决策 $x \\in \\mathbb{R}$ 在随机扰动 $\\xi$ 下的损失函数定义为 $f(x,\\xi) = \\frac{1}{2}(x - \\xi)^{2}$。假设 $\\xi$ 服从均值为 $\\mu \\neq 0$、方差为 $\\sigma^{2}$ 的正态分布，并设 $\\xi_{1},\\ldots,\\xi_{n}$ 是从该分布中抽取的独立同分布样本。\n\n基于样本均值近似（SAA），定义经验目标函数 $\\hat{f}_{n}(x) = \\frac{1}{2n}\\sum_{i=1}^{n}(x - \\xi_{i})^{2}$，并考虑岭正则化的 SAA 问题\n$$\n\\min_{x \\in \\mathbb{R}} \\ \\hat{f}_{n}(x) + \\frac{\\lambda}{2}\\|x\\|^{2},\n$$\n其中 $\\lambda \\geq 0$ 是正则化参数，$\\|x\\|$ 表示欧几里得范数。\n\n从期望和方差的基本定义以及正态分布的性质出发，按以下步骤进行：\n\n1. 求解岭正则化的 SAA 问题，以获得优化器 $x_{n}^{\\lambda}$，将其表示为样本均值 $\\bar{\\xi} = \\frac{1}{n}\\sum_{i=1}^{n}\\xi_{i}$ 和 $\\lambda$ 的函数。\n\n2. 设 $F(x) = \\mathbb{E}[f(x,\\xi)]$，并用 $v^{\\star} = \\inf_{x \\in \\mathbb{R}}F(x)$ 表示真实最优值。考虑 $v^{\\star}$ 的代入估计量 $\\tilde{v}_{n}^{\\lambda} = F(x_{n}^{\\lambda})$。推导偏差 $\\mathbb{E}[\\tilde{v}_{n}^{\\lambda}] - v^{\\star}$ 和方差 $\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda})$ 的显式公式，用 $\\mu$、$\\sigma^{2}$、$n$ 和 $\\lambda$ 表示。\n\n3. 对大样本 $n$ 使用前导阶渐近分析，确定正则化参数 $\\lambda$（作为 $n$、$\\mu$ 和 $\\sigma^{2}$ 的函数），该参数在 $1/n$ 的一阶精度上最小化均方误差 $\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\left(\\mathbb{E}[\\tilde{v}_{n}^{\\lambda}] - v^{\\star}\\right)^{2} + \\mathrm{Var}(\\tilde{v}_{n}^{\\lambda})$。您的推导必须从基本定义开始，且仅使用正态随机变量的期望和方差的性质。\n\n将您的最终答案表示为渐近最优 $\\lambda$ 的单一闭式解析表达式，用 $n$、$\\mu$ 和 $\\sigma^{2}$ 表示。无需四舍五入。", "solution": "用户希望我解决一个关于带岭正则化的样本均值近似（SAA）的三部分问题。\n\n### 问题验证\n\n**第 1 步：提取已知条件**\n\n-   损失函数：$f(x,\\xi) = \\frac{1}{2}(x - \\xi)^{2}$，其中 $x \\in \\mathbb{R}$。\n-   随机变量：$\\xi$ 服从均值为 $\\mu \\neq 0$、方差为 $\\sigma^2$ 的正态分布。因此，$\\xi \\sim N(\\mu, \\sigma^2)$。\n-   样本：$\\xi_{1},\\ldots,\\xi_{n}$ 是从 $\\xi$ 的分布中抽取的独立同分布（i.i.d.）样本。\n-   SAA 目标函数：$\\hat{f}_{n}(x) = \\frac{1}{2n}\\sum_{i=1}^{n}(x - \\xi_{i})^{2}$。\n-   岭正则化的 SAA 问题：$\\min_{x \\in \\mathbb{R}} \\ \\hat{f}_{n}(x) + \\frac{\\lambda}{2}\\|x\\|^{2}$，其中 $\\lambda \\geq 0$，$\\|x\\|$ 是欧几里得范数。\n-   样本均值：$\\bar{\\xi} = \\frac{1}{n}\\sum_{i=1}^{n}\\xi_{i}$。\n-   真实目标函数：$F(x) = \\mathbb{E}[f(x,\\xi)]$。\n-   真实最优值：$v^{\\star} = \\inf_{x \\in \\mathbb{R}}F(x)$。\n-   代入估计量：$\\tilde{v}_{n}^{\\lambda} = F(x_{n}^{\\lambda})$，其中 $x_{n}^{\\lambda}$ 是正则化 SAA 问题的解。\n-   均方误差 (MSE)：$\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\left(\\mathbb{E}[\\tilde{v}_{n}^{\\lambda}] - v^{\\star}\\right)^{2} + \\mathrm{Var}(\\tilde{v}_{n}^{\\lambda})$。\n\n**第 2 步：使用提取的已知条件进行验证**\n\n-   **科学依据**：该问题在统计学习理论和随机优化领域是成熟的。它涉及 SAA、岭正则化、偏差-方差权衡和 MSE 分析等标准概念。使用二次损失函数和正态分布是常见且科学合理的。\n-   **适定性**：问题定义清晰。目标函数是凸的，确保存在唯一的最小化器。任务是具体的，并导向唯一的解析解。\n-   **客观性**：问题使用精确的数学语言陈述，没有任何主观或模糊的术语。\n\n**第 3 步：结论与行动**\n\n该问题是有效的，因为它是自洽的、科学合理的且适定的。我将继续进行完整解答。\n\n### 第 1 部分：求解岭正则化的 SAA 问题\n\n正则化的目标函数是 $L(x) = \\hat{f}_{n}(x) + \\frac{\\lambda}{2}\\|x\\|^{2}$。由于 $x \\in \\mathbb{R}$，$\\|x\\|^2 = x^2$。\n$$\nL(x) = \\frac{1}{2n}\\sum_{i=1}^{n}(x - \\xi_{i})^{2} + \\frac{\\lambda}{2}x^{2}\n$$\n当 $\\lambda \\ge 0$ 时，该函数是严格凸的（因为第一项是凸的，当 $\\lambda  0$ 时第二项是严格凸的，当 $\\lambda=0$ 时其和是凸的）。通过将关于 $x$ 的一阶导数设为零，可以找到唯一的最小化器 $x_{n}^{\\lambda}$。\n$$\n\\frac{d L(x)}{dx} = \\frac{d}{dx} \\left( \\frac{1}{2n}\\sum_{i=1}^{n}(x^{2} - 2x\\xi_{i} + \\xi_{i}^{2}) + \\frac{\\lambda}{2}x^{2} \\right) = \\frac{1}{2n}\\sum_{i=1}^{n}(2x - 2\\xi_{i}) + \\lambda x = 0\n$$\n$$\n\\frac{1}{n} \\left( \\sum_{i=1}^{n}x - \\sum_{i=1}^{n}\\xi_{i} \\right) + \\lambda x = 0\n$$\n$$\n\\frac{1}{n} (nx - n\\bar{\\xi}) + \\lambda x = 0\n$$\n$$\nx - \\bar{\\xi} + \\lambda x = 0\n$$\n$$\n(1+\\lambda)x = \\bar{\\xi}\n$$\n解出 $x$，我们得到优化器：\n$$\nx_{n}^{\\lambda} = \\frac{\\bar{\\xi}}{1+\\lambda}\n$$\n\n### 第 2 部分：代入估计量的偏差和方差\n\n首先，我们确定真实目标函数 $F(x)$ 和真实最优值 $v^{\\star}$。\n$$\nF(x) = \\mathbb{E}[f(x,\\xi)] = \\mathbb{E}\\left[\\frac{1}{2}(x - \\xi)^{2}\\right] = \\frac{1}{2}\\mathbb{E}[x^2 - 2x\\xi + \\xi^2]\n$$\n利用期望的线性性质，\n$$\nF(x) = \\frac{1}{2}(x^2 - 2x\\mathbb{E}[\\xi] + \\mathbb{E}[\\xi^2])\n$$\n我们知道 $\\mathbb{E}[\\xi] = \\mu$ 且 $\\mathrm{Var}(\\xi) = \\mathbb{E}[\\xi^2] - (\\mathbb{E}[\\xi])^2 = \\sigma^2$，所以 $\\mathbb{E}[\\xi^2] = \\sigma^2 + \\mu^2$。将这些代入 $F(x)$：\n$$\nF(x) = \\frac{1}{2}(x^2 - 2x\\mu + \\sigma^2 + \\mu^2) = \\frac{1}{2}((x-\\mu)^2 + \\sigma^2)\n$$\n真实最优值 $v^{\\star}$ 是 $F(x)$ 的最小值。这在 $x^{\\star} = \\mu$ 时取得，所以：\n$$\nv^{\\star} = F(\\mu) = \\frac{1}{2}((\\mu-\\mu)^2 + \\sigma^2) = \\frac{\\sigma^2}{2}\n$$\n代入估计量是 $\\tilde{v}_{n}^{\\lambda} = F(x_{n}^{\\lambda})$。\n$$\n\\tilde{v}_{n}^{\\lambda} = \\frac{1}{2}\\left(\\left(x_{n}^{\\lambda} - \\mu\\right)^2 + \\sigma^2\\right) = \\frac{1}{2}\\left(\\left(\\frac{\\bar{\\xi}}{1+\\lambda} - \\mu\\right)^2\\right) + \\frac{\\sigma^2}{2}\n$$\n偏差是 $\\mathbb{E}[\\tilde{v}_{n}^{\\lambda}] - v^{\\star}$。\n$$\n\\mathbb{E}[\\tilde{v}_{n}^{\\lambda}] - v^{\\star} = \\mathbb{E}\\left[\\frac{1}{2}\\left(\\frac{\\bar{\\xi}}{1+\\lambda} - \\mu\\right)^2\\right] + \\frac{\\sigma^2}{2} - \\frac{\\sigma^2}{2} = \\frac{1}{2}\\mathbb{E}\\left[\\left(\\frac{\\bar{\\xi}}{1+\\lambda} - \\mu\\right)^2\\right]\n$$\n令 $Y = \\frac{\\bar{\\xi}}{1+\\lambda} - \\mu$。偏差是 $\\frac{1}{2}\\mathbb{E}[Y^2]$。我们使用性质 $\\mathbb{E}[Y^2] = \\mathrm{Var}(Y) + (\\mathbb{E}[Y])^2$。\n样本均值 $\\bar{\\xi}$ 的均值为 $\\mathbb{E}[\\bar{\\xi}] = \\mu$，方差为 $\\mathrm{Var}(\\bar{\\xi}) = \\frac{\\sigma^2}{n}$。\n$Y$ 的均值为：\n$$\n\\mathbb{E}[Y] = \\mathbb{E}\\left[\\frac{\\bar{\\xi}}{1+\\lambda} - \\mu\\right] = \\frac{\\mathbb{E}[\\bar{\\xi}]}{1+\\lambda} - \\mu = \\frac{\\mu}{1+\\lambda} - \\mu = -\\frac{\\lambda\\mu}{1+\\lambda}\n$$\n$Y$ 的方差为：\n$$\n\\mathrm{Var}(Y) = \\mathrm{Var}\\left(\\frac{\\bar{\\xi}}{1+\\lambda} - \\mu\\right) = \\frac{1}{(1+\\lambda)^2}\\mathrm{Var}(\\bar{\\xi}) = \\frac{\\sigma^2}{n(1+\\lambda)^2}\n$$\n因此，$\\tilde{v}_{n}^{\\lambda}$ 的偏差是：\n$$\n\\text{Bias}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{2}\\left(\\frac{\\sigma^2}{n(1+\\lambda)^2} + \\left(-\\frac{\\lambda\\mu}{1+\\lambda}\\right)^2\\right) = \\frac{1}{2(1+\\lambda)^2}\\left(\\frac{\\sigma^2}{n} + \\lambda^2\\mu^2\\right)\n$$\n接下来，我们计算方差 $\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda})$。\n$$\n\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda}) = \\mathrm{Var}\\left(\\frac{1}{2}Y^2 + \\frac{\\sigma^2}{2}\\right) = \\frac{1}{4}\\mathrm{Var}(Y^2)\n$$\n由于 $\\bar{\\xi} \\sim N(\\mu, \\sigma^2/n)$，变量 $Y = \\frac{\\bar{\\xi}}{1+\\lambda} - \\mu$ 也服从正态分布。根据上面计算的均值和方差，$Y \\sim N(-\\frac{\\lambda\\mu}{1+\\lambda}, \\frac{\\sigma^2}{n(1+\\lambda)^2})$。\n令 $Y = a + bZ$ 其中 $Z \\sim N(0,1)$，$a = \\mathbb{E}[Y] = -\\frac{\\lambda\\mu}{1+\\lambda}$，以及 $b^2 = \\mathrm{Var}(Y) = \\frac{\\sigma^2}{n(1+\\lambda)^2}$。\n我们需要 $\\mathrm{Var}(Y^2) = \\mathrm{Var}((a+bZ)^2)$。使用标准正态随机变量的矩（$\\mathbb{E}[Z]=0, \\mathbb{E}[Z^2]=1, \\mathbb{E}[Z^3]=0, \\mathbb{E}[Z^4]=3$）：\n$$\n\\mathbb{E}[Y^2] = a^2+b^2\\mathbb{E}[Z^2] = a^2+b^2\n$$\n$$\n\\mathbb{E}[Y^4] = \\mathbb{E}[(a+bZ)^4] = \\mathbb{E}[a^4 + 4a^3bZ + 6a^2b^2Z^2 + 4ab^3Z^3 + b^4Z^4] = a^4 + 6a^2b^2 + 3b^4\n$$\n$$\n\\mathrm{Var}(Y^2) = \\mathbb{E}[Y^4] - (\\mathbb{E}[Y^2])^2 = (a^4 + 6a^2b^2 + 3b^4) - (a^2+b^2)^2 = 4a^2b^2 + 2b^4\n$$\n所以，$\\tilde{v}_{n}^{\\lambda}$ 的方差是：\n$$\n\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{4}(4a^2b^2 + 2b^4) = a^2b^2 + \\frac{1}{2}b^4\n$$\n代入 $a^2$ 和 $b^2$ 的表达式：\n$$\n\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda}) = \\frac{\\lambda^2\\mu^2}{(1+\\lambda)^2} \\frac{\\sigma^2}{n(1+\\lambda)^2} + \\frac{1}{2}\\left(\\frac{\\sigma^2}{n(1+\\lambda)^2}\\right)^2 = \\frac{\\lambda^2\\mu^2\\sigma^2}{n(1+\\lambda)^4} + \\frac{\\sigma^4}{2n^2(1+\\lambda)^4}\n$$\n$$\n\\mathrm{Var}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{(1+\\lambda)^4}\\left(\\frac{\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{\\sigma^4}{2n^2}\\right)\n$$\n\n### 第 3 部分：渐近最优正则化参数\n\n均方误差是 $\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\left(\\text{Bias}(\\tilde{v}_{n}^{\\lambda})\\right)^2 + \\mathrm{Var}(\\tilde{v}_{n}^{\\lambda})$。\n$$\n\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\left(\\frac{1}{2(1+\\lambda)^2}\\left(\\frac{\\sigma^2}{n} + \\lambda^2\\mu^2\\right)\\right)^2 + \\frac{1}{(1+\\lambda)^4}\\left(\\frac{\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{\\sigma^4}{2n^2}\\right)\n$$\n展开偏差的平方项：\n$$\n(\\text{Bias})^2 = \\frac{1}{4(1+\\lambda)^4}\\left(\\frac{\\sigma^4}{n^2} + \\frac{2\\lambda^2\\mu^2\\sigma^2}{n} + \\lambda^4\\mu^4\\right)\n$$\n加上方差：\n$$\n\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{4(1+\\lambda)^4}\\left(\\frac{\\sigma^4}{n^2} + \\frac{2\\lambda^2\\mu^2\\sigma^2}{n} + \\lambda^4\\mu^4\\right) + \\frac{1}{(1+\\lambda)^4}\\left(\\frac{\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{\\sigma^4}{2n^2}\\right)\n$$\n在共同分母下合并项：\n$$\n\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{(1+\\lambda)^4} \\left[ \\frac{\\sigma^4}{4n^2} + \\frac{2\\lambda^2\\mu^2\\sigma^2}{4n} + \\frac{\\lambda^4\\mu^4}{4} + \\frac{4\\lambda^2\\mu^2\\sigma^2}{4n} + \\frac{2\\sigma^4}{4n^2} \\right]\n$$\n$$\n\\mathrm{MSE}(\\tilde{v}_{n}^{\\lambda}) = \\frac{1}{4(1+\\lambda)^4} \\left[ \\lambda^4\\mu^4 + \\frac{6\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{3\\sigma^4}{n^2} \\right]\n$$\n为了找到最小化此 MSE 的最优 $\\lambda$，我们对 $\\lambda$ 求导并令结果为零。\n设 $f(\\lambda) = (1+\\lambda)^{-4}$ 和 $g(\\lambda) = \\lambda^4\\mu^4 + \\frac{6\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{3\\sigma^4}{n^2}$。\n$\\mathrm{MSE} = \\frac{1}{4}f(\\lambda)g(\\lambda)$ 的导数是 $\\frac{1}{4}(f'g + fg')=0$。\n$ f'(\\lambda) = -4(1+\\lambda)^{-5} $，$ g'(\\lambda) = 4\\lambda^3\\mu^4 + \\frac{12\\lambda\\mu^2\\sigma^2}{n} $。\n将导数设为零得到 $-4(1+\\lambda)^{-5}g(\\lambda) + (1+\\lambda)^{-4}g'(\\lambda) = 0$。\n乘以 $(1+\\lambda)^5$：\n$$\n-4g(\\lambda) + (1+\\lambda)g'(\\lambda) = 0\n$$\n$$\n-4\\left(\\lambda^4\\mu^4 + \\frac{6\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{3\\sigma^4}{n^2}\\right) + (1+\\lambda)\\left(4\\lambda^3\\mu^4 + \\frac{12\\lambda\\mu^2\\sigma^2}{n}\\right) = 0\n$$\n展开并按 $\\lambda$ 的幂次收集项：\n$$\n(-4\\lambda^4\\mu^4 - \\frac{24\\lambda^2\\mu^2\\sigma^2}{n} - \\frac{12\\sigma^4}{n^2}) + (4\\lambda^3\\mu^4 + \\frac{12\\lambda\\mu^2\\sigma^2}{n} + 4\\lambda^4\\mu^4 + \\frac{12\\lambda^2\\mu^2\\sigma^2}{n}) = 0\n$$\n$$\n4\\lambda^3\\mu^4 - \\frac{12\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{12\\lambda\\mu^2\\sigma^2}{n} - \\frac{12\\sigma^4}{n^2} = 0\n$$\n$$\n\\lambda^3\\mu^4 - \\frac{3\\lambda^2\\mu^2\\sigma^2}{n} + \\frac{3\\lambda\\mu^2\\sigma^2}{n} - \\frac{3\\sigma^4}{n^2} = 0\n$$\n对于大的 $n$，我们预期 $\\lambda$ 会很小。我们进行渐近分析，假设 $\\lambda$ 以 $c/n$ 的形式缩放，其中 $c$ 为某个常数。令 $\\lambda = c/n$。\n$$\n\\frac{c^3\\mu^4}{n^3} - \\frac{3(c^2/n^2)\\mu^2\\sigma^2}{n} + \\frac{3(c/n)\\mu^2\\sigma^2}{n} - \\frac{3\\sigma^4}{n^2} = 0\n$$\n$$\n\\frac{c^3\\mu^4}{n^3} - \\frac{3c^2\\mu^2\\sigma^2}{n^3} + \\frac{3c\\mu^2\\sigma^2}{n^2} - \\frac{3\\sigma^4}{n^2} = 0\n$$\n为了找到前导阶行为，我们乘以 $n^2$：\n$$\n\\frac{c^3\\mu^4}{n} - \\frac{3c^2\\mu^2\\sigma^2}{n} + 3c\\mu^2\\sigma^2 - 3\\sigma^4 = 0\n$$\n当 $n \\to \\infty$ 时取极限，含有 $1/n$ 的项消失，剩下主导平衡方程：\n$$\n3c\\mu^2\\sigma^2 - 3\\sigma^4 = 0\n$$\n由于 $\\mu \\neq 0$ 且 $\\sigma^2$ 是方差（假定为正），我们可以解出 $c$：\n$$\nc = \\frac{3\\sigma^4}{3\\mu^2\\sigma^2} = \\frac{\\sigma^2}{\\mu^2}\n$$\n因此，渐近最优正则化参数为 $\\lambda = c/n$。\n$$\n\\lambda = \\frac{\\sigma^2}{n\\mu^2}\n$$", "answer": "$$\\boxed{\\frac{\\sigma^2}{n\\mu^2}}$$", "id": "3174756"}]}