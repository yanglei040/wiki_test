{"hands_on_practices": [{"introduction": "要想真正掌握 Kelley 切平面法，没有比亲手迭代计算更好的方法了。本练习 [@problem_id:3141056] 将指导您在一个凸的分段线性函数上，完整地体验该算法的核心步骤。通过计算次梯度、构建切平面并求解由此产生的线性规划主问题，您将对如何通过迭代优化多面体模型以逼近最优解建立起具体而深刻的理解。", "problem": "考虑在盒子区域 $X=\\{x\\in\\mathbb{R}^{2}:\\|x\\|_{\\infty}\\le 2\\}$ 上的凸最小化问题，其目标函数 $f:\\mathbb{R}^{2}\\to\\mathbb{R}$ 定义为 $f(x)=\\max\\{x_{1}+x_{2},\\,2x_{1}-x_{2},\\,1-x_{1}\\}$，其中 $\\|x\\|_{\\infty}=\\max\\{|x_{1}|,|x_{2}|\\}$。仿射函数的逐点最大值是凸函数，对于一个凸函数 $f$，在点 $y$ 处的任何次梯度 $g\\in\\partial f(y)$ 都遵循次梯度不等式 $f(x)\\ge f(y)+g^{\\top}(x-y)$（对所有 $x$ 成立）。Kelley 切平面法使用此不等式构造线性下估计量，并在 $f$ 的上境图上求解一系列线性规划 (LP) 主问题。\n\n从 $y^{0}=(0,0)$ 开始使用 Kelley 切平面法。在每次迭代 $k$ 中，查询 $y^{k}$ 处的预言机，它会返回 $f$ 在 $y^{k}$ 处的一个次梯度，该次梯度来自于在 $y^{k}$ 处最大值中活跃的一个仿射函数。在变量 $(x,t)$ 中形成 Kelley 切平面 $t\\ge f(y^{k})+g^{k\\top}(x-y^{k})$，并定义主 LP，该 LP 在所有已收集的切平面和 $x\\in X$ 的约束下最小化 $t$。令 $y^{k+1}$ 为主 LP 最优解的 $x$ 分量。如果存在多个最优解，选择具有最小欧几里得范数 $\\|x\\|_{2}$ 的解作为 $y^{k+1}$。\n\n任务：\n- 显式计算在 $y^{0}$、$y^{1}$ 和 $y^{2}$ 处生成的前三个 Kelley 切平面。\n- 写出相应的三个 LP 主问题。\n- 求解每个主问题以获得 $y^{1}$、$y^{2}$、$y^{3}$ 及其最优目标值 $t^{1}$、$t^{2}$、$t^{3}$。\n- 作为你的最终答案，提供 $t^{3}$ 的精确值。\n\n无需四舍五入；将你的最终答案表示为一个精确数。", "solution": "该问题要求将 Kelley 切割平面法应用于一个凸最小化问题。我们的任务是从一个给定的初始点开始，执行算法的三次迭代，并确定第三个主问题的最优目标值。\n\n问题是在可行集 $X = \\{x \\in \\mathbb{R}^2 : \\|x\\|_\\infty \\le 2\\}$ 上最小化 $f(x) = \\max\\{x_1+x_2, 2x_1-x_2, 1-x_1\\}$。集合 $X$ 可以显式地写为 $X = \\{(x_1, x_2) \\in \\mathbb{R}^2 : -2 \\le x_1 \\le 2, -2 \\le x_2 \\le 2\\}$。\n\nKelley 切割平面法生成一个点序列 $\\{y^k\\}$ 和一个最优值的下界序列 $\\{t^k\\}$。在每次迭代 $k$ 中，我们求解一个线性规划 (LP) 主问题来找到下一个迭代点 $y^{k+1}$ 和更新后的下界 $t^{k+1}$。主问题在被称为“切割”的一组线性不等式约束下最小化变量 $t$，这些切割由次梯度不等式导出。\n\n第 $k$ 个切割由 $t \\ge f(y^k) + g^{k\\top}(x-y^k)$ 给出，其中 $g^k$ 是 $f$ 在 $y^k$ 处的次梯度。对于一个定义为几个可微函数最大值的函数，某一点的次梯度可以取在该点处任何一个活跃（即达到最大值）的函数的梯度。\n\n令这三个仿射函数为 $f_1(x) = x_1+x_2$，$f_2(x) = 2x_1-x_2$ 和 $f_3(x) = 1-x_1$。它们的梯度分别是 $g_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$，$g_2 = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$ 和 $g_3 = \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix}$。\n\n**迭代 0 ($k=0$)**\n\n我们从初始点 $y^0 = (0,0)$ 开始。\n\n1.  **预言机查询**：我们首先在 $y^0$ 处计算目标函数的值：\n    $$f(y^0) = f(0,0) = \\max\\{0+0, 2(0)-0, 1-0\\} = \\max\\{0, 0, 1\\} = 1$$\n    活跃函数是 $f_3(x) = 1-x_1$。我们选择相应的梯度作为次梯度：\n    $$g^0 = g_3 = \\begin{pmatrix} -1 \\\\ 0 \\end{pmatrix}$$\n\n2.  **第一个 Kelley 切平面**：第一个切平面（切割 1）是使用次梯度不等式构造的：\n    $$t \\ge f(y^0) + g^{0\\top}(x-y^0)$$\n    $$t \\ge 1 + \\begin{pmatrix} -1  0 \\end{pmatrix} \\begin{pmatrix} x_1 - 0 \\\\ x_2 - 0 \\end{pmatrix}$$\n    $$t \\ge 1 - x_1$$\n\n3.  **第一个主问题 (LP1)**：我们在第一个切平面和约束 $x \\in X$ 的条件下最小化 $t$：\n    $$\n    \\begin{aligned}\n    (LP1) \\quad \\min_{x, t} \\quad  t \\\\\n    \\text{s.t.} \\quad  t \\ge 1 - x_1 \\\\\n     -2 \\le x_1 \\le 2 \\\\\n     -2 \\le x_2 \\le 2\n    \\end{aligned}\n    $$\n\n4.  **LP1 的解**：为了最小化 $t$，我们必须最小化不等式的右侧 $1-x_1$。这可以通过在可行集 $X$ 上最大化 $x_1$ 来实现。最大值为 $x_1=2$。\n    因此，$t$ 的最优值是 $t^1 = 1 - 2 = -1$。\n    $x$ 的最优解集合是 $\\{(x_1, x_2) : x_1=2, -2 \\le x_2 \\le 2\\}$。\n    根据决胜规则，我们必须选择欧几里得范数 $\\|x\\|_2 = \\sqrt{x_1^2 + x_2^2}$ 最小的解。对于 $x_1=2$，这需要最小化 $\\sqrt{2^2 + x_2^2}$，这在 $x_2=0$ 时发生。\n    因此，下一个迭代点是 $y^1 = (2,0)$，主问题的目标值为 $t^1=-1$。\n\n**迭代 1 ($k=1$)**\n\n我们用点 $y^1 = (2,0)$ 继续。\n\n1.  **预言机查询**：我们在 $y^1$ 处计算 $f$ 的值：\n    $$f(y^1) = f(2,0) = \\max\\{2+0, 2(2)-0, 1-2\\} = \\max\\{2, 4, -1\\} = 4$$\n    活跃函数是 $f_2(x) = 2x_1-x_2$。次梯度为：\n    $$g^1 = g_2 = \\begin{pmatrix} 2 \\\\ -1 \\end{pmatrix}$$\n\n2.  **第二个 Kelley 切平面**：第二个切平面（切割 2）是：\n    $$t \\ge f(y^1) + g^{1\\top}(x-y^1)$$\n    $$t \\ge 4 + \\begin{pmatrix} 2  -1 \\end{pmatrix} \\begin{pmatrix} x_1 - 2 \\\\ x_2 - 0 \\end{pmatrix}$$\n    $$t \\ge 4 + 2(x_1-2) - x_2 = 4 + 2x_1 - 4 - x_2$$\n    $$t \\ge 2x_1 - x_2$$\n\n3.  **第二个主问题 (LP2)**：我们将新的切平面加入主问题：\n    $$\n    \\begin{aligned}\n    (LP2) \\quad \\min_{x, t} \\quad  t \\\\\n    \\text{s.t.} \\quad  t \\ge 1 - x_1 \\quad (\\text{切割 1}) \\\\\n     t \\ge 2x_1 - x_2 \\quad (\\text{切割 2}) \\\\\n     -2 \\le x_1 \\le 2, \\quad -2 \\le x_2 \\le 2\n    \\end{aligned}\n    $$\n\n4.  **LP2 的解**：这等价于寻找 $\\min_{x \\in X} \\max\\{1-x_1, 2x_1-x_2\\}$。这个逐点最大值函数的最小值将出现在定义域 $X$ 的一个顶点上，或者出现在 $1-x_1=2x_1-x_2$ 的点上。\n    - 检查 $X = [-2,2]^2$ 的顶点：\n      - $x=(2,2): \\max\\{1-2, 4-2\\} = \\max\\{-1, 2\\}=2$。\n      - $x=(2,-2): \\max\\{1-2, 4-(-2)\\} = \\max\\{-1, 6\\}=6$。\n      - $x=(-2,2): \\max\\{1-(-2), -4-2\\} = \\max\\{3, -6\\}=3$。\n      - $x=(-2,-2): \\max\\{1-(-2), -4-(-2)\\} = \\max\\{3, -2\\}=3$。\n    - 检查 $1-x_1=2x_1-x_2$ 的点，这可以简化为 $x_2=3x_1-1$。在这条线上，最大值函数的值为 $1-x_1$。我们需要找到位于 $X$ 内的点 $(x_1, 3x_1-1)$ 中 $1-x_1$ 的最小值。这意味着要最大化 $x_1$。\n      $x_2 = 3x_1-1$ 在 $X$ 内的线段受其与盒子边界交点的限制。\n      - 在 $x_2=2$ 处: $2 = 3x_1-1 \\implies 3x_1=3 \\implies x_1=1$。点是 $(1,2)$。\n      - 在 $x_2=-2$ 处: $-2 = 3x_1-1 \\implies 3x_1=-1 \\implies x_1=-1/3$。点是 $(-1/3, -2)$。\n      该线段上最大的 $x_1$ 是 $x_1=1$。在点 $(1,2)$，目标值为 $1-1=0$。\n    比较所有候选值 $\\{2,6,3,0,1-(-1/3)=4/3\\}$，最小值为 $0$。\n    这个最小值出现在唯一的点 $(1,2)$。\n    因此，解是 $y^2 = (1,2)$ 且 $t^2=0$。\n\n**迭代 2 ($k=2$)**\n\n我们现在使用点 $y^2 = (1,2)$。\n\n1.  **预言机查询**：在 $y^2$ 处计算 $f$ 的值：\n    $$f(y^2) = f(1,2) = \\max\\{1+2, 2(1)-2, 1-1\\} = \\max\\{3, 0, 0\\} = 3$$\n    活跃函数是 $f_1(x) = x_1+x_2$。次梯度为：\n    $$g^2 = g_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n\n2.  **第三个 Kelley 切平面**：第三个切平面（切割 3）是：\n    $$t \\ge f(y^2) + g^{2\\top}(x-y^2)$$\n    $$t \\ge 3 + \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} x_1 - 1 \\\\ x_2 - 2 \\end{pmatrix}$$\n    $$t \\ge 3 + (x_1-1) + (x_2-2) = 3 + x_1 - 1 + x_2 - 2$$\n    $$t \\ge x_1 + x_2$$\n\n3.  **第三个主问题 (LP3)**：添加新的切平面形成 LP3：\n    $$\n    \\begin{aligned}\n    (LP3) \\quad \\min_{x, t} \\quad  t \\\\\n    \\text{s.t.} \\quad  t \\ge 1 - x_1 \\quad (\\text{切割 1}) \\\\\n     t \\ge 2x_1 - x_2 \\quad (\\text{切割 2}) \\\\\n     t \\ge x_1 + x_2 \\quad (\\text{切割 3}) \\\\\n     -2 \\le x_1 \\le 2, \\quad -2 \\le x_2 \\le 2\n    \\end{aligned}\n    $$\n\n4.  **LP3 的解**：这等价于寻找 $t^3 = \\min_{x \\in X} \\max\\{1 - x_1, 2x_1 - x_2, x_1 + x_2\\}$。\n    函数 $h(x) = \\max\\{1 - x_1, 2x_1 - x_2, x_1 + x_2\\}$ 是凸函数。它在 $\\mathbb{R}^2$ 上的无约束最小值出现在次微分包含零向量的点。这样的一个候选点是三个仿射函数都相等的地方：\n    $$1 - x_1 = 2x_1 - x_2 = x_1 + x_2$$\n    由 $2x_1 - x_2 = x_1 + x_2$，我们得到 $x_1 = 2x_2$。\n    将此代入 $1 - x_1 = x_1 + x_2$：\n    $$1 - 2x_2 = 2x_2 + x_2$$\n    $$1 = 5x_2 \\implies x_2 = \\frac{1}{5}$$\n    则 $x_1 = 2x_2 = 2(\\frac{1}{5}) = \\frac{2}{5}$。\n    让我们用第三个等式 $1 - x_1 = 2x_1 - x_2$ 来检验：\n    $1 - \\frac{2}{5} = \\frac{3}{5}$ 并且 $2(\\frac{2}{5}) - \\frac{1}{5} = \\frac{4}{5} - \\frac{1}{5} = \\frac{3}{5}$。等式成立。\n    三个函数相等的点是 $x^* = (\\frac{2}{5}, \\frac{1}{5})$。\n    我们检查这个点是否在可行集 $X$ 中：\n    $|x_1^*| = \\frac{2}{5} \\le 2$ 且 $|x_2^*| = \\frac{1}{5} \\le 2$。该点在 $X$ 内部。\n    由于凸函数 $h(x)$ 的无约束最小化点位于可行集 $X$ 内，它也是约束问题的最小化点。\n    x 变量的最优解是 $y^3 = (\\frac{2}{5}, \\frac{1}{5})$。\n    $t$ 的最优值是这些函数在该点的值：\n    $$t^3 = 1 - x_1 = 1 - \\frac{2}{5} = \\frac{3}{5}$$\n    第三个主问题的最优值是 $t^3 = \\frac{3}{5}$。\n\n结果摘要：\n- 切割 1: $t \\ge 1-x_1$。LP1 的解: $(y^1, t^1) = ((2,0), -1)$。\n- 切割 2: $t \\ge 2x_1-x_2$。LP2 的解: $(y^2, t^2) = ((1,2), 0)$。\n- 切割 3: $t \\ge x_1+x_2$。LP3 的解: $(y^3, t^3) = ((\\frac{2}{5}, \\frac{1}{5}), \\frac{3}{5})$。\n问题要求 $t^3$ 的精确值。", "answer": "$$\\boxed{\\frac{3}{5}}$$", "id": "3141056"}, {"introduction": "Kelley 切平面法在理论上虽然优雅，但其实际性能在很大程度上取决于待优化函数“上镜图”($\\text{epigraph}$)的几何形状。本练习 [@problem_id:3141057] 将通过一个光滑的非线性目标函数来探讨这一方面。您不仅将运用次梯度的链式法则来推导一个有效的切平面，还将分析为何用平面来逼近弯曲的上镜图会导致收敛缓慢，这是理解该方法局限性的一个关键视角。", "problem": "考虑凸函数 $f(x) = \\|A x - b\\|_{2}$，其中 $A \\in \\mathbb{R}^{2 \\times 2}$，$b \\in \\mathbb{R}^{2}$，$x \\in \\mathbb{R}^{2}$。$f$ 的上境图是集合 $\\{(x,t) \\in \\mathbb{R}^{2} \\times \\mathbb{R} \\mid t \\ge f(x)\\}$。Kelley 切平面法构建线性下估计量（切平面），这些切平面在先前的迭代点处支撑 $f$ 的上境图。在点 $x_{k}$ 处的一个有效切平面是根据 $f$ 在 $x_{k}$ 处的次梯度构建的，并且必须是上境图在点 $(x_{k}, f(x_{k}))$ 处的支撑超平面。设\n$$\nA = \\begin{bmatrix} 2  -1 \\\\ 0  1 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}, \\quad x_{k} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}.\n$$\n假设残差 $r_{k} = A x_{k} - b$ 非零，并且给定向量 $s_{k} = A^{\\top}(A x_{k} - b)$。选择给出了函数 $f(x) = \\|A x - b\\|_{2}$ 在 $x_{k}$ 处的有效 Kelley 切平面，并正确解释了为什么当 $f$ 的上境图是平滑弯曲时，仅使用线性切平面可能会很慢的选项。\n\nA. $t \\ge \\sqrt{5} + \\dfrac{-4 x_{1} + x_{2} - 1}{\\sqrt{5}}$。线性切平面在平滑弯曲的上境图上可能收敛缓慢，因为它们只捕捉一阶（切线）信息；一个分段线性下估计量需要许多切平面才能很好地逼近曲率，导致每次迭代的改进很小。\n\nB. $t \\ge \\sqrt{5} + \\left(-4 x_{1} + x_{2} - 1\\right)$。线性切平面在平滑的上境图上收敛很快，因为高曲率保证了每增加一个平面都能迈出大步。\n\nC. $t \\ge -\\dfrac{4}{\\sqrt{5}} x_{1} + \\dfrac{1}{\\sqrt{5}} x_{2}$。线性切平面在这里收敛缓慢，因为 $\\|A x - b\\|_{2}$ 不是凸函数，所以平面无法支撑上境图。\n\nD. $t \\ge \\sqrt{5} - \\dfrac{-4 x_{1} + x_{2} - 1}{\\sqrt{5}}$。线性切平面收敛缓慢，因为范数处处不可微，妨碍了有效的切线逼近。", "solution": "该问题要求推导给定凸函数和点的一个有效 Kelley 切平面，并评估该方法的性能特点。\n\n首先，我们为 Kelley 切平面建立理论基础。对于一个凸函数 $f(x)$，其上境图是 $\\mathbb{R}^{n} \\times \\mathbb{R}$ 中满足 $t \\ge f(x)$ 的点 $(x, t)$ 的集合。在迭代点 $x_k$ 处的 Kelley 切平面是一个线性不等式，它定义了上境图在点 $(x_k, f(x_k))$ 处的支撑超平面。这由函数的一阶近似给出：\n$$\nt \\ge f(x_k) + g_k^\\top (x - x_k)\n$$\n其中 $g_k$ 是 $f$ 在 $x_k$ 处的任意次梯度，即 $g_k \\in \\partial f(x_k)$。\n\n问题给出了函数 $f(x) = \\|A x - b\\|_{2}$ 和具体值：\n$$\nA = \\begin{bmatrix} 2  -1 \\\\ 0  1 \\end{bmatrix}, \\quad b = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}, \\quad x_{k} = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}.\n$$\n我们来计算 Kelley 切平面不等式所需的各个部分。\n\n1.  **计算 $f(x_k)$：**\n    在 $x_k$ 处的残差是 $r_k = A x_k - b$。\n    $$\n    A x_k = \\begin{bmatrix} 2  -1 \\\\ 0  1 \\end{bmatrix} \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} = \\begin{bmatrix} (2)(0) + (-1)(1) \\\\ (0)(0) + (1)(1) \\end{bmatrix} = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix}.\n    $$\n    $$\n    r_k = A x_k - b = \\begin{bmatrix} -1 \\\\ 1 \\end{bmatrix} - \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} -2 \\\\ -1 \\end{bmatrix}.\n    $$\n    题目陈述假设这个残差是非零的，事实也确实如此。现在我们可以计算函数值：\n    $$\n    f(x_k) = \\|A x_k - b\\|_{2} = \\left\\| \\begin{bmatrix} -2 \\\\ -1 \\end{bmatrix} \\right\\|_{2} = \\sqrt{(-2)^2 + (-1)^2} = \\sqrt{4 + 1} = \\sqrt{5}.\n    $$\n\n2.  **计算次梯度 $g_k \\in \\partial f(x_k)$：**\n    函数 $f(x) = \\|A x - b\\|_{2}$ 是欧几里得范数函数 $g(z) = \\|z\\|_2$ 和仿射函数 $h(x) = Ax-b$ 的复合。次微分的链式法则表明 $\\partial f(x) = A^\\top \\partial g(h(x))$。\n    欧几里得范数 $\\|z\\|_2$ 的次微分在 $z \\neq 0$ 时为 $\\{\\frac{z}{\\|z\\|_2}\\}$，在 $z = 0$ 时为闭单位球 $\\{u \\mid \\|u\\|_2 \\le 1\\}$。\n    由于 $A x_k - b = \\begin{bmatrix} -2 \\\\ -1 \\end{bmatrix} \\neq 0$，函数 $f$ 在 $x_k$ 处是可微的。次微分 $\\partial f(x_k)$ 只包含一个元素，即梯度 $\\nabla f(x_k)$。\n    $$\n    g_k = \\nabla f(x_k) = A^\\top \\frac{A x_k - b}{\\|A x_k - b\\|_{2}}.\n    $$\n    我们有 $A x_k - b = \\begin{bmatrix} -2 \\\\ -1 \\end{bmatrix}$ 和 $\\|A x_k - b\\|_{2} = \\sqrt{5}$。$A$ 的转置是：\n    $$\n    A^\\top = \\begin{bmatrix} 2  0 \\\\ -1  1 \\end{bmatrix}.\n    $$\n    所以，次梯度是：\n    $$\n    g_k = \\begin{bmatrix} 2  0 \\\\ -1  1 \\end{bmatrix} \\frac{1}{\\sqrt{5}} \\begin{bmatrix} -2 \\\\ -1 \\end{bmatrix} = \\frac{1}{\\sqrt{5}} \\begin{bmatrix} (2)(-2) + (0)(-1) \\\\ (-1)(-2) + (1)(-1) \\end{bmatrix} = \\frac{1}{\\sqrt{5}} \\begin{bmatrix} -4 \\\\ 1 \\end{bmatrix}.\n    $$\n    注意，问题给出了向量 $s_k = A^\\top(A x_k - b)$，即 $\\begin{bmatrix} -4 \\\\ 1 \\end{bmatrix}$。因此，次梯度是 $g_k = s_k / f(x_k)$。\n\n3.  **构建 Kelley 切平面不等式：**\n    将计算出的值代入一般形式 $t \\ge f(x_k) + g_k^\\top (x - x_k)$：\n    $$\n    t \\ge \\sqrt{5} + \\left( \\frac{1}{\\sqrt{5}} \\begin{bmatrix} -4 \\\\ 1 \\end{bmatrix} \\right)^\\top \\left( \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix} - \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix} \\right)\n    $$\n    $$\n    t \\ge \\sqrt{5} + \\frac{1}{\\sqrt{5}} \\begin{bmatrix} -4  1 \\end{bmatrix} \\begin{bmatrix} x_1 \\\\ x_2 - 1 \\end{bmatrix}\n    $$\n    $$\n    t \\ge \\sqrt{5} + \\frac{1}{\\sqrt{5}} (-4x_1 + (x_2 - 1))\n    $$\n    $$\n    t \\ge \\sqrt{5} + \\frac{-4x_1 + x_2 - 1}{\\sqrt{5}}\n    $$\n    这就是在 $x_k$ 处的有效 Kelley 切平面。\n\n现在，我们评估每个选项。\n\n**A. $t \\ge \\sqrt{5} + \\dfrac{-4 x_{1} + x_{2} - 1}{\\sqrt{5}}$。线性切平面在平滑弯曲的上境图上可能收敛缓慢，因为它们只捕捉一阶（切线）信息；一个分段线性下估计量需要许多切平面才能很好地逼近曲率，导致每次迭代的改进很小。**\n-   **切平面公式**：该不等式与我们推导的结果完全匹配。\n-   **解释**：这个解释是正确的。Kelley 切割平面法用一个由半空间（即切平面）交集形成的多面体集从下方逼近凸函数的上境图。对于像 $f(x) = \\|Ax-b\\|_2$ 这样具有平滑弯曲上境图的函数，每个线性切平面仅在一个点上与上境图相切。线性下估计量与实际函数之间的差距在远离切点时呈二次方增长。因此，需要许多切平面才能对曲面做出合理准确的逼近，这意味着算法通常步长很小，收敛缓慢。\n-   **结论**：**正确**。\n\n**B. $t \\ge \\sqrt{5} + \\left(-4 x_{1} + x_{2} - 1\\right)$。线性切平面在平滑的上境图上收敛很快，因为高曲率保证了每增加一个平面都能迈出大步。**\n-   **切平面公式**：这是不正确的。包含 $x_1$ 和 $x_2$ 的项应该除以 $\\sqrt{5}$。这个公式错误地使用了 $s_k = A^\\top(A x_k - b)$ 作为次梯度，而不是正确归一化的 $g_k = s_k / f(x_k)$。\n-   **解释**：这个解释是不正确的。高曲率正是导致线性逼近效果差、并使得像 Kelley 法这样的一阶方法收敛缓慢的原因。\n-   **结论**：**不正确**。\n\n**C. $t \\ge -\\dfrac{4}{\\sqrt{5}} x_{1} + \\dfrac{1}{\\sqrt{5}} x_{2}$。线性切平面在这里收敛缓慢，因为 $\\|A x - b\\|_{2}$ 不是凸函数，所以平面无法支撑上境图。**\n-   **切平面公式**：这是不正确的。它缺少了常数项 $f(x_k) - g_k^\\top x_k$。完整的不等式是 $t \\ge f(x_k) + g_k^\\top(x-x_k) = (f(x_k) - g_k^\\top x_k) + g_k^\\top x$。常数项的计算结果为 $\\sqrt{5} - \\frac{1}{\\sqrt{5}}(-4(0) + 1(1)) = \\sqrt{5} - \\frac{1}{\\sqrt{5}} = \\frac{4}{\\sqrt{5}}$。所以完整的不等式应为 $t \\ge \\frac{4}{\\sqrt{5}} + \\frac{-4x_1+x_2}{\\sqrt{5}}$。所提供的公式是不完整的。\n-   **解释**：这个解释是根本错误的。函数 $f(x) = \\|A x - b\\|_{2}$ 是一个著名的凸函数例子。它是一个凸函数（欧几里得范数）与一个仿射函数的复合。Kelley 方法的整个理论基础都建立在函数是凸函数这一前提上，这保证了基于次梯度的切平面是有效的全局下估计量。\n-   **结论**：**不正确**。\n\n**D. $t \\ge \\sqrt{5} - \\dfrac{-4 x_{1} + x_{2} - 1}{\\sqrt{5}}$。线性切平面收敛缓慢，因为范数处处不可微，妨碍了有效的切线逼近。**\n-   **切平面公式**：这是不正确的。$f(x_k)$ 项和次梯度项之间的符号是错误的。支撑超平面不等式是 $t \\ge f(x_k) + g_k^\\top(x-x_k)$，而不是 $t \\ge f(x_k) - g_k^\\top(x-x_k)$。\n-   **解释**：这个解释是不正确的。欧几里得范数 $\\|z\\|_2$ 除了在 $z=0$ 处之外处处可微。关于范数“处处不可微”的说法是错误的。在点 $x_k$ 处，函数是可微的，因为 $A x_k - b \\neq 0$。收敛缓慢是由于对于一个弯曲函数，线性逼近的质量较差，而不是普遍缺乏可微性。\n-   **结论**：**不正确**。\n\n只有选项 A 同时提供了 Kelley 切平面的正确数学公式和对该方法性能的正确概念性解释。", "answer": "$$\\boxed{A}$$", "id": "3141057"}, {"introduction": "Kelley 切平面法与我们熟悉的梯度下降等算法有何不同？本练习 [@problem_id:3141039] 通过在同一个简单问题上分析两种方法单步迭代的差异，提供了一个直接的对比。您将发现一个关键且时常令人意外的行为差异：梯度下降采取局部步长，保证了目标函数的改进，而 Kelley 法则是在整个可行域上最小化一个全局模型，这可能导致真实目标函数值出现大的、非单调的跳跃，从而揭示了局部与全局优化策略之间的权衡。", "problem": "考虑在立方体 $X=[-1,1]^{2}$ 上对欧几里得范数 $f(x)=\\|x\\|_{2}$ 进行凸最小化。在第 $k$ 次迭代时，假设当前点为 $x_{k}=(\\tfrac{1}{2},\\tfrac{1}{2})\\neq 0$。Kelley 切平面法在 $x_{k}$ 处使用一个次梯度构建一个仿射下估计量，并通过该迭代点的单次切割，求解一个在 $X$ 上的主线性规划 (LP) 问题，以获得下一个点 $x_{k+1}$。相比之下，梯度下降法使用步长 $\\alpha$ 且 $0  \\alpha  \\|x_{k}\\|_{2}$，计算 $x^{\\mathrm{GD}}=x_{k}-\\alpha\\nabla f(x_{k})$。仅使用凸函数和次梯度的基本性质，以及欧几里得范数在非零点处梯度的定义，判断在这种情况下以下哪个陈述是正确的。\n\nA. 在 $x_k$ 处进行单次切割，Kelley 主 LP 解 $x_{k+1}$ 求解 $\\min_{y\\in X} g_{k}^{\\top}y$，其中 $g_{k}$ 是 $x_{k}$ 处的次梯度，因此 $x_{k+1}$ 是顶点 $(-1,-1)$。分段线性模型值减小，但 $x_{k+1}$ 处的真实目标值 $\\|x\\|_{2}$ 相对于 $\\|x_{k}\\|_{2}$ 增加。\n\nB. 对于任意步长 $\\alpha$ 且 $0  \\alpha  \\|x_{k}\\|_{2}$，梯度下降更新 $x^{\\mathrm{GD}}=x_{k}-\\alpha\\nabla f(x_{k})$ 将目标值从 $\\|x_{k}\\|_{2}$ 严格减小到 $\\|x_{k}\\|_{2}-\\alpha$，并且点保持在 $X$ 内。\n\nC. 当在立方体上最小化 $f(x)=\\|x\\|_{2}$ 时，Kelley 主 LP 总是返回原点 $x_{k+1}=(0,0)$，因为原点既能最小化真实函数，也能最小化在 $x_{k}$ 处的任何仿射线性化。\n\nD. 对于 $f(x)=\\|x\\|_{2}$，Kelley 主 LP 更新 $x_{k+1}$ 和梯度下降更新 $x^{\\mathrm{GD}}$ 重合，因为两者都使用在 $x_{k}$ 处的次梯度方向。\n\nE. 如果添加了更多的切平面（多个过去的切割），Kelley 主 LP 会立即修正对 $f(x)=\\|x\\|_{2}$ 的下估计，使得 $x_{k+1}$ 不可能位于 $X$ 的一个顶点上。\n\n选择所有正确的选项。", "solution": "该问题要求分析两种不同的优化算法在集合 $X = [-1,1]^2$ 上最小化 $f(x) = \\|x\\|_2$ 的一步，起始点为 $x_k = (\\frac{1}{2}, \\frac{1}{2})$。\n\n**1. 准备工作：目标函数的次梯度**\n目标函数是 $f(x) = \\|x\\|_2 = \\sqrt{x_1^2 + x_2^2}$。\n对于任何 $x \\neq 0$，$f(x)$ 是可微的，其梯度是唯一的次梯度：\n$$ \\nabla f(x) = \\frac{x}{\\|x\\|_2} $$\n当前点是 $x_k = (\\frac{1}{2}, \\frac{1}{2})$。其欧几里得范数是：\n$$ \\|x_k\\|_2 = \\sqrt{(\\tfrac{1}{2})^2 + (\\tfrac{1}{2})^2} = \\sqrt{\\tfrac{1}{4} + \\tfrac{1}{4}} = \\sqrt{\\tfrac{1}{2}} = \\frac{1}{\\sqrt{2}} $$\n在 $x_k$ 处的次梯度 $g_k$ 是：\n$$ g_k = \\nabla f(x_k) = \\frac{x_k}{\\|x_k\\|_2} = \\frac{(\\frac{1}{2}, \\frac{1}{2})}{\\frac{1}{\\sqrt{2}}} = \\left(\\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2}\\right) $$\n\n**2. Kelley 切平面法分析**\nKelley 方法用一个分段线性下模型来近似凸函数 $f(x)$。在 $x_k$ 处进行单次切割，该模型由一个仿射函数组成，即在 $x_k$ 处的一阶泰勒近似（或基于次梯度的支撑线）：\n$$ l(y) = f(x_k) + g_k^\\top(y - x_k) $$\n根据定义，对于所有 $y$ 都有 $l(y) \\le f(y)$。该算法通过在可行集 $X$ 上最小化这个线性近似来找到下一个迭代点 $x_{k+1}$。\n$$ x_{k+1} = \\arg\\min_{y \\in X} l(y) = \\arg\\min_{y \\in X} \\left( f(x_k) + g_k^\\top(y - x_k) \\right) $$\n由于 $f(x_k)$ 和 $g_k^\\top x_k$ 相对于优化变量 $y$ 是常数，这等价于求解以下线性规划 (LP) 问题：\n$$ x_{k+1} = \\arg\\min_{y \\in X} g_k^\\top y $$\n我们必须求解 $\\min_{y \\in [-1,1]^2} g_k^\\top y$，其中 $g_k = (\\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2})$。目标函数是 $\\frac{\\sqrt{2}}{2}y_1 + \\frac{\\sqrt{2}}{2}y_2$。由于 $y_1$ 和 $y_2$ 的系数都是正的，这个线性函数在正方形 $[-1,1]^2$ 上的最小值在 $y_1$ 和 $y_2$ 取其可能的最小负值时达到，即 $y_1 = -1$ 和 $y_2 = -1$。\n因此，下一个迭代点是：\n$$ x_{k+1} = (-1, -1) $$\n\n**3. 梯度下降法分析**\n梯度下降更新由 $x^{\\mathrm{GD}} = x_k - \\alpha \\nabla f(x_k)$ 给出，步长 $\\alpha$ 满足 $0  \\alpha  \\|x_k\\|_2$。\n代入 $x_k$ 和 $\\nabla f(x_k) = g_k$ 的值：\n$$ x^{\\mathrm{GD}} = x_k - \\alpha g_k = x_k - \\alpha \\frac{x_k}{\\|x_k\\|_2} = x_k \\left(1 - \\frac{\\alpha}{\\|x_k\\|_2}\\right) $$\n让我们分析此更新的属性。\n-   **目标值**：新的目标值是：\n    $$ \\|x^{\\mathrm{GD}}\\|_2 = \\left\\| x_k \\left(1 - \\frac{\\alpha}{\\|x_k\\|_2}\\right) \\right\\|_2 = \\left| 1 - \\frac{\\alpha}{\\|x_k\\|_2} \\right| \\|x_k\\|_2 $$\n    条件 $0  \\alpha  \\|x_k\\|_2$ 意味着 $0  \\frac{\\alpha}{\\|x_k\\|_2}  1$，所以 $1 - \\frac{\\alpha}{\\|x_k\\|_2}$ 是正的。因此：\n    $$ \\|x^{\\mathrm{GD}}\\|_2 = \\left(1 - \\frac{\\alpha}{\\|x_k\\|_2}\\right) \\|x_k\\|_2 = \\|x_k\\|_2 - \\alpha $$\n-   **可行性**：我们必须检查 $x^{\\mathrm{GD}}$ 是否保持在 $X = [-1,1]^2$ 内。\n    更新向量是：\n    $$ x^{\\mathrm{GD}} = \\left(\\frac{1}{2}, \\frac{1}{2}\\right) - \\alpha \\left(\\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2}\\right) = \\left(\\frac{1}{2} - \\frac{\\alpha\\sqrt{2}}{2}, \\frac{1}{2} - \\frac{\\alpha\\sqrt{2}}{2}\\right) $$\n    根据条件 $0  \\alpha  \\|x_k\\|_2 = \\frac{1}{\\sqrt{2}}$，我们有 $0  \\alpha\\sqrt{2}  1$。\n    让我们检查 $x^{\\mathrm{GD}}$ 各分量的边界：\n    $$ \\frac{1}{2} - \\frac{1 \\cdot \\sqrt{2}}{2}  x_1^{\\mathrm{GD}}  \\frac{1}{2} - \\frac{0 \\cdot \\sqrt{2}}{2} $$\n    $$ \\frac{1}{2}(1 - \\sqrt{2})  x_1^{\\mathrm{GD}}  \\frac{1}{2} $$\n    上界是 $\\frac{1}{2}$，在 $[-1,1]$ 内。下界是 $\\frac{1}{2}(1-\\sqrt{2}) \\approx \\frac{1}{2}(1 - 1.414) = -0.207$，也在 $[-1,1]$ 内。\n    由于 $x^{\\mathrm{GD}}$ 是 $x_k = (\\frac{1}{2}, \\frac{1}{2})$ 的一个正数缩放，且缩放因子小于1，$x^{\\mathrm{GD}}$ 的两个坐标都将是正的并且小于 $\\frac{1}{2}$。因此，$x^{\\mathrm{GD}}$ 肯定在 $X = [-1,1]^2$ 内。\n\n### 逐项分析\n\n**A. 在 $x_{k}$ 处进行单次切割，Kelley 主 LP 解 $x_{k+1}$ 求解 $\\min_{y\\in X} g_{k}^{\\top}y$，其中 $g_{k}$ 是 $x_{k}$ 处的次梯度，因此 $x_{k+1}$ 是顶点 $(-1,-1)$。分段线性模型值减小，但 $x_{k+1}$ 处的真实目标值 $\\|x\\|_{2}$ 相对于 $\\|x_{k}\\|_{2}$ 增加。**\n-   第一部分，即 LP 求解 $\\min_{y\\in X} g_{k}^{\\top}y$ 且解为 $x_{k+1} = (-1, -1)$，在我们的 Kelley 方法分析中已经验证。这是正确的。\n-   第二部分比较了真实目标值。\n    -   $\\|x_k\\|_2 = \\|(\\frac{1}{2}, \\frac{1}{2})\\|_2 = \\frac{1}{\\sqrt{2}} \\approx 0.707$。\n    -   $\\|x_{k+1}\\|_2 = \\|(-1, -1)\\|_2 = \\sqrt{(-1)^2 + (-1)^2} = \\sqrt{2} \\approx 1.414$。\n    -   确实，$\\|x_{k+1}\\|_2 > \\|x_k\\|_2$。真实目标值增加了。这是切平面法的一个典型行为，它不保证真实目标函数的单调下降。\n-   短语“分段线性模型值减小”意味着线性模型在新点 $x_{k+1}$ 处的值小于其在旧点 $x_k$ 处的值。\n    -   $l(x_k) = f(x_k) = \\frac{1}{\\sqrt{2}}$。\n    -   $l(x_{k+1}) = f(x_k) + g_k^\\top(x_{k+1}-x_k) = \\frac{1}{\\sqrt{2}} + (\\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2})^\\top((-\\frac{3}{2}), (-\\frac{3}{2})) = \\frac{1}{\\sqrt{2}} - \\frac{3\\sqrt{2}}{2} = -\\sqrt{2}$。\n    -   由于 $-\\sqrt{2}  \\frac{1}{\\sqrt{2}}$，模型值减小。这是由算法的设计保证的。\n-   这个陈述的所有部分都是正确的。\n**结论：正确。**\n\n**B. 对于任意步长 $\\alpha$ 且 $0  \\alpha  \\|x_{k}\\|_{2}$，梯度下降更新 $x^{\\mathrm{GD}}=x_{k}-\\alpha\\nabla f(x_{k})$ 将目标值从 $\\|x_{k}\\|_{2}$ 严格减小到 $\\|x_{k}\\|_{2}-\\alpha$，并且点保持在 $X$ 内。**\n-   第一部分，即目标值变为 $\\|x_{k}\\|_{2}-\\alpha$，在我们的梯度下降分析中已经验证。由于 $\\alpha > 0$，这是一个严格的减小。这是正确的。\n-   第二部分，即 $x^{\\mathrm{GD}}$ 保持在 $X = [-1,1]^2$ 内，也得到了验证。新点 $x^{\\mathrm{GD}}$ 位于 $(0,0)$ 和 $x_k = (\\frac{1}{2}, \\frac{1}{2})$ 之间的线段上，所以保证它在 $X$ 内。这是正确的。\n-   这个陈述的所有部分都是正确的。\n**结论：正确。**\n\n**C. 当在立方体上最小化 $f(x)=\\|x\\|_{2}$ 时，Kelley 主 LP 总是返回原点 $x_{k+1}=(0,0)$，因为原点既能最小化真实函数，也能最小化在 $x_{k}$ 处的任何仿射线性化。**\n-   Kelley 主 LP 求解 $\\min_{y \\in X} g_k^\\top y$。在我们的具体案例中，这得到了 $x_{k+1}=(-1,-1)$，而不是 $(0,0)$。所以第一个主张立即被我们的反例所证伪。\n-   推理也是有缺陷的。原点 $(0,0)$ 最小化真实函数 $f(x)=\\|x\\|_2$。然而，它不一定能最小化仿射线性化 $l(y) = f(x_k) + g_k^\\top(y-x_k)$。最小化 $l(y)$ 等价于最小化 $g_k^\\top y$。对于我们的 $g_k = (\\frac{\\sqrt{2}}{2}, \\frac{\\sqrt{2}}{2})$，$y=(0,0)$ 处的值 $g_k^\\top y$ 是 $0$。但对于 $y=(-1,-1) \\in X$，值是 $-\\sqrt{2}$，更小。所以原点并没有最小化线性化函数。\n**结论：不正确。**\n\n**D. 对于 $f(x)=\\|x\\|_{2}$，Kelley 主 LP 更新 $x_{k+1}$ 和梯度下降更新 $x^{\\mathrm{GD}}$ 重合，因为两者都使用在 $x_{k}$ 处的次梯度方向。**\n-   我们的分析表明 $x_{k+1} = (-1, -1)$ 而 $x^{\\mathrm{GD}}$ 是位于 $(0,0)$ 和 $(\\frac{1}{2}, \\frac{1}{2})$ 之间的开线段上的一个点。这些点显然不相同。\n-   推理是有问题的。虽然两种方法都使用次梯度，但它们的使用方式不同。梯度下降是在负梯度方向上迈出局部一步。Kelley 方法是在整个可行集上对一个线性模型进行全局最小化。这些是根本不同的操作。\n**结论：不正确。**\n\n**E. 如果添加了更多的切平面（多个过去的切割），Kelley 主 LP 会立即修正对 $f(x)=\\|x\\|_{2}$ 的下估计，使得 $x_{k+1}$ 不可能位于 $X$ 的一个顶点上。**\n-   让我们考虑找到 $x_{k+1} = (-1, -1)$ 之后的下一次迭代。我们基于 $x_{k+1}$ 添加一个新的切割。新的主问题将是在 $X$ 上最小化 $\\max\\{l_k(x), l_{k+1}(x)\\}$。\n-   为下一个点（比如 $x_{k+2}$）要解决的问题是一个线性规划（尽管如果我们引入上镜图变量 $t$，则是在更高维空间中）。在多面体集上的 LP 解出现在该集的一个顶点上。这个顶点解在 x 空间上的投影可能（也可能不）是原始集 $X$ 的一个顶点。\n-   让我们分析这个具体问题。经过在 $x_k=(\\frac{1}{2}, \\frac{1}{2})$ 和 $x_{k+1}=(-1,-1)$ 的两次切割后，问题是最小化 $t$，约束条件是 $x \\in X$, $t \\ge l_k(x)$, 以及 $t \\ge l_{k+1}(x)$。这等价于 $\\min_{x \\in [-1,1]^2} \\max\\{ \\frac{\\sqrt{2}}{2}(x_1+x_2), \\frac{-1}{\\sqrt{2}}(x_1+x_2) + \\sqrt{2} \\}$.\n-   实际上， $l_k(x) = f(x_k) + g_k^\\top(x-x_k) = \\frac{1}{\\sqrt{2}} + \\frac{1}{\\sqrt{2}}(x_1+x_2 - 1) = \\frac{1}{\\sqrt{2}}(x_1+x_2)$.\n-   $l_{k+1}(x) = f(x_{k+1}) + g_{k+1}^\\top(x-x_{k+1}) = \\sqrt{2} + \\frac{-1}{\\sqrt{2}}(x_1+1+x_2+1) = \\sqrt{2} - \\frac{1}{\\sqrt{2}}(x_1+x_2+2) = -\\frac{1}{\\sqrt{2}}(x_1+x_2)$.\n-   我们要求解 $\\min_{x \\in X} \\max\\{\\frac{1}{\\sqrt{2}}(x_1+x_2), -\\frac{1}{\\sqrt{2}}(x_1+x_2)\\} = \\min_{x \\in X} \\frac{1}{\\sqrt{2}}|x_1+x_2|$。\n-   $[-1,1]^2$ 中 $x_1+x_2$ 的范围是 $[-2,2]$。$|x_1+x_2|$ 的最小值是0，在 $x_1+x_2=0$ 的线段上达到。这个解集包括立方体 $X$ 的顶点 $(1, -1)$ 和 $(-1, 1)$。一个 LP 求解器可能会返回这些顶点之一作为 $x_{k+2}$ 的解。\n-   因此，关于下一个迭代点*不能*位于 X 的一个顶点上的陈述是错误的。\n**结论：不正确。**", "answer": "$$\\boxed{AB}$$", "id": "3141039"}]}