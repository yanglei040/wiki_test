{"hands_on_practices": [{"introduction": "任何局部搜索启发式算法的核心都在于其邻域函数 $N(x)$，它定义了从当前解到候选解的“移动”方式。设计一个好的邻域涉及到在生成邻居的计算成本和这些邻居的质量之间做出关键权衡。本练习 [@problem_id:3136481] 将通过一个课程表安排问题的案例，让你定量地分析这种权衡，并揭示为何将领域知识融入邻域设计能够带来更高效的搜索算法。", "problem": "大学课程表问题旨在将 $n$ 个事件分配到 $t$ 个时间槽和 $r$ 个房间中。一个解 $x$ 是一个满足硬约束的分配方案，这些硬约束包括教师时间不重叠、房间容量限制以及每个房间-时间对只能有一个事件。软约束，例如将事件分散到不同天或最小化晚间时段的使用，会产生惩罚值。设目标函数为软约束惩罚值的加权和 $f(x)$，并通过在搜索过程中拒绝不可行的邻居来强制执行硬约束。局部搜索方法使用一个邻域函数 $N(x)$ 来生成候选移动；从 $x$ 到 $y$ 的移动被接受的条件是 $y$ 可行且 $f(y)  f(x)$。\n\n考虑两种邻域设计：\n- 通用邻域 $N_g(x)$：由交换和插入移动组成，不考虑领域结构：任何两个事件可以交换其时间槽，任何单个事件可以移动到任何时间槽-房间对，但需在生成后进行可行性检查。\n- 领域特定邻域 $N_d(x)$：利用领域知识，根据冲突图和容量约束预先筛选移动：仅当交换能保持教师时间不重叠和满足容量时才提出交换建议，仅当插入到能容纳且不产生冲突的时间槽-房间对时才提出插入建议。\n\n假设在相同的随机邻居采样方案和评估预算下，对于一个特定实例有以下经验统计数据：\n- 在 $N_g(x)$ 下，一个随机生成的邻居是可行的概率为 $q_g = 0.2$，并且在可行的条件下，它是改进解的概率为 $a_g = 0.25$。每个邻居的生成和评估成本为 $c_g = 1$ 个时间单位。\n- 在 $N_d(x)$ 下，一个随机生成的邻居是可行的概率为 $q_d = 0.8$，并且在可行的条件下，它是改进解的概率为 $a_d = 0.5$。每个邻居的生成和评估成本为 $c_d = 1.5$ 个时间单位。\n\n假设局部搜索采用简单的爬山法：从 $N(x)$ 中均匀随机抽取一个邻居 $y$，如果 $y$ 可行且 $f(y)  f(x)$ 则接受 $y$；否则停留在 $x$ 并抽取另一个邻居。此外，考虑一个使用模拟退火（SA）的变体，其中一个目标函数值增加 $\\Delta f = f(y) - f(x) > 0$ 的非改进可行移动以概率 $p_{\\text{SA}} = \\exp(-\\Delta f / T)$ 在温度 $T$ 下被接受。\n\n评估以下陈述并选择所有正确的选项：\n\nA. 在拒绝不可行和非改进移动的爬山法下，对于给定的 $q_g$、$a_g$、$c_g$、$q_d$、$a_d$、$c_d$，$N_d(x)$ 的每个接受的改进步骤的期望时间小于 $N_g(x)$。\n\nB. 在任何温度 $T$ 的模拟退火算法下，将邻域从 $N_g(x)$ 限制到 $N_d(x)$ 必然会降低在可行域中逃离局部最优解的概率，因此无论 $T$ 为多少，使用 $N_d(x)$ 的 SA 收敛效果会更差。\n\nC. 如果 $N_d(x)$ 在可行解集上导出一个连通图（即，对于任意两个可行分配 $x$ 和 $x'$，存在一条由 $N_d$ 中的移动组成的从 $x$ 到 $x'$ 的路径），那么限制到 $N_d(x)$ 会保留全局最优可行解的可达性，同时可能提高每次迭代的效率。\n\nD. 在禁忌搜索中，通用邻域 $N_g(x)$ 总是优于领域特定邻域 $N_d(x)$，因为禁忌机制和惩罚措施弥补了高不可行移动率，使得领域知识变得多余。\n\n选择所有正确的选项。", "solution": "用户希望我扮演一位严谨的STEM教授，解决一个关于启发式优化方法的问题。\n\n### 问题验证\n\n首先，我将验证问题陈述。\n\n**步骤1：提取已知条件**\n\n- **问题背景**：大学课程表编排。\n- **变量**：$n$ 个事件，$t$ 个时间槽，$r$ 个房间。\n- **解的表示**：一个解 $x$ 是事件的一个分配。\n- **约束**：\n    - 硬约束：教师时间不重叠、房间容量限制、每个房间-时间对只有一个事件。必须被满足。\n    - 软约束：分散事件、最小化晚间时段。会产生惩罚值。\n- **目标函数**：$f(x)$ 是软约束惩罚值的加权和；目标是最小化。\n- **搜索范式**：局部搜索，使用邻域函数 $N(x)$。不可行的邻居被拒绝。\n- **邻域定义**：\n    - **通用邻域 $N_g(x)$**：\n        - 移动：交换任意两个事件的时间槽，或将任意事件插入任意时间槽-房间对。\n        - 可行性检查：生成后检查。\n        - 统计数据：\n            - 可行性概率：$q_g = 0.2$。\n            - 条件改进概率：$a_g = 0.25$。\n            - 每个邻居的成本：$c_g = 1$ 个时间单位。\n    - **领域特定邻域 $N_d(x)$**：\n        - 移动：基于冲突图和容量约束进行预筛选。\n        - 统计数据：\n            - 可行性概率：$q_d = 0.8$。\n            - 条件改进概率：$a_d = 0.5$。\n            - 每个邻居的成本：$c_d = 1.5$ 个时间单位。\n- **算法**：\n    - **爬山法**：如果一个随机抽取的邻居 $y$ 是可行的且 $f(y)  f(x)$，则接受它。\n    - **模拟退火（SA）**：一个目标值增加 $\\Delta f = f(y) - f(x) > 0$ 的非改进可行移动以概率 $p_{\\text{SA}} = \\exp(-\\Delta f / T)$ 被接受。\n\n**步骤2：使用提取的已知条件进行验证**\n\n- **科学基础**：该问题在组合优化和元启发式算法这一成熟领域中有坚实的基础。所有概念，包括课程表编排、局部搜索、邻域设计、爬山法和模拟退火，都是标准的且定义正确。\n- **良态性**：问题提供了足够的定量数据来评估各个陈述。每个选项提出的问题都可以通过基于给定模型的逻辑推导和计算来回答。\n- **客观性**：语言精确、客观。\n- **一致性**：问题陈述内部是一致的。在 $N_d(x)$ 的描述中可能存在一个模糊之处，它“根据冲突图和容量约束预先筛选移动”，这可能暗示着100%的可行性。然而，给定的可行性是 $q_d = 0.8$。这并非矛盾；它意味着预筛选处理了部分（但非全部）硬约束（例如，它可能处理了教师冲突和容量问题，但没有处理“每个房间-时间对只能有一个事件”的约束，该约束在生成后检查），这在复杂问题领域是一个现实的场景。\n- **现实性**：提供的数值统计数据是合理的。更复杂的、领域特定的邻域生成器具有更高的计算成本（$c_d > c_g$），但产生更高比例的高质量移动（$q_d > q_g$，$a_d > a_g$）是常见的。\n\n**步骤3：结论和行动**\n\n问题陈述是有效的、科学上合理的、良态的且内部一致的。我将继续进行解题推导。\n\n### 解题推导\n\n我现在将评估四个陈述中的每一个。\n\n**A. 在拒绝不可行和非改进移动的爬山法下，对于给定的 $q_g$、$a_g$、$c_g$、$q_d$、$a_d$、$c_d$，$N_d(x)$ 的每个接受的改进步骤的期望时间小于 $N_g(x)$。**\n\n为了评估这个陈述，我们必须计算每种邻域找到并接受一个改进移动的期望时间。\n找到一个被接受的改进的过程是一系列伯努利试验，其中“成功”是生成一个既可行又具改进性的邻居。达到首次成功所需的试验次数遵循几何分布。\n\n设 $p$ 为单次试验成功的概率。首次成功所需的期望试验次数为 $1/p$。\n设 $c$ 为每次试验的成本（时间）。\n每个接受的改进步骤的期望时间是 $E[\\text{Time}] = c \\times (1/p)$。\n\n单次试验成功的概率（即生成一个可行且改进的邻居）是邻居可行概率（$q$）与在可行条件下它具改进性的条件概率（$a$）的乘积。因此，$p = q \\times a$。\n\n对于通用邻域 $N_g(x)$：\n- 一个可行且改进的邻居的概率：$p_g = q_g \\times a_g = 0.2 \\times 0.25 = 0.05$。\n- 每个邻居的生成/评估成本：$c_g = 1$ 个时间单位。\n- 每次改进的期望时间：$E_g = \\frac{c_g}{p_g} = \\frac{1}{0.05} = 20$ 个时间单位。\n\n对于领域特定邻域 $N_d(x)$：\n- 一个可行且改进的邻居的概率：$p_d = q_d \\times a_d = 0.8 \\times 0.5 = 0.4$。\n- 每个邻居的生成/评估成本：$c_d = 1.5$ 个时间单位。\n- 每次改进的期望时间：$E_d = \\frac{c_d}{p_d} = \\frac{1.5}{0.4} = \\frac{15}{4} = 3.75$ 个时间单位。\n\n比较期望时间：$E_d = 3.75$ 和 $E_g = 20$。\n由于 $3.75  20$，每个接受的改进步骤的期望时间确实对于 $N_d(x)$ 来说小于 $N_g(x)$。\n\nA的结论：**正确**。\n\n**B. 在任何温度 $T$ 的模拟退火算法下，将邻域从 $N_g(x)$ 限制到 $N_d(x)$ 必然会降低在可行域中逃离局部最优解的概率，因此无论 $T$ 为多少，使用 $N_d(x)$ 的 SA 收敛效果会更差。**\n\n这个陈述对逃离局部最优做出了一个很强的断言。在SA中逃离局部最优需要进行一个非改进的移动，其概率为 $p_{\\text{SA}} = \\exp(-\\Delta f / T)$。逃离的能力取决于邻域中是否存在这样的非改进可行邻居。\n\n让我们计算在单次试验中生成一个可行、非改进邻居的概率。这由 $p_{\\text{escape\\_candidate}} = q \\times (1-a)$ 给出。\n\n对于通用邻域 $N_g(x)$：\n- 生成一个可行、非改进邻居的概率：\n$p_{g, \\text{esc}} = q_g \\times (1 - a_g) = 0.2 \\times (1 - 0.25) = 0.2 \\times 0.75 = 0.15$。\n\n对于领域特定邻域 $N_d(x)$：\n- 生成一个可行、非改进邻居的概率：\n$p_{d, \\text{esc}} = q_d \\times (1 - a_d) = 0.8 \\times (1 - 0.5) = 0.8 \\times 0.5 = 0.4$。\n\n生成一个潜在逃逸移动的概率对于 $N_d(x)$（$0.4$）要高于 $N_g(x)$（$0.15$）。因此，限制到 $N_d(x)$ “必然会降低逃离局部最优的概率”这个前提是错误的。使用 $N_d(x)$，SA算法更有可能找到一个非改进的候选移动来考虑逃逸。\n\n此外，“无论 $T$ 为多少，SA收敛效果会更差”的结论是一个没有根据的泛化。SA的整体性能取决于探索（非改进移动）和利用（改进移动）之间的平衡，以及 $T$ 的降温表。像 $N_d(x)$ 这样一个在寻找改进移动（如A所示）和非改进移动方面都更高效的邻域，可能会导致更好的收敛，可能还能配合更快的降温表。该陈述从根本上就是错误的。\n\nB的结论：**错误**。\n\n**C. 如果 $N_d(x)$ 在可行解集上导出一个连通图（即，对于任意两个可行分配 $x$ 和 $x'$，存在一条由 $N_d$ 中的移动组成的从 $x$ 到 $x'$ 的路径），那么限制到 $N_d(x)$ 会保留全局最优可行解的可达性，同时可能提高每次迭代的效率。**\n\n这个陈述包含两个主张。\n\n1.  **“……保留全局最优可行解的可达性”**：前提是邻域 $N_d(x)$ 在所有可行解的集合上导出一个连通图。根据定义，连通图意味着任何节点（可行解）都可以从任何其他节点通过一条由边（邻域中的移动）组成的路径到达。全局最优解是这个可行解集中的一个成员。因此，如果图是连通的，那么从任何起始可行解出发都可以到达任何全局最优解。这部分陈述是搜索空间连通性定义的直接且正确的结果。\n\n2.  **“……同时可能提高每次迭代的效率”**：这个主张表明使用 $N_d(x)$ 可能更有效率。我们对陈述A的分析证实了这一点，对于给定的数据。我们计算出寻找一个改进移动（爬山法中每次迭代效率的一个度量）的期望时间，对于 $N_d(x)$ 是 $E_d = 3.75$，而对于 $N_g(x)$ 是 $E_g = 20$。效率提升是显著的。“可能”这个词的使用是恰当的，因为这种效率增益取决于具体的问题实例和邻域统计数据，而不是一个普遍规律。\n\n该陈述正确地将一个关键的理论属性（连通性，保证可达性）与一个实际的好处（提高效率）联系起来，这一点由问题的数据所证明。这代表了启发式设计中一个理想的目标：创建一个“更智能”的邻域，它既高效又不牺牲探索整个可行空间的能力。\n\nC的结论：**正确**。\n\n**D. 在禁忌搜索中，通用邻域 $N_g(x)$ 总是优于领域特定邻域 $N_d(x)$，因为禁忌机制和惩罚措施弥补了高不可行移动率，使得领域知识变得多余。**\n\n这个陈述做出了一个绝对的断言（“总是优于”）和一个错误的推测（“使得领域知识变得多余”）。\n\n任何局部搜索方法（包括禁忌搜索，TS）的效率都关键地取决于它所评估的邻居的成本和质量。邻域 $N_g(x)$ 有 $80\\%$ 的时间（$1-q_g$）生成不可行的移动。在问题所描述的设置中，这些移动被直接拒绝，意味着使用 $N_g(x)$ 的每次试验中有 $80\\%$ 的计算努力被浪费了。禁忌列表是TS的核心，它作用于*被接受的移动*。它无法“弥补”大量因不可行而甚至没有成为接受候选的生成移动。\n\n断言领域知识变得“多余”与为困难问题设计有效算法的最基本原则之一相悖。“没有免费午餐”定理表明，一个算法的性能之所以能够提升，恰恰是因为它融合了关于问题结构的知识。领域特定邻域 $N_d(x)$ 就是体现这种知识以更有效地引导搜索的一个例子。抛弃这种知识而选择一个暴力、通用的邻域几乎总是一个糟糕的策略。一个更高效的邻域允许TS在相同的时间内执行更多有意义的搜索步骤，从而找到更好的解。\n\n“总是”这个词使这个陈述确定无疑是错误的。很容易构造出场景（如此问题中所给出的），在这些场景中，一个设计良好的领域特定邻域在TS框架内的表现远超通用邻域。\n\nD的结论：**错误**。", "answer": "$$\\boxed{AC}$$", "id": "3136481"}, {"introduction": "超越传统的局部搜索，我们将探索一种更先进的基于模型的元启发式算法——交叉熵（CE）方法。该方法通过迭代地优化一个概率模型来引导搜索，使其能生成位于解空间中高质量区域的样本。本编码练习 [@problem_id:3136467] 将指导你为经典的 $0$-$1$ 背包问题完整实现交叉熵算法，涵盖从采样、解修复到模型参数的统计更新等所有关键步骤。通过这个实践，你将深入理解算法如何“学习”并聚焦于更有希望的解。", "problem": "您将实现用于二元采样分布的交叉熵方法，以解决一个单实例的 $0$-$1$ 背包问题，并分析其对精英比例的敏感性。交叉熵方法是一种基于模型的随机搜索方法，它通过最小化与一个集中于高性能解的目标分布之间的 Kullback–Leibler 散度（也称为交叉熵），来迭代地更新参数化的采样分布。这里的采样分布族是独立的伯努利分布的乘积，每个物品对应一个伯努利分布。更新是通过在模型下最大化精英解集似然的第一性原理推导出来的。您必须实现完整的方法，并为指定的精英比例测试套件返回定量结果。\n\n背包实例：令 $n$ 表示物品数量，$\\mathbf{w} \\in \\mathbb{N}^{n}$ 为重量，$\\mathbf{v} \\in \\mathbb{N}^{n}$ 为价值， $C \\in \\mathbb{N}$ 为容量。考虑 $n=15$，容量 $C=50$，其中\n$\\mathbf{w} = [12,7,11,8,9,13,4,6,10,3,14,5,2,1,15]$ 且\n$\\mathbf{v} = [36,14,22,21,19,32,9,17,25,8,28,12,5,3,34]$。\n一个候选解是一个向量 $\\mathbf{x} \\in \\{0,1\\}^{n}$，其目标为 $f(\\mathbf{x}) = \\sum_{i=1}^{n} v_{i} x_{i}$，可行性约束为 $\\sum_{i=1}^{n} w_{i} x_{i} \\le C$。\n\n采样分布：使用一个独立伯努利参数的向量 $\\boldsymbol{\\theta} \\in (0,1)^{n}$，其中第 $i$ 位通过 $x_{i} \\sim \\text{Bernoulli}(\\theta_{i})$ 采样。初始化所有 $i$ 的 $\\theta_{i} = 0.5$。\n\n可行性处理：为确保可行性，对每个超出容量的采样 $\\mathbf{x}$ 应用一个确定性修复算子。如果 $\\sum_{i} w_{i} x_{i} > C$，则按照比率 $r_{j} = v_{j} / w_{j}$ 的递增顺序（即，首先移除 $v_{j}/w_{j}$ 最小的物品），迭代地将 $x_{j} \\leftarrow 0$，直到 $\\sum_{i} w_{i} x_{i} \\le C$。该算子必须在有限步骤内终止并产生一个可行解。\n\n交叉熵迭代：在每次迭代 $t = 1,2,\\dots,T$ 中，从当前的 $\\boldsymbol{\\theta}$ 中独立采样 $N$ 个解，如果需要则修复它们，评估 $f(\\cdot)$，并选择目标值最高的前 $m$ 个解作为精英集 $\\mathcal{E}$，其中对于给定的精英比例 $p \\in (0,1]$，$m = \\max(1, \\lceil pN \\rceil)$。通过在伯努利乘积模型下最大化精英集的似然来更新 $\\boldsymbol{\\theta}$，使用一个带有参数 $\\alpha \\in (0,1]$ 的指数平滑步骤。更新后，将每个 $\\theta_{i}$ 投影到区间 $[\\varepsilon, 1 - \\varepsilon]$ 中，其中 $\\varepsilon \\in (0, 0.5)$，以避免退化。维持并返回在所有样本和所有迭代中找到的最佳可行目标值。\n\n您在设计和推导中必须使用并明确依据的基本原理：\n- $0$-$1$ 背包问题的定义：最大化 $f(\\mathbf{x}) = \\sum_{i=1}^{n} v_{i} x_{i}$，约束条件为 $\\sum_{i=1}^{n} w_{i} x_{i} \\le C$，其中 $\\mathbf{x} \\in \\{0,1\\}^{n}$。\n- 独立伯努利乘积族：对于 $\\mathbf{x} \\in \\{0,1\\}^{n}$，$p_{\\boldsymbol{\\theta}}(\\mathbf{x}) = \\prod_{i=1}^{n} \\theta_{i}^{x_{i}} (1-\\theta_{i})^{1 - x_{i}}$。\n- 应用于有限精英数据集的独立伯努利变量的最大似然估计。\n- Kullback–Leibler 散度的定义，以及最小化到精英支持的目标分布的交叉熵与最大化精英集上的似然之间的等价性。\n\n您的实现中要使用的超参数：\n- 每次迭代的样本数 $N = 300$。\n- 迭代次数 $T = 60$。\n- 平滑参数 $\\alpha = 0.7$。\n- 概率下限 $\\varepsilon = 0.05$。\n- 所有测试用例的随机数生成器种子 $s = 314159$。\n\n测试套件：您必须评估算法为以下每个精英比例 $p$ 返回的最佳目标值：\n- 情况 1：$p = 0.05$。\n- 情况 2：$p = 0.20$。\n- 情况 3：$p = 0.50$。\n- 情况 4：$p = 0.90$。\n\n覆盖性设计：测试套件包括一个小的精英比例 $p = 0.05$（激进更新）、一个中等比例 $p = 0.20$、一个平衡比例 $p = 0.50$ 和一个非常大的比例 $p = 0.90$（保守更新），以探究交叉熵方法中的偏差-方差权衡。\n\n答案规范：\n- 对于每种情况，返回算法在 $T$ 次迭代后找到的最佳可行目标值的单个整数。\n- 将四种情况的结果汇总为一行输出，格式严格为方括号内以逗号分隔的列表，例如 $[r_{1},r_{2},r_{3},r_{4}]$，其中每个 $r_{k}$ 是一个整数。\n- 不涉及物理单位。不涉及角度。百分比必须按提供的小数输入。\n- 您的程序必须以指定格式产生一行输出，并且不得要求任何用户输入或外部文件。", "solution": "该问题要求实现交叉熵（CE）方法，为 $0$-$1$ 背包问题的一个特定实例找到高质量的解。将在一组给定的测试套件上分析算法性能对精英比例参数 $p$ 的敏感性。\n\n该方法首先对问题陈述进行正式验证，发现其在科学上是合理的、适定的且完整的。验证之后，将推导并解释一个详细的、基于原理的解决方案。\n\n### 问题验证\n\n**步骤 1：提取给定信息**\n\n*   **问题**：$0$-$1$ 背包问题。\n*   **实例**：\n    *   物品数量：$n=15$。\n    *   容量：$C=50$。\n    *   重量：$\\mathbf{w} = [12,7,11,8,9,13,4,6,10,3,14,5,2,1,15]$。\n    *   价值：$\\mathbf{v} = [36,14,22,21,19,32,9,17,25,8,28,12,5,3,34]$。\n*   **解向量**：$\\mathbf{x} \\in \\{0,1\\}^{n}$。\n*   **目标**：最大化 $f(\\mathbf{x}) = \\sum_{i=1}^{n} v_{i} x_{i}$。\n*   **约束**：$\\sum_{i=1}^{n} w_{i} x_{i} \\le C$。\n*   **采样分布**：带参数 $\\boldsymbol{\\theta} \\in (0,1)^{n}$ 的独立伯努利分布的乘积。\n*   **初始化**：对所有 $i$，$\\theta_{i} = 0.5$。\n*   **可行性处理**：一种确定性修复算子，它以价值重量比 $r_j = v_j/w_j$ 的递增顺序，从超重的背包中迭代地移除物品。\n*   **CE 迭代**：基于采样、修复、评估、精英选择和参数更新。\n*   **基本原理**：$0$-$1$ 背包定义、伯努利乘积模型、伯努利变量的最大似然估计（MLE）、KL 散度最小化与 MLE 的等价性。\n*   **超参数**：\n    *   每次迭代的样本数：$N = 300$。\n    *   迭代次数：$T = 60$。\n    *   平滑参数：$\\alpha = 0.7$。\n    *   概率下限：$\\varepsilon = 0.05$。\n    *   随机种子：$s = 314159$。\n*   **测试套件**：精英比例 $p \\in \\{0.05, 0.20, 0.50, 0.90\\}$。\n*   **输出**：为每个 $p$ 找到的最佳可行目标值，格式化为列表。\n\n**步骤 2：使用提取的给定信息进行验证**\n\n根据验证标准对问题进行评估：\n*   **科学依据**：该问题在优化（交叉熵方法）和计算机科学（背包问题）等成熟领域中有坚实的理论基础。引用的数学原理是正确的。\n*   **适定性**：所有必要的数据、参数和算法步骤都已明确定义。使用固定的随机种子确保每个测试用例都有唯一且可复现的结果。\n*   **客观性**：问题陈述使用精确、定量且无偏见的语言。\n*   问题没有显示出任何科学不合理、不完整、矛盾或模糊等缺陷。它是一个标准的、非平凡的计算问题，完全可以验证。\n\n**步骤 3：结论与行动**\n\n该问题是**有效的**。将提供完整的解决方案。\n\n### 解决方案推导与算法设计\n\n交叉熵方法是一种随机优化算法，它通过迭代更新解空间上概率分布的参数来工作。其目标是演化分布，使其在具有高目标值的区域中生成样本。\n\n**1. 背包问题与概率模型**\n\n问题是选择 $n=15$ 个物品的一个子集，以在不超过重量容量 $C=50$ 的前提下最大化总价值。一个解是一个二元向量 $\\mathbf{x} \\in \\{0,1\\}^{n}$，其中如果物品 $i$ 被包含则 $x_i=1$，否则 $x_i=0$。\n目标函数是 $f(\\mathbf{x}) = \\mathbf{v}^T \\mathbf{x} = \\sum_{i=1}^{n} v_{i} x_{i}$，约束条件为 $\\mathbf{w}^T \\mathbf{x} = \\sum_{i=1}^{n} w_{i} x_{i} \\le C$。\n\n我们在解空间 $\\{0,1\\}^n$ 上定义一个参数化的概率分布。根据规定，这是一个独立伯努利分布的乘积：\n$$p_{\\boldsymbol{\\theta}}(\\mathbf{x}) = \\prod_{i=1}^{n} p(x_i | \\theta_i) = \\prod_{i=1}^{n} \\theta_{i}^{x_{i}} (1-\\theta_{i})^{1 - x_{i}}$$\n这里，$\\boldsymbol{\\theta} = (\\theta_1, \\dots, \\theta_n)$ 是参数向量，其中 $\\theta_i$ 是物品 $i$ 被包含在解中（$x_i=1$）的概率。最初，所有物品被选中的机会均等：对于所有 $i=1, \\dots, n$，$\\theta_i^{(0)} = 0.5$。\n\n**2. 通过最大似然估计进行参数更新**\n\nCE 方法的核心是 $\\boldsymbol{\\theta}$ 的更新规则。在每次迭代 $t$ 中，我们从当前分布 $p_{\\boldsymbol{\\theta}^{(t-1)}}(\\mathbf{x})$ 生成一个包含 $N$ 个候选解的群体。在修复和评估这些解之后，我们选择一个包含 $m$ 个表现最好的解的“精英集”$\\mathcal{E}$。下一次迭代的分布 $\\boldsymbol{\\theta}^{(t)}$ 被选择为更“接近”一个理想的、只会从这个精英集中生成解的分布。\n\n最小化 $p_{\\boldsymbol{\\theta}}(\\mathbf{x})$ 与这个理想目标分布之间的 Kullback-Leibler 散度（或交叉熵），等价于在我们的模型 $p_{\\boldsymbol{\\theta}}(\\mathbf{x})$ 下最大化精英样本的似然。\n\n设精英集为 $\\mathcal{E} = \\{\\mathbf{x}^{(1)}, \\mathbf{x}^{(2)}, \\dots, \\mathbf{x}^{(m)}\\}$。似然函数是：\n$$L(\\boldsymbol{\\theta}; \\mathcal{E}) = \\prod_{j=1}^{m} p_{\\boldsymbol{\\theta}}(\\mathbf{x}^{(j)}) = \\prod_{j=1}^{m} \\prod_{i=1}^{n} \\theta_{i}^{x_{i}^{(j)}} (1-\\theta_{i})^{1 - x_{i}^{(j)}}$$\n为了更容易最大化，我们使用对数似然：\n$$\\log L(\\boldsymbol{\\theta}; \\mathcal{E}) = \\sum_{j=1}^{m} \\sum_{i=1}^{n} \\left[ x_{i}^{(j)} \\log(\\theta_i) + (1-x_{i}^{(j)}) \\log(1-\\theta_i) \\right]$$\n为了找到最大化该函数的参数 $\\boldsymbol{\\theta}$，我们对每个 $\\theta_k$ 求偏导数并令其为零：\n$$\\frac{\\partial \\log L}{\\partial \\theta_k} = \\sum_{j=1}^{m} \\left[ \\frac{x_{k}^{(j)}}{\\theta_k} - \\frac{1-x_{k}^{(j)}}{1-\\theta_k} \\right] = 0$$\n$$\\frac{1}{\\theta_k} \\sum_{j=1}^{m} x_{k}^{(j)} = \\frac{1}{1-\\theta_k} \\sum_{j=1}^{m} (1-x_{k}^{(j)})$$\n求解 $\\theta_k$ 得到最大似然估计，我们记为 $\\hat{\\theta}_k$：\n$$\\hat{\\theta}_k = \\frac{\\sum_{j=1}^{m} x_{k}^{(j)}}{m}$$\n这个简洁的结果表明，第 $k$ 个物品的最优参数 $\\hat{\\theta}_k$ 就是该物品在精英集中所有解中被包含的频率。\n\n**3. 平滑更新与参数投影**\n\n为防止过早收敛并提供稳定性，参数更新使用带有平滑参数 $\\alpha$ 的指数移动平均进行平滑：\n$$\\boldsymbol{\\theta}^{(t)} = \\alpha \\hat{\\boldsymbol{\\theta}} + (1-\\alpha) \\boldsymbol{\\theta}^{(t-1)}$$\n较大的 $\\alpha$（如指定的 $\\alpha=0.7$）会给最近的精英集更多的权重，导致更快的收敛，而较小的 $\\alpha$ 则导致更保守的更新。\n\n此外，为确保搜索不会因概率完全收敛到 $0$ 或 $1$ 而停滞，更新后的参数被投影到区间 $[\\varepsilon, 1-\\varepsilon]$ 中。对于每个分量 $i$：\n$$\\theta_i^{(t)} \\leftarrow \\max(\\varepsilon, \\min(1-\\varepsilon, \\theta_i^{(t)}))$$\n当 $\\varepsilon=0.05$ 时，每个物品始终有至少 $5\\%$ 的机会被采样（或不被采样），从而保持一定程度的探索。\n\n**4. 可行性修复算子**\n\n由于从伯努利分布中采样不遵守背包容量约束，因此需要一个修复步骤。对于任何生成的解 $\\mathbf{x}$，如果 $\\mathbf{w}^T\\mathbf{x} > C$，我们必须移除物品直到满足约束。指定的策略是首先移除价值重量比 $r_j = v_j/w_j$ 最低的物品。这是一个贪心选择，旨在在减少重量的同时尽可能多地保留价值。该算子在评估前应用于每个生成的样本。\n\n**5. 完整算法**\n\n对于给定的精英比例 $p$，完整算法如下：\n\n1.  **初始化**：\n    *   设置迭代计数器 $t \\leftarrow 0$。\n    *   初始化伯努利参数 $\\boldsymbol{\\theta}^{(0)} \\leftarrow (0.5, 0.5, \\dots, 0.5)$。\n    *   初始化找到的最佳目标值 $f_{best} \\leftarrow -\\infty$。\n    *   预先计算按 $v_j/w_j$ 排序的物品索引。\n    *   设置精英样本数 $m = \\max(1, \\lceil pN \\rceil)$。\n\n2.  **迭代循环**：对于 $t = 1, \\dots, T$：\n    *   **采样**：通过抽取 $x_i^{(j)} \\sim \\text{Bernoulli}(\\theta_i^{(t-1)})$ 生成 $N$ 个样本 $\\{\\mathbf{x}^{(1)}, \\dots, \\mathbf{x}^{(N)}\\}$。\n    *   **修复**：对于每个样本 $\\mathbf{x}^{(j)}$：如果 $\\mathbf{w}^T\\mathbf{x}^{(j)} > C$，则应用修复算子直到 $\\mathbf{w}^T\\mathbf{x}^{(j)} \\le C$。令修复后的样本为 $\\{\\mathbf{x'}^{(1)}, \\dots, \\mathbf{x'}^{(N)}\\}$。\n    *   **评估**：计算所有 $j=1, \\dots, N$ 的目标值 $f(\\mathbf{x'}^{(j)})$。\n    *   **更新最优值**：$f_{best} \\leftarrow \\max(f_{best}, \\max_{j} f(\\mathbf{x'}^{(j)}))$。\n    *   **精英选择**：识别出具有最高目标值的 $m$ 个修复后样本的集合 $\\mathcal{E}$。\n    *   **参数更新**：\n        a. 计算 MLE：对于所有 $i=1, \\dots, n$，$\\hat{\\theta}_i = \\frac{1}{m} \\sum_{\\mathbf{x'} \\in \\mathcal{E}} x'_i$。\n        b. 平滑：$\\boldsymbol{\\theta}^{(t)} = \\alpha \\hat{\\boldsymbol{\\theta}} + (1-\\alpha) \\boldsymbol{\\theta}^{(t-1)}$。\n        c. 投影：$\\theta_i^{(t)} \\leftarrow \\max(\\varepsilon, \\min(1-\\varepsilon, \\theta_i^{(t)}))$。\n\n3.  **终止**：在 $T$ 次迭代后，返回 $f_{best}$。\n\n对测试套件 $\\{0.05, 0.20, 0.50, 0.90\\}$ 中的每个 $p$ 值重复此过程，每次运行时重新初始化随机数生成器，以确保公平、独立的试验。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Implements the Cross-Entropy method for the 0-1 knapsack problem\n    and evaluates it for a suite of elite fraction parameters.\n    \"\"\"\n    \n    # Knapsack problem instance\n    n = 15\n    capacity = 50\n    weights = np.array([12, 7, 11, 8, 9, 13, 4, 6, 10, 3, 14, 5, 2, 1, 15])\n    values = np.array([36, 14, 22, 21, 19, 32, 9, 17, 25, 8, 28, 12, 5, 3, 34])\n\n    # Hyperparameters\n    N_SAMPLES = 300\n    N_ITERATIONS = 60\n    ALPHA = 0.7  # Smoothing parameter\n    EPSILON = 0.05  # Probability floor\n    SEED = 314159\n\n    # Test suite for elite fraction p\n    test_cases = [0.05, 0.20, 0.50, 0.90]\n    \n    # Pre-calculate value-to-weight ratios and sorted indices for repair\n    # Handle division by zero if a weight is 0, though not present in this data\n    with np.errstate(divide='ignore', invalid='ignore'):\n        ratios = values / weights\n    ratios[np.isinf(ratios)] = np.finfo(np.float64).max # If w=0, v>0, ratio is infinite\n    ratios[np.isnan(ratios)] = -1.0 # If w=0, v=0\n    \n    # Indices of items sorted by increasing v/w ratio\n    # Items with lower ratios will be removed first\n    sorted_indices_for_repair = np.argsort(ratios)\n    \n    final_results = []\n\n    for p_elite in test_cases:\n        # Initialize RNG for reproducibility for each test case\n        rng = np.random.default_rng(SEED)\n        \n        # Initialize Bernoulli parameters\n        theta = np.full(n, 0.5)\n        \n        # Track the best objective value found so far\n        best_overall_value = 0\n        \n        # Calculate number of elite samples\n        # m = max(1, ceil(p*N))\n        m_elite = max(1, int(math.ceil(p_elite * N_SAMPLES)))\n\n        for _ in range(N_ITERATIONS):\n            # 1. Sampling: Generate N samples from the Bernoulli distribution\n            # samples[i, j] is 1 if item j is in sample i, 0 otherwise\n            random_values = rng.random((N_SAMPLES, n))\n            samples = (random_values  theta).astype(int)\n            \n            repaired_samples = np.copy(samples)\n            \n            # 2. Feasibility Repair\n            for i in range(N_SAMPLES):\n                current_weight = np.dot(repaired_samples[i], weights)\n                if current_weight > capacity:\n                    # The sample is overweight, repair it\n                    # Iterate through items sorted by low v/w ratio\n                    for item_idx in sorted_indices_for_repair:\n                        if repaired_samples[i, item_idx] == 1:\n                            # Remove this item from the knapsack\n                            repaired_samples[i, item_idx] = 0\n                            current_weight -= weights[item_idx]\n                            if current_weight = capacity:\n                                # Repair complete for this sample\n                                break\n            \n            # 3. Evaluation\n            objective_values = np.dot(repaired_samples, values)\n\n            # 4. Update Best-So-Far\n            current_best_value = np.max(objective_values)\n            if current_best_value > best_overall_value:\n                best_overall_value = current_best_value\n            \n            # 5. Elite Selection\n            # Get indices of the top m_elite samples\n            elite_indices = np.argsort(objective_values)[-m_elite:]\n            elite_samples = repaired_samples[elite_indices]\n\n            # 6. Parameter Update\n            # a. MLE estimate\n            theta_hat = np.mean(elite_samples, axis=0)\n            \n            # b. Smoothing\n            theta = ALPHA * theta_hat + (1 - ALPHA) * theta\n            \n            # c. Projection\n            theta = np.clip(theta, EPSILON, 1 - EPSILON)\n\n        final_results.append(int(best_overall_value))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n\n```", "id": "3136467"}, {"introduction": "在实际应用中，一个常被忽视但至关重要的挑战是：何时停止一个迭代式的启发式算法？由于许多启发式算法具有随机性，并且理论上可以无限运行，因此设计一个有效的终止准则是节省计算资源和确保解质量的关键。这个编码实践 [@problem_id:3136544] 直面这一问题，要求你实现并模拟一个自适应停止规则。你将通过分析过早停止与过晚停止的风险，学习如何利用统计工具在不确定性中做出明智的决策。", "problem": "要求您仅使用概率论和统计学的基本定义以及标准算法结构，为一个随机启发式优化过程设计、论证并评估一个自适应停止准则。目标是量化过早停止与过晚停止之间的权衡。\n\n假设一个迭代启发式优化器产生一个非负标量改进序列 $\\{\\Delta_t\\}_{t=1}^{\\infty}$，其中 $\\Delta_t$ 是在第 $t$ 次迭代时实现的目标函数值的改进量。用指数衰减曲线对期望改进量进行建模：\n$$\n\\mathbb{E}[\\Delta_t] = A e^{-\\beta t},\n$$\n其中 $A \\gt 0$ 且 $\\beta \\gt 0$。观测到的改进量为\n$$\n\\Delta_t = \\max\\{0,\\, A e^{-\\beta t} + \\eta_t\\},\n$$\n其中 $\\{\\eta_t\\}$ 是独立同分布的高斯噪声项，满足 $\\eta_t \\sim \\mathcal{N}(0,\\sigma^2)$，并且负值在 0 处被截断以确保非负性。\n\n定义以下两种停止时间。\n\n- 神谕停止时间。对于一个参考容差 $\\epsilon_{\\text{true}} \\gt 0$，神谕停止索引是满足 $\\mathbb{E}[\\Delta_t] \\le \\epsilon_{\\text{true}}$ 的最小整数 $t_{\\star}$，即：\n$$\nt_{\\star} = \\min\\{t \\in \\mathbb{N} : A e^{-\\beta t} \\le \\epsilon_{\\text{true}}\\}.\n$$\n\n- 自适应移动平均准则。对于窗口长度 $w \\in \\mathbb{N}$ 和估计容差 $\\epsilon_{\\text{est}} \\gt 0$，定义移动平均值为：\n$$\n\\overline{\\Delta}_t = \\frac{1}{w} \\sum_{i=t-w+1}^{t} \\Delta_i \\quad \\text{for} \\quad t \\ge w.\n$$\n自适应停止索引为：\n$$\n\\tau = \\min\\left\\{t \\in \\mathbb{N}: t \\ge w \\ \\text{and} \\ \\overline{\\Delta}_t \\le \\epsilon_{\\text{est}}\\right\\},\n$$\n并约定如果在达到允许的最大迭代次数 $T_{\\max}$ 之前该集合为空，则将 $\\tau$ 设置为 $T_{\\max}$。\n\n对于下方的每个参数集，执行一个包含 $M$ 次独立运行的蒙特卡洛实验。在每次运行中，模拟改进序列直到 $T_{\\max}$，并记录自适应停止索引 $\\tau$ 和神谕索引 $t_{\\star}$。量化：\n\n- 过早停止风险，即 $\\tau \\lt t_{\\star}$ 的运行次数所占的比例。\n- 延迟停止风险，即 $\\tau \\gt t_{\\star}$ 的运行次数所占的比例。\n\n两种风险都必须以 $[0,1]$ 区间内的小数形式报告，并四舍五入到三位小数。\n\n使用以下测试套件。每个元组列出了 $(A,\\ \\beta,\\ \\sigma,\\ w,\\ \\epsilon_{\\text{est}},\\ \\epsilon_{\\text{true}},\\ T_{\\max},\\ M,\\ \\text{seed})$：\n\n- 测试 1：$(0.5, 0.05, 0.02, 10, 0.01, 0.01, 400, 4000, 123)$。\n- 测试 2：$(0.5, 0.05, 0.02, 5, 0.02, 0.01, 400, 4000, 456)$。\n- 测试 3：$(0.5, 0.05, 0.02, 20, 0.005, 0.01, 400, 4000, 789)$。\n- 测试 4：$(0.5, 0.05, 0.08, 3, 0.01, 0.01, 400, 4000, 42)$。\n- 测试 5：$(0.02, 0.1, 0.005, 5, 0.01, 0.01, 200, 4000, 321)$。\n\n要求与说明：\n\n- 本问题不涉及角度；没有需要指定的角度单位。\n- 不涉及物理单位；所有量均为无量纲标量。\n- 对于每个测试，根据神谕的模型定义计算 $t_{\\star}$，并确保所选参数满足 $t_{\\star} \\le T_{\\max}$。\n- 您的程序必须输出单行内容，包含一个浮点数列表：按给定顺序，对每个测试输出过早停止风险和延迟停止风险，两者均四舍五入到三位小数。将所有测试结果汇总到一个列表中。例如，输出格式必须严格遵循 $[r_{1,\\text{prem}},r_{1,\\text{delay}},r_{2,\\text{prem}},\\dots,r_{5,\\text{delay}}]$ 的形式，不含空格。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[r_1,r_2,r_3]$）。", "solution": "该问题要求为随机优化过程设计和评估一个自适应停止准则。这将通过蒙特卡洛模拟，将一个实用的、数据驱动的准则与一个理论上的“神谕”准则的性能进行比较来完成。\n\n### 基本概念\n\n问题的核心在于探索与利用之间的权衡，这是优化中的一个经典主题。迭代优化器旨在随时间推移改进解。每次迭代的改进量（用 $\\Delta_t$ 表示）被建模为一个随机过程。我们假设期望改进量遵循指数衰减，这是对收益递减过程的常见建模方式：\n$$\n\\mathbb{E}[\\Delta_t] = A e^{-\\beta t}\n$$\n此处，$A  0$ 代表初始改进规模，$\\beta  0$ 是衰减率。观测到的改进量 $\\Delta_t$ 是此期望值的带噪版本：\n$$\n\\Delta_t = \\max\\{0,\\, A e^{-\\beta t} + \\eta_t\\}\n$$\n其中 $\\eta_t$ 是一个随机噪声项，建模为独立同分布（i.i.d.）的高斯变量，$\\eta_t \\sim \\mathcal{N}(0, \\sigma^2)$。$\\max\\{0, \\cdot\\}$ 操作确保观测到的改进量为非负，这具有物理意义。\n\n### 神谕停止准则\n\n一个理想的停止准则会在*期望*的未来改进量降至一个有意义的阈值 $\\epsilon_{\\text{true}}$ 以下时，精确地终止优化过程。这就定义了神谕停止时间 $t_{\\star}$，它在现实世界场景中是无法获取的，因为它需要知道底层模型参数 $A$ 和 $\\beta$。\n神谕停止索引 $t_{\\star}$ 是使得期望改进量不大于真实容差 $\\epsilon_{\\text{true}}$ 的最小整数时间 $t$：\n$$\nt_{\\star} = \\min\\{t \\in \\mathbb{N} : A e^{-\\beta t} \\le \\epsilon_{\\text{true}}\\}\n$$\n这个不等式可以求解 $t$：\n$$\nA e^{-\\beta t} \\le \\epsilon_{\\text{true}} \\implies e^{-\\beta t} \\le \\frac{\\epsilon_{\\text{true}}}{A} \\implies -\\beta t \\le \\ln\\left(\\frac{\\epsilon_{\\text{true}}}{A}\\right)\n$$\n$$\nt \\ge -\\frac{1}{\\beta} \\ln\\left(\\frac{\\epsilon_{\\text{true}}}{A}\\right) \\implies t \\ge \\frac{1}{\\beta} \\ln\\left(\\frac{A}{\\epsilon_{\\text{true}}}\\right)\n$$\n由于 $t$ 必须是整数，$t_{\\star}$ 是满足此条件的最小整数，可以通过对右侧表达式向上取整得到。由于 $t$ 必须是正整数（$t \\in \\mathbb{N}$），我们有：\n$$\nt_{\\star} = \\max\\left(1, \\left\\lceil \\frac{1}{\\beta} \\ln\\left(\\frac{A}{\\epsilon_{\\text{true}}}\\right) \\right\\rceil\\right)\n$$\n对于每组参数，$t_{\\star}$ 是一个确定性的常数值，作为我们的基准。\n\n### 自适应停止准则\n\n一个实用的停止准则无法访问 $\\mathbb{E}[\\Delta_t]$，必须依赖于可观测的、带噪声的序列 $\\{\\Delta_t\\}$。所提出的自适应准则使用简单移动平均来过滤噪声并估计改进的近期趋势。在大小为 $w$ 的窗口上的移動平均定義为：\n$$\n\\overline{\\Delta}_t = \\frac{1}{w} \\sum_{i=t-w+1}^{t} \\Delta_i \\quad \\text{for} \\quad t \\ge w\n$$\n自适应停止索引 $\\tau$ 是指该移动平均值首次降至指定的估计容差 $\\epsilon_{\\text{est}}$ 以下的时间 $t$（在 $t=w$ 时或之后，此时第一个完整窗口可用）：\n$$\n\\tau = \\min\\left\\{t \\in \\mathbb{N}: t \\ge w \\ \\text{and} \\ \\overline{\\Delta}_t \\le \\epsilon_{\\text{est}}\\right\\}\n$$\n如果在达到最大迭代次数 $T_{\\max}$ 前此条件都未满足，我们设置 $\\tau = T_{\\max}$。\n\n该准则的行为受窗口大小 $w$、噪声水平 $\\sigma$ 和所选容差 $\\epsilon_{\\text{est}}$ 之间相互作用的支配。\n- 较小的 $w$ 使准则响应灵敏但易受噪声影响，可能因随机的下降而导致过早停止，或因随机的峰值而导致延迟停止。\n- 较大的 $w$ 能更好地平滑噪声，但会引入延迟。平均值 $\\overline{\\Delta}_t$ 将包含较旧、较大的 $\\Delta_i$ 值，可能在真实期望改进量早已降至阈值以下很久之后，仍使平均值保持在 $\\epsilon_{\\text{est}}$ 以上，从而导致延迟停止。\n\n### 蒙特卡洛模拟与风险评估\n\n由于 $\\Delta_t$ 是一个随机变量，自适应停止时间 $\\tau$ 也是一个随机变量。为了评估自适应准则的性能，我们必须分析 $\\tau$ 相对于固定的神谕时间 $t_{\\star}$ 的分布。蒙特卡洛模拟是进行此分析的合适工具。\n\n其流程如下：\n1. 对于给定的参数集 $(A, \\beta, \\sigma, w, \\epsilon_{\\text{est}}, \\epsilon_{\\text{true}}, T_{\\max}, M, \\text{seed})$，我们首先计算确定性的神谕时间 $t_{\\star}$。\n2. 然后我们进行 $M$ 次独立的模拟运行。\n3. 在每次运行中：\n    a. 生成一个随机噪声序列 $\\{\\eta_t\\}_{t=1}^{T_{\\max}}$。\n    b. 计算观测到的改进序列 $\\{\\Delta_t\\}_{t=1}^{T_{\\max}}$。\n    c. 计算移动平均序列 $\\{\\overline{\\Delta}_t\\}_{t=w}^{T_{\\max}}$。\n    d. 确定该次特定运行的自适应停止时间 $\\tau$。\n4. 经过 $M$ 次运行后，我们得到一个包含 $M$ 个 $\\tau$ 值的样本。然后我们可以通过统计结果来估计风险：\n    - **过早停止风险**：过程停止过早的运行次数比例，即 $P(\\tau  t_{\\star}) \\approx \\frac{\\text{count}(\\tau  t_{\\star})}{M}$。这代表了未能实现优化全部潜力的风险。\n    - **延迟停止风险**：过程停止过晚的运行次数比例，即 $P(\\tau > t_{\\star}) \\approx \\frac{\\text{count}(\\tau > t_{\\star})}{M}$。这代表了浪费计算资源的风险。\n\nPython 实现将为每个提供的测试用例执行此模拟。使用 NumPy 可以进行高效的向量化操作，以生成序列和计算移动平均值。随机数生成由种子控制，以确保可复现性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the Monte Carlo simulation for all test cases and print the results.\n    \"\"\"\n    # Test suite: (A, beta, sigma, w, eps_est, eps_true, T_max, M, seed)\n    test_cases = [\n        (0.5, 0.05, 0.02, 10, 0.01, 0.01, 400, 4000, 123),\n        (0.5, 0.05, 0.02, 5, 0.02, 0.01, 400, 4000, 456),\n        (0.5, 0.05, 0.02, 20, 0.005, 0.01, 400, 4000, 789),\n        (0.5, 0.05, 0.08, 3, 0.01, 0.01, 400, 4000, 42),\n        (0.02, 0.1, 0.005, 5, 0.01, 0.01, 200, 4000, 321),\n    ]\n\n    results = []\n    for params in test_cases:\n        premature_risk, delayed_risk = run_simulation(*params)\n        results.extend([round(premature_risk, 3), round(delayed_risk, 3)])\n\n    # Format output according to the problem specification\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(A, beta, sigma, w, eps_est, eps_true, T_max, M, seed):\n    \"\"\"\n    Performs a Monte Carlo simulation for a single set of parameters.\n\n    Args:\n        A (float): Initial improvement scale.\n        beta (float): Decay rate.\n        sigma (float): Standard deviation of Gaussian noise.\n        w (int): Moving average window size.\n        eps_est (float): Estimated tolerance for the adaptive rule.\n        eps_true (float): True tolerance for the oracle rule.\n        T_max (int): Maximum number of iterations.\n        M (int): Number of Monte Carlo runs.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        tuple[float, float]: A tuple containing the premature stopping risk and\n                             the delayed stopping risk.\n    \"\"\"\n    # Step 1: Calculate the deterministic oracle stopping time t_star\n    # t_star must be an integer t >= 1.\n    # The condition is t >= (1/beta) * ln(A / eps_true).\n    if A = eps_true:\n        t_star = 1\n    else:\n        t_star_val = (1 / beta) * np.log(A / eps_true)\n        t_star = int(np.ceil(t_star_val))\n        if t_star  1:\n            t_star = 1\n\n    # Step 2: Set up Monte Carlo simulation\n    rng = np.random.default_rng(seed)\n    premature_count = 0\n    delayed_count = 0\n    \n    # Generate time steps array (1-based index)\n    t_steps = np.arange(1, T_max + 1)\n    \n    # Pre-calculate the expected improvement curve\n    expected_delta = A * np.exp(-beta * t_steps)\n\n    for _ in range(M):\n        # Step 3a: Generate noise and observed improvements for one run\n        eta = rng.normal(loc=0, scale=sigma, size=T_max)\n        delta_t = np.maximum(0, expected_delta + eta)\n\n        # Step 3b: Calculate moving averages efficiently using cumulative sums\n        # This creates a sliding window of size w over delta_t\n        cumsum_delta = np.cumsum(delta_t)\n        # Pad with 0 for the t-w calculation\n        cumsum_delta_padded = np.concatenate(([0], cumsum_delta))\n        moving_sums = cumsum_delta_padded[w:] - cumsum_delta_padded[:-w]\n        moving_averages = moving_sums / w\n\n        # moving_averages[i] corresponds to the average at time t = i + w\n        \n        # Step 3c: Find the adaptive stopping time tau\n        # Find indices where the condition is met\n        below_threshold_indices = np.where(moving_averages = eps_est)[0]\n        \n        if below_threshold_indices.size > 0:\n            # The first index 'k' where the condition is met\n            first_idx = below_threshold_indices[0]\n            # Convert index back to time t. Index k corresponds to t = k + w.\n            tau = first_idx + w\n        else:\n            # If condition is never met, stop at T_max\n            tau = T_max\n\n        # Step 3d: Compare tau with t_star and update counters\n        if tau  t_star:\n            premature_count += 1\n        elif tau > t_star:\n            delayed_count += 1\n\n    # Step 4: Calculate risks\n    premature_risk = premature_count / M\n    delayed_risk = delayed_count / M\n\n    return premature_risk, delayed_risk\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "3136544"}]}