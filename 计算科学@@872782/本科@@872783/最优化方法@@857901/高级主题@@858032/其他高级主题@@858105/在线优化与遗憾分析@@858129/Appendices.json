{"hands_on_practices": [{"introduction": "理论的基石是在实践中奠定的。这个练习将带你深入了解在线凸优化的核心算法——在线次梯度下降法（Online Subgradient Descent）。你将有机会亲手推导其著名的 $O(\\sqrt{T})$ 懊悔上界，并通过编程实现该算法，直观地验证理论保证在不同数值情景下的表现。[@problem_id:3188888]", "problem": "考虑在线凸优化（Online Convex Optimization, OCO）的设定。设决策集为以原点为中心、半径为 $R  0$ 的闭欧几里得球 $\\mathcal{X} = \\{x \\in \\mathbb{R}^d : \\lVert x \\rVert_2 \\le R\\}$。在每一轮 $t \\in \\{1,2,\\dots,T\\}$ 中，在线学习器选择一个点 $x_t \\in \\mathcal{X}$，之后对手揭示一个凸损失函数 $f_t : \\mathcal{X} \\to \\mathbb{R}$。该函数关于欧几里得范数是 $G$-Lipschitz 的，即对所有 $x \\in \\mathcal{X}$，每个次梯度 $g_t \\in \\partial f_t(x)$ 都满足 $\\lVert g_t \\rVert_2 \\le G$，其中 $G  0$。学习器产生损失 $f_t(x_t)$。经过 $T$ 轮后的累积懊悔定义为\n$$\n\\mathrm{Regret}_T \\triangleq \\sum_{t=1}^T f_t(x_t) - \\min_{x \\in \\mathcal{X}} \\sum_{t=1}^T f_t(x).\n$$\n学习器使用在线次梯度下降法（也称为投影次梯度下降法）：从 $x_1 = 0$ 开始，对于选定的步长 $\\eta  0$，更新规则为\n$$\nx_{t+1} = \\Pi_{\\mathcal{X}}\\big(x_t - \\eta \\, g_t\\big),\n$$\n其中 $g_t \\in \\partial f_t(x_t)$ 是在 $x_t$ 处的次梯度，$\\Pi_{\\mathcal{X}}$ 表示到 $\\mathcal{X}$ 上的欧几里得投影。\n\n任务：\n1) 从凸性、次梯度和欧几里得投影的定义出发，推导出一个关于 $\\mathrm{Regret}_T$ 的非渐近上界。该上界应表现出对 $T$ 的次线性依赖关系，并假设你选择一个常数步长 $\\eta$，该步长是 $R$、$G$ 和 $T$ 的函数。你的推导必须仅依赖于基本事实：凸函数的次梯度不等式、欧几里得投影的非扩张性以及初等代数恒等式。你的最终上界必须用 $R$、$G$ 和 $T$ 明确表示，并且其尺度应为 $O(\\sqrt{T})$。\n\n2) 实现一个程序，该程序在一个形式为 $f_t(x) = g_t^\\top x$ 且 $\\lVert g_t \\rVert_2 \\le G$ 的合成线性损失族上实例化上述算法，并通过多个测试用例在数值上验证观测到的懊悔受你推导的理论上界的约束。对于线性损失，你必须通过欧几里得球上最小化问题的闭式解来精确计算比较基准 $\\arg\\min_{x \\in \\mathcal{X}} \\sum_{t=1}^T f_t(x)$，从而计算出确切的懊悔。使用你在任务1中选择的常数步长 $\\eta$。\n\n使用以下测试套件。在每个案例中，常数 $G$ 表示 $g_t$ 的范数界，维度是 $d$，时间范围是 $T$，球半径是 $R$。所有随机数生成必须使用给定的种子来保证可复现性，并且每个生成的 $g_t$ 都必须满足 $\\lVert g_t \\rVert_2 = G$。\n\n- 案例 A (理想路径，随机化): $d = 5$, $R = 3.0$, $G = 2.0$, $T = 400$。通过从均值为零、独立分量方差为 1 的正态分布中采样来生成每个 $g_t$，然后归一化为单位欧几里得范数，并缩放至范数 $G$。对随机数生成器使用种子 $0$。\n\n- 案例 B (边界，单步): $d = 3$, $R = 1.0$, $G = 1.0$, $T = 1$。使用确定性次梯度 $g_1 = G \\cdot e_1$，其中 $e_1$ 是 $\\mathbb{R}^d$ 中的第一个标准基向量。\n\n- 案例 C (对抗性，方向跟随迭代点): $d = 7$, $R = 2.0$, $G = 1.5$, $T = 600$。对于 $t \\ge 1$，定义 $g_t = G \\cdot \\frac{x_t}{\\max(\\lVert x_t \\rVert_2, 10^{-12})}$，并约定如果 $\\lVert x_t \\rVert_2 = 0$，则 $g_t = G \\cdot e_1$。\n\n- 案例 D (交替固定方向，近似抵消的和): $d = 10$, $R = 2.0$, $G = 3.0$, $T = 2500$。使用种子 $42$，从均值为零、独立分量方差为 1 的正态分布中抽取一个固定的非零向量 $u \\in \\mathbb{R}^d$，然后设置 $u \\leftarrow u / \\lVert u \\rVert_2$。对于奇数 $t$，设置 $g_t = G u$；对于偶数 $t$，设置 $g_t = -G u$。\n\n- 案例 E (强梯度，频繁投影到边界): $d = 2$, $R = 0.5$, $G = 10.0$, $T = 200$。完全按照案例 A 的方式生成每个 $g_t$，使用种子 $123$。\n\n对于每个案例，使用 $x_1 = 0$ 和你的常数步长 $\\eta$ 运行在线次梯度下降法，计算确切的懊悔 $\\mathrm{Regret}_T$，并将其与你得到的关于 $R$、$G$ 和 $T$ 的显式上界函数进行比较。当且仅当 $\\mathrm{Regret}_T \\le \\text{Bound}(R,G,T) + \\varepsilon$（其中 $\\varepsilon = 10^{-9}$）时，确定一个布尔结果为真。\n\n最终输出格式要求：你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，“[result1,result2,result3]”），其中每个结果是按 A、B、C、D、E 顺序排列的相应案例的布尔值。不允许有其他输出。", "solution": "为在线次梯度下降算法推导懊悔界是在线凸优化分析中的一个标准任务。该问题陈述是有效的，因为它在科学上基于已建立的优化理论，问题提法是适定的，并且是客观的。我们着手处理这两个任务。\n\n### 任务1：懊悔界的推导\n\n我们的目标是推导懊悔的上界，其定义为 $\\mathrm{Regret}_T \\triangleq \\sum_{t=1}^T f_t(x_t) - \\min_{x \\in \\mathcal{X}} \\sum_{t=1}^T f_t(x)$。令 $x^* = \\arg\\min_{x \\in \\mathcal{X}} \\sum_{t=1}^T f_t(x)$ 为一个事后最优解。由于每个 $f_t$ 都是凸函数，它们的和也是凸函数。又因为定义域 $\\mathcal{X}$ 是紧集，所以这样的最小化子 $x^*$ 保证存在。懊悔可以重写为 $\\mathrm{Regret}_T = \\sum_{t=1}^T f_t(x_t) - \\sum_{t=1}^T f_t(x^*)$。\n\n推导过程依赖于三个基本性质：\n1.  **次梯度不等式：** 对于一个凸函数 $f_t$ 和任意次梯度 $g_t \\in \\partial f_t(x_t)$，我们有 $f_t(x_t) - f_t(x^*) \\le g_t^\\top(x_t - x^*)$。\n2.  **投影性质：** 欧几里得投影算子 $\\Pi_{\\mathcal{X}}$ 是非扩张的。其一个关键推论是，对于任何 $y \\in \\mathbb{R}^d$ 和任何 $z \\in \\mathcal{X}$，有 $\\lVert \\Pi_{\\mathcal{X}}(y) - z \\rVert_2^2 \\le \\lVert y - z \\rVert_2^2$。\n3.  **Lipschitz 条件：** 损失函数是 $G$-Lipschitz 的，这意味着任何次梯度 $g_t \\in \\partial f_t(x)$ 的欧几里得范数有界，即 $\\lVert g_t \\rVert_2 \\le G$。\n\n我们来分析迭代点 $x_t$ 与固定最优解 $x^*$ 之间的距离。更新规则是 $x_{t+1} = \\Pi_{\\mathcal{X}}(x_t - \\eta g_t)$。考虑平方欧几里得距离 $\\lVert x_{t+1} - x^* \\rVert_2^2$。由于 $x^* \\in \\mathcal{X}$，我们可以应用投影性质：\n$$\n\\lVert x_{t+1} - x^* \\rVert_2^2 = \\lVert \\Pi_{\\mathcal{X}}(x_t - \\eta g_t) - x^* \\rVert_2^2 \\le \\lVert (x_t - \\eta g_t) - x^* \\rVert_2^2\n$$\n使用恒等式 $\\lVert a - b \\rVert_2^2 = \\lVert a \\rVert_2^2 - 2a^\\top b + \\lVert b \\rVert_2^2$ 展开右侧项：\n$$\n\\lVert (x_t - x^*) - \\eta g_t \\rVert_2^2 = \\lVert x_t - x^* \\rVert_2^2 - 2\\eta g_t^\\top(x_t - x^*) + \\eta^2 \\lVert g_t \\rVert_2^2\n$$\n结合这些不等式，我们得到：\n$$\n\\lVert x_{t+1} - x^* \\rVert_2^2 \\le \\lVert x_t - x^* \\rVert_2^2 - 2\\eta g_t^\\top(x_t - x^*) + \\eta^2 \\lVert g_t \\rVert_2^2\n$$\n这个不等式是分析的核心。我们将其重新整理，以分离出在次梯度不等式中出现的项 $g_t^\\top(x_t - x^*)$：\n$$\n2\\eta g_t^\\top(x_t - x^*) \\le \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 + \\eta^2 \\lVert g_t \\rVert_2^2\n$$\n两边同除以 $2\\eta$ (因为 $\\eta  0$)：\n$$\ng_t^\\top(x_t - x^*) \\le \\frac{1}{2\\eta} \\left( \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 \\right) + \\frac{\\eta}{2} \\lVert g_t \\rVert_2^2\n$$\n现在，我们应用次梯度不等式 $f_t(x_t) - f_t(x^*) \\le g_t^\\top(x_t - x^*)$ 来界定每轮的懊悔：\n$$\nf_t(x_t) - f_t(x^*) \\le \\frac{1}{2\\eta} \\left( \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 \\right) + \\frac{\\eta}{2} \\lVert g_t \\rVert_2^2\n$$\n为了得到总懊悔，我们将这个不等式从 $t=1$ 到 $T$ 进行求和：\n$$\n\\sum_{t=1}^T (f_t(x_t) - f_t(x^*)) \\le \\sum_{t=1}^T \\left[ \\frac{1}{2\\eta} \\left( \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 \\right) + \\frac{\\eta}{2} \\lVert g_t \\rVert_2^2 \\right]\n$$\n左边恰好是 $\\mathrm{Regret}_T$。右边可以分成两个和：\n$$\n\\mathrm{Regret}_T \\le \\frac{1}{2\\eta} \\sum_{t=1}^T \\left( \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 \\right) + \\frac{\\eta}{2} \\sum_{t=1}^T \\lVert g_t \\rVert_2^2\n$$\n第一个求和项是一个伸缩级数：\n$$\n\\sum_{t=1}^T \\left( \\lVert x_t - x^* \\rVert_2^2 - \\lVert x_{t+1} - x^* \\rVert_2^2 \\right) = (\\lVert x_1 - x^* \\rVert_2^2 - \\lVert x_2 - x^* \\rVert_2^2) + \\dots + (\\lVert x_T - x^* \\rVert_2^2 - \\lVert x_{T+1} - x^* \\rVert_2^2) = \\lVert x_1 - x^* \\rVert_2^2 - \\lVert x_{T+1} - x^* \\rVert_2^2\n$$\n由于 $\\lVert x_{T+1} - x^* \\rVert_2^2 \\ge 0$，我们可以用 $\\lVert x_1 - x^* \\rVert_2^2$ 来作为这个伸缩级数的上界。\n懊悔界变为：\n$$\n\\mathrm{Regret}_T \\le \\frac{1}{2\\eta} \\lVert x_1 - x^* \\rVert_2^2 + \\frac{\\eta}{2} \\sum_{t=1}^T \\lVert g_t \\rVert_2^2\n$$\n现在我们使用题目中的具体条件。初始点是 $x_1 = 0$。比较基准 $x^*$ 位于决策集 $\\mathcal{X} = \\{x \\in \\mathbb{R}^d : \\lVert x \\rVert_2 \\le R\\}$ 中，所以 $\\lVert x^* \\rVert_2 \\le R$。因此，$\\lVert x_1 - x^* \\rVert_2^2 = \\lVert 0 - x^* \\rVert_2^2 = \\lVert x^* \\rVert_2^2 \\le R^2$。次梯度的界为 $G$，所以对所有的 $t$ 都有 $\\lVert g_t \\rVert_2^2 \\le G^2$。代入这些条件得到：\n$$\n\\mathrm{Regret}_T \\le \\frac{R^2}{2\\eta} + \\frac{\\eta T G^2}{2}\n$$\n这个界对任何常数步长 $\\eta  0$ 都成立。为了实现关于 $T$ 的次线性懊悔，我们必须选择 $\\eta$ 作为 $T$ 的函数。我们选择 $\\eta$ 来最小化这个上界。令 $B(\\eta) = \\frac{R^2}{2\\eta} + \\frac{\\eta T G^2}{2}$。我们通过将其关于 $\\eta$ 的导数设为零来找到最小值：\n$$\n\\frac{dB}{d\\eta} = -\\frac{R^2}{2\\eta^2} + \\frac{TG^2}{2} = 0 \\implies \\eta^2 = \\frac{R^2}{TG^2} \\implies \\eta = \\frac{R}{G\\sqrt{T}}\n$$\n将这个最优常数步长代回到懊悔界中：\n$$\n\\mathrm{Regret}_T \\le \\frac{R^2}{2} \\left( \\frac{G\\sqrt{T}}{R} \\right) + \\frac{T G^2}{2} \\left( \\frac{R}{G\\sqrt{T}} \\right) = \\frac{RG\\sqrt{T}}{2} + \\frac{RG\\sqrt{T}}{2} = RG\\sqrt{T}\n$$\n因此，懊悔的一个非渐近上界是 $\\mathrm{Regret}_T \\le RG\\sqrt{T}$。这个界展示了所要求的对时间范围 $T$ 的次线性 $O(\\sqrt{T})$ 依赖关系。对于我们的数值验证，我们将使用步长 $\\eta = \\frac{R}{G\\sqrt{T}}$ 和上界 $\\mathrm{Bound}(R, G, T) = RG\\sqrt{T}$。\n\n### 任务2：实现与数值验证\n\n实现遵循在线次梯度下降算法。对于每个测试用例，我们使用指定的参数和次梯度生成规则来模拟在线学习过程的 $T$ 轮。我们计算确切的懊悔，并验证它小于或等于推导出的理论上界 $RG\\sqrt{T}$ 加上一个小的容差 $\\varepsilon = 10^{-9}$。\n\n对于线性损失 $f_t(x) = g_t^\\top x$，累积损失为 $\\sum_{t=1}^T f_t(x) = (\\sum_{t=1}^T g_t)^\\top x$。比较基准的累积损失是 $\\min_{x \\in \\mathcal{X}} (\\sum_{t=1}^T g_t)^\\top x$。令 $S = \\sum_{t=1}^T g_t$。我们希望在 $\\lVert x \\rVert_2 \\le R$ 的约束下最小化 $S^\\top x$。当 $x$ 的方向与 $S$ 相反且位于球的边界上时，达到最小值。最小化子是 $x^* = -R \\frac{S}{\\lVert S \\rVert_2}$ (如果 $S \\neq 0$)。最小损失是 $S^\\top x^* = -R \\frac{S^\\top S}{\\lVert S \\rVert_2} = -R \\lVert S \\rVert_2$。如果 $S=0$，则任何 $x \\in \\mathcal{X}$ 都是最小化子，最小损失为 $0$。\n\n以下代码为所有测试用例实现了此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_simulation(d: int, R: float, G: float, T: int, case: str, seed: int | None) - bool:\n    \"\"\"\n    Runs one instance of the Online Subgradient Descent simulation.\n\n    Args:\n        d: Dimension of the space.\n        R: Radius of the Euclidean ball.\n        G: Lipschitz constant (norm bound on subgradients).\n        T: Time horizon (number of rounds).\n        case: A string identifying the test case ('A', 'B', 'C', 'D', 'E').\n        seed: Random seed for reproducibility.\n\n    Returns:\n        A boolean indicating if the observed regret is within the theoretical bound.\n    \"\"\"\n    if seed is not None:\n        rng = np.random.default_rng(seed)\n\n    # Optimal constant step size from the theoretical derivation\n    if T  0:\n        eta = R / (G * np.sqrt(T))\n    else: # Handle T=0 case, though not in test suite.\n        eta = 0.0\n\n    # Initialization\n    x = np.zeros(d)  # Initial iterate x_1 = 0\n    learner_loss = 0.0\n    sum_g = np.zeros(d)\n\n    # Pre-computation for case D\n    if case == 'D':\n        u_vec = rng.normal(size=d)\n        u_norm = np.linalg.norm(u_vec)\n        if u_norm  1e-15:\n            u = u_vec / u_norm\n        else:  # Fallback for the highly unlikely event of a zero vector\n            u = np.zeros(d)\n            u[0] = 1.0\n\n    # Main OCO loop for T rounds\n    for t in range(1, T + 1):\n        # 1. Adversary reveals subgradient g_t at x_t (current x)\n        if case == 'A' or case == 'E':\n            g_vec = rng.normal(size=d)\n            g_norm = np.linalg.norm(g_vec)\n            if g_norm  1e-15:\n                g = G * g_vec / g_norm\n            else: # Fallback\n                g = np.zeros(d)\n                g[0] = G\n        elif case == 'B':\n            g = np.zeros(d)\n            g[0] = G\n        elif case == 'C':\n            x_norm = np.linalg.norm(x)\n            if x_norm == 0:  # Convention for x_t = 0\n                g = np.zeros(d)\n                g[0] = G\n            else:\n                g = G * x / max(x_norm, 1e-12)\n        elif case == 'D':\n            if t % 2 == 1:  # Odd t\n                g = G * u\n            else:  # Even t\n                g = -G * u\n        else:\n            raise ValueError(f\"Unknown case: {case}\")\n        \n        # 2. Learner incurs loss f_t(x_t) = g_t^T x_t\n        learner_loss += g @ x\n\n        # 3. Update sum of gradients for comparator calculation\n        sum_g += g\n\n        # 4. Learner computes next iterate x_{t+1}\n        # Unprojected update\n        y = x - eta * g\n        # Projection onto the Euclidean ball\n        y_norm = np.linalg.norm(y)\n        if y_norm  R:\n            x = R * y / y_norm\n        else:\n            x = y\n    \n    # After T rounds, calculate the exact regret\n    # 1. Calculate the comparator's total loss\n    sum_g_norm = np.linalg.norm(sum_g)\n    if sum_g_norm  1e-12:\n        # x_star = -R * sum_g / sum_g_norm\n        # comparator_loss = sum_g @ x_star = -R * ||sum_g||_2\n        comparator_loss = -R * sum_g_norm\n    else:\n        comparator_loss = 0.0\n\n    # 2. Compute the final regret\n    regret = learner_loss - comparator_loss\n\n    # 3. Compute the theoretical upper bound\n    bound = R * G * np.sqrt(T)\n    \n    # 4. Verify if regret is within the bound, with a small numerical tolerance\n    epsilon = 1e-9\n    return regret = bound + epsilon\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        {'d': 5, 'R': 3.0, 'G': 2.0, 'T': 400, 'case': 'A', 'seed': 0},\n        {'d': 3, 'R': 1.0, 'G': 1.0, 'T': 1, 'case': 'B', 'seed': None},\n        {'d': 7, 'R': 2.0, 'G': 1.5, 'T': 600, 'case': 'C', 'seed': None},\n        {'d': 10, 'R': 2.0, 'G': 3.0, 'T': 2500, 'case': 'D', 'seed': 42},\n        {'d': 2, 'R': 0.5, 'G': 10.0, 'T': 200, 'case': 'E', 'seed': 123},\n    ]\n\n    results = []\n    for params in test_cases:\n        is_bounded = run_simulation(**params)\n        results.append(is_bounded)\n\n    # Format the final output as a comma-separated list of booleans in lowercase.\n    # Python str(bool) gives 'True', 'False'; problem example is ambiguous.\n    # Standard practice often uses lowercase for JSON/API-style booleans.\n    # To be safe and explicit, we will use lowercase strings.\n    print(f\"[{','.join(map(lambda b: str(b).lower(), results))}]\")\n\nsolve()\n```", "id": "3188888"}, {"introduction": "虽然在线梯度下降法功能强大，但当决策空间具有特殊几何结构时，我们可以设计出更高效的算法。本练习将介绍镜像下降法（Mirror Descent），这是一种能够巧妙适应问题几何特性的通用框架。你将为概率单纯形（probability simplex）这一常见约束空间实现一个经典的镜像下降实例——指数梯度算法（Exponentiated Gradient algorithm），并体验其懊悔如何随时间演化。[@problem_id:3186873]", "problem": "要求您通过使用熵镜像映射的镜像下降法，为单纯形约束的优化问题实现随机梯度下降（SGD），并经验性地评估累积懊悔如何以 $\\mathcal{O}(\\sqrt{T})$ 的阶数进行扩展，其中 $T$ 是轮数。定义域为概率单纯形 $\\Delta^K = \\{x \\in \\mathbb{R}^K \\mid x_i \\ge 0, \\sum_{i=1}^K x_i = 1\\}$，其中 $K$ 是给定的维度。在每一轮 $t \\in \\{1,\\dots,T\\}$ 中，算法会选择一个点 $x_t \\in \\Delta^K$，然后产生一个随机线性损失 $f_t(x_t) = g_t^\\top x_t$，其中 $g_t \\in \\mathbb{R}^K$ 是一个坐标有界的随机向量。相对于 $\\Delta^K$ 中的最佳固定比较基准的累积懊悔定义为\n$$\nR_T = \\sum_{t=1}^T f_t(x_t) - \\min_{x \\in \\Delta^K} \\sum_{t=1}^T f_t(x).\n$$\n\n您将实现的程序必须使用带有熵镜像映射的镜像下降法。熵镜像映射通过负香农熵 $R(x) = \\sum_{i=1}^K x_i \\log x_i$ 定义，其关联的Bregman散度为 $D_R(y\\|x) = R(y) - R(x) - \\nabla R(x)^\\top (y - x)$。您的实现应执行由无偏梯度样本驱动的随机更新，并在每一轮都遵守单纯形约束。随机梯度样本 $g_t$ 必须从一个坐标有界的科学合理模型中生成。具体而言，对于每个测试用例，将 $g_t$ 构建为一个固定的基准成本向量 $c \\in [0,B]^K$ 加上附加零均值噪声后的裁剪版本，并将 $g_t$ 的每个坐标裁剪到区间 $[0,B]$ 以强制执行界限 $\\|g_t\\|_\\infty \\le B$，其中 $B  0$ 是给定的。初始点必须是 $\\Delta^K$ 上的均匀分布。\n\n您的任务是：\n- 根据上述规范，使用熵镜像映射和随机线性损失在 $\\Delta^K$ 上实现镜像下降算法，生成一个保持在 $\\Delta^K$ 内的序列 $\\{x_t\\}_{t=1}^T$。\n- 对于每个测试用例，计算相对于 $\\Delta^K$ 中最佳不动点的累积懊悔 $R_T$，然后用 $\\sqrt{T}$ 对其进行归一化，以获得量 $R_T / \\sqrt{T}$。\n- 使用提供的种子进行伪随机数生成，以确保确定性的可复现性。\n\n推导和实现的基本依据：\n- 损失函数 $f_t(x) = g_t^\\top x$ 的凸性以及概率单纯形 $\\Delta^K$ 的定义。\n- 镜像下降法的定义：它是一种优化方法，基于选定的严格凸正则化项 $R$ 进行迭代更新，并使用相应的Bregman散度 $D_R$。\n- 负香农熵作为 $\\Delta^K$ 上严格凸正则化项的性质。\n- 在线优化中累积懊悔 $R_T$ 的概念，以及在适当选择学习率和有界梯度的情况下其相对于 $T$ 的扩展性。\n\n测试套件规范：\n实现程序以运行以下 $5$ 个测试用例。在每个用例中，$K$ 是单纯形的维度，$T$ 是迭代次数，$B$ 是随机梯度坐标的上限，$\\sigma$ 是附加噪声的标准差，$c$ 是基准成本向量，$\\text{seed}$ 是伪随机种子。$c$ 的所有条目都在 $[0,B]$ 范围内。\n\n- 用例 $1$：$K=5$, $T=2000$, $B=1.0$, $\\sigma=0.2$, $c = [0.1, 0.2, 0.3, 0.4, 0.5]$, $\\text{seed}=42$。\n- 用例 $2$：$K=2$, $T=500$, $B=1.0$, $\\sigma=0.3$, $c = [0.0, 0.5]$, $\\text{seed}=7$。\n- 用例 $3$：$K=10$, $T=5000$, $B=2.0$, $\\sigma=0.5$, $c$ 是从 $0.1$ 到 $1.0$ 的长度为 $10$ 的等距向量, $\\text{seed}=17$。\n- 用例 $4$：$K=1$, $T=1000$, $B=1.0$, $\\sigma=0.1$, $c = [0.7]$, $\\text{seed}=99$。\n- 用例 $5$：$K=5$, $T=4000$, $B=1.0$, $\\sigma=0.2$, $c = [0.1, 0.2, 0.3, 0.4, 0.5]$, $\\text{seed}=123$。\n\n输出要求：\n您的程序应产生单行输出，其中包含 $5$ 个测试用例的归一化懊悔 $R_T / \\sqrt{T}$，格式为方括号括起来的逗号分隔列表（例如，$[r_1,r_2,r_3,r_4,r_5]$）。每个 $r_i$ 必须是实数（小数）。输出中不允许超出此单行的任何额外文本或格式。\n\n此问题不涉及物理单位。不使用角度。不要用百分号表示任何数量；需要时请使用小数。", "solution": "用户提供的问题陈述已经过验证，并被确定为是合理的、适定的和可形式化的。它描述了在线凸优化中的一个经典问题：在后见之明的情况下，最小化相对于静态专家的累积懊悔，其中决策空间是概率单纯形。\n\n问题是在概率单纯形 $\\Delta^K = \\{x \\in \\mathbb{R}^K \\mid x_i \\ge 0, \\sum_{i=1}^K x_i = 1\\}$ 上，为一系列线性损失函数实现随机镜像下降算法。在每个时间步 $t \\in \\{1, \\dots, T\\}$，算法选择一个点 $x_t \\in \\Delta^K$ 并产生损失 $f_t(x_t) = g_t^\\top x_t$，其中 $g_t$ 是一个随机梯度。目标是计算归一化的累积懊悔 $R_T / \\sqrt{T}$，其中 $R_T = \\sum_{t=1}^T f_t(x_t) - \\min_{x \\in \\Delta^K} \\sum_{t=1}^T f_t(x)$。\n\n解决方案的核心是镜像下降更新规则。这是一种推广了标准梯度下降的迭代优化方法。从 $x_t$ 到 $x_{t+1}$ 的更新由下式给出：\n$$\nx_{t+1} = \\arg\\min_{x \\in \\Delta^K} \\left\\{ \\eta_t g_t^\\top x + D_R(x \\| x_t) \\right\\}\n$$\n其中 $\\eta_t$ 是学习率，$g_t = \\nabla f_t(x_t)$ 是损失函数的梯度，$D_R(y \\| x)$ 是与严格凸正则化函数 $R(x)$ 相关的Bregman散度。\n\n对于此问题，正则化项是在单纯形内部定义的负香农熵：\n$$\nR(x) = \\sum_{i=1}^K x_i \\log x_i\n$$\n该正则化项的梯度为 $\\nabla R(x)$，其分量为 $(\\nabla R(x))_i = \\log x_i + 1$。Bregman散度为 $D_R(y \\| x) = R(y) - R(x) - \\nabla R(x)^\\top (y - x)$。\n\n将这些代入更新规则，并省略相对于最小化变量 $x$ 的常数项，更新步骤变为：\n$$\nx_{t+1} = \\arg\\min_{x \\in \\Delta^K} \\left\\{ \\eta_t g_t^\\top x + R(x) - (\\nabla R(x_t))^\\top x \\right\\}\n$$\n$$\nx_{t+1} = \\arg\\min_{x \\in \\Delta^K} \\left\\{ \\sum_{i=1}^K \\eta_t (g_t)_i x_i + \\sum_{i=1}^K x_i \\log x_i - \\sum_{i=1}^K (\\log (x_t)_i + 1) x_i \\right\\}\n$$\n这是一个在单纯形上的凸优化问题。针对约束 $\\sum_i x_i = 1$ 引入拉格朗日乘子 $\\lambda$，一阶最优性条件为每个分量 $(x_{t+1})_i$ 产生一个闭式解：\n$$\n(x_{t+1})_i = \\frac{(x_t)_i \\exp(-\\eta_t (g_t)_i)}{\\sum_{j=1}^K (x_t)_j \\exp(-\\eta_t (g_t)_j)}\n$$\n这个更新规则被称为指数梯度算法。它确保如果 $x_t \\in \\Delta^K$，那么 $x_{t+1}$ 也位于 $\\Delta^K$ 中。初始点是单纯形的中心 $x_1$，其中对于所有 $i \\in \\{1, \\dots, K\\}$，$(x_1)_i = 1/K$。\n\n学习率的选择对于实现期望的 $\\mathcal{O}(\\sqrt{T})$ 懊悔扩展性至关重要。对于坐标有界（即 $\\|g_t\\|_\\infty \\le B$）的梯度的在线镜像下降，理论懊悔界由下式给出：\n$$\nR_T \\le \\frac{D_{R, \\text{max}}}{\\eta} + \\frac{\\eta}{2} \\sum_{t=1}^T \\|g_t\\|_*^2\n$$\n对于熵正则化项，相关范围是 $D_{R, \\text{max}} = \\max_{x \\in \\Delta^K} R(x) - \\min_{x \\in \\Delta^K} R(x) = 0 - (-\\log K) = \\log K$。针对此设置使用更具体的界限和固定的学习率 $\\eta$，累积懊悔的界限为 $R_T \\le \\frac{\\log K}{\\eta} + \\frac{\\eta T B^2}{2}$。为了最小化这个上界，我们选择 $\\eta$ 来平衡这两项：\n$$\n\\frac{\\log K}{\\eta} = \\frac{\\eta T B^2}{2} \\implies \\eta^2 = \\frac{2 \\log K}{T B^2} \\implies \\eta = \\frac{\\sqrt{2 \\log K}}{B \\sqrt{T}}\n$$\n使用这个固定的学习率，懊悔的界限为 $R_T \\le B\\sqrt{2T\\log K}$，这表现出所需的 $\\mathcal{O}(\\sqrt{T})$ 扩展性。实现将使用这个有理论依据的学习率。对于 $K=1$ 的特殊情况，$\\log K = 0$，因此 $\\eta=0$，这意味着点永远不会离开其初始状态，这是正确的，因为 $\\Delta^1$ 是一个单点。\n\n对于给定的测试用例及其参数 $K, T, B, \\sigma, c, \\text{seed}$，总体算法如下：\n1.  用给定的 `seed` 初始化伪随机数生成器。\n2.  初始化点 $x_1$，其中对于 $i=1, \\dots, K$，$(x_1)_i = 1/K$。\n3.  计算学习率 $\\eta = \\frac{\\sqrt{2 \\log K}}{B \\sqrt{T}}$。\n4.  初始化总算法损失 $\\mathcal{L}_{alg} = 0$ 和总梯度和向量 $G_T = \\mathbf{0} \\in \\mathbb{R}^K$。\n5.  对于 $t=1, \\dots, T$ 进行迭代：\n    a. 生成随机梯度 $g_t$：创建一个噪声向量 $\\epsilon_t$，其分量从正态分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取，然后设置 $g_t = \\text{clip}(c + \\epsilon_t, 0, B)$。\n    b. 产生当前轮次的损失：$l_t = g_t^\\top x_t$。\n    c. 更新总损失：$\\mathcal{L}_{alg} = \\mathcal{L}_{alg} + l_t$。\n    d. 更新总梯度和：$G_T = G_T + g_t$。\n    e. 使用指数梯度更新规则和学习率 $\\eta$ 计算下一个点 $x_{t+1}$。\n6.  循环结束后，计算后见之明中最佳不动点的损失。这是单纯形上线性函数的最小值，该最小值必然出现在某个顶点上：$\\mathcal{L}_{opt} = \\min_{x \\in \\Delta^K} G_T^\\top x = \\min_{i \\in \\{1,\\dots,K\\}} (G_T)_i$。\n7.  计算累积懊悔 $R_T = \\mathcal{L}_{alg} - \\mathcal{L}_{opt}$。\n8.  计算归一化懊悔 $r = R_T / \\sqrt{T}$。\n\n此过程将应用于所有 $5$ 个测试用例以生成最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements Stochastic Mirror Descent with an entropic regularizer (Exponentiated Gradient)\n    on the probability simplex to calculate normalized cumulative regret for several test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'K': 5, 'T': 2000, 'B': 1.0, 'sigma': 0.2, 'c': np.array([0.1, 0.2, 0.3, 0.4, 0.5]), 'seed': 42},\n        {'K': 2, 'T': 500, 'B': 1.0, 'sigma': 0.3, 'c': np.array([0.0, 0.5]), 'seed': 7},\n        {'K': 10, 'T': 5000, 'B': 2.0, 'sigma': 0.5, 'c': np.linspace(0.1, 1.0, 10), 'seed': 17},\n        {'K': 1, 'T': 1000, 'B': 1.0, 'sigma': 0.1, 'c': np.array([0.7]), 'seed': 99},\n        {'K': 5, 'T': 4000, 'B': 1.0, 'sigma': 0.2, 'c': np.array([0.1, 0.2, 0.3, 0.4, 0.5]), 'seed': 123},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        K = case['K']\n        T = case['T']\n        B = case['B']\n        sigma = case['sigma']\n        c = case['c']\n        seed = case['seed']\n\n        rng = np.random.default_rng(seed)\n\n        # Handle the trivial case K=1\n        if K == 1:\n            results.append(0.0)\n            continue\n            \n        # 1. Initialize point x_1 at the center of the simplex\n        x = np.ones(K) / K\n        \n        # 2. Calculate the theoretically optimal fixed learning rate eta\n        eta = np.sqrt(2 * np.log(K) / (T * B**2))\n\n        # 3. Initialize tracking variables\n        total_algorithm_loss = 0.0\n        total_gradient_sum = np.zeros(K)\n\n        # 4. Main loop for T rounds\n        for t in range(T):\n            # a. Generate stochastic gradient g_t\n            noise = rng.normal(0, sigma, size=K)\n            g_t = np.clip(c + noise, 0, B)\n\n            # b. Incur loss and update total loss\n            loss_t = np.dot(g_t, x)\n            total_algorithm_loss += loss_t\n\n            # c. Update total gradient sum\n            total_gradient_sum += g_t\n            \n            # d. Update point x_t to x_{t+1} using Exponentiated Gradient rule\n            # Numerically stable implementation: find max_val and subtract it inside exp\n            # This does not change the result due to normalization.\n            unnormalized_weights = x * np.exp(-eta * g_t)\n            # The check for sum being zero is for extreme cases, very unlikely here.\n            norm_factor = np.sum(unnormalized_weights)\n            if norm_factor  0:\n                x = unnormalized_weights / norm_factor\n            else:\n                # If all weights become numerically zero, reset to uniform.\n                # This is a safeguard and shouldn't be hit with the chosen eta.\n                x = np.ones(K) / K\n\n        # 5. Calculate loss of the best fixed point in hindsight\n        # This is min_{x in Delta^K} (sum g_t)^T x = min_i (sum_t g_t)_i\n        best_fixed_loss = np.min(total_gradient_sum)\n\n        # 6. Compute cumulative regret\n        regret = total_algorithm_loss - best_fixed_loss\n\n        # 7. Normalize regret and store the result\n        normalized_regret = regret / np.sqrt(T)\n        results.append(normalized_regret)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```", "id": "3186873"}]}