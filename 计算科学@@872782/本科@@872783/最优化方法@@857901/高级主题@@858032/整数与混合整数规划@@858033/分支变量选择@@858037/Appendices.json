{"hands_on_practices": [{"introduction": "在分支定界法中，一个常见的直觉是优先选择对目标函数影响最大的变量进行分支。然而，这种简单的启发式方法有时会产生误导。一个变量的重要性不仅取决于它在目标函数中的系数，更关键的是它如何通过约束与其他变量相互作用。\n\n这个练习 [@problem_id:3104763] 将通过一个精心设计的计算实例，揭示一个反直觉的现象。你将分析一个目标函数系数很小的变量，并发现对它进行分支竟能带来巨大的边界改进。这旨在培养一种超越表面指标、深入分析约束结构的思维方式，这对于设计高效的求解策略至关重要。", "problem": "考虑以下最大化问题的一个混合整数线性规划 (MILP)，其二元决策变量为 $x_1$、$x_2$ 和 $x_3$：\n最大化 $8 x_1 + 7 x_2 + 0.1 x_3$\n约束条件为\n$2 x_1 + 2 x_2 + 3 x_3 \\le 4$，\n$x_1 + x_2 - x_3 \\le 1$，\n$0 \\le x_i \\le 1$，对于 $i \\in \\{1,2,3\\}$，\n$x_i \\in \\{0,1\\}$，对于 $i \\in \\{1,2,3\\}$。\n\n在分支定界 (B&B) 树的根节点处，使用线性规划 (LP) 松弛，即去掉整数性要求 $x_i \\in \\{0,1\\}$，只保留 $0 \\le x_i \\le 1$。令 $z_{\\text{parent}}$ 表示根节点处的最优 LP 目标值。考虑在根节点上对变量 $x_3$ 进行分支，分别创建两个子节点，对应 $x_3 = 0$ 和 $x_3 = 1$。令 $z_0$ 和 $z_1$ 分别表示这两个子节点的最优 LP 目标值。\n\n将对 $x_3$ 分支所带来的平均界限改进量定义为\n$\\Delta_{\\text{avg}} = \\dfrac{\\left(z_{\\text{parent}} - z_0\\right) + \\left(z_{\\text{parent}} - z_1\\right)}{2}$。\n计算此实例的 $\\Delta_{\\text{avg}}$。然后，在您的解答中，通过引用约束条件与 $x_3$ 的相互作用方式，解释为什么对 $x_3$ (其目标系数 $0.1$ 很小) 进行分支，却能产生一个大的平均界限改进量。\n\n将 $\\Delta_{\\text{avg}}$ 的最终数值四舍五入到 $3$ 位有效数字。最终答案中不需要也不允许使用单位。", "solution": "我们从混合整数优化中的基本定义开始：混合整数线性规划 (MILP) 的线性规划 (LP) 松弛为最大化问题中的真实最优值提供了一个上界，而分支定界 (B&B) 中对变量进行分支会将可行域分割成不相交的子问题，从而可以收紧这个界限。分支处的界限改进量是通过 LP 上界相对于父节点的减少量来衡量的。我们将计算父节点 LP 界限 $z_{\\text{parent}}$、子节点 LP 界限 $z_0$ 和 $z_1$，然后计算平均界限改进量 $\\Delta_{\\text{avg}}$。\n\n步骤 $1$：求解根节点的 LP 松弛。根节点的 LP 松弛问题为\n最大化 $8 x_1 + 7 x_2 + 0.1 x_3$\n约束条件为\n$2 x_1 + 2 x_2 + 3 x_3 \\le 4$，\n$x_1 + x_2 - x_3 \\le 1$，\n$0 \\le x_i \\le 1$，对于 $i \\in \\{1,2,3\\}$。\n\n引入聚合变量 $s = x_1 + x_2$。约束条件变为\n$2 s + 3 x_3 \\le 4$，\n$s \\le 1 + x_3$，\n$0 \\le s \\le 2$，\n$0 \\le x_3 \\le 1$，\n目标函数变为 $8 x_1 + 7 x_2 + 0.1 x_3$。对于固定的 $s$，通过将 $s$ 尽可能多地分配给系数较大的变量，可以最大化表达式 $8 x_1 + 7 x_2$。因此，最优分配为\n如果 $s \\le 1$，设 $x_1 = s$，$x_2 = 0$，得到 $8 x_1 + 7 x_2 = 8 s$，\n如果 $1 \\le s \\le 2$，设 $x_1 = 1$，$x_2 = s - 1$，得到 $8 x_1 + 7 x_2 = 7 s + 1$。\n\n因此，目标函数变为\n$O(s,x_3) = \\begin{cases}\n8 s + 0.1 x_3,  & 0 \\le s \\le 1, \\\\\n7 s + 1 + 0.1 x_3,  & 1 \\le s \\le 2,\n\\end{cases}$\n约束条件为\n$s \\le \\min\\{2 - 1.5 x_3, 1 + x_3\\}$，\n$0 \\le x_3 \\le 1$。\n\n对于每个 $x_3$，最优的 $s$ 是最大可行 $s$，因为 $O(s,x_3)$ 在两种情况下都是关于 $s$ 递增的。比较两个上界：\n$2 - 1.5 x_3 \\le 1 + x_3$ 在 $1 - 2.5 x_3 \\le 0$ 时成立，即 $x_3 \\ge 0.4$。\n因此，\n对于 $0 \\le x_3 \\le 0.4$，更紧的约束是 $s \\le 1 + x_3$，所以选择 $s = 1 + x_3$，\n对于 $0.4 \\le x_3 \\le 1$，更紧的约束是 $s \\le 2 - 1.5 x_3$，所以选择 $s = 2 - 1.5 x_3$。\n\n情况 $1$：$0 \\le x_3 \\le 0.4$。此时 $s = 1 + x_3 \\in [1,1.4]$，所以我们处于 $1 \\le s \\le 2$ 的情况，并且\n$O(x_3) = 7 s + 1 + 0.1 x_3 = 7(1 + x_3) + 1 + 0.1 x_3 = 8 + 7.1 x_3$，\n该函数关于 $x_3$ 递增，因此在这种情况下，最大值在 $x_3 = 0.4$ 处取得。\n\n情况 $2$：$0.4 \\le x_3 \\le 1$。此时 $s = 2 - 1.5 x_3$。根据 $s \\ge 1$ 是否成立，存在两种子情况。\n子情况 $2\\text{a}$：$0.4 \\le x_3 \\le \\tfrac{2}{3}$。此时 $s \\ge 1$，所以\n$O(x_3) = 7 s + 1 + 0.1 x_3 = 7(2 - 1.5 x_3) + 1 + 0.1 x_3 = 15 - 10.4 x_3$，\n该函数关于 $x_3$ 递减，所以在此子区间上的最大值在 $x_3 = 0.4$ 处取得。\n子情况 $2\\text{b}$：$\\tfrac{2}{3} \\le x_3 \\le 1$。此时 $s \\le 1$，所以\n$O(x_3) = 8 s + 0.1 x_3 = 8(2 - 1.5 x_3) + 0.1 x_3 = 16 - 11.9 x_3$，\n该函数也关于 $x_3$ 递减，其最大值在 $x_3 = \\tfrac{2}{3}$ 处取得，但该值严格小于下面计算出的在 $x_3 = 0.4$ 处的值。\n\n因此，全局最大值点在边界 $x_3 = 0.4$ 处，对应的 $s = 1.4$。在 $1 \\le s \\le 2$ 的情况下，分配为 $x_1 = 1$，$x_2 = s - 1 = 0.4$。因此，根节点 LP 最优目标值为\n$z_{\\text{parent}} = 8 \\cdot 1 + 7 \\cdot 0.4 + 0.1 \\cdot 0.4 = 8 + 2.8 + 0.04 = 10.84$。\n\n步骤 $2$：求解对 $x_3$ 分支的两个子节点的 LP 松弛。\n\n$x_3 = 0$ 的子节点：\n约束条件变为 $2 x_1 + 2 x_2 \\le 4$ 和 $x_1 + x_2 \\le 1$。合并得到 $x_1 + x_2 \\le 1$。为最大化 $8 x_1 + 7 x_2$，设 $x_1 = 1$，$x_2 = 0$。该子节点的 LP 界限为\n$z_0 = 8 \\cdot 1 + 7 \\cdot 0 + 0.1 \\cdot 0 = 8$。\n\n$x_3 = 1$ 的子节点：\n约束条件变为 $2 x_1 + 2 x_2 + 3 \\le 4$，即 $x_1 + x_2 \\le 0.5$，以及 $x_1 + x_2 \\le 2$ (此处为非绑定约束)。为最大化 $8 x_1 + 7 x_2$，将全部的 $0.5$ 分配给 $x_1$：$x_1 = 0.5$，$x_2 = 0$。该子节点的 LP 界限为\n$z_1 = 8 \\cdot 0.5 + 7 \\cdot 0 + 0.1 \\cdot 1 = 4 + 0.1 = 4.1$。\n\n步骤 $3$：计算平均界限改进量。根据定义，\n$\\Delta_{\\text{avg}} = \\dfrac{\\left(z_{\\text{parent}} - z_0\\right) + \\left(z_{\\text{parent}} - z_1\\right)}{2}\n= \\dfrac{\\left(10.84 - 8\\right) + \\left(10.84 - 4.1\\right)}{2}\n= \\dfrac{2.84 + 6.74}{2}\n= \\dfrac{9.58}{2}\n= 4.79$。\n\n对此现象的解释和说明：尽管 $x_3$ 的目标系数很小（即 $0.1$），但附加约束 $x_1 + x_2 - x_3 \\le 1$ 将 $x_3$ 与高利润变量 $x_1$ 和 $x_2$ 紧密耦合。在根节点的 LP 松弛中，将 $x_3$ 增加 $\\Delta$ 会使和 $x_1 + x_2$ 最多增加 $\\Delta$，由于 $x_1$ 和 $x_2$ 的系数较大，这可以被用来将目标函数大约增加 $7 \\Delta$ 到 $8 \\Delta$。这就是为什么 LP 将 $x_3$ 设置为 $0.4$，尽管其直接贡献仅为 $0.04$。当我们对 $x_3$ 进行分支并强制 $x_3=0$ 或 $x_3=1$ 时，我们破坏了这种分数值的“促成”效应：当 $x_3=0$ 时，耦合约束将 $x_1+x_2$ 的上限定为 $1$；当 $x_3=1$ 时，背包约束 $2 x_1 + 2 x_2 + 3 x_3 \\le 4$ 将 $x_1+x_2$ 的上限定为 $0.5$。两个分支都严重降低了 LP 上界，从而产生了一个大的平均界限改进量 $\\Delta_{\\text{avg}} = 4.79$。这说明，当紧密的附加约束将一个变量与高利润变量强链接时，对该目标系数很小的变量进行分支，也可能带来出乎意料的强界限改进。", "answer": "$$\\boxed{4.79}$$", "id": "3104763"}, {"introduction": "线性规划松弛为我们提供了关于分支选择的宝贵信息，例如变量的“约化成本”（reduced cost）。通常认为，约化成本不为零的变量是更有潜力的分支候选，因为改变它们的值会直接影响目标函数。但如果一个变量的约化成本为零，是否意味着它就是一个糟糕的选择呢？\n\n这个练习 [@problem_id:3104676] 探讨了这一深刻问题。你将分析一个特殊构造的案例，其中一个约化成本为零的变量是最佳的分支选择。其关键在于“强推理”（strong inference）的概念：对该变量进行分支会触发一系列逻辑推导，立即确定其他所有变量的值，从而一步到位地关闭整数规划与线性松弛解之间的差距。这个练习强调了在选择分支变量时，理解问题的逻辑结构与利用对偶信息同样重要。", "problem": "考虑混合整数线性规划（MILP）问题\n$$\\min \\sum_{i=1}^{4} w_i x_i$$\n约束条件为\n$$x_i - y = 0 \\quad \\text{for } i \\in \\{1,2,3,4\\},$$\n$$x_1 + x_2 + x_3 + x_4 \\ge 3,$$\n$$x_i \\in \\{0,1\\} \\text{ for } i \\in \\{1,2,3,4\\}, \\quad 0 \\le y \\le 1,$$\n其中权重由下式给出\n$$w_1 = 3, \\quad w_2 = 5, \\quad w_3 = 7, \\quad w_4 = 11.$$\n\n本问题将通过分支定界法（B&B）中的分支变量选择视角进行分析，重点关注在强推理约束下，对零简约成本的变量进行分支可能有效的情况。使用线性规划（LP）对偶性和简约成本的基本概念：LP中一个变量的简约成本定义为 $r_j = c_j - a_j^{\\top} u$，其中 $c_j$ 是变量 $j$ 的目标系数，$a_j$ 是变量 $j$ 的约束系数列向量，$u$ 是对应约束的对偶价格向量。\n\n任务：\n1. 求解该MILP的LP松弛问题（即将 $x_i \\in \\{0,1\\}$ 替换为 $0 \\le x_i \\le 1$），并确定最优LP解 $(x_1,x_2,x_3,x_4,y)$ 和最优LP目标值。\n2. 使用LP基和简约成本的基本性质，证明变量 $y$ 在最优LP解处的简约成本为零。\n3. 在根节点对变量 $y$ 进行B&B分支。对于分支 $y=0$，推断其对 $(x_1,x_2,x_3,x_4)$ 的影响及可行性。对于分支 $y=1$，推断其对 $(x_1,x_2,x_3,x_4)$ 的影响并计算得到的LP界（目标值）。\n4. 将对 $y$ 进行分支所带来的直接下界改善定义为两个子节点LP界的最小值与根节点LP界之差。计算这个改善值，结果为一个实数。\n\n简要解释为什么这个构造表明，由于强的推理约束（等式 $x_i - y = 0$ 和覆盖约束 $x_1 + x_2 + x_3 + x_4 \\ge 3$），对一个零简约成本的变量进行分支可能出人意料地有效。你的最终答案必须是下界改善的数值。无需四舍五入。", "solution": "所给问题是一个混合整数线性规划（MILP）问题，定义如下：\n$$ \\min \\sum_{i=1}^{4} w_i x_i $$\n约束条件为\n$$ x_i - y = 0 \\quad \\text{for } i \\in \\{1,2,3,4\\} $$\n$$ x_1 + x_2 + x_3 + x_4 \\ge 3 $$\n$$ x_i \\in \\{0,1\\} \\text{ for } i \\in \\{1,2,3,4\\}, \\quad 0 \\le y \\le 1 $$\n权重为 $w_1 = 3$，$w_2 = 5$，$w_3 = 7$ 和 $w_4 = 11$。\n\n验证证实了该问题具有科学依据、提法恰当、目标明确，并包含所有必要信息。这是优化方法领域中的一个有效问题。我们开始求解。\n\n**1. LP松弛解**\n\n为了得到LP松弛，我们将整数约束 $x_i \\in \\{0,1\\}$ 替换为连续约束 $0 \\le x_i \\le 1$。问题变为：\n$$ \\min \\quad 3x_1 + 5x_2 + 7x_3 + 11x_4 $$\n约束条件为：\n$$ x_i - y = 0, \\quad i=1,2,3,4 $$\n$$ x_1 + x_2 + x_3 + x_4 \\ge 3 $$\n$$ 0 \\le x_i \\le 1, \\quad i=1,2,3,4 $$\n$$ 0 \\le y \\le 1 $$\n约束 $x_i - y = 0$ 意味着 $x_1 = x_2 = x_3 = x_4 = y$。我们可以在问题中用 $y$ 替换每个 $x_i$。目标函数变为：\n$$ \\min \\quad (3+5+7+11)y = 26y $$\n关于 $x_i$ 和 $y$ 的约束被简化。约束 $\\sum_{i=1}^{4} x_i \\ge 3$ 变为 $y+y+y+y \\ge 3$，即 $4y \\ge 3$，或 $y \\ge \\frac{3}{4}$。界限 $0 \\le x_i \\le 1$ 变为 $0 \\le y \\le 1$。$y$ 的界限本身也是 $0 \\le y \\le 1$。这些关于 $y$ 的约束的交集是 $\\frac{3}{4} \\le y \\le 1$。\n简化后的LP是：\n$$ \\min \\quad 26y $$\n$$ \\text{s.t.} \\quad \\frac{3}{4} \\le y \\le 1 $$\n为了最小化目标 $26y$，我们必须选择 $y$ 的最小可行值，即 $y^* = \\frac{3}{4}$。\n因此，LP松弛的最优解是：\n$$ y^* = \\frac{3}{4} $$\n$$ x_i^* = \\frac{3}{4} \\quad \\text{for } i \\in \\{1,2,3,4\\} $$\n最优LP目标值，它作为B&B树根节点的下界，是：\n$$ Z_{LP} = 26 \\times \\frac{3}{4} = \\frac{78}{4} = \\frac{39}{2} = 19.5 $$\n\n**2. y的零简约成本证明**\n\n根据定义，最优LP解的基中变量的简约成本为零。我们可以证明 $y$ 是一个基变量。在LP松弛中，所有变量 $x_1, x_2, x_3, x_4, y$ 的值都严格介于其下界和上界（$0$ 和 $1$）之间。在非退化的最优解中，不处于其界限上的变量必须是基变量。由于有五个变量（$x_1, x_2, x_3, x_4, y$）不处于其界限上，并且有五个等式约束（四个 $x_i-y=0$ 和一个处于激活状态的 $\\sum x_i \\ge 3$），这五个变量可以构成一个有效的基，从而证实它们是基变量。因为 $y$ 是一个基变量，所以其简约成本为 $0$。\n\n或者，我们可以使用简约成本的定义 $r_j = c_j - a_j^\\top u$ 和LP对偶性。设 $u_1, u_2, u_3, u_4$ 为约束 $x_i - y = 0$ 的对偶变量，设 $v \\ge 0$ 为约束 $\\sum x_i \\ge 3$ 的对偶变量。$y$ 的目标系数是 $c_y=0$。约束矩阵中 $y$ 对应的列是 $a_y = (-1, -1, -1, -1, 0)^\\top$。$y$ 的简约成本是：\n$$ r_y = c_y - \\begin{pmatrix} u_1 & u_2 & u_3 & u_4 & v \\end{pmatrix} \\begin{pmatrix} -1 \\\\ -1 \\\\ -1 \\\\ -1 \\\\ 0 \\end{pmatrix} = 0 - (-u_1 - u_2 - u_3 - u_4) = \\sum_{i=1}^{4} u_i $$\n根据互补松弛性，因为 $x_i^* = \\frac{3}{4} > 0$，所以每个 $x_i$ 对应的对偶约束必须是激活的：$u_i + v = w_i$。此外，强对偶性意味着原始目标值和对偶目标值相等：$3v = 19.5$，得出 $v = 6.5$。我们可以解出 $u_i$：\n$u_1 = w_1 - v = 3 - 6.5 = -3.5$\n$u_2 = w_2 - v = 5 - 6.5 = -1.5$\n$u_3 = w_3 - v = 7 - 6.5 = 0.5$\n$u_4 = w_4 - v = 11 - 6.5 = 4.5$\n总和为 $\\sum_{i=1}^{4} u_i = -3.5 - 1.5 + 0.5 + 4.5 = 0$。\n因此，$y$ 的简约成本为 $r_y = 0$。\n\n**3. 对变量y进行分支定界**\n\n我们通过从根节点创建两个子问题来进行分支，分别对应分支 $y=0$ 和 $y=1$。这是一个有效的分支，因为在任何整数可行解中，由于 $y$ 与二元变量 $x_i$ 的耦合关系，$y$ 的值最终必须为 $0$ 或 $1$。\n\n**分支 1：$y=0$**\n我们将约束 $y=0$ 添加到LP松弛问题中。\n约束 $x_i - y = 0$ 立即意味着对于所有 $i \\in \\{1,2,3,4\\}$，$x_i = 0$。\n我们根据覆盖约束检查可行性：\n$$ \\sum_{i=1}^{4} x_i = 0+0+0+0 = 0 $$\n约束 $\\sum x_i \\ge 3$ 变为 $0 \\ge 3$，这是一个矛盾。\n该分支是不可行的。此节点的下界为 $+\\infty$。该节点被剪枝。\n\n**分支 2：$y=1$**\n我们将约束 $y=1$ 添加到LP松弛问题中。\n约束 $x_i - y = 0$ 意味着对于所有 $i \\in \\{1,2,3,4\\}$，$x_i = 1$。\n我们检查可行性：\n- $x_i = 1$ 满足 $0 \\le x_i \\le 1$。\n- $y=1$ 满足 $0 \\le y \\le 1$。\n- 覆盖约束：$\\sum x_i = 1+1+1+1=4 \\ge 3$。该约束得到满足。\n这个分支只有一个可行点 $(x_1, x_2, x_3, x_4, y) = (1,1,1,1,1)$。这是一个整数可行解。\n该解的目标值即为此节点的LP界：\n$$ Z_{y=1} = 3(1) + 5(1) + 7(1) + 11(1) = 26 $$\n此节点产生了一个整数解，因此我们找到了该MILP的一个上界（$Z_{UB}=26$）。由于其LP解是整数，该节点被探明（剪枝）。\n\n**4. 下界改善**\n\n根节点的下界为 $Z_{LP} = 19.5$。\n对 $y$ 进行分支后，子节点的界分别为 $\\infty$ 和 $26$。新的全局下界是活动节点界的最小值。由于两个子节点都被剪枝，我们已经解决了问题，最优目标值为 $26$。子问题的直接下界更新为：\n$$ Z_{new} = \\min(\\infty, 26) = 26 $$\n直接下界改善是这个新下界与根节点下界之间的差值：\n$$ \\text{Improvement} = Z_{new} - Z_{LP} = 26 - 19.5 = 6.5 $$\n\n尽管 $y$ 的简约成本为零，但对其进行分支之所以有效，源于等式约束 $x_i - y = 0$ 的强大推理能力。这些约束将连续变量 $y$ 与所有二元变量 $x_i$ 紧密联系起来。强迫 $y$ 取与最终整数解一致的值（$0$ 和 $1$），会立即迫使所有 $x_i$ 取整数值。这能一次性解决所有的非整数问题，并迅速导向不可行性的证明或一个整数解，从而在单一步骤内完全弥合整数间隙（$26 - 19.5 = 6.5$）。这表明，当B&B中的变量选择规则考虑到变量的结构性作用和分支的逻辑影响，而不仅仅依赖于像简约成本这样的局部LP信息时，它们可以更加有效。", "answer": "$$\\boxed{6.5}$$", "id": "3104676"}, {"introduction": "在认识到简单启发式方法的局限性后，我们现在转向设计一种更稳健、更实用的分支规则。一个优秀的分支策略通常需要平衡多个因素。最著名的启发式规则之一是选择“最接近分数”的变量（即其小数部分最接近 $0.5$），因为这代表了最大的不确定性。然而，我们可以通过考虑变量在问题结构中的“重要性”来进一步改进它。\n\n这个动手编程练习 [@problem_id:3104685] 将指导你实现一个更智能的分支启发式规则。你将通过一个加权方案，来量化每个变量在“紧约束”（即几乎被满足的约束）中的参与度，并用这个权重来调整其“分数偏差”。通过这种方式，你将学会开发一种能够优先处理那些既具有高度不确定性又在结构上至关重要的变量的策略，这是现代混合整数规划求解器中常用技术的一个缩影。", "problem": "您的任务是设计并实现一个程序，该程序基于线性规划 (LP) 松弛的输出，为混合整数线性规划 (MILP) 选择一个分支变量。该程序必须基于优化的基本原理，并且必须计算一个加权度量来衡量每个变量作为分支变量的适合性。从线性规划和混合整数线性规划的核心定义出发，推导出一个基于约束重要性对变量进行加权的规则，并将其与小数部分与0.5的接近程度的度量相结合。最终的选择必须是使这个加权差异最小化的变量的索引（使用零基索引）。\n\n使用的基本定义：\n- 混合整数线性规划 (MILP) 问题的线性规划 (LP) 松弛由一组线性约束和一个连续决策向量定义。考虑形式为 $A x \\le b$ 的约束，其中 $A \\in \\mathbb{R}^{m \\times n}$，$b \\in \\mathbb{R}^{m}$，且 $x \\in \\mathbb{R}^{n}$ 是LP松弛解。第 $j$ 个约束的松弛量为 $s_j = b_j - (A x)_j$，对于一个可行的LP解，$s_j \\ge 0$。\n- 一个变量的小数部分定义为 $\\operatorname{frac}(x_i) = x_i - \\lfloor x_i \\rfloor$。\n- 分支变量选择旨在选择一个变量，对其进行分支有望强力收紧松弛。根据经验，小数部分最接近 $0.5$ 的变量具有影响力，而深度参与紧约束的变量应被赋予更高的权重。\n\n您的任务：\n1. 对于每个模型，仅使用在LP解处可用的量，为每个约束 $j$ 计算一个约束重要性得分。令约束重要性定义为 $I_j = \\dfrac{1}{1 + s_j}$，其中 $s_j$ 是约束 $j$ 的松弛量。此公式通过为紧约束（小的 $s_j$）分配较大的 $I_j$ 来强调它们。\n2. 对于每个变量 $i$，计算一个权重 $w_i$，该权重聚合了其在各约束中相对于其重要性的参与度。使用系数的绝对值大小来衡量参与度：$w_i = \\sum_{j=1}^{m} I_j \\, |a_{j,i}|$，其中 $a_{j,i}$ 是 $A$ 的 $(j,i)$ 项。\n3. 对于每个变量 $i$，计算其小数部分与 $0.5$ 的绝对偏差，即 $d_i = \\left| \\operatorname{frac}(x_i^*) - 0.5 \\right|$，其中 $x_i^*$ 是变量 $i$ 的LP松弛值。\n4. 通过 $S_i = w_i \\cdot d_i$ 结合权重和偏差来定义选择分数 $S_i$。如果 $w_i = 0$，则将 $S_i$ 视为 $+\\infty$，以排除不参与任何约束的变量。\n5. 选择得分 $S_i$ 最小的变量索引 $i^\\star$。如果在小的容差（使用绝对容差 $\\epsilon = 10^{-9}$）内出现平局，则通过选择具有最大 $w_i$ 的候选者来打破平局，如果仍然平局，则选择最小的索引。\n\n实现上述过程，并将其应用于以下模型测试集。在每个模型中，所有变量都被视为整数约束，并且LP松弛解 $x^*$ 是可行的。\n\n模型 $\\mathbf{1}$ (正常情况，具有混合小数部分):\n- 约束矩阵:\n$$\nA^{(1)} = \\begin{bmatrix}\n1  & 2 & 0 & 1 \\\\\n0  & 1 & 3 & 1 \\\\\n2  & 0 & 1 & 0\n\\end{bmatrix}\n$$\n- 右侧向量:\n$$\nb^{(1)} = \\begin{bmatrix} 5 \\\\ 6 \\\\ 3 \\end{bmatrix}\n$$\n- LP松弛解:\n$$\nx^{*(1)} = \\begin{bmatrix} 0.8 \\\\ 1.5 \\\\ 0.2 \\\\ 1.1 \\end{bmatrix}\n$$\n\n模型 $\\mathbf{2}$ (边界情况，一个整数和一个半整数小数部分):\n- 约束矩阵:\n$$\nA^{(2)} = \\begin{bmatrix}\n1 & 1 & 1 \\\\\n2 & 0 & 1\n\\end{bmatrix}\n$$\n- 右侧向量:\n$$\nb^{(2)} = \\begin{bmatrix} 4.0 \\\\ 5.0 \\end{bmatrix}\n$$\n- LP松弛解:\n$$\nx^{*(2)} = \\begin{bmatrix} 2.0 \\\\ 1.49 \\\\ 0.5 \\end{bmatrix}\n$$\n\n模型 $\\mathbf{3}$ (平局情况：两个变量的小数部分为半整数):\n- 约束矩阵:\n$$\nA^{(3)} = \\begin{bmatrix}\n1 & 0 & 1 & 2 \\\\\n0 & 2 & 1 & 0\n\\end{bmatrix}\n$$\n- 右侧向量:\n$$\nb^{(3)} = \\begin{bmatrix} 4.0 \\\\ 4.0 \\end{bmatrix}\n$$\n- LP松弛解:\n$$\nx^{*(3)} = \\begin{bmatrix} 0.5 \\\\ 1.5 \\\\ 0.75 \\\\ 1.25 \\end{bmatrix}\n$$\n\n模型 $\\mathbf{4}$ (边缘情况，一个零权重变量被排除在选择之外):\n- 约束矩阵:\n$$\nA^{(4)} = \\begin{bmatrix}\n1 & 1 & 0\n\\end{bmatrix}\n$$\n- 右侧向量:\n$$\nb^{(4)} = \\begin{bmatrix} 1.4 \\end{bmatrix}\n$$\n- LP松弛解:\n$$\nx^{*(4)} = \\begin{bmatrix} 0.3 \\\\ 0.7 \\\\ 0.49 \\end{bmatrix}\n$$\n\n您的程序必须：\n- 为四个模型中的每一个实现上述五步流程。\n- 生成单行输出，其中包含四个模型选定索引的逗号分隔列表，并用方括号括起来，使用零基索引。例如，输出格式必须严格为 $[i_1,i_2,i_3,i_4]$ 的形式，其中每个 $i_k$ 是一个整数。\n\n不涉及物理单位或角度单位。所有计算出的数值输出必须是无单位的纯数字。最终输出必须严格遵循指定的单行格式，不得包含任何额外文本。", "solution": "问题陈述要求我们设计并实现一种特定的启发式方法，用于在混合整数线性规划（MILP）的上下文中选择分支变量。该选择基于线性规划（LP）松弛的解。问题定义清晰，数学上合理，并提供了所有必要的数据和公式。因此，我将对四个指定的模型中的每一个进行系统的推导和计算。\n\n该方法的核心是为每个变量 $x_i$ 计算一个选择分数 $S_i$，并选择分数最小的变量。分数 $S_i$ 是一个权重 $w_i$ 和一个偏差 $d_i$ 的乘积，其中 $w_i$ 衡量变量在约束系统中的结构重要性，$d_i$ 衡量变量的小数值与 $0.5$ 的距离。\n\n流程如下：\n1.  对于每个约束 $j$，计算松弛量 $s_j = b_j - (A x^*)_j$，其中 $x^*$ 是LP松弛解。然后，约束重要性为 $I_j = \\frac{1}{1 + s_j}$。\n2.  对于每个变量 $i$，计算其权重 $w_i = \\sum_{j=1}^{m} I_j \\, |a_{j,i}|$，其中 $a_{j,i}$ 是约束矩阵 $A$ 的元素。\n3.  对于每个变量 $i$，找到其小数部分 $\\operatorname{frac}(x_i^*) = x_i^* - \\lfloor x_i^* \\rfloor$ 并计算偏差 $d_i = |\\operatorname{frac}(x_i^*) - 0.5|$。\n4.  计算选择分数 $S_i = w_i \\cdot d_i$。一个特殊条件适用：如果 $w_i = 0$，则 $S_i$ 被设为 $+\\infty$。\n5.  选择分数 $S_i$ 最小的变量。平局首先通过选择具有最大权重 $w_i$ 的变量来解决，然后通过选择索引最小的变量来解决。分数比较使用 $10^{-9}$ 的容差 $\\epsilon$。\n\n我们现在将此流程应用于每个模型。\n\n### 模型 1\n给定：\n- $A^{(1)} = \\begin{bmatrix} 1  & 2 & 0 & 1 \\\\ 0  & 1 & 3 & 1 \\\\ 2  & 0 & 1 & 0 \\end{bmatrix}$\n- $b^{(1)} = \\begin{bmatrix} 5 \\\\ 6 \\\\ 3 \\end{bmatrix}$\n- $x^{*(1)} = \\begin{bmatrix} 0.8 \\\\ 1.5 \\\\ 0.2 \\\\ 1.1 \\end{bmatrix}$\n\n**步骤 1：约束松弛量和重要性**\n首先，我们计算乘积 $A^{(1)}x^{*(1)}$：\n$$ A^{(1)}x^{*(1)} = \\begin{bmatrix} 1(0.8) + 2(1.5) + 0(0.2) + 1(1.1) \\\\ 0(0.8) + 1(1.5) + 3(0.2) + 1(1.1) \\\\ 2(0.8) + 0(1.5) + 1(0.2) + 0(1.1) \\end{bmatrix} = \\begin{bmatrix} 4.9 \\\\ 3.2 \\\\ 1.8 \\end{bmatrix} $$\n松弛量 $s_j = b_j - (A x^*)_j$ 为：\n- $s_1 = 5 - 4.9 = 0.1$\n- $s_2 = 6 - 3.2 = 2.8$\n- $s_3 = 3 - 1.8 = 1.2$\n约束重要性 $I_j = 1/(1+s_j)$ 为：\n- $I_1 = 1 / (1 + 0.1) = 1 / 1.1 \\approx 0.90909$\n- $I_2 = 1 / (1 + 2.8) = 1 / 3.8 \\approx 0.26316$\n- $I_3 = 1 / (1 + 1.2) = 1 / 2.2 \\approx 0.45455$\n\n**步骤 2：变量权重**\n权重 $w_i = \\sum_{j} I_j |a_{j,i}|$ 为：\n- $w_0 = I_1|1| + I_2|0| + I_3|2| \\approx 0.90909(1) + 0.45455(2) \\approx 1.81818$\n- $w_1 = I_1|2| + I_2|1| + I_3|0| \\approx 0.90909(2) + 0.26316(1) \\approx 2.08134$\n- $w_2 = I_1|0| + I_2|3| + I_3|1| \\approx 0.26316(3) + 0.45455(1) \\approx 1.24401$\n- $w_3 = I_1|1| + I_2|1| + I_3|0| \\approx 0.90909(1) + 0.26316(1) \\approx 1.17225$\n\n**步骤 3：偏差**\n小数部分 $\\operatorname{frac}(x_i^*)$ 和偏差 $d_i$ 为：\n- $x_0^* = 0.8 \\implies \\operatorname{frac}(x_0^*) = 0.8 \\implies d_0 = |0.8 - 0.5| = 0.3$\n- $x_1^* = 1.5 \\implies \\operatorname{frac}(x_1^*) = 0.5 \\implies d_1 = |0.5 - 0.5| = 0.0$\n- $x_2^* = 0.2 \\implies \\operatorname{frac}(x_2^*) = 0.2 \\implies d_2 = |0.2 - 0.5| = 0.3$\n- $x_3^* = 1.1 \\implies \\operatorname{frac}(x_3^*) = 0.1 \\implies d_3 = |0.1 - 0.5| = 0.4$\n\n**步骤 4 & 5：分数和选择**\n分数 $S_i = w_i \\cdot d_i$ 为：\n- $S_0 \\approx 1.81818 \\cdot 0.3 \\approx 0.54545$\n- $S_1 \\approx 2.08134 \\cdot 0.0 = 0.0$\n- $S_2 \\approx 1.24401 \\cdot 0.3 \\approx 0.37320$\n- $S_3 \\approx 1.17225 \\cdot 0.4 \\approx 0.46890$\n最低分数为 $S_1 = 0.0$。因此，选择的变量索引为 $1$。\n\n### 模型 2\n给定：\n- $A^{(2)} = \\begin{bmatrix} 1 & 1 & 1 \\\\ 2 & 0 & 1 \\end{bmatrix}$\n- $b^{(2)} = \\begin{bmatrix} 4.0 \\\\ 5.0 \\end{bmatrix}$\n- $x^{*(2)} = \\begin{bmatrix} 2.0 \\\\ 1.49 \\\\ 0.5 \\end{bmatrix}$\n\n**步骤 1：约束松弛量和重要性**\n$A^{(2)}x^{*(2)} = \\begin{bmatrix} 1(2.0) + 1(1.49) + 1(0.5) \\\\ 2(2.0) + 0(1.49) + 1(0.5) \\end{bmatrix} = \\begin{bmatrix} 3.99 \\\\ 4.5 \\end{bmatrix}$\n- $s_1 = 4.0 - 3.99 = 0.01$\n- $s_2 = 5.0 - 4.5 = 0.5$\n- $I_1 = 1 / (1 + 0.01) = 1 / 1.01 \\approx 0.99010$\n- $I_2 = 1 / (1 + 0.5) = 1 / 1.5 \\approx 0.66667$\n\n**步骤 2：变量权重**\n- $w_0 = I_1|1| + I_2|2| \\approx 0.99010(1) + 0.66667(2) \\approx 2.32343$\n- $w_1 = I_1|1| + I_2|0| \\approx 0.99010(1) \\approx 0.99010$\n- $w_2 = I_1|1| + I_2|1| \\approx 0.99010(1) + 0.66667(1) \\approx 1.65677$\n\n**步骤 3：偏差**\n- $x_0^* = 2.0 \\implies \\operatorname{frac}(x_0^*) = 0.0 \\implies d_0 = |0.0 - 0.5| = 0.5$\n- $x_1^* = 1.49 \\implies \\operatorname{frac}(x_1^*) = 0.49 \\implies d_1 = |0.49 - 0.5| = 0.01$\n- $x_2^* = 0.5 \\implies \\operatorname{frac}(x_2^*) = 0.5 \\implies d_2 = |0.5 - 0.5| = 0.0$\n\n**步骤 4 & 5：分数和选择**\n- $S_0 \\approx 2.32343 \\cdot 0.5 \\approx 1.16172$\n- $S_1 \\approx 0.99010 \\cdot 0.01 \\approx 0.00990$\n- $S_2 \\approx 1.65677 \\cdot 0.0 = 0.0$\n最低分数为 $S_2 = 0.0$。选择的变量索引为 $2$。\n\n### 模型 3\n给定：\n- $A^{(3)} = \\begin{bmatrix} 1 & 0 & 1 & 2 \\\\ 0 & 2 & 1 & 0 \\end{bmatrix}$\n- $b^{(3)} = \\begin{bmatrix} 4.0 \\\\ 4.0 \\end{bmatrix}$\n- $x^{*(3)} = \\begin{bmatrix} 0.5 \\\\ 1.5 \\\\ 0.75 \\\\ 1.25 \\end{bmatrix}$\n\n**步骤 1：约束松弛量和重要性**\n$A^{(3)}x^{*(3)} = \\begin{bmatrix} 1(0.5) + 0(1.5) + 1(0.75) + 2(1.25) \\\\ 0(0.5) + 2(1.5) + 1(0.75) + 0(1.25) \\end{bmatrix} = \\begin{bmatrix} 3.75 \\\\ 3.75 \\end{bmatrix}$\n- $s_1 = 4.0 - 3.75 = 0.25$\n- $s_2 = 4.0 - 3.75 = 0.25$\n- $I_1 = 1 / (1 + 0.25) = 1 / 1.25 = 0.8$\n- $I_2 = 1 / (1 + 0.25) = 1 / 1.25 = 0.8$\n\n**步骤 2：变量权重**\n- $w_0 = I_1|1| + I_2|0| = 0.8(1) = 0.8$\n- $w_1 = I_1|0| + I_2|2| = 0.8(2) = 1.6$\n- $w_2 = I_1|1| + I_2|1| = 0.8(1) + 0.8(1) = 1.6$\n- $w_3 = I_1|2| + I_2|0| = 0.8(2) = 1.6$\n\n**步骤 3：偏差**\n- $x_0^* = 0.5 \\implies \\operatorname{frac}(x_0^*) = 0.5 \\implies d_0 = |0.5 - 0.5| = 0.0$\n- $x_1^* = 1.5 \\implies \\operatorname{frac}(x_1^*) = 0.5 \\implies d_1 = |0.5 - 0.5| = 0.0$\n- $x_2^* = 0.75 \\implies \\operatorname{frac}(x_2^*) = 0.75 \\implies d_2 = |0.75 - 0.5| = 0.25$\n- $x_3^* = 1.25 \\implies \\operatorname{frac}(x_3^*) = 0.25 \\implies d_3 = |0.25 - 0.5| = 0.25$\n\n**步骤 4 & 5：分数和选择**\n- $S_0 = 0.8 \\cdot 0.0 = 0.0$\n- $S_1 = 1.6 \\cdot 0.0 = 0.0$\n- $S_2 = 1.6 \\cdot 0.25 = 0.4$\n- $S_3 = 1.6 \\cdot 0.25 = 0.4$\n最低分数为 $0.0$，由索引为 $0$ 和 $1$ 的变量共享。我们应用平局决胜规则：选择权重 $w_i$ 最大的候选者。\n- 候选者 $0$：$w_0 = 0.8$\n- 候选者 $1$：$w_1 = 1.6$\n由于 $w_1 > w_0$，我们选择索引为 $1$ 的变量。\n\n### 模型 4\n给定：\n- $A^{(4)} = \\begin{bmatrix} 1 & 1 & 0 \\end{bmatrix}$\n- $b^{(4)} = \\begin{bmatrix} 1.4 \\end{bmatrix}$\n- $x^{*(4)} = \\begin{bmatrix} 0.3 \\\\ 0.7 \\\\ 0.49 \\end{bmatrix}$\n\n**步骤 1：约束松弛量和重要性**\n$A^{(4)}x^{*(4)} = \\begin{bmatrix} 1(0.3) + 1(0.7) + 0(0.49) \\end{bmatrix} = \\begin{bmatrix} 1.0 \\end{bmatrix}$\n- $s_1 = 1.4 - 1.0 = 0.4$\n- $I_1 = 1 / (1 + 0.4) = 1 / 1.4 \\approx 0.71429$\n\n**步骤 2：变量权重**\n- $w_0 = I_1|1| = 1/1.4 \\approx 0.71429$\n- $w_1 = I_1|1| = 1/1.4 \\approx 0.71429$\n- $w_2 = I_1|0| = 0$\n\n**步骤 3：偏差**\n- $x_0^* = 0.3 \\implies \\operatorname{frac}(x_0^*) = 0.3 \\implies d_0 = |0.3 - 0.5| = 0.2$\n- $x_1^* = 0.7 \\implies \\operatorname{frac}(x_1^*) = 0.7 \\implies d_1 = |0.7 - 0.5| = 0.2$\n- $x_2^* = 0.49 \\implies \\operatorname{frac}(x_2^*) = 0.49 \\implies d_2 = |0.49 - 0.5| = 0.01$\n\n**步骤 4 & 5：分数和选择**\n- $S_0 = (1/1.4) \\cdot 0.2 = 0.2 / 1.4 = 1/7 \\approx 0.14286$\n- $S_1 = (1/1.4) \\cdot 0.2 = 0.2 / 1.4 = 1/7 \\approx 0.14286$\n- $w_2=0$，根据规则，$S_2 = +\\infty$。\n最低分数为 $1/7$，由索引为 $0$ 和 $1$ 的变量共享。我们应用第一个平局决胜规则（最大权重）。\n- 候选者 $0$：$w_0 = 1/1.4$\n- 候选者 $1$：$w_1 = 1/1.4$\n权重相同，因此我们应用第二个平局决胜规则：选择最小的索引。索引为 $0$ 和 $1$。最小的是 $0$。因此，我们选择索引为 $0$ 的变量。\n\n### 结果摘要\n- 模型 1: 索引 $1$\n- 模型 2: 索引 $2$\n- 模型 3: 索引 $1$\n- 模型 4: 索引 $0$\n\n最终输出将是这些索引的列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the solution process for all test cases.\n    \"\"\"\n\n    def select_branching_variable(A, b, x_star, tol=1e-9):\n        \"\"\"\n        Implements the 5-step process to select a branching variable.\n        \n        Args:\n            A (np.ndarray): Constraint matrix.\n            b (np.ndarray): Right-hand side vector.\n            x_star (np.ndarray): LP relaxation solution vector.\n            tol (float): Tolerance for score comparison.\n\n        Returns:\n            int: The zero-based index of the selected variable.\n        \"\"\"\n        A = np.atleast_2d(A)\n        m, n = A.shape\n        b = np.atleast_1d(b)\n        x_star = np.atleast_1d(x_star)\n\n        # Step 1: Compute slacks and constraint importances\n        s = b - A @ x_star\n        # This can be slightly negative due to float precision, clamp at 0.\n        s[s  0] = 0\n        I = 1.0 / (1.0 + s)\n\n        # Step 2: Compute variable weights\n        # w_i = sum_j I_j * |a_ji|\n        w = np.dot(I, np.abs(A))\n\n        # Step 3: Compute deviations from 0.5\n        # frac(x_i) = x_i - floor(x_i)\n        frac_x = x_star - np.floor(x_star)\n        d = np.abs(frac_x - 0.5)\n\n        # Step 4: Compute selection scores\n        # S_i = w_i * d_i\n        S = w * d\n        # If w_i = 0, treat S_i as +inf\n        zeros_w_indices = np.where(np.isclose(w, 0))[0]\n        S[zeros_w_indices] = np.inf\n\n        # Step 5: Select variable index\n        if np.all(np.isinf(S)):\n            # This case should not happen with the given data but is a safe guard.\n            return 0\n            \n        min_score = np.min(S)\n        \n        # Find all candidates with score close to the minimum\n        candidate_indices = np.where(np.abs(S - min_score) = tol)[0]\n\n        if len(candidate_indices) == 1:\n            return candidate_indices[0]\n        \n        # Tie-breaking rule 1: largest w_i\n        candidate_weights = w[candidate_indices]\n        max_w = np.max(candidate_weights)\n        \n        # Use np.isclose for robust float comparison\n        best_candidates_by_weight = candidate_indices[np.isclose(candidate_weights, max_w)]\n\n        if len(best_candidates_by_weight) == 1:\n            return best_candidates_by_weight[0]\n\n        # Tie-breaking rule 2: smallest index\n        return np.min(best_candidates_by_weight)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"A\": np.array([[1, 2, 0, 1], [0, 1, 3, 1], [2, 0, 1, 0]]),\n            \"b\": np.array([5, 6, 3]),\n            \"x_star\": np.array([0.8, 1.5, 0.2, 1.1])\n        },\n        {\n            \"A\": np.array([[1, 1, 1], [2, 0, 1]]),\n            \"b\": np.array([4.0, 5.0]),\n            \"x_star\": np.array([2.0, 1.49, 0.5])\n        },\n        {\n            \"A\": np.array([[1, 0, 1, 2], [0, 2, 1, 0]]),\n            \"b\": np.array([4.0, 4.0]),\n            \"x_star\": np.array([0.5, 1.5, 0.75, 1.25])\n        },\n        {\n            \"A\": np.array([[1, 1, 0]]),\n            \"b\": np.array([1.4]),\n            \"x_star\": np.array([0.3, 0.7, 0.49])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = select_branching_variable(case[\"A\"], case[\"b\"], case[\"x_star\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3104685"}]}