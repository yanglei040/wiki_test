{"hands_on_practices": [{"introduction": "强制性是确保优化问题解存在的一个重要性质。然而，一个函数即使在每个坐标轴方向上都是凸的，也未必是强制的。本练习通过一个看似简单的函数 $f(x_1, x_2) = x_1^2 x_2^2$ 来揭示这一微妙之处。你将通过寻找函数值保持有界的“无限深谷”路径，来亲手验证非强制性，从而建立对这一概念的直观理解。[@problem_id:3108676]", "problem": "设函数 $f:\\mathbb{R}^2\\to\\mathbb{R}$ 定义为 $f(x_1,x_2)=x_1^2 x_2^2$。请仅使用凸分析和优化中的核心定义来分析 $f$。\n\n任务：\n1) 使用单变量函数的凸性定义，验证对于每个固定的 $x_2\\in\\mathbb{R}$，映射 $x_1\\mapsto f(x_1,x_2)$ 在 $\\mathbb{R}$ 上是凸的，并且对于每个固定的 $x_1\\in\\mathbb{R}$，映射 $x_2\\mapsto f(x_1,x_2)$ 在 $\\mathbb{R}$ 上是凸的。\n2) 使用强制性（coercivity）的定义（即，如果 $\\lim_{\\|x\\|\\to\\infty} f(x)=+\\infty$，则函数 $f:\\mathbb{R}^n\\to\\mathbb{R}$ 是强制的），通过找出 $f$ 保持有上界的显式无界方向（谷），证明 $f$ 不是强制的。\n3) 计算值\n$$\nL \\;=\\; \\liminf_{\\|(x_1,x_2)\\|\\to\\infty} f(x_1,x_2).\n$$\n给出你的最终答案，形式为一个实数。不需要四舍五入。", "solution": "问题陈述已经过验证，被认为是一个在数学分析和优化领域中定义良好、有科学依据的问题。\n\n待分析的函数是 $f:\\mathbb{R}^2\\to\\mathbb{R}$，定义为 $f(x_1,x_2)=x_1^2 x_2^2$。\n\n**1) 分离凸性分析**\n\n我们被要求验证函数 $f$ 在每个变量上是分离凸的。如果一个函数对于每个变量，通过固定其他变量得到的单变量函数是凸的，则该函数是分离凸的（或称逐坐标凸的）。对于一个二次可微的单变量函数 $g(t)$，凸分析中的一个核心结果表明，$g$ 在一个区间上是凸的，当且仅当其二阶导数 $g''(t)$ 在该区间上是非负的。\n\n首先，我们固定 $x_2 \\in \\mathbb{R}$ 并分析映射 $x_1 \\mapsto f(x_1, x_2)$ 的凸性。我们定义单变量函数 $g_{x_2}(x_1) = f(x_1, x_2) = x_2^2 x_1^2$。这里，$x_2$ 被视为一个常数。函数 $g_{x_2}$ 是关于 $x_1$ 的多项式，因此在 $\\mathbb{R}$ 上是无限可微的。我们计算它关于 $x_1$ 的一阶和二阶导数：\n$$\ng_{x_2}'(x_1) = \\frac{d}{dx_1}(x_2^2 x_1^2) = 2x_2^2 x_1\n$$\n$$\ng_{x_2}''(x_1) = \\frac{d^2}{dx_1^2}(x_2^2 x_1^2) = 2x_2^2\n$$\n对于任何实数 $x_2$，项 $x_2^2$ 是非负的，即 $x_2^2 \\ge 0$。因此，对于所有 $x_1 \\in \\mathbb{R}$，二阶导数 $g_{x_2}''(x_1) = 2x_2^2 \\ge 0$。由于其二阶导数处处非负，所以对于任何固定的 $x_2 \\in \\mathbb{R}$，函数 $x_1 \\mapsto f(x_1, x_2)$ 在 $\\mathbb{R}$ 上是凸的。\n\n接着，我们固定 $x_1 \\in \\mathbb{R}$ 并分析映射 $x_2 \\mapsto f(x_1, x_2)$ 的凸性。我们定义单变量函数 $h_{x_1}(x_2) = f(x_1, x_2) = x_1^2 x_2^2$。这里，$x_1$ 被视为一个常数。这个函数在 $\\mathbb{R}$ 上也是无限可微的。我们计算它关于 $x_2$ 的一阶和二阶导数：\n$$\nh_{x_1}'(x_2) = \\frac{d}{dx_2}(x_1^2 x_2^2) = 2x_1^2 x_2\n$$\n$$\nh_{x_1}''(x_2) = \\frac{d^2}{dx_2^2}(x_1^2 x_2^2) = 2x_1^2\n$$\n对于任何实数 $x_1$，项 $x_1^2$ 是非负的，即 $x_1^2 \\ge 0$。因此，对于所有 $x_2 \\in \\mathbb{R}$，二阶导数 $h_{x_1}''(x_2) = 2x_1^2 \\ge 0$。由于二阶导数是非负的，所以对于任何固定的 $x_1 \\in \\mathbb{R}$，函数 $x_2 \\mapsto f(x_1, x_2)$ 在 $\\mathbb{R}$ 上是凸的。\n\n这就完成了对 $f$ 是分离凸函数的验证。\n\n**2) 非强制性的证明**\n\n如果 $\\lim_{\\|x\\|\\to\\infty} f(x)=+\\infty$，则函数 $f:\\mathbb{R}^n\\to\\mathbb{R}$ 被定义为强制的（coercive）。要证明 $f(x_1, x_2) = x_1^2 x_2^2$ 不是强制的，我们必须在 $\\mathbb{R}^2$ 中找到一个无界点序列 $\\{z_k\\}_{k=1}^\\infty$，使得当 $k\\to\\infty$ 时 $\\|z_k\\|\\to\\infty$，但函数值序列 $\\{f(z_k)\\}_{k=1}^\\infty$ 不趋向于 $+\\infty$。\n\n当 $x_1=0$ 或 $x_2=0$ 时，函数 $f(x_1, x_2)$ 的值为 $0$。这对应于 $\\mathbb{R}^2$ 中的坐标轴。这些轴代表了函数保持在恒定低值的“谷”。让我们考虑沿 $x_1$ 轴的一条路径。\n\n我们定义一个点序列 $z_k = (k, 0)$，其中 $k=1, 2, 3, \\dots$。这些点的范数为 $\\|z_k\\| = \\sqrt{k^2 + 0^2} = k$。当 $k\\to\\infty$ 时，我们有 $\\|z_k\\|\\to\\infty$，因此该点序列是无界的。\n\n现在，我们计算函数 $f$ 在这些点上的值：\n$$\nf(z_k) = f(k, 0) = k^2 \\cdot 0^2 = 0\n$$\n函数值序列对于所有 $k$ 均为 $f(z_k)=0$。该序列的极限是 $\\lim_{k\\to\\infty} f(z_k) = 0$，而不是 $+\\infty$。\n\n因为我们找到了一条路径，沿此路径 $\\|z_k\\|\\to\\infty$ 但 $f(z_k)$ 不趋近于 $+\\infty$，所以函数 $f$ 不是强制的。另一条这样的路径是沿 $x_2$ 轴，例如取点 $(0, k)$。\n\n**3) 下极限的计算**\n\n我们被要求计算值 $L = \\liminf_{\\|(x_1,x_2)\\|\\to\\infty} f(x_1,x_2)$。该下极限的定义是：\n$$\nL = \\lim_{R\\to\\infty} \\left( \\inf_{\\|(x_1,x_2)\\| > R} f(x_1,x_2) \\right)\n$$\n其中 $\\|(x_1,x_2)\\|$ 表示欧几里得范数 $\\sqrt{x_1^2+x_2^2}$。\n\n首先，我们观察到对于所有 $(x_1, x_2) \\in \\mathbb{R}^2$，都有 $f(x_1, x_2) = x_1^2 x_2^2 \\ge 0$，因为它是平方的乘积。这意味着 $f$ 在 $\\mathbb{R}^2$ 的任何子集上的下确界（infimum）都必须大于或等于 $0$。\n\n对于任意的 $R > 0$，我们考虑 $f$ 在集合 $S_R = \\{(x_1, x_2) \\in \\mathbb{R}^2 : \\|(x_1, x_2)\\| > R\\}$ 上的下确界。我们想要确定 $\\inf_{(x_1,x_2) \\in S_R} f(x_1,x_2)$。\n\n根据我们对强制性的分析，我们知道在离原点任意远的地方都存在点使得 $f$ 的值为 $0$。对于任何给定的 $R > 0$，我们选择点 $p_R = (R+1, 0)$。这个点的范数是 $\\|p_R\\| = \\sqrt{(R+1)^2 + 0^2} = R+1$。由于 $R+1 > R$，点 $p_R$ 属于集合 $S_R$。\n\n函数在该点的值为：\n$$\nf(p_R) = f(R+1, 0) = (R+1)^2 \\cdot 0^2 = 0\n$$\n因此，对于任何 $R > 0$，在 $S_R$ 中都存在一个点，使得 $f$ 在该点的值为 $0$。由于对于所有点都有 $f(x_1, x_2) \\ge 0$，因此 $f$ 在集合 $S_R$ 上的最大下界（下确界）必须是 $0$。\n$$\n\\inf_{\\|(x_1,x_2)\\| > R} f(x_1,x_2) = 0\n$$\n这对任何 $R > 0$ 的选择都成立。\n\n现在，我们可以计算下极限 $L$：\n$$\nL = \\lim_{R\\to\\infty} \\left( \\inf_{\\|(x_1,x_2)\\| > R} f(x_1,x_2) \\right) = \\lim_{R\\to\\infty} 0 = 0\n$$\n因此，下极限的值是 $0$。", "answer": "$$\n\\boxed{0}\n$$", "id": "3108676"}, {"introduction": "从直观的几何图像转向更普适的代数分析，二次型在最小二乘法等众多优化问题中扮演着核心角色。本练习将探讨二次函数 $f(x) = \\|Ax\\|_2^2 - \\|x\\|_2^2$ 的强制性。通过这个练习，你将学会如何将函数的强制性与矩阵 $A$ 的奇异值联系起来，从而掌握判断一类重要函数是否具有全局最优解的精确代数准则。[@problem_id:3108687]", "problem": "考虑一个矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 以及由 $f(x) = \\|A x\\|_{2}^{2} - \\|x\\|_{2}^{2}$ 定义的函数 $f : \\mathbb{R}^{n} \\to \\mathbb{R}$，其中 $\\|\\cdot\\|_{2}$ 表示欧几里得范数。仅使用矫顽性（coercivity）和奇异值的核心定义，用 $A$ 的最小奇异值 $\\sigma_{\\min}(A)$ 来确定 $f$ 的矫顽性阈值，并计算紧致常数 $c$，使得对所有 $x \\in \\mathbb{R}^{n}$ 都有 $f(x) \\geq c \\|x\\|_{2}^{2}$。请以 $c$ 关于 $\\sigma_{\\min}(A)$ 的解析表达式作为最终答案。此外，在你的解法中，解释矫顽性失效的情况。最终报告的量必须是单个不带单位的闭式表达式。", "solution": "我们从 $\\mathbb{R}^{n}$ 上函数的矫顽性定义开始。一个函数 $f : \\mathbb{R}^{n} \\to \\mathbb{R}$ 是矫顽的，如果当 $\\|x\\|_{2} \\to +\\infty$ 时，有 $f(x) \\to +\\infty$。所讨论的函数是二次型\n$$\nf(x) = \\|A x\\|_{2}^{2} - \\|x\\|_{2}^{2} = x^{\\top} (A^{\\top} A - I) x,\n$$\n其中 $I$ 是 $\\mathbb{R}^{n \\times n}$ 中的单位矩阵。$f(x)$ 在 $\\|x\\|_{2} \\to \\infty$ 时的增长由对称矩阵 $A^{\\top} A - I$ 的定性决定。\n\n我们回顾线性代数中一个熟知的结论：如果矩阵 $A$ 的奇异值为 $\\sigma_{1}(A) \\geq \\sigma_{2}(A) \\geq \\cdots \\geq \\sigma_{r}(A) > 0$（其中 $r = \\operatorname{rank}(A)$），以及秩之外可能存在的零，那么 $A^{\\top} A$ 的谱由这些奇异值的平方构成，即 $\\sigma_{i}(A)^{2}$（每个都具有相应的重数），并且如果 $n > m$ 则可能还有零。特别地，在奇异值分解中，$A^{\\top} A$ 限制在 $V$ 的像空间上的最小特征值与 $\\sigma_{\\min}(A)^{2}$ 相匹配，其中，如果 $A$ 是满列秩的，$\\sigma_{\\min}(A)$ 表示最小的非零奇异值；如果 $A$ 是秩亏的，且我们将定义扩展以包含零，则 $\\sigma_{\\min}(A) = 0$。\n\n我们使用奇异值分解（SVD）来分析 $f(x)$。根据奇异值分解（SVD），存在正交矩阵 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$，以及一个对角线元素为非负值 $\\sigma_{i}(A)$ 的对角矩阵 $\\Sigma \\in \\mathbb{R}^{m \\times n}$，使得 $A = U \\Sigma V^{\\top}$。令 $y = V^{\\top} x$。由于 $V$ 是正交的，所以 $\\|y\\|_{2} = \\|x\\|_{2}$。那么\n$$\n\\|A x\\|_{2}^{2} = \\|U \\Sigma V^{\\top} x\\|_{2}^{2} = \\|\\Sigma y\\|_{2}^{2} = \\sum_{i=1}^{\\min\\{m,n\\}} \\sigma_{i}(A)^{2} y_{i}^{2},\n$$\n如果 $n > m$，则 $y$ 的额外坐标贡献为零。因此，\n$$\nf(x) = \\sum_{i=1}^{\\min\\{m,n\\}} \\left( \\sigma_{i}(A)^{2} - 1 \\right) y_{i}^{2} - \\sum_{i=\\min\\{m,n\\}+1}^{n} y_{i}^{2}.\n$$\n等价地，通过对超出秩的 $i$ 填充 $\\sigma_{i}(A) = 0$，我们可以写出\n$$\nf(x) = \\sum_{i=1}^{n} \\left( \\sigma_{i}(A)^{2} - 1 \\right) y_{i}^{2}.\n$$\n该表示立即给出了紧致下界\n$$\nf(x) \\geq \\left( \\min_{i} \\left\\{ \\sigma_{i}(A)^{2} - 1 \\right\\} \\right) \\sum_{i=1}^{n} y_{i}^{2}\n= \\left( \\sigma_{\\min}(A)^{2} - 1 \\right) \\|x\\|_{2}^{2}.\n$$\n因此，对于所有 $x$ 都满足 $f(x) \\geq c \\|x\\|_{2}^{2}$ 的紧致常数 $c$ 是\n$$\nc = \\sigma_{\\min}(A)^{2} - 1.\n$$\n\n现在我们将此界与矫顽性联系起来。如果 $c > 0$，即 $\\sigma_{\\min}(A) > 1$，那么\n$$\nf(x) \\geq c \\|x\\|_{2}^{2} \\to +\\infty \\quad \\text{当} \\quad \\|x\\|_{2} \\to +\\infty,\n$$\n所以 $f$ 是矫顽的。如果 $c = 0$，即 $\\sigma_{\\min}(A) = 1$，那么在对应于奇异值为 $1$ 的方向 $y$ 上，对 $f$ 的贡献为零，并且 $f$ 在这些方向上不会增长到 $+\\infty$；因此 $f$ 不是矫顽的。如果 $c  0$，即 $\\sigma_{\\min}(A)  1$（包括 $\\sigma_{\\min}(A) = 0$ 的秩亏情况），那么在对应于严格小于 $1$ 的奇异值的方向上，二次型的贡献为负值，实际上，当 $\\|x\\|_{2} \\to +\\infty$ 时，$f(x)$ 在这些方向上趋向于 $-\\infty$，因此矫顽性更彻底地失效了。\n\n因此，矫顽性阈值完全由 $\\sigma_{\\min}(A)$ 通过紧致界 $c = \\sigma_{\\min}(A)^{2} - 1$ 确定，当且仅当 $\\sigma_{\\min}(A) > 1$ 时，矫顽性成立；当 $\\sigma_{\\min}(A) = 1$ 时失效（在某些方向上不增长）；并且当 $\\sigma_{\\min}(A)  1$ 时失效（在某些方向上无下界）。", "answer": "$$\\boxed{\\sigma_{\\min}(A)^{2} - 1}$$", "id": "3108687"}, {"introduction": "理论与实践的结合是掌握优化方法的关键。强制性保证了全局最小值的存在，但这是否意味着梯度下降等算法总能找到它？本练习通过构建一个虽然具有强制性、却在远离最小值处存在“平坦区域”的函数，来探讨这一问题。这个实践将帮助你理解为什么即使解的存在性得到保证，优化算法仍可能在实践中“卡住”，从而深化对算法行为和函数地貌之间关系的认识。[@problem_id:3108708]", "problem": "考虑在配备了欧几里得范数 $\\|\\cdot\\|$ 的 $\\mathbb{R}^2$ 空间中的无约束优化问题。如果当 $\\|\\mathbf{x}\\|\\to\\infty$ 时，有 $f(\\mathbf{x})\\to +\\infty$，则称函数 $f:\\mathbb{R}^2\\to\\mathbb{R}$ 是强制的（coercive）。基于梯度的方法（例如，梯度下降）使用梯度 $\\nabla f(\\mathbf{x})$ 生成迭代点，并依赖非零梯度来走向极小值点。请选择唯一一个选项，该选项既提供了一个强制的、且在远离其极小值点处有一个平坦区域（即 $\\nabla f(\\mathbf{x})=\\mathbf{0}$）的函数，又正确描述了这种情况对采用固定步长的基本梯度下降法所造成的具体挑战。\n\nA. $f_A(\\mathbf{x})=\\|\\mathbf{x}\\|^2$。断言：$f_A$ 是强制的，并且在远离其极小值点处有一个平坦区域；基于梯度的方法可能在任何满足 $\\nabla f_A(\\mathbf{x})=\\mathbf{0}$ 的地方停滞。\n\nB. $f_B(\\mathbf{x})=\\begin{cases}\\|\\mathbf{x}\\|^2,  \\|\\mathbf{x}\\| \\le 6\\\\ 36,  \\|\\mathbf{x}\\| > 6\\end{cases}$。断言：$f_B$ 是强制的，并且有一个平坦的环形区域 $6\\|\\mathbf{x}\\|8$；采用固定步长的梯度法如果在此平坦环形区域中初始化，可能会被困住。\n\nC. $f_C(\\mathbf{x})=\\begin{cases}\\|\\mathbf{x}\\|^2,  \\|\\mathbf{x}\\|\\le 6\\\\ 36,  6\\|\\mathbf{x}\\|\\le 8\\\\ \\|\\mathbf{x}\\|^2-28,  \\|\\mathbf{x}\\|> 8\\end{cases}$。断言：$f_C$ 是强制的，并且有一个平坦的环形区域 $6\\|\\mathbf{x}\\|8$，在此区域中 $\\nabla f_C(\\mathbf{x})=\\mathbf{0}$；采用固定步长的梯度法如果在此环形区域中初始化，将不会移动，因为更新步骤使用了 $\\nabla f_C(\\mathbf{x})$。\n\nD. $f_D(\\mathbf{x})=\\|\\mathbf{x}\\|$。断言：因为 $f_D$ 是强制的，所以梯度下降必须从任何起始点收敛；不存在由远离极小值点的平坦区域引起的问题。", "solution": "首先验证问题陈述的科学合理性和一致性。\n\n**步骤1：提取已知条件**\n- 优化问题在 $\\mathbb{R}^2$ 空间中是无约束的。\n- 使用的范数是欧几里得范数，记为 $\\|\\cdot\\|$。\n- 函数 $f:\\mathbb{R}^2\\to\\mathbb{R}$ 被定义为强制的，如果当 $\\|\\mathbf{x}\\|\\to\\infty$ 时，$f(\\mathbf{x})\\to +\\infty$。\n- 背景是基于梯度的优化方法，这些方法使用梯度 $\\nabla f(\\mathbf{x})$ 来寻找极小值点。\n- 任务是识别出唯一一个选项，该选项提供的函数既是强制的，又在远离其极小值点处有一个平坦区域（其中 $\\nabla f(\\mathbf{x})=\\mathbf{0}$），并且正确描述了这对采用固定步长的基本梯度下降法所造成的挑战。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据：** 强制性、欧几里得空间、梯度和梯度下降等概念在数学优化领域是基本且定义明确的。该问题基于标准定义。\n- **适定性：** 问题要求根据一套清晰的标准从列表中选择一个选项。这些标准是客观的，可以对每个函数进行形式化检验。预期会有一个唯一且可推导的答案。\n- **客观性：** 定义和属性（强制性、零梯度）是数学性的，没有主观解释的余地。\n- **完整性和一致性：** 问题提供了评估选项所需的所有必要定义和背景。没有内部矛盾。\n\n**步骤3：结论与行动**\n问题陈述有效。可以开始对每个选项进行分析。\n\n核心任务是根据三个标准评估每个提供的函数 $f(\\mathbf{x})$：\n1.  $f(\\mathbf{x})$ 是否是强制的？\n2.  $f(\\mathbf{x})$ 是否有一个平坦区域（一个 $\\nabla f(\\mathbf{x}) = \\mathbf{0}$ 的区域），该区域远离函数的全局极小值点？\n3.  对梯度下降所面临挑战的描述是否准确？\n\n**选项A的分析**\n- 函数：$f_A(\\mathbf{x})=\\|\\mathbf{x}\\|^2$。对于 $\\mathbf{x} \\in \\mathbb{R}^2$，这表示 $f_A(x_1, x_2) = x_1^2 + x_2^2$。\n- **强制性：** 当 $\\|\\mathbf{x}\\| \\to \\infty$ 时，显然 $\\|\\mathbf{x}\\|^2 \\to \\infty$。因此，$f_A$ 是强制的。\n- **平坦区域：** 梯度为 $\\nabla f_A(\\mathbf{x}) = 2\\mathbf{x}$。梯度为零向量 $\\nabla f_A(\\mathbf{x}) = \\mathbf{0}$ 当且仅当 $2\\mathbf{x} = \\mathbf{0}$，即 $\\mathbf{x} = \\mathbf{0}$。点 $\\mathbf{x} = \\mathbf{0}$ 是 $f_A$ 的唯一全局极小值点。因此，该函数没有*远离*其极小值点的平坦区域。该选项中的断言是错误的。\n- **结论：** 不正确。\n\n**选项B的分析**\n- 函数：$f_B(\\mathbf{x})=\\begin{cases}\\|\\mathbf{x}\\|^2,  \\|\\mathbf{x}\\| \\le 6\\\\ 36,  \\|\\mathbf{x}\\| > 6\\end{cases}$。\n- **强制性：** 强制性的定义要求当 $\\|\\mathbf{x}\\|\\to\\infty$ 时，$f(\\mathbf{x})\\to +\\infty$。对于 $f_B$，当 $\\|\\mathbf{x}\\| > 6$ 时，函数值恒为 36。因此，$\\lim_{\\|\\mathbf{x}\\|\\to\\infty} f_B(\\mathbf{x}) = 36$，而不是 $+\\infty$。函数 $f_B$ 不是强制的。\n- **平坦区域：** 极小值点在 $\\mathbf{x}=\\mathbf{0}$。函数在区域 $\\|\\mathbf{x}\\|>6$ 内是常数，该区域包括环形区域 $6\\|\\mathbf{x}\\|8$。在此环形区域中，$\\nabla f_B(\\mathbf{x}) = \\mathbf{0}$。这个平坦区域远离极小值点。所以这部分断言是正确的。然而，由于该函数不是强制的，所以该选项无效。\n- **结论：** 不正确。\n\n**选项C的分析**\n- 函数：$f_C(\\mathbf{x})=\\begin{cases}\\|\\mathbf{x}\\|^2,  \\|\\mathbf{x}\\|\\le 6\\\\ 36,  6\\|\\mathbf{x}\\|\\le 8\\\\ \\|\\mathbf{x}\\|^2-28,  \\|\\mathbf{x}\\|> 8\\end{cases}$。\n- **强制性：** 为了检查强制性，我们考察 $\\|\\mathbf{x}\\|\\to\\infty$ 时的行为。对于 $\\|\\mathbf{x}\\| > 8$，函数为 $f_C(\\mathbf{x})=\\|\\mathbf{x}\\|^2-28$。其极限为 $\\lim_{\\|\\mathbf{x}\\|\\to\\infty} (\\|\\mathbf{x}\\|^2-28) = +\\infty$。因此，$f_C$ 是强制的。\n- **平坦区域：** $f_C$ 的全局极小值点在 $\\mathbf{x}=\\mathbf{0}$ 处，其中 $f_C(\\mathbf{0})=0$。在由 $6\\|\\mathbf{x}\\|8$ 定义的开环形区域中，函数值为常数 $36$。对于此环形区域中的所有 $\\mathbf{x}$，梯度 $\\nabla f_C(\\mathbf{x})$ 都是零向量。这个区域明显远离位于原点的极小值点。因此，该函数在远离其极小值点处有一个平坦区域。\n- **挑战描述：** 标准的梯度下降更新规则是 $\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha \\nabla f(\\mathbf{x}_k)$，其中 $\\alpha > 0$ 是一个固定的步长。如果一个迭代点 $\\mathbf{x}_k$ 在开环形区域 $6\\|\\mathbf{x}\\|8$ 中被初始化或进入该区域，那么 $\\nabla f_C(\\mathbf{x}_k)=\\mathbf{0}$。更新步骤将变为 $\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha(\\mathbf{0}) = \\mathbf{x}_k$。所有后续的迭代点都将相同，算法会停滞，无法到达位于 $\\mathbf{x}=\\mathbf{0}$ 的极小值点。对这一挑战的描述是正确的。\n- **结论：** 正确。\n\n**选项D的分析**\n- 函数：$f_D(\\mathbf{x})=\\|\\mathbf{x}\\|$。\n- **强制性：** 当 $\\|\\mathbf{x}\\| \\to \\infty$ 时，$f_D(\\mathbf{x})=\\|\\mathbf{x}\\| \\to \\infty$。因此，$f_D$ 是强制的。\n- **平坦区域：** 问题要求一个*具有*远离其极小值点的平坦区域的函数。$f_D$ 的极小值点在 $\\mathbf{x} = \\mathbf{0}$。对于任何 $\\mathbf{x} \\neq \\mathbf{0}$，梯度为 $\\nabla f_D(\\mathbf{x}) = \\frac{\\mathbf{x}}{\\|\\mathbf{x}\\|}$。梯度的范数为 $\\|\\nabla f_D(\\mathbf{x})\\| = \\|\\frac{\\mathbf{x}}{\\|\\mathbf{x}\\|}\\| = 1$。由于对于任何 $\\mathbf{x} \\neq \\mathbf{0}$，梯度都不是零向量，所以该函数在远离其极小值点处没有平坦区域。$f_D$ 不满足问题的前提——找到一个*具有*这样区域的函数。\n- **挑战描述：** 该断言称“梯度下降必须从任何起始点收敛”。这是一个非常强的断言，对于固定步长来说通常不成立。如果步长 $\\alpha$ 选择不当（例如，$\\alpha > 2\\|\\mathbf{x}_k\\|$），算法可能会越过最小值点而无法收敛。不论此断言的正确性如何，该函数本身不符合问题的主要标准。\n- **结论：** 不正确。\n\n根据以上分析，只有选项C提供了一个强制的、在远离极小值点处有平坦区域、并正确描述了其对梯度下降法造成的陷阱的函数。", "answer": "$$\\boxed{C}$$", "id": "3108708"}]}