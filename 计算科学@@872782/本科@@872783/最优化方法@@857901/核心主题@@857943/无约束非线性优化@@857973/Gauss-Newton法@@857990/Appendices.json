{"hands_on_practices": [{"introduction": "在开始任何优化过程之前，我们必须首先明确要最小化的目标。这个练习的核心是计算“残差”，即模型预测值与实际观测数据之间的差异，这是所有最小二乘法的基础构件 [@problem_id:2214281]。通过这个基本计算，您可以亲手感受模型参数如何影响其与数据的拟合程度。", "problem": "在非线性最小二乘拟合的背景下，一个常见的任务是最小化残差平方和。考虑一个描述某种物理现象的模型，由函数 $f(x, \\beta) = \\beta_1 \\sqrt{x} + \\beta_2$ 给出，其中 $\\beta = (\\beta_1, \\beta_2)^T$ 是待确定的参数向量。\n\n一次实验产生了两个数据点 $(x_i, y_i)$：第一个点是 $(4, 5)$，第二个点是 $(9, 7)$。\n\n第 $i$ 个数据点的残差定义为 $r_i(\\beta) = y_i - f(x_i, \\beta)$。残差向量 $r(\\beta)$ 是一个列向量，其分量是各个残差 $r_i(\\beta)$。\n\n给定参数的初始估计 $\\beta^{(0)} = (1, 3)^T$，计算相应的残差向量 $r(\\beta^{(0)})$。将您的最终答案表示为一个包含两个元素的行矩阵，其元素对应于残差向量的分量。", "solution": "给定模型 $f(x,\\beta)=\\beta_{1}\\sqrt{x}+\\beta_{2}$，残差 $r_{i}(\\beta)=y_{i}-f(x_{i},\\beta)$，数据点 $(x_{1},y_{1})=(4,5)$ 和 $(x_{2},y_{2})=(9,7)$，以及初始估计 $\\beta^{(0)}=(\\beta_{1}^{(0)},\\beta_{2}^{(0)})^{T}=(1,3)^{T}$。\n\n使用 $\\beta^{(0)}$ 计算在给定 $x_{i}$ 处的模型预测值：\n$$\nf(x_{1},\\beta^{(0)})=\\beta_{1}^{(0)}\\sqrt{x_{1}}+\\beta_{2}^{(0)}=1\\cdot\\sqrt{4}+3=2+3=5,\n$$\n$$\nf(x_{2},\\beta^{(0)})=\\beta_{1}^{(0)}\\sqrt{x_{2}}+\\beta_{2}^{(0)}=1\\cdot\\sqrt{9}+3=3+3=6.\n$$\n\n计算残差：\n$$\nr_{1}(\\beta^{(0)})=y_{1}-f(x_{1},\\beta^{(0)})=5-5=0,\n$$\n$$\nr_{2}(\\beta^{(0)})=y_{2}-f(x_{2},\\beta^{(0)})=7-6=1.\n$$\n\n因此，残差向量的分量为 $0$ 和 $1$。表示为包含两个元素的行矩阵，即为 $\\begin{pmatrix}0  1\\end{pmatrix}$。", "answer": "$$\\boxed{\\begin{pmatrix}0  1\\end{pmatrix}}$$", "id": "2214281"}, {"introduction": "理解了残差的定义后，下一步是探索高斯-牛顿法如何迭代地减小残差。这个练习将引导您完整地执行一次高斯-牛顿迭代 [@problem_id:2214282]。您将应用线性近似的核心思想，通过求解一个线性子问题来更新参数，从而具体地掌握该方法的迭代机制。", "problem": "在一项实验研究中，某个物理过程由函数 $y(x) = \\frac{x}{1+ax}$ 建模，其中 $a$ 是一个待确定的未知参数。一位研究人员收集了两个数据点 $(x_i, y_i)$：第一个点是 $(1, 0.5)$，第二个点是 $(2, 0.8)$。\n\n为了在最小二乘意义下找到最佳拟合数据的参数 $a$ 的最优值，该研究人员决定使用高斯-牛顿法。从初始猜测值 $a_0 = 1$ 开始，执行恰好一次高斯-牛顿法迭代，以找到该参数的更新估计值，记为 $a_1$。\n\n请将 $a_1$ 的答案表示为最简精确分数。", "solution": "我们用模型函数 $y(x;a)=\\dfrac{x}{1+a x}$ 对数据进行建模。残差定义为 $r_{i}(a)=y_i - y(x_{i};a)$。从 $a_0$ 开始对单个参数 $a$ 的高斯-牛顿更新公式为\n$$\n\\Delta a=-(J^{\\top}J)^{-1}J^{\\top}r,\n$$\n其中 $J_{i}=\\dfrac{\\partial r_{i}}{\\partial a}$ 是在 $a_{0}$ 处求得的雅可比矩阵元素，而 $r$ 是在 $a_{0}$ 处求得的残差向量。然后 $a_{1}=a_{0}+\\Delta a$。\n\n首先，计算雅可比矩阵。\n$$\nJ_i = \\frac{\\partial r_i}{\\partial a} = - \\frac{\\partial y(x_i;a)}{\\partial a} = - \\left( - \\frac{x_i^2}{(1+ax_i)^2} \\right) = \\frac{x_i^2}{(1+ax_i)^2}\n$$\n对于数据点 $(x_{1},y_{1})=(1,\\tfrac{1}{2})$ 和 $(x_{2},y_{2})=(2,\\tfrac{4}{5})$，以及初始猜测值 $a_{0}=1$，雅可比矩阵的各项为\n$$\nJ_{1}=\\frac{1^{2}}{(1+1)^{2}}=\\frac{1}{4},\\quad\nJ_{2}=\\frac{2^{2}}{(1+2)^{2}}=\\frac{4}{9}.\n$$\n\n在 $a_{0}=1$ 处的残差为\n$$\nr_{1}=y_1-y(1;1)=\\frac{1}{2}-\\frac{1}{2}=0,\\quad\nr_{2}=y_2-y(2;1)=\\frac{4}{5}-\\frac{2}{3}=\\frac{2}{15}.\n$$\n\n计算标量 $J^{\\top}r$ 和 $J^{\\top}J$：\n$$\nJ^{\\top}r=J_{1}r_{1}+J_{2}r_{2}=0+\\left(\\frac{4}{9}\\right)\\left(\\frac{2}{15}\\right)=\\frac{8}{135},\n$$\n$$\nJ^{\\top}J=J_{1}^{2}+J_{2}^{2}=\\left(\\frac{1}{4}\\right)^{2}+\\left(\\frac{4}{9}\\right)^{2}=\\frac{1}{16}+\\frac{16}{81}=\\frac{81+256}{1296}=\\frac{337}{1296}.\n$$\n\n因此，\n$$\n\\Delta a=-\\frac{J^{\\top}r}{J^{\\top}J}=-\\frac{\\frac{8}{135}}{\\frac{337}{1296}}=-\\frac{8}{135}\\cdot\\frac{1296}{337}=-\\frac{384}{1685}.\n$$\n\n所以，更新后的估计值为\n$$\na_{1}=a_{0}+\\Delta a=1-\\frac{384}{1685}=\\frac{1685-384}{1685}=\\frac{1301}{1685}.\n$$", "answer": "$$\\boxed{\\frac{1301}{1685}}$$", "id": "2214282"}, {"introduction": "尽管高斯-牛顿法很强大，但它有其局限性，尤其是在处理病态问题时。这个更深入的练习旨在揭示一个关键的失效模式：当雅可比矩阵 $J(x)$ 接近奇异时，算法会变得不稳定 [@problem_id:3232802]。通过编写代码实现标准高斯-牛顿算法及其Levenberg-Marquardt (LM) 稳定版本，您将亲身体会到阻尼项对于构建稳健优化求解器的重要性。", "problem": "您需要编写一个完整、可运行的程序，用于分析高斯-牛顿法及其 Levenberg-Marquardt (LM) 稳定化方法，应用于一个单参数非线性最小二乘问题。目标是通过原理性推导和具体实现来证明，当雅可比矩阵接近奇异时，无阻尼的高斯-牛顿步长可能会发生震荡或发散，而增加一个 Levenberg-Marquardt 阻尼项可以稳定迭代过程。\n\n从以下基本原理开始：\n- 非线性最小二乘的目标函数为 $F(x) = \\tfrac{1}{2}\\lVert r(x)\\rVert_2^2$，其中 $r(x)$ 是一个残差函数向量。\n- 在 $x$ 处的一阶泰勒线性化为 $r(x + \\Delta) \\approx r(x) + J(x)\\Delta$，其中 $J(x)$ 是 $r(x)$ 的雅可比矩阵。\n- 最小化该线性化模型可得到正规方程 $J(x)^\\top J(x)\\Delta = -J(x)^\\top r(x)$。\n- Levenberg-Marquardt (LM) 方法通过增加一个阻尼项 $\\lambda I$（其中 $I$ 是单位矩阵）来增广正规矩阵，求解 $\\big(J(x)^\\top J(x) + \\lambda I\\big)\\Delta = -J(x)^\\top r(x)$，其中 $\\lambda > 0$。\n\n您的程序必须实例化一个一维残差模型 $r(x) = \\sin(x)$（角度以弧度为单位），并执行高斯-牛顿（无阻尼，对应于 $\\lambda = 0$）和 Levenberg-Marquardt（有阻尼，使用指定的 $\\lambda > 0$）迭代。该残差模型意味着最小二乘目标函数为 $F(x) = \\tfrac{1}{2}\\sin^2(x)$。在这种情况下，雅可比矩阵 $J(x)$ 是一个标量。您必须：\n- 从基本定义推导出专用于一维残差 $r(x) = \\sin(x)$ 的高斯-牛顿和 LM 更新规则。\n- 使用推导出的更新规则为两种方法实现固定迭代次数的求解器。\n- 证明在 $J(x)$ 接近奇异的点附近（具体来说是 $x \\approx \\tfrac{\\pi}{2} + k\\pi$，其中 $k$ 为整数），无阻尼的高斯-牛顿迭代会表现出震荡或发散（大幅交替的步长或步长超出有界域），而带有正阻尼参数的 LM 方法通过限制步长大小来稳定迭代过程。\n\n角度必须以弧度为单位。不涉及任何物理单位。除了恒定的 LM 阻尼外，您的算法不得使用任何线搜索或信赖域自适应方法。\n\n测试套件和输出规范：\n- 使用以下测试用例，每个用例指定为一个元组 $(x_0, \\lambda, N, L)$：\n  1. 一个接近奇异的雅可比矩阵情况，以引发不稳定性：$x_0 = \\tfrac{\\pi}{2} - 10^{-6}$, $\\lambda = 1.0$, $N = 10$, $L = 50$。\n  2. 一个震荡但可恢复的情况：$x_0 = 1.4$, $\\lambda = 0.5$, $N = 10$, $L = 50$。\n  3. 一个远离奇异点的理想情况：$x_0 = 2.0$, $\\lambda = 0.1$, $N = 10$, $L = 50$。\n- 对于每个用例，运行 $N$ 次无阻尼高斯-牛顿迭代（即，对于高斯-牛顿法设置 $\\lambda = 0$）和 $N$ 次使用给定 $\\lambda$ 的 LM 迭代。对于每个用例中的每种方法，计算：\n  - 最终残差范数 $|r(x_N)|$，以浮点数形式表示。\n  - 一个布尔类型的稳定性标志，如果所有迭代点 $x_k$ 都满足 $|x_k| \\le L$ 则为真，否则为假。\n  - 最大步长 $\\max_k |\\Delta_k|$，以浮点数形式表示，其中 $\\Delta_k$ 是第 $k$ 次迭代的更新量。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。结果必须构造成一个列表的列表，每个内部列表对应一个测试用例，每个内部列表包含按以下顺序排列的六个条目：$[\\text{gn\\_final\\_residual}, \\text{lm\\_final\\_residual}, \\text{gn\\_stable}, \\text{lm\\_stable}, \\text{gn\\_max\\_step}, \\text{lm\\_max\\_step}]$。例如，输出格式必须类似于 $[[r_{11}, r_{12}, b_{11}, b_{12}, s_{11}, s_{12}], [r_{21}, r_{22}, b_{21}, b_{22}, s_{21}, s_{22}], [r_{31}, r_{32}, b_{31}, b_{32}, s_{31}, s_{32}]]$，其中 $r_{ij}$ 是浮点数，$b_{ij}$ 是布尔值。\n\n科学真实性和覆盖范围：\n- 接近奇异的情况强制了一个边界条件，在该条件下，无阻尼方法会遇到接近于零的雅可比矩阵，这可能导致巨大的步长。LM 阻尼项 $\\lambda I$ 必须能缓解这种不稳定性。\n- 震荡情况表现为无阻尼高斯-牛顿法产生大幅度的交替步长，而在 LM 阻尼作用下，这些步长会减小。\n- 理想情况展示了两种方法的收敛性。\n- 角度以弧度为单位。\n- 所有输出必须是指定的基本类型（布尔值和浮点数）。", "solution": "该问题要求对一个特定的一维非线性最小二乘问题，验证和实现高斯-牛顿（GN）法及其 Levenberg-Marquardt（LM）稳定化方法。其目标是展示当雅可比矩阵接近奇异时，LM 稳定化如何修正无阻尼高斯-牛顿法固有的不稳定性。\n\n首先，我们建立理论基础。一般的非线性最小二乘问题旨在最小化一个目标函数 $F(x)$，该函数定义为残差向量 $r(x)$ 的欧几里得范数平方的一半：\n$$\nF(x) = \\frac{1}{2}\\lVert r(x)\\rVert_2^2\n$$\n高斯-牛顿法在每次迭代中通过围绕当前迭代点 $x_k$ 线性化残差函数 $r(x)$ 来近似目标函数。更新步长 $\\Delta$ 通过求解以下线性化最小二乘问题得到：\n$$\n\\min_{\\Delta} \\frac{1}{2}\\lVert r(x_k) + J(x_k)\\Delta\\rVert_2^2\n$$\n其中 $J(x_k)$ 是 $r(x)$在 $x_k$ 处的雅可比矩阵。这个线性问题的解由以下正规方程给出：\n$$\nJ(x_k)^\\top J(x_k)\\Delta_{GN} = -J(x_k)^\\top r(x_k)\n$$\nLevenberg-Marquardt 方法引入一个阻尼参数 $\\lambda > 0$ 来对问题进行正则化，这在矩阵 $J(x_k)^\\top J(x_k)$ 奇异或病态时尤其有用。LM 更新步长 $\\Delta_{LM}$ 通过求解修正后的正规方程得到：\n$$\n\\left(J(x_k)^\\top J(x_k) + \\lambda I\\right)\\Delta_{LM} = -J(x_k)^\\top r(x_k)\n$$\n其中 $I$ 是单位矩阵。\n\n现在，我们将这些通用公式特化到给定的一维问题，其中残差是一个标量函数 $r(x) = \\sin(x)$。\n目标函数变为：\n$$\nF(x) = \\frac{1}{2}(r(x))^2 = \\frac{1}{2}\\sin^2(x)\n$$\n$F(x)$ 的最小值出现在 $\\sin(x) = 0$ 的地方，即对于任意整数 $n$，在 $x = n\\pi$ 处。\n在这个一维案例中，雅可比矩阵 $J(x)$ 是一个 $1 \\times 1$ 的矩阵（一个标量），对应于 $r(x)$ 的一阶导数：\n$$\nJ(x) = \\frac{dr}{dx} = \\frac{d}{dx}(\\sin(x)) = \\cos(x)\n$$\n当 $J(x) = \\cos(x) \\approx 0$ 时，雅可比矩阵是（接近）奇异的，这发生在 $x \\approx \\frac{\\pi}{2} + k\\pi$（对于任意整数 $k$）的情况下。\n\n我们为这两种方法推导具体的更新规则。\n对于高斯-牛顿法（无阻尼，等价于 $\\lambda=0$），正规方程为：\n$$\n(\\cos(x_k))^\\top (\\cos(x_k))\\Delta_{GN} = -(\\cos(x_k))^\\top (\\sin(x_k))\n$$\n$$\n\\cos^2(x_k) \\Delta_{GN} = -\\sin(x_k)\\cos(x_k)\n$$\n假设 $\\cos(x_k) \\neq 0$，我们可以解出步长 $\\Delta_{GN}$：\n$$\n\\Delta_{GN} = -\\frac{\\sin(x_k)\\cos(x_k)}{\\cos^2(x_k)} = -\\frac{\\sin(x_k)}{\\cos(x_k)} = -\\tan(x_k)\n$$\n因此，高斯-牛顿法的更新规则是：\n$$\nx_{k+1} = x_k + \\Delta_{GN} = x_k - \\tan(x_k)\n$$\n当 $x_k$ 接近雅可比矩阵奇异的点，即 $x_k \\to \\frac{\\pi}{2} + k\\pi$ 时，该方法的不稳定性变得很明显。在这些点，$\\cos(x_k) \\to 0$，导致 $|\\tan(x_k)| \\to \\infty$。更新步长 $\\Delta_{GN}$ 变得任意大，从而导致发散或剧烈震荡。\n\n对于 Levenberg-Marquardt 方法，修正后的正规方程包含阻尼项 $\\lambda > 0$。在这个一维案例中，单位矩阵 $I$ 是标量 $1$：\n$$\n(\\cos^2(x_k) + \\lambda)\\Delta_{LM} = -\\sin(x_k)\\cos(x_k)\n$$\n由于 $\\cos^2(x_k) \\ge 0$ 且 $\\lambda > 0$，项 $(\\cos^2(x_k) + \\lambda)$ 总是正的，并且以 $\\lambda$ 为下界远离零。因此，该系统总是良态的。LM 更新步长是：\n$$\n\\Delta_{LM} = -\\frac{\\sin(x_k)\\cos(x_k)}{\\cos^2(x_k) + \\lambda}\n$$\nLevenberg-Marquardt 的更新规则是：\n$$\nx_{k+1} = x_k + \\Delta_{LM} = x_k - \\frac{\\sin(x_k)\\cos(x_k)}{\\cos^2(x_k) + \\lambda}\n$$\n现在考虑奇异点附近的行为，此时 $\\cos(x_k) \\to 0$。在此极限下，分子 $\\sin(x_k)\\cos(x_k)$ 也趋近于 $0$。分母趋近于 $\\lambda$。因此，步长 $\\Delta_{LM}$ 趋近于 $0$。阻尼项有效地限制了步长大小，防止了在无阻尼高斯-牛顿法中观察到的灾难性行为。即使从雅可比矩阵奇异区域附近开始，这也能确保稳定性并促进收敛。\n\n接下来的实现将通过对给定的测试用例迭代这两个更新规则，来数值地展示这种推导出的行为。结果将量化最终残差、在给定界限内的迭代序列的稳定性以及所采取步长的大小。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Analyzes Gauss-Newton and Levenberg-Marquardt methods for a 1D\n    nonlinear least-squares problem, demonstrating LM stabilization.\n    \"\"\"\n\n    # Test cases as tuples of (x0, lambda, N, L)\n    test_cases = [\n        (np.pi / 2.0 - 1e-6, 1.0, 10, 50.0), # Near-singular Jacobian case\n        (1.4, 0.5, 10, 50.0),               # Oscillatory-but-recoverable case\n        (2.0, 0.1, 10, 50.0)                # Happy-path case\n    ]\n\n    results = []\n\n    def run_iterations(x0, N, L, damp_lambda):\n        \"\"\"\n        Performs N iterations of a solver for the objective F(x) = 0.5*sin^2(x).\n\n        Args:\n            x0 (float): Initial guess.\n            N (int): Number of iterations.\n            L (float): Stability bound for |x_k|.\n            damp_lambda (float): Damping parameter. If 0, use Gauss-Newton.\n                                 If > 0, use Levenberg-Marquardt.\n\n        Returns:\n            A tuple containing:\n            - final_residual (float): |r(x_N)|.\n            - is_stable (bool): True if all |x_k| = L.\n            - max_step (float): Maximum magnitude of any step delta_k.\n        \"\"\"\n        x = x0\n        stable = True\n        max_step_mag = 0.0\n\n        for _ in range(N):\n            # The Jacobian is singular when cos(x) is zero.\n            # Avoid division by zero for the pure Gauss-Newton case if x is exactly pi/2 + k*pi.\n            # np.tan will handle large values gracefully, returning inf.\n            cos_x = np.cos(x)\n            sin_x = np.sin(x)\n\n            if damp_lambda == 0:  # Gauss-Newton\n                # Delta = -tan(x)\n                # Avoid explicit division by zero if cos_x is extremely small.\n                # np.tan handles this by returning large numbers or inf.\n                delta = -np.tan(x)\n\n            else:  # Levenberg-Marquardt\n                # Delta = -sin(x)cos(x) / (cos^2(x) + lambda)\n                numerator = -sin_x * cos_x\n                denominator = cos_x**2 + damp_lambda\n                delta = numerator / denominator\n\n            if np.isinf(delta) or np.isnan(delta):\n                # If step is infinite/NaN, it's definitively unstable and huge.\n                # To assign a finite but large value for max_step.\n                # Using 2*L is arbitrary but indicates a large step.\n                current_step_mag = 2 * L \n                x = x + (2 * L * np.sign(-delta) if not np.isnan(delta) else 0)\n            else:\n                current_step_mag = abs(delta)\n\n            if current_step_mag > max_step_mag:\n                max_step_mag = current_step_mag\n\n            x = x + delta\n            \n            if abs(x) > L:\n                stable = False\n        \n        final_residual = abs(np.sin(x))\n        \n        return final_residual, stable, max_step_mag\n\n    for x0, lm_lambda, N, L in test_cases:\n        # Run Gauss-Newton (undamped, lambda = 0)\n        gn_final_residual, gn_stable, gn_max_step = run_iterations(x0, N, L, 0)\n\n        # Run Levenberg-Marquardt (damped)\n        lm_final_residual, lm_stable, lm_max_step = run_iterations(x0, N, L, lm_lambda)\n\n        case_results = [\n            gn_final_residual,\n            lm_final_residual,\n            gn_stable,\n            lm_stable,\n            gn_max_step,\n            lm_max_step,\n        ]\n        results.append(case_results)\n\n    # Format the final output string exactly as specified.\n    # The default str() representation for lists includes spaces, which is acceptable.\n    # The boolean values will be represented as 'True' and 'False'.\n    output_str = \"[\" + \",\".join(map(str, results)) + \"]\"\n    \n    print(output_str)\n\nsolve()\n```", "id": "3232802"}]}