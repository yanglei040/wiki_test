{"hands_on_practices": [{"introduction": "BFGS方法的核心在于割线条件 $H_{k+1}y_k = s_k$，它强制新的Hessian逆矩阵近似 $H_{k+1}$ 能够反映最近一步的曲率信息。这个练习将我们置于一个 $y_k$ 与 $s_k$ 平行的理想化场景中 [@problem_id:3166918]，旨在通过分析这个一维子空间上的变换，清晰地揭示割线条件如何直接决定更新后矩阵的行为，从而加深我们对BFGS更新机制核心思想的理解。", "problem": "考虑一个二阶连续可微函数 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$ 以及一个拟牛顿迭代，该迭代形成步长 $s_{k}=x_{k+1}-x_{k}$ 和梯度差 $y_{k}=\\nabla f(x_{k+1})-\\nabla f(x_{k})$。假设使用逆 Broyden-Fletcher-Goldfarb-Shanno (BFGS) 方法将一个对称正定的逆 Hessian 矩阵近似 $H_{k}$ 更新为 $H_{k+1}$。假设曲率条件 $y_{k}^{\\top}s_{k}0$ 成立，并且在这种特殊情况下，梯度差与步长平行，即对于某个标量 $c0$，有 $y_{k}=c\\,s_{k}$。\n\n从逆 BFGS 更新的基本性质出发（割线条件 $H_{k+1}y_{k}=s_{k}$、对称性、在曲率条件下保持正定性，以及编码了在割线条件下最小变化更新的标准逆 BFGS 公式），分析 $H_{k+1}$ 如何作用于由 $s_{k}$ 张成的一维子空间中的向量。具体来说，确定 $H_{k+1}$ 对任何平行于 $s_{k}$ 的向量进行缩放的确切标量。\n\n你的最终答案必须是关于 $c$ 的单个闭式解析表达式。不需要数值近似。", "solution": "该问题要求在特定条件下，分析用于近似逆 Hessian 矩阵 $H_{k}$ 的逆 Broyden-Fletcher-Goldfarb-Shanno (BFGS) 更新。我们需要确定更新后的矩阵 $H_{k+1}$ 对平行于步长向量 $s_{k}$ 的向量进行缩放的比例因子。\n\n首先，我们建立数学背景。给定一个二阶连续可微函数 $f:\\mathbb{R}^{n}\\to\\mathbb{R}$。一次拟牛顿方法的迭代产生步长 $s_{k} = x_{k+1} - x_{k}$ 和梯度差 $y_{k} = \\nabla f(x_{k+1}) - \\nabla f(x_{k})$。逆 Hessian 矩阵近似 $H_{k}$ 被假设为对称正定的。从 $H_{k}$ 到 $H_{k+1}$ 的更新是使用逆 BFGS 方法进行的。给定曲率条件 $y_{k}^{\\top}s_{k}0$ 成立。\n\n所提供的特殊条件是梯度差向量 $y_{k}$ 与步长向量 $s_{k}$ 平行，可以表示为 $y_{k}=c\\,s_{k}$，其中标量 $c0$。条件 $c0$ 与曲率条件一致，因为 $y_{k}^{\\top}s_{k} = (c\\,s_{k})^{\\top}s_{k} = c\\,s_{k}^{\\top}s_{k} = c\\,\\|s_{k}\\|^{2}$，只要 $s_{k} \\neq 0$，该值就大于 $0$。\n\n我们的目标是找到一个标量 $\\lambda$，使得对于任何平行于 $s_{k}$ 的向量 $v$，方程 $H_{k+1}v = \\lambda v$ 成立。任何这样的向量 $v$ 都可以写成 $v = \\alpha s_{k}$ 的形式，其中 $\\alpha \\in \\mathbb{R}$ 是一个标量。问题就简化为寻找矩阵 $H_{k+1}$ 对应于特征向量 $s_k$ 的特征值 $\\lambda$，即找到 $\\lambda$ 使得 $H_{k+1}s_{k} = \\lambda s_{k}$。\n\n问题陈述指引我们从逆 BFGS 更新的基本性质出发，其中之一就是割线条件。割线条件是对更新后的逆 Hessian 矩阵近似 $H_{k+1}$ 施加的一个要求，以确保它能正确地包含沿方向 $s_k$ 观测到的函数 $f$ 的曲率信息。该条件由下式给出：\n$$\nH_{k+1}y_{k} = s_{k}\n$$\n这个条件规定了 $H_{k+1}$ 对向量 $y_k$ 的作用。我们可以利用这个性质结合特殊条件 $y_k = c s_k$ 来直接解决问题。\n\n将 $y_k = c s_k$ 代入割线方程，我们得到：\n$$\nH_{k+1}(c\\,s_{k}) = s_{k}\n$$\n根据矩阵-向量乘法的线性性质，可以将标量 $c$ 提取出来：\n$$\nc\\,(H_{k+1}s_{k}) = s_{k}\n$$\n因为给定 $c0$，我们可以将方程两边同时除以 $c$ 来分离出 $H_{k+1}s_{k}$ 项：\n$$\nH_{k+1}s_{k} = \\frac{1}{c}s_{k}\n$$\n这个方程表明 $s_{k}$ 是矩阵 $H_{k+1}$ 的一个特征向量，对应的特征值为 $\\frac{1}{c}$。\n\n现在，考虑由 $s_k$ 张成的一维子空间中的任意向量 $v$。这样的向量可以写成 $v = \\alpha s_{k}$ 的形式，其中 $\\alpha$ 是一个标量。将 $H_{k+1}$ 应用于 $v$：\n$$\nH_{k+1}v = H_{k+1}(\\alpha s_{k}) = \\alpha (H_{k+1}s_{k}) = \\alpha \\left(\\frac{1}{c}s_{k}\\right) = \\frac{1}{c}(\\alpha s_{k}) = \\frac{1}{c}v\n$$\n这表明 $H_{k+1}$ 将任何平行于 $s_k$ 的向量按标量因子 $\\frac{1}{c}$ 进行缩放。\n\n为了完整起见，并确认此结果与完整的 BFGS 更新机制一致，我们可以分析标准的逆 BFGS 更新公式。正如问题中所述，该公式编码了在割线条件下的最小变化性质。该公式为：\n$$\nH_{k+1} = \\left(I - \\frac{s_{k}y_{k}^{\\top}}{y_{k}^{\\top}s_{k}}\\right) H_{k} \\left(I - \\frac{y_{k}s_{k}^{\\top}}{y_{k}^{\\top}s_{k}}\\right) + \\frac{s_{k}s_{k}^{\\top}}{y_{k}^{\\top}s_{k}}\n$$\n其中 $I$ 是单位矩阵。我们将 $y_{k}=c\\,s_{k}$ 代入此公式。分母变为 $y_{k}^{\\top}s_{k} = c\\,s_{k}^{\\top}s_{k}$。括号中的项变为：\n$$\n\\frac{s_{k}y_{k}^{\\top}}{y_{k}^{\\top}s_{k}} = \\frac{s_{k}(c\\,s_{k})^{\\top}}{c\\,s_{k}^{\\top}s_{k}} = \\frac{c\\,s_{k}s_{k}^{\\top}}{c\\,s_{k}^{\\top}s_{k}} = \\frac{s_{k}s_{k}^{\\top}}{s_{k}^{\\top}s_{k}}\n$$\n我们定义投影矩阵 $P_{s_k} = \\frac{s_{k}s_{k}^{\\top}}{s_{k}^{\\top}s_{k}}$。更新公式简化为：\n$$\nH_{k+1} = (I - P_{s_k}) H_{k} (I - P_{s_k}) + \\frac{s_{k}s_{k}^{\\top}}{c\\,s_{k}^{\\top}s_{k}} = (I - P_{s_k}) H_{k} (I - P_{s_k}) + \\frac{1}{c}P_{s_k}\n$$\n现在，我们将这个算子 $H_{k+1}$ 应用于向量 $s_{k}$：\n$$\nH_{k+1}s_{k} = \\left( (I - P_{s_k}) H_{k} (I - P_{s_k}) + \\frac{1}{c}P_{s_k} \\right) s_{k}\n$$\n我们将 $s_k$ 分配到各项中：\n$$\nH_{k+1}s_{k} = (I - P_{s_k}) H_{k} (I - P_{s_k})s_{k} + \\frac{1}{c}P_{s_k}s_{k}\n$$\n根据投影矩阵的定义，$P_{s_k}s_k = s_k$。因此，$(I - P_{s_k})s_k = s_k - P_{s_k}s_k = s_k - s_k = 0$。\n将此代入方程，第一项消失：\n$$\nH_{k+1}s_{k} = (I - P_{s_k}) H_{k} (0) + \\frac{1}{c}(s_{k})\n$$\n$$\nH_{k+1}s_{k} = 0 + \\frac{1}{c}s_{k} = \\frac{1}{c}s_{k}\n$$\n这证实了从割线条件直接得到的结果。$H_{k+1}$ 对任何平行于 $s_k$ 的向量进行缩放的标量是 $\\frac{1}{c}$。", "answer": "$$\\boxed{\\frac{1}{c}}$$", "id": "3166918"}, {"introduction": "BFGS更新的一个关键优势是它能保持Hessian逆近似矩阵的正定性，但这依赖于一个重要的前提：曲率条件 $y_k^\\top s_k \\gt 0$ 成立。本练习将引导我们探索当优化问题具有非凸性，导致曲率条件不被满足时的情形 [@problem_id:3167001]。我们将亲手计算一个无阻尼的BFGS更新如何失去正定性，并学习如何通过引入“阻尼”（damping）策略来修正更新，从而保证算法的稳定性和收敛性。", "problem": "考虑在 $\\mathbb{R}^{2}$ 上定义的二次目标函数 $f(x) = \\frac{1}{2} x^{\\top} A x$，其中 $A = \\begin{pmatrix}1  0 \\\\ 0  -1\\end{pmatrix}$。设当前迭代点为 $x_{k} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$，下一个迭代点为 $x_{k+1} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$，从而 $s_{k} = x_{k+1} - x_{k}$。设当前的逆 Hessian 近似矩阵为 $H_{k} = I$，并定义 $B_{k} = H_{k}^{-1}$。\n\n任务：\n1. 验证点 $x = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$ 是 $f$ 的一个鞍点，并计算 $s_{k}$ 和 $y_{k} = \\nabla f(x_{k+1}) - \\nabla f(x_{k})$。证明 $y_{k}^{\\top} s_{k} \\le 0$。\n2. 使用 Broyden–Fletcher–Goldfarb–Shanno (BFGS) 方法中的无阻尼逆更新公式，根据 $H_{k}$、$s_{k}$ 和 $y_{k}$ 计算 $H_{k+1}$，并证明 $H_{k+1}$ 不是正定的。\n3. 为了恢复正定性，考虑一种阻尼策略，该策略用阻尼向量 $\\bar{y}_{k} = \\theta y_{k} + (1 - \\theta) B_{k} s_{k}$ 替换 $y_{k}$，其中参数 $\\theta \\in (0,1]$。施加曲率条件 $s_{k}^{\\top} \\bar{y}_{k} = \\delta \\, s_{k}^{\\top} B_{k} s_{k}$，其中 $\\delta = \\frac{1}{5}$。确定在 $(0,1]$ 中满足此等式的最大 $\\theta$，然后计算相应的阻尼更新 $H_{k+1}$ 以验证其正定性。\n\n答案规格：将 $\\theta$ 的值报告为最简精确有理数。不需要四舍五入。", "solution": "该问题提法明确，且基于数值优化的原理，特别是关于拟牛顿法中的 Broyden–Fletcher–Goldfarb–Shanno (BFGS) 更新的性质。我们将给出完整的解答。\n\n目标函数为 $f(x) = \\frac{1}{2} x^{\\top} A x$，其中 $x \\in \\mathbb{R}^{2}$，$A = \\begin{pmatrix}1  0 \\\\ 0  -1\\end{pmatrix}$。它可以写成 $f(x_1, x_2) = \\frac{1}{2}(x_1^2 - x_2^2)$。\n\n### 任务1：鞍点和曲率条件\n\n首先，我们计算目标函数的梯度 $\\nabla f(x)$ 和 Hessian 矩阵 $\\nabla^2 f(x)$。\n梯度由 $\\nabla f(x) = A x = \\begin{pmatrix}1  0 \\\\ 0  -1\\end{pmatrix} \\begin{pmatrix}x_1 \\\\ x_2\\end{pmatrix} = \\begin{pmatrix}x_1 \\\\ -x_2\\end{pmatrix}$ 给出。\nHessian 矩阵是常数矩阵 $\\nabla^2 f(x) = A = \\begin{pmatrix}1  0 \\\\ 0  -1\\end{pmatrix}$。\n\n为验证 $x = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$ 是一个鞍点，我们检查一阶和二阶条件。\n1.  在 $x = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$ 处的梯度是 $\\nabla f(\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}) = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$，证实了它是一个临界点。\n2.  Hessian 矩阵 $A$ 的特征值为 $\\lambda_1 = 1$ 和 $\\lambda_2 = -1$。由于特征值符号相反，该 Hessian 矩阵是不定的。具有不定 Hessian 矩阵的临界点是一个鞍点。\n\n接下来，我们计算向量 $s_k$ 和 $y_k$。\n给定的迭代点为 $x_{k} = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$ 和 $x_{k+1} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$。\n步长向量 $s_k$ 定义为 $s_{k} = x_{k+1} - x_{k}$：\n$$s_k = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} - \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix}$$\n向量 $y_k$ 定义为梯度的变化量，即 $y_{k} = \\nabla f(x_{k+1}) - \\nabla f(x_{k})$。\n$\\nabla f(x_{k}) = \\nabla f(\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}) = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$。\n$\\nabla f(x_{k+1}) = \\nabla f(\\begin{pmatrix}0 \\\\ 1\\end{pmatrix}) = \\begin{pmatrix}0 \\\\ -1\\end{pmatrix}$。\n因此，\n$$y_k = \\begin{pmatrix}0 \\\\ -1\\end{pmatrix} - \\begin{pmatrix}0 \\\\ 0\\end{pmatrix} = \\begin{pmatrix}0 \\\\ -1\\end{pmatrix}$$\n现在我们检查曲率 $y_k^\\top s_k$ 的符号：\n$$y_k^\\top s_k = \\begin{pmatrix}0  -1\\end{pmatrix} \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} = (0)(0) + (-1)(1) = -1$$\n由于 $y_k^\\top s_k = -1 \\le 0$，BFGS 方法的标准曲率条件未被满足，该条件要求 $y_k^\\top s_k  0$ 以保证更新后的 Hessian 近似矩阵的正定性。\n\n### 任务2：无阻尼 BFGS 更新\n\n逆 BFGS 更新公式由下式给出：\n$$H_{k+1} = H_k - \\frac{H_k y_k y_k^\\top H_k}{y_k^\\top H_k y_k} + \\frac{s_k s_k^\\top}{s_k^\\top y_k}$$\n我们已知初始的逆 Hessian 近似矩阵为 $H_k = I = \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix}$。\n我们计算更新所需的各个部分：\n$s_k s_k^\\top = \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} \\begin{pmatrix}0  1\\end{pmatrix} = \\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix}$。\n$y_k^\\top H_k y_k = y_k^\\top I y_k = y_k^\\top y_k = \\begin{pmatrix}0  -1\\end{pmatrix}\\begin{pmatrix}0 \\\\ -1\\end{pmatrix} = 1$。\n$H_k y_k y_k^\\top H_k = I y_k y_k^\\top I = y_k y_k^\\top = \\begin{pmatrix}0 \\\\ -1\\end{pmatrix} \\begin{pmatrix}0  -1\\end{pmatrix} = \\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix}$。\n我们有 $s_k^\\top y_k = -1$。\n将这些代入更新公式：\n$$H_{k+1} = \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix} - \\frac{\\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix}}{1} + \\frac{\\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix}}{-1} = \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix} - \\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix} - \\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix} = \\begin{pmatrix}1  0 \\\\ 0  -1\\end{pmatrix}$$\n为了检查 $H_{k+1}$ 是否为正定矩阵，我们使用 Sylvester 准则。所有顺序主子式必须为正。\n第一个顺序主子式是 $H_{11} = 1  0$。\n第二个顺序主子式是 $\\det(H_{k+1}) = (1)(-1) - (0)(0) = -1$。\n由于行列式为负，$H_{k+1}$ 不是正定的。\n\n### 任务3：阻尼 BFGS 更新\n\n为了恢复正定性，我们使用一种阻尼策略。向量 $y_k$ 被 $\\bar{y}_k = \\theta y_k + (1-\\theta) B_k s_k$ 替换，其中 $\\theta \\in (0, 1]$。我们已知 $H_k = I$，所以它的逆矩阵，即直接的 Hessian 近似矩阵，是 $B_k = H_k^{-1} = I$。\n阻尼向量变为 $\\bar{y}_k = \\theta y_k + (1-\\theta) s_k$。\n\n参数 $\\theta$ 通过施加修正后的曲率条件 $s_k^\\top \\bar{y}_k = \\delta s_k^\\top B_k s_k$ 来确定，其中 $\\delta = \\frac{1}{5}$。\n代入 $\\bar{y}_k$ 的表达式和 $B_k=I$：\n$$s_k^\\top (\\theta y_k + (1-\\theta) s_k) = \\frac{1}{5} s_k^\\top s_k$$\n展开左侧得到：\n$$\\theta (s_k^\\top y_k) + (1-\\theta) (s_k^\\top s_k) = \\frac{1}{5} (s_k^\\top s_k)$$\n我们有之前计算出的值 $s_k^\\top y_k = -1$ 和 $s_k^\\top s_k = \\begin{pmatrix}0  1\\end{pmatrix}\\begin{pmatrix}0 \\\\ 1\\end{pmatrix} = 1$。\n将这些值代入关于 $\\theta$ 的方程中：\n$$\\theta(-1) + (1-\\theta)(1) = \\frac{1}{5}(1)$$\n$$-\\theta + 1 - \\theta = \\frac{1}{5}$$\n$$1 - 2\\theta = \\frac{1}{5}$$\n$$2\\theta = 1 - \\frac{1}{5} = \\frac{4}{5}$$\n$$\\theta = \\frac{2}{5}$$\n这个值位于指定的区间 $(0, 1]$ 内，因此是所要求的值。\n\n我们现在使用这个 $\\theta$ 来计算 $H_{k+1}$ 的阻尼更新。\n首先，我们求出阻尼向量 $\\bar{y}_k$：\n$$\\bar{y}_k = \\frac{2}{5} y_k + \\left(1-\\frac{2}{5}\\right) s_k = \\frac{2}{5} \\begin{pmatrix}0 \\\\ -1\\end{pmatrix} + \\frac{3}{5} \\begin{pmatrix}0 \\\\ 1\\end{pmatrix} = \\begin{pmatrix}0 \\\\ -2/5\\end{pmatrix} + \\begin{pmatrix}0 \\\\ 3/5\\end{pmatrix} = \\begin{pmatrix}0 \\\\ 1/5\\end{pmatrix}$$\n新的曲率项是 $s_k^\\top \\bar{y}_k = \\begin{pmatrix}0  1\\end{pmatrix} \\begin{pmatrix}0 \\\\ 1/5\\end{pmatrix} = \\frac{1}{5}$。这是正数，符合要求。\n\n我们使用 $\\bar{y}_k$ 应用 BFGS 更新公式：\n$$H_{k+1} = H_k - \\frac{H_k \\bar{y}_k \\bar{y}_k^\\top H_k}{\\bar{y}_k^\\top H_k \\bar{y}_k} + \\frac{s_k s_k^\\top}{s_k^\\top \\bar{y}_k}$$\n让我们计算各个组成部分：\n$\\bar{y}_k^\\top H_k \\bar{y}_k = \\bar{y}_k^\\top I \\bar{y}_k = \\bar{y}_k^\\top \\bar{y}_k = \\begin{pmatrix}0  1/5\\end{pmatrix}\\begin{pmatrix}0 \\\\ 1/5\\end{pmatrix} = \\frac{1}{25}$。\n$H_k \\bar{y}_k \\bar{y}_k^\\top H_k = \\bar{y}_k \\bar{y}_k^\\top = \\begin{pmatrix}0 \\\\ 1/5\\end{pmatrix} \\begin{pmatrix}0  1/5\\end{pmatrix} = \\begin{pmatrix}0  0 \\\\ 0  1/25\\end{pmatrix}$。\n$s_k s_k^\\top = \\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix}$。\n将这些代入 $H_{k+1}$ 的公式中：\n$$H_{k+1} = \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix} - \\frac{\\begin{pmatrix}0  0 \\\\ 0  1/25\\end{pmatrix}}{1/25} + \\frac{\\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix}}{1/5}$$\n$$H_{k+1} = \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix} - \\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix} + 5 \\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix} = \\begin{pmatrix}1  0 \\\\ 0  1\\end{pmatrix} + 4 \\begin{pmatrix}0  0 \\\\ 0  1\\end{pmatrix} = \\begin{pmatrix}1  0 \\\\ 0  5\\end{pmatrix}$$\n为验证该矩阵是正定的，我们检查它的特征值，即其对角线元素 $1$ 和 $5$。由于它们都为正，该矩阵是正定的。或者，顺序主子式为 $10$ 和 $\\det(H_{k+1}) = 5  0$，这也证实了其正定性。\n\n确定的 $\\theta$ 值为 $\\frac{2}{5}$。", "answer": "$$\\boxed{\\frac{2}{5}}$$", "id": "3167001"}, {"introduction": "BFGS算法最引人注目的特性之一是其“自校正”能力：即使从一个非常糟糕的初始Hessian逆近似 $H_0$ 开始，后续的迭代也会系统性地改进该近似。这个编程练习将让你通过在凸二次函数上实现带有精确线搜索的BFGS算法，来亲眼见证这一强大特性 [@problem_id:3166990]。通过量化度量 $\\| H_K A - I \\|_2$ 的衰减，你将具体地观察到近似矩阵 $H_k$ 是如何逐步收敛于真实Hessian矩阵的逆 $A^{-1}$ 的。", "problem": "考虑一个光滑无约束优化问题，其目标函数为凸二次函数，定义为 $f(x) = \\tfrac{1}{2} x^{\\top} A x - b^{\\top} x$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是对称正定矩阵，$b \\in \\mathbb{R}^{n}$，$x \\in \\mathbb{R}^{n}$。其梯度为 $\\nabla f(x) = A x - b$。拟牛顿法构造迭代序列 $x_{k+1} = x_k + \\alpha_k p_k$，其中 $p_k = - H_k \\nabla f(x_k)$，$H_k$ 是对海森矩阵逆的近似。Broyden–Fletcher–Goldfarb–Shanno (BFGS) 方法是一种拟牛顿方案，它强制执行割线条件 $H_{k+1} y_k = s_k$（其中 $s_k = x_{k+1} - x_k$ 且 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$），并通过一个在满足割线条件下最小化变化的秩二校正，以保持对称性和正定性的方式将 $H_k$ 更新为 $H_{k+1}$。\n\n您将为凸二次函数实现一个BFGS算法，该算法沿选定方向 $p_k$ 使用精确线搜索。精确线搜索的步长必须是 $\\phi(\\alpha) = f(x_k + \\alpha p_k)$ 沿该射线的最小值点；对于凸二次函数 $f$，该最小值点是唯一确定的。使用以下基本依据和定义：\n- 如上所述的目标函数 $f(x)$ 和梯度 $\\nabla f(x)$。\n- $s_k$、$y_k$ 和割线条件的定义。\n- 针对凸二次函数沿方向 $p_k$ 的精确线搜索。\n\n您的任务是：\n1. 从所述基本依据出发，推导 BFGS 逆海森矩阵更新公式，该公式强制执行割线条件 $H_{k+1} y_k = s_k$，在 $y_k^{\\top} s_k  0$ 时保持对称性和正定性，并且源于最小变化原则。解释为什么对凸二次函数进行精确线搜索能确保 $y_k^{\\top} s_k  0$。\n2. 使用您推导的更新公式，实现一个程序，对下述每个测试用例，从指定的初始向量 $x_0$ 和初始逆海森矩阵近似 $H_0$ 开始，执行带有精确线搜索的 BFGS 迭代。对每个测试用例，精确运行 $K$ 次迭代，除非因 $\\| \\nabla f(x_k) \\|$ 足够小或公式中的分母在数值上可忽略而导致迭代无法定义；在这种情况下，提前停止。完成后，计算谱范数衰减度量 $\\| H_K A - I \\|_2$，其中 $I$ 是 $n \\times n$ 单位矩阵，$\\| \\cdot \\|_2$ 是矩阵算子二范数（最大奇异值）。这个量在数值上反映了自校正特性：即使 $H_0$ 很差，对凸二次函数重复进行 BFGS 更新也会驱使 $H_k$ 趋向于 $A^{-1}$。\n3. 生成最终的程序输出，格式为单行，内容是方括号内包含的逗号分隔列表，该列表包含所提供测试套件的 $\\| H_K A - I \\|_2$ 最终值，并按下述顺序排列。这些输出是无量纲的实数。\n\n测试套件：\n- 用例 $1$（$H_0$ 缩放不佳的理想情况）：\n  - $n = 3$\n  - $$A_1 = \\begin{bmatrix} 4  1  0 \\\\ 1  3  0 \\\\ 0  0  2 \\end{bmatrix}, \\quad b_1 = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}.$$\n  - $$x_{0,1} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad H_{0,1} = 0.1 \\, I_3.$$\n  - 迭代次数 $K_1 = 3$。\n- 用例 $2$（$H_0 = A^{-1}$ 的边界情况）：\n  - $n = 3$\n  - $$A_2 = \\begin{bmatrix} 2  0  0 \\\\ 0  5  0 \\\\ 0  0  1 \\end{bmatrix}, \\quad b_2 = \\begin{bmatrix} 1 \\\\ -1 \\\\ 2 \\end{bmatrix}.$$\n  - $$x_{0,2} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad H_{0,2} = A_2^{-1}.$$\n  - 迭代次数 $K_2 = 3$。\n- 用例 $3$（病态二次函数）：\n  - $n = 3$\n  - $$A_3 = \\begin{bmatrix} 10^{-3}  0  0 \\\\ 0  1  0 \\\\ 0  0  10^{3} \\end{bmatrix}, \\quad b_3 = \\begin{bmatrix} 1 \\\\ 1 \\\\ 1 \\end{bmatrix}.$$\n  - $$x_{0,3} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad H_{0,3} = I_3.$$\n  - 迭代次数 $K_3 = 3$。\n- 用例 $4$（方向不佳但对称正定的 $H_0$）：\n  - $n = 3$\n  - $$A_4 = \\begin{bmatrix} 6  2  1 \\\\ 2  5  0 \\\\ 1  0  3 \\end{bmatrix}, \\quad b_4 = \\begin{bmatrix} 0.5 \\\\ -1 \\\\ 2 \\end{bmatrix}.$$\n  - $$x_{0,4} = \\begin{bmatrix} 0 \\\\ 0 \\\\ 0 \\end{bmatrix}, \\quad H_{0,4} = \\begin{bmatrix} 3  1  0 \\\\ 1  1  0 \\\\ 0  0  0.5 \\end{bmatrix}.$$\n  - 迭代次数 $K_4 = 3$。\n\n实现细节：\n- 对凸二次函数 $f$ 沿 $p_k$ 使用精确线搜索来确定 $\\alpha_k$，$\\alpha_k$ 是 $f(x_k + \\alpha p_k)$ 沿方向 $p_k$ 的唯一最小值点。\n- 如果 $\\| \\nabla f(x_k) \\|_2 \\leq 10^{-12}$，或 $p_k^{\\top} A p_k \\leq 10^{-14}$，或 $y_k^{\\top} s_k \\leq 10^{-14}$ 会导致更新无定义，则提前停止。\n- 对每个用例完成迭代后，计算单个浮点数 $\\| H_K A - I \\|_2$。\n- 您的程序应生成单行输出，其中包含一个方括号括起来的逗号分隔列表，按 $[r_1, r_2, r_3, r_4]$ 的顺序排列，其中 $r_i$ 对应于用例 $i$。\n\n本问题不涉及物理单位或角度单位。所有输出必须是无单位的实数。", "solution": "此问题有效。它在科学上基于凸优化理论，特别是拟牛顿法。问题提法清晰，为执行指定次数迭代的BFGS算法提供了所有必要的定义、初始条件和参数。定义凸二次目标的矩阵是对称正定的，初始逆海森矩阵近似也是对称正定的，确保了问题设置的一致性和可行性。\n\n### 1. 推导与理论背景\n\nBroyden–Fletcher–Goldfarb–Shanno (BFGS) 方法是一种用于无约束优化的拟牛顿算法。它通过迭代构建海森矩阵逆的近似 $H_k$。从 $H_k$ 到 $H_{k+1}$ 的更新旨在满足几个关键属性。\n\n#### 1.1 BFGS 逆海森矩阵更新\n\nBFGS 更新的推导旨在满足割线条件、保持对称性并维持正定性。对于从 $x_k$ 到 $x_{k+1}$ 的移动，我们定义位移 $s_k$ 和梯度变化 $y_k$：\n$$ s_k = x_{k+1} - x_k $$\n$$ y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k) $$\n割线条件要求新的逆海森矩阵近似 $H_{k+1}$ 将 $y_k$ 映射到 $s_k$：\n$$ H_{k+1} y_k = s_k $$\n对于二次函数 $f(x) = \\frac{1}{2}x^{\\top} A x - b^{\\top} x$，其梯度为 $\\nabla f(x) = Ax-b$。因此，$y_k = (Ax_{k+1}-b) - (Ax_k-b) = A(x_{k+1}-x_k) = As_k$。割线条件于是变为 $H_{k+1} A s_k = s_k$，这意味着 $H_{k+1}$ 在 $s_k$ 方向上充当 $A$ 的逆。\n\n逆海森矩阵 $H_k$ 的 BFGS 更新是满足割线条件并最小化加权弗罗贝尼乌斯范数变化量 $\\|H_k^{-1/2}(H_{k+1}-H_k)H_k^{-1/2}\\|_F$ 的唯一对称更新。最终的更新公式是对 $H_k$ 的一个秩二校正：\n$$ H_{k+1} = \\left(I - \\frac{s_k y_k^{\\top}}{y_k^{\\top} s_k}\\right) H_k \\left(I - \\frac{y_k s_k^{\\top}}{y_k^{\\top} s_k}\\right) + \\frac{s_k s_k^{\\top}}{y_k^{\\top} s_k} $$\n其中 $I$ 是单位矩阵。\n\n我们来验证其性质：\n1.  **割线条件**：我们必须证明 $H_{k+1} y_k = s_k$。令 $\\rho_k = 1 / (y_k^{\\top} s_k)$。\n    $$ H_{k+1} y_k = \\left(I - \\rho_k s_k y_k^{\\top}\\right) H_k \\left(I - \\rho_k y_k s_k^{\\top}\\right) y_k + \\rho_k s_k s_k^{\\top} y_k $$\n    项 $\\left(I - \\rho_k y_k s_k^{\\top}\\right) y_k$ 可简化为 $y_k - \\rho_k y_k (s_k^{\\top} y_k) = y_k - \\frac{1}{y_k^{\\top} s_k} y_k (y_k^{\\top} s_k) = y_k - y_k = 0$。\n    因此，表达式的第一部分为零：\n    $$ H_{k+1} y_k = 0 + \\rho_k s_k (s_k^{\\top} y_k) = \\frac{1}{y_k^{\\top} s_k} s_k (y_k^{\\top} s_k) = s_k $$\n    割线条件得以满足。\n\n2.  **对称性**：如果 $H_k$ 是对称的（$H_k = H_k^{\\top}$），那么 $H_{k+1}$ 也必须是对称的。项 $\\frac{s_k s_k^{\\top}}{y_k^{\\top} s_k}$ 是一个由标量缩放的外积，因此它是对称的。第一项的形式为 $M H_k M^{\\top}$，其中 $M = (I - \\rho_k s_k y_k^{\\top})$，这并不直接显示为对称。然而，其形式是 $M H_k (M')^T$，其中 $M' = (I - \\rho_k s_k y_k^T)$ 而不是 $(I - \\rho_k y_k s_k^T)$。让我们重新检查公式：$(I - \\rho_k y_k s_k^{\\top})^{\\top} = I - \\rho_k (s_k y_k^{\\top})^{\\top} = I - \\rho_k y_k s_k^{\\top}$。所以，我们检查第一项的转置：\n    $$ \\left[ \\left(I - \\rho_k s_k y_k^{\\top}\\right) H_k \\left(I - \\rho_k y_k s_k^{\\top}\\right) \\right]^{\\top} = \\left(I - \\rho_k y_k s_k^{\\top}\\right)^{\\top} H_k^{\\top} \\left(I - \\rho_k s_k y_k^{\\top}\\right)^{\\top} $$\n    $$ = \\left(I - \\rho_k s_k y_k^{\\top}\\right) H_k \\left(I - \\rho_k y_k s_k^{\\top}\\right) $$\n    第一项是对称的，因此 $H_{k+1}$ 也是对称的。\n\n3.  **正定性**：如果 $H_k$ 是正定的，并且曲率条件 $y_k^{\\top} s_k  0$ 成立，那么 $H_{k+1}$ 也是正定的。对于任意非零向量 $z \\in \\mathbb{R}^n$，我们有：\n    $$ z^{\\top} H_{k+1} z = z^{\\top}\\left(I - \\rho_k s_k y_k^{\\top}\\right) H_k \\left(I - \\rho_k y_k s_k^{\\top}\\right)z + \\rho_k z^{\\top}s_k s_k^{\\top}z $$\n    令 $v = (I - \\rho_k y_k s_k^{\\top})z$。第一项变为 $v^{\\top} H_k v$。由于 $H_k$ 是正定的，所以 $v^{\\top} H_k v \\ge 0$。第二项是 $\\rho_k (z^{\\top}s_k)^2 = \\frac{(z^{\\top}s_k)^2}{y_k^{\\top}s_k}$。由于 $y_k^{\\top}s_k  0$，该项也是非负的。两项之和为零的唯一情况是两项都为零，这意味着 $z$ 是 $y_k$ 的倍数，并且也与 $s_k$ 正交，这只有在 $z=0$ 时才会发生。因此 $H_{k+1}$ 是正定的。\n\n#### 1.2 曲率条件与精确线搜索\n\n正定性的保持取决于曲率条件 $y_k^{\\top} s_k  0$。对于具有对称正定（SPD）海森矩阵 $A$ 的凸二次目标函数 $f(x)$，通过精确线搜索可以保证此条件成立。\n步长为 $s_k = \\alpha_k p_k$，其中 $p_k = -H_k \\nabla f(x_k)$。由于 $H_k$ 是对称正定的，如果 $\\nabla f(x_k) \\ne 0$，则 $p_k$ 是一个下降方向：\n$$ \\nabla f(x_k)^{\\top} p_k = - \\nabla f(x_k)^{\\top} H_k \\nabla f(x_k)  0 $$\n如前所示，对于二次函数，$y_k = A s_k$。因此：\n$$ y_k^{\\top} s_k = (A s_k)^{\\top} s_k = s_k^{\\top} A s_k $$\n由于 $A$ 是对称正定的，对于任何非零的 $s_k$ 都有 $s_k^{\\top} A s_k  0$。向量 $s_k = \\alpha_k p_k$ 是非零的，因为 $p_k \\ne 0$（如果未达到最优点），并且对于下降方向，通过精确线搜索得到的步长 $\\alpha_k$ 将为正。\n\n#### 1.3 二次函数的精确线搜索\n\n精确线搜索步长 $\\alpha_k$ 使得 $\\phi(\\alpha) = f(x_k + \\alpha p_k)$ 最小化。\n$$ \\phi(\\alpha) = \\frac{1}{2}(x_k + \\alpha p_k)^{\\top}A(x_k + \\alpha p_k) - b^{\\top}(x_k + \\alpha p_k) $$\n为了找到最小值，我们将关于 $\\alpha$ 的导数设为零：\n$$ \\frac{d\\phi}{d\\alpha} = \\nabla f(x_k + \\alpha p_k)^{\\top} p_k = 0 $$\n新点的梯度是 $\\nabla f(x_k + \\alpha p_k) = A(x_k + \\alpha p_k) - b = (Ax_k - b) + \\alpha A p_k = \\nabla f(x_k) + \\alpha A p_k$。\n将此代入导数方程：\n$$ (\\nabla f(x_k) + \\alpha A p_k)^{\\top} p_k = 0 $$\n$$ \\nabla f(x_k)^{\\top} p_k + \\alpha p_k^{\\top} A p_k = 0 $$\n求解 $\\alpha$ 可得最优步长 $\\alpha_k$：\n$$ \\alpha_k = - \\frac{\\nabla f(x_k)^{\\top} p_k}{p_k^{\\top} A p_k} $$\n由于 $p_k$ 是下降方向，分子为正。由于 $A$ 是对称正定的，分母也为正。因此，$\\alpha_k  0$。\n\n### 2. 算法摘要\n\n对于每个测试用例，算法按以下步骤进行：\n1.  初始化 $x_0$ 和 $H_0$。\n2.  对于 $k = 0, 1, \\dots, K-1$：\n    a.  计算梯度 $g_k = \\nabla f(x_k) = A x_k - b$。\n    b.  检查收敛性：如果 $\\| g_k \\|_2$ 低于容差（$10^{-12}$），则终止循环。\n    c.  计算搜索方向 $p_k = -H_k g_k$。\n    d.  计算精确线搜索步长 $\\alpha_k = - (g_k^{\\top} p_k) / (p_k^{\\top} A p_k)$。检查分母是否接近于零（$10^{-14}$），如果是则终止。\n    e.  更新位置：$x_{k+1} = x_k + \\alpha_k p_k$。\n    f.  计算 $s_k = x_{k+1} - x_k$ 和 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$。\n    g.  检查曲率条件：如果 $y_k^{\\top} s_k$ 低于容差（$10^{-14}$），则终止循环。\n    h.  使用上面推导的公式执行 BFGS 更新以找到 $H_{k+1}$。\n    i.  设置 $x_k \\leftarrow x_{k+1}$ 和 $H_k \\leftarrow H_{k+1}$。\n3.  循环结束后，计算最终度量 $\\|H_K A - I\\|_2$，其中 $H_K$ 是最终的逆海森矩阵近似。\n\n此过程将为问题陈述中提供的每个测试用例实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_bfgs(A, b, x0, H0, K_max):\n    \"\"\"\n    Performs BFGS iterations for a convex quadratic with exact line search.\n\n    Args:\n        A (np.ndarray): The symmetric positive definite matrix of the quadratic objective.\n        b (np.ndarray): The linear term vector of the quadratic objective.\n        x0 (np.ndarray): The initial point.\n        H0 (np.ndarray): The initial inverse Hessian approximation.\n        K_max (int): The maximum number of iterations.\n\n    Returns:\n        float: The spectral norm of (H_final * A - I).\n    \"\"\"\n    n = A.shape[0]\n    x_k = x0.copy()\n    H_k = H0.copy()\n    identity = np.identity(n)\n\n    for k in range(K_max):\n        # Step a: Compute gradient\n        grad_k = A @ x_k - b\n\n        # Step b: Check for convergence\n        grad_norm = np.linalg.norm(grad_k)\n        if grad_norm = 1e-12:\n            break\n\n        # Step c: Compute search direction\n        p_k = -H_k @ grad_k\n        \n        # Step d: Compute exact line search step size\n        denom_alpha = p_k.T @ A @ p_k\n        if denom_alpha = 1e-14:\n            break\n            \n        alpha_k = -(grad_k.T @ p_k) / denom_alpha\n\n        # Step e: Update position\n        x_k_plus_1 = x_k + alpha_k * p_k\n\n        # Step f: Define s_k and y_k\n        s_k = x_k_plus_1 - x_k\n        grad_k_plus_1 = A @ x_k_plus_1 - b\n        y_k = grad_k_plus_1 - grad_k\n        \n        # Step g: Check curvature condition\n        y_k_T_s_k = y_k.T @ s_k\n        if y_k_T_s_k = 1e-14:\n            break\n            \n        # Step h: Perform the BFGS update\n        rho_k = 1.0 / y_k_T_s_k\n        \n        term1 = identity - rho_k * np.outer(s_k, y_k)\n        term2 = identity - rho_k * np.outer(y_k, s_k)\n        \n        H_k_plus_1 = term1 @ H_k @ term2 + rho_k * np.outer(s_k, s_k)\n\n        # Step i: Update for next iteration\n        x_k = x_k_plus_1\n        H_k = H_k_plus_1\n\n    # After loop, compute the final metric\n    metric = np.linalg.norm(H_k @ A - identity, ord=2)\n    return metric\n\ndef solve():\n    \"\"\"\n    Solves the optimization problem for all test cases and prints the results.\n    \"\"\"\n    # Case 1\n    A1 = np.array([[4, 1, 0], [1, 3, 0], [0, 0, 2]], dtype=float)\n    b1 = np.array([1, 2, 3], dtype=float)\n    x0_1 = np.array([0, 0, 0], dtype=float)\n    H0_1 = 0.1 * np.identity(3)\n    K1 = 3\n\n    # Case 2\n    A2 = np.array([[2, 0, 0], [0, 5, 0], [0, 0, 1]], dtype=float)\n    b2 = np.array([1, -1, 2], dtype=float)\n    x0_2 = np.array([0, 0, 0], dtype=float)\n    H0_2 = np.linalg.inv(A2)\n    K2 = 3\n\n    # Case 3\n    A3 = np.array([[1e-3, 0, 0], [0, 1, 0], [0, 0, 1e3]], dtype=float)\n    b3 = np.array([1, 1, 1], dtype=float)\n    x0_3 = np.array([0, 0, 0], dtype=float)\n    H0_3 = np.identity(3)\n    K3 = 3\n\n    # Case 4\n    A4 = np.array([[6, 2, 1], [2, 5, 0], [1, 0, 3]], dtype=float)\n    b4 = np.array([0.5, -1, 2], dtype=float)\n    x0_4 = np.array([0, 0, 0], dtype=float)\n    H0_4 = np.array([[3, 1, 0], [1, 1, 0], [0, 0, 0.5]], dtype=float)\n    K4 = 3\n    \n    test_cases = [\n        (A1, b1, x0_1, H0_1, K1),\n        (A2, b2, x0_2, H0_2, K2),\n        (A3, b3, x0_3, H0_3, K3),\n        (A4, b4, x0_4, H0_4, K4)\n    ]\n\n    results = []\n    for A, b, x0, H0, K_max in test_cases:\n        result = run_bfgs(A, b, x0, H0, K_max)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3166990"}]}