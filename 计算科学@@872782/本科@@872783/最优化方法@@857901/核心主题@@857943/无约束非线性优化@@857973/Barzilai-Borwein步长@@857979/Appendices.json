{"hands_on_practices": [{"introduction": "要真正掌握Barzilai-Borwein (BB) 方法的精髓，最好的方式莫过于亲手实践。我们将从一个典型的“难题”——病态二次函数——开始。这个练习将引导你计算BB步长，并直观地理解为何BB方法通过“过步”策略（即步长大于当前方向上的最优步长）能够打破最速下降法的“Z”字形下降路径，从而在整体上实现更快的收敛。通过这个例子，你将深入理解BB方法非单调性的本质及其优势。[@problem_id:2162618]", "problem": "考虑最小化二次目标函数 $f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^T A \\mathbf{x}$ 的问题，其中 $\\mathbf{x} = (x_1, x_2)^T \\in \\mathbb{R}^2$。该函数代表了一个系统辨识任务中的简化成本函数，其目标是找到最小化误差的最优参数向量 $\\mathbf{x}$。矩阵 $A$ 由下式给出：\n$$A = \\begin{pmatrix} 100  0 \\\\ 0  1 \\end{pmatrix}$$\n该矩阵的高条件数表明两个参数具有截然不同的敏感度，这使得标准优化方法难以应对。\n\n我们将使用一种基于梯度的迭代方法来寻找最小值，起始点为 $\\mathbf{x}_0 = (1, 10)^T$。通用的更新规则是 $\\mathbf{x}_{k+1} = \\mathbf{x}_k - \\alpha_k \\nabla f(\\mathbf{x}_k)$。\n\n对于第一次迭代（从 $k=0$ 到 $k=1$），使用精确线搜索执行最速下降法的一步。步长 $\\alpha_0$ 被选择为能精确最小化 $f(\\mathbf{x}_0 - \\alpha \\nabla f(\\mathbf{x}_0))$ 的值。\n\n对于所有后续迭代（$k \\geq 1$），我们切换到 Barzilai-Borwein (BB) 方法。Barzilai-Borwein 方法的一种常用步长策略定义为：\n$$\\alpha_k = \\frac{s_{k-1}^T s_{k-1}}{s_{k-1}^T y_{k-1}}$$\n其中 $s_{k-1} = \\mathbf{x}_k - \\mathbf{x}_{k-1}$ 是上一步的位移向量，而 $y_{k-1} = \\nabla f(\\mathbf{x}_k) - \\nabla f(\\mathbf{x}_{k-1})$ 是梯度的变化量。\n\n您需要完成两个目标：\n1.  计算第一个 Barzilai-Borwein 步长 $\\alpha_1$ 的值。将您的数值答案四舍五入到四位有效数字。\n2.  众所周知，BB 方法在处理病态二次问题时通常优于最速下降法，尽管它具有非单调性行为（即，函数值 $f(\\mathbf{x}_k)$ 可能不会在每一步都减小）。请选择下面最能为这种加速收敛提供几何直觉的陈述。\n\n(A) BB 方法保证每一步梯度的大小单调减小，从而迫使其更快地趋于零。\n\n(B) 通过使用前一次迭代信息的步长，该方法确保连续的梯度向量完全共线，从而消除了“之”字形行为。\n\n(C) BB 步长通常比精确线搜索在当前方向上所能得到的步长要大。这种“过步”打破了最速下降法中连续梯度的严格正交性，产生了一个与成本函数椭圆等值线的长轴更对齐的新搜索方向。\n\n(D) 该方法计算的步长始终是海森矩阵 $A$ 最大和最小特征值倒数的平均值，从而在所有特征方向上提供平衡的移动。\n\n(E) BB 步长总是小于最速下降步长，这使得算法更稳定，并防止在病态问题中因大步长可能发生的发散。\n\n请将第 1 部分和第 2 部分的答案以一个二元行矩阵的形式给出，其中 $\\alpha_1$ 的数值答案为第一个元素，第 2 部分正确选项对应的大写字母为第二个元素。", "solution": "我们正在最小化二次函数 $f(\\mathbf{x})=\\frac{1}{2}\\mathbf{x}^{T}A\\mathbf{x}$，其中 $A=\\mathrm{diag}(100,1)$。对于对称矩阵 $A$，梯度为 $\\nabla f(\\mathbf{x})=A\\mathbf{x}$。\n\n从 $\\mathbf{x}_{0}=\\begin{pmatrix}1\\\\10\\end{pmatrix}$ 开始，在 $k=0$ 处的最速下降方向是 $-\\nabla f(\\mathbf{x}_{0})$。计算梯度：\n$$\n\\mathbf{g}_{0}=\\nabla f(\\mathbf{x}_{0})=A\\mathbf{x}_{0}=\\begin{pmatrix}100\\\\10\\end{pmatrix}.\n$$\n沿着 $-\\mathbf{g}_{0}$ 方向进行精确线搜索，最优步长由标准二次公式给出\n$$\n\\alpha_{0}=\\frac{\\mathbf{g}_{0}^{T}\\mathbf{g}_{0}}{\\mathbf{g}_{0}^{T}A\\mathbf{g}_{0}}.\n$$\n计算所需的内积：\n$$\n\\mathbf{g}_{0}^{T}\\mathbf{g}_{0}=100^{2}+10^{2}=10100,\\qquad\nA\\mathbf{g}_{0}=\\begin{pmatrix}10000\\\\10\\end{pmatrix},\\qquad\n\\mathbf{g}_{0}^{T}A\\mathbf{g}_{0}=100\\cdot 10000+10\\cdot 10=1000100.\n$$\n因此\n$$\n\\alpha_{0}=\\frac{10100}{1000100}=\\frac{101}{10001}.\n$$\n更新到 $\\mathbf{x}_{1}$：\n$$\n\\mathbf{x}_{1}=\\mathbf{x}_{0}-\\alpha_{0}\\mathbf{g}_{0}\n=\\begin{pmatrix}1\\\\10\\end{pmatrix}-\\frac{101}{10001}\\begin{pmatrix}100\\\\10\\end{pmatrix}\n=\\begin{pmatrix}1-\\frac{10100}{10001}\\\\10-\\frac{1010}{10001}\\end{pmatrix}\n=\\begin{pmatrix}-\\frac{99}{10001}\\\\\\frac{99000}{10001}\\end{pmatrix}.\n$$\n\n对于第一步 Barzilai-Borwein 迭代（$k=1$），定义\n$$\n\\mathbf{s}_{0}=\\mathbf{x}_{1}-\\mathbf{x}_{0}=-\\alpha_{0}\\mathbf{g}_{0},\\qquad\n\\mathbf{y}_{0}=\\nabla f(\\mathbf{x}_{1})-\\nabla f(\\mathbf{x}_{0})=A\\mathbf{x}_{1}-A\\mathbf{x}_{0}=A(\\mathbf{x}_{1}-\\mathbf{x}_{0})=A\\mathbf{s}_{0}.\n$$\n规定的 BB 步长是\n$$\n\\alpha_{1}=\\frac{\\mathbf{s}_{0}^{T}\\mathbf{s}_{0}}{\\mathbf{s}_{0}^{T}\\mathbf{y}_{0}}\n=\\frac{(-\\alpha_{0}\\mathbf{g}_{0})^{T}(-\\alpha_{0}\\mathbf{g}_{0})}{(-\\alpha_{0}\\mathbf{g}_{0})^{T}(A(-\\alpha_{0}\\mathbf{g}_{0}))}\n=\\frac{\\alpha_{0}^{2}\\mathbf{g}_{0}^{T}\\mathbf{g}_{0}}{\\alpha_{0}^{2}\\mathbf{g}_{0}^{T}A\\mathbf{g}_{0}}\n=\\frac{\\mathbf{g}_{0}^{T}\\mathbf{g}_{0}}{\\mathbf{g}_{0}^{T}A\\mathbf{g}_{0}}\n=\\alpha_{0}.\n$$\n因此，\n$$\n\\alpha_{1}=\\frac{101}{10001}\\approx 0.0100999\\ldots,\n$$\n四舍五入到四位有效数字是 $0.01010$。\n\n对于几何直觉，采用精确线搜索的最速下降法在二次函数上产生的连续迭代梯度是正交的，这在病态问题中会导致沿狭窄山谷的“之”字形移动。Barzilai-Borwein 方法使用割线信息选择步长，该步长通常大于当前最速下降方向的精确线搜索步长，从而打破了连续梯度的严格正交性，并产生一个与椭圆等值线的长轴更好地对齐的搜索方向，从而在病态二次问题上加速收敛。这对应于选项 (C)。", "answer": "$$\\boxed{\\begin{pmatrix} 0.01010  C \\end{pmatrix}}$$", "id": "2162618"}, {"introduction": "在建立了BB方法的直观认识后，我们来深入探讨其背后的数学原理。这个练习要求你推导一个精确的数学条件，在该条件下，对于二次目标函数，BB1步长恰好等于精确线搜索步长。通过解决这个问题，你将揭示BB步长与问题海森矩阵（Hessian matrix）谱特性之间的深刻联系，从而更严谨地理解BB方法是如何“学习”并适应问题的曲率信息的。[@problem_id:3100582]", "problem": "考虑一个严格凸二次目标函数 $f(x) = \\frac{1}{2} x^{\\top} Q x - b^{\\top} x$ 的无约束最小化问题，其中 $Q \\in \\mathbb{R}^{n \\times n}$ 是对称正定矩阵，且 $b \\in \\mathbb{R}^{n}$。令第 $k$ 次迭代的梯度为 $g_{k} = \\nabla f(x_{k})$。定义位移 $s_{k} = x_{k} - x_{k-1}$ 和梯度差 $y_{k} = g_{k} - g_{k-1}$。梯度下降步使用 $x_{k+1} = x_{k} - \\alpha_{k} g_{k}$，步长 $\\alpha_{k}  0$。第一种 Barzilai–Borwein (BB1) 步长是选择一个标量，用于沿 $s_{k}$ 和 $y_{k}$ 方向近似逆 Hessian 矩阵。\n\n从二次模型、其梯度和精确线搜索（沿负梯度方向最小化）的基本定义出发，推导一个涉及 $Q$ 以及梯度 $g_{k-1}$ 和 $g_{k}$ 的数学条件。在该条件下，对于二次目标函数，在第 $k$ 次迭代时计算出的 BB1 步长等于同一次迭代中使用的精确线搜索步长。\n\n然后，在 $\\mathbb{R}^{2}$ 中通过一个具体构造来验证此条件：取\n$$\nQ = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix}, \\quad \\text{选择任意 } x_{k-1} \\in \\mathbb{R}^{2} \\text{ 使得 } g_{k-1} = \\begin{pmatrix} 0 \\\\ 2 \\end{pmatrix}, \\quad \\alpha_{k-1} = \\frac{1}{5},\n$$\n设 $x_{k} = x_{k-1} - \\alpha_{k-1} g_{k-1}$，并定义 $b = Q x_{k-1} - g_{k-1}$ 以确保指定的 $g_{k-1}$ 与二次模型一致。在此构造下，计算在第 $k$ 次迭代时 BB1 和精确线搜索产生的共同步长值 $\\alpha$。请以精确值（非四舍五入）的形式表示最终答案。", "solution": "目标函数是一个严格凸二次函数：\n$$f(x) = \\frac{1}{2} x^{\\top} Q x - b^{\\top} x$$\n其中 $Q$ 是对称正定（SPD）矩阵。$f(x)$ 在迭代点 $x_k$ 的梯度由下式给出：\n$$g_k = \\nabla f(x_k) = Q x_k - b$$\n\n**第一部分：条件的推导**\n\n首先，我们推导第 $k$ 次迭代的精确线搜索步长（记为 $\\alpha_k^{\\text{ELS}}$）的表达式。该步长是使一维函数 $\\phi(\\alpha) = f(x_k - \\alpha g_k)$ 最小化的 $\\alpha$ 值。为求最小值，我们将 $\\phi(\\alpha)$ 对 $\\alpha$ 的导数设为零：\n$$\\frac{d\\phi}{d\\alpha} = -g_k^{\\top} Q (x_k - \\alpha g_k) + g_k^{\\top} b = -g_k^{\\top} (Q x_k - b) + \\alpha g_k^{\\top} Q g_k = 0$$\n注意到 $g_k = Q x_k - b$，上式可简化为：\n$$-g_k^{\\top} g_k + \\alpha g_k^{\\top} Q g_k = 0$$\n由于 $g_k$ 非零（否则算法已收敛）且 $Q$ 是对称正定的，因此 $g_k^{\\top} Q g_k  0$。我们可以解出 $\\alpha$：\n$$\\alpha_k^{\\text{ELS}} = \\frac{g_k^{\\top} g_k}{g_k^{\\top} Q g_k}$$\n\n接下来，我们推导第 $k$ 次迭代的第一种 Barzilai-Borwein (BB1) 步长（记为 $\\alpha_k^{\\text{BB1}}$）。其定义为：\n$$\\alpha_k^{\\text{BB1}} = \\frac{s_k^{\\top} s_k}{s_k^{\\top} y_k}$$\n其中 $s_k = x_k - x_{k-1}$ 且 $y_k = g_k - g_{k-1} = Q s_k$。将 $s_k = x_k - x_{k-1} = -\\alpha_{k-1} g_{k-1}$ 代入上式：\n$$\\alpha_k^{\\text{BB1}} = \\frac{(-\\alpha_{k-1} g_{k-1})^{\\top} (-\\alpha_{k-1} g_{k-1})}{(-\\alpha_{k-1} g_{k-1})^{\\top} Q (-\\alpha_{k-1} g_{k-1})} = \\frac{g_{k-1}^{\\top} g_{k-1}}{g_{k-1}^{\\top} Q g_{k-1}}$$\n两个步长相等的条件是 $\\alpha_k^{\\text{BB1}} = \\alpha_k^{\\text{ELS}}$。令推导出的表达式相等，得到涉及 $Q$、$g_{k-1}$ 和 $g_k$ 的数学条件：\n$$\\frac{g_{k-1}^{\\top} g_{k-1}}{g_{k-1}^{\\top} Q g_{k-1}} = \\frac{g_k^{\\top} g_k}{g_k^{\\top} Q g_k}$$\n\n**第二部分：验证与计算**\n\n对于 $\\mathbb{R}^2$ 中的一个具体构造，我们给定以下值：\n$$Q = \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix}, \\quad g_{k-1} = \\begin{pmatrix} 0 \\\\ 2 \\end{pmatrix}, \\quad \\alpha_{k-1} = \\frac{1}{5}$$\n首先，我们计算第 $k$ 次迭代的 BB1 步长 $\\alpha_k^{\\text{BB1}}$：\n$$g_{k-1}^{\\top} g_{k-1} = 4$$\n$$g_{k-1}^{\\top} Q g_{k-1} = \\begin{pmatrix} 0  2 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 2 \\end{pmatrix} = 16$$\n因此，BB1 步长为：\n$$\\alpha_k^{\\text{BB1}} = \\frac{4}{16} = \\frac{1}{4}$$\n\n接下来，我们计算精确线搜索步长 $\\alpha_k^{\\text{ELS}}$。我们首先需要求出 $g_k$。对于二次目标函数，梯度更新规则是：\n$$g_k = (I - \\alpha_{k-1} Q) g_{k-1}$$\n代入给定值：\n$$g_k = \\left(\\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} - \\frac{1}{5} \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix}\\right) \\begin{pmatrix} 0 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 4/5  0 \\\\ 0  1/5 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 2/5 \\end{pmatrix}$$\n现在我们可以计算 $\\alpha_k^{\\text{ELS}}$ 所需的量：\n$$g_k^{\\top} g_k = \\left(\\frac{2}{5}\\right)^2 = \\frac{4}{25}$$\n$$g_k^{\\top} Q g_k = \\begin{pmatrix} 0  2/5 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  4 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 2/5 \\end{pmatrix} = \\frac{16}{25}$$\n因此，精确线搜索步长为：\n$$\\alpha_k^{\\text{ELS}} = \\frac{g_k^{\\top} g_k}{g_k^{\\top} Q g_k} = \\frac{4/25}{16/25} = \\frac{4}{16} = \\frac{1}{4}$$\n两个步长确实相等，从而验证了该特定构造下的条件。共同的步长值是 $\\frac{1}{4}$。出现相等的原因是初始梯度 $g_{k-1}$ 是 Hessian 矩阵 $Q$ 的一个特征向量，这导致所有后续梯度都与 $g_{k-1}$ 平行。", "answer": "$$\\boxed{\\frac{1}{4}}$$", "id": "3100582"}, {"introduction": "从理论转向实践，本练习将探讨BB方法在实际应用中一个至关重要的问题：数值稳定性。我们将构建一个特定的场景，其中第二种Barzilai-Borwein步长（BB2）的计算公式会因除以一个接近于零的数而变得极其不稳定。你的任务是分析并选择最合适的保护策略，以确保算法的稳健性。这个过程将凸显在设计和实现真实世界的优化算法时，考虑周全的数值保护措施是何等重要。[@problem_id:3100631]", "problem": "考虑将梯度法应用于一个$3$维光滑二次目标函数，该函数定义为 $f(x) = \\tfrac{1}{2} x^{\\top} H x$，其中 $H \\in \\mathbb{R}^{3 \\times 3}$ 是一个对称正定Hessian矩阵。设 $H = \\operatorname{diag}(10, 10, 10^{-8})$，并假设在第 $k-1$ 次迭代时，点为 $x_{k-1} = (1, 1, 1)^{\\top}$，下一个迭代点沿着第三个坐标方向产生：$x_{k} = x_{k-1} + \\delta e_{3} = (1, 1, 1 + \\delta)^{\\top}$，其中 $\\delta \\in \\mathbb{R}$，$e_{3}$ 是第三个标准基向量。定义在基于梯度的方法中使用的标准梯度差和步长差：$s_{k-1} = x_{k} - x_{k-1}$ 和 $y_{k-1} = \\nabla f(x_{k}) - \\nabla f(x_{k-1})$。假设采用一种Barzilai–Borwein (BB) 梯度法，该方法周期性地计算第二种Barzilai–Borwein步长 (BB2)，该步长是基于使用 $s_{k-1}$ 和 $y_{k-1}$ 的割线思想构建的，并回想一下，即使梯度差很小，梯度本身也可能非零。\n\n第一部分（构造）：使用二次目标函数的基本关系式 $\\nabla f(x) = H x$，证明对于量级为 $1$ 的 $\\delta$，量 $y_{k-1}^{\\top} y_{k-1}$ 可以任意接近机器精度，而单个梯度 $\\nabla f(x_{k-1})$ 和 $\\nabla f(x_{k})$ 非零且具有中等大小的量级。解释各向异性曲率（$H$的特征值）在此效应中的作用。\n\n第二部分（安全措施）：BB2步长关键地依赖于 $y_{k-1}^{\\top} y_{k-1}$。在上述情景中，不带安全措施地选择BB2可能会导致数值不稳定性。以下哪种策略最适合确保迭代稳定，同时保留基于割线思想的缩放，并为回退到第一种Barzilai–Borwein步长 (BB1) 提供有原则的方案？\n\nA. 对BB2步长施加界限，将其裁剪到一个区间 $[\\alpha_{\\min}, \\alpha_{\\max}]$ 内，其中 $\\alpha_{\\min}  0$ 且 $\\alpha_{\\max}  \\infty$；此外，如果对于一个小的阈值 $\\varepsilon  0$ 有 $y_{k-1}^{\\top} y_{k-1} \\le \\varepsilon$，则绕过BB2，转而计算BB1步长，并且仅在 $s_{k-1}^{\\top} y_{k-1}  0$ 时使用它；否则，重用上一步的步长或一个安全的默认值。\n\nB. 在BB2公式中用 $y_{k-1}^{\\top} y_{k-1} + \\varepsilon$ (其中 $\\varepsilon  0$ 是一个小数) 替换 $y_{k-1}^{\\top} y_{k-1}$，然后继续计算，不进行任何界限设置或回退，因为仅正则化本身就能防止除以零。\n\nC. 在构建BB2之前对梯度差进行归一化，设置 $\\tilde{y}_{k-1} = y_{k-1} / \\|y_{k-1}\\|_{2}$，然后用 $\\tilde{y}_{k-1}$ 代替 $y_{k-1}$ 以避免小分母；这确保了分母恰好为 $1$。\n\nD. 在计算BB2后，依赖一个单调回溯线搜索，它会拒绝任何不稳定的步长；不需要界限设置或回退，因为仅线搜索本身就能强制保证稳定性。\n\n选择唯一的最佳选项。", "solution": "该问题陈述在科学上是合理的、适定的、客观的，并为进行严谨分析提供了所有必要信息。所述情景是数值优化中关于病态问题和类拟牛顿法稳定性的经典案例研究。该问题是有效的。\n\n我们继续进行两部分的分析。\n\n**第一部分：构造与分析**\n\n目标函数为 $f(x) = \\tfrac{1}{2} x^{\\top} H x$，其中 $H = \\operatorname{diag}(10, 10, 10^{-8})$。梯度为 $\\nabla f(x) = Hx$。\n给定点为 $x_{k-1} = (1, 1, 1)^{\\top}$ 和 $x_{k} = (1, 1, 1 + \\delta)^{\\top}$。\n\n首先，我们计算这些点的梯度：\n$$ \\nabla f(x_{k-1}) = H x_{k-1} = \\begin{pmatrix} 10  0  0 \\\\ 0  10  0 \\\\ 0  0  10^{-8} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 10 \\\\ 10 \\\\ 10^{-8} \\end{pmatrix} $$\n$$ \\nabla f(x_{k}) = H x_{k} = \\begin{pmatrix} 10  0  0 \\\\ 0  10  0 \\\\ 0  0  10^{-8} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1+\\delta \\end{pmatrix} = \\begin{pmatrix} 10 \\\\ 10 \\\\ 10^{-8}(1+\\delta) \\end{pmatrix} $$\n这些梯度的欧几里得范数平方为：\n$$ \\|\\nabla f(x_{k-1})\\|_2^2 = 10^2 + 10^2 + (10^{-8})^2 = 200 + 10^{-16} $$\n对于量级为 $1$ 的 $\\delta$，例如 $\\delta=1$：\n$$ \\|\\nabla f(x_{k})\\|_2^2 = 10^2 + 10^2 + (2 \\cdot 10^{-8})^2 = 200 + 4 \\cdot 10^{-16} $$\n在这两种情况下，梯度的量级约为 $\\sqrt{200} \\approx 14.14$，这是一个“中等大小”的量级。梯度明显非零。\n\n接下来，我们计算步长差 $s_{k-1}$ 和梯度差 $y_{k-1}$：\n$$ s_{k-1} = x_{k} - x_{k-1} = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1+\\delta \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\delta \\end{pmatrix} = \\delta e_3 $$\n$$ y_{k-1} = \\nabla f(x_{k}) - \\nabla f(x_{k-1}) = \\begin{pmatrix} 10 \\\\ 10 \\\\ 10^{-8}(1+\\delta) \\end{pmatrix} - \\begin{pmatrix} 10 \\\\ 10 \\\\ 10^{-8} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\delta \\cdot 10^{-8} \\end{pmatrix} $$\n或者，使用关系式 $y_{k-1} = H s_{k-1}$：\n$$ y_{k-1} = H(\\delta e_3) = \\delta (H e_3) = \\delta \\begin{pmatrix} 10  0  0 \\\\ 0  10  0 \\\\ 0  0  10^{-8} \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\\\ 1 \\end{pmatrix} = \\delta \\begin{pmatrix} 0 \\\\ 0 \\\\ 10^{-8} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\delta \\cdot 10^{-8} \\end{pmatrix} $$\n现在我们计算关键量 $y_{k-1}^{\\top} y_{k-1}$：\n$$ y_{k-1}^{\\top} y_{k-1} = \\|y_{k-1}\\|_2^2 = (\\delta \\cdot 10^{-8})^2 = \\delta^2 \\cdot 10^{-16} $$\n鉴于 $\\delta$ 是1的量级，$y_{k-1}^{\\top} y_{k-1}$ 的值是 $10^{-16}$ 的量级。这与标准的双精度机器精度（约 $2.22 \\times 10^{-16}$）在同一数量级，意味着它任意接近机器精度。\n\n各向异性曲率的作用：目标函数的曲率由Hessian矩阵 $H$ 决定。其特征值 $\\lambda_1=10$、$\\lambda_2=10$ 和 $\\lambda_3=10^{-8}$ 分别表示沿主轴 $e_1, e_2, e_3$ 的曲率。$\\lambda_{1,2}$ 和 $\\lambda_3$ 之间的极端差异表明了高度的各向异性曲率：函数在 $e_1-e_2$ 平面内非常陡峭，但在 $e_3$ 方向上极其平坦。迭代点仅在 $e_3$ 方向上改变（$s_{k-1} = \\delta e_3$），这是最小曲率的方向。梯度的变化由 $y_{k-1} = H s_{k-1} = \\lambda_3 s_{k-1}$ 给出。这个变化的量级 $\\|y_{k-1}\\|_2 = \\lambda_3 \\|s_{k-1}\\|_2$ 因此被非常小的特征值 $\\lambda_3=10^{-8}$ 所缩放。同时，梯度向量 $\\nabla f(x_{k-1})$ 很大，因为点 $x_{k-1}$ 在高曲率方向（$e_1, e_2$）上有显著的分量。这说明了各向异性曲率如何导致这样一种情况：梯度很大，但其沿某一特定方向的变化却微乎其微。\n\n**第二部分：BB2步长的安全措施**\n\n第二种Barzilai-Borwein (BB2) 步长定义为：\n$$ \\alpha_k^{\\text{BB2}} = \\frac{s_{k-1}^{\\top} y_{k-1}}{y_{k-1}^{\\top} y_{k-1}} $$\n使用第一部分推导出的值：\n$$ s_{k-1}^{\\top} y_{k-1} = (\\delta e_3)^{\\top} (\\delta \\cdot 10^{-8} e_3) = \\delta^2 \\cdot 10^{-8} $$\n$$ y_{k-1}^{\\top} y_{k-1} = \\delta^2 \\cdot 10^{-16} $$\n$$ \\alpha_k^{\\text{BB2}} = \\frac{\\delta^2 \\cdot 10^{-8}}{\\delta^2 \\cdot 10^{-16}} = 10^8 $$\nBB2公式得出了一个巨大的步长，这将导致数值不稳定性和发散。这是分母 $y_{k-1}^{\\top} y_{k-1}$ 接近于零的直接结果。我们现在必须评估所提出的安全措施策略。\n\n**选项A分析**：该选项提出了一个多层次、鲁棒的策略。\n1.  **界限**：将步长裁剪到一个预定义的区间 $[\\alpha_{\\min}, \\alpha_{\\max}]$ 内，是一种标准且有效的启发式方法，用以防止无论其来源如何的病态大或小的步长。它会将计算出的 $10^8$ 裁剪为一个合理的 $\\alpha_{\\max}$。\n2.  **分母检查**：它通过检查 $y_{k-1}^{\\top} y_{k-1}$ 是否低于阈值 $\\varepsilon$ 来直接解决已识别的问题。这主动地检测了潜在的不稳定性。\n3.  **有原则的回退**：如果BB2的分母不安全，它建议切换到第一种Barzilai-Borwein步长 (BB1)，即 $\\alpha_k^{\\text{BB1}} = \\frac{s_{k-1}^{\\top} s_{k-1}}{s_{k-1}^{\\top} y_{k-1}}$。这是一个合乎逻辑的替代方案，因为两者都源于相同的割线思想。这保留了该方法的核心思想。\n4.  **曲率条件**：它包括检查 $s_{k-1}^{\\top} y_{k-1}  0$。这一点至关重要，因为对于二次函数，$s_{k-1}^{\\top} y_{k-1} = s_{k-1}^{\\top} H s_{k-1}$。一个正值确保了函数在步长方向上具有正曲率，这对于BB步长为正且定义良好是必要的。\n5.  **最终回退**：如果连BB1步长也无法安全计算（例如，如果 $s_{k-1}^{\\top} y_{k-1} \\le 0$），它会采取一个安全的默认值。\n这种全面的策略与实现鲁棒BB方法的最佳实践相一致。它在可能的情况下保留了基于割线的缩放，并为稳定性提供了一系列级联的安全保障。\n**结论：正确**\n\n**选项B分析**：该选项建议用 $D + \\varepsilon$ 替换分母 $D = y_{k-1}^{\\top} y_{k-1}$。这是一种正则化形式。得到的步长将是 $\\alpha_k = \\frac{\\delta^2 \\cdot 10^{-8}}{\\delta^2 \\cdot 10^{-16} + \\varepsilon}$。虽然这确实可以防止除以零，但它是一个临时的修复方法。$\\varepsilon$ 的选择是任意的，如果选择得太大，可能会过度抑制步长，如果太小，则可能无法稳定步长。更重要的是，它修改了BB2公式，从而改变了基于割线的缩放，而不是保留它。它也是一个不完整的策略，因为它没有处理分子 $s_{k-1}^{\\top} y_{k-1}$ 可能为非正数的情况。\n**结论：不正确**\n\n**选项C分析**：该选项建议在使用前对 $y_{k-1}$ 进行归一化。新的BB2步长将使用 $\\tilde{y}_{k-1} = y_{k-1} / \\|y_{k-1}\\|_2$ 进行计算。分母变为 $\\|\\tilde{y}_{k-1}\\|_2^2=1$，这解决了小分母问题。然而，BB步长的有效性源于嵌入在 $s_{k-1}$ 和 $y_{k-1}$ 量级中的缩放信息。对 $y_{k-1}$ 进行归一化会丢弃其量级中包含的这一关键曲率信息。这从根本上改变了该方法，并明确违反了“保留基于割线思想的缩放”的目标。\n**结论：不正确**\n\n**选项D分析**：该选项建议依赖一个单调回溯线搜索。这里有两个主要缺陷。首先，标准的Barzilai-Borwein方法本质上是非单调的；其良好性能通常归因于此特性。通过单调线搜索在每一步强制函数值下降可能对其收敛性有害，并且与该方法的精神背道而驰。其次，即使使用一个兼容的（非单调的）线搜索，它也是一种被动的措施。它将以一个病态大的步长（$\\alpha_k=10^8$）启动，并且必须执行多次昂贵的函数评估才能将步长减小到合理的大小。一个鲁棒的算法应该主动计算一个合理的步长，而不是依赖一个昂贵的回溯过程来修正一个糟糕的初始猜测。\n**结论：不正确**\n\n结论：选项A描述了创建稳定鲁棒的Barzilai-Borwein方法实现的最合适、最全面和被广泛接受的策略。它正确地识别了失效模式，并采用了一系列有原则的检查和回退方案，这些方案在保证数值稳定性的同时，保留了该方法的底层理论。", "answer": "$$\\boxed{A}$$", "id": "3100631"}]}