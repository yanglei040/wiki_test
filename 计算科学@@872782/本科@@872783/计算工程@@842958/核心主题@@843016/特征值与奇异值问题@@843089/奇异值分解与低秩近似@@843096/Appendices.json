{"hands_on_practices": [{"introduction": "掌握理论知识的最佳途径是付诸实践。让我们从一个基本练习开始，探讨低秩近似如何与简单的矩阵变换（如缩放）相互作用。这个思想实验将帮助你巩固对“最佳”近似基本性质的理解，并揭示当整个数据集被一致地缩放时，其最显著的特征（即其秩-1近似）会发生什么变化。[@problem_id:1374776]", "problem": "在数据分析领域，一种用于特征提取和降噪的常用技术是用一个更简单的低秩矩阵来近似一个大型数据矩阵。设 $A$ 是一个非零的 $m \\times n$ 实矩阵，代表一个数据集。$A$ 的最佳秩1近似，记作 $A_1$，被定义为最小化差的弗罗贝尼乌斯范数 $\\|A - A_1\\|_F$ 的秩1矩阵。这种近似捕捉了数据中最主要的特征。\n\n一位分析师对数据集进行变换，得到了一个新矩阵 $B$，由关系式 $B = -3A$ 定义。该分析师需要为这个新数据集 $B$ 找到最佳秩1近似。\n\n以下哪个表达式正确地用 $A_1$ 表示 $B$ 的最佳秩1近似？\n\nA. $A_1$\n\nB. $-A_1$\n\nC. $3A_1$\n\nD. $-3A_1$\n\nE. $9A_1$\n\nF. 在没有矩阵 $A$ 的具体值的情况下，无法确定该关系。", "solution": "设 $A \\in \\mathbb{R}^{m \\times n}$ 为非零矩阵，并设 $A_{1}$ 表示其在弗罗贝尼乌斯范数下的最佳秩1近似：\n$$\nA_{1} = \\arg\\min_{\\operatorname{rank}(X)=1} \\|A - X\\|_{F}.\n$$\n考虑 $B = cA$，其中 $c = -3 \\neq 0$。我们寻求 $B$ 的最佳秩1近似 $B_{1}$，即：\n$$\nB_{1} = \\arg\\min_{\\operatorname{rank}(Y)=1} \\|B - Y\\|_{F}.\n$$\n使用两个事实：\n1) 弗罗贝尼乌斯范数的齐次性：对于任意标量 $c$ 和任意矩阵 $M$，\n$$\n\\|cM\\|_{F} = |c| \\|M\\|_{F}.\n$$\n2) 在非零缩放变换下秩不变：当 $c \\neq 0$ 时，$\\operatorname{rank}(Y)=1$ 当且仅当 $\\operatorname{rank}(Y/c)=1$。\n\n对于任意秩1矩阵 $Y$，定义 $X := Y/c$。则 $X$ 是秩1的，且\n$$\n\\|B - Y\\|_{F} = \\|cA - Y\\|_{F} = \\|c(A - X)\\|_{F} = |c| \\|A - X\\|_{F}.\n$$\n因此，\n$$\n\\min_{\\operatorname{rank}(Y)=1} \\|B - Y\\|_{F}\n= |c| \\min_{\\operatorname{rank}(X)=1} \\|A - X\\|_{F},\n$$\n并且最小值点通过 $Y^{\\ast} = c X^{\\ast}$ 对应。根据定义，$X^{\\ast} = A_{1}$，因此可得\n$$\nB_{1} = c A_{1}.\n$$\n当 $c = -3$ 时，我们得到\n$$\nB_{1} = -3 A_{1}.\n$$\n\n等价地，根据 Eckart–Young 定理，如果 $A = \\sum_{i=1}^{r} \\sigma_{i} u_{i} v_{i}^{\\top}$ 且 $\\sigma_{1} \\geq \\sigma_{2} \\geq \\cdots \\geq 0$，则 $A_{1} = \\sigma_{1} u_{1} v_{1}^{\\top}$。对于 $B = -3A$，一个奇异值分解（SVD）是 $B = \\sum_{i=1}^{r} (3\\sigma_{i}) \\tilde{u}_{i} v_{i}^{\\top}$，其中 $\\tilde{u}_{i} = -u_{i}$ 以便奇异值保持非负。因此 $B_{1} = 3\\sigma_{1} \\tilde{u}_{1} v_{1}^{\\top} = -3 \\sigma_{1} u_{1} v_{1}^{\\top} = -3 A_{1}$。\n\n因此，正确选项是 D。", "answer": "$$\\boxed{D}$$", "id": "1374776"}, {"introduction": "在对低秩近似的性质有了直观感受之后，一个自然而然的问题是：我们如何精确地量化近似的优劣？本练习将理论与计算相结合，要求你应用SVD理论的基石——Eckart-Young-Mirsky定理——来确定一个特定矩阵的最佳低秩近似所产生的误差。通过这个计算，你将体会到被截断的奇异值是如何直接控制近似精度的。[@problem_id:1071275]", "problem": "设 $A$ 是一个 $m \\times n$ 的实矩阵。$A$ 的奇异值分解 (SVD) 是一种形如 $A = U\\Sigma V^T$ 的因式分解，其中 $U$ 是一个 $m \\times m$ 的正交矩阵，$V$ 是一个 $n \\times n$ 的正交矩阵，$\\Sigma$ 是一个 $m \\times n$ 的矩形对角矩阵，其对角线上的元素为非负实数。$\\Sigma$ 的对角元素 $\\sigma_i$ 被称为 $A$ 的奇异值，通常按 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r > 0$ 的顺序排列，其中 $r = \\text{rank}(A)$。\n\n截断奇异值分解 (truncated SVD) 提供了 $A$ 的一个低秩近似。$A$ 的最佳秩-$k$ 近似，记作 $A_k$，由 $A_k = \\sum_{i=1}^k \\sigma_i u_i v_i^T$ 给出，其中 $u_i$ 和 $v_i$ 分别是 $U$ 和 $V$ 的第 $i$ 列。\n\nEckart-Young-Mirsky 定理指出，$A_k$ 是 $A$ 在谱范数（矩阵 2-范数）$\\| \\cdot \\|_2$ 意义下的最优秩-$k$ 近似。该近似的误差由第一个被截断的奇异值给出：\n$$\n\\|A - A_k\\|_2 = \\sigma_{k+1}\n$$\n\n考虑一个 3x3 的对称帕斯卡矩阵 $P_3$，它由二项式系数 $P_{ij} = \\binom{i+j-2}{i-1}$ 定义，其中 $i,j \\in \\{1, 2, 3\\}$。\n\n当用矩阵 $P_3$ 的最佳秩-$k$ 近似 $(P_3)_k$ (其中 $k=2$) 来近似 $P_3$ 时，求其误差的谱范数 $\\|P_3 - (P_3)_k\\|_2$。", "solution": "1. 根据 Eckart–Young–Mirsky 定理可得\n$$\\|P_3 - (P_3)_k\\|_2 = \\sigma_{k+1},$$ \n其中 $\\sigma_i$ 是 $P_3$ 的奇异值，并按 $\\sigma_1\\ge\\sigma_2\\ge\\sigma_3>0$ 排序。\n2. 对于对称矩阵\n$$P_3=\\begin{pmatrix}111\\\\123\\\\136\\end{pmatrix}$$ \n其奇异值等于其特征值。特征多项式为\n$$\\det(P_3-\\lambda I)=\\lambda^3-9\\lambda^2+9\\lambda-1=0.$$\n3. 提取因子 $(\\lambda-1)$ 可得\n$$\\lambda^3-9\\lambda^2+9\\lambda-1=(\\lambda-1)(\\lambda^2-8\\lambda+1),$$\n所以特征值为\n$$\\lambda=1,\\quad \\lambda=4\\pm\\sqrt{15}.$$\n4. 将奇异值排序为 $\\sigma_1=4+\\sqrt{15}\\ge\\sigma_2=1\\ge\\sigma_3=4-\\sqrt{15}$，对于 $k=2$，误差范数为\n$$\\|P_3-(P_3)_2\\|_2=\\sigma_3=4-\\sqrt{15}.$$", "answer": "$$\\boxed{4-\\sqrt{15}}$$", "id": "1071275"}, {"introduction": "SVD的威力远不止于数据压缩，它也是现代数据分析中主成分分析（PCA）的计算核心。这个高级练习模拟了一个常见于真实世界数据的场景：一个强烈的异常值如何影响我们对数据主要结构的判断。通过分析这个问题，你将深入理解SVD是如何识别数据方差最大的方向（即主成分），以及为什么它对异常值如此敏感，这是在应用SVD进行特征提取或数据去噪时必须考虑的关键点。[@problem_id:2435636]", "problem": "考虑一个在$\\mathbb{R}^d$中按如下方式构建的数据集。有$N$个基线样本$x_i \\in \\mathbb{R}^d$，其形式为$x_i = s_i a$，$i \\in \\{1,\\dots,N\\}$。其中$a \\in \\mathbb{R}^d$满足$\\|a\\|_2 = 1$，标量$s_i \\in \\mathbb{R}$满足$\\sum_{i=1}^N s_i = 0$，且$\\sum_{i=1}^N s_i^2$是有限的。附加一个额外的离群样本$x_{N+1} \\in \\mathbb{R}^d$，其形式为$x_{N+1} = M c$，其中$c \\in \\mathbb{R}^d$满足$\\|c\\|_2 = 1$和$a^\\top c = 0$，$M  0$是一个标量参数。令$X \\in \\mathbb{R}^{(N+1)\\times d}$为数据矩阵，其第$i$行为$x_i^\\top$。令$\\bar{x} \\in \\mathbb{R}^d$表示样本均值$\\bar{x} = \\frac{1}{N+1}\\sum_{i=1}^{N+1} x_i$，并定义列中心化数据矩阵$X' = X - \\mathbf{1}\\bar{x}^\\top$，其中$\\mathbf{1} \\in \\mathbb{R}^{N+1}$是全1向量。令奇异值分解（SVD）为$X' = U \\Sigma V^\\top$，其中$U \\in \\mathbb{R}^{(N+1)\\times (N+1)}$，$\\Sigma \\in \\mathbb{R}^{(N+1)\\times d}$，$V \\in \\mathbb{R}^{d\\times d}$，$\\Sigma$的对角线上的非负奇异值按非增序排列。在主成分分析（PCA）中，第一主成分是$V$的第一列（主导右奇异向量），最大奇异值等于$(X')^\\top X'$的主导特征值的平方根。\n\n关于离群点如何影响$X'$的主成分和低秩结构，以下哪些陈述是正确的？\n\nA. 对于足够大的$M$，第一主成分与$c$对齐。\n\nB. 通过减去$\\bar{x}$进行中心化后，离群点的贡献被抵消，因此对于所有的$M$，第一主成分必然保持与$a$对齐。\n\nC. 存在一个由$M^2 \\frac{N}{N+1} = \\sum_{i=1}^N s_i^2$决定的切换阈值，在该阈值处，第一主成分在$a$和$c$之间的对齐方式发生改变。\n\nD. 对于大的$M$，$X'$的最大奇异值与$\\sqrt{\\frac{N}{N+1}}\\,M$成比例，不计$M$的低阶项。\n\nE. 如果$a^\\top c = 0$，那么$X'$的前两个右奇异向量不必是正交的。\n\nF. 当$M \\to \\infty$时，最佳秩-1近似（在由$X'$导出的弗罗贝尼乌斯范数下）的平方误差收敛于$\\sum_{i=1}^N s_i^2$。", "solution": "我们首先分析中心化数据矩阵$X'$的结构。数据的主成分是类协方差矩阵$S = (X')^\\top X'$的特征向量。分析过程如下。\n\n首先，我们计算样本均值$\\bar{x}$：\n$$ \\bar{x} = \\frac{1}{N+1} \\sum_{i=1}^{N+1} x_i = \\frac{1}{N+1} \\left( \\sum_{i=1}^N x_i + x_{N+1} \\right) $$\n给定$x_i = s_i a$（对于$i \\in \\{1,\\dots,N\\}$），$x_{N+1} = M c$，以及条件$\\sum_{i=1}^N s_i = 0$，这可以简化为：\n$$ \\bar{x} = \\frac{1}{N+1} \\left( \\left(\\sum_{i=1}^N s_i\\right) a + M c \\right) = \\frac{1}{N+1} (0 \\cdot a + M c) = \\frac{M}{N+1} c $$\n\n接下来，我们定义中心化数据点，$x_i' = x_i - \\bar{x}$。\n对于$i \\in \\{1, \\dots, N\\}$：\n$$ x_i' = s_i a - \\frac{M}{N+1} c $$\n对于$i = N+1$：\n$$ x_{N+1}' = M c - \\frac{M}{N+1} c = \\left( M - \\frac{M}{N+1} \\right) c = \\frac{M(N+1) - M}{N+1} c = \\frac{MN}{N+1} c $$\n中心化数据矩阵$X'$的行是$(x_i')^\\top$。\n\n主成分是$S = (X')^\\top X'$的特征向量。我们计算这个矩阵：\n$$ S = \\sum_{i=1}^{N+1} x_i' (x_i')^\\top = \\sum_{i=1}^{N} x_i' (x_i')^\\top + x_{N+1}' (x_{N+1}')^\\top $$\n前$N$个点的和是：\n$$ \\sum_{i=1}^{N} \\left( s_i a - \\frac{M}{N+1} c \\right) \\left( s_i a - \\frac{M}{N+1} c \\right)^\\top $$\n$$ = \\sum_{i=1}^{N} \\left( s_i^2 a a^\\top - \\frac{s_i M}{N+1} a c^\\top - \\frac{s_i M}{N+1} c a^\\top + \\left(\\frac{M}{N+1}\\right)^2 c c^\\top \\right) $$\n使用$\\sum_{i=1}^N s_i = 0$并分配求和：\n$$ = \\left(\\sum_{i=1}^{N} s_i^2\\right) a a^\\top - \\frac{M}{N+1}\\left(\\sum_{i=1}^{N} s_i\\right) (a c^\\top + c a^\\top) + N \\left(\\frac{M}{N+1}\\right)^2 c c^\\top $$\n$$ = \\left(\\sum_{i=1}^{N} s_i^2\\right) a a^\\top + N \\frac{M^2}{(N+1)^2} c c^\\top $$\n现在，加上$x_{N+1}'$的项：\n$$ S = \\left(\\sum_{i=1}^{N} s_i^2\\right) a a^\\top + N \\frac{M^2}{(N+1)^2} c c^\\top + \\left(\\frac{MN}{N+1}\\right)^2 c c^\\top $$\n$$ S = \\left(\\sum_{i=1}^{N} s_i^2\\right) a a^\\top + \\left( N \\frac{M^2}{(N+1)^2} + \\frac{M^2 N^2}{(N+1)^2} \\right) c c^\\top $$\n$$ S = \\left(\\sum_{i=1}^{N} s_i^2\\right) a a^\\top + \\frac{M^2 N(1+N)}{(N+1)^2} c c^\\top $$\n$$ S = \\left(\\sum_{i=1}^{N} s_i^2\\right) a a^\\top + \\frac{M^2 N}{N+1} c c^\\top $$\n令$\\lambda_a = \\sum_{i=1}^N s_i^2$和$\\lambda_c(M) = M^2 \\frac{N}{N+1}$。该矩阵为$S = \\lambda_a a a^\\top + \\lambda_c(M) c c^\\top$。\n因为$a$和$c$是标准正交的（$a^\\top c = 0$, $\\|a\\|_2 = 1$, $\\|c\\|_2=1$），所以它们是$S$的特征向量：\n$S a = (\\lambda_a a a^\\top + \\lambda_c(M) c c^\\top) a = \\lambda_a a (a^\\top a) = \\lambda_a a$.\n$S c = (\\lambda_a a a^\\top + \\lambda_c(M) c c^\\top) c = \\lambda_c(M) c (c^\\top c) = \\lambda_c(M) c$.\n特征值是$\\lambda_a$和$\\lambda_c(M)$。在$\\{a, c\\}$张成的空间的正交补中的任何向量$v$都是特征值为$0$的特征向量。主成分是$S$对应于非零特征值的特征向量，按特征值的大小排序。第一主成分对应于最大的特征值。\n\n现在我们评估每个陈述。\n\nA. 对于足够大的$M$，第一主成分与$c$对齐。\n与向量$a$相关的特征值是$\\lambda_a = \\sum_{i=1}^N s_i^2$，这是一个有限常数。与向量$c$相关的特征值是$\\lambda_c(M) = M^2 \\frac{N}{N+1}$。当$M \\to \\infty$时，$\\lambda_c(M)$无界增长，而$\\lambda_a$保持不变。因此，对于足够大的$M$，有$\\lambda_c(M)  \\lambda_a$。最大特征值将是$\\lambda_c(M)$，相应的特征向量（第一主成分）将是$c$。这个陈述是**正确的**。\n\nB. 通过减去$\\bar{x}$进行中心化后，离群点的贡献被抵消，因此对于所有的$M$，第一主成分必然保持与$a$对齐。\n这个断言是错误的。离群点的贡献没有被抵消。中心化的离群点是$x_{N+1}' = \\frac{MN}{N+1} c$，这是非零的。如选项A的分析所示，对于大的$M$，第一主成分与$c$对齐，而不是$a$。这个陈述是**不正确的**。\n\nC. 存在一个由$M^2 \\frac{N}{N+1} = \\sum_{i=1}^N s_i^2$决定的切换阈值，在该阈值处，第一主成分在$a$和$c$之间的对齐方式发生改变。\n第一主成分由两个特征值$\\lambda_a$和$\\lambda_c(M)$中较大的一个决定。当这两个特征值相等时，即$\\lambda_a = \\lambda_c(M)$，第一主成分的身份发生切换。代入特征值的表达式，我们得到$\\sum_{i=1}^N s_i^2 = M^2 \\frac{N}{N+1}$。这个方程定义了发生切换的$M$的阈值。这个陈述是**正确的**。\n\nD. 对于大的$M$，$X'$的最大奇异值与$\\sqrt{\\frac{N}{N+1}}\\,M$成比例，不计$M$的低阶项。\n$X'$的奇异值$\\sigma_j$是$S = (X')^\\top X'$的特征值的平方根。对于大的$M$，最大的特征值是$\\lambda_{max} = \\lambda_c(M) = M^2 \\frac{N}{N+1}$。相应的最大奇异值是$\\sigma_1 = \\sqrt{\\lambda_c(M)} = \\sqrt{M^2 \\frac{N}{N+1}} = M \\sqrt{\\frac{N}{N+1}}$。这个表达式与陈述所声称的完全一致，没有低阶项。这个陈述是**正确的**。\n\nE. 如果$a^\\top c = 0$，那么$X'$的前两个右奇异向量不必是正交的。\n$X'$的右奇异向量是SVD分解$X' = U \\Sigma V^\\top$中矩阵$V$的列。根据奇异值分解的定义，矩阵$V$是一个正交矩阵。因此，它的列构成一个标准正交向量集。因此，任何两个不同的右奇异向量必须是正交的。该陈述与SVD的性质直接矛盾。这个陈述是**不正确的**。\n\nF. 当$M \\to \\infty$时，最佳秩-1近似（在由$X'$导出的弗罗贝尼乌斯范数下）的平方误差收敛于$\\sum_{i=1}^N s_i^2$。\n根据Eckart-Young-Mirsky定理，$X'$的最佳秩-k近似的弗罗贝尼乌斯范数平方误差是从$k+1$到矩阵秩的奇异值平方和。对于秩-1近似（$k=1$），这个误差是$\\sum_{j=2}^{\\text{rank}} \\sigma_j^2$。奇异值的平方是$S$的特征值。当$M \\to \\infty$时，最大的特征值是$\\lambda_1 = \\lambda_c(M) = M^2 \\frac{N}{N+1}$，第二大的特征值是$\\lambda_2 = \\lambda_a = \\sum_{i=1}^N s_i^2$。所有其他特征值都是$0$。因此，平方误差是$\\lambda_2 + \\lambda_3 + \\dots = \\lambda_a + 0 + \\dots = \\sum_{i=1}^N s_i^2$。这是一个常数值。因此，误差收敛于这个值。这个陈述是**正确的**。", "answer": "$$\\boxed{ACDF}$$", "id": "2435636"}]}