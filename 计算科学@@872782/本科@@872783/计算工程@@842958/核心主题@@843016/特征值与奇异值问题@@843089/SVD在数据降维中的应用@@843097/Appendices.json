{"hands_on_practices": [{"introduction": "奇异值分解（SVD）最直接的应用之一是数据压缩。该实践通过一个计算流体动力学（CFD）中的速度场数据的假设场景，让您亲手比较两种数据缩减策略：基于SVD的截断和更直观的空间粗化（即块平均）。通过量化这两种方法在数据重建上的误差，您将深刻体会到SVD为何能够在给定压缩率下，提供理论上最优的低秩逼近，从而最大限度地保留原始数据中的关键信息。[@problem_id:2371486]", "problem": "考虑一个来自计算流体力学 (CFD) 的双分量速度场，其定义在一个具有 $m$ 行和 $n$ 列的矩形网格上。设空间域为 $[0,1] \\times [0,1]$，网格点坐标为 $x_j = \\frac{j}{n-1}$（对于 $j \\in \\{0,1,\\dots,n-1\\}$）和 $y_i = \\frac{i}{m-1}$（对于 $i \\in \\{0,1,\\dots,m-1\\}$），并约定如果 $n=1$ 则 $x_0 = 0$，如果 $m=1$ 则 $y_0 = 0$。定义每个网格点上速度的水平和垂直分量如下：\n$$\nu(i,j) = \\sin\\!\\big(2\\pi x_j\\big)\\cos\\!\\big(2\\pi y_i\\big) + 0.3 \\cos\\!\\big(4\\pi x_j + 0.1\\big)\\sin\\!\\big(2\\pi y_i\\big) + 0.1\\, y_i,\n$$\n$$\nv(i,j) = -\\cos\\!\\big(2\\pi x_j\\big)\\sin\\!\\big(2\\pi y_i\\big) + 0.25 \\sin\\!\\big(2\\pi x_j\\big)\\sin\\!\\big(4\\pi y_i + 0.3\\big) + 0.1\\, x_j,\n$$\n对所有有效的索引 $(i,j)$ 均成立。三角函数中的角度以弧度为单位。\n\n通过垂直堆叠这些分量，将该场聚合成一个实数矩阵 $M \\in \\mathbb{R}^{(2m)\\times n}$：\n$$\nM = \\begin{bmatrix} U \\\\ V \\end{bmatrix}, \\quad U_{i,j} = u(i,j), \\quad V_{i,j} = v(i,j).\n$$\n\n现比较两种数据降维策略及其重构方法：\n\n1. 秩为 $r$ 的奇异值分解 (SVD) 截断：设 $M$ 的奇异值分解为 $M = Q \\Sigma W^\\top$，其中 $Q \\in \\mathbb{R}^{(2m)\\times(2m)}$，$\\Sigma \\in \\mathbb{R}^{(2m)\\times n}$，$W \\in \\mathbb{R}^{n\\times n}$。其秩为 $r$ 的截断重构 $M_r$ 为\n$$\nM_r = Q_{[:,1:r]} \\,\\Sigma_{[1:r,1:r]} \\, W_{[:,1:r]}^\\top,\n$$\n其中 $r \\in \\mathbb{N}$ 满足 $1 \\le r \\le \\min(2m,n)$，记号 $A_{[:,1:r]}$ 表示选择前 $r$ 列，$A_{[1:r,1:r]}$ 表示选择前导 $r\\times r$ 主子矩阵。\n\n2. 空间粗化与块平均重构：给定正整数 $s_y$ 和 $s_x$，将 $U$ 和 $V$ 的 $m\\times n$ 网格划分为大小为 $s_y \\times s_x$ 的不重叠块，但在边界处块的大小可能较小。对每个块，用该块内原始所有元素的算术平均值替换该块中的所有元素。对 $U$ 和 $V$ 独立执行此操作，得到 $\\widehat{U}$ 和 $\\widehat{V}$，并定义粗化重构 $\\widehat{M} = \\begin{bmatrix} \\widehat{U} \\\\ \\widehat{V} \\end{bmatrix}$。\n\n对于每个重构 $\\widetilde{M} \\in \\{M_r, \\widehat{M}\\}$，使用 Frobenius 范数定义其相对重构误差为\n$$\n\\varepsilon(\\widetilde{M}) = \\frac{\\lVert M - \\widetilde{M} \\rVert_F}{\\lVert M \\rVert_F}.\n$$\n\n你的任务是实现一个程序，对下面指定的每个测试用例，根据给定的 $(m,n)$ 构建 $M$，计算秩为 $r$ 的 SVD 截断重构 $M_r$，使用块大小 $(s_y,s_x)$ 计算空间粗化重构 $\\widehat{M}$，评估误差 $\\varepsilon(M_r)$ 和 $\\varepsilon(\\widehat{M})$，并为每个测试用例返回单个浮点数值\n$$\n\\Delta = \\varepsilon(\\widehat{M}) - \\varepsilon(M_r).\n$$\n$\\Delta$ 的正值表示，对于该测试用例，秩为 $r$ 的 SVD 重构的相对误差小于粗化重构的相对误差。\n\n测试套件（角度以弧度为单位）：\n- 用例 1：$(m,n,r,s_y,s_x) = (48,64,8,4,4)$。\n- 用例 2：$(m,n,r,s_y,s_x) = (32,30,1,64,64)$。\n- 用例 3：$(m,n,r,s_y,s_x) = (64,24,6,8,6)$。\n- 用例 4：$(m,n,r,s_y,s_x) = (24,96,5,6,8)$。\n- 用例 5：$(m,n,r,s_y,s_x) = (40,50,3,1,1)$。\n\n最终输出格式：你的程序应生成单行输出，其中包含一个用方括号括起来的、逗号分隔的浮点数列表，这些浮点数按上述用例的顺序排列，即：\n$$\n[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4,\\Delta_5].\n$$\n任何行上都不应打印其他文本。本问题中没有物理单位，所有角度都以弧度为单位。每个 $\\Delta_k$ 都必须作为浮点数输出。答案必须严格按照上述定义计算，不得引入任何替代的归一化或加权方法。", "solution": "我们从第一性原理出发，对两种重构方法和误差度量进行形式化。实数矩阵 $M \\in \\mathbb{R}^{(2m)\\times n}$ 的奇异值分解 (SVD) 是一个形如 $M = Q \\Sigma W^\\top$ 的分解，其中 $Q \\in \\mathbb{R}^{(2m)\\times(2m)}$ 和 $W \\in \\mathbb{R}^{n\\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{(2m)\\times n}$ 是对角矩阵，其主对角线上有非负奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge 0$（其方形核心之外可能用零填充）。对于满足 $1 \\le r \\le \\min(2m,n)$ 的任意秩参数 $r$，其秩为 $r$ 的截断重构为：\n$$\nM_r = \\sum_{k=1}^{r} \\sigma_k \\, q_k \\, w_k^\\top = Q_{[:,1:r]}\\,\\Sigma_{[1:r,1:r]}\\,W_{[:,1:r]}^\\top,\n$$\n其中 $q_k$ 和 $w_k$ 分别是 $Q$ 和 $W$ 的第 $k$ 列。根据 Eckart–Young–Mirsky 定理，在所有秩至多为 $r$ 的矩阵中，$M_r$ 是 $M$ 在 Frobenius 范数意义下的最佳逼近。因此，其相对 Frobenius 误差为\n$$\n\\varepsilon(M_r) = \\frac{\\left\\|M - M_r\\right\\|_F}{\\left\\|M\\right\\|_F} = \\frac{\\sqrt{\\sum_{k=r+1}^{\\rho} \\sigma_k^2}}{\\sqrt{\\sum_{k=1}^{\\rho} \\sigma_k^2}},\n$$\n其中 $\\rho = \\operatorname{rank}(M)$。\n\n空间粗化重构是通过一个逐块平均算子定义的。对于给定的块大小 $(s_y,s_x)$（其中 $s_y \\in \\mathbb{N}$ 和 $s_x \\in \\mathbb{N}$），我们将索引集 $\\{0,1,\\dots,m-1\\} \\times \\{0,1,\\dots,n-1\\}$ 划分为笛卡尔块：\n$$\nB_{\\alpha,\\beta} = \\{(i,j) \\,\\mid\\, \\alpha s_y \\le i \\le \\min((\\alpha+1)s_y-1,m-1),\\ \\beta s_x \\le j \\le \\min((\\beta+1)s_x-1,n-1) \\},\n$$\n对于 $\\alpha \\in \\{0,1,\\dots,\\lceil m/s_y \\rceil - 1\\}$ 和 $\\beta \\in \\{0,1,\\dots,\\lceil n/s_x \\rceil - 1\\}$。对于任意矩阵 $A \\in \\mathbb{R}^{m\\times n}$，定义其分片常数投影 $\\mathcal{P}_{s_y,s_x}(A)$，即为每个块 $B_{\\alpha,\\beta}$ 赋予以下值：\n$$\n\\left(\\mathcal{P}_{s_y,s_x}(A)\\right)_{i,j} = \\frac{1}{|B_{\\alpha,\\beta}|}\\sum_{(p,q)\\in B_{\\alpha,\\beta}} A_{p,q} \\quad \\text{for all } (i,j)\\in B_{\\alpha,\\beta}.\n$$\n该算子是到“在每个块 $B_{\\alpha,\\beta}$ 上为常数的矩阵所构成的子空间”上的正交投影算子（相对于 Frobenius 内积）。将该算子应用于每个分量可得 $\\widehat{U}=\\mathcal{P}_{s_y,s_x}(U)$ 和 $\\widehat{V}=\\mathcal{P}_{s_y,s_x}(V)$，从而得到重构的堆叠矩阵 $\\widehat{M} = \\begin{bmatrix}\\widehat{U} \\\\ \\widehat{V}\\end{bmatrix}$。其相关的相对误差为\n$$\n\\varepsilon(\\widehat{M}) = \\frac{\\left\\|M - \\widehat{M}\\right\\|_F}{\\left\\|M\\right\\|_F}.\n$$\n\n速度场被确定性地指定如下：\n$$\nu(i,j) = \\sin(2\\pi x_j)\\cos(2\\pi y_i) + 0.3 \\cos(4\\pi x_j + 0.1)\\sin(2\\pi y_i) + 0.1\\, y_i,\n$$\n$$\nv(i,j) = -\\cos(2\\pi x_j)\\sin(2\\pi y_i) + 0.25 \\sin(2\\pi x_j)\\sin(4\\pi y_i + 0.3) + 0.1\\, x_j,\n$$\n其中 $x_j = \\frac{j}{n-1}$（当 $n1$ 时），如果 $n=1$ 则 $x_0=0$；$y_i = \\frac{i}{m-1}$（当 $m1$ 时），如果 $m=1$ 则 $y_0=0$。将 $U$ 和 $V$ 构建为 $m\\times n$ 数组并堆叠，即可得到 $M \\in \\mathbb{R}^{(2m)\\times n}$。\n\n对于每个测试元组 $(m,n,r,s_y,s_x)$，计算步骤直接遵循以下定义：\n- 通过在网格点上评估 $u(i,j)$ 和 $v(i,j)$ 并进行堆叠，根据指定的 $m$ 和 $n$ 生成 $M$。\n- 计算秩为 $r$ 的 SVD 截断 $M_r$ 及其相对 Frobenius 误差 $\\varepsilon(M_r)$。\n- 使用给定的 $(s_y,s_x)$ 计算块平均重构 $\\widehat{U}$ 和 $\\widehat{V}$，将它们堆叠成 $\\widehat{M}$，并计算 $\\varepsilon(\\widehat{M})$。\n- 报告标量差值 $\\Delta = \\varepsilon(\\widehat{M}) - \\varepsilon(M_r)$。\n\n该测试套件涵盖了一个具有中等块大小和秩的典型案例、一个块大小超过域（单块平均）的边界情况、一个 $2m \\gg n$ 的高矩阵案例、一个 $n \\gg 2m$ 的宽矩阵案例，以及一个 $(s_y,s_x)=(1,1)$ 的恒等粗化案例（其粗化误差恰好为零）。最终输出是一个列表 $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4,\\Delta_5]$，按顺序对应于这些案例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef generate_velocity_field(m: int, n: int):\n    # Coordinates in [0,1], handle degenerate sizes\n    if n  1:\n        x = np.linspace(0.0, 1.0, n)\n    else:\n        x = np.array([0.0])\n    if m  1:\n        y = np.linspace(0.0, 1.0, m)\n    else:\n        y = np.array([0.0])\n\n    X, Y = np.meshgrid(x, y, indexing='xy')\n\n    # Define u and v components as specified\n    u = np.sin(2.0 * np.pi * X) * np.cos(2.0 * np.pi * Y) \\\n        + 0.3 * np.cos(4.0 * np.pi * X + 0.1) * np.sin(2.0 * np.pi * Y) \\\n        + 0.1 * Y\n\n    v = -np.cos(2.0 * np.pi * X) * np.sin(2.0 * np.pi * Y) \\\n        + 0.25 * np.sin(2.0 * np.pi * X) * np.sin(4.0 * np.pi * Y + 0.3) \\\n        + 0.1 * X\n\n    return u, v\n\ndef stack_components(u: np.ndarray, v: np.ndarray) - np.ndarray:\n    # Stack u and v vertically: shape (2m, n)\n    return np.vstack([u, v])\n\ndef truncated_svd_reconstruction(M: np.ndarray, r: int) - np.ndarray:\n    # Compute rank-r truncated SVD reconstruction\n    U, s, Vh = np.linalg.svd(M, full_matrices=False)\n    r = int(r)\n    Ur = U[:, :r]\n    sr = s[:r]\n    Vhr = Vh[:r, :]\n    # Equivalent to Ur @ np.diag(sr) @ Vhr but more efficient:\n    return (Ur * sr) @ Vhr\n\ndef block_mean_reconstruction(A: np.ndarray, sy: int, sx: int) - np.ndarray:\n    m, n = A.shape\n    R = np.empty_like(A)\n    # Iterate over blocks\n    for r0 in range(0, m, sy):\n        r1 = min(r0 + sy, m)\n        for c0 in range(0, n, sx):\n            c1 = min(c0 + sx, n)\n            block = A[r0:r1, c0:c1]\n            mean_val = block.mean() if block.size  0 else 0.0\n            R[r0:r1, c0:c1] = mean_val\n    return R\n\ndef relative_frobenius_error(A: np.ndarray, B: np.ndarray) - float:\n    diff = A - B\n    num = np.linalg.norm(diff, ord='fro')\n    den = np.linalg.norm(A, ord='fro')\n    # In our construction, den should be  0, but guard just in case\n    if den == 0.0:\n        return 0.0 if num == 0.0 else float('inf')\n    return float(num / den)\n\ndef solve():\n    # Define the test cases from the problem statement as (m, n, r, s_y, s_x)\n    test_cases = [\n        (48, 64, 8, 4, 4),\n        (32, 30, 1, 64, 64),\n        (64, 24, 6, 8, 6),\n        (24, 96, 5, 6, 8),\n        (40, 50, 3, 1, 1),\n    ]\n\n    results = []\n    for m, n, r, sy, sx in test_cases:\n        # Generate field and stack\n        u, v = generate_velocity_field(m, n)\n        M = stack_components(u, v)\n\n        # Truncated SVD reconstruction and error\n        Mr = truncated_svd_reconstruction(M, r)\n        err_svd = relative_frobenius_error(M, Mr)\n\n        # Block coarsening reconstruction and error (apply per component)\n        u_hat = block_mean_reconstruction(u, sy, sx)\n        v_hat = block_mean_reconstruction(v, sy, sx)\n        M_hat = stack_components(u_hat, v_hat)\n        err_coarse = relative_frobenius_error(M, M_hat)\n\n        # Delta = coarsening error - SVD error\n        delta = err_coarse - err_svd\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    # Format with a reasonable precision for readability.\n    print(\"[\" + \",\".join(f\"{val:.10f}\" for val in results) + \"]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2371486"}, {"introduction": "在许多工程和科学问题中，我们面临着求解形如 $A x = b$ 的线性反问题。当矩阵 $A$ 是病态的（ill-conditioned）时，对数据 $b$ 的微小扰动（如测量噪声）都可能导致解 $x$ 出现巨大误差。本练习引导您使用截断奇异值分解（TSVD）作为一种正则化方法来稳定解。您将通过一个经典的病态希尔伯特矩阵（Hilbert matrix）案例，计算并比较“残差范数”（$\\|A \\tilde{x}_{k} - b\\|_{2}$）和“解误差范数”（$\\|\\tilde{x}_{k} - x\\|_{2}$），从而揭示正则化中的一个核心权衡：对数据拟合得更好（残差更小）并不总意味着解更接近真实值（解误差更小）。[@problem_id:2371492]", "problem": "考虑一个计算工程中的线性逆问题，其模型为 $A x = b$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个病态矩阵，$x \\in \\mathbb{R}^{n}$ 是一个未知参数向量，$b \\in \\mathbb{R}^{m}$ 是给定的数据。病态性会导致 $b$ 中的微小扰动引起解的巨大变化，使得该问题在有限精度计算中实际上是不适定的。您将研究一种使用奇异值分解 (SVD) 的数据降维方法，以构造一个截断SVD解，并比较解的残差和解的误差。\n\n基本原理：\n- 使用奇异值分解 (SVD) 的定义：任何实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 都存在一个分解 $A = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个对角矩阵，其非负对角元按非递增顺序排列。\n- 使用最小二乘原理：对于超定系统，解应最小化残差的欧几里得范数 $\\|A \\tilde{x} - b\\|_{2}$。\n- 使用欧几里得范数的性质及其正交不变性。\n\n您的任务：\n- 对每个测试用例，构造一个矩阵 $A$、一个真值向量 $x$ 和一个数据向量 $b = A x + e$，其中 $e$ 是一个扮演测量噪声角色的确定性扰动向量。\n- 通过仅保留 $A$ 的 $k$ 个最大奇异分量来计算截断SVD (TSVD) 解 $\\tilde{x}_{k}$。\n- 对每个用例，计算：\n  1. 残差范数 $r = \\|A \\tilde{x}_{k} - b\\|_{2}$。\n  2. 解误差范数 $e_{x} = \\|\\tilde{x}_{k} - x\\|_{2}$。\n- 所有范数均使用欧几里得范数，并将所有结果表示为四舍五入到恰好 $6$ 位小数的实数。\n\n所有测试用例的构造规则：\n- 按元素定义 Hilbert 型矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其元素为 $A_{ij} = \\dfrac{1}{i + j - 1}$，$1 \\le i \\le m$, $1 \\le j \\le n$。\n- 定义真值向量 $x \\in \\mathbb{R}^{n}$，其元素为 $x_{i} = \\dfrac{(-1)^{i}}{i}$，$1 \\le i \\le n$。\n- 定义确定性扰动向量 $e \\in \\mathbb{R}^{m}$，其元素为 $e_{i} = \\sigma \\cdot (-1)^{i}$，$1 \\le i \\le m$，其中标量 $\\sigma \\ge 0$ 由每个测试用例给定。\n- 构造 $b = A x + e$。\n- 如下构造截断SVD解：计算 $A$ 的SVD，并仅保留 $k$ 个最大的奇异分量来构建 $\\tilde{x}_{k}$。如果 $k = 0$，则定义 $\\tilde{x}_{0}$ 为 $\\mathbb{R}^{n}$ 中的零向量。\n- 计算 $r = \\|A \\tilde{x}_{k} - b\\|_{2}$ 和 $e_{x} = \\|\\tilde{x}_{k} - x\\|_{2}$。\n- 将 $r$ 和 $e_{x}$ 四舍五入到恰好 $6$ 位小数。\n\n测试套件：\n- 用例 $1$：$m = 8$, $n = 8$, $k = 0$, $\\sigma = 10^{-6}$。\n- 用例 $2$：$m = 8$, $n = 8$, $k = 2$, $\\sigma = 10^{-3}$。\n- 用例 $3$：$m = 8$, $n = 8$, $k = 4$, $\\sigma = 10^{-3}$。\n- 用例 $4$：$m = 8$, $n = 8$, $k = 4$, $\\sigma = 0$。\n- 用例 $5$：$m = 8$, $n = 8$, $k = 8$, $\\sigma = 10^{-3}$。\n- 用例 $6$：$m = 10$, $n = 6$, $k = 3$, $\\sigma = 10^{-4}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由逗号分隔的配对列表，并置于一对方括号中。每个配对 $[r,e_{x}]$ 对应一个测试用例，顺序与列表中的顺序相同，其中的两个数字都四舍五入到 $6$ 位小数。该行中不允许出现任何空格。\n- 例如，整体输出应类似于 $[[r_{1},e_{x,1}],[r_{2},e_{x,2}],\\dots,[r_{6},e_{x,6}]]$，其中每个 $r_{i}$ 和 $e_{x,i}$ 都是小数点后恰好有 $6$ 位数字的十进制数。", "solution": "所提出的问题是有效的。它在数值线性代数和逆问题这一成熟领域具有科学依据，具体来说是奇异值分解 (SVD) 在正则化中的应用。该问题陈述是清晰的，所有必要的参数和构造规则都已明确定义，确保了每个测试用例都有唯一且可计算的解。其中没有逻辑矛盾、歧义或事实错误的假设。\n\n所讨论的问题是求解线性方程组 $A x = b$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个病态矩阵，$x \\in \\mathbb{R}^{n}$ 是未知参数向量，$b \\in \\mathbb{R}^{m}$ 是被噪声污染的数据向量。数据向量建模为 $b = A x_{\\text{true}} + e$，其中 $x_{\\text{true}}$ 是真值解，$e$ 是代表测量噪声的扰动向量。$A$ 的病态性意味着 $b$ 中的微小扰动可能导致通过简单地对系统求逆所获得的解出现巨大的、不符合物理规律的振荡。\n\n解决这种不适定性问题的一种标准方法是正则化，而截断奇异值分解 (TSVD) 是实现正则化的一种强大技术。矩阵 $A$ 的SVD分解由下式给出：\n$$ A = U \\Sigma V^{\\top} $$\n其中 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵 ($U^{\\top}U = I_m$, $V^{\\top}V = I_n$)，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 是一个包含奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots \\ge \\sigma_r  0$ 的矩形对角矩阵，其中 $r = \\text{rank}(A)$。设 $U$ 的列为 $\\{u_i\\}_{i=1}^m$，$V$ 的列为 $\\{v_i\\}_{i=1}^n$。\n\n最小化 $\\|Ax - b\\|_2$ 的标准最小二乘解可以通过 Moore-Penrose 伪逆 $A^{\\dagger} = V \\Sigma^{\\dagger} U^{\\top}$ 来表示：\n$$ \\hat{x} = A^{\\dagger}b = \\sum_{i=1}^{r} \\frac{u_i^{\\top}b}{\\sigma_i} v_i $$\n对于病态矩阵，许多奇异值 $\\sigma_i$ 都非常小。如果分子 $u_i^{\\top}b$ 没有相应地小，那么除以小的 $\\sigma_i$ 会放大来自数据向量 $b$ 的噪声，从而破坏解。\n\nTSVD 方法通过截断求和来对解进行正则化，仅包括与 $k$ 个最大奇异值相关的分量，其中 $k \\le r$ 是截断参数。TSVD 解记作 $\\tilde{x}_k$，定义为：\n$$ \\tilde{x}_k = \\sum_{i=1}^{k} \\frac{u_i^{\\top}b}{\\sigma_i} v_i $$\n对于截断参数 $k=0$ 的情况，求和为空，解被定义为零向量，即 $\\tilde{x}_0 = \\mathbf{0} \\in \\mathbb{R}^n$。\n\n我们的任务是计算两个关键指标：残差范数 $r = \\|A\\tilde{x}_k - b\\|_2$ 和解误差范数 $e_x = \\|\\tilde{x}_k - x_{\\text{true}}\\|_2$。\n\n残差向量为 $A\\tilde{x}_k - b$。使用 $Av_i = \\sigma_i u_i$，我们有：\n$$ A\\tilde{x}_k = A \\left(\\sum_{i=1}^{k} \\frac{u_i^{\\top}b}{\\sigma_i} v_i\\right) = \\sum_{i=1}^{k} \\frac{u_i^{\\top}b}{\\sigma_i} (Av_i) = \\sum_{i=1}^{k} (u_i^{\\top}b) u_i $$\n数据向量 $b$ 可以在 $U$ 的标准正交基中展开为 $b = \\sum_{j=1}^{m} (u_j^{\\top}b) u_j$。因此，残差为：\n$$ A\\tilde{x}_k - b = \\sum_{i=1}^{k} (u_i^{\\top}b) u_i - \\sum_{j=1}^{m} (u_j^{\\top}b) u_j = - \\sum_{j=k+1}^{m} (u_j^{\\top}b) u_j $$\n根据正交向量的勾股定理，残差的范数平方为：\n$$ r^2 = \\|A\\tilde{x}_k - b\\|_2^2 = \\sum_{j=k+1}^{m} (u_j^{\\top}b)^2 $$\n\n解误差向量为 $\\tilde{x}_k - x_{\\text{true}}$。我们使用 $b = Ax_{\\text{true}} + e$ 来展开 $\\tilde{x}_k$：\n$$ \\tilde{x}_k = \\sum_{i=1}^{k} \\frac{u_i^{\\top}(Ax_{\\text{true}} + e)}{\\sigma_i} v_i = \\sum_{i=1}^{k} \\frac{u_i^{\\top}Ax_{\\text{true}}}{\\sigma_i} v_i + \\sum_{i=1}^{k} \\frac{u_i^{\\top}e}{\\sigma_i} v_i $$\n使用关系式 $u_i^{\\top}A = (A^{\\top}u_i)^{\\top} = (V\\Sigma^{\\top}U^{\\top}u_i)^{\\top} = (\\sigma_i v_i)^{\\top} = \\sigma_i v_i^{\\top}$，第一项变为：\n$$ \\sum_{i=1}^{k} \\frac{\\sigma_i v_i^{\\top}x_{\\text{true}}}{\\sigma_i} v_i = \\sum_{i=1}^{k} (v_i^{\\top}x_{\\text{true}}) v_i $$\n真值解 $x_{\\text{true}}$ 可以在 $V$ 的标准正交基中展开为 $x_{\\text{true}} = \\sum_{j=1}^{n} (v_j^{\\top}x_{\\text{true}}) v_j$。因此，误差向量为：\n$$ \\tilde{x}_k - x_{\\text{true}} = \\left( \\sum_{i=1}^{k} (v_i^{\\top}x_{\\text{true}}) v_i - \\sum_{j=1}^{n} (v_j^{\\top}x_{\\text{true}}) v_j \\right) + \\sum_{i=1}^{k} \\frac{u_i^{\\top}e}{\\sigma_i} v_i $$\n$$ \\tilde{x}_k - x_{\\text{true}} = \\underbrace{- \\sum_{j=k+1}^{n} (v_j^{\\top}x_{\\text{true}}) v_j}_{\\text{截断误差}} + \\underbrace{\\sum_{i=1}^{k} \\frac{u_i^{\\top}e}{\\sigma_i} v_i}_{\\text{扰动误差}} $$\n这两个误差分量是正交的，因为它们是标准正交基 $\\{v_i\\}$ 的不相交子集的线性组合。解误差的范数平方是这些分量范数平方的和：\n$$ e_x^2 = \\|\\tilde{x}_k - x_{\\text{true}}\\|_2^2 = \\sum_{j=k+1}^{n} (v_j^{\\top}x_{\\text{true}})^2 + \\sum_{i=1}^{k} \\left(\\frac{u_i^{\\top}e}{\\sigma_i}\\right)^2 $$\n截断参数 $k$ 的最优选择涉及一个权衡：增加 $k$ 会减少截断误差，但会增加扰动误差，特别是当噪声 $e$ 显著且奇异值 $\\sigma_i$ 很小时。\n\n对每个测试用例，我们应用以下步骤：\n1.  构造 Hilbert 矩阵 $A \\in \\mathbb{R}^{m \\times n}$，其元素为 $A_{ij} = \\frac{1}{(i+1) + (j+1) - 1} = \\frac{1}{i+j+1}$ (对于从0开始索引的 $i,j$）。\n2.  构造真值向量 $x \\in \\mathbb{R}^{n}$，其元素为 $x_i = \\frac{(-1)^{i+1}}{i+1}$ (对于从0开始索引的 $i$）。\n3.  构造扰动向量 $e \\in \\mathbb{R}^{m}$，其元素为 $e_i = \\sigma \\cdot (-1)^{i+1}$ (对于从0开始索引的 $i$）。\n4.  构造数据向量 $b = Ax + e$。\n5.  计算 $A$ 的SVD：$A = U \\Sigma V^{\\top}$。\n6.  如果 $k=0$，则设 $\\tilde{x}_0 = \\mathbf{0}$。否则，计算 $\\tilde{x}_k = \\sum_{i=1}^{k} \\frac{u_i^{\\top}b}{\\sigma_i} v_i$。\n7.  计算残差范数 $r = \\|A\\tilde{x}_k - b\\|_2$ 和解误差范数 $e_x = \\|\\tilde{x}_k - x\\|_2$。\n8.  将两个结果都四舍五入到 $6$ 位小数。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a series of linear inverse problems using Truncated SVD (TSVD).\n\n    For each test case, it constructs a Hilbert matrix A, a ground-truth\n    solution x, and a perturbed data vector b. It then computes the TSVD\n    solution x_tilde_k for a given truncation level k. Finally, it calculates\n    the residue norm ||A*x_tilde_k - b||_2 and the solution error norm\n    ||x_tilde_k - x||_2.\n    \"\"\"\n\n    test_cases = [\n        # (m, n, k, sigma)\n        (8, 8, 0, 1e-6),\n        (8, 8, 2, 1e-3),\n        (8, 8, 4, 1e-3),\n        (8, 8, 4, 0.0),\n        (8, 8, 8, 1e-3),\n        (10, 6, 3, 1e-4),\n    ]\n\n    results_list = []\n\n    for m, n, k, sigma in test_cases:\n        # Step 1: Construct the Hilbert matrix A\n        # Using 1-based indexing in formula, A_ij = 1/(i+j-1)\n        # In 0-based numpy, this is 1/((i+1)+(j+1)-1) = 1/(i+j+1)\n        i_indices, j_indices = np.meshgrid(np.arange(m), np.arange(n), indexing='ij')\n        A = 1.0 / (i_indices + j_indices + 1)\n\n        # Step 2: Construct the ground-truth vector x\n        # Using 1-based indexing in formula, x_i = (-1)^i/i for i=1..n\n        idx_n = np.arange(1, n + 1)\n        x_true = ((-1)**idx_n) / idx_n\n\n        # Step 3: Construct the perturbation vector e\n        # Using 1-based indexing in formula, e_i = sigma * (-1)^i for i=1..m\n        idx_m = np.arange(1, m + 1)\n        e = sigma * ((-1)**idx_m)\n\n        # Step 4: Form the data vector b\n        b = A @ x_true + e\n\n        # Step 5: Compute the SVD of A\n        # full_matrices=True to match the problem statement's definition\n        U, s, Vh = np.linalg.svd(A, full_matrices=True)\n        # Vh is V.T\n\n        # Step 6: Compute the TSVD solution x_tilde_k\n        if k == 0:\n            x_tilde_k = np.zeros(n)\n        else:\n            # Slices for the truncated components\n            s_k = s[:k]\n            U_k = U[:, :k]\n            Vh_k = Vh[:k, :]\n\n            # Compute x_tilde_k = V_k * (S_k^-1 * (U_k^T * b))\n            # This is numerically more stable than forming the pseudoinverse matrix.\n            c = U_k.T @ b\n            w = c / s_k\n            x_tilde_k = Vh_k.T @ w\n\n        # Step 7: Calculate residue and solution error norms\n        residue_norm = np.linalg.norm(A @ x_tilde_k - b)\n        solution_error_norm = np.linalg.norm(x_tilde_k - x_true)\n        \n        # Step 8: Format results to 6 decimal places\n        r_str = f\"{residue_norm:.6f}\"\n        e_x_str = f\"{solution_error_norm:.6f}\"\n        \n        results_list.append(f\"[{r_str},{e_x_str}]\")\n\n    # Final print statement in the exact required format\n    final_output = f\"[{','.join(results_list)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2371492"}, {"introduction": "从传感器阵列到数字图像，数据缺失是一个普遍存在的问题。如果我们可以合理地假设完整数据具有低秩结构（例如，传感器读数高度相关），就可以利用这一先验知识来“填补”或“修复”缺失的数值。本实践将指导您实现一个基于SVD的迭代算法，用于解决矩阵完成（matrix completion）问题。通过在每次迭代中将数据投影到低秩空间，该算法能有效恢复缺失的条目。这个练习不仅展示了SVD作为复杂数据恢复算法核心构件的强大能力，也让您接触到现代数据科学中的一个前沿领域。[@problem_id:2371448]", "problem": "您正在处理一个源于具有相关通道的传感器阵列的数据缩减任务。$m$ 个传感器在 $n$ 个时间步上记录的数据表示为一个实矩阵 $X_{\\text{true}} \\in \\mathbb{R}^{m \\times n}$。由于通信丢失和数据损坏，只有一部分条目被观测到。令 $\\Omega \\subset \\{1,\\dots,m\\} \\times \\{1,\\dots,n\\}$ 表示观测条目的索引集，并令 $P_{\\Omega}$ 为采样算子，其定义为：若 $(i,j) \\in \\Omega$，则 $(P_{\\Omega}(Z))_{ij} = Z_{ij}$，否则 $(P_{\\Omega}(Z))_{ij} = 0$。目标是利用 $X_{\\text{true}}$ 具有低秩（反映了相关的传感器行为）这一假设，以及弗罗贝尼乌斯范数下的最佳秩-k近似是通过截断奇异值分解（SVD）得到的这一事实，来重构一个低秩矩阵 $X \\in \\mathbb{R}^{m \\times n}$ 以逼近 $X_{\\text{true}}$。\n\n需要使用的基本定义和事实：\n- 奇异值分解（SVD）指出，任何矩阵 $Z \\in \\mathbb{R}^{m \\times n}$ 都可以写成 $Z = U \\Sigma V^{\\top}$ 的形式，其中 $U \\in \\mathbb{R}^{m \\times m}$ 为正交矩阵， $V \\in \\mathbb{R}^{n \\times n}$ 为正交矩阵，$\\Sigma \\in \\mathbb{R}^{m \\times n}$ 为对角非负矩阵。\n- 弗罗贝尼乌斯范数 $\\|Z\\|_{F} = \\sqrt{\\sum_{i,j} Z_{ij}^{2}}$。\n- Eckart–Young 定理：对于给定的 $k \\in \\mathbb{N}$，在弗罗贝尼乌斯范数下，对 $Z$ 的最佳秩-k 近似可以通过将 $Z$ 的 SVD 截断为其最大的 $k$ 个奇异值及对应的奇异向量来获得。\n\n考虑以下通过低秩近似进行修复的定点迭代方案：\n- 初始化 $X^{(0)} = 0$。\n- 对于迭代 $t = 0,1,2,\\dots$：\n  1. 构造填充矩阵 $Y^{(t)} = P_{\\Omega}(Y) + P_{\\Omega^{c}}(X^{(t)})$，其中 $Y = P_{\\Omega}(X_{\\text{true}} + N)$ 是观测到的数据（可能含噪声），$N$ 是一个噪声矩阵（可能为零），$P_{\\Omega^{c}}$ 是互补采样算子，它保留不在 $\\Omega$ 中的条目，并将 $\\Omega$ 中的条目置零。\n  2. 通过保留最大的 $k$ 个奇异值和对应的奇异向量，计算 $Y^{(t)}$ 的秩-k 截断SVD近似 $X^{(t+1)}$。\n- 当 $\\|X^{(t+1)} - X^{(t)}\\|_{F} / \\max(1, \\|X^{(t)}\\|_{F}) \\le \\varepsilon$ 或当 $t$ 达到预设的最大迭代次数时停止，并返回 $X^{(t+1)}$。\n\n实现该算法并在以下测试套件上进行评估。对于每个测试，计算相对弗罗贝尼乌斯误差 $\\|X_{\\text{est}} - X_{\\text{true}}\\|_{F} / \\|X_{\\text{true}}\\|_{F}$，结果为一个浮点数。\n\n测试套件（所有数字均为实数标量，每个矩阵都明确给出）：\n\n- 案例 A（理想路径，中等采样率，精确低秩）：\n  - 维度：$m = 6$, $n = 5$。\n  - 构造 $X_{\\text{true}} = A_{A} B_{A}^{\\top}$，其中 $A_{A} \\in \\mathbb{R}^{6 \\times 2}$ 且 $B_{A} \\in \\mathbb{R}^{5 \\times 2}$：\n    - $A_{A} = \\begin{bmatrix}\n      1  0 \\\\\n      0  1 \\\\\n      1  1 \\\\\n      2  -1 \\\\\n      -1  2 \\\\\n      0.5  1.5\n      \\end{bmatrix}$,\n      $B_{A} = \\begin{bmatrix}\n      2  1 \\\\\n      1  -1 \\\\\n      0  2 \\\\\n      -1  0.5 \\\\\n      1.5  -0.5\n      \\end{bmatrix}$。\n  - 掩码 $M_{A} \\in \\{0,1\\}^{6 \\times 5}$，其中1表示观测到的条目：\n    - $M_{A} = \\begin{bmatrix}\n      1  1  0  1  0 \\\\\n      0  1  1  0  1 \\\\\n      1  0  1  1  0 \\\\\n      1  1  0  0  1 \\\\\n      0  1  1  1  0 \\\\\n      1  0  0  1  1\n      \\end{bmatrix}$。\n  - 噪声 $N_{A} = 0$（所有条目均为零）。\n  - 目标秩 $k = 2$。\n  - 停止参数：最大迭代次数 $t_{\\max} = 1000$，容差 $\\varepsilon = 10^{-10}$。\n\n- 案例 B（边界情况，完全观测，在真实秩下精确恢复）：\n  - 维度：$m = 4$, $n = 4$。\n  - 构造 $X_{\\text{true}} = A_{B} B_{B}^{\\top}$，其中 $A_{B} \\in \\mathbb{R}^{4 \\times 2}$ 且 $B_{B} \\in \\mathbb{R}^{4 \\times 2}$：\n    - $A_{B} = \\begin{bmatrix}\n      2  0 \\\\\n      0  1 \\\\\n      1  -1 \\\\\n      3  2\n      \\end{bmatrix}$,\n      $B_{B} = \\begin{bmatrix}\n      1  2 \\\\\n      0.5  -1 \\\\\n      2  0 \\\\\n      1  1\n      \\end{bmatrix}$。\n  - 掩码 $M_{B}$ 是 $\\mathbb{R}^{4 \\times 4}$ 中的全1矩阵。\n  - 噪声 $N_{B} = 0$。\n  - 目标秩 $k = 2$。\n  - 停止参数：最大迭代次数 $t_{\\max} = 1000$，容差 $\\varepsilon = 10^{-12}$。\n\n- 案例 C（边缘情况，整行缺失）：\n  - 维度：$m = 5$, $n = 5$。\n  - 构造 $X_{\\text{true}} = A_{C} B_{C}^{\\top}$，其中 $A_{C} \\in \\mathbb{R}^{5 \\times 2}$ 且 $B_{C} \\in \\mathbb{R}^{5 \\times 2}$：\n    - $A_{C} = \\begin{bmatrix}\n      1  0 \\\\\n      0  1 \\\\\n      1  1 \\\\\n      2  1 \\\\\n      -1  2\n      \\end{bmatrix}$,\n      $B_{C} = \\begin{bmatrix}\n      1  1 \\\\\n      2  -1 \\\\\n      -1  0.5 \\\\\n      0  2 \\\\\n      1  -2\n      \\end{bmatrix}$。\n  - 掩码 $M_{C} \\in \\{0,1\\}^{5 \\times 5}$：\n    - $M_{C} = \\begin{bmatrix}\n      1  0  1  1  0 \\\\\n      1  1  0  0  1 \\\\\n      0  0  0  0  0 \\\\\n      1  1  1  0  1 \\\\\n      0  1  0  1  1\n      \\end{bmatrix}$。\n  - 噪声 $N_{C} = 0$。\n  - 目标秩 $k = 2$。\n  - 停止参数：最大迭代次数 $t_{\\max} = 2000$，容差 $\\varepsilon = 10^{-12}$。\n\n- 案例 D（含噪声观测，中等采样率）：\n  - 维度：$m = 5$, $n = 4$。\n  - 构造 $X_{\\text{true}} = A_{D} B_{D}^{\\top}$，其中 $A_{D} \\in \\mathbb{R}^{5 \\times 2}$ 且 $B_{D} \\in \\mathbb{R}^{4 \\times 2}$：\n    - $A_{D} = \\begin{bmatrix}\n      1  0 \\\\\n      0  1 \\\\\n      1  -1 \\\\\n      2  1 \\\\\n      -1  2\n      \\end{bmatrix}$,\n      $B_{D} = \\begin{bmatrix}\n      1  2 \\\\\n      2  1 \\\\\n      -1  1 \\\\\n      0.5  -0.5\n      \\end{bmatrix}$。\n  - 掩码 $M_{D} \\in \\{0,1\\}^{5 \\times 4}$：\n    - $M_{D} = \\begin{bmatrix}\n      1  1  0  1 \\\\\n      1  0  1  1 \\\\\n      1  1  0  0 \\\\\n      0  1  1  1 \\\\\n      1  0  1  0\n      \\end{bmatrix}$。\n  - 加性噪声 $N_{D} \\in \\mathbb{R}^{5 \\times 4}$：\n    - $N_{D} = \\begin{bmatrix}\n      0.01  -0.02  0  0 \\\\\n      -0.03  0  0.02  -0.01 \\\\\n      0.02  0.01  0  0 \\\\\n      0  -0.02  0.03  -0.01 \\\\\n      0.01  0  -0.02  0\n      \\end{bmatrix}$。\n  - 目标秩 $k = 2$。\n  - 停止参数：最大迭代次数 $t_{\\max} = 1500$，容差 $\\varepsilon = 10^{-10}$。\n\n实现要求：\n- 严格按照所述实现迭代方案，在每次迭代中对填充矩阵 $Y^{(t)}$ 使用秩-k 截断SVD。使用弗罗贝尼乌斯范数来衡量收敛性。\n- 对于每个案例，计算相对弗罗贝尼乌斯误差 $\\|X_{\\text{est}} - X_{\\text{true}}\\|_{F} / \\|X_{\\text{true}}\\|_{F}$，结果为一个四舍五入到六位小数的浮点数。\n- 最终输出格式：您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表的结果（例如，$[r_{A},r_{B},r_{C},r_{D}]$），其中 $r_{A}$、$r_{B}$、$r_{C}$ 和 $r_{D}$ 分别是案例 A、B、C 和 D 的四舍五入后的相对误差。不应打印任何其他文本。", "solution": "所提出的问题是计算工程领域中一个明确定义的任务，具体涉及传感器阵列的数据分析和信号处理领域。它涉及在底层真实数据为低秩的假设下，从不完整且可能含噪声的观测中重构数据矩阵。这是一个经典的矩阵补全问题。所提出的方法是一种基于奇异值分解（SVD）的迭代算法，SVD是低秩近似的一种标准且强大的技术。\n\n在继续之前，需要对问题陈述进行验证。\n\n**步骤1：提取的已知条件**\n- **数据模型：** 一个底层的低秩真实数据矩阵 $X_{\\text{true}} \\in \\mathbb{R}^{m \\times n}$。\n- **观测模型：** 一组观测到的条目由索引集 $\\Omega \\subset \\{1,\\dots,m\\} \\times \\{1,\\dots,n\\}$ 给出。观测值为 $Y = P_{\\Omega}(X_{\\text{true}} + N)$，其中 $N$ 是一个噪声矩阵，$P_{\\Omega}$ 是保留 $\\Omega$ 中条目并将其他条目置零的采样算子。\n- **迭代算法：**\n  - 初始化：$X^{(0)} = 0$。\n  - 迭代 $t=0, 1, 2, \\dots$：\n    1. $Y^{(t)} = P_{\\Omega}(Y) + P_{\\Omega^{c}}(X^{(t)})$，其中 $P_{\\Omega^{c}}$ 是互补采样算子。\n    2. $X^{(t+1)}$ 是 $Y^{(t)}$ 在弗罗贝尼乌斯范数下的最佳秩-k 近似，通过截断SVD获得。\n- **停止标准：** 当 $\\|X^{(t+1)} - X^{(t)}\\|_{F} / \\max(1, \\|X^{(t)}\\|_{F}) \\le \\varepsilon$ 或达到最大迭代次数 $t_{\\max}$ 时，迭代终止。\n- **评估指标：** 相对弗罗贝尼乌斯误差 $\\|X_{\\text{est}} - X_{\\text{true}}\\|_{F} / \\|X_{\\text{true}}\\|_{F}$，其中 $X_{\\text{est}}$ 是最终估计的矩阵。\n- **测试案例：** 提供了四个不同的案例（A、B、C、D），并明确定义了矩阵 $A, B$（用于构造 $X_{\\text{true}} = AB^{\\top}$）、观测掩码 $M$、噪声矩阵 $N$、维度 $m, n$、目标秩 $k$ 以及停止参数 $\\varepsilon, t_{\\max}$。\n\n**步骤2：验证**\n根据所需标准对问题进行评估：\n- **科学依据：** 该问题坚实地植根于线性代数和数值优化。使用SVD进行低秩近似由Eckart–Young定理证明是合理的。该迭代过程是解决矩阵补全问题的著名方法，与奇异值阈值算法相关。整个设置是科学严谨的。\n- **适定性：** 每个测试案例的所有必要参数、矩阵和条件都已明确定义。该算法是确定性的，目标函数（在数据约束下最小化秩）与给定的迭代求解器意味着唯一的计算结果。\n- **客观性：** 问题以精确的数学语言陈述，没有歧义或主观论断。\n\n**步骤3：结论**\n该问题被认定为**有效**。这是一个数值线性代数中的标准、公式明确的问题，具有清晰的指令和可验证的测试案例。现在可以构建解决方案。\n\n**解题步骤**\n\n目标是实现并评估指定的用于低秩矩阵补全的迭代算法。该算法的功能是通过反复强制执行两个属性：与观测数据的一致性和对低秩模型的遵守。\n\n核心迭代步骤定义为：\n$X^{(t+1)} = \\mathcal{S}_k(P_{\\Omega}(Y) + P_{\\Omega^{c}}(X^{(t)}))$\n其中 $\\mathcal{S}_k(Z)$ 表示计算矩阵 $Z$ 的最佳秩-k 近似的操作。根据 Eckart-Young 定理，如果 $Z$ 的 SVD 是 $Z = U \\Sigma V^{\\top}$，则 $\\mathcal{S}_k(Z) = U_k \\Sigma_k V_k^{\\top}$，其中 $U_k$ 和 $V_k$ 分别是由 $U$ 和 $V$ 的前 $k$ 列组成的矩阵，而 $\\Sigma_k$ 是前 $k$ 个奇异值的对角矩阵。\n\n让我们使用提供的掩码矩阵 $M \\in \\{0,1\\}^{m \\times n}$ 来重新表述更新规则，其中如果 $(i,j) \\in \\Omega$，则 $M_{ij}=1$，否则 $M_{ij}=0$。采样算子可以用逐元素（哈达玛）积 $\\circ$ 来表示。\n- $P_{\\Omega}(Z) = M \\circ Z$\n- $P_{\\Omega^{c}}(Z) = (J - M) \\circ Z$，其中 $J$ 是全1矩阵。\n\n观测到的数据矩阵是 $Y_{\\text{obs}} = P_{\\Omega}(X_{\\text{true}} + N) = M \\circ (X_{\\text{true}} + N)$。\n迭代更新过程如下：\n1.  **初始化：** 估计值被初始化为零矩阵：$X^{(0)} = 0 \\in \\mathbb{R}^{m \\times n}$。\n2.  **迭代** $t = 0, 1, ..., t_{\\max}-1$：\n    a. **存储前一个估计值：** $X_{\\text{prev}} = X^{(t)}$。\n    b. **填充矩阵：** 通过将已知的观测条目与当前对未知条目的估计相结合，形成一个临时矩阵 $Y^{(t)}$：\n       $$Y^{(t)} = Y_{\\text{obs}} + (J-M) \\circ X^{(t)}$$\n    c. **投影到低秩：** 通过计算 $Y^{(t)}$ 的秩-k 截断SVD来获得新的估计值 $X^{(t+1)}$：\n       $$X^{(t+1)} = \\mathcal{S}_k(Y^{(t)})$$\n    d. **检查收敛性：** 如果连续估计值之间的相对变化低于容差 $\\varepsilon$，则过程停止：\n       $$\\frac{\\|X^{(t+1)} - X_{\\text{prev}}\\|_F}{\\max(1, \\|X_{\\text{prev}}\\|_F)} \\le \\varepsilon$$\n3.  **输出：** 返回最终计算出的矩阵 $X_{\\text{est}} = X^{(t+1)}$。\n\n每个测试案例的最终评估是估计矩阵 $X_{\\text{est}}$ 和真实值矩阵 $X_{\\text{true}}$ 之间的相对弗罗贝尼乌斯误差：\n$$ \\text{Error} = \\frac{\\|X_{\\text{est}} - X_{\\text{true}}\\|_F}{\\|X_{\\text{true}}\\|_F} $$\n\n- **案例 A** 代表了一个标准应用，其中有相当一部分条目缺失，但底层矩阵的秩恰好为2。预计该算法将收敛到一个低误差的解。\n- **案例 B** 是一个平凡案例，其中所有条目都被观测到（$M=J$）。算法应在第一次迭代中完美恢复 $X_{\\text{true}}$。$Y^{(0)} = M \\circ X_{\\text{true}} + (J-M) \\circ X^{(0)} = X_{\\text{true}} + 0 = X_{\\text{true}}$。由于 $X_{\\text{true}}$ 的秩为2，因此 $\\mathcal{S}_2(X_{\\text{true}}) = X_{\\text{true}}$。所以，$X^{(1)} = X_{\\text{true}}$，误差应接近机器精度。\n- **案例 C** 是一个边缘案例，其中一整行都未被观测到。矩阵补全理论中的一个已知结论是，在这种情况下恢复是不可能的，因为没有信息来约束该行中的值。算法会收敛，但从真实值的角度来看，缺失行的误差将是任意的，从而导致较高的整体重构误差。\n- **案例 D** 在观测值中包含了加性噪声。算法将尝试找到一个最能拟合含噪声数据的秩-2矩阵。重构将不会是精确的，因为算法会通过将数据投影到低秩子空间上来去噪。最终误差预计将非零但很小，反映了算法抑制部分噪声的能力。\n\n实现将遵循为每个提供的测试案例所设定的此逻辑。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and evaluate the test cases for matrix completion.\n    \"\"\"\n\n    def run_completion_algorithm(X_true, mask, noise, k, t_max, epsilon):\n        \"\"\"\n        Implements the iterative SVD-based matrix completion algorithm.\n        \n        Args:\n            X_true (np.ndarray): The ground truth matrix.\n            mask (np.ndarray): The observation mask (1s for observed, 0s for missing).\n            noise (np.ndarray): The additive noise matrix.\n            k (int): The target rank.\n            t_max (int): The maximum number of iterations.\n            epsilon (float): The convergence tolerance.\n\n        Returns:\n            np.ndarray: The estimated matrix X_est.\n        \"\"\"\n        m, n = X_true.shape\n        X_est = np.zeros((m, n))\n        Y_obs = mask * (X_true + noise)\n        \n        for _ in range(t_max):\n            X_prev = X_est.copy()\n            \n            # 1. Form the filled matrix\n            Y_filled = Y_obs + (1 - mask) * X_est\n            \n            # 2. Compute the rank-k truncated SVD approximation\n            try:\n                U, s, Vt = np.linalg.svd(Y_filled, full_matrices=False)\n                # Reconstruct from top k singular values/vectors\n                X_est = U[:, :k] @ np.diag(s[:k]) @ Vt[:k, :]\n            except np.linalg.LinAlgError:\n                # In case of non-convergence of SVD, though unlikely for these test cases.\n                break\n\n            # 3. Check for convergence\n            norm_prev = np.linalg.norm(X_prev, 'fro')\n            diff_norm = np.linalg.norm(X_est - X_prev, 'fro')\n            \n            if diff_norm / max(1.0, norm_prev)  epsilon:\n                break\n                \n        return X_est\n\n    # Define Test Cases\n    \n    # Case A\n    A_A = np.array([\n        [1, 0], [0, 1], [1, 1],\n        [2, -1], [-1, 2], [0.5, 1.5]\n    ])\n    B_A = np.array([\n        [2, 1], [1, -1], [0, 2],\n        [-1, 0.5], [1.5, -0.5]\n    ])\n    X_true_A = A_A @ B_A.T\n    M_A = np.array([\n        [1, 1, 0, 1, 0], [0, 1, 1, 0, 1], [1, 0, 1, 1, 0],\n        [1, 1, 0, 0, 1], [0, 1, 1, 1, 0], [1, 0, 0, 1, 1]\n    ])\n    N_A = np.zeros_like(X_true_A)\n    params_A = {'X_true': X_true_A, 'mask': M_A, 'noise': N_A, 'k': 2, 't_max': 1000, 'epsilon': 1e-10}\n\n    # Case B\n    A_B = np.array([[2, 0], [0, 1], [1, -1], [3, 2]])\n    B_B = np.array([[1, 2], [0.5, -1], [2, 0], [1, 1]])\n    X_true_B = A_B @ B_B.T\n    M_B = np.ones((4, 4))\n    N_B = np.zeros_like(X_true_B)\n    params_B = {'X_true': X_true_B, 'mask': M_B, 'noise': N_B, 'k': 2, 't_max': 1000, 'epsilon': 1e-12}\n\n    # Case C\n    A_C = np.array([[1, 0], [0, 1], [1, 1], [2, 1], [-1, 2]])\n    B_C = np.array([[1, 1], [2, -1], [-1, 0.5], [0, 2], [1, -2]])\n    X_true_C = A_C @ B_C.T\n    M_C = np.array([\n        [1, 0, 1, 1, 0], [1, 1, 0, 0, 1], [0, 0, 0, 0, 0],\n        [1, 1, 1, 0, 1], [0, 1, 0, 1, 1]\n    ])\n    N_C = np.zeros_like(X_true_C)\n    params_C = {'X_true': X_true_C, 'mask': M_C, 'noise': N_C, 'k': 2, 't_max': 2000, 'epsilon': 1e-12}\n\n    # Case D\n    A_D = np.array([[1, 0], [0, 1], [1, -1], [2, 1], [-1, 2]])\n    B_D = np.array([[1, 2], [2, 1], [-1, 1], [0.5, -0.5]])\n    X_true_D = A_D @ B_D.T\n    M_D = np.array([\n        [1, 1, 0, 1], [1, 0, 1, 1], [1, 1, 0, 0],\n        [0, 1, 1, 1], [1, 0, 1, 0]\n    ])\n    N_D = np.array([\n        [0.01, -0.02, 0, 0], [-0.03, 0, 0.02, -0.01],\n        [0.02, 0.01, 0, 0], [0, -0.02, 0.03, -0.01],\n        [0.01, 0, -0.02, 0]\n    ])\n    params_D = {'X_true': X_true_D, 'mask': M_D, 'noise': N_D, 'k': 2, 't_max': 1500, 'epsilon': 1e-10}\n\n    test_cases = [params_A, params_B, params_C, params_D]\n    results = []\n\n    for case_params in test_cases:\n        X_est = run_completion_algorithm(**case_params)\n        X_true = case_params['X_true']\n        \n        # Calculate relative Frobenius error\n        error = np.linalg.norm(X_est - X_true, 'fro') / np.linalg.norm(X_true, 'fro')\n        \n        # Round to six decimal places\n        rounded_error = round(error, 6)\n        results.append(rounded_error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2371448"}]}