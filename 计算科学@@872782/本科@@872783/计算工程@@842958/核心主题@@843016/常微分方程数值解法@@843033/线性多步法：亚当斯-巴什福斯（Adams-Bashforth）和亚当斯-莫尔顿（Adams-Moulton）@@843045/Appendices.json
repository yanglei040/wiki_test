{"hands_on_practices": [{"introduction": "根据Dahlquist等价定理，一个线性多步法收敛的充要条件是它既要相容又要零稳定。这个练习提供了一个绝佳的实践机会，通过分析一个虽然相容但违反了零稳定性根本条件的（假设的）方法，来亲手验证该定理的重要性。通过实施这个方法并观察其发散行为[@problem_id:2410027]，你将深刻理解为何根条件对于保证数值解的可靠性至关重要。", "problem": "设 $y(t)$ 满足初值问题 $y'(t) = -y(t)$ 及 $y(0) = 1$。考虑由下式定义的两步线性多步法（LMM）：\n$$ y_{n+2} - 2 y_{n+1} + y_n = 0, $$\n该方法应用于均匀网格 $t_n = n h$ 上，步长 $h > 0$。该方法通过 $y_0 = 1$ 以及根据每个情况指定的 $y_1 = e^{-h}$ 或 $y_1 = 1$ 进行初始化。\n\n任务：\n1. 从基本定义出发，判断该方法是否是相容的，以及是否满足零点稳定性的根条件。你的判断必须仅基于相容性和线性多步法根条件的定义。\n2. 完全按照上述说明实现该方法，计算每个测试用例在 $t = T$ 时的数值近似解。对于给定的 $T$ 和 $h$，取 $N = T/h$（假设 $N$ 为整数），并使用指定的 $y_1$ 初始化来计算该方法产生的数值 $y_N$。计算绝对误差 $|y_N - e^{-T}|$。\n3. 使用以下测试套件，每个测试用例由三元组 $(T,h,\\text{start})$ 指定，其中 $\\text{start}$ 为 $\\text{exact}$ 表示 $y_1 = e^{-h}$，或为 $\\text{constant}$ 表示 $y_1 = 1$：\n- $(1, 0.1, \\text{exact})$\n- $(1, 0.05, \\text{exact})$\n- $(1, 0.025, \\text{exact})$\n- $(0, 0.1, \\text{exact})$\n- $(10, 0.1, \\text{exact})$\n- $(1, 0.1, \\text{constant})$\n\n你的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[r_1,r_2,\\dots]$），列表中的每个 $r_i$ 是对应测试用例（按所列顺序）的绝对误差 $|y_N - e^{-T}|$。本问题不涉及物理单位。如果出现任何角度，必须以弧度为单位，但此处并未使用角度。", "solution": "所述问题在数学上是良定义的且内部一致。它提出了一个在常微分方程数值分析中标准且具有启发性的问题。我们将着手进行分析和求解。\n\n该问题要求分析由以下递推关系给出的两步线性多步法（LMM）：\n$$ y_{n+2} - 2 y_{n+1} + y_n = 0 $$\n此方法将应用于初值问题（IVP）$y'(t) = -y(t)$，其中 $y(0) = 1$。\n\n一个通用的 $k$ 步 LMM 表示为：\n$$ \\sum_{j=0}^{k} \\alpha_j y_{n+j} = h \\sum_{j=0}^{k} \\beta_j f(t_{n+j}, y_{n+j}) $$\n对于给定的方法，步数为 $k=2$。通过比较两种形式，我们确定其系数：\n- $\\alpha_2 = 1$, $\\alpha_1 = -2$, $\\alpha_0 = 1$。\n- $\\beta_2 = 0$, $\\beta_1 = 0$, $\\beta_0 = 0$。\n\n一个关键的观察是，所有的 $\\beta_j$ 系数都为零。这意味着该数值方法没有利用来自微分方程 $y' = f(t,y)$ 的信息，在本例中即 $f(t,y) = -y$。该方法的演化仅取决于其自身的系数和初始值，而不取决于它本应模拟的动力学过程。这是一个严重的缺陷，接下来的形式化分析将阐明这一点。\n\n### 第1部分：相容性和零点稳定性\n\n**相容性分析**\n如果一个 LMM 的精度阶 $p$ 至少为 $1$（$p \\ge 1$），则称该方法是相容的。这等价于其系数满足以下两个代数条件：\n$1$. $\\sum_{j=0}^{k} \\alpha_j = 0$\n$2$. $\\sum_{j=0}^{k} j \\alpha_j = \\sum_{j=0}^{k} \\beta_j$\n\n我们来验证给定方法是否满足这些条件：\n$1$. $\\sum_{j=0}^{2} \\alpha_j = \\alpha_0 + \\alpha_1 + \\alpha_2 = 1 + (-2) + 1 = 0$。此条件满足。\n$2$. 对于左边：$\\sum_{j=0}^{2} j \\alpha_j = (0 \\cdot \\alpha_0) + (1 \\cdot \\alpha_1) + (2 \\cdot \\alpha_2) = (0 \\cdot 1) + (1 \\cdot (-2)) + (2 \\cdot 1) = -2 + 2 = 0$。\n对于右边：$\\sum_{j=0}^{2} \\beta_j = \\beta_0 + \\beta_1 + \\beta_2 = 0 + 0 + 0 = 0$。\n左边等于右边。此条件也满足。\n\n由于两个条件都成立，该方法是**相容的**。为了确定其阶数，我们考察局部截断误差，它由算子 $L[y(t); h] = \\sum_{j=0}^k \\alpha_j y(t+jh) - h \\sum_{j=0}^k \\beta_j y'(t+jh)$ 定义。对于本方法：\n$$ L[y(t); h] = y(t+2h) - 2y(t+h) + y(t) $$\n使用 $y(t+h)$ 和 $y(t+2h)$ 在 $t$ 点的泰勒级数展开：\n$y(t+h) = y(t) + h y'(t) + \\frac{h^2}{2} y''(t) + O(h^3)$\n$y(t+2h) = y(t) + 2h y'(t) + \\frac{(2h)^2}{2} y''(t) + O(h^3) = y(t) + 2h y'(t) + 2h^2 y''(t) + O(h^3)$\n将这些代入 $L[y(t); h]$ 的表达式中：\n$$ L[y(t); h] = [y(t) + 2h y'(t) + 2h^2 y''(t)] - 2[y(t) + h y'(t) + \\frac{h^2}{2} y''(t)] + y(t) + O(h^3) $$\n$$ L[y(t); h] = (1-2+1)y(t) + (2-2)h y'(t) + (2-1)h^2 y''(t) + O(h^3) = h^2 y''(t) + O(h^3) $$\n方法的阶 $p$ 由 $L[y(t); h] = O(h^{p+1})$ 定义。这里，$p+1=2$，所以阶数是 $p=1$。相容性得到确认。\n\n**零点稳定性分析**\nLMM 的零点稳定性由其第一特征多项式 $\\rho(z)$ 的根决定：\n$$ \\rho(z) = \\sum_{j=0}^{k} \\alpha_j z^j $$\n对于给定的方法，该多项式为：\n$$ \\rho(z) = \\alpha_0 + \\alpha_1 z + \\alpha_2 z^2 = 1 - 2z + z^2 = (z-1)^2 $$\n通过求解 $(z-1)^2 = 0$ 可得 $\\rho(z)=0$ 的根，得到一个在 $z_1 = z_2 = 1$ 处的二重根。\n\n零点稳定性的**根条件**要求：\n$1$. $\\rho(z)$ 的所有根都必须位于复平面的单位圆内或单位圆上（即 $|z| \\le 1$）。\n$2$. 任何位于单位圆上的根（即 $|z|=1$）都必须是单根（重数为 $1$）。\n\n在我们的例子中，根 $z=1$ 的模为 $|1|=1$，因此它位于单位圆上。然而，它的重数是 $2$，大于 $1$。因此，根条件的第二部分被违反。该方法是**非零点稳定的**。\n\n根据 Dahlquist 等价定理，一个 LMM 是收敛的当且仅当它既是相容的又是零点稳定的。由于该方法不是零点稳定的，所以它是**不收敛的**。这意味着当步长 $h$ 趋近于零时，数值解不会收敛到该初值问题的真解。数值测试将展示这种发散现象。\n\n### 第2部分：实现与计算\n\n该数值格式是一个常系数线性齐次递推关系：\n$$ y_{n+2} = 2y_{n+1} - y_n $$\n这个递推关系的特征方程是 $r^2 - 2r + 1 = 0$，它与多项式 $\\rho(r)$ 相同。它有一个二重根 $r=1$。这种递推关系的通解形式为：\n$$ y_n = c_1 (1)^n + c_2 n (1)^n = c_1 + c_2 n $$\n常数 $c_1$ 和 $c_2$ 由序列的初始两个值 $y_0$ 和 $y_1$ 决定。\n- 当 $n=0$ 时：$y_0 = c_1 + c_2 \\cdot 0 \\implies c_1 = y_0$。\n- 当 $n=1$ 时：$y_1 = c_1 + c_2 \\cdot 1 \\implies c_2 = y_1 - c_1 = y_1 - y_0$。\n\n因此，在第 $n$ 步的数值解的显式公式是：\n$$ y_n = y_0 + n(y_1 - y_0) $$\n这个表达式表明，数值解随步数索引 $n$ 线性增长。这是 $z=1$ 处二重根的直接后果，也是该方法不稳定的机制。\n\n为了计算在最终时间 $T=Nh$ 时的数值近似解 $y_N$，我们直接使用此公式并令 $n=N$。对于每个测试用例 $(T, h, \\text{start})$：\n$1$. 计算步数 $N = T/h$。\n$2$. 设置初始值 $y_0 = 1$。\n$3$. 根据 'start' 条件确定第二个值 $y_1$：\n    - 如果是 'exact'，则 $y_1 = e^{-h}$。\n    - 如果是 'constant'，则 $y_1 = 1$。\n$4$. 计算在 $t=T$ 时的数值解：$y_N = y_0 + N(y_1 - y_0)$。\n$5$. 计算在 $t=T$ 时的真解：$y(T) = e^{-T}$。\n$6$. 绝对误差为 $|y_N - e^{-T}|$。\n\n这个递推关系的解析解在计算上是精确的，并且比基于循环的实现更高效，避免了任何浮点误差的累积。最终答案中的程序将实现这一逻辑。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the given problem by analyzing a linear multistep method and calculating\n    the absolute error for a suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (T, h, start_type)\n        (1.0, 0.1, \"exact\"),\n        (1.0, 0.05, \"exact\"),\n        (1.0, 0.025, \"exact\"),\n        (0.0, 0.1, \"exact\"),\n        (10.0, 0.1, \"exact\"),\n        (1.0, 0.1, \"constant\"),\n    ]\n\n    results = []\n    for T, h, start_type in test_cases:\n        # The problem statement assumes N = T/h is an integer.\n        # We handle T = 0 as a special case for N.\n        if T == 0.0:\n            N = 0\n        else:\n            # Use rounding to handle potential floating point inaccuracies in T/h\n            N = int(round(T / h))\n\n        # Initial condition from the IVP: y(0) = 1\n        y0 = 1.0\n\n        # Determine y_1 based on the start type specified in the test case.\n        if start_type == \"exact\":\n            y1 = np.exp(-h)\n        elif start_type == \"constant\":\n            y1 = 1.0\n        else:\n            # This path should not be reached with the given test cases.\n            raise ValueError(f\"Unknown start_type: {start_type}\")\n\n        # The linear multistep method y_{n+2} - 2*y_{n+1} + y_n = 0 is a\n        # linear recurrence relation. Its characteristic equation r^2 - 2r + 1 = 0\n        # has a double root r=1. The general solution is y_n = c1 + c2*n.\n        # Using y_0 and y_1 to find the constants c1 and c2, we get the\n        # specific solution: y_n = y_0 + n * (y_1 - y_0).\n        # We can use this analytical solution of the recurrence to compute y_N directly.\n        if N == 0:\n            y_N = y0\n        else:\n            y_N = y0 + N * (y1 - y0)\n\n        # The exact solution to the IVP y'(t) = -y(t) with y(0) = 1 is y(t) = exp(-t).\n        y_exact_T = np.exp(-T)\n\n        # Compute the absolute error |y_N - y(T)|.\n        error = np.abs(y_N - y_exact_T)\n        results.append(error)\n\n    # Print the results in the specified format: [r1,r2,r3,...]\n    # The format string ensures a consistent number of decimal places for clarity.\n    print(f\"[{','.join(f'{r:.10f}' for r in results)}]\")\n\nsolve()\n```", "id": "2410027"}, {"introduction": "预测-校正（Predictor-Corrector）格式是利用显式方法（预测子）的简便性来求解隐式方法（校正子）的强大技术。本练习将指导你构建一个经典的预测-评估-校正-评估（PECE）方案，它耦合了二阶Adams-Bashforth预测子和梯形法则（即二阶Adams-Moulton）校正子。通过推导其特征多项式并分析其绝对稳定性区域[@problem_id:2371160]，你将掌握评估组合数值方案稳定性的核心技能，这对于在实际应用中选择合适的积分步长至关重要。", "problem": "考虑标量初值问题 $y'(t)=\\lambda y(t)$，其中 $y(0)=1$，$\\lambda \\in \\mathbb{C}$ 的物理单位为 $\\mathrm{s}^{-1}$，$t$ 的单位为秒。通过将二阶显式 Adams–Bashforth 预测子与梯形法则校正子（也称为二阶 Adams–Moulton 方法）相结合，构建一个两步预测-评估-校正-评估 (PECE) 格式，每步精确执行一次校正。将此 PECE 格式应用于线性测试方程 $y'(t)=\\lambda y(t)$，以推导出将 $y_n \\approx y(t_n)$ 推进到 $y_{n+1} \\approx y(t_{n+1})$ 的齐次线性两步递推关系，其中步长 $h>0$ 秒为定值，且 $t_{n+1}=t_n+h$。令 $z = h\\lambda$ 表示无量纲步长参数。\n\n对此测试方程，该两步 PECE 方法的绝对稳定性定义如下：对于给定的 $z \\in \\mathbb{C}$，构建所推导的线性两步递推的特征多项式，并令 $\\xi_1(z)$ 和 $\\xi_2(z)$ 为其两个根。当且仅当两个根都满足 $\\lvert \\xi_1(z)\\rvert \\le 1$ 和 $\\lvert \\xi_2(z)\\rvert \\le 1$ 时，该方法在 $z$ 处是绝对稳定的。在根的模恰好等于 $1$ 的情况下，假定其为单根。\n\n你的程序必须从第一性原理出发，进行符号推导，以计算任意 $z \\in \\mathbb{C}$ 的特征多项式，然后用它来评估给定 $(\\lambda,h)$ 的稳定性。此外，沿着负实轴 $z\\in \\mathbb{R}_{\\le 0}$（即 $\\lambda \\in \\mathbb{R}_{0}$ 且 $h \\ge 0$），对于给定的负实数 $\\lambda$，确定使该方法保持绝对稳定的最大步长 $h_{\\max}$（单位为秒）。\n\n使用以下参数值测试套件来检验您的实现：\n- 稳定性查询（对每个查询返回一个布尔值）：\n  1. $(\\lambda,h)=(-1,\\,0.5)$，\n  2. $(\\lambda,h)=(-1,\\,1.5)$，\n  3. $(\\lambda,h)=(-40,\\,0.05)$，\n  4. $(\\lambda,h)=(-1+10\\,\\mathrm{i},\\,0.05)$，\n  5. $(\\lambda,h)=(10\\,\\mathrm{i},\\,0.1)$，\n  6. $(\\lambda,h)=(-3,\\,0)$，\n其中 $\\mathrm{i}$ 表示虚数单位，所有 $\\lambda$ 的单位均为 $\\mathrm{s}^{-1}$，所有 $h$ 的单位均为 $\\mathrm{s}$。\n\n- 最大稳定步长查询（返回一个浮点数，单位为秒）：\n  7. 对于 $\\lambda=-1$（单位为 $\\mathrm{s}^{-1}$），计算 $h_{\\max}$（单位为 $\\mathrm{s}$），其定义为使方法对于 $z=h\\lambda \\in \\mathbb{R}_{\\le 0}$ 保持绝对稳定的 $h\\ge 0$ 的上确界。将 $h_{\\max}$ 以秒为单位表示为四舍五入到 $6$ 位小数的十进制数。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为以上测试用例的结果，顺序完全一致。其中，第 $1$ 到第 $6$ 项为布尔值，第 $7$ 项为一个浮点数（四舍五入到 $6$ 位小数）。例如，输出格式必须为 $[b_1,b_2,b_3,b_4,b_5,b_6,h_{\\max}]$，其中每个 $b_j$ 是 $\\mathrm{True}$ 或 $\\mathrm{False}$，$h_{\\max}$ 是一个小数点后有 $6$ 位数字的十进制数。所有时间单位都应视为 $\\mathrm{s}$，所有速率单位都应视为 $\\mathrm{s}^{-1}$。", "solution": "问题陈述已通过验证，可用于分析。该问题具有科学依据，提法明确且客观。我们开始进行求解。\n\n任务是分析应用于线性测试方程 $y'(t) = \\lambda y(t)$（其中 $\\lambda \\in \\mathbb{C}$）的两步预测-评估-校正-评估 (PECE) 数值格式的绝对稳定性。该格式使用二阶 Adams-Bashforth (AB2) 方法作为预测子，梯形法则（即单步二阶 Adams-Moulton 方法，AM2）作为校正子，每步进行一次校正。\n\n设 $y_n$ 为在时间 $t_n = n h$ 处对 $y(t_n)$ 的数值近似，其中步长 $h > 0$ 为定值。设 $f_n = f(t_n, y_n) = \\lambda y_n$。为方便起见，使用无量纲参数 $z = h\\lambda$。\n\nPECE 格式通过以下步骤将解从 $(y_{n-1}, y_n)$ 推进到 $y_{n+1}$：\n\n1.  **预测 (P)**：使用显式两步 AB2 公式计算预测值 $y_{n+1}^{(P)}$：\n    $$y_{n+1}^{(P)} = y_n + \\frac{h}{2}(3f_n - f_{n-1})$$\n    对于测试方程，这变为：\n    $$y_{n+1}^{(P)} = y_n + \\frac{h\\lambda}{2}(3y_n - y_{n-1}) = \\left(1 + \\frac{3z}{2}\\right)y_n - \\frac{z}{2}y_{n-1}$$\n\n2.  **评估 (E)**：使用预测值 $y_{n+1}^{(P)}$ 评估函数 $f$：\n    $$f_{n+1}^{(P)} = \\lambda y_{n+1}^{(P)}$$\n\n3.  **校正 (C)**：使用隐式梯形法则计算该步的最终值 $y_{n+1}$，通过使用 $f_{n+1}^{(P)}$ 将其显式化：\n    $$y_{n+1} = y_n + \\frac{h}{2}(f_{n+1}^{(P)} + f_n)$$\n    对于测试方程，这变为：\n    $$y_{n+1} = y_n + \\frac{h\\lambda}{2}(y_{n+1}^{(P)} + y_n) = \\left(1 + \\frac{z}{2}\\right)y_n + \\frac{z}{2}y_{n+1}^{(P)}$$\n\n4.  **评估 (E)**：执行最终的评估 $f_{n+1} = \\lambda y_{n+1}$，该值将在下一个积分步中使用（即用于计算 $y_{n+2}$）。\n\n为推导递推关系，我们将预测步骤中 $y_{n+1}^{(P)}$ 的表达式代入校正方程：\n$$y_{n+1} = \\left(1 + \\frac{z}{2}\\right)y_n + \\frac{z}{2}\\left[\\left(1 + \\frac{3z}{2}\\right)y_n - \\frac{z}{2}y_{n-1}\\right]$$\n$$y_{n+1} = \\left(1 + \\frac{z}{2} + \\frac{z}{2} + \\frac{3z^2}{4}\\right)y_n - \\frac{z^2}{4}y_{n-1}$$\n$$y_{n+1} = \\left(1 + z + \\frac{3z^2}{4}\\right)y_n - \\frac{z^2}{4}y_{n-1}$$\n\n这得到了齐次线性两步递推关系：\n$$y_{n+1} - \\left(1 + z + \\frac{3z^2}{4}\\right)y_n + \\frac{z^2}{4}y_{n-1} = 0$$\n\n为分析稳定性，我们寻找 $y_n = \\xi^n$ 形式的解。将其代入递推关系并除以 $\\xi^{n-1}$（对于 $\\xi \\neq 0$），得到特征多项式 $P(\\xi; z)$：\n$$P(\\xi; z) = \\xi^2 - \\left(1 + z + \\frac{3z^2}{4}\\right)\\xi + \\frac{z^2}{4} = 0$$\n该方法在给定 $z$ 处的稳定性由这个二次方程的根 $\\xi_1(z)$ 和 $\\xi_2(z)$ 的模决定。根据问题定义，如果 $|\\xi_1(z)| \\le 1$ 且 $|\\xi_2(z)| \\le 1$，则该方法是绝对稳定的。问题指明，如果一个根的模为 $1$，则应视为单根，因此稳定性区域边界上的点也包括在内。\n\n**稳定性查询（情况 1-6）：**\n我们通过计算 $z=h\\lambda$ 并求特征多项式的根来评估每对给定 $(\\lambda, h)$ 的稳定性。\n\n1.  $(\\lambda, h) = (-1, 0.5) \\implies z = -0.5$。多项式为 $\\xi^2 - 0.6875\\xi + 0.0625 = 0$。根为 $\\xi_1 \\approx 0.5797$ 和 $\\xi_2 \\approx 0.1078$。两个根的模都小于 $1$。稳定。\n2.  $(\\lambda, h) = (-1, 1.5) \\implies z = -1.5$。多项式为 $\\xi^2 - 1.1875\\xi + 0.5625 = 0$。根是共轭复数 $\\xi_{1,2} \\approx 0.59375 \\pm 0.45821i$。两个根的模为 $|\\xi| = \\sqrt{0.5625} = 0.75  1$。稳定。\n3.  $(\\lambda, h) = (-40, 0.05) \\implies z = -2.0$。多项式为 $\\xi^2 - 2\\xi + 1 = (\\xi-1)^2 = 0$。根为 $\\xi_1 = \\xi_2 = 1$。模恰好为 $1$。根据问题的稳定性定义，这被认为是稳定的。\n4.  $(\\lambda, h) = (-1+10i, 0.05) \\implies z = -0.05 + 0.5i$。多项式具有复系数。数值计算得出根为 $\\xi_1 \\approx 0.6792 + 0.5255i$ 和 $\\xi_2 \\approx 0.0851 - 0.0630i$。模为 $|\\xi_1| \\approx 0.8588$ 和 $|\\xi_2| \\approx 0.1059$。两者都小于 $1$。稳定。\n5.  $(\\lambda, h) = (10i, 0.1) \\implies z = i$。多项式为 $\\xi^2 - (0.25+i)\\xi - 0.25 = 0$。数值计算得出根为 $\\xi_1 \\approx 0.125 + 1.1408i$ 和 $\\xi_2 \\approx 0.125 - 0.1408i$。模为 $|\\xi_1| \\approx 1.1477$ 和 $|\\xi_2| \\approx 0.1883$。由于 $|\\xi_1| > 1$，该方法不稳定。\n6.  $(\\lambda, h) = (-3, 0) \\implies z = 0$。多项式为 $\\xi^2 - \\xi = 0$。根为 $\\xi_1 = 1$ 和 $\\xi_2 = 0$。两个根的模都小于或等于 $1$。稳定。\n\n**最大稳定步长（情况 7）：**\n我们需要找到负实轴上的稳定区间，即对于 $z \\in \\mathbb{R}_{\\le 0}$。稳定性边界是通过对实数 $z$ 的特征多项式应用根条件 $|\\xi_i| \\le 1$ 来确定的。对于具有实系数的二阶多项式 $\\xi^2 - A\\xi + B = 0$，其根位于单位圆盘内的条件（Jury 稳定性判据）是：\n(i) $P(1) = 1 - A + B \\ge 0$。\n(ii) $P(-1) = 1 + A + B \\ge 0$。\n(iii) $|B| \\le 1$。\n\n对于我们的多项式，$A(z) = 1+z+\\frac{3z^2}{4}$ 且 $B(z) = \\frac{z^2}{4}$。\n(i) $1 - (1+z+\\frac{3z^2}{4}) + \\frac{z^2}{4} = -z - \\frac{z^2}{2} = -z(1+\\frac{z}{2}) \\ge 0$。由于 $z \\le 0$，所以 $-z \\ge 0$。因此，我们需要 $1+\\frac{z}{2} \\ge 0 \\implies z \\ge -2$。\n(ii) $1 + (1+z+\\frac{3z^2}{4}) + \\frac{z^2}{4} = 2 + z + z^2$。这个二次多项式的主导系数为正，且根为复数，因此对于实数 $z$ 它总是正的。此条件总是满足。\n(iii) $|\\frac{z^2}{4}| \\le 1 \\implies z^2 \\le 4 \\implies |z| \\le 2$。对于 $z \\le 0$，这等价于 $z \\ge -2$。\n\n综合这些条件，该方法在 $z \\in [-2, 0]$ 上是稳定的。\n给定 $\\lambda = -1 \\ \\mathrm{s}^{-1}$，我们有 $z = -h$。稳定性条件变为 $-2 \\le -h \\le 0$，可简化为 $0 \\le h \\le 2$。稳定步长的集合是 $[0, 2]$。\n最大稳定步长 $h_{\\max}$ 是该集合的上确界，即 $h_{\\max} = 2 \\ \\mathrm{s}$。要求的格式是四舍五入到 $6$ 位小数的浮点数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by analyzing the stability of a PECE scheme\n    for a given set of parameters.\n    \"\"\"\n\n    # Test cases for stability queries (lambda, h)\n    # lambda is in 1/s, h is in s.\n    stability_test_cases = [\n        (-1.0, 0.5),           # Case 1\n        (-1.0, 1.5),           # Case 2\n        (-40.0, 0.05),         # Case 3\n        (-1.0 + 10.0j, 0.05),  # Case 4\n        (10.0j, 0.1),          # Case 5\n        (-3.0, 0.0),           # Case 6\n    ]\n\n    results = []\n\n    def is_stable(z):\n        \"\"\"\n        Checks the stability of the method for a given non-dimensional step z.\n        The characteristic polynomial is xi^2 - A*xi + B = 0.\n        \"\"\"\n        z = complex(z)  # Ensure z is treated as a complex number\n        \n        # Coefficients of the characteristic polynomial\n        A = 1 + z + 0.75 * z**2\n        B = 0.25 * z**2\n        \n        # Find the roots of the polynomial: xi^2 - A*xi + B = 0\n        coeffs = [1.0, -A, B]\n        roots = np.roots(coeffs)\n        \n        # The method is stable if all roots have magnitude = 1.\n        # The problem states to assume roots with magnitude=1 are simple.\n        # A small tolerance is added to handle floating-point inaccuracies.\n        return np.all(np.abs(roots) = 1.0 + 1e-9)\n\n    # Process stability queries\n    for lambda_val, h_val in stability_test_cases:\n        z = lambda_val * h_val\n        results.append(is_stable(z))\n\n    # Process maximum stable step size query (Case 7)\n    # For lambda = -1, the stability interval for z=h*lambda=-h is [-2, 0].\n    # This implies -2 = -h = 0, which means 0 = h = 2.\n    # The supremum h_max is therefore 2.0.\n    h_max = 2.0\n    results.append(f\"{h_max:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2371160"}, {"introduction": "在数值计算中，一个算法的好坏不仅取决于其精度，还取决于其计算成本。这个实践练习将引导你超越简单的精度分析，进入算法优化的领域。通过比较不同阶数的Adams-Bashforth预测子与一个固定的三阶Adams-Moulton校正子配对时的成本效益[@problem_id:2410035]，你将学会如何评估数值方法的“性价比”。这项练习突显了一个重要的实际问题：更高阶的方法不一定总是更优选择，最优设计需要在精度和效率之间做出权衡。", "problem": "实现一个程序，对于一个固定的三阶 Adams–Moulton 校正子，比较三种预测子选择的成本与精度权衡。考虑由线性常微分方程 $y'(t)=\\lambda\\,y(t)$ 定义的标量初值问题，初始条件为 $y(0)=1$，区间为 $t\\in[0,T]$。其精确解为 $y(t)=\\exp(\\lambda t)$。对于下面的每个实验，使用一个均匀步长 $h$，使得 $T/h$ 为整数，并计算 $N=T/h$ 步。你必须比较三种预测-校正方案，它们都使用单次校正步骤和三阶 Adams–Moulton (AM) 校正子，但预测子不同：分别是两步 Adams–Bashforth (AB2)、三步 Adams–Bashforth (AB3) 和四步 Adams–Bashforth (AB4)。此处，Adams–Bashforth (AB) 和 Adams–Moulton (AM) 表示标准线性多步法。校正子是三阶 Adams–Moulton 方法。预测子分别是二阶、三阶或四阶的 Adams–Bashforth 方法。\n\n对每种方案，采用以下成本模型。每次计算右端函数 $f(t,y)=\\lambda y$ 的成本计为 $1$。为启动多步法方案，使用 $y_k = \\exp(\\lambda t_k)$ 在所需的过去网格点 $t_k=k\\,h$ 上精确初始化所需的最小历史记录，并计算相应的 $f_k=f(t_k,y_k)$；将这些函数求值计入成本。此后的每一步，执行一次预测和一次校正，使用单次 Adams–Moulton 校正，其中必须在预测值处和校正值处各计算一次 $f$。将这两次求值都计入成本。不要对校正子执行任何进一步的迭代。令最终时刻的绝对全局误差为 $E=\\lvert y_N - \\exp(\\lambda T)\\rvert$，令函数求值总成本为 $C$。\n\n将成本归一化误差定义为 $E/C$。对于下面的每个测试用例，确定使用 AB3 预测子和 AM3 校正子是否在 AB2、AB3 和 AB4 三种选择中产生最小的成本归一化误差。如果一个方法获得了最小的 $E/C$ 值，则认为它在此意义上是最优的；如果出现平局，则选择预测子阶数最小的方法。\n\n测试套件。运行以下五个参数集，每个参数集指定为 $(\\lambda, T, h)$：\n- 情况 1：$(\\lambda, T, h)=(-1.0,\\,1.0,\\,0.05)$。\n- 情况 2：$(\\lambda, T, h)=(-10.0,\\,1.0,\\,0.02)$。\n- 情况 3：$(\\lambda, T, h)=(-1.0,\\,1.0,\\,0.01)$。\n- 情况 4：$(\\lambda, T, h)=(1.0,\\,1.0,\\,0.01)$。\n- 情况 5：$(\\lambda, T, h)=(-1.0,\\,1.0,\\,0.2)$。\n\n你的程序必须为每种情况生成一个布尔值，指示 AB3 在成本归一化误差标准下是否最优。最终输出必须是单行，包含从情况 1 到情况 5 的五个布尔结果列表，格式为逗号分隔的 Python 风格列表，例如 $[b_1,b_2,b_3,b_4,b_5]$，其中每个 $b_i$ 为 $\\mathrm{True}$ 或 $\\mathrm{False}$。", "solution": "在尝试解答之前，需要对问题陈述进行严格验证。\n\n**步骤 1：提取已知条件**\n\n- **微分方程：** $y'(t) = \\lambda y(t)$\n- **初始条件：** $y(0) = 1$\n- **区间：** $t \\in [0, T]$\n- **精确解：** $y(t) = \\exp(\\lambda t)$\n- **步长：** 均匀步长 $h$，使得 $N = T/h$ 是一个整数。\n- **校正方法（固定）：** 三阶 Adams-Moulton (AM)。问题也将其称为“三步校正子”，这造成了歧义。\n- **预测方法（可变）：**\n    1. 两步 Adams-Bashforth (AB2)\n    2. 三步 Adams-Bashforth (AB3)\n    3. 四步 Adams-Bashforth (AB4)\n- **积分方案：** PECE（预测-求值-校正-求值）模式，单次校正步骤。\n- **成本模型：**\n    - 一次函数求值 $f(t, y) = \\lambda y$ 的成本为 $1$。\n    - 初始化：对于需要直到 $t_k$ 的历史记录的方法，值 $y_0, y_1, ..., y_k$ 取自精确解。成本包括对这些点中的每一个进行一次函数求值，即计算 $f_0, f_1, ..., f_k$。\n    - 每步：每个 PECE 步骤产生 $2$ 的成本（预测子一次求值，校正子一次求值）。\n- **度量标准：**\n    - 全局误差：$E = |y_N - \\exp(\\lambda T)|$\n    - 总成本：$C$，即函数求值的总次数。\n    - 性能度量：成本归一化误差，$E/C$。\n- **目标：** 确定 AB3/AM 方案是否最优，即它是否产生最小的 $E/C$。\n- **平局决胜规则：** 如果多种方法产生相同的最小 $E/C$，则认为预测子阶数最小的方法最优。\n- **测试用例 $(\\lambda, T, h)$:**\n    1. $(-1.0, 1.0, 0.05)$\n    2. $(-10.0, 1.0, 0.02)$\n    3. $(-1.0, 1.0, 0.01)$\n    4. $(1.0, 1.0, 0.01)$\n    5. $(-1.0, 1.0, 0.2)$\n\n**步骤 2：使用提取的已知条件进行验证**\n\n该问题具有科学依据、提法明确且客观。它涉及求解常微分方程的标准数值方法。然而，问题陈述中存在一个微小的不一致之处。它指明了“一个固定的 Adams–Moulton 三步校正子”，并且“校正子是三阶 Adams–Moulton 方法”。\n\n- 一个标准的**三步** Adams-Moulton 方法 (AM3) 是**四阶**的。其公式为 $y_{n+1} = y_n + \\frac{h}{24}(9f_{n+1} + 19f_n - 5f_{n-1} + f_{n-2})$。\n- 一个标准的**三阶** Adams-Moulton 方法 (AM2) 是一个**两步**方法。其公式为 $y_{n+1} = y_n + \\frac{h}{12}(5f_{n+1} + 8f_n - f_{n-1})$。\n\n这是一个矛盾。严格的解释将使问题无效。然而，由于“阶”是数值方法比“步数”（可以有不同计算方式）更基本、更不模糊的属性，我将假定“三阶”的规定是预期的意图。这是对该歧义的合理解释。\n\n**结论：** 该问题被认为是有效的，但这取决于对所指出歧义的解决。解决方案将基于三阶 Adams-Moulton 校正子。\n\n**步骤 3：构建解决方案**\n\n我们将实现三种预测-校正方案。所有方案都使用 PECE 模式，并以三阶 Adams-Moulton (AM2) 方法作为校正子。\n\n常微分方程为 $y' = f(t,y) = \\lambda y$。令 $y_n$ 为 $y(t_n)$ 在 $t_n = n h$ 处的数值近似值，且 $f_n = f(t_n, y_n) = \\lambda y_n$。\n\n**校正子：三阶 Adams-Moulton (AM2, 2步)**\n校正步骤使用预测的函数值 $f_{n+1}^{(p)} = f(t_{n+1}, y_{n+1}^{(p)})$ 计算最终值 $y_{n+1}$。\n$$ y_{n+1} = y_n + \\frac{h}{12} (5 f_{n+1}^{(p)} + 8 f_n - f_{n-1}) $$\n此方法需要历史值 $y_n$ 和 $f_n, f_{n-1}$。因此，它可以从 $n=1$ 开始应用以计算 $y_2$。\n\n我们根据它们的预测子分析这三种方案。\n\n**方案 1：AB2 预测子 / AM2 校正子**\n预测子是二阶 Adams-Bashforth 方法（2步）：\n$$ y_{n+1}^{(p)} = y_n + \\frac{h}{2} (3 f_n - f_{n-1}) $$\n- **初始化：** 预测子需要 $f_0$ 和 $f_1$。校正子也需要直到索引 1 的值。因此，我们必须精确初始化 $y_0$ 和 $y_1$。\n  - $y_0 = y(0) = 1$。计算 $f_0 = \\lambda y_0$。成本：$1$。\n  - $y_1 = y(h) = \\exp(\\lambda h)$。计算 $f_1 = \\lambda y_1$。成本：$1$。\n  - 初始成本为 $2$。\n- **迭代：** 主循环从 $n=1$ 到 $N-1$ 运行，执行 $(N-1)$ 步。每步成本为 $2$。\n- **总成本 ($C_2$):** $C_2 = 2 + 2(N-1) = 2N$。\n\n**方案 2：AB3 预测子 / AM2 校正子**\n预测子是三阶 Adams-Bashforth 方法（3步）：\n$$ y_{n+1}^{(p)} = y_n + \\frac{h}{12} (23 f_n - 16 f_{n-1} + 5 f_{n-2}) $$\n- **初始化：** 预测子需要 $f_0, f_1, f_2$。我们精确初始化 $y_0, y_1, y_2$。\n  - 计算 $f_0, f_1, f_2$。初始成本为 $3$。\n- **迭代：** 第一个要计算的值是 $y_3$。循环从 $n=2$ 到 $N-1$ 运行，执行 $(N-2)$ 步。\n- **总成本 ($C_3$):** $C_3 = 3 + 2(N-2) = 2N - 1$。\n\n**方案 3：AB4 预测子 / AM2 校正子**\n预测子是四阶 Adams-Bashforth 方法（4步）：\n$$ y_{n+1}^{(p)} = y_n + \\frac{h}{24} (55 f_n - 59 f_{n-1} + 37 f_{n-2} - 9 f_{n-3}) $$\n- **初始化：** 预测子需要 $f_0, f_1, f_2, f_3$。我们精确初始化 $y_0, y_1, y_2, y_3$。\n  - 计算 $f_0, f_1, f_2, f_3$。初始成本为 $4$。\n- **迭代：** 第一个要计算的值是 $y_4$。循环从 $n=3$ 到 $N-1$ 运行，执行 $(N-3)$ 步。\n- **总成本 ($C_4$):** $C_4 = 4 + 2(N-3) = 2N - 2$。\n\n**最优性条件**\n对于每个测试用例，我们计算成本归一化误差 $v_2 = E_2/C_2$、$v_3 = E_3/C_3$ 和 $v_4 = E_4/C_4$。AB3 方案被确定为最优的条件是，当且仅当其度量 $v_3$ 严格小于 $v_2$ 并且小于或等于 $v_4$。形式上，如果满足以下条件，AB3 是最优的：\n$$ (v_3  v_2) \\land (v_3 \\le v_4) $$\n该逻辑包含了平局决胜规则，该规则偏好低阶预测子。如果 $v_3 = v_2$，则选择 AB2。如果 $v_3 = v_4$，则选择 AB3。\n\n该算法将为每个测试用例实现，以计算这三个度量并评估此条件。每个用例的最终结果将是一个布尔值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the experiments for each test case.\n    \"\"\"\n\n    test_cases = [\n        # Case 1: (lambda, T, h)\n        (-1.0, 1.0, 0.05),\n        # Case 2\n        (-10.0, 1.0, 0.02),\n        # Case 3\n        (-1.0, 1.0, 0.01),\n        # Case 4\n        (1.0, 1.0, 0.01),\n        # Case 5\n        (-1.0, 1.0, 0.2),\n    ]\n\n    results = []\n    for params in test_cases:\n        v2 = run_predictor_corrector_scheme(predictor_order=2, params=params)\n        v3 = run_predictor_corrector_scheme(predictor_order=3, params=params)\n        v4 = run_predictor_corrector_scheme(predictor_order=4, params=params)\n\n        # Optimality condition for AB3: E/C is minimal.\n        # Tie-breaking rule: smallest predictor order wins.\n        # AB3 is optimal if (v3  v2) AND (v3 = v4).\n        is_ab3_optimal = (v3  v2) and (v3 = v4)\n        results.append(is_ab3_optimal)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef run_predictor_corrector_scheme(predictor_order, params):\n    \"\"\"\n    Runs a single predictor-corrector scheme for a given predictor order and parameters.\n\n    Args:\n        predictor_order (int): The order of the Adams-Bashforth predictor (2, 3, or 4).\n        params (tuple): A tuple containing (lambda, T, h).\n\n    Returns:\n        float: The cost-normalized error E/C.\n    \"\"\"\n    lam, T, h = params\n    N = int(round(T / h))\n    \n    # f(t, y) = lambda * y\n    f = lambda y_val: lam * y_val\n\n    # Arrays to store solution y and function evaluations f\n    y = np.zeros(N + 1, dtype=np.float64)\n    f_vals = np.zeros(N + 1, dtype=np.float64)\n    \n    # s is the number of steps for the predictor, which determines initialization\n    s = predictor_order\n\n    # Initialization\n    # Initialize minimal required history using exact solution y(t) = exp(lambda*t)\n    # The cost is 1 for each function evaluation.\n    cost = 0\n    for k in range(s):\n        tk = k * h\n        y[k] = np.exp(lam * tk)\n        f_vals[k] = f(y[k])\n        cost += 1\n\n    # Main PECE loop\n    # Loop starts after the initialized history, i.e., at n = s-1\n    for n in range(s - 1, N):\n        # P: Predict y_{n+1}\n        if predictor_order == 2: # AB2\n            y_pred = y[n] + (h / 2.0) * (3.0 * f_vals[n] - f_vals[n-1])\n        elif predictor_order == 3: # AB3\n            y_pred = y[n] + (h / 12.0) * (23.0 * f_vals[n] - 16.0 * f_vals[n-1] + 5.0 * f_vals[n-2])\n        elif predictor_order == 4: # AB4\n            y_pred = y[n] + (h / 24.0) * (55.0 * f_vals[n] - 59.0 * f_vals[n-1] + 37.0 * f_vals[n-2] - 9.0 * f_vals[n-3])\n        else:\n            raise ValueError(\"Unsupported predictor order.\")\n        \n        # E: Evaluate f at predicted value\n        f_pred = f(y_pred)\n        cost += 1\n        \n        # C: Correct y_{n+1} using AM2 (order 3)\n        y[n+1] = y[n] + (h / 12.0) * (5.0 * f_pred + 8.0 * f_vals[n] - f_vals[n-1])\n        \n        # E: Evaluate f at corrected value for the next step\n        f_vals[n+1] = f(y[n+1])\n        cost += 1\n        \n    # Calculate final error and cost-normalized error\n    y_exact_final = np.exp(lam * T)\n    error = np.abs(y[N] - y_exact_final)\n    \n    if cost == 0:\n        return float('inf')\n\n    return error / cost\n\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2410035"}]}