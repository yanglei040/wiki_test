{"hands_on_practices": [{"introduction": "预条件共轭梯度（PCG）方法是求解大型稀疏对称正定（SPD）线性系统的基石。然而，其有效性甚至数值稳定性都严重依赖于预条件子 $M$ 的性质。这个练习 [@problem_id:2427468] 提供了一个具体的例子，通过构造一个非对称正定的预条件子导致算法立即失效的情况，来说明为何预条件子本身也必须是SPD矩阵。这是关于如何正确选择预条件子的一节关键课程。", "problem": "考虑线性系统 $A \\mathbf{x} = \\mathbf{b}$，其中包含对称正定（SPD）矩阵\n$$\nA = \\begin{pmatrix}\n2  0 \\\\\n0  1\n\\end{pmatrix},\n$$\n右端项为\n$$\n\\mathbf{b} = \\begin{pmatrix}\n1 \\\\\n1\n\\end{pmatrix},\n$$\n初始猜测为 $\\mathbf{x}_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。设预条件子为对称但非 SPD 矩阵\n$$\nM = \\begin{pmatrix}\n1  0 \\\\\n0  -1\n\\end{pmatrix}.\n$$\n定义初始残差 $\\mathbf{r}_{0} = \\mathbf{b} - A \\mathbf{x}_{0}$，预处理残差 $\\mathbf{z}_{0}$ 为 $M \\mathbf{z}_{0} = \\mathbf{r}_{0}$ 的唯一解。考虑标量\n$$\ns = \\mathbf{r}_{0}^{\\top} \\mathbf{z}_{0}.\n$$\n精确计算 $s$。将最终答案表示为单个实数。无需四舍五入。", "solution": "矩阵 $A$ 是对称正定的，因为它是一个对角矩阵，且对角线元素 $2$ 和 $1$ 均为正。矩阵 $M$ 是对称但非正定的，因为其特征值为 $1$ 和 $-1$，所以它是不定的。\n\n根据定义，初始残差为\n$$\n\\mathbf{r}_{0} = \\mathbf{b} - A \\mathbf{x}_{0}.\n$$\n给定 $\\mathbf{x}_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$，我们得到\n$$\n\\mathbf{r}_{0} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} - \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}.\n$$\n预处理残差 $\\mathbf{z}_{0}$ 由求解下式定义\n$$\nM \\mathbf{z}_{0} = \\mathbf{r}_{0}.\n$$\n由于 $M = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix}$ 是可逆的，且 $M^{-1} = M$，我们有\n$$\n\\mathbf{z}_{0} = M^{-1} \\mathbf{r}_{0} = M \\mathbf{r}_{0} = \\begin{pmatrix} 1  0 \\\\ 0  -1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}.\n$$\n现在计算标量\n$$\ns = \\mathbf{r}_{0}^{\\top} \\mathbf{z}_{0} = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix} = 1 \\cdot 1 + 1 \\cdot (-1) = 0.\n$$\n这个值直接显示了预条件共轭梯度（PCG）方法的一种失败模式：在标准的左预处理公式中，步长系数 $\\alpha_{0}$ 使用分子 $(\\mathbf{r}_{0}^{\\top} \\mathbf{z}_{0})$，而搜索方向的递推公式使用比率 $(\\mathbf{r}_{k+1}^{\\top} \\mathbf{z}_{k+1}) / (\\mathbf{r}_{k}^{\\top} \\mathbf{z}_{k})$。当 $s = \\mathbf{r}_{0}^{\\top} \\mathbf{z}_{0} = 0$ 且 $\\mathbf{r}_{0} \\neq \\mathbf{0}$ 时，在使用非 SPD 预条件子 $M$ 的情况下，该方法在第一次迭代时会发生崩溃。\n\n因此，所求标量为 $0$。", "answer": "$$\\boxed{0}$$", "id": "2427468"}, {"introduction": "在建立了预条件子的基本要求之后，我们现在转向一个实际的、完整的实现。在这个编程练习 [@problem_id:2444004] 中，你将解决经典的二维拉普拉斯方程问题。通过分别实现带有和不带对称逐次超松弛（SSOR）预条件子的共轭梯度（CG）方法，你将亲身体验一个精心选择的预条件子如何能够显著加速实际科学计算问题的收敛速度。", "problem": "你需要编写一个完整的、可运行的程序，研究对称逐次超松弛 (SSOR) 方法的行为，以及它在应用于拉普拉斯型方程时，如何作为其他求解器的预条件子发挥作用。你的解法需要从基本数学模型出发，推导出所有必需的离散化方案和迭代方法。不要使用任何预先提供的公式；相反，应从定义和经过验证的事实出发，推导所需的表达式。\n\n考虑在单位正方形上具有狄利克雷边界条件的二维拉普拉斯型问题。其连续模型基于由梯度散度定义的拉普拉斯算子。离散化必须在内部点的均匀网格上进行。其结果是一个具有实对称正定矩阵的线性系统。\n\n你的程序必须：\n- 使用基本的有限差分原理，在大小为 $N \\times N$ 的内部点均匀网格上对连续模型进行离散化，从而构建线性系统。\n- 使用一个由光滑函数构造的非平凡右端项，该函数在单位正方形的边界上取值为零，以确保与齐次狄利克雷条件的一致性。\n- 从第一性原理出发，实现用于对称正定系统的共轭梯度法 (CG)，当残差的相对 2-范数小于给定容差时停止迭代。\n- 实现使用对称逐次超松弛 (SSOR) 预条件子的预处理共轭梯度法 (PCG)。SSOR 预条件子必须从与逐次超松弛 (SOR) 相关联的矩阵分裂中推导得出，并且必须在 PCG 内部作为算子应用，而不是显式地构造为一个稠密逆矩阵。松弛因子必须用 $\\omega$ 表示，并限制在 $0  \\omega  2$ 的范围内。\n- 对于每个测试用例，计算并记录两个整数：未预处理的 CG 的迭代次数和带有 SSOR 的 PCG 的迭代次数，两者均使用基于残差相对 2-范数的相同停止准则。\n\n解法推导的基本依据：\n- 拉普拉斯算子是梯度的散度。在均匀网格上，其标准的二阶中心有限差分离散化与齐次狄利克雷边界条件相结合，会产生一个具有实对称正定矩阵的稀疏线性系统。\n- 针对对称正定矩阵的共轭梯度法，是通过在相对于矩阵诱导内积的共轭方向上，最小化与系统矩阵相关的二次型而推导出来的。\n- 逐次超松弛法由矩阵分裂（分为对角、严格下三角和严格上三角部分）和一个松弛因子定义。对称逐次超松弛法通过应用前向和后向扫描来为 $0  \\omega  2$ 定义一个对称正定预条件子。\n\n测试套件：\n- 使用以下测试用例集，其中每个用例是一个元组 $(N, \\omega)$，$N$ 是每个方向上内部点的数量，$\\omega$ 是 SSOR 的松弛因子：\n    1. $(16, 1.0)$\n    2. $(16, 1.5)$\n    3. $(16, 1.9)$\n    4. $(8, 1.7)$\n\n算法规范：\n- 所有求解器的初始猜测值必须是零向量。\n- 右端项必须由一个在单位正方形边界上为零的光滑函数生成；在每个 $N$ 对应的内部网格上构造它，并组装成对应于离散系统的向量。\n- CG 和 PCG 的停止准则必须是相对残差 2-范数（定义为 $\\|r_k\\|_2 / \\|r_0\\|_2$）小于 $10^{-8}$，其中 $r_k$ 是第 $k$ 次迭代的残差，$r_0$ 是初始残差。如果在 5000 次迭代之前未达到此容差，则停止并返回已执行的迭代次数。\n\n输出规范：\n- 对于每个测试用例，输出一个包含两个整数的列表 $[k_{\\mathrm{CG}}, k_{\\mathrm{PCG-SSOR}}]$，其中 $k_{\\mathrm{CG}}$ 是未预处理共轭梯度法的迭代次数，$k_{\\mathrm{PCG-SSOR}}$ 是使用给定 $\\omega$ 的 SSOR 预处理的预处理共轭梯度法的迭代次数。\n- 你的程序应生成单行输出，其中包含所有测试用例的结果，格式为一个由逗号分隔的、包含这两个整数的列表的列表，并用方括号括起来。例如：$[[3,2],[4,2],[5,2],[3,2]]$。", "solution": "所提出的问题是计算物理学中一个适定且科学合理的问题，要求实现并比较求解拉普拉斯型偏微分方程的数值方法。它基于数值分析的基本原理，没有歧义或矛盾。我们将进行形式化的推导和求解。\n\n我们考虑的问题是在单位正方形域 $\\Omega = (0,1) \\times (0,1)$ 上的二维拉普拉斯型方程：\n$$\n-\\nabla^2 u(x,y) = f(x,y) \\quad \\text{for} \\quad (x,y) \\in \\Omega\n$$\n服从齐次狄利克雷边界条件，$u(x,y) = 0$ 对于 $(x,y) \\in \\partial\\Omega$。算子 $\\nabla^2$ 是拉普拉斯算子，定义为梯度的散度，$\\nabla^2 u = \\nabla \\cdot (\\nabla u) = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}$。\n\n首先，我们必须离散化这个连续问题。我们定义一个在每个方向上有 $N$ 个内部点的均匀网格。网格间距为 $h = \\frac{1}{N+1}$。网格点为 $(x_i, y_j) = (ih, jh)$，其中 $i,j = 0, 1, \\dots, N+1$。函数 $u$ 的未知值在内部点处进行近似，记为 $u_{i,j} \\approx u(x_i, y_j)$，其中 $i,j = 1, \\dots, N$。在边界上（即 $i=0, N+1$ 或 $j=0, N+1$）的值为零。\n\n我们采用二阶中心有限差分来近似二阶导数：\n$$\n\\frac{\\partial^2 u}{\\partial x^2}\\bigg|_{(x_i, y_j)} \\approx \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2}\n$$\n$$\n\\frac{\\partial^2 u}{\\partial y^2}\\bigg|_{(x_i, y_j)} \\approx \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2}\n$$\n将这些代入原始方程，得到每个内部网格点 $(i,j)$ 处的离散方程：\n$$\n-\\left( \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h^2} + \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h^2} \\right) = f_{i,j}\n$$\n其中 $f_{i,j} = f(x_i, y_j)$。整理这个表达式，我们得到五点差分格式方程：\n$$\n4u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1} = h^2f_{i,j}\n$$\n这 $N^2$ 个关于 $N^2$ 个未知数 $u_{i,j}$ 的线性方程构成一个线性系统 $A\\mathbf{u} = \\mathbf{b}$。其中，$\\mathbf{u}$ 是一个由未知数 $u_{i,j}$ 按特定顺序（通常是字典序，即逐行或逐列）排列而成的向量。矩阵 $A$ 是一个大小为 $N^2 \\times N^2$ 的实稀疏块三对角矩阵。众所周知，对于此问题，矩阵 $A$ 是对称正定的 (SPD)，这些性质对于选择迭代求解器至关重要。\n\n为了确保与齐次边界条件的一致性，我们必须构造一个源函数 $f(x,y)$，使得精确解 $u(x,y)$ 在边界上为零。我们可以构造这样一个解。让我们选择 $u_{exact}(x,y) = \\sin(\\pi x)\\sin(\\pi y)$，它显然满足在 $\\partial\\Omega$ 上 $u=0$。然后，通过应用负拉普拉斯算子得到相应的源函数：\n$$\nf(x,y) = -\\nabla^2 u_{exact}(x,y) = -\\left( -\\pi^2\\sin(\\pi x)\\sin(\\pi y) - \\pi^2\\sin(\\pi x)\\sin(\\pi y) \\right) = 2\\pi^2\\sin(\\pi x)\\sin(\\pi y)\n$$\n那么，我们线性系统的右端项向量 $\\mathbf{b}$ 由元素 $b_{k} = h^2 f(x_i, y_j)$ 组成，其中索引 $k$ 对应于网格点 $(i,j)$。\n\n在建立线性系统 $A\\mathbf{u} = \\mathbf{b}$ 之后，我们现在转向其求解。\n\n共轭梯度 (CG) 法是一种为求解矩阵 $A$ 是对称正定的线性系统而设计的迭代算法。它通过选择 $A$-正交的搜索方向，在不断扩大的克雷洛夫子空间上有效地最小化误差的 $A$-范数，从而优于最速下降法。算法如下，从初始猜测 $\\mathbf{x}_0 = \\mathbf{0}$ 开始：\n1. 初始化：$\\mathbf{r}_0 = \\mathbf{b} - A\\mathbf{x}_0 = \\mathbf{b}$，第一个搜索方向 $\\mathbf{p}_0 = \\mathbf{r}_0$。\n2. 对于迭代 $k = 0, 1, 2, \\dots$：\n   a. 计算步长：$\\alpha_k = \\frac{\\mathbf{r}_k^T \\mathbf{r}_k}{\\mathbf{p}_k^T A \\mathbf{p}_k}$。\n   b. 更新解：$\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$。\n   c. 更新残差：$\\mathbf{r}_{k+1} = \\mathbf{r}_k - \\alpha_k A \\mathbf{p}_k$。\n   d. 检查收敛性，例如 $\\|\\mathbf{r}_{k+1}\\|_2 \\le \\epsilon$。\n   e. 计算下一个搜索方向的改进量：$\\beta_k = \\frac{\\mathbf{r}_{k+1}^T \\mathbf{r}_{k+1}}{\\mathbf{r}_k^T \\mathbf{r}_k}$。\n   f. 更新搜索方向：$\\mathbf{p}_{k+1} = \\mathbf{r}_{k+1} + \\beta_k \\mathbf{p}_k$。\n\nCG 的收敛速度取决于条件数 $\\kappa(A)$。对于病态系统，收敛可能很慢。预处理是一种将原系统转换为具有更有利谱性质的系统的技术。我们求解 $M^{-1}A\\mathbf{x} = M^{-1}\\mathbf{b}$，其中 $M$ 是预条件子，它是一个近似于 $A$ 的对称正定矩阵，并且对于它，$M\\mathbf{z} = \\mathbf{r}$ 这样的系统很容易求解。\n\n预处理共轭梯度 (PCG) 算法修改了 CG 以包含此预处理步骤。\n1. 初始化：$\\mathbf{x}_0 = \\mathbf{0}$，$\\mathbf{r}_0 = \\mathbf{b}$。\n2. 求解预处理系统：$M\\mathbf{z}_0 = \\mathbf{r}_0$。\n3. 设置搜索方向：$\\mathbf{p}_0 = \\mathbf{z}_0$。\n4. 对于迭代 $k = 0, 1, 2, \\dots$：\n   a. 计算步长：$\\alpha_k = \\frac{\\mathbf{r}_k^T \\mathbf{z}_k}{\\mathbf{p}_k^T A \\mathbf{p}_k}$。\n   b. 更新解：$\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$。\n   c. 更新残差：$\\mathbf{r}_{k+1} = \\mathbf{r}_k - \\alpha_k A \\mathbf{p}_k$。\n   d. 检查收敛性。\n   e. 求解预处理系统：$M\\mathbf{z}_{k+1} = \\mathbf{r}_{k+1}$。\n   f. 计算改进量：$\\beta_k = \\frac{\\mathbf{r}_{k+1}^T \\mathbf{z}_{k+1}}{\\mathbf{r}_k^T \\mathbf{z}_k}$。\n   g. 更新搜索方向：$\\mathbf{p}_{k+1} = \\mathbf{z}_{k+1} + \\beta_k \\mathbf{p}_k$。\n\n我们的任务是使用对称逐次超松弛 (SSOR) 预条件子。为了推导其形式，我们从矩阵分裂 $A = D - L - U$ 开始，其中 $D$ 是 $A$ 的对角部分，$-L$ 是严格下三角部分，$-U$ 是严格上三角部分。对于我们的对称矩阵 $A$，有 $U = L^T$。SSOR 定常迭代包含一次前向 SOR 扫描和一次后向 SOR 扫描。这种结构产生了一个对称的预条件子 $M_{SSOR}$。SSOR 预条件子的标准定义是：\n$$\nM_{SSOR} = \\frac{1}{\\omega(2-\\omega)}(D - \\omega L) D^{-1} (D - \\omega U)\n$$\n对于我们的对称正定矩阵 $A$ 和松弛因子 $0  \\omega  2$，预条件子 $M_{SSOR}$ 也是对称正定的。问题要求我们将此预条件子作为算子来应用，即实现一个函数，对于给定的向量 $\\mathbf{r}$，计算 $\\mathbf{z} = M_{SSOR}^{-1}\\mathbf{r}$，而无需显式地构造 $M_{SSOR}$。\n为了找到 $M_{SSOR}^{-1}$ 的作用，我们求解系统 $M_{SSOR}\\mathbf{z} = \\mathbf{r}$：\n$$\n\\frac{1}{\\omega(2-\\omega)}(D - \\omega L) D^{-1} (D - \\omega U)\\mathbf{z} = \\mathbf{r}\n$$\n我们定义一个中间向量 $\\mathbf{y} = D^{-1} (D - \\omega U)\\mathbf{z}$。方程变为 $(D - \\omega L)\\mathbf{y} = \\omega(2-\\omega)\\mathbf{r}$。由于 $(D - \\omega L)$ 是一个下三角矩阵，我们可以通过在网格上进行一次前向代入来求解 $\\mathbf{y}$。\n找到 $\\mathbf{y}$ 之后，我们可以从 $\\mathbf{y}$ 的定义中求出 $\\mathbf{z}$。我们有 $(D - \\omega U)\\mathbf{z} = D\\mathbf{y}$。由于 $(D - \\omega U)$ 是一个上三角矩阵，我们通过在网格上进行一次后向代入来求解 $\\mathbf{z}$。\n\n因此，计算 $\\mathbf{z} = M_{SSOR}^{-1}\\mathbf{r}$ 的过程如下：\n1. 第一次扫描（前向代入）：求解 $(D - \\omega L)\\mathbf{y} = \\omega(2-\\omega)\\mathbf{r}$ 以得到 $\\mathbf{y}$。\n2. 第二次扫描（后向代入）：求解 $(D - \\omega U)\\mathbf{z} = D\\mathbf{y}$ 以得到 $\\mathbf{z}$。\n\n对于我们特定的矩阵 $A$，其对角元全部为 4，因此 $D = 4I$。在网格点 $(i,j)$ 处的前向扫描方程为：$4y_{i,j} - \\omega(y_{i-1,j} + y_{i,j-1}) = \\omega(2-\\omega)r_{i,j}$。后向扫描方程为：$4z_{i,j} - \\omega(z_{i+1,j} + z_{i,j+1}) = 4y_{i,j}$。这些扫描的计算成本低廉，并构成了 PCG 算法中预处理步骤的核心。\n\n现在，我们可以着手实现这些算法，并在指定的测试用例上评估它们的性能。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef assemble_rhs(N, h):\n    \"\"\"\n    Assembles the right-hand side vector for the discretized Poisson equation\n    -div(grad(u)) = f on a unit square. The function f is derived from a\n    manufactured solution u_exact = sin(pi*x)sin(pi*y).\n    \"\"\"\n    coords = h * np.arange(1, N + 1)\n    X, Y = np.meshgrid(coords, coords, indexing='ij')\n    f_analytic = 2 * (np.pi**2) * np.sin(np.pi * X) * np.sin(np.pi * Y)\n    b = (h**2) * f_analytic\n    return b.flatten()\n\ndef matvec(v_flat, N):\n    \"\"\"\n    Computes the matrix-vector product Av for the 5-point Laplacian stencil.\n    The matrix A is never explicitly formed.\n    \"\"\"\n    v = v_flat.reshape((N, N))\n    v_padded = np.zeros((N + 2, N + 2))\n    v_padded[1:-1, 1:-1] = v\n    \n    # Apply the stencil: 4*v_ij - v_{i-1,j} - v_{i+1,j} - v_{i,j-1} - v_{i,j+1}\n    Av = 4 * v - (v_padded[0:-2, 1:-1] + v_padded[2:, 1:-1] +\n                    v_padded[1:-1, 0:-2] + v_padded[1:-1, 2:])\n    \n    return Av.flatten()\n\ndef ssor_preconditioner(r_flat, N, omega):\n    \"\"\"\n    Applies the SSOR preconditioner solve Mz = r.\n    This is implemented as a forward sweep followed by a backward sweep.\n    M = (1/(w(2-w))) * (D - wL) * D^-1 * (D - wU)\n    D = 4I\n    \"\"\"\n    r_grid = r_flat.reshape((N, N))\n    \n    # 1. Forward substitution: solve (D - omega*L)y = omega*(2-omega)*r\n    # D is 4I. L corresponds to connections to lower-indexed nodes.\n    # 4*y_ij - omega*y_{i-1,j} - omega*y_{i,j-1} = omega*(2-omega)*r_ij\n    y_grid = np.zeros((N, N))\n    rhs1_grid = omega * (2 - omega) * r_grid\n    for j in range(N):\n        for i in range(N):\n            term = rhs1_grid[i, j]\n            if i > 0:\n                term += omega * y_grid[i - 1, j]\n            if j > 0:\n                term += omega * y_grid[i, j - 1]\n            y_grid[i, j] = term / 4.0\n\n    # 2. Backward substitution: solve (D - omega*U)z = D*y\n    # D is 4I. U corresponds to connections to higher-indexed nodes.\n    # 4*z_ij - omega*z_{i+1,j} - omega*z_{i,j+1} = 4*y_ij\n    z_grid = np.zeros((N, N))\n    rhs2_grid = 4.0 * y_grid\n    for j in range(N - 1, -1, -1):\n        for i in range(N - 1, -1, -1):\n            term = rhs2_grid[i, j]\n            if i  N - 1:\n                term += omega * z_grid[i + 1, j]\n            if j  N - 1:\n                term += omega * z_grid[i, j + 1]\n            z_grid[i, j] = term / 4.0\n            \n    return z_grid.flatten()\n\ndef cg_solver(N, b, tol, max_iter):\n    \"\"\"\n    Conjugate Gradient solver for Ax=b.\n    \"\"\"\n    x = np.zeros_like(b)\n    r = b.copy()\n    p = r.copy()\n    \n    r0_norm = np.linalg.norm(r)\n    if r0_norm == 0:\n        return 0\n        \n    rs_old = np.dot(r, r)\n    \n    for k in range(max_iter):\n        Ap = matvec(p, N)\n        alpha = rs_old / np.dot(p, Ap)\n        \n        x += alpha * p\n        r -= alpha * Ap\n        \n        rs_new = np.dot(r, r)\n        \n        if np.sqrt(rs_new) / r0_norm = tol:\n            return k + 1\n            \n        p = r + (rs_new / rs_old) * p\n        rs_old = rs_new\n        \n    return max_iter\n\ndef pcg_ssor_solver(N, b, omega, tol, max_iter):\n    \"\"\"\n    Preconditioned Conjugate Gradient solver using SSOR as preconditioner.\n    \"\"\"\n    x = np.zeros_like(b)\n    r = b.copy()\n    \n    r0_norm = np.linalg.norm(r)\n    if r0_norm == 0:\n        return 0\n\n    z = ssor_preconditioner(r, N, omega)\n    p = z.copy()\n    rz_old = np.dot(r, z)\n\n    for k in range(max_iter):\n        Ap = matvec(p, N)\n        alpha = rz_old / np.dot(p, Ap)\n        \n        x += alpha * p\n        r -= alpha * Ap\n        \n        if np.linalg.norm(r) / r0_norm = tol:\n            return k + 1\n            \n        z = ssor_preconditioner(r, N, omega)\n        rz_new = np.dot(r, z)\n        \n        beta = rz_new / rz_old\n        p = z + beta * p\n        rz_old = rz_new\n        \n    return max_iter\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and print the results.\n    \"\"\"\n    # (N, omega)\n    test_cases = [\n        (16, 1.0),\n        (16, 1.5),\n        (16, 1.9),\n        (8, 1.7)\n    ]\n    \n    results = []\n    tol = 1e-8\n    max_iter = 5000\n\n    for case in test_cases:\n        N, omega = case\n        h = 1.0 / (N + 1)\n        \n        # Assemble the right-hand side vector\n        b = assemble_rhs(N, h)\n        \n        # Run unpreconditioned Conjugate Gradient\n        k_cg = cg_solver(N, b, tol, max_iter)\n        \n        # Run Preconditioned Conjugate Gradient with SSOR\n        k_pcg_ssor = pcg_ssor_solver(N, b, omega, tol, max_iter)\n        \n        results.append(f\"[{k_cg},{k_pcg_ssor}]\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2444004"}, {"introduction": "在前面的实践基础上，这个练习 [@problem_id:2427470] 将探索一种更先进的策略：块预条件。虽然像点雅可比这样的点式方法很简单，但将未知量分组处理通常可以产生更强大（尽管也更昂贵）的预条件子。你将为二维泊松问题实现一个行块雅可比预条件子，并将其性能与无预条件求解器和更简单的点雅可比预条件子进行比较，从而深入理解预条件设计中固有的权衡。", "problem": "构建一个程序，该程序针对一系列线性系统，这些线性系统源于在内部尺寸为 $n \\times n$ 的正方形网格上，对具有齐次狄利克雷边界条件的二维泊松方程进行标准五点有限差分格式离散化后得到。该程序将构建并应用一个块雅可比预条件子，其块对应于连续的节点线。系统矩阵是 $N=n^2$ 的对称正定矩阵 $A \\in \\mathbb{R}^{N \\times N}$，定义为\n$$\nA = I_n \\otimes T_n + T_n \\otimes I_n,\n$$\n其中 $T_n \\in \\mathbb{R}^{n \\times n}$ 是一个三对角矩阵，其主对角线元素为 $2$，次对角线和超对角线元素为 $-1$，$\\otimes$ 表示克罗内克积。未知向量按行主序的字典序排列。设右端项为 $b = \\mathbf{1} \\in \\mathbb{R}^{N}$，初始猜测值为 $x_0 = \\mathbf{0} \\in \\mathbb{R}^{N}$。\n\n通过取 $A$ 的块对角线来定义块雅可比预条件子 $M \\in \\mathbb{R}^{N \\times N}$，其块对角线对应于以下两种情况之一：\n- 平行于 $x$ 轴的线（逐行分块），或\n- 平行于 $y$ 轴的线（逐列分块），\n使得每个块都是一个三对角矩阵 $B \\in \\mathbb{R}^{n \\times n}$，等于 $T_n + 2 I_n$，并独立地应用于每一条线。同时考虑点雅可比预条件子 $M_{\\mathrm{pt}} = \\mathrm{diag}(A)$。\n\n对于下面测试套件中的每个参数集，使用共轭梯度法（为对称正定系统定义）在三种配置下求解线性系统 $A x = b$：无预条件、点雅可比预条件和具有指定方向的行块雅可比预条件。在所有情况下，当残差范数满足以下条件时，迭代在最小的非负整数 $k$ 处终止：\n$$\n\\|r_k\\|_2 \\le \\varepsilon \\, \\|r_0\\|_2,\n$$\n其中 $r_k = b - A x_k$，容差 $\\varepsilon = 10^{-8}$（在欧几里得范数下测量），并将迭代次数限制在最多 $K_{\\max} = 5000$ 步。对于每个参数集，报告四个值：迭代次数 $k_{\\mathrm{none}}$、$k_{\\mathrm{pt}}$、$k_{\\mathrm{blk}}$，以及表示为实数的比率 $k_{\\mathrm{none}} / k_{\\mathrm{blk}}$。\n\n测试套件（每种情况都是一个对 $(n, \\mathrm{orientation})$，其中 $\\mathrm{orientation} \\in \\{\\text{row}, \\text{col}\\}$ 选择行块方向）：\n- 情况 1：$(n, \\mathrm{orientation}) = (1, \\text{row})$。\n- 情况 2：$(n, \\mathrm{orientation}) = (8, \\text{row})$。\n- 情况 3：$(n, \\mathrm{orientation}) = (8, \\text{col})$。\n- 情况 4：$(n, \\mathrm{orientation}) = (32, \\text{row})$。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，且无空格。每个测试用例的结果本身必须是 $[k_{\\mathrm{none}},k_{\\mathrm{pt}},k_{\\mathrm{blk}},k_{\\mathrm{none}}/k_{\\mathrm{blk}}]$ 形式的列表。因此，总体输出格式为\n$$\n\\bigl[ [k_{\\mathrm{none}},k_{\\mathrm{pt}},k_{\\mathrm{blk}},k_{\\mathrm{none}}/k_{\\mathrm{blk}}], \\ldots \\bigr],\n$$\n打印在一行上，例如 $[[a,b,c,d],[e,f,g,h],\\ldots]$，所有条目均为数值。", "solution": "问题陈述经评估有效。这是一个在计算工程和数值线性代数领域内的适定、有科学依据的问题。它要求实现和比较用于求解一个特定、明确定义的线性系统的预条件迭代方法。所有参数、常数和目标都已明确陈述，并与公认的科学原理一致。因此，我们可以继续提供完整的解决方案。\n\n该问题要求解线性方程组 $A x = b$，其中矩阵 $A \\in \\mathbb{R}^{N \\times N}$（$N = n^2$）源于在方形网格上对二维泊松方程的五点有限差分离散化。该矩阵由克罗内克积和给出：\n$$\nA = I_n \\otimes T_n + T_n \\otimes I_n\n$$\n这里，$I_n$ 是 $n \\times n$ 的单位矩阵，$T_n$ 是 $n \\times n$ 的三对角矩阵，其主对角线元素为 $2$，第一亚对角线和第一超对角线元素为 $-1$。此构造假设网格未知数采用行主序的字典序排列。得到的矩阵 $A$ 是对称正定的（SPD），这是选择求解器的关键属性。右端项是 $b = \\mathbf{1}$（一个全为 1 的向量），初始猜测值是 $x_0 = \\mathbf{0}$。\n\n选择的迭代求解器是共轭梯度（CG）法，它是求解 SPD 系统的标准且最高效的克雷洛夫子空间方法。我们将实现预条件共轭梯度（PCG）算法，该算法求解系统 $M^{-1} A x = M^{-1} b$，其中 $M$ 是预条件子。对于初始猜测值 $x_0$，算法如下：\n\n1.  初始化：$k=0$, $r_0 = b - A x_0$。\n2.  设置停止准则：$\\tau = \\varepsilon \\|r_0\\|_2$，其中 $\\varepsilon = 10^{-8}$。\n3.  预处理：求解 $M z_0 = r_0$。\n4.  设置初始搜索方向：$p_0 = z_0$。\n5.  计算 $\\rho_0 = r_0^T z_0$。\n6.  对 $k = 0, 1, 2, \\ldots, K_{\\max}-1$ 进行迭代：\n    a. $q_k = A p_k$\n    b. $\\alpha_k = \\rho_k / (p_k^T q_k)$\n    c. $x_{k+1} = x_k + \\alpha_k p_k$\n    d. $r_{k+1} = r_k - \\alpha_k q_k$\n    e. 如果 $\\|r_{k+1}\\|_2 \\le \\tau$，则终止并报告 $k+1$ 次迭代。\n    f. 求解 $M z_{k+1} = r_{k+1}$。\n    g. $\\rho_{k+1} = r_{k+1}^T z_{k+1}$\n    h. $\\beta_k = \\rho_{k+1} / \\rho_k$\n    i. $p_{k+1} = z_{k+1} + \\beta_k p_k$\n    j. $\\rho_k \\leftarrow \\rho_{k+1}$\n\n我们将分析由 $M$ 的选择定义的三种预处理策略。\n\n**1. 无预处理**\n这种情况等同于将预条件子 $M$ 设置为单位矩阵 $M=I$。预处理步骤“求解 $M z_k = r_k$”变得微不足道：$z_k = r_k$。这恢复为标准的共轭梯度算法。收敛速度取决于原始矩阵 $A$ 的条件数 $\\kappa(A)$，对于此问题，该条件数为 $O(n^2)$。这导致对于较大的 $n$ 收敛缓慢。\n\n**2. 点雅可比预处理**\n点雅可比预条件子是矩阵 $A$ 的对角线，因此 $M_{\\mathrm{pt}} = \\mathrm{diag}(A)$。$A = I_n \\otimes T_n + T_n \\otimes I_n$ 的对角线元素是 $I_n \\otimes T_n$ 和 $T_n \\otimes I_n$ 的对角线元素之和。$I_n \\otimes T_n$ 的对角线是一个包含 $n^2$ 个元素的向量，所有元素都等于 $2$。$T_n \\otimes I_n$ 的对角线也是一个包含 $n^2$ 个元素的向量，所有元素都等于 $2$。因此，$A$ 的对角线是常数，其所有元素均为 $2+2=4$。预条件子是 $M_{\\mathrm{pt}} = 4I_N$。应用其逆 $M_{\\mathrm{pt}}^{-1}$ 是一个简单且计算成本低的操作：将向量除以标量 $4$。\n\n**3. 行块雅可比预处理**\n此预条件子 $M_{\\mathrm{blk}}$ 是通过取 $A$ 的块对角线构建的，其中块对应于网格上的节点线。\n对于行主序，矩阵 $A$ 是一个块三对角矩阵：\n$$\nA = \\begin{pmatrix}\nT_n+2I_n  -I_n   \\\\\n-I_n  T_n+2I_n  -I_n  \\\\\n \\ddots  \\ddots  \\ddots \\\\\n  -I_n  T_n+2I_n\n\\end{pmatrix}\n$$\n对角块记为 $B$，有 $B = T_n + 2I_n$。该矩阵是三对角矩阵，主对角线元素为 $4$，次对角线元素为 $-1$。它也是对称正定的。\n\n-   **逐行方向**：块对应于网格的行。对于行主序，单个网格行上的未知数在解向量中是连续索引的。因此，块雅可比预条件子是 $A$ 的块对角线，$M_{\\mathrm{blk}} = \\mathrm{diag}(B, B, ..., B)$。将 $M_{\\mathrm{blk}}^{-1}$ 应用于残差向量 $r$ 需要求解 $n$ 个大小为 $n \\times n$ 的独立线性系统，即对每个块 $i=1, \\ldots, n$ 求解 $B z_i = r_i$。由于 $B$ 是一个带状矩阵（三对角），这些系统可以被高效求解。\n\n-   **逐列方向**：块对应于网格的列。在行主序排列的向量中，单个网格列的未知数不是连续的；它们以步长 $n$ 分隔。由于问题的对称性，耦合单列内未知数的 $A$ 的子矩阵也是矩阵 $B = T_n+2I_n$。应用预条件子逆的过程包括：对于 $n$ 个列中的每一列，(1) 从残差向量 $r$ 中收集相应的跨步元素，(2) 求解以矩阵 $B$ 为系数的 $n \\times n$ 系统，以及 (3) 将结果散布回解向量 $z$ 中。\n\n对于逐列情况的预处理矩阵 $M_{\\mathrm{blk,col}}^{-1}A$ 与逐行情况的预处理矩阵 $M_{\\mathrm{blk,row}}^{-1}A$ 相似。具体来说，如果 $P$ 是将行主序映射到列主序的置换矩阵，那么 $M_{\\mathrm{blk,col}} = P^T M_{\\mathrm{blk,row}} P$。由于算子和域的对称性，有 $PAP^T = A$ 成立。因此，$M_{\\mathrm{blk,col}}^{-1}A$ 的特征值与 $M_{\\mathrm{blk,row}}^{-1}A$ 的特征值相同。由于共轭梯度法的收敛性取决于特征值分布，我们预计对于给定的 $n$，迭代次数 $k_{\\mathrm{blk}}$ 对于 `row` 和 `col` 两种方向将是相同的。\n\n实现将构建矩阵 $A$ 和预条件子所需的必要结构。对于块雅可比预条件子，为提高效率，将使用带状线性求解器来求解三对角系统。将在每个测试用例上对三种配置中的每一种执行 PCG 算法，以确定迭代次数 $k_{\\mathrm{none}}$、$k_{\\mathrm{pt}}$ 和 $k_{\\mathrm{blk}}$。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef create_A(n):\n    \"\"\"\n    Constructs the matrix A for the 2D Poisson problem on an n x n grid.\n    \"\"\"\n    if n == 0:\n        return np.array([[]])\n    if n == 1:\n        return np.array([[4.0]])\n        \n    diag_main = np.full(n, 2.0)\n    diag_off = np.full(n-1, -1.0)\n    T_n = np.diag(diag_main) + np.diag(diag_off, k=1) + np.diag(diag_off, k=-1)\n    \n    I_n = np.eye(n)\n    \n    A = np.kron(I_n, T_n) + np.kron(T_n, I_n)\n    return A\n\ndef apply_preconditioner_inv(r, n, precon_config):\n    \"\"\"\n    Applies the inverse of the preconditioner M to a vector r.\n    z = M_inv * r\n    precon_config is a tuple (type, orientation), e.g., ('block', 'row').\n    \"\"\"\n    precon_type, orientation = precon_config\n    \n    if precon_type == 'none':\n        return r.copy()\n    \n    if precon_type == 'point':\n        # M = diag(A), which is 4*I\n        return r / 4.0\n        \n    if precon_type == 'block':\n        N = n * n\n        if N == 0:\n            return np.array([])\n        z = np.zeros(N)\n        \n        # The block matrix B = T_n + 2*I_n is tridiagonal with\n        # 4 on the main diagonal and -1 on the off-diagonals.\n        # We use a banded solver for B*z_i = r_i.\n        # Banded matrix format for scipy.linalg.solve_banded:\n        # ab[0, :] are super-diagonal elements (u=1)\n        # ab[1, :] are main-diagonal elements\n        # ab[2, :] are sub-diagonal elements (l=1)\n        # Since u=1, first element of ab[0,:] is ignored.\n        # Since l=1, last element of ab[2,:] is ignored.\n        ab = np.zeros((3, n))\n        ab[0, 1:] = -1.0\n        ab[1, :] = 4.0\n        ab[2, :-1] = -1.0\n        \n        if orientation == 'row':\n            for i in range(n):\n                start, end = i * n, (i + 1) * n\n                r_i = r[start:end]\n                z_i = solve_banded((1, 1), ab, r_i)\n                z[start:end] = z_i\n        elif orientation == 'col':\n            for j in range(n):\n                r_j = r[j::n] # Gather elements for column j\n                z_j = solve_banded((1, 1), ab, r_j)\n                z[j::n] = z_j # Scatter back\n        return z\n        \n    raise ValueError(\"Unknown preconditioner type\")\n\ndef run_cg(n, precon_config):\n    \"\"\"\n    Runs the Preconditioned Conjugate Gradient method for a given n and preconditioner.\n    \"\"\"\n    N = n * n\n    if N == 0:\n        return 0\n        \n    A = create_A(n)\n    b = np.ones(N)\n    x = np.zeros(N)\n    \n    epsilon = 1e-8\n    max_iter = 5000\n    \n    r = b - A @ x\n    \n    norm_r0 = np.linalg.norm(r)\n    if norm_r0 == 0:\n        return 0\n    \n    threshold = epsilon * norm_r0\n    \n    z = apply_preconditioner_inv(r, n, precon_config)\n    p = z.copy()\n    rho_old = r @ z\n    \n    for k in range(max_iter):\n        Ap = A @ p\n        \n        # Handle potential breakdown for very small systems/singular cases\n        p_dot_Ap = p @ Ap\n        if p_dot_Ap = 0:\n            # CG requires SPD matrix. Negative or zero value indicates problem.\n            # Could happen with non-SPD preconditioner, but ours are SPD.\n            # More likely due to floating point error accumulation.\n            # Stop if direction is not a descent direction.\n            return k + 1\n\n        alpha = rho_old / p_dot_Ap\n        x += alpha * p\n        r -= alpha * Ap\n        \n        if np.linalg.norm(r) = threshold:\n            return k + 1\n            \n        z = apply_preconditioner_inv(r, n, precon_config)\n        rho_new = r @ z\n        \n        if rho_old == 0: # Should not happen if everything is correct\n            return k + 1\n\n        beta = rho_new / rho_old\n        p = z + beta * p\n        rho_old = rho_new\n        \n    return max_iter\n\ndef solve():\n    test_cases = [\n        (1, 'row'),\n        (8, 'row'),\n        (8, 'col'),\n        (32, 'row'),\n    ]\n    \n    results = []\n    for n, orientation in test_cases:\n        k_none = run_cg(n, ('none', None))\n        k_pt = run_cg(n, ('point', None))\n        k_blk = run_cg(n, ('block', orientation))\n        \n        # Handle division by zero if k_blk is 0\n        ratio = float(k_none) / k_blk if k_blk != 0 else float('inf')\n        \n        results.append(f\"[{k_none},{k_pt},{k_blk},{ratio}]\")\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2427470"}]}