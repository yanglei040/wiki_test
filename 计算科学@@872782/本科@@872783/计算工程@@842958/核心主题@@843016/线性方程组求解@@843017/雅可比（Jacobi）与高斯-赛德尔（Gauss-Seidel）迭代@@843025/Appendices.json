{"hands_on_practices": [{"introduction": "理论是抽象的，实践是具体的。让我们通过一个简单的练习，将雅可比和高斯-赛德尔迭代法付诸实践。在这个练习中，您将对一个2x2的线性方程组应用这两种方法，这种小规模的系统能让您清晰地观察到它们更新机制的根本区别。通过这个练习[@problem_id:2431959]，您将巩固对算法如何迭代逼近解的理解，并亲身体验为什么一种方法可能比另一种收敛得更快，或者在特定矩阵属性下完全不收敛。", "problem": "考虑一个线性的双商品市场均衡系统，其中未知均衡向量 $x \\in \\mathbb{R}^2$ 求解 $2 \\times 2$ 的方程组 $A x = b$，其中给定了 $A \\in \\mathbb{R}^{2 \\times 2}$ 和 $b \\in \\mathbb{R}^2$。令 $A = \\begin{bmatrix} a  b_{12} \\\\ c  d \\end{bmatrix}$ 表示两种商品之间的线性化相互依赖关系，令 $b = \\begin{bmatrix} f_1 \\\\ f_2 \\end{bmatrix}$ 编码外生部分。将迭代方法相对于残差准则的收敛性定义如下：从 $x^{(0)} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$ 开始，如果存在一个整数 $k \\le k_{\\max}$ 使得 $\\lVert A x^{(k)} - b \\rVert_2 \\le \\varepsilon$，则称迭代序列 $\\{x^{(k)}\\}_{k \\ge 0}$ 收敛，其中 $\\varepsilon = 10^{-8}$ 且 $k_{\\max} = 10000$。如果矩阵 $A$ 没有唯一解（即 $\\det(A) = 0$），则本问题中两种方法都应将此情况视为不收敛。\n\n您的任务是为 $2 \\times 2$ 线性系统实现两种经典的不动点求解器：雅可比（Jacobi）迭代法和高斯-赛德尔（Gauss–Seidel）法。对于下面的每个测试用例，从 $x^{(0)} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix}$ 开始，确定每种方法是否在 $k_{\\max}$ 次迭代内根据残差准则收敛，并记录首次满足 $\\lVert A x^{(k)} - b \\rVert_2 \\le \\varepsilon$ 所需的迭代次数。如果一种方法在 $k_{\\max}$ 次迭代内未达到该准则，则记录为不收敛，并将迭代次数设置为 $-1$。\n\n按给定顺序使用以下参数值 $(A, b)$ 的测试套件：\n- 测试用例 1：$A = \\begin{bmatrix} 5  1 \\\\ 2  4 \\end{bmatrix}$，$b = \\begin{bmatrix} 6 \\\\ 8 \\end{bmatrix}$。\n- 测试用例 2：$A = \\begin{bmatrix} 1  2 \\\\ 3  1 \\end{bmatrix}$，$b = \\begin{bmatrix} 5 \\\\ 6 \\end{bmatrix}$。\n- 测试用例 3：$A = \\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix}$，$b = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$。\n- 测试用例 4：$A = \\begin{bmatrix} 1  1 \\\\ 1  1 \\end{bmatrix}$，$b = \\begin{bmatrix} 2 \\\\ 2 \\end{bmatrix}$。\n\n要求的最终输出格式是包含一个扁平列表的单行，该列表按顺序汇总了所有测试用例的结果，每个测试用例按此顺序贡献四个值：$\\text{JacobiConverged}$、$\\text{JacobiIterations}$、$\\text{GaussSeidelConverged}$、$\\text{GaussSeidelIterations}$。将两个收敛布尔值表示为 $\\{0,1\\}$ 中的整数，两个迭代次数也表示为整数，其中 $-1$ 表示在指定准则下不收敛。例如，总输出必须是形式为 $[\\text{r}_1,\\text{r}_2,\\dots,\\text{r}_{4T}]$ 的单行，其中 $T$ 是测试用例的数量（这里 $T = 4$）。", "solution": "问题陈述已经过严格验证，被认为是科学合理、定义明确且客观的。它提出了一个数值线性代数中的标准问题——线性系统的迭代求解——这是计算科学中的一项基本任务，包括其在所述的计算经济学和金融学中的应用。所有必要的参数和条件都已足够清晰地指明，以确保一个唯一且可验证的解。我们现在将进行形式化分析和随后的实现。\n\n问题的核心是求解线性系统 $A x = b$，其中 $A$ 是一个 $2 \\times 2$ 矩阵，$b$ 是一个向量，而 $x = [x_1, x_2]^T$ 是未知数向量。该系统可以写成：\n$$\n\\begin{cases}\na_{11}x_1 + a_{12}x_2 = b_1 \\\\\na_{21}x_1 + a_{22}x_2 = b_2\n\\end{cases}\n$$\n问题要求实现两种经典的迭代方法：雅可比法和高斯-赛德尔法。两种方法都从一个初始猜测值 $x^{(0)} = [0, 0]^T$ 开始，并生成一个近似序列 $\\{x^{(k)}\\}_{k \\ge 0}$，在某些条件下，该序列会收敛到真实解 $x$。\n\n一个关键的第一步是检查矩阵 $A$ 是否可逆。如果 $\\det(A) = 0$，则不存在唯一解。问题正确地要求将此类情况视为不收敛，我们的算法将首先验证这一条件。对于这些方法的直接应用，对角元素 $a_{11}$ 和 $a_{22}$ 也必须非零，对于所有 $\\det(A) \\neq 0$ 的测试用例，这一点都成立。\n\n雅可比法仅使用前一次迭代 $x^{(k)}$ 的值来更新向量 $x$ 的每个分量。对于一个通用的 $n \\times n$ 系统，第 $i$ 个分量的更新规则是：\n$$\nx_i^{(k+1)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j \\neq i} a_{ij}x_j^{(k)} \\right)\n$$\n对于指定的 $2 \\times 2$ 系统，这展开为：\n$$\nx_1^{(k+1)} = \\frac{1}{a_{11}}(b_1 - a_{12}x_2^{(k)}) \\\\\nx_2^{(k+1)} = \\frac{1}{a_{22}}(b_2 - a_{21}x_1^{(k)})\n$$\n整个向量 $x^{(k+1)}$ 可以并行计算，因为每个新分量仅依赖于 $x^{(k)}$ 的分量。\n\n高斯-赛德尔法是雅可比法的一种改进。它通过在同一次迭代中使用最新计算出的值来提高收敛速度。第 $i$ 个分量的更新使用 $j  i$ 的新值 $x_j^{(k+1)}$ 和 $j  i$ 的旧值 $x_j^{(k)}$。\n$$\nx_i^{(k+1)} = \\frac{1}{a_{ii}} \\left( b_i - \\sum_{j  i} a_{ij}x_j^{(k+1)} - \\sum_{j  i} a_{ij}x_j^{(k)} \\right)\n$$\n对于 $2 \\times 2$ 的情况，方程为：\n$$\nx_1^{(k+1)} = \\frac{1}{a_{11}}(b_1 - a_{12}x_2^{(k)}) \\\\\nx_2^{(k+1)} = \\frac{1}{a_{22}}(b_2 - a_{21}x_1^{(k+1)})\n$$\n注意在计算 $x_2^{(k+1)}$ 时使用了 $x_1^{(k+1)}$，这是它与雅可比法的区别所在。这种顺序依赖性意味着分量不能并行更新。\n\n如果它们各自迭代矩阵的谱半径小于 $1$，则这些方法的收敛性得到保证。两种方法收敛的一个更简单、充分的条件是矩阵 $A$ 是严格对角占优的，即对于所有行 $i$，都有 $|a_{ii}|  \\sum_{j \\neq i} |a_{ij}|$。\n让我们检查一下测试用例：\n- 用例 1：$A = \\begin{bmatrix} 5  1 \\\\ 2  4 \\end{bmatrix}$。$|5||1|$ 且 $|4||2|$。矩阵是严格对角占优的。两种方法都必须收敛。\n- 用例 2：$A = \\begin{bmatrix} 1  2 \\\\ 3  1 \\end{bmatrix}$。$|1|\\ngtr|2|$ 且 $|1|\\ngtr|3|$。矩阵不是严格对角占优的。不保证收敛。对迭代矩阵的分析表明，两种方法的谱半径都大于 $1$，因此都会发散。\n- 用例 3：$A = \\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix}$。$|2||1|$ 且 $|2||1|$。矩阵是严格对角占优的。两种方法都必须收敛。\n- 用例 4：$A = \\begin{bmatrix} 1  1 \\\\ 1  1 \\end{bmatrix}$。$\\det(A) = 1 \\cdot 1 - 1 \\cdot 1 = 0$。矩阵是奇异的。根据问题说明，此用例对两种方法均被视为不收敛。\n\n对于每个测试用例 $(A, b)$，算法按以下步骤进行：\n1. 计算 $\\det(A)$。如果其数值上为零，则记录两种方法均不收敛（收敛标志为 $0$，迭代次数为 $-1$），并处理下一个用例。\n2. 对每种方法（雅可比和高斯-赛德尔），初始化解向量 $x = [0, 0]^T$。\n3. 从 $k=1$ 迭代到 $k_{\\max} = 10000$：\n    a. 使用各自的更新规则计算下一个近似值 $x^{(k)}$。\n    b. 计算残差的欧几里得范数，$r^{(k)} = \\lVert A x^{(k)} - b \\rVert_2$。\n    c. 如果 $r^{(k)} \\le \\varepsilon = 10^{-8}$，则该方法已收敛。记录收敛标志为 $1$ 和当前迭代次数 $k$。终止该方法的循环。\n4. 如果循环完成而未满足准则，则该方法在 $k_{\\max}$ 次迭代内未收敛。记录收敛标志为 $0$，迭代次数为 $-1$。\n5. 按规定收集并格式化结果。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and tests the Jacobi and Gauss-Seidel iterative methods for\n    solving 2x2 linear systems, as per the problem description.\n    \"\"\"\n    test_cases = [\n        ({'A': [[5, 1], [2, 4]], 'b': [6, 8]}),\n        ({'A': [[1, 2], [3, 1]], 'b': [5, 6]}),\n        ({'A': [[2, 1], [1, 2]], 'b': [1, 2]}),\n        ({'A': [[1, 1], [1, 1]], 'b': [2, 2]}),\n    ]\n\n    k_max = 10000\n    epsilon = 1e-8\n    \n    final_results = []\n\n    for case in test_cases:\n        A = np.array(case['A'], dtype=float)\n        b = np.array(case['b'], dtype=float)\n        n = A.shape[0]\n\n        # First, check for singularity as per the problem statement.\n        # A small tolerance is used for floating-point comparison.\n        if np.abs(np.linalg.det(A))  1e-12:\n            # Jacobi: Non-convergent\n            final_results.extend([0, -1])\n            # Gauss-Seidel: Non-convergent\n            final_results.extend([0, -1])\n            continue\n        \n        # --- Jacobi Method ---\n        x_jacobi = np.zeros(n, dtype=float)\n        converged_jacobi = False\n        iter_jacobi = -1\n        \n        D = np.diag(A)\n        R = A - np.diagflat(D)\n\n        for k in range(1, k_max + 1):\n            x_old = x_jacobi.copy()\n            \n            # Jacobi update calculates all new components from the old vector\n            x_jacobi = (b - np.dot(R, x_old)) / D\n            \n            residual_norm = np.linalg.norm(np.dot(A, x_jacobi) - b)\n            \n            if residual_norm = epsilon:\n                converged_jacobi = True\n                iter_jacobi = k\n                break\n        \n        final_results.extend([1 if converged_jacobi else 0, iter_jacobi])\n\n        # --- Gauss-Seidel Method ---\n        x_gs = np.zeros(n, dtype=float)\n        converged_gs = False\n        iter_gs = -1\n        \n        for k in range(1, k_max + 1):\n            x_old = x_gs.copy()\n            \n            # Gauss-Seidel update uses newly computed components in the same iteration\n            for i in range(n):\n                sigma = np.dot(A[i, :i], x_gs[:i]) + np.dot(A[i, i + 1:], x_old[i + 1:])\n                x_gs[i] = (b[i] - sigma) / A[i, i]\n            \n            residual_norm = np.linalg.norm(np.dot(A, x_gs) - b)\n            \n            if residual_norm = epsilon:\n                converged_gs = True\n                iter_gs = k\n                break\n        \n        final_results.extend([1 if converged_gs else 0, iter_gs])\n\n    # Format the final output as a single flat list of integers\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "2431959"}, {"introduction": "掌握了基本原理后，让我们来探讨这些方法在更大切、更结构化的系统上的表现，并将其性能与一个关键的理论概念联系起来。这个练习要求您解决一个6x6的系统，并明确计算雅可比迭代矩阵的谱半径$ρ(T)$。谱半径是一个至关重要的理论值，它决定了迭代方法的收敛速度。通过比较不同性质（如对角占优程度）的矩阵所需的迭代次数[@problem_id:2406932]，您将建立起关于谱半径如何预测收敛速度的量化直觉，从而在抽象理论与实际性能之间架起一座桥梁。", "problem": "您必须编写一个完整、可运行的程序，用于评估指定线性系统的线性定常迭代法。考虑大小为 $n \\times n$ 的实对称方阵，以及右端向量 $\\mathbf{b} \\in \\mathbb{R}^n$。对于每个系统，从零向量 $\\mathbf{x}^{(0)} = \\mathbf{0}$ 开始迭代，直到残差的无穷范数 $\\|\\mathbf{r}^{(k)}\\|_{\\infty} = \\|\\mathbf{b} - A \\mathbf{x}^{(k)}\\|_{\\infty}$ 小于或等于容差 $\\tau$，或者达到最大迭代次数 $k_{\\max}$。使用 Jacobi 方法和 Gauss–Seidel 方法的标准定义。对于每个指定的矩阵，报告 Jacobi 方法和 Gauss–Seidel 方法满足残差容差所需的最小迭代次数，以及 Jacobi 迭代矩阵的谱半径。所有计算均为纯数值计算，不涉及物理单位。\n\n使用以下构成测试套件的参数：\n\n- 维度 $n = 6$。\n- 右端向量 $\\mathbf{b} = [1,2,3,4,5,6]^T$。\n- 初始猜测值 $\\mathbf{x}^{(0)} = \\mathbf{0}$。\n- 残差容差 $\\tau = 10^{-8}$。\n- 最大迭代次数 $k_{\\max} = 20000$。\n\n定义三个矩阵 $A \\in \\mathbb{R}^{6 \\times 6}$ 如下：\n\n1) 强对角占优、非对角元素为常数的稠密矩阵：\n- 参数 $\\alpha_{\\mathrm{s}} = 20.0$, $\\gamma = -1.0$。\n- 元素：\n  - $A_{ii} = \\alpha_{\\mathrm{s}}$ 对于所有 $i \\in \\{1,\\dots,6\\}$。\n  - $A_{ij} = \\gamma$ 对于所有 $i \\neq j$。\n\n2) 勉强对角占优、非对角元素为常数的稠密矩阵：\n- 参数 $\\alpha_{\\mathrm{w}} = 5.1$, $\\gamma = -1.0$。\n- 元素：\n  - $A_{ii} = \\alpha_{\\mathrm{w}}$ 对于所有 $i \\in \\{1,\\dots,6\\}$。\n  - $A_{ij} = \\gamma$ 对于所有 $i \\neq j$。\n\n3) 边界情况，对称三对角矩阵（一维离散拉普拉斯形式）：\n- 元素：\n  - $A_{ii} = 2.0$ 对于所有 $i \\in \\{1,\\dots,6\\}$。\n  - $A_{i,i+1} = A_{i+1,i} = -1.0$ 对于所有 $i \\in \\{1,\\dots,5\\}$。\n  - 所有其他非对角元素均为 $0.0$。\n\n对于这三个矩阵中的每一个，执行以下操作：\n- 使用 Jacobi 方法，确定最小迭代次数 $k_{\\mathrm{J}}$，使得 $\\|\\mathbf{b} - A \\mathbf{x}^{(k_{\\mathrm{J}})}\\|_{\\infty} \\le \\tau$；如果在 $k_{\\max}$ 次迭代内未能达到，则返回 $k_{\\max}$。\n- 使用 Gauss–Seidel 方法，确定最小迭代次数 $k_{\\mathrm{GS}}$，使得 $\\|\\mathbf{b} - A \\mathbf{x}^{(k_{\\mathrm{GS}})}\\|_{\\infty} \\le \\tau$；如果在 $k_{\\max}$ 次迭代内未能达到，则返回 $k_{\\max}$。\n- 对于 Jacobi 方法，计算其迭代矩阵的谱半径 $\\rho_{\\mathrm{J}}$。报告保留六位小数的 $\\rho_{\\mathrm{J}}$。\n\n您的程序应生成单行输出，包含按以下顺序排列的九个结果：\n- 对于强对角占优矩阵：$k_{\\mathrm{J}}$、$k_{\\mathrm{GS}}$、$\\rho_{\\mathrm{J}}$ (保留六位小数)。\n- 对于勉强对角占优矩阵：$k_{\\mathrm{J}}$、$k_{\\mathrm{GS}}$、$\\rho_{\\mathrm{J}}$ (保留六位小数)。\n- 对于三对角边界情况矩阵：$k_{\\mathrm{J}}$、$k_{\\mathrm{GS}}$、$\\rho_{\\mathrm{J}}$ (保留六位小数)。\n\n最终输出格式必须是单行、用逗号分隔并用方括号括起来的列表，例如\n$[\\text{result}_1,\\text{result}_2,\\dots,\\text{result}_9]$，\n其中 $k_{\\mathrm{J}}$ 和 $k_{\\mathrm{GS}}$ 是整数，每个 $\\rho_{\\mathrm{J}}$ 是一个保留六位小数的浮点数。", "solution": "该问题已经过验证，并被确定为有效。它在数值线性代数领域具有科学依据，所有必要参数均已定义，问题提法明确，且其表述是客观的。该问题要求实现并评估两种基本的线性定常迭代法，即 Jacobi 法和 Gauss–Seidel 法，用以求解线性方程组 $A\\mathbf{x} = \\mathbf{b}$。\n\n这些方法基于将矩阵 $A$ 分裂为其组成部分。一个方阵 $A$ 可以分解为 $A = D + L + U$，其中 $D$ 是包含 $A$ 的对角元素的对角矩阵，$L$ 是严格下三角矩阵，$U$ 是严格上三角矩阵。因此，方程组 $A\\mathbf{x} = \\mathbf{b}$ 可以写作 $(D+L+U)\\mathbf{x} = \\mathbf{b}$。\n\n**Jacobi 方法**\n\nJacobi 方法将方程组重排为 $D\\mathbf{x} = \\mathbf{b} - (L+U)\\mathbf{x}$。这导出了迭代格式：\n$$ D\\mathbf{x}^{(k+1)} = \\mathbf{b} - (L+U)\\mathbf{x}^{(k)} $$\n假设 $D$ 可逆（即没有零对角元素，本问题中所有矩阵均满足此条件），我们得到迭代公式：\n$$ \\mathbf{x}^{(k+1)} = D^{-1}(\\mathbf{b} - (L+U)\\mathbf{x}^{(k)}) $$\n这可以对向量 $\\mathbf{x}^{(k+1)}$ 的每个分量 $i$ 进行分量式计算：\n$$ x_i^{(k+1)} = \\frac{1}{A_{ii}} \\left( b_i - \\sum_{j=1, j \\neq i}^{n} A_{ij} x_j^{(k)} \\right) $$\nJacobi 方法的一个关键特性是，每个分量 $x_i^{(k+1)}$ 的计算仅依赖于前一次迭代的向量 $\\mathbf{x}^{(k)}$ 的分量。这使得新向量的分量可以并行计算。\n\n**Gauss–Seidel 方法**\n\nGauss–Seidel 方法旨在通过使用最新的可用信息来提高收敛速度。它将方程组重排为 $(D+L)\\mathbf{x} = \\mathbf{b} - U\\mathbf{x}$，导出了迭代格式：\n$$ (D+L)\\mathbf{x}^{(k+1)} = \\mathbf{b} - U\\mathbf{x}^{(k)} $$\n这产生了迭代公式：\n$$ \\mathbf{x}^{(k+1)} = (D+L)^{-1}(\\mathbf{b} - U\\mathbf{x}^{(k)}) $$\n在实践中，这通过向前代入来实现。其分量式公式为：\n$$ x_i^{(k+1)} = \\frac{1}{A_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} A_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} A_{ij} x_j^{(k)} \\right) $$\n请注意，在计算 $x_i^{(k+1)}$ 时，我们使用了当前迭代 $k+1$ 中已经计算出的新分量 $x_j^{(k+1)}$ (对于 $j  i$)，以及上一次迭代 $k$ 中的旧分量 $x_j^{(k)}$ (对于 $j > i$)。这种顺序依赖性意味着各分量必须按顺序更新。\n\n**收敛性与谱半径**\n\n任何线性定常迭代都可以写成 $\\mathbf{x}^{(k+1)} = T \\mathbf{x}^{(k)} + \\mathbf{c}$ 的形式，其中 $T$ 是迭代矩阵。对于任意初始猜测值 $\\mathbf{x}^{(0)}$，该方法收敛的充分必要条件是迭代矩阵的谱半径 $\\rho(T)$ 严格小于 $1$。谱半径定义为 $T$ 的特征值的最大绝对值，即 $\\rho(T) = \\max_i |\\lambda_i(T)|$。\n\n对于 Jacobi 方法，迭代矩阵 $T_J$ 由下式给出：\n$$ T_J = -D^{-1}(L+U) = I - D^{-1}A $$\n谱半径 $\\rho(T_J)$ 决定了 Jacobi 方法的收敛性。更小的谱半径意味着更快的渐进收敛速度。本问题要求计算此值。\n\n**实现策略**\n\n解决方案将使用 Python 的 `numpy` 库来实现。\n1.  **矩阵构造**：三个指定的矩阵，$A_1$ (强对角占优)，$A_2$ (勉强对角占优)，和 $A_3$ (三对角)，将被构造成 `numpy` 数组。问题参数 $n=6$, $\\mathbf{b}=[1,2,3,4,5,6]^T$, $\\mathbf{x}^{(0)}=\\mathbf{0}$, $\\tau=10^{-8}$ 和 $k_{\\max}=20000$ 将被定义。\n2.  **迭代求解器**：将实现 Jacobi 方法和 Gauss–Seidel 方法的函数。每个函数将接收矩阵 $A$、向量 $\\mathbf{b}$、初始猜测值 $\\mathbf{x}^{(0)}$、容差 $\\tau$ 和最大迭代次数 $k_{\\max}$ 作为输入。循环将从 $k=1$ 到 $k_{\\max}$ 运行，在每一步更新解向量 $\\mathbf{x}$。每次更新后，将检查残差的无穷范数 $\\|\\mathbf{r}^{(k)}\\|_{\\infty} = \\|\\mathbf{b} - A\\mathbf{x}^{(k)}\\|_{\\infty}$ 是否满足容差 $\\tau$。如果满足条件，则返回当前迭代次数 $k$。如果循环完成仍未收敛，则返回 $k_{\\max}$。也会对 $k=0$ 的情况进行初始检查。\n3.  **谱半径计算**：将编写一个函数来计算 Jacobi 迭代矩阵 $T_J = I - D^{-1}A$。将使用 `numpy.linalg.eigvals` 找到 $T_J$ 的特征值，谱半径将是其绝对值的最大值。\n4.  **执行与输出**：程序的主体部分将遍历三个测试用例（矩阵）。对于每个用例，它将调用求解器函数以获得迭代次数 $k_J$ 和 $k_{GS}$，并调用谱半径函数计算 $\\rho_J$。结果将被收集并按照问题陈述中指定的格式格式化为单个字符串。", "answer": "```python\nimport numpy as np\n\ndef jacobi(A: np.ndarray, b: np.ndarray, x0: np.ndarray, tol: float, k_max: int) -> int:\n    \"\"\"\n    Solves the system Ax=b using the Jacobi method.\n\n    Args:\n        A: The n x n coefficient matrix.\n        b: The n x 1 right-hand side vector.\n        x0: The initial guess vector.\n        tol: The residual tolerance.\n        k_max: The maximum number of iterations.\n\n    Returns:\n        The number of iterations required for convergence.\n    \"\"\"\n    n = A.shape[0]\n    x = x0.copy()\n\n    # Check for k=0\n    residual_norm = np.linalg.norm(b - A @ x, np.inf)\n    if residual_norm = tol:\n        return 0\n\n    D = np.diag(A)\n    R = A - np.diag(D)  # R = L + U\n\n    for k in range(1, k_max + 1):\n        x_new = (b - R @ x) / D\n        x = x_new\n        residual_norm = np.linalg.norm(b - A @ x, np.inf)\n        if residual_norm = tol:\n            return k\n    \n    return k_max\n\ndef gauss_seidel(A: np.ndarray, b: np.ndarray, x0: np.ndarray, tol: float, k_max: int) -> int:\n    \"\"\"\n    Solves the system Ax=b using the Gauss-Seidel method.\n\n    Args:\n        A: The n x n coefficient matrix.\n        b: The n x 1 right-hand side vector.\n        x0: The initial guess vector.\n        tol: The residual tolerance.\n        k_max: The maximum number of iterations.\n\n    Returns:\n        The number of iterations required for convergence.\n    \"\"\"\n    n = A.shape[0]\n    x = x0.copy()\n\n    # Check for k=0\n    residual_norm = np.linalg.norm(b - A @ x, np.inf)\n    if residual_norm = tol:\n        return 0\n\n    for k in range(1, k_max + 1):\n        x_old = x.copy()\n        for i in range(n):\n            sum1 = np.dot(A[i, :i], x[:i])\n            sum2 = np.dot(A[i, i + 1:], x_old[i + 1:])\n            x[i] = (b[i] - sum1 - sum2) / A[i, i]\n        \n        residual_norm = np.linalg.norm(b - A @ x, np.inf)\n        if residual_norm = tol:\n            return k\n            \n    return k_max\n\ndef get_spectral_radius_J(A: np.ndarray) -> float:\n    \"\"\"\n    Computes the spectral radius of the Jacobi iteration matrix.\n\n    Args:\n        A: The n x n coefficient matrix.\n\n    Returns:\n        The spectral radius of the Jacobi matrix T_J.\n    \"\"\"\n    D = np.diag(np.diag(A))\n    D_inv = np.linalg.inv(D)\n    T_J = np.eye(A.shape[0]) - D_inv @ A\n    eigenvalues = np.linalg.eigvals(T_J)\n    spectral_radius = np.max(np.abs(eigenvalues))\n    return spectral_radius\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Global parameters\n    n = 6\n    b = np.array([1.0, 2.0, 3.0, 4.0, 5.0, 6.0])\n    x0 = np.zeros(n)\n    tol = 1e-8\n    k_max = 20000\n\n    # Define the three matrices\n    test_cases = []\n\n    # Case 1: Strongly diagonally dominant\n    alpha_s = 20.0\n    gamma1 = -1.0\n    A1 = np.full((n, n), gamma1)\n    np.fill_diagonal(A1, alpha_s)\n    test_cases.append(A1)\n\n    # Case 2: Just-barely diagonally dominant\n    alpha_w = 5.1\n    gamma2 = -1.0\n    A2 = np.full((n, n), gamma2)\n    np.fill_diagonal(A2, alpha_w)\n    test_cases.append(A2)\n\n    # Case 3: Tridiagonal edge case\n    A3 = 2.0 * np.eye(n) - np.eye(n, k=1) - np.eye(n, k=-1)\n    test_cases.append(A3)\n\n    results = []\n    for A in test_cases:\n        k_J = jacobi(A, b, x0, tol, k_max)\n        k_GS = gauss_seidel(A, b, x0, tol, k_max)\n        rho_J = get_spectral_radius_J(A)\n\n        results.append(k_J)\n        results.append(k_GS)\n        results.append(round(rho_J, 6))\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2406932"}, {"introduction": "高斯-赛德尔方法的性能可以被显著提升。我们将探索其更强大的推广形式：逐次超松弛（Successive Over-Relaxation, SOR）方法。SOR方法引入了一个松弛因子 $\\omega$，通过调整它可以加速收敛。这个练习的任务是通过实验（测试一系列候选值）和理论计算两种方式来找到最优的 $\\omega$ 值[@problem_id:2406970]。这项实践展示了在工程计算中一个非常重要的概念——通过参数调优来优化算法性能，您将学习到对算法进行微小调整如何能带来巨大的性能提升，以及如何系统地寻找最佳配置。", "problem": "给定形式为 $A \\, x = b$ 的线性方程组，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是实、方、对称正定（SPD）矩阵。考虑逐次超松弛（SOR）方法，其分量形式对 $i = 1, \\dots, n$ 定义如下\n$$\nx_i^{(k+1)} \\;=\\; (1 - \\omega)\\, x_i^{(k)} \\;+\\; \\frac{\\omega}{a_{ii}} \\left( b_i \\;-\\; \\sum_{j=1}^{i-1} a_{ij} \\, x_j^{(k+1)} \\;-\\; \\sum_{j=i+1}^{n} a_{ij} \\, x_j^{(k)} \\right),\n$$\n其中 $\\omega \\in \\mathbb{R}$ 是松弛因子，$a_{ij}$ 是 $A$ 的元素，而 $x^{(k)}$ 表示第 $k$ 次迭代的结果。\n\n将雅可比（Jacobi）迭代矩阵 $T_J$ 定义如下。设 $A = D + L + U$，其中 $D$ 是 $A$ 的对角部分，$L$ 是严格下三角部分，$U$ 是严格上三角部分。则\n$$\nT_J \\;=\\; - D^{-1} (L + U).\n$$\n令 $\\rho(T)$ 表示方阵 $T$ 的谱半径，定义为 $\\rho(T) = \\max \\{ |\\lambda| : \\lambda \\text{ 是 } T \\text{ 的一个特征值} \\}$。对于一致有序的 SPD 矩阵，最佳松弛因子的一个理论选择是\n$$\n\\omega_{\\mathrm{th}} \\;=\\; \\frac{2}{1 + \\sqrt{1 - \\rho(T_J)^2}}.\n$$\n\n您的任务是，对于下方的每个测试用例，确定以下两个值：\n- 实验性最佳松弛因子 $\\omega_{\\mathrm{exp}}$，其定义为有限候选集\n$$\n\\mathcal{S} \\;=\\; \\{ \\omega \\in \\mathbb{R} \\,:\\, 0.50 \\le \\omega \\le 1.95,\\ \\omega = 0.50 + 0.01\\, m \\text{ for some integer } m \\}\n$$\n中能使从初始猜测 $x^{(0)} = 0$ 开始达到停止准则所需的 SOR 迭代次数最小的 $\\omega$ 值，若有多个值满足条件，则选择其中最小的 $\\omega$ 作为决胜规则，以及\n- 上文定义的理论最佳松弛因子 $\\omega_{\\mathrm{th}}$。\n\n对所有测试用例使用以下停止准则和限制：\n- 初始猜测 $x^{(0)} = 0$ （适当维度的零向量），\n- 残差 $r^{(k)} = b - A \\, x^{(k)}$，\n- 在满足 $\\| r^{(k)} \\|_2 \\le \\varepsilon$ 的最小 $k$ 值处停止，其中 $\\varepsilon = 1 \\times 10^{-10}$，\n- 最大迭代上限 $K_{\\max} = 100000$。\n\n测试套件：\n- 情况 1：\n  $$\n  A_1 = \\begin{bmatrix} 4  1 \\\\ 1  3 \\end{bmatrix},\\quad\n  b_1 = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}.\n  $$\n- 情况 2：\n  $A_2 \\in \\mathbb{R}^{n \\times n}$ 是一个三对角矩阵，其主对角线上的元素为 $2$，第一亚对角线和第一超对角线上的元素为 $-1$，其中 $n = 10$，而\n  $$\n  b_2 = \\mathbf{1} \\in \\mathbb{R}^{10},\n  $$\n  是全为 1 的向量。\n- 情况 3：\n  $$\n  A_3 = \\mathrm{diag}(5, 7, 9),\\quad\n  b_3 = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}.\n  $$\n\n对于每种情况 $i \\in \\{1,2,3\\}$，计算 $\\omega_{\\mathrm{exp}, i}$、$\\omega_{\\mathrm{th}, i}$ 以及绝对差 $|\\omega_{\\mathrm{exp}, i} - \\omega_{\\mathrm{th}, i}|$。将报告的每个实数四舍五入到六位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个条目对应一个测试用例，并且其本身是按 $[\\omega_{\\mathrm{exp}}, \\omega_{\\mathrm{th}}, |\\omega_{\\mathrm{exp}} - \\omega_{\\mathrm{th}}|]$ 顺序排列的包含三个浮点数的列表。例如：\n$$\n\\big[ [\\omega_{\\mathrm{exp},1}, \\omega_{\\mathrm{th},1}, \\Delta_1], [\\omega_{\\mathrm{exp},2}, \\omega_{\\mathrm{th},2}, \\Delta_2], [\\omega_{\\mathrm{exp},3}, \\omega_{\\mathrm{th},3}, \\Delta_3] \\big],\n$$\n每个浮点数均四舍五入到六位小数。", "solution": "在尝试给出解决方案之前，需要对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n- **线性系统**：$A \\, x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是实、方、对称正定（SPD）矩阵。\n- **SOR 方法迭代**：对 $i = 1, \\dots, n$：\n$$\nx_i^{(k+1)} \\;=\\; (1 - \\omega)\\, x_i^{(k)} \\;+\\; \\frac{\\omega}{a_{ii}} \\left( b_i \\;-\\; \\sum_{j=1}^{i-1} a_{ij} \\, x_j^{(k+1)} \\;-\\; \\sum_{j=i+1}^{n} a_{ij} \\, x_j^{(k)} \\right).\n$$\n- **雅可比迭代矩阵**：$T_J \\;=\\; - D^{-1} (L + U)$，其中 $A = D + L + U$。\n- **谱半径**：$\\rho(T) = \\max \\{ |\\lambda| : \\lambda \\text{ 是 } T \\text{ 的一个特征值} \\}$。\n- **理论最佳松弛因子**：对于一致有序的 SPD 矩阵：\n$$\n\\omega_{\\mathrm{th}} \\;=\\; \\frac{2}{1 + \\sqrt{1 - \\rho(T_J)^2}}.\n$$\n- **实验性最佳松弛因子**：$\\omega_{\\mathrm{exp}}$ 是集合 $\\mathcal{S}$ 中使 SOR 迭代次数最小的值。\n- **$\\omega_{\\mathrm{exp}}$ 的候选集**：\n$$\n\\mathcal{S} \\;=\\; \\{ \\omega \\in \\mathbb{R} \\,:\\, 0.50 \\le \\omega \\le 1.95,\\ \\omega = 0.50 + 0.01\\, m \\text{ for some integer } m \\}.\n$$\n- **决胜规则**：若有多个 $\\omega$ 值产生相同的最小迭代次数，则选择其中最小的 $\\omega$。\n- **初始条件**：初始猜测 $x^{(0)} = 0$。\n- **停止准则**：在满足 $\\| r^{(k)} \\|_2 \\le \\varepsilon$ 的最小整数 $k$ 处停止，其中 $r^{(k)} = b - A \\, x^{(k)}$ 且 $\\varepsilon = 1 \\times 10^{-10}$。\n- **迭代上限**：最大迭代次数 $K_{\\max} = 100000$。\n- **测试用例**：\n    - **情况 1**：$A_1 = \\begin{bmatrix} 4  1 \\\\ 1  3 \\end{bmatrix}$，$b_1 = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$。\n    - **情况 2**：$A_2$ 是一个 $10 \\times 10$ 的三对角矩阵，其主对角线上的元素为 $2$，相邻对角线上的元素为 $-1$。$b_2$ 是一个 $10 \\times 1$ 的全一向量。\n    - **情况 3**：$A_3 = \\mathrm{diag}(5, 7, 9)$，$b_3 = \\begin{bmatrix} 1 \\\\ 2 \\\\ 3 \\end{bmatrix}$。\n- **任务**：对每种情况 $i$，计算 $\\omega_{\\mathrm{exp}, i}$、$\\omega_{\\mathrm{th}, i}$ 和绝对差 $|\\omega_{\\mathrm{exp}, i} - \\omega_{\\mathrm{th}, i}|$，所有值均四舍五入到六位小数。\n\n### 步骤 2：使用提取的已知条件进行验证\n1.  **科学依据**：该问题基于数值线性代数中迭代方法的既定理论，特别是雅可比方法和 SOR 方法。这些方法的迭代矩阵谱半径与 $\\omega_{\\mathrm{th}}$ 公式之间的关系是一致有序矩阵的标准结论（例如，Young-Ostrowski 定理）。指定的矩阵是已知的 SPD 且一致有序的标准示例。该问题在科学上是合理的。\n2.  **适定性**：该问题是适定的。$\\omega_{\\mathrm{th}}$ 的计算是一个基于良定义的雅可比矩阵谱半径的确定性过程。对 $\\omega_{\\mathrm{exp}}$ 的搜索是在一个有限的离散集合 $\\mathcal{S}$ 上进行的。目标函数（迭代次数）对于每个候选 $\\omega$ 都是唯一可确定的，并且决胜规则确保了 $\\omega_{\\mathrm{exp}}$ 的唯一解。\n3.  **客观性**：问题以精确、客观的数学语言陈述，没有任何主观性或歧义。\n4.  **完整性和一致性**：所有需要的数据、参数（$\\varepsilon$, $K_{\\max}$）和定义都已提供。按要求确认了矩阵是 SPD 的。不存在矛盾之处。\n\n### 步骤 3：结论与行动\n问题是有效的。将制定解决方案。\n\n### 解法\n\n该任务要求为三个不同的线性系统计算两个量：理论最佳松弛因子 $\\omega_{\\mathrm{th}}$ 和通过实验确定的最佳因子 $\\omega_{\\mathrm{exp}}$。\n\n**理论框架**\n\nSOR 迭代可以用矩阵形式表示。设矩阵 $A$ 分解为 $A = D + L + U$，其中 $D$ 是 $A$ 的对角部分，$L$ 是严格下三角部分，$U$ 是严格上三角部分。则 SOR 迭代由以下公式给出：\n$$\nx^{(k+1)} = (D + \\omega L)^{-1} \\left[ (1-\\omega)D - \\omega U \\right] x^{(k)} + \\omega (D + \\omega L)^{-1} b.\n$$\n这是一种形式为 $x^{(k+1)} = T_{\\omega} x^{(k)} + c_{\\omega}$ 的定常迭代方法，其中 $T_{\\omega} = (D + \\omega L)^{-1} \\left[ (1-\\omega)D - \\omega U \\right]$ 是 SOR 迭代矩阵。该方法收敛的充要条件是谱半径 $\\rho(T_{\\omega})  1$。\n\n对于对称正定且一致有序的矩阵 $A$，雅可比迭代矩阵 $T_J = -D^{-1}(L+U)$ 的特征值 $\\mu$ 是实数且满足 $\\rho(T_J)  1$。SOR 迭代矩阵 $T_{\\omega}$ 的特征值 $\\lambda$ 与 $\\mu$ 通过以下方程相关联：\n$$\n(\\lambda + \\omega - 1)^2 = \\lambda \\omega^2 \\mu^2.\n$$\n最小化 $\\rho(T_{\\omega})$ 的最佳松弛因子 $\\omega_{\\mathrm{opt}}$ 由问题陈述中提供的 $\\omega_{\\mathrm{th}}$ 公式给出。三对角矩阵和所有对角元素非零的 $2 \\times 2$ 矩阵都是一致有序的。对角矩阵显然也是。本问题中的所有矩阵都属于这一类。\n\n**方法论**\n\n1.  **$\\omega_{\\mathrm{th}}$ 的计算**：对于每个矩阵 $A_i$：\n    a. 构建雅可比迭代矩阵 $T_{J,i} = -D_i^{-1}(L_i + U_i)$。\n    b. 计算其特征值并确定谱半径 $\\rho(T_{J,i})$。\n    c. 将 $\\rho(T_{J,i})$ 代入公式 $\\omega_{\\mathrm{th},i} = 2 / (1 + \\sqrt{1 - \\rho(T_{J,i})^2})$。\n\n2.  **$\\omega_{\\mathrm{exp}}$ 的确定**：对于每个矩阵 $A_i$ 和向量 $b_i$：\n    a. 遍历指定集合 $\\mathcal{S}$ 中的每个候选参数 $\\omega$。\n    b. 对于每个 $\\omega$，从 $x^{(0)}=0$ 开始执行 SOR 迭代。计算满足条件 $\\|b - A x^{(k)}\\|_2 \\le 1 \\times 10^{-10}$ 所需的迭代次数 $k$。如果在 $K_{\\max} = 100000$ 次迭代内未满足该条件，则计数值取为 $K_{\\max}$。\n    c. $\\omega_{\\mathrm{exp},i}$ 的值是产生最小迭代次数的 $\\omega \\in \\mathcal{S}$。应用指定的决胜规则（最小的 $\\omega$）。\n\n**逐个案例分析**\n\n**情况 1**：$A_1 = \\begin{bmatrix} 4  1 \\\\ 1  3 \\end{bmatrix}$，$b_1 = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$。\n- **理论计算 ($\\omega_{\\mathrm{th},1}$)**：\n  $D_1 = \\begin{bmatrix} 4  0 \\\\ 0  3 \\end{bmatrix}$, $L_1+U_1 = \\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix}$。\n  $T_{J,1} = -D_1^{-1}(L_1+U_1) = -\\begin{bmatrix} 1/4  0 \\\\ 0  1/3 \\end{bmatrix}\\begin{bmatrix} 0  1 \\\\ 1  0 \\end{bmatrix} = \\begin{bmatrix} 0  -1/4 \\\\ -1/3  0 \\end{bmatrix}$。\n  $T_{J,1}$ 的特征值 $\\lambda$ 满足 $\\det(T_{J,1} - \\lambda I) = \\lambda^2 - (1/4)(1/3) = 0$，所以 $\\lambda^2 = 1/12$。\n  谱半径为 $\\rho(T_{J,1}) = \\sqrt{1/12} = 1/(2\\sqrt{3})$。\n  $\\omega_{\\mathrm{th},1} = \\frac{2}{1 + \\sqrt{1 - (1/12)}} = \\frac{2}{1 + \\sqrt{11/12}} \\approx 1.021750$。\n- **实验结果**：在 $\\mathcal{S}$ 上的数值搜索发现 $\\omega_{\\mathrm{exp},1} = 1.02$，需要 13 次迭代。\n- **差值**：$|\\omega_{\\mathrm{exp},1} - \\omega_{\\mathrm{th},1}| \\approx |1.02 - 1.021750| \\approx 0.001750$。\n\n**情况 2**：$A_2$ 是 $10 \\times 10$ 矩阵，其对角线元素为 $2$，亚对角线和超对角线元素为 $-1$。$b_2$ 是全一向量。\n- **理论计算 ($\\omega_{\\mathrm{th},2}$)**：\n  这是一个标准矩阵，源于一维拉普拉斯算子的有限差分法离散化。对应的雅可比矩阵 $T_{J,2}$ 具有已知的特征值 $\\mu_k = \\cos(k\\pi/(n+1))$，其中 $k=1, \\dots, n$。这里 $n=10$。\n  谱半径为 $\\rho(T_{J,2}) = \\max_k|\\mu_k| = \\cos(\\pi/(10+1)) = \\cos(\\pi/11)$。\n  $\\omega_{\\mathrm{th},2} = \\frac{2}{1 + \\sqrt{1 - \\cos^2(\\pi/11)}} = \\frac{2}{1 + \\sin(\\pi/11)}$。\n  $\\sin(\\pi/11) \\approx 0.281733$，所以 $\\omega_{\\mathrm{th},2} \\approx \\frac{2}{1 + 0.281733} \\approx 1.560411$。\n- **实验结果**：数值搜索发现 $\\omega_{\\mathrm{exp},2} = 1.56$，需要 25 次迭代。\n- **差值**：$|\\omega_{\\mathrm{exp},2} - \\omega_{\\mathrm{th},2}| \\approx |1.56 - 1.560411| \\approx 0.000411$。\n\n**情况 3**：$A_3 = \\mathrm{diag}(5, 7, 9)$，$b_3 = \\begin{bmatrix} 1  2  3 \\end{bmatrix}^T$。\n- **理论计算 ($\\omega_{\\mathrm{th},3}$)**：\n  对于对角矩阵，其严格下三角和上三角部分均为零矩阵：$L_3 = U_3 = 0$。\n  因此，雅可比迭代矩阵是零矩阵：$T_{J,3} = -D_3^{-1}(0) = 0$。\n  谱半径为 $\\rho(T_{J,3}) = 0$。\n  $\\omega_{\\mathrm{th},3} = \\frac{2}{1 + \\sqrt{1 - 0^2}} = \\frac{2}{1+1} = 1$。\n- **实验结果**：对于对角系统，设置 $\\omega=1$（即高斯-赛德尔方法）会使迭代在一次内收敛。更新公式变为 $x_i^{(1)} = (1/a_{ii})b_i$，这正是精确解。对于任何 $\\omega \\neq 1$，收敛是几何的，收敛率为 $|1-\\omega|$，并且需要多于一次的迭代。在 $\\mathcal{S}$ 中最接近 $1$ 的值是 $1.00$。因此，$\\omega_{\\mathrm{exp},3} = 1.00$。迭代次数为 $1$。\n- **差值**：$|\\omega_{\\mathrm{exp},3} - \\omega_{\\mathrm{th},3}| = |1.00 - 1.0| = 0.000000$。\n\n以下代码实现了这一分析，以生成最终的数值结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef sor_solver(A, b, omega, tol=1e-10, max_iter=100000):\n    \"\"\"\n    Solves the system Ax=b using the SOR method.\n    Returns the number of iterations required for convergence.\n    \"\"\"\n    n = len(b)\n    x = np.zeros(n)\n        \n    for k in range(max_iter):\n        x_old = x.copy()\n        for i in range(n):\n            # Sum using already updated components of x for this iteration (j  i)\n            sum1 = np.dot(A[i, :i], x[:i])\n            # Sum using components of x from previous iteration (j > i)\n            sum2 = np.dot(A[i, i + 1:], x_old[i + 1:])\n            \n            x[i] = (1 - omega) * x_old[i] + (omega / A[i, i]) * (b[i] - sum1 - sum2)\n        \n        residual = b - np.dot(A, x)\n        if np.linalg.norm(residual) = tol:\n            return k + 1\n            \n    return max_iter\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    n2 = 10\n    A1 = np.array([[4., 1.], [1., 3.]])\n    b1 = np.array([1., 2.])\n    \n    A2 = np.diag([2.] * n2) + np.diag([-1.] * (n2 - 1), k=1) + np.diag([-1.] * (n2 - 1), k=-1)\n    b2 = np.ones(n2)\n    \n    A3 = np.diag([5., 7., 9.])\n    b3 = np.array([1., 2., 3.])\n    \n    test_cases = [\n        (A1, b1),\n        (A2, b2),\n        (A3, b3),\n    ]\n\n    results = []\n    \n    # Define the search space for the experimental omega\n    omegas = np.round(np.arange(0.50, 1.95 + 1e-9, 0.01), 2)\n    \n    for A, b in test_cases:\n        # Part 1: Calculate theoretical omega\n        D = np.diag(np.diag(A))\n        L = np.tril(A, k=-1)\n        U = np.triu(A, k=1)\n        \n        # Check if D is invertible (no zeros on diagonal)\n        diag_D = np.diag(D)\n        \n        if np.any(diag_D == 0):\n            # This case will not happen with the given SPD matrices\n            # but is a good practice check.\n            rho_Tj = float('inf') \n        else:\n            D_inv = np.diag(1. / diag_D)\n            T_j = -np.dot(D_inv, L + U)\n            \n            try:\n                eigenvalues = np.linalg.eigvals(T_j)\n                rho_Tj = np.max(np.abs(eigenvalues))\n            except np.linalg.LinAlgError:\n                rho_Tj = float('inf')\n\n        if rho_Tj  1:\n            omega_th = 2 / (1 + np.sqrt(1 - rho_Tj**2))\n        else:\n            omega_th = float('nan') # Not well-defined\n\n        # Part 2: Find experimental omega\n        min_iters = float('inf')\n        omega_exp = -1.0\n        \n        for omega in omegas:\n            iters = sor_solver(A, b, omega, tol=1e-10, max_iter=100000)\n            if iters  min_iters:\n                min_iters = iters\n                omega_exp = omega\n                \n        # Part 3: Calculate the absolute difference\n        diff = np.abs(omega_exp - omega_th)\n        \n        # Store results for this case\n        results.append([omega_exp, omega_th, diff])\n\n    # Final print statement in the exact required format.\n    formatted_case_strings = []\n    for res_case in results:\n        # Format each number to 6 decimal places and join into a string like \"[num1,num2,num3]\"\n        formatted_numbers = [f\"{val:.6f}\" for val in res_case]\n        formatted_case_strings.append(f\"[{','.join(formatted_numbers)}]\")\n    \n    # Join all case strings into the final output format \"[[...],[...],...]\"\n    final_output = f\"[{','.join(formatted_case_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2406970"}]}