{"hands_on_practices": [{"introduction": "在工程和科学领域，我们经常需要从充满噪声的测量数据中提取有用的模型，而线性最小二乘法为此提供了一个强大而直接的工具。这个练习将带你体验一个典型的应用场景：校准传感器 [@problem_id:2218047]。你将学习如何将实验数据转化为一个超定线性系统，并利用正规方程组来找到最佳拟合参数，从而最小化预测值与实际测量值之间的误差。", "problem": "一位工程师正在校准一种新型热传感器。传感器的输出电压 $V$ 被假定为环境温度 $T$ 的线性函数。该关系由方程 $V(T) = c_0 + c_1 T$ 建模，其中 $c_0$ 和 $c_1$ 是待确定的校准常数。为了确定这些常数，在受控环境中进行了四次测量：\n\n*   在温度为 $T=10$ 摄氏度时，测得的电压为 $V=2.6$ 伏特。\n*   在温度为 $T=20$ 摄氏度时，测得的电压为 $V=3.4$ 伏特。\n*   在温度为 $T=30$ 摄氏度时，测得的电压为 $V=4.7$ 伏特。\n*   在温度为 $T=40$ 摄氏度时，测得的电压为 $V=5.4$ 伏特。\n\n参数 $c_0$ 和 $c_1$ 的确定方式是，使得测量电压与线性模型预测电压之间的平方差之和最小化。令得到的最佳拟合直线为 $\\hat{V}(T) = \\hat{c}_0 + \\hat{c}_1 T$。\n\n您的任务是计算残差向量的欧几里得范数，其中残差向量的分量是单次测量电压与该最佳拟合直线预测的相应电压之间的差值。\n\n以伏特为单位表示您的最终答案，并四舍五入到三位有效数字。", "solution": "我们将电压建模为温度的线性函数 $V(T)=c_{0}+c_{1}T$，并使用四个测量值 $(T_{i},V_{i})=(10,2.6),(20,3.4),(30,4.7),(40,5.4)$ 通过最小二乘法确定 $(\\hat{c}_{0},\\hat{c}_{1})$。设设计矩阵为 $X=\\begin{pmatrix}1 & 10 \\\\ 1 & 20 \\\\ 1 & 30 \\\\ 1 & 40\\end{pmatrix}$，观测向量为 $\\boldsymbol{V}=\\begin{pmatrix}2.6 \\\\ 3.4 \\\\ 4.7 \\\\ 5.4\\end{pmatrix}$。最小二乘估计满足\n$$\n\\begin{pmatrix}\\hat{c}_{0} \\\\ \\hat{c}_{1}\\end{pmatrix}=(X^{T}X)^{-1}X^{T}\\boldsymbol{V},\n$$\n等价于正规方程组\n$$\n\\begin{pmatrix}n & \\sum T_{i} \\\\ \\sum T_{i} & \\sum T_{i}^{2}\\end{pmatrix}\\begin{pmatrix}\\hat{c}_{0} \\\\ \\hat{c}_{1}\\end{pmatrix}=\\begin{pmatrix}\\sum V_{i} \\\\ \\sum T_{i}V_{i}\\end{pmatrix}.\n$$\n计算各项和：$n=4$，$\\sum T_{i}=10+20+30+40=100$，$\\sum T_{i}^{2}=10^{2}+20^{2}+30^{2}+40^{2}=3000$，$\\sum V_{i}=2.6+3.4+4.7+5.4=16.1$，以及 $\\sum T_{i}V_{i}=10\\cdot 2.6+20\\cdot 3.4+30\\cdot 4.7+40\\cdot 5.4=451$。因此我们求解\n$$\n\\begin{pmatrix}4 & 100 \\\\ 100 & 3000\\end{pmatrix}\\begin{pmatrix}\\hat{c}_{0} \\\\ \\hat{c}_{1}\\end{pmatrix}=\\begin{pmatrix}16.1 \\\\ 451\\end{pmatrix}.\n$$\n行列式为 $4\\cdot 3000-100\\cdot 100=2000$，所以\n$$\n\\hat{c}_{0}=\\frac{3000\\cdot 16.1-100\\cdot 451}{2000}=1.6,\\quad \\hat{c}_{1}=\\frac{-100\\cdot 16.1+4\\cdot 451}{2000}=0.097.\n$$\n因此，最佳拟合直线为 $\\hat{V}(T)=1.6+0.097T$。\n\n计算在四个温度下的残差 $r_{i}=V_{i}-\\hat{V}(T_{i})$：\n$$\n\\hat{V}(10)=1.6+0.097\\cdot 10=2.57,\\quad r_{1}=2.6-2.57=0.03,\n$$\n$$\n\\hat{V}(20)=1.6+0.097\\cdot 20=3.54,\\quad r_{2}=3.4-3.54=-0.14,\n$$\n$$\n\\hat{V}(30)=1.6+0.097\\cdot 30=4.51,\\quad r_{3}=4.7-4.51=0.19,\n$$\n$$\n\\hat{V}(40)=1.6+0.097\\cdot 40=5.48,\\quad r_{4}=5.4-5.48=-0.08.\n$$\n残差向量 $\\boldsymbol{r}$ 的欧几里得范数为\n$$\n\\|\\boldsymbol{r}\\|_{2}=\\sqrt{\\sum_{i=1}^{4}r_{i}^{2}}=\\sqrt{(0.03)^{2}+(-0.14)^{2}+(0.19)^{2}+(-0.08)^{2}}=\\sqrt{0.063}.\n$$\n计算平方根并四舍五入到三位有效数字，得到\n$$\n\\|\\boldsymbol{r}\\|_{2}\\approx 0.251.\n$$\n这个值的单位是伏特，因为每个残差都是一个电压差。", "answer": "$$\\boxed{0.251}$$", "id": "2218047"}, {"introduction": "超越了单纯的数据拟合，最小二乘法的核心是一个优美的几何概念：正交投影。求解最小二乘问题，本质上等同于将一个向量投影到一个由矩阵列向量张成的子空间上，找到该子空间中离原向量最近的点。这个以机器人运动规划为背景的练习 [@problem_id:2218040]，将帮助你直观地理解这一基本原理，并将抽象的代数计算与具体的空间几何联系起来。", "problem": "您是一名控制系统工程师，正在研究一个简单的2自由度（2-DOF）机器人操纵臂。该机器人的末端执行器在3D空间中移动，其相对于基座的位置由坐标向量 $\\mathbf{p} = [x, y, z]^T$ 描述。机器人的运动由两个独立的执行器产生。第一个执行器沿方向向量 $\\mathbf{u}_1 = [1, 0, 1]^T$ 移动末端执行器，第二个执行器沿方向向量 $\\mathbf{u}_2 = [0, 1, 1]^T$ 移动它。因此，任何可达位置 $\\mathbf{p}_{reach}$ 都必须是这两个向量的线性组合：$\\mathbf{p}_{reach} = c_1 \\mathbf{u}_1 + c_2 \\mathbf{u}_2$，其中标量系数 $c_1$ 和 $c_2$ 代表执行器的位移。这意味着所有可达点的集合构成一个通过原点的平面。\n\n一项任务要求机器人的末端执行器移动到目标位置 $\\mathbf{b} = [1, 2, 2]^T$。这个点可能不在机器人的可达平面内。控制系统的目标是在可达平面内找到一个点 $\\mathbf{p}^*$，使其在几何上最接近目标点 $\\mathbf{b}$。这个最优点是 $\\mathbf{b}$ 在由执行器方向向量张成的子空间上的正交投影。\n\n使用正规方程法，确定这个最优可达点 $\\mathbf{p}^*$ 的坐标向量。请将您的答案表示为具有精确分数分量的列向量。", "solution": "该问题要求计算向量 $\\mathbf{b}$ 在由向量 $\\mathbf{u}_1$ 和 $\\mathbf{u}_2$ 张成的子空间上的正交投影。该子空间是矩阵 $A$ 的列空间，其中 $A$ 的列是 $\\mathbf{u}_1$ 和 $\\mathbf{u}_2$。投影 $\\mathbf{p}^*$ 是 $A$ 的列空间中最接近 $\\mathbf{b}$ 的向量。\n\n首先，我们定义矩阵 $A$ 和向量 $\\mathbf{b}$：\n$$ A = \\begin{bmatrix} \\mathbf{u}_1 & \\mathbf{u}_2 \\end{bmatrix} = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{bmatrix}, \\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\end{bmatrix} $$\n\n投影 $\\mathbf{p}^*$ 可以表示为 $A$ 的列的线性组合，即 $\\mathbf{p}^* = A\\mathbf{c}^*$，其中 $\\mathbf{c}^* = \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix}$ 是使欧几里得距离的平方 $\\|A\\mathbf{c} - \\mathbf{b}\\|^2$ 最小化的系数向量。这是一个线性最小二乘问题。解 $\\mathbf{c}^*$ 可通过求解正规方程得到：\n$$ A^T A \\mathbf{c}^* = A^T \\mathbf{b} $$\n\n我们通过计算该方程的各部分来进行求解。\n\n步骤 1：计算矩阵 $A^T A$。\n$A$ 的转置是：\n$$ A^T = \\begin{bmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{bmatrix} $$\n现在，我们计算乘积 $A^T A$：\n$$ A^T A = \\begin{bmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{bmatrix} \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{bmatrix} = \\begin{bmatrix} (1)(1)+(0)(0)+(1)(1) & (1)(0)+(0)(1)+(1)(1) \\\\ (0)(1)+(1)(0)+(1)(1) & (0)(0)+(1)(1)+(1)(1) \\end{bmatrix} = \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix} $$\n\n步骤 2：计算向量 $A^T \\mathbf{b}$。\n$$ A^T \\mathbf{b} = \\begin{bmatrix} 1 & 0 & 1 \\\\ 0 & 1 & 1 \\end{bmatrix} \\begin{bmatrix} 1 \\\\ 2 \\\\ 2 \\end{bmatrix} = \\begin{bmatrix} (1)(1)+(0)(2)+(1)(2) \\\\ (0)(1)+(1)(2)+(1)(2) \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix} $$\n\n步骤 3：求解正规方程以得到 $\\mathbf{c}^*$。\n方程组为：\n$$ \\begin{bmatrix} 2 & 1 \\\\ 1 & 2 \\end{bmatrix} \\begin{bmatrix} c_1 \\\\ c_2 \\end{bmatrix} = \\begin{bmatrix} 3 \\\\ 4 \\end{bmatrix} $$\n这对应于两个线性方程：\n1) $2c_1 + c_2 = 3$\n2) $c_1 + 2c_2 = 4$\n\n从方程(1)中，我们可以用 $c_1$ 表示 $c_2$：\n$c_2 = 3 - 2c_1$\n\n将此代入方程(2)：\n$c_1 + 2(3 - 2c_1) = 4$\n$c_1 + 6 - 4c_1 = 4$\n$-3c_1 = -2$\n$c_1 = \\frac{2}{3}$\n\n现在，将 $c_1$ 的值代回以求得 $c_2$：\n$c_2 = 3 - 2\\left(\\frac{2}{3}\\right) = 3 - \\frac{4}{3} = \\frac{9}{3} - \\frac{4}{3} = \\frac{5}{3}$\n因此，系数向量为 $\\mathbf{c}^* = \\begin{bmatrix} 2/3 \\\\ 5/3 \\end{bmatrix}$。\n\n步骤 4：计算投影向量 $\\mathbf{p}^*$。\n最优可达点 $\\mathbf{p}^*$ 由 $A\\mathbf{c}^*$ 给出：\n$$ \\mathbf{p}^* = A\\mathbf{c}^* = \\begin{bmatrix} 1 & 0 \\\\ 0 & 1 \\\\ 1 & 1 \\end{bmatrix} \\begin{bmatrix} \\frac{2}{3} \\\\ \\frac{5}{3} \\end{bmatrix} = \\begin{bmatrix} (1)\\left(\\frac{2}{3}\\right) + (0)\\left(\\frac{5}{3}\\right) \\\\ (0)\\left(\\frac{2}{3}\\right) + (1)\\left(\\frac{5}{3}\\right) \\\\ (1)\\left(\\frac{2}{3}\\right) + (1)\\left(\\frac{5}{3}\\right) \\end{bmatrix} = \\begin{bmatrix} \\frac{2}{3} \\\\ \\frac{5}{3} \\\\ \\frac{2}{3} + \\frac{5}{3} \\end{bmatrix} = \\begin{bmatrix} \\frac{2}{3} \\\\ \\frac{5}{3} \\\\ \\frac{7}{3} \\end{bmatrix} $$\n\n最优可达点的坐标向量是 $\\mathbf{p}^* = [2/3, 5/3, 7/3]^T$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{2}{3} \\\\\n\\frac{5}{3} \\\\\n\\frac{7}{3}\n\\end{pmatrix}\n}\n$$", "id": "2218040"}, {"introduction": "理论上的完美公式在实际计算中可能会遇到意想不到的挑战，数值稳定性是计算工程中的一个核心议题。当最小二乘问题中的矩阵 $A$ 的列向量几近线性相关时，该问题便是“病态的”(ill-conditioned)，其解对输入数据的微小扰动会异常敏感。这个编程练习 [@problem_id:2409733] 将引导你通过构建一系列逐渐病态的矩阵，亲手验证和量化这种敏感性，从而深刻理解直接求解正规方程在数值上的脆弱性。", "problem": "创建一个完整的、可运行的程序，用于评估线性最小二乘法最小化器对右侧扰动的敏感性，其中涉及一族具有近似共线列的显式定义矩阵。对于给定的实矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和向量 $b \\in \\mathbb{R}^m$，设线性最小二乘解 $x_{LS}$ 是欧几里得范数目标函数 $\\lVert A x - b \\rVert_2$ 的最小化子。考虑在 $\\mathbb{R}^3$ 中以下具有两列（即 $m = 3$ 和 $n = 2$）的确定性设置，该设置基于标准正交向量 $c_1 = \\frac{1}{\\sqrt{2}}[1,1,0]^\\top$ 和 $w = \\frac{1}{\\sqrt{2}}[1,-1,0]^\\top$。\n\n对于下方的每个测试用例，构造矩阵 $A \\in \\mathbb{R}^{3 \\times 2}$，定义 $x_{\\text{true}} \\in \\mathbb{R}^2$，形成 $b = A x_{\\text{true}}$，并在 $w$ 方向上形成一个扰动 $\\Delta b$，其大小由相对因子 $r$ 指定；即 $\\lVert \\Delta b \\rVert_2 = r \\, \\lVert b \\rVert_2$ 且 $\\Delta b = \\alpha \\, w$，其中 $\\alpha = r \\, \\lVert b \\rVert_2$。对每种情况，计算最小二乘解 $x_{LS}(b)$ 和 $x_{LS}(b + \\Delta b)$，然后计算解相对于 $b$ 中扰动的放大因子 $R$，其定义为\n$$\nR = \\frac{\\lVert x_{LS}(b + \\Delta b) - x_{LS}(b) \\rVert_2 / \\lVert x_{LS}(b) \\rVert_2}{\\lVert \\Delta b \\rVert_2 / \\lVert b \\rVert_2}.\n$$\n如果上述表达式中任何分母为零，则使用与连续性一致的极限值来解释相应的比率，并在实现中使用一个严格为正的可忽略常数来防止除以零。\n\n使用以下测试套件，其中所有数字均为精确且无量纲的：\n- 测试用例 1 (良态基线)：$A = [c_1,\\, w]$ (列向量)，$x_{\\text{true}} = [2,\\, 1]^\\top$, $r = 10^{-6}$。\n- 测试用例 2 (中度近似共线性)：$A = [c_1,\\, c_1 + \\epsilon w]$，其中 $\\epsilon = 10^{-3}$，$x_{\\text{true}} = [2,\\, 1]^\\top$, $r = 10^{-6}$。\n- 测试用例 3 (极端近似共线性)：$A = [c_1,\\, c_1 + \\epsilon w]$，其中 $\\epsilon = 10^{-9}$，$x_{\\text{true}} = [2,\\, 1]^\\top$, $r = 10^{-6}$。\n- 测试用例 4 (精确共线性和秩亏)：$A = [c_1,\\, c_1]$，$x_{\\text{true}} = [2,\\, 1]^\\top$, $r = 10^{-6}$。\n\n对于每个测试用例，所需的答案是如上定义的单个实数 $R$。您的程序必须按指定顺序处理所有四个测试用例，并生成单行输出，其中包含用方括号括起来的四个结果的逗号分隔列表，例如 $[R_1,R_2,R_3,R_4]$。不涉及物理单位。不使用角度。所有数值输出必须是该单行上的实数（采用十进制或科学记数法）。", "solution": "该问题要求分析线性最小二乘解对右侧向量 $b$ 扰动的敏感性。我们需要为四个涉及列向量逐渐共线的矩阵的特定测试用例计算一个放大因子 $R$。\n\n线性最小二乘问题定义为：对于给定的矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 和向量 $b \\in \\mathbb{R}^m$，找到一个向量 $x_{LS} \\in \\mathbb{R}^n$，使其最小化残差的欧几里得范数 $\\lVert Ax - b \\rVert_2$。\n\n这个问题的解可以用 $A$ 的 Moore-Penrose 伪逆（记作 $A^\\dagger$）正式表示为 $x_{LS} = A^\\dagger b$。当矩阵 $A$ 具有满列秩（即 $\\text{rank}(A) = n$）时，伪逆由 $A^\\dagger = (A^\\top A)^{-1} A^\\top$ 给出，解 $x_{LS}$ 是唯一的，可以通过求解正规方程组得到：\n$$\nA^\\top A x = A^\\top b\n$$\n如果 $A$ 是秩亏的，最小二乘问题仍然有解，但解不唯一。在这种情况下，通常会选择一个唯一的解，即在所有最小化子中具有最小欧几里得范数的解。`numpy.linalg.lstsq` 函数按照标准做法返回这个最小范数解，该解也由 $x_{LS} = A^\\dagger b$ 给出。\n\n解 $x_{LS}$ 对 $b$ 中扰动 $\\Delta b$ 的敏感性是这个问题的核心。设扰动后的向量为 $b' = b + \\Delta b$。新的解是 $x_{LS}(b + \\Delta b) = A^\\dagger (b + \\Delta b)$。因此，解的变化量 $\\Delta x$ 为：\n$$\n\\Delta x = x_{LS}(b + \\Delta b) - x_{LS}(b) = A^\\dagger (b + \\Delta b) - A^\\dagger b = A^\\dagger \\Delta b\n$$\n问题将放大因子 $R$ 定义为解的相对变化与右侧向量的相对变化之比：\n$$\nR = \\frac{\\lVert \\Delta x \\rVert_2 / \\lVert x_{LS}(b) \\rVert_2}{\\lVert \\Delta b \\rVert_2 / \\lVert b \\rVert_2} = \\frac{\\lVert A^\\dagger \\Delta b \\rVert_2 / \\lVert A^\\dagger b \\rVert_2}{\\lVert \\Delta b \\rVert_2 / \\lVert b \\rVert_2}\n$$\n在此问题中，$b$ 的相对扰动是固定的：$\\lVert \\Delta b \\rVert_2 / \\lVert b \\rVert_2 = r = 10^{-6}$。因此，公式简化为：\n$$\nR = \\frac{\\lVert x_{LS}(b + \\Delta b) - x_{LS}(b) \\rVert_2 / \\lVert x_{LS}(b) \\rVert_2}{r}\n$$\n每个测试用例的步骤是构造矩阵 $A$、真实解 $x_{\\text{true}}$、向量 $b = A x_{\\text{true}}$ 和扰动 $\\Delta b$。然后我们计算 $b$ 和 $b+\\Delta b$ 的最小二乘解以求得 $R$。基向量是标准正交向量 $c_1 = \\frac{1}{\\sqrt{2}}[1,1,0]^\\top$ 和 $w = \\frac{1}{\\sqrt{2}}[1,-1,0]^\\top$。\n\n情况1：$A = [c_1, w]$, $x_{\\text{true}} = [2, 1]^\\top$, $r = 10^{-6}$。\n矩阵 $A$ 具有标准正交列。因此，$A^\\top A = I$，其中 $I$ 是 $2 \\times 2$ 单位矩阵。$A$ 的条件数是 $\\kappa_2(A) = 1$。该系统是完全良态的。\n$b = A x_{\\text{true}} = 2c_1 + 1w$。由于 $b$ 被构造成位于 $A$ 的列空间中，且 $A$ 是满秩的，因此 $x_{LS}(b) = x_{\\text{true}}$。\n$\\lVert x_{LS}(b) \\rVert_2 = \\lVert x_{\\text{true}} \\rVert_2 = \\sqrt{2^2 + 1^2} = \\sqrt{5}$。\n扰动为 $\\Delta b = r \\lVert b \\rVert_2 w$。\n解的变化量为 $\\Delta x = A^\\dagger \\Delta b = (A^\\top A)^{-1} A^\\top \\Delta b = A^\\top \\Delta b$。\n$\\Delta x = A^\\top (r \\lVert b \\rVert_2 w) = r \\lVert b \\rVert_2 A^\\top w = r \\lVert b \\rVert_2 \\begin{pmatrix} c_1^\\top w \\\\ w^\\top w \\end{pmatrix} = r \\lVert b \\rVert_2 \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。\n$\\lVert \\Delta x \\rVert_2 = r \\lVert b \\rVert_2$。\n$\\lVert b \\rVert_2 = \\lVert 2c_1 + w \\rVert_2 = \\sqrt{4\\lVert c_1 \\rVert_2^2 + \\lVert w \\rVert_2^2} = \\sqrt{4+1} = \\sqrt{5}$。\n所以，$\\lVert \\Delta x \\rVert_2 = r\\sqrt{5}$。\n放大因子为 $R = \\frac{\\lVert \\Delta x \\rVert_2 / \\lVert x_{LS}(b) \\rVert_2}{r} = \\frac{(r\\sqrt{5}) / \\sqrt{5}}{r} = 1$。\n\n情况2和3：$A = [c_1, c_1 + \\epsilon w]$，其中 $\\epsilon = 10^{-3}$ 和 $\\epsilon = 10^{-9}$。\n当 $\\epsilon \\to 0$ 时，$A$ 的列向量近似共线。矩阵 $A$ 变得越来越病态。\n从分析可知，$x_{LS}(b) = x_{\\text{true}}$。\n解的变化量为 $\\Delta x = \\frac{r}{\\epsilon}\\sqrt{9+\\epsilon^2} \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}$。\n范数为 $\\lVert \\Delta x \\rVert_2 = \\frac{r\\sqrt{2}}{\\epsilon}\\sqrt{9+\\epsilon^2}$。\n那么 $R = \\frac{\\lVert \\Delta x \\rVert_2 / \\lVert x_{LS}(b) \\rVert_2}{r} = \\frac{(\\frac{r\\sqrt{2}}{\\epsilon}\\sqrt{9+\\epsilon^2}) / \\sqrt{5}}{r} = \\frac{\\sqrt{2}\\sqrt{9+\\epsilon^2}}{\\epsilon\\sqrt{5}}$。\n当 $\\epsilon \\to 0$ 时，$R$ 与 $1/\\epsilon$ 成正比增长。对于小的 $\\epsilon$，$R \\approx \\frac{3\\sqrt{2}}{\\epsilon\\sqrt{5}}$。这表明病态系统对扰动具有极高的敏感性。\n\n情况4：$A = [c_1, c_1]$。\n矩阵 $A$ 是秩亏的，$\\text{rank}(A)=1$。列向量完全共线 ($\\epsilon = 0$)。\n$b = A x_{\\text{true}} = 2c_1 + 1c_1 = 3c_1$。$b$ 位于 $A$ 的列空间中。\n$Ax=b$ 的精确解集是直线 $x_1+x_2 = 3$。最小范数解是这条直线上离原点最近的点，即 $x_{LS}(b) = [1.5, 1.5]^\\top$。\n扰动为 $\\Delta b = r \\lVert b \\rVert_2 w = 3rw$。这个扰动向量 $w$ 与 $A$ 的列空间 $\\text{span}\\{c_1\\}$ 正交。\n最小二乘解将右侧向量投影到 $A$ 的列空间上。\n$P_A(b+\\Delta b) = P_A(b) + P_A(\\Delta b) = b + 0 = b$。\n因此，寻找 $x_{LS}(b+\\Delta b)$ 的问题等同于寻找 $x_{LS}(b)$，因为扰动被投影掉了。\n因此，$x_{LS}(b+\\Delta b) = x_{LS}(b) = [1.5, 1.5]^\\top$。这意味着 $\\Delta x = 0$，所以 $\\lVert \\Delta x \\rVert_2 = 0$。\n放大因子为 $R = \\frac{0 / \\lVert x_{LS}(b) \\rVert_2}{r} = 0$。\n值 $R=0$ 显示了与情况2/3中 $\\epsilon \\to 0$ 的极限不连续。这是因为对于任何 $\\epsilon > 0$，$A$ 的列空间是 $\\text{span}\\{c_1, w\\}$，而扰动 $\\Delta b \\propto w$ 位于其中。在 $\\epsilon = 0$ 时，列空间坍缩为 $\\text{span}\\{c_1\\}$，而相同的扰动 $\\Delta b$ 与其正交。伪逆解的行为对于列空间内部与外部的扰动有根本的不同。问题陈述是有效的，这个结果是正确的。\n\n实现将以数值方式计算这些值。\n\n```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Evaluates the sensitivity of the linear least-squares minimizer to perturbations\n    for a family of matrices with increasingly collinear columns.\n    \"\"\"\n    \n    # Define the orthonormal basis vectors\n    c1 = (1 / np.sqrt(2)) * np.array([1.0, 1.0, 0.0])\n    w = (1 / np.sqrt(2)) * np.array([1.0, -1.0, 0.0])\n    \n    # Define x_true and r as specified in the problem\n    x_true = np.array([2.0, 1.0])\n    r = 1e-6\n    \n    # Test cases parameters: (name, epsilon)\n    # Epsilon defines the matrix A. A special value of None is used for the first case.\n    test_params = [\n        (\"well-conditioned baseline\", None),\n        (\"moderate near collinearity\", 1e-3),\n        (\"extreme near collinearity\", 1e-9),\n        (\"exact collinearity\", 0.0)\n    ]\n    \n    results = []\n\n    # Small constant to prevent division by zero, as per problem instructions\n    ZERO_GUARD = 1e-15\n\n    for name, epsilon in test_params:\n        # Step 1: Construct matrix A\n        if epsilon is None:\n            # Case 1: A = [c1, w]\n            A = np.c_[c1, w]\n        else:\n            # Cases 2, 3, 4: A = [c1, c1 + epsilon * w]\n            col2 = c1 + epsilon * w\n            A = np.c_[c1, col2]\n            \n        # Step 2: Form b and the perturbation delta_b\n        b = A @ x_true\n        \n        norm_b = np.linalg.norm(b)\n        safe_norm_b = norm_b if norm_b > ZERO_GUARD else ZERO_GUARD\n        \n        # Perturbation is in the direction of w\n        delta_b = r * norm_b * w\n        \n        b_perturbed = b + delta_b\n\n        # Step 3: Compute the least-squares solutions\n        # Use rcond=None to adopt the new default behavior of numpy.linalg.lstsq\n        x_ls_b = np.linalg.lstsq(A, b, rcond=None)[0]\n        x_ls_b_perturbed = np.linalg.lstsq(A, b_perturbed, rcond=None)[0]\n        \n        # Step 4: Compute the amplification factor R\n        delta_x = x_ls_b_perturbed - x_ls_b\n        \n        norm_delta_x = np.linalg.norm(delta_x)\n        norm_x_ls_b = np.linalg.norm(x_ls_b)\n        \n        safe_norm_x_ls_b = norm_x_ls_b if norm_x_ls_b > ZERO_GUARD else ZERO_GUARD\n\n        # The relative error in x\n        rel_err_x = norm_delta_x / safe_norm_x_ls_b\n        \n        # The relative error in b is, by definition, r.\n        # R = rel_err_x / (||delta_b|| / ||b||) = rel_err_x / r\n        # We must handle the case where r is zero, though problem states r=10^-6\n        safe_r = r if r > ZERO_GUARD else ZERO_GUARD\n        \n        R = rel_err_x / safe_r\n        \n        results.append(R)\n\n    # Final print statement in the exact required format.\n    # The output format is a list of strings representing the numbers.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "answer": "[1.0,1414.213564035656,1414213562.373095,0.0]", "id": "2409733"}]}