{"hands_on_practices": [{"introduction": "当一个非常小的数与1相加时，计算中会出现一种被称为“灾难性抵消”的精度损失。本练习将通过评估函数 $\\ln(1+x)$ 来探讨这一问题，并比较直接计算与更稳健的泰勒级数近似之间的差异。通过亲手找到一个算法优于另一个的“交叉点”，你将深刻理解在何种情况下以及为何需要切换计算策略。[@problem_id:2420005]", "problem": "您需要研究有限精度舍入对接近1的自然对数求值的影响。设 $f(x) = \\ln(1+x)$，其中实数 $x$ 满足 $-1 < x < 1$。在使用电气与电子工程师协会 (IEEE) $754$ 标准二进制 $64$ 位浮点运算时，考虑以下两种对 $f(x)$ 的有限精度近似方法：(i) 直接计算 $\\ln(1+x)$，即先在浮点运算中计算 $1+x$，然后对该舍入后的结果应用自然对数函数；以及 (ii) $K$ 次截断泰勒多项式 $T_K(x) = \\sum_{n=1}^{K} (-1)^{n+1} \\dfrac{x^n}{n}$，该多项式由 $\\ln(1+x)$ 在 $x=0$ 处的泰勒级数得到，此级数在 $|x|<1$ 时收敛。对于每个 $x$，将近似值 $g(x)$ 的绝对前向误差定义为 $E[g](x) = \\left| g(x) - y_{\\mathrm{ref}}(x) \\right|$，其中 $y_{\\mathrm{ref}}(x)$ 表示 $\\ln(1+x)$ 的数学精确值在相同浮点格式下四舍五入到最接近的可表示数。\n\n您的任务是，在一个给定的低量级输入网格上，比较直接求值近似 $y_{\\mathrm{naive}}(x)$ 和泰勒近似 $T_K(x)$ 的绝对前向误差，并找出一个离散的交叉输入值，在该点泰勒近似首次比直接求值更精确。\n\n使用的定义：\n- 对于给定的整数 $K \\ge 1$, $T_K(x) = \\sum_{n=1}^{K} (-1)^{n+1} \\dfrac{x^n}{n}$。\n- $y_{\\mathrm{naive}}(x)$ 是通过先在浮点运算中计算 $1+x$ 然后对该浮点结果应用自然对数来计算 $\\ln(1+x)$ 的结果。\n- $y_{\\mathrm{ref}}(x)$ 是 $\\ln(1+x)$ 的数学精确值在相同格式下四舍五入到最接近的可表示浮点值。\n\n离散网格上的交叉点定义：\n- 固定一个符号 $s \\in \\{+1,-1\\}$ 和一个整数 $K \\ge 1$。考虑有序网格 $S_{s} = \\{ s \\cdot 10^{-j} : j = 1,2,\\dots,20 \\}$，该网格按量级递减（即 $j$ 递增）排序。\n- 对于 $(s,K)$，交叉点 $x^\\star$ 定义为按给定顺序扫描网格 $S_s$ 时，满足 $E[T_K](x) < E[y_{\\mathrm{naive}}](x)$ 的第一个元素 $x$。如果网格上不存在这样的 $x$，则交叉点定义为“非数值 (not-a-number)”，应报告为浮点数 NaN。\n\n测试套件：\n- 情况1：$s=+1$, $K=3$。\n- 情况2：$s=+1$, $K=7$。\n- 情况3：$s=-1$, $K=3$。\n- 情况4：$s=-1$, $K=7$。\n\n最终输出格式：\n您的程序应生成单行输出，其中按顺序包含对应情况1到4的四个交叉点结果，格式为方括号括起来的逗号分隔列表，例如 $[r_1,r_2,r_3,r_4]$，其中每个 $r_i$ 是一个浮点数（如果在网格上未找到交叉点，则使用 NaN）。本问题不涉及单位，也不涉及角度。所有数值答案必须是纯十进制或科学记数法表示的浮点值，不带任何百分号。", "solution": "该问题要求分析在 $x$ 值很小时计算函数 $f(x) = \\ln(1+x)$ 时的数值误差。我们必须比较两种近似方法：一种是直接的朴素求值，另一种是截断的泰勒级数多项式。目标是在一个指定的离散网格上，找出使得泰勒近似首次比朴素方法更精确的输入值 $x^\\star$。这是计算工程领域中一个关于数值误差管理的经典问题。\n\n该分析基于两种相互竞争的误差来源：舍入误差和截断误差。\n\n首先，考虑朴素求值，记为 $y_{\\mathrm{naive}}(x)$。它的计算过程是先执行浮点加法 $1+x$，然后对结果取自然对数。当 $|x| \\ll 1$ 时，$1+x$ 这个操作会遭受一种称为灾难性抵消 (catastrophic cancellation) 的现象。在有限精度运算中，例如指定的 IEEE $754$ 标准二进制 $64$ 位格式，数字 $1$ 没有小数部分。当一个很小的数 $x$ 与 $1$ 相加时，$x$ 中相对于 $1$ 小于机器精度 ($\\epsilon_{\\mathrm{mach}}$) 的低位比特会丢失。对于 $64$ 位浮点数，机器精度 $\\epsilon_{\\mathrm{mach}} \\approx 2.22 \\times 10^{-16}$。和 $1+x$ 被舍入到最接近的可表示浮点数，从而引入一个量级约为 $\\epsilon_{\\mathrm{mach}}$ 的舍入误差。这个误差相对于 $\\ln(1+x) \\approx x$ 的真实值来说很大，主导了 $y_{\\mathrm{naive}}(x)$ 的精度。因此，当 $|x| \\to 0$ 时，绝对前向误差 $E[y_{\\mathrm{naive}}](x)$ 预计会稳定在一个约为 $\\epsilon_{\\mathrm{mach}}$ 的水平上。\n\n其次，考虑泰勒级数近似 $T_K(x) = \\sum_{n=1}^{K} (-1)^{n+1} \\frac{x^n}{n}$。这是 $\\ln(1+x)$ 在 $x=0$ 处展开的 $K$ 次泰勒多项式。这种近似的主要误差是截断误差，它源于忽略了无穷级数的高阶项。余项 $R_K(x) = \\ln(1+x) - T_K(x)$ 是有界的。对于一个满足必要收敛准则的交错级数（本级数在 $0 \\le x  1$ 时满足），截断误差的绝对值以被忽略的第一项的绝对值为界：$|R_K(x)| \\le \\frac{|x|^{K+1}}{K+1}$。随着 $|x|$ 趋近于 $0$，该误差会迅速减小。多项式本身的计算也涉及会引入舍入误差的算术运算，但对于较小的 $K$ 值，这个误差通常远小于截断误差，尤其是在我们网格上 $|x|$ 较大的情况下。\n\n交叉点 $x^\\star$ 出现在主导误差源发生切换的地方。对于“较大”的 $|x|$ 值（例如 $10^{-1}$），$T_K(x)$ 的截断误差相当大，这使得朴素求值更为精确。随着 $|x|$ 的减小，$T_K(x)$ 的截断误差迅速减小，而由于灾难性抵消，$y_{\\mathrm{naive}}(x)$ 的舍入误差则顽固地保持在较高水平。交叉点是在有序网格上（从较大 $|x|$ 向较小 $|x|$ 扫描）第一个使得泰勒级数误差 $E[T_K](x)$ 低于朴素求值误差 $E[y_{\\mathrm{naive}}](x)$ 的点。\n\n计算步骤如下：\n$1$. 我们建立一个高精度参考值 $y_{\\mathrm{ref}}(x)$。问题将其定义为 $\\ln(1+x)$ 的数学精确值四舍五入到最接近的可表示 $64$ 位浮点数。在计算上，最好通过使用为此目的设计的数值稳定库函数来实现，例如 `numpy.log1p(x)`。该函数通过对小的 $x$ 使用不同的算法来避免 $1+x$ 的抵消问题。\n$2$. 对于网格中的每个点 $x \\in S_s = \\{ s \\cdot 10^{-j} : j = 1, 2, \\ldots, 20 \\}$，我们使用 $64$ 位浮点运算计算三个必要的值：\n    - 参考值 $y_{\\mathrm{ref}}(x) = \\mathrm{numpy.log1p}(x)$。\n    - 朴素值 $y_{\\mathrm{naive}}(x) = \\mathrm{numpy.log}(1.0 + x)$。\n    - 泰勒近似值 $T_K(x)$，通过对其各项求和计算得出。\n$3$. 然后我们计算绝对前向误差：\n    - $E[y_{\\mathrm{naive}}](x) = |y_{\\mathrm{naive}}(x) - y_{\\mathrm{ref}}(x)|$。\n    - $E[T_K](x) = |T_K(x) - y_{\\mathrm{ref}}(x)|$。\n$4$. 我们按 $j$ 递增（即 $x$ 的量级递减）的顺序遍历网格 $S_s$。将满足条件 $E[T_K](x)  E[y_{\\mathrm{naive}}](x)$ 的第一个 $x$ 记录为交叉点 $x^\\star$。如果在整个网格中没有找到这样的点，则结果定义为非数值 (NaN)。对四个测试用例中的每一个重复此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the numerical crossover problem for evaluating ln(1+x).\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    # Each case is a tuple (s, K), where s is the sign and K is the Taylor degree.\n    test_cases = [\n        (1, 3),   # Case 1: s=+1, K=3\n        (1, 7),   # Case 2: s=+1, K=7\n        (-1, 3),  # Case 3: s=-1, K=3\n        (-1, 7)   # Case 4: s=-1, K=7\n    ]\n\n    results = []\n    \n    # Use 64-bit floating point numbers as specified (IEEE 754 binary64)\n    dtype = np.float64\n\n    def T_K(x, K):\n        \"\"\"\n        Calculates the degree-K truncated Taylor polynomial for ln(1+x).\n        T_K(x) = sum_{n=1 to K} [(-1)^(n+1) * x^n / n]\n        \n        Args:\n            x (float): The input value.\n            K (int): The degree of the polynomial.\n        \n        Returns:\n            float: The value of the Taylor polynomial.\n        \"\"\"\n        total = dtype(0.0)\n        # A direct summation is clear and efficient enough for small K.\n        # Horner's method could also be used but adds complexity for this form.\n        for n in range(1, K + 1):\n            term = ((-1)**(n + 1)) * (x**n) / n\n            total += term\n        return total\n\n    for s, K in test_cases:\n        crossover_x = np.nan\n\n        # The grid S_s is ordered by decreasing magnitude (increasing j)\n        for j in range(1, 21):\n            x = dtype(s) * (dtype(10.0)**(-j))\n            \n            # 1. Reference value: Use numpy.log1p for high accuracy\n            y_ref = np.log1p(x)\n            \n            # 2. Naive evaluation: Direct computation causing catastrophic cancellation\n            y_naive = np.log(dtype(1.0) + x)\n            \n            # 3. Taylor polynomial approximation\n            y_taylor = T_K(x, K)\n            \n            # 4. Calculate absolute forward errors\n            error_naive = np.abs(y_naive - y_ref)\n            error_taylor = np.abs(y_taylor - y_ref)\n\n            # 5. Check for crossover condition\n            # The crossover is the FIRST point on the ordered grid where Taylor is better.\n            if error_taylor  error_naive:\n                crossover_x = x\n                break # Found the crossover, so exit the loop for this case.\n        \n        results.append(crossover_x)\n\n    # Final print statement in the exact required format.\n    # The map(str, ...) is robust for converting floats and NaN to strings.\n    # For NaN, str(np.nan) produces 'nan'. The problem statement says to use NaN.\n    # This implies the string representation is acceptable.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2420005"}, {"introduction": "在数值方法中，我们常常需要在不同类型的误差之间做出权衡。这个练习将通过让你为有限差分公式寻找最优步长 $h$ 来展示这种根本性的冲突。你将需要平衡随着 $h$ 减小而减小的截断误差，以及随着 $h$ 减小而增大的舍入误差，从而体验到数值计算中的“最佳点”是如何产生的。[@problem_id:2420015]", "problem": "考虑使用三点中心差分公式来近似函数 $f(x) = \\sin(x)$ 在点 $x = 1.0$ 处的导数\n$$\nD(h) = \\frac{f(1.0+h) - f(1.0-h)}{2h}.\n$$\n假设所有算术运算均根据电气和电子工程师协会 (IEEE) $754$ 标准以浮点数形式执行，并采用四舍五入到最近值的方式，单位舍入误差为 $u = 2^{-53}$。进一步假设，基本函数 $\\sin(\\cdot)$ 的每次调用都遵循标准浮点模型，因此计算值 $\\widetilde{\\sin}(y)$ 满足 $\\widetilde{\\sin}(y) = \\sin(y)\\,(1+\\delta)$ 且 $|\\delta| \\le u$，并且每次基本算术运算都满足相同的相对误差界。将 $h$ 视为足够小，以至于 $h$ 和 $u$ 的主阶项占主导地位，并以弧度为单位计算 $\\sin$ 和 $\\cos$。确定步长 $h$ 的值，该值使得在 $x=1.0$ 处，由截断误差和舍入误差的综合影响引起的计算值 $D(h)$ 的绝对误差的主阶界最小。提供 $h$ 的单个数值。将您的答案四舍五入到 $4$ 位有效数字。答案是无量纲的。", "solution": "问题陈述经过验证，被认为是科学上合理的、适定的和客观的。这是数值分析中一个关于截断误差和舍入误差之间平衡的标准问题。我们将进行形式化的求解。\n\n使用中心差分公式的计算值 $\\widetilde{D}(h)$ 来近似导数 $f'(x)$ 的总绝对误差，其上界为截断误差和舍入误差之和：\n$$\n|\\widetilde{D}(h) - f'(x)| \\le |D(h) - f'(x)| + |\\widetilde{D}(h) - D(h)|\n$$\n第一项 $|D(h) - f'(x)|$ 表示有限差分公式固有的截断误差 $E_{\\text{trunc}}(h)$。第二项 $|\\widetilde{D}(h) - D(h)|$ 是由浮点运算引起的舍入误差 $E_{\\text{round}}(h)$。\n\n首先，我们分析截断误差。函数 $f(x)$ 导数的三点中心差分公式由下式给出：\n$$\nD(h) = \\frac{f(x+h) - f(x-h)}{2h}\n$$\n我们使用 $f(x+h)$ 和 $f(x-h)$ 在点 $x$ 附近的泰勒级数展开：\n$$\nf(x+h) = f(x) + h f'(x) + \\frac{h^2}{2} f''(x) + \\frac{h^3}{6} f'''(x) + \\frac{h^4}{24} f^{(4)}(x) + \\frac{h^5}{120} f^{(5)}(x) + O(h^6)\n$$\n$$\nf(x-h) = f(x) - h f'(x) + \\frac{h^2}{2} f''(x) - \\frac{h^3}{6} f'''(x) + \\frac{h^4}{24} f^{(4)}(x) - \\frac{h^5}{120} f^{(5)}(x) + O(h^6)\n$$\n从第一个展开式中减去第二个展开式，得到：\n$$\nf(x+h) - f(x-h) = 2h f'(x) + \\frac{h^3}{3} f'''(x) + \\frac{h^5}{60} f^{(5)}(x) + O(h^7)\n$$\n将此结果代入 $D(h)$ 的公式中：\n$$\nD(h) = \\frac{2h f'(x) + \\frac{h^3}{3} f'''(x) + O(h^5)}{2h} = f'(x) + \\frac{h^2}{6} f'''(x) + O(h^4)\n$$\n截断误差为 $E_{\\text{trunc}}(h) = |D(h) - f'(x)|$。该误差的主阶项为：\n$$\nE_{\\text{trunc}}(h) \\approx \\left| \\frac{h^2}{6} f'''(x) \\right|\n$$\n对于给定函数 $f(x) = \\sin(x)$，其三阶导数为 $f'''(x) = -\\cos(x)$。求值点为 $x=1.0$ 弧度。则截断误差为：\n$$\nE_{\\text{trunc}}(h) \\approx \\frac{h^2}{6} |-\\cos(1.0)| = \\frac{h^2}{6} \\cos(1.0)\n$$\n因为 $1.0$ 弧度在第一象限，其中 $\\cos(1.0)  0$。\n\n接下来，我们分析舍入误差。该公式涉及对两个几乎相等的数 $f(x+h)$ 和 $f(x-h)$（对于小的 $h$）进行相减，这会导致灾难性抵消。这是舍入误差的主要来源。计算出的函数值为 $\\widetilde{f}(x+h) = f(x+h)(1+\\delta_1)$ 和 $\\widetilde{f}(x-h) = f(x-h)(1+\\delta_2)$，其中 $|\\delta_1|, |\\delta_2| \\le u$，$u = 2^{-53}$ 是单位舍入误差。计算出的分子中的绝对误差的上界为：\n$$\n|f(x+h)(1+\\delta_1) - f(x-h)(1+\\delta_2) - (f(x+h) - f(x-h))| \\approx |f(x+h)\\delta_1 - f(x-h)\\delta_2|\n$$\n此误差的界为 $\\le u|f(x+h)| + u|f(x-h)|$。对于小的 $h$，我们可以近似 $f(x+h) \\approx f(x)$ 和 $f(x-h) \\approx f(x)$。因此，分子中的误差上界约为 $2u|f(x)|$。这个误差随后通过除以 $2h$ 进行传播。因此，主阶舍入误差为：\n$$\nE_{\\text{round}}(h) \\approx \\frac{2u|f(x)|}{2h} = \\frac{u|f(x)|}{h}\n$$\n对于 $f(x) = \\sin(x)$ 在 $x=1.0$ 处，这变为：\n$$\nE_{\\text{round}}(h) \\approx \\frac{u|\\sin(1.0)|}{h} = \\frac{u\\sin(1.0)}{h}\n$$\n因为 $\\sin(1.0)  0$。\n\n总误差界 $E(h)$ 是主阶截断误差和主阶舍入误差之和：\n$$\nE(h) \\approx E_{\\text{trunc}}(h) + E_{\\text{round}}(h) = \\frac{h^2}{6}\\cos(1.0) + \\frac{u\\sin(1.0)}{h}\n$$\n为了找到使该误差界最小的步长 $h$，我们将 $E(h)$ 对 $h$ 求导，并令结果为零：\n$$\n\\frac{dE}{dh} = \\frac{2h}{6}\\cos(1.0) - \\frac{u\\sin(1.0)}{h^2} = \\frac{h}{3}\\cos(1.0) - \\frac{u\\sin(1.0)}{h^2}\n$$\n令 $\\frac{dE}{dh} = 0$：\n$$\n\\frac{h_{\\text{opt}}}{3}\\cos(1.0) = \\frac{u\\sin(1.0)}{h_{\\text{opt}}^2}\n$$\n求解 $h_{\\text{opt}}$：\n$$\nh_{\\text{opt}}^3 = \\frac{3u\\sin(1.0)}{\\cos(1.0)} = 3u\\tan(1.0)\n$$\n$$\nh_{\\text{opt}} = (3u\\tan(1.0))^{1/3}\n$$\n现在，我们代入数值 $u = 2^{-53}$ 并以弧度计算 $\\tan(1.0)$。\n$$\nh_{\\text{opt}} = (3 \\times 2^{-53} \\times \\tan(1.0))^{1/3}\n$$\n使用计算器，$\\tan(1.0) \\approx 1.55740772$。\n$$\nh_{\\text{opt}} \\approx (3 \\times 2^{-53} \\times 1.55740772)^{1/3}\n$$\n$$\nh_{\\text{opt}} \\approx (4.67222317 \\times 2^{-53})^{1/3}\n$$\n$$\nh_{\\text{opt}} \\approx (4.67222317 \\times 1.11022302 \\times 10^{-16})^{1/3}\n$$\n$$\nh_{\\text{opt}} \\approx (5.18742014 \\times 10^{-16})^{1/3}\n$$\n$$\nh_{\\text{opt}} \\approx 8.03525 \\times 10^{-6}\n$$\n题目要求将答案四舍五入到 $4$ 位有效数字。\n$$\nh_{\\text{opt}} \\approx 8.035 \\times 10^{-6}\n$$\n这是平衡递减的截断误差和递增的舍入误差的最佳步长。", "answer": "$$\n\\boxed{8.035 \\times 10^{-6}}\n$$", "id": "2420015"}, {"introduction": "数值稳定性不仅取决于单个表达式，更与整个算法的设计息息相关。本练习使用贝塞尔函数的三项递推关系，生动地展示了一个“前向”（不稳定）的递推如何灾难性地放大初始误差，而一个“后向”（稳定）的递推却能收敛到正确解。这让你能够深入探索算法的内在属性，理解为何看似等价的计算路径会产生截然不同的结果。[@problem_id:2420035]", "problem": "给定整数阶第一类柱贝塞尔函数，记为 $J_n(x)$，它满足三项递推关系\n$$\nJ_{k+1}(x) = \\frac{2k}{x} J_k(x) - J_{k-1}(x), \\quad \\text{其中整数 } k \\ge 1, \\text{ 且实数 } x  0.\n$$\n设“可信参考”值 $J_n^{\\mathrm{ref}}(x)$ 由一个可靠的 $J_n(x)$ 实现，以至少双精度的浮点算术计算得出。定义 $J_n(x)$ 的两种计算近似如下：\n\n- 前向近似 $J_n^{\\mathrm{fwd}}(x)$，通过从 $J_0(x)$ 和 $J_1(x)$ 的精确基准值开始，向上（$k$ 递增）传播递推关系得到。\n- 后向近似 $J_n^{\\mathrm{bwd}}(x)$，通过从一个足够大的 $M \\ge n$ 开始，使用 $k=M$ 和 $k=M+1$ 处的任意初始值，向下（$k$ 递减）传播递推关系，然后对所得序列进行归一化，使其在0阶的值与可信参考值 $J_0^{\\mathrm{ref}}(x)$ 匹配。\n\n对于每个测试用例 $(x,n)$，通过计算相对误差来量化这两种方法的数值稳定性\n$$\ne_{\\mathrm{rel}} = \\frac{\\left|J_n^{\\mathrm{approx}}(x) - J_n^{\\mathrm{ref}}(x)\\right|}{\\max\\left(\\left|J_n^{\\mathrm{ref}}(x)\\right|, \\delta\\right)},\n$$\n其中 $\\delta = 10^{-300}$，分别对前向和后向近似进行计算。每个测试用例报告两个浮点数，顺序为前向误差，然后是后向误差。\n\n测试套件：\n- 用例 1: $(x,n) = (10.0, 20)$。\n- 用例 2: $(x,n) = (1.0, 20)$。\n- 用例 3: $(x,n) = (50.0, 20)$。\n- 用例 4: $(x,n) = (25.0, 60)$。\n- 用例 5: $(x,n) = (5.0, 5)$。\n\n您的程序必须为每个用例计算上面定义的两个浮点数 $e_{\\mathrm{rel}}^{\\mathrm{fwd}}$ 和 $e_{\\mathrm{rel}}^{\\mathrm{bwd}}$，对 $J_n^{\\mathrm{ref}}(x)$ 以及需要时的基准值 $J_0(x)$ 和 $J_1(x)$ 使用相同的可信参考实现。最终输出必须是单行，包含一个逗号分隔的 $2 \\times 5$ 个浮点数列表，按上述用例顺序排列，每个用例内按 $(e_{\\mathrm{rel}}^{\\mathrm{fwd}}, e_{\\mathrm{rel}}^{\\mathrm{bwd}})$ 排序。例如，\n\"[fwd1,bwd1,fwd2,bwd2,fwd3,bwd3,fwd4,bwd4,fwd5,bwd5]\".", "solution": "问题陈述已经过分析并被认为是有效的。它具有科学依据，提法恰当且客观。它涉及计算科学中一个基础而经典的主题：特殊函数递推关系的数值稳定性。我们将提供一个完整的解决方案。\n\n该问题要求对计算第一类柱贝塞尔函数 $J_n(x)$ 的两种数值方案进行比较分析，该函数是二阶常微分方程的解\n$$ x^2 y''(x) + x y'(x) + (x^2 - n^2) y(x) = 0. $$\n对于整数阶 $n$，$J_n(x)$ 的值通过所提供的三项递推关系联系起来：\n$$ J_{k+1}(x) = \\frac{2k}{x} J_k(x) - J_{k-1}(x), \\quad k \\ge 1, x  0. $$\n这是一个线性二阶齐次差分方程。其通解可以写成两个线性无关解 $J_k(x)$ 和诺伊曼函数（Neumann function，第二类贝塞尔函数）$Y_k(x)$ 的线性组合。因此，由该递推关系生成的任何数值序列 $f_k$ 都可以表示为\n$$ f_k = A \\cdot J_k(x) + B \\cdot Y_k(x), $$\n其中 $A$ 和 $B$ 是由初始条件决定的常数。\n\n递推关系的稳定性关键取决于大阶数 $k$ 时 $J_k(x)$ 和 $Y_k(x)$ 的渐近行为。对于固定的实数 $x  0$，当 $k \\to \\infty$ 时：\n$$ J_k(x) \\sim \\frac{1}{\\sqrt{2\\pi k}} \\left(\\frac{ex}{2k}\\right)^k \\to 0 $$\n$$ Y_k(x) \\sim -\\sqrt{\\frac{2}{\\pi k}} \\left(\\frac{2k}{ex}\\right)^k \\to -\\infty $$\n$J_k(x)$ 被称为“最小”解，因为其数值迅速减小，而 $Y_k(x)$ 是“主导”解，因为其数值无界增长。数值方案的稳定性取决于它如何传播初始浮点表示误差，这些误差不可避免地会引入主导解 $Y_k(x)$ 的一个非零分量。\n\n1.  **前向（向上）递推**：\n    前向方案从 $J_0(x)$ 和 $J_1(x)$ 的精确已知基准值开始，计算序列 $J_2(x), J_3(x), \\dots, J_n(x)$。设计算值为 $\\tilde{J}_k(x)$。由于有限的机器精度，初始值会存在微小误差：\n    $$ \\tilde{J}_0(x) = J_0(x) + \\epsilon_0 $$\n    $$ \\tilde{J}_1(x) = J_1(x) + \\epsilon_1 $$\n    这些误差会将主导解 $Y_k(x)$ 的一个微小但非零的分量引入到计算序列中。然后应用递推关系：\n    $$ \\tilde{J}_{k+1}(x) = \\frac{2k}{x} \\tilde{J}_k(x) - \\tilde{J}_{k-1}(x). $$\n    当 $k  |x|$ 时，因子 $2k/x$ 的绝对值大于 $2$。这会在每一步放大任何存在的误差。不希望出现的 $Y_k(x)$ 分量，最初很小，会迅速增长并最终压倒最小解 $J_k(x)$，导致所有有效数字的损失。因此，对于阶数 $n$ 远大于自变量 $x$ 的情况，该方法是数值不稳定的。相反，对于 $n \\ll |x|$，因子 $2k/x$ 很小，递推是稳定的。\n\n2.  **后向（向下）递推**：\n    该技术是 Miller's Algorithm 的一种形式，它利用了反向递推的稳定性。将关系式改写为计算阶数递减的项：\n    $$ J_{k-1}(x) = \\frac{2k}{x} J_k(x) - J_{k+1}(x). $$\n    我们从一个选择得足够大的索引 $M$ 开始（例如，$M \\gg n$ 和 $M \\gg |x|$）。我们用任意值初始化序列，例如 $f_{M+1}=0$ 和 $f_M=1$，这可以看作是 $J_M(x)$ 和 $Y_M(x)$ 的任意线性组合。向下迭代时，主导解现在是 $J_k(x)$（当 $k$ 从 $M$ 递减时它会增长），而之前的主导解 $Y_k(x)$ 现在是最小解（当 $k$ 递减时它会减小）。来自任意初始值的 $Y_k(x)$ 的任何分量都会被迅速抑制。经过足够次数的迭代后，计算出的序列 $f_k$ 与期望的解 $J_k(x)$ 成正比：\n    $$ f_k \\approx C \\cdot J_k(x) \\quad \\text{对于 } k  M. $$\n    比例常数 $C$ 通过使用已知值或求和恒等式对序列进行归一化来确定。按照规定，我们使用 $J_0(x)$ 的可信参考值进行归一化：\n    $$ C = \\frac{J_0^{\\mathrm{ref}}(x)}{f_0}. $$\n    则 $J_n(x)$ 的最终近似由下式给出：\n    $$ J_n^{\\mathrm{bwd}}(x) = \\frac{J_0^{\\mathrm{ref}}(x)}{f_0} f_n. $$\n    只要 $M$ 选择得足够大，该方法对所有 $n$ 都是数值稳定的。一个实际的选择是 $M = n + k_0$，其中 $k_0$ 是一个安全余量，例如 $k_0 = 50$。\n\n3.  **实现细节**：\n    可信参考值 $J_n^{\\mathrm{ref}}(x)$，包括基准情形 $J_0^{\\mathrm{ref}}(x)$ 和 $J_1^{\\mathrm{ref}}(x)$，将从 `scipy.special.jv` 函数中获得，这是一个高质量、可靠的实现。对于每个测试用例 $(x,n)$，我们计算 $J_n^{\\mathrm{fwd}}(x)$ 和 $J_n^{\\mathrm{bwd}}(x)$，然后使用以下公式计算它们各自相对于 $J_n^{\\mathrm{ref}}(x)$ 的相对误差：\n    $$ e_{\\mathrm{rel}} = \\frac{\\left|J_n^{\\mathrm{approx}}(x) - J_n^{\\mathrm{ref}}(x)\\right|}{\\max\\left(\\left|J_n^{\\mathrm{ref}}(x)\\right|, \\delta\\right)}, $$\n    其中小的正则化参数 $\\delta = 10^{-300}$ 用于防止除以零或次正规数。\n\n预期是在 $n  x$ 的情况下，前向递推会显示出较大的误差，而后向递推将保持准确。在 $n \\le x$ 的情况下，两种方法都应产生准确的结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import jv\n\ndef solve():\n    \"\"\"\n    Computes and compares the numerical stability of forward and backward recurrence\n    for the cylindrical Bessel function of the first kind, J_n(x).\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (10.0, 20),\n        (1.0, 20),\n        (50.0, 20),\n        (25.0, 60),\n        (5.0, 5),\n    ]\n\n    # Regularization parameter for relative error calculation\n    delta = 1.0e-300\n\n    results = []\n    \n    for x, n in test_cases:\n        # 0. Obtain trusted reference values from SciPy\n        j_ref_n = jv(n, x)\n        j_ref_0 = jv(0, x)\n        j_ref_1 = jv(1, x)\n\n        # 1. Forward (upward) recurrence\n        # J_k+1(x) = (2k/x) * J_k(x) - J_k-1(x)\n        j_fwd_array = np.zeros(n + 1, dtype=np.float64)\n        if n >= 0:\n            j_fwd_array[0] = j_ref_0\n        if n >= 1:\n            j_fwd_array[1] = j_ref_1\n        \n        for k in range(1, n):\n            j_fwd_array[k + 1] = (2.0 * k / x) * j_fwd_array[k] - j_fwd_array[k - 1]\n        \n        j_approx_fwd = j_fwd_array[n]\n\n        # 2. Backward (downward) recurrence (Miller's algorithm)\n        # J_k-1(x) = (2k/x) * J_k(x) - J_k+1(x)\n        m = n + 50  # Start from a sufficiently large order M >> n, |x|\n        f = np.zeros(m + 2, dtype=np.float64)\n        f[m + 1] = 0.0  # Arbitrary starting values\n        f[m] = 1.0\n\n        for k in range(m, 0, -1):\n            f[k - 1] = (2.0 * k / x) * f[k] - f[k + 1]\n\n        # Normalize the sequence using the trusted J_0(x)\n        if f[0] != 0:\n            normalization_constant = j_ref_0 / f[0]\n            j_approx_bwd = normalization_constant * f[n]\n        else:\n            # This case is highly unlikely but handle for robustness\n            j_approx_bwd = np.nan\n\n        # 3. Calculate relative errors\n        # e_rel = |approx - ref| / max(|ref|, delta)\n        \n        # Forward error\n        numerator_fwd = np.abs(j_approx_fwd - j_ref_n)\n        denominator_fwd = np.maximum(np.abs(j_ref_n), delta)\n        e_rel_fwd = numerator_fwd / denominator_fwd\n        \n        # Backward error\n        numerator_bwd = np.abs(j_approx_bwd - j_ref_n)\n        denominator_bwd = np.maximum(np.abs(j_ref_n), delta)\n        e_rel_bwd = numerator_bwd / denominator_bwd\n\n        results.extend([e_rel_fwd, e_rel_bwd])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2420035"}]}