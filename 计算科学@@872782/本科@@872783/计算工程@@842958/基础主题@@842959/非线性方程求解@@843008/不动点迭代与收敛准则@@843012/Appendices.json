{"hands_on_practices": [{"introduction": "理论知识的价值在于应用，现在我们将通过一系列动手实践来深化对不动点迭代的理解。第一个练习将探讨如何策略性地设计迭代格式以实现更快的收敛速度。虽然 $|g'(r)|  1$ 保证了收敛，但 $g'(r)$ 的具体值决定了收敛的快慢，当 $g'(r)=0$ 时能达到最理想的二次收敛。这项实践将指导你如何通过调整松弛法 $g(x) = x - \\alpha f(x)$ 中的参数 $\\alpha$ 来精确实现这一目标，从而将一个普通的迭代法转变为一个高效的求解工具 [@problem_id:2393364]。", "problem": "在计算工程中，不动点迭代是求解控制方程离散化后产生的非线性代数方程组的基本方法。考虑标量非线性方程\n$$\nf(x) = x^{3} - 6x^{2} + 11x - 6 = 0,\n$$\n该方程在 $x = 1$，$x = 2$ 和 $x = 3$ 处有三个简单的实根。对于每个根 $r_{k} \\in \\{1, 2, 3\\}$，构造一个松弛形式的不动点迭代\n$$\nx_{n+1} = g_{k}(x_{n}), \\quad g_{k}(x) = x - \\alpha_{k}\\, f(x),\n$$\n其中常数参数 $\\alpha_{k}$ 的选择应使迭代在目标根 $r_{k}$ 附近至少是二次收敛的。然后确定分别对应于 $r_{1} = 1$，$r_{2} = 2$ 和 $r_{3} = 3$ 的 $\\alpha_{1}$，$\\alpha_{2}$ 和 $\\alpha_{3}$ 的精确值，并计算\n$$\nS = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}.\n$$\n提供 $S$ 的单个精确值。不需要四舍五入。", "solution": "在尝试求解之前，对问题陈述进行验证。\n\n步骤1：提取已知条件。\n提供的信息如下：\n- 非线性标量方程为 $f(x) = x^{3} - 6x^{2} + 11x - 6 = 0$。\n- 方程有三个简单的实根：$r_{1} = 1$，$r_{2} = 2$ 和 $r_{3} = 3$。\n- 为每个根 $r_{k}$ 给定一个不动点迭代格式：$x_{n+1} = g_{k}(x_{n})$。\n- 迭代函数定义为松弛形式：$g_{k}(x) = x - \\alpha_{k}\\, f(x)$。\n- 参数 $\\alpha_{k}$ 必须被选择，以使迭代在对应根 $r_{k}$ 附近至少是二次收敛的。\n- 目标是计算总和 $S = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}$。\n\n步骤2：使用提取的已知条件进行验证。\n对问题的有效性进行评估：\n- **科学依据：** 该问题植根于数值方法的基本理论，特别是不动点迭代及其收敛准则。收敛阶（线性、二次等）的概念是计算科学与工程中的一个标准课题。该问题是科学合理的。\n- **适定性：** 该问题提供了明确的目标和充分的信息。“至少二次收敛”的条件对迭代函数的导数施加了特定的数学约束，这使得每个参数 $\\alpha_{k}$ 都能被唯一确定。该问题是适定的。\n- **客观性：** 该问题使用精确的数学语言陈述，没有歧义、主观性或意见。\n\n该问题没有任何科学上不合理、不完整、矛盾或含糊不清的缺陷。它是数值分析中一个标准的、可形式化的问题。\n\n步骤3：结论与行动。\n问题被认为是有效的。将推导解答。\n\n问题的核心在于分析不动点迭代 $x_{n+1} = g(x_{n})$ 的收敛速度。如果 $r$ 是 $g(x)$ 的一个不动点（即 $g(r) = r$），并且迭代函数在 $r$ 的一个邻域内是压缩映射，则不动点迭代收敛于根 $r$。收敛阶由 $g(x)$ 在不动点 $r$ 处的导数值决定。\n\n为了使迭代局部至少是二次收敛的，迭代函数的一阶导数在不动点处必须为零。即 $g'(r) = 0$。如果满足此条件，$g(x)$ 在 $r$ 附近的泰勒级数展开为：\n$$\ng(x) = g(r) + g'(r)(x-r) + \\frac{g''(r)}{2!}(x-r)^{2} + O((x-r)^{3})\n$$\n当 $g(r)=r$ 且 $g'(r)=0$ 时，上式变为：\n$$\ng(x) - r = \\frac{g''(r)}{2}(x-r)^{2} + O((x-r)^{3})\n$$\n令 $e_{n} = x_{n} - r$ 为第 $n$ 次迭代的误差。则 $x_{n} = r + e_{n}$，且 $x_{n+1} = g(x_{n})$。\n$$\ne_{n+1} = x_{n+1} - r = g(x_{n}) - r = g(r + e_{n}) - r = \\frac{g''(r)}{2} e_{n}^{2} + O(e_{n}^{3})\n$$\n这种关系，即第 $n+1$ 步的误差与第 $n$ 步误差的平方成正比，是二次收敛的定义，前提是 $g''(r) \\neq 0$。“至少二次”的条件要求 $g'(r)=0$。\n\n对于每个根 $r_k$，迭代函数为 $g_{k}(x) = x - \\alpha_{k} f(x)$。首先，我们确认每个根 $r_k$ 都是 $g_k(x)$ 的不动点。根据定义，$f(r_k) = 0$，所以 $g_{k}(r_{k}) = r_{k} - \\alpha_{k} f(r_{k}) = r_{k} - \\alpha_{k}(0) = r_{k}$。这对任意选择的 $\\alpha_k$ 都成立。\n\n为确保至少二次收敛，我们必须强制执行条件 $g_{k}'(r_{k}) = 0$。我们首先计算 $g_{k}(x)$ 的导数：\n$$\ng_{k}'(x) = \\frac{d}{dx} \\left( x - \\alpha_{k} f(x) \\right) = 1 - \\alpha_{k} f'(x)\n$$\n在根 $r_k$ 处计算该导数并令其为零，得到：\n$$\ng_{k}'(r_{k}) = 1 - \\alpha_{k} f'(r_{k}) = 0\n$$\n求解 $\\alpha_k$，我们发现所需的值是：\n$$\n\\alpha_{k} = \\frac{1}{f'(r_{k})}\n$$\n这假设 $f'(r_k) \\neq 0$，对于问题中陈述的单根，这是成立的。\n\n接下来，我们必须计算给定函数 $f(x) = x^{3} - 6x^{2} + 11x - 6$ 的导数：\n$$\nf'(x) = \\frac{d}{dx} \\left( x^{3} - 6x^{2} + 11x - 6 \\right) = 3x^{2} - 12x + 11\n$$\n现在我们可以为三个根中的每一个计算 $\\alpha_k$ 的值。\n\n对于根 $r_{1} = 1$：\n$$\nf'(1) = 3(1)^{2} - 12(1) + 11 = 3 - 12 + 11 = 2\n$$\n因此，参数 $\\alpha_{1}$ 是：\n$$\n\\alpha_{1} = \\frac{1}{f'(1)} = \\frac{1}{2}\n$$\n\n对于根 $r_{2} = 2$：\n$$\nf'(2) = 3(2)^{2} - 12(2) + 11 = 3(4) - 24 + 11 = 12 - 24 + 11 = -1\n$$\n因此，参数 $\\alpha_{2}$ 是：\n$$\n\\alpha_{2} = \\frac{1}{f'(2)} = \\frac{1}{-1} = -1\n$$\n\n对于根 $r_{3} = 3$：\n$$\nf'(3) = 3(3)^{2} - 12(3) + 11 = 3(9) - 36 + 11 = 27 - 36 + 11 = 2\n$$\n因此，参数 $\\alpha_{3}$ 是：\n$$\n\\alpha_{3} = \\frac{1}{f'(3)} = \\frac{1}{2}\n$$\n\n最后，问题要求计算总和 $S = \\alpha_{1} + \\alpha_{2} + \\alpha_{3}$：\n$$\nS = \\frac{1}{2} + (-1) + \\frac{1}{2} = 1 - 1 = 0\n$$\n$S$ 的值恰好是 $0$。", "answer": "$$\\boxed{0}$$", "id": "2393364"}, {"introduction": "对于一个给定的方程 $f(x) = 0$，将其代数重排为不动点形式 $x = g(x)$ 的方法并非唯一，而不同的选择会对迭代过程产生深远的影响。这个编程练习将让你亲手实现求解同一方程的不同 $g(x)$ 函数。你将会发现，不同的迭代格式可能会收敛到不同的解，甚至完全无法收敛，这将为你提供一个关于吸引不动点、排斥不动点以及吸引盆等概念的直观且深刻的理解 [@problem_id:2393371]。", "problem": "您需要编写一个完整的程序，用于比较标量非线性方程 $e^{x} - 4x = 0$ 在不同形式 $x = g(x)$ 的重排下，不动点迭代的收敛行为和吸引盆。该程序必须是确定性的，且不得需要任何用户输入。\n\n从以下基本原理开始：\n- 函数 $g$ 的不动点定义：一个点 $x^{\\star}$ 满足 $x^{\\star} = g(x^{\\star})$。\n- 不动点迭代：给定初始猜测值 $x_0$，生成序列 $x_{k+1} = g(x_k)$。\n- 源于巴拿赫不动点定理（也称为压缩映射原理）的不动点迭代的充分局部收敛准则：如果 $g$ 是连续可微的，并且在不动点 $x^{\\star}$ 的一个邻域内存在 $|\\lvert g'(x) \\rvert| \\le q  1$，那么对于该邻域内的任何初始值 $x_0$，迭代 $x_{k+1} = g(x_k)$ 都会收敛到 $x^{\\star}$。\n\n程序任务：\n1. 实现非线性函数 $f(x) = e^{x} - 4x$ 及其导数 $f'(x) = e^{x} - 4$。\n2. 实现以下三个不动点映射 $g$：\n   - $g_{\\mathrm{A}}(x) = \\dfrac{e^{x}}{4}$，对所有实数 $x$ 有定义。\n   - $g_{\\mathrm{B}}(x) = \\ln(4x)$，仅在 $x > 0$ 时有定义。\n   - $g_{\\mathrm{N}}(x) = x - \\dfrac{f(x)}{f'(x)}$（写成不动点映射形式的牛顿法），在 $f'(x) \\neq 0$ 时有定义。\n3. 为每个不动点映射实现迭代 $x_{k+1} = g(x_k)$，并遵循以下终止和失败准则：\n   - 如果 $\\lvert x_{k+1} - x_k \\rvert \\le \\varepsilon_x$ 或 $\\lvert f(x_{k+1}) \\rvert \\le \\varepsilon_f$ 之一成立，则视为收敛，其中 $\\varepsilon_x = 10^{-12}$ 且 $\\varepsilon_f = 10^{-12}$。\n   - 如果发生以下任何一种情况，则视为失败：\n     - 下一次迭代超出了映射的定义域（例如，对于 $g_{\\mathrm{B}}$，如果在任何步骤中 $x_k \\le 0$）。\n     - 在任何步骤中产生了非有限值（非数字或无穷大）。\n     - 达到最大迭代次数 $N_{\\max} = 200$ 仍未收敛。\n     - 对于 $g_{\\mathrm{N}}$，在任何步骤中导数的绝对值 $\\lvert f'(x_k) \\rvert$ 低于阈值 $\\tau = 10^{-12}$，因此更新是病态的。\n4. 计算高精度的参考根以用于分类。$f(x) = 0$ 恰好有两个实根：一个在区间 $[0, 0.5]$ 内，一个在区间 $[2, 3]$ 内。使用一个稳健的区间求根方法（例如，二分法或 Brent 方法）计算参考值 $r_1 \\in [0, 0.5]$ 和 $r_2 \\in [2, 3]$，绝对精度至少为 $10^{-14}$。\n5. 吸引盆分类：对于一个收敛的迭代值 $x^{\\star}$，根据其与两个参考根的接近程度进行分类，规则如下：\n   - 如果 $\\lvert x^{\\star} - r_1 \\rvert \\le 10^{-8}$，则分配整数 $0$。\n   - 如果 $\\lvert x^{\\star} - r_2 \\rvert \\le 10^{-8}$，则分配整数 $1$。\n   - 否则分配整数 $-1$。\n   对于失败的迭代，分配整数 $-1$。\n6. 使用以下 $(g,\\ x_0)$ 对的测试套件来探查不同的吸引盆、边界情况和定义域：\n   - $(g_{\\mathrm{A}},\\ x_0 = -1.0)$\n   - $(g_{\\mathrm{A}},\\ x_0 = 0.1)$\n   - $(g_{\\mathrm{A}},\\ x_0 = 0.6)$\n   - $(g_{\\mathrm{A}},\\ x_0 = 2.5)$\n   - $(g_{\\mathrm{B}},\\ x_0 = 0.2)$\n   - $(g_{\\mathrm{B}},\\ x_0 = 2.5)$\n   - $(g_{\\mathrm{B}},\\ x_0 = 1.0)$\n   - $(g_{\\mathrm{B}},\\ x_0 = -0.5)$\n   - $(g_{\\mathrm{N}},\\ x_0 = -1.0)$\n   - $(g_{\\mathrm{N}},\\ x_0 = 0.5)$\n   - $(g_{\\mathrm{N}},\\ x_0 = 4.0)$\n   - $(g_{\\mathrm{N}},\\ x_0 = \\ln 4)$\n7. 输出规格：您的程序应生成单行输出，其中包含测试套件的分类结果，顺序与上面列出的相同，形式为方括号内由逗号分隔的整数列表（例如，$[0,0,1,-1]$）。不应打印任何额外文本。\n\n重要说明：\n- 此问题不涉及角度，因此不需要角度单位。\n- 不涉及物理单位。\n- 通过严格应用上述定义域检查和失败准则，确保数值的稳健性。", "solution": "问题陈述已经过严格验证，并被认为是合理的。这是一个计算工程领域的适定问题，其基础是数值分析的既定原理，特别是不动点迭代理论和牛顿法。所有参数、函数和准则都已足够精确地定义，以确保存在唯一的、确定性的解。我们继续进行分析并推导解决方案。\n\n目标是分析三种不同不动点迭代格式在求解非线性方程 $f(x) = e^{x} - 4x = 0$ 时的收敛性。\n\n**1. 高精度根的确定**\n\n方程 $f(x) = 0$ 等价于寻找 $y = e^x$ 和 $y = 4x$ 的交点。图形分析显示存在两个实根。问题陈述正确地指出了包含这些根的区间。为验证这一点，我们在区间边界处计算 $f(x)$ 的值：\n- 对于区间 $[0, 0.5]$：\n  $f(0) = e^{0} - 4(0) = 1  0$。\n  $f(0.5) = e^{0.5} - 4(0.5) = \\sqrt{e} - 2 \\approx 1.6487 - 2 = -0.3513  0$。\n- 对于区间 $[2, 3]$：\n  $f(2) = e^{2} - 4(2) = e^2 - 8 \\approx 7.3891 - 8 = -0.6109  0$。\n  $f(3) = e^{3} - 4(3) = e^3 - 12 \\approx 20.0855 - 12 = 8.0855 > 0$。\n\n由于 $f(x)$ 是连续的，根据介值定理，每个区间内都保证存在一个根。我们将这些根记为 $r_1 \\in [0, 0.5]$ 和 $r_2 \\in [2, 3]$。为了作为分类的基准，使用稳健的数值方法（特别是 Brent 方法）将这些根计算到高精度（绝对容差至少为 $10^{-14}$）。\n\n**2. 不动点映射的收敛性分析**\n\n不动点迭代 $x_{k+1} = g(x_k)$ 到不动点 $x^{\\star}$ 的收敛性取决于迭代映射导数的绝对值 $\\lvert g'(x^{\\star}) \\rvert$。对于局部收敛，$\\lvert g'(x^{\\star}) \\rvert  1$ 是充分条件。如果 $\\lvert g'(x^{\\star}) \\rvert > 1$，则该不动点是排斥的，迭代将会发散。如果 $\\lvert g'(x^{\\star}) \\rvert = 1$，则检验是不确定的，需要更详细的分析。\n\n根据定义，$f(x)=0$ 的根 $r_1$ 和 $r_2$ 是任何有效重排形式 $x=g(x)$ 的不动点。在这些点上，$e^{x^\\star} = 4x^\\star$。\n\n- **映射 A**: $g_{\\mathrm{A}}(x) = \\dfrac{e^x}{4}$。\n  其导数为 $g'_{\\mathrm{A}}(x) = \\dfrac{e^x}{4}$。\n  - 在第一个根 $r_1$ 处：$g'_{\\mathrm{A}}(r_1) = \\dfrac{e^{r_1}}{4} = \\dfrac{4r_1}{4} = r_1$。数值上，$r_1 \\approx 0.3574$。因此，$\\lvert g'_{\\mathrm{A}}(r_1) \\rvert \\approx 0.3574  1$。不动点 $r_1$ 是吸引的。\n  - 在第二个根 $r_2$ 处：$g'_{\\mathrm{A}}(r_2) = \\dfrac{e^{r_2}}{4} = \\dfrac{4r_2}{4} = r_2$。数值上，$r_2 \\approx 2.1533$。因此，$\\lvert g'_{\\mathrm{A}}(r_2) \\rvert \\approx 2.1533 > 1$。不动点 $r_2$ 是排斥的。\n  因此，使用 $g_{\\mathrm{A}}(x)$ 的迭代如果从足够近的初值开始，预期会收敛到 $r_1$，并从 $r_2$ 的邻域发散。\n\n- **映射 B**: $g_{\\mathrm{B}}(x) = \\ln(4x)$，定义于 $x > 0$。\n  其导数为 $g'_{\\mathrm{B}}(x) = \\dfrac{1}{4x} \\cdot 4 = \\dfrac{1}{x}$。\n  - 在第一个根 $r_1$ 处：$\\lvert g'_{\\mathrm{B}}(r_1) \\rvert = \\dfrac{1}{r_1} \\approx \\dfrac{1}{0.3574} \\approx 2.798 > 1$。不动点 $r_1$ 是排斥的。\n  - 在第二个根 $r_2$ 处：$\\lvert g'_{\\mathrm{B}}(r_2) \\rvert = \\dfrac{1}{r_2} \\approx \\dfrac{1}{2.1533} \\approx 0.4644  1$。不动点 $r_2$ 是吸引的。\n  此映射表现出与 $g_{\\mathrm{A}}(x)$ 互补的行为。迭代预期会收敛到 $r_2$ 并从 $r_1$ 发散。\n\n- **映射 N (牛顿法)**: $g_{\\mathrm{N}}(x) = x - \\dfrac{f(x)}{f'(x)}$。\n  这里，$f(x) = e^x - 4x$ 且 $f'(x) = e^x - 4$。二阶导数是 $f''(x) = e^x$。\n  不动点映射的导数是 $g'_{\\mathrm{N}}(x) = \\dfrac{f(x)f''(x)}{(f'(x))^2}$。\n  在任何单根 $x^{\\star}$ 处（其中 $f(x^{\\star}) = 0$ 且 $f'(x^{\\star}) \\neq 0$），导数为 $g'_{\\mathrm{N}}(x^{\\star}) = 0$。\n  对于我们的问题，$f'(r_1) = e^{r_1} - 4 = 4r_1 - 4 \\neq 0$ 且 $f'(r_2) = e^{r_2} - 4 = 4r_2 - 4 \\neq 0$，所以两个根都是单根。\n  条件 $g'_{\\mathrm{N}}(x^{\\star}) = 0$ 意味着二次收敛，其速度极快。对于牛顿法而言，$r_1$ 和 $r_2$ 都是超吸引不动点。如果迭代遇到 $f'(x) = 0$ 的点，即 $x = \\ln(4)$，则会失败。该点对应于 $f(x)$ 的局部最小值。\n\n**3. 算法实现与执行**\n\n解决方案将通过一个结构化的、确定性的过程在 Python 程序中实现。\n1.  **初始化**: 定义所有常量：收敛容差 $\\varepsilon_x = 10^{-12}$ 和 $\\varepsilon_f = 10^{-12}$，最大迭代次数 $N_{\\max} = 200$，牛顿法导数阈值 $\\tau = 10^{-12}$，以及分类容差 $10^{-8}$。\n2.  **参考根计算**: 使用 `scipy.optimize.brentq` 计算根 $r_1$ 和 $r_2$，其精度高于问题要求。\n3.  **函数定义**: 实现函数 $f(x)$、$f'(x)$、$g_{\\mathrm{A}}(x)$、$g_{\\mathrm{B}}(x)$ 和 $g_{\\mathrm{N}}(x)$。根据规定，$g_{\\mathrm{B}}$ 和 $g_{\\mathrm{N}}$ 的实现包含内部检查，用于在出现定义域违规（对于 $g_{\\mathrm{B}}$，$x_k \\le 0$）或病态更新（对于 $g_{\\mathrm{N}}$，$\\lvert f'(x_k) \\rvert \\le \\tau$）时引发异常。\n4.  **迭代求解器**: 一个主函数对给定的映射 $g$ 和初始猜测值 $x_0$ 执行不动点迭代 $x_{k+1} = g(x_k)$。该函数最多运行 $N_{\\max}$ 步。在每一步中，它使用准则 $\\lvert x_{k+1} - x_k \\rvert \\le \\varepsilon_x$ 或 $\\lvert f(x_{k+1}) \\rvert \\le \\varepsilon_f$ 检查收敛性。它还处理因非有限结果或映射函数引发的异常而导致的失败。该函数返回一个状态（'converged' 或 'failed'）和最终迭代值。\n5.  **分类**: 一个独立的分类函数接收求解器的输出。如果状态是 'failed'，它返回 $-1$。如果状态是 'converged'，它使用 $\\lvert x^{\\star} - r \\rvert \\le 10^{-8}$ 准则将最终迭代值 $x^{\\star}$ 与参考根 $r_1$ 和 $r_2$ 进行比较，并相应地返回 $0$、$1$ 或 $-1$。\n6.  **测试套件执行**: 程序遍历所提供的测试用例列表。对于每个 $(g, x_0)$ 对，它调用求解器和分类器，并处理初始猜测值已在映射定义域之外的边界情况（例如，对于 $g_{\\mathrm{B}}$，$x_0 \\le 0$）。\n7.  **最终输出**: 整数分类结果被收集到一个列表中，并以指定格式打印：`[c_1,c_2,...,c_N]`。\n\n这种系统化的方法确保了所有问题要求都得到精确和稳健的满足。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Solves the given problem by comparing fixed-point iterations for f(x) = e^x - 4x = 0.\n    \"\"\"\n    # Define problem parameters\n    EPS_X = 1e-12\n    EPS_F = 1e-12\n    MAX_ITER = 200\n    DERIV_THRESHOLD = 1e-12\n    CLASSIFICATION_TOL = 1e-8\n    ROOT_FINDING_TOL = 1e-15\n\n    # Task 1  4: Implement f(x) and compute high-accuracy reference roots.\n    # The nonlinear function f(x) = e^x - 4x.\n    def f(x):\n        try:\n            val = np.exp(x) - 4.0 * x\n        except OverflowError:\n            val = np.inf\n        return val\n\n    # Its derivative f'(x) = e^x - 4.\n    def f_prime(x):\n        try:\n            val = np.exp(x) - 4.0\n        except OverflowError:\n            val = np.inf\n        return val\n\n    # Use a robust bracketed method to find reference roots r1 and r2.\n    r1 = brentq(f, 0.0, 0.5, xtol=ROOT_FINDING_TOL)\n    r2 = brentq(f, 2.0, 3.0, xtol=ROOT_FINDING_TOL)\n\n    # Task 2: Implement the three fixed-point maps.\n    # g_A(x) = e^x / 4\n    def g_A(x):\n        return np.exp(x) / 4.0\n\n    # g_B(x) = ln(4x), defined for x > 0.\n    def g_B(x):\n        if x = 0:\n            raise ValueError(\"Domain error for g_B: x must be > 0.\")\n        return np.log(4.0 * x)\n\n    # g_N(x) = x - f(x)/f'(x) (Newton's method).\n    def g_N(x):\n        f_prime_val = f_prime(x)\n        if abs(f_prime_val)  DERIV_THRESHOLD:\n            raise ValueError(\"Derivative near zero for g_N.\")\n        return x - f(x) / f_prime_val\n\n    g_map = {'A': g_A, 'B': g_B, 'N': g_N}\n\n    # Task 3  5: Implement the iteration and classification logic.\n    def run_iteration_and_classify(g_name, x0):\n        # Handle cases where initial guess is invalid.\n        if g_name == 'B' and x0 = 0:\n            return -1\n        if g_name == 'N' and abs(f_prime(x0))  DERIV_THRESHOLD:\n            return -1\n\n        g_func = g_map[g_name]\n        x_k = x0\n\n        for _ in range(MAX_ITER):\n            try:\n                x_k_plus_1 = g_func(x_k)\n            except (ValueError, OverflowError):\n                # Catches domain errors from g_B, derivative error from g_N,\n                # and overflow in exp().\n                return -1\n\n            # Check for failure due to non-finite values.\n            if not np.isfinite(x_k_plus_1):\n                return -1\n\n            # Check for convergence.\n            converged_x_step = abs(x_k_plus_1 - x_k) = EPS_X\n            converged_f_val = abs(f(x_k_plus_1)) = EPS_F\n            \n            if converged_x_step or converged_f_val:\n                x_star = x_k_plus_1\n                # Classify the converged root.\n                if abs(x_star - r1) = CLASSIFICATION_TOL:\n                    return 0\n                elif abs(x_star - r2) = CLASSIFICATION_TOL:\n                    return 1\n                else:\n                    return -1 # Converged to a non-target or with insufficient precision for classification\n            \n            x_k = x_k_plus_1\n\n        # Failure due to reaching max iterations.\n        return -1\n\n    # Task 6: Define and run the test suite.\n    test_cases = [\n        ('A', -1.0),\n        ('A', 0.1),\n        ('A', 0.6),\n        ('A', 2.5),\n        ('B', 0.2),\n        ('B', 2.5),\n        ('B', 1.0),\n        ('B', -0.5), # Fails on initial condition\n        ('N', -1.0),\n        ('N', 0.5),\n        ('N', 4.0),\n        ('N', np.log(4.0)) # Fails on initial condition\n    ]\n\n    results = []\n    for g_name, x0 in test_cases:\n        result = run_iteration_and_classify(g_name, x0)\n        results.append(result)\n\n    # Task 7: Output a single line in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\n# Execute the main function.\nsolve()\n```", "id": "2393371"}, {"introduction": "现在，让我们将不动点迭代法应用于解决一个真实的工程问题。这项实践将聚焦于流体力学中著名的、用于计算管道摩擦系数的隐式 Colebrook-White 方程。你不仅需要实现一个标准的不动点迭代来求解这一关键参数，还将探索并应用 Steffensen 加速法——一种能将线性收敛提升至二次收敛的强大技术。通过这个练习，你将体验到如何为满足实际工程需求而优化数值工具的效率和鲁棒性 [@problem_id:2393339]。", "problem": "考虑用于圆形管道中完全湍流内部流动的 Darcy 摩擦系数，记为 $f$。对于给定的雷诺数 $Re$（无量纲）和相对粗糙度 $k$（无量纲），隐式 Colebrook-White 关系式将 $f$ 定义为\n$$\n\\frac{1}{\\sqrt{f}} = -2 \\log_{10}\\!\\left(\\frac{k}{3.7} + \\frac{2.51}{Re \\sqrt{f}}\\right).\n$$\n此处 $\\log_{10}$ 表示以 10 为底的对数，$Re \\ge 4000$，$k \\ge 0$。未知数 $f$ 是无量纲的，且为严格正数。\n\n编写一个完整、可运行的程序，对于下面列出的每个测试用例，使用两种方法计算 Colebrook-White 关系式唯一的物理相关根 $f$：\n- 应用于隐式方程的数学一致不动点公式的标准不动点迭代法，以及\n- 应用于相同不动点映射的 Steffensen 加速法。\n\n对于每种方法和每个测试用例，生成：\n- 收敛的 $f$ 值，四舍五入到 $12$ 位小数，\n- 所用的总迭代步数（整数计数），以及\n- 执行的不动点映射评估总次数（整数计数）。\n\n对两种方法采用以下收敛和运行时控制：\n- 连续摩擦系数估计值的绝对差准则：当 $|f_{n+1} - f_n| \\le \\tau$ 且 $\\tau = 10^{-12}$ 时终止，\n- 允许的迭代步数有硬性上限：标准不动点法最多 $N_{\\max}^{(\\mathrm{std})} = 200$ 步，Steffensen 法最多 $N_{\\max}^{(\\mathrm{st})} = 100$ 步。\n\n测试套件（每对为 $(Re,k)$，两者均为无量纲）：\n- 情况 $1$：$(Re, k) = (4 \\times 10^{3}, 0)$，\n- 情况 $2$：$(Re, k) = (10^{5}, 10^{-4})$，\n- 情况 $3$：$(Re, k) = (10^{6}, 10^{-3})$，\n- 情况 $4$：$(Re, k) = (10^{7}, 5 \\times 10^{-3})$，\n- 情况 $5$：$(Re, k) = (5 \\times 10^{4}, 5 \\times 10^{-5})$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个测试用例按上述情况的顺序列为嵌套列表。\n- 对于每个测试用例，嵌套列表必须按\n$[f_{\\mathrm{std}}, n_{\\mathrm{std}}, e_{\\mathrm{std}}, f_{\\mathrm{st}}, n_{\\mathrm{st}}, e_{\\mathrm{st}}]$ 的顺序排列，\n其中 $f_{\\mathrm{std}}$ 和 $f_{\\mathrm{st}}$ 是四舍五入到 12 位小数的摩擦系数，$n_{\\mathrm{std}}$ 和 $n_{\\mathrm{st}}$ 是迭代次数，$e_{\\mathrm{std}}$ 和 $e_{\\mathrm{st}}$ 是不动点映射的评估次数。单行输出不得包含任何空白字符。例如：\n“[ [0.020000000000,12,12,0.020000000000,4,8], ... ]”（此示例仅用于说明）。", "solution": "所述问题是有效的。它涉及 Colebrook-White 方程的数值解，该方程是流体力学中一个成熟的基础关系式，用于确定湍流管道流中的摩擦系数。该问题具有科学依据，提法恰当，所有参数和条件的规定都足够清晰，可以得到唯一且可验证的解。\n\n任务是对于给定的雷诺数 $Re$ 和相对粗糙度 $k$，找到隐式方程的根 $f$：\n$$\n\\frac{1}{\\sqrt{f}} = -2 \\log_{10}\\!\\left(\\frac{k}{3.7} + \\frac{2.51}{Re \\sqrt{f}}\\right)\n$$\n这必须使用两种迭代数值方法来完成。\n\n**1. 不动点公式**\n为了应用不动点迭代，必须将方程重排为 $f = g(f)$ 的形式。通过将 $f$ 分离到左侧，可以导出一个稳定且收敛的映射 $g(f)$。设 Colebrook-White 方程的右侧表示为 $A(f)$。\n$$\nA(f) = -2 \\log_{10}\\!\\left(\\frac{k}{3.7} + \\frac{2.51}{Re \\sqrt{f}}\\right)\n$$\n那么方程为 $\\frac{1}{\\sqrt{f}} = A(f)$。解出 $f$ 可得：\n$$\n\\sqrt{f} = \\frac{1}{A(f)} \\implies f = \\left(\\frac{1}{A(f)}\\right)^2\n$$\n这给出了不动点映射函数 $g(f)$：\n$$\ng(f) = \\left(\\frac{1}{-2 \\log_{10}\\!\\left(\\frac{k}{3.7} + \\frac{2.51}{Re \\sqrt{f}}\\right)}\\right)^2\n$$\n相应的迭代格式为 $f_{n+1} = g(f_n)$，其中 $f_n$ 是第 $n$ 次迭代时摩擦系数的估计值。\n\n**2. 初始猜测**\n开始迭代需要一个初始猜测值 $f_0$。通过 Colebrook-White 方程的显式近似，可以得到一个稳健的 $f_0$ 选择。Haaland 方程提供了这样的一个近似：\n$$\n\\frac{1}{\\sqrt{f_0}} \\approx -1.8 \\log_{10}\\!\\left(\\left(\\frac{k}{3.7}\\right)^{1.11} + \\frac{6.9}{Re}\\right)\n$$\n解出 $f_0$ 可以得到一个接近真实根的高质量初始值，从而确保快速收敛。\n\n**3. 数值方案与收敛准则**\n\n**a) 标准不动点迭代法**\n标准不动点迭代算法的步骤如下：\n1.  从一个初始猜测值 $f_0$ 开始。\n2.  对于 $n = 0, 1, 2, \\ldots$，使用映射计算下一个估计值：$f_{n+1} = g(f_n)$。\n3.  当连续估计值之间的绝对差小于指定的容差 $\\tau = 10^{-12}$，即 $|f_{n+1} - f_n| \\le \\tau$ 时，过程终止。\n4.  迭代次数 $n_{\\mathrm{std}}$ 是计算映射 $f_{n+1} = g(f_n)$ 的总次数。\n5.  评估次数 $e_{\\mathrm{std}}$ 是调用函数 $g(f)$ 的总次数。对于此方法，$e_{\\mathrm{std}} = n_{\\mathrm{std}}$。该过程的迭代次数上限为 $N_{\\max}^{(\\mathrm{std})} = 200$。\n\n**b) Steffensen 法**\nSteffensen 法是一种加速技术，通常将不动点迭代的线性收敛转换为二次收敛。它使用来自底层不动点序列的三个点来外插一个更好的估计值。\n1.  从一个初始猜测值 $f_0$ 开始。\n2.  对于每个步骤 $n$：\n    a. 设当前估计值为 $p_0 = f_n$。\n    b. 使用映射 $g$ 生成两个中间值：$p_1 = g(p_0)$ 和 $p_2 = g(p_1)$。\n    c. 使用 Aitken's $\\Delta^2$ 公式计算加速更新：\n    $$\n    f_{n+1} = p_0 - \\frac{(p_1 - p_0)^2}{p_2 - 2p_1 + p_0}\n    $$\n3.  终止基于相同的准则：$|f_{n+1} - f_n| \\le \\tau = 10^{-12}$。\n4.  上述一个完整周期构成 Steffensen 法的单次迭代步。迭代次数为 $n_{\\mathrm{st}}$。\n5.  由于每个步骤需要两次对映射函数 $g(f)$ 的评估，总评估次数为 $e_{\\mathrm{st}} = 2 \\times n_{\\mathrm{st}}$。该过程的迭代次数上限为 $N_{\\max}^{(\\mathrm{st})} = 100$。\n\n实现过程将通过定义映射 $g(f)$、初始猜测和两个迭代求解器的函数来进行。然后将这些函数应用于每个测试用例以生成所需的结果。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Colebrook-White equation for multiple test cases using both\n    standard fixed-point iteration and Steffensen's acceleration.\n    \"\"\"\n\n    # Test suite: each element is a tuple (Reynolds number, relative roughness)\n    test_cases = [\n        (4e3, 0.0),\n        (1e5, 1e-4),\n        (1e6, 1e-3),\n        (1e7, 5e-3),\n        (5e4, 5e-5),\n    ]\n\n    # Convergence and runtime controls\n    TOLERANCE = 1e-12\n    MAX_ITER_STD = 200\n    MAX_ITER_ST = 100\n\n    def g(f, Re, k):\n        \"\"\"\n        The fixed-point mapping function g(f) derived from the Colebrook-White equation.\n        \"\"\"\n        if f = 0:\n            # Physically, f must be positive. This avoids domain errors.\n            return np.inf\n        \n        log_arg = k / 3.7 + 2.51 / (Re * np.sqrt(f))\n        \n        if log_arg = 0:\n            # Argument to log10 must be positive.\n            return np.inf\n            \n        return (-2.0 * np.log10(log_arg))**-2.0\n\n    def haaland_initial_guess(Re, k):\n        \"\"\"\n        Calculates an initial guess for f using the Haaland equation.\n        \"\"\"\n        if Re  4000:\n            # Haaland is for turbulent flow\n            return 64.0 / Re  # Laminar flow friction factor, as a fallback\n        \n        # Note: (k/3.7)**1.11 is safe since k >= 0\n        rhs = -1.8 * np.log10((k / 3.7)**1.11 + 6.9 / Re)\n        f0 = (1.0 / rhs)**2\n        return f0\n\n    def standard_fixed_point(Re, k, f_initial):\n        \"\"\"\n        Performs standard fixed-point iteration.\n        Returns: (converged_f, iteration_count, evaluation_count)\n        \"\"\"\n        f_n = f_initial\n        eval_count = 0\n        for i in range(1, MAX_ITER_STD + 1):\n            f_n_plus_1 = g(f_n, Re, k)\n            eval_count += 1\n            if abs(f_n_plus_1 - f_n) = TOLERANCE:\n                return f_n_plus_1, i, eval_count\n            f_n = f_n_plus_1\n        # Return last value if not converged\n        return f_n, MAX_ITER_STD, eval_count\n\n    def steffensen_method(Re, k, f_initial):\n        \"\"\"\n        Performs Steffensen's accelerated fixed-point iteration.\n        Returns: (converged_f, iteration_count, evaluation_count)\n        \"\"\"\n        f_n = f_initial\n        eval_count = 0\n        for i in range(1, MAX_ITER_ST + 1):\n            p0 = f_n\n            \n            p1 = g(p0, Re, k)\n            p2 = g(p1, Re, k)\n            eval_count += 2\n            \n            denominator = p2 - 2 * p1 + p0\n            \n            if abs(denominator)  1e-20:  # Avoid division by zero, fallback to a standard step\n                f_n_plus_1 = p2\n            else:\n                f_n_plus_1 = p0 - (p1 - p0)**2 / denominator\n\n            if abs(f_n_plus_1 - f_n) = TOLERANCE:\n                return f_n_plus_1, i, eval_count\n            f_n = f_n_plus_1\n        # Return last value if not converged\n        return f_n, MAX_ITER_ST, eval_count\n\n    all_results_str = []\n    for Re, k in test_cases:\n        f0 = haaland_initial_guess(Re, k)\n        \n        # Standard Fixed-Point Iteration\n        f_std, n_std, e_std = standard_fixed_point(Re, k, f0)\n        \n        # Steffensen's Method\n        f_st, n_st, e_st = steffensen_method(Re, k, f0)\n        \n        # Format results for the current case\n        f_std_str = f\"{f_std:.12f}\"\n        f_st_str = f\"{f_st:.12f}\"\n        \n        case_str = f\"[{f_std_str},{n_std},{e_std},{f_st_str},{n_st},{e_st}]\"\n        all_results_str.append(case_str)\n        \n    # Final output string with no whitespace\n    final_output = f\"[{','.join(all_results_str)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2393339"}]}