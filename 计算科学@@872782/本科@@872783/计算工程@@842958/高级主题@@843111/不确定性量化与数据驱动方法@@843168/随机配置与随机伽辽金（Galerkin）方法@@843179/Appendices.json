{"hands_on_practices": [{"introduction": "随机配点方法的核心是使用多项式插值来逼近模型响应。本练习旨在揭示一个关键的陷阱，即所谓的“混叠误差”。通过尝试用过少的配点来表示一个高振荡函数，我们将亲眼看到该方法如何产生严重不准确的统计估计，从而强调了仔细选择配点数量的重要性([@problem_id:2439565])。", "problem": "考虑一个在单位区间 $[0,1]$ 上均匀分布的单一输入随机变量 $\\xi$。设确定性模型响应为高度振荡函数 $f(\\xi) = \\sin\\!\\big(20\\pi\\,\\xi\\big)$，其中所有三角函数的参数均以弧度为单位。使用一维随机配点方法，在 $[0,1]$ 上取 $N$ 个 Clenshaw–Curtis 点，定义 $p_N(\\xi)$ 为一个次数至多为 $N-1$ 的唯一多项式，它在这 $N$ 个点上对 $f(\\xi)$ 进行插值。将 $[0,1]$ 上的均匀分布视为概率测度，定义配点预测的均值和方差为\n$$\\mu_N = \\int_{0}^{1} p_N(\\xi)\\, \\mathrm{d}\\xi, \\quad \\sigma_N^2 = \\int_{0}^{1} \\big(p_N(\\xi)\\big)^2\\, \\mathrm{d}\\xi - \\mu_N^2.$$\n设精确均值和方差为\n$$\\mu = \\int_{0}^{1} \\sin\\!\\big(20\\pi\\,\\xi\\big)\\,\\mathrm{d}\\xi, \\quad \\sigma^2 = \\int_{0}^{1} \\sin^2\\!\\big(20\\pi\\,\\xi\\big)\\,\\mathrm{d}\\xi.$$\n你的任务是，对于每个指定的 $N$，计算均值的绝对误差 $|\\mu_N - \\mu|$ 和方差的绝对误差 $|\\sigma_N^2 - \\sigma^2|$。Clenshaw–Curtis 点是由下式给出的 $N$ 个节点\n$$\\xi_k = \\frac{1 - \\cos\\!\\left(\\frac{k\\pi}{N-1}\\right)}{2}, \\quad k=0,1,\\ldots,N-1.$$\n精确值 $\\mu$ 和 $\\sigma^2$ 必须从第一性原理出发进行解析推导。多项式 $p_N$ 被纯粹地定义为通过指定的节点和 $f$ 的值、次数至多为 $N-1$ 的唯一插值多项式。\n\n测试集：\n- 情况 1：$N=3$。\n- 情况 2：$N=5$。\n- 情况 3：$N=9$。\n- 情况 4：$N=21$。\n\n对于每种情况，返回数对 $[|\\mu_N - \\mu|, |\\sigma_N^2 - \\sigma^2|]$，并四舍五入到恰好 $6$ 位小数。\n\n最终输出格式：\n你的程序应生成单行输出，包含一个由方括号括起来的逗号分隔列表。其中，每种情况的结果表示为一个包含两个条目的列表，且不含空格。例如，包含四种情况的输出必须如下所示：\n$$\\big[\\,[a_1,b_1],[a_2,b_2],[a_3,b_3],[a_4,b_4]\\,\\big],$$\n其中每个 $a_i$ 和 $b_i$ 是一个写有恰好 6 位小数的实数。不应打印任何其他文本。", "solution": "首先，我们验证问题陈述的有效性。\n\n**步骤 1：提取已知条件**\n- 随机变量：$\\xi \\sim U([0,1])$。\n- 模型：$f(\\xi) = \\sin(20\\pi\\xi)$。\n- 插值多项式：$p_N(\\xi)$，一个次数 $\\le N-1$ 的多项式，在 $N$ 个 Clenshaw-Curtis 点上对 $f(\\xi)$ 进行插值。\n- Clenshaw-Curtis 点：$\\xi_k = \\frac{1 - \\cos(k\\pi/(N-1))}{2}$，其中 $k=0, \\ldots, N-1$。\n- 预测均值：$\\mu_N = \\int_0^1 p_N(\\xi) d\\xi$。\n- 预测方差：$\\sigma_N^2 = \\int_0^1 (p_N(\\xi))^2 d\\xi - \\mu_N^2$。\n- “精确均值”：$\\mu = \\int_0^1 \\sin(20\\pi\\xi) d\\xi$。\n- “精确方差”：$\\sigma^2 = \\int_0^1 \\sin^2(20\\pi\\xi) d\\xi$。\n- 任务：计算当 $N \\in \\{3, 5, 9, 21\\}$ 时 $|\\mu_N - \\mu|$ 和 $|\\sigma_N^2 - \\sigma^2|$ 的值。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，是适定的、客观的。粗略地看，可能会认为“精确方差” $\\sigma^2$ 的定义存在缺陷。给定的 $\\sigma^2$ 公式是二阶矩 $E[f(\\xi)^2]$ 的公式，而不是方差 $Var(f(\\xi)) = E[f(\\xi)^2] - (E[f(\\xi)])^2$ 的公式。问题接着要求将多项式模型的方差 $\\sigma_N^2$ 与真实模型的二阶矩 $\\sigma^2$ 进行比较。这种比较在统计上似乎不一致。\n\n然而，严格的分析表明这并非一个缺陷。我们首先计算精确均值 $\\mu$：\n$$ \\mu = \\int_0^1 \\sin(20\\pi\\xi) d\\xi = \\left[ -\\frac{\\cos(20\\pi\\xi)}{20\\pi} \\right]_0^1 = -\\frac{1}{20\\pi}(\\cos(20\\pi)-\\cos(0)) = -\\frac{1}{20\\pi}(1-1) = 0 $$\n由于精确均值 $\\mu = E[f(\\xi)]$ 为零，精确方差为 $Var(f(\\xi)) = E[f(\\xi)^2] - \\mu^2 = E[f(\\xi)^2]$。因此，在这种特定情况下，所提供的 $\\sigma^2$ 定义实际上是正确的方差定义。这一微妙之处事后证明了问题陈述的有效性。该问题是有效的。\n\n**步骤 3：进行求解**\n\n我们提供一个完整的解析解和数值解。\n\n**1. 精确均值和方差**\n如上计算，精确均值为 $\\mu = 0$。\n精确方差由 $\\sigma^2 = \\int_0^1 \\sin^2(20\\pi\\xi) d\\xi$ 给出。我们使用恒等式 $\\sin^2(x) = \\frac{1-\\cos(2x)}{2}$：\n$$ \\sigma^2 = \\int_0^1 \\frac{1 - \\cos(40\\pi\\xi)}{2} d\\xi = \\frac{1}{2} \\left[ \\xi - \\frac{\\sin(40\\pi\\xi)}{40\\pi} \\right]_0^1 = \\frac{1}{2} ((1-0) - (0-0)) = \\frac{1}{2} $$\n因此，精确值为 $\\mu=0$ 和 $\\sigma^2=0.5$。\n\n**2. 均值误差**\n均值误差为 $|\\mu_N - \\mu|$。由于 $\\mu=0$，该误差为 $|\\mu_N|$。预测均值为 $\\mu_N = \\int_0^1 p_N(\\xi) d\\xi$。\n函数 $f(\\xi) = \\sin(20\\pi\\xi)$ 关于区间中心点 $(\\frac{1}{2}, 0)$ 呈点对称，因为 $f(1-\\xi) = \\sin(20\\pi(1-\\xi)) = \\sin(20\\pi - 20\\pi\\xi) = \\sin(-20\\pi\\xi) = -f(\\xi)$。\nClenshaw-Curtis 节点 $\\xi_k$ 关于 $\\xi=1/2$ 对称，即 $\\xi_k + \\xi_{N-1-k} = 1$。\n由于插值节点是对称的，且这些节点上的函数值是反对称的（$f(\\xi_{N-1-k}) = -f(\\xi_k)$），唯一的插值多项式 $p_N(\\xi)$ 也必须相对于 $\\xi=1/2$ 是反对称的，满足 $p_N(1-\\xi) = -p_N(\\xi)$。\n这样一个反对称函数在对称区间 $[0,1]$ 上的积分为零：\n$$ \\mu_N = \\int_0^1 p_N(\\xi) d\\xi = 0 $$\n这可以通过变量替换 $u=1-\\xi$ 来证明。\n因此，对于任何 $N$，预测均值 $\\mu_N$ 都恰好为 $0$。对于所有测试情况，均值的绝对误差为 $|\\mu_N - \\mu| = |0-0| = 0$。\n\n**3. 方差误差**\n方差误差为 $|\\sigma_N^2 - \\sigma^2|$。预测方差为 $\\sigma_N^2 = \\int_0^1 (p_N(\\xi))^2 d\\xi - \\mu_N^2$。由于 $\\mu_N=0$，该式简化为 $\\sigma_N^2 = \\int_0^1 (p_N(\\xi))^2 d\\xi$。\n需要计算的误差是 $\\left| \\int_0^1 (p_N(\\xi))^2 d\\xi - 0.5 \\right|$。\n解析地求出多项式 $p_N(\\xi)$ 及其积分是相当繁琐的。需要一种稳健的数值方法。\n\n插值多项式 $p_N(\\xi)$ 是一个次数至多为 $N-1$ 的多项式。它的平方 $(p_N(\\xi))^2$ 是一个次数至多为 $2(N-1)$ 的多项式。\n我们可以使用一个对次数为 $2N-2$ 的多项式精确的数值积分法则来精确计算 $(p_N(\\xi))^2$ 的积分。$M$ 点 Gauss-Legendre 积分法则对次数最高为 $2M-1$ 的多项式是精确的。通过选择 $M=N$，该法则对次数最高为 $2N-1$ 的多项式是精确的，这已足够，因为 $2N-2 \\le 2N-1$。\n设 $\\{z_i, w_i\\}_{i=1}^N$ 是缩放到区间 $[0,1]$ 上的 $N$ 点 Gauss-Legendre 积分节点和权重。则积分为：\n$$ \\sigma_N^2 = \\int_0^1 (p_N(\\xi))^2 d\\xi = \\sum_{i=1}^{N} w_i (p_N(z_i))^2 $$\n为了使用这个公式，我们需要在 Gauss 节点 $z_i$ 上计算多项式 $p_N(\\xi)$ 的值。这不应该通过首先在单项式基中找到多项式的系数来完成，因为这是一个病态问题。相反，我们使用数值稳定的重心插值公式。对于一个求值点 $z$，值 $p_N(z)$ 为：\n$$ p_N(z) = \\frac{\\sum_{k=0}^{N-1} \\frac{\\lambda_k}{z-\\xi_k} f(\\xi_k)}{\\sum_{k=0}^{N-1} \\frac{\\lambda_k}{z-\\xi_k}} $$\n其中 $\\xi_k$ 是 Clenshaw-Curtis 插值节点，$f(\\xi_k)$ 是相应的函数值。这些节点的重心权重 $\\lambda_k$ 由 $\\lambda_k = (-1)^k \\delta_k$ 给出，其中当 $k=0$ 和 $k=N-1$ 时 $\\delta_k = 1/2$，当 $1 \\le k \\le N-2$ 时 $\\delta_k=1$。\n\n整体算法如下：\n1. 对于每个给定的 $N$：\n2. 均值误差为 $0$。\n3. 计算 Clenshaw-Curtis 节点 $\\xi_k$ 和函数值 $y_k=f(\\xi_k)$。\n4. 计算重心权重 $\\lambda_k$。\n5. 获取 $[0,1]$ 上的 $N$ 点 Gauss-Legendre 节点 $z_i$ 和权重 $w_i$。\n6. 对于每个 Gauss 节点 $z_i$，使用重心公式计算 $p_N(z_i)$。\n7. 计算预测方差 $\\sigma_N^2 = \\sum_{i=1}^N w_i (p_N(z_i))^2$。\n8. 计算方差的绝对误差 $|\\sigma_N^2 - 0.5|$。\n\n这个过程在提供的 Python 代码中实现。对于 $N=3$，插值节点为 $\\{0, 1/2, 1\\}$。函数值为 $f(0)=\\sin(0)=0$，$f(1/2)=\\sin(10\\pi)=0$ 和 $f(1)=\\sin(20\\pi)=0$。穿过这三个点的唯一二次多项式是 $p_3(\\xi) \\equiv 0$。因此，$\\sigma_3^2 = 0$，误差为 $|0-0.5|=0.5$。对于其他 $N$，计算以数值方式进行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef solve():\n    \"\"\"\n    Computes the absolute errors in the mean and variance for a stochastic\n    collocation problem.\n    \"\"\"\n    test_cases = [3, 5, 9, 21]\n    exact_mean = 0.0\n    exact_second_moment = 0.5  # This is also the exact variance since mean is 0.\n\n    all_results = []\n\n    for N in test_cases:\n        # The absolute error in the mean is always 0 due to symmetry.\n        mean_error = 0.0\n\n        # 1. Compute Clenshaw-Curtis nodes and function values\n        k = np.arange(N)\n        if N  1:\n            cc_nodes = (1.0 - np.cos(k * np.pi / (N - 1))) / 2.0\n        else:\n            # Special case for N=1, although not in test suite.\n            cc_nodes = np.array([0.5]) \n        \n        f_values = np.sin(20.0 * np.pi * cc_nodes)\n        \n        # For N=3, nodes are 0, 0.5, 1, and f_values are all 0.\n        # So, the interpolating polynomial p_3(xi) is identically 0.\n        if N == 3:\n            predicted_variance = 0.0\n            variance_error = np.abs(predicted_variance - exact_second_moment)\n            all_results.append([mean_error, variance_error])\n            continue\n\n        # 2. Barycentric weights for Clenshaw-Curtis nodes\n        bary_weights = np.ones(N) * (-1.0)**k\n        if N  1:\n            bary_weights[0] *= 0.5\n            bary_weights[-1] *= 0.5\n\n        # 3. Get N-point Gauss-Legendre nodes and weights for interval [0, 1]\n        gl_nodes_std, gl_weights_std = roots_legendre(N)\n        gl_nodes = (gl_nodes_std + 1.0) / 2.0\n        gl_weights = gl_weights_std / 2.0\n\n        # 4. Evaluate interpolating polynomial p_N at Gauss nodes\n        p_N_at_gl_nodes = np.zeros(N)\n        for i in range(N):\n            z = gl_nodes[i]\n            # Barycentric formula\n            # Note: For Gauss-Legendre nodes on (0,1) and CC-nodes including {0,1},\n            # z will not be one of the cc_nodes, so no division by zero.\n            terms = bary_weights / (z - cc_nodes)\n            p_N_at_gl_nodes[i] = np.sum(terms * f_values) / np.sum(terms)\n\n        # 5. Compute predicted variance using Gauss-Legendre quadrature\n        predicted_variance = np.sum(gl_weights * (p_N_at_gl_nodes**2))\n\n        # 6. Compute absolute error in variance\n        variance_error = np.abs(predicted_variance - exact_second_moment)\n\n        all_results.append([mean_error, variance_error])\n\n    # Format the final output string\n    result_strings = []\n    for res in all_results:\n        result_strings.append(f'[{res[0]:.6f},{res[1]:.6f}]')\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2439565"}, {"introduction": "在实际应用中，我们通常不知道问题的精确解，这使得评估随机近似的准确性变得困难。本练习介绍了一种强大的技术：后验误差估计。通过比较由两个连续多项式阶数得到的解，我们可以构建一个实用的指标来判断我们计算结果的收敛性和可靠性([@problem_id:2439622])。", "problem": "考虑以下为标量随机输入定义的参数化模型问题。令随机变量表示为 $\\xi \\sim \\mathcal{U}([-1,1])$（$[-1,1]$ 上的均匀分布）。将参数化系数定义为 $a(\\xi) = a_0 + a_1 \\xi$，其中 $a_0 \\in \\mathbb{R}$ 和 $a_1 \\in \\mathbb{R}$，并假设 $a_0  |a_1|$，因此对于所有 $\\xi \\in [-1,1]$ 都有 $a(\\xi)  0$。考虑以下线性常微分方程\n$$\n\\frac{dy}{dt}(t;\\xi) + a(\\xi)\\,y(t;\\xi) = 1,\\quad t \\in (0,T], \\quad y(0;\\xi) = y_0,\n$$\n其中 $T \\in \\mathbb{R}_{0}$ 且 $y_0 \\in \\mathbb{R}$。在时间 $T$ 的唯一解为\n$$\nQ(\\xi) = y(T;\\xi) = y_0 e^{-a(\\xi)\\,T} + \\frac{1 - e^{-a(\\xi)\\,T}}{a(\\xi)}.\n$$\n对于给定的非负整数多项式次数 $p \\in \\mathbb{Z}_{\\ge 0}$，定义：\n- 随机配点近似 $u_p(\\xi)$ 为 $\\xi$ 中次数最多为 $p$ 的唯一多项式，它在由 $p+1$ 次勒让德多项式在 $(-1,1)$ 上的 $p+1$ 个不同配置点（即其零点）上插值 $Q(\\xi)$。\n- 类似地，更高阶的近似 $u_{p+1}(\\xi)$ 是次数最多为 $p+1$ 的唯一多项式，它在 $p+2$ 次勒让德多项式的 $p+2$ 个零点上插值 $Q(\\xi)$。\n\n将后验误差指标定义为这两种近似之差的均方根（相对于 $\\xi$ 的定律）：\n$$\n\\eta_p \\equiv \\left( \\mathbb{E}\\left[ \\left(u_p(\\xi)-u_{p+1}(\\xi)\\right)^2 \\right] \\right)^{1/2}\n= \\left( \\frac{1}{2} \\int_{-1}^1 \\left(u_p(\\xi)-u_{p+1}(\\xi)\\right)^2 \\, d\\xi \\right)^{1/2}.\n$$\n\n您的任务是编写一个完整的程序，对下面测试套件中的每组参数，计算如上定义的标量误差指标 $\\eta_p$，并将其报告为浮点数。\n\n测试套件（每个案例为 $(a_0,a_1,y_0,T,p)$）：\n- 案例1：$(1.0, 0.3, 0.5, 1.0, 2)$。\n- 案例2：$(1.0, 0.8, 1.0, 2.0, 0)$。\n- 案例3：$(1.4, 0.0, 0.7, 0.3, 3)$。\n- 案例4：$(2.0, 0.99, 1.0, 3.0, 4)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含上述案例的结果，以逗号分隔的列表形式包含在方括号中，顺序与测试套件相同，例如 $[r_1,r_2,r_3,r_4]$，其中每个 $r_i$ 是相应案例计算出的 $\\eta_p$ 的浮点值。\n- 不应打印其他文本或行。", "solution": "所提出的问题是计算工程领域中一个定义明确的标准练习，特别是在使用随机谱方法进行不确定性量化方面。它具有科学依据，是自洽的，并且是算法可解的。所有提供的常数和函数都有明确定义，并且约束条件确保了该问题的适定性。因此，该问题是有效的，并将提供一个解决方案。\n\n目标是为参数化常微分方程（ODE）解的随机配点近似计算后验误差指标 $\\eta_p$。\n\n控制 ODE 是：\n$$\n\\frac{dy}{dt}(t;\\xi) + a(\\xi)\\,y(t;\\xi) = 1, \\quad y(0;\\xi) = y_0\n$$\n其中 $\\xi$ 是遵循 $[-1,1]$ 上均匀分布的随机变量，表示为 $\\xi \\sim \\mathcal{U}([-1,1])$。系数 $a(\\xi)$ 是 $\\xi$ 的仿射函数：\n$$\na(\\xi) = a_0 + a_1 \\xi\n$$\n问题陈述了 $a_0  |a_1|$，这保证了对于所有 $\\xi \\in [-1,1]$ 都有 $a(\\xi)  0$。这个条件至关重要，因为它确保了解是良态的并且没有奇点。关注量 $Q(\\xi) = y(T;\\xi)$ 的解析解由下式给出：\n$$\nQ(\\xi) = y_0 e^{-a(\\xi)\\,T} + \\frac{1 - e^{-a(\\xi)\\,T}}{a(\\xi)}\n$$\n\n问题的核心涉及对 $Q(\\xi)$ 的两种多项式近似：\n1.  $u_p(\\xi)$：一个次数最多为 $p$ 的多项式，通过在一组特定的 $p+1$ 个点上插值精确解 $Q(\\xi)$ 来构建。这些点被称为配点，是 $p+1$ 次勒让德多项式 $P_{p+1}(\\xi)$ 的根。\n2.  $u_{p+1}(\\xi)$：类似地，一个次数最多为 $p+1$ 的多项式，在 $p+2$ 次勒让德多项式 $P_{p+2}(\\xi)$ 的 $p+2$ 个根上插值 $Q(\\xi)$。\n\n误差指标 $\\eta_p$ 定义为这两个连续近似之差的均方根范数。对于具有 $\\xi \\sim \\mathcal{U}([-1,1])$ 的函数 $f(\\xi)$，其期望 $\\mathbb{E}[\\cdot]$ 由 $\\frac{1}{2}\\int_{-1}^{1} f(\\xi) \\,d\\xi$ 给出。因此，$\\eta_p$ 计算如下：\n$$\n\\eta_p = \\left( \\mathbb{E}\\left[ \\left(u_p(\\xi)-u_{p+1}(\\xi)\\right)^2 \\right] \\right)^{1/2} = \\left( \\frac{1}{2} \\int_{-1}^1 \\left(u_p(\\xi)-u_{p+1}(\\xi)\\right)^2 \\, d\\xi \\right)^{1/2}\n$$\n\n为每个测试案例计算 $\\eta_p$ 的计算策略如下：\n1.  **参数实例化**：对于给定的一组参数 $(a_0, a_1, y_0, T, p)$，定义具体的函数 $a(\\xi)$ 和 $Q(\\xi)$。\n2.  **$u_p(\\xi)$ 的构建**：\n    a. 通过找到勒让德多项式 $P_{p+1}(\\xi)$ 的根来确定 $p+1$ 个配点。这可以通过使用标准的数值例程来完成，例如 `numpy.polynomial.legendre.leggauss(p+1)`。\n    b. 在这 $p+1$ 个点上评估精确解 $Q(\\xi)$ 以获得点对 $(\\xi_i, Q(\\xi_i))$。\n    c. 构建穿过这些点的次数为 $p$ 的唯一插值多项式 $u_p(\\xi)$。一个稳健的方法是使用拉格朗日插值，`scipy.interpolate.lagrange` 为此提供了一个方便的实现，返回一个多项式对象。\n3.  **$u_{p+1}(\\xi)$ 的构建**：对下一个更高次数重复步骤2中描述的过程。找到 $P_{p+2}(\\xi)$ 的 $p+2$ 个根，在这些新点上评估 $Q(\\xi)$，并构建插值多项式 $u_{p+1}(\\xi)$。\n4.  **误差计算**：\n    a. 定义差分多项式 $d(\\xi) = u_p(\\xi) - u_{p+1}(\\xi)$。由于 $u_p$ 和 $u_{p+1}$ 表示为多项式对象，它们的差也是一个多项式对象。\n    b. 被积函数是 $(d(\\xi))^2$，它也是一个多项式。多项式的积分可以精确计算。我们构建多项式 $(d(\\xi))^2$ 并找到其不定积分。然后通过在积分限上评估不定积分来计算在 $[-1, 1]$ 上的定积分。\n    c. 最后，通过取该积分值的一半的平方根来计算 $\\eta_p$。\n\n当 $a_1 = 0$ 时（如案例3），出现一个特殊情况。此时，$a(\\xi) = a_0$ 是一个常数。因此，解 $Q(\\xi)$ 也是一个常数，与 $\\xi$ 无关。对常数函数的任何多项式插值都会得到该常数本身。因此，$u_p(\\xi) = u_{p+1}(\\xi) = Q$，它们的差为零，$\\eta_p$ 精确为 $0$。这个案例可以作为对实现正确性的健全性检查。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import lagrange\nfrom numpy.polynomial.legendre import leggauss\n\ndef solve():\n    \"\"\"\n    Computes the a-posteriori error indicator for a stochastic collocation method\n    applied to a parametric ODE.\n    \"\"\"\n    # Test suite: (a_0, a_1, y_0, T, p)\n    test_cases = [\n        (1.0, 0.3, 0.5, 1.0, 2),\n        (1.0, 0.8, 1.0, 2.0, 0),\n        (1.4, 0.0, 0.7, 0.3, 3),\n        (2.0, 0.99, 1.0, 3.0, 4),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        a0, a1, y0, T, p = case\n\n        # A special case where the coefficient a(xi) is deterministic.\n        # In this situation, the solution Q is a constant, so any polynomial\n        # interpolant will also be that constant. The difference u_p - u_{p+1}\n        # is identically zero, hence the error indicator eta_p is zero.\n        if a1 == 0.0:\n            results.append(0.0)\n            continue\n\n        # Define the parameterized coefficient a(xi)\n        def a(xi):\n            return a0 + a1 * xi\n\n        # Define the exact solution Q(xi). The condition a0  |a1| ensures\n        # the denominator a(xi) is never zero for xi in [-1, 1].\n        def Q(xi):\n            a_val = a(xi)\n            exp_term = np.exp(-a_val * T)\n            # The term (1 - exp(-x))/x is evaluated robustly. While a_val  0 is\n            # guaranteed, this form would be stable even if a_val were close to 0.\n            term2 = (1.0 - exp_term) / a_val\n            return y0 * exp_term + term2\n\n        # --- Construct u_p(xi), the polynomial of degree p ---\n        p_degree = p\n        # Collocation points are the p+1 zeros of the Legendre polynomial of degree p+1.\n        num_points_p = p_degree + 1\n        nodes_p, _ = leggauss(num_points_p)\n        # Evaluate the exact solution Q at these nodes.\n        q_values_p = Q(nodes_p)\n        # Create the interpolating polynomial using Lagrange interpolation.\n        # The result is a numpy.poly1d object.\n        u_p = lagrange(nodes_p, q_values_p)\n\n        # --- Construct u_{p+1}(xi), the polynomial of degree p+1 ---\n        p1_degree = p + 1\n        # Collocation points are the p+2 zeros of the Legendre polynomial of degree p+2.\n        num_points_p1 = p1_degree + 1\n        nodes_p1, _ = leggauss(num_points_p1)\n        # Evaluate the exact solution Q at these new nodes.\n        q_values_p1 = Q(nodes_p1)\n        # Create the interpolating polynomial.\n        u_p1 = lagrange(nodes_p1, q_values_p1)\n\n        # --- Compute the error indicator eta_p ---\n        # The difference d(xi) = u_p(xi) - u_{p+1}(xi) is a polynomial.\n        d = u_p - u_p1\n        \n        # The squared difference is also a polynomial.\n        d_squared = d * d\n        \n        # We integrate d_squared from -1 to 1 exactly.\n        # poly.integ() returns the antiderivative polynomial.\n        integral_poly = d_squared.integ()\n        integral_value = integral_poly(1.0) - integral_poly(-1.0)\n        \n        # Compute eta_p according to its definition.\n        eta_p = np.sqrt(integral_value / 2.0)\n        \n        results.append(eta_p)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```", "id": "2439622"}, {"introduction": "本练习是一个综合性实践，将不确定性量化方法应用于一个经典的物理问题——热传导方程。它直接对比了非侵入式的随机配点方法和侵入式的随机伽辽金方法。通过实现这两种方法，您将对这两种核心方法在理论和实践上的差异有更深刻的理解([@problem_id:2439592])。", "problem": "考虑带齐次狄利克雷边界条件和随机热扩散系数的一维热方程，\n$$\nu_t(x,t,\\alpha) = \\alpha \\, u_{xx}(x,t,\\alpha), \\quad x \\in [0,1], \\ t \\ge 0,\n$$\n$$\nu(0,t,\\alpha)=0, \\quad u(1,t,\\alpha)=0, \\quad u(x,0,\\alpha)=\\sin(\\pi x),\n$$\n其中热扩散系数 $\\alpha$ 是一个在 $[a,b]$ 上均匀分布的标量随机变量，满足 $0ab$。您的任务是计算两种不同方法得到的解在指定评估点 $(x^\\star, t)$ 处的均值和方差之间的绝对误差。\n- 随机伽辽金（SG）方法：使用一个基于勒让德多项式的 $p$ 阶多项式混沌展开来近似解。\n- 随机配点（SC）方法：使用一个 $Q$ 点高斯-勒让德求积法则来计算解的统计矩。对于本练习，假设SC方法提供了“精确”的基准值，用于评估SG近似的准确性。\n\n您需要为以下每个测试用例计算数对 $[| \\mu_{SG} - \\mu_{SC} |, | \\sigma^2_{SG} - \\sigma^2_{SC} |]$。\n\n测试用例（每个案例为 $(a,b,p,Q,t,x^\\star)$）：\n- 案例1：$(0.1, 0.5, 3, 8, 0.3, 0.5)$\n- 案例2：$(0.1, 0.5, 5, 6, 0.0, 0.5)$\n- 案例3：$(0.01, 1.0, 5, 16, 0.2, 0.3)$\n- 案例4：$(0.1, 0.9, 7, 20, 2.0, 0.5)$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含上述案例的结果，以方括号括起来的逗号分隔列表形式呈现。每个案例的结果应表示为一个包含两个浮点数的列表，格式为 `[error_mean,error_variance]`，不含空格，例如 `[[e_m1,e_v1],[e_m2,e_v2],...]`。\n- 不应打印其他文本或行。", "solution": "所提出的问题是计算工程领域中一个有效且适定的问题，特别是在不确定性量化领域。它在科学上基于热传递的物理学以及随机分析和数值方法的数学原理。所有必要的数据和条件都已提供。因此，我将继续提供一个完整的解决方案。\n\n分析始于具有随机热扩散系数 $\\alpha$ 的一维热方程：\n$$\nu_t(x,t,\\alpha) = \\alpha \\, u_{xx}(x,t,\\alpha), \\quad x \\in [0,1], \\ t \\ge 0\n$$\n服从齐次狄利克雷边界条件 $u(0,t,\\alpha)=0, u(1,t,\\alpha)=0$ 和初始条件 $u(x,0,\\alpha)=\\sin(\\pi x)$。扩散系数 $\\alpha$ 在 $[a,b]$ 上均匀分布，它是通过仿射变换从一个标准均匀随机变量 $\\xi \\sim \\mathcal{U}([-1,1])$ 映射而来：\n$$\n\\alpha(\\xi) = \\bar{\\alpha} + \\hat{\\alpha}\\xi = \\frac{a+b}{2} + \\frac{b-a}{2}\\xi\n$$\n此处，$\\bar{\\alpha} = \\mathbb{E}[\\alpha]$ 是均值，$\\hat{\\alpha} = (b-a)/2$ 是一个缩放因子。\n\n**随机伽辽金方法推导**\n\n随机伽辽金（SG）方法寻求一种多项式混沌展开（PCE）形式的近似解：\n$$\nu(x,t,\\xi) \\approx u_p(x,t,\\xi) = \\sum_{k=0}^{p} u_k(x,t) \\psi_k(\\xi)\n$$\n其中 $\\{\\psi_k(\\xi)\\}$ 是 $[-1,1]$ 上关于均匀概率测度的标准正交勒让德多项式，满足 $\\mathbb{E}[\\psi_i(\\xi)\\psi_j(\\xi)] = \\frac{1}{2}\\int_{-1}^{1} \\psi_i(\\xi)\\psi_j(\\xi) d\\xi = \\delta_{ij}$。\n\n我们将此拟设代入控制偏微分方程：\n$$\n\\frac{\\partial}{\\partial t} \\sum_{k=0}^{p} u_k(x,t) \\psi_k(\\xi) = \\alpha(\\xi) \\frac{\\partial^2}{\\partial x^2} \\sum_{k=0}^{p} u_k(x,t) \\psi_k(\\xi)\n$$\n根据算子的线性性质，这变为：\n$$\n\\sum_{k=0}^{p} \\frac{\\partial u_k(x,t)}{\\partial t} \\psi_k(\\xi) = \\alpha(\\xi) \\sum_{k=0}^{p} \\frac{\\partial^2 u_k(x,t)}{\\partial x^2} \\psi_k(\\xi)\n$$\n通过将该方程与每个基函数 $\\psi_j(\\xi)$（$j=0, \\dots, p$）作内积来进行伽辽金投影。内积由期望算子 $\\mathbb{E}[\\cdot]$ 定义。\n$$\n\\mathbb{E}\\left[ \\psi_j(\\xi) \\sum_{k=0}^{p} \\frac{\\partial u_k}{\\partial t} \\psi_k(\\xi) \\right] = \\mathbb{E}\\left[ \\psi_j(\\xi) \\alpha(\\xi) \\sum_{k=0}^{p} \\frac{\\partial^2 u_k}{\\partial x^2} \\psi_k(\\xi) \\right]\n$$\n利用期望的线性和基函数的正交性，左侧简化为：\n$$\n\\sum_{k=0}^{p} \\frac{\\partial u_k}{\\partial t} \\mathbb{E}[\\psi_j \\psi_k] = \\sum_{k=0}^{p} \\frac{\\partial u_k}{\\partial t} \\delta_{jk} = \\frac{\\partial u_j}{\\partial t}\n$$\n右侧变为：\n$$\n\\sum_{k=0}^{p} \\frac{\\partial^2 u_k}{\\partial x^2} \\mathbb{E}[\\alpha(\\xi) \\psi_j(\\xi) \\psi_k(\\xi)]\n$$\n这得到了一个关于模态系数 $u_j(x,t)$ 的 $p+1$ 个耦合的确定性偏微分方程组：\n$$\n\\frac{\\partial u_j}{\\partial t}(x,t) = \\sum_{k=0}^{p} C_{jk} \\frac{\\partial^2 u_k}{\\partial x^2}(x,t), \\quad j = 0, \\dots, p\n$$\n其中耦合矩阵的项由 $C_{jk} = \\mathbb{E}[\\alpha(\\xi) \\psi_j(\\xi) \\psi_k(\\xi)]$ 给出。代入 $\\alpha(\\xi)$ 的表达式：\n$$\nC_{jk} = \\mathbb{E}[(\\bar{\\alpha} + \\hat{\\alpha}\\xi) \\psi_j \\psi_k] = \\bar{\\alpha} \\mathbb{E}[\\psi_j \\psi_k] + \\hat{\\alpha} \\mathbb{E}[\\xi \\psi_j \\psi_k] = \\bar{\\alpha} \\delta_{jk} + \\hat{\\alpha} \\mathbb{E}[\\xi \\psi_j \\psi_k]\n$$\n由于勒让德多项式的三项递推关系，以 $\\mathbb{E}[\\xi \\psi_j \\psi_k]$ 为项的矩阵是三对角的。这使得耦合矩阵 $\\mathbf{C}$ 是一个对称三对角矩阵。\n\n**针对特定问题的简化**\n\n初始条件和边界条件的形式允许使用分离变量法。解在所有时间内都保持 $\\sin(\\pi x)$ 的空间形式。因此，我们可以假设一个形式为 $u(x,t,\\xi) = \\hat{u}(t,\\xi) \\sin(\\pi x)$ 的解。将其代入原始偏微分方程，得到关于振幅 $\\hat{u}(t,\\xi)$ 的随机常微分方程：\n$$\n\\frac{d\\hat{u}}{dt} = -\\pi^2 \\alpha(\\xi) \\hat{u}\n$$\n初始条件 $u(x,0,\\xi)=\\sin(\\pi x)$ 意味着 $\\hat{u}(0,\\xi)=1$。精确解为 $\\hat{u}(t,\\xi) = \\exp(-\\pi^2 \\alpha(\\xi) t)$。完整的随机解为 $u(x,t,\\xi) = \\exp(-\\pi^2 \\alpha(\\xi) t) \\sin(\\pi x)$。\n\n这种分离使得能够将PCE系数写为 $u_k(x,t) = \\hat{u}_k(t) \\sin(\\pi x)$。将此代入耦合的偏微分方程组，并注意到 $\\frac{\\partial^2}{\\partial x^2}(\\hat{u}_k \\sin(\\pi x)) = -\\pi^2 \\hat{u}_k \\sin(\\pi x)$，我们得到了一个关于时间系数 $\\hat{u}_k(t)$ 的线性常微分方程组：\n$$\n\\frac{d \\hat{u}_j(t)}{dt} = -\\pi^2 \\sum_{k=0}^{p} C_{jk} \\hat{u}_k(t)\n$$\n以向量形式表示，即为 $\\frac{d\\hat{\\mathbf{u}}}{dt} = -\\pi^2 \\mathbf{C} \\hat{\\mathbf{u}}(t)$，其中 $\\hat{\\mathbf{u}}(t) = [\\hat{u}_0(t), \\dots, \\hat{u}_p(t)]^T$。\n\n该系统的初始条件通过将 $\\hat{u}(0,\\xi)=1$ 投影到基上得到：\n$$\n\\hat{u}_k(0) = \\mathbb{E}[1 \\cdot \\psi_k(\\xi)] = \\mathbb{E}[\\psi_0(\\xi) \\psi_k(\\xi)] = \\delta_{0k}\n$$\n因此，初始向量为 $\\hat{\\mathbf{u}}(0) = [1, 0, \\dots, 0]^T$。该常微分方程组的解由矩阵指数给出：\n$$\n\\hat{\\mathbf{u}}(t) = e^{-\\pi^2 \\mathbf{C} t} \\hat{\\mathbf{u}}(0)\n$$\n\n**从随机伽辽金法计算均值和方差**\n\n解的均值为：\n$$\n\\mathbb{E}[u_p(x,t,\\xi)] = \\mathbb{E}\\left[\\sin(\\pi x) \\sum_{k=0}^{p} \\hat{u}_k(t) \\psi_k(\\xi)\\right] = \\sin(\\pi x) \\sum_{k=0}^{p} \\hat{u}_k(t) \\mathbb{E}[\\psi_k(\\xi)]\n$$\n由于 $\\mathbb{E}[\\psi_k(\\xi)]=\\delta_{0k}$，均值仅由零阶系数决定：\n$$\n\\mu_{SG}(x,t) = \\mathbb{E}[u_p(x,t,\\xi)] = \\hat{u}_0(t) \\sin(\\pi x)\n$$\n方差为 $\\mathrm{Var}(u_p) = \\mathbb{E}[u_p^2] - (\\mathbb{E}[u_p])^2$。平方的期望值为：\n$$\n\\mathbb{E}[u_p^2] = \\sin^2(\\pi x) \\mathbb{E}\\left[\\left(\\sum_{k=0}^{p} \\hat{u}_k(t) \\psi_k(\\xi)\\right)^2\\right] = \\sin^2(\\pi x) \\sum_{i=0}^{p}\\sum_{j=0}^{p} \\hat{u}_i(t)\\hat{u}_j(t) \\mathbb{E}[\\psi_i\\psi_j] = \\sin^2(\\pi x) \\sum_{k=0}^{p} \\hat{u}_k(t)^2\n$$\n因此，方差由高阶系数的平方和给出：\n$$\n\\sigma^2_{SG}(x,t) = \\left( \\sin^2(\\pi x) \\sum_{k=0}^{p} \\hat{u}_k(t)^2 \\right) - \\left( \\hat{u}_0(t) \\sin(\\pi x) \\right)^2 = \\sin^2(\\pi x) \\sum_{k=1}^{p} \\hat{u}_k(t)^2\n$$\n\n**随机配点法**\n\n随机配点（SC）方法通过数值求积来近似期望。对于给定的函数 $f(\\xi)$，其期望使用 $Q$ 点高斯-勒让德求积法则来近似：\n$$\n\\mathbb{E}[f(\\xi)] = \\frac{1}{2}\\int_{-1}^1 f(\\xi) d\\xi \\approx \\sum_{q=1}^{Q} \\frac{w'_q}{2} f(\\xi_q) = \\sum_{q=1}^{Q} w_q f(\\xi_q)\n$$\n其中 $(\\xi_q, w'_q)$ 是 $[-1,1]$ 上的标准高斯-勒让德节点和权重，而 $w_q = w'_q/2$ 是相应的概率权重。\n\n步骤如下：\n1.  对每个求积节点 $\\xi_q$，确定物理参数 $\\alpha_q = \\alpha(\\xi_q)$。\n2.  对每个 $\\alpha_q$ 求解确定性问题。在本例中，我们在点 $(x^\\star, t)$ 处计算精确解：\n    $$\n    U_q = u(x^\\star, t; \\alpha_q) = e^{-\\pi^2 \\alpha_q t} \\sin(\\pi x^\\star)\n    $$\n3.  均值被近似为这些解的加权和：\n    $$\n    \\mu_{SC}(x^\\star, t) \\approx \\sum_{q=1}^{Q} w_q U_q\n    $$\n4.  方差被近似为：\n    $$\n    \\sigma^2_{SC}(x^\\star, t) \\approx \\mathbb{E}[u^2] - (\\mathbb{E}[u])^2 \\approx \\left(\\sum_{q=1}^{Q} w_q U_q^2\\right) - \\mu_{SC}^2\n    $$\n对于足够多的配点 $Q$，此方法提供了对真实统计量的高度精确估计，可作为可靠的基准，用以比较SG近似的准确性。\n\n**数值实现**\n\n数值任务涉及实现这两种方法。\n对于SG，矩阵 $\\mathbf{C}$ 使用高阶数值求积构建。通过对角化 $\\mathbf{C} = \\mathbf{V}\\mathbf{\\Lambda}\\mathbf{V}^T$ 并计算 $\\hat{\\mathbf{u}}(t) = \\mathbf{V} e^{-\\pi^2 \\mathbf{\\Lambda} t} \\mathbf{V}^T \\hat{\\mathbf{u}}(0)$ 来求解常微分方程组。\n对于SC，在每个 $Q$ 配点上计算确定性解，并使用求积法则组合结果。\n然后为每个测试用例计算绝对误差 $| \\mu_{SG} - \\mu_{SC} |$ 和 $| \\sigma^2_{SG} - \\sigma^2_{SC} |$。", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre, eval_legendre\nfrom scipy.linalg import eigh, expm\n\ndef solve():\n    \"\"\"\n    Solves the given problem by comparing Stochastic Galerkin (SG) and\n    Stochastic Collocation (SC) methods for a 1D heat equation with a\n    random parameter.\n    \"\"\"\n    test_cases = [\n        # (a, b, p, Q, t, x_star)\n        (0.1, 0.5, 3, 8, 0.3, 0.5),\n        (0.1, 0.5, 5, 6, 0.0, 0.5),\n        (0.01, 1.0, 5, 16, 0.2, 0.3),\n        (0.1, 0.9, 7, 20, 2.0, 0.5),\n    ]\n\n    results = []\n\n    for a, b, p, Q, t, x_star in test_cases:\n        # --- Stochastic Galerkin (SG) Method ---\n        \n        # 1. Construct the coupling matrix C using numerical quadrature.\n        # The integrand is a polynomial of degree up to 1+2p.\n        # Gauss-Legendre quadrature with N_quad points is exact for polynomials\n        # of degree up to 2*N_quad - 1. We need 2*N_quad - 1 = 1+2p = N_quad = p+1.\n        # We choose a safe number of points.\n        N_quad_C = 2 * p + 2\n        nodes_C, weights_C = roots_legendre(N_quad_C)\n        \n        # Orthonormal Legendre polynomials: psi_k(xi) = sqrt(2k+1) * P_k(xi)\n        psi_vals = np.zeros((p + 1, N_quad_C))\n        for k in range(p + 1):\n            psi_vals[k, :] = np.sqrt(2 * k + 1) * eval_legendre(k, nodes_C)\n            \n        alpha_vals = (a + b) / 2.0 + (b - a) / 2.0 * nodes_C\n        \n        C = np.zeros((p + 1, p + 1))\n        # C_jk = E[alpha * psi_j * psi_k] = 0.5 * integral(alpha * psi_j * psi_k, dxi)\n        for j in range(p + 1):\n            for k in range(j, p + 1): # Matrix is symmetric\n                integrand = alpha_vals * psi_vals[j, :] * psi_vals[k, :]\n                integral_val = np.sum(weights_C * integrand)\n                C[j, k] = 0.5 * integral_val\n                if j != k:\n                    C[k, j] = C[j, k]\n\n        # 2. Evolve the system of ODEs for the coefficients\n        u_hat_0 = np.zeros(p + 1)\n        u_hat_0[0] = 1.0\n\n        # Solution: u_hat(t) = expm(-pi^2 * C * t) @ u_hat_0\n        # For symmetric C, diagonalization is numerically stable and efficient.\n        evals, V = eigh(C)\n        exp_lambda_t = np.exp(-np.pi**2 * evals * t)\n        u_hat_t = V @ (exp_lambda_t * (V.T @ u_hat_0))\n\n        # 3. Compute SG mean and variance\n        sin_x_star = np.sin(np.pi * x_star)\n        mean_sg = u_hat_t[0] * sin_x_star\n        var_sg = np.sum(u_hat_t[1:]**2) * sin_x_star**2\n\n        # --- Stochastic Collocation (SC) Method ---\n        \n        # 1. Get Gauss-Legendre nodes and weights for SC\n        nodes_sc, weights_sc = roots_legendre(Q)\n        prob_weights_sc = weights_sc / 2.0\n        \n        # 2. Evaluate deterministic solution at each node\n        alpha_sc = (a + b) / 2.0 + (b - a) / 2.0 * nodes_sc\n        sol_vals_sc = np.exp(-np.pi**2 * alpha_sc * t) * sin_x_star\n        \n        # 3. Compute SC mean and variance\n        mean_sc = np.sum(prob_weights_sc * sol_vals_sc)\n        \n        # Var = E[u^2] - (E[u])^2\n        var_sc = np.sum(prob_weights_sc * sol_vals_sc**2) - mean_sc**2\n\n        # --- Comparison ---\n        error_mean = np.abs(mean_sg - mean_sc)\n        error_var = np.abs(var_sg - var_sc)\n\n        results.append(f\"[{error_mean},{error_var}]\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2439592"}]}