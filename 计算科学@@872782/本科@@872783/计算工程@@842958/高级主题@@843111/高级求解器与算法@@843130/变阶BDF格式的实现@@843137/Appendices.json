{"hands_on_practices": [{"introduction": "本练习将指导您从基本原理出发，构建一个完整的变阶后向差分公式（BDF）求解器。您将通过从后向差分推导 BDF 公式并实现阶数选择逻辑，来为线性常微分方程开发一个求解器。这项实践不仅能巩固您对 BDF 方法核心机制的理解，还能通过对比有理数与浮点数系数，揭示数值计算中舍入误差与截断误差之间的微妙关系[@problem_id:2401859]。", "problem": "针对均匀网格上步长为 $h$ 的标量线性初值问题 $y'(t)=\\lambda\\,y(t)+s(t)$，实现一个变阶向后差分公式（BDF）时间积分器。该数值方法必须基于后向有限差分和多项式插值的定义，并须遵守以下约束。\n\n- 精度/稳定性基础：从初值问题的核心定义以及用一个在均匀网格上插值 $k$ 个先前点的多项式来逼近 $y(t)$ 的概念出发。利用导数和多项式精确性的定义，得出一个阶数为 $k$ 的隐式线性多步法规则（即 $k$ 阶 BDF 方法）。在推导过程中，不要从任何预先给定的 BDF 公式开始。\n- 变阶：在每一步 $t_{n+1}=t_n+h$，仅使用当前均匀历史 $\\{y_n,y_{n-1},\\dots\\}$ 的数据选择一个阶数 $k\\in\\{1,2,3,4,5\\}$，具体如下。对于每个可行的 $k$（受限于历史数据长度），通过求解为 $y_{n+1}$ 产生的单个隐式线性方程，计算出 $k$ 阶 BDF 预测值 $y_{n+1}^{(k)}$。对于 $k\\ge 2$，定义一个局部截断误差代理 $e_k=\\lvert y_{n+1}^{(k)}-y_{n+1}^{(k-1)}\\rvert$。在所有可行的 $k$ 中，选择使 $e_k$ 最小化的阶数，但限制所选阶数相对于上一步使用的阶数变化最多为 $\\pm 1$。当只有 $k=1$ 可行时，使用 $k=1$。\n- 每步线性求解：因为 $f(t,y)=\\lambda\\,y+s(t)$ 对 $y$ 是线性的，所以 $k$ 阶的隐式 BDF 步骤必须简化为对 $y_{n+1}$ 的单次线性求解，其分母为标量。不允许也无需非线性迭代。\n- 有理数系数：将每个 BDF 系数（对于每个阶数 $k\\in\\{1,2,3,4,5\\}$）存储为精确有理数。您的程序必须执行两次不同的运行：\n  1. 一次“有理系数”运行，它使用这些在使用时转换为标准浮点数的精确有理数（系数不预先舍入到有限的小数位数）。\n  2. 一次“浮点系数”运行，它首先将每个有理系数舍入为单精度浮点数（将每个有理数转换为 $32$ 位浮点数），然后使用这些舍入后的系数进行计算（它们在算术运算中可能会被提升到标准精度，但它们的值必须是单精度舍入后的值）。\n- 最终时间 $T$ 的误差分解目标：定义\n  - 步长为 $h$ 时的舍入误差代理为 $E_{\\mathrm{round}}(h)=\\lvert y^{\\mathrm{float\\text{-}coef}}(T;h)-y^{\\mathrm{rational\\text{-}coef}}(T;h)\\rvert$。\n  - 步长为 $h$ 时的截断误差代理为 $E_{\\mathrm{trunc}}(h)=\\lvert y^{\\mathrm{rational\\text{-}coef}}(T;h)-y^{\\mathrm{rational\\text{-}coef}}(T;h/2)\\rvert$。\n- 角度单位：当出现余弦源项 $s(t)=\\cos(t)$ 时，角度必须以弧度为单位解释。\n\n实现该求解器，并为下面测试套件中的每个测试用例计算 $E_{\\mathrm{round}}(h)$ 和 $E_{\\mathrm{trunc}}(h)$。假设 $t_0=0$ 且步长均匀。在所有情况下，最终时间 $T$ 都能被 $h$ 和 $h/2$ 整除。\n\n测试套件：\n- 用例 A（理想路径，中等刚性衰减）：$\\lambda=-1$, $s(t)\\equiv 0$, $y(0)=1$, $T=10$, $h=0.1$。\n- 用例 B（更刚性的衰减）：$\\lambda=-50$, $s(t)\\equiv 0$, $y(0)=1$, $T=1$, $h=0.02$。\n- 用例 C（受迫衰减）：$\\lambda=-5$, $s(t)=\\cos(t)$ 其中 $t$ 以弧度为单位, $y(0)=0$, $T=10$, $h=0.1$。\n\n程序要求：\n- 使用上述流程实现一个最大阶数为 $5$ 的变阶 BDF。\n- 将所有 BDF 系数存储为精确有理数，并从这些有理数生成两套系数集（使用时为有理数和单精度舍入数）。\n- 对于每个用例，计算上面定义的配对 $(E_{\\mathrm{round}}(h), E_{\\mathrm{trunc}}(h))$。\n\n最终输出格式：\n您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表的结果，顺序为\n$[E_{\\mathrm{round}}^{(A)},E_{\\mathrm{trunc}}^{(A)},E_{\\mathrm{round}}^{(B)},E_{\\mathrm{trunc}}^{(B)},E_{\\mathrm{round}}^{(C)},E_{\\mathrm{trunc}}^{(C)}]$，\n其中每个条目都是一个浮点数。例如，一个语法正确的输出看起来像 $[0.0,1.0,2.5,3.75,4.0,6.25]$。", "solution": "该问题要求为标量线性常微分方程 (ODE) $y'(t) = \\lambda y(t) + s(t)$ 实现一个变阶向后差分公式 (BDF) 求解器。这是一个计算科学中的适定问题。首先，我们必须按规定从基本原理推导 $k$ 阶 BDF 方法。\n\n**1. BDF-k 公式的推导**\n\n一个 $k$ 阶 BDF 方法通过对一个 $k$ 次多项式 $P(t)$ 求导来近似导数 $y'(t_{n+1})$，该多项式插值了最近的 $k+1$ 个解点：$(t_{n+1}, y_{n+1}), (t_n, y_n), \\dots, (t_{n+1-k}, y_{n+1-k})$。对于均匀步长 $h$，我们有 $t_j = jh$。那么近似为 $y'(t_{n+1}) \\approx P'(t_{n+1})$。\n\n一个系统性的推导系数的方法是使用后向差分。一个函数 $g$ 在点 $x$ 处的导数用其在该点的后向差分表示的公式为：\n$$g'(x) = \\frac{1}{h} \\sum_{j=1}^{\\infty} \\frac{\\nabla^j g(x)}{j}$$\n其中 $\\nabla$ 是后向差分算子，$\\nabla g(x) = g(x) - g(x-h)$。将此级数在 $j=k$ 处截断，得到一个 $k$ 阶近似。将其应用于我们的数值解序列 $\\{y_i\\}$，我们近似 $y'(t_{n+1})$ 为：\n$$y'(t_{n+1}) \\approx \\frac{1}{h} \\sum_{j=1}^{k} \\frac{1}{j} \\nabla^j y_{n+1}$$\n这里，$\\nabla^j y_{n+1}$ 是使用点 $y_{n+1}, y_n, \\dots$ 的 $j$ 阶后向差分。将此代入 ODE $y'(t_{n+1})=\\lambda y_{n+1}+s(t_{n+1})$，我们得到 BDF-k 公式：\n$$\\frac{1}{h} \\sum_{j=1}^{k} \\frac{1}{j} \\nabla^j y_{n+1} = \\lambda y_{n+1} + s(t_{n+1})$$\n让我们为 $k=1, \\dots, 5$ 展开这个式子。后向差分算子定义为 $\\nabla y_i = y_i - y_{i-1}$，且 $\\nabla^j y_i = \\nabla(\\nabla^{j-1} y_i)$。\n\n对于 $k=1$：\n$$ \\frac{1}{h} \\nabla y_{n+1} = \\frac{1}{h}(y_{n+1} - y_n) = \\lambda y_{n+1} + s_{n+1} $$\n$$ \\implies y_{n+1} - y_n = h(\\lambda y_{n+1} + s_{n+1}) $$\n\n对于 $k=2$：\n$$ \\frac{1}{h} \\left(\\nabla y_{n+1} + \\frac{1}{2}\\nabla^2 y_{n+1}\\right) = \\lambda y_{n+1} + s_{n+1} $$\n$$ \\nabla^2 y_{n+1} = (y_{n+1} - y_n) - (y_n - y_{n-1}) = y_{n+1} - 2y_n + y_{n-1} $$\n$$ \\implies (y_{n+1} - y_n) + \\frac{1}{2}(y_{n+1} - 2y_n + y_{n-1}) = h(\\lambda y_{n+1} + s_{n+1}) $$\n$$ \\implies \\frac{3}{2}y_{n+1} - 2y_n + \\frac{1}{2}y_{n-1} = h(\\lambda y_{n+1} + s_{n+1}) $$\n\n继续这个过程，我们可以将 BDF-k 方法表示为一般形式：\n$$\\sum_{i=0}^{k} c_{k,i} y_{n+1-i} = h(\\lambda y_{n+1} + s_{n+1})$$\n系数 $c_{k,i}$ 是有理数。它们的推导如下：\n- 对于 $k=1$: $\\{c_{1,0}, c_{1,1}\\} = \\{1, -1\\}$\n- 对于 $k=2$: $\\{c_{2,0}, c_{2,1}, c_{2,2}\\} = \\{\\frac{3}{2}, -2, \\frac{1}{2}\\}$\n- 对于 $k=3$: $\\{c_{3,0}, \\dots, c_{3,3}\\} = \\{\\frac{11}{6}, -3, \\frac{3}{2}, -\\frac{1}{3}\\}$\n- 对于 $k=4$: $\\{c_{4,0}, \\dots, c_{4,4}\\} = \\{\\frac{25}{12}, -4, 3, -\\frac{4}{3}, \\frac{1}{4}\\}$\n- 对于 $k=5$: $\\{c_{5,0}, \\dots, c_{5,5}\\} = \\{\\frac{137}{60}, -5, 5, -\\frac{10}{3}, \\frac{5}{4}, -\\frac{1}{5}\\}$\n\n**2. 求解 $y_{n+1}$**\n\nBDF 公式是隐式的。对于给定的线性 ODE，我们可以代数地解出 $y_{n+1}$。\n$$c_{k,0} y_{n+1} + \\sum_{i=1}^{k} c_{k,i} y_{n+1-i} = h \\lambda y_{n+1} + h s_{n+1}$$\n$$(c_{k,0} - h\\lambda) y_{n+1} = h s_{n+1} - \\sum_{i=1}^{k} c_{k,i} y_{n+1-i}$$\n$$y_{n+1} = \\frac{h s_{n+1} - \\sum_{i=1}^{k} c_{k,i} y_{n-i+1}}{c_{k,0} - h\\lambda}$$\n求和项涉及 $k$ 个先前的 $y$ 值。设历史向量为 $Y_n = [y_n, y_{n-1}, \\dots]$。那么求和是系数向量 $[c_{k,1}, \\dots, c_{k,k}]$ 和历史向量 $[y_n, \\dots, y_{n-k+1}]$ 的点积。\n\n**3. 变阶选择算法**\n\n问题指定了一个在每个时间步改变阶数 $k$ 的特定算法。设 $k_{prev}$ 是上一步使用的阶数。在当前步骤计算 $y_{n+1}$ 时：\n\n1.  **确定历史允许的阶数：** 确定阶数集合 $K_{hist} = \\{ k \\in \\mathbb{Z} \\mid 1 \\le k \\le \\min(n+1, 5) \\}$，其中 $n+1$ 是包括初始条件 $y_0$ 在内的历史点数。\n2.  **计算预测值：** 对于每个阶数 $k \\in K_{hist}$，使用上面推导的 BDF-k 公式计算一个预测值 $y_{n+1}^{(k)}$。\n3.  **计算误差代理：** 对于每个在 $K_{hist}$ 中且 $k \\ge 2$ 的阶数，计算误差代理 $e_k = \\lvert y_{n+1}^{(k)} - y_{n+1}^{(k-1)} \\rvert$。\n4.  **选择最优无约束阶数：** 如果只有 $k=1$ 可行，则必须选择 $k=1$。否则，找到在所有定义了 $e_k$ 的 $k$ 中最小化误差代理 $e_k$ 的阶数 $k_{opt}$：\n    $$k_{opt} = \\underset{k \\in K_{hist}, k \\ge 2}{\\arg\\min} \\{e_k\\}$$\n5.  **应用约束：** 新的阶数 $k_{new}$ 通过将 $k_{opt}$ 约束在与前一阶数 $k_{prev}$ 最多相差一步的范围内来确定。\n    $$k_{new} = \\max(k_{prev}-1, \\min(k_{opt}, k_{prev}+1))$$\n    我们必须确保 $k_{new} \\geq 1$。由于 $k_{prev} \\ge 1$，所以 $k_{prev}-1 \\ge 0$。因此，最终的保障是 $k_{new} = \\max(1, k_{new})$。\n6.  **更新解：** 当前步骤的解是对应于所选阶数的解：$y_{n+1} = y_{n+1}^{(k_{new})}$。$k_{new}$ 的值成为下一步的 $k_{prev}$。\n\n初始步骤必须使用 $k=1$，所以我们初始化 $k_{prev}=1$。必须维护解值的历史记录以计算后续步骤。\n\n**4. 误差度量计算**\n程序必须为每个测试用例执行三次运行，以计算所需的误差度量：\n1.  步长为 $h$ 的 `rational-coef` 运行：`y_rat_h`\n2.  步长为 $h$ 的 `float-coef` 运行：`y_float_h`\n3.  步长为 $h/2$ 的 `rational-coef` 运行：`y_rat_h2`\n\n`float-coef` 运行需要在求解器中使用之前，将精确的有理 BDF 系数舍入为单精度（$32$-位）浮点数。\n\n然后按如下方式计算误差：\n- 舍入误差代理：$E_{\\mathrm{round}}(h) = \\lvert y_{float\\_h} - y_{rat\\_h} \\rvert$\n- 截断误差代理：$E_{\\mathrm{trunc}}(h) = \\lvert y_{rat\\_h} - y_{rat\\_h2} \\rvert$\n\n实现将精确遵循此逻辑。", "answer": "```python\nimport numpy as np\nfrom fractions import Fraction\nimport math\n\ndef get_bdf_coeffs(coeff_type='rational'):\n    \"\"\"\n    Generates BDF coefficients for orders 1-5.\n    \n    Args:\n        coeff_type (str): 'rational' for exact fractions, 'float' for\n                          single-precision rounded floats.\n\n    Returns:\n        A dictionary mapping order k to a list of its coefficients.\n    \"\"\"\n    # Coefficients c_{k,i} for sum_{i=0 to k} c_{k,i} y_{n+1-i} = h f_{n+1}\n    base_coeffs = {\n        1: [Fraction(1), Fraction(-1)],\n        2: [Fraction(3, 2), Fraction(-2), Fraction(1, 2)],\n        3: [Fraction(11, 6), Fraction(-3), Fraction(3, 2), Fraction(-1, 3)],\n        4: [Fraction(25, 12), Fraction(-4), Fraction(3), Fraction(-4, 3), Fraction(1, 4)],\n        5: [Fraction(137, 60), Fraction(-5), Fraction(5), Fraction(-10, 3), Fraction(5, 4), Fraction(-1, 5)],\n    }\n\n    if coeff_type == 'rational':\n        return {k: [float(c) for c in v] for k, v in base_coeffs.items()}\n    elif coeff_type == 'float':\n        # Round to single-precision float (float32) and then use as standard float (float64)\n        float_coeffs = {}\n        for k, v in base_coeffs.items():\n            float_coeffs[k] = [float(np.float32(c)) for c in v]\n        return float_coeffs\n    else:\n        raise ValueError(\"Invalid coefficient type\")\n\ndef solve_ode_variable_bdf(params, h, coeff_type):\n    \"\"\"\n    Solves y'(t) = lambda*y(t) + s(t) with a variable-order BDF method.\n    \"\"\"\n    lam, s_func, y0, T = params['lambda'], params['s_func'], params['y0'], params['T']\n    \n    # Ensure T is a multiple of h\n    num_steps = round(T / h)\n    \n    bdf_coeffs = get_bdf_coeffs(coeff_type)\n    \n    # History of y values, y_hist[0] = y_n, y_hist[1] = y_{n-1}, ...\n    y_hist = [y0]\n    k_prev = 1\n    max_order = 5\n\n    for n in range(num_steps):\n        t_next = (n + 1) * h\n        \n        # 1. Identify history-admissible orders\n        k_hist_max = min(len(y_hist), max_order)\n        \n        # 2. Compute predictions for all admissible orders\n        y_preds = {}\n        for k in range(1, k_hist_max + 1):\n            coeffs = bdf_coeffs[k]\n            c_k0 = coeffs[0]\n            \n            # History term: - sum_{i=1 to k} c_{k,i} * y_{n+1-i}\n            history_sum = -sum(coeffs[i] * y_hist[i-1] for i in range(1, k + 1))\n            \n            numerator = h * s_func(t_next) + history_sum\n            denominator = c_k0 - h * lam\n            \n            y_preds[k] = numerator / denominator\n\n        # 3.  4. Select optimal order based on error proxies\n        k_opt = 1 \n        if k_hist_max > 1:\n            # Orders for which e_k can be computed\n            k_err_domain = range(2, k_hist_max + 1)\n            \n            errors = {k: abs(y_preds[k] - y_preds[k-1]) for k in k_err_domain}\n            \n            if errors:\n                # Find the order k that minimizes e_k\n                k_opt = min(errors, key=errors.get)\n\n        # 5. Apply +/- 1 constraint\n        k_new = k_opt\n        if k_new > k_prev + 1:\n            k_new = k_prev + 1\n        if k_new  k_prev - 1:\n            k_new = k_prev - 1\n        k_new = max(1, k_new)\n        \n        # 6. Update solution and history\n        y_next = y_preds[k_new]\n        y_hist.insert(0, y_next)\n        \n        # Trim history to max required length\n        if len(y_hist) > max_order:\n            y_hist.pop()\n            \n        k_prev = k_new\n        \n    return y_hist[0]\n\ndef solve():\n    test_cases = [\n        # Case A\n        {'params': {'lambda': -1.0, 's_func': lambda t: 0.0, 'y0': 1.0, 'T': 10.0}, 'h': 0.1},\n        # Case B\n        {'params': {'lambda': -50.0, 's_func': lambda t: 0.0, 'y0': 1.0, 'T': 1.0}, 'h': 0.02},\n        # Case C\n        {'params': {'lambda': -5.0, 's_func': lambda t: math.cos(t), 'y0': 0.0, 'T': 10.0}, 'h': 0.1},\n    ]\n\n    results = []\n    for case in test_cases:\n        params = case['params']\n        h = case['h']\n        \n        # Run with rational coeffs at h\n        y_rat_h = solve_ode_variable_bdf(params, h, 'rational')\n        \n        # Run with float coeffs at h\n        y_float_h = solve_ode_variable_bdf(params, h, 'float')\n        \n        # Run with rational coeffs at h/2\n        y_rat_h2 = solve_ode_variable_bdf(params, h / 2.0, 'rational')\n        \n        # Compute error proxies\n        e_round = abs(y_float_h - y_rat_h)\n        e_trunc = abs(y_rat_h - y_rat_h2)\n        \n        results.extend([e_round, e_trunc])\n    \n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```", "id": "2401859"}, {"introduction": "现实世界中的大多数问题都是非线性的，这使得求解 BDF 隐式步成为一个非线性方程求解问题。本练习聚焦于如何为此实现牛顿法，并探讨了在近似计算雅可比矩阵时，如何选择有限差分步长 $h_J$ 这一关键实践问题。通过这个练习，您将亲身体验在确保近似精度的同时，维持数值稳定性的重要权衡[@problem_id:2401862]。", "problem": "考虑在所有实数时间上定义的标量初值问题，其常微分方程为\n$$\ny'(t) = \\cos(t) + \\lambda\\,(y(t) - \\sin(t))^3,\\quad y(0)=0,\n$$\n其中 $\\lambda$ 是一个实数参数，$\\sin(\\cdot)$ 和 $\\cos(\\cdot)$ 分别表示正弦和余弦函数，角度以弧度为单位。对于所有 $t$，其精确解为 $y(t)=\\sin(t)$。\n\n设一个阶数 $p\\in\\{1,2,3\\}$ 的变阶向后差分格式（BDF）方法，使用恒定时间步长 $\\Delta t0$，从时间 $t_n$ 向前推进一个步长至 $t_{n+1}=t_n+\\Delta t$。第 $(n+1)$ 步的 BDF 残差定义为\n$$\nR(y_{n+1}) = \\sum_{j=0}^{p} \\alpha_j\\, y_{n+1-j} - \\Delta t\\; f(t_{n+1}, y_{n+1}),\n$$\n其中 $f(t,y)=\\cos(t) + \\lambda\\,(y - \\sin(t))^3$，且均匀步长的 BDF 系数 $\\{\\alpha_j\\}_{j=0}^{p}$ 为：\n- 当 $p=1$ 时：$\\alpha_0 = 1$, $\\alpha_1 = -1$，\n- 当 $p=2$ 时：$\\alpha_0 = \\tfrac{3}{2}$, $\\alpha_1 = -2$, $\\alpha_2 = \\tfrac{1}{2}$，\n- 当 $p=3$ 时：$\\alpha_0 = \\tfrac{11}{6}$, $\\alpha_1 = -3$, $\\alpha_2 = \\tfrac{3}{2}$, $\\alpha_3 = -\\tfrac{1}{3}$。\n\n假设先前的数值是精确的，由 $y_{n+1-j}=\\sin(t_{n+1}-j\\,\\Delta t)$ 给出，其中 $j=1,\\dots,p$。非线性求解的初始猜测值为 $y_{n+1}^{(0)}=y_n=\\sin(t_n)$，其中 $t_{n+1}=p\\,\\Delta t$ 且 $t_n=(p-1)\\,\\Delta t$。\n\n设残差关于 $y_{n+1}$ 的雅可比矩阵通过增量为 $h_J0$ 的前向有限差分进行近似，\n$$\nJ(y) \\approx \\frac{R(y+h_J)-R(y)}{h_J}.\n$$\n在每个测试案例中，计算将牛顿法应用于 $R(y_{n+1})=0$ 所需的迭代次数 $k$。该牛顿法使用上述有限差分雅可比近似和初始猜测值，直到满足停止条件 $\\lvert R(y_{n+1}^{(k)})\\rvert \\le \\varepsilon$ 或超过最大迭代次数 $k_{\\max}$。使用 $\\varepsilon = 10^{-12}$ 和 $k_{\\max}=50$。同时报告终止时的绝对解误差，\n$$\ne = \\lvert y_{n+1}^{(k)} - \\sin(t_{n+1})\\rvert,\n$$\n其中 $y_{n+1}^{(k)}$ 是最后的迭代值（无论是在收敛时还是达到 $k_{\\max}$ 后）。\n\n测试套件：\n对以下参数集 $(p,\\Delta t,\\lambda,h_J)$ 进行评估：\n- 情况 $1$：$(p=\\;1,\\;\\Delta t=\\;0.1,\\;\\lambda=\\;10,\\;h_J=\\;10^{-6})$，\n- 情况 $2$：$(p=\\;2,\\;\\Delta t=\\;0.05,\\;\\lambda=\\;100,\\;h_J=\\;10^{-6})$，\n- 情况 $3$：$(p=\\;3,\\;\\Delta t=\\;0.01,\\;\\lambda=\\;1000,\\;h_J=\\;10^{-6})$，\n- 情况 $4$：$(p=\\;2,\\;\\Delta t=\\;0.05,\\;\\lambda=\\;100,\\;h_J=\\;10^{-12})$，\n- 情况 $5$：$(p=\\;2,\\;\\Delta t=\\;0.05,\\;\\lambda=\\;100,\\;h_J=\\;10^{-2})$，\n- 情况 $6$：$(p=\\;1,\\;\\Delta t=\\;0.2,\\;\\lambda=\\;0,\\;h_J=\\;10^{-6})$。\n\n对于每种情况，生成一个结果，该结果为列表 $[k,e]$，其中 $k$ 是所用牛顿迭代的整数次数，$e$ 是上面定义的浮点绝对误差。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个逗号分隔的列表，列表内容是六个案例的结果。每个案例结果本身是一个包含两个元素的列表，无空格，并用方括号括起来。例如，格式必须如下所示：\n$$\n\\big[\\,[k_1,e_1],[k_2,e_2],[k_3,e_3],[k_4,e_4],[k_5,e_5],[k_6,e_6]\\,\\big].\n$$", "solution": "在尝试任何解决方案之前，所提出的问题都经过了严格的验证。\n\n### 步骤1：提取已知条件\n\n从问题陈述中提取的已知条件如下：\n- **常微分方程（ODE）**：$y'(t) = \\cos(t) + \\lambda\\,(y(t) - \\sin(t))^3$\n- **初始条件**：$y(0)=0$\n- **精确解**：对于所有 $t \\in \\mathbb{R}$，$y(t)=\\sin(t)$\n- **数值方法**：阶数 $p \\in \\{1,2,3\\}$ 且恒定时间步长 $\\Delta t0$ 的变阶向后差分格式（BDF）。\n- **BDF残差**：$R(y_{n+1}) = \\sum_{j=0}^{p} \\alpha_j\\, y_{n+1-j} - \\Delta t\\; f(t_{n+1}, y_{n+1})$\n- **右端函数**：$f(t,y)=\\cos(t) + \\lambda\\,(y - \\sin(t))^3$\n- **BDF系数 $\\{\\alpha_j\\}_{j=0}^{p}$**：\n  - 当 $p=1$ 时：$\\alpha_0 = 1$, $\\alpha_1 = -1$\n  - 当 $p=2$ 时：$\\alpha_0 = \\tfrac{3}{2}$, $\\alpha_1 = -2$, $\\alpha_2 = \\tfrac{1}{2}$\n  - 当 $p=3$ 时：$\\alpha_0 = \\tfrac{11}{6}$, $\\alpha_1 = -3$, $\\alpha_2 = \\tfrac{3}{2}$, $\\alpha_3 = -\\tfrac{1}{3}$\n- **历史值假设**：先前的解值是精确的，$y_{n+1-j}=\\sin(t_{n+1}-j\\,\\Delta t)$，其中 $j \\in \\{1, \\dots, p\\}$。\n- **时间离散化**：步长从 $t_n$ 到 $t_{n+1}$，其中 $t_{n+1}=p\\,\\Delta t$ 且 $t_n=(p-1)\\,\\Delta t$。\n- **非线性求解器**：将牛顿法应用于 $R(y_{n+1})=0$。\n- **初始猜测值**：$y_{n+1}^{(0)}=y_n=\\sin(t_n)$。\n- **雅可比矩阵近似**：前向有限差分，$J(y) \\approx \\frac{R(y+h_J)-R(y)}{h_J}$，增量为 $h_J0$。\n- **收敛准则**：$|R(y_{n+1}^{(k)})| \\le \\varepsilon$，容差 $\\varepsilon = 10^{-12}$。\n- **迭代限制**：最大迭代次数 $k_{\\max}=50$。\n- **输出指标**：迭代次数 $k$ 和绝对误差 $e = \\lvert y_{n+1}^{(k)} - \\sin(t_{n+1})\\rvert$。\n- **测试套件**：\n  - 情况 $1$：$(p=1,\\;\\Delta t=0.1,\\;\\lambda=10,\\;h_J=10^{-6})$\n  - 情况 $2$：$(p=2,\\;\\Delta t=0.05,\\;\\lambda=100,\\;h_J=10^{-6})$\n  - 情况 $3$：$(p=3,\\;\\Delta t=0.01,\\;\\lambda=1000,\\;h_J=10^{-6})$\n  - 情况 $4$：$(p=2,\\;\\Delta t=0.05,\\;\\lambda=100,\\;h_J=10^{-12})$\n  - 情况 $5$：$(p=2,\\;\\Delta t=0.05,\\;\\lambda=100,\\;h_J=10^{-2})$\n  - 情况 $6$：$(p=1,\\;\\Delta t=0.2,\\;\\lambda=0,\\;h_J=10^{-6})$\n\n### 步骤2：使用提取的已知条件进行验证\n\n该问题根据既定标准进行评估：\n- **科学基础和客观性**：该问题植根于常微分方程的数值分析领域，这是计算工程学的核心课题。它采用了标准、成熟的方法（BDF、牛顿法）和概念（有限差分雅可比矩阵）。所有术语在数学上都是精确和客观的。\n- **适定性**：问题给出了足够的细节。推进一个时间步长的算法由给定的初始猜测、更新公式（具有指定雅可比矩阵的牛顿法）和终止条件完全确定。对于每组输入参数，这个确定性过程都会产生唯一的结果。\n- **完整性和一致性**：所有必需的数据，包括ODE、BDF系数、每个测试用例的参数值以及算法规范，都已提供。没有矛盾之处。假设历史值是精确的，这是分析数值方法局部误差的标准技术，并且与提供的精确解 $y(t)=\\sin(t)$ 一致。时间索引 $t_{n+1} = p \\Delta t$ 是对 $p$ 阶第一步的明确规定。\n\n### 步骤3：结论与行动\n\n此问题是**有效的**。它是一个定义明确的数值分析计算任务。将提供一个解决方案。\n\n### 解决方案\n\n目标是模拟给定非线性ODE的变阶BDF方法的单个步骤，并报告内部牛顿求解器的性能。对于每个测试用例 $(p, \\Delta t, \\lambda, h_J)$，其过程如下。\n\n首先，我们为BDF积分步骤建立背景。BDF方法是一种隐式线性多步法。对于形式为 $y'(t) = f(t, y(t))$ 的ODE，阶数为 $p$ 的BDF格式要求在每个时间步 $t_{n+1}$ 求解以下关于未知数 $y_{n+1}$ 的非线性代数方程：\n$$\n\\sum_{j=0}^{p} \\alpha_j y_{n+1-j} - \\Delta t f(t_{n+1}, y_{n+1}) = 0\n$$\n为简化求解过程，我们定义残差函数 $R(y)$，其中 $y$ 是解 $y_{n+1}$ 的一个候选值：\n$$\nR(y) = \\alpha_0 y + \\sum_{j=1}^{p} \\alpha_j y_{n+1-j} - \\Delta t f(t_{n+1}, y)\n$$\n问题指定历史值 $y_{n+1-j}$（对于 $j \\in \\{1, \\dots, p\\}$）是已知且精确的，即 $y_{n+1-j} = \\sin(t_{n+1-j})$。时间由 $t_{n+1} = p \\Delta t$ 和 $t_{n+1-j} = t_{n+1} - j \\Delta t = (p-j)\\Delta t$ 定义。求和的历史部分可以作为当前步骤的一个常数预先计算：\n$$\nH_n = \\sum_{j=1}^{p} \\alpha_j \\sin((p-j)\\Delta t)\n$$\n然后，残差函数可以更紧凑地写为：\n$$\nR(y) = \\alpha_0 y + H_n - \\Delta t \\left( \\cos(t_{n+1}) + \\lambda(y - \\sin(t_{n+1}))^3 \\right)\n$$\n我们必须使用牛顿法找到 $R(y)=0$ 的根。牛顿法的迭代格式由下式给出：\n$$\ny_{n+1}^{(k+1)} = y_{n+1}^{(k)} - \\left[ J\\left(y_{n+1}^{(k)}\\right) \\right]^{-1} R\\left(y_{n+1}^{(k)}\\right)\n$$\n其中 $y_{n+1}^{(k)}$ 是第 $k$ 次的迭代值。雅可比矩阵 $J(y)$ 是残差关于 $y$ 的导数，$J(y) = \\frac{dR}{dy}$。问题要求对此雅可比矩阵使用前向有限差分近似：\n$$\nJ(y) \\approx \\frac{R(y+h_J) - R(y)}{h_J}\n$$\n迭代过程从初始猜测值 $y_{n+1}^{(0)} = y_n = \\sin(t_n) = \\sin((p-1)\\Delta t)$ 开始。迭代继续进行，直到满足停止条件 $|R(y_{n+1}^{(k)})| \\le \\varepsilon = 10^{-12}$，或者迭代次数 $k$ 超过最大值 $k_{\\max}=50$。\n\n单个测试用例的算法如下：\n$1$. 确定参数 $(p, \\Delta t, \\lambda, h_J)$ 和常数 $\\varepsilon=10^{-12}$，$k_{\\max}=50$。\n$2$. 选择与阶数 $p$ 对应的BDF系数 $\\{\\alpha_j\\}$。\n$3$. 设置当前步的时间：$t_{n+1} = p \\Delta t$。\n$4$. 计算常数历史项 $H_n = \\sum_{j=1}^{p} \\alpha_j \\sin((p-j)\\Delta t)$。\n$5$. 定义残差函数 $R(y) = \\alpha_0 y + H_n - \\Delta t (\\cos(t_{n+1}) + \\lambda(y - \\sin(t_{n+1}))^3)$。\n$6$. 初始化牛顿迭代：$k=0$ 且 $y_{cur} = \\sin((p-1)\\Delta t)$。\n$7$. 开始迭代循环，从 $k$ 等于 $0$ 到 $k_{\\max}-1$：\n    a. 计算当前迭代值的残差：$R_{cur} = R(y_{cur})$。\n    b. 检查是否收敛：如果 $|R_{cur}| \\le \\varepsilon$，则跳出循环并转到步骤 $9$。\n    c. 近似雅可比矩阵：$J_{cur} = (R(y_{cur} + h_J) - R_{cur}) / h_J$。\n    d. 执行牛顿更新：$y_{cur} \\leftarrow y_{cur} - R_{cur} / J_{cur}$。\n$8$. 如果循环完成但未收敛，最终迭代值是最后一次迭代的 $y_{cur}$，迭代计数为 $k_{\\max}$。问题要求报告最终的迭代计数，这将是循环中的 $k+1$，即 $k_{max}$。然而，定义暗示我们报告*更新*或已执行的迭代次数。一个从 $k=0$到 $k_{max}-1$ 的循环执行 $k_{max}$ 次迭代。如果在第 $k$ 次停止，则已执行 $k$ 次迭代。让我们将循环定义为从 $k=1$到 $k_{max}$。在 $k=0$ 时进行初始检查。如果未收敛，则循环开始。因此，如果它在3次更新后收敛，则 $k=3$。如果初始猜测是正确的，则 $k=0$。\n   修订后的循环逻辑：\n   初始化 $k=0$, $y_k = y_{n+1}^{(0)}$。\n   WHILE $k  k_{\\max}$:\n     计算 $R(y_k)$。\n     IF $|R(y_k)| \\le \\varepsilon$，break。\n     计算 $J(y_k)$。\n     $y_{k+1} = y_k - R(y_k)/J(y_k)$。\n     $k \\leftarrow k+1$。\n   此逻辑正确地计算了更新次数。\n$9$. 终止时，最终迭代次数为 $k$，最终近似值为 $y_{n+1}^{(k)} = y_{cur}$。\n$10$. 计算绝对误差：$e = |y_{n+1}^{(k)} - \\sin(t_{n+1})|$。\n$11$. 该测试用例的结果为数对 $[k, e]$。\n\n这个完整的流程必须对六个指定的测试用例中的每一个都执行。实现将使用标准双精度浮点运算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the given problem by running the specified test suite and printing\n    the results in the required format.\n    \"\"\"\n\n    test_cases = [\n        # (p, Δt, λ, h_J)\n        (1, 0.1, 10, 1e-6),\n        (2, 0.05, 100, 1e-6),\n        (3, 0.01, 1000, 1e-6),\n        (2, 0.05, 100, 1e-12),\n        (2, 0.05, 100, 1e-2),\n        (1, 0.2, 0, 1e-6),\n    ]\n\n    results = []\n    for case in test_cases:\n        k, e = run_newton_bdf_step(*case)\n        results.append(f\"[{k},{e}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef run_newton_bdf_step(p, dt, lam, h_j):\n    \"\"\"\n    Performs one BDF step using Newton's method for a given set of parameters.\n\n    Args:\n        p (int): Order of the BDF method.\n        dt (float): Time step size Δt.\n        lam (float): Parameter λ in the ODE.\n        h_j (float): Increment for finite-difference Jacobian.\n\n    Returns:\n        tuple: A tuple containing:\n            - k (int): Number of Newton iterations.\n            - error (float): Absolute error at termination.\n    \"\"\"\n    epsilon = 1e-12\n    k_max = 50\n\n    bdf_coeffs = {\n        1: {'alpha': [1.0, -1.0]},\n        2: {'alpha': [3.0/2.0, -2.0, 1.0/2.0]},\n        3: {'alpha': [11.0/6.0, -3.0, 3.0/2.0, -1.0/3.0]}\n    }\n\n    if p not in bdf_coeffs:\n        raise ValueError(f\"Invalid order p={p}. Must be 1, 2, or 3.\")\n\n    alpha = bdf_coeffs[p]['alpha']\n    alpha_0 = alpha[0]\n    \n    # Time points\n    t_next = p * dt\n    t_prev = (p - 1) * dt\n\n    # Pre-compute history term\n    history_sum = 0.0\n    for j in range(1, p + 1):\n        t_hist = (p - j) * dt\n        history_sum += alpha[j] * np.sin(t_hist)\n    \n    sin_t_next = np.sin(t_next)\n    cos_t_next = np.cos(t_next)\n\n    def f(y, t):\n        return cos_t_next + lam * (y - sin_t_next)**3\n\n    def residual(y):\n        return alpha_0 * y + history_sum - dt * f(y, t_next)\n    \n    # Newton's method\n    k = 0\n    y_k = np.sin(t_prev)  # Initial guess y_n+1^(0) = y_n\n\n    while k  k_max:\n        res_k = residual(y_k)\n\n        if np.abs(res_k) = epsilon:\n            break\n\n        # Finite difference Jacobian\n        res_h = residual(y_k + h_j)\n        jac_k = (res_h - res_k) / h_j\n        \n        # Avoid division by zero if Jacobian is pathologically small\n        if np.abs(jac_k)  1e-14:\n            # This indicates a problem, e.g., stagnation. We stop.\n            k = k_max\n            break\n\n        # Newton update\n        y_k = y_k - res_k / jac_k\n        k += 1\n    \n    # Final error calculation\n    error = np.abs(y_k - sin_t_next)\n\n    return k, error\n    \nsolve()\n```", "id": "2401862"}, {"introduction": "一个实用的求解器必须能够处理积分过程中的中断，例如由“事件检测”触发的中断。本练习将演示一种精巧的技术，即通过多项式插值创建“合成历史”，从而在不损失精度的情况下重启高阶方法。这项实践将加深您对 BDF 方法与其多项式基础之间内在联系的理解，并展示如何提升求解器的实际应用价值[@problem_id:2401895]。", "problem": "给定一个由常微分方程 (ODE) $y^{\\prime}(t) = \\lambda\\, y(t)$ 定义的标量初值问题，其精确解为 $y(t) = \\exp(\\lambda t)$。假设在时间 $t = t_e$ 检测到一个事件，并且积分必须在 $t_e$ 处使用一个阶数为 $k$ 的后向差分格式 (BDF) 以恒定的事件后步长 $h$ 重启。为了在重启时不损失 $k$ 阶精度，需要一组与新步长对齐的 $k$ 个历史值，即 $y(t_e), y(t_e - h), \\dots, y\\left(t_e - (k-1)h\\right)$，我们称之为合成历史。\n\n对于下面的每个测试用例，请使用以下基于基本多项式插值和后向差分格式定义的定义和任务：\n\n- 设 $\\{\\tau_i\\}_{i=1}^{k}$ 为 $k$ 个不同的事件前采样时间，对所有 $i$ 均满足 $\\tau_i  t_e$。将 $k+1$ 个插值节点的集合定义为 $\\{(\\tau_i, y(\\tau_i))\\}_{i=1}^{k} \\cup \\{(t_e, y(t_e))\\}$。设 $p_k(t)$ 是对这 $k+1$ 个点进行插值的唯一的至多 $k$ 次多项式。将与新步长对齐的合成历史定义为 $y_e^{(j)} := p_k\\left(t_e - j h\\right)$，其中 $j \\in \\{0,1,\\dots,k-1\\}$ 且 $y_e^{(0)} = p_k(t_e)$。\n\n- 阶数为 $k$、步长恒为 $h$ 的后向差分格式 (BDF) 由系数 $\\{\\alpha_j\\}_{j=0}^{k}$ 定义，这些系数使得在 $t_{n+1}$ 处的离散导数对于所有至多 $k$ 次的多项式都是精确的。这些系数由等距网格 $s_j = -j$（其中 $j \\in \\{0,1,\\dots,k\\}$）上的矩条件唯一确定：\n  1. 对于所有满足 $m \\in \\{0,2,3,\\dots,k\\}$ 的整数 $m$，有 $\\sum_{j=0}^{k} \\alpha_j s_j^m = 0$。\n  2. $\\sum_{j=0}^{k} \\alpha_j s_j = 1$。\n  在 $t_{n+1} = t_e + h$ 处的 BDF 更新由下式给出：\n  $$\\sum_{j=0}^{k} \\alpha_j\\, y_{n+1-j} = h\\, y^{\\prime}(t_{n+1}),$$\n  其中 $y_{n+1} = y(t_e+h)$，而对于 $j \\in \\{1,\\dots,k\\}$，$y_{n+1-j}$ 是上文定义的合成历史值 $y_e^{(j-1)}$。对于 ODE $y^{\\prime} = \\lambda y$，这变成了一个标量隐式方程：\n  $$\\alpha_0\\, y(t_e+h) + \\sum_{j=1}^{k} \\alpha_j\\, y_e^{(j-1)} = h\\, \\lambda\\, y(t_e+h),$$\n  其唯一解为\n  $$y(t_e+h) = \\frac{-\\sum_{j=1}^{k} \\alpha_j\\, y_e^{(j-1)}}{\\alpha_0 - h\\, \\lambda}.$$\n\n对于每个测试用例，你的程序必须根据指定的插值节点构造 $p_k(t)$，评估合成历史 $y_e^{(j)}$，通过求解上述线性矩条件来确定 $k$ 阶 BDF 系数 $\\{\\alpha_j\\}_{j=0}^{k}$，使用隐式公式计算单步重启值 $y(t_e+h)$，并报告相对于精确解 $y_{\\text{exact}}(t_e+h) = \\exp(\\lambda (t_e+h))$ 的绝对误差。每个测试用例的结果是浮点数绝对误差 $|y(t_e+h) - y_{\\text{exact}}(t_e+h)|$。\n\n测试套件：\n- 用例 A (一般成功路径)：$\\lambda = -2.0$, $k = 3$, $h = 0.05$, $t_e = 0.9$, 事件前采样时间 $\\tau = [0.2, 0.5, 0.7]$。\n- 用例 B (边界阶数)：$\\lambda = 1.1$, $k = 1$, $h = 0.03$, $t_e = 0.2$, 事件前采样时间 $\\tau = [0.0]$。\n- 用例 C (更高阶)：$\\lambda = -4.0$, $k = 5$, $h = 0.02$, $t_e = 0.9$, 事件前采样时间 $\\tau = [0.0, 0.12, 0.25, 0.44, 0.68]$。\n- 用例 D (小步长，聚集数据)：$\\lambda = 0.5$, $k = 2$, $h = 0.005$, $t_e = 0.92$, 事件前采样时间 $\\tau = [0.88, 0.9]$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果按上述测试用例的顺序列出。例如，输出必须是 $[r_A,r_B,r_C,r_D]$ 的形式，其中每个 $r_{\\cdot}$ 是对应案例的绝对误差，表示为浮点数。", "solution": "问题陈述已经过分析并被确定为有效。它在科学上基于常微分方程数值分析的原理，是适定的，并且所有术语的定义都是客观且无矛盾的。我现在将提供严谨的解决方案。\n\n任务是计算后向差分格式 (BDF) 积分器在特定时间 $t_e$ 重启时的单步误差。此次重启需要构建一个“合成历史”——即过去等距点上的一组解值——这组值先前并不存在，因为事件前的步长与新的事件后步长 $h$ 不对齐。该问题正确地使用多项式插值来形式化此过程。\n\n解决方案是一个直接的多步计算过程。\n\n首先，我们必须构建合成历史。对于一个 $k$ 阶 BDF 方法，我们需要 $k$ 个历史点。该方法对于次数最高为 $k$ 的多项式必须是精确的。因此，生成历史的函数最自然的选择是一个次数至多为 $k$ 的多项式，我们记为 $p_k(t)$。一个次数至多为 $k$ 的唯一多项式由 $k+1$ 个不同的点确定。问题提供了这些点：$k$ 个事件前数据点 $\\{(\\tau_i, y(\\tau_i))\\}_{i=1}^{k}$ 和事件时间点本身的值 $(t_e, y(t_e))$。函数 $y(t)$ 是测试方程 $y'(t) = \\lambda y(t)$ 的精确解，即 $y(t) = \\exp(\\lambda t)$。因此，我们有 $k+1$ 个插值节点 $\\{(\\tau, \\exp(\\lambda \\tau))\\}_{\\tau \\in \\{\\tau_1, \\dots, \\tau_k, t_e\\}}$。我们找到穿过这些节点的唯一多项式 $p_k(t)$。在计算上，这通过求解一个关于多项式系数的线性系统来实现。一旦确定了 $p_k(t)$，我们就可以通过在所需的等距网格点上评估此多项式来生成合成历史值 $y_e^{(j)}$：\n$$y_e^{(j)} = p_k(t_e - j h) \\quad \\text{for } j \\in \\{0, 1, \\dots, k-1\\}$$\n\n其次，我们必须确定 $k$ 阶 BDF 的系数 $\\{\\alpha_j\\}_{j=0}^{k}$。问题提供了定义的矩条件。这些条件指出，离散微分算子对于次数最高为 $k$ 的所有单项式 $t^m$ 都必须是精确的，这导出了一个关于 $k+1$ 个未知系数的 $k+1$ 个线性方程组。该系统规定如下：\n$$\n\\sum_{j=0}^{k} \\alpha_j s_j^m =\n\\begin{cases}\n1  \\text{if } m=1 \\\\\n0  \\text{if } m \\in \\{0, 2, 3, \\dots, k\\}\n\\end{cases}\n$$\n其中 $s_j = -j$。这可以写成矩阵形式 $M \\mathbf{\\alpha} = \\mathbf{b}$，其中 $M$ 是一个范德蒙矩阵，其元素为 $M_{m,j} = (-j)^m$（行 $m \\in \\{0, \\dots, k\\}$，列 $j \\in \\{0, \\dots, k\\}$），未知向量是 $\\mathbf{\\alpha} = [\\alpha_0, \\dots, \\alpha_k]^T$，右侧向量是 $\\mathbf{b} = [0, 1, 0, \\dots, 0]^T$。求解这个非奇异系统可以得到给定阶数 $k$ 的唯一 BDF 系数组。\n\n第三，我们计算第一个事件后时间步 $t_{e}+h$ 的数值解。将 BDF 公式应用于微分方程 $y' = \\lambda y$ 在时间 $t_e+h$ 处，得到：\n$$\\alpha_0 y(t_e+h) + \\sum_{j=1}^{k} \\alpha_j y_e^{(j-1)} = h \\lambda y(t_e+h)$$\n在此，值 $y_e^{(j-1)}$ 是第一步中计算出的合成历史点。请注意，对于 $j \\in \\{1, \\dots, k\\}$，索引 $j-1$ 的范围是从 $0$ 到 $k-1$，与我们的合成值集合相匹配。这是一个关于未知数 $y(t_e+h)$ 的隐式方程，可以很容易地代数求解：\n$$y(t_e+h) = \\frac{-\\sum_{j=1}^{k} \\alpha_j y_e^{(j-1)}}{\\alpha_0 - h \\lambda}$$\n分子是合成历史的加权和，分母是方法在 $h\\lambda$ 处评估的稳定性函数。\n\n最后，我们通过计算绝对误差来量化该过程的准确性。我们将数值计算出的值 $y(t_e+h)$ 与同一点的精确解析解 $y_{\\text{exact}}(t_e+h) = \\exp(\\lambda(t_e+h))$进行比较。因此，误差为：\n$$\\text{Error} = |y(t_e+h) - y_{\\text{exact}}(t_e+h)|$$\n\n对问题陈述中指定的每个测试用例都执行这一整套操作。实现将使用稳健的数值库函数进行多项式拟合和求解 BDF 系数的线性系统。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the BDF restart problem for a suite of test cases.\n    \"\"\"\n\n    test_cases = [\n        # Case A (general happy path)\n        {'lambda_val': -2.0, 'k': 3, 'h': 0.05, 't_e': 0.9, 'tau': [0.2, 0.5, 0.7]},\n        # Case B (boundary order)\n        {'lambda_val': 1.1, 'k': 1, 'h': 0.03, 't_e': 0.2, 'tau': [0.0]},\n        # Case C (higher order)\n        {'lambda_val': -4.0, 'k': 5, 'h': 0.02, 't_e': 0.9, 'tau': [0.0, 0.12, 0.25, 0.44, 0.68]},\n        # Case D (short step, clustered data)\n        {'lambda_val': 0.5, 'k': 2, 'h': 0.005, 't_e': 0.92, 'tau': [0.88, 0.9]},\n    ]\n\n    results = []\n    for case in test_cases:\n        error = calculate_restart_error(**case)\n        results.append(error)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef calculate_restart_error(lambda_val, k, h, t_e, tau):\n    \"\"\"\n    Calculates the absolute error for a single BDF restart test case.\n\n    Args:\n        lambda_val (float): The lambda parameter of the ODE y' = lambda*y.\n        k (int): The order of the BDF method.\n        h (float): The post-event step size.\n        t_e (float): The time of the event and restart.\n        tau (list[float]): A list of k pre-event sampling times.\n\n    Returns:\n        float: The absolute error |y_computed(t_e+h) - y_exact(t_e+h)|.\n    \"\"\"\n    # Step 1: Construct the interpolating polynomial p_k(t)\n    # The interpolation nodes are the k pre-event points plus the event point.\n    interp_times = np.array(tau + [t_e])\n    \n    # The corresponding y-values are from the exact solution y(t) = exp(lambda*t)\n    interp_values = np.exp(lambda_val * interp_times)\n    \n    # Find the coefficients of the unique polynomial of degree at most k.\n    # With k+1 points, polyfit of degree k gives the exact interpolating polynomial.\n    poly_coeffs = np.polyfit(interp_times, interp_values, k)\n\n    # Step 2: Evaluate p_k(t) to get the synthetic history\n    # The synthetic history points are at t_e, t_e - h, ..., t_e - (k-1)h\n    synth_eval_times = t_e - np.arange(k) * h\n    synthetic_history = np.polyval(poly_coeffs, synth_eval_times) # y_e^(0), ..., y_e^(k-1)\n\n    # Step 3: Determine the BDF coefficients {alpha_j}\n    # This requires solving a (k+1)x(k+1) linear system M*alpha = b\n    # M_mj = (-j)^m for m, j in {0, ..., k}\n    m_powers = np.arange(k + 1).reshape(-1, 1)\n    j_bases = -np.arange(k + 1)\n    M = np.power(j_bases, m_powers)\n    \n    # The RHS vector b is [0, 1, 0, ..., 0]^T\n    b = np.zeros(k + 1)\n    b[1] = 1.0\n    \n    alpha_coeffs = np.linalg.solve(M, b) # [alpha_0, alpha_1, ..., alpha_k]\n\n    # Step 4: Compute the one-step restart value y(t_e+h)\n    # y(t_e+h) = (-sum_{j=1 to k} alpha_j * y_e^(j-1)) / (alpha_0 - h*lambda)\n    # The sum is alpha_1*y_e^0 + alpha_2*y_e^1 + ... + alpha_k*y_e^(k-1)\n    numerator_sum = np.dot(alpha_coeffs[1:], synthetic_history)\n    numerator = -numerator_sum\n    \n    denominator = alpha_coeffs[0] - h * lambda_val\n    \n    y_computed = numerator / denominator\n\n    # Step 5: Calculate the absolute error\n    y_exact = np.exp(lambda_val * (t_e + h))\n    error = np.abs(y_computed - y_exact)\n    \n    return error\n\nsolve()\n```", "id": "2401895"}]}