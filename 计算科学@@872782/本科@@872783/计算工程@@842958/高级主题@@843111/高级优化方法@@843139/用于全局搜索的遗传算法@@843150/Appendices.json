{"hands_on_practices": [{"introduction": "我们的第一个实践将深入探讨遗传算法的一个经典应用：组合优化。我们将解决字体提示 (font hinting) 问题 [@problem_id:2396561]，即在低分辨率下寻找一个字母形状的最佳像素表示。这项练习将挑战你如何将抽象的质量标准——例如易读性和形状保真度——转化为一个数学适应度函数，并使用标准的遗传算法来探索由像素模式构成的广阔搜索空间。", "problem": "您将处理一个离散全局搜索问题，该问题将低分辨率字形易读性形式化为一个组合优化任务。对于给定的整数网格大小 $N \\in \\mathbb{N}$，定义一个二值图像为一个矩阵 $X \\in \\{0,1\\}^{N \\times N}$，其中元素 $X_{r,c}=1$ 表示在第 r 行和第 c 列有一个点亮的像素，否则 $X_{r,c}=0$。设 $T \\in \\{0,1\\}^{N \\times N}$ 是一个具有相同形状的固定目标二值图像。对于一个候选解 $X$，定义以下几项：\n- 匹配项 $m(X,T)$：\n$$\nm(X,T) \\;=\\; 1 \\;-\\; \\frac{1}{N^2} \\sum_{r=0}^{N-1}\\sum_{c=0}^{N-1} \\left| X_{r,c} - T_{r,c} \\right|.\n$$\n- 连通性项 $c(X)$：令 $S(X)=\\{(r,c)\\,:\\,X_{r,c}=1\\}$，并将 $(r,c)$ 的 4-邻域定义为 $\\{(r-1,c),(r+1,c),(r,c-1),(r,c+1)\\}$（当索引在边界内时）。如果存在一个 4-邻居 $(r',c')$ 使得 $X_{r',c'}=1$，则令 $h_{r,c}(X)=1$，否则 $h_{r,c}(X)=0$。定义\n$$\nc(X) \\;=\\; \\begin{cases}\n\\displaystyle \\frac{1}{|S(X)|}\\sum_{(r,c)\\in S(X)} h_{r,c}(X),  & \\text{若 } |S(X)|>0,\\\\\n0,  & \\text{若 } |S(X)|=0.\n\\end{cases}\n$$\n- 孤立项 $i(X)$：令 $(r,c)$ 的 8-邻域为所有满足 $\\max(|r'-r|,|c'-c|)=1$ 的 $(r',c')$（当索引在边界内时）。如果存在一个 8-邻居 $(r',c')$ 使得 $X_{r',c'}=1$，则令 $g_{r,c}(X)=1$，否则 $g_{r,c}(X)=0$。定义孤立点亮像素的比例\n$$\ni(X) \\;=\\; \\begin{cases}\n\\displaystyle \\frac{1}{|S(X)|}\\sum_{(r,c)\\in S(X)} \\big(1 - g_{r,c}(X)\\big),  & \\text{若 } |S(X)|>0,\\\\\n0,  & \\text{若 } |S(X)|=0.\n\\end{cases}\n$$\n- 面积偏差项 $a(X,T)$：\n$$\na(X,T) \\;=\\; \\frac{\\big|\\;|S(X)| - |S(T)|\\;\\big|}{N^2}.\n$$\n给定非负权重 $w_m,w_c,w_i,w_a \\in \\mathbb{R}_{\\ge 0}$，需要最大化的目标函数是\n$$\nF(X;T,w_m,w_c,w_i,w_a) \\;=\\; w_m\\, m(X,T) \\;+\\; w_c\\, c(X) \\;-\\; w_i\\, i(X) \\;-\\; w_a\\, a(X,T).\n$$\n\n对于每个指定的测试用例，您的程序必须在严格的评估预算 $B \\in \\mathbb{N}$ 的限制下搜索域 $\\{0,1\\}^{N \\times N}$，并报告在该预算内找到的最大目标值。一次评估是指对一个特定的 $X$ 计算 $F(X;T,w_m,w_c,w_i,w_a)$。您必须将每个报告的值四舍五入到 6 位小数。\n\n测试套件规范。在所有情况下，索引都是从零开始的，行 $r \\in \\{0,1,\\dots,N-1\\}$，列 $c \\in \\{0,1,\\dots,N-1\\}$。每个目标 $T$ 都被明确定义为点亮像素的集合 $S(T) \\subset \\{0,\\dots,N-1\\} \\times \\{0,\\dots,N-1\\}$。\n\n- 用例 1（理想路径）：$N=8$，权重 $(w_m,w_c,w_i,w_a)=(0.6,\\,0.3,\\,0.4,\\,0.2)$，预算 $B=6000$。目标 $T$ 编码一个类似于字母 E 的块状字形，带有一个垂直主干和三个水平条：\n  1. 垂直主干：所有满足 $r \\in \\{1,2,3,4,5,6\\}$ 和 $c=1$ 的 $(r,c)$。\n  2. 顶条：所有满足 $r=1$ 和 $c \\in \\{1,2,3,4,5\\}$ 的 $(r,c)$。\n  3. 中间条：所有满足 $r=3$ 和 $c \\in \\{1,2,3,4\\}$ 的 $(r,c)$。\n  4. 底条：所有满足 $r=6$ 和 $c \\in \\{1,2,3,4,5\\}$ 的 $(r,c)$。\n\n- 用例 2（边界尺寸和更强的正则化）：$N=5$，权重 $(w_m,w_c,w_i,w_a)=(0.5,\\,0.2,\\,0.7,\\,0.6)$，预算 $B=2000$。目标 $T$ 是一个最小化的 E：\n  1. 垂直主干：所有满足 $r \\in \\{1,2,3\\}$ 和 $c=1$ 的 $(r,c)$。\n  2. 顶条：所有满足 $r=1$ 和 $c \\in \\{1,2,3\\}$ 的 $(r,c)$。\n  3. 中间条：所有满足 $r=2$ 和 $c \\in \\{1,2\\}$ 的 $(r,c)$。\n  4. 底条：所有满足 $r=3$ 和 $c \\in \\{1,2,3\\}$ 的 $(r,c)$。\n\n- 用例 3（类对角线结构和强调连通性）：$N=8$，权重 $(w_m,w_c,w_i,w_a)=(0.5,\\,0.6,\\,0.3,\\,0.2)$，预算 $B=8000$。目标 $T$ 编码一个类似于字母 A 的块状字形，带有两个垂直支腿、一个顶条和一个横杆：\n  1. 左支腿：所有满足 $r \\in \\{2,3,4,5,6\\}$ 和 $c=1$ 的 $(r,c)$。\n  2. 右支腿：所有满足 $r \\in \\{2,3,4,5,6\\}$ 和 $c=6$ 的 $(r,c)$。\n  3. 顶条：所有满足 $r=1$ 和 $c \\in \\{2,3,4,5\\}$ 的 $(r,c)$。\n  4. 横杆：所有满足 $r=4$ 和 $c \\in \\{2,3,4,5\\}$ 的 $(r,c)$。\n\n最终输出格式。您的程序应生成单行输出，其中包含用例 1、2 和 3 的三个四舍五入后的目标值，按此顺序排列，形式为用方括号括起来的逗号分隔列表。例如，它必须以 [$v_1$,$v_2$,$v_3$] 的形式精确打印一行，其中每个 $v_k$ 是一个使用标准四舍五入取到 6 位小数的实数。", "solution": "所呈现的问题是一个离散全局搜索任务，要求在一个高维二值空间上最大化一个复杂的目标函数。一个大小为 $N \\times N$ 的二值图像的搜索空间是 $\\{0,1\\}^{N \\times N}$，其中包含 $2^{N^2}$ 种可能的配置。对于给定的 $N=5$ 和 $N=8$，搜索空间分别有 $2^{25} \\approx 3.3 \\times 10^7$ 和 $2^{64} \\approx 1.8 \\times 10^{19}$ 个成员。穷举搜索在计算上是不可行的。该问题施加了严格的评估预算，这将其框定为一个黑盒优化任务，其目标是在有限次数的函数评估内找到最佳可能解。这种结构使得使用元启发式搜索算法成为必要。\n\n遗传算法 (Genetic Algorithm, GA) 是解决此类问题的一种非常适合的方法。遗传算法受到自然选择过程的启发，在探索大型、复杂且知之甚少的搜索空间方面非常有效。目标函数 $F(X;T,w_m,w_c,w_i,w_a)$ 是衡量相似性、连通性及其他结构特性的几个分量的加权和，这很可能导致一个具有许多局部最优解的崎岖适应度景观。由于遗传算法采用基于种群的方法和诸如交叉、变异等随机算子，因此对于陷入此类局部最优解具有鲁棒性。\n\n所实现的解决方案是根据此问题的具体情况量身定制的标准遗传算法。\n\n**1. 表示法与种群**\n种群中的一个个体代表一个候选解，它是一个 $N \\times N$ 的二值矩阵 $X$。种群由固定数量的此类个体组成。为了可复现性，伪随机数生成器使用一个常量值作为种子。初始种群以目标图像 $T$ 本身、$T$ 的几个变异版本以及大部分随机生成的图像作为种子，以确保在利用已知优良区域和探索更广阔搜索空间之间取得平衡。\n\n**2. 适应度评估**\n个体 $X$ 的适应度由目标函数 $F(X;T,w_m,w_c,w_i,w_a)$ 决定。该函数的各分量计算如下：\n- 匹配项 $m(X,T) = 1 - \\frac{1}{N^2} \\sum_{r,c} |X_{r,c} - T_{r,c}|$ 是候选图像与目标图像之间的归一化一致性。\n- 面积偏差项 $a(X,T) = \\frac{|\\sum X_{r,c} - \\sum T_{r,c}|}{N^2}$ 惩罚点亮像素数量上的差异。\n- 连通性项 $c(X)$ 和孤立项 $i(X)$ 需要分析像素邻域。这些项可以通过二维卷积高效计算。使用 `scipy.signal.convolve2d` 和适当的核，通过一次操作即可计算出整个网格中每个像素的点亮邻居数量。对于使用 4-邻域的 $c(X)$，其核为 $\\begin{pmatrix} 0 & 1 & 0 \\\\ 1 & 0 & 1 \\\\ 0 & 1 & 0 \\end{pmatrix}$。对于基于 8-邻域的 $i(X)$，其核为 $\\begin{pmatrix} 1 & 1 & 1 \\\\ 1 & 0 & 1 \\\\ 1 & 1 & 1 \\end{pmatrix}$。这种向量化方法比遍历像素要高效得多。一个 `Evaluator` 类封装了适应度计算，并严格执行评估预算 $B$。\n\n**3. 选择**\n锦标赛选择法用于为下一代选择父代。在 k-路锦标赛中，从当前种群中随机选择 k 个个体，适应度最高的个体被选为父代。该方法在选择压力和种群多样性之间提供了良好的平衡。\n\n**4. 遗传算子**\n- **交叉**：采用均匀交叉。对于每个像素位置，随机选择由哪个父代将其像素值贡献给子代。该算子有效地结合了双亲的特征。\n- **变异**：在交叉后对子代应用位翻转变异。每个像素值（位）都有一个小的独立概率被翻转。变异率设置为 $1/N^2$，平均每个个体会发生一次变异，从而引入新的遗传物质并防止过早收敛。\n\n**5. 世代循环与精英保留**\n遗传算法以代为单位进行。在每个循环中，从旧种群创建新种群。该算法实施了精英保留策略，即当前代中少数表现最佳的个体保证存活，从而保留高质量的解。新种群的其余部分由通过选择、交叉和变异生成的子代填充。一旦评估预算 $B$ 耗尽，算法即终止，并将整个运行期间发现的最高适应度值作为结果报告。\n\n这种系统化的、基于原则的设计确保了一个鲁棒的搜索过程，能够在指定的计算约束内，在复杂的适应度景观中导航，为给定的字形易读性问题找到高质量的解。", "answer": "```python\nimport numpy as np\nfrom scipy.signal import convolve2d\n\n# Static seed for reproducibility across runs\nRNG = np.random.default_rng(42)\n\nclass FitnessEvaluator:\n    \"\"\"Calculates the fitness of a candidate image and manages the evaluation budget.\"\"\"\n    def __init__(self, target_matrix, weights, budget):\n        self.T = target_matrix\n        self.N = self.T.shape[0]\n        self.w_m, self.w_c, self.w_i, self.w_a = weights\n        \n        self.target_pixel_count = np.sum(self.T)\n        self.N_squared = self.N * self.N\n        \n        self.kernel_4_conn = np.array([[0, 1, 0], [1, 0, 1], [0, 1, 0]], dtype=np.uint8)\n        self.kernel_8_conn = np.array([[1, 1, 1], [1, 0, 1], [1, 1, 1]], dtype=np.uint8)\n        \n        self.eval_budget = budget\n        self.eval_count = 0\n        self.max_fitness_found = -np.inf\n\n    def calculate_fitness(self, X):\n        \"\"\"Computes the objective function F for a given image X.\"\"\"\n        if self.eval_count >= self.eval_budget:\n            return None\n\n        # Match term m(X, T)\n        match_term = 1.0 - np.sum(np.abs(X - self.T)) / self.N_squared\n        \n        pixel_count = np.sum(X)\n        \n        if pixel_count == 0:\n            conn_term = 0.0\n            iso_term = 0.0\n        else:\n            # Connectivity term c(X) using 4-neighborhood\n            neighbors_4 = convolve2d(X, self.kernel_4_conn, mode='same', boundary='fill', fillvalue=0)\n            connected_pixels = (neighbors_4 > 0) * X\n            conn_term = np.sum(connected_pixels) / pixel_count\n            \n            # Isolation term i(X) using 8-neighborhood\n            neighbors_8 = convolve2d(X, self.kernel_8_conn, mode='same', boundary='fill', fillvalue=0)\n            isolated_pixels = (neighbors_8 == 0) * X\n            iso_term = np.sum(isolated_pixels) / pixel_count\n            \n        # Area-deviation term a(X, T)\n        area_dev_term = np.abs(pixel_count - self.target_pixel_count) / self.N_squared\n        \n        fitness = (self.w_m * match_term + \n                   self.w_c * conn_term - \n                   self.w_i * iso_term - \n                   self.w_a * area_dev_term)\n        \n        self.eval_count += 1\n        if fitness > self.max_fitness_found:\n            self.max_fitness_found = fitness\n            \n        return fitness\n\ndef tournament_selection_idx(fitnesses, k):\n    \"\"\"Selects an individual's index using a tournament.\"\"\"\n    pop_size = len(fitnesses)\n    contender_indices = RNG.choice(pop_size, k, replace=False)\n    \n    best_contender_idx = -1\n    best_fitness = -np.inf\n    \n    for idx in contender_indices:\n        if fitnesses[idx] > best_fitness:\n            best_fitness = fitnesses[idx]\n            best_contender_idx = idx\n            \n    return best_contender_idx\n\ndef uniform_crossover(p1, p2):\n    \"\"\"Performs uniform crossover on two parents.\"\"\"\n    mask = RNG.integers(0, 2, size=p1.shape, dtype=np.uint8)\n    child1 = p1 * mask + p2 * (1 - mask)\n    child2 = p2 * mask + p1 * (1 - mask)\n    return child1, child2\n\ndef mutate(individual, mutation_rate):\n    \"\"\"Applies bit-flip mutation to an individual.\"\"\"\n    mutation_mask = RNG.random(individual.shape)  mutation_rate\n    individual[mutation_mask] = 1 - individual[mutation_mask]\n\ndef run_genetic_algorithm(N, target_pixels, weights, budget):\n    \"\"\"Main GA loop for a single test case.\"\"\"\n    \n    target_matrix = np.zeros((N, N), dtype=np.uint8)\n    for r, c in target_pixels:\n        target_matrix[r, c] = 1\n        \n    evaluator = FitnessEvaluator(target_matrix, weights, budget)\n    \n    # GA Parameters\n    pop_size = 100\n    elite_size = 2\n    tournament_k = 3\n    mutation_rate = 1.0 / (N * N)\n    crossover_prob = 0.9\n\n    # Initialization\n    population = []\n    fitnesses = []\n    \n    # Seed population with target, its mutations, and random individuals\n    initial_seeds = [(target_matrix.copy(), 0), (target_matrix.copy(), int(0.05 * N*N)), (target_matrix.copy(), int(0.1 * N*N))]\n    for ind, num_flips in initial_seeds:\n        if num_flips > 0:\n            indices_to_flip = RNG.choice(N * N, num_flips, replace=False)\n            flat_ind = ind.flatten()\n            flat_ind[indices_to_flip] = 1 - flat_ind[indices_to_flip]\n            ind = flat_ind.reshape((N, N))\n        \n        fit = evaluator.calculate_fitness(ind)\n        if fit is not None:\n            population.append(ind)\n            fitnesses.append(fit)\n\n    while len(population)  pop_size:\n        individual = RNG.integers(0, 2, size=(N, N), dtype=np.uint8)\n        fit = evaluator.calculate_fitness(individual)\n        if fit is None: break\n        population.append(individual)\n        fitnesses.append(fit)\n\n    if not population: return -np.inf\n\n    # Main generational loop\n    while evaluator.eval_count  evaluator.eval_budget:\n        # Sort population by fitness for elitism\n        sorted_indices = np.argsort(fitnesses)\n        new_population = [population[i] for i in sorted_indices[-elite_size:]]\n        new_fitnesses = [fitnesses[i] for i in sorted_indices[-elite_size:]]\n\n        # Generate offspring\n        while len(new_population)  pop_size:\n            parent1_idx = tournament_selection_idx(fitnesses, tournament_k)\n            parent2_idx = tournament_selection_idx(fitnesses, tournament_k)\n            parent1 = population[parent1_idx]\n            parent2 = population[parent2_idx]\n\n            if RNG.random()  crossover_prob:\n                child1, child2 = uniform_crossover(parent1, parent2)\n            else:\n                child1, child2 = parent1.copy(), parent2.copy()\n            \n            mutate(child1, mutation_rate)\n            mutate(child2, mutation_rate)\n\n            fit1 = evaluator.calculate_fitness(child1)\n            if fit1 is None: break\n            new_population.append(child1)\n            new_fitnesses.append(fit1)\n            \n            if len(new_population)  pop_size:\n                fit2 = evaluator.calculate_fitness(child2)\n                if fit2 is None: break\n                new_population.append(child2)\n                new_fitnesses.append(fit2)\n            \n        if evaluator.eval_count >= evaluator.eval_budget: break\n\n        population = new_population\n        fitnesses = new_fitnesses\n\n    return evaluator.max_fitness_found\n\ndef solve():\n    test_cases = [\n        {\n            \"N\": 8, \"weights\": (0.6, 0.3, 0.4, 0.2), \"budget\": 6000,\n            \"target_pixels\": set(\n                [(r, 1) for r in range(1, 7)] + [(1, c) for c in range(1, 6)] +\n                [(3, c) for c in range(1, 5)] + [(6, c) for c in range(1, 6)]\n            )\n        },\n        {\n            \"N\": 5, \"weights\": (0.5, 0.2, 0.7, 0.6), \"budget\": 2000,\n            \"target_pixels\": set(\n                [(r, 1) for r in range(1, 4)] + [(1, c) for c in range(1, 4)] +\n                [(2, c) for c in range(1, 3)] + [(3, c) for c in range(1, 4)]\n            )\n        },\n        {\n            \"N\": 8, \"weights\": (0.5, 0.6, 0.3, 0.2), \"budget\": 8000,\n            \"target_pixels\": set(\n                [(r, 1) for r in range(2, 7)] + [(r, 6) for r in range(2, 7)] +\n                [(1, c) for c in range(2, 6)] + [(4, c) for c in range(2, 6)]\n            )\n        }\n    ]\n    \n    results = []\n    for case in test_cases:\n        max_val = run_genetic_algorithm(\n            case[\"N\"], case[\"target_pixels\"], case[\"weights\"], case[\"budget\"]\n        )\n        results.append(round(max_val, 6))\n    \n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "2396561"}, {"introduction": "在掌握了基本原理之后，我们的第二个实践将从离散域过渡到连续域，这是工程设计中常见的场景。你将使用一个实数编码遗传算法 (real-coded genetic algorithm, RCGA) 来优化一个超材料单元的几何形状，目标是实现一种特定的热学特性 [@problem_id:2396545]。这项练习将向你介绍连续优化中的关键技术，包括实数编码的染色体、算术交叉算子以及用于处理设计约束的罚函数法。", "problem": "您的任务是实现一个实数编码遗传算法（GA），对一个超材料晶胞的有效热膨胀响应的简化无量纲代理模型进行全局搜索。目标是最小化一个近似于有效热膨胀系数的标量目标。所有角度必须以弧度为单位处理。最终答案必须是无量纲实数。\n\n本任务的基础知识包括：(i) 优化的定义，即在一个定义域上寻找使标量函数最小化的参数的搜索过程；(ii) 基于种群的随机搜索（遗传算法）的定义，其通过选择、交叉和变异进行繁殖；以及 (iii) 用于约束优化的罚函数法。\n\n决策变量和定义域：\n- 设染色体为一个向量 $\\mathbf{x} = (t, s, \\phi)$，其中 $t$ 是厚度比，$s$ 是铰链柔度比，$\\phi$ 是以弧度为单位的内凹角。这些都是无量纲的。\n- 标称变量定义域为：\n  - $t \\in [0.05, 0.95]$，\n  - $s \\in [0.10, 0.90]$，\n  - $\\phi \\in [0.10, 1.30]$ 弧度。\n- 派生的相对密度代理值为 $r_d(t,s) = 0.5\\,t + 0.5\\,(1 - s)$，其必须满足 $r_d \\in [0.20, 0.80]$。\n\n目标函数（待最小化）：\n通过下式定义代理目标函数 $f(t,s,\\phi)$：\n$$\nf(t,s,\\phi) = c_0 + c_1 t + c_2 s + c_3 \\sin(\\phi) + c_4 t s - c_5 s \\sin(\\phi) - c_6 (1 - t) \\sin(\\phi) + \\Pi_{\\text{dens}}(t,s) + \\Pi_{\\text{box}}(t,s,\\phi),\n$$\n其中常数为\n$$\nc_0=0.2,\\quad c_1=0.1,\\quad c_2=0.15,\\quad c_3=0.3,\\quad c_4=0.05,\\quad c_5=0.6,\\quad c_6=0.5.\n$$\n罚项用于强制执行约束条件，\n$$\n\\Pi_{\\text{dens}}(t,s) = M \\left(\\max\\{0, r_d(t,s) - 0.80\\}\\right)^2 + M \\left(\\max\\{0, 0.20 - r_d(t,s)\\}\\right)^2,\n$$\n$$\n\\Pi_{\\text{box}}(t,s,\\phi) = B\\left(\\max\\{0, t - \\overline{t}\\}\\right)^2 + B\\left(\\max\\{0, \\underline{t} - t\\}\\right)^2 + B\\left(\\max\\{0, s - \\overline{s}\\}\\right)^2 + B\\left(\\max\\{0, \\underline{s} - s\\}\\right)^2 + B\\left(\\max\\{0, \\phi - \\overline{\\phi}\\}\\right)^2 + B\\left(\\max\\{0, \\underline{\\phi} - \\phi\\}\\right)^2,\n$$\n其中 $M=10$，$B=100$，且 $(\\underline{t},\\overline{t})=(0.05,0.95)$，$(\\underline{s},\\overline{s})=(0.10,0.90)$，$(\\underline{\\phi},\\overline{\\phi})=(0.10,1.30)$，除非测试用例为 $\\phi$ 指定了不同的界限。\n\n遗传算法设计要求：\n- 染色体编码：实值向量 $\\mathbf{x}\\in\\mathbb{R}^3$。\n- 初始化：在每个决策变量的箱式界限内进行均匀采样。\n- 适应度：与 $f(t,s,\\phi)$ 相同；为最小化目标。\n- 选择：锦标赛选择，锦标赛大小 $k=3$。\n- 交叉：算术交叉，其中两个父代 $\\mathbf{x}^{(1)}$ 和 $\\mathbf{x}^{(2)}$ 产生两个子代\n  $\\mathbf{y}^{(1)} = \\omega \\mathbf{x}^{(1)} + (1-\\omega)\\mathbf{x}^{(2)}$，$\\mathbf{y}^{(2)} = \\omega \\mathbf{x}^{(2)} + (1-\\omega)\\mathbf{x}^{(1)}$，\n  其中 $\\omega \\sim \\text{Uniform}[0,1]$，以概率 $p_c$ 应用。\n- 变异：每个基因以概率 $p_m$ 应用独立高斯变异；对于基因 $j$，\n  $y_j \\leftarrow y_j + \\mathcal{N}\\!\\left(0, \\sigma^2 (\\overline{b}_j - \\underline{b}_j)^2\\right)$，其中 $[\\underline{b}_j,\\overline{b}_j]$ 是基因 $j$ 的界限，$\\sigma$ 是一个标量缩放因子。变异后，将值裁剪至箱式界限内。\n- 精英保留：将最优的 $E=\\max\\{1,\\lfloor 0.05\\,N \\rfloor\\}$ 个个体不加改变地复制到下一代，其中 $N$ 是种群大小。\n- 终止条件：固定的代数 $G$。\n- 随机性：所有随机数生成都必须按照指定设置种子，以确保确定性输出。\n\n角度单位：\n- 所有角度 $\\phi$ 均以弧度为单位。\n\n测试套件：\n在以下三个测试用例上实现并运行遗传算法。每个测试用例都由其界限、算法超参数和随机种子完全指定。\n\n- 测试用例 A（通用“理想路径”）：\n  - 界限：$t \\in [0.05,0.95]$，$s \\in [0.10,0.90]$，$\\phi \\in [0.10,1.30]$ 弧度。\n  - 种群大小 $N=60$，代数 $G=120$，交叉概率 $p_c=0.9$，每个基因的变异概率 $p_m=0.2$，变异尺度 $\\sigma=0.05$。\n  - 随机种子：$12345$。\n\n- 测试用例 B（角度处于边界；小内凹角）：\n  - 界限：$t \\in [0.05,0.95]$，$s \\in [0.10,0.90]$，$\\phi \\in [0.10,0.25]$ 弧度。\n  - 种群大小 $N=80$，代数 $G=180$，交叉概率 $p_c=0.9$，每个基因的变异概率 $p_m=0.2$，变异尺度 $\\sigma=0.04$。\n  - 随机种子：$2023$。\n\n- 测试用例 C（小种群但大角度的边缘情况）：\n  - 界限：$t \\in [0.05,0.95]$，$s \\in [0.10,0.90]$，$\\phi \\in [1.10,1.30]$ 弧度。\n  - 种群大小 $N=25$，代数 $G=300$，交叉概率 $p_c=0.8$，每个基因的变异概率 $p_m=0.3$，变异尺度 $\\sigma=0.06$。\n  - 随机种子：$314159$。\n\n要求输出：\n- 对于每个测试用例，计算遗传算法在终止时找到的最佳（最低）目标值 $f_{\\min}$。\n- 您的程序应生成单行输出，其中包含三个结果，格式为方括号内以逗号分隔的列表，每个值四舍五入到 $6$ 位小数，顺序为 A、B、C。例如，确切格式必须为 [$x_1,x_2,x_3$] 的形式，其中 $x_1$、$x_2$ 和 $x_3$ 是四舍五入到 $6$ 位小数的实数。", "solution": "问题陈述已经过严格验证，并被确定为有效。它具有科学依据、适定且客观。它为实现一个实数编码遗传算法以解决一个明确定义的优化问题提供了完整、自洽且计算上可行的规范。所有参数、约束和算法组件都得到了精确描述，从而可以获得一个确定性且可验证的解。\n\n任务是找到代理目标函数 $f(t,s,\\phi)$ 的最小值，该函数是三个无量纲决策变量的函数：厚度比 $t$、铰链柔度比 $s$ 和内凹角 $\\phi$。搜索使用遗传算法（GA）进行，这是一种受自然选择原理启发的随机优化启发式算法。解决方案通过精确地按照规范实现此算法来构建。\n\n首先，我们定义要最小化的目标函数。它由一个基础代理模型和用于施加约束的罚项组成。完整的函数为：\n$$\nf(t,s,\\phi) = c_0 + c_1 t + c_2 s + c_3 \\sin(\\phi) + c_4 t s - c_5 s \\sin(\\phi) - c_6 (1 - t) \\sin(\\phi) + \\Pi_{\\text{dens}}(t,s) + \\Pi_{\\text{box}}(t,s,\\phi)\n$$\n常数给定为 $c_0=0.2$，$c_1=0.1$，$c_2=0.15$，$c_3=0.3$，$c_4=0.05$，$c_5=0.6$ 和 $c_6=0.5$。\n\n约束通过外点罚函数法处理。对派生量——相对密度代理值 $r_d(t,s) = 0.5\\,t + 0.5\\,(1 - s)$ 的一个约束，要求 $r_d \\in [0.20, 0.80]$。这由罚项 $\\Pi_{\\text{dens}}(t,s)$ 强制执行：\n$$\n\\Pi_{\\text{dens}}(t,s) = M \\left(\\max\\{0, r_d(t,s) - 0.80\\}\\right)^2 + M \\left(\\max\\{0, 0.20 - r_d(t,s)\\}\\right)^2\n$$\n罚参数 $M=10$。\n对决策变量的箱式约束，$t \\in [\\underline{t}, \\overline{t}]$，$s \\in [\\underline{s}, \\overline{s}]$ 和 $\\phi \\in [\\underline{\\phi}, \\overline{\\phi}]$，形式上由罚项 $\\Pi_{\\text{box}}(t,s,\\phi)$ 处理：\n$$\n\\Pi_{\\text{box}}(t,s,\\phi) = B\\sum_{j \\in \\{t,s,\\phi\\}} \\left( \\left(\\max\\{0, x_j - \\overline{x}_j\\}\\right)^2 + \\left(\\max\\{0, \\underline{x}_j - x_j\\}\\right)^2 \\right)\n$$\n罚参数 $B=100$。尽管指定的遗传算法机制中的初始化和变异裁剪确保所有被评估的个体都位于这些箱式界限内，使得该项在功能上为零，但根据问题陈述，为了形式上的完整性，它仍被包含在目标函数的定义中。\n\n遗传算法作为一个代际模型实现，包含以下组件：\n1.  **染色体和种群：** 种群中的每个个体（染色体）都由一个实值向量 $\\mathbf{x} = (t, s, \\phi) \\in \\mathbb{R}^3$ 表示。一个种群由 $N$ 个这样的个体组成。初始种群是通过为每个个体的每个变量在其指定定义域内进行均匀随机抽样生成的。\n2.  **适应度评估：** 个体的适应度就是其目标函数值 $f(\\mathbf{x})$。该算法旨在最小化此值。\n3.  **进化周期：** 算法进行固定的代数 $G$。在每一代中，从旧种群创建新种群。\n4.  **精英保留：** 为确保保留迄今为止找到的最佳解，一组精英个体被直接带到下一代。精英个体的数量为 $E=\\max\\{1,\\lfloor 0.05\\,N \\rfloor\\}$。\n5.  **繁殖：** 新一代中剩余的 $N-E$ 个个体通过选择、交叉和变异产生。\n    -   **选择：** 使用锦标赛选择法从当前种群中选择父代。对于每个所需的父代，进行一次大小为 $k=3$ 的锦标赛：从种群中随机选择 $3$ 个个体，适应度最佳（最低）的那个被宣布为获胜者，并成为父代。\n    -   **交叉：** 被选中的父代进行配对。以交叉概率 $p_c$，一对父代 $\\mathbf{x}^{(1)}$ 和 $\\mathbf{x}^{(2)}$ 通过算术交叉产生两个子代 $\\mathbf{y}^{(1)}$ 和 $\\mathbf{y}^{(2)}$：\n        $$\n        \\mathbf{y}^{(1)} = \\omega \\mathbf{x}^{(1)} + (1-\\omega)\\mathbf{x}^{(2)}\n        $$\n        $$\n        \\mathbf{y}^{(2)} = \\omega \\mathbf{x}^{(2)} + (1-\\omega)\\mathbf{x}^{(1)}\n        $$\n        其中 $\\omega$ 是从 $\\text{Uniform}[0,1]$ 中抽取的随机变量。如果不发生交叉，子代就是父代的直接复制。\n    -   **变异：** 每个新子代的每个基因（分量）都有概率 $p_m$ 发生变异。如果一个基因 $y_j$ 被选中进行变异，其值会通过添加高斯噪声来改变：\n        $$\n        y_j \\leftarrow y_j + \\mathcal{N}\\!\\left(0, \\sigma^2 (\\overline{b}_j - \\underline{b}_j)^2\\right)\n        $$\n        其中 $[\\underline{b}_j, \\overline{b}_j]$ 是基因 $j$ 的有效范围，$\\sigma$ 是给定的变异尺度因子。变异后，基因的值被裁剪以确保其保持在界限 $[\\underline{b}_j, \\overline{b}_j]$ 内。\n\n由于每个测试用例都使用了指定的随机种子，整个过程是确定性的。该算法针对提供的三个不同测试用例执行，并报告每个用例在终止时找到的最佳适应度值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to define, run, and report results for all test cases.\n    \"\"\"\n    # Global constants for the objective function as per the problem statement.\n    CONSTANTS = {\n        'c': [0.2, 0.1, 0.15, 0.3, 0.05, 0.6, 0.5], # c0 through c6\n        'M': 10.0,\n        'B': 100.0\n    }\n\n    def objective_function(x, bounds):\n        \"\"\"\n        Calculates the objective function value for a given individual x.\n        x is a numpy array [t, s, phi].\n        bounds is a dictionary {'t':(min,max), 's':(min,max), 'phi':(min,max)}.\n        \"\"\"\n        t, s, phi = x[0], x[1], x[2]\n        c0, c1, c2, c3, c4, c5, c6 = CONSTANTS['c']\n        M = CONSTANTS['M']\n        B = CONSTANTS['B']\n        \n        t_min, t_max = bounds['t']\n        s_min, s_max = bounds['s']\n        phi_min, phi_max = bounds['phi']\n\n        # Base surrogate objective function F(t,s,phi)\n        f_base = (c0 + c1 * t + c2 * s + c3 * math.sin(phi) + \n                  c4 * t * s - c5 * s * math.sin(phi) - \n                  c6 * (1.0 - t) * math.sin(phi))\n\n        # Derived relative density proxy and its penalty\n        r_d = 0.5 * t + 0.5 * (1.0 - s)\n        pi_dens = M * (max(0.0, r_d - 0.8)**2) + M * (max(0.0, 0.2 - r_d)**2)\n\n        # Box constraint penalty. This is included for formal correctness, though\n        # clipping in the GA ensures individuals are always within bounds.\n        pi_box_t = B * (max(0.0, t - t_max)**2) + B * (max(0.0, t_min - t)**2)\n        pi_box_s = B * (max(0.0, s - s_max)**2) + B * (max(0.0, s_min - s)**2)\n        pi_box_phi = B * (max(0.0, phi - phi_max)**2) + B * (max(0.0, phi_min - phi)**2)\n        pi_box = pi_box_t + pi_box_s + pi_box_phi\n\n        return f_base + pi_dens + pi_box\n\n    class GeneticAlgorithm:\n        \"\"\"\n        Implements the specified real-coded Genetic Algorithm.\n        \"\"\"\n        def __init__(self, bounds, N, G, pc, pm, sigma, k, seed):\n            self.bounds = bounds\n            self.bounds_arr = np.array([bounds['t'], bounds['s'], bounds['phi']])\n            self.N = N\n            self.G = G\n            self.pc = pc\n            self.pm = pm\n            self.sigma = sigma\n            self.k = k\n            self.rng = np.random.default_rng(seed)\n            self.E = max(1, math.floor(0.05 * self.N))\n            self.population = None\n            self.best_fitness_overall = float('inf')\n\n        def _initialize_population(self):\n            pop = np.zeros((self.N, 3))\n            pop[:, 0] = self.rng.uniform(self.bounds['t'][0], self.bounds['t'][1], self.N)\n            pop[:, 1] = self.rng.uniform(self.bounds['s'][0], self.bounds['s'][1], self.N)\n            pop[:, 2] = self.rng.uniform(self.bounds['phi'][0], self.bounds['phi'][1], self.N)\n            return pop\n\n        def _evaluate_population(self, pop):\n            return np.array([objective_function(ind, self.bounds) for ind in pop])\n\n        def _tournament_selection(self, pop, fitnesses):\n            indices = self.rng.choice(self.N, size=self.k, replace=False)\n            tournament_fitnesses = fitnesses[indices]\n            winner_idx_in_tournament = np.argmin(tournament_fitnesses)\n            winner_idx_in_pop = indices[winner_idx_in_tournament]\n            return pop[winner_idx_in_pop]\n\n        def _mutate_individual(self, ind):\n            for j in range(3):\n                if self.rng.random()  self.pm:\n                    gene_range = self.bounds_arr[j, 1] - self.bounds_arr[j, 0]\n                    std_dev = self.sigma * gene_range\n                    noise = self.rng.normal(loc=0.0, scale=std_dev)\n                    ind[j] += noise\n            return np.clip(ind, self.bounds_arr[:, 0], self.bounds_arr[:, 1])\n\n        def run(self):\n            self.population = self._initialize_population()\n\n            for _ in range(self.G):\n                fitnesses = self._evaluate_population(self.population)\n                \n                # Track the best fitness found in any generation\n                min_fitness_current_gen = np.min(fitnesses)\n                if min_fitness_current_gen  self.best_fitness_overall:\n                    self.best_fitness_overall = min_fitness_current_gen\n\n                # Elitism: preserve the best E individuals\n                elite_indices = np.argsort(fitnesses)[:self.E]\n                elites = self.population[elite_indices]\n                \n                new_population = [None] * self.N\n                new_population[:self.E] = elites\n\n                # Reproduction: create N-E new individuals\n                num_offspring = self.N - self.E\n                \n                offspring_list = []\n                for _ in range(num_offspring // 2):\n                    p1 = self._tournament_selection(self.population, fitnesses)\n                    p2 = self._tournament_selection(self.population, fitnesses)\n\n                    if self.rng.random()  self.pc:\n                        omega = self.rng.random()\n                        c1 = omega * p1 + (1 - omega) * p2\n                        c2 = omega * p2 + (1 - omega) * p1\n                    else:\n                        c1, c2 = p1.copy(), p2.copy()\n                    \n                    offspring_list.append(self._mutate_individual(c1))\n                    offspring_list.append(self._mutate_individual(c2))\n\n                if num_offspring % 2 == 1:\n                    p1 = self._tournament_selection(self.population, fitnesses)\n                    c1 = p1.copy()\n                    offspring_list.append(self._mutate_individual(c1))\n\n                new_population[self.E:] = offspring_list\n                self.population = np.array(new_population)\n            \n            # Final evaluation at termination\n            final_fitnesses = self._evaluate_population(self.population)\n            final_min_fitness = np.min(final_fitnesses)\n            if final_min_fitness  self.best_fitness_overall:\n                 self.best_fitness_overall = final_min_fitness\n            \n            return self.best_fitness_overall\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"bounds\": {'t': (0.05, 0.95), 's': (0.10, 0.90), 'phi': (0.10, 1.30)},\n            \"N\": 60, \"G\": 120, \"pc\": 0.9, \"pm\": 0.2, \"sigma\": 0.05, \"k\": 3, \"seed\": 12345\n        },\n        {\n            \"bounds\": {'t': (0.05, 0.95), 's': (0.10, 0.90), 'phi': (0.10, 0.25)},\n            \"N\": 80, \"G\": 180, \"pc\": 0.9, \"pm\": 0.2, \"sigma\": 0.04, \"k\": 3, \"seed\": 2023\n        },\n        {\n            \"bounds\": {'t': (0.05, 0.95), 's': (0.10, 0.90), 'phi': (1.10, 1.30)},\n            \"N\": 25, \"G\": 300, \"pc\": 0.8, \"pm\": 0.3, \"sigma\": 0.06, \"k\": 3, \"seed\": 314159\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        ga = GeneticAlgorithm(\n            bounds=case[\"bounds\"], N=case[\"N\"], G=case[\"G\"],\n            pc=case[\"pc\"], pm=case[\"pm\"], sigma=case[\"sigma\"],\n            k=case[\"k\"], seed=case[\"seed\"]\n        )\n        best_f = ga.run()\n        results.append(best_f)\n\n    # Final print statement in the exact required format.\n    rounded_results = [round(r, 6) for r in results]\n    print(f\"[{','.join(map(str, rounded_results))}]\")\n\nsolve()\n```", "id": "2396545"}, {"introduction": "我们最后的实践将挑战提升至一个更高的层次，专注于为棘手的 NP-hard 问题设计“智能”算子。你将通过实现一个能够感知图结构的自定义交叉算子来解决最小顶点覆盖问题 (Minimum Vertex Cover) [@problem_id:2396605]，该算子能够识别并保留如图中的三角形和星形等关键“构建模块”。这项练习揭示了高级元启发式算法的一个核心原则：将领域知识嵌入搜索过程，是解决最复杂计算问题的关键。", "problem": "给定一个有限、无向、简单的图 $G = (V,E)$，其中 $|V| = n$ 且 $|E| = m$。顶点覆盖是一个子集 $C \\subseteq V$，使得对于每条边 $(u,v) \\in E$，都有 $u \\in C$ 或 $v \\in C$。最小顶点覆盖问题是找到一个基数最小的顶点覆盖。染色体是一个二进制向量 $x \\in \\{0,1\\}^n$，其中索引 $i$ 对应于顶点 $i \\in V$，$x_i = 1$ 当且仅当顶点 $i$ 被包含在候选覆盖中。由 $x$ 表示的覆盖大小为 $|x| = \\sum_{i=0}^{n-1} x_i$。定义染色体 $x$ 的未覆盖边数为 $U(x) = |\\{(u,v)\\in E \\mid x_u = 0 \\wedge x_v = 0\\}|$。定义惩罚适应度为 $f(x) = |x| + M \\cdot U(x)$，其中 $M = n + 1$。\n\n按以下方式定义关键子图。三角形是任意一个 $3$ 顶点子集 $\\{i,j,k\\} \\subseteq V$，使得三条边 $(i,j)$, $(j,k)$ 和 $(i,k)$ 都在 $E$ 中。以 $c \\in V$ 为中心的星形图是在 $\\{c\\} \\cup N(c)$ 上的导出子图，其中 $N(c)$ 是 $c$ 的邻域，并满足约束条件 $\\deg(c) \\ge 3$。按以下规则顺序构建一个不相交的关键子图族 $\\mathcal{H}$：首先包含所有三角形；然后，按度数的非递增顺序，仅当以 $c$ 为中心的星形图的顶点集与已在 $\\mathcal{H}$ 中的所有子图的顶点集都不相交时，才包含该星形图；当所有度数至少为 $3$ 的中心点都已被考虑后，停止操作。因此，$\\mathcal{H}$中的每个 $H$ 要么是三角形，要么是星形图，并且 $\\mathcal{H}$ 中子图的顶点集是两两不相交的。\n\n交叉算子 $X$ 以图 $G$、不相交的关键子图族 $\\mathcal{H}$ 以及两个父代染色体 $p^{(1)}, p^{(2)} \\in \\{0,1\\}^n$ 作为输入，并生成一个满足以下所有性质的子代染色体 $c \\in \\{0,1\\}^n$：\n\n- 关键子图上的保留：对于每个 $H \\in \\mathcal{H}$（其顶点集为 $V(H)$），定义局部未覆盖数 $U_H(p) = |\\{(u,v)\\in E \\mid u \\in V(H), v \\in V(H), p_u = 0, p_v = 0\\}|$ 和局部大小 $|p|_H = \\sum_{i \\in V(H)} p_i$。定义局部成本 $g_H(p) = |p|_H + M \\cdot U_H(p)$。对于所有 $i \\in V(H)$，子代必须满足 $c_i = p^{(k)}_i$，其中 $k \\in \\{1,2\\}$ 的选择应使 $g_H(p^{(k)})$ 最小化；如果出现平局，则可以等概率地选择任一父代。\n- 关键子图之外：对于所有 $j \\in V \\setminus \\bigcup_{H \\in \\mathcal{H}} V(H)$，子代必须满足 $c_j \\in \\{p^{(1)}_j, p^{(2)}_j\\}$，且对于这些位置，$c_j = p^{(1)}_j$ 和 $c_j = p^{(2)}_j$ 出现的概率相等且相互独立。\n\n交叉之后，必须通过一个确定性的可行性修复步骤将 $c$ 转换为一个顶点覆盖，然后进行一个确定性的剪枝步骤，该步骤迭代地移除任何冗余的已选顶点（将 $x_i$ 设为 $0$），前提是移除操作能保持可行性，直到无法再进行此类移除为止。可行性修复和剪枝操作只能修改子代 $c$，并且必须在有限时间内终止。\n\n任务。实现一个完整的程序，该程序：\n\n- 对于下面列出的每个测试图，执行一个在 $\\{0,1\\}^n$ 上的基于群体的搜索，该搜索应用上述交叉算子 $X$ 作为唯一的重组机制，并使用惩罚适应度 $f(x)$ 来指導搜索。该搜索必须是随机的，但通过固定随机种子可以复现。它必须包括随机初始化和按位变异，每位变异概率等于 $1/n$，变异操作在修复和剪枝之前应用于子代。\n- 对于每个测试图，在固定的计算预算（对所有图都相同）结束后，返回在 $f(x)$ 下找到的最佳染色体，并附带说明它是否是一个有效的顶点覆盖。\n\n测试套件。使用以下图；顶点从 $0$ 标记到 $n-1$，每条边 $(u,v)$ 都是无向的：\n\n- 测试 1（非二分图，包含一个三角形）：$n = 3$, $E = \\{(0,1),(1,2),(0,2)\\}$。\n- 测试 2（星形图，高度数中心）：$n = 6$, $E = \\{(0,1),(0,2),(0,3),(0,4),(0,5)\\}$。\n- 测试 3（带对角线的环，包含一个三角形）：$n = 4$, $E = \\{(0,1),(1,2),(2,3),(3,0),(0,2)\\}$。\n- 测试 4（边界情况，空图）：$n = 5$, $E = \\emptyset$。\n\n计算预算和可复现性。对所有测试使用相同的固定随机种子。对于每个测试，使用相同的种群大小和相同的代数。必须以每位 $1/n$ 的概率应用变异。可行性修复和剪枝必须在评估 $f(x)$ 之前应用于所有个体。\n\n最终输出。你的程序必须生成一行输出，将所有测试结果聚合为一个用方括号括起来的逗号分隔列表。对于上面列出的每个测试，按顺序输出两个整数：找到的最佳覆盖大小 $|x^\\star|$ 和一个可行性指标，如果 $U(x^\\star) = 0$ 则定义为 $1$，否则为 $0$。因此，最终输出格式是一个长度为 $8$ 的单一列表：$[|x^\\star_1|,b_1,|x^\\star_2|,b_2,|x^\\star_3|,b_3,|x^\\star_4|,b_4]$，其中对于每个测试 $i$，$b_i \\in \\{0,1\\}$。", "solution": "所提出的问题是演化算法领域的一个计算练习，专门针对无向图上的最小顶点覆盖问题。问题陈述经过严格验证，被认为是有效的。它在科学上基于图论和遗传算法的既定原则，问题定义明确，其组成部分的描述具有足够的精确性（尽管有时很微妙）以支持形式化实现。虽然在选择机制或修复和剪枝的精确贪心规则等方面存在微小的歧义，但这些在算法描述中是典型的，可以通过采用标准的、确定性的实践来解决，这与创建*一个*完整程序的任务是一致的。因此，该问题是可解的。\n\n任务的核心是实现一个遗传算法（GA），该算法具有一个高度特化的交叉算子和一个重组后的修复与剪枝序列。我们现在将根据所提供的原则来描绘该算法的设计。\n\n染色体是一个二进制向量 $x \\in \\{0,1\\}^n$，其中 $n$ 是顶点数。如果 $x_i=1$，则顶点 $i$ 在候选顶点覆盖中；如果 $x_i=0$，则不在。染色体的质量由惩罚适应度函数 $f(x) = |x| + M \\cdot U(x)$ 评估，其中 $|x|$ 是覆盖的大小（$x_i=1$ 的顶点数），$U(x)$ 是未被顶点集覆盖的边数，而 $M=n+1$ 是一个惩罚系数。$M  n$ 的选择确保了任何不可行解（$U(x) \\ge 1$）的适应度值都比任何可行解（$U(x)=0$）的要差，因为一个可行覆盖的最大大小为 $n$。\n\n指定的遗传算法按以下方式运行：\n\n1.  **关键子图识别**：在演化过程开始之前，分析图 $G$ 以识别一个不相交的关键子图族 $\\mathcal{H}$。构建过程是顺序性的和确定性的：\n    *   首先，识别图中的所有三角形。采用一种贪心方法来形成这些三角形的不相交集合：它们按确定性顺序（例如，按其顶点索引的字典序排序）进行处理，一个三角形仅在其顶点集与已添加到 $\\mathcal{H}$ 的子图的顶点集不相交时才被添加到 $\\mathcal{H}$ 中。\n    *   接下来，按度数的非递增顺序考虑顶点作为潜在的星形图中心。一个以 $c$ 为中心且度数 $\\deg(c) \\ge 3$ 的星形图仅在其顶点集 $\\{c\\} \\cup N(c)$ 与当前 $\\mathcal{H}$ 中所有子图的顶点集不相交时才被添加到 $\\mathcal{H}$ 中。\n    此过程产生一个由两两顶点不相交的三角形和星形图组成的集合 $\\mathcal{H}$。不属于 $\\mathcal{H}$ 中任何子图的顶点在交叉过程中被分开处理。\n\n2.  **遗传算法循环**：GA以恒定的种群大小运行固定的代数。\n    *   **初始化**：创建一个随机染色体的初始种群。然后每个染色体都经过修复和剪枝算子的处理，以确保起始种群完全由有效的、极小的顶点覆盖组成。\n    *   **选择**：为了产生子代，从当前种群中选择父代。由于主种群由有效覆盖组成，其适应度 $f(x)$ 简化为其大小 $|x|$。标准的锦标赛选择是合适的：从种群中随机选择少量个体，大小最小（适应度最佳）的个体被选为父代。\n    *   **交叉**：特化的交叉算子 $X$ 从两个父代 $p^{(1)}$ 和 $p^{(2)}$ 生成单个子代 $c$。\n        *   对于每个关键子图 $H \\in \\mathcal{H}$，算子为两个父代评估局部成本 $g_H(p) = |p|_H + M \\cdot U_H(p)$。该成本评估父代在 $H$ 的顶点和导出边上的局部表现。对应于 $H$ 顶点的基因块从具有更优（更低）局部成本的父代复制到子代。平局随机打破。关键要注意的是，即使对于一个有效的全局覆盖 $p$，如果 $H$ 内的一条边被 $H$ 外的一个顶点所覆盖，其局部未覆盖数 $U_H(p)$也可能不为零。\n        *   对于所有不属于 $\\mathcal{H}$ 中任何子图的顶点，子代的基因由均匀交叉决定：$c_j$以相等的概率从 $\\{p^{(1)}_j, p^{(2)}_j\\}$ 中随机选择。\n    *   **变异**：新创建的子代染色体经历按位翻转变异，其中每个位 $c_i$ 以 $1/n$ 的概率被翻转。\n    *   **修复和剪枝**：将（可能不可行的）子代染色体确定性地转换为一个有效的、极小的顶点覆盖。\n        1.  **可行性修复**：使染色体成为一个有效的顶点覆盖。应用一个确定性规则：按固定顺序遍历图的所有边。如果发现一条边 $(u,v)$ 未被覆盖（$x_u=0, x_v=0$），则将其中一个顶点添加到覆盖中（例如，通过设置 $x_u=1$，其中 $uv$）。\n        2.  **剪枝**：通过迭代地从覆盖中移除顶点来使覆盖成为极小的。按一个固定的、确定性的顺序（例如，按顶点索引的升序）遍历所有选中的顶点。对于每个选中的顶点，暂时将其从覆盖中移除。如果移除后覆盖仍然有效，则永久移除该顶点；否则，将其加回。重复此过程，直到没有顶点可以被移除为止。\n    *   **替换**：经过修复和剪枝的新一代个体将取代旧一代，可能除了一个或多个精英个体（迄今为止找到的最佳解），这些精英个体被保留以确保算法性能不会下降。\n\n此算法在每个测试用例上运行，并报告在指定的世代数结束时找到的最佳可行覆盖的大小及其可行性状态。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# A complete and runnable Python 3.12 program.\n# This program implements the specified genetic algorithm for the minimum vertex cover problem.\n# It uses only the numpy library (version 1.23.5) as permitted.\n\n# Define GA parameters not specified in the problem statement.\n# These are kept constant across all test cases.\nPOPULATION_SIZE = 50\nGENERATIONS = 50\nTOURNAMENT_SIZE = 3\nRANDOM_SEED = 42\n\nclass VertexCoverGA:\n    \"\"\"\n    Implements the specialized genetic algorithm for the Minimum Vertex Cover problem\n    as described in the problem statement.\n    \"\"\"\n    def __init__(self, n, edges, pop_size, generations, seed):\n        self.n = n\n        # Ensure edges are consistently ordered, e.g., (min, max)\n        self.edges = sorted([tuple(sorted(e)) for e in edges])\n        self.pop_size = pop_size\n        self.generations = generations\n        self.rng = np.random.default_rng(seed)\n        self.M = n + 1\n        \n        self.adj = [set() for _ in range(n)]\n        for u, v in self.edges:\n            self.adj[u].add(v)\n            self.adj[v].add(u)\n        \n        self.H, self.non_h_vertices = self._find_critical_subgraphs()\n\n    def _find_critical_subgraphs(self):\n        \"\"\"\n        Constructs the disjoint family of critical sub-graphs H, following the\n        specified rules: triangles first, then stars.\n        \"\"\"\n        H = []\n        used_vertices = set()\n        \n        # 1. Greedily find all disjoint triangles\n        all_triangles = set()\n        if self.n >= 3:\n            for i in range(self.n):\n                # Sort neighbors to ensure deterministic processing and triangle representation\n                neighbors = sorted(list(self.adj[i]))\n                for j_idx in range(len(neighbors)):\n                    for k_idx in range(j_idx + 1, len(neighbors)):\n                        v, w = neighbors[j_idx], neighbors[k_idx]\n                        if v > i and w > i: # Avoid re-discovering triangles\n                            continue\n                        if w in self.adj[v]:\n                            triangle = tuple(sorted((i, v, w)))\n                            all_triangles.add(triangle)\n\n        # Sort triangles to have a deterministic order for greedy selection\n        sorted_triangles = sorted(list(all_triangles))\n        \n        for t_vertices in sorted_triangles:\n             t_set = set(t_vertices)\n             if not t_set.intersection(used_vertices):\n                 H.append({'type': 'triangle', 'vertices': t_set})\n                 used_vertices.update(t_set)\n\n        # 2. Greedily find disjoint stars\n        degrees = [(i, len(self.adj[i])) for i in range(self.n)]\n        degrees.sort(key=lambda x: (-x[1], x[0])) # Sort by degree desc, then index asc\n\n        for i, deg in degrees:\n            if deg  3:\n                break\n            star_vertices = {i} | self.adj[i]\n            if not star_vertices.intersection(used_vertices):\n                H.append({'type': 'star', 'vertices': star_vertices})\n                used_vertices.update(star_vertices)\n        \n        non_h_vertices = sorted([v for v in range(self.n) if v not in used_vertices])        \n        return H, non_h_vertices\n\n    def _local_cost(self, p, h_block_vertices):\n        size_h = sum(p[i] for i in h_block_vertices)\n        uncovered_h = 0\n        h_v_list = list(h_block_vertices)\n        for i in range(len(h_v_list)):\n            for j in range(i + 1, len(h_v_list)):\n                u, v = h_v_list[i], h_v_list[j]\n                if v in self.adj[u] and p[u] == 0 and p[v] == 0:\n                    uncovered_h += 1\n        return size_h + self.M * uncovered_h\n\n    def crossover(self, p1, p2):\n        child = np.zeros(self.n, dtype=np.int8)\n        \n        for h_block in self.H:\n            h_vertices = h_block['vertices']\n            cost1 = self._local_cost(p1, h_vertices)\n            cost2 = self._local_cost(p2, h_vertices)\n            \n            winner = p1 if cost1  cost2 else p2 if cost2  cost1 else (p1 if self.rng.random()  0.5 else p2)\n            \n            for v_idx in h_vertices:\n                child[v_idx] = winner[v_idx]\n\n        for j in self.non_h_vertices:\n            child[j] = p1[j] if self.rng.random()  0.5 else p2[j]\n\n        return child\n\n    def mutate(self, chromosome):\n        if self.n == 0:\n            return chromosome\n        mutation_prob = 1.0 / self.n\n        for i in range(self.n):\n            if self.rng.random()  mutation_prob:\n                chromosome[i] = 1 - chromosome[i]\n        return chromosome\n\n    def is_cover(self, chromosome):\n        return all(chromosome[u] == 1 or chromosome[v] == 1 for u, v in self.edges)\n\n    def repair(self, chromosome):\n        for u, v in self.edges:\n            if chromosome[u] == 0 and chromosome[v] == 0:\n                chromosome[u] = 1 # Deterministic rule: add vertex with smaller index\n        return chromosome\n\n    def prune(self, chromosome):\n        changed = True\n        node_order = list(range(self.n))\n        while changed:\n            changed = False\n            for i in node_order:\n                if chromosome[i] == 1:\n                    chromosome[i] = 0\n                    if not self.is_cover(chromosome):\n                        chromosome[i] = 1\n                    else:\n                        changed = True\n        return chromosome\n\n    def run(self):\n        population = self.rng.integers(0, 2, size=(self.pop_size, self.n), dtype=np.int8)\n        \n        for i in range(self.pop_size):\n            population[i] = self.repair(population[i])\n            population[i] = self.prune(population[i])\n\n        # Handle case of n=0 graph\n        if self.n == 0:\n            return 0, 1\n\n        best_chromosome = population[0].copy()\n        best_fitness = np.sum(best_chromosome)\n\n        for _ in range(self.generations):\n            fitnesses = np.sum(population, axis=1)\n\n            current_best_idx = np.argmin(fitnesses)\n            if fitnesses[current_best_idx]  best_fitness:\n                best_fitness = fitnesses[current_best_idx]\n                best_chromosome = population[current_best_idx].copy()\n            \n            new_population = np.zeros((self.pop_size, self.n), dtype=np.int8)\n            new_population[0] = best_chromosome.copy() # Elitism\n            \n            for i in range(1, self.pop_size):\n                tourn_indices1 = self.rng.choice(self.pop_size, TOURNAMENT_SIZE, replace=False)\n                p1_idx = tourn_indices1[np.argmin(fitnesses[tourn_indices1])]\n                \n                tourn_indices2 = self.rng.choice(self.pop_size, TOURNAMENT_SIZE, replace=False)\n                p2_idx = tourn_indices2[np.argmin(fitnesses[tourn_indices2])]\n\n                parent1 = population[p1_idx]\n                parent2 = population[p2_idx]\n                \n                child = self.crossover(parent1, parent2)\n                child = self.mutate(child)\n                child = self.repair(child)\n                child = self.prune(child)\n                \n                new_population[i] = child\n            \n            population = new_population\n\n        best_size = np.sum(best_chromosome)\n        is_feasible_flag = 1 if self.is_cover(best_chromosome) else 0\n        \n        return int(best_size), is_feasible_flag\n\ndef solve():\n    \"\"\"\n    Main function to run the GA on the test suite and print the results\n    in the specified format.\n    \"\"\"\n    test_cases = [\n        {'n': 3, 'edges': [(0, 1), (1, 2), (0, 2)]},\n        {'n': 6, 'edges': [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5)]},\n        {'n': 4, 'edges': [(0, 1), (1, 2), (2, 3), (3, 0), (0, 2)]},\n        {'n': 5, 'edges': []},\n    ]\n\n    results = []\n    for case in test_cases:\n        ga = VertexCoverGA(\n            n=case['n'],\n            edges=case['edges'],\n            pop_size=POPULATION_SIZE,\n            generations=GENERATIONS,\n            seed=RANDOM_SEED\n        )\n        best_size, is_feasible = ga.run()\n        results.extend([best_size, is_feasible])\n    \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2396605"}]}