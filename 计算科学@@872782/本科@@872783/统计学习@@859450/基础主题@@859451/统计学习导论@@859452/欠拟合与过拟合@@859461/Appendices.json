{"hands_on_practices": [{"introduction": "过拟合与欠拟合是机器学习中的核心概念，但如何从直观感觉过渡到量化诊断呢？本练习将指导你完成这一过程。通过一个经典的多项式回归任务，你将学习不仅使用均方误差（MSE），还利用残差的频域分析来精确识别模型何时容量不足（欠拟合），何时容量过剩并开始“记忆”噪声（过拟合）。这项实践将为你提供一套具体的、可复现的工具来诊断模型的拟合状态 [@problem_id:3135788]。", "problem": "给定一个以经验风险最小化（ERM）为模型的一维回归监督学习场景。设输入为 $x \\in [-1,1]$，真实目标函数为一个已知次数为 $d^\\star$ 的多项式，并受到均值为零、方差为 $\\sigma^2$ 的高斯噪声污染。具体来说，数据按 $y = f^\\star(x) + \\varepsilon$ 生成，其中 $f^\\star(x) = \\sum_{k=0}^{d^\\star} a_k x^k$，$d^\\star = 4$，系数为 $a_0 = 0.3$, $a_1 = -0.8$, $a_2 = 0.5$, $a_3 = 0.0$, $a_4 = 0.7$，噪声为 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$，且 $\\sigma = 0.1$（因此 $\\sigma^2 = 0.01$）。数据集大小为 $N = 200$ 个点，其输入 $x$ 从 $[-1,1]$ 区间内均匀抽取。使用 $N_{\\text{train}} = 120$ 个样本进行训练，使用 $N_{\\text{valid}} = 80$ 个样本进行验证。使用固定的随机种子 $42$ 来确保可复现性。\n\n您的任务是实现带岭回归（也称为 $\\ell_2$ 正则化）的多项式回归。对于选定的模型次数 $d$ 和正则化强度 $\\lambda \\ge 0$，构建设计矩阵 $\\Phi \\in \\mathbb{R}^{m \\times (d+1)}$，其条目为 $\\Phi_{i,k} = x_i^k$。给定训练数据 $(\\Phi_{\\text{train}}, y_{\\text{train}})$，使用以下闭式解计算岭估计器系数 $w \\in \\mathbb{R}^{d+1}$：\n$$\nw = \\left(\\Phi_{\\text{train}}^\\top \\Phi_{\\text{train}} + \\lambda I\\right)^{-1} \\Phi_{\\text{train}}^\\top y_{\\text{train}},\n$$\n其中 $I$ 是 $(d+1) \\times (d+1)$ 的单位矩阵。使用此估计器在训练集和验证集上获得预测，并计算残差 $r_{\\text{train}} = y_{\\text{train}} - \\hat{y}_{\\text{train}}$ 和 $r_{\\text{valid}} = y_{\\text{valid}} - \\hat{y}_{\\text{valid}}$。\n\n从基本原理出发，使用以下定义和度量来识别欠拟合和过拟合：\n\n- 均方误差（MSE）定义为 $ \\text{MSE} = \\frac{1}{m} \\sum_{i=1}^m (y_i - \\hat{y}_i)^2 $。令 $\\text{MSE}_{\\text{train}}$ 和 $\\text{MSE}_{\\text{valid}}$ 分别表示训练和验证的均方误差。\n- 残差中的振荡在频域中进行量化。计算按相应输入 $x$ 升序排序的验证残差序列的离散傅里叶变换（Discrete Fourier Transform, DFT）。使用实值 DFT $R = \\text{rfft}(r_{\\text{valid-sorted}})$ 并定义高频能量比如下：\n$$\n\\rho_{\\text{HF}} = \\frac{\\sum_{k \\in \\mathcal{H}} |R_k|^2}{\\sum_{k \\in \\mathcal{P}} |R_k|^2},\n$$\n其中 $\\mathcal{P}$ 索引除零频箱外的所有正频率箱，而 $\\mathcal{H}$ 索引正频率箱的最高四分位数（即 $\\mathcal{P}$ 中频率最高的 $25\\%$）。如果分母为零，则定义 $\\rho_{\\text{HF}} = 0$。\n\n使用以下带有固定阈值的分类规则来判断一个模型是欠拟合、良好拟合还是过拟合。记已知噪声方差为 $\\sigma^2 = 0.01$，阈值分别为 $t_u = 1.3$, $t_o = 0.9$, $t_o' = 1.2$, $h_u = 0.35$, $h_o = 0.45$。\n\n- 欠拟合（代码 $0$）：如果 $d  d^\\star$，或者 $\\text{MSE}_{\\text{train}} \\ge t_u \\sigma^2$ 且 $\\text{MSE}_{\\text{valid}} \\ge t_u \\sigma^2$ 且 $\\rho_{\\text{HF}} \\le h_u$，则判定为欠拟合。\n- 过拟合（代码 $2$）：如果 $d > d^\\star$ 且 $\\text{MSE}_{\\text{train}} \\le t_o \\sigma^2$ 且 $\\text{MSE}_{\\text{valid}} \\ge t_o' \\sigma^2$ 且 $\\rho_{\\text{HF}} \\ge h_o$，则判定为过拟合。\n- 良好拟合（代码 $1$）：如果以上两个条件都不满足，则判定为良好拟合。\n\n请实现上述过程，并评估以下改变 $d$ 和 $\\lambda$ 的测试套件：\n\n- 情况 1：$d = 2$, $\\lambda = 0.001$。\n- 情况 2：$d = 4$, $\\lambda = 0.05$。\n- 情况 3：$d = 12$, $\\lambda = 0.0$。\n- 情况 4：$d = 12$, $\\lambda = 10.0$。\n- 情况 5：$d = 4$, $\\lambda = 0.0$。\n\n您的程序必须按规定生成数据集，为每种情况拟合模型，计算指标，并按给定顺序输出这些情况的分类代码。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[0,1,2,0,1]$）。此问题不需要物理单位、角度单位或百分比。最终输出值为如上指定的整数。程序必须是完整且可直接运行的，无需外部输入或文件。请按规定使用确定性种子，以便任何运行该程序的人都能复现结果。", "solution": "该问题陈述经过了细致的验证，并被确定为有效。它在科学上是合理的、自洽的，并且定义明确，在计算统计和机器学习领域提供了一个清晰且可形式化的任务。\n\n该任务是基于一组精确的量化标准，将多项式回归模型分类为欠拟合、良好拟合或过拟合。解决方案涉及数据生成、模型拟合、指标计算以及对几个测试用例的分类。由于指定了随机种子，整个过程是确定性的。\n\n### 步骤 1：数据生成与准备\n\n此回归问题的基础是一个合成数据集。输入 $x$ 和输出 $y$ 之间的真实关系由一个已知的 $d^\\star=4$ 次多项式函数 $f^\\star(x)$ 定义：\n$$\nf^\\star(x) = a_0 + a_1 x + a_2 x^2 + a_3 x^3 + a_4 x^4\n$$\n其系数为 $a_0 = 0.3$, $a_1 = -0.8$, $a_2 = 0.5$, $a_3 = 0.0$, $a_4 = 0.7$。\n\n观测数据受到加性高斯白噪声 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$ 的干扰，其中噪声方差为 $\\sigma^2 = 0.01$。因此，每个数据点 $(x_i, y_i)$ 根据以下模型生成：\n$$\ny_i = f^\\star(x_i) + \\varepsilon_i\n$$\n共创建 $N=200$ 个数据点。输入值 $x_i$ 从区间 $[-1, 1]$ 上的均匀分布中抽取。为确保可复现性，随机数生成器使用固定的种子 $42$ 进行初始化。\n\n生成的 $N=200$ 个点的数据集随后被确定性地打乱并分割成一个大小为 $N_{\\text{train}} = 120$ 的训练集和一个大小为 $N_{\\text{valid}} = 80$ 的验证集。这种划分使我们能够训练模型并独立评估其泛化性能。\n\n### 步骤 2：带岭回归的多项式回归\n\n对于每个测试用例，我们将一个指定次数 $d$ 的多项式模型拟合到训练数据上。模型假设的形式为：\n$$\n\\hat{y}(x) = \\sum_{k=0}^d w_k x^k = \\mathbf{w}^\\top \\phi(x)\n$$\n其中 $\\mathbf{w} \\in \\mathbb{R}^{d+1}$ 是待学习的模型系数向量，$\\phi(x) = [1, x, x^2, \\dots, x^d]^\\top$ 是特征向量。\n\n对于一组 $m$ 个训练样本，我们构建设计矩阵 $\\Phi_{\\text{train}} \\in \\mathbb{R}^{m \\times (d+1)}$，其中每个条目为 $(\\Phi_{\\text{train}})_{i,k} = x_i^k$，对于 $i \\in \\{1, \\dots, m\\}$ 和 $k \\in \\{0, \\dots, d\\}$。\n\n系数 $\\mathbf{w}$ 使用岭回归进行估计，该方法最小化正则化的平方误差和：\n$$\n\\mathcal{L}(\\mathbf{w}) = \\|\\mathbf{y}_{\\text{train}} - \\Phi_{\\text{train}}\\mathbf{w}\\|_2^2 + \\lambda \\|\\mathbf{w}\\|_2^2\n$$\n这里，$\\lambda \\ge 0$ 是正则化参数，用于控制对系数大小的惩罚。最优权重向量 $\\mathbf{w}$ 的闭式解由正规方程给出：\n$$\n\\mathbf{w} = \\left(\\Phi_{\\text{train}}^\\top \\Phi_{\\text{train}} + \\lambda I\\right)^{-1} \\Phi_{\\text{train}}^\\top \\mathbf{y}_{\\text{train}}\n$$\n其中 $I$ 是 $(d+1) \\times (d+1)$ 的单位矩阵。为了数值稳定性，这个线性系统使用 `numpy.linalg.solve` 求解，而不是显式地计算矩阵的逆。\n\n### 步骤 3：模型评估指标\n\n一旦模型训练完成（即 $\\mathbf{w}$ 已计算），其性能将使用两个关键指标进行评估。\n\n**均方误差 (MSE):** MSE 衡量预测值 $\\hat{y}_i$ 与实际值 $y_i$ 之间平方差的平均值。它分别对训练集和验证集进行计算：\n$$\n\\text{MSE}_{\\text{train}} = \\frac{1}{N_{\\text{train}}} \\sum_{i=1}^{N_{\\text{train}}} (y_{\\text{train},i} - \\hat{y}_{\\text{train},i})^2\n$$\n$$\n\\text{MSE}_{\\text{valid}} = \\frac{1}{N_{\\text{valid}}} \\sum_{i=1}^{N_{\\text{valid}}} (y_{\\text{valid},i} - \\hat{y}_{\\text{valid},i})^2\n$$\n\n**高频能量比 ($\\rho_{\\text{HF}}$):** 该指标量化了模型在验证集上误差的振荡特性，这是过拟合的一个常见症状。步骤如下：\n1.  计算验证残差：$\\mathbf{r}_{\\text{valid}} = \\mathbf{y}_{\\text{valid}} - \\hat{\\mathbf{y}}_{\\text{valid}}$。\n2.  根据其相应输入值 $x_{\\text{valid}}$ 的升序对这些残差进行排序。令此排序后的序列为 $\\mathbf{r}_{\\text{valid-sorted}}$。\n3.  计算排序后残差的实值离散傅里叶变换 (DFT)：$R = \\text{rfft}(\\mathbf{r}_{\\text{valid-sorted}})$。对于 $N_{\\text{valid}} = 80$，输出 $R$ 是一个长度为 $41$ 的复数数组。\n4.  正频率箱集合 $\\mathcal{P}$ 由除零频（直流）分量外的所有频率箱组成。对于 RFFT 输出 $R$，这些对应于索引 $k \\in \\{1, 2, \\dots, 40\\}$。\n5.  高频箱集合 $\\mathcal{H}$ 定义为 $\\mathcal{P}$ 中频率的最高四分位数（最高的 $25\\%$）。这对应于最后 $40 \\times 0.25 = 10$ 个箱，其索引为 $k \\in \\{31, 32, \\dots, 40\\}$。\n6.  高频能量比即为 $\\mathcal{H}$ 中的能量与 $\\mathcal{P}$ 中总能量之比：\n    $$\n    \\rho_{\\text{HF}} = \\frac{\\sum_{k \\in \\mathcal{H}} |R_k|^2}{\\sum_{k \\in \\mathcal{P}} |R_k|^2}\n    $$\n    如果分母为零，则定义 $\\rho_{\\text{HF}}$ 为 $0$。\n\n### 步骤 4：分类逻辑\n\n计算出的指标用于根据一组固定的规则将每个模型分类为欠拟合、良好拟合或过拟合。真实噪声方差为 $\\sigma^2 = 0.01$，阈值为 $t_u = 1.3$, $t_o = 0.9$, $t_o' = 1.2$, $h_u = 0.35$, $h_o = 0.45$。\n\n- **欠拟合 (代码 $0$):** 如果模型的次数 $d$ 小于真实次数 $d^\\star$，*或者* 它在训练集和验证集上都表现出高误差，并且残差振荡较低，则判定为欠拟合。形式上：\n  $$\n  (d  d^\\star) \\lor (\\text{MSE}_{\\text{train}} \\ge t_u \\sigma^2 \\land \\text{MSE}_{\\text{valid}} \\ge t_u \\sigma^2 \\land \\rho_{\\text{HF}} \\le h_u)\n  $$\n\n- **过拟合 (代码 $2$):** 如果模型的次数 $d$ 大于 $d^\\star$，*并且* 它表现出较低的训练误差、显著较高的验证误差以及残差中的高频振荡，则判定为过拟合。形式上：\n  $$\n  (d > d^\\star) \\land (\\text{MSE}_{\\text{train}} \\le t_o \\sigma^2 \\land \\text{MSE}_{\\text{valid}} \\ge t_o' \\sigma^2 \\land \\rho_{\\text{HF}} \\ge h_o)\n  $$\n\n- **良好拟合 (代码 $1$):** 如果一个模型既不满足欠拟合也不满足过拟合的标准，则被分类为良好拟合。\n\n这些规则为偏差-方差权衡概念提供了一个具体的、算法化的定义。该程序为每个指定的测试用例实现此逻辑，生成最终的分类代码列表。", "answer": "```python\nimport numpy as np\nimport scipy.fft\n\ndef solve():\n    \"\"\"\n    Main function to execute the polynomial regression analysis and classification.\n    \"\"\"\n    #\n    # Step 0: Define constants and problem parameters\n    #\n    RANDOM_SEED = 42\n    D_STAR = 4\n    A_COEFFS = np.array([0.3, -0.8, 0.5, 0.0, 0.7])\n    SIGMA = 0.1\n    SIGMA_SQUARED = SIGMA**2\n    N_TOTAL = 200\n    N_TRAIN = 120\n    N_VALID = 80\n\n    # Classification thresholds\n    T_U = 1.3\n    T_O = 0.9\n    T_O_PRIME = 1.2\n    H_U = 0.35\n    H_O = 0.45\n\n    # Test cases to evaluate\n    test_cases = [\n        {'d': 2, 'lambda': 0.001},  # Case 1\n        {'d': 4, 'lambda': 0.05},   # Case 2\n        {'d': 12, 'lambda': 0.0},    # Case 3\n        {'d': 12, 'lambda': 10.0},   # Case 4\n        {'d': 4, 'lambda': 0.0},    # Case 5\n    ]\n    \n    #\n    # Step 1: Generate dataset\n    #\n    rng = np.random.default_rng(RANDOM_SEED)\n\n    # Generate x values\n    x = rng.uniform(-1, 1, size=N_TOTAL)\n\n    # Generate true function values y_star\n    def f_star(x_in):\n        return A_COEFFS[0] + A_COEFFS[1] * x_in + A_COEFFS[2] * x_in**2 + \\\n               A_COEFFS[3] * x_in**3 + A_COEFFS[4] * x_in**4\n\n    y_star = f_star(x)\n\n    # Add Gaussian noise\n    noise = rng.normal(0, SIGMA, size=N_TOTAL)\n    y = y_star + noise\n\n    # Split into training and validation sets\n    indices = np.arange(N_TOTAL)\n    rng.shuffle(indices)\n    \n    train_indices = indices[:N_TRAIN]\n    valid_indices = indices[N_TRAIN:]\n\n    x_train, y_train = x[train_indices], y[train_indices]\n    x_valid, y_valid = x[valid_indices], y[valid_indices]\n\n    #\n    # Helper functions\n    #\n    def construct_design_matrix(x_data, degree):\n        \"\"\"Constructs the polynomial design matrix Phi.\"\"\"\n        return np.vander(x_data, degree + 1, increasing=True)\n\n    results = []\n\n    #\n    # Step 2-4: Process each test case\n    #\n    for case in test_cases:\n        d = case['d']\n        lambda_reg = case['lambda']\n\n        # Construct design matrices\n        phi_train = construct_design_matrix(x_train, d)\n        phi_valid = construct_design_matrix(x_valid, d)\n\n        # Fit the model using ridge regression (numerically stable)\n        d_plus_1 = d + 1\n        A = phi_train.T @ phi_train + lambda_reg * np.eye(d_plus_1)\n        b = phi_train.T @ y_train\n        w = np.linalg.solve(A, b)\n\n        # Make predictions\n        y_hat_train = phi_train @ w\n        y_hat_valid = phi_valid @ w\n\n        # Calculate metrics\n        # a) MSE\n        mse_train = np.mean((y_train - y_hat_train)**2)\n        mse_valid = np.mean((y_valid - y_hat_valid)**2)\n        \n        # b) High-frequency energy ratio rho_HF\n        residuals_valid = y_valid - y_hat_valid\n        \n        # Sort residuals according to x_valid\n        sort_indices = np.argsort(x_valid)\n        residuals_valid_sorted = residuals_valid[sort_indices]\n        \n        # Compute RFFT\n        R = scipy.fft.rfft(residuals_valid_sorted)\n        \n        # Calculate energies\n        # P: positive frequencies (indices 1 to end)\n        # H: top quartile of P (last 10 for N_valid=80)\n        # N_valid = 80 -> rfft length = 41. P_indices = 1..40. H_indices = 31..40.\n        num_positive_freqs = len(R) - 1\n        top_quartile_size = int(np.ceil(0.25 * num_positive_freqs))\n        \n        energy_P = np.sum(np.abs(R[1:])**2)\n        energy_H = np.sum(np.abs(R[-top_quartile_size:])**2)\n        \n        rho_hf = energy_H / energy_P if energy_P > 0 else 0.0\n        \n        # Apply classification rules\n        code = 1 # Default to well-fit\n\n        # Underfitting rule\n        is_underfit_by_degree = (d  D_STAR)\n        is_underfit_by_metrics = (mse_train >= T_U * SIGMA_SQUARED and \\\n                                  mse_valid >= T_U * SIGMA_SQUARED and \\\n                                  rho_hf = H_U)\n        if is_underfit_by_degree or is_underfit_by_metrics:\n            code = 0\n\n        # Overfitting rule\n        is_overfit_by_metrics = (d > D_STAR and \\\n                                 mse_train = T_O * SIGMA_SQUARED and \\\n                                 mse_valid >= T_O_PRIME * SIGMA_SQUARED and \\\n                                 rho_hf >= H_O)\n        if is_overfit_by_metrics:\n            code = 2\n            \n        results.append(code)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3135788"}, {"introduction": "当我们诊断出模型存在过拟合问题时，下一步自然是寻找控制它的方法。本练习介绍了一种强大的技术——正则化，它在这里通过“分布鲁棒性”的概念来体现。你将亲手调节一个“鲁棒性”参数 $\\lambda$，它本质上控制着模型的复杂度，并通过观察训练误差和测试误差的变化，找到最小化泛化误差的最佳平衡点。这个过程让你直观地体验到在偏差和方差之间进行权衡的艺术 [@problem_id:3189697]。", "problem": "您将研究在一个简单的分布鲁棒优化设置中，鲁棒性参数如何权衡线性回归中的过拟合与欠拟合。您的程序必须生成合成数据，训练一系列由鲁棒性参数索引的估计器，并计算诊断量，以验证适度的鲁棒性可以减少过拟合，而过度的鲁棒性则会导致欠拟合。\n\n基本原理。考虑使用平方损失的线性回归。设 $x \\in \\mathbb{R}^d$，$y \\in \\mathbb{R}$，以及一个线性预测器 $f_w(x) = w^\\top x$，其参数为 $w \\in \\mathbb{R}^d$。在训练数据 $\\{(x_i,y_i)\\}_{i=1}^n$ 上的经验风险最小化目标是平均平方损失 $n^{-1} \\sum_{i=1}^n (y_i - w^\\top x_i)^2$。分布鲁棒优化公式用围绕经验分布的模糊集上的最坏情况期望来代替名义期望。对于由特征的 $\\ell_2$-有界扰动导出的一大类模糊集，其鲁棒对应问题已知等价于经验风险加上对 $w$ 的 $\\ell_2$ 惩罚，惩罚权重随鲁棒性半径的增加而增加。这产生了一系列估计器，它们在经验风险最小化（低鲁棒性）和强正则化解（高鲁棒性）之间进行插值。\n\n数据生成。对于下方的每个测试用例，按如下方式从同一分布生成一个训练集和一个独立的测试集。对于给定的维度 $d$ 和样本大小 $n$，设 $G \\in \\mathbb{R}^{d \\times d}$ 具有独立的标准正态分布条目。从 $G$ 的 $QR$ 分解中计算薄正交因子 $Q \\in \\mathbb{R}^{d \\times d}$。令特征值为 $e_k = 1 - 0.95 (k-1)/(d-1)$（对于 $k \\in \\{1,\\dots,d\\}$），并定义协方差矩阵 $\\Sigma = Q \\,\\mathrm{diag}(e_1,\\dots,e_d)\\, Q^\\top$。从均值为零、协方差为 $\\Sigma$ 的多元正态分布中独立抽取 $X \\in \\mathbb{R}^{n \\times d}$ 的各行，并以同样的方式抽取 $X_{\\mathrm{test}} \\in \\mathbb{R}^{n_{\\mathrm{test}} \\times d}$ 的各行，其中 $n_{\\mathrm{test}} = 2000$。定义真实参数 $w^\\star \\in \\mathbb{R}^d$ 为 $w^\\star_j = 1/j$（对于 $j \\in \\{1,\\dots,10\\}$）和 $w^\\star_j = 0$（对于 $j \\in \\{11,\\dots,d\\}$）。生成 $y = X w^\\star + \\sigma \\,\\varepsilon$ 和 $y_{\\mathrm{test}} = X_{\\mathrm{test}} w^\\star + \\sigma \\,\\varepsilon_{\\mathrm{test}}$，其中 $\\varepsilon \\in \\mathbb{R}^n$ 和 $\\varepsilon_{\\mathrm{test}} \\in \\mathbb{R}^{n_{\\mathrm{test}}}$ 的条目是独立的标准正态随机变量。在生成 $G$、$X$、$X_{\\mathrm{test}}$、$\\varepsilon$ 和 $\\varepsilon_{\\mathrm{test}}$ 之前，为每个测试用例使用指定的随机种子来初始化伪随机数生成器。\n\n鲁棒估计器。对于每个非负鲁棒性参数 $\\lambda$，训练一个估计器，该估计器最小化经验平方损失加上 $\\lambda$ 乘以 $w$ 的平方 $\\ell_2$ 范数，即最小化 $n^{-1} \\sum_{i=1}^n (y_i - w^\\top x_i)^2 + \\lambda \\|w\\|_2^2$。精确计算最小化器 $w_\\lambda$，然后计算：\n- 训练均方误差 $\\mathrm{MSE}_{\\mathrm{train}}(\\lambda) = n^{-1} \\sum_{i=1}^n (y_i - x_i^\\top w_\\lambda)^2$。\n- 测试均方误差 $\\mathrm{MSE}_{\\mathrm{test}}(\\lambda) = n_{\\mathrm{test}}^{-1} \\sum_{i=1}^{n_{\\mathrm{test}}} (y_{\\mathrm{test},i} - x_{\\mathrm{test},i}^\\top w_\\lambda)^2$。\n- 泛化差距 $g(\\lambda) = \\mathrm{MSE}_{\\mathrm{test}}(\\lambda) - \\mathrm{MSE}_{\\mathrm{train}}(\\lambda)$。\n\n您的程序必须处理以下三个测试用例。每个测试用例是一个元组 $(n,d,\\sigma,\\text{seed},\\Lambda)$，其中 $\\Lambda$ 是要评估的鲁棒性参数列表：\n- 测试用例 1：$(n=80, d=60, \\sigma=1.5, \\text{seed}=7, \\Lambda = [0, 0.1, 1, 10, 100])$。\n- 测试用例 2：$(n=100, d=30, \\sigma=2.0, \\text{seed}=11, \\Lambda = [0, 0.01, 0.1, 1, 5])$。\n- 测试用例 3：$(n=60, d=50, \\sigma=0.5, \\text{seed}=19, \\Lambda = [0, 0.01, 0.1, 1, 20])$。\n\n对于每个测试用例，计算并报告三个整数：\n1. 获得最小测试均方误差 $\\mathrm{MSE}_{\\mathrm{test}}(\\lambda)$ 的 $\\lambda \\in \\Lambda$ 的索引 $i^\\star$（从零开始）。如果出现平局，选择最小的索引。\n2. 指示符 $b_1 \\in \\{0,1\\}$，如果序列 $\\mathrm{MSE}_{\\mathrm{train}}(\\lambda)$（遍历 $\\Lambda$）在数值公差范围内随 $\\lambda$ 严格递增（将其解释为非递减且至少有一次严格增加，使用 $10^{-10}$ 的公差），则该指示符等于 $1$，否则等于 $0$。\n3. 指示符 $b_2 \\in \\{0,1\\}$，如果在数值公差范围内，泛化差距从 $\\lambda=0$ 到 $\\lambda = \\Lambda[i^\\star]$ 严格减小（即 $g(0) > g(\\Lambda[i^\\star]) + 10^{-10}$），则该指示符等于 $1$，否则等于 $0$。\n\n最终输出格式。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的整数列表，该列表由按顺序连接的测试用例的三元组构成。例如，输出必须类似于 $[i^\\star_1,b_{1,1},b_{2,1},i^\\star_2,b_{1,2},b_{2,2},i^\\star_3,b_{1,3},b_{2,3}]$。\n\n不涉及物理单位或角度单位；所有量均为无量纲实数。通过在每个测试用例中使用指定的种子来初始化伪随机数生成器，确保所有计算都是确定性的。", "solution": "该问题要求在一个线性回归设置中，使用一种源于分布鲁棒优化的机制来分析欠拟合和过拟合之间的权衡。该框架引入了一个鲁棒性参数 $\\lambda$，如问题所述，它等价于岭回归（Ridge Regression）中的正则化参数。我们将首先建立估计器的解析解，然后详细说明数据生成和评估过程。\n\n### 基于原理的设计\n\n#### 1. 作为岭回归的鲁棒估计器\n\n问题定义了一个估计器 $w_\\lambda$，它最小化给定鲁棒性参数 $\\lambda \\ge 0$ 的目标函数：\n$$ J(w) = \\frac{1}{n} \\sum_{i=1}^n (y_i - w^\\top x_i)^2 + \\lambda \\|w\\|_2^2 $$\n该目标由两项组成：经验风险（训练数据上的平均平方误差）和正则化项（对参数向量 $w$ 的 $\\ell_2$ 惩罚）。这就是著名的岭回归目标函数。\n\n为了找到最小化 $J(w)$ 的最优参数向量 $w_\\lambda$，我们计算 $J(w)$ 关于 $w$ 的梯度并将其设为零。在矩阵表示法中，设 $X \\in \\mathbb{R}^{n \\times d}$ 是特征向量 $x_i^\\top$ 构成的矩阵， $y \\in \\mathbb{R}^n$ 是目标值 $y_i$ 构成的向量。该目标可以写作：\n$$ J(w) = \\frac{1}{n} \\|y - Xw\\|_2^2 + \\lambda w^\\top w $$\n梯度 $\\nabla_w J(w)$ 是：\n$$ \\nabla_w J(w) = \\nabla_w \\left( \\frac{1}{n}(y - Xw)^\\top(y - Xw) + \\lambda w^\\top w \\right) $$\n$$ \\nabla_w J(w) = \\frac{1}{n} \\nabla_w (y^\\top y - 2y^\\top Xw + w^\\top X^\\top Xw) + 2\\lambda w $$\n$$ \\nabla_w J(w) = \\frac{1}{n} (-2X^\\top y + 2X^\\top Xw) + 2\\lambda w $$\n将梯度设为零以找到最小值：\n$$ \\frac{1}{n} (2X^\\top Xw - 2X^\\top y) + 2\\lambda w = 0 $$\n$$ X^\\top Xw - X^\\top y + n\\lambda w = 0 $$\n$$ (X^\\top X + n\\lambda I)w = X^\\top y $$\n其中 $I$ 是 $d \\times d$ 的单位矩阵。\n\n这就得出了岭回归的正规方程组。通过求解这个线性系统可以找到解 $w_\\lambda$：\n$$ w_\\lambda = (X^\\top X + n\\lambda I)^{-1} X^\\top y $$\n对于任何 $\\lambda  0$，矩阵 $(X^\\top X + n\\lambda I)$ 都是正定的，因此是可逆的，保证了唯一解的存在。当 $\\lambda=0$ 时，这简化为普通最小二乘法（OLS）。我们将使用一个数值稳定的线性系统求解器来为给定列表 $\\Lambda$ 中的每个值找到 $w_\\lambda$。\n\n#### 2. 数据生成过程\n\n问题指定了生成合成数据的详细过程，通过随机种子确保可复现性。\n1.  从一个具有标准正态分布条目的矩阵 $G$ 的QR分解中生成一个随机正交矩阵 $Q \\in \\mathbb{R}^{d \\times d}$。$Q$ 的列将作为数据协方差矩阵的特征向量。\n2.  定义一组特征值 $e_k = 1 - 0.95 \\frac{k-1}{d-1}$（对于 $k=1, \\dots, d$）。这些特征值从 $e_1=1$ 线性衰减到 $e_d=0.05$，从而创建一个结构化的协方差。\n3.  协方差矩阵构造为 $\\Sigma = Q \\mathrm{diag}(e_1, \\dots, e_d) Q^\\top$。\n4.  训练特征向量（$X \\in \\mathbb{R}^{n \\times d}$）和测试特征向量（$X_{\\mathrm{test}} \\in \\mathbb{R}^{n_{\\mathrm{test}} \\times d}$）从多元正态分布 $\\mathcal{N}(0, \\Sigma)$ 中抽取。\n5.  定义一个真实参数向量 $w^\\star \\in \\mathbb{R}^d$，其具有稀疏的非零元素，模拟只有少数特征相关的场景。具体来说， $w^\\star_j = 1/j$（对于 $j \\in \\{1,\\dots,10\\}$）且 $w^\\star_j = 0$（对于 $j  10$）。\n6.  目标值通过线性模型 $y = Xw^\\star + \\sigma \\varepsilon$ 和 $y_{\\mathrm{test}} = X_{\\mathrm{test}}w^\\star + \\sigma \\varepsilon_{\\mathrm{test}}$ 生成，其中 $\\varepsilon$ 和 $\\varepsilon_{\\mathrm{test}}$ 是独立同分布的标准正态噪声向量。\n\n#### 3. 评估与解释\n\n对于每个 $\\lambda \\in \\Lambda$，我们计算 $w_\\lambda$ 并使用三个关键指标评估其性能：\n-   **训练均方误差 ($\\mathrm{MSE}_{\\mathrm{train}}(\\lambda)$)**：衡量模型对其训练数据的拟合程度。过拟合的模型将具有非常低的训练MSE。\n-   **测试均方误差 ($\\mathrm{MSE}_{\\mathrm{test}}(\\lambda)$)**：衡量模型对来自同一分布的未见新数据的泛化能力。这是模型性能的主要指标。\n-   **泛化差距 ($g(\\lambda)$)**：差值 $\\mathrm{MSE}_{\\mathrm{test}}(\\lambda) - \\mathrm{MSE}_{\\mathrm{train}}(\\lambda)$。大的差距是过拟合的标志。\n\n每个测试用例所需的输出旨在诊断过拟合和欠拟合：\n1.  **$i^\\star$**：这是最小化测试误差的 $\\lambda$ 的索引。这个 $\\lambda_ {\\mathrm{opt}} = \\Lambda[i^\\star]$ 代表了最优的正则化量。如果 $\\lambda_{\\mathrm{opt}}  0$，则表明未正则化的OLS模型（$\\lambda=0$）是次优的，很可能是由于过拟合。\n2.  **$b_1$**：该指示符验证 $\\mathrm{MSE}_{\\mathrm{train}}(\\lambda)$ 是 $\\lambda$ 的非递减函数。这是一个预期的理论属性：随着正则化强度 $\\lambda$ 的增加，对 $w$ 的约束变得更紧，这不会降低训练集上的最小化损失。\n3.  **$b_2$**：该指示符检查与 $\\lambda=0$ 相比，在最优 $\\lambda_{\\mathrm{opt}}$ 处的泛化差距是否更小。差距的显著减小（$g(0)  g(\\lambda_{\\mathrm{opt}})$）表明正则化已成功缓解了过拟合。\n\n参数 $\\lambda$ 控制着偏差-方差权衡。低 $\\lambda$（低鲁棒性）导致低偏差、高方差的估计器，可能会过拟合训练数据。高 $\\lambda$（高鲁棒性）导致高偏差、低方差的估计器，可能会欠拟合数据。最优的 $\\lambda$ 在两者之间取得平衡，从而最小化测试误差。\n\n解决方案的实现方式是：对每个测试用例遵循这些步骤，计算所需的量，并格式化最终输出。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Investigates the effect of a robustness parameter on overfitting and underfitting\n    in linear regression by solving a series of test cases.\n\n    The problem is framed as a distributionally robust optimization problem which is\n    equivalent to Ridge Regression. For each test case, the function performs:\n    1. Synthetic data generation based on specified parameters (n, d, sigma, seed).\n    2. Training a series of Ridge regression models for a list of robustness\n       parameters (lambda).\n    3. Computing training MSE, test MSE, and the generalization gap for each model.\n    4. Determining diagnostic quantities (i_star, b1, b2) that characterize the\n       model's behavior in terms of the bias-variance trade-off.\n    \"\"\"\n    test_cases = [\n        (80, 60, 1.5, 7, [0, 0.1, 1, 10, 100]),\n        (100, 30, 2.0, 11, [0, 0.01, 0.1, 1, 5]),\n        (60, 50, 0.5, 19, [0, 0.01, 0.1, 1, 20]),\n    ]\n\n    final_results = []\n    n_test = 2000\n    tol = 1e-10\n\n    for n, d, sigma, seed, Lambda in test_cases:\n        np.random.seed(seed)\n\n        # 1. Data Generation\n        # Generate covariance matrix Sigma\n        G = np.random.randn(d, d)\n        Q, _ = np.linalg.qr(G)\n        \n        # Eigenvalues e_k\n        if d == 1:\n            eigenvalues = np.array([1.0])\n        else:\n            k = np.arange(1, d + 1)\n            # The formula is e_k = 1 - 0.95 * (k-1)/(d-1)\n            eigenvalues = 1 - 0.95 * (k - 1) / (d - 1)\n        \n        Sigma = Q @ np.diag(eigenvalues) @ Q.T\n        \n        # Ground-truth parameter w_star\n        w_star = np.zeros(d)\n        num_nonzero = min(10, d)\n        w_star[:num_nonzero] = 1.0 / np.arange(1, num_nonzero + 1)\n        \n        # Generate feature matrices X and X_test\n        mean_vec = np.zeros(d)\n        X = np.random.multivariate_normal(mean_vec, Sigma, n)\n        X_test = np.random.multivariate_normal(mean_vec, Sigma, n_test)\n        \n        # Generate noise and target variables y and y_test\n        epsilon = np.random.randn(n)\n        epsilon_test = np.random.randn(n_test)\n        y = X @ w_star + sigma * epsilon\n        y_test = X_test @ w_star + sigma * epsilon_test\n\n        # 2. Model Training and Evaluation\n        train_mses = []\n        test_mses = []\n        gaps = []\n        \n        # Pre-compute parts of the normal equation for efficiency\n        XTX = X.T @ X\n        XTy = X.T @ y\n        \n        for lam in Lambda:\n            # Solve (X'X + n*lambda*I)w = X'y for w\n            A = XTX + n * lam * np.identity(d)\n            w_lambda = np.linalg.solve(A, XTy)\n            \n            # Compute training MSE\n            mse_train = np.mean((y - X @ w_lambda)**2)\n            train_mses.append(mse_train)\n            \n            # Compute test MSE\n            mse_test = np.mean((y_test - X_test @ w_lambda)**2)\n            test_mses.append(mse_test)\n            \n            # Compute generalization gap\n            gaps.append(mse_test - mse_train)\n            \n        # 3. Compute Required Outputs\n        \n        # Output 1: i_star (index of minimum test MSE)\n        i_star = np.argmin(test_mses)\n        \n        # Output 2: b1 (indicator for non-decreasing train MSE with strict increase)\n        train_mses_arr = np.array(train_mses)\n        if len(Lambda) > 1:\n            diffs = np.diff(train_mses_arr)\n            is_nondecreasing = np.all(diffs >= -tol)\n            has_strict_increase = np.any(diffs > tol)\n            b1 = 1 if is_nondecreasing and has_strict_increase else 0\n        else:\n            b1 = 0\n            \n        # Output 3: b2 (indicator for generalization gap reduction)\n        # Assumes Lambda[0] = 0, which is true for all test cases\n        g_zero = gaps[0]\n        g_istar = gaps[i_star]\n        b2 = 1 if g_zero > g_istar + tol else 0\n        \n        final_results.extend([i_star, b1, b2])\n\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3189697"}, {"introduction": "在现实世界的数据分析中，仅仅观察到验证误差高于训练误差并不足以得出过拟合的结论，因为这种差异可能仅仅源于数据的随机波动。本练习将你的诊断技能提升到一个新的层次：统计严谨性。你将学习如何将“过拟合检测”构建为一个正式的假设检验问题，使用成对 t 检验来判断训练与验证误差之间的差距是否具有统计显著性。此外，你还将掌握多重比较校正（如 Bonferroni 和 Benjamini-Hochberg 方法）这一关键技能，以确保在比较多个模型时结论的可靠性 [@problem_id:3189600]。", "problem": "给定同一学习算法的多个超参数设置下，交叉验证 (CV) 中各折的训练误差和验证误差数组。目标是通过正式检验验证误差是否平均超过训练误差，来确定增加模型容量是否会导致统计上显著的过拟合。将此问题构建为一组配对假设检验，每个超参数设置对应一个检验，并对多重比较进行校正。\n\n基本定义：对于每个索引为 $i \\in \\{1,2,3,4\\}$ 的超参数设置和每个索引为 $k \\in \\{1,\\dots,n\\}$ (其中 $n=10$) 的折，您拥有训练误差 $e_{\\text{train},i,k}$ 和验证误差 $e_{\\text{valid},i,k}$。定义配对差异 $d_{i,k} = e_{\\text{valid},i,k} - e_{\\text{train},i,k}$。过拟合被操作化定义为备择假设 $H_{1,i}: \\mathbb{E}[d_{i,k}]  0$，其相对于原假设 $H_{0,i}: \\mathbb{E}[d_{i,k}] = 0$ 进行检验。此检验使用配对 Student's t-检验，并遵循配对样本的标准假设（各折独立，差异近似正态分布）。使用与 $H_{1,i}$ 对应的单侧方向。\n\n您必须使用两种程序来控制 $m=4$ 个同时检验的总体错误率：\n- 用于族内错误率 (FWER) 控制的 Bonferroni 校正。\n- 用于错误发现率 (FDR) 控制的 Benjamini-Hochberg (BH) 程序。\n\n对两种校正均采用 $\\alpha = 0.05$ 的显著性水平。为每个超参数设置报告一个布尔形式的过拟合决策：如果在指定的多重比较校正后，该设置的假设检验是显著的，并且 $d_{i,k}$ 的样本均值为正，则返回 $\\,\\text{True}\\,$，否则返回 $\\,\\text{False}\\,$。\n\n测试套件：\n- 共有 $m=4$ 个超参数设置，每个设置有 $n=10$ 折。下面的数组是各折的误差（无单位，以小数表示）。\n- 超参数 $i=1$（高容量模型，预期有强过拟合）：\n  - $e_{\\text{train},1,\\cdot} = [0.06, 0.05, 0.07, 0.08, 0.06, 0.05, 0.07, 0.06, 0.08, 0.05]$\n  - $e_{\\text{valid},1,\\cdot} = [0.16, 0.14, 0.18, 0.20, 0.16, 0.14, 0.17, 0.16, 0.20, 0.14]$\n- 超参数 $i=2$（调优良好的模型，预期无显著差异）：\n  - $e_{\\text{train},2,\\cdot} = [0.12, 0.13, 0.11, 0.12, 0.13, 0.11, 0.12, 0.12, 0.13, 0.11]$\n  - $e_{\\text{valid},2,\\cdot} = [0.121, 0.130, 0.112, 0.123, 0.131, 0.109, 0.118, 0.122, 0.131, 0.110]$\n- 超参数 $i=3$（低容量模型，预期欠拟合；验证误差不大于训练误差）：\n  - $e_{\\text{train},3,\\cdot} = [0.20, 0.19, 0.21, 0.22, 0.20, 0.19, 0.21, 0.22, 0.20, 0.19]$\n  - $e_{\\text{valid},3,\\cdot} = [0.18, 0.17, 0.19, 0.20, 0.18, 0.17, 0.19, 0.20, 0.18, 0.17]$\n- 超参数 $i=4$（边界情况，小的正差异伴随显著的可变性）：\n  - $e_{\\text{train},4,\\cdot} = [0.095, 0.105, 0.100, 0.110, 0.090, 0.103, 0.098, 0.107, 0.096, 0.104]$\n  - $e_{\\text{valid},4,\\cdot} = [0.090, 0.115, 0.140, 0.110, 0.105, 0.133, 0.088, 0.127, 0.101, 0.129]$\n\n算法要求：\n- 对于每个 $i$，计算 $H_{1,i}: \\mathbb{E}[d_{i,k}]  0$ 的单侧配对 $t$-检验的 $p$-值。\n- 应用 Bonferroni 校正：校正后的 $p$-值为 $p^{\\text{Bonf}}_{i} = \\min(1, m \\cdot p_{i})$，如果 $p^{\\text{Bonf}}_{i} \\le \\alpha$ 且 $d_{i,k}$ 的样本均值为正，则判定为 $\\,\\text{True}\\,$。\n- 在水平 $\\alpha$ 下应用 Benjamini-Hochberg (BH) 阶梯程序：对 $p$-值进行排序，找到满足 $p_{(k)} \\leq \\frac{k}{m}\\alpha$ 的最大索引 $k$，拒绝所有 $p_{i} \\leq p_{(k)}$ 的假设，并对那些被拒绝且 $d_{i,k}$ 样本均值为正的假设判定为 $\\,\\text{True}\\,$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。该列表由两个无空格的列表组成：第一个列表按顺序给出基于 Bonferroni 的对 $i=1,2,3,4$ 的决策，第二个列表按顺序给出基于 Benjamini-Hochberg 的对 $i=1,2,3,4$ 的决策。例如，一个有效的输出形式为 $[[\\text{True},\\text{False},\\text{False},\\text{True}],[\\text{True},\\text{False},\\text{False},\\text{True}]]$.", "solution": "该问题要求使用正式的统计程序来确定增加的模型容量是否会导致显著的过拟合。这通过对 $m=4$ 个不同超参数设置的 $k$-折交叉验证程序中的训练误差和验证误差执行一系列配对假设检验来完成。我们将使用 Bonferroni 和 Benjamini-Hochberg (BH) 方法来控制这些多重比较的总体错误率。\n\n基本原则是将过拟合操作化定义为预期验证误差大于预期训练误差的条件。对于给定的超参数设置 $i$，数据由 $n=10$ 个折中每一折的训练误差 $e_{\\text{train},i,k}$ 和验证误差 $e_{\\text{valid},i,k}$ 的配对观测值组成。配对的产生是因为两种误差都是在相同的数据分区（折 $k$）上计算的。\n\n首先，我们将超参数设置 $i$ 的每个折 $k$ 的差异定义为 $d_{i,k} = e_{\\text{valid},i,k} - e_{\\text{train},i,k}$。正的平均差异 $\\mathbb{E}[d_{i,k}] > 0$ 表示过拟合。我们将其形式化为一个单侧假设检验：\n- 原假设 $H_{0,i}: \\mu_{d_i} = \\mathbb{E}[d_{i,k}] = 0$（验证误差和训练误差之间没有差异）。\n- 备择假设 $H_{1,i}: \\mu_{d_i}  0$（验证误差大于训练误差，即过拟合）。\n\n为此，我们使用配对 Student's t-检验。每个假设 $i$ 的检验统计量计算如下：\n$$ t_i = \\frac{\\bar{d}_i}{s_{d_i} / \\sqrt{n}} $$\n其中 $\\bar{d}_i$ 是差异 $d_{i,k}$ 的样本均值，$s_{d_i}$ 是这些差异的样本标准差，而 $n=10$ 是折数（样本数）。在原假设下，该统计量服从自由度为 $n-1=9$ 的 t-分布。由此，我们为 $m=4$ 个检验中的每一个计算单侧 $p$-值 $p_i$。\n\n由于我们同时进行 $m=4$ 个检验，我们必须对多重比较进行校正，以在显著性水平 $\\alpha=0.05$ 下控制总体错误率。\n\n1.  **Bonferroni 校正（族内错误率控制）**：此方法控制在所有检验中至少犯一次 I 型错误（假阳性）的概率。这是一种保守的方法，它将每个单独检验的显著性阈值调整为 $\\alpha' = \\alpha/m$。如果原假设 $H_{0,i}$ 对应的 $p$-值 $p_i \\le \\alpha/m$，则拒绝该原假设。如果 $H_{0,i}$ 被拒绝且样本平均差异 $\\bar{d}_i > 0$，则最终的过拟合决策为 $\\text{True}$。\n\n2.  **Benjamini-Hochberg (BH) 程序（错误发现率控制）**：此方法控制所有被拒绝的假设中假阳性的预期比例。它通常比 Bonferroni 更强大（不那么保守）。程序如下：\n    a. 将原始 $p$-值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n    b. 找到满足 $p_{(k)} \\le \\frac{k}{m}\\alpha$ 的最大秩 $k$。令其为 $k_{\\text{max}}$。\n    c. 拒绝所有满足 $p_i \\le p_{(k_{\\text{max}})}$ 的原假设 $H_{0,i}$。如果不存在这样的 $k$，则不拒绝任何假设。\n    d. 如果 $H_{0,i}$ 被拒绝且 $\\bar{d}_i > 0$，则最终的过拟合决策为 $\\text{True}$。\n\n**步骤 1：计算差异和原始 p-值**\n\n我们已知 $n=10$, $m=4$, 且 $\\alpha=0.05$。对于每个超参数设置 $i$，我们计算差异 $d_{i,k}$ 并执行单侧配对 $t$-检验。\n\n-   **超参数 $i=1$**：\n    $e_{\\text{train},1} = [0.06, 0.05, 0.07, 0.08, 0.06, 0.05, 0.07, 0.06, 0.08, 0.05]$\n    $e_{\\text{valid},1} = [0.16, 0.14, 0.18, 0.20, 0.16, 0.14, 0.17, 0.16, 0.20, 0.14]$\n    $d_1 = [0.10, 0.09, 0.11, 0.12, 0.10, 0.09, 0.10, 0.10, 0.12, 0.09]$\n    $\\bar{d}_1 = 0.102$，$s_{d_1} \\approx 0.01135$。$t$-统计量为 $t_1 \\approx 28.38$。在 $df=9$ 的情况下，$p$-值为 $p_1 \\approx 1.5 \\times 10^{-10}$。\n\n-   **超参数 $i=2$**：\n    $e_{\\text{train},2} = [0.12, 0.13, 0.11, 0.12, 0.13, 0.11, 0.12, 0.12, 0.13, 0.11]$\n    $e_{\\text{valid},2} = [0.121, 0.130, 0.112, 0.123, 0.131, 0.109, 0.118, 0.122, 0.131, 0.110]$\n    $d_2 = [0.001, 0.0, 0.002, 0.003, 0.001, -0.001, -0.002, 0.002, 0.001, 0.0]$\n    $\\bar{d}_2 = 0.0007$，$s_{d_2} \\approx 0.00164$。$t$-统计量为 $t_2 \\approx 1.35$。在 $df=9$ 的情况下，$p$-值为 $p_2 \\approx 0.105$。\n\n-   **超参数 $i=3$**：\n    $e_{\\text{train},3} = [0.20, 0.19, 0.21, 0.22, 0.20, 0.19, 0.21, 0.22, 0.20, 0.19]$\n    $e_{\\text{valid},3} = [0.18, 0.17, 0.19, 0.20, 0.18, 0.17, 0.19, 0.20, 0.18, 0.17]$\n    $d_3 = [-0.02, -0.02, -0.02, -0.02, -0.02, -0.02, -0.02, -0.02, -0.02, -0.02]$\n    $\\bar{d}_3 = -0.02$。由于样本平均差异为负，数据与备择假设 $H_{1,3}: \\mu_{d_3}  0$ 的方向相反。无论 $p$-值如何，决策都是 $\\text{False}$。为完整起见，$p_3 \\approx 1.0$。\n\n-   **超参数 $i=4$**：\n    $e_{\\text{train},4} = [0.095, 0.105, 0.100, 0.110, 0.090, 0.103, 0.098, 0.107, 0.096, 0.104]$\n    $e_{\\text{valid},4} = [0.090, 0.115, 0.140, 0.110, 0.105, 0.133, 0.088, 0.127, 0.101, 0.129]$\n    $d_4 = [-0.005, 0.01, 0.04, 0.0, 0.015, 0.03, -0.01, 0.02, 0.005, 0.025]$\n    $\\bar{d}_4 = 0.013$，$s_{d_4} \\approx 0.0173$。$t$-统计量为 $t_4 \\approx 2.38$。在 $df=9$ 的情况下，$p$-值为 $p_4 \\approx 0.0205$。\n\n原始 $p$-值和平均差异摘要：\n- $i=1$: $\\bar{d}_1 = 0.102 > 0$, $p_1 \\approx 1.5 \\times 10^{-10}$\n- $i=2$: $\\bar{d}_2 = 0.0007 > 0$, $p_2 \\approx 0.105$\n- $i=3$: $\\bar{d}_3 = -0.02 \\le 0$, $p_3 \\approx 1.0$\n- $i=4$: $\\bar{d}_4 = 0.013 > 0$, $p_4 \\approx 0.0205$\n\n**步骤 2：应用 Bonferroni 校正**\n\n校正后的显著性水平为 $\\alpha' = \\alpha / m = 0.05 / 4 = 0.0125$。\n- $i=1$：$\\bar{d}_1 > 0$ 且 $p_1 \\approx 1.5 \\times 10^{-10} \\le 0.0125$。结果：$\\text{True}$。\n- $i=2$：$\\bar{d}_2 > 0$ 但 $p_2 \\approx 0.105 \\not\\le 0.0125$。结果：$\\text{False}$。\n- $i=3$：$\\bar{d}_3 \\le 0$。结果：$\\text{False}$。\n- $i=4$：$\\bar{d}_4 > 0$ 但 $p_4 \\approx 0.0205 \\not\\le 0.0125$。结果：$\\text{False}$。\n\nBonferroni 决策列表为 $[\\text{True}, \\text{False}, \\text{False}, \\text{False}]$。\n\n**步骤 3：应用 Benjamini-Hochberg 程序**\n\n1.  排序后的 $p$-值：\n    - $p_{(1)} = p_1 \\approx 1.5 \\times 10^{-10}$ (原始索引 1)\n    - $p_{(2)} = p_4 \\approx 0.0205$ (原始索引 4)\n    - $p_{(3)} = p_2 \\approx 0.105$ (原始索引 2)\n    - $p_{(4)} = p_3 \\approx 1.0$ (原始索引 3)\n\n2.  临界值 $\\frac{k}{m}\\alpha = \\frac{k}{4}(0.05) = k \\cdot 0.0125$：\n    - $k=1: 0.0125$\n    - $k=2: 0.0250$\n    - $k=3: 0.0375$\n    - $k=4: 0.0500$\n\n3.  找到满足 $p_{(k)} \\le \\frac{k}{m}\\alpha$ 的最大 $k$:\n    - 对于 $k=4$：$p_{(4)} \\approx 1.0 \\not\\le 0.0500$。\n    - 对于 $k=3$：$p_{(3)} \\approx 0.105 \\not\\le 0.0375$。\n    - 对于 $k=2$：$p_{(2)} \\approx 0.0205 \\le 0.0250$。此条件成立。\n    因此，$k_{\\text{max}}=2$。显著性阈值为 $p_{(2)} \\approx 0.0205$。\n\n4.  拒绝所有 $p_i \\le 0.0205$ 的 $H_{0,i}$。这适用于 $p_1$ 和 $p_4$。\n    - $i=1$：$H_0$ 被拒绝。$\\bar{d}_1 > 0$。结果：$\\text{True}$。\n    - $i=2$：$H_0$ 未被拒绝（$p_2 > 0.0205$）。结果：$\\text{False}$。\n    - $i=3$：$\\bar{d}_3 \\le 0$。结果：$\\text{False}$。\n    - $i=4$：$H_0$ 被拒绝。$\\bar{d}_4 > 0$。结果：$\\text{True}$。\n\nBenjamini-Hochberg 决策列表为 $[\\text{True}, \\text{False}, \\text{False}, \\text{True}]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Performs paired t-tests and multiple comparison corrections to detect overfitting.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([0.06, 0.05, 0.07, 0.08, 0.06, 0.05, 0.07, 0.06, 0.08, 0.05]),\n            np.array([0.16, 0.14, 0.18, 0.20, 0.16, 0.14, 0.17, 0.16, 0.20, 0.14])\n        ),\n        (\n            np.array([0.12, 0.13, 0.11, 0.12, 0.13, 0.11, 0.12, 0.12, 0.13, 0.11]),\n            np.array([0.121, 0.130, 0.112, 0.123, 0.131, 0.109, 0.118, 0.122, 0.131, 0.110])\n        ),\n        (\n            np.array([0.20, 0.19, 0.21, 0.22, 0.20, 0.19, 0.21, 0.22, 0.20, 0.19]),\n            np.array([0.18, 0.17, 0.19, 0.20, 0.18, 0.17, 0.19, 0.20, 0.18, 0.17])\n        ),\n        (\n            np.array([0.095, 0.105, 0.100, 0.110, 0.090, 0.103, 0.098, 0.107, 0.096, 0.104]),\n            np.array([0.090, 0.115, 0.140, 0.110, 0.105, 0.133, 0.088, 0.127, 0.101, 0.129])\n        )\n    ]\n\n    alpha = 0.05\n    m = len(test_cases)\n    \n    # --- Step 1: Calculate raw p-values and mean differences ---\n    p_values = []\n    mean_diffs = []\n    for e_train, e_valid in test_cases:\n        diffs = e_valid - e_train\n        mean_diffs.append(np.mean(diffs))\n        \n        # We only care about positive differences for overfitting\n        if np.mean(diffs) = 0:\n            p_values.append(1.0)\n        else:\n            # Perform one-sided paired t-test for valid > train\n            t_stat, p_val = stats.ttest_rel(e_valid, e_train, alternative='greater')\n            p_values.append(p_val)\n\n    # --- Step 2: Bonferroni Correction ---\n    bonferroni_threshold = alpha / m\n    bonferroni_decisions = []\n    for i in range(m):\n        is_significant = p_values[i] = bonferroni_threshold\n        is_positive_diff = mean_diffs[i] > 0\n        bonferroni_decisions.append(is_significant and is_positive_diff)\n\n    # --- Step 3: Benjamini-Hochberg (BH) Procedure ---\n    bh_decisions = [False] * m\n    \n    # Sort p-values while keeping track of original indices\n    # We use a stable sort to handle ties, although not strictly necessary here\n    sorted_indices = np.argsort(p_values)\n    sorted_p_values = np.array(p_values)[sorted_indices]\n\n    # Find the largest k such that p_(k) = (k/m)*alpha\n    k_max = 0\n    for k in range(m, 0, -1):\n        if sorted_p_values[k-1] = (k / m) * alpha:\n            k_max = k\n            break\n    \n    # If a threshold is found, reject corresponding hypotheses\n    if k_max > 0:\n        p_threshold = sorted_p_values[k_max - 1]\n        for i in range(m):\n            if p_values[i] = p_threshold and mean_diffs[i] > 0:\n                bh_decisions[i] = True\n\n    # --- Final Output Formatting ---\n    # Convert Python boolean to string 'True' or 'False'\n    bonf_str = ','.join(map(str, bonferroni_decisions))\n    bh_str = ','.join(map(str, bh_decisions))\n    \n    print(f\"[[{bonf_str}],[{bh_str}]]\")\n\nsolve()\n\n```", "id": "3189600"}]}