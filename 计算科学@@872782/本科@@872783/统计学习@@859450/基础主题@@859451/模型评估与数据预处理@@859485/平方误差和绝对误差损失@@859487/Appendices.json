{"hands_on_practices": [{"introduction": "我们通过一个具体的数值案例来开启实践之旅。这个练习将直观地展示一个核心观点：由于单个极端异常值的存在，均方误差（$MSE$）和平均绝对误差（$MAE$）对模型性能的排序可能会截然相反。通过计算和比较 [@problem_id:3168840]，你将亲身体会到 $L_2$ 损失对异常值的敏感性以及 $L_1$ 损失的稳健性，为理解两者差异奠定坚实的基础。", "problem": "考虑一个深度学习回归任务，其中两个模型（标记为 $X$ 和 $Y$）在 $n=10$ 个留出样本上进行评估。观察到其残差（预测值减去真实值）如下。对于模型 $X$，9 个样本的残差为 $-0.5$，1 个样本的残差为 $10$。对于模型 $Y$，5 个样本的残差为 $-1.8$，5 个样本的残差为 $+1.8$。在不使用任何预先给定的公式的情况下，确定哪个模型在平均绝对误差（MAE）上排名更好，哪个在均方误差（MSE）上排名更好，并选择通过引用适当的残差分布矩来正确解释为什么排名会反转的选项。回想一下，平均绝对误差（MAE）和均方误差（MSE）是标准的回归性能指标。\n\n哪个选项是正确的？\n\nA. $MAE$ 偏好模型 $X$，而 $MSE$ 偏好模型 $Y$。这种反转可以解释为，$MSE$ 由二阶矩（方差）驱动，在由于 $X$ 中存在单个极端异常值而导致的高峰度重尾残差下会变得很大，而 $MAE$ 取决于一阶绝对矩，对孤立的异常值相对稳健。$X$ 中的正偏度表示不对称性，但其本身并不会推翻 $MAE$ 的稳健性。\n\nB. $MAE$ 和 $MSE$ 都偏好模型 $Y$，因为其平均残差为 $0$，并且 $MSE$ 主要取决于均值；一旦考虑了均值，$X$ 中的异常值就不会改变排名。\n\nC. $MAE$ 偏好模型 $Y$，而 $MSE$ 偏好模型 $X$，因为 $MAE$ 比 $MSE$ 更强烈地放大了大的异常值，所以 $X$ 中的极端残差对 $MAE$ 的影响比对 $MSE$ 的影响更大。\n\nD. 当存在单个正异常值时，排名不会反转；这种反转需要负偏度。因此，对于给定的残差，$MAE$ 和 $MSE$ 都偏好同一个模型。\n\nE. $MAE$ 偏好模型 $X$，$MSE$ 偏好模型 $Y$，但反转主要是因为 $MSE$ 对偏度而不是方差有响应；即使方差相似，偏度本身也会直接增加 $MSE$。", "solution": "在进行求解之前，对问题陈述进行了严格验证。\n\n### 步骤 1：提取已知条件\n- 一个深度学习回归任务涉及两个模型，$X$ 和 $Y$。\n- 留出样本的数量为 $n=10$。\n- 模型 $X$ 的残差（表示为集合 $R_X$）由 9 个值为 $-0.5$ 和 1 个值为 $10$ 组成。\n- 模型 $Y$ 的残差（表示为集合 $R_Y$）由 5 个值为 $-1.8$ 和 5 个值为 $1.8$ 组成。\n- 任务是确定哪个模型在平均绝对误差（MAE）和均方误差（MSE）上排名更好，并通过引用残差分布矩来解释排名可能发生的反转。\n- 约束是“不使用任何预先给定的公式”来解决问题，这被解释为从指标的基本定义推导出结果。\n\n### 步骤 2：使用提取的已知条件进行验证\n- **科学依据：** 该问题基于统计学和机器学习评估中的基本和标准概念：平均绝对误差（MAE）、均方误差（MSE），以及使用统计矩（均值、方差、偏度、峰度）对残差分布的分析。这些都是该领域公认的核心概念。\n- **问题定义良好：** 问题提供了计算所需指标的所有必要数值数据。残差集合已完全指定，样本数量一致。问题明确，可以得出一个唯一的、可计算的解。\n- **客观性：** 问题使用精确、客观的语言和数值数据陈述。它不包含主观或基于意见的主张。\n\n该问题不违反任何无效性标准。这是一个定义良好、科学合理、客观的问题，旨在测试对回归指标的理解。\n\n### 步骤 3：结论和行动\n问题是**有效的**。将推导解答。\n\n### 解答推导\n这些指标从第一性原理定义如下。对于一组 $n$ 个残差 $\\{r_i\\}_{i=1}^n$：\n- **平均绝对误差 (MAE)** 是残差绝对值的平均值：$MAE = \\frac{1}{n} \\sum_{i=1}^n |r_i|$。\n- **均方误差 (MSE)** 是残差平方值的平均值：$MSE = \\frac{1}{n} \\sum_{i=1}^n r_i^2$。\n任一指标值越低，表示模型性能越好。\n\n**模型 X 的计算：**\n残差为 $R_X = \\{ \\underbrace{-0.5, \\dots, -0.5}_{9 \\text{ 次}}, 10 \\}$。样本数量为 $n=10$。\n\n- **模型 X 的 MAE ($MAE_X$)：**\n$$MAE_X = \\frac{1}{10} \\left( 9 \\times |-0.5| + 1 \\times |10| \\right)$$\n$$MAE_X = \\frac{1}{10} \\left( 9 \\times 0.5 + 10 \\right)$$\n$$MAE_X = \\frac{1}{10} \\left( 4.5 + 10 \\right) = \\frac{14.5}{10} = 1.45$$\n\n- **模型 X 的 MSE ($MSE_X$)：**\n$$MSE_X = \\frac{1}{10} \\left( 9 \\times (-0.5)^2 + 1 \\times (10)^2 \\right)$$\n$$MSE_X = \\frac{1}{10} \\left( 9 \\times 0.25 + 100 \\right)$$\n$$MSE_X = \\frac{1}{10} \\left( 2.25 + 100 \\right) = \\frac{102.25}{10} = 10.225$$\n\n**模型 Y 的计算：**\n残差为 $R_Y = \\{ \\underbrace{-1.8, \\dots, -1.8}_{5 \\text{ 次}}, \\underbrace{1.8, \\dots, 1.8}_{5 \\text{ 次}} \\}$。样本数量为 $n=10$。\n\n- **模型 Y 的 MAE ($MAE_Y$)：**\n$$MAE_Y = \\frac{1}{10} \\left( 5 \\times |-1.8| + 5 \\times |1.8| \\right)$$\n$$MAE_Y = \\frac{1}{10} \\left( 5 \\times 1.8 + 5 \\times 1.8 \\right)$$\n$$MAE_Y = \\frac{1}{10} \\left( 10 \\times 1.8 \\right) = 1.8$$\n\n- **模型 Y 的 MSE ($MSE_Y$)：**\n$$MSE_Y = \\frac{1}{10} \\left( 5 \\times (-1.8)^2 + 5 \\times (1.8)^2 \\right)$$\n$$MSE_Y = \\frac{1}{10} \\left( 10 \\times (1.8)^2 \\right)$$\n$$MSE_Y = (1.8)^2 = 3.24$$\n\n**排名比较：**\n- **MAE:** $MAE_X = 1.45$ 且 $MAE_Y = 1.8$。由于 $1.45  1.8$，模型 $X$ 在 MAE 上的排名更好。\n- **MSE:** $MSE_X = 10.225$ 且 $MSE_Y = 3.24$。由于 $10.225 > 3.24$，模型 $Y$ 在 MSE 上的排名更好。\n\n排名确实发生了反转。\n\n**使用残差分布矩进行分析：**\n- **MAE** 是关于原点的一阶绝对矩 ($E[|R|]$)。它对所有误差进行线性处理（取绝对值）。对于模型 $X$，9 个小误差对总和的贡献很小，而单个大异常值则线性贡献 ($10$)。总体平均值保持相对较低。\n- **MSE** 是关于原点的二阶矩 ($E[R^2]$)。它通过恒等式 $MSE = \\sigma^2 + \\mu^2$ 与方差（二阶中心矩，$\\sigma^2 = E[(R-\\mu)^2]$）和均值（一阶矩，$\\mu = E[R]$）相关。由于平方运算，MSE 对大误差的惩罚不成比例。对于模型 $X$，单个残差 $10$ 对平方和的贡献为 $10^2 = 100$，在总和中占主导地位，导致 MSE 非常高。这种对极端异常值的敏感性是 MSE 的特点。\n- 极端异常值的存在（如模型 $X$ 的残差中所示）会产生“重尾”分布。这可以通过**峰度**（缩放的四阶中心矩）来量化，对于模型 $X$，峰度会非常高（尖峰分布）。高峰度表明异常值比正态分布中的更极端，而 MSE 对此高度敏感。\n- 模型 $X$ 的分布也是不对称的，如其**偏度**（缩放的三阶中心矩）所示。单个大的正残差产生了强烈的正偏。虽然偏度描述了不对称性，但与 MSE 大小最直接相关的是峰度和潜在的方差。\n- 模型 $Y$ 的残差围绕 $0$ 对称，因此其均值和偏度均为 $0$。它没有极端异常值，因此方差适中，MSE 也适中。\n\n### 逐项分析选项\n\n**A. $MAE$ 偏好模型 $X$，而 $MSE$ 偏好模型 $Y$。这种反转可以解释为，$MSE$ 由二阶矩（方差）驱动，在由于 $X$ 中存在单个极端异常值而导致的高峰度重尾残差下会变得很大，而 $MAE$ 取决于一阶绝对矩，对孤立的异常值相对稳健。$X$ 中的正偏度表示不对称性，但其本身并不会推翻 $MAE$ 的稳健性。**\n- 排名是正确的：我们的计算显示 $MAE$ 偏好 $X$，$MSE$ 偏好 $Y$。\n- 解释是合理的。$MSE$ 确实由二阶矩 ($E[R^2]$) 驱动，因此与方差密切相关。它对由 $X$ 残差中的异常值引起的重尾和高峰度极为敏感。\n- 相反，$MAE$ ($E[|R|]$) 是一阶绝对矩，并且已知对这类异常值更稳健。\n- 关于偏度的陈述也是正确的；它表示不对称性，但 MSE 值大的主要原因是平方误差的大小，这通过方差和峰度能更好地描述。\n- **结论：** 正确。\n\n**B. $MAE$ 和 $MSE$ 都偏好模型 $Y$，因为其平均残差为 $0$，并且 $MSE$ 主要取决于均值；一旦考虑了均值，$X$ 中的异常值就不会改变排名。**\n- 第一句话“$MAE$ 和 $MSE$ 都偏好模型 $Y$”是错误的。我们的计算显示 $MAE$ 偏好模型 $X$。\n- 理由“$MSE$ 主要取决于均值”是错误的。$MSE = \\sigma^2 + \\mu^2$。对于模型 $X$，均值为 $\\mu_X = \\frac{1}{10}(9 \\times -0.5 + 10) = 0.55$，所以 $\\mu_X^2 = 0.3025$。方差为 $\\sigma_X^2 = MSE_X - \\mu_X^2 = 10.225 - 0.3025 = 9.9225$。MSE 显然由方差主导，而不是均值。\n- **结论：** 不正确。\n\n**C. $MAE$ 偏好模型 $Y$，而 $MSE$ 偏好模型 $X$，因为 $MAE$ 比 $MSE$ 更强烈地放大了大的异常值，所以 $X$ 中的极端残差对 $MAE$ 的影响比对 $MSE$ 的影响更大。**\n- 排名“$MAE$ 偏好模型 $Y$ 而 $MSE$ 偏好模型 $X$”与计算结果完全相反。\n- 理由“$MAE$ 比 $MSE$ 更强烈地放大了大的异常值”是根本错误的。MSE 中的平方运算 ($r^2$) 比 MAE 中的绝对值运算 ($|r|$) 导致对大误差的放大作用强得多。\n- **结论：** 不正确。\n\n**D. 当存在单个正异常值时，排名不会反转；这种反转需要负偏度。因此，对于给定的残差，$MAE$ 和 $MSE$ 都偏好同一个模型。**\n- 前提“当存在单个正异常值时，排名不会反转”显然是错误的，因为计算已经显示了反转。\n- 声称反转“需要负偏度”是一个毫无根据且不正确的断言。反转取决于异常值的大小与其他残差分布之间的相互作用，而不是偏度的符号。\n- **结论：** 不正确。\n\n**E. $MAE$ 偏好模型 $X$，$MSE$ 偏好模型 $Y$，但反转主要是因为 $MSE$ 对偏度而不是方差有响应；即使方差相似，偏度本身也会直接增加 $MSE$。**\n- 初始排名是正确的。\n- 理由“$MSE$ 对偏度而不是方差有响应”是错误的。$MSE$ 是关于原点的二阶矩。方差是二阶中心矩。偏度与三阶中心矩有关。它们是不同的概念。MSE 是方差和均值的直接函数，而不是偏度的函数。在由异常值驱动的分布中，高偏度常常与高方差同时出现，但 MSE 的值是由方差和均值决定的，而不是直接由偏度决定的。\n- **结论：** 不正确。", "answer": "$$\\boxed{A}$$", "id": "3168840"}, {"introduction": "理论的深度需要通过实践来巩固。最后一个练习 [@problem_id:3175036] 将引导你通过编写蒙特卡洛模拟程序，亲自探索和验证前述概念。你将模拟一个受污染的数据生成过程，并比较基于 $L_1$ 损失的估计量（样本中位数）和基于 $L_2$ 损失的估计量（样本均值）的性能。通过调整污染比例和异常值严重程度等参数，你将能动态地观察到稳健统计的威力，并确定不同损失函数在不同场景下的优劣领域。", "problem": "考虑一个一维回归问题，其中真实响应为常数，等于参数 $\\theta \\in \\mathbb{R}$。观测到的标签受到对称加性污染：对于每个独立同分布 (i.i.d.) 的观测索引 $i \\in \\{1,2,\\dots,n\\}$，观测到的标签为 $Y_i = \\theta + W_i$，其中 $W_i$ 服从一个双组分混合分布。具体来说，噪声 $W_i$ 以 $1 - \\alpha$ 的概率从均值为 $0$、方差为 $\\sigma^2$ 的高斯分布中抽取，以 $\\alpha$ 的概率从位置为 $0$、尺度为 $b$ 的拉普拉斯分布中抽取。该混合分布关于 $0$ 对称，污染分数 $\\alpha \\in [0,1)$ 控制拉普拉斯离群值出现的频率。\n\n需要从样本 $\\{Y_1,\\dots,Y_n\\}$ 中构建两个关于 $\\theta$ 的经验估计量：\n- 最小化经验平方误差损失 $L_2(y,\\hat{\\theta}) = (y - \\hat{\\theta})^2$ 的估计量。\n- 最小化经验绝对误差损失 $L_1(y,\\hat{\\theta}) = |y - \\hat{\\theta}|$ 的估计量。\n\n将估计量 $\\hat{\\theta}$ 的绝对风险定义为 $R_{\\mathrm{abs}}(\\hat{\\theta}) = \\mathbb{E}[\\,|\\hat{\\theta} - \\theta|\\,]$，平方风险定义为 $R_{\\mathrm{sq}}(\\hat{\\theta}) = \\mathbb{E}[\\,(\\hat{\\theta} - \\theta)^2\\,]$，其中期望是根据污染模型引起的抽样分布计算的。\n\n您的任务是编写一个程序，对下面套件中的每个测试用例，通过蒙特卡洛模拟（使用固定的随机种子以保证可复现性）估计这两个估计量的绝对风险和平方风险，然后确定在每种损失下的优势区域：\n- 在 $L_1$ 下，如果基于 $L_1$ 的估计量的估计绝对风险严格小于基于 $L_2$ 的估计量的估计绝对风险，则称其占优；否则，不占优。\n- 在 $L_2$ 下，如果基于 $L_2$ 的估计量的估计平方风险严格小于基于 $L_1$ 的估计量的估计平方风险，则称其占优；否则，不占优。\n\n在所有情况下都使用 $\\theta = 0$。对于每个案例，对完整样本执行至少 $M = 2000$ 次独立重复的蒙特卡洛模拟；在每次重复中，根据污染模型生成 $n$ 个 i.i.d. 标签，并计算两个估计量及其相对于 $\\theta$ 的误差。将 $M$ 次重复的误差取平均值以估计风险，然后进行比较。\n\n测试套件（每个案例指定 $(\\alpha,\\sigma,b,n)$）：\n- 案例 1：$\\alpha = 0$，$\\sigma = 1$， $b = 3$， $n = 1000$。\n- 案例 2：$\\alpha = 0.2$，$\\sigma = 1$， $b = 5$， $n = 1000$。\n- 案例 3：$\\alpha = 0.4$，$\\sigma = 1$， $b = 10$，$n = 1000$。\n- 案例 4：$\\alpha = 0.2$，$\\sigma = 1$， $b = 1$， $n = 1000$。\n- 案例 5：$\\alpha = 0.2$，$\\sigma = 1$， $b = 5$， $n = 50$。\n\n最终输出格式：您的程序应生成单行输出，其中包含结果，格式为一个逗号分隔的双元素列表的列表，每个测试用例对应一个，并用方括号括起来。每个双元素列表必须为 $[a,b]$ 的形式，其中 $a$ 是一个布尔值，指示基于 $L_1$ 的估计量在绝对风险下是否占优，$b$ 是一个布尔值，指示基于 $L_2$ 的估计量在平方风险下是否占优。例如，输出可能看起来像 $[[\\mathrm{True},\\mathrm{False}],[\\mathrm{False},\\mathrm{True}],\\dots]$。", "solution": "用户提供的问题经评估有效。该问题在科学上是合理的，提法明确且客观，提出了一个稳健统计估计中的标准问题。\n\n### 1. 理论框架\n\n该问题要求在存在污染数据的情况下，比较中心趋势参数 $\\theta$ 的两个基本估计量。这些估计量是通过最小化两种不同的经验损失函数得出的。\n\n#### 1.1. 估计量\n\n- **$L_2$（平方误差）损失估计量：** 估计量 $\\hat{\\theta}_2$ 最小化经验平方误差 $R_{\\mathrm{emp}, 2}(\\hat{\\theta}) = \\sum_{i=1}^n (Y_i - \\hat{\\theta})^2$。为了找到最小值，我们对 $\\hat{\\theta}$ 求导并令其为零：\n$$\n\\frac{d}{d\\hat{\\theta}} \\sum_{i=1}^n (Y_i - \\hat{\\theta})^2 = \\sum_{i=1}^n -2(Y_i - \\hat{\\theta}) = -2 \\left( \\sum_{i=1}^n Y_i - n\\hat{\\theta} \\right) = 0\n$$\n这得到 $\\hat{\\theta} = \\frac{1}{n}\\sum_{i=1}^n Y_i$。因此，最小化平方误差损失的估计量是**样本均值**。我们将其表示为 $\\hat{\\theta}_{\\text{mean}}$。\n\n- **$L_1$（绝对误差）损失估计量：** 估计量 $\\hat{\\theta}_1$ 最小化经验绝对误差 $R_{\\mathrm{emp}, 1}(\\hat{\\theta}) = \\sum_{i=1}^n |Y_i - \\hat{\\theta}|$。这是统计学中一个众所周知的结果：使该和最小化的 $\\hat{\\theta}$ 的值是**样本中位数**。我们将其表示为 $\\hat{\\theta}_{\\text{median}}$。\n\n#### 1.2. 噪声模型\n\n观测数据 $Y_i$ 的生成方式为 $Y_i = \\theta + W_i$，其中噪声项 $W_i$ 从一个混合分布中抽取。$W_i$ 的概率密度函数 (PDF) 由下式给出：\n$$\nf_W(w) = (1-\\alpha) \\cdot \\phi(w; 0, \\sigma^2) + \\alpha \\cdot f_L(w; 0, b)\n$$\n其中 $\\phi(w; 0, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{w^2}{2\\sigma^2}\\right)$ 是均值为 $0$、方差为 $\\sigma^2$ 的高斯分布的概率密度函数，而 $f_L(w; 0, b) = \\frac{1}{2b} \\exp\\left(-\\frac{|w|}{b}\\right)$ 是位置为 $0$、尺度为 $b$ 的拉普拉斯分布的概率密度函数。与高斯分布相比，拉普拉斯分布以其更重的尾部而闻名，这使其成为生成离群值的合适模型。参数 $\\alpha$ 控制这些离群值的出现频率。\n\n#### 1.3. 风险函数与优势\n\n我们的任务是使用两个风险函数来评估 $\\hat{\\theta}_{\\text{mean}}$ 和 $\\hat{\\theta}_{\\text{median}}$ 的性能：\n- **绝对风险：** $R_{\\mathrm{abs}}(\\hat{\\theta}) = \\mathbb{E}[|\\hat{\\theta} - \\theta|]$\n- **平方风险：** $R_{\\mathrm{sq}}(\\hat{\\theta}) = \\mathbb{E}[(\\hat{\\theta} - \\theta)^2]$，即均方误差 (MSE)。\n\n期望 $\\mathbb{E}[\\cdot]$ 是对所有可以从指定的数据生成过程中抽取的可能随机样本 $\\{Y_1, \\dots, Y_n\\}$ 计算的。由于对于给定的混合模型和估计量，对这些风险进行解析推导是复杂的，因此我们使用蒙特卡洛模拟来估计它们。\n\n- 如果基于 $L_1$ 的估计量（$\\hat{\\theta}_{\\text{median}}$）的估计绝对风险严格小于基于 $L_2$ 的估计量（$\\hat{\\theta}_{\\text{mean}}$）的估计绝对风险，则称其在绝对风险下占优。\n- 如果基于 $L_2$ 的估计量（$\\hat{\\theta}_{\\text{mean}}$）的估计平方风险严格小于基于 $L_1$ 的估计量（$\\hat{\\theta}_{\\text{median}}$）的估计平方风险，则称其在平方风险下占优。\n\n### 2. 蒙特卡洛模拟过程\n\n对于每个测试用例 $(\\alpha, \\sigma, b, n)$，我们在 $\\theta=0$ 和模拟次数 $M=2000$ 的条件下执行以下步骤。\n\n1.  **设置随机种子：** 使用固定的种子以确保随机数生成的可复现性。\n2.  **生成样本：** 对于 $M$ 次蒙特卡洛重复中的每一次：\n    a. 生成一个大小为 $n$ 的样本，表示为 $\\{Y_1, \\dots, Y_n\\}$。由于 $\\theta=0$，我们有 $Y_i = W_i$。为了生成每个 $W_i$，我们首先从参数为 $\\alpha$ 的伯努利分布中抽样。如果结果为 $1$（以概率 $\\alpha$ 发生），我们从 $\\text{Laplace}(0, b)$ 中抽样。如果结果为 $0$（以概率 $1-\\alpha$ 发生），我们从 $\\mathcal{N}(0, \\sigma^2)$ 中抽样。\n    b. 重复此过程以创建 $M$ 个独立的、每个大小为 $n$ 的数据集。\n3.  **计算估计量：** 对于 $M$ 个数据集中的每一个：\n    a. 计算样本均值 $\\hat{\\theta}_{\\text{mean}}$。\n    b. 计算样本中位数 $\\hat{\\theta}_{\\text{median}}$。\n4.  **计算误差：** 对于每次重复 $j \\in \\{1, \\dots, M\\}$，计算估计误差。由于 $\\theta=0$，误差就是估计量的值。我们为每次重复计算四个量：\n    - 中位数的绝对误差：$|\\hat{\\theta}_{\\text{median},j}|$\n    - 均值的绝对误差：$|\\hat{\\theta}_{\\text{mean},j}|$\n    - 中位数的平方误差：$(\\hat{\\theta}_{\\text{median},j})^2$\n    - 均值的平方误差：$(\\hat{\\theta}_{\\text{mean},j})^2$\n5.  **估计风险：** 通过对所有 $M$ 次重复的相应误差求平均来估计风险：\n    - $\\hat{R}_{\\mathrm{abs}}(\\hat{\\theta}_{\\text{median}}) = \\frac{1}{M} \\sum_{j=1}^M |\\hat{\\theta}_{\\text{median},j}|$\n    - $\\hat{R}_{\\mathrm{abs}}(\\hat{\\theta}_{\\text{mean}}) = \\frac{1}{M} \\sum_{j=1}^M |\\hat{\\theta}_{\\text{mean},j}|$\n    - $\\hat{R}_{\\mathrm{sq}}(\\hat{\\theta}_{\\text{median}}) = \\frac{1}{M} \\sum_{j=1}^M (\\hat{\\theta}_{\\text{median},j})^2$\n    - $\\hat{R}_{\\mathrm{sq}}(\\hat{\\theta}_{\\text{mean}}) = \\frac{1}{M} \\sum_{j=1}^M (\\hat{\\theta}_{\\text{mean},j})^2$\n6.  **确定优势：** 对于每个测试用例，我们应用指定的优势规则：\n    - **$L_1$ 优势：** 如果 $\\hat{R}_{\\mathrm{abs}}(\\hat{\\theta}_{\\text{median}})  \\hat{R}_{\\mathrm{abs}}(\\hat{\\theta}_{\\text{mean}})$，则结果为 `True`，否则为 `False`。\n    - **$L_2$ 优势：** 如果 $\\hat{R}_{\\mathrm{sq}}(\\hat{\\theta}_{\\text{mean}})  \\hat{R}_{\\mathrm{sq}}(\\hat{\\theta}_{\\text{median}})$，则结果为 `True`，否则为 `False`。\n\n为五个测试用例中的每一个实施此过程以生成最终输出。为了提高效率，该逻辑是向量化的，一次性生成所有 $M \\times n$ 个噪声值，然后在适当的轴上计算估计量和风险。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Performs Monte Carlo simulations to compare the absolute and squared risks\n    of the sample mean and sample median estimators under a contaminated noise model.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (alpha, sigma, b, n)\n        (0.0, 1.0, 3.0, 1000),  # Case 1: Purely Gaussian noise\n        (0.2, 1.0, 5.0, 1000),  # Case 2: Contamination with heavy-tailed outliers\n        (0.4, 1.0, 10.0, 1000), # Case 3: Higher contamination, more severe outliers\n        (0.2, 1.0, 1.0, 1000),  # Case 4: Contamination with less severe outliers\n        (0.2, 1.0, 5.0, 50),    # Case 5: Smaller sample size\n    ]\n\n    # Monte Carlo simulation parameters\n    M = 2000  # Number of independent replicates\n    theta = 0.0 # True parameter value\n    \n    # Set a fixed random seed for reproducibility\n    np.random.seed(42)\n\n    results = []\n    for alpha, sigma, b, n in test_cases:\n        # Vectorized generation of all random variables for M replicates\n        # Shape of all arrays will be (M, n)\n        \n        # Determine for each of the M*n observations whether it's from Gaussian or Laplace\n        # 1 for Laplace, 0 for Gaussian\n        is_laplace = np.random.binomial(1, alpha, size=(M, n))\n        \n        # Generate noise from both distributions for all M*n points\n        gaussian_noise = np.random.normal(loc=0, scale=sigma, size=(M, n))\n        laplace_noise = np.random.laplace(loc=0, scale=b, size=(M, n))\n        \n        # Combine the noise based on the mixture choices\n        # if is_laplace is 0, use gaussian_noise, otherwise use laplace_noise\n        W = np.where(is_laplace == 1, laplace_noise, gaussian_noise)\n        \n        # The observed labels Y_i = theta + W_i. Since theta=0, Y = W.\n        Y = W\n        \n        # Calculate estimators for each of the M replicates.\n        # axis=1 performs the operation across each sample of size n.\n        \n        # L1-based estimator: sample median\n        theta_hat_1 = np.median(Y, axis=1) # Shape: (M,)\n        \n        # L2-based estimator: sample mean\n        theta_hat_2 = np.mean(Y, axis=1)   # Shape: (M,)\n        \n        # Calculate errors relative to the true theta=0\n        # error_1 is median - theta, error_2 is mean - theta\n        error_1 = theta_hat_1 - theta\n        error_2 = theta_hat_2 - theta\n        \n        # Estimate the risks by averaging errors over M replicates\n        \n        # Absolute risks\n        risk_abs_1 = np.mean(np.abs(error_1)) # E[|median - theta|]\n        risk_abs_2 = np.mean(np.abs(error_2)) # E[|mean - theta|]\n        \n        # Squared risks\n        risk_sq_1 = np.mean(error_1**2) # E[(median - theta)^2]\n        risk_sq_2 = np.mean(error_2**2) # E[(mean - theta)^2]\n        \n        # Determine dominance based on strict inequality\n        \n        # Under L1 loss, does the L1-based estimator (median) dominate?\n        # This means: is the absolute risk of the median strictly less than that of the mean?\n        l1_dominates = risk_abs_1  risk_abs_2\n        \n        # Under L2 loss, does the L2-based estimator (mean) dominate?\n        # This means: is the squared risk of the mean strictly less than that of the median?\n        l2_dominates = risk_sq_2  risk_sq_1\n        \n        results.append([l1_dominates, l2_dominates])\n\n    # Format the final output as a single string\n    # e.g., [[True,False],[False,True]]\n    output_str = \"[\" + \",\".join([f\"[{str(res[0])},{str(res[1])}]\" for res in results]) + \"]\"\n\n    # Final print statement in the exact required format.\n    print(output_str)\n\nsolve()\n```", "id": "3175036"}]}