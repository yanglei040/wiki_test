{"hands_on_practices": [{"introduction": "在训练了一个输出概率的分类模型后，一个常见的任务是选择一个最佳的分类阈值。这个练习将指导你使用验证集（$X_{\\text{val}}$）来寻找一个能够最大化特定性能指标（如 $F_\\beta$ 分数）的阈值 $t^*$。然后，我们将在测试集（$X_{\\text{test}}$）上评估使用该阈值的模型，以获得其泛化性能的无偏估计。\n\n这个实践的核心是帮助你理解“阈值过拟合”的风险 [@problem_id:3188635]。即使模型本身泛化良好，所选的阈值也可能过度拟合验证集，导致在未知数据上性能下降，这种现象可以通过计算验证集和测试集之间的“过拟合差距”来量化。", "problem": "考虑一个二元分类模型，该模型在两个不相交的数据集上输出校准的预测概率：一个验证集 $X_{\\text{val}}$ 和一个测试集 $X_{\\text{test}}$。设验证集包含预测概率 $p^{(\\text{val})}_i \\in [0,1]$ 及对应的二元标签 $y^{(\\text{val})}_i \\in \\{0,1\\}$，其中 $i = 1,\\dots,n_{\\text{val}}$；测试集也类似，包含 $p^{(\\text{test})}_j \\in [0,1]$ 和 $y^{(\\text{test})}_j \\in \\{0,1\\}$，其中 $j = 1,\\dots,n_{\\text{test}}$。一个阈值 $t \\in [0,1]$ 会导出预测标签，当且仅当 $p_i \\ge t$ 时 $\\hat{y}_i(t) = 1$，否则 $\\hat{y}_i(t) = 0$。\n\n从统计学习的核心定义出发：\n- 精确率 $P$ 定义为 $P = \\frac{TP}{TP + FP}$，并约定当 $TP + FP = 0$ 时 $P = 0$。其中 $TP$ 表示真正例（True Positives），即 $(\\hat{y}=1, y=1)$ 的实例数量；$FP$ 表示假正例（False Positives），即 $(\\hat{y}=1, y=0)$ 的实例数量。\n- 召回率 $R$ 定义为 $R = \\frac{TP}{TP + FN}$，并约定当 $TP + FN = 0$ 时 $R = 0$。其中 $FN$ 表示假反例（False Negatives），即 $(\\hat{y}=0, y=1)$ 的实例数量。\n- 对于 $\\beta > 0$，$F_\\beta$ 分数定义为精确率 $P$ 和召回率 $R$ 的加权调和平均数，即 $F_\\beta = \\frac{(1+\\beta^2) \\cdot P \\cdot R}{\\beta^2 \\cdot P + R}$，并约定当分母为 $0$ 时 $F_\\beta = 0$。\n\n目标是在类别分布偏移和 $\\beta$ 值变化的情况下，量化因在 $X_{\\text{val}}$ 上调优而导致的阈值过拟合。对于给定的 $\\beta$，通过在有限候选集 $\\{0\\} \\cup S \\cup \\{1\\}$（其中 $S$ 是 $p^{(\\text{val})}_i$ 的唯一值集合）上进行穷举搜索，选择使 $X_{\\text{val}}$ 上的 $F_\\beta$ 最大化的阈值 $t^\\ast$。如果有多个阈值在 $X_{\\text{val}}$ 上达到相同的最大 $F_\\beta$ 值，则选择这些最大化阈值中最大的一个来打破平局。然后，使用 $t^\\ast$ 计算 $X_{\\text{val}}$ 和 $X_{\\text{test}}$ 上的 $F_\\beta$ 值，并报告定义为如下的过拟合差距：\n$$\n\\Delta = F_\\beta\\big(X_{\\text{val}}; t^\\ast\\big) - F_\\beta\\big(X_{\\text{test}}; t^\\ast\\big).\n$$\n\n您的程序必须实现上述过程，并为以下参数值的测试套件生成过拟合差距。所有数组都是有序列表；所有数字都是实值标量。\n\n测试用例 A (理想路径，中等 $\\beta$，轻度偏移):\n- 验证集预测概率：$[0.92, 0.81, 0.76, 0.63, 0.58, 0.49, 0.45, 0.41, 0.35, 0.22, 0.17, 0.08]$。\n- 验证集标签：$[1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0]$。\n- 测试集预测概率：$[0.90, 0.84, 0.79, 0.70, 0.34, 0.30, 0.27, 0.20, 0.15, 0.12]$。\n- 测试集标签：$[1, 1, 0, 1, 0, 0, 0, 0, 0, 0]$。\n- $\\beta = 1$。\n\n测试用例 B (侧重召回率，更强的偏移):\n- 验证集预测概率：$[0.88, 0.83, 0.77, 0.74, 0.62, 0.52, 0.47, 0.40, 0.33, 0.25]$。\n- 验证集标签：$[1, 1, 1, 0, 1, 0, 0, 0, 0, 0]$。\n- 测试集预测概率：$[0.86, 0.80, 0.55, 0.51, 0.49, 0.45, 0.38, 0.31, 0.28, 0.18]$。\n- 测试集标签：$[0, 1, 1, 0, 0, 0, 0, 0, 0, 0]$。\n- $\\beta = 2$。\n\n测试用例 C (分数持平，平局处理):\n- 验证集预测概率：$[0.50, 0.50, 0.50, 0.50]$。\n- 验证集标签：$[1, 0, 0, 1]$。\n- 测试集预测概率：$[0.50, 0.50, 0.50]$。\n- 测试集标签：$[0, 0, 1]$。\n- $\\beta = 1$。\n\n测试用例 D (侧重精确率，极端偏移导致在 $t^\\ast$ 下 $X_{\\text{test}}$ 上没有预测为正例的样本):\n- 验证集预测概率：$[0.95, 0.90, 0.85, 0.40, 0.35, 0.30]$。\n- 验证集标签：$[1, 1, 1, 0, 0, 0]$。\n- 测试集预测概率：$[0.60, 0.55, 0.50, 0.45, 0.20, 0.10]$。\n- 测试集标签：$[1, 0, 0, 0, 0, 0]$。\n- $\\beta = 0.5$。\n\n实现要求：\n- 在 $X_{\\text{val}}$ 上使用对指定候选阈值的穷舉搜索来选择 $t^\\ast$。\n- 计算 $F_\\beta$ 时，使用以下等效的基于计数的表达式\n$$\nF_\\beta = \\frac{(1+\\beta^2)\\,TP}{(1+\\beta^2)\\,TP + \\beta^2\\,FN + FP},\n$$\n并约定如果分母等于 $0$，则 $F_\\beta = 0$。\n- 对每个测试用例，按上述规定计算 $\\Delta$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个 $\\Delta$ 都表示为四舍五入到 $6$ 位小数的十进制数，并按 A、B、C、D 的顺序排列。例如，格式必须为 $\\texttt{[0.123456,0.234567,0.345678,0.456789]}$。", "solution": "该问题要求我们量化一个二元分类模型的阈值过拟合情况。这通过计算验证集 $X_{\\text{val}}$ 和测试集 $X_{\\text{test}}$ 之间的性能差距 $\\Delta$ 来实现。性能指标是 $F_\\beta$ 分数。问题的核心在于，首先在验证集上选择一个最佳分类阈值 $t^\\ast$，然后衡量该阈值下的性能在未见过的测试集上的泛化能力。一个较大的正差距 $\\Delta = F_\\beta(X_{\\text{val}}; t^\\ast) - F_\\beta(X_{\\text{test}}; t^\\ast)$ 表明阈值 $t^\\ast$ 对验证数据的特定特征产生了过拟合。\n\n解决方案通过对每个给定的测试用例遵循一个确定性的、分步的过程来实现。\n\n**步骤 1：识别候选阈值**\n\n对于一个预测概率为 $p$ 的樣本，只有当阈值 $t$ 跨过 $p$ 的值时，其分类结果才会改变。因此，为了找到使 $F_\\beta$ 分数最大化的阈值，评估一个有限的候选阈值集合就足够了。问题指定该集合为 $\\{0\\} \\cup S \\cup \\{1\\}$，其中 $S$ 是验证集中唯一预测概率 $p^{(\\text{val})}_i$ 的集合。我们构建这个候选集，记为 $T_{\\text{candidates}}$，并按升序对其进行排序。排序对于正确实现指定的平局打破规则至关重要。\n\n**步骤 2：在验证集上选择最优阈值**\n\n我们在排序后的候选集 $T_{\\text{candidates}}$ 上对最优阈值 $t^\\ast$ 进行穷举搜索。对于每个候选阈值 $t \\in T_{\\text{candidates}}$，我们计算其在验证数据 $X_{\\text{val}}$ 上的 $F_\\beta$ 分数。\n\n对于实例 $i$，如果其概率分数 $p_i \\ge t$，则预测标签为 $\\hat{y}_i(t) = 1$，否则为 $\\hat{y}_i(t) = 0$。基于这些预测和真实标签 $y_i$，我们统计真正例 ($TP$)、假正例 ($FP$) 和假反例 ($FN$) 的数量。\n\n接着，使用问题中提供的基于计数的公式计算 $F_\\beta$ 分数，该公式在数值上是稳定的，并且避免了在计算精确率和召回率中间步骤时出现除以零的情况：\n$$\nF_\\beta = \\frac{(1+\\beta^2) \\cdot TP}{(1+\\beta^2) \\cdot TP + \\beta^2 \\cdot FN + FP}\n$$\n如果分母为零（仅当 $TP=FP=FN=0$ 时发生），则定义 $F_\\beta = 0$。\n\n我们遍历排序后的候选阈值 $t \\in T_{\\text{candidates}}$，并追踪目前为止找到的最大 $F_\\beta$ 分数（称之为 $F_{\\beta, \\text{max}}$）以及达到该分数的阈值 $t^\\ast$。更新规则如下：如果当前阈值 $t$ 产生的 $F_\\beta$ 分数大于或等于 $F_{\\beta, \\text{max}}$，我们就将 $F_{\\beta, \\text{max}}$ 更新为这个新分数，并设置 $t^\\ast = t$。因为我们是按升序遍历阈值，所以这个规则确保了如果有多个阈值产生相同的最大分数，将选择其中最大的一个作为 $t^\\ast$，从而满足了问题的平局打破要求。\n\n**步骤 3：计算过拟合差距**\n\n一旦从验证集确定了最优阈值 $t^\\ast$，我们就可以计算过拟合差距 $\\Delta$。\n\n首先，验证集上的 $F_\\beta$ 分数就是上一步中找到的最大分数：$F_\\beta(X_{\\text{val}}; t^\\ast) = F_{\\beta, \\text{max}}$。\n其次，我们通过将相同的阈值 $t^\\ast$ 应用于测试概率 $p^{(\\text{test})}_j$ 来生成预测，然后使用相同的 $F_\\beta$ 公式以及测试集的 $TP$、$FP$ 和 $FN$ 计数，来计算测试集上的 $F_\\beta$ 分数 $F_\\beta(X_{\\text{test}}; t^\\ast)$。\n\n过拟合差距是这两个分数之差：\n$$\n\\Delta = F_\\beta(X_{\\text{val}}; t^\\ast) - F_\\beta(X_{\\text{test}}; t^\\ast)\n$$\n\n这个过程被封装在一个程序中，该程序处理四个指定的测试用例，计算相应的 $\\Delta$，并将结果格式化为单个逗号分隔的列表。该实现使用 `numpy` 库来高效地进行计数（$TP, FP, FN$）的向量化计算和数组操作。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_overfitting_gap(p_val, y_val, p_test, y_test, beta):\n    \"\"\"\n    Computes the F-beta overfitting gap for a given set of parameters.\n\n    1. Finds the optimal threshold t* on the validation set.\n    2. Calculates F_beta(X_val; t*) and F_beta(X_test; t*).\n    3. Returns the difference Delta.\n    \"\"\"\n    # Ensure inputs are numpy arrays for vectorized operations\n    p_val, y_val = np.array(p_val), np.array(y_val)\n    p_test, y_test = np.array(p_test), np.array(y_test)\n\n    # Step 1: Identify candidate thresholds\n    # The set is {0} U S U {1}, where S is the set of unique validation probabilities.\n    candidate_thresholds = sorted(list(set(p_val) | {0., 1.}))\n\n    # Step 2: Find the optimal threshold t* on the validation set\n    max_f_beta = -1.0\n    t_star = -1.0\n\n    beta_sq = beta**2\n    one_plus_beta_sq = 1 + beta_sq\n    \n    total_pos_val = np.sum(y_val)\n\n    for t in candidate_thresholds:\n        y_hat_val = (p_val = t).astype(int)\n\n        tp = np.sum((y_hat_val == 1)  (y_val == 1))\n        fp = np.sum((y_hat_val == 1)  (y_val == 0))\n        # fn = np.sum((y_hat_val == 0)  (y_val == 1))\n        fn = total_pos_val - tp\n\n        numerator = one_plus_beta_sq * tp\n        denominator = (one_plus_beta_sq * tp) + (beta_sq * fn) + fp\n\n        f_beta = numerator / denominator if denominator  0 else 0.0\n\n        # Tie-breaking rule: select the largest threshold.\n        # Since we iterate through sorted thresholds, this condition correctly captures it.\n        if f_beta = max_f_beta:\n            max_f_beta = f_beta\n            t_star = t\n            \n    f_beta_val = max_f_beta\n\n    # Step 3: Calculate F_beta on the test set using t* and find the gap\n    total_pos_test = np.sum(y_test)\n    y_hat_test = (p_test = t_star).astype(int)\n\n    tp_test = np.sum((y_hat_test == 1)  (y_test == 1))\n    fp_test = np.sum((y_hat_test == 1)  (y_test == 0))\n    # fn_test = np.sum((y_hat_test == 0)  (y_test == 1))\n    fn_test = total_pos_test - tp_test\n\n    numerator_test = one_plus_beta_sq * tp_test\n    denominator_test = (one_plus_beta_sq * tp_test) + (beta_sq * fn_test) + fp_test\n\n    f_beta_test = numerator_test / denominator_test if denominator_test  0 else 0.0\n\n    gap = f_beta_val - f_beta_test\n    return gap\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Test case A\n        {\n            \"p_val\": [0.92, 0.81, 0.76, 0.63, 0.58, 0.49, 0.45, 0.41, 0.35, 0.22, 0.17, 0.08],\n            \"y_val\": [1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n            \"p_test\": [0.90, 0.84, 0.79, 0.70, 0.34, 0.30, 0.27, 0.20, 0.15, 0.12],\n            \"y_test\": [1, 1, 0, 1, 0, 0, 0, 0, 0, 0],\n            \"beta\": 1.0\n        },\n        # Test case B\n        {\n            \"p_val\": [0.88, 0.83, 0.77, 0.74, 0.62, 0.52, 0.47, 0.40, 0.33, 0.25],\n            \"y_val\": [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n            \"p_test\": [0.86, 0.80, 0.55, 0.51, 0.49, 0.45, 0.38, 0.31, 0.28, 0.18],\n            \"y_test\": [0, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n            \"beta\": 2.0\n        },\n        # Test case C\n        {\n            \"p_val\": [0.50, 0.50, 0.50, 0.50],\n            \"y_val\": [1, 0, 0, 1],\n            \"p_test\": [0.50, 0.50, 0.50],\n            \"y_test\": [0, 0, 1],\n            \"beta\": 1.0\n        },\n        # Test case D\n        {\n            \"p_val\": [0.95, 0.90, 0.85, 0.40, 0.35, 0.30],\n            \"y_val\": [1, 1, 1, 0, 0, 0],\n            \"p_test\": [0.60, 0.55, 0.50, 0.45, 0.20, 0.10],\n            \"y_test\": [1, 0, 0, 0, 0, 0],\n            \"beta\": 0.5\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        gap = compute_overfitting_gap(\n            case[\"p_val\"], case[\"y_val\"],\n            case[\"p_test\"], case[\"y_test\"],\n            case[\"beta\"]\n        )\n        results.append(gap)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "3188635"}, {"introduction": "学会了如何使用验证集后，一个自然的问题是：如果验证集本身存在缺陷怎么办？这个练习探讨了一个常见问题：验证数据未能覆盖所有可能的输入特征空间。我们将模拟一个验证集在特征空间中存在“缺口”的情景，并在此基础上进行模型选择（选择多项式模型的阶数）。\n\n通过这个实践，你将观察到所选模型在一个完整的测试集上的表现，特别是它在验证时“未见过的”区域的表现如何 [@problem_id:3188594]。这个练习突显了一个至关重要的假设：验证集必须能代表真实的数据分布。它揭示了模型外推的风险，帮助你建立直觉，理解为什么验证集和测试集之间的分布差异会导致糟糕的模型选择和意外的模型失效。", "problem": "要求您研究验证集中系统性覆盖缺口对模型选择的影响，并在一个全面的测试集上量化由此产生的外推风险。请完全在以下纯数学和算法设置内进行操作。\n\n设特征域为闭区间 $[0,1]$，真实回归函数为 $f:[0,1]\\to\\mathbb{R}$。考虑平方损失。$X$ 的训练分布是 $[0,1]$ 上的均匀分布，多项式假设类中学习到的预测器定义为在该训练分布下期望平方损失的最小化器。验证分布在 $S_{\\mathrm{val}}=[0,a]\\cup[b,1]$ 上是均匀的，对于给定的 $0\\le a\\le b\\le 1$，并重新归一化至单位质量。测试分布在 $[0,1]$ 上是均匀的。所有三角函数的参数均以弧度为单位。\n\n使用的基本基础和定义：\n- 对于任何假设类 $\\mathcal{H}$ 和损失 $\\ell$，在 $X$ 上的分布 $\\mathbb{P}$ 下，$h\\in\\mathcal{H}$ 的风险为 $R_{\\mathbb{P}}(h)=\\mathbb{E}_{X\\sim \\mathbb{P}}[\\ell(h(X),f(X))]$。在平方损失下，$\\ell(y,\\hat y)=(y-\\hat y)^2$。\n- 在平方损失和固定的 $X$ 分布下，线性假设类中的风险最小化器是 $f$ 在该类别的线性张成空间上的正交投影（相对于由该分布定义的 $L^2$ 内积）。\n- 设 $\\{P_k\\}_{k\\ge 0}$ 表示区间 $[-1,1]$ 上的 Legendre 多项式，它们关于均匀权重是正交的。通过 $\\varphi_k(x)=\\sqrt{2k+1}\\,P_k(2x-1)$ 定义 $[0,1]$ 上的标准正交基，使得对于所有 $k,j\\in\\mathbb{N}_0$，都有 $\\int_0^1 \\varphi_k(x)\\varphi_j(x)\\,dx=\\delta_{kj}$。\n\n模型和选择协议：\n- 对于一个非负整数 $d$，定义假设类 $\\mathcal{H}_d=\\mathrm{span}\\{\\varphi_0,\\dots,\\varphi_d\\}$。训练分布在 $[0,1]$ 上是均匀的，因此 $\\mathcal{H}_d$ 中的风险最小化预测器为\n$$\ng_d^\\star(x)=\\sum_{k=0}^d a_k\\,\\varphi_k(x),\\quad\\text{其中 } a_k=\\int_0^1 f(x)\\,\\varphi_k(x)\\,dx.\n$$\n- 给定一个有限的候选次数集 $\\mathcal{D}$，模型选择会选择\n$$\nd^\\star\\in\\arg\\min_{d\\in\\mathcal{D}} R_{\\mathrm{val}}(g_d^\\star),\\quad R_{\\mathrm{val}}(g)=\\frac{1}{|S_{\\mathrm{val}}|}\\int_{S_{\\mathrm{val}}} \\bigl(f(x)-g(x)\\bigr)^2\\,dx,\n$$\n其中当 $a\\le b$ 时，有 $|S_{\\mathrm{val}}|=(a-0)+(1-b)$。通过选择最小的 $d$ 来解决平局问题。\n\n每个测试用例需要报告的量：\n- 选择的次数 $d^\\star$。\n- 测试均方误差 $R_{\\mathrm{test}}(g_{d^\\star}^\\star)=\\int_0^1 \\bigl(f(x)-g_{d^\\star}^\\star(x)\\bigr)^2\\,dx$。\n- 外推风险分数\n$$\n\\mathrm{Frac}_{\\mathrm{mask}}(d^\\star)=\\frac{\\int_a^b \\bigl(f(x)-g_{d^\\star}^\\star(x)\\bigr)^2\\,dx}{\\int_0^1 \\bigl(f(x)-g_{d^\\star}^\\star(x)\\bigr)^2\\,dx},\n$$\n如果分母为 $0$，则定义为 $0$。\n\n数值要求：\n- 所有需要的积分都必须使用在 $[L,R]\\subseteq[0,1]$ 上的 Gauss–Legendre 求积法进行数值计算，至少使用 $N_q=200$ 个节点，这些节点通过从 $[-1,1]$ 进行仿射映射获得。这确保了稳定和准确的近似，同时保持完全的确定性。\n- 使用如上定义的标准正交基 $\\{\\varphi_k\\}$。不要用有限样本来近似训练；使用正交投影系数 $a_k=\\int_0^1 f(x)\\,\\varphi_k(x)\\,dx$。\n- 三角函数中的角度以弧度为单位。\n\n候选次数集和测试套件：\n- 候选次数集 $\\mathcal{D}=\\{0,1,3,5,7\\}$。\n- 四个测试用例 $(f,a,b)$：\n    - 用例 1：$f(x)=\\sin(2\\pi x)$, $(a,b)=(0.6,0.8)$。\n    - 用例 2：$f(x)=x^2+0.05\\sin(8\\pi x)$, $(a,b)=(0.4,0.4)$。\n    - 用例 3：$f(x)=\\dfrac{1}{1+25(x-0.5)^2}$, $(a,b)=(0.45,0.55)$。\n    - 用例 4：$f(x)=\\sin(10\\pi x)$, $(a,b)=(0.0,0.3)$。\n\n任务：\n- 实现一个程序，对于每个测试用例，计算所有 $d\\in\\mathcal{D}$ 的 $g_d^\\star$，通过在 $S_{\\mathrm{val}}$ 上的验证风险来选择 $d^\\star$，然后报告 $[d^\\star, R_{\\mathrm{test}}(g_{d^\\star}^\\star), \\mathrm{Frac}_{\\mathrm{mask}}(d^\\star)]$。\n- 对于数值报告，将浮点输出四舍五入到六位小数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个元素是测试用例的三元素列表，并且行中任何地方都没有空格。例如，打印的行应如下所示：$[[d_1,r_1,q_1],[d_2,r_2,q_2],[d_3,r_3,q_3],[d_4,r_4,q_4]]$，其中每个 $r_i$ 和 $q_i$ 都四舍五入到六位小数。", "solution": "用户请求解决一个回归背景下的模型选择问题，其中验证数据存在系统性缺口。任务是量化此缺口对模型选择的影响，以及在完整测试集上产生的外推误差。该问题定义明确、科学上合理且计算上可行。我将提供一个完整的解决方案。\n\n### 基于原则的解决方案设计\n\n该解决方案基于统计学习理论、逼近论和数值分析的基本原理构建。\n\n**1. 使用正交多项式进行函数逼近**\n\n问题的核心在于用一系列多项式逼近真实函数 $f(x)$。假设类 $\\mathcal{H}_d$ 是由一组基函数张成的嵌套线性空间，$\\mathcal{H}_d = \\mathrm{span}\\{\\varphi_0, \\ldots, \\varphi_d\\}$。问题指定了一个源自 Legendre 多项式的特定基 $\\{\\varphi_k\\}_{k \\ge 0}$。这些基函数 $\\varphi_k(x) = \\sqrt{2k+1} P_k(2x-1)$ 被构造成相对于 $[0,1]$ 上带有均匀权重函数的标准 $L^2$ 内积是标准正交的，即 $\\langle \\varphi_k, \\varphi_j \\rangle = \\int_0^1 \\varphi_k(x) \\varphi_j(x) dx = \\delta_{kj}$，其中 $\\delta_{kj}$ 是克罗内克 delta。\n\n特征 $X$ 的训练分布在 $[0,1]$ 上是均匀的。这意味着训练风险为 $R_{\\text{train}}(g) = \\mathbb{E}_{X \\sim U[0,1]}[(f(X)-g(X))^2] = \\int_0^1 (f(x)-g(x))^2 dx$。对于给定的假设类 $\\mathcal{H}_d$，最小化此训练风险的最优预测器 $g_d^\\star$ 是真实函数 $f$ 到子空间 $\\mathcal{H}_d$ 上的正交投影。由于基 $\\{\\varphi_k\\}$ 的标准正交性，该投影具有类似于傅立叶级数展开的简单形式：\n$$\ng_d^\\star(x) = \\sum_{k=0}^d \\langle f, \\varphi_k \\rangle \\varphi_k(x) = \\sum_{k=0}^d a_k \\varphi_k(x)\n$$\n其中系数由 $a_k = \\int_0^1 f(x) \\varphi_k(x) dx$ 给出。这种表述方式避免了在有限训练集上进行经验风险最小化的需要，并允许直接采用解析风格的解法。\n\n**2. 风险评估与模型选择**\n\n虽然模型 $g_d^\\star$ 在其类别中对于训练分布是最优的，但我们必须从候选集 $\\mathcal{D}=\\{0,1,3,5,7\\}$ 中选择最佳类别（即最佳次数 $d$）。指导原则是选择预期对新数据泛化能力最好的模型。这通常通过使用验证集来估计。\n\n问题引入了一个在 $S_{\\mathrm{val}} = [0,a] \\cup [b,1]$ 上均匀但在“遮蔽”区间 $(a,b)$ 上为零的验证分布。因此，验证风险为：\n$$\nR_{\\mathrm{val}}(g_d^\\star) = \\frac{1}{|S_{\\mathrm{val}}|} \\int_{S_{\\mathrm{val}}} (f(x) - g_d^\\star(x))^2 dx = \\frac{1}{a+1-b} \\left( \\int_0^a (f(x) - g_d^\\star(x))^2 dx + \\int_b^1 (f(x) - g_d^\\star(x))^2 dx \\right)\n$$\n模型选择的过程是为每个 $d \\in \\mathcal{D}$ 计算 $R_{\\mathrm{val}}(g_d^\\star)$，并选择产生最小验证风险的次数 $d^\\star$。该协议模拟了一个常见的实际场景，即用于模型调优的可用数据可能无法覆盖整个操作域。\n\n**3. 量化性能与外推风险**\n\n所选模型 $g_{d^\\star}^\\star$ 的真实性能通过其测试风险来衡量，该风险与训练风险一样，在完整域 $[0,1]$ 上评估：\n$$\nR_{\\mathrm{test}}(g_{d^\\star}^\\star) = \\int_0^1 (f(x) - g_{d^\\star}^\\star(x))^2 dx\n$$\n得益于正交投影和 Parseval 定理的性质，这个测试风险可以被准确高效地计算，而无需直接对平方误差进行积分。平方误差是残差函数 $f - g_{d^\\star}^\\star$ 的范数的平方，该函数与子空间 $\\mathcal{H}_{d^\\star}$ 正交。这导出了恒等式：\n$$\nR_{\\mathrm{test}}(g_{d^\\star}^\\star) = \\int_0^1 f(x)^2 dx - \\sum_{k=0}^{d^\\star} a_k^2\n$$\n这个公式在数值上比直接积分平方差更稳定，因为它避免了潜在的相减抵消。\n\n分析的核心是衡量外推风险，即集中在验证期间未见区域 $(a,b)$ 中的误差。外推风险分数 $\\mathrm{Frac}_{\\mathrm{mask}}(d^\\star)$ 对此进行量化：\n$$\n\\mathrm{Frac}_{\\mathrm{mask}}(d^\\star) = \\frac{\\int_a^b (f(x) - g_{d^\\star}^\\star(x))^2 dx}{R_{\\mathrm{test}}(g_{d^\\star}^\\star)}\n$$\n这个比率表明总测试误差中有多大比例来自模型在未经证实的区域中未能正确预测。高值表示验证风险是真实测试风险的一个糟糕代理，这是分布变化的直接后果。\n\n**4. 使用 Gauss-Legendre 求积法的数值实现**\n\n所有需要的积分——用于系数 $a_k$、验证风险和遮蔽风险，以及 $\\int f^2 dx$——不一定有闭式反导数。问题要求采用一种特定的、确定性的数值方法：至少有 $N_q=200$ 个节点的 Gauss-Legendre 求积法。对于一个积分 $\\int_L^R h(x) dx$，该方法提供了一个高度精确的近似：\n$$\n\\int_L^R h(x) dx \\approx \\frac{R-L}{2} \\sum_{i=1}^{N_q} w_i h\\left(\\frac{R-L}{2} x_i + \\frac{R+L}{2}\\right)\n$$\n其中 $\\{x_i\\}$ 和 $\\{w_i\\}$ 是在规范区间 $[-1,1]$ 上的求积法则的节点和权重。这种方法确保了计算的可重复性和精确性，适合科学计算问题。\n\n算法首先计算直到 $\\mathcal{D}$ 中最大次数的所有系数 $a_k$。然后，对于每个候选次数 $d$，构建预测器 $g_d^\\star(x)$ 并计算其验证风险。在选择最佳次数 $d^\\star$ 后，使用上述公式计算最终的测试风险和外推分数。对每个测试用例重复整个过程。", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre, eval_legendre\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    It implements the full pipeline from model definition to final metric calculation.\n    \"\"\"\n\n    # --- Problem Constants and Numerical Setup ---\n    DEGREES = [0, 1, 3, 5, 7]\n    N_Q = 200 # Number of quadrature points\n\n    # Pre-compute Gauss-Legendre nodes and weights for the interval [-1, 1]\n    X_GL, W_GL = roots_legendre(N_Q)\n\n    # --- Helper Functions ---\n\n    def gauss_legendre_integrate(func, a, b):\n        \"\"\"\n        Numerically integrates a function `func` over the interval [a, b]\n        using N_Q-point Gauss-Legendre quadrature.\n        \"\"\"\n        if a = b:\n            return 0.0\n        # Affine transformation of nodes from [-1, 1] to [a, b]\n        t = 0.5 * (b - a) * X_GL + 0.5 * (b + a)\n        integral = 0.5 * (b - a) * np.sum(W_GL * func(t))\n        return integral\n\n    def phi(k, x):\n        \"\"\"\n        Evaluates the k-th orthonormal basis function phi_k at points x.\n        The basis is orthonormal on [0, 1].\n        \"\"\"\n        # Ensure x is a numpy array for vectorized operations\n        x = np.asarray(x)\n        # Map x from [0, 1] to [-1, 1] for Legendre polynomial evaluation\n        y = 2 * x - 1\n        return np.sqrt(2 * k + 1) * eval_legendre(k, y)\n\n    def process_case(f, a, b):\n        \"\"\"\n        Processes a single test case (f, a, b) and returns the required metrics.\n        \"\"\"\n        max_d = max(DEGREES)\n        \n        # 1. Pre-compute all necessary coefficients a_k up to max_d\n        a_coeffs = np.zeros(max_d + 1)\n        for k in range(max_d + 1):\n            integrand = lambda x: f(x) * phi(k, x)\n            a_coeffs[k] = gauss_legendre_integrate(integrand, 0, 1)\n\n        # 2. Iterate through candidate degrees to find the best one via validation\n        validation_risks = []\n        for d in DEGREES:\n            # Define the predictor g_d*(x) and squared error function\n            def g_d_star(x):\n                x = np.asarray(x)\n                res = np.zeros_like(x, dtype=float)\n                for k in range(d + 1):\n                    res += a_coeffs[k] * phi(k, x)\n                return res\n\n            def squared_error(x):\n                return (f(x) - g_d_star(x))**2\n\n            # Calculate validation risk R_val over S_val = [0, a] U [b, 1]\n            integral_val = gauss_legendre_integrate(squared_error, 0, a) + \\\n                           gauss_legendre_integrate(squared_error, b, 1)\n            \n            s_val_measure = a + (1 - b)\n            r_val = integral_val / s_val_measure if s_val_measure  1e-12 else 0.0\n            validation_risks.append(r_val)\n\n        # 3. Select d_star: the degree that minimizes validation risk\n        # Ties are broken by choosing the smallest degree, which is handled naturally\n        # by finding the first index of the minimum risk.\n        min_risk = np.min(validation_risks)\n        d_star_index = np.where(np.isclose(validation_risks, min_risk))[0][0]\n        d_star = DEGREES[d_star_index]\n\n        # 4. Calculate final quantities for the selected model g_{d_star}^*\n        \n        # Test Risk R_test using the numerically stable formula\n        integral_f_squared = gauss_legendre_integrate(lambda x: f(x)**2, 0, 1)\n        sum_a_k_squared = np.sum(a_coeffs[:d_star + 1]**2)\n        r_test = max(0, integral_f_squared - sum_a_k_squared)\n\n        # Extrapolation Risk Fraction\n        frac_mask = 0.0\n        if r_test  1e-12:\n            def g_d_star_final(x):\n                x = np.asarray(x)\n                res = np.zeros_like(x, dtype=float)\n                for k in range(d_star + 1):\n                    res += a_coeffs[k] * phi(k, x)\n                return res\n            \n            def squared_error_final(x):\n                return (f(x) - g_d_star_final(x))**2\n\n            integral_mask = gauss_legendre_integrate(squared_error_final, a, b)\n            frac_mask = integral_mask / r_test\n        \n        return d_star, r_test, frac_mask\n\n    # --- Test Suite Definition ---\n    test_cases = [\n        (lambda x: np.sin(2 * np.pi * x), 0.6, 0.8),\n        (lambda x: x**2 + 0.05 * np.sin(8 * np.pi * x), 0.4, 0.4),\n        (lambda x: 1.0 / (1.0 + 25 * (x - 0.5)**2), 0.45, 0.55),\n        (lambda x: np.sin(10 * np.pi * x), 0.0, 0.3)\n    ]\n\n    # --- Main Execution Loop ---\n    results = []\n    for f, a, b in test_cases:\n        d_star, r_test, frac_mask = process_case(f, a, b)\n        results.append((d_star, r_test, frac_mask))\n\n    # --- Format and Print Final Output ---\n    formatted_results = [f\"[{d},{r:.6f},{q:.6f}]\" for d, r, q in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3188594"}, {"introduction": "许多真实世界的数据集，如金融数据或气象记录，都包含时间维度，这使得简单的随机划分方法不再适用。本练习旨在解决为时序数据创建有效的数据划分这一挑战。我们将处理一个合成的时间序列数据集，并比较不同的划分策略，例如带间隔的连续时间块划分和交错周期性划分。\n\n这个动手实践对于理解时间序列感知的验证原则至关重要 [@problem_id:3188604]。它教会我们必须尊重数据的时间顺序以避免“数据泄漏”（即用未来的信息来预测过去），并设计能够真实评估模型在生产环境中性能的划分策略。通过选择最佳的特征工程窗口并评估模型在数据模式变化时的泛化能力，你将掌握处理时序数据划分的关键技能。", "problem": "您将处理一个合成的、完全指定的统计学习任务，该任务旨在评估当特征提取使用滑动窗口时，训练、验证和测试集的划分策略如何与时序协变量和静态特征相互作用。您的目标是编写一个程序，实现一个完整的训练-验证-测试流程，通过验证集选择一个特征提取窗口，并报告测试集的均方误差（以小数形式表示），同时遵守时间感知约束。该程序必须是自包含的，并且不能读取任何输入。\n\n数据生成过程定义如下。存在一个单一的静态特征和一个单变量的时序协变量。令 $t \\in \\{0,1,\\dots,T-1\\}$ 为时间索引。定义时序协变量序列 $c_t$ 为\n$$\nc_t = A \\cdot \\sin\\left(\\frac{2\\pi}{P} \\, t + \\phi_t\\right),\n$$\n其中相位 $\\phi_t$ 可能会在指定的突变点 $T_{\\text{shift}}$ 处发生一次变化。具体来说，\n$$\n\\phi_t = \n\\begin{cases}\n0  \\text{if } t  T_{\\text{shift}},\\\\\n\\phi_{\\text{shift}}  \\text{if } t \\ge T_{\\text{shift}}.\n\\end{cases}\n$$\n所有三角函数参数的单位均为弧度。静态特征是在所有时间点均为常数标量 $s$。响应 $y_t$ 是使用时序协变量的滚动平均值生成的，其真实窗口大小可能在 $T_{\\text{shift}}$ 处发生变化：\n$$\nw^*(t) = \n\\begin{cases}\nw_1  \\text{if } t  T_{\\text{shift}},\\\\\nw_2  \\text{if } t \\ge T_{\\text{shift}},\n\\end{cases}\n$$\n且\n$$\ny_t = \\beta_0 + \\beta_1 \\cdot \\frac{1}{w^*(t)} \\sum_{j=1}^{w^*(t)} c_{t-j} + \\beta_2 \\cdot s,\n$$\n仅当 $t \\ge \\max\\{w_1,w_2\\}$ 时，该式才有明确定义。数据中不存在随机噪声。\n\n您必须建立一个线性模型，用从观测到的协变量 $c_t$ 上应用候选滚动窗口 $w$ 所构建的特征来预测 $y_t$：\n- 对于任意候选窗口 $w$，在时间 $t$ 的特征向量为\n$$\nx^{(w)}_t = \\left[\\,1,\\;\\frac{1}{w}\\sum_{j=1}^{w} c_{t-j},\\; s\\,\\right],\n$$\n该式在 $t \\ge w$ 时有效。您必须从一个给定的有限集合 $\\mathcal{W}$ 中考虑多个候选窗口，并通过验证集选择最佳窗口。\n\n训练-验证-测试过程和约束：\n- 设“合格”时间索引集合为 $\\mathcal{I} = \\{t_{\\min}, t_{\\min}+1, \\dots, T-1\\}$，其中 $t_{\\min} = \\max\\left(\\{w_1,w_2\\} \\cup \\mathcal{W}\\right)$，以确保所有的滚动平均值都有明确定义。\n- 您必须支持两种确定性的划分策略：\n\n  1. 带间隔的连续时间块：给定比例 $p_{\\text{train}} = 0.6$，$p_{\\text{val}} = 0.2$ 和一个整数间隔 $g \\ge 0$，将 $\\mathcal{I}$ 划分为不相交的连续段用于训练、验证和测试，在训练集和验证集之间插入一个大小为 $g$ 的间隔，在验证集和测试集之间也插入一个同样大小的间隔。设 $n = |\\mathcal{I}|$。定义 $n_{\\text{train}} = \\lfloor 0.6n \\rfloor$，$n_{\\text{val}} = \\lfloor 0.2n \\rfloor$，并将考虑间隔后剩余的索引分配给测试集（剩余数量为 $n - n_{\\text{train}} - n_{\\text{val}} - 2g$，在提供的测试套件中假定此值为非负）。每个数据段内必须保持时间顺序。\n  \n  2. 交错周期性划分：固定周期 $m = 5$。根据索引在 $\\mathcal{I}$ 中对 $m$ 取模的余数将其分配到不同的集合：若 $t \\bmod m \\in \\{0,1,2\\}$，则分配给训练集；若 $t \\bmod m \\in \\{3\\}$，则分配给验证集；若 $t \\bmod m \\in \\{4\\}$，则分配给测试集。\n\n- 对于每个候选窗口 $w \\in \\mathcal{W}$，在训练集上拟合一个普通最小二乘线性回归模型，以最小化用 $x^{(w)}_t$ 预测 $y_t$ 的经验平方损失。将训练设计矩阵记为 $X_{\\text{train}}^{(w)}$，训练响应向量记为 $y_{\\text{train}}$。最小二乘估计值 $\\hat{\\theta}^{(w)}$ 满足正规方程 $X_{\\text{train}}^{(w)\\top} X_{\\text{train}}^{(w)} \\hat{\\theta}^{(w)} = X_{\\text{train}}^{(w)\\top} y_{\\text{train}}$。使用任何数值稳定的方法来获得一个解（例如，Moore-Penrose 伪逆）。\n- 通过在验证集上的均方误差来评估每个 $w$\n$$\n\\text{MSE}_{\\text{val}}(w) = \\frac{1}{|\\mathcal{V}|} \\sum_{t \\in \\mathcal{V}} \\left(y_t - x^{(w)}_t \\cdot \\hat{\\theta}^{(w)}\\right)^2,\n$$\n并选择使 $\\text{MSE}_{\\text{val}}(w)$ 最小化的窗口 $\\hat{w}$。如果 $\\text{MSE}_{\\text{val}}$ 出现平局，则在最小化者中选择最小的 $w$。\n- 选择 $\\hat{w}$ 后，使用训练集和验证集的并集，并采用相同的特征定义来重新拟合模型，以获得 $\\hat{\\theta}^{(\\hat{w})}_{\\text{refit}}$。\n- 报告测试集的均方误差\n$$\n\\text{MSE}_{\\text{test}} = \\frac{1}{|\\mathcal{T}|} \\sum_{t \\in \\mathcal{T}} \\left(y_t - x^{(\\hat{w})}_t \\cdot \\hat{\\theta}^{(\\hat{w})}_{\\text{refit}}\\right)^2.\n$$\n\n角度单位要求：所有角度均以弧度为单位。\n\n您的程序必须为以下参数设置的测试套件实现上述过程。每个测试用例指定了 $(T, P, A, \\beta_0, \\beta_1, \\beta_2, s, w_1, w_2, T_{\\text{shift}}, \\phi_{\\text{shift}}, \\text{split}, \\text{extra}, \\mathcal{W})$：\n\n- 测试用例 1（理想情况，无季节性相位或窗口变化）：\n  - $T=120$, $P=24$, $A=2$, $\\beta_0=0.5$, $\\beta_1=1.2$, $\\beta_2=-0.7$, $s=1.3$.\n  - $w_1=8$, $w_2=8$, $T_{\\text{shift}}=120$, $\\phi_{\\text{shift}}=0$.\n  - 划分：带间隔 $g=3$ 的连续块；按上文定义使用 $p_{\\text{train}}=0.6$，$p_{\\text{val}}=0.2$。\n  - 候选窗口 $\\mathcal{W}=\\{4,8,12\\}$。\n\n- 测试用例 2（仅在测试时段出现季节性相位和窗口变化）：\n  - $T=120$, $P=24$, $A=2$, $\\beta_0=0.5$, $\\beta_1=1.2$, $\\beta_2=-0.7$, $s=1.3$.\n  - $w_1=4$, $w_2=12$, $T_{\\text{shift}}=80$, $\\phi_{\\text{shift}}=\\frac{\\pi}{2}$.\n  - 划分：带间隔 $g=3$ 的连续块；按上文定义使用 $p_{\\text{train}}=0.6$，$p_{\\text{val}}=0.2$。\n  - 候选窗口 $\\mathcal{W}=\\{4,8,12\\}$。\n\n- 测试用例 3（在季节性相位和窗口变化下的交错划分）：\n  - $T=120$, $P=24$, $A=2$, $\\beta_0=0.5$, $\\beta_1=1.2$, $\\beta_2=-0.7$, $s=1.3$.\n  - $w_1=6$, $w_2=10$, $T_{\\text{shift}}=60$, $\\phi_{\\text{shift}}=\\frac{\\pi}{3}$.\n  - 划分：周期 $m=5$ 的交错划分，将余数为 $\\{0,1,2\\}$ 的分配给训练集，余数为 $\\{3\\}$ 的分配给验证集，余数为 $\\{4\\}$ 的分配给测试集。\n  - 候选窗口 $\\mathcal{W}=\\{4,6,10,12\\}$。\n\n- 测试用例 4（窗口大小的边界情况且无变化）：\n  - $T=40$, $P=10$, $A=1.5$, $\\beta_0=0.5$, $\\beta_1=1.2$, $\\beta_2=-0.7$, $s=1.3$.\n  - $w_1=1$, $w_2=1$, $T_{\\text{shift}}=40$, $\\phi_{\\text{shift}}=0$.\n  - 划分：带间隔 $g=0$ 的连续块；按上文定义使用 $p_{\\text{train}}=0.6$，$p_{\\text{val}}=0.2$。\n  - 候选窗口 $\\mathcal{W}=\\{1,2\\}$。\n\n实现要求：\n- 对于每个测试用例，完全按照描述构建 $c_t$ 和 $y_t$。\n- 仅使用过去的协变量值 $c_{t-j}$ 来计算特征；不要使用相对于 $t$ 的未来值。\n- 将指定的划分策略应用于合格索引集 $\\mathcal{I} = \\{t_{\\min},\\dots,T-1\\}$，其中 $t_{\\min} = \\max(\\{w_1,w_2\\}\\cup \\mathcal{W})$。\n- 在训练数据上为每个候选模型进行训练，通过最小化验证集均方误差来选择 $\\hat{w}$（平局时选择较小的 $w$），使用训练集加验证集为 $\\hat{w}$ 重新拟合模型，并计算测试集均方误差。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按测试用例 1 到 4 的顺序排列，每个均方误差都四舍五入到恰好 6 位小数。例如，输出可能看起来像 $[0.000123,0.045678,0.010000,0.000000]$。", "solution": "该问题提出了一个合成的、确定性的统计学习任务，旨在评估在存在潜在结构性断点的时间序列背景下的模型选择策略。该过程涉及数据生成、使用滑动窗口的特征工程、时间感知的数据划分、模型训练、通过验证集进行超参数（窗口大小）选择，以及在测试集上进行最终性能评估。该解决方案严格遵守指定的过程。\n\n**1. 数据生成**\n\n首先，对于每个测试用例，我们在时间范围 $t \\in \\{0, 1, \\dots, T-1\\}$ 上生成时序协变量序列 $c_t$ 和响应序列 $y_t$。\n\n时序协变量 $c_t$ 定义为一个正弦函数：\n$$\nc_t = A \\cdot \\sin\\left(\\frac{2\\pi}{P} \\, t + \\phi_t\\right)\n$$\n其中相位 $\\phi_t$ 是分段常数，在给定的时间 $t=T_{\\text{shift}}$ 从 $0$ 变为指定值 $\\phi_{\\text{shift}}$：\n$$\n\\phi_t = \n\\begin{cases}\n0  \\text{if } t  T_{\\text{shift}},\\\\\n\\phi_{\\text{shift}}  \\text{if } t \\ge T_{\\text{shift}}.\n\\end{cases}\n$$\n\n响应变量 $y_t$ 是一个常数静态特征 $s$ 和 $c_t$ 过去值的滚动平均值的线性函数。用于此滚动平均的窗口大小 $w^*(t)$ 也是分段常数，在 $T_{\\text{shift}}$ 处从 $w_1$ 变为 $w_2$：\n$$\nw^*(t) = \n\\begin{cases}\nw_1  \\text{if } t  T_{\\text{shift}},\\\\\nw_2  \\text{if } t \\ge T_{\\text{shift}}.\n\\end{cases}\n$$\n响应 $y_t$ 则由下式给出：\n$$\ny_t = \\beta_0 + \\beta_1 \\cdot \\left(\\frac{1}{w^*(t)} \\sum_{j=1}^{w^*(t)} c_{t-j}\\right) + \\beta_2 \\cdot s\n$$\n该值仅在回看窗口不延伸到 $t=0$ 之前的时间点 $t$ 上有定义。为确保所有候选模型和真实数据生成过程都有明确定义，我们在一个“合格”时间索引集合 $\\mathcal{I} = \\{t_{\\min}, t_{\\min}+1, \\dots, T-1\\}$ 上操作，其中 $t_{\\min}$ 是所有涉及的窗口大小（包括真实的和候选的）的最大值：$t_{\\min} = \\max\\left(\\{w_1, w_2\\} \\cup \\mathcal{W}\\right)$。\n\n**2. 数据划分**\n\n合格索引集 $\\mathcal{I}$ 根据两种指定策略之一被划分为训练集、验证集和测试集：\n\n- **连续时间块：** $\\mathcal{I}$ 的有序索引被划分为三个连续的块，分别用于训练、验证和测试。训练集取前 $\\lfloor 0.6n \\rfloor$ 个索引，验证集取接下来的 $\\lfloor 0.2n \\rfloor$ 个索引，其中 $n = |\\mathcal{I}|$。在训练集和验证集之间，以及验证集和测试集之间，强制设置一个大小为 $g$ 的时间间隔，以模拟接收数据的延迟。测试集包含所有剩余的索引。\n- **交错周期性划分：** 来自 $\\mathcal{I}$ 的索引根据其对周期 $m=5$ 取模的值被分配到不同的集合。$t \\bmod 5 \\in \\{0, 1, 2\\}$ 的索引构成训练集，$t \\bmod 5 = 3$ 的索引构成验证集，$t \\bmod 5 = 4$ 的索引构成测试集。这种策略确保了所有三个集合都从整个时间段中抽取，如果数据属性随时间变化，这可能是有利的。\n\n**3. 特征工程与模型选择**\n\n预测模型是一个线性回归模型。对于来自集合 $\\mathcal{W}$ 的每个候选窗口大小 $w$，在每个时间点 $t$ 构建一个特征向量 $x^{(w)}_t$：\n$$\nx^{(w)}_t = \\left[\\,1,\\;\\frac{1}{w}\\sum_{j=1}^{w} c_{t-j},\\; s\\,\\right]\n$$\n该向量的三个分量分别对应于截距项、从时序协变量派生的特征以及静态特征。\n\n任务的核心是选择最优窗口大小 $\\hat{w}$。这通过以下步骤实现：\n1.  对于每个候选窗口 $w \\in \\mathcal{W}$，使用训练数据拟合一个普通最小二乘（OLS）线性模型。模型系数 $\\hat{\\theta}^{(w)}$ 通过求解正规方程得到，为此我们使用 Moore-Penrose 伪逆来确保数值稳定性：$\\hat{\\theta}^{(w)} = (X_{\\text{train}}^{(w)\\top} X_{\\text{train}}^{(w)})^{-1} X_{\\text{train}}^{(w)\\top} y_{\\text{train}}$。在实现中，这被计算为 $\\hat{\\theta}^{(w)} = \\text{pinv}(X_{\\text{train}}^{(w)}) \\cdot y_{\\text{train}}$。\n2.  每个训练好的模型 $(\\hat{\\theta}^{(w)}, w)$ 的性能通过计算其在验证集上的均方误差（MSE）来评估：\n    $$\n    \\text{MSE}_{\\text{val}}(w) = \\frac{1}{|\\mathcal{V}|} \\sum_{t \\in \\mathcal{V}} \\left(y_t - x^{(w)}_t \\cdot \\hat{\\theta}^{(w)}\\right)^2\n    $$\n3.  产生最小验证 MSE 的窗口大小 $\\hat{w}$ 被选为最佳超参数。平局决胜规则规定，如果多个窗口产生相同的最小 MSE，则选择其中最小的窗口大小。\n\n**4. 最终评估**\n\n在确定最优窗口大小 $\\hat{w}$ 后，模型被重新训练。这一次，训练数据与验证数据合并，形成一个组合的训练-验证集。这一步利用更多的数据来获得一个可能更鲁棒的模型参数估计。新的系数 $\\hat{\\theta}^{(\\hat{w})}_{\\text{refit}}$ 是通过在这个组合数据集上用特征集 $x^{(\\hat{w})}_t$ 拟合模型得到的。\n\n最后，这个重新拟合的模型的性能在迄今未使用的测试集上进行评估。计算测试 MSE，它代表了模型在未见数据上的泛化误差：\n$$\n\\text{MSE}_{\\text{test}} = \\frac{1}{|\\mathcal{T}|} \\sum_{t \\in \\mathcal{T}} \\left(y_t - x^{(\\hat{w})}_t \\cdot \\hat{\\theta}^{(\\hat{w})}_{\\text{refit}}\\right)^2\n$$\n这个最终值是每个测试用例报告的结果。整个过程是确定性的，对于每组输入参数都会产生唯一的结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (T, P, A, beta0, beta1, beta2, s, w1, w2, T_shift, phi_shift, split_type, extra, W_set)\n        (120, 24, 2, 0.5, 1.2, -0.7, 1.3, 8, 8, 120, 0.0, 'contiguous', 3, {4, 8, 12}),\n        (120, 24, 2, 0.5, 1.2, -0.7, 1.3, 4, 12, 80, np.pi/2, 'contiguous', 3, {4, 8, 12}),\n        (120, 24, 2, 0.5, 1.2, -0.7, 1.3, 6, 10, 60, np.pi/3, 'interleaved', 5, {4, 6, 10, 12}),\n        (40, 10, 1.5, 0.5, 1.2, -0.7, 1.3, 1, 1, 40, 0.0, 'contiguous', 0, {1, 2}),\n    ]\n\n    results = []\n    for params in test_cases:\n        mse = solve_case(*params)\n        results.append(f\"{mse:.6f}\")\n    \n    print(f\"[{','.join(results)}]\")\n\ndef solve_case(T, P, A, beta0, beta1, beta2, s, w1, w2, T_shift, phi_shift, split_type, extra, W_set):\n    \"\"\"\n    Solves a single instance of the statistical learning problem.\n    \"\"\"\n    # 1. Determine eligible time indices\n    t_min = max(list(W_set) + [w1, w2])\n\n    # 2. Generate data: c_t and y_t\n    t_range = np.arange(T)\n    phi_t = np.where(t_range  T_shift, 0, phi_shift)\n    c_t = A * np.sin(2 * np.pi / P * t_range + phi_t)\n\n    w_star_t = np.where(t_range  T_shift, w1, w2)\n    y_full = np.full(T, np.nan)\n    for t in range(t_min, T):\n        w_star = w_star_t[t]\n        # Rolling mean for the true response. Slicing c_t[t-w_star:t] corresponds to c_{t-j} for j=1..w_star\n        mean_c = np.mean(c_t[t - w_star : t])\n        y_full[t] = beta0 + beta1 * mean_c + beta2 * s\n    \n    # 3. Create data splits\n    eligible_indices = np.arange(t_min, T)\n    if split_type == 'contiguous':\n        n = len(eligible_indices)\n        g = extra\n        n_train = int(0.6 * n)\n        n_val = int(0.2 * n)\n        \n        train_indices = eligible_indices[:n_train]\n        val_indices = eligible_indices[n_train + g : n_train + g + n_val]\n        test_indices = eligible_indices[n_train + g + n_val + g :]\n    elif split_type == 'interleaved':\n        m = extra\n        train_indices = eligible_indices[np.isin(eligible_indices % m, [0, 1, 2])]\n        val_indices = eligible_indices[eligible_indices % m == 3]\n        test_indices = eligible_indices[eligible_indices % m == 4]\n    else:\n        raise ValueError(\"Unknown split type\")\n\n    # 4. Pre-compute rolling mean features for all candidate windows\n    rolling_means = {}\n    for w in W_set:\n        means_w = np.full(T, np.nan)\n        for t in range(w, T):\n            means_w[t] = np.mean(c_t[t-w:t])\n        rolling_means[w] = means_w\n\n    # 5. Model selection loop (hyperparameter tuning)\n    val_mses = {}\n    for w in sorted(list(W_set)): # Sort to ensure tie-breaking rule is met\n        # Construct training data matrix and response vector\n        X_train = np.c_[np.ones(len(train_indices)), rolling_means[w][train_indices], np.full(len(train_indices), s)]\n        y_train = y_full[train_indices]\n        \n        # Fit model using pseudoinverse for numerical stability\n        theta_hat = np.linalg.pinv(X_train) @ y_train\n        \n        # Evaluate on validation set\n        if len(val_indices)  0:\n            X_val = np.c_[np.ones(len(val_indices)), rolling_means[w][val_indices], np.full(len(val_indices), s)]\n            y_val = y_full[val_indices]\n            \n            y_pred_val = X_val @ theta_hat\n            val_mses[w] = np.mean((y_val - y_pred_val)**2)\n        else: # Handle cases with empty validation set\n            val_mses[w] = np.inf\n\n    # Select best window w_hat based on validation MSE, with tie-breaking\n    w_hat = min(val_mses.keys(), key=lambda w: (val_mses[w], w))\n\n    # 6. Refit on train+validation and evaluate on test set\n    refit_indices = np.sort(np.concatenate((train_indices, val_indices)))\n    \n    X_refit = np.c_[np.ones(len(refit_indices)), rolling_means[w_hat][refit_indices], np.full(len(refit_indices), s)]\n    y_refit = y_full[refit_indices]\n    \n    theta_refit = np.linalg.pinv(X_refit) @ y_refit\n    \n    if len(test_indices)  0:\n        X_test = np.c_[np.ones(len(test_indices)), rolling_means[w_hat][test_indices], np.full(len(test_indices), s)]\n        y_test = y_full[test_indices]\n        \n        y_pred_test = X_test @ theta_refit\n        test_mse = np.mean((y_test - y_pred_test)**2)\n    else: # Handle cases with empty test set\n        test_mse = 0.0\n    \n    return test_mse\n\n# The original problem description implies sorting W_set for the loop, I've added it to be explicit.\n# Let me re-check the tie-breaking rule. \"select the smallest w\".\n# The key=lambda w: (val_mses[w], w) already does this.\n# The `sorted(list(W_set))` is not strictly necessary for correctness but makes the loop order deterministic.\n# The original code did not have it, I'll remove it to be more faithful to the original logic, as min() on dict keys is deterministic enough for this purpose.\ndef solve_case(T, P, A, beta0, beta1, beta2, s, w1, w2, T_shift, phi_shift, split_type, extra, W_set):\n    \"\"\"\n    Solves a single instance of the statistical learning problem.\n    \"\"\"\n    # 1. Determine eligible time indices\n    t_min = max(list(W_set) + [w1, w2])\n\n    # 2. Generate data: c_t and y_t\n    t_range = np.arange(T)\n    phi_t = np.where(t_range  T_shift, 0, phi_shift)\n    c_t = A * np.sin(2 * np.pi / P * t_range + phi_t)\n\n    w_star_t = np.where(t_range  T_shift, w1, w2)\n    y_full = np.full(T, np.nan)\n    for t in range(t_min, T):\n        w_star = w_star_t[t]\n        mean_c = np.mean(c_t[t - w_star : t])\n        y_full[t] = beta0 + beta1 * mean_c + beta2 * s\n    \n    # 3. Create data splits\n    eligible_indices = np.arange(t_min, T)\n    if split_type == 'contiguous':\n        n = len(eligible_indices)\n        g = extra\n        n_train = int(0.6 * n)\n        n_val = int(0.2 * n)\n        \n        train_indices = eligible_indices[:n_train]\n        val_indices = eligible_indices[n_train + g : n_train + g + n_val]\n        test_indices = eligible_indices[n_train + g + n_val + g :]\n    elif split_type == 'interleaved':\n        m = extra\n        train_indices = eligible_indices[np.isin(eligible_indices % m, [0, 1, 2])]\n        val_indices = eligible_indices[eligible_indices % m == 3]\n        test_indices = eligible_indices[eligible_indices % m == 4]\n    else:\n        raise ValueError(\"Unknown split type\")\n\n    # 4. Pre-compute rolling mean features for all candidate windows\n    rolling_means = {}\n    for w in W_set:\n        means_w = np.full(T, np.nan)\n        for t in range(w, T):\n            means_w[t] = np.mean(c_t[t-w:t])\n        rolling_means[w] = means_w\n\n    # 5. Model selection loop (hyperparameter tuning)\n    val_mses = {}\n    for w in W_set:\n        X_train = np.c_[np.ones(len(train_indices)), rolling_means[w][train_indices], np.full(len(train_indices), s)]\n        y_train = y_full[train_indices]\n        \n        theta_hat = np.linalg.pinv(X_train) @ y_train\n        \n        if len(val_indices)  0:\n            X_val = np.c_[np.ones(len(val_indices)), rolling_means[w][val_indices], np.full(len(val_indices), s)]\n            y_val = y_full[val_indices]\n            \n            y_pred_val = X_val @ theta_hat\n            val_mses[w] = np.mean((y_val - y_pred_val)**2)\n        else:\n            val_mses[w] = np.inf\n\n    w_hat = min(val_mses.keys(), key=lambda w: (val_mses[w], w))\n\n    # 6. Refit on train+validation and evaluate on test set\n    refit_indices = np.sort(np.concatenate((train_indices, val_indices)))\n    \n    X_refit = np.c_[np.ones(len(refit_indices)), rolling_means[w_hat][refit_indices], np.full(len(refit_indices), s)]\n    y_refit = y_full[refit_indices]\n    \n    theta_refit = np.linalg.pinv(X_refit) @ y_refit\n    \n    if len(test_indices)  0:\n        X_test = np.c_[np.ones(len(test_indices)), rolling_means[w_hat][test_indices], np.full(len(test_indices), s)]\n        y_test = y_full[test_indices]\n        \n        y_pred_test = X_test @ theta_refit\n        test_mse = np.mean((y_test - y_pred_test)**2)\n    else:\n        test_mse = 0.0\n    \n    return test_mse\n\nsolve()\n```", "id": "3188604"}]}