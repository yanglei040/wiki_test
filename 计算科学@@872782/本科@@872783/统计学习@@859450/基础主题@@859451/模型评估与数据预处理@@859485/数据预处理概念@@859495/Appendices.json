{"hands_on_practices": [{"introduction": "真实世界的数据很少能完美符合线性模型的假设，例如误差方差恒定（同方差性）。这个练习将指导你探索一种常见情况：当噪声是乘性而非加性时，如何通过对数变换来稳定方差并改善模型拟合。通过亲手生成数据并比较变换前后的模型性能，你将直观地理解为什么对数变换是处理具有乘性误差或指数增长趋势数据的有力工具 [@problem_id:3112629]。", "problem": "您的任务是构建一个基于乘性噪声模型的数据集，并评估对数变换如何影响线性建模性能。背景为统计学习及数据预处理概念。您可以使用的基本原理包括对数的性质，即对于正实数 $a$ 和 $b$，$\\log(ab)=\\log a+\\log b$，以及概率论中的标准定义，包括独立性下的期望和对数正态分布的成熟公式。\n\n考虑一对独立的正常数随机变量 $(X,\\varepsilon)$ 和一个正常数 $\\beta$，它们之间的生成关系为 $Y=\\beta X \\varepsilon$。假设 $\\varepsilon$ 服从对数正态分布，其中 $\\log \\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$，因此其均值 $\\mathbb{E}[\\varepsilon]$ 等于 $\\exp(\\sigma^2/2)$。目标是比较对数变换前后的普通最小二乘拟合，并评估该变换是否通过线性化乘性噪声效应的方式提高了拟合质量。\n\n对于每个测试用例，您的程序必须执行以下步骤：\n\n- 使用指定的 $X$ 分布以及 $\\beta$ 和 $\\sigma$ 参数，生成一个大小为 $n$ 的数据集。\n- 构建 $Y=\\beta X \\varepsilon$，其中 $\\varepsilon$ 从参数为 $\\mu=0$ 和给定测试用例 $\\sigma$ 的对数正态分布中独立抽取。\n- 对未经变换的变量 $Y$ 对 $X$ 拟合一个带截距的普通最小二乘 (OLS) 线性模型，即通过最小化残差平方和来近似 $Y \\approx a+bX$，并计算估计斜率 $b_{\\text{pre}}$ 和决定系数 $R^2_{\\text{pre}}$。\n- 对经过对数变换的变量 $\\log Y$ 对 $\\log X$ 拟合一个带截距的普通最小二乘线性模型，即近似 $\\log Y \\approx a_{\\log}+b_{\\log}\\log X$，并计算估计斜率 $b_{\\text{post}}$ 和决定系数 $R^2_{\\text{post}}$。\n- 计算原始尺度下的绝对斜率误差，相对于总体条件均值线性斜率，即 $\\left|b_{\\text{pre}} - \\beta \\exp(\\sigma^2/2)\\right|$，以及对数变换尺度下的绝对斜率误差，相对于期望的线性关系，即 $\\left|b_{\\text{post}} - 1\\right|$。\n- 报告对数变换后 $R^2$ 是否改善（以布尔值 $R^2_{\\text{post}} > R^2_{\\text{pre}}$ 表示），以及两个斜率误差。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果必须是 $[R2\\_improves,err\\_pre,err\\_post]$ 形式的列表，其中 $R2\\_improves$ 是一个布尔值，$err\\_pre$ 和 $err\\_post$ 是保留六位小数的浮点数。最终打印的输出应形如 $[[\\text{bool},\\text{float},\\text{float}],\\ldots]$，每个测试用例对应一个条目，并按下面指定的顺序排列。\n\n使用以下测试套件。为保证可复现性，请为每个用例使用指定的独立伪随机数生成器种子。\n\n- 测试用例 1：$\\beta=2.0$, $n=200$, $\\sigma=0.3$, $X \\sim \\text{均匀分布}[1,10]$, 种子 $42$。\n- 测试用例 2：$\\beta=1.5$, $n=200$, $\\sigma=0.0$, $X \\sim \\text{均匀分布}[1,10]$, 种子 $123$。\n- 测试用例 3：$\\beta=1.0$, $n=1000$, $\\sigma=1.0$, $X \\sim \\text{指数分布}(\\text{scale}=3)$, 种子 $7$。\n- 测试用例 4：$\\beta=0.5$, $n=50$, $\\sigma=0.8$, $X \\sim \\text{对数正态分布}(\\mu=-0.2,\\sigma=0.5)$, 种子 $2025$。\n\n不涉及角度单位，也没有物理单位。不得使用百分比；所有量都应以小数表示。\n\n您的程序必须遵守指定的输出格式，且不得读取输入或写入文件。", "solution": "问题陈述已经过验证，被认为是合理的。它在统计学习原理上有科学依据，问题阐述清晰，目标明确，数据充分，没有歧义或矛盾。\n\n这个问题的核心在于理解和缓解线性回归背景下的异方差性——即误差方差非恒定。我们给定的是一个乘性噪声模型，这是此类问题的常见来源。\n\n**理论框架**\n\n数据的生成模型由关系式 $Y = \\beta X \\varepsilon$ 给出，其中 $Y$ 和 $X$ 是可观测变量，$\\beta$ 是一个正常数比例因子，$\\varepsilon$ 是一个乘性噪声项。变量 $X$ 和 $\\varepsilon$ 是独立且为正的。噪声项 $\\varepsilon$ 被指定为遵循对数正态分布，使其自然对数 $\\log \\varepsilon$ 服从均值为 $0$、方差为 $\\sigma^2$ 的正态分布，记为 $\\log \\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n**对未变换模型的分析：$Y$ 对 $X$**\n\n首先，我们考虑对未变换的变量进行直接线性回归。$Y$ 和 $X$ 之间的理论关系由条件期望 $\\mathbb{E}[Y | X=x]$ 描述。由于 $X$ 和 $\\varepsilon$ 的独立性：\n$$\n\\mathbb{E}[Y | X=x] = \\mathbb{E}[\\beta x \\varepsilon | X=x] = \\beta x \\mathbb{E}[\\varepsilon]\n$$\n对于一个对数正态随机变量 $\\varepsilon$，其中 $\\log \\varepsilon \\sim \\mathcal{N}(\\mu, \\sigma^2)$，其期望为 $\\mathbb{E}[\\varepsilon] = \\exp(\\mu + \\sigma^2/2)$。在我们的例子中，$\\mu=0$，所以 $\\mathbb{E}[\\varepsilon] = \\exp(\\sigma^2/2)$。\n因此，条件期望是：\n$$\n\\mathbb{E}[Y | X=x] = (\\beta e^{\\sigma^2/2}) x\n$$\n这个关系在 $x$ 上是线性的，斜率为 $\\beta e^{\\sigma^2/2}$。$Y$ 对 $X$ 的普通最小二乘 (OLS) 拟合试图估计这个潜在的线性趋势。因此，用于比较的目标斜率是 $\\beta e^{\\sigma^2/2}$。\n\n然而，OLS 估计量要成为最佳线性无偏估计量 (BLUE) 的一个关键假设是同方差性，即误差项的方差是恒定的。我们来考察条件方差：\n$$\n\\text{Var}(Y | X=x) = \\text{Var}(\\beta x \\varepsilon) = (\\beta x)^2 \\text{Var}(\\varepsilon)\n$$\n由于 $\\text{Var}(\\varepsilon)$ 是一个正常数（对于 $\\sigma > 0$），$Y$ 的方差与 $x^2$ 成正比。这是一个典型的异方差性案例：观测值的方差随着预测变量 $X$ 的增大而增大。违反这一假设会导致 OLS 估计量效率低下，假设检验结果不可靠。\n\n**对对数变换模型的分析：$\\log Y$ 对 $\\log X$**\n\n为了解决乘性噪声和异方差性问题，我们提出使用对数变换。对生成模型应用自然对数得到：\n$$\n\\log Y = \\log(\\beta X \\varepsilon) = \\log \\beta + \\log X + \\log \\varepsilon\n$$\n我们定义一组新变量：$Y' = \\log Y$，$X' = \\log X$，以及一个加性误差项 $\\epsilon' = \\log \\varepsilon$。模型变为：\n$$\nY' = (\\log \\beta) + 1 \\cdot X' + \\epsilon'\n$$\n根据定义，误差项 $\\epsilon'$ 服从正态分布，即 $\\epsilon' \\sim \\mathcal{N}(0, \\sigma^2)$。在这个变换后的空间里，$Y'$ 和 $X'$ 之间的关系是完全线性的，真实斜率为 $1$，截距为 $\\log \\beta$。误差项 $\\epsilon'$ 现在是加性的，其方差 $\\sigma^2$ 对所有 $X'$ 值都是恒定的。这个新模型满足了 OLS 的关键假设（线性、误差正态性以及同方差性）。因此，我们期望在对数变换后的数据上进行的 OLS 拟合会更加稳健，并能更好地表征潜在关系。在这个变换后的尺度上，用于比较的目标斜率是 $1$。\n\n**计算方法**\n\n程序通过模拟来经验性地验证这些理论见解。对于每个指定的测试用例：\n1. 用特定的种子初始化一个伪随机数生成器以确保可复现性。\n2. 生成一个大小为 $n$ 的数据集。预测变量 $X$ 从其指定分布中抽取。乘性噪声项 $\\varepsilon$ 从参数为 $\\mu=0$ 和给定 $\\sigma$ 的对数正态分布中抽取。然后构造响应变量 $Y$ 为 $Y = \\beta X \\varepsilon$。\n3. **变换前拟合**：将一个形式为 $Y \\approx a_{\\text{pre}} + b_{\\text{pre}}X$ 的 OLS 模型拟合到数据 $(X, Y)$。计算斜率估计值 $b_{\\text{pre}}$ 和决定系数 $R^2_{\\text{pre}}$。绝对斜率误差计算为 $|b_{\\text{pre}} - \\beta e^{\\sigma^2/2}|$。\n4. **变换后拟合**：将变量变换为 $\\log X$ 和 $\\log Y$。将一个形式为 $\\log Y \\approx a_{\\text{post}} + b_{\\text{post}}\\log X$ 的 OLS 模型拟合到数据 $(\\log X, \\log Y)$。计算斜率估计值 $b_{\\text{post}}$ 和决定系数 $R^2_{\\text{post}}$。绝对斜率误差计算为 $|b_{\\text{post}} - 1|$。\n5. 决定系数 $R^2$ 作为预测变量和响应变量之间皮尔逊相关系数的平方来计算，对于简单线性回归，这等价于 $1 - \\frac{\\sum_i (y_i - \\hat{y}_i)^2}{\\sum_i (y_i - \\bar{y})^2}$。\n6. 最终的指标被组合成一个列表：$[R^2_{\\text{post}} > R^2_{\\text{pre}}, |b_{\\text{pre}} - \\beta e^{\\sigma^2/2}|, |b_{\\text{post}} - 1|]$。布尔值表示对数变换是否在解释方差方面改善了模型拟合。两个误差项量化了每个域中斜率估计的准确性。", "answer": "```python\nimport numpy as np\n\ndef perform_analysis(beta, n, sigma, x_dist_params, seed):\n    \"\"\"\n    Generates a dataset under a multiplicative noise model and compares\n    OLS fits before and after a logarithmic transformation.\n\n    Args:\n        beta (float): The scaling factor in the model Y = beta * X * epsilon.\n        n (int): The number of data points to generate.\n        sigma (float): The scale parameter (std dev) of the log-normal noise.\n                       log(epsilon) ~ N(0, sigma^2).\n        x_dist_params (tuple): A tuple describing the distribution of X.\n                               e.g., ('uniform', low, high)\n        seed (int): The seed for the random number generator.\n\n    Returns:\n        list: A list containing [R2_improves, err_pre, err_post].\n    \"\"\"\n    # 1. Initialize RNG and generate data\n    rng = np.random.default_rng(seed)\n\n    dist_type = x_dist_params[0]\n    if dist_type == 'uniform':\n        # Generate X from Uniform(low, high)\n        X = rng.uniform(low=x_dist_params[1], high=x_dist_params[2], size=n)\n    elif dist_type == 'exponential':\n        # Generate X from Exponential(scale)\n        X = rng.exponential(scale=x_dist_params[1], size=n)\n    elif dist_type == 'lognormal':\n        # Generate X from Lognormal(mu, sigma)\n        X = rng.lognormal(mean=x_dist_params[1], sigma=x_dist_params[2], size=n)\n    else:\n        # This case should not be reached with the given problem\n        raise ValueError(\"Unknown distribution for X\")\n\n    # Generate multiplicative noise epsilon from Lognormal(0, sigma)\n    # This means log(epsilon) is N(0, sigma^2)\n    epsilon = rng.lognormal(mean=0.0, sigma=sigma, size=n)\n\n    # Construct Y\n    Y = beta * X * epsilon\n    \n    # 2. Pre-transformation OLS fit (Y vs X)\n    # Using np.polyfit to get slope (b_pre) and intercept\n    b_pre, _ = np.polyfit(X, Y, 1)\n\n    # R-squared is the square of correlation for simple linear regression\n    # Handle cases where variance is zero to avoid NaN\n    if np.var(X) > 1e-12 and np.var(Y) > 1e-12:\n        R2_pre = np.corrcoef(X, Y)[0, 1]**2\n    else:\n        R2_pre = 0.0\n\n    # 3. Log-transform data\n    log_X = np.log(X)\n    log_Y = np.log(Y)\n\n    # 4. Post-transformation OLS fit (log Y vs log X)\n    b_post, _ = np.polyfit(log_X, log_Y, 1)\n\n    if np.var(log_X) > 1e-12 and np.var(log_Y) > 1e-12:\n        R2_post = np.corrcoef(log_X, log_Y)[0, 1]**2\n    else:\n        R2_post = 0.0\n\n    # 5. Compute comparison metrics\n    R2_improves = R2_post > R2_pre\n\n    # Absolute slope error for the pre-transformation model\n    target_slope_pre = beta * np.exp(sigma**2 / 2.0)\n    err_pre = np.abs(b_pre - target_slope_pre)\n\n    # Absolute slope error for the post-transformation model\n    target_slope_post = 1.0\n    err_post = np.abs(b_post - target_slope_post)\n\n    return [R2_improves, round(err_pre, 6), round(err_post, 6)]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final output.\n    \"\"\"\n    test_cases = [\n        {'beta': 2.0, 'n': 200, 'sigma': 0.3, 'x_dist_params': ('uniform', 1.0, 10.0), 'seed': 42},\n        {'beta': 1.5, 'n': 200, 'sigma': 0.0, 'x_dist_params': ('uniform', 1.0, 10.0), 'seed': 123},\n        {'beta': 1.0, 'n': 1000, 'sigma': 1.0, 'x_dist_params': ('exponential', 3.0), 'seed': 7},\n        {'beta': 0.5, 'n': 50, 'sigma': 0.8, 'x_dist_params': ('lognormal', -0.2, 0.5), 'seed': 2025}\n    ]\n\n    results = []\n    for case in test_cases:\n        result = perform_analysis(**case)\n        results.append(result)\n\n    # Format the output string exactly as required\n    formatted_results = []\n    for res in results:\n        # res[0] is boolean, res[1] and res[2] are floats\n        formatted_results.append(f\"[{str(res[0]).lower()},{res[1]:.6f},{res[2]:.6f}]\")\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3112629"}, {"introduction": "数据中的异常值是常见的挑战，它们可能严重扭曲非稳健的统计估计量，如均值和标准差，从而影响数据缩放的效果。本练习将引导你深入研究稳健统计的核心概念，通过编程实现一个对抗性场景，比较传统缩放方法与基于Huber M估计的稳健缩放方法的“崩溃点” [@problem_id:3112649]。这个实践将让你直观地感受到不同预处理方法在面对数据污染时的表现差异，并理解“稳健性”在构建可靠模型中的重要性。", "problem": "您的任务是经验性地比较统计学习中数据预处理所使用的两种一维缩放方案的稳健性：一种是使用样本均值和中位数绝对偏差 (MAD) 的非稳健方案，另一种是基于Huber化的稳健方案。您将构建对抗性离群值，并在最坏情况污染下估计每种方案的经验有限样本击穿分数。\n\n定义与基本基础：\n- 假设一个数据集是一个向量 $x \\in \\mathbb{R}^n$，其条目为 $x_i$，其中 $i \\in \\{1,\\dots,n\\}$。\n- 标准化值定义为 $z_i = \\dfrac{x_i - \\hat{\\mu}}{\\hat{s}}$，其中 $\\hat{\\mu}$ 是一个位置估计量，$\\hat{s}$ 是一个尺度估计量。\n- 样本均值定义为 $\\hat{\\mu}_{\\mathrm{mean}} = \\dfrac{1}{n}\\sum_{i=1}^n x_i$。\n- 中位数绝对偏差 (MAD) 定义为 $\\mathrm{MAD}(x) = \\mathrm{median}_{i}\\left(\\left|x_i - \\mathrm{median}_{j}(x_j)\\right|\\right)$，在非稳健方案中，我们将使用 $\\hat{s}_{\\mathrm{MAD}} = \\mathrm{MAD}(x)$ 作为尺度估计（不带任何效率重缩放常数）。\n- 参数为 $c>0$ 的Huber损失定义为\n$$\n\\rho_c(u) = \n\\begin{cases}\n\\dfrac{1}{2}u^2,  \\text{if } |u| \\le c, \\\\\nc|u| - \\dfrac{1}{2}c^2,  \\text{if } |u| > c,\n\\end{cases}\n$$\n其对应影响（得分）函数为\n$$\n\\psi_c(u) = \n\\begin{cases}\nu,  \\text{if } |u| \\le c, \\\\\nc\\cdot \\mathrm{sign}(u),  \\text{if } |u| > c.\n\\end{cases}\n$$\n- Huber化的位置估计量 $\\hat{\\mu}_{\\mathrm{Huber}}$ 和Huber化的尺度估计量 $\\hat{s}_{\\mathrm{Huber}}$ 可以通过求解耦合的M估计方程\n$$\n\\sum_{i=1}^n \\psi_c\\!\\left(\\dfrac{x_i - \\hat{\\mu}}{\\hat{s}}\\right) = 0, \n\\quad\n\\hat{s}^2 = \\dfrac{1}{n}\\sum_{i=1}^n \\min\\!\\left((x_i - \\hat{\\mu})^2, (c\\hat{s})^2\\right),\n$$\n得到，我们将使用基于MAD的初始稳健尺度和基于样本中位数的初始稳健位置，通过不动点迭代进行数值近似求解。\n\n经验击穿分数：\n- 估计量的有限樣本击穿点是在对抗性替换下能将估计量驱动到任意坏值的最小污染比例。我们将在一个固定网格上将其数值近似为最小污染比例 $p$，在该比例下，估计的位置或尺度违反了从无污染数据集中推导出的预定大界限。\n- 给定一个基础数据集 $x^{(0)} \\in \\mathbb{R}^n$、一个污染比例 $p \\in [0,1]$ 和一个离群值 $A \\gg 0$，通过将 $x^{(0)}$ 的前 $k = \\lfloor pn \\rfloor$ 个条目替换为单一值 $+A$ 来构建一个对抗性污染的数据集 $x^{(p)}$。\n- 令 $s_0 = \\mathrm{MAD}(x^{(0)})$ 表示未污染数据的基线稳健尺度。定义界限\n$$\nL = \\alpha_L s_0,\\quad S_{\\max} = \\alpha_H s_0,\\quad S_{\\min} = \\alpha_L^{\\prime} s_0,\n$$\n其中 $\\alpha_L > 0$、$\\alpha_H > 0$ 和 $\\alpha_L^{\\prime} > 0$ 是常数。\n- 对于预定网格上的每个污染水平 $p$，计算每种方案下的 $(\\hat{\\mu},\\hat{s})$，如果 $|\\hat{\\mu}| > L$ 或 $\\hat{s} > S_{\\max}$ 或 $\\hat{s}  S_{\\min}$，则宣布发生击穿。经验击穿分数是网格上发生击穿的最小 $p$ 值。\n\n待实现的方案：\n1. 均值/MAD 缩放：$\\hat{\\mu} = \\hat{\\mu}_{\\mathrm{mean}}$ 和 $\\hat{s} = \\mathrm{MAD}(x)$。\n2. Huber化缩放：初始化 $\\hat{\\mu}^{(0)} = \\mathrm{median}(x)$ 和 $\\hat{s}^{(0)} = \\mathrm{MAD}(x)$，然后迭代\n$$\nr_i^{(t)} = \\dfrac{x_i - \\hat{\\mu}^{(t)}}{\\hat{s}^{(t)}},\\quad\nw_i^{(t)} = \\min\\!\\left(1, \\dfrac{c}{|r_i^{(t)}|+\\varepsilon}\\right),\\quad\n\\hat{\\mu}^{(t+1)} = \\dfrac{\\sum_i w_i^{(t)} x_i}{\\sum_i w_i^{(t)}},\n$$\n$$\n\\hat{s}^{(t+1)} = \\sqrt{\\dfrac{1}{n}\\sum_{i=1}^n \\min\\!\\left((x_i - \\hat{\\mu}^{(t+1)})^2, (c\\hat{s}^{(t)})^2\\right)},\n$$\n进行固定次数的迭代，其中 $\\varepsilon$ 是一个用于避免除以零的小正数常量。最终的 $(\\hat{\\mu},\\hat{s}) = (\\hat{\\mu}^{(T)},\\hat{s}^{(T)})$。\n\n测试套件：\n使用 $n = 200$，Huber参数 $c = 1.345$，离群值 $A = 10^9$，污染网格\n$$\n\\mathcal{P} = [\\,0,\\;0.001,\\;0.005,\\;0.01,\\;0.02,\\;0.05,\\;0.1,\\;0.2,\\;0.3,\\;0.4,\\;0.49,\\;0.5,\\;0.51\\,],\n$$\n和界限 $\\alpha_L = 10$, $\\alpha_H = 10$, $\\alpha_L^{\\prime} = 0.05$。构建三个基础数据集 $x^{(0)}$：\n- 情况1：标准正态分布，$x_i \\sim \\mathcal{N}(0,1)$，种子为 $123$。\n- 情况2：自由度为 $\\nu=3$ 的Student-$t$分布，$x_i \\sim t_3$，种子为 $456$。\n- 情况3：平移指数分布，$y_i \\sim \\mathrm{Exp}(\\lambda=1)$ 且 $x_i = y_i - \\dfrac{1}{n}\\sum_j y_j$，种子为 $789$。\n\n任务：\n- 对每种情况，遵循上述污染过程和击穿准则，计算两种方案的经验击穿分数。\n- 报告每个经验击穿分数，四舍五入到三位小数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含结果，格式为逗号分隔的列表的列表，每个内部列表对应一个测试用例并包含两个浮点数：$[\\text{breakdown\\_mean\\_MAD},\\text{breakdown\\_Huberized}]$。例如，包含三个测试用例的输出应如下所示\n$$\n[[a_1,b_1],[a_2,b_2],[a_3,b_3]]\n$$\n其中每个 $a_i$ 和 $b_i$ 是四舍五入到三位小数的小数。不应打印其他任何文本。不涉及物理单位或角度，污染比例必须表示为小数。", "solution": "我们的目标是通过在对抗性污染下的经验有限样本击穿分数来评估两种缩放方案的稳健性。概念上的出发点是稳健统计学中击穿点的定义：能够迫使估计量达到任意大或无意义的值的最小污染比例。由于数值上无法达到精确的无穷大，我们定义相对于未污染数据稳健尺度的阈值来检测实际的发散。\n\n基于原则的逐步设计：\n1. 基线稳健尺度和界限：对于一个未受污染的数据集 $x^{(0)}$，计算 $s_0 = \\mathrm{MAD}(x^{(0)})$。使用常数 $\\alpha_L$, $\\alpha_H$, $\\alpha_L^{\\prime}$ 来构建界限 $L = \\alpha_L s_0$, $S_{\\max} = \\alpha_H s_0$ 和 $S_{\\min} = \\alpha_L^{\\prime} s_0$。这将击穿检测锚定在数据集的内在尺度上。\n\n2. 对抗性污染模型：对于任何选定的比例 $p \\in [0,1]$，用单个极端离群值 $+A$ (其中 $A \\gg 0$) 替换 $x^{(0)}$ 中的 $k = \\lfloor pn \\rfloor$ 个条目。这是对抗性的，因为将所有污染点置于一个大的恒定幅度上会最大化位置偏移，并可能夸大尺度，特别是对于非稳健的估计量。\n\n3. 非稳健方案（均值/MAD）：\n   - 位置：$\\hat{\\mu} = \\dfrac{1}{n}\\sum_i x_i$。该估计量的理论击穿点为 $0$，因为任何非零比例的任意大污染都可以迫使 $\\hat{\\mu}$ 任意远离其未受污染时的值。\n   - 尺度：$\\hat{s} = \\mathrm{MAD}(x)$，其本身具有较高的擊穿点（约 $0.5$），但在该缩放方案中，位置使用的是均值，这使得标准化输出变得脆弱。在我们的击穿检测中，我们会仔细追踪 $|\\hat{\\mu}|$ 是否超过 $L$ 以及 $\\hat{s}$ 是否违反其界限。\n\n4. 稳健方案（Huber化缩放）：我们使用Huber的M估计原理。位置方程 $\\sum \\psi_c\\!\\left(\\dfrac{x_i - \\hat{\\mu}}{\\hat{s}}\\right) = 0$ 通过 $\\psi_c$ 限制大残差的影响，而尺度更新\n   $$\n   \\hat{s}^2 = \\dfrac{1}{n}\\sum_{i=1}^n \\min\\!\\left((x_i - \\hat{\\mu})^2, (c\\hat{s})^2\\right)\n   $$\n   在阈值 $c\\hat{s}$ 处对平方残差进行Winsor化处理。\n   - 算法解：从稳健的初始值 $\\hat{\\mu}^{(0)} = \\mathrm{median}(x)$ 和 $\\hat{s}^{(0)} = \\mathrm{MAD}(x)$ 开始，并应用不动点迭代。在每次迭代 $t$ 中，形成标准化残差 $r_i^{(t)}$，计算权重 $w_i^{(t)} = \\min\\!\\left(1, \\dfrac{c}{|r_i^{(t)}|+\\varepsilon}\\right)$（对于小的 $\\varepsilon0$），将位置更新为加权平均 $\\hat{\\mu}^{(t+1)}$，并通过Winsor化的二阶矩公式 $\\hat{s}^{(t+1)}$ 更新尺度。此过程源于Huber的M估计的一阶条件，并对应于迭代重加权最小二乘法和Winsor化。\n   - 稳健性直觉：因为 $\\psi_c$ 限制了每个点的影响，所以少于半数的污染无法将位置推得太远；Winsor化的尺度也限制了极端点的影响。然而，一旦污染超过约一半，对抗方就可以控制两个方程，因为大多数点都被污染了。然后，不动点迭代会（由于与Winsor化阈值的重复相乘）使 $\\hat{s}$ 膨胀并使 $\\hat{\\mu}$ 偏移，从而导致击穿。因此，Huber化缩放的经验击穿点预计在 $0.5$ 附近。\n\n5. 经验击穿检测：对于固定网格上的每个污染比例 $p$，计算两种方案下的 $(\\hat{\\mu},\\hat{s})$，并检查是否 $|\\hat{\\mu}| > L$ 或 $\\hat{s} > S_{\\max}$ 或 $\\hat{s}  S_{\\min}$。发生这种情况的最小 $p$ 值即被报告为经验击穿分数。\n\n6. 测试套件设计：\n   - 情况1（理想情况）：标准正态分布 $x_i \\sim \\mathcal{N}(0,1)$。由于极端的 $A$ 值，均值/MAD 方案应在最小的非零污染水平上击穿，而Huber化缩放应能抵抗到接近 $0.5$。\n   - 情况2（重尾）：自由度为 $\\nu=3$ 的Student-$t$分布。基础数据具有重尾特性，这对尺度估计的稳定性构成了挑战，但两种方案之间击穿点的相对差异应该保持不变。\n   - 情况3（偏斜）：平移指数分布。非对称性测试了初始化和迭代的稳健性，特别是中位数/MAD 的起始值。\n\n7. 输出：对于每种情况，计算两种方案的经验击穿分数，将它们四舍五入到三位小数，并以单行格式 $[[a_1,b_1],[a_2,b_2],[a_3,b_3]]$ 呈现。\n\n这种方法遵循了稳健估计、Huber影响函数和击穿点的基本定义，将它们转化为在对抗性污染下测试稳健性的实用算法，而不依赖于捷径公式。阈值 $L$、$S_{\\max}$ 和 $S_{\\min}$ 用于以有原则的方式，相对于未污染数据集的稳健尺度 $s_0$ 来检测数值发散。", "answer": "```python\nimport numpy as np\n\n# Environment: Python 3.12, numpy 1.23.5, scipy not used.\n\ndef mad(x: np.ndarray) -> float:\n    \"\"\"Median Absolute Deviation (unscaled).\"\"\"\n    med = np.median(x)\n    return np.median(np.abs(x - med))\n\ndef mean_mad_estimates(x: np.ndarray) -> tuple[float, float]:\n    \"\"\"Non-robust location (mean) and robust scale (MAD).\"\"\"\n    mu = float(np.mean(x))\n    s = float(mad(x))\n    # Guard against zero MAD\n    if s == 0.0 or not np.isfinite(s):\n        s = 1e-12\n    return mu, s\n\ndef huberized_location_scale(x: np.ndarray, c: float = 1.345, max_iter: int = 100, tol: float = 1e-9) -> tuple[float, float]:\n    \"\"\"\n    Huberized location and scale via fixed-point iteration:\n    - Location: weighted mean with weights w_i = min(1, c / |r_i|)\n    - Scale: winsorized second moment s^2 = mean(min(diff^2, (c*s)^2))\n    Initialization uses median and MAD.\n    \"\"\"\n    n = x.size\n    # Robust initializers\n    mu = float(np.median(x))\n    s = float(mad(x))\n    if s == 0.0 or not np.isfinite(s):\n        s = 1e-6\n    eps = 1e-12\n\n    for _ in range(max_iter):\n        # Standardized residuals\n        r = (x - mu) / (s + eps)\n        # Huber weights for location\n        w = np.minimum(1.0, c / (np.abs(r) + eps))\n        # Update location: weighted mean\n        w_sum = np.sum(w)\n        if w_sum == 0.0 or not np.isfinite(w_sum):\n            w_sum = 1e-12\n        mu_new = float(np.sum(w * x) / w_sum)\n\n        # Update scale: winsorized second moment at threshold c*s\n        diff = x - mu_new\n        clip_sq = np.minimum(diff * diff, (c * s) ** 2)\n        s_new = float(np.sqrt(np.mean(clip_sq)))\n        if s_new == 0.0 or not np.isfinite(s_new):\n            s_new = s  # fallback to previous\n\n        # Convergence check\n        if abs(mu_new - mu)  tol and abs(s_new - s)  tol:\n            mu, s = mu_new, s_new\n            break\n\n        mu, s = mu_new, s_new\n\n    return mu, s\n\ndef contaminate(x0: np.ndarray, p: float, A: float) -> np.ndarray:\n    \"\"\"Replace floor(p*n) entries with the adversarial value +A.\"\"\"\n    n = x0.size\n    k = int(np.floor(p * n))\n    if k == 0:\n        return x0.copy()\n    x = x0.copy()\n    x[:k] = A\n    return x\n\ndef empirical_breakdown_fraction(\n    x0: np.ndarray,\n    A: float,\n    p_grid: list[float],\n    alpha_L: float,\n    alpha_H: float,\n    alpha_L_prime: float,\n    scheme: str,\n    c: float = 1.345\n) -> float:\n    \"\"\"\n    Compute the empirical breakdown fraction for a given scheme:\n    - scheme in {\"mean_mad\", \"huberized\"}.\n    Breakdown if |mu| > L or s > S_max or s  S_min, where bounds are based on s0 = MAD(x0).\n    \"\"\"\n    s0 = mad(x0)\n    # Guard s0 to avoid zero baseline scale\n    if s0 == 0.0 or not np.isfinite(s0):\n        s0 = 1e-6\n\n    L = alpha_L * s0\n    S_max = alpha_H * s0\n    S_min = alpha_L_prime * s0\n\n    for p in p_grid:\n        x = contaminate(x0, p, A)\n        if scheme == \"mean_mad\":\n            mu_hat, s_hat = mean_mad_estimates(x)\n        elif scheme == \"huberized\":\n            mu_hat, s_hat = huberized_location_scale(x, c=c)\n        else:\n            raise ValueError(\"Unknown scheme\")\n\n        # Breakdown conditions\n        if (abs(mu_hat) > L) or (s_hat > S_max) or (s_hat  S_min) or (not np.isfinite(mu_hat)) or (not np.isfinite(s_hat)):\n            return float(p)\n\n    # If no breakdown observed on the grid, return 1.0 as a sentinel\n    return 1.0\n\ndef generate_base_data(case: int, n: int, seed: int) -> np.ndarray:\n    rng = np.random.RandomState(seed)\n    if case == 1:\n        # Standard Normal\n        return rng.normal(loc=0.0, scale=1.0, size=n)\n    elif case == 2:\n        # Student-t with nu=3\n        return rng.standard_t(df=3, size=n)\n    elif case == 3:\n        # Shifted Exponential: centered to have mean ~0\n        y = rng.exponential(scale=1.0, size=n)\n        return y - np.mean(y)\n    else:\n        raise ValueError(\"Unknown case\")\n\ndef format_results(rows: list[tuple[float, float]]) -> str:\n    \"\"\"Format nested list of floats with three decimals and no spaces.\"\"\"\n    inner = []\n    for a, b in rows:\n        inner.append(f\"[{a:.3f},{b:.3f}]\")\n    return \"[\" + \",\".join(inner) + \"]\"\n\ndef solve():\n    # Test suite parameters\n    n = 200\n    c = 1.345\n    A = 1e9\n    p_grid = [0.0, 0.001, 0.005, 0.01, 0.02, 0.05, 0.1, 0.2, 0.3, 0.4, 0.49, 0.5, 0.51]\n    alpha_L = 10.0\n    alpha_H = 10.0\n    alpha_L_prime = 0.05\n\n    test_cases = [\n        # (case_id, seed)\n        (1, 123),\n        (2, 456),\n        (3, 789),\n    ]\n\n    results = []\n    for case_id, seed in test_cases:\n        x0 = generate_base_data(case_id, n, seed)\n\n        bp_mean_mad = empirical_breakdown_fraction(\n            x0=x0, A=A, p_grid=p_grid,\n            alpha_L=alpha_L, alpha_H=alpha_H, alpha_L_prime=alpha_L_prime,\n            scheme=\"mean_mad\", c=c\n        )\n        bp_huber = empirical_breakdown_fraction(\n            x0=x0, A=A, p_grid=p_grid,\n            alpha_L=alpha_L, alpha_H=alpha_H, alpha_L_prime=alpha_L_prime,\n            scheme=\"huberized\", c=c\n        )\n        results.append((bp_mean_mad, bp_huber))\n\n    # Print final output line in exact required format\n    print(format_results(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3112649"}, {"introduction": "在处理时间序列数据时，一个最微妙也最严重的错误是“数据泄漏”，即在模型训练中无意间使用了来自未来的信息。本练习设计了一个场景，你将亲手构建一个包含未来信息的“泄漏”特征，并观察它如何导致模型在交叉验证中表现出虚高的性能 [@problem_id:3112690]。更重要的是，你将学会如何通过设计正确的时间感知交叉验证流程来防止这种泄漏，确保模型评估的有效性和真实性。", "problem": "您的任务是构建一个确定性程序，用以展示和量化在时间序列预处理中因错误地包含一个源于未来的特征而导致的数据泄露，然后设计一个时间感知的交叉验证过程，通过在每个折叠（fold）内部重新计算特征而不使用未来信息来消除这种泄露。目标是从第一性原理出发，对存在有序数据情况下的时间依赖性、平稳性以及交叉验证的有效性进行推理。\n\n请使用以下基础和定义：单变量时间序列是由离散时间 $t$ 索引的序列 $\\{y_t\\}_{t=0}^{T}$。一阶自回归过程 (AR(1)) 由 $y_{t+1} = a \\, y_t + \\varepsilon_{t+1}$ 给出，其中 $\\varepsilon_{t}$ 是方差为 $\\sigma^2$ 的零均值噪声，且 $|a|  1$ 确保了弱平稳性。普通最小二乘 (OLS) 回归通过最小化均方误差 (MSE) $\\frac{1}{n}\\sum_{i=1}^{n}(y_i - \\hat{y}_i)^2$ 来估计系数 $\\hat{\\beta}$。随机 K 折交叉验证 (cross-validation (CV)) 假设样本是独立同分布的，并将索引随机划分为 $K$ 个不相交的折叠；在时间序列中，由于时间依赖性和因果约束，这一假设被违反。用于时间序列的时间感知 CV 使用遵循时间顺序的前向链（扩展窗口）划分：训练仅使用索引 $\\leq t_{\\text{train}}$ 的数据，验证使用 $(t_{\\text{train}}, t_{\\text{val}}]$ 区间内的索引。\n\n按如下方式构建监督学习目标 $y_{t+1}$ 和在时间 $t$ 的特征。无泄露、仅使用过去信息的特征为 $f_{1,t} = y_t$ 和 $f_{2,t} = \\frac{1}{W}\\sum_{j=0}^{W-1} y_{t-j}$（一个仅使用当前值和 $W-1$ 个过去值的滞后均值）。一个有泄露、源于未来的特征是 $g_{2,t} = \\frac{1}{W}\\sum_{j=0}^{W-1} y_{t+1-j}$，它使用了 $y_{t+1}$；将其与 $g_{1,t} = y_t$ 配对，得到一个有泄露的特征集，当 $W \\ge 1$ 时，它将目标直接嵌入到输入中，从而违反了训练时的信息约束。\n\n您的程序必须：\n\n1. 模拟一个 AR(1) 过程，用于主实验的参数如下：长度 $N = 1200$，自回归系数 $a = 0.8$，新息标准差 $\\sigma = 1.0$，以及初始条件 $y_0 = 0$。使用一个固定的随机数生成器种子以确保确定性。\n\n2. 为索引为 $t \\in \\{W-1, W, \\dots, N-2\\}$ 的行构建两个特征集，使得目标为 $y_{t+1}$：\n   - 有泄露的特征：$x_t^{\\text{leak}} = \\big(y_t, \\frac{1}{W}\\sum_{j=0}^{W-1} y_{t+1-j}, 1\\big)$，其中最后一个分量是截距项。\n   - 无泄露的特征：$x_t^{\\text{past}} = \\big(y_t, \\frac{1}{W}\\sum_{j=0}^{W-1} y_{t-j}, 1\\big)$，其中最后一个分量是截距项。\n\n3. 实现两种 CV 方案：\n   - 随机 K 折 CV，其中 $K = 6$，在划分前使用固定种子对行索引进行均匀随机打乱。对于此 CV，使用全局预计算的有泄露特征 $x_t^{\\text{leak}}$。\n   - 时间感知的前向链 CV，包含 $K=5$ 个折叠，初始训练集大小为 $n_{\\text{train},0} = 500$，验证块大小为 $n_{\\text{val}} = 100$（第 $k$ 个折叠使用直到索引 $n_{\\text{train},0} + (k-1) n_{\\text{val}} - 1$ 的训练行，并在接下来的 $n_{\\text{val}}$ 行上进行验证）。您必须实现两种变体：\n     (i) 使用全局预计算的有泄露特征 $x_t^{\\text{leak}}$，以证明如果特征是使用未来信息预计算的，那么仅靠时间感知的划分本身并不能修复特征泄露。\n     (ii) 在每个折叠内部，对于训练和验证段，严格仅使用截至时间 $t$ 的可用过去数据来重新计算特征，从而为每个折叠生成无泄露的特征 $x_t^{\\text{past}}$。\n\n4. 在每个折叠中，对指定的特征拟合带截距的 OLS 线性模型，并在验证集上计算 MSE；将各折叠的验证 MSE 取平均，以获得交叉验证的 MSE。\n\n5. 设计一个边界测试，其中滚动窗口 $W=1$，这使得有泄露的滚动均值恰好等于 $y_{t+1}$，并展示这种灾难性的泄露形式。\n\n您的程序必须实现以下测试套件，并生成单行输出，其中按顺序包含每个测试的布尔结果：\n\n- 测试 A (理想路径下的泄露检测): 当 $N = 1200$, $a = 0.8$, $\\sigma = 1.0$, $W = 5$ 时，使用有泄露的特征进行随机 $K = 6$ 折 CV，计算交叉验证的 MSE，如果其严格小于 $0.1$，则返回 true。\n- 测试 B (不重新计算特征的时间感知划分仍然会泄露): 使用相同的 $N$, $a$, $\\sigma$, $W$ 和指定的时间感知 CV，但使用全局预计算的有泄露特征，计算交叉验证的 MSE，如果其严格小于 $0.1$，则返回 true。\n- 测试 C (每个折叠内重新计算特征的时间感知 CV 可防止泄露): 使用相同的 $N$, $a$, $\\sigma$, $W$ 和指定的时间感知 CV，但在每个折叠内重新计算无泄露的特征，计算交叉验证的 MSE，如果其位于区间 $[0.6, 1.4]$ 内，则返回 true。\n- 测试 D (边界情况，$W = 1$ 的灾难性泄露): 当 $N = 800$, $a = 0.8$, $\\sigma = 1.0$, $W = 1$ 时，使用全局预计算的有泄露特征进行随机 $K = 6$ 折 CV，计算交叉验证的 MSE，如果其严格小于 $10^{-12}$，则返回 true。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，\"[resultA,resultB,resultC,resultD]\"）。每个结果必须是一个布尔字面量。不得打印任何额外文本。不涉及任何物理单位或角度，也不应输出百分比。所有常量和测试参数必须完全按照上述规定进行硬编码，以确保在不同环境中的可复现性和可测试性。随机数生成器种子也必须在程序中固定，以使结果具有确定性。解决方案必须能在支持指定库和语言的任何现代环境中运行。", "solution": "该问题要求通过计算来演示时间序列预测中的数据泄露、其后果以及通过正确的交叉验证和特征工程来解决该问题的方法。问题的核心在于时序数据中的因果性原则：预测未来状态的模型不能访问来自该未来状态的信息。\n\n该问题被验证为是合理的、适定的和有科学依据的。它提出了一个统计学习领域中清晰、可形式化的实验。\n\n**1. 基本原理：时间序列、因果性与数据泄露**\n\n时间序列 $\\{y_t\\}$ 是按时间排序的观测序列。预测中的一个基本原则是因果性：时间 $t+1$ 的状态受时间 $\\tau \\leq t$ 的状态影响，但不受时间 $\\tau'  t+1$ 的状态影响。预测模型必须遵守这一约束。当来自未来的信息（相对于预测时间点）在无意中被用于训练模型时，就会发生数据泄露。这会导致对模型性能的评估过于乐观且不正确。\n\n该问题定义了两种使用时间 $t$ 可用信息来预测目标 $y_{t+1}$ 的特征：\n\n- **无泄露（仅过去）特征**：$x_t^{\\text{past}} = \\big(y_t, \\frac{1}{W}\\sum_{j=0}^{W-1} y_{t-j}, 1\\big)$。这两个特征，即值 $y_t$ 和在 $[t-W+1, t]$ 上的滞后均值，都只使用了在时间 $t$ 或之前可用的信息。这在因果上是有效的。\n\n- **有泄露（包含未来）特征**：$x_t^{\\text{leak}} = \\big(y_t, \\frac{1}{W}\\sum_{j=0}^{W-1} y_{t+1-j}, 1\\big)$。第二个特征 $g_{2,t} = \\frac{1}{W}\\sum_{j=0}^{W-1} y_{t+1-j}$ 是在窗口 $[t-W+2, t+1]$ 上的移动平均值。关键的是，这个平均值包含了项 $y_{t+1}$（当 $j=0$ 时），而这正是我们试图预测的量。这是一种直接的数据泄露形式。一个旨在最小化均方误差 (MSE) 的普通最小二乘 (OLS) 模型将学会给这个特征赋予很大的权重，因为它与目标完全相关。\n\n**2. 交叉验证方案及其有效性**\n\n该问题对比了两种交叉验证 (CV) 方案：\n\n- **随机 K 折 CV**：这种标准方法假设样本是独立同分布的 (i.i.d.)。它将所有数据点 $(x_i, y_i)$ 随机打乱并分成 $K$ 个折叠。对于时间序列，这是无效的，因为它破坏了时间依赖结构。模型可能会用 $t=100$ 的数据进行训练，而在 $t=50$ 的数据上进行验证。从时间角度看这是荒谬的，并构成了另一种形式的泄露，因为相对于其验证任务，模型已经“看到”了未来。\n\n- **时间感知的前向链 CV**：此方法保留了时间顺序。数据被划分为一系列训练集和验证集。对于第 $k$ 次划分，训练集包含截至时间 $t_k$ 的数据，验证集包含随后时期 $(t_k, t_k+h]$ 内的数据。这模仿了真实世界的场景，即模型在新增数据上被周期性地重新训练，并用于预测不久的将来。\n\n**3. 对所要求测试的分析**\n\n解决方案将围绕四个已定义的测试来构建，每个测试都旨在揭示数据泄露问题的不同方面。核心预测模型是 OLS，它找到系数 $\\hat{\\beta}$ 以最小化由 $\\text{MSE} = \\frac{1}{n}\\sum_{i=1}^{n}(y_i - x_i^T \\hat{\\beta})^2$ 给出的 MSE。OLS 的解由 $\\hat{\\beta} = (X^T X)^{-1} X^T \\mathbf{y}$ 给出。\n\n**测试 A：随机 CV 导致的泄露**\n该测试将有泄露的特征 ($x_t^{\\text{leak}}$) 与无效的交叉验证方法（随机 K 折）相结合。有泄露的特征 $g_{2,t}$ 包含了目标 $y_{t+1}$。OLS 模型会轻易发现这种关系，从而在验证集上做出近乎完美的预测。随机 CV 中的打乱操作并不能缓解这个问题；它只确保了泄露在每个折叠中都存在。因此，预期得到的 MSE 会极低，远低于过程的内在随机性，从而满足条件 $\\text{MSE}  0.1$。\n\n**测试 B：使用时间感知 CV 时的泄露**\n该测试使用正确的时间感知 CV 划分，但作用于预先计算好的、带有泄露的特征 ($x_t^{\\text{leak}}$)。虽然 CV 划分尊重了因果性（在过去的数据上训练，在未来的数据上验证），但特征本身已经被污染。在 CV 过程开始之前，泄露就已经“烘焙”进了特征矩阵 $X^{\\text{leak}}$。因此，每个折叠中的模型仍然能通过有泄露的特征访问到目标变量，并将产生一个人为压低的 MSE。该测试表明，如果特征工程存在缺陷，仅靠正确的 CV 划分是不够的。预期 MSE 同样会非常低，满足 $\\text{MSE}  0.1$。\n\n**测试 C：使用正确的 CV 和特征，无泄露**\n该测试将正确的时间感知 CV 与正确设计的、无泄露的特征 ($x_t^{\\text{past}}$) 相结合。特征在每个折叠的上下文中被重新评估（概念上如此，尽管在这种情况下，它仅意味着使用对所有时间点都有效的预计算 `X_past` 矩阵）。现在，模型必须仅使用来自时间 $t$ 及更早的信息来预测 $y_{t+1}$。底层的数据生成过程是 $y_{t+1} = a y_t + \\varepsilon_{t+1}$，其中 $\\varepsilon_{t+1}$ 是方差为 $\\sigma^2 = 1.0^2 = 1.0$ 的不可预测噪声。使用过去数据的最佳线性模型只能解释 $a y_t$ 部分。因此，不可约误差（贝叶斯错误率）为 $\\text{Var}(\\varepsilon_{t+1}) = \\sigma^2 = 1.0$。我们的 OLS 模型使用的信息比仅仅 $y_t$ 稍多（它还使用了一个过去的滚动均值），因此它可能实现一个略低于 1.0 的 MSE。由于有限样本效应，计算出的 MSE 将围绕这个理论值波动。条件 $\\text{MSE} \\in [0.6, 1.4]$ 为一个正确指定的、无泄露的模型提供了一个合理的范围。\n\n**测试 D：灾难性泄露的边界情况**\n该测试研究了滚动窗口大小为 $W=1$ 的极端情况。有泄露的特征变为 $g_{2,t} = \\frac{1}{1}\\sum_{j=0}^{0} y_{t+1-j} = y_{t+1}$。用于预测的特征向量是 $x_t^{\\text{leak}} = (y_t, y_{t+1}, 1)$，而目标是 $y_{t+1}$。线性回归问题是为模型 $\\hat{y}_{t+1} = \\beta_0 y_t + \\beta_1 y_{t+1} + \\beta_2$ 找到 $\\beta_0, \\beta_1, \\beta_2$。最小化平方误差的 OLS 解显然是 $\\hat{\\beta} = (0, 1, 0)^T$。模型的预测是 $\\hat{y}_{t+1} = y_{t+1}$，导致误差为零。在计算上，这将表现为一个在机器精度数量级上的 MSE，因此有条件 $\\text{MSE}  10^{-12}$。\n\n**算法实现**\n该程序将通过首先使用固定种子模拟 AR(1) 过程来实现这四个测试。然后，它将构建有泄露和无泄露的特征矩阵。对于每个测试，它将应用指定的 CV 方法，在每个折叠中使用 `numpy.linalg.lstsq` 拟合 OLS 模型，计算平均验证 MSE，并将其与指定的阈值进行比较以生成布尔结果。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a series of tests to demonstrate and quantify data leakage\n    in time series preprocessing and cross-validation.\n    \"\"\"\n\n    # --- Helper Functions ---\n\n    def simulate_ar1(N, a, sigma, y0, seed):\n        \"\"\"Simulates an AR(1) process.\"\"\"\n        np.random.seed(seed)\n        y = np.zeros(N)\n        y[0] = y0\n        innovations = np.random.normal(0, sigma, N - 1)\n        for t in range(N - 1):\n            y[t + 1] = a * y[t] + innovations[t]\n        return y\n\n    def create_feature_matrices(y, W):\n        \"\"\"\n        Constructs supervised learning matrices from a time series.\n        y: The raw time series.\n        W: The rolling window size.\n        \"\"\"\n        N = len(y)\n        # Valid time indices for features are t in [W-1, N-2]\n        # This gives (N-2) - (W-1) + 1 = N - W samples.\n        num_samples = N - W\n        \n        # Initialize matrices\n        X_past = np.zeros((num_samples, 3))\n        X_leak = np.zeros((num_samples, 3))\n        Y = np.zeros(num_samples)\n\n        for i in range(num_samples):\n            t = i + W - 1  # Time index in the original series y\n\n            # Target\n            Y[i] = y[t + 1]\n\n            # Non-leaky features (past-only)\n            past_mean = np.mean(y[t - W + 1 : t + 1])\n            X_past[i, :] = [y[t], past_mean, 1]\n\n            # Leaky features (includes future)\n            leak_mean = np.mean(y[t + 1 - W + 1 : t + 1 + 1])\n            X_leak[i, :] = [y[t], leak_mean, 1]\n            \n        return X_past, X_leak, Y\n    \n    def fit_ols_and_get_mse(X_train, Y_train, X_val, Y_val):\n        \"\"\"Fits an OLS model and computes validation MSE.\"\"\"\n        if X_train.shape[0] == 0:\n            return np.nan\n        beta, _, _, _ = np.linalg.lstsq(X_train, Y_train, rcond=None)\n        Y_pred = X_val @ beta\n        mse = np.mean((Y_val - Y_pred)**2)\n        return mse\n\n    def run_random_kfold_cv(X, Y, K, seed):\n        \"\"\"Performs random K-fold cross-validation.\"\"\"\n        np.random.seed(seed)\n        num_samples = X.shape[0]\n        indices = np.arange(num_samples)\n        np.random.shuffle(indices)\n        \n        fold_size = num_samples // K\n        mses = []\n\n        for i in range(K):\n            start = i * fold_size\n            end = (i + 1) * fold_size if i  K - 1 else num_samples\n            \n            val_indices = indices[start:end]\n            train_indices = np.setdiff1d(indices, val_indices, assume_unique=True)\n            \n            X_train, Y_train = X[train_indices], Y[train_indices]\n            X_val, Y_val = X[val_indices], Y[val_indices]\n            \n            mses.append(fit_ols_and_get_mse(X_train, Y_train, X_val, Y_val))\n            \n        return np.mean(mses)\n\n    def run_time_aware_cv(X, Y, K, n_train0, n_val):\n        \"\"\"Performs time-aware (forward-chaining) cross-validation.\"\"\"\n        mses = []\n        for i in range(K):\n            train_end_idx = n_train0 + i * n_val\n            val_end_idx = train_end_idx + n_val\n            \n            train_indices = np.arange(train_end_idx)\n            val_indices = np.arange(train_end_idx, val_end_idx)\n\n            X_train, Y_train = X[train_indices], Y[train_indices]\n            X_val, Y_val = X[val_indices], Y[val_indices]\n\n            mses.append(fit_ols_and_get_mse(X_train, Y_train, X_val, Y_val))\n        \n        return np.mean(mses)\n\n    results = []\n    \n    # --- Shared Parameters and Seeds ---\n    AR1_SEED = 42\n    CV_RANDOM_SEED = 123\n    \n    # --- Test A: Leaky features + Random CV ---\n    N_A, a_A, sigma_A, W_A, K_A = 1200, 0.8, 1.0, 5, 6\n    y_A = simulate_ar1(N_A, a_A, sigma_A, 0, seed=AR1_SEED)\n    _, X_leak_A, Y_A = create_feature_matrices(y_A, W_A)\n    mse_A = run_random_kfold_cv(X_leak_A, Y_A, K_A, seed=CV_RANDOM_SEED)\n    results.append(mse_A  0.1)\n\n    # --- Test B: Leaky features + Time-aware CV ---\n    N_B, a_B, sigma_B, W_B = 1200, 0.8, 1.0, 5\n    K_B, n_train0_B, n_val_B = 5, 500, 100\n    y_B = simulate_ar1(N_B, a_B, sigma_B, 0, seed=AR1_SEED)\n    _, X_leak_B, Y_B = create_feature_matrices(y_B, W_B)\n    mse_B = run_time_aware_cv(X_leak_B, Y_B, K_B, n_train0_B, n_val_B)\n    results.append(mse_B  0.1)\n\n    # --- Test C: Non-leaky features + Time-aware CV ---\n    N_C, a_C, sigma_C, W_C = 1200, 0.8, 1.0, 5\n    K_C, n_train0_C, n_val_C = 5, 500, 100\n    y_C = simulate_ar1(N_C, a_C, sigma_C, 0, seed=AR1_SEED)\n    X_past_C, _, Y_C = create_feature_matrices(y_C, W_C)\n    mse_C = run_time_aware_cv(X_past_C, Y_C, K_C, n_train0_C, n_val_C)\n    results.append(0.6 = mse_C = 1.4)\n\n    # --- Test D: Catastrophic leakage (W=1) + Random CV ---\n    N_D, a_D, sigma_D, W_D, K_D = 800, 0.8, 1.0, 1, 6\n    y_D = simulate_ar1(N_D, a_D, sigma_D, 0, seed=AR1_SEED)\n    _, X_leak_D, Y_D = create_feature_matrices(y_D, W_D)\n    mse_D = run_random_kfold_cv(X_leak_D, Y_D, K_D, seed=CV_RANDOM_SEED)\n    results.append(mse_D  1e-12)\n\n    # --- Final Output ---\n    # Format: [resultA,resultB,resultC,resultD]\n    print(f\"[{','.join(map(str, results))}]\".lower())\n\nsolve()\n```", "id": "3112690"}]}