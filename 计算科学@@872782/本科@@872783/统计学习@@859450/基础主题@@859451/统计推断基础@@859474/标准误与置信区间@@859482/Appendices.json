{"hands_on_practices": [{"introduction": "在掌握了单个回归系数的标准误计算之后，一个自然而然的问题是：我们如何评估多个系数线性组合（例如，两个预测变量效应之差）的不确定性？本练习将指导你动手计算回归系数线性组合的标准误和置信区间。通过这个过程，你将深刻理解系数估计值之间的协方差（体现在 $(X^\\top X)^{-1}$ 矩阵的非对角元素中）在解决此类问题时所扮演的关键角色 [@problem_id:3176582]。", "problem": "考虑一个包含截距项和两个预测变量的线性回归模型，其矩阵形式为 $y = X\\beta + \\varepsilon$，其中 $y \\in \\mathbb{R}^{n}$，$X \\in \\mathbb{R}^{n \\times p}$ 且 $p=3$，$\\beta \\in \\mathbb{R}^{3}$，$\\varepsilon \\in \\mathbb{R}^{n}$。假设误差满足 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$。令 $\\hat{\\beta}$ 为普通最小二乘 (OLS) 估计量。已知 $n=25$，残差平方和 $\\text{SSE} = 220$，且矩阵 $(X^{\\top}X)^{-1}$ 等于\n$$\n\\begin{pmatrix}\n0.50  0.02  -0.01 \\\\\n0.02  0.20  0.00 \\\\\n-0.01  0.00  0.10\n\\end{pmatrix}.\n$$\n考虑在两个协变量行向量 $x_{a}^{\\top} = \\begin{pmatrix} 1  2  -1 \\end{pmatrix}$ 和 $x_{b}^{\\top} = \\begin{pmatrix} 1  0  3 \\end{pmatrix}$ 处的预测差分泛函 $f(\\beta) = x_{a}^{\\top}\\beta - x_{b}^{\\top}\\beta$。从所述假设下 OLS 估计量分布的基本原理出发，仔细推导用 $\\hat{\\beta}$ 的协方差和 $(X^{\\top}X)^{-1}$ 表示的标准误，为 $f(\\beta)$ 构建一个双侧 $95\\%$ 置信区间。在数值计算中，使用自由度为 $n-p$ 的双侧学生t分布在置信水平 $0.95$ 下的临界值 $t_{0.975,\\,22} = 2.074$。明确指出置信区间的中心和半宽，然后仅报告半宽。将你报告的半宽四舍五入到四位有效数字。", "solution": "用户希望为回归系数的线性组合构建一个 $95\\%$ 的置信区间，并报告其半宽。\n\n### 步骤 1：提取已知条件\n- 线性模型：$y = X\\beta + \\varepsilon$\n- $y \\in \\mathbb{R}^{n}$, $X \\in \\mathbb{R}^{n \\times p}$, $\\beta \\in \\mathbb{R}^{p}$, $\\varepsilon \\in \\mathbb{R}^{n}$\n- 观测数量：$n=25$\n- 参数数量（包括截距项）：$p=3$\n- 误差分布假设：$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$\n- 残差平方和：$\\text{SSE} = 220$\n- 矩阵 $(X^{\\top}X)^{-1}$：\n$$\n(X^{\\top}X)^{-1} = \n\\begin{pmatrix}\n0.50  0.02  -0.01 \\\\\n0.02  0.20  0.00 \\\\\n-0.01  0.00  0.10\n\\end{pmatrix}\n$$\n- 目标泛函：$f(\\beta) = x_{a}^{\\top}\\beta - x_{b}^{\\top}\\beta$\n- 协变量向量：$x_{a}^{\\top} = \\begin{pmatrix} 1  2  -1 \\end{pmatrix}$ 和 $x_{b}^{\\top} = \\begin{pmatrix} 1  0  3 \\end{pmatrix}$\n- 置信水平：$95\\%$\n- 临界值：$t_{0.975,\\,22} = 2.074$ （自由度为 $n-p = 25-3=22$ 的学生t分布）\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在线性回归理论的框架内定义明确。构建置信区间所需的所有要素均已提供。假设（误差的正态性）是此类问题的标准假设。矩阵 $(X^{\\top}X)^{-1}$ 是对称的，这是此类矩阵的必要属性。该问题具有科学依据，提法恰当且客观。它没有违反任何无效标准。\n\n### 步骤 3：结论与行动\n此问题是 **有效的**。将提供完整解答。\n\n### 置信区间与半宽的推导\n$\\beta$ 的普通最小二乘 (OLS) 估计量是 $\\hat{\\beta} = (X^{\\top}X)^{-1}X^{\\top}y$。在给定假设 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$ 下，估计量 $\\hat{\\beta}$ 也服从正态分布。具体来说，其分布为：\n$$\n\\hat{\\beta} \\sim \\mathcal{N}\\left(\\beta, \\sigma^{2}(X^{\\top}X)^{-1}\\right)\n$$\n目标泛函是 $f(\\beta) = x_{a}^{\\top}\\beta - x_{b}^{\\top}\\beta$。我们可以将其表示为 $\\beta$ 各分量的线性组合：\n$$\nf(\\beta) = (x_{a} - x_{b})^{\\top}\\beta\n$$\n我们定义一个向量 $c = x_{a} - x_{b}$。那么 $f(\\beta) = c^{\\top}\\beta$。$f(\\beta)$ 的自然估计量是 $f(\\hat{\\beta}) = c^{\\top}\\hat{\\beta}$。\n\n由于 $\\hat{\\beta}$ 服从正态分布，其分量的任何线性组合（例如 $c^{\\top}\\hat{\\beta}$）也服从正态分布。\n该估计量的期望值为：\n$$\nE[f(\\hat{\\beta})] = E[c^{\\top}\\hat{\\beta}] = c^{\\top}E[\\hat{\\beta}] = c^{\\top}\\beta = f(\\beta)\n$$\n这表明 $f(\\hat{\\beta})$ 是 $f(\\beta)$ 的无偏估计量。\n该估计量的方差为：\n$$\n\\text{Var}(f(\\hat{\\beta})) = \\text{Var}(c^{\\top}\\hat{\\beta}) = c^{\\top}\\text{Cov}(\\hat{\\beta})c = c^{\\top}\\left(\\sigma^{2}(X^{\\top}X)^{-1}\\right)c = \\sigma^{2}c^{\\top}(X^{\\top}X)^{-1}c\n$$\n因此，我们估计量的分布为：\n$$\nf(\\hat{\\beta}) \\sim \\mathcal{N}\\left(f(\\beta), \\sigma^{2}c^{\\top}(X^{\\top}X)^{-1}c\\right)\n$$\n方差 $\\sigma^{2}$ 通常是未知的，必须从数据中估计。$\\sigma^{2}$ 的无偏估计量是均方误差 (MSE)，其公式为：\n$$\n\\hat{\\sigma}^{2} = \\frac{\\text{SSE}}{n-p}\n$$\n其中 $n-p$ 是残差的自由度。一个标准结论是，量 $\\frac{(n-p)\\hat{\\sigma}^{2}}{\\sigma^{2}} = \\frac{\\text{SSE}}{\\sigma^{2}}$ 服从自由度为 $n-p$ 的卡方分布，即 $\\chi_{n-p}^{2}$。\n\n为了构建置信区间，我们构造一个服从学生t分布的枢轴量。标准化的随机变量\n$$\nZ = \\frac{f(\\hat{\\beta}) - f(\\beta)}{\\sqrt{\\sigma^{2}c^{\\top}(X^{\\top}X)^{-1}c}} \\sim \\mathcal{N}(0, 1)\n$$\n是一个标准正态变量。如果我们将未知的 $\\sigma^{2}$ 替换为其估计值 $\\hat{\\sigma}^{2}$，我们得到 t 统计量：\n$$\nT = \\frac{f(\\hat{\\beta}) - f(\\beta)}{\\sqrt{\\hat{\\sigma}^{2}c^{\\top}(X^{\\top}X)^{-1}c}} = \\frac{f(\\hat{\\beta}) - f(\\beta)}{\\text{SE}(f(\\hat{\\beta}))}\n$$\n其中 $\\text{SE}(f(\\hat{\\beta})) = \\sqrt{\\hat{\\sigma}^{2}c^{\\top}(X^{\\top}X)^{-1}c}$ 是估计量 $f(\\hat{\\beta})$ 的标准误。该统计量 $T$ 服从自由度为 $n-p$ 的学生t分布。\n$$\nT \\sim t_{n-p}\n$$\n$f(\\beta)$ 的一个双侧 $(1-\\alpha)$ 置信区间是使用 t 分布的临界值 $t_{\\alpha/2, n-p}$ 构建的，使得 $P(|T| > t_{\\alpha/2, n-p}) = \\alpha$。在我们的例子中，置信水平是 $95\\%$，所以 $\\alpha = 0.05$ 且 $\\alpha/2 = 0.025$。相关的临界值由其上分位数表示，即 $t_{1-\\alpha/2, n-p} = t_{0.975, n-p}$。该区间由下式给出：\n$$\nf(\\hat{\\beta}) \\pm t_{1-\\alpha/2, n-p} \\times \\text{SE}(f(\\hat{\\beta}))\n$$\n置信区间的中心是 $f(\\hat{\\beta})$，半宽是 $W = t_{1-\\alpha/2, n-p} \\times \\text{SE}(f(\\hat{\\beta}))$。题目要求的是这个半宽。\n\n现在，我们用给定的值进行计算。\n首先，计算向量 $c$：\n$$\nc^{\\top} = x_{a}^{\\top} - x_{b}^{\\top} = \\begin{pmatrix} 1  2  -1 \\end{pmatrix} - \\begin{pmatrix} 1  0  3 \\end{pmatrix} = \\begin{pmatrix} 0  2  -4 \\end{pmatrix}\n$$\n所以，$c = \\begin{pmatrix} 0 \\\\ 2 \\\\ -4 \\end{pmatrix}$。\n\n接下来，计算误差方差的估计值 $\\hat{\\sigma}^{2}$：\n$$\n\\hat{\\sigma}^{2} = \\frac{\\text{SSE}}{n-p} = \\frac{220}{25-3} = \\frac{220}{22} = 10\n$$\n接下来，计算二次型 $c^{\\top}(X^{\\top}X)^{-1}c$：\n$$\nc^{\\top}(X^{\\top}X)^{-1} = \\begin{pmatrix} 0  2  -4 \\end{pmatrix} \\begin{pmatrix}\n0.50  0.02  -0.01 \\\\\n0.02  0.20  0.00 \\\\\n-0.01  0.00  0.10\n\\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} (0)(0.50)+(2)(0.02)+(-4)(-0.01)  (0)(0.02)+(2)(0.20)+(-4)(0.00)  (0)(-0.01)+(2)(0.00)+(-4)(0.10) \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} 0+0.04+0.04  0+0.40+0  0+0-0.40 \\end{pmatrix} = \\begin{pmatrix} 0.08  0.40  -0.40 \\end{pmatrix}\n$$\n现在，乘以 $c$：\n$$\nc^{\\top}(X^{\\top}X)^{-1}c = \\begin{pmatrix} 0.08  0.40  -0.40 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 2 \\\\ -4 \\end{pmatrix}\n$$\n$$\n= (0.08)(0) + (0.40)(2) + (-0.40)(-4) = 0 + 0.80 + 1.60 = 2.40\n$$\n现在，我们可以计算 $f(\\hat{\\beta})$ 的标准误的平方：\n$$\n\\text{SE}(f(\\hat{\\beta}))^{2} = \\hat{\\sigma}^{2} c^{\\top}(X^{\\top}X)^{-1}c = (10)(2.40) = 24\n$$\n标准误为：\n$$\n\\text{SE}(f(\\hat{\\beta})) = \\sqrt{24}\n$$\n自由度为 $n-p=22$。$95\\%$ 置信区间的临界值由题目给出，为 $t_{0.975, 22} = 2.074$。\n\n置信区间的半宽为：\n$$\nW = t_{0.975, 22} \\times \\text{SE}(f(\\hat{\\beta})) = 2.074 \\times \\sqrt{24}\n$$\n数值上，$\\sqrt{24} \\approx 4.898979...$\n$$\nW = 2.074 \\times 4.898979... \\approx 10.158683...\n$$\n将此结果四舍五入到四位有效数字，得到 $10.16$。\n置信区间的中心是 $f(\\hat{\\beta}) = c^{\\top}\\hat{\\beta}$，我们不需要计算它。半宽是所要求的值。\n半宽是 $10.16$。", "answer": "$$\n\\boxed{10.16}\n$$", "id": "3176582"}, {"introduction": "在回归分析中，截距 $\\beta_0$ 的置信区间通常会自动报告，但它在所有情况下都有意义吗？本练习通过一个思想实验，让你探究实验设计（特别是预测变量 $x$ 的取值范围）如何影响截距估计的稳定性。你会发现，当数据点远离 $x=0$ 时，对截距的推断本质上是一种外推，这可能导致其置信区间变得非常宽，失去实际参考价值 [@problem_id:3176623]。这个练习强调了理解回归统计量背后几何直觉的重要性。", "problem": "一位研究人员拟合了一个形式为 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ 的简单线性回归模型，其中 $\\varepsilon_i \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^2)$（独立同分布，均值为 $0$，方差为 $\\sigma^2$）。在经典线性模型下，普通最小二乘（OLS）估计量是无偏的，其抽样变异性由设计矩阵和 $\\sigma^2$ 决定。\n\n为研究当预测变量范围极小时，截距估计量的不确定性如何表现，我们考虑三种实验设计，每种设计的样本量均为 $n = 30$，且误差方差 $\\sigma^2$ 相同：\n\n- 设计 A：$x_i$ 在 $[9.8, 10.2]$ 上均匀分布。\n- 设计 B：$x_i$ 在 $[0.0, 0.4]$ 上均匀分布。\n- 设计 C：$x_i$ 在 $[-0.2, 0.2]$ 上均匀分布。\n\n假设拟合的模型在不同设计中产生相似的残差标准差（因此截距不确定性的差异是由 $x$ 的设计驱动的）。您为每种设计中的截距 $\\beta_0$ 计算一个 $95\\%$ 的置信区间。\n\n下列哪个陈述最好地描述了在这种情况下截距的置信区间何时会宽到没有信息量，并正确解释了截距估计量的标准误 $\\operatorname{SE}(\\hat{\\beta}_0)$ 如何依赖于 $\\bar{x}$ 和 $\\sum_{i=1}^{n} (x_i - \\bar{x})^2$？\n\nA. 当预测变量范围很小时，如果 $|\\bar{x}|$ 很大，截距的置信区间可能会非常宽，因为从远离 $x=0$ 的数据进行外推会增大 $\\operatorname{SE}(\\hat{\\beta}_0)$。具体来说，$\\operatorname{SE}(\\hat{\\beta}_0)$ 随 $|\\bar{x}|$ 的增大而增大，随 $\\sum_{i=1}^{n} (x_i - \\bar{x})^2$ 的增大而减小。因此，设计 A 产生的截距区间比设计 B 和 C 的宽得多。\n\nB. 截距的标准误随 $\\sum_{i=1}^{n} (x_i - \\bar{x})^2$ 的增大而增大，并且基本上与 $\\bar{x}$ 无关。因此，一个很小的预测变量范围会直接收窄截距的区间，除非误差是异方差的。\n\nC. 一个很小的预测变量范围总是会收窄截距的置信区间，因为 $x$ 的变异性较小会降低整体不确定性；较大的 $|\\bar{x}|$ 会因在较大的 $x$ 处有更高的杠杆率而稳定截距。\n\nD. 截距的标准误近似等于残差标准差除以 $\\sqrt{n}$，无论 $\\bar{x}$ 或 $x_i$ 的散布程度如何。因此，如果残差变异性相似，所有三种设计都应该产生相似的截距区间。", "solution": "用户希望我遵循一位严谨的STEM教授的角色来解决一个统计学问题。我将首先验证问题陈述，然后基于第一性原理推导解决方案，最后评估每个选项。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n- **模型：** 简单线性回归，$y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$。\n- **误差项：** $\\varepsilon_i \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^2)$（独立同分布的正态分布，均值为 $0$，方差为 $\\sigma^2$）。\n- **估计量：** 普通最小二乘法（OLS）。\n- **样本量：** 所有设计均为 $n = 30$。\n- **误差方差：** 所有设计的 $\\sigma^2$ 相同。\n- **假设：** 所有设计的残差标准差相似。\n- **设计 A：** $x_i$ 在 $[9.8, 10.2]$ 上均匀分布。\n- **设计 B：** $x_i$ 在 $[0.0, 0.4]$ 上均匀分布。\n- **设计 C：** $x_i$ 在 $[-0.2, 0.2]$ 上均匀分布。\n- **任务：** 描述截距 $\\beta_0$ 的置信区间的特征，并解释其标准误 $\\operatorname{SE}(\\hat{\\beta}_0)$ 对预测变量均值 $\\bar{x}$ 和离差平方和 $\\sum_{i=1}^{n} (x_i - \\bar{x})^2$ 的依赖关系。\n\n**步骤 2：使用提取的已知条件进行验证**\n1.  **科学上成立：** 该问题牢固地建立在经典线性回归模型框架内，这是统计学的基石。模型、假设和概念（标准误、置信区间）都是标准的且在数学上是合理的。\n2.  **问题定义良好：** 问题提供了足够的信息来确定截距估计量标准误的函数形式，并定性地比较其在三种指定设计中的量级。可以得出一个唯一的概念性结论。\n3.  **客观性：** 语言清晰、精确，没有主观陈述。设计被客观地指定。\n4.  **完整性：** 问题是自洽的。分析截距不确定性所需的所有必要组成部分（$n$、模型形式、误差结构以及预测变量设计的具体细节）都已提供。残差标准差相似的假设简化了比较，按预期将其重点放在设计矩阵上。\n\n**步骤 3：结论与行动**\n问题陈述是有效的。这是一个在回归分析中表述良好的概念性问题。我现在将开始推导解决方案。\n\n### 解决方案推导\n\n分析的核心是 OLS 截距估计量 $\\hat{\\beta}_0$ 的方差公式，以及由此得到的标准误。在简单线性回归模型中，OLS 估计量由以下公式给出：\n$$ \\hat{\\beta}_1 = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} $$\n$$ \\hat{\\beta}_0 = \\bar{y} - \\hat{\\beta}_1 \\bar{x} $$\n其中 $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$ 且 $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i$。\n\n为了找到 $\\hat{\\beta}_0$ 的标准误，我们必须首先推导其方差。我们利用方差的性质以及在模型假设下 $\\operatorname{Cov}(\\bar{y}, \\hat{\\beta}_1) = 0$ 这一事实。\n$$ \\operatorname{Var}(\\hat{\\beta}_0) = \\operatorname{Var}(\\bar{y} - \\hat{\\beta}_1 \\bar{x}) $$\n$$ \\operatorname{Var}(\\hat{\\beta}_0) = \\operatorname{Var}(\\bar{y}) + \\bar{x}^2 \\operatorname{Var}(\\hat{\\beta}_1) - 2\\bar{x}\\operatorname{Cov}(\\bar{y}, \\hat{\\beta}_1) $$\n所需的组成部分是：\n-   $\\operatorname{Var}(\\bar{y}) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{i=1}^n y_i\\right) = \\frac{1}{n^2}\\sum_{i=1}^n \\operatorname{Var}(y_i) = \\frac{n\\sigma^2}{n^2} = \\frac{\\sigma^2}{n}$。\n-   $\\operatorname{Var}(\\hat{\\beta}_1) = \\frac{\\sigma^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}$。\n-   $\\operatorname{Cov}(\\bar{y}, \\hat{\\beta}_1) = 0$。这是一个标准结果；中心化的预测变量与响应变量的样本均值不相关。\n\n将这些代入 $\\hat{\\beta}_0$ 的方差表达式中：\n$$ \\operatorname{Var}(\\hat{\\beta}_0) = \\frac{\\sigma^2}{n} + \\bar{x}^2 \\frac{\\sigma^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} $$\n$$ \\operatorname{Var}(\\hat{\\beta}_0) = \\sigma^2 \\left( \\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\right) $$\n\n标准误 $\\operatorname{SE}(\\hat{\\beta}_0)$ 是估计方差的平方根，其中 $\\sigma^2$ 被其估计量 $\\hat{\\sigma}^2$（残差方差，通常写作 $s^2$ 或 $RSE^2$）替代。\n$$ \\operatorname{SE}(\\hat{\\beta}_0) = \\hat{\\sigma} \\sqrt{\\frac{1}{n} + \\frac{\\bar{x}^2}{\\sum_{i=1}^{n} (x_i - \\bar{x})^2}} $$\n$\\beta_0$ 的 $95\\%$ 置信区间的宽度与 $\\operatorname{SE}(\\hat{\\beta}_0)$ 成正比：$2 \\times t_{n-2, 0.975} \\times \\operatorname{SE}(\\hat{\\beta}_0)$。由于假设 $n$ 和 $\\hat{\\sigma}$ 在不同设计中是恒定的，区间宽度由平方根下的项决定。\n\n这个公式揭示了两个关键的依赖关系：\n1.  由于 $\\bar{x}^2$ 项的存在，标准误随 $|\\bar{x}|$ 的增大而增大。这反映了从数据中心（$\\bar{x}$）外推到 $x=0$ 处的 y 轴截距所引入的不确定性。\n2.  标准误随预测变量的散布程度 $\\sum_{i=1}^{n} (x_i - \\bar{x})^2$ 的增大而减小。更大的散布范围提供了更稳定的回归线。\n\n问题陈述所有三种设计的预测变量范围都“很小”。让我们来分析这些设计：\n-   所有设计的样本量均为 $n=30$，预测变量范围均为 $0.4$。由于点是均匀分布的，离差平方和 $S_{xx} = \\sum_{i=1}^{n} (x_i - \\bar{x})^2$ 对于所有三种设计将是相同且很小的。\n-   关键区别在于预测变量的均值 $\\bar{x}$：\n    -   **设计 A：** $x_i \\in [9.8, 10.2] \\implies \\bar{x}_A = 10.0$。\n    -   **设计 B：** $x_i \\in [0.0, 0.4] \\implies \\bar{x}_B = 0.2$。\n    -   **设计 C：** $x_i \\in [-0.2, 0.2] \\implies \\bar{x}_C = 0.0$。\n\n现在我们为每个设计比较 $\\frac{\\bar{x}^2}{\\sum (x_i - \\bar{x})^2}$ 这一项：\n-   **设计 A：** $\\frac{(10.0)^2}{S_{xx}} = \\frac{100}{S_{xx}}$。由于 $S_{xx}$ 很小，这一项非常大。\n-   **设计 B：** $\\frac{(0.2)^2}{S_{xx}} = \\frac{0.04}{S_{xx}}$。这一项比设计 A 的小得多。\n-   **设计 C：** $\\frac{(0.0)^2}{S_{xx}} = 0$。不确定性被最小化，且 $\\operatorname{SE}(\\hat{\\beta}_0) = \\hat{\\sigma}/\\sqrt{n}$。\n\n结论：当预测变量范围很小（$S_{xx}$ 很小）时，截距的不确定性主要由外推距离 $|\\bar{x}|$ 决定。设计 A 涉及从以 $\\bar{x}=10.0$ 为中心的数据到 $x=0$ 的大规模外推，导致一个极大的标准误和一个宽的、信息量不足的 $\\beta_0$ 置信区间。设计 B 和 C 的数据更接近 $x=0$，因此它们的置信区间将显著更窄。具体来说，设计 A 将产生比 B 和 C 宽得多的区间。\n\n### 逐项分析\n\n**A. 当预测变量范围很小时，如果 $|\\bar{x}|$ 很大，截距的置信区间可能会非常宽，因为从远离 $x=0$ 的数据进行外推会增大 $\\operatorname{SE}(\\hat{\\beta}_0)$。具体来说，$\\operatorname{SE}(\\hat{\\beta}_0)$ 随 $|\\bar{x}|$ 的增大而增大，随 $\\sum_{i=1}^{n} (x_i - \\bar{x})^2$ 的增大而减小。因此，设计 A 产生的截距区间比设计 B 和 C 的宽得多。**\n这个陈述与我们的推导完全一致。它正确地指出了当 $|\\bar{x}|$ 很大时外推的作用，正确地陈述了 $\\operatorname{SE}(\\hat{\\beta}_0)$ 对 $|\\bar{x}|$ 和 $\\sum_{i=1}^{n} (x_i - \\bar{x})^2$ 的数学依赖关系，并正确地比较了三种设计。\n**结论：正确**\n\n**B. 截距的标准误随 $\\sum_{i=1}^{n} (x_i - \\bar{x})^2$ 的增大而增大，并且基本上与 $\\bar{x}$ 无关。因此，一个很小的预测变量范围会直接收窄截距的区间，除非误差是异方差的。**\n这个陈述在多个方面都是不正确的。首先，$\\operatorname{SE}(\\hat{\\beta}_0)$ 随 $\\sum_{i=1}^{n} (x_i - \\bar{x})^2$ 的增大而*减小*，因为该项出现在分母中。其次，它强烈依赖于 $\\bar{x}$，除非在 $\\bar{x} \\approx 0$ 的特殊情况下。\n**结论：不正确**\n\n**C. 一个很小的预测变量范围总是会收窄截距的置信区间，因为 $x$ 的变异性较小会降低整体不确定性；较大的 $|\\bar{x}|$ 会因在较大的 $x$ 处有更高的杠杆率而稳定截距。**\n这个陈述有根本性的错误。一个很小的预测变量范围（小的 $\\sum(x_i - \\bar{x})^2$）会*增加*斜率的不确定性，这反过来又会影响截距的不确定性。此外，较大的 $|\\bar{x}|$ 由于需要外推而极大地*破坏*了截距估计的稳定性，正如方差公式分子中的 $\\bar{x}^2$ 项所示。\n**结论：不正确**\n\n**D. 截距的标准误近似等于残差标准差除以 $\\sqrt{n}$，无论 $\\bar{x}$ 或 $x_i$ 的散布程度如何。因此，如果残差变异性相似，所有三种设计都应该产生相似的截距区间。**\n这个陈述将一个特例描述为普遍规则。公式 $\\operatorname{SE}(\\hat{\\beta}_0) \\approx \\hat{\\sigma}/\\sqrt{n}$ 仅在 $\\frac{\\bar{x}^2}{\\sum(x_i - \\bar{x})^2}$ 项可以忽略不计时才有效，这要求 $\\bar{x} \\approx 0$。这对设计 C 成立，但对设计 A 则大错特错。因此，所有设计将有相似区间的说法是不正确的。\n**结论：不正确**", "answer": "$$\\boxed{A}$$", "id": "3176623"}, {"introduction": "理论公式为我们提供了计算标准误的解析路径，但这依赖于一系列经典假设。在现实世界中，当这些假设受到挑战时，我们该怎么办？这个最终的实践练习将带你进入计算统计的世界，你将亲手编程实现并比较三种估计标准误的方法：经典解析法、刀切法 (jackknife) 和非参数自助法 (bootstrap) [@problem_id:3176572]。通过在含有高杠杆点等挑战性特征的数据上应用这些技术，你将获得宝贵的实战经验，并对不同方法的优缺点形成更深刻的理解。", "problem": "考虑一个经典的线性回归设定，其中观测到的响应向量 $y \\in \\mathbb{R}^n$ 被建模为 $y = X \\beta + \\varepsilon$，其中设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，系数向量为 $\\beta \\in \\mathbb{R}^p$，噪声向量为 $\\varepsilon \\in \\mathbb{R}^n$。假设 $\\varepsilon$ 的均值为零且方差有限，并使用普通最小二乘法 (OLS) 估计。在本问题中，您将使用三种方法——经典线性模型假设下的解析方法、通过留一法实现的刀切法以及非参数自助法——来估计单个系数 $\\hat{\\beta}_j$ 的标准误 (SE)，然后为杠杆敏感设计构建并比较 $95\\%$ 置信区间 (CI)。\n\n您必须实现一个程序，该程序能够：\n- 推导普通最小二乘法 (OLS) 系数估计，其中普通最小二乘法 (OLS) 意味着选择 $\\hat{\\beta}$ 以最小化残差平方和。\n- 使用经典线性模型假设和根据残差估计的误差方差，获得所选坐标 $\\hat{\\beta}_j$ 的解析标准误 (SE)。使用具有 $n - p$ 自由度的学生 t 分布构建一个双侧 $95\\%$ 置信区间 (CI)。\n- 通过依次系统地排除每个观测值并汇总留一法估计值，计算 $\\hat{\\beta}_j$ 的刀切法标准误。使用与解析置信区间中相同的基于 t 分布的分位数，构建一个双侧 $95\\%$ 置信区间。\n- 通过对 $(X, y)$ 的行进行有放回重采样（指定的次数为 $B$），为每个自助样本重新估计 $\\hat{\\beta}_j$，并取 $2.5\\%$ 和 $97.5\\%$ 的经验分位数，来计算自助法标准误和一个百分位 $95\\%$ 置信区间。\n\n您必须专注于杠杆敏感设计（即，其中 $X$ 的某些行对拟合产生异常高影响的设计）。实验是完全指定且确定性的：您的程序必须使用提供的种子和参数生成 $y$，然后报告每个测试用例所要求的指标。\n\n您必须使用的基本原理：\n- 经典线性模型下的普通最小二乘法 (OLS) 估计器。\n- 回归设计中的杠杆概念（即 $X$ 中能够强烈影响拟合的行）。\n- 刀切法和自助法的重采样原理。\n\n不要在问题陈述中使用或引用快捷公式。您的实现应从这些原理出发，符合逻辑。\n\n测试套件：\n- 案例 A（均衡设计，低杠杆）：\n  - 设 $n = 40, p = 2$，并设 $x$ 是在 $[-2, 2]$ 区间上均匀分布的 $40$ 个点。定义 $X = [\\mathbf{1}, x]$（一个截距项和一个预测变量）。\n  - 真实系数 $\\beta^\\star = [1.0, 2.0]$。\n  - 噪声是独立的正态分布，标准差为 $\\sigma = 0.5$。\n  - 使用随机种子 $123$ 生成 $y = X \\beta^\\star + \\varepsilon$。\n  - 目标索引 $j = 1$（$x$ 的斜率）。\n  - 自助法重复次数 $B = 1000$，自助法种子为 $321$。\n\n- 案例 B（一个极端杠杆点，相同维度）：\n  - 设 $n = 40, p = 2$，并设 $x$ 是在 $[-1, 1]$ 区间上均匀分布的 $40$ 个点，但将其第一个元素设置为 $10.0$。定义 $X = [\\mathbf{1}, x]$。\n  - 真实系数 $\\beta^\\star = [1.0, 2.0]$。\n  - 噪声是独立的正态分布，标准差为 $\\sigma = 0.5$。\n  - 使用随机种子 $456$ 生成 $y = X \\beta^\\star + \\varepsilon$。\n  - 目标索引 $j = 1$（$x$ 的斜率）。\n  - 自助法重复次数 $B = 1000$，自助法种子为 $654$。\n\n- 案例 C（存在杠杆点的近共线性，三个预测变量包括截距）：\n  - 设 $n = 12, p = 3$。设 $x_1$ 是在 $[-1, 1]$ 区间上均匀分布的 $12$ 个点，并定义 $x_2 = 0.98 x_1 + 0.02 \\sin(k)$，其中 $k = 0, 1, \\dots, 11$，然后设置 $x_1[11] = 5.0$ 和 $x_2[11] = 4.9$。定义 $X = [\\mathbf{1}, x_1, x_2]$。\n  - 真实系数 $\\beta^\\star = [0.5, 1.5, -0.5]$。\n  - 噪声是独立的正态分布，标准差为 $\\sigma = 0.8$。\n  - 使用随机种子 $789$ 生成 $y = X \\beta^\\star + \\varepsilon$。\n  - 目标索引 $j = 2$（$x_2$ 上的系数）。\n  - 自助法重复次数 $B = 2000$，自助法种子为 $987$。\n\n对于每个测试用例，按顺序计算并返回：\n1. $\\hat{\\beta}_j$ 的解析标准误（一个浮点数）。\n2. $\\hat{\\beta}_j$ 的自助法标准误（一个浮点数）。\n3. $\\hat{\\beta}_j$ 的刀切法标准误（一个浮点数）。\n4. 解析置信区间宽度（一个浮点数）。\n5. 自助法百分位置信区间宽度（一个浮点数）。\n6. 刀切法置信区间宽度（一个浮点数）。\n7. 解析置信区间是否包含真实系数 $\\beta^\\star_j$？（一个布尔值）。\n8. 自助法百分位置信区间是否包含 $\\beta^\\star_j$？（一个布尔值）。\n9. 刀切法置信区间是否包含 $\\beta^\\star_j$？（一个布尔值）。\n\n您的程序应生成单行输出，其中包含一个逗号分隔的列表，该列表由三个用方括号括起来的、按测试套件顺序排列的各案例列表组成。例如，最终打印的行必须如下所示：\n$[[r_{A,1}, r_{A,2}, \\dots, r_{A,9}], [r_{B,1}, \\dots, r_{B,9}], [r_{C,1}, \\dots, r_{C,9}]]$，\n其中所有的 $r_{*,*}$ 是为每个案例计算的浮点数或布尔值。不需要单位；将量表示为无量纲的浮点数和布尔值。", "solution": "该问题被评估为有效，其科学依据植根于统计回归理论，问题陈述清晰，所有必要的参数和条件均已指定，并且其表述是客观的。我们将继续推导必要的公式并构建解决方案。\n\n### 1. 普通最小二乘法 (OLS) 估计\n\n经典线性回归模型由 $y = X \\beta + \\varepsilon$ 给出，其中 $y \\in \\mathbb{R}^n$ 是响应向量，$X \\in \\mathbb{R}^{n \\times p}$ 是设计矩阵，$\\beta \\in \\mathbb{R}^p$ 是系数向量，$\\varepsilon \\in \\mathbb{R}^n$ 是噪声向量。普通最小二乘法 (OLS) 估计量，记为 $\\hat{\\beta}$，是使残差平方和 (RSS) 最小化的 $\\beta$ 值：\n$$\nS(\\beta) = \\|y - X\\beta\\|^2_2 = (y - X\\beta)^T (y - X\\beta)\n$$\n为了找到最小值，我们对 $S(\\beta)$ 关于 $\\beta$ 求导，并令梯度为零：\n$$\n\\frac{\\partial S(\\beta)}{\\partial \\beta} = -2X^T(y - X\\beta) = 0\n$$\n这导出了正规方程：\n$$\n(X^T X) \\hat{\\beta} = X^T y\n$$\n假设矩阵 $X^T X$ 是可逆的（即 $X$ 具有满列秩），则唯一的 OLS 解为：\n$$\n\\hat{\\beta} = (X^T X)^{-1} X^T y\n$$\n该估计量是 $y$ 的线性函数。为了数值稳定性，直接求解该线性方程组比计算 $X^T X$ 的逆矩阵更可取。\n\n### 2. 解析标准误与置信区间\n\n在经典线性模型 (CLM) 假设下，误差 $\\varepsilon_i$ 是不相关的，并且具有恒定方差 $\\sigma^2$，即 $\\text{Cov}(\\varepsilon) = \\sigma^2 I_n$，其中 $I_n$ 是 $n \\times n$ 的单位矩阵。OLS 估计量 $\\hat{\\beta}$ 的协方差矩阵是：\n$$\n\\text{Cov}(\\hat{\\beta}) = \\text{Cov}((X^T X)^{-1} X^T y) = (X^T X)^{-1} X^T \\text{Cov}(y) X (X^T X)^{-1}\n$$\n由于 $\\text{Cov}(y) = \\text{Cov}(X\\beta + \\varepsilon) = \\text{Cov}(\\varepsilon) = \\sigma^2 I_n$，这可以简化为：\n$$\n\\text{Cov}(\\hat{\\beta}) = \\sigma^2 (X^T X)^{-1}\n$$\n单个系数估计 $\\hat{\\beta}_j$（对于 $j \\in \\{0, 1, \\dots, p-1\\}$）的方差是该矩阵的第 $j$ 个对角元素：\n$$\n\\text{Var}(\\hat{\\beta}_j) = \\sigma^2 \\left[(X^T X)^{-1}\\right]_{jj}\n$$\n在实践中，真实的误差方差 $\\sigma^2$ 是未知的，必须从数据中估计。$\\sigma^2$ 的一个无偏估计量是：\n$$\n\\hat{\\sigma}^2 = \\frac{1}{n-p} \\sum_{i=1}^n e_i^2 = \\frac{\\text{RSS}}{n-p}\n$$\n其中 $e = y - X\\hat{\\beta}$ 是残差。分母 $n-p$ 代表残差的自由度。\n$\\hat{\\beta}_j$ 的估计标准误 (SE) 是估计方差的平方根：\n$$\n\\text{SE}_{\\text{analytic}}(\\hat{\\beta}_j) = \\sqrt{\\hat{\\sigma}^2 \\left[(X^T X)^{-1}\\right]_{jj}} = \\hat{\\sigma} \\sqrt{\\left[(X^T X)^{-1}\\right]_{jj}}\n$$\n假设误差也服从正态分布，则量 $\\frac{\\hat{\\beta}_j - \\beta_j}{\\text{SE}(\\hat{\\beta}_j)}$ 服从具有 $n-p$ 自由度的学生 t 分布。$\\beta_j$ 的一个双侧 $(1-\\alpha) \\cdot 100\\%$ 置信区间 (CI) 构建如下：\n$$\n\\text{CI}_{\\text{analytic}} = \\left[ \\hat{\\beta}_j - t_{1-\\alpha/2, n-p} \\cdot \\text{SE}_{\\text{analytic}}(\\hat{\\beta}_j), \\quad \\hat{\\beta}_j + t_{1-\\alpha/2, n-p} \\cdot \\text{SE}_{\\text{analytic}}(\\hat{\\beta}_j) \\right]\n$$\n其中 $t_{1-\\alpha/2, n-p}$ 是 $t_{n-p}$ 分布的 $(1-\\alpha/2)$-分位数。对于 $95\\%$ 的置信区间，$\\alpha = 0.05$。该区间的宽度为 $2 \\cdot t_{0.975, n-p} \\cdot \\text{SE}_{\\text{analytic}}(\\hat{\\beta}_j)$。\n\n### 3. 刀切法标准误与置信区间\n\n刀切法是一种重采样技术，它通过每次系统地排除一个观测值来估计估计量的方差。设 $\\hat{\\beta}$ 是来自大小为 $n$ 的完整数据集的估计值。\n1. 对于每个 $i = 1, \\dots, n$，通过从 $X$ 和 $y$ 中移除第 $i$ 行来形成第 $i$ 个留一数据集，记为 $(X_{(-i)}, y_{(-i)})$。\n2. 对这 $n$ 个数据集中的每一个计算 OLS 估计：$\\hat{\\beta}_{(-i)} = (X_{(-i)}^T X_{(-i)})^{-1} X_{(-i)}^T y_{(-i)}$。\n3. 我们关注目标系数，得到 $n$ 个估计值 $\\{\\hat{\\beta}_{j,(-1)}, \\dots, \\hat{\\beta}_{j,(-n)}\\}$。\n4. $\\hat{\\beta}_j$ 的刀切法方差估计由下式给出：\n$$\n\\widehat{\\text{Var}}_{\\text{jack}}(\\hat{\\beta}_j) = \\frac{n-1}{n} \\sum_{i=1}^n (\\hat{\\beta}_{j,(-i)} - \\bar{\\beta}_j)^2\n$$\n其中 $\\bar{\\beta}_j = \\frac{1}{n} \\sum_{i=1}^n \\hat{\\beta}_{j,(-i)}$ 是留一法估计值的均值。\n5. 刀切法标准误是该方差的平方根：\n$$\n\\text{SE}_{\\text{jack}}(\\hat{\\beta}_j) = \\sqrt{\\widehat{\\text{Var}}_{\\text{jack}}(\\hat{\\beta}_j)}\n$$\n根据规定，刀切法置信区间围绕全样本估计 $\\hat{\\beta}_j$ 对称构建，使用与解析方法相同的 t-分位数：\n$$\n\\text{CI}_{\\text{jack}} = \\left[ \\hat{\\beta}_j - t_{1-\\alpha/2, n-p} \\cdot \\text{SE}_{\\text{jack}}(\\hat{\\beta}_j), \\quad \\hat{\\beta}_j + t_{1-\\alpha/2, n-p} \\cdot \\text{SE}_{\\text{jack}}(\\hat{\\beta}_j) \\right]\n$$\n其宽度为 $2 \\cdot t_{0.975, n-p} \\cdot \\text{SE}_{\\text{jack}}(\\hat{\\beta}_j)$。\n\n### 4. 自助法标准误与置信区间\n\n非参数自助法通过从原始数据中有放回地重采样来生成重复数据集。这种方法不依赖于 CLM 假设。\n1. 指定自助法重复次数 $B$。\n2. 对于每次重复 $b = 1, \\dots, B$：\n    a. 通过从原始数据 $(X, y)$ 中有放回地抽取 $n$ 行来创建一个自助样本 $(X^*_b, y^*_b)$。\n    b. 在此自助样本上计算 OLS 估计：$\\hat{\\beta}^*_b = (X^{*T}_b X^*_b)^{-1} X^{*T}_b y^*_b$。请注意，某些自助样本可能导致奇异的 $X^{*T}_b X^*_b$ 矩阵，尤其是在高杠杆设计中。在这种情况下，可以使用广义逆矩阵（例如 Moore-Penrose 伪逆矩阵）来找到最小范数最小二乘解。\n3. 此过程产生 $B$ 个自助系数向量的集合，$\\{\\hat{\\beta}^*_1, \\dots, \\hat{\\beta}^*_B\\}$。考虑目标系数的分布，$\\{\\hat{\\beta}^*_{j,1}, \\dots, \\hat{\\beta}^*_{j,B}\\}$。\n4. 自助法标准误是这些自助估计值的样本标准差：\n$$\n\\text{SE}_{\\text{boot}}(\\hat{\\beta}_j) = \\sqrt{\\frac{1}{B-1} \\sum_{b=1}^B (\\hat{\\beta}^*_{j,b} - \\bar{\\beta}^*_j)^2}, \\text{ 其中 } \\bar{\\beta}^*_j = \\frac{1}{B} \\sum_{b=1}^B \\hat{\\beta}^*_{j,b}\n$$\n5. 百分位自助法置信区间直接从自助估计值的经验分布构建。$(1-\\alpha) \\cdot 100\\%$ 百分位置信区间由排序后的自助重复样本的 $(\\alpha/2)$ 和 $(1-\\alpha/2)$ 分位数给出。对于 $95\\%$ 的置信区间：\n$$\n\\text{CI}_{\\text{percentile}} = [q_{0.025}, q_{0.975}]\n$$\n其中 $q_{p}$ 是集合 $\\{\\hat{\\beta}^*_{j,1}, \\dots, \\hat{\\beta}^*_{j,B}\\}$ 的第 $p$ 个经验分位数。该区间的宽度是 $q_{0.975} - q_{0.025}$。这种方法的优点是，如果自助分布是偏态的（这在存在有影响的数据点时经常发生），它可以产生不对称的区间。\n\n程序现在将为每个指定的测试用例实现这三种方法。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n\n    test_cases = [\n        # Case A: Balanced design, low leverage\n        {\n            \"n\": 40, \"p\": 2,\n            \"x_def\": lambda n: (np.c_[np.ones(n), np.linspace(-2, 2, n)], None),\n            \"beta_star\": np.array([1.0, 2.0]),\n            \"sigma\": 0.5,\n            \"y_seed\": 123,\n            \"target_j\": 1,\n            \"B\": 1000,\n            \"bootstrap_seed\": 321\n        },\n        # Case B: One extreme leverage point\n        {\n            \"n\": 40, \"p\": 2,\n            \"x_def\": lambda n: (\n                np.c_[np.ones(n), (lambda x: (x.__setitem__(0, 10.0), x)[1])(np.linspace(-1, 1, n))], None\n            ),\n            \"beta_star\": np.array([1.0, 2.0]),\n            \"sigma\": 0.5,\n            \"y_seed\": 456,\n            \"target_j\": 1,\n            \"B\": 1000,\n            \"bootstrap_seed\": 654\n        },\n        # Case C: Near-collinearity with a leverage point\n        {\n            \"n\": 12, \"p\": 3,\n            \"x_def\": lambda n: (\n                (lambda x1, x2: (\n                    (x1.__setitem__(n-1, 5.0), x2.__setitem__(n-1, 4.9)),\n                    np.c_[np.ones(n), x1, x2]\n                )[1])(np.linspace(-1, 1, n), 0.98 * np.linspace(-1, 1, n) + 0.02 * np.sin(np.arange(n))),\n                None\n            ),\n            \"beta_star\": np.array([0.5, 1.5, -0.5]),\n            \"sigma\": 0.8,\n            \"y_seed\": 789,\n            \"target_j\": 2,\n            \"B\": 2000,\n            \"bootstrap_seed\": 987\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        results = run_case(case)\n        all_results.append(results)\n\n    # Convert boolean to lower case string representation for printing\n    # This formatting part is outside the scope of the core logic, for display only.\n    final_output_str = str(all_results).replace(\"True\", \"true\").replace(\"False\", \"false\")\n    print(final_output_str)\n\n\ndef get_ols_estimate(X, y):\n    \"\"\"\n    Computes OLS estimates using np.linalg.lstsq for numerical stability.\n    \"\"\"\n    beta_hat, _, _, _ = np.linalg.lstsq(X, y, rcond=None)\n    return beta_hat\n\ndef run_case(params):\n    \"\"\"\n    Runs a single test case and computes all required metrics.\n    \"\"\"\n    n, p = params[\"n\"], params[\"p\"]\n    X, _ = params[\"x_def\"](n)\n    beta_star = params[\"beta_star\"]\n    sigma = params[\"sigma\"]\n    y_seed = params[\"y_seed\"]\n    target_j = params[\"target_j\"]\n    B = params[\"B\"]\n    bootstrap_seed = params[\"bootstrap_seed\"]\n    \n    # Generate response vector y\n    rng_y = np.random.default_rng(y_seed)\n    epsilon = rng_y.normal(0, sigma, n)\n    y = X @ beta_star + epsilon\n\n    # --- Full Sample OLS ---\n    beta_hat = get_ols_estimate(X, y)\n    beta_hat_j = beta_hat[target_j]\n\n    # --- 1. Analytic Method ---\n    residuals = y - X @ beta_hat\n    rss = residuals.T @ residuals\n    sigma_hat_sq = rss / (n - p)\n    sigma_hat = np.sqrt(sigma_hat_sq)\n    \n    try:\n        C = np.linalg.inv(X.T @ X)\n        analytic_se = sigma_hat * np.sqrt(C[target_j, target_j])\n        \n        df = n - p\n        t_crit = t.ppf(0.975, df)\n        analytic_ci_half_width = t_crit * analytic_se\n        analytic_ci = [beta_hat_j - analytic_ci_half_width, beta_hat_j + analytic_ci_half_width]\n        analytic_ci_width = 2 * analytic_ci_half_width\n        analytic_contains_true = (analytic_ci[0] = beta_star[target_j] = analytic_ci[1])\n    except np.linalg.LinAlgError:\n        analytic_se = np.nan\n        analytic_ci_width = np.nan\n        analytic_contains_true = False\n        t_crit = t.ppf(0.975, n - p) # still need for jackknife\n\n    # --- 2. Bootstrap Method ---\n    rng_boot = np.random.default_rng(bootstrap_seed)\n    bootstrap_betas_j = []\n    \n    for _ in range(B):\n        indices = rng_boot.choice(n, size=n, replace=True)\n        X_boot, y_boot = X[indices], y[indices]\n        \n        beta_boot = get_ols_estimate(X_boot, y_boot)\n        bootstrap_betas_j.append(beta_boot[target_j])\n\n    bootstrap_betas_j = np.array(bootstrap_betas_j)\n    \n    bootstrap_se = np.std(bootstrap_betas_j, ddof=1)\n    \n    bootstrap_ci = np.quantile(bootstrap_betas_j, [0.025, 0.975])\n    bootstrap_ci_width = bootstrap_ci[1] - bootstrap_ci[0]\n    bootstrap_contains_true = (bootstrap_ci[0] = beta_star[target_j] = bootstrap_ci[1])\n\n    # --- 3. Jackknife Method ---\n    jackknife_betas_j = []\n    for i in range(n):\n        X_jack = np.delete(X, i, axis=0)\n        y_jack = np.delete(y, i, axis=0)\n        \n        beta_jack = get_ols_estimate(X_jack, y_jack)\n        jackknife_betas_j.append(beta_jack[target_j])\n    \n    jackknife_betas_j = np.array(jackknife_betas_j)\n    beta_j_bar_jack = np.mean(jackknife_betas_j)\n    \n    jackknife_var = ((n - 1) / n) * np.sum((jackknife_betas_j - beta_j_bar_jack)**2)\n    jackknife_se = np.sqrt(jackknife_var)\n    \n    jackknife_ci_half_width = t_crit * jackknife_se\n    jackknife_ci = [beta_hat_j - jackknife_ci_half_width, beta_hat_j + jackknife_ci_half_width]\n    jackknife_ci_width = 2 * jackknife_ci_half_width\n    jackknife_contains_true = (jackknife_ci[0] = beta_star[target_j] = jackknife_ci[1])\n    \n    return [\n        analytic_se, bootstrap_se, jackknife_se,\n        analytic_ci_width, bootstrap_ci_width, jackknife_ci_width,\n        analytic_contains_true, bootstrap_contains_true, jackknife_contains_true\n    ]\n\n\n# The problem asks for a specific string output format from the program.\n# To conform to that, the main entry point is modified to format the list output.\n# The core logic in run_case is untouched.\nif __name__ == '__main__':\n    test_cases = [\n        # Case A\n        {\n            \"n\": 40, \"p\": 2, \"x_def\": lambda n: (np.c_[np.ones(n), np.linspace(-2, 2, n)], None),\n            \"beta_star\": np.array([1.0, 2.0]), \"sigma\": 0.5, \"y_seed\": 123, \"target_j\": 1, \"B\": 1000, \"bootstrap_seed\": 321\n        },\n        # Case B\n        {\n            \"n\": 40, \"p\": 2, \"x_def\": lambda n: (np.c_[np.ones(n), (lambda x: (x.__setitem__(0, 10.0), x)[1])(np.linspace(-1, 1, n))], None),\n            \"beta_star\": np.array([1.0, 2.0]), \"sigma\": 0.5, \"y_seed\": 456, \"target_j\": 1, \"B\": 1000, \"bootstrap_seed\": 654\n        },\n        # Case C\n        {\n            \"n\": 12, \"p\": 3, \"x_def\": lambda n: ((lambda x1, x2: ((x1.__setitem__(n - 1, 5.0), x2.__setitem__(n - 1, 4.9)), np.c_[np.ones(n), x1, x2])[1])(np.linspace(-1, 1, n), 0.98 * np.linspace(-1, 1, n) + 0.02 * np.sin(np.arange(n))), None),\n            \"beta_star\": np.array([0.5, 1.5, -0.5]), \"sigma\": 0.8, \"y_seed\": 789, \"target_j\": 2, \"B\": 2000, \"bootstrap_seed\": 987\n        }\n    ]\n    all_results = []\n    for case in test_cases:\n        case_results = run_case(case)\n        formatted_case_results = []\n        for item in case_results:\n            if isinstance(item, bool) or isinstance(item, np.bool_):\n                formatted_case_results.append(str(item).lower())\n            else:\n                formatted_case_results.append(item)\n        all_results.append(formatted_case_results)\n    \n    print(str(all_results).replace(\"'\", \"\"))\n\n```", "id": "3176572"}]}