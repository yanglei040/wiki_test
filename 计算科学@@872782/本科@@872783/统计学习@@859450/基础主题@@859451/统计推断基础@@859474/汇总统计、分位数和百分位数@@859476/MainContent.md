## 引言

分位数与百[分位数](@entry_id:178417)是统计学中最基本也最强大的概念之一。超越了仅仅作为数据排序后某个位置上的值的简单描述，它们为我们提供了一扇深入洞察数据[分布](@entry_id:182848)全貌的窗口。然而，许多数据分析的初学者乃至从业者，虽然频繁使用[中位数](@entry_id:264877)、[四分位数](@entry_id:167370)等指标，却可能对其背后的统计原理、计算方法的微妙差异，以及其在现代数据科学中的深远应用缺乏系统性的认识。这种知识上的差距，限制了我们充分利用[分位数](@entry_id:178417)解决复杂问题的能力，尤其是在面对含有异常值、[偏态](@entry_id:178163)或[重尾分布](@entry_id:142737)的真实世界数据时。

本文旨在填补这一鸿沟，为您提供一个关于分位数的全面而深入的指南。我们将从基本原理出发，逐步深入到高级应用，帮助您构建一个坚实的知识体系。

- 在“**原理与机制**”一章中，我们将剖析[分位数](@entry_id:178417)的多种定义方式，揭示其为何在不同软件中会产生不同结果。我们还将深入探讨其关键的数学性质，如稳健性和变换[等变性](@entry_id:636671)，并从优化的角度揭示其作为损失[函数最小化](@entry_id:138381)器的深刻内涵，最后介绍围绕其展开的[统计推断](@entry_id:172747)理论。
- 随后的“**应用与跨学科联系**”一章将理论付诸实践，通过金融、工程、生物医学和机器学习等多个领域的真实案例，展示分位数如何被用于风险管理、性能评估、稳健建模和不确定性量化。
- 最后，在“**动手实践**”部分，您将有机会通过解决具体问题，将所学知识融会贯通，亲身体验[分位数](@entry_id:178417)在数据分析中的威力。

通过这趟旅程，您将不仅理解分位数“是什么”，更能掌握“为什么”以及“如何用”，从而在数据分析的道路上迈出更坚实的一步。

## 原理与机制

在上一章引言之后，本章将深入探讨[分位数](@entry_id:178417)和百[分位数](@entry_id:178417)的统计原理与核心机制。我们将从其基本定义出发，揭示其多重解释和内在属性，进而探讨其在统计推断和机器学习中的高级应用。本章旨在为您构建一个关于[分位数](@entry_id:178417)的系统性知识框架，从“是什么”和“为什么”的层面，全面理解其在数据科学中的关键作用。

### [分位数](@entry_id:178417)的定义：不止一种方式

从直观上看，一个总体的**$p$-[分位数](@entry_id:178417)**（$p$-quantile），记为 $q_p$，是将该总体的[概率分布](@entry_id:146404)在数值上划分为两个部分的点：理论上，有比例为 $p$ 的总体成员低于 $q_p$，有比例为 $1-p$ 的成员高于 $q_p$。百分位数（percentile）只是分位数的一种特殊表达，例如，第80个百[分位数](@entry_id:178417)即为 $p=0.80$ 的分位数。

这个直观概念可以通过累积分布函数（Cumulative Distribution Function, CDF）$F(x) = \mathbb{P}(X \le x)$ 进行严格定义。对于一个连续且严格单调递增的CDF，$p$-[分位数](@entry_id:178417) $q_p$ 是满足以下方程的唯一解：

$F(q_p) = p$

然而，当我们从理论总体转向实际数据样本时，情况变得复杂起来。对于一组观测数据 $X_1, X_2, \ldots, X_n$，我们使用**[经验累积分布函数](@entry_id:167083)**（Empirical Cumulative Distribution Function, ECDF）来近似 $F(x)$：

$\hat{F}_n(x) = \frac{1}{n} \sum_{i=1}^{n} \mathbf{1}\{X_i \le x\}$

其中 $\mathbf{1}\{\cdot\}$ 是[指示函数](@entry_id:186820)。$\hat{F}_n(x)$ 是一个[阶梯函数](@entry_id:159192)，它在每个观测数据点 $X_i$ 处跳跃，跳跃幅度为 $1/n$（或其倍数，如果存在重复值）。由于 $\hat{F}_n(x)$ 的非连续性，方程 $\hat{F}_n(q) = p$ 可能没有解，或者有无穷多个解。这导致了样本分位数定义的模糊性，并催生了多种计算约定。

#### 基于ECDF逆的定义

一种最直接的定义方式是将样本分位数视为ECDF的[广义逆](@entry_id:140762)。对于给定的概率 $p \in (0,1]$，样本 $p$-分位数 $\hat{q}_p$ 可以定义为满足 $\hat{F}_n(\hat{q}_p) \ge p$ 的最小值。如果我们将样本数据排序得到**[顺序统计量](@entry_id:266649)**（order statistics）$x_{(1)} \le x_{(2)} \le \ldots \le x_{(n)}$，这一定义等价于选择特定的[顺序统计量](@entry_id:266649)。具体而言，该[分位数](@entry_id:178417)由下式给出：

$\hat{q}_p = x_{(\lceil np \rceil)}$

其中 $\lceil \cdot \rceil$ 是向上取整（ceiling）函数。例如，对于一个包含 $n=8$ 个观测值的样本，其 $0.25$-分位数（即第一个[四分位数](@entry_id:167370)）将是 $x_{(\lceil 8 \times 0.25 \rceil)} = x_{(2)}$；其[中位数](@entry_id:264877)（$0.50$-[分位数](@entry_id:178417)）是 $x_{(\lceil 8 \times 0.50 \rceil)} = x_{(4)}$。这种方法的优点是其定义清晰且直接与ECDF的结构相关联。[@problem_id:3177989]

#### [线性插值](@entry_id:137092)定义

然而，上述定义会导致[分位数函数](@entry_id:271351)本身也是一个阶梯函数，它在 $p$ 的某些区间内保持不变。在许多应用中，我们期望分位数随着 $p$ 的变化而平滑变化。因此，**线性插值**（linear interpolation）方法应运而生，并被主流统计软件（如R、Python的NumPy库）广泛采用。

这类方法通常通过一个公式计算一个实数值索引 $h$，然后根据该索引在两个相邻的[顺序统计量](@entry_id:266649)之间进行插值。一个被广泛使用的插值方案（在Hyndman与Fan的分类法中称为类型7，也是R语言的默认方法）定义如下 [@problem_id:3177908]：

1.  计算索引 $h = (n-1)p + 1$。
2.  将 $h$ 分解为整数部分 $j = \lfloor h \rfloor$ 和小数部分 $g = h - j$。
3.  样本分位数由线性插值公式给出：$\hat{q}_p = x_{(j)} + g(x_{(j+1)} - x_{(j)})$。

让我们通过一个例子来比较这两种方法。假设一个样本有 $n=8$ 个观测值，排序后为 $\{2, 3, 7, 11, 13, 17, 19, 23\}$。我们计算其 $90\%$ 分位数（$p=0.90$）。[@problem_id:3177989]
-   根据**ECDF逆定义**：$\hat{q}_{0.90} = x_{(\lceil 8 \times 0.90 \rceil)} = x_{(\lceil 7.2 \rceil)} = x_{(8)} = 23$。
-   根据**[线性插值](@entry_id:137092)定义**：
    -   $h = (8-1)(0.90) + 1 = 6.3 + 1 = 7.3$。
    -   $j = \lfloor 7.3 \rfloor = 7$， $g = 7.3 - 7 = 0.3$。
    -   $\hat{q}_{0.90} = x_{(7)} + 0.3(x_{(8)} - x_{(7)}) = 19 + 0.3(23 - 19) = 19 + 1.2 = 20.2$。

显而易见，不同的定义会产生不同的数值结果。这种差异在小样本量时尤其显著。因此，在科学研究中，仅仅报告“第75百[分位数](@entry_id:178417)”而不指明其计算方法，可能会导致结果无法被他人精确复现，从而损害研究的**[可重复性](@entry_id:194541)**（reproducible research）。当独立分析师使用不同软件的默认设置时，他们可能会合理地得到不同的数值，这正是统计实践中需要注意的细节。[@problem_id:3177908]

### [分位数](@entry_id:178417)的基本性质

[分位数](@entry_id:178417)之所以在统计学中占据核心地位，不仅因为它们能够描述[分布](@entry_id:182848)，更源于其优越的数学性质。其中两个最重要的性质是**单调变换下的[等变性](@entry_id:636671)**和**对异常值的稳健性**。

#### 单调变换下的[等变性](@entry_id:636671)

**[等变性](@entry_id:636671)**（Equivariance）是指一个统计量的变换与数据本身的变换相兼容。对于分位数而言，它在一个严格单调递增的函数 $g$ 变换下是等变的。这意味着，对数据进行变换后再计算分位数，与先计算[分位数](@entry_id:178417)再进行变换，结果是相同的。

形式上，若 $Y = g(X)$ 且 $g$ 是严格单调递增函数，则 $Y$ 的 $p$-[分位数](@entry_id:178417) $q_p(Y)$ 与 $X$ 的 $p$-分位数 $q_p(X)$ 之间的关系为：

$q_p(g(X)) = g(q_p(X))$

这个性质的证明源于[分位数](@entry_id:178417)的定义。事件 $\{g(X) \le g(q_p(X))\}$ 与事件 $\{X \le q_p(X)\}$ 是等价的，因为 $g$ 是单调的。因此，它们的概率相同：$\mathbb{P}(g(X) \le g(q_p(X))) = \mathbb{P}(X \le q_p(X)) = p$。这表明 $g(q_p(X))$ 正是 $g(X)$ 的 $p$-[分位数](@entry_id:178417)。

这个性质在实践中非常有用。例如，在处理具有[重尾分布](@entry_id:142737)的正值数据（如收入、[网络延迟](@entry_id:752433)）时，通常会进行[对数变换](@entry_id:267035) $Y = \ln(X)$ 来稳定[方差](@entry_id:200758)或使[分布](@entry_id:182848)更对称。分位数的[等变性](@entry_id:636671)保证了在对数尺度上设定的阈值可以直接转换回原始尺度。如果我们决定将对数尺度上超过 $80\%$ 分位数的值视为异常，即 $Y \ge q_{0.8}(Y)$，这完全等同于在原始尺度上将 $X \ge \exp(q_{0.8}(Y))$ 的值视为异常。由于 $q_{0.8}(Y) = \ln(q_{0.8}(X))$，这个阈值就是 $X \ge q_{0.8}(X)$。因此，无论是在原始尺度还是变换尺度上使用[分位数](@entry_id:178417)作为阈值，识别出的观测[子集](@entry_id:261956)是完全相同的。[@problem_id:3177900]

相比之下，许多其他统计量，如均值，不具备此性质。由于[Jensen不等式](@entry_id:144269)，通常 $\mathbb{E}[\ln(X)]  \ln(\mathbb{E}[X])$。这意味着在对数尺度上的均值无法直接转换回原始尺度上的均值。这种差异使得分位数在设定阈值和进行[跨尺度](@entry_id:754544)比较时成为一个更可靠和一致的工具。

#### 对异常值的稳健性

**稳健性**（Robustness）是指一个[统计估计量](@entry_id:170698)在数据受到污染或存在异常值（outliers）时，其表现依然稳定的能力。均值以其对异常值的极端敏感性而闻名——一个无穷大的异常值可以将样本均值拉向无穷大。相比之下，分位数，尤其是中位数，表现出高度的稳健性。

这种差异可以通过**[影响函数](@entry_id:168646)**（Influence Function, IF）来精确量化。[影响函数](@entry_id:168646)衡量了在数据[分布](@entry_id:182848) $F$ 中引入一个位于 $x$ 点的无限小的污染时，统计量 $T(F)$ 所受到的标准化影响。其定义为：

$\mathrm{IF}(x; T, F) \equiv \lim_{\varepsilon \to 0^{+}} \frac{T((1-\varepsilon)F + \varepsilon \Delta_{x}) - T(F)}{\varepsilon}$

其中 $\Delta_x$ 是在点 $x$ 处的点[质量分布](@entry_id:158451)。

对于**均值** $\mu(F) = \int y \, dF(y)$，其[影响函数](@entry_id:168646)为：

$\mathrm{IF}(x; \mu, F) = x - \mu(F)$

这个函数是无界的。这意味着，当污染点 $x$ 远离[分布](@entry_id:182848)中心 $\mu(F)$ 时，它对均值的影响可以任意大。

对于**中位数** $\theta(F)$（即 $0.5$-分位数），假设其处的[概率密度](@entry_id:175496) $f(\theta(F))$ 大于零，其[影响函数](@entry_id:168646)为：

$\mathrm{IF}(x; \theta, F) = \frac{\mathrm{sgn}(x-\theta(F))}{2f(\theta(F))}$

其中 $\mathrm{sgn}(\cdot)$ 是[符号函数](@entry_id:167507)。这个函数是**有界的**。无论污染点 $x$ 离中位数多远，其影响都被限制在一个固定范围内。例如，对于[标准正态分布](@entry_id:184509)，中位数为0，其[影响函数](@entry_id:168646)的[绝对值](@entry_id:147688)被限制在 $\frac{1}{2\varphi(0)} = \frac{\sqrt{2\pi}}{2} \approx 1.25$。这从数学上证明了中位数对极端异常值的稳健性。[@problem_id:3177954]

这种稳健性在[回归分析](@entry_id:165476)中尤为重要。传统的[普通最小二乘法](@entry_id:137121)（OLS）回归的斜率估计对[高杠杆点](@entry_id:167038)（即$x$值异常）和$y$值异常的观测非常敏感，因为它本质上是基于均值和协[方差](@entry_id:200758)的。作为一种稳健的替代方法，**[Theil-Sen估计](@entry_id:634178)**通过计算所有数据点对的斜率的中位数来估计回归斜率。在一个包含异常值的回归任务中，OLS斜率可能会被异[常点](@entry_id:164624)严重扭曲，而Theil-Sen斜率则能更好地抵抗这种影响，保持对数据主体趋势的稳定估计。[@problem_id:3177954]

### 优化视角：[分位数](@entry_id:178417)作为损失最小化器

除了作为[分布](@entry_id:182848)的描述符，分位数还可以从一个完全不同的角度来理解：作为特定[损失函数](@entry_id:634569)的最小化器。这个视角不仅为分位数提供了更深刻的理论基础，也将其推广到更广泛的**[分位数回归](@entry_id:169107)**（quantile regression）框架中。

核心在于**非对称绝对损失函数**（asymmetric absolute loss），也常被称为**检验损失**（check loss）或**弹球损失**（pinball loss）。对于给定的分位水平 $\tau \in (0,1)$，该[损失函数](@entry_id:634569)定义为：

$\rho_{\tau}(u) = \begin{cases} \tau u  \text{if } u \ge 0 \\ (\tau-1)u  \text{if } u  0 \end{cases}$

这个函数是凸的，但在 $u=0$ 处有一个“拐点”。当预测值高于真实值（$u0$）时，损失的权重是 $1-\tau$；当预测值低于真实值（$u>0$）时，权重是 $\tau$。

一个深刻的结论是，对于一个[随机变量](@entry_id:195330) $X$，其总体的 $\tau$-[分位数](@entry_id:178417) $q_\tau$ 正是最小化期望损失 $\mathbb{E}[\rho_{\tau}(X-\theta)]$ 的那个 $\theta$ 值。[@problem_id:3177894]

$\arg\min_{\theta} \mathbb{E}[\rho_{\tau}(X-\theta)] = q_{\tau}(X)$

这个结论可以通过[凸优化](@entry_id:137441)的次梯度（subgradient）理论推导得出。一个凸函数在某点取最小值的充要条件是，0 包含在该点的[次梯度](@entry_id:142710)集合中。$L_p(\theta)=\mathbb{E}[\rho_{\tau}(X-\theta)]$ 的次梯度为区间 $[F(\theta^-)-\tau, F(\theta)-\tau]$。因此，[最优性条件](@entry_id:634091) $0 \in [F(\theta^{*-})-\tau, F(\theta^*)-\tau]$ 等价于 $F(\theta^{*-}) \le \tau \le F(\theta^*)$，这正是分位数的概率定义。

这个优化框架的威力在于其[可扩展性](@entry_id:636611)。我们可以将常数 $\theta$ 替换为一个关于[协变](@entry_id:634097)量 $x$ 的[线性模型](@entry_id:178302) $\beta^T x$，从而定义**[分位数回归](@entry_id:169107)**。其目标是最小化样本损失：

$\arg\min_{\beta} \sum_{i=1}^n \rho_{\tau}(y_i - \beta^T x_i)$

与[最小二乘回归](@entry_id:262382)（它最小化平方损失，旨在建模**条件均值** $\mathbb{E}[Y|X]$）不同，[分位数回归](@entry_id:169107)旨在建模**条件[分位数](@entry_id:178417)** $q_{\tau}(Y|X)$。这使得我们能够探索协变量对响应变量[分布](@entry_id:182848)的各个部分（如[中位数](@entry_id:264877)、第10百分位数、第90百分位数）的影响，而不仅仅是中心趋势。

此外，这个框架可以自然地与[正则化技术](@entry_id:261393)相结合。例如，通过加入 $L_1$ 范数惩罚项（LASSO），我们可以构建稀疏[分位数回归](@entry_id:169107)模型：

$\arg\min_{\beta} \sum_{i=1}^n \rho_{\tau}(y_i - \beta^T x_i) + \lambda \|\beta\|_1$

通过分析其在 $\beta = 0$ 处的[次梯度最优性条件](@entry_id:634317)，可以发现，当[正则化参数](@entry_id:162917) $\lambda$ 足够大时，模型的最优解将是 $\hat{\beta}=0$。这表明，与[LASSO](@entry_id:751223)在线性回归中的作用类似，$L_1$ 正则化的[分位数回归](@entry_id:169107)能够执行[变量选择](@entry_id:177971)，识别出对特定条件[分位数](@entry_id:178417)有显著影响的特征。[@problem_id:3177990]

### [分位数](@entry_id:178417)的统计推断

在估计了样本分位数后，一个自然的问题是：我们对这个估计的[置信度](@entry_id:267904)有多高？[统计推断](@entry_id:172747)为我们提供了量化这种不确定性的工具，主要包括置信区间和[渐近分布](@entry_id:272575)理论。

#### [分布](@entry_id:182848)无关的[置信区间](@entry_id:142297)

[分位数](@entry_id:178417)的一个显著优点是，我们可以为其构建**[分布](@entry_id:182848)无关的置信区间**（distribution-free confidence intervals），即该区间的有效性不依赖于数据来自何种特定的[概率分布](@entry_id:146404)（如[正态分布](@entry_id:154414)）。

这种方法的基础是[顺序统计量](@entry_id:266649)和[二项分布](@entry_id:141181)之间的联系。令 $q_p$ 为总体 $p$-分位数。对于来自连续分布的任意一个观测 $X_i$，其值小于 $q_p$ 的概率恰好为 $p$。因此，在一个大小为 $n$ 的样本中，小于 $q_p$ 的观测数量 $K$ 服从二项分布 $K \sim \text{Binomial}(n, p)$。

一个由两个[顺序统计量](@entry_id:266649)构成的区间 $(X_{(i)}, X_{(j)})$（其中 $i  j$），其包含总体分位数 $q_p$ 的概率为：

$\mathbb{P}(X_{(i)} \le q_p \le X_{(j)}) = \mathbb{P}(K \ge i) - \mathbb{P}(K \ge j) = \sum_{k=i}^{j-1} \binom{n}{k} p^k (1-p)^{n-k}$

通过选择合适的 $i$ 和 $j$，我们可以构造一个具有特定[置信水平](@entry_id:182309)（如95%）的区间。例如，我们可以选择 $i$ 和 $j$ 使得它们关于中点 $np$ 对称，以获得最短的区间。这种方法无需任何[分布](@entry_id:182848)假设，具有极强的普适性。

#### [渐近分布](@entry_id:272575)理论

对于大样本，中心极限定理的一个变种为我们提供了样本分位数的渐近正态分布。在一些温和的[正则性条件](@entry_id:166962)下（主要是总体CDF $F$ 在 $q_p$ 处可微且其导数，即[概率密度函数](@entry_id:140610) $f(q_p)$，大于零），样本 $p$-分位数 $\widehat{q}_p$ 渐近服从[正态分布](@entry_id:154414)：

$\sqrt{n}(\widehat{q}_p - q_p) \xrightarrow{d} \mathcal{N}\left(0, \frac{p(1-p)}{[f(q_p)]^2}\right)$

这个强大的结论是许多推断方法的基础。它告诉我们，样本分位数的[方差](@entry_id:200758)与[分位数](@entry_id:178417)水平 $p$（越接近0或1，[方差](@entry_id:200758)越大）、样本量 $n$（$n$越大，[方差](@entry_id:200758)越小）以及总体在[分位数](@entry_id:178417)处的密度 $f(q_p)$（密度越小，即[分布](@entry_id:182848)在该处越平坦，[分位数](@entry_id:178417)的不确定性越大）有关。

基于这个理论，我们可以构造一个近似的 $100(1-\alpha)\%$ 置信区间：

$\widehat{q}_p \pm z_{1-\alpha/2} \frac{\sqrt{p(1-p)}}{\sqrt{n}\widehat{f}(\widehat{q}_p)}$

其中 $z_{1-\alpha/2}$ 是标准正态分布的 $1-\alpha/2$ [分位数](@entry_id:178417)，$\widehat{f}(\widehat{q}_p)$ 是对 $f(q_p)$ 的一个一致估计，例如使用[核密度估计](@entry_id:167724)或基于[顺序统计量](@entry_id:266649)的差分方法。