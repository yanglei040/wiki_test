{"hands_on_practices": [{"introduction": "让我们将所学知识付诸实践，完成一个常见的机器学习任务：验证分类器的性能。这个练习 [@problem_id:3130833] 要求你检验一个分类器的真正例率 ($TPR$) 是否达到了特定标准。通过实现这个检验，你将亲眼看到第一类和第二类错误这些抽象概念，如何与分类器的决策阈值及其在ROC曲线上的位置具体地联系起来，从而为模型评估建立至关重要的直觉。", "problem": "给定一个二元分类器，它为每个实例输出一个实值分数。假设分数分布是固定的，并由以下科学上合理的模型给出：当真实类别为正时，分数服从均值为 $\\mu_1$、标准差为 $\\sigma$ 的高斯分布；当真实类别为负时，分数服从均值为 $\\mu_0$、标准差为 $\\sigma$ 的高斯分布，其中 $\\mu_1 > \\mu_0$ 且 $\\sigma > 0$。对于任意决策阈值 $\\tau$，如果分数至少为 $\\tau$，则分类为正。这会产生一条由 $(\\mu_0,\\mu_1,\\sigma)$ 固定的接收者操作特征（ROC）曲线。对于阈值 $\\tau$，真阳性率和假阳性率分别为\n$$\\mathrm{TPR}(\\tau) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_1}{\\sigma}\\right), \\quad \\mathrm{FPR}(\\tau) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_0}{\\sigma}\\right),$$\n其中 $\\Phi(\\cdot)$ 表示标准正态分布的累积分布函数。\n\n设计一个单边假设检验，以验证分类器在选定阈值 $\\tau$ 下的真阳性率至少为基准值 $p_0$。令 $p(\\tau)$ 表示阈值 $\\tau$ 下的真阳性率。您从正类总体中观察 $m$ 次独立抽样，并记录在阈值 $\\tau$ 下的真阳性数量。根据伯努利模型，真阳性计数 $X$ 是一个参数为 $m$ 和 $p(\\tau)$ 的二项随机变量，记作 $X \\sim \\mathrm{Binomial}(m, p(\\tau))$。考虑检验\n$$H_0: \\ p(\\tau) \\ge p_0 \\quad \\text{versus} \\quad H_1: \\ p(\\tau)  p_0,$$\n使用“若 $X \\le k$ 则拒绝 $H_0$”形式的下尾拒绝规则，其中整数截断值 $k$ 的选择是为了在二项分布离散性允许的范围内尽可能接近目标显著性水平 $\\alpha_{\\text{target}}$。对于给定的 $k$，I 型错误概率 $\\alpha$ 是在 $H_0$ 为真时拒绝它的概率，在边界情况 $p(\\tau) = p_0$ 下，它等于 $\\alpha = \\Pr(X \\le k \\mid m, p_0)$。对于给定的 $k$ 和特定的真实率 $p(\\tau)$，II 型错误概率 $\\beta$ 是在 $H_1$ 为真时未能拒绝 $H_0$ 的概率，即当 $p(\\tau)  p_0$ 时，$\\beta = \\Pr(X > k \\mid m, p(\\tau))$。\n\n您的任务：\n- 从第一性原理出发，推导固定的高斯分数模型如何在给定 $(\\mu_0,\\mu_1,\\sigma)$ 的情况下，生成作为 $\\tau$ 函数的 $\\mathrm{TPR}(\\tau)$ 和 $\\mathrm{FPR}(\\tau)$。\n- 从二项模型以及 I 型和 II 型错误的定义出发，说明如何选择整数截断值 $k$ 以满足 $\\Pr(X \\le k \\mid m, p_0) \\le \\alpha_{\\text{target}}$，并计算得到的名义 I 型错误 $\\alpha_{\\text{nominal}} = \\Pr(X \\le k \\mid m, p_0)$。\n- 对于测试套件中的每个阈值 $\\tau$，计算：\n    1. 由固定 ROC 曲线导出的真阳性率 $p(\\tau)$ 和假阳性率 $\\mathrm{FPR}(\\tau)$。\n    2. 由 $k$、$m$ 和 $p_0$ 决定的名义 I 型错误 $\\alpha_{\\text{nominal}}$。\n    3. 在 $\\tau$ 处的实际 I 型错误，定义为 $\\alpha_{\\text{real}}(\\tau) = \\Pr(X \\le k \\mid m, p(\\tau))$; 这仅在 $p(\\tau) \\ge p_0$ 时有意义，但为了完整性，您仍应为所有 $\\tau$ 计算其值。\n    4. 在 $\\tau$ 处的实际 II 型错误，定义为 $\\beta_{\\text{real}}(\\tau) = \\Pr(X > k \\mid m, p(\\tau)) = 1 - \\Pr(X \\le k \\mid m, p(\\tau))$; 这在 $p(\\tau)  p_0$ 时有意义，但您应为所有 $\\tau$ 计算其值，以观察在 ROC 曲线保持固定的情况下，改变 $\\tau$ 如何权衡 $\\alpha_{\\text{real}}(\\tau)$ 与 $\\beta_{\\text{real}}(\\tau)$。\n\n使用以下参数和测试套件：\n- 固定分数模型：$\\mu_0 = 0$, $\\mu_1 = 1.5$, $\\sigma = 1$。\n- 基准率：$p_0 = 0.85$（以小数表示）。\n- 样本量：$m = 50$。\n- 目标显著性水平：$\\alpha_{\\text{target}} = 0.05$（以小数表示）。\n- 阈值：$\\tau \\in \\{-0.5, \\ 0.0, \\ 0.464, \\ 1.0, \\ 1.5, \\ 2.5\\}$，其中选择 $\\tau = 0.464$ 是为了使 $\\mathrm{TPR}(\\tau)$ 接近 $p_0$。\n\n输出规范：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。\n- 每个测试用例的结果必须是包含六个小数值的列表，顺序为 $[\\tau,\\mathrm{TPR}(\\tau),\\mathrm{FPR}(\\tau),\\alpha_{\\text{nominal}},\\alpha_{\\text{real}}(\\tau),\\beta_{\\text{real}}(\\tau)]$，每个值四舍五入到六位小数。\n- 因此，最终输出应为列表的列表，针对给定顺序的六个阈值，不含任何附加文本。例如，输出行将类似于“[ [t1,tp1,fp1,a_nom1,a_real1,b_real1], [t2,tp2,fp2,a_nom2,a_real2,b_real2], ... ]”。\n\n您的解决方案必须按照规定实现为一个完整的、可运行的程序，并且不得要求任何用户输入。", "solution": "我们从固定的高斯分数模型开始。设当真实类别为正时，分数 $S$ 服从 $S \\sim \\mathcal{N}(\\mu_1,\\sigma^2)$ 分布；当真实类别为负时，分数 $S$ 服从 $S \\sim \\mathcal{N}(\\mu_0,\\sigma^2)$ 分布，其中 $\\mu_1 > \\mu_0$。对于任意阈值 $\\tau$，如果 $S \\ge \\tau$，我们预测为正。\n\n根据高斯随机变量累积分布函数的定义，对于一个标准正态变量 $Z \\sim \\mathcal{N}(0,1)$ 和任意实数 $z$，我们有 $\\Pr(Z \\le z) = \\Phi(z)$，其中 $\\Phi(\\cdot)$ 是标准正态累积分布函数。利用单调变换性质，\n$$\\Pr(S \\ge \\tau \\mid \\text{positive}) = \\Pr\\!\\left(\\frac{S - \\mu_1}{\\sigma} \\ge \\frac{\\tau - \\mu_1}{\\sigma}\\right) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_1}{\\sigma}\\right),$$\n因为 $\\frac{S - \\mu_1}{\\sigma} \\sim \\mathcal{N}(0,1)$。这就是真阳性率 $\\mathrm{TPR}(\\tau)$。同样，假阳性率是\n$$\\Pr(S \\ge \\tau \\mid \\text{negative}) = \\Pr\\!\\left(\\frac{S - \\mu_0}{\\sigma} \\ge \\frac{\\tau - \\mu_0}{\\sigma}\\right) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_0}{\\sigma}\\right),$$\n即 $\\mathrm{FPR}(\\tau)$。因为 $(\\mu_0,\\mu_1,\\sigma)$ 是固定的，所以 ROC 曲线（随着 $\\tau$ 变化，$\\mathrm{TPR}(\\tau)$ 对 $\\mathrm{FPR}(\\tau)$ 的参数图）是固定的，改变 $\\tau$ 会沿着该曲线移动。\n\n接下来，考虑检验在阈值 $\\tau$ 下的真阳性率（记为 $p(\\tau)$）是否达到或超过基准值 $p_0$。我们观察一批 $m$ 个独立抽取的正类实例，并将在阈值 $\\tau$ 下的真阳性数量记为 $X$。在成功概率为 $p(\\tau)$ 的独立试验的伯努利模型下，我们有\n$$X \\sim \\mathrm{Binomial}(m, p(\\tau)).$$\n我们建立单边假设检验\n$$H_0: \\ p(\\tau) \\ge p_0 \\quad \\text{versus} \\quad H_1: \\ p(\\tau)  p_0.$$\n对于这种单边检验，一个自然的拒绝规则是下尾截断：如果 $X \\le k$，则拒绝 $H_0$，其中 $k$ 为某个整数。对于给定的截断值 $k$，I 型错误概率 $\\alpha$ 定义为在原假设为真时错误地拒绝它的概率。对于像二项分布这样关于 $p$ 具有单调似然比族的分布，在 $H_0$ 下的最坏情况 I 型错误发生在边界 $p(\\tau) = p_0$ 处，因此\n$$\\alpha = \\Pr(X \\le k \\mid X \\sim \\mathrm{Binomial}(m, p_0)).$$\n给定一个目标显著性水平 $\\alpha_{\\text{target}}$，我们选择 $k$ 为满足\n$$\\Pr(X \\le k \\mid X \\sim \\mathrm{Binomial}(m, p_0)) \\le \\alpha_{\\text{target}}.$$\n的最大整数。这确保了尽管二项分布是离散的，检验的规模（size）不会超过 $\\alpha_{\\text{target}}$。得到的名义 I 型错误是\n$$\\alpha_{\\text{nominal}} = \\Pr(X \\le k \\mid X \\sim \\mathrm{Binomial}(m, p_0)).$$\n\n对于一个特定的真实率 $p(\\tau)$（当 $p(\\tau)  p_0$ 时，它位于备择区域），II 型错误概率 $\\beta$ 是在原假设为假时未能拒绝它的概率。在“如果 $X \\le k$ 则拒绝”的拒绝规则下，未能拒绝等价于 $X > k$，因此\n$$\\beta(p(\\tau)) = \\Pr\\!\\big(X > k \\mid X \\sim \\mathrm{Binomial}(m, p(\\tau))\\big) = 1 - \\Pr\\!\\big(X \\le k \\mid X \\sim \\mathrm{Binomial}(m, p(\\tau))\\big).$$\n为了研究在 ROC 固定的情况下，改变阈值如何影响错误概率，我们对每个 $\\tau$ 计算：\n- 从高斯分数模型导出的 $p(\\tau) = \\mathrm{TPR}(\\tau)$ 和 $\\mathrm{FPR}(\\tau)$；\n- 在 $p_0$ 下的名义 I 型错误 $\\alpha_{\\text{nominal}}$（与 $\\tau$ 无关，因为 $k$ 是用 $p_0$ 选择的）；\n- 在 $\\tau$ 处的实际 I 型错误 $\\alpha_{\\text{real}}(\\tau) = \\Pr(X \\le k \\mid m, p(\\tau))$，这在 $p(\\tau) \\ge p_0$ 时有意义，并且通常小于或等于 $\\alpha_{\\text{nominal}}$，因为随着成功概率的增加，下尾概率会减小；\n- 在 $\\tau$ 处的实际 II 型错误 $\\beta_{\\text{real}}(\\tau) = 1 - \\Pr(X \\le k \\mid m, p(\\tau))$，这在 $p(\\tau)  p_0$ 时有意义，并且随着 $p(\\tau)$ 的减小而增大。\n\n算法步骤：\n1. 使用标准正态累积分布函数 $\\Phi(\\cdot)$ 计算 $\\mathrm{TPR}(\\tau)$ 和 $\\mathrm{FPR}(\\tau)$，公式为\n$$\\mathrm{TPR}(\\tau) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_1}{\\sigma}\\right), \\quad \\mathrm{FPR}(\\tau) = 1 - \\Phi\\!\\left(\\frac{\\tau - \\mu_0}{\\sigma}\\right).$$\n2. 通过从 $k=-1$ 向上扫描来确定整数截断值 $k$，找到满足 $\\Pr(X \\le k \\mid m, p_0) \\le \\alpha_{\\text{target}}$ 的最大 $k$。这里 $k=-1$ 对应于一个空的拒绝域（永不拒绝），随着 $k$ 的增加，下尾概率也增加。\n3. 使用二项累积分布函数计算 $\\alpha_{\\text{nominal}} = \\Pr(X \\le k \\mid m, p_0)$。\n4. 对每个 $\\tau$，计算 $\\alpha_{\\text{real}}(\\tau) = \\Pr(X \\le k \\mid m, p(\\tau))$ 和 $\\beta_{\\text{real}}(\\tau) = 1 - \\Pr(X \\le k \\mid m, p(\\tau))$。\n5. 将每个数值四舍五入到六位小数，并以要求的列表的列表格式输出。\n\n测试套件覆盖范围：\n- $\\tau = -0.5$ 和 $\\tau = 0.0$ 产生高于 $p_0$ 的高 $\\mathrm{TPR}(\\tau)$（原假设的理想路径）。\n- $\\tau = 0.464$ 针对边界情况，此时 $\\mathrm{TPR}(\\tau)$ 接近 $p_0$（边界条件）。\n- $\\tau = 1.0$ 和 $\\tau = 1.5$ 产生低于 $p_0$ 的较低 $\\mathrm{TPR}(\\tau)$（备择区域，其中 $\\beta$ 变得相关）。\n- $\\tau = 2.5$ 产生非常低的 $\\mathrm{TPR}(\\tau)$（高 II 型错误的边缘情况）。\n\n所有概率均以小数表示，而非百分比。不涉及物理单位或角度单位。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm, binom\n\ndef compute_tpr_fpr(tau, mu0, mu1, sigma):\n    # TPR = 1 - Phi((tau - mu1)/sigma)\n    # FPR = 1 - Phi((tau - mu0)/sigma)\n    z_pos = (tau - mu1) / sigma\n    z_neg = (tau - mu0) / sigma\n    tpr = 1.0 - norm.cdf(z_pos)\n    fpr = 1.0 - norm.cdf(z_neg)\n    return tpr, fpr\n\ndef choose_critical_k(m, p0, alpha_target):\n    # Find largest integer k such that BinomCDF(k; m, p0) = alpha_target.\n    # Start from k = -1 (empty rejection region) and increment while condition holds.\n    k = -1\n    while True:\n        next_k = k + 1\n        if next_k > m:\n            # Cannot exceed m; break\n            break\n        cdf_next = binom.cdf(next_k, m, p0)\n        if cdf_next = alpha_target + 1e-15:  # small tolerance for numerical stability\n            k = next_k\n        else:\n            break\n    return k\n\ndef solve():\n    # Fixed score model parameters\n    mu0 = 0.0\n    mu1 = 1.5\n    sigma = 1.0\n\n    # Hypothesis test parameters\n    p0 = 0.85        # baseline true positive rate under H0 (decimal)\n    m = 50           # number of positive instances sampled\n    alpha_target = 0.05  # target significance level (decimal)\n\n    # Thresholds to evaluate\n    thresholds = [-0.5, 0.0, 0.464, 1.0, 1.5, 2.5]\n\n    # Choose critical cutoff k based on m, p0, and alpha_target\n    k = choose_critical_k(m, p0, alpha_target)\n    # Compute nominal alpha at this k\n    alpha_nominal = binom.cdf(k, m, p0) if k >= 0 else 0.0\n\n    results = []\n    for tau in thresholds:\n        # Compute TPR and FPR from the fixed ROC model\n        tpr, fpr = compute_tpr_fpr(tau, mu0, mu1, sigma)\n        # Realized Type I error at tau (computed for completeness even if p(tau)  p0)\n        alpha_real = binom.cdf(k, m, tpr) if k >= 0 else 0.0\n        # Realized Type II error at tau\n        beta_real = 1.0 - alpha_real  # since accept region is X > k\n        # Round values to six decimal places as required\n        out = [\n            round(tau, 6),\n            round(tpr, 6),\n            round(fpr, 6),\n            round(alpha_nominal, 6),\n            round(alpha_real, 6),\n            round(beta_real, 6)\n        ]\n        results.append(out)\n\n    # Format as a single line: list of lists\n    # Ensure exact formatting with commas and brackets, no extra text.\n    def format_list(lst):\n        return \"[\" + \",\".join(str(x) for x in lst) + \"]\"\n    print(\"[\" + \",\".join(format_list(r) for r in results) + \"]\")\n\nsolve()\n```", "id": "3130833"}, {"introduction": "科学和工业领域的一项关键任务是设计足够强大的实验来检测有意义的效应。这个实践 [@problem_id:3130913] 将指导你完成假设检验中样本量计算的过程。通过推导和应用该公式，你将掌握第一类错误 ($\\alpha$)、第二类错误 ($\\beta$)、你希望检测的效应大小以及所需数据量 ($n$) 之间的基本关系，这是有效实验设计的基石。", "problem": "一个安全运营团队监控系统日志，统计每个固定时间窗口内的异常标志数量。在恒定速率机制下，将每个窗口的计数建模为来自速率参数为 $\\lambda$ 的泊松分布的独立抽样，这在科学上是合理的。该团队希望检验异常率是否相对于一个已知的基线 $\\lambda_0$ 有所增加。\n\n构建一个单边假设检验，其原假设为 $H_0: \\lambda = \\lambda_0$，备择假设为 $H_1: \\lambda = \\lambda_1$，其中 $\\lambda_1 = \\lambda_0(1+\\delta)$ 且 $\\delta > 0$ 是一个小数。设 $Y_1,\\dots,Y_n$ 是在 $n$ 个独立窗口中观测到的计数，并定义总计数为 $X = \\sum_{i=1}^{n} Y_i$。当 $X$ 超过一个阈值 $c$ 时，该检验将拒绝 $H_0$。该阈值 $c$ 的选择是为了控制I类错误率 $\\alpha$（即在 $H_0$ 为真时拒绝 $H_0$ 的概率）。团队计划稍后通过在 $H_0$ 条件下从泊松模型中模拟抽样来验证所达到的 $\\alpha$ 值，但为了规划目的，他们需要一个关于样本量的解析表达式。\n\n从I类错误 $\\alpha$ 和II类错误 $\\beta$（在 $H_1$ 为真时未能拒绝 $H_0$ 的概率）的核心定义出发，并仅使用关于泊松分布的成熟结论（其均值和方差等于其速率参数）以及中心极限定理（CLT）的近似（即对于大的 $n$，$X$ 近似服从均值为 $n\\lambda$、方差为 $n\\lambda$ 的正态分布），推导出一个表达式，用于计算能够达到I类错误率 $\\alpha$ 和II类错误率 $\\beta$ 以检测从 $\\lambda_0$ 到 $\\lambda_1 = \\lambda_0(1+\\delta)$ 的速率增加所需的最小整数样本量 $n$。\n\n然后，对于规划参数 $\\lambda_0=5$, $\\delta=0.1$, $\\alpha=0.05$, 和 $\\beta=0.2$，对此表达式进行数值计算，并报告满足这些标准的最小整数 $n$。不要使用任何连续性校正。答案必须是单个整数。除了取最小整数之外，没有其他舍入要求。", "solution": "该问题要求推导用于比较两个泊松速率的单边假设检验所需的最小样本量 $n$，然后进行数值计算。推导将基于I类和II类错误的定义，并使用中心极限定理(CLT)进行近似。\n\n首先，我们来形式化问题设定。给定 $n$ 个独立同分布的随机变量 $Y_1, \\dots, Y_n$，其中 $Y_i \\sim \\text{Poisson}(\\lambda)$。检验统计量是它们的和，$X = \\sum_{i=1}^{n} Y_i$。泊松分布的一个性质是，独立泊松变量的和仍然是泊松变量。因此，$X \\sim \\text{Poisson}(n\\lambda)$。\n\n假设检验为：\n原假设 $H_0: \\lambda = \\lambda_0$\n备择假设 $H_1: \\lambda = \\lambda_1$，其中 $\\lambda_1 = \\lambda_0(1+\\delta)$ 且 $\\delta > 0$。\n\n问题陈述要求使用中心极限定理（CLT）近似。对于大的样本量 $n$，$X$ 的分布可以用正态分布来近似。\n在 $H_0$ 之下，$X$ 的均值为 $E[X|H_0] = n\\lambda_0$，方差为 $\\text{Var}(X|H_0) = n\\lambda_0$。所以，$X \\stackrel{\\text{approx}}{\\sim} \\mathcal{N}(n\\lambda_0, n\\lambda_0)$。\n在 $H_1$ 之下，$X$ 的均值为 $E[X|H_1] = n\\lambda_1$，方差为 $\\text{Var}(X|H_1) = n\\lambda_1$。所以，$X \\stackrel{\\text{approx}}{\\sim} \\mathcal{N}(n\\lambda_1, n\\lambda_1)$。\n\n决策规则是：如果 $X > c$，则拒绝 $H_0$，其中 $c$ 是一个临界值。\n\nI类错误率 $\\alpha$ 是指当 $H_0$ 为真时拒绝 $H_0$ 的概率。\n$$ \\alpha = P(\\text{reject } H_0 | H_0) = P(X > c | \\lambda = \\lambda_0) $$\n使用在 $H_0$ 下对 $X$ 的正态近似，我们对变量进行标准化：\n$$ \\alpha = P\\left( \\frac{X - n\\lambda_0}{\\sqrt{n\\lambda_0}} > \\frac{c - n\\lambda_0}{\\sqrt{n\\lambda_0}} \\right) $$\n设 $Z$ 为一个标准正态随机变量，$Z \\sim \\mathcal{N}(0,1)$。设 $z_\\alpha$ 为标准正态分布的上 $\\alpha$ 分位数，定义为 $P(Z > z_\\alpha) = \\alpha$。于是我们有：\n$$ \\frac{c - n\\lambda_0}{\\sqrt{n\\lambda_0}} = z_\\alpha $$\n解出临界值 $c$，我们得到第一个表达式：\n$$ c = n\\lambda_0 + z_\\alpha \\sqrt{n\\lambda_0} \\quad (1) $$\n\nII类错误率 $\\beta$ 是指当 $H_1$ 为真时未能拒绝 $H_0$ 的概率。\n$$ \\beta = P(\\text{fail to reject } H_0 | H_1) = P(X \\le c | \\lambda = \\lambda_1) $$\n使用在 $H_1$ 下对 $X$ 的正态近似，我们对变量进行标准化：\n$$ \\beta = P\\left( \\frac{X - n\\lambda_1}{\\sqrt{n\\lambda_1}} \\le \\frac{c - n\\lambda_1}{\\sqrt{n\\lambda_1}} \\right) $$\n设 $z_\\beta$ 为标准正态分布的上 $\\beta$ 分位数，即 $P(Z > z_\\beta) = \\beta$。根据正态分布的对称性，$P(Z \\le -z_\\beta) = \\beta$。因此：\n$$ \\frac{c - n\\lambda_1}{\\sqrt{n\\lambda_1}} = -z_\\beta $$\n解出临界值 $c$，我们得到第二个表达式：\n$$ c = n\\lambda_1 - z_\\beta \\sqrt{n\\lambda_1} \\quad (2) $$\n\n现在，我们将方程 $(1)$ 和 $(2)$ 中关于 $c$ 的两个表达式相等，以求得所需的样本量 $n$。\n$$ n\\lambda_0 + z_\\alpha \\sqrt{n\\lambda_0} = n\\lambda_1 - z_\\beta \\sqrt{n\\lambda_1} $$\n重新整理各项以求解 $n$：\n$$ n\\lambda_1 - n\\lambda_0 = z_\\alpha \\sqrt{n\\lambda_0} + z_\\beta \\sqrt{n\\lambda_1} $$\n$$ n(\\lambda_1 - \\lambda_0) = \\sqrt{n} (z_\\alpha \\sqrt{\\lambda_0} + z_\\beta \\sqrt{\\lambda_1}) $$\n假设 $n > 0$，我们可以两边同除以 $\\sqrt{n}$：\n$$ \\sqrt{n}(\\lambda_1 - \\lambda_0) = z_\\alpha \\sqrt{\\lambda_0} + z_\\beta \\sqrt{\\lambda_1} $$\n分离出 $\\sqrt{n}$：\n$$ \\sqrt{n} = \\frac{z_\\alpha \\sqrt{\\lambda_0} + z_\\beta \\sqrt{\\lambda_1}}{\\lambda_1 - \\lambda_0} $$\n两边平方得到 $n$ 的表达式：\n$$ n = \\left( \\frac{z_\\alpha \\sqrt{\\lambda_0} + z_\\beta \\sqrt{\\lambda_1}}{\\lambda_1 - \\lambda_0} \\right)^2 $$\n给定 $\\lambda_1 = \\lambda_0(1+\\delta)$，所以 $\\lambda_1 - \\lambda_0 = \\lambda_0 \\delta$。将此代入公式：\n$$ n = \\frac{(z_\\alpha \\sqrt{\\lambda_0} + z_\\beta \\sqrt{\\lambda_0(1+\\delta)})^2}{(\\lambda_0 \\delta)^2} = \\frac{(\\sqrt{\\lambda_0}(z_\\alpha + z_\\beta \\sqrt{1+\\delta}))^2}{\\lambda_0^2 \\delta^2} $$\n$$ n = \\frac{\\lambda_0 (z_\\alpha + z_\\beta \\sqrt{1+\\delta})^2}{\\lambda_0^2 \\delta^2} = \\frac{(z_\\alpha + z_\\beta \\sqrt{1+\\delta})^2}{\\lambda_0 \\delta^2} $$\n这就是样本量 $n$ 的通用解析表达式。\n\n接下来，我们使用给定的参数对这个表达式进行求值：$\\lambda_0=5$, $\\delta=0.1$, $\\alpha=0.05$, 以及 $\\beta=0.2$。\n首先，我们找出标准正态分布对应的 $z$ 分数。\n对于I类错误率 $\\alpha=0.05$，$z_{0.05}$ 是满足 $P(Z > z_{0.05}) = 0.05$ 的值。该值为 $z_{0.05} \\approx 1.64485$。\n对于II类错误率 $\\beta=0.2$，$z_{0.2}$ 是满足 $P(Z > z_{0.2}) = 0.2$ 的值。该值为 $z_{0.2} \\approx 0.84162$。\n\n现在，我们将这些值代入推导出的 $n$ 的公式中：\n$$ n = \\frac{(1.64485 + 0.84162 \\sqrt{1+0.1})^2}{5 \\times (0.1)^2} $$\n$$ n = \\frac{(1.64485 + 0.84162 \\sqrt{1.1})^2}{5 \\times 0.01} $$\n我们来计算各项：\n$$ \\sqrt{1.1} \\approx 1.048809 $$\n$$ n \\approx \\frac{(1.64485 + 0.84162 \\times 1.048809)^2}{0.05} $$\n$$ n \\approx \\frac{(1.64485 + 0.88277)^2}{0.05} $$\n$$ n \\approx \\frac{(2.52762)^2}{0.05} $$\n$$ n \\approx \\frac{6.38886}{0.05} $$\n$$ n \\approx 127.777 $$\n由于样本量 $n$ 必须是整数，并且计算出的值是达到所需错误率的最小值，我们必须对这个值向上取整。样本量为 $127$ 会导致错误率略高于指定值。因此，最小整数样本量是大于计算值的下一个整数。\n$$ n_{\\text{min}} = \\lceil 127.777 \\rceil = 128 $$", "answer": "$$\\boxed{128}$$", "id": "3130913"}, {"introduction": "随着模型变得越来越复杂，对它们的解释也变得愈加精妙。这个问题 [@problem_id:3130912] 探讨了在随机森林特征重要性这一广泛使用的技术背景下，假设检验的微妙之处。你将研究相关联的预测变量如何扭曲置换检验的结果，导致第一类错误膨胀或统计功效降低。深入理解这种情况对于培养准确解释机器学习模型、避免常见陷阱所必需的批判性判断力至关重要。", "problem": "一位数据科学家使用随机森林模型，通过 $n$ 个独立同分布的观测值，从预测变量 $(X_1,\\dots,X_p)$ 中预测一个响应变量 $Y$。为了评估特定预测变量 $X_j$ 的重要性，他们使用了一种基于置换的检验统计量 $T_j$。该统计量定义为：在保持训练好的森林模型不变的情况下，将 $X_j$ 在袋外 (out-of-bag) 样本中进行置换，所导致的袋外预测损失的增加量。他们考虑了一个单边假设检验，其原假设 $H_0$ 为：置换 $X_j$ 对期望泛化损失没有影响；备择假设 $H_1$ 为：置换 $X_j$ 会增加期望损失。该检验在显著性水平 $\\alpha$ 下进行，决策规则是在 $T_j$ 相对于其参考分布足够大时拒绝 $H_0$。第一类错误是在 $H_0$ 为真时拒绝 $H_0$ 的概率，记为 $\\alpha$；第二类错误是在 $H_1$ 为真时未能拒绝 $H_0$ 的概率，记为 $\\beta$。\n\n现在假设存在第二个预测变量 $X_k$，它与 $X_j$ 强相关（例如，$\\operatorname{corr}(X_j,X_k)$ 的绝对值接近 $1$），并且随机森林在训练期间有机会在 $X_j$ 或 $X_k$ 上进行分裂。该科学家关心预测变量之间的相关性如何影响置换检验的有效性以及错误率 $\\alpha$ 和 $\\beta$。他们还考虑了一种条件置换方案，在该方案中，$X_j$ 在以 $X_k$ 为条件的置换（例如，通过在 $X_k$ 的窄区间内对 $X_j$ 进行重排，或者通过从条件分布 $P(X_j \\mid X_k)$ 的估计中抽样 $X_j$），从而使得 $X_j$ 和 $X_k$ 之间的依赖关系在置换下得以保留。\n\n下列哪些陈述是正确的？请选择所有适用选项。\n\nA. 如果 $X_j$ 与 $Y$ 无关，但与一个真正具有预测性的 $X_k$ 强相关，那么在对 $X_j$ 进行标准（无条件）置换的情况下，该检验能维持名义上的第一类错误率 $\\alpha$，因为在 $H_0$ 假设下，置换不会改变 $(X_j,X_k,Y)$ 的联合分布。\n\nB. 如果 $X_j$ 与 $Y$ 无关，但与一个真正具有预测性的 $X_k$ 强相关，那么在对 $X_j$ 进行标准（无条件）置换的情况下，该检验可能会有膨胀的第一类错误率，即 $\\mathbb{P}(\\text{拒绝 }H_0 \\mid H_0) > \\alpha$，因为训练好的森林模型可能会使用 $X_j$ 作为 $X_k$ 的代理，而置换会破坏这种代理关系。\n\nC. 如果 $X_j$ 确实影响 $Y$，但与另一个也携带相同信号的预测变量 $X_k$ 强相关，那么对 $X_j$ 进行标准（无条件）置换会降低检验效能，从而增加 $\\beta$，因为剩余的相关预测变量补偿了被置换的变量，导致观测到的 $T_j$ 值很小。\n\nD. 一种将 $X_j$ 在以 $X_k$ 为条件下进行置换的条件置换方案，其目的在于在 $H_0$ 假设下保留 $X_j$ 和 $X_k$ 之间的依赖结构，从而将第一类错误率的控制恢复到名义水平 $\\alpha$（至少在正则性条件下是渐近成立的）。\n\nE. 条件置换能在任何样本量和任何预测变量间的依赖结构下，同时保证最大的检验效能和对第一类错误率的控制；因此，相对于标准置换，它在所有情况下都能严格减小 $\\beta$，同时将 $\\alpha$ 固定在名义水平。", "solution": "用户希望我验证问题陈述的有效性，如果有效，则通过评估每个选项来解决问题。\n\n### 步骤 1：提取已知条件\n-   **模型：** 随机森林，从预测变量 $(X_1, \\dots, X_p)$ 预测响应变量 $Y$。\n-   **数据：** $n$ 个独立同分布的观测值。\n-   **检验统计量：** $T_j$，当预测变量 $X_j$ 被置换时，袋外（OOB）预测损失的增加量。\n-   **假设：**\n    -   原假设 $H_0$：置换 $X_j$ 对期望泛化损失没有影响。\n    -   备择假设 $H_1$：置换 $X_j$ 会增加期望损失。\n-   **显著性水平：** $\\alpha$。\n-   **决策规则：** 如果 $T_j$ 足够大，则拒绝 $H_0$。\n-   **错误类型：**\n    -   第一类错误：$\\mathbb{P}(\\text{拒绝 } H_0 \\mid H_0 \\text{ 为真}) = \\alpha$。\n    -   第二类错误：$\\mathbb{P}(\\text{未能拒绝 } H_0 \\mid H_1 \\text{ 为真}) = \\beta$。\n-   **场景：** 一个预测变量 $X_k$ 与 $X_j$ 强相关（例如，$|\\operatorname{corr}(X_j,X_k)| \\approx 1$）。\n-   **替代检验：** 一种条件置换方案，其中 $X_j$ 在以 $X_k$ 为条件的置换，以保留它们之间的依赖关系。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准评估问题陈述。\n\n-   **科学依据：** 问题描述了随机森林中基于置换的特征重要性，这是由 Leo Breiman 引入的一种标准技术。提出的问题——多重共线性对该检验的第一类和第二类错误的影响——是有据可查的，并且是机器学习可解释性中的一个核心挑战。条件置换的概念也是统计文献中（例如，由 Strobl 等人）为解决这些问题而提出的一种公认方法。该问题具有科学合理性。\n-   **问题定义明确：** 问题要求在特定条件下（相关预测变量）评估特定假设检验的统计特性（第一类和第二类错误）。问题的结构使其能够根据已建立的统计原则得出一组确定的正确答案。\n-   **客观性：** 语言技术性强、精确，没有主观或模糊的术语。\n-   **完整性：** 问题提供了所有必要的概念信息，以推断错误率 $\\alpha$ 和 $\\beta$ 的定性行为。不需要具体的数值。\n-   **一致性：** 提供的定义和场景在内部是一致的。\n\n### 步骤 3：结论与行动\n问题陈述是**有效的**。这是一个关于统计学习中一个非平凡主题的、表述良好的问题。我现在将进行解答和逐项分析。\n\n***\n\n### 基于原理的推导\n\n这个问题的核心在于理解标准的置换重要性检验究竟衡量的是什么，特别是在存在相关预测变量的情况下。\n\n对预测变量 $X_j$ 进行标准置换特征重要性分析的步骤如下：\n1.  在训练数据上训练一个随机森林模型。\n2.  计算袋外（OOB）预测误差。\n3.  在 OOB 样本中随机置换预测变量 $X_j$ 的值。这打破了 $X_j$ 与响应变量 $Y$ 之间的关联。关键是，这也打破了 $X_j$ 与所有其他预测变量 $X_k$（其中 $k \\neq j$）之间的关联。\n4.  在这个置换过的数据集上计算 OOB 预测误差。\n5.  检验统计量 $T_j$ 是从步骤 2 到步骤 4 的误差增加量。\n\n这个过程所检验的原假设是预测变量 $X_j$ 与响应变量 $Y$ 没有关联。如果 $Y$ 独立于 $X_j$，那么置换 $X_j$ 平均而言不应改变预测误差。\n\n当预测变量相关时，问题就变得复杂了。让我们考虑两个相关的预测变量 $X_j$ 和 $X_k$。\n\n-   **对第一类错误的影响：** 假设 $X_j$ 是一个“无关”预测变量（它对 $Y$ 没有因果效应，并且不提供任何在其他预测变量中不存在的关于 $Y$ 的信息），但它与一个真正具有预测能力的变量 $X_k$ 强相关。形式上，这可以表述为在给定其他预测变量的情况下，$Y$ 与 $X_j$ 条件独立：$Y \\perp X_j \\mid X_{(-j)}$。在这种情况下，“无*额外*预测价值”的原假设为真。然而，由于相关性，$X_j$ 与 $Y$ 并非边缘独立。当我们无条件地置换 $X_j$ 时，我们打破了它与 $X_k$ 的相关性。模型是在 $X_j$ 和 $X_k$ 相关的原始数据上训练的，现在却接收到在真实数据生成分布下极不可能出现的 $(X_j, X_k)$ 数据点对。这可能导致预测不佳和误差大幅增加，即 $T_j$ 增大。因此，检验会错误地拒绝 $H_0$ 并将 $X_j$ 标记为重要，从而导致第一类错误率膨胀。\n\n-   **对第二类错误（检验效能）的影响：** 假设 $X_j$ 和 $X_k$ 都具有真实的预测能力，并且它们也强相关。它们携带了冗余信息。随机森林算法在每次分裂时贪婪地选择预测变量，可能会在某些树中使用 $X_j$，在另一些树中使用 $X_k$。因此，这两个预测变量所携带信号的总“重要性”被稀释或分散了。当我们置换 $X_j$ 以衡量其重要性时，$X_j$ 的信息就丢失了。然而，模型仍然可以依赖高度相关的预测变量 $X_k$ 来进行预测。由于 $X_k$ 补偿了 $X_j$ 的损失，预测误差的增加量 $T_j$ 将会比 $X_j$ 是其信息唯一载体时要小。较小的 $T_j$ 值使其更不可能超过拒绝阈值。因此，检验更难发现 $X_j$ 确实是重要的，这意味着检验的效能较低，或者等价地说，第二类错误率 $\\beta$ 增加。\n\n-   **条件置换：** 这项技术旨在专门解决第一类错误膨胀的问题。通过仅在具有相似其他预测变量（例如 $X_k$）值的观测值组内对 $X_j$ 的值进行置换，该方案试图保留数据的相关性结构。然后，该检验衡量的是在*保持其相关同伴信息不变的情况下*，打破 $X_j$ 和 $Y$ 之间联系的影响。这更准确地检验了条件独立性假设 $Y \\perp X_j \\mid X_{(-j)}$，因此可以将第一类错误率恢复到其名义水平 $\\alpha$。\n\n### 逐项分析\n\n**A. 如果 $X_j$ 与 $Y$ 无关，但与一个真正具有预测性的 $X_k$ 强相关，那么在对 $X_j$ 进行标准（无条件）置换的情况下，该检验能维持名义上的第一类错误率 $\\alpha$，因为在 $H_0$ 假设下，置换不会改变 $(X_j,X_k,Y)$ 的联合分布。**\n\n前提“与 $Y$ 无关”在这种情况下最好被解释为条件意义上的无关（$Y \\perp X_j \\mid X_k$），这样 $X_j$ 才是一个无关变量。该陈述中的推理是有缺陷的。对 $X_j$ 的无条件置换并*不*会使 $(X_j, X_k, Y)$ 的联合分布保持不变。它明确地改变了预测变量的联合分布，使 $X_j$ 和 $X_k$ 变得独立，即它用 $P(X_j)P(X_k)$ 替换了 $P(X_j, X_k)$。由于它们是相关的，$P(X_j, X_k) \\neq P(X_j)P(X_k)$。这为模型创造了不切实际的数据点，而模型是在原始相关结构上训练的。模型的误差增加，导致一个大的 $T_j$ 和对 $H_0$ 的拒绝。这意味着第一类错误率被夸大了，而不是维持在 $\\alpha$。\n**结论：不正确。**\n\n**B. 如果 $X_j$ 与 $Y$ 无关，但与一个真正具有预测性的 $X_k$ 强相关，那么在对 $X_j$ 进行标准（无条件）置换的情况下，该检验可能会有膨胀的第一类错误率，即 $\\mathbb{P}(\\text{拒绝 }H_0 \\mid H_0) > \\alpha$，因为训练好的森林模型可能会使用 $X_j$ 作为 $X_k$ 的代理，而置换会破坏这种代理关系。**\n\n该陈述准确地描述了第一类错误率膨胀的机制。由于 $X_j$ 和真正具有预测性的 $X_k$ 之间存在强相关性，随机森林可能学会使用 $X_j$ 作为 $X_k$ 的代理。无条件置换通过解耦 $X_j$ 和 $X_k$ 来切断这种代理关系。模型现在看到它未曾训练过的特征组合（例如，一个与 $X_k$ 值“不一致”的 $X_j$ 值），导致其预测性能显著下降。这导致一个大的检验统计量 $T_j$，使得即使当 $X_j$ 没有提供超出 $X_k$ 的额外信息时，也频繁拒绝原假设。因此，第一类错误率超过了名义水平 $\\alpha$。\n**结论：正确。**\n\n**C. 如果 $X_j$ 确实影响 $Y$，但与另一个也携带相同信号的预测变量 $X_k$ 强相关，那么对 $X_j$ 进行标准（无条件）置换会降低检验效能，从而增加 $\\beta$，因为剩余的相关预测变量补偿了被置换的变量，导致观测到的 $T_j$ 值很小。**\n\n该陈述正确地指出了检验效能损失的问题。当两个预测变量是冗余的时，模型对其中任何一个的依赖性都会减弱。重要性被“分享”了。当 $X_j$ 被置换时，模型仍然可以使用包含相似信息的 $X_k$。$X_k$ 的这种补偿作用意味着性能下降的幅度（以及 $T_j$ 的值）没有模型中不存在 $X_k$ 时的那么显著。一个较小的 $T_j$ 意味着检验不太可能正确地将 $X_j$ 识别为重要变量，从而降低了检验的效能（$1-\\beta$）并增加了第二类错误率 $\\beta$。\n**结论：正确。**\n\n**D. 一种将 $X_j$ 在以 $X_k$ 为条件下进行置换的条件置换方案，其目的在于在 $H_0$ 假设下保留 $X_j$ 和 $X_k$ 之间的依赖结构，从而将第一类错误率的控制恢复到名义水平 $\\alpha$（至少在正则性条件下是渐近成立的）。**\n\n该陈述正确地描述了条件置换的目的和效果。通过仅在具有相似 $X_k$ 值的观测数据点中对 $X_j$ 进行重排，它们之间的相关性得以保持。检验不再受到创建“不切实际”数据点的影响。相反，它隔离了在考虑了 $X_k$ 之后 $X_j$ 的独特贡献。这个过程是专门设计用来检验条件重要性并纠正标准置换检验中第一类错误率膨胀的问题的。限定词“至少在正则性条件下是渐近成立的”是恰当的，因为有限样本的性能取决于条件化的质量（例如，分箱大小或估计的条件分布的准确性）。\n**结论：正确。**\n\n**E. 条件置换能在任何样本量和任何预测变量间的依赖结构下，同时保证最大的检验效能和对第一类错误率的控制；因此，相对于标准置换，它在所有情况下都能严格减小 $\\beta$，同时将 $\\alpha$ 固定在名义水平。**\n\n这个陈述过于强烈和绝对。统计方法很少（如果曾经有的话）能提供如此普遍的保证。\n1.  **“在任何样本量下保证...”**：第一类错误率的控制和检验效能的特性通常是渐近的。在有限样本中，条件化的有效性是不完美的。\n2.  **“最大的检验效能”**：没有最大检验效能的保证。事实上，通过检验一个更具体、有条件的假设，如果感兴趣的是边际效应，该检验可能反而会降低发现它的效能。\n3.  **“在所有情况下都严格减小 $\\beta$”**：这是错误的。一个减少膨胀的第一类错误率的程序通常需要在效能上进行权衡。不能保证条件置换在所有情况下都比标准置换更具效能。例如，在没有相关性的情况下，条件化的额外复杂性可能会引入噪声，并与更简单且在这种情况下有效的标准置换检验相比，略微降低效能。这一说法夸大了该方法的优点。\n**结论：不正确。**", "answer": "$$\\boxed{BCD}$$", "id": "3130912"}]}