{"hands_on_practices": [{"introduction": "在使用验证集方法时，一个基本的实践问题是：需要多大的验证集才能可靠地判断一个模型是否优于另一个？本练习将引导您从统计功效分析的角度来回答这个问题。通过推导检测两个模型之间给定性能差异所需的最小验证集大小，您将学习如何设计具有统计学意义的模型比较实验，确保您的结论不仅仅是随机性的产物 [@problem_id:3187538]。", "problem": "您正在使用验证集方法比较两个监督学习模型 $\\mathcal{M}_{1}$ 和 $\\mathcal{M}_{2}$。对于每个具有特征-响应对 $(\\boldsymbol{x}, y)$ 的验证观测值，定义一个瞬时损失 $\\ell(y, f(\\boldsymbol{x}))$。假设如下：\n- 对于模型 $\\mathcal{M}_{j}$，每个观测值的验证损失 $\\{\\ell_{j,i}\\}_{i=1}^{n_{j}}$ 是独立同分布的，其均值为 $\\mu_{j}$，方差为 $\\sigma^{2}$，其中 $j \\in \\{1,2\\}$。\n- 这两个模型在不相交的验证子集上进行评估，以确保模型间的独立性。您为每个模型分配相同数量的验证观测值，因此 $n_{1} = n_{2} = n_{\\text{val}}/2$，其中 $n_{\\text{val}}$ 是验证集的总大小。\n- 您将通过基于中心极限定理 (CLT) 和标准正态近似的均值差异双样本检验来比较平均验证损失。\n\n您将在显著性水平 $\\alpha$ 下，检验原假设 $H_{0}: \\mu_{1} - \\mu_{2} = 0$ 与双边备择假设 $H_{1}: \\mu_{1} - \\mu_{2} \\neq 0$。您希望设计的 $n_{\\text{val}}$ 足够大，以便当平均损失的真实差异量值为 $\\delta  0$（即 $|\\mu_{1} - \\mu_{2}| = \\delta$）时，检验的功效为 $1 - \\beta$。假设为了设计的目的，共同方差 $\\sigma^{2}$ 是已知的。令 $z_{p}$ 表示标准正态分布的 $p$-分位数。\n\n从第一性原理（中心极限定理和双样本 z 检验的 I/II 型错误的定义）出发，推导在显著性水平 $\\alpha$ 下达到期望功效所需的最小总验证集大小 $n_{\\text{val}}$ 的闭式解析表达式，该表达式用 $\\alpha$、$\\beta$、$\\sigma^{2}$ 和 $\\delta$ 表示。将您的最终答案表示为关于 $\\alpha$、$\\beta$、$\\sigma^{2}$、$\\delta$ 和 $z_{p}$ 的单个解析表达式。不需要数值近似或四舍五入。", "solution": "用户希望找到双样本检验达到指定功效所需的最小总验证集大小 $n_{\\text{val}}$。\n\n### 步骤 1：提取已知条件\n-   模型：$\\mathcal{M}_{1}$、$\\mathcal{M}_{2}$。\n-   损失函数：$\\ell(y, f(\\boldsymbol{x}))$。\n-   模型 $\\mathcal{M}_{j}$ 的每个观测值的验证损失：$\\{\\ell_{j,i}\\}_{i=1}^{n_{j}}$。\n-   损失的分布：集合 $\\{\\ell_{j,i}\\}_{i=1}^{n_{j}}$ 被假设为独立同分布（i.i.d.）随机变量的样本，其均值为 $E[\\ell_{j,i}] = \\mu_{j}$，方差为 $\\text{Var}(\\ell_{j,i}) = \\sigma^{2}$，其中 $j \\in \\{1,2\\}$。\n-   验证集：这两个模型在不相交的验证子集上进行评估。\n-   样本大小：$n_{1} = n_{2} = n_{\\text{val}}/2$。\n-   检验程序：基于中心极限定理 (CLT) 和标准正态近似的均值差异双样本检验。\n-   原假设 $H_{0}$：$\\mu_{1} - \\mu_{2} = 0$。\n-   备择假设 $H_{1}$：$\\mu_{1} - \\mu_{2} \\neq 0$。\n-   显著性水平（I 型错误率）：$\\alpha$。\n-   期望功效：$1 - \\beta$，其中 $\\beta$ 是 II 型错误率。\n-   效应大小（真实差异）：$|\\mu_{1} - \\mu_{2}| = \\delta  0$。\n-   已知共同方差：$\\sigma^{2}$。\n-   符号：$z_{p}$ 表示标准正态分布的 $p$-分位数。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，提法明确且客观。它提出了一个统计假设检验和功效分析中的标准和基本问题，特别应用于机器学习中的模型比较。其设定是自洽且一致的；所有必要的参数（$\\alpha$、$\\beta$、$\\sigma^{2}$、$\\delta$）和假设（独立同分布的损失、CLT 近似、已知方差）都已提供，以推导所需的样本大小 $n_{\\text{val}}$。该问题不违反任何科学原理，没有歧义，并且需要基于统计学第一性原理进行形式化推导。\n\n### 步骤 3：结论与行动\n该问题有效。将提供一个完整的、有理有据的解决方案。\n\n### 推导\n令 $n = n_{1} = n_{2} = n_{\\text{val}}/2$ 为每个验证子集中的观测数量。令 $\\bar{L}_{1} = \\frac{1}{n} \\sum_{i=1}^{n} \\ell_{1,i}$ 和 $\\bar{L}_{2} = \\frac{1}{n} \\sum_{i=1}^{n} \\ell_{2,i}$ 分别为模型 $\\mathcal{M}_{1}$ 和 $\\mathcal{M}_{2}$ 的样本平均损失。\n\n我们关心的是平均损失的差异，其估计量为 $\\bar{D} = \\bar{L}_{1} - \\bar{L}_{2}$。\n该估计量的期望值为 $E[\\bar{D}] = E[\\bar{L}_{1}] - E[\\bar{L}_{2}] = \\mu_{1} - \\mu_{2}$。\n由于两个验证集是独立的，该估计量的方差为 $\\text{Var}(\\bar{D}) = \\text{Var}(\\bar{L}_{1}) + \\text{Var}(\\bar{L}_{2})$。\n由于单个损失是独立同分布的，每个样本均值的方差为 $\\text{Var}(\\bar{L}_{j}) = \\frac{\\sigma^{2}}{n}$。\n因此，差异的方差为 $\\text{Var}(\\bar{D}) = \\frac{\\sigma^{2}}{n} + \\frac{\\sigma^{2}}{n} = \\frac{2\\sigma^{2}}{n}$。\n\n根据中心极限定理，对于足够大的样本量 $n$，$\\bar{D}$ 的分布近似为正态分布：\n$$ \\bar{D} \\approx \\mathcal{N}\\left(\\mu_{1} - \\mu_{2}, \\frac{2\\sigma^{2}}{n}\\right) $$\n在原假设 $H_{0}: \\mu_{1} - \\mu_{2} = 0$ 下，检验统计量 $Z$ 是通过对 $\\bar{D}$ 进行标准化来构建的：\n$$ Z = \\frac{\\bar{D} - 0}{\\sqrt{\\text{Var}(\\bar{D})}} = \\frac{\\bar{L}_{1} - \\bar{L}_{2}}{\\sqrt{2\\sigma^{2}/n}} $$\n在 $H_{0}$ 下，$Z$ 服从标准正态分布，$Z \\sim \\mathcal{N}(0, 1)$。\n\n对于显著性水平为 $\\alpha$ 的双边检验，如果 $|Z|$ 的观测值大于临界值 $z_{1-\\alpha/2}$，我们拒绝 $H_{0}$。拒绝域为 $|Z|  z_{1-\\alpha/2}$。这等价于如果 $|\\bar{D}|  z_{1-\\alpha/2} \\sqrt{\\frac{2\\sigma^{2}}{n}}$，则拒绝 $H_{0}$。\n\n检验的功效是 $1-\\beta$，即当备择假设 $H_{1}$ 为真时正确拒绝 $H_{0}$ 的概率。我们已知在 $H_{1}$ 下，真实差异的量值为 $|\\mu_{1} - \\mu_{2}| = \\delta  0$。我们可以不失一般性地分析 $\\mu_{1} - \\mu_{2} = \\delta$ 的情况；$\\mu_{1} - \\mu_{2} = -\\delta$ 的情况会得到对称的结果。\n\n功效是在 $\\mu_{1} - \\mu_{2} = \\delta$ 的条件下，$\\bar{D}$ 落入拒绝域的概率：\n$$ 1 - \\beta = P\\left(|\\bar{D}|  z_{1-\\alpha/2} \\sqrt{\\frac{2\\sigma^{2}}{n}} \\;\\Bigg|\\; \\mu_{1} - \\mu_{2} = \\delta\\right) $$\n$$ 1 - \\beta = P\\left(\\bar{D}  z_{1-\\alpha/2} \\sqrt{\\frac{2\\sigma^{2}}{n}}\\right) + P\\left(\\bar{D}  -z_{1-\\alpha/2} \\sqrt{\\frac{2\\sigma^{2}}{n}}\\right) $$\n其中概率是在 $\\bar{D} \\sim \\mathcal{N}(\\delta, \\frac{2\\sigma^{2}}{n})$ 的假设下计算的。\n对于一个设计良好且功效相当高的检验，在 $H_{1}$ 下 $\\bar{D}$ 的分布会远离 0。第二项 $P(\\bar{D}  -z_{1-\\alpha/2} \\sqrt{\\frac{2\\sigma^{2}}{n}})$ 对应于在“错误”的尾部拒绝，通常可以忽略不计。因此，我们只考虑主要项来近似功效：\n$$ 1 - \\beta \\approx P\\left(\\bar{D}  z_{1-\\alpha/2} \\sqrt{\\frac{2\\sigma^{2}}{n}} \\;\\Bigg|\\; \\mu_{1} - \\mu_{2} = \\delta\\right) $$\n为了评估这个概率，我们在备择假设下对 $\\bar{D}$ 进行标准化：\n$$ 1 - \\beta \\approx P\\left( \\frac{\\bar{D} - \\delta}{\\sqrt{2\\sigma^{2}/n}}  \\frac{z_{1-\\alpha/2}\\sqrt{2\\sigma^{2}/n} - \\delta}{\\sqrt{2\\sigma^{2}/n}} \\right) $$\n令 $Z' = \\frac{\\bar{D} - \\delta}{\\sqrt{2\\sigma^{2}/n}}$。在 $H_{1}$ 下，$Z' \\sim \\mathcal{N}(0, 1)$。方程变为：\n$$ 1 - \\beta \\approx P\\left( Z'  z_{1-\\alpha/2} - \\frac{\\delta}{\\sqrt{2\\sigma^{2}/n}} \\right) $$\n如果 $P(Z'  c) = 1-\\beta$，那么 $c$ 必须是标准正态分布的 $\\beta$-分位数，即 $c = z_{\\beta}$。根据正态分布的对称性，$z_{\\beta} = -z_{1-\\beta}$。所以我们有：\n$$ -z_{1-\\beta} = z_{1-\\alpha/2} - \\frac{\\delta}{\\sqrt{2\\sigma^{2}/n}} $$\n现在，我们求解 $n$：\n$$ \\frac{\\delta}{\\sqrt{2\\sigma^{2}/n}} = z_{1-\\alpha/2} + z_{1-\\beta} $$\n$$ \\frac{\\delta \\sqrt{n}}{\\sqrt{2\\sigma^{2}}} = z_{1-\\alpha/2} + z_{1-\\beta} $$\n$$ \\sqrt{n} = \\frac{\\sqrt{2\\sigma^{2}}}{\\delta} (z_{1-\\alpha/2} + z_{1-\\beta}) $$\n两边平方，得到每组所需的样本大小：\n$$ n = \\frac{2\\sigma^{2}(z_{1-\\alpha/2} + z_{1-\\beta})^2}{\\delta^2} $$\n问题要求的是总验证集大小 $n_{\\text{val}}$。由于 $n = n_{\\text{val}}/2$，我们有：\n$$ n_{\\text{val}} = 2n = \\frac{4\\sigma^{2}(z_{1-\\alpha/2} + z_{1-\\beta})^2}{\\delta^2} $$\n该表达式给出了在显著性水平 $\\alpha$ 下，以功效 $1-\\beta$ 检测到量值为 $\\delta$ 的真实差异所需的最小总验证样本数。", "answer": "$$\\boxed{\\frac{4\\sigma^{2}(z_{1-\\alpha/2} + z_{1-\\beta})^{2}}{\\delta^{2}}}$$", "id": "3187538"}, {"introduction": "在真实世界应用中，训练数据和部署环境的数据分布常常不一致，这被称为“数据集偏移”。此练习探讨了一种常见情况——“类别先验偏移”，即训练集和验证集中类别的比例不同。您将从贝叶斯定理出发，推导如何在这种偏移下调整分类器的决策阈值，并计算因使用未校正的“朴素”阈值而导致的性能损失 [@problem_id:3187498]。这项实践揭示了验证方法的一个关键陷阱，并培养了在非理想条件下进行稳健模型评估的能力。", "problem": "考虑一个二元分类问题，其标签为 $Y \\in \\{0,1\\}$，特征向量为 $X \\in \\mathbb{R}^{d}$。一个分类器产生一个得分 $s(X)$，该得分已针对训练分布进行了校准，即 $s(X) = P_{\\text{train}}(Y=1 \\mid X)$，其中训练集类别先验为 $\\pi_{\\text{train}} = P_{\\text{train}}(Y=1)$。假设训练分布和验证分布之间存在类别先验漂移，即类条件特征密度满足 $p_{\\text{train}}(X \\mid Y=y) = p_{\\text{val}}(X \\mid Y=y)$ (对于 $y \\in \\{0,1\\}$)，而类别先验则变为 $\\pi_{\\text{val}} = P_{\\text{val}}(Y=1) \\neq \\pi_{\\text{train}}$。在0-1损失下，通过对得分进行阈值处理来做出预测：如果 $s(X) \\ge t$，则 $\\hat{Y} = 1$，否则 $\\hat{Y} = 0$。\n\n从贝叶斯定理出发，推导验证后验概率 $P_{\\text{val}}(Y=1 \\mid X)$ 关于校准得分 $s(X)$ 和先验 $\\pi_{\\text{train}}$、$\\pi_{\\text{val}}$ 的表达式，并证明在验证分布下的贝叶斯最优决策可以通过对 $s(X)$ 在一个依赖于 $\\pi_{\\text{train}}$ 和 $\\pi_{\\text{val}}$ 的、经先验调整的阈值 $t^{\\star}$ 处进行阈值处理来实现。\n\n为了量化先验不匹配对验证误差的影响，假设在训练分布下，以真实标签为条件的得分分布为\n$$\nf_{S \\mid Y=1}(s) = 2s, \\quad f_{S \\mid Y=0}(s) = 2(1-s), \\quad \\text{for } s \\in [0,1],\n$$\n这与在 $\\pi_{\\text{train}} = \\frac{1}{2}$ 和均匀边际得分密度下的校准是一致的。在验证分布下，对于阈值 $t$，期望0-1误差为\n$$\n\\text{Err}_{\\text{val}}(t) = P_{\\text{val}}(\\hat{Y} \\neq Y) = (1-\\pi_{\\text{val}})\\int_{t}^{1} f_{S \\mid Y=0}(s) \\, ds + \\pi_{\\text{val}} \\int_{0}^{t} f_{S \\mid Y=1}(s) \\, ds.\n$$\n\n设 $\\pi_{\\text{train}} = \\frac{1}{2}$ 且 $\\pi_{\\text{val}} = \\frac{3}{10}$。计算使用经先验调整的阈值 $t^{\\star}$ 而不是朴素阈值 $t=\\frac{1}{2}$ 所获得的验证误差的绝对减少量 $\\Delta$，即\n$$\n\\Delta = \\text{Err}_{\\text{val}}\\!\\left(\\frac{1}{2}\\right) - \\text{Err}_{\\text{val}}(t^{\\star}).\n$$\n将您的数值答案四舍五入到四位有效数字。以小数形式表示您的最终答案，不带百分号。", "solution": "该问题要求完成三项任务：首先，根据校准的训练得分 $s(X) = P_{\\text{train}}(Y=1 \\mid X)$ 以及训练和验证先验 $\\pi_{\\text{train}}$ 和 $\\pi_{\\text{val}}$，推导验证后验概率 $P_{\\text{val}}(Y=1 \\mid X)$ 的表达式。其次，证明在验证分布下的贝叶斯最优决策规则对应于对 $s(X)$ 在一个调整后的阈值 $t^{\\star}$ 处进行阈值处理。第三，计算使用此最优阈值与朴素阈值相比所实现的验证误差的减少量。\n\n首先，我们推导验证后验概率 $P_{\\text{val}}(Y=1 \\mid X)$ 的表达式。根据贝叶斯定理，在验证分布上的后验概率为：\n$$ P_{\\text{val}}(Y=1 \\mid X) = \\frac{p_{\\text{val}}(X \\mid Y=1) P_{\\text{val}}(Y=1)}{p_{\\text{val}}(X)} $$\n分母，即边际密度 $p_{\\text{val}}(X)$，可以使用全概率公式展开：\n$$ p_{\\text{val}}(X) = p_{\\text{val}}(X \\mid Y=1) P_{\\text{val}}(Y=1) + p_{\\text{val}}(X \\mid Y=0) P_{\\text{val}}(Y=0) $$\n使用给定的先验 $\\pi_{\\text{val}} = P_{\\text{val}}(Y=1)$ 和 $1-\\pi_{\\text{val}} = P_{\\text{val}}(Y=0)$，上式变为：\n$$ P_{\\text{val}}(Y=1 \\mid X) = \\frac{p_{\\text{val}}(X \\mid Y=1) \\pi_{\\text{val}}}{p_{\\text{val}}(X \\mid Y=1) \\pi_{\\text{val}} + p_{\\text{val}}(X \\mid Y=0) (1-\\pi_{\\text{val}})} $$\n问题陈述了存在类别先验漂移，其中类条件密度不变：$p_{\\text{train}}(X \\mid Y=y) = p_{\\text{val}}(X \\mid Y=y)$ 对于 $y \\in \\{0,1\\}$。将这些代入方程中：\n$$ P_{\\text{val}}(Y=1 \\mid X) = \\frac{p_{\\text{train}}(X \\mid Y=1) \\pi_{\\text{val}}}{p_{\\text{train}}(X \\mid Y=1) \\pi_{\\text{val}} + p_{\\text{train}}(X \\mid Y=0) (1-\\pi_{\\text{val}})} $$\n接下来，我们将类条件密度 $p_{\\text{train}}(X \\mid Y)$ 与校准得分 $s(X)$ 联系起来。根据 $s(X) = P_{\\text{train}}(Y=1 \\mid X)$ 的定义和在训练分布上的贝叶斯定理：\n$$ s(X) = \\frac{p_{\\text{train}}(X \\mid Y=1) \\pi_{\\text{train}}}{p_{\\text{train}}(X)} \\implies p_{\\text{train}}(X \\mid Y=1) = \\frac{s(X) p_{\\text{train}}(X)}{\\pi_{\\text{train}}} $$\n$$ 1-s(X) = \\frac{p_{\\text{train}}(X \\mid Y=0) (1-\\pi_{\\text{train}})}{p_{\\text{train}}(X)} \\implies p_{\\text{train}}(X \\mid Y=0) = \\frac{(1-s(X)) p_{\\text{train}}(X)}{1-\\pi_{\\text{train}}} $$\n将这些类条件密度的表达式代入 $P_{\\text{val}}(Y=1 \\mid X)$ 的方程中：\n$$ P_{\\text{val}}(Y=1 \\mid X) = \\frac{\\frac{s(X) p_{\\text{train}}(X)}{\\pi_{\\text{train}}} \\pi_{\\text{val}}}{\\frac{s(X) p_{\\text{train}}(X)}{\\pi_{\\text{train}}} \\pi_{\\text{val}} + \\frac{(1-s(X)) p_{\\text{train}}(X)}{1-\\pi_{\\text{train}}} (1-\\pi_{\\text{val}})} $$\n项 $p_{\\text{train}}(X)$ 从分子和分母中消去，得到所需的表达式：\n$$ P_{\\text{val}}(Y=1 \\mid X) = \\frac{\\frac{s(X) \\pi_{\\text{val}}}{\\pi_{\\text{train}}}}{\\frac{s(X) \\pi_{\\text{val}}}{\\pi_{\\text{train}}} + \\frac{(1-s(X))(1-\\pi_{\\text{val}})}{1-\\pi_{\\text{train}}}} $$\n这可以通过将分子和分母同乘以 $\\pi_{\\text{train}}(1-\\pi_{\\text{train}})$ 来简化：\n$$ P_{\\text{val}}(Y=1 \\mid X) = \\frac{s(X) (1-\\pi_{\\text{train}}) \\pi_{\\text{val}}}{s(X) (1-\\pi_{\\text{train}}) \\pi_{\\text{val}} + (1-s(X)) \\pi_{\\text{train}} (1-\\pi_{\\text{val}})} $$\n对于0-1损失，贝叶斯最优分类器预测后验概率最高的类别。在验证分布下的决策规则是，如果 $P_{\\text{val}}(Y=1 \\mid X) \\ge \\frac{1}{2}$，则预测 $\\hat{Y}=1$。使用我们推导的表达式，这等价于：\n$$ \\frac{s(X) (1-\\pi_{\\text{train}}) \\pi_{\\text{val}}}{s(X) (1-\\pi_{\\text{train}}) \\pi_{\\text{val}} + (1-s(X)) \\pi_{\\text{train}} (1-\\pi_{\\text{val}})} \\ge \\frac{1}{2} $$\n假设 $s(X) \\in (0,1)$，则分母为正，因此我们可以交叉相乘：\n$$ 2 s(X) (1-\\pi_{\\text{train}}) \\pi_{\\text{val}} \\ge s(X) (1-\\pi_{\\text{train}}) \\pi_{\\text{val}} + (1-s(X)) \\pi_{\\text{train}} (1-\\pi_{\\text{val}}) $$\n$$ s(X) (1-\\pi_{\\text{train}}) \\pi_{\\text{val}} \\ge (1-s(X)) \\pi_{\\text{train}} (1-\\pi_{\\text{val}}) $$\n$$ s(X) [(1-\\pi_{\\text{train}}) \\pi_{\\text{val}} + \\pi_{\\text{train}} (1-\\pi_{\\text{val}})] \\ge \\pi_{\\text{train}} (1-\\pi_{\\text{val}}) $$\n这表明最优决策是在一个新值 $t^{\\star}$ 处对原始得分 $s(X)$ 进行阈值处理：\n$$ s(X) \\ge \\frac{\\pi_{\\text{train}} (1-\\pi_{\\text{val}})}{(1-\\pi_{\\text{train}}) \\pi_{\\text{val}} + \\pi_{\\text{train}} (1-\\pi_{\\text{val}})} = t^{\\star} $$\n现在我们进行数值计算。给定 $\\pi_{\\text{train}} = \\frac{1}{2}$ 和 $\\pi_{\\text{val}} = \\frac{3}{10}$。最优阈值 $t^{\\star}$ 是：\n$$ t^{\\star} = \\frac{\\frac{1}{2} \\left(1-\\frac{3}{10}\\right)}{\\left(1-\\frac{1}{2}\\right) \\frac{3}{10} + \\frac{1}{2} \\left(1-\\frac{3}{10}\\right)} = \\frac{\\frac{1}{2} \\cdot \\frac{7}{10}}{\\frac{1}{2} \\cdot \\frac{3}{10} + \\frac{1}{2} \\cdot \\frac{7}{10}} = \\frac{\\frac{7}{20}}{\\frac{3}{20} + \\frac{7}{20}} = \\frac{\\frac{7}{20}}{\\frac{10}{20}} = \\frac{7}{10} = 0.7 $$\n对于阈值 $t$ 的验证误差由下式给出：\n$$ \\text{Err}_{\\text{val}}(t) = P_{\\text{val}}(\\hat{Y} \\neq Y) = (1-\\pi_{\\text{val}})\\int_{t}^{1} f_{S \\mid Y=0}(s) \\, ds + \\pi_{\\text{val}} \\int_{0}^{t} f_{S \\mid Y=1}(s) \\, ds $$\n当 $f_{S \\mid Y=1}(s) = 2s$ 和 $f_{S \\mid Y=0}(s) = 2(1-s)$ 时，我们计算积分：\n$$ \\int_{t}^{1} 2(1-s) \\, ds = \\left[ -(1-s)^2 \\right]_{t}^{1} = 0 - (-(1-t)^2) = (1-t)^2 $$\n$$ \\int_{0}^{t} 2s \\, ds = \\left[ s^2 \\right]_{0}^{t} = t^2 $$\n将这些代入 $\\pi_{\\text{val}} = \\frac{3}{10}$ 的误差表达式中：\n$$ \\text{Err}_{\\text{val}}(t) = \\left(1-\\frac{3}{10}\\right) (1-t)^2 + \\frac{3}{10} t^2 = \\frac{7}{10} (1-t)^2 + \\frac{3}{10} t^2 $$\n我们需要计算朴素阈值 $t=\\frac{1}{2}$ 和最优阈值 $t^{\\star}=\\frac{7}{10}$ 的误差。\n对于 $t=\\frac{1}{2}$：\n$$ \\text{Err}_{\\text{val}}\\!\\left(\\frac{1}{2}\\right) = \\frac{7}{10} \\left(1-\\frac{1}{2}\\right)^2 + \\frac{3}{10} \\left(\\frac{1}{2}\\right)^2 = \\frac{7}{10} \\left(\\frac{1}{4}\\right) + \\frac{3}{10} \\left(\\frac{1}{4}\\right) = \\left(\\frac{7}{10} + \\frac{3}{10}\\right) \\frac{1}{4} = 1 \\cdot \\frac{1}{4} = \\frac{1}{4} = 0.25 $$\n对于 $t^{\\star}=\\frac{7}{10}$：\n$$ \\text{Err}_{\\text{val}}(t^{\\star}) = \\text{Err}_{\\text{val}}\\!\\left(\\frac{7}{10}\\right) = \\frac{7}{10} \\left(1-\\frac{7}{10}\\right)^2 + \\frac{3}{10} \\left(\\frac{7}{10}\\right)^2 = \\frac{7}{10} \\left(\\frac{3}{10}\\right)^2 + \\frac{3}{10} \\left(\\frac{7}{10}\\right)^2 $$\n$$ = \\frac{7}{10} \\cdot \\frac{9}{100} + \\frac{3}{10} \\cdot \\frac{49}{100} = \\frac{63}{1000} + \\frac{147}{1000} = \\frac{210}{1000} = 0.21 $$\n验证误差的绝对减少量 $\\Delta$ 是这两个误差值之差：\n$$ \\Delta = \\text{Err}_{\\text{val}}\\!\\left(\\frac{1}{2}\\right) - \\text{Err}_{\\text{val}}(t^{\\star}) = 0.25 - 0.21 = 0.04 $$\n问题要求答案四舍五入到四位有效数字。因此，$0.04$ 写作 $0.04000$。", "answer": "$$\\boxed{0.04000}$$", "id": "3187498"}, {"introduction": "理论知识需要在实践中得到巩固。本练习要求您编写程序，将前一个练习 [@problem_id:3187498] 中关于类别先验偏移的概念付诸实践。您将实现一个场景，其中分类器的决策阈值在验证集上进行调整，然后在具有不同类别普遍性和非对称错误成本的部署环境中使用，并量化由此产生的“性能漂移” [@problem_id:3187560]。通过亲手编码和观察结果，您将深刻理解在模型部署中适应数据分布变化的重要性。", "problem": "您将实现一个程序，比较通过验证集方法选择的固定决策阈值与部署流行度下的成本敏感最优阈值，并量化当部署时流行度发生变化时所导致的性能漂移。\n\n您有一个二元分类器，它输出一个连续的分数。对于类别标签 $Y \\in \\{0,1\\}$，分数 $S$ 的类条件分布是方差相等的高斯（正态）分布。具体来说，对于类别 $Y=0$，$S \\sim \\mathcal{N}(\\mu_0,\\sigma^2)$；对于类别 $Y=1$，$S \\sim \\mathcal{N}(\\mu_1,\\sigma^2)$，其中 $\\sigma  0$ 且 $\\mu_1 \\neq \\mu_0$。阈值规则规定，当且仅当 $S \\ge t$ 时，预测 $\\hat{Y}=1$。\n\n您将使用以下基本原理：\n- 在流行度为 $\\pi = \\mathbb{P}(Y=1)$、假阳性成本为 $c_{\\mathrm{FP}}  0$、假阴性成本为 $c_{\\mathrm{FN}}  0$ 的情况下，预期的误分类成本由预期风险给出：\n$$\n\\mathcal{L}(t;\\pi) = c_{\\mathrm{FN}} \\, \\pi \\, \\mathbb{P}(S  t \\mid Y=1) \\;+\\; c_{\\mathrm{FP}} \\, (1-\\pi) \\, \\mathbb{P}(S \\ge t \\mid Y=0).\n$$\n- 对于高斯类条件分布和阈值规则，这些概率是正态累积分布函数的积分。\n\n您的任务：\n1) 验证集调优。对于给定的验证流行度 $\\pi_{\\mathrm{val}}$、假阳性成本 $c_{\\mathrm{FP}}$、假阴性成本 $c_{\\mathrm{FN}}$ 和类条件参数 $(\\mu_0,\\mu_1,\\sigma)$，选择使预期误分类成本 $\\mathcal{L}(t;\\pi_{\\mathrm{val}})$ 最小化的阈值 $t_{\\mathrm{val}}^\\star$。\n2) 部署评估与流行度变化。对于给定的部署流行度 $\\pi_{\\mathrm{dep}}$，评估使用验证集调优的阈值时在部署阶段的预期成本 $\\mathcal{L}(t_{\\mathrm{val}}^\\star;\\pi_{\\mathrm{dep}})$。\n3) 部署时的成本敏感最优阈值。计算使 $\\mathcal{L}(t;\\pi_{\\mathrm{dep}})$ 最小化的阈值 $t_{\\mathrm{dep}}^\\star$，并计算相应的最小部署成本 $\\mathcal{L}(t_{\\mathrm{dep}}^\\star;\\pi_{\\mathrm{dep}})$。\n4) 量化性能漂移。报告：\n- 使用验证集选择的阈值时的部署成本 $\\mathcal{L}(t_{\\mathrm{val}}^\\star;\\pi_{\\mathrm{dep}})$。\n- 最优部署成本 $\\mathcal{L}(t_{\\mathrm{dep}}^\\star;\\pi_{\\mathrm{dep}})$。\n- 定义为 $\\mathcal{L}(t_{\\mathrm{val}}^\\star;\\pi_{\\mathrm{dep}}) \\big/ \\mathcal{L}(t_{\\mathrm{dep}}^\\star;\\pi_{\\mathrm{dep}})$ 的乘性漂移比率。\n\n实现要求：\n- 基于上述高斯模型，使用精确的正态累积分布和密度计算（不使用蒙特卡洛采样）。\n- 最小化预期成本的阈值必须通过第一性原理最小化预期风险来获得；您可以解析或数值地完成此操作。\n- 所有输出必须是实数。将所有报告的浮点输出四舍五入到 $6$ 位小数。\n\n测试套件：\n对于每个测试用例，您将获得 $(\\mu_0,\\mu_1,\\sigma,\\pi_{\\mathrm{val}},\\pi_{\\mathrm{dep}},c_{\\mathrm{FP}},c_{\\mathrm{FN}})$。\n\n为以下 $5$ 个测试用例提供结果：\n- 案例 A（无流行度变化，对称成本，类别分离良好）：$(\\mu_0,\\mu_1,\\sigma,\\pi_{\\mathrm{val}},\\pi_{\\mathrm{dep}},c_{\\mathrm{FP}},c_{\\mathrm{FN}}) = (0, 2, 1, 0.5, 0.5, 1, 1)$。\n- 案例 B（中度流行度变化，正例变少）：$(0, 2, 1, 0.5, 0.2, 1, 1)$。\n- 案例 C（极端流行度变化，正例非常罕见）：$(0, 2, 1, 0.5, 0.02, 1, 1)$。\n- 案例 D（中度变化伴随非对称成本，假阴性成本更高）：$(0, 2, 1, 0.5, 0.2, 1, 5)$。\n- 案例 E（高部署流行度，弱分离，非对称成本）：$(0, 0.5, 1, 0.5, 0.8, 1, 2)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有案例的结果，形式为列表的列表，每个内部列表包含三个浮点数，顺序为 $[\\mathcal{L}(t_{\\mathrm{val}}^\\star;\\pi_{\\mathrm{dep}}), \\mathcal{L}(t_{\\mathrm{dep}}^\\star;\\pi_{\\mathrm{dep}}), \\mathcal{L}(t_{\\mathrm{val}}^\\star;\\pi_{\\mathrm{dep}})/\\mathcal{L}(t_{\\mathrm{dep}}^\\star;\\pi_{\\mathrm{dep}})]$，所有数值均四舍五入到 $6$ 位小数。例如：$[[0.123456,0.120000,1.028800],[\\dots],\\dots]$。\n- 程序必须在没有任何用户输入的情况下运行，并以指定格式精确打印一行。", "solution": "该问题要求我们分析一个二元分类器在类别流行度于验证阶段和部署阶段之间发生变化时的性能下降情况。分类器的分数 $S$ 对每个类别都遵循高斯分布，其中对于类别 $Y=0$，$S \\sim \\mathcal{N}(\\mu_0, \\sigma^2)$；对于类别 $Y=1$，$S \\sim \\mathcal{N}(\\mu_1, \\sigma^2)$。使用一种基于分数的阈值规则，如果一个实例的分数 $S$ 大于或等于阈值 $t$（即 $S \\ge t$），则将其分类为正例（$\\hat{Y}=1$）。\n\n性能由预期误分类成本衡量，该成本是阈值 $t$ 和类别流行度 $\\pi = \\mathbb{P}(Y=1)$ 的函数。成本函数由以下公式给出：\n$$\n\\mathcal{L}(t;\\pi) = c_{\\mathrm{FN}} \\, \\pi \\, \\mathbb{P}(S  t \\mid Y=1) \\;+\\; c_{\\mathrm{FP}} \\, (1-\\pi) \\, \\mathbb{P}(S \\ge t \\mid Y=0)\n$$\n这里，$c_{\\mathrm{FN}}$ 是假阴性（当 $Y=1$ 时预测 $\\hat{Y}=0$）的成本，$c_{\\mathrm{FP}}$ 是假阳性（当 $Y=0$ 时预测 $\\hat{Y}=1$）的成本。\n\n条件概率可以用正态分布的累积分布函数（CDF）来表示。令 $\\Phi(z)$ 表示标准正态分布 $\\mathcal{N}(0,1)$ 的 CDF。\n假阴性率 $\\mathrm{FNR}(t) = \\mathbb{P}(S  t \\mid Y=1)$ 是一个真正例实例的分数低于阈值的概率。给定 $S \\mid Y=1 \\sim \\mathcal{N}(\\mu_1, \\sigma^2)$，则有：\n$$\n\\mathrm{FNR}(t) = \\mathbb{P}\\left(\\frac{S-\\mu_1}{\\sigma}  \\frac{t-\\mu_1}{\\sigma} \\mid Y=1\\right) = \\Phi\\left(\\frac{t-\\mu_1}{\\sigma}\\right)\n$$\n假阳性率 $\\mathrm{FPR}(t) = \\mathbb{P}(S \\ge t \\mid Y=0)$ 是一个真负例实例的分数等于或高于阈值的概率。给定 $S \\mid Y=0 \\sim \\mathcal{N}(\\mu_0, \\sigma^2)$，则有：\n$$\n\\mathrm{FPR}(t) = \\mathbb{P}\\left(\\frac{S-\\mu_0}{\\sigma} \\ge \\frac{t-\\mu_0}{\\sigma} \\mid Y=0\\right) = 1 - \\Phi\\left(\\frac{t-\\mu_0}{\\sigma}\\right)\n$$\n将这些代入成本函数，我们得到：\n$$\n\\mathcal{L}(t;\\pi) = c_{\\mathrm{FN}} \\, \\pi \\, \\Phi\\left(\\frac{t-\\mu_1}{\\sigma}\\right) \\;+\\; c_{\\mathrm{FP}} \\, (1-\\pi) \\, \\left(1 - \\Phi\\left(\\frac{t-\\mu_0}{\\sigma}\\right)\\right)\n$$\n我们的首要目标是找到最优阈值 $t^\\star$，以最小化给定流行度 $\\pi$ 下的此成本。我们通过求 $\\mathcal{L}(t;\\pi)$ 关于 $t$ 的导数并将其设为零来实现。令 $\\phi(z)$ 为标准正态分布的概率密度函数（PDF），它是 $\\Phi(z)$ 的导数。使用链式法则：\n$$\n\\frac{d\\mathcal{L}}{dt} = c_{\\mathrm{FN}} \\, \\pi \\, \\phi\\left(\\frac{t-\\mu_1}{\\sigma}\\right) \\frac{1}{\\sigma} \\;+\\; c_{\\mathrm{FP}} \\, (1-\\pi) \\, \\left(- \\phi\\left(\\frac{t-\\mu_0}{\\sigma}\\right) \\frac{1}{\\sigma}\\right) = 0\n$$\n$$\nc_{\\mathrm{FN}} \\, \\pi \\, \\phi\\left(\\frac{t-\\mu_1}{\\sigma}\\right) = c_{\\mathrm{FP}} \\, (1-\\pi) \\, \\phi\\left(\\frac{t-\\mu_0}{\\sigma}\\right)\n$$\n代入高斯 PDF 的公式 $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2}$：\n$$\nc_{\\mathrm{FN}} \\, \\pi \\, \\exp\\left(-\\frac{1}{2}\\left(\\frac{t-\\mu_1}{\\sigma}\\right)^2\\right) = c_{\\mathrm{FP}} \\, (1-\\pi) \\, \\exp\\left(-\\frac{1}{2}\\left(\\frac{t-\\mu_0}{\\sigma}\\right)^2\\right)\n$$\n取两边的自然对数：\n$$\n\\ln(c_{\\mathrm{FN}} \\, \\pi) - \\frac{(t-\\mu_1)^2}{2\\sigma^2} = \\ln(c_{\\mathrm{FP}} \\, (1-\\pi)) - \\frac{(t-\\mu_0)^2}{2\\sigma^2}\n$$\n重新整理以求解 $t$：\n$$\n(t-\\mu_0)^2 - (t-\\mu_1)^2 = 2\\sigma^2 \\ln\\left(\\frac{c_{\\mathrm{FP}}(1-\\pi)}{c_{\\mathrm{FN}}\\pi}\\right)\n$$\n$$\n(t^2 - 2t\\mu_0 + \\mu_0^2) - (t^2 - 2t\\mu_1 + \\mu_1^2) = 2\\sigma^2 \\ln\\left(\\frac{c_{\\mathrm{FP}}(1-\\pi)}{c_{\\mathrm{FN}}\\pi}\\right)\n$$\n$$\n2t(\\mu_1 - \\mu_0) - (\\mu_1^2 - \\mu_0^2) = 2\\sigma^2 \\ln\\left(\\frac{c_{\\mathrm{FP}}(1-\\pi)}{c_{\\mathrm{FN}}\\pi}\\right)\n$$\n由于 $\\mu_1 \\ne \\mu_0$，我们可以解出最优阈值 $t^\\star$：\n$$\n2t(\\mu_1 - \\mu_0) = (\\mu_1^2 - \\mu_0^2) + 2\\sigma^2 \\ln\\left(\\frac{c_{\\mathrm{FP}}(1-\\pi)}{c_{\\mathrm{FN}}\\pi}\\right)\n$$\n$$\nt^\\star(\\pi) = \\frac{\\mu_0 + \\mu_1}{2} + \\frac{\\sigma^2}{\\mu_1 - \\mu_0} \\ln\\left(\\frac{c_{\\mathrm{FP}}(1-\\pi)}{c_{\\mathrm{FN}}\\pi}\\right)\n$$\n这个解析表达式使我们能够为任何给定的参数集计算最优阈值。该问题的编程实现如下。\n\n```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Solves the performance drift problem for a set of test cases and prints\n    the results in the specified format.\n    \"\"\"\n    test_cases = [\n        # Case A\n        (0, 2, 1, 0.5, 0.5, 1, 1),\n        # Case B\n        (0, 2, 1, 0.5, 0.2, 1, 1),\n        # Case C\n        (0, 2, 1, 0.5, 0.02, 1, 1),\n        # Case D\n        (0, 2, 1, 0.5, 0.2, 1, 5),\n        # Case E\n        (0, 0.5, 1, 0.5, 0.8, 1, 2)\n    ]\n\n    def calculate_optimal_threshold(mu0, mu1, sigma, pi, c_fp, c_fn):\n        if pi = 0: return np.inf\n        if pi >= 1: return -np.inf\n        \n        cost_prevalence_ratio = (c_fp * (1 - pi)) / (c_fn * pi)\n        log_term = np.log(cost_prevalence_ratio)\n        \n        t_star = (mu0 + mu1) / 2 + (sigma**2 / (mu1 - mu0)) * log_term\n        return t_star\n\n    def calculate_expected_cost(t, mu0, mu1, sigma, pi, c_fp, c_fn):\n        if pi = 0: return c_fp * norm.sf(t, loc=mu0, scale=sigma)\n        if pi >= 1: return c_fn * norm.cdf(t, loc=mu1, scale=sigma)\n\n        fnr = norm.cdf(t, loc=mu1, scale=sigma)\n        fpr = norm.sf(t, loc=mu0, scale=sigma)\n        \n        cost = c_fn * pi * fnr + c_fp * (1 - pi) * fpr\n        return cost\n\n    results = []\n    for case in test_cases:\n        mu0, mu1, sigma, pi_val, pi_dep, c_fp, c_fn = case\n\n        t_val_star = calculate_optimal_threshold(mu0, mu1, sigma, pi_val, c_fp, c_fn)\n        cost_val_t_dep_pi = calculate_expected_cost(t_val_star, mu0, mu1, sigma, pi_dep, c_fp, c_fn)\n        \n        t_dep_star = calculate_optimal_threshold(mu0, mu1, sigma, pi_dep, c_fp, c_fn)\n        cost_dep_t_dep_pi = calculate_expected_cost(t_dep_star, mu0, mu1, sigma, pi_dep, c_fp, c_fn)\n        \n        if cost_dep_t_dep_pi > 1e-12:\n            drift_ratio = cost_val_t_dep_pi / cost_dep_t_dep_pi\n        else:\n            drift_ratio = 1.0 if np.isclose(cost_val_t_dep_pi, 0) else np.inf\n\n        results.append([cost_val_t_dep_pi, cost_dep_t_dep_pi, drift_ratio])\n\n    # Format the final output string as specified\n    formatted_results = []\n    for res in results:\n        formatted_res = f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f}]\"\n        formatted_results.append(formatted_res)\n    \n    print(f\"[{','.join(formatted_results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "answer": "[[0.158655,0.158655,1.000000],[0.158655,0.112028,1.416200],[0.158655,0.035414,4.479867],[0.237983,0.165682,1.436402],[0.638520,0.638167,1.000553]]", "id": "3187560"}]}