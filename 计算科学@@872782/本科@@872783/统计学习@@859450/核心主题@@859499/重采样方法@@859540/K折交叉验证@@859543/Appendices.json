{"hands_on_practices": [{"introduction": "K-折交叉验证最核心的应用之一是超参数调优。本练习将指导您为一个二元分类器选择最佳决策阈值，以最大化 $F_{\\beta}$ 分数，这在处理不平衡数据集时尤为重要。通过比较在整个数据集上找到的“全局”阈值与通过交叉验证得到的“聚合”阈值，您将亲身体会到正确评估模型性能的重要性。[@problem_id:3139044]", "problem": "给定一个深度学习模型的二分类输出，其形式为预测概率和真实标签。考虑一个由阈值 $t \\in [0,1]$ 参数化的决策规则，定义为：如果 $p_i \\ge t$，则 $\\hat{y}_i(t) = 1$，否则 $\\hat{y}_i(t) = 0$。其中 $\\mathbf{p} = (p_1,\\dots,p_N)$ 是预测概率，$\\mathbf{y} = (y_1,\\dots,y_N)$ 是真实标签，且 $y_i \\in \\{0,1\\}$。将阈值 $t$ 的混淆计数分别定义为真阳性（true positives）$\\mathrm{TP}(t)$、假阳性（false positives）$\\mathrm{FP}(t)$ 和假阴性（false negatives）$\\mathrm{FN}(t)$。\n\n加权 $F$-分数（$F_\\beta$ 分数），是为 $\\beta > 0$ 定义的，使用精确率（precision）和召回率（recall）的成熟公式。一种在边缘情况下也能良好定义的、基于计数的形式是\n$$\nF_\\beta(t) = \\frac{(1+\\beta^2)\\,\\mathrm{TP}(t)}{(1+\\beta^2)\\,\\mathrm{TP}(t) + \\beta^2\\,\\mathrm{FN}(t) + \\mathrm{FP}(t)}.\n$$\n你将使用 $k$-折交叉验证（CV）为 $F_\\beta$ 实现阈值选择，比较聚合阈值与全局阈值，并检验在类别不平衡情况下的效果。使用以下基础：精确率、召回率和 $F_\\beta$ 的定义，二元决策规则 $\\hat{y}_i(t)$，以及标准的 $k$-折交叉验证程序，该程序将索引划分为 $k$ 个大小尽可能相等（相差最多为 1）的连续折。\n\n算法要求：\n- 对于任何数据集 $(\\mathbf{p},\\mathbf{y})$，将全局阈值 $t^*$ 定义为在完整数据集上使 $F_\\beta(t)$ 最大化的 $t$ 值。论证并实现一个离散搜索，搜索范围是所有唯一的预测概率 $\\mathbf{p}$ 组成的候选阈值集合，并增补 $0$ 和 $1+\\epsilon$（其中 $\\epsilon = 10^{-6}$）。这种做法是有效的，因为决策规则仅在 $t$ 越过某个预测概率时才会改变，使得 $F_\\beta(t)$ 在这些点之间是分段常数。\n- 通过选择达到最大 $F_\\beta$ 值的阈值中最小的一个来解决平局问题。\n- 对于 $k$-折交叉验证，将索引集 $\\{1,\\dots,N\\}$ 划分为 $k$ 个连续的折，其大小相差最多为一（前 $r = N \\bmod k$ 个折的大小为 $\\lfloor N/k \\rfloor + 1$，其余折的大小为 $\\lfloor N/k \\rfloor$）。对于每个折 $j \\in \\{1,\\dots,k\\}$，仅使用该折的验证数据计算使 $F_\\beta(t)$ 最大化的折最优阈值 $t_j$。将聚合阈值定义为 $\\bar{t} = \\frac{1}{k}\\sum_{j=1}^k t_j$。\n- 通过在完整数据集上评估 $F_\\beta(t^*)$ 和 $F_\\beta(\\bar{t})$，比较全局阈值 $t^*$ 和聚合阈值 $\\bar{t}$。\n\n测试套件：\n- 案例 A（平衡， $k=5$, $\\beta=1$）：\n  - $\\mathbf{y} = [$ $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$, $1$, $0$ $]$.\n  - $\\mathbf{p} = [$ $0.92$, $0.18$, $0.88$, $0.32$, $0.83$, $0.41$, $0.77$, $0.47$, $0.71$, $0.52$, $0.66$, $0.56$, $0.61$, $0.60$, $0.59$, $0.62$, $0.58$, $0.63$, $0.54$, $0.68$ $]$.\n- 案例 B（不平衡， $k=3$, $\\beta=2$）：\n  - $\\mathbf{y}$ 的长度 $N = 30$，其中正例位于索引 $3, 7, 12, 18, 24, 29$ 处（描述中使用基于 0 的索引）： $\\mathbf{y} = [$ $0$, $0$, $0$, $1$, $0$, $0$, $0$, $1$, $0$, $0$, $0$, $0$, $1$, $0$, $0$, $0$, $0$, $0$, $1$, $0$, $0$, $0$, $0$, $0$, $1$, $0$, $0$, $0$, $0$, $1$ $]$.\n  - $\\mathbf{p} = [$ $0.05$, $0.15$, $0.20$, $0.90$, $0.25$, $0.30$, $0.35$, $0.87$, $0.40$, $0.45$, $0.50$, $0.55$, $0.89$, $0.58$, $0.62$, $0.66$, $0.70$, $0.74$, $0.86$, $0.78$, $0.60$, $0.52$, $0.48$, $0.44$, $0.92$, $0.42$, $0.38$, $0.34$, $0.80$, $0.88$ $]$.\n- 案例 C（极端不平衡， $k=5$, $\\beta=0.5$）：\n  - $\\mathbf{y}$ 的长度 $N = 15$，其中唯一的正例位于索引 $11$ 处： $\\mathbf{y} = [$ $0$, $0$, $0$, $0$, $0$, $0$, $0$, $0$, $0$, $0$, $0$, $1$, $0$, $0$, $0$ $]$.\n  - $\\mathbf{p} = [$ $0.10$, $0.20$, $0.30$, $0.40$, $0.45$, $0.50$, $0.55$, $0.60$, $0.65$, $0.85$, $0.88$, $0.95$, $0.70$, $0.72$, $0.75$ $]$.\n\n你的程序必须：\n- 完全按照规定实现阈值搜索和 $k$-折交叉验证聚合，包括平局处理规则和使用 $\\epsilon = 10^{-6}$ 扩充候选集。\n- 对于每个测试案例，计算全局阈值 $t^*$、聚合阈值 $\\bar{t}$，以及在完整数据集上评估的相应分数 $F_\\beta(t^*)$ 和 $F_\\beta(\\bar{t})$。\n\n最终输出格式：\n- 生成单行输出，其中包含三个测试案例的结果，格式为一个扁平的、用方括号括起来的逗号分隔列表。该列表必须是\n  - [$t^*_A$, $\\bar{t}_A$, $F_\\beta(t^*_A)$, $F_\\beta(\\bar{t}_A)$, $t^*_B$, $\\bar{t}_B$, $F_\\beta(t^*_B)$, $F_\\beta(\\bar{t}_B)$, $t^*_C$, $\\bar{t}_C$, $F_\\beta(t^*_C)$, $F_\\beta(\\bar{t}_C)$],\n  每个数值都格式化为六位小数。", "solution": "用户在机器学习模型评估领域提供了一个定义明确的计算问题。该问题具有科学依据，可以形式化，并且是自包含的。所有必要的数据、定义和算法过程都已明确指定，没有歧义。因此，该问题是有效的，并将提供一个解决方案。\n\n问题的核心是比较为二分类器选择分类阈值 $t$ 的两种策略。分类器在给定阈值下的性能通过加权 $F_\\beta$ 分数来衡量。\n\n首先，让我们将各个组成部分形式化。我们给定一组 $N$ 个真实标签 $\\mathbf{y} = (y_1, \\dots, y_N)$，其中 $y_i \\in \\{0,1\\}$，以及一组相应的预测概率 $\\mathbf{p} = (p_1, \\dots, p_N)$，其中 $p_i \\in [0,1]$。决策阈值 $t$ 用于根据以下规则将这些概率转换为二元预测 $\\hat{\\mathbf{y}}(t) = (\\hat{y}_1(t), \\dots, \\hat{y}_N(t))$：\n$$\n\\hat{y}_i(t) = \\begin{cases} 1 & \\text{if } p_i \\ge t \\\\ 0 & \\text{if } p_i < t \\end{cases}\n$$\n基于这些预测，我们可以计算作为 $t$ 的函数的真阳性（$\\mathrm{TP}$）、假阳性（$\\mathrm{FP}$）和假阴性（$\\mathrm{FN}$）的数量：\n$$\n\\mathrm{TP}(t) = \\sum_{i=1}^N \\mathbf{1}(p_i \\ge t \\land y_i = 1)\n$$\n$$\n\\mathrm{FP}(t) = \\sum_{i=1}^N \\mathbf{1}(p_i \\ge t \\land y_i = 0)\n$$\n$$\n\\mathrm{FN}(t) = \\sum_{i=1}^N \\mathbf{1}(p_i < t \\land y_i = 1)\n$$\n其中 $\\mathbf{1}(\\cdot)$ 是指示函数。问题为给定的 $\\beta > 0$ 提供了一个稳健的、基于计数的 $F_\\beta$ 分数定义：\n$$\nF_\\beta(t) = \\frac{(1+\\beta^2)\\,\\mathrm{TP}(t)}{(1+\\beta^2)\\,\\mathrm{TP}(t) + \\beta^2\\,\\mathrm{FN}(t) + \\mathrm{FP}(t)}\n$$\n即使在预测正例总数或实际正例总数为零的情况下，这种形式也定义良好，此时分子为 $0$。如果分母也为 $0$（即 $\\mathrm{TP}=\\mathrm{FP}=\\mathrm{FN}=0$），则分数取为 $0$。\n\n主要任务是实现一个算法来找到最大化 $F_\\beta(t)$ 的最优阈值 $t$。问题强制要求使用特定的搜索策略。寻找最优 $t$ 不需要扫描整个区间 $[0,1]$。$\\mathrm{TP}(t)$、$\\mathrm{FP}(t)$ 和 $\\mathrm{FN}(t)$ 的值仅在阈值 $t$ 越过某个概率值 $p_i$ 时才会改变。因此，函数 $F_\\beta(t)$ 是分段常数。可以在一个离散的候选阈值集合上进行完整搜索。指定的候选集合由 $\\mathbf{p}$ 中所有唯一的概率分数组成，并增补两个特殊值：$0$ 和 $1+\\epsilon$（其中 $\\epsilon=10^{-6}$）。值 $t=0$ 对应所有样本都被分类为正例的情况，而 $t=1+\\epsilon$ 确保所有样本都被分类为负例（因为某些 $p_i$ 可能恰好为 $1$）。通过在这个排序后的候选集上搜索，我们可以找到最大的 $F_\\beta$ 值。问题指定了一个平局处理规则：如果多个阈值得出相同的最大 $F_\\beta$ 分数，则必须选择这些阈值中最小的一个。\n\n定义了此优化过程后，我们可以找到两种不同类型的阈值：\n\n1.  **全局阈值 ($t^*$):** 此阈值是通过将上述优化过程应用于整个数据集 $(\\mathbf{y}, \\mathbf{p})$ 来找到的。它代表了对于全部观测数据的单一最佳阈值。\n\n2.  **聚合阈值 ($\\bar{t}$):** 此阈值是使用 $k$-折交叉验证得出的。数据集的索引 $\\{0, 1, \\dots, N-1\\}$ 被划分为 $k$ 个连续、不重叠的折。划分是确定性的：前 $r = N \\bmod k$ 个折包含 $\\lfloor N/k \\rfloor + 1$ 个样本，剩下的 $k-r$ 个折包含 $\\lfloor N/k \\rfloor$ 个样本。对于每个折 $j \\in \\{1, \\dots, k\\}$，该折内的数据作为验证集。该折的最优阈值 $t_j$ 是通过仅使用对应于折 $j$ 的数据点 $(\\mathbf{y}_j, \\mathbf{p}_j)$ 来最大化 $F_\\beta(t)$ 找到的。然后，聚合阈值计算为这些特定于折的阈值的算术平均值：\n    $$\n    \\bar{t} = \\frac{1}{k} \\sum_{j=1}^k t_j\n    $$\n这种交叉验证方法模拟了在未见数据上寻找阈值的过程，而对结果进行平均提供了一个更稳健的估计，不易对特定的数据划分产生过拟合。\n\n最后，问题要求比较这两个阈值 $t^*$ 和 $\\bar{t}$ 的性能。比较是通过在**整个数据集**上评估每个阈值的 $F_\\beta$ 分数来进行的。这使得我们可以直接评估哪种阈值选择策略在观测数据的完整分布上产生更好的结果。\n\n实现的将包括三个主要部分：一个用于计算 $F_\\beta(t)$ 的函数，一个用于为给定数据集找到最优阈值的函数，以及一个主程序，用于协调每个测试用例的计算，包括 k-折拆分逻辑和最终评估。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to execute the problem's requirements for all test cases.\n    \"\"\"\n    \n    # Define test cases from the problem statement\n    case_a = {\n        \"y\": [1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0, 1, 0],\n        \"p\": [0.92, 0.18, 0.88, 0.32, 0.83, 0.41, 0.77, 0.47, 0.71, 0.52, 0.66, 0.56, 0.61, 0.60, 0.59, 0.62, 0.58, 0.63, 0.54, 0.68],\n        \"k\": 5,\n        \"beta\": 1.0,\n    }\n    \n    y_b = np.zeros(30, dtype=int)\n    pos_indices_b = [3, 7, 12, 18, 24, 29]\n    y_b[pos_indices_b] = 1\n    case_b = {\n        \"y\": y_b.tolist(),\n        \"p\": [0.05, 0.15, 0.20, 0.90, 0.25, 0.30, 0.35, 0.87, 0.40, 0.45, 0.50, 0.55, 0.89, 0.58, 0.62, 0.66, 0.70, 0.74, 0.86, 0.78, 0.60, 0.52, 0.48, 0.44, 0.92, 0.42, 0.38, 0.34, 0.80, 0.88],\n        \"k\": 3,\n        \"beta\": 2.0,\n    }\n    \n    y_c = np.zeros(15, dtype=int)\n    y_c[11] = 1\n    case_c = {\n        \"y\": y_c.tolist(),\n        \"p\": [0.10, 0.20, 0.30, 0.40, 0.45, 0.50, 0.55, 0.60, 0.65, 0.85, 0.88, 0.95, 0.70, 0.72, 0.75],\n        \"k\": 5,\n        \"beta\": 0.5,\n    }\n\n    test_cases = [case_a, case_b, case_c]\n    epsilon = 1e-6\n    results = []\n\n    def calculate_f_beta(y, p, t, beta):\n        \"\"\"Calculates the F-beta score for a given threshold.\"\"\"\n        if y.size == 0:\n            return 0.0\n        \n        y_pred = (p >= t).astype(int)\n        \n        tp = np.sum((y_pred == 1)  (y == 1))\n        fp = np.sum((y_pred == 1)  (y == 0))\n        fn = np.sum((y_pred == 0)  (y == 1))\n        \n        beta_sq = beta**2\n        numerator = (1 + beta_sq) * tp\n        denominator = (1 + beta_sq) * tp + beta_sq * fn + fp\n        \n        if denominator == 0:\n            return 0.0\n        else:\n            return numerator / denominator\n\n    def find_optimal_threshold(y, p, beta, epsilon):\n        \"\"\"Finds the optimal threshold that maximizes F-beta score.\"\"\"\n        if y.size == 0:\n            return 0.0\n        \n        unique_p = np.unique(p)\n        candidate_thresholds = np.concatenate(([0.0], unique_p, [1.0 + epsilon]))\n        # Sorting is implicit from np.unique and concatenation order, but let's be explicit\n        candidate_thresholds.sort()\n        \n        best_t = candidate_thresholds[0]\n        max_f_beta = -1.0\n        \n        for t in candidate_thresholds:\n            f_beta_score = calculate_f_beta(y, p, t, beta)\n            if f_beta_score > max_f_beta:\n                max_f_beta = f_beta_score\n                best_t = t\n                \n        return best_t\n\n    def process_case(y, p, k, beta, epsilon):\n        \"\"\"Processes a single test case to find thresholds and scores.\"\"\"\n        y = np.array(y)\n        p = np.array(p)\n        N = len(y)\n        \n        # 1. Calculate global threshold t*\n        t_star = find_optimal_threshold(y, p, beta, epsilon)\n        \n        # 2. Calculate k-fold aggregated threshold t_bar\n        fold_thresholds = []\n        \n        n_per_fold = N // k\n        n_larger_folds = N % k\n        \n        current_idx = 0\n        for i in range(k):\n            fold_size = n_per_fold + 1 if i  n_larger_folds else n_per_fold\n            fold_indices = np.arange(current_idx, current_idx + fold_size)\n            \n            y_fold = y[fold_indices]\n            p_fold = p[fold_indices]\n            \n            t_j = find_optimal_threshold(y_fold, p_fold, beta, epsilon)\n            fold_thresholds.append(t_j)\n            \n            current_idx += fold_size\n            \n        t_bar = np.mean(fold_thresholds)\n        \n        # 3. Evaluate F-beta scores on the full dataset\n        f_beta_star = calculate_f_beta(y, p, t_star, beta)\n        f_beta_bar = calculate_f_beta(y, p, t_bar, beta)\n        \n        return t_star, t_bar, f_beta_star, f_beta_bar\n\n    for case in test_cases:\n        t_star, t_bar, f_beta_star, f_beta_bar = process_case(\n            case[\"y\"], case[\"p\"], case[\"k\"], case[\"beta\"], epsilon\n        )\n        results.extend([t_star, t_bar, f_beta_star, f_beta_bar])\n\n    # Format and print the final results\n    formatted_results = [f\"{x:.6f}\" for x in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3139044"}, {"introduction": "数据增强是提升模型泛化能力的强大技术，但如果使用不当，极易引入一种称为“数据泄漏”的严重问题。本练习通过一个图像分类任务，让您量化比较在交叉验证中正确应用数据增强（仅在训练集上增强）与错误应用（在划分数据前对整个数据集进行增强）所导致的性能评估差异。这个实践将帮助您深刻理解并避免这一常见陷阱。[@problem_id:3134696]", "problem": "您的任务是设计并实现一个计算实验，用以分析在统计学习中使用图像旋转进行数据增强的情况下，$k$-折交叉验证 (CV) 的表现。其目的是量化仅对训练折应用增强与增强泄露到验证折的情况之间的差异。您的程序必须是一个完整的、可运行的实现，无需外部输入即可产生所要求的输出。\n\n需要使用的基本原理和定义：\n- 交叉验证 (CV)：对于一个给定的数据集 $D = \\{(x_i, y_i)\\}_{i=1}^n$ 和一个学习算法，泛化误差的 $k$-折交叉验证估计量定义为在 $k$ 个折上的平均验证损失。设数据折为索引集 $V_1, \\dots, V_k$，它们构成了 $\\{1,\\dots,n\\}$ 的一个划分，并用 $T_j = \\{1,\\dots,n\\} \\setminus V_j$ 表示相应的训练集索引。对于在 $T_j$ 上训练的模型 $\\hat{f}_j$，准确率的CV估计量为\n$$\n\\widehat{\\text{Acc}}_{\\text{CV}} = \\frac{1}{k} \\sum_{j=1}^k \\frac{1}{|V_j|} \\sum_{i \\in V_j} \\mathbf{1}\\{\\hat{f}_j(x_i) = y_i\\},\n$$\n其中 $\\mathbf{1}\\{\\cdot\\}$ 是指示函数。\n- 数据增强：一种应用于输入 $x$ 的保标签变换 $\\mathcal{A}_\\theta$，由以度为单位的旋转角 $\\theta$ 参数化。在本问题中，$\\theta \\in \\{90, 180, 270\\}$，且 $\\mathcal{A}_\\theta$ 是围绕图像中心旋转 $\\theta$ 度的图像旋转。\n- 独立性原则：规范的CV要求在给定数据生成过程的条件下，验证样本独立于训练样本。当同一基础样本的变换版本同时出现在训练折和验证折中时，就会发生泄露，这违反了独立性假设并导致估计量产生偏差。\n\n数据集构建：\n- 考虑 $n$ 张大小为 $h \\times w$ 的基础图像 $\\{x_i\\}_{i=1}^n$，其标签为 $y_i \\in \\{0,1\\}$，其中类别 0 是居中的“+”图案，类别 1 是居中的“×”图案。\n- 每张基础图像都是通过对理想模板进行扰动生成的，扰动包括线条粗细的微小随机偏移和标准差为 $\\sigma$ 的加性高斯噪声，然后将像素强度裁剪到区间 $[0,1]$ 内。以 $\\theta \\in \\{90,180,270\\}$ 进行的旋转会保留类别标签。\n- 分类器是基于平方 $\\ell_2$ 距离的最近质心分类器。对于一个训练集 $(X_{\\text{train}}, Y_{\\text{train}})$，计算类别质心\n$$\n\\mu_c = \\frac{1}{|\\{i: Y_{\\text{train},i} = c\\}|} \\sum_{i:Y_{\\text{train},i}=c} X_{\\text{train},i}, \\quad c \\in \\{0,1\\},\n$$\n并预测 $\\hat{y}(x) = \\arg\\min_{c \\in \\{0,1\\}} \\|x - \\mu_c\\|_2^2$。\n\n两种待比较的CV估计量：\n1. 规范的增强CV：对于每个折 $j \\in \\{1,\\dots,k\\}$，仅通过给定角度集 $S$（角度以度为单位）中的旋转来增强训练图像，即使用 $\\{x_i\\} \\cup \\{\\mathcal{A}_\\theta(x_i): \\theta \\in S\\}$（其中 $i \\in T_j$）来训练 $\\hat{f}_j$，并在未增强的验证图像 $\\{x_i: i \\in V_j\\}$ 上进行评估。\n2. 泄露CV：首先，通过 $S$ 中的旋转对整个数据集进行全局增强，形成 $D' = \\bigcup_{i=1}^n \\left(\\{x_i\\} \\cup \\{\\mathcal{A}_\\theta(x_i): \\theta \\in S\\}\\right)$，然后对 $D'$ 执行 $k$-折交叉验证，在这些增强后的样本上进行训练和验证。该过程允许同一基础图像的增强变体出现在不同的折中，从而在训练样本和验证样本之间产生依赖性。\n\n您的程序必须：\n- 按规定生成合成数据集。\n- 实现最近质心分类器。\n- 计算两种流程的平均 $k$-折交叉验证准确率，并返回其差值\n$$\n\\Delta = \\widehat{\\text{Acc}}_{\\text{CV}}^{\\text{leak}} - \\widehat{\\text{Acc}}_{\\text{CV}}^{\\text{proper}}.\n$$\n\n角度单位：所有角度均以度为单位。\n\n答案类型：所有输出必须是实数（浮点数）。\n\n测试套件和覆盖范围：\n实现以下测试用例，每个用例定义为一个元组 $(n, h, w, k, S, \\sigma, \\text{seed})$，并按顺序处理。对于每个测试用例，计算并输出 $\\Delta$。\n\n- 用例 1（正常路径）：$(n, h, w, k, S, \\sigma, \\text{seed}) = (60, 16, 16, 5, \\{90, 180, 270\\}, 0.10, 42)$。\n- 用例 2（边界情况，无增强）：$(60, 16, 16, 5, \\varnothing, 0.10, 43)$，其中 $\\varnothing$ 表示空的角度集。\n- 用例 3（折数较少）：$(60, 16, 16, 2, \\{90, 180, 270\\}, 0.10, 44)$。\n- 用例 4（高噪声）：$(60, 16, 16, 5, \\{90, 180, 270\\}, 0.50, 45)$。\n- 用例 5（单角度增强）：$(60, 16, 16, 10, \\{90\\}, 0.10, 46)$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表内容为各测试用例的结果，顺序与测试用例一致。例如，包含三个结果的输出应类似于 $[r_1,r_2,r_3]$，其中每个 $r_i$ 都是一个浮点数。角度以度为单位。不应打印任何额外文本。", "solution": "我们从 $k$-折交叉验证 (CV) 的核心定义和独立性要求出发。$k$-折CV估计量对不相交的各折上的验证性能进行平均，其作为泛化性能估计量的可靠性，取决于在给定数据生成过程的条件下，训练集和验证集之间的条件独立性。当仅对训练折应用增强时，变换 $\\mathcal{A}_\\theta$ 丰富了训练分布，同时保持验证样本是来自原始数据分布的独立抽样，从而维护了CV估计量的完整性。当增强泄露到验证折时——特别是通过在构建折之前增强整个数据集——同一基础样本的增强版本可能被同时分配到训练集和验证集，这违反了独立性并引入了乐观偏差。\n\n我们将这两种估计量形式化：\n- 规范的增强CV估计量：\n$$\n\\widehat{\\text{Acc}}_{\\text{proper}} = \\frac{1}{k} \\sum_{j=1}^k \\frac{1}{|V_j|} \\sum_{i \\in V_j} \\mathbf{1}\\left\\{ \\arg\\min_{c \\in \\{0,1\\}} \\|x_i - \\mu_{c}^{(j)}\\|_2^2 = y_i \\right\\},\n$$\n其中\n$$\n\\mu_{c}^{(j)} = \\frac{1}{|\\{t \\in T_j: y_t = c\\}| + |\\{(t,\\theta): t \\in T_j, y_t = c, \\theta \\in S\\}|} \\left( \\sum_{t \\in T_j, y_t=c} x_t + \\sum_{t \\in T_j, y_t=c} \\sum_{\\theta \\in S} \\mathcal{A}_\\theta(x_t) \\right).\n$$\n验证使用未增强的 $x_i$（其中 $i \\in V_j$）。\n\n- 泄露CV估计量：\n构建 $D' = \\bigcup_{i=1}^n \\left(\\{x_i\\} \\cup \\{\\mathcal{A}_\\theta(x_i): \\theta \\in S\\}\\right)$，然后直接在 $D'$ 上执行 $k$-折CV。设 $V'_1, \\dots, V'_k$ 为数据折， $T'_j$ 为其补集。泄露估计量为\n$$\n\\widehat{\\text{Acc}}_{\\text{leak}} = \\frac{1}{k} \\sum_{j=1}^k \\frac{1}{|V'_j|} \\sum_{(i,\\phi) \\in V'_j} \\mathbf{1}\\left\\{ \\arg\\min_{c \\in \\{0,1\\}} \\| \\mathcal{A}_\\phi (x_i) - \\tilde{\\mu}_{c}^{(j)} \\|_2^2 = y_i \\right\\},\n$$\n其中\n$$\n\\tilde{\\mu}_{c}^{(j)} = \\frac{1}{|\\{(t,\\psi) \\in T'_j: y_t = c\\}|} \\sum_{(t,\\psi) \\in T'_j, y_t=c} \\mathcal{A}_\\psi(x_t).\n$$\n\n偏差机制：\n在规范的流程中，验证集中的 $x_i$ 不会（直接或通过其变换副本）用于训练。在泄露流程中，对于许多 $i$，某个变换后的 $\\mathcal{A}_\\psi(x_i)$ 可能存在于训练集中，而 $\\mathcal{A}_\\phi(x_i)$ 用于验证，这在训练样本和验证样本之间产生了高度相关性。对于最近质心分类器，这种相关性减小了 $\\| \\mathcal{A}_\\phi (x_i) - \\tilde{\\mu}_{y_i}^{(j)} \\|_2^2$ 并增加了正确分类的概率，因此平均而言 $\\widehat{\\text{Acc}}_{\\text{leak}} \\ge \\widehat{\\text{Acc}}_{\\text{proper}}$。我们感兴趣的量是其差值\n$$\n\\Delta = \\widehat{\\text{Acc}}_{\\text{leak}} - \\widehat{\\text{Acc}}_{\\text{proper}}.\n$$\n\n算法设计：\n1. 合成数据生成：\n   - 创建 $n$ 张大小为 $h \\times w$ 的基础图像。对于类别 0，通过设置穿过中心的垂直和水平条中的像素来绘制一个居中的“+”图案，线条粗细随机（例如，1或2个像素），中心有微小的随机偏移。对于类别 1，通过设置沿两条对角线的像素来绘制一个居中的“×”图案，具有类似的随机粗细和偏移。\n   - 对每个像素添加标准差为 $\\sigma$ 的独立高斯噪声，并将值裁剪到 $[0,1]$ 范围内。\n   - 分配标签，使每个类别包含 $n/2$ 张图像（均衡），然后打乱顺序。\n\n2. 增强算子：\n   - 对于以度为单位的角度 $\\theta \\in S \\subseteq \\{90,180,270\\}$，通过以90度为增量（即使用 $k = \\theta/90$ 的 $\\text{np.rot90}$）来实现 $\\mathcal{A}_\\theta$，并保留标签。\n\n3. 分类器：\n   - 基于平方 $\\ell_2$ 距离的最近质心分类器。为进行计算，将图像展平为 $\\mathbb{R}^{h \\cdot w}$ 中的向量。根据训练集（根据需要包括增强样本）计算类别质心，并通过最近质心预测验证样本的类别。\n\n4. $k$-折划分：\n   - 对于规范的增强CV，将 $n$ 个基础样本划分为 $k$ 折。对于第 $j$ 折，仅使用 $S$ 中的角度增强训练集，保持验证集不增强，训练质心，并在验证折上计算准确率。对所有折的结果取平均以获得 $\\widehat{\\text{Acc}}_{\\text{proper}}$。\n   - 对于泄露CV，首先增强整个数据集（包括原始图像和 $S$ 中的旋转图像），然后在这个增强的数据集上执行 $k$-折CV，在增强样本上进行训练和验证，以获得 $\\widehat{\\text{Acc}}_{\\text{leak}}$。\n\n5. 差值：\n   - 为每个测试用例计算 $\\Delta$。\n\n测试套件覆盖范围的基本原理：\n- 用例 1 使用适中的 $k$、多个角度和较小的噪声，代表一个典型场景。\n- 用例 2 使用 $S = \\varnothing$（无增强），此时我们预期 $\\Delta \\approx 0$，因为两种流程是相同的。\n- 用例 3 使用较小的 $k$，这增加了增强后的副本跨折出现的几率，可能放大泄露效应。\n- 用例 4 增加了噪声 $\\sigma$，用于检验鲁棒性；在嘈杂条件下，泄露可以人为地提升性能。\n- 用例 5 使用 $k=10$ 和单个角度，用于测试对增强集大小的敏感性。\n\n最终输出：\n单行输出 $[\\Delta_1,\\Delta_2,\\Delta_3,\\Delta_4,\\Delta_5]$，其中浮点数按顺序对应上述用例。\n\n此设计严格遵守CV背后的独立性原则，并通过计算揭示了如何通过增强泄露违反该原则，从而在估计的准确率中产生乐观偏差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef make_plus_image(h, w, thickness, off_y, off_x):\n    \"\"\"\n    Create a centered plus '+' pattern with given thickness and small offsets.\n    Intensities are 1.0 on the pattern, 0.0 elsewhere.\n    \"\"\"\n    img = np.zeros((h, w), dtype=np.float64)\n    cy = h // 2 + off_y\n    cx = w // 2 + off_x\n    # Horizontal bar\n    y_start = max(cy - thickness // 2, 0)\n    y_end = min(cy + thickness // 2 + 1, h)\n    img[y_start:y_end, :] = 1.0\n    # Vertical bar\n    x_start = max(cx - thickness // 2, 0)\n    x_end = min(cx + thickness // 2 + 1, w)\n    img[:, x_start:x_end] = 1.0\n    return img\n\ndef make_x_image(h, w, thickness, off_y, off_x):\n    \"\"\"\n    Create a centered 'x' pattern (two diagonals) with given thickness and small offsets.\n    Intensities are 1.0 on the pattern, 0.0 elsewhere.\n    \"\"\"\n    img = np.zeros((h, w), dtype=np.float64)\n    cy = h // 2 + off_y\n    cx = w // 2 + off_x\n    # Draw diagonals with thickness by marking pixels close to diagonal lines\n    yy, xx = np.meshgrid(np.arange(h), np.arange(w), indexing='ij')\n    # Centered diagonals adjusted by offsets\n    # Line 1: slope +1 through (cy, cx)\n    # Distance from line y - cy = x - cx => y - x = cy - cx\n    d1 = np.abs((yy - xx) - (cy - cx))\n    # Line 2: slope -1 through (cy, cx)\n    # Distance from line y - cy = -(x - cx) => y + x = cy + cx\n    d2 = np.abs((yy + xx) - (cy + cx))\n    mask = (d1 = thickness/2) | (d2 = thickness/2)\n    img[mask] = 1.0\n    return img\n\ndef add_noise_and_clip(img, noise_std, rng):\n    noisy = img + rng.normal(loc=0.0, scale=noise_std, size=img.shape)\n    return np.clip(noisy, 0.0, 1.0)\n\ndef generate_dataset(n, h, w, noise_std, seed):\n    \"\"\"\n    Generate n base images: half '+' class (label 0), half 'x' class (label 1),\n    with random thickness and small offsets, plus Gaussian noise.\n    Returns images (n, h, w) and labels (n,).\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    images = np.zeros((n, h, w), dtype=np.float64)\n    labels = np.zeros(n, dtype=np.int64)\n    # Balanced labels: 0 then 1 alternating\n    base_labels = np.array([0, 1] * (n // 2) + ([0] if n % 2 == 1 else []), dtype=np.int64)\n    # Shuffle labels for randomness\n    rng.shuffle(base_labels)\n    for i in range(n):\n        c = base_labels[i]\n        labels[i] = c\n        thickness = rng.integers(1, 3)  # 1 or 2\n        off_y = rng.integers(-1, 2)     # -1, 0, 1\n        off_x = rng.integers(-1, 2)     # -1, 0, 1\n        if c == 0:\n            img = make_plus_image(h, w, thickness, off_y, off_x)\n        else:\n            img = make_x_image(h, w, thickness, off_y, off_x)\n        img = add_noise_and_clip(img, noise_std, rng)\n        images[i] = img\n    return images, labels\n\ndef rotate_image(img, angle_deg):\n    \"\"\"\n    Rotate the image by angle degrees (must be in {90,180,270}) using np.rot90.\n    \"\"\"\n    if angle_deg % 90 != 0 or angle_deg == 0:\n        # Only support non-zero multiples of 90 as per augmentation set; skip 0 in augmentation\n        raise ValueError(\"Only 90, 180, 270 degrees supported for augmentation\")\n    k = (angle_deg // 90) % 4\n    return np.rot90(img, k)\n\ndef augment_images(images, labels, angles):\n    \"\"\"\n    For each image, return list of (original + rotated versions) according to angles.\n    angles: list of integers from {90, 180, 270}. Original is always included when leak=True;\n            for training-only augmentation, we'll explicitly include original.\n    \"\"\"\n    augmented_imgs = []\n    augmented_labels = []\n    for img, y in zip(images, labels):\n        # include original\n        augmented_imgs.append(img)\n        augmented_labels.append(y)\n        for ang in angles:\n            aug = rotate_image(img, ang)\n            augmented_imgs.append(aug)\n            augmented_labels.append(y)\n    return np.array(augmented_imgs), np.array(augmented_labels)\n\ndef kfold_indices(n, k, seed):\n    \"\"\"\n    Return list of k folds, each a numpy array of indices.\n    Shuffle indices using seed, then split into k contiguous folds as evenly as possible.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    indices = np.arange(n, dtype=np.int64)\n    rng.shuffle(indices)\n    folds = []\n    fold_sizes = np.full(k, n // k, dtype=int)\n    fold_sizes[:(n % k)] += 1\n    start = 0\n    for fs in fold_sizes:\n        end = start + fs\n        folds.append(indices[start:end])\n        start = end\n    return folds\n\ndef compute_centroids(X_train, y_train):\n    \"\"\"\n    Compute class centroids for labels 0 and 1.\n    X_train: (m, d), y_train: (m,)\n    Returns mu0, mu1 as (d,) arrays.\n    \"\"\"\n    # In case a class is missing, handle by using zeros to avoid crash\n    c0 = (y_train == 0)\n    c1 = (y_train == 1)\n    if not np.any(c0) or not np.any(c1):\n        # If missing a class, return centroids computed from available class and zeros for missing\n        mu0 = X_train[c0].mean(axis=0) if np.any(c0) else np.zeros(X_train.shape[1], dtype=np.float64)\n        mu1 = X_train[c1].mean(axis=0) if np.any(c1) else np.zeros(X_train.shape[1], dtype=np.float64)\n        return mu0, mu1\n    mu0 = X_train[c0].mean(axis=0)\n    mu1 = X_train[c1].mean(axis=0)\n    return mu0, mu1\n\ndef predict_nearest_centroid(X_val, mu0, mu1):\n    \"\"\"\n    Predict labels for validation set X_val given centroids mu0 and mu1.\n    \"\"\"\n    # Compute squared distances to centroids\n    d0 = np.sum((X_val - mu0) ** 2, axis=1)\n    d1 = np.sum((X_val - mu1) ** 2, axis=1)\n    return (d1  d0).astype(np.int64)  # predict 1 if distance to mu1 is smaller, else 0\n\ndef cross_val_accuracy_proper(images, labels, k, angles, seed):\n    \"\"\"\n    Proper augmentation: augment only training folds; validate on original base images.\n    \"\"\"\n    n = images.shape[0]\n    folds = kfold_indices(n, k, seed)\n    h, w = images.shape[1], images.shape[2]\n    accs = []\n    for fold in folds:\n        val_idx = fold\n        train_idx = np.setdiff1d(np.arange(n, dtype=np.int64), val_idx, assume_unique=True)\n        # Training data: original + augment rotations for training indices\n        X_train_list = []\n        y_train_list = []\n        for idx in train_idx:\n            img = images[idx]\n            y = labels[idx]\n            # include original\n            X_train_list.append(img.reshape(h * w))\n            y_train_list.append(y)\n            # include augmentations\n            for ang in angles:\n                aug = rotate_image(img, ang)\n                X_train_list.append(aug.reshape(h * w))\n                y_train_list.append(y)\n        X_train = np.stack(X_train_list, axis=0)\n        y_train = np.array(y_train_list, dtype=np.int64)\n        mu0, mu1 = compute_centroids(X_train, y_train)\n        # Validation data: original base images only\n        X_val = images[val_idx].reshape(len(val_idx), h * w)\n        y_val = labels[val_idx]\n        y_pred = predict_nearest_centroid(X_val, mu0, mu1)\n        acc = np.mean(y_pred == y_val)\n        accs.append(acc)\n    return float(np.mean(accs))\n\ndef cross_val_accuracy_leak(images, labels, k, angles, seed):\n    \"\"\"\n    Leakage augmentation: augment entire dataset first (include originals and rotations),\n    then perform k-fold CV on the augmented dataset.\n    \"\"\"\n    # Augment entire dataset: originals + rotations in angles\n    aug_imgs, aug_labels = augment_images(images, labels, angles)\n    n_aug = aug_imgs.shape[0]\n    folds = kfold_indices(n_aug, k, seed)\n    h, w = images.shape[1], images.shape[2]\n    accs = []\n    for fold in folds:\n        val_idx = fold\n        train_idx = np.setdiff1d(np.arange(n_aug, dtype=np.int64), val_idx, assume_unique=True)\n        X_train = aug_imgs[train_idx].reshape(len(train_idx), h * w)\n        y_train = aug_labels[train_idx]\n        mu0, mu1 = compute_centroids(X_train, y_train)\n        X_val = aug_imgs[val_idx].reshape(len(val_idx), h * w)\n        y_val = aug_labels[val_idx]\n        y_pred = predict_nearest_centroid(X_val, mu0, mu1)\n        acc = np.mean(y_pred == y_val)\n        accs.append(acc)\n    return float(np.mean(accs))\n\ndef compute_delta(n, h, w, k, angles, noise_std, seed):\n    images, labels = generate_dataset(n, h, w, noise_std, seed)\n    if not angles: # handle empty angle set\n        return 0.0\n    acc_proper = cross_val_accuracy_proper(images, labels, k, angles, seed)\n    acc_leak = cross_val_accuracy_leak(images, labels, k, angles, seed)\n    return acc_leak - acc_proper\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (n, h, w, k, angles_list, noise_std, seed)\n    test_cases = [\n        (60, 16, 16, 5, [90, 180, 270], 0.10, 42),  # Case 1: happy path\n        (60, 16, 16, 5, [],              0.10, 43),  # Case 2: boundary, no augmentation\n        (60, 16, 16, 2, [90, 180, 270],  0.10, 44),  # Case 3: few folds\n        (60, 16, 16, 5, [90, 180, 270],  0.50, 45),  # Case 4: high noise\n        (60, 16, 16, 10, [90],           0.10, 46),  # Case 5: single-angle augmentation\n    ]\n\n    results = []\n    for case in test_cases:\n        n, h, w, k, angles, noise_std, seed = case\n        delta = compute_delta(n, h, w, k, angles, noise_std, seed)\n        # Format with a reasonable precision\n        results.append(f\"{delta:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3134696"}, {"introduction": "交叉验证的有效性建立在一个关键的统计假设之上：各折之间的数据样本是独立的。当数据集中存在隐藏的重复或高度相似的样本时，这一假设便被打破，导致交叉验证低估模型的真实泛化误差。本练习将引导您从理论上推导并用代码计算这种情况下产生的“乐观偏差”，从而揭示违反独立性假设的后果。[@problem_id:3134661]", "problem": "你需要对$k$-折交叉验证（CV）的一种特定失效模式进行形式化和分析。当数据集包含隐藏的重复样本或近似相同的样本，其残差在各折之间呈正相关，从而违反了标准的独立性假设时，就会出现这种失效。你必须仅从统计学习中风险和协方差的核心定义出发，推导出一个简单估计量在显式相关模型下的期望CV风险和真实泛化风险，然后量化CV估计中的偏差。\n\n考虑以下反例构造。有一个包含$m$个近似相同观测值的单一潜在组。对于每个观测值$j \\in \\{1,\\dots,m\\}$，其结果为$y_j = \\mu + \\varepsilon_j$，其中$\\mu$是一个未知的常数，而$(\\varepsilon_1,\\dots,\\varepsilon_m)$是一个零均值的等相关噪声向量，其方差为$\\sigma^2$，两两之间的相关系数为$\\rho \\in [0,1]$，即对所有$j$，$\\operatorname{Var}(\\varepsilon_j) = \\sigma^2$，对所有$i \\neq j$，$\\operatorname{Cov}(\\varepsilon_i,\\varepsilon_j) = \\rho \\sigma^2$。等相关性捕捉了样本间隐藏的重复性或近似同一性。执行$k$-折交叉验证（CV），各折均匀划分这$m$个观测值；为简化起见，假设$k$能整除$m$。在每一折上，训练一个估计量，该估计量通过训练集的均值来预测验证集的结果，\n$$\n\\widehat{\\mu}_{\\text{tr}} \\;=\\; \\mu \\;+\\; \\frac{1}{n_{\\text{tr}}} \\sum_{i \\in \\text{train}} \\varepsilon_i,\n$$\n其中$n_{\\text{tr}} = m \\cdot \\frac{k-1}{k}$是该折中的训练观测值数量。在验证集上评估平方误差。将真实泛化风险定义为在一个与训练残差独立的全新、独立抽取$y_{\\text{new}} = \\mu + \\varepsilon_{\\text{new}}$（其中$\\varepsilon_{\\text{new}} \\sim \\mathcal{N}(0,\\sigma^2)$）上的期望平方误差。\n\n你的任务：\n- 仅使用期望、方差、协方差的基本性质以及风险作为期望损失的定义，推导在给定等相关模型下，$k$-折CV期望平方误差的闭式表达式。你必须用$k$、$m$、$\\rho$和$\\sigma^2$来表示结果。不要假设各折之间独立；相反，应使用所述的相关结构，该结构适用于所有重复对，包括那些被分到不同折中的重复对。\n- 再次用$k$、$m$、$\\rho$和$\\sigma^2$来表示，为同一个估计量在一个全新的、独立的样本上推导真实泛化风险的闭式表达式。\n- 将CV偏差定义为期望CV风险与真实风险之差。证明对于任何$\\rho \\in (0,1]$，该偏差都严格为负，从而提供一个数学上明确的反例，说明由于隐藏的重复性引起的相关性，$k$-折CV存在乐观偏差。\n- 实现一个完整的、可运行的程序，对于指定的测试套件，计算每个测试用例的偏差，该偏差为一个等于期望CV风险与真实风险之差的浮点数。将每个结果四舍五入到$6$位小数。\n\n测试套件：\n- 情况 1：$k=2$, $m=4$, $\\rho=0.3$, $\\sigma^2=1.0$.\n- 情况 2：$k=5$, $m=10$, $\\rho=0.9$, $\\sigma^2=1.0$.\n- 情况 3：$k=10$, $m=10$, $\\rho=0.0$, $\\sigma^2=2.0$.\n- 情况 4：$k=3$, $m=6$, $\\rho=0.5$, $\\sigma^2=0.5$.\n\n最终输出格式：\n- 你的程序应生成一行输出，其中包含一个逗号分隔的列表，用方括号括起来，结果的顺序与上述测试套件的顺序一致。例如，抽象形式为[$b_1$,$b_2$,$b_3$,$b_4$]，其中每个$b_i$是情况$i$的偏差，四舍五入到$6$位小数。", "solution": "该问题要求在特定数据相关模型下，推导和分析$k$-折交叉验证（CV）的偏差。我们必须从基本统计定义出发，推导期望CV风险、真实泛化风险以及由此产生的偏差。\n\n设$m$个观测值的集合索引为$\\mathcal{D} = \\{1, 2, \\dots, m\\}$。观测值$j$的结果是$y_j = \\mu + \\varepsilon_j$，其中$\\mu$是一个未知常数。噪声向量$(\\varepsilon_1, \\dots, \\varepsilon_m)$满足$\\mathbb{E}[\\varepsilon_j] = 0$，对所有$j$有$\\operatorname{Var}(\\varepsilon_j) = \\sigma^2$，对所有$i \\neq j$有$\\operatorname{Cov}(\\varepsilon_i, \\varepsilon_j) = \\rho\\sigma^2$。\n\n在$k$-折CV方案中，对于每一折$f \\in \\{1, \\dots, k\\}$，数据被划分为大小为$n_{\\text{tr}} = m \\frac{k-1}{k}$的训练集$\\mathcal{D}_{\\text{tr}}^{(f)}$和大小为$n_{\\text{val}} = \\frac{m}{k}$的验证集$\\mathcal{D}_{\\text{val}}^{(f)}$。第$f$折的估计量是训练数据的均值：\n$$\n\\widehat{\\mu}_{\\text{tr}}^{(f)} = \\frac{1}{n_{\\text{tr}}} \\sum_{i \\in \\mathcal{D}_{\\text{tr}}^{(f)}} y_i = \\mu + \\frac{1}{n_{\\text{tr}}} \\sum_{i \\in \\mathcal{D}_{\\text{tr}}^{(f)}} \\varepsilon_i\n$$\n令$\\bar{\\varepsilon}_{\\text{tr}}^{(f)} = \\frac{1}{n_{\\text{tr}}} \\sum_{i \\in \\mathcal{D}_{\\text{tr}}^{(f)}} \\varepsilon_i$。则$\\widehat{\\mu}_{\\text{tr}}^{(f)} = \\mu + \\bar{\\varepsilon}_{\\text{tr}}^{(f)}$。\n\n### 1. 期望$k$-折CV风险的推导\n\nCV风险是验证集上的平均平方误差。根据问题设置的对称性，任何折中的任何验证样本的期望平方误差都是相同的。因此，我们可以在不失一般性的情况下，分析单个任意的验证点，例如$j \\in \\mathcal{D}_{\\text{val}}^{(f)}$。CV风险是该点平方误差的期望值。\n\n观测值$j$的预测误差为：\n$$\ny_j - \\widehat{\\mu}_{\\text{tr}}^{(f)} = (\\mu + \\varepsilon_j) - (\\mu + \\bar{\\varepsilon}_{\\text{tr}}^{(f)}) = \\varepsilon_j - \\bar{\\varepsilon}_{\\text{tr}}^{(f)}\n$$\n期望误差为$\\mathbb{E}[\\varepsilon_j - \\bar{\\varepsilon}_{\\text{tr}}^{(f)}] = \\mathbb{E}[\\varepsilon_j] - \\mathbb{E}[\\bar{\\varepsilon}_{\\text{tr}}^{(f)}] = 0 - 0 = 0$。\n因此，期望CV风险$\\mathbb{E}[R_{CV}]$是该误差项的方差：\n$$\n\\mathbb{E}[R_{CV}] = \\mathbb{E}\\left[ (y_j - \\widehat{\\mu}_{\\text{tr}}^{(f)})^2 \\right] = \\operatorname{Var}\\left(\\varepsilon_j - \\bar{\\varepsilon}_{\\text{tr}}^{(f)}\\right)\n$$\n使用性质$\\operatorname{Var}(X-Y) = \\operatorname{Var}(X) + \\operatorname{Var}(Y) - 2\\operatorname{Cov}(X,Y)$，我们得到：\n$$\n\\mathbb{E}[R_{CV}] = \\operatorname{Var}(\\varepsilon_j) + \\operatorname{Var}(\\bar{\\varepsilon}_{\\text{tr}}^{(f)}) - 2\\operatorname{Cov}(\\varepsilon_j, \\bar{\\varepsilon}_{\\text{tr}}^{(f)})\n$$\n我们计算每一项：\n1.  根据定义，$\\operatorname{Var}(\\varepsilon_j) = \\sigma^2$。\n2.  $\\operatorname{Var}(\\bar{\\varepsilon}_{\\text{tr}}^{(f)})$：$n_{\\text{tr}}$个相关变量均值的方差。\n    $$\n    \\operatorname{Var}(\\bar{\\varepsilon}_{\\text{tr}}^{(f)}) = \\operatorname{Var}\\left(\\frac{1}{n_{\\text{tr}}} \\sum_{i \\in \\mathcal{D}_{\\text{tr}}^{(f)}} \\varepsilon_i\\right) = \\frac{1}{n_{\\text{tr}}^2} \\left[ \\sum_{i \\in \\mathcal{D}_{\\text{tr}}^{(f)}} \\operatorname{Var}(\\varepsilon_i) + \\sum_{i, l \\in \\mathcal{D}_{\\text{tr}}^{(f)}, i \\neq l} \\operatorname{Cov}(\\varepsilon_i, \\varepsilon_l) \\right]\n    $$\n    有$n_{\\text{tr}}$个方差项（$\\sigma^2$）和$n_{\\text{tr}}(n_{\\text{tr}}-1)$个协方差项（$\\rho\\sigma^2$）。\n    $$\n    \\operatorname{Var}(\\bar{\\varepsilon}_{\\text{tr}}^{(f)}) = \\frac{1}{n_{\\text{tr}}^2} \\left[ n_{\\text{tr}}\\sigma^2 + n_{\\text{tr}}(n_{\\text{tr}}-1)\\rho\\sigma^2 \\right] = \\frac{\\sigma^2}{n_{\\text{tr}}} [1 + (n_{\\text{tr}}-1)\\rho]\n    $$\n3.  $\\operatorname{Cov}(\\varepsilon_j, \\bar{\\varepsilon}_{\\text{tr}}^{(f)})$：一个验证点噪声与训练点噪声均值之间的协方差。\n    $$\n    \\operatorname{Cov}(\\varepsilon_j, \\bar{\\varepsilon}_{\\text{tr}}^{(f)}) = \\operatorname{Cov}\\left(\\varepsilon_j, \\frac{1}{n_{\\text{tr}}} \\sum_{i \\in \\mathcal{D}_{\\text{tr}}^{(f)}} \\varepsilon_i\\right) = \\frac{1}{n_{\\text{tr}}} \\sum_{i \\in \\mathcal{D}_{\\text{tr}}^{(f)}} \\operatorname{Cov}(\\varepsilon_j, \\varepsilon_i)\n    $$\n    因为$j$在验证集中，$i$在训练集中，所以$j \\neq i$。因此，$\\operatorname{Cov}(\\varepsilon_j, \\varepsilon_i) = \\rho\\sigma^2$。\n    $$\n    \\operatorname{Cov}(\\varepsilon_j, \\bar{\\varepsilon}_{\\text{tr}}^{(f)}) = \\frac{1}{n_{\\text{tr}}} \\sum_{i \\in \\mathcal{D}_{\\text{tr}}^{(f)}} \\rho\\sigma^2 = \\frac{n_{\\text{tr}}\\rho\\sigma^2}{n_{\\text{tr}}} = \\rho\\sigma^2\n    $$\n将这些代入$\\mathbb{E}[R_{CV}]$的表达式中：\n$$\n\\mathbb{E}[R_{CV}] = \\sigma^2 + \\frac{\\sigma^2}{n_{\\text{tr}}}[1 + (n_{\\text{tr}}-1)\\rho] - 2\\rho\\sigma^2\n$$\n\n### 2. 真实泛化风险的推导\n\n真实泛化风险$R_{\\text{true}}$是在一个新的、独立的观测$y_{\\text{new}} = \\mu + \\varepsilon_{\\text{new}}$上的期望平方误差。这里，$\\varepsilon_{\\text{new}}$的均值为$0$，方差为$\\sigma^2$，且与所有训练样本$(\\varepsilon_1, \\dots, \\varepsilon_m)$独立。风险是为在$n_{\\text{tr}}$个样本上训练的同类型估计量评估的。\n$$\nR_{\\text{true}} = \\mathbb{E}\\left[ (y_{\\text{new}} - \\widehat{\\mu}_{\\text{tr}}^{(f)})^2 \\right]\n$$\n期望是对训练数据和新数据两者取的。误差项为：\n$$\ny_{\\text{new}} - \\widehat{\\mu}_{\\text{tr}}^{(f)} = (\\mu + \\varepsilon_{\\text{new}}) - (\\mu + \\bar{\\varepsilon}_{\\text{tr}}^{(f)}) = \\varepsilon_{\\text{new}} - \\bar{\\varepsilon}_{\\text{tr}}^{(f)}\n$$\n和之前一样，期望误差为$0$，所以风险即为方差：\n$$\nR_{\\text{true}} = \\operatorname{Var}(\\varepsilon_{\\text{new}} - \\bar{\\varepsilon}_{\\text{tr}}^{(f)}) = \\operatorname{Var}(\\varepsilon_{\\text{new}}) + \\operatorname{Var}(\\bar{\\varepsilon}_{\\text{tr}}^{(f)}) - 2\\operatorname{Cov}(\\varepsilon_{\\text{new}}, \\bar{\\varepsilon}_{\\text{tr}}^{(f)})\n$$\n我们计算每一项：\n1.  根据定义，$\\operatorname{Var}(\\varepsilon_{\\text{new}}) = \\sigma^2$。\n2.  $\\operatorname{Var}(\\bar{\\varepsilon}_{\\text{tr}}^{(f)}) = \\frac{\\sigma^2}{n_{\\text{tr}}}[1 + (n_{\\text{tr}}-1)\\rho]$，如前所述。\n3.  $\\operatorname{Cov}(\\varepsilon_{\\text{new}}, \\bar{\\varepsilon}_{\\text{tr}}^{(f)})$：由于$\\varepsilon_{\\text{new}}$与训练集中的所有$\\varepsilon_i$独立，协方差为$0$。\n\n将这些代入：\n$$\nR_{\\text{true}} = \\sigma^2 + \\frac{\\sigma^2}{n_{\\text{tr}}}[1 + (n_{\\text{tr}}-1)\\rho] - 0\n$$\n\n### 3. CV偏差的推导及负性证明\n\n交叉验证估计的偏差是期望CV风险与真实泛化风险之差。\n$$\n\\text{Bias} = \\mathbb{E}[R_{CV}] - R_{\\text{true}}\n$$\n使用上面推导的表达式：\n$$\n\\text{Bias} = \\left( \\sigma^2 + \\frac{\\sigma^2}{n_{\\text{tr}}}[1 + (n_{\\text{tr}}-1)\\rho] - 2\\rho\\sigma^2 \\right) - \\left( \\sigma^2 + \\frac{\\sigma^2}{n_{\\text{tr}}}[1 + (n_{\\text{tr}}-1)\\rho] \\right)\n$$\n$\\sigma^2$项和整个包含$\\operatorname{Var}(\\bar{\\varepsilon}_{\\text{tr}}^{(f)})$的项都消掉了，剩下：\n$$\n\\text{Bias} = -2\\rho\\sigma^2\n$$\n这个异常简洁的结果表明，偏差与折数$k$和样本量$m$无关。它仅取决于相关性$\\rho$和噪声方差$\\sigma^2$。偏差完全源于验证数据和训练数据之间的协方差，而当在一个真正独立的测试集上评估时，这个协方差是不存在的。\n\n**负性证明：**\n题目要求证明对于$\\rho \\in (0, 1]$，偏差是严格为负的。\n已知：\n- $\\rho \\in (0, 1]$，这意味着$\\rho  0$。\n- $\\sigma^2$是一个方差。对于一个非平凡问题，我们必须有$\\sigma^2  0$。测试用例证实了这一点。\n\n因为$2  0$，$\\rho  0$，且$\\sigma^2  0$，它们的乘积$2\\rho\\sigma^2$是严格为正的。\n因此，等于$-2\\rho\\sigma^2$的偏差对于任何$\\rho \\in (0,1]$都是严格为负的。这表明，当样本之间存在隐藏的相关性（由$\\rho  0$建模）时，$k$-折CV是乐观偏误的（即它低估了真实误差）。如果$\\rho=0$，偏差为$0$，这恢复了独立数据的标准结果。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the bias of k-fold Cross-Validation under an equicorrelation model.\n\n    The problem asks for the derivation of the CV bias, defined as the difference\n    between the expected CV risk and the true generalization risk. The derivation\n    in the solution text shows that:\n    \n    Expected CV Risk: E[R_CV] = sigma^2 + Var(mean(epsilon_tr)) - 2 * rho * sigma^2\n    True Risk: R_true = sigma^2 + Var(mean(epsilon_tr))\n    \n    Bias = E[R_CV] - R_true = -2 * rho * sigma^2\n\n    This simple formula is independent of k and m. This function implements this\n    result to calculate the bias for the specified test suite.\n    \"\"\"\n\n    # Test suite from the problem statement.\n    # Each tuple is (k, m, rho, sigma_sq).\n    test_cases = [\n        (2, 4, 0.3, 1.0),\n        (5, 10, 0.9, 1.0),\n        (10, 10, 0.0, 2.0),\n        (3, 6, 0.5, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        # Unpack parameters. k and m are not needed for the final bias calculation.\n        k, m, rho, sigma_sq = case\n        \n        # Calculate the bias using the derived formula.\n        bias = -2 * rho * sigma_sq\n        \n        # Format the result to 6 decimal places as a string.\n        results.append(f\"{bias:.6f}\")\n\n    # Print the final output in the required format: [b_1,b_2,b_3,b_4]\n    print(f\"[{','.join(results)}]\")\n\n# Execute the solver.\nsolve()\n```", "id": "3134661"}]}