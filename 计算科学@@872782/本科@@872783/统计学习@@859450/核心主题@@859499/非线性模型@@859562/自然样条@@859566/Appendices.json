{"hands_on_practices": [{"introduction": "自然样条的一个关键特征是在边界点上其二阶导数为零，这使得函数在数据范围之外趋向于线性。这个练习通过一个具体的计算任务 [@problem_id:2189207]，揭示了当真实函数的行为与此假设不符时可能产生的近似误差。通过将自然样条的二阶导数与函数 $f(x) = x^4$ 的真实二阶导数进行比较，你可以量化这一边界约束带来的影响，并深入理解模型假设的重要性。", "problem": "考虑函数 $f(x) = x^4$。构造一个自然三次样条 $S(x)$，在节点 $x_0 = 0$，$x_1 = 1$ 和 $x_2 = 2$ 处对该函数进行插值。三次样条被定义为分段三次多项式，在其节点上具有二阶连续可导性。自然三次样条还满足边界条件 $S''(x_0) = 0$ 和 $S''(x_n) = 0$，其中 $x_0$ 和 $x_n$ 分别是第一个和最后一个节点。\n\n这种边界条件的选择虽然在数学上很方便，但如果真实函数的二阶导数在边界处不为零，可能会导致较大的逼近误差。\n\n计算在点 $x = 1.8$ 处二阶导数近似的绝对误差，定义为 $|S''(1.8) - f''(1.8)|$。\n\n将你的最终答案四舍五入到四位有效数字。", "solution": "目标是计算绝对误差 $|S''(1.8) - f''(1.8)|$。该过程包括三个主要部分：\n1.  计算函数 $f(x)$ 在 $x=1.8$ 处的真实二阶导数。\n2.  确定自然三次样条 $S(x)$ 在 $x=1.8$ 处的二阶导数。\n3.  计算绝对差值。\n\n**第一步：计算真实二阶导数 $f''(1.8)$**\n\n给定函数为 $f(x) = x^4$。我们求其一阶和二阶导数：\n$$f'(x) = \\frac{d}{dx}(x^4) = 4x^3$$\n$$f''(x) = \\frac{d}{dx}(4x^3) = 12x^2$$\n现在，我们计算在 $x = 1.8$ 处的二阶导数：\n$$f''(1.8) = 12(1.8)^2 = 12(3.24) = 38.88$$\n\n**第二步：确定样条的二阶导数 $S''(1.8)$**\n\n为了找到 $S''(x)$，我们首先需要找到样条在节点处的二阶导数值，记为 $M_i = S''(x_i)$。节点为 $x_0=0, x_1=1, x_2=2$。对应的函数值为：\n$$y_0 = f(x_0) = 0^4 = 0$$\n$$y_1 = f(x_1) = 1^4 = 1$$\n$$y_2 = f(x_2) = 2^4 = 16$$\n步长为 $h_i = x_{i+1} - x_i$：\n$$h_0 = x_1 - x_0 = 1 - 0 = 1$$\n$$h_1 = x_2 - x_1 = 2 - 1 = 1$$\n\n对于三次样条，其矩 $M_i$ 通过以下关于内部节点（本例中仅为 $i=1$）的方程组相关联：\n$$h_{i-1}M_{i-1} + 2(h_{i-1} + h_i)M_i + h_i M_{i+1} = 6 \\left( \\frac{y_{i+1}-y_i}{h_i} - \\frac{y_i-y_{i-1}}{h_{i-1}} \\right)$$\n对于 $i=1$：\n$$h_0 M_0 + 2(h_0 + h_1)M_1 + h_1 M_2 = 6 \\left( \\frac{y_2 - y_1}{h_1} - \\frac{y_1 - y_0}{h_0} \\right)$$\n我们已知该样条是*自然*三次样条，这意味着在端点处的二阶导数为零：\n$$M_0 = S''(x_0) = S''(0) = 0$$\n$$M_2 = S''(x_2) = S''(2) = 0$$\n将所有已知值代入 $M_1$ 的方程中：\n$$(1)(0) + 2(1 + 1)M_1 + (1)(0) = 6 \\left( \\frac{16 - 1}{1} - \\frac{1 - 0}{1} \\right)$$\n$$4M_1 = 6 (15 - 1)$$\n$$4M_1 = 6 (14)$$\n$$4M_1 = 84$$\n$$M_1 = 21$$\n因此，样条的矩为 $M_0=0, M_1=21, M_2=0$。\n\n在区间 $[x_i, x_{i+1}]$ 上，三次样条的二阶导数是一个线性函数，它对矩 $M_i$ 和 $M_{i+1}$ 进行插值：\n$$S_i''(x) = M_i \\frac{x_{i+1} - x}{h_i} + M_{i+1} \\frac{x - x_i}{h_i}$$\n点 $x=1.8$ 位于第二个区间 $[x_1, x_2] = [1, 2]$ 中，所以我们设 $i=1$：\n$$S_1''(x) = M_1 \\frac{x_2 - x}{h_1} + M_2 \\frac{x - x_1}{h_1}$$\n代入已知值 $M_1=21, M_2=0, x_1=1, x_2=2, h_1=1$：\n$$S''(x) = 21 \\frac{2 - x}{1} + 0 \\frac{x - 1}{1} = 21(2-x) \\quad \\text{for } x \\in [1, 2]$$\n现在我们可以计算样条在 $x=1.8$ 处的二阶导数：\n$$S''(1.8) = 21(2 - 1.8) = 21(0.2) = 4.2$$\n\n**第三步：计算绝对误差**\n\n最后，我们按照问题陈述中定义的方式计算绝对误差：\n$$\\text{Error} = |S''(1.8) - f''(1.8)|$$\n$$\\text{Error} = |4.2 - 38.88| = |-34.68| = 34.68$$\n问题要求将答案四舍五入到四位有效数字。数字 $34.68$ 已经有四位有效数字。", "answer": "$$\\boxed{34.68}$$", "id": "2189207"}, {"introduction": "在理解了自然样条的边界假设后，我们来探索其作为函数逼近工具的强大能力。这个动手实践 [@problem_id:3153014] 要求你编写程序，用不同数量的节点构造自然样条来逼近指数函数，并计算其 $L^2$ 逼近误差。通过这个过程，你将直观地看到增加节点数量如何提高样条的拟合精度，并掌握评估模型性能的基本方法。", "problem": "要求您实现一个程序，为函数 $f(x) = e^x$ 在区间 $[0,1]$ 上构建自然三次样条逼近，并针对几个指定的总节点数计算每个样条的 $L^2$ 逼近误差。在统计学习的背景下，自然样条是一个分段三次多项式函数，它二次连续可微，并在端点处满足线性边界条件。这些条件限制了函数在边界附近的灵活性，并通常能减少方差。对于自然三次样条，自然边界条件将区间端点处的二阶导数设置为零。\n\n从以下基本定义开始：\n- 一个在 $[0,1]$ 上总节点数为 $K$ 的自然三次样条 $s_K(x)$ 是一个函数，它在由非递减节点序列 $0 = \\tau_0 \\le \\tau_1 \\le \\dots \\le \\tau_{K-1} = 1$ 确定的子区间上是分段三次多项式，满足所有 $i \\in \\{0,1,\\dots,K-1\\}$ 的插值约束 $s_K(\\tau_i) = f(\\tau_i)$，在 $[0,1]$ 上具有连续的一阶和二阶导数，并满足边界条件 $s_K''(0) = 0$ 和 $s_K''(1) = 0$。\n- 在 $[0,1]$ 上的 $L^2$ 逼近误差定义为\n$$\nE_K \\;=\\; \\left( \\int_{0}^{1} \\big( s_K(x) - f(x) \\big)^2 \\, dx \\right)^{1/2}.\n$$\n\n您的任务是：\n1. 对于每个指定的总节点数 $K$，在 $[0,1]$ 上构建一个由 $\\tau_i = \\frac{i}{K-1}$（其中 $i \\in \\{0,1,\\dots,K-1\\}$）给出的均匀节点序列。\n2. 使用这些节点，构建在节点处对 $f(x) = e^x$ 进行插值并满足 $s_K''(0) = 0$ 和 $s_K''(1) = 0$ 的自然三次样条 $s_K(x)$。\n3. 通过数值计算积分，为每个样条计算在 $[0,1]$ 上的 $L^2$ 逼近误差 $E_K$。\n\n实现要求：\n- 使用数值稳定且精确的方法来计算定义 $E_K$ 的积分。最终的误差值必须计算到高精度。\n- 此问题不涉及任何物理单位和角度。\n- 您的程序必须是一个完整的、可运行的程序，不需要任何外部输入。\n\n测试套件：\n- 使用以下总节点数 $K$：$\\{2, 3, 5, 11\\}$。\n  - $K = 2$ 检验了仅有端点作为节点的边界情况。\n  - $K = 3$ 包含一个位于 $x = \\frac{1}{2}$ 的内部节点。\n  - $K = 5$ 引入了中等数量的内部节点。\n  - $K = 11$ 在 $[0,1]$ 上提供了一个更精细的节点网格。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果按所提供测试用例的顺序排列。每个 $E_K$ 值必须四舍五入到小数点后八位。例如：“[a,b,c,d]”，其中 $a$、$b$、$c$ 和 $d$ 分别是 $K \\in \\{2,3,5,11\\}$ 的四舍五入值。", "solution": "该问题要求为函数 $f(x) = e^x$ 在区间 $[0, 1]$ 上构建自然三次样条进行逼近，并随后为一组给定的总节点数 $K$ 计算 $L^2$ 逼近误差。解决方案包括两个主要阶段：首先，构建样条；其次，计算误差积分。\n\n**1. 自然三次样条的构建**\n\n一个具有 $K$ 个节点 $\\tau_0, \\tau_1, \\dots, \\tau_{K-1}$ 的三次样条 $s_K(x)$ 是一个分段三次多项式函数。在每个子区间 $[\\tau_i, \\tau_{i+1}]$（其中 $i \\in \\{0, 1, \\dots, K-2\\}$）上，样条 $s_K(x)$ 由一个唯一的三次多项式表示，我们将其记为 $s_i(x)$。这 $K-1$ 个多项式总共有 $4(K-1)$ 个未知系数。这些系数通过施加一系列条件来确定。\n\n插值三次样条的标准条件如下：\n-   **插值**：样条必须穿过给定的数据点。对于每个节点 $\\tau_i$，我们要求 $s_K(\\tau_i) = f(\\tau_i)$。设 $y_i = f(\\tau_i)$。这提供了 $K$ 个条件，具体来说，对于所有 $i \\in \\{0, \\dots, K-2\\}$，有 $s_i(\\tau_i) = y_i$ 和 $s_i(\\tau_{i+1}) = y_{i+1}$。这些构成了 $2(K-1)$ 个约束。\n-   **一阶导数的连续性**：在每个内部节点 $\\tau_i$（其中 $i \\in \\{1, \\dots, K-2\\}$），样条的一阶导数必须连续：$s'_{i-1}(\\tau_i) = s'_i(\\tau_i)$。这增加了 $K-2$ 个约束。\n-   **二阶导数的连续性**：同样地，在每个内部节点 $\\tau_i$（其中 $i \\in \\{1, \\dots, K-2\\}$），二阶导数必须连续：$s''_{i-1}(\\tau_i) = s''_i(\\tau_i)$。这又增加了 $K-2$ 个约束。\n\n来自插值和连续性的总约束数为 $2(K-1) + (K-2) + (K-2) = 4K-6$。由于有 $4(K-1)$ 个系数待定，我们还需要两个额外的约束。这些约束由边界条件提供。对于**自然三次样条**，边界条件是：\n-   **自然边界条件**：样条的二阶导数在区间端点处为零。给定区间 $[0, 1]$，其中 $\\tau_0=0$ 和 $\\tau_{K-1}=1$，这些条件是 $s_K''(0) = 0$ 和 $s_K''(1) = 0$。\n\n一种确定样条系数的标准且计算稳定的方法是首先求解节点处的二阶导数，记为 $M_i = s_K''(\\tau_i)$。对于均匀节点序列，其中任意两个连续节点之间的间距是常数 $h = \\tau_{i+1} - \\tau_i = \\frac{1}{K-1}$，连续性条件会导出一个关于未知值 $M_1, \\dots, M_{K-2}$ 的线性方程组。对于 $i \\in \\{1, \\dots, K-2\\}$，其控制方程为：\n$$\nM_{i-1} + 4M_i + M_{i+1} = \\frac{6}{h^2}(y_{i+1} - 2y_i + y_{i-1})\n$$\n自然边界条件提供了 $M_0 = 0$ 和 $M_{K-1} = 0$。将这些代入方程组，得到一个关于内部二阶导数 $M_1, \\dots, M_{K-2}$ 的 $(K-2) \\times (K-2)$ 三对角线性方程组。该系统是严格对角占优的，因此有唯一解。\n\n一旦所有 $M_i$ 的值都已知，任何子区间 $[\\tau_i, \\tau_{i+1}]$ 上的三次多项式 $s_i(x)$ 就由以下公式唯一确定：\n$$\ns_i(x) = M_i \\frac{(\\tau_{i+1}-x)^3}{6h} + M_{i+1} \\frac{(x-\\tau_i)^3}{6h} + \\left(\\frac{y_{i+1}-y_i}{h} - \\frac{h}{6}(M_{i+1}-M_i)\\right)(x-\\tau_i) + \\left(y_i - \\frac{M_i h^2}{6}\\right)\n$$\n这种手动构建过程可以使用成熟的数值库方便而稳健地执行。Python 的 SciPy 库中的 `scipy.interpolate.CubicSpline` 类，配合 `bc_type='natural'` 参数，可以自动完成整个过程。它接收节点位置 $\\tau_i$ 和对应的函数值 $y_i=e^{\\tau_i}$ 作为输入，并构建所需的样条函数。\n\n**2. $L^2$ 逼近误差计算**\n\n样条逼近的质量由 $L^2$ 误差衡量，定义为：\n$$\nE_K = \\left( \\int_{0}^{1} \\big( s_K(x) - f(x) \\big)^2 \\, dx \\right)^{1/2}\n$$\n在这个问题中，$f(x) = e^x$。被积函数是 $(s_K(x) - e^x)^2$。由于 $s_K(x)$ 是一个分段多项式而 $e^x$ 是一个无限可微的函数，被积函数是连续且性质良好的，这使其适合于高精度的数值积分。\n\n积分是在整个区间 $[0, 1]$ 上计算的。一种高效的计算方法是使用自适应求积例程，它会调整步长以达到期望的精度，并将计算精力集中在被积函数变化最剧烈的区域。`scipy.integrate.quad` 函数是完成此任务的绝佳选择，因为它提供了 QUADPACK 库自适应积分算法的稳健而精确的实现。\n\n**3. 算法实现**\n\n对于每个指定的总节点数 $K$，总体算法如下：\n1.  **生成节点和数据**：对于给定的 $K$，在区间 $[0, 1]$ 上创建均匀节点序列 $\\tau_i = \\frac{i}{K-1}$，其中 $i \\in \\{0, 1, \\dots, K-1\\}$。计算相应的函数值 $y_i = e^{\\tau_i}$。\n2.  **构建样条**：使用 `scipy.interpolate.CubicSpline`，并传入节点 $\\tau$、函数值 $y$ 以及边界条件类型 `bc_type='natural'` 来创建样条函数 $s_K(x)$。\n3.  **定义被积函数**：定义一个 Python 函数，用于计算任意给定 $x \\in [0, 1]$ 的平方误差 $(s_K(x) - e^x)^2$。\n4.  **数值积分**：使用 `scipy.integrate.quad` 计算平方误差函数从 $x=0$ 到 $x=1$ 的定积分。\n5.  **计算误差**：通过对积分结果取平方根来计算最终的 $L^2$ 误差 $E_K$。\n6.  **格式化输出**：按要求将计算出的误差 $E_K$ 格式化为八位小数。\n\n对测试集 $\\{2, 3, 5, 11\\}$ 中的每个 $K$ 值重复此过程。特殊情况 $K=2$ 会产生一个线性函数，`CubicSpline` 构造函数使用自然边界条件能正确处理这种情况。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import CubicSpline\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Constructs natural cubic splines for f(x) = e^x and computes their L2 error.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [2, 3, 5, 11]\n\n    results = []\n    for K in test_cases:\n        # Step 1: Generate a uniform knot sequence on [0,1] and evaluate f(x) at these knots.\n        # The number of knots is K. The knots are tau_i = i/(K-1) for i in {0, ..., K-1}.\n        knots = np.linspace(0.0, 1.0, K)\n        \n        # The function to approximate is f(x) = e^x.\n        y_values = np.exp(knots)\n        \n        # Step 2: Construct the natural cubic spline.\n        # The 'bc_type=\"natural\"' argument sets the second derivatives at the endpoints\n        # (x=0 and x=1) to zero, which is the definition of a natural spline.\n        # This function handles the underlying linear algebra (solving the tridiagonal system) internally.\n        natural_spline = CubicSpline(knots, y_values, bc_type='natural')\n        \n        # Step 3: Define the integrand for the L^2 error calculation.\n        # The integrand is the squared difference between the spline and the true function.\n        def squared_error_integrand(x):\n            return (natural_spline(x) - np.exp(x))**2\n            \n        # Step 4: Numerically evaluate the integral of the squared error over [0,1].\n        # scipy.integrate.quad uses adaptive quadrature for high accuracy.\n        # It returns a tuple: (result, estimated_absolute_error). We only need the result.\n        integral_value, _ = quad(squared_error_integrand, 0.0, 1.0)\n        \n        # Step 5: Compute the L^2 error, which is the square root of the integral.\n        l2_error = np.sqrt(integral_value)\n        \n        # Append the result, formatted to exactly eight decimal places.\n        results.append(f\"{l2_error:.8f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3153014"}, {"introduction": "这个最终练习 [@problem_id:3153008] 将自然样条置于一个实际的回归问题中，并将其与全局多项式拟合进行对比。通过比较两种模型在训练数据范围之外的积分平方误差，你将深刻理解自然样条的线性尾部约束为何在避免过拟合并产生更稳健的预测方面至关重要。这项实践有助于培养在不同模型之间进行权衡和选择的批判性思维，这是统计学习中的一项核心技能。", "problem": "给定一个综合回归设置，其目标是比较自然三次样条和全局三次多项式拟合在逼近未知目标函数时的行为。从最小二乘回归的基本原理和带自然边界条件的三次样条的定义出发，在相同的训练数据上实现两种回归估计器：(i) 一个全局三次多项式和 (ii) 一个在训练输入范围内具有等间距节点的自然三次样条。然后，使用数值积分，计算每个估计器在指定的评估区间上的积分平方误差，该区间包括训练范围并延伸到尾部。\n\n使用以下基本基础：\n- 普通最小二乘回归：给定一个设计矩阵 $X \\in \\mathbb{R}^{n \\times p}$ 和响应 $y \\in \\mathbb{R}^n$，最小二乘估计器 $\\hat{\\beta}$ 最小化 $\\sum_{i=1}^n (y_i - (X \\hat{\\beta})_i)^2$ 并对于特征向量 $x$ 产生 $\\hat{f}(x) = x^\\top \\hat{\\beta}$。\n- 三次样条回归：三次样条是在节点处一阶和二阶导数连续的分段三次函数。自然三次样条施加自然边界条件，要求在边界节点处的二阶导数为零，这意味着在边界节点区间之外呈线性行为。\n- 积分平方误差：对于一个估计器 $\\hat{f}$ 和真实函数 $f$，在区间 $[A,B]$ 上的积分平方误差为 $\\int_A^B \\left(\\hat{f}(x) - f(x)\\right)^2 \\, dx$，它可以通过在精细网格上使用黎曼和或梯形法则进行数值逼近。\n\n实现以下内容，不要在问题文本中提供或依赖快捷公式：\n\n1. 数据生成。对于每个测试用例，生成在 $[a,b]$ 中均匀分布的训练输入 $x_i$ 和输出 $y_i = f(x_i) + \\epsilon_i$，其中 $\\epsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$ 是独立同分布的高斯噪声。对于任何三角函数，使用弧度角。\n2. 估计器。\n   - 全局三次多项式：使用特征映射 $x \\mapsto [1, x, x^2, x^3]$ 进行回归。\n   - 自然三次样条：使用一个标准的自然三次样条基，其边界节点在 $a$ 和 $b$ 处，以及在 $[a,b]$ 中等间距分布的 $M-2$ 个内部节点，产生一个 $M$ 维设计，其中前两列代表线性部分，其余 $M-2$ 列代表强制自然边界条件的调整后的截断三次分量。\n3. 评估。对于每个拟合模型，通过在 $N_{\\text{eval}}$ 个点的均匀网格上评估真实函数 $f$ 和拟合函数 $\\hat{f}$，并应用梯形法则，来近似计算在 $[A,B]$ 上的积分平方误差。\n\n测试套件。实现并运行以下四个测试用例，每个用例由 $(f, a, b, A, B, n_{\\text{train}}, \\sigma, M, N_{\\text{eval}}, \\text{seed})$ 指定：\n- 用例 1 (具有中等尾部的正常路径)：$f(x) = \\sin(2x) + 0.3 x$, $a=-3$, $b=3$, $A=-5$, $B=5$, $n_{\\text{train}}=61$, $\\sigma=0.1$, $M=7$, $N_{\\text{eval}}=10001$, $\\text{seed}=1$。\n- 用例 2 (无噪声和线性主导的尾部)：$f(x) = x + 0.5 \\sin(x)$, $a=-1$, $b=1$, $A=-4$, $B=4$, $n_{\\text{train}}=41$, $\\sigma=0.0$, $M=5$, $N_{\\text{eval}}=10001$, $\\text{seed}=2$。\n- 用例 3 (曲率加线性趋势，中等噪声)：$f(x) = e^{-x^2} + x$, $a=-2$, $b=2$, $A=-3$, $B=3$, $n_{\\text{train}}=81$, $\\sigma=0.05$, $M=6$, $N_{\\text{eval}}=10001$, $\\text{seed}=3$。\n- 用例 4 (具有最少节点和宽尾部的边缘用例)：$f(x) = \\sin(x)$, $a=-2$, $b=2$, $A=-6$, $B=6$, $n_{\\text{train}}=51$, $\\sigma=0.0$, $M=3$, $N_{\\text{eval}}=10001$, $\\text{seed}=4$。\n\n对于每个用例，计算三个量：自然样条的积分平方误差 $\\text{ISE}_{\\text{ns}}$，三次多项式的积分平方误差 $\\text{ISE}_{\\text{cp}}$，以及差值 $\\text{ISE}_{\\text{ns}} - \\text{ISE}_{\\text{cp}}$。将所有报告的浮点数四舍五入到 $6$ 位小数。\n\n最终输出格式。您的程序应生成单行输出，其中包含结果，形式为列表的列表，每个子列表对应于用例 1 到 4 序列中的一个测试用例。每个子列表必须为 $[\\text{ISE}_{\\text{ns}}, \\text{ISE}_{\\text{cp}}, \\text{ISE}_{\\text{ns}} - \\text{ISE}_{\\text{cp}}]$ 的形式，并且所有数字都四舍五入到 6 位小数，例如：$[[0.123456,0.234567,-0.111111],[...],...]$。", "solution": "该问题要求通过评估两种回归模型——全局三次多项式和自然三次样条——在指定区间上拟合目标函数的性能，来对它们进行比较。性能指标是积分平方误差 (Integrated Squared Error, ISE)。分析从普通最小二乘 (ordinary least squares, OLS) 回归的基本原理和每种模型的基函数的数学定义出发。\n\n两种模型的基础都是 OLS 回归。给定一组 $n_{\\text{train}}$ 个训练对 $(x_i, y_i)$，我们的目标是找到一个函数 $\\hat{f}$，以最小化残差平方和 $\\text{RSS}(\\beta) = \\sum_{i=1}^{n_{\\text{train}}} (y_i - \\hat{f}(x_i))^2$。对于形式为 $\\hat{f}(x) = \\sum_{j=1}^{p} \\beta_j h_j(x)$ 的线性模型，其中 $\\{h_j(x)\\}_{j=1}^p$ 是一组基函数，这等价于求解最小化 $\\|y - X\\beta\\|^2$ 的系数向量 $\\hat{\\beta} \\in \\mathbb{R}^p$。这里，$y = [y_1, \\dots, y_{n_{\\text{train}}}]^\\top$ 是响应向量，$X$ 是一个 $n_{\\text{train}} \\times p$ 的设计矩阵，其条目为 $X_{ij} = h_j(x_i)$。其著名解由 $\\hat{\\beta} = (X^\\top X)^{-1} X^\\top y$ 给出，在数值上最好使用奇异值分解等方法计算，正如在标准线性代数库 (`lstsq`) 中实现的那样。\n\n第一个模型是**全局三次多项式**，其中函数假定为形式 $\\hat{f}_{\\text{cp}}(x) = \\beta_0 + \\beta_1 x + \\beta_2 x^2 + \\beta_3 x^3$。基函数是 $\\{h_1(x), h_2(x), h_3(x), h_4(x)\\} = \\{1, x, x^2, x^3\\}$。相应的设计矩阵 $X_{\\text{cp}}$ 是一个 $n_{\\text{train}} \\times 4$ 的矩阵，其中第 $i$ 行为 $[1, x_i, x_i^2, x_i^3]$。\n\n第二个模型是**自然三次样条**。三次样条是在一系列称为节点的点上连续且具有连续一阶和二阶导数的分段三次多项式。自然三次样条施加了一个额外约束：函数在边界节点之外必须是线性的。这是通过要求二阶导数在最小和最大节点处为零来实现的。对于一组 $M$ 个节点 $\\xi_1  \\xi_2  \\dots  \\xi_M$，其中 $\\xi_1$ 和 $\\xi_M$ 是边界节点，自然三次样条空间的一个标准 $M$ 维基由以下给出：\n$N_1(x) = 1$\n$N_2(x) = x$\n$N_{j+2}(x) = d_j(x) - d_{M-1}(x)$ for $j = 1, \\dots, M-2$.\n函数 $d_j(x)$ 定义为：\n$$d_j(x) = \\frac{(x - \\xi_j)_+^3 - (x - \\xi_M)_+^3}{\\xi_M - \\xi_j}$$\n其中如果 $u > 0$ 则 $(u)_+ = u$，否则为 $0$。这种基函数的选择明确确保了它们的任何线性组合对于 $x  \\xi_1$ 和 $x > \\xi_M$ 都是线性的。对于每个测试用例，我们在训练区间 $[a,b]$ 上构造一组 $M$ 个等间距的节点，使得 $\\xi_1=a$ 和 $\\xi_M=b$。相应的设计矩阵 $X_{\\text{ns}}$ 是一个 $n_{\\text{train}} \\times M$ 矩阵，其第 $i$ 行为 $[N_1(x_i), N_2(x_i), \\dots, N_M(x_i)]$。\n\n一旦两个模型都拟合到训练数据 $(x_i, y_i = f(x_i) + \\mathcal{N}(0, \\sigma^2))$ 以获得估计器 $\\hat{f}_{\\text{cp}}(x)$ 和 $\\hat{f}_{\\text{ns}}(x)$，我们就评估它们的性能。度量标准是在评估区间 $[A,B]$ 上的积分平方误差 (ISE)：\n$$\\text{ISE}(\\hat{f}) = \\int_A^B (\\hat{f}(x) - f(x))^2 \\, dx$$\n这个积分使用梯形法则进行数值逼近。创建一个包含 $N_{\\text{eval}}$ 个点的精细均匀网格，该网格跨越区间 $[A,B]$。设这些点为 $z_k$，其中 $k=1, \\dots, N_{\\text{eval}}$，点之间的恒定间距为 $\\Delta z = (B-A)/(N_{\\text{eval}}-1)$。然后 ISE 可近似为：\n$$\\text{ISE}(\\hat{f}) \\approx \\sum_{k=1}^{N_{\\text{eval}}-1} \\frac{(\\hat{f}(z_k) - f(z_k))^2 + (\\hat{f}(z_{k+1}) - f(z_{k+1}))^2}{2} \\Delta z$$\n此过程被用于计算三次多项式的 $\\text{ISE}_{\\text{cp}}$ 和自然样条的 $\\text{ISE}_{\\text{ns}}$，为比较它们的行为提供了一个定量基础，特别是在训练区间 $[a,b]$ 之外的外推区域。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and compares global cubic polynomial and natural cubic spline\n    regression models based on their integrated squared error.\n    \"\"\"\n\n    # Define the true functions for the test cases.\n    # Angles are in radians.\n    functions = {\n        1: lambda x: np.sin(2 * x) + 0.3 * x,\n        2: lambda x: x + 0.5 * np.sin(x),\n        3: lambda x: np.exp(-x**2) + x,\n        4: lambda x: np.sin(x),\n    }\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, -3, 3, -5, 5, 61, 0.1, 7, 10001, 1),\n        (2, -1, 1, -4, 4, 41, 0.0, 5, 10001, 2),\n        (3, -2, 2, -3, 3, 81, 0.05, 6, 10001, 3),\n        (4, -2, 2, -6, 6, 51, 0.0, 3, 10001, 4),\n    ]\n\n    def build_natural_spline_basis(x, knots):\n        \"\"\"\n        Constructs the design matrix for a natural cubic spline.\n        The basis is derived from \"The Elements of Statistical Learning\".\n        \"\"\"\n        M = len(knots)\n        x = np.asarray(x)\n        basis = np.zeros((len(x), M))\n        \n        basis[:, 0] = 1.0\n        if M  1:\n            basis[:, 1] = x\n\n        if M  2:\n            def d_func(x_vec, knot_k, knot_M):\n                # Implements the d_k(x) function for the spline basis\n                term1 = np.maximum(0, x_vec - knot_k)**3\n                term2 = np.maximum(0, x_vec - knot_M)**3\n                return (term1 - term2) / (knot_M - knot_k)\n\n            knot_M_val = knots[-1]\n            d_M_minus_1_vec = d_func(x, knots[M-2], knot_M_val)\n            \n            for j in range(1, M - 1):\n                knot_j = knots[j-1]\n                d_j_vec = d_func(x, knot_j, knot_M_val)\n                basis[:, j + 1] = d_j_vec - d_M_minus_1_vec\n                \n        return basis\n\n    results = []\n    for case in test_cases:\n        f_id, a, b, A, B, n_train, sigma, M, N_eval, seed = case\n        f = functions[f_id]\n\n        # 1. Data Generation\n        rng = np.random.default_rng(seed)\n        x_train = np.linspace(a, b, n_train)\n        noise = rng.normal(0, sigma, size=n_train)\n        y_train = f(x_train) + noise\n\n        # 2. Estimators\n        # Global Cubic Polynomial\n        X_cp_train = np.vander(x_train, 4, increasing=True)\n        beta_cp = np.linalg.lstsq(X_cp_train, y_train, rcond=None)[0]\n\n        def f_hat_cp(x_eval):\n            X_cp_eval = np.vander(x_eval, 4, increasing=True)\n            return X_cp_eval @ beta_cp\n\n        # Natural Cubic Spline\n        knots = np.linspace(a, b, M)\n        X_ns_train = build_natural_spline_basis(x_train, knots)\n        beta_ns = np.linalg.lstsq(X_ns_train, y_train, rcond=None)[0]\n        \n        def f_hat_ns(x_eval):\n            X_ns_eval = build_natural_spline_basis(x_eval, knots)\n            return X_ns_eval @ beta_ns\n\n        # 3. Evaluation\n        x_eval = np.linspace(A, B, N_eval)\n        y_true_eval = f(x_eval)\n\n        # ISE for Cubic Polynomial\n        y_hat_cp_eval = f_hat_cp(x_eval)\n        squared_error_cp = (y_hat_cp_eval - y_true_eval)**2\n        ise_cp = np.trapz(squared_error_cp, x_eval)\n\n        # ISE for Natural Spline\n        y_hat_ns_eval = f_hat_ns(x_eval)\n        squared_error_ns = (y_hat_ns_eval - y_true_eval)**2\n        ise_ns = np.trapz(squared_error_ns, x_eval)\n\n        # Store results rounded to 6 decimal places\n        diff = ise_ns - ise_cp\n        results.append([round(ise_ns, 6), round(ise_cp, 6), round(diff, 6)])\n\n    # Final print statement in the exact required format.\n    case_strs = []\n    for res in results:\n        num_strs = [str(val) for val in res]\n        case_strs.append(f\"[{','.join(num_strs)}]\")\n    print(f\"[{','.join(case_strs)}]\")\n\nsolve()\n```", "id": "3153008"}]}