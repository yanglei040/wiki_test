{"hands_on_practices": [{"introduction": "感知机的收敛性定理虽然优雅，但它依赖于理想的数据假设。在现实世界中，数据集常常包含远离大部分数据点的异常值。本练习旨在探索标准感知机算法的一个关键弱点：它对这类大范数异常值的敏感性 [@problem_id:3099471]。通过亲手实现和测试该算法，你将观察到少数几个“坏”数据点如何极大地减缓甚至破坏学习过程，并动手实践诸如更新裁剪和稳健归一化等强大的缓解策略，以构建更具鲁棒性的分类器。", "problem": "要求您实现并评估一个由感知机算法训练的线性分类器，该分类器在存在少量大范数离群点的情况下进行训练。目的是量化分类器对这些离群点的敏感性，并测试两种缓解策略：裁剪更新幅度和基于分布尺度估计的稳健归一化。您的实现必须是一个完整的、可运行的程序，并能产生完全符合指定格式的输出。\n\n从以下基本和核心定义开始。线性分类器由一个权重向量 $w \\in \\mathbb{R}^d$ 和一个偏置 $b \\in \\mathbb{R}$ 定义，它通过决策规则 $\\hat{y} = \\mathrm{sign}(w^\\top x + b)$ 对输入 $x \\in \\mathbb{R}^d$ 预测标签 $\\hat{y} \\in \\{-1,+1\\}$。感知机学习规则在样本 $(x,y)$ 被错误分类时更新参数，即当 $y(w^\\top x + b) \\le 0$ 时，执行 $w \\leftarrow w + y x$ 和 $b \\leftarrow b + y$。已知感知机在线性可分数据上所犯错误次数的上限取决于数据半径和间隔；但是，您不应假设任何特定的简化公式，而必须通过实验实现并测量其行为。\n\n您将在 $d=2$ 维空间中生成具有两个线性可分的数据类别。对所有测试用例使用以下构造和参数：\n- 设基础尺度为 $R = 1.0$。\n- 将正类中心置于 $\\mu_+ = (3R, 0)$，负类中心置于 $\\mu_- = (-3R, 0)$。\n- 对每个类别，生成 $n_+ = n_- = 50$ 个基准点，其坐标为 $x = (\\mu_{\\mathrm{class},1}, u)$，其中对每个点而言，$u$ 独立地从区间 $[-R, R]$ 中均匀采样，而 $\\mu_{\\mathrm{class},1}$ 是相应类别中心的第一个坐标。这确保了数据可被由 $x_1 = 0$ 定义的超平面线性分离。\n- 离群点：当测试用例指定时，为每个类别添加 $k_+ = k_- = 2$ 个离群点，确定性地放置在正类的 $x = (N\\cdot R, 0)$ 和负类的 $x = (-N\\cdot R, 0)$ 处，其中 $N$ 是该测试用例特定的离群点范数因子。将离群点按类别交替顺序（正、负、正、负）插入序列的开头，然后附加所有基准点（先是所有正类基准点，然后是所有负类基准点）。这种排序因训练早期交替出现的大范数错误分类而增加了有害更新的可能性。\n- 正类点的标签为 $y=+1$，负类点的标签为 $y=-1$。\n\n需实现的训练协议：\n- 通过附加一个常数特征 $1$ 来增广输入，以便更新可以对增广向量以向量形式写出。\n- 将权重向量初始化为零向量，偏置初始化为 $0$，等效于将增广权重向量初始化为零向量。\n- 按照上述固定顺序对数据集执行 $T = 5$ 次完整遍历（epochs），在各轮次之间不打乱数据顺序。\n- 对于每个样本 $(x, y)$，如果 $y \\cdot (w^\\top x + b) \\le 0$，则进行一次更新。更新的具体形式取决于测试用例指定的缓解方法：\n  1. 标准感知机：对原始的 $x$ 执行未经修改的更新 $w \\leftarrow w + y x$ 和 $b \\leftarrow b + y$。\n  2. 裁剪更新：计算欧几里得范数 $\\|x\\|_2$。设 $c$ 为一个正阈值；定义一个缩放因子 $s = \\min\\{1, c / \\|x\\|_2\\}$。应用更新时用 $s x$ 代替 $x$，即 $w \\leftarrow w + y (s x)$ 和 $b \\leftarrow b + y$。这限制了任何单个样本所贡献的最大步长。\n  3. 稳健归一化：通过计算整个训练集上的稳健尺度参数 $s_{\\mathrm{rob}} = \\mathrm{median}(\\{\\|x_i\\|_2\\})$ 来预处理所有输入 $x_i$。将每个 $x_i$ 替换为 $\\tilde{x}_i = x_i \\cdot \\frac{s_{\\mathrm{rob}}}{\\max\\{s_{\\mathrm{rob}}, \\|x_i\\|_2\\}}$，然后使用标准感知机更新规则在归一化后的输入上进行训练。这使得范数 $\\|x_i\\|_2 \\le s_{\\mathrm{rob}}$ 的点保持不变，并将范数较大的点按比例缩小，使其范数最多为 $s_{\\mathrm{rob}}$。\n\n每个测试用例需报告的指标：\n- 统计在所有 $T$ 轮中进行的总更新次数（等同于总错误次数）。这是一个整数。\n\n您必须在单个程序中实现上述内容，并在以下测试套件上运行它，该套件旨在覆盖一般情况、中度离群点和极端离群点，以及各种缓解策略：\n- 测试用例 1：无离群点 ($N = 0$)，标准感知机。\n- 测试用例 2：中度离群点 ($N = 50$)，标准感知机。\n- 测试用例 3：中度离群点 ($N = 50$)，使用阈值 $c = R$ 的裁剪更新。\n- 测试用例 4：中度离群点 ($N = 50$)，稳健归一化。\n- 测试用例 5：极端离群点 ($N = 1000$)，标准感知机。\n- 测试用例 6：极端离群点 ($N = 1000$)，使用阈值 $c = R/2$ 的裁剪更新。\n\n确定性要求：\n- 在数据生成中的任何随机过程使用固定的种子 $s_0 = 2025$，以确保确定性输出。\n- 在各轮次之间不要打乱数据集。\n\n最终输出格式：\n- 您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表，例如 $[r_1, r_2, r_3, r_4, r_5, r_6]$，其中 $r_i$ 是按上述顺序列出的第 $i$ 个测试用例的整数总更新次数。打印的行必须只包含此列表，不得有任何附加文本。", "solution": "该问题要求实现和评估感知机线性分类器，特别关注其对大范数离群点的敏感性以及两种缓解策略的有效性。解决方案涉及生成合成数据，实现带有特定修改的感知机算法，并报告在多个测试用例中的总分类错误（更新）次数。\n\n线性分类器由一个权重向量 $w \\in \\mathbb{R}^d$ 和一个标量偏置 $b \\in \\mathbb{R}$ 定义。对于输入向量 $x \\in \\mathbb{R}^d$，它根据规则 $\\hat{y} = \\mathrm{sign}(w^\\top x + b)$ 预测一个标签 $\\hat{y} \\in \\{-1, +1\\}$。问题设置在 $d=2$ 维空间中。感知机学习算法通过迭代调整参数 $w$ 和 $b$ 来正确分类训练样本。当一个样本 $(x, y)$ 被错误分类时，即满足条件 $y(w^\\top x + b) \\le 0$ 时，参数按如下方式更新：\n$$\nw \\leftarrow w + y x\n$$\n$$\nb \\leftarrow b + y\n$$\n为方便符号表示和计算，我们可以增广输入向量和权重向量。设增广权重向量为 $\\tilde{w} = [w_1, \\dots, w_d, b]^\\top \\in \\mathbb{R}^{d+1}$，增广输入向量为 $\\tilde{x} = [x_1, \\dots, x_d, 1]^\\top \\in \\mathbb{R}^{d+1}$。决策规则变为 $\\hat{y} = \\mathrm{sign}(\\tilde{w}^\\top \\tilde{x})$，而对于错误分类（$y(\\tilde{w}^\\top \\tilde{x}) \\le 0$），更新规则简化为单个向量加法：\n$$\n\\tilde{w} \\leftarrow \\tilde{w} + y\\tilde{x}\n$$\n参数被初始化为零，即 $\\tilde{w}_{\\text{init}} = \\mathbf{0}$。\n\n标准感知机更新的一个关键特性是，权重向量变化的幅度为 $\\|\\Delta \\tilde{w}\\|_2 = \\|y\\tilde{x}\\|_2 = \\|\\tilde{x}\\|_2 = \\sqrt{\\|x\\|_2^2 + 1}$。这种对输入向量范数的直接依赖是该算法对离群点敏感的根源。一个具有异常大范数的错误分类点将导致一次不成比例的大更新，可能将决策边界推离最优位置，并导致随后在其他行为良好的数据点上产生许多错误。\n\n该实验旨在展示这一现象。一个基础数据集由两个类别生成，其中心分别位于 $\\mu_+ = (3R, 0)$ 和 $\\mu_- = (-3R, 0)$，基础尺度为 $R=1.0$。每个类别包含 $n=50$ 个形式为 $(\\mu_{\\mathrm{class},1}, u)$ 的点，其中 $u$ 从 $[-R, R]$ 上的均匀分布中抽取。这种构造创建了一个可被纵轴 $x_1=0$ 线性分离的数据集。在这个干净的数据集上，我们添加 $k=2$ 对离群点，确定性地位于 $(\\pm N \\cdot R, 0)$。离群点范数因子 $N$ 很大（$N \\in \\{50, 1000\\}$），确保这些点具有非常大的范数。这些离群点被放置在训练序列的开头，以最大化它们对初始为零的权重向量的破坏性影响。\n\n测试了两种针对标准感知机的缓解策略：\n\n1.  **裁剪更新**：此策略直接限制了参数更新的幅度。对于一个错误分类的点 $(x, y)$，根据一个预定义的裁剪阈值 $c>0$ 计算一个缩放因子 $s = \\min\\{1, c/\\|x\\|_2\\}$。权重向量 $w$ 通过 $w \\leftarrow w + y(sx)$ 更新，而偏置则正常更新 $b \\leftarrow b+y$。这种方法确保了由任何单个样本引起的 $w$ 的变化是有界的。\n\n2.  **稳健归一化**：这是一种在训练开始前应用一次的数据预处理技术。首先，在整个训练集上计算数据尺度的一个稳健估计值，$s_{\\mathrm{rob}} = \\mathrm{median}(\\{\\|x_i\\|_2\\})$。然后，每个输入向量 $x_i$ 被替换为一个归一化版本 $\\tilde{x}_i$：\n    $$\n    \\tilde{x}_i = x_i \\cdot \\frac{s_{\\mathrm{rob}}}{\\max\\{s_{\\mathrm{rob}}, \\|x_i\\|_2\\}}\n    $$\n    这种变换使得范数小于或等于中位数的点保持不变，同时将所有范数大于中位数的点缩小，使其范数恰好为 $s_{\\mathrm{rob}}$。这有效地“拉回”了大范数的离群点，在学习过程开始前减小了它们的潜在影响。\n\n实现将首先为每个测试用例生成指定的数据集。然后，对于“稳健归一化”的情况，数据将被预处理。训练循环在固定顺序的数据集上迭代 $T=5$ 次（epochs）。在每个轮次中，评估每个样本。如果发生错误，总错误计数器会增加，并根据该测试用例指定的方法（“标准”、“裁剪”或“稳健”）更新权重。每个用例的最终输出是累积的错误总数。整个过程通过使用固定的随机种子 $s_0=2025$ 进行数据生成以及在轮次之间不打乱数据来确保其确定性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_single_test_case(params, seed):\n    \"\"\"\n    Runs a single test case for the perceptron algorithm.\n\n    Args:\n        params (dict): A dictionary containing the parameters for the test case,\n                       including 'N', 'method', and 'c'.\n        seed (int): The random seed for reproducibility.\n\n    Returns:\n        int: The total number of updates (mistakes) made during training.\n    \"\"\"\n    np.random.seed(seed)\n    \n    # Define problem constants\n    R = 1.0\n    n = 50\n    k = 2\n    d = 2\n    T = 5\n    \n    # Extract test case parameters\n    N = params['N']\n    method = params['method']\n    c = params['c']\n\n    # --- Data Generation ---\n    # Base points\n    x_pos_base = np.zeros((n, d))\n    x_pos_base[:, 0] = 3 * R\n    x_pos_base[:, 1] = np.random.uniform(-R, R, size=n)\n    y_pos_base = np.ones(n)\n\n    x_neg_base = np.zeros((n, d))\n    x_neg_base[:, 0] = -3 * R\n    x_neg_base[:, 1] = np.random.uniform(-R, R, size=n)\n    y_neg_base = -np.ones(n)\n\n    # Assemble dataset with outliers first, in specified alternating order\n    X_list = []\n    y_list = []\n\n    if N > 0:\n        x_pos_outlier = np.array([N * R, 0.0])\n        x_neg_outlier = np.array([-N * R, 0.0])\n        for _ in range(k):\n            X_list.append(x_pos_outlier)\n            y_list.append(1.0)\n            X_list.append(x_neg_outlier)\n            y_list.append(-1.0)\n    \n    X_list.extend(list(x_pos_base))\n    y_list.extend(list(y_pos_base))\n    X_list.extend(list(x_neg_base))\n    y_list.extend(list(y_neg_base))\n\n    X = np.array(X_list)\n    y = np.array(y_list)\n\n    # --- Pre-processing for Robust Normalization ---\n    if method == 'robust':\n        norms = np.linalg.norm(X, axis=1)\n        # Handle the case where all norms are zero to avoid division by zero\n        s_rob = np.median(norms)\n        if s_rob > 0:\n            scaling_factors = s_rob / np.maximum(s_rob, norms)\n            X = X * scaling_factors[:, np.newaxis]\n\n    # --- Training ---\n    # Augment inputs with a bias term\n    X_aug = np.hstack([X, np.ones((X.shape[0], 1))])\n    \n    # Initialize augmented weight vector\n    w_aug = np.zeros(d + 1)\n    \n    update_count = 0\n\n    for _ in range(T):\n        for i in range(X.shape[0]):\n            x_i_aug = X_aug[i]\n            y_i = y[i]\n            \n            # Check for misclassification\n            if y_i * (w_aug @ x_i_aug) = 0:\n                update_count += 1\n                \n                # Apply update based on the specified method\n                if method == 'standard' or method == 'robust':\n                    w_aug += y_i * x_i_aug\n                elif method == 'clipped':\n                    x_i = X[i]  # Original un-augmented vector for norm calculation\n                    norm_x = np.linalg.norm(x_i)\n                    s = 1.0\n                    if norm_x > 0 and c is not None:\n                        s = min(1.0, c / norm_x)\n                    \n                    # Update weights and bias separately as specified\n                    w_update = y_i * s * x_i\n                    b_update = y_i * 1.0  # Bias update is not scaled\n                    \n                    w_aug[:d] += w_update\n                    w_aug[d] += b_update\n\n    return update_count\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    s0 = 2025\n    test_cases = [\n        {'N': 0, 'method': 'standard', 'c': None},\n        {'N': 50, 'method': 'standard', 'c': None},\n        {'N': 50, 'method': 'clipped', 'c': 1.0},\n        {'N': 50, 'method': 'robust', 'c': None},\n        {'N': 1000, 'method': 'standard', 'c': None},\n        {'N': 1000, 'method': 'clipped', 'c': 0.5},\n    ]\n\n    all_results = []\n    for params in test_cases:\n        result = run_single_test_case(params, s0)\n        all_results.append(result)\n\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3099471"}, {"introduction": "除了单个异常值，特征空间的整体结构也深刻地影响着学习算法的性能。本练习将焦点从数据质量转向数据结构，具体探讨特征之间的相关性如何影响感知机的收敛速度 [@problem_id:3099389]。你将生成具有可控相关性水平的数据，并发现高度相关的特征会为算法的收敛制造一个充满挑战的“地形”。通过应用线性代数工具——格拉姆-施密特（Gram-Schmidt）正交化过程来去相关特征，你将通过实验验证一个条件良好（well-conditioned）的正交特征空间能够显著加快收敛速度。", "problem": "要求您编写一个完整、可运行的程序，以通过实验分析特征相关性如何影响感知器学习算法的收敛速度，以及如何通过 Gram–Schmidt 过程对特征进行去相关处理来改变这一行为。您的程序必须从基本原理出发实现感知器，并基于 Gram–Schmidt 正交规范化执行特征空间变换，以获得去相关的表示用于比较。\n\n使用的基本原理：\n- 带有感知器更新规则的线性分类器定义：对于数据点 $\\{(x_i,y_i)\\}_{i=1}^n$，其中 $x_i \\in \\mathbb{R}^d$ 且标签为 $y_i \\in \\{-1,+1\\}$，感知器维护一个权重向量 $w \\in \\mathbb{R}^d$，并在对 $(x_i,y_i)$ 分类错误时使用规则 $w \\leftarrow w + y_i x_i$ 来更新它。\n- Gram–Schmidt 正交规范化：对于一个矩阵 $X \\in \\mathbb{R}^{n \\times d}$，Gram–Schmidt 过程产生一个因子分解 $X = QR$，其中 $Q \\in \\mathbb{R}^{n \\times d}$ 具有正交规范化的列，而当 $X$ 为满列秩时，$R \\in \\mathbb{R}^{d \\times d}$ 是一个可逆的上三角矩阵。相应的线性特征变换 $A = R^{-1}$ 将每个 $x_i$ 映射到 $z_i = A x_i$，从而生成 $Z = X A = Q$，其列在整个数据集上是正交规范的。\n\n您的程序必须：\n- 生成具有受控特征相关性的、合成的线性可分数据集。对于每个测试用例，从均值为零、协方差为等相关协方差矩阵 $\\Sigma = (1-\\rho) I_d + \\rho \\mathbf{1}\\mathbf{1}^\\top$ 的多元正态分布中，在 $d$ 维空间中抽取 $n$ 个样本，其中 $\\rho \\in (-1/(d-1), 1)$ 是相关系数，$\\mathbf{1}$ 是 $\\mathbb{R}^d$ 中的全一向量。从标准正态分布中抽取一个真实权重 $w_\\star \\in \\mathbb{R}^d$，并分配标签 $y_i = \\operatorname{sign}(w_\\star^\\top x_i) \\in \\{-1,+1\\}$。为确保正间隔，通过 $x_i \\leftarrow x_i + m\\, y_i\\, u$ 修改特征，其中 $u = \\frac{w_\\star}{\\|w_\\star\\|_2}$ 且 $m  0$ 是所有测试用例共用的一个固定间隔注入常数。\n- 实现一个确定性的感知器过程，该过程：\n  - 初始化 $w = 0 \\in \\mathbb{R}^d$。\n  - 按固定的索引顺序 $i = 1,2,\\dots,n$ 扫描 $n$ 个样本。\n  - 在每次出现 $y_i (w^\\top x_i) \\le 0$ 的错误时，应用更新规则 $w \\leftarrow w + y_i x_i$。\n  - 持续对数据集进行完整遍历，直到某次完整遍历不再出现任何错误，并返回所做的总更新次数。\n- 对原始特征矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 通过 $X = Q R$ 计算 Gram–Schmidt 变换，并构成去相关的特征 $Z = X R^{-1} = Q$。对 $Z$ 使用相同的标签 $y$ 运行完全相同的感知器过程，并记录收敛所需的总更新次数。\n- 为保证可复现性，每个测试用例使用一个固定的随机种子。所有随机抽取必须使用该测试用例指定的种子。\n- 对于所有线性代数和范数，使用标准的欧几里得内积。\n\n需要实现的测试套件：\n- 使用间隔注入 $m = 1.0$。\n- 对于每个测试用例，使用相应的元组 $(d,n,\\rho,\\text{seed})$ 按上述规定生成数据：\n  - 用例 1：$(d,n,\\rho,\\text{seed}) = (\\,2,\\,100,\\,0.0,\\,42\\,)$。\n  - 用例 2：$(d,n,\\rho,\\text{seed}) = (\\,2,\\,100,\\,0.95,\\,43\\,)$。\n  - 用例 3：$(d,n,\\rho,\\text{seed}) = (\\,2,\\,100,\\,{-0.95},\\,44\\,)$。\n  - 用例 4：$(d,n,\\rho,\\text{seed}) = (\\,3,\\,120,\\,0.8,\\,45\\,)$。\n\n每个测试用例的所需输出：\n- 生成一对整数 $[u_{\\text{orig}}, u_{\\text{ortho}}]$，其中 $u_{\\text{orig}}$ 是在原始相关特征 $X$ 上感知器收敛所需的总更新次数，而 $u_{\\text{ortho}}$ 是在经过 Gram–Schmidt 去相关的特征 $Z$ 上感知器收敛所需的总更新次数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由四个整数对组成的、以逗号分隔的列表，用方括号括起来，不含空格。例如：$[[u_1,v_1],[u_2,v_2],[u_3,v_3],[u_4,v_4]]$，其中每个 $u_k$ 和 $v_k$ 是对应于上述顺序的第 $k$ 个测试用例的整数。", "solution": "用户要求对感知器算法的收敛速度与特征相关性的函数关系进行实验性分析。这将通过以下方式实现：生成具有受控特征间相关性的合成数据集，在此原始数据上运行一个确定性的感知器算法，然后将其性能与在数据的去相关版本上运行相同算法进行比较。去相关操作是通过源自 Gram-Schmidt 正交规范化过程的特征空间变换来执行的。\n\n解决方案的结构如下：\n1.  **数据生成**：一种用于创建具有指定相关结构的线性可分数据集的精确方法。\n2.  **感知器算法**：感知器学习规则的实现。\n3.  **特征去相关**：应用 Gram-Schmidt 正交规范化来变换特征空间。\n4.  **实验过程**：针对单个测试用例的完整流程，结合上述组件以生成所需输出。\n\n**1. 数据生成**\n\n一个合成数据集由 $n$ 个实例组成，每个实例都是一个对偶 $(x_i, y_i)$，其中 $x_i \\in \\mathbb{R}^d$ 是一个特征向量，$y_i \\in \\{-1, +1\\}$ 是一个类别标签。\n\n- **初始特征生成**：特征向量最初从一个均值为零、协方差矩阵为 $\\Sigma$ 的 $d$ 维多元正态分布中抽取：\n$$\nx_i \\sim \\mathcal{N}(0, \\Sigma)\n$$\n协方差矩阵 $\\Sigma$ 被构造成具有等相关结构，由一个参数 $\\rho \\in (-1/(d-1), 1)$ 控制：\n$$\n\\Sigma = (1-\\rho) I_d + \\rho \\mathbf{1}\\mathbf{1}^\\top\n$$\n这里，$I_d$ 是 $d \\times d$ 的单位矩阵，$\\mathbf{1}$ 是一个 $d \\times 1$ 的全一向量。这种结构确保了每个特征的方差为 $1$，并且任意两个不同特征 $j$ 和 $k$ 之间的协方差为 $\\text{Cov}(X_j, X_k) = \\rho$。\n\n- **标签分配**：一个真实的分割超平面由一个权重向量 $w_\\star \\in \\mathbb{R}^d$ 定义，其分量从标准正态分布中抽取，$w_{\\star,j} \\sim \\mathcal{N}(0,1)$。然后根据每个点 $x_i$ 落在该超平面的哪一侧来分配标签：\n$$\ny_i = \\operatorname{sgn}(w_\\star^\\top x_i)\n$$\n为确保 $y_i \\in \\{-1, +1\\}$，任何 $w_\\star^\\top x_i = 0$ 的情况（对于连续分布来说是罕见事件）都通过分配 $y_i = +1$ 来解决。\n\n- **间隔注入**：为确保数据是线性可分的且具有非零间隔（这是感知器算法保证收敛的一个条件），特征向量会被调整。此过程将每个点 $x_i$ 沿正确方向进一步推离分割超平面。修改后的特征向量 $x'_i$ 由下式给出：\n$$\nx'_i = x_i + m y_i u\n$$\n其中 $m  0$ 是一个固定的间隔常数（在此问题中 $m=1.0$），$u$ 是垂直于真实超平面的单位向量，$u = \\frac{w_\\star}{\\|w_\\star\\|_2}$。此操作保证了每个点相对于由 $w_\\star$ 定义的超平面至少有 $m$ 的几何间隔。这些修改后的向量 $\\{x'_i\\}$ 的集合构成了最终的特征矩阵 $X$。\n\n**2. 感知器学习算法**\n\n感知器算法是一种用于为线性可分数据集寻找分割超平面的迭代方法。这里实现的算法是确定性的。\n\n- **初始化**：权重向量初始化为零向量，$w = 0 \\in \\mathbb{R}^d$。总更新次数的计数器初始化为 $0$。\n\n- **迭代**：该算法以轮次（pass）进行。在每一轮中，它按固定顺序遍历所有数据点 $(x_i, y_i)$，其中 $i=1, \\dots, n$。对于每个点，它检查分类条件：\n$$\ny_i (w^\\top x_i) \\le 0\n$$\n如果满足此条件，则该点被错误分类（或位于边界上），权重向量根据感知器规则进行更新：\n$$\nw \\leftarrow w + y_i x_i\n$$\n总更新计数器递增。\n\n- **终止**：当算法完成对数据集的一次完整遍历而没有任何更新时，它将终止。更新计数器的最终值是关注的结果，记为 $u$。\n\n**3. 通过 Gram-Schmidt 进行特征去相关**\n\n该问题要求与一个去相关的特征集进行比较。这是通过对原始特征矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 应用线性变换来实现的。\n\n- **QR 分解**：Gram-Schmidt 过程应用于特征矩阵 $X$ 的*列*。$X$ 的列 $\\{c_1, \\dots, c_d\\}$ 可以看作是 $\\mathbb{R}^n$ 中的向量，其中每个向量代表单个特征的所有观测值。该过程在计算上通过 $X$ 的简约 QR 分解实现：\n$$\nX = QR\n$$\n其中 $Q \\in \\mathbb{R}^{n \\times d}$ 是一个具有正交规范化列的矩阵（即 $Q^\\top Q = I_d$），$R \\in \\mathbb{R}^{d \\times d}$ 是一个可逆的上三角矩阵（假设 $X$ 具有满列秩，对于给定的数据生成过程，这极有可能）。\n\n- **特征变换**：问题通过矩阵 $A = R^{-1}$ 定义变换。新的特征矩阵 $Z \\in \\mathbb{R}^{n \\times d}$ 是通过将此变换应用于 $X$ 得到的：\n$$\nZ = XA = XR^{-1}\n$$\n通过代入 $X=QR$，我们发现新的特征矩阵就是 $Q$：\n$$\nZ = (QR)R^{-1} = Q(RR^{-1}) = QI_d = Q\n$$\n新的特征向量（即 $Z=Q$ 的行）将与原始标签 $y$ 一起用于训练第二个感知器。由此产生的特征空间的特性是，其定义特征的列向量是正交规范的，这意味着它们在数据集的样本中是不相关的。\n\n**4. 实验过程**\n\n对于由元组 $(d, n, \\rho, \\text{seed})$ 指定的每个测试用例，执行以下步骤：\n1.  为保证可复现性，设置随机数生成器的种子。\n2.  使用第 1 节中描述的过程生成原始特征矩阵 $X$ 和标签 $y$。\n3.  在数据集 $(X,y)$ 上运行感知器算法（第 2 节），并记录收敛所需的总更新次数 $u_{\\text{orig}}$。\n4.  计算 $X$ 的简约 QR 分解以获得 $Q$ 和 $R$。\n5.  设置变换后的特征矩阵 $Z=Q$。\n6.  在变换后的数据集 $(Z,y)$ 上运行感知器算法，并记录总更新次数 $u_{\\text{ortho}}$。\n7.  该测试用例的最终输出是整数对 $[u_{\\text{orig}}, u_{\\text{ortho}}]$。\n\n这一对比分析预期将表明，对于高相关性值 $|\\rho|$，更新次数 $u_{\\text{orig}}$ 将显著大于 $u_{\\text{ortho}}$。正交规范化过程使数据的几何结构规整化，通常能带来更快、更稳定的收敛。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_perceptron(features, labels):\n    \"\"\"\n    Runs the deterministic perceptron algorithm.\n\n    Args:\n        features (np.ndarray): The feature matrix (n_samples, n_features).\n        labels (np.ndarray): The label vector (n_samples,).\n\n    Returns:\n        int: The total number of updates until convergence.\n    \"\"\"\n    n_samples, n_features = features.shape\n    w = np.zeros(n_features)\n    total_updates = 0\n    \n    while True:\n        updates_in_pass = 0\n        for i in range(n_samples):\n            # Perceptron mistake condition\n            if labels[i] * np.dot(w, features[i]) = 0:\n                # Perceptron update rule\n                w += labels[i] * features[i]\n                total_updates += 1\n                updates_in_pass += 1\n        \n        # Termination condition\n        if updates_in_pass == 0:\n            break\n            \n    return total_updates\n\ndef run_single_case(d, n, rho, seed, m):\n    \"\"\"\n    Performs the full analysis for a single test case.\n\n    Args:\n        d (int): Number of features (dimensions).\n        n (int): Number of samples.\n        rho (float): Correlation coefficient.\n        seed (int): Random seed for reproducibility.\n        m (float): Margin injection constant.\n\n    Returns:\n        list[int, int]: A pair of integers [u_orig, u_ortho].\n    \"\"\"\n    # 1. Set seed for reproducibility\n    rng = np.random.default_rng(seed)\n    \n    # 2. Generate synthetic data\n    # Create the equicorrelation covariance matrix\n    cov_matrix = (1 - rho) * np.eye(d) + rho * np.ones((d, d))\n    \n    # Draw samples from a multivariate normal distribution\n    X_initial = rng.multivariate_normal(mean=np.zeros(d), cov=cov_matrix, size=n)\n    \n    # Draw a ground-truth weight vector\n    w_star = rng.standard_normal(size=d)\n    \n    # Assign labels\n    y = np.sign(X_initial @ w_star)\n    # Ensure labels are in {-1, +1}\n    y[y == 0] = 1\n    \n    # 3. Perform margin injection\n    u = w_star / np.linalg.norm(w_star)\n    # Use broadcasting to add the margin term to each row of X\n    X_orig = X_initial + m * y[:, np.newaxis] * u\n    \n    # 4. Run perceptron on original features\n    u_orig = run_perceptron(X_orig, y)\n    \n    # 5. Decorrelate features using Gram-Schmidt (QR decomposition)\n    # 'reduced' mode is essential for non-square matrices\n    Q, R = np.linalg.qr(X_orig, mode='reduced')\n    Z_ortho = Q\n    \n    # 6. Run perceptron on decorrelated features\n    u_ortho = run_perceptron(Z_ortho, y)\n    \n    return [u_orig, u_ortho]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    # Margin injection constant common to all tests\n    m = 1.0\n\n    # Test suite: (d, n, rho, seed)\n    test_cases = [\n        (2, 100, 0.0, 42),\n        (2, 100, 0.95, 43),\n        (2, 100, -0.95, 44),\n        (3, 120, 0.8, 45),\n    ]\n\n    results = []\n    for d, n, rho, seed in test_cases:\n        result = run_single_case(d, n, rho, seed, m)\n        results.append(result)\n\n    # Format the output string as specified, e.g., [[u1,v1],[u2,v2],...]\n    result_str_parts = [f\"[{u},{v}]\" for u, v in results]\n    final_output = f\"[{','.join(result_str_parts)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3099389"}, {"introduction": "在探讨了数据属性如何影响学习之后，我们现在转向改进学习算法本身。标准的感知机更新可能收敛缓慢，并且容易在决策边界附近振荡，尤其是在处理间隔（margin）较小的数据集时。本练习将介绍动量（momentum）法，这是一种加速梯度类优化的经典技术 [@problem_id:3099401]。通过引入一个累积历史更新的“速度”项，动量可以帮助算法在一致的方向上更快速地移动，从而在复杂的优化“地形”中穿行。你将亲手为感知机实现动量，并分析它对收敛速度的影响以及可能带来的“过冲”现象，从而深入理解现代优化器的基石之一。", "problem": "考虑欧几里得空间中的二元分类问题，其中输入是向量 $x \\in \\mathbb{R}^d$，标签是 $y \\in \\{-1,+1\\}$。一个带偏置的线性分类器使用增广权重向量 $w \\in \\mathbb{R}^{d+1}$ 和增广输入 $\\tilde{x} \\in \\mathbb{R}^{d+1}$（定义为 $\\tilde{x} = [x; 1]$），并预测 $f(\\tilde{x}) = \\mathrm{sign}(w^\\top \\tilde{x})$。感知机更新是一种错误驱动的规则，即当数据点被错误分类时修改 $w$。在此任务中，您将在边缘可分数据集上实现一个带动量的感知机（一种重球式更新），以探究其收敛速度和过冲现象。\n\n本任务的基础知识：\n- 线性可分性：如果存在一个 $w^\\star$ 使得对于所有 $i$ 都有 $y_i (w^{\\star\\top} \\tilde{x}_i)  0$，则数据集 $\\{(x_i,y_i)\\}_{i=1}^n$ 是线性可分的。当 $y_i (w^\\top \\tilde{x}_i) \\le 0$ 时，感知机学习准则会更新 $w$。\n- 错误驱动更新：对于一个被错误分类的样本 $(x_t,y_t)$，经典感知机执行 $w_{t+1} = w_t + \\eta y_t \\tilde{x}_t$，其中学习率 $\\eta  0$。\n- 动量（重球法）：维持一个速度向量 $v_t$，当出现错误分类时，更新规则为 $v_{t+1} = \\beta v_t + \\eta y_t \\tilde{x}_t$，其中动量系数 $\\beta \\in [0,1)$；否则更新规则为 $v_{t+1} = \\beta v_t$。权重更新为 $w_{t+1} = w_t + v_{t+1}$。\n\n您的程序必须：\n1. 实现一个单遍、循环、错误驱动的带动量感知机。在第 $t$ 次迭代时，令 $i = t \\bmod n$ 为下一个数据点 $(x_i,y_i)$ 的索引。计算间隔 $m_t = y_i (w_t^\\top \\tilde{x}_i)$。如果 $m_t \\le 0$，执行动量更新 $v_{t+1} = \\beta v_t + \\eta y_i \\tilde{x}_i$，将错误计数器加 1，并设置 $w_{t+1} = w_t + v_{t+1}$。如果 $m_t  0$，执行 $v_{t+1} = \\beta v_t$ 和 $w_{t+1} = w_t + v_{t+1}$。初始化 $w_0 = 0$ 和 $v_0 = 0$。使用迭代上限 $T_{\\max}$，以便在未达到收敛时停止。\n2. 收敛准则：一旦对于所有 $j \\in \\{1,\\dots,n\\}$ 都有 $y_j (w^\\top \\tilde{x}_j)  0$，即判定为收敛。\n3. 过冲量化：令 $M(w)$ 为在权重 $w$ 下被错误分类的点的总数，即 $M(w) = \\sum_{i=1}^n \\mathbf{1}\\{y_i (w^\\top \\tilde{x}_i) \\le 0\\}$。对于每次错误驱动的更新（即 $m_t \\le 0$ 的迭代），在更新前立即计算 $M(w_t)$，并在更新后立即计算 $M(w_{t+1})$。如果 $M(w_{t+1})  M(w_t)$，则计为一个过冲事件。将过冲率定义为总过冲事件数除以错误驱动更新的总次数。如果没有错误驱动的更新，则将过冲率定义为 $0$。\n4. 收敛速度度量：报告直到收敛（或达到迭代上限，如果未收敛）所执行的错误驱动更新的总次数。\n\n测试套件。使用以下固定的数据集和超参数：\n- 数据集 $\\mathcal{D}_1$（在 $\\mathbb{R}^2$ 中边缘可分）：正例点位于 $(1.0, 1.05)$, $(2.0, 2.05)$, $(3.0, 3.05)$，负例点位于 $(1.0, 0.95)$, $(2.0, 1.95)$, $(3.0, 2.95)$。正例标签为 $+1$，负例标签为 $-1$。\n- 数据集 $\\mathcal{D}_2$（间隔极小）：正例点位于 $(0.0, 0.001)$, $(1.0, 1.001)$, $(2.0, 2.001)$，负例点位于 $(0.0, -0.001)$, $(1.0, 0.999)$, $(2.0, 1.999)$，标签分别为 $+1$ 和 $-1$。\n- 数据集 $\\mathcal{D}_3$（不可分边界情况）：正例点位于 $(0.0, 0.0)$, $(1.0, 1.0)$，负例点位于 $(0.0, 0.0)$, $(1.0, 1.0)$，标签分别为 $+1$ 和 $-1$。\n\n构建以下四个测试用例：\n- 测试用例 1：数据集 $\\mathcal{D}_1$，学习率 $\\eta = 0.1$，动量 $\\beta = 0.0$，迭代上限 $T_{\\max} = 5000$。\n- 测试用例 2：数据集 $\\mathcal{D}_1$，学习率 $\\eta = 0.1$，动量 $\\beta = 0.9$，迭代上限 $T_{\\max} = 5000$。\n- 测试用例 3：数据集 $\\mathcal{D}_2$，学习率 $\\eta = 0.05$，动量 $\\beta = 0.95$，迭代上限 $T_{\\max} = 8000$。\n- 测试用例 4：数据集 $\\mathcal{D}_3$，学习率 $\\eta = 0.1$，动量 $\\beta = 0.9$，迭代上限 $T_{\\max} = 2000$。\n\n每个测试用例的必需输出，按顺序排列：\n- 直到收敛（如果未收敛则为达到迭代上限）为止的错误驱动更新的整数次数。\n- 过冲率，以浮点数形式表示，四舍五入到 $6$ 位小数。\n- 一个布尔值，指示是否已达到收敛。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含四个测试用例的汇总结果，格式为逗号分隔的列表，并用方括号括起来。每个元素是针对一个测试用例的列表 $[\\text{steps}, \\text{overshoot\\_ratio}, \\text{converged}]$。例如，形式为 $[[s_1, r_1, c_1],[s_2, r_2, c_2],[s_3, r_3, c_3],[s_4, r_4, c_4]]$ 的输出，其中过冲率四舍五入到 $6$ 位小数。", "solution": "我们从增广形式的感知机分类模型开始。对于一个输入 $x \\in \\mathbb{R}^d$，我们附加一个恒定的偏置坐标以获得 $\\tilde{x} = [x; 1] \\in \\mathbb{R}^{d+1}$。由 $w \\in \\mathbb{R}^{d+1}$ 参数化的线性分类器预测 $f(\\tilde{x}) = \\mathrm{sign}(w^\\top \\tilde{x})$。$(\\tilde{x},y)$ 在权重 $w$ 下的间隔为 $m = y (w^\\top \\tilde{x})$。正确分类对应于 $m  0$。\n\n感知机学习准则是错误驱动的：每当一个点 $(\\tilde{x}_i, y_i)$ 被错误分类或位于决策边界上，即 $y_i (w^\\top \\tilde{x}_i) \\le 0$ 时，参数会朝着 $y_i \\tilde{x}_i$ 的方向更新。经典更新规则是 $w_{t+1} = w_t + \\eta y_t \\tilde{x}_t$，其中学习率为 $\\eta  0$。为了引入动量，我们维持一个速度向量 $v_t \\in \\mathbb{R}^{d+1}$，该向量对过去的更新进行指数平均。重球式更新定义如下：\n$$\nv_{t+1} =\n\\begin{cases}\n\\beta v_t + \\eta y_t \\tilde{x}_t   \\text{如果 } y_t (w_t^\\top \\tilde{x}_t) \\le 0,\\\\\n\\beta v_t   \\text{如果 } y_t (w_t^\\top \\tilde{x}_t) > 0,\n\\end{cases}\n\\qquad\nw_{t+1} = w_t + v_{t+1},\n$$\n其中 $\\beta \\in [0,1)$ 是动量系数。我们初始化 $w_0 = 0$ 和 $v_0 = 0$。迭代确定性地循环遍历数据集：在第 $t$ 次迭代时，索引为 $i = t \\bmod n$，其中数据集包含 $n$ 个点。这是一种与错误驱动逻辑相结合的确定性循环方案，用于测试收敛行为。\n\n当当前参数 $w$ 正确分类所有训练点时，即对于所有 $j \\in \\{1,\\dots,n\\}$ 都有 $y_j (w^\\top \\tilde{x}_j)  0$ 时，检测到收敛。我们量化两个方面：\n1. 收敛速度：直到收敛所进行的错误驱动更新的总次数。形式上，计算其中 $y_t (w_t^\\top \\tilde{x}_t) \\le 0$ 且更新使用了 $\\eta y_t \\tilde{x}_t$ 的迭代次数；将此计数表示为整数 $S$。\n2. 过冲：动量可能导致更新立即恶化分类性能，特别是在间隔较小的边缘可分数据集上。我们将错分计数定义为 $M(w) = \\sum_{i=1}^n \\mathbf{1}\\{y_i (w^\\top \\tilde{x}_i) \\le 0\\}$。在每次错误驱动的更新中，更新前计算 $M(w_t)$，更新后计算 $M(w_{t+1})$。如果 $M(w_{t+1})  M(w_t)$，则计为一个过冲事件。过冲率是过冲事件数除以 $S$，如果 $S = 0$，则定义为 $0$。\n\n算法流程如下：\n- 初始化 $w_0 = 0$, $v_0 = 0$，错误计数 $S = 0$，过冲计数 $O = 0$。\n- 对于 $t = 0,1,2,\\dots$ 直到达到迭代上限 $T_{\\max}$：\n  - 设置 $i = t \\bmod n$ 并计算 $m_t = y_i (w_t^\\top \\tilde{x}_i)$。\n  - 计算当前的错分计数 $M(w_t)$。\n  - 如果 $m_t \\le 0$，更新 $v_{t+1} = \\beta v_t + \\eta y_i \\tilde{x}_i$，然后 $w_{t+1} = w_t + v_{t+1}$，并增加 $S$。计算 $M(w_{t+1})$；如果 $M(w_{t+1})  M(w_t)$，则增加 $O$。\n  - 如果 $m_t  0$，更新 $v_{t+1} = \\beta v_t$ 和 $w_{t+1} = w_t + v_{t+1}$。\n  - 更新后，检查收敛性：如果 $M(w_{t+1}) = 0$，则停止。\n- 输出为 $S$、过冲率 $O/S$（四舍五入到 $6$ 位小数，如果 $S=0$ 则为 $0$），以及一个指示是否收敛的布尔值。\n\n为何这些定义是合理的：\n- 间隔 $y (w^\\top \\tilde{x})$ 直接编码了分类是否正确，是感知机准则下线性分类的基础量。\n- 错误驱动规则遵循了经过充分检验的感知机算法，这是统计学习中处理线性可分数据的基石。\n- 带有系数 $\\beta$ 的动量通过平均过去的更新来加速沿一致方向的移动，可能减少在边缘可分数据上达到分离超平面所需的更新次数，但由于惯性可能导致过冲，暂时增加 $M(w)$。\n\n该测试套件旨在探索：\n- 一个典型的边缘可分数据集 $\\mathcal{D}_1$，其类别间偏移很小，用于比较无动量（$\\beta = 0$）和强动量（$\\beta = 0.9$）的情况。\n- 一个间隔极小的数据集 $\\mathcal{D}_2$，配合强动量（$\\beta = 0.95$），以突显过冲趋势。\n- 一个不可分数据集 $\\mathcal{D}_3$ 作为边界条件，以验证程序能通过迭代上限终止且不收敛。\n\n最终的程序精确地实现了此算法，为每个测试用例计算所需的指标，将过冲率四舍五入到 $6$ 位小数，并以指定的单行格式打印汇总结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef misclassification_count(w, Xb, y):\n    # y * (Xb @ w) = 0 counts as misclassification\n    margins = y * (Xb @ w)\n    return int(np.sum(margins = 0.0))\n\ndef perceptron_with_momentum(X, y, eta, beta, max_steps):\n    \"\"\"\n    Implements cyclic mistake-driven perceptron with momentum.\n\n    Parameters:\n        X: np.ndarray of shape (n_samples, n_features)\n        y: np.ndarray of shape (n_samples,), labels in {-1, +1}\n        eta: float, learning rate\n        beta: float, momentum coefficient in [0,1)\n        max_steps: int, iteration cap (each iteration visits one example)\n\n    Returns:\n        steps: int, number of mistake-driven updates performed\n        overshoot_ratio: float, overshoot events / steps (rounded to 6 decimals)\n        converged: bool, True if converged before cap\n    \"\"\"\n    n, d = X.shape\n    # Augment with bias term\n    Xb = np.hstack([X, np.ones((n, 1))])\n    w = np.zeros(d + 1, dtype=float)\n    v = np.zeros(d + 1, dtype=float)\n\n    steps = 0  # mistake-driven updates\n    overshoots = 0  # overshoot events only counted on mistake-driven updates\n\n    converged = False\n    for t in range(max_steps):\n        i = t % n\n        margin = y[i] * (np.dot(w, Xb[i]))\n        before_mis = misclassification_count(w, Xb, y)\n\n        if margin = 0.0:\n            # mistake-driven update\n            v = beta * v + eta * y[i] * Xb[i]\n            w_new = w + v\n            after_mis = misclassification_count(w_new, Xb, y)\n            steps += 1\n            if after_mis > before_mis:\n                overshoots += 1\n            w = w_new\n        else:\n            # decay-only update\n            v = beta * v\n            w = w + v\n\n        # check convergence\n        if misclassification_count(w, Xb, y) == 0:\n            converged = True\n            break\n\n    if steps == 0:\n        overshoot_ratio = 0.0\n    else:\n        overshoot_ratio = round(overshoots / steps, 6)\n\n    return steps, overshoot_ratio, converged\n\ndef solve():\n    # Define the datasets as per the problem statement.\n    # Dataset D1: borderline-separable\n    X1 = np.array([\n        [1.0, 1.05], [2.0, 2.05], [3.0, 3.05],  # positives\n        [1.0, 0.95], [2.0, 1.95], [3.0, 2.95]   # negatives\n    ], dtype=float)\n    y1 = np.array([+1, +1, +1, -1, -1, -1], dtype=int)\n\n    # Dataset D2: extremely small margin\n    X2 = np.array([\n        [0.0, 0.001], [1.0, 1.001], [2.0, 2.001],   # positives\n        [0.0, -0.001], [1.0, 0.999], [2.0, 1.999]   # negatives\n    ], dtype=float)\n    y2 = np.array([+1, +1, +1, -1, -1, -1], dtype=int)\n\n    # Dataset D3: non-separable edge case\n    X3 = np.array([\n        [0.0, 0.0], [1.0, 1.0],   # positives\n        [0.0, 0.0], [1.0, 1.0]    # negatives (duplicate locations)\n    ], dtype=float)\n    y3 = np.array([+1, +1, -1, -1], dtype=int)\n\n    # Test cases: (X, y, eta, beta, max_steps)\n    test_cases = [\n        (X1, y1, 0.1, 0.0, 5000),   # Case 1: baseline no momentum\n        (X1, y1, 0.1, 0.9, 5000),   # Case 2: strong momentum on D1\n        (X2, y2, 0.05, 0.95, 8000), # Case 3: tiny margin with strong momentum\n        (X3, y3, 0.1, 0.9, 2000)    # Case 4: non-separable edge case\n    ]\n\n    results = []\n    for X, y, eta, beta, max_steps in test_cases:\n        steps, overshoot_ratio, converged = perceptron_with_momentum(X, y, eta, beta, max_steps)\n        # Ensure overshoot ratio is a float with up to 6 decimals already\n        results.append([steps, overshoot_ratio, converged])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3099401"}]}