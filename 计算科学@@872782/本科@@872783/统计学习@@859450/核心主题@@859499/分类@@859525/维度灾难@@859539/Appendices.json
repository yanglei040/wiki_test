{"hands_on_practices": [{"introduction": "我们对三维空间的直观理解在更高维度上常常会失效。“维度灾难”的一个核心根源在于高维空间的反直觉几何特性。这个练习将通过一个思想实验，带领我们计算并比较二维圆形和百维超球体中，靠近“表面”的区域占总体积的比例，从而揭示高维物体体积的惊人分布规律。[@problem_id:2439725]", "problem": "在用于计算经济学和金融学数值方法的高维状态空间中，考虑以下与体积集中相关的几何比较。\n\n在二维空间中，一个单位半径的圆内切于一个边长为 $2$ 的正方形；在一百维空间中，一个单位半径的欧几里得超球体内切于一个边长为 $2$ 的超立方体。对于每个球体，定义其“外壳”为所有到中心的距离在半径 $1 - \\varepsilon$ 和 $1$ 之间的点的集合，其中 $\\varepsilon = 0.05$。\n\n令 $f_{n}(\\varepsilon)$ 表示 $n$ 维球体体积中位于此外壳内的部分所占的比例。计算比率\n$$\nc \\equiv \\frac{f_{100}(0.05)}{f_{2}(0.05)}.\n$$\n将您的答案表示为单个实数，并四舍五入到四位有效数字。", "solution": "必须首先验证问题陈述的科学性和逻辑完整性。\n\n**第1步：提取已知条件**\n- 在 $n$ 维空间中考虑一个单位半径的欧几里得超球面。\n- 该超球体内切于一个边长为 $2$ 的超立方体。这个信息是一致的，但对于核心计算是辅助性的。\n- 超球体的“外壳”被定义为径向距离 $r$ 满足 $1 - \\varepsilon \\le r \\le 1$ 的点的集合。\n- 外壳厚度参数的具体值为 $\\varepsilon = 0.05$。\n- $f_{n}(\\varepsilon)$ 被定义为 $n$ 维球体体积中位于此外壳内的部分所占的比例。\n- 需要计算的比率为 $c \\equiv \\frac{f_{100}(0.05)}{f_{2}(0.05)}$。\n- 最终答案必须是单个实数，并四舍五入到四位有效数字。\n\n**第2步：使用提取的已知条件进行验证**\n该问题具有科学依据，提法明确且客观。它提出了一个高维几何中的标准问题，这是数学中的一个基本课题，并对计算科学、统计学和金融学等领域有直接影响，尤其关系到被称为“维度灾难”的现象。定义精确，参数已给出，不存在矛盾或歧义。该问题是一个可以形式化的计算，并且不违反任何科学原理。\n\n**第3步：结论与行动**\n问题有效。将提供完整解答。\n\n一个半径为 $R$ 的 $n$ 维球（超球面）的体积由以下公式给出：\n$$\nV_n(R) = C_n R^n\n$$\n其中 $C_n = \\frac{\\pi^{n/2}}{\\Gamma(\\frac{n}{2} + 1)}$ 是一个仅取决于维度 $n$ 的常数。$\\Gamma$ 表示伽马函数。\n\n问题将 $f_n(\\varepsilon)$ 定义为单位半径（$R=1$）的 $n$ 维球体中，包含在厚度为 $\\varepsilon$ 的外壳内的体积所占的比例。单位 $n$ 维球体的总体积是 $V_n(1)$。不属于外壳部分的内部核心的体积，是一个半径为 $1 - \\varepsilon$ 的 $n$ 维球体的体积。这个体积是 $V_n(1 - \\varepsilon)$。\n\n外壳的体积 $V_{\\text{shell}}$ 是总体积与内部核心体积之差：\n$$\nV_{\\text{shell}} = V_n(1) - V_n(1 - \\varepsilon)\n$$\n比例 $f_n(\\varepsilon)$ 是外壳体积与总体积之比：\n$$\nf_n(\\varepsilon) = \\frac{V_{\\text{shell}}}{V_n(1)} = \\frac{V_n(1) - V_n(1 - \\varepsilon)}{V_n(1)}\n$$\n代入体积公式，我们得到：\n$$\nf_n(\\varepsilon) = \\frac{C_n (1)^n - C_n (1 - \\varepsilon)^n}{C_n (1)^n}\n$$\n常数 $C_n$ 在分子和分母中被消去，这极大地简化了表达式：\n$$\nf_n(\\varepsilon) = \\frac{1 - (1 - \\varepsilon)^n}{1} = 1 - (1 - \\varepsilon)^n\n$$\n这个结果表明，外壳中的体积比例与体积常数 $C_n$ 无关，仅取决于维度 $n$ 和相对厚度 $\\varepsilon$。这是高维空间的一个关键特征：体积集中在表面附近。\n\n我们被要求计算在 $n=100$ 和 $n=2$ 的特定情况下，当 $\\varepsilon = 0.05$ 时的比率 $c$。\n\n首先，我们计算二维情况（圆）下的 $f_2(0.05)$：\n$$\nf_2(0.05) = 1 - (1 - 0.05)^2 = 1 - (0.95)^2 = 1 - 0.9025 = 0.0975\n$$\n这表明一个单位圆 $9.75\\%$ 的面积位于其边界 $0.05$ 的范围内。\n\n接下来，我们计算一百维情况（超球面）下的 $f_{100}(0.05)$：\n$$\nf_{100}(0.05) = 1 - (1 - 0.05)^{100} = 1 - (0.95)^{100}\n$$\n现在，我们必须对其进行数值计算。\n$$\n(0.95)^{100} \\approx 0.00592052922\n$$\n因此，\n$$\nf_{100}(0.05) \\approx 1 - 0.00592052922 = 0.99407947078\n$$\n这个惊人的结果表明，一个100维超球面超过 $99.4\\%$ 的体积集中在其半径最外层 $5\\%$ 构成的壳层中。\n\n最后，我们计算所需的比率 $c$：\n$$\nc = \\frac{f_{100}(0.05)}{f_{2}(0.05)} = \\frac{1 - (0.95)^{100}}{1 - (0.95)^2}\n$$\n代入我们计算的数值：\n$$\nc \\approx \\frac{0.99407947078}{0.0975} \\approx 10.19568688\n$$\n问题要求答案四舍五入到四位有效数字。\n该值为 $10.19568688...$。前四位有效数字是 $1$、$0$、$1$、$9$。第五位有效数字是 $5$，因此需要将第四位数字向上取整。\n$$\nc \\approx 10.20\n$$\n这个结果定量地说明了“维度灾难”：随着维度的增加，超球体的绝大部分体积移动到其表面，使得中心区域变得“空旷”。这对于依赖于高维空间采样或离散化的数值方法具有深远的影响。", "answer": "$$\n\\boxed{10.20}\n$$", "id": "2439725"}, {"introduction": "既然高维空间大部分是“空的”，那么依赖于“局部”信息的非参数方法会遇到什么挑战？本练习将探讨这一问题，展示在样本量固定的情况下，为了在局部邻域内捕获足够的数据点来控制方差，我们必须将邻域的“半径”扩展到何种程度。通过分析这种偏差-方差权衡，我们将理解为何一个忽略了部分真实变量的低维简化模型，有时反而能做出更准确的预测。[@problem_id:2439720]", "problem": "您观察到一个来自数据生成过程 (DGP) 的样本，其样本量为 $n=100000$。该过程由 $y=f(x_1,\\ldots,x_{100})$ 定义，其中 $f$ 是一个未知的连续函数，并且关于欧几里得范数是全局利普希茨的，利普希茨常数为 $L>0$。协变量满足 $x_j \\sim \\text{Uniform}[0,1]$，对于所有 $j \\in \\{1,\\ldots,100\\}$ 独立同分布。您感兴趣的是根据 $x$ 对 $y$ 进行样本外预测。\n\n考虑一个非参数局部常数回归规则，对于一个查询点 $x_0$，该规则对所有坐标都位于以 $x_0$ 为中心、边长为 $h$ 的超立方体内的训练点的 $y$ 值进行平均（即，$x$ 的每个坐标都位于 $x_0$ 相应坐标的 $h/2$ 范围内；忽略边界效应）。为了控制方差，您要求邻域内的训练观测值的期望数量至少为 $m=30$。\n\n令 $d$ 表示预测器使用的协变量数量。在完整模型中，$d=100$。在一个仅使用前两个协变量的简化模型中，$d=2$，因此对于某个在二维空间中使用相同局部常数规则的预测器 $g$，$y \\approx g(x_1,x_2)$。\n\n仅使用关于独立均匀变量和 $\\mathbb{R}^d$ 中体积的基本事实，判断哪个陈述最好地解释了为什么简化模型 $y \\approx g(x_1,x_2)$ 可能比在 $d=100$ 维空间中使用相同样本量 $n$ 非参数地学习 $f$ 对预测更有用，尽管真实的数据生成过程依赖于全部100个变量。\n\n选择一个选项。\n\n- A. 在 $d=100$ 的情况下，要在 $n=100000$ 的样本中达到 $m=30$ 的期望邻域大小，需要一个接近1的边长 $h$，因此邻域实际上是全局的，对于一个利普希茨函数 $f$ 会引入巨大的偏差。在 $d=2$ 的情况下，所需的 $h$ 非常小，允许在方差相当的情况下进行真正的局部平均，偏差很低。因此，低维预测器可以有更好的样本外泛化能力。\n\n- B. 因为只要保留的协变量 $x_1,x_2$ 与被省略的协变量相关，省略 $x_3,\\ldots,x_{100}$ 就能消除偏差，所以双变量模型总是更适合预测。\n\n- C. 随着维度的增加，$[0,1]^d$ 中任意两点之间的欧几里得距离都变为零，因此使用许多变量会使所有邻域坍缩，并破坏预测能力。\n\n- D. 高维度会机械地减小估计量的方差，而与样本量 $n$ 无关，因此只有当 $n$ 极小时，使用较少的协变量才有帮助，而这里情况并非如此。", "solution": "必须首先验证问题陈述的科学性和逻辑完整性。\n\n### 步骤1：提取已知条件\n- 样本量：$n=100000$。\n- 数据生成过程 (DGP)：$y=f(x_1,\\ldots,x_{100})$，其中 $f$ 是一个未知函数。\n- $f$ 的性质：连续且关于欧几里得范数是全局利普希茨的，利普希茨常数为 $L>0$。\n- 协变量：$x_j \\sim \\text{Uniform}[0,1]$，对于所有 $j \\in \\{1,\\ldots,100\\}$ 独立同分布。因此，向量 $x$ 在单位超立方体 $[0,1]^{100}$ 上均匀分布。\n- 估计量：一个局部常数回归规则。对于一个查询点 $x_0$，预测值是邻域内训练点 $x$ 的 $y$ 值的平均值，该邻域由以 $x_0$ 为中心、边长为 $h$ 的超立方体定义。\n- 边界效应将被忽略。\n- 方差控制约束：邻域内的训练观测值的期望数量必须至少为 $m=30$。\n- 完整模型维度：$d=100$。\n- 简化模型维度：$d=2$，仅使用协变量 $x_1, x_2$。\n- 目标：解释为什么维度为 $d=2$ 的模型可能比维度为 $d=100$ 的模型对预测更有用。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题具有科学依据。它描述了一个用于说明非参数回归背景下“维度灾难”的典型场景，这是统计学和机器学习中的一个基石概念。问题提法恰当；它提供了足够的信息（$n, m$、协变量的分布、函数 $f$ 的类别以及估计量的结构）以对所涉及的权衡进行形式化分析。语言客观而精确。问题是自洽的，没有内部矛盾或事实错误。这是统计理论中的一个有效练习。\n\n### 步骤3：结论与行动\n问题陈述是有效的。将推导出一个完整的解决方案。\n\n这个问题的核心在于理解高维空间的几何特性如何影响非参数估计中的偏差-方差权衡。该估计量是一个局部平均值。其性能取决于局部邻域的大小，由超立方体边长 $h$ 表征。\n\n数据点从单位超立方体 $[0,1]^d$ 上的均匀分布中抽取。对于一个查询点 $x_0$，其邻域是一个边长为 $h$ 的超立方体。这个邻域的体积是 $V = h^d$。由于数据是均匀分布的，并且我们忽略边界效应，单个数据点落入这个邻域的概率是 $p = V = h^d$。\n\n对于一个大小为 $n$ 的给定样本，邻域中的点数 $K$ 服从二项分布 $B(n, p)$。点的期望数量是 $E[K] = np = nh^d$。问题施加了约束，即为了控制估计量的方差，这个期望值必须至少为 $m=30$。我们将目标设为 $E[K]=m$ 来满足这个条件。\n$$nh^d = m$$\n我们可以求解所需的边长 $h$：\n$$h = \\left(\\frac{m}{n}\\right)^{1/d}$$\n给定 $n = 100000$ 和 $m = 30$，我们有：\n$$\\frac{m}{n} = \\frac{30}{100000} = 3 \\times 10^{-4}$$\n所以，边长 $h$ 是维度 $d$ 的函数：\n$$h(d) = (3 \\times 10^{-4})^{1/d}$$\n\n现在，我们分析问题中提出的两种情况。\n\n情况1：完整模型 ($d=100$)\n对于使用全部100个协变量的模型，所需的边长 $h$ 是：\n$$h(100) = (3 \\times 10^{-4})^{1/100}$$\n为了计算这个值，我们使用对数：\n$$\\ln(h(100)) = \\frac{1}{100} \\ln(3 \\times 10^{-4}) \\approx \\frac{1}{100} (\\ln(3) - 4\\ln(10)) \\approx \\frac{1}{100}(1.0986 - 4 \\times 2.3026) = \\frac{1}{100}(1.0986 - 9.2104) = -0.0811$$\n$$h(100) = e^{-0.0811} \\approx 0.922$$\n对于100个维度中的每一个，边长 $h \\approx 0.92$ 意味着“局部”邻域跨越了每个变量整个范围的大约92%。这绝不是一个“局部”区域；它几乎是全局的。在任何点 $x_0$ 的预测都是对可能离 $x_0$ 很远的点进行平均。由于真实函数 $f$ 是利普希茨的，局部常数估计量的偏差由一个与邻域大小成正比的项所界定。对于一个大的 $h$，邻域中的点 $x_i$ 的函数值 $f(x_i)$ 可能与 $f(x_0)$ 非常不同，导致巨大的平均偏差。\n\n情况2：简化模型 ($d=2$)\n对于仅使用2个协变量的模型，所需的边长 $h$ 是：\n$$h(2) = (3 \\times 10^{-4})^{1/2} = \\sqrt{3 \\times 10^{-4}} = \\sqrt{3} \\times 10^{-2} \\approx 1.732 \\times 10^{-2} = 0.01732$$\n边长 $h \\approx 0.017$ 相对于单位区间 $[0,1]$ 来说很小。该邻域是真正的局部邻域。在这样一个小的区域上进行平均可以确保所有用于预测的点 $x_i$ 都接近查询点 $x_0$。因为 $f$ 是连续的，所以在这个小邻域中的所有点都有 $f(x_i) \\approx f(x_0)$，从而导致很小的平均偏差。\n\n根据构造，两种估计量都被设计为具有相当的方差，因为它们都使用期望样本量为 $m=30$ 的局部平均。它们在样本外预测误差（均方误差，MSE），即偏差平方和方差之和中的主要差异将来自于偏差项。\n\n$d=100$ 的模型有巨大的偏差。$d=2$ 的模型偏差很小。因此，尽管 $d=2$ 的模型是设定不当的（它忽略了变量 $x_3, \\ldots, x_{100}$），但其大大降低的估计偏差可以导致总MSE远小于 $d=100$ 的模型，后者灾难性地遭受维度灾难的影响。更简单的模型可能提供更优的样本外预测。\n\n现在，我们评估每个选项。\n\n- **A. 在 $d=100$ 的情况下，要在 $n=100000$ 的样本中达到 $m=30$ 的期望邻域大小，需要一个接近1的边长 $h$，因此邻域实际上是全局的，对于一个利普希茨函数 $f$ 会引入巨大的偏差。在 $d=2$ 的情况下，所需的 $h$ 非常小，允许在方差相当的情况下进行真正的局部平均，偏差很低。因此，低维预测器可以有更好的样本外泛化能力。**\n这个陈述是我们推导的完美总结。它正确地指出了当 $d=100$ 时 $h$ 很大，而当 $d=2$ 时 $h$ 很小。它正确地将大的 $h$ 与大的偏差联系起来，将小的 $h$ 与小的偏差联系起来。它注意到方差是可比的。低维预测器可以更好地泛化这一结论是这个分析的正确结果。**正确**。\n\n- **B. 因为只要保留的协变量 $x_1,x_2$ 与被省略的协变量相关，省略 $x_3,\\ldots,x_{100}$ 就能消除偏差，所以双变量模型总是更适合预测。**\n这个陈述根本上是有缺陷的。从模型中省略相关变量（$x_3, \\ldots, x_{100}$ 是真实数据生成过程的一部分）是设定偏差的一个来源。它并不能消除偏差。这个说法与事实恰恰相反。这个陈述显示了对模型设定的深刻误解。**不正确**。\n\n- **C. 随着维度的增加，$[0,1]^d$ 中任意两点之间的欧几里得距离都变为零，因此使用许多变量会使所有邻域坍缩，并破坏预测能力。**\n这个陈述事实上是不正确的。从 $[0,1]^d$ 中均匀抽取的两个随机点 $X, Y$ 之间的期望欧几里得距离平方是 $E[\\|X-Y\\|^2] = d \\cdot E[(X_1-Y_1)^2] = d/6$。因此，期望距离随 $\\sqrt{d}$ 增长。距离不会收敛到零；它们会集中在更大的值上。前提是错误的。**不正确**。\n\n- **D. 高维度会机械地减小估计量的方差，而与样本量 $n$ 无关，因此只有当 $n$ 极小时，使用较少的协变量才有帮助，而这里情况并非如此。**\n这个陈述是不正确的。对于固定的样本量 $n$ 和固定的邻域体积（即固定的 $h$），增加维度 $d$ 会导致数据更稀疏。任何固定邻域中的点数减少，这会*增加*估计量的方差。维度灾难迫使我们在大偏差（增加 $h$）或大方差（保持 $h$ 小）之间做出选择。高维度机械地减小方差的说法是错误的。**不正确**。", "answer": "$$\\boxed{A}$$", "id": "2439720"}, {"introduction": "维度灾难不仅使数据变得稀疏，还会影响我们衡量数据点之间“距离”的方式。本练习将通过一个分类问题来说明，当数据中包含与分类任务无关但方差很大的“噪声”特征时，它们如何主导欧几里得距离的计算，从而“淹没”有用特征的信号。通过对比原始特征和标准化特征下的分类效果，本练习揭示了特征缩放在处理高维数据时的极端重要性。[@problem_id:3181691]", "problem": "考虑一个二元分类问题，其中有 $2$ 个类别 $Y \\in \\{-1,+1\\}$，类别先验概率相等，每个类别有 $n$ 个训练样本。特征位于 $\\mathbb{R}^d$ 空间，且坐标之间相互独立。其中有 $s$ 个信息坐标和 $d-s$ 个无关坐标。对于每个信息坐标 $j \\le s$，类别条件分布为 $X_j \\mid Y=+1 \\sim \\mathcal{N}(\\delta,1)$ 和 $X_j \\mid Y=-1 \\sim \\mathcal{N}(-\\delta,1)$，其中 $\\delta>0$ 是一个固定值。对于每个无关坐标 $j > s$，没有类别信号：对于两个类别，$X_j \\mid Y \\sim \\mathcal{N}(0,\\tau^2)$，其中 $\\tau^2 \\gg 1$。训练类别的质心是每个类别在各个坐标上的样本均值。测试点通过最近质心规则进行分类，使用的距离可以是原始欧几里得距离，也可以是特征按真实方差进行逐个标准化（即，将每个坐标 $j$ 除以其标准差 $\\sigma_j$，其中当 $j\\le s$ 时 $\\sigma_j^2=1$，当 $j>s$ 时 $\\sigma_j^2=\\tau^2$）后的欧几里得距离。\n\n设 $\\Delta_{\\mathrm{raw}}$ 表示对于一个来自 $+1$ 类的测试点，其到两个样本质心的平方原始距离之差（到 $+1$ 质心的距离减去到 $-1$ 质心的距离），并设 $\\Delta_{\\mathrm{std}}$ 表示在计算欧几里得距离之前特征按真实方差标准化后的类似差值。如果该差值为负，则判定为 $+1$ 类。\n\n仅使用基本定义（欧几里得距离、正态分布的性质、独立性以及全方差定律），推断这些决策统计量的均值和方差如何随 $d$, $s$, $n$, $\\delta$ 和 $\\tau$ 变化，并回答以下问题。哪些陈述是正确的？\n\nA. 在使用原始特征的情况下，无关坐标对 $\\Delta_{\\mathrm{raw}}$ 的期望条件方差贡献了一个量级为 $8(d-s)\\tau^4/n$ 的项。因此，如果 $(d-s)\\tau^4/n \\gg s^2 \\delta^4$，则错分概率接近 $1/2$。\n\nB. 按真实方差标准化后，无关坐标对 $\\Delta_{\\mathrm{std}}$ 的期望条件方差的贡献量级为 $8(d-s)/n$，该值不依赖于 $\\tau$，从而防止了少数大方差坐标主导决策。\n\nC. 如果 $n \\to \\infty$，使得样本质心等于真实均值，那么在原始欧几里得距离下，类别均值差为零的无关坐标不会影响最近质心决策边界。\n\nD. 标准化将信息坐标上的平均决策裕度（margin）减小了 $1/\\tau^2$ 的因子，因此随着 $d$ 的增加，通常会损害性能。", "solution": "用户希望我批判性地分析一个关于维度灾难的统计学习问题。我必须首先验证问题陈述的有效性，如果有效，则继续对每个选项进行完整的推导和评估。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n-   **分类任务**：二元分类，类别 $Y \\in \\{-1, +1\\}$。\n-   **先验概率**：类别先验概率相等，$P(Y=+1) = P(Y=-1) = 1/2$。\n-   **训练数据**：每个类别 $n$ 个样本。\n-   **特征空间**：$\\mathbb{R}^d$，坐标独立。\n-   **特征类型**：$s$ 个信息坐标 ($j \\in \\{1, \\dots, s\\}$) 和 $d-s$ 个无关坐标 ($j \\in \\{s+1, \\dots, d\\}$)。\n-   **分布（信息坐标, $j \\le s$）**：\n    -   $X_j \\mid Y=+1 \\sim \\mathcal{N}(\\delta, 1)$，其中 $\\delta > 0$。\n    -   $X_j \\mid Y=-1 \\sim \\mathcal{N}(-\\delta, 1)$。\n-   **分布（无关坐标, $j > s$）**：\n    -   $X_j \\mid Y \\sim \\mathcal{N}(0, \\tau^2)$，其中 $\\tau^2 \\gg 1$。\n-   **分类器**：基于样本均值（质心）的最近质心规则。设 $\\hat{\\mu}_+$ 和 $\\hat{\\mu}_-$ 分别为 $+1$ 类和 $-1$ 类的样本均值向量。\n-   **决策统计量**：\n    -   $\\Delta_{\\mathrm{raw}} = \\|x_{\\text{test}} - \\hat{\\mu}_+\\|^2_2 - \\|x_{\\text{test}} - \\hat{\\mu}_-\\|^2_2$，使用原始欧几里得距离。\n    -   $\\Delta_{\\mathrm{std}} = \\sum_{j=1}^d \\frac{(x_{\\text{test},j} - \\hat{\\mu}_{+,j})^2}{\\sigma_j^2} - \\sum_{j=1}^d \\frac{(x_{\\text{test},j} - \\hat{\\mu}_{-,j})^2}{\\sigma_j^2}$，其中特征按真实方差标准化，定义为当 $j\\le s$ 时 $\\sigma_j^2=1$，当 $j>s$ 时 $\\sigma_j^2=\\tau^2$。\n-   **决策规则**：如果差值统计量（$\\Delta_{\\mathrm{raw}}$ 或 $\\Delta_{\\mathrm{std}}$）为负，则分类为 $+1$。\n-   **测试点**：分析针对一个来自 $Y=+1$ 类的测试点 $x_{\\text{test}}$。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学依据**：该问题是统计学习中一个公认的理论模型，用于阐释维度灾难，特别是高维噪声如何降低分类器性能。它使用了正态分布、样本均值和欧几里得距离等标准统计工具。该设置在科学上和数学上都是合理的。\n-   **适定性**：问题陈述清晰。所有变量和统计量都有定义。所提问题是关于均值和方差的缩放性质，这些都可以从给定的分布中计算出来。可以进行唯一且有意义的分析。\n-   **客观性**：问题以精确的数学语言陈述，没有主观性或歧义。\n-   **清单违规检查**：该问题没有违反任何无效性标准。它是完整的、一致的、可形式化的，并且具有科学相关性。标准化方差 $\\sigma_j^2$ 的定义被明确给出，消除了潜在的歧义。\n\n**步骤3：结论与行动**\n问题陈述是**有效的**。我将继续进行详细的推导和分析。\n\n### 解题推导\n\n设 $x$ 是一个来自 $+1$ 类的测试点。决策统计量，无论是原始的还是标准化的，都具有以下一般形式：\n$$ \\Delta = \\|x' - \\hat{\\mu}'_+\\|^2_2 - \\|x' - \\hat{\\mu}'_-\\|^2_2 $$\n其中带撇的变量代表原始或标准化的特征。展开平方范数，我们得到：\n$$ \\Delta = (x'^T x' - 2x'^T \\hat{\\mu}'_+ + \\hat{\\mu}'_+^T \\hat{\\mu}'_+) - (x'^T x' - 2x'^T \\hat{\\mu}'_- + \\hat{\\mu}'_-^T \\hat{\\mu}'_-) $$\n$$ \\Delta = 2x'^T(\\hat{\\mu}'_- - \\hat{\\mu}'_+) + \\|\\hat{\\mu}'_+\\|^2_2 - \\|\\hat{\\mu}'_-\\|^2_2 $$\n这可以通过引入分量差 $\\hat{\\delta}'_j = \\hat{\\mu}'_{+,j} - \\hat{\\mu}'_{-,j}$ 和中点 $\\hat{m}'_j = (\\hat{\\mu}'_{+,j} + \\hat{\\mu}'_{-,j})/2$ 来简化：\n$$ \\Delta = \\sum_{j=1}^d \\left( (x'_j - \\hat{\\mu}'_{+,j})^2 - (x'_j - \\hat{\\mu}'_{-,j})^2 \\right) = \\sum_{j=1}^d \\left( -2x'_j\\hat{\\delta}'_j + (\\hat{\\mu}'_{+,j})^2 - (\\hat{\\mu}'_{-,j})^2 \\right) $$\n$$ \\Delta = -2 \\sum_{j=1}^d \\hat{\\delta}'_j (x'_j - \\hat{m}'_j) $$\n我们关心 $\\Delta$ 的均值和方差。分析将以训练数据为条件进行（训练数据决定了 $\\hat{\\mu}_+$ 和 $\\hat{\\mu}_-$），然后对训练数据的分布取期望。令 $T$ 表示训练数据集。\n\n**样本均值的性质**\n样本均值 $\\hat{\\mu}_{\\pm,j} = \\frac{1}{n}\\sum_{i=1}^n x_{i,j}^{(\\pm)}$ 是随机变量。它们的性质如下：\n-   对于信息坐标 ($j \\le s$)：\n    -   $\\hat{\\mu}_{+,j} \\sim \\mathcal{N}(\\delta, 1/n)$\n    -   $\\hat{\\mu}_{-,j} \\sim \\mathcal{N}(-\\delta, 1/n)$\n-   对于无关坐标 ($j > s$)：\n    -   $\\hat{\\mu}_{+,j} \\sim \\mathcal{N}(0, \\tau^2/n)$\n    -   $\\hat{\\mu}_{-,j} \\sim \\mathcal{N}(0, \\tau^2/n)$\n设 $\\hat{\\delta}_j = \\hat{\\mu}_{+,j} - \\hat{\\mu}_{-,j}$。由于每个类别的训练集是独立的：\n-   对于 $j \\le s$：$E[\\hat{\\delta}_j] = \\delta - (-\\delta) = 2\\delta$。$\\text{Var}(\\hat{\\delta}_j) = 1/n + 1/n = 2/n$。所以 $\\hat{\\delta}_j \\sim \\mathcal{N}(2\\delta, 2/n)$。\n-   对于 $j > s$：$E[\\hat{\\delta}_j] = 0 - 0 = 0$。$\\text{Var}(\\hat{\\delta}_j) = \\tau^2/n + \\tau^2/n = 2\\tau^2/n$。所以 $\\hat{\\delta}_j \\sim \\mathcal{N}(0, 2\\tau^2/n)$。\n\n**对 $\\Delta_{\\mathrm{raw}}$ 的分析**\n\n对于原始特征，我们使用给定的变量。一个测试点 $x$ 来自 $+1$ 类，因此当 $j \\le s$ 时 $x_j \\sim \\mathcal{N}(\\delta, 1)$，当 $j > s$ 时 $x_j \\sim \\mathcal{N}(0, \\tau^2)$。测试点独立于训练数据 $T$。\n\n在给定训练数据 $T$ 的情况下，$\\Delta_{\\mathrm{raw}}$ 的条件方差是：\n$$ \\text{Var}(\\Delta_{\\mathrm{raw}}|T) = \\text{Var}\\left(-2\\sum_{j=1}^d \\hat{\\delta}_j(x_j - \\hat{m}_j) \\bigg| T\\right) = \\sum_{j=1}^d \\text{Var}(-2\\hat{\\delta}_j x_j | T) = \\sum_{j=1}^d 4\\hat{\\delta}_j^2 \\text{Var}(x_j) $$\n期望条件方差是此数量在 $T$ 上的期望：\n$$ E[\\text{Var}(\\Delta_{\\mathrm{raw}}|T)] = \\sum_{j=1}^d 4 E[\\hat{\\delta}_j^2] \\text{Var}(x_j) $$\n我们需要 $E[\\hat{\\delta}_j^2] = \\text{Var}(\\hat{\\delta}_j) + (E[\\hat{\\delta}_j])^2$：\n-   对于 $j \\le s$：$E[\\hat{\\delta}_j^2] = 2/n + (2\\delta)^2 = 2/n + 4\\delta^2$。$\\text{Var}(x_j) = 1$。\n-   对于 $j > s$：$E[\\hat{\\delta}_j^2] = 2\\tau^2/n + 0^2 = 2\\tau^2/n$。$\\text{Var}(x_j) = \\tau^2$。\n\n无关坐标 ($j>s$) 对此期望条件方差的贡献是：\n$$ \\sum_{j=s+1}^d 4 E[\\hat{\\delta}_j^2] \\text{Var}(x_j) = \\sum_{j=s+1}^d 4 \\left(\\frac{2\\tau^2}{n}\\right) (\\tau^2) = (d-s) \\frac{8\\tau^4}{n} $$\n\n决策统计量的总均值为 $E[\\Delta_{\\mathrm{raw}}] = -4s\\delta^2$。这构成了“信号”。当 $\\Delta_{\\mathrm{raw}}$ 的方差（噪声）远大于其均值的平方（信号）时，错分概率会变大。对于大的 $d-s$ 或 $\\tau$，方差中的主导项是无关坐标的贡献。\n\n**A. 在使用原始特征的情况下，无关坐标对 $\\Delta_{\\mathrm{raw}}$ 的期望条件方差贡献了一个量级为 $8(d-s)\\tau^4/n$ 的项。因此，如果 $(d-s)\\tau^4/n \\gg s^2 \\delta^4$，则错分概率接近 $1/2$。**\n陈述的第一部分是我们计算的精确结果。条件 $(d-s)\\tau^4/n \\gg s^2 \\delta^4$ 意味着无关坐标的方差贡献（量级为 $\\mathcal{O}((d-s)\\tau^4/n)$）远大于信号项的平方，即 $(|E[\\Delta_{\\mathrm{raw}}]|)^2 = (4s\\delta^2)^2 = 16s^2\\delta^4$（在常数因子范围内）。当决策统计量的方差远超其均值时，$\\Delta_{\\mathrm{raw}}$ 的分布会变得非常宽，并且相对于其展宽，其中心实际上接近于零。因此，得到错误符号的概率 $P(\\Delta_{\\mathrm{raw}} > 0)$ 将接近 $1/2$，这相当于随机猜测。\n**结论：正确。**\n\n**对 $\\Delta_{\\mathrm{std}}$ 的分析**\n\n对于标准化特征，每个坐标都按其真实标准差 $\\sigma_j$ 进行缩放。\n-   对于 $j \\le s$：$\\sigma_j^2=1$，所以没有变化。\n-   对于 $j > s$：$\\sigma_j^2=\\tau^2$。缩放后的变量是 $z_j=x_j/\\tau$，$\\hat{\\nu}_{\\pm,j}=\\hat{\\mu}_{\\pm,j}/\\tau$。\n缩放后的无关坐标 ($j>s$) 的分布变为：\n-   测试点：$x_j \\sim \\mathcal{N}(0, \\tau^2) \\implies z_j \\sim \\mathcal{N}(0, 1)$。因此，$\\text{Var}(z_j)=1$。\n-   样本均值：$\\hat{\\mu}_{\\pm,j} \\sim \\mathcal{N}(0, \\tau^2/n) \\implies \\hat{\\nu}_{\\pm,j} \\sim \\mathcal{N}(0, 1/n)$。\n设 $\\hat{\\delta}^{\\text{std}}_j = \\hat{\\nu}_{+,j} - \\hat{\\nu}_{-,j}$。对于 $j>s$，$\\hat{\\delta}^{\\text{std}}_j \\sim \\mathcal{N}(0, 2/n)$。\n那么 $E[(\\hat{\\delta}^{\\text{std}}_j)^2] = \\text{Var}(\\hat{\\delta}^{\\text{std}}_j) + (E[\\hat{\\delta}^{\\text{std}}_j])^2 = 2/n + 0 = 2/n$。\n\n无关坐标对 $\\Delta_{\\mathrm{std}}$ 的期望条件方差的贡献是：\n$$ \\sum_{j=s+1}^d 4 E[(\\hat{\\delta}^{\\text{std}}_j)^2] \\text{Var}(z_j) = \\sum_{j=s+1}^d 4 \\left(\\frac{2}{n}\\right) (1) = (d-s) \\frac{8}{n} $$\n\n**B. 按真实方差标准化后，无关坐标对 $\\Delta_{\\mathrm{std}}$ 的期望条件方差的贡献量级为 $8(d-s)/n$，该值不依赖于 $\\tau$，从而防止了少数大方差坐标主导决策。**\n我们的计算证实其贡献恰好是 $8(d-s)/n$。这一项与 $\\tau$ 无关。通过除以 $\\tau$，标准化有效地消除了在原始特征情况下看到的爆炸性的 $\\tau^4$ 因子。这防止了具有大方差 $\\tau^2$ 的无关特征压倒信息特征的信号，而这正是标准化在此背景下的全部目的。\n**结论：正确。**\n\n**对 $n \\to \\infty$ 情况的分析**\n\n根据大数定律，当训练样本数 $n \\to \\infty$ 时，样本均值收敛于真实总体均值。\n$$ \\hat{\\mu}_+ \\to \\mu_+ = E[X|Y=+1] \\quad \\text{and} \\quad \\hat{\\mu}_- \\to \\mu_- = E[X|Y=-1] $$\n这些真实均值向量的坐标是：\n-   对于 $j \\le s$：$\\mu_{+,j} = \\delta$, $\\mu_{-,j} = -\\delta$。\n-   对于 $j > s$：$\\mu_{+,j} = 0$, $\\mu_{-,j} = 0$。\n\n最近质心分类器的决策边界是与质心等距的点 $x$ 的集合：\n$$ \\|x - \\mu_+\\|^2 = \\|x - \\mu_-\\|^2 $$\n$$ \\sum_{j=1}^d (x_j - \\mu_{+,j})^2 = \\sum_{j=1}^d (x_j - \\mu_{-,j})^2 $$\n将总和分为信息坐标和无关坐标：\n$$ \\sum_{j=1}^s (x_j - \\mu_{+,j})^2 + \\sum_{j=s+1}^d (x_j - \\mu_{+,j})^2 = \\sum_{j=1}^s (x_j - \\mu_{-,j})^2 + \\sum_{j=s+1}^d (x_j - \\mu_{-,j})^2 $$\n对于无关坐标 ($j>s$)，我们有 $\\mu_{+,j} = \\mu_{-,j} = 0$。总和变为 $\\sum_{j=s+1}^d (x_j - 0)^2 = \\sum_{j=s+1}^d (x_j - 0)^2$，这一项被消掉了。决策边界的方程简化为：\n$$ \\sum_{j=1}^s (x_j - \\delta)^2 = \\sum_{j=1}^s (x_j + \\delta)^2 $$\n$$ \\sum_{j=1}^s (x_j^2 - 2\\delta x_j + \\delta^2) = \\sum_{j=1}^s (x_j^2 + 2\\delta x_j + \\delta^2) $$\n$$ -2\\delta \\sum_{j=1}^s x_j = 2\\delta \\sum_{j=1}^s x_j \\implies 4\\delta \\sum_{j=1}^s x_j = 0 $$\n由于 $\\delta > 0$，决策边界是由 $\\sum_{j=1}^s x_j = 0$ 定义的超平面。\n\n**C. 如果 $n \\to \\infty$，使得样本质心等于真实均值，那么在原始欧几里得距离下，类别均值差为零的无关坐标不会影响最近质心决策边界。**\n决策边界的方程 $\\sum_{j=1}^s x_j = 0$ 仅依赖于信息坐标。对任何点 $x$ 的决策仅取决于 $\\sum_{j=1}^s x_j$ 的值，而不取决于其无关坐标 $x_j$ (对于 $j>s$) 的值。从这个意义上说，无关坐标不影响决策边界或分类结果。\n**结论：正确。**\n\n**对陈述 D 的分析**\n\n让我们计算标准化决策统计量的均值，$E[\\Delta_{\\mathrm{std}}]$。\n$$ E[\\Delta_{\\mathrm{std}}] = E\\left[ -2 \\sum_{j=1}^d \\hat{\\delta}'_j (x'_j - \\hat{m}'_j) \\right] $$\n和之前一样，我们可以先对测试点取期望，然后对训练数据取期望。对于来自 $+1$ 类的测试点：当 $j \\le s$ 时 $E[x'_j]=\\delta$（无缩放），当 $j>s$ 时 $E[z_j]=0$。\n来自信息坐标 ($j \\le s$) 的贡献与原始情况相同，因为 $\\sigma_j^2=1$。对均值的这一贡献是 $-4s\\delta^2$。\n对于一个无关坐标 ($j>s$)，对均值的贡献是 $E[2\\hat{\\delta}^{\\text{std}}_j \\hat{m}^{\\text{std}}_j]$。\n$ \\hat{\\delta}^{\\text{std}}_j \\hat{m}^{\\text{std}}_j = \\frac{\\hat{\\mu}_{+,j}-\\hat{\\mu}_{-,j}}{\\tau} \\frac{\\hat{\\mu}_{+,j}+\\hat{\\mu}_{-,j}}{2\\tau} = \\frac{\\hat{\\mu}_{+,j}^2 - \\hat{\\mu}_{-,j}^2}{2\\tau^2} $。\n$ E[\\hat{\\mu}_{+,j}^2] = \\text{Var}(\\hat{\\mu}_{+,j}) + (E[\\hat{\\mu}_{+,j}])^2 = \\tau^2/n + 0^2 = \\tau^2/n$。同样地 $E[\\hat{\\mu}_{-,j}^2] = \\tau^2/n$。\n因此，$E[\\hat{\\delta}^{\\text{std}}_j \\hat{m}^{\\text{std}}_j] = \\frac{\\tau^2/n - \\tau^2/n}{2\\tau^2} = 0$。\n总均值为 $E[\\Delta_{\\mathrm{std}}] = -4s\\delta^2 + 0 = -4s\\delta^2$。\n\n**D. 标准化将信息坐标上的平均决策裕度（margin）减小了 $1/\\tau^2$ 的因子，因此随着 $d$ 的增加，通常会损害性能。**\n平均决策裕度 $|E[\\Delta]|$，在原始和标准化情况下均为 $|-4s\\delta^2| = 4s\\delta^2$。标准化不影响信息坐标（因为 $\\sigma_j=1$），所以这些坐标对均值的贡献不变。关于裕度减小的陈述是错误的。因子 $1/\\tau^2$ 的应用不正确。此外，标准化显著减少了来自无关坐标的噪声，提高了信噪比，从而*改善*了性能，而不是损害性能。\n**结论：错误。**\n\n### 评估总结\n-   陈述 A：正确。\n-   陈述 B：正确。\n-   陈述 C：正确。\n-   陈述 D：错误。\n\n问题是问哪些陈述是正确的。陈述 A、B 和 C 都是从问题设置中得出的正确推论。", "answer": "$$\\boxed{ABC}$$", "id": "3181691"}]}