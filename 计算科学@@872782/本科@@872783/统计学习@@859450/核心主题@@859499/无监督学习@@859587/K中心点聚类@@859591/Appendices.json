{"hands_on_practices": [{"introduction": "K-medoids聚类的核心是最小化数据点到其中心点的距离之和，而“距离”的定义本身是算法的一个关键选择。本练习 [@problem_id:3135257] 将引导你使用三种不同的距离度量——曼哈顿距离 ($d_1$)、欧几里得距离 ($d_2$) 和余弦距离 ($d_{\\cos}$)——来对同一数据集进行聚类。通过亲手实现并比较结果，你将深刻理解距离度量的选择如何影响聚类结构，并学会量化这种差异，这是在实际应用中做出明智决策的基础。", "problem": "您被赋予的任务是在相同的数据集上，使用三种不同的距离度量来实施和分析 $k$-中心点（k-medoids）聚类，并量化中心点位置对度量选择的敏感性。这三种度量分别是曼哈顿距离 $d_1$、欧几里得距离 $d_2$ 和余弦角距离 $d_{\\cos}$。此任务的基础是度量空间的定义、一个旨在最小化数据点到其指定代表点距离之和的聚类目标的定义，以及将中心点定义为必须是实际数据点的代表点的约束。您的程序在选择中心点时，对于任何平局情况都必须使用确定性的选择规则：每当出现平局时，总是选择最小的索引。索引必须按照数据点给定的顺序从 $0$ 开始分配。\n\n使用的定义：\n- 两个向量 $x \\in \\mathbb{R}^p$ 和 $y \\in \\mathbb{R}^p$ 之间的曼哈顿距离 $d_1$ 是 $d_1(x,y)=\\sum_{i=1}^p |x_i-y_i|$。\n- 两个向量 $x \\in \\mathbb{R}^p$ 和 $y \\in \\mathbb{R}^p$ 之间的欧几里得距离 $d_2$ 是 $d_2(x,y)=\\sqrt{\\sum_{i=1}^p (x_i-y_i)^2}$。\n- 两个向量 $x \\in \\mathbb{R}^p$ 和 $y \\in \\mathbb{R}^p$ 之间的余弦角距离 $d_{\\cos}$ 是 $d_{\\cos}(x,y)=1-\\dfrac{x \\cdot y}{\\|x\\|\\|y\\|}$，其中 $x \\cdot y$ 是点积，$\\|x\\|$ 是欧几里得范数。如果 $\\|x\\|=0$ 或 $\\|y\\|=0$ 但不都为零，则定义 $d_{\\cos}(x,y)=1$；如果两个范数都为零，则定义 $d_{\\cos}(x,y)=0$。\n\n$k$-中心点目标是选择一个包含 $k$ 个索引的集合 $M \\subset \\{0,1,\\dots,n-1\\}$，并将每个数据点分配给在所选度量下最近的中心点，从而最小化总簇内距离。中心点是数据点之一。您必须实现一个确定性过程，该过程从这个目标出发，仅使用经过充分检验的规则和定义，为每个度量和每个数据集找到一组中心点索引。必须通过总是选择最小索引来打破平局，以保证确定性。\n\n在为每个数据集获得三种度量的中心点集合后，使用中心点索引集合之间的 Jaccard 集相异性来量化中心点位置对度量选择的敏感性。给定两个集合 $A$ 和 $B$，Jaccard 相似性是 $J(A,B)=\\dfrac{|A \\cap B|}{|A \\cup B|}$，Jaccard 相异性是 $1-J(A,B)$。对于每个数据集，计算度量对 $(d_1,d_2)$、$(d_1,d_{\\cos})$ 和 $(d_2,d_{\\cos})$ 的三个成对相异性。\n\n测试套件：\n- 数据集 $X_1 \\in \\mathbb{R}^{9 \\times 2}$，$k_1=3$：\n$$\nX_1=\\begin{bmatrix}\n-0.5  0.2 \\\\\n0.3  -0.2 \\\\\n0.1  0.3 \\\\\n5.1  5.2 \\\\\n4.9  5.05 \\\\\n5.3  4.9 \\\\\n-5.2  5.1 \\\\\n-4.8  4.9 \\\\\n-5.1  5.3\n\\end{bmatrix}, \\quad k_1=3.\n$$\n- 数据集 $X_2 \\in \\mathbb{R}^{5 \\times 2}$，$k_2=1$：\n$$\nX_2=\\begin{bmatrix}\n1  0 \\\\\n2  0 \\\\\n3  0 \\\\\n0  10 \\\\\n0  8\n\\end{bmatrix}, \\quad k_2=1.\n$$\n- 数据集 $X_3 \\in \\mathbb{R}^{4 \\times 2}$，$k_3=2$：\n$$\nX_3=\\begin{bmatrix}\n1  0 \\\\\n2  0 \\\\\n3  0 \\\\\n10  0\n\\end{bmatrix}, \\quad k_3=2.\n$$\n\n您的程序必须：\n- 对于每个数据集 $X_i$ 及其 $k_i$，使用一个从目标定义推导出来且与上述平局打破规则一致的确定性 $k$-中心点过程，计算在 $d_1$、$d_2$ 和 $d_{\\cos}$ 下的中心点索引集。\n- 对于每个数据集，按顺序计算度量对 $(d_1,d_2)$、$(d_1,d_{\\cos})$ 和 $(d_2,d_{\\cos})$ 的中心点索引集之间的三个 Jaccard 相异性。\n- 生成一行输出，其中包含一个用方括号括起来的逗号分隔列表的结果，每个结果本身是一个包含三个浮点数的列表，对应于该数据集按指定顺序的三个相异性。例如，外层列表是 $\\big[\\,[\\delta_{12}^{(1)},\\delta_{1c}^{(1)},\\delta_{2c}^{(1)}],\\,[\\delta_{12}^{(2)},\\delta_{1c}^{(2)},\\delta_{2c}^{(2)}],\\,[\\delta_{12}^{(3)},\\delta_{1c}^{(3)},\\delta_{2c}^{(3)}]\\,\\big]$，其中 $\\delta_{ab}^{(i)}$ 是在数据集 $i$ 上使用度量 $a$ 和 $b$ 找到的中心点索引集之间的 Jaccard 相异性。将每个浮点数四舍五入到 $3$ 位小数。", "solution": "用户提供的问题被评估为有效。它在统计学习领域，特别是 k-中心点聚类方面，具有科学依据。该问题定义明确、客观且自成体系，为获得唯一的确定性解提供了所有必要的数据、定义和约束。对于给定的数据集大小，穷举搜索方法在计算上是可行的，并保证能找到由 k-中心点目标函数定义的最优解。\n\n### 基于原则的设计\n\n这个问题的核心是为一个包含 $n$ 个点的给定数据集 $X = \\{x_0, x_1, \\dots, x_{n-1}\\}$ 找到一个最优的 $k$ 个中心点集合，以最小化总成本函数。中心点必须是来自数据集 $X$ 的数据点之一。对于一个选定的包含 $k$ 个中心点索引的集合 $M \\subset \\{0, 1, \\dots, n-1\\}$，其中 $|M|=k$，总簇内距离和定义为：\n\n$$\nC(M) = \\sum_{i=0}^{n-1} \\min_{m \\in M} d(x_i, x_{m})\n$$\n\n这里，$d(x_i, x_m)$ 是数据点 $x_i$ 和中心点数据点 $x_m$ 在指定度量下的距离。任务要求对三种不同的距离度量执行此优化：曼哈顿距离（$d_1$）、欧几里得距离（$d_2$）和余弦距离（$d_{\\cos}$）。\n\n找到最小化 $C(M)$ 的全局最优中心点集 $M^*$ 是一个 NP-难问题。然而，所提供的数据集足够小，允许对所有可能的 $k$ 个中心点的组合进行穷举搜索。此类组合的数量由二项式系数 $\\binom{n}{k}$ 给出。对于给定的数据集：\n- $X_1$：$n=9, k=3 \\implies \\binom{9}{3} = 84$ 种组合。\n- $X_2$：$n=5, k=1 \\implies \\binom{5}{1} = 5$ 种组合。\n- $X_3$：$n=4, k=2 \\implies \\binom{4}{2} = 6$ 种组合。\n\n由于这些数字很小，穷举搜索在计算上是可行的，并保证能找到成本函数 $C(M)$ 的全局最小值，从而满足问题对直接从目标定义推导出的过程的要求。\n\n解决方案按以下步骤进行：\n\n1.  **距离函数**：根据定义实现所需的三种距离度量：\n    -   曼哈顿距离：$d_1(x,y)=\\sum_{i=1}^p |x_i-y_i|$\n    -   欧几里得距离：$d_2(x,y)=\\sqrt{\\sum_{i=1}^p (x_i-y_i)^2}$\n    -   余弦角距离：$d_{\\cos}(x,y)=1-\\frac{x \\cdot y}{\\|x\\|\\|y\\|}$，并按规定对零向量进行特殊处理。\n\n2.  **最优中心点搜索**：对于每个数据集和每个度量：\n    a.  为给定的度量预先计算 $n \\times n$ 距离矩阵，以优化后续的成本计算。\n    b.  从集合 $\\{0, 1, \\dots, n-1\\}$ 中生成所有可能的 $k$ 个索引的组合。\n    c.  对于每种组合（一个候选中心点集 $M$）：\n        i.  通过将 $n$ 个数据点中每个点到 $M$ 中最近中心点的距离相加，来计算总成本 $C(M)$。\n    d.  识别产生最小成本的中心点集 $M^*$。为确保在平局情况下的确定性（即多个集合产生相同的最小成本），我们依赖于标准库函数（如 Python 的 `itertools.combinations`）生成的组合的字典序。选择遇到的第一个达到最小成本的集合。这是通过仅在发现严格更小的成本时才更新最佳集合来实现的。\n\n3.  **敏感性分析**：在确定给定数据集的三种度量（$M_{d_1}$, $M_{d_2}$, $M_{d_{\\cos}}$）的最优中心点索引集后：\n    a.  计算三对集合的 Jaccard 相异性：$(M_{d_1}, M_{d_2})$、$(M_{d_1}, M_{d_{\\cos}})$ 和 $(M_{d_2}, M_{d_{\\cos}})$。\n    b.  两个集合 $A$ 和 $B$ 之间的 Jaccard 相异性由 $1 - J(A,B) = 1 - \\frac{|A \\cap B|}{|A \\cup B|}$ 给出。这量化了因度量变化导致的中心点位置的相异性。\n\n4.  **输出格式化**：根据指定的输出格式，收集每个数据集计算出的相異性，并将其格式化为一个由浮点数列表组成的列表，四舍五入到三位小数。\n\n这种结构化方法通过直接优化目标函数来确保正确性，通过明确定义的平局打破程序来保证确定性，并满足问题陈述的所有要求。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main function to solve the k-medoids problem for the given test suite.\n    \"\"\"\n\n    def d_manhattan(p1, p2):\n        \"\"\"Computes Manhattan distance.\"\"\"\n        return np.sum(np.abs(p1 - p2))\n\n    def d_euclidean(p1, p2):\n        \"\"\"Computes Euclidean distance.\"\"\"\n        return np.linalg.norm(p1 - p2)\n\n    def d_cosine(p1, p2):\n        \"\"\"Computes Cosine angular distance with specified handling for zero vectors.\"\"\"\n        norm_p1 = np.linalg.norm(p1)\n        norm_p2 = np.linalg.norm(p2)\n\n        if norm_p1 == 0 and norm_p2 == 0:\n            return 0.0\n        if norm_p1 == 0 or norm_p2 == 0:\n            return 1.0\n        \n        dot_product = np.dot(p1, p2)\n        cos_sim = dot_product / (norm_p1 * norm_p2)\n        # Clamp to handle potential floating point inaccuracies\n        cos_sim = np.clip(cos_sim, -1.0, 1.0)\n        return 1.0 - cos_sim\n\n    def find_optimal_medoids(data, k, metric_func):\n        \"\"\"\n        Finds the optimal set of k medoids using an exhaustive search.\n        \"\"\"\n        n = data.shape[0]\n        indices = range(n)\n        \n        dist_matrix = np.zeros((n, n))\n        for i in range(n):\n            for j in range(i, n):\n                d = metric_func(data[i], data[j])\n                dist_matrix[i, j] = d\n                dist_matrix[j, i] = d\n\n        min_total_cost = float('inf')\n        best_medoids = None\n\n        for medoid_indices_tuple in combinations(indices, k):\n            current_total_cost = 0.0\n            for i in indices:\n                min_dist_to_medoid = min(dist_matrix[i, m] for m in medoid_indices_tuple)\n                current_total_cost += min_dist_to_medoid\n            \n            if current_total_cost  min_total_cost:\n                min_total_cost = current_total_cost\n                best_medoids = medoid_indices_tuple\n        \n        return set(best_medoids)\n\n    def jaccard_dissimilarity(set1, set2):\n        \"\"\"Computes the Jaccard dissimilarity between two sets.\"\"\"\n        intersection_size = len(set1.intersection(set2))\n        union_size = len(set1.union(set2))\n        if union_size == 0:\n            return 0.0\n        return 1.0 - (intersection_size / union_size)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([\n            [-0.5, 0.2], [0.3, -0.2], [0.1, 0.3],\n            [5.1, 5.2], [4.9, 5.05], [5.3, 4.9],\n            [-5.2, 5.1], [-4.8, 4.9], [-5.1, 5.3]\n        ]), 3),\n        (np.array([\n            [1, 0], [2, 0], [3, 0],\n            [0, 10], [0, 8]\n        ]), 1),\n        (np.array([\n            [1, 0], [2, 0], [3, 0], [10, 0]\n        ]), 2)\n    ]\n\n    metrics = {\n        'd1': d_manhattan,\n        'd2': d_euclidean,\n        'dcos': d_cosine\n    }\n    \n    all_results = []\n\n    for data, k in test_cases:\n        medoid_sets = {}\n        for name, func in metrics.items():\n            medoid_sets[name] = find_optimal_medoids(data, k, func)\n        \n        m1 = medoid_sets['d1']\n        m2 = medoid_sets['d2']\n        m_cos = medoid_sets['dcos']\n\n        dis_1_2 = jaccard_dissimilarity(m1, m2)\n        dis_1_cos = jaccard_dissimilarity(m1, m_cos)\n        dis_2_cos = jaccard_dissimilarity(m2, m_cos)\n        \n        dataset_results = [round(dis_1_2, 3), round(dis_1_cos, 3), round(dis_2_cos, 3)]\n        all_results.append(dataset_results)\n    \n    # Format the final output string precisely\n    output_parts = []\n    for res_list in all_results:\n        formatted_floats = [f\"{x:.3f}\" for x in res_list]\n        list_str = f\"[{','.join(formatted_floats)}]\"\n        output_parts.append(list_str)\n        \n    final_output_str = f\"[{','.join(output_parts)}]\"\n    print(final_output_str)\n\nsolve()\n```", "id": "3135257"}, {"introduction": "K-medoids算法的一个关键优势在于其对异常值的稳健性，这与K-means等其他算法形成鲜明对比。本练习 [@problem_id:3135235] 是一个思想实验，旨在揭示这一特性的数学原理。你将通过分析计算，确定一个新加入的远距离数据点在何种条件下会“自立门户”，成为一个独立的聚类中心，从而加深对medoid选择如何自然地隔离异常点的理解。", "problem": "考虑实线上的 $k$-中心点聚类目标，使用欧几里得距离，其中中心点被限制为从数据点中选择。设原始数据集为多重集 $X = \\{-1, 0, 1, 9, 10, 11\\}$，并固定 $k = 2$。一个位于位置 $s \\in \\mathbb{R}$ 的新点 $z$ 被加入，形成 $X' = X \\cup \\{z\\}$。$k$-中心点聚类目标旨在寻找一个势为 $k$ 的子集 $M \\subset X'$，并将 $X'$ 中的每个点分配给 $M$ 中最近的中心点，以最小化总距离和。从 $k$-中心点目标等于所有点到其最近选定中心点的距离之和这个基本定义出发，确定阈值距离 $D^{\\ast}$，使得如果 $r = \\min\\{|s|, |s - 10|\\}  D^{\\ast}$，则全局最优的 $k$-中心点解将使用 $z$ 作为其中一个中心点（从而 $z$ 形成一个单点簇）。将您的最终答案表示为一个精确的数字（无需四舍五入）。", "solution": "用户希望找到一个阈值距离 $D^{\\ast}$，对于添加到数据集 $X$ 的新点 $z$，如果该点与原始簇的距离大于 $D^{\\ast}$，它将成为 $k=2$ 聚类中的两个中心点之一。\n\n首先，让我们建立必要的定义。\n原始数据集为多重集 $X = \\{-1, 0, 1, 9, 10, 11\\}$。\n中心点的数量为 $k=2$。\n一个位于位置 $s \\in \\mathbb{R}$ 的新点 $z$ 被加入，形成新的数据集 $X' = X \\cup \\{z\\}$。\n中心点必须从 $X'$ 中的点中选择。\n目标是找到一个势为 $|M|=k=2$ 的中心点集 $M \\subset X'$，以最小化 $X'$ 中每个点到其在 $M$ 中最近中心点的欧几里得距离的总和。成本函数为 $C(M) = \\sum_{p \\in X'} \\min_{m \\in M} |p-m|$。\n变量 $r$ 定义为 $r = \\min\\{|s|, |s - 10|\\}$。我们寻求一个阈值 $D^{\\ast}$，使得对于任何满足 $r  D^{\\ast}$ 的 $s$，全局最优中心点集 $M_{opt}$ 必须包含 $z$。\n\n这个问题需要比较在两种情况下可实现的最小成本：\n1.  情况1：两个中心点仅从原始集 $X$ 中选择。设此最小成本为 $C_{no-z}$。\n2.  情况2：一个中心点是新点 $z$，另一个从 $X$ 中选择。设此最小成本为 $C_{with-z}$。\n\n$z$ 成为最优解一部分的条件是 $C_{with-z}  C_{no-z}$。我们需要找到关于 $r$ 的阈值 $D^{\\ast}$，以保证此不等式成立。\n\n我们来分析情况1：$z$ 不是中心点。\n中心点集为 $M = \\{m_1, m_2\\}$，其中 $m_1, m_2 \\in X$。成本是：\n$$C(M) = \\sum_{p \\in X'} \\min_{m \\in M} |p-m| = \\left( \\sum_{x \\in X} \\min(|x-m_1|, |x-m_2|) \\right) + \\min(|s-m_1|, |s-m_2|)$$\n数据集 $X$ 由两个不同的簇组成：$X_1 = \\{-1, 0, 1\\}$ 和 $X_2 = \\{9, 10, 11\\}$。直观上，为了最小化 $X$ 中各点的距离之和，两个中心点应该从每个簇中各选一个。对于一条线上的点集，最好的单个中心点是它的中位数。\n对于 $X_1$，中位数是 $0$。距离之和为 $|-1-0| + |0-0| + |1-0| = 2$。\n对于 $X_2$，中位数是 $10$。距离之和为 $|9-10| + |10-10| + |11-10| = 2$。\n我们选择中心点集 $M_A = \\{0, 10\\}$。来自 $X$ 中各点的成本贡献为：\n$$\\sum_{x \\in X} \\min(|x-0|, |x-10|) = \\sum_{x \\in X_1} |x-0| + \\sum_{x \\in X_2} |x-10| = 2 + 2 = 4$$\n从 $X$ 中选择任何其他两个中心点都会导致 $X$ 中各点的成本更高。例如，对于 $M=\\{1,9\\}$，$X$ 上的成本是 $(\\sum_{x \\in X_1} |x-1|) + (\\sum_{x \\in X_2} |x-9|) = (2+1+0) + (0+1+2) = 6$。\n当新点 $z$ 远离 $X$ 时（即对于大的 $r$），项 $\\sum_{x \\in X} \\min(|x-m_1|, |x-m_2|)$ 在为 $X$ 聚类选择中心点时占主导地位。点对 $\\{0,10\\}$ 使该项最小化。\n对于新点 $z$ 和中心点 $\\{0, 10\\}$，其成本分量是 $\\min(|s-0|, |s-10|)$，这正是 $r$ 的定义。\n因此，选择这对中心点的总成本是 $C(M_A) = 4 + r$。\n对于大的 $r$，从 $X$ 中选择其他中心点会导致更高的成本。例如，考虑 $M_B = \\{0, 11\\}$，$X$ 上的成本是 $\\sum_{x \\in X}\\min(|x-0|,|x-11|) = (1+0+1) + (2+1+0) = 5$。对于大的正数 $s$，$z$ 的成本将是 $|s-11| = s-11$。总成本为 $5+s-11 = s-6$。对于 $M_A=\\{0,10\\}$，成本是 $4+|s-10|=4+s-10=s-6$。在这种极限情况下，成本是相等的。对大的负数 $s$ 进行类似分析表明，像 $\\{-1,10\\}$ 这样的点对也产生相同的最小成本 $4+r$。因此，我们可以自信地断言，对于大的 $r$：\n$$C_{no-z} = 4 + r$$\n\n现在，我们来分析情况2：$z$ 是一个中心点。\n中心点集为 $M = \\{m_1, z\\}$，其中 $m_1 \\in X$。成本是：\n$$C(M) = \\sum_{p \\in X'} \\min(|p-m_1|, |p-s|)$$\n由于 $z$ 是一个中心点，它到最近中心点的距离是 $0$。成本简化为对 $X$ 中各点的求和：\n$$C_{with-z} = \\min_{m_1 \\in X} \\left( \\sum_{x \\in X} \\min(|x-m_1|, |x-s|) \\right)$$\n问题要求找到 $r$ 的一个阈值 $D^{\\ast}$。我们考虑 $r$ 很大的情况。一个大的 $r$ 意味着 $s$ 远离区间 $[0, 10]$。\n如果 $s$ 离 $X$ 很远，那么对于 $X$ 中的任何点 $x$ 和任何潜在的中心点 $m_1 \\in X$，距离 $|x-m_1|$ 将显著小于 $|x-s|$。\n形式上，对于任何 $x, m_1 \\in X$，我们有 $|x-m_1| \\leq |11 - (-1)| = 12$。对于足够大的 $|s|$，距离 $|x-s|$ 将大于这个值。例如，如果 $s > 11$， $X$ 中离 $s$ 最近的点是 $11$。条件 $|x-m_1|  |x-s|$ 需要对所有 $x, m_1 \\in X$ 成立。最坏的情况是 $x=11$ 和 $m_1=-1$：我们需要 $|11-(-1)|  |11-s|$，所以 $12  s-11$，这意味着 $s > 23$。如果 $s  -1$，最坏的情况是 $x=-1, m_1=11$：我们需要 $|-1-11|  |-1-s|$，所以 $12  |-1-s| = -s-1$，这意味着 $s  -13$。\n如果对于一个足够大的 $D^{\\ast}$ 有 $r > D^{\\ast}$，那么该条件成立，并且 $X$ 中的每个点 $x$ 都将被分配给中心点 $m_1$。\n成本表达式随后简化为寻找集合 $X$ 的 1-中心点：\n$$C_{with-z} = \\min_{m_1 \\in X} \\sum_{x \\in X} |x-m_1|$$\n我们需要为每个可能的中心点 $m_1 \\in X$ 计算这个和。设 $S(m_1) = \\sum_{x \\in X} |x-m_1|$。\n- $S(-1) = (0) + (1) + (2) + (10) + (11) + (12) = 36$\n- $S(0) = (1) + (0) + (1) + (9) + (10) + (11) = 32$\n- $S(1) = (2) + (1) + (0) + (8) + (9) + (10) = 30$\n- $S(9) = (10) + (9) + (8) + (0) + (1) + (2) = 30$\n- $S(10) = (11) + (10) + (9) + (1) + (0) + (1) = 32$\n- $S(11) = (12) + (11) + (10) + (2) + (1) + (0) = 36$\n最小值为 $30$，当中心点 $m_1$ 选为 $1$ 或 $9$ 时出现。\n因此，对于足够大的 $r$，当 $z$ 是一个中心点时的最小成本是：\n$$C_{with-z} = 30$$\n\n最后，我们确定阈值 $D^{\\ast}$。\n全局最优解使用 $z$ 作为中心点的条件是 $C_{with-z}  C_{no-z}$。\n代入推导出的成本：\n$$30  4 + r$$\n$$26  r$$\n这给出了一个阈值 $D^{\\ast}=26$。对于 $r>26$，选择 $z$ 作为中心点的成本（$30$）严格小于不选择它的成本（$4+r > 4+26 = 30$）。\n用于简化成本函数的逻辑在 $r>26$ 时是有效的。例如，$r>26$ 意味着 $s>36$ 或 $s-16$。这两种情况都满足条件（$s>23$ 或 $s-13$），即 $X$ 中的所有点都比离 $z$ 更近于某个内部中心点 $m_1$。\n\n因此，阈值距离是 $D^{\\ast}=26$。", "answer": "$$\n\\boxed{26}\n$$", "id": "3135235"}, {"introduction": "在将算法从理论转化为代码时，我们常常会遇到“平局”的情况，即多个选项具有相同的成本或距离。本练习 [@problem_id:3135303] 聚焦于K-medoids实现中的一个重要细节：平局决胜规则。你将探索两种不同的确定性策略如何解决在选择最优中心点或分配数据点时可能出现的模糊性，并观察这些看似微小的规则如何影响最终的聚类结果，这对于构建可复现和可靠的机器学习系统至关重要。", "problem": "给定一个预先计算好的相异性矩阵 $D \\in \\mathbb{R}^{n \\times n}$，该矩阵对称、元素非负，且对于所有 $i \\in \\{0,\\dots,n-1\\}$ 都有 $D_{i,i} = 0$。在 k-中心点聚类中，选择一个中心点集合 $M \\subseteq \\{0,\\dots,n-1\\}$（其中 $|M| = k$），以最小化聚类目标函数\n$$\nJ(M) \\equiv \\sum_{i=0}^{n-1} \\min_{m \\in M} D_{i,m}.\n$$\n当 $D$ 包含平局值时，存在两种不同的模糊性来源，必须通过明确的平局打破规则来解决：\n- 分配平局：对于给定的 $M$，如果某个索引 $i$ 存在多个中心点 $m \\in M$ 使得 $D_{i,m}$ 达到相同的最小值，则发生分配平局。分配平局打破规则 $T_a$ 必须指定在这种平局发生时将 $i$ 分配给哪个中心点。\n- 中心点集平局：如果存在多个中心点集合 $M$ 都能最小化 $J(M)$，则发生中心点集平局。中心点集平局打破规则 $T_m$ 必须指定在这些最小化者中返回哪个中心点集合。\n\n设计两种确定性的平局打破策略，每种策略都能解决上述两种类型的平局：\n- 策略 $\\mathcal{A}$：$T_m$ 选择字典序最小的中心点集合（当中心点索引按升序排列时），而 $T_a$ 将平局点分配给索引最小的中心点。\n- 策略 $\\mathcal{B}$：$T_m$ 选择字典序最大的中心点集合（当中心点索引按升序排列时），而 $T_a$ 将平局点分配给索引最大的中心点。\n\n从 k-中心点目标 $J(M)$ 的核心定义和集合 $\\{0,\\dots,n-1\\}$ 上的隶属关系属性出发，实现一个精确求解器，该求解器：\n- 枚举所有大小为 $|M| = k$ 的中心点集合 $M$，并使用给定的 $D$ 计算 $J(M)$。\n- 应用指定策略中的 $T_m$ 从中心点集最小化者中进行选择。\n- 使用指定策略中的 $T_a$ 生成每个索引 $i$ 到 $M$ 中一个中心点的最终分配。\n\n使用以下测试套件，演示平局打破如何影响中心点身份和 $J(M)$ 的稳定性。对于每个测试用例，使用提供的 $D$ 和 $k$，在策略 $\\mathcal{A}$ 和 $\\mathcal{B}$ 下运行求解器，并报告结果。\n\n测试套件：\n- 案例 1（正常路径，有多个最优中心点集）：设 $n = 6, k = 2$，且\n$$\nD_1 = \\begin{pmatrix}\n0  1  1  4  4  4 \\\\\n1  0  1  4  4  4 \\\\\n1  1  0  4  4  4 \\\\\n4  4  4  0  1  1 \\\\\n4  4  4  1  0  1 \\\\\n4  4  4  1  1  0 \\\\\n\\end{pmatrix}.\n$$\n- 案例 2（边界条件，k=1 且所有可能的中心点之间存在对称平局）：设 $n = 4, k = 1$，且\n$$\nD_2 = \\begin{pmatrix}\n0  1  2  1 \\\\\n1  0  1  2 \\\\\n2  1  0  1 \\\\\n1  2  1  0 \\\\\n\\end{pmatrix}.\n$$\n- 案例 3（边缘情况，有重复点和分配平局）：设 $n = 5, k = 2$，且\n$$\nD_3 = \\begin{pmatrix}\n0  0  2  2  3 \\\\\n0  0  2  2  3 \\\\\n2  2  0  0  3 \\\\\n2  2  0  0  3 \\\\\n3  3  3  3  0 \\\\\n\\end{pmatrix}.\n$$\n\n对于每个案例，您的程序必须计算并返回一个列表，其中包含：\n- 策略 $\\mathcal{A}$ 下的中心点索引，以升序列表形式表示。\n- 策略 $\\mathcal{A}$ 下的分配向量，以列表形式表示，其中第 $i$ 个条目是分配给 $i$ 的中心点索引。\n- 策略 $\\mathcal{A}$ 下的目标值 $J(M)$，以整数形式表示。\n- 策略 $\\mathcal{B}$ 下的中心点索引，以升序列表形式表示。\n- 策略 $\\mathcal{B}$ 下的分配向量，以列表形式表示，其中第 $i$ 个条目是分配给 $i$ 的中心点索引。\n- 策略 $\\mathcal{B}$ 下的目标值 $J(M)$，以整数形式表示。\n- 一个布尔值，指示在此案例中两种策略下的 $J(M)$ 是否相同。\n- 一个布尔值，指示在此案例中两种策略下的中心点身份是否相同。\n\n您的程序应生成单行输出，其中包含三个案例的结果，格式为逗号分隔的列表，并用方括号括起来，聚合格式如下：\n$$\n[\\text{case1\\_result},\\text{case2\\_result},\\text{case3\\_result}],\n$$\n其中每个 $\\text{caseX\\_result}$ 本身就是上面描述的列表。不应打印任何额外的文本。", "solution": "在尝试任何解决方案之前，需对问题陈述进行验证。\n\n### 第 1 步：提取已知条件\n\n1.  **目标函数**：需要最小化的 k-中心点聚类目标函数是 $J(M) \\equiv \\sum_{i=0}^{n-1} \\min_{m \\in M} D_{i,m}$，其中 $M$ 是一个包含 $k$ 个中心点索引的集合。\n2.  **相异性矩阵**：提供一个矩阵 $D \\in \\mathbb{R}^{n \\times n}$，该矩阵对称（$D_{i,j} = D_{j,i}$），具有非负项（$D_{i,j} \\ge 0$），且对角线为零（$D_{i,i} = 0$）。\n3.  **平局来源**：\n    -   **分配平局**：对于给定的中心点集 $M$，一个点 $i$ 对 $M$ 中的多个中心点具有相同的最小相异性。\n    -   **中心点集平局**：多个不同的中心点集 $M$ 产生相同的目标函数 $J(M)$ 最小值。\n4.  **平局打破策略**：\n    -   **策略 $\\mathcal{A}$**：\n        -   $T_m$（中心点集）：在所有最小化者中，选择字典序最小的中心点集。\n        -   $T_a$（分配）：将出现平局的点分配给索引最小的中心点。\n    -   **策略 $\\mathcal{B}$**：\n        -   $T_m$（中心点集）：在所有最小化者中，选择字典序最大的中心点集。\n        -   $T_a$（分配）：将出现平局的点分配给索引最大的中心点。\n5.  **任务**：实现一个精确求解器，该求解器枚举所有可能的中心点集，应用指定的平局打破策略，并确定最终的中心点集和分配。\n6.  **测试用例**：\n    -   **案例 1**：$n = 6$, $k = 2$, $D_1 = \\begin{pmatrix} 0  1  1  4  4  4 \\\\ 1  0  1  4  4  4 \\\\ 1  1  0  4  4  4 \\\\ 4  4  4  0  1  1 \\\\ 4  4  4  1  0  1 \\\\ 4  4  4  1  1  0 \\end{pmatrix}$。\n    -   **案例 2**：$n = 4$, $k = 1$, $D_2 = \\begin{pmatrix} 0  1  2  1 \\\\ 1  0  1  2 \\\\ 2  1  0  1 \\\\ 1  2  1  0 \\end{pmatrix}$。\n    -   **案例 3**：$n = 5$, $k = 2$, $D_3 = \\begin{pmatrix} 0  0  2  2  3 \\\\ 0  0  2  2  3 \\\\ 2  2  0  0  3 \\\\ 2  2  0  0  3 \\\\ 3  3  3  3  0 \\end{pmatrix}$。\n7.  **要求输出**：对于每个案例，输出一个包含八个元素的列表：策略 $\\mathcal{A}$ 下的中心点、策略 $\\mathcal{A}$ 下的分配、策略 $\\mathcal{A}$ 下的目标值、策略 $\\mathcal{B}$ 下的中心点、策略 $\\mathcal{B}$ 下的分配、策略 $\\mathcal{B}$ 下的目标值、一个指示目标值是否相等的布尔值，以及一个指示中心点集是否相等的布尔值。最终输出必须是单行，包含这三个案例的结果列表所组成的列表。\n\n### 第 2 步：使用提取的已知条件进行验证\n\n根据验证标准分析问题。\n\n-   **有科学依据**：该问题植根于统计学习中一个成熟的领域，特别是非监督聚类。k-中心点算法及其目标函数 $J(M)$ 是标准概念。相异性矩阵 $D$ 的属性与其数学定义一致。该问题在科学上是合理的。\n-   **适定的**：任务是通过穷举枚举找到最优的中心点集合。搜索空间由大小为 n 的集合中所有 k 元子集组成，是有限的。对于任何给定的中心点集合，目标函数 $J(M)$ 都是唯一定义的。所提供的平局打破规则 $T_m$ 和 $T_a$ 是确定性且无歧义的，确保对于每种策略（$\\mathcal{A}$ 和 $\\mathcal{B}$），都存在单一、唯一的解。因此，该问题是适定的。\n-   **客观的**：该问题使用精确的数学语言和定义进行阐述。所有术语都得到了明确定义，测试用例也用具体的数值数据指定，没有主观解释的余地。\n-   **未检测到缺陷**：该问题没有违反任何基本原则，不是隐喻性的，包含了所有必要信息，对于给定的约束条件（n 很小）在计算上是可行的，并且结构清晰。\n\n### 第 3 步：结论与行动\n\n问题是 **有效的**。将按要求开发和实现一个解决方案。\n\n### 解决方案推导\n\n该解决方案需要一个精确算法，对所有可能的中心点集合进行穷举搜索。指导设计的原则如下。\n\n**1. 候选中心点集的组合枚举**\n所有可能的中心点集的集合是索引集 $\\{0, 1, \\dots, n-1\\}$ 中所有 k 元子集的集合。可以系统地生成这个候选中心点集集合，记为 $\\mathcal{C}_M$。此搜索空间的大小由二项式系数 $\\binom{n}{k} = \\frac{n!}{k!(n-k)!}$ 给出。对于测试套件中的小 n 和 k 值，这种枚举在计算上是可行的。\n\n**2. 目标函数的计算**\n对于每个候选中心点集 $M \\in \\mathcal{C}_M$，必须计算目标函数 $J(M)$。其定义为 $J(M) = \\sum_{i=0}^{n-1} \\min_{m \\in M} D_{i,m}$。此计算涉及对每个数据点 $i$，找到其与 $M$ 中任何已选中心点的最小相异性，然后将这些最小相异性对所有数据点求和。\n\n**3. 最小化与中心点集平局打破 ($T_m$)**\n在为所有 $M \\in \\mathcal{C}_M$ 计算 $J(M)$ 后，确定最小目标值 $J_{\\min} = \\min_{M \\in \\mathcal{C}_M} J(M)$。可能会有多个中心点集达到此最小值。设最优中心点集为 $\\mathcal{M}_{\\text{opt}} = \\{M \\in \\mathcal{C}_M \\mid J(M) = J_{\\min}\\}$。如果 $|\\mathcal{M}_{\\text{opt}}|  1$，则发生中心点集平局。应用平局打破规则 $T_m$ 从 $\\mathcal{M}_{\\text{opt}}$ 中选择单个中心点集：\n-   在策略 $\\mathcal{A}$ 下，选择字典序最小的集合。假设每个集合内的索引已排序，这对应于使用标准元组比较找到 $\\min(\\mathcal{M}_{\\text{opt}})$。\n-   在策略 $\\mathcal{B}$ 下，选择字典序最大的集合，即 $\\max(\\mathcal{M}_{\\text{opt}})$。\n\n令唯一选择的中心点集为 $M_{\\text{final}}$。\n\n**4. 最终分配与分配平局打破 ($T_a$)**\n确定最终中心点集 $M_{\\text{final}}$ 后，将每个数据点 $i \\in \\{0, \\dots, n-1\\}$ 分配给 $M_{\\text{final}}$ 中的一个中心点。点 $i$ 的分配是一个中心点 $m_i^* \\in M_{\\text{final}}$，使得 $D_{i, m_i^*} = \\min_{m \\in M_{\\text{final}}} D_{i,m}$。如果满足此条件的中心点集合 $M_i^{\\text{tie}} = \\{m \\in M_{\\text{final}} \\mid D_{i,m} = \\min_{m' \\in M_{\\text{final}}} D_{i,m'}\\}$ 包含多个元素，则发生分配平局。分配平局打破规则 $T_a$ 解决此问题：\n-   在策略 $\\mathcal{A}$ 下，将点 $i$ 分配给 $M_i^{\\text{tie}}$ 中索引最小的中心点，因此 $m_i^* = \\min(M_i^{\\text{tie}})$。\n-   在策略 $\\mathcal{B}$ 下，将点 $i$ 分配给 $M_i^{\\text{tie}}$ 中索引最大的中心点，因此 $m_i^* = \\max(M_i^{\\text{tie}})$。\n\n此过程产生一个最终的分配向量，其中第 i 个元素是点 i 被分配到的中心点的索引。\n\n该算法通过将此逻辑封装到一个函数中来执行，该函数可针对每个策略和每个测试用例运行。然后按照指定格式汇总和格式化结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import combinations\n\ndef solve_k_medoids_exact(D, k, policy):\n    \"\"\"\n    Implements an exact k-medoids solver with specified tie-breaking policies.\n\n    Args:\n        D (np.ndarray): A precomputed n x n dissimilarity matrix.\n        k (int): The number of medoids.\n        policy (str): The tie-breaking policy, either 'A' or 'B'.\n            - Policy 'A': Lexicographically smallest for medoid-set ties,\n                          smallest index for assignment ties.\n            - Policy 'B': Lexicographically largest for medoid-set ties,\n                          largest index for assignment ties.\n\n    Returns:\n        tuple: A tuple containing:\n            - list: The final medoid indices, sorted.\n            - list: The assignment vector for each point.\n            - int: The objective function value.\n    \"\"\"\n    n = D.shape[0]\n    indices = range(n)\n    \n    # Generate all candidate medoid sets\n    candidate_medoid_sets = list(combinations(indices, k))\n    \n    min_objective_val = float('inf')\n    optimal_medoid_sets = []\n    \n    # Step 1  2: Enumerate and calculate objective function J(M)\n    for medoids_tuple in candidate_medoid_sets:\n        medoids = list(medoids_tuple)\n        \n        # For each point, find the dissimilarity to the nearest medoid\n        dissimilarities = np.min(D[:, medoids], axis=1)\n        objective_val = np.sum(dissimilarities)\n        \n        # Check for a new minimum or a tie\n        if objective_val  min_objective_val:\n            min_objective_val = objective_val\n            optimal_medoid_sets = [medoids_tuple]\n        elif objective_val == min_objective_val:\n            optimal_medoid_sets.append(medoids_tuple)\n\n    # Step 3: Apply medoid-set tie-breaking (Tm)\n    if policy == 'A':\n        final_medoids_tuple = min(optimal_medoid_sets)\n    elif policy == 'B':\n        final_medoids_tuple = max(optimal_medoid_sets)\n    else:\n        raise ValueError(\"Policy must be 'A' or 'B'\")\n        \n    final_medoids = list(final_medoids_tuple)\n\n    # Step 4: Apply assignment tie-breaking (Ta)\n    assignments = np.zeros(n, dtype=int)\n    for i in range(n):\n        # Dissimilarities from point i to each chosen medoid\n        d_to_medoids = D[i, final_medoids]\n        min_dist = np.min(d_to_medoids)\n        \n        # Find all medoids that achieve this minimum distance\n        tying_medoid_indices_in_list = np.where(d_to_medoids == min_dist)[0]\n        tying_medoids = [final_medoids[j] for j in tying_medoid_indices_in_list]\n        \n        if policy == 'A':\n            assignments[i] = min(tying_medoids)\n        else: # Policy 'B'\n            assignments[i] = max(tying_medoids)\n            \n    # The objective value is an integer as per problem statement's Ds\n    return sorted(final_medoids), assignments.tolist(), int(round(min_objective_val))\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results in the required format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"n\": 6, \"k\": 2,\n            \"D\": np.array([\n                [0, 1, 1, 4, 4, 4],\n                [1, 0, 1, 4, 4, 4],\n                [1, 1, 0, 4, 4, 4],\n                [4, 4, 4, 0, 1, 1],\n                [4, 4, 4, 1, 0, 1],\n                [4, 4, 4, 1, 1, 0],\n            ])\n        },\n        {\n            \"n\": 4, \"k\": 1,\n            \"D\": np.array([\n                [0, 1, 2, 1],\n                [1, 0, 1, 2],\n                [2, 1, 0, 1],\n                [1, 2, 1, 0],\n            ])\n        },\n        {\n            \"n\": 5, \"k\": 2,\n            \"D\": np.array([\n                [0, 0, 2, 2, 3],\n                [0, 0, 2, 2, 3],\n                [2, 2, 0, 0, 3],\n                [2, 2, 0, 0, 3],\n                [3, 3, 3, 3, 0],\n            ])\n        }\n    ]\n\n    all_case_results = []\n    for case in test_cases:\n        D_matrix, k_val = case[\"D\"], case[\"k\"]\n        \n        medoids_A, assignments_A, J_A = solve_k_medoids_exact(D_matrix, k_val, 'A')\n        medoids_B, assignments_B, J_B = solve_k_medoids_exact(D_matrix, k_val, 'B')\n        \n        j_equal = (J_A == J_B)\n        medoids_equal = (medoids_A == medoids_B)\n        \n        case_result = [\n            medoids_A,\n            assignments_A,\n            J_A,\n            medoids_B,\n            assignments_B,\n            J_B,\n            j_equal,\n            medoids_equal\n        ]\n        all_case_results.append(case_result)\n\n    # Custom string formatting to match the required output (no spaces in lists)\n    def format_item(item):\n        if isinstance(item, list):\n            return f\"[{','.join(map(str, item))}]\"\n        if isinstance(item, bool):\n            return str(item).lower()\n        return str(item)\n\n    case_strings = []\n    for case_res in all_case_results:\n        item_strings = [format_item(item) for item in case_res]\n        case_strings.append(f\"[{','.join(item_strings)}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```", "id": "3135303"}]}