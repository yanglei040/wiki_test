{"hands_on_practices": [{"introduction": "在探索算法公平性时，我们不仅要关注分类任务，还要考虑回归问题。本练习将引导我们思考一个核心问题：当一个模型需要服务于特征与结果关系不尽相同的多个群体时，我们如何定义和实现公平？此题设定了一个场景，其中两个群体的结果不仅与特征有不同的线性关系（即不同的斜率 $\\beta_A$），还具有不同水平的内在噪声（即异方差性 $\\sigma_{a}^{2}$）。通过推导，我们将揭示如何通过调整加权最小二乘法中的权重，来精确地实现一个特定的公平目标——跨群体均方误差相等，从而将抽象的“公平-准确性”权衡变得具体可感 [@problem_id:3098302]。", "problem": "一个二元敏感属性 $A \\in \\{0,1\\}$ 将一个群体划分为两个组，其概率为 $\\mathbb{P}(A=a)=p_{a}$，其中 $p_{0}, p_{1} \\in (0,1)$ 且 $p_{0}+p_{1}=1$。单个实值特征 $X \\in \\mathbb{R}$ 的分布满足 $\\mathbb{E}[X \\mid A=a]=0$ 和 $\\operatorname{Var}(X \\mid A=a)=1$（对于每个 $a \\in \\{0,1\\}$），结果 $Y \\in \\mathbb{R}$ 服从线性结构模型 $Y=\\beta_{A} X+\\varepsilon_{A}$，其中 $\\beta_{0}, \\beta_{1} \\in \\mathbb{R}$ 是特定于群体的斜率，$\\mathbb{E}[\\varepsilon_{A} \\mid X, A]=0$，且 $\\operatorname{Var}(\\varepsilon_{A} \\mid X, A=a)=\\sigma_{a}^{2}$，其中 $\\sigma_{0}^{2}, \\sigma_{1}^{2} > 0$。我们通过在 $\\theta \\in \\mathbb{R}$ 上最小化加权平方损失 $\\mathbb{E}[w(A)\\,(Y-\\theta X)^{2}]$ 来拟合一个单一的共享线性预测器 $\\hat{Y}_{\\theta}=\\theta X$，其中 $w(0)=w_{0}>0$ 和 $w(1)=w_{1}>0$ 是固定的正权重。为消除权重的尺度不确定性，我们假设归一化约束为 $p_{0} w_{0}+p_{1} w_{1}=1$。\n\n将回归中的公平性定义为群体条件均方误差相等：$\\mathbb{E}[(Y-\\hat{Y}_{\\theta})^{2} \\mid A=0]=\\mathbb{E}[(Y-\\hat{Y}_{\\theta})^{2} \\mid A=1]$。从条件期望、均方误差和加权最小二乘法的一阶最优性条件的核心定义出发，推导出唯一的归一化权重对 $(w_{0}, w_{1})$，使得加权最小二乘解 $\\theta$ 满足公平性准则。您的推导应明确阐明异方差噪声（即 $\\sigma_{0}^{2} \\neq \\sigma_{1}^{2}$）在使用单一共享预测器时如何在预测准确性与公平性约束之间造成不可避免的权衡，然后展示如何通过选择适当的权重来引导拟合的 $\\theta$ 以均衡条件均方误差，从而纠正此问题。\n\n假设 $\\beta_{0} \\neq \\beta_{1}$，并且参数满足公平性最优的共享斜率严格介于两个群体斜率之间，这在所述的归一化条件下保证了权重为正。请用 $\\beta_{0}$、$\\beta_{1}$、$\\sigma_{0}^{2}$、$\\sigma_{1}^{2}$、$p_{0}$ 和 $p_{1}$ 表示 $w_{0}$ 和 $w_{1}$ 的闭式解析表达式。不需要数值近似，也不涉及单位。请使用 LaTeX 的 $\\begin{pmatrix}$ 环境将最终答案表示为单行矩阵。", "solution": "该问题要求推导唯一的归一化权重对 $(w_{0}, w_{1})$，以确保加权最小二乘线性预测器满足特定的公平性准则。公平性准则定义为两个群体（$A=0$ 和 $A=1$）的群体条件均方误差相等。\n\n推导过程分为四个主要步骤：\n1.  通过最小化加权平方损失来确定最优预测器斜率 $\\theta$。\n2.  为每个群体 $a \\in \\{0,1\\}$ 构建群体条件均方误差 (MSE) 的公式。\n3.  应用公平性准则（群体条件 MSE 相等）来找到满足此约束的特定 $\\theta$ 值，记为 $\\theta_{F}$。\n4.  将步骤 1 中 $\\theta$ 的表达式与步骤 3 中 $\\theta_{F}$ 的值相等，并在给定的归一化约束下，求解得到的关于权重 $(w_{0}, w_{1})$ 的方程组。\n\n**步骤 1：加权最小二乘解**\n目标是找到使加权平方损失函数 $L(\\theta) = \\mathbb{E}[w(A)\\,(Y-\\theta X)^{2}]$ 最小化的斜率 $\\theta$。我们可以根据全期望定律，对敏感属性 $A$ 展开这个期望：\n$$L(\\theta) = \\sum_{a \\in \\{0,1\\}} \\mathbb{P}(A=a) \\mathbb{E}[w(A)\\,(Y-\\theta X)^{2} \\mid A=a]$$\n代入给定的概率 $p_{a}$ 和权重 $w_{a}$：\n$$L(\\theta) = p_{0} w_{0} \\mathbb{E}[(Y-\\theta X)^{2} \\mid A=0] + p_{1} w_{1} \\mathbb{E}[(Y-\\theta X)^{2} \\mid A=1]$$\n对于给定的群体 $A=a$，其结构模型为 $Y = \\beta_{a} X + \\varepsilon_{a}$。期望内的误差项变为：\n$$Y - \\theta X = (\\beta_{a} X + \\varepsilon_{a}) - \\theta X = (\\beta_{a} - \\theta)X + \\varepsilon_{a}$$\n平方误差为 $((\\beta_{a} - \\theta)X + \\varepsilon_{a})^{2} = (\\beta_{a}-\\theta)^{2}X^{2} + 2(\\beta_{a}-\\theta)X\\varepsilon_{a} + \\varepsilon_{a}^{2}$。我们计算其条件期望：\n$$\\mathbb{E}[((\\beta_{a} - \\theta)X + \\varepsilon_{a})^{2} \\mid A=a] = (\\beta_{a}-\\theta)^{2}\\mathbb{E}[X^{2} \\mid A=a] + 2(\\beta_{a}-\\theta)\\mathbb{E}[X\\varepsilon_{a} \\mid A=a] + \\mathbb{E}[\\varepsilon_{a}^{2} \\mid A=a]$$\n使用给定的条件：\n- $\\mathbb{E}[X \\mid A=a]=0$ 且 $\\operatorname{Var}(X \\mid A=a)=1$，这意味着 $\\mathbb{E}[X^{2} \\mid A=a] = \\operatorname{Var}(X \\mid A=a) + (\\mathbb{E}[X \\mid A=a])^{2} = 1 + 0^{2} = 1$。\n- $\\mathbb{E}[\\varepsilon_{A} \\mid X, A]=0$。根据迭代期望定律，$\\mathbb{E}[X\\varepsilon_{a} \\mid A=a] = \\mathbb{E}[\\mathbb{E}[X\\varepsilon_{a} \\mid X, A=a] \\mid A=a] = \\mathbb{E}[X \\mathbb{E}[\\varepsilon_{a} \\mid X, A=a] \\mid A=a] = \\mathbb{E}[X \\cdot 0 \\mid A=a] = 0$。\n- $\\operatorname{Var}(\\varepsilon_{A} \\mid X, A=a)=\\sigma_{a}^{2}$ 且 $\\mathbb{E}[\\varepsilon_{A} \\mid X, A=a] = 0$。这意味着 $\\mathbb{E}[\\varepsilon_{a}^{2} \\mid X, A=a] = \\sigma_{a}^{2}$。根据迭代期望定律，$\\mathbb{E}[\\varepsilon_{a}^{2} \\mid A=a] = \\mathbb{E}[\\mathbb{E}[\\varepsilon_{a}^{2} \\mid X, A=a] \\mid A=a] = \\mathbb{E}[\\sigma_{a}^{2} \\mid A=a] = \\sigma_{a}^{2}$。\n\n将这些结果代回，群体 $a$ 的平方误差的条件期望为 $(\\beta_{a} - \\theta)^{2} + \\sigma_{a}^{2}$。损失函数变为：\n$$L(\\theta) = p_{0} w_{0} [(\\beta_{0} - \\theta)^{2} + \\sigma_{0}^{2}] + p_{1} w_{1} [(\\beta_{1} - \\theta)^{2} + \\sigma_{1}^{2}]$$\n为了找到最小值，我们计算关于 $\\theta$ 的导数并将其设为零（一阶最优性条件）：\n$$\\frac{dL}{d\\theta} = p_{0} w_{0} [2(\\beta_{0} - \\theta)(-1)] + p_{1} w_{1} [2(\\beta_{1} - \\theta)(-1)] = 0$$\n$$-2 [p_{0} w_{0} (\\beta_{0} - \\theta) + p_{1} w_{1} (\\beta_{1} - \\theta)] = 0$$\n$$(p_{0} w_{0} + p_{1} w_{1})\\theta = p_{0} w_{0} \\beta_{0} + p_{1} w_{1} \\beta_{1}$$\n应用归一化约束 $p_{0} w_{0} + p_{1} w_{1} = 1$，我们得到 $\\theta$ 的加权最小二乘解：\n$$\\theta = p_{0} w_{0} \\beta_{0} + p_{1} w_{1} \\beta_{1}$$\n\n**步骤 2：群体条件均方误差**\n群体 $a$ 的均方误差 $\\text{MSE}_{a}$ 定义为 $\\mathbb{E}[(Y-\\hat{Y}_{\\theta})^{2} \\mid A=a]$。由于 $\\hat{Y}_{\\theta}=\\theta X$，这正是我们在步骤 1 中计算的条件期望：\n$$\\text{MSE}_{a} = \\mathbb{E}[(Y - \\theta X)^{2} \\mid A=a] = (\\beta_{a} - \\theta)^{2} + \\sigma_{a}^{2}$$\n该表达式表明，一个群体的 MSE 由两部分组成：一个偏差项 $(\\beta_{a}-\\theta)^{2}$，它衡量了群体最优斜率 $\\beta_a$ 与共享斜率 $\\theta$ 之间的平方差；以及一个来自不可约减噪声的方差项 $\\sigma_{a}^{2}$。\n\n**步骤 3：公平性约束**\n公平性准则要求 $\\text{MSE}_{0} = \\text{MSE}_{1}$。令 $\\theta_{F}$ 为满足此准则的 $\\theta$ 值。\n$$(\\beta_{0} - \\theta_{F})^{2} + \\sigma_{0}^{2} = (\\beta_{1} - \\theta_{F})^{2} + \\sigma_{1}^{2}$$\n展开平方项：\n$$\\beta_{0}^{2} - 2\\beta_{0}\\theta_{F} + \\theta_{F}^{2} + \\sigma_{0}^{2} = \\beta_{1}^{2} - 2\\beta_{1}\\theta_{F} + \\theta_{F}^{2} + \\sigma_{1}^{2}$$\n$$2\\beta_{1}\\theta_{F} - 2\\beta_{0}\\theta_{F} = \\beta_{1}^{2} - \\beta_{0}^{2} + \\sigma_{1}^{2} - \\sigma_{0}^{2}$$\n$$2\\theta_{F}(\\beta_{1} - \\beta_{0}) = (\\beta_{1} - \\beta_{0})(\\beta_{1} + \\beta_{0}) + (\\sigma_{1}^{2} - \\sigma_{0}^{2})$$\n由于 $\\beta_{0} \\neq \\beta_{1}$，我们可以除以 $2(\\beta_{1} - \\beta_{0})$：\n$$\\theta_{F} = \\frac{\\beta_{0} + \\beta_{1}}{2} + \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{2(\\beta_{1} - \\beta_{0})}$$\n这是使两组之间 MSE 相等的唯一斜率。如果噪声是同方差的（$\\sigma_{0}^{2} = \\sigma_{1}^{2}$），那么 $\\theta_F$ 就是两个特定群体斜率的平均值。然而，对于异方差噪声（$\\sigma_{0}^{2} \\neq \\sigma_{1}^{2}$），$\\theta_F$ 会偏离这个平均值以进行补偿。例如，如果群体 1 的噪声更大（$\\sigma_{1}^{2} > \\sigma_{0}^{2}$）且斜率更高（$\\beta_{1} > \\beta_{0}$），那么 $\\theta_F$ 必须大于平均值，以减小群体 1 的偏差项（通过使 $\\theta_F$ 更接近 $\\beta_1$）并增大群体 0 的偏差项，从而平衡整体的 MSE。这说明了其中的权衡：实现公平性需要选择一个斜率 $\\theta_F$，这个斜率对于任何一个群体本身或整个群体（通常是像 $p_0\\beta_0+p_1\\beta_1$ 这样的加权平均值）而言不一定是最优的，其目的是为了平衡各群体间的误差。权重 $(w_0, w_1)$ 是将加权最小二乘法（WLS）优化引导至这个特定的、由公平性驱动的目标 $\\theta_F$ 的机制。\n\n**步骤 4：求解权重**\n现在我们得到一个关于 $w_{0}$ 和 $w_{1}$ 的二元线性方程组：\n1.  $\\theta_{F} = p_{0} w_{0} \\beta_{0} + p_{1} w_{1} \\beta_{1}$\n2.  $1 = p_{0} w_{0} + p_{1} w_{1}$\n\n从方程 (2) 中，我们可以写出 $p_{1} w_{1} = 1 - p_{0} w_{0}$。将其代入方程 (1) 中：\n$$\\theta_{F} = p_{0} w_{0} \\beta_{0} + (1 - p_{0} w_{0})\\beta_{1} = p_{0} w_{0} \\beta_{0} + \\beta_{1} - p_{0} w_{0} \\beta_{1}$$\n$$\\theta_{F} - \\beta_{1} = p_{0} w_{0} (\\beta_{0} - \\beta_{1})$$\n$$w_{0} = \\frac{\\theta_{F} - \\beta_{1}}{p_{0}(\\beta_{0} - \\beta_{1})} = \\frac{\\beta_{1} - \\theta_{F}}{p_{0}(\\beta_{1} - \\beta_{0})}$$\n代入 $\\theta_{F}$ 的表达式：\n$$w_{0} = \\frac{1}{p_{0}(\\beta_{1} - \\beta_{0})} \\left[ \\beta_{1} - \\left(\\frac{\\beta_{0} + \\beta_{1}}{2} + \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{2(\\beta_{1} - \\beta_{0})}\\right) \\right]$$\n$$w_{0} = \\frac{1}{p_{0}(\\beta_{1} - \\beta_{0})} \\left[ \\frac{2\\beta_{1} - (\\beta_{0} + \\beta_{1})}{2} - \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{2(\\beta_{1} - \\beta_{0})} \\right]$$\n$$w_{0} = \\frac{1}{p_{0}(\\beta_{1} - \\beta_{0})} \\left[ \\frac{\\beta_{1} - \\beta_{0}}{2} - \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{2(\\beta_{1} - \\beta_{0})} \\right]$$\n$$w_{0} = \\frac{1}{2p_{0}} \\left( 1 - \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{(\\beta_{1} - \\beta_{0})^{2}} \\right)$$\n\n类似地，我们可以通过将 $p_{0}w_{0} = 1 - p_{1}w_{1}$ 代入方程 (1) 来求解 $w_{1}$：\n$$\\theta_{F} = (1 - p_{1} w_{1})\\beta_{0} + p_{1} w_{1} \\beta_{1} = \\beta_{0} + p_{1} w_{1}(\\beta_{1} - \\beta_{0})$$\n$$w_{1} = \\frac{\\theta_{F} - \\beta_{0}}{p_{1}(\\beta_{1} - \\beta_{0})}$$\n代入 $\\theta_{F}$ 的表达式：\n$$w_{1} = \\frac{1}{p_{1}(\\beta_{1} - \\beta_{0})} \\left[ \\left(\\frac{\\beta_{0} + \\beta_{1}}{2} + \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{2(\\beta_{1} - \\beta_{0})}\\right) - \\beta_{0} \\right]$$\n$$w_{1} = \\frac{1}{p_{1}(\\beta_{1} - \\beta_{0})} \\left[ \\frac{\\beta_{1} - \\beta_{0}}{2} + \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{2(\\beta_{1} - \\beta_{0})} \\right]$$\n$$w_{1} = \\frac{1}{2p_{1}} \\left( 1 + \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{(\\beta_{1} - \\beta_{0})^{2}} \\right)$$\n\n这些就是所求的唯一的归一化权重。假设 $\\theta_F$ 严格介于 $\\beta_0$ 和 $\\beta_1$ 之间，保证了 $1 \\pm \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{(\\beta_{1} - \\beta_{0})^{2}}$ 项为正，因此 $w_0, w_1 > 0$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{2p_{0}} \\left( 1 - \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{(\\beta_{1} - \\beta_{0})^{2}} \\right)  \\frac{1}{2p_{1}} \\left( 1 + \\frac{\\sigma_{1}^{2} - \\sigma_{0}^{2}}{(\\beta_{1} - \\beta_{0})^{2}} \\right)\n\\end{pmatrix}\n}\n$$", "id": "3098302"}, {"introduction": "假设我们已经成功构建了一个在训练数据上表现“公平”的模型，这是否意味着万事大吉？本练习通过一个精巧的数值案例，对这一乐观想法提出了挑战。我们将探讨一个在现实世界中极为常见的现象——协变量偏移（covariate shift），即测试数据中特征的分布与训练数据不同。你将亲手计算并验证，一个在训练集上满足均等化赔率（equalized odds）的分类器，在部署到具有协变量偏移的测试集上时，其公平性保证会如何“悄然”失效 [@problem_id:3098292]。这个练习不仅揭示了公平性保证的脆弱性，还引出了一种重要的审计工具——重要性加权，用于在分布变化的情况下更准确地评估模型的真实性能。", "problem": "考虑经验风险最小化（ERM）下的二元分类问题，其中有一个二元敏感属性 $A \\in \\{0,1\\}$、一个二元特征 $X \\in \\{0,1\\}$ 和一个二元标签 $Y \\in \\{0,1\\}$。分类器定义为 $\\hat{Y}(X) = \\mathbf{1}\\{X=1\\}$，其训练目标是最小化经验 $0$-$1$ 损失。设训练分布在不同组之间是不平衡的，其中 $P_{\\text{train}}(A=0) = 0.9$ 且 $P_{\\text{train}}(A=1) = 0.1$。假设标签条件概率在不同域和组之间是稳定的（仅存在协变量偏移），具体由 $P(Y=1 \\mid X=1) = \\frac{3}{4}$ 和 $P(Y=1 \\mid X=0) = \\frac{1}{4}$ 指定，因此对于训练和测试集均有 $P(Y=0 \\mid X=1) = \\frac{1}{4}$ 和 $P(Y=0 \\mid X=0) = \\frac{3}{4}$。在训练分布上，协变量条件概率是组间平衡的：$P_{\\text{train}}(X=1 \\mid A=0) = P_{\\text{train}}(X=1 \\mid A=1) = \\frac{1}{2}$。在测试分布上，存在特定于组的协变量偏移：$P_{\\text{test}}(X=1 \\mid A=0) = \\frac{3}{4}$ 且 $P_{\\text{test}}(X=1 \\mid A=1) = \\frac{1}{4}$。\n\n我们审计基于假阳性率（FPR）的均等化赔率这一公平性概念，其中，对于组 $a \\in \\{0,1\\}$，假阳性率定义为 $\\text{FPR}_{a} = P(\\hat{Y}=1 \\mid Y=0, A=a)$。首先，根据定义进行推理，验证训练集上的均等化赔率（即 $\\text{FPR}_{0}$ 和 $\\text{FPR}_{1}$ 相等）成立，而测试集上的均等化赔率不成立。然后，通过定义 $w_{a}(x) = \\frac{P_{\\text{test}}(X=x \\mid A=a)}{P_{\\text{train}}(X=x \\mid A=a)}$，提出在协变量偏移下的重要性加权审计方法，并使用这些权重将测试域的FPR重写为训练域上的加权条件期望。\n\n根据给定的数值，明确计算通过在训练分布上使用权重 $w_{a}(x)$ 进行审计得到的重要性加权假阳性率差距 $\\text{FPR}_{0}^{\\text{iw}} - \\text{FPR}_{1}^{\\text{iw}}$。将最终答案表示为小数或分数（不带百分号）。无需四舍五入。", "solution": "该问题要求分析一个分类器在以协变量偏移为特征的训练和测试分布下的假阳性率（FPR）。分类器由 $\\hat{Y}(X) = \\mathbf{1}\\{X=1\\}$ 给出，意味着当且仅当特征 $X$ 为1时，它预测一个正向结果（$\\hat{Y}=1$）。\n\n对于组 $a \\in \\{0, 1\\}$ 的假阳性率定义为 $\\text{FPR}_{a} = P(\\hat{Y}=1 \\mid Y=0, A=a)$。根据分类器的定义，这等价于 $\\text{FPR}_{a} = P(X=1 \\mid Y=0, A=a)$。我们将为训练和测试分布计算这个量。\n\n使用贝叶斯定理，我们可以将FPR表示为：\n$$ \\text{FPR}_{a} = \\frac{P(Y=0 \\mid X=1, A=a) P(X=1 \\mid A=a)}{P(Y=0 \\mid A=a)} $$\n问题指出标签条件概率是稳定的，即 $P(Y \\mid X, A) = P(Y \\mid X)$。因此，公式简化为：\n$$ \\text{FPR}_{a} = \\frac{P(Y=0 \\mid X=1) P(X=1 \\mid A=a)}{P(Y=0 \\mid A=a)} $$\n分母 $P(Y=0 \\mid A=a)$ 必须使用全概率定律为每个分布（训练和测试）计算：\n$$ P(Y=0 \\mid A=a) = \\sum_{x \\in \\{0,1\\}} P(Y=0 \\mid X=x, A=a) P(X=x \\mid A=a) $$\n$$ P_{\\text{dist}}(Y=0 \\mid A=a) = P(Y=0 \\mid X=0)P_{\\text{dist}}(X=0 \\mid A=a) + P(Y=0 \\mid X=1)P_{\\text{dist}}(X=1 \\mid A=a) $$\n其中 $P(Y=0 \\mid X=1) = \\frac{1}{4}$ 和 $P(Y=0 \\mid X=0) = \\frac{3}{4}$。\n\n**第1部分：验证训练和测试集上的均等化赔率**\n\n**训练分布：**\n首先，我们计算 $P_{\\text{train}}(Y=0 \\mid A=a)$：\n对于 $A=0$：$P_{\\text{train}}(Y=0 \\mid A=0) = (\\frac{3}{4})P_{\\text{train}}(X=0 \\mid A=0) + (\\frac{1}{4})P_{\\text{train}}(X=1 \\mid A=0) = (\\frac{3}{4})(\\frac{1}{2}) + (\\frac{1}{4})(\\frac{1}{2}) = \\frac{3}{8} + \\frac{1}{8} = \\frac{4}{8} = \\frac{1}{2}$。\n对于 $A=1$：$P_{\\text{train}}(Y=0 \\mid A=1) = (\\frac{3}{4})P_{\\text{train}}(X=0 \\mid A=1) + (\\frac{1}{4})P_{\\text{train}}(X=1 \\mid A=1) = (\\frac{3}{4})(\\frac{1}{2}) + (\\frac{1}{4})(\\frac{1}{2}) = \\frac{1}{2}$。\n\n现在，我们计算训练集FPR：\n$\\text{FPR}_{0}^{\\text{train}} = \\frac{P(Y=0 \\mid X=1) P_{\\text{train}}(X=1 \\mid A=0)}{P_{\\text{train}}(Y=0 \\mid A=0)} = \\frac{(\\frac{1}{4})(\\frac{1}{2})}{\\frac{1}{2}} = \\frac{1}{4}$。\n$\\text{FPR}_{1}^{\\text{train}} = \\frac{P(Y=0 \\mid X=1) P_{\\text{train}}(X=1 \\mid A=1)}{P_{\\text{train}}(Y=0 \\mid A=1)} = \\frac{(\\frac{1}{4})(\\frac{1}{2})}{\\frac{1}{2}} = \\frac{1}{4}$。\n由于 $\\text{FPR}_{0}^{\\text{train}} = \\text{FPR}_{1}^{\\text{train}}$，因此在训练分布上，基于FPR的均等化赔率成立。\n\n**测试分布：**\n首先，我们计算 $P_{\\text{test}}(Y=0 \\mid A=a)$：\n对于 $A=0$：$P_{\\text{test}}(Y=0 \\mid A=0) = (\\frac{3}{4})P_{\\text{test}}(X=0 \\mid A=0) + (\\frac{1}{4})P_{\\text{test}}(X=1 \\mid A=0) = (\\frac{3}{4})(\\frac{1}{4}) + (\\frac{1}{4})(\\frac{3}{4}) = \\frac{3}{16} + \\frac{3}{16} = \\frac{6}{16} = \\frac{3}{8}$。\n对于 $A=1$：$P_{\\text{test}}(Y=0 \\mid A=1) = (\\frac{3}{4})P_{\\text{test}}(X=0 \\mid A=1) + (\\frac{1}{4})P_{\\text{test}}(X=1 \\mid A=1) = (\\frac{3}{4})(\\frac{3}{4}) + (\\frac{1}{4})(\\frac{1}{4}) = \\frac{9}{16} + \\frac{1}{16} = \\frac{10}{16} = \\frac{5}{8}$。\n\n现在，我们计算测试集FPR：\n$\\text{FPR}_{0}^{\\text{test}} = \\frac{P(Y=0 \\mid X=1) P_{\\text{test}}(X=1 \\mid A=0)}{P_{\\text{test}}(Y=0 \\mid A=0)} = \\frac{(\\frac{1}{4})(\\frac{3}{4})}{\\frac{3}{8}} = \\frac{\\frac{3}{16}}{\\frac{3}{8}} = \\frac{1}{2}$。\n$\\text{FPR}_{1}^{\\text{test}} = \\frac{P(Y=0 \\mid X=1) P_{\\text{test}}(X=1 \\mid A=1)}{P_{\\text{test}}(Y=0 \\mid A=1)} = \\frac{(\\frac{1}{4})(\\frac{1}{4})}{\\frac{5}{8}} = \\frac{\\frac{1}{16}}{\\frac{5}{8}} = \\frac{1}{10}$。\n由于 $\\text{FPR}_{0}^{\\text{test}} \\neq \\text{FPR}_{1}^{\\text{test}}$，因此在测试分布上，基于FPR的均等化赔率不成立。\n\n**第2部分：重要性加权审计**\n\n重要性加权审计的目标是使用训练域分布来估计测试域的量。重要性加权的FPR，$\\text{FPR}_{a}^{\\text{iw}}$，是测试FPR，$\\text{FPR}_{a}^{\\text{test}}$的估计量。在完全了解分布的情况下，这个理论量精确地等于 $\\text{FPR}_{a}^{\\text{test}}$。我们将通过显式计算来证明这一点。\n\n测试FPR可以写成期望的比率：\n$$ \\text{FPR}_{a}^{\\text{test}} = P_{\\text{test}}(\\hat{Y}=1 \\mid Y=0, A=a) = \\frac{P_{\\text{test}}(\\hat{Y}=1, Y=0 \\mid A=a)}{P_{\\text{test}}(Y=0 \\mid A=a)} = \\frac{E_{\\text{test}}[\\hat{Y}(X) \\mathbf{1}\\{Y=0\\} \\mid A=a]}{E_{\\text{test}}[\\mathbf{1}\\{Y=0\\} \\mid A=a]} $$\n在协变量偏移下，我们可以使用重要性权重 $w_{a}(x) = \\frac{P_{\\text{test}}(X=x \\mid A=a)}{P_{\\text{train}}(X=x \\mid A=a)}$ 将这些测试域的期望重写为加权的训练域期望。这给出了重要性加权FPR的公式：\n$$ \\text{FPR}_{a}^{\\text{iw}} = \\frac{E_{\\text{train}}[\\hat{Y}(X) \\mathbf{1}\\{Y=0\\} w_a(X) \\mid A=a]}{E_{\\text{train}}[\\mathbf{1}\\{Y=0\\} w_a(X) \\mid A=a]} $$\n首先，我们计算权重：\n对于 $A=0$：$w_0(1) = \\frac{P_{\\text{test}}(X=1 \\mid A=0)}{P_{\\text{train}}(X=1 \\mid A=0)} = \\frac{3/4}{1/2} = \\frac{3}{2}$。$w_0(0) = \\frac{P_{\\text{test}}(X=0 \\mid A=0)}{P_{\\text{train}}(X=0 \\mid A=0)} = \\frac{1/4}{1/2} = \\frac{1}{2}$。\n对于 $A=1$：$w_1(1) = \\frac{P_{\\text{test}}(X=1 \\mid A=1)}{P_{\\text{train}}(X=1 \\mid A=1)} = \\frac{1/4}{1/2} = \\frac{1}{2}$。$w_1(0) = \\frac{P_{\\text{test}}(X=0 \\mid A=1)}{P_{\\text{train}}(X=0 \\mid A=1)} = \\frac{3/4}{1/2} = \\frac{3}{2}$。\n\n现在我们为每个组a计算分子和分母。期望 $E_{\\text{train}}[\\cdot \\mid A=a]$ 是基于联合分布 $P_{\\text{train}}(X, Y \\mid A=a) = P(Y \\mid X) P_{\\text{train}}(X \\mid A=a)$ 计算的。\n\n**对于组 A=0**：\n分子是 $N_0 = E_{\\text{train}}[\\mathbf{1}\\{X=1\\} \\mathbf{1}\\{Y=0\\} w_0(X) \\mid A=0]$。唯一的非零项是当 $X=1, Y=0$ 时。\n$N_0 = w_0(1) P_{\\text{train}}(X=1, Y=0 \\mid A=0) = w_0(1) P(Y=0 \\mid X=1) P_{\\text{train}}(X=1 \\mid A=0) = (\\frac{3}{2}) (\\frac{1}{4}) (\\frac{1}{2}) = \\frac{3}{16}$。\n分母是 $D_0 = E_{\\text{train}}[\\mathbf{1}\\{Y=0\\} w_0(X) \\mid A=0]$。\n$D_0 = w_0(0) P_{\\text{train}}(X=0, Y=0 \\mid A=0) + w_0(1) P_{\\text{train}}(X=1, Y=0 \\mid A=0)$\n$D_0 = w_0(0) P(Y=0 \\mid X=0) P_{\\text{train}}(X=0 \\mid A=0) + N_0 = (\\frac{1}{2}) (\\frac{3}{4}) (\\frac{1}{2}) + \\frac{3}{16} = \\frac{3}{16} + \\frac{3}{16} = \\frac{6}{16} = \\frac{3}{8}$。\n所以，$\\text{FPR}_{0}^{\\text{iw}} = \\frac{N_0}{D_0} = \\frac{3/16}{3/8} = \\frac{1}{2}$。\n\n**对于组 A=1**：\n分子是 $N_1 = E_{\\text{train}}[\\mathbf{1}\\{X=1\\} \\mathbf{1}\\{Y=0\\} w_1(X) \\mid A=1]$。\n$N_1 = w_1(1) P_{\\text{train}}(X=1, Y=0 \\mid A=1) = w_1(1) P(Y=0 \\mid X=1) P_{\\text{train}}(X=1 \\mid A=1) = (\\frac{1}{2}) (\\frac{1}{4}) (\\frac{1}{2}) = \\frac{1}{16}$。\n分母是 $D_1 = E_{\\text{train}}[\\mathbf{1}\\{Y=0\\} w_1(X) \\mid A=1]$。\n$D_1 = w_1(0) P_{\\text{train}}(X=0, Y=0 \\mid A=1) + w_1(1) P_{\\text{train}}(X=1, Y=0 \\mid A=1)$\n$D_1 = w_1(0) P(Y=0 \\mid X=0) P_{\\text{train}}(X=0 \\mid A=1) + N_1 = (\\frac{3}{2}) (\\frac{3}{4}) (\\frac{1}{2}) + \\frac{1}{16} = \\frac{9}{16} + \\frac{1}{16} = \\frac{10}{16} = \\frac{5}{8}$。\n所以，$\\text{FPR}_{1}^{\\text{iw}} = \\frac{N_1}{D_1} = \\frac{1/16}{5/8} = \\frac{1}{10}$。\n\n正如预期的，$\\text{FPR}_{a}^{\\text{iw}} = \\text{FPR}_{a}^{\\text{test}}$ 对两个组都成立。重要性加权的假阳性率差距是：\n$$ \\text{FPR}_{0}^{\\text{iw}} - \\text{FPR}_{1}^{\\text{iw}} = \\frac{1}{2} - \\frac{1}{10} = \\frac{5}{10} - \\frac{1}{10} = \\frac{4}{10} = \\frac{2}{5} $$\n作为小数，结果是0.4。", "answer": "$$ \\boxed{\\frac{2}{5}} $$", "id": "3098292"}, {"introduction": "前面的练习展示了模型和数据分布带来的挑战，但如果我们用来评估公平性的数据本身就存在偏差呢？本练习深入探讨了另一个现实困境：标签噪声（label noise），特别是当噪声水平因群体而异时的情况。我们将从第一性原理出发，推导群体相关的标签噪声如何系统性地扭曲我们对均等化赔率等公平性指标的观测结果，甚至可能将一个本质上不公平的模型伪装成公平的。更重要的是，这个练习将引导你掌握一种“去偏”方法，即通过构建一个能感知噪声的损失函数，来修正评估过程，从而穿透数据质量问题的迷雾，洞察模型真实的公平属性 [@problem_id:3098319]。", "problem": "考虑一个统计学习中的二元分类任务，其中有受保护属性 $A \\in \\{0,1\\}$、真实标签 $Y \\in \\{0,1\\}$，以及一个输出二元预测 $\\hat{Y} \\in \\{0,1\\}$ 的分类器。数据生成过程引入了与组相关的对称标签噪声：对于每个受保护属性为 $A=a$ 的样本，观测到的标签 $Y^{\\mathrm{obs}}$ 通过异或（XOR）关系 $Y^{\\mathrm{obs}} = Y \\oplus Z$ 与真实标签 $Y$ 相关，其中 $Z \\mid A=a \\sim \\mathrm{Bernoulli}(\\eta_a)$ 在给定 $A$ 的条件下独立于 $(X,Y,\\hat{Y})$，且 $\\eta_a \\in [0,1/2)$ 是组 $a$ 的标签翻转概率。设组 $a$ 中的正例率为 $\\pi_a = \\mathbb{P}(Y=1 \\mid A=a)$，并定义真正率 $t_a = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1, A=a)$ 和假正率 $f_a = \\mathbb{P}(\\hat{Y}=1 \\mid Y=0, A=a)$。\n\n均等化赔率（Equalized Odds, EO）是一个约束条件，即当根据真实标签 $Y$ 进行衡量时，两个组 $a \\in \\{0,1\\}$ 的 $t_a$ 和 $f_a$ 都相等。在实践中，EO 通常是使用观测标签 $Y^{\\mathrm{obs}}$ 而不是 $Y$ 来强制执行或评估的。\n\n你的任务是：\n1. 从条件概率的定义和全概率定律出发，推导基于 $Y^{\\mathrm{obs}}$ 测量的组条件率，即 $\\tilde{t}_a = \\mathbb{P}(\\hat{Y}=1 \\mid Y^{\\mathrm{obs}}=1, A=a)$ 和 $\\tilde{f}_a = \\mathbb{P}(\\hat{Y}=1 \\mid Y^{\\mathrm{obs}}=0, A=a)$，并用 $\\eta_a$、$\\pi_a$、$t_a$ 和 $f_a$ 表示。\n2. 使用这些表达式，解释当 EO 是在 $Y^{\\mathrm{obs}}$ 而非 $Y$ 上强制执行或评估时，即使关于 $Y$ 的 EO 成立，各组间噪声率 $\\eta_a$ 和正例率 $\\pi_a$ 的差异如何扭曲均等化赔率。\n3. 提出一种通过噪声感知损失函数的去偏策略，该策略在给定的与组相关的对称噪声下，能够产生对干净标签风险的无偏估计。推导组 $a$ 的 $2 \\times 2$ 损坏矩阵及其逆矩阵，并用基于干净标签的基础损失 $\\ell(\\hat{p}, y)$ 写出修正后的损失 $\\tilde{\\ell}(\\hat{p}, y^{\\mathrm{obs}}, a)$。\n4. 作为你的最终答案，提供在所述模型下从 $(t_a, f_a)$ 到 $(\\tilde{t}_a, \\tilde{f}_a)$ 的封闭形式映射，使用 LaTeX 的 $\\begin{pmatrix}$ 环境表示为单个行矩阵。\n\n不需要数值近似。请用精确的符号形式表达你的最终答案。最终答案必须是单一的封闭形式解析表达式。", "solution": "该问题要求对与组相关的对称标签噪声对均等化赔率（EO）公平性准则的影响进行多部分分析。我们给定以下定义：受保护属性 $A \\in \\{0, 1\\}$、真实标签 $Y \\in \\{0, 1\\}$、观测标签 $Y^{\\mathrm{obs}} \\in \\{0, 1\\}$，以及分类器的预测 $\\hat{Y} \\in \\{0, 1\\}$。噪声模型为 $Y^{\\mathrm{obs}} = Y \\oplus Z$，其中 $Z \\mid A=a \\sim \\mathrm{Bernoulli}(\\eta_a)$，噪声率为 $\\eta_a \\in [0, 1/2)$。组 $a$ 的关键量是正例率 $\\pi_a = \\mathbb{P}(Y=1 \\mid A=a)$、真正率 $t_a = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1, A=a)$ 和假正率 $f_a = \\mathbb{P}(\\hat{Y}=1 \\mid Y=0, A=a)$。我们的任务是将这些量与它们在带噪声的观测标签上测量的对应量联系起来：$\\tilde{t}_a = \\mathbb{P}(\\hat{Y}=1 \\mid Y^{\\mathrm{obs}}=1, A=a)$ 和 $\\tilde{f}_a = \\mathbb{P}(\\hat{Y}=1 \\mid Y^{\\mathrm{obs}}=0, A=a)$。\n\n### 1. 观测率 $\\tilde{t}_a$ 和 $\\tilde{f}_a$ 的推导\n\n我们首先推导 $\\tilde{t}_a$ 的表达式。根据条件概率的定义：\n$$\n\\tilde{t}_a = \\mathbb{P}(\\hat{Y}=1 \\mid Y^{\\mathrm{obs}}=1, A=a) = \\frac{\\mathbb{P}(\\hat{Y}=1, Y^{\\mathrm{obs}}=1 \\mid A=a)}{\\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid A=a)}\n$$\n我们通过应用全概率定律，以真实标签 $Y$ 为条件，分别推导分子和分母。\n\n首先，对于分母 $\\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid A=a)$:\n$$\n\\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid A=a) = \\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid Y=1, A=a)\\mathbb{P}(Y=1 \\mid A=a) + \\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid Y=0, A=a)\\mathbb{P}(Y=0 \\mid A=a)\n$$\n噪声模型 $Y^{\\mathrm{obs}} = Y \\oplus Z$（其中 $Z \\sim \\mathrm{Bernoulli}(\\eta_a)$）给出了标签翻转概率：\n$\\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid Y=1, A=a) = \\mathbb{P}(Z=0 \\mid A=a) = 1-\\eta_a$（标签未翻转）。\n$\\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid Y=0, A=a) = \\mathbb{P}(Z=1 \\mid A=a) = \\eta_a$（标签从 $0$ 翻转为 $1$）。\n由于 $\\mathbb{P}(Y=1 \\mid A=a) = \\pi_a$ 且 $\\mathbb{P}(Y=0 \\mid A=a) = 1-\\pi_a$，分母变为：\n$$\n\\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid A=a) = (1-\\eta_a)\\pi_a + \\eta_a(1-\\pi_a)\n$$\n\n接下来，对于分子 $\\mathbb{P}(\\hat{Y}=1, Y^{\\mathrm{obs}}=1 \\mid A=a)$:\n$$\n\\mathbb{P}(\\hat{Y}=1, Y^{\\mathrm{obs}}=1 \\mid A=a) = \\sum_{y \\in \\{0,1\\}} \\mathbb{P}(\\hat{Y}=1, Y^{\\mathrm{obs}}=1 \\mid Y=y, A=a)\\mathbb{P}(Y=y \\mid A=a)\n$$\n根据假设，$Z$ 在给定 $A$ 的条件下独立于 $(X, Y, \\hat{Y})$，因此 $Y^{\\mathrm{obs}}$ 在给定 $(Y, A)$ 的条件下与 $\\hat{Y}$ 条件独立。因此，我们可以分解联合概率：\n$\\mathbb{P}(\\hat{Y}=1, Y^{\\mathrm{obs}}=1 \\mid Y=y, A=a) = \\mathbb{P}(\\hat{Y}=1 \\mid Y=y, A=a)\\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid Y=y, A=a)$。\n和中的两项是：\n当 $y=1$ 时：$\\mathbb{P}(\\hat{Y}=1 \\mid Y=1, A=a)\\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid Y=1, A=a)\\mathbb{P}(Y=1 \\mid A=a) = t_a(1-\\eta_a)\\pi_a$。\n当 $y=0$ 时：$\\mathbb{P}(\\hat{Y}=1 \\mid Y=0, A=a)\\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid Y=0, A=a)\\mathbb{P}(Y=0 \\mid A=a) = f_a\\eta_a(1-\\pi_a)$。\n分子是这两项的和：\n$$\n\\mathbb{P}(\\hat{Y}=1, Y^{\\mathrm{obs}}=1 \\mid A=a) = t_a(1-\\eta_a)\\pi_a + f_a\\eta_a(1-\\pi_a)\n$$\n结合分子和分母，得到 $\\tilde{t}_a$ 的表达式：\n$$\n\\tilde{t}_a = \\frac{t_a(1-\\eta_a)\\pi_a + f_a\\eta_a(1-\\pi_a)}{(1-\\eta_a)\\pi_a + \\eta_a(1-\\pi_a)}\n$$\n\n类似的推导得出 $\\tilde{f}_a = \\mathbb{P}(\\hat{Y}=1 \\mid Y^{\\mathrm{obs}}=0, A=a)$ 的表达式。\n分母是 $\\mathbb{P}(Y^{\\mathrm{obs}}=0 \\mid A=a) = 1 - \\mathbb{P}(Y^{\\mathrm{obs}}=1 \\mid A=a) = \\eta_a\\pi_a + (1-\\eta_a)(1-\\pi_a)$。\n分子是 $\\mathbb{P}(\\hat{Y}=1, Y^{\\mathrm{obs}}=0 \\mid A=a)$：\n$\\mathbb{P}(\\hat{Y}=1, Y^{\\mathrm{obs}}=0 \\mid A=a) = \\mathbb{P}(\\hat{Y}=1 \\mid Y=1, A=a)\\mathbb{P}(Y^{\\mathrm{obs}}=0 \\mid Y=1, A=a)\\pi_a + \\mathbb{P}(\\hat{Y}=1 \\mid Y=0, A=a)\\mathbb{P}(Y^{\\mathrm{obs}}=0 \\mid Y=0, A=a)(1-\\pi_a)$\n$= t_a\\eta_a\\pi_a + f_a(1-\\eta_a)(1-\\pi_a)$。\n结合这些，得到 $\\tilde{f}_a$ 的表达式：\n$$\n\\tilde{f}_a = \\frac{t_a\\eta_a\\pi_a + f_a(1-\\eta_a)(1-\\pi_a)}{\\eta_a\\pi_a + (1-\\eta_a)(1-\\pi_a)}\n$$\n\n### 2. 均等化赔率的扭曲\n\n相对于真实标签 $Y$ 的均等化赔率要求 $t_0=t_1$ 且 $f_0=f_1$。我们将这些共同的比率分别表示为 $t$ 和 $f$。推导出的组 $a$ 的观测率表达式变为：\n$$\n\\tilde{t}_a = \\frac{t(1-\\eta_a)\\pi_a + f\\eta_a(1-\\pi_a)}{(1-\\eta_a)\\pi_a + \\eta_a(1-\\pi_a)}\n$$\n$$\n\\tilde{f}_a = \\frac{t\\eta_a\\pi_a + f(1-\\eta_a)(1-\\pi_a)}{\\eta_a\\pi_a + (1-\\eta_a)(1-\\pi_a)}\n$$\n这些表达式表明，观测率 $\\tilde{t}_a$ 和 $\\tilde{f}_a$ 不仅仅是 $t$ 和 $f$ 的函数；它们关键地依赖于特定组的噪声率 $\\eta_a$ 和正例率 $\\pi_a$。如果各组间的噪声率不同（$\\eta_0 \\neq \\eta_1$）或正例率不同（$\\pi_0 \\neq \\pi_1$），那么即使真实率满足 EO（$t_0=t_1$ 且 $f_0=f_1$），观测率通常也不会相等。也就是说，$\\tilde{t}_0 \\neq \\tilde{t}_1$ 且 $\\tilde{f}_0 \\neq \\tilde{f}_1$。\n\n例如，$\\tilde{t}_a$ 可以解释为真实率 $t$ 和 $f$ 的加权平均值。权重由给定观测标签下真实标签的后验概率 $\\mathbb{P}(Y=y \\mid Y^{\\mathrm{obs}}=1, A=a)$ 决定，而这些后验概率本身依赖于 $\\eta_a$ 和 $\\pi_a$。\n具体来说，$\\tilde{t}_a = t_a \\cdot \\mathbb{P}(Y=1 \\mid Y^{\\mathrm{obs}}=1, A=a) + f_a \\cdot \\mathbb{P}(Y=0 \\mid Y^{\\mathrm{obs}}=1, A=a)$。$\\eta_a$ 和 $\\pi_a$ 的差异改变了混合中 $t_a$ 和 $f_a$ 的权重，导致不同组的观测率 $\\tilde{t}_a$ 不同。因此，在带噪声的数据 $Y^{\\mathrm{obs}}$ 上强制执行或评估 EO 是具有误导性的，并且不能保证分类器相对于真实标签 $Y$ 满足 EO。\n\n### 3. 通过噪声感知损失的去偏策略\n\n为了从带噪声的数据中获得对干净标签风险的无偏估计，我们可以使用修正后的损失函数。对于给定组 $a$ 和输出概率 $\\hat{p}$ 的分类器，其干净标签风险为 $R_a(\\hat{p}) = \\mathbb{E}_{X,Y \\mid A=a}[\\ell(\\hat{p}(X), Y)]$。带噪声的风险是 $\\tilde{R}_a(\\hat{p}) = \\mathbb{E}_{X,Y^{\\mathrm{obs}} \\mid A=a}[\\ell(\\hat{p}(X), Y^{\\mathrm{obs}})]$。我们寻求一个修正后的损失 $\\tilde{\\ell}(\\hat{p}, y^{\\mathrm{obs}}, a)$ 使得 $\\mathbb{E}_{X,Y^{\\mathrm{obs}} \\mid A=a}[\\tilde{\\ell}(\\hat{p}(X), Y^{\\mathrm{obs}}, a)] = R_a(\\hat{p})$。这个条件必须对任何分类器都成立，这要求对于任何给定的实例 $X$，条件期望都必须匹配：\n$$\n\\mathbb{E}_{Y^{\\mathrm{obs}} \\mid X, A=a}[\\tilde{\\ell}(\\hat{p}(X), Y^{\\mathrm{obs}}, a)] = \\mathbb{E}_{Y \\mid X, A=a}[\\ell(\\hat{p}(X), Y)]\n$$\n干净标签和带噪声标签分布之间的关系由损坏矩阵 $C_a$ 来刻画，其中 $(C_a)_{ij} = \\mathbb{P}(Y^{\\mathrm{obs}}=j \\mid Y=i, A=a)$，对于 $i,j \\in \\{0, 1\\}$。\n对于给定的对称噪声模型：\n$C_a(0,0) = 1-\\eta_a$, $C_a(0,1) = \\eta_a$, $C_a(1,0) = \\eta_a$, $C_a(1,1) = 1-\\eta_a$。\n所以，损坏矩阵是：\n$$\nC_a = \\begin{pmatrix} 1-\\eta_a  \\eta_a \\\\ \\eta_a  1-\\eta_a \\end{pmatrix}\n$$\n令 $\\mathbf{L} = (\\ell(\\hat{p}, 0), \\ell(\\hat{p}, 1))^\\top$ 为干净损失的向量，$\\tilde{\\mathbf{L}} = (\\tilde{\\ell}(\\hat{p}, 0, a), \\tilde{\\ell}(\\hat{p}, 1, a))^\\top$ 为修正后损失的向量。无偏风险条件简化为 $\\mathbf{L} = C_a^\\top \\tilde{\\mathbf{L}}$。由于 $C_a$ 是对称的，$C_a^\\top = C_a$，因此我们求解 $\\tilde{\\mathbf{L}} = C_a^{-1}\\mathbf{L}$。\n为了求逆矩阵，我们计算行列式：$\\det(C_a) = (1-\\eta_a)^2 - \\eta_a^2 = 1 - 2\\eta_a$。因为 $\\eta_a  1/2$，行列式非零。\n逆矩阵是：\n$$\nC_a^{-1} = \\frac{1}{1-2\\eta_a} \\begin{pmatrix} 1-\\eta_a  -\\eta_a \\\\ -\\eta_a  1-\\eta_a \\end{pmatrix}\n$$\n通过将此逆矩阵应用于干净损失向量来获得修正后的损失：\n$$\n\\begin{pmatrix} \\tilde{\\ell}(\\hat{p}, 0, a) \\\\ \\tilde{\\ell}(\\hat{p}, 1, a) \\end{pmatrix} = \\frac{1}{1-2\\eta_a} \\begin{pmatrix} (1-\\eta_a)\\ell(\\hat{p}, 0) - \\eta_a\\ell(\\hat{p}, 1) \\\\ -\\eta_a\\ell(\\hat{p}, 0) + (1-\\eta_a)\\ell(\\hat{p}, 1) \\end{pmatrix}\n$$\n我们可以使用观测标签 $y^{\\mathrm{obs}}$ 为 $\\tilde{\\ell}(\\hat{p}, y^{\\mathrm{obs}}, a)$ 写出一个单一的表达式：\n$$\n\\tilde{\\ell}(\\hat{p}, y^{\\mathrm{obs}}, a) = (1-y^{\\mathrm{obs}}) \\frac{(1-\\eta_a)\\ell(\\hat{p}, 0) - \\eta_a\\ell(\\hat{p}, 1)}{1-2\\eta_a} + y^{\\mathrm{obs}} \\frac{(1-\\eta_a)\\ell(\\hat{p}, 1) - \\eta_a\\ell(\\hat{p}, 0)}{1-2\\eta_a}\n$$\n在对带噪声的标签 $Y^{\\mathrm{obs}}$ 进行训练时使用这个修正后的损失，可以得到关于干净标签 $Y$ 的真实风险的无偏估计，前提是噪声率 $\\eta_a$ 已知或可以被准确估计。\n\n### 4. 最终答案的表述\n\n最后的任务是提供从 $(t_a, f_a)$ 到 $(\\tilde{t}_a, \\tilde{f}_a)$ 的映射，以单个行矩阵的形式表示。根据第一部分的推导，这个映射由我们为 $\\tilde{t}_a$ 和 $\\tilde{f}_a$ 找到的表达式给出。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{t_a(1-\\eta_a)\\pi_a + f_a\\eta_a(1-\\pi_a)}{(1-\\eta_a)\\pi_a + \\eta_a(1-\\pi_a)}  \\frac{t_a\\eta_a\\pi_a + f_a(1-\\eta_a)(1-\\pi_a)}{\\eta_a\\pi_a + (1-\\eta_a)(1-\\pi_a)}\n\\end{pmatrix}\n}\n$$", "id": "3098319"}]}