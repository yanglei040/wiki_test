{"hands_on_practices": [{"introduction": "理论是基础，但真正的理解源于实践。在本节中，我们将通过一系列动手练习来巩固和拓展我们对排列特征重要性（Permutation Feature Importance, PFI）的理解。第一个练习将PFI应用于一个至关重要且普遍存在的数据科学问题：数据泄漏。我们将学习如何通过编程构建一个包含“泄漏”特征的场景，并利用PFI来识别这个异常的预测因子，这对于建立稳健和可靠的模型至关重要。[@problem_id:3156657]", "problem": "您必须编写一个完整、可运行的程序，该程序构建包含和不包含标签泄漏的合成数据集，并使用置换特征重要性 (Permutation Feature Importance, PFI) 来检测可疑特征。该程序必须从基本原理出发实现所有计算，从平方损失下的经验风险开始，且不得依赖任何外部机器学习库。程序将执行一个小型测试套件的参数设置，并输出一行收集到的检测结果。\n\n背景和基本原理：从平方损失下的经验风险最小化开始。对于一个特征矩阵 $X \\in \\mathbb{R}^{n \\times d}$ 和目标向量 $y \\in \\mathbb{R}^{n}$，数据集上的平方损失是由均方误差 (Mean Squared Error, MSE) 定义的经验风险，对于预测值 $\\hat{y}$，其定义为 $ \\frac{1}{n} \\sum_{i=1}^{n} (y_i - \\hat{y}_i)^2 $。通过普通最小二乘法 (Ordinary Least Squares, OLS) 或使用少量 $\\ell_2$ 正则化项的数值稳定变体，最小化经验平方损失来拟合线性预测器。通过量化在保持模型固定的情况下，当单个特征被随机置換时经验风险的变化来估计该特征的 PFI。\n\n数据生成：对于每个测试用例，生成一个包含 $n_{\\text{train}} = 800$ 个样本的训练集和一个包含 $n_{\\text{test}} = 200$ 个样本的测试集。对于训练集和测试集，从标准正态分布 $ \\mathcal{N}(0,1) $ 中独立抽取基本特征 $X_1, X_2, X_3$。生成目标 $ y = 3 X_1 - 2 X_2 + \\epsilon $，其中包含独立噪声 $ \\epsilon \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2) $，且 $ \\sigma_\\epsilon = 0.5 $。定义泄漏特征 $ X_{\\text{leak}} = y + \\delta $，其中 $ \\delta \\sim \\mathcal{N}(0, \\sigma_\\delta^2) $ 且 $ \\sigma_\\delta = \\gamma \\cdot \\operatorname{std}(y_{\\text{train}}) $。在这里，$ \\gamma \\ge 0 $ 是一个控制泄漏强度的测试用例参数。在“无泄漏”条件下，不使用 $ X_{\\text{leak}} = y + \\delta $，而是将 $ X_{\\text{leak}} $ 构建为一个独立的、均值为零、标准差等于 $ \\operatorname{std}(y_{\\text{train}}) $ 的正态特征，且与 $ y $ 无关。用列 $ [X_1, X_2, X_3, X_{\\text{leak}}] $ 构成完整的特征矩阵。\n\n模型拟合：通过最小化训练集上的经验平方损失来拟合线性模型 $ \\hat{y} = X w $。使用一个小的 $\\ell_2$ 正则化（岭回归），系数为 $ \\lambda = 10^{-6} $，以确保数值稳定性。计算测试集上的基线 MSE。\n\nPFI 估计：对于每个特征索引 $ j \\in \\{0,1,2,3\\} $，通过重复地仅置换测试特征矩阵的第 $ j $ 列，同时保持训练好的模型不变，重新计算测试 MSE，并对相对于基线的 MSE 增量进行平均，从而估计其 PFI。每个特征使用 $ B = 30 $ 次独立置换进行平均。程序中所有的随机性必须由一个固定的种子控制，以确保可复现性。\n\n可疑特征标记：为进行泄漏检测，定义两个阈值。设 $ \\Delta_j $ 表示特征 $ j $ 的估计 PFI，设 $ \\Delta_{\\text{leak}} $ 为泄漏特征的 PFI。设 $ \\Delta_{\\max,\\neg\\text{leak}} $ 为所有非泄漏特征中的最大 PFI。如果同时满足以下两个条件，则声明泄漏特征为可疑：\n- 绝对风险标准：$ \\Delta_{\\text{leak}} \\ge \\tau \\cdot \\text{MSE}_{\\text{baseline}} $，\n- 相对优势标准：$ \\Delta_{\\text{leak}} \\ge \\alpha \\cdot \\Delta_{\\max,\\neg\\text{leak}} $。\n这里 $ \\tau > 0 $ 和 $ \\alpha > 1 $ 是测试用例的参数。\n\n测试套件：针对以下四个参数集运行程序，其中每个集合是一个元组 $ (\\gamma, \\text{has\\_leak}, \\tau, \\alpha) $：\n- 情况 1：$ (\\gamma = 0.0, \\text{has\\_leak} = 1, \\tau = 1.0, \\alpha = 2.0) $。\n- 情况 2：$ (\\gamma = 0.2, \\text{has\\_leak} = 1, \\tau = 1.0, \\alpha = 2.0) $。\n- 情况 3：$ (\\gamma = 4.0, \\text{has\\_leak} = 1, \\tau = 1.0, \\alpha = 2.0) $。\n- 情况 4：$ (\\gamma = 0.0, \\text{has\\_leak} = 0, \\tau = 1.0, \\alpha = 2.0) $。\n\n对于每种情况，输出一个布尔值，指示泄漏特征是否被标记为可疑。在整个程序中使用单一固定的随机种子以保证可复现性。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按测试套件用例的顺序显示结果（例如，$[r_1,r_2,r_3,r_4]$，其中每个 $ r_i $ 是一个布尔值）。除了这一行之外，不得有任何额外的输出或空白字符。", "solution": "该问题被评估为有效，因为它在科学上基于统计学习理论，定义完整且一致，问题阐述清晰，并且表述客观。我们将着手构建一个解决方案。\n\n目标是从基本原理出发，实现一个使用置换特征重要性 (Permutation Feature Importance, PFI) 检测数据泄漏的程序。这包括数据合成、模型拟合和重要性估计，最终形成一个用于标记可疑特征的决策规则。\n\n### 1. 数据生成\n\n我们首先合成数据集。对于每个测试用例，我们生成一个大小为 $n_{\\text{train}} = 800$ 的训练集和一个大小为 $n_{\\text{test}} = 200$ 的测试集。过程如下：\n\n- **基本特征**：三个独立的基本特征 $X_1$、$X_2$ 和 $X_3$ 从标准正态分布 $\\mathcal{N}(0,1)$ 中抽取。我们为每个特征生成 $n_{\\text{train}} + n_{\\text{test}} = 1000$ 个样本，然后将它们划分为训练集和测试集。设基本特征矩阵为 $X_{\\text{base, train}} \\in \\mathbb{R}^{800 \\times 3}$ 和 $X_{\\text{base, test}} \\in \\mathbb{R}^{200 \\times 3}$。\n\n- **目标变量**：目标变量 $y$ 是前两个基本特征的线性组合，并加入了高斯噪声。关系如下：\n$$ y = 3 X_1 - 2 X_2 + \\epsilon $$\n其中噪声项 $\\epsilon$ 从 $\\mathcal{N}(0, \\sigma_\\epsilon^2)$ 中抽取，且 $\\sigma_\\epsilon = 0.5$。目标向量 $y_{\\text{train}}$ 和 $y_{\\text{test}}$ 使用相应的特征和噪声样本生成。\n\n- **泄漏特征**：第四个特征 $X_{\\text{leak}}$ 在由 `has_leak` 参数指定的两种不同条件下构建：\n    1.  **有泄漏 (`has_leak = 1`)**：该特征是目标变量的一个直接的、带噪声的副本：\n        $$ X_{\\text{leak}} = y + \\delta $$\n        噪声 $\\delta$ 从正态分布 $\\mathcal{N}(0, \\sigma_\\delta^2)$ 中抽取，其中标准差 $\\sigma_\\delta$ 是训练集中目标变量标准差和泄漏强度参数 $\\gamma$ 的函数：\n        $$ \\sigma_\\delta = \\gamma \\cdot \\operatorname{std}(y_{\\text{train}}) $$\n        较小的 $\\gamma$ 意味着更强的泄漏。$\\gamma=0$ 表示完美泄漏，此时 $X_{\\text{leak}} = y$。\n    2.  **无泄漏 (`has_leak = 0`)**：该特征独立于目标 $y$ 生成。它从一个均值为 $0$、标准差等于训练目标变量标准差的正态分布中抽取：\n        $$ X_{\\text{leak}} \\sim \\mathcal{N}(0, (\\operatorname{std}(y_{\\text{train}}))^2) $$\n        此设计确保 $X_{\\text{leak}}$ 的边际分布与目标的尺度相似，使其成为一个合理但无泄漏的特征。\n\n- **最终特征矩阵**：通过将基本特征与泄漏特征拼接，形成完整的特征矩阵 $X_{\\text{train}}$ 和 $X_{\\text{test}}$，得到具有四列的矩阵：$[X_1, X_2, X_3, X_{\\text{leak}}]$。\n\n### 2. 模型拟合：岭回归\n\n一个线性模型 $\\hat{y} = Xw$ 被拟合到训练数据上。权重向量 $w \\in \\mathbb{R}^4$ 通过最小化带有少量 $\\ell_2$ 正则化项（岭回归）的经验平方损失来确定，以确保数值稳定性。训练数据上的目标函数 $J(w)$ 为：\n$$ J(w) = \\frac{1}{n_{\\text{train}}} \\| y_{\\text{train}} - X_{\\text{train}}w \\|_2^2 + \\lambda \\|w\\|_2^2 $$\n其中 $\\lambda = 10^{-6}$ 是正则化系数。通过将梯度 $\\nabla_w J(w)$ 设为零，可以找到最优权重向量 $w$ 的解析解：\n$$ \\nabla_w J(w) = \\frac{2}{n_{\\text{train}}} X_{\\text{train}}^T (X_{\\text{train}}w - y_{\\text{train}}) + 2\\lambda w = 0 $$\n$$ (X_{\\text{train}}^T X_{\\text{train}} + n_{\\text{train}}\\lambda I)w = X_{\\text{train}}^T y_{\\text{train}} $$\n这得到了解：\n$$ w = (X_{\\text{train}}^T X_{\\text{train}} + n_{\\text{train}}\\lambda I)^{-1} X_{\\text{train}}^T y_{\\text{train}} $$\n其中 $I$ 是 $4 \\times 4$ 的单位矩阵。\n\n### 3. 置换特征重要性 (PFI)\n\nPFI 通过量化当特征值被随机打乱时模型性能的下降来衡量特征的重要性。这种打乱操作破坏了特征与目标变量之间的关系。\n\n- **基线分数**：首先，我们计算训练好的模型在未经修改的测试集上的基线均方误差 (MSE)：\n$$ \\text{MSE}_{\\text{baseline}} = \\frac{1}{n_{\\text{test}}} \\sum_{i=1}^{n_{\\text{test}}} (y_{\\text{test},i} - (X_{\\text{test}}w)_i)^2 $$\n\n- **置换后分数**：对于每个特征 $j \\in \\{0, 1, 2, 3\\}$，我们执行以下过程 $B=30$ 次：\n    1.  通过随机打乱 $X_{\\text{test}}$ 的第 $j$ 列来创建一个置换后的测试矩阵 $X_{\\text{test}}^{(j,b)}$。\n    2.  用这个置换后的矩阵计算 MSE：$\\text{MSE}^{(j,b)} = \\frac{1}{n_{\\text{test}}} \\| y_{\\text{test}} - X_{\\text{test}}^{(j,b)}w \\|_2^2$。\n\n- **PFI 计算**：特征 $j$ 的 PFI，记为 $\\Delta_j$，是所有置换中 MSE相对于基线 MSE 的平均增量：\n$$ \\Delta_j = \\left( \\frac{1}{B} \\sum_{b=1}^{B} \\text{MSE}^{(j,b)} \\right) - \\text{MSE}_{\\text{baseline}} $$\n一个大的正值 $\\Delta_j$ 表明模型在预测时严重依赖特征 $j$。\n\n### 4. 泄漏检测\n\n任务的核心是利用计算出的 PFI 分数来标记泄漏特征（$j=3$）为可疑。一个特征如果不仅重要，而且与其他信息丰富的特征相比，其重要性不成比例地高，则被认为是可疑的。这通过两个标准来形式化：\n\n-   **绝对风险标准**：泄漏特征的 PFI，$\\Delta_{\\text{leak}} = \\Delta_3$，必须超过一个与基线模型误差成比例的阈值。这确保了特征的影响在绝对意义上是显著的。\n    $$ \\Delta_{\\text{leak}} \\ge \\tau \\cdot \\text{MSE}_{\\text{baseline}} $$\n-   **相对优势标准**：泄漏特征的 PFI 必须显著大于任何非泄漏特征的最大 PFI，$\\Delta_{\\max,\\neg\\text{leak}} = \\max(\\Delta_0, \\Delta_1, \\Delta_2)$。这可以识别出那些可疑地占主导地位的特征。\n    $$ \\Delta_{\\text{leak}} \\ge \\alpha \\cdot \\Delta_{\\max,\\neg\\text{leak}} $$\n\n当且仅当两个条件都满足时，泄漏特征才被标记。参数 $\\tau$ 和 $\\alpha$ 控制检测逻辑的灵敏度，并为每个测试用例提供。这种双阈值方法有助于区分真正的泄漏特征和那些仅仅是强大但合法的预测因子。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs synthetic datasets, fits a linear model, and uses Permutation\n    Feature Importance (PFI) to detect a suspicious leakage feature based on\n    pre-defined criteria. The implementation is from first principles.\n    \"\"\"\n    \n    # Set a single fixed random seed for reproducibility across the entire program.\n    np.random.seed(42)\n    rng = np.random.default_rng(42)\n\n    # Test suite parameters: (gamma, has_leak, tau, alpha)\n    test_cases = [\n        (0.0, 1, 1.0, 2.0),\n        (0.2, 1, 1.0, 2.0),\n        (4.0, 1, 1.0, 2.0),\n        (0.0, 0, 1.0, 2.0),\n    ]\n\n    results = []\n\n    for case_params in test_cases:\n        gamma, has_leak, tau, alpha = case_params\n\n        # --- 1. Data Generation ---\n        n_train = 800\n        n_test = 200\n        n_total = n_train + n_test\n        sigma_eps = 0.5\n\n        # Base features X1, X2, X3 from N(0,1)\n        X_base_all = rng.standard_normal(size=(n_total, 3))\n        X_base_train = X_base_all[:n_train, :]\n        X_base_test = X_base_all[n_train:, :]\n\n        # Target variable y = 3*X1 - 2*X2 + noise\n        epsilon = rng.normal(loc=0.0, scale=sigma_eps, size=n_total)\n        y_all = 3 * X_base_all[:, 0] - 2 * X_base_all[:, 1] + epsilon\n        y_train = y_all[:n_train]\n        y_test = y_all[n_train:]\n        \n        y_train_std = np.std(y_train)\n\n        # Leakage feature X_leak\n        if has_leak:\n            # X_leak = y + delta\n            sigma_delta = gamma * y_train_std\n            delta = rng.normal(loc=0.0, scale=sigma_delta, size=n_total)\n            X_leak_all = y_all + delta\n        else:\n            # X_leak is independent N(0, std(y_train)^2)\n            X_leak_all = rng.normal(loc=0.0, scale=y_train_std, size=n_total)\n        \n        X_leak_train = X_leak_all[:n_train].reshape(-1, 1)\n        X_leak_test = X_leak_all[n_train:].reshape(-1, 1)\n\n        # Final feature matrices\n        X_train = np.hstack([X_base_train, X_leak_train])\n        X_test = np.hstack([X_base_test, X_leak_test])\n        \n        # --- 2. Model Fitting (Ridge Regression) ---\n        lambda_reg = 1e-6\n        n_features = X_train.shape[1]\n        \n        XTX = X_train.T @ X_train\n        I = np.identity(n_features)\n        # w = (X'X + n_train * lambda * I)^-1 * X'y\n        weights = np.linalg.inv(XTX + n_train * lambda_reg * I) @ X_train.T @ y_train\n\n        # --- 3. PFI Estimation ---\n        B = 30  # Number of permutations\n        \n        # Baseline MSE on test set\n        y_pred_baseline = X_test @ weights\n        mse_baseline = np.mean((y_test - y_pred_baseline)**2)\n        \n        pfi_scores = []\n        for j in range(n_features):\n            permuted_mses = []\n            for _ in range(B):\n                X_test_permuted = X_test.copy()\n                col_to_permute = X_test_permuted[:, j].copy()\n                rng.shuffle(col_to_permute)\n                X_test_permuted[:, j] = col_to_permute\n                \n                y_pred_permuted = X_test_permuted @ weights\n                mse_permuted = np.mean((y_test - y_pred_permuted)**2)\n                permuted_mses.append(mse_permuted)\n            \n            mean_permuted_mse = np.mean(permuted_mses)\n            pfi_j = mean_permuted_mse - mse_baseline\n            pfi_scores.append(pfi_j)\n\n        # --- 4. Leakage Detection ---\n        pfi_leak_feature = pfi_scores[3]\n        # Handle case where all non-leak PFIs are negative\n        pfi_non_leak_scores = pfi_scores[:3]\n        pfi_max_non_leak = np.max(pfi_non_leak_scores) if pfi_non_leak_scores else 0.0\n\n        # Absolute-risk criterion\n        abs_risk_cond = (pfi_leak_feature >= tau * mse_baseline)\n        \n        # Relative-dominance criterion\n        rel_dom_cond = (pfi_leak_feature >= alpha * pfi_max_non_leak)\n        \n        is_suspicious = abs_risk_cond and rel_dom_cond\n        results.append(str(is_suspicious))\n\n    # Final output must be a single line in the specified format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3156657"}, {"introduction": "全局特征重要性告诉我们一个特征在整体上的影响力，但这可能会掩盖更复杂的模式。在第二个练习中，我们将探索一个更高级的概念：条件特征重要性。通过将数据分层并计算每个子集内的PFI，我们可以揭示一个特征的重要性是如何随另一个特征的值而变化的，从而深入理解特征间的交互作用。[@problem_id:3156620]", "problem": "您将实现分层置换特征重要性（Permutation Feature Importance, PFI），以研究在另一个特征的分位数定义的分层中，一个特征的条件重要性。此项任务的基础是在指定损失函数下预期预测误差的定义及其经验近似。您将依赖以下要素。\n\n1. 损失与风险。设损失函数为平方误差损失，定义为 $L(y, \\hat{y}) = (y - \\hat{y})^2$。预期预测误差（风险）定义为 $R = \\mathbb{E}[L(Y, \\hat{f}(X))]$，我们用有限样本上的经验均值来近似它。\n\n2. 置换特征重要性（PFI）。对于一个给定的已训练预测器 $\\hat{f}$ 和目标特征 $X_j$，在特定损失函数下，$X_j$ 的PFI定义为：通过随机置换 $X_j$ 的值来打破 $X_j$ 与响应变量之间的关联后，风险的增加量。在此过程中，所有其他特征保持不变，从而保留了 $X_j$ 的边际分布。该过程利用了在 $X_j$ 的置换下，所有其他特征与标签的联合分布的不变性。\n\n3. 分层PFI。为分析条件重要性，您将在由另一特征 $X_k$ 的分位数区间定义的分层内执行PFI。具体来说，您将：\n   - 使用 $X_k$ 在概率 $0, \\frac{1}{Q}, \\ldots, 1$ 处的经验分位数，将测试数据划分为 $Q$ 个区间。\n   - 在每个区间内，计算基线经验误差，然后在仅在该区间内置换 $X_j$ 后计算经验误差（以保留该分层中 $X_k$ 的条件分布）。\n   - 对于区间 $b$，$b$ 的分层PFI是在该区间内置换后的经验误差与基线经验误差之差，并在多次独立置换上取平均值。\n\n您的程序必须实现以下端到端的流程：\n\nA. 数据生成。对于每个测试用例，从模型\n$$\nY = \\alpha + a\\,X_j + b\\,X_k + c\\,(X_j X_k) + \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, \\sigma^2),\n$$\n中模拟独立同分布的样本 $(X_j, X_k, Y)$，其中 $(X_j, X_k)$ 服从联合高斯分布，均值为零，方差为单位方差，相关系数为 $\\rho$。为生成具有指定相关系数 $\\rho$ 的一对变量，抽取独立的 $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$，并设置 $X_k = Z_2$ 和 $X_j = \\rho Z_2 + \\sqrt{1-\\rho^2}\\, Z_1$。使用 $n_{\\text{train}}$ 个样本进行训练，使用 $n_{\\text{test}}$ 个样本进行测试。\n\nB. 模型拟合。使用普通最小二乘法（Ordinary Least Squares, OLS）拟合一个线性模型 $\\hat{f}$，该模型包含一个截距项和三个原始特征：\n$$\n\\phi(X_j, X_k) = \\big[1,\\; X_j,\\; X_k,\\; X_j X_k\\big].\n$$\n在训练集上进行训练，以获得系数向量 $\\hat{w}$，使得\n$$\n\\hat{f}(X_j, X_k) = \\hat{w}_0 + \\hat{w}_1 X_j + \\hat{w}_2 X_k + \\hat{w}_3 (X_j X_k).\n$$\n\nC. 在测试集上，在 $X_k$ 的分位数区间内进行分层PFI。对于固定的区间数 $Q$，在测试集上计算 $X_k$ 在概率 $0, \\frac{1}{Q}, \\ldots, 1$ 处的经验分位数，形成 $Q$ 个连续的区间。在区间 $q$ 中，执行以下操作：\n   - 计算该区间内的基线均方误差（Mean Squared Error, MSE）：\n     $$\n     \\text{MSE}_{\\text{base}, q} = \\frac{1}{m_q} \\sum_{i \\in \\text{bin } q} \\big(Y_i - \\hat{f}(X_{j,i}, X_{k,i})\\big)^2,\n     $$\n     其中 $m_q$ 是区间 $q$ 中的测试样本数量。\n   - 对于 $R$ 次独立重复，随机置换区间 $q$ 内样本的 $X_j$ 值，使用置换后的 $X_j$ 和未改变的 $X_k$ 在模型 $\\hat{f}$ 中重新计算预测值，并记录该区间内置换后的均方误差 $\\text{MSE}_{\\text{perm}, q}^{(r)}$。\n   - 区间 $q$ 的分层PFI为\n     $$\n     I_q = \\left(\\frac{1}{R} \\sum_{r=1}^R \\text{MSE}_{\\text{perm}, q}^{(r)} \\right) - \\text{MSE}_{\\text{base}, q}.\n     $$\n\nD. 输出。对于每个测试用例，输出列表 $[I_1, I_2, \\ldots, I_Q]$，并四舍五入到3位小数。将所有测试用例的输出聚合到一行，格式化为Python风格的列表的列表。例如，最后一行应如下所示 $[[i_{1,1},\\ldots,i_{1,Q}], [i_{2,1},\\ldots,i_{2,Q}], \\ldots]$。\n\n实现细节和约束：\n\n- 使用平方误差损失 $L(y, \\hat{y}) = (y - \\hat{y})^2$。\n- 在测试集上，使用由 $X_k$ 的经验四分位数定义的 $Q = 4$ 个区间。区间的左边界是包含性的，对于最后一个区间，右边界也应包含在内，以覆盖所有测试点。\n- 每个区间使用 $R = 128$ 次独立置换。\n- 使用 $n_{\\text{train}} = 3000$ 和 $n_{\\text{test}} = 1500$。\n- 为保证数值稳定性，您可以通过最小二乘例程来求解OLS问题。\n- 随机性与可复现性：\n  - 对于测试用例索引 $i \\in \\{0,1,2,3\\}$，使用种子 $s_{\\text{train}} = 1234 + 100 i$ 生成训练数据，使用种子 $s_{\\text{test}} = 5678 + 100 i$ 生成测试数据，并使用种子 $s_{\\text{perm}} = 91011 + 100 i$ 用于置换的随机性。\n- 四舍五入与格式化：\n  - 在输出前，将每个特定于区间的重要性 $I_q$ 四舍五入到3位小数。\n  - 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，不含任何额外文本。\n\n测试套件规范：\n\n提供以下四个测试用例的结果，每个用例由 $(\\alpha, a, b, c, \\sigma, \\rho)$ 定义：\n\n- 用例1：$(\\alpha, a, b, c, \\sigma, \\rho) = (0.0, 1.0, 0.5, 1.0, 0.3, 0.4)$。\n- 用例2：$(\\alpha, a, b, c, \\sigma, \\rho) = (0.0, 1.0, 0.5, 0.0, 0.3, 0.4)$。\n- 用例3：$(\\alpha, a, b, c, \\sigma, \\rho) = (0.0, 1.0, 0.5, -1.0, 0.3, 0.4)$。\n- 用例4：$(\\alpha, a, b, c, \\sigma, \\rho) = (0.0, 0.0, 1.0, 0.0, 0.3, 0.0)$。\n\n给开发者的说明：\n\n- 按描述实现完整的流程。\n- 不要读取任何输入；所有参数均按上述规定固定。\n- 最终输出必须是严格符合指定格式的单行文本，例如：$[[0.123,0.234,0.345,0.456],[\\ldots],\\ldots]$。", "solution": "该问题是有效的。这是一个适定（well-posed）且具有科学依据的计算统计学任务，要求实现分层置换特征重要性（PFI）。所有参数、模型和过程都得到了清晰且一致的定义。\n\n在此，我们详细说明计算分层PFI的逐步过程。\n\n### A. 数据生成\n\n第一步是模拟训练和测试数据集。对于由参数集 $(\\alpha, a, b, c, \\sigma, \\rho)$ 指定的四个测试用例中的每一个，我们生成两个独立的数据集：一个大小为 $n_{\\text{train}} = 3000$ 的训练集和一个大小为 $n_{\\text{test}} = 1500$ 的测试集。每个样本由一个三元组 $(X_j, X_k, Y)$ 组成。\n\n特征 $(X_j, X_k)$ 从一个二元高斯分布中抽取，该分布具有零均值、单位方差和指定的相关系数 $\\rho$。这通过首先生成两个独立的标准正态变量 $Z_1, Z_2 \\sim \\mathcal{N}(0,1)$，然后如下构造相关变量来实现：\n$$\nX_k = Z_2\n$$\n$$\nX_j = \\rho Z_2 + \\sqrt{1-\\rho^2}\\, Z_1\n$$\n这种构造确保了 $\\mathbb{E}[X_j] = \\mathbb{E}[X_k] = 0$，$\\text{Var}[X_j] = \\text{Var}[X_k] = 1$ 以及 $\\text{Cov}[X_j, X_k] = \\rho$。\n\n响应变量 $Y$ 是从真实的结构模型生成的，该模型包含每个特征的主效应和一个交互项：\n$$\nY = \\alpha + a\\,X_j + b\\,X_k + c\\,(X_j X_k) + \\varepsilon\n$$\n噪声项 $\\varepsilon$ 从一个均值为零、方差为 $\\sigma^2$ 的正态分布中抽取，即 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^2)$。\n\n为确保可复现性，对于由索引 $i \\in \\{0, 1, 2, 3\\}$ 标记的每个测试用例，都使用不同的种子来初始化用于训练数据生成（$s_{\\text{train}}$）、测试数据生成（$s_{\\text{test}}$）和置换过程（$s_{\\text{perm}}$）的独立随机数生成器。\n\n### B. 模型拟合\n\n下一步是将一个预测模型 $\\hat{f}$ 拟合到生成的训练数据上。指定的模型是一个线性回归模型，其特征包括一个截距项、两个原始预测变量及其交互项。特征向量由 $\\phi(X_j, X_k) = [1, X_j, X_k, X_j X_k]$ 给出。该模型的功能形式为：\n$$\n\\hat{f}(X_j, X_k) = \\hat{w}_0 + \\hat{w}_1 X_j + \\hat{w}_2 X_k + \\hat{w}_3 (X_j X_k)\n$$\n系数向量 $\\hat{w} = [\\hat{w}_0, \\hat{w}_1, \\hat{w}_2, \\hat{w}_3]^T$ 是使用普通最小二乘法（OLS）确定的。这涉及找到使训练集上平方误差和最小化的 $\\hat{w}$。解决方案通过求解线性系统 $\\Phi_{\\text{train}}^T \\Phi_{\\text{train}} \\hat{w} = \\Phi_{\\text{train}}^T Y_{\\text{train}}$ 获得，其中 $\\Phi_{\\text{train}}$ 是由训练数据构建的 $n_{\\text{train}} \\times 4$ 设计矩阵。为了数值稳定性，这是通过使用像 `numpy.linalg.lstsq` 这样的最小二乘求解器来实现的。\n\n### C. 分层置换特征重要性（PFI）\n\n任务的核心是计算特征 $X_j$ 在特征 $X_k$ 的值条件下的PFI。此操作在测试集上执行。\n\n1.  **分层：** 测试数据基于 $X_k$ 的值被划分为 $Q=4$ 个不相交的区间（层）。这些区间由测试集中 $X_k$ 的经验四分位数定义。具体来说，我们找到对应于概率 $\\{0.25, 0.50, 0.75\\}$ 的分位数，这些值作为四个区间的边界。这将数据划分为四个大小近似相等的组。\n\n2.  **区间内PFI计算：** 对于每个区间 $q \\in \\{1, 2, 3, 4\\}$，我们按如下方式计算重要性分数 $I_q$：\n    *   **基线误差：** 首先，我们使用原始、未置换的数据计算区间 $q$ 内样本的基线均方误差（$\\text{MSE}$）。设 $S_q$ 为区间 $q$ 中样本的索引集合，并设 $m_q = |S_q|$ 为该区间中的样本数。基线误差为：\n        $$\n        \\text{MSE}_{\\text{base}, q} = \\frac{1}{m_q} \\sum_{i \\in S_q} \\big(Y_i - \\hat{f}(X_{j,i}, X_{k,i})\\big)^2\n        $$\n    *   **置换后误差：** 接下来，我们衡量在*该分层内*打破 $X_j$ 和 $Y$ 之间关联的影响。这是通过仅在区间 $q$ 的样本中重复置换 $X_j$ 的值来完成的。此过程对 $R=128$ 次独立置换进行重复。对于每次置换 $r \\in \\{1, \\ldots, R\\}$，我们获得一个置换后的特征向量 $X_{j, \\text{perm}}^{(r)}$ 并计算相应的均方误差：\n        $$\n        \\text{MSE}_{\\text{perm}, q}^{(r)} = \\frac{1}{m_q} \\sum_{i \\in S_q} \\big(Y_i - \\hat{f}(X_{j, \\text{perm}, i}^{(r)}, X_{k,i})\\big)^2\n        $$\n    *   **重要性分数：** 置换后的误差在 $R$ 次重复中取平均值。区间 $q$ 的分层PFI是误差的增加量，定义为平均置换均方误差与基线均方误差之间的差值：\n        $$\n        I_q = \\left(\\frac{1}{R} \\sum_{r=1}^R \\text{MSE}_{\\text{perm}, q}^{(r)} \\right) - \\text{MSE}_{\\text{base}, q}\n        $$\n\n### D. 输出生成\n\n对四个指定的测试用例中的每一个都执行上述过程。对于每个用例，结果是一个包含四个重要性分数的列表 $[I_1, I_2, I_3, I_4]$，其中每个 $I_q$ 都四舍五入到3位小数。最终输出是这些结果的聚合，形成一个Python风格的列表的列表，并格式化为字符串。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the complete pipeline for stratified Permutation Feature Importance.\n    \"\"\"\n\n    # --- Problem Parameters ---\n    Q = 4  # Number of quantile bins\n    R = 128  # Number of permutations per bin\n    n_train = 3000\n    n_test = 1500\n\n    test_cases = [\n        # Case 1: (alpha, a, b, c, sigma, rho)\n        (0.0, 1.0, 0.5, 1.0, 0.3, 0.4),\n        # Case 2: No interaction term\n        (0.0, 1.0, 0.5, 0.0, 0.3, 0.4),\n        # Case 3: Negative interaction term\n        (0.0, 1.0, 0.5, -1.0, 0.3, 0.4),\n        # Case 4: No effect from X_j and no correlation\n        (0.0, 0.0, 1.0, 0.0, 0.3, 0.0),\n    ]\n\n    all_results = []\n\n    for i, params in enumerate(test_cases):\n        alpha, a, b, c, sigma, rho = params\n\n        # --- A. Data Generation ---\n        # Set up random number generators for reproducibility\n        s_train = 1234 + 100 * i\n        s_test = 5678 + 100 * i\n        s_perm = 91011 + 100 * i\n        rng_train = np.random.default_rng(s_train)\n        rng_test = np.random.default_rng(s_test)\n        rng_perm = np.random.default_rng(s_perm)\n\n        # Generate training data\n        Z1_train = rng_train.normal(size=n_train)\n        Z2_train = rng_train.normal(size=n_train)\n        Xk_train = Z2_train\n        Xj_train = rho * Z2_train + np.sqrt(1 - rho**2) * Z1_train\n        eps_train = rng_train.normal(loc=0, scale=sigma, size=n_train)\n        Y_train = alpha + a * Xj_train + b * Xk_train + c * (Xj_train * Xk_train) + eps_train\n\n        # Generate test data\n        Z1_test = rng_test.normal(size=n_test)\n        Z2_test = rng_test.normal(size=n_test)\n        Xk_test = Z2_test\n        Xj_test = rho * Z2_test + np.sqrt(1 - rho**2) * Z1_test\n        eps_test = rng_test.normal(loc=0, scale=sigma, size=n_test)\n        Y_test = alpha + a * Xj_test + b * Xk_test + c * (Xj_test * Xk_test) + eps_test\n\n        # --- B. Model Fitting ---\n        # Construct design matrix for training: [1, Xj, Xk, Xj*Xk]\n        Phi_train = np.c_[np.ones(n_train), Xj_train, Xk_train, Xj_train * Xk_train]\n        \n        # Solve OLS to get model weights\n        w_hat, _, _, _ = np.linalg.lstsq(Phi_train, Y_train, rcond=None)\n\n        def predict(Xj, Xk, weights):\n            \"\"\"Makes predictions using the fitted linear model.\"\"\"\n            Phi = np.c_[np.ones(len(Xj)), Xj, Xk, Xj * Xk]\n            return Phi @ weights\n\n        def mean_squared_error(y_true, y_pred):\n            \"\"\"Computes the mean squared error.\"\"\"\n            return np.mean((y_true - y_pred)**2)\n\n        # --- C. Stratified PFI ---\n        # Define strata based on Xk_test quantiles\n        quantile_boundaries = np.quantile(Xk_test, [0.25, 0.5, 0.75])\n        bin_indices = np.digitize(Xk_test, bins=quantile_boundaries)\n\n        case_importances = []\n        for q in range(Q):\n            in_bin_mask = (bin_indices == q)\n            \n            # Skip if a bin is empty (unlikely for this data size)\n            if not np.any(in_bin_mask):\n                case_importances.append(0.0)\n                continue\n\n            Xj_bin = Xj_test[in_bin_mask]\n            Xk_bin = Xk_test[in_bin_mask]\n            Y_bin = Y_test[in_bin_mask]\n\n            # Compute baseline MSE in the bin\n            Y_pred_base = predict(Xj_bin, Xk_bin, w_hat)\n            mse_base = mean_squared_error(Y_bin, Y_pred_base)\n            \n            # Compute permuted MSEs over R repetitions\n            permuted_mses = []\n            for _ in range(R):\n                Xj_perm = rng_perm.permutation(Xj_bin)\n                Y_pred_perm = predict(Xj_perm, Xk_bin, w_hat)\n                mse_perm = mean_squared_error(Y_bin, Y_pred_perm)\n                permuted_mses.append(mse_perm)\n            \n            # Calculate importance score for the bin\n            avg_mse_perm = np.mean(permuted_mses)\n            importance_q = avg_mse_perm - mse_base\n            case_importances.append(round(importance_q, 3))\n        \n        all_results.append(case_importances)\n\n    # --- D. Output ---\n    # Format the results into a single string: [[...],[...],...]\n    inner_strings = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_string = f\"[{','.join(inner_strings)}]\"\n    print(final_string)\n\nsolve()\n```", "id": "3156620"}, {"introduction": "特征重要性的评估并非绝对，它与我们选择的性能度量标准密切相关。最后一个练习将探讨PFI在不同评估指标（如AUC、对数损失和F1分数）下的表现，特别是在存在类别不平衡的情况下。通过这个练习，我们将看到不同指标如何导致不同的重要性排序，从而培养在实际应用中批判性选择和解释PFI结果的能力。[@problem_id:3156641]", "problem": "您必须编写一个完整、可运行的程序，以实证方式检验置换特征重要性在二元分类中如何响应类别不平衡。该研究必须通过在具有倾斜类别先验 $p(y)$ 的合成数据上训练一个概率分类器，然后在三种不同的指标下评估置换特征重要性来进行：受试者工作特征曲线下面积 (AUC)、对数损失 (log-loss) 和 F1 分数。\n\n请从以下基本定义开始。\n\n- 二元分类设置：令 $(\\mathbf{x}_i, y_i)$（其中 $i \\in \\{1,\\dots,n\\}$）为独立同分布的样本，其特征为 $\\mathbf{x}_i \\in \\mathbb{R}^d$，二元标签为 $y_i \\in \\{0,1\\}$，从一个联合分布中抽取，该分布的类别先验为 $p(y=1) = \\pi \\in (0,1)$。\n- 逻辑回归模型：一个带有参数 $\\mathbf{w} \\in \\mathbb{R}^{d+1}$ 的概率分类器将一个增广特征向量 $\\tilde{\\mathbf{x}} = [1, \\mathbf{x}^\\top]^\\top$ 映射到一个预测概率 $\\hat{p}(y=1 \\mid \\mathbf{x}) = \\sigma(\\mathbf{w}^\\top \\tilde{\\mathbf{x}})$，其中 $\\sigma(z) = \\frac{1}{1 + e^{-z}}$ 是 logistic sigmoid 函数。带 $\\ell_2$ 惩罚项的正则化经验风险是平均负对数似然加上对非截距系数的惩罚项。\n- 受试者工作特征曲线下面积 (AUC)：AUC 是一个随机选择的正例比一个随机选择的负例获得更高分数的概率；它是一个在 $[0,1]$ 区间内的标量。\n- 对数损失：对数损失（交叉熵）是负对数似然的经验均值，即 $-\\frac{1}{n}\\sum_{i=1}^n \\left[y_i \\log \\hat{p}_i + (1-y_i)\\log(1-\\hat{p}_i)\\right]$。\n- F1 分数：F1 分数是精确率（precision）和召回率（recall）的调和平均值。使用固定的 0.5 阈值，定义预测标签 $\\hat{y}_i = \\mathbb{I}[\\hat{p}_i \\ge 0.5]$，则精确率为 $\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FP}}$，召回率为 $\\frac{\\mathrm{TP}}{\\mathrm{TP}+\\mathrm{FN}}$，F1 分数为 $\\frac{2 \\cdot \\mathrm{precision} \\cdot \\mathrm{recall}}{\\mathrm{precision} + \\mathrm{recall}}$，并约定除以 0 的结果为 0。\n- 置换特征重要性 (PFI)：给定一个已训练的模型和一个性能指标，\n  - 对于需要最大化的指标（如 AUC 和 F1），特征 $j$ 的重要性定义为 $\\Delta_j = S(\\text{baseline}) - S(\\text{permuted } j)$，其中 $S$ 表示在未置换或已置换的测试集上计算的指标，模型参数保持不变。\n  - 对于需要最小化的指标（如对数损失），重要性定义为 $\\Delta_j = L(\\text{permuted } j) - L(\\text{baseline})$，其中 $L$ 表示损失。在这两种情况下，较大的 $\\Delta_j$ 表示更高的重要性。\n\n数据生成过程。您的程序必须在 $d = 3$ 维度上生成具有条件高斯特征和可控类别先验的合成数据。对于每个样本，抽取 $y \\sim \\mathrm{Bernoulli}(\\pi)$，然后在给定 $y$ 的条件下，抽取 $\\mathbf{x} \\mid y \\sim \\mathcal{N}(\\boldsymbol{\\mu}_y, \\mathbf{I}_3)$，其均值为\n- $\\boldsymbol{\\mu}_1 = [2.0,\\, 0.8,\\, 0.0]^\\top$ 和\n- $\\boldsymbol{\\mu}_0 = [0.0,\\, 0.0,\\, 0.0]^\\top$，\n协方差矩阵为单位矩阵 $\\mathbf{I}_3$。使用独立的抽样来生成训练集和测试集。\n\n训练。通过最小化平均负对数似然加上对非截距系数的 $\\ell_2$ 惩罚（正则化强度 $\\lambda = 1.0$）来拟合一个带截距项的逻辑回归模型。使用一个能够可靠收敛的数值稳定优化器。\n\n评估与置换。对于每个测试案例，在测试集上计算基线 AUC、对数损失和 F1。然后，通过独立地置换相应的测试特征列 $K$ 次并对结果变化进行平均，来计算每个 3 个特征在各个指标下的 PFI，其中 $K = 5$。每个测试案例使用固定的随机种子以确保可复现性。\n\n跨指标比较。为了总结关于类别不平衡和指标选择的敏感性，请对每个测试案例执行以下两项操作：\n- 确定每个指标下最重要特征的索引（从零开始），即 $\\arg\\max_j \\Delta_j$，分别针对 AUC、对数损失和 F1。如果出现平局，则选择最小的索引。\n- 计算 (AUC, 对数损失)、(AUC, F1) 和 (对数损失, F1) 这几对三维 PFI 向量之间的 Spearman 秩相关系数。如果由于秩的方差为零而导致相关系数未定义，则该相关系数返回 $0.0$。\n\n测试套件。您的程序必须运行以下三个测试案例，每个案例指定了类别先验 $\\pi$、样本大小和随机种子：\n- 案例 1（平衡）：$\\pi = 0.5$，$n_{\\text{train}} = 4000$，$n_{\\text{test}} = 20000$，seed $= 123$。\n- 案例 2（中度不平衡）：$\\pi = 0.2$，$n_{\\text{train}} = 4000$，$n_{\\text{test}} = 20000$，seed $= 456$。\n- 案例 3（严重不平衡）：$\\pi = 0.05$，$n_{\\text{train}} = 4000$，$n_{\\text{test}} = 20000$，seed $= 789$。\n\n答案规格和输出格式。对于每个案例，按以下固定顺序生成一个包含 6 个数字的列表：\n- AUC 指标下最重要特征的索引（整数，属于 $\\{0,1,2\\}$），\n- 对数损失指标下最重要特征的索引（整数，属于 $\\{0,1,2\\}$），\n- F1 指标下最重要特征的索引（整数，属于 $\\{0,1,2\\}$），\n- AUC-PFI 和对数损失-PFI 之间的 Spearman 秩相关系数（浮点数），\n- AUC-PFI 和 F1-PFI 之间的 Spearman 秩相关系数（浮点数），\n- 对数损失-PFI 和 F1-PFI 之间的 Spearman 秩相关系数（浮点数）。\n\n将所有三个案例的结果按顺序汇总到一个长度为 18 的单一扁平列表中。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$[a_1,a_2,\\dots,a_{18}]$）。浮点数必须打印并四舍五入到恰好 6 位小数，整数打印时不带小数。不涉及物理单位。不使用角度。如果出现百分比，必须表示为小数，但本问题不要求明确报告任何百分比。", "solution": "用户提供了一个有效的问题陈述。\n\n### 1. 问题阐述与目标\n\n目标是实证研究置换特征重要性 (PFI) 在二元分类任务中，不同程度的类别不平衡下的稳定性。我们将训练一个概率分类器，具体为逻辑回归，并使用三个不同的性能指标来评估 PFI：受试者工作特征曲线下面积 (AUC)、对数损失 (log-loss) 和 F1 分数。分析将重点关注随着类别先验概率 $\\pi = p(y=1)$ 变得更加倾斜，特征重要性排序以及这些排序之间的相关性如何变化。\n\n### 2. 合成数据生成\n\n数据在 $d=3$ 维度上从一个条件高斯分布中生成。每个样本 $(\\mathbf{x}, y)$ 的生成过程如下：\n1.  从一个伯努利分布中抽取一个二元标签 $y$：$y \\sim \\mathrm{Bernoulli}(\\pi)$。\n2.  在标签 $y$ 的条件下，从一个多元正态分布中抽取一个特征向量 $\\mathbf{x} \\in \\mathbb{R}^3$：$\\mathbf{x} \\mid y \\sim \\mathcal{N}(\\boldsymbol{\\mu}_y, \\mathbf{I}_3)$。\n两个类别的均值分别为：类别 $y=1$ 的均值为 $\\boldsymbol{\\mu}_1 = [2.0, 0.8, 0.0]^\\top$，类别 $y=0$ 的均值为 $\\boldsymbol{\\mu}_0 = [0.0, 0.0, 0.0]^\\top$。协方差矩阵是单位矩阵 $\\mathbf{I}_3$，这表示特征是条件独立的并且具有单位方差。\n\n均值之差 $\\boldsymbol{\\mu}_1 - \\boldsymbol{\\mu}_0 = [2.0, 0.8, 0.0]^\\top$ 决定了特征的内在预测能力。特征 0 的分离度最大，其次是特征 1。特征 2 在类别条件均值之间没有分离度，因此是一个不相关或噪声特征。\n\n### 3. 逻辑回归模型与训练\n\n我们采用逻辑回归模型，该模型预测在给定特征向量 $\\mathbf{x}$ 的情况下，正类别 $y=1$ 的概率。该模型使用一个增广特征向量 $\\tilde{\\mathbf{x}} = [1, \\mathbf{x}^\\top]^\\top$ 以包含截距项。预测概率为：\n$$\n\\hat{p}(y=1 \\mid \\mathbf{x}) = \\sigma(\\mathbf{w}^\\top \\tilde{\\mathbf{x}})\n$$\n其中 $\\mathbf{w} \\in \\mathbb{R}^{d+1}$ 是模型参数（权重）向量，$\\sigma(z) = (1 + e^{-z})^{-1}$ 是 logistic sigmoid 函数。\n\n模型通过最小化一个正则化经验风险函数进行训练。根据规定，此函数是训练集上的平均负对数似然 (NLL) 和对特征系数（不包括截距 $w_0$）的 $\\ell_2$ 惩罚项之和。对于大小为 $n_{\\text{train}}$ 的训练集，要最小化的目标函数 $J(\\mathbf{w})$ 是：\n$$\nJ(\\mathbf{w}) = \\left( -\\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} \\left[ y_i \\log(\\hat{p}_i) + (1-y_i) \\log(1-\\hat{p}_i) \\right] \\right) + \\lambda \\sum_{j=1}^{d} w_j^2\n$$\n其中 $\\hat{p}_i = \\sigma(\\mathbf{w}^\\top \\tilde{\\mathbf{x}}_i)$，正则化强度为 $\\lambda = 1.0$。这个目标函数是凸函数，保证了唯一最小值的存在。我们可以使用像 L-BFGS 这样的拟牛顿法来找到最优参数 $\\mathbf{w}^*$，该方法需要目标函数的梯度：\n$$\n\\nabla_{\\mathbf{w}} J(\\mathbf{w}) = \\frac{1}{n_{\\text{train}}} \\sum_{i=1}^{n_{\\text{train}}} (\\hat{p}_i - y_i) \\tilde{\\mathbf{x}}_i + 2\\lambda \\mathbf{w}_{\\text{reg}}\n$$\n其中 $\\mathbf{w}_{\\text{reg}} = [0, w_1, \\dots, w_d]^\\top$ 是一个向量，其截距位置为零，其余为惩罚项的系数值。\n\n### 4. 性能指标与置换特征重要性\n\n我们使用三个指标来评估模型性能和特征重要性：\n\n-   **AUC**：一个基于排序的指标，对类别不平衡和校准不敏感。它衡量一个随机选择的正样本比一个随机选择的负样本排名更高的概率。AUC 为 0.5 表示不比随机猜测好，而 1.0 表示完美区分。\n-   **对数损失**：一个严格评分规则，用于评估预测概率的质量。它对区分度和校准度都很敏感，并且受类别不平衡的影响。值越低越好。\n-   **F1 分数**：精确率和召回率的调和平均值，使用固定的 0.5 阈值对二值化预测进行计算。该指标对阈值的选择和类别分布高度敏感。\n\n特征 $j$ 的置换特征重要性 (PFI) 是通过测量当测试集中该特征的值被随机打乱时，模型性能的下降（或对于损失函数是增加）来计算的。这种打乱操作破坏了该特征与目标变量之间的关系。其步骤如下：\n1.  在原始测试集上计算基线性能指标 $S_{\\text{base}}$。\n2.  对于每个特征 $j \\in \\{0, 1, 2\\}$：\n    a. 对于 $K=5$ 次重复中的每一次，创建测试集的一个副本，并随机置换对应于特征 $j$ 的列。\n    b. 在这个置换过的数据集上计算性能指标 $S_{\\text{perm}, k}$。\n    c. 对 $K$ 次重复的分数取平均值：$\\bar{S}_{\\text{perm}} = \\frac{1}{K} \\sum_{k=1}^K S_{\\text{perm}, k}$。\n3.  计算重要性 $\\Delta_j$：\n    -   对于 AUC 和 F1（最大化指标）：$\\Delta_j = S_{\\text{base}} - \\bar{S}_{\\text{perm}}$。\n    -   对于对数损失（最小化指标）：$\\Delta_j = \\bar{S}_{\\text{perm}} - S_{\\text{base}}$。\n\n无论哪种情况，更大的 $\\Delta_j$ 值都表示更高的重要性。\n\n### 5. 分析与算法实现\n\n对于每个测试案例，我们进行两种分析来比较三种指标的 PFI 结果：\n\n1.  **最重要特征**：我们为三个 PFI 向量中的每一个确定最重要特征的索引，即 $\\arg\\max_j \\Delta_j$。这揭示了每个指标认为哪个特征影响最大。平局通过选择最小的索引来解决。\n2.  **秩相关**：我们计算 (AUC, 对数损失)、(AUC, F1) 和 (对数损失, F1) 这几对三维 PFI 向量之间的 Spearman 秩相关系数 $\\rho$。相关系数为 1.0 表示这些指标产生了相同的特征重要性排序。较低的值则表示存在分歧。如果相关系数由于秩的方差为零而未定义，则报告为 0.0。\n\n总体算法通过以下 Python 脚本实现：\n-   一个主循环遍历由 $(\\pi, n_{\\text{train}}, n_{\\text{test}}, \\text{seed})$ 定义的三个测试案例。\n-   对于每个案例，使用给定的种子创建一个 `numpy.random.default_rng` 实例，以确保数据生成和置換的可复现性。\n-   生成合成的训练和测试数据集。\n-   使用 `scipy.optimize.minimize` 和 `L-BFGS-B` 求解器来训练逻辑回归模型，该求解器被提供了目标函数及其解析梯度，以提高效率和稳定性。\n-   通过实现上述置换过程，为每个特征和每个指标计算 PFI。\n-   AUC 使用 Wilcoxon-Mann-Whitney U 统计量公式稳健地计算，并通过 `scipy.stats.rankdata` 实现。对数损失和 F1 分数直接根据其定义实现，并注意处理数值边界情况（例如，`log(0)` 或除以零）。\n-   计算最重要特征的索引和 Spearman 相关系数。使用 `scipy.stats.spearmanr` 进行相关性计算，并检查 `NaN` 结果。\n-   每个案例的六个结果值被收集起来，格式化为指定的精度，并作为单个逗号分隔的列表打印出来。", "answer": "```python\nimport numpy as np\nimport scipy.optimize\nimport scipy.special\nimport scipy.stats\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation across all test cases.\n    \"\"\"\n    test_cases = [\n        # Case 1 (balanced)\n        {'pi': 0.5, 'n_train': 4000, 'n_test': 20000, 'seed': 123},\n        # Case 2 (moderate imbalance)\n        {'pi': 0.2, 'n_train': 4000, 'n_test': 20000, 'seed': 456},\n        # Case 3 (severe imbalance)\n        {'pi': 0.05, 'n_train': 4000, 'n_test': 20000, 'seed': 789},\n    ]\n\n    mu1 = np.array([2.0, 0.8, 0.0])\n    mu0 = np.array([0.0, 0.0, 0.0])\n    d = 3\n    lambda_reg = 1.0\n    K_permutations = 5\n    \n    all_results = []\n\n    for case in test_cases:\n        pi, n_train, n_test, seed = case['pi'], case['n_train'], case['n_test'], case['seed']\n        \n        # RNG for reproducibility within a test case\n        rng = np.random.default_rng(seed)\n\n        # 1. Data Generation\n        def generate_data(n_samples, pi_val, rng_instance):\n            y = rng_instance.binomial(1, pi_val, size=n_samples)\n            X = np.zeros((n_samples, d))\n            n_pos = np.sum(y)\n            n_neg = n_samples - n_pos\n            X[y == 1, :] = mu1 + rng_instance.standard_normal(size=(n_pos, d))\n            X[y == 0, :] = mu0 + rng_instance.standard_normal(size=(n_neg, d))\n            return X, y\n        \n        X_train, y_train = generate_data(n_train, pi, rng)\n        X_test, y_test = generate_data(n_test, pi, rng)\n\n        # Add intercept term\n        X_train_aug = np.hstack([np.ones((n_train, 1)), X_train])\n        \n        # 2. Logistic Regression Training\n        def log_reg_cost_grad(w, X, y, lambda_val):\n            n_samples = X.shape[0]\n            z = X @ w\n            \n            # Cost Function (Average NLL + L2 Penalty)\n            # Use numerically stable log-sum-exp trick: log(1+exp(z)) = logaddexp(0, z)\n            avg_nll = np.sum(np.logaddexp(0, z) - y * z) / n_samples\n            penalty = lambda_val * np.sum(w[1:]**2)\n            cost = avg_nll + penalty\n            \n            # Gradient\n            p_hat = scipy.special.expit(z)\n            grad_nll = X.T @ (p_hat - y) / n_samples\n            grad_pen = np.zeros_like(w)\n            grad_pen[1:] = 2 * lambda_val * w[1:]\n            grad = grad_nll + grad_pen\n            \n            return cost, grad\n\n        w_initial = np.zeros(d + 1)\n        res = scipy.optimize.minimize(\n            lambda w: log_reg_cost_grad(w, X_train_aug, y_train, lambda_reg),\n            w_initial,\n            method='L-BFGS-B',\n            jac=True\n        )\n        w_opt = res.x\n\n        def predict_proba(X, w):\n            X_aug = np.hstack([np.ones((X.shape[0], 1)), X])\n            return scipy.special.expit(X_aug @ w)\n\n        # 3. Metric Implementations\n        def compute_auc(y_true, y_pred):\n            n_pos = np.sum(y_true == 1)\n            n_neg = np.sum(y_true == 0)\n            if n_pos == 0 or n_neg == 0:\n                return 0.5\n            ranks = scipy.stats.rankdata(y_pred)\n            rank_sum_pos = np.sum(ranks[y_true == 1])\n            u_stat = rank_sum_pos - (n_pos * (n_pos + 1) / 2)\n            return u_stat / (n_pos * n_neg)\n\n        def compute_log_loss(y_true, p_hat):\n            epsilon = 1e-15\n            p_hat_clipped = np.clip(p_hat, epsilon, 1 - epsilon)\n            return -np.mean(y_true * np.log(p_hat_clipped) + (1 - y_true) * np.log(1 - p_hat_clipped))\n\n        def compute_f1(y_true, p_hat):\n            y_pred = (p_hat >= 0.5).astype(int)\n            tp = np.sum((y_true == 1)  (y_pred == 1))\n            fp = np.sum((y_true == 0)  (y_pred == 1))\n            fn = np.sum((y_true == 1)  (y_pred == 0))\n            \n            precision_den = tp + fp\n            recall_den = tp + fn\n            \n            precision = tp / precision_den if precision_den > 0 else 0.0\n            recall = tp / recall_den if recall_den > 0 else 0.0\n            \n            f1_den = precision + recall\n            f1 = 2 * precision * recall / f1_den if f1_den > 0 else 0.0\n            return f1\n            \n        metrics = {\n            'auc': {'func': compute_auc, 'type': 'maximize'},\n            'log_loss': {'func': compute_log_loss, 'type': 'minimize'},\n            'f1': {'func': compute_f1, 'type': 'maximize'}\n        }\n        \n        # 4. PFI Calculation\n        pfi_results = {}\n        p_test_base = predict_proba(X_test, w_opt)\n\n        for name, metric_info in metrics.items():\n            metric_func = metric_info['func']\n            baseline_score = metric_func(y_test, p_test_base)\n            importances = np.zeros(d)\n            \n            for j in range(d):\n                permuted_scores = np.zeros(K_permutations)\n                for k in range(K_permutations):\n                    X_test_perm = X_test.copy()\n                    rng.shuffle(X_test_perm[:, j])\n                    p_test_perm = predict_proba(X_test_perm, w_opt)\n                    permuted_scores[k] = metric_func(y_test, p_test_perm)\n                \n                avg_permuted_score = np.mean(permuted_scores)\n                \n                if metric_info['type'] == 'maximize':\n                    importances[j] = baseline_score - avg_permuted_score\n                else: # minimize\n                    importances[j] = avg_permuted_score - baseline_score\n            \n            pfi_results[name] = importances\n\n        # 5. Analysis\n        pfi_auc = pfi_results['auc']\n        pfi_log_loss = pfi_results['log_loss']\n        pfi_f1 = pfi_results['f1']\n        \n        argmax_auc = np.argmax(pfi_auc)\n        argmax_log_loss = np.argmax(pfi_log_loss)\n        argmax_f1 = np.argmax(pfi_f1)\n        \n        def safe_spearmanr(x, y):\n            corr, _ = scipy.stats.spearmanr(x, y)\n            return corr if not np.isnan(corr) else 0.0\n\n        corr_auc_logloss = safe_spearmanr(pfi_auc, pfi_log_loss)\n        corr_auc_f1 = safe_spearmanr(pfi_auc, pfi_f1)\n        corr_logloss_f1 = safe_spearmanr(pfi_log_loss, pfi_f1)\n        \n        case_results = [\n            argmax_auc, argmax_log_loss, argmax_f1,\n            corr_auc_logloss, corr_auc_f1, corr_logloss_f1\n        ]\n        all_results.extend(case_results)\n\n    # Final formatting and printing\n    formatted_results = []\n    for item in all_results:\n        if isinstance(item, (int, np.integer)):\n            formatted_results.append(str(item))\n        else:\n            formatted_results.append(f\"{item:.6f}\")\n            \n    print(f\"[{','.join(formatted_results)}]\")\n\n\nsolve()\n```", "id": "3156641"}]}