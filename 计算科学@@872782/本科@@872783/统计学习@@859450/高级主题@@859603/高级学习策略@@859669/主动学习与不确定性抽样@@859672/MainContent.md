## 引言
在数据驱动的机器学习时代，获取大量高质量的标注数据是构建高性能模型的关键，但这往往伴随着高昂的人力与时间成本。主动学习（Active Learning）为这一挑战提供了强有力的解决方案。它并非被动地接收随机数据，而是通过一个智能的迭代循环，让学习算法主动“提问”，找出对模型提升最有价值的未标注样本，从而在有限的标注预算下实现模型性能的最大化。本文旨在系统性地介绍[主动学习](@entry_id:157812)的核心思想，特别是其中最经典和广泛应用的分支——不确定性抽样。

本文将分为三个核心章节，带领读者从理论基础走向实践应用。在“原理与机制”一章中，我们将深入剖析量化[模型不确定性](@entry_id:265539)的多种经典方法，探讨它们之间的异同，并讨论如何平衡不确定性与多样性，以及在实践中遇到的关键挑战。接下来，在“应用与跨学科连接”一章中，我们将展示这些原理如何与从传统机器学习到前沿[深度学习](@entry_id:142022)的各种模型相结合，并应用于生态学、[药物发现](@entry_id:261243)等多个领域，突显其作为通用工具的强大能力。最后，在“动手实践”部分，您将有机会通过具体的编程练习，亲手实现和评估不同的[抽样策略](@entry_id:188482)，从而将理论知识转化为实践技能。通过这一结构化的学习路径，您将全面掌握主动学习的精髓，并了解如何利用它来解决实际问题。

## 原理与机制

在“引言”章节中，我们确立了[主动学习](@entry_id:157812)的基本目标：在有限的标注预算下，通过智能地选择数据点进行标注，以最大化模型的性能。本章将深入探讨实现这一目标的核心技术原理与机制。我们将从量化模型“不确定性”的经典启发式方法出发，逐步过渡到更高级的、能够平衡不确定性与多样性的框架。此外，我们还将讨论在现实世界应用中至关重要的实践挑战，如处理异[常点](@entry_id:164624)、[模型校准](@entry_id:146456)问题，并最终探讨主动学习的理论基础和何时停止标注的关键问题。

### [量化不确定性](@entry_id:272064)：核心[抽样策略](@entry_id:188482)

池化主动学习（Pool-based Active Learning）最直观的策略是，向人类专家查询模型最“不确定”的数据点。其背后的假设是，这些模型难以判断的样本位于或靠近决策边界，为模型学习该边界提供了最有价值的信息。有多种方法可以量化这种不确定性，其中三种最为核心和常用。

为形式化这些定义，我们假设一个[概率分类](@entry_id:637254)器为每个输入$x$输出一个[后验概率](@entry_id:153467)[分布](@entry_id:182848)$p(y|x)$，其中$y$属于类别集合$\mathcal{Y}$。我们用$p_{(1)}(x)$表示最大的[后验概率](@entry_id:153467)，即$\max_{y \in \mathcal{Y}} p(y|x)$，用$p_{(2)}(x)$表示第二大的[后验概率](@entry_id:153467)。

**最小[置信度](@entry_id:267904)（Least-Confidence, LC）**

这是最简单的策略。它直接关注模型最可能的预测结果的置信度。[置信度](@entry_id:267904)越低，意味着不确定性越高。其不确定性得分定义为：
$$
u_{\mathrm{LC}}(x) = 1 - p_{(1)}(x)
$$
[主动学习](@entry_id:157812)器会选择得分最高的样本进行查询，这等价于选择$p_{(1)}(x)$最低的样本。该策略虽然简单，但它完全忽略了其他类别的[概率分布](@entry_id:146404)信息，因此可能比较“短视”。

**边缘采样（Margin Sampling, MS）**

边缘[采样策略](@entry_id:188482)通过考虑最可能的和次可能的类别预测之间的差异来改进最小置信度。边缘越小，意味着模型越难区分这两个最有可能的选项，因此不确定性越高。其不确定性得分定义为需要**最小化**的值：
$$
u_{\mathrm{margin}}(x) = p_{(1)}(x) - p_{(2)}(x)
$$
主动学习器会选择得分最低的样本进行查询。该策略聚焦于最具竞争力的两个类别之间的模糊性。

**[熵采样](@entry_id:634467)（Entropy Sampling）**

该策略采用信息论中的[香农熵](@entry_id:144587)来量化不确定性，从而将整个[后验概率](@entry_id:153467)[分布](@entry_id:182848)都纳入考量。当[概率分布](@entry_id:146404)接近[均匀分布](@entry_id:194597)时，熵最大，表示不确定性最高。其不确定性得分定义为：
$$
H[Y|x] = - \sum_{y \in \mathcal{Y}} p(y|x) \log p(y|x)
$$
[主动学习](@entry_id:157812)器会选择熵最高的样本进行查询。这是三种方法中信息最全面的。

**策略比较与分析**

这些策略虽然都旨在捕捉不确定性，但它们的侧重点不同，导致在某些情况下会做出不同的选择。

一个有趣的问题是，这些策略在何种情况下是等价的？让我们来分析一下[二分类](@entry_id:142257)（$K=2$）的情形[@problem_id:3095044]。在这种情况下，对于任意样本$x$，如果我们知道最可能的类别的概率是$p_{(1)}(x)$，那么次可能的（也就是唯一的另一个）类别的概率必然是$p_{(2)}(x) = 1 - p_{(1)}(x)$。

*   最小[置信度](@entry_id:267904)策略的目标是最大化$1 - p_{(1)}(x)$，等价于最小化$p_{(1)}(x)$。
*   边缘[采样策略](@entry_id:188482)的目标是最小化$p_{(1)}(x) - p_{(2)}(x) = p_{(1)}(x) - (1 - p_{(1)}(x)) = 2p_{(1)}(x) - 1$。由于$f(z) = 2z - 1$是一个严格单调递增函数，最小化$2p_{(1)}(x) - 1$也等价于最小化$p_{(1)}(x)$。

因此，在二[分类问题](@entry_id:637153)中，**最小置信度采样和边缘采样总是等价的**，它们会选择完全相同的样本。

然而，当类别数$K>2$时，这种[等价关系](@entry_id:138275)就不复存在了。$p_{(2)}(x)$不再是$p_{(1)}(x)$的简单函数。我们可以通过一个具体的例子来理解它们的差异[@problem_id:3095044]。假设一个三[分类问题](@entry_id:637153)中，我们有两个未标注的样本$x_A$和$x_B$，其后验概率[分布](@entry_id:182848)分别为：
*   $x_A$: $(0.60, 0.39, 0.01)$
*   $x_B$: $(0.51, 0.26, 0.23)$

我们来计算它们各自的得分：
*   对于$x_A$：$p_{(1)} = 0.60, p_{(2)} = 0.39$。
    *   最小[置信度](@entry_id:267904)得分: $u_{\mathrm{LC}}(x_A) = 1 - 0.60 = 0.40$。
    *   边缘得分: $u_{\mathrm{margin}}(x_A) = 0.60 - 0.39 = 0.21$。
*   对于$x_B$：$p_{(1)} = 0.51, p_{(2)} = 0.26$。
    *   最小[置信度](@entry_id:267904)得分: $u_{\mathrm{LC}}(x_B) = 1 - 0.51 = 0.49$。
    *   边缘得分: $u_{\mathrm{margin}}(x_B) = 0.51 - 0.26 = 0.25$。

根据[选择规则](@entry_id:140784)：
*   最小置信度策略选择得分**最高**的。由于$0.49 > 0.40$，它将选择$x_B$。
*   边缘[采样策略](@entry_id:188482)选择得分**最低**的。由于$0.21  0.25$，它将选择$x_A$。

这个例子清晰地表明，在多分类场景下，不同策略的偏好会出现分歧。LC策略更关注“模型对最佳选择有多大把握”，而MS策略更关注“最佳选择与次佳选择之间的区分难度”。[熵采样](@entry_id:634467)则会考虑整个[分布](@entry_id:182848)的“平坦度”，在某些情况下可能选择与前两者都不同的样本[@problem_id:3095122]。

### 不确定性的其他视角

将不确定性等同于后验概率[分布](@entry_id:182848)的形态是直观的，但并非唯一的方式。另一种强大的视角是将不确定性与查询一个样本后对模型产生的**潜在影响**联系起来。一个好的查询应该能最大程度地改变或“改进”模型。

**期望模型改变量（Expected Model Change）**

这个思想是选择那个在期望意义上能最大程度改变模型参数的样本。在[随机梯度下降](@entry_id:139134)（SGD）的框架下，模型参数的改变量与损失函数的梯度成正比。因此，我们可以选择那个期望梯度范数最大的样本。

让我们以二元逻辑回归为例来推导这个准则[@problem_id:3095055]。模型参数为$\theta$，输入为$x$，模型预测$p(y=1|x) = \sigma(\theta^\top x)$，其中$\sigma(\cdot)$是sigmoid函数。损失函数$\ell(\theta; x, y)$的梯度为：
$$
\nabla_\theta \ell(\theta; x, y) = (\sigma(\theta^\top x) - y)x
$$
令$p = \sigma(\theta^\top x)$，则梯度为$(p-y)x$。由于我们不知道真实标签$y$，我们对$y$的[后验预测分布](@entry_id:167931)（即参数为$p$的[伯努利分布](@entry_id:266933)）求期望。期望模型改变量（这里用期望梯度范数来衡量）为：
$$
\mathcal{M}(x) = \mathbb{E}_{y \sim \mathrm{Bern}(p)} \left[ \|(p-y)x\|_2 \right]
$$
展开期望：
$$
\mathcal{M}(x) = p(y=1) \cdot \|(p-1)x\|_2 + p(y=0) \cdot \|(p-0)x\|_2
$$
$$
= p \cdot |p-1| \cdot \|x\|_2 + (1-p) \cdot |p| \cdot \|x\|_2
$$
因为$p \in (0,1)$，所以$|p-1|=1-p$且$|p|=p$。代入后得到：
$$
\mathcal{M}(x) = p(1-p)\|x\|_2 + (1-p)p\|x\|_2 = 2p(1-p)\|x\|_2
$$
这个结果非常富有启发性。不确定性项$p(1-p)$与熵$H(p)$一样，在$p=0.5$（即[决策边界](@entry_id:146073)上）达到最大值。然而，$\mathcal{M}(x)$还包含一个额外的因子$\|x\|_2$，即样本[特征向量](@entry_id:151813)的欧几里得范数。这意味着，在同样处于决策边界上的两个点中，**期望模型改变量策略会偏好那个距离原点更远的点**，因为它会引发更大规模的梯度更新。这巧妙地将信息不确定性与优化过程联系在了一起。

### 不确定性与多样性的权衡

仅依赖[不确定性采样](@entry_id:635527)有一个显著的缺点：**冗余**。如果模型在某一数据区域感到不确定，很可能会在该区域找到大量高度不确定的样本。连续查询这些彼此相似的样本，所带来的信息收益会递减。这就引出了[主动学习](@entry_id:157812)中的另一个核心概念：**多样性（Diversity）**。一个好的主动学习策略应该在不确定性和多样性之间取得平衡。

**核心集选择（Core-Set Selection）：多样性优先**

与[不确定性采样](@entry_id:635527)相反，核心集方法旨在选择一小组具有[代表性](@entry_id:204613)的样本，使它们能“覆盖”整个未标注数据集。这是一种纯粹基于多样性的策略，它通常与模型本身无关，只依赖于数据的特征表示。

一个常见的核心集算法是**k-中心贪心算法**[@problem_id:3095018]。该算法从一个初始已标注集合$S_0$开始，迭代地进行以下操作：
1.  对于每个未标注样本$x_i$，计算它到当前已标注集合$S$的最小距离，即 $d(x_i, S) = \min_{s \in S} \|z(x_i) - z(s)\|_2$，其中$z(\cdot)$是样本的特征嵌入。
2.  选择那个具有最大最小距离的样本$x^* = \arg\max_{x_i \notin S} d(x_i, S)$。
3.  将$x^*$加入已标注集合$S$，并重复此过程。

这个过程直观地选择了那些处于数据空间中最“未被探索”区域的样本。与[熵采样](@entry_id:634467)等方法相比，核心集选择保证了对整个[特征空间](@entry_id:638014)的良好覆盖，但它完全忽略了模型的不确定性信息。

**通过[行列式](@entry_id:142978)点过程（DPP）结合不确定性与多样性**

如何在同一个框架下优雅地结合不确定性和多样性？**[行列式](@entry_id:142978)点过程（Determinantal Point Processes, DPPs）**提供了一个强大而符合第一性原理的解决方案[@problem_id:3095129]。

DPP是一个在给定集合的[子集](@entry_id:261956)上定义的概率模型，一个[子集](@entry_id:261956)$S$被选中的概率与其核矩阵$K$的对应[主子矩阵](@entry_id:201119)$K_S$的[行列式](@entry_id:142978)成正比：$P(S) \propto \det(K_S)$。这里的核矩阵$K$必须是半正定的。

[行列式](@entry_id:142978)$\det(K_S)$具有优美的几何意义：它可以被解释为由$S$中各项的[特征向量](@entry_id:151813)所张成的平行[多面体](@entry_id:637910)的（平方）体积。这个性质天然地编码了多样性：如果向一个集合中添加一个与已有项非常相似的项，其[特征向量](@entry_id:151813)与原有向量近似[线性相关](@entry_id:185830)，这将导致[行列式](@entry_id:142978)（即体积）的增益很小。相反，添加一个与已有项很不相似的项，会显著增加体积。

我们可以巧妙地设计核矩阵$K$来同时编码不确定性（也称“质量”）和多样性：
$$
K_{ij} = \alpha \cdot \mathrm{sim}(x_i, x_j) + \beta \cdot u(x_i) \cdot \delta_{ij}
$$
这里：
*   $\mathrm{sim}(x_i, x_j)$ 是一个相似度函数（如高斯[RBF核](@entry_id:166868)），构成核矩阵的非对角线部分，由权重$\alpha$控制。它负责编码**多样性**。
*   $u(x_i)$ 是一个预先计算好的不确定性（或质量）分数，构成核矩阵的对角线部分，由权重$\beta$控制。它负责编码**不确定性**。$\delta_{ij}$是克罗内克符号。

通过调整$\alpha$和$\beta$的相对大小，我们可以控制不确定性和多样性之间的权衡。例如[@problem_id:3095129]：
*   当$\alpha=0, \beta0$时，$K$是一个[对角矩阵](@entry_id:637782)，$\det(K_S) = \prod_{i \in S} \beta u(x_i)$。最大化[行列式](@entry_id:142978)等价于选择不确定性分数$u(x_i)$最高的$k$个样本，退化为纯[不确定性采样](@entry_id:635527)。
*   当$\alpha0, \beta=0$时，$\det(K_S)$只由样本间的相似性决定，退化为纯多样性采样。

虽然精确地找到使$\det(K_S)$最大化的$k$元[子集](@entry_id:261956)是[NP难问题](@entry_id:146946)，但一个简单的贪心算法（每次迭代添加能使[行列式](@entry_id:142978)增益最大的项）可以给出高质量的近似解，并且在实践中被广泛应用。

### 实践中的挑战与改进

将[主动学习](@entry_id:157812)算法应用于现实世界时，我们会遇到一些理论模型未曾考虑的复杂情况。本节讨论两个关键挑战及其解决方案。

**挑战一：异[常点](@entry_id:164624)（Outliers）**

单纯的[不确定性采样](@entry_id:635527)策略常常会优先选择异[常点](@entry_id:164624)。这是因为异[常点](@entry_id:164624)远离数据的主体[分布](@entry_id:182848)，模型在这些区域的训练不足，因此会表现出很高的不确定性。然而，标注这些稀有且可能不具代表性的样本对于提升模型在核心任务上的性能帮助不大，甚至可能有害。

**解决方案：密度加权[不确定性采样](@entry_id:635527)**

一个有效的解决方案是在不确定性得分上乘以一个反映数据密度的权重，从而惩罚位于低密度区域的样本[@problem_id:3095061]。新的采集分数可以定义为：
$$
S(x) = H[y|x] \cdot (\hat{p}(x))^\beta
$$
其中：
*   $H[y|x]$ 是我们熟悉的[不确定性度量](@entry_id:152963)，如熵。
*   $\hat{p}(x)$ 是对$x$点数据密度的估计，通常通过**[核密度估计](@entry_id:167724)（Kernel Density Estimation, KDE）**计算得到。
*   $\beta \ge 0$ 是一个超参数，用于控制密度加权的强度。当$\beta=0$时，该策略退化为纯[熵采样](@entry_id:634467)。当$\beta  0$时，只有那些既不确定又处于数据密集区域的样本才能获得高分。

这种方法使得[主动学习](@entry_id:157812)器能够聚焦于那些既有信息量又具[代表性](@entry_id:204613)的样本，从而实现更稳健和高效的学习。

**挑战二：[模型校准](@entry_id:146456)不佳（Model Miscalibration）**

所有基于概率输出的[不确定性度量](@entry_id:152963)都隐含地假设模型输出的概率是“可信”的。一个**校准良好**的模型，其预测概率能准确反映真实的成功率。例如，对于模型预测为$0.8$的所有样本，其中真实标签为正例的比例确实应该在$80\%$左右。

然而，许多现代[深度学习模型](@entry_id:635298)都存在校准不佳的问题，它们可能系统性地过于自信（例如，对所有预测都输出接近$0$或$1$的概率）或过于不自信。这种**校准偏差**会严重扭曲不确定性的度量[@problem_id:3095056]。例如，一个模型可能对某个它实际上很有把握的样本（真实概率为$0.9$）输出了一个接近$0.5$的未校准概率。[熵采样](@entry_id:634467)算法会错误地认为这是一个高度不确定的点，从而浪费一次宝贵的查询机会。

**解决方案：[概率校准](@entry_id:636701)**

解决之道是在计算不确定性之前，先对模型的原始输出进行**校准**。**保序回归（Isotonic Regression）**是一种强大且流行的非参数校准方法。

该方法通过一个独立的校准数据集来学习一个单调非减函数$f$，该函数将模型的原始分数（logits或概率）映射到一个新的、校准后的概率。学习过程通常通过**池邻近违规算法（Pool Adjacent Violators Algorithm, PAVA）**完成。[主动学习](@entry_id:157812)的流程就变为：
1.  模型对未标注样本$x$输出原始分数$s$。
2.  应用校准函数得到校准后的概率 $\tilde{p} = f(s)$。
3.  基于校准后的概率$\tilde{p}$计算不确定性，如$H(\tilde{p})$。
4.  选择不确定性最高的样本进行查询。

通过引入校准步骤，我们可以获得更可靠的[不确定性估计](@entry_id:191096)，从而使主动学习的选择更加精准，避免因模型自身的“幻觉”而做出次优决策[@problem_id:3095056]。

### 理论基础与[停止准则](@entry_id:136282)

到目前为止，我们主要关注“如何选择”样本。本节将回答两个更根本的问题：第一，为什么[主动学习](@entry_id:157812)在理论上是有效的？第二，我们应该在什么时候停止标注过程？

**[主动学习](@entry_id:157812)为何高效？——相异系数**

基于相异（Disagreement）的[主动学习](@entry_id:157812)算法（如[不确定性采样](@entry_id:635527)）的效率源于它能有效减小**版本空间**——即与已标注数据一致的所有可能假设的集合。其标注效率可以用**相异系数（Disagreement Coefficient）** $\theta$ 来刻画[@problem_id:3095048]。

相异系数衡量了“坏”假设（那些与真实假设$h^*$略有不同的假设）与$h^*$的预测结果有多大的差异。形式上，给定一个以$h^*$为中心、半径为$r$的误差球$B(h^*, r)$（即所有错误率不超过$r$的假设集合），该球内所有假设的**相异区域**$\mathrm{DIS}(B(h^*, r))$是所有这些假设中至少存在一对预测不一致的样本点集合。相异系数定义为：
$$
\theta(h^*) = \sup_{r0} \frac{\Pr_X(\mathrm{DIS}(B(h^*, r)))}{r}
$$
$\theta$越小，意味着与真实假设$h^*$相似的“坏”假设只在一个很小的区域内与$h^*$产生[分歧](@entry_id:193119)。主动学习可以通过查询这个小区域内的样本，高效地排除大量“坏”假设。理论表明，要达到$\epsilon$的额外误差，主动学习所需的标注[数量级](@entry_id:264888)为$\mathcal{O}(\theta(\mathcal{H}) \ln(1/\epsilon))$，其中$\theta(\mathcal{H})$是[假设空间](@entry_id:635539)$\mathcal{H}$中最大的相异系数。

例如，对于在单位区间$[0,1]$上[均匀分布](@entry_id:194597)数据的一维阈值分类器（$h_t(x) = \mathbf{1}[x \ge t]$），可以精确计算出$\theta(\mathcal{H})=2$ [@problem_id:3095048]。这意味着其标注复杂度约为$2\ln(1/\epsilon)$。这个对数依赖关系远优于被动学习（随机采样）的[线性依赖](@entry_id:185830)关系$O(1/\epsilon)$，从理论上证明了[主动学习](@entry_id:157812)的优越性。

**何时停止？——基于风险的[停止准则](@entry_id:136282)**

主动学习是一个迭代过程，一个关键问题是何时终止。一个合理的准则是：当模型的性能（如分类风险$R = \mathbb{E}[\ell]$）已经足够好，或者其估计的[置信区间](@entry_id:142297)已经足够窄时，就停止标注。

然而，主动学习采集的已标注样本集是有偏的，不能直接用其平均损失来估计总体风险$R$。我们需要一个无偏的[风险估计](@entry_id:754371)器。**逆倾向加权（Inverse Propensity Weighting）**为此提供了解决方案，其中**Hájek估计器**是一种常用的形式[@problem_id:3095014]：
$$
\hat{R} = \frac{\sum_{i=1}^n \ell_i / p_i}{\sum_{i=1}^n 1 / p_i}
$$
这里，$\ell_i$是第$i$个已标注样本上的损失，$p_i$是它被主动学习策略选中的概率（倾向分）。

有了风险的[点估计](@entry_id:174544)$\hat{R}$，我们还需要其不确定性的度量，即[标准误](@entry_id:635378)$\mathrm{SE}(\hat{R})$。由于$\hat{R}$的解析形式复杂，通常采用**[非参数自助法](@entry_id:142410)（Nonparametric Bootstrap）**来估计其标准误：通过对已标注样本集进行上千次有放回的重采样，每次都计算一个$\hat{R}^*$，最后计算这些$\hat{R}^*$的标准差作为$\mathrm{SE}(\hat{R})$的估计。

最后，我们可以构造一个基于[正态近似](@entry_id:261668)的[置信区间](@entry_id:142297)：$\text{CI} = [\hat{R} \pm z_{\alpha/2} \cdot \widehat{\mathrm{SE}}_{\text{boot}}]$。[停止准则](@entry_id:136282)便可以设定为：**当该置信区间的宽度小于预设的阈值$\tau$时，停止标注**[@problem_id:3095014]。

**单次查询的收益是什么？——风险降低与[信息增益](@entry_id:262008)**

我们还可以从[信息增益](@entry_id:262008)的角度来理解单次查询的价值。假设在一个简化的“局部拟合”模型下，查询样本$s_k$后，模型在该点的预测会更新为真实的[条件概率](@entry_id:151013)$p_{s_k}$。那么，这次查询带来的期望[经验风险](@entry_id:633993)的降低量$\Delta_k = R_{k-1} - R_k$可以被推导出来[@problem_id:3121440]。

其结果是：
$$
\Delta_k = \frac{1}{N} D_{\mathrm{KL}}(\mathrm{Bern}(p_{s_k}) || \mathrm{Bern}(q_{s_k}))
$$
这里，$N$是未标注池的大小，$q_{s_k}$是查询前模型对$s_k$的预测[概率分布](@entry_id:146404)，而$p_{s_k}$是其真实[概率分布](@entry_id:146404)。$D_{\mathrm{KL}}$是[KL散度](@entry_id:140001)，衡量了两个[分布](@entry_id:182848)的差异。这个优美的公式表明，**单次查询的收益正比于模型在该点的“认知”与“现实”之间的差距**。[主动学习](@entry_id:157812)的过程，本质上就是寻找并修正模型认知偏差最大的地方，从而最大化信息获取，最快地降低整体风险。