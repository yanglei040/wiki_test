{"hands_on_practices": [{"introduction": "一个估计器的“击穿点”是稳健统计学中的一个核心概念，它量化了在估计结果变得完全不可靠之前，一个数据集能容忍的恶意数据的最大比例。这个练习通过一个简化的场景，让你亲手计算和比较均值、修剪均值和中位数这三种位置估计量的击穿点，从而直观地理解不同估计器在面对异常值时的稳健性差异。通过这个练习[@problem_id:3171418]，你将建立起对稳健性概念的基本直觉。", "problem": "考虑一维稳健统计学习中的ε-污染模型，其中大小为 $n$ 的训练样本包含 $(1-\\epsilon)n$ 个从基础分布中抽取的干净点和 $\\epsilon n$ 个对抗性离群值。在本问题中，将基础分布视为在 $0$ 处的退化分布，因此干净点均为 $0$。并让对抗方将所有离群值放置在一个大的正值 $M$ 处。这种最坏情况下的污染使得分析变为纯粹的组合问题，并避免了随机性。\n\n定义三个位置估计量：\n1. 样本均值 $\\bar{x}$。\n2. 对称τ-截尾均值，其中 $0 \\le \\tau  \\frac{1}{2}$。该方法截去 $k = \\lfloor \\tau n \\rfloor$ 个最小值和 $k$ 个最大值，然后对剩余的 $n - 2k$ 个观测值求平均。对于一个排序后的样本 $x_{(1)} \\le \\cdots \\le x_{(n)}$，截尾均值为\n$$\n\\bar{x}_{\\mathrm{trim}} = \\frac{1}{n - 2k} \\sum_{i=k+1}^{n-k} x_{(i)}.\n$$\n3. 由Tukey深度定义的Tukey中位数（在一维情况下，这等同于样本中位数）。当 $n$为奇数时，它是 $x_{((n+1)/2)}$；当 $n$ 为偶数时，它是 $\\frac{1}{2}\\left(x_{(n/2)} + x_{(n/2+1)}\\right)$。\n\n使用稳健统计学中崩溃点的基本定义：对于一个视为泛函 $T$ 的估计量，其在分布 $P$ 上的崩溃点是指，能够通过对抗性污染使估计量的值变得无界的最小污染水平 $\\epsilon$，即\n$$\n\\varepsilon^\\star(T, P) = \\inf \\left\\{\\epsilon \\in [0,1]: \\sup_Q \\left\\| T\\left( (1-\\epsilon)P + \\epsilon Q \\right) \\right\\| = \\infty \\right\\},\n$$\n其中 $Q$ 遍历所有可能的污染分布。在上述具有明确构造的有限样本情景中，这简化为求解最小的离群值比例 $\\epsilon$（等价于整数数量 $m = \\epsilon n$），使得当 $M \\to \\infty$ 时，估计量的值无限增大。\n\n你的任务：\n- 从上述稳健崩溃点定义和干净点为 $0$、对抗性离群值为 $M$ 的明确污染构造出发，推导在有限样本情景下，当 $M \\to \\infty$ 时，使每个估计量变得无界所需的最小污染比例 $\\epsilon^\\star$。在适用时，将答案表示为 $n$ 和 $\\tau$ 的函数，并对因离群值为整数数量而需要的所有取整操作进行说明。\n- 同时，确定这三个估计量的渐近崩溃点，解释ε-污染模型在大样本极限下的意义，并提供不依赖于 $n$ 的值。\n- 实现一个确定性程序，对于每个测试用例 $(n,\\tau)$，返回两个三元组：\n  - 渐近崩溃点 $[\\varepsilon^\\star(\\text{mean}), \\varepsilon^\\star(\\text{trimmed mean}), \\varepsilon^\\star(\\text{Tukey median})]$。\n  - 有限样本污染阈值，采用明确构造 $[\\epsilon^\\star_{\\text{mean}}(n), \\epsilon^\\star_{\\text{trim}}(n,\\tau), \\epsilon^\\star_{\\text{Tukey}}(n)]$。\n\n测试组：\n- 使用以下参数集 $(n,\\tau)$：\n  1. $(100, 0.1)$ 作为一个通用案例。\n  2. $(101, 0.1)$ 以测试奇数 $n$ 对中位数的影响。\n  3. $(100, 0.0)$ 以测试截尾消失的边界情况。\n  4. $(20, 0.2)$ 以测试中等截尾程度下的离散取整效应。\n  5. $(2, 0.0)$ 以测试最小的偶数样本量。\n\n最终输出格式：\n- 你的程序应生成单行输出，包含一个由方括号括起来的逗号分隔列表，不含空格。每个测试用例贡献一对包含三个浮点数的列表：第一个列表是按上述顺序排列的渐近崩溃点，第二个列表是按相同顺序排列的有限样本阈值。总输出是所有测试用例的这些对的列表。例如，格式应如下所示\n$$\n\\left[\\left[[a_1,a_2,a_3],[b_1,b_2,b_3]\\right],\\left[[\\cdots],[\\cdots]\\right],\\ldots\\right]\n$$\n其中 $a_i$ 和 $b_i$ 是十进制数。", "solution": "该问题是有效的，因为它科学地基于稳健统计学的原理，定义清晰、问题表述明确，并以客观、正式的语言表达。分析位置估计量的崩溃点是一个标准的理论问题。我们将继续推导所需的量。\n\n问题定义了一个特定的污染情景：对于一个大小为 $n$ 的样本，我们有 $n-m$ 个值为 $0$ 的“干净”数据点和 $m$ 个值为大的正数 $M$ 的“对抗性”离群点。污染比例为 $\\epsilon = m/n$。我们寻求导致估计量的值在 $M \\to \\infty$ 时变得无界的最小离群值整数数量 $m$。有限样本崩溃点就是这个最小比例，$\\epsilon^\\star = m/n$。渐近崩溃点是当 $n \\to \\infty$ 时此比例的极限。\n\n排序后的样本，表示为 $x_{(1)} \\le x_{(2)} \\le \\cdots \\le x_{(n)}$，将由 $n-m$ 个零和其后的 $m$ 个值 $M$ 组成。具体来说，$x_{(i)} = 0$ 当 $i \\le n-m$ 时，以及 $x_{(i)} = M$ 当 $i > n-m$ 时。\n\n**1. 样本均值 ($\\bar{x}$)**\n\n样本均值定义为 $\\bar{x} = \\frac{1}{n} \\sum_{i=1}^n x_i$。\n对于给定的污染样本，总和包含 $n-m$ 个等于 $0$ 的项和 $m$ 个等于 $M$ 的项。\n样本均值的值为：\n$$\n\\bar{x} = \\frac{1}{n} \\left( (n-m) \\cdot 0 + m \\cdot M \\right) = \\frac{m M}{n}\n$$\n为了使估计量在 $M \\to \\infty$ 时趋于无穷， $M$ 的系数必须非零。\n$$\n\\lim_{M \\to \\infty} \\frac{m M}{n} = \\infty \\quad \\iff \\quad \\frac{m}{n} > 0 \\quad \\iff \\quad m > 0\n$$\n满足 $m > 0$ 的最小整数 $m$ 是 $m=1$。\n\n- **有限样本崩溃点**：最小离群值数量为 $m=1$。相应的比例为：\n$$ \\epsilon^\\star_{\\text{mean}}(n) = \\frac{1}{n} $$\n- **渐近崩溃点**：取样本量 $n$ 趋于无穷时的极限：\n$$ \\varepsilon^\\star(\\text{mean}) = \\lim_{n \\to \\infty} \\frac{1}{n} = 0 $$\n\n**2. 对称τ-截尾均值 ($\\bar{x}_{\\mathrm{trim}}$)**\n\nτ-截尾均值通过移除 $k = \\lfloor \\tau n \\rfloor$ 个最小值和 $k$ 个最大观测值，并对剩余的 $n-2k$ 个点求平均来计算。其公式为：\n$$\n\\bar{x}_{\\mathrm{trim}} = \\frac{1}{n - 2k} \\sum_{i=k+1}^{n-k} x_{(i)}\n$$\n估计量的值由点 $x_{(k+1)}, \\dots, x_{(n-k)}$ 决定。在我们的设置中，这些点要么是 $0$ 要么是 $M$。如果总和中的所有点都是 $0$，估计量将是有界的（等于 $0$）。如果总和中至少有一个点是 $M$，它将变得无界。\n\n值为 $M$ 的离群值占据了排序后样本中最大的 $m$ 个位置：$x_{(n-m+1)}, \\dots, x_{(n)}$。\n最大的 $k$ 个值被截掉。它们是 $x_{(n-k+1)}, \\dots, x_{(n)}$。\n如果离群值的数量 $m$ 小于或等于高端截尾点的数量 $k$（即 $m \\le k$），那么所有离群值都将成为被截尾集合的一部分。剩余点的最大索引是 $n-k$。离群值的最小索引是 $n-m+1$。如果 $n-m+1 > n-k$，或者 $k+1 > m$，则所有离群值都被截掉。\n当至少有一个离群值*未被*截尾时，就会发生崩溃。这种情况发生在离群值的数量 $m$ 足够大，以至于“溢出”到被平均的样本部分中时。这要求离群值的数量大于从顶部截去的点的数量 $k$。\n因此，崩溃的条件是 $m > k$。\n满足此条件的最小整数 $m$ 是 $m = k+1$。代入 $k = \\lfloor \\tau n \\rfloor$，最小离群值数量为 $m = \\lfloor \\tau n \\rfloor + 1$。\n\n- **有限样本崩溃点**：最小污染比例为：\n$$ \\epsilon^\\star_{\\text{trim}}(n, \\tau) = \\frac{\\lfloor \\tau n \\rfloor + 1}{n} $$\n- **渐近崩溃点**：我们取 $n \\to \\infty$ 时的极限。使用性质 $\\lim_{n\\to\\infty} \\frac{\\lfloor \\tau n \\rfloor}{n} = \\tau$：\n$$ \\varepsilon^\\star(\\text{trimmed mean}) = \\lim_{n \\to \\infty} \\frac{\\lfloor \\tau n \\rfloor + 1}{n} = \\lim_{n \\to \\infty} \\left(\\frac{\\lfloor \\tau n \\rfloor}{n} + \\frac{1}{n}\\right) = \\tau + 0 = \\tau $$\n\n**3. Tukey中位数（样本中位数）**\n\n样本中位数的定义取决于 $n$ 的奇偶性。\n如果中位数值为 $M$ 或包含与 $M$ 成比例的项，就会发生崩溃，而这会在中心数据点之一是值为 $M$ 的离群值时发生。\n\n- **情况1：$n$ 为奇数**。设 $n = 2j+1$。中位数是单个中心值 $x_{((n+1)/2)} = x_{(j+1)}$。如果这个点是一个离群值，就会发生崩溃。离群值是 $x_{(n-m+1)}, \\dots, x_{(n)}$。所以我们需要中位数的索引在离群值范围内：\n$$ \\frac{n+1}{2} > n-m \\implies m > n - \\frac{n+1}{2} = \\frac{n-1}{2} $$\n因为 $n$ 是奇数，所以 $(n-1)/2 = j$ 是一个整数。满足 $m > j$ 的最小整数 $m$ 是 $m = j+1 = (n+1)/2$。\n\n- **情况2：$n$ 为偶数**。设 $n = 2j$。中位数是两个中心值的平均值，$\\frac{1}{2}(x_{(n/2)} + x_{(n/2+1)}) = \\frac{1}{2}(x_{(j)} + x_{(j+1)})$。如果这两个点中至少有一个是 $M$，估计量就会变得无界。如果索引较高的点 $x_{(j+1)}$ 是一个离群值，这就得到了保证。条件是：\n$$ \\frac{n}{2}+1 > n-m \\implies m > n - \\left(\\frac{n}{2}+1\\right) = \\frac{n}{2}-1 $$\n因为 $n$ 是偶数，所以 $n/2-1 = j-1$ 是一个整数。满足 $m > j-1$ 的最小整数 $m$ 是 $m = j = n/2$。\n\n我们可以统一这两种情况。对于奇数 $n$，最小离群值数量是 $m=(n+1)/2$；对于偶数 $n$，是 $m=n/2$。这对应于 $m = \\lceil n/2 \\rceil$。\n\n- **有限样本崩溃点**：最小污染比例为：\n$$ \\epsilon^\\star_{\\text{Tukey}}(n) = \\frac{\\lceil n/2 \\rceil}{n} $$\n- **渐近崩溃点**：在大样本 $n$ 的极限下，$\\lceil n/2 \\rceil \\approx n/2$。\n$$ \\varepsilon^\\star(\\text{Tukey median}) = \\lim_{n \\to \\infty} \\frac{\\lceil n/2 \\rceil}{n} = \\frac{1}{2} = 0.5 $$\n\n**结果摘要**\n\n| 估计量 | 渐近崩溃点 ($\\varepsilon^\\star$) | 有限样本崩溃点 ($\\epsilon^\\star$) |\n| :--- | :---: | :---: |\n| 样本均值 | $0$ | $\\frac{1}{n}$ |\n| 截尾均值 | $\\tau$ | $\\frac{\\lfloor \\tau n \\rfloor + 1}{n}$ |\n| Tukey中位数 | $0.5$ | $\\frac{\\lceil n/2 \\rceil}{n}$ |\n\n这些公式被实现用于计算给定测试用例的结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Calculates the asymptotic and finite-sample breakdown points for three estimators\n    under an epsilon-contamination model for several test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (100, 0.1),  # General case\n        (101, 0.1),  # Odd n effects on the median\n        (100, 0.0),  # Trimming vanishes, should equal mean\n        (20, 0.2),   # Discrete rounding effects\n        (2, 0.0),    # Smallest even sample size\n    ]\n\n    all_results = []\n    for n, tau in test_cases:\n        # 1. Asymptotic Breakdown Points\n        # These are derived theoretical limits as n -> infinity.\n        # Mean: 0\n        # Trimmed Mean: tau\n        # Median: 0.5\n        asymptotic_bps = [0.0, tau, 0.5]\n\n        # 2. Finite-Sample Breakdown Points\n        # These depend on the sample size n and integer arithmetic.\n        \n        # For the sample mean, 1 outlier is sufficient to cause breakdown.\n        # Minimal fraction of outliers = 1/n.\n        finite_mean_bp = 1 / n\n\n        # For the trimmed mean, breakdown occurs if outliers exceed the trim count k.\n        # k = floor(tau * n). Minimal outliers m = k + 1.\n        # Minimal fraction = (k + 1) / n.\n        k = np.floor(tau * n)\n        finite_trimmed_mean_bp = (k + 1) / n\n\n        # For the median, breakdown occurs if more than half the points are outliers.\n        # Minimal outliers m = ceil(n / 2).\n        # Minimal fraction = ceil(n/2) / n.\n        finite_median_bp = np.ceil(n / 2) / n\n\n        finite_bps = [finite_mean_bp, finite_trimmed_mean_bp, finite_median_bp]\n        \n        all_results.append([asymptotic_bps, finite_bps])\n\n    # Format the final output string to match the problem specification\n    # precisely (list of lists, no spaces).\n    case_strings = []\n    for async_res, finite_res in all_results:\n        async_str = f\"[{','.join(map(str, async_res))}]\"\n        finite_str = f\"[{','.join(map(str, finite_res))}]\"\n        case_strings.append(f\"[{async_str},{finite_str}]\")\n    \n    final_output = f\"[{','.join(case_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```", "id": "3171418"}, {"introduction": "在理解了估计器可能“崩溃”的极端情况后，我们转向一个更细致的工具——影响函数，来衡量稳健性。影响函数精确地量化了单个异常数据点对模型参数估计的“影响力”。在这个实践中[@problem_id:3171489]，你将比较非稳健的普通最小二乘法（OLS）和稳健的Huber回归的影响函数，从而在代码层面验证稳健方法如何通过限制异常值的影响来保护我们的模型。", "problem": "考虑一个由数据生成过程 $y = \\beta_0 + \\beta_1 x + \\varepsilon$ 定义的带截距项的一维线性回归模型，其中 $x$ 是一个标量预测变量，$\\varepsilon$ 是独立噪声。采用经验风险最小化（ERM）作为基本方法：通过最小化数据分布下的期望损失来估计参数。对于普通最小二乘法（OLS），损失是平方损失；对于 Huber 回归，损失是带阈值参数的 Huber 损失。通过影响函数（IF）来研究稳健性，该函数衡量当数据分布在单一点上受到污染时参数估计的无穷小变化。\n\n您需要构建并分析一个具有重尾噪声的统计上合理的场景，具体如下：\n\n1. 使用模型 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$ 生成一个大小为 $n = 5000$ 的合成数据集，参数为 $\\beta_0 = 1.0$ 和 $\\beta_1 = 1.5$。从均值为 $0$、方差为 $1$ 的标准正态分布中独立抽取预测变量 $x_i$。从自由度为 $\\nu = 3$、尺度为 $s = 1.0$ 的学生 t 分布中独立抽取噪声 $\\varepsilon_i$。为了可复现性，使用固定的随机种子 $42$。\n\n2. 在带截距项和单个预测变量的线性回归的 ERM 中，将设计向量写作 $\\tilde{x} = \\begin{bmatrix}1 \\\\ x\\end{bmatrix}$。设损失为 $\\rho(r)$，是残差 $r = y - \\tilde{x}^\\top \\theta$ 的函数，其中 $\\theta = \\begin{bmatrix}\\beta_0 \\\\ \\beta_1\\end{bmatrix}$。定义得分函数 $\\psi(r) = \\frac{d}{dr}\\rho(r)$ 和估计方程 $\\mathbb{E}[\\psi(r)\\tilde{x}] = 0$。在污染点 $z_0 = (x_0, y_0)$ 处的影响函数（IF）由参数泛函关于 $\\varepsilon$-污染的 Gateaux 导数给出：考虑污染后的分布 $(1 - \\varepsilon)P + \\varepsilon \\Delta_{z_0}$，并在 $\\varepsilon = 0$ 处对估计方程的解进行微分。使用敏感度矩阵 $A = \\mathbb{E}\\left[\\frac{\\partial}{\\partial \\theta}\\{\\psi(r)\\tilde{x}\\}\\right]$ 来表示 IF。通过对生成的数据进行样本平均来计算期望。\n\n3. 对于 OLS，使用平方损失，其中 $\\rho_{\\text{OLS}}(r) = \\frac{1}{2} r^2$ 且 $\\psi_{\\text{OLS}}(r) = r$。对于 Huber 回归，使用带阈值参数 $\\delta > 0$ 的 Huber 损失，定义为 $\\rho_{\\delta}(r) = \\begin{cases} \\frac{1}{2}r^2  \\text{若 } |r| \\le \\delta \\\\ \\delta|r| - \\frac{1}{2}\\delta^2  \\text{若 } |r| > \\delta \\end{cases}$，因此 $\\psi_{\\delta}(r) = \\begin{cases} r  \\text{若 } |r| \\le \\delta \\\\ \\delta \\,\\mathrm{sign}(r)  \\text{若 } |r| > \\delta \\end{cases}$。将阈值设为 $\\delta = k \\cdot \\hat{\\sigma}$，其中 $k = 1.345$ 是一个常数，$\\hat{\\sigma}$ 是 $\\varepsilon$ 的一个稳健尺度估计，计算方法是中位数绝对偏差（MAD）乘以 $1.4826$。在计算 $\\psi_{\\delta}$ 和 Huber 回归的敏感度矩阵时使用此 $\\delta$。\n\n4. 通过样本均值近似敏感度矩阵。对于 OLS，使用 $A_{\\text{OLS}} \\approx -\\frac{1}{n}\\sum_{i=1}^{n} \\tilde{x}_i \\tilde{x}_i^\\top$，因为 $\\psi_{\\text{OLS}}'(r) = 1$。对于 Huber，使用 $A_{\\text{Huber}} \\approx -\\frac{1}{n}\\sum_{i=1}^{n} I(|\\varepsilon_i| \\le \\delta)\\, \\tilde{x}_i \\tilde{x}_i^\\top$，其中 $I(\\cdot)$ 是指示函数，且如果 $|r| \\le \\delta$ 则 $\\psi_{\\delta}'(r) = 1$，否则为 $0$。在形成残差和敏感度矩阵时，使用真实参数 $\\theta^\\star = \\begin{bmatrix}1.0 \\\\ 1.5\\end{bmatrix}$，因此 $r_i = \\varepsilon_i$。\n\n5. 对于一个污染点 $z_0 = (x_0, y_0)$，其残差为 $r_0 = y_0 - \\tilde{x}_0^\\top \\theta^\\star$，IF 向量为 $\\mathsf{IF}(z_0) = -A^{-1}\\{\\psi(r_0)\\tilde{x}_0\\}$。为 OLS 和 Huber 回归计算此值。为比较稳健性，对每个测试用例报告标量比率 $R = \\|\\mathsf{IF}_{\\text{Huber}}(z_0)\\|_2 \\big/ \\|\\mathsf{IF}_{\\text{OLS}}(z_0)\\|_2$，其中 $\\|\\cdot\\|_2$ 表示欧几里得范数。\n\n使用以下以 $(x_0, r_0)$ 表示的污染点测试套件，并为每个点定义 $y_0 = \\beta_0 + \\beta_1 x_0 + r_0$：\n- 情况 1：$(x_0, r_0) = (0.0, 0.5)$，因此 $y_0 = 1.0 + 1.5 \\cdot 0.0 + 0.5$。\n- 情况 2：$(x_0, r_0) = (0.0, 10.0)$，因此 $y_0 = 1.0 + 1.5 \\cdot 0.0 + 10.0$。\n- 情况 3：$(x_0, r_0) = (5.0, 0.5)$，因此 $y_0 = 1.0 + 1.5 \\cdot 5.0 + 0.5$。\n- 情况 4：$(x_0, r_0) = (5.0, 10.0)$，因此 $y_0 = 1.0 + 1.5 \\cdot 5.0 + 10.0$。\n\n您的程序应生成单行输出，其中包含上述四种情况的比率 $R$，形式为用方括号括起来的逗号分隔列表（例如，$[r_1,r_2,r_3,r_4]$）。输出必须是实数（浮点数）。此问题不涉及角度或物理单位。", "solution": "该问题被评估为有效。这是一个在稳健统计学（统计学习的一个子领域）中定义明确、有科学依据的练习。所有提供的数据、定义和方程在内部都是一致的，是该领域的标准内容，并且足以推导出唯一的数值解。该问题要求使用影响函数（IF）（这是用于此目的的标准工具）来定量比较普通最小二乘法（OLS）和 Huber 回归的稳健性。\n\n目标是计算 Huber 回归与 OLS 回归的影响函数的欧几里得范数之比，$R = \\|\\mathsf{IF}_{\\text{Huber}}(z_0)\\|_2 \\big/ \\|\\mathsf{IF}_{\\text{OLS}}(z_0)\\|_2$，针对四个不同的污染点 $z_0$。较小的比率表示对特定污染具有更强的稳健性。步骤如下：\n\n首先，我们根据问题规范生成一个合成数据集。\n- 样本大小：$n = 5000$。\n- 预测变量 $x_i$（对于 $i=1, \\dots, n$）独立地从标准正态分布 $x_i \\sim \\mathcal{N}(0, 1)$ 中抽取。\n- 噪声项 $\\varepsilon_i$ 独立地从自由度为 $\\nu = 3$、尺度为 $s=1.0$ 的学生 t 分布中抽取。\n- 数据生成过程为 $y_i = \\beta_0 + \\beta_1 x_i + \\varepsilon_i$，真实参数为 $\\beta_0 = 1.0$ 和 $\\beta_1 = 1.5$。\n使用固定的随机种子 $42$ 以保证可复现性。每个观测的设计向量是 $\\tilde{x}_i = [1, x_i]^\\top$。\n\n分析使用真实参数向量 $\\theta^\\star = [\\beta_0, \\beta_1]^\\top = [1.0, 1.5]^\\top$ 来计算残差，这将残差简化为噪声项本身，$r_i = y_i - \\tilde{x}_i^\\top \\theta^\\star = \\varepsilon_i$。\n\n对于 Huber 回归，其损失函数 $\\rho_{\\delta}(r)$ 需要一个阈值参数 $\\delta$。该参数设置为 $\\delta = k \\cdot \\hat{\\sigma}$，其中 $k=1.345$，$\\hat{\\sigma}$ 是噪声标准差的一个稳健估计。我们通过 $1.4826 \\times \\text{MAD}(\\varepsilon)$ 计算 $\\hat{\\sigma}$，其中 $\\text{MAD}(\\varepsilon)$ 是噪声项的中位数绝对偏差，由 $\\text{median}_i(|\\varepsilon_i - \\text{median}_j(\\varepsilon_j)|)$ 给出。\n\n对于一个污染点 $z_0 = (x_0, y_0)$，其影响函数由 $\\mathsf{IF}(z_0) = -A^{-1}\\{\\psi(r_0)\\tilde{x}_0\\}$ 给出，其中 $r_0 = y_0 - \\tilde{x}_0^\\top\\theta^\\star$ 是污染点的残差，$\\psi(\\cdot)$ 是得分函数（损失函数 $\\rho(\\cdot)$ 的导数），$A$ 是敏感度矩阵。\n\n敏感度矩阵 $A$ 定义为 $A = \\mathbb{E}\\left[\\frac{\\partial}{\\partial \\theta}\\{\\psi(r)\\tilde{x}\\}\\right] = \\mathbb{E}[-\\psi'(r)\\tilde{x}\\tilde{x}^\\top]$。我们使用在生成的数据集上的样本均值来近似这个期望。\n- 对于 OLS，损失为 $\\rho_{\\text{OLS}}(r) = \\frac{1}{2}r^2$，因此得分函数为 $\\psi_{\\text{OLS}}(r) = r$，其导数为 $\\psi'_{\\text{OLS}}(r) = 1$。敏感度矩阵为 $A_{\\text{OLS}} \\approx -\\frac{1}{n} \\sum_{i=1}^n \\tilde{x}_i \\tilde{x}_i^\\top$。\n- 对于 Huber 回归，得分函数为 $\\psi_{\\delta}(r) = \\text{sign}(r) \\min(|r|, \\delta)$。其导数为 $\\psi'_{\\delta}(r) = I(|r| \\le \\delta)$，其中 $I(\\cdot)$ 是指示函数。敏感度矩阵为 $A_{\\text{Huber}} \\approx -\\frac{1}{n} \\sum_{i=1}^n I(|\\varepsilon_i| \\le \\delta) \\tilde{x}_i \\tilde{x}_i^\\top$。\n\n对于由污染点 $(x_0, r_0)$ 定义的四个测试用例中的每一个：\n1. 设计向量为 $\\tilde{x}_0 = [1, x_0]^\\top$。\n2. 计算得分函数值 $\\psi_{\\text{OLS}}(r_0) = r_0$ 和 $\\psi_{\\delta}(r_0) = \\text{sign}(r_0) \\min(|r_0|, \\delta)$。\n3. 构建向量 $\\{\\psi_{\\text{OLS}}(r_0)\\tilde{x}_0\\}$ 和 $\\{\\psi_{\\delta}(r_0)\\tilde{x}_0\\}$。\n4. 通过求解相应的线性方程组，计算影响函数向量 $\\mathsf{IF}_{\\text{OLS}}(z_0) = -A_{\\text{OLS}}^{-1}\\{\\psi_{\\text{OLS}}(r_0)\\tilde{x}_0\\}$ 和 $\\mathsf{IF}_{\\text{Huber}}(z_0) = -A_{\\text{Huber}}^{-1}\\{\\psi_{\\delta}(r_0)\\tilde{x}_0\\}$。\n5. 计算这些向量的欧几里得范数 $\\|\\mathsf{IF}_{\\text{OLS}}(z_0)\\|_2$ 和 $\\|\\mathsf{IF}_{\\text{Huber}}(z_0)\\|_2$。\n6. 计算并收集最终的比率 $R$。\n\n对所有测试用例重复此过程，并将所得比率格式化为所需的输出。", "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef solve():\n    \"\"\"\n    Computes the ratio of influence function norms for Huber vs. OLS regression.\n    \"\"\"\n    # 1. Define constants and set up the simulation environment\n    n = 5000\n    beta_0 = 1.0\n    beta_1 = 1.5\n    theta_star = np.array([beta_0, beta_1])\n    nu = 3.0\n    s_scale = 1.0\n    seed = 42\n    k = 1.345\n    mad_const = 1.4826\n\n    # 2. Generate synthetic data\n    rng = np.random.default_rng(seed)\n    x = rng.normal(loc=0.0, scale=1.0, size=n)\n    # Per problem statement, residuals for matrix calculation are the noise terms\n    eps = stats.t.rvs(df=nu, loc=0.0, scale=s_scale, size=n, random_state=rng)\n    \n    # Construct the design matrix with an intercept term\n    X_tilde = np.c_[np.ones(n), x]\n\n    # 3. Calculate the Huber threshold parameter delta\n    # Compute MAD of the noise terms\n    med_eps = np.median(eps)\n    mad = np.median(np.abs(eps - med_eps))\n    \n    # Compute the robust scale estimate sigma_hat\n    sigma_hat = mad_const * mad\n    \n    # Compute the Huber threshold delta\n    delta = k * sigma_hat\n\n    # 4. Compute the sensitivity matrices A_OLS and A_Huber\n    # For OLS\n    A_ols = (-1/n) * (X_tilde.T @ X_tilde)\n    \n    # For Huber\n    # Find indices where residuals are within the delta threshold\n    inlier_indices = np.abs(eps) = delta\n    # Create the sub-matrix of inliers\n    X_tilde_inliers = X_tilde[inlier_indices]\n    A_huber = (-1/n) * (X_tilde_inliers.T @ X_tilde_inliers)\n\n    # 5. Define test cases and compute ratios\n    test_cases = [\n        (0.0, 0.5),   # Case 1: No leverage, small residual\n        (0.0, 10.0),  # Case 2: No leverage, large residual (vertical outlier)\n        (5.0, 0.5),   # Case 3: High leverage, small residual\n        (5.0, 10.0),  # Case 4: High leverage, large residual\n    ]\n    \n    results = []\n    \n    for x0, r0 in test_cases:\n        x_tilde_0 = np.array([1.0, x0])\n        \n        # --- OLS Influence Function ---\n        # Score function value for OLS\n        psi_ols_r0 = r0\n        # Vector for the IF formula\n        v_ols = psi_ols_r0 * x_tilde_0\n        # Compute IF by solving the linear system A * IF = -v\n        if_ols = np.linalg.solve(A_ols, -v_ols)\n        # Compute the L2 norm\n        norm_if_ols = np.linalg.norm(if_ols)\n        \n        # --- Huber Influence Function ---\n        # Score function value for Huber (clipped at delta)\n        psi_huber_r0 = np.sign(r0) * min(np.abs(r0), delta)\n        # Vector for the IF formula\n        v_huber = psi_huber_r0 * x_tilde_0\n        # Compute IF by solving the linear system\n        if_huber = np.linalg.solve(A_huber, -v_huber)\n        # Compute the L2 norm\n        norm_if_huber = np.linalg.norm(if_huber)\n        \n        # --- Ratio Calculation ---\n        # Handle the case where the denominator might be zero (unlikely here)\n        if norm_if_ols == 0:\n            ratio = np.inf if norm_if_huber > 0 else 0\n        else:\n            ratio = norm_if_huber / norm_if_ols\n            \n        results.append(ratio)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3171489"}, {"introduction": "我们将经典稳健统计中的思想应用于现代对抗学习领域，探索如何为分类器的预测提供可验证的“安全保证”。“认证稳健性”旨在确定一个输入点周围的“安全区域”，在此区域内的任何对抗性扰动都无法改变模型的预测结果。这个练习[@problem_id:3171496]将指导你利用对偶范数和梯度的关系，为一个线性分类器计算其在$\\ell_{1}$和$\\ell_{2}$范数扰动下的认证稳健半径，让你掌握评估模型对抗脆弱性的核心技术。", "problem": "给定一个二维二元分类器，由线性评分函数 $f(\\mathbf{x}) = \\mathbf{w}^{\\top} \\mathbf{x} + b$ 定义，其参数 $\\mathbf{w} \\in \\mathbb{R}^{2}$ 和 $b \\in \\mathbb{R}$ 是固定的。分类由 $f(\\mathbf{x})$ 的符号决定，标签为 $y \\in \\{-1, +1\\}$，有符号间隔为 $m(\\mathbf{x}, y) = y \\cdot f(\\mathbf{x})$。考虑在 $\\mathbf{x}$ 周围的 $\\ell_{p}$-范数球内受约束的对抗性扰动 $\\boldsymbol{\\delta} \\in \\mathbb{R}^{2}$，其中对抗者试图通过选择 $\\boldsymbol{\\delta}$ 来改变分类符号，使得 $f(\\mathbf{x} + \\boldsymbol{\\delta}) \\leq 0$。通过赫尔德不等式（Hölder’s inequality）建立的对偶范数之间的联系，提供了一种通过对所需扰动大小进行下界估计来验证鲁棒性的方法。您必须构建一个简单的二维数据集，应用固定的线性分类器，并使用梯度 $\\nabla_{\\mathbf{x}} f(\\mathbf{x})$ 和对偶范数关系比较在 $\\ell_{1}$ 和 $\\ell_{2}$ 扰动模型下的认证鲁棒性。\n\n使用的基本事实：\n- 赫尔德不等式与对偶范数：对于任意 $\\mathbf{a}, \\mathbf{b} \\in \\mathbb{R}^{d}$，有 $|\\mathbf{a}^{\\top} \\mathbf{b}| \\leq \\|\\mathbf{a}\\|_{q} \\|\\mathbf{b}\\|_{p}$，其中 $1/p + 1/q = 1$。$p=1$ 的对偶是 $q=\\infty$，而 $p=2$ 的对偶是 $q=2$。\n- 对于线性模型 $f(\\mathbf{x}) = \\mathbf{w}^{\\top} \\mathbf{x} + b$，其关于输入的梯度为 $\\nabla_{\\mathbf{x}} f(\\mathbf{x}) = \\mathbf{w}$。\n\n构建数据集：\n- 为分类器使用以下固定参数：$\\mathbf{w} = (0.8, -0.6)$ 和 $b = 0.1$。\n- 考虑 $\\mathbb{R}^{2}$ 中的以下五个带标签的点：\n    1. $\\mathbf{x}_{1} = (2.0, -1.0)$，标签 $y_{1} = +1$。\n    2. $\\mathbf{x}_{2} = (0.5, 0.5)$，标签 $y_{2} = -1$。\n    3. $\\mathbf{x}_{3} = (-1.0, 2.0)$，标签 $y_{3} = -1$。\n    4. $\\mathbf{x}_{4} = (0.125, 0.0)$，标签 $y_{4} = +1$。\n    5. $\\mathbf{x}_{5} = (-0.125, 0.0)$，标签 $y_{5} = +1$。\n\n任务：\n- 对于每个测试点 $(\\mathbf{x}_{i}, y_{i})$，计算有符号间隔 $m_{i} = y_{i} \\cdot f(\\mathbf{x}_{i})$。\n- 使用梯度 $\\mathbf{g} = \\nabla_{\\mathbf{x}} f(\\mathbf{x}) = \\mathbf{w}$ 和赫尔德不等式提供的对偶范数关系，确定针对 $\\ell_{1}$ 和 $\\ell_{2}$ 对抗者的认证鲁棒性半径。认证半径是最大的 $\\epsilon$，使得对于所有满足 $\\|\\boldsymbol{\\delta}\\|_{p} \\leq \\epsilon$ 的扰动 $\\boldsymbol{\\delta}$，都不能改变 $f(\\mathbf{x})$ 的符号。如果 $m_{i} \\leq 0$，则认证半径为 $0$，因为该点已被错误分类或位于决策边界上。将每个点的 $\\ell_{1}$ 和 $\\ell_{2}$ 认证半径表示为非负实数。\n- 将每个计算出的半径四舍五入到六位小数。\n\n测试套件：\n- 上面列出的五个点涵盖了一般情况（大正间隔）、一个错误分类点（负间隔）、另一个中等间隔的正确分类点、一个接近边界的小正间隔情况，以及一个间隔恰好为零的边界情况。这覆盖了典型条件和边缘条件。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例对应一个双元素列表 $[\\text{radius}_{\\ell_{1}}, \\text{radius}_{\\ell_{2}}]$，顺序与上面的测试用例相同。例如，输出应如下所示：\n$[[r_{1,\\ell_{1}}, r_{1,\\ell_{2}}],[r_{2,\\ell_{1}}, r_{2,\\ell_{2}}],\\dots,[r_{5,\\ell_{1}}, r_{5,\\ell_{2}}]]$\n所有半径必须是四舍五入到六位小数的浮点数。不应打印任何其他文本。", "solution": "该问题陈述经评估具有科学依据、定义明确且客观。它提供了一套完整且一致的定义、参数和数据，用以解决线性模型对抗鲁棒性中的一个标准问题。任务是为给定的线性分类器和一组数据点计算认证鲁棒性半径，这是一个定义明确的数学过程。因此，该问题被认为是 **有效的**。\n\n解决方案首先推导线性分类器认证鲁棒性半径的一般公式，然后将此公式应用于数据集中提供的特定点。\n\n线性分类器由评分函数 $f(\\mathbf{x}) = \\mathbf{w}^{\\top} \\mathbf{x} + b$ 定义，其中 $\\mathbf{x} \\in \\mathbb{R}^{d}$ 是输入向量，$\\mathbf{w} \\in \\mathbb{R}^{d}$ 是权重向量，$b \\in \\mathbb{R}$ 是偏置。预测标签为 $\\text{sign}(f(\\mathbf{x}))$。真实标签用 $y \\in \\{-1, +1\\}$ 表示。如果 $y \\cdot f(\\mathbf{x}) > 0$，则点 $(\\mathbf{x}, y)$ 被正确分类。量 $m(\\mathbf{x}, y) = y \\cdot f(\\mathbf{x})$ 是有符号间隔。\n\n对抗鲁棒性关注的是分类器预测在输入受到小扰动时的稳定性。对抗者试图找到一个具有小范数 $\\|\\boldsymbol{\\delta}\\|_{p}$ 的扰动 $\\boldsymbol{\\delta}$，以导致错误分类。对于一个正确分类的点，这意味着找到一个 $\\boldsymbol{\\delta}$，使得分类器输出的符号翻转，即 $y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta}) \\leq 0$。\n\n认证鲁棒性半径 $\\epsilon_p$ 是这样一个最大值，即对于所有满足 $\\|\\boldsymbol{\\delta}\\|_{p} \\leq \\epsilon_p$ 的扰动 $\\boldsymbol{\\delta}$，分类结果保持不变，即 $y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta}) > 0$。\n\n对于线性模型，在扰动 $\\boldsymbol{\\delta}$ 下评分函数的变化可以由一阶近似精确给出：\n$$f(\\mathbf{x} + \\boldsymbol{\\delta}) = \\mathbf{w}^{\\top} (\\mathbf{x} + \\boldsymbol{\\delta}) + b = (\\mathbf{w}^{\\top}\\mathbf{x} + b) + \\mathbf{w}^{\\top}\\boldsymbol{\\delta} = f(\\mathbf{x}) + \\nabla_{\\mathbf{x}}f(\\mathbf{x})^{\\top} \\boldsymbol{\\delta}$$\n由于 $\\nabla_{\\mathbf{x}}f(\\mathbf{x}) = \\mathbf{w}$，我们有 $f(\\mathbf{x} + \\boldsymbol{\\delta}) = f(\\mathbf{x}) + \\mathbf{w}^{\\top}\\boldsymbol{\\delta}$。\n\n为了确定鲁棒性，我们必须找到范数 $\\|\\boldsymbol{\\delta}\\|_p \\leq \\epsilon$ 的扰动 $\\boldsymbol{\\delta}$，它使 $y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta})$ 在负方向上变化最大。\n$$y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta}) = y \\cdot (f(\\mathbf{x}) + \\mathbf{w}^{\\top}\\boldsymbol{\\delta}) = y \\cdot f(\\mathbf{x}) + y \\cdot (\\mathbf{w}^{\\top}\\boldsymbol{\\delta})$$\n项 $y \\cdot f(\\mathbf{x})$ 是初始有符号间隔 $m(\\mathbf{x}, y)$。对抗者试图使项 $y \\cdot (\\mathbf{w}^{\\top}\\boldsymbol{\\delta})$ 尽可能为负。\n根据赫尔德不等式，我们有 $|\\mathbf{a}^{\\top}\\mathbf{b}| \\leq \\|\\mathbf{a}\\|_{q}\\|\\mathbf{b}\\|_{p}$，其中 $1/p + 1/q = 1$。这意味着 $\\mathbf{w}^{\\top}\\boldsymbol{\\delta}$ 的最小值为 $-\\|\\mathbf{w}\\|_{q}\\|\\boldsymbol{\\delta}\\|_{p}$。\n因此，$y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta})$ 的最小值为：\n$$\\min_{\\|\\boldsymbol{\\delta}\\|_p \\leq \\epsilon} \\left( y \\cdot f(\\mathbf{x} + \\boldsymbol{\\delta}) \\right) = y \\cdot f(\\mathbf{x}) - |y| \\cdot \\|\\mathbf{w}\\|_q \\epsilon = m(\\mathbf{x}, y) - \\|\\mathbf{w}\\|_q \\epsilon$$\n只要这个最小值大于 $0$，分类器就保证是鲁棒的：\n$$m(\\mathbf{x}, y) - \\|\\mathbf{w}\\|_q \\epsilon > 0 \\implies \\epsilon  \\frac{m(\\mathbf{x}, y)}{\\|\\mathbf{w}\\|_q}$$\n认证半径 $\\epsilon_p$ 是阈值 $\\frac{m(\\mathbf{x}, y)}{\\|\\mathbf{w}\\|_q}$。此公式仅对 $m(\\mathbf{x}, y) > 0$ 的正确分类点有效。如果一个点被错误分类或在边界上（$m(\\mathbf{x}, y) \\leq 0$），则不需要任何扰动即可满足非正间隔条件，因此认证半径为 $0$。\n因此，认证半径的一般公式为：\n$$\\epsilon_p(\\mathbf{x}, y) = \\max\\left(0, \\frac{y \\cdot f(\\mathbf{x})}{\\|\\mathbf{w}\\|_q}\\right)$$\n其中 $1/p + 1/q = 1$。\n\n问题提供了分类器参数：$\\mathbf{w} = (0.8, -0.6)$ 和 $b = 0.1$。\n我们需要计算 $\\ell_1$ 和 $\\ell_2$ 扰动的认证半径。\n对于 $\\ell_1$ 扰动 ($p=1$)，其对偶范数为 $\\ell_\\infty$-范数 ($q=\\infty$)。\n$$\\|\\mathbf{w}\\|_{\\infty} = \\max(|0.8|, |-0.6|) = 0.8$$\n对于 $\\ell_2$ 扰动 ($p=2$)，其对偶范数为 $\\ell_2$-范数 ($q=2$)。\n$$\\|\\mathbf{w}\\|_2 = \\sqrt{0.8^2 + (-0.6)^2} = \\sqrt{0.64 + 0.36} = \\sqrt{1} = 1.0$$\n半径的公式为：\n$$r_{\\ell_1} = \\max\\left(0, \\frac{m(\\mathbf{x}, y)}{0.8}\\right)$$\n$$r_{\\ell_2} = \\max\\left(0, \\frac{m(\\mathbf{x}, y)}{1.0}\\right)$$\n\n现在我们将这些公式应用于五个给定的数据点。\n\n1.  **点 1**: $\\mathbf{x}_{1} = (2.0, -1.0)$， $y_{1} = +1$\n    $f(\\mathbf{x}_1) = (0.8)(2.0) + (-0.6)(-1.0) + 0.1 = 1.6 + 0.6 + 0.1 = 2.3$\n    $m_1 = y_1 \\cdot f(\\mathbf{x}_1) = (+1)(2.3) = 2.3$。由于 $m_1 > 0$：\n    $r_{1, \\ell_1} = 2.3 / 0.8 = 2.875$\n    $r_{1, \\ell_2} = 2.3 / 1.0 = 2.3$\n\n2.  **点 2**: $\\mathbf{x}_{2} = (0.5, 0.5)$， $y_{2} = -1$\n    $f(\\mathbf{x}_2) = (0.8)(0.5) + (-0.6)(0.5) + 0.1 = 0.4 - 0.3 + 0.1 = 0.2$\n    $m_2 = y_2 \\cdot f(\\mathbf{x}_2) = (-1)(0.2) = -0.2$。由于 $m_2 \\leq 0$ (错误分类)：\n    $r_{2, \\ell_1} = 0.0$\n    $r_{2, \\ell_2} = 0.0$\n\n3.  **点 3**: $\\mathbf{x}_{3} = (-1.0, 2.0)$， $y_{3} = -1$\n    $f(\\mathbf{x}_3) = (0.8)(-1.0) + (-0.6)(2.0) + 0.1 = -0.8 - 1.2 + 0.1 = -1.9$\n    $m_3 = y_3 \\cdot f(\\mathbf{x}_3) = (-1)(-1.9) = 1.9$。由于 $m_3 > 0$：\n    $r_{3, \\ell_1} = 1.9 / 0.8 = 2.375$\n    $r_{3, \\ell_2} = 1.9 / 1.0 = 1.9$\n\n4.  **点 4**: $\\mathbf{x}_{4} = (0.125, 0.0)$， $y_{4} = +1$\n    $f(\\mathbf{x}_4) = (0.8)(0.125) + (-0.6)(0.0) + 0.1 = 0.1 + 0.0 + 0.1 = 0.2$\n    $m_4 = y_4 \\cdot f(\\mathbf{x}_4) = (+1)(0.2) = 0.2$。由于 $m_4 > 0$：\n    $r_{4, \\ell_1} = 0.2 / 0.8 = 0.25$\n    $r_{4, \\ell_2} = 0.2 / 1.0 = 0.2$\n\n5.  **点 5**: $\\mathbf{x}_{5} = (-0.125, 0.0)$， $y_{5} = +1$\n    $f(\\mathbf{x}_5) = (0.8)(-0.125) + (-0.6)(0.0) + 0.1 = -0.1 + 0.0 + 0.1 = 0.0$\n    $m_5 = y_5 \\cdot f(\\mathbf{x}_5) = (+1)(0.0) = 0.0$。由于 $m_5 \\leq 0$ (在决策边界上)：\n    $r_{5, \\ell_1} = 0.0$\n    $r_{5, \\ell_2} = 0.0$\n\n最终计算出的半径，四舍五入到六位小数，如下：\n- 点 1: $[2.875000, 2.300000]$\n- 点 2: $[0.000000, 0.000000]$\n- 点 3: $[2.375000, 1.900000]$\n- 点 4: $[0.250000, 0.200000]$\n- 点 5: $[0.000000, 0.000000]$", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the certified robustness radii for a linear classifier\n    against l1 and l2 perturbations for a given set of data points.\n    \"\"\"\n    # Fixed parameters for the classifier\n    w = np.array([0.8, -0.6])\n    b = 0.1\n\n    # Dataset of labeled points\n    test_cases = [\n        (np.array([2.0, -1.0]), 1),\n        (np.array([0.5, 0.5]), -1),\n        (np.array([-1.0, 2.0]), -1),\n        (np.array([0.125, 0.0]), 1),\n        (np.array([-0.125, 0.0]), 1)\n    ]\n\n    # Calculate dual norms of the weight vector w\n    # For l1 radius (p=1), we need the dual norm q=inf\n    norm_w_inf = np.linalg.norm(w, ord=np.inf)\n    # For l2 radius (p=2), we need the dual norm q=2\n    norm_w_2 = np.linalg.norm(w, ord=2)\n\n    results = []\n    for x, y in test_cases:\n        # Compute the scoring function output\n        f_x = w.T @ x + b\n        \n        # Compute the signed margin\n        margin = y * f_x\n        \n        # If the point is misclassified or on the boundary, the radius is 0\n        if margin = 0:\n            r_l1 = 0.0\n            r_l2 = 0.0\n        else:\n            # Compute certified radii using the formula: margin / ||w||_q\n            r_l1 = margin / norm_w_inf\n            r_l2 = margin / norm_w_2\n            \n        results.append((r_l1, r_l2))\n\n    # Format the results into the required string format with 6 decimal places.\n    # e.g., [[r1_l1,r1_l2],[r2_l1,r2_l2],...]\n    formatted_results = [f\"[{r[0]:.6f},{r[1]:.6f}]\" for r in results]\n    output_string = f\"[{','.join(formatted_results)}]\"\n    \n    print(output_string)\n\nsolve()\n```", "id": "3171496"}]}