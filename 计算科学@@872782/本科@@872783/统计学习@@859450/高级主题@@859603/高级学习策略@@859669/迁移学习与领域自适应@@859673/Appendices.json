{"hands_on_practices": [{"introduction": "我们将从领域自适应中一个常见且清晰的场景开始：先验概率偏移（prior probability shift）。这个练习 [@problem_id:3189015] 要求你在源域和目标域之间唯一的区别是类别平衡度发生变化时，调整你的分类器。你将通过调整模型的 logits 推导并实现一个理论上完美的修正方法，展示一个简单的改变如何能让你的模型完美地适应新领域。", "problem": "考虑在源域和目标域之间存在先验概率偏移情况下的多类域自适应问题。该问题的基本依据包括以下定义和事实。对于随机输入 $x$ 和离散标签 $y \\in \\{0,1,\\ldots,K-1\\}$，令 $p_S(y)$ 和 $p_T(y)$ 分别表示源域和目标域的类先验分布。令 $p_S(y \\mid x)$ 和 $p_T(y \\mid x)$ 表示源域和目标域的后验概率。假设在先验偏移模型中，类条件密度在不同域之间是不变的，即对于所有 $y$，都有 $p_S(x \\mid y) = p_T(x \\mid y)$。根据 Bayes 法则和先验偏移假设，目标域后验概率满足 $p_T(y \\mid x) \\propto p_S(y \\mid x) \\cdot \\frac{p_T(y)}{p_S(y)}$。在多项逻辑模型中，分类器由一个得分向量（logits）$h(x) \\in \\mathbb{R}^K$ 表示，其 softmax 函数通过 $p_S(y=k \\mid x) = \\frac{\\exp(h_k(x))}{\\sum_{j=0}^{K-1} \\exp(h_j(x))}$ 产生源域概率。多类分类的标准监督训练目标是交叉熵损失，对于一个带标签的样本 $(x,y)$，其定义为 $\\ell(h(x), y) = -\\log\\left( \\frac{\\exp(h_y(x))}{\\sum_{j=0}^{K-1} \\exp(h_j(x))} \\right)$，这在 softmax 模型下即为负对数似然。最大后验概率（MAP）决策规则选择后验概率最大的类别。\n\n任务。从先验偏移模型以及上述 softmax 和交叉熵损失的定义出发，推导校准感知自适应原理。该原理通过一个类别相关的偏移量来修改 logits，此偏移量源自目标域与源域类先验的比例，从而使交叉熵能反映目标域的后验概率。然后，在一个程序中实现该原理，该程序需要对下面的每个测试用例计算：\n- 在给定的带标签目标样本上，无自适应的平均交叉熵损失（基准损失）。\n- 在相同样本上，带校准感知自适应的平均交叉熵损失（自适应后损失）。\n- 无自适应的分类准确率（基准准确率），表示为 $[0,1]$ 范围内的小数。\n- 带自适应的分类准确率（自适应后准确率），表示为 $[0,1]$ 范围内的小数。\n\n计算时使用以下定义：\n- 对于任何 logits 向量 $z \\in \\mathbb{R}^K$，softmax 为 $\\operatorname{softmax}(z)_k = \\frac{\\exp(z_k)}{\\sum_{j=0}^{K-1}\\exp(z_j)}$。\n- 对于一个 logits 为 $z$、标签为 $y$ 的样本，其交叉熵为 $\\ell(z, y) = -\\log(\\operatorname{softmax}(z)_y)$。\n- 分类规则为 $\\hat{y} = \\arg\\max_{k \\in \\{0,\\ldots,K-1\\}} z_k$。\n- 校准感知自适应通过加上一个 $\\mathbb{R}^K$ 中的常数偏移向量来修改 logits，该向量仅取决于类别索引 $k$ 和给定的域先验，然后使用相同的 softmax 和交叉熵定义。\n\n数值要求：\n- 所有平均损失必须四舍五入到六位小数。\n- 所有准确率必须四舍五入到四位小数，并以小数形式表示（而非百分比）。\n- 不涉及物理单位或角度。\n\n测试套件。每个测试用例提供类别数 $K$、源域先验 $\\pi_S \\in \\mathbb{R}^K$、目标域先验 $\\pi_T \\in \\mathbb{R}^K$、一组目标域 logits $\\{h^{(i)}\\}_{i=1}^n$ 以及相应的目标域标签 $\\{y^{(i)}\\}_{i=1}^n$。\n\n- 测试用例 1（无先验偏移）：\n  - $K = 3$。\n  - $\\pi_S = [\\,0.4,\\,0.35,\\,0.25\\,]$。\n  - $\\pi_T = [\\,0.4,\\,0.35,\\,0.25\\,]$。\n  - Logits 行：\n    - $[\\,2.0,\\,0.5,\\,-1.0\\,]$, $y=0$。\n    - $[\\,0.2,\\,1.5,\\,0.0\\,]$, $y=1$。\n    - $[\\,\\,-0.5,\\,-0.2,\\,1.0\\,]$, $y=2$。\n    - $[\\,1.0,\\,1.2,\\,0.8\\,]$, $y=1$。\n    - $[\\,0.9,\\,-1.0,\\,0.3\\,]$, $y=0$。\n\n- 测试用例 2（目标域先验严重偏向类别 0）：\n  - $K = 3$。\n  - $\\pi_S = [\\,0.3333333333,\\,0.3333333333,\\,0.3333333333\\,]$。\n  - $\\pi_T = [\\,0.7,\\,0.2,\\,0.1\\,]$。\n  - Logits 行：\n    - $[\\,\\,-0.2,\\,0.4,\\,0.0\\,]$, $y=0$。\n    - $[\\,0.1,\\,0.0,\\,0.2\\,]$, $y=0$。\n    - $[\\,1.0,\\,-0.5,\\,-0.3\\,]$, $y=0$。\n    - $[\\,0.0,\\,1.1,\\,-0.1\\,]$, $y=1$。\n    - $[\\,\\,-0.8,\\,0.3,\\,0.4\\,]$, $y=2$。\n    - $[\\,0.6,\\,-0.2,\\,0.0\\,]$, $y=0$。\n\n- 测试用例 3（反向先验偏移，目标域偏向类别 1 和 2）：\n  - $K = 3$。\n  - $\\pi_S = [\\,0.6,\\,0.3,\\,0.1\\,]$。\n  - $\\pi_T = [\\,0.2,\\,0.5,\\,0.3\\,]$。\n  - Logits 行：\n    - $[\\,1.5,\\,0.2,\\,-0.2\\,]$, $y=1$。\n    - $[\\,0.8,\\,0.7,\\,0.6\\,]$, $y=2$。\n    - $[\\,\\,-0.3,\\,0.9,\\,0.0\\,]$, $y=1$。\n    - $[\\,2.0,\\,-0.5,\\,-0.2\\,]$, $y=0$。\n    - $[\\,\\,-0.5,\\,0.1,\\,1.2\\,]$, $y=2$。\n    - $[\\,0.1,\\,0.2,\\,0.0\\,]$, $y=1$。\n    - $[\\,0.5,\\,-0.3,\\,0.4\\,]$, $y=2$。\n\n程序输出规范。你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果。对于每个测试用例，按 $[L_{\\text{base}}, L_{\\text{adapt}}, A_{\\text{base}}, A_{\\text{adapt}}]$ 的顺序将四个数字附加到此列表中，其中 $L_{\\text{base}}$ 是四舍五入到六位小数的平均基准损失，$L_{\\text{adapt}}$ 是四舍五入到六位小数的平均自适应后损失，$A_{\\text{base}}$ 是四舍五入到四位小数的基准准确率，$A_{\\text{adapt}}$ 是四舍五入到四位小数的自适应后准确率。因此，对于 3 个测试用例，输出列表必须包含 12 个数字。程序必须是自包含的，并且不得读取任何输入或访问外部文件。", "solution": "该问题要求推导并实现一种在先验概率偏移下的域自适应方法，即校准感知自适应方法。核心任务是调整源域分类器的 logits $h(x)$，以正确反映目标域的后验概率。\n\n首先，我们根据给定的信息来形式化地描述问题。给定一个源域 $S$ 和一个目标域 $T$。对于输入 $x$ 和类别标签 $y \\in \\{0, 1, \\ldots, K-1\\}$，源域和目标域的类先验概率分别表示为 $p_S(y)$ 和 $p_T(y)$，当 $y=k$ 时，我们将其写为 $\\pi_S(k)$ 和 $\\pi_T(k)$。核心假设是先验偏移，即类条件密度在不同域之间是不变的：\n$$ p_S(x \\mid y) = p_T(x \\mid y) \\quad \\forall y $$\n源域分类器提供 logits $h(x) \\in \\mathbb{R}^K$，通过 softmax 函数可以从中获得源域后验概率 $p_S(y \\mid x)$：\n$$ p_S(y=k \\mid x) = \\frac{\\exp(h_k(x))}{\\sum_{j=0}^{K-1} \\exp(h_j(x))} $$\n目标是找到 logits $h(x)$ 到新 logits $h'_{\\text{adapt}}(x)$ 的一个变换，使得新 logits 的 softmax 对应于目标域后验概率 $p_T(y \\mid x)$。\n\n我们从先验偏移假设下目标域和源域后验概率之间的关系开始推导。根据 Bayes 法则，$p_T(y \\mid x) = \\frac{p_T(x \\mid y) p_T(y)}{p_T(x)}$。边际概率 $p_T(x)$ 是关于 $y$ 的归一化常数，因此我们可以将其写成正比关系：\n$$ p_T(y \\mid x) \\propto p_T(x \\mid y) p_T(y) $$\n利用类条件不变性 $p_T(x \\mid y) = p_S(x \\mid y)$，我们得到：\n$$ p_T(y \\mid x) \\propto p_S(x \\mid y) p_T(y) $$\n根据源域的 Bayes 法则，我们可以将 $p_S(x \\mid y)$ 表示为 $p_S(x \\mid y) = \\frac{p_S(y \\mid x) p_S(x)}{p_S(y)}$。将其代入正比关系中得到：\n$$ p_T(y \\mid x) \\propto \\frac{p_S(y \\mid x) p_S(x)}{p_S(y)} p_T(y) $$\n项 $p_S(x)$ 对于给定的 $x$ 是一个常数，可以被吸收到比例常数中。因此，我们得到了题目中给出的关键关系：\n$$ p_T(y=k \\mid x) \\propto p_S(y=k \\mid x) \\cdot \\frac{\\pi_T(k)}{\\pi_S(k)} $$\n现在，我们代入源域后验概率 $p_S(y=k \\mid x)$ 的 softmax 定义：\n$$ p_T(y=k \\mid x) \\propto \\left( \\frac{\\exp(h_k(x))}{\\sum_{j=0}^{K-1} \\exp(h_j(x))} \\right) \\cdot \\frac{\\pi_T(k)}{\\pi_S(k)} $$\n分母 $\\sum_{j=0}^{K-1} \\exp(h_j(x))$ 对于类别索引 $k$ 也是一个常数，可以被吸收到比例常数中。剩下：\n$$ p_T(y=k \\mid x) \\propto \\exp(h_k(x)) \\cdot \\frac{\\pi_T(k)}{\\pi_S(k)} $$\n利用属性 $a \\cdot b = \\exp(\\log(a)) \\cdot \\exp(\\log(b)) = \\exp(\\log(a) + \\log(b))$，我们可以将表达式重写为：\n$$ p_T(y=k \\mid x) \\propto \\exp\\left(h_k(x) + \\log\\left(\\frac{\\pi_T(k)}{\\pi_S(k)}\\right)\\right) $$\n这个结果表明，类别 $k$ 的目标域后验概率与一个修正后的 logit 的指数成正比。这定义了**校准感知自适应原理**：通过在原始源域 logits 上加上一个类别相关的偏移量来获得自适应后的 logits $h'_{\\text{adapt}}(x)$。设该偏移向量为 $c \\in \\mathbb{R}^K$，其分量为 $c_k$：\n$$ c_k = \\log\\left(\\frac{\\pi_T(k)}{\\pi_S(k)}\\right) $$\n那么，对于给定的输入 $x$，自适应后的 logits 为：\n$$ h'_{k, \\text{adapt}}(x) = h_k(x) + c_k $$\n这些自适应后 logits 的 softmax 将正确地产生目标域后验概率：\n$$ p_T(y=k \\mid x) = \\operatorname{softmax}(h'_{\\text{adapt}}(x))_k = \\frac{\\exp(h'_{k, \\text{adapt}}(x))}{\\sum_{j=0}^{K-1} \\exp(h'_{j, \\text{adapt}}(x))} $$\n基于这个推导出的原理，我们现在可以定义所需的度量指标。对于一个给定的、logits 为 $h(x)$ 的样本 $(x, y)$，我们计算：\n1.  **基准（未自适应）度量指标**：使用原始 logits $h(x)$ 计算。\n    *   基准交叉熵损失：$\\ell_{\\text{base}}(h(x), y) = -\\log(\\operatorname{softmax}(h(x))_y)$。\n    *   基准预测：$\\hat{y}_{\\text{base}} = \\arg\\max_{k} h_k(x)$。\n    *   平均基准损失 $L_{\\text{base}}$ 和基准准确率 $A_{\\text{base}}$ 是这些量在数据集上的平均值。\n\n2.  **自适应后度量指标**：使用自适应后的 logits $h'_{\\text{adapt}}(x) = h(x) + c$ 计算。\n    *   自适应后交叉熵损失：$\\ell_{\\text{adapt}}(h'_{\\text{adapt}}(x), y) = -\\log(\\operatorname{softmax}(h'_{\\text{adapt}}(x))_y)$。这是目标域模型下的负对数似然。\n    *   自适应后预测（目标域后验的 MAP 规则）：$\\hat{y}_{\\text{adapt}} = \\arg\\max_{k} h'_{k, \\text{adapt}}(x)$。\n    *   平均自适应后损失 $L_{\\text{adapt}}$ 和自适应后准确率 $A_{\\text{adapt}}$ 是这些量在数据集上的平均值。\n\n实现过程将首先根据给定的源域和目标域先验 $\\pi_S$ 和 $\\pi_T$ 计算常数偏移向量 $c$，从而处理每个测试用例。然后，对每个样本计算四个度量指标：基准损失、自适应后损失、基准准确率和自适应后准确率。最后，将这些指标在测试用例的所有样本上取平均，并四舍五入到指定的精度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the domain adaptation problem for the given test suite.\n    Derives and applies calibration-aware adaptation, then computes and\n    formats the required metrics.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"K\": 3,\n            \"pi_S\": [0.4, 0.35, 0.25],\n            \"pi_T\": [0.4, 0.35, 0.25],\n            \"logits\": [\n                [2.0, 0.5, -1.0], [0.2, 1.5, 0.0], [-0.5, -0.2, 1.0],\n                [1.0, 1.2, 0.8], [0.9, -1.0, 0.3]\n            ],\n            \"labels\": [0, 1, 2, 1, 0]\n        },\n        {\n            \"K\": 3,\n            \"pi_S\": [0.3333333333, 0.3333333333, 0.3333333333],\n            \"pi_T\": [0.7, 0.2, 0.1],\n            \"logits\": [\n                [-0.2, 0.4, 0.0], [0.1, 0.0, 0.2], [1.0, -0.5, -0.3],\n                [0.0, 1.1, -0.1], [-0.8, 0.3, 0.4], [0.6, -0.2, 0.0]\n            ],\n            \"labels\": [0, 0, 0, 1, 2, 0]\n        },\n        {\n            \"K\": 3,\n            \"pi_S\": [0.6, 0.3, 0.1],\n            \"pi_T\": [0.2, 0.5, 0.3],\n            \"logits\": [\n                [1.5, 0.2, -0.2], [0.8, 0.7, 0.6], [-0.3, 0.9, 0.0],\n                [2.0, -0.5, -0.2], [-0.5, 0.1, 1.2], [0.1, 0.2, 0.0],\n                [0.5, -0.3, 0.4]\n            ],\n            \"labels\": [1, 2, 1, 0, 2, 1, 2]\n        }\n    ]\n\n    def softmax(z):\n        \"\"\"Computes the numerically stable softmax of a vector.\"\"\"\n        z_shifted = z - np.max(z)\n        exps = np.exp(z_shifted)\n        return exps / np.sum(exps)\n\n    def compute_metrics_for_case(pi_S_list, pi_T_list, logits_list, labels_list):\n        \"\"\"\n        Computes base and adapted metrics for a single test case.\n        \"\"\"\n        pi_S = np.array(pi_S_list, dtype=np.float64)\n        pi_T = np.array(pi_T_list, dtype=np.float64)\n        logits = np.array(logits_list, dtype=np.float64)\n        labels = np.array(labels_list)\n        n_samples = len(labels)\n\n        # The prior shift assumption requires pi_S(k) > 0 for the ratio to be defined.\n        # Problem data adheres to this.\n        offset = np.log(pi_T / pi_S)\n\n        base_losses = []\n        base_correct_count = 0\n        adapted_losses = []\n        adapted_correct_count = 0\n\n        for i in range(n_samples):\n            h = logits[i]\n            y = labels[i]\n\n            # Base (unadapted) metrics\n            base_probs = softmax(h)\n            base_loss = -np.log(base_probs[y])\n            base_losses.append(base_loss)\n            \n            base_pred = np.argmax(h)\n            if base_pred == y:\n                base_correct_count += 1\n\n            # Adapted metrics\n            h_adapt = h + offset\n            adapted_probs = softmax(h_adapt)\n            adapted_loss = -np.log(adapted_probs[y])\n            adapted_losses.append(adapted_loss)\n            \n            adapted_pred = np.argmax(h_adapt)\n            if adapted_pred == y:\n                adapted_correct_count += 1\n\n        mean_base_loss = np.mean(base_losses)\n        base_accuracy = base_correct_count / n_samples\n        mean_adapted_loss = np.mean(adapted_losses)\n        adapted_accuracy = adapted_correct_count / n_samples\n        \n        # Rounding to specified precision\n        L_base = round(mean_base_loss, 6)\n        L_adapt = round(mean_adapted_loss, 6)\n        A_base = round(base_accuracy, 4)\n        A_adapt = round(adapted_accuracy, 4)\n\n        return [L_base, L_adapt, A_base, A_adapt]\n\n    all_results = []\n    for case in test_cases:\n        case_results = compute_metrics_for_case(\n            case[\"pi_S\"],\n            case[\"pi_T\"],\n            case[\"logits\"],\n            case[\"labels\"]\n        )\n        all_results.extend(case_results)\n\n    # Format output according to specification.\n    # Losses to 6 decimal places, accuracies to 4 decimal places.\n    formatted_results = [\n        f\"{res:.6f}\" if i % 4  2 else f\"{res:.4f}\"\n        for i, res in enumerate(all_results)\n    ]\n    \n    # Python's default string conversion for floats might not have the decimal point.\n    # We re-format to ensure the format is consistent.\n    final_output = []\n    for i, res in enumerate(all_results):\n        if i % 4  2: # Losses\n            final_output.append(f\"{res:.6f}\")\n        else: # Accuracies\n            final_output.append(f\"{res:.4f}\")\n\n    print(f\"[{','.join(final_output)}]\")\n\nsolve()\n```", "id": "3189015"}, {"introduction": "在许多现实情况下，我们对领域偏移缺乏详细的了解，只能接触到无标签的目标数据。这个练习 [@problem_id:3189008] 探讨了一种流行的启发式方法：自适应批量归一化（Batch Normalization, BN）统计量。通过一个可解析的模型，你将研究该技术的工作原理，更重要的是，发现它在何种条件下能够提升性能，又在何种情况下会自相矛盾地使性能恶化。", "problem": "考虑一个统计学习中的二元分类器，其包含一个批量归一化 (BN) 层。批量归一化 (BN) 通过减去数据集范围的边际均值并除以数据集范围的边际标准差来对标量特征 $x$ 进行归一化。在源域上进行训练时，分类器使用经 BN 归一化的特征来做出决策：当归一化特征为非负时，预测为类别 $+1$，否则预测为类别 $-1$。在目标域上进行推理时，只有无标签的目标域数据可用于调整 BN 统计量（均值和方差），这是一个标准的无监督域自适应 (DA) 过程。\n\n假设以下基本前提：\n- 源域具有二元标签 $y \\in \\{+1,-1\\}$ 和单个标量特征 $x$。在给定标签 $y$ 的条件下，$x$ 服从高斯分布，其类条件均值为 $\\mu_S^y$，共享方差为 $\\sigma^2$。类先验概率为 $\\pi_S = \\mathbb{P}(y=+1)$。\n- 源域 BN 统计量是使用源域无标签混合数据计算出的边际均值 $\\mu_S^{\\mathrm{mix}}$ 和边际标准差 $\\sigma_S^{\\mathrm{mix}}$。在 BN 归一化空间中，用于预测 $+1$ 与 $-1$ 的决策规则是以 $0$ 为阈值。\n- 目标域中 $x \\mid y$ 的高斯函数形式与源域相同，共享方差为 $\\sigma^2$，但类条件均值可能因域间存在一个对两个类别都相等的未知偏移量而发生偏移，并且类先验概率也可能不同。具体而言，定义 $\\mu_T^{+1} = \\mu_S^{+1} + \\delta$ 和 $\\mu_T^{-1} = \\mu_S^{-1} + \\delta$（对于某个偏移量 $\\delta$），并令 $\\pi_T = \\mathbb{P}(y=+1)$ 表示目标域先验概率。\n- BN 调整使用无标签的目标域数据来重新计算目标域边际均值 $\\mu_T^{\\mathrm{mix}}$ 和目标域边际标准差 $\\sigma_T^{\\mathrm{mix}}$，并在 BN 归一化空间中应用相同的零阈值决策规则。\n\n您的任务是实现一个程序，该程序为每个指定的测试用例计算在以下两种情况下的目标域错分类风险：\n1.  使用源域边际均值作为原始 BN 阈值（即，在原始特征空间中使用 $\\mu_S^{\\mathrm{mix}}$ 作为决策阈值）。\n2.  使用目标域边际均值作为调整后的 BN 阈值（即，在原始特征空间中使用 $\\mu_T^{\\mathrm{mix}}$ 作为决策阈值）。\n\n错分类风险必须根据给定的高斯假设和类先验概率精确计算，无需使用目标域的标签。然后，对于每个测试用例，输出一个布尔值，指示与使用源域 BN 统计量相比，BN 调整是否严格降低了目标域的错分类风险。严格降低意味着调整后的风险更小，而非相等。如果没有严格降低，则输出应为 false。\n\n要使用的测试套件（每个元组编码为 $(\\mu_S^{+1}, \\mu_S^{-1}, \\sigma, \\pi_S, \\delta, \\pi_T)$）：\n- 用例 $1$：$(1.0, -1.0, 0.5, 0.5, 1.0, 0.5)$\n- 用例 $2$：$(0.8, -0.8, 0.5, 0.5, 0.0, 0.5)$\n- 用例 $3$：$(1.0, -1.0, 0.5, 0.5, 0.0, 0.8)$\n- 用例 $4$：$(1.0, -1.0, 1.5, 0.5, 0.2, 0.5)$\n\n您必须使用的定义：\n- 源域边际均值为 $\\mu_S^{\\mathrm{mix}} = \\pi_S \\mu_S^{+1} + (1 - \\pi_S)\\mu_S^{-1}$。\n- 目标域类条件均值为 $\\mu_T^{+1} = \\mu_S^{+1} + \\delta$ 和 $\\mu_T^{-1} = \\mu_S^{-1} + \\delta$。\n- 目标域边际均值为 $\\mu_T^{\\mathrm{mix}} = \\pi_T \\mu_T^{+1} + (1 - \\pi_T)\\mu_T^{-1}$。\n\n程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如 $[r_1,r_2,r_3,r_4]$），其中每个 $r_i$ 是对应测试用例的布尔值，指示 BN 调整是否严格降低了目标域的风险。", "solution": "问题要求我们确定批量归一化统计量的无监督域自适应是否严格降低了目标域上的错分类风险。我们获得了一个关于源域和目标域中数据的特定统计模型。\n\n该模型适用于一个标签为 $y \\in \\{-1, +1\\}$ 的二元分类问题。特征 $x$ 是一个单一标量。类条件分布是高斯分布。在源域中，$x|y \\sim \\mathcal{N}(\\mu_S^y, \\sigma^2)$，类先验概率为 $\\pi_S = \\mathbb{P}(y=+1)$。在目标域中，均值被一个公共偏移量 $\\delta$ 平移，因此 $\\mu_T^{+1} = \\mu_S^{+1} + \\delta$ 且 $\\mu_T^{-1} = \\mu_S^{-1} + \\delta$。方差 $\\sigma^2$ 是共享的。目标域类先验概率为 $\\pi_T = \\mathbb{P}(y=+1)$。\n\n分类器使用一个批量归一化 (BN) 层。决策规则是，如果归一化特征为非负，则预测为类别 $+1$，否则预测为类别 $-1$。归一化特征为 $(x - \\mu^{\\mathrm{mix}}) / \\sigma^{\\mathrm{mix}}$，其中 $\\mu^{\\mathrm{mix}}$ 和 $\\sigma^{\\mathrm{mix}}$ 分别是 $x$ 的边际均值和边际标准差。由于对于非退化分布，边际标准差总是正的，因此决策规则 $\\frac{x-\\mu^{\\mathrm{mix}}}{\\sigma^{\\mathrm{mix}}} \\ge 0$ 等价于对原始特征 $x$ 应用一个简单阈值：\n$$\n\\hat{y} = \\begin{cases} +1  \\text{if } x \\ge \\theta \\\\ -1  \\text{if } x  \\theta \\end{cases}\n$$\n其中阈值 $\\theta$ 是边际均值 $\\mu^{\\mathrm{mix}}$。\n\n我们必须比较两种对目标域数据进行分类的情况：\n1.  使用源域 BN 统计量：阈值是源域边际均值，$\\theta_S = \\mu_S^{\\mathrm{mix}}$。\n2.  使用调整后的 BN 统计量：阈值是目标域边际均值，$\\theta_T = \\mu_T^{\\mathrm{mix}}$，由无标签的目标域数据计算得出。\n\n这些阈值的公式如下：\n-   源域阈值：$\\theta_S = \\mu_S^{\\mathrm{mix}} = \\pi_S \\mu_S^{+1} + (1 - \\pi_S)\\mu_S^{-1}$。\n-   目标域阈值：$\\theta_T = \\mu_T^{\\mathrm{mix}} = \\pi_T \\mu_T^{+1} + (1 - \\pi_T)\\mu_T^{-1}$。\n\n目标是计算每个阈值在目标域上的错分类风险，并检查自适应是否带来了严格的改进。对于给定的阈值 $\\theta$，错分类风险 $R$ 是在目标域上做出错误预测的概率：\n$$\nR(\\theta) = \\mathbb{P}(\\hat{y} \\ne y) = \\mathbb{P}(\\hat{y}=-1 | y=+1)\\mathbb{P}(y=+1) + \\mathbb{P}(\\hat{y}=+1 | y=-1)\\mathbb{P}(y=-1)\n$$\n使用决策规则和目标域先验概率 $\\pi_T$，上式变为：\n$$\nR(\\theta) = \\pi_T \\cdot \\mathbb{P}(x  \\theta | y=+1) + (1-\\pi_T) \\cdot \\mathbb{P}(x \\ge \\theta | y=-1)\n$$\n目标域中的数据遵循 $x|y=+1 \\sim \\mathcal{N}(\\mu_T^{+1}, \\sigma^2)$ 和 $x|y=-1 \\sim \\mathcal{N}(\\mu_T^{-1}, \\sigma^2)$。这些概率可以使用标准正态分布的累积分布函数 (CDF) $\\Phi(z)$ 来表示：\n$$\n\\mathbb{P}(x  \\theta | y=+1) = \\Phi\\left(\\frac{\\theta - \\mu_T^{+1}}{\\sigma}\\right)\n$$\n$$\n\\mathbb{P}(x \\ge \\theta | y=-1) = 1 - \\mathbb{P}(x  \\theta | y=-1) = 1 - \\Phi\\left(\\frac{\\theta - \\mu_T^{-1}}{\\sigma}\\right) = \\Phi\\left(\\frac{\\mu_T^{-1} - \\theta}{\\sigma}\\right)\n$$\n将这些代入风险方程，得到目标域风险的完整公式：\n$$\nR(\\theta) = \\pi_T \\Phi\\left(\\frac{\\theta - \\mu_T^{+1}}{\\sigma}\\right) + (1-\\pi_T) \\Phi\\left(\\frac{\\mu_T^{-1} - \\theta}{\\sigma}\\right)\n$$\n现在，我们将此框架应用于每个测试用例。对于每个用例，我们将计算使用源域阈值的风险 $R_S = R(\\theta_S)$ 和使用调整后阈值的风险 $R_T = R(\\theta_T)$。然后我们评估布尔条件 $R_T  R_S$。\n\n**用例 1：** $(\\mu_S^{+1}, \\mu_S^{-1}, \\sigma, \\pi_S, \\delta, \\pi_T) = (1.0, -1.0, 0.5, 0.5, 1.0, 0.5)$\n-   源域参数：$\\mu_S^{+1}=1.0$, $\\mu_S^{-1}=-1.0$, $\\pi_S=0.5$。\n-   目标域参数：$\\sigma=0.5$, $\\delta=1.0$, $\\pi_T=0.5$。\n-   派生的目标域均值：$\\mu_T^{+1} = 1.0 + 1.0 = 2.0$, $\\mu_T^{-1} = -1.0 + 1.0 = 0.0$。\n-   阈值：\n    -   $\\theta_S = 0.5 \\cdot (1.0) + (1-0.5) \\cdot (-1.0) = 0.0$。\n    -   $\\theta_T = 0.5 \\cdot (2.0) + (1-0.5) \\cdot (0.0) = 1.0$。\n-   在目标域上的风险：\n    -   $R_S = R(0.0) = 0.5 \\cdot \\Phi\\left(\\frac{0.0 - 2.0}{0.5}\\right) + 0.5 \\cdot \\Phi\\left(\\frac{0.0 - 0.0}{0.5}\\right) = 0.5 \\cdot (\\Phi(-4.0) + \\Phi(0.0)) \\approx 0.5 \\cdot (3.17 \\times 10^{-5} + 0.5) \\approx 0.250016$。\n    -   $R_T = R(1.0) = 0.5 \\cdot \\Phi\\left(\\frac{1.0 - 2.0}{0.5}\\right) + 0.5 \\cdot \\Phi\\left(\\frac{0.0 - 1.0}{0.5}\\right) = 0.5 \\cdot (\\Phi(-2.0) + \\Phi(-2.0)) = \\Phi(-2.0) \\approx 0.02275$。\n-   比较：$R_T  R_S$。结果为 **True**。\n\n**用例 2：** $(\\mu_S^{+1}, \\mu_S^{-1}, \\sigma, \\pi_S, \\delta, \\pi_T) = (0.8, -0.8, 0.5, 0.5, 0.0, 0.5)$\n-   这是一个无偏移情景，源域和目标域分布相同（$\\delta=0$, $\\pi_S=\\pi_T$）。\n-   源域参数：$\\mu_S^{+1}=0.8$, $\\mu_S^{-1}=-0.8$, $\\pi_S=0.5$。\n-   目标域参数：$\\sigma=0.5$, $\\delta=0.0$, $\\pi_T=0.5$。\n-   派生的目标域均值：$\\mu_T^{+1} = 0.8$, $\\mu_T^{-1} = -0.8$。\n-   阈值：\n    -   $\\theta_S = 0.5 \\cdot (0.8) + 0.5 \\cdot (-0.8) = 0.0$。\n    -   $\\theta_T = 0.5 \\cdot (0.8) + 0.5 \\cdot (-0.8) = 0.0$。\n-   风险：由于 $\\theta_S = \\theta_T$，风险是相同的，$R_S = R_T$。\n-   比较：降低不是严格的（$R_T \\not R_S$）。结果为 **False**。\n\n**用例 3：** $(\\mu_S^{+1}, \\mu_S^{-1}, \\sigma, \\pi_S, \\delta, \\pi_T) = (1.0, -1.0, 0.5, 0.5, 0.0, 0.8)$\n-   这是一个先验概率偏移情景（$\\delta=0$, $\\pi_S \\ne \\pi_T$）。\n-   源域参数：$\\mu_S^{+1}=1.0$, $\\mu_S^{-1}=-1.0$, $\\pi_S=0.5$。\n-   目标域参数：$\\sigma=0.5$, $\\delta=0.0$, $\\pi_T=0.8$。\n-   派生的目标域均值：$\\mu_T^{+1} = 1.0$, $\\mu_T^{-1} = -1.0$。\n-   阈值：\n    -   $\\theta_S = 0.5 \\cdot (1.0) + 0.5 \\cdot (-1.0) = 0.0$。\n    -   $\\theta_T = 0.8 \\cdot (1.0) + 0.2 \\cdot (-1.0) = 0.8 - 0.2 = 0.6$。\n-   在目标域上的风险：\n    -   $R_S = R(0.0) = 0.8 \\cdot \\Phi\\left(\\frac{0.0 - 1.0}{0.5}\\right) + 0.2 \\cdot \\Phi\\left(\\frac{-1.0 - 0.0}{0.5}\\right) = 0.8 \\cdot \\Phi(-2.0) + 0.2 \\cdot \\Phi(-2.0) = \\Phi(-2.0) \\approx 0.02275$。\n    -   $R_T = R(0.6) = 0.8 \\cdot \\Phi\\left(\\frac{0.6 - 1.0}{0.5}\\right) + 0.2 \\cdot \\Phi\\left(\\frac{-1.0 - 0.6}{0.5}\\right) = 0.8 \\cdot \\Phi(-0.8) + 0.2 \\cdot \\Phi(-3.2) \\approx 0.8 \\cdot (0.21186) + 0.2 \\cdot (0.000687) \\approx 0.16948 + 0.00014 \\approx 0.16962$。\n-   比较：$R_T > R_S$。自适应增加了风险。结果为 **False**。\n\n**用例 4：** $(\\mu_S^{+1}, \\mu_S^{-1}, \\sigma, \\pi_S, \\delta, \\pi_T) = (1.0, -1.0, 1.5, 0.5, 0.2, 0.5)$\n-   这是一个具有较大方差的协变量偏移情景。\n-   源域参数：$\\mu_S^{+1}=1.0$, $\\mu_S^{-1}=-1.0$, $\\pi_S=0.5$。\n-   目标域参数：$\\sigma=1.5$, $\\delta=0.2$, $\\pi_T=0.5$。\n-   派生的目标域均值：$\\mu_T^{+1} = 1.0 + 0.2 = 1.2$, $\\mu_T^{-1} = -1.0 + 0.2 = -0.8$。\n-   阈值：\n    -   $\\theta_S = 0.5 \\cdot (1.0) + 0.5 \\cdot (-1.0) = 0.0$。\n    -   $\\theta_T = 0.5 \\cdot (1.2) + 0.5 \\cdot (-0.8) = 0.6 - 0.4 = 0.2$。\n-   在目标域上的风险：\n    -   $R_S = R(0.0) = 0.5 \\cdot \\Phi\\left(\\frac{0.0 - 1.2}{1.5}\\right) + 0.5 \\cdot \\Phi\\left(\\frac{-0.8 - 0.0}{1.5}\\right) = 0.5 \\cdot (\\Phi(-0.8) + \\Phi(-0.5333)) \\approx 0.5 \\cdot (0.21186 + 0.2969) \\approx 0.25438$。\n    -   $R_T = R(0.2) = 0.5 \\cdot \\Phi\\left(\\frac{0.2-1.2}{1.5}\\right) + 0.5 \\cdot \\Phi\\left(\\frac{-0.8-0.2}{1.5}\\right) = 0.5 \\cdot (\\Phi(-0.6667) + \\Phi(-0.6667)) = \\Phi(-0.6667) \\approx 0.25249$。\n-   比较：$R_T  R_S$。结果为 **True**。\n\n综上所述，四个用例的结果分别为 **True**、**False**、**False** 和 **True**。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes for each test case whether BN adaptation strictly reduces \n    target-domain misclassification risk.\n    \"\"\"\n    # Test suite to use (each tuple encodes (mu_S^+1, mu_S^-1, sigma, pi_S, delta, pi_T))\n    test_cases = [\n        (1.0, -1.0, 0.5, 0.5, 1.0, 0.5), # Case 1\n        (0.8, -0.8, 0.5, 0.5, 0.0, 0.5), # Case 2\n        (1.0, -1.0, 0.5, 0.5, 0.0, 0.8), # Case 3\n        (1.0, -1.0, 1.5, 0.5, 0.2, 0.5), # Case 4\n    ]\n\n    results = []\n\n    def calculate_risk(theta, mu_T_p1, mu_T_m1, sigma, pi_T):\n        \"\"\"\n        Calculates the misclassification risk on the target domain for a given threshold.\n        R(theta) = pi_T * P(predict -1 | y=+1) + (1-pi_T) * P(predict +1 | y=-1)\n                 = pi_T * P(x  theta | y=+1) + (1-pi_T) * P(x >= theta | y=-1)\n        \"\"\"\n        # P(x  theta | y=+1) where x ~ N(mu_T_p1, sigma^2)\n        prob_miss_p1 = norm.cdf((theta - mu_T_p1) / sigma)\n        \n        # P(x >= theta | y=-1) where x ~ N(mu_T_m1, sigma^2)\n        # This is 1 - P(x  theta | y=-1) = 1 - cdf(...) = norm.sf(...)\n        prob_miss_m1 = norm.sf((theta - mu_T_m1) / sigma)\n\n        risk = pi_T * prob_miss_p1 + (1 - pi_T) * prob_miss_m1\n        return risk\n\n    for case in test_cases:\n        mu_S_p1, mu_S_m1, sigma, pi_S, delta, pi_T = case\n\n        # Calculate target-domain class-conditional means\n        mu_T_p1 = mu_S_p1 + delta\n        mu_T_m1 = mu_S_m1 + delta\n        \n        # 1. Calculate threshold from source BN statistics\n        # The threshold is the source marginal mean.\n        theta_S = pi_S * mu_S_p1 + (1 - pi_S) * mu_S_m1\n\n        # 2. Calculate threshold from adapted BN statistics\n        # The threshold is the target marginal mean.\n        theta_T = pi_T * mu_T_p1 + (1 - pi_T) * mu_T_m1\n        \n        # Calculate misclassification risk on the target domain for both thresholds\n        risk_source_thresh = calculate_risk(theta_S, mu_T_p1, mu_T_m1, sigma, pi_T)\n        risk_adapted_thresh = calculate_risk(theta_T, mu_T_p1, mu_T_m1, sigma, pi_T)\n        \n        # Determine if adaptation strictly reduces risk\n        adaptation_improves = risk_adapted_thresh  risk_source_thresh\n        results.append(adaptation_improves)\n\n    # Format output as a comma-separated list of booleans in brackets.\n    # The boolean values must be capitalized as `True` or `False`.\n    # Using map(str, ...) is suitable as it calls the `str()` representation.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3189008"}, {"introduction": "我们应该如何评估领域自适应方法的成功与否？这最后一个练习 [@problem_id:3188990] 深入探讨了模型判别能力与校准度之间一个至关重要但常被忽视的区别。通过模拟实验，你将亲眼见证一种自适应方法如何在提高曲线下面积（AUC）的同时，降低其预测概率的质量（Brier分数），从而促使我们采用更细致的评估方法。", "problem": "考虑一个具有一个源域和多个目标域的二元分类问题。目标是以有原则的方式研究域偏移下的校准与判别之间的权衡，并实现一个程序，以演示一个在目标域上改善判别的方法何时会恶化校准。\n\n从以下基础定义开始。\n\n1.  设输入为实值特征，记作 $x \\in \\mathbb{R}$，标签为 $y \\in \\{0,1\\}$。一个概率分类器输出一个分数 $s(x) \\in \\mathbb{R}$ 和一个预测概率 $\\hat{p}(x) \\in [0,1]$，通常通过一个逻辑斯蒂链接 $\\sigma(t) = 1/(1+e^{-t})$ 实现，其中 $\\hat{p}(x) = \\sigma(s(x))$。\n\n2.  某个分布上的受试者工作特征曲线下面积（Area Under the Receiver Operating Characteristic Curve, AUC）是一个随机选择的正实例比一个随机选择的负实例得分更高的概率。形式上，对于分数 $s(X)$ 和标签 $Y$，\n    $$\n    \\mathrm{AUC} = \\mathbb{P}\\big(s(X^+) > s(X^-)\\big) + \\tfrac{1}{2}\\mathbb{P}\\big(s(X^+) = s(X^-)\\big).\n    $$\n    判别质量通过 $\\mathrm{AUC}$ 进行评估；它仅取决于由 $s(x)$ 引导出的排序。\n\n3.  Brier 分数是预测概率的均方误差，\n    $$\n    \\mathrm{Brier} = \\mathbb{E}\\big[(\\hat{p}(X) - Y)^2\\big],\n    $$\n    这是一个强调校准的合宜评分规则。\n\n4.  源域 $\\mathcal{S}$ 由一个具有共享方差的同方差高斯类条件模型生成。具体来说，设 $Y \\sim \\mathrm{Bernoulli}(\\pi_{\\mathcal{S}})$，其中 $\\pi_{\\mathcal{S}} = 0.5$，条件分布为\n    $$\n    X \\mid Y=1 \\sim \\mathcal{N}(\\mu_{1,\\mathcal{S}}, \\sigma_{\\mathcal{S}}^2), \\quad X \\mid Y=0 \\sim \\mathcal{N}(\\mu_{0,\\mathcal{S}}, \\sigma_{\\mathcal{S}}^2),\n    $$\n    其中 $\\mu_{1,\\mathcal{S}} = 1.5$，$\\mu_{0,\\mathcal{S}} = -1.5$，且 $\\sigma_{\\mathcal{S}} = 1.0$。\n\n5.  在此源模型下，贝叶斯后验对数几率是 $x$ 的线性函数。根据基本的高斯似然和贝叶斯法则，后验对数几率的形式为\n    $$\n    \\log\\frac{\\mathbb{P}(Y=1\\mid X=x)}{\\mathbb{P}(Y=0\\mid X=x)} = \\log\\frac{\\pi_{\\mathcal{S}}}{1-\\pi_{\\mathcal{S}}} + \\frac{\\mu_{1,\\mathcal{S}} - \\mu_{0,\\mathcal{S}}}{\\sigma_{\\mathcal{S}}^2}\\,x - \\frac{\\mu_{1,\\mathcal{S}}^2 - \\mu_{0,\\mathcal{S}}^2}{2\\sigma_{\\mathcal{S}}^2}.\n    $$\n    因此，一个校准的源模型是\n    $$\n    s_{\\mathrm{base}}(x) = w_{\\mathcal{S}} x + b_{\\mathcal{S}}, \\quad \\hat{p}_{\\mathrm{base}}(x) = \\sigma\\big(s_{\\mathrm{base}}(x)\\big),\n    $$\n    其中 $w_{\\mathcal{S}} = (\\mu_{1,\\mathcal{S}} - \\mu_{0,\\mathcal{S}})/\\sigma_{\\mathcal{S}}^2$ 且 $b_{\\mathcal{S}} = \\log\\frac{\\pi_{\\mathcal{S}}}{1-\\pi_{\\mathcal{S}}} - \\frac{\\mu_{1,\\mathcal{S}}^2 - \\mu_{0,\\mathcal{S}}^2}{2\\sigma_{\\mathcal{S}}^2}$。\n\n6.  一个旨在用于方差偏移目标的、聚焦于秩的域适应评分函数由二次统计量定义，\n    $$\n    s_{\\mathrm{rank}}(x) = \\gamma x^2 + \\delta, \\quad \\hat{p}_{\\mathrm{rank}}(x) = \\sigma\\big(s_{\\mathrm{rank}}(x)\\big),\n    $$\n    其中固定常数 $\\gamma = 1.0$ 和 $\\delta = 2.0$。这一选择有意地优先考虑基于幅度 $\\lvert x \\rvert$ 的判别，而目的不在于概率校准。请注意，对于类条件分布具有相等均值但不同方差的目标域，对数似然比是 $x$ 的二次函数，因此按 $x^2$ 排序与该设置下最强大的检验是一致的。\n\n您将在三个目标域上评估这两种方法，以突显不同类型偏移下的校准与判别之间的权衡。每个目标域 $\\mathcal{T}$ 都有其自己的标签先验 $\\pi_{\\mathcal{T}}$ 和类条件高斯参数。对于每种目标情况，从指定的目标分布中生成一个大小为 $n_{\\mathcal{T}}$ 的独立同分布数据集，为基础模型和秩聚焦模型评估 $\\mathrm{AUC}$ 和 $\\mathrm{Brier}$，然后返回一个布尔值，表示秩聚焦模型是否在目标域上严格改善了 $\\mathrm{AUC}$ 同时严格恶化了 Brier 分数。\n\n目标域测试套件：\n\n- 案例 A（方差偏移，均值相等）：$n_{\\mathcal{T}} = 80000$，$\\pi_{\\mathcal{T}} = 0.2$，$X \\mid Y=1 \\sim \\mathcal{N}(0.0, 2.0^2)$，$X \\mid Y=0 \\sim \\mathcal{N}(0.0, 0.5^2)$。此目标域具有相等的均值和不同的方差，有利于基于 $\\lvert x \\rvert$ 的二次排序。\n\n- 案例 B（无偏移）：$n_{\\mathcal{T}} = 80000$，$\\pi_{\\mathcal{T}} = 0.5$，$X \\mid Y=1 \\sim \\mathcal{N}(1.5, 1.0^2)$，$X \\mid Y=0 \\sim \\mathcal{N}(-1.5, 1.0^2)$。此目标域与源域相同。\n\n- 案例 C（仅标签偏移）：$n_{\\mathcal{T}} = 80000$，$\\pi_{\\mathcal{T}} = 0.2$，$X \\mid Y=1 \\sim \\mathcal{N}(1.5, 1.0^2)$，$X \\mid Y=0 \\sim \\mathcal{N}(-1.5, 1.0^2)$。此目标域保持条件分布不变，但改变了类先验。\n\n实现要求：\n\n- 使用源参数解析计算 $w_{\\mathcal{S}}$ 和 $b_{\\mathcal{S}}$。然后，对每个目标案例，模拟数据，计算 $\\hat{p}_{\\mathrm{base}}$ 和 $\\hat{p}_{\\mathrm{rank}}$ 的 $\\mathrm{AUC}$ 和 $\\mathrm{Brier}$，并确定\n$$\n\\big(\\mathrm{AUC}_{\\mathrm{rank}} > \\mathrm{AUC}_{\\mathrm{base}}\\big) \\;\\;\\text{and}\\;\\; \\big(\\mathrm{Brier}_{\\mathrm{rank}} > \\mathrm{Brier}_{\\mathrm{base}}\\big)\n$$\n是否成立。使用固定的随机种子以使结果具有确定性。\n\n- 您的程序必须输出一行，其中包含一个对应于案例 A、B 和 C 的三个布尔值的列表（按此顺序）。第 $i$ 个布尔值必须为真，当且仅当在第 $i$ 个目标案例上，秩聚焦模型比基础模型具有严格更高的 $\\mathrm{AUC}$ 和严格更高（更差）的 Brier 分数。输出格式为单行，包含一个用方括号括起来的逗号分隔列表，例如，“[True,False,True]”。\n\n附加概念任务（在您的书面解决方案中解决，而非在代码中）：基于第一性原理，解释为什么在域偏移下，一个方法可以在增加 $\\mathrm{AUC}$ 的同时恶化 Brier 分数，并为域适应提出一套联合评估判别和校准的评估指标套件，明确地从经过充分检验的定义中论证每个指标。此问题不涉及任何物理单位。", "solution": "该问题已经过验证，被确定为一项有效、适定且具有科学依据的统计学习练习。它为分析概率分类器在域偏移下的判别与校准之间的权衡提供了一个清晰而完整的设置。所有定义、参数和评估标准都得到了正式和正确的陈述。\n\n解决方案分三个阶段进行。首先，我们确定所提供模型的解析形式。其次，我们分析每个模型在三个目标域上的预期行为。第三，我们解决关于判别和校准指标分歧的概念性问题。\n\n**1. 解析模型规范**\n\n该问题定义了一个源于源域 $\\mathcal{S}$ 的基础模型和一个秩聚焦模型。\n\n源域参数为 $\\pi_{\\mathcal{S}} = 0.5$，$\\mu_{1,\\mathcal{S}} = 1.5$，$\\mu_{0,\\mathcal{S}} = -1.5$，以及 $\\sigma_{\\mathcal{S}} = 1.0$。\n\n基础模型的分数函数为 $s_{\\mathrm{base}}(x) = w_{\\mathcal{S}} x + b_{\\mathcal{S}}$，其中参数源于源分布的贝叶斯后验对数几率。\n权重 $w_{\\mathcal{S}}$ 计算如下：\n$$\nw_{\\mathcal{S}} = \\frac{\\mu_{1,\\mathcal{S}} - \\mu_{0,\\mathcal{S}}}{\\sigma_{\\mathcal{S}}^2} = \\frac{1.5 - (-1.5)}{1.0^2} = \\frac{3.0}{1.0} = 3.0\n$$\n偏置 $b_{\\mathcal{S}}$ 计算如下：\n$$\nb_{\\mathcal{S}} = \\log\\frac{\\pi_{\\mathcal{S}}}{1-\\pi_{\\mathcal{S}}} - \\frac{\\mu_{1,\\mathcal{S}}^2 - \\mu_{0,\\mathcal{S}}^2}{2\\sigma_{\\mathcal{S}}^2}\n$$\n给定 $\\pi_{\\mathcal{S}} = 0.5$，第一项 $\\log\\frac{0.5}{1-0.5} = \\log(1) = 0$。\n给定 $\\mu_{1,\\mathcal{S}} = 1.5$ 和 $\\mu_{0,\\mathcal{S}} = -1.5$，第二项的分子是 $\\mu_{1,\\mathcal{S}}^2 - \\mu_{0,\\mathcal{S}}^2 = (1.5)^2 - (-1.5)^2 = 2.25 - 2.25 = 0$。\n因此，$b_{\\mathcal{S}} = 0 - 0 = 0$。\n\n基础模型因此是：\n$$\ns_{\\mathrm{base}}(x) = 3.0x, \\quad \\hat{p}_{\\mathrm{base}}(x) = \\sigma(3.0x)\n$$\n根据其构建方式，该模型是源域 $\\mathcal{S}$ 的贝叶斯最优分类器，这意味着它在该特定数据分布上是完美校准且具有最大判别性的。\n\n秩聚焦模型给定固定参数 $\\gamma = 1.0$ 和 $\\delta = 2.0$：\n$$\ns_{\\mathrm{rank}}(x) = 1.0x^2 + 2.0, \\quad \\hat{p}_{\\mathrm{rank}}(x) = \\sigma(x^2 + 2.0)\n$$\n该模型被设计用于在特定类型的域偏移下表现良好，即类别具有相等均值但不同方差，使得对数似然比成为 $x$ 的二次函数。\n\n**2. 在目标域上的性能分析**\n\n我们为每个目标案例评估条件 $(\\mathrm{AUC}_{\\mathrm{rank}} > \\mathrm{AUC}_{\\mathrm{base}}) \\land (\\mathrm{Brier}_{\\mathrm{rank}} > \\mathrm{Brier}_{\\mathrm{base}})$。\n\n**案例 A（方差偏移）：**\n目标分布的参数为 $\\pi_{\\mathcal{T}} = 0.2$，$X \\mid Y=1 \\sim \\mathcal{N}(0.0, 2.0^2)$，以及 $X \\mid Y=0 \\sim \\mathcal{N}(0.0, 0.5^2)$。\n此处，类条件均值相等，$\\mu_{1,\\mathcal{T}} = \\mu_{0,\\mathcal{T}} = 0.0$，但方差不同，$\\sigma_{1,\\mathcal{T}}^2 = 4.0$ 和 $\\sigma_{0,\\mathcal{T}}^2 = 0.25$。该目标的贝叶斯最优分数函数（与对数似然比成正比）是 $x$ 的二次函数。具体来说，大的 $|x|$ 值为 $Y=1$ 提供了证据，因为 $\\sigma_{1,\\mathcal{T}} > \\sigma_{0,\\mathcal{T}}$。\n- **判别（AUC）：** 秩聚焦模型的分数 $s_{\\mathrm{rank}}(x) = x^2 + 2.0$ 随 $|x|$ 增加，正确捕捉了此目标的排序原则。基础模型的分数 $s_{\\mathrm{base}}(x) = 3.0x$ 将表现不佳，因为相同幅度的正值和负值 $x$ 会被赋予非常不同的分数，即使它们为 $Y=1$ 提供了相同的证据。因此，我们预期 $\\mathrm{AUC}_{\\mathrm{rank}} > \\mathrm{AUC}_{\\mathrm{base}}$。\n- **校准（Brier 分数）：** 秩聚焦模型使用任意系数 $\\gamma=1.0, \\delta=2.0$，这些系数并非从目标分布的参数（$\\pi_{\\mathcal{T}}, \\mu_i, \\sigma_i$）推导得出。因此，概率 $\\hat{p}_{\\mathrm{rank}}(x)$ 将不会校准到真实的后验概率 $\\mathbb{P}(Y=1|X=x)$，导致较高的 Brier 分数。基础模型也是误设的，并且将是未校准的。然而，秩模型虽然在排序上更优，但可能严重失校，导致更高（更差）的 Brier 分数。我们预期 $\\mathrm{Brier}_{\\mathrm{rank}} > \\mathrm{Brier}_{\\mathrm{base}}$。\n- **结论：** 该条件预期为 **True**。\n\n**案例 B（无偏移）：**\n目标分布与源分布相同。\n- **判别（AUC）：** 基础模型 $s_{\\mathrm{base}}(x)$ 是该分布的贝叶斯最优分类器，将实现可能的最大 AUC。秩聚焦模型 $s_{\\mathrm{rank}}(x)$ 是误设的，因为最优判别器是线性的，而非二次的。我们预期 $\\mathrm{AUC}_{\\mathrm{rank}}  \\mathrm{AUC}_{\\mathrm{base}}$。\n- **校准（Brier 分数）：** 基础模型通过构造是完美校准的，并将实现可能的最低 Brier 分数。秩聚焦模型是误设的，校准会很差，导致 Brier 分数高得多。\n- **结论：** 条件的第一部分 $\\mathrm{AUC}_{\\mathrm{rank}} > \\mathrm{AUC}_{\\mathrm{base}}$ 为假。该条件预期为 **False**。\n\n**案例 C（仅标签偏移）：**\n类条件分布与源相同，但类先验变为 $\\pi_{\\mathcal{T}} = 0.2$。\n- **判别（AUC）：** AUC 是一种秩排序的度量，对类别平衡（标签偏移）不敏感。实例的最优排序由似然比 $p(x|Y=1)/p(x|Y=0)$ 决定，该比率与源相比没有变化。因此，线性分数 $s_{\\mathrm{base}}(x)$ 仍然是最优的排序器。二次分数 $s_{\\mathrm{rank}}(x)$ 仍然是误设的。因此，我们预期 $\\mathrm{AUC}_{\\mathrm{rank}}  \\mathrm{AUC}_{\\mathrm{base}}$。\n- **校准（Brier 分数）：** 基础模型的概率 $\\hat{p}_{\\mathrm{base}}(x) = \\sigma(3.0x)$ 通过截距 $b_{\\mathcal{S}}=0$ 隐含地假设了源先验 $\\pi_{\\mathcal{S}}=0.5$。针对目标的正确校准模型应为 $\\hat{p}(x) = \\sigma(3.0x + b_{\\mathcal{T}})$，其中 $b_{\\mathcal{T}} = \\log(\\pi_{\\mathcal{T}}/(1-\\pi_{\\mathcal{T}})) = \\log(0.2/0.8) \\approx -1.386$。由于其截距错误，基础模型现在是失校的。秩模型也是失校的。然而，基础模型远比秩模型更接近真实形式。\n- **结论：** 条件的第一部分 $\\mathrm{AUC}_{\\mathrm{rank}} > \\mathrm{AUC}_{\\mathrm{base}}$ 为假。该条件预期为 **False**。\n\n**3. 概念任务：判别 vs. 校准及指标套件**\n\n**为什么 AUC 能增加而 Brier 分数会恶化**\n\n这种现象是这两种度量评估的不同属性的直接结果。\n- **AUC（判别）：** ROC 曲线下面积是一种基于秩的度量。它对于分类器分数的任何严格保序变换都是不变的。也就是说，如果一个模型输出分数 $s(x)$，其 AUC 与一个输出分数 $f(s(x))$ 的模型相同，其中 $f$ 是任何严格递增的函数。AUC 仅衡量分类器是否一致地为正实例分配比负实例更高的分数。\n- **Brier 分数（校准）：** Brier 分数 $\\mathbb{E}[(\\hat{p}(X) - Y)^2]$ 是一种合宜评分规则，它衡量预测概率的均方误差。它对 $\\hat{p}(x)$ 的实际数值高度敏感。如果一个模型在所有预测概率为（例如）0.8 的实例中，大约有 80% 的实例实际上是正例，则该模型是良好校准的。对分数 $s(x)$ 应用任意的单调变换 $f$ 通常会破坏校准，因为新的“概率”$\\sigma(f(s(x)))$ 将不再对应于真实的后验概率 $\\mathbb{P}(Y=1|X=x)$。\n\n在域偏移下，一种新的特征变换（如案例 A 中的二次分数）可能能更好地分离目标域中的类别，从而改善排序并因此获得更高的 AUC。然而，如果产生的分数不是目标分布上后验对数几率的恰当表示，应用 sigmoid 函数将产生失校的概率。这会导致更高（更差）的 Brier 分数，从而产生观察到的权衡：以恶化校准为代价改善判别。\n\n**为域适应提出的评估指标套件**\n\n为了全面评估分类器在域适应后的性能，需要一套能够分别和联合评估判别与校准的指标。\n\n1.  **判别指标：ROC 曲线下面积 (AUC)**\n    -   **论证：** 作为衡量模型排序能力的标准度量，AUC 对于理解模型是否能区分不同类别至关重要。其对分数变换和类别流行度的不变性使其成为纯粹判别能力的稳健指标，而这正是适应的主要目标之一。\n\n2.  **校准指标：期望校准误差 (ECE)**\n    -   **论证：** ECE 通过将预测按其置信度（预测概率）划分到不同的箱中，并计算每个箱中平均置信度与观察到的准确率之间差异的加权平均值，从而直接衡量失校程度。形式上，$\\mathrm{ECE} = \\sum_{m=1}^{M} \\frac{|B_m|}{n} |\\mathrm{acc}(B_m) - \\mathrm{conf}(B_m)|$。与 Brier 分数不同，ECE 孤立了校准误差，使其在诊断特定于校准的失败时具有很高的可解释性。一个好的适应方法不应显著增加 ECE。\n\n3.  **总体质量指标：Brier 分数**\n    -   **论证：** Brier 分数是一种合宜评分规则，意味着模型被激励报告其真实信念以最小化该分数。它优雅地结合了判别和校准的各个方面。Brier 分数可以分解为可靠性（校准）、分辨率（判别的一个方面）和不确定性分量。一个低的 Brier 分数表明模型既有判别力（高分辨率）又校准良好（低可靠性误差）。它可作为概率预测总体质量的优秀单一概括性指标。\n\n这个 $\\{\\mathrm{AUC}, \\mathrm{ECE}, \\mathrm{Brier\\ Score}\\}$ 的套件提供了一个全面的视角。理想的适应会提高 AUC，同时保持 ECE 和 Brier 分数较低。观察到 AUC 增加的同时 ECE 和 Brier 分数也增加，清楚地表明了本问题旨在突显的权衡。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expit as sigmoid\n\ndef solve():\n    \"\"\"\n    Solves the problem by simulating three target domains and evaluating two models\n    on each, checking for a discrimination-calibration trade-off.\n    \"\"\"\n\n    # Set a fixed random seed for reproducibility\n    np.random.seed(0)\n\n    # --- Analytical Parameters ---\n    # Source parameters\n    mu1_s, mu0_s, sigma_s, pi_s = 1.5, -1.5, 1.0, 0.5\n    \n    # Base model parameters (derived analytically)\n    w_s = (mu1_s - mu0_s) / sigma_s**2\n    b_s = np.log(pi_s / (1.0 - pi_s)) - (mu1_s**2 - mu0_s**2) / (2 * sigma_s**2)\n\n    # Rank model parameters (given)\n    gamma, delta = 1.0, 2.0\n\n    # Test suite of target domain parameters\n    test_cases = [\n        # Case A: Variance shift, equal means\n        {'name': 'A', 'n_t': 80000, 'pi_t': 0.2, 'mu1_t': 0.0, 'sigma1_t': 2.0, 'mu0_t': 0.0, 'sigma0_t': 0.5},\n        # Case B: No shift\n        {'name': 'B', 'n_t': 80000, 'pi_t': 0.5, 'mu1_t': 1.5, 'sigma1_t': 1.0, 'mu0_t': -1.5, 'sigma0_t': 1.0},\n        # Case C: Label shift only\n        {'name': 'C', 'n_t': 80000, 'pi_t': 0.2, 'mu1_t': 1.5, 'sigma1_t': 1.0, 'mu0_t': -1.5, 'sigma0_t': 1.0},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        # --- Data Generation ---\n        n_t, pi_t = case['n_t'], case['pi_t']\n        n1_t = int(n_t * pi_t)\n        n0_t = n_t - n1_t\n\n        x1_t = np.random.normal(loc=case['mu1_t'], scale=case['sigma1_t'], size=n1_t)\n        x0_t = np.random.normal(loc=case['mu0_t'], scale=case['sigma0_t'], size=n0_t)\n\n        x_target = np.concatenate((x1_t, x0_t))\n        y_target = np.concatenate((np.ones(n1_t), np.zeros(n0_t)))\n\n        # --- Model Evaluation ---\n        # Base model\n        s_base = w_s * x_target + b_s\n        p_base = sigmoid(s_base)\n        \n        # Rank-focused model\n        s_rank = gamma * x_target**2 + delta\n        p_rank = sigmoid(s_rank)\n\n        # --- Metric Calculation ---\n        # Brier score\n        brier_base = np.mean((p_base - y_target)**2)\n        brier_rank = np.mean((p_rank - y_target)**2)\n        \n        # AUC calculation (using the efficient rank-based method)\n        def calculate_auc(y_true, y_score):\n            y_true = np.asarray(y_true, dtype=bool)\n            \n            n1 = np.count_nonzero(y_true)\n            n0 = len(y_true) - n1\n            \n            if n1 == 0 or n0 == 0:\n                return 0.5 # Or handle as undefined, 0.5 is a common convention\n            \n            # Use argsort to get ranks efficiently\n            order = np.argsort(y_score)\n            y_true_sorted = y_true[order]\n            \n            # Sum of ranks for the positive class\n            # np.where returns a tuple, we need the first element\n            pos_ranks_sum = np.sum(np.where(y_true_sorted)[0] + 1)\n            \n            # Wilcoxon-Mann-Whitney U statistic relationship\n            auc = (pos_ranks_sum - n1 * (n1 + 1) / 2) / (n1 * n0)\n            return auc\n\n        auc_base = calculate_auc(y_target, s_base)\n        auc_rank = calculate_auc(y_target, s_rank)\n\n        # --- Condition Check ---\n        # Did the rank model strictly improve AUC and strictly worsen Brier?\n        trade_off_occurred = (auc_rank > auc_base) and (brier_rank > brier_base)\n        results.append(trade_off_occurred)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3188990"}]}