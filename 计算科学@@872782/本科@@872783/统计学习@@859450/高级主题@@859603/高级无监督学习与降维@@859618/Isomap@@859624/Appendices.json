{"hands_on_practices": [{"introduction": "Isomap算法的核心思想是：只要流形上的采样点足够密集，那么根据这些点构建的邻域图中的最短路径距离，就能很好地近似真实测地距离。这种近似的精确度与流形的局部弯曲程度（即曲率）和采样点的密度息息相关。这个练习 ([@problem_id:3133711]) 将让你亲手验证这一原理，通过理论推导和编程实验，量化地探索曲率、采样密度与近似误差之间的关系，从而深入理解Isomap算法的根基。", "problem": "考虑嵌入在三维欧几里得空间中的一条一维曲线，该曲线由一个连续可微的映射 $\\gamma: [a,b] \\to \\mathbb{R}^3$ 表示。曲线上的内蕴度量是测地距离，其值等于沿 $\\gamma$ 的弧长。等距特征映射 (Isometric Feature Mapping, Isomap) 通过在流形的采样点上构建的邻域图上的最短路径距离来近似测地距离。对于一条一维曲线，若采样足够精细，且邻域仅连接沿曲线的连续样本点，则两个采样点之间的 Isomap 路径长度是沿曲线段的连续样本点之间欧几里得弦长的总和，从而得到真实弧长的多边形近似。\n\n您的任务是设计并测试一个实验，该实验改变曲率大小，并量化采样密度必须如何相应调整，以保证 Isomap 恢复的内蕴度量与真实值之间的绝对失真不超过预设的阈值 $\\epsilon$。请从基本的几何概念出发，不要预设任何目标公式。使用以下定义和经过充分验证的事实作为您的起点：\n\n- 对于由弧长 $s$ 参数化的平面或空间曲线，其曲率 $\\kappa(s)$ 衡量了曲线在局部偏离直线的快慢程度。\n- 对于速度为 $v(t) = \\|\\gamma'(t)\\|$ 的曲线 $\\gamma(t)$，参数 $t_1$ 和 $t_2$ 之间的弧长为 $L(t_1,t_2) = \\int_{t_1}^{t_2} v(t)\\, dt$。\n- 对于半径为 $R$、弧长为 $s$ 的圆弧，其对应的直弦长为 $c = 2 R \\sin\\!\\left(\\frac{s}{2R}\\right)$，并且 $\\sin(x)$ 的麦克劳林级数展开为 $\\sin(x) = x - \\frac{x^3}{6} + \\cdots$。\n\n基于以上信息，推导出最大曲率 $\\kappa_{\\max}$ 和以弧长计量的采样间隔 $\\delta$ 如何控制多边形链长度与沿曲线的真实测地长度之间的最坏情况绝对失真。利用此关系，得出一个关于所需最大弧长间距 $\\delta$ 的闭式上界（以 $\\epsilon$、$\\kappa_{\\max}$ 和总曲线长度 $T$ 表示），然后推导出所需的最小整数样本数 $N$，以确保在连续邻居链上计算的 Isomap 距离对于所有采样点对的绝对失真最多为 $\\epsilon$。\n\n完成推导后，实现一个程序，该程序：\n- 计算每个测试曲线的最大曲率 $\\kappa_{\\max}$ 和总长度 $T$。\n- 使用您推导出的上界，计算所需最小样本数 $N_{\\text{theory}}$，以保证 Isomap 距离与真实测地距离之间的最大绝对失真最多为 $\\epsilon$。\n- 在弧长上（而非参数空间上）以 $N_{\\text{theory}}$ 个点均匀采样曲线。构建仅连接连续样本点的链图。计算 Isomap 距离（作为沿链的欧几里得弦长之和）以及真实测地距离（作为弧长之差）。报告在所有采样点对中观测到的最大绝对失真。\n- 生成一行输出，其中包含所有测试用例的结果，格式为一个逗号分隔的列表，列表中的每个元素是一个包含两个值的列表 $[N_{\\text{theory}}, \\text{max\\_distortion}]$，整个输出由方括号包围。\n\n所有三角函数的角度单位必须是弧度。\n\n使用以下测试套件，它涵盖了不同曲率和长度的多种情况：\n\n- 测试 1（平面圆弧）：半径 $R = 1.5$，弧长 $L = 3.0$，失真阈值 $\\epsilon = 0.005$。曲线为 $\\gamma(s) = \\big(R \\cos(s/R), R \\sin(s/R), 0\\big)$，其中 $s \\in [0, L]$。\n- 测试 2（平面正弦曲线）：振幅 $A = 0.5$，频率 $\\omega = 2.0$，参数区间 $t \\in [0, 2.0]$，失真阈值 $\\epsilon = 0.01$。曲线为 $\\gamma(t) = \\big(t, A \\sin(\\omega t), 0\\big)$。\n- 测试 3（螺旋线）：半径 $a = 1.0$，螺距参数 $b = 0.2$，参数区间 $t \\in [0, 4.0]$，失真阈值 $\\epsilon = 0.005$。曲线为 $\\gamma(t) = \\big(a \\cos t, a \\sin t, b t\\big)$。\n- 测试 4（低曲率圆弧）：半径 $R = 100.0$，弧长 $L = 3.0$，失真阈值 $\\epsilon = 0.005$。曲线为 $\\gamma(s) = \\big(R \\cos(s/R), R \\sin(s/R), 0\\big)$，其中 $s \\in [0, L]$。\n\n您的程序应生成一行输出，其中包含四个测试的结果，格式为一个由方括号包围的逗号分隔列表，每个结果是一个双元素列表 $[N_{\\text{theory}}, \\text{max\\_distortion}]$。例如，格式必须与 $[[N_1,d_1],[N_2,d_2],[N_3,d_3],[N_4,d_4]]$ 完全一致，不得包含任何额外文本。\n\n本问题中所有数学实体均以 LaTeX 书写。角度以弧度为单位。不涉及物理单位，因此无需进行单位转换。将数值输出表示为普通十进制数。", "solution": "该问题要求推导所需最小样本数 $N$，以确保在一维曲线上，通过多边形链近似的 Isomap 距离与真实测地距离的绝对误差在 $\\epsilon$ 以内。此推导必须基于曲线的总长度 $T$ 和其最大曲率 $\\kappa_{\\max}$。\n\n求解过程分为四个步骤：\n1.  分析单个小曲线段上的局部失真。\n2.  累加局部失真，以找到曲线上任意两点之间总失真的上界。\n3.  利用此上界推导出所需的采样密度，首先表示为最大弧长间距 $\\delta$，然后表示为最小样本数 $N$。\n4.  将推导出的公式应用于指定的测试用例，并实现一个数值实验来验证理论界限。\n\n**1. 局部失真分析**\n\n考虑两个连续采样点之间的一小段曲线。真实的测地距离是该段的弧长，记为 $\\delta s$。在本问题的特定配置中，Isomap 距离是连接这两点的直线弦长，记为 $\\delta c$。局部绝对失真为 $\\delta s - \\delta c$。\n\n为了界定此误差，我们用其密切圆来局部模拟该曲线段。此圆的半径为 $R = 1/\\kappa$，其中 $\\kappa$ 是局部曲率。对于长度为 $\\delta s$、半径为 $R$ 的圆弧，相应的弦长由公式 $\\delta c = 2R \\sin(\\frac{\\delta s}{2R})$ 给出。\n\n问题提供了 $\\sin(x)$ 的麦克劳林级数：\n$$ \\sin(x) = x - \\frac{x^3}{3!} + \\frac{x^5}{5!} - \\dots $$\n对于 $x \\ge 0$，这是一个各项绝对值递减的交错级数。此类级数的一个已知性质是其和由其部分和界定。具体而言，对我们的目的来说，$x - \\frac{x^3}{6} \\le \\sin(x) \\le x$。\n\n应用上界 $\\sin(x) \\le x$，其中 $x = \\frac{\\delta s}{2R}$：\n$$ \\delta c = 2R \\sin\\left(\\frac{\\delta s}{2R}\\right) \\le 2R \\left(\\frac{\\delta s}{2R}\\right) = \\delta s $$\n这证实了弦长总是小于或等于弧长，因此失真 $\\delta s - \\delta c$ 是非负的。\n\n为了找到失真的上界，我们使用 $\\sin(x)$ 的下界：\n$$ \\delta c = 2R \\sin\\left(\\frac{\\delta s}{2R}\\right) \\ge 2R \\left[ \\left(\\frac{\\delta s}{2R}\\right) - \\frac{1}{6}\\left(\\frac{\\delta s}{2R}\\right)^3 \\right] $$\n$$ \\delta c \\ge \\delta s - 2R \\frac{(\\delta s)^3}{48R^3} = \\delta s - \\frac{(\\delta s)^3}{24R^2} $$\n整理此不等式可得局部失真的上界：\n$$ \\delta s - \\delta c \\le \\frac{(\\delta s)^3}{24R^2} $$\n代入曲率 $\\kappa = 1/R$，我们得到以曲率表示的局部失真界限：\n$$ \\delta s - \\delta c \\le \\frac{\\kappa^2 (\\delta s)^3}{24} $$\n\n**2. 全局失真上界**\n\n问题规定，曲线在 $N$ 个点上进行采样，这些点在弧长上均匀间隔。这产生了 $N-1$ 个线段，每个线段的弧长为 $\\delta = T/(N-1)$，其中 $T$ 是曲线的总长度。\n\n任意两个采样点 $p_i$ 和 $p_j$（其中 $ji$）之间的绝对失真 $D_{ij}$ 是真实测地距离 $S_{ij}$ 与 Isomap 路径长度 $C_{ij}$ 之差。\n$$ S_{ij} = \\sum_{k=i}^{j-1} \\delta s_k = (j-i)\\delta $$\n$$ C_{ij} = \\sum_{k=i}^{j-1} \\delta c_k $$\n$$ D_{ij} = S_{ij} - C_{ij} = \\sum_{k=i}^{j-1} (\\delta s_k - \\delta c_k) = \\sum_{k=i}^{j-1} (\\delta - \\delta c_k) $$\n为了找到任意点对 $(i, j)$ 的全局失真上界，我们将每个线段中的局部曲率 $\\kappa_k$ 替换为整个曲线上的最大曲率 $\\kappa_{\\max}$。\n$$ D_{ij} = \\sum_{k=i}^{j-1} (\\delta - \\delta c_k) \\le \\sum_{k=i}^{j-1} \\frac{\\kappa_{\\max}^2 \\delta^3}{24} = (j-i) \\frac{\\kappa_{\\max}^2 \\delta^3}{24} $$\n最大可能失真 $D_{\\max}$ 将发生在连接曲线两个端点（从 $i=0$到 $j=N-1$）的最长路径上。该路径包含所有 $N-1$ 个线段。\n$$ D_{\\max} = D_{0,N-1} \\le (N-1) \\frac{\\kappa_{\\max}^2 \\delta^3}{24} $$\n由于总长度为 $T = (N-1)\\delta$，我们可以将此界限重写为：\n$$ D_{\\max} \\le T \\frac{\\kappa_{\\max}^2 \\delta^2}{24} $$\n\n**3. 所需采样密度的推导**\n\n我们给定一个最大允许绝对失真 $\\epsilon$。为保证 Isomap 近似足够精确，我们要求 $D_{\\max} \\le \\epsilon$。\n$$ T \\frac{\\kappa_{\\max}^2 \\delta^2}{24} \\le \\epsilon $$\n求解最大允许弧长间距 $\\delta$：\n$$ \\delta^2 \\le \\frac{24\\epsilon}{T \\kappa_{\\max}^2} $$\n$$ \\delta \\le \\frac{1}{\\kappa_{\\max}} \\sqrt{\\frac{24\\epsilon}{T}} $$\n这是弧长间距的闭式上界。\n\n为了找到最小样本数 $N$，我们使用关系式 $N-1 = T/\\delta$。较小的 $\\delta$ 对应较大的样本数。为满足关于 $\\delta$ 的不等式，我们需要：\n$$ N-1 \\ge \\frac{T}{\\frac{1}{\\kappa_{\\max}} \\sqrt{\\frac{24\\epsilon}{T}}} = T \\kappa_{\\max} \\sqrt{\\frac{T}{24\\epsilon}} = \\kappa_{\\max} \\sqrt{\\frac{T^3}{24\\epsilon}} $$\n由于 $N$ 必须是整数，线段数 $N-1$ 必须是满足此条件的最小整数。这可以通过对右侧表达式取上整（ceiling）来实现。\n$$ N-1 = \\left\\lceil \\kappa_{\\max} \\sqrt{\\frac{T^3}{24\\epsilon}} \\right\\rceil $$\n因此，最小样本数 $N_{\\text{theory}}$ 为：\n$$ N_{\\text{theory}} = \\left\\lceil \\kappa_{\\max} \\sqrt{\\frac{T^3}{24\\epsilon}} \\right\\rceil + 1 $$\n此公式提供了保证失真最多为 $\\epsilon$ 所需的理论最小样本数。\n\n**4. 在测试用例上的应用**\n\n将推导的公式和数值模拟应用于每个测试用例。对于每条曲线，我们必须首先计算其总弧长 $T$ 和最大曲率 $\\kappa_{\\max}$。$\\mathbb{R}^3$ 中参数曲线 $\\gamma(t)$ 的曲率公式为：\n$$ \\kappa(t) = \\frac{\\|\\gamma'(t) \\times \\gamma''(t)\\|}{\\|\\gamma'(t)\\|^3} $$\n总弧长为 $T = \\int_{t_{\\min}}^{t_{\\max}} \\|\\gamma'(t)\\| dt$。对于非弧长参数化的曲线，要在弧长上均匀采样，需要求解给定弧长 $s$ 所对应的参数 $t$，这通常通过对弧长函数 $s(t) = \\int_{t_{\\min}}^t \\|\\gamma'(\\tau)\\| d\\tau$ 进行数值求根来实现。\n\n实现部分将为每条曲线计算 $N_{\\text{theory}}$，在弧长上均匀地以 $N_{\\text{theory}}$ 个点对曲线进行采样，计算所有点对的测地距离和 Isomap 距离，并找出观察到的最大绝对失真。", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import quad\nfrom scipy.optimize import brentq\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the Isomap distortion problem for four test cases.\n    Derives and applies a formula for the minimum number of samples,\n    then runs a numerical experiment to verify the distortion bound.\n    \"\"\"\n\n    test_cases = [\n        {'id': 1, 'type': 'circle', 'R': 1.5, 'L': 3.0, 'epsilon': 0.005},\n        {'id': 2, 'type': 'sinusoid', 'A': 0.5, 'w': 2.0, 't_max': 2.0, 'epsilon': 0.01},\n        {'id': 3, 'type': 'helix', 'a': 1.0, 'b': 0.2, 't_max': 4.0, 'epsilon': 0.005},\n        {'id': 4, 'type': 'circle', 'R': 100.0, 'L': 3.0, 'epsilon': 0.005},\n    ]\n\n    results = []\n\n    for case in test_cases:\n        if case['type'] == 'circle':\n            R = case['R']\n            T = case['L']\n            epsilon = case['epsilon']\n\n            kappa_max = 1.0 / R\n            \n            gamma = lambda s: np.array([R * np.cos(s / R), R * np.sin(s / R), 0.0])\n            s_range = [0, T]\n\n        elif case['type'] == 'sinusoid':\n            A = case['A']\n            w = case['w']\n            t_max = case['t_max']\n            epsilon = case['epsilon']\n\n            # Curvature calculation\n            # k(t) = |x'y'' - y'x''| / (x'^2 + y'^2)^(3/2)\n            # x(t)=t, y(t)=A*sin(w*t) => x'=1, x''=0, y'=A*w*cos(w*t), y''=-A*w^2*sin(w*t)\n            # k(t) = A*w^2*|sin(w*t)| / (1 + (A*w*cos(w*t))^2)^(3/2)\n            # Max curvature occurs when sin(wt)=1 and cos(wt)=0\n            kappa_max = A * w**2\n\n            gamma = lambda t: np.array([t, A * np.sin(w * t), 0.0])\n            speed = lambda t: np.sqrt(1 + (A * w * np.cos(w * t))**2)\n            \n            T = quad(speed, 0, t_max)[0]\n            s_range = [0, T]\n\n        elif case['type'] == 'helix':\n            a = case['a']\n            b = case['b']\n            t_max = case['t_max']\n            epsilon = case['epsilon']\n\n            # Curvature k = a / (a^2 + b^2)\n            kappa_max = a / (a**2 + b**2)\n            \n            # Speed ||gamma'(t)|| = sqrt(a^2 + b^2)\n            const_speed = np.sqrt(a**2 + b**2)\n            T = t_max * const_speed\n            \n            gamma = lambda t: np.array([a * np.cos(t), a * np.sin(t), b * t])\n            s_range = [0, T]\n\n        # Calculate theoretical number of samples N_theory\n        if T == 0 or kappa_max == 0:\n             # Handle trivial case, though not in test suite. Minimum 2 samples.\n             N_theory = 2\n        else:\n            # Formula: N = ceil(kappa_max * sqrt(T^3 / (24*epsilon))) + 1\n            val_inside_sqrt = (T**3) / (24 * epsilon)\n            num_segments = math.ceil(kappa_max * np.sqrt(val_inside_sqrt))\n            N_theory = int(num_segments) + 1\n        \n        # Ensure at least 2 samples for a segment\n        if N_theory  2:\n            N_theory = 2\n\n        # Sample the curve at N_theory points, evenly spaced in arc length\n        num_segments = N_theory - 1\n        delta_s = T / num_segments\n        target_arc_lengths = [i * delta_s for i in range(N_theory)]\n\n        sample_points = []\n        if case['type'] == 'circle':\n            # Parameterized by arc length s\n            s_samples = target_arc_lengths\n            for s in s_samples:\n                sample_points.append(gamma(s))\n        \n        elif case['type'] == 'helix':\n            # Constant speed, so arc length is proportional to parameter t\n            # s = t * const_speed => t = s / const_speed\n            const_speed = np.sqrt(case['a']**2 + case['b']**2)\n            t_samples = [s / const_speed for s in target_arc_lengths]\n            for t in t_samples:\n                sample_points.append(gamma(t))\n                \n        elif case['type'] == 'sinusoid':\n            # General case: need to solve for t for each s\n            arc_length_func = lambda t: quad(speed, 0, t)[0]\n            t_samples = [0.0]\n            \n            # Use Brent's method to find t_i for each target s_i\n            t_max_param = case['t_max']\n            for s_target in target_arc_lengths[1:]:\n                # Function to find root of: arc_length_func(t) - s_target = 0\n                f_to_solve = lambda t: arc_length_func(t) - s_target\n                # Search interval starts from the last found t\n                t_start_interval = t_samples[-1]\n                t_i = brentq(f_to_solve, t_start_interval, t_max_param)\n                t_samples.append(t_i)\n\n            for t in t_samples:\n                sample_points.append(gamma(t))\n\n        # Calculate max observed distortion\n        max_obs_distortion = 0.0\n        if N_theory > 1:\n            chords = [np.linalg.norm(sample_points[k+1] - sample_points[k]) for k in range(N_theory - 1)]\n            # Cumulative sums for efficient calculation of Isomap distances\n            isomap_prefix_sum = np.cumsum(np.concatenate(([0], chords)))\n            \n            for i in range(N_theory):\n                for j in range(i + 1, N_theory):\n                    geodesic_dist = (j - i) * delta_s\n                    # Isomap distance is the sum of chords between i and j\n                    isomap_dist = isomap_prefix_sum[j] - isomap_prefix_sum[i]\n                    distortion = abs(geodesic_dist - isomap_dist)\n                    if distortion > max_obs_distortion:\n                        max_obs_distortion = distortion\n        \n        results.append([N_theory, max_obs_distortion])\n\n    # Format the final output string\n    result_str = ','.join([f\"[{N},{d}]\" for N, d in results])\n    print(f\"[{result_str}]\")\n\n\nsolve()\n```", "id": "3133711"}, {"introduction": "在构建邻域图之后，Isomap算法中计算量最大的步骤是计算所有点对之间的最短路径（APSP）。不同的APSP算法，如Floyd-Warshall算法或在每个节点上运行Dijkstra算法，在性能上差异巨大，尤其是在处理大规模数据集时。这项实践 ([@problem_id:3133665]) 将带你从理论走向实际应用，通过对两种经典算法的时间和内存复杂度进行建模分析，你将学会在给定的数据集规模和计算资源下做出明智的算法选择，这是将机器学习算法应用于实际问题的关键技能。", "problem": "考虑等距特征映射 (Isometric Feature Mapping, Isomap)，其核心计算步骤是在一个包含 $N$ 个点且边权重为非负的加权无向 $k$-近邻图上，获取所有点对之间的测地距离。获取该测地距离矩阵的两种典型策略是：(a) Floyd–Warshall 算法，以及 (b) 在稀疏的 $k$-近邻图上从每个节点运行 Dijkstra 算法。假设以下基础：(i) Floyd–Warshall 的时间复杂度为 $\\mathcal{O}(N^3)$，它作用于一个稠密的 $N \\times N$ 矩阵；(ii) 在具有 $V$ 个顶点和 $E$ 条边的稀疏图上，使用二叉堆的单源 Dijkstra 算法的时间复杂度为 $\\mathcal{O}((E+V)\\log V)$；(iii) 一个对称的 $k$-近邻图的平均度约为 $k$，因此无向边的数量为 $M \\approx \\frac{N k}{2}$，并且邻接表示法存储两个方向（即大约 $2M$ 条有向弧）。\n您需要设计一个程序，该程序针对每个测试用例，通过估算每种算法的时间和内存使用量来模拟其在标准笔记本电脑上的可行性，然后计算两种算法选择的可行性开始出现分歧的最小数据集规模。\n使用以下建模假设进行估算：\n- 所有稠密 $N \\times N$ 矩阵均使用双精度浮点数（每个条目 $8$ 字节）。\n- 在稀疏邻接表示中，将每条有向弧存储为两个字段：一个 $64$ 位整数的邻居索引和一个 $64$ 位浮点数的权重，每条有向弧总共占用 $16$ 字节。\n- 对于 Floyd–Warshall，时间近似为 $t_{\\mathrm{FW}}(N) = c_{\\mathrm{FW}} \\, N^3$ 秒，其中 $c_{\\mathrm{FW}} = 5 \\times 10^{-8}$。\n- 对于重复 Dijkstra，时间近似为 $t_{\\mathrm{DK}}(N,k) = c_{\\mathrm{DK}} \\, \\left(\\frac{N^2 k}{2}\\right) \\log_2 N$ 秒，其中 $c_{\\mathrm{DK}} = 5 \\times 10^{-8}$。\n- 对于内存，近似为：\n  - Floyd–Warshall: $m_{\\mathrm{FW}}(N) = 8 N^2$ 字节（一个稠密距离/权重矩阵）。\n  - 重复 Dijkstra: $m_{\\mathrm{DK}}(N,k) = 8 N^2 + 16 \\times (2 \\times \\frac{N k}{2}) = 8 N^2 + 16 N k$ 字节（稠密距离矩阵加上稀疏邻接弧）。\n- 将 $1$ gibibyte (GiB) 解释为 $2^{30}$ 字节。\n定义一个算法在时间预算为 $T$ 秒、内存预算为 $R$ GiB 的条件下，对于 $(N,k)$ 的可行性为以下两个不等式同时成立：估算时间 $\\le T$ 且估算内存 $\\le R \\times 2^{30}$。\n对于每个测试用例，定义翻转规模 $N_{\\mathrm{flip}}$ 为满足 $N \\ge 2$ 的最小整数，在该 $N$ 值下，对于给定的 $k$、$T$ 和 $R$，两种算法中恰好只有一种是可行的。如果在非常大的 $N$（假设搜索空间包含上述模型有意义的所有 $N$）范围内不存在这样的 $N$，则该测试用例返回 $0$。\n测试套件：\n- 情况 A: $(R, T, k) = (16 \\text{ GiB}, 1800 \\text{ s}, 12)$。\n- 情况 B: $(R, T, k) = (8 \\text{ GiB}, 600 \\text{ s}, 6)$。\n- 情况 C: $(R, T, k) = (32 \\text{ GiB}, 120 \\text{ s}, 50)$。\n- 情况 D: $(R, T, k) = (16 \\text{ GiB}, 900 \\text{ s}, 1200)$。\n您的程序必须：\n- 完全按照上述定义实现可行性检查。\n- 为每个测试用例计算并返回 $N_{\\mathrm{flip}}$。\n- 输出一行，包含四个结果，格式为方括号内以逗号分隔的列表，例如 $\\left[\\text{A},\\text{B},\\text{C},\\text{D}\\right]$，其中每个条目都是一个整数。\n所有时间必须以秒为单位，所有内存量必须在内部以字节为单位（按照指定的从 GiB 转换的方式）。最终输出必须是整数。程序不得接受任何输入，并且必须确定性地运行。", "solution": "该问题要求我们，在给定的计算预算和性能模型下，确定两种用于计算所有点对最短路径的算法——Floyd-Warshall (FW) 和重复 Dijkstra (DK)——其可行性发生分歧的最小数据集规模 $N$，记为 $N_{\\mathrm{flip}}$。\n\n### 1. 可行性的数学建模\n\n每种算法的可行性由两个约束条件决定：时间预算 $T$ 和内存预算 $R$。问题为时间和内存成本提供了精确的模型，这些模型是数据集规模 $N$ 和近邻参数 $k$ 的函数。所有计算中，内存单位为字节，时间单位为秒，并且 $1$ GiB 定义为 $2^{30}$ 字节。\n\n令 $R_{bytes} = R \\times 2^{30}$。\n对于一个给定的配置 $(R, T, k)$，一个算法对于大小为 $N$ 的数据集是可行的，当且仅当其估算的时间和内存使用量都在指定的预算之内。\n\n**Floyd-Warshall (FW) 算法：**\n时间和内存模型如下：\n- 时间：$t_{\\mathrm{FW}}(N) = c_{\\mathrm{FW}} N^3$，其中 $c_{\\mathrm{FW}} = 5 \\times 10^{-8}$。\n- 内存：$m_{\\mathrm{FW}}(N) = 8 N^2$。\n\nFW 的可行性条件是：\n$c_{\\mathrm{FW}} N^3 \\le T \\quad (1)$\n$8 N^2 \\le R_{bytes} \\quad (2)$\n\n**重复 Dijkstra (DK) 算法：**\n$k$-近邻图的时间和内存模型如下：\n- 时间：$t_{\\mathrm{DK}}(N,k) = c_{\\mathrm{DK}} \\left(\\frac{N^2 k}{2}\\right) \\log_2 N$，其中 $c_{\\mathrm{DK}} = 5 \\times 10^{-8}$。\n- 内存：$m_{\\mathrm{DK}}(N,k) = 8 N^2 + 16 N k$。\n\nDK 的可行性条件是：\n$c_{\\mathrm{DK}} \\frac{N^2 k}{2} \\log_2 N \\le T \\quad (3)$\n$8 N^2 + 16 N k \\le R_{bytes} \\quad (4)$\n\n### 2. 可行性阈值的推导\n\n对于每种算法，成本函数都随 $N$ 单调递增。这意味着对于每种算法，都存在一个最大整数数据集规模 $N_{int}$，使其在该规模下是可行的。对于任何 $N  N_{int}$，该算法都是不可行的。这个阈值由时间和内存约束中更严格的一个决定。\n\n**Floyd-Warshall 阈值 ($N_{int, FW}$):**\n由不等式 $(1)$，时间约束对 $N$ 施加了一个限制：\n$N^3 \\le \\frac{T}{c_{\\mathrm{FW}}} \\implies N \\le \\left(\\frac{T}{c_{\\mathrm{FW}}}\\right)^{1/3}$。\n设此为 $N_{lim, FW, time}$。\n\n由不等式 $(2)$，内存约束意味着：\n$N^2 \\le \\frac{R_{bytes}}{8} \\implies N \\le \\sqrt{\\frac{R_{bytes}}{8}}$。\n设此为 $N_{lim, FW, mem}$。\n\nFW 的总体最大规模是 $N_{max, FW} = \\min(N_{lim, FW, time}, N_{lim, FW, mem})$。因此，最大整数规模是 $N_{int, FW} = \\lfloor N_{max, FW} \\rfloor$。\n\n**重复 Dijkstra 阈值 ($N_{int, DK}$):**\n由不等式 $(3)$，时间约束给出了一个超越不等式：\n$N^2 \\log_2 N \\le \\frac{2 T}{c_{\\mathrm{DK}} k}$。\n由于函数 $f(N) = N^2 \\log_2 N$ 在 $N \\ge 1$ 时是单调递增的，我们可以使用数值方法（如二分搜索）找到满足此条件的最大整数 $N$。设这个整数阈值为 $N_{int, DK, time}$。\n\n由不等式 $(4)$，内存约束是一个二次不等式：\n$8 N^2 + 16 k N - R_{bytes} \\le 0$。\n相应二次方程 $8x^2 + 16kx - R_{bytes} = 0$ 的正根给出了 $N$ 的上界：\n$N = \\frac{-16k + \\sqrt{(16k)^2 - 4(8)(-R_{bytes})}}{2(8)} = \\frac{-16k + \\sqrt{256k^2 + 32 R_{bytes}}}{16} = -k + \\sqrt{k^2 + \\frac{R_{bytes}}{8}}$。\n设此为 $N_{lim, DK, mem}$。整数阈值为 $\\lfloor N_{lim, DK, mem} \\rfloor$。\n\nDK 的总体整数阈值是 $N_{int, DK} = \\min(N_{int, DK, time}, \\lfloor N_{lim, DK, mem} \\rfloor)$。\n\n### 3. 翻转规模 ($N_{\\mathrm{flip}}$) 条件\n\n翻转规模 $N_{\\mathrm{flip}}$ 定义为使两种算法的可行性状态不同的最小整数 $N \\ge 2$。设 $F_{FW}(N)$ 和 $F_{DK}(N,k)$ 为布尔可行性函数。我们寻求最小的 $N \\ge 2$ 使得 $F_{FW}(N) \\neq F_{DK}(N,k)$。\n\n对于给定的 $N$，算法 `alg` 的可行性仅取决于 $N \\le N_{int, alg}$ 是否成立。\n- 对于任何 $N \\le \\min(N_{int, FW}, N_{int, DK})$，两种算法都是可行的。\n- 对于任何 $N  \\max(N_{int, FW}, N_{int, DK})$，两种算法都是不可行的。\n\n可行性的分歧只能发生在这两种状态之间的范围内。\n不失一般性，我们假设 $N_{int, FW}  N_{int, DK}$。\n- 对于任何满足 $N \\le N_{int, FW}$ 的整数 $N$，两种算法都是可行的。\n- 在 $N = N_{int, FW} + 1$ 时，FW 变得不可行，因为 $N  N_{int, FW}$。然而，DK 仍然是可行的，因为 $N_{int, FW} + 1 \\le N_{int, DK}$。\n这是它们可行性出现差异的第一个 $N$ 值。因此，$N_{\\mathrm{flip}} = N_{int, FW} + 1 = \\min(N_{int, FW}, N_{int, DK}) + 1$。\n\n如果 $N_{int, FW} = N_{int, DK}$，那么对于任何 $N \\le N_{int, FW}$，两者都可行。对于任何 $N  N_{int, FW}$，两者都不可行。不存在恰好只有一种算法可行的 $N$。在这种情况下，$N_{\\mathrm{flip}}=0$。\n\n一般规则是：\n$N_{\\mathrm{flip}} = \\begin{cases} \\min(N_{int, FW}, N_{int, DK}) + 1  \\text{如果 } N_{int, FW} \\neq N_{int, DK} \\\\ 0  \\text{如果 } N_{int, FW} = N_{int, DK} \\end{cases}$\n\n实现将为每个测试用例计算 $N_{int, FW}$ 和 $N_{int, DK}$，并应用此规则来找到 $N_{\\mathrm{flip}}$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Computes the flip size N_flip for each test case based on algorithmic\n    feasibility models.\n    \"\"\"\n\n    # Define the modeling constants.\n    C_FW = 5e-8\n    C_DK = 5e-8\n    GIB_TO_BYTES = 2**30\n\n    test_cases = [\n        # Case A: (R, T, k) = (16 GiB, 1800 s, 12)\n        (16, 1800, 12),\n        # Case B: (R, T, k) = (8 GiB, 600 s, 6)\n        (8, 600, 6),\n        # Case C: (R, T, k) = (32 GiB, 120 s, 50)\n        (32, 120, 50),\n        # Case D: (R, T, k) = (16 GiB, 900 s, 1200)\n        (16, 900, 1200),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        R, T, k = case\n        R_bytes = R * GIB_TO_BYTES\n\n        # --- Calculate N_int_fw ---\n        # Time limit for FW: c_fw * N^3 = T => N = (T / c_fw)^(1/3)\n        n_lim_fw_time = (T / C_FW)**(1/3)\n        \n        # Memory limit for FW: 8 * N^2 = R_bytes => N = sqrt(R_bytes / 8)\n        n_lim_fw_mem = math.sqrt(R_bytes / 8)\n        \n        n_int_fw = math.floor(min(n_lim_fw_time, n_lim_fw_mem))\n        \n        # --- Calculate N_int_dk ---\n        # Time limit for DK: c_dk * (N^2*k/2) * log2(N) = T\n        # => N^2 * log2(N) = 2 * T / (c_dk * k)\n        C_time_dk = (2 * T) / (C_DK * k)\n\n        # Binary search for the largest integer N satisfying the time constraint.\n        # The search range is from 2 up to a safe upper bound. The FW memory\n        # limit provides a generous and safe upper bound for N.\n        low = 2\n        high = math.ceil(n_lim_fw_mem) + 1  # Safe upper bound\n        n_int_dk_time = 1\n        \n        while low = high:\n            mid = (low + high) // 2\n            if mid  2: # Ensure mid is at least 2 for log2 to be non-negative.\n                low = mid + 1\n                continue\n            \n            # Use numpy's log2 for consistency with the problem statement\n            val = (mid**2) * np.log2(mid)\n            if val = C_time_dk:\n                n_int_dk_time = mid # This is a potential solution\n                low = mid + 1\n            else:\n                high = mid - 1\n        \n        # Memory limit for DK: 8N^2 + 16Nk - R_bytes = 0\n        # Positive root of 8x^2 + 16kx - C = 0\n        a, b, c = 8, 16 * k, -R_bytes\n        discriminant = b**2 - 4 * a * c\n        n_lim_dk_mem = (-b + math.sqrt(discriminant)) / (2 * a)\n\n        n_int_dk = math.floor(min(n_int_dk_time, n_lim_dk_mem))\n\n        # --- Determine N_flip ---\n        if n_int_fw == n_int_dk:\n            n_flip = 0\n        else:\n            # The flip occurs at the first N where one becomes infeasible.\n            # This is 1 + the minimum of the two feasibility thresholds.\n            n_flip = min(n_int_fw, n_int_dk) + 1\n        \n        results.append(int(n_flip))\n        \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3133665"}, {"introduction": "标准的Isomap算法在处理采样密度不均的数据时会遇到挑战。它可能会在不同密度的区域之间错误地建立“捷径”连接，从而扭曲了对真实测地距离的估计。为了解决这个问题，我们可以让算法在构建图时“感知”数据密度，剔除那些跨越低密度区域的不可靠连接。这项高级练习 ([@problem_id:3133637]) 将引导你亲手实现一个更稳健的Isomap版本，通过在一个特制的数据集上复现并解决这个问题，你将学会如何针对复杂数据场景对经典算法进行改进和创新。", "problem": "要求您使用一个带密度阈值的图来实现等距映射 (Isomap)，以移除跨越低密度区域的边，并在一个合成数据集上测试其行为。该数据集包含两条连接相同端点但采样密度不同的平行流形路径。目标是基于图测地线近似和经典多维缩放 (MDS) 的第一性原理进行推理，并量化密度阈值化对估计测地距离的影响。\n\n按如下方式在二维空间中构建一个确定性数据集。设环境空间为 $\\mathbb{R}^2$。考虑一个以原点为中心、半径为 $r = 1$ 的单位圆。定义两个端点 $A = (1, 0)$ 和 $B = (-1, 0)$。在 $A$ 和 $B$ 之间生成两条半圆路径：\n- 高密度上半圆：对于在 $(0,\\pi)$（弧度）内均匀分布的 $n_{\\text{high}}$ 个内角 $\\theta_j$，包含点 $(\\cos \\theta_j, \\sin \\theta_j)$。然后将 $A$ 和 $B$ 作为唯二的端点包含在内。\n- 低密度下半圆：对于在 $(0,\\pi)$（弧度）内均匀分布的 $n_{\\text{low}}$ 个内角 $\\phi_\\ell$，包含点 $(\\cos \\phi_\\ell, -\\sin \\phi_\\ell)$。此下半圆路径不包含端点，从而使两条路径共享唯一的端点 $A$ 和 $B$。\n\n所有角度必须以弧度为单位。\n\n使用以下基本原理：\n- 图测地线近似：给定数据点 $X = \\{x_i \\in \\mathbb{R}^D\\}_{i=1}^n$，构建一个 k-近邻 (k-NN) 图，其边权重等于欧几里得距离。该图上所有点对之间的最短路径距离可近似流形上的测地距离。这一原理基于：在足够密集的采样和适当的局部连接下，图上的最短路径会收敛于底层流形上的测地线。\n- 经典多维缩放 (MDS)：给定一个对称距离矩阵 $\\Delta = [\\delta_{ij}]$，构建中心化的格拉姆矩阵\n$$\nB = -\\tfrac{1}{2} H \\Delta^{\\circ 2} H,\n$$\n其中 $H = I - \\tfrac{1}{n}\\mathbf{1}\\mathbf{1}^\\top$，$I$ 是单位矩阵，$\\mathbf{1}$ 是全为 1 的向量，$\\Delta^{\\circ 2}$ 表示逐元素平方。如果 $B = Q \\Lambda Q^\\top$ 是其特征分解（特征值按降序排列），则嵌入到 $\\mathbb{R}^d$ 的坐标由 $Y = Q_d \\Lambda_d^{1/2}$ 的行给出，其中 $Q_d$ 包含前 $d$ 个特征向量，$\\Lambda_d$ 包含相应的特征值。对于本任务，您必须实现测地距离计算；测试输出不需要嵌入步骤。\n\n定义一个密度阈值 Isomap 图如下。设 $D = [\\|x_i - x_j\\|_2]$ 为欧几里得距离矩阵。通过以下方式在每个点定义一个局部密度代理：\n$$\n\\rho_i = \\frac{1}{d_i^{(m)} + \\varepsilon},\n$$\n其中 $d_i^{(m)}$ 是从 $x_i$ 到其第 $m$ 个最近邻（不包括自身）的距离，$\\varepsilon$ 是一个小的正常数以避免除以零。给定一个密度阈值 $\\tau  0$，如果 $k$-NN 图中存在一条边 $(i,j)$ 满足\n$$\n\\min(\\rho_i, \\rho_j)  \\tau.\n$$\n则移除该边。这样可以移除跨越低密度区域的边。\n\n在单个程序中实现以下过程：\n1. 构建标准的 $k$-NN 图，其对称边权重等于欧几里得距离。\n2. 使用该图上的所有点对最短路径算法，计算端点之间的基线测地距离 $d_{\\text{base}}(A,B)$。\n3. 使用上述第 $m$ 个最近邻规则计算密度得分 $\\rho_i$。\n4. 对于给定的阈值 $\\tau$，使用规则 $\\min(\\rho_i, \\rho_j) \\ge \\tau$ 剪枝边，并计算密度阈值测地距离 $d_{\\text{den}}(A,B)$。\n5. 如果剪枝后 $A$ 和 $B$ 不再连通，则定义 $d_{\\text{den}}(A,B) = +\\infty$。\n\n测试套件。使用以下固定参数和测试用例来量化方法的行为：\n- 数据集参数：$r = 1$，上半圆上有 $n_{\\text{high}} = 120$ 个内部点，下半圆上有 $n_{\\text{low}} = 6$ 个内部点。角度在 $(0,\\pi)$ 内均匀分布，并以弧度表示。数据集是 $\\{A\\}$、上半圆内部点、$\\{B\\}$ 和下半圆内部点的并集。\n- 图参数：$k$-NN 的 $k = 6$，密度估计的 $m = 5$，以及 $\\varepsilon = 10^{-12}$。\n- 端点：$A$ 是构造数组中的第一个点，$B$ 是第 $(1 + n_{\\text{high}})$ 个点。\n\n定义三个测试用例，每个用例产生一个布尔结果：\n- 用例 1（理想情况）：使用 $\\tau = 1.5$。输出谓词 $d_{\\text{den}}(A,B)  d_{\\text{base}}(A,B) + 10^{-2}$ 的布尔值。\n- 用例 2（几乎不剪枝）：使用 $\\tau = 0.0$。输出谓词 $\\lvert d_{\\text{den}}(A,B) - d_{\\text{base}}(A,B) \\rvert  10^{-12}$ 的布尔值。\n- 用例 3（过度剪枝）：使用 $\\tau = 10.0$。输出谓词 $d_{\\text{den}}(A,B) = +\\infty$ 的布尔值。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如：\"[true_case1,true_case2,true_case3]\"），列表中的每个条目是按上述顺序对应的测试用例的布尔结果。打印的布尔值必须采用 Python 的默认布尔格式 \"True\" 或 \"False\"，方括号内没有空格。\n\n在此问题中，所有数值都必须视为无量纲，所有角度都以弧度为单位。不要求也不允许用户输入；程序必须完全自包含且具有确定性。", "solution": "该问题要求实现并分析等距映射 (Isomap) 算法的一种密度感知变体。核心任务是评估在邻域图上根据局部点密度进行边剪枝，如何影响在合成数据集上对测地距离的估计。该数据集经过专门设计，包含两条采样密度不同的路径，旨在创建一个标准 Isomap 可能会产生不正确距离估计的场景。\n\n解决方案分为四个主要阶段：\n1.  生成一个确定性的二维数据集。\n2.  构建一个基线邻域图，并计算两个指定端点之间的最短路径距离，记为 $d_{\\text{base}}(A,B)$。\n3.  实现一种基于密度的边剪枝机制。\n4.  在剪枝后的图上计算最短路径距离 $d_{\\text{den}}(A,B)$，并针对三个不同的密度阈值评估其行为。\n\n**1. 数据集构建**\n\n该数据集构建于二维欧几里得空间 $\\mathbb{R}^2$ 中。它由位于以原点为中心、半径为 $r=1$ 的单位圆上的点组成。两条半圆形路径连接端点 $A=(1, 0)$ 和 $B=(-1, 0)$。\n\n*   **高密度上半圆：** 该路径由端点 $A$ 和 $B$ 以及 $n_{\\text{high}} = 120$ 个内部点组成。这些点通过 $(\\cos \\theta_j, \\sin \\theta_j)$ 生成，其中角度 $\\theta_j$（$j=1, \\dots, n_{\\text{high}}$）在开区间 $(0, \\pi)$ 内均匀分布。该路径上的总点数为 122 个。\n*   **低密度下半圆：** 该路径由 $n_{\\text{low}} = 6$ 个内部点组成，通过 $(\\cos \\phi_\\ell, -\\sin \\phi_\\ell)$ 生成，其中角度 $\\phi_\\ell$（$\\ell=1, \\dots, n_{\\text{low}}$）同样在 $(0, \\pi)$ 内均匀分布。该路径与上半圆路径共享端点 $A$ 和 $B$，但其自身定义中不包含这两个端点，以确保每个端点只有一个实例。\n\n最终数据集是 $N = 1 + n_{\\text{high}} + 1 + n_{\\text{low}} = 1 + 120 + 1 + 6 = 128$ 个点的集合。这些点在一个数组中排序，使得点 $A$ 位于索引 0，点 $B$ 位于索引 $1 + n_{\\text{high}} = 121$。这种特定结构创建了一个具有非均匀采样密度的流形。\n\n**2. 基线测地距离计算**\n\nIsomap 算法通过计算邻域图上的最短路径来近似流形上点之间的内在测地距离。\n\n*   **步骤 1：邻域图构建。** 我们首先构建一个 $k$-近邻（$k$-NN）图，其中 $k=6$。图的顶点对应于数据点 $\\{\\mathbf{x}_i\\}_{i=1}^N$。如果点 $\\mathbf{x}_i$ 和 $\\mathbf{x}_j$ 中的一个是另一个的 $k$ 个最近邻之一，则在它们之间创建一条边。图是对称的：如果 $\\mathbf{x}_j$ 是 $\\mathbf{x}_i$ 的邻居，则添加边 $(i, j)$；如果 $\\mathbf{x}_i$ 是 $\\mathbf{x}_j$ 的邻居，则也添加边 $(j, i)$。边 $(i,j)$ 的权重设置为欧几里得距离 $\\|\\mathbf{x}_i - \\mathbf{x}_j\\|_2$。不存在的边的权重为无穷大。这将为基线图生成一个加权邻接矩阵。\n\n*   **步骤 2：最短路径计算。** 使用 Floyd-Warshall 算法计算该图上所有点对之间的最短路径距离。得到的距离矩阵提供了对底层流形上测地距离的近似。端点之间的基线测地距离 $d_{\\text{base}}(A,B)$ 是该矩阵中对应于从点 $A$（索引 0）到点 $B$（索引 121）的路径的条目。由于数据集的设计，上、下路径之间可能会形成“捷径”边，尤其是在端点附近。这可能导致 $d_{\\text{base}}(A,B)$ 低估了沿上半圆的真实流形距离（即 $\\pi r = \\pi \\approx 3.14159$）。\n\n**3. 密度阈值图剪枝**\n\n为了修正这类捷径，引入了一种基于密度的剪枝策略。\n\n*   **步骤 1：局部密度估计。** 每个点 $\\mathbf{x}_i$ 的局部密度代理定义为：\n    $$\n    \\rho_i = \\frac{1}{d_i^{(m)} + \\varepsilon}\n    $$\n    其中 $d_i^{(m)}$ 是从 $\\mathbf{x}_i$ 到其第 $m$ 个最近邻的欧几里得距离（$m=5$），$\\varepsilon = 10^{-12}$ 是一个小的常数以防止除以零。位于密集采样区域（如上半圆）的点将具有较小的 $d_i^{(m)}$ 值，因此具有较高的 $\\rho_i$ 分数。相反，位于稀疏采样区域（如下半圆）的点将具有较大的 $d_i^{(m)}$ 值和较低的 $\\rho_i$ 分数。\n\n*   **步骤 2：边剪枝。** 给定一个密度阈值 $\\tau  0$，如果 $k$-NN 图中的一条现有边 $(i,j)$ 的任一端点的密度低于该阈值，则移除该边。形式化规则是：如果\n    $$\n    \\min(\\rho_i, \\rho_j)  \\tau\n    $$\n    则移除边 $(i,j)$。该规则有效地消除了连接高密度区域中的点与低密度区域中的点的边，这些边通常是存在问题的“捷径”边。\n\n**4. 测试用例评估**\n\n对于给定的 $\\tau$ 对图进行剪枝后，在剪枝后的图上使用 Floyd-Warshall 算法重新计算所有点对的最短路径。这得到了密度阈值测地距离 $d_{\\text{den}}(A,B)$。如果剪枝导致点 $A$ 和 $B$ 不再连通，则该距离定义为 $+\\infty$。\n\n*   **用例 1：$\\tau = 1.5$。** 这个“理想情况”的阈值预期足够低，可以保留高密度上半圆路径内的边，但又足够高，可以剪除连接上下路径的捷径边。这迫使最短路径更忠实地沿着上半圆行进，从而得到一个距离 $d_{\\text{den}}(A,B)$，该距离是 $\\pi$ 的更好近似，因此大于可能被低估的 $d_{\\text{base}}(A,B)$。谓词 $d_{\\text{den}}(A,B) > d_{\\text{base}}(A,B) + 10^{-2}$ 预期为真。\n\n*   **用例 2：$\\tau = 0.0$。** 阈值为 0 时，不会剪枝任何边，因为密度 $\\rho_i$ 总是正的。剪枝后的图与基线图相同。因此，$d_{\\text{den}}(A,B)$ 必须等于 $d_{\\text{base}}(A,B)$。谓词 $|\\,d_{\\text{den}}(A,B) - d_{\\text{base}}(A,B)\\,|  10^{-12}$ 将为真。\n\n*   **用例 3：$\\tau = 10.0$。** 这个“过度剪枝”的阈值设置得足够高，以至于大于数据集中大多数（如果不是全部）点的密度值（即使是高密度路径上的点）。这将导致大量边被移除，很可能将图断开成孤立的组件或小碎片。因此，$A$ 和 $B$ 之间将不存在路径，从而得到 $d_{\\text{den}}(A,B) = +\\infty$。谓词 $d_{\\text{den}}(A,B) = +\\infty$ 预期为真。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import cdist\nfrom scipy.sparse.csgraph import floyd_warshall\n\ndef solve():\n    \"\"\"\n    Implements and tests a density-aware Isomap variant on a synthetic dataset.\n    \"\"\"\n    # Define parameters from the problem statement.\n    r, n_high, n_low = 1.0, 120, 6\n    k, m, epsilon = 6, 5, 1e-12\n    idx_A, idx_B = 0, 1 + n_high\n    test_taus = [1.5, 0.0, 10.0]\n\n    # --- 1. Dataset Generation ---\n    n_total = n_high + n_low + 2\n    points = np.zeros((n_total, 2))\n    \n    # Endpoint A\n    points[0] = [r, 0]\n    \n    # High-density upper semicircle (interior points)\n    theta = np.linspace(0, np.pi, n_high + 2)[1:-1]\n    points[1:1+n_high] = np.array([r * np.cos(theta), r * np.sin(theta)]).T\n    \n    # Endpoint B\n    points[1+n_high] = [-r, 0]\n    \n    # Low-density lower semicircle (interior points)\n    phi = np.linspace(0, np.pi, n_low + 2)[1:-1]\n    points[1+n_high+1:] = np.array([r * np.cos(phi), -r * np.sin(phi)]).T\n\n    # --- Euclidean Distance Matrix ---\n    D_euc = cdist(points, points)\n\n    # --- 2. Baseline Geodesic Distance Calculation ---\n    # Build k-NN graph\n    n_points = D_euc.shape[0]\n    G_base = np.full((n_points, n_points), np.inf)\n    np.fill_diagonal(G_base, 0)\n    \n    neighbor_indices = np.argsort(D_euc, axis=1)[:, 1:k+1]\n    for i in range(n_points):\n        for j in neighbor_indices[i]:\n            G_base[i, j] = D_euc[i, j]\n            G_base[j, i] = D_euc[j, i]  # Symmetrize graph\n\n    # Compute baseline geodesic distance\n    dist_matrix_base = floyd_warshall(csgraph=G_base, directed=False)\n    d_base = dist_matrix_base[idx_A, idx_B]\n\n    # --- 3. Density-Thresholded Graph Pruning ---\n    # Compute local densities\n    sorted_dists = np.sort(D_euc, axis=1)\n    d_m = sorted_dists[:, m]\n    rho = 1.0 / (d_m + epsilon)\n    \n    results = []\n    # --- 4. Evaluation of Test Cases ---\n    for tau in test_taus:\n        # Prune graph based on density\n        G_pruned = G_base.copy()\n        \n        # Vectorized pruning for efficiency\n        # Find all edges: where G_base is finite\n        # Create a matrix of min densities for each potential edge\n        rho_min_matrix = np.minimum.outer(rho, rho)\n        \n        # Define mask for edges to be pruned\n        pruning_mask = (G_base != np.inf)  (rho_min_matrix  tau)\n        G_pruned[pruning_mask] = np.inf\n\n        # Compute density-thresholded geodesic distance\n        dist_matrix_pruned = floyd_warshall(csgraph=G_pruned, directed=False)\n        d_den = dist_matrix_pruned[idx_A, idx_B]\n\n        # Evaluate the predicate for the current test case\n        if tau == 1.5:\n            result = d_den > d_base + 1e-2\n        elif tau == 0.0:\n            result = abs(d_den - d_base)  1e-12\n        elif tau == 10.0:\n            result = d_den == np.inf\n        else: # Should not be reached with the given test cases\n            result = False\n\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3133637"}]}