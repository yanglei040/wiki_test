{"hands_on_practices": [{"introduction": "Metropolis-Hastings 算法的核心在于决定接受还是拒绝一个新提议的状态。这个决策由接受概率（acceptance probability）控制。本练习将引导你完成一个具体的接受概率计算，这是理解和实现该算法的基本功。通过这个练习，你将亲手应用核心公式，从而牢固掌握MH算法的单步运行机制。[@problem_id:1932824]", "problem": "一位统计学家正在使用马尔可夫链蒙特卡洛（MCMC）方法从参数 $\\lambda$ 的后验分布中抽样。已知该后验分布服从率参数为 $\\beta_0$ 的指数分布，其概率密度函数为 $\\pi(\\lambda) = \\beta_0 \\exp(-\\beta_0 \\lambda)$（当 $\\lambda  0$ 时），以及 $\\pi(\\lambda)=0$（当 $\\lambda \\le 0$ 时）。\n\n对于MCMC模拟，采用了随机游走Metropolis-Hastings算法。在给定当前状态 $\\lambda_c$ 的情况下，新状态 $\\lambda_p$ 的提议是从一个均值等于当前状态、标准差为 $\\sigma$ 的正态分布中抽取的。即，提议分布为 $q(\\lambda_p | \\lambda_c)$，对应于正态分布 $\\mathcal{N}(\\lambda_c, \\sigma^2)$。\n\n假设后验分布的率参数为 $\\beta_0 = 0.5$，提议分布的标准差为 $\\sigma = 1.0$。在链中的某一步，当前状态为 $\\lambda_c = 2.4$。然后，算法提议了一个新状态 $\\lambda_p = 3.1$。当前状态和提议状态都在有效域（$\\lambda  0$）内。\n\n计算此提议移动的接受概率。将你的最终答案四舍五入到三位有效数字。", "solution": "在Metropolis-Hastings算法中，从 $\\lambda_{c}$ 到 $\\lambda_{p}$ 的提议移动的接受概率为\n$$\n\\alpha = \\min\\left(1,\\;\\frac{\\pi(\\lambda_{p})\\,q(\\lambda_{c}\\mid \\lambda_{p})}{\\pi(\\lambda_{c})\\,q(\\lambda_{p}\\mid \\lambda_{c})}\\right).\n$$\n对于由 $\\mathcal{N}(\\lambda_{c},\\sigma^{2})$ 给出的随机游走正态提议 $q(\\lambda_{p}\\mid \\lambda_{c})$，该提议是对称的，所以\n$$\nq(\\lambda_{c}\\mid \\lambda_{p})=q(\\lambda_{p}\\mid \\lambda_{c}),\n$$\n因此提议比率为 $1$。于是，\n$$\n\\alpha=\\min\\left(1,\\;\\frac{\\pi(\\lambda_{p})}{\\pi(\\lambda_{c})}\\right).\n$$\n目标密度是率参数为 $\\beta_{0}$ 的指数分布：\n$$\n\\pi(\\lambda)=\\beta_{0}\\exp(-\\beta_{0}\\lambda)\\quad\\text{for}\\ \\lambda0,\\quad \\pi(\\lambda)=0\\ \\text{otherwise}.\n$$\n因为 $\\lambda_{c}$ 和 $\\lambda_{p}$ 都是正数，我们有\n$$\n\\frac{\\pi(\\lambda_{p})}{\\pi(\\lambda_{c})}\n=\\frac{\\beta_{0}\\exp(-\\beta_{0}\\lambda_{p})}{\\beta_{0}\\exp(-\\beta_{0}\\lambda_{c})}\n=\\exp\\!\\big(-\\beta_{0}(\\lambda_{p}-\\lambda_{c})\\big).\n$$\n代入给定值 $\\beta_{0}=0.5$、$\\lambda_{c}=2.4$ 和 $\\lambda_{p}=3.1$，\n$$\n\\alpha=\\min\\left(1,\\;\\exp\\!\\big(-0.5\\cdot(3.1-2.4)\\big)\\right)\n=\\min\\left(1,\\;\\exp(-0.35)\\right)\n=\\exp(-0.35).\n$$\n数值上，$\\exp(-0.35)\\approx 0.704688\\ldots$，四舍五入到三位有效数字是 $0.705$。", "answer": "$$\\boxed{0.705}$$", "id": "1932824"}, {"introduction": "掌握了单步计算之后，理解马尔可夫链的长期行为至关重要。本练习探讨了不可约性（irreducibility）这一关键概念，即链能否访问到目标分布的所有区域。通过一个编码实践，你将面对一个具有不连通支撑集（disconnected support）的目标分布，并亲眼见证一个设计不当的提议分布如何导致采样器无法正确收敛。这是 MCMC 诊断中至关重要的一课。[@problem_id:3160213]", "problem": "考虑 Metropolis-Hastings 算法（MH），该算法构建具有指定平稳分布的马尔可夫链。设实值状态空间是两个不相交闭区间的并集，目标概率密度函数 $\\,\\pi(x)\\,$ 的支撑集为 $$S = [0,1] \\cup [2,3],$$ 在其他地方为零。定义 $$\\pi(x) = \\begin{cases} \\tfrac{1}{2},  x \\in [0,1] \\text{ 或 } x \\in [2,3], \\\\ 0,  \\text{其他情况,} \\end{cases}$$ 这是一个有效的概率密度，因为 $S$ 的总长度为 $2$，且在每个单位长度的区间上密度为 $\\tfrac{1}{2}$。考虑两种类型的提议分布：\n\n- 一种对称的局部提议 $\\,q(x' \\mid x)\\,$，由 $$[x - \\delta,\\, x + \\delta]$$ 上的均匀分布给出，其中 $\\,\\delta  0\\,$ 是一个固定的半宽度。该提议是对称的，即只要 $\\,q(x' \\mid x) = q(x \\mid x')\\,$ 均非零，它们就相等。\n- 一种独立提议 $\\,q(x' \\mid x) = q(x')\\,$，由 $$[0,3]$$ 上的均匀分布给出，它不依赖于当前状态 $\\,x。$\n\n您必须分析、实现并经验性地证明，当局部提议的半宽度 $\\,\\delta\\,$ 太小以至于无法跨越区间之间的间隙时，遍历性（特别是 $\\psi$-不可约性）会失效，并将其与恢复不可约性的参数化或提议机制进行对比。\n\n从基本概念入手：马尔可夫链的定义、概率测度支撑集的概念、细致平衡条件以及不可约性的定义。特别地，使用以下原则：MH 接受函数必须通过确保相对于目标密度 $\\,\\pi(x)\\,$ 的细致平衡来导出，并且落在 $\\,\\pi(x') = 0\\,$ 区域的提议必须被拒绝。\n\n程序的算法要求：\n\n- 实现一个函数，该函数使用指定的提议类型和参数，从初始状态 $\\,x_0\\,$ 开始模拟 MH 链 $\\,N\\,$ 步。如果 $\\,\\pi(x_0) = 0,$ 实现必须检测到无效的初始状态，并返回整数 $\\,1\\,$ 作为该情况的测试结果。\n- 对于有效的起始状态，跟踪链在 $\\,N\\,$ 步内是否曾访问过右侧区间 $$[2,3]$$。该情况的结果必须是一个布尔值：如果链至少访问过一次 $[2,3]$，则为 $\\,\\text{True}\\,$，否则为 $\\,\\text{False}\\,$。\n- 为每个测试用例使用固定的随机种子，以确保可复现性。\n- 对成员资格测试使用闭区间；具体来说，使用 $\\,\\le\\,$ 比较，以便恰好在 $\\,0,\\,1,\\,2,\\,$ 和 $\\,3\\,$ 处的点被认为在其各自的区间内。\n\n测试套件和覆盖范围：\n\n设间隙长度为 $$g = 1,$$ 即，$[0,1]$ 的右端点与 $[2,3]$ 的左端点之间的距离为 $\\,g。$ 以下五个测试用例必须严格按照规定实现，以覆盖正常路径、边界条件和边缘情况：\n\n1. 局部对称提议，$\\,\\delta = 0.49,$ 初始状态 $\\,x_0 = 0.5,$ 步数 $\\,N = 20000,$ 种子 $\\,42.$ 预期行为：由于 $\\,\\delta  g,$ 链无法跨越间隙。\n2. 局部对称提议，$\\,\\delta = 1.5,$ 初始状态 $\\,x_0 = 1.0,$ 步数 $\\,N = 20000,$ 种子 $\\,123.$ 预期行为：由于 $\\,\\delta  g,$ 链可以跨越间隙。\n3. 局部对称提议，$\\,\\delta = 1.0,$ 初始状态 $\\,x_0 = 1.0,$ 步数 $\\,N = 20000,$ 种子 $\\,2023.$ 边界行为：链无法以非零概率跨越间隙，因为来自 $\\,x \\in [0,1]\\,$ 的提议落在 $$[x - 1,\\, x + 1] \\subset [0,2],$$ 中，而事件 $\\,x' = 2\\,$ 的概率为 $\\,0。$\n4. 独立提议 $\\,q(x')\\,$ 在 $[0,3]$ 上均匀分布，初始状态 $\\,x_0 = 0.5,$ 步数 $\\,N = 100,$ 种子 $\\,7.$ 预期行为：链是不可约的，因为从 $S$ 中的任何状态出发，提议都有正概率落在 $[2,3]$ 中。\n5. 无效初始状态：局部对称提议，$\\,\\delta = 0.4,$ 初始状态 $\\,x_0 = 1.5,$ 步数 $\\,N = 100,$ 种子 $\\,99.$ 要求行为：检测到 $\\,\\pi(x_0) = 0\\,$ 并返回整数 $\\,1。$\n\n最终输出格式：\n\n您的程序应生成单行输出，其中包含按上述五个测试用例顺序排列的结果，结果为逗号分隔的列表并用方括号括起来。对于前四个测试用例，打印布尔值，指示链是否至少访问过一次 $[2,3]$；对于第五个测试用例，打印整数 $\\,1。$ 例如，打印的行必须具有 $$[b_1, b_2, b_3, b_4, i_5],$$ 的形式，其中每个 $\\,b_k\\,$ 是一个布尔值，$\\,i_5 = 1。$ 不应打印任何附加文本。", "solution": "该问题是有效的，因为它在科学上是合理的、问题陈述是适定的，并且提供了所有必要的信息。它提出了 Metropolis-Hastings 算法中不可约性失效的一个典型例子，这是计算科学和马尔可夫链蒙特卡洛方法中的一个基本概念。\n\nMetropolis-Hastings (MH) 算法是一种从难以直接采样的概率分布中生成随机样本序列的方法。样本序列构成一个马尔可夫链，这是一个随机过程，其中转移到任何特定状态的概率仅取决于当前状态，而与之前的事件序列无关。MH 算法的核心思想是构建一个马尔可夫链，使其平稳分布为所需的目标分布 $\\pi(x)$。马尔可夫链从支撑集内的任何起点收敛到其唯一平稳分布所需的关键性质是遍历性。遍历性意味着链既是不可约的又是**非**周期的。本分析侧重于不可约性。\n\n如果对于 $\\pi(x)$ 支撑集（记作 $\\text{supp}(\\pi)$）内的任何状态 $x$，以及任何具有正概率的集合 $A \\subseteq \\text{supp}(\\pi)$（即 $\\int_A \\pi(x) dx  0$），链在有限步内从 $x$ 移动到集合 $A$ 的概率非零，则称马尔可夫链是 $\\pi$-不可约的。在这个问题中，目标分布的支撑集是集合 $S = [0,1] \\cup [2,3]$。为了使链不可约，它必须能够在两个不相交的区间 $[0,1]$ 和 $[2,3]$ 之间转移。\n\nMH 算法构造马尔可夫链的转移核，以满足关于 $\\pi(x)$ 的细致平衡条件。这个条件是 $\\pi(x)$ 成为平稳分布的充分但不必要条件。细致平衡由下式给出：\n$$\n\\pi(x) P(x' \\mid x) = \\pi(x') P(x \\mid x')\n$$\n其中 $P(x' \\mid x)$ 是从状态 $x$ 转移到状态 $x'$ 的概率密度。MH 算法通过一个两步过程来定义此转移：提议和接受。首先，从一个提议分布 $q(x' \\mid x)$ 中提出一个候选状态 $x'$。其次，该提议以概率 $\\alpha(x' \\mid x)$ 被接受。因此，对于 $x' \\neq x$，转移密度为 $P(x' \\mid x) = q(x' \\mid x) \\alpha(x' \\mid x)$。将其代入细致平衡方程可得：\n$$\n\\pi(x) q(x' \\mid x) \\alpha(x' \\mid x) = \\pi(x') q(x \\mid x') \\alpha(x \\mid x')\n$$\nMH 的接受概率被选择来满足此关系：\n$$\n\\alpha(x' \\mid x) = \\min \\left( 1, \\frac{\\pi(x') q(x \\mid x')}{\\pi(x) q(x' \\mid x)} \\right)\n$$\n如果提议的状态 $x'$ 位于 $\\pi(x)$ 的支撑集之外，则 $\\pi(x')=0$，导致接受概率 $\\alpha(x' \\mid x) = 0$。在这种情况下，提议总是被拒绝，链停留在当前状态，即 $x_{t+1} = x_t$。\n\n指定的目标分布为：当 $x \\in S = [0,1] \\cup [2,3]$ 时，$\\pi(x) = \\frac{1}{2}$；否则 $\\pi(x) = 0$。这个定义带来了一个关键的简化：对于任何两个状态 $x, x' \\in S$，目标密度的比率为 $\\frac{\\pi(x')}{\\pi(x)} = \\frac{1/2}{1/2} = 1$。因此，对于从 $x \\in S$ 到 $x' \\in S$ 的任何提议移动，接受概率公式简化为：\n$$\n\\alpha(x' \\mid x) = \\min \\left( 1, \\frac{q(x \\mid x')}{q(x' \\mid x)} \\right)\n$$\n我们分析这两种提议机制：\n\n1.  **局部对称提议**：提议分布 $q(x' \\mid x)$ 对应于 $[x-\\delta, x+\\delta]$ 上的均匀分布。如果 $x' \\in [x-\\delta, x+\\delta]$，则密度为 $q(x' \\mid x) = \\frac{1}{2\\delta}$，否则为 0。这是对称的，意味着 $q(x' \\mid x) = q(x \\mid x')$，因为条件 $|x' - x| \\le \\delta$ 在 $x$ 和 $x'$ 中是对称的。因此，比率 $\\frac{q(x \\mid x')}{q(x' \\mid x)} = 1$。对于向状态 $x' \\in S$ 的任何提议移动，接受概率为 $\\alpha(x' \\mid x) = \\min(1, 1) = 1$。所以，如果一个提议落在支撑集 $S$ 内，它总是被接受。如果落在 $S$ 外，它总是被拒绝。\n    链的不可约性取决于提议分布是否能跨越区间 $[0,1]$ 和 $[2,3]$ 之间的间隙 $g=1$。从状态 $x \\in [0,1]$ 出发的提议是从 $[x-\\delta, x+\\delta]$ 生成的。源自 $[0,1]$ 的提议可能达到的最高值来自 $x=1$，这给出了提议区间 $[1-\\delta, 1+\\delta]$。为了使链能够从 $[0,1]$ 跳到 $[2,3]$，这个区间必须与 $[2,3]$ 有非零的重叠。这要求 $1+\\delta \\ge 2$，即 $\\delta \\ge 1$。\n    -   **情况 1 ($\\delta = 0.49  1$)**：从 $x=1$ 出发的最大可达值为 $1.49$。不可能提议一个在 $[2,3]$ 中的状态。链是可约的，被困在它开始的区间内。\n    -   **情况 2 ($\\delta = 1.5  1$)**：从任何 $x \\in [0.5, 1]$ 出发，提议区间 $[x-1.5, x+1.5]$ 与 $[2,3]$ 有非空交集。例如，从 $x_0=1$ 出发，提议值可高达 $2.5$。转移是可能的，链是不可约的。\n    -   **情况 3 ($\\delta = 1.0$)**：从 $x=1$ 出发的最大可达值恰好是 $2$。提议区间是 $[0, 2]$。由于提议是从连续均匀分布中抽取的，生成精确值 $x'=2$ 的概率为 $0$。因此，链不能以非零概率跨入 $[2,3]$ 的内部。链是可约的。\n\n2.  **独立提议**：提议分布是 $[0,3]$ 上的均匀分布 $q(x' \\mid x) = q(x')$，因此对于 $x' \\in [0,3]$，密度为 $q(x') = \\frac{1}{3}$。在这里，提议不依赖于当前状态 $x$。对于任何 $x, x' \\in [0,3]$，提议密度的比率为 $\\frac{q(x \\mid x')}{q(x' \\mid x)} = \\frac{q(x)}{q(x')} = \\frac{1/3}{1/3} = 1$。与对称情况类似，向 $x' \\in S$ 的任何移动的接受概率为 $\\alpha(x' \\mid x) = 1$。\n    不可约性得到保证。从任何状态 $x \\in S$，都会从 $[0,3]$ 中均匀地提议一个新的状态 $x'$。该提议落入右侧区间 $[2,3]$ 的概率是 $\\frac{3-2}{3-0} = \\frac{1}{3}  0$。由于这样的提议会被接受，链可以在支撑集的两个组成部分之间单步移动。链是不可约的。\n\n最后，问题要求识别无效的初始状态。如果 $x_0$ 使得 $\\pi(x_0)=0$（例如，情况 5 中的 $x_0 = 1.5$），则链没有在目标分布的支撑集上正确初始化。实现必须检测到这一点。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Metropolis-Hastings problem by running five specified test cases.\n    \"\"\"\n\n    def pi(x: float) - float:\n        \"\"\"\n        Target probability density function pi(x).\n        Supported on S = [0,1] U [2,3].\n        \"\"\"\n        if (0.0 = x = 1.0) or (2.0 = x = 3.0):\n            return 0.5\n        return 0.0\n\n    def run_mh_simulation(\n        proposal_type: str,\n        delta: float | None,\n        x0: float,\n        N: int,\n        seed: int\n    ) - bool | int:\n        \"\"\"\n        Simulates the Metropolis-Hastings Markov chain for a given test case.\n\n        Args:\n            proposal_type: 'local' for symmetric or 'independent' for independent proposal.\n            delta: Half-width for the local proposal.\n            x0: Initial state.\n            N: Number of steps.\n            seed: Random seed for reproducibility.\n\n        Returns:\n            - Integer 1 if the initial state x0 is invalid (pi(x0) == 0).\n            - Boolean True if the chain visits the interval [2,3].\n            - Boolean False otherwise.\n        \"\"\"\n        # Step 1: Validate initial state\n        if pi(x0) == 0.0:\n            return 1\n\n        # Step 2: Initialize chain and tracking variables\n        rng = np.random.default_rng(seed)\n        current_x = x0\n        visited_right_interval = (2.0 = current_x = 3.0)\n\n        # Step 3: Run the MCMC simulation for N steps\n        for _ in range(N):\n            # Propose a new state x_prime\n            if proposal_type == 'local':\n                if delta is None:\n                    # This case should not happen based on problem description but is a safeguard\n                    raise ValueError(\"Delta must be provided for local proposal.\")\n                x_prime = rng.uniform(current_x - delta, current_x + delta)\n            elif proposal_type == 'independent':\n                x_prime = rng.uniform(0.0, 3.0)\n            else:\n                raise ValueError(f\"Unknown proposal type: {proposal_type}\")\n\n            # As derived in the solution, for this specific problem, the acceptance\n            # probability alpha is 1 for any proposal that lands in the support of pi,\n            # and 0 otherwise. This simplifies the accept/reject step.\n            if pi(x_prime)  0.0:\n                current_x = x_prime\n\n            # Track if the chain has ever visited the right interval [2, 3]\n            if not visited_right_interval and (2.0 = current_x = 3.0):\n                visited_right_interval = True\n        \n        return visited_right_interval\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. Local proposal, delta  gap, should not cross\n        {'proposal_type': 'local', 'delta': 0.49, 'x0': 0.5, 'N': 20000, 'seed': 42},\n        # 2. Local proposal, delta > gap, should cross\n        {'proposal_type': 'local', 'delta': 1.5, 'x0': 1.0, 'N': 20000, 'seed': 123},\n        # 3. Local proposal, delta = gap, cannot cross (prob=0 event)\n        {'proposal_type': 'local', 'delta': 1.0, 'x0': 1.0, 'N': 20000, 'seed': 2023},\n        # 4. Independent proposal, should be irreducible and cross\n        {'proposal_type': 'independent', 'delta': None, 'x0': 0.5, 'N': 100, 'seed': 7},\n        # 5. Invalid initial state, should return 1\n        {'proposal_type': 'local', 'delta': 0.4, 'x0': 1.5, 'N': 100, 'seed': 99},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_mh_simulation(\n            proposal_type=case['proposal_type'],\n            delta=case['delta'],\n            x0=case['x0'],\n            N=case['N'],\n            seed=case['seed']\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3160213"}, {"introduction": "在实际应用中，模型参数通常带有约束（例如，方差必须为正）。一个常见的处理技巧是将其变换到一个无约束的空间（例如，通过对数变换），但这要求对目标密度函数进行严谨的变换。本练习将引导你完成这一变换的推导和代码实现，重点是雅可比行列式（Jacobian determinant）在其中的关键作用。通过数值验证算法在变换前后的一致性，你将掌握一项进行复杂建模所需的高级技能。[@problem_id:3148250]", "problem": "考虑马尔可夫链蒙特卡洛 (MCMC) 中的 Metropolis-Hastings 算法，该算法构建一个马尔可夫链，其平稳分布等于期望的目标密度。Metropolis-Hastings 接受概率根据第一性原理定义如下。给定状态空间上的目标密度 $\\pi(x)$ 和提议核 $q(x' \\mid x)$，从状态 $x$ 移动到状态 $x'$ 的提议的接受概率为\n$$\n\\alpha(x \\to x') = \\min\\left(1,\\; \\frac{\\pi(x')\\, q(x \\mid x')}{\\pi(x)\\, q(x' \\mid x)}\\right).\n$$\n假设我们对一个变换后的变量 $u = g(x)$ 执行 Metropolis-Hastings 采样，其中 $g$ 是一个双射、可微的变换，其逆变换 $g^{-1}$ 也可微且雅可比行列式非零。目标密度必须通过变量变换被正确地转换为 $u$ 空间上的密度，记为 $\\pi_u(u)$，使用\n$$\n\\pi_u(u) = \\pi_x\\big(g^{-1}(u)\\big)\\,\\left|\\det J_{g^{-1}}(u)\\right|,\n$$\n其中 $J_{g^{-1}}(u)$ 是 $g^{-1}$ 在 $u$ 处求值的雅可比矩阵。如果 $u$ 空间中的提议是 $q_u(u' \\mid u)$，那么 $u$ 空间中的 Metropolis-Hastings 接受概率是\n$$\n\\alpha_u(u \\to u') = \\min\\left(1,\\; \\frac{\\pi_u(u')\\, q_u(u \\mid u')}{\\pi_u(u)\\, q_u(u' \\mid u)}\\right).\n$$\n通过 $x' = g^{-1}(u')$ 和 $x = g^{-1}(u)$ 将提议从 $u$ 空间映射回 $x$ 空间，可以通过变量变换获得隐含的提议密度 $q_x(x' \\mid x)$。在科学上一致的实现中，使用正确变换的目标在 $u$ 空间中计算的接受概率，必须与使用原始目标和导出提议在 $x$ 空间中计算的接受概率一致。\n\n您的任务是推导变换后变量 $u$ 上的接受概率表达式，确定包括雅可比因子在内的正确变换目标 $\\pi_u(u)$，并实现一个程序，对一组测试用例，数值上验证在 $u$ 空间和 $x$ 空间中计算的接受概率之间的一致性。所有数学量必须以无量纲单位处理。\n\n您必须考虑以下变换和目标：\n- 对数变换 $u = \\log x$ (对于 $x  0$)：\n  - $x$ 上的伽马目标：$\\pi_x(x) \\propto x^{k - 1} \\exp\\left(-\\frac{x}{\\theta}\\right)$，其中形状 $k  0$，尺度 $\\theta  0$。\n  - $x$ 上的指数目标：$\\pi_x(x) \\propto \\exp(-\\lambda x)$，其中率 $\\lambda  0$。\n- 恒等变换 $u = x$ (对于 $x \\in \\mathbb{R}$)：\n  - $x$ 上的标准正态目标：$\\pi_x(x) \\propto \\exp\\left(-\\frac{x^2}{2}\\right)$。\n\n对于提议：\n- 在 $u$ 空间中，使用标准差为 $\\sigma  0$ 的高斯随机游走提议：$q_u(u' \\mid u) = \\mathcal{N}(u'; u, \\sigma^2)$。\n- 对于对数变换情况， $x$ 空间中导出的提议是对数正态分布：$q_x(x' \\mid x) = \\text{LogNormal}(x'; \\log x, \\sigma)$。\n- 对于恒等变换情况， $x$ 空间中导出的提议是高斯分布：$q_x(x' \\mid x) = \\mathcal{N}(x'; x, \\sigma^2)$。\n\n实现以下接受概率计算：\n- 在 $u$ 空间中：\n  $$\n  \\alpha_u(u \\to u') = \\min\\left(1,\\; \\exp\\left[\\log \\pi_u(u') - \\log \\pi_u(u) + \\log q_u(u \\mid u') - \\log q_u(u' \\mid u)\\right]\\right).\n  $$\n- 在 $x$ 空间中：\n  $$\n  \\alpha_x(x \\to x') = \\min\\left(1,\\; \\exp\\left[\\log \\pi_x(x') - \\log \\pi_x(x) + \\log q_x(x \\mid x') - \\log q_x(x' \\mid x)\\right]\\right).\n  $$\n\n使用以下参数值测试套件，在不同场景下验证 $\\alpha_u$ 和 $\\alpha_x$ 之间的一致性：\n1. 理想路径，使用伽马目标的对数变换：\n   - $k = 2.3$, $\\theta = 1.1$, $u = 0.25$, $u' = 0.7$, $\\sigma = 0.5$。\n2. 靠近 $x \\approx 0$ 的边界情况，使用伽马目标的对数变换：\n   - $k = 2.3$, $\\theta = 1.1$, $u = -0.1$, $u' = -5.0$, $\\sigma = 0.5$。\n3. 基准情况，使用标准正态目标的恒等变换：\n   - $u = 1.0$, $u' = -1.7$, $\\sigma = 1.0$。\n4. 使用指数目标的对数变换：\n   - $\\lambda = 1.7$, $u = 0.3$, $u' = -1.0$, $\\sigma = 0.7$。\n\n您的程序必须为每个测试用例计算绝对差值\n$$\n\\Delta = \\left|\\alpha_u - \\alpha_x\\right|\n$$\n作为浮点数。最终输出必须是单行，包含一个用方括号括起来的逗号分隔列表，其中包含按上述顺序列出的四个 $\\Delta$ 值（例如，$\\left[\\delta_1,\\delta_2,\\delta_3,\\delta_4\\right]$）。不应打印任何其他文本。", "solution": "问题陈述已经过验证，并被认为是有效的。它具有科学依据，问题定义明确，客观且内部一致。它提出了计算统计学中一个标准的、非平凡的问题，该问题涉及在所有密度都得到正确变换的前提下，Metropolis-Hastings 接受概率在变量变换下的不变性。\n\n核心任务是证明，无论是在变换空间（$u$ 空间）中使用变换后的目标密度计算，还是在原始空间（$x$ 空间）中使用原始目标密度和导出的提议密度计算，Metropolis-Hastings 接受概率都保持不变。我们必须对几个测试用例证明 $\\alpha_u = \\alpha_x$。\n\n从状态 $s$ 移动到 $s'$ 的接受概率由下式给出\n$$ \\alpha(s \\to s') = \\min\\left(1, R\\right) \\quad \\text{其中} \\quad R = \\frac{\\pi(s') q(s \\mid s')}{\\pi(s) q(s' \\mid s)} $$\n使用对数在数值上更稳定：\n$$ \\alpha(s \\to s') = \\min\\left(1, \\exp\\left[\\log\\pi(s') - \\log\\pi(s) + \\log q(s \\mid s') - \\log q(s' \\mid s)\\right]\\right) $$\n\n我们首先建立理论上的等价性。设变换为 $u = g(x)$，其逆变换为 $x = g^{-1}(u)$。概率密度函数 $\\pi_x(x)$ 的变量变换公式是\n$$ \\pi_u(u) = \\pi_x\\big(g^{-1}(u)\\big) \\left|\\det J_{g^{-1}}(u)\\right| $$\n其中 $J_{g^{-1}}(u)$ 是逆变换的雅可比矩阵。\n\n$u$ 空间中的提议密度 $q_u(u' \\mid u)$ 在 $x$ 空间中导出提议密度 $q_x(x' \\mid x)$，这也通过变量变换相关联：\n$$ q_x(x' \\mid x) = q_u\\big(g(x') \\mid g(x)\\big) \\left|\\det J_g(x')\\right| $$\n其中 $J_g(x')$ 是正向变换 $g$ 的雅可比矩阵。根据反函数定理，$\\left|\\det J_g(x')\\right| = 1 / \\left|\\det J_{g^{-1}}(u')\\right|$，其中 $u'=g(x')$。\n因此，\n$$ q_x(x' \\mid x) = \\frac{q_u(u' \\mid u)}{\\left|\\det J_{g^{-1}}(u')\\right|} \\quad \\text{以及类似地} \\quad q_x(x \\mid x') = \\frac{q_u(u \\mid u')}{\\left|\\det J_{g^{-1}}(u)\\right|} $$\n\n现在，我们写出 $x$ 空间中的接受比率 $R_x$ 并代入这些关系：\n$$ R_x = \\frac{\\pi_x(x') q_x(x \\mid x')}{\\pi_x(x) q_x(x' \\mid x)} = \\frac{\\pi_x(x')}{\\pi_x(x)} \\frac{q_u(u \\mid u') / \\left|\\det J_{g^{-1}}(u)\\right|}{q_u(u' \\mid u) / \\left|\\det J_{g^{-1}}(u')\\right|} = \\frac{\\pi_x(x')}{\\pi_x(x)} \\frac{q_u(u \\mid u')}{q_u(u' \\mid u)} \\frac{\\left|\\det J_{g^{-1}}(u')\\right|}{\\left|\\det J_{g^{-1}}(u)\\right|} $$\n重新整理各项，我们得到：\n$$ R_x = \\left( \\frac{\\pi_x(x') \\left|\\det J_{g^{-1}}(u')\\right|}{\\pi_x(x) \\left|\\det J_{g^{-1}}(u)\\right|} \\right) \\left( \\frac{q_u(u \\mid u')}{q_u(u' \\mid u)} \\right) = \\frac{\\pi_u(u')}{\\pi_u(u)} \\frac{q_u(u \\mid u')}{q_u(u' \\mid u)} = R_u $$\n由于比率 $R_x$ 和 $R_u$ 相同，它们的接受概率 $\\alpha_x = \\min(1, R_x)$ 和 $\\alpha_u = \\min(1, R_u)$ 也必须相同。数值实现将验证这一基本性质。\n\n我们现在为每种情况推导具体的量。$u$ 空间中的提议总是一个对称的高斯随机游走，$q_u(u' \\mid u) = \\mathcal{N}(u; u, \\sigma^2)$，这意味着 $q_u(u' \\mid u) = q_u(u \\mid u')$。因此，提议比率项 $\\log q_u(u \\mid u') - \\log q_u(u' \\mid u) = 0$。\n\n**1. 对数变换：$u = \\log x$ (对于 $x  0$)**\n- 逆变换：$x = g^{-1}(u) = \\exp(u)$。\n- 雅可比行列式（一维情况）：$J_{g^{-1}}(u) = \\frac{dx}{du} = \\exp(u)$。\n- 雅可比行列式绝对值：$|\\det J_{g^{-1}}(u)| = \\exp(u)$。\n- $x$ 空间中导出的提议来自 $x' = \\exp(u')$，其中 $u' \\sim \\mathcal{N}(u, \\sigma^2) = \\mathcal{N}(\\log x, \\sigma^2)$。这意味着 $x'$ 是对数正态分布的。其概率密度函数为 $q_x(x' \\mid x) = \\frac{1}{x'\\sigma\\sqrt{2\\pi}} \\exp\\left(-\\frac{(\\log x' - \\log x)^2}{2\\sigma^2}\\right)$。这个提议在 $x$ 和 $x'$ 中不是对称的。\n- $x$ 空间中提议的对数比率为：\n  $$ \\log q_x(x \\mid x') - \\log q_x(x' \\mid x) = \\left(-\\log x - \\dots\\right) - \\left(-\\log x' - \\dots\\right) = \\log x' - \\log x = \\log(x'/x) $$\n\n**1(a). 伽马目标：** $\\pi_x(x) \\propto x^{k - 1} \\exp\\left(-\\frac{x}{\\theta}\\right)$\n- $x$ 空间中的对数目标：$\\log\\pi_x(x) = (k - 1)\\log x - \\frac{x}{\\theta} + C_x$。\n- $u$ 空间中的变换目标：\n  $ \\pi_u(u) = \\pi_x(\\exp u) |\\exp u| \\propto (\\exp u)^{k-1} \\exp\\left(-\\frac{\\exp u}{\\theta}\\right) \\exp u = \\exp(ku - \\frac{\\exp u}{\\theta}) $\n- $u$ 空间中的对数目标：$\\log \\pi_u(u) = ku - \\frac{\\exp u}{\\theta} + C_u$。\n\n**1(b). 指数目标：** $\\pi_x(x) \\propto \\exp(-\\lambda x)$\n- $x$ 空间中的对数目标：$\\log\\pi_x(x) = -\\lambda x + C_x$。\n- $u$ 空间中的变换目标：\n  $ \\pi_u(u) = \\pi_x(\\exp u) |\\exp u| \\propto \\exp(-\\lambda \\exp u) \\exp u $\n- $u$ 空间中的对数目标：$\\log \\pi_u(u) = u - \\lambda \\exp u + C_u$。\n\n**2. 恒等变换：$u = x$ (对于 $x \\in \\mathbb{R}$) **\n- 逆变换：$x = g^{-1}(u) = u$。\n- 雅可比行列式：$J_{g^{-1}}(u) = \\frac{dx}{du} = 1$。\n- 雅可比行列式绝对值：$|\\det J_{g^{-1}}(u)| = 1$。\n- $x$ 空间中提议的对数比率为 $0$，因为导出的提议 $q_x(x'|x) = \\mathcal{N}(x; x, \\sigma^2)$ 是对称的。\n- 变换后的目标具有相同的形式：$\\pi_u(u) = \\pi_x(u)$。\n\n**2(a). 标准正态目标：** $\\pi_x(x) \\propto \\exp\\left(-\\frac{x^2}{2}\\right)$\n- $x$ 空间中的对数目标：$\\log \\pi_x(x) = -\\frac{x^2}{2} + C_x$。\n- $u$ 空间中的对数目标：$\\log \\pi_u(u) = -\\frac{u^2}{2} + C_u$。\n\n程序将通过实现这些推导出的对数密度函数和完整的接受概率公式，为每个测试用例计算差值 $\\Delta = |\\alpha_u - \\alpha_x|$。由于已证明的理论等价性，$\\Delta$ 应为零，只受浮点数值精度的影响。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and verifies the Metropolis-Hastings acceptance probability under a change of variables.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # 1. Happy path, log transform with gamma target\n        {'type': 'gamma_log', 'params': {'k': 2.3, 'theta': 1.1}, 'u': 0.25, 'u_prime': 0.7, 'sigma': 0.5},\n        # 2. Boundary case near x=0, log transform with gamma target\n        {'type': 'gamma_log', 'params': {'k': 2.3, 'theta': 1.1}, 'u': -0.1, 'u_prime': -5.0, 'sigma': 0.5},\n        # 3. Baseline identity transform with standard normal target\n        {'type': 'normal_identity', 'params': {}, 'u': 1.0, 'u_prime': -1.7, 'sigma': 1.0},\n        # 4. Log transform with exponential target\n        {'type': 'exp_log', 'params': {'lambda': 1.7}, 'u': 0.3, 'u_prime': -1.0, 'sigma': 0.7}\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        u = case['u']\n        u_prime = case['u_prime']\n        params = case['params']\n        \n        # --- U-Space Calculation ($\\alpha_u$) ---\n        \n        log_pi_u_val = 0.0\n        log_pi_u_prime_val = 0.0\n        \n        if case['type'] == 'gamma_log':\n            k, theta = params['k'], params['theta']\n            # log_pi_u(u) = k*u - exp(u)/theta\n            log_pi_u_val = k * u - np.exp(u) / theta\n            log_pi_u_prime_val = k * u_prime - np.exp(u_prime) / theta\n        elif case['type'] == 'exp_log':\n            lam = params['lambda']\n            # log_pi_u(u) = u - lambda*exp(u)\n            log_pi_u_val = u - lam * np.exp(u)\n            log_pi_u_prime_val = u_prime - lam * np.exp(u_prime)\n        elif case['type'] == 'normal_identity':\n            # log_pi_u(u) = -u^2 / 2\n            log_pi_u_val = -u**2 / 2.0\n            log_pi_u_prime_val = -u_prime**2 / 2.0\n            \n        # For a symmetric Gaussian proposal in u-space, the proposal ratio is 1, and its log is 0.\n        log_q_u_ratio = 0.0\n        \n        log_r_u = log_pi_u_prime_val - log_pi_u_val + log_q_u_ratio\n        alpha_u = min(1.0, np.exp(log_r_u))\n\n        # --- X-Space Calculation ($\\alpha_x$) ---\n        \n        log_pi_x_val = 0.0\n        log_pi_x_prime_val = 0.0\n        log_q_x_ratio = 0.0\n        \n        if 'log' in case['type']:\n            # Log transform: u = log(x) => x = exp(u)\n            x = np.exp(u)\n            x_prime = np.exp(u_prime)\n            # For a log-normal proposal, log q(x|x') - log q(x'|x) = log(x'/x)\n            log_q_x_ratio = np.log(x_prime / x)\n            \n            if 'gamma' in case['type']:\n                k, theta = params['k'], params['theta']\n                # log_pi_x(x) = (k - 1)*log(x) - x/theta\n                log_pi_x_val = (k - 1.0) * np.log(x) - x / theta\n                log_pi_x_prime_val = (k - 1.0) * np.log(x_prime) - x_prime / theta\n            elif 'exp' in case['type']:\n                lam = params['lambda']\n                # log_pi_x(x) = -lambda*x\n                log_pi_x_val = -lam * x\n                log_pi_x_prime_val = -lam * x_prime\n        \n        elif 'identity' in case['type']:\n            # Identity transform: u = x\n            x = u\n            x_prime = u_prime\n            # For a symmetric Gaussian proposal, the proposal ratio is 1, and its log is 0.\n            log_q_x_ratio = 0.0\n            \n            if 'normal' in case['type']:\n                # log_pi_x(x) = -x^2 / 2\n                log_pi_x_val = -x**2 / 2.0\n                log_pi_x_prime_val = -x_prime**2 / 2.0\n\n        log_r_x = log_pi_x_prime_val - log_pi_x_val + log_q_x_ratio\n        alpha_x = min(1.0, np.exp(log_r_x))\n        \n        # Calculate the absolute difference\n        delta = abs(alpha_u - alpha_x)\n        results.append(delta)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3148250"}]}