{"hands_on_practices": [{"introduction": "高斯混合模型（GMM）是无监督学习中的一个典型问题，通常用于聚类。虽然期望最大化（EM）算法是解决GMM的常用方法，但变分推断为我们提供了一个强大的贝叶斯视角，使我们能够得到对潜在变量和模型参数的完整后验分布的近似。这个练习 ([@problem_id:3191998]) 将带你从零开始构建坐标上升变分推断（CAVI）算法，让你亲身体验其“E步骤”和“M步骤”的交替优化过程。", "problem": "考虑一个一维、双成分的高斯混合模型，该模型具有潜在成分指示符和未知的成分均值。设有 $K=2$ 个成分和 $N$ 个标量观测值 $\\{x_n\\}_{n=1}^N$。该生成模型由以下经过充分检验的结构定义：\n- 潜在指示符 $z_n \\in \\{1,2\\}$ 从一个分类分布中独立抽取，混合权重为 $\\pi = (\\pi_1,\\pi_2)$，其中 $\\pi_k \\in (0,1)$ 且 $\\pi_1 + \\pi_2 = 1$。\n- 在给定 $z_n = k$ 和成分均值 $\\mu_k$ 的条件下，每个观测值 $x_n$ 从一个已知方差为 $\\sigma^2$ 的高斯分布中抽取，即 $x_n \\mid (z_n=k,\\mu_k) \\sim \\mathcal{N}(\\mu_k,\\sigma^2)$。\n- 未知的成分均值具有独立的高斯先验分布 $\\mu_k \\sim \\mathcal{N}(m_{0k},\\tau_{0k}^{-1})$，其中 $\\tau_{0k} > 0$ 是先验精度，$m_{0k}$ 是先验均值。\n\n使用变分推断中的证据下界（ELBO）定义以及平均场分解 $q(z,\\mu) = \\left(\\prod_{n=1}^N q(z_n)\\right)\\left(\\prod_{k=1}^2 q(\\mu_k)\\right)$，从第一性原理推导以下各项的坐标上升变分更新：\n1. 责任度 $r_{nk} = q(z_n = k)$，其中 $n \\in \\{1,\\dots,N\\}$ 且 $k \\in \\{1,2\\}$。\n2. 变分因子 $q(\\mu_k)$，包括其均值和精度的闭式表达式。\n\n请将你的推导建立在基础的ELBO恒等式 $\\mathcal{L}(q) = \\mathbb{E}_q[\\log p(x,z,\\mu)] - \\mathbb{E}_q[\\log q(z,\\mu)]$ 和每个因子的最优平均场因子更新规则 $q^*(\\theta_i) \\propto \\exp\\left(\\mathbb{E}_{q(\\theta_{\\setminus i})}[\\log p(x,\\theta)]\\right)$ 之上。除了这些定义，不要使用任何快捷公式。\n\n在推导出更新规则后，实现一个确定性的坐标上升算法，该算法：\n- 将责任度均匀初始化为 $r_{nk} = 1/2$（对所有 $n, k$）。\n- 交替更新 $q(\\mu_k)$ 的参数和责任度 $r_{nk}$。\n- 当连续迭代之间所有 $n,k$ 的责任度绝对差值之和最多为容差 $T$ 时，或达到最大迭代次数时停止。\n\n使用以下测试套件来评估标签切换（label switching）的影响和一个边界情况。对于每个测试，根据需要运行算法两次，并按照描述比较结果。在比较责任度时，使用容差 $T = 10^{-8}$。\n\n- 测试1（理想情况，全排列下的标签不变性）：\n  - 观测值：$x = [\\, -2.2,\\, -1.9,\\, -1.7,\\, 1.5,\\, 1.8,\\, 2.2 \\,]$。\n  - 已知方差：$\\sigma^2 = 0.25$。\n  - 混合权重：$\\pi = [\\, 0.5,\\, 0.5 \\,]$。\n  - 先验均值：$m_0 = [\\, -2.0,\\, 2.0 \\,]$。\n  - 先验精度：$\\tau_0 = [\\, 1.0,\\, 1.0 \\,]$。\n  运行算法以获得责任度 $R^{(A)}$。然后再次运行算法，但将标签完全置换，即交换混合权重和先验均值：$\\pi' = [\\, 0.5,\\, 0.5 \\,]$, $m_0' = [\\, 2.0,\\, -2.0 \\,]$, $\\tau_0' = [\\, 1.0,\\, 1.0 \\,]$，得到 $R^{(B)}$。检查 $R^{(A)}$ 是否在容差 $T$ 内与 $R^{(B)}$ 相等（允许列置换）。结果应为一个布尔值。\n\n- 测试2（边缘情况，破坏不变性的部分置换）：\n  - 观测值：$x = [\\, -2.2,\\, -1.9,\\, -1.7,\\, 1.5,\\, 1.8,\\, 2.2 \\,]$。\n  - 已知方差：$\\sigma^2 = 0.25$。\n  - 混合权重：$\\pi = [\\, 0.7,\\, 0.3 \\,]$。\n  - 先验均值：$m_0 = [\\, -2.0,\\, 2.0 \\,]$。\n  - 先验精度：$\\tau_0 = [\\, 1.0,\\, 1.0 \\,]$。\n  运行算法以获得责任度 $R^{(C)}$。然后再次运行算法，但交换先验均值，混合权重保持原始顺序（部分置换）：$m_0' = [\\, 2.0,\\, -2.0 \\,]$, $\\pi' = [\\, 0.7,\\, 0.3 \\,]$，得到 $R^{(D)}$。确定 $R^{(C)}$ 是否与 $R^{(D)}$ 在容差 $T$ 之外存在差异（即使在列置换后）。结果应为一个指示非不变性的布尔值。\n\n- 测试3（边界条件，不可区分的成分）：\n  - 观测值：$x = [\\, -1.0,\\, 1.0 \\,]$。\n  - 已知方差：$\\sigma^2 = 1.0$。\n  - 混合权重：$\\pi = [\\, 0.5,\\, 0.5 \\,]$。\n  - 先验均值：$m_0 = [\\, 0.0,\\, 0.0 \\,]$。\n  - 先验精度：$\\tau_0 = [\\, 100.0,\\, 100.0 \\,]$。\n  运行算法一次，并计算所有数据点和成分的责任度与 $0.5$ 之间的最大绝对偏差。结果应为一个浮点数。\n\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[\\,\\text{result1},\\text{result2},\\text{result3}\\,]$），其中 $\\text{result1}$ 和 $\\text{result2}$ 是测试1和2的布尔值，$\\text{result3}$ 是测试3的浮点数。", "solution": "用户提供的问题是有效的。这是一个统计学习领域中定义明确的问题，具体涉及变分推断，具有清晰一致的模型定义、特定的算法任务和可验证的测试用例。所有必要的数据和参数都已提供。\n\n问题是为双成分高斯混合模型（GMM）推导并实现一个坐标上升变分推断（CAVI）算法。该推导将基于平均场近似和最优变分因子的一般形式。\n\n### 1. 模型设定\n\n设观测数据为 $N$ 个标量的集合 $\\{x_n\\}_{n=1}^N$。潜在变量是成分均值 $\\mu = \\{\\mu_1, \\mu_2\\}$ 和成分分配 $z = \\{z_n\\}_{n=1}^N$，其中每个 $z_n \\in \\{1, 2\\}$。为方便起见，我们使用独热编码表示 $z_n$，即如果第 $n$ 个观测值来自成分 $k$，则 $z_{nk}=1$，否则 $z_{nk}=0$。\n\n生成过程如下：\n- 每个成分均值的先验是独立的高斯分布：\n$$p(\\mu_k) = \\mathcal{N}(\\mu_k | m_{0k}, \\tau_{0k}^{-1})$$\n其中 $m_{0k}$ 是先验均值，$\\tau_{0k} > 0$ 是先验精度。\n- 潜在成分指示符 $z_n$ 从一个具有已知混合权重 $\\pi = (\\pi_1, \\pi_2)$ 的分类分布中抽取：\n$$p(z_n | \\pi) = \\prod_{k=1}^2 \\pi_k^{z_{nk}}$$\n- 每个观测值 $x_n$ 在给定其分配的成分 $k$ 和相应均值 $\\mu_k$ 的条件下，从一个已知方差为 $\\sigma^2$ 的高斯分布中抽取：\n$$p(x_n | z_n, \\mu) = \\prod_{k=1}^2 \\mathcal{N}(x_n | \\mu_k, \\sigma^2)^{z_{nk}}$$\n\n所有变量（观测变量和潜在变量）的完整联合概率分布由下式给出：\n$$p(x, z, \\mu) = p(\\mu) p(z | \\pi) p(x | z, \\mu) = \\left(\\prod_{k=1}^2 p(\\mu_k)\\right) \\left(\\prod_{n=1}^N p(z_n | \\pi)\\right) \\left(\\prod_{n=1}^N p(x_n | z_n, \\mu)\\right)$$\n联合分布的对数为：\n$$\\log p(x, z, \\mu) = \\sum_{k=1}^2 \\log p(\\mu_k) + \\sum_{n=1}^N \\sum_{k=1}^2 z_{nk} \\log \\pi_k + \\sum_{n=1}^N \\sum_{k=1}^2 z_{nk} \\log \\mathcal{N}(x_n | \\mu_k, \\sigma^2)$$\n\n### 2. 变分推断设置\n\n我们使用平均场变分族来近似真实后验 $p(z, \\mu | x)$。变分分布 $q(z, \\mu)$ 分解为：\n$$q(z, \\mu) = q(z)q(\\mu) = \\left(\\prod_{n=1}^N q(z_n)\\right) \\left(\\prod_{k=1}^2 q(\\mu_k)\\right)$$\n其中每个 $q(z_n)$ 是一个关于 $K=2$ 个成分的分类分布，由概率 $r_{nk} = q(z_n=k)$ 表征，而每个 $q(\\mu_k)$ 是关于成分 $k$ 的均值的分布。\n\n坐标上升算法通过固定其他因子来迭代优化每个因子 $q(\\theta_i)$。因子 $q^*(\\theta_i)$ 的最优形式由下式给出：\n$$\\log q^*(\\theta_i) = \\mathbb{E}_{q(\\theta_{\\setminus i})}[\\log p(x, \\theta)] + \\mathrm{constant}$$\n其中 $\\theta_i$ 是潜在变量之一（$z_n$ 或 $\\mu_k$），$\\theta_{\\setminus i}$ 表示所有其他潜在变量。\n\n### 3. $q(\\mu_k)$ 更新规则的推导\n\n为了找到 $q(\\mu_k)$ 的最优形式，我们应用通用更新规则。最优分布 $q^*(\\mu_k)$ 的对数与对数联合概率关于所有其他因子 $q(z)$ 和 $q(\\mu_{j \\neq k})$ 的期望成正比：\n$$\\log q^*(\\mu_k) = \\mathbb{E}_{q(z)}[\\log p(x, z, \\mu)] + \\mathrm{constant}$$\n我们只需要考虑 $\\log p(x, z, \\mu)$ 中依赖于 $\\mu_k$ 的项：\n$$\\log q^*(\\mu_k) = \\mathbb{E}_{q(z)}\\left[\\sum_{n=1}^N z_{nk} \\log \\mathcal{N}(x_n | \\mu_k, \\sigma^2)\\right] + \\log \\mathcal{N}(\\mu_k | m_{0k}, \\tau_{0k}^{-1}) + \\mathrm{const}$$\n期望 $\\mathbb{E}_{q(z)}[z_{nk}]$ 是责任度 $r_{nk}$。令 $\\tau = 1/\\sigma^2$ 为已知的数据精度。\n$$\\log q^*(\\mu_k) = \\sum_{n=1}^N r_{nk} \\left(-\\frac{1}{2} \\log(2\\pi\\sigma^2) - \\frac{\\tau}{2}(x_n - \\mu_k)^2\\right) + \\left(-\\frac{1}{2} \\log(2\\pi\\tau_{0k}^{-1}) - \\frac{\\tau_{0k}}{2}(\\mu_k - m_{0k})^2\\right) + \\mathrm{const}$$\n为了确定 $q^*(\\mu_k)$ 的形式，我们收集包含 $\\mu_k$ 的项：\n$$\\log q^*(\\mu_k) = -\\frac{\\tau}{2} \\sum_{n=1}^N r_{nk}(x_n^2 - 2x_n\\mu_k + \\mu_k^2) - \\frac{\\tau_{0k}}{2}(\\mu_k^2 - 2\\mu_k m_{0k} + m_{0k}^2) + \\mathrm{const}$$\n按 $\\mu_k$ 的幂次对各项进行分组：\n- 含 $\\mu_k^2$ 的项：$-\\frac{1}{2}\\mu_k^2 \\left(\\tau_{0k} + \\tau \\sum_{n=1}^N r_{nk}\\right)$\n- 含 $\\mu_k$ 的项：$\\mu_k \\left(\\tau_{0k}m_{0k} + \\tau \\sum_{n=1}^N r_{nk}x_n\\right)$\n这是 $\\mu_k$ 的一个二次型，这是高斯密度对数的特征。一个高斯分布 $\\mathcal{N}(\\mu | m, \\lambda^{-1})$ 的对数密度形式为 $-\\frac{\\lambda}{2}\\mu^2 + \\lambda m \\mu + \\mathrm{const}$。\n通过匹配系数，我们发现 $q^*(\\mu_k)$ 是一个高斯分布 $\\mathcal{N}(\\mu_k | m_k, \\tau_k^{-1})$，其精度为 $\\tau_k$，均值为 $m_k$：\n$$\\tau_k = \\tau_{0k} + \\tau \\sum_{n=1}^N r_{nk}$$\n$$m_k = \\frac{\\tau_{0k}m_{0k} + \\tau \\sum_{n=1}^N r_{nk}x_n}{\\tau_k}$$\n这些是变分分布 $q(\\mu_k)$ 参数的更新方程。\n\n### 4. $q(z_n)$ 更新规则的推导\n\n类似地，我们通过对数联合概率关于所有其他因子 $\\{q(z_j)\\}_{j \\neq n}$ 和 $\\{q(\\mu_k)\\}_{k=1}^2$ 取期望，来找到 $q(z_n)$ 的最优形式：\n$$\\log q^*(z_n) = \\mathbb{E}_{q(\\mu)}[\\log p(x, z, \\mu)] + \\mathrm{constant}$$\n我们收集依赖于 $z_n$ 的项：\n$$\\log q^*(z_n) = \\sum_{k=1}^2 z_{nk} \\log \\pi_k + \\sum_{k=1}^2 z_{nk} \\mathbb{E}_{q(\\mu_k)}[\\log \\mathcal{N}(x_n | \\mu_k, \\sigma^2)] + \\mathrm{const}$$\n这意味着 $q^*(z_n)$ 是一个分类分布。成分 $k$ 的对数概率为：\n$$\\log q^*(z_n=k) \\equiv \\log r_{nk} \\propto \\log \\pi_k + \\mathbb{E}_{q(\\mu_k)}[\\log \\mathcal{N}(x_n | \\mu_k, \\sigma^2)]$$\n让我们展开期望项：\n$$\\mathbb{E}_{q(\\mu_k)}[\\log \\mathcal{N}(x_n | \\mu_k, \\sigma^2)] = \\mathbb{E}_{q(\\mu_k)}\\left[-\\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{\\tau}{2}(x_n - \\mu_k)^2\\right]$$\n$$= -\\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{\\tau}{2} \\mathbb{E}_{q(\\mu_k)}[x_n^2 - 2x_n\\mu_k + \\mu_k^2]$$\n$$= -\\frac{1}{2}\\log(2\\pi\\sigma^2) - \\frac{\\tau}{2} (x_n^2 - 2x_n\\mathbb{E}[\\mu_k] + \\mathbb{E}[\\mu_k^2])$$\n从我们推导出的 $q(\\mu_k) = \\mathcal{N}(\\mu_k | m_k, \\tau_k^{-1})$ 的形式，我们有：\n$$\\mathbb{E}[\\mu_k] = m_k$$\n$$\\mathbb{E}[\\mu_k^2] = \\mathrm{Var}[\\mu_k] + (\\mathbb{E}[\\mu_k])^2 = \\tau_k^{-1} + m_k^2$$\n将这些代入 $\\log q^*(z_n=k)$ 的表达式中，并舍去相对于 $k$ 为常数的项（如 $-\\frac{1}{2}\\log(2\\pi\\sigma^2)$ 和 $-\\frac{\\tau}{2}x_n^2$）：\n$$\\log \\tilde{\\rho}_{nk} \\propto \\log \\pi_k + \\tau x_n \\mathbb{E}[\\mu_k] - \\frac{\\tau}{2} \\mathbb{E}[\\mu_k^2]$$\n$$\\log \\tilde{\\rho}_{nk} = \\log \\pi_k + \\tau x_n m_k - \\frac{\\tau}{2}(m_k^2 + \\tau_k^{-1})$$\n责任度 $r_{nk} = q(z_n=k)$ 是通过对指数化后的值进行归一化得到的：\n$$r_{nk} = \\frac{\\exp(\\log \\tilde{\\rho}_{nk})}{\\sum_{j=1}^2 \\exp(\\log \\tilde{\\rho}_{nj})}$$\n\n### 5. 算法总结\n\n坐标上升变分推断（CAVI）算法的步骤如下：\n1.  **初始化**：初始化责任度 $r_{nk}$（例如，均匀初始化为 $r_{nk} = 1/2$）。\n2.  **迭代**直至收敛：\n    a. **更新 $q(\\mu)$（类M步）**：对每个成分 $k=1,2$，使用当前的责任度 $r_{nk}$ 更新变分分布 $q(\\mu_k)$ 的参数 $m_k$ 和 $\\tau_k$：\n       $$\\tau_k \\leftarrow \\tau_{0k} + \\tau \\sum_{n=1}^N r_{nk}$$\n       $$m_k \\leftarrow \\frac{\\tau_{0k}m_{0k} + \\tau \\sum_{n=1}^N r_{nk}x_n}{\\tau_k}$$\n    b. **更新 $q(z)$（类E步）**：对每个数据点 $n=1,\\dots,N$，使用更新后的 $q(\\mu)$ 参数更新责任度 $r_{nk}$：\n       $$\\log \\tilde{\\rho}_{nk} \\leftarrow \\log \\pi_k + \\tau x_n m_k - \\frac{\\tau}{2}(m_k^2 + \\tau_k^{-1})$$\n       $$r_{nk} \\leftarrow \\frac{\\exp(\\log \\tilde{\\rho}_{nk})}{\\sum_{j=1}^2 \\exp(\\log \\tilde{\\rho}_{nj})}$$\n    c. **检查收敛**：如果责任度的变化小于容差 $T$ 或达到最大迭代次数，则停止。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the variational inference problem for the provided test cases.\n    \"\"\"\n\n    def run_cavi(x, sigma_sq, pi, m0, tau0, tol, max_iter=100):\n        \"\"\"\n        Runs the Coordinate Ascent Variational Inference algorithm for a GMM.\n\n        Args:\n            x (np.ndarray): 1D array of observations.\n            sigma_sq (float): Known variance of the Gaussian components.\n            pi (np.ndarray): 1D array of mixing weights.\n            m0 (np.ndarray): 1D array of prior means for component means.\n            tau0 (np.ndarray): 1D array of prior precisions for component means.\n            tol (float): Convergence tolerance for responsibilities.\n            max_iter (int): Maximum number of iterations.\n\n        Returns:\n            np.ndarray: A (N, K) array of final responsibilities.\n        \"\"\"\n        N = x.shape[0]\n        K = pi.shape[0]\n        tau = 1.0 / sigma_sq\n\n        # Initialize responsibilities uniformly\n        r_nk = np.full((N, K), 1.0 / K)\n\n        for i in range(max_iter):\n            r_nk_old = r_nk.copy()\n\n            # M-step: Update q(mu_k)\n            # Sum of responsibilities for each component\n            N_k = np.sum(r_nk, axis=0) # Shape (K,)\n            # Update variational precision for mu_k\n            tau_k = tau0 + tau * N_k # Shape (K,)\n            # Update variational mean for mu_k\n            # r_nk.T is (K,N), x is (N,). (r_nk.T @ x) is sum(r_nk * x) for each k\n            sum_r_x = r_nk.T @ x # Shape (K,)\n            m_k = (tau0 * m0 + tau * sum_r_x) / tau_k # Shape (K,)\n\n            # E-step: Update q(z_n), i.e., the responsibilities r_nk\n            E_mu_k_sq = 1.0 / tau_k + m_k**2 # Shape (K,)\n            \n            # Use broadcasting for efficiency. x[:, np.newaxis] is (N,1)\n            # m_k and E_mu_k_sq are (K,) which broadcasts to (N,K)\n            log_rho_nk = np.log(pi) + tau * x[:, np.newaxis] * m_k - (tau / 2) * E_mu_k_sq\n            \n            # Log-sum-exp trick for numerical stability\n            log_rho_nk_max = np.max(log_rho_nk, axis=1, keepdims=True)\n            log_rho_nk_stable = log_rho_nk - log_rho_nk_max\n            rho_nk = np.exp(log_rho_nk_stable)\n            \n            # Normalize to get responsibilities\n            r_nk = rho_nk / np.sum(rho_nk, axis=1, keepdims=True)\n\n            # Check for convergence\n            diff = np.sum(np.abs(r_nk - r_nk_old))\n            if diff  tol:\n                break\n        \n        return r_nk\n\n    T = 10**-8\n    results = []\n\n    # Test 1: Happy path, label invariance under full permutation\n    x1 = np.array([-2.2, -1.9, -1.7, 1.5, 1.8, 2.2])\n    sigma_sq1 = 0.25\n    pi_A = np.array([0.5, 0.5])\n    m0_A = np.array([-2.0, 2.0])\n    tau0_1 = np.array([1.0, 1.0])\n    R_A = run_cavi(x1, sigma_sq1, pi_A, m0_A, tau0_1, T)\n\n    pi_B = np.array([0.5, 0.5]) # Same pi\n    m0_B = np.array([2.0, -2.0]) # Swapped means\n    tau0_B = np.array([1.0, 1.0])\n    R_B = run_cavi(x1, sigma_sq1, pi_B, m0_B, tau0_B, T)\n\n    # Check for equality up to column permutation (label switching)\n    is_invariant = np.allclose(R_A, R_B, atol=T) or np.allclose(R_A, R_B[:, ::-1], atol=T)\n    results.append(is_invariant)\n\n    # Test 2: Edge case, partial permutation that breaks invariance\n    x2 = np.array([-2.2, -1.9, -1.7, 1.5, 1.8, 2.2])\n    sigma_sq2 = 0.25\n    pi_C = np.array([0.7, 0.3])\n    m0_C = np.array([-2.0, 2.0])\n    tau0_2 = np.array([1.0, 1.0])\n    R_C = run_cavi(x2, sigma_sq2, pi_C, m0_C, tau0_2, T)\n    \n    pi_D = np.array([0.7, 0.3]) # Unswapped pi\n    m0_D = np.array([2.0, -2.0]) # Swapped means\n    tau0_D = np.array([1.0, 1.0])\n    R_D = run_cavi(x2, sigma_sq2, pi_D, m0_D, tau0_D, T)\n\n    # Check if results are different even after accounting for label switching\n    is_non_invariant = not (np.allclose(R_C, R_D, atol=T) or np.allclose(R_C, R_D[:, ::-1], atol=T))\n    results.append(is_non_invariant)\n\n    # Test 3: Boundary condition, indistinguishable components\n    x3 = np.array([-1.0, 1.0])\n    sigma_sq3 = 1.0\n    pi_3 = np.array([0.5, 0.5])\n    m0_3 = np.array([0.0, 0.0])\n    tau0_3 = np.array([100.0, 100.0])\n    R_3 = run_cavi(x3, sigma_sq3, pi_3, m0_3, tau0_3, T)\n    max_dev = np.max(np.abs(R_3 - 0.5))\n    results.append(max_dev)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3191998"}, {"introduction": "许多现实世界的模型，如贝叶斯逻辑回归，并不具备我们在GMM练习中遇到的那种方便的“共轭”属性，这使得直接推导更新规则变得困难。本练习 ([@problem_id:691486]) 将展示变分推断的一个关键优势：通过使用局部变分界来处理这类非共轭模型。我们将学习如何通过一个二次函数来近似一个棘手的似然项，从而使参数更新变得可行，这在变分推断的实际应用中是一个常见且强大的技巧。", "problem": "考虑一个用于二元分类任务的贝叶斯逻辑回归模型。给定一个数据点 $(x, t)$，其中 $x=(x_1, x_2)^T \\in \\mathbb{R}^2$ 是特征向量，$t \\in \\{-1, 1\\}$ 是对应的类别标签。标签的似然由 $p(t|w,x) = \\sigma(t w^T x)$ 给出，其中 $w=(w_1, w_2)^T$ 是权重向量，$\\sigma(z) = (1+e^{-z})^{-1}$ 是逻辑S型函数（logistic sigmoid function）。\n\n权重上设置了一个零均值各向同性高斯先验，其精度为 $\\alpha > 0$：\n$$p(w) = \\mathcal{N}(w | 0, \\alpha^{-1}I)$$\n其中 $I$ 是 $2 \\times 2$ 的单位矩阵。\n\n真实的后验分布 $p(w|x,t)$ 是难解的。我们使用变分推断和一个分解的高斯后验近似（平均场）来近似它：\n$$q(w) = q_1(w_1)q_2(w_2) = \\mathcal{N}(w_1|\\mu_1, v_1)\\mathcal{N}(w_2|\\mu_2, v_2)$$\n\n为了处理似然和先验的非共轭性，证据下界（ELBO）中的对数似然项被近似。项 $\\log \\sigma(z)$ 由一个涉及变分参数 $\\xi \\in \\mathbb{R}$ 的二次函数作为其下界：\n$$ \\log \\sigma(z) \\ge \\log \\sigma(\\xi) + \\frac{1}{2}(z - \\xi) - \\lambda(\\xi)(z^2 - \\xi^2) $$\n其中函数 $\\lambda(\\xi)$ 定义为：\n$$ \\lambda(\\xi) = \\frac{\\tanh(\\xi/2)}{4\\xi} $$\n\n变分参数被迭代更新。考虑分布 $q_1(w_1)$ 的单次更新步骤。假设另一个因子 ($\\mu_2$) 和局部下界 ($\\xi$) 的参数是固定的，求出使ELBO最大化的最优均值 $\\mu_1$ 的表达式。你的答案应使用 $x_1, x_2, t, \\alpha, \\xi$ 和 $\\mu_2$ 来表示。", "solution": "1. 为对数似然项设定下界：\n$$\\log\\sigma(tw^T x)\\ge\\log\\sigma(\\xi)+\\frac12\\,t(w_1x_1+w_2x_2)-\\lambda(\\xi)\\bigl[t^2(w_1x_1+w_2x_2)^2-\\xi^2\\bigr].$$\n\n2. 对数先验：\n$$\\log p(w)=-\\frac12\\alpha(w_1^2+w_2^2)+\\text{常数}.$$\n\n3. 构造 $w_1$ 的变分指数：\n$$\nE_{q_2}[\\log p(w)+\\log\\sigma(tw^T x)]\n=\\;-\\tfrac12\\,\\alpha\\,w_1^2\n+\\underbrace{\\tfrac12\\,t\\,x_1\\,w_1}_{\\text{来自线性项}}\n-\\lambda(\\xi)\\,E_{q_2}[(w_1x_1+w_2x_2)^2]\n+\\text{常数}.\n$$\n\n4. 计算 $E_{q_2}[(w_1x_1+w_2x_2)^2]$：\n$$\n(w_1x_1+\\mu_2x_2)^2+v_2x_2^2\n=w_1^2x_1^2+2w_1x_1\\mu_2x_2+\\text{常数}.\n$$\n\n5. 收集 $w_1$ 的二次项和线性项：\n- 二次项：$-\\tfrac12(\\alpha+2\\lambda(\\xi)x_1^2)w_1^2$。\n- 线性项：$(\\tfrac12t x_1-2\\lambda(\\xi)x_1x_2\\mu_2)w_1$。\n\n6. 读出高斯参数：\n$$\n\\text{精度}=\\alpha+2\\lambda(\\xi)x_1^2,\\quad\n\\text{自然均值}=\\tfrac12t x_1-2\\lambda(\\xi)x_1x_2\\mu_2\n$$\n因此\n$$\n\\mu_1=\\frac{\\tfrac12t x_1-2\\lambda(\\xi)x_1x_2\\mu_2}{\\alpha+2\\lambda(\\xi)x_1^2}.\n$$", "answer": "$$\\boxed{\\frac{\\tfrac12\\,t\\,x_1 \\;-\\;2\\,\\lambda(\\xi)\\,x_1\\,x_2\\,\\mu_2}{\\alpha+2\\,\\lambda(\\xi)\\,x_1^2}}$$", "id": "691486"}, {"introduction": "对于海量数据集，前述练习中那种在每一步都使用整个数据集进行更新的“批处理”方式会变得异常缓慢。随机变分推断（SVI）正是为了解决这一挑战而生，它将VI转化为一种可扩展的随机优化算法。本练习 ([@problem_id:3192036]) 将深入探讨SVI的核心：如何获得目标函数（ELBO）的无偏梯度估计。通过动手实现并比较两种著名的梯度估计方法——重参数化技巧和得分函数估计器，你将直观地理解它们在梯度方差和应用条件上的关键差异。", "problem": "考虑对一个正标量参数 $\\theta \\in (0,\\infty)$ 进行贝叶斯推断，其似然为泊松分布，先验为伽马分布。设观测数据为计数 $\\{x_i\\}_{i=1}^n$，其中 $x_i \\in \\{0,1,2,\\dots\\}$，其模型为 $x_i \\mid \\theta \\sim \\text{Poisson}(\\theta)$。采用形状参数为 $a>0$、速率参数为 $b>0$ 的伽马先验 $\\theta \\sim \\text{Gamma}(a,b)$。我们将使用对数正态变分族 $q(\\theta \\mid \\mu,\\sigma)$ 来近似后验分布，该变分族定义为 $\\log \\theta \\sim \\mathcal{N}(\\mu,\\sigma^2)$，其中 $\\mu \\in \\mathbb{R}$ 且 $\\sigma > 0$。\n\n从第一性原理出发，使用变分推断的证据下界 (ELBO) 定义和标准概率定义，推导变分参数 $\\mu$ 和 $\\sigma$ 的重参数化梯度。使用链式法则和一种有效的、基于采样的 $\\theta$ 参数化方法，该方法用一个标准正态随机变量来表示 $\\theta$。另外，使用对数导数技巧推导得分函数梯度。您应将 ELBO 表示为一种形式，使其梯度可以分解为模型项期望的贡献和变分分布熵的贡献。除了这些基本模型定义外，不要假设任何共轭性或闭式后验。\n\n实现这两种梯度估计器（重参数化和得分函数），并对每一种估计器，使用少量样本计算 ELBO 关于 $\\mu$ 和 $\\sigma$ 的梯度的蒙特卡洛估计。为评估偏差减少情况，将每个小样本梯度估计与一个高精度参考梯度进行比较，该参考梯度是使用重参数化估计器和大量样本计算得出的。将差异量化为小样本估计与参考值之间绝对差值的平均值，该平均值通过多次独立重复实验计算得出。报告重参数化估计器是否对 $\\mu$ 和 $\\sigma$ 都产生了比得分函数估计器更小的平均绝对差异。\n\n您必须处理以下测试套件。每个测试用例提供了变分参数 $(\\mu,\\sigma)$、先验参数 $(a,b)$ 和一个数据集 $\\{x_i\\}_{i=1}^n$：\n\n- 测试用例 1：$\\mu = 0.0$, $\\sigma = 0.5$, $a = 2.0$, $b = 1.0$, 数据 $\\{1,0,2,1,3,2,1,0,1,2\\}$ (此处 $n=10$)。\n- 测试用例 2：$\\mu = 1.0$, $\\sigma = 0.1$, $a = 3.0$, $b = 2.0$, 数据 $\\{5,4,6,3,7,5,6,4\\}$ (此处 $n=8$)。\n- 测试用例 3：$\\mu = -0.5$, $\\sigma = 1.5$, $a = 1.5$, $b = 0.5$, 数据 $\\{0,1,0,2,1\\}$ (此处 $n=5$)。\n- 测试用例 4：$\\mu = 0.2$, $\\sigma = 0.2$, $a = 5.0, b = 4.0$, 数据 $\\{2,0,1,0,3,1\\}$ (此处 $n=6$)。\n\n对于每个测试用例：\n- 使用重参数化估计器和 $S_{\\text{ref}} = 200000$ 个样本，计算一个高精度的参考梯度。\n- 使用 $S_{\\text{small}} = 16$ 个样本计算小样本梯度估计，并对两种估计器，在 $R = 100$ 次独立重复实验中计算绝对差异的平均值。\n- 对于每个测试用例，输出一个布尔值，该值指示重参数化估计器的平均绝对差异是否同时对 $\\mu$ 和 $\\sigma$ 严格小于得分函数估计器的平均绝对差异。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[\\text{result}_1,\\text{result}_2,\\text{result}_3,\\text{result}_4]$），其中每个 $result_k$ 是测试用例 $k$ 的布尔值。此问题不涉及任何物理单位或角度；所有量纲均为无量纲。您的实现必须是自包含的，并通过在内部固定所有伪随机种子来确保确定性。", "solution": "用户希望在变分推断的背景下，比较两种不同梯度估计器对证据下界 (ELBO) 的性能。该模型包含一个用于观测计数 $\\{x_i\\}$ 的泊松似然（速率参数为 $\\theta$），一个关于 $\\theta$ 的伽马先验，以及一个用于 $\\theta$ 后验分布的对数正态变分近似。\n\n**问题验证**\n\n**步骤 1：提取已知条件**\n-   **模型**:\n    -   似然：$x_i \\mid \\theta \\sim \\text{Poisson}(\\theta)$，对于 $i=1, \\dots, n$。数据包含计数 $\\{x_i\\}_{i=1}^n$。\n    -   先验：$\\theta \\sim \\text{Gamma}(a,b)$，形状参数 $a>0$，速率参数 $b>0$。\n-   **变分近似**:\n    -   后验分布 $p(\\theta \\mid \\{x_i\\})$ 的变分族是 $q(\\theta \\mid \\mu,\\sigma)$，一个由 $\\log \\theta \\sim \\mathcal{N}(\\mu,\\sigma^2)$ 定义的对数正态分布，参数为 $\\mu \\in \\mathbb{R}$ 和 $\\sigma>0$。\n-   **任务**:\n    1.  推导 ELBO 关于变分参数 $\\mu$ 和 $\\sigma$ 的重参数化梯度和得分函数梯度。\n    2.  实现这两种估计器。\n    3.  对于给定的测试用例，使用重参数化估计器和 $S_{\\text{ref}} = 200000$ 个样本计算一个高精度参考梯度。\n    4.  对于这两种估计器，计算小样本（$S_{\\text{small}}=16$）梯度估计，并在 $R=100$ 次独立重复实验中计算与参考梯度之间的平均绝对差异。\n    5.  对于每个测试用例，确定重参数化估计器的平均绝对差异是否同时对 $\\mu$ 和 $\\sigma$ 都严格小于得分函数估计器的平均绝对差异。\n-   **测试套件**:\n    -   用例 1: $\\mu = 0.0, \\sigma = 0.5, a = 2.0, b = 1.0, \\text{数据}=\\{1,0,2,1,3,2,1,0,1,2\\}$。\n    -   用例 2: $\\mu = 1.0, \\sigma = 0.1, a = 3.0, b = 2.0, \\text{数据}=\\{5,4,6,3,7,5,6,4\\}$。\n    -   用例 3: $\\mu = -0.5, \\sigma = 1.5, a = 1.5, b = 0.5, \\text{数据}=\\{0,1,0,2,1\\}$。\n    -   用例 4: $\\mu = 0.2, \\sigma = 0.2, a = 5.0, b = 4.0, \\text{数据}=\\{2,0,1,0,3,1\\}$。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，是计算统计学和机器学习中的一个标准任务。问题定义明确，为获得唯一的数值解提供了所有必要的定义、数据和参数。语言客观、精确。该问题满足所有有效性标准。\n\n**步骤 3：结论与行动**\n问题有效。将提供完整解决方案。\n\n**数学推导**\n\n设 $\\phi = (\\mu, \\sigma)$ 为变分参数。ELBO $\\mathcal{L}(\\phi)$ 由下式给出：\n$$ \\mathcal{L}(\\phi) = \\mathbb{E}_{q(\\theta;\\phi)}[\\log p(\\mathbf{x}, \\theta) - \\log q(\\theta;\\phi)] $$\n联合对数概率 $\\log p(\\mathbf{x}, \\theta)$ 是对数似然和对数先验之和。\n$$ \\log p(\\mathbf{x} \\mid \\theta) = \\sum_{i=1}^n \\log\\left(\\frac{\\theta^{x_i}e^{-\\theta}}{x_i!}\\right) = \\left(\\sum_{i=1}^n x_i\\right)\\log\\theta - n\\theta - \\sum_{i=1}^n \\log(x_i!) $$\n$$ \\log p(\\theta) = \\log\\left(\\frac{b^a}{\\Gamma(a)}\\theta^{a-1}e^{-b\\theta}\\right) = (a-1)\\log\\theta - b\\theta + a\\log b - \\log\\Gamma(a) $$\n设 $S_x = \\sum_{i=1}^n x_i$。将它们结合起来得到：\n$$ \\log p(\\mathbf{x}, \\theta) = (S_x + a - 1)\\log\\theta - (n+b)\\theta + \\text{const} $$\n变分分布 $q(\\theta;\\phi)$ 是对数正态分布，因此其对数概率密度函数 (log-PDF) 为：\n$$ \\log q(\\theta;\\phi) = -\\log\\theta - \\log\\sigma - \\frac{1}{2}\\log(2\\pi) - \\frac{(\\log\\theta - \\mu)^2}{2\\sigma^2} $$\n问题建议将 ELBO 梯度表示为两个分量的和：期望对数联合概率的梯度和 $q$ 的熵的梯度。\n$$ \\mathcal{L}(\\phi) = \\mathbb{E}_{q(\\theta;\\phi)}[\\log p(\\mathbf{x}, \\theta)] + H(q) $$\n其中 $H(q) = -\\mathbb{E}_{q(\\theta;\\phi)}[\\log q(\\theta;\\phi)]$ 是熵。对于对数正态分布，$H(q) = \\mu + \\log\\sigma + \\frac{1}{2}\\log(2\\pi e)$。熵项的梯度是解析的：\n$$ \\nabla_\\mu H(q) = 1, \\quad \\nabla_\\sigma H(q) = \\frac{1}{\\sigma} $$\n\n**1. 重参数化梯度估计器**\n重参数化技巧允许我们将 $\\theta$ 写成一个关于 $\\phi$ 和一个具有固定分布的辅助随机变量 $\\epsilon$ 的确定性函数。由于 $\\log\\theta \\sim \\mathcal{N}(\\mu, \\sigma^2)$，我们可以设 $\\log\\theta = \\mu + \\sigma\\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0,1)$。因此，$\\theta(\\phi, \\epsilon) = \\exp(\\mu + \\sigma\\epsilon)$。\n期望对数联合概率的梯度可以通过将梯度移入期望内部来计算：\n$$ \\nabla_\\phi \\mathbb{E}_{q(\\theta;\\phi)}[\\log p(\\mathbf{x}, \\theta)] = \\nabla_\\phi \\mathbb{E}_{\\epsilon\\sim\\mathcal{N}(0,1)}[\\log p(\\mathbf{x}, \\theta(\\phi,\\epsilon))] = \\mathbb{E}_{\\epsilon\\sim\\mathcal{N}(0,1)}[\\nabla_\\phi \\log p(\\mathbf{x}, \\theta(\\phi,\\epsilon))] $$\n使用链式法则，$\\nabla_\\phi \\log p = \\frac{d \\log p}{d\\theta} \\nabla_\\phi \\theta$。\n$$ \\frac{d\\log p}{d\\theta} = \\frac{S_x+a-1}{\\theta} - (n+b) $$\n$\\theta$ 相对于 $\\phi$ 的梯度为：\n$$ \\frac{\\partial\\theta}{\\partial\\mu} = \\exp(\\mu+\\sigma\\epsilon) \\cdot 1 = \\theta, \\quad \\frac{\\partial\\theta}{\\partial\\sigma} = \\exp(\\mu+\\sigma\\epsilon) \\cdot \\epsilon = \\theta\\epsilon $$\n所以，对数联合项的梯度为：\n$$ \\frac{\\partial \\log p}{\\partial\\mu} = \\left(\\frac{S_x+a-1}{\\theta} - (n+b)\\right)\\theta = S_x+a-1 - (n+b)\\theta $$\n$$ \\frac{\\partial \\log p}{\\partial\\sigma} = \\left(\\frac{S_x+a-1}{\\theta} - (n+b)\\right)\\theta\\epsilon = (S_x+a-1 - (n+b)\\theta)\\epsilon $$\n与熵的梯度结合，完整的 ELBO 梯度为：\n$$ \\nabla_\\mu \\mathcal{L}(\\phi) = \\mathbb{E}_{\\epsilon}[S_x+a-1 - (n+b)\\theta] + 1 = \\mathbb{E}_{\\epsilon}[S_x+a - (n+b)\\theta(\\phi,\\epsilon)] $$\n$$ \\nabla_\\sigma \\mathcal{L}(\\phi) = \\mathbb{E}_{\\epsilon}[(S_x+a-1 - (n+b)\\theta)\\epsilon] + \\frac{1}{\\sigma} $$\n一个具有 $S$ 个样本 $\\{\\epsilon^{(s)}\\}_{s=1}^S$ 的蒙特卡洛估计器，其中 $\\theta^{(s)} = \\exp(\\mu+\\sigma\\epsilon^{(s)})$，是：\n$$ \\hat{g}_\\mu^{\\text{reparam}} = \\frac{1}{S}\\sum_{s=1}^S [S_x+a - (n+b)\\theta^{(s)}] $$\n$$ \\hat{g}_\\sigma^{\\text{reparam}} = \\frac{1}{S}\\sum_{s=1}^S [(S_x+a-1 - (n+b)\\theta^{(s)})\\epsilon^{(s)}] + \\frac{1}{\\sigma} $$\n\n**2. 得分函数梯度估计器 (REINFORCE)**\n该估计器基于对数导数技巧，$\\nabla_\\phi q(\\theta;\\phi) = q(\\theta;\\phi) \\nabla_\\phi \\log q(\\theta;\\phi)$。它适用于完整的 ELBO 表达式 $\\mathcal{L}(\\phi) = \\mathbb{E}_{q}[\\log p(\\mathbf{x}, \\theta) - \\log q(\\theta;\\phi)]$。\n$$ \\nabla_\\phi \\mathcal{L}(\\phi) = \\mathbb{E}_{q(\\theta;\\phi)}[(\\log p(\\mathbf{x}, \\theta) - \\log q(\\theta;\\phi)) \\nabla_\\phi \\log q(\\theta;\\phi)] $$\n我们需要得分函数，即 $\\nabla_\\phi \\log q(\\theta;\\phi)$。\n$$ \\nabla_\\mu \\log q = \\frac{\\partial}{\\partial\\mu} \\left(-\\frac{(\\log\\theta - \\mu)^2}{2\\sigma^2}\\right) = \\frac{\\log\\theta - \\mu}{\\sigma^2} $$\n$$ \\nabla_\\sigma \\log q = \\frac{\\partial}{\\partial\\sigma} \\left(-\\log\\sigma - \\frac{(\\log\\theta - \\mu)^2}{2\\sigma^2}\\right) = -\\frac{1}{\\sigma} + \\frac{(\\log\\theta - \\mu)^2}{\\sigma^3} = \\frac{(\\log\\theta - \\mu)^2 - \\sigma^2}{\\sigma^3} $$\n一个具有 $S$ 个样本 $\\{\\theta^{(s)}\\}_{s=1}^S \\sim q(\\theta;\\phi)$ 的蒙特卡洛估计器是：\n$$ \\hat{g}_\\mu^{\\text{score}} = \\frac{1}{S}\\sum_{s=1}^S \\left[ (\\log p(\\mathbf{x}, \\theta^{(s)}) - \\log q(\\theta^{(s)};\\phi)) \\left(\\frac{\\log\\theta^{(s)} - \\mu}{\\sigma^2}\\right) \\right] $$\n$$ \\hat{g}_\\sigma^{\\text{score}} = \\frac{1}{S}\\sum_{s=1}^S \\left[ (\\log p(\\mathbf{x}, \\theta^{(s)}) - \\log q(\\theta^{(s)};\\phi)) \\left(\\frac{(\\log\\theta^{(s)} - \\mu)^2 - \\sigma^2}{\\sigma^3}\\right) \\right] $$\n为了实现这一点，我们通过相同的重参数化方法 $\\theta^{(s)} = \\exp(\\mu+\\sigma\\epsilon^{(s)})$（其中 $\\epsilon^{(s)} \\sim \\mathcal{N}(0,1)$）采样 $\\theta^{(s)}$，并计算每个样本的完整项 $\\log p(\\mathbf{x}, \\theta^{(s)})$ 和 $\\log q(\\theta^{(s)};\\phi)$。\n\n实现将遵循这些推导出的公式来计算梯度，并将其与高精度参考值进行差异比较。每个测试用例的布尔结果表明，就 $\\mu$ 和 $\\sigma$ 的平均绝对差异而言，重参数化估计器是否更优。", "answer": "```python\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef solve():\n    \"\"\"\n    Derives, implements, and compares reparameterization and score-function\n    gradient estimators for a Bayesian model with a Poisson likelihood.\n    \"\"\"\n    \n    # Fix the global random seed for deterministic and reproducible execution.\n    np.random.seed(42)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'mu': 0.0, 'sigma': 0.5, 'a': 2.0, 'b': 1.0, 'data': [1, 0, 2, 1, 3, 2, 1, 0, 1, 2]},\n        {'mu': 1.0, 'sigma': 0.1, 'a': 3.0, 'b': 2.0, 'data': [5, 4, 6, 3, 7, 5, 6, 4]},\n        {'mu': -0.5, 'sigma': 1.5, 'a': 1.5, 'b': 0.5, 'data': [0, 1, 0, 2, 1]},\n        {'mu': 0.2, 'sigma': 0.2, 'a': 5.0, 'b': 4.0, 'data': [2, 0, 1, 0, 3, 1]},\n    ]\n\n    results = []\n    for case in test_cases:\n        mu, sigma, a, b, data = case['mu'], case['sigma'], case['a'], case['b'], case['data']\n        \n        # Pre-compute data-dependent constants\n        n = len(data)\n        Sx = np.sum(data)\n\n        # Monte Carlo settings\n        S_ref = 200000\n        S_small = 16\n        R = 100\n\n        # --- High-Accuracy Reference Gradient Calculation ---\n        # Generate a large number of samples from the base distribution.\n        eps_ref = np.random.standard_normal(S_ref)\n        # Transform samples to the Log-Normal variational distribution for theta.\n        theta_ref = np.exp(mu + sigma * eps_ref)\n        \n        # Compute the reference gradient using the reparameterization estimator,\n        # known for its low variance and unbiasedness.\n        grad_mu_ref = np.mean(Sx + a - (n + b) * theta_ref)\n        grad_sigma_ref = np.mean((Sx + a - 1 - (n + b) * theta_ref) * eps_ref) + 1.0 / sigma\n\n        # --- Discrepancy Evaluation over Replicates ---\n        reparam_disc_mu = np.zeros(R)\n        reparam_disc_sigma = np.zeros(R)\n        score_disc_mu = np.zeros(R)\n        score_disc_sigma = np.zeros(R)\n\n        # Pre-calculate constants for the score function estimator's f(theta) term\n        sum_log_fact_x = np.sum(gammaln(np.array(data) + 1.0))\n        log_prior_const = a * np.log(b) - gammaln(a)\n        log_joint_const = log_prior_const - sum_log_fact_x\n\n        for r in range(R):\n            # Generate a small sample set, used by both estimators for a fair comparison\n            eps_small = np.random.standard_normal(S_small)\n            log_theta_small = mu + sigma * eps_small\n            theta_small = np.exp(log_theta_small)\n\n            # --- 1. Reparameterization Estimator (Small Sample) ---\n            grad_mu_reparam = np.mean(Sx + a - (n + b) * theta_small)\n            grad_sigma_reparam = np.mean((Sx + a - 1 - (n + b) * theta_small) * eps_small) + 1.0 / sigma\n            \n            # Store absolute discrepancy from the reference\n            reparam_disc_mu[r] = np.abs(grad_mu_reparam - grad_mu_ref)\n            reparam_disc_sigma[r] = np.abs(grad_sigma_reparam - grad_sigma_ref)\n\n            # --- 2. Score-Function Estimator (Small Sample) ---\n            # Calculate f(theta) = log p(x, theta) - log q(theta)\n            # log p(x, theta)\n            log_joint = (Sx + a - 1) * log_theta_small - (n + b) * theta_small + log_joint_const\n            # log q(theta)\n            log_q = -log_theta_small - np.log(sigma) - 0.5 * np.log(2 * np.pi) - (log_theta_small - mu)**2 / (2 * sigma**2)\n            f_theta = log_joint - log_q\n            \n            # Calculate grad log q(theta)\n            grad_log_q_mu = (log_theta_small - mu) / (sigma**2)\n            grad_log_q_sigma = ((log_theta_small - mu)**2 - sigma**2) / (sigma**3)\n            \n            # Calculate score function gradients\n            grad_mu_score = np.mean(f_theta * grad_log_q_mu)\n            grad_sigma_score = np.mean(f_theta * grad_log_q_sigma)\n            \n            # Store absolute discrepancy from the reference\n            score_disc_mu[r] = np.abs(grad_mu_score - grad_mu_ref)\n            score_disc_sigma[r] = np.abs(grad_sigma_score - grad_sigma_ref)\n    \n        # Compute average discrepancies over all replicates\n        avg_reparam_disc_mu = np.mean(reparam_disc_mu)\n        avg_reparam_disc_sigma = np.mean(reparam_disc_sigma)\n        avg_score_disc_mu = np.mean(score_disc_mu)\n        avg_score_disc_sigma = np.mean(score_disc_sigma)\n    \n        # --- Final Comparison ---\n        # Check if reparameterization estimator is strictly better for both parameters\n        is_reparam_better = (avg_reparam_disc_mu  avg_score_disc_mu) and \\\n                            (avg_reparam_disc_sigma  avg_score_disc_sigma)\n        \n        results.append(is_reparam_better)\n\n    # Print the final results in the specified format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3192036"}]}