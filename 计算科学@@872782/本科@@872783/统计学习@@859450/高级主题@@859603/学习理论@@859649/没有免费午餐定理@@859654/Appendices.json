{"hands_on_practices": [{"introduction": "泛化差距（测试误差减去训练误差）是衡量模型学习效果的关键指标。这个练习将探讨一个由“没有免费午餐”定理决定的极端情况：当数据标签完全是随机噪声时，会发生什么。通过推导一个完美拟合（插值）训练数据的算法的期望泛化差距，我们将揭示在没有真实信号的情况下，过拟合所能达到的最大程度。[@problem_id:3153395]", "problem": "考虑一个$K$类分类问题，其输入空间为$\\mathcal{X}$，标签空间为$\\mathcal{Y}=\\{1,2,\\dots,K\\}$。设$(X,Y)$是一个随机对，其中$X \\sim P_{X}$是任意的，而$Y$与$X$独立并在$\\mathcal{Y}$上均匀分布。你观察到一个训练样本$S=\\{(x_{i},y_{i})\\}_{i=1}^{n}$，它由从$P_{X} \\times \\text{Unif}(\\mathcal{Y})$中抽取的$n$个独立同分布的样本构成。一个学习算法$\\mathcal{A}$将样本$S$（以及可能的内部随机性）映射到一个分类器$\\hat{f}_{S}:\\mathcal{X}\\to\\mathcal{Y}$。假设$\\mathcal{A}$是一个插值算法，这意味着训练数据上的经验$0$-$1$风险恰好为零：\n$$\nR_{\\text{train}}(S) \\equiv \\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{1}\\{\\hat{f}_{S}(x_{i}) \\neq y_{i}\\} = 0.\n$$\n将$\\hat{f}_{S}$的条件测试风险定义为\n$$\nR_{\\text{test}}(S) \\equiv \\Pr\\big(\\hat{f}_{S}(X) \\neq Y \\,\\big|\\, S\\big),\n$$\n其中概率是针对一个独立的测试对$(X,Y)\\sim P_{X}\\times \\text{Unif}(\\mathcal{Y})$计算的。设$R_{\\text{baseline}}$表示一个分类器的错误率，该分类器独立于$X$和$S$，从$\\mathcal{Y}$中均匀随机地猜测一个标签。\n\n仅使用基本定义（独立性、条件期望和$0$-$1$损失的定义），推导期望泛化差距\n$$\n\\mathbb{E}\\big[R_{\\text{test}}(S)-R_{\\text{train}}(S)\\big]\n$$\n的精确表达式，该表达式是$K$的函数，其中期望是关于样本$S$的随机性（以及$\\mathcal{A}$的任何内部随机性）计算的。将你的最终答案表示为关于$K$的单一闭式解析表达式。不需要近似或四舍五入，也不涉及任何单位。", "solution": "问题要求我们求出期望泛化差距$\\mathbb{E}\\big[R_{\\text{test}}(S)-R_{\\text{train}}(S)\\big]$的精确表达式。该期望是针对随机训练样本$S$以及学习算法$\\mathcal{A}$的任何内部随机性计算的。\n\n首先，我们分析泛化差距中的两项：测试风险$R_{\\text{test}}(S)$和训练风险$R_{\\text{train}}(S)$。\n\n训练风险$R_{\\text{train}}(S)$定义为$R_{\\text{train}}(S) \\equiv \\frac{1}{n}\\sum_{i=1}^{n}\\mathbf{1}\\{\\hat{f}_{S}(x_{i}) \\neq y_{i}\\}$。问题陈述算法$\\mathcal{A}$是一个插值算法，这意味着训练数据上的经验$0$-$1$风险恰好为零。因此，对于任何抽取的训练样本$S$，我们有：\n$$\nR_{\\text{train}}(S) = 0\n$$\n这个条件意味着学习到的分类器正确分类了所有训练样本：对于所有$i \\in \\{1, 2, \\dots, n\\}$，都有$\\hat{f}_{S}(x_{i}) = y_{i}$。\n\n在$R_{\\text{train}}(S) = 0$的情况下，期望泛化差距简化为：\n$$\n\\mathbb{E}\\big[R_{\\text{test}}(S)-R_{\\text{train}}(S)\\big] = \\mathbb{E}\\big[R_{\\text{test}}(S) - 0\\big] = \\mathbb{E}\\big[R_{\\text{test}}(S)\\big]\n$$\n问题因此简化为计算期望测试风险。\n\n条件测试风险$R_{\\text{test}}(S)$定义为在一个新的、独立的测试对$(X, Y)$上的错误概率，以训练样本$S$为条件：\n$$\nR_{\\text{test}}(S) \\equiv \\Pr\\big(\\hat{f}_{S}(X) \\neq Y \\,\\big|\\, S\\big)\n$$\n期望$\\mathbb{E}\\big[R_{\\text{test}}(S)\\big]$是对所有可能的训练集$S$求的。使用全期望定律（或称塔性质），我们可以写出：\n$$\n\\mathbb{E}\\big[R_{\\text{test}}(S)\\big] = \\mathbb{E}_{S}\\left[\\Pr\\big(\\hat{f}_{S}(X) \\neq Y \\,\\big|\\, S\\big)\\right] = \\Pr\\big(\\hat{f}_{S}(X) \\neq Y\\big)\n$$\n右侧是总错误概率，其中概率是针对所有随机性来源计算的：训练样本$S$、算法$\\mathcal{A}$中的任何内部随机性以及测试对$(X, Y)$。\n\n为了计算这个概率，先计算正确预测的概率$\\Pr\\big(\\hat{f}_{S}(X) = Y\\big)$会更容易。我们有：\n$$\n\\Pr\\big(\\hat{f}_{S}(X) \\neq Y\\big) = 1 - \\Pr\\big(\\hat{f}_{S}(X) = Y\\big)\n$$\n设测试输入$X$的预测由随机变量$\\hat{Y} = \\hat{f}_{S}(X)$表示。这个预测$\\hat{Y}$是训练样本$S$和测试输入$X$（以及$\\mathcal{A}$的任何内部随机性）的函数。测试点的真实标签是随机变量$Y$。\n\n问题的核心在于指定的数据生成分布。测试标签$Y$从集合$\\mathcal{Y}=\\{1, 2, \\dots, K\\}$中均匀抽取，并且与测试输入$X$独立。此外，整个测试对$(X,Y)$与训练样本$S$独立。因此，测试标签$Y$与随机变量集合$(X, S)$以及算法的任何内部随机性都独立。由于预测$\\hat{Y} = \\hat{f}_{S}(X)$是$(X, S)$（以及内部随机性）的函数，因此可以推断出$Y$与$\\hat{Y}$独立。\n\n我们通过对所有可能的正确标签结果求和来计算正确预测的概率：\n$$\n\\Pr(\\hat{Y} = Y) = \\sum_{k=1}^{K} \\Pr(\\hat{Y} = k \\text{ and } Y = k)\n$$\n因为$\\hat{Y}$和$Y$是独立随机变量，所以联合概率是边际概率的乘积：\n$$\n\\Pr(\\hat{Y} = k \\text{ and } Y = k) = \\Pr(\\hat{Y} = k) \\cdot \\Pr(Y = k)\n$$\n根据问题陈述，$Y$在$\\mathcal{Y}$上均匀分布。因此，对于任何标签$k \\in \\mathcal{Y}$：\n$$\n\\Pr(Y = k) = \\frac{1}{K}\n$$\n将此代入求和式中得到：\n$$\n\\Pr(\\hat{Y} = Y) = \\sum_{k=1}^{K} \\Pr(\\hat{Y} = k) \\cdot \\frac{1}{K} = \\frac{1}{K} \\sum_{k=1}^{K} \\Pr(\\hat{Y} = k)\n$$\n随机变量$\\hat{Y}$所有可能结果的概率之和必须等于$1$。由于$\\hat{f}_{S}:\\mathcal{X}\\to\\mathcal{Y}$，$\\hat{Y}$的可能结果是$\\mathcal{Y}$中的标签。因此：\n$$\n\\sum_{k=1}^{K} \\Pr(\\hat{Y} = k) = 1\n$$\n将此结果代回，我们得到正确预测的概率：\n$$\n\\Pr(\\hat{Y} = Y) = \\frac{1}{K} \\cdot 1 = \\frac{1}{K}\n$$\n这个结果与算法$\\mathcal{A}$的选择无关，只要它对给定输入产生确定性预测，并且是标签$Y$作为纯噪声、与特征$X$没有统计依赖关系的直接后果。\n\n那么总错误概率是：\n$$\n\\Pr\\big(\\hat{f}_{S}(X) \\neq Y\\big) = 1 - \\Pr\\big(\\hat{f}_{S}(X) = Y\\big) = 1 - \\frac{1}{K}\n$$\n这就是期望测试风险$\\mathbb{E}\\big[R_{\\text{test}}(S)\\big]$的值。\n\n最后，我们可以计算期望泛化差距：\n$$\n\\mathbb{E}\\big[R_{\\text{test}}(S)-R_{\\text{train}}(S)\\big] = \\mathbb{E}\\big[R_{\\text{test}}(S)\\big] - \\mathbb{E}\\big[R_{\\text{train}}(S)\\big]\n$$\n由于对所有$S$都有$R_{\\text{train}}(S)=0$，其期望也为$0$。\n$$\n\\mathbb{E}\\big[R_{\\text{test}}(S)-R_{\\text{train}}(S)\\big] = \\left(1 - \\frac{1}{K}\\right) - 0 = 1 - \\frac{1}{K}\n$$\n这个表达式可以重写为$\\frac{K-1}{K}$。这个结果展示了“没有免费午餐”定理的一种形式：在特征和标签之间没有任何相关性的情况下，一个完美插值嘈杂训练数据的算法，其测试性能并不比随机猜测更好。插值条件只是将训练误差驱动到$0$，从而最大化了测试和训练性能之间的差距。", "answer": "$$\n\\boxed{1 - \\frac{1}{K}}\n$$", "id": "3153395"}, {"introduction": "“没有免费午餐”定理主要针对监督学习，其性能依赖于特征与标签之间的关联。这个编码练习旨在直观地展示这一点。通过对标签进行随机重排来人为地破坏这种关联，我们将观察到监督学习算法的性能如何崩溃到随机猜测的水平，而仅在特征中寻找结构的无监督算法则不受影响，从而揭示了不同学习范式成功的根源。[@problem_id:3199442]", "problem": "给定监督学习和无监督学习的基本定义。在监督学习中，任务是使用带标签的数据对 $(X,Y)$ 来学习一个从输入 $X \\in \\mathbb{R}^d$ 到标签 $Y \\in \\{0,1,\\dots,C-1\\}$ 的映射。在无监督学习中，任务是在不使用 $Y$ 的情况下发现输入 $X$ 中的结构。假设采用标准的概率形式，其中数据从一个联合分布 $p(X,Y)$ 中独立同分布地抽取，分类准确率通过在留出的测试集上计算期望指示函数 $\\mathbb{E}[\\mathbf{1}\\{\\hat{Y}(X)=Y\\}]$ 来衡量，而无监督结构恢复则通过使用一个置换不变指数将发现的簇与潜在类别进行比较来衡量。\n\n仅使用这些核心定义和“当 $Y$ 与 $X$ 相互独立时，没有任何分类器可以在没有额外假设的情况下系统地优于随机猜测”这一原则，设计一个程序，通过实验证明在对抗性重打标签的情况下，监督和无监督过程有何不同，而当标签反映潜在结构时，两种过程都表现正常。具体来说，对于下面指定的每个测试用例，您必须：\n\n1) 在 $\\mathbb{R}^2$ 中生成类别均衡的数据：\n- 固定整数 $C \\ge 2$（类别数）和 $n \\ge 2$（每个类别的样本数），以及实数参数 $\\sigma > 0$（簇的离散程度）和 $R > 0$（半径）。角度使用弧度。\n- 对于每个类别 $c \\in \\{0,1,\\dots,C-1\\}$，定义一个均值\n$$\n\\mu_c = R \\begin{bmatrix} \\cos\\left( \\tfrac{2\\pi c}{C} \\right) \\\\ \\sin\\left( \\tfrac{2\\pi c}{C} \\right) \\end{bmatrix},\n$$\n并从高斯分布\n$$\nX \\mid (Y=c) \\sim \\mathcal{N}\\!\\left(\\mu_c, \\ \\sigma^2 I_2\\right),\n$$\n中独立生成 $n$ 个样本，其中 $I_2$ 是 $2 \\times 2$ 的单位矩阵。生成的数据集总大小为 $N = C \\cdot n$。将每个类别的数据划分为大小为 $n_{\\text{train}} = n/2$ 的训练集和大小为 $n_{\\text{test}} = n/2$ 的测试集（假设在所有测试用例中 $n$ 均为偶数）。\n\n2) 无监督结构恢复：\n- 对所有 $N$ 个输入 $X$ 运行 $k$-means 聚类（$k=C$），忽略标签 $Y$。使用任何明确定义的初始化过程和固定的迭代次数上限以确保终止。\n- 计算聚类分配结果与真实标签 $Y$ 之间的调整兰德指数 (ARI)。对于 $N$ 个项目的两个划分 $\\mathcal{U}$ 和 $\\mathcal{V}$，其列联表条目为 $n_{ij}$，行和为 $a_i$，列和为 $b_j$，ARI 的计算公式为\n$$\n\\operatorname{ARI} = \\frac{\\sum_{i,j} \\binom{n_{ij}}{2} - \\frac{\\left(\\sum_i \\binom{a_i}{2}\\right)\\left(\\sum_j \\binom{b_j}{2}\\right)}{\\binom{N}{2}}}{\\tfrac{1}{2}\\left[\\sum_i \\binom{a_i}{2} + \\sum_j \\binom{b_j}{2}\\right] - \\frac{\\left(\\sum_i \\binom{a_i}{2}\\right)\\left(\\sum_j \\binom{b_j}{2}\\right)}{\\binom{N}{2}}}.\n$$\n\n3) 使用真实标签的监督学习基线：\n- 使用真实标签 $Y_{\\text{train}}$ 在训练集上训练一个最近质心分类器。对于每个类别 $c$，计算质心\n$$\n\\hat{\\mu}_c = \\frac{1}{|\\{i : Y_i=c, \\ i \\in \\text{train}\\}|} \\sum_{i: Y_i=c, \\ i \\in \\text{train}} X_i,\n$$\n并通过 $\\hat{y}(x) = \\arg\\min_{c \\in \\{0,\\dots,C-1\\}} \\|x - \\hat{\\mu}_c\\|_2^2$ 对一个测试点 $x$ 进行分类。计算测试准确率，即被正确分类的测试点的比例。\n\n4) 在对抗性置换标签下的监督学习：\n- 通过对训练标签应用一个均匀随机置换 $\\pi$ 来在训练集上构建对抗性标签，从而得到 $Y_{\\text{train}}^{\\pi}$。这保留了各类别的样本数量，但破坏了 $X$ 和 $Y$ 之间的一致性。\n- 使用 $(X_{\\text{train}}, Y_{\\text{train}}^{\\pi})$ 训练同一个最近质心分类器。用真实的测试标签 $Y_{\\text{test}}$ 来评估其测试准确率。\n\n您的程序必须为以下每个测试用例（这是测试套件）执行上述步骤，并对所有随机选择使用提供的种子以保证可复现性：\n\n- 测试用例 1：$(C, n, \\sigma, R, \\text{seed}) = (3, 150, 0.6, 5.0, 1234)$。\n- 测试用例 2：$(C, n, \\sigma, R, \\text{seed}) = (2, 200, 0.6, 4.0, 2021)$。\n- 测试用例 3：$(C, n, \\sigma, R, \\text{seed}) = (5, 250, 0.6, 7.0, 9876)$。\n\n最终输出格式：\n- 对于每个测试用例，计算三元组 $[ \\text{ARI}, \\ \\text{Acc}_{\\text{true}}, \\ \\text{Acc}_{\\text{perm}} ]$，其中 $\\text{ARI}$ 是步骤 2 中的调整兰德指数，$\\text{Acc}_{\\text{true}}$ 是步骤 3 中的监督学习测试准确率，$\\text{Acc}_{\\text{perm}}$ 是步骤 4 中的监督学习测试准确率。将所有三个值表示为小数点后精确到三位的小数。\n- 您的程序应生成单行输出，其中包含三个测试用例的结果，格式为这些三元组的逗号分隔列表，并用方括号括起来，例如：\"[ [a1,b1,c1],[a2,b2,c2],[a3,b3,c3] ]\"，其中每个 $a$、$b$ 和 $c$ 都替换为计算出的值。", "solution": "问题陈述是有效的。它提出了一个定义明确的计算实验，该实验基于统计机器学习的基本原理，旨在通过实验证明监督学习和无监督学习之间的概念差异。所有参数、算法和评估指标都已明确指定，构成一个自成体系且可复现的任务。\n\n该实验旨在突出一项核心区别：监督学习算法学习从输入 $X$ 到输出 $Y$ 的预测性映射，因此严重依赖于训练标签的正确性；而无监督学习算法仅在输入 $X$ 内部寻找内在结构，独立于任何提供的标签。本解决方案将实现指定的流程来证明这一原则。\n\n**1. 数据生成**\n\n本实验的基础是一个合成数据集，其中数据点 $X \\in \\mathbb{R}^2$ 的几何结构与潜在类别标签 $Y \\in \\{0, 1, \\dots, C-1\\}$ 有着内在的联系。对于给定的类别数 $C$、每个类别的样本数 $n$、簇的离散程度 $\\sigma$ 和半径 $R$，我们从一个高斯混合模型中生成数据。每个类别 $c$ 的均值 $\\mu_c$ 放置在半径为 $R$ 的圆上，并具有均匀的角度间隔：\n$$\n\\mu_c = R \\begin{bmatrix} \\cos\\left( \\tfrac{2\\pi c}{C} \\right) \\\\ \\sin\\left( \\tfrac{2\\pi c}{C} \\right) \\end{bmatrix}.\n$$\n然后，类别 $c$ 的数据点从以该均值为中心的各向同性高斯分布中采样：\n$$\nX \\mid (Y=c) \\sim \\mathcal{N}\\!\\left(\\mu_c, \\ \\sigma^2 I_2\\right),\n$$\n其中 $I_2$ 是 $2 \\times 2$ 的单位矩阵。这个过程在特征空间 $\\mathbb{R}^2$ 中创建了 $C$ 个不同的簇。为了进行实验，生成了总共 $N=C \\cdot n$ 个点的数据集，然后对于每个类别，数据被确定性地分割成大小为 $n_{\\text{train}} = n/2$ 的训练集和大小为 $n_{\\text{test}} = n/2$ 的测试集。\n\n**2. 无监督学习：使用 k-means 进行结构恢复**\n\n无监督学习旨在无需参考标签的情况下在数据中寻找模式。在这里，我们对整个输入特征集 $X$ 应用 $k$-means 聚类算法（$k=C$）。该算法通过迭代最小化簇内平方和，将 $N$ 个数据点划分为 $C$ 个簇。关键在于，$k$-means 完全不知道真实标签 $Y$。\n\n这种结构恢复的成功与否由调整兰德指数 (ARI) 来量化。ARI 衡量两个数据聚类结果之间的相似性，在本例中，即 $k$-means 找到的簇和由真实标签 $Y$ 定义的基准真相划分。ARI 是根据两个划分的列联表计算得出的，该表记录了在真实划分中属于类别 $i$ 且在预测划分中属于簇 $j$ 的点的数量 $n_{ij}$。其公式为：\n$$\n\\operatorname{ARI} = \\frac{\\text{Index} - \\text{Expected Index}}{\\text{Max Index} - \\text{Expected Index}} = \\frac{\\sum_{i,j} \\binom{n_{ij}}{2} - \\frac{\\left(\\sum_i \\binom{a_i}{2}\\right)\\left(\\sum_j \\binom{b_j}{2}\\right)}{\\binom{N}{2}}}{\\tfrac{1}{2}\\left[\\sum_i \\binom{a_i}{2} + \\sum_j \\binom{b_j}{2}\\right] - \\frac{\\left(\\sum_i \\binom{a_i}{2}\\right)\\left(\\sum_j \\binom{b_j}{2}\\right)}{\\binom{N}{2}}},\n$$\n其中 $a_i$ 和 $b_j$ 是列联表的行和与列和。ARI 为 1.0 表示完美恢复了潜在结构，而 ARI 接近 0.0 则表示聚类效果不比随机好。由于数据生成过程创建了与真实标签相对应的几何上分离的簇，并且 $k$-means 基于这种几何结构进行操作，我们期望得到一个高的 ARI。这个结果完全不受标签 $Y$ 如何存储或操作的影响，因为算法并未使用它们。\n\n**3. 监督学习：使用最近质心进行分类**\n\n相比之下，监督学习明确地使用标签。我们采用最近质心分类器。\n\n**3.1. 使用真实标签进行训练**\n首先，在合法的训练集 $(X_{\\text{train}}, Y_{\\text{train}})$ 上训练分类器。对于每个类别 $c$，它会计算一个经验质心 $\\hat{\\mu}_c$，即所有属于该类的训练特征向量的均值：\n$$\n\\hat{\\mu}_c = \\frac{1}{n_{\\text{train}}} \\sum_{i: Y_{\\text{train},i}=c} X_{\\text{train},i}.\n$$\n由于训练数据是从同样结构良好的分布中抽取的，这些经验质心 $\\hat{\\mu}_c$ 将是真实均值 $\\mu_c$ 的可靠估计。为了对一个新的测试点 $x$ 进行分类，分类器会找到在欧几里得距离上离它最近的质心：\n$$\n\\hat{y}(x) = \\arg\\min_{c \\in \\{0,\\dots,C-1\\}} \\|x - \\hat{\\mu}_c\\|_2^2.\n$$\n性能由测试集上的准确率来衡量，$\\text{Acc}_{\\text{true}} = \\frac{1}{N_{\\text{test}}} \\sum_{i=1}^{N_{\\text{test}}} \\mathbf{1}\\{\\hat{y}(X_{\\text{test},i}) = Y_{\\text{test},i}\\}$。鉴于簇是良好分离的，我们期望 $\\text{Acc}_{\\text{true}}$ 会非常高，接近 1.0。\n\n**3.2. 使用对抗性置换标签进行训练**\n接下来，我们模拟一个对抗性场景，其中训练标签被破坏。我们通过对原始训练标签 $Y_{\\text{train}}$ 应用一个均匀随机置换 $\\pi$ 来创建一组新的标签 $Y_{\\text{train}}^{\\pi}$。此操作保留了每个类别中的样本数量，但将标签与 $X_{\\text{train}}$ 的底层几何结构完全解耦。现在，$(X, Y^{\\pi})$ 的联合分布中，$Y^{\\pi}$ 与 $X$ 相互独立。\n\n然后，在被破坏的数据集 $(X_{\\text{train}}, Y_{\\text{train}}^{\\pi})$ 上训练同一个最近质心分类器。得到的质心将是无意义的；每个“质心”将是来自不同真实簇的点的平均值，并且它们很可能都位于数据全局均值附近，即原点 $(0,0)$。\n\n当这个训练不佳的分类器在原始测试集 $(X_{\\text{test}}, Y_{\\text{test}})$ 上进行评估时，其相对于真实标签的预测将是任意的。其准确率 $\\text{Acc}_{\\text{perm}}$ 预计将骤降至随机猜测的水平。对于一个均衡的 $C$ 类问题，这个基线准确率是 $1/C$。\n\n这对监督实验证明了该算法完全依赖于特征和标签之间有意义的相关性。当这种相关性被破坏时，监督模型学习失败，从而证实了基本原则。综合结果将显示出高的 $\\text{ARI}$ 和 $\\text{Acc}_{\\text{true}}$，但低的 $\\text{Acc}_{\\text{perm}}$。", "answer": "```python\nimport numpy as np\nfrom scipy.special import comb\nfrom scipy.cluster.vq import kmeans, vq\n\ndef generate_data(C, n, sigma, R, rng):\n    \"\"\"Generates data from C Gaussian clusters on a circle.\"\"\"\n    n_total = C * n\n    X = np.zeros((n_total, 2))\n    Y = np.zeros(n_total, dtype=int)\n    \n    cov = np.array([[sigma**2, 0], [0, sigma**2]])\n\n    for c in range(C):\n        mean = np.array([R * np.cos(2 * np.pi * c / C), R * np.sin(2 * np.pi * c / C)])\n        start_idx = c * n\n        end_idx = (c + 1) * n\n        \n        X[start_idx:end_idx, :] = rng.multivariate_normal(mean, cov, size=n)\n        Y[start_idx:end_idx] = c\n        \n    return X, Y\n\ndef split_data(X, Y, C, n):\n    \"\"\"Splits data into training and test sets, stratified by class.\"\"\"\n    n_train_per_class = n // 2\n    n_test_per_class = n // 2\n    \n    X_train, Y_train = [], []\n    X_test, Y_test = [], []\n    \n    for c in range(C):\n        class_indices = np.where(Y == c)[0]\n        \n        train_indices = class_indices[:n_train_per_class]\n        test_indices = class_indices[n_train_per_class:]\n        \n        X_train.append(X[train_indices])\n        Y_train.append(Y[train_indices])\n        X_test.append(X[test_indices])\n        Y_test.append(Y[test_indices])\n\n    return np.vstack(X_train), np.hstack(Y_train), np.vstack(X_test), np.hstack(Y_test)\n\ndef adjusted_rand_index(labels_true, labels_pred):\n    \"\"\"Computes the Adjusted Rand Index.\"\"\"\n    # Based on the formula from the problem statement.\n    n_samples = len(labels_true)\n    classes = np.unique(labels_true)\n    clusters = np.unique(labels_pred)\n    \n    # Contingency table\n    contingency = np.zeros((classes.size, clusters.size), dtype=int)\n    for i in range(classes.size):\n        for j in range(clusters.size):\n            contingency[i, j] = np.sum((labels_true == classes[i])  (labels_pred == clusters[j]))\n\n    # Sum of combinations for n_ij\n    sum_comb_nij = np.sum([comb(n, 2, exact=True) for n in contingency.flatten()])\n    \n    # Sum of combinations for row sums (a_i) and col sums (b_j)\n    sum_comb_ai = np.sum([comb(n, 2, exact=True) for n in np.sum(contingency, axis=1)])\n    sum_comb_bj = np.sum([comb(n, 2, exact=True) for n in np.sum(contingency, axis=0)])\n    \n    # Total combinations\n    comb_N2 = comb(n_samples, 2, exact=True)\n    \n    # Expected index\n    expected_index = (sum_comb_ai * sum_comb_bj) / comb_N2\n    \n    # Max index\n    max_index = (sum_comb_ai + sum_comb_bj) / 2\n    \n    numerator = sum_comb_nij - expected_index\n    denominator = max_index - expected_index\n    \n    if denominator == 0:\n        # This can happen if the clustering is trivial (e.g., all points in one cluster)\n        # or perfect. If numerator is also 0 (perfect clustering), ARI is 1.\n        return 1.0 if numerator == 0 else 0.0\n        \n    return numerator / denominator\n\nclass NearestCentroid:\n    \"\"\"Nearest Centroid Classifier.\"\"\"\n    def __init__(self):\n        self.centroids_ = None\n        self.classes_ = None\n\n    def fit(self, X, y):\n        self.classes_ = np.unique(y)\n        self.centroids_ = np.array([X[y == c].mean(axis=0) for c in self.classes_])\n        return self\n\n    def predict(self, X):\n        if self.centroids_ is None:\n            raise RuntimeError(\"Classifier has not been trained. Call fit() first.\")\n        # Compute squared Euclidean distances using broadcasting\n        # (a-b)^2 = a^2 - 2ab + b^2\n        X_norm_sq = np.sum(X**2, axis=1)[:, np.newaxis]\n        centroids_norm_sq = np.sum(self.centroids_**2, axis=1)[np.newaxis, :]\n        dot_product = X @ self.centroids_.T\n        \n        distances_sq = X_norm_sq - 2 * dot_product + centroids_norm_sq\n        \n        return self.classes_[np.argmin(distances_sq, axis=1)]\n\ndef solve():\n    test_cases = [\n        # (C, n, sigma, R, seed)\n        (3, 150, 0.6, 5.0, 1234),\n        (2, 200, 0.6, 4.0, 2021),\n        (5, 250, 0.6, 7.0, 9876),\n    ]\n\n    all_results = []\n\n    for C, n, sigma, R, seed in test_cases:\n        rng = np.random.default_rng(seed)\n        \n        # 1. Data generation\n        X, Y = generate_data(C, n, sigma, R, rng)\n        X_train, Y_train, X_test, Y_test = split_data(X, Y, C, n)\n\n        # 2. Unsupervised structure recovery (k-means)\n        # For reproducibility, initialize centroids manually from the data using the seeded RNG.\n        initial_centroids = X[rng.choice(X.shape[0], C, replace=False)]\n        centroids_kmeans, _ = kmeans(X, initial_centroids, iter=300)\n        cluster_assignments, _ = vq(X, centroids_kmeans)\n        ari = adjusted_rand_index(Y, cluster_assignments)\n\n        # 3. Supervised baseline with true labels\n        clf_true = NearestCentroid()\n        clf_true.fit(X_train, Y_train)\n        Y_pred_true = clf_true.predict(X_test)\n        acc_true = np.mean(Y_pred_true == Y_test)\n\n        # 4. Supervised under adversarially permuted labels\n        Y_train_perm = rng.permutation(Y_train)\n        clf_perm = NearestCentroid()\n        clf_perm.fit(X_train, Y_train_perm)\n        Y_pred_perm = clf_perm.predict(X_test)\n        acc_perm = np.mean(Y_pred_perm == Y_test)\n        \n        # Collect and format results for the current case\n        case_result = f\"[{ari:.3f},{acc_true:.3f},{acc_perm:.3f}]\"\n        all_results.append(case_result)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n\n```", "id": "3199442"}, {"introduction": "“没有免费午餐”定理最大胆的论断是：在所有可能任务的平均情况下，没有一种学习算法能优于其他任何算法。这个练习将通过计算和统计检验来直接验证这一核心主张。我们将比较两种截然不同的学习算法在一系列随机生成的任务上的表现，并利用配对t检验来实证检验它们的平均性能差异是否确实与零没有显著区别。[@problem_id:3153410]", "problem": "给定两个监督学习算法，您需要在统计学习的 No Free Lunch 定理框架下对它们进行比较。输入域是所有固定长度二进制向量的有限集。您的任务是通过在所有可能的标记上均匀抽样目标函数来设计合成任务，并实现一个配对假设检验，以验证两种学习器之间的平均性能差异是否与零无显著差异。\n\n使用的基本原理：\n- 有限域上监督学习的 No Free Lunch (NFL) 原则：在有限域上的目标函数服从均匀分布和零一损失下，所有学习算法在未见点上的期望泛化性能相等。\n- 风险和准确率的定义：对于假设 $h$ 和目标函数 $f$，在有限集 $U$ 上的零一损失下，准确率为 $\\frac{1}{|U|}\\sum_{x\\in U}\\mathbf{1}\\{h(x)=f(x)\\}$。\n- 使用配对 Student's $t$-test 的经典假设检验：给定配对差异 $\\{d_t\\}_{t=1}^k$，假设它们独立且近似服从均值为 $\\mu_d$ 和有限方差的正态分布，我们使用检验统计量 $T=\\bar{d}/(s_d/\\sqrt{k})$ 和自由度 $k-1$ 来检验原假设 $H_0:\\mu_d=0$。其中 $\\bar{d}$ 是样本均值，$s_d$ 是经过 Bessel's correction 的样本标准差。\n\n实验的设置和精确定义：\n- 输入空间：对于正整数 $m$，定义 $X=\\{0,1\\}^m$，使用二进制展开，按字典序由整数 $\\{0,1,\\dots,2^m-1\\}$ 表示。\n- 训练集：固定训练集大小 $n$，$0 \\le n \\le 2^m$。令训练索引集为 $X$ 中按字典序排列的前 $n$ 个元素，记为 $S=\\{x_0,\\dots,x_{n-1}\\}$。未见集为 $U=X\\setminus S$。\n- 目标函数抽样：一个目标函数 $f:X\\to\\{0,1\\}$ 由一个二进制向量 $y\\in\\{0,1\\}^{|X|}$ 表示。为了均匀抽样 $f$，对所有 $i\\in\\{0,\\dots,|X|-1\\}$，独立地从参数为 $1/2$ 的 Bernoulli 分布中抽取每个 $y_i$，即 $y_i\\sim\\mathrm{Bernoulli}(1/2)$。对于 $k=2^{|X|}$ 的特殊情况，将 $k$ 个任务定义为对 $X$ 的所有可能二进制标记的详尽枚举，按 $y$ 的字典序排列。\n- 学习器 $A_1$（在 $S$ 上使用 Hamming distance 的一近邻）：给定 $S$ 和标签 $y|_S$，定义 $A_1$ 对于任何 $x\\in X$，预测其在 $S$ 中基于 $\\{0,1\\}^m$ 上的 Hamming distance 的最近邻的标签。如果出现平局，则选择 $S$ 中字典序最小的训练点来打破平局。\n- 学习器 $A_2$（经验多数常数）：给定 $S$ 和标签 $y|_S$，定义 $A_2$ 对于所有 $x\\in X$ 均预测 $S$ 中的经验多数标签。如果 $S$ 中出现平局，则预测 $0$。\n- 每任务性能：对于每个抽样的任务 $f$，在 $S$ 上使用 $y|_S$ 训练 $A_1$ 和 $A_2$，并计算它们在 $U$ 上的准确率。设 $a_1$ 和 $a_2$ 为所得的准确率。定义配对差异 $d=a_1-a_2$。\n\n要实现的统计检验：\n- 对于给定的整数 $k\\ge 1$，通过如上所述均匀抽样 $f$ 来生成 $k$ 个独立任务（或者当 $k=2^{|X|}$ 时，详尽枚举所有 $2^{|X|}$ 个标记）。计算配对差异 $\\{d_t\\}_{t=1}^k$。\n- 使用配对 Student's $t$-test 在显著性水平 $\\alpha\\in(0,1)$ 下，检验原假设 $H_0:\\mu_d=0$ 与双边备择假设 $H_1:\\mu_d\\ne 0$。\n- 如果 $k2$ 或样本标准差 $s_d$ 为零，则定义 $p$ 值为 $1$ 并且不拒绝 $H_0$。\n- 否则，计算 $T=\\bar{d}/(s_d/\\sqrt{k})$，自由度为 $k-1$，以及 Student's $t$-distribution 的双边 $p$ 值 $p=2\\cdot\\mathrm{sf}(|T|)$，其中 $\\mathrm{sf}$ 是生存函数。当 $p\\alpha$ 时，决定不拒绝 $H_0$。\n\n您的程序必须实现上述流程，并为每个测试用例产生一个决策。\n\n测试套件和所需输出：\n- 使用以下四个测试用例，每个测试用例指定为一个元组 $(m,n,k,\\text{seed},\\alpha)$：\n  1. $(5,8,64,12345,0.05)$\n  2. $(5,8,1,7,0.05)$\n  3. $(3,2,256,0,0.05)$，由于 $k=2^{|X|}$，进行详尽枚举，种子被忽略。\n  4. $(6,10,100,2024,0.01)$\n- 对于 $k\\ne 2^{|X|}$ 的情况，使用给定的种子初始化伪随机数生成器，以抽样 $k$ 个函数 $f$ 作为指定的独立同分布的均匀标记。\n- 对于每个测试用例，所需的答案是一个布尔值，指示在水平 $\\alpha$ 下，平均性能差异是否与 $0$ 无显著差异，即如果不拒绝 $H_0$ 则返回 $\\text{True}$，否则返回 $\\text{False}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按上述顺序包含四个测试用例的布尔决策，例如，“[$\\text{True}$,$\\text{False}$,$\\text{True}$,$\\text{True}$]”。输出行中不允许有其他文本。", "solution": "该问题要求对监督学习的 No Free Lunch (NFL) 定理的一个核心原则进行实证验证。该定理指出，在有限域上的所有可能目标函数上取平均时，没有任何一种学习算法优于其他任何算法。我们将实施一个统计实验来检验这一原则，具体方法是比较两个特定的学习算法 $A_1$ 和 $A_2$，并对它们的性能差异进行假设检验。\n\n理论基础是有限输入空间 $X$ 上的监督学习的 NFL 定理。如果我们考虑在所有可能的目标函数 $f: X \\to \\{0,1\\}$ 集合上的均匀概率分布，那么对于任何学习算法，在未见点集 $U \\subset X$ 上的期望泛化准确率都是相同的。设 $\\mathcal{A}$ 为所有学习算法的空间， $S$ 为训练集。对于任意两个算法 $A_1, A_2 \\in \\mathcal{A}$，该定理意味着：\n$$\n\\mathbb{E}_{f \\sim \\text{Unif}}[\\text{Acc}_U(A_1(S, f|_S))] = \\mathbb{E}_{f \\sim \\text{Unif}}[\\text{Acc}_U(A_2(S, f|_S))]\n$$\n其中 $\\text{Acc}_U(h) = \\frac{1}{|U|} \\sum_{x \\in U} \\mathbf{1}\\{h(x) = f(x)\\}$ 是假设 $h$ 在未见集 $U$ 上的准确率。这直接导出了它们的准确率期望差异为零的结论：\n$$\n\\mu_d = \\mathbb{E}_{f \\sim \\text{Unif}}[\\text{Acc}_U(A_1) - \\text{Acc}_U(A_2)] = 0\n$$\n\n实验设计将此理论结果转化为一个统计原假设，$H_0: \\mu_d = 0$，我们将其与备择假设 $H_1: \\mu_d \\neq 0$ 进行检验。该实验由以下部分定义：\n1.  **输入空间**：域是所有固定长度为 $m$ 的二进制向量的集合，$X = \\{0,1\\}^m$。为便于计算，我们用字典序中的整数 $i \\in \\{0, 1, \\dots, 2^m-1\\}$ 来表示 $X$ 的元素。\n2.  **数据划分**：空间 $X$ 被划分为一个大小为 $n$ 的固定训练集 $S$（由字典序中的前 $n$ 个点组成）和一个未见集 $U = X \\setminus S$。\n3.  **任务生成**：一个任务由一个目标函数 $f: X \\to \\{0,1\\}$ 定义，表示为一个二进制向量 $y \\in \\{0,1\\}^{|X|}$。对于给定的任务数 $k$，我们生成 $k$ 个这样的函数。如果 $k$ 小于可能函数的总数 $2^{|X|}$，我们独立且均匀地抽样它们，这等价于从 $\\mathrm{Bernoulli}(1/2)$ 分布中抽取每个标签 $y_i$。如果 $k=2^{|X|}$，我们则对所有可能的函数进行详尽枚举。\n4.  **学习算法**：\n    -   **$A_1$ (1-Nearest Neighbor)**：对于任何点 $x \\in X$，该算法找到训练集 $S$ 中在 Hamming distance 下最接近 $x$ 的点 $x_s$。预测结果是该邻居的标签 $f(x_s)$。通过选择字典序最小的邻居来打破平局。\n    -   **$A_2$ (Empirical Majority)**：该算法确定训练集 $S$ 上的多数标签（0 或 1）。然后它为 $X$ 中的所有点预测这同一个标签。如果训练标签出现平局，它默认预测 $0$。\n\n对于 $k$ 个生成的任务中的每一个，我们都在训练数据 $(S, f|_S)$ 上训练两个算法，并计算它们各自在未见数据 $U$ 上的准确率 $a_1$ 和 $a_2$。任务 $t$ 的配对差异是 $d_t = a_{1,t} - a_{2,t}$。\n\n统计分析是针对 $k$ 个差异的样本 $\\{d_t\\}_{t=1}^k$ 进行的。我们使用配对 Student's $t$-test。检验统计量计算如下：\n$$\nT = \\frac{\\bar{d}}{s_d / \\sqrt{k}}\n$$\n其中 $\\bar{d}$ 是差异的样本均值，$s_d$ 是使用 Bessel's correction 的样本标准差（即分母为 $k-1$）。在原假设下，统计量 $T$ 服从自由度为 $k-1$ 的 Student's $t$-distribution。双边 $p$ 值计算为 $p = 2 \\cdot \\mathrm{sf}(|T|)$，其中 $\\mathrm{sf}$ 是 $t$-distribution 的生存函数。根据问题说明，如果 $k  2$ 或者 $s_d=0$，则 $p$ 值取为 $1$。如果得到的 $p$ 值大于指定的显著性水平 $\\alpha$，我们不拒绝原假设 $H_0$。\n\n实现过程首先为每个测试用例 $(m, n, k, \\text{seed}, \\alpha)$ 初始化参数。然后生成输入空间 $X$ 的二进制表示，并将其划分为 $S$ 和 $U$。一个循环迭代 $k$ 次，每次生成一个目标函数，训练两个学习器，评估它们在 $U$ 上的准确率，并计算差异。在收集所有 $k$ 个差异后，执行 $t$-test 以获得一个 $p$ 值，然后将其与 $\\alpha$ 进行比较，以决定是否拒绝原假设。最终输出是每个测试用例的布尔决策。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Implements the experimental pipeline to test the No Free Lunch theorem.\n    For each test case, it compares two learning algorithms by performing a\n    paired t-test on their performance difference over a set of synthetic tasks.\n    \"\"\"\n    test_cases = [\n        (5, 8, 64, 12345, 0.05),\n        (5, 8, 1, 7, 0.05),\n        (3, 2, 256, 0, 0.05),\n        (6, 10, 100, 2024, 0.01),\n    ]\n\n    results = []\n    for m, n, k, seed, alpha in test_cases:\n        num_X = 2**m\n        num_U = num_X - n\n\n        # Pre-compute binary representations for the input space X\n        X_bin = np.zeros((num_X, m), dtype=np.int8)\n        for i in range(num_X):\n            binary_repr = np.binary_repr(i, width=m)\n            X_bin[i] = np.array(list(binary_repr), dtype=np.int8)\n\n        S_bin = X_bin[:n]\n        U_bin = X_bin[n:]\n\n        differences = []\n\n        is_exhaustive = (k == 2**num_X)\n        if not is_exhaustive:\n            rng = np.random.default_rng(seed)\n\n        for task_idx in range(k):\n            # Step 1: Generate a target function y\n            if is_exhaustive:\n                # Exhaustive enumeration of all possible labelings\n                y_repr = np.binary_repr(task_idx, width=num_X)\n                y = np.array(list(y_repr), dtype=np.int8)\n            else:\n                # Random sampling of labelings\n                y = rng.integers(0, 2, size=num_X, dtype=np.int8)\n\n            y_train = y[:n]\n            y_unseen = y[n:]\n\n            # Step 2: Run Learner A1 (1-NN)\n            h1_unseen = np.zeros(num_U, dtype=np.int8)\n            for i in range(num_U):\n                # Calculate Hamming distances from the current unseen point to all training points\n                distances = np.sum(S_bin != U_bin[i], axis=1)\n                # Find the index of the nearest neighbor. np.argmin breaks ties by first occurrence.\n                best_s_idx = np.argmin(distances)\n                h1_unseen[i] = y_train[best_s_idx]\n\n            # Step 3: Run Learner A2 (Empirical Majority)\n            num_ones = np.sum(y_train)\n            if num_ones > n / 2:\n                h2_pred = 1\n            else:  # Handles both minority and tie cases, predicting 0\n                h2_pred = 0\n            h2_unseen = np.full(num_U, h2_pred, dtype=np.int8)\n\n            # Step 4: Compute accuracies and their difference\n            # check if num_U is zero to avoid division by zero\n            if num_U > 0:\n                acc1 = np.sum(h1_unseen == y_unseen) / num_U\n                acc2 = np.sum(h2_unseen == y_unseen) / num_U\n                diff = acc1 - acc2\n            else:\n                diff = 0.0\n\n            differences.append(diff)\n\n        # Step 5: Perform paired t-test\n        diff_arr = np.array(differences)\n        \n        # As per problem, if k  2, or s_d is 0, p-value is 1.\n        # np.std with ddof=1 produces NaN for k=1, so check k  2 first.\n        s_d = 0.0\n        if k >= 2:\n            s_d = np.std(diff_arr, ddof=1)\n\n        if k  2 or s_d == 0:\n            p_value = 1.0\n        else:\n            d_bar = np.mean(diff_arr)\n            t_stat = d_bar / (s_d / np.sqrt(k))\n            df = k - 1\n            # Two-sided p-value\n            p_value = 2 * t.sf(np.abs(t_stat), df)\n\n        # Step 6: Make decision\n        # Do not reject H0 if p > alpha\n        decision = p_value > alpha\n        results.append(decision)\n\n    # Format and print the final output\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3153410"}]}