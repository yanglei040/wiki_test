{"hands_on_practices": [{"introduction": "回归调整是控制混杂偏倚的常用方法，但其成功与否取决于一个关键假设：条件可忽略性（conditional ignorability）。本练习 [@problem_id:3106696] 提供了一系列受控的思想实验，旨在帮助你建立直观理解：何时该假设成立，何时又会因为存在未观测混杂因素或使用了不完美的代理变量而失效。通过辨析这些情景，你将能更深刻地理解为何我们需要发展更复杂的因果推断估计方法。", "problem": "考虑一个二元处理变量 $T \\in \\{0,1\\}$、一个观测到的协变量 $X$、一个可能未观测到的变量 $U$ 以及一个结果变量 $Y$。假设稳定单位处理价值假设 (SUTVA) 和一致性成立，因此对于每个单位，观测到的结果满足 $Y = Y(T)$，并将平均处理效应 (ATE) 定义为 $E\\big[Y(1) - Y(0)\\big]$。您将从条件独立性和全期望定律的定义出发，研究使用条件均值 $E[Y \\mid T, X]$ 进行回归调整是否足以识别 ATE。在以下所有情景中，假设误差项 $\\varepsilon$ 独立于 $(T,X,U)$，且 $E[\\varepsilon] = 0$ 并具有有限方差。\n\n对于每个情景，确定使用回归函数 $E[Y \\mid T, X]$ 是否足以识别 ATE，即使用 $E[Y \\mid T, X]$ 来求得 $E\\big[Y(1) - Y(0)\\big]$ 的条件是否成立。选择所有成立的情景。\n\n选项 A：\n- $X \\sim \\text{Bernoulli}(0.5)$，$T \\sim \\text{Bernoulli}(0.5)$，且 $T$ 独立于 $X$。\n- 结果由 $Y = 2T + X + \\varepsilon$ 生成。\n- 此情景中没有 $U$。\n\n选项 B：\n- $U \\sim \\text{Bernoulli}(0.5)$，$X \\sim \\text{Bernoulli}(0.5)$，且 $X$ 独立于 $U$。\n- 处理是确定性的 $T = U$。\n- 结果由 $Y = 2T + U + \\varepsilon$ 生成。\n\n选项 C：\n- $U \\sim \\text{Bernoulli}(0.5)$。\n- 观测到的协变量 $X$ 是 $U$ 的一个含噪声的代理变量：$P(X = U) = 0.8$ 且 $P(X \\neq U) = 0.2$。\n- 处理是确定性的 $T = U$。\n- 结果由 $Y = 2T + U + \\varepsilon$ 生成。\n\n选项 D：\n- $U \\sim \\text{Bernoulli}(0.5)$，且 $X = U$ (即，$X$ 等于 $U$ 且没有误差)。\n- 处理在以 $U$ 为条件下是随机化的，使得 $P(T = 1 \\mid U = 1) = 0.8$ 且 $P(T = 1 \\mid U = 0) = 0.2$。\n- 结果由 $Y = 2T + U + \\varepsilon$ 生成。\n\n在每个选项中，从基本定义（一致性/SUTVA、条件独立性和全期望定律）出发，论证 $E[Y \\mid T, X]$ 是否能识别 $E\\big[Y(1) - Y(0)\\big]$，以及何时因 $X$ 未能关闭所有后门路径而失败。选择所有正确的选项。\n\nA. 选项 A\n\nB. 选项 B\n\nC. 选项 C\n\nD. 选项 D", "solution": "问题要求确定在哪四个情景中，基于条件期望 $E[Y \\mid T, X]$ 的回归调整公式足以识别定义为 $E\\big[Y(1) - Y(0)\\big]$ 的平均处理效应 (ATE)。\n\n首先，让我们建立理论基础。问题说明我们可以假设 SUTVA 和一致性，这意味着 $Y = Y(T)$。ATE 是 $E[Y(1) - Y(0)]$。根据全期望定律，我们可以将 ATE 写成：\n$$ E\\big[Y(1) - Y(0)\\big] = E_X\\Big[E\\big[Y(1) \\mid X\\big] - E\\big[Y(0) \\mid X\\big]\\Big] $$\n回归调整估计量定义为：\n$$ \\tau_{adj} = E_X\\Big[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]\\Big] $$\n根据一致性，$E[Y \\mid T=1, X] = E[Y(1) \\mid T=1, X]$ 且 $E[Y \\mid T=0, X] = E[Y(0) \\mid T=0, X]$。\n为了使 $\\tau_{adj}$ 等于 ATE，我们需要条件可忽略性假设（也称为无混淆性或基于可观测变量的选择）成立：\n$$ \\big(Y(1), Y(0)\\big) \\perp T \\mid X $$\n这意味着，在给定协变量 $X$ 的条件下，处理分配 $T$ 独立于潜在结果。用因果图的语言来说，这等价于陈述协变量集 $X$ 阻断了从处理 $T$ 到结果 $Y$ 的所有后门路径。后门路径是 $T$ 和 $Y$ 之间的一条非因果路径，其上有一条指向 $T$ 的箭头。\n\n后门路径的一个常见来源是同时作为 $T$ 和 $Y$ 共同原因的变量 $U$（一个混淆变量）。路径 $T \\leftarrow U \\rightarrow Y$ 必须被阻断。如果 $U$ 是观测到的协变量 $X$ 的一部分，那么以 $X$为条件可以阻断这条路径。如果 $U$ 未被观测到，识别可能会失败。\n\n在所有情景中，结果的结构方程形式为 $Y = 2T + \\text{不含 } T \\text{ 的项} + \\varepsilon$。\n潜在结果是通过将 $T$ 设置为 $1$ 或 $0$ 得出的：\n- $Y(1) = 2(1) + \\dots + \\varepsilon$\n- $Y(0) = 2(0) + \\dots + \\varepsilon$\n任何单位的因果效应是 $Y(1) - Y(0) = 2$。\n因此，在所有四个情景中，真实的平均处理效应 (ATE) 是：\n$$ E\\big[Y(1) - Y(0)\\big] = E[2] = 2 $$\n因此，问题简化为检查在哪几个情景中，回归调整估计量 $\\tau_{adj}$ 等于 $2$。\n\n我们已知，在所有情景中，$E[\\varepsilon]=0$ 且 $\\varepsilon$ 独立于 $(T, X, U)$。\n\n### 选项 A\n\n- **设置**：$X \\sim \\text{Bernoulli}(0.5)$，$T \\sim \\text{Bernoulli}(0.5)$，$T \\perp X$。$Y = 2T + X + \\varepsilon$。此情景中没有未观测到的混淆变量 $U$。\n- **分析**：\n潜在结果是 $Y(1) = 2 + X + \\varepsilon$ 和 $Y(0) = X + \\varepsilon$。\n条件可忽略性假设是 $(Y(1), Y(0)) \\perp T \\mid X$。潜在结果是 $X$ 和 $\\varepsilon$ 的函数。我们已知 $T$ 独立于 $X$。我们还已知 $\\varepsilon$ 独立于 $(T, X, U)$，这意味着 $\\varepsilon \\perp T$。由于 $T$ 同时独立于 $X$ 和 $\\varepsilon$，它也独立于任何 $(X, \\varepsilon)$ 的函数。因此，$T \\perp (Y(1), Y(0))$。无条件独立性意味着给定 $X$ 的条件独立性。所以，该条件成立。从 $T$ 到 $Y$ 没有后门路径。这是一个随机对照试验。\n我们来计算这个估计量：\n$$ E[Y \\mid T, X] = E[2T + X + \\varepsilon \\mid T, X] = 2T + X + E[\\varepsilon \\mid T, X] $$\n由于 $\\varepsilon$ 独立于 $(T,X)$，$E[\\varepsilon \\mid T, X] = E[\\varepsilon]=0$。所以，$E[Y \\mid T, X] = 2T + X$。\n回归調整估计量是：\n$$ \\tau_{adj} = E_X\\Big[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]\\Big] = E_X\\Big[ (2(1) + X) - (2(0) + X) \\Big] = E_X[2] = 2 $$\n- **结论**：由于 $\\tau_{adj} = 2$，即真实的 ATE，回归调整足以识别 ATE。**正确**。\n\n### 选项 B\n\n- **设置**：$U \\sim \\text{Bernoulli}(0.5)$，$X \\sim \\text{Bernoulli}(0.5)$，$X \\perp U$。处理是 $T = U$。结果是 $Y = 2T + U + \\varepsilon$。\n- **分析**：\n这里，$U$ 是 $T$ (因为 $T=U$) 和 $Y$ (因为 $U$ 在 $Y$ 的结构方程中) 的共同原因。这产生了一条后门路径 $T \\leftarrow U \\rightarrow Y$。由于 $U$ 未被观测，这条路径可能是开放的。观测到的协变量 $X$ 独立于 $U$，因此以 $X$ 为条件无法阻断该路径。\n潜在结果是 $Y(t) = 2t + U + \\varepsilon$。我们需要检查是否 $(Y(1), Y(0)) \\perp T \\mid X$。这等价于检查是否 $U \\perp T \\mid X$。但 $T=U$，所以我们是在检查是否 $U \\perp U \\mid X$。这显然是错误的。条件可忽略性不成立。\n我们来计算这个估计量。首先，将 $T=U$ 代入观测数据的结果方程：$Y = 2T + T + \\varepsilon = 3T + \\varepsilon$。\n$$ E[Y \\mid T, X] = E[3T + \\varepsilon \\mid T, X] = 3T + E[\\varepsilon \\mid T, X] = 3T $$\n回归调整估计量是：\n$$ \\tau_{adj} = E_X\\Big[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]\\Big] = E_X\\big[3(1) - 3(0)\\big] = E_X[3] = 3 $$\n- **结论**：估计量 $\\tau_{adj} = 3$ 不等于真实的 ATE $2$。差异是由于未观测变量 $U$ 造成的混淆。**错误**。\n\n### 选项 C\n\n- **设置**：$U \\sim \\text{Bernoulli}(0.5)$，$X$ 是 $U$ 的一个含噪声的代理变量，满足 $P(X=U)=0.8$。处理是 $T = U$。结果是 $Y = 2T + U + \\varepsilon$。\n- **分析**：\n与选项 B 类似，$U$ 是一个混淆变量，产生了后门路径 $T \\leftarrow U \\rightarrow Y$。在这里，我们观测到 $U$ 的一个代理变量 $X$。因果结构是 $U \\rightarrow X$ 和 $T \\leftarrow U \\rightarrow Y$。以混淆变量的子节点 $X$ 为条件，并不能阻断后门路径。条件 $U \\perp T \\mid X$ 不成立，因为知道 $X$ 提供了关于 $U$ 的信息，但并不能使 $U$ 独立于 $T=U$。\n我们来计算这个估计量。与选项 B 一样，观测到的结果是 $Y = 3T+\\varepsilon$。\n$$ E[Y \\mid T, X] = E[3T + \\varepsilon \\mid T, X] = 3T + E[\\varepsilon \\mid T, X] = 3T $$\n计算过程与选项 B 相同，因为一旦给定 $T$，$U$ 也就已知了 ($U=T$)，所以任何来自 $X$ 关于 $U$ 的额外信息对于计算 $U$ 的条件期望而言都变得冗余。\n回归调整估计量是：\n$$ \\tau_{adj} = E_X\\Big[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]\\Big] = E_X\\big[3 - 0\\big] = 3 $$\n- **结论**：估计量 $\\tau_{adj} = 3$ 不等于真实的 ATE $2$。这是一个由不完美代理变量导致的残留混淆的典型案例。**错误**。\n\n### 选项 D\n\n- **设置**：$U \\sim \\text{Bernoulli}(0.5)$，$X = U$。处理 $T$ 在以 $U$ 为条件下是随机化的：$P(T=1|U=1)=0.8, P(T=1|U=0)=0.2$。结果是 $Y = 2T + U + \\varepsilon$。\n- **分析**：\n同样地，$U$ 是 $T$ 和 $Y$ 的共同原因，因此存在后门路径 $T \\leftarrow U \\rightarrow Y$。然而，在这种情景下，混淆变量 $U$ 通过 $X=U$被完美地观测到。通过以 $X$ 为条件，我们实际上是在以混淆变量本身为条件，这就阻断了后门路径。\n我们来正式检查条件可忽略性假设：$(Y(1), Y(0)) \\perp T \\mid X$。潜在结果是 $Y(t) = 2t + U + \\varepsilon$。因为它们是 $U$ 和 $\\varepsilon$ 的函数，我们必须检查是否 $(U, \\varepsilon) \\perp T \\mid X$。给定 $X=U$，这变成 $(U, \\varepsilon) \\perp T \\mid U$。一个变量总是依赖于其自身，但当我们以它为条件时，它的值是固定的。所以我们只需要检查是否 $\\varepsilon \\perp T \\mid U$。我们已知 $\\varepsilon$ 独立于 $(T,X,U)$ 的联合分布，这意味着 $\\varepsilon \\perp T \\mid U$。因此，条件可忽略性成立。\n我们来计算这个估计量：\n$$ E[Y \\mid T, X] = E[2T + U + \\varepsilon \\mid T, X] $$\n因为 $X=U$，这等价于：\n$$ E[Y \\mid T, X] = E[2T + X + \\varepsilon \\mid T, X] = 2T + X + E[\\varepsilon \\mid T,X] = 2T + X $$\n回归调整估计量是：\n$$ \\tau_{adj} = E_X\\Big[E[Y \\mid T=1, X] - E[Y \\mid T=0, X]\\Big] = E_X\\Big[ (2(1) + X) - (2(0) + X) \\Big] = E_X[2] = 2 $$\n- **结论**：由于 $\\tau_{adj} = 2$，即真实的 ATE，回归调整足以识别 ATE。这个情景代表了通过将混淆变量包含在回归模型中来成功控制混淆。**正确**。\n\n使用回归函数 $E[Y \\mid T, X]$ 足以识别 ATE 的情景是 A 和 D。", "answer": "$$\\boxed{AD}$$", "id": "3106696"}, {"introduction": "当我们认识到简单的回归调整可能因模型设定错误而失败时，一个更强大的工具——增强逆概率加权（Augmented Inverse Probability Weighted, AIPW）估计量便应运而生。本练习 [@problem_id:3106777] 将通过模拟向你展示其强大的“双重稳健性”（double robustness）特性：只要两个“滋扰模型”（结果模型或倾向性得分模型）中有一个被正确设定，AIPW 估计量就能保持一致性。亲手实现这个过程，你将体会到这一特性在实际数据分析中如何为我们提供关键的“安全网”。", "problem": "考虑一个二元处理设定，其包含潜在结果 $Y(1)$ 和 $Y(0)$、一个观测到的协变量 $X \\in \\mathbb{R}$、一个处理指标 $T \\in \\{0,1\\}$ 以及一个观测到的结果 $Y \\in \\mathbb{R}$。假设遵循以下基本原则：一致性 $Y = T Y(1) + (1 - T) Y(0)$、条件可忽略性 $(Y(1), Y(0)) \\perp T \\mid X$ 和正值性，即对于所有实现值 $x$，都有 $0  \\mathbb{P}(T = 1 \\mid X = x)  1$。目标参数是平均处理效应 (ATE)，定义为 $\\Delta = \\mathbb{E}[Y(1) - Y(0)]$。\n\n您将研究在两种统计学习模型下的增广逆概率加权 (AIPW) 估计量：\n- 一个结果回归模型 $m_t(x) \\approx \\mathbb{E}[Y \\mid T = t, X = x]$，其中 $t \\in \\{0,1\\}$。\n- 一个倾向得分模型 $e(x) \\approx \\mathbb{P}(T = 1 \\mid X = x)$。\n\n请构建一个例子，其中结果回归模型被正确设定而倾向得分模型被错误设定，并通过经验证明增广逆概率加权 (AIPW) 估计量的双重稳健性。双重稳健性指的是，如果结果回归模型或倾向得分模型中有一个被正确设定（不一定两者都正确），则该估计量是一致的。\n\n模拟的数据生成过程：\n- 协变量：$X \\sim \\mathcal{N}(0,1)$。\n- 处理分配：$T \\mid X \\sim \\text{Bernoulli}(e^\\star(X))$，其中 $e^\\star(x) = \\frac{1}{1 + \\exp(-(\\alpha x + c))}$ 是参数为 $\\alpha$ 和 $c$ 的逻辑斯谛函数。\n- 结果：$Y = \\beta_0 + \\beta_1 X + \\tau T + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$，并且在给定 $X$ 和 $T$ 的条件下独立于 $X$ 和 $T$。真实的平均处理效应是一个常数，等于 $\\tau$。\n\n估计中要使用的模型设定：\n- 正确的结果回归模型：将 $Y$ 回归到一个截距项、$T$ 和 $X$ 上；然后使用这个线性模型，将 $m_1(x)$ 和 $m_0(x)$ 分别设定为在 $T = 1$ 和 $T = 0$ 条件下的拟合条件均值。\n- 错误设定的结果回归模型：将 $Y$ 仅回归到一个截距项和 $T$ 上（省略 $X$）。\n- 正确的倾向得分模型：使用真实的函数 $e^\\star(x) = \\frac{1}{1 + \\exp(-(\\alpha x + c))}$，并带有数据生成过程中的已知参数 $\\alpha$ 和 $c$。\n- 错误设定的倾向得分模型：使用常数函数 $e(x) = 0.5$。\n\n根据上述基本原则和定义，推导 $\\Delta$ 的 AIPW 估计量并实现它。对于一个样本 $\\{(X_i,T_i,Y_i)\\}_{i=1}^n$，使用估计出的 $m_1(X_i)$、$m_0(X_i)$ 和 $e(X_i)$，计算 $\\Delta$ 的 AIPW 估计值，并报告其相对于真实 $\\tau$ 的偏差。\n\n测试套件：\n对于每个测试，根据指定参数模拟数据，按规定拟合模型，计算 AIPW 估计值 $\\widehat{\\Delta}_{\\text{AIPW}}$，并报告偏差 $\\widehat{\\Delta}_{\\text{AIPW}} - \\tau$，结果为浮点数，四舍五入到 $6$ 位小数。\n\n- 测试 $1$ (双重稳健性，结果模型正确，倾向得分模型错误，顺利情况): $n = 50000$, $\\beta_0 = 2.0$, $\\beta_1 = 1.0$, $\\tau = 3.0$, $\\sigma = 1.0$, $\\alpha = 1.2$, $c = -0.2$, 结果回归模型正确, 倾向得分模型错误, 随机种子 $123$.\n- 测试 $2$ (双重稳健性，倾向得分模型正确，结果模型错误): $n = 50000$, $\\beta_0 = 2.0$, $\\beta_1 = 1.0$, $\\tau = 3.0$, $\\sigma = 1.0$, $\\alpha = 1.2$, $c = -0.2$, 结果回归模型错误, 倾向得分模型正确, 随机种子 $456$.\n- 测试 $3$ (两个模型均错误设定): $n = 50000$, $\\beta_0 = 2.0$, $\\beta_1 = 1.0$, $\\tau = 3.0$, $\\sigma = 1.0$, $\\alpha = 1.2$, $c = -0.2$, 结果回归模型错误, 倾向得分模型错误, 随机种子 $789$.\n- 测试 $4$ (两个模型均正确设定): $n = 50000$, $\\beta_0 = 2.0$, $\\beta_1 = 1.0$, $\\tau = 3.0$, $\\sigma = 1.0$, $\\alpha = 1.2$, $c = -0.2$, 结果回归模型正确, 倾向得分模型正确, 随机种子 $321$.\n- 测试 $5$ (边缘情况，接近正值性边界但有效，双重稳健性，结果模型正确，倾向得分模型错误): $n = 50000$, $\\beta_0 = 2.0$, $\\beta_1 = 1.0$, $\\tau = 3.0$, $\\sigma = 1.0$, $\\alpha = 4.0$, $c = 0.0$, 结果回归模型正确, 倾向得分模型错误, 随机种子 $654$.\n\n最终输出格式：\n您的程序应产生单行输出，其中包含五个偏差值，形式为方括号内以逗号分隔的列表 (例如, $[b_1,b_2,b_3,b_4,b_5]$)，其中每个 $b_j$ 是测试 $j$ 的偏差，四舍五入到 $6$ 位小数。不应打印其他任何文本。", "solution": "首先，我们推导平均处理效应 (ATE) $\\Delta = \\mathbb{E}[Y(1) - Y(0)]$ 的增广逆概率加权 (AIPW) 估计量。AIPW 估计量具有双重稳健性，这意味着只要倾向得分模型或结果模型中有一个被正确设定，它就是一致的。\n\nAIPW 估计量基于以下影响函数 (influence function) 的思想。对于潜在结果均值 $\\mu_1 = \\mathbb{E}[Y(1)]$ 的估计，其分量为：\n$$ \\psi_1(X, T, Y; m_1, e) = \\frac{T(Y - m_1(X))}{e(X)} + m_1(X) $$\n其中，$m_1(X)$ 是结果回归模型 $\\mathbb{E}[Y \\mid T=1, X]$ 的估计，$e(X)$ 是倾向得分模型 $\\mathbb{P}(T=1 \\mid X)$ 的估计。可以证明，如果 $e(X)$ 或 $m_1(X)$ 中至少有一个是真实模型的无偏估计，那么 $\\mathbb{E}[\\psi_1] = \\mu_1$。\n\n类似地，对于 $\\mu_0 = \\mathbb{E}[Y(0)]$ 的估计，其分量为：\n$$ \\psi_0(X, T, Y; m_0, e) = \\frac{(1-T)(Y - m_0(X))}{1-e(X)} + m_0(X) $$\n\n因此，对于一个包含 $n$ 个观测值的样本 $\\{(X_i, T_i, Y_i)\\}_{i=1}^n$，ATE 的 AIPW 估计量为：\n$$ \\widehat{\\Delta}_{\\text{AIPW}} = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\psi_1(X_i, T_i, Y_i; \\hat{m}_1, \\hat{e}) - \\psi_0(X_i, T_i, Y_i; \\hat{m}_0, \\hat{e}) \\right] $$\n$$ = \\frac{1}{n} \\sum_{i=1}^n \\left[ \\left(\\frac{T_i(Y_i - \\hat{m}_1(X_i))}{\\hat{e}(X_i)} + \\hat{m}_1(X_i)\\right) - \\left(\\frac{(1-T_i)(Y_i - \\hat{m}_0(X_i))}{1-\\hat{e}(X_i)} + \\hat{m}_0(X_i)\\right) \\right] $$\n\n接下来，我们根据问题描述实现模拟。\n**数据生成过程 (DGP)**:\n-   $X \\sim \\mathcal{N}(0,1)$\n-   $T \\mid X \\sim \\text{Bernoulli}(\\operatorname{logit}^{-1}(\\alpha x + c))$\n-   $Y = \\beta_0 + \\beta_1 X + \\tau T + \\varepsilon$, 其中 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^2)$。真实 ATE 为 $\\tau$。\n\n**模型设定**:\n1.  **正确的结果模型**: 通过对 $Y$ 关于截距项、$T$ 和 $X$ 进行线性回归来估计 $\\hat{m}_1(X)$ 和 $\\hat{m}_0(X)$。这与 DGP 的线性形式匹配。\n2.  **错误的结果模型**: 通过对 $Y$ 关于截距项和 $T$ 进行线性回归来估计，忽略了混杂因素 $X$。\n3.  **正确的倾向得分模型**: 使用真实的逻辑斯谛函数形式及已知的参数 $\\alpha$ 和 $c$ 来计算 $\\hat{e}(X)$。\n4.  **错误的倾向得分模型**: 将倾向得分设定为常数 $\\hat{e}(X) = 0.5$。\n\n我们对五个测试用例分别应用这些设定：\n-   **测试 1**: 结果模型正确，倾向得分模型错误。双重稳健性应保证估计无偏。\n-   **测试 2**: 结果模型错误，倾向得分模型正确。双重稳健性应保证估计无偏。\n-   **测试 3**: 两个模型均错误。我们预期估计量会有显著偏差。\n-   **测试 4**: 两个模型均正确。估计量应无偏。\n-   **测试 5**: 结果模型正确，倾向得分模型错误，且倾向得分接近 0 或 1。双重稳健性仍应保证估计无偏，尽管方差可能更大。\n\n计算每个测试用例的 AIPW 估计值 $\\widehat{\\Delta}_{\\text{AIPW}}$，并减去真实 ATE $\\tau$ 得到偏差。", "answer": "```python\nimport numpy as np\n\ndef simulate_data(n, beta0, beta1, tau, sigma, alpha, c, seed):\n    \"\"\"\n    Simulates data according to the specified data generating process.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # Generate covariate X from a standard normal distribution\n    X = rng.normal(0, 1, n)\n    \n    # Calculate true propensity scores e*(X)\n    logit_e_star = alpha * X + c\n    e_star = 1 / (1 + np.exp(-logit_e_star))\n    \n    # Generate treatment assignment T from a Bernoulli distribution\n    T = rng.binomial(1, e_star, n)\n    \n    # Generate outcome Y\n    epsilon = rng.normal(0, sigma, n)\n    Y = beta0 + beta1 * X + tau * T + epsilon\n    \n    return X, T, Y\n\ndef fit_outcome_regression(X, T, Y, is_correct):\n    \"\"\"\n    Fits the outcome regression model (correctly or misspecified) and returns\n    predicted outcomes for T=0 and T=1.\n    \"\"\"\n    n = len(Y)\n    if is_correct:\n        # Correct specification: Y ~ intercept + T + X\n        A = np.vstack([np.ones(n), T, X]).T\n        # Solve Normal Equations (A'A)beta = A'Y for OLS coefficients\n        try:\n            coeffs = np.linalg.solve(A.T @ A, A.T @ Y)\n        except np.linalg.LinAlgError:\n            coeffs = np.linalg.pinv(A.T @ A) @ A.T @ Y\n            \n        b0_hat, bT_hat, bX_hat = coeffs\n        \n        # Predicted outcomes under T=1 and T=0\n        m1_hat = b0_hat + bT_hat * 1 + bX_hat * X\n        m0_hat = b0_hat + bT_hat * 0 + bX_hat * X\n    else:\n        # Misspecified: Y ~ intercept + T (omits confounder X)\n        A = np.vstack([np.ones(n), T]).T\n        try:\n            coeffs = np.linalg.solve(A.T @ A, A.T @ Y)\n        except np.linalg.LinAlgError:\n            coeffs = np.linalg.pinv(A.T @ A) @ A.T @ Y\n\n        b0_hat, bT_hat = coeffs\n        \n        # Predicted outcomes are constant with respect to X\n        m1_hat = np.full(n, b0_hat + bT_hat * 1)\n        m0_hat = np.full(n, b0_hat + bT_hat * 0)\n        \n    return m0_hat, m1_hat\n\ndef get_propensity_scores(X, is_correct, alpha, c):\n    \"\"\"\n    Returns the propensity scores (correctly or misspecified).\n    \"\"\"\n    if is_correct:\n        # Use the true propensity score function with true parameters\n        logit_e = alpha * X + c\n        e_hat = 1 / (1 + np.exp(-logit_e))\n    else:\n        # Misspecified as a constant\n        e_hat = np.full(len(X), 0.5)\n        \n    return e_hat\n\ndef calculate_aipw_estimate(T, Y, m0_hat, m1_hat, e_hat):\n    \"\"\"\n    Calculates the AIPW estimate of the Average Treatment Effect (ATE).\n    \"\"\"\n    # Component for E[Y(1)]\n    psi1 = (T * (Y - m1_hat)) / e_hat + m1_hat\n    \n    # Component for E[Y(0)]\n    psi0 = ((1 - T) * (Y - m0_hat)) / (1 - e_hat) + m0_hat\n    \n    # AIPW estimate is the sample average of the difference\n    aipw_est = np.mean(psi1 - psi0)\n    \n    return aipw_est\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (n, beta0, beta1, tau, sigma, alpha, c, outcome_correct, propensity_correct, seed)\n        (50000, 2.0, 1.0, 3.0, 1.0, 1.2, -0.2, True, False, 123), # Test 1\n        (50000, 2.0, 1.0, 3.0, 1.0, 1.2, -0.2, False, True, 456), # Test 2\n        (50000, 2.0, 1.0, 3.0, 1.0, 1.2, -0.2, False, False, 789), # Test 3\n        (50000, 2.0, 1.0, 3.0, 1.0, 1.2, -0.2, True, True, 321), # Test 4\n        (50000, 2.0, 1.0, 3.0, 1.0, 4.0, 0.0, True, False, 654), # Test 5\n    ]\n    \n    results = []\n    \n    for case in test_cases:\n        n, beta0, beta1, tau, sigma, alpha, c, outcome_correct, propensity_correct, seed = case\n        \n        # 1. Simulate data from the DGP\n        X, T, Y = simulate_data(n, beta0, beta1, tau, sigma, alpha, c, seed)\n        \n        # 2. Estimate nuisance functions based on test case specification\n        m0_hat, m1_hat = fit_outcome_regression(X, T, Y, outcome_correct)\n        e_hat = get_propensity_scores(X, propensity_correct, alpha, c)\n        \n        # 3. Calculate the AIPW estimate of the ATE\n        aipw_estimate = calculate_aipw_estimate(T, Y, m0_hat, m1_hat, e_hat)\n        \n        # 4. Calculate and store the bias\n        bias = aipw_estimate - tau\n        results.append(f\"{bias:.6f}\")\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3106777"}, {"introduction": "在估计了平均处理效应（Average Treatment Effect, ATE）之后，一个自然而然的进阶问题是：处理究竟是*如何*产生效果的？本练习 [@problem_id:3106705] 引入了中介分析（mediation analysis），并使用 G-computation 公式（G-formula）将总效应分解为直接效应和通过中介变量产生的间接效应。通过解决一个包含中间混杂因素（intermediate confounder）的复杂情景，你将学会如何应用 G-formula 来回答关于因果机制的更精细问题。", "problem": "考虑一个结构因果模型 (SCM)，其特征由以下随机变量定义：$X$（基线协变量）、$T$（在时间 $t_0$ 的二元处理）、$L$（在处理后、时间 $t_1$ 测量的中间混杂因素）、$M$（在时间 $t_2$ 测量的中介变量）和 $Y$（在时间 $t_3$ 的结果）。处理 $T$ 是通过观察分配的，并受到 $X$ 的混杂影响。中介变量 $M$ 和结果 $Y$ 都受到 $X$ 的影响，并且存在通过 $L$ 的中间混雜，$L$ 受 $T$ 和 $X$ 的影响，反过来又影响 $M$ 和 $Y$。假设数据生成过程如下，具有线性高斯结构方程和logistic处理分配：\n$$\nX \\sim \\mathcal{N}(\\mu_X, \\sigma_X^2),\n$$\n$$\n\\Pr(T = 1 \\mid X) = \\operatorname{logit}^{-1}(\\eta_0 + \\eta_1 X),\n$$\n$$\nL \\mid T, X \\sim \\mathcal{N}(\\alpha_0 + \\alpha_1 T + \\alpha_2 X, \\sigma_L^2),\n$$\n$$\nM \\mid T, X, L \\sim \\mathcal{N}(\\beta_0 + \\beta_1 T + \\beta_2 X + \\beta_3 L, \\sigma_M^2),\n$$\n$$\nY \\mid T, M, X, L \\sim \\mathcal{N}(\\gamma_0 + \\gamma_1 T + \\gamma_2 M + \\gamma_3 X + \\gamma_4 L, \\sigma_Y^2).\n$$\n目标是使用 g-计算公式 (G-formula) 来识别干预下的因果估计量。定义 do-算子干预如下：\n- 静态处理干预 $\\operatorname{do}(T = t)$，将 $T$ 设置为 $t \\in \\{0, 1\\}$。\n- 随机中介干预，在以 $X$ 和 $L$ 为条件下，从 $M$ 在 $\\operatorname{do}(T = t')$ (其中 $t' \\in \\{0, 1\\}$) 下应有的分布中抽取 $M$，同时保持 $L$ 在 $\\operatorname{do}(T = t)$ 下生成。\n\n在这些干预下，定义干预均值\n$$\n\\mathbb{E}[Y(t, t')] = \\mathbb{E}_X \\left[ \\mathbb{E}_{L \\mid \\operatorname{do}(T=t), X} \\left[ \\mathbb{E}_{M \\mid \\operatorname{do}(T=t'), X, L} \\left[ \\mathbb{E}[Y \\mid \\operatorname{do}(T=t), M, X, L] \\right] \\right] \\right],\n$$\n其中 $\\mathbb{E}[\\cdot]$ 表示期望，嵌套期望是相对于 SCM 所蕴含的相应干预分布计算的。\n\n任务：\n1. 仅从 SCM、do-算子的定义和 g-计算公式 (G-formula) 出发，推导在 $\\operatorname{do}(T = t)$ 干预下 $\\mathbb{E}[Y(t)]$ 的闭式表达式，以及在组合干预下 $\\mathbb{E}[Y(t, t')]$ 的闭式表达式，其中 $T$ 被设为 $t$，$M$ 从其在 $\\operatorname{do}(T = t')$ 下应有的分布中抽取，而 $L$ 则在 $\\operatorname{do}(T = t)$ 下生成。\n2. 使用这些闭式表达式，考虑以下干预效应：\n   - 平均处理效应 (ATE): $\\mathbb{E}[Y(1, 1)] - \\mathbb{E}[Y(0, 0)]$。\n   - 干预直接效应 (IDE): $\\mathbb{E}[Y(1, 0)] - \\mathbb{E}[Y(0, 0)]$。\n   - 干预间接效应 (IIE): $\\mathbb{E}[Y(1, 1)] - \\mathbb{E}[Y(1, 0)]$。\n   证明对于此 SCM，$\\text{ATE} = \\text{IDE} + \\text{IIE}$ 成立。\n3. 实现一个程序，对于每个指定的参数集，使用推导出的闭式表达式计算包含五个浮点数的列表\n   $$\n   \\left[\\mathbb{E}[Y(1, 1)],\\ \\mathbb{E}[Y(0, 0)],\\ \\text{IDE},\\ \\text{IIE},\\ \\text{ATE}\\right]\n   $$\n   。\n\n使用以下参数值测试套件（注意：方差 $\\sigma_X^2$, $\\sigma_L^2$, $\\sigma_M^2$, $\\sigma_Y^2$ 和处理分配参数 $\\eta_0$, $\\eta_1$ 在此线性高斯设置中不影响干预均值，包含它们仅为保证科学上的完整性）：\n- 测试用例 1 (一般情况，存在基线混杂)：\n  $\n  \\mu_X = 0.5,\\ \n  \\alpha_0 = 0.1,\\ \\alpha_1 = 0.8,\\ \\alpha_2 = 0.3,\\\n  \\beta_0 = 0.2,\\ \\beta_1 = 0.9,\\ \\beta_2 = 0.4,\\ \\beta_3 = 0.5,\\\n  \\gamma_0 = 0.0,\\ \\gamma_1 = 0.3,\\ \\gamma_2 = 1.2,\\ \\gamma_3 = 0.6,\\ \\gamma_4 = 0.7.\n  $\n- 测试用例 2 (中介变量对结果没有影响)：\n  $\n  \\mu_X = -0.2,\\ \n  \\alpha_0 = 0.0,\\ \\alpha_1 = 0.5,\\ \\alpha_2 = 0.2,\\\n  \\beta_0 = 0.1,\\ \\beta_1 = 0.7,\\ \\beta_2 = 0.3,\\ \\beta_3 = 0.6,\\\n  \\gamma_0 = 0.0,\\ \\gamma_1 = 0.4,\\ \\gamma_2 = 0.0,\\ \\gamma_3 = 0.5,\\ \\gamma_4 = 0.6.\n  $\n- 测试用例 3 (处理对结果没有直接影响，但存在强的中间混杂和中介效应)：\n  $\n  \\mu_X = 1.0,\\ \n  \\alpha_0 = 0.2,\\ \\alpha_1 = 1.0,\\ \\alpha_2 = 0.1,\\\n  \\beta_0 = 0.0,\\ \\beta_1 = 1.0,\\ \\beta_2 = 0.5,\\ \\beta_3 = 0.8,\\\n  \\gamma_0 = 0.0,\\ \\gamma_1 = 0.0,\\ \\gamma_2 = 1.0,\\ \\gamma_3 = 0.3,\\ \\gamma_4 = 0.9.\n  $\n- 测试用例 4 (边缘情况，$M$ 和 $Y$ 中不存在基线混杂)：\n  $\n  \\mu_X = 0.0,\\ \n  \\alpha_0 = 0.3,\\ \\alpha_1 = 0.2,\\ \\alpha_2 = 0.0,\\\n  \\beta_0 = 0.5,\\ \\beta_1 = 0.5,\\ \\beta_2 = 0.0,\\ \\beta_3 = 0.4,\\\n  \\gamma_0 = 0.0,\\ \\gamma_1 = 0.2,\\ \\gamma_2 = 0.8,\\ \\gamma_3 = 0.0,\\ \\gamma_4 = 0.3.\n  $\n\n您的程序应生成单行输出，按顺序包含每个测试用例的五个浮点数列表\n$\n\\left[\\mathbb{E}[Y(1, 1)],\\ \\mathbb{E}[Y(0, 0)],\\ \\text{IDE},\\ \\text{IIE},\\ \\text{ATE}\\right]\n$\n，并将这些按测试用例分的列表聚合为一个逗号分隔的列表，并用方括号括起来。例如，输出应如下所示\n$\n\\big[\\,[\\cdots],\\,[\\cdots],\\,[\\cdots],\\,[\\cdots]\\,\\big]\n$\n，不含任何额外文本。", "solution": "本题要求使用 g-计算公式 (G-formula) 对给定的结构因果模型 (SCM) 进行因果效应的识别与分解。我们将首先推导干预均值 $\\mathbb{E}[Y(t, t')]$ 的闭式表达式，然后用它来计算总效应 (ATE)、直接效应 (IDE) 和间接效应 (IIE)。\n\n**1. 干预均值的推导**\n\n干预均值定义为：\n$$ \\mathbb{E}[Y(t, t')] = \\mathbb{E}_X \\left[ \\mathbb{E}_{L \\mid \\operatorname{do}(T=t), X} \\left[ \\mathbb{E}_{M \\mid \\operatorname{do}(T=t'), X, L} \\left[ \\mathbb{E}[Y \\mid \\operatorname{do}(T=t), M, X, L] \\right] \\right] \\right] $$\n\n我们根据 SCM 从内向外逐步求解这个嵌套期望。\n\n- **最内层期望 (对 Y):**\n  在干预 $\\operatorname{do}(T=t)$ 下，$T$ 被固定为 $t$。$Y$ 的条件期望为：\n  $$ \\mathbb{E}[Y \\mid \\operatorname{do}(T=t), M, X, L] = \\gamma_0 + \\gamma_1 t + \\gamma_2 M + \\gamma_3 X + \\gamma_4 L $$\n\n- **第二层期望 (对 M):**\n  在干预 $\\operatorname{do}(T=t')$ 下，$M$ 的条件期望为 $\\mathbb{E}[M \\mid \\operatorname{do}(T=t'), X, L] = \\beta_0 + \\beta_1 t' + \\beta_2 X + \\beta_3 L$。将其代入上式：\n  $$ \\mathbb{E}_{M}[\\dots] = \\gamma_0 + \\gamma_1 t + \\gamma_2 (\\beta_0 + \\beta_1 t' + \\beta_2 X + \\beta_3 L) + \\gamma_3 X + \\gamma_4 L $$\n\n- **第三层期望 (对 L):**\n  在干预 $\\operatorname{do}(T=t)$ 下，$L$ 的条件期望为 $\\mathbb{E}[L \\mid \\operatorname{do}(T=t), X] = \\alpha_0 + \\alpha_1 t + \\alpha_2 X$。将其代入上式：\n  $$ \\mathbb{E}_{L, M}[\\dots] = \\gamma_0 + \\gamma_1 t + \\gamma_2 (\\beta_0 + \\beta_1 t' + \\beta_2 X + \\beta_3 (\\alpha_0 + \\alpha_1 t + \\alpha_2 X)) + \\gamma_3 X + \\gamma_4 (\\alpha_0 + \\alpha_1 t + \\alpha_2 X) $$\n\n- **最外层期望 (对 X):**\n  最后，对整个表达式关于 $X$ 的分布求期望，并代入 $\\mathbb{E}[X] = \\mu_X$。整理后得到 $\\mathbb{E}[Y(t, t')]$ 的闭式表达式，其形式为 $C_0 + C_1 t + C_2 t'$，其中：\n  $$ C_0 = (\\gamma_0 + \\gamma_2 \\beta_0 + \\alpha_0(\\gamma_4 + \\gamma_2 \\beta_3)) + \\mu_X(\\gamma_3 + \\gamma_2 \\beta_2 + \\alpha_2(\\gamma_4 + \\gamma_2 \\beta_3)) $$\n  $$ C_1 = \\gamma_1 + \\alpha_1(\\gamma_4 + \\gamma_2 \\beta_3) $$\n  $$ C_2 = \\gamma_2 \\beta_1 $$\n\n**2. 因果效应的计算**\n\n根据效应的定义，我们可以直接使用上面推导出的系数：\n- **干预直接效应 (IDE):**\n  $ \\text{IDE} = \\mathbb{E}[Y(1, 0)] - \\mathbb{E}[Y(0, 0)] = (C_0 + C_1) - C_0 = C_1 $\n\n- **干预间接效应 (IIE):**\n  $ \\text{IIE} = \\mathbb{E}[Y(1, 1)] - \\mathbb{E}[Y(1, 0)] = (C_0 + C_1 + C_2) - (C_0 + C_1) = C_2 $\n\n- **平均处理效应 (ATE):**\n  $ \\text{ATE} = \\mathbb{E}[Y(1, 1)] - \\mathbb{E}[Y(0, 0)] = (C_0 + C_1 + C_2) - C_0 = C_1 + C_2 $\n\n这也证明了 $\\text{ATE} = \\text{IDE} + \\text{IIE}$ 在此模型中成立。\n\n**3. 实现**\n\n我们实现一个程序，利用这些闭式表达式计算出各个测试用例所需的五个值：\n1. $\\mathbb{E}[Y(1, 1)] = C_0 + C_1 + C_2$\n2. $\\mathbb{E}[Y(0, 0)] = C_0$\n3. $\\text{IDE} = C_1$\n4. $\\text{IIE} = C_2$\n5. $\\text{ATE} = C_1 + C_2$\n\n在线性模型中，处理分配参数 $(\\eta_0, \\eta_1)$ 和误差项方差不影响期望的计算，因此在最终计算中未使用。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes causal effects for an SCM with intermediate confounding using derived closed-form expressions.\n    \"\"\"\n    test_cases = [\n        # Test case 1 (general case, baseline confounding present)\n        {\n            \"mu_X\": 0.5, \"alpha_0\": 0.1, \"alpha_1\": 0.8, \"alpha_2\": 0.3,\n            \"beta_0\": 0.2, \"beta_1\": 0.9, \"beta_2\": 0.4, \"beta_3\": 0.5,\n            \"gamma_0\": 0.0, \"gamma_1\": 0.3, \"gamma_2\": 1.2, \"gamma_3\": 0.6, \"gamma_4\": 0.7\n        },\n        # Test case 2 (mediator has no effect on outcome)\n        {\n            \"mu_X\": -0.2, \"alpha_0\": 0.0, \"alpha_1\": 0.5, \"alpha_2\": 0.2,\n            \"beta_0\": 0.1, \"beta_1\": 0.7, \"beta_2\": 0.3, \"beta_3\": 0.6,\n            \"gamma_0\": 0.0, \"gamma_1\": 0.4, \"gamma_2\": 0.0, \"gamma_3\": 0.5, \"gamma_4\": 0.6\n        },\n        # Test case 3 (no direct effect of treatment on outcome)\n        {\n            \"mu_X\": 1.0, \"alpha_0\": 0.2, \"alpha_1\": 1.0, \"alpha_2\": 0.1,\n            \"beta_0\": 0.0, \"beta_1\": 1.0, \"beta_2\": 0.5, \"beta_3\": 0.8,\n            \"gamma_0\": 0.0, \"gamma_1\": 0.0, \"gamma_2\": 1.0, \"gamma_3\": 0.3, \"gamma_4\": 0.9\n        },\n        # Test case 4 (edge case with no baseline confounding in M and Y)\n        {\n            \"mu_X\": 0.0, \"alpha_0\": 0.3, \"alpha_1\": 0.2, \"alpha_2\": 0.0,\n            \"beta_0\": 0.5, \"beta_1\": 0.5, \"beta_2\": 0.0, \"beta_3\": 0.4,\n            \"gamma_0\": 0.0, \"gamma_1\": 0.2, \"gamma_2\": 0.8, \"gamma_3\": 0.0, \"gamma_4\": 0.3\n        }\n    ]\n\n    results = []\n    for params in test_cases:\n        # Unpack parameters for readability\n        mu_X = params[\"mu_X\"]\n        alpha_0, alpha_1, alpha_2 = params[\"alpha_0\"], params[\"alpha_1\"], params[\"alpha_2\"]\n        beta_0, beta_1, beta_2, beta_3 = params[\"beta_0\"], params[\"beta_1\"], params[\"beta_2\"], params[\"beta_3\"]\n        gamma_0, gamma_1, gamma_2, gamma_3, gamma_4 = params[\"gamma_0\"], params[\"gamma_1\"], params[\"gamma_2\"], params[\"gamma_3\"], params[\"gamma_4\"]\n\n        # The derived formula for E[Y(t, t')] is of the form: C0 + C1*t + C2*t'\n        # C1 corresponds to the IDE, C2 corresponds to the IIE.\n\n        # Calculate IIE (C2)\n        # This is the effect path T -> M -> Y, coefficient gamma_2 * beta_1\n        iie = gamma_2 * beta_1\n\n        # Calculate an intermediate term for IDE (C1) and the constant part (C0)\n        # This term represents the total effect of L on Y, both directly and through M.\n        l_effect_on_y = gamma_4 + gamma_2 * beta_3\n\n        # Calculate IDE (C1)\n        # This is the effect of T on Y not mediated by the direct T->M path.\n        # It includes the direct T->Y path and the path T->L->Y (and T->L->M->Y).\n        ide = gamma_1 + alpha_1 * l_effect_on_y\n\n        # Calculate ATE\n        ate = ide + iie\n\n        # Calculate the constant part of the expectation (C0)\n        # This corresponds to E[Y(0, 0)]\n        constant_intercepts = gamma_0 + gamma_2 * beta_0 + alpha_0 * l_effect_on_y\n        constant_from_x = mu_X * (gamma_3 + gamma_2 * beta_2 + alpha_2 * l_effect_on_y)\n        e_y_00 = constant_intercepts + constant_from_x\n\n        # Calculate E[Y(1, 1)]\n        e_y_11 = e_y_00 + ate\n        \n        # Assemble the list of results for the current test case\n        case_result = [e_y_11, e_y_00, ide, iie, ate]\n        results.append(case_result)\n\n    # Format the final output as a comma-separated list of lists\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3106705"}]}