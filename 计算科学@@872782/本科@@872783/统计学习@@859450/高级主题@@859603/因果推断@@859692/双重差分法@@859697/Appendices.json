{"hands_on_practices": [{"introduction": "仅仅估算出处理效应的大小是不够的；我们还必须量化其统计显著性。这需要计算估计量的方差，从而得到标准误和置信区间。在双重差分法（DiD）等面板数据分析中，同一个体在不同时间点的观测值通常存在自相关，而忽略这种相关性会导致错误的标准误。本练习将引导你从第一性原理出发，推导在不同误差相关结构下双重差分估计量 $\\hat{\\tau}$ 的方差，这是任何实证研究者都需掌握的基本功。[@problem_id:3115377]", "problem": "考虑一个平衡面板，其中地点由 $i \\in \\{1,\\dots,N\\}$ 索引，时间由 $t \\in \\{1,\\dots,T\\}$ 索引。一项政策在时间 $t^{\\ast}$ 引入，该政策适用于一部分地点，称为处理组 $\\mathcal{G}$，其样本容量为 $N_{G}$；而其余地点构成控制组 $\\mathcal{C}$，其样本容量为 $N_{C}$，因此 $N_{G} + N_{C} = N$。定义政策前时期为 $\\mathcal{P} = \\{t : t  t^{\\ast}\\}$，其长度为 $T_{0}$；政策后时期为 $\\mathcal{S} = \\{t : t \\ge t^{\\ast}\\}$，其长度为 $T_{1}$，且 $T_{0} + T_{1} = T$。结果变量 $y_{it}$ 服从以下加性模型\n$$\ny_{it} = \\alpha_{i} + \\gamma_{t} + \\tau D_{it} + u_{it},\n$$\n其中，如果 $i \\in \\mathcal{G}$ 且 $t \\in \\mathcal{S}$，则 $D_{it} = 1$，否则 $D_{it} = 0$。待估参数 $\\tau$ 是平均处理效应。定义双重差分（DiD）估计量为\n$$\n\\hat{\\tau} = \\big(\\bar{y}_{\\mathcal{G},\\mathcal{S}} - \\bar{y}_{\\mathcal{G},\\mathcal{P}}\\big) - \\big(\\bar{y}_{\\mathcal{C},\\mathcal{S}} - \\bar{y}_{\\mathcal{C},\\mathcal{P}}\\big),\n$$\n其中 $\\bar{y}_{\\mathcal{G},\\mathcal{S}}$ 表示 $y_{it}$ 在 $i \\in \\mathcal{G}$ 和 $t \\in \\mathcal{S}$ 上的平均值，$\\bar{y}_{\\mathcal{G},\\mathcal{P}}$、$\\bar{y}_{\\mathcal{C},\\mathcal{S}}$ 和 $\\bar{y}_{\\mathcal{C},\\mathcal{P}}$ 也类似。\n\n假设 $u_{it}$ 的均值为零，并具有以下由常数 $\\sigma^{2}  0$、$\\rho_{L} \\in [-1,1]$ 和 $\\rho_{T} \\in [-1,1]$ 定义的协方差结构：\n- 对所有 $i,t$ 有 $\\mathrm{Var}(u_{it}) = \\sigma^{2}$，\n- 对所有 $i$ 和所有 $t \\neq s$ 有 $\\mathrm{Cov}(u_{it}, u_{is}) = \\rho_{L}\\sigma^{2}$（地点层面的跨时间相关性），\n- 对所有 $t$ 和所有 $i \\neq j$ 有 $\\mathrm{Cov}(u_{it}, u_{jt}) = \\rho_{T}\\sigma^{2}$（时间层面的跨地点相关性），\n- 当 $i \\neq j$ 且 $t \\neq s$ 时，$\\mathrm{Cov}(u_{it}, u_{js}) = 0$。\n\n从涉及随机变量线性组合的第一性原理和上述定义出发（不要调用任何现成的聚类稳健公式），推导在以下条件下 $\\mathrm{Var}(\\hat{\\tau})$ 的封闭式表达式：\n1. 仅按地点聚类（设 $\\rho_{T} = 0$），\n2. 仅按时间聚类（设 $\\rho_{L} = 0$），\n3. 按地点和时间双向聚类（允许 $\\rho_{L}$ 和 $\\rho_{T}$ 均存在）。\n\n请用 $N_{G}$、$N_{C}$、$T_{0}$、$T_{1}$、$\\sigma^{2}$、$\\rho_{L}$ 和 $\\rho_{T}$ 表示你的最终结果。将这三个方差按（仅地点、仅时间、双向）的顺序以单行矩阵的形式给出。无需四舍五入。", "solution": "问题要求在误差项 $u_{it}$ 的指定协方差结构下，求出双重差分（DiD）估计量 $\\hat{\\tau}$ 的方差。该问题内部一致，具有统计理论的科学依据，且是良定的。我们可以开始求解。\n\n首先，我们将DiD估计量 $\\hat{\\tau}$ 表示为模型各组成部分的形式。该估计量定义为：\n$$\n\\hat{\\tau} = \\big(\\bar{y}_{\\mathcal{G},\\mathcal{S}} - \\bar{y}_{\\mathcal{G},\\mathcal{P}}\\big) - \\big(\\bar{y}_{\\mathcal{C},\\mathcal{S}} - \\bar{y}_{\\mathcal{C},\\mathcal{P}}\\big)\n$$\n将模型 $y_{it} = \\alpha_{i} + \\gamma_{t} + \\tau D_{it} + u_{it}$ 代入四个平均值 $\\bar{y}_{\\cdot,\\cdot}$ 的定义中，我们观察到固定效应 $\\alpha_i$ 和 $\\gamma_t$ 被差分消除，真实的平均处理效应参数 $\\tau$ 也是如此。令 $\\bar{u}_{\\mathcal{G},\\mathcal{S}}$ 为 $u_{it}$ 在 $i \\in \\mathcal{G}$ 和 $t \\in \\mathcal{S}$ 上的平均值，其他项也类似。该估计量可以写为：\n$$\n\\hat{\\tau} = \\tau + \\big(\\bar{u}_{\\mathcal{G},\\mathcal{S}} - \\bar{u}_{\\mathcal{G},\\mathcal{P}}\\big) - \\big(\\bar{u}_{\\mathcal{C},\\mathcal{S}} - \\bar{u}_{\\mathcal{C},\\mathcal{P}}\\big)\n$$\n由于对所有 $i,t$ 都有 $\\mathrm{E}[u_{it}]=0$，可得 $\\mathrm{E}[\\hat{\\tau}] = \\tau$。该估计量的方差由误差项平均值组合的方差决定：\n$$\n\\mathrm{Var}(\\hat{\\tau}) = \\mathrm{Var}\\left( \\big(\\bar{u}_{\\mathcal{G},\\mathcal{S}} - \\bar{u}_{\\mathcal{G},\\mathcal{P}}\\big) - \\big(\\bar{u}_{\\mathcal{C},\\mathcal{S}} - \\bar{u}_{\\mathcal{C},\\mathcal{P}}\\big) \\right)\n$$\n我们可以将其表示为误差项 $u_{it}$ 的单个线性组合的方差。令 $W = (\\bar{u}_{\\mathcal{G},\\mathcal{S}} - \\bar{u}_{\\mathcal{G},\\mathcal{P}}) - (\\bar{u}_{\\mathcal{C},\\mathcal{S}} - \\bar{u}_{\\mathcal{C},\\mathcal{P}})$。我们可以写出 $W = \\sum_{i=1}^{N} \\sum_{t=1}^{T} w_{it} u_{it}$，其中权重 $w_{it}$ 定义如下：\n\\begin{itemize}\n    \\item 对于 $i \\in \\mathcal{G}$ 和 $t \\in \\mathcal{S}$ （处理组，政策后时期）：$w_{it} = \\frac{1}{N_G T_1}$\n    \\item 对于 $i \\in \\mathcal{G}$ 和 $t \\in \\mathcal{P}$ （处理组，政策前时期）：$w_{it} = -\\frac{1}{N_G T_0}$\n    \\item 对于 $i \\in \\mathcal{C}$ 和 $t \\in \\mathcal{S}$ （控制组，政策后时期）：$w_{it} = -\\frac{1}{N_C T_1}$\n    \\item 对于 $i \\in \\mathcal{C}$ 和 $t \\in \\mathcal{P}$ （控制组，政策前时期）：$w_{it} = \\frac{1}{N_C T_0}$\n\\end{itemize}\n这个线性组合的方差由下式给出：\n$$\n\\mathrm{Var}(\\hat{\\tau}) = \\mathrm{Var}(W) = \\mathrm{Var}\\left(\\sum_{i,t} w_{it} u_{it}\\right) = \\sum_{i,t} \\sum_{j,s} w_{it} w_{js} \\mathrm{Cov}(u_{it}, u_{js})\n$$\n我们使用问题中提供的协方差结构：\n\\begin{itemize}\n    \\item 如果 $i=j$ 且 $t=s$，则 $\\mathrm{Cov}(u_{it}, u_{js}) = \\sigma^{2}$。\n    \\item 如果 $i=j$ 且 $t \\neq s$，则 $\\mathrm{Cov}(u_{it}, u_{js}) = \\rho_{L}\\sigma^{2}$。\n    \\item 如果 $i \\neq j$ 且 $t=s$，则 $\\mathrm{Cov}(u_{it}, u_{js}) = \\rho_{T}\\sigma^{2}$。\n    \\item 如果 $i \\neq j$ 且 $t \\neq s$，则 $\\mathrm{Cov}(u_{it}, u_{js}) = 0$。\n\\end{itemize}\n我们可以根据这些情况将双重求和拆分为四个部分：\n$$\n\\mathrm{Var}(\\hat{\\tau}) = \\sum_{i,t} w_{it}^2 \\mathrm{Var}(u_{it}) + \\sum_{i} \\sum_{t \\neq s} w_{it} w_{is} \\mathrm{Cov}(u_{it}, u_{is}) + \\sum_{t} \\sum_{i \\neq j} w_{it} w_{jt} \\mathrm{Cov}(u_{it}, u_{jt}) + \\sum_{i \\neq j, t \\neq s} w_{it} w_{js} \\cdot 0\n$$\n$$\n\\mathrm{Var}(\\hat{\\tau}) = \\sigma^2 \\sum_{i,t} w_{it}^2 + \\rho_L \\sigma^2 \\sum_{i} \\sum_{t \\neq s} w_{it} w_{is} + \\rho_T \\sigma^2 \\sum_{t} \\sum_{i \\neq j} w_{it} w_{jt}\n$$\n我们来计算每一项。\n\n第1项：权重平方和。\n$$\n\\sum_{i,t} w_{it}^2 = \\sum_{i \\in \\mathcal{G}, t \\in \\mathcal{S}} \\left(\\frac{1}{N_G T_1}\\right)^2 + \\sum_{i \\in \\mathcal{G}, t \\in \\mathcal{P}} \\left(\\frac{-1}{N_G T_0}\\right)^2 + \\sum_{i \\in \\mathcal{C}, t \\in \\mathcal{S}} \\left(\\frac{-1}{N_C T_1}\\right)^2 + \\sum_{i \\in \\mathcal{C}, t \\in \\mathcal{P}} \\left(\\frac{1}{N_C T_0}\\right)^2\n$$\n这些求和中的项数分别为 $N_G T_1$、$N_G T_0$、$N_C T_1$ 和 $N_C T_0$。\n$$\n\\sum_{i,t} w_{it}^2 = \\frac{N_G T_1}{N_G^2 T_1^2} + \\frac{N_G T_0}{N_G^2 T_0^2} + \\frac{N_C T_1}{N_C^2 T_1^2} + \\frac{N_C T_0}{N_C^2 T_0^2} = \\frac{1}{N_G T_1} + \\frac{1}{N_G T_0} + \\frac{1}{N_C T_1} + \\frac{1}{N_C T_0}\n$$\n这可以因式分解为：\n$$\n\\sum_{i,t} w_{it}^2 = \\frac{1}{N_G}\\left(\\frac{1}{T_1} + \\frac{1}{T_0}\\right) + \\frac{1}{N_C}\\left(\\frac{1}{T_1} + \\frac{1}{T_0}\\right) = \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right)\\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)\n$$\n方差的第一项是 $\\sigma^2 \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right)\\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)$。\n\n第2项：地点层面相关性。和为 $\\sum_{i} \\sum_{t \\neq s} w_{it} w_{is}$。我们使用恒等式 $\\sum_{t \\neq s} a_t a_s = (\\sum_t a_t)^2 - \\sum_t a_t^2$。\n对于任何地点 $i \\in \\mathcal{G}$：\n$$ \\sum_{t} w_{it} = \\sum_{t \\in \\mathcal{S}} \\frac{1}{N_G T_1} + \\sum_{t \\in \\mathcal{P}} \\frac{-1}{N_G T_0} = T_1 \\cdot \\frac{1}{N_G T_1} - T_0 \\cdot \\frac{1}{N_G T_0} = \\frac{1}{N_G} - \\frac{1}{N_G} = 0 $$\n类似地，对于任何地点 $i \\in \\mathcal{C}$：\n$$ \\sum_{t} w_{it} = \\sum_{t \\in \\mathcal{S}} \\frac{-1}{N_C T_1} + \\sum_{t \\in \\mathcal{P}} \\frac{1}{N_C T_0} = -T_1 \\cdot \\frac{1}{N_C T_1} + T_0 \\cdot \\frac{1}{N_C T_0} = -\\frac{1}{N_C} + \\frac{1}{N_C} = 0 $$\n因此，对所有 $i$ 都有 $\\sum_t w_{it} = 0$。所以，$\\sum_{t \\neq s} w_{it} w_{is} = 0 - \\sum_t w_{it}^2$。\n$$\n\\sum_{i} \\sum_{t \\neq s} w_{it} w_{is} = \\sum_{i} \\left( -\\sum_{t} w_{it}^2 \\right) = - \\sum_{i,t} w_{it}^2 = -\\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right)\\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)\n$$\n方差的第二项是 $-\\rho_L \\sigma^2 \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right)\\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)$。\n\n第3项：时间层面相关性。和为 $\\sum_{t} \\sum_{i \\neq j} w_{it} w_{jt}$。我们使用恒等式 $\\sum_{i \\neq j} a_i a_j = (\\sum_i a_i)^2 - \\sum_i a_i^2$。\n对于任何时间 $t \\in \\mathcal{S}$：\n$$ \\sum_{i} w_{it} = \\sum_{i \\in \\mathcal{G}} \\frac{1}{N_G T_1} + \\sum_{i \\in \\mathcal{C}} \\frac{-1}{N_C T_1} = N_G \\cdot \\frac{1}{N_G T_1} - N_C \\cdot \\frac{1}{N_C T_1} = \\frac{1}{T_1} - \\frac{1}{T_1} = 0 $$\n类似地，对于任何时间 $t \\in \\mathcal{P}$：\n$$ \\sum_{i} w_{it} = \\sum_{i \\in \\mathcal{G}} \\frac{-1}{N_G T_0} + \\sum_{i \\in \\mathcal{C}} \\frac{1}{N_C T_0} = -N_G \\cdot \\frac{1}{N_G T_0} + N_C \\cdot \\frac{1}{N_C T_0} = -\\frac{1}{T_0} + \\frac{1}{T_0} = 0 $$\n因此，对所有 $t$ 都有 $\\sum_i w_{it} = 0$。所以，$\\sum_{i \\neq j} w_{it} w_{jt} = 0 - \\sum_i w_{it}^2$。\n$$\n\\sum_{t} \\sum_{i \\neq j} w_{it} w_{jt} = \\sum_{t} \\left( -\\sum_{i} w_{it}^2 \\right) = - \\sum_{i,t} w_{it}^2 = -\\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right)\\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)\n$$\n方差的第三项是 $-\\rho_T \\sigma^2 \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right)\\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)$。\n\n结合所有三项，我们得到 $\\hat{\\tau}$ 方差的一般表达式：\n$$\n\\mathrm{Var}(\\hat{\\tau}) = \\sigma^2(1 - \\rho_L - \\rho_T) \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right) \\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)\n$$\n这是双向聚类的一般表达式。\n\n我们现在可以求出所要求的三个特定情况的解。\n\n1.  **仅按地点聚类**：我们设 $\\rho_T = 0$。\n    $$\n    \\mathrm{Var}(\\hat{\\tau})_{\\text{loc}} = \\sigma^2(1 - \\rho_L) \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right) \\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)\n    $$\n\n2.  **仅按时间聚类**：我们设 $\\rho_L = 0$。\n    $$\n    \\mathrm{Var}(\\hat{\\tau})_{\\text{time}} = \\sigma^2(1 - \\rho_T) \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right) \\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)\n    $$\n\n3.  **双向聚类**：这是上面推导的一般公式。\n    $$\n    \\mathrm{Var}(\\hat{\\tau})_{\\text{two-way}} = \\sigma^2(1 - \\rho_L - \\rho_T) \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right) \\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)\n    $$\n\n我们按要求将这三个结果呈现在一个单行矩阵中。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\sigma^2(1 - \\rho_L) \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right) \\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)  \\sigma^2(1 - \\rho_T) \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right) \\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right)  \\sigma^2(1 - \\rho_L - \\rho_T) \\left(\\frac{1}{N_G} + \\frac{1}{N_C}\\right) \\left(\\frac{1}{T_0} + \\frac{1}{T_1}\\right) \\end{pmatrix}}\n$$", "id": "3115377"}, {"introduction": "双重差分法的核心假设是“平行趋势”，即处理组和控制组在没有政策干预的情况下，其结果变量的变化趋势是相同的。本练习将探讨一个现实场景，其中该假设因测量工具的演变（例如用于内容分析的语言模型随时间更新）而失效。我们将通过实现一种高级方法，即使用“负向控制结果”，来识别和校正这种时变测量偏差，从而加深对如何处理平行趋势假设被违背这一挑战的理解。[@problem_id:3115392]", "problem": "您的任务是实现一个程序，该程序计算一项政策对一个已测量的份额结果的影响的未经调整和经负向控制调整的双重差分法 (DiD) 估计值，并使用负向控制来检验测量漂移。背景设定为一个双组、双时期的设计，其中一个组在第二个时期接受处理。教学目标是，使用一个负向控制结果来检测并调整时变漂移，从而推导、实现并检验一个用于估计潜在政策效应的双重差分法估计量，该效应作用于一个受时变漂移影响的测量结果。您的推导必须从潜在结果框架和平行趋势假设开始，并且您不能假设任何预先给定的估计量公式。\n\n背景与定义：\n- 考虑两个组，由 $g \\in \\{\\mathrm{T}, \\mathrm{C}\\}$ 索引，其中 $\\mathrm{T}$ 表示处理组，$\\mathrm{C}$ 表示控制组；以及两个时间段，由 $t \\in \\{0,1\\}$ 索引，其中 $t=0$ 是前一时期，$t=1$ 是后一时期。\n- 令潜在结果（不受测量漂移影响）为 $Y^{\\ast}_{g t}$，解释为在时间 $t$ 国家组 $g$ 中仇恨言论的真实份额。令观测结果为 $Y_{g t}$，它受到来自语言模型的时变测量漂移的影响。\n- 令负向控制结果为 $W_{g t}$，它不受处理影响，但与观测结果共享相同的漂移因子。\n- 令在后一时期对处理组的潜在结果的处理效应为 $\\tau$。潜在结果框架和平行趋势假设适用于 $Y^{\\ast}_{g t}$：在没有处理的情况下，在期望上，处理组和控制组在 $t=0$ 和 $t=1$ 之间会平行演变。\n\n用于此问题的数据生成结构：\n- 潜在结果可加性地分解为组分量和时间分量，以及适用的处理效应：\n$$\nY^{\\ast}_{g t} = \\mu_{g} + \\psi_{t} + \\tau \\cdot \\mathbf{1}\\{g = \\mathrm{T}\\} \\cdot \\mathbf{1}\\{t = 1\\}。\n$$\n- 观测结果 $Y_{g t}$ 包含来自单一共同时变因子 $L_{t}$ 的漂移，其具有特定于组的载荷 $b_{g}$：\n$$\nY_{g t} = Y^{\\ast}_{g t} + b_{g} \\cdot L_{t}。\n$$\n- 负向控制 $W_{g t}$ 不受处理影响，并与具有特定于组的载荷 $d_{g}$ 的相同因子 $L_{t}$ 共享：\n$$\nW_{g t} = d_{g} \\cdot L_{t}。\n$$\n- 此问题中没有随机噪声；所有量均为确定性均值。所有份额都必须视为 $[0,1]$ 范围内的小数。\n\n您的任务：\n1) 使用潜在结果的定义和平行趋势假设，推导四个观测均值 $\\{Y_{\\mathrm{T}0}, Y_{\\mathrm{T}1}, Y_{\\mathrm{C}0}, Y_{\\mathrm{C}1}\\}$ 的一个对比，该对比消除了 $Y^{\\ast}_{g t}$ 中的组特定基线和共同时间效应，以在理想测量条件下识别对处理组的平均处理效应。实现这个对比以从观测数据中获得未经调整的估计量 $\\widehat{\\tau}_{\\mathrm{DiD}}$。\n2) 使用负向控制 $W_{g t}$，推导一个调整项，以从 $\\widehat{\\tau}_{\\mathrm{DiD}}$ 中移除由 $L_{t}$ 引起的漂移贡献。在这个综合练习中，假设载荷 $b_{g}$ 和 $d_{g}$ 是已知常数。在单因子漂移结构下，展示如何通过减去 $Y_{g t}$ 中可归因于漂移的DiD对比分量来构建一个调整后的估计量 $\\widehat{\\tau}_{\\mathrm{adj}}$，其中使用一个适当的标量来关联 $Y_{g t}$ 与 $W_{g t}$ 的跨组敏感度。实现此调整。在负向控制对比恰好为零的退化情况下，取 $\\widehat{\\tau}_{\\mathrm{adj}} = \\widehat{\\tau}_{\\mathrm{DiD}}$。\n3) 提供一个基于负向控制的漂移检测指标：计算 $W_{g t}$ 上的DiD对比，如果其绝对值超过数值容差 $\\varepsilon = 10^{-12}$，则将布尔值 $\\mathrm{drift\\_detected}$ 设置为 $\\mathrm{True}$，否则设置为 $\\mathrm{False}$。\n\n测试套件：\n对于每个测试用例，您将获得数值参数 $(\\mu_{\\mathrm{T}}, \\mu_{\\mathrm{C}}, \\psi_{0}, \\psi_{1}, \\tau, b_{\\mathrm{T}}, b_{\\mathrm{C}}, d_{\\mathrm{T}}, d_{\\mathrm{C}}, L_{0}, L_{1})$。使用它们确定性地构建观测单元均值 $Y_{g t}$ 和 $W_{g t}$，然后计算所需的输出。\n\n- 测试用例 1 (理想路径，无漂移差异)：\n  - $(\\mu_{\\mathrm{T}}, \\mu_{\\mathrm{C}}, \\psi_{0}, \\psi_{1}, \\tau) = (0.10, 0.12, 0.00, 0.01, 0.05)$\n  - $(b_{\\mathrm{T}}, b_{\\mathrm{C}}) = (0.02, 0.02)$\n  - $(d_{\\mathrm{T}}, d_{\\mathrm{C}}) = (1.0, 1.0)$\n  - $(L_{0}, L_{1}) = (1.0, 1.5)$\n\n- 测试用例 2 (无真实效应但存在漂移混淆)：\n  - $(\\mu_{\\mathrm{T}}, \\mu_{\\mathrm{C}}, \\psi_{0}, \\psi_{1}, \\tau) = (0.20, 0.20, 0.00, 0.00, 0.00)$\n  - $(b_{\\mathrm{T}}, b_{\\mathrm{C}}) = (0.06, 0.02)$\n  - $(d_{\\mathrm{T}}, d_{\\mathrm{C}}) = (3.0, 1.0)$\n  - $(L_{0}, L_{1}) = (1.0, 2.0)$\n\n- 测试用例 3 (真实效应加漂移混淆)：\n  - $(\\mu_{\\mathrm{T}}, \\mu_{\\mathrm{C}}, \\psi_{0}, \\psi_{1}, \\tau) = (0.15, 0.14, 0.00, 0.02, 0.04)$\n  - $(b_{\\mathrm{T}}, b_{\\mathrm{C}}) = (0.05, 0.02)$\n  - $(d_{\\mathrm{T}}, d_{\\mathrm{C}}) = (2.5, 1.0)$\n  - $(L_{0}, L_{1}) = (1.0, 1.8)$\n\n- 测试用例 4 (边界情况，无漂移变化)：\n  - $(\\mu_{\\mathrm{T}}, \\mu_{\\mathrm{C}}, \\psi_{0}, \\psi_{1}, \\tau) = (0.08, 0.10, 0.01, 0.02, 0.03)$\n  - $(b_{\\mathrm{T}}, b_{\\mathrm{C}}) = (0.04, 0.01)$\n  - $(d_{\\mathrm{T}}, d_{\\mathrm{C}}) = (2.0, 1.0)$\n  - $(L_{0}, L_{1}) = (2.0, 2.0)$\n\n程序输出要求：\n- 对于每个测试用例，按顺序 $[\\widehat{\\tau}_{\\mathrm{DiD}}, \\widehat{\\tau}_{\\mathrm{adj}}, \\mathrm{drift\\_detected}]$ 输出一个包含三个元素的列表。\n- 将所有测试用例的结果汇总到一个列表中，并打印一行包含此列表的列表，格式完全如下：一个Python风格的列表字面量，用逗号分隔，不需要空格，例如 $[[0.123456,0.123000,True],[\\dots],\\dots]$。\n- 将所有浮点值四舍五入到6位小数。布尔值必须显示为 $\\mathrm{True}$ 或 $\\mathrm{False}$。\n- 所有份额必须表示为小数，而非百分比。", "solution": "## 问题验证\n\n### 步骤 1：提取给定信息\n问题提供了以下数据、定义和条件：\n- **组**：$g \\in \\{\\mathrm{T}, \\mathrm{C}\\}$ (处理组，控制组)。\n- **时间段**：$t \\in \\{0, 1\\}$ (前一时期，后一时期)。\n- **潜在结果**：$Y^{\\ast}_{g t}$，不受测量漂移影响的真实结果。\n- **观测结果**：$Y_{g t}$，受漂移影响。\n- **负向控制结果**：$W_{g t}$，不受处理影响但受相同漂移因子影响。\n- **处理效应**：$\\tau$，在后一时期对处理组潜在结果的影响。\n- **假设**：$Y^{\\ast}_{g t}$ 的潜在结果框架和平行趋势假设。\n\n**数据生成结构 (确定性均值)：**\n1.  潜在结果模型：\n    $$\n    Y^{\\ast}_{g t} = \\mu_{g} + \\psi_{t} + \\tau \\cdot \\mathbf{1}\\{g = \\mathrm{T}\\} \\cdot \\mathbf{1}\\{t = 1\\}\n    $$\n    其中 $\\mu_g$ 是特定于组的固定效应，$\\psi_t$ 是特定于时间的固定效应。\n2.  观测结果模型 (含漂移)：\n    $$\n    Y_{g t} = Y^{\\ast}_{g t} + b_{g} \\cdot L_{t}\n    $$\n    其中 $L_t$ 是一个时变漂移因子，$b_g$ 是特定于组的因子载荷。\n3.  负向控制模型：\n    $$\n    W_{g t} = d_{g} \\cdot L_{t}\n    $$\n    其中 $d_g$ 是负向控制的特定于组的因子载荷。\n\n**任务：**\n1.  使用观测均值 $\\{Y_{\\mathrm{T}0}, Y_{\\mathrm{T}1}, Y_{\\mathrm{C}0}, Y_{\\mathrm{C}1}\\}$ 推导并实现一个未经调整的双重差分法 (DiD) 估计量 $\\widehat{\\tau}_{\\mathrm{DiD}}$。\n2.  推导并实现一个调整后的估计量 $\\widehat{\\tau}_{\\mathrm{adj}}$，该估计量使用负向控制 $W_{gt}$ 来校正漂移。对于零负向控制对比，$\\widehat{\\tau}_{\\mathrm{adj}}$ 应等于 $\\widehat{\\tau}_{\\mathrm{DiD}}$。\n3.  基于 $W_{gt}$ 上的 DiD 对比实现一个漂移检测指标 $\\mathrm{drift\\_detected}$，容差为 $\\varepsilon = 10^{-12}$。\n\n**测试套件参数：**\n- 案例 1: $(\\mu_{\\mathrm{T}}, \\mu_{\\mathrm{C}}, \\psi_{0}, \\psi_{1}, \\tau, b_{\\mathrm{T}}, b_{\\mathrm{C}}, d_{\\mathrm{T}}, d_{\\mathrm{C}}, L_{0}, L_{1}) = (0.10, 0.12, 0.00, 0.01, 0.05, 0.02, 0.02, 1.0, 1.0, 1.0, 1.5)$\n- 案例 2: $(\\mu_{\\mathrm{T}}, \\mu_{\\mathrm{C}}, \\psi_{0}, \\psi_{1}, \\tau, b_{\\mathrm{T}}, b_{\\mathrm{C}}, d_{\\mathrm{T}}, d_{\\mathrm{C}}, L_{0}, L_{1}) = (0.20, 0.20, 0.00, 0.00, 0.00, 0.06, 0.02, 3.0, 1.0, 1.0, 2.0)$\n- 案例 3: $(\\mu_{\\mathrm{T}}, \\mu_{\\mathrm{C}}, \\psi_{0}, \\psi_{1}, \\tau, b_{\\mathrm{T}}, b_{\\mathrm{C}}, d_{\\mathrm{T}}, d_{\\mathrm{C}}, L_{0}, L_{1}) = (0.15, 0.14, 0.00, 0.02, 0.04, 0.05, 0.02, 2.5, 1.0, 1.0, 1.8)$\n- 案例 4: $(\\mu_{\\mathrm{T}}, \\mu_{\\mathrm{C}}, \\psi_{0}, \\psi_{1}, \\tau, b_{\\mathrm{T}}, b_{\\mathrm{C}}, d_{\\mathrm{T}}, d_{\\mathrm{C}}, L_{0}, L_{1}) = (0.08, 0.10, 0.01, 0.02, 0.03, 0.04, 0.01, 2.0, 1.0, 2.0, 2.0)$\n\n### 步骤 2：使用提取的给定信息进行验证\n根据验证标准对问题进行评估：\n- **科学基础**：该问题牢固地植根于因果推断的统计/计量经济学理论，特别是双重差分法和负向控制的使用。潜在结果框架是一个标准的理论基础。加法模型是用于教学目的的常见简化假设。\n- **适定性**：该问题是适定的。数据生成过程是确定性的且被完全指定，从而为每个测试用例带来唯一的解。\n- **客观性**：语言精确且技术性强，不含主观性。\n- **完整性与一致性**：提供了所有必要的参数和模型。没有矛盾之处。\n- **现实性**：虽然确定性是一种简化，但该设置代表了经验研究中一个典型而常见的挑战，即测量工具（如语言模型）随时间演变，可能导致估计产生偏差。\n- **形式化**：该问题已用形式化的数学结构呈现。\n- **无其他缺陷**：该问题并非微不足道、类比或无法验证。这是一个应用和扩展统计方法的标准练习。\n\n### 步骤 3：结论与行动\n问题有效。将提供一个完整的、有理有据的解决方案。\n\n---\n## 推导与求解\n\n该问题要求推导和实现双重差分法 (DiD) 估计量。所有量都是确定性的单元格均值，因此我们可以省略期望算子。\n\n### 1. 未经调整的 DiD 估计量 ($\\widehat{\\tau}_{\\mathrm{DiD}}$) 的推导\n\n目标是估计对处理组的平均处理效应 (ATT)，它被定义为在处理后时期对处理组的处理效应。在潜在结果框架内，我们将潜在变量 $Y^{\\ast}$ 的潜在结果表示为 $Y^{\\ast}_{gt}(1)$（有处理）和 $Y^{\\ast}_{gt}(0)$（无处理）。处理仅在时间 $t=1$ 应用于组 $\\mathrm{T}$。ATT 是 $\\tau = Y^{\\ast}_{\\mathrm{T}1}(1) - Y^{\\ast}_{\\mathrm{T}1}(0)$。\n\n我们观测到 $Y^{\\ast}_{\\mathrm{T}1} = Y^{\\ast}_{\\mathrm{T}1}(1)$。项 $Y^{\\ast}_{\\mathrm{T}1}(0)$ 是反事实：即如果处理组在 $t=1$ 时未接受处理，其结果会是怎样。我们必须从可用数据中估计这个值。\n\n**平行趋势假设**是关键。它假定，在没有处理的情况下，处理组结果的变化本应与控制组结果的变化相同。形式上：\n$$\nY^{\\ast}_{\\mathrm{T}1}(0) - Y^{\\ast}_{\\mathrm{T}0}(0) = Y^{\\ast}_{\\mathrm{C}1}(0) - Y^{\\ast}_{\\mathrm{C}0}(0)\n$$\n由于处理组在 $t=0$ 时未被处理 ($Y^{\\ast}_{\\mathrm{T}0}=Y^{\\ast}_{\\mathrm{T}0}(0)$)，且控制组从未被处理 ($Y^{\\ast}_{\\mathrm{C}t}=Y^{\\ast}_{\\mathrm{C}t}(0)$)，我们可以写成：\n$$\nY^{\\ast}_{\\mathrm{T}1}(0) - Y^{\\ast}_{\\mathrm{T}0} = Y^{\\ast}_{\\mathrm{C}1} - Y^{\\ast}_{\\mathrm{C}0}\n$$\n重新排列以求解反事实 $Y^{\\ast}_{\\mathrm{T}1}(0)$：\n$$\nY^{\\ast}_{\\mathrm{T}1}(0) = Y^{\\ast}_{\\mathrm{T}0} + (Y^{\\ast}_{\\mathrm{C}1} - Y^{\\ast}_{\\mathrm{C}0})\n$$\n将此代入 $\\tau$ 的定义中：\n$$\n\\tau = Y^{\\ast}_{\\mathrm{T}1} - Y^{\\ast}_{\\mathrm{T}1}(0) = Y^{\\ast}_{\\mathrm{T}1} - [Y^{\\ast}_{\\mathrm{T}0} + (Y^{\\ast}_{\\mathrm{C}1} - Y^{\\ast}_{\\mathrm{C}0})]\n$$\n重新排列得到潜在变量的经典 DiD 表达式：\n$$\n\\tau = (Y^{\\ast}_{\\mathrm{T}1} - Y^{\\ast}_{\\mathrm{T}0}) - (Y^{\\ast}_{\\mathrm{C}1} - Y^{\\ast}_{\\mathrm{C}0})\n$$\n未经调整的估计量 $\\widehat{\\tau}_{\\mathrm{DiD}}$ 将此公式简单地应用于*观测*结果 $Y_{gt}$：\n$$\n\\widehat{\\tau}_{\\mathrm{DiD}} = (Y_{\\mathrm{T}1} - Y_{\\mathrm{T}0}) - (Y_{\\mathrm{C}1} - Y_{\\mathrm{C}0})\n$$\n\n### 2. 经漂移调整的估计量 ($\\widehat{\\tau}_{\\mathrm{adj}}$) 的推导\n\n如果测量漂移不遵循平行趋势，则未经调整的估计量 $\\widehat{\\tau}_{\\mathrm{DiD}}$ 是有偏的。让我们量化这种偏差。将 $Y_{g t} = Y^{\\ast}_{g t} + b_{g} L_{t}$ 代入 $\\widehat{\\tau}_{\\mathrm{DiD}}$ 公式：\n$$\n\\widehat{\\tau}_{\\mathrm{DiD}} = \\left( (Y^{\\ast}_{\\mathrm{T}1} + b_{\\mathrm{T}}L_1) - (Y^{\\ast}_{\\mathrm{T}0} + b_{\\mathrm{T}}L_0) \\right) - \\left( (Y^{\\ast}_{\\mathrm{C}1} + b_{\\mathrm{C}}L_1) - (Y^{\\ast}_{\\mathrm{C}0} + b_{\\mathrm{C}}L_0) \\right)\n$$\n分离与 $Y^{\\ast}$ 相关的项和漂移项 $(b_g, L_t)$：\n$$\n\\widehat{\\tau}_{\\mathrm{DiD}} = \\left[ (Y^{\\ast}_{\\mathrm{T}1} - Y^{\\ast}_{\\mathrm{T}0}) - (Y^{\\ast}_{\\mathrm{C}1} - Y^{\\ast}_{\\mathrm{C}0}) \\right] + \\left[ (b_{\\mathrm{T}}L_1 - b_{\\mathrm{T}}L_0) - (b_{\\mathrm{C}}L_1 - b_{\\mathrm{C}}L_0) \\right]\n$$\n第一个方括号是真实的处理效应 $\\tau$。第二个方括号是偏差项：\n$$\n\\text{偏差} = (b_{\\mathrm{T}} - b_{\\mathrm{C}}) (L_1 - L_0)\n$$\n因此，$\\widehat{\\tau}_{\\mathrm{DiD}} = \\tau + \\text{偏差}$。仅当因子载荷在组间不同 ($b_{\\mathrm{T}} \\neq b_{\\mathrm{C}}$) 且漂移因子随时间变化 ($L_1 \\neq L_0$) 时，漂移才会使估计产生偏差。\n\n为了校正此偏差，我们使用负向控制结果 $W_{gt}$。我们在 $W_{gt}$ 上计算一个 DiD 对比，称之为 $\\Delta_W$：\n$$\n\\Delta_W = (W_{\\mathrm{T}1} - W_{\\mathrm{T}0}) - (W_{\\mathrm{C}1} - W_{\\mathrm{C}0})\n$$\n代入定义 $W_{g t} = d_{g} L_{t}$：\n$$\n\\Delta_W = (d_{\\mathrm{T}}L_1 - d_{\\mathrm{T}}L_0) - (d_{\\mathrm{C}}L_1 - d_{\\mathrm{C}}L_0) = (d_{\\mathrm{T}} - d_{\\mathrm{C}})(L_1 - L_0)\n$$\n我们有两个方程：\n$1. \\text{偏差} = (b_{\\mathrm{T}} - b_{\\mathrm{C}})(L_1 - L_0)$\n$2. \\Delta_W = (d_{\\mathrm{T}} - d_{\\mathrm{C}})(L_1 - L_0)$\n\n假设 $d_{\\mathrm{T}} - d_{\\mathrm{C}} \\neq 0$，我们可以从第二个方程中将 $(L_1 - L_0)$ 表示为 $\\frac{\\Delta_W}{d_{\\mathrm{T}} - d_{\\mathrm{C}}}$。将其代入第一个方程：\n$$\n\\text{偏差} = (b_{\\mathrm{T}} - b_{\\mathrm{C}}) \\frac{\\Delta_W}{d_{\\mathrm{T}} - d_{\\mathrm{C}}} = \\left(\\frac{b_{\\mathrm{T}} - b_{\\mathrm{C}}}{d_{\\mathrm{T}} - d_{\\mathrm{C}}}\\right) \\Delta_W\n$$\n标量 $\\gamma = \\frac{b_{\\mathrm{T}} - b_{\\mathrm{C}}}{d_{\\mathrm{T}} - d_{\\mathrm{C}}}$ 将 $Y_{gt}$ 中的漂移效应与 $W_{gt}$ 中的漂移效应联系起来。由于 $b_g$ 和 $d_g$ 是已知的，我们可以计算这个标量并估计偏差。\n\n调整后的估计量 $\\widehat{\\tau}_{\\mathrm{adj}}$ 是通过从 $\\widehat{\\tau}_{\\mathrm{DiD}}$ 中减去估计的偏差得到的：\n$$\n\\widehat{\\tau}_{\\mathrm{adj}} = \\widehat{\\tau}_{\\mathrm{DiD}} - \\left(\\frac{b_{\\mathrm{T}} - b_{\\mathrm{C}}}{d_{\\mathrm{T}} - d_{\\mathrm{C}}}\\right) \\Delta_W\n$$\n这可以校正估计以恢复真实的 $\\tau$。问题规定，如果负向控制对比 $\\Delta_W$ 为零（在容差范围内），则不进行调整，因此 $\\widehat{\\tau}_{\\mathrm{adj}} = \\widehat{\\tau}_{\\mathrm{DiD}}$。该规则正确处理了 $L_1=L_0$（漂移无变化）或 $d_{\\mathrm{T}}=d_{\\mathrm{C}}$（负向控制中漂移平行）的情况，因为在这两种情况下 $\\Delta_W = 0$。\n\n### 3. 漂移检测指标\n漂移检测指标直接基于 $\\Delta_W$。如果该值非零（超出小的数值容差），则意味着漂移在各组之间不是平行的 ($d_T \\neq d_C$) 并且不随时间恒定 ($L_1 \\neq L_0$)。负向控制中的这种非平行漂移作为一个警告，表明观测结果 $Y_{gt}$ 的平行趋势假设很可能因测量漂移而被违反，从而混淆了 $\\widehat{\\tau}_{\\mathrm{DiD}}$。\n该指标定义为：\n$$\n\\mathrm{drift\\_detected} = \\begin{cases} \\mathrm{True}  \\text{如果 } |\\Delta_W|  \\varepsilon \\\\ \\mathrm{False}  \\text{如果 } |\\Delta_W| \\leq \\varepsilon \\end{cases}\n$$\n其中 $\\varepsilon = 10^{-12}$。\n\n### 实现策略\n\n对于每个测试用例，程序将：\n1.  接收参数 $(\\mu_{\\mathrm{T}}, \\mu_{\\mathrm{C}}, \\psi_{0}, \\psi_{1}, \\tau, b_{\\mathrm{T}}, b_{\\mathrm{C}}, d_{\\mathrm{T}}, d_{\\mathrm{C}}, L_{0}, L_{1})$。\n2.  使用各自的数据生成过程方程计算 $Y_{gt}$ 和 $W_{gt}$ 的四个观测均值。\n3.  计算 $\\widehat{\\tau}_{\\mathrm{DiD}} = (Y_{\\mathrm{T}1} - Y_{\\mathrm{T}0}) - (Y_{\\mathrm{C}1} - Y_{\\mathrm{C}0})$。\n4.  计算 $\\Delta_W = (W_{\\mathrm{T}1} - W_{\\mathrm{T}0}) - (W_{\\mathrm{C}1} - W_{\\mathrm{C}0})$。\n5.  确定 $\\mathrm{drift\\_detected} = |\\Delta_W|  10^{-12}$。\n6.  计算调整项。如果 $|\\Delta_W| \\leq 10^{-12}$，则调整项为 $0$。否则，调整项为 $\\frac{b_{\\mathrm{T}} - b_{\\mathrm{C}}}{d_{\\mathrmT} - d_{\\mathrm{C}}} \\Delta_W$。\n7.  计算 $\\widehat{\\tau}_{\\mathrm{adj}} = \\widehat{\\tau}_{\\mathrm{DiD}} - \\text{调整项}$。\n8.  将估计量四舍五入到6位小数，并按要求格式化输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes unadjusted and negative-control-adjusted DiD estimates.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (mu_T, mu_C, psi_0, psi_1, tau, b_T, b_C, d_T, d_C, L_0, L_1)\n        (0.10, 0.12, 0.00, 0.01, 0.05, 0.02, 0.02, 1.0, 1.0, 1.0, 1.5), # Case 1\n        (0.20, 0.20, 0.00, 0.00, 0.00, 0.06, 0.02, 3.0, 1.0, 1.0, 2.0), # Case 2\n        (0.15, 0.14, 0.00, 0.02, 0.04, 0.05, 0.02, 2.5, 1.0, 1.0, 1.8), # Case 3\n        (0.08, 0.10, 0.01, 0.02, 0.03, 0.04, 0.01, 2.0, 1.0, 2.0, 2.0)  # Case 4\n    ]\n\n    results = []\n    TOLERANCE = 1e-12\n\n    for case in test_cases:\n        mu_T, mu_C, psi_0, psi_1, tau, b_T, b_C, d_T, d_C, L_0, L_1 = case\n\n        # --- Data Generation ---\n        # Observed outcome Y_gt = Y*_gt + b_g * L_t\n        # where Y*_gt = mu_g + psi_t + tau * 1{g=T} * 1{t=1}\n        Y_T0 = mu_T + psi_0 + b_T * L_0\n        Y_T1 = mu_T + psi_1 + tau + b_T * L_1\n        Y_C0 = mu_C + psi_0 + b_C * L_0\n        Y_C1 = mu_C + psi_1 + b_C * L_1\n\n        # Negative control outcome W_gt = d_g * L_t\n        W_T0 = d_T * L_0\n        W_T1 = d_T * L_1\n        W_C0 = d_C * L_0\n        W_C1 = d_C * L_1\n\n        # --- Task 1: Unadjusted DiD Estimator ---\n        tau_did = (Y_T1 - Y_T0) - (Y_C1 - Y_C0)\n\n        # --- Task 2  3: Drift Detection and Adjusted Estimator ---\n        # DiD on the negative control\n        delta_W = (W_T1 - W_T0) - (W_C1 - W_C0)\n        \n        # Drift detection\n        drift_detected = abs(delta_W) > TOLERANCE\n\n        # Adjustment calculation\n        adjustment = 0.0\n        if drift_detected:\n            # The derivation shows Bias = ((b_T - b_C) / (d_T - d_C)) * delta_W\n            # And tau_adj = tau_did - Bias\n            delta_b = b_T - b_C\n            delta_d = d_T - d_C\n            \n            # The condition `drift_detected` ensures abs(delta_W) > 0.\n            # If delta_W is non-zero, it must be that (d_T - d_C) != 0 and (L_1 - L_0) != 0.\n            # So, delta_d cannot be zero if drift is detected.\n            # Thus, division by zero is avoided.\n            if abs(delta_d) > TOLERANCE:\n                gamma = delta_b / delta_d\n                adjustment = gamma * delta_W\n        \n        tau_adj = tau_did - adjustment\n\n        # Formatting results as per requirements\n        # Round floating point values to 6 decimal places.\n        # Booleans remain as True/False.\n        results.append([\n            round(tau_did, 6),\n            round(tau_adj, 6),\n            drift_detected\n        ])\n\n    # Convert the list of lists to the required string format\n    # [[0.123456,0.123000,True],...]\n    final_output_str = \"[\" + \",\".join([\n        f\"[{res[0]},{res[1]},{res[2]}]\" for res in results]) + \"]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output_str.replace(\" \", \"\"))\n\nsolve()\n\n```", "id": "3115392"}, {"introduction": "标准的双重差分估计量基于均值计算，因此对数据中的异常值或“重尾”分布极为敏感，而这在真实世界数据集中很常见。为了得到更可靠的估计结果，本练习将介绍稳健统计的核心思想，通过实现一个基于Huber损失函数的M估计量来构建稳健的双重差分模型。你将学习如何通过迭代重加权最小二乘法（IRLS）系统性地降低极端观测值的影响，并探索其抵御数据污染的能力。[@problem_id:3115350]", "problem": "考虑一个双时期、双组别的双重差分设置，其中单位 $i \\in \\{1,\\dots,n\\}$ 在时间 $t \\in \\{0,1\\}$ 被观测。令 $D_i \\in \\{0,1\\}$ 表示单位 $i$ 是否属于处理组（处理仅在处理后时期发生）。假设观测到的结果满足加性模型 $Y_{it} = \\mu + \\alpha_i + \\lambda_t + \\tau \\cdot (D_i \\cdot \\mathbf{1}\\{t=1\\}) + \\epsilon_{it}$，其中 $\\mu$ 是全局均值，$\\alpha_i$ 是单位固定效应，$\\lambda_t$ 是时间效应，$\\tau$ 是我们关注的处理效应，而 $\\epsilon_{it}$ 是误差项。在标准的平行趋势假设下，对时间进行一阶差分可以消除单位固定效应，从而得到每个单位的变化量\n$$\n\\Delta Y_i \\equiv Y_{i1} - Y_{i0} = \\lambda + \\tau D_i + u_i,\n$$\n其中 $\\lambda \\equiv \\lambda_1 - \\lambda_0$ 且 $u_i \\equiv \\epsilon_{i1} - \\epsilon_{i0}$。当存在重尾误差 $u_i$ 时，普通最小二乘法对异常值很敏感。为实现稳健性，考虑一种$M$-估计方法，该方法通过最小化应用于折叠后双重差分设定中回归残差的Huber损失：\n$$\n\\min_{\\beta_0, \\beta_1} \\sum_{i=1}^n \\rho_\\kappa\\!\\left(\\Delta Y_i - \\beta_0 - \\beta_1 D_i\\right),\n$$\n其中 $\\beta_0$ 代理 $\\lambda$，$\\beta_1$ 代理 $\\tau$，Huber损失定义为\n$$\n\\rho_\\kappa(z) = \n\\begin{cases}\n\\frac{1}{2} z^2,  \\text{若 } |z| \\le \\kappa, \\\\\n\\kappa |z| - \\frac{1}{2}\\kappa^2,  \\text{若 } |z|  \\kappa.\n\\end{cases}\n$$\n相关的得分函数是\n$$\n\\psi_\\kappa(z) = \\rho_\\kappa'(z) = \n\\begin{cases}\nz,  \\text{若 } |z| \\le \\kappa, \\\\\n\\kappa \\cdot \\mathrm{sign}(z),  \\text{若 } |z|  \\kappa.\n\\end{cases}\n$$\n此$M$-估计量的一种稳健实现是使用迭代重加权最小二乘法，其权重由 $\\psi_\\kappa$ 决定。对于标准化残差，通常选择$\\kappa = 1.345$以在正态误差下达到95%的效率。为了稳定迭代过程，使用从残差中通过中位数绝对偏差（MAD）估计的稳健尺度 $s$，即 $s = c_{\\mathrm{MAD}} \\cdot \\mathrm{MAD}$，其中 $c_{\\mathrm{MAD}} = 1.4826$。\n\n您的任务是：\n- 从第一性原理推导出一个算法，用于计算在折叠后的双重差分残差上使用Huber损失的稳健$M$-估计量 $(\\hat{\\beta}_0, \\hat{\\beta}_1)$。在一个迭代重加权最小二乘方案中实现该算法，该方案在每次迭代中通过稳健尺度 $s$ 重新缩放残差，并根据Huber得分函数更新权重。\n- 使用与折叠模型 $\\Delta Y_i = \\lambda + \\tau D_i + u_i$ 一致的合成数据生成过程，检验在重尾误差和对抗性污染下，$\\tau$ 的稳健估计量的实际崩溃行为。具体而言：\n  - 对每个 $i$ 独立地生成 $D_i \\sim \\mathrm{Bernoulli}(p_T)$。\n  - 从自由度为 $\\nu$ 的学生t分布中生成 $u_i$。当 $\\nu  2$ 时，通过乘以 $\\sigma \\sqrt{\\frac{\\nu - 2}{\\nu}}$ 来缩放抽样值，使其方差为 $\\sigma^2$；当 $\\nu \\le 2$ 时，仅乘以 $\\sigma$ 以确定名义尺度。\n  - 构建 $\\Delta Y_i = \\lambda + \\tau D_i + u_i$。\n  - 通过均匀随机选择一部分比例为 $p$ 的索引，并添加符号随机、幅度为 $A$ 的大异常值来模拟对抗性污染，即对于这些索引，将 $\\Delta Y_i$ 替换为 $\\Delta Y_i + s_i A$，其中 $s_i \\in \\{-1, +1\\}$。\n- 将实际崩溃准则定义如下：对于给定的污染比例 $p$，计算稳健估计值 $\\hat{\\tau}(p)$，如果 $|\\hat{\\tau}(p) - \\tau|  \\delta_{\\mathrm{tol}}$（其中 $\\delta_{\\mathrm{tol}}$ 是一个固定的容忍度），则宣告崩溃。实际崩溃点是在指定网格上导致宣告崩溃的最小 $p$ 值。\n- 实现该程序，以计算在一系列污染比例 $p \\in \\{0, 0.05, 0.10, \\dots, 0.50\\}$ 网格上的实际崩溃点。\n\n使用以下参数化测试套件（所有标量均以与结果相同的单位给出，自由度无单位）。对于每个测试用例，您必须：\n- 使用固定的随机种子模拟 $\\Delta Y_i$ 和 $D_i$ 以确保可复现性。\n- 在指定的网格上计算实际崩溃点。\n- 将实际崩溃点以 $[0,1]$ 范围内的十进制数形式返回，四舍五入到三位小数。如果在网格内没有发生崩溃，则返回网格中的最大值。\n\n测试套件：\n- 案例1：$n = 800$, $p_T = 0.5$, $\\tau = 2$, $\\lambda = 0$, $\\nu = 5$, $\\sigma = 1$, $A = 1000$, $\\delta_{\\mathrm{tol}} = 1.0$, 种子 $= 12345$。\n- 案例2：$n = 800$, $p_T = 0.5$, $\\tau = 2$, $\\lambda = 0$, $\\nu = 2$, $\\sigma = 1$, $A = 1000$, $\\delta_{\\mathrm{tol}} = 1.0$, 种子 $= 23456$。\n- 案例3：$n = 800$, $p_T = 0.5$, $\\tau = 2$, $\\lambda = 0$, $\\nu = 1$, $\\sigma = 1$, $A = 1000$, $\\delta_{\\mathrm{tol}} = 1.0$, 种子 $= 34567$。\n- 案例4：$n = 100$, $p_T = 0.5$, $\\tau = 2$, $\\lambda = 0$, $\\nu = 2$, $\\sigma = 1$, $A = 1000$, $\\delta_{\\mathrm{tol}} = 1.0$, 种子 $= 45678$。\n\n您的程序应生成单行输出，其中包含四个测试用例的实际崩溃点，格式为逗号分隔的列表并用方括号括起，例如 $[\\text{result1},\\text{result2},\\text{result3},\\text{result4}]$。所有四个值都必须是四舍五入到三位小数的十进制数。", "solution": "所提供的问题被视为有效。它提出了一个定义明确的任务，该任务属于稳健统计学领域，并应用于一个标准的计量经济学模型——双重差分（DiD）框架。模拟和估计所需的所有必要参数和条件都已提供。\n\n问题的核心是使用迭代重加权最小二乘（IRLS）算法为DiD模型实现一个$M$-估计量。我们首先从第一性原理推导出该算法，然后描述如何在一个模拟研究中实现它，以确定该估计量的实际崩溃点。\n\n### 算法推导：用于Huber DiD的迭代重加权最小二乘法\n\n问题是找到参数 $(\\hat{\\beta}_0, \\hat{\\beta}_1)$，使其最小化残差的Huber损失之和：\n$$\n\\min_{\\beta_0, \\beta_1} \\sum_{i=1}^n \\rho_\\kappa\\left(\\Delta Y_i - \\beta_0 - \\beta_1 D_i\\right)\n$$\n这里，$\\beta_0$ 是时间趋势 $\\lambda$ 的估计量，$\\beta_1$ 是处理效应 $\\tau$ 的估计量。为使估计量具有尺度不变性，残差 $r_i = \\Delta Y_i - (\\beta_0 + \\beta_1 D_i)$ 通过一个稳健的尺度度量 $s$ 进行标准化。然后将最小化问题应用于缩放后的残差。通过对目标函数关于 $\\beta_0$ 和 $\\beta_1$ 求导并将结果设为零，可以得到一阶条件。使用得分函数 $\\psi_\\kappa(z) = \\rho_\\kappa'(z)$，估计方程为：\n$$\n\\begin{align*}\n\\frac{\\partial}{\\partial \\beta_0}: \\quad  \\sum_{i=1}^n -\\psi_\\kappa\\left(\\frac{\\Delta Y_i - \\beta_0 - \\beta_1 D_i}{s}\\right) = 0 \\\\\n\\frac{\\partial}{\\partial \\beta_1}: \\quad  \\sum_{i=1}^n -\\psi_\\kappa\\left(\\frac{\\Delta Y_i - \\beta_0 - \\beta_1 D_i}{s}\\right) D_i = 0\n\\end{align*}\n$$\n这些方程构成了关于 $\\beta_0$ 和 $\\beta_1$ 的非线性方程组。IRLS算法提供了一个求解该方程组的迭代过程。我们为每个观测值 $i$ 定义一个权重 $w_i = \\psi_\\kappa(z_i) / z_i$，其中 $z_i = r_i/s$ 是缩放后的残差。根据这个定义，得分函数可以写成 $\\psi_\\kappa(z_i) = w_i z_i$。将此代入估计方程，得到：\n$$\n\\begin{align*}\n\\sum_{i=1}^n w_i \\frac{r_i}{s} = 0 \\quad \\implies \\quad \\sum_{i=1}^n w_i (\\Delta Y_i - \\beta_0 - \\beta_1 D_i) = 0 \\\\\n\\sum_{i=1}^n w_i \\frac{r_i}{s} D_i = 0 \\quad \\implies \\quad \\sum_{i=1}^n w_i (\\Delta Y_i - \\beta_0 - \\beta_1 D_i) D_i = 0\n\\end{align*}\n$$\n这些是 $\\Delta Y_i$ 对截距项和 $D_i$ 进行加权最小二乘（WLS）回归的正规方程，权重为 $w_i$。对于双组模型（控制组 $D_i=0$，处理组 $D_i=1$）的特定情况，$\\beta_0$ 和 $\\beta_1$ 的WLS解会大大简化。参数 $\\beta_0$ 代表控制组的（加权）平均结果，而 $\\beta_0+\\beta_1$ 代表处理组的（加权）平均结果。\n$$\n\\hat{\\beta}_0 = \\frac{\\sum_{i:D_i=0} w_i \\Delta Y_i}{\\sum_{i:D_i=0} w_i} \\qquad \\text{和} \\qquad \\hat{\\beta}_0 + \\hat{\\beta}_1 = \\frac{\\sum_{i:D_i=1} w_i \\Delta Y_i}{\\sum_{i:D_i=1} w_i}\n$$\n由此，处理效应 $\\tau$ 的估计值为：\n$$\n\\hat{\\beta}_1 = \\hat{\\tau} = \\frac{\\sum_{i:D_i=1} w_i \\Delta Y_i}{\\sum_{i:D_i=1} w_i} - \\frac{\\sum_{i:D_i=0} w_i \\Delta Y_i}{\\sum_{i:D_i=0} w_i}\n$$\n由于权重 $w_i$ 依赖于残差 $r_i$，而残差又依赖于 $\\beta_0$ 和 $\\beta_1$，这表明需要一个迭代解法。\n\n### IRLS算法流程\n\n1.  **初始化**：从一个初始估计值 $\\boldsymbol{\\hat{\\beta}}^{(0)} = (\\hat{\\beta}_0^{(0)}, \\hat{\\beta}_1^{(0)})$ 开始。一个简单的选择是普通最小二乘（OLS）估计，这对应于将所有权重 $w_i$ 设为1。\n2.  **迭代**：对于每一步 $k=0, 1, 2, \\dots$：\n    a.  计算残差：$r_i^{(k)} = \\Delta Y_i - (\\hat{\\beta}_0^{(k)} + \\hat{\\beta}_1^{(k)} D_i)$。\n    b.  使用残差的中位数绝对偏差（MAD）估计稳健尺度 $s^{(k)}$：$s^{(k)} = c_{\\mathrm{MAD}} \\cdot \\mathrm{median}_i(|r_i^{(k)} - \\mathrm{median}_j(r_j^{(k)})|)$，常数 $c_{\\mathrm{MAD}}=1.4826$ 是为了在正态误差分布下保持一致性。如果 $s^{(k)}$ 接近于零，可以停止迭代。\n    c.  计算缩放后的残差 $z_i^{(k)} = r_i^{(k)} / s^{(k)}$。\n    d.  基于参数为 $\\kappa = 1.345$ 的Huber函数计算新权重 $w_i^{(k+1)}$：\n        $$\n        w_i^{(k+1)} = \\begin{cases} 1  \\text{若 } |z_i^{(k)}| \\le \\kappa \\\\ \\kappa / |z_i^{(k)}|  \\text{若 } |z_i^{(k)}|  \\kappa \\end{cases}\n        $$\n    e.  使用权重 $w_i^{(k+1)}$ 计算控制组和处理组的加权平均值，以更新参数估计：\n        $$\n        \\hat{\\beta}_0^{(k+1)} = \\frac{\\sum_{i:D_i=0} w_i^{(k+1)} \\Delta Y_i}{\\sum_{i:D_i=0} w_i^{(k+1)}} ; \\quad \\hat{\\beta}_1^{(k+1)} = \\frac{\\sum_{i:D_i=1} w_i^{(k+1)} \\Delta Y_i}{\\sum_{i:D_i=1} w_i^{(k+1)}} - \\hat{\\beta}_0^{(k+1)}\n        $$\n3.  **终止**：当系数向量 $\\boldsymbol{\\hat{\\beta}} = (\\hat{\\beta}_0, \\hat{\\beta}_1)^T$ 的相对变化小于一个小的容忍度，或达到最大迭代次数后，迭代停止。\n\n### 用于计算实际崩溃点的模拟\n\n实际崩溃点是通过向数据中注入比例渐增的对抗性异常值 $p$，并观察估计量 $\\hat{\\tau}(p)$ 何时与真实值 $\\tau$ 的偏差超过指定容忍度 $\\delta_{\\mathrm{tol}}$ 来确定的。\n\n1.  **数据生成**：对于固定的随机种子，生成一个“干净”的数据集。\n    -   处理指标 $D_i \\sim \\mathrm{Bernoulli}(p_T)$，对于 $i=1, \\dots, n$。\n    -   重尾误差 $u_i$ 从自由度为 $\\nu$ 的学生t分布中抽取，并由 $\\sigma$ 缩放（如果 $\\nu2$，则使用方差调整因子）。\n    -   构建结果变量：$\\Delta Y_i = \\lambda + \\tau D_i + u_i$。\n2.  **污染循环**：在污染比例 $p \\in \\{0, 0.05, \\dots, 0.50\\}$ 的网格上进行迭代。\n    -   对于每个 $p$，通过选择一个大小为 $\\lfloor p \\cdot n \\rfloor$ 的观测值随机子集，并加上一个大的值 $\\pm A$ 来创建一个受污染的数据集。\n3.  **估计与崩溃检查**：\n    -   对受污染的数据集应用上述IRLS算法，得到估计值 $\\hat{\\tau}(p)$。\n    -   检查崩溃准则：$|\\hat{\\tau}(p) - \\tau|  \\delta_{\\mathrm{tol}}$。\n    -   实际崩溃点是网格中第一个满足此准则的 $p$ 值。如果网格中没有任何 $p$ 值满足该准则，则崩溃点被认为至少是网格中的最大值，即0.50。", "answer": "```python\nimport numpy as np\n\ndef huber_did(Y, D, kappa=1.345, max_iter=100, tol=1e-6):\n    \"\"\"\n    Computes the Huber M-estimator for a collapsed difference-in-differences model\n    using Iteratively Reweighted Least Squares (IRLS).\n\n    Args:\n        Y (np.ndarray): vector of outcome changes (Delta Y_i).\n        D (np.ndarray): vector of treatment indicators (D_i).\n        kappa (float): Huber loss parameter for standardized residuals.\n        max_iter (int): Maximum number of iterations for IRLS.\n        tol (float): Convergence tolerance for the coefficient vector.\n\n    Returns:\n        float: The estimated treatment effect (beta_1).\n    \"\"\"\n    ctrl_mask = (D == 0)\n    treat_mask = (D == 1)\n    \n    if not np.any(ctrl_mask) or not np.any(treat_mask):\n        return np.nan # Should not happen with problem data generation\n        \n    # Initial estimate using Ordinary Least Squares (OLS)\n    beta0 = np.mean(Y[ctrl_mask])\n    mean_treat = np.mean(Y[treat_mask])\n    beta1 = mean_treat - beta0\n    beta = np.array([beta0, beta1])\n\n    for _ in range(max_iter):\n        beta_old = beta.copy()\n        \n        # 1. Compute residuals\n        residuals = Y - (beta[0] + beta[1] * D)\n        \n        # 2. Compute robust scale using Median Absolute Deviation (MAD)\n        median_residuals = np.median(residuals)\n        mad = np.median(np.abs(residuals - median_residuals))\n        \n        # Scale factor c_MAD for consistency at the Normal model\n        scale = 1.4826 * mad\n        \n        # If scale is near-zero, residuals are likely constant.\n        # The unweighted estimate is stable and optimal.\n        if scale  1e-8:\n            break\n            \n        # 3. Compute Huber weights\n        z = residuals / scale\n        weights = np.ones_like(z)\n        huber_idx = np.abs(z) > kappa\n        weights[huber_idx] = kappa / np.abs(z[huber_idx])\n        \n        # 4. Update estimates via Weighted Least Squares (WLS)\n        # For the two-group case, this simplifies to weighted means.\n        w_ctrl = weights[ctrl_mask]\n        Y_ctrl = Y[ctrl_mask]\n        sum_w_ctrl = np.sum(w_ctrl)\n        \n        w_treat = weights[treat_mask]\n        Y_treat = Y[treat_mask]\n        sum_w_treat = np.sum(w_treat)\n        \n        # Pathological case: if all weights in a group are zero, revert to OLS.\n        if sum_w_ctrl  1e-8 or sum_w_treat  1e-8:\n            beta0 = np.mean(Y[ctrl_mask])\n            mean_treat = np.mean(Y[treat_mask])\n            beta1 = mean_treat - beta0\n            beta = np.array([beta0, beta1])\n            break\n\n        beta0_new = np.sum(w_ctrl * Y_ctrl) / sum_w_ctrl\n        mean_treat_new = np.sum(w_treat * Y_treat) / sum_w_treat\n        beta1_new = mean_treat_new - beta0_new\n        beta = np.array([beta0_new, beta1_new])\n\n        # 5. Check for convergence\n        rel_diff = np.linalg.norm(beta - beta_old) / (np.linalg.norm(beta_old) + 1e-8)\n        if rel_diff  tol:\n            break\n            \n    return beta[1]\n\ndef find_breakdown_point(n, p_T, tau, lam, nu, sigma, A, delta_tol, seed):\n    \"\"\"\n    Simulates data and finds the practical breakdown point of the Huber DiD estimator.\n    \n    Returns:\n        float: The smallest contamination fraction 'p' that causes breakdown, \n               rounded to three decimal places.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    # 1. Generate clean data\n    D = rng.binomial(1, p_T, size=n)\n    u_raw = rng.standard_t(nu, size=n)\n    \n    if nu > 2:\n        scale_factor = sigma * np.sqrt((nu - 2) / nu)\n    else:\n        scale_factor = sigma\n    u = u_raw * scale_factor\n    \n    Delta_Y_clean = lam + tau * D + u\n    \n    # 2. Iterate over contamination grid\n    p_grid = np.arange(0.0, 0.51, 0.05)\n    all_indices = np.arange(n)\n\n    for p in p_grid:\n        Delta_Y_contaminated = Delta_Y_clean.copy()\n        n_outliers = int(round(p * n))\n        \n        if n_outliers > 0:\n            outlier_indices = rng.choice(all_indices, size=n_outliers, replace=False)\n            signs = rng.choice([-1, 1], size=n_outliers)\n            Delta_Y_contaminated[outlier_indices] += signs * A\n            \n        # 3. Estimate effect and check for breakdown\n        tau_hat = huber_did(Delta_Y_contaminated, D)\n        \n        if np.abs(tau_hat - tau) > delta_tol:\n            return round(p, 3)\n            \n    # If no breakdown occurred, return the largest p value\n    return round(p_grid[-1], 3)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        # n, p_T, tau, lambda, nu, sigma, A, delta_tol, seed\n        (800, 0.5, 2, 0, 5, 1, 1000, 1.0, 12345),\n        (800, 0.5, 2, 0, 2, 1, 1000, 1.0, 23456),\n        (800, 0.5, 2, 0, 1, 1, 1000, 1.0, 34567),\n        (100, 0.5, 2, 0, 2, 1, 1000, 1.0, 45678),\n    ]\n\n    results = []\n    for case_params in test_cases:\n        result = find_breakdown_point(*case_params)\n        results.append(f\"{result:.3f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3115350"}]}