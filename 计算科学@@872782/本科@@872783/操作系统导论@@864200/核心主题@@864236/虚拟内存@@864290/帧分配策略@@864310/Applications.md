## 应用与跨学科联系

在前面的章节中，我们详细探讨了帧分配策略的核心原则与机制，特别是局部与全局分配这两种基本方法的实现细节。然而，这些策略并非孤立存在于理论之中。它们是[操作系统](@entry_id:752937)设计中的关键决策点，其影响深远，渗透到现代计算系统的性能、正确性、安全性乃至[能效](@entry_id:272127)等多个层面。本章的使命是带领读者超越基本定义，通过一系列面向应用的场景，探索这些核心原则在多样化、真实且跨学科的背景下是如何被运用、扩展和整合的。

我们的目标不是重复讲授核心概念，而是展示它们的实际效用。我们将看到，帧分配策略的选择并非一个简单的“效率与隔离”之间的权衡，而是一个与硬件架构、其他[操作系统](@entry_id:752937)子系统以及更广泛的系统级目标（如安全性和能效）紧密耦合的复杂决策。通过本章的学习，您将能够更深刻地理解，为何一个看似基础的[内存管理](@entry_id:636637)决策，会对从高性能计算集群到移动设备、从数据库系统到机器学习应用的各种计算场景产生决定性的影响。

### 现代硬件架构中的性能影响

帧分配策略与底层硬件的交互方式直接决定了系统的整体性能。随着处理器和内存系统变得日益复杂，一种“一刀切”的分[配方法](@entry_id:265480)已不再适用。理解策略与硬件之间的协同作用对于发挥硬件潜力至关重要。

#### [多处理器系统](@entry_id:752329)与一致性开销

在对称多处理（SMP）系统中，多个处理器核心共享主内存，这引入了缓存和[地址转换](@entry_id:746280)一致性的挑战。全局帧分配策略虽然提供了灵活性，但也可能带来显著的系统开销。当一个核心上的进程（例如，$P_j$）发生页错误并根据全局策略决定收回另一个核心上进程（$P_i$）的物理帧时，[操作系统](@entry_id:752937)必须使 $P_i$ 的页表项失效。如果 $P_i$ 的[地址转换](@entry_id:746280)信息被缓存在其所在核心的转换后备缓冲区（TLB）中，那么系统就必须发起一次代价高昂的“[TLB击落](@entry_id:756023)”（TLB Shootdown）。这通常通过处理器间中断（IPI）实现，强制目标核心刷新其TLB，以防止使用过时的[地址映射](@entry_id:170087)。

在一个拥有多个核心的系统中，如果每个核心都运行着独立的进程，全局替换策略会频繁地触发跨核心的页回收。例如，在一个4核系统中，每个核心运行一个独立的、以恒定速率产生[缺页](@entry_id:753072)的进程，一个完全随机的全局替换算法有高达 $75\%$ 的概率会选择一个不属于当前缺页进程的帧作为牺牲品。这意味着系统中的绝大多数缺页都会引发一次跨核心的[TLB击落](@entry_id:756023)。这种持续的跨核心中断和[TLB刷新](@entry_id:756020)会严重影响所有进程的执行效率，即使是那些本身行为良好、内存访问模式稳定的进程 [@problem_id:3645264]。

相比之下，局部帧分配策略天然地提供了隔离。由于每个进程只能在自己分配的帧集合内进行替换，因此一个进程的缺页不会导致其他进程的帧被回收。在这种模式下，[TLB击落](@entry_id:756023)事件仅限于进程自身行为（如`munmap`），而不会因其他进程的内存压力而引发。一个长期运行的进程，如果其[工作集](@entry_id:756753)稳定且小于其分配的帧数，在局部策略下可以实现接近 $100\%$ 的TLB命中率。然而，在全局策略下，即使该进程的[工作集](@entry_id:756753)远小于TLB容量，来自其他进程的内存压力所导致的频繁[TLB击落](@entry_id:756023)也会持续地使其TLB条目失效，从而显著降低其TLB命中率，引入额外的内存访问延迟 [@problem_id:3645297]。

#### 缓存感知与NUMA感知分配

内存访问性能不仅取决于TLB，还严重依赖于末级缓存（LLC）的命中率。在物理索引的缓存中，物理地址的一部分位被用来确定数据存放在哪个缓存组（cache set）。如果多个活跃的内存页碰巧映射到同一个缓存组，而该组的关联度（associativity）不足以容纳所有这些页的缓存行，就会发生“缓存冲突[抖动](@entry_id:200248)”（cache conflict thrashing），导致命中率急剧下降。

帧分配策略与一种称为“页着色”（page coloring）的技术相结合，可以有效地管理LLC的使用。页着色根据物理帧号中参与缓存组索引的位，将物理页分为不同的“颜色”。聪明的[操作系统](@entry_id:752937)可以将不同进程分配到不同颜色的物理页上。局部帧分配策略与页着色是天作之合：通过为每个进程分配一组互不相交的颜色，[操作系统](@entry_id:752937)可以确保不同进程的内存访问在LLC层面完全隔离，它们的数据会映射到不同的缓存组中，从而消除跨进程的缓存冲突。只要每个进程在单一颜色上的页需求不超过缓存的关联度，就可以避免[抖动](@entry_id:200248)。

然而，如果采用一个对颜色不敏感的全局分配策略，情况则可能恶化。例如，一个简单的全局分配器可能倾向于从一个连续的空闲帧列表中分配内存。这可能导致多个原本不相关的进程被不经意地分配到同一组狭窄的颜色范围内。在这种情况下，尽管系统总内存充足，但这些进程会在LLC的特定组上产生激烈的竞争，导致严重的性能下降。这表明，全局策略的潜在效率优势，可能会被其对底层缓存硬件的忽视所抵消 [@problem_id:3645332]。

在[非一致性内存访问](@entry_id:752608)（NUMA）架构中，处理器访问本地内存节点的延迟远低于访问远程节点的延迟。这为帧分配策略提出了新的挑战。
-   **节点局部化分配**：这是一种严格的局部策略，强制一个进程的所有内存都在其运行的CPU所在的NUMA节点上分配。这保证了最低的内存访问延迟，但代价是该进程可用的内存量受限于单个节点的容量。
-   **跨节点全局分配**：当本地节点内存不足时，允许进程的页被分配到远程节点上。这为进程提供了更大的内存空间，但代价是部分内存访问会跨越节点间互联，产生更高的延迟。

我们可以构建一个平均内存访问延迟模型来量化这种权衡。平均延迟是LLC命中、本地DRAM访问和远程D[RAM](@entry_id:173159)访问这三种情况的加权平均，权重取决于LLC的未命中率 $w$ 和页被放置在远程节点的概率 $\rho$。一个典型的模型如下：
$$L(w, \rho) = (1-w)L_{\mathrm{LLC}} + w(1-\rho)L_{\mathrm{local}} + w\rho L_{\mathrm{remote}}$$
全局策略下产生的跨节点流量，对于那些需要高带宽和低延迟的科学计算应用来说，是一个至关重要的性能指标。这个流量可以通过进程的总引用率、LLC未命中率、远程[分配比](@entry_id:183708)例以及缓存行大小来精确计算。不当的跨节点分配会迅速饱和节点间的互连带宽，成为整个系统的性能瓶颈 [@problem_id:3645241]。一种常见的NUMA感知分配策略是“首次接触”（first-touch）策略。在这种策略下，一个页面的物理帧会分配给首次对其进行写操作的线程所在的NUMA节点。通过将线程固定（pinning）到特定节点，并将数据初始化任务合理地[分布](@entry_id:182848)在这些线程之间，开发者可以精确地控制数据布局，从而最大限度地提高内存访问的局部性。然而，如果后续的计算阶段需要线程访问由其他节点上的线程初始化的数据，远程访问就在所难免。对这类访问模式的分析，可以揭示特定算法在[NUMA架构](@entry_id:752764)下的固有[通信开销](@entry_id:636355) [@problem_id:3663614]。

#### [异构计算](@entry_id:750240)：CPU-GPU交互

现代系统广泛采用图形处理器（GPU）进行[通用计算](@entry_id:275847)。统一内存（Unified Memory）模型允许CPU和GPU共享同一个[虚拟地址空间](@entry_id:756510)，简化了编程。在这种模型下，内存页可以在主机（CPU）和设备（GPU）之间按需迁移。当CPU访问一个位于GPU显存中的页时，会触发[缺页中断](@entry_id:753072)，将该页迁移回主机内存；反之亦然。

主机端的帧分配策略对这种异构系统的性能有着微妙而深刻的影响。考虑一个场景，进程 $P_1$ 在GPU上运行一个计算密集型内核，该内核依赖于一组托管页（managed pages）驻留在GPU显存中以获得高性能。同时，$P_1$ 的CPU线程也需要少量主机内存来执行控制任务。与此同时，另一个纯CPU进程 $P_2$ 正在运行，它有巨大的内存需求并持续产生缺页压力。

-   在**全局分配**策略下，$P_2$ 的[缺页](@entry_id:753072)压力会导致OS从全局池中回收帧，其中可能就包括属于 $P_1$ 的CPU工作集的帧。这会使 $P_1$ 的CPU端也开始频繁[缺页](@entry_id:753072)。更关键的是，如果 $P_1$ 的CPU端需要访问一个本应驻留在GPU上的托管页（例如，检查计算状态），但由于自身CPU[工作集](@entry_id:756753)被侵蚀而不得不重新从磁盘加载某些代码或数据页，这期间它可能会“意外地”接触到本应由GPU独占的托管页的地址。根据统一内存规则，这次CPU访问会触发一个从GPU到CPU的页迁移。这种不必要的迁移会严重干扰GPU内核的执行，因为它必须等待数据被移走，或者在后续访问时再等待数据被移回来。

-   在**局部分配**策略下，可以为 $P_1$ 和 $P_2$ 设置独立的帧配额。通过为 $P_1$ 提供足够满足其CPU[工作集](@entry_id:756753)的帧，我们可以将其与 $P_2$ 的内存颠簸（thrashing）[行为隔离](@entry_id:167102)开来。$P_1$ 的CPU端运行稳定，不会因内存压力而去意外触碰GPU托管页，从而保证了这些关键数据在GPU上的驻留，确保了计算内核的高性能 [@problem_id:3645298]。

### 与其他[操作系统](@entry_id:752937)子系统的交互

帧分配策略的选择并非[内存管理](@entry_id:636637)模块的内部事务，它与其他核心OS子系统（如[进程调度](@entry_id:753781)器和I/O管理器）的功能紧密交织。

#### 调度与内存感知

多级反馈队列（MLFQ）是一种常见的[CPU调度算法](@entry_id:748021)，它根据进程的行为（如CPU突发时间）动态调整其优先级。然而，一个进程的性能瓶颈可能并非CPU，而是内存。如果一个进程因为分配到的帧数少于其[工作集](@entry_id:756753)大小而不断地产生[缺页中断](@entry_id:753072)，那么即使给它再高的CPU优先级也无济于事。

这就引出了一种将调度与[内存管理](@entry_id:636637)相结合的“内存感知调度”（memory-aware scheduling）思想。例如，一个MLFQ调度器可以增加一条规则：当一个进程的[缺页率](@entry_id:753068)超过某个阈值时，自动提升其优先级。这种提升的有效性，完全取决于底层的帧分配策略。

-   在一个采用**局部帧分配**并为每个优先级队列设置硬性**内存预算**的系统中，这种提升是有效的。例如，一个在低优先级队列（预算较小）中[抖动](@entry_id:200248)的进程，在被提升到高优先级队列（预算较大）后，获得了更多的内存帧。如果新的预算足以容纳其[工作集](@entry_id:756753)，它的[缺页率](@entry_id:753068)就会下降，性能问题得到解决。

-   然而，在一个采用**优先级无关的全局分配**策略的系统中，这种提升则毫无意义。所有进程都在同一个内存池中竞争。提升一个进程的CPU优先级，并不会让它在争夺内存帧时获得任何优势。即使一个进程被提升到了最高优先级队列，它仍然可能因为整个系统的内存超额认购而被全局替换算法选中，其帧被回收。

这个例子清晰地表明，有效的系统调优需要调度器和[内存管理](@entry_id:636637)器协同工作。局部（或基于优先级的）分配策略为这种协同提供了必要的机制，而一个简单的全局策略则使这两个子系统的工作彼此脱节 [@problem_id:3645335]。

#### I/O与特殊内存类型

[操作系统](@entry_id:752937)需要处理各种特殊类型的内存，它们不能像普通的用户页一样被自由换出。一个典型的例子是用于设备驱动的**[内存映射](@entry_id:175224)I/O（MMIO）**或**直接内存访问（DMA）**的缓冲区。这些页必须被“钉”（pinned）在物理内存中，即标记为不可驱逐，因为硬件设备需要通过固定的物理地址直接访问它们。

这些不可驱逐的页对全局帧分配策略构成了严峻挑战。在一个全局池中，每一页被钉住，都意味着可供所有其他进程使用的、可替换的帧永久性地减少了一个。如果一个进程（如设备驱动）钉住了大量的内存，它实际上是在未被记账的情况下，悄悄地挤压了系统中所有其他进程的生存空间。这可能导致一个看似内存充足的系统，实际上其可驱逐的帧池已经严重超额，导致其他应用程序陷入[抖动](@entry_id:200248)。例如，在一个总共有200个帧的系统中，如果一个驱动程序钉住了80个帧，那么所有用户进程只能在剩下的120个帧中竞争。如果这些进程的总工作集超过120帧，系统就会发生[抖动](@entry_id:200248)，即使总需求（例如140帧）远小于系统总容量（200帧） [@problem_id:3645326]。

为了维护系统的稳定性和公平性，必须引入“护栏”（guardrails）。有效的护栏策略本质上都是对纯粹全局策略的修正，融入了局部化的思想：
1.  **记账与准入控制**：将一个进程钉住的帧数，计入该进程的内存配额。在允许一个新进程运行之前，执行准入控制，确保所有已运行进程（包括其钉住的内存）的总需求不超过物理内存总量。
2.  **内存池划分**：创建一个专门用于钉住内存的保留池，并将其与通用的、可驱逐的内存池分离开来。页替换守护进程只在可驱逐的池中工作。

近年来兴起的**持久性内存（PMEM）**带来了新的挑战。通过直接访问（DAX）模式，应用程序可以将PMEM文件直接映射到其地址空间，绕过[页缓存](@entry_id:753070)，以获得极低的访问延迟。使用DAX的应用程序（如数据库）通常会实现自己的[崩溃一致性](@entry_id:748042)协议，这依赖于对内存写操作、缓存行写回（cache line write-back）和[内存栅栏](@entry_id:751859)（memory fence）的精确控制。这种协议的正确性，隐含地假设了虚拟到物理的映射是稳定的，不会被[操作系统](@entry_id:752937)任意篡改。

如果[操作系统](@entry_id:752937)将一个天真的全局替换策略扩展到DAX映射的PMEM帧上，允许在DRAM压力大时回收一个“干净”的PMEM帧，这将破坏DAX的语义契约。即使数据已经持久化，但[操作系统](@entry_id:752937)单方面地解除映射，会使应用程序的逻辑崩溃——它可能持有指向该内存的指针，并期望它永远有效。这种干预破坏了应用程序对其持久化过程的直接控制。因此，正确的策略必须将DAX映射的帧从全局牺牲品集合中豁免，将它们视为一种特殊的、由应用管理的局部资源 [@problem_id:3645311]。

### 更广泛的系统级关注点

帧分配策略的影响超越了单一计算机的内部运作，延伸到应用层行为、系统安全和能源效率等更广泛的领域。

#### 安全性与[信息泄露](@entry_id:155485)

在多用户或[虚拟化](@entry_id:756508)环境中，隔离是安全的基础。局部帧分配策略通过在进程间建立内存“防火墙”，提供了一种天然的性能隔离。令人惊讶的是，这种隔离同样具有安全意义。全局帧分配策略由于其内在的跨进程干扰，可能引入一种微妙的“[侧信道](@entry_id:754810)”（side channel），让恶意进程能够窥探其他进程的行为。

地址空间布局随机化（ASLR）是一种关键的安全机制，它通过随机化进程的[内存布局](@entry_id:635809)（如栈、堆、库的位置）来阻止攻击者预测特定代码或数据的位置。然而，在全局LRU替换策略下，一个攻击者进程可以通过精心构造自己的内存访问模式，来推断一个受害者进程的内存使用情况。攻击者可以逐步增加自己使用的内存页数 $k$，同时精确测量自身的[缺页率](@entry_id:753068)或内存访问延迟。当 $k$ 增加到一个[临界点](@entry_id:144653)，使得攻击者和受害者的总[工作集](@entry_id:756753)大小恰好超过系统总物理帧数时，系统开始发生[抖动](@entry_id:200248)，攻击者的性能会急剧下降。通过识别这个“性能悬崖”，攻击者就能推断出受害者进程的工作集大小。虽然这并未直接破解ASLR（因为它没有揭示虚拟地址），但它泄露了关于受害者行为的重要信息。

相比之下，局部帧分配策略完全关闭了这种基于内存争用的[侧信道](@entry_id:754810)。由于每个进程都在其固定的帧配额内运行，一个进程的内存行为完全不会影响另一个进程的[缺页率](@entry_id:753068)。这再次凸显了局部策略在提供可预测和安全环境方面的重要性 [@problem_id:3645261]。

#### 应用层内存管理

许多现代应用，特别是那些运行在沙箱化语言运行时（如Java[虚拟机](@entry_id:756518)JVM或JavaScript引擎）中的应用，都拥有自己的内部内存管理器，其中最核心的就是垃圾回收器（GC）。这类应用的[性能调优](@entry_id:753343)，通常涉及设置一个堆大小（heap target），以在GC频率和内存占用之间取得平衡。

[操作系统](@entry_id:752937)的帧分配策略决定了这个“设置堆大小”任务的难易程度和可预测性。
-   在**局部帧分配**下，[操作系统](@entry_id:752937)为每个运行时实例提供了一个固定的内存上限（cap）。这就像给了每个应用一个硬性的“内存容器”。应用开发者或管理员可以放心地将堆大小设置为接近但不超过这个上限的值，因为他们知道，只要应用的工作集在这个范围内，就不会受到来自外部的干扰。性能隔离得到了保证。
-   在**全局帧分配**下，这个容器的边界是“柔软”且不确定的。一个JVM实例将其堆大小调大，会增加整个系统的内存需求。如果总需求超过了物理内存，全局替换算法可能会从其他JVM或JS实例中窃取帧，导致它们的性能下降。这使得[性能调优](@entry_id:753343)变得异常困难，因为一个应用的“最佳”堆大小，会动态地依赖于所有其他共存应用的行为。为了避免整个系统[抖动](@entry_id:200248)，所有应用的堆目标必须被协同管理，以确保它们的总[工作集](@entry_id:756753)之和不超过物理内存。

因此，当性能隔离是首要需求时（如在多租户云环境中），局部配额是合适的选择。当目标是最大化整个系统的吞吐量且应用需求多变时，全局共享可能更有效率，但需要上层的协调机制来防止灾难性的全局[抖动](@entry_id:200248) [@problem_id:3645294]。

#### 能源效率

在移动和嵌入式设备中，能源消耗是一个一级设计约束。[缺页](@entry_id:753072)和页驱逐都是耗能的操作。[缺页](@entry_id:753072)需要访问慢速的存储设备（如[闪存](@entry_id:176118)），而驱逐一个“脏”页则需要将其内容[写回](@entry_id:756770)存储，这两者都会消耗显著的能量。一个简单的线性模型可以近似地描述这种能耗：$E = \alpha \cdot \text{faults} + \beta \cdot \text{evictions}$。

帧分配策略直接影响缺页和驱逐的次数，从而影响[能效](@entry_id:272127)。这两种策略孰优孰劣，同样取决于具体的工作负载。
-   在一个场景中，一个进程的活动非常集中，[工作集](@entry_id:756753)很小，而另一个进程的内存需求量很大但时断时续。全局分配策略可能更节能，因为它允许第二个进程在需要时“借用”第一个进程暂时闲置的帧，避免了不必要的磁盘I/O。
-   在另一个场景中，两个进程都有中等大小的工作集，它们的总和略大于系统的物理内存。全局分配会导致两个进程相互干扰，不断地从对方那里窃取帧，引发持续的[抖动](@entry_id:200248)和高能耗。而局部策略，通过为每个进程分配一个略小于其工作集的固定配额，虽然会导致每个进程内部有一定的[缺页](@entry_id:753072)，但可以避免灾难性的跨进程干扰，总能耗可能反而更低 [@problem_id:3645262]。

### 形式化分析与高级视角

除了经验性的场景分析，我们还可以借助更严谨的数学工具来理解和比较帧分配策略。[控制论](@entry_id:262536)和博弈论为此提供了强大的形式化语言。

#### 控制论视角：稳定性和耦合

我们可以将动态帧分配[过程建模](@entry_id:183557)为一个[反馈控制系统](@entry_id:274717)。[操作系统](@entry_id:752937)的目标是调节每个进程的帧分配量 $F_i$，以使其观测到的[缺页率](@entry_id:753068) $r_i$ 稳定在一个期望的目标值 $r_i^\star$。控制器的输入是误差 $e_i = r_i - r_i^\star$，输出是帧分配的调整量。

-   **局部策略**对应于一组**解耦的单输入单输出（SISO）**控制系统。每个进程的帧分配 $F_i(k+1)$ 只依赖于其自身的误差 $e_i(k)$。系统的动态特性由一组独立的方程描述，其稳定性可以独立分析。
-   **全局策略**则是一个**耦合的多输入多输出（MIMO）**系统。一个进程的帧分配 $F_1(k+1)$ 不仅依赖于自身的误差 $e_1(k)$，还受到其他进程误差 $e_2(k)$ 的影响（因为帧是在它们之间重新分配的）。

对这些系统进行线性化分析，可以揭示一个深刻的结论：耦合会影响系统的稳定性。在某些参数下，原本在解耦（局部）系统中稳定的[控制器增益](@entry_id:262009) $k$，在耦合（全局）系统中可能会导致系统不稳定（例如，产生[振荡](@entry_id:267781)或发散）。这意味着，全局策略虽然可能更灵活，但其动态行为更复杂，控制器的“[稳定裕度](@entry_id:265259)”可能更小。设计一个稳定且性能良好的全局动态分配器，比为每个进程设计独立的局部控制器更具挑战性 [@problem_id:3645314]。

#### 博弈论视角：均衡与[最优策略](@entry_id:138495)

我们还可以将此问题建模为一个**[微分](@entry_id:158718)博弈**。在这个博弈中，每个进程都是一个“自私”的参与者，它选择自己的内存访问率 $a_i$ 以最大化自身的效用（例如，计算吞吐量减去缺页和内存占用成本）。[操作系统](@entry_id:752937)则扮演一个“社会规划者”的角色，它选择一个混合了局部和全局策略的参数 $\theta$，以最小化整个系统的总成本（所有进程的成本之和，加上全局策略带来的额外开销，如[TLB击落](@entry_id:756023)或帧迁移）。

通过求解这个博弈的纳什均衡，我们可以找到在给定的OS策略 $\theta$ 下，进程会如何理性地反应，达到一个稳定的访问率 $(a_1^\star(\theta), a_2^\star(\theta))$。然后，[操作系统](@entry_id:752937)可以在此基础上，通过选择 $\theta$ 来优化其目标。这种分析可能会揭示一些非直观的结果。例如，在某些效用和成本结构下，即使全局策略（$\theta  0$）能够根据需求更精确地匹配资源，但它引入的耦合项和系统开销可能会使得总社会成本随 $\theta$ 的增加而增加。在这种情况下，最优的OS策略竟然是纯粹的局部静态划分（$\theta^\star = 0$），因为它避免了所有协调成本和博弈的复杂性 [@problem_id:3645304]。

### 结论

本章的旅程从硬件的深处一直延伸到抽象的数学模型。我们看到，局部与全局帧分配策略之间的选择，远非一个简单的静态决策。它是一个贯穿整个[系统设计](@entry_id:755777)的核心主题，其影响在多个维度上展开：

-   在**性能**上，它决定了多核[通信开销](@entry_id:636355)、缓存效率和NUMA访存延迟。
-   在**正确性**上，它关系到对特殊内存类型（如MMIO和持久性内存）的语义支持。
-   在**系统协同**上，它决定了调度器与[内存管理](@entry_id:636637)器之间能否有效配合。
-   在**安全性**上，它关系到系统能否抵御基于资源争用的[侧信道攻击](@entry_id:275985)。
-   在**应用行为**上，它影响着[上层](@entry_id:198114)应用的[性能调优](@entry_id:753343)和[资源隔离](@entry_id:754298)。

最终，“最佳”策略是高度依赖于上下文的。局部策略提供了**隔离、可预测性和简单性**，这在安全关键系统、实时系统、多租户云以及需要精确性能控制的场景中至关重要。全局策略则提供了**灵活性和更高的资源利用率**，这在单一用户工作站或需求动态变化但可协同管理的服务器环境中可能更具优势。现代[操作系统](@entry_id:752937)通常采用[混合策略](@entry_id:145261)，例如带有动态调整配额的局部策略，或能够识别进程[子集](@entry_id:261956)并进行分组的全局策略，试图在隔离和效率这对永恒的矛盾之间找到最佳的[平衡点](@entry_id:272705)。