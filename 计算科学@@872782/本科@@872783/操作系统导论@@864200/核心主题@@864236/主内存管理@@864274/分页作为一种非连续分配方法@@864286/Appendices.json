{"hands_on_practices": [{"introduction": "分页机制通过按需加载页面，极大地提高了内存利用率，但其性能并非没有代价。每次发生页错误时，系统都需从慢速的二级存储中加载页面，这会显著增加内存访问的平均时间。此练习将引导您从基本概率原理出发，推导有效内存访问时间（EAT）的公式，从而量化页错误率对系统整体性能的影响。通过这个计算，您将深刻理解为何保持极低的页错误率是虚拟内存系统高效运行的关键。[@problem_id:3668071]", "problem": "一台计算机采用请求分页来支持虚拟内存，使用分页作为一种非连续分配方法。考虑一次由中央处理器（CPU）执行的内存引用。设当被引用的页面存在于主存中时，完成一次内存引用的时间为 $t_m$。当发生页错误时，操作系统必须处理该错误，产生的总页错误服务时间为 $t_f$（包括输入/输出（I/O）传输、操作系统开销和进程重启）。在错误被处理后，原始的内存引用被重试并在 $t_m$ 时间内完成。假设页错误率，定义为任意一次内存引用引发页错误的概率，为 $\\epsilon \\in [0,1]$。\n\n从随机变量的全期望定律出发，推导有效访问时间（EAT）作为 $\\epsilon$、$t_m$ 和 $t_f$ 的函数。使用您推导出的表达式，求解使有效访问时间满足 $EAT \\leq 2t_m$ 的最大 $\\epsilon$ 值。将您的最终答案表示为最大允许 $\\epsilon$ 的封闭形式符号表达式。无需进行数值计算。", "solution": "首先评估问题的有效性。\n\n### 步骤 1：提取已知条件\n-   计算机使用请求分页和分页作为非连续分配方法。\n-   当页面在主存中时，完成一次内存引用的时间是 $t_m$。\n-   当发生页错误时，总的页错误服务时间是 $t_f$。\n-   在页错误被处理后，原始的内存引用被重试并在时间 $t_m$ 内完成。\n-   页错误率，即发生页错误的概率，是 $\\epsilon$，其中 $\\epsilon \\in [0,1]$。\n-   有效访问时间（EAT）的推导必须从全期望定律开始。\n-   最终目标是求解使 $EAT \\leq 2t_m$ 成立的最大 $\\epsilon$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，是操作系统研究中的一个标准性能分析模型。所有术语，如“请求分页”、“页错误”、“有效访问时间”，在该领域内都有明确的定义。问题提法得当，提供了所有必要的变量（$t_m$、$t_f$、$\\epsilon$）和一个明确的目标。它也是客观的，使用了精确的技术语言。问题设定是完整和一致的，可以导出一个唯一且有意义的解。该问题没有违反任何无效性标准。\n\n### 步骤 3：结论与行动\n问题有效。将提供完整的解答。\n\n### 解题推导\n问题要求推导请求分页内存系统的有效访问时间（EAT）。我们必须从随机变量的全期望定律开始。\n\n设 $T$ 为表示完成单次内存引用总时间的随机变量。根据定义，EAT 是该随机变量的期望值，即 $EAT = E[T]$。\n\n设 $F$ 为内存引用导致页错误的事件。设 $F^c$ 为其互补事件，即被引用的页面存在于主存中（页面命中）。问题给出的页错误概率即为页错误率 $\\epsilon$。\n$$ P(F) = \\epsilon $$\n因此，页面命中的概率为：\n$$ P(F^c) = 1 - P(F) = 1 - \\epsilon $$\n\n对于随机变量 $T$，基于互斥且穷举的事件 $F$ 和 $F^c$ 的全期望定律给出如下：\n$$ E[T] = E[T|F] P(F) + E[T|F^c] P(F^c) $$\n其中 $E[T|A]$ 是在事件 $A$ 发生条件下 $T$ 的条件期望。\n\n我们必须根据问题陈述确定这两个条件期望的值。\n\n1.  $E[T|F^c]$：这是在未发生页错误（页面命中）情况下的期望访问时间。问题陈述，当页面在主存中时，完成一次内存引用的时间是 $t_m$。因此：\n    $$ E[T|F^c] = t_m $$\n\n2.  $E[T|F]$：这是在发生页错误情况下的期望访问时间。问题描述了发生错误时的事件序列：\n    - 操作系统处理错误，总共耗时 $t_f$。\n    - 错误处理完毕后，重试原始的内存引用。由于此时页面已保证在主存中，这次重试操作将在 $t_m$ 时间内完成。\n    发生页错误情况下的总时间是服务时间与成功重试时间的总和。\n    $$ E[T|F] = t_f + t_m $$\n\n现在，我们将这些分量代回全期望定律的公式中：\n$$ EAT = E[T] = (t_f + t_m) \\cdot P(F) + (t_m) \\cdot P(F^c) $$\n$$ EAT = (t_f + t_m) \\epsilon + t_m (1 - \\epsilon) $$\n\n我们简化这个 EAT 的表达式：\n$$ EAT = t_f \\epsilon + t_m \\epsilon + t_m - t_m \\epsilon $$\n$$ EAT = t_m + t_f \\epsilon $$\n这就是推导出的有效访问时间作为 $\\epsilon$、$t_m$ 和 $t_f$ 的函数表达式。\n\n问题的第二部分要求找到页错误率 $\\epsilon$ 的最大值，使得 EAT 不超过内存访问时间 $t_m$ 的两倍。这由不等式表示：\n$$ EAT \\leq 2t_m $$\n\n将我们推导出的 EAT 表达式代入此不等式：\n$$ t_m + t_f \\epsilon \\leq 2t_m $$\n\n为了解出 $\\epsilon$，我们首先通过不等式两边同时减去 $t_m$ 来分离出含有 $\\epsilon$ 的项：\n$$ t_f \\epsilon \\leq 2t_m - t_m $$\n$$ t_f \\epsilon \\leq t_m $$\n\n量 $t_m$ 和 $t_f$ 代表持续时间，因此是物理上的正实数。具体来说，$t_f > 0$。因此，我们可以在不等式两边同时除以 $t_f$ 而不改变不等号的方向：\n$$ \\epsilon \\leq \\frac{t_m}{t_f} $$\n\n问题要求满足此条件的 $\\epsilon$ 的*最大*值。所有有效的 $\\epsilon$ 值的集合是区间 $[0, \\frac{t_m}{t_f}]$，同时也遵守固有的物理约束 $\\epsilon \\geq 0$。该区间的最大值是 $\\frac{t_m}{t_f}$。问题还指出 $\\epsilon \\in [0,1]$。在任何实际的计算机系统中，页错误服务时间 $t_f$（涉及机械硬盘 I/O）比主存访问时间 $t_m$ 大几个数量级（例如，毫秒对纳秒）。因此，比率 $\\frac{t_m}{t_f}$ 是一个远小于 $1$ 的小正数，所以约束 $\\epsilon \\leq 1$ 是隐式满足的。\n\n最大允许的页错误率是所推导不等式的上界。", "answer": "$$ \\boxed{\\frac{t_m}{t_f}} $$", "id": "3668071"}, {"introduction": "虽然分页为非连续内存分配提供了极大的灵活性，但支撑这一机制的页表本身也需要占用内存空间。对于拥有巨大虚拟地址空间的现代系统，简单的单级页表会因自身体积过大而变得不切实际。此练习将带您剖析一个采用多级页表结构的系统，通过计算一个具体进程所需的页表开销，揭示分层设计如何在管理广阔地址空间的同时，有效控制其自身的内存占用。[@problem_id:3668035]", "problem": "一个系统为虚拟内存实现了分层分页，其具有以下基于标准定义的属性。每个虚拟地址的宽度为 $48$ 位。一个页面的大小为 $4$ KiB，即 $4 \\times 2^{10}$ 字节，每个页表条目占用 $8$ 字节。每个页表本身恰好占用一个物理页面。只使用标准的 $4$ KiB 页面（不使用更大的页面）。每个进程独占其页表层次结构；页表页面不在进程间共享。考虑一个进程，它精确地分配了 $64$ MiB 的用户空间虚拟内存，除此之外没有分配其他内存。这个 $64$ MiB 的区域是页面对齐的、连续的，对齐到 $2$ MiB 边界，并且完全位于虚拟地址空间中的单个 $1$ GiB 范围和单个 $512$ GiB 范围内。\n\n仅从以下核心定义出发：页面偏移量的宽度等于页面大小（以字节为单位）的 $\\log_{2}$，每个页表的条目数等于页面大小除以条目大小，以及一个包含 $n$ 个条目的级别会消耗虚拟地址中 $\\log_{2}(n)$ 个索引位。推导出此进程的页表所占用的总内存开销，以及在所有级别上实例化的页表页面的实际数量。以 KiB 为单位表示内存开销，并以纯数字表示页表页面的数量。提供精确的整数值；不要四舍五入。将您的最终答案报告为一个行向量 $\\big[$overhead in KiB, page table page count$\\big]$。", "solution": "我们从分页的基本定义开始。设页面大小为 $P$ 字节，每个页表条目的大小为 $E$ 字节。那么每个页表的条目数是\n$$\nN \\;=\\; \\frac{P}{E}.\n$$\n页面偏移量需要\n$$\nb_{\\text{off}} \\;=\\; \\log_{2}(P)\n$$\n位虚拟地址。如果每个页表有 $N$ 个条目，则每级的索引宽度为\n$$\nb_{\\ell} \\;=\\; \\log_{2}(N) \\;=\\; \\log_{2}\\!\\left(\\frac{P}{E}\\right).\n$$\n给定虚拟地址宽度为 $B$ 位，所有级别的索引位总数为 $B - b_{\\text{off}}$，这决定了级别的数量\n$$\nL \\;=\\; \\frac{B - b_{\\text{off}}}{b_{\\ell}}.\n$$\n\n代入参数。页面大小为 $P = 4 \\text{ KiB} = 4 \\times 2^{10} \\text{ bytes} = 2^{12} \\text{ bytes}$。条目大小为 $E = 8 \\text{ bytes} = 2^{3} \\text{ bytes}$。因此\n$$\nN \\;=\\; \\frac{2^{12}}{2^{3}} \\;=\\; 2^{9} \\;=\\; 512,\n$$\n并且\n$$\nb_{\\text{off}} \\;=\\; \\log_{2}(2^{12}) \\;=\\; 12,\\quad b_{\\ell} \\;=\\; \\log_{2}(2^{9}) \\;=\\; 9.\n$$\n当 $B = 48$ 时，索引位的数量为 $48 - 12 = 36$，因此级别的数量为\n$$\nL \\;=\\; \\frac{36}{9} \\;=\\; 4.\n$$\n因此，我们有一个标准的四级层次结构，其中每个较低级页表（第 1 级）映射 $N$ 个页面，即 $N \\times P$ 字节：\n$$\n\\text{coverage per level-1 table} \\;=\\; N \\cdot P \\;=\\; 2^{9} \\cdot 2^{12} \\;=\\; 2^{21} \\text{ bytes} \\;=\\; 2 \\text{ MiB}.\n$$\n\n该进程分配了一个大小为 $S = 64 \\text{ MiB} = 64 \\times 2^{20} \\text{ bytes} = 2^{26} \\text{ bytes}$ 的单一连续区域。在叶级别所需的页面数量是\n$$\nn_{\\text{pages}} \\;=\\; \\frac{S}{P} \\;=\\; \\frac{2^{26}}{2^{12}} \\;=\\; 2^{14} \\;=\\; 16384.\n$$\n每个第 1 级页表映射 $2 \\text{ MiB}$，即 $512$ 个页面。因此，所需的第 1 级页表的数量是\n$$\nn_{L1} \\;=\\; \\frac{n_{\\text{pages}}}{N} \\;=\\; \\frac{2^{14}}{2^{9}} \\;=\\; 2^{5} \\;=\\; 32.\n$$\n因为该 $64$ MiB 区域对齐到 $2$ MiB 边界，并且其大小是 $2$ MiB 的整数倍，所以恰好需要 $32$ 个第 1 级页表，而没有任何部分填充的额外页表。\n\n现在考虑第 2 级。每个第 2 级页表有 $512$ 个条目，每个条目指向一个第 1 级页表，因此一个第 2 级页表最多可以覆盖\n$$\n512 \\times (2 \\text{ MiB}) \\;=\\; 1 \\text{ GiB}.\n$$\n根据假设，该 $64$ MiB 区域完全位于一个 $1$ GiB 的范围内。因此，\n$$\nn_{L2} \\;=\\; 1.\n$$\n\n考虑第 3 级。每个第 3 级页表有 $512$ 个条目，每个条目指向一个第 2 级页表，因此一个第 3 级页表最多可以覆盖 $512 \\text{ GiB}$。我们的区域位于一个 $512$ GiB 的范围内，因此所需的第 3 级页表的数量是\n$$\nn_{L3} \\;=\\; 1.\n$$\n\n在第 4 级（顶层），根据假设，每个进程都有自己的顶层页表，因此\n$$\nn_{L4} \\;=\\; 1.\n$$\n\n因此，实例化的页表页面总数是各级之和：\n$$\nn_{\\text{pt-pages}} \\;=\\; n_{L1} + n_{L2} + n_{L3} + n_{L4} \\;=\\; 32 + 1 + 1 + 1 \\;=\\; 35.\n$$\n\n每个页表占用一个大小为 $P = 4 \\text{ KiB}$ 的物理页面。因此，由页表引起的内存开销是\n$$\n\\text{overhead} \\;=\\; n_{\\text{pt-pages}} \\times 4 \\text{ KiB} \\;=\\; 35 \\times 4 \\text{ KiB} \\;=\\; 140 \\text{ KiB}.\n$$\n\n根据要求，我们将内存开销（以 KiB 为单位）和页表页面数报告为一个行向量。因此，最终的数值对是\n$$\n\\big[140,\\, 35\\big].\n$$", "answer": "$$\\boxed{\\begin{pmatrix}140 & 35\\end{pmatrix}}$$", "id": "3668035"}, {"introduction": "操作系统提供的分页机制对应用程序员来说通常是透明的，但这并不意味着程序的内存访问模式无关紧要。不佳的访问模式可能导致“内存抖动”（thrashing）现象，即系统因频繁的页错误而将大量时间耗费在页面换入换出上，而非执行有效计算。此练习通过一个经典的矩阵遍历案例，生动地展示了数据在内存中的布局（行主序）与代码访问顺序（列主序）之间的冲突如何引发灾难性的性能问题，并揭示了通过简单的“循环交换”优化便能带来巨大的性能提升。[@problem_id:3668050]", "problem": "考虑一个操作系统中带有请求分页的二级存储系统。一个维度为 $M \\times N$ 的矩阵 $A$ 以行主序存储在一个连续的虚拟地址范围内。每个元素占用 $E$ 字节。系统使用的页面大小为 $P$ 字节，并维护 $F$ 个物理页框。页面置换策略是最近最少使用（LRU）。中央处理器（CPU）的缓存行大小为 $L$ 字节。假设如下：\n- 所有页框初始为空，并且只有 $A$ 的数据页会引起缺页中断。\n- 在页面级别上没有预取和预读。\n- 一旦一个页面驻留在页框中，除非它被换出，否则对该页面的进一步访问不会导致缺页中断。\n- 忽略快表（TLB）效应和任何页面级别以下的缓存未命中；只计算操作系统的缺页中断。\n- 程序执行以下两种嵌套循环遍历 $A$ 中的一种，每种遍历都只访问每个元素一次：\n  1. 行主序友好顺序：$i$ 从 $0$ 到 $M-1$（外循环），$j$ 从 $0$ 到 $N-1$（内循环），访问 $A[i][j]$。\n  2. 列主序顺序：$j$ 从 $0$ 到 $N-1$（外循环），$i$ 从 $0$ 到 $M-1$（内循环），访问 $A[i][j]$。\n\n从分页、虚拟到物理页面映射以及行主序矩阵地址映射的基本定义出发。利用这些原理，推断在每种遍历下访问的虚拟页号序列以及在 LRU 策略下这些页面的重用距离。然后，在以下具体参数下，计算每种遍历的缺页中断总数，以及通过将循环从列主序交换为行主序所获得的减少量：\n- $M = 1500$，$N = 1024$，$E = 8$ 字节，$P = 4096$ 字节，$F = 512$ 个页框，以及 $L = 64$ 字节。\n\n将你的最终答案表示为一个整数，该整数等于将循环从列主序顺序交换为行主序友好顺序所实现的缺页中断减少量。无需四舍五入。在最终的方框答案中只写明整数（无单位）。", "solution": "我们从核心定义开始：\n\n- 在请求分页中，虚拟内存被划分为大小为 $P$ 字节的固定大小页面，这些页面被映射到物理页框。当进程引用一个当前不在任何物理页框中的虚拟页面时，就会发生缺页中断。\n- 在最近最少使用（LRU）置換策略下，当没有空闲页框时，发生新的缺页中断时，最近一次访问时间最远的页面将被换出。\n- 一个大小为 $M \\times N$、元素大小为 $E$ 字节的行主序矩阵，其元素 $A[i][j]$ 存储在线性索引 $k = iN + j$ 处，虚拟字节地址为 $a(i,j) = a_{0} + E(iN + j)$，其中 $a_{0}$ 是 $A$ 的基地址。\n- 访问 $A[i][j]$ 所涉及的虚拟页号是 $v(i,j) = \\left\\lfloor \\dfrac{a(i,j)}{P} \\right\\rfloor = \\left\\lfloor \\dfrac{a_{0}}{P} + \\dfrac{E(iN + j)}{P} \\right\\rfloor$。由于只有 $v(i,j)$ 的差异才重要，我们可以忽略常数 $\\left\\lfloor \\dfrac{a_{0}}{P} \\right\\rfloor$ 并专注于 $\\left\\lfloor \\dfrac{E(iN + j)}{P} \\right\\rfloor$。\n\n我们将根据给定的参数，从一个空的驻留页框集开始，跟踪 LRU 下的重用模式，计算每种遍历顺序的缺页中断次数：\n- $M = 1500$，$N = 1024$，$E = 8$，$P = 4096$，$F = 512$，$L = 64$。\n\n注意，在所述假设下，CPU 缓存行大小 $L$ 不会改变缺页中断的计数，因为缺页中断发生在页面粒度 $P$ 上，一旦页面存在，页内空间局部性（即使分布在多个大小为 $L$ 的缓存行中）也不会引发额外的缺页中断。然而，我们明确保留 $L$ 是为了强调在该模型中，子页面局部性不影响缺页中断计数。\n\n第1步：计算 $A$ 的总大小和不同虚拟页面的总数。\n\n$A$ 的总字节数是\n$$\nB = M N E = 1500 \\times 1024 \\times 8 = 12{,}288{,}000.\n$$\n$A$ 占用的不同虚拟页面的总数是\n$$\nT = \\left\\lceil \\frac{B}{P} \\right\\rceil = \\left\\lceil \\frac{12{,}288{,}000}{4096} \\right\\rceil = \\left\\lceil 3000 \\right\\rceil = 3000.\n$$\n因为 $A$ 占用一个连续的虚拟区域，而行主序友好遍历以基本连续的顺序扫描该区域，所以这 $T$ 个页面中的每一个都只会被访问一次，并且在该遍历的后续过程中不会被重用。\n\n第2步：行主序友好顺序（外循环 $i$，内循环 $j$）的缺页中断。\n\n在行主序友好遍历中，内循环增加 $j$，使得对于固定的 $i$，$A[i][j]$ 访问连续的地址 $a(i,j) = a_{0} + E(iN + j)$。在整个遍历过程中，地址流在连续数组中是单调递增的。\n\n关键结论是：由于没有虚拟页面被重访（对连续区域的单调扫描），缺页中断的数量等于被访问的 $A$ 的不同页面的数量，而与 $F$ 或置換策略无关。即，\n$$\n\\text{PF}_{\\text{row}} = T = 3000.\n$$\n\n第3步：每行的页面结构以及列主序（外循环 $j$，内循环 $i$）的重用机会。\n\n首先，确定每行 $N$ 个元素跨越多少个页面。每个页面的元素数量是\n$$\n\\alpha = \\frac{P}{E} = \\frac{4096}{8} = 512 \\text{ elements per page}.\n$$\n因此，每行长度为 $N = 1024$ 个元素占用\n$$\nq = \\left\\lceil \\frac{N}{\\alpha} \\right\\rceil = \\left\\lceil \\frac{1024}{512} \\right\\rceil = 2 \\text{ pages per row}.\n$$\n对于固定的列 $j$，当 $i$ 增加 $1$ 时，线性索引增加 $N$，所以字节步长是\n$$\nS = E N = 8 \\times 1024 = 8192 \\text{ bytes} = 2P.\n$$\n因此，在单列内，连续访问恰好跳过 $2$ 个页面；对于 $i=0,1,2,\\dots$，虚拟页号序列 $v(i,j)$ 每次都严格增加 $2$（取决于由 $j$ 决定的基地址偏移量）。因此，在单列 $j$ 内，没有虚拟页面被重访；该列中的每次访问都触及一个新的虚拟页面。\n\n然而，跨列存在重用的可能性：对于 $0 \\leq j \\leq 511$，元素 $A[i][j]$ 位于第 $i$ 行的 $2$ 个页面中的第一个；而对于 $512 \\leq j \\leq 1023$，它位于第 $i$ 行的第二个页面。因此，对于前半部分的所有列（$j \\in [0,511]$），对第 $i$ 行的访问总是针对该行的同一个页面（其第一个页面）；类似地，对于后半部分（$j \\in [512,1023]$），访问针对该行的第二个页面。\n\n因此，如果系统能够在连续的列之间将当前半部分对应的所有 $M$ 个页面（每行一个页面）保留在物理内存中，那么前半部分将在列 $j=0$ 时产生 $M$ 次初始缺页中断，然后在列 $j=1,\\dots,511$ 时产生零次中断；后半部分类似地在 $j=512$ 时产生 $M$ 次初始缺页中断，之后为零。总计，列主序的最佳情况下的缺页中断次数为 $2M$。\n\n第4步：在 $F = 512$ 个页框和 LRU 策略下，列主序的缺页中断。\n\n我们现在考虑在 LRU 策略下，在列之间保留这 $M$ 个页面的可行性。在列 $j$ 的处理过程中，内循环访问 $M$ 个不同的页面（每行一个），并且在该列内不重访任何页面。在列 $j$ 结束时，LRU 策略下的最近使用次序是，最近使用的页面对应于最大的 $i$ 值。当移动到列 $j+1$ 并在 $i=0$ 处重新开始内循环时，对第 $i=0$ 行的访问试图重用大约在 $M$ 次页面引用之前最后被引用的页面。为了避免在该重用上发生中断，页框数 $F$ 需要至少为 $M$，这样当前半部分的 $M$ 个不同行页面才不会被换出。如果 $F  M$，那么在一列结束时，至少有 $M - F$ 个页面已被换出，特别是最早的那些（最小的 $i$）将不再驻留。因此，在下一列开始时，第 $i=0$ 行的页面会发生中断，第 $i=1$ 行的页面也类似，依此类推。实际上，当 $F \\ll M$ 时，每一列中的每一次访问都会发生中断，因为重用距离约为 $M$ 并超过了页框预算，导致完全的抖动。\n\n给定 $F = 512$ 和 $M = 1500$，我们有 $F  M$。因此，在列主序下：\n- 在每列 $j$ 中，$M$ 次访问中的每一次都触及了该列中首次访问的一个不同页面，因此每次访问都会发生中断。\n- 跨列时，由于在 LRU 策略下 $F  M$，没有重用被捕获，因此每次访问都会继续发生中断。\n\n因此，列主序的总缺页中断次数是\n$$\n\\text{PF}_{\\text{col}} = M N = 1500 \\times 1024 = 1{,}536{,}000.\n$$\n\n第5步：由于循环从列主序交换为行主序导致的缺页中断减少量。\n\n减少量是\n$$\n\\Delta = \\text{PF}_{\\text{col}} - \\text{PF}_{\\text{row}} = 1{,}536{,}000 - 3000 = 1{,}533{,}000.\n$$\n\n第6步：解释 $P$ 和 $L$ 的作用以及循环交换何时有帮助的条件。\n\n- 页面大小 $P$ 控制着 $\\alpha = P/E$，因此决定了 $q = \\lceil N / \\alpha \\rceil$，即每行的页面数。在我们的参数中，$q = 2$，这意味着当有足够的页框可用时，最优的列主序缺页中断计数为 $qM = 2M$，与连续扫描的行主序计数 $\\lceil M N E / P \\rceil = qM$ 相匹配。\n- 缓存行大小 $L$ 影响处理器缓存行为，但在给定假设下不影响操作系统的缺页中断次数。因此 $L$ 不计入缺页中断计数。\n- 通常，对于按行主序存储的矩阵，在 LRU 下进行列主序遍历时，当 $F  M$ 时交换循环会减少缺页中断，因为每个列半部分的工作集是 $M$ 个页面且无法被保留；当 $F \\geq M$ 时，列主序遍历可以在每个半部分内捕獲列间重用，产生 $qM$ 次中断，与行主序的计数相等。\n\n对于所要求的具体数值参数，确切的减少量是上面计算出的整数。", "answer": "$$\\boxed{1533000}$$", "id": "3668050"}]}