{"hands_on_practices": [{"introduction": "在我们设法缓解锁竞争之前，我们必须首先能够预测它。本练习将运用基本的排队论来建立一个模型，用以估算线程等待锁的平均时间。通过从第一性原理出发推导著名的 Pollaczek-Khinchine 公式，你将深刻理解到达率和锁持有时间的可变性等因素是如何导致竞争的 [@problem_id:3654523]。", "problem": "一个操作系统内核使用单个互斥锁来保护对共享运行队列的更新。线程根据泊松过程到达以尝试获取锁，速率为每秒 $\\lambda$ 次到达。获得锁后，线程执行一个临界区，其执行时间是一个随机变量 $S$（锁持有时间），该时间在线程之间独立，且独立于到达过程。该锁使用先来先服务（FCFS）的准入策略，并且调度程序确保在线程持有锁期间提供非抢占式服务。假设系统处于稳态，其中 $\\lambda \\mathbb{E}[S]  1$。\n\n您可以使用以下基本事实：(i) 对于泊松到达过程，泊松到达看到时间平均（PASTA）；(ii) 利特尔法则（Little’s Law）；(iii) 更新过程的平均剩余寿命恒等式，$\\mathbb{E}[R] = \\mathbb{E}[S^{2}] / \\left(2 \\mathbb{E}[S]\\right)$，其中 $R$ 是在繁忙期内随机时刻观察到的剩余服务时间。\n\n在此工作负载中，到达速率为 $\\lambda = 150{,}000$ 次/秒。临界区时间 $S$ 具有双峰分布：$S = 1$ 微秒的概率为 $0.9$，$S = 10$ 微秒的概率为 $0.1$。\n\n从上述核心定义和事实出发，将该锁建模为单服务器 FCFS 队列，并推导一个表达式，用于计算一个到达线程在获取锁之前等待的平均时间（不包括其自身的临界区时间）。然后，在给定参数下评估此平均等待时间。用微秒表示最终数值答案，并四舍五入到四位有效数字。", "solution": "首先验证问题，以确保其科学上合理、自洽且定义明确。\n\n### 步骤 1：提取给定条件\n-   **模型**：单服务器先来先服务（FCFS）队列。\n-   **到达过程**：泊松过程，速率 $\\lambda = 150{,}000$ 次到达/秒。\n-   **服务时间**：随机变量 $S$。其分布为双峰分布：$P(S = 1 \\text{ µs}) = 0.9$ 且 $P(S = 10 \\text{ µs}) = 0.1$。服务时间在线程间独立，且独立于到达过程。\n-   **稳定性条件**：系统处于稳态，其中 $\\lambda \\mathbb{E}[S]  1$。\n-   **提供的基本事实**：\n    1.  泊松到达看到时间平均（PASTA）。\n    2.  利特尔法则（Little’s Law）。\n    3.  平均剩余寿命恒等式：$\\mathbb{E}[R] = \\frac{\\mathbb{E}[S^2]}{2 \\mathbb{E}[S]}$，其中 $R$ 是在繁忙期内随机时刻观察到的剩余服务时间。\n-   **目标**：推导队列中的平均等待时间 $\\mathbb{E}[W_q]$ 的表达式，然后在给定参数下进行评估。最终答案应以微秒为单位，并四舍五入到四位有效数字。\n\n### 步骤 2：使用提取的给定条件进行验证\n该问题描述了一个具有泊松到达和通用服务时间分布的单服务器队列（M/G/1 队列），这是排队论中一个标准且被充分理解的模型，常用于计算机系统性能分析。该问题具有科学依据。\n\n问题提供了推导解决方案所需的所有必要参数（$\\lambda$ 和 $S$ 的分布）和理论工具。必须验证队列的稳定性。\n平均服务时间 $\\mathbb{E}[S]$ 为：\n$$ \\mathbb{E}[S] = (1 \\text{ µs}) \\times 0.9 + (10 \\text{ µs}) \\times 0.1 = 0.9 \\text{ µs} + 1.0 \\text{ µs} = 1.9 \\text{ µs} = 1.9 \\times 10^{-6} \\text{ s} $$\n到达速率为 $\\lambda = 150{,}000 \\text{ s}^{-1}$。\n服务器利用率 $\\rho$ 由 $\\lambda \\mathbb{E}[S]$ 给出：\n$$ \\rho = (150{,}000 \\text{ s}^{-1}) \\times (1.9 \\times 10^{-6} \\text{ s}) = 1.5 \\times 10^5 \\times 1.9 \\times 10^{-6} = 0.285 $$\n由于 $\\rho = 0.285  1$，稳定性条件得到满足，存在稳态解。问题定义明确且内部一致。它是客观的，没有歧义。\n\n### 步骤 3：结论与行动\n问题有效。将提供完整的解决方案。\n\n### 平均等待时间的推导\n该系统被建模为 M/G/1 队列。我们的目标是求出队列中的平均等待时间，记为 $\\mathbb{E}[W_q]$。这是一个到达的线程在开始其临界区之前平均等待的时间。\n\n考虑一个到达队列的线程。它必须等待的时间 $W_q$ 等于为系统中已存在的所有线程提供服务所需的总时间。这个时间由两部分组成：\n1.  当前持有锁的线程（如果有的话）的剩余服务时间。我们称这个随机变量为 $R_a$。\n2.  在新到达者之前排队等待的所有线程的完整服务时间之和。\n\n因此，我们可以将一个到达线程的等待时间写为：\n$$ W_q = R_a + \\sum_{i=1}^{N_q} S_i $$\n其中 $N_q$ 是到达时在队列中等待的线程数，$S_i$ 是队列中第 $i$ 个线程的服务时间。\n\n根据期望的线性性质，平均等待时间为：\n$$ \\mathbb{E}[W_q] = \\mathbb{E}[R_a] + \\mathbb{E}\\left[\\sum_{i=1}^{N_q} S_i\\right] $$\n\n由于 PASTA 属性，到达的线程观察到系统处于其稳态。队列中的时间平均线程数为 $\\mathbb{E}[N_q]$。服务时间 $S_i$ 独立于 $N_q$。我们可以对第二项应用沃尔德恒等式（Wald's identity）：\n$$ \\mathbb{E}\\left[\\sum_{i=1}^{N_q} S_i\\right] = \\mathbb{E}[S] \\mathbb{E}[N_q] $$\n通过对队列应用利特尔法则，平均等待线程数是到达率和平均等待时间的乘积：\n$$ \\mathbb{E}[N_q] = \\lambda \\mathbb{E}[W_q] $$\n将此代入前一个方程得到：\n$$ \\mathbb{E}\\left[\\sum_{i=1}^{N_q} S_i\\right] = \\mathbb{E}[S] (\\lambda \\mathbb{E}[W_q]) = (\\lambda \\mathbb{E}[S]) \\mathbb{E}[W_q] = \\rho \\mathbb{E}[W_q] $$\n\n现在我们分析第一项，$\\mathbb{E}[R_a]$，即一个到达者看到的平均剩余服务时间。一个到达的线程发现服务器（锁）正忙的概率为 $\\rho = \\lambda \\mathbb{E}[S]$，空闲的概率为 $1 - \\rho$。\n如果服务器空闲，剩余时间为 $0$。如果服务器正忙，期望的剩余服务时间由服务器忙碌条件下的平均剩余寿命恒等式给出，即 $\\mathbb{E}[R] = \\frac{\\mathbb{E}[S^2]}{2 \\mathbb{E}[S]}$。\n因此，一个到达者看到的无条件期望剩余时间是：\n$$ \\mathbb{E}[R_a] = \\rho \\cdot \\mathbb{E}[R] + (1-\\rho) \\cdot 0 = (\\lambda \\mathbb{E}[S]) \\cdot \\frac{\\mathbb{E}[S^2]}{2 \\mathbb{E}[S]} = \\frac{\\lambda \\mathbb{E}[S^2]}{2} $$\n\n结合这两个组成部分的表达式，我们得到：\n$$ \\mathbb{E}[W_q] = \\frac{\\lambda \\mathbb{E}[S^2]}{2} + \\rho \\mathbb{E}[W_q] $$\n现在我们可以解出 $\\mathbb{E}[W_q]$：\n$$ \\mathbb{E}[W_q] - \\rho \\mathbb{E}[W_q] = \\frac{\\lambda \\mathbb{E}[S^2]}{2} $$\n$$ \\mathbb{E}[W_q] (1 - \\rho) = \\frac{\\lambda \\mathbb{E}[S^2]}{2} $$\n$$ \\mathbb{E}[W_q] = \\frac{\\lambda \\mathbb{E}[S^2]}{2(1-\\rho)} $$\n这就是用于计算平均等待时间的 Pollaczek-Khinchine 公式。\n\n### 数值评估\n为了评估这个表达式，我们首先计算服务时间 $S$ 的必要矩。为方便起见，我们使用微秒（µs）作为时间单位进行计算。\n到达速率为 $\\lambda = 150{,}000 \\text{ s}^{-1} = 150{,}000 \\times 10^{-6} \\text{ µs}^{-1} = 0.15 \\text{ µs}^{-1}$。\n服务时间 $S$ 的分布为 $P(S=1 \\text{ µs}) = 0.9$ 和 $P(S=10 \\text{ µs}) = 0.1$。\n\n一阶矩（平均服务时间）：\n$$ \\mathbb{E}[S] = (0.9 \\times 1) + (0.1 \\times 10) = 0.9 + 1.0 = 1.9 \\text{ µs} $$\n\n服务时间的二阶矩：\n$$ \\mathbb{E}[S^2] = \\sum_{i} s_i^2 P(S=s_i) = (0.9 \\times 1^2) + (0.1 \\times 10^2) = (0.9 \\times 1) + (0.1 \\times 100) = 0.9 + 10 = 10.9 \\text{ µs}^2 $$\n\n服务器利用率 $\\rho$：\n$$ \\rho = \\lambda \\mathbb{E}[S] = (0.15 \\text{ µs}^{-1}) \\times (1.9 \\text{ µs}) = 0.285 $$\n如验证阶段所确认，系统是稳定的。\n\n现在，我们将这些值代入 $\\mathbb{E}[W_q]$ 的公式中：\n$$ \\mathbb{E}[W_q] = \\frac{\\lambda \\mathbb{E}[S^2]}{2(1-\\rho)} = \\frac{(0.15 \\text{ µs}^{-1}) \\times (10.9 \\text{ µs}^2)}{2(1-0.285)} $$\n$$ \\mathbb{E}[W_q] = \\frac{1.635 \\text{ µs}}{2(0.715)} = \\frac{1.635 \\text{ µs}}{1.43} $$\n$$ \\mathbb{E}[W_q] \\approx 1.14335664... \\text{ µs} $$\n问题要求答案四舍五入到四位有效数字。\n$$ \\mathbb{E}[W_q] \\approx 1.143 \\text{ µs} $$\n一个到达的线程在获取锁之前平均等待的时间大约是 $1.143$ 微秒。", "answer": "$$\\boxed{1.143}$$", "id": "3654523"}, {"introduction": "锁竞争不仅会造成延迟，还可能因产生大量流量而使系统互连不堪重负。本练习将从抽象的排队模型转向具体的硬件层面，要求你计算一个高竞争的自旋锁所消耗的缓存一致性带宽。这将揭示天真自旋等待的“无形成本”，并强调为何可伸缩性同时取决于软件算法和硬件交互 [@problem_id:3645691]。", "problem": "一个多核处理器实现了一个遵循“修改-独占-共享-无效”（MESI）状态的、基于目录的缓存一致性协议。该系统是缓存一致性非均匀内存访问（ccNUMA）架构，所有核心都连接到一个单一的片上互连。考虑一个使用“比较并交换”（CAS）实现的、采用“测试-再测试-再设置”（TTAS）模式的竞争自旋锁，其中许多线程重复读取位于单个缓存行中的锁变量，并且仅当读取操作表明锁可能可用时才尝试进行CAS操作。假设关于MESI一致性流量有以下基本事实：\n- 对缓存行的写入操作要求写入者通过“请求所有权读取”（RFO）来获得独占所有权，这会使该行的所有其他共享副本失效，并将该行的数据传输给写入者。\n- 对缓存中不存在的缓存行进行读取会发起一个“共享读取”（RS）事务，该事务将该行的数据传输给读取者。\n- 在一个高度竞争的TTAS锁中，当锁看起来可用时，读取操作会使该行在许多共享者之间保持共享状态，而每一次成功的锁获取或释放都是一次写入，会触发一次RFO并使所有共享者失效，此后，在下一次写入之前，每个被失效的自旋等待线程都会通过恰好一次RS来重新获取该行。\n\n假设有$N=40$个线程（每个线程都固定到其自己的核心上）在大小为$S=64$字节的单个缓存行上自旋等待。锁持有者的平均临界区时间为$t_{cs}=150\\times 10^{-9}$秒，并且竞争足够激烈，以至于锁一旦被释放，总有至少一个线程准备好立即获取它（即锁的吞吐量受临界区限制）。每个自旋等待的线程轮询得足够频繁，以至于在连续两次写入之间的每个锁阶段中，它至少执行一次读取，因此每次失效最终都会导致每个自旋等待线程在下一次写入之前恰好发起一次新的RS。\n\n互连上的一致性消息大小如下：\n- RFO请求头大小 $h_{RFO}=16$ 字节；每次RFO会向每个共享者触发大小为 $h_{inv}=8$ 字节的失效消息，并从每个被失效的共享者收到大小为 $h_{ack}=8$ 字节的确认消息；每次RFO还会向写入者产生一个大小为 $S$ 字节的单一数据响应。\n- RS请求头大小 $h_{RS}=16$ 字节；每次RS会向读取者产生一个大小为 $S$ 字节的单一数据响应。\n\n忽略所有其他流量（例如，与锁无关的内存写回、超出所列消息大小的目录状态更新以及传输层flit）。将所有列出的消息大小视为每条消息在互连上传输的总字节数。\n\n从所述的MESI和TTAS行为出发，推导失效和“请求所有权读取”（RFO）的稳态速率（以每秒次数计），然后计算此锁消耗的总一致性带宽（以字节/秒为单位），该带宽汇总了以下原因产生的字节数：\n- RFO及其引起的失效广播和确认，\n- 作为失效后果而发生的RS请求及其数据响应。\n\n以$\\mathrm{GBytes/s}$为单位表示最终带宽，并将您的答案四舍五入到四位有效数字。最终答案必须是一个实数值。", "solution": "用户要求我验证并解决一个关于多核系统中缓存一致性带宽的问题。\n\n### 步骤1：问题验证\n\n首先，我必须仔细验证问题陈述。\n\n#### 提取的已知条件：\n-   **系统：** 一个多核处理器，有$N=40$个线程，每个线程位于其自己的核心上。架构为缓存一致性非均匀内存访问（ccNUMA），拥有单一的片上互连。\n-   **协议：** 基于目录的MESI（修改-独占-共享-无效）协议。\n-   **同步原语：** 一个使用“测试-再测试-再设置”（TTAS）模式的竞争自旋锁，通过“比较并交换”（CAS）实现。锁变量位于单个缓存行中。\n-   **性能参数：**\n    -   缓存行大小：$S = 64$ 字节。\n    -   平均临界区时间：$t_{cs} = 150 \\times 10^{-9}$ 秒。\n    -   线程/核心数：$N = 40$。\n-   **一致性消息大小：**\n    -   请求所有权读取（RFO）请求头：$h_{RFO} = 16$ 字节。\n    -   失效消息：$h_{inv} = 8$ 字节。\n    -   失效确认：$h_{ack} = 8$ 字节。\n    -   RFO数据响应：$S = 64$ 字节。\n    -   共享读取（RS）请求头：$h_{RS} = 16$ 字节。\n    -   RS数据响应：$S = 64$ 字节。\n-   **假设与系统行为：**\n    1.  一次写入需要一个RFO，该RFO会使所有其他共享副本失效，并将数据传输给写入者。\n    2.  一次缓存未命中读取会发起一个RS，该RS将数据传输给读取者。\n    3.  竞争激烈，使得锁的吞吐量受临界区限制。\n    4.  在TTAS锁中，每次成功的获取或释放都是一次触发RFO的写入。\n    5.  在RFO使共享者失效后，每个被失效的自旋等待线程在下一次写入发生前，都会通过恰好一次RS来重新获取该行。\n\n#### 使用提取的已知条件进行验证：\n-   **科学依据：** 该问题牢固地植根于计算机体系结构和并行计算的原理。MESI、ccNUMA、TTAS、RFO和RS都是标准的、定义明确的概念。所描述的行为是一个简化但标准的自旋锁竞争模型。\n-   **良构性：** 问题是良构的。它提供了所有必要的数值（$N, S, t_{cs}$以及所有消息大小）和一套清晰的行为假设，从而可以计算出唯一且有意义的一致性带宽值。\n-   **客观性：** 问题以精确、客观和技术性的语言陈述，没有歧义或主观论断。\n-   **完整性与一致性：** 问题是自洽的。其中的假设虽然简化了一个复杂的过程，但都得到了明确的陈述并且内部一致。例如，每个失效导致每个自旋者进行一次RS的假设提供了一个清晰的计算模型。\n-   **可行性：** 场景和参数在高性能计算环境中是现实的。消息大小和时序是合理的。\n\n#### 结论：\n该问题在科学上是合理的、良构的且内部一致。它为定量分析提供了有效的基础。我将继续进行求解。\n\n### 步骤2：求解推导\n\n目标是计算竞争自旋锁消耗的总一致性带宽。策略是确定引发一致性事件的速率，并将其乘以每次事件传输的总数据量。\n\n#### 1. 一致性事件的速率\n问题指出，锁的吞吐量受临界区时间 $t_{cs}$ 的限制。这意味着平均每 $t_{cs}$ 秒发生一次锁的交接事件。一个锁交接周期包括一个线程释放锁和另一个线程立即获取锁。\n-   **锁释放：** 这是一个将锁变量设置为`free`的写操作。\n-   **锁获取：** 这是一次成功的“比较并交换”（CAS）操作，它是一个读-修改-写操作，本质上是一次写入。\n\n根据问题描述，“每一次成功的锁获取或释放都是一次写入，会触发一次RFO”。因此，在每个 $t_{cs}$ 的时间间隔内，会发生两次RFO事件。RFO的速率 $f_{RFO}$ 为：\n$$f_{RFO} = \\frac{2}{t_{cs}}$$\n这也是失效广播的速率，因为每次RFO都会触发一次。从数值上看，该速率为：\n$$f_{RFO} = \\frac{2}{150 \\times 10^{-9} \\, s} = \\frac{2}{150} \\times 10^{9} \\, s^{-1} \\approx 1.33 \\times 10^{7} \\, s^{-1}$$\n\n#### 2. 每次RFO事件的一致性流量\n我们必须计算单次RFO及其直接后果所产生的总互连流量。问题指出，一次RFO会使“所有其他共享副本”失效。在这个有 $N$ 个线程的高度竞争场景中，由一个线程发出的RFO需要使其余 $N-1$ 个线程中的副本失效。\n\n单次此类事件的总流量 $B_{event}$ 是RFO本身产生的流量与后续共享读取（RS）请求产生的流量之和。\n\n**A. RFO及其相关失效操作的流量 ($B_{RFO\\_traffic}$):**\n-   一个由写入核心发送的RFO请求头：$h_{RFO}$。\n-   发送给其他 $N-1$ 个核心的失效消息：$(N-1) \\times h_{inv}$。\n-   从 $N-1$ 个被失效核心发回的确认消息：$(N-1) \\times h_{ack}$。\n-   一个将缓存行传输给写入者的单一数据响应：$S$。\n\n$$B_{RFO\\_traffic} = h_{RFO} + (N-1)(h_{inv} + h_{ack}) + S$$\n代入给定值：\n$$B_{RFO\\_traffic} = 16 \\, \\text{bytes} + (40-1)(8 \\, \\text{bytes} + 8 \\, \\text{bytes}) + 64 \\, \\text{bytes}$$\n$$B_{RFO\\_traffic} = 16 + 39 \\times 16 + 64 = 16 + 624 + 64 = 704 \\, \\text{bytes}$$\n\n**B. 随后的共享读取请求的流量 ($B_{RS\\_traffic}$):**\nRFO使 $N-1$ 个核心失效。问题指出“每个被失效的自旋等待线程都会通过恰好一次RS来重新获取该行”。这意味着 $N-1$ 个核心将发出RS请求。每个RS请求都会产生请求头和数据响应的流量。\n-   来自 $N-1$ 个核心的RS请求头：$(N-1) \\times h_{RS}$。\n-   到 $N-1$ 个核心的数据响应：$(N-1) \\times S$。\n\n$$B_{RS\\_traffic} = (N-1)(h_{RS} + S)$$\n代入给定值：\n$$B_{RS\\_traffic} = (40-1)(16 \\, \\text{bytes} + 64 \\, \\text{bytes})$$\n$$B_{RS\\_traffic} = 39 \\times 80 = 3120 \\, \\text{bytes}$$\n\n**C. 每次事件的总流量：**\n与单个RFO-失效-重新获取序列相关的总流量为：\n$$B_{event} = B_{RFO\\_traffic} + B_{RS\\_traffic} = 704 \\, \\text{bytes} + 3120 \\, \\text{bytes} = 3824 \\, \\text{bytes}$$\n\n#### 3. 总一致性带宽\n总一致性带宽 $BW$ 是单位时间内产生的总流量。在每个 $t_{cs}$ 的周期内，发生两次此类事件（一次用于释放，一次用于获取）。每个周期的总流量为 $B_{cycle} = 2 \\times B_{event}$。带宽是此流量除以周期时间 $t_{cs}$。\n$$BW = \\frac{B_{cycle}}{t_{cs}} = \\frac{2 \\times B_{event}}{t_{cs}}$$\n代入数值：\n$$BW = \\frac{2 \\times 3824 \\, \\text{bytes}}{150 \\times 10^{-9} \\, s} = \\frac{7648}{150} \\times 10^{9} \\, \\text{Bytes/s}$$\n$$BW \\approx 50.9866... \\times 10^{9} \\, \\text{Bytes/s}$$\n\n问题要求答案以 GBytes/s 为单位，其中 $1$ GByte $= 10^9$ Bytes，并四舍五入到四位有效数字。\n$$BW \\approx 50.99 \\, \\text{GBytes/s}$$", "answer": "$$\\boxed{50.99}$$", "id": "3645691"}, {"introduction": "在理解了竞争的代价之后，下一步就是设计能够规避它的系统。本练习要求你比较传统的全局锁设计与一种可扩展的“每CPU”方法，后者为每个CPU都维护自己的数据。你将对其中的权衡（包括数据迁移和合并的开销）进行建模，从而定量地判断这种可扩展模式在何种情况下更具优势 [@problem_id:3654522]。", "problem": "您需要设计并实现一个单一、自包含的程序，该程序在一个多处理操作系统环境中，对两种设计下的平均单次操作延迟进行建模和比较：一种是保护单个共享数据结构的全局锁，另一种是每个中央处理器（per-CPU）的私有数据结构。目标是从第一性原理出发，对锁竞争和可扩展性进行推理，推导出一个量化模型，并计算延迟加速比。每个测试用例的加速比定义为全局锁设计下的平均延迟除以 per-CPU 设计下的平均延迟。\n\n请从以下基本原理出发，除了广为接受的结果和定义外，不使用或假设任何快捷公式：\n- 互斥（Mutual exclusion）将对临界区的访问序列化。当许多线程试图进入单个临界区时，它们会排队等待，从而增加平均延迟。\n- 利特尔定律（Little’s Law）指出，对于一个稳定系统，系统中的平均数量 $L$ 满足 $L = \\lambda W$，其中 $\\lambda$ 是到达率，而 $W$ 是在系统中的平均时间。\n- $M/M/1$ 队列是一个具有泊松到达（Poisson arrivals）和指数服务时间（exponential service times）的单服务器队列。它是一个经过充分检验的模型，用于模拟单一资源上的竞争。请用它来为全局锁和每个 per-CPU 锁的竞争建模。假设稳定性条件成立，即到达率严格小于服务率。\n\n您的实现需要使用的建模假设：\n- 全局锁设计：跨 $n$ 个 CPU 的所有需要互斥的操作都由一个单一锁进行序列化，将临界区建模为一个 $M/M/1$ 服务器，其服务率为 $\\mu_g$，总到达率为 $\\lambda = n r$，其中 $r$ 是需要临界区的操作的 per-CPU 到达率。该模型下的系统平均时间（延迟）应在稳定性条件下使用 $M/M/1$ 队列进行计算。\n- Per-CPU 设计：每个 CPU 都有自己的私有锁和数据结构，被独立地建模为 $M/M/1$ 队列，每个队列的到达率为 $r$，服务率为 $\\mu_\\ell$。除了本地锁的排队延迟外，还需计入跨 CPU 任务迁移的期望成本以及周期性合并（将 per-CPU 数据聚合到全局视图）的摊销成本。假设：\n  - 迁移：每次操作独立地以概率 $p$ 产生额外成本 $c_m$。将其建模为每次操作 $p c_m$ 的期望附加延迟。\n  - 合并：每 $\\Delta$ 秒发生一次合并，每个 CPU 的成本为 $c_s$。将其摊销为每次操作 $\\frac{c_s}{r \\Delta}$ 的附加延迟。\n\n程序中要使用的参数定义：\n- $n$：CPU 数量（无量纲）。\n- $r$：每个 CPU 的操作到达率（单位：操作/秒，$\\text{s}^{-1}$）。\n- $c_g$：全局锁设计的临界区服务时间（单位：秒，$\\text{s}$）。服务率为 $\\mu_g = \\frac{1}{c_g}$。\n- $c_\\ell$：per-CPU 设计的临界区服务时间（单位：秒，$\\text{s}$）。服务率为 $\\mu_\\ell = \\frac{1}{c_\\ell}$。\n- $p$：每次操作的迁移概率（无量纲）。\n- $c_m$：每次迁移操作的迁移成本（单位：秒，$\\text{s}$）。\n- $\\Delta$：合并间隔（单位：秒，$\\text{s}$）。\n- $c_s$：每次合并中每个 CPU 的合并成本（单位：秒，$\\text{s}$）。\n\n科学真实性要求：\n- 所有时间必须以秒（$\\text{s}$）为单位表示。\n- 所有到达率必须以操作/秒（$\\text{s}^{-1}$）为单位表示。\n- 使用 $M/M/1$ 稳定性条件 $n r  \\mu_g$ 和 $r  \\mu_\\ell$。\n\n您的任务是：\n- 仅使用上述基本原理和建模假设，推导出两种设计的平均单次操作延迟。\n- 实现一个程序，为每个测试用例计算延迟加速比 $S$，其定义为全局锁延迟除以 per-CPU 延迟。\n- 将每个输出 $S$ 四舍五入到六位小数。\n\n测试套件和参数：\n为以下五个测试用例提供结果，每个用例由 $(n, r, c_g, c_\\ell, p, c_m, \\Delta, c_s)$ 指定：\n\n- 案例 1（理想路径，中等竞争，轻量迁移和合并）：\n  - $n = 8$, $r = 4000$, $c_g = 1.2 \\times 10^{-5}$, $c_\\ell = 3.2 \\times 10^{-6}$, $p = 0.02$, $c_m = 5.0 \\times 10^{-6}$, $\\Delta = 0.2$, $c_s = 2.0 \\times 10^{-4}$。\n- 案例 2（边界条件：单 CPU，无迁移，无合并开销）：\n  - $n = 1$, $r = 4000$, $c_g = 1.0 \\times 10^{-5}$, $c_\\ell = 3.0 \\times 10^{-6}$, $p = 0.0$, $c_m = 1.0 \\times 10^{-6}$, $\\Delta = 1.0$, $c_s = 0.0$。\n- 案例 3（接近全局饱和，per-CPU 保持快速）：\n  - $n = 16$, $r = 1200$, $c_g = 5.0 \\times 10^{-5}$, $c_\\ell = 4.0 \\times 10^{-6}$, $p = 0.05$, $c_m = 1.0 \\times 10^{-5}$, $\\Delta = 0.05$, $c_s = 1.0 \\times 10^{-4}$。\n- 案例 4（高迁移和高合并开销，多 CPU）：\n  - $n = 32$, $r = 800$, $c_g = 3.0 \\times 10^{-5}$, $c_\\ell = 2.0 \\times 10^{-6}$, $p = 0.3$, $c_m = 1.0 \\times 10^{-5}$, $\\Delta = 0.02$, $c_s = 5.0 \\times 10^{-4}$。\n- 案例 5（合并成本高但频率极低）：\n  - $n = 8$, $r = 5000$, $c_g = 1.1 \\times 10^{-5}$, $c_\\ell = 2.5 \\times 10^{-6}$, $p = 0.15$, $c_m = 2.0 \\times 10^{-6}$, $\\Delta = 5.0$, $c_s = 2.0 \\times 10^{-2}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的加速比结果，例如 $\\left[ s_1, s_2, s_3, s_4, s_5 \\right]$，其中每个 $s_i$ 是一个四舍五入到六位小数的浮点数。具体来说，请使用以下确切的文本格式打印：\n- \"[result1,result2,result3,result4,result5]\"", "solution": "该问题要求对多 CPU 操作系统中管理共享数据的两种设计模式进行定量比较：单一全局锁与 per-CPU 私有数据结构。比较指标是加速比 $S$，定义为全局锁设计的平均单次操作延迟除以 per-CPU 设计的平均单次操作延迟。推导将基于排队论的第一性原理，特别是 $M/M/1$ 模型。\n\n首先，我们必须验证问题陈述。\n\n**步骤 1：提取已知条件**\n- **待比较的设计**：全局锁 vs. Per-CPU 私有数据结构。\n- **性能指标**：延迟加速比 $S = W_g / W_\\ell$，其中 $W_g$ 是全局锁延迟，$W_\\ell$ 是 per-CPU 延迟。\n- **建模框架**：\n  - 互斥序列化访问，导致排队。\n  - 利特尔定律：$L = \\lambda W$。\n  - 使用 $M/M/1$ 队列对竞争进行建模。\n  - 稳定性要求到达率 $\\lambda$ 小于服务率 $\\mu$。\n- **全局锁模型 ($W_g$)**：\n  - 单个 $M/M/1$ 服务器。\n  - 总到达率 $\\lambda_g = n \\cdot r$。\n  - 服务率 $\\mu_g = 1/c_g$。\n- **Per-CPU 模型 ($W_\\ell$)**：\n  - $n$ 个 CPU 中，每个 CPU 都有一个独立的 $M/M/1$ 队列。\n  - Per-CPU 到达率 $\\lambda_\\ell = r$。\n  - Per-CPU 服务率 $\\mu_\\ell = 1/c_\\ell$。\n  - 迁移带来的额外附加延迟：每次操作的期望成本为 $p \\cdot c_m$。\n  - 合并带来的额外附加延迟：每次操作的摊销成本为 $\\frac{c_s}{r \\cdot \\Delta}$。\n- **参数**：\n  - $n$：CPU 数量。\n  - $r$：per-CPU 到达率 ($\\text{s}^{-1}$)。\n  - $c_g$：全局锁服务时间 ($\\text{s}$)。\n  - $c_\\ell$：per-CPU 锁服务时间 ($\\text{s}$)。\n  - $p$：迁移概率。\n  - $c_m$：迁移成本 ($\\text{s}$)。\n  - $\\Delta$：合并间隔 ($\\text{s}$)。\n  - $c_s$：per-CPU 合并成本 ($\\text{s}$)。\n- **稳定性条件**：$n \\cdot r  \\mu_g$ 和 $r  \\mu_\\ell$。\n- **测试用例**：提供了五组参数。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，采用标准的 $M/M/1$ 排队模型来分析系统性能，这是计算机科学和工程领域的常见做法。锁竞争、可扩展性、迁移开销和数据聚合等概念是操作系统设计的基础。问题定义明确，提供了所有必要的参数和清晰的目标。语言客观且量化。\n\n我们必须为所有提供的测试用例验证稳定性条件。条件是 $n \\cdot r \\cdot c_g  1$ 和 $r \\cdot c_\\ell  1$。\n1.  **案例 1**：$n \\cdot r \\cdot c_g = 8 \\cdot 4000 \\cdot 1.2 \\times 10^{-5} = 0.384  1$。$r \\cdot c_\\ell = 4000 \\cdot 3.2 \\times 10^{-6} = 0.0128  1$。有效。\n2.  **案例 2**：$n \\cdot r \\cdot c_g = 1 \\cdot 4000 \\cdot 1.0 \\times 10^{-5} = 0.04  1$。$r \\cdot c_\\ell = 4000 \\cdot 3.0 \\times 10^{-6} = 0.012  1$。有效。\n3.  **案例 3**：$n \\cdot r \\cdot c_g = 16 \\cdot 1200 \\cdot 5.0 \\times 10^{-5} = 0.96  1$。$r \\cdot c_\\ell = 1200 \\cdot 4.0 \\times 10^{-6} = 0.0048  1$。有效。\n4.  **案例 4**：$n \\cdot r \\cdot c_g = 32 \\cdot 800 \\cdot 3.0 \\times 10^{-5} = 0.768  1$。$r \\cdot c_\\ell = 800 \\cdot 2.0 \\times 10^{-6} = 0.0016  1$。有效。\n5.  **案例 5**：$n \\cdot r \\cdot c_g = 8 \\cdot 5000 \\cdot 1.1 \\times 10^{-5} = 0.44  1$。$r \\cdot c_\\ell = 5000 \\cdot 2.5 \\times 10^{-6} = 0.0125  1$。有效。\n\n所有测试用例都满足稳定性条件。该问题是自包含的、一致的且科学上合理的。\n\n**步骤 3：结论与行动**\n问题是有效的。我们继续进行推导和求解。\n\n**延迟公式的推导**\n\n一个项目在 $M/M/1$ 排队系统中花费的平均时间（记为 $W$）是排队论的一个标准结果。给定到达率 $\\lambda$ 和服务率 $\\mu$，系统中的平均项目数是 $L = \\frac{\\lambda}{\\mu - \\lambda}$。根据利特尔定律，$L = \\lambda W$，这意味着 $W = \\frac{L}{\\lambda} = \\frac{1}{\\mu - \\lambda}$。该公式将用于全局和 per-CPU 排队模型。\n\n**1. 全局锁设计的平均延迟 ($W_g$)**\n此设计被建模为单个 $M/M/1$ 队列。\n- 到达单个全局锁的操作总到达率是所有 $n$ 个 CPU 速率的总和：\n  $$ \\lambda_g = n \\cdot r $$\n- 服务率 $\\mu_g$ 是服务时间 $c_g$ 的倒数：\n  $$ \\mu_g = \\frac{1}{c_g} $$\n- 应用 $M/M/1$ 延迟公式，系统中的平均单次操作时间（排队等待时间加服务时间）为：\n  $$ W_g = \\frac{1}{\\mu_g - \\lambda_g} = \\frac{1}{\\frac{1}{c_g} - n r} $$\n- 为避免大数相减时可能出现的浮点数问题，我们可以将其重写为：\n  $$ W_g = \\frac{c_g}{1 - n r c_g} $$\n此表达式表示在全局锁设计下一次操作的总平均延迟。\n\n**2. Per-CPU 设计的平均延迟 ($W_\\ell$)**\nPer-CPU 设计中的延迟是三个不同组成部分的总和：本地排队延迟、期望迁移成本和摊销合并成本。\n$$ W_\\ell = W_{\\text{queue}} + W_{\\text{migration}} + W_{\\text{consolidation}} $$\n\n- **本地排队延迟 ($W_{\\text{queue}}$)**：每个 CPU 都有自己的数据结构，受其自己的锁保护。这被建模为一个独立的 $M/M/1$ 队列。\n  - 到达单个 CPU 队列的到达率就是 $r$：\n    $$ \\lambda_\\ell = r $$\n  - 服务率是本地服务时间 $c_\\ell$ 的倒数：\n    $$ \\mu_\\ell = \\frac{1}{c_\\ell} $$\n  - 此本地队列的平均延迟为：\n    $$ W_{\\text{queue}} = \\frac{1}{\\mu_\\ell - \\lambda_\\ell} = \\frac{1}{\\frac{1}{c_\\ell} - r} = \\frac{c_\\ell}{1 - r c_\\ell} $$\n\n- **迁移成本 ($W_{\\text{migration}}$)**：问题规定，每次操作有概率 $p$ 会产生一个额外的迁移成本 $c_m$。该成本在所有操作上的平均期望值是延迟的一个附加分量。\n  $$ W_{\\text{migration}} = p \\cdot c_m $$\n\n- **合并成本 ($W_{\\text{consolidation}}$)**：一个合并过程每 $\\Delta$ 秒运行一次，并对每个 CPU 施加 $c_s$ 的成本。此成本必须摊销到在一个间隔内发生的操作上。\n  - 单个 CPU 在 $\\Delta$ 秒间隔内处理的操作数量为 $N_{ops} = r \\cdot \\Delta$。\n  - 总成本 $c_s$ 分摊到这 $N_{ops}$ 个操作上。因此，每次操作的摊销成本为：\n  $$ W_{\\text{consolidation}} = \\frac{c_s}{r \\Delta} $$\n\n- **Per-CPU 总延迟 ($W_\\ell$)**：将这三个分量相加，得到在 per-CPU 设计下一次操作的总平均延迟：\n  $$ W_\\ell = \\frac{c_\\ell}{1 - r c_\\ell} + p c_m + \\frac{c_s}{r \\Delta} $$\n\n**3. 延迟加速比 ($S$)**\n加速比 $S$ 定义为全局锁延迟与 per-CPU 延迟之比。\n$$ S = \\frac{W_g}{W_\\ell} = \\frac{\\frac{c_g}{1 - n r c_g}}{\\frac{c_\\ell}{1 - r c_\\ell} + p c_m + \\frac{c_s}{r \\Delta}} $$\n这就是将要实现并用于计算给定测试用例结果的最终表达式。", "answer": "\"[5.423985,3.430556,202.070312,3.566838,5.408791]\"", "id": "3654522"}]}