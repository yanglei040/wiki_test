{"hands_on_practices": [{"introduction": "理论知识的最终目的是解决实际问题。这个练习将你置于性能工程师的角色，面对一个真实的延迟敏感型服务调优任务。通过分析 CPU 利用率、运行队列长度和缓存未命中率等关键性能指标，你需要准确诊断出导致高尾延迟的瓶颈，并从几个调优选项中做出最明智的决策。[@problem_id:3672826]", "problem": "一个延迟敏感的远程过程调用 (RPC) 微服务运行在一台具有两个非一致性内存访问 (NUMA) 节点的对称多处理器上。该机器拥有 $32$ 个物理核心，均匀地分布在 NUMA 节点 $0$ 上的 $16$ 个核心和 NUMA 节点 $1$ 上的 $16$ 个核心。该服务被置于一个硬处理器亲和性掩码（硬亲和性）下，该掩码将其限制在 NUMA 节点 $0$ 上的 $8$ 个逻辑 CPU 上。操作系统调度器使用软处理器亲和性（软亲和性）来偏好最近使用过的核心，但也可能为了平衡负载而迁移任务。\n\n您可以调整软亲和性的“粘性”（以减少迁移并增加缓存局部性），或调整硬亲和性掩码（以更改服务可运行的 CPU 集合）。在 $\\Delta t = 60$ 秒的观察窗口内，您收集了性能计数器（perf）和服务水平指标：\n\n- 在 $8$ 个允许的 CPU 上，中央处理器 (CPU) 的平均使用率为 $92\\%$，其中 $3$ 个 CPU 的繁忙时间超过 $97\\%$，每个允许的 CPU 平均运行队列长度约为 $1.8$ 个可运行任务。机器上剩余的 $24$ 个 CPU 平均使用率为 $28\\%$。\n- 在允许的集合内，每次请求的平均跨核迁移为 $0.06$；由于硬掩码的构造，跨 NUMA 迁移为 $0$。\n- 末级缓存 (LLC) 未命中率很低：每千条指令的未命中次数 (MPKI) 中位数为 $3$，第九十九百分位数 ($P_{99}$) 为 $6$ MPKI。\n- 测得的服务的第九十九百分位数延迟 $P_{99}$ 为 $15$ 毫秒。服务水平目标是尾延迟目标 $P_{99} \\le X$ 毫秒，其中 $X = 10$ 毫秒。\n\n从基本原理出发，回顾一下：\n- 处理器亲和性约束或偏向线程运行的位置。硬亲和性定义了合法的 CPU 集合。软亲和性使调度器偏向于最近使用过的 CPU，以保持缓存局部性。\n- 缓存局部性减少了 LLC 未命中；频繁的迁移往往会增加 LLC 未命中，因为缓存是每个核心独有的。\n- 用排队论的术语来说，当服务器的使用率 $\\rho$ 接近 $1$ 时，等待时间会迅速增长；将工作分散到更多相同的服务器上可以降低每个服务器的 $\\rho$ 并降低尾延迟。\n\n鉴于以上情况，选择唯一的最佳下一步骤，以满足 $P_{99} \\le 10$ 毫秒的目标，同时将性能退化的风险降至最低。\n\nA. 收紧软亲和性（增加粘性），同时保持相同的硬掩码。\n\nB. 扩展硬亲和性掩码，以包含同一 NUMA 节点上更多的空闲 CPU，并保持软亲和性不变。\n\nC. 跨越两个 NUMA 节点扩展硬亲和性掩码，以包含另一个 NUMA 节点上的 CPU。\n\nD. 不做任何更改，并依赖进一步的缓存预热来降低 $P_{99}$。", "solution": "问题要求找出唯一最佳的操作，以将远程过程调用 (RPC) 微服务的第九十九百分位数 ($P_{99}$) 延迟从测量的 $15$ 毫秒降低到满足服务水平目标 (SLO) $P_{99} \\le 10$ 毫秒。\n\n首先，我们必须对问题陈述进行严格的验证。\n\n**步骤 1：提取已知条件**\n- 系统架构：对称多处理器，两个非一致性内存访问 (NUMA) 节点。\n- 核心配置：总共 $32$ 个物理核心，其中 $16$ 个在 NUMA 节点 $0$ 上，$16$ 个在 NUMA 节点 $1$ 上。\n- 服务配置：服务被硬处理器亲和性掩码限制在 NUMA 节点 $0$ 上的 $8$ 个逻辑 CPU 上。\n- 调度器：操作系统使用软处理器亲和性。\n- 可调参数：软亲和性粘性和硬亲和性掩码。\n- 观察窗口：$\\Delta t = 60$ 秒。\n- 性能指标：\n    - CPU 使用率（亲和性集合）：在 $8$ 个允许的 CPU 上平均为 $92\\%$；其中 $3$ 个 CPU 的使用率超过 $97\\%$。\n    - 运行队列长度：每个允许的 CPU 平均约有 $1.8$ 个可运行任务。\n    - CPU 使用率（其他）：在剩余的 $24$ 个 CPU 上平均为 $28\\%$。\n    - 迁移：在亲和性集合内，每次请求平均有 $0.06$ 次跨核迁移；$0$ 次跨 NUMA 迁移。\n    - 缓存性能：末级缓存 (LLC) 未命中数中位数为每千条指令 $3$ 次 (MPKI)；$P_{99}$ LLC 未命中数为 $6$ MPKI。\n    - 服务延迟：测得的 $P_{99} = 15$ 毫秒。\n    - 延迟目标：$P_{99} \\le X$ 毫秒，其中 $X = 10$ 毫秒。\n- 提供的基本原理：\n    1.  处理器亲和性：硬亲和性设置允许的 CPU；软亲和性使调度器偏向于最近使用过的 CPU。\n    2.  缓存局部性：迁移会增加 LLC 未命中。\n    3.  排队论：当使用率 $\\rho \\to 1$ 时，等待时间会迅速增加。\n\n**步骤 2：使用提取的已知条件进行验证**\n问题陈述具有科学依据、提法明确且客观。它展示了在现代多核、NUMA 系统中的一个经典性能调优场景。\n- NUMA、处理器亲和性、LLC 未命中、MPKI、运行队列长度和尾延迟等概念在计算机科学和操作系统中是标准概念。\n- 提供的数据是一致的，并指向一个可能的性能瓶颈。高 CPU 使用率 ($92\\%$) 与长运行队列 ($1.8 > 1$) 有因果关系，根据排队论，这直接导致等待时间增加，从而导致高尾延迟 ($P_{99}$)。\n- 低 LLC 未命中率 ($3$-$6$ MPKI) 和低迁移率 (每次请求 $0.06$ 次) 一致表明，缓存局部性不是主要问题。\n- 硬亲和性掩码限制在 NUMA 节点 $0$ 上，这正确地解释了为什么跨 NUMA 迁移为 $0$。\n- 问题并非未充分说明；有足够的信息来诊断根本原因并评估选项。它不是矛盾的、不可行的或微不足道的。\n\n**步骤 3：结论和行动**\n问题陈述是 **有效的**。我们可以继续进行解答。\n\n**解答的推导**\n\n主要目标是降低 $P_{99}$ 延迟。我们必须首先通过分析提供的指标来确定当前高延迟的根本原因。\n\n1.  **瓶颈诊断：**\n    最显著的证据是 CPU 争用的状态。分配给该服务的 $8$ 个 CPU 的平均使用率为 $92\\%$。其中三个几乎完全饱和 ($>97\\%$)。接近 $\\rho = 1$ 的使用率水平是性能瓶颈的强烈指标。每个 CPU 平均 $1.8$ 个任务的运行队列长度证实了这一点。大于 $1$ 的运行队列长度意味着，平均而言，可运行的任务多于可用的 CPU，迫使任务等待。这个等待时间，即*排队延迟*，是请求总响应时间的直接贡献者。尾延迟 ($P_{99}$) 对排队延迟尤其敏感，因为它反映了最不幸请求的体验，这些请求是在队列中等待时间最长的请求。\n\n    相比之下，与内存性能相关的指标是有利的。$3$ MPKI（中位数）和 $6$ MPKI ($P_{99}$) 的 LLC 未命中率被描述为低，这对于许多服务器工作负载来说是一个合理的评估。这一点，加上低跨核迁移率（每次请求 $0.06$ 次），表明应用程序表现出良好的缓存局部性，并且操作系统的软亲和性是有效的。\n\n    因此，结论很明确：主要瓶颈是 **CPU 饱和**，而不是缓存性能差或内存延迟过高。该服务因 CPU 周期而“饥饿”，导致高排队延迟，从而导致高 $P_{99}$ 延迟。\n\n2.  **评估建议的行动：**\n    最佳解决方案必须直接解决 CPU 饱和瓶颈，并以最小的风险引入新问题。\n\n    **A. 收紧软亲和性（增加粘性），同时保持相同的硬掩码。**\n    该行动旨在通过使迁移更加不频繁来提高缓存局部性。然而，数据显示缓存局部性已经很好，并不是问题的根源。通过增加粘性，此操作可能会加剧负载不平衡。这将使调度器更难将任务从一个饱和的 ($>97\\%$) 核心移动到 $8$ 个 CPU 集合中一个稍微不那么繁忙（但仍然过载）的核心。这可能会增加而不是减少最坏情况下的排队延迟。这个选项是错误的，因为它针对一个不存在的问题。\n    **结论：不正确。**\n\n    **B. 扩展硬亲和性掩码，以包含同一 NUMA 节点上更多的空闲 CPU，并保持软亲和性不变。**\n    这个行动直接针对问题的根本原因：CPU 饱和。在 NUMA 节点 $0$ 上，总共有 $16$ 个核心，服务只使用了其中的 $8$ 个。这在同一 NUMA 节点上留下了 $16 - 8 = 8$ 个空闲核心。扩展亲和性掩码以包含这些核心中的一部分或全部，将允许工作负载分布到更多的处理器上。这将降低每个核心的平均使用率 $\\rho$，使系统脱离 $\\rho \\approx 1$ 的临界区域。根据排队论原理，使用率的这种降低将导致等待时间的超线性减少，从而直接降低尾延迟。因为新的 CPU 位于*同一个* NUMA 节点上，所以在内存访问延迟方面没有惩罚；所有线程将继续快速、本地地访问节点 $0$ 上的内存。这是一个直接、高效且低风险的解决方案。\n    **结论：正确。**\n\n    **C. 跨越两个 NUMA 节点扩展硬亲和性掩码，以包含另一个 NUMA 节点上的 CPU。**\n    与选项 B 一样，这也会缓解 CPU 饱和。然而，它引入了一个重大的新风险。服务的内存大概是分配在 NUMA 节点 $0$ 上的。如果一个线程被调度到 NUMA 节点 $1$ 的一个 CPU 上，它的内存访问将变为*远程*访问，需要跨越节点间互连。远程内存访问的延迟显著高于本地访问，带宽也更低。这种效应，被称为“NUMA 税”，可能会引入一个新的内存访问瓶颈，抵消拥有更多 CPU 核心的好处，甚至可能增加整体延迟。由于本地 NUMA 节点上有空闲核心，这种跨 NUMA 的扩展是一种不必要且高风险的策略。\n    **结论：不正确。**\n\n    **D. 不做任何更改，并依赖进一步的缓存预热来降低 $P_{99}$。**\n    这个选项基于一个有缺陷的前提。对于一个高流量服务来说，$\\Delta t = 60$ 秒的观察窗口足以达到“热”缓存的稳态。高 CPU 使用率 ($92\\%$) 和长运行队列 ($1.8$) 等关键指标表明存在结构性资源短缺，而不是暂时的预热效应。低 LLC 未命中率进一步证实了缓存性能良好。等待无法解决工作负载需求与所配置的 CPU 资源之间的根本性不匹配问题。\n    **结论：不正确。**\n\n基于此分析，唯一正确识别并以最小风险解决 CPU 饱和瓶颈的选项是在本地 NUMA 节点上扩展 CPU 集合。", "answer": "$$\\boxed{B}$$", "id": "3672826"}, {"introduction": "在系统运维中，事后复盘与主动调优同样重要。本练习模拟了一次生产事故，其中错误的配置导致了硬亲和性设置被意外移除。你的任务是像一位系统侦探一样，通过分析事故前后的 CPU 驻留和迁移日志，重建事件的真相，并深刻理解硬亲和性在 NUMA 架构下对于维持性能稳定的关键作用。[@problem_id:3672794]", "problem": "一个基于 Linux 的服务运行在一个双路非统一内存访问 (NUMA) 系统上。该系统有 $2$ 个插槽（NUMA 节点），每个插槽有 $8$ 个物理核心，总共有 $16$ 个逻辑中央处理器 (CPU)。该服务启动了 $8$ 个相同的、CPU 密集型的工作线程，并使用首次接触分配策略，因此其大部分热点页面在线程最初于 NUMA 节点 $0$ 上运行时就已通过缺页中断分配。自动 NUMA 平衡功能被禁用。最初，每个工作线程都通过核心白名单被硬性绑定（硬性处理器亲和性）到 NUMA 节点 $0$ 上的一个不同核心。在时间 $t_0$，一个配置错误的 cron 作业执行，并将所有服务线程的硬性亲和性掩码重置为允许所有 $16$ 个逻辑 CPU，从而仅保留调度器的软亲和性生效（软亲和性是调度器为了缓存局部性而倾向于将任务保留在同一 CPU 上的偏好，但不是一个严格的约束）。后台批处理作业被绑定到 NUMA 节点 $1$，在那里造成了稳定的争用。\n\n您获得了在两个 $5$ 分钟的时间窗口内按每个工作线程聚合的 CPU 驻留和迁移日志：一个窗口在 $t_0$ 之前，另一个从 $t_0$ 之后立即开始。\n\n$t_0$ 之前：\n- 对于每个工作线程，在其主核心上花费的时间 > 95%，在其他核心上的时间各  1%，每分钟总迁移次数  1。\n- 跨节点驻留比例（在 NUMA 节点 $1$ 的 CPU 上运行的时间）约为 $0\\%$。\n\n$t_0$ 之后：\n- 对于每个工作线程，在单个使用最多的核心上花费的时间在 $30\\%$–$40\\%$ 范围内，在其他几个核心上的时间在 $5\\%$–$20\\%$ 之间；每个工作线程见到的不同核心总数 $ 10$。\n- 每个工作线程的跨节点驻留比例约为 $60\\%$。\n- 每个工作线程每分钟的总迁移次数约为 $120$。\n- 在该时间窗口内，$8$ 个工作线程的聚合 CPU 利用率仍然接近 $8$ 个完全繁忙的 CPU。\n\n假设一个常规的缓存层级结构，其中每个核心都有私有缓存，并共享一个插槽本地的末级缓存 (LLC)，且转译后备缓冲器 (TLB) 状态是每个核心独有的。同时假设由于 NUMA 效应，跨插槽的远程内存访问比本地访问慢。在观测窗口期间，没有其他系统参数发生变化。\n\n仅根据这些日志以及处理器亲和性和 NUMA 的基本定义，以下哪项最能重构该服务在 $t_0$ 之后可能产生的性能影响？\n\nA. 吞吐量下降且延迟方差增加，因为移除硬性亲和性导致频繁的跨核和跨插槽迁移，降低了缓存和转译后备缓冲器 (TLB) 的局部性，并增加了远程内存访问；在负载均衡下，调度器的软亲和性不足以将线程保留在其内存所在的本地节点，因此即使聚合利用率保持高位，每个 CPU 周期的工作量也下降了。\n\nB. 吞吐量增加且延迟降低，因为调度器可以将工作线程分布到更多核心上，软亲和性完美地保留了缓存局部性，并且跨插槽的缓存共享使 LLC 保持温暖，因此远程内存惩罚可以忽略不计。\n\nC. 吞吐量略有增加，因为当线程分布到更多核心时排队延迟减少，并且任何远程内存惩罚都通过自动页面迁移被消除，该机制会立即将热点页面重新定位到正在运行的插槽上，且没有可测量的开销。\n\nD. 吞吐量和延迟基本保持不变，因为软亲和性在实践中阻止了迁移，并且当总 CPU 利用率不变时，高迁移次数与缓存或 NUMA 惩罚无关。\n\n选择唯一的最佳答案。", "solution": "该问题要求分析在非统一内存访问 (NUMA) 系统上，将一个多线程服务的处理器亲和性从硬性更改为软性所带来的性能影响。解决方案必须从提供的日志数据以及操作系统和计算机体系结构的基本原理中推导出来。\n\n**问题验证**\n\n**步骤1：提取已知条件**\n- **系统架构：**\n  - $2$ 个插槽（NUMA 节点）。\n  - 每个插槽 $8$ 个物理核心。\n  - 总共 $16$ 个逻辑中央处理器 (CPU)。\n  - 非统一内存访问 (NUMA)，远程内存访问较慢。\n  - 缓存层级：每个核心有私有缓存，共享插槽本地的末级缓存 (LLC)。\n  - 转译后备缓冲器 (TLB) 状态是每个核心独有的。\n- **工作负载：**\n  - $8$ 个相同的、CPU 密集型的工作线程。\n- **初始状态（$t_0$ 之前）：**\n  - 内存分配：首次接触分配策略导致热点页面驻留在 NUMA 节点 $0$ 上。\n  - 亲和性：将 $8$ 个线程中的每一个硬性绑定到 NUMA 节点 $0$ 上的一个不同核心。\n  - 系统设置：自动 NUMA 平衡功能被禁用。\n  - 日志数据（$t_0$ 之前）：\n    - 每个工作线程在主核心的驻留时间：$ 95\\%$。\n    - 每个工作线程的迁移次数：$  1$ 次/分钟。\n    - 每个工作线程的跨节点驻留（在节点 $1$ 上）比例：$\\approx 0\\%$。\n- **状态变更（在 $t_0$ 时）：**\n  - 硬性亲和性掩码被重置，允许线程在所有 $16$ 个逻辑 CPU 上运行。\n  - 仅调度器的软亲和性保持生效。\n  - 存在来自绑定到 NUMA 节点 $1$ 的后台作业的稳定争用。\n- **最终状态（$t_0$ 之后）：**\n  - 日志数据（$t_0$ 之后）：\n    - 每个工作线程在最常用核心的驻留时间：$30\\%$–$40\\%$。\n    - 每个工作线程见到的不同核心数：$ 10$。\n    - 每个工作线程的跨节点驻留（在节点 $1$ 上）比例：$\\approx 60\\%$。\n    - 每个工作线程的迁移次数：$\\approx 120$ 次/分钟。\n    - $8$ 个工作线程的聚合 CPU 利用率：$\\approx 8$ 个完全繁忙的 CPU。\n\n**步骤2：使用提取的已知条件进行验证**\n问题陈述具有科学依据，定义明确且客观。\n- **科学合理性：** 该场景基于现代操作系统和计算机体系结构中的标准概念，包括 NUMA、处理器亲和性、CPU 调度、缓存层级和 TLB。所描述的行为与 Linux 调度器在此类条件下的行为方式一致。\n- **定义明确且完整：** 问题提供了一个清晰的“之前”和“之后”的状态，并提供了足够的量化数据（日志）和定性描述（系统配置）来推断性能影响。所有必要的假设都已说明。\n- **客观性和一致性：** 问题使用了精确的技术语言。日志数据与所描述的变更一致：对于 CPU 密集型任务，移除硬性亲和性将导致负载均衡调度器频繁迁移它们，这与日志显示的情况完全相符。没有矛盾之处。\n\n**步骤3：结论与行动**\n问题陈述有效，可以推导出解决方案。\n\n**性能影响推导**\n\n1.  **对 $t_0$ 之前状态的分析：**\n    初始配置对于此工作负载在 NUMA 系统上而言，是一个近乎理想的设置。\n    - **硬性亲和性：** 通过将 $8$ 个线程中的每一个绑定到 NUMA 节点 $0$ 上的 $8$ 个不同核心之一，服务自身的线程之间不存在对核心执行资源的争用。\n    - **数据局部性：** 在此绑定阶段期间的首次接触分配策略确保了线程访问的内存页面被分配在 NUMA 节点 $0$ 的本地 RAM 上。\n    - **性能特征：**\n        - **缓存：** 每个线程的工作集在其核心的私有缓存 (L1/L2) 和节点 $0$ 的共享 LLC 中保持“热”状态。低迁移率（$1/\\text{min}$）证实了这种稳定的驻留性。\n        - **TLB：** 每个核心上的 TLB 对于其驻留线程的虚拟到物理地址转换保持“热”状态。\n        - **内存访问：** 所有内存访问都指向节点 $0$ 上的本地 RAM，这是最快的路径。$\\approx 0\\%$ 的跨节点驻留比例证实了这一点。\n    这种状态的特点是高效率：每个 CPU 周期的有用指令数 (IPC) 很高。\n\n2.  **对 $t_0$ 之后状态的分析：**\n    移除硬性亲和性允许操作系统的调度器在所有 $16$ 个 CPU 上管理这 $8$ 个线程的放置，仅受其负载均衡算法和软亲和性的指导。\n    - **调度器行为：** 调度器的目标是保持所有 CPU 负载均匀。看到 $8$ 个 CPU 密集型任务，它会尝试分配它们。节点 $1$ 上存在其他作业使均衡变得复杂，但这并不会阻止调度器在感知到不平衡时将服务线程移动到节点 $1$。日志数据显示每个工作线程每分钟约有 $120$ 次迁移，并且每个工作线程使用了 $10$ 个不同的核心，这证实了调度器正在积极地移动线程。软亲和性，仅仅是一种偏好，显然被负载均衡器覆盖了。\n    - **性能后果：**\n        - **缓存和 TLB 抖动：** 随着频繁的迁移（$\\approx 120/\\text{min}$，或每秒 $2$ 次），一个线程不断地被移动到一个新的核心。这会使新核心的 L1/L2 缓存和 TLB 中关于该线程工作集的状态失效，从而强制从更高级别的内存中进行昂贵的重新抓取和页表遍历。这被称为缓存和 TLB 抖动。\n        - **NUMA 惩罚：** 最关键的影响来自跨插槽迁移。日志显示线程约有 $60\\%$ 的时间在 NUMA 节点 $1$ 的核心上运行。然而，它们的内存仍然在 NUMA 节点 $0$ 上（因为自动平衡已关闭）。因此，在大约 $60\\%$ 的执行时间里，这些线程正在执行跨插槽间链路的远程内存访问。这些远程访问的延迟明显高于本地访问，带宽也更低。\n        - **对 CPU 利用率的影响：** 日志指出，聚合 CPU 利用率保持在高位（$\\approx 8$ 个完全繁忙的 CPU）。这是一个关键的观察结果。这意味着 CPU 正在花费周期，但这*并不*意味着它们在取得有用的进展。现在，这些周期中的很大一部分被浪费在因等待来自远程内存的数据或从缓存/TLB 未命中中恢复而导致的流水线停顿上。因此，每个 CPU 周期完成的工作量 (IPC) 必然会急剧下降。\n    - **总体性能影响：** 缓存/TLB 抖动，以及最重要的是，频繁、高延迟的远程 NUMA 内存访问的组合，将导致实际完成的工作量严重下降。这意味着**吞吐量必须下降**。由于调度和迁移事件引入了可变性，完成任何给定工作单元的时间将变得不那么可预测，这意味着**延迟方差将增加**。\n\n**逐项分析选项**\n\n- **选项 A：** “吞吐量下降且延迟方差增加，因为移除硬性亲和性导致频繁的跨核和跨插槽迁移，降低了缓存和转译后备缓冲器 (TLB) 的局部性，并增加了远程内存访问；在负载均衡下，调度器的软亲和性不足以将线程保留在其内存所在的本地节点，因此即使聚合利用率保持高位，每个 CPU 周期的工作量也下降了。”\n  - 该陈述准确地综合了从问题描述和日志中推导出的所有后果。它正确地指出了吞ut量的下降、延迟方差的增加，以及根本原因：频繁迁移、缓存/TLB 局部性下降和远程内存访问增加。它正确地指出软亲和性不足，并正确地解释了“高利用率”不等于“高吞吐量”。\n  - **结论：正确**\n\n- **选项 B：** “吞吐量增加且延迟降低，因为调度器可以将工作线程分布到更多核心上，软亲和性完美地保留了缓存局部性，并且跨插槽的缓存共享使 LLC 保持温暖，因此远程内存惩罚可以忽略不计。”\n  - 该陈述包含多个事实错误。吞吐量不会增加。日志显示软亲和性是无效的，而不是完美的。LLC 通常不在插槽间共享。远程内存惩罚是 NUMA 的决定性特征，并且不可忽略，尤其是在跨节点驻留比例约为 $60\\%$ 的情况下。\n  - **结论：错误**\n\n- **选项 C：** “吞吐量略有增加，因为当线程分布到更多核心时排队延迟减少，并且任何远程内存惩罚都通过自动页面迁移被消除，该机制会立即将热点页面重新定位到正在运行的插槽上，且没有可测量的开销。”\n  - 这是错误的。问题明确指出“自动 NUMA 平衡功能被禁用”，因此页面不会被迁移。此外，即使启用了该功能，页面迁移也是一个重量级、非瞬时的过程，具有可测量的开销。将线程分散开来的任何微小好处都会被巨大的 NUMA 惩罚所淹没。\n  - **结论：错误**\n\n- **选项 D：** “吞吐量和延迟基本保持不变，因为软亲和性在实践中阻止了迁移，并且当总 CPU 利用率不变时，高迁移次数与缓存或 NUMA 惩罚无关。”\n  - 该陈述与证据直接矛盾。日志显示软亲和性*并不能*阻止迁移（$\\approx 120/\\text{min}$）。断言迁移次数与性能惩罚无关，在缓存和 NUMA 局部性的背景下是根本错误的。它也误解了“CPU 利用率”的含义。\n  - **结论：错误**\n\n唯一一个根据所提供的先验知识和日志数据正确重构性能影响的选项是 A。", "answer": "$$\\boxed{A}$$", "id": "3672794"}, {"introduction": "除了分析经验数据，建立量化模型是理解和预测系统性能的更高阶技能。这个练习将引导你使用排队论这一经典工具，为在硬亲和性与软亲和性策略下运行的流处理管道建立数学模型。通过推导端到端延迟的解析表达式，你将能够精确地量化缓存命中率提升与任务迁移开销之间的权衡。[@problem_id:3672755]", "problem": "一个多核系统以 $P$ 个阶段的流水线形式执行一个流式工作负载。每个阶段 $i \\in \\{1,2,\\dots,P\\}$ 从一个生产者-消费者队列中读取输入，执行计算，并将其结果入队到下一阶段的队列中。第一阶段的外部到达过程被建模为速率为 $\\lambda$ 的泊松过程。假设每个阶段的队列在稳态下可以近似为一个马尔可夫到达、马尔可夫服务、单服务器 (M/M/1) 队列。\n\n在硬处理器亲和性下，每个阶段 $i$ 被绑定到一个单独的中央处理器 (CPU) 核心上，该核心在缓存中保留其工作集，从而产生有效指数服务速率 $\\mu_i^{\\mathrm{H}} = \\gamma_i \\mu_i$，其中 $\\gamma_i \\geq 1$ 且基准 $\\mu_i  0$。在软处理器亲和性下，由阶段 $i$ 执行的每个任务在连续激活之间可能以概率 $q_i \\in [0,1)$ 跨核心迁移；在发生迁移的激活中，冷缓存效应会通过一个惩罚因子 $\\beta_i \\in (0,1)$ 来缩放基准速率，因此该激活的服务速率为 $\\beta_i \\mu_i$，否则为 $\\mu_i$。为了在软亲和性下进行 M/M/1 近似，我们将阶段 $i$ 的服务时间分布建模为单个指数分布，其速率等于其平均服务时间的倒数，\n$$\n\\mu_i^{\\mathrm{S}} = \\left( (1 - q_i)\\frac{1}{\\mu_i} + q_i \\frac{1}{\\beta_i \\mu_i} \\right)^{-1}.\n$$\n\n假设两种策略下系统都是稳定的，即 $\\lambda  \\min_{i} \\{\\mu_i^{\\mathrm{H}}\\}$ 且 $\\lambda  \\min_{i} \\{\\mu_i^{\\mathrm{S}}\\}$，并且 M/M/1 离去过程的结果 (Burke 定理) 成立，因此在稳态下每个阶段的到达都是速率为 $\\lambda$ 的泊松过程。\n\n仅使用 M/M/1 系统的基本排队论结果和上述定义，推导软亲和性下的端到端流水线平均延迟与硬亲和性下的端到端流水线平均延迟之比 $R$ 的闭式解析表达式，\n$$\nR \\equiv \\frac{\\mathbb{E}[T_{\\mathrm{soft}}]}{\\mathbb{E}[T_{\\mathrm{hard}}]},\n$$\n该表达式是关于 $i=1,\\dots,P$ 的 $\\lambda$、$\\mu_i$、$\\gamma_i$、$q_i$ 和 $\\beta_i$ 的函数。您的最终答案必须是单个闭式解析表达式。不需要进行数值评估。", "solution": "该问题要求推导一个由 $P$ 个 M/M/1 队列组成的流水线的端到端平均延迟在两种不同处理器亲和性策略下的比率。\n\n**第一步：定义两种策略下的总延迟**\n\n根据排队网络的线性性质，流水线的总端到端平均延迟（即平均逗留时间）是每个阶段平均延迟的总和。\n$$ \\mathbb{E}[T_{\\text{total}}] = \\sum_{i=1}^{P} \\mathbb{E}[T_i] $$\n对于一个到达率为 $\\lambda'$ 且服务速率为 $\\mu'$ 的 M/M/1 队列，其平均延迟由以下公式给出：\n$$ \\mathbb{E}[T] = \\frac{1}{\\mu' - \\lambda'} $$\n根据 Burke 定理，流水线中每个阶段的到达率都是 $\\lambda$。\n\n**第二步：计算硬亲和性下的延迟 ($\\mathbb{E}[T_{\\mathrm{hard}}]$)**\n\n在硬亲和性策略下，第 $i$ 阶段的服务速率为 $\\mu_i^{\\mathrm{H}} = \\gamma_i \\mu_i$。因此，第 $i$ 阶段的平均延迟为：\n$$ \\mathbb{E}[T_{i, \\mathrm{hard}}] = \\frac{1}{\\mu_i^{\\mathrm{H}} - \\lambda} = \\frac{1}{\\gamma_i \\mu_i - \\lambda} $$\n对所有 $P$ 个阶段求和，得到总的端到端平均延迟：\n$$ \\mathbb{E}[T_{\\mathrm{hard}}] = \\sum_{i=1}^{P} \\frac{1}{\\gamma_i \\mu_i - \\lambda} $$\n\n**第三步：计算软亲和性下的延迟 ($\\mathbb{E}[T_{\\mathrm{soft}}]$)**\n\n在软亲和性策略下，我们需要首先简化给定的有效服务速率 $\\mu_i^{\\mathrm{S}}$ 的表达式。该速率是平均服务时间的倒数。\n$$ \\frac{1}{\\mu_i^{\\mathrm{S}}} = (1 - q_i)\\frac{1}{\\mu_i} + q_i \\frac{1}{\\beta_i \\mu_i} $$\n找到一个公共分母 $\\beta_i \\mu_i$：\n$$ \\frac{1}{\\mu_i^{\\mathrm{S}}} = \\frac{(1 - q_i)\\beta_i}{\\beta_i \\mu_i} + \\frac{q_i}{\\beta_i \\mu_i} = \\frac{\\beta_i - \\beta_i q_i + q_i}{\\beta_i \\mu_i} = \\frac{\\beta_i + q_i(1 - \\beta_i)}{\\beta_i \\mu_i} $$\n因此，有效服务速率为：\n$$ \\mu_i^{\\mathrm{S}} = \\frac{\\beta_i \\mu_i}{\\beta_i + q_i(1 - \\beta_i)} $$\n现在，我们可以计算第 $i$ 阶段的平均延迟：\n$$ \\mathbb{E}[T_{i, \\mathrm{soft}}] = \\frac{1}{\\mu_i^{\\mathrm{S}} - \\lambda} = \\frac{1}{\\frac{\\beta_i \\mu_i}{\\beta_i + q_i(1 - \\beta_i)} - \\lambda} $$\n对所有 $P$ 个阶段求和，得到总的端到端平均延迟：\n$$ \\mathbb{E}[T_{\\mathrm{soft}}] = \\sum_{i=1}^{P} \\frac{1}{\\frac{\\beta_i \\mu_i}{\\beta_i + q_i(1 - \\beta_i)} - \\lambda} $$\n\n**第四步：推导比率 $R$**\n\n比率 $R$ 是 $\\mathbb{E}[T_{\\mathrm{soft}}]$ 与 $\\mathbb{E}[T_{\\mathrm{hard}}]$ 之商。\n$$ R = \\frac{\\mathbb{E}[T_{\\mathrm{soft}}]}{\\mathbb{E}[T_{\\mathrm{hard}}]} = \\frac{\\sum_{i=1}^{P} \\frac{1}{\\frac{\\beta_i \\mu_i}{\\beta_i + q_i(1 - \\beta_i)} - \\lambda}}{\\sum_{i=1}^{P} \\frac{1}{\\gamma_i \\mu_i - \\lambda}} $$\n为了得到一个更整洁的表达式，我们可以简化分子中的项：\n$$ \\frac{1}{\\frac{\\beta_i \\mu_i}{\\beta_i + q_i(1 - \\beta_i)} - \\lambda} = \\frac{1}{\\frac{\\beta_i \\mu_i - \\lambda(\\beta_i + q_i(1 - \\beta_i))}{\\beta_i + q_i(1 - \\beta_i)}} = \\frac{\\beta_i + q_i(1 - \\beta_i)}{\\beta_i \\mu_i - \\lambda(\\beta_i + q_i(1 - \\beta_i))} $$\n将这个简化的形式代入比率 $R$ 的表达式中，我们得到最终的闭式解析表达式。", "answer": "$$\n\\boxed{\nR = \\frac{\\sum_{i=1}^{P} \\frac{\\beta_i + q_i(1 - \\beta_i)}{\\beta_i \\mu_i - \\lambda(\\beta_i + q_i(1 - \\beta_i))}}{\\sum_{i=1}^{P} \\frac{1}{\\gamma_i \\mu_i - \\lambda}}\n}\n$$", "id": "3672755"}]}