{"hands_on_practices": [{"introduction": "线程模型虽然是运行时的内部实现，但它们的行为差异会在操作系统层面留下可观测的痕迹。本练习将指导你如何像侦探一样，通过分析 `strace` 这类系统调用追踪工具的输出来识别程序所采用的线程模型。这让你能将抽象的理论（一对一、多对一、多对多）与具体的系统行为联系起来，这是一项宝贵的诊断技能 [@problem_id:3689564]。", "problem": "一名软件工程师在一台现代操作系统（OS）上，使用系统调用跟踪器（strace）对同一个多线程程序的三个构建版本进行诊断。该程序创建了 $U = 4$ 个用户级工作线程。每个工作线程无限重复以下循环：在用户空间中执行大约 $100$ 毫秒的计算（无系统调用），然后对其自己的管道执行一次阻塞式读系统调用，最后执行一次短暂的写系统调用，将一个状态字节追加到一个共享日志文件中。每个工作线程的管道由一个慢速生产者提供数据，因此读取操作会频繁阻塞。系统调用跟踪器在调用时使用了跟踪线程和时间戳的选项。假设所有的读写都是标准的阻塞式调用，并且运行时库没有使用非阻塞输入/输出（I/O）或 I/O 多路复用。\n\n给定来自 strace 的三个观察结果，每个构建版本一个，其中跟踪器中显示的线程标识符对应一个内核线程（有时称为轻量级进程）：\n- 跟踪 A：在整个跟踪过程中只出现一个内核线程标识符。当任何工作线程发出阻塞式读取时，在很长一段时间内，直到该读取返回之前，没有任何其他线程的读或写操作出现。来自不同工作线程的写操作在时间上从不交错出现；它们严格地一个接一个地发生，中间被对应于阻塞式读取的长时间空闲间隔所分隔。\n- 跟踪 B：恰好出现 $4$ 个不同的内核线程标识符。当一个工作线程在读取中阻塞时，其他内核线程标识符继续向日志文件发出写操作。来自不同标识符的写操作在时间上频繁交错。\n- 跟踪 C：尽管有 $4$ 个用户级工作线程，但恰好出现 $2$ 个不同的内核线程标识符。当超过 $2$ 个工作线程在读取中阻塞时，在其中一个阻塞式读取返回之前，看不到任何额外的进展。当一个标识符在读取中阻塞时，另一个标识符继续发出可归因于其他某个工作线程的写操作。\n\n仅使用以下基本事实和定义：\n- 用户级线程由用户空间中的运行时库创建和调度；内核级线程由内核创建和调度。\n- 阻塞式系统调用（例如，对空管道的读取）会导致调用该调用的内核线程在内核中休眠，直到操作可以完成；在阻塞条件解决之前，内核不会调度该休眠的内核线程。\n- 系统调用跟踪器显示内核边界处的系统调用，并用调用它的内核线程的标识符标记每个调用；跟踪器不显示纯用户空间的计算步骤。\n- 在多对一模型中，$M$ 个用户级线程映射到一个内核级线程；在一对一模型中，每个用户级线程映射到一个不同的内核级线程；在多对多模型中，$M$ 个用户级线程在 $N$ 个内核级线程上进行多路复用，通常情况下 $1 < N < M$。\n\n哪种线程模型到跟踪 A、B 和 C 的分配与观察结果最一致？\n\nA. A：多对一，B：一对一，C：多对多\n\nB. A：一对一，B：多对一，C：多对多\n\nC. A：多对一，B：多对多，C：一对一\n\nD. A：多对多，B：一对一，C：多对一\n\nE. 以上都不是；strace 无法根据这些观察结果区分映射模型", "solution": "问题要求将正确的线程模型（多对一、一对一或多对多）分配给由 `strace` 工具揭示的一个多线程程序的三个观察到的行为。分析的关键在于用户级线程、内核级线程以及阻塞式系统调用的影响之间的关系。\n\n该程序创建了 $U = 4$ 个用户级工作线程。系统调用跟踪器 `strace` 报告内核级别的活动，通过执行系统调用的特定内核线程来识别它们。\n\n让我们根据提供的定义和观察来分析每个跟踪。\n\n**跟踪 A 的分析**\n\n- **观察结果：**只观察到一个内核线程标识符。当任何用户级工作线程执行阻塞式 `read` 系统调用时，整个进程的所有系统调用活动都停止了。直到阻塞的 `read` 完成，才观察到其他 `read` 或 `write` 调用。\n- **推理：**对于一个拥有 $U = 4$ 个用户线程的进程，观察到单个内核线程标识符，这表明所有 $4$ 个用户级线程都被映射到一个单一的内核级线程。这是**多对一**模型的定义。在这种模型中，如果任何用户级线程执行阻塞式系统调用，底层的（也是唯一的）内核线程就会阻塞。操作系统的调度器只看到这一个内核线程，由于它处于休眠状态，因此无法被调度。因此，没有其他用户级线程可以运行，因为用户级线程调度器本身也无法执行。这阻止了任何其他用户线程取得进展并发出自己的系统调用，这与观察到的整个进程变为空闲状态完全匹配。\n- **结论：**跟踪 A 与**多对一**线程模型一致。\n\n**跟踪 B 的分析**\n\n- **观察结果：**观察到恰好 $4$ 个不同的内核线程标识符。当一个内核线程在 `read` 上阻塞时，与该进程关联的其他内核线程会继续执行并发出 `write` 系统调用。\n- **推理：**观察到的内核线程数量（$4$）等于用户级线程的数量（$U = 4$）。这表明每个用户级线程都映射到其自己的专用内核级线程。这是**一对一**模型的定义。在此模型中，当一个用户线程执行阻塞式系统调用时，只有其对应的内核线程被操作系统阻塞。支持其他 $3$ 个用户线程的另外 $3$ 个内核线程仍然是可运行的。操作系统调度器可以继续调度这些其他内核线程，从而允许它们支持的用户线程取得进展，包括执行它们的 `write` 系统调用。这实现了真正的并发性，并解释了为什么即使在一个工作线程被阻塞时，来自不同工作线程的 `write` 调用也可以在时间上交错。\n- **结论：**跟踪 B 与**一对一**线程模型一致。\n\n**跟踪 C 的分析**\n\n- **观察结果：**尽管有 $U = 4$ 个用户级线程，但只观察到恰好 $2$ 个不同的内核线程标识符。当一个内核线程被阻塞时，另一个可以继续执行系统调用。但是，如果超过 $2$ 个用户工作线程在 `read` 中被阻塞，所有进展都会停止。\n- **推理：**在这里，我们有 $M=4$ 个用户线程在 $N=2$ 个内核线程上进行多路复用。这符合**多对多**模型的定义，该模型要求 $1  N  M$。在本例中，$1  2  4$。\n    - 用户级线程调度器负责将 $4$ 个用户线程映射到 $2$ 个内核线程上。\n    - 如果一个用户线程进行阻塞调用，它会占用两个内核线程中的一个。用户级调度器仍然可以将剩余的就绪用户线程映射到可用的那个内核线程上，从而使应用程序能够取得进展。这与观察到当一个标识符被阻塞时，另一个可以继续工作的现象是一致的。\n    - 系统的并发性受内核线程数量 $N=2$ 的限制。如果两个用户线程进行阻塞调用，两个可用的内核线程都将被阻塞。此时，即使其他 $2$ 个用户线程已准备好运行，也没有可用的内核线程来执行它们。整个进程陷入停滞。这完美地解释了“当超过 $2$ 个工作线程在读取中阻塞时，看不到任何额外的进展”这一观察结果。\n- **结论：**跟踪 C 与**多对多**线程模型一致。\n\n**分配总结：**\n-   跟踪 A：**多对一**\n-   跟踪 B：**一对一**\n-   跟踪 C：**多对多**\n\n现在，我们评估给出的选项。\n\n**逐项分析**\n\n- **A. A：多对一，B：一对一，C：多对多**\n 此分配与我们对所有三个跟踪得出的结论相符。\n **结论：正确。**\n\n- **B. A：一对一，B：多对一，C：多对多**\n 这错误地分配了跟踪 A 和跟踪 B 的模型。跟踪 A 只有 $1$ 个内核线程，不可能是一对一。跟踪 B 有 $4$ 个内核线程，不可能是多对一。\n **结论：不正确。**\n\n- **C. A：多对一，B：多对多，C：一对一**\n 这错误地分配了跟踪 B 和跟踪 C 的模型。跟踪 B 有 $4$ 个内核线程对应 $4$ 个用户线程，这是一对一，而不是多对多。跟踪 C 有 $2$ 个内核线程对应 $4$ 个用户线程，不可能是一对一。\n **结论：不正确。**\n\n- **D. A：多对多，B：一对一，C：多对一**\n 这错误地分配了跟踪 A 和跟踪 C 的模型。跟踪 A 只有 $1$ 个内核线程，是多对一，而不是多对多。跟踪 C 有 $2$ 个内核线程，不可能是多对一。\n **结论：不正确。**\n\n- **E. 以上都不是；strace 无法根据这些观察结果区分映射模型**\n 我们的分析表明，来自 `strace` 的观察结果，特别是内核线程标识符的数量和在阻塞系统调用下的行为，足以区分这三种基本的线程模型。\n **结论：不正确。**\n\n与分析一致的唯一选项是 A。", "answer": "$$\\boxed{A}$$", "id": "3689564"}, {"introduction": "线程模型的选择并非总是优劣分明，而是一项基于工作负载特性的工程权衡。此练习引导你通过建立一个量化模型，来分析这种权衡关系，特别是上下文切换开销与因阻塞I/O导致的并行度损失之间的平衡。通过推导临界阻塞率 $p^{*}$ [@problem_id:3689613]，你将能从数学上精确理解为什么在特定场景下，多对多模型比一对一模型更具优势。", "problem": "一台拥有$P$个相同核心的计算机运行着一个大型多线程工作负载。每个用户线程在中央处理器（CPU）计算阶段和阻塞式输入/输出（I/O）阶段之间交替进行。定义阻塞分数$p$，使得对于固定的每线程周期长度$L$，每个周期的CPU计算时间为$(1-p)L$，阻塞式I/O等待时间为$pL$。假设有$T$个用户线程，且$T \\gg P$。考虑两种线程模型：\n\n- 一对一（内核级）模型：每个用户线程都是一个内核线程。阻塞式I/O导致线程阻塞，操作系统（OS）在每次转换到阻塞状态时以及唤醒时都会执行一次成本为$c_k$的内核级上下文切换；也就是说，每个周期进行两次内核上下文切换，总成本为$2c_k$。因为$T \\gg P$，所以总有至少$P$个可运行的内核线程，因此核心不会因阻塞而缺少工作。\n\n- 多对多模型：使用$K$个轻量级进程（LWP），其中$K=P$。一个用户级调度器将用户线程多路复用到$K$个LWP上。当一个用户线程同步执行阻塞式I/O时，运行它的LWP也会阻塞$p$比例的时间，因此在任何时刻，未阻塞的LWP的期望数量为$P(1-p)$。用户级调度器在让出给I/O时以及恢复时都会执行一次成本为$c_u$的用户级上下文切换，每个周期总成本为$2c_u$。\n\n使用以下基本原则：\n\n- $P$个核心上的吞吐量与单位时间内完成的有效CPU工作总量成正比。\n\n- 阻塞式I/O等待时间$pL$不消耗核心时间；上下文切换成本$c_k$和$c_u$消耗核心时间。\n\n- 对于一个未阻塞的线程或LWP，在一个周期内，其用于有效CPU工作的核心时间比例为$\\frac{(1-p)L}{(1-p)L + \\text{overhead}}$，其中$\\text{overhead}$是在该周期内产生的总上下文切换成本。\n\n在这些假设下，推导出临界阻塞分数$p^{*}$（以$L$、$c_k$和$c_u$的闭式解析表达式表示），在该分数下，多对多模型在$P$个核心上实现的吞吐量与一对一模型完全相同。当$p  p^{*}$时，多对多模型的性能优于一对一模型。不需要进行数值四舍五入，最终表达式中不应包含任何物理单位。", "solution": "我们从吞吐量和周期结构的定义开始。每个用户线程的周期总持续时间为$L$，包括一个持续时间为$(1-p)L$的CPU计算阶段和一个持续时间为$pL$的阻塞式I/O阶段。阻塞式I/O不消耗CPU核心时间；上下文切换开销消耗核心时间。\n\n对于一对一模型，由于$T \\gg P$，尽管有些线程被阻塞，操作系统总是有至少$P$个可运行的内核线程。因此，所有$P$个核心都可以保持忙碌。在一个周期内，一个线程会产生两次内核级上下文切换（一次在转换到阻塞时，一次在唤醒时），每次成本为$c_k$，总开销为$2c_k$。对于一个未阻塞的实体，其用于有效CPU工作的核心时间比例为\n$$\n\\frac{(1-p)L}{(1-p)L + 2c_k}.\n$$\n由于有$P$个核心保持忙碌，聚合的有效CPU工作率（在一个与核心速度相关的比例常数下）为\n$$\nX_{1:1} = P \\cdot \\frac{(1-p)L}{(1-p)L + 2c_k}.\n$$\n\n对于使用$K=P$个轻量级进程（LWP）的多对多模型，同步阻塞式I/O导致每个LWP阻塞$p$比例的时间。在任何时刻，未阻塞的LWP的期望数量为$P(1-p)$，因此最多有$P(1-p)$个LWP可以并发运行，当$p>0$时可能会使一些核心闲置。对于一个活跃的LWP，在一个周期内，用户级调度器会产生两次用户级上下文切换（在I/O时让出和恢复时），每次成本为$c_u$，总开销为$2c_u$。对于一个活跃的LWP，其用于有效CPU工作的核心时间比例为\n$$\n\\frac{(1-p)L}{(1-p)L + 2c_u}.\n$$\n对活跃LWP的期望数量进行汇总，总的有效CPU工作率为\n$$\nX_{m:m} = P(1-p) \\cdot \\frac{(1-p)L}{(1-p)L + 2c_u}.\n$$\n\n我们寻求临界阻塞分数$p^{*}$，使得$X_{m:m} = X_{1:1}$。将两个表达式相等并消去公共正因子，得到\n$$\nP(1-p) \\cdot \\frac{(1-p)L}{(1-p)L + 2c_u} \\;=\\; P \\cdot \\frac{(1-p)L}{(1-p)L + 2c_k}.\n$$\n消去$P$和$(1-p)L$（在$p \\neq 1$时有效），我们得到\n$$\n(1-p) \\cdot \\frac{1}{(1-p)L + 2c_u} \\;=\\; \\frac{1}{(1-p)L + 2c_k}.\n$$\n两边同乘以正分母，得到\n$$\n(1-p)\\big((1-p)L + 2c_k\\big) = (1-p)L + 2c_u.\n$$\n令$x = 1 - p$。则等式变为\n$$\nx \\big(xL + 2c_k\\big) = xL + 2c_u,\n$$\n展开后为\n$$\nL x^{2} + 2c_k x = xL + 2c_u.\n$$\n整理各项，得到关于$x$的二次方程：\n$$\nL x^{2} + (2c_k - L) x - 2c_u = 0.\n$$\n使用二次公式求解$x$，\n$$\nx = \\frac{L - 2c_k \\pm \\sqrt{(2c_k - L)^{2} + 8Lc_u}}{2L}.\n$$\n由于两根之积为$-2c_u/L  0$，一个根是负的，一个是正的。在区间$[0,1]$内具有物理意义的根是带加号的那个：\n$$\nx^{*} = \\frac{L - 2c_k + \\sqrt{(2c_k - L)^{2} + 8Lc_u}}{2L}.\n$$\n回忆$x = 1 - p$，临界阻塞分数为\n$$\np^{*} = 1 - x^{*} = \\frac{L + 2c_k - \\sqrt{(2c_k - L)^{2} + 8Lc_u}}{2L}.\n$$\n\n因此，多对多模型的性能优于一对一模型，当且仅当$p  p^{*}$，其中$p^{*}$由上述闭式表达式给出。注意，最终表达式与$P$无关，因为两种模型的总吞吐量都与$P$成线性关系，且等式条件涉及的比例会消去$P$。", "answer": "$$\\boxed{\\frac{L + 2c_k - \\sqrt{(2c_k - L)^{2} + 8Lc_u}}{2L}}$$", "id": "3689613"}, {"introduction": "多对一线程模型因其用户态调度的轻量高效而具备吸引力，但它有一个致命弱点：任何一个阻塞的系统调用都可能“冻结”整个应用程序。本练习将你置于一个真实的工程场景中，要求你解决由 `getaddrinfo` 这样的库函数引起的全局停滞问题 [@problem_id:3689607]。你将评估多种解决方案，学会如何通过线程池、异步API或独立进程等技术来“卸载”阻塞操作，从而设计出健壮的系统。", "problem": "一个运行时系统实现了一个多对一用户级线程模型，其中 $U$ 个用户线程被多路复用到 $K = 1$ 个内核线程上。其调度器是协作式和事件驱动的，其核心不变量是，当唯一的内核线程在系统调用中被阻塞时，所有 $U$ 个用户线程都将无法取得进展。考虑一个由 $n$ 个用户线程组成的工作负载，这些线程执行网络密集型任务，偶尔会调用主机名解析例程 $getaddrinfo$，通过域名系统 (DNS) 将域名转换为地址。根据经验，在不利的网络条件下，$getaddrinfo$ 解析域名时，运行时系统会表现出数毫秒的停顿。\n\n从以下基本事实和定义出发，对可能阻塞的库函数的包装器设计进行推理：\n\n- 在多对一映射中，操作系统的调度器只调度单个内核线程；用户级调度纯粹在用户空间进行，内核对用户线程一无所知。因此，由该内核线程执行的任何阻塞操作都会阻止所有用户线程运行，直到该调用返回。\n- 阻塞调用是指其执行可能不会立即完成，并可能等待外部事件（例如，网络 I/O）的调用。在可移植操作系统接口 (POSIX) 中，等待 I/O 的阻塞系统调用可能无法被任意信号中断，并且库可能会透明地重启被中断的调用。\n- 为保持安全性，任何包装器都必须保留应用可见的语义，避免未定义行为，并在不违反应用程序编程接口 (API) 协定的情况下与用户级调度器集成。特别是，对于未指定为安全的函数，包装器必须遵守其可重入性和异步信号安全性的要求。\n- $getaddrinfo$ 执行的 DNS 解析内部可能使用套接字和 I/O，但该细节依赖于具体实现且未经标准化。GNU C 库 (glibc) 在某些系统上提供了一个异步变体 $getaddrinfo\\_a$。\n\n运行时工程师提出了几种策略来检测和转移可能阻塞的调用，以使单个内核线程永远不会导致整个进程停顿。如果正确实现，哪些策略既能在多对一模型中防止全局停顿，又能保持正确性？选择所有适用的选项。\n\nA. 在 $getaddrinfo$ 周围插入一个包装器（例如通过动态链接器插入），该包装器在一个由 $pthread\\_create$ 创建的专用内核线程池中执行该调用。包装器立即向用户级调度器返回一个类似 future 的句柄；用户线程被挂起，并通过一个线程安全队列和一个集成到事件循环中的 eventfd 或管道来通知完成。该包装器将 $getaddrinfo$ 视为可能阻塞的，并且绝不在单个内核线程上执行它。\n\nB. 安装一个定期的 $SIGALRM$，在调度器时间量 $q$ 后触发，并包装 $getaddrinfo$，使得信号处理器能够抢占该调用，将执行权让给其他用户线程。该包装器假定信号会中断 $getaddrinfo$，从而允许用户级调度器在同一个内核线程上继续执行，并在稍后恢复该调用。\n\nC. 通过调用 $res\\_init$ 并调整解析器选项（例如，更短的重试间隔、更少的域名服务器）来激进地配置解析器超时，以减少预期的解析时间 $T\\_{\\mathrm{dns}}$。继续在单个内核线程上执行 $getaddrinfo$；依赖于降低的阻塞概率来避免全局停顿。\n\nD. 在可用时使用 $getaddrinfo\\_a$ 来获得异步名称解析，将其完成通知集成到事件循环中，并在不可用时回退到卸载方式。通过使用异步交付并在完成前挂起用户级线程，确保包装器绝不在单个内核线程上运行阻塞式解析。\n\nE. 使用 $fork$-和-管道隔离来包装 $getaddrinfo$：包装器 $fork$ 一个子进程来执行 $getaddrinfo$；子进程将得到的 $struct\\ addrinfo$ 序列化为可移植格式并写入管道；父进程立即返回到用户级调度器，挂起调用方用户线程，并在管道就绪后反序列化结果。单个内核线程本身永远不会执行可能阻塞的解析操作。\n\n答案选项相互独立；选择所有满足所述条件的选项。", "solution": "问题描述了在采用多对一用户级线程模型的系统中一个经典的挑战：由单个底层内核线程进行的阻塞系统调用将阻塞所有用户级线程。目标是评估几种为可能阻塞的函数 `getaddrinfo` 设计的包装策略，以防止此类全局停顿，同时保持正确性。该系统有 $U$ 个用户线程在 $K=1$ 个内核线程上运行，工作负载为 $n$ 个任务。\n\n一个有效解决方案的核心原则是，负责运行用户级调度器事件循环的单个内核线程*绝不能*执行可能阻塞不确定时间的任何操作。阻塞操作必须被卸载到一个操作系统内核可以独立调度的独立执行上下文中。\n\n让我们逐一分析每个提议的策略。\n\n**A. 在 $getaddrinfo$ 周围插入一个包装器（例如通过动态链接器插入），该包装器在一个由 $pthread\\_create$ 创建的专用内核线程池中执行该调用。包装器立即向用户级调度器返回一个类似 future 的句柄；用户线程被挂起，并通过一个线程安全队列和一个集成到事件循环中的 eventfd 或管道来通知完成。该包装器将 $getaddrinfo$ 视为可能阻塞的，并且绝不在单个内核线程上执行它。**\n\n这个策略正确地识别了问题，并提出了一个健壮的标准解决方案。\n1.  **防止全局停顿**：通过使用 `pthread_create` 创建一个独立的内核线程池，阻塞的 `getaddrinfo` 调用由一个工作内核线程执行，而不是由运行用户级调度器的主内核线程执行。主线程只是将任务入队并继续其事件循环，运行其他就绪的用户线程。工作线程的阻塞不影响主线程，从而防止了全局停顿。这实际上在阻塞调用期间临时创建了一个多对多模型。\n2.  **保持正确性**：所述的返回结果的机制是合理的。一个“future”句柄、挂起用户线程、使用线程安全队列来存放结果并结合 `eventfd` 或管道进行通知，是将异步工作集成到事件驱动系统中的典范模式。它确保结果在没有竞争条件的情况下被传递回正确的用户线程，并且从用户线程的角度来看，应用程序的顺序逻辑得以保留。\n\n**结论**：**正确**。该策略有效地将阻塞工作卸载到另一个内核可调度的实体上，防止主事件循环停顿，并且使用了正确且安全的通信模式。\n\n**B. 安装一个定期的 $SIGALRM$，在调度器时间量 $q$ 后触发，并包装 $getaddrinfo$，使得信号处理器能够抢占该调用，将执行权让给其他用户线程。该包装器假定信号会中断 $getaddrinfo$，从而允许用户级调度器在同一个内核线程上继续执行，并在稍后恢复该调用。**\n\n这个策略在根本上是有缺陷且不安全的。\n1.  **防止全局停顿**：这种方法不会像描述的那样工作。如果内核线程在系统调用内部被阻塞（例如，等待 DNS 回复的 `recvmsg`），它在内核中处于睡眠状态。像 `SIGALRM` 这样的信号只有在该线程被再次调度运行时才会被递送，而这要等到阻塞调用完成或被内核中断时才会发生。当线程在内核中被阻塞时，信号处理器无法执行。此外，正如问题陈述所指出的，被信号中断的系统调用（返回 `EINTR`）通常会被 C 库透明地重启，这将使中断尝试无效。内核线程仍然被阻塞，全局停顿持续存在。\n2.  **保持正确性**：这个策略极其不安全。可以从信号处理器中安全调用的函数集合（异步信号安全函数）非常有限。用户级调度器的“让出（yield）”函数几乎可以肯定不是异步信号安全的，因为它需要操作调度器的数据结构，而这些数据结构在信号到达时可能处于不一致的状态。这将导致竞争条件和数据损坏。此外，`getaddrinfo` 本身没有被指定为可重入的，也没有被指定为可以被部分执行、中断然后稍后恢复。尝试这样做很可能会导致未定义行为。\n\n**结论**：**不正确**。这种方法基于对阻塞系统调用的信号处理的错误假设，并违反了关键的异步信号安全要求。\n\n**C. 通过调用 $res\\_init$ 并调整解析器选项（例如，更短的重试间隔、更少的域名服务器）来激进地配置解析器超时，以减少预期的解析时间 $T\\_{\\mathrm{dns}}$。继续在单个内核线程上执行 $getaddrinfo$；依赖于降低的阻塞概率来避免全局停顿。**\n\n这个策略是一种缓解措施，而不是一个解决方案。\n1.  **防止全局停顿**：这种方法不能防止全局停顿；它只是试图限制其持续时间。如果调用了 `getaddrinfo` 并且需要等待网络响应，它仍然会阻塞单个内核线程。即使超时被减少到（比如说）$500$ 毫秒，整个由 $U$ 个用户线程组成的系统仍将被冻结长达 $500$ 毫秒。问题要求的是防止停顿，而不仅仅是缩短停顿时间。对于任何非简单的应用程序，数毫秒的停顿仍然是全局停顿。\n2.  **保持正确性**：虽然调整解析器选项是一项有效的管理任务，但依赖它来解决一个基本的并发问题是错误的。此外，过于激进的超时会降低名称解析的可靠性，导致在暂时性的网络拥塞下解析失败，而原本是可以成功的。这可以被认为是未能保留应用可见的语义。然而，该策略的主要失败在于它无法防止阻塞。\n\n**结论**：**不正确**。该策略减少了停顿的最大持续时间，但没有防止停顿，未能满足核心要求。\n\n**D. 在可用时使用 $getaddrinfo\\_a$ 来获得异步名称解析，将其完成通知集成到事件循环中，并在不可用时回退到卸载方式。通过使用异步交付并在完成前挂起用户级线程，确保包装器绝不在单个内核线程上运行阻塞式解析。**\n\n这个策略使用了专门为解决此问题而设计的工具。\n1.  **防止全局停顿**：`getaddrinfo_a` 函数是为事件驱动应用设计的异步 API。它启动名称解析操作并立即返回，不会阻塞调用线程。实际的工作在后台执行（例如，由 C 库管理的辅助线程）。完成时会稍后通过某种方式（例如，回调函数）发出信号，该信号可以被集成到主事件循环中。这确保了主内核线程永远不会因 DNS 解析而阻塞。\n2.  **保持正确性**：在提供此功能的系统上（如带有 glibc 的系统），这是执行异步名称解析的指定且正确的方式。挂起用户线程并使用事件循环来处理完成通知的模式，是使此类 API 适应协作式用户级线程环境的正确方法。包含一个回退到其他卸载方法（如选项 A 或 E 中的方法）的机制，使得该策略既健壮又可移植。\n\n**结论**：**正确**。这是一个理想的解决方案，因为它使用了为该任务专门构建、高效且正确的 API。\n\n**E. 使用 $fork$-和-管道隔离来包装 $getaddrinfo$：包装器 $fork$ 一个子进程来执行 $getaddrinfo$；子进程将得到的 $struct\\ addrinfo$ 序列化为可移植格式并写入管道；父进程立即返回到用户级调度器，挂起调用方用户线程，并在管道就绪后反序列化结果。单个内核线程本身永远不会执行可能阻塞的解析操作。**\n\n这个策略将阻塞工作卸载到一个独立的进程。\n1.  **防止全局停顿**：`fork()` 系统调用创建一个新进程，操作系统内核会独立于父进程来调度它。阻塞的 `getaddrinfo` 调用发生在子进程中。父进程——其单个内核线程正在运行用户级调度器——可以作为其事件循环的一部分，以非阻塞方式监控管道的读取端。因为父进程不以阻塞方式等待子进程或管道，其内核线程可以自由地运行其他用户线程。这成功地防止了全局停顿。\n2.  **保持正确性**：这个机制在概念上是合理的。使用管道进行进程间通信 (IPC) 并在事件循环中监控其文件描述符是一个标准模式。如前所述，主要挑战是序列化和反序列化包含指针的 `struct addrinfo` 链表这一不简单的任务。然而，问题允许我们假设实现是正确的。虽然 `fork()` 可能因为涉及复制父进程的地址空间而显得重量级，但它是实现所需隔离的一种有效且正确的方式。\n\n**结论**：**正确**。尽管由于进程创建的开销，其效率可能低于基于线程的方法，但这是一种隔离阻塞调用和防止全局停顿的有效且正确的策略。\n\n总而言之，策略 A、D 和 E 都描述了在多对一线程模型中将阻塞操作从主内核线程卸载的有效方法，从而在保持正确性的同时防止系统范围的停顿。策略 B 和 C 是有缺陷的。", "answer": "$$\\boxed{ADE}$$", "id": "3689607"}]}