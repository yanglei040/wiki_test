{"hands_on_practices": [{"introduction": "在虚拟内存管理中，选择合适的页面大小是在性能和内存效率之间取得平衡的关键。较大的页面可以减少转换后备缓冲器（TLB）所需的条目数量，从而避免代价高昂的“TLB抖动”，但同时可能因内部碎片而浪费更多内存。这个练习将引导你解决一个实际的优化问题：如何在满足严格的碎片预算的同时，选择最小的页面大小来确保进程的工作集完全容纳于TLB中。[@problem_id:3626772]", "problem": "一个进程运行在一个中央处理器（CPU）上，其内存管理单元（MMU）使用一个具有 $E$ 个条目容量的转译后备缓冲器（TLB）。在一个时间片内，该进程的工作集由 CPU 主动访问的三个不相交的连续区域组成：一个大小为 $380\\,\\mathrm{KiB}$ 的热代码区，一个大小为 $220\\,\\mathrm{KiB}$ 的热堆区，以及一个大小为 $120\\,\\mathrm{KiB}$ 的活跃栈区。操作系统（OS）和硬件支持从集合 $\\{4\\,\\mathrm{KiB}, 8\\,\\mathrm{KiB}, 16\\,\\mathrm{KiB}, 32\\,\\mathrm{KiB}\\}$ 中选取的固定页面大小 $P$。\n\n假设每个区域内的每次访问在该区域内均匀分布，并且这三个区域不共享页面。当工作集中访问的不同页面数量超过 TLB 条目的数量时，会发生 TLB 未命中。工作集内的内部碎片定义为每个区域最后一个页面中的总闲置空间，即为这三个区域分配的页面总容量与它们的实际总大小之差。系统管理员对工作集施加了 $20\\,\\mathrm{KiB}$ 的内部碎片预算 $F_{\\max}$，以避免内存浪费。\n\n给定 $E = 64$，请从支持的集合中确定最小的页面大小 $P$（以字节为单位），该大小能同时 (i) 通过确保跨三个区域访问的不同页面数量不超过 $E$ 来避免 TLB 抖动，以及 (ii) 满足工作集的内部碎片预算。请用字节表示您的最终答案。无需四舍五入。", "solution": "首先将根据所需标准对问题进行验证。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n- TLB 容量：$E = 64$ 个条目。\n- 热代码区大小：$S_{code} = 380\\,\\mathrm{KiB}$。\n- 热堆区大小：$S_{heap} = 220\\,\\mathrm{KiB}$。\n- 活跃栈区大小：$S_{stack} = 120\\,\\mathrm{KiB}$。\n- 支持的页面大小集合：$P \\in \\{4\\,\\mathrm{KiB}, 8\\,\\mathrm{KiB}, 16\\,\\mathrm{KiB}, 32\\,\\mathrm{KiB}\\}$。\n- 内部碎片预算：$F_{\\max} = 20\\,\\mathrm{KiB}$。\n- 条件 (i)：访问的不同页面数量不得超过 $E$。\n- 条件 (ii)：工作集的总内部碎片不得超过 $F_{\\max}$。\n- 目标：从支持的集合中确定满足条件 (i) 和 (ii) 的最小页面大小 $P$。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据**：该问题基于操作系统和计算机体系结构的基本概念，特别是内存管理、分页、转译后备缓冲器（TLB）和内部碎片。提供的内存大小、TLB 容量和页面大小的值是现实的。\n- **适定性**：问题是自洽的，提供了所有必要的数据和约束。目标明确陈述：从一个离散集合中找到满足两个明确定义的数学不等式的 $P$ 的最小值。这种结构导向一个唯一的解（假设集合中存在解）。\n- **客观性**：问题使用精确、正式的语言陈述，没有主观或模糊的术语。\n- **无缺陷**：该问题不违反任何无效性标准。它是计算机科学中一个标准的、可形式化的问题，是完整和一致的，其条件是可行的，并且既不简单也不病态。\n\n**步骤 3：结论与行动**\n问题是**有效的**。将提供一个完整的解答。\n\n### 解答\n\n任务是从集合 $\\{4\\,\\mathrm{KiB}, 8\\,\\mathrm{KiB}, 16\\,\\mathrm{KiB}, 32\\,\\mathrm{KiB}\\}$ 中找到最小的页面大小 $P$，以满足与进程工作集的 TLB 使用和内部碎片相关的两个条件。该工作集由三个内存区域组成，大小分别为 $S_{code} = 380\\,\\mathrm{KiB}$，$S_{heap} = 220\\,\\mathrm{KiB}$ 和 $S_{stack} = 120\\,\\mathrm{KiB}$。\n\n首先，让我们将这两个条件形式化。\n\n**条件 (i)：避免 TLB 抖动**\n使用大小为 $P$ 的页面来映射大小为 $S$ 的内存区域所需的页面数 $N(S, P)$，由大小之比的向上取整给出：\n$$N(S, P) = \\left\\lceil \\frac{S}{P} \\right\\rceil$$\n工作集的总页面数 $N_{total}(P)$ 是三个区域各自所需页面数的总和：\n$$N_{total}(P) = N(S_{code}, P) + N(S_{heap}, P) + N(S_{stack}, P)$$\n为避免 TLB 抖动，总页面数不得超过 TLB 容量 $E=64$。\n$$N_{total}(P) \\le E$$\n\n**条件 (ii)：碎片预算**\n单个内存区域的内部碎片 $F(S, P)$ 是最后一个已分配页面内的未使用空间。它是为该区域分配的总内存与该区域实际大小之差。\n$$F(S, P) = (N(S, P) \\times P) - S = \\left(\\left\\lceil \\frac{S}{P} \\right\\rceil \\times P\\right) - S$$\n总内部碎片 $F_{total}(P)$ 是每个区域碎片之和：\n$$F_{total}(P) = F(S_{code}, P) + F(S_{heap}, P) + F(S_{stack}, P)$$\n这个总碎片必须在指定的预算 $F_{\\max} = 20\\,\\mathrm{KiB}$ 之内。\n$$F_{total}(P) \\le F_{\\max}$$\n\n我们现在将从提供的集合中评估每个可用的页面大小 $P$，从最小的开始，直到找到一个满足两个条件的页面大小。所有计算都将使用以千字节（$\\mathrm{KiB}$）表示的大小进行。\n\n**情况 1：$P = 4\\,\\mathrm{KiB}$**\n1.  **计算总页面数 $N_{total}(4)$**：\n    $N_{code} = \\lceil \\frac{380}{4} \\rceil = \\lceil 95 \\rceil = 95$\n    $N_{heap} = \\lceil \\frac{220}{4} \\rceil = \\lceil 55 \\rceil = 55$\n    $N_{stack} = \\lceil \\frac{120}{4} \\rceil = \\lceil 30 \\rceil = 30$\n    $N_{total}(4) = 95 + 55 + 30 = 180$\n\n2.  **检查 TLB 条件**：\n    $N_{total}(4) \\le E$ 是否成立？即 $180 \\le 64$ 是否成立？这是错误的。\n    页面大小 $P = 4\\,\\mathrm{KiB}$ 会导致 TLB 抖动，因此不是一个有效的解。我们无需检查碎片条件。\n\n**情况 2：$P = 8\\,\\mathrm{KiB}$**\n1.  **计算总页面数 $N_{total}(8)$**：\n    $N_{code} = \\lceil \\frac{380}{8} \\rceil = \\lceil 47.5 \\rceil = 48$\n    $N_{heap} = \\lceil \\frac{220}{8} \\rceil = \\lceil 27.5 \\rceil = 28$\n    $N_{stack} = \\lceil \\frac{120}{8} \\rceil = \\lceil 15 \\rceil = 15$\n    $N_{total}(8) = 48 + 28 + 15 = 91$\n\n2.  **检查 TLB 条件**：\n    $N_{total}(8) \\le E$ 是否成立？即 $91 \\le 64$ 是否成立？这是错误的。\n    页面大小 $P = 8\\,\\mathrm{KiB}$ 同样会导致 TLB 抖动，不是一个有效的解。\n\n**情况 3：$P = 16\\,\\mathrm{KiB}$**\n1.  **计算总页面数 $N_{total}(16)$**：\n    $N_{code} = \\lceil \\frac{380}{16} \\rceil = \\lceil 23.75 \\rceil = 24$\n    $N_{heap} = \\lceil \\frac{220}{16} \\rceil = \\lceil 13.75 \\rceil = 14$\n    $N_{stack} = \\lceil \\frac{120}{16} \\rceil = \\lceil 7.5 \\rceil = 8$\n    $N_{total}(16) = 24 + 14 + 8 = 46$\n\n2.  **检查 TLB 条件**：\n    $N_{total}(16) \\le E$ 是否成立？即 $46 \\le 64$ 是否成立？这是正确的。条件 (i) 得到满足。\n\n3.  **计算总碎片量 $F_{total}(16)$**：\n    $F_{code} = (24 \\times 16) - 380 = 384 - 380 = 4\\,\\mathrm{KiB}$\n    $F_{heap} = (14 \\times 16) - 220 = 224 - 220 = 4\\,\\mathrm{KiB}$\n    $F_{stack} = (8 \\times 16) - 120 = 128 - 120 = 8\\,\\mathrm{KiB}$\n    $F_{total}(16) = 4 + 4 + 8 = 16\\,\\mathrm{KiB}$\n\n4.  **检查碎片条件**：\n    $F_{total}(16) \\le F_{\\max}$ 是否成立？即 $16\\,\\mathrm{KiB} \\le 20\\,\\mathrm{KiB}$ 是否成立？这是正确的。条件 (ii) 得到满足。\n\n由于 $P = 16\\,\\mathrm{KiB}$ 同时满足两个条件，而更小的页面大小 $4\\,\\mathrm{KiB}$ 和 $8\\,\\mathrm{KiB}$ 未能满足，因此 $P = 16\\,\\mathrm{KiB}$ 是满足问题要求的最小页面大小。\n\n为完整起见，我们可以检查最后一个选项。\n\n**情况 4：$P = 32\\,\\mathrm{KiB}$**\n1.  **计算总页面数 $N_{total}(32)$**：\n    $N_{code} = \\lceil \\frac{380}{32} \\rceil = \\lceil 11.875 \\rceil = 12$\n    $N_{heap} = \\lceil \\frac{220}{32} \\rceil = \\lceil 6.875 \\rceil = 7$\n    $N_{stack} = \\lceil \\frac{120}{32} \\rceil = \\lceil 3.75 \\rceil = 4$\n    $N_{total}(32) = 12 + 7 + 4 = 23$\n    $23 \\le 64$ 是否成立？正确。条件 (i) 得到满足。\n\n2.  **计算总碎片量 $F_{total}(32)$**：\n    $F_{code} = (12 \\times 32) - 380 = 384 - 380 = 4\\,\\mathrm{KiB}$\n    $F_{heap} = (7 \\times 32) - 220 = 224 - 220 = 4\\,\\mathrm{KiB}$\n    $F_{stack} = (4 \\times 32) - 120 = 128 - 120 = 8\\,\\mathrm{KiB}$\n    $F_{total}(32) = 4 + 4 + 8 = 16\\,\\mathrm{KiB}$\n    $16\\,\\mathrm{KiB} \\le 20\\,\\mathrm{KiB}$ 是否成立？正确。条件 (ii) 得到满足。\n这个页面大小也有效，但问题要求的是最小的有效页面大小。\n\n满足两个条件的最小页面大小是 $16\\,\\mathrm{KiB}$。问题要求以字节为单位作答。\n$1\\,\\mathrm{KiB} = 1024\\,\\text{字节}$。\n因此，$P = 16 \\times 1024\\,\\text{字节} = 16384\\,\\text{字节}$。", "answer": "$$\\boxed{16384}$$", "id": "3626772"}, {"introduction": "为了有效管理巨大的虚拟地址空间，现代处理器采用了多级页表结构。虽然这种设计节省了空间，但它也引入了性能开销：每次TLB未命中都可能触发一次“页表遍历”，即一系列内存访问。本练习旨在量化这一开销，你将通过计算在考虑多层缓存（L1、L2）和主存（DRAM）访问概率的情况下，不同深度的页表结构的预期翻译延迟。[@problem_id:3626808]", "problem": "一个计算机系统支持带有多级页表的虚拟内存。针对大的虚拟地址空间，我们考虑两种设计方案：五级页表和四级页表。该系统使用 $4\\,\\text{KiB}$ 的页面大小，因此页面偏移量为 $12$ 位。每个页表页包含 $512$ 个条目，这意味着每个级别有 $9$ 个索引位。中央处理器 (CPU) 在转译后备缓冲器 (TLB) 未命中时，会执行硬件页表遍历。页表遍历在通向映射该页面的叶节点的路径上，每一级都精确读取一个页表条目 (PTE)。\n\n设计A（五级）支持 $57$ 位规范虚拟地址，该地址必须分解为 $5$ 个等宽的索引字段和一个偏移字段。设计B（四级）支持 $48$ 位规范虚拟地址，该地址必须分解为 $4$ 个等宽的索引字段和一个偏移字段。假设只有基页（没有巨页），并且进程工作集中的任何虚拟地址都已映射，因此设计所需的各级完整路径都存在。\n\n为了进行性能评估，假设PTE获取的存储层次结构如下：一级数据缓存 (L1)，延迟为 $1.0$ 纳秒；二级缓存 (L2)，延迟为 $4.0$ 纳秒；动态随机存取存储器 (DRAM)，延迟为 $70$ 纳秒。对于单次TLB未命中，在给定级别，PTE访问由各层级提供服务的概率如下。\n\n对于设计B（四级），从顶层到底层：\n- 级别 $4$：$\\Pr(\\text{L1}) = 0.97$, $\\Pr(\\text{L2}) = 0.02$, $\\Pr(\\text{DRAM}) = 0.01$。\n- 级别 $3$：$\\Pr(\\text{L1}) = 0.85$, $\\Pr(\\text{L2}) = 0.10$, $\\Pr(\\text{DRAM}) = 0.05$。\n- 级别 $2$：$\\Pr(\\text{L1}) = 0.40$, $\\Pr(\\text{L2}) = 0.35$, $\\Pr(\\text{DRAM}) = 0.25$。\n- 级别 $1$：$\\Pr(\\text{L1}) = 0.08$, $\\Pr(\\text{L2}) = 0.37$, $\\Pr(\\text{DRAM}) = 0.55$。\n\n对于设计A（五级），增加了一个顶层（级别 $5$），其概率为 $\\Pr(\\text{L1}) = 0.995$, $\\Pr(\\text{L2}) = 0.004$, $\\Pr(\\text{DRAM}) = 0.001$。对于级别 $4$ 到 $1$，使用与设计B相同的概率。\n\n仅使用虚拟地址分解的定义和TLB未命中时硬件页表遍历的行为，完成以下任务：\n1. 根据第一性原理，确定每种设计的查找深度 $d$（每次翻译遍历的级别数）。\n2. 通过将每个级别的预期延迟贡献相加，估算每种设计的预期页表遍历延迟 $L$，其中一个级别的预期延迟是该级别各层级延迟的概率加权平均值。\n\n以纳秒表示每个延迟 $L$，并四舍五入到四位有效数字。以单行矩阵的形式提供最终答案，顺序为 $[d_{\\text{five-level}}, L_{\\text{five-level}}, d_{\\text{four-level}}, L_{\\text{four-level}}]$。", "solution": "我们将首先提取所有给定信息，然后检查其一致性、可靠性和完整性，以此来验证问题。\n\n### 问题验证\n\n**步骤1：提取给定信息**\n\n问题陈述中明确提供的数据如下：\n\n- **全系统参数**：\n    - 带有多级页表的虚拟内存。\n    - 页面大小：$4\\,\\text{KiB}$。（$2^{12}$ 字节）\n    - 由页面大小得出的页面偏移位数：$12$。\n    - 每个页表页的条目数：$512$。（$2^9$）\n    - 每个级别隐含的索引位数：$9$。\n    - 机制：在转译后备缓冲器 (TLB) 未命中时进行硬件页表遍历。\n    - 行为：遍历在每一级读取一个页表条目 (PTE)。\n\n- **设计A**：\n    - 页表结构：五级。\n    - 规范虚拟地址大小：$57$ 位。\n    - 虚拟地址分解：$5$ 个等宽的索引字段和一个偏移字段。\n\n- **设计B**：\n    - 页表结构：四级。\n    - 规范虚拟地址大小：$48$ 位。\n    - 虚拟地址分解：$4$ 个等宽的索引字段和一个偏移字段。\n\n- **存储层次结构延迟**：\n    - 一级数据缓存 (L1)：$T_{L1} = 1.0\\,\\text{ns}$。\n    - 二级缓存 (L2)：$T_{L2} = 4.0\\,\\text{ns}$。\n    - 动态随机存取存储器 (DRAM)：$T_{DRAM} = 70\\,\\text{ns}$。\n\n- **PTE获取的概率**：\n    - **设计A（级别 5）**：\n        - $\\Pr(\\text{L1}) = 0.995$, $\\Pr(\\text{L2}) = 0.004$, $\\Pr(\\text{DRAM}) = 0.001$。\n    - **两种设计（级别 4-1，使用通用概率）**：\n        - **级别 4**：$\\Pr(\\text{L1}) = 0.97$, $\\Pr(\\text{L2}) = 0.02$, $\\Pr(\\text{DRAM}) = 0.01$。\n        - **级别 3**：$\\Pr(\\text{L1}) = 0.85$, $\\Pr(\\text{L2}) = 0.10$, $\\Pr(\\text{DRAM}) = 0.05$。\n        - **级别 2**：$\\Pr(\\text{L1}) = 0.40$, $\\Pr(\\text{L2}) = 0.35$, $\\Pr(\\text{DRAM}) = 0.25$。\n        - **级别 1**：$\\Pr(\\text{L1}) = 0.08$, $\\Pr(\\text{L2}) = 0.37$, $\\Pr(\\text{DRAM}) = 0.55$。\n\n**步骤2：使用提取的给定信息进行验证**\n\n1.  **科学和事实的可靠性**：该问题基于计算机系统架构的既定原则，特别是虚拟内存管理。多级页表、TLB、硬件页表遍历和存储层次结构等概念都是标准内容。所提供的延迟和概率值对于现代计算机系统来说是合理的。\n\n2.  **一致性**：我们必须验证给定参数是自洽的。\n    - 页面大小为 $4\\,\\text{KiB}$ 即 $2^{12}$ 字节，这正确地意味着页面偏移量为 $12$ 位。\n    - 一个包含 $512$ 个条目的页表页需要 $9$ 位来索引一个特定条目，因为 $2^9 = 512$。这与所述的“每个级别 $9$ 个索引位”一致。\n    - 对于**设计B（四级）**，虚拟地址被规定为 $48$ 位，分解为 $4$ 个索引字段和 $1$ 个偏移字段。所需的总位数为 $4 \\times (\\text{索引位数}) + (\\text{偏移位数})$。使用给定的值，即为 $4 \\times 9 + 12 = 36 + 12 = 48$ 位。这与指定的 $48$ 位地址大小完全匹配。索引字段“等宽”的约束得到了满足。\n    - 对于**设计A（五级）**，虚拟地址被规定为 $57$ 位，分解为 $5$ 个索引字段和 $1$ 个偏移字段。所需的总位数为 $5 \\times (\\text{索引位数}) + (\\text{偏移位数})$。使用给定的值，即为 $5 \\times 9 + 12 = 45 + 12 = 57$ 位。这与指定的 $57$ 位地址大小完全匹配。索引字段“等宽”的约束也得到了满足。\n    - 每个级别每次内存访问的概率之和为 $1$：\n        - 级别 5 (A): $0.995 + 0.004 + 0.001 = 1.0$。\n        - 级别 4: $0.97 + 0.02 + 0.01 = 1.0$。\n        - 级别 3: $0.85 + 0.10 + 0.05 = 1.0$。\n        - 级别 2: $0.40 + 0.35 + 0.25 = 1.0$。\n        - 级别 1: $0.08 + 0.37 + 0.55 = 1.0$。\n    问题陈述在内部是一致且完整的。\n\n3.  **适定性和客观性**：问题定义清晰，有待计算的具体量。所有必要数据均已提供，语言客观且技术性强。该问题允许一个唯一的、稳定的解。\n\n**步骤3：结论与行动**\n\n问题是**有效的**。它在科学上是可靠的，自洽的，一致的，并且是适定的。可以开始求解过程。\n\n### 求解\n\n该问题要求为每种设计计算两个量：查找深度 $d$ 和预期页表遍历延迟 $L$。\n\n**1. 确定查找深度 ($d$)**\n\n查找深度 $d$ 是在页表遍历期间转换虚拟地址所需的内存访问次数。多级页表在每一级都需要一次内存访问来查找下一级的PTE，最终访问叶PTE，该PTE将虚拟页面映射到物理帧。\n\n- 对于**设计A**，系统使用五级页表。因此，一次完整的页表遍历会遍历所有五个级别。查找深度为 $d_{\\text{five-level}} = 5$。\n- 对于**设计B**，系统使用四级页表。一次完整的页表遍历会遍历所有四个级别。查找深度为 $d_{\\text{four-level}} = 4$。\n\n**2. 估算预期页表遍历延迟 ($L$)**\n\n在给定级别 $i$ 获取单个PTE的预期延迟，记为 $E[T_i]$，是不同存储层级（L1缓存、L2缓存、DRAM）延迟的概率加权和。公式为：\n$$E[T_i] = \\Pr(\\text{L1}) \\times T_{L1} + \\Pr(\\text{L2}) \\times T_{L2} + \\Pr(\\text{DRAM}) \\times T_{DRAM}$$\n总的预期页表遍历延迟 $L$ 是所有遍历级别的预期延迟之和。\n$$L = \\sum_{i=1}^{d} E[T_i]$$\n\n给定的延迟为 $T_{L1} = 1.0\\,\\text{ns}$，$T_{L2} = 4.0\\,\\text{ns}$，以及 $T_{DRAM} = 70.0\\,\\text{ns}$。\n\n**设计B（四级）的延迟计算**\n\n设 $L_B$ 为设计B的总预期延迟。我们将级别 $4$ 到 $1$ 的预期延迟相加。设这些延迟为 $E[T_{B,4}]$, $E[T_{B,3}]$, $E[T_{B,2}]$ 和 $E[T_{B,1}]$。\n\n- 级别 4 的预期延迟：\n$$E[T_{B,4}] = (0.97 \\times 1.0\\,\\text{ns}) + (0.02 \\times 4.0\\,\\text{ns}) + (0.01 \\times 70.0\\,\\text{ns}) = 0.97 + 0.08 + 0.70 = 1.75\\,\\text{ns}$$\n\n- 级别 3 的预期延迟：\n$$E[T_{B,3}] = (0.85 \\times 1.0\\,\\text{ns}) + (0.10 \\times 4.0\\,\\text{ns}) + (0.05 \\times 70.0\\,\\text{ns}) = 0.85 + 0.40 + 3.50 = 4.75\\,\\text{ns}$$\n\n- 级别 2 的预期延迟：\n$$E[T_{B,2}] = (0.40 \\times 1.0\\,\\text{ns}) + (0.35 \\times 4.0\\,\\text{ns}) + (0.25 \\times 70.0\\,\\text{ns}) = 0.40 + 1.40 + 17.50 = 19.30\\,\\text{ns}$$\n\n- 级别 1 的预期延迟：\n$$E[T_{B,1}] = (0.08 \\times 1.0\\,\\text{ns}) + (0.37 \\times 4.0\\,\\text{ns}) + (0.55 \\times 70.0\\,\\text{ns}) = 0.08 + 1.48 + 38.50 = 40.06\\,\\text{ns}$$\n\n设计B的总预期页表遍历延迟是以下各项之和：\n$$L_B = E[T_{B,4}] + E[T_{B,3}] + E[T_{B,2}] + E[T_{B,1}] = 1.75 + 4.75 + 19.30 + 40.06 = 65.86\\,\\text{ns}$$\n结果 $65.86$ 已经有四位有效数字。所以，$L_{\\text{four-level}} = 65.86\\,\\text{ns}$。\n\n**设计A（五级）的延迟计算**\n\n设 $L_A$ 为设计A的总预期延迟。此设计在设计B的四级之上增加了一个第五级（级别 5）。级别 $4$ 到 $1$ 的概率与设计B中相同。因此，总延迟是设计B的延迟与新增的级别 5 的预期延迟 $E[T_{A,5}]$ 之和。\n\n- 级别 5 的预期延迟：\n$$E[T_{A,5}] = (0.995 \\times 1.0\\,\\text{ns}) + (0.004 \\times 4.0\\,\\text{ns}) + (0.001 \\times 70.0\\,\\text{ns}) = 0.995 + 0.016 + 0.070 = 1.081\\,\\text{ns}$$\n\n设计A的总预期页表遍历延迟为：\n$$L_A = E[T_{A,5}] + L_B = 1.081\\,\\text{ns} + 65.86\\,\\text{ns} = 66.941\\,\\text{ns}$$\n四舍五入到四位有效数字，我们得到 $L_{\\text{five-level}} = 66.94\\,\\text{ns}$。\n\n**结果总结**\n\n- **设计A（五级）**：\n    - 查找深度 $d_{\\text{five-level}} = 5$。\n    - 预期延迟 $L_{\\text{five-level}} = 66.94\\,\\text{ns}$。\n- **设计B（四级）**：\n    - 查找深度 $d_{\\text{four-level}} = 4$。\n    - 预期延迟 $L_{\\text{four-level}} = 65.86\\,\\text{ns}$。\n\n最终答案应以单行矩阵的形式提供，顺序为 $[d_{\\text{five-level}}, L_{\\text{five-level}}, d_{\\text{four-level}}, L_{\\text{four-level}}]$。\n这对应于 $[5, 66.94, 4, 65.86]$。", "answer": "$$\\boxed{\\begin{pmatrix} 5  66.94  4  65.86 \\end{pmatrix}}$$", "id": "3626808"}, {"introduction": "操作系统中的进程间通信（IPC）是协作计算的基础，而选择合适的IPC机制对性能至关重要。本练习将通过建立一个性能模型，来对比两种经典的IPC方法：管道和共享内存。你将推导出它们的吞吞吐量表达式，从而量化数据复制成本和同步开销对最终性能的影响，并从根本上理解为何共享内存通常能为大数据传输提供更高的带宽。[@problem_id:3626719]", "problem": "一个生产者进程与一个消费者进程在同一台机器上通信，使用字节流管道或共享内存区域。该机器的中央处理器（CPU）频率为 $f$（单位：周期/秒）。每条消息的载荷大小为 $s$ 字节。载荷由生产者生成，由消费者消耗；假设系统处于稳态操作，无批处理，且通信成本与计算不重叠。\n\n假设存在以下基本事实：\n- 进程间通信（IPC）的吞吐量定义为单位时间内传输的载荷字节数。\n- 每条消息的总通信时间是复制字节所用时间与同步所用时间的总和，两者不重叠。\n- 复制 $s$ 字节的内存成本为每字节 $c_{\\text{copy}}$ 个周期，且此成本与 $s$ 线性相关。\n- 每个端点每条消息会产生 $c_{\\text{sync}}$ 个周期的同步开销；因此，一个生产者-消费者对每条消息会产生 $2\\,c_{\\text{sync}}$ 个周期的同步开销。\n\n在这些假设下，对两种 IPC 机制进行建模：\n- 管道：数据从生产者的用户空间复制到内核缓冲区，然后再从内核缓冲区复制到消费者的用户空间，总共需要 $2$ 次复制。\n- 共享内存：生产者将载荷直接写入共享区域，消费者就地读取，总共需要 $1$ 次显式的载荷复制。\n\n请推导管道的稳态吞吐量 $\\tau_{\\text{pipe}}$ 和共享内存的稳态吞吐量 $\\tau_{\\text{shm}}$ 的闭式表达式，使其为 $f$、$s$、$c_{\\text{copy}}$ 和 $c_{\\text{sync}}$ 的函数。同时推导吞吐量比率 $R$，定义为 $R = \\tau_{\\text{shm}} / \\tau_{\\text{pipe}}$。所有吞吐量均以字节/秒为单位。最终答案必须是 $\\tau_{\\text{pipe}}$、$\\tau_{\\text{shm}}$ 和 $R$ 的解析表达式。", "solution": "用户希望验证以下问题：\n- 一个生产者进程与一个消费者进程在同一台机器上通信，使用字节流管道或共享内存区域。该机器的中央处理器（CPU）频率为 $f$（单位：周期/秒）。每条消息的载荷大小为 $s$ 字节。载荷由生产者生成，由消费者消耗；假设系统处于稳态操作，无批处理，且通信成本与计算不重叠。\n假设存在以下基本事实：\n- 进程间通信（IPC）的吞吐量定义为单位时间内传输的载荷字节数。\n- 每条消息的总通信时间是复制字节所用时间与同步所用时间的总和，两者不重叠。\n- 复制 $s$ 字节的内存成本为每字节 $c_{\\text{copy}}$ 个周期，且此成本与 $s$ 线性相关。\n- 每个端点每条消息会产生 $c_{\\text{sync}}$ 个周期的同步开销；因此，一个生产者-消费者对每条消息会产生 $2\\,c_{\\text{sync}}$ 个周期的同步开销。\n在这些假设下，对两种 IPC 机制进行建模：\n- 管道：数据从生产者的用户空间复制到内核缓冲区，然后再从内核缓冲区复制到消费者的用户空间，总共需要 $2$ 次复制。\n- 共享内存：生产者将载荷直接写入共享区域，消费者就地读取，总共需要 $1$ 次显式的载荷复制。\n请推导管道的稳态吞吐量 $\\tau_{\\text{pipe}}$ 和共享内存的稳态吞吐量 $\\tau_{\\text{shm}}$ 的闭式表达式，使其为 $f$、$s$、$c_{\\text{copy}}$ 和 $c_{\\text{sync}}$ 的函数。同时推导吞吐量比率 $R$，定义为 $R = \\tau_{\\text{shm}} / \\tau_{\\text{pipe}}$。所有吞吐量均以字节/秒为单位。最终答案必须是 $\\tau_{\\text{pipe}}$、$\\tau_{\\text{shm}}$ 和 $R$ 的解析表达式。\n\n### 步骤 1：提取已知条件\n- CPU 频率：$f$（周期/秒）\n- 每条消息的载荷大小：$s$（字节）\n- IPC 吞吐量定义：单位时间内传输的载荷字节数。\n- 每条消息的总通信时间，$T$：$T = T_{\\text{copy}} + T_{\\text{sync}}$（无重叠）。\n- 内存复制成本：$c_{\\text{copy}}$（周期/字节），与 $s$ 线性相关。\n- 同步成本：一个生产者-消费者对为 $2c_{\\text{sync}}$（周期/消息）。\n- 管道机制模型：每条消息 $2$ 次内存复制。\n- 共享内存模型：每条消息 $1$ 次内存复制。\n- 要求输出：管道吞吐量 $\\tau_{\\text{pipe}}$、共享内存吞吐量 $\\tau_{\\text{shm}}$ 及其比率 $R = \\tau_{\\text{shm}} / \\tau_{\\text{pipe}}$ 的表达式。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据指定标准对问题进行验证。\n\n- **科学依据**：该问题提出了一个简化但标准的性能模型，用于比较两种基本的进程间通信（IPC）机制。内核介导的通信（管道）与直接内存访问（共享内存）之间的区别，以及在数据复制方面的相关成本差异，是操作系统和计算机体系结构中的核心概念。该成本模型将每字节的复制开销与每条消息的同步开销分开，是性能分析中一种有效且广泛使用的一阶近似。该问题基于既定的计算机科学原理。\n- **适定性**：该问题定义清晰。它提供了所有必要的符号参数（$f, s, c_{\\text{copy}}, c_{\\text{sync}}$）和用于对两种 IPC 机制成本进行建模的明确规则。目标明确：推导三个特定的解析表达式。根据给定信息可以推导出唯一解。\n- **客观性**：问题陈述使用精确、无偏见和定量的语言表述。它使用了计算机科学领域的标准术语。没有主观或模糊的陈述。\n\n该问题没有任何使其无效的缺陷。它并非不科学、不可形式化、不完整、不切实际、不适定或微不足道。这是计算机系统性能建模领域一个标准的、可形式化的问题。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。将推导解答。\n\n稳态吞吐量 $\\tau$ 定义为传输一条消息所需的载荷大小 $s$ 除以总时间 $T$。\n$$\n\\tau = \\frac{s}{T}\n$$\n总时间 $T$ 是数据复制时间 $T_{\\text{copy}}$ 和同步时间 $T_{\\text{sync}}$ 的总和。\n$$\nT = T_{\\text{copy}} + T_{\\text{sync}}\n$$\n成本以 CPU 周期为单位给出，可以通过除以 CPU 频率 $f$ 转换为以秒为单位的时间。令 $C_{\\text{total}}$ 为每条消息的总周期数。\n$$\nT = \\frac{C_{\\text{total}}}{f}\n$$\n总周期数 $C_{\\text{total}}$ 是复制周期数 $C_{\\text{copy}}$ 和同步周期数 $C_{\\text{sync}}$ 的总和。\n$$\nC_{\\text{total}} = C_{\\text{copy}} + C_{\\text{sync}}\n$$\n\n首先，我们推导管道机制的吞吐量 $\\tau_{\\text{pipe}}$。\n管道机制需要 $2$ 次载荷复制。载荷大小为 $s$ 字节，复制成本为每字节 $c_{\\text{copy}}$ 个周期。\n复制的总周期数为：\n$$\nC_{\\text{copy, pipe}} = 2 \\cdot s \\cdot c_{\\text{copy}}\n$$\n一个生产者-消费者对的同步开销为每条消息 $2c_{\\text{sync}}$ 个周期。\n$$\nC_{\\text{sync, pipe}} = 2c_{\\text{sync}}\n$$\n管道每条消息的总周期数是这两个分量的和：\n$$\nC_{\\text{total, pipe}} = C_{\\text{copy, pipe}} + C_{\\text{sync, pipe}} = 2sc_{\\text{copy}} + 2c_{\\text{sync}} = 2(sc_{\\text{copy}} + c_{\\text{sync}})\n$$\n每条消息的总时间 $T_{\\text{pipe}}$ 是：\n$$\nT_{\\text{pipe}} = \\frac{C_{\\text{total, pipe}}}{f} = \\frac{2(sc_{\\text{copy}} + c_{\\text{sync}})}{f}\n$$\n因此，管道的吞吐量 $\\tau_{\\text{pipe}}$ 是：\n$$\n\\tau_{\\text{pipe}} = \\frac{s}{T_{\\text{pipe}}} = \\frac{s}{\\frac{2(sc_{\\text{copy}} + c_{\\text{sync}})}{f}} = \\frac{sf}{2(sc_{\\text{copy}} + c_{\\text{sync}})}\n$$\n\n接下来，我们推导共享内存机制的吞吐量 $\\tau_{\\text{shm}}$。\n共享内存机制只需要 $1$ 次显式载荷复制。\n复制的总周期数为：\n$$\nC_{\\text{copy, shm}} = 1 \\cdot s \\cdot c_{\\text{copy}} = sc_{\\text{copy}}\n$$\n同步成本保持不变，因为生产者和消费者仍必须协调对共享缓冲区的访问。\n$$\nC_{\\text{sync, shm}} = 2c_{\\text{sync}}\n$$\n共享内存每条消息的总周期数为：\n$$\nC_{\\text{total, shm}} = C_{\\text{copy, shm}} + C_{\\text{sync, shm}} = sc_{\\text{copy}} + 2c_{\\text{sync}}\n$$\n每条消息的总时间 $T_{\\text{shm}}$ 是：\n$$\nT_{\\text{shm}} = \\frac{C_{\\text{total, shm}}}{f} = \\frac{sc_{\\text{copy}} + 2c_{\\text{sync}}}{f}\n$$\n因此，共享内存的吞吐量 $\\tau_{\\text{shm}}$ 是：\n$$\n\\tau_{\\text{shm}} = \\frac{s}{T_{\\text{shm}}} = \\frac{s}{\\frac{sc_{\\text{copy}} + 2c_{\\text{sync}}}{f}} = \\frac{sf}{sc_{\\text{copy}} + 2c_{\\text{sync}}}\n$$\n\n最后，我们推导吞吐量比率 $R = \\tau_{\\text{shm}} / \\tau_{\\text{pipe}}$。\n$$\nR = \\frac{\\tau_{\\text{shm}}}{\\tau_{\\text{pipe}}} = \\frac{\\frac{sf}{sc_{\\text{copy}} + 2c_{\\text{sync}}}}{\\frac{sf}{2(sc_{\\text{copy}} + c_{\\text{sync}})}}\n$$\n分子和分母中的项 $sf$ 被消去：\n$$\nR = \\frac{2(sc_{\\text{copy}} + c_{\\text{sync}})}{sc_{\\text{copy}} + 2c_{\\text{sync}}}\n$$\n在此模型中，该比率代表共享内存相对于管道的性能优势。它是消息大小 $s$ 以及复制一字节与同步一条消息的相对成本的函数。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{sf}{2(sc_{\\text{copy}} + c_{\\text{sync}})}  \\frac{sf}{sc_{\\text{copy}} + 2c_{\\text{sync}}}  \\frac{2(sc_{\\text{copy}} + c_{\\text{sync}})}{sc_{\\text{copy}} + 2c_{\\text{sync}}}\n\\end{pmatrix}\n}\n$$", "id": "3626719"}]}