{"hands_on_practices": [{"introduction": "在构建完整的遗传算法之前，理解其核心驱动力——选择——是至关重要的。本练习将选择机制独立出来，以便研究其动态过程。您将通过模拟一个“接管”场景 [@problem_id:3137411]，观察一个优秀的个体如何在群体中扩散，并将随机模拟结果与一个简单的确定性模型进行比较，从而体会选择压力和随机机会（遗传漂变）各自扮演的角色。", "problem": "考虑一个遗传算法（GA）的纯选择模型，此处定义为一种遗传算法（GA），其每一代新种群的生成仅通过适应度比例选择，而没有交叉、变异或其他算子。种群由两种类型组成：一个最优个体和所有其他个体。设种群大小为 $N$，最优个体的选择强度为 $s$，即最优个体的适应度为 $s$，而所有其他个体的适应度为 $1$。初始种群包含 $1$ 个最优个体和 $N-1$ 个其他个体。\n\n在第 $t$ 代，令 $k_t$ 表示最优个体的数量。在适应度比例选择下，随机选择的后代来自最优类型的概率 $p_t$ 由最优类型的总适应度贡献除以种群总适应度得出。下一代是通过从上一代进行 $N$ 次有放回抽样得到的 $N$ 个个体，因此最优个体的数量 $k_{t+1}$ 是一个随机变量，服从试验次数为 $N$、成功概率为 $p_t$ 的二项分布。\n\n定义接管时间 $T$ 为满足 $k_t = N$ 的最小非负整数 $t$（即整个种群都由最优个体组成）。由于随机抽样，最优个体可能会灭绝，这意味着对于所有后续代，$k_t = 0$；在这种情况下，接管时间是未定义的。对于本问题，将估计的接管时间定义为在接管发生的条件下 $T$ 的条件期望，并通过蒙特卡洛模拟进行近似。\n\n您的任务是：\n- 实现一个模拟，对于给定的 $(N,s)$，执行 $R$ 次独立运行。每次运行从 $k_0 = 1$ 开始，通过重复的适应度比例抽样进行演化，直到 $k_t = N$（接管）、$k_t = 0$（灭绝）或达到预设的代数上限。对于每次达到接管的运行，记录其接管时间。通过对所有成功运行的接管时间取平均，来估计条件期望接管时间。\n- 计算接管时间的确定性近似值，该近似值源于假设在最优个体比例很小的情况下，最优个体的期望数量呈乘性增长。\n- 对于每个测试用例，报告蒙特卡洛估计值与确定性近似值之间的绝对差，结果四舍五入到三位小数。\n\n使用以下测试套件：\n1. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (100, 1.5, 500, 1000, 42)$\n2. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (100, 1.01, 500, 10000, 43)$\n3. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (50, 2.0, 300, 200, 44)$\n4. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (10, 1.5, 1000, 200, 45)$\n5. $(N,s,R,\\text{max\\_gen},\\text{seed}) = (200, 1.2, 300, 3000, 46)$\n\n您的程序应产生单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，列表中的每个元素是对应测试用例的绝对误差。如果在某个测试用例中，没有一次运行在代数上限内实现接管，则该用例的输出为浮点值 $\\mathrm{nan}$。例如，最终输出应类似于 $[e_1,e_2,e_3,e_4,e_5]$，其中每个 $e_i$ 是一个四舍五入到三位小数的浮点数。", "solution": "用户的问题陈述已经过验证，并被确定是严谨的。它在科学上基于种群遗传学和计算科学的原理，特别是带有选择的 Wright-Fisher 模型。该问题是适定的，为蒙特卡洛模拟和确定性近似提供了所有必要的参数和定义。目标清晰且正式。因此，我现在将提供一个完整的解决方案。\n\n该问题要求在一个演化过程的随机模拟与同一过程的简化确定性模型之间进行比较。目标是计算通过蒙特卡洛模拟估计的接管时间与通过确定性近似预测的接管时间之间的绝对差。\n\n让我们定义给定的参数和变量：\n- $N$：种群总大小。\n- $s$：“最优”个体类型的适应度，其中 $s > 1$。所有其他个体的适应度为 $1$。\n- $k_t$：在第 $t$ 代种群中最优个体的数量。初始状态为 $k_0 = 1$。\n- $p_t$：在第 $t$ 代从最优类型中选择一个后代的概率。\n\n模型的核心在于从第 $t$ 代到第 $t+1$ 代的转换。概率 $p_t$ 由 $k_t$ 个最优个体贡献的总适应度比例确定：\n$$\np_t = \\frac{k_t \\cdot s}{k_t \\cdot s + (N - k_t) \\cdot 1} = \\frac{s k_t}{s k_t + N - k_t}\n$$\n下一代是通过从当前代进行 $N$ 次独立有放回抽样形成的。因此，下一代中最优个体的数量 $k_{t+1}$ 服从试验次数为 $N$、成功概率为 $p_t$ 的二项分布：\n$$\nk_{t+1} \\sim \\text{Binomial}(N, p_t)\n$$\n\n解决方案包括三个主要步骤：推导确定性近似，概述蒙特卡洛模拟，以及计算最终误差。\n\n**1. 确定性近似 ($T_{det}$)**\n\n确定性模型通过追踪个体的期望数量 $E[k_t]$ 来近似随机过程。给定 $k_t$ 时，$k_{t+1}$ 的期望值为 $E[k_{t+1} | k_t] = N p_t$。\n$$\nE[k_{t+1} | k_t] = N \\left( \\frac{s k_t}{s k_t + N - k_t} \\right)\n$$\n问题指明，该近似应假设在最优个体的比例 $x_t = k_t/N$ 很小的情况下呈乘性增长。当 $x_t \\ll 1$ 时，我们可以近似分母：\n$$\ns k_t + N - k_t = N(1 + (s-1)\\frac{k_t}{N}) \\approx N\n$$\n将此代入期望值，得到期望数量的简化递推关系，我们记为 $\\bar{k}_t$：\n$$\n\\bar{k}_{t+1} \\approx N \\left( \\frac{s \\bar{k}_t}{N} \\right) = s \\bar{k}_t\n$$\n这是一个等比数列。从初始条件 $k_0 = 1$ 开始，在第 $t$ 代，最优个体的期望数量呈指数增长：\n$$\n\\bar{k}_t \\approx k_0 s^t = s^t\n$$\n接管被定义为整个种群都由最优个体组成的时间点，即数量达到 $N$ 时。我们在我们的连续近似中求解满足此条件所需的时间 $t$：\n$$\ns^t = N\n$$\n对两边取自然对数，得到：\n$$\nt \\ln(s) = \\ln(N)\n$$\n这就得到了确定性接管时间 $T_{det}$：\n$$\nT_{det} = \\frac{\\ln(N)}{\\ln(s)}\n$$\n这种近似忽略了随机抽样（遗传漂变）的随机效应，这种效应可能导致灭绝（尤其是在 $k_t$ 很小时），或者引起偏离平滑指数增长的现象。\n\n**2. 蒙特卡洛模拟估计 ($T_{MC}$)**\n\n为了捕捉过程的随机性，我们执行蒙特卡洛模拟。对于每组参数 $(N, s, R, \\text{max\\_gen}, \\text{seed})$，我们进行 $R$ 次独立运行。\n每次运行按以下步骤进行：\n1.  初始化状态：代数计数 $t=0$ 和最优个体数量 $k_0=1$。\n2.  迭代各代：对于每一代，将 $t$ 递增。\n3.  根据当前数量 $k_t$ 计算选择概率 $p_t$。\n4.  从二项分布中抽样下一代的最优个体数量 $k_{t+1}$：$k_{t+1} = \\text{rng.binomial}(N, p_t)$，其中 `rng` 是一个设定了种子的随机数生成器。\n5.  检查终止条件：\n    - 如果 $k_{t+1} = N$（接管），则将当前代数计数 $t+1$ 记录为本次运行的接管时间，并停止运行。\n    - 如果 $k_{t+1} = 0$（灭绝），则停止运行，不记录时间。\n    - 如果 $t$ 达到代数上限 `max_gen`，则停止运行。这是为了防止运行时间过长。\n在所有 $R$ 次运行完成后，我们将得到一个来自成功运行的接管时间列表。估计的条件期望接管时间 $T_{MC}$ 是这些记录时间的算术平均值。如果没有运行导致接管，$T_{MC}$ 被认为是未定义的，表示为 $\\mathrm{nan}$。\n\n**3. 误差计算**\n\n对于每个测试用例，最终结果是蒙特卡洛估计值与确定性近似值之间的绝对差，四舍五入到三位小数：\n$$\n\\Delta T = |T_{MC} - T_{det}|\n$$\n如果 $T_{MC}$ 是 $\\mathrm{nan}$，则差值 $\\Delta T$ 也是 $\\mathrm{nan}$。该实现将为所提供的五个测试用例中的每一个计算此值。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the absolute difference between a Monte Carlo estimate and a\n    deterministic approximation for the takeover time in a selection-only\n    genetic algorithm model.\n    \"\"\"\n    test_cases = [\n        # (N, s, R, max_gen, seed)\n        (100, 1.5, 500, 1000, 42),\n        (100, 1.01, 500, 10000, 43),\n        (50, 2.0, 300, 200, 44),\n        (10, 1.5, 1000, 200, 45),\n        (200, 1.2, 300, 3000, 46),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, s, R, max_gen, seed = case\n\n        # Initialize random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n\n        # --- Monte Carlo Simulation ---\n        takeover_times = []\n        for _ in range(R):\n            k = 1  # Initial number of best individuals\n            for t in range(1, max_gen + 1):\n                # Check for termination conditions from the previous state\n                if k == N:\n                    takeover_times.append(t - 1)\n                    break\n                if k == 0:\n                    break\n\n                # Calculate selection probability\n                total_fitness_best = k * s\n                total_fitness_other = (N - k) * 1.0\n                total_fitness = total_fitness_best + total_fitness_other\n                \n                # Handle potential division by zero if population empties, though k=0 check prevents this\n                if total_fitness == 0:\n                    p = 0.0\n                else:\n                    p = total_fitness_best / total_fitness\n\n                # Sample the next generation\n                k = rng.binomial(N, p)\n            \n            # Check for takeover at the end of the loop (if max_gen is reached exactly)\n            else: # This 'else' belongs to the 'for t' loop\n                if k == N:\n                    takeover_times.append(max_gen)\n\n\n        # Calculate the MC estimate\n        if not takeover_times:\n            mc_estimate = np.nan\n        else:\n            mc_estimate = np.mean(takeover_times)\n\n        # --- Deterministic Approximation ---\n        # T_det = log(N) / log(s)\n        det_approx = np.log(N) / np.log(s)\n\n        # --- Calculate Absolute Difference ---\n        if np.isnan(mc_estimate):\n            diff = np.nan\n            results.append('nan')\n        else:\n            diff = np.abs(mc_estimate - det_approx)\n            results.append(f\"{diff:.3f}\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```", "id": "3137411"}, {"introduction": "解决方案的编码方式，即其“基因型”，是遗传算法中的一个关键设计选择，它深刻影响着算法的搜索效率。本练习旨在通过分析比较两种常见的编码方案——标准二进制编码和格雷码——来揭示表示方法的重要性。通过精确计算而不是模拟 [@problem_id:3132789]，您将量化不同编码在单比特突变下所产生的“搜索邻域”的差异，从而理解编码如何影响算法在求解地形上的探索行为。", "problem": "您需要编写一个完整、可运行的程序，用于比较在优化球函数时，遗传算法（Genetic Algorithm, GA）中使用的两种基因型编码：标准二进制编码和格雷码。目标函数是在有界超矩形 $[L, U]^n$（其中 $L  0  U$）上定义的球函数 $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$。每个决策变量 $x_i$ 由 $b$ 个位表示，并通过均匀线性量化解码为实数值。\n\n使用的基本原理和定义：\n- 球函数 $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$ 是按坐标可分的。\n- 基因型到表现型的映射是一个线性量化器：对于每个坐标，一个 $b$ 位码字表示一个整数 $k \\in \\{0,1,\\dots,2^b - 1\\}$，该整数映射到一个实数值 $x = L + \\dfrac{U - L}{2^b - 1}\\,k$。这会在每个坐标上产生一个包含端点 $L$ 和 $U$ 在内的 $2^b$ 个点的均匀网格。\n- 对于二进制编码，码字是 $k$ 的标准二进制表示。对于格雷码，码字是 $k$ 的格雷码编码，解码时先应用格雷码到二进制的转换来恢复整数 $k$，然后再进行到 $x$ 的线性映射。\n- 单比特突变定义为在所有 $n b$ 个基因型位中随机均匀选择一个位并将其翻转。\n\n为每个测试用例计算并报告以下内容：\n1) 离散化误差。将离散化误差定义为由所选 $b$ 产生的离散网格上 $f(\\mathbf{x})$ 的最小可达值（两种编码均可，因为它们产生相同的表现型网格点集）减去 $f(\\mathbf{x})$ 在 $[L, U]^n$ 上的连续最优值。您必须精确计算此值，而不是通过采样。\n2) 通过单步改进概率反映的搜索偏好。将一种编码的单步改进概率 $P_{\\mathrm{improve}}$ 定义为（相对于基因型的均匀分布和在 $n b$ 个位位置中的均匀选择）单比特翻转严格减小 $f(\\mathbf{x})$ 的概率。您必须通过枚举精确计算此概率，而不是通过模拟。形式上，\n$$\nP_{\\mathrm{improve}} = \\frac{1}{(2^b)^n \\cdot n b} \\sum_{\\text{genotypes } g} \\sum_{p=1}^{n b} \\mathbf{1}\\big(f(g^{(p)})  f(g)\\big),\n$$\n其中 $g^{(p)}$ 是 $g$ 翻转第 $p$ 位后的基因型，而 $\\mathbf{1}(\\cdot)$ 是指示函数。利用 $f$ 的可分性以及位翻转只影响一个坐标的事实，将此问题简化为对单个 $b$ 位坐标的等效精确枚举。\n\n您的程序必须：\n- 对任何整数 $b \\ge 1$ 精确实现两种编码（二进制和格雷码）。\n- 使用精确逻辑而非浮点数比较来测试位翻转是否改进了单个坐标的贡献 $x^2$。具体方法是观察到，对于对称边界 $L = -U$ 和步长为 $\\Delta = \\dfrac{U - L}{2^b - 1}$ 的均匀量化，每个坐标的值等于 $x = \\Delta\\,(k - m)$，其中 $m = \\dfrac{2^b - 1}{2}$。因此，当且仅当 $\\lvert k' - m \\rvert  \\lvert k - m \\rvert$ 时，翻转会改进目标函数，这等价于 $\\lvert 2k' - (2^b - 1) \\rvert  \\lvert 2k - (2^b - 1) \\rvert$。\n- 从第一性原理出发精确计算离散化误差，而不是数值搜索网格。如果 $0 \\in [L, U]$，则连续最小值为 $0$，在 $\\mathbf{x} = \\mathbf{0}$ 处取得；否则，它是每个坐标上离 $0$ 最近的边界点。\n- 对于每个测试用例，输出一个包含四个数字的列表：二进制编码下的离散化误差、格雷码下的离散化误差、二进制编码下的单步改进概率以及格雷码下的单步改进概率。所有数字必须打印为小数并四舍五入到 $12$ 位。\n\n测试套件：\n使用以下五个测试用例，每个用例指定为一个元组 $(n, b, L, U)$，其中 $n$ 是维度，$b$ 是每个坐标的位长，$[L, U]$ 是边界区间：\n- $(\\,1,\\,3,\\,-1.0,\\,1.0\\,)$\n- $(\\,5,\\,4,\\,-1.0,\\,1.0\\,)$\n- $(\\,10,\\,8,\\,-1.0,\\,1.0\\,)$\n- $(\\,3,\\,1,\\,-1.0,\\,1.0\\,)$\n- $(\\,2,\\,12,\\,-1.0,\\,1.0\\,)$\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含五个测试用例的结果，格式为一个长度为五的逗号分隔列表，其中每个元素本身是按上述顺序排列的四个十进制数的逗号分隔列表，每个十进制数都四舍五入到 $12$ 位。例如，一个有效的形状是\n$$\n[\\,[d_1^{\\text{bin}}, d_1^{\\text{gray}}, p_1^{\\text{bin}}, p_1^{\\text{gray}}],\\dots,[d_5^{\\text{bin}}, d_5^{\\text{gray}}, p_5^{\\text{bin}}, p_5^{\\text{gray}}]\\,].\n$$\n不应打印任何额外文本。", "solution": "已对用户提供的问题进行了分析和验证。该问题具有科学依据，定义明确，且所有定义和约束都是自洽和一致的。任务是计算遗传算法在优化球函数时，使用的二进制编码和格雷码两种编码方式下的两个指标：离散化误差和单步改进概率。\n\n### 1. 离散化误差\n\n目标函数是在定义域 $\\mathbf{x} \\in [L, U]^n$ 上的球函数 $f(\\mathbf{x}) = \\sum_{i=1}^{n} x_i^2$。对于所有测试用例，$L = -1.0$ 且 $U = 1.0$，因此 $L  0  U$。$f(\\mathbf{x})$ 的连续最小值为 $f(\\mathbf{0}) = 0$，在 $\\mathbf{x} = \\mathbf{0}$ 处取得。\n\n问题描述了一种均匀线性量化方案，其中每个坐标 $x_i$ 从一个 $b$ 位码字映射而来。该码字对应一个整数 $k \\in \\{0, 1, \\dots, 2^b-1\\}$，该整数又映射到一个实数值 $x_k = L + \\frac{U-L}{2^b-1}k$。每个坐标的可能实数值集合，即网格点，由 $k$ 的范围决定。\n\n二进制编码和格雷码都提供了从 $b$ 位字符串集合到整数集合 $\\{0, 1, \\dots, 2^b-1\\}$ 的双射。因此，两种编码的可实现表现型值集合（即网格点）是相同的。离散化误差定义为网格上的最小值与连续最小值之差，因此它与二进制编码和格雷码的选择无关。\n\n为了找到 $f(\\mathbf{x})$ 在网格上的最小值，我们必须为每个坐标找到最接近 $0$ 的网格点 $x_k$。使 $x_k$ 最接近 $0$ 的 $k$ 值是与实数 $k_{\\text{real}} = -L \\frac{2^b-1}{U-L}$ 最接近的整数。\n给定 $L=-1.0$ 和 $U=1.0$，这变为 $k_{\\text{real}} = -(-1.0) \\frac{2^b-1}{1.0 - (-1.0)} = \\frac{2^b-1}{2}$。\n由于 $b \\ge 1$，$2^b-1$ 始终为奇数，所以 $k_{\\text{real}}$ 永远不是整数。与 $k_{\\text{real}}$ 最接近的两个整数是 $k_1 = \\lfloor \\frac{2^b-1}{2} \\rfloor = 2^{b-1}-1$ 和 $k_2 = \\lceil \\frac{2^b-1}{2} \\rceil = 2^{b-1}$。\n对应的表现型值为：\n$x_{k_1} = -1.0 + \\frac{2.0}{2^b-1}(2^{b-1}-1) = \\frac{-(2^b-1) + 2^b-2}{2^b-1} = \\frac{-1}{2^b-1}$。\n$x_{k_2} = -1.0 + \\frac{2.0}{2^b-1}(2^{b-1}) = \\frac{-(2^b-1) + 2^b}{2^b-1} = \\frac{1}{2^b-1}$。\n一个坐标可能的最小绝对值为 $|x^*| = \\frac{1}{2^b-1}$。\n在离散网格上 $f(\\mathbf{x})$ 的最小值在每个 $|x_i| = |x^*|$ 时取得，因此 $\\min_{\\text{grid}} f(\\mathbf{x}) = \\sum_{i=1}^{n} (x^*)^2 = n \\left(\\frac{1}{2^b-1}\\right)^2$。\n因此，离散化误差 $D$ 为：\n$$ D = \\min_{\\text{grid}} f(\\mathbf{x}) - \\min_{\\text{continuous}} f(\\mathbf{x}) = \\frac{n}{(2^b-1)^2} - 0 = \\frac{n}{(2^b-1)^2} $$\n这个值对于二进制编码和格雷码是相同的，所以 $D_{\\text{binary}} = D_{\\text{Gray}}$。\n\n### 2. 单步改进概率 ($P_{\\mathrm{improve}}$)\n\n单步改进概率定义为：\n$$ P_{\\mathrm{improve}} = \\frac{1}{(2^b)^n \\cdot nb} \\sum_{\\text{genotypes } g} \\sum_{p=1}^{nb} \\mathbf{1}\\big(f(g^{(p)})  f(g)\\big) $$\n由于球函数 $f(\\mathbf{x}) = \\sum_{i=1}^n x_i^2$ 的可分性，基因型中的单比特翻转仅影响一个坐标，比如说 $x_i \\to x_i'$。改进的条件 $f(g^{(p)})  f(g)$ 简化为 $(x_i')^2  x_i^2$，这等价于 $|x_i'|  |x_i|$。\n总的改进移动次数可以对每个坐标独立求和。设 $S$ 为单个 $b$ 位坐标在其所有 $2^b$ 种可能状态下，导致改进的单比特翻转的总次数。\n$$ S = \\sum_{c \\in \\{0,1\\}^b} \\sum_{j=1}^{b} \\mathbf{1}\\big( |x'(c^{(j)})|  |x(c)| \\big) $$\n其中 $c$ 是一个 $b$ 位码字，$c^{(j)}$ 是 $c$ 翻转第 $j$ 位后的码字，$x(c)$ 是对应于 $c$ 的表现型值。\n在所有 $n$ 个坐标和所有 $(2^b)^n$ 个基因型中，总的改进移动次数为 $n \\cdot (2^b)^{n-1} \\cdot S$。将此代入概率公式可以显著简化：\n$$ P_{\\mathrm{improve}} = \\frac{n \\cdot (2^b)^{n-1} \\cdot S}{(2^b)^n \\cdot nb} = \\frac{S}{2^b \\cdot b} $$\n这意味着我们只需要分析一个 $b$ 位坐标就能求出概率。$S$ 的值在二进制编码和格雷码之间会有所不同，因为从码字 $c$到整数 $k$（并因此到表现型值 $x$）的映射是不同的。\n\n为了避免浮点数不精确的问题，我们使用建议的基于整数的比较。对于 $L=-U$，条件 $|x'|  |x|$ 等价于 $|k' - m|  |k - m|$，其中 $m = (2^b-1)/2$。这可以乘以 $2$ 重写为 $|2k' - (2^b-1)|  |2k - (2^b-1)|$。\n\n计算每种编码的 $S$ 的算法如下：\n1. 初始化改进移动计数器 `improvements` 为 $0$。令 $M = 2^b - 1$。\n2. 遍历每个可能的 $b$ 位码字 $c$，由 $0$ 到 $2^b-1$ 的整数表示。\n3. 对于每个 $c$，确定其在给定编码（二进制或格雷码）下的整数值 $k$。\n    - 对于二进制编码，$k_{\\text{bin}}$ 是 $c$ 的整数值。\n    - 对于格雷码编码，$k_{\\text{gray}}$ 通过对 $c$ 进行格雷码到二进制的转换获得。\n4. 计算当前状态下与适应度相关的项：$V_{\\text{bin}} = |2k_{\\text{bin}} - M|$ 和 $V_{\\text{gray}} = |2k_{\\text{gray}} - M|$。\n5. 遍历从 $0$ 到 $b-1$ 的每个位位置 $j$。\n    a. 通过翻转 $c$ 的第 $j$ 位来确定新的码字 $c'$。\n    b. 解码 $c'$ 以获得新的整数值 $k'_{\\text{bin}}$ 和 $k'_{\\text{gray}}$。\n    c. 计算新的适应度项 $V'_{\\text{bin}} = |2k'_{\\text{bin}} - M|$ 和 $V'_{\\text{gray}} = |2k'_{\\text{gray}} - M|$。\n    d. 如果 $V'_{\\text{bin}}  V_{\\text{bin}}$，则增加二进制编码的计数器。\n    e. 如果 $V'_{\\text{gray}}  V_{\\text{gray}}$，则增加格雷码编码的计数器。\n6. 在遍历完所有码字和位翻转后，得到总计数 $S_{\\text{bin}}$ 和 $S_{\\text{gray}}$。\n7. 概率则为 $P_{\\mathrm{improve}}^{\\text{bin}} = S_{\\text{bin}} / (2^b \\cdot b)$ 和 $P_{\\mathrm{improve}}^{\\text{gray}} = S_{\\text{gray}} / (2^b \\cdot b)$。\n\n此过程在提供的代码中得到了精确实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes discretization error and one-step improvement probability for\n    binary and Gray encodings on the sphere function.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, b, L, U)\n        (1, 3, -1.0, 1.0),\n        (5, 4, -1.0, 1.0),\n        (10, 8, -1.0, 1.0),\n        (3, 1, -1.0, 1.0),\n        (2, 12, -1.0, 1.0),\n    ]\n\n    def gray_to_bin_int(g: int) -> int:\n        \"\"\"\n        Converts a Gray-coded integer to its corresponding binary integer value.\n        \"\"\"\n        b = g\n        mask = g >> 1\n        while mask > 0:\n            b ^= mask\n            mask >>= 1\n        return b\n\n    # Store results as formatted strings to match output specification.\n    formatted_results = []\n\n    for n, b, L, U in test_cases:\n        # 1. Discretization Error Calculation\n        # For L = -U, the continuous minimum is 0. The discrete grid point closest to 0\n        # for a coordinate is at |U|/(2^b - 1). The minimum of sum(x_i^2) is n * (|U|/(2^b - 1))^2.\n        # Since all test cases have U=1.0, this simplifies.\n        if (2**b - 1) == 0: # a_val is denominator\n             disc_error = float('inf') if n > 0 else 0.0 # handle b=0 case, though not in tests\n        else:\n             disc_error = n * (U / (2**b - 1))**2\n        \n        # Discretization error is independent of the encoding strategy, as both\n        # cover the same set of phenotype points.\n        d_bin = disc_error\n        d_gray = disc_error\n\n        # 2. One-Step Improvement Probability Calculation\n        improvements_bin = 0\n        improvements_gray = 0\n        num_states = 2**b\n        # Precompute a map from Gray coded integers to binary integers for efficiency.\n        gray_map = {g: gray_to_bin_int(g) for g in range(num_states)}\n        \n        # This value is used for the integer-based fitness comparison\n        # |2k' - M|  |2k - M| to avoid floating point issues.\n        M = num_states - 1\n\n        # Iterate over all possible b-bit codewords (represented as integers 0..2^b-1)\n        for c_int in range(num_states):\n            # For binary encoding, the integer value k is the codeword itself.\n            k_bin = c_int\n            # For Gray encoding, the codeword c_int must be converted to find k.\n            k_gray = gray_map[c_int]\n\n            # Objective value proxy for the current state for each encoding\n            val_bin = abs(2 * k_bin - M)\n            val_gray = abs(2 * k_gray - M)\n\n            # Iterate over all possible single-bit flips\n            for j in range(b):\n                # Flipping the j-th bit is equivalent to XOR with 2^j\n                c_prime_int = c_int ^ (1  j)\n\n                # --- Binary Encoding ---\n                k_prime_bin = c_prime_int\n                val_prime_bin = abs(2 * k_prime_bin - M)\n                if val_prime_bin  val_bin:\n                    improvements_bin += 1\n\n                # --- Gray Encoding ---\n                k_prime_gray = gray_map[c_prime_int]\n                val_prime_gray = abs(2 * k_prime_gray - M)\n                if val_prime_gray  val_gray:\n                    improvements_gray += 1\n\n        # The total number of possible one-bit mutations for a single coordinate\n        # is the number of states times the number of bits.\n        total_mutations = num_states * b\n        \n        p_bin = improvements_bin / total_mutations if total_mutations > 0 else 0.0\n        p_gray = improvements_gray / total_mutations if total_mutations > 0 else 0.0\n\n        sub_result = [d_bin, d_gray, p_bin, p_gray]\n        result_str = f\"[{','.join(f'{x:.12f}' for x in sub_result)}]\"\n        formatted_results.append(result_str)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3132789"}, {"introduction": "许多现实世界中的优化问题具有多个高质量的解，即所谓的“多峰问题”，而标准遗传算法往往会过早收敛到其中一个解，错失其他可能性。本练习将引导您实现一种强大的多样性维持技术——适应度共享。通过在一个具有多个峰值的函数上应用此方法 [@problem_id:3132784]，您将直观地看到适应度共享如何通过惩罚拥挤的搜索区域来鼓励种群维持多个“生态位”，从而同时发现多个最优解。", "problem": "要求您为一个具有显式适应度共享的一维连续优化问题设计并实现一个遗传算法（GA）。其目的是量化适应度共享在优化多峰目标函数时对保留多个生态位（niche）的效果。以下定义和事实构成了此任务的基础，您的解决方案必须由此推导得出。\n\n遗传算法（GA）维护一个候选解的种群，并迭代地应用选择、重组（交叉）和变异，以使种群向更高适应度的方向进化。标准遗传算法使用原始适应度值来确定选择概率或锦标赛结果，这可能导致在多峰景观中过早收敛到单个峰值。适应度共享是一种多样化方法，它通过惩罚拥挤区域来修改有效适应度，从而能够维持对应于不同峰值的多个生态位。\n\n考虑一个在标量决策变量 $x \\in [-5, 5]$ 上的实数编码遗传算法。多峰目标函数定义为高斯峰的总和，\n$$\nf(x) = \\sum_{k=1}^{K} a_k \\exp\\left(-\\frac{(x - c_k)^2}{2 w_k^2}\\right),\n$$\n其中 $K$ 表示峰的数量，$a_k$ 表示峰的振幅，$c_k$ 表示峰的中心，$w_k$ 表示峰的宽度。对于此问题，使用 $K = 4$ 及以下参数\n$$\nc = [-3.5, -0.5, 1.8, 3.2], \\quad a = [1.0, 0.8, 0.9, 1.2], \\quad w = [0.28, 0.35, 0.25, 0.30].\n$$\n\n适应度共享根据个体 $x_i$ 与种群中所有其他个体 $x_j$ 的距离来调整其有效适应度 $f'_i$：\n$$\nf'_i = \\frac{f(x_i)}{\\sum_{j=1}^{N} s\\left(d_{ij}\\right)},\n$$\n其中 $N$ 是种群大小，$d_{ij} = |x_i - x_j|$ 是决策空间中的欧氏距离，共享函数为\n$$\ns(d) = \\frac{1}{1 + \\left(\\frac{d}{\\sigma}\\right)^{\\alpha}},\n$$\n其中生态位半径 $\\sigma > 0$，形状参数 $\\alpha > 0$。当禁用适应度共享时，选择必须直接使用原始适应度 $f(x)$。\n\n您的遗传算法必须采用以下根据标准遗传算法原则设计的通用组件：\n- 初始化：在 $[L, U]$ 内均匀采样 $x$。\n- 选择：使用相关适应度（共享或原始）应用大小为 $\\kappa$ 的锦标赛选择。\n- 交叉：给定两个父代 $x_p$ 和 $x_q$，通过算术重组 $x_c = \\lambda x_p + (1 - \\lambda) x_q$ 生成一个子代，其中 $\\lambda \\in [0, 1]$ 均匀随机选取，应用概率为 $\\rho$。\n- 变异：添加高斯噪声 $\\epsilon \\sim \\mathcal{N}(0, \\mu^2)$ 并裁剪到 $[L, U]$ 区间内。\n- 精英主义：根据原始适应度保留前 $e$ 个个体。\n- 终止条件：在 $G$ 代后停止。\n\n为了量化多峰保留情况，定义一个峰发现准则：如果在运行结束时，最终种群中至少有 $n_{\\min}$ 个个体与以 $c_k$ 为中心的峰的距离小于 $r_{\\mathrm{detect}}$，则认为该峰被发现。使用 $r_{\\mathrm{detect}} = 0.3$ 和 $n_{\\min} = 3$。发现的峰计数是满足此准则的不同 $k \\in \\{1, 2, 3, 4\\}$ 的数量。\n\n为每个测试配置实现两个版本：一个使用适应度共享（给定 $\\sigma$ 和 $\\alpha$），一个不使用适应度共享的基准版本。对于每个配置，报告整数对 $[\\text{with\\_sharing}, \\text{without\\_sharing}]$，表示终止时发现的峰的数量。\n\n测试套件：\n对以下参数集运行遗传算法（每个配置是一个独立的测试用例）。为了可复现性，将每个用例的随机种子固定为 $s_i$，其中 $s_1 = 123, s_2 = 124, s_3 = 125, s_4 = 126, s_5 = 127$；在一个用例内，共享版本和基准版本的运行使用相同的种子。\n\n- 用例 $1$：$N = 60$, $G = 120$, $\\sigma = 0.6$, $\\alpha = 2$, $\\mu = 0.15$, $\\kappa = 3$, $\\rho = 0.9$, $e = \\lfloor 0.1 N \\rfloor$。\n- 用例 $2$：$N = 60$, $G = 120$, $\\sigma = 10^{-9}$, $\\alpha = 2$, $\\mu = 0.15$, $\\kappa = 3$, $\\rho = 0.9$, $e = \\lfloor 0.1 N \\rfloor$。\n- 用例 $3$：$N = 60$, $G = 120$, $\\sigma = 3.0$, $\\alpha = 2$, $\\mu = 0.15$, $\\kappa = 3$, $\\rho = 0.9$, $e = \\lfloor 0.1 N \\rfloor$。\n- 用例 $4$：$N = 30$, $G = 150$, $\\sigma = 0.6$, $\\alpha = 2$, $\\mu = 0.20$, $\\kappa = 3$, $\\rho = 0.9$, $e = \\lfloor 0.1 N \\rfloor$。\n- 用例 $5$：$N = 60$, $G = 120$, $\\sigma = 0.6$, $\\alpha = 4$, $\\mu = 0.15$, $\\kappa = 3$, $\\rho = 0.9$, $e = \\lfloor 0.1 N \\rfloor$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个元素对应一个测试用例，并且本身是一个双元素列表 $[\\text{with\\_sharing}, \\text{without\\_sharing}]$。例如，$[[a_1,b_1],[a_2,b_2],\\dots]$，其中 $a_i$ 和 $b_i$ 是 $i \\in \\{1,2,3,4,5\\}$ 的整数。", "solution": "该设计遵循标准遗传算法（GA）的原则和适应度共享机制。GA通过维护一个候选解的种群，评估适应度，并在多代中应用选择、交叉和变异来探索和利用搜索空间。选择会放大适应度较高的个体，这在多峰目标函数中往往导致大多数个体聚集在最高的峰值处，从而减少多样性并抑制其他峰的发现。\n\n适应度共享通过考虑种群密度来修改有效适应度。对于位于位置 $x_i$、原始适应度为 $f(x_i)$ 的个体，共享适应度的定义为\n$$\nf'_i = \\frac{f(x_i)}{\\sum_{j=1}^{N} s(d_{ij})}, \\quad d_{ij} = |x_i - x_j|,\n$$\n其中共享函数 $s(d)$ 随距离平滑衰减，遵循\n$$\ns(d) = \\frac{1}{1 + \\left(\\frac{d}{\\sigma}\\right)^{\\alpha}}.\n$$\n当许多个体位于 $x_i$ 的距离尺度 $\\sigma$ 内时，该分母会增大，从而降低拥挤区域中个体的有效适应度。在选择中，使用 $f'_i$ 而非 $f(x_i)$ 会惩罚过度拥挤，使得人口较少的生态位更具竞争力。两个极限情况揭示了与GA基本原理一致的行为：\n- 当 $\\sigma \\to 0^+$ 时，对于 $d > 0$ 有 $(\\frac{d}{\\sigma})^{\\alpha} \\to \\infty$ 且 $s(d > 0) \\to 0$，而 $s(0) = 1$。于是 $\\sum_j s(d_{ij}) \\approx 1$ 且 $f'_i \\approx f(x_i)$，恢复到基准GA。\n- 当 $\\sigma$ 相对于定义域直径变得非常大时，对于所有 $d$，有 $s(d) \\approx \\frac{1}{1 + 0} = 1$，因此 $\\sum_j s(d_{ij}) \\approx N$，得到 $f'_i \\approx \\frac{f(x_i)}{N}$。这会使整个种群的选择压力变得平坦，可能减慢收敛速度，并且如果变异和交叉不能补偿，会降低在多个峰周围形成集中集群的能力。\n\n多峰目标函数定义为高斯峰的总和，\n$$\nf(x) = \\sum_{k=1}^{K} a_k \\exp\\left(-\\frac{(x - c_k)^2}{2 w_k^2}\\right),\n$$\n其中 $K = 4$，中心 $c = [-3.5, -0.5, 1.8, 3.2]$，振幅 $a = [1.0, 0.8, 0.9, 1.2]$，以及宽度 $w = [0.28, 0.35, 0.25, 0.30]$。这些参数在 $[L, U] = [-5, 5]$ 内产生不同的峰，创建了一个现实且科学上合理的多峰景观。\n\n指定了GA组件以确保一个有原则的实现：\n- 初始化在 $[L, U]$ 内均匀采样 $x$，提供无偏的初始多样性。\n- 通过大小为 $\\kappa$ 的锦标赛进行选择，使用选定的适应度（共享或原始）。锦标赛选择基于这样的原则：更高的适应度增加了赢得锦标赛的概率，从而传播有利的性状。\n- 算术交叉 $x_c = \\lambda x_p + (1 - \\lambda) x_q$（其中 $\\lambda \\sim \\mathcal{U}[0, 1]$）适用于实数编码的GA，并尊重搜索空间的连续性。\n- 变异添加高斯噪声 $\\epsilon \\sim \\mathcal{N}(0, \\mu^2)$ 并裁剪到边界内，确保有界的探索。\n- 精英主义根据原始适应度保留前 $e$ 个个体，以避免突然丢失高质量的解，这与GA的利用方面相一致。\n\n为了量化多峰保留情况，将发现的峰计数定义为在终止时至少有 $n_{\\min}$ 个个体处于距离 $r_{\\mathrm{detect}}$ 内的峰 $c_k$ 的数量。使用 $r_{\\mathrm{detect}} = 0.3$ 和 $n_{\\min} = 3$ 确保检测需要一个非平凡的集群，而不是单个偶然的个体，这与维持生态位的目标一致。\n\n适应度共享的效果通过一个具有不同 $\\sigma$, $\\alpha$, $N$ 和 $G$ 的测试套件进行评估：\n- 适中的 $\\sigma$（例如 $\\sigma = 0.6$）和 $\\alpha = 2$ 通过在大致峰间距的尺度上惩罚过度拥挤的峰来促进多个生态位的形成，使得几个峰能够持续存在。\n- 接近零的 $\\sigma$ 近似于基准情况，说明当生态位无穷小时，共享的影响可以忽略不计。\n- 大的 $\\sigma$（例如 $\\sigma = 3.0$）会对所有个体进行类似的过度惩罚，使有效适应度扁平化，并减少了围绕任何峰进行巩固的选择压力，如果变异不能产生足够的收敛，这可能会减少持续集群的数量。\n- 增加 $\\alpha$ 会使共享函数变得更尖锐，使得惩罚随距离下降得更快，并调节生态位被分离的锐利程度。\n\n通过对每个用例使用相同的种子运行共享版本和基准版本，我们分离出适应度共享对最终发现的峰数量的影响。每个用例的最终输出包含一个配对 $[\\text{with\\_sharing}, \\text{without\\_sharing}]$。这直接量化了适应度共享如何改变GA在多峰景观中维持多个生态位的能力，这是从GA的基本原理和指定的共享函数中一致推导出来的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# Multimodal function: sum of Gaussians with specified parameters.\ndef f(x):\n    centers = np.array([-3.5, -0.5, 1.8, 3.2])\n    amplitudes = np.array([1.0, 0.8, 0.9, 1.2])\n    widths = np.array([0.28, 0.35, 0.25, 0.30])\n    # Ensure x is array-like\n    xv = np.atleast_1d(x)\n    total = np.zeros_like(xv, dtype=float)\n    for c, a, w in zip(centers, amplitudes, widths):\n        total += a * np.exp(-((xv - c) ** 2) / (2.0 * (w ** 2)))\n    return total\n\ndef sharing_denominator(pop, sigma_share, alpha):\n    \"\"\"\n    Compute the sharing denominator for each individual:\n    denom[i] = sum_j s(d_ij), where s(d) = 1 / (1 + (d/sigma)^alpha).\n    If sigma_share is None or 0.0, return ones (no sharing).\n    \"\"\"\n    n = pop.shape[0]\n    if sigma_share is None or sigma_share == 0.0:\n        return np.ones(n, dtype=float)\n    # Compute pairwise distances in 1D\n    dists = np.abs(pop.reshape(-1, 1) - pop.reshape(1, -1))\n    # Avoid numerical issues when sigma is extremely small by safe division\n    scaled = (dists / sigma_share) ** alpha\n    s = 1.0 / (1.0 + scaled)\n    denom = np.sum(s, axis=1)\n    # Ensure denom is at least 1 (it includes self s(0)=1)\n    return denom\n\ndef tournament_select(pop, fitness, k, rng):\n    \"\"\"\n    Tournament selection: returns index of selected individual.\n    \"\"\"\n    n = pop.shape[0]\n    # Sample k competitors without replacement\n    idxs = rng.choice(n, size=k, replace=False)\n    # Winner is the one with highest fitness\n    winner_idx = idxs[np.argmax(fitness[idxs])]\n    return winner_idx\n\ndef make_child(p1, p2, crossover_rate, mutation_sigma, bounds, rng):\n    \"\"\"\n    Produce one child from parents p1, p2 with arithmetic crossover and Gaussian mutation.\n    \"\"\"\n    L, U = bounds\n    if rng.random()  crossover_rate:\n        lam = rng.random()\n        child = lam * p1 + (1.0 - lam) * p2\n    else:\n        # Clone one parent randomly\n        child = p1 if rng.random()  0.5 else p2\n    # Mutation\n    child += rng.normal(loc=0.0, scale=mutation_sigma)\n    # Clip to bounds\n    child = np.clip(child, L, U)\n    return child\n\ndef count_discovered_peaks(pop, r_detect=0.3, n_min=3):\n    centers = np.array([-3.5, -0.5, 1.8, 3.2])\n    counts = []\n    for c in centers:\n        num_near = np.sum(np.abs(pop - c)  r_detect)\n        counts.append(num_near >= n_min)\n    return int(np.sum(counts))\n\ndef run_ga_case(seed, pop_size, generations, sigma_share, alpha, mutation_sigma, tournament_k, crossover_rate, elite_count):\n    rng = np.random.default_rng(seed)\n    L, U = -5.0, 5.0\n    # Initialize population uniformly\n    pop = rng.uniform(L, U, size=pop_size)\n    # Run GA loop\n    for _ in range(generations):\n        raw_fit = f(pop)\n        \n        # Determine the fitness to use for selection\n        if sigma_share is not None:\n            denom = sharing_denominator(pop, sigma_share, alpha)\n            selection_fit = raw_fit / denom\n        else:\n            selection_fit = raw_fit\n            \n        # Elites based on raw fitness\n        elite_idx = np.argsort(raw_fit)[-elite_count:]\n        elites = pop[elite_idx]\n        # Create offspring\n        offspring = []\n        needed = pop_size - elite_count\n        for _ in range(needed):\n            i1 = tournament_select(pop, selection_fit, tournament_k, rng)\n            i2 = tournament_select(pop, selection_fit, tournament_k, rng)\n            child = make_child(pop[i1], pop[i2], crossover_rate, mutation_sigma, (L, U), rng)\n            offspring.append(child)\n        pop = np.concatenate([elites, np.array(offspring)])\n    discovered = count_discovered_peaks(pop, r_detect=0.3, n_min=3)\n    return discovered\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (seed, N, G, sigma, alpha, mu, k, rho, elite_count)\n        (123, 60, 120, 0.6, 2.0, 0.15, 3, 0.9, int(0.1 * 60)),\n        (124, 60, 120, 1e-9, 2.0, 0.15, 3, 0.9, int(0.1 * 60)),\n        (125, 60, 120, 3.0, 2.0, 0.15, 3, 0.9, int(0.1 * 60)),\n        (126, 30, 150, 0.6, 2.0, 0.20, 3, 0.9, int(0.1 * 30)),\n        (127, 60, 120, 0.6, 4.0, 0.15, 3, 0.9, int(0.1 * 60)),\n    ]\n\n    results = []\n    for seed, N, G, sigma, alpha, mu, k, rho, e in test_cases:\n        # With sharing\n        with_sharing = run_ga_case(seed, N, G, sigma, alpha, mu, k, rho, e)\n        # Without sharing: same seed, sigma_share = None\n        without_sharing = run_ga_case(seed, N, G, None, alpha, mu, k, rho, e)\n        results.append([with_sharing, without_sharing])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results)).replace(' ', '')}]\")\n\nsolve()\n```", "id": "3132784"}]}