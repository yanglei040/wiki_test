{"hands_on_practices": [{"introduction": "理论学习之后，最好的检验方式就是亲手实现算法。本练习将指导你从零开始构建一个模拟退火求解器，并将其应用于经典的多峰优化基准问题——Rastrigin函数 [@problem_id:3193392]。通过这个实践，你将深入理解模拟退火的核心机制，包括Metropolis接受准则和几何降温策略，为解决更复杂的问题打下坚实基础。", "problem": "实现一个完整的模拟退火 (SA) 求解器，以在有界连续域上近似最小化多元 Rastrigin 能量函数，并通过经验研究收敛质量如何随维度变化。您的程序必须是自包含的，并为下面指定的固定测试套件生成结果。\n\n基本基础：基于以下基石构建您的算法。\n- $n$ 维的 Rastrigin 能量由下式给出\n$$E(\\mathbf{x}) = A n + \\sum_{i=1}^{n} \\left(x_i^2 - A \\cos(2\\pi x_i)\\right),$$\n域约束为 $\\mathbf{x} \\in [-B,B]^n$。使用 $A = 10$ 和 $B = 5.12$。所有三角函数参数均以弧度为单位。\n- 在温度 $T$ 下，构型 $\\mathbf{x}$ 的目标平稳分布的 Boltzmann 形式与 $\\exp\\!\\left(-E(\\mathbf{x})/T\\right)$ 成正比。\n- 当提议分布对称时，Metropolis 机制必须强制执行相对于平稳分布的细致平衡。\n- 使用几何降温方案，其中 $T_{k+1} = \\alpha T_k$，且 $0  \\alpha  1$，$T_0 > 0$。\n- 在 $\\mathbb{R}^n$ 中使用对称高斯提议机制。\n\n设计约束和要求：\n1. 提议和域处理。\n   - 从当前状态 $\\mathbf{x}$，提议 $\\mathbf{y} = \\mathbf{x} + \\boldsymbol{\\eta}$，其中 $\\boldsymbol{\\eta} \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I})$，$\\sigma$ 是一个与迭代相关的标量。\n   - 通过在边界处进行镜面反射来强制执行边界 $\\mathbf{y} \\in [-B,B]^n$，而不是通过拒绝或截断。也就是说，如果任何坐标超出该区间，则通过镜像对称将其反射回区间内；根据需要重复此过程，直到所有坐标都在 $[-B,B]$ 内。\n   - 为保持步长与维度无关，在每次迭代中，将名义步长参数 $s_0$ 按 $\\sigma = \\left(s_0/\\sqrt{n}\\right)\\sqrt{T/T_0}$ 进行缩放。\n2. 接受准则。\n   - 从对称提议分布和 Boltzmann 平稳分布的细致平衡要求出发，推导一个接受准则。不要假定任何快捷公式；明确论证您的准则如何强制执行细致平衡。\n3. 降温方案和停止条件。\n   - 使用给定的 $\\alpha$ 和 $T_0$ 的几何降温方案。\n   - 每个测试用例使用固定的评估预算，等于指定的提议移动次数。每次提议计为一次目标函数评估。\n4. 性能指标。\n   - 对于每个测试用例，仅报告 SA 运行找到的最终最佳能量，四舍五入到六位小数。不涉及物理单位。\n5. 角度单位。\n   - 所有三角函数计算必须使用弧度。\n\n测试套件和参数：\n- 所有情况均使用 $A = 10$ 和 $B = 5.12$。\n- 在以下用例上运行算法，每个用例指定为一个元组 $(n, \\text{seed}, \\text{evals}, T_0, \\alpha, s_0)$：\n  - 用例 1：$(1, 1, 4000, 5.0, 0.995, 0.5)$\n  - 用例 2：$(2, 2, 6000, 5.0, 0.995, 0.5)$\n  - 用例 3：$(5, 3, 10000, 5.0, 0.995, 0.5)$\n  - 用例 4：$(10, 4, 15000, 5.0, 0.995, 0.5)$\n  - 用例 5：$(20, 5, 20000, 5.0, 0.995, 0.5)$\n  - 用例 6 (固定维度下的降温方案敏感性)：$(10, 6, 15000, 5.0, 0.999, 0.5)$\n\n您的程序必须做到：\n- 按规定实现 SA，包含反射处理、高斯对称提议、与 Boltzmann 分布一致的接受准则以及几何降温。\n- 对于每个测试用例，从使用提供的伪随机数种子在 $[-B,B]^n$ 上均匀采样的初始点开始（确定性可复现）。\n- 在恰好给定的评估次数后，返回找到的最终最佳能量。\n\n最终输出格式：\n- 您的程序应产生单行输出，包含结果，格式为逗号分隔的浮点数列表，四舍五入到六位小数，用方括号括起来，不含空格。第 $i$ 个条目对应于上面列出的第 $i$ 个用例。例如，一个语法正确的输出看起来像\n$[\\text{r}_1,\\text{r}_2,\\text{r}_3,\\text{r}_4,\\text{r}_5,\\text{r}_6]$\n其中每个 $\\text{r}_i$ 是一个小数点后恰好有六位数字的十进制数。", "solution": "问题陈述经评估有效。它具有科学依据、问题适定、客观，并包含构建唯一可验证解决方案所需的所有必要信息。任务是实现一个模拟退火 (SA) 算法，以找到多元 Rastrigin 函数的近似全局最小值，并且所有算法组件和参数都已精确指定。\n\n该解决方案是基于统计力学和随机优化的基本原理开发的。\n\n1.  **目标函数**\n    需要最小化的能量函数是 $n$ 维 Rastrigin 函数，定义为：\n    $$E(\\mathbf{x}) = A n + \\sum_{i=1}^{n} \\left(x_i^2 - A \\cos(2\\pi x_i)\\right)$$\n    指定的常数为 $A = 10$ 和 $B = 5.12$。对于任何状态向量 $\\mathbf{x} = (x_1, x_2, \\ldots, x_n)$，其域是超立方体 $\\mathbf{x} \\in [-B, B]^n$。该函数的全局最小值为 $E(\\mathbf{0}) = 0$，在 $\\mathbf{x} = \\mathbf{0}$ 处取得。\n\n2.  **模拟退火与 Metropolis-Hastings 算法**\n    模拟退火是一种概率性元启发式算法，其灵感来源于冶金学中的物理退火过程。系统状态通过迭代演化，同时逐渐降低一个称为温度的控制参数 $T$。在高温 $T$ 时，系统会广泛地探索状态空间。随着 $T$ 的降低，系统被引导至一个低能量状态并稳定下来。\n\n    系统状态的演化由一个马尔可夫链控制，该马尔可夫链被设计为在任何给定温度 $T$ 下收敛到一个平稳的 Boltzmann 分布：\n    $$P(\\mathbf{x}; T) = \\frac{1}{Z(T)} \\exp\\left(-\\frac{E(\\mathbf{x})}{T}\\right)$$\n    其中 $Z(T)$ 是配分函数。该分布赋予低能量状态更高的概率。\n\n    为确保收敛到 $P(\\mathbf{x}; T)$，转移机制必须满足细致平衡条件。设 $W(\\mathbf{x} \\to \\mathbf{y})$ 是从状态 $\\mathbf{x}$ 到状态 $\\mathbf{y}$ 的转移概率。细致平衡要求：\n    $$P(\\mathbf{x}) W(\\mathbf{x} \\to \\mathbf{y}) = P(\\mathbf{y}) W(\\mathbf{y} \\to \\mathbf{x})$$\n    转移概率可以分解为一个提议概率 $g(\\mathbf{y}|\\mathbf{x})$ 和一个接受概率 $A(\\mathbf{y}|\\mathbf{x})$，使得 $W(\\mathbf{x} \\to \\mathbf{y}) = g(\\mathbf{y}|\\mathbf{x}) A(\\mathbf{y}|\\mathbf{x})$。将此式和 Boltzmann 分布代入细致平衡方程，可得：\n    $$e^{-E(\\mathbf{x})/T} g(\\mathbf{y}|\\mathbf{x}) A(\\mathbf{y}|\\mathbf{x}) = e^{-E(\\mathbf{y})/T} g(\\mathbf{x}|\\mathbf{y}) A(\\mathbf{x}|\\mathbf{y})$$\n    问题指定了一个对称提议分布 $g(\\mathbf{y}|\\mathbf{x}) = g(\\mathbf{x}|\\mathbf{y})$，该分布基于一个各向同性的高斯步长。这将条件简化为：\n    $$\\frac{A(\\mathbf{y}|\\mathbf{x})}{A(\\mathbf{x}|\\mathbf{y})} = \\frac{e^{-E(\\mathbf{y})/T}}{e^{-E(\\mathbf{x})/T}} = \\exp\\left(-\\frac{E(\\mathbf{y}) - E(\\mathbf{x})}{T}\\right)$$\n    对于接受概率，满足此比率的标准 Metropolis 选择是：\n    $$A(\\mathbf{y}|\\mathbf{x}) = \\min\\left(1, \\exp\\left(-\\frac{\\Delta E}{T}\\right)\\right)$$\n    其中 $\\Delta E = E(\\mathbf{y}) - E(\\mathbf{x})$。这就是所实现的接受准则。如果新状态具有更低的能量 ($\\Delta E  0$)，它总是被接受。如果它具有更高的能量 ($\\Delta E > 0$)，它将以一定的概率被接受，该概率随着能量增量变大或温度变低而减小。这使得算法能够逃离局部最小值。\n\n3.  **算法实现**\n    SA 求解器是遵循指定的设计约束实现的。\n\n    _初始化_：\n    - 初始温度设置为 $T_0$。\n    - 为保证可复现性，伪随机数生成器需要设定种子。\n    - 从域 $[-B, B]^n$ 上的均匀分布中抽取一个初始状态 $\\mathbf{x}_{\\text{current}}$。\n    - 计算能量 $E_{\\text{current}} = E(\\mathbf{x}_{\\text{current}})$。\n    - 初始化迄今找到的最佳状态和能量：$\\mathbf{x}_{\\text{best}} = \\mathbf{x}_{\\text{current}}$ 和 $E_{\\text{best}} = E_{\\text{current}}$。\n\n    _迭代循环_：算法进行固定次数的评估 (`evals`)。\n    1.  **提议生成**：从当前状态 $\\mathbf{x}_{\\text{current}}$ 生成一个新的候选状态 $\\mathbf{y}_{\\text{new}}$。从一个 $n$ 维正态分布 $\\mathcal{N}(\\mathbf{0}, \\sigma^2 \\mathbf{I})$ 中抽取一个随机步长向量 $\\boldsymbol{\\eta}$。提议方差 $\\sigma^2$ 与温度相关，以调整搜索尺度：\n        $$\\sigma(T) = \\frac{s_0}{\\sqrt{n}}\\sqrt{\\frac{T}{T_0}}$$\n        其中 $s_0$ 是一个名义步长参数。按 $1/\\sqrt{n}$ 进行缩放可确保步长向量的期望大小 $\\|\\boldsymbol{\\eta}\\|$ 大致上与维度 $n$ 无关。原始提议为 $\\mathbf{y}_{\\text{raw}} = \\mathbf{x}_{\\text{current}} + \\boldsymbol{\\eta}$。\n\n    2.  **边界处理**：使用镜面反射来强制执行域约束 $\\mathbf{x} \\in [-B, B]^n$。$\\mathbf{y}_{\\text{raw}}$ 的任何坐标如果落在区间 $[-B, B]$ 之外，都会被反射回区间内。重复此过程，直到该点位于域内。对于单个坐标 $y_i$ 和宽度为 $W=2B$ 的区间 $[-B, B]$，此映射通过考虑区间 $[0, W]$ 上的移位坐标 $y'_i = y_i + B$ 来实现。遍历的完整区间宽度数量为 $k = \\lfloor y'_i / W \\rfloor$。在 $[0, W]$ 段内的位置是 $y''_i = y'_i \\pmod{W}$。如果 $k$ 是偶数，则最终位置为 $y_i''-B$。如果 $k$ 是奇数，则粒子被反射了奇数次，其位置为 $(W-y_i'')-B$。最终得到的状态是 $\\mathbf{y}_{\\text{new}}$。这种确定性映射在实践意义上保留了 Metropolis 准则的对称性假设，正如在 SA 实现中通常所假定的那样。\n\n    3.  **接受**：计算能量 $E_{\\text{new}} = E(\\mathbf{y}_{\\text{new}})$。能量变化为 $\\Delta E = E_{\\text{new}} - E_{\\text{current}}$。新状态以如上定义的 Metropolis 概率 $A(\\mathbf{y}_{\\text{new}}|\\mathbf{x}_{\\text{current}})$ 被接受，即 $\\mathbf{x}_{\\text{current}} \\leftarrow \\mathbf{y}_{\\text{new}}$。\n\n    4.  **最佳状态跟踪**：在 $\\mathbf{x}_{\\text{current}}$ 可能更新后，将其能量与迄今为止找到的最佳能量 $E_{\\text{best}}$ 进行比较。如果 $E_{\\text{current}}  E_{\\text{best}}$，则设置 $E_{\\text{best}} = E_{\\text{current}}$。\n\n    5.  **降温**：根据几何降温方案降低温度：$T_{k+1} = \\alpha T_k$。\n\n    _终止_：循环在 `evals` 次提议后终止。$E_{\\text{best}}$ 的最终值作为结果报告。\n\n4.  **测试套件执行**\n    针对六个指定的测试用例执行该算法，每个用例都有自己的一组参数 $(n, \\text{seed}, \\text{evals}, T_0, \\alpha, s_0)$。每个用例的最终优化能量四舍五入到六位小数，并按要求格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and runs a Simulated Annealing solver for the Rastrigin function\n    as per the problem specification.\n    \"\"\"\n\n    # --- Constants specified in the problem ---\n    A = 10.0\n    B = 5.12\n\n    def rastrigin(x: np.ndarray, n: int) - float:\n        \"\"\"\n        Calculates the Rastrigin energy function for a given vector x.\n        E(x) = An + sum(x_i^2 - A*cos(2*pi*x_i))\n        \"\"\"\n        if n == 0:\n            return 0.0\n        return A * n + np.sum(x**2 - A * np.cos(2 * np.pi * x))\n\n    def reflect_bounds(y: np.ndarray, B_val: float) - np.ndarray:\n        \"\"\"\n        Enforces domain bounds [-B_val, B_val]^n by specular reflection.\n        Handles proposals that may be far outside the boundaries by repeated\n        reflection until the point is inside.\n        \"\"\"\n        min_val = -B_val\n        max_val = B_val\n        width = max_val - min_val\n\n        y_shifted = y - min_val\n        \n        # Calculate how many times the point has \"wrapped\" around the interval\n        num_wraps = np.floor(y_shifted / width)\n        \n        # The position within the base interval [0, width]\n        y_wrapped = y_shifted % width\n        \n        # Create masks for even and odd numbers of wraps\n        even_mask = num_wraps % 2 == 0\n        odd_mask = ~even_mask\n        \n        y_reflected = np.zeros_like(y)\n        \n        # If even wraps, position is relative to min_val\n        y_reflected[even_mask] = min_val + y_wrapped[even_mask]\n        \n        # If odd wraps, position is reflected relative to max_val\n        y_reflected[odd_mask] = max_val - y_wrapped[odd_mask]\n        \n        return y_reflected\n\n    def run_simulated_annealing(n: int, seed: int, evals: int, T0: float, alpha: float, s0: float) - float:\n        \"\"\"\n        Executes a single run of the Simulated Annealing algorithm.\n        \"\"\"\n        # 1. Initialization\n        rng = np.random.default_rng(seed)\n        \n        T = T0\n        \n        # Initial point sampled uniformly from the domain\n        x_current = rng.uniform(-B, B, size=n)\n        E_current = rastrigin(x_current, n)\n        \n        E_best = E_current\n\n        # 2. Main Loop\n        for _ in range(evals):\n            # Propose a new state\n            sigma = (s0 / np.sqrt(n if n > 0 else 1)) * np.sqrt(T / T0)\n            eta = rng.normal(loc=0.0, scale=sigma, size=n)\n            y_raw = x_current + eta\n            \n            # Enforce boundary conditions via reflection\n            y_new = reflect_bounds(y_raw, B)\n            \n            # Evaluate the new state\n            E_new = rastrigin(y_new, n)\n            \n            # Metropolis acceptance criterion\n            delta_E = E_new - E_current\n            \n            # Accept if better or with probability exp(-delta_E / T)\n            if delta_E  0 or (T > 0 and rng.random()  np.exp(-delta_E / T)):\n                x_current = y_new\n                E_current = E_new\n            \n            # Update the best energy found so far (from all accepted states)\n            if E_current  E_best:\n                E_best = E_current\n                \n            # Cool down the temperature\n            T *= alpha\n            \n        return E_best\n\n    # --- Test Suite ---\n    test_cases = [\n        # (n, seed, evals, T0, alpha, s0)\n        (1, 1, 4000, 5.0, 0.995, 0.5),\n        (2, 2, 6000, 5.0, 0.995, 0.5),\n        (5, 3, 10000, 5.0, 0.995, 0.5),\n        (10, 4, 15000, 5.0, 0.995, 0.5),\n        (20, 5, 20000, 5.0, 0.995, 0.5),\n        (10, 6, 15000, 5.0, 0.999, 0.5),\n    ]\n\n    results = []\n    for case in test_cases:\n        best_energy = run_simulated_annealing(*case)\n        # Round to 6 decimal places and format to ensure trailing zeros\n        results.append(f\"{round(best_energy, 6):.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3193392"}, {"introduction": "掌握了基本原理后，让我们将模拟退火应用于一个来自信号处理领域的实际问题：稀疏信号重构 [@problem_id:3193389]。这个练习是一个组合优化问题，我们将通过搜索最佳的“支撑集”来解决它。通过将模拟退火与简单的贪婪算法进行对比，你将亲眼见证它如何凭借概率性接受“上坡”移动的能力，成功逃离贪婪算法所陷入的局部最优陷阱。", "problem": "给定一个稀疏信号重构任务，该任务被构建为一个带有非凸稀疏性惩罚的全局优化问题。设 $A \\in \\mathbb{R}^{m \\times n}$ 是一个测量矩阵，其列向量被归一化为单位 $\\ell_2$-范数，$y \\in \\mathbb{R}^{m}$ 是观测到的数据向量，$x \\in \\mathbb{R}^{n}$ 是未知的 $K$-稀疏系数向量。考虑目标函数\n$$\nf(x) \\;=\\; \\lVert A x - y \\rVert_2^2 \\;+\\; \\lambda \\sum_{i=1}^n \\phi\\!\\left(\\lvert x_i \\rvert\\right),\n\\quad\\text{其中}\\quad\n\\phi(t) \\;=\\; \\log\\!\\left(1 + \\gamma t\\right),\n$$\n其中 $\\lambda > 0$ 且 $\\gamma > 0$。惩罚项 $\\phi(\\cdot)$ 在 $x$ 上是非凸的，这使得 $f(\\cdot)$ 通常也是非凸的。\n\n你必须基于统计力学中的正则系综来实现模拟退火（SA）算法。将目标函数 $f(\\cdot)$ 视为能量函数，并使用源于玻尔兹曼分布的 Metropolis 接受概率。具体来说，当提出从当前状态移动到候选状态时，以如下概率接受该候选状态：\n$$\np_{\\text{accept}} \\;=\\; \\min\\!\\left(1, \\exp\\!\\left(-\\frac{\\Delta f}{T}\\right)\\right),\n$$\n其中 $\\Delta f$ 是目标函数的变化量，$T$ 是当前温度。使用指数冷却策略 $T_k = T_0 \\, r^k$，其中初始温度 $T_0 > 0$，冷却速率 $0  r  1$。将 SA 状态定义为一个大小固定为 $\\lvert S \\rvert = K$ 的支撑集 $S \\subset \\{1,2,\\dots,n\\}$，并通过将一个索引 $i \\in S$ 与一个索引 $j \\notin S$ 交换来定义一步邻域。对于任何支撑集 $S$，令 $x^\\star(S)$ 表示限制在 $S$ 上的最小二乘（LS）解，即 $\\lVert A_S x_S - y \\rVert_2^2$ 在 $x_S \\in \\mathbb{R}^{K}$ 上的最小化子，其中对于所有 $i \\notin S$，有 $x_i = 0$。通过将 $x^\\star(S)$ 代入 $f(\\cdot)$ 来评估支撑集 $S$ 的 $f$ 值：\n$$\nf\\big(x^\\star(S)\\big) \\;=\\; \\left\\| A_S x^\\star_S - y \\right\\|_2^2 \\;+\\; \\lambda \\sum_{i \\in S} \\log\\!\\left(1 + \\gamma \\left|x^\\star_i\\right|\\right).\n$$\n\n作为一种基准的“贪心阈值法”，通过选取具有最大绝对相关性 $\\lvert (A^\\top y)_i \\rvert$ 的 $K$ 个索引来构建 $S_{\\text{greedy}}$，然后计算 LS 系数 $x^\\star(S_{\\text{greedy}})$ 及其目标值。\n\n你的任务是编写一个完整的、可运行的程序，该程序：\n- 构建指定的测试套件实例，\n- 运行贪心阈值基准方法以获得 $f\\big(x^\\star(S_{\\text{greedy}})\\big)$，\n- 从 $S_{\\text{greedy}}$ 开始，使用指定的 $(T_0, r)$ 和固定的迭代次数运行模拟退火算法来搜索支撑集，以获得最终的支撑集 $S_{\\text{SA}}$ 和 $f\\big(x^\\star(S_{\\text{SA}})\\big)$，\n- 对每个测试用例，输出一个布尔值，指示 SA 是否严格改进了目标函数，即 $f\\big(x^\\star(S_{\\text{SA}})\\big)  f\\big(x^\\star(S_{\\text{greedy}})\\big)$ 是否成立。\n\n测试套件必须按如下方式构建。对于每种情况，所有随机抽样都使用提供的种子以保证可复现性，并且 $A$ 的列必须归一化为单位 $\\ell_2$-范数：\n\n1. 具有中等稀疏度和噪声的理想情况：\n   - 参数：$m=32$, $n=64$, $K=5$, $\\lambda=0.10$, $\\gamma=10$, 噪声标准差 $\\sigma=0.05$。\n   - 种子：$12345$。\n   - 构建方法：抽取具有独立标准正态分布条目的 $A$ 并归一化其列；抽取一个 $K$-稀疏的真实值 $x_{\\text{true}}$，其非零条目从标准正态分布中抽取；设 $y = A x_{\\text{true}} + \\sigma \\cdot \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, I_m)$。\n   - SA 策略：$T_0 = 1.0$, $r = 0.995$, 迭代次数 $N_{\\text{SA}} = 3000$。\n\n2. 对抗性相关情况，以挑战贪心阈值法：\n   - 参数：$m=32$, $n=64$, $K=5$, $\\lambda=0.10$, $\\gamma=10$, 噪声标准差 $\\sigma=0.05$。\n   - 种子：$54321$。\n   - 构建方法：如情况1一样抽取 $A$ 和 $x_{\\text{true}}$，并类似地构成 $y$；然后选择一个随机索引 $j_{\\text{bad}} \\notin \\operatorname{supp}(x_{\\text{true}})$，并将 $A$ 的第 $j_{\\text{bad}}$ 列替换为与 $y$ 成比例并加上一个小的扰动的归一化向量，即设 $A_{\\cdot j_{\\text{bad}}} \\leftarrow \\frac{y + 0.01 \\eta}{\\lVert y + 0.01 \\eta \\rVert_2}$，其中 $\\eta \\sim \\mathcal{N}(0, I_m)$，并重新归一化该列。这使得 $\\lvert (A^\\top y)_{j_{\\text{bad}}} \\rvert$ 非常大，从而误导贪心阈值法。\n   - SA 策略：$T_0 = 1.0$, $r = 0.995$, 迭代次数 $N_{\\text{SA}} = 4000$。\n\n3. 高噪声情况：\n   - 参数：$m=24$, $n=48$, $K=4$, $\\lambda=0.20$, $\\gamma=8$, 噪声标准差 $\\sigma=0.20$。\n   - 种子：$111$。\n   - 构建方法：如情况1。\n   - SA 策略：$T_0 = 1.0$, $r = 0.995$, 迭代次数 $N_{\\text{SA}} = 3500$。\n\n4. 边界稀疏情况（$K=1$）与低噪声：\n   - 参数：$m=16$, $n=32$, $K=1$, $\\lambda=0.05$, $\\gamma=12$, 噪声标准差 $\\sigma=0.01$。\n   - 种子：$222$。\n   - 构建方法：如情况1。\n   - SA 策略：$T_0 = 1.0$, $r = 0.995$, 迭代次数 $N_{\\text{SA}} = 2500$。\n\n你的程序必须生成单行输出，其中包含四个测试用例的结果，格式为方括号括起来的逗号分隔列表，例如 $\\texttt{[True,False,True,True]}$。不涉及物理单位、角度或百分比；所有量都是实值且无单位。最终输出必须严格遵循所述格式。", "solution": "该问题要求通过最小化一个非凸目标函数来实现和比较两种稀疏信号重构方法。目标是找到一个 $K$-稀疏向量 $x \\in \\mathbb{R}^{n}$，以最小化\n$$\nf(x) \\;=\\; \\lVert A x - y \\rVert_2^2 \\;+\\; \\lambda \\sum_{i=1}^n \\phi\\!\\left(\\lvert x_i \\rvert\\right),\n\\quad\\text{其中}\\quad\n\\phi(t) \\;=\\; \\log\\!\\left(1 + \\gamma t\\right).\n$$\n第一项 $\\lVert A x - y \\rVert_2^2$ 是一个标准的最小二乘数据保真项，用于衡量模型 $A x$ 对观测值 $y$ 的拟合程度。第二项是一个促进稀疏性的惩罚项，其中 $\\lambda > 0$ 控制权衡。函数 $\\phi(t) = \\log(1 + \\gamma t)$ 是一个非凸惩罚项，这使得整个目标函数 $f(x)$ 也是非凸的，从而导致多个局部最小值。这种非凸性是主要的挑战，因为简单的基于梯度的方法容易陷入次优解。\n\n该问题将其构建为对支撑集的组合优化。我们的搜索空间中的一个状态是一个基数固定为 $\\lvert S \\rvert = K$ 的支撑集 $S \\subset \\{1, 2, \\dots, n\\}$。对于任何给定的支撑集 $S$，最优系数通过求解一个限制在由 $S$ 索引的 $A$ 的列上的标准最小二乘问题来找到。设 $A_S$ 是包含这些列的 $A$ 的子矩阵。此支撑集上的最优系数，表示为 $x^\\star_S$，是 $\\min_{z_S \\in \\mathbb{R}^K} \\lVert A_S z_S - y \\rVert_2^2$ 的解。该解可以使用标准的线性最小二乘求解器计算，得到 $x^\\star_S = (A_S^\\top A_S)^{-1} A_S^\\top y$。然后，通过将不在 $S$ 中的分量设置为零来构造完整的向量 $x^\\star(S)$。状态 $S$ 的“能量”是在 $x^\\star(S)$ 处评估的目标函数：\n$$\nE(S) \\;=\\; f\\big(x^\\star(S)\\big) \\;=\\; \\left\\| A_S x^\\star_S - y \\right\\|_2^2 \\;+\\; \\lambda \\sum_{i \\in S} \\log\\!\\left(1 + \\gamma \\left|x^\\star_i\\right|\\right).\n$$\n\n一种基准的“贪心阈值法”被用于比较。这种启发式方法通过选择与相关向量 $c = A^\\top y$ 的最大绝对值相对应的 $K$ 个索引来构建初始支撑集 $S_{\\text{greedy}}$。该方法计算成本低但目光短浅，因为它没有考虑所选列之间的相互作用，并且很容易被误导，例如，被那些与测量向量 $y$ 高度相关但并非真实底层支撑集一部分的列所误导。\n\n模拟退火（SA）被用作一种更复杂的全局优化元启发式算法，以克服贪心方法的局限性。SA 借用了冶金学中退火过程的类比，即先将材料加热然后缓慢冷却，以增大晶体尺寸并减少缺陷。\n1.  **初始化**：搜索从贪心方法提供的支撑集开始，$S_{\\text{current}} = S_{\\text{greedy}}$。这提供了一个合理的起点。\n2.  **邻域**：一个支撑集 $S$ 的邻域被定义为所有可以通过将单个索引 $i \\in S$ 与单个索引 $j \\notin S$ 交换而达到的支撑集。在每次迭代中，从当前支撑集 $S_{\\text{current}}$ 生成一个随机邻居 $S_{\\text{candidate}}$。\n3.  **Metropolis 接受准则**：算法评估能量的变化，$\\Delta E = E(S_{\\text{candidate}}) - E(S_{\\text{current}})$。如果 $\\Delta E  0$，则候选状态更好，移动总是被接受。如果 $\\Delta E \\ge 0$，则移动到一个更差的状态，但它仍可能以玻尔兹曼因子给出的概率 $p_{\\text{accept}} = \\exp(-\\Delta E/T)$ 被接受。这种进行“上坡”移动的能力对于跳出局部最小值至关重要。参数 $T$ 是“温度”，它调节这个概率。\n4.  **冷却策略**：在整个搜索过程中，温度 $T$ 会逐渐降低。指定的指数冷却策略是 $T_k = T_0 r^k$，其中 $T_0$ 是初始温度，$r \\in (0, 1)$ 是冷却速率，$k$ 是迭代次数。在高温下，算法广泛探索搜索空间，容易接受较差的解。随着 $T$ 的降低，算法变得更具选择性，主要接受更好的解，并最终收敛到一个低能量状态。\n\n对于每个测试用例，我们根据指定的参数和随机种子生成问题数据 $(A, y)$。我们计算贪心解 $S_{\\text{greedy}}$ 及其目标值 $f_{\\text{greedy}}$。然后，我们从 $S_{\\text{greedy}}$ 开始，运行 SA 算法固定次数的迭代。记录在整个 SA 运行过程中找到的最佳支撑集 $S_{\\text{SA}}$ 及其对应的目标值 $f_{\\text{SA}}$。最后，我们通过检查是否 $f_{\\text{SA}}  f_{\\text{greedy}}$ 来确定 SA 算法是否找到了一个严格更好的解。对每个用例报告此比较的布尔结果。特别是，对抗性用例的构建旨在展示一个 $S_{\\text{greedy}}$ 被故意设计为次优的场景，为 SA 展示其卓越的全局搜索能力提供了明确的机会。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # Case 1: Ideal case\n        {\n            'm': 32, 'n': 64, 'K': 5, 'lam': 0.10, 'gam': 10, 'sigma': 0.05,\n            'seed': 12345, 'T0': 1.0, 'r': 0.995, 'iters': 3000, 'adversarial': False\n        },\n        # Case 2: Adversarial correlation\n        {\n            'm': 32, 'n': 64, 'K': 5, 'lam': 0.10, 'gam': 10, 'sigma': 0.05,\n            'seed': 54321, 'T0': 1.0, 'r': 0.995, 'iters': 4000, 'adversarial': True\n        },\n        # Case 3: High-noise\n        {\n            'm': 24, 'n': 48, 'K': 4, 'lam': 0.20, 'gam': 8, 'sigma': 0.20,\n            'seed': 111, 'T0': 1.0, 'r': 0.995, 'iters': 3500, 'adversarial': False\n        },\n        # Case 4: Boundary sparsity (K=1)\n        {\n            'm': 16, 'n': 32, 'K': 1, 'lam': 0.05, 'gam': 12, 'sigma': 0.01,\n            'seed': 222, 'T0': 1.0, 'r': 0.995, 'iters': 2500, 'adversarial': False\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_case(**case)\n        # Python's bool string representation is 'True' or 'False'\n        results.append(str(result))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef run_case(m, n, K, lam, gam, sigma, seed, T0, r, iters, adversarial):\n    \"\"\"\n    Runs a single test case for the sparse reconstruction problem.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # Generate data\n    A = rng.normal(size=(m, n))\n    A /= np.linalg.norm(A, axis=0)\n\n    x_true = np.zeros(n)\n    true_support_indices = rng.choice(n, K, replace=False)\n    x_true[true_support_indices] = rng.normal(size=K)\n\n    noise = rng.normal(size=m)\n    y = A @ x_true + sigma * noise\n\n    if adversarial:\n        all_indices = set(range(n))\n        true_support_set = set(true_support_indices)\n        outside_support = list(all_indices - true_support_set)\n        j_bad = rng.choice(outside_support)\n        \n        eta = rng.normal(size=m)\n        new_col = y + 0.01 * eta\n        new_col /= np.linalg.norm(new_col)\n        A[:, j_bad] = new_col\n        # Re-normalize just in case\n        A[:, j_bad] /= np.linalg.norm(A[:, j_bad])\n\n    def evaluate_objective(support_indices, A_mat, y_vec, lam_param, gam_param):\n        \"\"\"\n        Calculates the objective function for a given support set.\n        \"\"\"\n        S_list = sorted(list(support_indices))\n        if not S_list:\n            resid_norm_sq = np.linalg.norm(y_vec)**2\n            penalty = 0.0\n        else:\n            A_S = A_mat[:, S_list]\n            try:\n                x_S = np.linalg.lstsq(A_S, y_vec, rcond=None)[0]\n                resid_norm_sq = np.linalg.norm(A_S @ x_S - y_vec)**2\n                penalty = lam_param * np.sum(np.log(1 + gam_param * np.abs(x_S)))\n            except np.linalg.LinAlgError:\n                return float('inf') # Penalize singular matrices\n            \n        return resid_norm_sq + penalty\n\n    # Greedy Thresholding Baseline\n    correlations = np.abs(A.T @ y)\n    S_greedy = set(np.argsort(correlations)[-K:])\n    f_greedy = evaluate_objective(S_greedy, A, y, lam, gam)\n\n    # Simulated Annealing\n    S_current = S_greedy\n    f_current = f_greedy\n    S_best = S_current\n    f_best = f_greedy\n\n    all_indices = set(range(n))\n    T = T0\n\n    for _ in range(iters):\n        # Generate a neighbor by swapping one index\n        if K == 0 or K == n: # No swaps possible\n            break\n            \n        S_outside = list(all_indices - S_current)\n        idx_to_remove = rng.choice(list(S_current))\n        idx_to_add = rng.choice(S_outside)\n\n        S_candidate = S_current.copy()\n        S_candidate.remove(idx_to_remove)\n        S_candidate.add(idx_to_add)\n\n        f_candidate = evaluate_objective(S_candidate, A, y, lam, gam)\n        delta_f = f_candidate - f_current\n\n        # Metropolis acceptance criterion\n        if delta_f  0:\n            accept = True\n        else:\n            prob = np.exp(-delta_f / T) if T > 0 else 0\n            if rng.random()  prob:\n                accept = True\n            else:\n                accept = False\n        \n        if accept:\n            S_current = S_candidate\n            f_current = f_candidate\n\n        if f_current  f_best:\n            S_best = S_current\n            f_best = f_current\n            \n        # Exponential cooling\n        T *= r\n        \n    f_SA = f_best\n\n    return f_SA  f_greedy\n\nif __name__ == '__main__':\n    solve()\n\n```", "id": "3193389"}, {"introduction": "在实际应用中，固定的降温策略往往效率不高且难以调整。本练习将带你探索一个更高级的主题：设计自适应降温策略 [@problem_id:3193437]。我们将构建一个温度的反馈控制器，通过监测和调控接受率，使其动态地向目标区间收敛，从而让算法更加稳健且易于使用。", "problem": "要求您为全局优化中的模拟退火算法设计、校准并评估一种自适应温度控制规则。其核心更新形式为 $T_{k+1} = T_k \\cdot f(a_k)$，其中 $T_k$ 是第 $k$ 个迭代周期的温度，$a_k$ 是在麦特罗波利斯准则下于第 $k$ 个迭代周期观测到的接受率。您必须从基本定义和事实中推导出一个有原则的 $f(\\cdot)$ 选择，校准其灵敏度以满足目标接受窗口，然后在多个目标函数地貌上测试其稳定性。\n\n推导的基本依据：\n- 模拟退火是一种随机搜索方法，它从当前点 $\\mathbf{x}$ 迭代地提议一个移动，移动到从对称提议分布 $q(\\mathbf{y}\\mid\\mathbf{x})$ 中抽取的新点 $\\mathbf{y}$。\n- 麦特罗波利斯接受概率为 $p_{\\text{acc}}(\\mathbf{x}\\to\\mathbf{y}; T) = \\min\\{1,\\exp(-(E(\\mathbf{y})-E(\\mathbf{x}))/T)\\}$，其中 $E(\\cdot)$ 是目标函数（待最小化），$T$ 是温度。\n- 第 $k$ 个迭代周期的接受率 $a_k$ 是该周期内被接受的提议的经验比例。\n- 对于对称提议和固定的提议尺度，平均接受率是温度 $T$ 的一个非递减函数。\n\n设计目标：\n- 构建一个 $f(\\cdot)$ 的自适应规则，仅使用每个迭代周期观测到的接受率 $a_k$，将过程驱动至一个期望的接受窗口 $[\\ell,u] = [0.2, 0.5]$。\n- 在目标窗口周围使用一个死区，以便当 $a_k$ 位于 $[\\ell,u]$ 内部时，温度保持不变。\n- 您的 $f(\\cdot)$ 函数必须相对于 $a_k$ 与窗口的偏差是单调的：如果 $a_k  \\ell$，该规则应增加 $T$；如果 $a_k > u$，则应降低 $T$。\n\n实现约束和使用的算法：\n- 使用对称高斯提议 $q(\\mathbf{y}\\mid\\mathbf{x}) = \\mathcal{N}(\\mathbf{x}, \\sigma^2 I)$，每个测试用例具有指定的标准差 $\\sigma$ 和单位协方差 $I$。\n- 对于维度 $d > 1$，在 $\\mathbf{x}_0 = \\mathbf{0}$ 处初始化；对于维度 $d=1$，在 $x_0 = 0$ 处初始化。\n- 在 $T_0 = 1.0$ 处初始化温度。\n- 每个迭代周期 $k$ 执行 $M$ 次独立提议，并根据麦特罗波利斯规则计算经验接受率 $a_k$ 作为接受移动的比例。\n- 使用形式为 $T_{k+1} = T_k \\cdot f(a_k)$ 的自适应乘法规则，该规则由一个正标量增益 $\\eta$ 和一个死区控制信号 $h(a)$ 参数化：\n  - 如果 $a \\in [\\ell,u]$，则 $h(a) = 0$，\n  - 如果 $a > u$，则 $h(a) = a - u$，\n  - 如果 $a  \\ell$，则 $h(a) = a - \\ell$，\n  - 并且 $f(a) = \\exp(-\\eta \\, h(a))$。\n- 为保证数值鲁棒性，确保对所有 $k$，$T_k$ 保持在有界区间 $[10^{-8}, 10^{8}]$ 内。\n\n校准要求：\n- 通过从候选集 $\\{\\;0.25,\\;0.5,\\;1.0,\\;2.0\\;\\}$ 中选择增益 $\\eta$，以在短期训练运行中最大化稳态窗口的依从性。\n- 校准中使用 $K_{\\text{cal}} = 30$ 个迭代周期，每个周期有 $M=200$ 次提议。将候选 $\\eta$ 的校准分数定义为最后 $K_{\\text{cal}}/2$ 个迭代周期中 $a_k \\in [\\ell,u]$ 的周期所占的比例。选择得分最高的 $\\eta$；若得分相同，则选择最小的 $\\eta$。\n\n评估要求：\n- 校准后，使用选定的 $\\eta$ 和相同的接受窗口 $[\\ell,u]=[0.2,0.5]$，对每个测试用例进行稳定性评估，评估包含 $K_{\\text{eval}} = 60$ 个迭代周期，每个周期 $M=200$ 次提议。\n- 将测试用例的稳定性指标定义为在最后 $K_{\\text{eval}}/2$ 个迭代周期中，其接受率位于 $[\\ell,u]$ 内的周期所占的比例。\n\n待测试的地貌（目标函数 $E(\\mathbf{x})$）：\n- 维度为 $d$ 的二次碗型函数：$E(\\mathbf{x}) = \\sum_{i=1}^d x_i^2$。\n- 维度为 $d$ 的 Rastrigin 函数：$E(\\mathbf{x}) = 10d + \\sum_{i=1}^d \\left(x_i^2 - 10\\cos(2\\pi x_i)\\right)$。\n- 维度为 $d$ 的 Rosenbrock 函数：$E(\\mathbf{x}) = \\sum_{i=1}^{d-1} \\left(100(x_{i+1} - x_i^2)^2 + (1 - x_i)^2\\right)$。\n- 多井一维分段二次函数：对于 $d=1$，$E(x) = \\min\\left\\{(x+4)^2+2,\\;0.5\\,x^2,\\;1.5\\,(x-4)^2+1\\right\\}$。\n\n测试套件：\n- 案例 1：地貌 = 二次函数， $d=2$， $\\sigma=0.8$， 种子 $=42$。\n- 案例 2：地貌 = Rastrigin 函数， $d=2$， $\\sigma=0.5$， 种子 $=43$。\n- 案例 3：地貌 = Rosenbrock 函数， $d=2$， $\\sigma=0.3$， 种子 $=44$。\n- 案例 4：地貌 = wells1d， $d=1$， $\\sigma=1.0$， 种子 $=45$。\n\n角度单位不适用。不存在物理单位。\n\n程序输出规范：\n- 您的程序必须按所列顺序为每个测试用例运行校准和评估。\n- 对每个测试用例，计算评估稳定性指标，结果为一个在 $[0,1]$ 区间内、四舍五入到三位小数的小数。\n- 您的程序应产生单行输出，其中包含四个结果，以逗号分隔的列表形式，并用方括号括起来，例如 $[0.900,0.867,0.733,0.950]$。\n\n为保证可复现性，所有随机选择都必须使用指定的种子。不需要用户输入。程序必须是自包含的，并且可以直接运行。", "solution": "该问题陈述在计算科学领域，特别是在启发式优化领域，提出了一个有效且定义明确的任务。它要求为模拟退火（SA）算法设计、校准和评估一种自adaptive温度控制机制。该问题在科学上基于统计力学和反馈控制理论的原理，是自包含的，所有必要的参数和过程都已指定，并且其表述是客观的。\n\n### 步骤1：问题陈述的验证\n\n我将首先系统化所提供的信息并验证其完整性。\n\n#### 提取的已知条件：\n- **核心算法**：模拟退火（SA），使用对称提议分布 $q(\\mathbf{y}\\mid\\mathbf{x})$。\n- **接受准则**：麦特罗波利斯概率 $p_{\\text{acc}}(\\mathbf{x}\\to\\mathbf{y}; T) = \\min\\{1,\\exp(-(E(\\mathbf{y})-E(\\mathbf{x}))/T)\\}$，其中 $E(\\cdot)$ 是待最小化的目标函数。\n- **可观测量**：经验接受率 $a_k$，即第 $k$ 个迭代周期中被接受的提议所占的比例。\n- **自适应温度规则**：$T_{k+1} = T_k \\cdot f(a_k)$。\n- **目标接受窗口**：$[\\ell,u] = [0.2, 0.5]$。\n- **控制函数形式**：$f(a) = \\exp(-\\eta \\, h(a))$，其中 $\\eta > 0$ 是一个增益参数。\n- **控制信号 `h(a)` 的定义**：\n    - 如果 $a \\in [0.2, 0.5]$，则 $h(a) = 0$（死区）\n    - 如果 $a > 0.5$，则 $h(a) = a - 0.5$\n    - 如果 $a  0.2$，则 $h(a) = a - 0.2$\n- **提议分布**：对称高斯分布 $q(\\mathbf{y}\\mid\\mathbf{x}) = \\mathcal{N}(\\mathbf{x}, \\sigma^2 I)$。\n- **初始条件**：\n    - 状态：$\\mathbf{x}_0 = \\mathbf{0}$（对于 $d=1$ 则为 $x_0=0$）。\n    - 温度：$T_0 = 1.0$。\n- **模拟参数**：每个迭代周期 $M=200$ 次提议。\n- **数值稳定性**：温度 $T_k$ 被裁剪到区间 $[10^{-8}, 10^{8}]$ 内。\n- **校准过程**：\n    - 候选增益：$\\eta \\in \\{0.25, 0.5, 1.0, 2.0\\}$。\n    - 迭代周期数：$K_{\\text{cal}} = 30$。\n    - 评分指标：在 $k \\in [K_{\\text{cal}}/2, K_{\\text{cal}}-1]$ 的迭代周期中，$a_k \\in [\\ell, u]$ 的周期所占的比例。\n    - 选择规则：选择得分最高的 $\\eta$；若得分相同，则选择最小的 $\\eta$。\n- **评估过程**：\n    - 迭代周期数：$K_{\\text{eval}} = 60$。\n    - 稳定性指标：使用校准后的 $\\eta$，在 $k \\in [K_{\\text{eval}}/2, K_{\\text{eval}}-1]$ 的迭代周期中，$a_k \\in [\\ell, u]$ 的周期所占的比例。\n- **目标函数**：二次函数、Rastrigin 函数、Rosenbrock 函数以及一个一维多井函数。\n- **测试用例**：定义了四个具体案例，每个案例都规定了地貌、维度 $d$、提议标准差 $\\sigma$ 和一个随机种子。\n\n#### 验证结论：\n该问题是**有效的**。\n1.  **有科学依据**：其表述基于模拟退火的既定原则，并引入了一个合理、定义明确的反馈控制机制。目标函数是优化文献中的标准基准测试。\n2.  **定义明确**：该问题指定了一个完整、确定性的过程。所有初始条件、参数和算法都有定义。校准和评估指标明确无误，并提供了平局决胜规则，确保了对于给定的实现有唯一的结果。\n3.  **客观性**：语言正式而精确，没有主观性。\n4.  **完整且一致**：提供了所有必要信息。自适应规则的逻辑与其既定目标一致：当接受率过高时降低温度，过低时升高温度，这构成了一个经典的负反馈系统。\n\n### 步骤2：有原则的解决方案设计\n\n这个问题的核心是通过动态调整控制参数——温度 $T_k$ ——来调节 SA 过程的一个关键可观测量——接受率 $a_k$。这是一个经典的反馈控制问题。\n\n#### 反馈回路\n所提出的系统构成一个负反馈回路。\n1.  **系统**：在给定温度 $T_k$ 下的 SA 搜索过程。\n2.  **输出**：经验接受率 $a_k$。\n3.  **传感器**：从第 $k$ 个迭代周期的 $M$ 次提议中计算 $a_k$。\n4.  **控制器**：更新规则 $T_{k+1} = T_k \\cdot f(a_k)$，它根据观测到的 $a_k$ 与目标窗口 $[\\ell, u]$ 之间的误差来计算新温度。\n5.  **执行器**：在下一个迭代周期中，将新温度 $T_{k+1}$ 应用于麦特罗波利斯准则。\n\n问题中陈述的基本假设是，对于固定的提议尺度 $\\sigma$，接受率是温度的非递减函数。这确保了调整 $T$ 为控制 $a_k$ 提供了一个手段。增加 $T$ 会使得接受更高能量（更差的解）的移动变得更容易，从而增加 $a_k$。降低 $T$ 则有相反的效果。\n\n#### 控制律：$T_{k+1} = T_k \\cdot \\exp(-\\eta \\, h(a_k))$\n该控制律是乘法形式的，对于像温度这样的尺度参数来说，这是一个自然的选择。我们来分析其组成部分。\n\n1.  **误差信号 $h(a_k)$**：该函数测量与目标窗口的偏差。其分段定义实现了一个“死区”控制器。\n    - 如果 $a_k \\in [\\ell, u] = [0.2, 0.5]$，那么 $h(a_k) = 0$。系统处于期望的操作范围内，因此不采取纠正措施。温度保持不变（$f(a_k) = \\exp(0) = 1$），这有助于促进稳定性并防止不必要的振荡。\n    - 如果 $a_k > u$，那么 $h(a_k) = a_k - u > 0$。误差为正。\n    - 如果 $a_k  \\ell$，那么 $h(a_k) = a_k - \\ell  0$。误差为负。\n    因此，信号 $h(a_k)$ 指示了偏离目标窗口最近边界的方向和幅度。\n\n2.  **类比例-积分作用**：这种乘法更新可以被看作是对数空间中的一个离散时间积分器。设 $\\tau_k = \\ln T_k$。更新规则为 $\\tau_{k+1} = \\tau_k - \\eta \\, h(a_k)$。这是一个作用于对数温度的离散时间积分控制器，其中控制器根据累积误差调整变量。增益参数 $\\eta$ 缩放此调整的幅度，从而控制控制器的响应性。\n\n3.  **指数映射**：使用 $f(a) = \\exp(-\\eta h(a))$ 确保了乘法因子始终为正，这对于温度来说是一个物理上的必然要求。指数中的负号对于实现负反馈至关重要：\n    - 如果 $a_k$ 过高（$h(a_k) > 0$），指数为负，因此 $\\exp(-\\eta h(a_k))  1$。这会降低 $T_{k+1}$，从而倾向于将接受率降回到窗口内。\n    - 如果 $a_k$ 过低（$h(a_k)  0$），指数为正，因此 $\\exp(-\\eta h(a_k)) > 1$。这会增加 $T_{k+1}$，从而倾向于将接受率提升回窗口内。\n\n#### 校准与评估\n- **$\\eta$ 的校准**：增益 $\\eta$ 决定了响应性与稳定性之间的权衡。低 $\\eta$ 会导致校正缓慢，可能无法将 $a_k$ 保持在窗口内。高 $\\eta$ 可能导致过度校正以及 $T_k$ 和 $a_k$ 的大幅振荡。问题指定了一种务实的方法：对一组候选值 $\\{\\;0.25,\\;0.5,\\;1.0,\\;2.0\\;\\}$ 进行网格搜索。对于每个地貌，我们模拟一次短暂的“训练”运行，并选择能最大化在目标窗口内停留时间的 $\\eta$。平局决胜规则（选择最小的 $\\eta$）偏向于一个更温和、更稳定的控制器，这是一种合理的工程启发式方法。\n\n- **评估**：在为特定地貌和提议尺度校准了 $\\eta$ 之后，会在一次更长的运行中评估已调优控制器的性能。稳定性指标计算于此运行的后半部分，用于评估控制器的稳态性能，即其在初始瞬态期后将接受率维持在目标窗口内的能力。\n\n整个过程是设计和测试一个简单自适应系统的一种鲁棒且有原则的方法。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the design, calibration, and evaluation of an adaptive\n    temperature control rule for Simulated Annealing.\n    \"\"\"\n\n    # --- Objective Functions ---\n    def quadratic(x):\n        return np.sum(x**2)\n\n    def rastrigin(x):\n        d = len(x)\n        if d == 0: return 0.0\n        return 10 * d + np.sum(x**2 - 10 * np.cos(2 * np.pi * x))\n\n    def rosenbrock(x):\n        d = len(x)\n        if d  2:\n            return 0.0\n        return np.sum(100 * (x[1:] - x[:-1]**2)**2 + (1 - x[:-1])**2)\n\n    def wells1d(x):\n        # Input x is a 1-element array\n        val = x[0]\n        return min((val + 4)**2 + 2, 0.5 * val**2, 1.5 * (val - 4)**2 + 1)\n\n    # --- Test Suite Configuration ---\n    test_cases = [\n        {'name': 'quadratic', 'func': quadratic, 'd': 2, 'sigma': 0.8, 'seed': 42},\n        {'name': 'rastrigin', 'func': rastrigin, 'd': 2, 'sigma': 0.5, 'seed': 43},\n        {'name': 'rosenbrock', 'func': rosenbrock, 'd': 2, 'sigma': 0.3, 'seed': 44},\n        {'name': 'wells1d', 'func': wells1d, 'd': 1, 'sigma': 1.0, 'seed': 45},\n    ]\n\n    # --- Global Parameters ---\n    l, u = 0.2, 0.5\n    M = 200\n    T_clip_min, T_clip_max = 1e-8, 1e8\n    eta_candidates = [0.25, 0.5, 1.0, 2.0]\n    K_cal = 30\n    K_eval = 60\n    \n    final_results = []\n\n    for case in test_cases:\n        objective_func = case['func']\n        d = case['d']\n        sigma = case['sigma']\n        seed = case['seed']\n\n        # --- Calibration Phase ---\n        best_eta = -1\n        max_score = -1\n\n        for eta in eta_candidates:\n            rng = np.random.default_rng(seed)\n            x_current = np.zeros(d)\n            e_current = objective_func(x_current)\n            T_current = 1.0\n            \n            acceptance_rates_cal = []\n\n            for k in range(K_cal):\n                accepted_count = 0\n                for _ in range(M):\n                    x_proposal = x_current + rng.normal(0, sigma, size=d)\n                    e_proposal = objective_func(x_proposal)\n                    delta_e = e_proposal - e_current\n\n                    if delta_e  0:\n                        accept = True\n                    else:\n                        if T_current > 0:\n                            prob_acc = np.exp(-delta_e / T_current)\n                            accept = rng.random()  prob_acc\n                        else:\n                            accept = False\n                    \n                    if accept:\n                        accepted_count += 1\n                        x_current = x_proposal\n                        e_current = e_proposal\n                \n                a_k = accepted_count / M\n                acceptance_rates_cal.append(a_k)\n\n                if a_k > u:\n                    h_a = a_k - u\n                elif a_k  l:\n                    h_a = a_k - l\n                else:\n                    h_a = 0.0\n                \n                f_a = np.exp(-eta * h_a)\n                T_current = np.clip(T_current * f_a, T_clip_min, T_clip_max)\n            \n            score_epochs = acceptance_rates_cal[K_cal // 2:]\n            score = np.mean([l = ar = u for ar in score_epochs])\n            \n            if score > max_score:\n                max_score = score\n                best_eta = eta\n            elif score == max_score:\n                if best_eta == -1 or eta  best_eta:\n                    best_eta = eta\n\n        # --- Evaluation Phase ---\n        rng = np.random.default_rng(seed)\n        x_current = np.zeros(d)\n        e_current = objective_func(x_current)\n        T_current = 1.0\n        \n        acceptance_rates_eval = []\n\n        for k in range(K_eval):\n            accepted_count = 0\n            for _ in range(M):\n                x_proposal = x_current + rng.normal(0, sigma, size=d)\n                e_proposal = objective_func(x_proposal)\n                delta_e = e_proposal - e_current\n\n                if delta_e  0:\n                    accept = True\n                else:\n                    if T_current > 0:\n                        prob_acc = np.exp(-delta_e / T_current)\n                        accept = rng.random()  prob_acc\n                    else:\n                        accept = False\n\n                if accept:\n                    accepted_count += 1\n                    x_current = x_proposal\n                    e_current = e_proposal\n            \n            a_k = accepted_count / M\n            acceptance_rates_eval.append(a_k)\n\n            if a_k > u:\n                h_a = a_k - u\n            elif a_k  l:\n                h_a = a_k - l\n            else:\n                h_a = 0.0\n            \n            f_a = np.exp(-best_eta * h_a)\n            T_current = np.clip(T_current * f_a, T_clip_min, T_clip_max)\n\n        metric_epochs = acceptance_rates_eval[K_eval // 2:]\n        stability_metric = np.mean([l = ar = u for ar in metric_epochs])\n        \n        final_results.append(round(stability_metric, 3))\n\n    # --- Final Output ---\n    print(f\"[{','.join(f'{r:.3f}' for r in final_results)}]\")\n\nsolve()\n```", "id": "3193437"}]}