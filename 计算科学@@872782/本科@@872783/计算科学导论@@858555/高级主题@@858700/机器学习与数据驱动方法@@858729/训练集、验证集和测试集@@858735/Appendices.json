{"hands_on_practices": [{"introduction": "创建训练集、验证集和测试集的首要规则是确保它们在统计上是独立的。这个练习 [@problem_id:3194804] 旨在解决一个常见但隐蔽的错误：由不当的数据增强操作导致的数据泄漏。通过亲手实现错误和正确的两种流程，您将深刻理解为什么在进行任何数据增强之前必须先分割数据集，这是确保模型评估可靠性不可或缺的一步。", "problem": "给定一个场景，其中在将数据集划分为训练集、验证集和测试集之前，独立地创建了增强数据样本。这可能导致同一原始样本的增强近似副本分布在不同的数据子集中，这是一种数据泄露形式，会使无偏模型评估失效。您的任务是在一个独立的程序中实现并分析两个流水线：一个是在划分前进行增强的朴素流水线，另一个是先划分原始样本，然后在每个子集内进行增强的修正流水线。您将根据一个固定的测试套件为这两个流水线计算泄露指标。\n\n请使用以下基本设定：\n- 为了进行无偏评估，训练集、验证集和测试集必须近似于独立同分布的样本。如果关于某个测试样本的信息间接存在于训练数据中，就会发生数据泄露。如果同一原始样本的增强近似副本出现在不同的数据子集中，那么独立性假设就被违反了。\n- 将原始样本身份定义为组标识符。所有源自同一原始样本的增强样本都属于同一个等价类。如果两个增强样本来自同一个原始身份，则称它们为增强孪生样本。\n- 设 $x \\in \\mathbb{R}^d$ 表示一个基础特征向量。一次增强产生 $x' = (1+a)x + \\epsilon$，其中 $a$ 是一个小的乘性抖动，$\\epsilon$ 是小的加性噪声。对于仅使用特征进行近似副本检测，定义两个向量 $u, v \\in \\mathbb{R}^d$ 的余弦相似度为 $\\mathrm{cos}(u,v) = \\dfrac{u^\\top v}{\\lVert u \\rVert_2 \\lVert v \\rVert_2}$。如果对于一个固定的阈值 $\\theta$，有 $\\mathrm{cos}(u,v) \\ge \\theta$，则两个样本是近似副本。\n- 结构良好的划分意味着给定原始身份的所有增强孪生样本必须仅存在于一个数据子集中。如果在不同的子集中发现孪生样本，则发生泄露事件。\n\n您的程序必须：\n1. 使用提供的随机种子，为每个测试用例确定性地生成合成基础样本和增强样本。对于每个基础身份，从 $\\mathbb{R}^d$ 的标准正态分布中抽取一个基础向量，并将其归一化为单位长度。对于 $k$ 次增强中的每一次，从区间 $[-0.01, 0.01]$ 中均匀抽取 $a$，从标准差为 $\\sigma$ 的零均值各向同性高斯分布中抽取 $\\epsilon$，然后构建 $x' = (1 + a)\\, x + \\epsilon$ 并将 $x'$ 归一化为单位长度。\n2. 实现两个流水线：\n   - 朴素流水线：为所有身份创建所有增强样本，然后通过样本级别的随机打乱，根据比例 $(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}})$ 将增强后的集合随机划分为训练集、验证集和测试集，其中 $r_{\\mathrm{train}} + r_{\\mathrm{val}} + r_{\\mathrm{test}} = 1$。设前 $\\lfloor N r_{\\mathrm{train}} \\rfloor$ 个样本为训练集，接下来的 $\\lfloor N r_{\\mathrm{val}} \\rfloor$ 个为验证集，其余为测试集，其中 $N$ 是增强样本的总数。\n   - 修正流水线：首先随机打乱基础身份，并使用相同的比例取整规则在身份级别上将它们按组划分为训练、验证和测试身份集。然后，为每个身份直接在其分配到的子集中生成 $k$ 个增强样本。\n3. 为每个流水线计算：\n   - 组泄露计数 $G$：其增强样本出现在至少两个不同子集中的基础身份的数量。\n   - 跨子集近似副本对计数 $P$：跨不同子集的样本对数量，其余弦相似度严格大于 $\\theta$。仅计算位于不同子集中的样本对；对三个子集对（训练-验证、训练-测试、验证-测试）求和。在计算余弦相似度之前，所有向量都必须进行归一化，以确保点积等于余弦相似度。\n\n使用以下测试套件。每个测试用例提供 $(n_{\\mathrm{base}}, k, d, r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}, \\sigma, \\theta, \\text{seed})$：\n- 案例 1：$n_{\\mathrm{base}} = 50$, $k = 3$, $d = 128$, $(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}) = (0.7, 0.15, 0.15)$, $\\sigma = 0.01$, $\\theta = 0.99$, $\\text{seed} = 42$。\n- 案例 2（边界情况：无增强多重性）：$n_{\\mathrm{base}} = 40$, $k = 1$, $d = 128$, $(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}) = (0.6, 0.2, 0.2)$, $\\sigma = 0.01$, $\\theta = 0.99$, $\\text{seed} = 123$。\n- 案例 3（更强的增强）：$n_{\\mathrm{base}} = 30$, $k = 10$, $d = 128$, $(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}) = (0.6, 0.2, 0.2)$, $\\sigma = 0.01$, $\\theta = 0.99$, $\\text{seed} = 7$。\n- 案例 4（不平衡比例和极小的验证集）：$n_{\\mathrm{base}} = 7$, $k = 4$, $d = 128$, $(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}) = (0.8, 0.01, 0.19)$, $\\sigma = 0.01$, $\\theta = 0.99$, $\\text{seed} = 2023$。\n\n对于每个测试用例，按顺序产生以下六个整数：\n- $I_{\\mathrm{naive}}$：指示符，如果 $G_{\\mathrm{naive}} > 0$ 则为 $1$，否则为 $0$。\n- $I_{\\mathrm{corr}}$：指示符，如果 $G_{\\mathrm{corr}} > 0$ 则为 $1$，否则为 $0$。\n- $G_{\\mathrm{naive}}$：朴素流水线的组泄露计数。\n- $G_{\\mathrm{corr}}$：修正流水线的组泄露计数。\n- $P_{\\mathrm{naive}}$：朴素流水线的跨子集近似副本对计数。\n- $P_{\\mathrm{corr}}$：修正流水线的跨子集近似副本对计数。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含四个测试用例的所有结果，这些结果被展平并打印为单个逗号分隔的整数列表，并用方括号括起来。顺序必须是先案例 1 的值，然后是案例 2，接着是案例 3，最后是案例 4，每个案例贡献六个整数，顺序与上述规定完全一致。例如，一个包含两个假设案例的输出格式为 $[I_1,I_2,G_1,G_2,P_1,P_2,\\dots]$。不应打印任何额外文本。", "solution": "用户提供了一个关于机器学习工作流中因数据增强和数据集划分顺序不当而导致数据泄露的问题陈述。任务是实现并对比两个流水线：一个是在划分前进行增强的“朴素”流水线，另一个是先划分后增强的“修正”流水线。分析涉及为每个流水线在一系列测试用例上计算特定的泄露指标。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n\n- **核心概念**：由于在训练集、验证集和测试集划分之前对原始样本进行增强，导致其近似副本分布于不同子集中，从而引发数据泄露，这违反了进行无偏模型评估所需的独立同分布（i.i.d.）假设。\n- **定义**：\n    - **原始样本身份**：原始数据样本的组标识符。\n    - **增强孪生样本**：源自同一原始身份的样本。\n    - **结构良好的划分**：一种划分方式，其中给定身份的所有增强孪生样本都位于同一个分区（训练集、验证集或测试集）内。\n    - **泄露事件**：来自同一身份的增强孪生样本出现在不同子集中的情况。\n- **增强过程**：\n    - 增强样本 $x'$ 是从基础特征向量 $x \\in \\mathbb{R}^d$ 通过公式 $x' = (1 + a) \\cdot x + \\epsilon$ 生成的。\n    - 基础向量 $x$被归一化为单位长度。\n    - $a$ 从均匀分布 $U[-0.01, 0.01]$ 中抽取。\n    - $\\epsilon$ 是一个噪声向量，从标准差为 $\\sigma$ 的零均值各向同性高斯分布中抽取，即 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_d)$。\n    - 最终的增强向量 $x'$ 也被归一化为单位长度。\n- **近似副本检测**：\n    - 如果两个样本 $u, v$ 的余弦相似度 $\\mathrm{cos}(u,v) = \\frac{u^\\top v}{\\lVert u \\rVert_2 \\lVert v \\rVert_2}$ 严格大于阈值 $\\theta$，则它们是近似副本。由于所有向量都被归一化为单位长度，这简化为 $u^\\top v > \\theta$。\n- **流水线实现**：\n    - **朴素流水线**：生成所有增强样本，然后随机打乱并根据比例 $(r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}})$ 将整个增强样本集划分为训练/验证/测试集。划分大小为 $\\lfloor N r_{\\mathrm{train}} \\rfloor$、$\\lfloor N r_{\\mathrm{val}} \\rfloor$ 以及剩余部分用于测试，其中 $N$ 是增强样本的总数。\n    - **修正流水线**：随机打乱并划分基础身份集到训练/验证/测试身份集。然后，在每个身份被分配到的子集内为其生成增强样本。\n- **待计算指标**：\n    - **组泄露计数 ($G$)**：其增强样本出现在至少两个不同子集中的基础身份的数量。\n    - **跨子集近似副本对计数 ($P$)**：样本对 $(u, v)$ 的数量，其中 $u$ 和 $v$ 位于不同的子集且 $\\mathrm{cos}(u,v) > \\theta$。该计数在训练-验证、训练-测试和验证-测试对之间求和。\n- **测试套件**：提供了四个案例，每个案例都带有参数 $(n_{\\mathrm{base}}, k, d, r_{\\mathrm{train}}, r_{\\mathrm{val}}, r_{\\mathrm{test}}, \\sigma, \\theta, \\text{seed})$。\n    - 案例 1: $(50, 3, 128, 0.7, 0.15, 0.15, 0.01, 0.99, 42)$\n    - 案例 2: $(40, 1, 128, 0.6, 0.2, 0.2, 0.01, 0.99, 123)$\n    - 案例 3: $(30, 10, 128, 0.6, 0.2, 0.2, 0.01, 0.99, 7)$\n    - 案例 4: $(7, 4, 128, 0.8, 0.01, 0.19, 0.01, 0.99, 2023)$\n- **输出**：对于每个案例，需要六个整数值：$I_{\\mathrm{naive}} = (G_{\\mathrm{naive}} > 0)$、$I_{\\mathrm{corr}} = (G_{\\mathrm{corr}} > 0)$、$G_{\\mathrm{naive}}$、$G_{\\mathrm{corr}}$、$P_{\\mathrm{naive}}$、$P_{\\mathrm{corr}}$。最终输出必须是这些整数的单个展平列表。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n该问题在科学和数学上是合理的。它解决了一个应用机器学习中的现实世界关键问题，即预处理过程中的数据泄露。关于增强、划分以及泄露指标（$G$ 和 $P$）的定义是精确且可形式化的。为每个测试用例使用确定性的随机种子确保了问题是适定的，并拥有唯一、可验证的解。每个测试用例都提供了所有必要的参数。问题没有歧义、主观性或事实错误。\n\n**步骤 3：结论与行动**\n\n问题陈述是**有效的**。我将继续构建解决方案。\n\n### 算法设计与原则\n\n解决方案需要确定性地实现数据生成、两种不同的数据划分流水线以及两种泄露指标。问题的核心是展示样本级划分与组级划分之间的结构差异，并量化由此产生的数据泄露。\n\n**1. 确定性数据生成**\n\n对于每个测试用例，将使用提供的 `seed` 为随机数生成器设置种子。这确保了可复现性。\n-   **基础样本**：对于 $n_{\\mathrm{base}}$ 个身份中的每一个，从标准正态分布 $\\mathcal{N}(0, I_d)$ 中抽取一个基础向量 $x \\in \\mathbb{R}^d$。然后将该向量归一化，使其欧几里得范数为 $1$，即 $x \\leftarrow x / \\lVert x \\rVert_2$。\n-   **增强样本**：对于每个基础样本 $x$，创建 $k$ 个增强样本。对于每次增强 $x'$，从 $U[-0.01, 0.01]$ 中抽取一个乘性抖动项 $a$，并从 $\\mathcal{N}(0, \\sigma^2 I_d)$ 中抽取一个加性噪声向量 $\\epsilon$。增强向量计算为 $x' = (1+a)x + \\epsilon$。关键的是，$x'$ 也被归一化为单位长度，$x' \\leftarrow x' / \\lVert x' \\rVert_2$。这种归一化将余弦相似度的计算简化为简单的点积，因为对于单位向量 $u$ 和 $v$，有 $\\mathrm{cos}(u,v) = u^\\top v$。\n\n**2. 朴素流水线：先增强后划分**\n\n此流水线模仿了在划分数据集之前应用增强的错误但常见的做法。\n-   首先，生成总共 $N = n_{\\mathrm{base}} \\times k$ 个增强样本并存储它们，同时记录它们对应的原始基础身份索引（从 $0$ 到 $n_{\\text{base}}-1$）。\n-   然后，这 $N$ 个样本的集合被随机打乱。\n-   打乱后的集合被分区。训练样本的数量为 $N_{\\mathrm{train}} = \\lfloor N \\cdot r_{\\mathrm{train}} \\rfloor$。验证样本的数量为 $N_{\\mathrm{val}} = \\lfloor N \\cdot r_{\\mathrm{val}} \\rfloor$。测试集包含剩余的 $N_{\\mathrm{test}} = N - N_{\\mathrm{train}} - N_{\\mathrm{val}}$ 个样本。\n-   这种随机的、样本级别的分配很可能会将同一原始样本的增强孪生样本分布到不同的子集中，从而导致泄露。\n\n**3. 修正流水线：先划分后增强**\n\n此流水线遵循正确的程序以防止因增强而导致的泄漏。\n-   首先，随机打乱 $n_{\\mathrm{base}}$ 个*基础身份*的集合。\n-   使用相同的比例逻辑将这些身份划分为训练、验证和测试集。训练身份的数量为 $n_{\\mathrm{train}} = \\lfloor n_{\\mathrm{base}} \\cdot r_{\\mathrm{train}} \\rfloor$，验证身份为 $n_{\\mathrm{val}} = \\lfloor n_{\\mathrm{base}} \\cdot r_{\\mathrm{val}} \\rfloor$，测试身份为 $n_{\\mathrm{test}} = n_{\\mathrm{base}} - n_{\\mathrm{train}} - n_{\\mathrm{val}}$。\n-   在身份被分配到子集后，增强过程在每个子集*内部*执行。对于训练身份集中的每个身份，为其生成 $k$ 个增强样本并添加到训练数据中。对验证和测试身份集执行相同的操作。\n-   通过这种构造，可以保证单个原始样本的所有增强版本都在同一个子集中。\n\n**4. 泄露指标计算**\n\n对于每个流水线产生的划分，我们计算两个指标：\n-   **组泄露计数 ($G$)**：我们遍历从 $0$ 到 $n_{\\mathrm{base}}-1$ 的每个基础身份。对于每个身份，我们查找其增强后代出现在哪些子集中。如果唯一子集的数量大于 $1$，我们增加 $G$。对于修正流水线，$G$ 将确定性地为 $0$。\n-   **近似副本对计数 ($P$)**：我们必须计算跨不同子集的、余弦相似度大于 $\\theta$ 的样本对数量。这通过计算两两子集数据矩阵之间的完整点积矩阵来完成。对于数据为 $X_1 \\in \\mathbb{R}^{N_1 \\times d}$ 和 $X_2 \\in \\mathbb{R}^{N_2 \\times d}$ 的子集，相似度矩阵为 $S = X_1 X_2^\\top \\in \\mathbb{R}^{N_1 \\times N_2}$。相似度大于 $\\theta$ 的对数是 $S$ 中大于 $\\theta$ 的元素数量。这个计数在训练-验证、训练-测试和验证-测试对上求和。\n\n每个测试用例的最终输出包括六个整数：$(G_{\\mathrm{naive}} > 0)$, $(G_{\\mathrm{corr}} > 0)$, $G_{\\mathrm{naive}}$, $G_{\\mathrm{corr}}$, $P_{\\mathrm{naive}}$, 和 $P_{\\mathrm{corr}}$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        # (n_base, k, d, r_train, r_val, r_test, sigma, theta, seed)\n        (50, 3, 128, 0.7, 0.15, 0.15, 0.01, 0.99, 42),\n        (40, 1, 128, 0.6, 0.2, 0.2, 0.01, 0.99, 123),\n        (30, 10, 128, 0.6, 0.2, 0.2, 0.01, 0.99, 7),\n        (7, 4, 128, 0.8, 0.01, 0.19, 0.01, 0.99, 2023),\n    ]\n\n    all_results = []\n    for params in test_cases:\n        n_base, k, d, r_train, r_val, r_test, sigma, theta, seed = params\n        rng = np.random.default_rng(seed)\n\n        # 1. Generate base data\n        base_vectors = rng.standard_normal(size=(n_base, d))\n        base_vectors /= np.linalg.norm(base_vectors, axis=1, keepdims=True)\n\n        # 2. Run both pipelines and compute metrics\n        g_naive, p_naive = run_naive_pipeline(\n            base_vectors, k, d, r_train, r_val, sigma, theta, rng\n        )\n        g_corr, p_corr = run_corrected_pipeline(\n            base_vectors, k, d, r_train, r_val, sigma, theta, rng\n        )\n        \n        i_naive = 1 if g_naive  0 else 0\n        i_corr = 1 if g_corr  0 else 0\n\n        all_results.extend([i_naive, i_corr, g_naive, g_corr, p_naive, p_corr])\n\n    print(f\"[{','.join(map(str, all_results))}]\")\n\ndef generate_augmentations(base_vector, k, d, sigma, rng):\n    \"\"\"Generates k augmentations for a single base vector.\"\"\"\n    if k == 0:\n        return np.empty((0, d)), np.array([])\n    \n    a_jitter = rng.uniform(-0.01, 0.01, size=k)\n    noise = rng.normal(0, sigma, size=(k, d))\n    \n    # Broadcasting base_vector and a_jitter\n    augmented_vectors = (1 + a_jitter)[:, np.newaxis] * base_vector + noise\n    \n    norms = np.linalg.norm(augmented_vectors, axis=1, keepdims=True)\n    # Avoid division by zero, although highly unlikely\n    safe_norms = np.where(norms == 0, 1e-9, norms)\n    augmented_vectors /= safe_norms\n    \n    return augmented_vectors\n\ndef compute_metrics(splits_data, splits_ids, n_base, theta):\n    \"\"\"Computes group leakage (G) and near-duplicate pairs (P).\"\"\"\n    # Compute Group Leakage (G)\n    group_split_map = {i: set() for i in range(n_base)}\n    for split_name, ids in splits_ids.items():\n        for group_id in ids:\n            group_split_map[group_id].add(split_name)\n    \n    g_leakage = sum(1 for splits in group_split_map.values() if len(splits)  1)\n\n    # Compute Near-Duplicate Pairs (P)\n    p_pairs = 0\n    split_names = list(splits_data.keys())\n    \n    for i in range(len(split_names)):\n        for j in range(i + 1, len(split_names)):\n            name1, name2 = split_names[i], split_names[j]\n            data1, data2 = splits_data[name1], splits_data[name2]\n            \n            if data1.shape[0] == 0 or data2.shape[0] == 0:\n                continue\n\n            similarity_matrix = data1 @ data2.T\n            p_pairs += np.sum(similarity_matrix  theta)\n            \n    return g_leakage, p_pairs\n\ndef run_naive_pipeline(base_vectors, k, d, r_train, r_val, sigma, theta, rng):\n    \"\"\"Implements the naive augment-then-split pipeline.\"\"\"\n    n_base = base_vectors.shape[0]\n    total_samples = n_base * k\n\n    if total_samples == 0:\n        return 0, 0\n        \n    all_augmented_data = np.empty((total_samples, d))\n    all_group_ids = np.empty(total_samples, dtype=int)\n\n    for i in range(n_base):\n        start_idx = i * k\n        end_idx = (i + 1) * k\n        all_augmented_data[start_idx:end_idx] = generate_augmentations(base_vectors[i], k, d, sigma, rng)\n        all_group_ids[start_idx:end_idx] = i\n\n    indices = rng.permutation(total_samples)\n    shuffled_data = all_augmented_data[indices]\n    shuffled_ids = all_group_ids[indices]\n\n    train_size = int(np.floor(total_samples * r_train))\n    val_size = int(np.floor(total_samples * r_val))\n\n    train_data = shuffled_data[0:train_size]\n    train_ids = shuffled_ids[0:train_size]\n\n    val_data = shuffled_data[train_size : train_size + val_size]\n    val_ids = shuffled_ids[train_size : train_size + val_size]\n\n    test_data = shuffled_data[train_size + val_size:]\n    test_ids = shuffled_ids[train_size + val_size:]\n\n    splits_data = {'train': train_data, 'val': val_data, 'test': test_data}\n    splits_ids = {'train': train_ids, 'val': val_ids, 'test': test_ids}\n    \n    return compute_metrics(splits_data, splits_ids, n_base, theta)\n\n\ndef run_corrected_pipeline(base_vectors, k, d, r_train, r_val, sigma, theta, rng):\n    \"\"\"Implements the corrected split-then-augment pipeline.\"\"\"\n    n_base = base_vectors.shape[0]\n    \n    if n_base == 0:\n        return 0, 0\n\n    identity_indices = rng.permutation(n_base)\n    \n    train_id_size = int(np.floor(n_base * r_train))\n    val_id_size = int(np.floor(n_base * r_val))\n\n    train_ids = identity_indices[0:train_id_size]\n    val_ids = identity_indices[train_id_size : train_id_size + val_id_size]\n    test_ids = identity_indices[train_id_size + val_id_size:]\n\n    train_data = np.vstack([generate_augmentations(base_vectors[i], k, d, sigma, rng) for i in train_ids]) if len(train_ids)  0 else np.empty((0, d))\n    val_data = np.vstack([generate_augmentations(base_vectors[i], k, d, sigma, rng) for i in val_ids]) if len(val_ids)  0 else np.empty((0, d))\n    test_data = np.vstack([generate_augmentations(base_vectors[i], k, d, sigma, rng) for i in test_ids]) if len(test_ids)  0 else np.empty((0, d))\n    \n    train_group_ids = np.repeat(train_ids, k)\n    val_group_ids = np.repeat(val_ids, k)\n    test_group_ids = np.repeat(test_ids, k)\n    \n    splits_data = {'train': train_data, 'val': val_data, 'test': test_data}\n    splits_ids = {'train': train_group_ids, 'val': val_group_ids, 'test': test_group_ids}\n\n    # By construction, G must be 0, but we compute it for verification.\n    return compute_metrics(splits_data, splits_ids, n_base, theta)\n\nsolve()\n```", "id": "3194804"}, {"introduction": "有了正确划分的数据集，我们现在可以自信地进行超参数调整和模型评估。这个练习 [@problem_id:3200874] 将引导您完成一个典型的机器学习工作流程：使用验证集为异常检测器找到最佳决策阈值。这个过程不仅会巩固您对 $F_1$ 分数等指标的理解，还将揭示一个关键的洞见——为什么在验证集上的表现可能过于乐观，并不能完全代表模型在真实未见测试数据上的性能。", "problem": "给定一个二元异常检测场景，其中包含三个不相交的数据集：训练集 $\\mathcal{D}_{\\text{train}}$、验证集 $\\mathcal{D}_{\\text{val}}$ 和测试集 $\\mathcal{D}_{\\text{test}}$。每个数据集都包含实值异常分数和真实的二元标签，其中标签 $0$ 表示正常实例，标签 $1$ 表示异常实例。您必须使用的基本依据由以下广泛接受的定义和规则组成。首先，仅使用训练集的统计数据通过标准化来归一化分数：对于任何分数 $x$，将标准化分数 $z$ 定义为\n$$\nz = \\frac{x - \\mu_{\\text{train}}}{\\sigma_{\\text{train}}},\n$$\n其中 $\\mu_{\\text{train}}$ 是 $\\mathcal{D}_{\\text{train}}$ 中分数的均值，$\\sigma_{\\text{train}}$ 是 $\\mathcal{D}_{\\text{train}}$ 中分数的标准差。其次，采用由阈值 $\\tau$ 参数化的决策规则：如果 $z \\ge \\tau$ 则预测为异常，否则预测为正常。第三，对于任何固定的 $\\tau$，在一个带标签的数据集上定义混淆矩阵计数为真正例 (TP)、假正例 (FP)、假负例 (FN) 和真负例 (TN)。根据这些计数，定义精确率 $P$ 和召回率 $R$ 为\n$$\nP = \\frac{TP}{TP+FP} \\quad \\text{if } TP+FP0, \\text{ else } P = 0, \\qquad\nR = \\frac{TP}{TP+FN} \\quad \\text{if } TP+FN0, \\text{ else } R = 0.\n$$\n那么 $F_1$ 分数为\n$$\nF_1 = \\begin{cases}\n\\frac{2PR}{P+R},  \\text{if } P+R0,\\\\\n0,  \\text{otherwise.}\n\\end{cases}\n$$\n您的任务是按如下方式研究在验证集上进行阈值选择以用于异常检测。对于每个测试用例，从 $\\mathcal{D}_{\\text{train}}$ 计算 $\\mu_{\\text{train}}$ 和 $\\sigma_{\\text{train}}$，相应地对 $\\mathcal{D}_{\\text{val}}$ 和 $\\mathcal{D}_{\\text{test}}$ 进行标准化，在一组候选阈值上变动决策阈值 $\\tau$（该组候选阈值由所有不同的标准化验证分数以及 $-\\infty$ 和 $+\\infty$ 组成），并选择在 $\\mathcal{D}_{\\text{val}}$ 上最大化 $F_1$ 分数的阈值 $\\tau^\\star$。如果出现平局（多个 $\\tau$ 达到相同的最大 $F_1$ 分数），则选择其中最大的 $\\tau$。最后，在 $\\tau^\\star$ 处评估 $\\mathcal{D}_{\\text{test}}$ 上的 $F_1$ 分数，并报告其差值\n$$\ng = F_1(\\mathcal{D}_{\\text{val}};\\tau^\\star) - F_1(\\mathcal{D}_{\\text{test}};\\tau^\\star).\n$$\n这个量 $g$ 是基于验证集的对测试性能的高估值，以小数形式表示。\n\n测试套件规范：\n对于每个用例，训练分数假定为仅包含正常样本。以下所有数字均为实值，必须按其书面形式精确解释。\n\n用例 1（分布偏移导致高估）：\n- $\\mathcal{D}_{\\text{train}}$ 分数：$[\\,0.9,\\,1.0,\\,1.1,\\,1.0,\\,0.95,\\,1.05\\,]$\n- $\\mathcal{D}_{\\text{val}}$ 原始分数：$[\\,0.7,\\,0.85,\\,0.95,\\,1.2,\\,2.0,\\,2.1,\\,1.9,\\,0.8\\,]$，标签：$[\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,1,\\,0\\,]$\n- $\\mathcal{D}_{\\text{test}}$ 原始分数：$[\\,0.9,\\,0.98,\\,1.3,\\,1.4,\\,1.5,\\,1.6,\\,1.7,\\,1.8\\,]$，标签：$[\\,0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,1,\\,1\\,]$\n\n用例 2（小验证集导致过拟合）：\n- $\\mathcal{D}_{\\text{train}}$ 分数：$[\\,0.0,\\,0.1,\\,-0.1,\\,0.15,\\,-0.05\\,]$\n- $\\mathcal{D}_{\\text{val}}$ 原始分数：$[\\,0.0,\\,0.05,\\,-0.05,\\,0.9\\,]$，标签：$[\\,0,\\,0,\\,0,\\,1\\,]$\n- $\\mathcal{D}_{\\text{test}}$ 原始分数：$[\\,0.0,\\,0.1,\\,0.2,\\,-0.1,\\,0.3,\\,0.4,\\,0.85,\\,0.75\\,]$，标签：$[\\,0,\\,0,\\,0,\\,0,\\,0,\\,0,\\,1,\\,1\\,]$\n\n用例 3（验证集中无异常的边界情况）：\n- $\\mathcal{D}_{\\text{train}}$ 分数：$[\\,5.0,\\,5.2,\\,4.8,\\,5.1,\\,4.9\\,]$\n- $\\mathcal{D}_{\\text{val}}$ 原始分数：$[\\,5.0,\\,5.1,\\,5.2,\\,5.3\\,]$，标签：$[\\,0,\\,0,\\,0,\\,0\\,]$\n- $\\mathcal{D}_{\\text{test}}$ 原始分数：$[\\,5.0,\\,5.1,\\,5.2,\\,5.5,\\,6.0,\\,6.5\\,]$，标签：$[\\,0,\\,0,\\,0,\\,1,\\,1,\\,1\\,]$\n\n实现要求：\n- 对于每个用例，完全按照上述规定计算 $g$，仅使用基于 $\\mathcal{D}_{\\text{train}}$ 统计数据的标准化分数。\n- 将每个 $g$ 表示为四舍五入到 $4$ 位小数的小数。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，例如 $[\\,g_1, g_2, g_3\\,]$，每个 $g$ 格式化为 $4$ 位小数，且不含任何附加文本。", "solution": "该问题要求我们计算模型在验证集上的性能与在测试集上的性能之间的性能差距，记为 $g$。这是机器学习中评估模型过拟合和超参数调整过程泛化能力的一项标准流程。具体任务涉及一个简单的基于阈值的异常检测器。求解方法是确定性的，包含几个步骤，下文将详细介绍。\n\n首先，对各组成指标进行严格定义至关重要。问题陈述，对于一个具有异常分数 $z$ 和真实二元标签 $y \\in \\{0, 1\\}$（其中 $1$ 表示异常）的数据集，决策规则是对于给定的阈值 $\\tau$，如果 $z \\ge \\tau$ 则预测为异常。这将数据集划分为四类：\n- 真正例 ($TP$)：$z \\ge \\tau$ 且 $y=1$ 的实例。\n- 假正例 ($FP$)：$z \\ge \\tau$ 且 $y=0$ 的实例。\n- 假负例 ($FN$)：$z  \\tau$ 且 $y=1$ 的实例。\n- 真负例 ($TN$)：$z  \\tau$ 且 $y=0$ 的实例。\n\n根据这些计数，我们定义精确率 ($P$) 和召回率 ($R$)：\n$$\nP = \\begin{cases} \\frac{TP}{TP+FP}  \\text{if } TP+FP > 0 \\\\ 0  \\text{if } TP+FP = 0 \\end{cases}\n$$\n$$\nR = \\begin{cases} \\frac{TP}{TP+FN}  \\text{if } TP+FN > 0 \\\\ 0  \\text{if } TP+FN = 0 \\end{cases}\n$$\n$F_1$ 分数，即精确率和召回率的调和平均数，定义如下：\n$$\nF_1 = \\begin{cases} \\frac{2PR}{P+R}  \\text{if } P+R > 0 \\\\ 0  \\text{if } P+R = 0 \\end{cases}\n$$\n\n整体算法流程如下：\n\n1.  **数据标准化**：第一步是为异常分数建立一个通用尺度。我们计算训练集 $\\mathcal{D}_{\\text{train}}$ 中分数的均值 $\\mu_{\\text{train}}$ 和总体标准差 $\\sigma_{\\text{train}}$。问题指定 $\\mathcal{D}_{\\text{train}}$ 只包含正常样本，这是训练某些类型异常检测器的常见做法。然后，使用训练统计数据将验证集 $\\mathcal{D}_{\\text{val}}$ 和测试集 $\\mathcal{D}_{\\text{test}}$ 中的每个原始分数 $x$ 转换为标准化分数 $z$：\n    $$\n    z = \\frac{x - \\mu_{\\text{train}}}{\\sigma_{\\text{train}}}\n    $$\n    这一转换至关重要，因为它*仅*使用来自训练数据的信息，以防止验证集或测试集的信息泄漏到特征工程过程中。\n\n2.  **在验证集上优化阈值**：决策阈值 $\\tau$ 是一个超参数。我们通过在标准化的验证集 $\\mathcal{D}_{\\text{val}}$ 上评估 $F_1$ 分数来对其进行优化。候选阈值集合 $\\mathcal{T}$ 由 $\\mathcal{D}_{\\text{val}}$ 中所有不同的标准化分数，并增补上 $-\\infty$ 和 $+\\infty$ 构成。对于每个 $\\tau \\in \\mathcal{T}$，我们计算相应的 $F_1$ 分数。最优阈值 $\\tau^\\star$ 是使该 $F_1$ 分数最大化的阈值。如果多个阈值产生相同的最大 $F_1$ 分数，问题指定了一个平局决胜规则：在竞争者中选择最大的 $\\tau$ 值。这会产生一个唯一的 $\\tau^\\star$。在验证集上实现的最大 $F_1$ 分数记为 $F_1(\\mathcal{D}_{\\text{val}};\\tau^\\star)$。\n\n3.  **在测试集上评估性能**：所选阈值 $\\tau^\\star$ 的泛化性能在未见过的测试集 $\\mathcal{D}_{\\text{test}}$ 上进行评估。我们将决策规则 $z_{\\text{test}} \\ge \\tau^\\star$ 应用于标准化的测试分数，并计算得出的 $F_1$ 分数，记为 $F_1(\\mathcal{D}_{\\text{test}};\\tau^\\star)$。\n\n4.  **差距计算**：最后，问题要求计算验证集 F1 分数和测试集 F1 分数之间的差值 $g$：\n    $$\n    g = F_1(\\mathcal{D}_{\\text{val}};\\tau^\\star) - F_1(\\mathcal{D}_{\\text{test}};\\tau^\\star)\n    $$\n    这个值 $g$ 量化了基于验证集的性能估计的乐观程度。一个大的正值表明模型和超参数的选择对验证集过拟合了。\n\n让我们将此过程应用于**用例 1**：\n\n- $\\mathcal{D}_{\\text{train}}$ 分数：$[\\,0.9,\\,1.0,\\,1.1,\\,1.0,\\,0.95,\\,1.05\\,]$\n- $\\mu_{\\text{train}} = 1.0$\n- $\\sigma_{\\text{train}} = \\sqrt{\\frac{1}{6}\\sum(x_i - \\mu_{\\text{train}})^2} \\approx 0.06455$\n\n- 对 $\\mathcal{D}_{\\text{val}}$ 分数进行标准化：$X_{\\text{val}} = [\\,0.7, \\dots, 0.8\\,]$, $Y_{\\text{val}} = [\\,0, \\dots, 0\\,]$\n  标准化后的分数为 $Z_{\\text{val}} \\approx [\\, -4.648, -2.324, -0.775, 3.098, 15.492, 17.041, 13.943, -3.098 \\,]$。\n  相应的标签是 $[\\,0, 0, 0, 0, 1, 1, 1, 0\\,]$。在 $\\mathcal{D}_{\\text{val}}$ 中，有 $3$ 个异常实例和 $5$ 个正常实例。\n\n- 候选阈值集合 $\\mathcal{T}$ 由 $Z_{\\text{val}}$ 中的 $8$ 个唯一值加上 $\\{-\\infty, +\\infty\\}$ 组成。我们遍历这 $10$ 个候选值。例如，如果我们选择 $\\tau$ 等于原始分数 $1.9$ 的标准化分数（即 $z(1.9) \\approx 13.943$），任何分数大于或等于此值的实例都会被预测为异常。$\\mathcal{D}_{\\text{val}}$ 中分数 $z \\ge 13.943$ 的实例对应于原始分数 $1.9, 2.0, 2.1$。它们的真实标签都是 $1$。因此，对于这个 $\\tau$：\n  - $TP=3$, $FP=0$, $FN=0$, $TN=5$。\n  - $P = 3/(3+0)=1$。 $R = 3/(3+0)=1$。\n  - $F_1 = (2 \\cdot 1 \\cdot 1) / (1+1) = 1.0$。\n  完整的搜索显示这是可能的最大 $F_1$ 分数。根据平局规则，我们选择产生此分数的最大阈值。因此，$\\tau^\\star \\approx 13.943$ 且 $F_1(\\mathcal{D}_{\\text{val}};\\tau^\\star) = 1.0$。\n\n- 我们现在使用 $\\tau^\\star$ 在 $\\mathcal{D}_{\\text{test}}$ 上进行评估。$\\mathcal{D}_{\\text{test}}$ 的标准化分数范围大约从 $-1.549$ 到 $12.394$。这些分数中没有一个大于或等于 $\\tau^\\star \\approx 13.943$。因此，所有测试实例都被分类为正常。\n  - $Y_{\\text{test}}$ 包含 $3$ 个异常实例和 $5$ 个正常实例。\n  - 预测结果全为正常，所以 $TP=0$ 且 $FP=0$。这意味着 $FN=3$ 且 $TN=5$。\n  - $P = 0/(0+0)=0$。 $R = 0/(0+3)=0$。\n  - $F_1(\\mathcal{D}_{\\text{test}};\\tau^\\star) = 0$。\n\n- 差距为 $g_1 = 1.0 - 0.0 = 1.0$。\n\n对于其他用例，遵循类似的过程。值得注意的是，在**用例 3** 中，验证集 $\\mathcal{D}_{\\text{val}}$ 不包含任何异常（$TP+FN=0$）。根据定义，这意味着对于任何 $\\tau$ 的选择，$R=0$，这又反过来迫使 $F_1=0$。最大 $F_1$ 分数为 $0$，所有候选阈值都能达到这个分数。平局决胜规则（“选择最大的 $\\tau$”）规定我们必须选择 $\\tau^\\star = +\\infty$。这个阈值应用于测试集时，同样得出 $F_1$ 分数为 $0$，使得差距 $g_3=0$。\n\n实现将为每个提供的用例系统地执行这些步骤。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all test cases.\n    It orchestrates the calculation of the performance gap 'g' for each case\n    and prints the final results in the specified format.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"train_scores\": [0.9, 1.0, 1.1, 1.0, 0.95, 1.05],\n            \"val_data\": (\n                [0.7, 0.85, 0.95, 1.2, 2.0, 2.1, 1.9, 0.8],\n                [0, 0, 0, 0, 1, 1, 1, 0]\n            ),\n            \"test_data\": (\n                [0.9, 0.98, 1.3, 1.4, 1.5, 1.6, 1.7, 1.8],\n                [0, 0, 0, 0, 0, 1, 1, 1]\n            )\n        },\n        {\n            \"train_scores\": [0.0, 0.1, -0.1, 0.15, -0.05],\n            \"val_data\": (\n                [0.0, 0.05, -0.05, 0.9],\n                [0, 0, 0, 1]\n            ),\n            \"test_data\": (\n                [0.0, 0.1, 0.2, -0.1, 0.3, 0.4, 0.85, 0.75],\n                [0, 0, 0, 0, 0, 0, 1, 1]\n            )\n        },\n        {\n            \"train_scores\": [5.0, 5.2, 4.8, 5.1, 4.9],\n            \"val_data\": (\n                [5.0, 5.1, 5.2, 5.3],\n                [0, 0, 0, 0]\n            ),\n            \"test_data\": (\n                [5.0, 5.1, 5.2, 5.5, 6.0, 6.5],\n                [0, 0, 0, 1, 1, 1]\n            )\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        g = process_case(case[\"train_scores\"], case[\"val_data\"], case[\"test_data\"])\n        results.append(f\"{g:.4f}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef calculate_f1(scores_z, labels, tau):\n    \"\"\"\n    Calculates the F1 score for a given dataset and threshold.\n    \n    Args:\n        scores_z (np.array): Standardized anomaly scores.\n        labels (np.array): Ground-truth binary labels (0=normal, 1=anomaly).\n        tau (float): The decision threshold.\n\n    Returns:\n        float: The calculated F1 score.\n    \"\"\"\n    predictions = (scores_z = tau).astype(int)\n    \n    tp = np.sum((predictions == 1)  (labels == 1))\n    fp = np.sum((predictions == 1)  (labels == 0))\n    fn = np.sum((predictions == 0)  (labels == 1))\n    \n    p_denom = tp + fp\n    r_denom = tp + fn\n    \n    p = tp / p_denom if p_denom  0 else 0.0\n    r = tp / r_denom if r_denom  0 else 0.0\n    \n    f1_denom = p + r\n    f1 = (2 * p * r) / f1_denom if f1_denom  0 else 0.0\n    \n    return f1\n\ndef process_case(train_scores, val_data, test_data):\n    \"\"\"\n    Processes a single test case to compute the performance gap 'g'.\n    \n    Args:\n        train_scores (list): Scores from the training set.\n        val_data (tuple): A tuple of (scores, labels) for the validation set.\n        test_data (tuple): A tuple of (scores, labels) for the test set.\n\n    Returns:\n        float: The performance gap g.\n    \"\"\"\n    train_scores_np = np.array(train_scores, dtype=np.float64)\n    mu_train = np.mean(train_scores_np)\n    sigma_train = np.std(train_scores_np)\n\n    def standardize(scores, mu, sigma):\n        if sigma == 0:\n            # Handle the case where all training scores are identical.\n            # Scores equal to mu get z=0, others +/- inf.\n            scores_np = np.array(scores, dtype=np.float64)\n            z = np.zeros_like(scores_np)\n            z[scores_np  mu] = np.inf\n            z[scores_np  mu] = -np.inf\n            return z\n        return (np.array(scores, dtype=np.float64) - mu) / sigma\n\n    val_scores_raw, val_labels_raw = val_data\n    val_scores_z = standardize(val_scores_raw, mu_train, sigma_train)\n    val_labels = np.array(val_labels_raw)\n\n    test_scores_raw, test_labels_raw = test_data\n    test_scores_z = standardize(test_scores_raw, mu_train, sigma_train)\n    test_labels = np.array(test_labels_raw)\n\n    # Identify candidate thresholds\n    candidate_taus = np.unique(val_scores_z)\n    candidate_taus = np.concatenate((candidate_taus, [-np.inf, np.inf]))\n    \n    # Find the best threshold on the validation set\n    f1_tau_pairs = []\n    for tau in candidate_taus:\n        f1 = calculate_f1(val_scores_z, val_labels, tau)\n        f1_tau_pairs.append((f1, tau))\n    \n    # Sort by F1 (desc) and then tau (desc) to apply tie-breaking rule\n    f1_tau_pairs.sort(key=lambda x: (x[0], x[1]), reverse=True)\n    \n    best_f1_val, tau_star = f1_tau_pairs[0]\n    \n    # Evaluate on the test set with the chosen threshold\n    f1_test = calculate_f1(test_scores_z, test_labels, tau_star)\n    \n    # Compute the gap\n    g = best_f1_val - f1_test\n    \n    return g\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3200874"}, {"introduction": "除了调整静态超参数，验证集在训练过程中的动态决策（例如决定何时停止训练）中也至关重要。这个练习 [@problem_id:3200888] 将提前停止的挑战构建为一个信号处理问题，其中真实的学习趋势被验证损失中的随机噪声所掩盖。您将应用指数移动平均（EMA）滤波器对这个信号进行去噪，从而更稳定、更可靠地判断出最佳的训练时长。", "problem": "本题提供模型开发中训练集、验证集和测试集的背景。训练集用于拟合参数，验证集用于选择超参数和决定何时停止训练，而测试集则保留用于无偏的最终评估。早停是一种模型选择策略，它在验证损失不再改善时便停止训练，从而减少过拟合。本题将验证损失形式化为一个带噪声的信号，并要求您使用低通滤波器来稳定早停决策。\n\n假设在轮次 $t$ 的验证损失被建模为一个离散时间信号\n$$\nL_{\\text{val}}(t) = \\mu(t) + \\epsilon_t,\n$$\n其中 $t \\in \\{0,1,\\dots,T-1\\}$，$\\mu(t)$ 是一个确定性趋势，捕捉了模型的潜在泛化行为，而 $\\epsilon_t$ 是均值为零、方差为 $\\sigma^2$ 的独立同分布 (IID) 噪声。考虑一个以指数移动平均 (EMA) 实现的一阶无限脉冲响应 (IIR) 低通滤波器，其平滑参数为 $\\alpha \\in (0,1)$：\n$$\ns_0 = L_{\\text{val}}(0), \\quad s_t = \\alpha \\, L_{\\text{val}}(t) + (1-\\alpha)\\, s_{t-1} \\quad \\text{for } t \\ge 1.\n$$\n早停决策被定义为使信号最小化的轮次索引：朴素决策使用原始验证损失\n$$\nt_{\\text{naive}} = \\arg\\min_{t} L_{\\text{val}}(t),\n$$\n而稳定化决策使用滤波后的信号\n$$\nt_{\\text{filtered}} = \\arg\\min_{t} s_t.\n$$\n如果出现任何相同值，应通过选择最小的索引来解决。\n\n您的任务是实现一个程序，对于下方的每个测试用例，通过构建 $\\mu(t)$ 并添加具有指定种子（以确保可复现性）的高斯噪声来合成 $L_{\\text{val}}(t)$，然后应用 EMA 低通滤波器，并返回 $t_{\\text{naive}}$ 和 $t_{\\text{filtered}}$。\n\n为了符合科学真实性，将确定性趋势 $\\mu(t)$ 定义为一个在轮次 $t_0$ 处具有最小值的二次函数，这捕捉了验证损失典型的先减少后因过拟合而增加的行为：\n$$\n\\mu(t) = m_0 + k \\, (t - t_0)^2,\n$$\n参数 $m_0  0$ 且 $k  0$。\n\n实现以下测试套件。在所有用例中，$\\epsilon_t$ 必须使用给定的种子从高斯分布 $\\mathcal{N}(0,\\sigma^2)$ 中抽取。\n\n- 测试用例 1（一般情况）：\n    - $T = 50$, $m_0 = 0.5$, $k = 0.002$, $t_0 = 20$, $\\sigma = 0.05$, $\\alpha = 0.2$, $\\text{seed} = 42$。\n- 测试用例 2（高噪声压力测试）：\n    - $T = 50$, $m_0 = 0.5$, $k = 0.002$, $t_0 = 20$, $\\sigma = 0.3$, $\\alpha = 0.2$, $\\text{seed} = 7$。\n- 测试用例 3（平缓趋势，潜在平台期）：\n    - $T = 60$, $m_0 = 0.4$, $k = 0.0001$, $t_0 = 25$, $\\sigma = 0.1$, $\\alpha = 0.1$, $\\text{seed} = 2023$。\n- 测试用例 4（短序列，边界行为）：\n    - $T = 12$, $m_0 = 0.6$, $k = 0.003$, $t_0 = 6$, $\\sigma = 0.2$, $\\alpha = 0.3$, $\\text{seed} = 99$。\n\n您的程序必须：\n- 对于每个测试用例，生成 $t \\in \\{0,1,\\dots,T-1\\}$ 的 $\\mu(t)$ 和 $L_{\\text{val}}(t)$。\n- 使用指定的 $\\alpha$ 应用 EMA 低通滤波器以生成 $s_t$。\n- 使用上述定义计算 $t_{\\text{naive}}$ 和 $t_{\\text{filtered}}$，通过选择最小的索引来解决相同值问题。\n- 生成单行输出，其中包含所有测试用例的聚合结果，形式为方括号内包含的逗号分隔列表。每个测试用例应贡献一个形式为 $[t_{\\text{naive}},t_{\\text{filtered}}]$ 的数对。例如，最终输出应类似于 $[[a_1,b_1],[a_2,b_2],[a_3,b_3],[a_4,b_4]]$，其中每个 $a_i$ 和 $b_i$ 都是整数。\n\n不涉及物理单位或角度。所有输出均为整数。最终输出必须只有一行，并遵循上述格式。", "solution": "### 问题验证\n\n#### 第一步：提取已知条件\n该问题提供了以下数据、定义和条件：\n- **验证损失模型**：在轮次 $t$ 的验证损失由 $L_{\\text{val}}(t) = \\mu(t) + \\epsilon_t$ 给出，其中 $t \\in \\{0,1,\\dots,T-1\\}$。\n- **确定性趋势**：潜在趋势是一个二次函数 $\\mu(t) = m_0 + k \\, (t - t_0)^2$，其中 $m_0 > 0$ 且 $k > 0$。\n- **噪声分量**：$\\epsilon_t$ 表示来自零均值高斯分布 $\\mathcal{N}(0, \\sigma^2)$ 的独立同分布 (IID) 噪声。\n- **EMA 滤波器**：一个一阶无限脉冲响应 (IIR) 低通滤波器被定义为具有平滑参数 $\\alpha \\in (0,1)$ 的指数移动平均 (EMA)：\n  - $s_0 = L_{\\text{val}}(0)$\n  - $s_t = \\alpha \\, L_{\\text{val}}(t) + (1-\\alpha)\\, s_{t-1}$ 对于 $t \\ge 1$。\n- **停止准则**：\n  - 朴素决策：$t_{\\text{naive}} = \\arg\\min_{t} L_{\\text{val}}(t)$。\n  - 稳定化决策：$t_{\\text{filtered}} = \\arg\\min_{t} s_t$。\n- **相同值处理规则**：对于 $\\arg\\min$ 操作中的任何相同值，应选择最小的索引。\n- **测试用例**：\n  1. $T = 50$, $m_0 = 0.5$, $k = 0.002$, $t_0 = 20$, $\\sigma = 0.05$, $\\alpha = 0.2$, $\\text{seed} = 42$。\n  2. $T = 50$, $m_0 = 0.5$, $k = 0.002$, $t_0 = 20$, $\\sigma = 0.3$, $\\alpha = 0.2$, $\\text{seed} = 7$。\n  3. $T = 60$, $m_0 = 0.4$, $k = 0.0001$, $t_0 = 25$, $\\sigma = 0.1$, $\\alpha = 0.1$, $\\text{seed} = 2023$。\n  4. $T = 12$, $m_0 = 0.6$, $k = 0.003$, $t_0 = 6$, $\\sigma = 0.2$, $\\alpha = 0.3$, $\\text{seed} = 99$。\n- **输出格式**：包含数对列表的单行，例如 `[[a_1,b_1],[a_2,b_2],[a_3,b_3],[a_4,b_4]]`。\n\n#### 第二步：使用提取的已知条件进行验证\n根据验证标准对问题进行评估：\n- **科学依据**：该问题具有科学依据。它采用了机器学习中一个有效且常见的简化模型来模拟验证损失，其中一个潜在的 U 形趋势被随机噪声所破坏。使用 EMA 滤波器平滑信号以获得更稳定的最小值估计是信号处理和时间序列分析中的标准技术。\n- **适定性**：该问题是适定的。所有参数和函数都被明确定义。为随机数生成器提供种子确保了结果是确定性的和可验证的。相同值处理规则是明确的。每个测试用例都存在唯一、稳定的解。\n- **客观性**：该问题使用精确、客观的数学语言陈述，没有任何主观性或歧义。\n- **完整性和一致性**：该设置是完整且自洽的。提供了四个测试用例所需的全部参数，并且没有内部矛盾。\n\n#### 第三步：结论与行动\n该问题被判定为**有效**。将提供完整解答。\n\n### 基于原则的设计\n该问题的解决方案涉及模拟和分析一个时间序列信号，该信号模拟了机器学习模型在训练过程中的验证损失。其基本科学原理是将观测信号 $L_{\\text{val}}(t)$ 分解为一个潜在的确定性过程 $\\mu(t)$ 和一个随机噪声分量 $\\epsilon_t$。\n\n确定性趋势 $\\mu(t) = m_0 + k \\, (t - t_0)^2$ 被建模为抛物线。这是一个基于模型训练期间验证指标典型行为的刻意选择。随着模型学习可泛化的模式，损失最初会减少，在轮次 $t_0$ 达到最优点，随后由于模型开始对训练数据过拟合，其泛化能力下降，损失会增加。\n\n噪声 $\\epsilon_t$ 被建模为独立同分布的高斯噪声 $\\mathcal{N}(0, \\sigma^2)$，它代表了验证过程中的内在随机性和可变性，例如，由于小批量采样造成的。这种噪声掩盖了潜在趋势的真实最小值，使得对 $L_{\\text{val}}(t)$ 的最小值进行朴素搜索（即找到 $t_{\\text{naive}}$）变得不可靠。\n\n为了解决这个问题，本题引入了低通滤波器，这是一种用于降噪的标准信号处理工具。指定的指数移动平均 (EMA) 是一个一阶 IIR 滤波器，由递归关系 $s_t = \\alpha \\, L_{\\text{val}}(t) + (1-\\alpha)\\, s_{t-1}$ 定义。该滤波器通过对当前观测值和先前的平滑值进行加权平均来计算平滑信号 $s_t$。参数 $\\alpha$ 控制平滑程度：较小的 $\\alpha$ 会产生更平滑的信号，但也会引入更多的延迟。滤波器的功能是衰减与噪声相关的高频分量，从而产生一个更接近真实趋势 $\\mu(t)$ 的信号 $s_t$。\n\n基于此平滑信号的早停决策 $t_{\\text{filtered}} = \\arg\\min_{t} s_t$，与 $t_{\\text{naive}}$ 相比，预计是对最优停止轮次 $t_0$ 的一个更鲁棒和准确的估计，尤其是在噪声水平 $\\sigma$ 较高时。\n\n实现计划是这些原则到计算算法的直接转换：\n$1$. 对于每个测试用例，使用指定的种子初始化随机数生成器，以确保噪声信号是可复现的。\n$2$. 使用 `numpy` 库进行高效的向量化操作。时间向量 $t$、趋势 $\\mu(t)$ 和噪声 $\\epsilon_t$ 作为数组生成。最终的验证损失 $L_{\\text{val}}(t)$ 是它们的和。\n$3$. 通过一个实现其递归定义的循环来计算 EMA 滤波后的信号 $s_t$。\n$4$. 最小值的索引 $t_{\\text{naive}}$ 和 $t_{\\text{filtered}}$ 使用 `numpy.argmin` 函数找到，该函数计算效率高，并通过返回第一个最小值的索引来正确实现相同值处理规则。\n$5$. 将所有测试用例得到的整数对 $[t_{\\text{naive}}, t_{\\text{filtered}}]$ 收集起来，并格式化为问题陈述中指定的确切字符串格式。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Synthesizes validation loss signals, applies an EMA filter, and determines\n    naive and filtered early stopping epochs for a suite of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (T, m_0, k, t_0, sigma, alpha, seed)\n        (50, 0.5, 0.002, 20, 0.05, 0.2, 42),\n        (50, 0.5, 0.002, 20, 0.3, 0.2, 7),\n        (60, 0.4, 0.0001, 25, 0.1, 0.1, 2023),\n        (12, 0.6, 0.003, 6, 0.2, 0.3, 99),\n    ]\n\n    results = []\n    for case in test_cases:\n        T, m0, k, t0, sigma, alpha, seed = case\n        \n        # Initialize random number generator for reproducibility\n        rng = np.random.default_rng(seed)\n        \n        # 1. Synthesize the validation loss signal L_val(t)\n        t = np.arange(T)\n        mu_t = m0 + k * (t - t0)**2\n        epsilon_t = rng.normal(loc=0.0, scale=sigma, size=T)\n        L_val = mu_t + epsilon_t\n        \n        # 2. Apply the EMA low-pass filter to produce s_t\n        s_t = np.zeros(T)\n        s_t[0] = L_val[0]\n        for i in range(1, T):\n            s_t[i] = alpha * L_val[i] + (1 - alpha) * s_t[i-1]\n            \n        # 3. Compute t_naive and t_filtered\n        # np.argmin breaks ties by selecting the first occurrence (smallest index)\n        t_naive = np.argmin(L_val)\n        t_filtered = np.argmin(s_t)\n        \n        # Store the result pair as integers\n        results.append([int(t_naive), int(t_filtered)])\n\n    # Final print statement in the exact required format: [[a1,b1],[a2,b2],...]\n    # This formatting ensures no spaces are included, matching the visual example.\n    pair_strings = [f\"[{res[0]},{res[1]}]\" for res in results]\n    print(f\"[{','.join(pair_strings)}]\")\n\nsolve()\n\n```", "id": "3200888"}]}