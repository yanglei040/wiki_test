{"hands_on_practices": [{"introduction": "物理信息神经网络（PINN）的核心思想在于其独特的损失函数，它将控制方程的残差和边界条件结合在一起。本练习将指导您为经典的泊松方程构建这一复合损失函数，该方程描述了静电学和稳态热分布等现象。通过这个练习，您将掌握构建PINN损失函数的基础，这是将物理定律融入神经网络的关键一步。[@problem_id:2126324]", "problem": "一位研究人员正在构建一个物理信息神经网络 (PINN)，以寻找二维方形区域内静电势 $V(x,y)$ 的近似解。该电势的物理行为由泊松方程描述：\n$$\n\\nabla^2 V(x,y) = -f(x,y)\n$$\n其中 $f(x,y)$ 表示给定的电荷分布密度，而 $\\nabla^2 = \\frac{\\partial^2}{\\partial x^2} + \\frac{\\partial^2}{\\partial y^2}$ 是拉普拉斯算子。该电势定义在域 $D = \\{(x,y) \\mid -L \\le x \\le L, -L \\le y \\le L\\}$ 上。该域的边界 $\\partial D$ 保持在零电势（接地），这施加了边界条件 $V(x,y) = 0$ 对所有 $(x,y) \\in \\partial D$ 成立。\n\nPINN 模型，记为 $\\hat{V}(x,y; \\theta)$，通过最小化一个包含了问题物理原理的损失函数 $L(\\theta)$ 来学习近似 $V(x,y)$。在此，$\\theta$ 表示神经网络的所有可训练参数。损失函数使用两组离散点进行计算：\n1.  一组位于域 $D$ 内部的 $N_{pde}$ 个配置点，$S_{pde} = \\{(x_i, y_i) \\mid i=1, \\dots, N_{pde}\\}$。\n2.  一组位于边界 $\\partial D$ 上的 $N_{bc}$ 个边界点，$S_{bc} = \\{(x_j, y_j) \\mid j=1, \\dots, N_{bc}\\}$。\n\n总损失函数 $L(\\theta)$ 是两个均方误差项的和：一个用于控制偏微分方程 ($L_{pde}$)，另一个用于边界条件 ($L_{bc}$)。\n\n构建总损失函数 $L(\\theta) = L_{pde} + L_{bc}$ 的数学表达式。你的表达式应使用网络输出 $\\hat{V}$、其二阶偏导数、函数 $f$、给定的点集及其各自的大小 $N_{pde}$ 和 $N_{bc}$ 来表示。", "solution": "我们从控制泊松方程和边界条件开始：\n$$\n\\nabla^{2}V(x,y)=-f(x,y), \\quad V(x,y)=0 \\text{ for } (x,y)\\in \\partial D.\n$$\n物理信息神经网络用 $\\hat{V}(x,y;\\theta)$ 来近似 $V$。在内部配置点 $(x_{i},y_{i})\\in S_{pde}$ 处的 PDE 残差通过将泊松方程施加于 $\\hat{V}$ 来定义：\n$$\nr_{i}(\\theta)=\\nabla^{2}\\hat{V}(x_{i},y_{i};\\theta)+f(x_{i},y_{i}).\n$$\n使用二维拉普拉斯算子的定义，这等价于\n$$\nr_{i}(\\theta)=\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i}).\n$$\n在 $S_{pde}$ 上强制执行 PDE 的均方误差则为\n$$\nL_{pde}(\\theta)=\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(r_{i}(\\theta)\\right)^{2}=\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i})\\right)^{2}.\n$$\n$\\partial D$ 上的边界条件 $V=0$ 通过惩罚 $\\hat{V}$ 在边界点 $(x_{j},y_{j})\\in S_{bc}$ 处与零的偏差来强制执行：\n$$\nL_{bc}(\\theta)=\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)-0\\right)^{2}=\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)\\right)^{2}.\n$$\n因此，总损失是这两个均方误差项的和：\n$$\nL(\\theta)=L_{pde}(\\theta)+L_{bc}(\\theta)=\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i})\\right)^{2}+\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)\\right)^{2}.\n$$", "answer": "$$\\boxed{\\frac{1}{N_{pde}}\\sum_{i=1}^{N_{pde}}\\left(\\frac{\\partial^{2}\\hat{V}}{\\partial x^{2}}(x_{i},y_{i};\\theta)+\\frac{\\partial^{2}\\hat{V}}{\\partial y^{2}}(x_{i},y_{i};\\theta)+f(x_{i},y_{i})\\right)^{2}+\\frac{1}{N_{bc}}\\sum_{j=1}^{N_{bc}}\\left(\\hat{V}(x_{j},y_{j};\\theta)\\right)^{2}}$$", "id": "2126324"}, {"introduction": "在掌握了稳态问题后，我们将更进一步，处理含时演化的偏微分方程。这类问题不仅需要满足边界条件，还必须遵循特定的初始状态。本练习以热传导方程为例，展示了如何将初始条件作为额外的损失项加入总损失中，从而让您能够为更广泛的初边值问题构建完整的PINN训练目标。[@problem_id:2126340]", "problem": "一位工程师正在为一根长度为 $L$ 的新型一维复合杆的热传递过程开发仿真程序。杆上的温度分布 $u(x, t)$ 由一维热方程控制：\n$$\n\\frac{\\partial u}{\\partial t} = \\alpha \\frac{\\partial^2 u}{\\partial x^2}\n$$\n对于 $x \\in [0, L]$ 和 $t \\in [0, T]$，其中 $\\alpha$ 是材料的热扩散系数。\n\n初始温度分布在 $t=0$ 时由 $u(x, 0) = \\sin\\left(\\frac{\\pi x}{L}\\right)$ 给出。\n边界条件如下：\n1. $x=0$ 处的端点保持在恒定的零温度：$u(0, t) = 0$。\n2. $x=L$ 处的端点受到周期性热源的作用，导致温度随时间变化：$u(L, t) = A \\cos(\\omega t)$，其中 $A$ 是振幅，$\\omega$ 是角频率。\n\n该工程师决定使用物理信息神经网络 (PINN) 来近似解 $u(x, t)$。PINN 由一个带有可训练参数 $\\theta$ 的神经网络 $\\hat{u}(x, t; \\theta)$ 表示。为了训练该网络，需要最小化一个总损失函数 $\\mathcal{L}_{\\text{total}}$。该损失函数通过对点进行采样，并强制满足控制偏微分方程、初始条件和边界条件来构建。\n\n采样点定义如下：\n- 一组 $N_p$ 个配置点 $\\{ (x_i^{(p)}, t_i^{(p)}) \\}_{i=1}^{N_p}$，从域的内部 $(0, L) \\times (0, T]$ 随机采样。\n- 一组 $N_{ic}$ 个初始点 $\\{ x_j^{(ic)} \\}_{j=1}^{N_{ic}}$，在 $t=0$ 时从空间域 $[0, L]$ 随机采样。\n- 一组 $N_{bc}$ 个边界时间点 $\\{ t_k^{(bc)} \\}_{k=1}^{N_{bc}}$，为每个边界从时间域 $[0, T]$ 随机采样。\n\n假设总损失是偏微分方程残差、初始条件和边界条件的均方误差之和（权重相等），下列哪个表达式正确地表示了总损失函数 $\\mathcal{L}_{\\text{total}}$？\n\n为简洁起见，我们基于网络的输出 $\\hat{u} = \\hat{u}(x, t; \\theta)$ 定义以下各项：\n- $\\mathcal{L}_{\\text{PDE}} = \\frac{1}{N_p} \\sum_{i=1}^{N_p} \\left| \\frac{\\partial \\hat{u}}{\\partial t}(x_i^{(p)}, t_i^{(p)}) - \\alpha \\frac{\\partial^2 \\hat{u}}{\\partial x^2}(x_i^{(p)}, t_i^{(p)}) \\right|^2$\n- $\\mathcal{L}_{\\text{IC}} = \\frac{1}{N_{ic}} \\sum_{j=1}^{N_{ic}} \\left| \\hat{u}(x_j^{(ic)}, 0) - \\sin\\left(\\frac{\\pi x_j^{(ic)}}{L}\\right) \\right|^2$\n- $\\mathcal{L}_{\\text{BC,0}} = \\frac{1}{N_{bc}} \\sum_{k=1}^{N_{bc}} \\left| \\hat{u}(0, t_k^{(bc)}) \\right|^2$\n- $\\mathcal{L}_{\\text{BC,L}} = \\frac{1}{N_{bc}} \\sum_{k=1}^{N_{bc}} \\left| \\hat{u}(L, t_k^{(bc)}) - A \\cos(\\omega t_k^{(bc)}) \\right|^2$\n\nA. $\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{PDE}} + \\mathcal{L}_{\\text{IC}} + \\mathcal{L}_{\\text{BC,0}} + \\frac{1}{N_{bc}} \\sum_{k=1}^{N_{bc}} \\left| \\hat{u}(L, t_k^{(bc)}) - A \\right|^2$\n\nB. $\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{PDE}} + \\mathcal{L}_{\\text{BC,0}} + \\mathcal{L}_{\\text{BC,L}}$\n\nC. $\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{PDE}} + \\mathcal{L}_{\\text{IC}} + \\mathcal{L}_{\\text{BC,0}} + \\mathcal{L}_{\\text{BC,L}}$\n\nD. $\\mathcal{L}_{\\text{total}} = \\frac{1}{N_{ic}} \\sum_{j=1}^{N_{ic}} \\left| \\frac{\\partial \\hat{u}}{\\partial t}(x_j^{(ic)}, 0) - \\alpha \\frac{\\partial^2 \\hat{u}}{\\partial x^2}(x_j^{(ic)}, 0) \\right|^2 + \\mathcal{L}_{\\text{IC}} + \\mathcal{L}_{\\text{BC,0}} + \\mathcal{L}_{\\text{BC,L}}$\n\nE. $\\mathcal{L}_{\\text{total}} = \\mathcal{L}_{\\text{PDE}} + \\frac{1}{N_{ic}} \\sum_{j=1}^{N_{ic}} \\left| \\hat{u}(x_j^{(ic)}, T) - \\sin\\left(\\frac{\\pi x_j^{(ic)}}{L}\\right) \\right|^2 + \\mathcal{L}_{\\text{BC,0}} + \\mathcal{L}_{\\text{BC,L}}$", "solution": "我们需要一个物理信息神经网络损失函数，该函数以相等的权重，强制满足时空域内部的控制偏微分方程、在 $t=0$ 时 $x \\in [0,L]$ 上的初始条件，以及在 $t \\in [0,T]$ 上 $x=0$ 和 $x=L$ 处的两个边界条件。PINN 的标准均方误差构造是这些分量的总和：\n- 在内部 $(0,L) \\times (0,T]$ 的配置点 $(x_{i}^{(p)}, t_{i}^{(p)})$ 上强制满足的偏微分方程残差，得到如定义的 $\\mathcal{L}_{\\text{PDE}}$。\n- 在 $t=0$ 时为采样的空间点 $x_{j}^{(ic)} \\in [0,L]$ 强制满足的初始条件，得到如定义的 $\\mathcal{L}_{\\text{IC}}$。\n- 在 $x=0$ 处为采样的时间点 $t_{k}^{(bc)} \\in [0,T]$ 强制满足的边界条件，得到如定义的 $\\mathcal{L}_{\\text{BC,0}}$。\n- 在 $x=L$ 处为采样的时间点 $t_{k}^{(bc)} \\in [0,T]$ 强制满足的边界条件，得到如定义的 $\\mathcal{L}_{\\text{BC,L}}$。\n\n在权重相等的情况下，正确的总损失是以下各项之和：\n$$\n\\mathcal{L}_{\\text{total}}=\\mathcal{L}_{\\text{PDE}}+\\mathcal{L}_{\\text{IC}}+\\mathcal{L}_{\\text{BC,0}}+\\mathcal{L}_{\\text{BC,L}}.\n$$\n现在评估各个选项：\n- 选项 A 将 $x=L$ 处的边界目标替换为 $A$ 而不是 $A\\cos(\\omega t)$，这与指定的随时间变化的边界条件不符，因此不正确。\n- 选项 B 完全省略了初始条件项，这违反了强制满足初始条件的要求，因此不正确。\n- 选项 C 正是四个正确定义的、权重相等的分量之和，因此是正确的。\n- 选项 D 在 $t=0$ 的初始条件采样集上计算偏微分方程残差，而不是在内部配置点上计算；这与所述的偏微分方程残差点的采样相矛盾，并且未能充分强制内部的偏微分方程，因此不正确。\n- 选项 E 强制了一个等于初始分布的末端时间条件 $t=T$，这在问题中没有指定，并且对于热方程而言，除非经过特殊构造，否则通常是不成立的；因此不正确。\n\n因此，正确的表达式是四个给定分量的简单相加，这对应于选项 C。", "answer": "$$\\boxed{C}$$", "id": "2126340"}, {"introduction": "除了在损失函数中惩罚边界误差外，还有一种更巧妙的方法来处理边界条件，即“硬编码”。通过精心设计网络输出函数的形式，我们可以从结构上保证其精确满足给定的边界条件，而无需任何训练。本练习将引导您思考如何通过改造网络架构来嵌入物理约束，这是一种强大且在实践中常用的技术。[@problem_id:2126300]", "problem": "在科学计算领域，物理信息神经网络 (PINNs) 已成为求解微分方程的强大工具。设计PINN的一个关键方面是确保其输出（即解的近似）满足给定的边界条件。实现这一目标的一种可靠方法是，通过构造网络最终的输出函数，使其天然满足这些条件。\n\n考虑一个在一维空间域 $x \\in [0, L]$ 上的问题。一个神经网络提供了一个原始、无约束的输出函数，记为 $\\hat{u}_{NN}(x)$。我们希望使用这个网络来找到一个微分方程的近似解 $u(x)$，该解满足以下非齐次狄利克雷边界条件：\n$$u(0) = A$$\n$$u(L) = B$$\n这里，$A$、$B$ 和 $L > 0$ 是给定的实常数。\n\n您的任务是设计一个变换，将网络的原始输出 $\\hat{u}_{NN}(x)$ 转换为一个新函数 $u_{NN}(x)$，并将其作为最终的近似解。这个变换必须保证，无论网络生成的函数 $\\hat{u}_{NN}(x)$ 是什么，$u_{NN}(x)$ 都能严格满足指定的边界条件。\n\n请给出 $u_{NN}(x)$ 关于网络原始输出 $\\hat{u}_{NN}(x)$ 以及参数 $x$、$L$、$A$ 和 $B$ 的表达式。", "solution": "我们寻找一个变换，它将网络的原始输出 $\\hat{u}_{NN}(x)$ 映射到一个函数 $u_{NN}(x)$，使得对于任何 $\\hat{u}_{NN}(x)$，该函数都能强制满足狄利克雷边界条件 $u_{NN}(0)=A$ 和 $u_{NN}(L)=B$。一种标准的构造方法是将 $u_{NN}(x)$ 分解为\n$$\nu_{NN}(x)=g(x)+s(x)\\,\\hat{u}_{NN}(x),\n$$\n其中 $g(x)$ 是任何满足边界条件的固定函数，而 $s(x)$ 是任何在两个边界上都为零的函数。具体来说，我们要求\n$$\ng(0)=A,\\quad g(L)=B,\\quad s(0)=0,\\quad s(L)=0.\n$$\n对于 $g(x)$，一个方便的选择是线性插值函数，\n$$\ng(x)=A\\left(1-\\frac{x}{L}\\right)+B\\left(\\frac{x}{L}\\right)=A+\\frac{B-A}{L}\\,x,\n$$\n以及简单的在边界处为零的因子\n$$\ns(x)=x(L-x),\n$$\n它满足 $s(0)=0$ 和 $s(L)=0$。因此，定义\n$$\nu_{NN}(x)=A\\left(1-\\frac{x}{L}\\right)+B\\left(\\frac{x}{L}\\right)+x(L-x)\\,\\hat{u}_{NN}(x).\n$$\n为了验证边界条件，在 $x=0$ 和 $x=L$ 处求值：\n$$\nu_{NN}(0)=A\\left(1-0\\right)+B\\left(0\\right)+0\\cdot L\\,\\hat{u}_{NN}(0)=A,\n$$\n$$\nu_{NN}(L)=A\\left(1-1\\right)+B\\left(\\frac{L}{L}\\right)+L( L-L)\\,\\hat{u}_{NN}(L)=B.\n$$\n因此，对于任何 $\\hat{u}_{NN}(x)$，构造出的 $u_{NN}(x)$ 都严格满足 $u_{NN}(0)=A$ 和 $u_{NN}(L)=B$。", "answer": "$$\\boxed{A\\left(1-\\frac{x}{L}\\right)+B\\left(\\frac{x}{L}\\right)+x\\left(L-x\\right)\\hat{u}_{NN}(x)}$$", "id": "2126300"}]}