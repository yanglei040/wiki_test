## 引言
在科学与工程领域，[计算模型](@entry_id:152639)是我们理解、预测和设计复杂系统的核心工具。然而，这些模型几乎总是包含不确定的参数，并且其自身也是对现实世界的简化和近似，导致我们的推断和预测充满不确定性。贝叶斯推断为系统性地应对这一挑战提供了强大框架，它能将数据与先验知识相结合，以量化和传播所有来源的不确定性。本文旨在为计算科学领域的学习者提供一份关于计算模型[贝叶斯推断](@entry_id:146958)的全面指南。

文章将循序渐进地展开。我们首先在 **“原理与机制”** 一章中，深入探讨[贝叶斯推断](@entry_id:146958)的数学基础、决策理论以及[模型比较](@entry_id:266577)的核心思想。随后，在 **“应用与跨学科联系”** 一章中，我们将跨越物理、生物到人工智能等多个领域，展示贝叶斯框架在解决真实世界问题中的强大能力与普适性。最后，通过 **“动手实践”** 部分，您将有机会把理论知识应用于解决具体问题，将所学转化为实践技能。通过这一学习路径，您将掌握在不确定性下进行严谨科学推理的关键工具。

## 原理与机制

本章深入探讨计算模型的[贝叶斯推断](@entry_id:146958)所依赖的核心原理与机制。在上一章介绍性讨论的基础上，我们将系统地剖析贝叶斯工作流的各个环节，从构建模型、更新信念，到评估模型和做出决策。我们将看到，[贝叶斯推断](@entry_id:146958)不仅仅是一套数学公式，更是一个用于在不确定性下进行严谨推理和学习的强大框架。

### [贝叶斯推断](@entry_id:146958)的核心：用数据更新信念

贝叶斯推断的基石是**[贝叶斯定理](@entry_id:151040) (Bayes' Theorem)**，它为我们提供了一种根据观测数据来更新关于模型参数信念的数学方法。给定一组观测数据 $y$ 和一个由参数 $\theta$ 表征的计算模型，贝叶斯定理可以表述为：

$p(\theta \mid y) = \frac{p(y \mid \theta) p(\theta)}{p(y)}$

这个表达式简洁地概括了学习过程的三个核心要素：

1.  **[先验分布](@entry_id:141376) (Prior Distribution)** $p(\theta)$：它代表了在观测任何数据之前，我们对参数 $\theta$ 的初始信念或知识。先验可以是“无信息的”，表示我们对参数知之甚少；也可以是“信息丰富的”，用以整合领域专家的知识或以往的研究成果。

2.  **[似然函数](@entry_id:141927) (Likelihood Function)** $p(y \mid \theta)$：这是连接参数和数据的桥梁。它描述了在给定一组特定参数 $\theta$ 的情况下，观测到数据 $y$ 的概率。在[计算模型](@entry_id:152639)的背景下，[似然函数](@entry_id:141927)通常基于一个“误差模型”，该模型描述了观测值 $y$ 与模型预测值 $u(\theta)$ 之间的差异。例如，一个常见的假设是加性[高斯噪声](@entry_id:260752)，即 $y \mid \theta \sim \mathcal{N}(u(\theta), \sigma^2)$，其中 $u(\theta)$ 是[确定性计算](@entry_id:271608)模型的输出。

3.  **[后验分布](@entry_id:145605) (Posterior Distribution)** $p(\theta \mid y)$：这是[贝叶斯推断](@entry_id:146958)的最终产物，代表了在考虑了观测数据 $y$ 之后，我们对参数 $\theta$ 更新后的信念。[后验分布](@entry_id:145605)是一个[概率分布](@entry_id:146404)，它捕捉了关于参数的所有信息，包括其最可能的值以及围绕这些值的不确定性。

分母 $p(y) = \int p(y \mid \theta) p(\theta) d\theta$ 被称为**[边际似然](@entry_id:636856) (Marginal Likelihood)** 或**证据 (Evidence)**。在[参数推断](@entry_id:753157)中，它是一个[归一化常数](@entry_id:752675)，确保[后验分布](@entry_id:145605)的积分为1。然而，我们稍后会看到，它在[模型比较](@entry_id:266577)中扮演着至关重要的角色。因此，贝叶斯定理通常以其正比形式被记住和使用：

$p(\theta \mid y) \propto p(y \mid \theta) p(\theta)$

这意味着[后验分布](@entry_id:145605)正比于似然与先验的乘积。

让我们通过一个具体的例子来理解这个更新过程。假设我们有一个简单的线性模型，其“真实”模拟器为 $u(\theta) = \alpha\theta + \beta$。我们观测到的数据 $y$ 带有[高斯噪声](@entry_id:260752)，即 $y \mid \theta \sim \mathcal{N}(u(\theta), \sigma^2)$。同时，我们对参数 $\theta$ 有一个[高斯先验](@entry_id:749752)信念，$\theta \sim \mathcal{N}(\mu_0, \tau_0^2)$。为了求得后验分布 $p(\theta \mid y)$，我们考察对数后验（忽略常数项）：

$\ln p(\theta \mid y) \propto -\frac{(y - (\alpha\theta + \beta))^2}{2\sigma^2} - \frac{(\theta - \mu_0)^2}{2\tau_0^2}$

通过展开并整理关于 $\theta$ 的二次项和一次项，我们可以运用“[配方法](@entry_id:265480)”技巧。这个过程揭示了[后验分布](@entry_id:145605)也是一个高斯分布 $\mathcal{N}(\mu_{\text{post}}, \sigma_{\text{post}}^2)$。其均值 $\mu_{\text{post}}$ 和[方差](@entry_id:200758) $\sigma_{\text{post}}^2$ 可以通过匹配系数得到。例如，后验[方差](@entry_id:200758)的倒数（即精度）是先验精度和（由[似然](@entry_id:167119)贡献的）数据精度的总和 [@problem_id:3101605]：

$\frac{1}{\sigma_{\text{post}}^2} = \frac{1}{\tau_0^2} + \frac{\alpha^2}{\sigma^2}$

而[后验均值](@entry_id:173826)则是先验均值和数据信息的精度加权平均 [@problem_id:3101605]：

$\mu_{\text{post}} = \sigma_{\text{post}}^2 \left( \frac{\mu_0}{\tau_0^2} + \frac{\alpha(y - \beta)}{\sigma^2} \right)$

这种先验分布和[后验分布](@entry_id:145605)属于同一[分布](@entry_id:182848)族（在此例中是高斯分布）的特性被称为**共轭性 (conjugacy)**。[共轭先验](@entry_id:262304)提供了闭合形式的后验更新，极大地简化了计算。

### [点估计](@entry_id:174544)与决策制定

后验分布 $p(\theta \mid y)$ 完整地描述了我们对参数 $\theta$ 的知识，但在许多实际应用中，我们需要选择一个单一的数值，即**[点估计](@entry_id:174544) (point estimate)** $\hat{\theta}$，用于报告、预测或运行[高保真度模拟](@entry_id:750285)。如何从一个完整的[概率分布](@entry_id:146404)中选择一个“最佳”值？这正是**贝叶斯决策理论 (Bayesian Decision Theory)** 的范畴。

该理论框架引入了一个**损失函数 (loss function)** $L(\hat{\theta}, \theta)$，它量化了当我们选择的估计值为 $\hat{\theta}$ 而真实值是 $\theta$ 时所付出的代价。贝叶斯方法的目标是选择一个能最小化在后验分布下期望损失的估计值。这个最优的估计值被称为**贝叶斯行动 (Bayes action)**。

$\hat{\theta}_{\text{Bayes}} = \arg\min_{\hat{\theta}} \mathbb{E}_{p(\theta \mid y)}[L(\hat{\theta}, \theta)] = \arg\min_{\hat{\theta}} \int L(\hat{\theta}, \theta) p(\theta \mid y) d\theta$

不同的损失函数反映了不同的决策目标，并对应不同的[最优估计量](@entry_id:176428)：

*   **[平方误差损失](@entry_id:178358) (Squared Error Loss)**：$L(\hat{\theta}, \theta) = (\hat{\theta} - \theta)^2$。最小化期望平方误差的贝叶斯行动是后验分布的**均值 (mean)**。
*   **[绝对误差损失](@entry_id:170764) (Absolute Error Loss)**：$L(\hat{\theta}, \theta) = |\hat{\theta} - \theta|$。最小化期望[绝对误差](@entry_id:139354)的贝叶斯行动是[后验分布](@entry_id:145605)的**中位数 (median)**。
*   **[0-1损失](@entry_id:173640) (Zero-One Loss)**：当 $\hat{\theta}$ 在 $\theta$ 的一个小邻域内时损失为0，否则为1。最小化这种损失的贝叶斯行动是后验分布的**众数 (mode)**。

[后验众数](@entry_id:174279)也被称为**最大后验估计 (Maximum A Posteriori, MAP)**。它是在给定数据下参数最可能的值。值得注意的是，对于对称的单峰后验分布（如[高斯分布](@entry_id:154414)），均值、中位数和众数是相同的。然而，对于[偏态分布](@entry_id:175811)，它们将有所不同，选择哪一个取决于我们的具体目标。

考虑一个[计算流体力学](@entry_id:747620) (CFD) [模型校准](@entry_id:146456)的例子，其中参数 $\theta$ 的后验分布被确定为[对数正态分布](@entry_id:261888) $\theta \mid y \sim \text{LN}(\mu, \sigma^2)$。这种[分布](@entry_id:182848)是[右偏](@entry_id:180351)的。如果我们的目标是最小化预期平方参数误差，那么贝叶斯行动就是[后验均值](@entry_id:173826) $\mathbb{E}[\theta \mid y] = \exp(\mu + \sigma^2/2)$。而[MAP估计](@entry_id:751667)则是[后验众数](@entry_id:174279) $\exp(\mu - \sigma^2)$。这两个值是不同的，强调了[点估计](@entry_id:174544)的选择必须与潜在的决策问题（由[损失函数](@entry_id:634569)定义）相匹配 [@problem_id:3101577]。

### 先验的角色：编码结构与正则化

先验分布不仅仅是主观信念的载体，它在现代[贝叶斯建模](@entry_id:178666)中，尤其是在高维问题中，扮演着实现**正则化 (regularization)** 和编码模型结构的关键角色。当参数数量 $p$ 远大于数据点数量 $n$ 时，如果没有先验的约束，模型极易[过拟合](@entry_id:139093)。

一个重要的应用领域是[稀疏性](@entry_id:136793)建模。在许多科学问题中，我们相信一个高维参数向量 $\theta$ 中的大部分分量都为零或接近于零。我们可以通过选择合适的**稀疏诱导先验 (sparsity-inducing prior)**来将这种信念融入模型中。

*   **拉普拉斯先验 (Laplace Prior)**：$p(\theta_j) \propto \exp(-|\theta_j|/b)$。该先验在0处有一个尖峰，并且尾部是指数衰减的。一个显著的特性是，使用拉普拉斯先验的[MAP估计](@entry_id:751667)等价于著名的[L1正则化](@entry_id:751088)（LASSO）。其解具有稀疏性，即许多参数的估计值恰好为零。例如，在一维正态均值问题 $y \sim \mathcal{N}(\theta, \sigma^2)$ 中，拉普拉斯先验下的[MAP估计](@entry_id:751667)由**[软阈值](@entry_id:635249)规则 (soft-thresholding rule)** 给出 [@problem_id:3101582]：
    $\hat{\theta}_{\text{MAP}} = \text{sign}(y) \max(|y| - \frac{\sigma^2}{b}, 0)$
    这个规则将所有[绝对值](@entry_id:147688)小于阈值 $\sigma^2/b$ 的观测值对应的[参数估计](@entry_id:139349)为零，而将其他参数向零收缩一个固定的量。

*   **马蹄铁先验 (Horseshoe Prior)**：这是一种更先进的**全局-局部收缩先验 (global-local shrinkage prior)**。它通过一个层次结构来建模：$\theta_j \mid \lambda_j, \tau \sim \mathcal{N}(0, \tau^2 \lambda_j^2)$。这里的 $\tau$ 是一个**全局[尺度参数](@entry_id:268705)**，它将所有系数都推向零。而 $\lambda_j$ 是每个系数独有的**局部[尺度参数](@entry_id:268705)**，它允许个别系数“逃脱”收缩。通过为 $\lambda_j$ 设置一个在零附近有很大[概率密度](@entry_id:175496)但在尾部很重的先验（如半[柯西分布](@entry_id:266469)），马蹄铁先验可以实现**自适应收缩 (adaptive shrinkage)**。它能非常强烈地收缩那些由噪声引起的、真实值可能为零的系数，同时对那些由强信号支撑的、真实值较大的系数施加非常小的收缩。与拉普拉斯先验相比，马蹄铁先验的尾部更重（多项式衰减而非指数衰减），因此它在保留大信号方面表现更佳，是高维[稀疏回归](@entry_id:276495)问题中的一个强大工具 [@problem_id:3101582]。

### 模型评估与比较

贝叶斯框架提供了一个内在且原则性的方法来比较不同的计算模型或科学假设。这里的“模型”可以指代不同的数学结构、不同的先验假设或不同的[似然函数](@entry_id:141927)。

比较的核心是**[边际似然](@entry_id:636856) (Marginal Likelihood)**，也称为**[模型证据](@entry_id:636856) (Model Evidence)**，$p(y)$。正如之前提到的，$p(y) = \int p(y \mid \theta) p(\theta) d\theta$。它代表了在积分掉所有参数后，模型 $M$ 产生观测数据 $y$ 的概率，即 $p(y \mid M)$。[边际似然](@entry_id:636856)自然地体现了**[奥卡姆剃刀](@entry_id:147174) (Occam's Razor)** 原则：一个好的模型不仅要能很好地拟[合数](@entry_id:263553)据（即 $p(y \mid \theta)$ 在某些 $\theta$ 处要高），而且其[参数空间](@entry_id:178581)不能过于庞大和灵活，以免“稀释”预测能力。一个过于复杂的模型需要将[先验概率](@entry_id:275634)质量分散到广阔的[参数空间](@entry_id:178581)中，导致其在任何特定数据集上的平均似然（即证据）都会降低。

给定两个竞争模型 $M_1$ 和 $M_2$，我们可以计算它们的**[贝叶斯因子](@entry_id:143567) (Bayes Factor)**：

$K = \frac{p(y \mid M_1)}{p(y \mid M_2)} = \frac{\int p(y \mid \theta_1, M_1) p(\theta_1 \mid M_1) d\theta_1}{\int p(y \mid \theta_2, M_2) p(\theta_2 \mid M_2) d\theta_2}$

[贝叶斯因子](@entry_id:143567)量化了数据支持一个模型相对于另一个模型的证据强度。如果 $K > 1$，则数据更支持 $M_1$。

我们还可以更进一步，为模型本身分配先验概率 $p(M_i)$。通过贝叶斯定理，我们可以计算每个模型的**[后验概率](@entry_id:153467) (posterior probability)**：

$p(M_i \mid y) = \frac{p(y \mid M_i) p(M_i)}{\sum_j p(y \mid M_j) p(M_j)}$

假设我们对两个模型没有先验偏好，即 $p(M_1) = p(M_2) = 0.5$，那么模型 $M_1$ 的后验概率就是 $\frac{K}{1+K}$。

例如，在分析网络流量时，我们可能不确定[丢包](@entry_id:269936)过程是应该用[二项分布](@entry_id:141181)模型（每个包独立丢失）还是[泊松分布](@entry_id:147769)模型（单位时间内的[丢包](@entry_id:269936)数）。我们可以为这两种模型分别建立贝叶斯模型（例如，二项-Beta模型和泊松-Gamma模型），然后计算各自的[边际似然](@entry_id:636856) $p_B(y)$ 和 $p_P(y)$。通过比较这两个值，我们可以量化数据更支持哪种关于[丢包](@entry_id:269936)机制的假设 [@problem_id:3101594]。

### 实践中的贝叶斯工作流：近似与诊断

理论上的贝叶斯推断优雅而强大，但在实践中，特别是对于复杂的[计算模型](@entry_id:152639)（如[非线性PDE](@entry_id:202123)求解器），[后验分布](@entry_id:145605)和[边际似然](@entry_id:636856)通常没有解析解，其计算涉及[高维积分](@entry_id:143557)，这带来了巨大的计算挑战。因此，近似方法和[模型诊断](@entry_id:136895)是贝叶斯工作流不可或缺的部分。

#### [近似推断](@entry_id:746496)方法

当精确计算不可行时，我们需要近似后验分布。主要有三类方法：

1.  **[拉普拉斯近似](@entry_id:636859) (Laplace Approximation)**：其思想是用一个高斯分布来近似后验分布。这个高斯分布的均值设在[后验分布](@entry_id:145605)的众数（[MAP估计](@entry_id:751667)）$\hat{\theta}$ 处，其协方差矩阵则由对数后验在众数点的[二阶导数](@entry_id:144508)（Hessian矩阵）的负逆决定。这本质上是对对数后验密度在峰值附近进行二阶泰勒展开。[拉普拉斯近似](@entry_id:636859)计算速度快，并且可以提供一个对[边际似然](@entry_id:636856)的近似估计。然而，它的主要缺点是其高斯形式的假设。如果真实的[后验分布](@entry_id:145605)是高度偏斜或多峰的，[拉普拉斯近似](@entry_id:636859)的效果会很差 [@problem_id:3101579]。

2.  **[变分推断](@entry_id:634275) (Variational Inference, VI)**：VI将推断问题转化为一个[优化问题](@entry_id:266749)。其目标是找到一个来自某个简单、易于处理的[分布](@entry_id:182848)族 $Q$（例如，分量间[相互独立](@entry_id:273670)的[分布](@entry_id:182848)，即**平均场 (mean-field)** 假设）的[分布](@entry_id:182848) $q(\theta)$，使其与真实的后验分布 $p(\theta \mid y)$ 最“接近”。“接近”程度通常用KL散度 $KL(q || p)$ 来衡量。最小化[KL散度](@entry_id:140001)等价于最大化一个叫做**[证据下界](@entry_id:634110) (Evidence Lower Bound, ELBO)** 的量。VI通常比MCMC快得多，但由于其近似假设（如平均场假设），它往往会低估后验分布的[方差](@entry_id:200758)和忽略参数间的相关性。这种[方差](@entry_id:200758)低估会导致模型的预测过于自信 [@problem_id:3101578]。

3.  **马尔可夫链蒙特卡洛 (Markov Chain [Monte Carlo](@entry_id:144354), MCMC)**：MCMC是一类基于采样的算法，它通过构建一个以真实[后验分布](@entry_id:145605)为[平稳分布](@entry_id:194199)的[马尔可夫链](@entry_id:150828)来从后验中抽取样本。像Metropolis-Hastings这样的算法 [@problem_id:3101601]，通过“提议-接受/拒绝”机制，能够探索复杂的后验分布。只要运行时间足够长，MCMC可以任意精确地近似[后验分布](@entry_id:145605)，被认为是[贝叶斯推断](@entry_id:146958)的“黄金标准”。但其计算成本高昂，且需要仔细诊断链的收敛性。

#### 模型检查与改进

获得后验分布（无论是精确的还是近似的）并非终点。一个负责任的建模者必须回答：“我的模型足够好吗？”模型检查（或称[模型诊断](@entry_id:136895)）是回答这个问题的关键步骤，它致力于发现模型与数据之间的系统性差异，从而指导模型的改进。

*   **后验预测检验 (Posterior Predictive Checks, PPCs)**：PPC的核心思想是：如果一个模型是好的，那么它应该能够生成与我们观测到的数据相似的数据。PPC的流程如下：
    1.  从后验分布 $p(\theta \mid y)$ 中抽取参数样本 $\{\theta^{(s)}\}_{s=1}^S$。
    2.  对于每个样本 $\theta^{(s)}$，从模型的生成过程中模拟出一个“复制”数据集 $y^{\text{rep},(s)}$。
    3.  选择一些**差异度量 (discrepancy measures)** $T(y)$，这些度量捕捉了你关心的数据的某些特征（如均值、[方差](@entry_id:200758)、最大值、数据点间的“粗糙度”等）。
    4.  比较观测数据的差异度量 $T(y)$ 与复制数据集的差异度量[分布](@entry_id:182848) $\{T(y^{\text{rep},(s)})\}$。如果 $T(y)$ 在 $\{T(y^{\text{rep},(s)})\}$ 的[分布](@entry_id:182848)中看起来像一个极端的离群值，那就表明模型未能捕捉到数据的该方面特征。这通常通过计算**后验预测[p值](@entry_id:136498) (posterior predictive p-value)** 来量化。

    例如，在拟合一个SIR[流行病模型](@entry_id:271049)时，我们可能发现模型能很好地预测总病例数（一个差异度量），但在捕捉报告病例数的周[内波](@entry_id:261048)动（例如，周末报告延迟导致的“粗糙度”）方面表现很差。这会通过一个针对“粗糙度”的差异度量的极端[p值](@entry_id:136498)表现出来，从而提示我们需要改进模型，比如加入一个描述周内效应的结构 [@problem_id:3101601]。

*   **[概率积分变换](@entry_id:262799) (Probability Integral Transform, PIT)**：对于连续型数据，PIT是一种强大的校准诊断工具。对于一个观测值 $y_i$，其PIT值定义为 $z_i = F_i(y_i)$，其中 $F_i$是该观测值对应的后验预测[累积分布函数](@entry_id:143135)(CDF)。其原理是：如果模型是完美校准的，那么PIT值 $\{z_i\}$ 应该服从[均匀分布](@entry_id:194597) $\text{Uniform}(0,1)$。
    
    通过绘制PIT值的直方图，我们可以直观地诊断模型的系统性偏差：
    *   **U形直方图**：表明模型的[预测分布](@entry_id:165741)过于狭窄（**欠分散/过于自信**）。观测值落在[预测分布](@entry_id:165741)尾部的频率远高于预期。
    *   **拱形直方图**：表明模型的[预测分布](@entry_id:165741)过于宽泛（**过分散/不够自信**）。
    *   **倾斜的直方图**：表明模型存在系统性偏倚（例如，预测值总是偏高或偏低）。

    当诊断出问题后，我们可以据此改进模型。例如，一个U形的PIT直方图表明我们需要增加模型的预测[方差](@entry_id:200758)，可能的修正包括增大[观测误差](@entry_id:752871)$\sigma^2$，或者将高斯误差模型替换为尾部更重的[学生t分布](@entry_id:267063)模型 [@problem_id:3101551]。

*   **评分规则 (Scoring Rules)**：当需要对不同的预测模型进行定量比较时，**恰当评分规则 (proper scoring rules)** 提供了一种原则性的方法。这些规则基于模型的整个[预测分布](@entry_id:165741)对观测结果进行评分。
    *   **对数分数 (Logarithmic Score)** $S_{\text{log}}(F, y^\star) = \ln p(y^\star)$，直接评估观测值 $y^\star$ 在预测密度函数下的值。它对模型分配给实际发生事件的概率密度非常敏感，因此对离群值极其敏感，会严厉惩罚那些给观测值分配了极低概率的模型。
    *   **连续排序概率分数 (Continuous Ranked Probability Score, CRPS)** 衡量的是预测CDF与观测值的[阶跃函数](@entry_id:159192)之间的积分平[方差](@entry_id:200758)。它不如对数分数那样对离群值敏感，且可以很容易地根据预测样本直接计算，无需进行[密度估计](@entry_id:634063)。当模型的预测只能通过样本获得时，CRPS通常是更稳健和实用的选择 [@problem_id:3101580]。

### 在计算科学中的应用

贝叶斯推断为解决计算科学中的核心挑战提供了统一的框架，包括量化由近似引起的误差和评估风险。

*   **量化[模型差异](@entry_id:198101)**：在许多领域，高保真度的模拟器（如CFD或FEM求解器）计算成本极高，因此常常使用快速的**代理模型 (surrogate model)** 或**模拟器 (emulator)** $f(\theta)$ 来替代。一个关键问题是：使用模拟器会给我们的推断带来多大的误差？我们可以通过比较基于真实模拟器 $u(\theta)$ 的后验 $p(\theta \mid y)$ 和基于模拟器 $f(\theta)$ 的后验 $\hat{p}(\theta \mid y)$ 来回答这个问题。**[Wasserstein距离](@entry_id:147338)**等度量提供了一种正式的方法来量化这两个[概率分布](@entry_id:146404)之间的差异。例如，对于两个高斯后验分布，2-[Wasserstein距离](@entry_id:147338)有一个简洁的[闭合形式](@entry_id:271343)，它同时考虑了[后验均值](@entry_id:173826)和[标准差](@entry_id:153618)的差异，从而为模拟器引入的推断误差提供了一个定量的衡量标准 [@problem_id:3101605]。

*   **[不确定性传播](@entry_id:146574)与风险评估**：贝叶斯推断的核心优势之一是它提供了一个完整的[后验分布](@entry_id:145605)，而不仅仅是一个[点估计](@entry_id:174544)。这个参数的[后验分布](@entry_id:145605)可以通过[计算模型](@entry_id:152639)传播，以量化模型预测或任何感兴趣量 (Quantity of Interest, QoI) 的不确定性。这在风险评估中尤其重要。例如，在使用显式[数值格式](@entry_id:752822)求解一个[偏微分方程](@entry_id:141332)时，其稳定性受到[CFL条件](@entry_id:178032)的限制，而CFL数本身可能依赖于一个不确定的物理参数（如[平流](@entry_id:270026)速度 $\theta$）。通过[贝叶斯推断](@entry_id:146958)得到 $\theta$ 的[后验分布](@entry_id:145605)后，我们可以计算出CFL数超过稳定极限的后验概率。这个概率值 $R = \Pr_{p(\theta \mid y)}(\text{CFL}(\theta) > 1)$ 直接量化了在给定数据和先验知识下，数值方案变得不稳定的风险，为选择合适的离散化参数（如时间步长 $\Delta t$）提供了决策依据 [@problem_id:3101621]。

总之，[贝叶斯推断](@entry_id:146958)为与[计算模型](@entry_id:152639)打交道的科学家和工程师提供了一整套原理和工具，使他们能够系统地整合数据、[量化不确定性](@entry_id:272064)、比较假设、诊断模型缺陷并做出稳健的决策。