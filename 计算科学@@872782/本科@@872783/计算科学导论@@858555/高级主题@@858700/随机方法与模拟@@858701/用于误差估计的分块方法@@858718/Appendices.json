{"hands_on_practices": [{"introduction": "掌握分块法的第一步是在实践中观察其效果。此练习将指导您生成一个合成的相关时间序列，该序列模拟了来自扩散蒙特卡洛等模拟的数据。您的目标是同时使用忽略相关性的朴素方法和分块法来计算均值的误差棒，从而进行直接比较，凸显考虑数据相关性的重要性。通过这个练习[@problem_id:2885597]，您将实现核心的分块算法，并学会如何解读其相对于朴素估计的结果。", "problem": "考虑在量子化学中，使用扩散蒙特卡洛（DMC）方法估算固定节点基态能量，其中测量的局域能量构成一个相关的时间序列。固定节点近似约束了节面，并将渐近平均能量移动了一个恒定的偏差，但不会改变围绕该均值的涨落的平稳性或自相关结构。因此，核心的统计任务是从相关观测值中估算样本均值的无偏标准误。\n\n从以下基础出发：\n- 具有有限积分自相关时间的平稳时间序列的样本均值遵循马尔可夫链的中心极限定理：随着样本数量的增加，样本均值的标度偏差趋向于正态分布，且样本均值的方差取决于自相关函数。\n- 具有平稳均值和方差的一阶自回归过程 (AR(1)) 是一个经过充分检验的模型，用于描述指数衰减的时间相关性。\n\n你的程序必须：\n- 使用具有指定参数的 AR(1) 高斯过程生成类 DMC 的合成局域能量轨迹。\n- 计算忽略相关性的均值的朴素标准误。\n- 使用二进制分块（也称为重分块）计算分块标准误。该方法通过对块大小为2的幂的连续数据进行平均来粗粒化序列，并选择满足最小块数约束的最大块大小，从而减少时间相关性带来的偏差。\n\n形式上，令合成的局域能量时间序列由一个 AR(1) 递归定义\n$$\nX_{t} = \\mu + \\rho \\left( X_{t-1} - \\mu \\right) + \\varepsilon_{t}, \\quad \\varepsilon_{t} \\sim \\mathcal{N}\\!\\left(0, \\sigma_{\\varepsilon}^{2}\\right),\n$$\n并在其平稳分布中初始化\n$$\nX_{0} \\sim \\mathcal{N}\\!\\left(\\mu, \\sigma^{2}\\right), \\quad \\sigma_{\\varepsilon}^{2} = \\sigma^{2}\\left(1-\\rho^{2}\\right),\n$$\n其中 $t \\in \\{1,2,\\dots,N-1\\}$，$N$ 是总样本数，$\\mu$ 是固定节点能量偏移（一个恒定均值），$\\sigma$ 是局域能量的平穩标准差，而 $\\rho \\in (-1,1)$ 控制相关强度。\n\n给定一个实现 $\\{X_{t}\\}_{t=0}^{N-1}$：\n- 朴素标准误是样本标准差除以 $\\sqrt{N}$，其中样本方差使用无偏除数。\n- 对于分块法，定义块大小 $b \\in \\{2^{0}, 2^{1}, 2^{2}, \\dots\\}$，对于每个块大小 $b$，形成 $n_{b} = \\lfloor N/b \\rfloor$ 个大小为 $b$ 的连续块，取它们的均值，并计算这些块均值的样本方差（使用无偏除数）。块大小为 $b$ 时的分块标准误是块均值方差除以 $n_{b}$ 的平方根。选择最大的块大小 $b^{\\star}$ 使得 $n_{b^{\\star}} \\geq B_{\\min}$，其中 $B_{\\min}$ 是指定的最小块数。使用此分块标准误作为报告的基于分块的误差棒。\n\n您的程序必须实现上述内容，不得使用任何快捷公式求解答案，并且必须为每个测试用例输出以下包含四个浮点数的列表：\n- 均值的朴素标准误。\n- 在 $b^{\\star}$ 处使用指定的 $B_{\\min}$ 确定的均值的分块标准误。\n- 朴素标准误与分块标准误的比率。\n- 估计的有效样本量，定义为原始序列的无偏样本方差与分块标准误平方的比值。\n\n所有浮点数输出必须四舍五入到六位小数。\n\n测试套件：\n使用以下四个参数集，每个参数集以元组 $(N, \\mu, \\sigma, \\rho, \\text{seed}, B_{\\min})$ 的形式给出：\n- 案例1：(N=65536, μ=-0.5, σ=1.0, ρ=0.0, seed=12345, B_min=16)。\n- 案例2：(N=65536, μ=-0.5, σ=1.0, ρ=0.8, seed=24680, B_min=16)。\n- 案例3：(N=65536, μ=-0.5, σ=1.0, ρ=0.98, seed=13579, B_min=16)。\n- 案例4：(N=50000, μ=-1.0, σ=1.5, ρ=0.9, seed=98765, B_min=16)。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个 Python 风格的列表，每个测试用例对应一个条目，每个条目本身是按上述顺序排列的四个浮点数的列表。该列表必须以逗号分隔并用方括号括起来，例如，`[[naive_1,blocked_1,ratio_1,effN_1],[naive_2,blocked_2,ratio_2,effN_2],...]`。\n不需要物理单位。不涉及角度。不得使用百分比；任何分数都必须表示为小数。程序必须完全自包含，无需任何输入。必须通过提供的种子确保确定性的伪随机数生成。所有步骤的计算必须遵守上述定义。", "solution": "所提出的问题是相关时间序列统计分析中一个明确定义的练习，这是处理计算物理和化学中蒙特卡洛模拟数据的基本任务。使用一阶自回归（AR(1)）过程来模拟扩散蒙特卡洛（DMC）计算中的局域能量涨落是一种标准且具有物理合理性的近似方法。目标是在存在时间相关性的情况下正确估计平均能量的统计不确定性。这需要超越假定数据独立的朴素统计估计量。\n\n对问题陈述的验证证实了其科学基础扎实、数学上适定，并包含了继续进行所需的所有信息。它既不平凡也非不适定。因此，可以构建一个严谨的解决方案。\n\n解决方案将遵循统计力学和时间序列分析的原理，分三个阶段进行开发。\n\n首先，我们必须生成合成数据。局域能量时间序列，表示为随机变量序列 $\\{X_t\\}_{t=0}^{N-1}$，被建模为一个平稳高斯 AR($1$) 过程。其演化由以下递归关系给出：\n$$\nX_{t} = \\mu + \\rho \\left( X_{t-1} - \\mu \\right) + \\varepsilon_{t}\n$$\n其中 $\\mu$ 是恒定平均能量，$\\rho$ 是连续步骤之间的自相关系数，$\\varepsilon_t$ 是均值为零、方差为 $\\sigma_{\\varepsilon}^2$ 的独立同分布高斯噪声项。为确保过程平稳且具有恒定方差 $\\sigma^2 = \\text{Var}(X_t)$，噪声方差必须设置为 $\\sigma_{\\varepsilon}^2 = \\sigma^2(1-\\rho^2)$。模拟开始于从平稳分布本身抽取初始状态 $X_0$，该分布是均值为 $\\mu$、方差为 $\\sigma^2$ 的正态分布，即 $X_0 \\sim \\mathcal{N}(\\mu, \\sigma^2)$。随后的点 $X_t$（对于 $t \\in \\{1, 2, \\dots, N-1\\}$）通过该递归生成。此过程保证了整个生成的序列是来自指定平稳过程的真实样本。\n\n其次，我们计算均值的朴素标准误。该估计量基于 $N$ 个数据点不相关的错误假设。其计算方式如下：\n$$\n\\text{SE}_{\\text{naive}} = \\frac{s}{\\sqrt{N}}\n$$\n其中 $s^2$ 是时间序列 $\\{X_t\\}$ 的无偏样本方差：\n$$\ns^2 = \\frac{1}{N-1} \\sum_{t=0}^{N-1} (X_t - \\bar{X})^2\n$$\n此处，$\\bar{X}$ 是序列的样本均值。对于任何正相关（$\\rho  0$），该估计量将系统地低估真实的不确定性。\n\n第三，我们实现分块法，这是一种考虑序列相关的稳健技术。其核心原理是将数据粗粒化为足够大的块，使得块平均值近似不相关。对于选定的块大小 $b$，原始序列被划分为 $n_b = \\lfloor N/b \\rfloor$ 个不重叠的块。计算每个块的均值，得到一个新的、更短的包含 $n_b$ 个块平均值的时间序列。\n然后可以从这些块均值的样本方差中估计总均值的方差。给定块大小 $b$ 的标准误为：\n$$\n\\text{SE}_{\\text{blocked}}(b) = \\sqrt{\\frac{\\text{var}(\\text{block means})}{n_b}}\n$$\n其中 $\\text{var}(\\text{block means})$ 是 $n_b$ 个块平均值的无偏样本方差。随着块大小 $b$ 的增加，块均值之间的相关性减弱，$\\text{SE}_{\\text{blocked}}(b)$ 收敛于均值的真实标准误。然而，随着 $b$ 的增加，$n_b$ 減少，导致方差的统计估计变差。因此，我们必须选择一个最优的块大小 $b^{\\star}$。问题指定了一个实用标准：$b^{\\star}$ 是形式为 $2^k$（$k \\ge 0$ 为整数）的最大块大小，使得块的数量 $n_{b^{\\star}}$ 至少为指定的最小值 $B_{\\min}$。此过程在减少相关性偏差和保持统计稳定性之間取得了平衡。\n\n最后，我们计算两个派生量来表征相关性的影响。朴素标准误与分块标准误之比 $\\text{SE}_{\\text{naive}} / \\text{SE}_{\\text{blocked}}(b^{\\star})$ 量化了朴素公式低估的程度。有效样本量定义为：\n$$\nN_{\\text{eff}} = \\frac{s^2}{(\\text{SE}_{\\text{blocked}}(b^{\\star}))^2}\n$$\n代表了产生等效统计误差的独立样本数量。对于正相关数据，我们预期 $N_{\\text{eff}}  N$。\n\n实现将对测试套件中提供的每个参数集执行此完整过程，通过使用指定的伪随机数生成器种子来确保确定性输出。所有数值结果将按要求四舍五入到六位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Generates synthetic DMC local-energy traces using an AR(1) process and\n    computes naive and blocked standard errors of the mean.\n    \"\"\"\n    \n    # Test cases are given as (N, mu, sigma, rho, seed, B_min).\n    test_cases = [\n        (65536, -0.5, 1.0, 0.0, 12345, 16),\n        (65536, -0.5, 1.0, 0.8, 24680, 16),\n        (65536, -0.5, 1.0, 0.98, 13579, 16),\n        (50000, -1.0, 1.5, 0.9, 98765, 16)\n    ]\n\n    all_results = []\n    for case in test_cases:\n        N, mu, sigma, rho, seed, B_min = case\n\n        # Initialize the pseudorandom number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n\n        # Generate the AR(1) time series.\n        # This series emulates correlated local energy data from a DMC simulation.\n        X = np.zeros(N)\n        sigma_eps = sigma * np.sqrt(1.0 - rho**2)\n\n        # Initialize from the stationary distribution.\n        X[0] = rng.normal(loc=mu, scale=sigma)\n        \n        # Generate the rest of the series via the AR(1) recursion.\n        for t in range(1, N):\n            epsilon_t = rng.normal(loc=0.0, scale=sigma_eps)\n            X[t] = mu + rho * (X[t-1] - mu) + epsilon_t\n\n        # Calculate the unbiased sample variance of the original series.\n        # This will be used for both naive error and effective sample size.\n        sample_variance = np.var(X, ddof=1)\n\n        # 1. Compute the naive standard error of the mean.\n        # This estimator ignores correlations and is expected to be inaccurate for rho != 0.\n        naive_se = np.sqrt(sample_variance / N)\n\n        # 2. Compute the blocked standard error of the mean.\n        # This involves reblocking the data with increasing block sizes.\n        blocked_se = -1.0  # Placeholder, will be updated in the loop.\n        k = 0\n        while True:\n            # Block sizes are powers of two.\n            b = 2**k\n            n_b = N // b\n            \n            # Stop if the number of blocks is less than the required minimum.\n            # The result from the previous iteration is the correct one.\n            if n_b  B_min:\n                break\n            \n            # If n_b becomes 1, variance calculation is impossible.\n            # B_min > 1 ensures this path is not taken for the final result.\n            if n_b = 1:\n                # If this is the first iteration (k=0), it means N  B_min\n                # and no valid blocking is possible. Set SE to NaN.\n                if k == 0:\n                    blocked_se = np.nan\n                break\n\n            # Reshape the data into blocks. Leftover data at the end of the series is discarded.\n            num_elements_to_block = n_b * b\n            data_to_block = X[:num_elements_to_block]\n            blocks = data_to_block.reshape((n_b, b))\n            \n            # Compute the means of the blocks.\n            block_means = np.mean(blocks, axis=1)\n            \n            # Compute the unbiased variance of the block means.\n            var_block_means = np.var(block_means, ddof=1)\n            \n            # The standard error of the grand mean, estimated from this blocking level.\n            # This value is updated and stored. The last valid one is used.\n            blocked_se = np.sqrt(var_block_means / n_b)\n            \n            k += 1\n\n        # 3. Compute the ratio of naive to blocked standard error.\n        ratio = naive_se / blocked_se\n        \n        # 4. Compute the effective sample size.\n        effective_n = sample_variance / (blocked_se**2)\n\n        # Collect and round results to six decimal places.\n        result_list = [\n            round(naive_se, 6),\n            round(blocked_se, 6),\n            round(ratio, 6),\n            round(effective_n, 6)\n        ]\n        all_results.append(result_list)\n\n    # Format the final output string to be a compact list of lists.\n    # e.g., [[item1,item2],[item3,item4]]\n    # The map(str, ...) converts each inner list to its string representation.\n    # The ','.join(...) combines them into a single string.\n    # The outer f-string adds the enclosing brackets.\n    final_output_str = f\"[{','.join(map(str, all_results))}]\"\n    final_output_str = final_output_str.replace(\" \", \"\")\n\n    print(final_output_str)\n\nsolve()\n```", "id": "2885597"}, {"introduction": "在学会如何实现分块法之后，理解其工作原理至关重要。这个练习[@problem_id:3102616]旨在通过一个“合理性检查”来建立这种直觉。通过随机打乱一个时间序列，我们能够破坏其内在的时间相关性。您将观察到，对于打乱后的序列，无论区块尺寸如何选择，分块法计算出的方差估计值都会收敛到简单的独立同分布（IID）估计值，这清晰地证明了该方法确实是针对数据中的时间依赖结构进行校正的。", "problem": "您的任务是验证在存在序列相关性的情况下，用于样本均值误差估计的分块方法。分块方法将一个按时间排序的序列划分为大小相等的非重叠组，以形成块均值，并根据这些块之间的变异性来估计样本均值的方差。需要验证的核心原理是，通过对时间索引进行随机排列来破坏时间相关性，应使基于分块的方差估计量退化为独立同分布（IID）的方差公式。\n\n使用的基本定义和事实：\n- 离散时间序列 $\\{X_t\\}_{t=1}^n$ 的样本均值为 $\\bar{X} = \\frac{1}{n} \\sum_{t=1}^n X_t$。\n- 对于方差为 $\\sigma^2$ 的 IID 数据，样本均值的方差为 $\\operatorname{Var}(\\bar{X}) = \\sigma^2 / n$。\n- 在块大小为 $b$ 的分块方法中，前 $m = \\lfloor n/b \\rfloor$ 个不重叠的块产生块均值 $Y_i = \\frac{1}{b} \\sum_{t=(i-1)b+1}^{ib} X_t$ (其中 $i=1,\\dots,m$)。当块足够大，使得块均值近似独立时，$\\bar{X}$ 的方差可利用 $\\{Y_i\\}$ 之间的变异性来近似。\n- 将索引的随机排列 $\\pi$ 应用于序列，得到 $X'_t = X_{\\pi(t)}$，这会保持 $\\{X_t\\}$ 的边际分布，但会破坏时间顺序，从而破坏序列相关性。\n\n任务：\n1. 对每个指定的测试用例，通过一阶自回归（AR）模型生成一个时间序列。该序列满足 $X_t = \\phi X_{t-1} + \\epsilon_t$ 且 $|\\phi|  1$，其中 $\\epsilon_t \\sim \\mathcal{N}(0,\\sigma_\\epsilon^2)$ 是独立的高斯新息，并且为了保证平稳性，$X_0$ 从方差为 $\\sigma_\\epsilon^2 / (1 - \\phi^2)$ 的平稳分布中抽取。每个测试用例使用一个固定的随机种子。\n2. 对于一系列块大小 $b$，按如下方式计算基于分块的样本均值方差估计量：形成 $m = \\lfloor n/b \\rfloor$ 个不重叠的块均值 $Y_1,\\dots,Y_m$，计算 $\\{Y_i\\}$ 的带有 Bessel 校正的无偏样本方差 $s_Y^2$，并通过 $\\hat{\\sigma}^2(b) = s_Y^2 / m$ 估计样本均值的方差。这利用了在 $\\{Y_i\\}$ 独立的条件下，$\\operatorname{Var}\\left(\\frac{1}{m}\\sum_{i=1}^m Y_i\\right) = \\operatorname{Var}(Y_i)/m$ 的恒等式。\n3. 计算样本均值的朴素 IID 方差估计量 $\\hat{\\sigma}_{\\text{iid}}^2 = s_X^2 / n$，其中 $s_X^2$ 是 $\\{X_t\\}_{t=1}^n$ 的无偏样本方差。\n4. 通过对索引进行随机排列，创建序列的随机排列版本 $\\{X'_t\\}_{t=1}^n$。对于每个 $b$，通过分块方法从 $\\{X'_t\\}$ 计算 $\\hat{\\sigma}'^2(b)$，并将其与 $\\hat{\\sigma}_{\\text{iid}}^2$进行比较。\n5. 对每个测试用例，如果对于所有列出的块大小 $b$，相对误差 $\\left|\\hat{\\sigma}'^2(b) - \\hat{\\sigma}_{\\text{iid}}^2\\right| / \\hat{\\sigma}_{\\text{iid}}^2$ 都小于指定的容差 $\\varepsilon$，则生成一个布尔值 `True`；否则为 `False`。这验证了当顺序被打乱时，分块估计量会退化为 IID 方差。\n\n约束和实现细节：\n- 如果 $b$ 不能整除 $n$，则仅使用前 $m b$ 个点；在下面的测试套件中，每个 $b$ 都能整除 $n$，因此 $m$ 是一个整数。\n- 使用带有 Bessel 校正的无偏样本方差。\n- 每个测试用例使用一个固定的伪随机数生成器种子，以确保可复现性以及测试用例之间的随机性是独立的。\n\n测试套件：\n- 测试用例 1 (具有强自相关性的一般理想路径)：$n = 8192$, $\\phi = 0.8$, $\\sigma_\\epsilon = 1$, 块大小 $b \\in \\{1,2,4,8,16,32,64,128,256\\}$, 容差 $\\varepsilon = 0.08$。\n- 测试用例 2 (弱自相关性)：$n = 4096$, $\\phi = 0.2$, $\\sigma_\\epsilon = 1$, 块大小 $b \\in \\{1,2,4,8,16,32,64,128,256,512\\}$, 容差 $\\varepsilon = 0.08$。\n- 测试用例 3 (IID 边界, $\\phi = 0$)：$n = 4096$, $\\phi = 0$, $\\sigma_\\epsilon = 1$, 块大小 $b \\in \\{1,2,4,8,16,32,64,128,256,512\\}$, 容差 $\\varepsilon = 0.08$。\n- 测试用例 4 (具有极强自相关性和更广 $b$ 覆盖范围的边缘情况)：$n = 8192$, $\\phi = 0.95$, $\\sigma_\\epsilon = 1$, 块大小 $b \\in \\{1,2,4,8,16,32,64,128,256,512\\}$, 容差 $\\varepsilon = 0.08$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含所有四个测试用例的结果，形式为方括号内以逗号分隔的列表，例如 `[result1,result2,result3,result4]`，其中每个 `result` 是一个布尔值，指示在该测试用例中，对于所列出的所有块大小，退化条件是否成立。", "solution": "该任务旨在验证时间序列分析中用于误差估计的分块方法的一个核心原理。具体来说，我们将验证对于一个具有时间相关性的时间序列，随机排列其数据点会破坏这种相关性，从而导致分块方法对样本均值方差的估计值退化为用于独立同分布（IID）数据的更简单的公式。\n\n该验证将针对几个测试用例进行数值化执行，每个测试用例由一个一阶自回归模型（AR(1)）定义。对于每个用例，我们遵循一个精确的算法步骤。\n\n首先，我们从一个 AR(1) 过程中生成一个长度为 $n$ 的平稳时间序列 $\\{X_t\\}_{t=1}^n$，该过程由以下方程给出：\n$$X_t = \\phi X_{t-1} + \\epsilon_t$$\n其中 $\\phi$ 是满足 $|\\phi|  1$ 的自回归系数，$\\{\\epsilon_t\\}$ 是从均值为 0、方差为 $\\sigma_\\epsilon^2$ 的正态分布中抽取的 IID 高斯随机变量（新息），即 $\\epsilon_t \\sim \\mathcal{N}(0, \\sigma_\\epsilon^2)$。为确保平稳性，初始值 $X_0$ 从该过程的平稳分布中抽取，即方差为 $\\sigma_X^2 = \\sigma_\\epsilon^2 / (1 - \\phi^2)$ 的 $\\mathcal{N}(0, \\sigma_X^2)$ 分布。对于每个测试用例，都使用一个固定的伪随机数生成器种子以保证可复现性。\n\n其次，我们计算样本均值 $\\bar{X} = \\frac{1}{n} \\sum_{t=1}^n X_t$ 方差的标准 IID 估计量。这个我们记为 $\\hat{\\sigma}_{\\text{iid}}^2$ 的估计量仅在数据点不相关时有效。其计算公式为：\n$$\\hat{\\sigma}_{\\text{iid}}^2 = \\frac{s_X^2}{n}$$\n其中 $s_X^2$ 是时间序列 $\\{X_t\\}_{t=1}^n$ 的无偏样本方差，使用 Bessel's 校正计算：\n$$s_X^2 = \\frac{1}{n-1} \\sum_{t=1}^n (X_t - \\bar{X})^2$$\n\n第三，我们通过对原始序列 $\\{X_t\\}_{t=1}^n$ 的索引进行随机排列，创建一个排列后的时间序列 $\\{X'_t\\}_{t=1}^n$。此操作保留了值的集合，因此样本均值和方差 ($s_{X'}^2 = s_X^2$) 不变，但破坏了 AR(1) 过程中固有的时间相关结构。所得到的序列 $\\{X'_t\\}$ 是一个可交换序列。\n\n第四，对于排列后的序列 $\\{X'_t\\}$，我们对一系列块大小 $b$ 应用分块方法。该序列被划分为 $m = \\lfloor n/b \\rfloor$ 个不重叠的块。对于给定的测试用例，$n$ 总能被 $b$ 整除，因此 $m=n/b$。我们计算每个块的均值：\n$$Y'_i = \\frac{1}{b} \\sum_{t=(i-1)b+1}^{ib} X'_t \\quad \\text{for } i = 1, \\dots, m$$\n分块方法通过将这些块均值 $\\{Y'_i\\}_{i=1}^m$ 视为近似独立的数据点来估计样本均值的方差。该估计量我们记为 $\\hat{\\sigma}'^2(b)$，由下式给出：\n$$\\hat{\\sigma}'^2(b) = \\frac{s_{Y'}^2}{m}$$\n其中 $s_{Y'}^2$ 是块均值 $\\{Y'_i\\}$ 的无偏样本方差：\n$$s_{Y'}^2 = \\frac{1}{m-1} \\sum_{i=1}^m (Y'_i - \\bar{Y'})^2$$\n此处，$\\bar{Y'}$ 是块均值的均值，其数值上与总样本均值 $\\bar{X'}$ 相同。\n\n最后，我们执行验证。核心假设是，对于排列后的（时间上无结构的）数据，无论块大小 $b$ 如何，分块估计值 $\\hat{\\sigma}'^2(b)$ 都应与 IID 估计值 $\\hat{\\sigma}_{\\text{iid}}^2$ 一致。我们通过检查对于所有指定的块大小 $b$，两个估计值之间的相对误差是否小于给定的容差 $\\varepsilon$ 来检验这一点。对于每个测试用例，最终结果是一个布尔值，如果以下条件对其列表中的所有 $b$ 都成立，则为 `True`，否则为 `False`：\n$$\\frac{\\left| \\hat{\\sigma}'^2(b) - \\hat{\\sigma}_{\\text{iid}}^2 \\right|}{\\hat{\\sigma}_{\\text{iid}}^2}  \\varepsilon$$\n\n理论上，这种退化是预期的，因为对于一个可交换序列，块均值样本方差的期望值 $E[s_{Y'}^2]$ 可以被证明近似于 $b \\cdot \\operatorname{Var}(\\bar{X'})$，其中 $\\bar{X'}$ 是 $n$ 个相关抽样的样本均值。在我们这个对一组固定数字进行随机排列的情况下，通过方差分析（ANOVA）的论证，我们可以证明组间均方（MSB）的期望值等于数据的总体样本方差，即 $E[MSB] = s_X^2$。由于 $\\hat{\\sigma}'^2(b) = MSB/n$ 且 $\\hat{\\sigma}_{\\text{iid}}^2 = s_X^2/n$，我们预期它们的值会很接近。容差 $\\varepsilon$ 考虑了 MSB 围绕其期望值的统计波动，当块数 $m$ 较小时，这一点尤其重要。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the validation for all test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'n': 8192, 'phi': 0.8, 'sigma_eps': 1.0, 'block_sizes': [1, 2, 4, 8, 16, 32, 64, 128, 256], 'tolerance': 0.08},\n        {'n': 4096, 'phi': 0.2, 'sigma_eps': 1.0, 'block_sizes': [1, 2, 4, 8, 16, 32, 64, 128, 256, 512], 'tolerance': 0.08},\n        {'n': 4096, 'phi': 0.0, 'sigma_eps': 1.0, 'block_sizes': [1, 2, 4, 8, 16, 32, 64, 128, 256, 512], 'tolerance': 0.08},\n        {'n': 8192, 'phi': 0.95, 'sigma_eps': 1.0, 'block_sizes': [1, 2, 4, 8, 16, 32, 64, 128, 256, 512], 'tolerance': 0.08},\n    ]\n\n    results = []\n    # Use a different seed for each test case for independent experiments.\n    # The seeds are fixed to ensure the overall result is reproducible.\n    for i, case in enumerate(test_cases):\n        result = validate_blocking_collapse(**case, seed=i)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef validate_blocking_collapse(n, phi, sigma_eps, block_sizes, tolerance, seed):\n    \"\"\"\n    Performs the validation for a single test case.\n\n    Args:\n        n (int): Length of the time series.\n        phi (float): Autoregressive coefficient.\n        sigma_eps (float): Standard deviation of innovations.\n        block_sizes (list): List of block sizes to test.\n        tolerance (float): Relative error tolerance.\n        seed (int): Seed for the pseudorandom number generator.\n\n    Returns:\n        bool: True if the collapse condition holds for all block sizes, False otherwise.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n\n    # 1. Generate AR(1) time series\n    if abs(phi)  1.0:\n        var_x_stationary = sigma_eps**2 / (1 - phi**2)\n    else:\n        # This case is not expected based on problem constraints but included for robustness.\n        var_x_stationary = 1.0 \n    \n    x0 = rng.normal(loc=0, scale=np.sqrt(var_x_stationary))\n    innovations = rng.normal(loc=0, scale=sigma_eps, size=n)\n    \n    x = np.zeros(n)\n    x[0] = phi * x0 + innovations[0]\n    for t in range(1, n):\n        x[t] = phi * x[t-1] + innovations[t]\n        \n    # 2. Compute naive IID variance estimator for the sample mean\n    s_x_sq = np.var(x, ddof=1)\n    sigma_iid_sq = s_x_sq / n\n\n    # 3. Create a randomly permuted version of the series\n    x_prime = rng.permutation(x)\n\n    # 4. For each block size, compute the blocking estimator and check the condition\n    for b in block_sizes:\n        m = n // b\n        \n        # Ensure there are at least 2 blocks to compute variance\n        if m  2:\n            # According to problem specification, m is always >= 8.\n            # If for some reason m  2, the variance s_Y^2 is undefined.\n            # We treat this as a failure of the condition.\n            return False\n\n        # Reshape the permuted series into blocks\n        blocks = x_prime.reshape((m, b))\n        \n        # Compute means of the blocks\n        y_prime = np.mean(blocks, axis=1)\n        \n        # Compute the unbiased sample variance of the block means\n        s_y_prime_sq = np.var(y_prime, ddof=1)\n        \n        # Compute the blocking-based variance estimator for the sample mean\n        sigma_prime_sq_b = s_y_prime_sq / m\n\n        # 5. Check if the relative error is within the specified tolerance\n        if sigma_iid_sq == 0:\n            # This is extremely unlikely but would occur if all x_t are identical.\n            # If both estimators are 0, the error is 0. If not, it's infinite.\n            if sigma_prime_sq_b != 0:\n                return False\n        else:\n            relative_error = np.abs(sigma_prime_sq_b - sigma_iid_sq) / sigma_iid_sq\n            if relative_error >= tolerance:\n                # If the condition fails for any block size, the entire test case fails.\n                return False\n\n    # If the loop completes, the condition held for all block sizes.\n    return True\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3102616"}, {"introduction": "既然我们能够为一个给定的数据集正确地估计误差，我们就可以解决一个更高级也更实际的问题：我们需要收集多少数据才能达到预期的精度？这最后一个练习[@problem_id:3102661]将向您展示如何使用分块法来估计一个过程的“有效方差”。这个估计值随后可以用来预测达到特定精度所需的最小样本量，这对于设计高效的计算实验是一项至关重要的技能。", "problem": "给定一个单变量时间序列，要求使用分块方法来考虑时间自相关性，在置信水平受控的情况下，估计达到预设相对误差所需的最小样本量。推导必须从弱相关平稳序列的中心极限定理（CLT）和积分自相关时间的定义开始。算法必须通过显式构造分块平均值并外推稳定的分块方差来避免使用快捷公式。您的程序将为提供的测试套件生成合成时间序列，执行分块分析，并输出所需的最小样本量。\n\n起点和定义。考虑一个严平稳时间序列 $\\{X_t\\}_{t=1}^N$，其均值为 $\\mu$，方差为 $\\sigma_X^2$，自相关函数为 $\\rho_k = \\operatorname{Corr}(X_t,X_{t+k})$。根据弱相关序列的中心极限定理，样本均值 $\\bar{X} = \\frac{1}{N}\\sum_{t=1}^N X_t$ 近似服从正态分布，其均值为 $\\mu$，方差为\n$$\n\\operatorname{Var}(\\bar{X}) \\approx \\frac{\\sigma_X^2}{N}\\left(1 + 2\\sum_{k=1}^{\\infty}\\rho_k\\right) = \\frac{\\sigma_{\\mathrm{eff}}^2}{N},\n$$\n其中 $\\sigma_{\\mathrm{eff}}^2 = \\sigma_X^2 \\left(1 + 2\\sum_{k=1}^{\\infty}\\rho_k\\right)$ 是考虑了自相关性后每个独立样本的有效方差。在实践中，$\\sigma_{\\mathrm{eff}}^2$ 是未知的，必须从数据中估计。\n\n分块估计量。对于选定的块大小 $b \\in \\mathbb{N}$，定义 $N_b = \\left\\lfloor \\frac{N}{b} \\right\\rfloor$ 个不重叠的块和块均值\n$$\nY_j = \\frac{1}{b}\\sum_{i=1}^{b} X_{(j-1)b + i}, \\quad j = 1,\\dots,N_b.\n$$\n令 $s_Y^2(b)$ 表示 $\\{Y_j\\}_{j=1}^{N_b}$ 的无偏样本方差。有效方差的一个标准分块估计量是\n$$\n\\hat{\\sigma}^2(b) = b \\, s_Y^2(b),\n$$\n理想情况下，当 $b \\to \\infty$ 时，该值会稳定（接近一个平台期），反映出 $\\sigma_{\\mathrm{eff}}^2$。为了既能正则化有限 $b$ 的效应，又能确保在块级别有足够的平均以满足中心极限定理，仅使用那些 $N_b \\geq 30$ 的块大小，并将 $\\hat{\\sigma}^2(b)$ 作为 $1/b$ 的函数线性外推到 $1/b \\to 0$。\n\n目标误差准则。对于目标相对误差 $\\epsilon  0$ 和由标准正态分位数 $z  0$ 编码的双侧置信水平，要求\n$$\nz \\, \\frac{\\hat{\\sigma}}{\\sqrt{N}} \\le \\epsilon \\, |\\bar{X}|,\n$$\n其中 $\\hat{\\sigma} = \\sqrt{\\hat{\\sigma}^2}$ 是外推得到的有效标准差，$\\bar{X}$ 是整个序列的样本均值。求解满足此不等式的最小整数 $N$。\n\n算法要求。\n- 将块大小 $b$ 的序列构造为 2 的幂，即 $b \\in \\{2^k: k \\in \\mathbb{N}_0\\}$，并限制在那些满足 $N_b = \\left\\lfloor \\frac{N}{b} \\right\\rfloor \\ge 30$ 的块大小。对于每个这样的 $b$，计算 $\\hat{\\sigma}^2(b) = b \\, s_Y^2(b)$，其中 $s_Y^2(b)$ 使用无偏除数 $N_b - 1$ 计算。仅使用前 $M = b N_b$ 个样本来形成完整的块。\n- 对选定的 $b$ 值，对 $y = \\hat{\\sigma}^2(b)$ 和 $x = 1/b$ 进行线性回归，以获得在 $x = 0$ 处的截距，该截距定义了外推的 $\\hat{\\sigma}^2$。如果由于抽样变异性导致外推的截距为负，则在取平方根之前将其限制为 $0$。\n- 使用所有 $N$ 个可用样本计算 $\\bar{X}$。\n- 计算最小整数\n$$\nN_{\\min} = \\left\\lceil \\left(\\frac{z \\, \\hat{\\sigma}}{\\epsilon \\, |\\bar{X}|}\\right)^2 \\right\\rceil.\n$$\n如果 $|\\bar{X}|$ 在数值上极小，则使用一个小的正数下限（如 $10^{-15}$）以避免除以零。对于给定的测试套件，假设 $\\bar{X} \\ne 0$。\n\n测试套件。您的程序必须通过在内部生成时间序列来实现以下四个确定性测试用例，每个序列的长度为 $N_0 = 65536$：\n\n- 案例 1（独立同分布 (IID) 正态）：$\\mu = 1.0$，$\\sigma_X = 2.0$，种子 $= 20231102$，$\\epsilon = 0.05$，$z = 1.96$。\n- 案例 2（一阶自回归 (AR(1))）：$\\phi = 0.7$，$\\mu = 1.0$，平稳标准差 $\\sigma_X = 2.0$，种子 $= 20231103$，$\\epsilon = 0.05$，$z = 1.96$。通过 $X_t = \\mu + \\phi (X_{t-1} - \\mu) + \\eta_t$ 生成过程，其中 $\\eta_t \\sim \\mathcal{N}(0,\\sigma_\\eta^2)$ 且 $\\sigma_\\eta = \\sigma_X \\sqrt{1 - \\phi^2}$，并从平稳分布 $\\mathcal{N}(\\mu,\\sigma_X^2)$ 中初始化 $X_1$。\n- 案例 3（AR(1)，更强相关性）：$\\phi = 0.95$，$\\mu = 1.0$，$\\sigma_X = 2.0$，种子 $= 20231104$，$\\epsilon = 0.05$，$z = 1.96$，生成方式同案例 2。\n- 案例 4（均值较小的 IID 正态）：$\\mu = 0.1$，$\\sigma_X = 1.0$，种子 $= 20231105$，$\\epsilon = 0.02$，$z = 1.96$。\n\n输出规范。您的程序必须生成单行，包含四个整数的列表 $ [N_{\\min}^{(1)}, N_{\\min}^{(2)}, N_{\\min}^{(3)}, N_{\\min}^{(4)}] $，顺序如此，除逗号外无多余空格。例如，输出格式必须与 $[123,456,789,1011]$ 完全一样。", "solution": "该问题是有效的，因为它科学上合理、提法明确、客观，并提供了一套完整且一致的指令。任务是估计一个平稳时间序列样本均值达到指定相对误差 $\\epsilon$ 所需的最小样本量 $N_{\\min}$，同时考虑了自相关性。该方法基于用于估计样本均值有效方差的分块方法，并结合了线性外推。解决方案涉及生成合成时间序列，执行分块分析，并为四个不同的测试用例计算 $N_{\\min}$。\n\n方法论的基础是弱相关平稳序列的中心极限定理。对于一个时间序列 $\\{X_t\\}_{t=1}^N$，其均值为 $\\mu$，方差为 $\\sigma_X^2$，样本均值 $\\bar{X} = \\frac{1}{N}\\sum_{t=1}^N X_t$ 近似服从正态分布，其均值为 $\\mu$，方差由下式给出：\n$$\n\\operatorname{Var}(\\bar{X}) \\approx \\frac{\\sigma_X^2}{N}\\left(1 + 2\\sum_{k=1}^{\\infty}\\rho_k\\right) = \\frac{\\sigma_{\\mathrm{eff}}^2}{N}\n$$\n其中 $\\rho_k$ 是滞后为 $k$ 的自相关系数，$\\sigma_{\\mathrm{eff}}^2$ 是有效方差。这个有效方差捕捉了相关性对样本均值不确定性的影响。我们的目标是从数据中估计 $\\sigma_{\\mathrm{eff}}^2$。\n\n问题为每个测试用例指定了需要实现的详细算法。\n\n**第 1 部分：时间序列生成**\n对于每个测试用例，根据提供的参数生成一个长度为 $N_0 = 65536$ 的时间序列。通过为每个案例使用指定的随机数生成器种子来确保结果的确定性。\n\n- **独立同分布 (IID) 正态序列（案例 1 和 4）**：序列 $\\{X_t\\}$ 通过从正态分布 $\\mathcal{N}(\\mu, \\sigma_X^2)$ 中抽取 $N_0$ 个样本生成，其中均值 $\\mu$ 和标准差 $\\sigma_X$ 由具体案例给出。\n\n- **一阶自回归 (AR(1)) 序列（案例 2 和 3）**：AR(1) 过程由以下递推关系定义：\n$$\nX_t = \\mu + \\phi (X_{t-1} - \\mu) + \\eta_t\n$$\n其中 $\\phi$ 是自回归系数，$\\{\\eta_t\\}$ 是一个白噪声过程，$\\eta_t \\sim \\mathcal{N}(0, \\sigma_\\eta^2)$。为确保该过程具有期望的平稳标准差 $\\sigma_X$，新息项 $\\eta_t$ 的方差设置为 $\\sigma_\\eta^2 = \\sigma_X^2(1 - \\phi^2)$。生成过程首先从平稳分布 $\\mathcal{N}(\\mu, \\sigma_X^2)$ 中抽取第一个点 $X_1$。随后的点 $X_t$（对于 $t=2, \\dots, N_0$）使用递推关系迭代生成。\n\n**第 2 部分：分块分析与方差外推**\n生成时间序列后，使用带有外推的分块方法估计有效方差 $\\sigma_{\\mathrm{eff}}^2$。\n\n1.  **选择块大小**：分析使用 2 的幂作为块大小，即 $b = 2^k$，$k = 0, 1, 2, \\dots$。一个块大小 $b$ 仅在它能产生至少 $N_b = \\lfloor N_0/b \\rfloor \\ge 30$ 个块时才被认为是有效的。这个条件确保了中心极限定理可以合理地应用于块均值本身。对于 $N_0=65536$，有效的块大小为 $b \\in \\{1, 2, 4, \\dots, 2048\\}$。\n\n2.  **计算分块方差**：对于每个有效的块大小 $b$，执行以下步骤：\n    a. 将时间序列划分为 $N_b = \\lfloor N_0/b \\rfloor$ 个不重叠的大小为 $b$ 的块。由于 $N_0 = 2^{16}$，对于所有有效的块大小 $b=2^k$，除法是精确的，所有 $N_0$ 个数据点都被使用。\n    b. 计算每个块的均值，$Y_j = \\frac{1}{b}\\sum_{i=1}^{b} X_{(j-1)b + i}$，其中 $j = 1, \\dots, N_b$。\n    c. 使用 $N_b - 1$ 作为除数，计算这些块均值的无偏样本方差 $s_Y^2(b)$。\n    d. 计算该块大小的分块方差估计量 $\\hat{\\sigma}^2(b) = b \\cdot s_Y^2(b)$。随着 $b$ 的增加，块内的相关性被平均掉，块均值 $Y_j$ 变得越来越不相关。在极限 $b \\to \\infty$ 时，$Y_j$ 变得有效独立，$\\hat{\\sigma}^2(b)$ 收敛于 $\\sigma_{\\mathrm{eff}}^2$。\n\n3.  **线性外推**：估计量 $\\hat{\\sigma}^2(b)$ 存在有限尺寸偏差，对于大的 $b$，该偏差通常与 $1/b$ 成正比。为了校正这一点，我们外推到极限 $b \\to \\infty$（即 $1/b \\to 0$）。收集所有有效块大小的配对 $(x, y) = (1/b, \\hat{\\sigma}^2(b))$。对 $y$ 关于 $x$ 进行简单线性回归。所得回归线的截距提供了有效方差的外推估计值，记为 $\\hat{\\sigma}^2$。如果抽样波动导致截距为负，它在物理上是无意义的，将被限制为 $0$。有效标准差的最终估计值为 $\\hat{\\sigma} = \\sqrt{\\hat{\\sigma}^2}$。\n\n**第 3 部分：计算最小样本量**\n有了估计的有效标准差 $\\hat{\\sigma}$ 和全样本均值 $\\bar{X} = \\frac{1}{N_0}\\sum_{t=1}^{N_0} X_t$，问题是找到满足目标误差准则的最小样本量 $N_{\\min}$：\n$$\nz \\, \\frac{\\hat{\\sigma}}{\\sqrt{N_{\\min}}} \\le \\epsilon \\, |\\bar{X}|\n$$\n这里，$z$ 是对应于所需置信水平的标准正态分位数（例如，对于 $95\\%$ 置信度，$z=1.96$），$\\epsilon$ 是目标相对误差。解出 $N_{\\min}$ 得：\n$$\nN_{\\min} \\ge \\left(\\frac{z \\, \\hat{\\sigma}}{\\epsilon \\, |\\bar{X}|}\\right)^2\n$$\n由于 $N_{\\min}$ 必须是一个整数，我们取右侧表达式的向上取整（ceiling）：\n$$\nN_{\\min} = \\left\\lceil \\left(\\frac{z \\, \\hat{\\sigma}}{\\epsilon \\, |\\bar{X}|}\\right)^2 \\right\\rceil\n$$\n对四个测试用例中的每一个都执行此计算，以产生最终输出。问题陈述保证了 $\\bar{X}$ 不会病态地接近于零，因此对于这个特定的测试套件，不需要特殊处理除以零的情况。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import linregress\n\ndef generate_series(params):\n    \"\"\"\n    Generates a time series based on the provided parameters.\n    \"\"\"\n    N0 = params['N0']\n    mu = params['mu']\n    sigma_x = params['sigma_x']\n    seed = params['seed']\n    series_type = params['type']\n    \n    rng = np.random.default_rng(seed)\n\n    if series_type == 'iid':\n        return rng.normal(loc=mu, scale=sigma_x, size=N0)\n    elif series_type == 'ar1':\n        phi = params['phi']\n        sigma_eta = sigma_x * np.sqrt(1 - phi**2)\n        \n        x = np.zeros(N0)\n        # Initialize with a draw from the stationary distribution\n        x[0] = rng.normal(loc=mu, scale=sigma_x)\n        \n        # Generate the rest of the series\n        for t in range(1, N0):\n            eta_t = rng.normal(loc=0, scale=sigma_eta)\n            x[t] = mu + phi * (x[t-1] - mu) + eta_t\n        return x\n    else:\n        raise ValueError(f\"Unknown series type: {series_type}\")\n\ndef estimate_effective_variance(series, N0):\n    \"\"\"\n    Estimates the effective variance using the blocking method with extrapolation.\n    \"\"\"\n    # 1. Determine valid block sizes\n    block_sizes = []\n    k = 0\n    while True:\n        b = 2**k\n        if N0 // b  30:\n            break\n        block_sizes.append(b)\n        k += 1\n\n    # 2. Calculate blocked variance for each block size\n    blocked_variances = []\n    inv_block_sizes = []\n\n    for b in block_sizes:\n        Nb = N0 // b\n        # Since N0 is a power of 2, N0 is divisible by all valid b, so M=N0\n        M = Nb * b\n        \n        # Reshape data into blocks\n        block_data = series[:M].reshape(Nb, b)\n        \n        # Calculate block means\n        block_means = block_data.mean(axis=1)\n        \n        # Calculate unbiased variance of block means (ddof=1)\n        s_Y_sq = np.var(block_means, ddof=1)\n        \n        # Calculate the blocked variance estimator\n        sigma_hat_sq_b = b * s_Y_sq\n        \n        blocked_variances.append(sigma_hat_sq_b)\n        inv_block_sizes.append(1/b)\n\n    # 3. Perform linear extrapolation\n    # regression of y = sigma_hat_sq_b on x = 1/b\n    regression_result = linregress(x=inv_block_sizes, y=blocked_variances)\n    \n    # The intercept is the extrapolated value at 1/b = 0\n    sigma_sq_extrapolated = regression_result.intercept\n    \n    # Clamp to 0 if negative\n    sigma_sq_extrapolated = max(0, sigma_sq_extrapolated)\n    \n    return sigma_sq_extrapolated\n\ndef calculate_n_min(series, sigma_hat_sq, params):\n    \"\"\"\n    Calculates the minimum required sample size N_min.\n    \"\"\"\n    z = params['z']\n    epsilon = params['epsilon']\n    \n    sigma_hat = np.sqrt(sigma_hat_sq)\n    x_bar = np.mean(series)\n    \n    # Per problem statement, abs(x_bar) is not pathologically small for test cases.\n    # The minimum positive floor is not strictly necessary but good practice.\n    abs_x_bar = abs(x_bar)\n    if abs_x_bar  1e-15:\n        abs_x_bar = 1e-15\n\n    # Calculate N_min\n    n_min_float = (z * sigma_hat / (epsilon * abs_x_bar))**2\n    n_min = int(np.ceil(n_min_float))\n    \n    return n_min\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the results.\n    \"\"\"\n    N0 = 65536\n    test_cases = [\n        # Case 1 (IID normal)\n        {'type': 'iid', 'mu': 1.0, 'sigma_x': 2.0, 'seed': 20231102, 'epsilon': 0.05, 'z': 1.96, 'N0': N0},\n        # Case 2 (AR(1))\n        {'type': 'ar1', 'phi': 0.7, 'mu': 1.0, 'sigma_x': 2.0, 'seed': 20231103, 'epsilon': 0.05, 'z': 1.96, 'N0': N0},\n        # Case 3 (AR(1), stronger correlation)\n        {'type': 'ar1', 'phi': 0.95, 'mu': 1.0, 'sigma_x': 2.0, 'seed': 20231104, 'epsilon': 0.05, 'z': 1.96, 'N0': N0},\n        # Case 4 (IID normal with small mean)\n        {'type': 'iid', 'mu': 0.1, 'sigma_x': 1.0, 'seed': 20231105, 'epsilon': 0.02, 'z': 1.96, 'N0': N0},\n    ]\n\n    results = []\n    for params in test_cases:\n        # 1. Generate the time series\n        series = generate_series(params)\n        \n        # 2. Estimate the effective variance\n        sigma_hat_sq = estimate_effective_variance(series, N0)\n        \n        # 3. Calculate the minimum sample size\n        n_min = calculate_n_min(series, sigma_hat_sq, params)\n        \n        results.append(n_min)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3102661"}]}