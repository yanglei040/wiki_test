{"hands_on_practices": [{"introduction": "在信任任何模拟结果之前，我们必须验证代码是否正确实现了预期的数值模型。对于逼近连续系统的方法，一项基本的验证技术是收敛阶测试。该测试通过确认数值误差是否随着网格分辨率的提高而以理论预测的速率减小，来验证模型的正确性。本练习 ([@problem_id:3097495]) 将指导您完成对几种有限差分格式的这一基本验证过程。", "problem": "给定一个定义在区间 $[0,2\\pi]$ 上的周期性标量场 $u(x)$，其中 $u(x)=\\sin(x)$，角度以弧度为单位。考虑使用三种有限差分格式（向前差分、二阶中心差分和四阶中心差分）在均匀周期性网格上近似空间导数 $u'(x)$ 的数值模拟。您的任务是分析多种网格分辨率下的模拟输出，通过计算输出误差的离散 $L^2$ 和 $L^\\infty$ 范数，并在对数-对数坐标上拟合斜率，以验证观察到的精度阶数。\n\n使用的基本核心定义：\n- 均匀网格有 $N$ 个点，间距为 $h=\\frac{2\\pi}{N}$，网格点为 $x_i = i h$，其中 $i=0,1,\\dots,N-1$，具有周期性边界条件。\n- 精确导数为 $u'(x)=\\cos(x)$。\n- 导数的向前差分格式为 $D_f u_i = \\frac{u_{i+1}-u_i}{h}$，并采用周期性环绕处理 $u_{N}\\equiv u_0$。\n- 导数的二阶中心差分格式为 $D_c u_i = \\frac{u_{i+1}-u_{i-1}}{2h}$，并采用周期性环绕处理。\n- 导数的四阶中心差分格式为 $D_4 u_i = \\frac{-u_{i+2}+8u_{i+1}-8u_{i-1}+u_{i-2}}{12h}$，并采用周期性环绕处理。\n- 周期性网格上的离散 $L^2$ 误差范数定义为 $\\lVert e \\rVert_{2,h} = \\sqrt{h \\sum_{i=0}^{N-1} e_i^2}$，对于均匀的 $h$，它一致地近似了 $[0,2\\pi]$ 上的连续 $L^2$ 范数。\n- 离散 $L^\\infty$ 误差范数定义为 $\\lVert e \\rVert_{\\infty} = \\max_{0 \\le i \\le N-1} |e_i|$。\n- 如果一个 $p$ 阶方法的误差缩放满足 $E(h) \\approx C h^p$（其中 $C$ 为某个常数），则取自然对数可得 $\\ln(E(h)) \\approx \\ln(C) + p \\ln(h)$。因此，通过最小二乘法对点集 $\\left(\\ln(h), \\ln(E(h))\\right)$ 进行直线拟合，所得斜率即为观察到的阶数 $p$。\n\n您的程序必须实现上述三种格式，为周期性网格上的 $u(x)=\\sin(x)$ 生成模拟输出（数值导数），为每个网格计算误差数组 $e_i = D u_i - \\cos(x_i)$，为每个网格分辨率评估 $\\lVert e \\rVert_{2,h}$ 和 $\\lVert e \\rVert_{\\infty}$，然后通过拟合 $\\ln(E)$ 相对于 $\\ln(h)$ 的斜率来估计两种范数下的阶数 $p$。\n\n测试套件：\n- 测试用例 $1$（正常路径，一阶方法）：向前差分，网格尺寸为 $\\{32,64,128,256\\}$。\n- 测试用例 $2$（正常路径，二阶方法）：二阶中心差分，网格尺寸为 $\\{16,32,64,128\\}$。\n- 测试用例 $3$（高阶方法）：四阶中心差分，网格尺寸为 $\\{8,16,32,64,128\\}$。\n- 测试用例 $4$（为保证稳定性的细网格覆盖）：二阶中心差分，网格尺寸为 $\\{128,256,512,1024,2048,4096\\}$。\n\n对于每个测试用例，计算两个浮点数：从 $L^2$ 范数得到的估计斜率 $p$ 和从 $L^\\infty$ 范数得到的估计斜率 $p$，两者都通过对给定网格尺寸下的 $\\ln(E)$ 与 $\\ln(h)$ 进行最小二乘拟合获得。角度必须以弧度处理。无需进行物理单位转换。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果必须是一个包含两个浮点数的列表 $[p_{L^2},p_{L^\\infty}]$，每个浮点数四舍五入到三位小数。例如，输出应类似于 $[[p_{11},p_{12}],[p_{21},p_{22}],\\dots]$，逗号之间没有空格。\n\n每个测试用例的答案是包含两个浮点数的列表。整个程序必须是一个完整的、可运行的程序，能够产生上述单行输出，无需任何用户输入。", "solution": "该问题要求我们对用于近似周期函数一阶导数的三种有限差分格式，经验性地验证其精度阶数。这是计算科学中验证模拟代码的一项基本流程。该分析涉及在不同分辨率的网格上计算数值导数，计算与精确解的误差，并确定当网格间距 $h$ 减小时误差的收敛率。\n\n该方法包括四个主要步骤：网格离散化、应用数值格式、误差计算以及通过在对数-对数坐标上进行线性回归来估计精度阶数。\n\n**1. 域和函数的离散化**\n问题设定在一维周期域 $[0, 2\\pi]$ 上。该域被离散化为一个包含 $N$ 个点的均匀网格，索引从 $i=0$ 到 $i=N-1$。网格点位于 $x_i = i h$，其中网格间距（或分辨率）为 $h = \\frac{2\\pi}{N}$。\n给定的标量场为 $u(x) = \\sin(x)$，在每个网格点上对其求值，形成一个离散的函数值向量 $u_i = u(x_i) = \\sin(i h)$。作为我们误差分析基准的解析导数是 $u'(x) = \\cos(x)$，给出精确的离散值 $u'_i = u'(x_i) = \\cos(i h)$。\n\n**2. 一阶导数的有限差分格式**\n我们使用网格上的离散值 $u_i$ 来近似导数 $u'(x_i)$。问题指定了三种格式。通过确保网格索引采用环绕处理来施加周期性，即索引 $j$ 被处理为 $j \\pmod N$。\n\n- **向前差分 ($D_f$)**：一种单边、一阶精度的格式。\n$$ D_f u_i = \\frac{u_{i+1} - u_i}{h} $$\n该方法的截断误差主项与 $h$ 成正比，因此其预期精度阶数为 $p=1$。\n\n- **二阶中心差分 ($D_c$)**：一种对称、二阶精度的格式。\n$$ D_c u_i = \\frac{u_{i+1} - u_{i-1}}{2h} $$\n其截断误差与 $h^2$ 成正比，因此其预期精度阶数为 $p=2$。\n\n- **四阶中心差分 ($D_4$)**：一种更宽的、对称的、四阶精度的格式。\n$$ D_4 u_i = \\frac{-u_{i+2} + 8u_{i+1} - 8u_{i-1} + u_{i-2}}{12h} $$\n其截断误差与 $h^4$ 成正比，因此其预期精度阶数为 $p=4$。\n\n对于每种格式，都会为所有点 $i=0, \\dots, N-1$ 计算一个数值导数值向量 $(D u)_i$。\n\n**3. 误差计算和范数**\n数值近似的误差由误差向量 $e$ 捕获，其中每个分量是数值导数和精确导数之间的逐点差：\n$$ e_i = (D u)_i - u'(x_i) $$\n为了量化该误差向量的总体大小，我们为每个网格分辨率 $N$ 计算两种不同的范数。\n\n- **离散 $L^2$ 范数 ($\\lVert e \\rVert_{2,h}$)**：该范数是连续 $L^2$ 范数的离散模拟，用于衡量整个网格上的均方根误差。其定义为：\n$$ \\lVert e \\rVert_{2,h} = \\sqrt{h \\sum_{i=0}^{N-1} e_i^2} $$\n因子 $\\sqrt{h}$ 确保该离散范数是连续积分范数 $\\left(\\int_0^{2\\pi} e(x)^2 dx\\right)^{1/2}$ 的一个一致近似。\n\n- **$L^\\infty$ 范数 ($\\lVert e \\rVert_{\\infty}$)**：也称为最大范数，它衡量网格上最坏情况下的逐点误差：\n$$ \\lVert e \\rVert_{\\infty} = \\max_{0 \\le i \\le N-1} |e_i| $$\n\n**4. 精度阶数验证**\n如果一个数值方法的误差 $E$ 随网格间距 $h$ 的变化关系满足 $E(h) \\approx C h^p$（其中 $C$ 为某个常数，且 $h \\to 0$），则该方法的精度阶数为 $p$。为了从模拟数据中确定 $p$，我们为一系列具有逐渐减小的网格间距 $h_j$ 的模拟计算误差 $E$（同时使用 $L^2$ 和 $L^\\infty$ 范数）。\n\n通过对该缩放关系取自然对数，我们得到一个线性方程：\n$$ \\ln(E(h)) \\approx \\ln(C) + p \\ln(h) $$\n这表明 $\\ln(E)$ 相对于 $\\ln(h)$ 的图将近似为一条斜率为 $p$ 的直线。因此，我们可以通过对模拟生成的数据点集 $(\\ln(h_j), \\ln(E_j))$ 进行线性最小二乘拟合来估计观察到的精度阶数。所得最佳拟合直线的斜率即为 $p$ 的经验值。\n\n指定的测试用例提供了不同的格式和网格尺寸集 $\\{N\\}$，使我们能够执行此分析，并将观察到的阶数与每种方法的理论期望值进行比较。例如，对于测试用例 1（向前差分），我们预期两种范数下的斜率都接近于 $1$。对于测试用例 3（四阶中心差分），我们预期斜率接近于 $4$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the observed order of accuracy for three finite-difference stencils\n    by analyzing simulation error norms on a log-log scale.\n    \"\"\"\n\n    # Define the finite-difference stencil functions\n    def forward_diff(u, h):\n        \"\"\"Computes the derivative using a first-order forward-difference stencil.\"\"\"\n        return (np.roll(u, -1) - u) / h\n\n    def central_diff2(u, h):\n        \"\"\"Computes the derivative using a second-order central-difference stencil.\"\"\"\n        return (np.roll(u, -1) - np.roll(u, 1)) / (2 * h)\n\n    def central_diff4(u, h):\n        \"\"\"Computes the derivative using a fourth-order central-difference stencil.\"\"\"\n        return (-np.roll(u, -2) + 8 * np.roll(u, -1) - 8 * np.roll(u, 1) + np.roll(u, 2)) / (12 * h)\n\n    # Define the test cases as a list of tuples: (stencil_function, list_of_N_values)\n    test_cases = [\n        (forward_diff, [32, 64, 128, 256]),\n        (central_diff2, [16, 32, 64, 128]),\n        (central_diff4, [8, 16, 32, 64, 128]),\n        (central_diff2, [128, 256, 512, 1024, 2048, 4096])\n    ]\n\n    all_results = []\n\n    # Process each test case\n    for stencil_func, N_values in test_cases:\n        h_vals = []\n        l2_errors = []\n        linf_errors = []\n\n        # Run simulation for each grid size N\n        for N in N_values:\n            h = 2 * np.pi / N\n            h_vals.append(h)\n            \n            # Create the grid and evaluate the function and its exact derivative\n            x = np.linspace(0, 2 * np.pi, N, endpoint=False)\n            u = np.sin(x)\n            u_prime_exact = np.cos(x)\n            \n            # Compute the numerical derivative using the specified stencil\n            u_prime_numerical = stencil_func(u, h)\n            \n            # Compute the error vector\n            error_vec = u_prime_numerical - u_prime_exact\n            \n            # Compute and store the L2 and L-infinity error norms\n            l2_error = np.sqrt(h * np.sum(error_vec**2))\n            l2_errors.append(l2_error)\n            \n            linf_error = np.max(np.abs(error_vec))\n            linf_errors.append(linf_error)\n\n        # Convert lists to numpy arrays for vectorized operations\n        h_vals_np = np.array(h_vals)\n        l2_errors_np = np.array(l2_errors)\n        linf_errors_np = np.array(linf_errors)\n\n        # Take the natural log of h and the error norms\n        log_h = np.log(h_vals_np)\n        log_l2_err = np.log(l2_errors_np)\n        log_linf_err = np.log(linf_errors_np)\n\n        # Perform linear regression to find the slope (order of accuracy, p)\n        # np.polyfit(x, y, 1) returns [slope, intercept]\n        p_l2 = np.polyfit(log_h, log_l2_err, 1)[0]\n        p_linf = np.polyfit(log_h, log_linf_err, 1)[0]\n        \n        all_results.append([p_l2, p_linf])\n        \n    # Format the final output string exactly as required\n    formatted_results = []\n    for p_l2, p_linf in all_results:\n        formatted_results.append(f\"[{p_l2:.3f},{p_linf:.3f}]\")\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3097495"}, {"introduction": "许多模拟包含随机性，即使参数完全相同，每次运行也会产生不同的结果。因此，确保这些结果在统计上是稳定且可复现的至关重要。本练习 ([@problem_id:3097442]) 介绍了一个严谨的框架，用于量化不同运行间的可变性，并为可复现性定义清晰的、基于度量的标准。", "problem": "您正在分析一个随机模拟的输出。对于固定的参数化，该模拟产生标量观测值，其分布可被假定为独立同分布。为了量化不同随机种子下运行间的变异性，并测试关键输出指标的可复现性阈值，请实现以下基于大数定律和中心极限定理 (CLT) 的程序。\n\n基本定义：\n- 对于有限集 $S$ 中的每个随机种子 $s$，模拟会从一个真实均值为 $\\mu$、真实标准差为 $\\sigma$ 的正态分布中，产生 $K$ 个独立的标量观测值 $x_{s,1}, x_{s,2}, \\dots, x_{s,K}$。用数学符号表示为，$x_{s,i} \\sim \\mathcal{N}(\\mu, \\sigma^2)$，并且对于固定的 $s$，$\\{x_{s,i}\\}_{i=1}^K$ 是独立的。\n- 对于每个种子 $s$，将种子级别的样本均值和方差定义为\n  $$ m_s = \\frac{1}{K} \\sum_{i=1}^{K} x_{s,i}, \\quad v_s = \\frac{1}{K-1} \\sum_{i=1}^{K} \\left(x_{s,i} - m_s\\right)^2, \\quad s_s = \\sqrt{v_s}. $$\n- 跨种子地，将种子均值的总均值和种子均值的跨种子标准差定义为\n  $$ \\bar{m} = \\frac{1}{|S|} \\sum_{s \\in S} m_s, \\quad sd_m = \\sqrt{\\frac{1}{|S| - 1} \\sum_{s \\in S} \\left(m_s - \\bar{m}\\right)^2}. $$\n- 跨种子地，将种子标准差的总均值和种子标准差的跨种子标准差定义为\n  $$ \\bar{s} = \\frac{1}{|S|} \\sum_{s \\in S} s_s, \\quad sd_{sd} = \\sqrt{\\frac{1}{|S| - 1} \\sum_{s \\in S} \\left(s_s - \\bar{s}\\right)^2}. $$\n- 将种子均值的相对跨种子变异性定义为\n  $$ rv_m = \\begin{cases}\n  \\dfrac{sd_m}{|\\bar{m}|},  \\text{if } |\\bar{m}| \\ge \\varepsilon, \\\\\n  \\dfrac{sd_m}{\\bar{s}},  \\text{if } |\\bar{m}|  \\varepsilon,\n  \\end{cases} $$\n  其中 $\\varepsilon  0$ 是一个指定的小阈值。\n- 将种子标准差的相对跨种子变异性定义为\n  $$ rv_{sd} = \\frac{sd_{sd}}{\\bar{s}}. $$\n- 将均值和标准差的成对一致性比例分别定义为\n  $$ f_m = \\frac{1}{\\binom{|S|}{2}} \\left|\\left\\{ \\{s,t\\} \\subset S, s \\ne t : |m_s - m_t| \\le \\Delta_m \\right\\}\\right|, $$\n  $$ f_{sd} = \\frac{1}{\\binom{|S|}{2}} \\left|\\left\\{ \\{s,t\\} \\subset S, s \\ne t : |s_s - s_t| \\le \\Delta_{sd} \\right\\}\\right|. $$\n- 根据中心极限定理 (CLT)，种子级别的样本均值 $m_s$ 近似服从正态分布，其标准误差为 $s_s / \\sqrt{K}$。对每个种子 $s$ 使用由下式定义的双边名义95%置信区间\n  $$ CI_s = \\left[m_s - z \\cdot \\frac{s_s}{\\sqrt{K}},\\; m_s + z \\cdot \\frac{s_s}{\\sqrt{K}}\\right], $$\n  其中 $z$ 是标准正态分布的第97.5百分位数，即 $z \\approx 1.959963984540054$。定义覆盖率\n  $$ c = \\frac{1}{|S|} \\left|\\left\\{ s \\in S : \\bar{m} \\in CI_s \\right\\}\\right|. $$\n\n可复现性决策规则：\n- 当且仅当 $rv_m \\le \\tau_m$ 且 $f_m \\ge p_m$ 时，均值指标被宣告为可复现的。\n- 当且仅当 $rv_{sd} \\le \\tau_{sd}$ 且 $f_{sd} \\ge p_{sd}$ 时，变异性指标（每个种子内观测值的标准差）被宣告为可复现的。\n- 当且仅当 $c \\ge q$ 时，CLT覆盖率测试宣告为通过。\n\n实现要求：\n- 对于每个测试用例，您必须使用由给定的 $s \\in S$ 作为种子的伪随机数生成器，严格按照 $x_{s,i} \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 生成种子级别的观测值，以确保确定性行为。\n- 使用上述公式计算 $m_s$、$s_s$、$\\bar{m}$、$sd_m$、$\\bar{s}$、$sd_{sd}$、$rv_m$、$rv_{sd}$、$f_m$、$f_{sd}$ 和 $c$，然后评估决策规则。\n- 每个测试用例的最终答案必须是一个包含三个整数的列表 $[M, D, C]$，其中如果均值指标是可复现的，则 $M$ 为 $1$，否则为 $0$；如果变异性指标是可复现的，则 $D$ 为 $1$，否则为 $0$；如果CLT覆盖率测试通过，则 $C$ 为 $1$，否则为 $0$。\n\n测试套件：\n- 测试用例 A (正常路径)：\n  - 参数：$\\mu = 5.0$, $\\sigma = 2.0$, $K = 1000$, $S = \\{0, 1, 2, \\dots, 19\\}$, $\\varepsilon = 10^{-8}$。\n  - 阈值：$\\tau_m = 0.03$, $\\Delta_m = 0.15$, $p_m = 0.9$, $\\tau_{sd} = 0.05$, $\\Delta_{sd} = 0.12$, $p_{sd} = 0.9$, $q = 0.9$。\n- 测试用例 B (小样本，严格阈值)：\n  - 参数：$\\mu = 5.0$, $\\sigma = 2.0$, $K = 30$, $S = \\{0, 1, 2, \\dots, 9\\}$, $\\varepsilon = 10^{-8}$。\n  - 阈值：$\\tau_m = 0.03$, $\\Delta_m = 0.25$, $p_m = 0.9$, $\\tau_{sd} = 0.05$, $\\Delta_{sd} = 0.20$, $p_{sd} = 0.9$, $q = 1.0$。\n- 测试用例 C (均值接近于零，必要时启用备用归一化)：\n  - 参数：$\\mu = 0.0$, $\\sigma = 1.0$, $K = 500$, $S = \\{100, 101, 102, \\dots, 114\\}$, $\\varepsilon = 10^{-8}$。\n  - 阈值：$\\tau_m = 0.06$, $\\Delta_m = 0.10$, $p_m = 0.8$, $\\tau_{sd} = 0.06$, $\\Delta_{sd} = 0.10$, $p_{sd} = 0.8$, $q = 0.9$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含按A、B、C顺序排列的三个测试用例结果向量的列表，该列表为逗号分隔并用方括号括起来。每个测试用例的结果向量本身也必须是一个用方括号括起来的逗号分隔列表。例如，您的输出必须如下所示\n  - $[[M_A, D_A, C_A],[M_B, D_B, C_B],[M_C, D_C, C_C]]$，\n  其中每个符号是如上定义的整数 $0$ 或 $1$。", "solution": "该问题要求实现一个统计程序，以评估一个随机模拟的输出在多次运行（每次都用不同的随机种子初始化）中的可复现性。评估基于三个标准：输出均值的可复现性、输出标准差的可复现性，以及中心极限定理（CLT）所预测的置信区间的一致性。解决方案涉及生成模拟数据、计算一系列统计指标，并应用一套预设的决策规则。\n\n每个测试用例的处理过程如下：\n\n1.  **数据生成**：对于给定的测试用例，其参数包括真实均值 $\\mu$、真实标准差 $\\sigma$、每次运行的观测次数 $K$ 以及一组随机种子 $S$，我们首先生成原始数据。对于每个种子 $s \\in S$，我们从正态分布 $\\mathcal{N}(\\mu, \\sigma^2)$ 中产生 $K$ 个独立同分布 (i.i.d.) 的观测值 $\\{x_{s,1}, x_{s,2}, \\dots, x_{s,K}\\}$。伪随机数生成器必须以 $s$ 为种子，以确保结果的确定性和可复现性。\n\n2.  **种子内统计**：对于与种子 $s$ 对应的每组观测值，我们计算样本均值 $m_s$ 和无偏样本标准差 $s_s$。公式如下：\n    $$ m_s = \\frac{1}{K} \\sum_{i=1}^{K} x_{s,i} $$\n    $$ s_s = \\sqrt{\\frac{1}{K-1} \\sum_{i=1}^{K} \\left(x_{s,i} - m_s\\right)^2} $$\n    此步骤为均值生成 $|S|$ 个值 $\\{m_s\\}_{s \\in S}$，为标准差生成 $|S|$ 个值 $\\{s_s\\}_{s \\in S}$。\n\n3.  **跨种子聚合统计**：使用种子级别的均值和标准差集合，我们计算四个聚合统计量。\n    - 种子均值的总均值 $\\bar{m}$：\n      $$ \\bar{m} = \\frac{1}{|S|} \\sum_{s \\in S} m_s $$\n    - 种子均值的跨种子样本标准差 $sd_m$：\n      $$ sd_m = \\sqrt{\\frac{1}{|S| - 1} \\sum_{s \\in S} \\left(m_s - \\bar{m}\\right)^2} $$\n    - 种子标准差的总均值 $\\bar{s}$：\n      $$ \\bar{s} = \\frac{1}{|S|} \\sum_{s \\in S} s_s $$\n    - 种子标准差的跨种子样本标准差 $sd_{sd}$：\n      $$ sd_{sd} = \\sqrt{\\frac{1}{|S| - 1} \\sum_{s \\in S} \\left(s_s - \\bar{s}\\right)^2} $$\n    $sd_m$ 和 $sd_{sd}$ 的分母中使用 $|S|-1$ 是为了计算种子级别统计量的无偏样本标准差。\n\n4.  **相对变异性指标**：接着，我们量化种子级别统计量的相对变异性。\n    - 均值的相对变异性 $rv_m$ 定义了条件归一化，以避免被接近零的均值除。给定一个小阈值 $\\varepsilon  0$：\n      $$ rv_m = \\begin{cases}\n      \\dfrac{sd_m}{|\\bar{m}|},  \\text{if } |\\bar{m}| \\ge \\varepsilon \\\\\n      \\dfrac{sd_m}{\\bar{s}},  \\text{if } |\\bar{m}|  \\varepsilon\n      \\end{cases} $$\n    - 标准差的相对变异性 $rv_{sd}$ 通过平均标准差进行归一化：\n      $$ rv_{sd} = \\frac{sd_{sd}}{\\bar{s}} $$\n    其中我们可以假设 $\\bar{s}  0$，因为观测值是从 $\\sigma  0$ 的分布中抽取的。\n\n5.  **成对一致性比例**：为衡量成对运行之间的一致性，我们计算其统计量在给定容差内一致的配对所占的比例。\n    - 唯一的种子对总数为 $\\binom{|S|}{2}$。\n    - 均值的一致性比例 $f_m$ 是指在所有配对 $\\{s, t\\} \\subset S$ 中，绝对差 $|m_s - m_t|$ 不超过容差 $\\Delta_m$ 的配对所占的比例：\n      $$ f_m = \\frac{1}{\\binom{|S|}{2}} \\left|\\left\\{ \\{s,t\\} \\subset S, s \\ne t : |m_s - m_t| \\le \\Delta_m \\right\\}\\right| $$\n    - 类似地，标准差的一致性比例 $f_{sd}$ 使用容差 $\\Delta_{sd}$：\n      $$ f_{sd} = \\frac{1}{\\binom{|S|}{2}} \\left|\\left\\{ \\{s,t\\} \\subset S, s \\ne t : |s_s - s_t| \\le \\Delta_{sd} \\right\\}\\right| $$\n\n6.  **CLT 覆盖率**：中心极限定理表明，对于足够大的 $K$，样本均值 $m_s$ 近似服从正态分布。为每个种子 $s$ 构建真实均值的名义95%置信区间 ($CI_s$)：\n    $$ CI_s = \\left[m_s - z \\cdot \\frac{s_s}{\\sqrt{K}},\\; m_s + z \\cdot \\frac{s_s}{\\sqrt{K}}\\right] $$\n    其中 $z \\approx 1.959963984540054$ 是标准正态分布的第97.5百分位数。问题定义了一个覆盖率测试，该测试基于这些区间中有多少个包含了总均值 $\\bar{m}$。覆盖率 $c$ 为：\n    $$ c = \\frac{1}{|S|} \\left|\\left\\{ s \\in S : \\bar{m} \\in CI_s \\right\\}\\right| $$\n    这等价于对每个种子 $s$ 检查是否满足 $|\\bar{m} - m_s| \\le z \\cdot \\frac{s_s}{\\sqrt{K}}$。\n\n7.  **可复现性决策规则**：最后，我们应用指定的决策规则来确定均值、标准差和CLT覆盖率的可复现性状态。\n    - 如果 $rv_m \\le \\tau_m$ 且 $f_m \\ge p_m$，则均值是可复现的（$M=1$）。否则，$M=0$。\n    - 如果 $rv_{sd} \\le \\tau_{sd}$ 且 $f_{sd} \\ge p_{sd}$，则标准差是可复现的（$D=1$）。否则，$D=0$。\n    - 如果 $c \\ge q$，则CLT覆盖率测试通过（$C=1$）。否则，$C=0$。\n\n对每个测试用例执行这些步骤，并将得到的整数向量 $[M, D, C]$ 收集起来，形成最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import combinations\n\ndef calculate_reproducibility(params, thresholds):\n    \"\"\"\n    Performs the full reproducibility analysis for a single test case.\n    \"\"\"\n    # Unpack parameters\n    mu, sigma, K, S, epsilon = params\n    \n    # Unpack thresholds\n    tau_m, delta_m, p_m = thresholds['mean']\n    tau_sd, delta_sd, p_sd = thresholds['std_dev']\n    q = thresholds['clt']\n    \n    num_seeds = len(S)\n\n    # Step 1  2: Data Generation and Within-Seed Statistics\n    m_s_list = np.zeros(num_seeds)\n    s_s_list = np.zeros(num_seeds)\n\n    for i, seed in enumerate(S):\n        rng = np.random.default_rng(seed)\n        observations = rng.normal(loc=mu, scale=sigma, size=K)\n        m_s_list[i] = np.mean(observations)\n        # ddof=1 for unbiased sample standard deviation\n        s_s_list[i] = np.std(observations, ddof=1)\n\n    # Step 3: Across-Seed Aggregate Statistics\n    m_bar = np.mean(m_s_list)\n    # ddof=1 as per formula for sd_m\n    sd_m = np.std(m_s_list, ddof=1) if num_seeds > 1 else 0.0\n\n    s_bar = np.mean(s_s_list)\n    # ddof=1 as per formula for sd_sd\n    sd_sd = np.std(s_s_list, ddof=1) if num_seeds > 1 else 0.0\n\n    # Step 4: Relative Variability Metrics\n    if np.abs(m_bar) >= epsilon:\n        rv_m = sd_m / np.abs(m_bar)\n    else:\n        # Fallback normalization\n        rv_m = sd_m / s_bar if s_bar > 0 else np.inf\n    \n    rv_sd = sd_sd / s_bar if s_bar > 0 else np.inf\n\n    # Step 5: Pairwise Agreement Fractions\n    num_pairs = num_seeds * (num_seeds - 1) / 2\n    if num_pairs > 0:\n        agreement_count_m = 0\n        agreement_count_sd = 0\n        \n        for i, j in combinations(range(num_seeds), 2):\n            if np.abs(m_s_list[i] - m_s_list[j]) = delta_m:\n                agreement_count_m += 1\n            if np.abs(s_s_list[i] - s_s_list[j]) = delta_sd:\n                agreement_count_sd += 1\n        \n        f_m = agreement_count_m / num_pairs\n        f_sd = agreement_count_sd / num_pairs\n    else:\n        f_m = 1.0 # Vacuously true for  2 seeds\n        f_sd = 1.0\n\n    # Step 6: CLT Coverage Fraction\n    z = 1.959963984540054\n    # Standard error of the mean for each seed\n    se_m = s_s_list / np.sqrt(K)\n    \n    # Check if m_bar is within the CI for each seed\n    # |m_bar - m_s| = z * se_m\n    is_covered = np.abs(m_bar - m_s_list) = z * se_m\n    coverage_count = np.sum(is_covered)\n    c = coverage_count / num_seeds if num_seeds > 0 else 0.0\n\n    # Step 7: Reproducibility Decision Rules\n    M = 1 if rv_m = tau_m and f_m >= p_m else 0\n    D = 1 if rv_sd = tau_sd and f_sd >= p_sd else 0\n    C = 1 if c >= q else 0\n\n    return [M, D, C]\n\ndef solve():\n    \"\"\"\n    Main function to define test cases, run the analysis, and print results.\n    \"\"\"\n    test_cases = [\n        {\n            \"name\": \"Test case A\",\n            \"params\": (5.0, 2.0, 1000, list(range(20)), 1e-8),\n            \"thresholds\": {\n                \"mean\": (0.03, 0.15, 0.9),    # tau_m, delta_m, p_m\n                \"std_dev\": (0.05, 0.12, 0.9), # tau_sd, delta_sd, p_sd\n                \"clt\": 0.9,                  # q\n            }\n        },\n        {\n            \"name\": \"Test case B\",\n            \"params\": (5.0, 2.0, 30, list(range(10)), 1e-8),\n            \"thresholds\": {\n                \"mean\": (0.03, 0.25, 0.9),\n                \"std_dev\": (0.05, 0.20, 0.9),\n                \"clt\": 1.0,\n            }\n        },\n        {\n            \"name\": \"Test case C\",\n            \"params\": (0.0, 1.0, 500, list(range(100, 115)), 1e-8),\n            \"thresholds\": {\n                \"mean\": (0.06, 0.10, 0.8),\n                \"std_dev\": (0.06, 0.10, 0.8),\n                \"clt\": 0.9\n            }\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        result_vector = calculate_reproducibility(case['params'], case['thresholds'])\n        all_results.append(result_vector)\n\n    # Format the final output string exactly as required.\n    inner_strings = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    final_output = f\"[{','.join(inner_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3097442"}, {"introduction": "复杂的模拟常常产生高维输出，使其难以直接解释。主成分分析 (Principal Component Analysis, PCA) 是一种强大的降维技术，通过识别输出数据中的主要变化模式来实现。本练习 ([@problem_id:3097441]) 将向您展示如何从第一性原理出发实现 PCA，不仅能找到这些模式，还能追溯到驱动它们的输入参数。", "problem": "您的任务是使用主成分分析 (PCA) 来分析重复模拟运行产生的多元输出。目标是识别输出空间中的主导模式，并解释输入参数如何驱动这些模式。您必须从变异和协方差的核心定义出发实现PCA，而不能调用任何黑箱PCA例程。\n\n您需要设计一个程序，为下述每个测试用例执行以下操作：\n\n1. 从线性模拟器生成数据。\n   - 对于给定的运行次数 $N$、输出数量 $M$ 和参数数量 $K$，从指定的协方差矩阵为 $\\Sigma \\in \\mathbb{R}^{K \\times K}$ 的零均值多元正态分布中生成参数向量 $p_i \\in \\mathbb{R}^K$，其中 $i \\in \\{1,\\dots,N\\}$。\n   - 令 $B \\in \\mathbb{R}^{M \\times K}$ 为一个固定的输出基矩阵，其列编码了潜在的输出模式。\n   - 对于每次运行 $i$，生成输出 $y_i \\in \\mathbb{R}^M$，其计算公式为 $y_i = B p_i + \\varepsilon_i$，其中 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2 I_M)$，$I_M$ 是 $M \\times M$ 的单位矩阵，$\\sigma \\ge 0$ 是指定的噪声标准差。\n   - 将所有的 $y_i^\\top$ 行堆叠成数据矩阵 $X \\in \\mathbb{R}^{N \\times M}$。\n\n2. 对输出进行PCA。\n   - 通过减去样本均值，对 $X$ 的每个输出（列）进行中心化，得到中心化矩阵 $X_c$。\n   - 基于 $X_c$ 计算输出空间中的样本协方差。根据协方差结构，使用与“主方向是最大化投影方差的正交归一方向”这一定义相符的分解方法，计算输出空间中的主方向及相关方差。\n   - 设 $X_c$ 的奇异值分解为 $X_c = U S V^\\top$，其中 $U \\in \\mathbb{R}^{N \\times r}$，$S \\in \\mathbb{R}^{r \\times r}$ 是对角矩阵，其对角线上的非负元素为 $(s_1,\\dots,s_r)$，$V \\in \\mathbb{R}^{M \\times r}$，且 $r = \\min(N, M)$。输出空间中的第一个主方向是 $V$ 的第一列 $v_1$，第一个主成分得分是 $U S$ 的第一列。\n   - 第一个主成分的方差解释率为 $\\mathrm{EVR}_1 = \\dfrac{s_1^2}{\\sum_{j=1}^r s_j^2}$。\n\n3. 模式识别与参数解释。\n   - 计算第一个主方向 $v_1$ 与 $B$ 的各列之间的对齐分数，其值在 $[0,1]$ 区间内。对于 $B$ 的每一列 $b_j$，定义 $\\hat{b}_j = b_j / \\lVert b_j \\rVert_2$。与 $b_j$ 的对齐分数为 $|\\hat{b}_j^\\top v_1|$。报告在 $j \\in \\{0,\\dots,K-1\\}$ 范围内的最大对齐分数。\n   - 计算第一个主成分得分（一个 $N$ 维向量）与每次运行的各参数序列（每个均为 $N$ 维向量）之间的绝对皮尔逊相关系数。报告具有最大绝对相关系数的参数索引 $j \\in \\{0,\\dots,K-1\\}$（若存在并列情况，则选择最小的索引）。\n\n4. 每个测试用例的数值输出。\n   - 对每个测试用例，生成一个包含三个条目的列表：$[\\mathrm{EVR}_1, \\mathrm{Alignment}, \\mathrm{DominantIndex}]$。\n   - 将所有浮点输出（$\\mathrm{EVR}_1$ 和 $\\mathrm{Alignment}$）四舍五入到恰好 $6$ 位小数。主导索引是一个整数，无需四舍五入。\n\n5. 最终输出格式。\n   - 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为一个由各测试列表组成的逗号分隔列表，不含空格，并用方括号括起来。例如，两个测试用例的有效输出形如 $[[0.912345,0.998765,0],[0.673210,0.812345,1]]$。\n\n您解决方案中需遵循的基本推导依据：\n- 多元数据的样本中心化和样本协方差。\n- 主成分的定义：最大化投影样本方差的正交归一方向，这些方向由样本协方差的特征向量给出，并可通过奇异值分解 (SVD) 计算。\n\n定义和约定：\n- 对于向量 $v$，$\\lVert v \\rVert_2 = \\sqrt{\\sum_i v_i^2}$。\n- 归一化算子为 $\\mathrm{normalize}(v) = v / \\lVert v \\rVert_2$，其中 $\\lVert v \\rVert_2 \\ne 0$。\n- 两个长度为 $N$ 的向量 $x$ 和 $y$ 之间的皮尔逊相关系数为 $\\dfrac{\\sum_{i=1}^N (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^N (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^N (y_i - \\bar{y})^2}}$。\n\n角度单位不适用。本问题中没有物理单位。所有答案必须是实数（对于前两个条目）和整数（对于第三个条目）。\n\n测试套件：\n- 所有用例的共同约定：\n  - 令 $\\mathrm{rng}$ 为使用给定种子初始化的 NumPy 默认随机数生成器。参数抽样为 $P \\sim \\mathcal{N}(0, \\Sigma)$，其中 $P \\in \\mathbb{R}^{N \\times K}$ 具有独立的行。令噪声 $E \\in \\mathbb{R}^{N \\times M}$ 的元素独立服从 $\\mathcal{N}(0, \\sigma^2)$ 分布。构造 $X = P B^\\top + E$。\n  - 对下方的原始整数向量应用 $\\mathrm{normalize}$ 以构成 $B$ 的列。\n\n- 测试用例1（理想路径，单一主导模式）：\n  - $N = 200$, $M = 6$, $K = 3$, 种子 $= 12345$。\n  - $B$ 的列：\n    - $b_0 = \\mathrm{normalize}([2,1,0,0,0,0])$,\n    - $b_1 = \\mathrm{normalize}([0,1,2,0,0,0])$,\n    - $b_2 = \\mathrm{normalize}([0,0,0,1,-1,0])$。\n  - 协方差 $\\Sigma = \\mathrm{diag}([2.0, 0.7, 0.3])$。\n  - 噪声标准差 $\\sigma = 0.1$。\n\n- 测试用例2（具有相关参数的两个可比较的输出模式）：\n  - $N = 150$, $M = 6$, $K = 3$, 种子 $= 2021$。\n  - $B$ 的列：\n    - $b_0 = \\mathrm{normalize}([1,1,0,0,0,0])$,\n    - $b_1 = \\mathrm{normalize}([-1,1,0,0,0,0])$,\n    - $b_2 = 0.5 \\times \\mathrm{normalize}([0,0,0,1,1,1])$。\n  - 协方差 $\\Sigma = \\begin{bmatrix} 1.5  0.9  0 \\\\ 0.9  1.5  0 \\\\ 0  0  0.1 \\end{bmatrix}$。\n  - 噪声标准差 $\\sigma = 0.2$。\n\n- 测试用例3（近乎无噪声，清晰的第一个模式）：\n  - $N = 60$, $M = 5$, $K = 2$, 种子 $= 7$。\n  - $B$ 的列：\n    - $b_0 = \\mathrm{normalize}([1,2,0,0,0])$,\n    - $b_1 = \\mathrm{normalize}([0,0,1,1,0])$。\n  - 协方差 $\\Sigma = \\mathrm{diag}([3.0, 0.1])$。\n  - 噪声标准差 $\\sigma = 0.01$。\n\n您的程序必须为每个测试用例实现以下计算：\n- 根据中心化数据矩阵的奇异值计算 $\\mathrm{EVR}_1$。\n- 计算最大对齐度 $ \\max_j |\\hat{b}_j^\\top v_1| $，其中 $\\hat{b}_j$ 是 $B$ 的归一化列，$v_1$ 是中心化数据矩阵的第一个右奇异向量。\n- 计算与第一个主成分得分具有最大绝对皮尔逊相关系数的参数的索引，若存在并列则选择最小的索引。\n\n最终输出格式：\n- 生成恰好一行，其中包含一个列表，每个测试用例对应一个三元组，顺序与上述测试用例一致。\n- 每个三元组必须为 $[\\mathrm{EVR}_1,\\mathrm{Alignment},\\mathrm{DominantIndex}]$ 的形式，不含空格，且浮点值四舍五入到恰好 $6$ 位小数。", "solution": "我们从变异、协方差和正交分解的基本定义出发。给定 $N$ 次运行和 $M$ 个输出，通过按行堆叠输出向量 $y_i^\\top$ 形成数据矩阵 $X \\in \\mathbb{R}^{N \\times M}$。输出的样本均值向量为 $\\bar{x} \\in \\mathbb{R}^M$，其分量为 $\\bar{x}_j = \\frac{1}{N} \\sum_{i=1}^N X_{ij}$。中心化数据为 $X_c = X - \\mathbf{1} \\bar{x}^\\top$，其中 $\\mathbf{1} \\in \\mathbb{R}^N$ 是全1向量。输出空间中的样本协方差为 $S = \\frac{1}{N-1} X_c^\\top X_c \\in \\mathbb{R}^{M \\times M}$。\n\n根据主成分分析 (PCA) 的定义，主方向是输出空间中使投影数据的样本方差最大化的正交归一方向。这些方向由与降序特征值相关联的 $S$ 的特征向量给出。在数值上，这些特征向量可以等效地通过对 $X_c$ 进行奇异值分解 (SVD) 获得，$X_c = U S_V V^\\top$，其中 $S_V$ 是一个对角矩阵，其非负奇异值为 $(s_1, s_2, \\dots, s_r)$，$r = \\min(N, M)$。右奇异向量（$V$ 的列）是输出空间中的主方向，而左奇异向量经奇异值缩放后（$U S_V$）则产生主成分得分。由主成分 $j$ 解释的方差为 $\\lambda_j = \\frac{s_j^2}{N-1}$，因此主成分 $j$ 的方差解释率为\n$$\n\\mathrm{EVR}_j = \\frac{\\lambda_j}{\\sum_{k=1}^r \\lambda_k} = \\frac{s_j^2}{\\sum_{k=1}^r s_k^2}.\n$$\n这可由样本协方差的定义和谱定理得出。\n\n为了根据模拟器已知的潜在输出模式（$B$ 的列）来解释第一个主方向，我们考虑第一个主方向 $v_1$ 与每个归一化的模拟器列 $\\hat{b}_j = b_j / \\lVert b_j \\rVert_2$ 之间夹角的余弦：\n$$\n\\text{alignment}_j = |\\hat{b}_j^\\top v_1| \\in [0,1].\n$$\n因为 $v_1$ 和 $\\hat{b}_j$ 都是单位向量，所以这个值等于它们之间夹角的余弦绝对值，其中 $1$ 表示完全对齐（或完全反向对齐，但我们使用绝对值来消除特征向量固有的符号模糊性）。\n\n为了将第一个主成分与输入参数关联起来，令 $z \\in \\mathbb{R}^N$ 为第一个主成分得分向量，即 $U S_V$ 的第一列。对于每个参数 $j \\in \\{0, \\dots, K-1\\}$，考虑由历次运行的参数向量的第 $j$ 个分量构成的序列 $p^{(j)} \\in \\mathbb{R}^N$。$z$ 和 $p^{(j)}$ 之间的皮尔逊相关系数为\n$$\nr_j = \\frac{\\sum_{i=1}^N (z_i - \\bar{z})(p^{(j)}_i - \\overline{p}^{(j)})}{\\sqrt{\\sum_{i=1}^N (z_i - \\bar{z})^2} \\sqrt{\\sum_{i=1}^N (p^{(j)}_i - \\overline{p}^{(j)})^2}},\n$$\n其中 $\\bar{z}$ 和 $\\overline{p}^{(j)}$ 表示样本均值。我们将 $\\arg\\max_j |r_j|$ 报告为主导参数索引，若存在并列则选择最小的索引。这种解释与以下概念相符：PCA得分捕捉了输出空间中方差最大的方向，而与这些得分线性关联最强的参数是最具影响力的驱动因素。\n\n每个测试用例的算法流程：\n1. 通过将提供的整数向量归一化为单位长度来构造 $B$ 的列 $b_j$，并应用任何指定的标量乘数。\n2. 使用指定的种子初始化随机数生成器。从指定的协方差为 $\\Sigma$ 的多元正态分布中抽取 $N$ 个独立的参数向量，形成 $P \\in \\mathbb{R}^{N \\times K}$。\n3. 从 $\\mathcal{N}(0, \\sigma^2)$ 分布中抽取独立的元素，构成噪声 $E \\in \\mathbb{R}^{N \\times M}$。\n4. 构造 $X = P B^\\top + E$ 并对列进行中心化以获得 $X_c$。\n5. 计算 $X_c$ 的SVD为 $X_c = U S_V V^\\top$，其中 $V \\in \\mathbb{R}^{M \\times r}$，奇异值为 $(s_1, \\dots, s_r)$。\n6. 计算 $\\mathrm{EVR}_1 = s_1^2 / \\sum_{k=1}^r s_k^2$。\n7. 提取 $V$ 的第一列 $v_1$。对于 $B$ 的每一列，计算 $\\mathrm{Alignment} = \\max_j |\\hat{b}_j^\\top v_1|$，其中 $\\hat{b}_j = b_j / \\lVert b_j \\rVert_2$。\n8. 计算得分 $z$ 为 $U S_V$ 的第一列（即 $z = U[:,0] \\cdot s_1$）。对于每个参数列 $P[:, j]$，计算 $z$ 和 $P[:, j]$ 之间的绝对皮尔逊相关系数。使用最小索引平局决胜规则确定 $\\mathrm{DominantIndex} = \\arg\\max_j |r_j|$。\n9. 将 $\\mathrm{EVR}_1$ 和 $\\mathrm{Alignment}$ 四舍五入到恰好 $6$ 位小数。保持 $\\mathrm{DominantIndex}$ 为整数。\n10. 按照规定，将所有测试用例的结果输出为由三元组构成的单个列表，不含空格。\n\n正确性证明：\n- 中心化确保协方差捕捉的是围绕均值的变异。\n- 基于SVD的计算得出了输出空间中的主方向（$V$ 的列）和奇异值，其平方与沿这些方向的样本方差成正比。这是根据SVD与样本协方差 $S$ 的特征分解之间的等价关系得出的。\n- 对齐度量使用了余弦相似度，这是欧几里得空间中方向相似性的自然度量，并且对于 $b_j$ 的缩放和 $v_1$ 的符号模糊性具有不变性。\n- 基于相关的解释反映了潜在驱动因素（得分）与参数之间的线性关联，这是在已知协变量的情况下解释PCA的标准方法。\n\n该实现遵循了上述定义，并为三个指定的测试用例计算了所要求的量。最终输出按要求聚合了结果，浮点值四舍五入到六位小数，并采用不含空格的精确格式。", "answer": "```python\nimport numpy as np\n\ndef normalize(v):\n    v = np.asarray(v, dtype=float)\n    n = np.linalg.norm(v)\n    if n == 0.0:\n        return v.copy()\n    return v / n\n\ndef build_B(columns, scales=None):\n    \"\"\"\n    columns: list of 1D arrays/lists to be normalized\n    scales: optional list of scalars to multiply each normalized column\n    \"\"\"\n    cols = []\n    for i, c in enumerate(columns):\n        vc = normalize(np.array(c, dtype=float))\n        if scales is not None:\n            vc = vc * float(scales[i])\n        cols.append(vc)\n    return np.column_stack(cols)\n\ndef generate_data(N, M, K, B, Sigma, sigma_noise, seed):\n    rng = np.random.default_rng(seed)\n    # Parameters: N x K from multivariate normal\n    P = rng.multivariate_normal(mean=np.zeros(K), cov=Sigma, size=N)\n    # Noise: N x M\n    E = rng.normal(loc=0.0, scale=sigma_noise, size=(N, M))\n    # Outputs: X = P @ B.T + E\n    X = P @ B.T + E\n    return X, P\n\ndef center_columns(X):\n    mean = X.mean(axis=0, keepdims=True)\n    return X - mean, mean.ravel()\n\ndef pca_first_component(Xc):\n    # SVD of centered data matrix\n    U, S, VT = np.linalg.svd(Xc, full_matrices=False)\n    # First right singular vector (principal direction in output space)\n    v1 = VT.T[:, 0]\n    # Explained variance ratio of first component\n    S2 = S**2\n    evr1 = float(S2[0] / S2.sum()) if S2.sum() > 0 else 0.0\n    # First principal component scores: first column of U*S\n    scores1 = U[:, 0] * S[0] if S.size > 0 else np.zeros(Xc.shape[0])\n    return v1, evr1, scores1\n\ndef max_alignment_with_B(v1, B):\n    # Normalize columns of B\n    norms = np.linalg.norm(B, axis=0)\n    # Avoid division by zero\n    norms[norms == 0.0] = 1.0\n    Bn = B / norms\n    # v1 should already be unit norm from SVD, but ensure stability\n    v1n = v1 / (np.linalg.norm(v1) if np.linalg.norm(v1) > 0 else 1.0)\n    dots = np.abs(Bn.T @ v1n)\n    return float(dots.max())\n\ndef pearson_abs_correlations(z, P):\n    # z: N-vector of scores\n    # P: N x K matrix of parameters\n    zc = z - z.mean()\n    z_norm = np.linalg.norm(zc)\n    K = P.shape[1]\n    abs_rs = np.zeros(K, dtype=float)\n    for j in range(K):\n        pj = P[:, j]\n        pjc = pj - pj.mean()\n        pj_norm = np.linalg.norm(pjc)\n        if z_norm == 0.0 or pj_norm == 0.0:\n            r = 0.0\n        else:\n            r = float((zc @ pjc) / (z_norm * pj_norm))\n        abs_rs[j] = abs(r)\n    return abs_rs\n\ndef format_results_no_spaces(results):\n    # results: list of [float, float, int]\n    parts = []\n    for triple in results:\n        f1, f2, idx = triple\n        # Ensure proper formatting for floats and ints\n        if isinstance(f1, (np.floating,)):\n            f1 = float(f1)\n        if isinstance(f2, (np.floating,)):\n            f2 = float(f2)\n        s = f\"[{format(f1, '.6f')},{format(f2, '.6f')},{int(idx)}]\"\n        parts.append(s)\n    return \"[\" + \",\".join(parts) + \"]\"\n\ndef solve():\n    test_cases = []\n\n    # Test case 1\n    # N=200, M=6, K=3, seed=12345\n    N1, M1, K1, seed1 = 200, 6, 3, 12345\n    cols1 = [\n        [2, 1, 0, 0, 0, 0],\n        [0, 1, 2, 0, 0, 0],\n        [0, 0, 0, 1, -1, 0],\n    ]\n    B1 = build_B(cols1)  # unit-norm columns\n    Sigma1 = np.diag([2.0, 0.7, 0.3])\n    sigma_noise1 = 0.1\n    test_cases.append((N1, M1, K1, B1, Sigma1, sigma_noise1, seed1))\n\n    # Test case 2\n    # N=150, M=6, K=3, seed=2021\n    N2, M2, K2, seed2 = 150, 6, 3, 2021\n    cols2 = [\n        [1, 1, 0, 0, 0, 0],\n        [-1, 1, 0, 0, 0, 0],\n        [0, 0, 0, 1, 1, 1],\n    ]\n    scales2 = [1.0, 1.0, 0.5]\n    B2 = build_B(cols2, scales=scales2)\n    Sigma2 = np.array([[1.5, 0.9, 0.0],\n                       [0.9, 1.5, 0.0],\n                       [0.0, 0.0, 0.1]])\n    sigma_noise2 = 0.2\n    test_cases.append((N2, M2, K2, B2, Sigma2, sigma_noise2, seed2))\n\n    # Test case 3\n    # N=60, M=5, K=2, seed=7\n    N3, M3, K3, seed3 = 60, 5, 2, 7\n    cols3 = [\n        [1, 2, 0, 0, 0],\n        [0, 0, 1, 1, 0],\n    ]\n    B3 = build_B(cols3)\n    Sigma3 = np.diag([3.0, 0.1])\n    sigma_noise3 = 0.01\n    test_cases.append((N3, M3, K3, B3, Sigma3, sigma_noise3, seed3))\n\n    results = []\n    for (N, M, K, B, Sigma, sigma_noise, seed) in test_cases:\n        X, P = generate_data(N, M, K, B, Sigma, sigma_noise, seed)\n        Xc, _ = center_columns(X)\n        v1, evr1, scores1 = pca_first_component(Xc)\n        alignment = max_alignment_with_B(v1, B)\n        abs_rs = pearson_abs_correlations(scores1, P)\n        dominant_idx = int(np.argmax(abs_rs))\n        # Round floats to 6 decimals for final output\n        results.append([round(evr1, 6), round(alignment, 6), dominant_idx])\n\n    print(format_results_no_spaces(results))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3097441"}]}