{"hands_on_practices": [{"introduction": "性能模型的一个最实际的用途是进行规划和设定目标。在我们投入大量精力去优化一段代码之前，可以利用古斯塔夫森定律来回答一个关键问题：如果我们想在特定数量的处理器上达到某个加速比目标，我们的程序最多能容忍多大比例的串行部分？这个练习 [@problem_id:3139830] 将指导你解决这个“逆向问题”，为并行程序设计设定一个明确的“串行开销预算”。", "problem": "一个高性能计算（HPC）团队计划扩展一个模拟，在增加处理器数量的同时保持墙上时钟时间（wall-clock time）固定。假设计算由一个固有的串行部分和一个完全可并行的部分组成，除了串行部分外没有额外的开销。设在并行机器上运行的总时间中，用于串行部分的时间所占的比例用 $\\alpha$ 表示，处理器数量为 $N$。该团队使用可扩展加速比的定义：在墙上时钟时间固定的情况下，单个处理器执行相同规模工作负载所需的时间与 $N$ 个处理器实际花费的时间之比。\n\n仅以上述定义为出发点，请确定在 $N=128$ 个处理器上达到 $S(N)=120$ 的设计目标可扩展加速比时，允许的最大串行比例 $\\alpha$。不要引用任何记忆的公式；从第一性原理出发推导所需内容。将最终的 $\\alpha$ 报告为一个纯数，并四舍五入到四位有效数字。", "solution": "首先对问题陈述进行验证。\n\n### 步骤 1：提取已知条件\n- 计算由一个固有的串行部分和一个完全可并行的部分组成。\n- 扩展时墙上时钟时间保持固定。\n- $\\alpha$：在并行机器上运行的总时间中用于串行部分的时间所占的比例。\n- $N$：处理器数量。\n- 可扩展加速比定义为：单个处理器执行相同规模工作负载所需的时间与 $N$ 个处理器实际花费的时间之比。\n- 设计目标可扩展加速比：$S(N) = 120$。\n- 处理器数量：$N = 128$。\n- 限制条件：推导必须从第一性原理出发，不得引用记忆的公式。\n- 要求输出：$\\alpha$ 的值，以纯数形式表示并四舍五入到四位有效数字。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，因为它描述了并行计算性能分析的一个标准模型，即可扩展加速比，这也是 Gustafson 定律的基础。该问题提法恰当，为可扩展加速比提供了明确的定义，并提供了足够的数值数据（$S(N)$ 和 $N$）来求解未知变量 $\\alpha$。术语客观而精确。该问题没有违反任何基本原理，并非不完整或自相矛盾，并在计算科学领域内提出了一个可解且非平凡的挑战。\n\n### 步骤 3：结论与行动\n该问题是**有效的**。将按规定从第一性原理推导求解。\n\n### 推导\n设 $T(N)$ 是一个任务在 $N$ 个处理器上运行的总墙上时钟时间。问题陈述中指出该时间是固定的。为方便起见且不失一般性，我们可以将此时间归一化为 $T(N)=1$ 个单位。\n\n根据问题定义，$\\alpha$ 是在并行机器（$N$ 个处理器）上运行的总时间中用于串行部分的时间所占的比例。\n在 $N$ 个处理器上用于串行部分的时间是：\n$$T_{\\text{serial}, N} = \\alpha T(N)$$\n剩余时间用于可并行的部分：\n$$T_{\\text{parallel}, N} = (1 - \\alpha) T(N)$$\n两者之和为 $T_{\\text{serial}, N} + T_{\\text{parallel}, N} = \\alpha T(N) + (1-\\alpha)T(N) = T(N)$，这与定义一致。\n\n接下来，我们必须确定单个处理器（$N=1$）执行这个相同规模的工作负载所需的时间。设此时间为 $T(1)$。该工作负载由一个串行部分和一个并行部分组成。\n\n根据定义，工作负载的串行部分是不可并行的。因此，执行它所需的时间与处理器数量无关。单个处理器上串行部分的时间与 $N$ 个处理器上串行部分的时间相同。\n$$T_{\\text{serial}, 1} = T_{\\text{serial}, N} = \\alpha T(N)$$\n\n工作负载的并行部分是完全可并行的。当在 $N$ 个处理器上运行时，工作被分配给它们，耗时 $T_{\\text{parallel}, N}$。如果这同样数量的并行工作要在单个处理器上执行，将需要 $N$ 倍的时间。\n$$T_{\\text{parallel}, 1} = N \\cdot T_{\\text{parallel}, N} = N(1 - \\alpha) T(N)$$\n\n单个处理器的总时间 $T(1)$ 是其串行部分和并行部分时间的总和：\n$$T(1) = T_{\\text{serial}, 1} + T_{\\text{parallel}, 1}$$\n$$T(1) = \\alpha T(N) + N(1 - \\alpha) T(N)$$\n提出因子 $T(N)$，我们得到：\n$$T(1) = [\\alpha + N(1 - \\alpha)] T(N)$$\n\n问题将可扩展加速比 $S(N)$ 定义为单个处理器所需的时间（$T(1)$）与 $N$ 个处理器实际花费的时间（$T(N)$）之比。\n$$S(N) = \\frac{T(1)}{T(N)}$$\n代入我们得到的 $T(1)$ 的表达式：\n$$S(N) = \\frac{[\\alpha + N(1 - \\alpha)] T(N)}{T(N)}$$\n$$S(N) = \\alpha + N(1 - \\alpha)$$\n这个从第一性原理推导出的表达式，将可扩展加速比 $S(N)$ 与串行比例 $\\alpha$ 和处理器数量 $N$ 联系起来。\n\n现在我们必须求解 $\\alpha$。\n$$S(N) = \\alpha + N - N\\alpha$$\n$$S(N) - N = \\alpha - N\\alpha$$\n$$S(N) - N = \\alpha(1 - N)$$\n$$\\alpha = \\frac{S(N) - N}{1 - N}$$\n为了避免分母中出现负号，我们可以将分子和分母同乘以 $-1$：\n$$\\alpha = \\frac{N - S(N)}{N - 1}$$\n\n问题给出了具体数值 $N = 128$ 和目标加速比 $S(128) = 120$。我们把这些值代入推导出的 $\\alpha$ 方程中。\n$$\\alpha = \\frac{128 - 120}{128 - 1}$$\n$$\\alpha = \\frac{8}{127}$$\n\n为了给出最终答案，我们计算其数值并四舍五入到四位有效数字。\n$$\\alpha \\approx 0.0629921259...$$\n前四位有效数字是 $6$、$2$、$9$、$9$。第五位数字是 $2$，小于 $5$，因此我们不对最后一位有效数字进行进位。\n$$\\alpha \\approx 0.06299$$\n这是满足指定设计目标所允许的最大串行比例。", "answer": "$$\\boxed{0.06299}$$", "id": "3139830"}, {"introduction": "假设串行分数 $f$ 是一个常数，这是一个有用的简化，但在现实世界的应用中情况可能更为复杂。这个练习 [@problem_id:3169108] 探讨了一个更贴近实际的场景，其中串行分数本身会随着处理器数量 $p$ 的增加而变化，这在自适应网格加密（AMR）等应用中很常见。这促使我们去分析系统的长期，即渐近（asymptotic）的扩展行为，并理解效率如何随着规模的扩大而演变。", "problem": "一个科学计算团队正在研究一个自适应网格加密（AMR）模拟在固定时间伸缩视角（Gustafson视角）下的并行性能。令 $S(p)$ 表示在 $p$ 个相同处理器上的加速比，定义为在 1 个处理器上执行伸缩后问题的时间与在 $p$ 个处理器上执行同一伸缩后问题的时间之比。令 $E(p) = S(p)/p$ 表示并行效率。在固定时间伸缩视角下，当 $p$ 增长时，通过增加问题规模来保持总墙上时钟时间近似恒定，使得可并行化部分随 $p$ 增长，而固有的串行部分不增长。令 $T_s$ 和 $T_p$ 分别表示在 $p$ 个处理器上对墙上时钟时间的串行和可并行化贡献，因此在 $p$ 个处理器上的执行时间为 $T_s + T_p$，对于伸缩后的问题在 1 个处理器上的执行时间为 $T_s + p\\,T_p$。将伸缩后问题的串行分数定义为 $f(p) = T_s/(T_s + T_p)$。仅使用这些定义，推导出一个用 $p$ 和 $f(p)$ 表示 $S(p)$ 的表达式，并由此表示出 $E(p)$。\n\n现在考虑一个AMR工作负载，其中串行分数随 $p$ 的变化关系如下：\n$$\nf(p) = \\frac{0.4}{1 + \\sqrt{p}}.\n$$\n使用你推导的表达式，确定当 $p \\to \\infty$ 时 $S(p)$ 的渐近行为，并找出满足 $E(p) \\ge 0.95$ 的最小整数 $p$。\n\n哪个选项正确地陈述了渐近行为和最小整数阈值？\n\n- A. 当 $p \\to \\infty$ 时，$S(p) \\sim p$，并且满足 $E(p) \\ge 0.95$ 的最小整数 $p$ 是 $p = 47$。\n- B. 当 $p \\to \\infty$ 时，$S(p)$ 饱和到一个常数（与 $p$ 无关），并且满足 $E(p) \\ge 0.95$ 的最小整数 $p$ 约为 $p \\approx 9$。\n- C. 当 $p \\to \\infty$ 时，$S(p) \\sim \\sqrt{p}$，并且满足 $E(p) \\ge 0.95$ 的最小整数 $p$ 约为 $p \\approx 100$。\n- D. 当 $p \\to \\infty$ 时，$S(p) \\sim p$，但由于串行部分的存在，没有有限的 $p$ 能达到 $E(p) \\ge 0.95$。", "solution": "首先将验证问题陈述的正确性、一致性和科学依据。\n\n### 第1步：提取已知条件\n- $S(p)$: 在 $p$ 个相同处理器上的加速比。\n- $p$: 处理器数量。\n- 伸缩模型：固定时间伸缩（Gustafson视角）。\n- 加速比的定义：$S(p)$ 是在 1 个处理器上执行伸缩后问题的时间与在 $p$ 个处理器上执行同一伸缩后问题的时间之比。\n- $E(p)$: 并行效率，定义为 $E(p) = S(p)/p$。\n- $T_s$: 对墙上时钟时间的固有串行贡献，不随 $p$ 增长。\n- $T_p$: 在 $p$ 个处理器上对墙上时钟时间的可并行化贡献。\n- 在 $p$ 个处理器上的执行时间：$T(p) = T_s + T_p$。\n- 对于伸缩后的问题在 1 个处理器上的执行时间：$T(1)_{\\text{scaled}} = T_s + p\\,T_p$。\n- 总墙上时钟时间 $T_s + T_p$ 保持近似恒定。\n- 问题规模被增加，以使可并行化部分随 $p$ 增长。\n- 串行分数的定义：$f(p) = T_s/(T_s + T_p)$。\n- 串行分数的特定工作负载模型：$f(p) = \\frac{0.4}{1 + \\sqrt{p}}$。\n- 问题要求：\n    1. 用 $p$ 和 $f(p)$ 表示 $S(p)$ 和 $E(p)$ 的表达式。\n    2. 当 $p \\to \\infty$ 时 $S(p)$ 的渐近行为。\n    3. 满足 $E(p) \\ge 0.95$ 的最小整数 $p$。\n\n### 第2步：使用提取的已知条件进行验证\n该问题在计算科学和并行计算领域内定义明确且具有科学依据。所提供的关于加速比、效率和执行时间的定义，是在Gustafson的伸缩加速比模型下进行性能分析的标准定义。\n\n- 加速比的定义由 $S(p) = \\frac{T(1)_{\\text{scaled}}}{T(p)} = \\frac{T_s + p\\,T_p}{T_s + T_p}$ 给出。这是对伸缩加速比的正确表述。\n- 串行分数 $f(p)$ 是相对于在 $p$ 个处理器上的执行时间定义的，这在此上下文中是标准的。\n- $f(p)$ 的函数形式是一个假设但物理上合理的模型，代表了串行开销（例如通信）的增长远慢于可并行化工作量的场景。\n- 问题内部是一致的。陈述“总墙上时钟时间保持近似恒定”（$T_s+T_p \\approx \\text{const}$）而“可并行化部分随 $p$ 增长”可以通过理解“可并行化部分”指的是*工作量*，而不是*时间*来解决。如果并行工作量是 $W_p$，那么 $T_p = W_p/p$。为了使 $T_p$ 和 $T_s$ 恒定，$W_p$ 必须与 $p$ 成比例增长，这与模型是一致的。在给定的问题中，$T_s$ 和 $T_p$ 不一定是常数，而是 $p$ 的函数，使得 $T_s+T_p$ 保持恒定。然而，关于 $f(p)$ 的显式表达式意味着当 $p$ 变化时 $T_s$ 和 $T_p$ 之间有特定的关系，这覆盖了一般的陈述。推导仅依赖于明确的定义。\n\n### 第3步：结论与行动\n问题有效。这是一个在并行性能分析中提法恰当且科学合理的问题。可以继续求解过程。\n\n### 推导与求解\n\n**第1部分：推导 $S(p)$ 和 $E(p)$ 的表达式**\n我们已知加速比 $S(p)$ 和串行分数 $f(p)$ 的定义：\n$$S(p) = \\frac{T_s + p\\,T_p}{T_s + T_p}$$\n$$f(p) = \\frac{T_s}{T_s + T_p}$$\n我们也可以将运行时间的并行分数表示为：\n$$1 - f(p) = 1 - \\frac{T_s}{T_s + T_p} = \\frac{T_s + T_p - T_s}{T_s + T_p} = \\frac{T_p}{T_s + T_p}$$\n现在，我们用 $f(p)$ 和 $(T_s + T_p)$ 重写 $S(p)$ 的分子和分母：\n- 分子：$T_s + p\\,T_p = f(p)(T_s+T_p) + p(1-f(p))(T_s+T_p) = (f(p) + p(1-f(p)))(T_s+T_p)$\n- 分母：$T_s + T_p = (1)(T_s+T_p)$\n将这些代入 $S(p)$ 的表达式中：\n$$S(p) = \\frac{(f(p) + p(1-f(p)))(T_s+T_p)}{T_s+T_p} = f(p) + p(1-f(p))$$\n这可以重写为 $S(p) = p + f(p)(1-p)$。这是 Gustafson 定律的标准公式。\n\n接下来，我们推导并行效率 $E(p)$ 的表达式：\n$$E(p) = \\frac{S(p)}{p} = \\frac{f(p) + p(1-f(p))}{p} = \\frac{f(p)}{p} + 1 - f(p)$$\n这可以重写为 $E(p) = 1 - f(p)(1 - \\frac{1}{p}) = 1 - f(p)\\frac{p-1}{p}$。\n\n**第2部分：$S(p)$ 的渐近行为**\n我们已知串行分数的具体形式：\n$$f(p) = \\frac{0.4}{1 + \\sqrt{p}}$$\n为了找到当 $p \\to \\infty$ 时 $S(p)$ 的渐近行为，我们检查表达式 $S(p) = p + f(p)(1-p)$。\n$$\\lim_{p \\to \\infty} f(p) = \\lim_{p \\to \\infty} \\frac{0.4}{1 + \\sqrt{p}} = 0$$\n为了确定渐近关系，我们可以分析比率 $S(p)/p$：\n$$\\lim_{p \\to \\infty} \\frac{S(p)}{p} = \\lim_{p \\to \\infty} E(p) = \\lim_{p \\to \\infty} \\left(1 - f(p) + \\frac{f(p)}{p}\\right)$$\n因为 $\\lim_{p \\to \\infty} f(p) = 0$ 且 $\\lim_{p \\to \\infty} f(p)/p = 0$，我们有：\n$$\\lim_{p \\to \\infty} E(p) = 1 - 0 + 0 = 1$$\n$S(p)/p$ 的极限为 $1$ 意味着对于大的 $p$，$S(p)$ 的行为类似于 $p$。在渐近表示法中，这写作 $S(p) \\sim p$。\n\n**第3部分：满足 $E(p) \\ge 0.95$ 的最小整数 $p$**\n我们需要解不等式 $E(p) \\ge 0.95$。使用我们推导的 $E(p)$ 表达式：\n$$1 - f(p)\\frac{p-1}{p} \\ge 0.95$$\n$$0.05 \\ge f(p)\\frac{p-1}{p}$$\n代入给定的 $f(p)$ 表达式：\n$$0.05 \\ge \\left(\\frac{0.4}{1 + \\sqrt{p}}\\right) \\left(\\frac{p-1}{p}\\right)$$\n$$0.05 \\ge \\frac{0.4(p-1)}{p(1+\\sqrt{p})}$$\n假设 $p>1$，我们可以重新整理不等式：\n$$\\frac{p(1+\\sqrt{p})}{p-1} \\ge \\frac{0.4}{0.05}$$\n$$\\frac{p(1+\\sqrt{p})}{p-1} \\ge 8$$\n让我们解相应的等式来找到 $p$ 的边界值：\n$$p(1+\\sqrt{p}) = 8(p-1)$$\n$$p + p\\sqrt{p} = 8p - 8$$\n$$p\\sqrt{p} - 7p + 8 = 0$$\n令 $x = \\sqrt{p}$。该方程变为关于 $x$ 的三次多项式：\n$$x^3 - 7x^2 + 8 = 0$$\n我们需要找到函数 $h(x) = x^3 - 7x^2 + 8$ 的根。我们关心的是 $x > 1$ 的解（因为 $p>1$）。让我们测试一些值：\n$h(6) = 6^3 - 7(6^2) + 8 = 216 - 7(36) + 8 = 224 - 252 = -28$。\n$h(7) = 7^3 - 7(7^2) + 8 = 343 - 343 + 8 = 8$。\n因为 $h(6)  0$ 且 $h(7) > 0$，所以根 $x$ 位于 $6$ 和 $7$ 之间。\n让我们找一个更精确的值。\n当 $x \\approx 6.8$ 时，$h(6.8) = (6.8)^3 - 7(6.8)^2 + 8 = 314.432 - 7(46.24) + 8 = 322.432 - 323.68 = -1.248$。\n当 $x \\approx 6.9$ 时，$h(6.9) = (6.9)^3 - 7(6.9)^2 + 8 = 328.509 - 7(47.61) + 8 = 336.509 - 333.27 = 3.239$。\n根在 $6.8$ 和 $6.9$ 之间。\n$p$ 的值是 $x^2$。所以，$p$ 的临界点在 $(6.8)^2 = 46.24$ 和 $(6.9)^2 = 47.61$ 之间。\n不等式是 $\\frac{p(1+\\sqrt{p})}{p-1} \\ge 8$。对于 $p4$，左边的函数是递增的。\n因此，对于任何大于我们找到的根的 $p$，不等式都将成立。根约等于 $p \\approx 46.65$（来自 $x \\approx \\sqrt{46.65} \\approx 6.83$）。\n我们需要满足条件的最小整数 $p$。\n对于 $p=46$，$p  46.65$，所以我们预期 $E(46)  0.95$。\n对于 $p=47$，$p > 46.65$，所以我们预期 $E(47) \\ge 0.95$。\n因此，满足 $E(p) \\ge 0.95$ 的最小整数 $p$ 是 $47$。\n\n### 逐项分析选项\n\n- **A. 当 $p \\to \\infty$ 时，$S(p) \\sim p$，并且满足 $E(p) \\ge 0.95$ 的最小整数 $p$ 是 $p = 47$。**\n  - 渐近行为 $S(p) \\sim p$ 如推导所示是正确的。\n  - 对于效率条件的最小整数 $p=47$ 如计算所示是正确的。\n  - **结论：正确**\n\n- **B. 当 $p \\to \\infty$ 时，$S(p)$ 饱和到一个常数（与 $p$ 无关），并且满足 $E(p) \\ge 0.95$ 的最小整数 $p$ 约为 $p \\approx 9$。**\n  - 渐近行为不正确。$S(p) \\sim p$，它不会饱和。饱和是 Amdahl 定律的特征，而不是 Gustafson 定律的。\n  - 值 $p \\approx 9$ 是不正确的。我们的计算显示 $p=47$。\n  - **结论：不正确**\n\n- **C. 当 $p \\to \\infty$ 时，$S(p) \\sim \\sqrt{p}$，并且满足 $E(p) \\ge 0.95$ 的最小整数 $p$ 约为 $p \\approx 100$。**\n  - 渐近行为不正确。$S(p) \\sim p$，而不是 $\\sqrt{p}$。\n  - 虽然 $p=100$ 确实满足 $E(p) \\ge 0.95$，但它不是*最小*的这样的整数。\n  - **结论：不正确**\n\n- **D. 当 $p \\to \\infty$ 时，$S(p) \\sim p$，但由于串行部分的存在，没有有限的 $p$ 能达到 $E(p) \\ge 0.95$。**\n  - 渐近行为 $S(p) \\sim p$ 是正确的。\n  - 声称没有有限的 $p$ 能达到效率目标是不正确的。我们明确地发现对于 $p \\ge 47$，$E(p) \\ge 0.95$。效率函数 $E(p)$ 在 $p \\to \\infty$ 时趋近于 $1$，因此它最终必须超过任何小于 $1$ 的阈值。\n  - **结论：不正确**", "answer": "$$\\boxed{A}$$", "id": "3169108"}, {"introduction": "对一个计算模型最高层次的理解，莫过于亲手实现它。这个最终练习 [@problem_id:3139767] 将挑战你将弱缩放（weak scaling）的第一性原理转化为一个可工作的程序。通过在代码中从零开始构建模型，你不仅能验证理论公式的正确性，还能对工作负载的串行和并行部分如何相互作用，以及它们如何共同决定最终加速比，形成一个更深刻、更具体的认识。", "problem": "要求您在高性能计算（HPC）的背景下，形式化并验证一个归因于 Gustafson 定律的弱扩展预测。目标是从第一性原理出发，不预设任何最终公式，并实现一个程序，在一小组测试套件上对得出的预测进行数值验证。\n\n从以下基础且广为接受的定义开始：\n- 令 $N$ 表示并行工作单元（例如，中央处理器（CPU）核心）的数量。\n- 在弱扩展（weak scaling）情况下，总问题规模与 $N$ 成比例增长，从而使得每个工作单元的墙上时间（wall time）大致保持不变。\n- 将给定工作负载下并行程序的总工作量分解为不可并行化（顺序）部分和可完全并行化部分。定义参数 $\\alpha \\in [0,1]$ 为在单个工作单元上运行基准工作负载时，花费在不可并行化部分的时间比例；$1-\\alpha$ 为同一基准工作负载下，花费在可并行化部分的时间比例。\n- 将弱扩展的加速比 $S(N)$ 定义为：单个工作单元执行与 $N$ 成比例的扩展后工作负载所需的时间，与 $N$ 个工作单元实际执行该扩展后工作负载所需时间的比值。\n\n仅基于以上基础，通过推断在为保持每个工作单元的墙上时间恒定而扩展总工作负载时，工作的顺序部分和可并行化部分在弱扩展下如何变化，从而推导出 $S(N)$ 关于 $N$ 和 $\\alpha$ 的表达式。\n\n实现要求：\n- 将基准的每个工作单元的墙上时间设为 $T_{\\text{base}} = 1$（任意但一致的时间单位）；无需进行物理单位转换。\n- 对于每个测试用例 $(N,\\alpha)$，构建：\n  1. 基于上述定义和弱扩展约束（每个工作单元的墙上时间恒定为 $T_{\\text{base}}=1$），建模出的 $N$ 个工作单元在扩展后工作负载上的并行执行时间 $T_N$。\n  2. 同一扩展后工作负载在单个工作单元上建模出的执行时间 $T_1(N)$。\n  3. 测量得到的加速比 $S_{\\text{meas}}(N) = T_1(N)/T_N$。\n  4. 从您的推导中得到的理论加速比 $S_{\\text{theory}}(N)$。\n  5. 每个测试用例的布尔判定结果：如果 $\\lvert S_{\\text{meas}}(N) - S_{\\text{theory}}(N)\\rvert \\le \\varepsilon$（容差 $\\varepsilon = 10^{-12}$），则为真，否则为假。\n\n测试套件：\n- 使用以下五个 $(N,\\alpha)$ 对，它们共同覆盖了通用场景、边界值和边缘情况：\n  - $(N,\\alpha) = (1, 0.3)$\n  - $(N,\\alpha) = (8, 0.1)$\n  - $(N,\\alpha) = (64, 0)$\n  - $(N,\\alpha) = (16, 1)$\n  - $(N,\\alpha) = (32, 0.25)$\n\n答案格式：\n- 您的程序必须生成单行输出，其中包含按给定顺序排列的五个测试用例的布尔值列表，格式为逗号分隔的 Python 风格列表（例如，$[\\text{True},\\text{False},\\ldots]$）。不允许有其他输出。\n- 所有中间量都是无量纲的实数，不需要单位。", "solution": "问题陈述已经过严格的验证过程。所有给定条件均按原文提取，并根据科学合理性、良构性（well-posedness）和客观性的标准对问题进行了分析。\n\n**给定条件：**\n1.  $N$：并行工作单元的数量。\n2.  弱扩展：总问题规模与 $N$ 成比例增长，使得每个工作单元的墙上时间大致保持不变。\n3.  $\\alpha$：在单个工作单元上运行基准工作负载时，花费在不可并行化部分的时间比例，其中 $\\alpha \\in [0,1]$。\n4.  $1-\\alpha$：同一基准工作负载下，花费在可并行化部分的时间比例。\n5.  $S(N)$：弱扩展加速比，定义为单个工作单元执行扩展后工作负载所需时间与 $N$ 个工作单元所需时间的比值。\n6.  $T_{\\text{base}} = 1$：基准的每个工作单元的墙上时间。\n7.  容差 $\\varepsilon = 10^{-12}$。\n8.  测试用例：$(N,\\alpha) = (1, 0.3)$, $(8, 0.1)$, $(64, 0)$, $(16, 1)$, $(32, 0.25)$。\n\n**结论：**\n此问题是**有效的**。这是一个科学上成立且良构的练习，旨在从第一性原理推导和验证 Gustafson 定律——这是计算科学中的一个基本概念。定义清晰、一致，并且足以推导出一个唯一且有意义的解。\n\n我们现在将进行推导和随后的数值验证。\n\n### 从第一性原理推导 Gustafson 定律\n\n目标是推导出弱扩展加速比 $S(N)$ 作为工作单元数量 $N$ 和基准程序顺序部分比例 $\\alpha$ 的函数表达式。\n\n**步骤 1：基准工作负载分析 ($N=1$)**\n\n我们考虑在单个工作单元（$N=1$）上执行的基准工作负载。总执行时间给定为 $T_{\\text{base}}$，我们将其设为 1 个任意时间单位。\n$$\nT_1(\\text{base}) = T_{\\text{base}} = 1\n$$\n这个总时间由一个顺序（不可并行化）部分和一个可并行化部分组成。根据问题定义，$\\alpha$ 是花费在顺序部分的时间比例。\n-   顺序部分的时间：$T_{s,1} = \\alpha T_1(\\text{base}) = \\alpha \\cdot 1 = \\alpha$。\n-   可并行化部分的时间：$T_{p,1} = (1-\\alpha) T_1(\\text{base}) = (1-\\alpha) \\cdot 1 = 1-\\alpha$。\n\n从计算工作量的角度来思考会很有帮助，它与单个工作单元的执行时间成正比。假设单个工作单元每单位时间执行一个单位的工作，那么基准情况下的总工作量 $W_{\\text{base}}$ 为：\n-   顺序工作量：$W_s = T_{s,1} = \\alpha$。\n-   可并行化工作量：$W_p = T_{p,1} = 1-\\alpha$。\n\n**步骤 2：扩展后工作负载分析（针对 $N$ 个工作单元）**\n\n在弱扩展下，总问题规模会增加以保持每个工作单元的执行时间恒定。这是通过扩展工作的可并行化部分来实现的，而顺序部分假定保持不变，因为它通常与不随数据大小扩展的开销或问题设置/拆卸相关。\n\n-   扩展后问题的顺序工作量 $W_{s,N}$ 保持不变：$W_{s,N} = W_s = \\alpha$。\n-   可并行化工作量 $W_{p,N}$ 随工作单元数量线性扩展：$W_{p,N} = N \\cdot W_p = N(1-\\alpha)$。\n\n这个新的、扩展后问题的总工作量是其顺序和可并行化部分之和：\n$$\nW_{\\text{total}}(N) = W_{s,N} + W_{p,N} = \\alpha + N(1-\\alpha)\n$$\n\n**步骤 3：计算扩展后工作负载的执行时间**\n\n我们现在计算这个总工作量 $W_{\\text{total}}(N)$ 在两种不同机器配置下的执行时间：单个工作单元和 $N$ 个工作单元。\n\n-   **在单个工作单元上的时间， $T_1(N)$**：单个工作单元必须执行所有工作，包括顺序和可并行化的部分。\n    $$\n    T_1(N) = W_{\\text{total}}(N) = \\alpha + N(1-\\alpha)\n    $$\n-   **在 $N$ 个工作单元上的时间， $T_N(N)$**：$N$ 个工作单元并行执行扩展后的工作负载。\n    -   顺序工作量 $W_{s,N}$ 无法并行化，必须由一个工作单元执行，耗时 $\\alpha$。\n    -   可并行化工作量 $W_{p,N}$ 被完美地分配给 $N$ 个工作单元。因此，这部分所花费的时间是 $\\frac{W_{p,N}}{N} = \\frac{N(1-\\alpha)}{N} = 1-\\alpha$。\n    -   在 $N$ 个工作单元上的总执行时间 $T_N(N)$ 是顺序和并行部分的时间之和：\n        $$\n        T_N(N) = \\alpha + (1-\\alpha) = 1\n        $$\n    这个结果证实了弱扩展的前提：在 $N$ 个工作单元上，扩展后问题的墙上时间是恒定的，等于基准时间 $T_{\\text{base}}=1$。为简洁起见，我们将 $T_N(N)$ 表示为 $T_N$。\n\n**步骤 4：推导加速比公式**\n\n问题将弱扩展加速比 $S(N)$ 定义为：单个工作单元执行扩展后工作负载所需的时间与 $N$ 个工作单元实际所需时间的比值。\n$$\nS(N) = \\frac{T_1(N)}{T_N}\n$$\n代入步骤 3 中推导出的表达式：\n$$\nS(N) = \\frac{\\alpha + N(1-\\alpha)}{1}\n$$\n这就得到了 Gustafson 定律的理论公式：\n$$\nS_{\\text{theory}}(N) = \\alpha + N(1-\\alpha)\n$$\n\n### 数值验证计划\n\n该实现将测试此推导的一致性。对于每个测试用例 $(N, \\alpha)$：\n1.  扩展后工作负载的并行执行时间为 $T_N = 1$。\n2.  扩展后工作负载在单个工作单元上的执行时间为 $T_1(N) = \\alpha + N(1-\\alpha)$。\n3.  “测量”的加速比计算为 $S_{\\text{meas}}(N) = T_1(N) / T_N$。\n4.  “理论”加速比使用推导出的公式计算，$S_{\\text{theory}}(N) = \\alpha + N(1-\\alpha)$。\n5.  根据构造，$S_{\\textmeas}(N) = S_{\\text{theory}}(N)$。因此，验证检查 $|\\text{S}_{\\text{meas}}(N) - S_{\\text{theory}}(N)| \\le \\varepsilon$ 将确认所推导模型的实现的自洽性。对于所有有效输入，此检查的结果必须为真。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and numerically verifies Gustafson's law for weak scaling speedup.\n\n    For each test case (N, alpha), the program calculates the theoretical speedup\n    and a \"measured\" speedup based on a first-principles model of execution time,\n    then compares them.\n    \"\"\"\n    # Define the test cases from the problem statement: (N, alpha) pairs.\n    # N is the number of workers, alpha is the sequential fraction.\n    test_cases = [\n        (1, 0.3),    # Base case N=1\n        (8, 0.1),    # General case\n        (64, 0.0),   # Edge case: perfectly parallelizable\n        (16, 1.0),   # Edge case: purely sequential\n        (32, 0.25)   # General case\n    ]\n\n    # Tolerance for floating-point comparison\n    epsilon = 1e-12\n\n    results = []\n    for N, alpha in test_cases:\n        # Cast N to float to ensure floating-point arithmetic throughout\n        N = float(N)\n\n        # Step 1: Modeled parallel execution time on N workers, T_N.\n        # In weak scaling, problem size is increased to keep per-worker time\n        # constant. Starting with a baseline time T_base = 1, the time on\n        # N workers for the scaled problem, T_N, is also 1.\n        # T_N_sequential = alpha\n        # T_N_parallel = (N * (1 - alpha)) / N = 1 - alpha\n        # T_N = T_N_sequential + T_N_parallel = alpha + (1 - alpha) = 1.0\n        T_N = 1.0\n\n        # Step 2: Modeled single-worker execution time for the scaled workload, T_1(N).\n        # A single worker must perform all the work of the scaled problem.\n        # The sequential work is 'alpha'.\n        # The parallelizable work, scaled by N, is N * (1.0 - alpha).\n        T_1_N = alpha + N * (1.0 - alpha)\n\n        # Step 3: Measured speedup, S_meas(N), based on the definition.\n        # S_meas(N) = T_1(N) / T_N\n        S_meas_N = T_1_N / T_N\n\n        # Step 4: Theoretically derived speedup, S_theory(N) (Gustafson's Law).\n        # This is the formula derived from first principles in the solution text.\n        S_theory_N = alpha + N * (1.0 - alpha)\n\n        # Step 5: Boolean verdict.\n        # Check if the measured speedup matches the theoretical formula\n        # within the given tolerance. By construction, they should be identical.\n        verdict = abs(S_meas_N - S_theory_N) = epsilon\n        results.append(verdict)\n\n    # Final print statement in the exact required format.\n    # The output is a list of booleans, formatted as a string.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3139767"}]}