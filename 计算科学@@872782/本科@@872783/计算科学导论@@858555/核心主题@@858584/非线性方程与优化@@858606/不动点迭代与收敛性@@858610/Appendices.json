{"hands_on_practices": [{"introduction": "理论学习的最佳方式是付诸实践。这个练习将通过求解经典的 $x = \\cos(x)$ 方程，引导你将压缩映射定理应用于实际代码中，并分析其收敛行为。通过这个练习 [@problem_id:3231288]，你将直观地理解理论与数值计算结果之间的联系。", "problem": "考虑定义在闭区间 $[0,1]$ 上的不动点方程 $x=\\cos x$ 以及不动点迭代 $x_{k+1}=\\cos x_k$。使用以下基本依据：函数 $g$ 的不动点 $x^\\star$ 满足 $x^\\star=g(x^\\star)$ 的定义、中值定理 (MVT) 以及压缩映射定理 (CMT)，也称为 Banach 不动点定理。迭代过程使用弧度作为角度单位。您的程序必须实现该迭代，并对指定的测试套件验证其收敛性和单调性。\n\n任务：\n- 从基本定义出发，论证为什么函数 $g(x)=\\cos x$ 将 $[0,1]$ 映射到自身。使用导数 $g'(x)=-\\sin x$ 和界 $\\sup_{x\\in[0,1]}|\\sin x|=\\sin(1)$（其中 $\\sin(1)1$）来证明 $g$ 是 $[0,1]$ 上的一个压缩映射，因此存在唯一的不动点 $x^\\star\\in[0,1]$，对于任意 $x_0\\in[0,1]$，序列 $\\{x_k\\}$ 都收敛于此不动点。\n- 分析迭代序列的单调行为。由于 $g$ 在 $[0,1]$ 上是严格递减的，因此整个序列 $\\{x_k\\}$ 通常不是单调的。然而，请证明偶数子序列 $\\{x_{2k}\\}$ 和奇数子序列 $\\{x_{2k+1}\\}$ 各自都是单调的，并且收敛到相同的极限 $x^\\star$。\n- 实现一个程序，对所提供测试套件中的每个初始值 $x_0$，执行不动点迭代 $x_{k+1}=\\cos x_k$，直到相邻两次迭代的差满足 $|x_{k+1}-x_k|10^{-12}$ 或达到最大迭代次数 $1000$ 次为止。为每个测试用例存储完整的迭代序列。角度单位必须是弧度。\n- 对于每个测试用例，计算并报告：\n  1. 初始值 $x_0$。\n  2. 停止迭代后不动点的最终近似值，记为 $x_{\\text{approx}}$。\n  3. 执行的迭代次数 $N$。\n  4. 一个布尔值，指示完整序列 $\\{x_k\\}_{k=0}^N$ 是否单调（非递减或非递增）。\n  5. 一个布尔值，指示偶数索引子序列 $\\{x_{2k}\\}$ 是否单调（非递减或非递增）。\n  6. 一个布尔值，指示奇数索引子序列 $\\{x_{2k+1}\\}$ 是否单调（非递减或非递增）。\n- 使用以下初始值测试套件（均为弧度）：$x_0\\in\\{0,\\,\\tfrac{1}{2},\\,1,\\,0.7390851332151607\\}$。最后一个值是唯一不动点 $x^\\star$ 的一个高精度近似值。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。每个测试用例的结果本身必须是一个列表，其确切形式为 $[x_0,x_{\\text{approx}},N,\\text{is\\_monotone\\_full},\\text{is\\_monotone\\_even},\\text{is\\_monotone\\_odd}]$。例如，整体输出将类似于 $[[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot]]$，其中包含四个内部列表，对应四个测试用例。\n\n上述所有数值在程序中必须作为标量处理。程序不得读取任何输入，并且必须打印所需的单行作为其唯一输出。", "solution": "我们首先回顾基本定义和事实。函数 $g$ 的不动点是一个满足 $x^\\star=g(x^\\star)$ 的值 $x^\\star$。数值不动点迭代通过 $x_{k+1}=g(x_k)$ 构建一个序列 $\\{x_k\\}$，并寻求一个极限 $x^\\star$，使得 $x_k\\to x^\\star$ 且 $x^\\star=g(x^\\star)$。压缩映射定理 (CMT) 指出，如果函数 $g$ 将一个完备度量空间映射到其自身，并且对于定义域中的所有 $x,y$ 和某个常数 $L1$，满足 Lipschitz 界 $|g(x)-g(y)|\\le L|x-y|$，那么 $g$ 有一个唯一的不动点 $x^\\star$，并且对于定义域中的任何初始值 $x_0$，迭代 $x_{k+1}=g(x_k)$ 都收敛到 $x^\\star$。\n\n我们分析函数 $g(x)=\\cos x$ 在闭区间 $[0,1]$ 上的性质。首先，我们证明 $g$ 将 $[0,1]$ 映射到自身。对于 $x\\in[0,1]$，我们有 $\\cos x\\in[\\cos 1,\\,\\cos 0]=[\\cos 1,\\,1]$。由于 $\\cos 10$，因此可得 $g([0,1])\\subset[0,1]$。接下来，我们计算导数 $g'(x)=-\\sin x$。在 $[0,1]$ 上，函数 $\\sin x$ 是非负的，且上界为 $\\sin 1$，所以\n$$\n\\sup_{x\\in[0,1]}|g'(x)|=\\sup_{x\\in[0,1]}|\\sin x|=\\sin(1).\n$$\n因为 $\\sin(1)1$，我们可以使用中值定理 (MVT) 推导出 Lipschitz 界：对于任意 $x,y\\in[0,1]$，存在某个位于 $x$ 和 $y$ 之间的 $\\xi$，使得\n$$\n|g(x)-g(y)|=|\\cos x-\\cos y|=|g'(\\xi)|\\,|x-y|\\le \\sin(1)\\,|x-y|,\n$$\n因此 $g$ 是在 $[0,1]$ 上的一个压缩映射，其压缩常数为 $L=\\sin(1)1$。根据压缩映射定理，存在一个唯一的不动点 $x^\\star\\in[0,1]$，并且对于任意 $x_0\\in[0,1]$，由 $x_{k+1}=\\cos x_k$ 定义的序列都收敛到 $x^\\star$。\n\n接下来我们分析单调行为。注意到 $g$ 在 $[0,1]$ 上是严格递减的，因为 $g'(x)=-\\sin x\\le 0$，并且对于 $x\\in(0,1]$，我们有 $\\sin x0$。设 $x^\\star$ 为唯一不动点。考虑误差 $e_k=x_k-x^\\star$。利用中值定理，存在某个位于 $x_k$ 和 $x^\\star$ 之间的 $\\xi_k$，使得\n$$\ne_{k+1}=x_{k+1}-x^\\star=g(x_k)-g(x^\\star)=g'(\\xi_k)\\,(x_k-x^\\star)=-\\sin(\\xi_k)\\,e_k.\n$$\n在 $[0,1]$ 上，$\\sin(\\xi_k)\\in[0,\\sin(1)]$，只要 $\\sin(\\xi_k)0$， $e_{k+1}$ 的符号就与 $e_k$ 的符号相反。因此，除非 $e_k=0$，误差的符号会交替变化，所以整个序列 $\\{x_k\\}$ 通常是振荡的，而不是单调的。然而，因为 $g(x)$ 是一个递减函数，所以二次迭代函数 $g^{(2)}(x) = g(g(x))$ 是一个递增函数。可以证明，如果 $x_0 \\neq x^\\star$，那么偶数子序列 $\\{x_{2k}\\}$ 和奇数子序列 $\\{x_{2k+1}\\}$ 将分别单调地从 $x^\\star$ 的两侧收敛到不动点。例如，如果 $x_0  x^\\star$，那么 $x_1 > x^\\star$ 且 $x_2  x^\\star$。可以进一步证明 $x_0  x_2  x^\\star$ 并且 $x_1 > x_3 > x^\\star$，因此偶数子序列单调递增，奇数子序列单调递减。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef fixed_point_cos(x0, tol=1e-12, max_iter=1000):\n    \"\"\"\n    Perform fixed-point iteration x_{k+1} = cos(x_k) starting from x0.\n    Angles are in radians.\n    Returns:\n        x_approx: final approximation\n        iterations: number of iterations performed\n        seq: list of iterates including the initial value\n    \"\"\"\n    seq = [float(x0)]\n    x_prev = float(x0)\n    iterations = 0\n    for k in range(max_iter):\n        x_next = float(np.cos(x_prev))\n        seq.append(x_next)\n        iterations += 1\n        if abs(x_next - x_prev)  tol:\n            break\n        x_prev = x_next\n    return seq[-1], iterations, seq\n\ndef is_monotone(sequence, tol=0.0):\n    \"\"\"\n    Check if a sequence is monotone nondecreasing or monotone nonincreasing.\n    Equality is allowed.\n    tol can be used to soften comparisons, but defaults to strict.\n    \"\"\"\n    if len(sequence) = 1:\n        return True\n    diffs = [sequence[i+1] - sequence[i] for i in range(len(sequence)-1)]\n    nondecreasing = all(d >= -tol for d in diffs)\n    nonincreasing = all(d = tol for d in diffs)\n    return nondecreasing or nonincreasing\n\ndef solve():\n    # Define the test cases from the problem statement (radians).\n    test_cases = [\n        0.0,\n        0.5,\n        1.0,\n        0.7390851332151607,  # high-precision approximation to the fixed point\n    ]\n\n    results = []\n    for x0 in test_cases:\n        x_approx, iters, seq = fixed_point_cos(x0, tol=1e-12, max_iter=1000)\n        # Full sequence monotonicity\n        mono_full = is_monotone(seq, tol=0.0)\n        # Even-indexed subsequence: indices 0,2,4,...\n        even_seq = seq[0::2]\n        mono_even = is_monotone(even_seq, tol=0.0)\n        # Odd-indexed subsequence: indices 1,3,5,...\n        odd_seq = seq[1::2]\n        mono_odd = is_monotone(odd_seq, tol=0.0)\n        # Assemble result for this test case\n        results.append([x0, x_approx, iters, mono_full, mono_even, mono_odd])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3231288"}, {"introduction": "当一个算法能够收敛后，下一个实际问题便是它的效率。如果迭代的压缩常数 $L$ 非常接近 $1$，收敛过程可能会异常缓慢，缺乏实用价值。这个练习 [@problem_id:3130626] 将通过一个简单的仿射映射来展示这一问题，并引入一种强大的加速技术——艾特肯 (Aitken) 的 $\\Delta^2$ 加速法，来显著提升收敛速度。", "problem": "考虑一个由映射 $g:\\mathbb{R}\\to\\mathbb{R}$ 定义的实数轴上的一维不动点迭代。该映射是一个收缩映射，其利普希茨常数为 $L\\in[0,1)$。使用收缩映射的基本定义：对于所有 $x,y\\in\\mathbb{R}$，有 $|g(x)-g(y)|\\le L|x-y|$，以及不动点迭代的定义 $x_{k+1}=g(x_k)$。您的目标是构建并分析一族映射，当收缩常数 $L$ 接近 $1$ 时，该族映射表现出慢速线性收敛，然后应用一种经典的加速技术来量化其改进效果。\n\n使用仿射族\n$g(x)=L\\,x+(1-L)\\,c,$\n其中 $c\\in\\mathbb{R}$ 是一个已知常数。当 $L\\in[0,1)$ 时，该族是一个收缩映射，其不动点是满足 $x^\\star=g(x^\\star)$ 的值 $x^\\star$。\n\n仅从核心定义出发，完成以下任务。\n\n- 任务 A（普通不动点迭代）：对于给定的 $L\\in[0,1)$、不动点目标 $c\\in\\mathbb{R}$、初始猜测值 $x_0\\in\\mathbb{R}$ 和容差 $\\varepsilon0$，确定未经加速的不动点迭代 $x_{k+1}=g(x_k)$ 产生满足 $|x_k-c|\\le\\varepsilon$ 的迭代值 $x_k$ 所需的 $g$ 的最小求值次数。每次迭代计为一次 $g$ 的求值。仅使用问题数据中直接定义的量。\n\n- 任务 B（加速）：对不动点迭代应用一种标准的序列加速方法，特别是 Aitken 的 delta-squared 过程（当应用于不动点迭代时，也称为 Steffensen 加速法）。使用经典的三点变换，将通过连续应用 $g$ 生成的三元组 $(x_k,x_{k+1},x_{k+2})$ 转换为一个加速估计值 $\\hat{x}_k$。计算获得满足 $|\\hat{x}_k-c|\\le\\varepsilon$ 的加速估计值所需的 $g$ 的求值次数，其中每个加速估计值需要在当前的 $x_k$ 之外额外进行两次 $g$ 的求值来形成 $(x_{k+1},x_{k+2})$。如果在某一步数值退化导致无法应用该变换，则根据需要继续生成下一个三元组。\n\n- 任务 C（量化改进）：对于每种情况，计算加速比，即普通不动点迭代所需的求值次数与加速方法所需次数的比值。将此加速比表示为小数。\n\n设计您的程序以解决以下测试套件。在所有情况下，使用相同的容差 $\\varepsilon=10^{-8}$、初始猜测值 $x_0=c+1$ 和不动点目标 $c=3$。\n\n- 情况 1：$L=0.9$。\n- 情况 2：$L=0.99$。\n- 情况 3：$L=0.0$（边界情况）。\n- 情况 4：$L=0.9999$（接近边界，普通收敛非常慢）。\n\n您的程序必须输出单行，该行由一个用方括号括起来的逗号分隔列表组成，其中每个元素对应一种情况，并且本身是一个形式为 $[N_{\\text{plain}},N_{\\text{acc}},S]$ 的列表：\n- $N_{\\text{plain}}$ 是普通不动点迭代达到 $|x_k-c|\\le\\varepsilon$ 所需的 $g$ 的最小求值次数。\n- $N_{\\text{acc}}$ 是 Aitken 加速方案达到 $|\\hat{x}_k-c|\\le\\varepsilon$ 所需的 $g$ 的求值次数。\n- $S$ 是加速比 $N_{\\text{plain}}/N_{\\text{acc}}$，表示为小数。\n\n作为确切输出格式的示例，程序应打印出类似 $[[1,2,0.5],[\\dots],[\\dots],[\\dots]]$ 的单行，不含空格。\n\n此问题不涉及物理单位或角度。所有要求的输出均为指定的整数或小数。", "solution": "问题陈述被评估为有效。它在科学上基于不动点迭代和序列加速的数学理论，提法明确，提供了所有必要的数据，并使用客观、无歧义的语言表述。该问题是计算科学导论中的一个标准练习，满足有效问题的所有标准。\n\n我们开始进行求解，该过程分为对普通不动点迭代的分析（任务 A）、对加速迭代的分析（任务 B）和加速比的计算（任务 C）。\n\n不动点迭代由映射 $g(x) = L x + (1-L)c$ 定义，其中 $L \\in [0,1)$，迭代过程为 $x_{k+1} = g(x_k)$。此迭代的不动点 $x^\\star$ 是方程 $x^\\star = g(x^\\star)$ 的解。\n$$x^\\star = L x^\\star + (1-L)c$$\n$$x^\\star (1-L) = (1-L)c$$\n由于 $L \\in [0,1)$，项 $(1-L)$ 非零，因此我们可以用它来除。\n$$x^\\star = c$$\n这证实了常数 $c$ 是映射 $g(x)$ 的唯一不动点。\n\n### 任务 A：普通不动点迭代\n\n我们分析序列 $x_k$ 到不动点 $x^\\star = c$ 的收敛性。设第 $k$ 次迭代的误差为 $e_k = x_k - c$。\n$$x_{k+1} - c = g(x_k) - c$$\n$$x_{k+1} - c = (L x_k + (1-L)c) - c$$\n$$x_{k+1} - c = L x_k - Lc$$\n$$x_{k+1} - c = L(x_k - c)$$\n这给出了误差递推关系 $e_{k+1} = L e_k$。通过归纳法，第 $k$ 次迭代的误差与初始误差 $e_0 = x_0 - c$ 相关：\n$$e_k = L^k e_0$$\n终止条件是 $|x_k - c| \\le \\varepsilon$，用误差表示即为 $|e_k| \\le \\varepsilon$。\n$$|L^k e_0| \\le \\varepsilon$$\n$$|L|^k |x_0 - c| \\le \\varepsilon$$\n由于 $L \\in [0,1)$，我们有 $|L| = L$。问题指定 $x_0 = c+1$，因此 $|x_0 - c| = |(c+1) - c| = 1$。条件简化为：\n$$L^k \\le \\varepsilon$$\n我们必须找到满足此不等式的最小整数 $k \\ge 1$。获得 $x_k$ 所需的 $g$ 的求值次数恰好为 $k$。我们将其表示为 $N_{\\text{plain}}$。初始状态 $x_0$ 是给定的，因此对于 $k=0$ 不需要求值。由于 $|x_0-c|=1$ 且 $\\varepsilon=10^{-8}$，在 $k=0$ 时条件不满足。\n\n我们必须考虑 $L$ 的两种子情况。\n\n情况 $L=0$：\n映射为 $g(x) = (1-0)c = c$。第一个迭代值为 $x_1 = g(x_0) = c$。\n误差为 $|x_1 - c| = |c-c|=0$。由于 $0 \\le \\varepsilon$，条件在一次迭代后满足。\n因此，对于 $L=0$，$N_{\\text{plain}} = 1$。\n\n情况 $L \\in (0,1)$：\n我们通过对两边取自然对数来解不等式 $L^k \\le \\varepsilon$。\n$$k \\ln(L) \\le \\ln(\\varepsilon)$$\n由于 $L \\in (0,1)$，其对数 $\\ln(L)$ 为负。除以一个负数会反转不等号：\n$$k \\ge \\frac{\\ln(\\varepsilon)}{\\ln(L)}$$\n最小整数 $k$ 是此表达式的向上取整。\n$$N_{\\text{plain}} = \\left\\lceil \\frac{\\ln(\\varepsilon)}{\\ln(L)} \\right\\rceil$$\n\n### 任务 B：加速迭代\n\nAitken 的 delta-squared 过程从给定序列 $x_k$ 生成一个加速序列 $\\hat{x}_k$。加速估计的公式是：\n$$\\hat{x}_k = x_k - \\frac{(x_{k+1} - x_k)^2}{x_{k+2} - 2x_{k+1} + x_k}$$\n要计算第一个加速项 $\\hat{x}_0$，我们需要三元组 $(x_0, x_1, x_2)$。这需要两次 $g$ 的求值：$x_1 = g(x_0)$ 和 $x_2 = g(x_1)$。计算 $\\hat{x}_k$ 需要生成序列直到 $x_{k+2}$，这需要 $k+2$ 次 $g$ 的求值。我们寻求找到一个满足 $|\\hat{x}_k-c| \\le \\varepsilon$ 的估计值 $\\hat{x}_k$ 所需的总求值次数的最小值 $N_{\\text{acc}}$。\n\n让我们分析 Aitken 方法在仿射序列 $x_k = c + L^k(x_0-c)$ 上的性能。\n差分为：\n$$x_{k+1} - x_k = (c + L^{k+1}(x_0-c)) - (c + L^k(x_0-c)) = (L^{k+1} - L^k)(x_0-c) = L^k(L-1)(x_0-c)$$\n分母是二阶差分：\n$$x_{k+2} - 2x_{k+1} + x_k = (x_{k+2}-x_{k+1}) - (x_{k+1}-x_k)$$\n$$= L^{k+1}(L-1)(x_0-c) - L^k(L-1)(x_0-c) = (L^{k+1}-L^k)(L-1)(x_0-c)$$\n$$= L^k(L-1)(L-1)(x_0-c) = L^k(L-1)^2(x_0-c)$$\n只要 $L \\neq 0$、$L \\neq 1$ 且 $x_0 \\neq c$，分母就非零。问题约束 $L \\in [0,1)$ 和 $x_0 = c+1$ 保证了对于 $L \\in (0,1)$ 这一点成立。\n\nAitken 公式中的修正项变为：\n$$\\frac{(x_{k+1} - x_k)^2}{x_{k+2} - 2x_{k+1} + x_k} = \\frac{\\left[L^k(L-1)(x_0-c)\\right]^2}{L^k(L-1)^2(x_0-c)} = \\frac{L^{2k}(L-1)^2(x_0-c)^2}{L^k(L-1)^2(x_0-c)} = L^k(x_0-c)$$\n将此代回 $\\hat{x}_k$ 的公式中：\n$$\\hat{x}_k = x_k - L^k(x_0-c) = (c + L^k(x_0-c)) - L^k(x_0-c) = c$$\n这个显著的结果表明，对于仿射迭代，只要分母非零，Aitken 方法一步就能产生精确的不动点 $c$。\n\n对于所有 $L \\in (0,1)$，$\\hat{x}_0$ 的分母为 $(L-1)^2(x_0-c) \\neq 0$。因此，第一个加速估计值 $\\hat{x}_0$ 等于 $c$。误差 $|\\hat{x}_0 - c| = 0$，小于或等于任何正数 $\\varepsilon$。为了计算 $\\hat{x}_0$，我们需要 $x_1$ 和 $x_2$，这需要 2 次 $g$ 的求值。因此，对于所有 $L \\in (0,1)$，$N_{\\text{acc}} = 2$。\n\n对于边界情况 $L=0$，序列是 $x_0=c+1, x_1=c, x_2=c, \\dots$。\n让我们计算 $\\hat{x}_0$：\n$$x_1 - x_0 = c - (c+1) = -1$$\n$$x_2 - 2x_1 + x_0 = c - 2c + (c+1) = 1$$\n分母非零。\n$$\\hat{x}_0 = x_0 - \\frac{(x_1 - x_0)^2}{x_2 - 2x_1 + x_0} = (c+1) - \\frac{(-1)^2}{1} = c+1 - 1 = c$$\n再次找到了精确的不动点。这需要计算 $x_1=g(x_0)$ 和 $x_2=g(x_1)$，总共 2 次求值。所以，对于 $L=0$，$N_{\\text{acc}} = 2$。\n\n总之，对于所有测试用例，$N_{\\text{acc}} = 2$。\n\n### 任务 C：量化改进\n\n加速比 $S$ 是普通方法所需的求值次数与加速方法所需次数的比值：\n$$S = \\frac{N_{\\text{plain}}}{N_{\\text{acc}}}$$\n使用我们推导出的结果，这变为：\n$$S = \\frac{N_{\\text{plain}}}{2}$$\n\n### 测试用例计算\n- 共享参数：$c=3$, $x_0 = c+1 = 4$, $\\varepsilon=10^{-8}$。\n- $\\ln(\\varepsilon) = \\ln(10^{-8}) = -8 \\ln(10) \\approx -18.42068$。\n\n情况 1：$L=0.9$\n$N_{\\text{plain}} = \\lceil \\frac{\\ln(10^{-8})}{\\ln(0.9)} \\rceil = \\lceil \\frac{-18.42068}{-0.10536} \\rceil = \\lceil 174.83 \\rceil = 175$。\n$N_{\\text{acc}} = 2$。\n$S = 175 / 2 = 87.5$。\n\n情况 2：$L=0.99$\n$N_{\\text{plain}} = \\lceil \\frac{\\ln(10^{-8})}{\\ln(0.99)} \\rceil = \\lceil \\frac{-18.42068}{-0.01005} \\rceil = \\lceil 1832.85 \\rceil = 1833$。\n$N_{\\text{acc}} = 2$。\n$S = 1833 / 2 = 916.5$。\n\n情况 3：$L=0.0$\n$N_{\\text{plain}} = 1$。\n$N_{\\text{acc}} = 2$。\n$S = 1 / 2 = 0.5$。\n\n情况 4：$L=0.9999$\n$N_{\\text{plain}} = \\lceil \\frac{\\ln(10^{-8})}{\\ln(0.9999)} \\rceil = \\lceil \\frac{-18.42068}{-0.000100005} \\rceil = \\lceil 184201.3 \\rceil = 184202$。\n$N_{\\text{acc}} = 2$。\n$S = 184202 / 2 = 92101.0$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the fixed-point iteration problem for a given test suite.\n\n    The problem analyzes an affine fixed-point iteration g(x) = L*x + (1-L)*c\n    with fixed point c. It compares the number of function evaluations\n    required for convergence by a plain iteration versus an Aitken-accelerated\n    iteration.\n    \"\"\"\n\n    # Define the shared parameters from the problem statement.\n    c = 3.0\n    x0 = c + 1.0\n    eps = 1e-8\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        0.9,      # Case 1\n        0.99,     # Case 2\n        0.0,      # Case 3\n        0.9999,   # Case 4\n    ]\n\n    def get_n_plain(L: float, x0: float, c: float, eps: float) -> int:\n        \"\"\"\n        Calculates the minimal number of evaluations for plain fixed-point iteration.\n\n        The error e_k = x_k - c follows e_k = L^k * e_0.\n        The condition is |e_k| = eps, which means L^k * |x0 - c| = eps.\n        Given |x0 - c| = 1, this simplifies to L^k = eps.\n        \"\"\"\n        # Check if already converged (not the case for the given problem data)\n        if abs(x0 - c) = eps:\n            return 0\n        \n        # Handle the boundary case L=0 separately.\n        # x_1 = g(x_0) = (1-0)*c = c. Convergence in 1 step.\n        if L == 0.0:\n            return 1\n        \n        # For L in (0, 1), solve L^k = eps for k.\n        # k * log(L) = log(eps) -> k >= log(eps) / log(L)\n        # We need the smallest integer k.\n        num_iterations = np.ceil(np.log(eps) / np.log(L))\n        return int(num_iterations)\n\n    def get_n_acc(L: float, x0: float, c: float, eps: float) -> int:\n        \"\"\"\n        Calculates the minimal number of evaluations for Aitken-accelerated iteration.\n        \n        For an affine iteration g(x) = L*x + (1-L)*c, Aitken's method is known\n        to converge to the exact fixed point with the first accelerated estimate,\n        x_hat_0. Calculation of x_hat_0 requires the triple (x0, x1, x2).\n        \n        x1 = g(x0)  (1st evaluation)\n        x2 = g(x1)  (2nd evaluation)\n        \n        This holds for all L in [0, 1) as long as the denominator of Aitken's\n        formula is non-zero, which is true for the given test cases.\n        \"\"\"\n        # Check trivial convergence\n        if abs(x0 - c) = eps:\n            return 0\n            \n        # As derived in the solution, Aitken's method requires 2 evaluations\n        # to compute x_hat_0, which gives the exact solution c.\n        return 2\n\n    results = []\n    for L_val in test_cases:\n        N_plain = get_n_plain(L_val, x0, c, eps)\n        N_acc = get_n_acc(L_val, x0, c, eps)\n        \n        # Speedup is the ratio of evaluations.\n        S = N_plain / N_acc\n        \n        results.append([N_plain, N_acc, S])\n\n    # Format the output string exactly as specified in the problem,\n    # constructing it part by part to avoid extra spaces from str(list).\n    inner_parts = []\n    for res in results:\n        # For case L=0.9999, S is an integer value, but problem asks for decimal.\n        # Standard float formatting handles this.\n        inner_parts.append(f'[{res[0]},{res[1]},{res[2]}]')\n    \n    final_output = f\"[{','.join(inner_parts)}]\"\n\n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```", "id": "3130626"}, {"introduction": "最后一个练习关注数值编程中一个微妙但至关重要的问题：何时停止迭代？理论上等价的两个停止准则，在有限精度的计算机上可能表现出巨大差异。这个练习 [@problem_id:3130615] 精心设计了一些场景，揭示了舍入和相消误差如何导致一个准则失效而另一个成功，从而教会你在编写稳健的数值代码时的重要一课。", "problem": "您将研究不动点迭代的两种常见停止准则，以及有限精度算术如何导致它们不一致。考虑由递推关系 $x_{k+1} = g(x_k)$（对于 $k = 0, 1, 2, \\dots$）和给定的初始值 $x_0$ 定义的一维不动点迭代。在精确算术中，根据定义关系 $x_{k+1} = g(x_k)$，基于残差的量 $r_k = \\lvert x_k - g(x_k) \\rvert$ 和基于增量的量 $s_k = \\lvert x_{k+1} - x_k \\rvert$ 是相等的。然而，在浮点算术中，由于抵消和舍入误差，这两个计算出的量可能会不一致，有时甚至差异很大。您的任务是编写一个程序，该程序针对几个测试用例，在每次迭代中计算两种停止准则，并报告每个准则首次低于预定容差的迭代索引。您必须使用标准绝对值作为范数，所有角度都必须以弧度为单位。\n\n使用的基本原理和定义：\n- 函数 $g$ 的不动点是满足 $x^{\\star} = g(x^{\\star})$ 的 $x^{\\star}$。\n- 不动点迭代由 $x_{k+1} = g(x_k)$ 定义。\n- 对于一维问题，使用绝对值 $\\lvert \\cdot \\rvert$ 作为范数。\n- 所有角度必须以弧度为单位进行解释。\n\n在每次迭代索引 $k$ 处要评估的停止准则：\n- 基于残差的：对每个测试用例，使用指定的 $g$ 的形式计算 $r_k = \\lvert x_k - g(x_k) \\rvert$。\n- 基于增量的：使用计算出的下一个迭代值 $x_{k+1}$ 计算 $s_k = \\lvert x_{k+1} - x_k \\rvert$。\n- 记录 $k_{\\mathrm{res}}$ 为满足 $r_k  \\tau$（容差）的最小 $k$，如果在最大迭代次数 $K$ 之前没有出现这样的 $k$，则记录为 $-1$。\n- 记录 $k_{\\mathrm{inc}}$ 为满足 $s_k  \\tau$ 的最小 $k$，如果在最大迭代次数 $K$ 之前没有出现这样的 $k$，则记录为 $-1$。\n\n设计您的程序以运行以下测试套件。在每种情况下，完全按照指定实现 $g$，包括任何有意设计的数值稳定或不稳定的公式，并遵循给定的容差 $\\tau$、最大迭代次数 $K$ 和初始值 $x_0$。\n\n测试套件：\n1. 行为良好的映射（理想路径）：\n   - 函数：$g(x) = \\cos(x)$。\n   - 初始值：$x_0 = 1$。\n   - 容差：$\\tau = 10^{-10}$。\n   - 最大迭代次数：$K = 100$。\n   - 注意：使用标准的余弦函数，角度以弧度为单位。\n\n2. 抵消导致残差产生误导：\n   - 函数：$g(x) = x - \\log(1 + x)$，其中，对于迭代更新，您必须使用 $\\log(1+x)$ 的数值稳定计算方法来计算 $x_{k+1} = x_k - \\mathrm{log1p}(x_k)$，但对于残差，您必须使用朴素的复合计算 $\\log(1 + x_k)$（即，以浮点数计算 $1 + x_k$，然后取自然对数）来计算 $r_k = \\lvert \\log(1 + x_k) \\rvert$。当 $x_k$ 非常小时，这会故意引发抵消。\n   - 初始值：$x_0 = 10^{-8}$。\n   - 容差：$\\tau = 10^{-17}$。\n   - 最大迭代次数：$K = 5$。\n   - 本例不涉及角度。\n\n3. 舍入导致增量产生误导：\n   - 函数：$g(x) = x - \\arctan(x)$。\n   - 初始值：$x_0 = 10^{16}$。\n   - 容差：$\\tau = 10^{-12}$。\n   - 最大迭代次数：$K = 2$。\n   - 注意：使用标准反正切函数，角度以弧度为单位。\n\n对于每个测试用例，您的程序应生成两个整数：$k_{\\mathrm{res}}$ 和 $k_{\\mathrm{inc}}$。按以下顺序将三个测试用例的结果汇总到一个列表中：\n- 测试用例 1：$k_{\\mathrm{res}}$，$k_{\\mathrm{inc}}$。\n- 测试用例 2：$k_{\\mathrm{res}}$，$k_{\\mathrm{inc}}$。\n- 测试用例 3：$k_{\\mathrm{res}}$，$k_{\\mathrm{inc}}$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含六个整数，以逗号分隔的列表形式用方括号括起来，顺序与上文指定的完全一致。例如，格式必须是\n$[k_{\\mathrm{res},1},k_{\\mathrm{inc},1},k_{\\mathrm{res},2},k_{\\mathrm{inc},2},k_{\\mathrm{res},3},k_{\\mathrm{inc},3}]$。\n\n不允许用户输入；所有参数必须按照上述规定进行硬编码。所有角度（如适用）均以弧度为单位。所有输出必须是整数。", "solution": "该问题要求在有限精度浮点算术的背景下，分析一维不动点迭代 $x_{k+1} = g(x_k)$ 的两种不同停止准则。这两种准则分别基于残差 $r_k = \\lvert x_k - g(x_k) \\rvert$ 和增量 $s_k = \\lvert x_{k+1} - x_k \\rvert$。在精确算术中，由于 $x_{k+1}$ 被定义为 $g(x_k)$，这两个量是相同的。然而，由于浮点计算中的舍入和抵消误差，它们的计算值可能会有显著差异，从而可能导致关于收敛的不同结论。\n\n任务是实现一个程序，针对三个特定的测试用例，执行不动点迭代，并追踪每个准则首次低于给定容差 $\\tau$ 的迭代索引 $k$。设 $k_{\\mathrm{res}}$ 是满足 $r_k  \\tau$ 的最小索引 $k$，而 $k_{\\mathrm{inc}}$ 是满足 $s_k  \\tau$ 的最小索引 $k$。如果在最大迭代次数 $K$ 内未满足条件，则报告相应的索引为 $-1$。迭代索引从 $k=0, 1, 2, \\dots, K-1$ 开始。\n\n每个测试用例的算法总体结构如下：\n1. 用初始值 $x_0$ 初始化当前迭代值 $x$。\n2. 初始化 $k_{\\mathrm{res}} = -1$ 和 $k_{\\mathrm{inc}} = -1$。\n3. 对 $k$ 从 $0$ 到 $K-1$ 进行循环：\n    a. 按照测试用例的规定计算 $g(x_k)$。请注意，对于用例 2，用于残差的公式与用于迭代更新的公式不同。\n    b. 使用规定的公式计算残差 $r_k = \\lvert x_k - g(x_k) \\rvert$。\n    c. 如果 $r_k  \\tau$ 且 $k_{\\mathrm{res}}$ 尚未设置（即 $k_{\\mathrm{res}} = -1$），则设置 $k_{\\mathrm{res}} = k$。\n    d. 使用规定的更新规则计算下一个迭代值 $x_{k+1}$。\n    e. 计算增量 $s_k = \\lvert x_{k+1} - x_k \\rvert$。\n    f. 如果 $s_k  \\tau$ 且 $k_{\\mathrm{inc}}$ 尚未设置（即 $k_{\\mathrm{inc}} = -1$），则设置 $k_{\\mathrm{inc}} = k$。\n    g. 更新迭代值以进行下一步：$x_k \\leftarrow x_{k+1}$。\n    h. 如果 $k_{\\mathrm{res}}$ 和 $k_{\\mathrm{inc}}$ 都已找到，可以提前终止循环。\n4. 循环结束后，报告确定的 $k_{\\mathrm{res}}$ 和 $k_{\\mathrm{inc}}$ 的值。\n\n让我们分析每个测试用例。\n\n**测试用例 1：行为良好的映射**\n- 函数：$g(x) = \\cos(x)$\n- 初始值：$x_0 = 1$\n- 容差：$\\tau = 10^{-10}$\n- 最大迭代次数：$K = 100$\n\n对于这种情况，迭代为 $x_{k+1} = \\cos(x_k)$。函数 $g(x) = \\cos(x)$ 在包含其不动点 $x^\\star \\approx 0.739085$ 的区间上是一个压缩映射，因为在 $x^\\star$ 附近 $\\lvert g'(x) \\rvert = \\lvert -\\sin(x) \\rvert  1$。$g(x_k)$ 的计算是数值稳定的。残差为 $r_k = \\lvert x_k - \\cos(x_k) \\rvert$，下一个迭代值为 $x_{k+1} = \\cos(x_k)$。增量为 $s_k = \\lvert x_{k+1} - x_k \\rvert = \\lvert \\cos(x_k) - x_k \\rvert$。在浮点算术中，如果我们计算 `gxk = cos(xk)`，那么 `rk = abs(xk - gxk)` 和 `sk = abs(gxk - xk)` 将产生相同的浮点值。因此，我们期望 $k_{\\mathrm{res}}$ 和 $k_{\\mathrm{inc}}$ 相等。迭代将一直进行，直到变化的幅度降到 $\\tau$ 以下。\n\n**测试用例 2：抵消导致残差产生误导**\n- 函数更新：$x_{k+1} = x_k - \\mathrm{log1p}(x_k)$\n- 残差评估：$r_k = \\lvert \\log(1 + x_k) \\rvert$ (朴素计算)\n- 初始值：$x_0 = 10^{-8}$\n- 容差：$\\tau = 10^{-17}$\n- 最大迭代次数：$K = 5$\n\n这个用例旨在展示抵消误差如何影响残差计算。$g(x) = x - \\log(1+x)$ 的不动点是 $x^\\star = 0$。\n更新规则 $x_{k+1} = x_k - \\mathrm{log1p}(x_k)$ 使用了数值稳定的函数 `log1p(x)`，该函数能为小的 $x$ 精确计算 $\\log(1+x)$。增量计算为 $s_k = \\lvert x_{k+1} - x_k \\rvert = \\lvert (x_k - \\mathrm{log1p}(x_k)) - x_k \\rvert = \\lvert-\\mathrm{log1p}(x_k)\\rvert$，这也是精确的。\n然而，残差是通过 $r_k = \\lvert \\log(1 + x_k) \\rvert$ 计算的。当 $x_k$ 变得非常小时，其值可能相对于 $1$ 小于机器精度。在标准的双精度浮点算术（IEEE 754）中，机器精度大约是 $2.22 \\times 10^{-16}$。如果 $\\lvert x_k \\rvert$ 足够小（例如，大约 $10^{-17}$），浮点和 $1 + x_k$ 将被舍入为精确的 $1.0$。因此，$\\log(1.0)$ 的计算结果为 $0$，导致 $r_k$ 过早地变为 $0$。\n追踪迭代过程：\n- $k=0$：$x_0 = 10^{-8}$。迭代给出 $x_1 = x_0 - \\mathrm{log1p}(x_0) \\approx x_0 - (x_0 - x_0^2/2) \\approx x_0^2/2 \\approx 0.5 \\times 10^{-16}$。\n- $k=1$：$x_1 \\approx 0.5 \\times 10^{-16}$。这个值小于机器精度。残差 $r_1$ 的计算涉及 $1+x_1$，其计算结果为 $1.0$。因此 $r_1 = \\lvert \\log(1.0) \\rvert = 0$。这小于 $\\tau = 10^{-17}$，所以 $k_{\\mathrm{res}}=1$。然而，增量为 $s_1 = \\lvert -\\mathrm{log1p}(x_1) \\rvert \\approx x_1 \\approx 0.5 \\times 10^{-16}$，这大于 $\\tau$。\n- $k=2$：$x_2 = x_1 - \\mathrm{log1p}(x_1) \\approx x_1^2/2 \\approx 0.125 \\times 10^{-32}$。增量 $s_2 = \\lvert -\\mathrm{log1p}(x_2) \\rvert \\approx x_2 \\approx 1.25 \\times 10^{-33}$。这个值小于 $\\tau$，所以 $k_{\\mathrm{inc}} = 2$。\n我们预测 $k_{\\mathrm{res}}=1$ 且 $k_{\\mathrm{inc}}=2$。\n\n**测试用例 3：舍入导致增量产生误导**\n- 函数：$g(x) = x - \\arctan(x)$\n- 初始值：$x_0 = 10^{16}$\n- 容差：$\\tau = 10^{-12}$\n- 最大迭代次数：$K = 2$\n\n这个用例演示了更新规则中的灾难性抵消如何误导基于增量的停止准则。$g(x) = x - \\arctan(x)$ 的不动点是 $x^\\star = 0$。\n对于像 $x_0 = 10^{16}$ 这样的大初始值，更新为 $x_1 = x_0 - \\arctan(x_0)$。对于大的 $x$，$\\arctan(x) \\approx \\pi/2 \\approx 1.57$。运算为 $10^{16} - (\\pi/2)$。在双精度算术中，在 $10^{16}$ 附近，连续可表示数之间的间隔大约是 $10^{16} \\times \\epsilon_{\\text{machine}} \\approx 10^{16} \\times 2.22 \\times 10^{-16} = 2.22$。由于要减去的值 $\\pi/2$ 小于这个间隔，减法 $10^{16} - \\pi/2$ 的结果被舍入到最接近的可表示数，也就是 $10^{16}$ 本身。\n因此，计算出的下一个迭代值是 $x_1 = x_0$。\n让我们分析 $k=0$ 时的停止准则：\n- 增量为 $s_0 = \\lvert x_1 - x_0 \\rvert = \\lvert 10^{16} - 10^{16} \\rvert = 0$。这小于 $\\tau=10^{-12}$，所以 $k_{\\mathrm{inc}}=0$。\n- 残差为 $r_0 = \\lvert x_0 - g(x_0) \\rvert = \\lvert x_0 - (x_0 - \\arctan(x_0)) \\rvert = \\lvert \\arctan(x_0) \\rvert = \\arctan(10^{16}) \\approx \\pi/2$。这远大于 $\\tau$，正确地表明迭代值远离不动点。\n迭代在 $x_k = 10^{16}$ 处停滞，因此残差准则永远不会被满足。\n我们预测 $k_{\\mathrm{inc}}=0$ 且 $k_{\\mathrm{res}}=-1$。\n\n程序将实现这三个测试用例，并将得到的六个整数（$k_{\\mathrm{res},1}, k_{\\mathrm{inc},1}, k_{\\mathrm{res},2}, k_{\\mathrm{inc},2}, k_{\\mathrm{res},3}, k_{\\mathrm{inc},3}$）收集到一个列表中作为最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Runs three test cases for fixed-point iteration, comparing residual-based\n    and increment-based stopping criteria in finite-precision arithmetic.\n    \"\"\"\n    \n    # Define test cases: (g_update, g_residual, x0, tau, K)\n    # g_residual is a function to calculate g(x) for the residual, which might\n    # differ from the update rule due to numerical stability considerations.\n    test_cases = [\n        {\n            \"name\": \"Well-behaved\",\n            \"g_update\": lambda x: np.cos(x),\n            \"g_residual\": lambda x: np.cos(x),\n            \"x0\": 1.0,\n            \"tau\": 1e-10,\n            \"K\": 100,\n        },\n        {\n            \"name\": \"Cancellation in residual\",\n            # Update uses stable log1p\n            \"g_update\": lambda x: x - np.log1p(x),\n            # Residual uses naive log(1+x) to induce cancellation\n            \"g_residual\": lambda x: x - np.log(1 + x),\n            \"x0\": 1e-8,\n            \"tau\": 1e-17,\n            \"K\": 5,\n        },\n        {\n            \"name\": \"Rounding in increment\",\n            \"g_update\": lambda x: x - np.arctan(x),\n            \"g_residual\": lambda x: x - np.arctan(x),\n            \"x0\": 1e16,\n            \"tau\": 1e-12,\n            \"K\": 2,\n        },\n    ]\n\n    results = []\n\n    for case in test_cases:\n        x_k = case[\"x0\"]\n        tau = case[\"tau\"]\n        K = case[\"K\"]\n        g_update = case[\"g_update\"]\n        g_residual = case[\"g_residual\"]\n\n        k_res = -1\n        k_inc = -1\n\n        for k in range(K):\n            # 1. Compute residual-based criterion\n            # The residual is r_k = |x_k - g(x_k)|. The problem defines g(x)\n            # differently for update vs residual in case 2.\n            # In general, g(x) = x - h(x) -> r_k = |h(x_k)|\n            # Case 1: h(x) = x - cos(x) => residual seems to be |x_k - cos(x_k)|\n            # Case 2: h(x) = log(1+x) => residual is |log(1+x_k)|\n            # Case 3: h(x) = arctan(x) => residual is |arctan(x_k)|\n            # The problem text can be interpreted as r_k = |x_k - g_residual(x_k)|. Let's follow this.\n            \n            # For Case 2, the problem states the residual is r_k = |log(1+x_k)|.\n            # This is equivalent to |x_k - g(x_k)| if g(x) = x - log(1+x_k).\n            if case[\"name\"] == \"Cancellation in residual\":\n                r_k = np.abs(np.log(1 + x_k))\n            else:\n                gx_for_res = g_residual(x_k)\n                r_k = np.abs(x_k - gx_for_res)\n\n            # Check residual stopping criterion\n            if r_k  tau and k_res == -1:\n                k_res = k\n\n            # 2. Compute next iterate and increment-based criterion\n            x_k_plus_1 = g_update(x_k)\n            s_k = np.abs(x_k_plus_1 - x_k)\n\n            # Check increment stopping criterion\n            if s_k  tau and k_inc == -1:\n                k_inc = k\n            \n            # 3. Update for next iteration\n            x_k = x_k_plus_1\n\n            # Optimization: stop if both criteria are met\n            if k_res != -1 and k_inc != -1:\n                break\n        \n        results.extend([k_res, k_inc])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3130615"}]}