{"hands_on_practices": [{"introduction": "千里之行，始于足下。在共轭梯度法中，第一步与最速下降法相同，都是将负梯度方向作为初始搜索方向。这项基础练习 [@problem_id:2211287] 将指导你计算这个初始方向和最优步长，为整个迭代过程奠定基础。", "problem": "考虑最小化二次目标函数 $f(\\mathbf{x}) = f(x_1, x_2)$ 的问题，该函数由下式给出：\n$$f(x_1, x_2) = \\frac{3}{2}x_1^2 + x_1x_2 + x_2^2 - x_1 - 4x_2$$\n其中 $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$。\n\n我们希望应用共轭梯度法，从初始点 $\\mathbf{x}_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ 开始。算法的第一次迭代将从 $\\mathbf{x}_0$ 移动到一个新点 $\\mathbf{x}_1 = \\mathbf{x}_0 + \\alpha_0 \\mathbf{d}_0$，其中 $\\mathbf{d}_0$ 是初始搜索方向，$\\alpha_0$ 是最优步长。\n\n确定初始搜索方向向量 $\\mathbf{d}_0 = \\begin{pmatrix} d_{0,1} \\\\ d_{0,2} \\end{pmatrix}$ 的分量，以及最优步长 $\\alpha_0$ 的精确值。\n\n请将最终答案表示为一个 $1 \\times 3$ 的行矩阵，按顺序包含 $d_{0,1}$、$d_{0,2}$ 和 $\\alpha_0$ 的值。必要时，所有值都应表示为精确分数。", "solution": "我们通过确定对称矩阵 $Q$ 和向量 $\\mathbf{c}$，将二次目标函数重写为标准形式 $f(\\mathbf{x})=\\frac{1}{2}\\mathbf{x}^{T}Q\\mathbf{x}-\\mathbf{c}^{T}\\mathbf{x}$。根据\n$$f(x_{1},x_{2})=\\frac{3}{2}x_{1}^{2}+x_{1}x_{2}+x_{2}^{2}-x_{1}-4x_{2},$$\n我们有\n$$Q=\\begin{pmatrix}3 & 1 \\\\ 1 & 2\\end{pmatrix},\\qquad \\mathbf{c}=\\begin{pmatrix}1 \\\\ 4\\end{pmatrix}。$$\n梯度为 $\\nabla f(\\mathbf{x})=Q\\mathbf{x}-\\mathbf{c}$。在初始点 $\\mathbf{x}_{0}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$，梯度为\n$$\\mathbf{g}_{0}=\\nabla f(\\mathbf{x}_{0})=Q\\mathbf{x}_{0}-\\mathbf{c}=\\begin{pmatrix}0 \\\\ 0\\end{pmatrix}-\\begin{pmatrix}1 \\\\ 4\\end{pmatrix}=\\begin{pmatrix}-1 \\\\ -4\\end{pmatrix}。$$\n在共轭梯度法中，初始搜索方向是负梯度：\n$$\\mathbf{d}_{0}=-\\mathbf{g}_{0}=\\begin{pmatrix}1 \\\\ 4\\end{pmatrix}。$$\n沿 $\\mathbf{d}_{0}$ 方向的精确线搜索步长通过最小化 $\\phi(\\alpha)=f(\\mathbf{x}_{0}+\\alpha\\mathbf{d}_{0})$ 得到，可得\n$$\\alpha_{0}=-\\frac{\\mathbf{d}_{0}^{T}\\mathbf{g}_{0}}{\\mathbf{d}_{0}^{T}Q\\mathbf{d}_{0}}=\\frac{\\mathbf{g}_{0}^{T}\\mathbf{g}_{0}}{\\mathbf{d}_{0}^{T}Q\\mathbf{d}_{0}},$$\n因为 $\\mathbf{d}_{0}=-\\mathbf{g}_{0}$。计算分子：\n$$\\mathbf{g}_{0}^{T}\\mathbf{g}_{0}=(-1)^{2}+(-4)^{2}=1+16=17。$$\n计算分母：\n$$Q\\mathbf{d}_{0}=\\begin{pmatrix}3 & 1 \\\\ 1 & 2\\end{pmatrix}\\begin{pmatrix}1 \\\\ 4\\end{pmatrix}=\\begin{pmatrix}7 \\\\ 9\\end{pmatrix},\\qquad \\mathbf{d}_{0}^{T}Q\\mathbf{d}_{0}=\\begin{pmatrix}1 & 4\\end{pmatrix}\\begin{pmatrix}7 \\\\ 9\\end{pmatrix}=7+36=43。$$\n因此，\n$$\\alpha_{0}=\\frac{17}{43}。$$\n因此，$d_{0,1}=1$，$d_{0,2}=4$，且 $\\alpha_{0}=\\frac{17}{43}$，必要时表示为精确分数。", "answer": "$$\\boxed{\\begin{pmatrix} 1 & 4 & \\frac{17}{43} \\end{pmatrix}}$$", "id": "2211287"}, {"introduction": "真正让共轭梯度法与众不同的是它对后续搜索方向的巧妙选择。这些方向相对于系统矩阵是“共轭”的，确保了每一步都朝着最小值前进，而不会抵消先前步骤的成果。在这个练习 [@problem_id:2211315] 中，你将通过计算来验证这一关键属性，从而更深刻地理解该算法的效率。", "problem": "考虑一个无约束优化问题，即最小化一个二维二次函数 $f(\\mathbf{x})$，其中 $\\mathbf{x} = \\begin{pmatrix} x_1 \\\\ x_2 \\end{pmatrix}$。该函数定义为 $f(\\mathbf{x}) = \\frac{1}{2}\\mathbf{x}^T A \\mathbf{x} - \\mathbf{b}^T \\mathbf{x}$，其中对称正定矩阵 $A$ 和向量 $\\mathbf{b}$ 由下式给出：\n$$\nA = \\begin{pmatrix} 5 & 2 \\\\ 2 & 1 \\end{pmatrix}, \\quad \\mathbf{b} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\n$$\n我们将使用共轭梯度 (CG) 法的 Fletcher-Reeves 变体来寻找该函数的最小值。该函数的梯度为 $\\nabla f(\\mathbf{x}) = A\\mathbf{x} - \\mathbf{b}$。从点 $\\mathbf{x}_k$ 开始，CG 方法的迭代步骤如下：\n\n1.  令 $g_k = \\nabla f(\\mathbf{x}_k)$ 为当前点的梯度。\n2.  搜索方向 $\\mathbf{p}_k$ 由以下规则确定：\n    -   对于第一次迭代 ($k=0$)：$\\mathbf{p}_0 = -g_0$。\n    -   对于后续迭代 ($k > 0$)：$\\mathbf{p}_k = -g_k + \\beta_k \\mathbf{p}_{k-1}$，其中 $\\beta_k = \\frac{g_k^T g_k}{g_{k-1}^T g_{k-1}}$。\n3.  步长 $\\alpha_k$ 计算公式为 $\\alpha_k = \\frac{g_k^T g_k}{\\mathbf{p}_k^T A \\mathbf{p}_k}$。\n4.  位置更新公式为 $\\mathbf{x}_{k+1} = \\mathbf{x}_k + \\alpha_k \\mathbf{p}_k$。\n5.  下一次迭代的梯度使用高效公式 $g_{k+1} = g_k + \\alpha_k A \\mathbf{p}_k$ 进行更新。\n\n如果数量 $\\mathbf{u}^T A \\mathbf{v}$ 等于零，则称两个向量 $\\mathbf{u}$ 和 $\\mathbf{v}$ 关于矩阵 $A$ 是共轭的。CG 方法的一个关键特性是它生成一系列相互共轭的搜索方向。\n\n您的任务是从点 $\\mathbf{x}_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$ 开始应用 CG 方法，生成前两个搜索方向 $\\mathbf{p}_0$ 和 $\\mathbf{p}_1$。然后，计算表达式 $\\mathbf{p}_0^T A \\mathbf{p}_1$ 的值。", "solution": "我们最小化 $f(\\mathbf{x})=\\frac{1}{2}\\mathbf{x}^{T}A\\mathbf{x}-\\mathbf{b}^{T}\\mathbf{x}$，其中 $A=\\begin{pmatrix}5 & 2\\\\2 & 1\\end{pmatrix}$，$\\mathbf{b}=\\begin{pmatrix}1\\\\1\\end{pmatrix}$，从 $\\mathbf{x}_{0}=\\begin{pmatrix}0\\\\0\\end{pmatrix}$ 开始。梯度为 $\\nabla f(\\mathbf{x})=A\\mathbf{x}-\\mathbf{b}$。\n\n计算初始梯度：\n$$\n\\mathbf{g}_{0}=\\nabla f(\\mathbf{x}_{0})=A\\mathbf{x}_{0}-\\mathbf{b}=\\begin{pmatrix}0\\\\0\\end{pmatrix}-\\begin{pmatrix}1\\\\1\\end{pmatrix}=\\begin{pmatrix}-1\\\\-1\\end{pmatrix}.\n$$\n第一个搜索方向：\n$$\n\\mathbf{p}_{0}=-\\mathbf{g}_{0}=\\begin{pmatrix}1\\\\1\\end{pmatrix}.\n$$\n步长 $\\alpha_{0}$：\n$$\n\\alpha_{0}=\\frac{\\mathbf{g}_{0}^{T}\\mathbf{g}_{0}}{\\mathbf{p}_{0}^{T}A\\mathbf{p}_{0}},\\quad \\mathbf{g}_{0}^{T}\\mathbf{g}_{0}=(-1)^{2}+(-1)^{2}=2,\n$$\n$$\nA\\mathbf{p}_{0}=\\begin{pmatrix}5 & 2\\\\2 & 1\\end{pmatrix}\\begin{pmatrix}1\\\\1\\end{pmatrix}=\\begin{pmatrix}7\\\\3\\end{pmatrix},\\quad \\mathbf{p}_{0}^{T}A\\mathbf{p}_{0}=\\begin{pmatrix}1 & 1\\end{pmatrix}\\begin{pmatrix}7\\\\3\\end{pmatrix}=10,\n$$\n$$\n\\alpha_{0}=\\frac{2}{10}=\\frac{1}{5}.\n$$\n更新位置和梯度：\n$$\n\\mathbf{x}_{1}=\\mathbf{x}_{0}+\\alpha_{0}\\mathbf{p}_{0}=\\begin{pmatrix}0\\\\0\\end{pmatrix}+\\frac{1}{5}\\begin{pmatrix}1\\\\1\\end{pmatrix}=\\begin{pmatrix}\\frac{1}{5}\\\\\\frac{1}{5}\\end{pmatrix},\n$$\n$$\n\\mathbf{g}_{1}=\\mathbf{g}_{0}+\\alpha_{0}A\\mathbf{p}_{0}=\\begin{pmatrix}-1\\\\-1\\end{pmatrix}+\\frac{1}{5}\\begin{pmatrix}7\\\\3\\end{pmatrix}=\\begin{pmatrix}\\frac{2}{5}\\\\-\\frac{2}{5}\\end{pmatrix}.\n$$\n计算 $\\beta_{1}$ 和第二个搜索方向 $\\mathbf{p}_{1}$：\n$$\n\\beta_{1}=\\frac{\\mathbf{g}_{1}^{T}\\mathbf{g}_{1}}{\\mathbf{g}_{0}^{T}\\mathbf{g}_{0}}=\\frac{\\left(\\frac{2}{5}\\right)^{2}+\\left(-\\frac{2}{5}\\right)^{2}}{2}=\\frac{\\frac{8}{25}}{2}=\\frac{4}{25},\n$$\n$$\n\\mathbf{p}_{1}=-\\mathbf{g}_{1}+\\beta_{1}\\mathbf{p}_{0}=-\\begin{pmatrix}\\frac{2}{5}\\\\-\\frac{2}{5}\\end{pmatrix}+\\frac{4}{25}\\begin{pmatrix}1\\\\1\\end{pmatrix}=\\begin{pmatrix}-\\frac{6}{25}\\\\\\frac{14}{25}\\end{pmatrix}.\n$$\n最后，计算 $\\mathbf{p}_{0}^{T}A\\mathbf{p}_{1}$：\n$$\nA\\mathbf{p}_{1}=\\begin{pmatrix}5 & 2\\\\2 & 1\\end{pmatrix}\\begin{pmatrix}-\\frac{6}{25}\\\\\\frac{14}{25}\\end{pmatrix}=\\begin{pmatrix}-\\frac{2}{25}\\\\\\frac{2}{25}\\end{pmatrix},\n$$\n$$\n\\mathbf{p}_{0}^{T}A\\mathbf{p}_{1}=\\begin{pmatrix}1 & 1\\end{pmatrix}\\begin{pmatrix}-\\frac{2}{25}\\\\\\frac{2}{25}\\end{pmatrix}=0.\n$$\n这证实了前两个 CG 搜索方向是 A-共轭的。", "answer": "$$\\boxed{0}$$", "id": "2211315"}, {"introduction": "理论应用于实际问题时才能展现其生命力。这项高级实践 [@problem_id:3110688] 将挑战你使用共轭梯度法求解一个物理弹簧-质量系统的平衡状态。你不仅将为一个大型稀疏系统实现该算法，还将探索预处理技术如何在你处理具有挑战性的病态问题时显著提升性能。", "problem": "给定一个一维线性弹簧链，其两端连接到固定支撑上。设 $n$ 是内部节点的数量，其位移未知，索引为 $i \\in \\{1,2,\\dots,n\\}$。设边界节点的索引为 $0$ 和 $n+1$，并固定在零位移处。设连接节点 $i$ 和节点 $i+1$ 的弹簧的刚度为 $k_i > 0$，其中 $i \\in \\{0,1,\\dots,n\\}$。在由胡克定律和力平衡控制的静态平衡下，位移 $u \\in \\mathbb{R}^n$ 满足线性系统\n$$\nK u = f,\n$$\n其中 $K \\in \\mathbb{R}^{n \\times n}$ 是对称正定 (SPD) 矩阵，其元素为\n$$\nK_{i,i} = k_{i-1} + k_i \\quad \\text{for} \\; i=1,\\dots,n,\n$$\n$$\nK_{i,i+1} = -k_i \\quad \\text{for} \\; i=1,\\dots,n-1,\n$$\n$$\nK_{i,i-1} = -k_{i-1} \\quad \\text{for} \\; i=2,\\dots,n,\n$$\n且 $f \\in \\mathbb{R}^n$ 是施加在内部节点上的外力向量。共轭梯度 (CG) 法是一种求解 SPD 系统的克雷洛夫子空间方法，可以解释为最小化二次能量泛函\n$$\n\\Phi(u) = \\tfrac{1}{2} u^\\top K u - f^\\top u,\n$$\n其搜索方向相对于 $K$-内积是相互共轭的。\n\n您的任务是编写一个完整的程序，该程序：\n- 根据给定的刚度 $k_i$，通过其三对角结构隐式构造 $K$，而不形成稠密矩阵。\n- 使用共轭梯度法求解 $K u = f$，从零向量开始，当相对残差范数 $\\|r_k\\|_2/\\|f\\|_2 \\leq \\varepsilon$ 或迭代次数达到指定的最大值时停止。这里 $r_k = f - K u_k$ 是第 $k$ 次迭代的残差。\n- 使用简单的对角 (Jacobi) 预条件子重复求解，该预条件子使用 $M = \\mathrm{diag}(K)$，因此预处理后的系统是 $M^{-1} K u = M^{-1} f$。\n- 对于每个测试用例和每种求解器变体，报告所用的整数迭代次数和最终的相对残差 $\\|r_k\\|_2/\\|f\\|_2$ (作为浮点数)。\n\n对所有运行使用以下固定的容差和迭代上限：\n- 容差：$\\varepsilon = 10^{-8}$。\n- 最大迭代次数：$n$。\n\n将力向量设置为在最后一个内部节点上的单位载荷，\n$$\nf = [0, 0, \\dots, 0, 1]^\\top \\in \\mathbb{R}^n.\n$$\n\n测试套件。使用 $n=200$ 和以下四种刚度模式；在每种情况下，确保所有 $k_i$ 都严格为正：\n1. 均匀刚度（理想情况）：对于所有 $i \\in \\{0,1,\\dots,n\\}$，$k_i = 1$。\n2. 块状对比（中等异质性）：对于所有 $i$，$k_i = 1$，除了索引 $i \\in \\{80,81,\\dots,120\\}$ 处 $k_i = 10$。\n3. 对数正态变异性（强异质性）：对于所有 $i$，$k_i = \\exp(Z_i)$，其中 $Z_i$ 是独立同分布的正态随机变量，均值为 $0$，标准差为 $1$，使用固定的种子 $42$ 确定性地生成。也就是说，对于所有 $i$，$Z_i \\sim \\mathcal{N}(0,1)$，并且必须将随机数生成器初始化为 $42$ 以使结果可复现。\n4. 近奇异瓶颈（边界情况）：对于所有 $i$，$k_i = 1$，除了 $k_{100} = 10^{-6}$。\n\n输出规范。对于每个测试用例，运行无预处理的共轭梯度法和雅可比预处理的共轭梯度法。记录：\n- 方法所用的整数迭代次数（等于满足停止准则时的迭代次数，如果未满足准则，则为最大迭代次数 $n$）。\n- 最终的相对残差（作为浮点数）。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须按以下顺序包含所有测试用例的平铺值：\n$$\n[\\text{it}_1^\\text{none}, \\text{it}_1^\\text{jac}, \\text{rel}_1^\\text{none}, \\text{rel}_1^\\text{jac}, \\text{it}_2^\\text{none}, \\text{it}_2^\\text{jac}, \\text{rel}_2^\\text{none}, \\text{rel}_2^\\text{jac}, \\text{it}_3^\\text{none}, \\text{it}_3^\\text{jac}, \\text{rel}_3^\\text{none}, \\text{rel}_3^\\text{jac}, \\text{it}_4^\\text{none}, \\text{it}_4^\\text{jac}, \\text{rel}_4^\\text{none}, \\text{rel}_4^\\text{jac}],\n$$\n其中 $\\text{it}_j^\\cdot$ 是整数，$\\text{rel}_j^\\cdot$ 是浮点数，对应测试用例 $j \\in \\{1,2,3,4\\}$ 和由上标指示的求解器变体。输出中不需要物理单位，因为报告的量是无量纲的计数和范数。程序必须是自包含的，并且在重复运行时产生相同的结果。", "solution": "我们从线性弹簧的胡克定律开始，该定律指出弹簧中的力与其伸长量成正比，即 $F = k \\Delta$，其中 $k$ 是刚度，$\\Delta$ 是长度变化量。在一个由弹簧连接且端点固定的节点组成的一维链中，当每个内部节点上的合力等于所施加的外力时，达到静态平衡。记 $u_i$ 为内部节点 $i$ 的位移，则其左侧弹簧施加到节点 $i$ 上的力为 $k_{i-1}(u_{i-1} - u_i)$（由于左边界固定，故 $u_0 = 0$），而其右侧弹簧施加的力为 $k_{i}(u_{i+1} - u_i)$（由于右边界固定，故 $u_{n+1} = 0$）。将这些力相加并令其等于外力 $f_i$ 可得到平衡方程\n$$\nk_{i-1}(u_{i-1} - u_i) + k_{i}(u_{i+1} - u_i) = f_i, \\quad i=1,\\dots,n.\n$$\n整理各项可得线性系统 $K u = f$，其中\n$$\nK_{i,i} = k_{i-1} + k_{i}, \\quad K_{i,i-1} = -k_{i-1}, \\quad K_{i,i+1} = -k_i,\n$$\n其他位置为零，这证实了 $K$ 是三对角且对称的。此外，$K$ 是对称正定 (SPD) 的，因为它来自于严格凸的二次能量泛函的二阶导数（海森矩阵）\n$$\n\\Phi(u) = \\tfrac{1}{2} \\sum_{i=0}^{n} k_i (u_{i+1} - u_i)^2 - \\sum_{i=1}^{n} f_i u_i,\n$$\n其中 $u_0 = u_{n+1} = 0$。由于对所有 $i$ 都有 $k_i > 0$，二次型 $u^\\top K u$ 对所有非零 $u$ 均为正，这意味着正定性。\n\n共轭梯度 (CG) 法通过在扩展的克雷洛夫子空间上最小化 $\\Phi(u)$ 来求解 SPD 系统。它构造了 $K$-共轭的搜索方向 $\\{p_k\\}$，即对于 $i \\neq j$ 有 $p_i^\\top K p_j = 0$，并沿着这些方向进行线搜索。从 $u_0 = 0$ 开始，残差为 $r_0 = f - K u_0 = f$，并设 $p_0 = r_0$，算法迭代更新\n$$\n\\alpha_k = \\frac{r_k^\\top r_k}{p_k^\\top K p_k}, \\quad u_{k+1} = u_k + \\alpha_k p_k, \\quad r_{k+1} = r_k - \\alpha_k K p_k,\n$$\n并计算\n$$\n\\beta_{k+1} = \\frac{r_{k+1}^\\top r_{k+1}}{r_k^\\top r_k}, \\quad p_{k+1} = r_{k+1} + \\beta_{k+1} p_k.\n$$\n一个等价且通常更稳健的变体使用预处理后的残差 $z_k = M^{-1} r_k$，其中预条件子 $M$ 在某种意义上近似于 $K$。预处理共轭梯度 (PCG) 法的递推式变为\n$$\n\\alpha_k = \\frac{r_k^\\top z_k}{p_k^\\top K p_k}, \\quad u_{k+1} = u_k + \\alpha_k p_k, \\quad r_{k+1} = r_k - \\alpha_k K p_k,\n$$\n$$\nz_{k+1} = M^{-1} r_{k+1}, \\quad \\beta_{k+1} = \\frac{r_{k+1}^\\top z_{k+1}}{r_k^\\top z_k}, \\quad p_{k+1} = z_{k+1} + \\beta_{k+1} p_k.\n$$\n一个简单且广泛使用的选择是雅可比预条件子，$M = \\mathrm{diag}(K)$，其应用成本低廉，并且可以减小特征值的分布范围。\n\nCG 的收敛速度由条件数 $\\kappa(K) = \\lambda_{\\max}(K)/\\lambda_{\\min}(K)$ 控制。能量范数中的一个经典界是\n$$\n\\frac{\\|e_k\\|_K}{\\|e_0\\|_K} \\leq 2 \\left( \\frac{\\sqrt{\\kappa(K)} - 1}{\\sqrt{\\kappa(K)} + 1} \\right)^k,\n$$\n其中 $e_k = u^\\star - u_k$，$u^\\star$ 是精确解。当刚度值在链上变化很大时，$K$ 的特征值会散开，$\\kappa(K)$ 会增大，从而减慢 CG 的收敛速度。预处理旨在减小 $\\kappa(M^{-1}K)$，使特征值聚集，从而加速收敛。\n\n此问题的算法设计：\n- 使用刚度边列表 $\\{k_i\\}_{i=0}^{n}$，通过其三对角元素隐式地构造 $K$。对角元素为 $d_i = k_{i-1} + k_i$ (对于 $i=1,\\dots,n$)，非对角元素为 $o_i = -k_i$ (对于 $i=1,\\dots,n-1$)。为了高效地计算乘法 $y = K x$，计算\n$$\ny_i = d_i x_i + o_i x_{i+1} + o_{i-1} x_{i-1},\n$$\n并对末端索引进行适当处理。\n- 实现 CG 和 PCG，使用零向量作为初始猜测。停止准则为 $\\|r_k\\|_2 / \\|f\\|_2 \\leq 10^{-8}$ 或 $k$ 达到 $n$。\n- 对于雅可比预条件子，设置 $M = \\mathrm{diag}(K)$，因此 $M^{-1}$ 的作用是将每个分量除以相应的对角元素 $d_i$。\n- 按规定准备四个测试用例。第三个测试用例必须使用固定的正态随机数种子确定性地生成，然后转换为 $k_i = \\exp(Z_i)$，以确保 $k_i > 0$。\n- 对于每个测试用例，运行两种求解器，记录迭代次数和最终相对残差，并以规定的单行列表格式打印汇总结果。\n\n结果解释：\n- 在均匀刚度的情况下，特征值表现良好，CG 应在相对较少的迭代次数内收敛；雅可比预条件子可能提供适度的改进。\n- 在块状对比的情况下，某一段刚度的增加会产生局部高频模式，从而增加条件数。与无预处理的 CG 相比，雅可比预处理通常会减少迭代次数。\n- 在对数正态情况下，$k_i$ 的巨大变异性导致强异质性和更宽的特征值谱；预处理应该会有更显著的效果。\n- 在近奇异瓶颈的情况下，一个非常小的刚度会产生一个几乎不连通的系统，具有极小的特征值和巨大的条件数；无预处理的 CG 可能会接近迭代上限，即使是雅可比预处理也可能只能部分缓解这个问题。\n\n最终的程序清晰且确定性地实现了这些步骤，并以整数和浮点数的有序列表形式输出了所需的单行结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef build_tridiag_from_edges(k_edges: np.ndarray):\n    \"\"\"\n    Given spring stiffnesses between consecutive nodes k_edges of length n+1\n    (including boundary-to-node springs), construct the tridiagonal representation\n    of the SPD stiffness matrix K for n interior unknowns.\n\n    Returns:\n        diag: length-n diagonal entries of K\n        off:  length-(n-1) off-diagonal entries (both upper and lower, symmetric)\n    \"\"\"\n    # k_edges shape: (n+1,)\n    n = k_edges.shape[0] - 1\n    # Diagonal: d_i = k_{i-1} + k_i for i = 1..n, but using 0-based indexing\n    diag = k_edges[:-1] + k_edges[1:]\n    # Off-diagonal entries correspond to interior springs between nodes i and i+1: -k_i for i=1..n-1\n    off = -k_edges[1:-1]\n    return diag, off\n\ndef matvec_tridiag(diag: np.ndarray, off: np.ndarray, x: np.ndarray):\n    \"\"\"\n    Multiply y = K x for a symmetric tridiagonal K specified by diag and off.\n    diag length n, off length n-1.\n    \"\"\"\n    n = diag.shape[0]\n    y = diag * x\n    if n > 1:\n        y[:-1] += off * x[1:]\n        y[1:] += off * x[:-1]\n    return y\n\ndef pcg_tridiag(diag: np.ndarray, off: np.ndarray, b: np.ndarray, M_inv: np.ndarray | None,\n                tol: float, max_iter: int):\n    \"\"\"\n    Preconditioned Conjugate Gradient for symmetric positive definite tridiagonal system.\n    If M_inv is None, performs unpreconditioned CG.\n\n    Returns:\n        x: solution vector\n        iters: iteration count used (int)\n        rel_res: final relative residual ||r|| / ||b|| (float)\n    \"\"\"\n    n = diag.shape[0]\n    x = np.zeros(n, dtype=float)\n    r = b.copy()  # since A x0 = 0 for x0 = 0\n    b_norm = np.linalg.norm(b)\n    # Handle the trivial case b == 0 to avoid division by zero in relative residual\n    if b_norm == 0.0:\n        return x, 0, 0.0\n\n    # Apply preconditioner\n    if M_inv is None:\n        z = r.copy()\n    else:\n        z = M_inv * r\n\n    p = z.copy()\n    rz_old = float(np.dot(r, z))\n\n    rel_res = np.linalg.norm(r) / b_norm\n    if rel_res = tol:\n        return x, 0, rel_res\n\n    iters = 0\n    for k in range(max_iter):\n        Ap = matvec_tridiag(diag, off, p)\n        pAp = float(np.dot(p, Ap))\n        # Guard against breakdown (should not occur for SPD and proper preconditioning)\n        if pAp = 0.0:\n            iters = k\n            rel_res = np.linalg.norm(r) / b_norm\n            return x, iters, rel_res\n        alpha = rz_old / pAp\n        x += alpha * p\n        r -= alpha * Ap\n        rel_res = np.linalg.norm(r) / b_norm\n        iters = k + 1\n        if rel_res = tol:\n            break\n        if M_inv is None:\n            z = r.copy()\n        else:\n            z = M_inv * r\n        rz_new = float(np.dot(r, z))\n        # Guard against breakdown\n        if rz_old == 0.0:\n            break\n        beta = rz_new / rz_old\n        p = z + beta * p\n        rz_old = rz_new\n\n    # Return final values\n    return x, iters, rel_res\n\ndef make_test_cases(n: int):\n    \"\"\"\n    Create the four test cases as specified:\n      1) Uniform stiffness: k_i = 1\n      2) Block contrast: k_i = 1 except k_i = 10 for i in [80, 120]\n      3) Log-normal: k_i = exp(Z_i), Z_i ~ N(0,1) with seed 42\n      4) Bottleneck: k_i = 1 except k_100 = 1e-6\n    Returns a list of k_edges arrays.\n    \"\"\"\n    cases = []\n\n    # Case 1: Uniform\n    k_uniform = np.ones(n + 1, dtype=float)\n    cases.append(k_uniform)\n\n    # Case 2: Block contrast\n    k_block = np.ones(n + 1, dtype=float)\n    # Indices 80..120 inclusive (safe within 0..n)\n    low = 80\n    high = min(120, n)  # ensure bound for n=200\n    k_block[low:high + 1] = 10.0\n    cases.append(k_block)\n\n    # Case 3: Log-normal with seed 42\n    rng = np.random.default_rng(42)\n    Z = rng.normal(loc=0.0, scale=1.0, size=n + 1)\n    k_logn = np.exp(Z)\n    cases.append(k_logn)\n\n    # Case 4: Near-singular bottleneck\n    k_bottle = np.ones(n + 1, dtype=float)\n    bottleneck_index = 100\n    if 0 = bottleneck_index = n:\n        k_bottle[bottleneck_index] = 1e-6\n    cases.append(k_bottle)\n\n    return cases\n\ndef run_case(k_edges: np.ndarray, tol: float):\n    \"\"\"\n    Build K from k_edges, run CG and Jacobi-PCG, return iteration counts and final relative residuals.\n    \"\"\"\n    diag, off = build_tridiag_from_edges(k_edges)\n    n = diag.shape[0]\n    b = np.zeros(n, dtype=float)\n    b[-1] = 1.0  # unit load at the last interior node\n    max_iter = n\n\n    # Unpreconditioned CG\n    x_none, it_none, rel_none = pcg_tridiag(diag, off, b, M_inv=None, tol=tol, max_iter=max_iter)\n\n    # Jacobi preconditioner M = diag(K)\n    M_inv = 1.0 / diag\n    x_jac, it_jac, rel_jac = pcg_tridiag(diag, off, b, M_inv=M_inv, tol=tol, max_iter=max_iter)\n\n    return it_none, it_jac, rel_none, rel_jac\n\ndef solve():\n    # Define the test cases from the problem statement.\n    n = 200\n    tol = 1e-8\n    k_cases = make_test_cases(n)\n\n    results = []\n    for k_edges in k_cases:\n        it_none, it_jac, rel_none, rel_jac = run_case(k_edges, tol)\n        # Append in the specified flattened order: it_none, it_jac, rel_none, rel_jac\n        results.extend([it_none, it_jac, rel_none, rel_jac])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3110688"}]}