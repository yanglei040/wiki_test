{"hands_on_practices": [{"introduction": "嵌入式龙格-库塔方法的核心在于无需额外计算函数即可估算局部截断误差。但为什么主方法和嵌入式方法的阶数必须不同？本练习将通过符号推导来回答这一根本问题。你将从阶数条件出发，构建一个$p=2(1)$的嵌入式方法族，并揭示一个病态案例，阐明为何同阶嵌入式估算器在关键测试问题上会失效，从而为自适应步长控制的设计原则打下坚实基础。[@problem_id:3123519]", "problem": "考虑一个带有一个嵌入式估计器的一般两级显式龙格-库塔（RK）方法。其各级定义如下：\n$$\nk_{1} \\;=\\; f(y_{n}), \\qquad k_{2} \\;=\\; f\\!\\big(y_{n} + h\\,a_{21}\\,k_{1}\\big),\n$$\n主更新和嵌入式更新分别为\n$$\ny_{n+1}^{(p)} \\;=\\; y_{n} + h\\big(b_{1}\\,k_{1} + b_{2}\\,k_{2}\\big), \\qquad y_{n+1}^{(\\hat{p})} \\;=\\; y_{n} + h\\big(\\hat{b}_{1}\\,k_{1} + \\hat{b}_{2}\\,k_{2}\\big),\n$$\n其中，$h$ 是时间步长，$f$ 是一个足够光滑的右端项，$a_{21}$、$b_{1}$、$b_{2}$、$\\hat{b}_{1}$、$\\hat{b}_{2}$ 是方法系数。目标是构建一个主阶为 $p=2$、嵌入阶为 $\\hat{p}=1$ 的嵌入式对，记为 $p=2(1)$。\n\n从初值问题 $y'(t) = f(y(t))$（其中 $y(t_{n}) = y_{n}$）精确解的泰勒展开式和上述方法的定义出发，通过匹配主方法和嵌入式估计器的级数系数到适当的阶，推导阶条件。对于两级显式情况，以自由级参数 $a_{21} = \\alpha \\neq 0$ 为基准，符号化地求解阶条件，并产生 $p=2(1)$ 嵌入式对的单参数族 $\\{b_{1}(\\alpha), b_{2}(\\alpha); \\hat{b}_{1}, \\hat{b}_{2}\\}$。\n\n然后，构建一个病态系统，以证明为什么对于可靠的步长控制，嵌入式误差的阶必须与主方法的阶不同。考虑线性自治测试方程 $y'(t) = \\lambda\\,y(t)$，其中常数 $\\lambda \\in \\mathbb{R}$。通过直接计算单步更新来证明，如果选择嵌入式估计器与主方法具有相同的阶 $p=2$，同时共享相同的级参数 $a_{21}=\\alpha$，那么嵌入式误差估计\n$$\nE \\;=\\; y_{n+1}^{(p)} - y_{n+1}^{(\\hat{p})}\n$$\n对于所有的 $h$、$\\lambda$ 和 $y_{n}$ 都会消失，尽管对于此测试方程，任一方法的真实局部截断误差都不为零。最后，给出在这种病态情况下 $E$ 的显式表达式。\n\n你的最终答案必须是一个单行矩阵，包含你推导出的 $p=2(1)$ 对的五个系数 $\\big(b_{1}(\\alpha), b_{2}(\\alpha), a_{21}(\\alpha), \\hat{b}_{1}, \\hat{b}_{2}\\big)$，其后是上述病态情况下 $E$ 的表达式。不需要进行数值舍入。请使用精确的符号形式表达最终答案。", "solution": "用户提供了一个来自计算科学领域的有效问题陈述，具体涉及嵌入式龙格-库塔方法的推导和分析。该问题具有科学依据，是适定且客观的。我将提供完整的解答。\n\n该问题分为两部分。首先，我们推导一个两级显式龙格-库塔（RK）方法形成 $p=2(1)$ 嵌入式对的阶条件。其次，我们分析一个病态情况，其中主方法和嵌入式估计器都是 $p=2$ 阶的。\n\n**第一部分：$p=2(1)$ RK 对的推导**\n\n我们首先考虑初值问题 $y'(t) = f(y(t))$（其中 $y(t_n) = y_n$）精确解的泰勒级数展开。在时间 $t_{n+1} = t_n + h$ 的解由以下公式给出：\n$$\ny(t_n + h) = y(t_n) + h y'(t_n) + \\frac{h^2}{2} y''(t_n) + O(h^3)\n$$\n使用链式法则和常微分方程的定义，我们可以用 $f$ 及其关于 $y$ 的偏导数（记为 $f_y$, $f_{yy}$ 等）来表示 $y$ 的导数。\n$y'(t_n) = f(y(t_n)) = f(y_n)$\n$y''(t_n) = \\frac{d}{dt} f(y(t)) \\Big|_{t=t_n} = f_y(y(t_n)) \\cdot y'(t_n) = f_y f$\n将这些代入泰勒展开式，我们得到：\n$$\ny(t_n + h) = y_n + h f + \\frac{h^2}{2} f_y f + O(h^3)\n$$\n接下来，我们展开由 RK 方法提供的数值解。该方法定义如下：\n$$\nk_{1} = f(y_{n}) \\\\\nk_{2} = f(y_{n} + h a_{21} k_{1}) \\\\\ny_{n+1} = y_{n} + h (b_{1} k_{1} + b_{2} k_{2})\n$$\n我们将级 $k_2$ 在 $y_n$ 附近进行泰勒级数展开：\n$k_1 = f(y_n) = f$\n$$\nk_2 = f(y_n + h a_{21} f) = f(y_n) + (h a_{21} f) f_y(y_n) + O(h^2) = f + h a_{21} f_y f + O(h^2)\n$$\n现在，我们将 $k_1$ 和 $k_2$ 的展开式代入主方法 $y_{n+1}^{(p)}$ 的更新公式中：\n$$\ny_{n+1}^{(p)} = y_n + h \\big( b_1 f + b_2 (f + h a_{21} f_y f + O(h^2)) \\big)\n$$\n$$\ny_{n+1}^{(p)} = y_n + h (b_1 + b_2) f + h^2 (b_2 a_{21}) f_y f + O(h^3)\n$$\n为了使主方法达到 $p=2$ 阶，其展开式必须与精确解的展开式在 $O(h^2)$ 项之前都匹配。通过比较 $f$ 和 $f_y f$ 的系数，我们得到阶条件：\n\\begin{align*}\n\\text{阶 } p=2 \\text{ 条件:} \\\\\nO(h):  \\quad b_1 + b_2 = 1 \\\\\nO(h^2):  \\quad b_2 a_{21} = \\frac{1}{2}\n\\end{align*}\n类似地，对于嵌入式方法 $y_{n+1}^{(\\hat{p})} = y_{n} + h(\\hat{b}_{1}k_{1} + \\hat{b}_{2}k_{2})$，我们找到其展开式：\n$$\ny_{n+1}^{(\\hat{p})} = y_n + h (\\hat{b}_1 + \\hat{b}_2) f + h^2 (\\hat{b}_2 a_{21}) f_y f + O(h^3)\n$$\n为了使嵌入式方法达到 $\\hat{p}=1$ 阶，其展开式必须与精确解的展开式在 $O(h)$ 项之前都匹配。这给出了一个单一的阶条件：\n\\begin{align*}\n\\text{阶 } \\hat{p}=1 \\text{ 条件:} \\\\\nO(h):  \\quad \\hat{b}_1 + \\hat{b}_2 = 1\n\\end{align*}\n现在，我们解这些方程组。问题指定了一个自由参数 $a_{21} = \\alpha \\neq 0$。\n从 $p=2$ 的条件：\n$b_2 \\alpha = \\frac{1}{2} \\implies b_2 = \\frac{1}{2\\alpha}$\n$b_1 = 1 - b_2 = 1 - \\frac{1}{2\\alpha}$\n对于 $\\hat{p}=1$ 的条件，有无穷多个解。一个常见且简单的选择是设置 $\\hat{b}_2=0$，这意味着 $\\hat{b}_1=1$。这个选择使得嵌入式方法等价于前向欧拉法，$y_{n+1}^{(\\hat{p})} = y_n + h k_1 = y_n + h f(y_n)$，这确实是一个一阶方法。\n\n由此产生的 $p=2(1)$ 对的单参数族系数为：\n$b_1(\\alpha) = 1 - \\frac{1}{2\\alpha}$\n$b_2(\\alpha) = \\frac{1}{2\\alpha}$\n$a_{21}(\\alpha) = \\alpha$\n$\\hat{b}_1 = 1$\n$\\hat{b}_2 = 0$\n\n**第二部分：病态情况分析**\n\n我们现在研究嵌入式方法被选择与主方法具有相同阶数（即 $p=\\hat{p}=2$）且共享相同级值（相同的 $a_{21}$）的情况。测试方程是线性自治系统 $y'(t) = \\lambda y(t)$，其中 $f(y) = \\lambda y$。\n\n现在两种方法的阶条件是相同的：\n对于主方法 ($p=2$)：$b_1 + b_2 = 1$ 且 $b_2 a_{21} = \\frac{1}{2}$。\n对于嵌入式方法 ($\\hat{p}=2$)：$\\hat{b}_1 + \\hat{b}_2 = 1$ 且 $\\hat{b}_2 a_{21} = \\frac{1}{2}$。\n\n让我们计算此测试问题的各级：\n$k_1 = f(y_n) = \\lambda y_n$\n$k_2 = f(y_n + h a_{21} k_1) = \\lambda(y_n + h a_{21} (\\lambda y_n)) = \\lambda y_n (1 + h a_{21} \\lambda)$\n\n主方法的更新为：\n$$\ny_{n+1}^{(p)} = y_n + h \\left( b_1(\\lambda y_n) + b_2(\\lambda y_n (1 + h a_{21} \\lambda)) \\right)\n$$\n$$\ny_{n+1}^{(p)} = y_n \\left( 1 + h\\lambda(b_1 + b_2) + (h\\lambda)^2 (b_2 a_{21}) \\right)\n$$\n代入 $p=2$ 阶条件，$b_1+b_2=1$ 和 $b_2 a_{21}=1/2$：\n$$\ny_{n+1}^{(p)} = y_n \\left( 1 + h\\lambda + \\frac{1}{2}(h\\lambda)^2 \\right)\n$$\n嵌入式方法的更新为：\n$$\ny_{n+1}^{(\\hat{p})} = y_n + h \\left( \\hat{b}_1(\\lambda y_n) + \\hat{b}_2(\\lambda y_n (1 + h a_{21} \\lambda)) \\right)\n$$\n$$\ny_{n+1}^{(\\hat{p})} = y_n \\left( 1 + h\\lambda(\\hat{b}_1 + \\hat{b}_2) + (h\\lambda)^2 (\\hat{b}_2 a_{21}) \\right)\n$$\n代入（假设的） $\\hat{p}=2$ 阶条件，$\\hat{b}_1+\\hat{b}_2=1$ 和 $\\hat{b}_2 a_{21}=1/2$：\n$$\ny_{n+1}^{(\\hat{p})} = y_n \\left( 1 + h\\lambda + \\frac{1}{2}(h\\lambda)^2 \\right)\n$$\n嵌入式误差估计定义为 $E = y_{n+1}^{(p)} - y_{n+1}^{(\\hat{p})}$。计算这个差值：\n$$\nE = y_n \\left( 1 + h\\lambda + \\frac{1}{2}(h\\lambda)^2 \\right) - y_n \\left( 1 + h\\lambda + \\frac{1}{2}(h\\lambda)^2 \\right) = 0\n$$\n对于任何 $h$、$\\lambda$ 和 $y_n$ 的选择，误差估计恒为零。然而，任一方法的真实局部截断误差（LTE）都不为零。对于精确解 $y(t_{n+1}) = y_n \\exp(h\\lambda)$，LTE 为：\n$$\n\\text{LTE} = y_n \\exp(h\\lambda) - y_n \\left( 1 + h\\lambda + \\frac{1}{2}(h\\lambda)^2 \\right) = y_n \\left( \\frac{(h\\lambda)^3}{6} + O(h^4) \\right) \\neq 0\n$$\n这表明，如果在一个两级格式中，嵌入式方法与主方法具有相同的阶并共享其级计算，那么误差估计器对于线性问题会失效，因为它错误地报告零误差。这就是为什么嵌入式对通常由不同阶的方法构成，例如 $p(\\hat{p})$ 其中 $\\hat{p}=p-1$。\n\n在这种病态情况下，$E$ 的表达式是 $E=0$。$p=2(1)$ 对的五个系数是 $b_{1}(\\alpha) = 1 - \\frac{1}{2\\alpha}$、$b_{2}(\\alpha) = \\frac{1}{2\\alpha}$、$a_{21}(\\alpha) = \\alpha$、$\\hat{b}_{1}=1$ 和 $\\hat{b}_{2}=0$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1 - \\frac{1}{2\\alpha}  \\frac{1}{2\\alpha}  \\alpha  1  0  0\n\\end{pmatrix}\n}\n$$", "id": "3123519"}, {"introduction": "理解了嵌入式方法阶数不同的必要性之后，下一个关键问题是：这个误差估算器本身的精度如何？本练习旨在通过理论推导和数值实验两种方式来确定嵌入式误差估算器的渐近阶。你将首先从局部截断误差的定义出发，证明一个$p(p-1)$阶方法对的误差估算器具有$p$阶精度，然后通过编程实现，用数值结果验证这一重要理论结论。[@problem_id:3123523]", "problem": "您需要推导并验证显式嵌入式龙格-库塔对中嵌入式误差估计子的渐近阶。请从局部截断误差和单步法一致性的基本定义出发，除了标准定义外，不假设任何特殊公式。\n\n任务A部分（推导）：考虑一个显式嵌入式龙格-库塔对，它在单步内计算两个近似值：一个阶为 $p$ 的高阶近似值 $y_{n+1}$ 和一个阶为 $p-1$ 的低阶近似值 $\\hat{y}_{n+1}$，两者均由同一组阶段求值得到。利用单步法局部截断误差的定义及其在定点 $t_n$ 处关于步长 $h$ 的泰勒展开，推导对于一个通用的 $p(p-1)$ 对，其嵌入式误差估计子 $\\lVert \\hat{y}_{n+1} - y_{n+1} \\rVert$ 的渐近阶（当 $h \\to 0$ 时）。您的推导必须从以下定义出发：一个 $r$ 阶方法的局部截断误差在 $h^r$ 阶及以下的项均为零，且其主误差项表现为 $C h^{r+1}$ 的形式，其中 $C$ 是一个与问题相关的常数。推导过程中不得假设任何已知的龙格-库塔误差系数。\n\n任务B部分（数值测试）：用一种现代编程语言实现一个程序，该程序能够：\n- 使用固定步长，在一个有限区间上对初值为 $y(0)=0$ 的标量初值问题 $y'=\\sin t$ 进行积分。角度必须以弧度处理。\n- 使用两个显式嵌入式龙格-库塔对：一个 $p=3, p-1=2$ 的 Bogacki–Shampine $3(2)$ 对，以及一个 $p=2, p-1=1$ 的 Heun–Euler $2(1)$ 对。\n- 对于每个固定的步长 $h$，计算在所有步数中嵌入式误差估计子的最大值 $\\max_{n} \\lvert \\hat{y}_{n+1} - y_{n+1} \\rvert$。\n- 通过对测得的最大值对数与步长对数进行最小二乘线性拟合来估计观测阶，使得拟合直线的斜率近似于关于 $h$ 的渐近阶。\n\n测试套件：\n- 测试用例1：在 $[0, 4.0]$ 上使用 Bogacki–Shampine $3(2)$ 方法，步长 $h \\in \\{0.5, 0.25, 0.125, 0.0625\\}$。\n- 测试用例2：在 $[0, 4.0]$ 上使用 Heun–Euler $2(1)$ 方法，步长 $h \\in \\{0.5, 0.25, 0.125, 0.0625\\}$。\n- 测试用例3：在 $[0, 0.5]$ 上使用 Bogacki–Shampine $3(2)$ 方法，步长 $h \\in \\{0.1, 0.05, 0.025, 0.0125\\}$。\n- 测试用例4：在 $[0, 0.5]$ 上使用 Heun–Euler $2(1)$ 方法，步长 $h \\in \\{0.1, 0.05, 0.025, 0.0125\\}$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含按测试用例1到4顺序排列的四个观测阶（即拟合的斜率），每个数值四舍五入到三位小数，并以逗号分隔的列表形式包含在方括号内。例如，输出必须类似于 $[s_1,s_2,s_3,s_4]$，其中每个 $s_i$ 是打印到三位小数的实数。不应打印任何其他文本。", "solution": "此问题包含两部分。A部分要求推导一个通用的阶为 $p$ 和 $p-1$ 的显式嵌入式龙格-库塔对中嵌入式误差估计子的渐近阶。B部分要求对 Bogacki–Shampine $3(2)$ 对和 Heun–Euler $2(1)$ 对的推导阶进行数值验证。\n\n### A部分：渐近阶的推导\n\n设初值问题 (IVP) 为 $y'(t) = f(t, y(t))$，初始条件为 $y(t_0) = y_0$。我们假设精确解 $y(t)$ 足够光滑。\n\n单步数值方法利用在 $t_n$ 处的信息来近似 $t_{n+1} = t_n + h$ 处的解。设 $y_n$ 为在 $t_n$ 处的数值近似。为了分析*局部误差*，我们假设在该步开始时数值解是精确的，即 $y_n = y(t_n)$。\n\n问题陈述将一个方法定义为 $r$ 阶，如果从精确解开始的单步误差 $y(t_{n+1}) - y_{n+1}$ 的主项表现为 $C h^{r+1}$ 的形式，其中 $C$ 是某个非零的、与问题相关的常数。这就是局部截断误差。\n\n我们有一个由两种方法组成的嵌入式龙格-库塔对：\n1.  一个阶为 $p$ 的高阶方法，它产生近似值 $y_{n+1}$。\n2.  一个阶为 $p-1$ 的低阶方法，它产生近似值 $\\hat{y}_{n+1}$。\n\n根据阶的定义，这两种方法的局部误差为：\n$$y(t_{n+1}) - y_{n+1} = \\mathcal{E}_{p,n} h^{p+1} + O(h^{p+2})$$\n$$y(t_{n+1}) - \\hat{y}_{n+1} = \\mathcal{E}_{p-1,n} h^{p} + O(h^{p+1})$$\n\n这里，$\\mathcal{E}_{p,n}$ 和 $\\mathcal{E}_{p-1,n}$ 是在第 $n$ 步的主局部截断误差系数。为了使方法分别为 $p$ 阶和 $p-1$ 阶（而不是更高阶），这些系数通常必须非零。项 $O(h^k)$ 表示当 $h \\to 0$ 时比 $h^{k-1}$ 更快消失的高阶项。\n\n我们记作 $\\Delta_{n+1}$ 的嵌入式误差估计子是两个数值近似值之差：\n$$\\Delta_{n+1} = \\hat{y}_{n+1} - y_{n+1}$$\n\n为了找到 $\\Delta_{n+1}$ 的渐近行为，我们可以用精确解 $y(t_{n+1})$ 及其各自的局部误差来表示 $y_{n+1}$ 和 $\\hat{y}_{n+1}$：\n$$y_{n+1} = y(t_{n+1}) - \\left( \\mathcal{E}_{p,n} h^{p+1} + O(h^{p+2}) \\right)$$\n$$\\hat{y}_{n+1} = y(t_{n+1}) - \\left( \\mathcal{E}_{p-1,n} h^{p} + O(h^{p+1}) \\right)$$\n\n现在，我们通过代入这些表达式来计算差值 $\\Delta_{n+1} = \\hat{y}_{n+1} - y_{n+1}$：\n$$\\Delta_{n+1} = \\left( y(t_{n+1}) - \\mathcal{E}_{p-1,n} h^{p} - O(h^{p+1}) \\right) - \\left( y(t_{n+1}) - \\mathcal{E}_{p,n} h^{p+1} - O(h^{p+2}) \\right)$$\n\n精确解项 $y(t_{n+1})$ 被消掉：\n$$\\Delta_{n+1} = - \\mathcal{E}_{p-1,n} h^{p} - O(h^{p+1}) + \\mathcal{E}_{p,n} h^{p+1} + O(h^{p+2})$$\n\n我们可以合并高阶项。项 $\\mathcal{E}_{p,n} h^{p+1}$ 是 $h^{p+1}$ 阶的，因此它被吸收到 $O(h^{p+1})$ 项中。这得出：\n$$\\Delta_{n+1} = - \\mathcal{E}_{p-1,n} h^{p} + O(h^{p+1})$$\n\n为使低阶方法精确为 $p-1$ 阶，对于一般问题，系数 $\\mathcal{E}_{p-1,n}$ 必须非零。因此，误差估计子 $\\Delta_{n+1}$ 展开式中的主项是 $-\\mathcal{E}_{p-1,n} h^{p}$。\n\n那么，误差估计子的范数为：\n$$\\lVert \\Delta_{n+1} \\rVert = \\lVert \\hat{y}_{n+1} - y_{n+1} \\rVert = \\lVert - \\mathcal{E}_{p-1,n} h^{p} + O(h^{p+1}) \\rVert$$\n当 $h \\to 0$ 时，该范数的行为由主项决定：\n$$\\lVert \\hat{y}_{n+1} - y_{n+1} \\rVert \\approx \\lVert \\mathcal{E}_{p-1,n} \\rVert h^{p}$$\n\n这表明嵌入式误差估计子的渐近阶为 $p$。此估计子是低阶方法局部误差 $y(t_{n+1}) - \\hat{y}_{n+1}$ 的一个代理，该局部误差的阶为 $p$。一个重要的结论是，误差估计子的精度阶高于它所估计的误差的阶。\n\n### B部分：数值验证\n\n为验证此结果，我们将实现指定的龙格-库塔对并分析嵌入式误差估计子的收敛性。根据推导，我们预期：\n- 对于 Bogacki–Shampine $3(2)$ 对 ($p=3$)，误差估计子 $\\lvert \\hat{y}_{n+1} - y_{n+1} \\rvert$ 应以 $p=3$ 阶收敛。\n- 对于 Heun–Euler $2(1)$ 对 ($p=2$)，误差估计子 $\\lvert \\hat{y}_{n+1} - y_{n+1} \\rvert$ 应以 $p=2$ 阶收敛。\n\n数值过程包括使用一组递减的步长 $h_i$ 在给定区间上对初值问题 $y'=\\sin t, y(0)=0$ 进行积分。对于每个 $h_i$，我们计算区间上的最大误差估计值 $E_i = \\max_{n} \\lvert \\hat{y}_{n+1} - y_{n+1} \\rvert$。由于我们预期 $E_i \\approx C h_i^p$，取对数得到 $\\log(E_i) \\approx \\log(C) + p \\log(h_i)$。对 $\\log(E_i)$ 与 $\\log(h_i)$ 进行线性最小二乘拟合，将得到一个近似于阶数 $p$ 的斜率。以下代码对四个指定的测试用例执行此验证。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and verifies the asymptotic order of embedded Runge-Kutta error estimators.\n    \"\"\"\n\n    # Define the differential equation for the IVP: y' = sin(t)\n    def f(t, y):\n        return np.sin(t)\n\n    # Implementation of the Heun-Euler 2(1) embedded pair step\n    def heun_euler_step(f_func, t, y, h):\n        \"\"\"\n        Performs one step of the Heun-Euler 2(1) method.\n        p=2 (Heun's method), p-1=1 (Forward Euler method).\n        \"\"\"\n        k1 = f_func(t, y)\n        k2 = f_func(t + h, y + h * k1)\n        \n        # Higher-order solution (p=2, Heun's method)\n        y_next = y + (h / 2.0) * (k1 + k2)\n        \n        # Lower-order solution (p-1=1, Forward Euler)\n        y_hat_next = y + h * k1\n        \n        return y_next, y_hat_next\n\n    # Implementation of the Bogacki-Shampine 3(2) embedded pair step\n    def bs32_step(f_func, t, y, h):\n        \"\"\"\n        Performs one step of the Bogacki-Shampine 3(2) method.\n        Uses the standard 4-stage explicit formulation.\n        p=3, p-1=2.\n        \"\"\"\n        k1 = f_func(t, y)\n        k2 = f_func(t + 0.5 * h, y + 0.5 * h * k1)\n        k3 = f_func(t + 0.75 * h, y + 0.75 * h * k2)\n        \n        # Higher-order solution (p=3)\n        y_next = y + h * (2.0/9.0 * k1 + 1.0/3.0 * k2 + 4.0/9.0 * k3)\n        \n        k4 = f_func(t + h, y_next)\n        \n        # Lower-order solution (p-1=2)\n        y_hat_next = y + h * (7.0/24.0 * k1 + 1.0/4.0 * k2 + 1.0/3.0 * k3 + 1.0/8.0 * k4)\n        \n        return y_next, y_hat_next\n\n    def run_integration(step_func, t_span, y0, h):\n        \"\"\"\n        Integrates the ODE using a given step function and fixed step size h.\n        Returns the maximum embedded error estimate over the interval.\n        \"\"\"\n        t = t_span[0]\n        y = y0\n        error_estimates = []\n\n        while t  t_span[1]:\n            # Ensure the last step does not overshoot the interval end\n            current_h = min(h, t_span[1] - t)\n            \n            y_next, y_hat_next = step_func(f, t, y, current_h)\n            \n            error_estimates.append(np.abs(y_hat_next - y_next))\n            \n            y = y_next\n            t += current_h\n        \n        if not error_estimates:\n            return 0.0\n            \n        return np.max(error_estimates)\n\n    def estimate_order(h_values, max_errors):\n        \"\"\"\n        Estimates the convergence order by a linear fit on log-log data.\n        \"\"\"\n        log_h = np.log(h_values)\n        log_e = np.log(max_errors)\n        \n        # np.polyfit with degree 1 performs a linear least-squares fit.\n        # It returns [slope, intercept]. The slope is the estimated order.\n        slope, _ = np.polyfit(log_h, log_e, 1)\n        return slope\n\n    # Define the four test cases from the problem statement\n    test_cases = [\n        {'method': bs32_step, 't_span': [0.0, 4.0], 'h_values': np.array([0.5, 0.25, 0.125, 0.0625])},\n        {'method': heun_euler_step, 't_span': [0.0, 4.0], 'h_values': np.array([0.5, 0.25, 0.125, 0.0625])},\n        {'method': bs32_step, 't_span': [0.0, 0.5], 'h_values': np.array([0.1, 0.05, 0.025, 0.0125])},\n        {'method': heun_euler_step, 't_span': [0.0, 0.5], 'h_values': np.array([0.1, 0.05, 0.025, 0.0125])},\n    ]\n\n    results = []\n    y0 = 0.0  # Initial condition y(0) = 0\n\n    for case in test_cases:\n        max_errors = []\n        for h in case['h_values']:\n            max_err = run_integration(case['method'], case['t_span'], y0, h)\n            max_errors.append(max_err)\n        \n        observed_order = estimate_order(case['h_values'], np.array(max_errors))\n        results.append(observed_order)\n\n    # Print the final results in the specified format\n    print(f\"[{','.join([f'{r:.3f}' for r in results])}]\")\n\nsolve()\n```", "id": "3123523"}, {"introduction": "有了可靠的误差估算器，我们如何将其应用于实际的步长控制？步长选择需要在精度和稳定性之间取得平衡。本练习将通过经典的线性测试方程 $y'=\\lambda y$ 来让你亲手实践这一权衡过程。你将构建一个教学上简洁的$2(1)$嵌入式龙格-库塔配对，并推导其稳定性函数和误差函数，最终确定在满足稳定性和给定精度容差双重约束下的最大允许步长。[@problem_id:3123496]", "problem": "一个显式嵌入式 Runge-Kutta $2(1)$ 对通过计算各阶段的导数，并用两组不同的权重对其进行组合，从而将初值问题 $y' = f(t,y)$ 从 $t_n$ 推进到 $t_{n+1} = t_n + h$：一组权重用于二阶近似，另一组用于一阶嵌入式近似。从显式 Runge-Kutta 方法的定义和二阶方法的阶条件出发，构建一个具有简单有理系数的、用于教学的 Butcher 表，该表定义了这样一个具有两个阶段的对。然后，在常数 $\\lambda \\in \\mathbb{R}$ 和步长 $h > 0$（其中 $z = h \\lambda$）的线性测试方程 $y' = \\lambda y$ 上分析其行为。\n\n使用线性测试方程和构建的表，推导二阶方法的单步稳定性函数 $R(z)$ 和嵌入式一阶方法的单步函数 $\\widehat{R}(z)$。通过 $E(z) = R(z) - \\widehat{R}(z)$ 定义嵌入式单步误差估计器，使得在测试方程上，两个近似值之间的每步差满足 $y_{n+1} - \\widehat{y}_{n+1} = E(z)\\, y_n$。通过对实数 $z$ 施加两个同时成立的条件，即通常的绝对稳定性条件 $\\lvert R(z) \\rvert \\leq 1$ 和一个嵌入式校准界限 $\\lvert E(z) \\rvert \\leq \\theta$（其中 $\\theta \\ge 0$ 是用户指定的容差），在负实轴上校准二阶方法的绝对稳定域。对于 $\\lambda  0$，这将得到一个以 $\\lambda$ 和 $\\theta$ 表示的最大允许步长 $h_{\\max}$。对于 $\\lambda > 0$，解释其对允许步长 $h$ 的影响。\n\n你的程序必须实现所构建的表和推导出的条件，以计算下面测试套件中每种情况的 $h_{\\max}$。程序不应执行任何数值积分；它应使用专门针对测试方程 $y'=\\lambda y$ 解析推导出的表达式。\n\n测试套件（每种情况都是一个 $(\\lambda,\\theta)$ 对）：\n- 情况1：$\\lambda = -1$，$\\theta = \\frac{1}{8}$。\n- 情况2：$\\lambda = -\\frac{1}{2}$，$\\theta = 10$。\n- 情况3：$\\lambda = -10$，$\\theta = 100$。\n- 情况4：$\\lambda = -10$，$\\theta = 0.005$。\n- 情况5：$\\lambda = 3$，$\\theta = 1$。\n- 情况6：$\\lambda = -2$，$\\theta = 0$。\n\n对于每种情况，以浮点数形式输出 $h_{\\max}$ 的值。你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔的结果列表（例如，$[h_1,h_2,\\dots,h_6]$）。不涉及任何物理单位；所有值都是无量纲的实数。", "solution": "问题陈述经过严格验证，被认定为有效。它在常微分方程数值方法理论方面有坚实的科学基础，问题设定良好，目标明确，数据充分，并且没有任何科学上的不健全、模糊或矛盾之处。\n\n求解过程分为几个步骤：\n1.  为一个 $2(1)$ 嵌入式 Runge-Kutta 对构建一个合适的 Butcher 表。\n2.  针对线性测试方程 $y'=\\lambda y$，推导高阶方法和嵌入式方法的稳定性函数。\n3.  分析稳定性和校准条件，以推导最大步长 $h_{\\max}$ 的表达式。\n4.  对所提供的测试用例计算 $h_{\\max}$。\n\n**步骤1：构建 Butcher 表**\n一个 $s$ 阶显式 Runge-Kutta 方法由以下形式的 Butcher 表定义：\n$$\n\\begin{array}{c|c}\n\\mathbf{c}  \\mathbf{A} \\\\\n\\hline\n  \\mathbf{b}^T \\\\\n  \\widehat{\\mathbf{b}}^T\n\\end{array}\n=\n\\begin{array}{c|cccc}\nc_1  a_{11}  a_{12}  \\dots  a_{1s} \\\\\nc_2  a_{21}  a_{22}  \\dots  a_{2s} \\\\\n\\vdots  \\vdots  \\vdots  \\ddots  \\vdots \\\\\nc_s  a_{s1}  a_{s2}  \\dots  a_{ss} \\\\\n\\hline\n  b_1  b_2  \\dots  b_s \\\\\n  \\hat{b}_1  \\hat{b}_2  \\dots  \\hat{b}_s\n\\end{array}\n$$\n对于一个两阶段（$s=2$）的显式方法，矩阵 $\\mathbf{A}$ 是严格下三角矩阵，因此 $a_{11}=a_{12}=a_{22}=0$。相容性条件 $c_i = \\sum_{j=1}^{s} a_{ij}$ 要求 $c_1 = 0$ 且 $c_2 = a_{21}$。该表简化为：\n$$\n\\begin{array}{c|cc}\n0  0  0 \\\\\nc_2  c_2  0 \\\\\n\\hline\n  b_1  b_2 \\\\\n  \\hat{b}_1  \\hat{b}_2\n\\end{array}\n$$\n使用权重 $b_i$ 的方法必须是二阶精确的。二阶方法的阶条件是：\n1.  一阶条件：$\\sum_{i=1}^2 b_i = b_1 + b_2 = 1$\n2.  二阶条件：$\\sum_{i=1}^2 b_i c_i = b_1 c_1 + b_2 c_2 = 1/2$\n\n使用权重 $\\hat{b}_i$ 的嵌入式方法必须是一阶精确的。一阶方法的阶条件是：\n1.  一阶条件：$\\sum_{i=1}^2 \\hat{b}_i = \\hat{b}_1 + \\hat{b}_2 = 1$\n\n将 $c_1=0$ 代入二阶条件，得到 $b_2 c_2 = 1/2$。为了构建一个具有简单有理系数的表，我们可以选择 $c_2=1$。这意味着 $a_{21}=1$ 且 $b_2=1/2$。根据 $b_i$ 的一阶条件，我们得到 $b_1 = 1 - b_2 = 1 - 1/2 = 1/2$。\n\n对于嵌入式一阶方法，我们需要满足 $\\hat{b}_1 + \\hat{b}_2 = 1$，同时确保它不是二阶的，即 $\\sum \\hat{b}_i c_i = \\hat{b}_2 c_2 = \\hat{b}_2 \\neq 1/2$。一个简单的选择是选取第一阶段的结果，这对应于 Forward Euler 方法。这可以通过设置 $\\hat{b}_1=1$ 和 $\\hat{b}_2=0$ 来实现。这些权重满足 $\\hat{b}_1+\\hat{b}_2=1$，且二阶条件不满足，因为 $\\hat{b}_2(1) = 0 \\neq 1/2$。\n\n我们的 $2(1)$ 对的最终 Butcher 表为：\n$$\n\\begin{array}{c|cc}\n0  0  0 \\\\\n1  1  0 \\\\\n\\hline\n  1/2  1/2 \\\\\n  1  0\n\\end{array}\n$$\n\n**步骤2：推导稳定性函数**\n我们在线性测试方程 $y' = \\lambda y$（其中 $\\lambda \\in \\mathbb{R}$）上分析该方法。各阶段为：\n$$ k_1 = f(t_n, y_n) = \\lambda y_n $$\n$$ k_2 = f(t_n+c_2h, y_n+ha_{21}k_1) = \\lambda(y_n + h(1)k_1) = \\lambda(y_n + h\\lambda y_n) = \\lambda y_n (1+h\\lambda) $$\n令 $z=h\\lambda$。则 $k_1 = \\lambda y_n$ 且 $k_2 = \\lambda y_n (1+z)$。\n\n二阶近似 $y_{n+1}$ 为：\n$$ y_{n+1} = y_n + h(b_1 k_1 + b_2 k_2) = y_n + h\\left(\\frac{1}{2}\\lambda y_n + \\frac{1}{2}\\lambda y_n(1+z)\\right) $$\n$$ y_{n+1} = y_n \\left(1 + \\frac{h\\lambda}{2}(1 + 1+z)\\right) = y_n \\left(1 + \\frac{z}{2}(2+z)\\right) = y_n \\left(1 + z + \\frac{z^2}{2}\\right) $$\n二阶方法的稳定性函数为 $R(z)$，由 $y_{n+1} = R(z)y_n$ 定义。因此：\n$$ R(z) = 1 + z + \\frac{z^2}{2} $$\n\n一阶嵌入式近似 $\\widehat{y}_{n+1}$ 为：\n$$ \\widehat{y}_{n+1} = y_n + h(\\hat{b}_1 k_1 + \\hat{b}_2 k_2) = y_n + h(1 \\cdot \\lambda y_n + 0 \\cdot k_2) = y_n (1+h\\lambda) $$\n嵌入式方法的稳定性函数为 $\\widehat{R}(z)$，由 $\\widehat{y}_{n+1} = \\widehat{R}(z)y_n$ 定义。因此：\n$$ \\widehat{R}(z) = 1+z $$\n\n单步误差估计函数 $E(z)$ 是：\n$$ E(z) = R(z) - \\widehat{R}(z) = \\left(1 + z + \\frac{z^2}{2}\\right) - (1+z) = \\frac{z^2}{2} $$\n\n**步骤3：稳定性和校准条件分析**\n对于给定的 $\\lambda \\in \\mathbb{R}$ 和 $\\theta \\ge 0$，我们需要找到能同时满足两个条件的最大步长 $h_{\\max}$：\n1.  绝对稳定性：$|R(z)| \\le 1$\n2.  嵌入式校准：$|E(z)| \\le \\theta$\n\n情况 $\\lambda  0$：此时，$z = h\\lambda  0$。\n绝对稳定性条件 $|1 + z + z^2/2| \\le 1$ 等价于 $-1 \\le 1 + z + z^2/2 \\le 1$。\n右侧不等式 $1 + z + z^2/2 \\le 1$ 简化为 $z + z^2/2 \\le 0$，即 $z(1+z/2) \\le 0$。由于 $z0$，这要求 $1+z/2 \\ge 0$，意味着 $z \\ge -2$。\n左侧不等式 $-1 \\le 1 + z + z^2/2$ 简化为 $z^2/2 + z + 2 \\ge 0$，即 $z^2+2z+4 \\ge 0$。这个二次多项式的判别式为 $2^2 - 4(1)(4) = -12  0$，且首项系数为正，所以该二次式对所有实数 $z$ 恒为正。\n因此，对于 $z0$，绝对稳定性要求 $z \\in [-2, 0)$。\n\n嵌入式校准条件为 $|z^2/2| \\le \\theta$。由于 $z^2/2$ 是非负的，这即是 $z^2/2 \\le \\theta$，得出 $z^2 \\le 2\\theta$，或 $|z| \\le \\sqrt{2\\theta}$。由于 $z0$，这意味着 $-z \\le \\sqrt{2\\theta}$，即 $z \\ge -\\sqrt{2\\theta}$。\n\n为了同时满足两个条件，$z$ 必须满足 $z \\ge -2$ 和 $z \\ge -\\sqrt{2\\theta}$。这等价于 $z \\ge \\max(-2, -\\sqrt{2\\theta}) = -\\min(2, \\sqrt{2\\theta})$。\n代入 $z=h\\lambda$：\n$$ h\\lambda \\ge -\\min(2, \\sqrt{2\\theta}) $$\n由于 $\\lambda  0$，除以 $\\lambda$ 会使不等号反向：\n$$ h \\le \\frac{-\\min(2, \\sqrt{2\\theta})}{\\lambda} = \\frac{\\min(2, \\sqrt{2\\theta})}{-\\lambda} = \\frac{\\min(2, \\sqrt{2\\theta})}{|\\lambda|} $$\n因此，最大允许步长为：\n$$ h_{\\max} = \\frac{\\min(2, \\sqrt{2\\theta})}{|\\lambda|} \\quad (\\text{对于 } \\lambda  0) $$\n\n情况 $\\lambda > 0$：此时，$z = h\\lambda > 0$。\n稳定性函数为 $R(z) = 1 + z + z^2/2$。对于任何 $z>0$，每一项都为正，所以 $R(z) > 1$。绝对稳定性条件 $|R(z)| \\le 1$ 对于任何 $h>0$ 都无法满足。唯一允许的非负步长是 $h=0$。因此，对于 $\\lambda > 0$，该方法是无条件不稳定的。\n最大允许步长为 $h_{\\max} = 0$。\n\n**实现摘要：**\n对于给定的 $(\\lambda, \\theta)$ 对，$h_{\\max}$ 的值计算如下：\n- 如果 $\\lambda > 0$，则 $h_{\\max} = 0$。\n- 如果 $\\lambda = 0$，则 $z=0$, $R(0)=1$, $E(0)=0$。对于任何 $h>0$ 条件都满足，所以 $h_{\\max} \\to \\infty$。测试套件中不包含此情况。\n- 如果 $\\lambda  0$，则 $h_{\\max} = \\frac{1}{-\\lambda} \\min(2, \\sqrt{2\\theta})$。\n\n此推导出的公式将被实现，用于计算测试套件的结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the maximum admissible step size h_max for an embedded RK2(1)\n    method based on stability and error tolerance criteria for the linear\n    test equation y' = lambda*y.\n    \"\"\"\n    # Define the test cases from the problem statement as pairs of (lambda, theta).\n    test_cases = [\n        (-1.0, 1.0/8.0),   # Case 1\n        (-0.5, 10.0),      # Case 2\n        (-10.0, 100.0),    # Case 3\n        (-10.0, 0.005),    # Case 4\n        (3.0, 1.0),        # Case 5\n        (-2.0, 0.0),       # Case 6\n    ]\n\n    results = []\n    for case in test_cases:\n        lam, theta = case\n        h_max = 0.0\n\n        # For lambda > 0, the method is unconditionally unstable for h > 0.\n        # R(z) = 1 + z + z^2/2 > 1 for z = h*lambda > 0.\n        # Thus, |R(z)| = 1 is only satisfied for h=0.\n        if lam > 0:\n            h_max = 0.0\n        # For lambda  0, we must satisfy two conditions:\n        # 1. Absolute stability |R(z)| = 1, which for z0 implies z >= -2.\n        #    This translates to h = -2/lambda.\n        # 2. Error calibration |E(z)| = theta, where E(z) = z^2/2.\n        #    This implies z^2 = 2*theta, or z >= -sqrt(2*theta).\n        #    This translates to h = -sqrt(2*theta)/lambda.\n        # The maximum step size h_max is the minimum of these two bounds.\n        elif lam  0:\n            abs_lam = -lam\n            # Calculate the two upper bounds for h\n            bound_stability = 2.0 / abs_lam\n            bound_calibration = np.sqrt(2.0 * theta) / abs_lam\n            h_max = min(bound_stability, bound_calibration)\n\n        # The case lambda = 0 is not in the test suite. If it were,\n        # z=0 for all h, R(0)=1, E(0)=0, so any h is admissible,\n        # and h_max would be infinity.\n\n        results.append(h_max)\n\n    # Format the final output as a comma-separated list in brackets.\n    # The map(str, ...) ensures float representation for all numbers.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3123496"}]}