## 引言
线性方程组是计算科学的基石，是描述从工程设计到经济预测等众多现实世界现象的通用语言。然而，仅仅了解如何用纸笔解一个简单的[方程组](@entry_id:193238)，与掌握在现代计算中处理大规模、复杂系统的能力之间，存在着巨大的鸿沟。许多学习者难以将抽象的代数理论、高效的计算算法以及这些工具在跨学科问题中的实际应用联系起来，更不了解在有限精度计算机上求解时可能遇到的陷阱。

本文旨在搭建一座桥梁，引领读者从理论基础走向实际应用。在“原理与机制”一章中，我们将深入探讨[线性系统](@entry_id:147850)的核心概念，系统地学习高斯消元、[LU分解](@entry_id:144767)等直接解法，以及适用于[大型稀疏系统](@entry_id:177266)的雅可比和高斯-赛德尔等迭代方法，并直面数值稳定性这一关键挑战。接下来的“应用与跨学科联系”一章将展示这些方法的强大威力，探索它们如何为[电路分析](@entry_id:261116)、[数据拟合](@entry_id:149007)、经济建模乃至GPS定位等不同领域的问题提供清晰的计算框架。最后，通过“动手实践”部分，你将有机会通过解决具体问题来巩固所学知识，将理论真正转化为技能。

## 原理与机制

线性方程组是计算科学中无处不在的数学结构，从工程设计、数据分析到经济建模，其应用遍及各个领域。理解如何表示、求解和分析这些[方程组](@entry_id:193238)，是掌握计算方法论的基石。本章将深入探讨线性方程组的核心原理与求解机制，从[基本表示](@entry_id:157678)法出发，过渡到[直接法与迭代法](@entry_id:165131)两大求解策略，并着重阐述在实际计算中至关重要的数值稳定性和效率问题。

### [线性系统](@entry_id:147850)的三种视角

一个线性方程组通常以一组包含多个变量的线性方程形式出现。例如，一个包含 $m$ 个方程和 $n$ 个未知数的系统可以写作：
$$
\begin{align*}
a_{11}x_1 + a_{12}x_2 + \dots + a_{1n}x_n = b_1 \\
a_{21}x_1 + a_{22}x_2 + \dots + a_{2n}x_n = b_2 \\
\vdots \qquad \qquad \qquad \vdots \qquad = \quad \vdots \\
a_{m1}x_1 + a_{m2}x_2 + \dots + a_{mn}x_n = b_m
\end{align*}
$$
其中 $x_1, x_2, \dots, x_n$ 是待求解的未知数，$a_{ij}$ 是系数，$b_i$ 是常数项。为了更系统地处理这些方程，我们通常采用更紧凑的表示法。

第一种也是最常见的视角是**矩阵-向量形式**。我们可以将所有系数 $a_{ij}$ 组织成一个 $m \times n$ 的矩阵 $A$，将所有未知数组织成一个 $n \times 1$ 的列向量 $\mathbf{x}$，将所有常数项组织成一个 $m \times 1$ 的列向量 $\mathbf{b}$。这样，整个[方程组](@entry_id:193238)就可以简洁地表示为：
$$
A\mathbf{x} = \mathbf{b}
$$
这种表示法将求解问题转化为一个关于矩阵和向量的代数问题，是线性代数理论应用的核心。

第二种视角，即**行图像 (row picture)**，将每个[线性方程](@entry_id:151487)解释为一个几何对象。在二维空间中，一个[线性方程](@entry_id:151487)代表一条直线；在三维空间中，代表一个平面；在更高维空间中，则代表一个**超平面 (hyperplane)**。从这个角度看，[求解线性方程组](@entry_id:169069)等价于寻找所有这些超平面的公共交点。解的[存在性与唯一性](@entry_id:263101)也因此有了直观的几何解释：若所有[超平面](@entry_id:268044)交于一点，则系统有唯一解；若它们交于一条[线或](@entry_id:170208)一个更高维的[子空间](@entry_id:150286)，则有无穷多解；若它们没有公共交点（例如，两条[平行线](@entry_id:169007)），则系统无解。

第三种视角是**[列图像](@entry_id:150789) (column picture)**，它将问题重新表述为向量的**线性组合 (linear combination)**。如果我们将矩阵 $A$ 的各列视为列向量 $\mathbf{a}_1, \mathbf{a}_2, \dots, \mathbf{a}_n$，那么[矩阵方程](@entry_id:203695) $A\mathbf{x} = \mathbf{b}$ 可以展开为：
$$
x_1\mathbf{a}_1 + x_2\mathbf{a}_2 + \dots + x_n\mathbf{a}_n = \mathbf{b}
$$
这个**向量方程**揭示了一个深刻的联系：[求解线性方程组](@entry_id:169069)等价于寻找一组“权重”或“系数” $(x_1, x_2, \dots, x_n)$，使得矩阵 $A$ 的列向量能够线性组合成右侧的向量 $\mathbf{b}$。换言之，解存在当且仅当向量 $\mathbf{b}$ 位于由矩阵 $A$ 的列向量所张成的**[列空间](@entry_id:156444) (column space)** 中。

这个视角在许多应用问题中非常自然。例如，一个[冶金学](@entry_id:158855)家需要混合三种现有合金（A、B、C）来制造一种新合金 [@problem_id:1392390]。假设三种合金中铜、锡、锌的[质量百分比](@entry_id:137694)分别为：
*   合金 A: (60% 铜, 10% 锡, 30% 锌)
*   合金 B: (20% 铜, 40% 锡, 40% 锌)
*   合金 C: (50% 铜, 0% 锡, 50% 锌)

我们可以将每种合金的成分表示为一个列向量：
$$
\mathbf{a}_A = \begin{pmatrix} 0.60 \\ 0.10 \\ 0.30 \end{pmatrix}, \quad \mathbf{a}_B = \begin{pmatrix} 0.20 \\ 0.40 \\ 0.40 \end{pmatrix}, \quad \mathbf{a}_C = \begin{pmatrix} 0.50 \\ 0 \\ 0.50 \end{pmatrix}
$$
如果目标是生产一种包含 45.0 kg 铜、13.0 kg 锡和 42.0 kg 锌的最终混合物，目标向量为 $\mathbf{b} = \begin{pmatrix} 45.0 \\ 13.0 \\ 42.0 \end{pmatrix}$。设所需三种合金的质量分别为 $x_A, x_B, x_C$，那么该[混合问题](@entry_id:634383)可以直接用向量方程表示：
$$
x_A \begin{pmatrix} 0.60 \\ 0.10 \\ 0.30 \end{pmatrix} + x_B \begin{pmatrix} 0.20 \\ 0.40 \\ 0.40 \end{pmatrix} + x_C \begin{pmatrix} 0.50 \\ 0 \\ 0.50 \end{pmatrix} = \begin{pmatrix} 45.0 \\ 13.0 \\ 42.0 \end{pmatrix}
$$
求解这个[方程组](@entry_id:193238)，就是找到合适的质量 $x_A, x_B, x_C$ 来精确配比出目标合金。

### 解的存在性、唯一性与近似

当方程的数量 $m$ 和未知数的数量 $n$ 不相等时，系统的特性会发生变化。如果 $m > n$，即方程多于未知数，系统被称为**[超定系统](@entry_id:151204) (overdetermined system)**。这种系统通常没有精确解，因为施加的约束（方程）太多。反之，如果 $m  n$，系统被称为**[欠定系统](@entry_id:148701) (underdetermined system)**，通常有无穷多解。

在科学和工程实践中，[超定系统](@entry_id:151204)极为常见，尤其是在[数据拟合](@entry_id:149007)问题中。实验数据总是伴随着测量误差，导致模型无法完美穿过所有数据点。在这种情况下，我们的目标不再是寻找一个精确解，而是寻找一个“最佳”的**近似解**。

**[最小二乘法](@entry_id:137100) (Least Squares Method)** 是处理此类问题的标准方法。其核心思想是，寻找一个解 $\mathbf{x}$，使得[残差向量](@entry_id:165091) $\mathbf{r} = \mathbf{b} - A\mathbf{x}$ 的大小最小化。通常，我们最小化残差的**欧几里得范数 (Euclidean norm)** 的平方，即 $\min_{\mathbf{x}} \|\mathbf{b} - A\mathbf{x}\|_2^2$。

考虑一个实际场景：一名学生通过实验记录了一个抛射体在不同时间的四个高度数据点，并希望用一个二次多项式 $y(t) = c_0 + c_1 t + c_2 t^2$ 来拟合其轨迹 [@problem_id:2207634]。
实验数据为：(1s, 5.0m), (2s, 6.0m), (3s, 5.5m), (4s, 3.0m)。
将每个数据点代入模型，我们得到一个关于未知系数 $c_0, c_1, c_2$ 的线性方程组：
$$
\begin{cases}
    c_0 + c_1(1) + c_2(1)^2 = 5.0 \\
    c_0 + c_1(2) + c_2(2)^2 = 6.0 \\
    c_0 + c_1(3) + c_2(3)^2 = 5.5 \\
    c_0 + c_1(4) + c_2(4)^2 = 3.0
\end{cases}
$$
这个系统有 4 个方程和 3 个未知数，是一个[超定系统](@entry_id:151204)。用矩阵形式表达 $A\mathbf{x}=\mathbf{b}$，其中 $\mathbf{x} = \begin{pmatrix} c_0 \\ c_1 \\ c_2 \end{pmatrix}$，我们得到：
$$
A = \begin{pmatrix}
1  1  1 \\
1  2  4 \\
1  3  9 \\
1  4  16
\end{pmatrix}, \quad \mathbf{b} = \begin{pmatrix}
5.0 \\
6.0 \\
5.5 \\
3.0
\end{pmatrix}
$$
由于数据中存在噪声，这个[方程组](@entry_id:193238)很可能无解。最小二乘法通过求解一个称为**[正规方程](@entry_id:142238) (normal equations)** 的相关系统 $A^T A \mathbf{x} = A^T \mathbf{b}$，来找到最小化误差的系数 $\mathbf{x}$，从而得到最佳拟合曲线。

### 直接求解法：有限步内的精确求解

对于有唯一解的方阵系统（$m=n$），**直接法**旨在通过有限步的代数运算得到精确解（在不考虑计算机舍入误差的前提下）。

#### [高斯消元法](@entry_id:153590)与[回代](@entry_id:146909)

**高斯消元法 (Gaussian Elimination)** 是最经典的直接法。其策略是通过一系列**初等行变换**，将原始的系数矩阵 $A$ 转化为一个**[上三角矩阵](@entry_id:150931) (upper triangular matrix)** $U$。因为行变换是可逆的，转化后的系统 $U\mathbf{x} = \mathbf{c}$ 与原系统 $A\mathbf{x} = \mathbf{b}$ 是等价的。

一个[上三角系统](@entry_id:635483)求解起来非常容易。例如，考虑以下已经处于上三角形式的系统 [@problem_id:1392372]：
$$
\begin{align*}
2x_1 + 6x_2 + 4x_3 = \frac{11}{2} \\
3x_2 - 2x_3 = -2 \\
4x_3 = 6
\end{align*}
$$
我们可以使用**[回代法](@entry_id:168868) (Back Substitution)** 来求解。从最后一个方程开始，逐步向上求解：
1.  从第三个方程解出 $x_3$：
    $4x_3 = 6 \implies x_3 = \frac{6}{4} = \frac{3}{2}$。

2.  将 $x_3$ 的值代入第二个方程，解出 $x_2$：
    $3x_2 - 2(\frac{3}{2}) = -2 \implies 3x_2 - 3 = -2 \implies 3x_2 = 1 \implies x_2 = \frac{1}{3}$。

3.  将 $x_2$ 和 $x_3$ 的值代入第一个方程，解出 $x_1$：
    $2x_1 + 6(\frac{1}{3}) + 4(\frac{3}{2}) = \frac{11}{2} \implies 2x_1 + 2 + 6 = \frac{11}{2} \implies 2x_1 = -\frac{5}{2} \implies x_1 = -\frac{5}{4}$。

这样，我们便高效地获得了系统的唯一解 $\begin{pmatrix} -5/4  1/3  3/2 \end{pmatrix}^T$。[高斯消元法](@entry_id:153590)的前半部分（消元）就是系统化地将任意方阵系统转化为这种易于求解的形式。

#### LU 分解的威力

高斯消元法虽然有效，但其过程将对矩阵 $A$ 和向量 $\mathbf{b}$ 的操作耦合在一起。如果我们有多个具有相同[系数矩阵](@entry_id:151473) $A$ 但不同右端项 $\mathbf{b}$ 的系统需要求解（这在工程应用中很常见），反复执行高斯消元会非常低效。

**LU 分解 (LU Factorization)** 提供了一种更优雅、更高效的方案。它将高斯消元的过程形式化为一次性的矩阵分解。其目标是将矩阵 $A$ 分解为一个**下[三角矩阵](@entry_id:636278) (lower triangular matrix)** $L$ 和一个[上三角矩阵](@entry_id:150931) $U$ 的乘积：
$$
A = LU
$$
通常，$L$ 的对角线元素被设置为 1（Doolittle 分解）或 $U$ 的对角线元素被设置为 1（Crout 分解）。这个分解过程本质上记录了高斯消元所执行的行变换。

一旦获得了 $L$ 和 $U$，求解 $A\mathbf{x} = \mathbf{b}$ 的过程就转化为两个简单的三角系统求解：
1.  令 $\mathbf{y} = U\mathbf{x}$，原方程变为 $L\mathbf{y} = \mathbf{b}$。这是一个下三角系统，可以通过**前代法 (Forward Substitution)** 快速求解 $\mathbf{y}$。
2.  得到中间向量 $\mathbf{y}$ 后，再求解[上三角系统](@entry_id:635483) $U\mathbf{x} = \mathbf{y}$。这可以通过我们已经熟悉的[回代法](@entry_id:168868)完成。

例如，假设一个系统 $A\mathbf{x} = \mathbf{b}$ 的系数矩阵 $A$ 已被分解为 $L$ 和 $U$ [@problem_id:2207676]：
$$
L = \begin{pmatrix} 1  0  0 \\ 2  1  0 \\ -1  3  1 \end{pmatrix}, \quad
U = \begin{pmatrix} 2  -1  3 \\ 0  5  -2 \\ 0  0  -1 \end{pmatrix}, \quad
\mathbf{b} = \begin{pmatrix} 8 \\ 21 \\ -2 \end{pmatrix}
$$
**第一步：求解 $L\mathbf{y} = \mathbf{b}$**
$$
\begin{pmatrix} 1  0  0 \\ 2  1  0 \\ -1  3  1 \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \\ y_3 \end{pmatrix} = \begin{pmatrix} 8 \\ 21 \\ -2 \end{pmatrix}
$$
通过前代法：
$y_1 = 8$
$2y_1 + y_2 = 21 \implies 2(8) + y_2 = 21 \implies y_2 = 5$
$-y_1 + 3y_2 + y_3 = -2 \implies -8 + 3(5) + y_3 = -2 \implies y_3 = -9$
得到 $\mathbf{y} = \begin{pmatrix} 8 \\ 5 \\ -9 \end{pmatrix}$。

**第二步：求解 $U\mathbf{x} = \mathbf{y}$**
$$
\begin{pmatrix} 2  -1  3 \\ 0  5  -2 \\ 0  0  -1 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ x_3 \end{pmatrix} = \begin{pmatrix} 8 \\ 5 \\ -9 \end{pmatrix}
$$
通过[回代法](@entry_id:168868)：
$-x_3 = -9 \implies x_3 = 9$
$5x_2 - 2x_3 = 5 \implies 5x_2 - 2(9) = 5 \implies 5x_2 = 23 \implies x_2 = \frac{23}{5}$
$2x_1 - x_2 + 3x_3 = 8 \implies 2x_1 - \frac{23}{5} + 3(9) = 8 \implies 2x_1 = -\frac{72}{5} \implies x_1 = -\frac{36}{5}$
最终解为 $\mathbf{x} = \begin{pmatrix} -36/5  23/5  9 \end{pmatrix}^T$。[LU分解](@entry_id:144767)的初始成本较高，但一旦完成，后续求解过程非常迅速。

### 计算的风险：稳定与条件

到目前为止，我们都假设计算在理想的实数域中进行。然而，在真实的计算机上，数字以有限精度的**浮点数 (floating-point numbers)** 形式存储和运算，这带来了新的挑战：**数值稳定性 (numerical stability)**。

#### [病态系统](@entry_id:137611)与敏感性

某些[线性系统](@entry_id:147850)本身就具有内在的“不稳定性”。对于这类系统，输入数据（即矩阵 $A$ 或向量 $\mathbf{b}$）的微小扰动会导致解 $\mathbf{x}$ 发生巨大的变化。这类系统被称为**[病态系统](@entry_id:137611) (ill-conditioned system)**。

一个直观的例子是求解两条几近平行的直线的交点 [@problem_id:1392353]。考虑系统：
$$
\begin{align*}
x + y = 5 \\
(1-\epsilon)x + y = 2
\end{align*}
$$
其中 $\epsilon$ 是一个很小的正数。两条线的斜率分别为 $-1$ 和 $-(1-\epsilon)$，非常接近。求解该系统得到 $x_0 = 3/\epsilon$ 和 $y_0 = 5 - 3/\epsilon$。
现在，我们对第二个方程的右侧施加一个微小的扰动 $\delta$：
$$
\begin{align*}
x + y = 5 \\
(1-\epsilon)x + y = 2 + \delta
\end{align*}
$$
新解变为 $x_1 = (3-\delta)/\epsilon$ 和 $y_1 = 5 - (3-\delta)/\epsilon$。
新旧解之间的欧几里得距离为：
$$
d = \sqrt{(x_1-x_0)^2 + (y_1-y_0)^2} = \sqrt{(-\frac{\delta}{\epsilon})^2 + (\frac{\delta}{\epsilon})^2} = \frac{\sqrt{2}\,|\delta|}{|\epsilon|}
$$
这个结果表明，输入端的一个小扰动 $\delta$ 被放大了一个因子 $1/|\epsilon|$。如果 $\epsilon$ 非常小（例如 $10^{-8}$），那么即使 $\delta$ 只有 $10^{-6}$，解的变化也可能是巨大的。这就是[病态系统](@entry_id:137611)的典型特征。

为了量化这种敏感性，我们定义**[条件数](@entry_id:145150) (condition number)** $\kappa(A)$。对于一个可逆矩阵 $A$，其条件数定义为：
$$
\kappa(A) = \|A\| \|A^{-1}\|
$$
其中 $\| \cdot \|$ 是某种[矩阵范数](@entry_id:139520)。[条件数](@entry_id:145150)总是 $\ge 1$。如果 $\kappa(A)$ 是一个较小的数（接近 1），则称系统是**良态的 (well-conditioned)**。如果 $\kappa(A)$ 非常大，则系统是**病态的 (ill-conditioned)**。粗略地说，如果输入数据有 $d$ 位有效数字的精度，那么在[病态系统](@entry_id:137611)中，解的精度可能会损失 $\log_{10}(\kappa(A))$ 位。

计算[条件数](@entry_id:145150)本身需要计算[矩阵的逆](@entry_id:140380)和范数。以 $L_1$ 范数（最大绝对列和）为例，计算一个 $2 \times 2$ 矩阵 $A = \begin{pmatrix} 3  -1 \\ 5  2 \end{pmatrix}$ 的[条件数](@entry_id:145150) [@problem_id:2207677]：
1.  计算 $\|A\|_1$:
    列1和: $|3|+|5|=8$。列2和: $|-1|+|2|=3$。因此，$\|A\|_1 = \max\{8, 3\} = 8$。
2.  计算 $A^{-1}$:
    $\det(A) = (3)(2) - (-1)(5) = 11$。
    $A^{-1} = \frac{1}{11}\begin{pmatrix} 2  1 \\ -5  3 \end{pmatrix}$。
3.  计算 $\|A^{-1}\|_1$:
    列1和: $\frac{|2|+|-5|}{11} = \frac{7}{11}$。列2和: $\frac{|1|+|3|}{11} = \frac{4}{11}$。因此，$\|A^{-1}\|_1 = \frac{7}{11}$。
4.  计算[条件数](@entry_id:145150)：
    $\kappa_1(A) = \|A\|_1 \|A^{-1}\|_1 = 8 \times \frac{7}{11} = \frac{56}{11} \approx 5.09$。
这个条件数相对较小，表明该系统是良态的。

#### 有限精度与选主元的必要性

令人惊讶的是，即使一个系统是良态的，一个设计不佳的算法也可能在有限精度计算中得出灾难性的错误结果。[高斯消元法](@entry_id:153590)中的一个关键步骤是选择**主元 (pivot)**，即用于消去其下方元素的对角[线元](@entry_id:196833)素。如果主元非常小，就会导致问题。

考虑一个用于[机器人控制](@entry_id:275824)的系统，其中 $\epsilon = 10^{-4}$ 是一个很小的参数 [@problem_id:2207679]：
$$
\begin{align*}
\epsilon x_1 + x_2 = 1 \\
x_1 + x_2 = 2
\end{align*}
$$
该系统的精确解约为 $x_1 \approx 1, x_2 \approx 1$。现在，我们在一台只能进行3位[有效数字](@entry_id:144089)舍入运算的假想计算机上求解它。

**方法1：不使用选主元 (No Pivoting)**
[增广矩阵](@entry_id:150523)为 $\begin{pmatrix} 1.00 \times 10^{-4}  1  |  1 \\ 1  1  |  2 \end{pmatrix}$。
主元是 $a_{11} = 1.00 \times 10^{-4}$。
乘子 $m_{21} = \frac{1}{1.00 \times 10^{-4}} = 1.00 \times 10^4$。
执行行变换 $R_2 \leftarrow R_2 - m_{21}R_1$：
新 $a'_{22} = 1 - (1.00 \times 10^4)(1) = -9999 \to -1.00 \times 10^4$ (舍入后)。
新 $b'_{2} = 2 - (1.00 \times 10^4)(1) = -9998 \to -1.00 \times 10^4$ (舍入后)。
这里发生了**灾难性的抵消 (catastrophic cancellation)**，原始 $a_{22}$ 和 $b_2$ 的信息几乎完全丢失。
消元后的系统为 $\begin{pmatrix} 1.00 \times 10^{-4}  1  |  1 \\ 0  -1.00 \times 10^4  |  -1.00 \times 10^4 \end{pmatrix}$。
[回代](@entry_id:146909)得到：$x_2 = 1.00$，然后 $x_1 = \frac{1 - 1.00}{1.00 \times 10^{-4}} = 0$。
解为 $(0, 1)$，这与精确解相去甚远。

**方法2：使用部分选主元 (Partial Pivoting)**
在第一步，比较第一列的元素：$|a_{11}| = 10^{-4}$ 和 $|a_{21}|=1$。由于 $|a_{21}|$ 更大，我们交换第1行和第2行，以避免使用小主元。
新系统为 $\begin{pmatrix} 1  1  |  2 \\ 1.00 \times 10^{-4}  1  |  1 \end{pmatrix}$。
主元是 $a_{11} = 1$。
乘子 $m_{21} = \frac{1.00 \times 10^{-4}}{1} = 1.00 \times 10^{-4}$。
执行行变换 $R_2 \leftarrow R_2 - m_{21}R_1$：
新 $a'_{22} = 1 - (1.00 \times 10^{-4})(1) = 0.9999 \to 1.00$ (舍入后)。
新 $b'_{2} = 1 - (1.00 \times 10^{-4})(2) = 0.9998 \to 1.00$ (舍入后)。
消元后的系统为 $\begin{pmatrix} 1  1  |  2 \\ 0  1.00  |  1.00 \end{pmatrix}$。
[回代](@entry_id:146909)得到：$x_2 = 1.00$，然后 $x_1 = 2 - 1.00 = 1.00$。
解为 $(1, 1)$，这与精确解非常吻合。

这个例子有力地证明了**[选主元策略](@entry_id:169556)**（在每一步选择[绝对值](@entry_id:147688)最大的元素作为主元）对于保证高斯消元法数值稳定性的至关重要性。在实践中，几乎所有可靠的[直接求解器](@entry_id:152789)都内置了[选主元策略](@entry_id:169556)。

### 迭代求解法：一种替代路径

对于规模极其庞大（例如，百万级变量）且**稀疏 (sparse)**（即大部分系数为零）的线性系统，直接法如[LU分解](@entry_id:144767)会因为计算量（[时间复杂度](@entry_id:145062)）和存储需求（填充效应）而变得不切实际。在这种情况下，**迭代法 (iterative methods)** 提供了一条更可行的路径。

#### [不动点迭代](@entry_id:749443)与经典方法

迭代法的基本思想是从一个初始猜测 $\mathbf{x}^{(0)}$ 出发，通过一个固定的迭代规则不断产生新的近似解序列 $\mathbf{x}^{(1)}, \mathbf{x}^{(2)}, \dots$，直到序列收敛到真实解 $\mathbf{x}$。
多数[迭代法](@entry_id:194857)都可被表达为**[不动点迭代](@entry_id:749443) (fixed-point iteration)** 的形式：
$$
\mathbf{x}^{(k+1)} = T \mathbf{x}^{(k)} + \mathbf{c}
$$
其中 $T$ 是**[迭代矩阵](@entry_id:637346) (iteration matrix)**，$\mathbf{c}$ 是一个常数向量，它们都由原始矩阵 $A$ 和向量 $\mathbf{b}$ 导出。

为了导出这个形式，我们首先将矩阵 $A$ 分解为其对角部分 $D$、严格下三角部分 $-L$ 和严格上三角部分 $-U$，即 $A = D - L - U$。
原方程 $A\mathbf{x}=\mathbf{b}$ 变为 $(D - L - U)\mathbf{x} = \mathbf{b}$。

**[雅可比法](@entry_id:147508) (Jacobi Method)** 的思想是，将对角项保留在左侧，其[余项](@entry_id:159839)移到右侧：
$$
D\mathbf{x} = (L+U)\mathbf{x} + \mathbf{b}
$$
然后，两边同乘以 $D^{-1}$（假设 $D$ 可逆，即对角线上没有零），得到迭代公式：
$$
\mathbf{x} = D^{-1}(L+U)\mathbf{x} + D^{-1}\mathbf{b}
$$
这就定义了[雅可比法](@entry_id:147508)的[迭代矩阵](@entry_id:637346) $T_J = D^{-1}(L+U)$ 和常数向量 $\mathbf{c}_J = D^{-1}\mathbf{b}$。

以系统 $A\mathbf{x} = \mathbf{b}$ 为例，其中 [@problem_id:2207662]：
$$
A = \begin{pmatrix} 5  -1  2 \\ 2  8  -1 \\ -1  1  4 \end{pmatrix}, \quad \mathbf{b} = \begin{pmatrix} 10 \\ 11 \\ 3 \end{pmatrix}
$$
[分解矩阵](@entry_id:146050) $A$：
$$
D = \begin{pmatrix} 5  0  0 \\ 0  8  0 \\ 0  0  4 \end{pmatrix}, \quad L = \begin{pmatrix} 0  0  0 \\ -2  0  0 \\ 1  -1  0 \end{pmatrix}, \quad U = \begin{pmatrix} 0  1  -2 \\ 0  0  1 \\ 0  0  0 \end{pmatrix}
$$
[雅可比法](@entry_id:147508)的[迭代矩阵](@entry_id:637346)为：
$$
T_J = D^{-1}(L+U) = \begin{pmatrix} 1/5  0  0 \\ 0  1/8  0 \\ 0  0  1/4 \end{pmatrix} \begin{pmatrix} 0  1  -2 \\ -2  0  1 \\ 1  -1  0 \end{pmatrix} = \begin{pmatrix} 0  1/5  -2/5 \\ -1/4  0  1/8 \\ 1/4  -1/4  0 \end{pmatrix}
$$
常数向量为：
$$
\mathbf{c}_J = D^{-1}\mathbf{b} = \begin{pmatrix} 1/5  0  0 \\ 0  1/8  0 \\ 0  0  1/4 \end{pmatrix} \begin{pmatrix} 10 \\ 11 \\ 3 \end{pmatrix} = \begin{pmatrix} 2 \\ 11/8 \\ 3/4 \end{pmatrix}
$$

**[高斯-赛德尔法](@entry_id:145727) (Gauss-Seidel Method)** 是[雅可比法](@entry_id:147508)的一个改进。在计算 $\mathbf{x}^{(k+1)}$ 的第 $i$ 个分量时，它会立即使用刚刚计算出的 $\mathbf{x}^{(k+1)}$ 的前 $i-1$ 个分量，而不是像[雅可比法](@entry_id:147508)那样全部使用上一轮 $\mathbf{x}^{(k)}$ 的分量。这通常会加速收敛。其迭代公式为 $\mathbf{x}^{(k+1)} = (D-L)^{-1}(U\mathbf{x}^{(k)} + \mathbf{b})$。

#### [迭代法的收敛性](@entry_id:273433)问题

迭代法的核心问题是：迭代序列是否**收敛 (converge)**？理论上，[不动点迭代](@entry_id:749443) $\mathbf{x}^{(k+1)} = T \mathbf{x}^{(k)} + \mathbf{c}$ 收敛于唯一解的充要条件是[迭代矩阵](@entry_id:637346) $T$ 的**谱半径 (spectral radius)** $\rho(T)$（即其[特征值](@entry_id:154894)[绝对值](@entry_id:147688)的最大值）小于 1。

然而，计算谱半径本身可能比求解原系统还要困难。幸运的是，存在一些更容易检验的**充分条件**。其中最著名和最实用的是**[严格对角占优](@entry_id:154277) (strictly diagonally dominant, SDD)**。
一个矩阵 $A$ 被称为[严格对角占优](@entry_id:154277)，如果对于每一行，对角线元素的[绝对值](@entry_id:147688)都**严格大于**该行所有其他非对角线元素[绝对值](@entry_id:147688)之和。即：
$$
|a_{ii}| > \sum_{j \neq i} |a_{ij}| \quad \text{for all } i
$$
**[对角占优](@entry_id:748380)定理**指出：如果一个矩阵 $A$ 是[严格对角占优](@entry_id:154277)的，那么对于任意的初始猜测 $\mathbf{x}^{(0)}$，[雅可比法](@entry_id:147508)和[高斯-赛德尔法](@entry_id:145727)都保证收敛。

我们来检验以下矩阵是否满足此条件 [@problem_id:2207685]：
$$
A = \begin{pmatrix}
9  -2  3 \\
1  -5  2 \\
-4  1  6
\end{pmatrix}
$$
*   **行 1:** $|9| = 9$。非对角元素[绝对值](@entry_id:147688)和为 $|-2| + |3| = 5$。因为 $9 > 5$，条件满足。
*   **行 2:** $|-5| = 5$。非对角元素[绝对值](@entry_id:147688)和为 $|1| + |2| = 3$。因为 $5 > 3$，条件满足。
*   **行 3:** $|6| = 6$。非对角元素[绝对值](@entry_id:147688)和为 $|-4| + |1| = 5$。因为 $6 > 5$，条件满足。

由于所有行都满足条件，该矩阵是[严格对角占优](@entry_id:154277)的。因此，我们可以断定，使用[高斯-赛德尔法](@entry_id:145727)（或[雅可比法](@entry_id:147508)）求解以该矩阵为系数矩阵的任何[线性系统](@entry_id:147850) $A\mathbf{x}=\mathbf{b}$，都将收敛到唯一解。这个准则为我们在求解前判断迭代法是否可靠提供了一个强有力的工具。

### 算法效率：成本收益分析

选择求解算法时，除了稳定性和收敛性，**计算成本 (computational cost)** 也是一个关键考量。成本通常用所需的**[浮点运算次数](@entry_id:749457) (floating-point operations, flops)** 来衡量。

对于一个 $n \times n$ 的[稠密矩阵](@entry_id:174457)，标准的[高斯消元法](@entry_id:153590)（包括[前向消元](@entry_id:177124)和[回代](@entry_id:146909)）所需的乘法/除法运算总数近似为 $\frac{1}{3}n^3$。更精确的计数表明，对于一个 $10 \times 10$ 的系统，总共需要 430 次乘法/除法运算 [@problem_id:2207648]。运算量随 $n$ 的三次方增长，即这是一个 $O(n^3)$ 的算法。对于 $n=1000$，运算次数将达到数亿级别；对于 $n=10^6$，直接法变得完全不可行。

相比之下，像[雅可比](@entry_id:264467)或高斯-赛德尔这样的迭代法，每次迭代的成本主要在于矩阵-向量乘法。对于一个[稠密矩阵](@entry_id:174457)，这需要 $O(n^2)$ 次运算。如果矩阵是稀疏的，并且每行平均只有 $k$ 个非零元，那么每次迭代的成本仅为 $O(kn)$。若迭代 $N$ 次收敛，总成本为 $O(Nn^2)$ 或 $O(Nkn)$。

这就形成了一个清晰的权衡：
*   **直接法**：计算成本高（$O(n^3)$），但只要系统非奇异且算法稳定，就能在固定步数内给出解。
*   **[迭代法](@entry_id:194857)**：每次迭代成本低，特别是对于稀疏矩阵。但总成本取决于收敛速度（即迭代次数 $N$），且收敛性不总是有保证的。

在实践中，对于中小型稠密系统，经过优化的直接法（如基于LU或QR分解的库函数）通常是首选。对于[大型稀疏系统](@entry_id:177266)，尤其是在[偏微分方程数值解](@entry_id:753287)等领域产生的系统，迭代法（通常是比雅可比/高斯-赛德尔更高级的共轭梯度法或GMRES法）则是唯一可行的选择。