{"hands_on_practices": [{"introduction": "牛顿差商与函数的导数有着深刻的联系。一个关键的理论性质是，对于一个 $m$ 次多项式，其 $m+1$ 阶及更高阶的差商在精确算术中恒为零。本练习将指导你通过编程来数值验证这一基本定理，从而加深对差商算法及其与多项式结构关系的理解，并学习如何处理浮点运算带来的误差。[@problem_id:3164007]", "problem": "你的任务是设计并实现一个数值测试，用于验证牛顿差商的一个核心结构性质：对于从一个已知次数的多项式中精确采样的数据，在精确计算中，所有阶数严格大于该多项式次数的差商都为零。你的程序必须从基本原理出发计算这些差商，并数值地验证此消失性质，同时考虑到浮点舍入效应。\n\n从基本定义开始：\n- 一个 $m$ 次多项式是任何可以写成 $p(x) = \\sum_{k=0}^{m} a_k x^k$ 形式的函数 $p(x)$，其中 $a_0, a_1, \\dots, a_m$ 为系数。\n- 给定不同的节点 $x_0, x_1, \\dots, x_n$ 和值 $f(x_0), f(x_1), \\dots, f(x_n)$，牛顿差商通过以下方式递归定义：\n  $$ f[x_i] := f(x_i), $$\n  $$ f[x_i, x_{i+1}, \\dots, x_{i+k}] := \\frac{f[x_{i+1}, \\dots, x_{i+k}] - f[x_i, \\dots, x_{i+k-1}]}{x_{i+k} - x_i}, $$\n  对于 $k \\ge 1$ 和 $0 \\le i \\le n - k$。\n- 在精确计算中，如果 $f$ 是一个 $m$ 次多项式，那么对于任意阶数 $r > m$，所有 $r$ 阶差商 $f[x_i, x_{i+1}, \\dots, x_{i+r}]$ 都精确地为零。\n\n你的任务是：\n1. 实现一个函数，根据其按升序排列的系数 $[a_0, a_1, \\dots, a_m]$ 来计算多项式 $p(x)$ 的值。\n2. 对于一组给定的不同节点 $[x_0, x_1, \\dots, x_{n-1}]$ 和相应的值 $[f(x_0), f(x_1), \\dots, f(x_{n-1})]$，仅使用上述基本递归定义，实现对整个牛顿差商表的计算。\n3. 对于一个声称的多项式次数 $m$，验证所有阶数严格大于 $m$ 的差商在数值上是可忽略的。为了使此测试对浮点舍入具有鲁棒性，请使用一个自适应绝对容差\n   $$ \\tau = 10^{-10} \\cdot S, $$\n   其中\n   $$ S = \\max\\left(1, \\max_{0 \\le i \\le n-1} |f(x_i)|, \\max_{0 \\le r \\le \\min(m, n-1)} \\max_{0 \\le i \\le n-1-r} |f[x_i, x_{i+1}, \\dots, x_{i+r}]| \\right). $$\n   如果对于每个阶数 $r$（其中 $r > m$）和每个有效索引 $i$，不等式 $|f[x_i, \\dots, x_{i+r}]| \\le \\tau$ 都成立，则声明测试通过。\n\n测试套件：\n提供并使用以下测试用例集。对于每个用例，多项式系数按升序 $[a_0, a_1, \\dots, a_m]$ 列出，给定了已知次数 $m$，并指定了节点。所有节点都是不同的。\n\n- 用例 1 (正常路径，二次多项式):\n  - 多项式系数: $[1, -2, 3]$ 意为 $p(x) = 1 - 2x + 3x^2$。\n  - 次数: $m = 2$。\n  - 节点: $[-2.0, -1.0, 0.5, 3.0]$。\n\n- 用例 2 (高次多项式，多节点，非均匀间距):\n  - 多项式系数: $[-4, 2, 0, -0.5]$ 意为 $p(x) = -4 + 2x + 0x^2 - 0.5x^3$。\n  - 次数: $m = 3$。\n  - 节点: $[-1.0, -0.5, 0.0, 0.1, 0.2, 0.5, 2.0]$。\n\n- 用例 3 (边界情况，常数多项式):\n  - 多项式系数: $[5]$ 意为 $p(x) = 5$。\n  - 次数: $m = 0$。\n  - 节点: $[-10.0, -5.0, 0.0, 4.0, 100.0]$。\n\n- 用例 4 (数值挑战性尺度，四次多项式，小节点间距):\n  - 多项式系数: $[7, 0, -300.0, 0, 1000000.0]$ 意为 $p(x) = 7 - 300x^2 + 1000000x^4$。\n  - 次数: $m = 4$。\n  - 节点: $[-0.01, -0.005, 0.0, 0.005, 0.01, 0.02]$。\n\n- 用例 5 (线性多项式，对称节点):\n  - 多项式系数: $[0.25, -7.0]$ 意为 $p(x) = 0.25 - 7x$。\n  - 次数: $m = 1$。\n  - 节点: $[-3.0, -2.0, -1.0, 0.0, 1.0, 3.0]$。\n\n输出规格：\n你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，并按顺序对应上述用例。每个结果都是一个布尔值，指示该用例的验证是否通过。例如，输出格式必须严格为以下形式\n$$ [\\text{True},\\text{False},\\text{True},\\dots] $$\n不得打印任何额外文本。", "solution": "该问题要求实现一个数值测试，以验证牛顿差商对于多项式的一个基本性质。具体来说，对于一个次数为 $m$ 的多项式函数 $f(x)$，在精确计算中，所有阶数 $r > m$ 的差商都必须为零。该测试必须考虑到浮点数的不精确性，通过检查这些高阶差商是否在数值上可忽略，即其绝对值是否小于一个自适应容差 $\\tau$。\n\n解决方案由三个主要部分构成：一个用于计算多项式值的函数，一个用于计算牛顿差商表的函数，以及一个协调整个测试的主验证函数。\n\n首先，需要一种鲁棒的方法来计算多项式 $p(x) = \\sum_{k=0}^{m} a_k x^k$ 的值。给定按升序排列的系数 $[a_0, a_1, \\dots, a_m]$，霍纳法（Horner's method）是首选算法。它计算效率高，仅需 $m$ 次乘法和 $m$ 次加法，并且通常比朴素地计算并求和 $a_k x^k$ 形式的项在数值上更稳定。该方法基于将多项式重写为 $p(x) = a_0 + x(a_1 + x(a_2 + \\dots + x(a_{m-1} + a_m x)\\dots))$。这种嵌套形式通过迭代进行求值，通常从最内层开始。对于系数 $[a_0, \\dots, a_m]$，其递推关系为 $y \\leftarrow a_k + x \\cdot y$，其中 $k$ 从 $m-1$ 递减到 $0$，初始值为 $y = a_m$。\n\n其次，问题的核心是计算牛顿差商。给定 $n$ 个不同的节点 $\\{x_0, x_1, \\dots, x_{n-1}\\}$ 及其对应的函数值 $\\{f(x_0), f(x_1), \\dots, f(x_{n-1})\\}$，差商由以下递推关系定义：\n$$\nf[x_i, x_{i+1}, \\dots, x_{i+k}] := \\frac{f[x_{i+1}, \\dots, x_{i+k}] - f[x_i, \\dots, x_{i+k-1}]}{x_{i+k} - x_i}\n$$\n基例是 $0$ 阶差商，即函数值本身：$f[x_i] = f(x_i)$。\n\n这种递归结构适合于通过迭代计算来填充一个二维表。假设有一个表 $D$，其结构使 $D_{i,k}$ 存储从节点 $x_i$ 开始的 $k$ 阶差商，即 $D_{i,k} = f[x_i, \\dots, x_{i+k}]$。第一列（$k=0$）用函数值初始化：$D_{i,0} = f(x_i)$。后续的列（阶数 $k=1, 2, \\dots, n-1$）使用前一列（$k-1$）的值进行计算：\n$$\nD_{i,k} = \\frac{D_{i+1, k-1} - D_{i, k-1}}{x_{i+k} - x_i}\n$$\n此计算过程对 $k$ 从 $1$ 到 $n-1$ 进行，对于每个 $k$，索引 $i$ 的范围是从 $0$ 到 $n-1-k$。\n\n第三，验证逻辑集成了这些组件。对于一个给定的多项式，其系数为 $[a_0, \\dots, a_m]$，声称次数为 $m$，以及一组 $n$ 个节点 $\\{x_j\\}$，过程如下：\n1.  采样多项式：使用霍纳法为所有节点 $j=0, \\dots, n-1$ 计算 $y_j = p(x_j)$。\n2.  计算差商表：使用节点 $\\{x_j\\}$ 和计算出的值 $\\{y_j\\}$ 来生成完整的 $n \\times n$ 差商表 $D$。\n3.  确定自适应容差 $\\tau$：容差必须相对于有效（非零）差商的量级进行缩放。缩放因子 $S$ 定义为：\n    $$\n    S = \\max\\left(1, \\max_{\\substack{0 \\le r \\le \\min(m, n-1) \\\\ 0 \\le i \\le n-1-r}} |f[x_i, \\dots, x_{i+r}]| \\right)\n    $$\n    它的计算方法是，找出差商表中阶数 $r$ 从 $0$ 到 $\\min(m, n-1)$ 的所有条目 $D_{i,r}$ 中的最大绝对值，然后取该值与 $1$ 的最大值。容差即为 $\\tau = 10^{-10} \\cdot S$。这种自适应方法可以防止因多项式的值或其导数的尺度问题而导致的假阳性/假阴性。\n4.  执行验证：理论性质表明，对于 $r > m$，差商 $f[x_i, \\dots, x_{i+r}]$ 应为零。数值测试检查对于所有从 $m+1$ 到 $n-1$ 的阶数 $r$ 和所有有效的索引 $i$，是否有 $|D_{i,r}| \\le \\tau$ 成立。如果这个不等式对所有这些差商都成立，则对于给定的多项式和节点，测试通过。只要有一个差商超过容差，测试就失败。如果 $m \\ge n-1$，则不存在阶数大于 $m$ 的差商，因此测试无条件为真。\n\n这套完整的流程提供了一种有原则且数值上鲁棒的方法，来测试牛顿差商的指定性质。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef evaluate_poly(coeffs, x):\n    \"\"\"\n    Evaluates a polynomial at a given point x using Horner's method.\n\n    Args:\n        coeffs (list or np.ndarray): A list of coefficients [a_0, a_1, ..., a_m]\n                                      in ascending order of degree.\n        x (float): The point at which to evaluate the polynomial.\n\n    Returns:\n        float: The value of the polynomial p(x).\n    \"\"\"\n    result = 0.0\n    for coeff in reversed(coeffs):\n        result = coeff + x * result\n    return result\n\ndef compute_divided_differences(nodes, values):\n    \"\"\"\n    Computes the full Newton divided differences table.\n\n    Args:\n        nodes (np.ndarray): An array of distinct nodes x_0, ..., x_{n-1}.\n        values (np.ndarray): An array of function values f(x_0), ..., f(x_{n-1}).\n\n    Returns:\n        np.ndarray: A 2D array where table[i, k] is the k-th order\n                    divided difference f[x_i, ..., x_{i+k}].\n    \"\"\"\n    n = len(nodes)\n    dd_table = np.zeros((n, n))\n    dd_table[:, 0] = values\n\n    for k in range(1, n):  # k is the order of the difference\n        for i in range(n - k):  # i is the starting index\n            numerator = dd_table[i + 1, k - 1] - dd_table[i, k - 1]\n            denominator = nodes[i + k] - nodes[i]\n            if denominator == 0:\n                # This case should not be reached given the problem statement\n                # guarantees distinct nodes.\n                raise ValueError(\"Nodes must be distinct.\")\n            dd_table[i, k] = numerator / denominator\n            \n    return dd_table\n\ndef verify_vanishing_property(coeffs, m, nodes):\n    \"\"\"\n    Verifies that divided differences of order > m for a polynomial of\n    degree m are numerically negligible.\n\n    Args:\n        coeffs (list): Polynomial coefficients [a_0, ..., a_m].\n        m (int): The degree of the polynomial.\n        nodes (list): A list of distinct nodes for sampling.\n\n    Returns:\n        bool: True if the verification passes, False otherwise.\n    \"\"\"\n    nodes = np.array(nodes, dtype=float)\n    n = len(nodes)\n\n    # If there are not enough points to compute a difference of order > m,\n    # the condition is vacuously true. The loop range for verification will be empty.\n    # Ex: n=4 nodes, max order is 3. If m=3, test is for r > 3, which doesn't exist.\n\n    # 1. Sample the polynomial at the given nodes\n    values = np.array([evaluate_poly(coeffs, x) for x in nodes])\n\n    # 2. Compute the full divided difference table\n    dd_table = compute_divided_differences(nodes, values)\n\n    # 3. Determine the adaptive tolerance tau\n    # Calculate scale S\n    s_val = 1.0\n    # The max order to consider for S is min(m, n-1)\n    max_order_for_s = min(m, n - 1)\n    if n > 0:\n        s_val = max(s_val, np.max(np.abs(values)))\n\n    if max_order_for_s >= 0:\n        relevant_part_of_table = dd_table[:, :max_order_for_s + 1]\n        s_val = max(s_val, np.max(np.abs(relevant_part_of_table)))\n    \n    tau = 1e-10 * s_val\n\n    # 4. Perform the verification\n    # Check all divided differences of order r > m\n    for r in range(m + 1, n):\n        num_diffs_in_order = n - r\n        for i in range(num_diffs_in_order):\n            if abs(dd_table[i, r]) > tau:\n                return False\n\n    return True\n\ndef solve():\n    \"\"\"\n    Runs the verification test on a suite of predefined cases and\n    prints the results in the specified format.\n    \"\"\"\n    test_cases = [\n        {\n            \"coeffs\": [1, -2, 3],\n            \"m\": 2,\n            \"nodes\": [-2.0, -1.0, 0.5, 3.0],\n        },\n        {\n            \"coeffs\": [-4, 2, 0, -0.5],\n            \"m\": 3,\n            \"nodes\": [-1.0, -0.5, 0.0, 0.1, 0.2, 0.5, 2.0],\n        },\n        {\n            \"coeffs\": [5],\n            \"m\": 0,\n            \"nodes\": [-10.0, -5.0, 0.0, 4.0, 100.0],\n        },\n        {\n            \"coeffs\": [7, 0, -300.0, 0, 1000000.0],\n            \"m\": 4,\n            \"nodes\": [-0.01, -0.005, 0.0, 0.005, 0.01, 0.02],\n        },\n        {\n            \"coeffs\": [0.25, -7.0],\n            \"m\": 1,\n            \"nodes\": [-3.0, -2.0, -1.0, 0.0, 1.0, 3.0],\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = verify_vanishing_property(case[\"coeffs\"], case[\"m\"], case[\"nodes\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Convert Python booleans to lowercase strings for JSON-like output.\n    print(f\"[{','.join(map(lambda b: str(b).lower(), results))}]\")\n\n# The provided solution in the original file printed uppercase booleans,\n# but the problem spec shows an example with lowercase. Let's adjust to match\n# the problem spec example for strictness.\n# On re-reading problem spec, example is [True,False,True,...],\n# so Python's default `str(bool)` is correct.\ndef solve_original_output():\n    test_cases = [\n        {\"coeffs\": [1, -2, 3], \"m\": 2, \"nodes\": [-2.0, -1.0, 0.5, 3.0]},\n        {\"coeffs\": [-4, 2, 0, -0.5], \"m\": 3, \"nodes\": [-1.0, -0.5, 0.0, 0.1, 0.2, 0.5, 2.0]},\n        {\"coeffs\": [5], \"m\": 0, \"nodes\": [-10.0, -5.0, 0.0, 4.0, 100.0]},\n        {\"coeffs\": [7, 0, -300.0, 0, 1000000.0], \"m\": 4, \"nodes\": [-0.01, -0.005, 0.0, 0.005, 0.01, 0.02]},\n        {\"coeffs\": [0.25, -7.0], \"m\": 1, \"nodes\": [-3.0, -2.0, -1.0, 0.0, 1.0, 3.0]},\n    ]\n    results = [verify_vanishing_property(case[\"coeffs\"], case[\"m\"], case[\"nodes\"]) for case in test_cases]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve_original_output()\n```", "id": "3164007"}, {"introduction": "在了解了差商在处理光滑多项式时的优雅表现后，我们自然会问：当函数不光滑时会发生什么？本练习将以绝对值函数 $f(x)=|x|$ 为例，它在 $x=0$ 处有一个“尖点”且不可导。你将通过计算并观察其高阶差商的行为，亲身体验非光滑性如何导致高阶系数的“放大”而非消失，这为理解高次多项式插值的潜在不稳定性提供了重要线索。[@problem_id:3164020]", "problem": "你的任务是研究当被插值函数存在非光滑点时，其最高阶牛顿系数（也称为最高阶差商）的行为。考虑绝对值函数 $f(x)=|x|$，它在 $x=0$ 处有一个不可微的尖点。对于在互异节点 $x_{0},x_{1},\\ldots,x_{k}$ 处对函数 $f$ 进行插值的、次数至多为 $k$ 的唯一多项式 $P_{k}$，其牛顿基表示法的最高阶系数根据定义即为 $k$ 阶差商 $[x_{0},x_{1},\\ldots,x_{k}]f$。从以下基本事实出发：(i) 对于互异节点，存在唯一的插值多项式；(ii) 对于任意一组互异节点，都存在牛顿基展开。请研究在不同的节点配置下，函数 $f(x)=|x|$ 的最高阶牛顿系数的大小，以评估非光滑性如何放大高阶系数。\n\n程序要求：\n- 实现一个过程，给定互异节点 $x_{0},x_{1},\\ldots,x_{k}$ 和一个函数 $f$，通过从插值多项式的牛顿形式中正确提取最高阶系数，来计算 $k$ 阶差商 $[x_{0},x_{1},\\ldots,x_{k}]f$。该计算必须与差商的标准定义一致。\n- 将你的实现应用于下面列出的每个测试用例中的函数 $f(x)=|x|$。\n- 对于每个测试用例，你的程序必须计算并返回一个实数，该实数等于给定节点和函数 $f(x)=|x|$ 的 $k$ 阶差商 $[x_{0},x_{1},\\ldots,x_{k}]f$。不应返回任何其他量。\n\n测试套件（每个用例指定了节点；此处 $k=\\text{节点数}-1$）：\n1. 节点 $[-2,-1,0,1,2]$ （即 $x_{0}=-2$, $x_{1}=-1$, $x_{2}=0$, $x_{3}=1$, $x_{4}=2$；因此 $k=4$）。\n2. 节点 $[-2,-1,-0.5,-0.25]$ （即 $x_{0}=-2$, $x_{1}=-1$, $x_{2}=-0.5$, $x_{3}=-0.25$；因此 $k=3$）。\n3. 节点 $[0.25,0.5,1.0,2.0]$ （即 $x_{0}=0.25$, $x_{1}=0.5$, $x_{2}=1.0$, $x_{3}=2.0$；因此 $k=3$）。\n4. 节点 $[-10^{-3},0,10^{-3}]$ （即 $x_{0}=-10^{-3}$, $x_{1}=0$, $x_{2}=10^{-3}$；因此 $k=2$）。\n5. 节点 $[-10^{-3},10^{-3},2\\times 10^{-3}]$ （即 $x_{0}=-10^{-3}$, $x_{1}=10^{-3}$, $x_{2}=2\\times 10^{-3}$；因此 $k=2$）。\n6. 节点 $[-3,-0.1,0.2,0.9]$ （即 $x_{0}=-3$, $x_{1}=-0.1$, $x_{2}=0.2$, $x_{3}=0.9$；因此 $k=3$）。\n\n输出规格：\n- 你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的结果顺序与上述测试用例的顺序相同。例如，包含三个结果的输出应类似于 $[\\text{result}_{1},\\text{result}_{2},\\text{result}_{3}]$。\n- 每个结果必须是一个实数（一个浮点数）。本问题不涉及单位。\n\n设计意图与覆盖范围：\n- 测试套件包括一个包含尖点的对称节点集 ($[-2,-1,0,1,2]$)、两个完全位于尖点一侧的光滑区间节点集 ($[-2,-1,-0.5,-0.25]$ 和 $[0.25,0.5,1.0,2.0]$)、两个展示放大效应的靠近尖点的小间距边缘情况 ($[-10^{-3},0,10^{-3}]$ 和 $[-10^{-3},10^{-3},2\\times 10^{-3}]$)，以及一个跨越尖点的通用不规则节点集 ($[-3,-0.1,0.2,0.9]$)。答案是实数，量化了每种情况下 $f(x)=|x|$ 的最高阶牛顿系数。", "solution": "这个问题是有效的，因为它在科学上基于数值分析的原理，特别是多项式插值和牛顿差商。它是适定的、客观的，并为每个测试用例提供了计算唯一解所需的所有数据。函数 $f(x)=|x|$ 是一个标准的说明性例子，用于展示插值多项式对于非光滑函数的行为。\n\n目标是针对函数 $f(x)=|x|$ 和几组给定的互异节点，计算其最高阶差商 $[x_{0}, x_{1}, \\ldots, x_{k}]f$。这个量正是插值多项式牛顿形式的首项系数。\n\n设 $f(x)$ 为一个函数，$x_{0}, x_{1}, \\ldots, x_{k}$ 为 $k+1$ 个互异的点，称为节点。存在一个次数至多为 $k$ 的唯一多项式 $P_k(x)$，使得对所有 $i \\in \\{0, 1, \\ldots, k\\}$ 都有 $P_k(x_i) = f(x_i)$。该多项式可以表示为牛顿形式：\n$$\nP_k(x) = c_0 + c_1(x-x_0) + c_2(x-x_0)(x-x_1) + \\cdots + c_k(x-x_0)(x-x_1)\\cdots(x-x_{k-1})\n$$\n系数 $c_j$ 是差商，定义为 $c_j = [x_0, x_1, \\ldots, x_j]f$。本问题要求计算最高阶系数 $c_k = [x_0, x_1, \\ldots, x_k]f$。\n\n差商由以下递归公式定义：\n零阶差商是函数值本身：\n$$\n[x_i]f = f(x_i)\n$$\n对于阶数 $j > 0$，差商递归定义为：\n$$\n[x_i, x_{i+1}, \\ldots, x_{i+j}]f = \\frac{[x_{i+1}, \\ldots, x_{i+j}]f - [x_i, \\ldots, x_{i+j-1}]f}{x_{i+j} - x_i}\n$$\n这个递归定义构成了计算算法的基础。我们可以构建一个差商表，但为了仅找到最高阶系数，可以使用一种空间效率更高的算法。我们可以使用一个大小为 $k+1$ 的一维数组（例如 `c`），并对其进行迭代更新。\n\n该算法流程如下：\n1.  初始化一个长度为 $k+1$ 的数组 `c`，其值为节点处的函数值：$c_i = f(x_i)$，其中 $i=0, 1, \\ldots, k$。\n2.  对 $j$ 从 $1$ 到 $k$ 进行迭代。这对应于计算 $j$ 阶差商。\n3.  在每次迭代 $j$ 中，对 $i$ 从 $k$ 向下迭代到 $j$。这种反向循环顺序对于正确地原地更新数组 `c`至关重要。\n4.  使用递归公式更新条目 $c_i$。在步骤 $(j,i)$ 中，值 $c_i$ 保存着 $(j-1)$ 阶差商 $[x_{i-j+1}, \\ldots, x_i]f$，而 $c_{i-1}$ 保存着 $[x_{i-j}, \\ldots, x_{i-1}]f$。更新公式为：\n    $$\n    c_i \\leftarrow \\frac{c_i - c_{i-1}}{x_i - x_{i-j}}\n    $$\n5.  当循环完成（即在 $j=k$ 的迭代之后），数组的最后一个元素 $c_k$ 将保存所需的目标最高阶差商 $[x_0, x_1, \\ldots, x_k]f$。\n\n一个关键的理论结果将差商与导数联系起来。如果函数 $f$ 在包含节点 $x_0, \\ldots, x_n$ 的区间上是 $n$ 次连续可微的，那么在包含这些节点的最小区间内存在一个点 $\\xi$，使得：\n$$\n[x_0, \\ldots, x_n]f = \\frac{f^{(n)}(\\xi)}{n!}\n$$\n本问题中的函数是 $f(x)=|x|$。该函数除了在 $x=0$ 处有一个“尖点”（一个不可微点）之外，处处光滑。\n- 对于任何所有节点满足 $x_i > 0$ 或所有节点满足 $x_i < 0$ 的节点集，该函数等价于一个线性多项式（分别为 $f(x)=x$ 或 $f(x)=-x$）。对于这样的函数，$f''(x) = 0$ 并且所有更高阶的导数也为零。因此，对于 $k \\ge 2$，其 $k$ 阶差商必定为 $0$。这适用于测试用例 2 和 3。\n- 当节点集包含 $x=0$ 或跨越该点时，函数在包含节点的区间上是不光滑的。差商公式仍然适用，但我们不能再将其与高阶导数联系起来。相反，差商量化了函数在给定节点上的“多项式性”。$x=0$ 处的非光滑性预计将导致非零且可能很大的高阶差商，这反映了绝对值函数引入的奇点。测试用例旨在探究这种行为。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_highest_order_dd(nodes):\n    \"\"\"\n    Computes the highest-order Newton divided difference for f(x)=|x|.\n\n    Args:\n        nodes (list or tuple of float): A list of distinct nodes x_0, x_1, ..., x_k.\n\n    Returns:\n        float: The k-th order divided difference [x_0, ..., x_k]f.\n    \"\"\"\n    x = np.array(nodes, dtype=float)\n    y = np.abs(x)\n    k = len(x) - 1\n\n    if k  0:\n        return 0.0\n\n    # The array 'coeffs' will be updated in-place.\n    # Initially, it holds the 0-th order differences (the function values).\n    coeffs = y.copy()\n\n    # Iterate from j=1 (1st order diff) to j=k (k-th order diff).\n    for j in range(1, k + 1):\n        # The inner loop computes the j-th order differences.\n        # It must run in reverse to use the (j-1)-th order differences\n        # from the previous 'j' iteration before they are overwritten.\n        for i in range(k, j - 1, -1):\n            numerator = coeffs[i] - coeffs[i-1]\n            denominator = x[i] - x[i-j]\n            coeffs[i] = numerator / denominator\n\n    # The highest-order coefficient is the last element.\n    return coeffs[k]\n\ndef solve():\n    \"\"\"\n    Solves the problem by computing the highest-order divided difference\n    for f(x)=|x| for each of the provided test cases.\n    \"\"\"\n    test_cases = [\n        # 1. Symmetric set containing the kink\n        [-2.0, -1.0, 0.0, 1.0, 2.0],\n        # 2. Smooth-side set on the negative side\n        [-2.0, -1.0, -0.5, -0.25],\n        # 3. Smooth-side set on the positive side\n        [0.25, 0.5, 1.0, 2.0],\n        # 4. Small-spacing set symmetric about the kink\n        [-1e-3, 0.0, 1e-3],\n        # 5. Small-spacing asymmetric set near the kink\n        [-1e-3, 1e-3, 2e-3],\n        # 6. General irregular set crossing the kink\n        [-3.0, -0.1, 0.2, 0.9],\n    ]\n\n    results = []\n    for nodes in test_cases:\n        result = compute_highest_order_dd(nodes)\n        results.append(result)\n\n    # Format the final output string as required.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3164020"}, {"introduction": "理论知识的最终目的是解决实际问题。高次多项式插值在处理某些函数（如龙格函数）时会产生剧烈的振荡，即龙格现象。本练习将前两个实践的洞察力付诸实践：你将设计并实现一个智能算法，利用牛顿系数的大小作为“警报信号”，在系数超过阈值时自动将全局插值切换为分段插值，从而有效地抑制振荡，构建一个更稳定、更精确的插值模型。[@problem_id:3163936]", "problem": "要求您在牛顿差商框架内，形式化并实现一个在单个全局插值多项式与分段多项式之间切换的原则性准则，并在函数 $f(x)=\\dfrac{1}{1+x^2}$ 上对其进行测试。请使用纯数学术语进行描述，不依赖于任何特定的编程语言。您的最终交付成果必须是一个完整且可运行的程序，并遵循末尾的输出规范。\n\n从以下基本定义开始。\n\n1. 给定不同的节点 $x_0,\\dots,x_n$ 和函数值 $y_i=f(x_i)$，差商递归定义如下\n$$\nf[x_i]=y_i,\\quad f[x_i,x_{i+1},\\dots,x_{i+k}] \\;=\\; \\frac{f[x_{i+1},\\dots,x_{i+k}] - f[x_i,\\dots,x_{i+k-1}]}{x_{i+k}-x_i},\n$$\n对于 $k\\ge 1$。牛顿基函数为 $1,(x-x_0),(x-x_0)(x-x_1),\\dots$。\n\n2. 对于不同的 $x_i$，穿过点 $(x_i,y_i)$ 的至多 $n$ 次的唯一插值多项式存在，并且可以用牛顿基表示，其系数由差商给出。\n\n设计一个准则并构建一个算法，该算法从左到右遍历一组有序节点，并决定何时停止增长当前的多项式片段并开始一个新的片段。您的准则必须基于监测最新可用的高阶牛顿系数绝对值的增长情况。具体来说，对于一个暂定包含节点 $x_s,\\dots,x_t$ 的当前片段和一个预备的新节点 $x_{t+1}$，计算暂定节点集 $x_s,\\dots,x_{t+1}$ 的差商系数。如果最高阶系数的绝对值 $|c_k|$（其中 $k=t+1-s\\ge 1$）超过预设的正阈值 $\\tau$，则不要将 $x_{t+1}$ 添加到当前片段；而是将当前片段最终确定为 $x_s,\\dots,x_t$，并在 $x_{t+1}$ 处开始一个新片段。绝不使用 $k=0$ 的系数（其等于 $f[x_s]$）来触发分割。如果从未超过阈值，您将得到一个单一的全局片段。\n\n实现以下任务。\n\n- 通过在区间 $[-5,5]$ 上取 $N$ 个等距点来构造节点，即 $x_i=-5 + \\dfrac{10\\,i}{N-1}$（对于 $i=0,\\dots,N-1$），并设置 $y_i=f(x_i)$，其中 $f(x)=\\dfrac{1}{1+x^2}$。\n- 实现一个顺序的片段构建算法，该算法使用上述准则和阈值 $\\tau0$：\n  - 在最左边的节点处初始化一个片段。\n  - 尝试通过一次添加一个下一个节点来增长该片段。\n  - 在每次尝试时，为暂定片段重新计算牛顿差商系数，并仅检查阶数 $k\\ge 1$ 的最新系数。\n  - 如果 $|c_k|\\le \\tau$，则接受该节点并继续增长；如果 $|c_k|\\tau$，则在不包含新节点的情况下最终确定当前片段，并在该节点处开始一个新片段。\n- 对于求值，对于每个具有节点 $x_s,\\dots,x_t$ 及其牛顿系数 $c_0,\\dots,c_{t-s}$ 的片段，在 $[x_s,x_t]$ 中的任意 $x$ 处，使用牛顿基下的嵌套乘法来计算多项式的值。\n\n为了进行定量评估，在一个密集网格上定义最大绝对误差如下。设评估网格为 $[-5,5]$ 上的 $M$ 个等距点。对于此网格上的每个 $x$，选择其节点区间包含 $x$ 的片段（除了最后一个片段包含 $5$ 之外，将右端点包含在左侧片段中），评估相应的分段多项式，并计算 $|p(x)-f(x)|$。报告该网格上的最大值。\n\n您的程序必须为下面的每个测试用例计算在 $[-5,5]$ 上 $M=2001$ 个等距点网格上的最大绝对误差，并以所需的格式将结果作为单个列表输出。使用实数算术，不使用外部数据。\n\n测试套件：\n- 案例 A (理想路径): $N=21$, $\\tau=1.0$。\n- 案例 B (全局多项式): $N=21$, $\\tau=10^{12}$。\n- 案例 C (积极分割): $N=21$, $\\tau=10^{-3}$。\n- 案例 D (小数据集): $N=3$, $\\tau=1.0$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为 [案例 A, 案例 B, 案例 C, 案例 D]。每个条目必须是该案例的最大绝对误差的浮点数，四舍五入到 $6$ 位小数。示例格式：$[0.123456,0.000001,0.987654,0.314159]$。", "solution": "该问题要求设计并实现一种自适应算法，用于构建分段多项式插值。任务的核心是开发一个数据驱动的准则，以决定何时对插值域进行划分，目的是减轻在等距节点上进行高阶全局多项式插值时特有的振荡行为，即著名的龙格现象。函数 $f(x) = \\frac{1}{1+x^2}$ 在区间 $[-5, 5]$ 上是说明此问题的典型例子。\n\n所提出算法的基本原理是监测差商系数的增长情况。对于不同的节点 $x_0, x_1, \\dots, x_k$，k 阶差商 $f[x_0, \\dots, x_k]$ 通过差商中值定理与函数的导数相关联：\n$$\nf[x_0, \\dots, x_k] = \\frac{f^{(k)}(\\xi)}{k!}\n$$\n其中 $\\xi$ 位于这些节点所张成的区间内。大幅值的差商意味着大的导数值，这反过来表明插值多项式可能会经历快速变化和潜在的振荡。该算法将这一观察形式化为一个具体的分裂准则。\n\n算法流程如下：\n\n1.  **节点生成**：将域 $[-5, 5]$ 离散化为一组 $N$ 个有序的等距节点 $\\{x_i\\}_{i=0}^{N-1}$，其中 $x_i = -5 + \\frac{10i}{N-1}$。相应的函数值计算为 $y_i = f(x_i)$。\n\n2.  **顺序分段构建**：算法从左到右遍历节点以构建多项式片段。\n    *   设当前片段从节点索引 $s$ 开始。初始时，$s=0$。\n    *   算法逐个暂定地添加后续节点 $x_{s+1}, x_{s+2}, \\dots, x_t$。\n    *   对于在节点 $\\{x_s, \\dots, x_t\\}$ 上定义的每个暂定片段，计算牛顿差商系数 $c_j = f[x_s, \\dots, x_{s+j}]$（其中 $j = 0, \\dots, k$），$k = t-s$ 是暂定多项式的次数。\n    *   **分裂准则**：将最高阶系数的绝对值 $|c_k| = |f[x_s, \\dots, x_t]|$ 与预设的正阈值 $\\tau$ 进行比较。此检查针对任何阶数 $k \\ge 1$ 的新系数执行。\n        *   如果 $|c_k| \\le \\tau$，则节点 $x_t$ 成功并入当前片段。通过考虑下一个节点 $x_{t+1}$ 继续该过程。\n        *   如果 $|c_k|  \\tau$，则拒绝添加节点 $x_t$，因为它可能会引入不稳定性。当前片段使用节点 $\\{x_s, \\dots, x_{t-1}\\}$ 最终确定。在节点 $x_t$ 处启动一个新片段，意味着下一个片段的起始索引设置为 $s \\leftarrow t$。\n\n3.  **数据结构**：此过程的最终结果是一组片段。每个片段由其构成节点 $\\{z_0, \\dots, z_d\\}$（原始 $x_i$ 的一个子序列）和相应的牛顿系数 $\\{c_0, \\dots, c_d\\}$ 定义。\n\n4.  **多项式求值**：对于给定点 $x_{eval}$，我们必须首先确定正确的多项式片段。域 $[-5, 5]$ 根据片段的起始节点进行划分。如果片段起始于 $x_{s_0}, x_{s_1}, \\dots, x_{s_p}$，则第 $i$ 个片段的多项式用于在区间 $[x_{s_i}, x_{s_{i+1}})$ 上求值。最后一个片段覆盖区间 $[x_{s_p}, x_{N-1}]$。\n    一旦选定了具有节点 $\\{z_0, \\dots, z_d\\}$ 和系数 $\\{c_0, \\dots, c_d\\}$ 的适当片段，就使用牛顿形式的霍纳方法（秦九韶算法）来求值多项式，这种方法计算效率高且数值稳定：\n    $$\n    P(x_{eval}) = ( \\dots ( (c_d \\cdot (x_{eval}-z_{d-1}) + c_{d-1}) \\cdot (x_{eval}-z_{d-2}) + c_{d-2} ) \\dots ) \\cdot (x_{eval}-z_0) + c_0\n    $$\n\n5.  **误差评估**：为量化所得分段插值 $P(x)$ 的准确性，在 $[-5, 5]$ 上的一个包含 $M=2001$ 个点的密集评估网格上，计算其与真实函数 $f(x)$ 的最大绝对误差。误差由 $\\max_{x \\in \\text{grid}} |P(x) - f(x)|$ 给出。\n\n这种有原则的方法允许从单个全局多项式（当 $\\tau$ 很大时）自动过渡到细粒度的分段多项式（当 $\\tau$ 很小时），从而使模型复杂度能适应由差商揭示的函数的局部行为。\n\n实现包含三个主要部分：\na) 一个为给定节点集和值集计算牛顿差商系数的函数。\nb) 主要的划分逻辑，它遍历节点，应用准则，并生成多项式片段列表。\nc) 一个求值函数，它对任意 $x$ 找到正确的片段并对其牛顿多项式求值，然后用它来计算指定网格上的最大误差。", "answer": "```python\nimport numpy as np\n\ndef _compute_divided_diffs(xs, ys):\n    \"\"\"\n    Computes the Newton divided-difference coefficients for an in-place array.\n    This version returns the full diagonal of coefficients needed for the piece.\n    \n    Args:\n        xs (np.ndarray): The x-coordinates of the nodes for the current piece.\n        ys (np.ndarray): The y-coordinates of the nodes for the current piece.\n\n    Returns:\n        np.ndarray: The array of Newton coefficients for this piece.\n    \"\"\"\n    n = len(xs)\n    if n == 0:\n        return np.array([])\n    \n    coeffs = np.copy(ys).astype(float)\n    # The coefficients are the diagonal of the DD table.\n    # We can compute them using an in-place algorithm on a 1D array.\n    for j in range(1, n):\n        # Update from the end to the beginning to use previous iteration's values\n        for i in range(n - 1, j - 1, -1):\n            denominator = xs[i] - xs[i - j]\n            if denominator == 0:\n                raise ValueError(\"Nodes must be distinct.\")\n            coeffs[i] = (coeffs[i] - coeffs[i - 1]) / denominator\n    \n    # The coefficients for the polynomial based at x_0, x_1, ... are now\n    # stored in coeffs[0], coeffs[1], ...\n    # Let's return the diagonal c_j = f[x_0, ..., x_j]\n    # The current `coeffs` array holds f[x_i, ..., x_{i+j}] in position `i+j`\n    # after the j-th outer loop. No, this is incorrect.\n    # Let's use a more standard table-diagonal approach.\n    \n    n = len(xs)\n    coeffs_diag = np.copy(ys).astype(float)\n    for j in range(1, n):\n        for i in range(n - 1, j - 1, -1):\n             coeffs_diag[i] = (coeffs_diag[i] - coeffs_diag[i-1]) / (xs[i] - xs[i-j])\n    return coeffs_diag\n\n\ndef _build_pieces(x_nodes, y_nodes, tau):\n    \"\"\"\n    Constructs the piecewise polynomial based on the splitting criterion.\n\n    Args:\n        x_nodes (np.ndarray): All x-coordinates for interpolation.\n        y_nodes (np.ndarray): All y-coordinates for interpolation.\n        tau (float): The threshold for splitting.\n\n    Returns:\n        list: A list of piece dictionaries. Each dictionary contains 'nodes' and 'coeffs'.\n    \"\"\"\n    N = len(x_nodes)\n    pieces = []\n    start_idx = 0\n\n    while start_idx  N:\n        current_piece_len = 1\n        while start_idx + current_piece_len = N:\n            if current_piece_len == 1: # A piece must have at least one point (degree 0)\n                current_piece_len += 1\n                continue\n            \n            end_idx = start_idx + current_piece_len\n            tentative_nodes_x = x_nodes[start_idx : end_idx]\n            tentative_nodes_y = y_nodes[start_idx : end_idx]\n            \n            coeffs = _compute_divided_diffs(tentative_nodes_x, tentative_nodes_y)\n            highest_order_coeff = coeffs[-1]\n            \n            # Criterion: If adding the new point blows up the coefficient, split.\n            if abs(highest_order_coeff) > tau:\n                break # Finalize the piece without the current point\n            \n            current_piece_len += 1\n\n        # The loop broke, so the piece is from start_idx to start_idx + current_piece_len - 2\n        final_end_idx = start_idx + current_piece_len - 1\n        final_nodes_x = x_nodes[start_idx:final_end_idx]\n        final_nodes_y = y_nodes[start_idx:final_end_idx]\n        \n        # If the piece is empty (can happen at the very end), handle it\n        if len(final_nodes_x) == 0:\n            if start_idx  N: # Add the last single point as a piece\n                final_nodes_x = x_nodes[start_idx:start_idx+1]\n                final_nodes_y = y_nodes[start_idx:start_idx+1]\n            else:\n                 break\n        \n        final_coeffs = _compute_divided_diffs(final_nodes_x, final_nodes_y)\n        pieces.append({'nodes': final_nodes_x, 'coeffs': final_coeffs})\n        \n        start_idx = final_end_idx\n\n    return pieces\n\n\ndef _evaluate_newton_poly(x, nodes, coeffs):\n    \"\"\"\n    Evaluates a polynomial in Newton form at a point x using Horner's method.\n    \"\"\"\n    d = len(coeffs) - 1\n    if d  0: return 0.0 # Empty piece\n    y = coeffs[d]\n    for i in range(d - 1, -1, -1):\n        y = y * (x - nodes[i]) + coeffs[i]\n    return y\n\ndef calculate_max_error(N, tau, M):\n    \"\"\"\n    Performs the full procedure for one test case.\n    \"\"\"\n    f = lambda x: 1.0 / (1.0 + x**2)\n    \n    x_nodes = np.linspace(-5.0, 5.0, N)\n    y_nodes = f(x_nodes)\n    \n    pieces = _build_pieces(x_nodes, y_nodes, tau)\n    \n    x_eval_grid = np.linspace(-5.0, 5.0, M)\n    p_eval = np.zeros_like(x_eval_grid)\n    \n    piece_start_nodes_x = [p['nodes'][0] for p in pieces if len(p['nodes']) > 0]\n    \n    for i, x_val in enumerate(x_eval_grid):\n        piece_idx = np.searchsorted(piece_start_nodes_x, x_val, side='right') - 1\n        piece_idx = max(0, piece_idx) # Clip to 0 for values before the first node.\n            \n        selected_piece = pieces[piece_idx]\n        \n        p_eval[i] = _evaluate_newton_poly(x_val, selected_piece['nodes'], selected_piece['coeffs'])\n        \n    f_eval = f(x_eval_grid)\n    max_error = np.max(np.abs(p_eval - f_eval))\n    \n    return max_error\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    # The logic in _build_pieces was complex; a simpler sequential scan is more direct.\n    # The provided Python solution has a logic error. Let's rewrite a correct version.\n\n    def build_pieces_correct(x_nodes, y_nodes, tau):\n        pieces = []\n        i = 0\n        N = len(x_nodes)\n        while i  N:\n            start_idx = i\n            # Grow the current piece\n            for j in range(start_idx + 1, N):\n                # Tentative piece nodes\n                current_nodes_x = x_nodes[start_idx : j + 1]\n                current_nodes_y = y_nodes[start_idx : j + 1]\n                \n                # We need to check the highest order coefficient, which is of order k = j - start_idx\n                k = j - start_idx\n                if k  1: continue\n\n                coeffs = _compute_divided_diffs(current_nodes_x, current_nodes_y)\n                if abs(coeffs[-1]) > tau:\n                    # Split before this point j\n                    i = j\n                    break\n            else:\n                # No split occurred, the rest of the nodes form the last piece\n                i = N\n            \n            # Finalize the piece\n            piece_nodes_x = x_nodes[start_idx:i]\n            piece_nodes_y = y_nodes[start_idx:i]\n            # Handle single-point remainder\n            if not len(piece_nodes_x):\n                piece_nodes_x = x_nodes[start_idx:start_idx+1]\n                piece_nodes_y = y_nodes[start_idx:start_idx+1]\n                i = start_idx + 1\n\n            piece_coeffs = _compute_divided_diffs(piece_nodes_x, piece_nodes_y)\n            pieces.append({'nodes': piece_nodes_x, 'coeffs': piece_coeffs})\n        return pieces\n\n    def calculate_max_error_correct(N, tau, M):\n        f = lambda x: 1.0 / (1.0 + x**2)\n        x_nodes = np.linspace(-5.0, 5.0, N)\n        y_nodes = f(x_nodes)\n        \n        pieces = build_pieces_correct(x_nodes, y_nodes, tau)\n        \n        x_eval_grid = np.linspace(-5.0, 5.0, M)\n        p_eval = np.zeros_like(x_eval_grid)\n        \n        piece_start_nodes_x = [p['nodes'][0] for p in pieces if len(p['nodes']) > 0]\n        \n        for i, x_val in enumerate(x_eval_grid):\n            # Find the correct piece for x_val\n            idx = np.searchsorted(piece_start_nodes_x, x_val, side='right') - 1\n            idx = max(0, idx)\n            \n            selected_piece = pieces[idx]\n            p_eval[i] = _evaluate_newton_poly(x_val, selected_piece['nodes'], selected_piece['coeffs'])\n            \n        f_eval = f(x_eval_grid)\n        max_error = np.max(np.abs(p_eval - f_eval))\n        return max_error\n\n\n    test_cases = [\n        (21, 1.0),       # Case A\n        (21, 10e11),     # Case B (10^12) -> effectively 1e12\n        (21, 1e-3),      # Case C (10^-3)\n        (3, 1.0),        # Case D\n    ]\n    \n    M = 2001\n    results = []\n    \n    for N, tau in test_cases:\n        # Use the corrected logic, as the original included code was flawed.\n        max_err = calculate_max_error_correct(N, tau, M)\n        results.append(f\"{max_err:.6f}\") # Format to 6 decimal places\n        \n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3163936"}]}