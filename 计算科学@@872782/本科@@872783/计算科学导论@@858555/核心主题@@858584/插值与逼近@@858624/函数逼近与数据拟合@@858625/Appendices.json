{"hands_on_practices": [{"introduction": "理论知识需要通过实践来巩固。此实践环节旨在通过具体的编码挑战，加深您对函数近似中核心概念的理解。我们将从近似一个在机器学习领域至关重要的非光滑函数——修正线性单元（ReLU）函数开始。ReLU 函数 $f(x) = \\max(0, x)$ 在 $x=0$ 处存在一个“拐点”，其导数在此处不连续，这为多项式和样条等光滑近似方法带来了独特的挑战。通过这项练习 [@problem_id:3133577]，您将亲手实现并量化比较这两种经典方法在处理此类非光滑特性时的表现，从而深入理解它们各自的优势与局限性。", "problem": "您的任务是使用平滑近似在有限区间上逼近整流线性单元（ReLU）函数，该函数定义为 $f(x) = \\max(0, x)$。目标是构建两个近似函数族，并根据最大函数误差和最大导数失配来量化它们的精度。这项工作必须基于最小二乘近似和平滑变分公式的基本原理。\n\n构建并评估以下近似函数：\n- 多项式最小二乘近似函数：对于选定的区间 $[a,b]$ 和多项式次数 $n$，在 $[a,b]$ 上选择 $N_{\\text{fit}}$ 个均匀间隔的样本点 $\\{x_i\\}_{i=1}^{N_{\\text{fit}}}$，并形成一个近似函数 $p_n(x)$，该函数最小化离散最小二乘目标 $\\sum_{i=1}^{N_{\\text{fit}}} \\left(p_n(x_i) - f(x_i)\\right)^2$。在一个精细的评估网格上评估所得到的近似及其导数。\n- 三次平滑样条近似函数：对于相同的区间 $[a,b]$，如上所述在 $N_{\\text{fit}}$ 个均匀间隔点上对函数进行采样，并构建一个三次平滑样条 $s(x)$，该样条在数据保真度和平滑度之间取得平衡。该样条被定义为形如 $\\sum_{i=1}^{N_{\\text{fit}}} \\left(s(x_i) - f(x_i)\\right)^2 + \\lambda \\int_{a}^{b} \\left(s''(x)\\right)^2 \\, dx$ 的泛函的最小化子，其中 $\\lambda \\ge 0$ 表示平滑度惩罚项。使用标准三次样条（$k=3$）和指定的平滑参数。在一个精细的评估网格上评估所得到的近似及其导数。\n\n定义需要报告的精度指标：\n- 在区间 $[a,b]$ 上，在一个由 $N_{\\text{eval}}$ 个点组成的精细网格上计算的最大函数误差，由下式给出：\n$$E_{\\max} = \\max_{x \\in [a,b]} \\left|g(x) - f(x)\\right|,$$\n其中 $g(x)$ 表示近似函数（$p_n(x)$ 或 $s(x)$）。\n- 在 $[a,b] \\setminus \\{0\\}$ 上，在一个精细网格上计算的最大导数失配，不包括 $x=0$（在此处 $f'(x)$ 未定义），由下式给出：\n$$D_{\\max} = \\max_{x \\in [a,b] \\setminus \\{0\\}} \\left|g'(x) - f'(x)\\right|,$$\n其中，对于 $x0$，$f'(x)=0$；对于 $x0$，$f'(x)=1$。\n\n实现要求：\n- 拟合和评估均使用均匀网格。\n- 对于多项式最小二乘近似，通过求解在拟合网格上形成的单项式基 $\\{1, x, x^2, \\dots, x^n\\}$ 的系数的线性最小二乘问题来导出 $p_n(x)$。\n- 对于三次平滑样条，使用具有指定平滑参数和均匀拟合网格的三次样条（$k=3$）；样条必须是可微的，并且其导数 $s'(x)$ 必须在精细网格上进行评估。\n- 整流线性单元（ReLU）函数 $f'(x)$ 的导数分段定义为：当 $x0$ 时为 $0$，当 $x0$ 时为 $1$，并且在 $x=0$ 处不予考虑。\n\n评估网格和数值细节：\n- 在每个区间 $[a,b]$ 上使用 $N_{\\text{eval}} = 10001$ 个均匀间隔点进行评估。\n- 在计算 $D_{\\max}$ 时，通过省略满足 $|x| \\le \\varepsilon$（其中 $\\varepsilon = 10^{-12}$）的点，将点 $x=0$ 从评估网格中排除。\n\n测试套件：\n- 多项式情况 1：$[a,b]=[-1,1]$，次数 $n=3$，$N_{\\text{fit}}=501$。\n- 多项式情况 2：$[a,b]=[-3,3]$，次数 $n=7$，$N_{\\text{fit}}=2001$。\n- 样条情况 1：$[a,b]=[-1,1]$，平滑参数 $s=0.0$，$N_{\\text{fit}}=201$。\n- 样条情况 2：$[a,b]=[-1,1]$，平滑参数 $s=0.01$，$N_{\\text{fit}}=201$。\n- 样条情况 3：$[a,b]=[-1,1]$，平滑参数 $s=10.0$，$N_{\\text{fit}}=201$。\n\n答案规格：\n- 对于每个测试用例，计算并返回一个包含两个浮点数 $[E_{\\max}, D_{\\max}]$ 的列表，每个浮点数四舍五入到六位小数。\n- 您的程序应生成单行输出，其中包含一个逗号分隔的列表，该列表被方括号括起来，具体来说，是这些每个案例列表的列表。例如，具有三个案例的输出应类似于 $[[e_1,d_1],[e_2,d_2],[e_3,d_3]]$，其中每个 $e_i$ 和 $d_i$ 都是四舍五入到六位小数的十进制浮点数。\n\n所有量纲均为无量纲。本问题不涉及角度。不应使用外部输入或文件；程序必须是自包含的。", "solution": "问题陈述已经过验证，被认为是有效的。它在数值分析和函数近似的既定原则上具有科学依据，是良构的，并提供了所有必要信息，且以客观、正式的语言表述。任务是使用多项式最小二乘和三次平滑样条来近似整流线性单元（ReLU）函数，并量化近似质量。该问题是计算科学中的一个标准练习。\n\n待近似的函数是整流线性单元（ReLU），定义为：\n$$f(x) = \\max(0, x)$$\n这个函数是连续的，但它的一阶导数在 $x=0$ 处不连续。在其存在的地方，导数是亥维赛德阶跃函数：\n$$\nf'(x) = \\begin{cases}\n    0  \\text{如果 } x  0 \\\\\n    1  \\text{如果 } x > 0\n\\end{cases}\n$$\n在 $x=0$ 处的不可微性对平滑近似函数构成了挑战。\n\n**方法一：多项式最小二乘近似**\n\n第一种方法寻求一个 $n$ 次多项式形式的近似：\n$$p_n(x) = \\sum_{j=0}^{n} c_j x^j$$\n系数 $\\mathbf{c} = [c_0, c_1, \\dots, c_n]^T$ 是通过最小化在区间 $[a,b]$ 上的 $N_{\\text{fit}}$ 个离散样本点 $\\{x_i\\}_{i=1}^{N_{\\text{fit}}}$ 上的平方误差和来确定的。要最小化的目标函数是：\n$$S(\\mathbf{c}) = \\sum_{i=1}^{N_{\\text{fit}}} \\left( p_n(x_i) - f(x_i) \\right)^2$$\n代入 $p_n(x)$ 的表达式，我们得到一个线性最小二乘问题。这可以以矩阵形式表示为最小化 $\\|\\mathbf{A}\\mathbf{c} - \\mathbf{y}\\|_2^2$，其中 $\\mathbf{y}$ 是函数值 $f(x_i)$ 的向量，$\\mathbf{A}$ 是范德蒙矩阵，其元素为 $A_{ij} = x_i^j$，其中 $i \\in \\{1, \\dots, N_{\\text{fit}}\\}$ 和 $j \\in \\{0, \\dots, n\\}$。解可以通过求解正规方程 $\\mathbf{A}^T\\mathbf{A}\\mathbf{c} = \\mathbf{A}^T\\mathbf{y}$ 来找到。数值稳定的算法，例如基于QR分解的算法，被用来求解 $\\mathbf{c}$。一旦系数已知，多项式 $p_n(x)$ 及其导数 $p'_n(x) = \\sum_{j=1}^{n} j c_j x^{j-1}$ 就可以在任何点上进行评估。\n\n**方法二：三次平滑样条近似**\n\n第二种方法采用三次平滑样条 $s(x)$。与纯插值不同，平滑样条是最小化罚和方的函数。被最小化的目标泛函是：\n$$ \\sum_{i=1}^{N_{\\text{fit}}} \\left(s(x_i) - f(x_i)\\right)^2 + \\lambda \\int_{a}^{b} \\left(s''(x)\\right)^2 \\, dx $$\n第一项强制对数据点的保真度，而第二项由平滑参数 $\\lambda \\ge 0$ 加权，惩罚由二阶导数平方的积分所度量的粗糙度。这代表了偏差（拟合不足）和方差（过度振荡）之间的经典权衡。标准数值库通常使用一个相关的平滑参数 $s$，它设定了残差平方和的上限，$\\sum_{i=1}^{N_{\\text{fit}}} (s(x_i) - f(x_i))^2 \\le s$。当 $s=0$ 时，样条被约束以穿过所有数据点，从而产生插值样条。随着 $s$ 的增加，样条变得更平滑，更多地偏离数据点。三次样条（$k=3$）是一种分段3次多项式，它在整个区间上是连续的，并且具有连续的一阶和二阶导数（$C^2$连续性）。得到的样条对象可以被评估其值 $s(x)$ 和其导数 $s'(x)$。\n\n**误差指标计算**\n\n每个近似 $g(x)$（其中 $g$ 是 $p_n$ 或 $s$）的质量使用在 $[a,b]$ 上的 $N_{\\text{eval}}$ 个点的精细评估网格上的两个指标进行评估。\n\n1.  **最大函数误差 ($E_{\\max}$)**：此指标量化了近似函数与真实函数值之间的最大偏差。\n    $$E_{\\max} = \\max_{x \\in [a,b]} \\left|g(x) - f(x)\\right|$$\n\n2.  **最大导数失配 ($D_{\\max}$)**：此指标测量了近似函数的导数与真实函数导数之间的最大偏差。\n    $$D_{\\max} = \\max_{x \\in [a,b] \\setminus \\{0\\}} \\left|g'(x) - f'(x)\\right|$$\n    点 $x=0$ 被明确地排除在此计算之外，因为 $f'(x)$ 在那里是未定义的。在计算上，这是通过忽略零点附近一个小的容差 $\\varepsilon$ 内的点来处理的，即 $|x| \\le \\varepsilon = 10^{-12}$ 的点。\n\n将实施以下算法，以按问题陈述中指定的方式计算每个测试用例的结果。", "answer": "```python\nimport numpy as np\nfrom scipy.interpolate import UnivariateSpline\nfrom numpy.polynomial import polynomial as P\n\ndef solve():\n    \"\"\"\n    Constructs and evaluates polynomial and spline approximations of the ReLU function.\n    \"\"\"\n    \n    # Define the target function and its derivative\n    f_relu = lambda x: np.maximum(0, x)\n    f_relu_prime = lambda x: (x > 0).astype(float)\n    \n    # Define evaluation grid parameters\n    N_eval = 10001\n    epsilon = 1e-12\n    \n    # Test suite provided in the problem statement\n    test_cases = [\n        {'type': 'polynomial', 'interval': [-1, 1], 'degree': 3, 'N_fit': 501},\n        {'type': 'polynomial', 'interval': [-3, 3], 'degree': 7, 'N_fit': 2001},\n        {'type': 'spline', 'interval': [-1, 1], 's': 0.0, 'N_fit': 201},\n        {'type': 'spline', 'interval': [-1, 1], 's': 0.01, 'N_fit': 201},\n        {'type': 'spline', 'interval': [-1, 1], 's': 10.0, 'N_fit': 201},\n    ]\n\n    all_results = []\n\n    for case in test_cases:\n        a, b = case['interval']\n        N_fit = case['N_fit']\n        \n        # Create grids\n        x_fit = np.linspace(a, b, N_fit)\n        x_eval = np.linspace(a, b, N_eval)\n        \n        # Get function values on the fitting grid\n        y_fit = f_relu(x_fit)\n        \n        g_eval = None\n        g_prime_eval = None\n        \n        if case['type'] == 'polynomial':\n            n = case['degree']\n            \n            # Perform polynomial least-squares fit\n            poly_fit = P.Polynomial.fit(x_fit, y_fit, n)\n            \n            # Evaluate the polynomial and its derivative on the fine grid\n            g_eval = poly_fit(x_eval)\n            g_prime_eval = poly_fit.deriv()(x_eval)\n\n        elif case['type'] == 'spline':\n            s_param = case['s']\n            \n            # Construct the cubic smoothing spline\n            spline = UnivariateSpline(x_fit, y_fit, k=3, s=s_param)\n            \n            # Evaluate the spline and its derivative on the fine grid\n            g_eval = spline(x_eval)\n            g_prime_eval = spline.derivative(n=1)(x_eval)\n            \n        # Evaluate the true function and its derivative on the fine grid\n        f_eval = f_relu(x_eval)\n        f_prime_eval = f_relu_prime(x_eval)\n        \n        # Calculate maximum function error\n        E_max = np.max(np.abs(g_eval - f_eval))\n        \n        # Calculate maximum derivative mismatch, excluding the point x=0\n        mask = np.abs(x_eval) > epsilon\n        D_max = np.max(np.abs(g_prime_eval[mask] - f_prime_eval[mask]))\n        \n        all_results.append([round(E_max, 6), round(D_max, 6)])\n\n    # Format the final output string as a list of lists without spaces\n    outer_list_str = []\n    for res in all_results:\n        inner_list_str = f\"[{res[0]:.6f},{res[1]:.6f}]\"\n        outer_list_str.append(inner_list_str)\n    final_output_str = f\"[{','.join(outer_list_str)}]\"\n    \n    print(final_output_str)\n\nsolve()\n```", "id": "3133577"}, {"introduction": "在科学和工程应用中，我们处理的数据几乎总是含有噪声。从这些含噪数据中提取有用信息，例如计算其导数，是一个常见但充满挑战的任务，因为传统的数值微分方法会极大地放大噪声。本练习 [@problem_id:3133528] 将引导您使用 Savitzky-Golay 滤波器，这是一种基于局部多项式拟合的强大技术，能够有效平滑数据并稳健地估计导数。通过调节滤波器的窗口大小，您将通过蒙特卡洛模拟，直观地探索并量化统计学和机器学习中的一个基本概念——偏差-方差权衡（bias-variance trade-off）。", "problem": "给定一个在等距网格上采样、并被加性独立同分布噪声污染的光滑标量函数。您的任务是使用 Savitzky-Golay 多项式平滑方法，从带噪样本中近似其梯度，即一阶导数，并量化由窗口大小选择引起的偏差-方差权衡。您必须设计一个程序，该程序使用固定的随机种子执行蒙特卡洛评估，以确保确定性输出。您的推导应基于以下基本原则：导数的定义、光滑函数的泰勒级数展开、局部窗口上的最小二乘多项式拟合，以及统计偏差和方差的定义。\n\n设置。设真实函数为\n$$\nf(x) = e^{\\sin(2\\pi x)} + \\frac{1}{2} x^3,\n$$\n其导数为\n$$\ng(x) = \\frac{df}{dx}(x) = e^{\\sin(2\\pi x)} \\cdot \\cos(2\\pi x) \\cdot 2\\pi + \\frac{3}{2} x^2,\n$$\n其中三角函数的参数以弧度为单位。考虑在区间 $$[0,1]$$ 上大小为 $$N=201$$ 的均匀网格，由 $$x_i = \\frac{i}{N-1}$$（对于 $$i=0,1,\\dots,N-1$$）给出，间距为 $$\\Delta = \\frac{1}{N-1}$$。对于每次蒙特卡洛复制，生成带噪观测值\n$$\ny_i = f(x_i) + \\varepsilon_i,\n$$\n其中 $$\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma^2)$$ 在 $$i$$ 上是独立的。使用固定的复制次数 $$S=200$$ 和固定的随机种子 $$12345$$ 以保证可复现性。\n\n估计器。对于给定的奇数窗口长度 $$w$$ 和多项式阶数 $$p$$（其中 $$w  p \\ge 0$$），将点 $$x_i$$ 处的 Savitzky-Golay 导数估计器 $$\\widehat{g}_i$$ 定义为：在以 $$x_i$$ 为中心的长度为 $$w$$ 的窗口上（边界附近作适当处理），最小化残差平方和的 $$p$$ 次多项式在 $$x_i$$ 处的一阶导数，然后除以 $$\\Delta$$ 以正确缩放到 $$g(x)$$ 的单位。\n\n偏差-方差评估。对于每种配置 $$(w,p,\\sigma)$$，运行 $$S$$ 次复制以获得 $$\\widehat{g}_i^{(s)}$$（其中 $$s=1,\\dots,S$$ 且 $$i=0,\\dots,N-1$$）。令\n$$\n\\overline{g}_i = \\frac{1}{S}\\sum_{s=1}^S \\widehat{g}_i^{(s)}\n$$\n为网格位置 $$i$$ 处估计器的经验均值，并令\n$$\n\\widehat{\\operatorname{Var}}_i = \\frac{1}{S-1}\\sum_{s=1}^S \\left(\\widehat{g}_i^{(s)} - \\overline{g}_i\\right)^2\n$$\n为位置 $$i$$ 处的样本方差。定义均方根偏差为\n$$\n\\operatorname{RMSBias} = \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1} \\left(\\overline{g}_i - g(x_i)\\right)^2}\n$$\n以及平均方差为\n$$\n\\operatorname{MeanVar} = \\frac{1}{N}\\sum_{i=0}^{N-1} \\widehat{\\operatorname{Var}}_i.\n$$\n\n测试套件。使用以下四种配置来评估不同窗口大小和噪声水平下的偏差-方差权衡，同时保持多项式阶数固定为 $$p=3$$：\n- 情况 $$1$$（小窗口）：$$(w,p,\\sigma) = (5,3,0.05)$$。\n- 情况 $$2$$（中等窗口）：$$(w,p,\\sigma) = (21,3,0.05)$$。\n- 情况 $$3$$（大窗口）：$$(w,p,\\sigma) = (61,3,0.05)$$。\n- 情况 $$4$$（更高噪声）：$$(w,p,\\sigma) = (21,3,0.20)$$。\n\n您的程序必须：\n- 使用在 $$[0,1]$$ 上大小为 $$N=201$$、间距为 $$\\Delta = \\frac{1}{200}$$ 的网格。\n- 对于每种情况，使用相同的固定种子 $$12345$$ 生成 $$S=200$$ 个独立的带噪数据集以保证可复现性，并使用指定的 $$(w,p)$$ 和导数阶数 $$1$$，通过 Savitzky-Golay 平滑来估计导数。在整个过程中，所有三角函数均使用弧度度量。\n- 计算如上定义的 $$\\operatorname{RMSBias}$$ 和 $$\\operatorname{MeanVar}$$。\n- 将每个报告的数字四舍五入到恰好 $$6$$ 位小数。\n\n最终输出格式。您的程序应生成单行输出，其中包含所有测试用例结果的逗号分隔列表，按顺序排列，每个用例贡献两个浮点数 $$(\\operatorname{RMSBias}, \\operatorname{MeanVar})$$，从而产生一个包含 $$8$$ 个数字的扁平列表。该行必须用方括号括起来，例如\n$$\n[\\text{bias}_1,\\text{var}_1,\\text{bias}_2,\\text{var}_2,\\text{bias}_3,\\text{var}_3,\\text{bias}_4,\\text{var}_4].\n$$\n不应打印任何附加文本。在本问题中，所有数值均为无单位量，角度应以弧度为单位进行解释。将所有打印的数字四舍五入到 $$6$$ 位小数。", "solution": "用户提供的问题是有效的。这是一个结构良好、具有科学依据的计算科学练习，专注于函数逼近和偏差-方差权衡。所有必要的参数、函数和定义均已提供，没有矛盾或含糊之处。\n\n解决方案将是一个基于蒙特卡洛模拟的数值实验。每个测试用例的核心步骤如下：\n1.  **网格与函数定义**：在区间 $[0,1]$ 上定义一个包含 $N=201$ 个点的均匀网格。在这些网格点上计算真实函数 $f(x) = e^{\\sin(2\\pi x)} + \\frac{1}{2} x^3$ 及其解析导数 $g(x) = \\frac{df}{dx}(x) = 2\\pi e^{\\sin(2\\pi x)} \\cos(2\\pi x) + \\frac{3}{2} x^2$ 的值。\n\n2.  **蒙特卡洛模拟**：对于窗口大小 $w$、多项式阶数 $p$ 和噪声标准差 $\\sigma$ 的每一种配置，执行 $S=200$ 次复制的模拟。为确保可复现性，并允许在相同的随机噪声样本集上直接比较参数变化的影响，每个配置的模拟开始时都使用固定的随机种子 $12345$。\n    - 在每次复制 $s \\in \\{1, \\dots, S\\}$ 中，生成带噪数据 $y_i^{(s)} = f(x_i) + \\varepsilon_i^{(s)}$，其中 $\\varepsilon_i^{(s)}$ 从正态分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取。\n    - Savitzky-Golay 滤波器应用于带噪数据 $\\{y_i^{(s)}\\}$ 以估计一阶导数。这是通过使用 `scipy.signal.savgol_filter` 并设置 `deriv=1` 来完成的。该滤波器在大小为 $w$ 的窗口内对数据点进行局部 $p$ 次多项式拟合，并计算该多项式的导数。函数的 `delta` 参数设置为网格间距 $\\Delta = 1/(N-1)$，以确保导数被正确缩放。此过程为每个网格点 $x_i$ 产生估计的导数 $\\widehat{g}_i^{(s)}$。\n\n3.  **偏差与方差计算**：完成 $S$ 次复制后，收集到的每个网格点 $i$ 的估计值 $\\{\\widehat{g}_i^{(s)}\\}_{s=1}^S$ 用于计算性能指标。\n    - 每个点上估计器的经验均值计算为 $\\overline{g}_i = \\frac{1}{S}\\sum_{s=1}^S \\widehat{g}_i^{(s)}$。\n    - 每个点上的偏差平方为 $(\\overline{g}_i - g(x_i))^2$。然后，将整体性能指标，即均方根偏差，计算为 $\\operatorname{RMSBias} = \\sqrt{\\frac{1}{N}\\sum_{i=0}^{N-1} (\\overline{g}_i - g(x_i))^2}$。\n    - 每个点上估计器的样本方差使用无偏估计量公式计算 $\\widehat{\\operatorname{Var}}_i = \\frac{1}{S-1}\\sum_{s=1}^S (\\widehat{g}_i^{(s)} - \\overline{g}_i)^2$。\n    - 整体平均方差是这些样本方差在所有网格点上的平均值：$\\operatorname{MeanVar} = \\frac{1}{N}\\sum_{i=0}^{N-1} \\widehat{\\operatorname{Var}}_i$。\n\n4.  **权衡分析**：为四个不同的测试用例计算配对 $(\\operatorname{RMSBias}, \\operatorname{MeanVar})$：\n    - 情况 1：$(w,p,\\sigma) = (5,3,0.05)$ (小窗口)\n    - 情况 2：$(w,p,\\sigma) = (21,3,0.05)$ (中等窗口)\n    - 情况 3：$(w,p,\\sigma) = (61,3,0.05)$ (大窗口)\n    - 情况 4：$(w,p,\\sigma) = (21,3,0.20)$ (高噪声)\n\n此过程可以对偏差-方差权衡进行定量评估。通常，增加窗口大小 $w$ 会导致方差减小（因为对更多的噪声点进行了平均），但偏差会增加（因为局部多项式必须拟合更宽、可能更弯曲的函数段，导致系统性误差）。增加噪声水平 $\\sigma$ 主要会增加方差，而对偏差的影响很小。然后将最终结果格式化为所需的精度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.signal import savgol_filter\n\ndef solve():\n    \"\"\"\n    Performs a Monte Carlo assessment of the Savitzky-Golay derivative estimator\n    to quantify the bias-variance trade-off.\n    \"\"\"\n    # Define simulation parameters from the problem statement.\n    N = 201\n    S = 200\n    SEED = 12345\n\n    # Define the test cases.\n    test_cases = [\n        # (w, p, sigma)\n        (5, 3, 0.05),   # Case 1: small window\n        (21, 3, 0.05),  # Case 2: moderate window\n        (61, 3, 0.05),  # Case 3: large window\n        (21, 3, 0.20),  # Case 4: higher noise\n    ]\n\n    # Grid setup\n    x = np.linspace(0.0, 1.0, N)\n    delta = 1.0 / (N - 1)\n\n    # True function and its derivative\n    def f(t):\n        return np.exp(np.sin(2 * np.pi * t)) + 0.5 * t**3\n\n    def g(t):\n        return (np.exp(np.sin(2 * np.pi * t)) * np.cos(2 * np.pi * t) * 2 * np.pi\n                + 1.5 * t**2)\n\n    f_x = f(x)\n    g_x = g(x)\n\n    results = []\n\n    for w, p, sigma in test_cases:\n        # For each case, re-initialize the random number generator with the same seed\n        # for a fair comparison of parameters on identical noise patterns.\n        rng = np.random.default_rng(SEED)\n\n        # Array to store derivative estimates from all S replications\n        all_g_hats = np.zeros((S, N))\n\n        # Monte Carlo simulation loop\n        for s in range(S):\n            # Generate noisy observations\n            noise = rng.normal(loc=0.0, scale=sigma, size=N)\n            y = f_x + noise\n\n            # Estimate the derivative using Savitzky-Golay filter\n            g_hat = savgol_filter(y, window_length=w, polyorder=p,\n                                  deriv=1, delta=delta)\n            all_g_hats[s, :] = g_hat\n\n        # Calculate statistics after all replications are complete\n        \n        # Empirical mean of the estimator at each grid point\n        g_bar = np.mean(all_g_hats, axis=0)\n        \n        # Sample variance of the estimator at each grid point (ddof=1 for S-1 denominator)\n        var_hat = np.var(all_g_hats, axis=0, ddof=1)\n\n        # Compute overall RMS Bias and Mean Variance\n        squared_bias = (g_bar - g_x)**2\n        rms_bias = np.sqrt(np.mean(squared_bias))\n        mean_var = np.mean(var_hat)\n\n        results.append(rms_bias)\n        results.append(mean_var)\n\n    # Format the results for final output\n    # All numbers are rounded to exactly 6 decimal places.\n    formatted_results = [f\"{val:.6f}\" for val in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3133528"}, {"introduction": "样条函数是功能强大的近似工具，但其效果在很大程度上取决于“节点”（knots）的放置位置。虽然均匀分布的节点易于实现，但根据函数自身的特性来策略性地放置节点，往往能以更少的参数获得更高的精度。这项练习 [@problem_id:3133600] 将问题提升到了一个新的层次，将节点放置视为一个离散优化问题。您需要通过穷举搜索，从一组候选位置中为样条函数找到最佳的内部节点组合，以最小化对目标函数 $f(x)=\\sin(5x)$ 的近似误差，并将其结果与标准的均匀节点策略进行对比，从而切身体会自适应方法在函数近似中的巨大威力。", "problem": "您的任务是设计并实现一个程序，该程序将一个分段三次样条拟合到区间 $[0,2\\pi]$ 上的函数 $f(x)=\\sin(5x)$，其中所有角度都以弧度为单位。该样条是通过对具有一组指定内部节点的立方B样条空间进行最小二乘 (LS) 拟合来构建的。您必须将内部节点放置问题作为一个在候选网格上的离散组合优化问题，并将找到的最佳拟合与使用均匀间隔内部节点的基准进行比较。所有涉及角度的量都必须以弧度处理。误差度量是在密集评估网格上，拟合样条与真实函数之间的均方误差 (MSE)。您的输出必须是如下指定的浮点数。\n\n基本原理和约束：\n- 从最小二乘拟合的定义出发，即最小化在选定函数空间上观测值与模型之间的残差平方和。这里的模型空间是由一组固定的内部节点和次数 $k=3$ 定义的立方样条的有限维向量空间。\n- 使用区间 $[a,b]=[0,2\\pi]$，其中 $x$ 以弧度为单位，目标函数为 $f(x)=\\sin(5x)$。\n- 对于每个测试用例，生成一个数据集 $\\{(x_i,y_i)\\}_{i=1}^{N_{\\text{data}}}$，其中 $x_i$ 在 $[0,2\\pi]$ 上均匀分布，且 $y_i=f(x_i)$。不添加噪声。\n- 将评估网格 $\\{x_j^{\\text{eval}}\\}_{j=1}^{N_{\\text{eval}}}$ 上的均方误差定义为\n$$\n\\text{MSE}=\\frac{1}{N_{\\text{eval}}}\\sum_{j=1}^{N_{\\text{eval}}}\\left(s(x_j^{\\text{eval}})-f(x_j^{\\text{eval}})\\right)^2,\n$$\n其中 $s(x)$ 是拟合的样条，而 $f(x)=\\sin(5x)$。\n- 内部节点必须严格位于 $(0,2\\pi)$ 内部，并且严格递增。样条次数为 $k=3$ (三次)，除了最小二乘法外没有额外的平滑处理；拟合完全通过最小化样条空间中的残差平方和来实现。\n\n优化公式：\n- 设 $m$ 表示要放置的内部节点数量，设 $N_{\\text{cand}}$ 表示候选内部节点位置的数量，这些候选位置是在开区间 $(0,2\\pi)$ 中生成的 $N_{\\text{cand}}$ 个等距点。\n- 自由节点放置问题是离散的：从 $N_{\\text{cand}}$ 个候选位置中选择 $m$ 个不同的内部节点位置，以最小化评估网格上的均方误差 (MSE)。这个选择是一个对所有 $\\binom{N_{\\text{cand}}}{m}$ 种组合的组合优化问题。针对本问题，您必须通过对所有组合进行穷举来解决它，并选择产生最小 MSE 的那一个。如果任何组合由于可行性约束而无法产生有效的样条拟合，则应跳过该组合，而不终止程序。\n- 基准情况使用 $m$ 个在 $(0,2\\pi)$ 内均匀分布的内部节点，即将 $[0,2\\pi]$ 分成 $m+1$ 个相等的子区间，并在每个内部分割点放置一个内部节点。\n\n评估和输出：\n- 使用 $N_{\\text{eval}}=2001$ 个在 $[0,2\\pi]$ 上均匀分布的评估点来计算 MSE。\n- 对于每个测试用例，计算：\n  1. $\\text{MSE}_{\\text{free}}^\\star$：通过对来自 $N_{\\text{cand}}$ 个内部候选节点的所有大小为 $m$ 的组合进行穷举搜索所达到的最小 MSE。\n  2. $\\text{MSE}_{\\text{uniform}}$：使用 $m$ 个均匀分布的内部节点时的 MSE。\n  3. 比率 $r=\\text{MSE}_{\\text{free}}^\\star / \\text{MSE}_{\\text{uniform}}$，以浮点数形式表示。\n\n测试套件：\n在以下三个测试用例上运行程序，每个用例表示为一个三元组 $(m, N_{\\text{cand}}, N_{\\text{data}})$：\n- 用例 1：$(m, N_{\\text{cand}}, N_{\\text{data}})=(2, 10, 101)$。\n- 用例 2：$(m, N_{\\text{cand}}, N_{\\text{data}})=(3, 12, 121)$。\n- 用例 3：$(m, N_{\\text{cand}}, N_{\\text{data}})=(3, 13, 151)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含三个比率 $[r_1,r_2,r_3]$，按上述顺序列出，分别对应三个测试用例。每个比率必须精确到小数点后 $6$ 位，列表必须用逗号分隔，无空格，并用方括号括起来。例如，一个可接受的输出格式为 $[0.123456,0.234567,0.345678]$。", "solution": "用户要求设计并实现一个程序，以解决分段三次样条的节点放置优化问题。该问题被验证为是合理的、适定的和客观的。这是一个涉及函数逼近的标准数值分析任务。\n\n### 基于原理的设计\n\n解决方案是基于使用样条进行函数逼近和数值优化的原理构建的。\n\n1.  **样条表示**：一种称为样条的分段多项式函数，由其多项式次数 $k$ 和一个称为节点的点序列定义。对于此问题，我们使用三次样条，因此次数为 $k=3$。样条在节点处的平滑度由节点的多重性决定。这里使用的特定样条基是B样条基，它具有适用于数值计算的理想属性，例如局部支撑和构成单位分解。一个样条函数 $s(x)$ 可以表示为B样条基函数 $B_{j,k,t}(x)$ 的线性组合：\n    $$\n    s(x) = \\sum_{j=0}^{n-1} c_j B_{j, k, t}(x)\n    $$\n    其中 $\\{c_j\\}$ 是样条系数，$t$ 是节点向量，$n$ 是基函数的数量。基函数的数量与内部节点数 $m$ 和样条次数 $k$ 的关系为 $n = m + k + 1$。对于区间 $[a, b]$ 上具有 $m$ 个内部节点 $\\{t_1, \\dots, t_m\\}$ 的样条，其完整节点向量 $t$ 是通过在内部节点两侧增补具有 $k+1$ 重数性的边界节点来构建的。这确保了样条对于某些拟合类型能够适当地插值边界条件。因此，完整的节点向量为：\n    $$\n    t = [\\underbrace{a, \\dots, a}_{k+1 \\text{ times}}, t_1, \\dots, t_m, \\underbrace{b, \\dots, b}_{k+1 \\text{ times}}]\n    $$\n\n2.  **最小二乘拟合**：该问题要求通过最小化残差平方和，将样条拟合到一组数据点 $\\{(x_i, y_i)\\}_{i=1}^{N_{\\text{data}}}$。数据由目标函数 $f(x) = \\sin(5x)$ 生成，不含噪声。目标是找到最小化以下表达式的系数 $c = (c_0, \\dots, c_{n-1})$：\n    $$\n    \\sum_{i=1}^{N_{\\text{data}}} \\left( s(x_i) - y_i \\right)^2 = \\sum_{i=1}^{N_{\\text{data}}} \\left( \\sum_{j=0}^{n-1} c_j B_{j, k, t}(x_i) - y_i \\right)^2\n    $$\n    这是一个线性最小二乘问题。如果我们定义一个设计矩阵 $A$，其元素为 $A_{ij} = B_{j, k, t}(x_i)$，一个系数向量 $c$ 和一个数据值向量 $y$，那么问题就是找到最小化 $\\|Ac - y\\|_2^2$ 的 $c$。`scipy.interpolate.make_lsq_spline` 函数专门用于解决这个问题，需要提供数据点、完整的节点向量和样条次数。\n\n3.  **节点放置优化**：样条逼近的质量在很大程度上取决于其节点的放置。节点的优化放置是一个具有挑战性的非线性优化问题。本问题将其简化为一个离散组合优化问题。在开区间 $(a, b) = (0, 2\\pi)$ 内建立一个包含 $N_{\\text{cand}}$ 个候选节点位置的网格。任务是从这些候选中选择一个包含 $m$ 个节点的子集，使得在最小二乘拟合后能得到最低的均方误差 (MSE)。MSE 的定义如下：\n    $$\n    \\text{MSE} = \\frac{1}{N_{\\text{eval}}} \\sum_{j=1}^{N_{\\text{eval}}} \\left( s(x_j^{\\text{eval}}) - f(x_j^{\\text{eval}}) \\right)^2\n    $$\n    由于给定测试用例的组合数 $\\binom{N_{\\text{cand}}}{m}$ 很小，该问题通过穷举搜索解决。我们遍历每一种可能的 $m$ 个节点的组合，对每一种组合执行最小二乘拟合，计算由此产生的 MSE，并找出产生最小 MSE 的组合，记为 $\\text{MSE}_{\\text{free}}^\\star$。\n\n4.  **基准比较**：为了量化通过优化节点位置所带来的改进，将自由节点放置的结果与基准情况进行比较。基准情况使用 $m$ 个在区间 $(0, 2\\pi)$ 内均匀分布的内部节点。这为样条逼近提供了一个标准的、非自适应的参考。此配置的 MSE，即 $\\text{MSE}_{\\text{uniform}}$，使用相同的最小二乘拟合过程计算。\n\n5.  **算法实现**：\n    -   对于每个测试用例 `(m, N_cand, N_data)`，执行主逻辑。\n    -   定义一个辅助函数，用于计算给定一组内部节点的 MSE。该函数封装了样条的创建、拟合和评估，从而提高了代码的重用性和清晰度。它包含了对可能不满足唯一最小二乘解条件（例如，Schoenberg-Whitney 条件）的节点和数据组合的错误处理，确保了程序的鲁棒性。\n    -   穷举搜索使用 `itertools.combinations` 遍历候选节点的所有组合，并为每个组合调用辅助函数以找到 `MSE_free_star`。\n    -   基准 MSE，即 `MSE_uniform`，通过使用均匀分布的节点调用相同的辅助函数来计算。\n    -   计算、格式化并存储最终的比率 $r = \\text{MSE}_{\\text{free}}^\\star / \\text{MSE}_{\\text{uniform}}$。\n    -   处理完所有测试用例后，按指定格式打印收集到的比率。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.interpolate import make_lsq_spline\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Solves a set of spline fitting problems with knot optimization.\n    For each test case, it computes the ratio of the Mean Squared Error (MSE)\n    from an optimized knot placement to the MSE from a uniform knot placement.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (2, 10, 101),\n        (3, 12, 121),\n        (3, 13, 151),\n    ]\n\n    results = []\n    \n    # Process each test case\n    for m, N_cand, N_data in test_cases:\n        # --- 1. Setup Phase: Define constants, grids, and target function ---\n        a, b = 0.0, 2.0 * np.pi\n        k = 3\n        N_eval = 2001\n        \n        # Target function to be approximated\n        f = lambda x: np.sin(5.0 * x)\n        \n        # Data points for least-squares fitting\n        x_data = np.linspace(a, b, N_data)\n        y_data = f(x_data)\n        \n        # Dense grid for evaluating the approximation error (MSE)\n        x_eval = np.linspace(a, b, N_eval)\n        y_true_eval = f(x_eval)\n\n        # --- 2. Helper Function for MSE Calculation ---\n        def compute_spline_mse(interior_knots):\n            \"\"\"\n            Computes the MSE for a spline fit with a given set of interior knots.\n            \n            Args:\n                interior_knots (list or np.ndarray): A list of interior knot locations.\n            \n            Returns:\n                float: The calculated Mean Squared Error. Returns np.inf if fitting fails.\n            \"\"\"\n            try:\n                # The full knot vector includes boundary knots with multiplicity k+1.\n                t = np.concatenate(([a] * (k + 1), sorted(interior_knots), [b] * (k + 1)))\n                \n                # Perform the least-squares spline fit.\n                # make_lsq_spline finds the coefficients c for the spline s(x)\n                # that minimizes the sum of squared errors ||s(x_data) - y_data||^2.\n                spl = make_lsq_spline(x_data, y_data, t, k, check_finite=False)\n                \n                # Evaluate the fitted spline on the dense evaluation grid.\n                y_spline_eval = spl(x_eval)\n                \n                # Calculate the Mean Squared Error.\n                mse = np.mean((y_spline_eval - y_true_eval) ** 2)\n                return mse\n                \n            except (ValueError, np.linalg.LinAlgError):\n                # The Schoenberg-Whitney conditions might not be met for certain\n                # pathological knot/data configurations, causing the fit to fail.\n                # As per the problem, such combinations should be skipped.\n                return np.inf\n\n        # --- 3. Free-Knot Optimization (Exhaustive Search) ---\n        # Generate N_cand candidate knots uniformly in the open interval (a, b).\n        cand_knots = np.linspace(a, b, N_cand + 2)[1:-1]\n        min_mse_free = np.inf\n        \n        # Iterate over all combinations of m knots from the candidate set.\n        for knot_combo in combinations(cand_knots, m):\n            mse = compute_spline_mse(list(knot_combo))\n            min_mse_free = min(min_mse_free, mse)\n        \n        # --- 4. Uniform-Knot Baseline ---\n        # Generate m uniformly spaced interior knots.\n        uniform_knots = np.linspace(a, b, m + 2)[1:-1]\n        mse_uniform = compute_spline_mse(uniform_knots)\n        \n        # --- 5. Compute and Store the Ratio ---\n        # If mse_uniform is zero or inf, the ratio is ill-defined.\n        # This is unlikely but handled for robustness.\n        if mse_uniform > 0 and np.isfinite(mse_uniform):\n            ratio = min_mse_free / mse_uniform\n        else:\n            ratio = 1.0  # Or another sensible default\n        \n        results.append(f\"{ratio:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3133600"}]}