{"hands_on_practices": [{"introduction": "我们经常使用标准的、预先推导出的有限差分公式，但理解这些公式的构建过程至关重要。这项实践将深入探讨其核心，将推导过程本身转化为一种算法。您将实现一个通用工具，它能为任意阶的导数在任意给定的网格点上生成有限差分权重，从而深刻理解其背后的数学原理 [@problem_id:3238803]。", "problem": "您的任务是实现并测试一个通用例程，该例程使用一组给定的模板节点来生成用于近似高阶导数的精确有限差分权重。推导的基本依据必须是光滑函数的泰勒级数展开和由此导出的矩条件。您的实现必须求解一个从多项式精确性条件推导出的方形线性系统，并尽可能使用精确有理数算术。\n\n设 $f$ 为一个光滑函数，$x \\in \\mathbb{R}$ 为一个点，$h \\in \\mathbb{R}$ 为一个步长，模板由不同的节点 $s_0, s_1, \\dots, s_{n-1} \\in \\mathbb{R}$ 给出。目标是构造权重 $w_0, w_1, \\dots, w_{n-1}$，使得有限差分公式\n$$\n\\frac{1}{h^p} \\sum_{j=0}^{n-1} w_j \\, f(x + h s_j)\n$$\n对于所有次数最高为 $n-1$ 的多项式，都能精确地再现其 $p$ 阶导数 $f^{(p)}(x)$。\n\n从泰勒级数展开式\n$$\nf(x + h s_j) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(x)}{k!} (h s_j)^k,\n$$\n出发，对次数 $k = 0, 1, \\dots, n-1$ 施加多项式精确性（矩）条件：\n$$\n\\sum_{j=0}^{n-1} w_j s_j^k =\n\\begin{cases}\n0,  \\text{if } k \\neq p, \\\\\np!,  \\text{if } k = p.\n\\end{cases}\n$$\n这些条件产生了包含 $n$ 个未知数 $w_j$ 的 $n$ 个方程的线性系统。该系统的矩阵是一个方形范德蒙型矩阵，其元素为 $s_j^k$。\n\n您的程序必须：\n- 为通用的导数阶数 $p$ 和互不相同的通用模板节点 $s_j$ 构建并求解线性系统。\n- 当节点为整数时，通过标准库功能在有理数域中进行运算，使用精确有理数算术，从而使得到的权重是精确的有理数。如果精确符号求解不适用（例如，非整数节点），则可接受浮点求解，但在此任务中，所有提供的模板节点均为整数。\n- 验证输入并通过受控方式引发或发出错误信号来处理无效配置。无效情况包括重复的模板节点以及 $p$ 超出范围 $0 \\leq p \\leq n-1$。\n\n测试套件规范：\n在您的程序中实现以下测试用例，并根据最终输出格式要求汇总结果。\n\n1.  $p = 1$ 且节点为 $[-1, 0, 1]$（此处 $n = 3$，$h = 1$ 用于生成权重）的中心一阶导数权重。计算权重并将其与期望的精确有理数值 $\\left[-\\frac{1}{2}, 0, \\frac{1}{2}\\right]$ 进行比较。以浮点数形式报告最大绝对差。\n\n2.  $p = 2$ 且节点为 $[-1, 0, 1]$（$h = 1$ 用于生成权重）的中心二阶导数权重。计算权重并将其与期望的精确有理数值 $[1, -2, 1]$ 进行比较。以浮点数形式报告最大绝对差。\n\n3.  $p = 5$ 且节点为 $[0, 1, 2, 3, 4, 5]$（$h = 1$ 用于生成权重）的前向五阶导数权重。将计算出的权重与期望的精确整数序列 $[-1, 5, -10, 10, -5, 1]$ 进行比较。报告一个表示是否完全相等的布尔值。\n\n4.  使用前向五阶导数权重对光滑函数进行数值近似的精度。使用测试用例3中的权重，设 $x = 0$，$h = 10^{-3}$，以及 $f(x) = e^x$。计算对 $f^{(5)}(0)$ 的近似的绝对误差，对于 $f(x) = e^x$，该值等于 $1$。以浮点数形式报告绝对误差。\n\n5.  非均匀模板上的多项式精确性。设 $p = 2$，节点为 $[-2, -1, 0, 1, 3, 4]$（六个不同的整数节点），$x = 0$，以及 $h = 0.1$。使用生成的权重来近似 $f(x) = x^2$ 在 $x = 0$ 处的二阶导数。因为该格式被构造成对次数最高为 $n-1$ 的多项式是精确的，所以结果应恰好为 $f^{(2)}(0) = 2$。报告一个布尔值，表示与 $2$ 的绝对差是否小于 $10^{-12}$。\n\n6.  无效的导数阶数。尝试用节点 $[0, 1]$ 和 $p = 3$ 生成权重。由于 $p \\geq n$ 是无效的，该例程必须发出错误信号。报告一个布尔值，表示错误是否被正确检测到。\n\n7.  重复节点（奇异系统）。尝试用节点 $[0, 0, 1]$ 和 $p = 1$ 生成权重。由于重复节点会导致奇异矩阵，该例程必须发出错误信号。报告一个布尔值，表示错误是否被正确检测到。\n\n最终输出格式要求：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的结果按与上述测试套件相对应的顺序排列：\n1.  测试用例1的浮点数最大绝对差。\n2.  测试用例2的浮点数最大绝对差。\n3.  测试用例3的布尔结果。\n4.  测试用例4的浮点数绝对误差。\n5.  测试用例5的布尔结果。\n6.  测试用例6的布尔结果。\n7.  测试用例7的布尔结果。\n\n例如，输出应如下所示：\n\"[r1,r2,r3,r4,r5,r6,r7]\".", "solution": "目标是确定一个有限差分公式的权重 $w_0, w_1, \\dots, w_{n-1}$，该公式用于近似一个足够光滑的函数 $f(x)$ 在点 $x$ 处的 $p$ 阶导数。该公式由下式给出：\n$$\nf^{(p)}(x) \\approx \\frac{1}{h^p} \\sum_{j=0}^{n-1} w_j f(x + h s_j)\n$$\n其中 $\\{s_j\\}_{j=0}^{n-1}$ 是一个由 $n$ 个不同的无量纲节点组成的模板，$h$ 是步长。推导权重的方法是要求该公式对所有次数最高为 $n-1$ 的多项式都精确成立。\n\n我们从 $f(x + \\Delta x)$ 在点 $x$ 处的泰勒级数展开式开始：\n$$\nf(x + \\Delta x) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(x)}{k!} (\\Delta x)^k\n$$\n将模板中的每个节点代入 $\\Delta x = h s_j$，我们得到：\n$$\nf(x + h s_j) = \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(x)}{k!} (h s_j)^k\n$$\n现在，我们将此展开式代入有限差分公式的求和部分：\n$$\n\\sum_{j=0}^{n-1} w_j f(x + h s_j) = \\sum_{j=0}^{n-1} w_j \\left( \\sum_{k=0}^{\\infty} \\frac{f^{(k)}(x)}{k!} (h s_j)^k \\right)\n$$\n假设一致收敛允许交换求和顺序：\n$$\n\\sum_{j=0}^{n-1} w_j f(x + h s_j) = \\sum_{k=0}^{\\infty} \\frac{h^k f^{(k)}(x)}{k!} \\left( \\sum_{j=0}^{n-1} w_j s_j^k \\right)\n$$\n完整的有限差分公式旨在近似 $f^{(p)}(x)$，这意味着上述方程的右侧在除以 $h^p$ 后应化简为 $f^{(p)}(x)$。这意味着我们期望：\n$$\n\\frac{1}{h^p} \\sum_{k=0}^{\\infty} \\frac{h^k f^{(k)}(x)}{k!} \\left( \\sum_{j=0}^{n-1} w_j s_j^k \\right) = f^{(p)}(x)\n$$\n为了使此等式对任意函数 $f(x)$（或更具体地说，对其泰勒级数表示）成立，左侧每个导数项 $f^{(k)}(x)$ 的系数必须与右侧相应的项匹配。右侧仅包含 $f^{(p)}(x)$ 项。因此，对于 $k \\neq p$，$f^{(k)}(x)$ 的系数必须为零，而 $f^{(p)}(x)$ 的系数必须为 $1$。这给了我们关于内部和（矩）的以下条件：\n- 对于 $k = p$：$f^{(p)}(x)$ 的系数是 $\\frac{1}{h^p} \\frac{h^p}{p!} \\left( \\sum_{j=0}^{n-1} w_j s_j^p \\right)$。我们将其设为等于 $1$。\n$$\n\\frac{1}{p!} \\left( \\sum_{j=0}^{n-1} w_j s_j^p \\right) = 1 \\implies \\sum_{j=0}^{n-1} w_j s_j^p = p!\n$$\n- 对于 $k \\neq p$：$f^{(k)}(x)$ 的系数是 $\\frac{1}{h^p} \\frac{h^k}{k!} \\left( \\sum_{j=0}^{n-1} w_j s_j^k \\right)$。我们将其设为等于 $0$。\n$$\n\\frac{h^k}{h^p k!} \\left( \\sum_{j=0}^{n-1} w_j s_j^k \\right) = 0 \\implies \\sum_{j=0}^{n-1} w_j s_j^k = 0\n$$\n对 $k = 0, 1, \\dots, n-1$ 施加这些条件。这就为 $n$ 个未知权重 $w_0, w_1, \\dots, w_{n-1}$ 提供了一个包含 $n$ 个线性方程的系统。该系统可以写成矩阵形式 $\\mathbf{A} \\mathbf{w} = \\mathbf{b}$，其中：\n$$\n\\mathbf{A} =\n\\begin{pmatrix}\ns_0^0  s_1^0  \\dots  s_{n-1}^0 \\\\\ns_0^1  s_1^1  \\dots  s_{n-1}^1 \\\\\n\\vdots  \\vdots  \\ddots  \\vdots \\\\\ns_0^{n-1}  s_1^{n-1}  \\dots  s_{n-1}^{n-1}\n\\end{pmatrix}\n, \\quad\n\\mathbf{w} =\n\\begin{pmatrix}\nw_0 \\\\\nw_1 \\\\\n\\vdots \\\\\nw_{n-1}\n\\end{pmatrix}\n, \\quad\n\\mathbf{b} =\n\\begin{pmatrix}\n0 \\\\\n\\vdots \\\\\np! \\\\\n\\vdots \\\\\n0\n\\end{pmatrix}\n$$\n矩阵 $\\mathbf{A}$ 是一个范德蒙矩阵。其行列式非零的充要条件是所有节点 $s_j$ 互不相同。问题陈述保证了对于有效输入，此条件成立，从而确保了权重 $\\mathbf{w}$ 存在唯一解。向量 $\\mathbf{b}$ 是一个零向量，除了索引为 $p$ 的项（第 $(p+1)$ 行）为 $p!$ 外。\n\n问题指出输入的模板节点是整数。为获得精确权重，必须使用有理数算术来求解该线性系统。这包括用有理数构造矩阵 $\\mathbf{A}$ 和向量 $\\mathbf{b}$，并使用像高斯消元法这样在有理数域上运算的算法。Python 的 `fractions` 模块为此提供了必要的工具。\n\n实现将包括一个主例程，该例程验证输入、构造线性系统并求解。\n输入验证必须确保两个条件：\n1. 所有模板节点 $s_j$ 必须互不相同。如果 `len(set(s))` 不等于 `len(s)`，范德蒙矩阵 $\\mathbf{A}$ 是奇异的，唯一解不存在。\n2. 导数的阶数 $p$ 必须在范围 $0 \\le p  n$ 内，其中 $n$ 是模板点的数量。这是因为 $n$ 个点可以唯一确定一个次数最高为 $n-1$ 的多项式，而这 $n$ 个约束条件被用来确定 $n$ 个权重。对于导数阶数 $p \\geq n$，不可能满足矩条件。\n\n对于有效输入，步骤如下：\n1. 定义 $n$ 为模板 $s$ 中的节点数。\n2. 构造 $n \\times n$ 矩阵 $\\mathbf{A}$，其中 $A_{kj} = s_j^k$，对于 $k, j \\in \\{0, \\dots, n-1\\}$。每个元素都表示为一个有理数。\n3. 构造 $n \\times 1$ 向量 $\\mathbf{b}$，其中对于 $k \\neq p$，$b_k = 0$ 且 $b_p = p!$。每个元素也都是一个有理数。\n4. 使用基于有理数算术的线性求解器（如带回代的高斯消元法）求解线性系统 $\\mathbf{A} \\mathbf{w} = \\mathbf{b}$，以得到 $\\mathbf{w}$。\n得到的向量 $\\mathbf{w}$ 将包含指定的有限差分格式的精确有理数权重。然后使用这些权重来执行测试套件所要求的计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom fractions import Fraction\nimport math\n\nclass FiniteDifferenceError(ValueError):\n    \"\"\"Custom exception for finite difference routine errors.\"\"\"\n    pass\n\ndef _solve_rational_system(A, b):\n    \"\"\"\n    Solves a linear system Ax=b where A and b contain Fraction objects.\n    Uses Gaussian elimination with back substitution.\n    \"\"\"\n    n = len(b)\n    # Create an augmented matrix\n    M = [row + [val] for row, val in zip(A, b)]\n\n    # Forward elimination\n    for i in range(n):\n        # Find a non-zero pivot\n        pivot_row = i\n        while pivot_row  n and M[pivot_row][i] == Fraction(0):\n            pivot_row += 1\n        \n        if pivot_row == n:\n            # This case is pre-empted by the duplicate node check,\n            # but is included for solver robustness.\n            raise np.linalg.LinAlgError(\"Singular matrix\")\n\n        # Swap the current row with the pivot row\n        M[i], M[pivot_row] = M[pivot_row], M[i]\n        \n        # Eliminate entries below the pivot\n        pivot_val = M[i][i]\n        for j in range(i + 1, n):\n            factor = M[j][i] / pivot_val\n            # M[j][i] = Fraction(0) # Not strictly necessary\n            for k in range(i + 1, n + 1):\n                M[j][k] -= factor * M[i][k]\n\n    # Backward substitution\n    x = [Fraction(0)] * n\n    for i in range(n - 1, -1, -1):\n        s = sum(M[i][j] * x[j] for j in range(i + 1, n))\n        x[i] = (M[i][n] - s) / M[i][i]\n        \n    return x\n\ndef generate_weights(s, p):\n    \"\"\"\n    Generates finite difference weights for a given stencil and derivative order.\n    \n    Args:\n        s (list or tuple of int): The stencil nodes.\n        p (int): The order of the derivative.\n        \n    Returns:\n        list of Fraction: The calculated weights.\n    \n    Raises:\n        FiniteDifferenceError: If inputs are invalid.\n    \"\"\"\n    n = len(s)\n    \n    # Input validation\n    if len(set(s)) != n:\n        raise FiniteDifferenceError(\"Stencil nodes must be distinct.\")\n    if not (0 = p  n):\n        raise FiniteDifferenceError(f\"Derivative order p must be in [0, n-1]. Got p={p}, n={n}.\")\n\n    # Construct the Vandermonde matrix A\n    A = []\n    for k in range(n):\n        A.append([Fraction(node)**k for node in s])\n\n    # Construct the right-hand side vector b\n    b = [Fraction(0)] * n\n    b[p] = Fraction(math.factorial(p))\n    \n    # The system is A_transpose * w = b. Solve A.T w = b, which is w.T A = b.T\n    # This means we solve A^T x = b for x, where A is the matrix from the loop above.\n    # The matrix in the problem is A_kj = s_j^k. The system is sum_j A_kj w_j = b_k.\n    # So A is the coefficient matrix directly.\n    return _solve_rational_system(A, b)\n\ndef solve():\n    \"\"\"\n    Runs the test suite and prints the final results.\n    \"\"\"\n    results = []\n\n    # Test Case 1: Central first derivative\n    p1 = 1\n    s1 = [-1, 0, 1]\n    expected_w1 = [Fraction(-1, 2), Fraction(0), Fraction(1, 2)]\n    computed_w1 = generate_weights(s1, p1)\n    diff1 = max(abs(float(c) - float(e)) for c, e in zip(computed_w1, expected_w1))\n    results.append(diff1)\n\n    # Test Case 2: Central second derivative\n    p2 = 2\n    s2 = [-1, 0, 1]\n    expected_w2 = [Fraction(1), Fraction(-2), Fraction(1)]\n    computed_w2 = generate_weights(s2, p2)\n    diff2 = max(abs(float(c) - float(e)) for c, e in zip(computed_w2, expected_w2))\n    results.append(diff2)\n\n    # Test Case 3: Forward fifth derivative\n    p3 = 5\n    s3 = [0, 1, 2, 3, 4, 5]\n    expected_w3 = [Fraction(v) for v in [-1, 5, -10, 10, -5, 1]]\n    computed_w3 = generate_weights(s3, p3)\n    exact_match3 = (computed_w3 == expected_w3)\n    results.append(exact_match3)\n\n    # Test Case 4: Numerical accuracy\n    p4 = 5\n    s4 = [0, 1, 2, 3, 4, 5]\n    h4 = 1e-3\n    x4 = 0.0\n    weights4 = generate_weights(s4, p4)\n    # f(x) = e^x, f^(5)(x) = e^x, f^(5)(0) = 1\n    approx4 = sum(float(w) * np.exp(x4 + h4 * node) for w, node in zip(weights4, s4)) / (h4**p4)\n    exact4 = 1.0\n    error4 = abs(approx4 - exact4)\n    results.append(error4)\n\n    # Test Case 5: Polynomial exactness on nonuniform stencil\n    p5 = 2\n    s5 = [-2, -1, 0, 1, 3, 4]\n    h5 = 0.1\n    x5 = 0.0\n    weights5 = generate_weights(s5, p5)\n    # f(x) = x^2, f''(x) = 2, f''(0) = 2\n    # The formula should be exact for polynomials of degree  n=6\n    f_vals5 = [(x5 + h5 * node)**2 for node in s5]\n    approx5 = sum(float(w) * fv for w, fv in zip(weights5, f_vals5)) / (h5**p5)\n    exact5 = 2.0\n    poly_exact5 = abs(approx5 - exact5)  1e-12\n    results.append(poly_exact5)\n\n    # Test Case 6: Invalid derivative order\n    error_detected6 = False\n    try:\n        generate_weights(s=[0, 1], p=3)\n    except FiniteDifferenceError:\n        error_detected6 = True\n    results.append(error_detected6)\n\n    # Test Case 7: Duplicate nodes\n    error_detected7 = False\n    try:\n        generate_weights(s=[0, 0, 1], p=1)\n    except FiniteDifferenceError:\n        error_detected7 = True\n    results.append(error_detected7)\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3238803"}, {"introduction": "在学习了如何生成差分格式后，合乎逻辑的下一步是在实践中验证它们的性能。这项练习通过让您实现几个常见的差分格式，将它们应用于一个具有已知解析导数的函数，并凭经验测量它们的收敛速度，从而弥合了理论与应用之间的差距。这种数值验证过程是计算科学的基石，确保了我们使用的工具能够如预期般工作 [@problem_id:3238903]。", "problem": "考虑函数 $f(x) = \\exp(-x^2)$。您的任务是使用中心有限差分模板来近似其高阶导数，从第一性原理推导截断误差阶，并与解析导数进行对比，以验证观测到的收敛率。\n\n您必须基于以下基础进行操作：\n- 使用 $f(x \\pm kh)$ 在点 $x = x_0$（其中 $k \\in \\mathbb{Z}$ 且 $h  0$ 是一个小数）的泰勒级数展开，来构造相容的中心有限差分导数近似。具体来说，使用泰勒展开式\n$$\nf(x_0 \\pm kh) = \\sum_{n=0}^{\\infty} \\frac{(\\pm kh)^n}{n!} f^{(n)}(x_0).\n$$\n- 使用截断误差阶的定义：如果对某个量 $Q$ 的近似 $A_h$ 满足 $A_h = Q + C h^p + \\mathcal{O}(h^{p+1})$，其中常数 $C \\neq 0$，则我们称该近似为 $p$ 阶。\n- 使用对于误差 $E(h_1)$ 和 $E(h_2)$ 在两个步长 $h_1$ 和 $h_2$ 之间的观测阶定义为\n$$\np_{\\mathrm{obs}} = \\frac{\\log\\big(E(h_1)/E(h_2)\\big)}{\\log(h_1/h_2)}.\n$$\n\n任务：\n1. 通过直接求导，推导 $f(x) = \\exp(-x^2)$ 的解析二阶和四阶导数 $f^{(2)}(x)$ 和 $f^{(4)}(x)$ 的符号表达式。\n2. 使用泰勒级数，推导以下各项的中心有限差分模板及其主截断误差：\n   - $f^{(2)}(x_0)$ 的标准中心 $3$ 点近似，\n   - 比 $3$ 点模板精度更高的 $f^{(2)}(x_0)$ 的中心 $5$ 点近似，\n   - $f^{(4)}(x_0)$ 的中心 $5$ 点近似。\n   不要假定任何预先知道的系数；通过匹配 $x_0$ 处的泰勒级数项来推导它们。\n3. 实现一个程序，在特定点上评估近似值，并通过计算与任务1中解析导数的误差以及当 $h$ 减半时的误差比率得到的观测阶来验证收敛阶。\n\n测试套件：\n- 使用网格间距序列 $h_k = 0.2 \\cdot 2^{-k}$，其中 $k \\in \\{0,1,2,3,4,5\\}$。\n- 对于下面的每种情况，计算误差 $E(h_k)$，即数值近似与 $x_0$ 处解析导数之间的绝对差值，然后使用连续的对 $(h_{k-1}, h_k)$ 计算观测阶 $p_k$，其中 $k \\in \\{1,2,3,4,5\\}$。\n- 为保证稳健性，将每种情况报告的观测阶定义为最后三个值 $\\{p_3, p_4, p_5\\}$ 的中位数。\n- 验证以下四种情况及其预期阶数和点：\n  - 情况 A：$f^{(2)}(x_0)$ 在 $x_0 = 0.7$ 处的中心 $3$ 点模板，预期阶为 $2$。\n  - 情况 B：$f^{(2)}(x_0)$ 在 $x_0 = 1.3$ 处的中心 $5$ 点模板，预期阶为 $4$。\n  - 情况 C：$f^{(4)}(x_0)$ 在 $x_0 = 0.0$ 处的中心 $5$ 点模板，预期阶为 $2$。\n  - 情况 D（边缘数值情况）：$f^{(2)}(x_0)$ 在 $x_0 = 2.0$ 处的中心 $5$ 点模板，预期阶为 $4$。\n\n每种情况的通过/失败标准：\n- 设 $\\tilde{p}$ 为报告的观测阶（$\\{p_3, p_4, p_5\\}$ 的中位数）。如果 $|\\tilde{p} - p_{\\mathrm{expected}}| \\le 0.3$，则该情况通过，否则失败，其中 $p_{\\mathrm{expected}}$ 是该情况的预期阶。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为 [情况 A, 情况 B, 情况 C, 情况 D]，其中每个条目是该情况的布尔结果，例如，“[True,True,False,True]”。\n- 不需要用户输入，本问题不涉及物理单位或角度单位。所有数值均为无量纲。", "solution": "经评估，该问题在数值分析方面有科学依据，问题陈述清晰，目标明确，没有不一致或模糊之处，因此是有效的。我们接下来给出一个完整的解法。\n\n解法分为三部分，对应问题陈述中概述的任务。首先，我们推导所需导数的解析表达式。其次，我们使用泰勒级数推导有限差分模板及其截断误差。第三，我们概述将在最终代码中实现的数值验证过程。\n\n### 第 1 部分：解析导数\n\n给定函数 $f(x) = \\exp(-x^2)$。我们将通过直接求导来计算其二阶和四阶导数 $f^{(2)}(x)$ 和 $f^{(4)}(x)$。为了在中间步骤中简化表示，我们用撇号表示关于 $x$ 的导数，即 $f'(x)$、$f''(x)$ 等。\n\n一阶导数为：\n$$\nf'(x) = \\frac{d}{dx} \\exp(-x^2) = -2x \\exp(-x^2) = -2x f(x)\n$$\n\n使用乘法法则求二阶导数：\n$$\nf''(x) = \\frac{d}{dx} (-2x f(x)) = -2 f(x) - 2x f'(x)\n$$\n代入 $f'(x) = -2x f(x)$：\n$$\nf''(x) = -2 f(x) - 2x (-2x f(x)) = (-2 + 4x^2) f(x)\n$$\n所以，二阶导数的解析表达式为：\n$$\nf^{(2)}(x) = (4x^2 - 2) \\exp(-x^2)\n$$\n\n为了求四阶导数，我们首先计算三阶导数：\n$$\nf'''(x) = \\frac{d}{dx} \\left( (4x^2 - 2) f(x) \\right) = (8x) f(x) + (4x^2 - 2) f'(x)\n$$\n代入 $f'(x) = -2x f(x)$：\n$$\nf'''(x) = 8x f(x) + (4x^2 - 2) (-2x f(x)) = (8x - 8x^3 + 4x) f(x) = (-8x^3 + 12x) f(x)\n$$\n\n最后，通过对 $f'''(x)$ 求导来计算四阶导数：\n$$\nf^{(4)}(x) = \\frac{d}{dx} \\left( (-8x^3 + 12x) f(x) \\right) = (-24x^2 + 12) f(x) + (-8x^3 + 12x) f'(x)\n$$\n代入 $f'(x) = -2x f(x)$：\n$$\nf^{(4)}(x) = (-24x^2 + 12) f(x) + (-8x^3 + 12x) (-2x f(x)) = (-24x^2 + 12 + 16x^4 - 24x^2) f(x)\n$$\n所以，四阶导数的解析表达式为：\n$$\nf^{(4)}(x) = (16x^4 - 48x^2 + 12) \\exp(-x^2)\n$$\n\n### 第 2 部分：有限差分模板和截断误差\n\n我们通过构建围绕点 $x_0$ 的泰勒级数展开式的线性组合，来推导中心有限差分公式及其主截断误差项。令 $f_0^{(n)}$ 表示 $f^{(n)}(x_0)$。相关的展开式为：\n$$\nf(x_0 \\pm h) = f_0 \\pm h f_0' + \\frac{h^2}{2} f_0'' + \\frac{\\pm h^3}{6} f_0''' + \\frac{h^4}{24} f_0^{(4)} + \\frac{\\pm h^5}{120} f_0^{(5)} + \\frac{h^6}{720} f_0^{(6)} + \\mathcal{O}(h^7)\n$$\n$$\nf(x_0 \\pm 2h) = f_0 \\pm 2h f_0' + \\frac{(2h)^2}{2} f_0'' + \\frac{\\pm (2h)^3}{6} f_0''' + \\frac{(2h)^4}{24} f_0^{(4)} + \\frac{\\pm (2h)^5}{120} f_0^{(5)} + \\frac{(2h)^6}{720} f_0^{(6)} + \\mathcal{O}(h^7)\n$$\n\n**2a. $f^{(2)}(x_0)$ 的 $3$ 点中心模板**\n我们寻求形式为 $f_0'' \\approx \\frac{c_{-1}f(x_0-h) + c_0 f(x_0) + c_1 f(x_0+h)}{h^2}$ 的近似。对于中心模板，对称性要求 $c_{-1}=c_1$。\n考虑组合 $f(x_0+h) - 2f(x_0) + f(x_0-h)$：\n$$\n(f_0 + h f_0' + \\frac{h^2}{2} f_0'' + \\frac{h^3}{6} f_0''' + \\frac{h^4}{24} f_0^{(4)} + \\mathcal{O}(h^6)) - 2f_0 + (f_0 - h f_0' + \\frac{h^2}{2} f_0'' - \\frac{h^3}{6} f_0''' + \\frac{h^4}{24} f_0^{(4)} + \\mathcal{O}(h^6))\n$$\n合并各项，奇数次幂的导数项相互抵消：\n$$\n= (1-2+1)f_0 + (1-1)h f_0' + (\\frac{1}{2}+\\frac{1}{2})h^2 f_0'' + (\\frac{1}{6}-\\frac{1}{6})h^3 f_0''' + (\\frac{1}{24}+\\frac{1}{24})h^4 f_0^{(4)} + \\mathcal{O}(h^6)\n$$\n$$\n= h^2 f_0'' + \\frac{h^4}{12} f_0^{(4)} + \\mathcal{O}(h^6)\n$$\n两边除以 $h^2$，我们得到近似式：\n$$\n\\frac{f(x_0-h) - 2f(x_0) + f(x_0+h)}{h^2} = f_0'' + \\frac{h^2}{12} f_0^{(4)} + \\mathcal{O}(h^4)\n$$\n模板为 $\\frac{1}{h^2}[f(x_0-h) - 2f(x_0) + f(x_0+h)]$。主截断误差为 $E_T = \\frac{h^2}{12} f_0^{(4)}$，因此该方法是 $p=2$ 阶的。\n\n**2b. $f^{(2)}(x_0)$ 的 $5$ 点中心模板**\n我们寻求形式为 $\\frac{1}{h^2} \\sum_{j=-2}^{2} c_j f(x_0+jh)$ 的更高精度的近似。对称性意味着 $c_{-j}=c_j$。线性组合为 $c_2(f(x_0-2h)+f(x_0+2h)) + c_1(f(x_0-h)+f(x_0+h)) + c_0 f(x_0)$。我们使用求和后的展开式：\n$$\nf(x_0-h) + f(x_0+h) = 2f_0 + h^2 f_0'' + \\frac{h^4}{12} f_0^{(4)} + \\frac{h^6}{360}f_0^{(6)} + \\mathcal{O}(h^8)\n$$\n$$\nf(x_0-2h)+f(x_0+2h) = 2f_0 + 4h^2 f_0'' + \\frac{4h^4}{3} f_0^{(4)} + \\frac{8h^6}{45}f_0^{(6)} + \\mathcal{O}(h^8)\n$$\n我们通过匹配导数项的系数，建立方程组来确定 $c_0, c_1, c_2$：\n$$\n\\text{分子} = (2c_2 + 2c_1 + c_0)f_0 + (4c_2 + c_1)h^2 f_0'' + (\\frac{4}{3}c_2 + \\frac{1}{12}c_1)h^4 f_0^{(4)} + \\dots\n$$\n为了近似 $h^2 f_0''$，我们要求：\n\\begin{enumerate}\n    \\item $f_0$ 的系数：$2c_2 + 2c_1 + c_0 = 0$\n    \\item $f_0''$ 的系数：$4c_2 + c_1 = 1$\n    \\item 为达到更高阶精度，我们消去下一个误差项 ($f_0^{(4)}$)：$\\frac{4}{3}c_2 + \\frac{1}{12}c_1 = 0$\n\\end{enumerate}\n从(3)式得，$16c_2 + c_1 = 0 \\implies c_1 = -16c_2$。\n代入(2)式：$4c_2 + (-16c_2) = 1 \\implies -12c_2 = 1 \\implies c_2 = -1/12$。\n于是 $c_1 = -16(-1/12) = 4/3$。\n从(1)式得：$c_0 = -2c_1 - 2c_2 = -2(4/3) - 2(-1/12) = -8/3 + 1/6 = -16/6 + 1/6 = -15/6 = -5/2$。\n系数为 $c_2=-1/12, c_1=4/3, c_0=-5/2$。模板为：\n$$\n\\frac{-\\frac{1}{12}f(x_0-2h) + \\frac{4}{3}f(x_0-h) - \\frac{5}{2}f(x_0) + \\frac{4}{3}f(x_0+h) - \\frac{1}{12}f(x_0+2h)}{h^2}\n$$\n分子展开式中的下一项涉及 $f_0^{(6)}$：$(\\frac{8}{45}c_2 + \\frac{1}{360}c_1)h^6 f_0^{(6)}$。\n代入数值：$(\\frac{8}{45}(-\\frac{1}{12}) + \\frac{1}{360}(\\frac{4}{3})) h^6 f_0^{(6)} = (-\\frac{2}{135} + \\frac{1}{270})h^6 f_0^{(6)} = -\\frac{3}{270}h^6 f_0^{(6)} = -\\frac{1}{90}h^6 f_0^{(6)}$。\n近似式为 $f_0'' - \\frac{h^4}{90}f_0^{(6)} + \\mathcal{O}(h^6)$。截断误差为 $E_T = -\\frac{h^4}{90}f_0^{(6)}$，因此该方法是 $p=4$ 阶的。\n\n**2c. $f^{(4)}(x_0)$ 的 $5$ 点中心模板**\n我们寻求形式为 $\\frac{1}{h^4} \\sum_{j=-2}^{2} c_j f(x_0+jh)$ 的 $f_0^{(4)}$ 近似。我们使用与 2b 中相同的分子展开式，但以不同方式匹配系数以分离出 $f_0^{(4)}$：\n$$\n\\text{分子} = (2c_2 + 2c_1 + c_0)f_0 + (4c_2 + c_1)h^2 f_0'' + (\\frac{4}{3}c_2 + \\frac{1}{12}c_1)h^4 f_0^{(4)} + \\dots\n$$\n为了近似 $h^4 f_0^{(4)}$，我们要求：\n\\begin{enumerate}\n    \\item $f_0$ 的系数：$2c_2 + 2c_1 + c_0 = 0$\n    \\item $f_0''$ 的系数：$4c_2 + c_1 = 0 \\implies c_1 = -4c_2$\n    \\item $f_0^{(4)}$ 的系数：$\\frac{4}{3}c_2 + \\frac{1}{12}c_1 = 1$\n\\end{enumerate}\n从(2)式，将 $c_1 = -4c_2$ 代入(3)式：$\\frac{4}{3}c_2 + \\frac{1}{12}(-4c_2) = 1 \\implies \\frac{4}{3}c_2 - \\frac{1}{3}c_2 = 1 \\implies c_2 = 1$。\n于是 $c_1 = -4(1) = -4$。\n从(1)式得：$c_0 = -2c_1 - 2c_2 = -2(-4) - 2(1) = 8 - 2 = 6$。\n系数为 $c_2=1, c_1=-4, c_0=6$。模板为：\n$$\n\\frac{f(x_0-2h) - 4f(x_0-h) + 6f(x_0) - 4f(x_0+h) + f(x_0+2h)}{h^4}\n$$\n分子展开式中的下一项涉及 $f_0^{(6)}$：$(\\frac{8}{45}c_2 + \\frac{1}{360}c_1)h^6 f_0^{(6)}$。\n代入数值：$(\\frac{8}{45}(1) + \\frac{1}{360}(-4))h^6 f_0^{(6)} = (\\frac{64}{360} - \\frac{4}{360})h^6 f_0^{(6)} = \\frac{60}{360}h^6 f_0^{(6)} = \\frac{1}{6}h^6 f_0^{(6)}$。\n近似式为 $f_0^{(4)} + \\frac{h^2}{6}f_0^{(6)} + \\mathcal{O}(h^4)$。截断误差为 $E_T = \\frac{h^2}{6}f_0^{(6)}$，因此该方法是 $p=2$ 阶的。\n\n### 第 3 部分：数值验证策略\n\n理论推导将通过计算进行验证。对于指定的四种测试情况中的每一种：\n\\begin{enumerate}\n    \\item 使用步长序列 $h_k = 0.2 \\cdot 2^{-k}$，其中 $k \\in \\{0, 1, 2, 3, 4, 5\\}$。\n    \\item 对于每个 $h_k$，在指定的点 $x_0$ 计算相应的有限差分近似值。\n    \\item 使用第 1 部分中的解析公式计算 $x_0$ 处的导数真值。\n    \\item 绝对误差 $E(h_k)$ 被计算为数值近似与解析值之间的绝对差。\n    \\item 使用连续的误差对，为 $k \\in \\{1, 2, 3, 4, 5\\}$ 计算观测收敛阶 $p_k$：\n    $$\n    p_k = \\frac{\\log(E(h_{k-1})/E(h_k))}{\\log(h_{k-1}/h_k)} = \\frac{\\log(E(h_{k-1})/E(h_k))}{\\log(2)}\n    $$\n    \\item 对于每种情况，报告的观测阶 $\\tilde{p}$ 定义为最后三个计算出的阶 $\\{p_3, p_4, p_5\\}$ 的中位数。这提供了当 $h \\to 0$ 时渐近收敛率的稳定估计。\n    \\item 最后，使用标准 $|\\tilde{p} - p_{\\mathrm{expected}}| \\le 0.3$ 对每种情况的预期理论阶 $p_{\\mathrm{expected}}$ 进行验证。\n\\end{enumerate}\n此过程将被封装到一个 Python 程序中，以生成最终的布尔结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of approximating higher derivatives and verifying convergence orders.\n    \"\"\"\n\n    # Part 1: Analytic Functions\n    def f(x: float) -> float:\n        \"\"\"The base function f(x) = exp(-x^2).\"\"\"\n        return np.exp(-x**2)\n\n    def f_d2(x: float) -> float:\n        \"\"\"The analytic second derivative of f(x).\"\"\"\n        return (4 * x**2 - 2) * np.exp(-x**2)\n\n    def f_d4(x: float) -> float:\n        \"\"\"The analytic fourth derivative of f(x).\"\"\"\n        return (16 * x**4 - 48 * x**2 + 12) * np.exp(-x**2)\n\n    # Part 2: Finite Difference Stencils\n    def approx_d2_3pt(func, x0: float, h: float) -> float:\n        \"\"\"3-point centered difference approximation for the 2nd derivative.\"\"\"\n        return (func(x0 - h) - 2 * func(x0) + func(x0 + h)) / h**2\n\n    def approx_d2_5pt(func, x0: float, h: float) -> float:\n        \"\"\"5-point centered difference approximation for the 2nd derivative (order 4).\"\"\"\n        return (-func(x0 - 2 * h) + 16 * func(x0 - h) - 30 * func(x0) + 16 * func(x0 + h) - func(x0 + 2 * h)) / (12 * h**2)\n\n    def approx_d4_5pt(func, x0: float, h: float) -> float:\n        \"\"\"5-point centered difference approximation for the 4th derivative (order 2).\"\"\"\n        return (func(x0 - 2 * h) - 4 * func(x0 - h) + 6 * func(x0) - 4 * func(x0 + h) + func(x0 + 2 * h)) / h**4\n\n    # Part 3: Numerical Verification\n    h_values = [0.2 * (2**-k) for k in range(6)]\n    \n    # Test cases: (approximation_function, analytic_function, evaluation_point_x0, expected_order)\n    test_cases = [\n        # Case A: 3-point f''(0.7), expected order 2\n        (approx_d2_3pt, f_d2, 0.7, 2),\n        # Case B: 5-point f''(1.3), expected order 4\n        (approx_d2_5pt, f_d2, 1.3, 4),\n        # Case C: 5-point f^(4)(0.0), expected order 2\n        (approx_d4_5pt, f_d4, 0.0, 2),\n        # Case D: 5-point f''(2.0) edge case, expected order 4\n        (approx_d2_5pt, f_d2, 2.0, 4),\n    ]\n\n    final_results = []\n    for approx_func, analytic_func, x0, p_expected in test_cases:\n        errors = []\n        for h in h_values:\n            approx_val = approx_func(f, x0, h)\n            analytic_val = analytic_func(x0)\n            error = np.abs(approx_val - analytic_val)\n            errors.append(error)\n\n        observed_orders = []\n        # Calculate observed orders p_k for k in {1,2,3,4,5}\n        for k in range(1, len(h_values)):\n            # Ratio of step sizes is 2\n            h_ratio = h_values[k-1] / h_values[k]\n            \n            # Avoid division by zero if error becomes numerically zero\n            if errors[k] > 0 and errors[k-1] > 0:\n                error_ratio = errors[k-1] / errors[k]\n                order = np.log(error_ratio) / np.log(h_ratio)\n                observed_orders.append(order)\n            else:\n                # If error is zero, convergence is perfect/infinite.\n                # This case isn't expected to be hit, but we handle it.\n                observed_orders.append(np.inf)\n\n        # Per problem, use median of last three observed orders {p_3, p_4, p_5}\n        # These correspond to indices 2, 3, 4 of observed_orders list\n        # which has 5 elements (p_1 to p_5).\n        if len(observed_orders) >= 5:\n            last_three_orders = observed_orders[2:5]\n            reported_order = np.median(last_three_orders)\n            \n            # Apply pass-fail criterion\n            passed = np.abs(reported_order - p_expected) = 0.3\n            final_results.append(passed)\n        else:\n            # This path should not be taken given the problem setup\n            final_results.append(False)\n\n    # Format the final output as specified\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3238903"}, {"introduction": "一旦我们能够构建和验证近似，就可以探索改进它们的方法。这项实践将介绍 Richardson 外推法，这是一种通过组合不同步长的结果来加速收敛的强大技术。更重要的是，它通过一个精心设计的实验表明，这种先进方法的成功取决于对近似误差结构的正确理解——这是在审慎应用数值算法时的一个关键教训 [@problem_id:3238865]。", "problem": "考虑一个光滑标量函数 $f:\\mathbb{R}\\to\\mathbb{R}$，其具有至少到 $5$ 阶的连续导数。目标是设计并实现一个数值实验，以展示 Richardson 外推法在应用于二阶导数 $f''(x)$ 时，对于两种不同的有限差分格式的表现。从基本原理开始：函数 $f$ 在点 $x$ 附近的泰勒级数展开表明，对于任何足够小的步长 $h$，存在一些包含 $f$ 的导数的系数，使得离散模板组合能够逼近 $f''(x)$，其主截断误差可以表示为 $h$ 的幂次。该原理是 Richardson 外推法所使用的渐近误差模型分析的基础。\n\n在所有涉及三角函数的计算中，请使用弧度制角度。\n\n你的任务是编写一个程序，对下面列出的每个测试用例执行以下步骤。\n\n1. 使用定义在点 $x-h$、$x$ 和 $x+h$ 上的对称中心差分模板实现二阶导数的近似。已知对于光滑函数 $f$，该模板的主截断误差是 $h$ 的偶数次幂。\n\n2. 使用定义在点 $x$、$x+h$ 和 $x+2h$ 上的前向差分模板实现二阶导数的近似。已知对于光滑函数 $f$，该模板的主截断误差是 $h$ 的奇数次幂。\n\n3. 对于这两种模板，使用步长为 $h$ 和 $h/2$ 时的值构造一个两级 Richardson 外推，假设主误差项按 $h^p$（其中 $p=2$）的比例缩放，这是由中心差分模板的对称性所决定的。将这个相同的 $p=2$ 假设未经修改地应用于前向差分模板。使用此假设计算外推估计值。\n\n4. 对于每个模板及其对应的外推估计值，对一个几何序列的步长 $\\{h,\\,h/2,\\,h/4,\\,\\dots\\}$，测量其绝对误差 $|A(h)-f''(x)|$，并通过对 $(\\log h, \\log\\text{误差})$ 数据点对进行直线拟合来计算经验收敛阶。经验收敛阶是最佳拟合直线的斜率，它量化了误差随 $h$ 变化的比例关系。\n\n5. 对于每个测试用例，报告四个浮点数，保留两位小数：基本中心差分估计的经验阶、其外推估计的经验阶、基本前向差分估计的经验阶、以及在 $p=2$ 的朴素假设下构造的其外推估计的经验阶。该数值实验应表明，Richardson 外推法显著改善了中心差分（提高了阶数），但当使用相同的、未经修改的 $p=2$ 假设时，未能对前向差分产生同样的改善效果。\n\n测试套件：\n- 用例 1：$f(x)=e^x$， $x_0=0.3$，初始步长 $h_0=0.2$，细化层级 $5$。\n- 用例 2：$f(x)=\\sin(x)$（角度为弧度制），$x_0=1.0$，初始步长 $h_0=0.3$，细化层级 $5$。\n- 用例 3：$f(x)=x^7-3x^3+2$， $x_0=0.1$，初始步长 $h_0=0.2$，细化层级 $5$。\n\n对于每个用例，构造步长的几何序列 $\\{h_k\\}_{k=0}^{L-1}$，其中 $h_k=h_0/2^k$ 且 $L=5$。对于外推估计，将每个 $h_k$ 与 $h_{k+1}=h_k/2$ 配对；使用所有可用的数据对报告收敛阶。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含所有结果，形式为一个用方括号括起来的逗号分隔列表。该列表必须按用例逐个排序，并且在每个用例内部，按以下顺序排列：中心差分基本阶、中心差分外推阶、前向差分基本阶、前向差分外推阶。例如，输出格式必须为 $[o_{1,\\text{c-base}},o_{1,\\text{c-extrap}},o_{1,\\text{f-base}},o_{1,\\text{f-extrap}},o_{2,\\text{c-base}},\\dots,o_{3,\\text{f-extrap}}]$，其中每个 $o$ 是一个保留两位小数的浮点数。", "solution": "该问题陈述是数值分析领域一个有效练习。它具有科学依据，问题定义明确且客观。它要求实现并分析一个涉及有限差分近似和 Richardson 外推法的标准数值实验。所有必需的参数，包括函数、求值点和数值参数（$h_0, L$），都已明确给出。预期的结果——即假设误差阶 $p=2$ 的 Richardson 外推法能改善中心差分格式，但无法改善前向差分格式——与已建立的数值方法理论是一致的。\n\n该问题的理论基础是足够光滑的函数 $f(x)$ 在点 $x$ 附近的泰勒级数展开。对于步长 $h$，我们有：\n$$f(x \\pm h) = f(x) \\pm hf'(x) + \\frac{h^2}{2!}f''(x) \\pm \\frac{h^3}{3!}f'''(x) + \\frac{h^4}{4!}f^{(4)}(x) \\pm \\dots$$\n\n**1. 有限差分格式**\n\n通过组合这些针对不同模板点的展开式，我们可以推导出二阶导数 $f''(x)$ 的近似值。\n\n**中心差分模板：**\n使用 $f(x+h)$ 和 $f(x-h)$ 的展开式：\n$$f(x+h) + f(x-h) = 2f(x) + h^2f''(x) + \\frac{h^4}{12}f^{(4)}(x) + O(h^6)$$\n求解 $f''(x)$ 可得：\n$$f''(x) = \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2} - \\frac{h^2}{12}f^{(4)}(x) - O(h^4)$$\n因此，中心差分近似 $D_C(h)$ 为：\n$$D_C(h) = \\frac{f(x+h) - 2f(x) + f(x-h)}{h^2}$$\n误差 $E_C(h) = D_C(h) - f''(x)$ 具有一个以 $h$ 的偶数次幂表示的渐近展开式：\n$$E_C(h) = C_2h^2 + C_4h^4 + C_6h^6 + \\dots$$\n其中 $C_2 = -\\frac{1}{12}f^{(4)}(x)$。主误差项为 $O(h^2)$，因此该方法是二阶精度的。\n\n**前向差分模板：**\n使用 $f(x+h)$ 和 $f(x+2h)$ 的展开式：\n$$f(x+h) = f(x) + hf'(x) + \\frac{h^2}{2}f''(x) + \\frac{h^3}{6}f'''(x) + O(h^4)$$\n$$f(x+2h) = f(x) + 2hf'(x) + 2h^2f''(x) + \\frac{4h^3}{3}f'''(x) + O(h^4)$$\n为了近似 $f''(x)$，我们可以构造线性组合 $f(x+2h) - 2f(x+h) + f(x)$，得到：\n$$f(x+2h) - 2f(x+h) + f(x) = h^2f''(x) + h^3f'''(x) + O(h^4)$$\n求解 $f''(x)$ 可得：\n$$f''(x) = \\frac{f(x+2h) - 2f(x+h) + f(x)}{h^2} - hf'''(x) - O(h^2)$$\n前向差分近似 $D_F(h)$ 为：\n$$D_F(h) = \\frac{f(x+2h) - 2f(x+h) + f(x)}{h^2}$$\n误差 $E_F(h) = D_F(h) - f''(x)$ 具有一个以 $h$ 的所有次幂表示的渐近展开式：\n$$E_F(h) = C_1h + C_2h^2 + C_3h^3 \\dots$$\n其中 $C_1 = f'''(x)$。主误差项为 $O(h)$，因此该方法是一阶精度的。\n\n**2. Richardson 外推法**\n\n设 $A(h)$ 是对真值 $A_{true}$ 的一个近似，其主误差项的阶为 $p$，即 $A(h) = A_{true} + Ch^p + O(h^q)$，其中 $qp$。我们可以通过组合在两个不同步长 $h$ 和 $h/2$ 下的近似值来计算一个更精确的估计：\n$$A_{true} \\approx A(h) - Ch^p$$\n$$A_{true} \\approx A(h/2) - C(h/2)^p$$\n消去未知常数 $C$ 即可得到外推值 $A_{extrap}$：\n$$A_{extrap} = \\frac{2^p A(h/2) - A(h)}{2^p-1}$$\n问题指定对两种格式都使用假设的阶数 $p=2$。公式为：\n$$A_{extrap}(h) = \\frac{4A(h/2) - A(h)}{3}$$\n\n- **应用于中心差分**：误差结构为 $E_C(h) = C_2h^2 + C_4h^4 + \\dots$。使用 $p=2$ 的外推公式与主误差项正确匹配。$O(h^2)$ 项被消除，新的主误差项变为 $O(h^4)$。精度阶预计会从 $2$ 提高到 $4$。\n\n- **应用于前向差分**：误差结构为 $E_F(h) = C_1h + C_2h^2 + \\dots$。使用不正确的假设 $p=2$ 应用外推公式：\n$$D_{F,extrap}(h) = \\frac{4 D_F(h/2) - D_F(h)}{3} = \\frac{4(f''(x) + C_1\\frac{h}{2} + \\dots) - (f''(x) + C_1h + \\dots)}{3}$$\n$$D_{F,extrap}(h) = \\frac{3f''(x) + (2C_1h - C_1h) + \\dots}{3} = f''(x) + \\frac{C_1}{3}h + \\dots$$\n$O(h)$ 项没有被消除。该方法仍然是一阶精度，外推未能提高其阶数。\n\n**3. 经验收敛阶**\n\n如果一个近似的误差 $E(h)$ 在 $h$ 很小时表现为 $E(h) \\approx Kh^p$，我们可以通过经验方法确定其阶数 $p$。对两边取对数可得：\n$$\\log|E(h)| \\approx \\log|K| + p \\log h$$\n这表明 $\\log|E(h)|$ 和 $\\log h$ 之间存在线性关系。这条直线的斜率就是精度阶 $p$。我们通过对点集 $\\{(\\log h_k, \\log|E(h_k)|)\\}_{k=0}^{L-1}$ 进行线性回归（最小二乘拟合）来计算该斜率。\n\n程序将为每个测试用例执行以下步骤：\n1. 定义函数 $f$ 及其精确的二阶导数 $f''$。\n2. 生成一个包含 $L=5$ 个步长的几何序列 $h_k = h_0/2^k$。\n3. 对于每个 $h_k$，计算基本近似值 $D_C(h_k)$ 和 $D_F(h_k)$ 及其绝对误差。\n4. 使用数据对 $(h_k, h_{k+1})$ 计算两种格式的外推值及其相应的绝对误差。这将为每个外推序列生成 $L-1=4$ 个数据点。\n5. 对于四组误差数据（中心差分基本值、中心差分外推值、前向差分基本值、前向差分外推值），通过求解对数-对数误差数据的最佳拟合直线斜率来计算经验收敛阶。\n6. 按照规定，为每个测试用例收集并格式化四个得出的收敛阶。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the numerical experiment problem for Richardson extrapolation.\n    \"\"\"\n\n    def linear_regression_slope(x_data, y_data):\n        \"\"\"\n        Calculates the slope of the best-fit line for (x, y) data.\n        This is equivalent to fitting y = m*x + c.\n        \"\"\"\n        # np.polyfit is a robust way to perform linear regression.\n        # It fits a polynomial of degree 1 and returns [slope, intercept].\n        slope, _ = np.polyfit(x_data, y_data, 1)\n        return slope\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"f\": lambda x: np.exp(x),\n            \"f_pp\": lambda x: np.exp(x), # f''(x)\n            \"x0\": 0.3,\n            \"h0\": 0.2,\n            \"L\": 5,\n        },\n        {\n            \"f\": lambda x: np.sin(x),\n            \"f_pp\": lambda x: -np.sin(x), # f''(x)\n            \"x0\": 1.0,\n            \"h0\": 0.3,\n            \"L\": 5,\n        },\n        {\n            \"f\": lambda x: x**7 - 3 * x**3 + 2,\n            \"f_pp\": lambda x: 42 * x**5 - 18 * x, # f''(x)\n            \"x0\": 0.1,\n            \"h0\": 0.2,\n            \"L\": 5,\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        f = case[\"f\"]\n        f_pp = case[\"f_pp\"]\n        x0 = case[\"x0\"]\n        h0 = case[\"h0\"]\n        L = case[\"L\"]\n\n        # Generate geometric sequence of step sizes\n        h_values = np.array([h0 / (2**k) for k in range(L)])\n        true_val = f_pp(x0)\n\n        # --- Central Difference Calculations ---\n        \n        # Base approximation\n        dc_base_vals = (f(x0 + h_values) - 2 * f(x0) + f(x0 - h_values)) / h_values**2\n        errors_c_base = np.abs(dc_base_vals - true_val)\n        order_c_base = linear_regression_slope(np.log(h_values), np.log(errors_c_base))\n\n        # Extrapolated approximation\n        # Uses L-1 pairs of (h, h/2), corresponding to h_k and h_{k+1}\n        h_extrap = h_values[:-1] # The larger step size in each pair\n        dc_base_h = dc_base_vals[:-1] # A(h)\n        dc_base_h_half = dc_base_vals[1:] # A(h/2)\n        \n        # Richardson formula for p=2: (4*A(h/2) - A(h))/3\n        dc_extrap_vals = (4 * dc_base_h_half - dc_base_h) / 3\n        errors_c_extrap = np.abs(dc_extrap_vals - true_val)\n        order_c_extrap = linear_regression_slope(np.log(h_extrap), np.log(errors_c_extrap))\n\n        # --- Forward Difference Calculations ---\n\n        # Base approximation\n        df_base_vals = (f(x0 + 2 * h_values) - 2 * f(x0 + h_values) + f(x0)) / h_values**2\n        errors_f_base = np.abs(df_base_vals - true_val)\n        order_f_base = linear_regression_slope(np.log(h_values), np.log(errors_f_base))\n        \n        # Extrapolated approximation (naively using p=2)\n        df_base_h = df_base_vals[:-1] # A(h)\n        df_base_h_half = df_base_vals[1:] # A(h/2)\n        \n        df_extrap_vals = (4 * df_base_h_half - df_base_h) / 3\n        errors_f_extrap = np.abs(df_extrap_vals - true_val)\n        order_f_extrap = linear_regression_slope(np.log(h_extrap), np.log(errors_f_extrap))\n\n        # Append results for the current case, rounded to two decimal places\n        all_results.extend([\n            order_c_base,\n            order_c_extrap,\n            order_f_base,\n            order_f_extrap\n        ])\n\n    # Format the final output string\n    formatted_results = [f\"{x:.2f}\" for x in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3238865"}]}