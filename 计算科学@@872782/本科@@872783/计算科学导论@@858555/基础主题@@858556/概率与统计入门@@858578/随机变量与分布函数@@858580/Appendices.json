{"hands_on_practices": [{"introduction": "在概率论中，一项基本技能是推导一个随机变量的函数的分布。当物理量或信号通过某种转换过程被观测时，这项技能就显得至关重要。这个练习 [@problem_id:1416753] 将通过一个非线性变换 $Y = X^2$ 来探讨这一概念，这在科学和工程领域中很常见，例如能量或信号功率与另一变量的平方成正比。要成功解决这个问题，你需要仔细运用累积分布函数（CDF）的定义。", "problem": "设 $X$ 是一个连续随机变量，其累积分布函数 (CDF) $F_X(x)$ 由以下分段表达式给出：\n$$\nF_X(x) =\n\\begin{cases}\n0  \\text{当 } x \\le -1 \\\\\n\\frac{1}{2}(x+1)^2  \\text{当 } -1  x \\le 0 \\\\\n1 - \\frac{1}{2}(1-x)^2  \\text{当 } 0  x \\le 1 \\\\\n1  \\text{当 } x > 1\n\\end{cases}\n$$\n一个新的随机变量 $Y$ 由变换 $Y = X^2$ 定义。求随机变量 $Y$ 的累积分布函数 $F_Y(y)$。答案应以 $F_Y(y)$ 的单个闭式解析表达式的形式给出，该表达式可以是分段定义的。", "solution": "给定一个连续随机变量 $X$，其支撑集为 $[-1,1]$，累积分布函数为\n$$\nF_{X}(x)=\n\\begin{cases}\n0  \\text{当 } x \\le -1 \\\\\n\\frac{1}{2}(x+1)^{2}  \\text{当 } -1  x \\le 0 \\\\\n1 - \\frac{1}{2}(1-x)^{2}  \\text{当 } 0  x \\le 1 \\\\\n1  \\text{当 } x > 1\n\\end{cases}\n$$\n定义 $Y=X^{2}$。由于 $X$ 的支撑集是 $[-1,1]$，所以 $Y$ 的支撑集是 $[0,1]$。对于任意 $y \\in \\mathbb{R}$，$Y$ 的累积分布函数为\n$$\nF_{Y}(y)=\\mathbb{P}(Y \\le y)=\\mathbb{P}(X^{2} \\le y).\n$$\n如果 $y  0$，那么事件 $X^{2} \\le y$ 不可能发生，因此\n$$\nF_{Y}(y)=0 \\quad \\text{当 } y  0.\n$$\n如果 $y \\ge 1$，那么由于 $X \\in [-1,1]$，$X^{2} \\le y$ 必然成立，因此\n$$\nF_{Y}(y)=1 \\quad \\text{当 } y \\ge 1.\n$$\n对于 $0 \\le y  1$，我们有 $\\mathbb{P}(X^2 \\le y) = \\mathbb{P}(-\\sqrt{y} \\le X \\le \\sqrt{y}) = F_X(\\sqrt{y}) - F_X(-\\sqrt{y})$。由于 $y \\in [0,1)$，我们有 $\\sqrt{y} \\in [0,1)$ 和 $-\\sqrt{y} \\in (-1,0]$。因此，我们可以应用 $F_X(x)$ 的相应分段定义：\n$$ F_X(\\sqrt{y}) = 1 - \\frac{1}{2}(1-\\sqrt{y})^2 $$\n$$ F_X(-\\sqrt{y}) = \\frac{1}{2}(-\\sqrt{y}+1)^2 = \\frac{1}{2}(1-\\sqrt{y})^2 $$\n将它们代入，得到：\n$$ F_Y(y) = \\left(1 - \\frac{1}{2}(1-\\sqrt{y})^2\\right) - \\frac{1}{2}(1-\\sqrt{y})^2 = 1 - (1-\\sqrt{y})^2 = 1 - (1 - 2\\sqrt{y} + y) = 2\\sqrt{y} - y $$\n结合所有情况，我们得到完整的 CDF：", "answer": "$$\\boxed{\nF_{Y}(y)=\n\\begin{cases}\n0  \\text{if } y  0 \\\\\n2\\sqrt{y}-y  \\text{if } 0 \\le y \\le 1 \\\\\n1  \\text{if } y > 1\n\\end{cases}\n}$$", "id": "1416753"}, {"introduction": "累积分布函数不仅是一个理论构造，它也是计算模拟中最基本算法之一——逆变换采样法（inverse transform sampling）的关键。这个练习 [@problem_id:3183232] 要求你将此方法应用于一个复杂的混合随机变量，它既包含连续的区间，也包含离散的概率质量点。你将推导其累积分布函数及其广义逆函数，然后编写代码生成样本，从而完成从数学理论到实际应用的完整过程。", "problem": "设 $X$ 是一个混合随机变量，其分布律由一个具有分段定义的概率密度函数 (PDF) 的绝对连续部分和两个点质量尖峰（原子）组成。使用以下基本定义作为基础：\n- $X$ 的累积分布函数 (CDF) 为 $F_X(x) = \\mathbb{P}(X \\le x)$。\n- 当 $X$ 是绝对连续的时，$F_X$ 是可微的，其导数等于 PDF：$f_X(x) = \\frac{d}{dx}F_X(x)$。\n- 在位于 $x_0$ 的任意原子处，CDF 的跳跃幅度为 $F_X(x_0) - F_X(x_0^-) = \\mathbb{P}(X = x_0)$。\n- 广义逆 CDF（也称为分位数函数）为 $F_X^{-1}(u) = \\inf\\{x \\in \\mathbb{R} : F_X(x) \\ge u\\}$，其中 $u \\in [0,1]$。\n- 逆 CDF 采样法使用一个均匀随机变量 (URV) $U \\sim \\mathrm{Uniform}(0,1)$，并设置 $X = F_X^{-1}(U)$。\n\n$X$ 的分布指定如下：\n- 具有 PDF $f_X(x)$ 的连续部分：\n  1. 对于 $x \\in [0,1)$，$f_X(x) = a$，其中 $a = 0.4$。\n  2. 对于 $x \\in [1,2)$，$f_X(x) = b\\,(2-x)$，其中 $b = 0.8$。\n- 两个原子（尖峰）：\n  1. 在 $x = 0.5$ 处，质量为 $p_1 = 0.1$。\n  2. 在 $x = 2$ 处，质量为 $p_2 = 0.1$。\n\n任务：\n1. 严格从上述基本定义出发，推导所有实数 $x$ 的 CDF $F_X(x)$ 的完整分段表达式。您的推导必须正确处理在区间 $[0,1)$ 和 $[1,2)$ 上的连续累积，以及在 $x=0.5$ 和 $x=2$ 处大小分别为 $p_1$ 和 $p_2$ 的跳跃。\n2. 仅使用定义 $F_X^{-1}(u) = \\inf\\{x : F_X(x) \\ge u\\}$，推导在 $u \\in [0,1]$ 上广义逆 CDF $F_X^{-1}(u)$ 的完整、分段解析表达式。您的表达式必须明确处理 $F_X$ 中由 $x=0.5$ 和 $x=2$ 处的跳跃所对应的 $u$ 值处的不连续性。\n3. 实现一个程序，该程序：\n   - 在给定 $U \\sim \\mathrm{Uniform}(0,1)$ 的情况下，计算并使用您推导的 $F_X^{-1}(u)$ 通过逆 CDF 采样 $X$。\n   - 通过检查特定的 $u$ 值是否映射到原子位置，并通过经验验证五个不相交集的概率，来验证跨不连续点的正确性。这些集合划分了支撑集，从而隔离了连续区域和原子：\n     - $S_1 = \\{X  0.5\\}$，期望概率为 $0.2$。\n     - $S_2 = \\{X = 0.5\\}$，期望概率为 $0.1$。\n     - $S_3 = \\{0.5  X  1\\}$，期望概率为 $0.2$。\n     - $S_4 = \\{1 \\le X  2\\}$，期望概率为 $0.4$。\n     - $S_5 = \\{X = 2\\}$，期望概率为 $0.1$。\n   - 使用一个容差参数 $\\varepsilon$，如果在 $S_1, \\dots, S_5$ 上，经验概率和理论概率之间的最大绝对偏差小于或等于 $\\varepsilon$，则宣布经验验证成功。\n\n测试套件：\n- 情况 1（确定性尖峰映射）：验证在 $u$ 值为 $[0.2, 0.25, 0.3, 0.9, 0.95, 1.0]$ 时，$F_X^{-1}(u)$ 分别等于 $[0.5, 0.5, 0.5, 2, 2, 2]$。\n- 情况 2（采样，中等规模）：使用种子 $123$ 和容差 $\\varepsilon = 0.02$ 采样 $N=5000$ 个值；返回一个布尔值，指示所有五个集合 $S_1$–$S_5$ 是否同时通过。\n- 情况 3（采样，较大规模）：使用种子 $456$ 和容差 $\\varepsilon = 0.005$ 采样 $N=50000$ 个值；返回一个布尔值，指示所有五个集合 $S_1$–$S_5$ 是否同时通过。\n- 情况 4（分位数函数的单调性）：检查 $F_X^{-1}(u)$ 在网格 $[0.0, 0.1, 0.19, 0.2, 0.25, 0.3, 0.31, 0.49, 0.5, 0.7, 0.89, 0.9, 0.95, 1.0]$ 上是非递减的。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[result1,result2,result3,result4]”）。每个结果必须是一个布尔值，按给定顺序指示相应测试用例的通过或失败。\n- 不得打印任何额外文本。", "solution": "该问题要求推导混合随机变量 $X$ 的累积分布函数 (CDF) $F_X(x)$ 及其广义逆 $F_X^{-1}(u)$，然后通过一个实现来验证这些推导。\n\n随机变量 $X$ 的分布律由一个密度为 $f_X(x)$ 的绝对连续部分和包含两个原子的离散部分组成。总概率必须等于 1。首先，我们验证此条件。\n连续部分的总概率为：\n$$\nP_c = \\int_0^1 a \\,dx + \\int_1^2 b(2-x) \\,dx\n$$\n给定 $a=0.4$ 和 $b=0.8$：\n$$\nP_c = \\int_0^1 0.4 \\,dx + \\int_1^2 0.8(2-x) \\,dx = 0.4[x]_0^1 + 0.8\\left[2x - \\frac{x^2}{2}\\right]_1^2\n$$\n$$\nP_c = 0.4(1-0) + 0.8\\left( (4-2) - (2 - \\frac{1}{2}) \\right) = 0.4 + 0.8\\left(2 - \\frac{3}{2}\\right) = 0.4 + 0.8(0.5) = 0.4 + 0.4 = 0.8\n$$\n离散原子的总概率是其质量之和：\n$$\nP_d = p_1 + p_2 = 0.1 + 0.1 = 0.2\n$$\n总概率为 $P_{total} = P_c + P_d = 0.8 + 0.2 = 1.0$。该分布是有效的。\n\n### 第 1 部分：累积分布函数 (CDF) $F_X(x)$ 的推导\n\n我们通过在 $X$ 的定义域上累积概率质量来推导 CDF $F_X(x) = \\mathbb{P}(X \\le x)$。对于混合随机变量，这涉及对概率密度函数 $f_X(x)$ 进行积分，并加上位于小于或等于 $x$ 的位置处任何原子的质量。\n\n1.  **对于 $x  0$**：$X$ 的支撑集在 $[0, 2]$ 上。因此，$\\mathbb{P}(X \\le x) = 0$。\n    $F_X(x) = 0$。\n\n2.  **对于 $0 \\le x  0.5$**：概率仅从连续密度 $f_X(t) = 0.4$ 累积。\n    $F_X(x) = \\int_{-\\infty}^x f_X(t) \\,dt = \\int_0^x 0.4 \\,dt = 0.4x$。\n\n3.  **在 $x = 0.5$ 处**：存在一个质量为 $p_1 = 0.1$ 的原子。CDF 在此点发生跳跃。\n    跳跃前的值为 $F_X(0.5^-) = \\lim_{t \\uparrow 0.5} F_X(t) = 0.4(0.5) = 0.2$。\n    在 $x=0.5$ 处的 CDF 为 $F_X(0.5) = F_X(0.5^-) + \\mathbb{P}(X=0.5) = 0.2 + p_1 = 0.2 + 0.1 = 0.3$。\n\n4.  **对于 $0.5 \\le x  1$**：概率是直到并包括 $x=0.5$ 的质量之和，加上在 $(0.5, x]$ 上从密度 $f_X(t)=0.4$ 累积的概率。\n    $F_X(x) = F_X(0.5^-) + p_1 + \\int_{0.5}^x 0.4 \\,dt = 0.2 + 0.1 + 0.4(x-0.5) = 0.3 + 0.4x - 0.2 = 0.4x+0.1$。\n\n5.  **对于 $1 \\le x  2$**：由于在 $x=1$ 处没有原子，CDF 在此点是连续的。\n    $F_X(1) = F_X(1^-) = 0.4(1) + 0.1 = 0.5$。\n    对于 $x \\in [1, 2)$，我们加上从密度 $f_X(t) = 0.8(2-t)$ 累积的概率。\n    $F_X(x) = F_X(1) + \\int_1^x 0.8(2-t) \\,dt = 0.5 + 0.8\\left[2t - \\frac{t^2}{2}\\right]_1^x$\n    $F_X(x) = 0.5 + 0.8\\left( (2x - \\frac{x^2}{2}) - (2 - \\frac{1}{2}) \\right) = 0.5 + 0.8\\left(2x - \\frac{x^2}{2} - \\frac{3}{2}\\right)$\n    $F_X(x) = 0.5 + 1.6x - 0.4x^2 - 1.2 = -0.4x^2 + 1.6x - 0.7$。\n\n6.  **在 $x = 2$ 处**：存在一个质量为 $p_2 = 0.1$ 的原子。CDF 再次发生跳跃。\n    跳跃前的值是 $F_X(2^-) = \\lim_{t \\uparrow 2} (-0.4t^2 + 1.6t - 0.7) = -0.4(4) + 1.6(2) - 0.7 = -1.6 + 3.2 - 0.7 = 0.9$。\n    在 $x=2$ 处的 CDF 为 $F_X(2) = F_X(2^-) + \\mathbb{P}(X=2) = 0.9 + p_2 = 0.9 + 0.1 = 1.0$。\n\n7.  **对于 $x > 2$**：所有概率都已被计算在内。\n    $F_X(x) = 1.0$。\n\n综合这些部分，完整的 CDF 为：\n$$\nF_X(x) = \\begin{cases}\n0  \\text{if } x  0 \\\\\n0.4x  \\text{if } 0 \\le x  0.5 \\\\\n0.4x + 0.1  \\text{if } 0.5 \\le x  1 \\\\\n-0.4x^2 + 1.6x - 0.7  \\text{if } 1 \\le x  2 \\\\\n1  \\text{if } x \\ge 2\n\\end{cases}\n$$\n\n### 第 2 部分：广义逆 CDF $F_X^{-1}(u)$ 的推导\n\n我们通过对分段 CDF $F_X(x)$ 的每个分段求逆，来推导广义逆 CDF $F_X^{-1}(u) = \\inf\\{x \\in \\mathbb{R} : F_X(x) \\ge u\\}$，其中 $u \\in [0, 1]$。\n\n1.  **对于 $u \\in [0, 0.2)$**：这对应于 $x \\in [0, 0.5)$。我们对 $u = 0.4x$ 求逆。\n    $x = u / 0.4 = 2.5u$。所以，$F_X^{-1}(u) = 2.5u$。\n\n2.  **对于 $u \\in [0.2, 0.3]$**：这个 $u$ 的范围对应于 $F_X$ 在 $x=0.5$ 处的跳跃。\n    $F_X(0.5^-)=0.2$ 且 $F_X(0.5)=0.3$。对于任何 $u \\in [0.2, 0.3]$，集合 $\\{x : F_X(x) \\ge u\\}$ 是 $[0.5, \\infty)$。该集合的下确界是 $0.5$。\n    因此，$F_X^{-1}(u) = 0.5$。\n\n3.  **对于 $u \\in (0.3, 0.5]$**：这对应于 $x \\in (0.5, 1]$。我们对 $u = 0.4x + 0.1$ 求逆。\n    $0.4x = u - 0.1 \\implies x = (u - 0.1)/0.4 = 2.5u - 0.25$。\n    所以，$F_X^{-1}(u) = 2.5u - 0.25$。\n\n4.  **对于 $u \\in (0.5, 0.9]$**：这对应于 $x \\in (1, 2]$。我们对 $u = -0.4x^2 + 1.6x - 0.7$ 求逆。\n    重新整理得到关于 $x$ 的二次方程：$0.4x^2 - 1.6x + (u+0.7) = 0$。\n    使用求根公式，$x = \\frac{1.6 \\pm \\sqrt{1.6^2 - 4(0.4)(u+0.7)}}{2(0.4)} = \\frac{1.6 \\pm \\sqrt{2.56 - 1.6u - 1.12}}{0.8} = \\frac{1.6 \\pm \\sqrt{1.44 - 1.6u}}{0.8}$。\n    这可以简化为 $x = 2 \\pm \\frac{\\sqrt{1.44 - 1.6u}}{0.8} = 2 \\pm \\sqrt{2.25 - 2.5u}$。\n    因为 $x$ 必须在区间 $(1, 2]$ 内，我们必须选择负根。\n    $F_X^{-1}(u) = 2 - \\sqrt{2.25 - 2.5u}$。\n\n5.  **对于 $u \\in (0.9, 1.0]$**：这个 $u$ 的范围对应于 $x=2$ 处的跳跃。\n    $F_X(2^-)=0.9$ 且 $F_X(2)=1.0$。对于任何 $u \\in (0.9, 1.0]$，集合 $\\{x : F_X(x) \\ge u\\}$ 是 $[2, \\infty)$。该集合的下确界是 $2$。\n    因此，$F_X^{-1}(u) = 2$。\n\n综合这些部分，完整的逆 CDF 为：\n$$\nF_X^{-1}(u) = \\begin{cases}\n2.5u  \\text{if } 0 \\le u  0.2 \\\\\n0.5  \\text{if } 0.2 \\le u \\le 0.3 \\\\\n2.5u - 0.25  \\text{if } 0.3  u \\le 0.5 \\\\\n2 - \\sqrt{2.25 - 2.5u}  \\text{if } 0.5  u \\le 0.9 \\\\\n2  \\text{if } 0.9  u \\le 1.0\n\\end{cases}\n$$\n\n### 第 3 部分：实现\n\n推导出的 $F_X^{-1}(u)$ 表达式在 Python 中实现。该函数接受一个均匀随机变量样本 $u$，并返回一个来自 $X$ 分布的样本 $x$。然后使用此函数执行问题陈述中描述的验证测试。代码定义了分段逆 CDF，然后执行四个测试用例：确定性尖峰映射、两个具有不同样本量和容差的采样验证，以及一个单调性检查。这些布尔测试的结果被收集并以指定格式打印。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the solution by deriving the inverse CDF, and then running the specified test cases.\n    \"\"\"\n\n    def inverse_cdf_scalar(u):\n        \"\"\"\n        Computes the generalized inverse CDF F_X^{-1}(u) for a scalar u.\n        This function implements the piecewise formula derived in the solution.\n        \"\"\"\n        if u  0.0:\n            # Although u should be in [0,1], handle out-of-bounds for robustness.\n            return 0.0\n        elif u  0.2:\n            # Corresponds to x in [0, 0.5)\n            return 2.5 * u\n        elif u = 0.3:\n            # Corresponds to the atom at x = 0.5\n            return 0.5\n        elif u = 0.5:\n            # Corresponds to x in [0.5, 1)\n            return 2.5 * u - 0.25\n        elif u = 0.9:\n            # Corresponds to x in [1, 2)\n            # This is the solution to 0.4x^2 - 1.6x + (u+0.7) = 0\n            return 2.0 - np.sqrt(2.25 - 2.5 * u)\n        else: # u > 0.9\n            # Corresponds to the atom at x = 2 and u > 1\n            return 2.0\n\n    # Vectorize the scalar function for efficient application to numpy arrays.\n    inverse_cdf = np.vectorize(inverse_cdf_scalar)\n\n    results = []\n\n    # Case 1: Deterministic spike mapping\n    u_vals_1 = np.array([0.2, 0.25, 0.3, 0.9, 0.95, 1.0])\n    expected_x = np.array([0.5, 0.5, 0.5, 2.0, 2.0, 2.0])\n    actual_x = inverse_cdf(u_vals_1)\n    # Use np.allclose for safe floating-point comparison\n    results.append(np.allclose(actual_x, expected_x))\n\n    def run_sampling_test(N, seed, epsilon):\n        \"\"\"\n        Helper function for Cases 2 and 3.\n        Generates N samples and validates their distribution against expected probabilities.\n        \"\"\"\n        np.random.seed(seed)\n        u_samples = np.random.rand(N)\n        x_samples = inverse_cdf(u_samples)\n\n        # Calculate empirical probabilities for the five disjoint sets.\n        # The comparisons are exact since the inverse CDF returns exact values for atoms.\n        p1_emp = np.sum(x_samples  0.5) / N   # S1: X  0.5\n        p2_emp = np.sum(x_samples == 0.5) / N  # S2: X = 0.5\n        p3_emp = np.sum((x_samples > 0.5)  (x_samples  1.0)) / N # S3: 0.5  X  1\n        p4_emp = np.sum((x_samples >= 1.0)  (x_samples  2.0)) / N # S4: 1 = X  2\n        p5_emp = np.sum(x_samples == 2.0) / N  # S5: X = 2\n\n        p_emp = np.array([p1_emp, p2_emp, p3_emp, p4_emp, p5_emp])\n        p_exp = np.array([0.2, 0.1, 0.2, 0.4, 0.1])\n        \n        # Check if the maximum absolute deviation is within the tolerance.\n        max_deviation = np.max(np.abs(p_emp - p_exp))\n        return max_deviation = epsilon\n\n    # Case 2: Sampling, moderate size\n    results.append(run_sampling_test(N=5000, seed=123, epsilon=0.02))\n\n    # Case 3: Sampling, larger size\n    results.append(run_sampling_test(N=50000, seed=456, epsilon=0.005))\n    \n    # Case 4: Monotonicity of the quantile function\n    u_grid = np.array([0.0, 0.1, 0.19, 0.2, 0.25, 0.3, 0.31, 0.49, 0.5, 0.7, 0.89, 0.9, 0.95, 1.0])\n    x_vals = inverse_cdf(u_grid)\n    # Check if the sequence of x values is non-decreasing using np.diff.\n    # A small tolerance is used for floating point arithmetic safety.\n    is_monotonic = np.all(np.diff(x_vals) >= -1e-9)\n    results.append(is_monotonic)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, [bool(r) for r in results]))}]\")\n\nsolve()\n```", "id": "3183232"}, {"introduction": "逆变换采样法虽然强大，但它要求累积分布函数是可逆的。如果情况并非如此，我们该怎么办？这个练习 [@problem_id:3183207] 将向你介绍马尔可夫链蒙特卡洛（MCMC）方法，这是一类功能强大的算法，用于从复杂分布中采样。你将实现经典的Metropolis-Hastings算法，从一个具有挑战性的重尾柯西分布中采样，并且还将学习诊断采样器性能的关键技能——这对任何计算科学家来说都至关重要。", "problem": "实现一个程序，该程序使用 Metropolis–Hastings 算法从一个重尾目标分布中进行采样，并将经验累积分布函数（CDF）与真实累积分布函数进行比较，以诊断不同链的混合情况和偏差。请完全以纯数学和逻辑术语进行操作。所有变量、符号和数字都必须被视为数学实体。\n\n你必须使用标准柯西分布作为重尾目标分布，该分布为一个实值随机变量 $X$ 定义，其位置参数 $\\theta = 0$ 且尺度参数 $\\gamma = 1$。目标概率密度函数 $f_X$ 和累积分布函数 $F_X$ 分别为：\n- $f_X(x) = \\dfrac{1}{\\pi \\gamma} \\dfrac{1}{1 + \\left(\\dfrac{x - \\theta}{\\gamma}\\right)^2}$，其中 $\\theta = 0$ 且 $\\gamma = 1$。\n- $F_X(x) = \\dfrac{1}{2} + \\dfrac{1}{\\pi} \\arctan\\!\\left(\\dfrac{x - \\theta}{\\gamma}\\right)$，其中 $\\theta = 0$ 且 $\\gamma = 1$。\n\n使用 Metropolis–Hastings 算法和对称高斯随机游走提议。也就是说，给定当前状态 $x$，提议 $x' \\sim \\mathcal{N}(x, s^2)$，其中 $s$ 是提议标准差。由于提议是对称的，接受概率 $\\alpha(x \\to x')$ 的选择必须满足细致平衡条件，以确保平稳分布即为目标分布。根据第一性原理，对称提议的接受概率为：\n$$\n\\alpha(x \\to x') \\;=\\; \\min\\left(1,\\; \\frac{f_X(x')}{f_X(x)}\\right).\n$$\n\n使用的基本原理和原则：\n- 随机变量 $X$ 的定义及其累积分布函数 $F_X(x) = \\mathbb{P}(X \\le x)$，以及对于连续型随机变量 $X$ 的概率密度函数 $f_X(x) = \\dfrac{d}{dx} F_X(x)$。\n- 对于一个马尔可夫链，若其转移核满足关于目标密度 $f_X$ 的细致平衡条件，则目标密度是平稳的，并且在标准正则性条件下，该链在分布上收敛于目标分布。\n- Metropolis–Hastings 构造通过以上文针对对称提议所述的概率 $\\alpha(x \\to x')$ 接受提议，从而确保了细致平衡。\n\n任务要求：\n- 实现一个 Metropolis–Hastings 采样器，使用标准差为 $s$ 的对称高斯提议从标准柯西目标分布中生成样本。为保证可复现性，请使用固定的伪随机种子：将种子设置为 $12345$。\n- 对于每个链，舍弃指定的预烧期（burn-in），并分析保留的样本（预烧期后）。\n- 为了比较保留样本的经验累积分布函数 $\\widehat{F}_X$ 与真实累积分布函数 $F_X$，计算柯尔莫哥洛夫距离：\n$$\nD = \\sup_{x \\in \\mathcal{G}} \\left| \\widehat{F}_X(x) - F_X(x) \\right|,\n$$\n其中 $\\mathcal{G}$ 是一个均匀的 $x$ 值网格。使用一个在区间 $[-25, 25]$ 上包含 $1001$ 个均匀间隔点的网格 $\\mathcal{G}$。\n- 对于每个链，还要计算预烧期后的接受率，定义为预烧期后发生的已接受提议数除以预烧期后作出的提议总数。将接受率报告为 $[0,1]$ 范围的小数（不使用百分号）。\n- 使用标准差参数为 $s$ 的高斯提议，具体数值如下面每个测试用例中所指定。\n\n测试套件：\n精确运行以下 $4$ 个独立的链。每个链由一个元组 $(\\text{length}, \\text{burn\\_in}, s, x_0)$ 指定，其中 $\\text{length}$ 是要保留的状态总数（包括预烧期），$\\text{burn\\_in}$ 是要舍弃的初始状态数，$s$ 是高斯随机游走的提议标准差，而 $x_0$ 是起始点。\n- 用例 1：$(20000, 2000, 2.5, 0.0)$ — 一个通用的理想路径配置。\n- 用例 2：$(20000, 2000, 0.1, 0.0)$ — 极小的提议，用于测试因高自相关性导致的混合不佳。\n- 用例 3：$(20000, 2000, 10.0, 0.0)$ — 极大的提议，用于测试因低接受率导致的混合不佳。\n- 用例 4：$(20000, 2000, 2.5, 50.0)$ — 从尾部很远的地方开始，用于测试收敛的鲁棒性和偏差。\n\n对每个用例，计算：\n- 预烧期后的接受率 $a$。\n- 在网格 $\\mathcal{G}$ 上 $\\widehat{F}_X$ 和 $F_X$ 之间的柯尔莫哥洛夫距离 $D$。\n\n最终输出格式：\n- 你的程序必须生成单行输出，其中包含所有 4 个用例的结果，形式为一个用方括号括起来的、以逗号分隔的浮点数列表，每个用例的两个浮点数按 $[a_1, D_1, a_2, D_2, a_3, D_3, a_4, D_4]$ 的顺序排列。\n- 将每个浮点数四舍五入到恰好 $6$ 位小数。\n- 不应打印任何其他文本。\n\n实现说明和约束：\n- 你必须使用上述定义自行实现 Metropolis–Hastings 算法。\n- 随机数生成器必须使用固定的种子 $12345$ 进行初始化。\n- 在点 $x$ 处的经验累积分布函数 $\\widehat{F}_X$ 定义为小于或等于 $x$ 的保留样本所占的比例。\n- $\\arctan(\\cdot)$ 中的角度以弧度为单位。\n- 不涉及任何物理单位。", "solution": "该问题要求实现并分析 Metropolis-Hastings 算法，用于从一个指定的重尾分布中采样。分析过程涉及通过比较生成样本的经验分布与真实的理论分布，来验证算法在不同参数设置下的性能。\n\n## 问题验证\n问题陈述已经过严格审查，并被确定为有效。它在科学上基于已建立的马尔可夫链蒙特卡洛（MCMC）方法的理论，在数学上是适定的，并提供了一套完整且一致的定义、参数和约束。所有必要信息均已提供，不存在矛盾、歧义或伪科学主张。该任务是计算统计学中的一个标准练习，非常适合指定的主题和领域。\n\n## 方法论框架\n\n### 目标分布\n目标分布是标准柯西分布，它是自由度为1的学生t分布族的一员。它的特点是其重尾，这意味着极端值出现的概率远高于高斯分布。对于随机变量 $X$，在位置参数 $\\theta=0$ 和尺度参数 $\\gamma=1$ 的情况下，其概率密度函数（PDF）$f_X(x)$ 和累积分布函数（CDF）$F_X(x)$ 如下：\n$$\nf_X(x) = \\frac{1}{\\pi(1+x^2)}\n$$\n$$\nF_X(x) = \\frac{1}{2} + \\frac{1}{\\pi} \\arctan(x)\n$$\n\n### Metropolis-Hastings 算法\nMetropolis-Hastings 算法是一种 MCMC 方法，用于从难以直接采样的概率分布中生成一系列随机样本。我们构建一个马尔可夫链，使其平稳分布为所需的目标分布 $f_X(x)$。\n\n算法流程如下。给定链在步骤 $t$ 的状态 $x_t$：\n$1$. 从一个提议分布 $q(x'|x_t)$ 中抽取下一个状态的候选值 $x'$。问题指定了一个对称高斯随机游走提议：\n$$\nx' \\sim \\mathcal{N}(x_t, s^2)\n$$\n其中 $s$ 是提议标准差。这个提议分布的密度是对称的，即 $q(x'|x_t) = q(x_t|x')$，因为它只依赖于距离 $|x' - x_t|$。\n\n$2$. 计算接受概率 $\\alpha(x_t \\to x')$。对于对称提议，这简化为 Metropolis 准则：\n$$\n\\alpha(x_t \\to x') = \\min\\left(1, \\frac{f_X(x')}{f_X(x_t)}\\right)\n$$\n代入柯西分布的 PDF，密度比为：\n$$\n\\frac{f_X(x')}{f_X(x_t)} = \\frac{\\frac{1}{\\pi(1+(x')^2)}}{\\frac{1}{\\pi(1+x_t^2)}} = \\frac{1+x_t^2}{1+(x')^2}\n$$\n\n$3$. 从 $[0, 1)$ 上的均匀分布中抽取一个随机数 $u$。下一个状态 $x_{t+1}$ 由以下方式确定：\n$$\nx_{t+1} = \\begin{cases} x'  \\text{if } u  \\alpha(x_t \\to x') \\\\ x_t  \\text{otherwise} \\end{cases}\n$$\n\n这个过程重复指定的步数 `length`。链的初始部分，即 `burn_in`（预烧期），会被丢弃，以使链收敛到其平稳分布。\n\n### 性能诊断\n对于每个生成的链，都会对预烧期后的样本计算两个指标。设链的总长度为 $L$，预烧期为 $B$。保留的样本为 $\\{x_B, x_{B+1}, \\dots, x_{L-1}\\}$，共 $N = L-B$ 个样本。\n\n$1$. **预烧期后接受率 ($a$)**：这个指标衡量了预烧期后被接受的提议移动所占的比例。它是采样器效率的一个指标。\n$$\na = \\frac{\\text{在 } t \\in \\{B, \\dots, L-1\\} \\text{ 期间接受的提议数}}{L-B}\n$$\n\n$2$. **柯尔莫哥洛夫距离 ($D$)**：这个定量度量评估了保留样本的经验累积分布函数（$\\widehat{F}_X$）与真实 CDF（$F_X$）之间的“距离”。它被定义为两个函数在指定点网格 $\\mathcal{G}$ 上的最大绝对差。\n$$\nD = \\sup_{x \\in \\mathcal{G}} \\left| \\widehat{F}_X(x) - F_X(x) \\right|\n$$\n评估在一个包含区间 $[-25, 25]$ 上 $1001$ 个点的离散网格 $\\mathcal{G}$ 上执行，因此上确界（supremum）变成了最大值。对于任何给定的点 $x$，经验 CDF 是小于或等于 $x$ 的保留样本所占的比例：\n$$\n\\widehat{F}_X(x) = \\frac{1}{N} \\sum_{i=B}^{L-1} \\mathbb{I}(x_i \\le x)\n$$\n其中 $\\mathbb{I}(\\cdot)$ 是指示函数。较小的 $D$ 值表示样本的经验分布是目标分布的一个良好近似。\n\n## 实现策略\n将使用一个单一函数为给定的测试用例 $(\\text{length}, \\text{burn\\_in}, s, x_0)$ 实现 Metropolis-Hastings 采样器。一个 `numpy` 随机数生成器将使用固定的种子 $12345$ 进行初始化，以确保每次运行时生成的随机数序列都相同，从而使整个模拟过程具有确定性和可复现性。\n\n实现的核心是一个运行 `length` 次迭代的循环。在循环内部，从高斯分布生成一个提议，使用柯西密度比计算接受概率，并根据从均匀分布中抽取的一个值来决定接受或拒绝该移动。\n\n循环完成后，将预烧期后的样本分离出来。接受率是通过一个在预烧期后阶段记录已接受移动的计数器来计算的。为了计算柯尔莫哥洛夫距离，将在指定的网格 $\\mathcal{G}$ 上评估真实 CDF 和经验 CDF。然后找出它们之间的最大绝对差。\n\n主执行块将遍历提供的四个测试用例，为每个用例调用采样器并汇总结果。最后，收集到的结果将按照问题的输出规范格式化为单个字符串。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the Metropolis-Hastings simulations for all test cases\n    and print the formatted results.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (length, burn_in, proposal_std, start_x)\n    test_cases = [\n        (20000, 2000, 2.5, 0.0),\n        (20000, 2000, 0.1, 0.0),\n        (20000, 2000, 10.0, 0.0),\n        (20000, 2000, 2.5, 50.0),\n    ]\n\n    # Initialize a single random number generator for reproducibility across all runs.\n    rng = np.random.default_rng(12345)\n    \n    results = []\n    for case in test_cases:\n        length, burn_in, s, x_0 = case\n        acceptance_rate, kolmogorov_dist = run_mcmc_chain(length, burn_in, s, x_0, rng)\n        results.extend([acceptance_rate, kolmogorov_dist])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{val:.6f}' for val in results)}]\")\n\ndef target_pdf_ratio(x_proposed, x_current):\n    \"\"\"\n    Computes the ratio of the target PDF f(x_proposed) / f(x_current).\n    For the standard Cauchy distribution, f(x) = 1 / (pi * (1 + x^2)).\n    The pi factors cancel, leaving (1 + x_current^2) / (1 + x_proposed^2).\n    \"\"\"\n    return (1.0 + x_current**2) / (1.0 + x_proposed**2)\n\ndef true_cdf(x):\n    \"\"\"\n    Computes the true CDF of the standard Cauchy distribution.\n    F(x) = 0.5 + arctan(x) / pi.\n    \"\"\"\n    return 0.5 + np.arctan(x) / np.pi\n\ndef run_mcmc_chain(length, burn_in, s, x_0, rng):\n    \"\"\"\n    Runs a single Metropolis-Hastings chain.\n\n    Args:\n        length (int): Total number of states to generate.\n        burn_in (int): Number of initial states to discard.\n        s (float): Standard deviation of the Gaussian proposal distribution.\n        x_0 (float): Starting point of the chain.\n        rng (np.random.Generator): The random number generator to use.\n\n    Returns:\n        tuple[float, float]: A tuple containing:\n            - The post-burn-in acceptance rate.\n            - The Kolmogorov distance D.\n    \"\"\"\n    samples = np.zeros(length)\n    samples[0] = x_0\n    \n    post_burnin_accepted_count = 0\n    current_x = x_0\n\n    for i in range(1, length):\n        # Propose a new state from a symmetric Gaussian random walk\n        proposed_x = rng.normal(loc=current_x, scale=s)\n        \n        # Calculate acceptance probability\n        acceptance_prob = min(1.0, target_pdf_ratio(proposed_x, current_x))\n        \n        # Accept or reject the proposal\n        if rng.uniform(0, 1)  acceptance_prob:\n            current_x = proposed_x\n            if i >= burn_in:\n                post_burnin_accepted_count += 1\n        \n        samples[i] = current_x\n\n    # --- Analysis ---\n    \n    # 1. Post burn-in acceptance rate\n    num_post_burnin_steps = length - burn_in\n    acceptance_rate = post_burnin_accepted_count / num_post_burnin_steps\n    \n    # 2. Kolmogorov distance\n    retained_samples = samples[burn_in:]\n    \n    # Define the grid for CDF comparison\n    grid = np.linspace(-25.0, 25.0, 1001)\n    \n    # Calculate true CDF on the grid\n    true_cdf_values = true_cdf(grid)\n    \n    # Calculate empirical CDF on the grid\n    # For each grid point `g`, count how many samples are = g, then divide by total samples.\n    # Broadcasting provides an efficient way to do this without a Python loop.\n    ecdf_values = np.mean(retained_samples[:, np.newaxis] = grid, axis=0)\n    \n    # Calculate Kolmogorov distance D\n    kolmogorov_dist = np.max(np.abs(ecdf_values - true_cdf_values))\n    \n    return acceptance_rate, kolmogorov_dist\n\nsolve()\n```", "id": "3183207"}]}