{"hands_on_practices": [{"introduction": "本练习将理论与计算相结合。我们将使用一个经典的贝叶斯推断场景——用伯努利（Bernoulli）数据更新贝塔（Beta）先验——来巩固期望、方差和全期望定律等概念。通过推导解析结果，并将其与蒙特卡洛（Monte Carlo）模拟进行比较 [@problem_id:3126330]，你将具体理解这些理论原理在实践中如何运作，并建立对分析和编程技能的信心。", "problem": "要求您在一个使用 Beta 先验和伯努利数据的贝叶斯更新场景中，实现并验证全期望定律和矩计算。未知参数是一个概率 $X \\in [0,1]$，其先验分布为 $X \\sim \\mathrm{Beta}(\\alpha,\\beta)$。您观察 $n$ 次成功概率为 $X$ 的独立同分布 (IID) 伯努利试验，并将其总结为成功次数 $k$。您的任务是：\n1) 从期望、方差和贝叶斯定理的定义出发，根据第一性原理，解析地推导给定数据下 $X$ 的后验分布。从该后验分布中，计算后验均值和后验方差。同时，使用全期望定律计算先验均值和无条件期望成功次数 $E[K]$。请勿使用任何现成的“快捷”公式；您的推导必须从 Beta 密度、伯努利似然、贝叶斯定理以及期望和方差的定义开始。\n2) 使用从后验分布中进行的蒙特卡洛抽样，数值近似后验均值和后验方差。此外，通过模拟分层过程来数值验证总成功次数的全期望定律：首先从先验分布中抽取 $X$，然后从参数为 $n$ 和 $X$ 的二项分布中抽取 $K$，并估计 $E[K]$。\n3) 为保证数值可复现性，请使用固定的随机种子 $123456$。使用 $M_{\\text{post}}=200000$ 个样本估计后验矩，并使用 $M_{\\text{tot}}=200000$ 个样本在全期望定律下估计 $E[K]$。\n4) 对于每个测试用例，按此精确顺序计算并报告以下七个量：\n- 解析先验均值 $E[X]$。\n- 通过全期望定律计算的解析无条件期望成功次数 $E[K]$。\n- 解析后验均值 $E[X \\mid \\text{data}]$。\n- 解析后验方差 $\\mathrm{Var}[X \\mid \\text{data}]$。\n- 蒙特卡洛后验均值估计 $\\widehat{E}[X \\mid \\text{data}]$。\n- 蒙特卡洛后验方差估计 $\\widehat{\\mathrm{Var}}[X \\mid \\text{data}]$。\n- 通过分层模拟得到的蒙特卡洛无条件期望成功次数估计 $\\widehat{E}[K]$。\n将每个报告值四舍五入到恰好 $6$ 位小数。\n测试套件：\n提供以下 $5$ 个测试用例的结果，每个用例指定为一个四元组 $(\\alpha,\\beta,n,k)$：\n- 用例 1：$(\\alpha,\\beta,n,k)=(2.0,3.0,10,4)$。\n- 用例 2：$(\\alpha,\\beta,n,k)=(2.0,5.0,0,0)$。\n- 用例 3：$(\\alpha,\\beta,n,k)=(0.5,0.5,5,5)$。\n- 用例 4：$(\\alpha,\\beta,n,k)=(50.0,50.0,10,8)$。\n- 用例 5：$(\\alpha,\\beta,n,k)=(1.5,0.5,3,0)$。\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素是对应一个测试用例的七个值，按指定顺序排列并四舍五入到 $6$ 位小数。例如，输出结构必须类似于 $[[v_{1,1},\\dots,v_{1,7}],[v_{2,1},\\dots,v_{2,7}],\\dots,[v_{5,1},\\dots,v_{5,7}]]$，不含任何额外文本。", "solution": "我们从基本定义开始。令 $X \\in [0,1]$ 表示一个未知的概率。$X$ 的先验密度是参数为 $\\alpha0$ 和 $\\beta0$ 的 Beta 密度，\n$$\np(x \\mid \\alpha,\\beta)=\\frac{1}{B(\\alpha,\\beta)} x^{\\alpha-1} (1-x)^{\\beta-1}, \\quad 0", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef beta_posterior_params(alpha, beta, n, k):\n    a_post = alpha + k\n    b_post = beta + n - k\n    return a_post, b_post\n\ndef beta_moments(a, b):\n    mean = a / (a + b)\n    var = (a * b) / ((a + b) ** 2 * (a + b + 1.0))\n    return mean, var\n\ndef monte_carlo_posterior_moments(rng, a_post, b_post, m_samples):\n    samples = rng.beta(a_post, b_post, size=m_samples)\n    mean = float(np.mean(samples))\n    # population variance (ddof=0) to match analytic Var\n    var = float(np.var(samples))\n    return mean, var\n\ndef monte_carlo_total_expectation_EK(rng, alpha, beta, n, m_samples):\n    # Draw hierarchical samples: X ~ Beta(alpha,beta), then K ~ Binomial(n, X)\n    x = rng.beta(alpha, beta, size=m_samples)\n    if n == 0:\n        # degenerate at 0 successes\n        k = np.zeros(m_samples, dtype=np.int64)\n    else:\n        k = rng.binomial(n, x, size=m_samples)\n    return float(np.mean(k))\n\ndef solve():\n    # Define the test cases from the problem statement: (alpha, beta, n, k)\n    test_cases = [\n        (2.0, 3.0, 10, 4),      # Case 1: general\n        (2.0, 5.0, 0, 0),       # Case 2: boundary n=0\n        (0.5, 0.5, 5, 5),       # Case 3: U-shaped prior, all successes\n        (50.0, 50.0, 10, 8),    # Case 4: strong prior\n        (1.5, 0.5, 3, 0),       # Case 5: skewed prior, no successes\n    ]\n\n    # Fixed random seed and sample sizes as specified\n    seed = 123456\n    m_post = 200000\n    m_tot = 200000\n    rng = np.random.default_rng(seed)\n\n    results_str_blocks = []\n\n    for alpha, beta, n, k in test_cases:\n        # Analytic prior mean\n        prior_mean, _ = beta_moments(alpha, beta)\n\n        # Law of total expectation analytic E[K] = n * E[X]\n        analytic_EK = n * prior_mean\n\n        # Posterior params and analytic posterior moments\n        a_post, b_post = beta_posterior_params(alpha, beta, n, k)\n        post_mean, post_var = beta_moments(a_post, b_post)\n\n        # Monte Carlo posterior moments\n        mc_post_mean, mc_post_var = monte_carlo_posterior_moments(rng, a_post, b_post, m_post)\n\n        # Monte Carlo law of total expectation for E[K]\n        mc_EK = monte_carlo_total_expectation_EK(rng, alpha, beta, n, m_tot)\n\n        # Round to 6 decimals and format\n        vals = [\n            prior_mean,\n            analytic_EK,\n            post_mean,\n            post_var,\n            mc_post_mean,\n            mc_post_var,\n            mc_EK\n        ]\n        formatted = \"[\" + \",\".join(f\"{v:.6f}\" for v in vals) + \"]\"\n        results_str_blocks.append(formatted)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str_blocks)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3126330"}, {"introduction": "许多科学问题涉及高维空间中的积分。这最后一个练习将展示为何概率方法不仅是一种替代方案，而且往往是解决此类问题的*唯一*可行途径。通过比较蒙特卡洛（Monte Carlo）积分与传统确定性方法（张量网格求积）在维度增加时的计算成本 [@problem_id:3145824]，你将直接观察到“维度灾难”（curse of dimensionality），并体会到蒙特卡洛方法的卓越效率，其误差率与问题的维度无关。", "problem": "考虑使用两种方法估算一个可分离函数在单位超立方体上的积分：蒙特卡洛 (MC) 采样和张量积网格复合梯形求积。设函数定义为 $f(\\mathbf{x}) = \\prod_{i=1}^{d} g(x_i)$，作用于 $[0,1]^d$ 上，其中 $g(t) = \\sin(\\pi t)$ 且角度以弧度为单位。所求积分为 $I_d = \\int_{[0,1]^d} f(\\mathbf{x}) \\, d\\mathbf{x}$。您的任务是实现一个程序，对于一组给定的维度 $d$ 和容差 $\\varepsilon$，计算并比较蒙特卡洛和张量网格求积法为保证均方根误差最多为 $\\varepsilon$ 所需的最小样本数。\n\n从以下基本依据开始：\n- 在 $[0,1]^d$ 上的均匀分布下，随机变量的期望和方差的定义。\n- 一维复合梯形法则的经典误差界：对于在 $[a,b]$ 上二阶连续可微的函数，若将其划分为 $m$ 个相等的子区间（因此步长为 $h = (b-a)/m$），则绝对误差满足 $\\left|\\int_{a}^{b} f(x)\\,dx - T_m\\right| \\le \\dfrac{(b-a)}{12} h^2 \\sup_{x \\in [a,b]} |f''(x)|$。对于 $[0,1]$，这简化为 $\\left|\\int_{0}^{1} f(x)\\,dx - T_m\\right| \\le \\dfrac{1}{12 m^2} \\sup_{x \\in [0,1]} |f''(x)|$。\n\n利用这些基本依据和 $f$ 的可分离结构：\n- 推导在 $[0,1]^d$ 上的均匀分布下 $f(\\mathbf{X})$ 的方差，其中 $\\mathbf{X}$ 在 $[0,1]^d$ 上均匀分布。利用此方差确定最小整数独立样本数 $n_{\\mathrm{MC}}$，使得 MC 估计量的标准误差最多为 $\\varepsilon$；也就是说，找到 $n_{\\mathrm{MC}}$，使得样本均值的方差的平方根最多为 $\\varepsilon$。\n- 对于张量网格求积，在每个坐标上使用具有相同子区间数 $m$ 的一维复合梯形法则，并取张量积以获得 $d$ 维求积。利用 $f$ 的可分离性，根据 $d$、$m$、一维积分 $I_1 = \\int_{0}^{1} g(t)\\,dt$ 以及 $g$ 的一维梯形误差界，构造一个可计算的 $d$ 维求积误差上界。从此界中，确定最小整数 $m$，使得绝对误差最多为 $\\varepsilon$，然后计算张量网格法则使用的总网格点数 $n_{\\mathrm{TG}} = (m+1)^d$。\n\n您的程序应针对每个测试用例 $(d,\\varepsilon)$ 计算：\n- $n_{\\mathrm{MC}}$，蒙特卡洛方法达到标准误差最多为 $\\varepsilon$ 所需的最小整数样本数。\n- $n_{\\mathrm{TG}}$，张量网格点数达到绝对误差上界最多为 $\\varepsilon$ 所需的最小整数数量。\n- 一个布尔值，指示 MC 在采样效率上是否占优，定义为 $n_{\\mathrm{MC}}  n_{\\mathrm{TG}}$。\n\n测试套件：\n使用以下 $(d,\\varepsilon)$ 对集合来测试不同情况：\n- 情况 1：$d = 1$，$\\varepsilon = 10^{-3}$（一维基准）。\n- 情况 2：$d = 5$，$\\varepsilon = 10^{-3}$（中等维度，紧容差）。\n- 情况 3：$d = 10$，$\\varepsilon = 10^{-3}$（较高维度，紧容差）。\n- 情况 4：$d = 20$，$\\varepsilon = 10^{-3}$（高维度，紧容差）。\n- 情况 5：$d = 1$，$\\varepsilon = 10^{-2}$（一维，较宽松容差）。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果，每个测试用例对应一个形如 $[n_{\\mathrm{MC}},n_{\\mathrm{TG}},\\mathrm{MC\\_dominates}]$ 的内部列表。布尔值应打印为 $\\mathrm{True}$ 或 $\\mathrm{False}$。输出中不允许有空格。例如，输出应类似于 $[[\\text{case1}],[\\text{case2}],\\dots]$，且不含任何空格。", "solution": "该问题要求确定两种数值积分方法——蒙特卡洛 (MC) 采样和张量积复合梯形求积——为将积分 $I_d = \\int_{[0,1]^d} f(\\mathbf{x}) \\, d\\mathbf{x}$ 估算至指定容差 $\\varepsilon$ 所需的最小函数求值次数。被积函数是一个可分离函数 $f(\\mathbf{x}) = \\prod_{i=1}^{d} g(x_i)$，其中 $g(t) = \\sin(\\pi t)$，作用于单位超立方体 $[0,1]^d$ 上。\n\n首先，我们验证问题陈述。\n**第一步：提取已知条件**\n- **函数**：$f(\\mathbf{x}) = \\prod_{i=1}^{d} g(x_i)$，定义域为 $[0,1]^d$。\n- **构成函数**：$g(t) = \\sin(\\pi t)$，角度以弧度为单位。\n- **积分**：$I_d = \\int_{[0,1]^d} f(\\mathbf{x}) \\, d\\mathbf{x}$。\n- **方法**：蒙特卡洛 (MC) 采样和张量积网格复合梯形求积。\n- **容差**：$\\varepsilon$。\n- **MC 条件**：MC 估计量的标准误差必须最多为 $\\varepsilon$。\n- **张量网格 (TG) 条件**：TG 求积的绝对误差必须最多为 $\\varepsilon$。\n- **一维梯形误差界**：对于在 $[0,1]$ 上有 $m$ 个子区间，$|\\int_{0}^{1} \\phi(x)\\,dx - T_m[\\phi]| \\le \\frac{1}{12 m^2} \\sup_{x \\in [0,1]} |\\phi''(x)|$。\n- **每个测试用例 $(d, \\varepsilon)$ 的输出**：\n    1.  $n_{\\mathrm{MC}}$：MC 采样的最小整数样本数。\n    2.  $n_{\\mathrm{TG}}$：TG 网格点的最小整数数量。\n    3.  一个表示 $n_{\\mathrm{MC}}  n_{\\mathrm{TG}}$ 的布尔值。\n- **测试套件**：$(d,\\varepsilon)$ 对为 $(1, 10^{-3}), (5, 10^{-3}), (10, 10^{-3}), (20, 10^{-3}), (1, 10^{-2})$。\n\n**第二步：使用提取的已知条件进行验证**\n该问题在科学上基于数值分析和概率论的标准原理。函数 $g(t) = \\sin(\\pi t)$ 行为良好且无限可微。该问题是适定的，因为它要求基于推导出的误差界计算最小整数样本数。定义和约束是自洽且数学上精确的，允许有唯一解。该设置没有矛盾、不切实际或不适定之处。\n\n**第三步：结论与行动**\n该问题被判定为**有效**。我们继续推导必要的公式。\n\n### 蒙特卡洛方法分析\n\n基于从 $[0,1]^d$ 中均匀抽取的 $n$ 个独立样本 $\\mathbf{X}_j$ 的 $I_d$ 的蒙特卡洛估计量是样本均值 $\\hat{I}_{d,n} = \\frac{1}{n} \\sum_{j=1}^{n} f(\\mathbf{X}_j)$。该估计量是无偏的，即 $E[\\hat{I}_{d,n}] = I_d$。\n\n该估计量的标准误差是其方差的平方根：\n$$\n\\mathrm{SE}(\\hat{I}_{d,n}) = \\sqrt{\\mathrm{Var}(\\hat{I}_{d,n})} = \\sqrt{\\mathrm{Var}\\left(\\frac{1}{n} \\sum_{j=1}^{n} f(\\mathbf{X}_j)\\right)} = \\frac{1}{\\sqrt{n}} \\sqrt{\\mathrm{Var}(f(\\mathbf{X}))}\n$$\n条件是 $\\mathrm{SE}(\\hat{I}_{d,n}) \\le \\varepsilon$，这意味着 $\\frac{\\sqrt{\\mathrm{Var}(f(\\mathbf{X}))}}{\\sqrt{n}} \\le \\varepsilon$，或 $n \\ge \\frac{\\mathrm{Var}(f(\\mathbf{X}))}{\\varepsilon^2}$。\n最小整数样本数为 $n_{\\mathrm{MC}} = \\left\\lceil \\frac{\\mathrm{Var}(f(\\mathbf{X}))}{\\varepsilon^2} \\right\\rceil$。\n\n我们必须计算 $\\mathrm{Var}(f(\\mathbf{X})) = E[f(\\mathbf{X})^2] - (E[f(\\mathbf{X})])^2$。\n由于 $f$ 的可分离性以及 $\\mathbf{X}$ 各分量的独立性，期望是多个一维期望的乘积。设 $X \\sim U[0,1]$。\n\n1.  $g(X)$ 的期望：\n    $$\n    E[g(X)] = \\int_0^1 g(t)\\,dt = \\int_0^1 \\sin(\\pi t)\\,dt = \\left[-\\frac{1}{\\pi}\\cos(\\pi t)\\right]_0^1 = -\\frac{1}{\\pi}(\\cos(\\pi) - \\cos(0)) = \\frac{2}{\\pi}\n    $$\n    令此值为 $I_1 = \\frac{2}{\\pi}$。则 $I_d = E[f(\\mathbf{X})] = (I_1)^d = \\left(\\frac{2}{\\pi}\\right)^d$。\n\n2.  $g(X)^2$ 的期望：\n    $$\n    E[g(X)^2] = \\int_0^1 g(t)^2\\,dt = \\int_0^1 \\sin^2(\\pi t)\\,dt = \\int_0^1 \\frac{1 - \\cos(2\\pi t)}{2}\\,dt = \\frac{1}{2}\\left[t - \\frac{\\sin(2\\pi t)}{2\\pi}\\right]_0^1 = \\frac{1}{2}\n    $$\n    则 $E[f(\\mathbf{X})^2] = \\prod_{i=1}^d E[g(X_i)^2] = \\left(\\frac{1}{2}\\right)^d$。\n\n$f(\\mathbf{X})$ 的方差为：\n$$\n\\mathrm{Var}(f(\\mathbf{X})) = \\left(\\frac{1}{2}\\right)^d - \\left(\\left(\\frac{2}{\\pi}\\right)^d\\right)^2 = \\left(\\frac{1}{2}\\right)^d - \\left(\\frac{2}{\\pi}\\right)^{2d}\n$$\n因此，MC 采样的最小数量为：\n$$\nn_{\\mathrm{MC}} = \\left\\lceil \\frac{(1/2)^d - (2/\\pi)^{2d}}{\\varepsilon^2} \\right\\rceil\n$$\n\n### 张量积求积分析\n\n在每个维度上有 $m$ 个子区间的 $d$ 维张量积梯形法则 $T_{m,d}$ 是 $d$ 个一维梯形法则 $T_m$ 的乘积。对于可分离函数 $f(\\mathbf{x}) = \\prod_{i=1}^d g(x_i)$，其积分为 $T_{m,d}[f] = \\prod_{i=1}^d T_m[g]$。\n\n误差为 $I_d - T_{m,d}[f] = (I_1)^d - (T_m[g])^d$。我们可以使用恒等式 $A^d - B^d = (A-B)\\sum_{k=0}^{d-1} A^{d-1-k} B^k$ 来表示此差值。令 $E_m = I_1 - T_m[g]$。\n总误差为 $(I_1 - T_m[g]) \\sum_{k=0}^{d-1} (I_1)^{d-1-k} (T_m[g])^k = E_m \\sum_{k=0}^{d-1} (I_1)^{d-1-k} (T_m[g])^k$。\n要界定此误差，我们需要界定 $|T_m[g]|$。函数 $g(t)=\\sin(\\pi t)$ 在 $[0,1]$ 上是凹函数，因为对于 $t \\in [0,1]$，$g''(t) = -\\pi^2 \\sin(\\pi t) \\le 0$。对于凹函数，梯形法则会低估积分值，所以 $T_m[g] \\le I_1$。由于 $g(t) \\ge 0$，我们有 $0 \\le T_m[g] \\le I_1$。\n因此， $|T_m[g]| \\le I_1 = |I_1|$。\n\n绝对误差的上界为：\n$$\n|I_d - T_{m,d}[f]| \\le |E_m| \\sum_{k=0}^{d-1} |I_1|^{d-1-k} |I_1|^k = |E_m| \\sum_{k=0}^{d-1} |I_1|^{d-1} = d |I_1|^{d-1} |E_m|\n$$\n现在我们使用给定的一维误差界 $|E_m| = |I_1 - T_m[g]| \\le \\frac{1}{12 m^2} \\sup_{t \\in [0,1]} |g''(t)|$。\n对于 $g(t) = \\sin(\\pi t)$，$g''(t) = -\\pi^2 \\sin(\\pi t)$。其上确界为 $\\sup_{t \\in [0,1]} |-\\pi^2 \\sin(\\pi t)| = \\pi^2$。\n所以， $|E_m| \\le \\frac{\\pi^2}{12m^2}$。\n\n总误差界变为：\n$$\n|I_d - T_{m,d}[f]| \\le d \\left(\\frac{2}{\\pi}\\right)^{d-1} \\frac{\\pi^2}{12m^2}\n$$\n我们要求此界最多为 $\\varepsilon$：\n$$\nd \\left(\\frac{2}{\\pi}\\right)^{d-1} \\frac{\\pi^2}{12m^2} \\le \\varepsilon \\implies m^2 \\ge \\frac{d \\pi^2}{12 \\varepsilon} \\left(\\frac{2}{\\pi}\\right)^{d-1}\n$$\n每个维度的最小整数子区间数 $m$ 为：\n$$\nm = \\left\\lceil \\sqrt{\\frac{d \\pi^2}{12 \\varepsilon} \\left(\\frac{2}{\\pi}\\right)^{d-1}} \\right\\rceil\n$$\n具有 $m$ 个子区间的复合梯形法则在每个维度上使用 $m+1$ 个点。对于 $d$ 维张量网格，总网格点数为 $n_{\\mathrm{TG}} = (m+1)^d$。\n\n### 总结与计算\n对于每个测试用例 $(d, \\varepsilon)$，我们计算：\n1.  $n_{\\mathrm{MC}} = \\left\\lceil \\frac{(1/2)^d - (2/\\pi)^{2d}}{\\varepsilon^2} \\right\\rceil$\n2.  $m = \\left\\lceil \\sqrt{\\frac{d \\pi^2}{12 \\varepsilon} (2/\\pi)^{d-1}} \\right\\rceil$ 和 $n_{\\mathrm{TG}} = (m+1)^d$。\n3.  $n_{\\mathrm{MC}}  n_{\\mathrm{TG}}$ 的布尔值。\n\n这些计算将在最终程序中实现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and compares the sample counts for Monte Carlo and tensor-grid\n    quadrature for a given set of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 10**-3),  # Case 1\n        (5, 10**-3),  # Case 2\n        (10, 10**-3), # Case 3\n        (20, 10**-3), # Case 4\n        (1, 10**-2),  # Case 5\n    ]\n\n    results = []\n    for d, epsilon in test_cases:\n        # --- Monte Carlo Calculation ---\n        # Variance of f(X), where X is uniform on [0,1]^d\n        # Var(f) = E[f^2] - (E[f])^2\n        # E[f] = (integral_0^1 sin(pi*t) dt)^d = (2/pi)^d\n        # E[f^2] = (integral_0^1 sin^2(pi*t) dt)^d = (1/2)^d\n        var_f = (0.5)**d - (2 / np.pi)**(2 * d)\n        \n        # n_MC = Var(f) / epsilon^2\n        # The number of samples must be an integer, so we take the ceiling.\n        n_mc = np.ceil(var_f / epsilon**2)\n        \n        # --- Tensor-Grid Quadrature Calculation ---\n        # Error_d = d * |I_1|^(d-1) * Error_1\n        # Error_1 = sup|g''| / (12 * m^2) = pi^2 / (12 * m^2)\n        # We need Error_d = epsilon\n        # d * (2/pi)^(d-1) * pi^2 / (12 * m^2) = epsilon\n        # m^2 = (d * pi^2 / (12 * epsilon)) * (2/pi)^(d-1)\n        \n        m_squared = (d * np.pi**2 / (12 * epsilon)) * (2 / np.pi)**(d - 1)\n        \n        # Minimal integer number of panels m\n        m = np.ceil(np.sqrt(m_squared))\n        \n        # Total number of grid points is (m+1)^d.\n        # Python's int handles arbitrary-precision integers, so overflow is not an issue.\n        n_tg = (int(m) + 1)**d\n        \n        # --- Comparison ---\n        mc_dominates = bool(n_mc  n_tg)\n        \n        # Append results as integers and a boolean.\n        # Use int() to convert from numpy float types.\n        results.append([int(n_mc), n_tg, mc_dominates])\n\n    # Final print statement in the exact required format.\n    # The format is [[case1_val1,case1_val2,...],[case2_val1,...],...] with no spaces.\n    # Using str() and then replace() is a robust way to achieve this.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3145824"}]}