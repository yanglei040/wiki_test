{"hands_on_practices": [{"introduction": "中心极限定理的一个基本应用是确定达到所需估计精度所需的样本量。这个练习将带你进入一个实际的工程情境——实时控制系统，你需要在统计精度和响应延迟之间做出权衡。通过解决这个问题[@problem_id:3153047]，你将掌握如何利用中心极限定理来量化这种权衡，并为一个受约束的系统计算出最佳样本数。", "problem": "一个实时控制器必须在发出驱动指令之前，通过对$n$个独立同分布的传感器读数进行平均，来估计一个恒定信号。每个读数被建模为$X_{i}=\\theta+\\eta_{i}$，其中$\\theta$是平均窗口内的恒定信号，而$\\eta_{i}$是均值为$0$、标准差为$\\sigma$的独立噪声项。控制器使用样本均值$\\bar{X}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$作为估计值。收集每个读数需要固定的时间$\\Delta t$，因此传感到驱动的延迟等于$n\\Delta t$。控制器必须遵守一个硬截止时间$T_{\\max}$，所以$n\\Delta t\\leq T_{\\max}$。设计要求是，在驱动时刻，绝对估计误差$|\\bar{X}_{n}-\\theta|\\leq \\varepsilon$的概率至少为$p_{0}$。这一要求由大数定律 (LLN) 证明其合理性，并使用中心极限定理 (CLT) 对大$n$的近似进行量化。\n\n给定：\n- 噪声标准差 $\\sigma=0.8$。\n- 容差 $\\varepsilon=0.10$。\n- 目标置信度 $p_{0}=0.95$。\n- 每样本时间 $\\Delta t=2\\times 10^{-3}$ 秒。\n- 最大允许延迟 $T_{\\max}=0.50$ 秒。\n\n从样本均值和方差的定义出发，并应用中心极限定理来近似$\\bar{X}_{n}$的分布，推导出同时满足概率要求和延迟约束的最小整数$n$。只报告$n$的整数值。", "solution": "首先验证问题，以确保其具有科学依据、是良定的，并提供了所有必要的信息。该问题是中心极限定理（CLT）的一个标准应用，用于确定一个受延迟约束的估计问题所需的样本量。所有参数都已提供且物理上一致。该问题被认为是有效的。\n\n解题过程如下。每个传感器读数$X_i$是一个随机变量，由$X_{i}=\\theta+\\eta_{i}$给出，其中$\\theta$是一个恒定信号，$\\eta_{i}$是均值为$E[\\eta_i] = 0$、标准差为$\\sigma$的独立同分布 (i.i.d.) 噪声项。\n\n首先，我们确定单个读数$X_i$的统计特性：\n$X_i$的期望值为 $E[X_i] = E[\\theta + \\eta_i] = \\theta + E[\\eta_i] = \\theta + 0 = \\theta$。\n$X_i$的方差为 $Var(X_i) = Var(\\theta + \\eta_i) = Var(\\eta_i) = \\sigma^2$。\n\n$\\theta$的估计值是$n$个读数的样本均值，$\\bar{X}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$。我们确定这个估计量的统计特性。\n样本均值的期望值为 $E[\\bar{X}_n] = E\\left[\\frac{1}{n}\\sum_{i=1}^{n}X_{i}\\right] = \\frac{1}{n}\\sum_{i=1}^{n}E[X_i] = \\frac{1}{n}(n\\theta) = \\theta$。这证实了样本均值是$\\theta$的无偏估计量。\n\n样本均值的方差，在$X_i$独立的条件下为：\n$$Var(\\bar{X}_n) = Var\\left(\\frac{1}{n}\\sum_{i=1}^{n}X_{i}\\right) = \\frac{1}{n^2}\\sum_{i=1}^{n}Var(X_i) = \\frac{1}{n^2}(n\\sigma^2) = \\frac{\\sigma^2}{n}$$\n因此，样本均值的标准差为 $SD(\\bar{X}_n) = \\sqrt{\\frac{\\sigma^2}{n}} = \\frac{\\sigma}{\\sqrt{n}}$。\n\n根据中心极限定理，对于足够大的样本量$n$，样本均值$\\bar{X}_n$的分布近似为正态分布，其均值为$\\theta$，方差为$\\frac{\\sigma^2}{n}$。我们可以将其写作$\\bar{X}_n \\sim \\mathcal{N}\\left(\\theta, \\frac{\\sigma^2}{n}\\right)$。\n为了分析概率要求，我们将随机变量$\\bar{X}_n$标准化，以得到一个标准正态变量$Z$：\n$$Z = \\frac{\\bar{X}_n - E[\\bar{X}_n]}{SD(\\bar{X}_n)} = \\frac{\\bar{X}_n - \\theta}{\\sigma/\\sqrt{n}}$$\n变量$Z$近似服从标准正态分布，$Z \\sim \\mathcal{N}(0,1)$。\n\n设计要求是绝对估计误差$|\\bar{X}_n - \\theta|$不超过$\\varepsilon$的概率至少为$p_0$。这表示为：\n$$P(|\\bar{X}_n - \\theta| \\leq \\varepsilon) \\geq p_0$$\n我们可以将概率内的不等式重写为 $-\\varepsilon \\leq \\bar{X}_n - \\theta \\leq \\varepsilon$。将不等式的各部分都除以$\\bar{X}_n$的标准差，得到：\n$$-\\frac{\\varepsilon}{\\sigma/\\sqrt{n}} \\leq \\frac{\\bar{X}_n - \\theta}{\\sigma/\\sqrt{n}} \\leq \\frac{\\varepsilon}{\\sigma/\\sqrt{n}}$$\n这等价于 $-\\frac{\\varepsilon\\sqrt{n}}{\\sigma} \\leq Z \\leq \\frac{\\varepsilon\\sqrt{n}}{\\sigma}$。概率要求变为：\n$$P\\left(-\\frac{\\varepsilon\\sqrt{n}}{\\sigma} \\leq Z \\leq \\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) \\geq p_0$$\n设$\\Phi(z)$为标准正态分布的累积分布函数 (CDF)。该概率由$\\Phi\\left(\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) - \\Phi\\left(-\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right)$给出。由于正态分布的对称性，$\\Phi(-z) = 1 - \\Phi(z)$，因此概率为$2\\Phi\\left(\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) - 1$。\n不等式为$2\\Phi\\left(\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) - 1 \\geq p_0$，可以重排为：\n$$\\Phi\\left(\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) \\geq \\frac{1+p_0}{2}$$\n给定$p_0 = 0.95$，所以我们需要$\\Phi\\left(\\frac{\\varepsilon\\sqrt{n}}{\\sigma}\\right) \\geq \\frac{1+0.95}{2} = 0.975$。\n设$z_c$为标准正态分布的临界值，使得$\\Phi(z_c) = 0.975$。查标准正态分布表可得$z_c \\approx 1.96$。\n因此，我们需要$\\frac{\\varepsilon\\sqrt{n}}{\\sigma} \\geq z_c$。解出$n$：\n$$\\sqrt{n} \\geq \\frac{\\sigma z_c}{\\varepsilon} \\implies n \\geq \\left(\\frac{\\sigma z_c}{\\varepsilon}\\right)^2$$\n代入给定值$\\sigma=0.8$，$\\varepsilon=0.10$和$z_c \\approx 1.96$：\n$$n \\geq \\left(\\frac{0.8 \\times 1.96}{0.10}\\right)^2 = \\left(\\frac{1.568}{0.10}\\right)^2 = (15.68)^2 = 245.8624$$\n由于$n$必须是整数，满足概率要求的最小样本数为$n = 246$。\n\n接下来，我们评估延迟约束。总传感时间为$n\\Delta t$，它不得超过截止时间$T_{\\max}$：\n$$n\\Delta t \\leq T_{\\max}$$\n这对$n$施加了一个上界：\n$$n \\leq \\frac{T_{\\max}}{\\Delta t}$$\n代入给定值$\\Delta t=2\\times 10^{-3}$秒和$T_{\\max}=0.50$秒：\n$$n \\leq \\frac{0.50}{2 \\times 10^{-3}} = \\frac{0.50}{0.002} = 250$$\n所以，$n$必须是小于或等于$250$的整数。\n\n我们必须找到同时满足以下两个条件的最小整数$n$：\n1. $n \\geq 246$ (来自概率要求)\n2. $n \\leq 250$ (来自延迟约束)\n\n$n$的可能整数值范围是$[246, 250]$。问题要求的是这个范围内的最小整数$n$。\n因此，$n$的最小有效值为$246$。\n我们来检查这个值：\n对于$n=246$，延迟为$246 \\times (2 \\times 10^{-3}) = 0.492$秒，小于$T_{\\max}=0.50$秒。\n对于$n=246$，条件$n \\geq 245.8624$得到满足，从而满足概率要求。\n对于$n=245$，概率要求将无法满足。\n因此，最小整数$n$为$246$。", "answer": "$$\\boxed{246}$$", "id": "3153047"}, {"introduction": "经典的中心极限定理依赖于样本独立同分布的假设，但在真实世界中，数据往往存在相关性，例如通信系统中的突发错误。这个练习探讨了当数据内部存在相关性时，我们如何通过“分块”技巧来扩展中心极限定理的应用。解决这个问题[@problem_id:3153114]将帮助你理解如何处理非理想数据，并准确估算在更复杂情境下的置信区间。", "problem": "一个计算科学团队正计划对一个二进制通信链路进行蒙特卡罗研究，以估计误码率。设误码指示器为一个伯努利随机变量 $X$，如果一个比特接收错误，则 $X=1$，否则 $X=0$。该团队将以等长的数据包（突发）形式收集数据。在每个数据包 $j$ 中，$m$ 个误码指示器 $(X_{j,1},X_{j,2},\\dots,X_{j,m})$ 共享相同的成对相关系数 $\\rho0$，而数据包之间相互独立。误码率的估计量是所有收集到的比特的样本均值 $\\hat{p}=\\bar{X}$。\n\n一次小规模的初步运行产生了一个规划值 $\\hat{p}_{0}=0.010$。正式运行将使用大小为 $m=100$ 比特的数据包，包内成对相关系数为 $\\rho=0.05$。使用大数定律（LLN）和中心极限定理（CLT），以及一个适用于正相关突发的基于块的CLT论证，确定所需的最小整数数据包数量 $K$，使得误码率的双边 $95\\%$ 正态近似置信区间的半宽至多为 $h=0.001$。\n\n将你的最终答案表示为保证所需半宽的最小整数 $K$。因为 $K$ 是一个整数计数，所以无需按有效数字进行四舍五入。", "solution": "该问题经验证具有科学依据、提法恰当且客观。这是一个统计模拟和通信理论中的标准问题，可以使用应用于相关数据的中心极限定理来解决。所有必要的参数都已提供，不存在矛盾。\n\n目标是找到最小的整数数据包数量 $K$，使得误码率 $p$ 的 $95\\%$ 置信区间的半宽至多为 $h=0.001$。$p$ 的估计量是所有 $N=Km$ 个比特的样本均值 $\\hat{p} = \\bar{X}$。\n\n$p$ 的双边正态近似置信区间由 $\\hat{p} \\pm h$ 给出，其中半宽 $h$ 定义为：\n$$h = z_{\\alpha/2} \\cdot \\sqrt{\\text{Var}(\\hat{p})}$$\n对于 $95\\%$ 的置信水平，$1-\\alpha = 0.95$，因此 $\\alpha=0.05$，$\\alpha/2 = 0.025$。相应的来自标准正态分布的临界值为 $z_{0.025} \\approx 1.96$。\n\n估计量 $\\hat{p}$ 是所有误码指示器的平均值：\n$$\\hat{p} = \\frac{1}{Km} \\sum_{j=1}^{K} \\sum_{i=1}^{m} X_{j,i}$$\n其中 $X_{j,i}$ 是第 $j$ 个数据包中第 $i$ 个比特的伯努利随机变量。比特总数为 $N=Km$。\n\n问题陈述数据包是相互独立的，但一个数据包内的比特是相关的。这种结构表明可以基于块应用中心极限定理（CLT）。我们定义包级别的平均值 $Y_j = \\frac{1}{m} \\sum_{i=1}^{m} X_{j,i}$。总体估计量 $\\hat{p}$ 是这些包平均值的均值：\n$$\\hat{p} = \\frac{1}{K} \\sum_{j=1}^{K} Y_j$$\n由于数据包是独立同分布的，所以随机变量 $Y_j$ 是独立同分布的（i.i.d.）。对于足够大的数据包数量 $K$，CLT确保 $\\hat{p}$ 的分布近似为正态分布，其均值为 $E[\\hat{p}] = E[Y_j] = p$，方差为：\n$$\\text{Var}(\\hat{p}) = \\text{Var}\\left(\\frac{1}{K} \\sum_{j=1}^{K} Y_j\\right) = \\frac{1}{K^2} \\sum_{j=1}^{K} \\text{Var}(Y_j) = \\frac{K \\cdot \\text{Var}(Y_1)}{K^2} = \\frac{\\text{Var}(Y_1)}{K}$$\n我们现在需要求出单个包平均值的方差 $\\text{Var}(Y_1)$。为简单起见，我们省略包索引 $j=1$。\n$$\\text{Var}(Y) = \\text{Var}\\left(\\frac{1}{m} \\sum_{i=1}^{m} X_i\\right) = \\frac{1}{m^2} \\text{Var}\\left(\\sum_{i=1}^{m} X_i\\right)$$\n相关随机变量之和的方差由下式给出：\n$$\\text{Var}\\left(\\sum_{i=1}^{m} X_i\\right) = \\sum_{i=1}^{m}\\sum_{k=1}^{m} \\text{Cov}(X_i, X_k) = \\sum_{i=1}^{m} \\text{Var}(X_i) + \\sum_{i \\neq k} \\text{Cov}(X_i, X_k)$$\n每个 $X_i$ 是参数为 $p$ 的伯努利随机变量。因此，$\\text{Var}(X_i) = p(1-p)$。\n对于 $i \\neq k$ 的成对相关系数给定为 $\\rho$：\n$$\\rho = \\frac{\\text{Cov}(X_i, X_k)}{\\sqrt{\\text{Var}(X_i)\\text{Var}(X_k)}} = \\frac{\\text{Cov}(X_i, X_k)}{p(1-p)}$$\n因此，对于 $i \\neq k$，有 $\\text{Cov}(X_i, X_k) = \\rho p(1-p)$。\n在双重求和中有 $m$ 个方差项和 $m(m-1)$ 个协方差项。\n$$\\text{Var}\\left(\\sum_{i=1}^{m} X_i\\right) = m \\cdot p(1-p) + m(m-1) \\cdot \\rho p(1-p) = m p(1-p) [1 + (m-1)\\rho]$$\n将此代回 $\\text{Var}(Y)$ 的表达式中：\n$$\\text{Var}(Y) = \\frac{1}{m^2} \\left( m p(1-p) [1 + (m-1)\\rho] \\right) = \\frac{p(1-p)}{m} [1 + (m-1)\\rho]$$\n最后，总体估计量 $\\hat{p}$ 的方差是：\n$$\\text{Var}(\\hat{p}) = \\frac{\\text{Var}(Y)}{K} = \\frac{p(1-p)}{Km} [1 + (m-1)\\rho]$$\n项 $[1 + (m-1)\\rho]$ 是由包内正相关引起的方差膨胀因子。\n\n给定的约束条件是半宽至多为 $h$：\n$$z_{0.025} \\sqrt{\\text{Var}(\\hat{p})} \\le h$$\n$$z_{0.025} \\sqrt{\\frac{p(1-p)}{Km} [1 + (m-1)\\rho]} \\le h$$\n两边平方并解出 $K$：\n$$(z_{0.025})^2 \\frac{p(1-p)}{Km} [1 + (m-1)\\rho] \\le h^2$$\n$$K \\ge \\frac{(z_{0.025})^2 p(1-p) [1 + (m-1)\\rho]}{h^2 m}$$\n真实的误码率 $p$ 是未知的。我们使用初步运行的规划值 $\\hat{p}_0 = 0.010$ 作为 $p$ 的估计值。给定：\n- $p$ 的规划值：$\\hat{p}_0 = 0.010$\n- 数据包大小 $m = 100$\n- 相关系数 $\\rho = 0.05$\n- 最大半宽 $h = 0.001$\n- z-分数 $z_{0.025} \\approx 1.96$\n\n将这些值代入关于 $K$ 的不等式中：\n$$K \\ge \\frac{(1.96)^2 (0.010)(1-0.010) [1 + (100-1)(0.05)]}{(0.001)^2 (100)}$$\n$$K \\ge \\frac{(3.8416) (0.010)(0.99) [1 + (99)(0.05)]}{10^{-6} \\cdot 100}$$\n$$K \\ge \\frac{(3.8416) (0.0099) [1 + 4.95]}{10^{-4}}$$\n$$K \\ge \\frac{0.03803184 \\cdot [5.95]}{10^{-4}}$$\n$$K \\ge \\frac{0.226289448}{10^{-4}}$$\n$$K \\ge 2262.89448$$\n由于数据包数量 $K$ 必须是整数，我们必须取满足此条件的最小整数值，即结果的向上取整。\n$$K = \\lceil 2262.89448 \\rceil = 2263$$\n因此，需要最少 $2263$ 个数据包才能达到所需的精度。", "answer": "$$\\boxed{2263}$$", "id": "3153114"}, {"introduction": "极限理论不仅能用于分析误差，更能指导我们进行优化设计。本练习将中心极限定理从一个分析工具转变为一个设计工具，应用在计算机图形学的蒙特卡洛渲染场景中。通过解决这个问题[@problem_id:3153099]，你将学习如何根据一个固定的计算预算，最优地分配资源（采样数），以最小化整个系统中的最大不确定性。", "problem": "考虑一个计算成像任务，其中每个像素对应一个随机亮度变量，其样本是独立同分布的。对于像素索引 $i \\in \\{1,\\dots,P\\}$，设亮度样本是实值随机变量 $L_i$ 的独立抽取，其均值 $\\mu_i$ 未知，方差 $\\sigma_i^2$ 有限。像素亮度的逐像素蒙特卡洛估计值是由 $n_i$ 个样本计算出的样本均值 $\\bar{L}_{i,n_i}$。假设一个初始引导遍为每个像素提供了 $n_{0,i}$ 个样本，并从这些引导样本中得到了 $\\sigma_i^2$ 的一个无偏方差估计 $s_i^2$。我们还有一个用于最终渲染遍的总样本预算 $N_{\\text{total}}$，使得 $\\sum_{i=1}^P n_i = N_{\\text{total}}$ 且对所有 $i$ 都有 $n_i \\ge n_{0,i}$。\n\n仅使用大数定律（LLN）和中心极限定理（CLT）作为概率基础，设计一个整数样本数 $\\{n_i\\}_{i=1}^P$ 的分配规则，以在给定的置信水平 $1-\\alpha$ 下，最小化所有像素中预测的双边置信区间半宽度的最大值，并满足约束条件 $\\sum_{i=1}^P n_i = N_{\\text{total}}$ 和 $n_i \\ge n_{0,i}$。具体而言：\n\n- 根据中心极限定理，对于大的 $n_i$，$\\bar{L}_{i,n_i}$ 的分布可以近似为均值为 $\\mu_i$、方差为 $\\sigma_i^2/n_i$ 的正态分布。因此，$\\mu_i$ 的双边 $(1-\\alpha)$ 置信区间半宽度约等于 $z_{1-\\alpha/2}\\sqrt{\\sigma_i^2/n_i}$，其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$ 分位数。\n- 使用 $s_i^2$ 作为 $\\sigma_i^2$ 的置换估计，并且你的算法决策必须仅由大数定律和中心极限定理来证明其合理性（例如，像素间的可分性、凸性论证以及边际方差随 $n_i$ 减少的单调性都是可以使用的推论）。\n\n你的程序必须：\n1. 从第一性原理推导如何选择整数 $\\{n_i\\}$，以在满足约束条件 $\\sum_{i=1}^P n_i = N_{\\text{total}}$ 和 $n_i \\ge n_{0,i}$ 的情况下，最小化所有像素中预测半宽度的最大值。\n2. 使用推导出的分配 $\\{n_i\\}$，计算预测的最大半宽度值\n   $$H_{\\max} \\equiv \\max_{1 \\le i \\le P} \\left( z_{1-\\alpha/2}\\sqrt{\\frac{s_i^2}{n_i}} \\right),$$\n3. 为实现整数可行性，如果推导出的最优分配包含非整数值，请将其转换为整数，同时保持约束条件，并确保任何单一样本的重新分配都不会使目标恶化。你的方法必须基于由中心极限定理目标证明其合理性的、有原则的边际改进论证。\n\n输入通过固定的测试套件嵌入在代码中。对于每个测试用例 $t$，你会得到：逐像素方差估计 $(s_1^2,\\dots,s_P^2)$、引导样本数 $(n_{0,1},\\dots,n_{0,P})$、总预算 $N_{\\text{total}}$ 和显著性水平 $\\alpha$。对于每个测试用例，你的程序必须输出标量 $H_{\\max}$，并四舍五入到六位小数。\n\n测试套件（五个用例）：\n- 用例 A: $P=1$, $(s_1^2) = (4.0)$, $(n_{0,1}) = (0)$, $N_{\\text{total}} = 100$, $\\alpha = 0.05$。\n- 用例 B: $P=2$, $(s_1^2,s_2^2) = (1.0,1.0)$, $(n_{0,1},n_{0,2}) = (0,0)$, $N_{\\text{total}} = 100$, $\\alpha = 0.05$。\n- 用例 C: $P=2$, $(s_1^2,s_2^2) = (4.0,1.0)$, $(n_{0,1},n_{0,2}) = (0,0)$, $N_{\\text{total}} = 100$, $\\alpha = 0.05$。\n- 用例 D: $P=3$, $(s_1^2,s_2^2,s_3^2) = (4.0,1.0,0.25)$, $(n_{0,1},n_{0,2},n_{0,3}) = (5,5,5)$, $N_{\\text{total}} = 30$, $\\alpha = 0.10$。\n- 用例 E: $P=3$, $(s_1^2,s_2^2,s_3^2) = (0.0,2.25,0.25)$, $(n_{0,1},n_{0,2},n_{0,3}) = (2,2,2)$, $N_{\\text{total}} = 12$, $\\alpha = 0.01$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个逗号分隔的 Python 风格浮点数列表，按用例 A 到 E 的顺序排列，每个数字都四舍五入到六位小数并用方括号括起来。例如，一个有效的输出行格式为 $[\\text{A},\\text{B},\\text{C},\\text{D},\\text{E}]$，其中每个符号代表该用例的四舍五入值。", "solution": "该问题要求找到一个整数样本分配 $\\{n_i\\}_{i=1}^P$，以在一组 $P$ 个像素上最小化预测置信区间半宽度的最大值，同时满足总样本预算 $N_{\\text{total}}$ 和逐像素最小样本数 $\\{n_{0,i}\\}$ 的约束。这是一个基于中心极限定理（CLT）和大数定律（LLN）的极小化极大优化问题。\n\n### 第一步：优化问题的公式化\n\n问题在于确定整数样本数 $n_1, n_2, \\dots, n_P$ 以求解：\n$$\n\\begin{aligned}\n \\underset{\\{n_i\\}}{\\text{minimize}}   \\max_{1 \\le i \\le P} H_i \\\\\n \\text{subject to}   \\sum_{i=1}^P n_i = N_{\\text{total}} \\\\\n   n_i \\ge n_{0,i} \\quad \\text{for all } i \\in \\{1, \\dots, P\\} \\\\\n   n_i \\in \\mathbb{Z}^+\n\\end{aligned}\n$$\n其中 $H_i$ 是像素 $i$ 的置信区间半宽度。中心极限定理为大的 $n_i$ 提供了近似：\n$$H_i = z_{1-\\alpha/2}\\sqrt{\\frac{\\sigma_i^2}{n_i}}$$\n我们使用引导遍中的无偏方差估计 $s_i^2$ 作为真实未知方差 $\\sigma_i^2$ 的置换估计量，这种替换由大数定律证明是合理的。因此，目标函数变为：\n$$\\text{minimize} \\max_{1 \\le i \\le P} \\left( z_{1-\\alpha/2}\\sqrt{\\frac{s_i^2}{n_i}} \\right)$$\n由于对于给定的置信水平 $1-\\alpha$，$z_{1-\\alpha/2}$ 是一个正常数，因此最小化最大半宽度等价于最小化项 $\\sqrt{s_i^2/n_i}$ 的最大值，而这又等价于最小化：\n$$\\max_{1 \\le i \\le P} \\left( \\frac{s_i^2}{n_i} \\right)$$\n这一项 $s_i^2/n_i$ 代表样本均值 $\\bar{L}_{i,n_i}$ 的估计方差。\n\n### 第二步：实数值 $n_i$ 的最优分配策略\n\n解决此类极小化极大问题的核心原则是使被最大化的各项相等。为了最小化 $\\max_i(E_i)$，其中 $E_i = s_i^2/n_i$ 是资源 $n_i$ 的递减函数，当所有非零误差项都相等时，即可达到最优解：\n$$\\frac{s_1^2}{n_1} = \\frac{s_2^2}{n_2} = \\dots = \\frac{s_P^2}{n_P} = C$$\n对于某个常数 $C$（对所有 $s_i^2 > 0$ 的像素成立）。这给出了最优（实数值）分配的关系：\n$$n_i = \\frac{s_i^2}{C}$$\n这表明最优样本数 $n_i$ 与方差 $s_i^2$ 成正比。我们可以使用总预算约束 $\\sum n_i = N_{\\text{total}}$ 来找到比例常数：\n$$\\sum_{i=1}^P \\frac{s_i^2}{C} = N_{\\text{total}} \\implies \\frac{1}{C} \\sum_{i=1}^P s_i^2 = N_{\\text{total}} \\implies \\frac{1}{C} = \\frac{N_{\\text{total}}}{\\sum_{j=1}^P s_j^2}$$\n将其代回，我们得到理想的实数值分配（暂时忽略 $n_i \\ge n_{0,i}$ 约束）：\n$$n_i^* = N_{\\text{total}} \\frac{s_i^2}{\\sum_{j=1}^P s_j^2}$$\n\n### 第三步：整合最小样本约束\n\n必须整合约束 $n_i \\ge n_{0,i}$。分配 $n_i^*$ 对某些像素可能违反此约束。如果对于某个像素 $i$ 有 $n_i^*  n_{0,i}$，我们被迫为其分配至少 $n_{0,i}$ 个样本。对于这样的像素，我们将其样本数“锁定”为 $n_i = n_{0,i}$。然后根据相同的原则，在剩余的“活跃”像素中将剩余预算进行最优地重新分配。这引出了一个迭代算法：\n1.  初始化活跃像素集 $A = \\{1, \\dots, P\\}$ 和预算 $N = N_{\\text{total}}$。\n2.  在一个循环中，为所有 $i \\in A$ 计算理想分配 $n_i^{\\text{ideal}} = N \\frac{s_i^2}{\\sum_{j \\in A} s_j^2}$。\n3.  识别出满足 $n_i^{\\text{ideal}}  n_{0,i}$ 的像素集 $V \\subseteq A$。\n4.  如果 $V$ 为空，则当前对 $i \\in A$ 的分配 $n_i^{\\text{ideal}}$ 是最优的，并且满足所有最小样本数要求。最终的实数值分配已找到。\n5.  如果 $V$ 不为空，则对每个 $i \\in V$，将其分配固定为 $n_i = n_{0,i}$。从 $A$ 中移除这些像素，并将预算 $N$ 减少 $\\sum_{i \\in V} n_{0,i}$。使用更小的活跃集和减少后的预算重复此循环。\n\n这个迭代过程产生一个满足所有约束的实数值分配 $\\{n_i^{\\text{real}}\\}$。\n\n### 第四步：整数样本分配\n\n推导出的实数值分配 $\\{n_i^{\\text{real}}\\}$ 必须转换为一个总和为 $N_{\\text{total}}$ 的整数分配 $\\{n_i\\}$。一个与最小化最大误差目标相一致、有原则的方法如下：\n1.  通过对实数解取底来初始化整数分配：$n_i' = \\lfloor n_i^{\\text{real}} \\rfloor$。由于 $n_i^{\\text{real}} \\ge n_{0,i}$ 且 $n_{0,i}$ 是整数，该分配满足 $n_i' \\ge n_{0,i}$。\n2.  计算待分配的剩余样本数：$R = N_{\\text{total}} - \\sum_{i=1}^P n_i'$。\n3.  将这 $R$ 个样本逐一分配。在 $R$ 步中的每一步，将一个样本添加给当前具有最大误差项 $s_i^2/n_i'$ 的像素。这是一种贪心方法，在每一步都直接针对极小化极大目标进行处理。如果一个 $s_i^2>0$ 的像素的 $n_i'=0$，其误差为无穷大，这确保了它会优先获得样本。\n\n### 第五步：最终计算\n\n一旦确定了最终的整数分配 $\\{n_i\\}$，就通过找出所有像素中的最大误差项，并乘以相应的正态分位数来计算最大半宽度：\n$$ H_{\\max} = \\max_{1 \\le i \\le P} \\left( z_{1-\\alpha/2}\\sqrt{\\frac{s_i^2}{n_i}} \\right) = z_{1-\\alpha/2} \\sqrt{\\max_{1 \\le i \\le P} \\left(\\frac{s_i^2}{n_i}\\right)} $$\n其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$ 分位数，可使用 `scipy.stats.norm.ppf(1 - \\alpha/2)` 找到。如果一个 $s_i^2>0$ 的像素的样本数 $n_i$ 为零，其半宽度被视为无穷大；但是，如果 $N_{\\text{total}}$ 足够大，分配算法会防止这种情况发生。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main solver function to process all test cases and print the results.\n    \"\"\"\n    # Test suite (five cases): P, s^2, n_0, N_total, alpha\n    test_cases = [\n        # Case A: P=1, (s_1^2)=(4.0), (n_0,1)=(0), N_total=100, alpha=0.05\n        (1, np.array([4.0]), np.array([0]), 100, 0.05),\n        # Case B: P=2, (s_1^2,s_2^2)=(1.0,1.0), (n_0,1,n_0,2)=(0,0), N_total=100, alpha=0.05\n        (2, np.array([1.0, 1.0]), np.array([0, 0]), 100, 0.05),\n        # Case C: P=2, (s_1^2,s_2^2)=(4.0,1.0), (n_0,1,n_0,2)=(0,0), N_total=100, alpha=0.05\n        (2, np.array([4.0, 1.0]), np.array([0, 0]), 100, 0.05),\n        # Case D: P=3, (s_1^2,s_2^2,s_3^2)=(4.0,1.0,0.25), (n_0,...)=(5,5,5), N_total=30, alpha=0.10\n        (3, np.array([4.0, 1.0, 0.25]), np.array([5, 5, 5]), 30, 0.10),\n        # Case E: P=3, (s_1^2,s_2^2,s_3^2)=(0.0,2.25,0.25), (n_0,...)=(2,2,2), N_total=12, alpha=0.01\n        (3, np.array([0.0, 2.25, 0.25]), np.array([2, 2, 2]), 12, 0.01),\n    ]\n\n    results = []\n    for P, s2_vals, n0_vals, N_total, alpha in test_cases:\n        result = _calculate_max_half_width(P, s2_vals, n0_vals, N_total, alpha)\n        results.append(result)\n\n    # Format the final output string\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef _calculate_max_half_width(P, s2_vals, n0_vals, N_total, alpha):\n    \"\"\"\n    Calculates the maximum confidence interval half-width for a single test case.\n    \"\"\"\n    \n    # --- Step 1: Real-valued allocation with constraints ---\n    n_real = np.zeros(P)\n    active_indices = list(range(P))\n    budget = float(N_total)\n    \n    # Iteratively lock pixels that don't meet their minimum sample count n_0\n    for _ in range(P + 1):  # Loop guard to prevent infinite loops\n        if not active_indices:\n            break\n            \n        sum_s2_active = sum(s2_vals[i] for i in active_indices)\n        \n        # If all remaining active pixels have zero variance, their allocation is minimal.\n        if sum_s2_active == 0:\n            for i in active_indices:\n                n_real[i] = n0_vals[i]\n                budget -= n_real[i]\n            # Remaining budget for zero-variance pixels can be distributed arbitrarily.\n            # To be deterministic, we add it to the first such pixel.\n            if len(active_indices)  0 and budget  0:\n                n_real[active_indices[0]] += budget\n            break\n\n        n_ideal = {i: budget * s2_vals[i] / sum_s2_active for i in active_indices}\n        \n        violators = {i for i in active_indices if n_ideal[i]  n0_vals[i]}\n\n        if not violators:\n            for i in active_indices:\n                n_real[i] = n_ideal[i]\n            break\n        \n        newly_locked_indices = []\n        for i in violators:\n            n_real[i] = float(n0_vals[i])\n            budget -= n_real[i]\n            newly_locked_indices.append(i)\n        \n        active_indices = [i for i in active_indices if i not in newly_locked_indices]\n        \n    # --- Step 2: Convert real allocation to integer allocation ---\n    n_alloc = np.floor(n_real).astype(int)\n    \n    # Distribute remainder samples using a greedy approach\n    remainder_samples = N_total - np.sum(n_alloc)\n    \n    for _ in range(remainder_samples):\n        errors = np.zeros(P)\n        for i in range(P):\n            if s2_vals[i]  0:\n                if n_alloc[i] == 0:\n                    errors[i] = np.inf\n                else:\n                    errors[i] = s2_vals[i] / n_alloc[i]\n            else:\n                errors[i] = -np.inf # Ensure zero-variance pixels are never chosen\n\n        # Find pixel with max error to give the next sample\n        idx_to_increment = np.argmax(errors)\n        n_alloc[idx_to_increment] += 1\n        \n    # --- Step 3: Calculate the maximum half-width ---\n    z_val = norm.ppf(1 - alpha / 2.0)\n    \n    max_error_term = 0.0\n    for i in range(P):\n        # A pixel with no samples and non-zero variance would have infinite error,\n        # but the algorithm ensures this doesn't happen if N_total is sufficient.\n        if n_alloc[i]  0:\n            error_term = s2_vals[i] / n_alloc[i]\n            if error_term  max_error_term:\n                max_error_term = error_term\n    \n    h_max = z_val * np.sqrt(max_error_term)\n    return h_max\n\nsolve()\n```", "id": "3153099"}]}