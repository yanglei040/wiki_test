{"hands_on_practices": [{"introduction": "理论学习的下一步是实践。本章将通过一系列动手实践，加深您对离散和连续概率分布的理解。我们将从一个经典的物理思想实验开始：两种理想气体的混合。这个练习将向您展示，如何仅从统计力学的基本假设出发，就能自然地推导出像二项分布这样基础的离散概率分布。通过这个过程，您将学会如何将物理场景转化为概率模型，并运用组合推理来解决问题。[@problem_id:1961995]", "problem": "一个总容积为 $V$ 的刚性绝热容器被一个可移动的隔板分为两个子容积 $V_1$ 和 $V_2$。容积 $V_1$ 中含有 $N_A$ 个理想气体 A 的粒子，而容积 $V_2$ 中含有 $N_B$ 个另一种理想气体 B 的粒子。气体 A 所占的体积分数由 $\\alpha$ 给出，使得 $V_1 = \\alpha V$ 且 $V_2 = (1-\\alpha)V$，其中 $0  \\alpha  1$。\n\n最初，两种气体都处于热平衡状态。随后移开隔板，使两种气体混合，组合系统达到一个新的热力学平衡状态。基于统计力学的基本假设，推导在原为容积 $V_2$ 的空间区域内找到恰好 $n$ 个气体 A 的粒子的概率 $P(n)$ 的表达式。变量 $n$ 是一个整数，其取值范围为从 $0$ 到 $N_A$。", "solution": "移开隔板后，组合系统演化至平衡态。根据统计力学的基本假设（等概率先验），微正则测度在相空间的可及区域上是均匀的。对于一个没有粒子间相互作用且被硬壁限制在容积 $V$ 内的理想气体混合物，其哈密顿量可分离为\n$$\nH=\\sum_{i=1}^{N_{A}} \\frac{|\\mathbf{p}_{i}|^{2}}{2 m_{A}}+\\sum_{j=1}^{N_{B}} \\frac{|\\mathbf{p}'_{j}|^{2}}{2 m_{B}},\n$$\n其中所有位置都被约束在 $V$ 内。因此，在总能量固定的微正则系综中，动量和位置变量是可因式分解的。对于任何只约束空间位置的事件（例如气体 A 粒子在指定子容积中的数量），其概率与总概率之比由相应的组态空间体积之比给出；动量积分是公共因子并会消去。\n\n令 $V_{1}=\\alpha V$ 和 $V_{2}=(1-\\alpha) V$ 表示原始的子容积。在平衡状态下，每个气体 A 粒子的位置的边际分布在 $V$ 上是均匀的。因此，任意一个 A 粒子位于 $V_{2}$ 内的概率是 $V_{2}/V=1-\\alpha$，位于 $V_{1}$ 内的概率是 $V_{1}/V=\\alpha$。因为粒子是无相互作用的，$N_{A}$ 个位置上的联合分布可以因式分解，因此可以等价地通过计算组态空间体积来计算概率。\n\n将 $P(n)$ 计算为组态空间测度之比。为明确起见，在计数过程中将气体 A 粒子视为可区分的（不可区分性的吉布斯因子在最终的比率中会消去）。$N_{A}$ 个位置的总组态空间体积是 $V^{N_{A}}$。$N_{A}$ 个 A 粒子中恰好有 $n$ 个位于 $V_{2}$ 内，其余 $N_{A}-n$ 个位于 $V_{1}$ 内所对应的组态空间体积为\n$$\n\\binom{N_{A}}{n} V_{2}^{n} V_{1}^{N_{A}-n},\n$$\n其中二项式系数计算了哪 $n$ 个粒子位于 $V_{2}$ 内的选择方式。因此，\n$$\nP(n)=\\frac{\\binom{N_{A}}{n} V_{2}^{n} V_{1}^{N_{A}-n}}{V^{N_{A}}}\n=\\binom{N_{A}}{n} \\left(\\frac{V_{2}}{V}\\right)^{n} \\left(\\frac{V_{1}}{V}\\right)^{N_{A}-n}.\n$$\n代入 $V_{1}=\\alpha V$ 和 $V_{2}=(1-\\alpha) V$ 可得\n$$\nP(n)=\\binom{N_{A}}{n} (1-\\alpha)^{n} \\alpha^{N_{A}-n},\n$$\n对所有满足 $0 \\leq n \\leq N_{A}$ 的整数 $n$ 均成立。气体 B 的存在只对相空间体积贡献一个乘法因子，该因子在概率比中被消去，因此对于理想混合物，$P(n)$ 与 $N_{B}$ 无关。", "answer": "$$\\boxed{\\binom{N_{A}}{n} (1-\\alpha)^{n} \\alpha^{N_{A}-n}}$$", "id": "1961995"}, {"introduction": "许多物理过程在特定极限下会从离散行为过渡到连续行为，理解这一转变至关重要。本练习以天体物理学中常见的光子计数为例，介绍了泊松分布，并探讨了在何种条件下可以用连续的高斯分布来近似它。这项实践旨在培养评估近似方法有效性的能力，这在计算科学中是一项关键技能，因为我们经常需要在准确性和效率之间做出权衡。[@problem_id:1896384]", "problem": "一位天体物理学家正在分析来自空间望远镜的图像。在一个短暂的固定曝光时间内，望远镜的电荷耦合器件（CCD）的单个像素收集到的光子数 $k$ 服从泊松分布 $P(k;\\lambda) = \\frac{\\lambda^k e^{-\\lambda}}{k!}$，其中 $\\lambda$ 是曝光期间预期的平均光子数。\n\n为了规划 $\\lambda$ 预期较大的较长观测，在计算上通常使用均值为 $\\mu = \\lambda$、方差为 $\\sigma^2 = \\lambda$ 的连续高斯（正态）分布来近似离散的泊松分布，这样做很方便。检验此近似有效性的一个常用快速方法是比较最可能事件的概率。对于整数均值 $\\lambda$，最可能探测到的光子数是 $k=\\lambda$。来自连续模型的相应近似值是从高斯分布在其峰值处的概率密度 $f(x=\\lambda)$ 推导出来的，其值为 $f(\\lambda) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} = \\frac{1}{\\sqrt{2\\pi\\lambda}}$。这个值近似于观测到恰好 $k=\\lambda$ 个光子的概率。\n\n请确定平均光子数 $\\lambda$ 的最小整数值，使得 $P(k=\\lambda; \\lambda)$ 的高斯峰值近似的相对误差小于 1.0%。相对误差定义为 $\\frac{|P_{approx} - P_{exact}|}{P_{exact}}$，其中 $P_{exact} = P(k=\\lambda; \\lambda)$ 且 $P_{approx} = \\frac{1}{\\sqrt{2\\pi\\lambda}}$。", "solution": "我们需要找到最小的整数 $\\lambda$，使得 $P(k=\\lambda;\\lambda)$ 的高斯峰值近似 $P_{\\text{approx}}=1/\\sqrt{2\\pi\\lambda}$ 与精确的泊松概率 $P_{\\text{exact}}=\\lambda^{\\lambda}e^{-\\lambda}/\\lambda!$ 相比，其相对误差小于 $0.01$。\n\n$P_{\\text{exact}}$ 可以使用斯特林公式进行近似，该公式给出了 $n!$ 的一个渐近展开。一个带严格余项的常用形式是罗宾斯界（Robbins' bounds）：\n$$ n! = \\sqrt{2\\pi n}\\left(\\frac{n}{e}\\right)^{n} e^{r_{n}}, \\quad \\text{其中 } \\frac{1}{12n+1}  r_n  \\frac{1}{12n} $$\n将这个公式代入 $P_{\\text{exact}}$ 的表达式中：\n$$ P_{\\text{exact}}(\\lambda) = \\frac{\\lambda^\\lambda e^{-\\lambda}}{\\lambda!} = \\frac{\\lambda^\\lambda e^{-\\lambda}}{\\sqrt{2\\pi\\lambda}(\\lambda/e)^\\lambda e^{r_\\lambda}} = \\frac{1}{\\sqrt{2\\pi\\lambda}} e^{-r_\\lambda} $$\n相对误差为：\n$$ \\text{相对误差} = \\frac{|P_{\\text{approx}} - P_{\\text{exact}}|}{P_{\\text{exact}}} = \\frac{|1/\\sqrt{2\\pi\\lambda} - (1/\\sqrt{2\\pi\\lambda})e^{-r_\\lambda}|}{(1/\\sqrt{2\\pi\\lambda})e^{-r_\\lambda}} = |e^{r_\\lambda} - 1| $$\n由于 $r_\\lambda$ 是一个小的正数，我们可以用泰勒展开 $e^x \\approx 1+x$ 来近似这个误差，得到相对误差 $\\approx r_\\lambda$。我们需要找到最小的整数 $\\lambda$ 使得 $|e^{r_\\lambda} - 1|  0.01$。\n由于 $r_\\lambda > 0$，这等价于 $e^{r_\\lambda}  1.01$，即 $r_\\lambda  \\ln(1.01) \\approx 0.00995$。\n利用罗宾斯界，我们知道 $r_\\lambda  1/(12\\lambda)$。因此，我们需要满足 $1/(12\\lambda)  0.00995$。\n$$ 12\\lambda > \\frac{1}{0.00995} \\approx 100.5 $$\n$$ \\lambda > \\frac{100.5}{12} \\approx 8.375 $$\n由于我们需要一个整数值，第一个满足条件的 $\\lambda$ 是 9。\n\n让我们直接检验 $\\lambda=8$ 和 $\\lambda=9$ 的值来确认。\n对于 $\\lambda=8$：\n$P_{\\text{exact}} = 8^8 e^{-8} / 8! \\approx 0.13959$\n$P_{\\text{approx}} = 1/\\sqrt{16\\pi} \\approx 0.14105$\n相对误差 = $|0.14105 - 0.13959| / 0.13959 \\approx 1.046\\%$，这大于 1%。\n\n对于 $\\lambda=9$：\n$P_{\\text{exact}} = 9^9 e^{-9} / 9! \\approx 0.13176$\n$P_{\\text{approx}} = 1/\\sqrt{18\\pi} \\approx 0.13298$\n相对误差 = $|0.13298 - 0.13176| / 0.13176 \\approx 0.926\\%$，这小于 1%。\n\n因此，满足条件的最小整数 $\\lambda$ 是 9。", "answer": "$$\\boxed{9}$$", "id": "1896384"}, {"introduction": "理论的价值最终体现在其应用和验证中。最后的这个实践将带您把理论付诸于代码，通过编程来检验二项分布的正态近似。您不仅会实现这一近似，还将学习并应用“连续性校正”这一重要技巧，以提高近似的精度。这个动手编码练习将帮助您巩固对近似理论的理解，并建立在数值验证和误差分析方面的实用技能。[@problem_id:3119292]", "problem": "给定独立同分布的伯努利随机变量 $Y_1, Y_2, \\dots, Y_n$，其参数为 $p$，即 $Y_i \\in \\{0,1\\}$ 且 $\\mathbb{P}(Y_i = 1) = p$。定义二项计数 $X = \\sum_{i=1}^{n} Y_i$。从核心定义 $\\mathbb{E}[Y_i] = p$、$\\mathrm{Var}(Y_i) = p(1-p)$ 和中心极限定理 (CLT) 出发，用文字推导使用正态分布对累积分布函数 $\\mathbb{P}(X \\leq k)$ 进行连续近似的方法，包括不使用和使用连续性校正两种情况。实现一个程序，用数值方法验证这些近似值与精确的二项累积分布函数的对比情况。\n\n你的程序必须：\n\n1. 使用二项分布的解析精确方法计算精确的累积概率 $\\mathbb{P}(X \\leq k)$。\n2. 计算 $\\mathbb{P}(X \\leq k)$ 的两种正态近似：\n   - 一种基于中心极限定理（CLT）且不带连续性校正的直接近似。\n   - 一种带连续性校正的近似，通过在应用连续模型前将离散阈值移至半整数实现。\n3. 使用固定的随机种子和固定次数的蒙特卡洛试验，模拟二项计数以经验地估计 $\\mathbb{P}(X \\leq k)$。使用 $N_{\\text{sim}} = 100000$ 次试验和种子 $12345$，以确保模拟是可复现的。此模拟仅用于说明目的；下文的验收检查必须将近似值与精确的二项分布解析概率进行比较。\n4. 对于每个测试用例，计算两种正态近似相对于精确二项累积概率的绝对误差。设容差为 $\\tau = 0.02$。为每个用例生成三个布尔值：\n   - 未使用连续性校正的误差是否最多为 $\\tau$。\n   - 使用了连续性校正的误差是否最多为 $\\tau$。\n   - 使用了连续性校正的误差是否小于或等于未使用连续性校正的误差。\n\n测试套件：\n使用以下 $(n,p,k)$ 用例来测试一系列情况（大 $n$ 和小 $p$、接近均值的阈值以及边界条件）：\n- 用例 1: $(n=1000,\\; p=0.01,\\; k=0)$。\n- 用例 2: $(n=1000,\\; p=0.01,\\; k=12)$。\n- 用例 3: $(n=10000,\\; p=0.001,\\; k=20)$。\n- 用例 4: $(n=500,\\; p=0.02,\\; k=15)$。\n- 用例 5: $(n=200,\\; p=0.001,\\; k=0)$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须是按测试用例顺序，将每个用例的三个布尔值扁平化拼接而成：$[$无校正通过, 连续性校正通过, 改进$]$（用例1），然后是用例2的同样三元组，依此类推。例如，一个包含五个用例的运行结果将如下所示：\n$[$b$_{1,1}$, b$_{1,2}$, b$_{1,3}$, b$_{2,1}$, b$_{2,2}$, b$_{2,3}$, \\dots, b$_{5,1}$, b$_{5,2}$, b$_{5,3}]$，\n其中每个 $b_{i,j}$ 都是一个布尔值。", "solution": "该问题要求推导二项分布的正态近似（包括使用和不使用连续性校正两种情况），并对这些近似值与精确值进行数值验证。推导过程将从伯努利变量的基本性质和中心极限定理（CLT）出发。\n\n一个二项随机变量 $X$ 表示在 $n$ 次独立试验中的总成功次数，其中每次试验的成功概率为 $p$。它被定义为 $n$ 个独立同分布（i.i.d.）的伯努利随机变量 $Y_1, Y_2, \\dots, Y_n$ 的和。\n$$X = \\sum_{i=1}^{n} Y_i$$\n每个 $Y_i$ 以概率 $p$ 取值为 1（成功），或以概率 $1-p$ 取值为 0（失败）。问题给出了单次伯努利试验的期望和方差：\n- 期望：$\\mathbb{E}[Y_i] = 1 \\cdot p + 0 \\cdot (1-p) = p$\n- 方差：$\\mathrm{Var}(Y_i) = \\mathbb{E}[Y_i^2] - (\\mathbb{E}[Y_i])^2 = (1^2 \\cdot p + 0^2 \\cdot (1-p)) - p^2 = p - p^2 = p(1-p)$\n\n由于期望的线性性质以及变量在方差求和时的独立性，二项随机变量 $X$ 的期望和方差为：\n- $X$ 的期望：$\\mu = \\mathbb{E}[X] = \\mathbb{E}\\left[\\sum_{i=1}^{n} Y_i\\right] = \\sum_{i=1}^{n} \\mathbb{E}[Y_i] = \\sum_{i=1}^{n} p = np$\n- $X$ 的方差：$\\sigma^2 = \\mathrm{Var}(X) = \\mathrm{Var}\\left(\\sum_{i=1}^{n} Y_i\\right) = \\sum_{i=1}^{n} \\mathrm{Var}(Y_i) = \\sum_{i=1}^{n} p(1-p) = np(1-p)$\n\n中心极限定理（CLT）指出，对于足够大量的独立同分布随机变量，它们的和（或平均值）将近似服从正态分布。将中心极限定理应用于 $X$，我们可以用一个具有相同均值 $\\mu = np$ 和方差 $\\sigma^2 = np(1-p)$ 的正态分布来近似其分布。设此近似正态变量为 $X_{norm} \\sim \\mathcal{N}(np, np(1-p))$。$X$ 的标准化版本是 $Z = \\frac{X - \\mu}{\\sigma} = \\frac{X - np}{\\sqrt{np(1-p)}}$，当 $n \\to \\infty$ 时，它在分布上收敛于标准正态分布 $\\mathcal{N}(0,1)$。\n\n我们希望近似二项分布的累积分布函数（CDF），即 $\\mathbb{P}(X \\leq k) = \\sum_{j=0}^{k} \\mathbb{P}(X=j)$。\n\n**1. 不使用连续性校正的正态近似**\n\n这是中心极限定理最直接的应用。我们用连续的正态变量 $X_{norm}$ 来近似离散的二项变量 $X$。概率 $\\mathbb{P}(X \\leq k)$ 近似为 $\\mathbb{P}(X_{norm} \\leq k)$。为计算此概率，我们对变量进行标准化：\n$$ \\mathbb{P}(X \\leq k) \\approx \\mathbb{P}(X_{norm} \\leq k) = \\mathbb{P}\\left(\\frac{X_{norm} - \\mu}{\\sigma} \\leq \\frac{k - \\mu}{\\sigma}\\right) = \\mathbb{P}\\left(Z \\leq \\frac{k - np}{\\sqrt{np(1-p)}}\\right) $$\n此概率由标准正态分布的累积分布函数给出，记为 $\\Phi(z)$。\n$$ \\mathbb{P}(X \\leq k) \\approx \\Phi\\left(\\frac{k - np}{\\sqrt{np(1-p)}}\\right) $$\n\n**2. 使用连续性校正的正态近似**\n\n此方法通过考虑我们正在使用连续分布来建模离散分布这一事实，提供了一种更精确的近似。二项分布的概率质量函数（PMF）仅在整数值上有定义。一种常见的可视化方式是直方图，其中概率 $\\mathbb{P}(X=j)$ 由一个以整数 $j$ 为中心、宽度为 1 的条形表示。这个条形覆盖了区间 $[j-0.5, j+0.5]$。\n累积概率 $\\mathbb{P}(X \\leq k)$ 是从 0 到 $k$ 的所有整数的概率之和。在直方图表示中，这对应于 $j=0, 1, \\dots, k$ 的条形的总面积。这些条形覆盖的总区域在连续轴上延伸至 $k+0.5$。\n因此，为了更好地近似这个和，我们将正态概率密度函数积分至 $k+0.5$。\n$$ \\mathbb{P}(X \\leq k) = \\sum_{j=0}^{k} \\mathbb{P}(X=j) \\approx \\mathbb{P}(X_{norm} \\leq k+0.5) $$\n对这个校正后的值进行标准化，得到带连续性校正的近似值：\n$$ \\mathbb{P}(X \\leq k) \\approx \\mathbb{P}\\left(Z \\leq \\frac{(k+0.5) - np}{\\sqrt{np(1-p)}}\\right) = \\Phi\\left(\\frac{k+0.5 - np}{\\sqrt{np(1-p)}}\\right) $$\n这种校正通常会提高正态近似的准确性，特别是当 $n$ 不是非常大或者 $p$ 接近 0 或 1 时。\n\n**3. 数值验证**\n\n程序将为每个测试用例 $(n,p,k)$ 实现以下计算：\n- **精确的二项分布CDF**：$\\mathbb{P}(X \\leq k) = \\sum_{j=0}^{k} \\binom{n}{j} p^j (1-p)^{n-j}$，使用 `scipy.stats.binom.cdf` 计算。\n- **正态近似（无连续性校正）**：$\\Phi\\left(\\frac{k - np}{\\sqrt{np(1-p)}}\\right)$，使用 `scipy.stats.norm.cdf` 计算。\n- **正态近似（有连续性校正）**：$\\Phi\\left(\\frac{k+0.5 - np}{\\sqrt{np(1-p)}}\\right)$，使用 `scipy.stats.norm.cdf` 计算。\n- **蒙特卡洛模拟**：通过从参数为 $n$ 和 $p$ 的二项分布中生成 $N_{\\text{sim}} = 100000$ 个样本，然后计算小于或等于 $k$ 的样本比例，来获得经验估计。这仅用于说明目的。\n- **误差分析**：计算两种正态近似相对于精确二项CDF的绝对误差。将这些误差与容差 $\\tau = 0.02$ 进行比较，以确定每种近似是否可接受。同时还会检查连续性校正是否带来了改进（即误差更小或相等）。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import binom, norm\n\ndef solve():\n    \"\"\"\n    Validates normal approximations to the binomial distribution.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, p, k)\n        (1000, 0.01, 0),\n        (1000, 0.01, 12),\n        (10000, 0.001, 20),\n        (500, 0.02, 15),\n        (200, 0.001, 0),\n    ]\n\n    # Constants for simulation and validation\n    N_sim = 100000\n    seed = 12345\n    tau = 0.02\n    \n    # Initialize a random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n    \n    results = []\n    for case in test_cases:\n        n, p, k = case\n        \n        # Calculate mean and standard deviation of the binomial distribution\n        mu = n * p\n        sigma_sq = n * p * (1 - p)\n\n        # 1. Compute the exact cumulative probability P(X = k)\n        exact_prob = binom.cdf(k, n, p)\n\n        # 2. Compute normal approximations\n        # Handle the edge case where variance is zero (p=0 or p=1),\n        # though not present in the test suite.\n        if sigma_sq > 0:\n            sigma = np.sqrt(sigma_sq)\n            \n            # 2a. Direct approximation without continuity correction\n            z_no_cc = (k - mu) / sigma\n            approx_no_cc = norm.cdf(z_no_cc)\n            \n            # 2b. Approximation with continuity correction\n            z_cc = (k + 0.5 - mu) / sigma\n            approx_cc = norm.cdf(z_cc)\n        else:\n            # If sigma is 0, the distribution is deterministic.\n            # X = mu with probability 1. The CDF is a step function.\n            approx_no_cc = 1.0 if k >= mu else 0.0\n            approx_cc = 1.0 if k + 0.5 >= mu else 0.0\n        \n        # 3. Simulate binomial counts to estimate P(X = k) empirically (for illustration)\n        # This part is required by the prompt but its result is not used in the final checks.\n        sim_samples = rng.binomial(n, p, size=N_sim)\n        mc_prob = np.mean(sim_samples = k)\n\n        # 4. Compute absolute errors and perform validation checks.\n        # The checks compare the approximations against the exact analytical probability.\n        err_no_cc = abs(approx_no_cc - exact_prob)\n        err_cc = abs(approx_cc - exact_prob)\n        \n        # Boolean check 1: Is error without correction within tolerance?\n        no_cc_pass = err_no_cc = tau\n        \n        # Boolean check 2: Is error with correction within tolerance?\n        cc_pass = err_cc = tau\n        \n        # Boolean check 3: Is continuity correction an improvement?\n        cc_improves = err_cc = err_no_cc\n        \n        results.extend([no_cc_pass, cc_pass, cc_improves])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3119292"}]}