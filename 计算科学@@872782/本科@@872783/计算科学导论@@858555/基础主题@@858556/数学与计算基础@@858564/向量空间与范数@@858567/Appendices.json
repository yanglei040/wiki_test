{"hands_on_practices": [{"introduction": "我们习惯于在欧几里得空间中测量点与点之间的距离。但是，我们如何衡量更抽象的对象（例如函数）之间的“距离”呢？本练习将引导你使用 $L_1$ 范数来解决这个问题，它通过对区间上的绝对差进行积分来量化两个连续函数之间的差异。通过这个实践 [@problem_id:2308541]，你将把对距离的直观理解从有限维向量空间扩展到无限维的函数空间，这对于理解科学和工程中的许多高级概念至关重要。", "problem": "在泛函分析领域，我们可以用多种方式来衡量函数之间的“距离”。考虑向量空间 $C[0,1]$，它由所有定义在闭区间 $[0, 1]$ 上的连续实值函数组成。\n\n定义距离的一种常用方法是使用 $L_1$ 范数。对于 $C[0,1]$ 中的任意函数 $f(x)$，其 $L_1$ 范数（记作 $\\|f\\|_1$）定义为：\n$$\n\\|f\\|_1 = \\int_{0}^{1} |f(x)| dx\n$$\n在此空间中，两个函数 $p(x)$ 和 $q(x)$ 之间的距离则由它们差的范数给出，即 $d(p, q) = \\|p - q\\|_1$。\n\n计算在空间 $C[0,1]$ 中，函数 $p(x) = x$ 和常数函数 $q(x) = \\frac{1}{2}$ 之间关于 $L_1$ 范数的确切距离。将答案表示为最简分数。", "solution": "给定在 $[0,1]$ 上的函数 $p(x)=x$ 和 $q(x)=\\frac{1}{2}$。$L_{1}$ 距离是\n$$\nd(p,q)=\\|p-q\\|_{1}=\\int_{0}^{1}|p(x)-q(x)|\\,dx=\\int_{0}^{1}\\left|x-\\frac{1}{2}\\right|\\,dx.\n$$\n绝对值在 $x=\\frac{1}{2}$ 处分开，当 $x\\in[0,\\frac{1}{2}]$ 时，$\\left|x-\\frac{1}{2}\\right|=\\frac{1}{2}-x$；当 $x\\in[\\frac{1}{2},1]$ 时，$\\left|x-\\frac{1}{2}\\right|=x-\\frac{1}{2}$。因此，\n$$\n\\int_{0}^{1}\\left|x-\\frac{1}{2}\\right|\\,dx=\\int_{0}^{\\frac{1}{2}}\\left(\\frac{1}{2}-x\\right)\\,dx+\\int_{\\frac{1}{2}}^{1}\\left(x-\\frac{1}{2}\\right)\\,dx.\n$$\n分别计算每个积分。对于第一个积分，\n$$\n\\int_{0}^{\\frac{1}{2}}\\left(\\frac{1}{2}-x\\right)\\,dx=\\left[\\frac{1}{2}x-\\frac{x^{2}}{2}\\right]_{0}^{\\frac{1}{2}}=\\left(\\frac{1}{2}\\cdot\\frac{1}{2}-\\frac{\\left(\\frac{1}{2}\\right)^{2}}{2}\\right)-0=\\frac{1}{4}-\\frac{1}{8}=\\frac{1}{8}.\n$$\n对于第二个积分，\n$$\n\\int_{\\frac{1}{2}}^{1}\\left(x-\\frac{1}{2}\\right)\\,dx=\\left[\\frac{x^{2}}{2}-\\frac{1}{2}x\\right]_{\\frac{1}{2}}^{1}=\\left(\\frac{1}{2}-\\frac{1}{2}\\right)-\\left(\\frac{\\left(\\frac{1}{2}\\right)^{2}}{2}-\\frac{1}{2}\\cdot\\frac{1}{2}\\right)=0-\\left(\\frac{1}{8}-\\frac{1}{4}\\right)=\\frac{1}{8}.\n$$\n将它们相加得到\n$$\n\\int_{0}^{1}\\left|x-\\frac{1}{2}\\right|\\,dx=\\frac{1}{8}+\\frac{1}{8}=\\frac{1}{4}.\n$$\n因此，确切的 $L_{1}$ 距离是 $\\frac{1}{4}$。", "answer": "$$\\boxed{\\frac{1}{4}}$$", "id": "2308541"}, {"introduction": "当我们学会了使用范数来衡量向量的“大小”后，一个自然而然的问题是：一个矩阵最多能将一个向量“拉伸”或“压缩”多少？这个问题 [@problem_id:3201809] 将带你探索矩阵的诱导范数（$\\|A\\|_p$），它衡量了矩阵作用于单位向量时可能产生的最大缩放因子。你将计算并比较同一个矩阵在三种最常见的范数（$p=1, 2, \\infty$）下的“大小”，并揭示这些数值如何直接关联到误差分析和迭代算法稳定性的判断等实际应用中。", "problem": "考虑由矩阵 $A \\in \\mathbb{R}^{2 \\times 2}$ 表示的线性变换，该变换作用于具有通常 $p$-范数的向量空间 $\\mathbb{R}^2$，其中\n$$\nA = \\begin{pmatrix}\n2  -1 \\\\\n1  3\n\\end{pmatrix}.\n$$\n设 $x = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$，并考虑缩放矩阵 $B = \\alpha A$，其中 $\\alpha = 0.26$。\n\n您的任务是评估以下关于 $p \\in \\{1,2,\\infty\\}$ 的诱导矩阵范数、$\\|Ax\\|_p$ 的界以及迭代 $x_{k+1} = B x_k$ 的稳定性的陈述。请选择所有正确的陈述。\n\nA. $A$ 的诱导 1-范数和 $\\infty$-范数均为 $4$，且 $A$ 的诱导 2-范数等于 $\\sqrt{\\dfrac{15 + \\sqrt{29}}{2}}$。\n\nB. 对于给定的 $x$，比值 $\\dfrac{\\|Ax\\|_1}{\\|x\\|_1}$ 等于 $\\dfrac{5}{2}$ 且不超过 $\\|A\\|_1$。\n\nC. 对于迭代 $x_{k+1} = B x_k$（其中 $B = \\alpha A$ 且 $\\alpha = 0.26$），该映射在 2-范数下是压缩映射，但在 1-范数或 $\\infty$-范数下不是压缩映射。\n\nD. 对于给定的 $x$，在 $p \\in \\{1,2,\\infty\\}$ 的界 $\\|Ax\\|_p \\le \\|A\\|_p \\|x\\|_p$ 中，最紧的上界（最小的右侧值）在 $p = \\infty$ 时达到。\n\nE. 对于任意矩阵 $A$，总有 $\\|A\\|_2 \\ge \\|A\\|_\\infty$。\n\nF. 对于给定的 $x$，在 $\\|Ax\\|_2 \\le \\|A\\|_2 \\|x\\|_2$ 中等号成立。", "solution": "我们从向量范数和诱导矩阵范数的基本定义出发。$\\mathbb{R}^n$ 上的向量 $p$-范数定义为\n$$\n\\|x\\|_p = \\left( \\sum_{i=1}^n |x_i|^p \\right)^{1/p} \\quad \\text{对于 } p \\in [1,\\infty), \\quad \\text{以及} \\quad \\|x\\|_\\infty = \\max_{1 \\le i \\le n} |x_i|.\n$$\n与向量范数 $\\|\\cdot\\|_p$ 对应的诱导（算子）矩阵范数定义为\n$$\n\\|A\\|_p = \\sup_{x \\ne 0} \\frac{\\|Ax\\|_p}{\\|x\\|_p} = \\sup_{\\|x\\|_p = 1} \\|Ax\\|_p.\n$$\n这些范数满足齐次性、三角不等式和次可乘性。对于 $p = \\infty$ 和 $p = 1$，我们可以利用三角不等式推导出显式形式；对于 $p = 2$，我们使用对称矩阵 $A^\\top A$ 的 Rayleigh 商。\n\n步骤 1：从基本原理计算 $\\|A\\|_\\infty$、$\\|A\\|_1$ 和 $\\|A\\|_2$。\n\n- 对于 $p = \\infty$，我们有对于任意满足 $\\|x\\|_\\infty = 1$ 的 $x$，\n$$\n\\|Ax\\|_\\infty = \\max_i \\left| \\sum_j a_{ij} x_j \\right| \\le \\max_i \\sum_j |a_{ij}| \\cdot |x_j| \\le \\max_i \\sum_j |a_{ij}| \\cdot \\|x\\|_\\infty = \\max_i \\sum_j |a_{ij}|.\n$$\n等号可以通过选择一个分量 $x_j$ 与达到最大值的行元素的符号相匹配的向量 $x$ 来取得。因此，\n$$\n\\|A\\|_\\infty = \\max_{1 \\le i \\le n} \\sum_{j=1}^n |a_{ij}|.\n$$\n对于 $A = \\begin{pmatrix} 2  -1 \\\\ 1  3 \\end{pmatrix}$，绝对值行和为：第 1 行: $|2| + |-1| = 3$，第 2 行: $|1| + |3| = 4$。因此\n$$\n\\|A\\|_\\infty = 4.\n$$\n\n- 对于 $p = 1$，使用类似的推导，\n$$\n\\|Ax\\|_1 = \\sum_i \\left| \\sum_j a_{ij} x_j \\right| \\le \\sum_i \\sum_j |a_{ij}| |x_j| = \\sum_j \\left( \\sum_i |a_{ij}| \\right) |x_j| \\le \\left( \\max_j \\sum_i |a_{ij}| \\right) \\sum_j |x_j| = \\left( \\max_j \\sum_i |a_{ij}| \\right) \\|x\\|_1,\n$$\n等号可以通过选择一个仅在达到最大值的列上具有非零分量的 $x$ 来取得。因此，\n$$\n\\|A\\|_1 = \\max_{1 \\le j \\le n} \\sum_{i=1}^n |a_{ij}|.\n$$\n对于 $A$，绝对值列和为：第 1 列: $|2| + |1| = 3$，第 2 列: $|-1| + |3| = 4$。因此\n$$\n\\|A\\|_1 = 4.\n$$\n\n- 对于 $p = 2$，根据定义，\n$$\n\\|A\\|_2 = \\sup_{\\|x\\|_2 = 1} \\|Ax\\|_2 = \\sup_{\\|x\\|_2 = 1} \\sqrt{ x^\\top A^\\top A x }.\n$$\n对于一个对称矩阵 $M$，在单位向量上 $x^\\top M x$ 的最大值等于其最大特征值。令 $M = A^\\top A$，我们计算\n$$\nA^\\top A =\n\\begin{pmatrix}\n2  1 \\\\\n-1  3\n\\end{pmatrix}\n\\begin{pmatrix}\n2  -1 \\\\\n1  3\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n5  1 \\\\\n1  10\n\\end{pmatrix}.\n$$\n特征多项式为 $\\lambda^2 - (5 + 10)\\lambda + (5 \\cdot 10 - 1 \\cdot 1) = \\lambda^2 - 15 \\lambda + 49$。特征值为\n$$\n\\lambda_{\\max} = \\frac{15 + \\sqrt{29}}{2}, \\quad \\lambda_{\\min} = \\frac{15 - \\sqrt{29}}{2}.\n$$\n因此，\n$$\n\\|A\\|_2 = \\sqrt{\\lambda_{\\max}} = \\sqrt{ \\frac{15 + \\sqrt{29}}{2} } \\approx 3.192.\n$$\n\n步骤 2：对于给定的 $x = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$，计算 $\\|Ax\\|_p$ 和其界。\n\n计算 $Ax$：\n$$\nAx = \\begin{pmatrix}\n2  -1 \\\\\n1  3\n\\end{pmatrix}\n\\begin{pmatrix}\n1 \\\\\n-1\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n2 \\cdot 1 + (-1) \\cdot (-1) \\\\\n1 \\cdot 1 + 3 \\cdot (-1)\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n3 \\\\\n-2\n\\end{pmatrix}.\n$$\n计算范数：\n$$\n\\|x\\|_1 = |1| + |-1| = 2, \\quad \\|x\\|_2 = \\sqrt{1^2 + (-1)^2} = \\sqrt{2}, \\quad \\|x\\|_\\infty = \\max\\{ |1|, |-1| \\} = 1.\n$$\n$$\n\\|Ax\\|_1 = |3| + |-2| = 5, \\quad \\|Ax\\|_2 = \\sqrt{3^2 + (-2)^2} = \\sqrt{13} \\approx 3.606, \\quad \\|Ax\\|_\\infty = \\max\\{ |3|, |-2| \\} = 3.\n$$\n相应的上界 $\\|A\\|_p \\|x\\|_p$ 是\n$$\np = 1: \\quad \\|A\\|_1 \\|x\\|_1 = 4 \\cdot 2 = 8,\n$$\n$$\np = 2: \\quad \\|A\\|_2 \\|x\\|_2 = \\sqrt{ \\frac{15 + \\sqrt{29}}{2} } \\cdot \\sqrt{2} = \\sqrt{ 15 + \\sqrt{29} } \\approx 4.514,\n$$\n$$\np = \\infty: \\quad \\|A\\|_\\infty \\|x\\|_\\infty = 4 \\cdot 1 = 4.\n$$\n在这些上界中，最小的上界是当 $p = \\infty$ 时取得的，其值为 4。\n\n步骤 3：对于 $B = \\alpha A$（其中 $\\alpha = 0.26$）的稳定性和压缩性。\n\n根据诱导范数的齐次性，\n$$\n\\|B\\|_p = \\|\\alpha A\\|_p = |\\alpha| \\|A\\|_p.\n$$\n因此，\n$$\n\\|B\\|_\\infty = 0.26 \\cdot 4 = 1.04, \\quad \\|B\\|_1 = 0.26 \\cdot 4 = 1.04, \\quad \\|B\\|_2 = 0.26 \\cdot \\sqrt{ \\frac{15 + \\sqrt{29}}{2} } \\approx 0.26 \\cdot 3.192 \\approx 0.830.\n$$\n线性迭代 $x_{k+1} = B x_k$ 在 $p$-范数下是压缩的，当且仅当 $\\|B\\|_{p}  1$，因为对于任意 $x,y$，\n$$\n\\|B x - B y\\|_p = \\|B (x - y)\\|_p \\le \\|B\\|_p \\|x - y\\|_p,\n$$\n该映射将距离以一个至多为 $c = \\|B\\|_p  1$ 的因子进行缩减。因此，根据上述数值，该迭代在 2-范数下是压缩的（因为 $0.830  1$），但在 1-范数或 $\\infty$-范数下不是压缩的（因为在这两种情况下 $1.04 > 1$）。\n\n步骤 4：条件数（用于线性系统的稳定性保证）和跨范数的比较。\n\n为了之后完整地评估选项陈述，回顾一下，在给定的诱导范数下的条件数定义为\n$$\n\\kappa_p(A) = \\|A\\|_p \\|A^{-1}\\|_p.\n$$\n对于 2-范数，$\\|A^{-1}\\|_2 = 1 / \\sigma_{\\min}(A)$，其中 $\\sigma_{\\min}(A) = \\sqrt{ \\lambda_{\\min}(A^\\top A) }$ 是最小奇异值。对于我们的矩阵 $A$，\n$$\n\\sigma_{\\max}(A) = \\sqrt{ \\lambda_{\\max} } = \\sqrt{ \\frac{15 + \\sqrt{29}}{2} } \\approx 3.192,\n$$\n$$\n\\sigma_{\\min}(A) = \\sqrt{ \\lambda_{\\min} } = \\sqrt{ \\frac{15 - \\sqrt{29}}{2} } \\approx \\sqrt{4.8075} \\approx 2.193,\n$$\n所以\n$$\n\\|A^{-1}\\|_2 = \\frac{1}{\\sigma_{\\min}(A)} \\approx \\frac{1}{2.193} \\approx 0.456, \\quad \\kappa_2(A) = \\frac{\\sigma_{\\max}(A)}{\\sigma_{\\min}(A)} \\approx \\frac{3.192}{2.193} \\approx 1.455.\n$$\n对于 1-范数和 $\\infty$-范数，我们显式计算 $A^{-1}$：\n$$\n\\det(A) = 2 \\cdot 3 - (-1) \\cdot 1 = 6 + 1 = 7, \\quad\nA^{-1} = \\frac{1}{7} \\begin{pmatrix} 3  1 \\\\ -1  2 \\end{pmatrix}.\n$$\n然后\n$$\n\\|A^{-1}\\|_\\infty = \\max \\left\\{ \\frac{|3| + |1|}{7}, \\frac{|-1| + |2|}{7} \\right\\} = \\max \\left\\{ \\frac{4}{7}, \\frac{3}{7} \\right\\} = \\frac{4}{7} \\approx 0.5714,\n$$\n$$\n\\|A^{-1}\\|_1 = \\max \\left\\{ \\frac{|3| + |-1|}{7}, \\frac{|1| + |2|}{7} \\right\\} = \\max \\left\\{ \\frac{4}{7}, \\frac{3}{7} \\right\\} = \\frac{4}{7} \\approx 0.5714,\n$$\n所以\n$$\n\\kappa_\\infty(A) = \\|A\\|_\\infty \\|A^{-1}\\|_\\infty = 4 \\cdot \\frac{4}{7} = \\frac{16}{7} \\approx 2.286, \\quad\n\\kappa_1(A) = \\|A\\|_1 \\|A^{-1}\\|_1 = 4 \\cdot \\frac{4}{7} = \\frac{16}{7} \\approx 2.286.\n$$\n因此对于这个矩阵 $A$，$\\kappa_2(A) \\approx 1.455  2.286 = \\kappa_\\infty(A) = \\kappa_1(A)$。\n\n逐项分析：\n\nA. 陈述：$\\|A\\|_1 = 4$，$\\|A\\|_\\infty = 4$，且 $\\|A\\|_2 = \\sqrt{ \\dfrac{15 + \\sqrt{29}}{2} }$。我们从基本原理出发计算了每一项。结论：正确。\n\nB. 陈述：对于 $x = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$，$\\dfrac{\\|Ax\\|_1}{\\|x\\|_1} = \\dfrac{5}{2}$ 且此值不超过 $\\|A\\|_1$。我们得到 $\\|Ax\\|_1 = 5$ 和 $\\|x\\|_1 = 2$，所以比值为 $\\dfrac{5}{2} = 2.5$。因为 $\\|A\\|_1 = 4$，所以确实有 $\\dfrac{\\|Ax\\|_1}{\\|x\\|_1} \\le \\|A\\|_1$。结论：正确。\n\nC. 陈述：对于 $B = 0.26 A$，迭代 $x_{k+1} = B x_k$ 在 2-范数下是压缩的，但在 1-范数或 $\\infty$-范数下不是。我们计算出 $\\|B\\|_2 \\approx 0.830  1$，$\\|B\\|_1 = 1.04 > 1$，且 $\\|B\\|_\\infty = 1.04 > 1$。根据压缩判据 $\\|B\\|_p  1$，该陈述成立。结论：正确。\n\nD. 陈述：对于给定的 $x$，在 $p \\in \\{1,2,\\infty\\}$ 的上界 $\\|Ax\\|_p \\le \\|A\\|_p \\|x\\|_p$ 中，最紧的上界在 $p = \\infty$ 时取得。我们计算了这些上界：$p=1$ 时为 $8$，$p=2$ 时约为 $4.514$，$p=\\infty$ 时为 $4$。最小的是 $p=\\infty$ 时的 $4$。结论：正确。\n\nE. 陈述：对于任意矩阵 $A$，总有 $\\|A\\|_2 \\ge \\|A\\|_\\infty$。这并非普遍成立；对于所有矩阵，这些范数之间没有统一的大小顺序。对于我们这个特定的矩阵 $A$，$\\|A\\|_2 \\approx 3.192$ 且 $\\|A\\|_\\infty = 4$，所以 $\\|A\\|_2  \\|A\\|_\\infty$，这提供了一个反例。结论：不正确。\n\nF. 陈述：对于给定的 $x$，在 $\\|Ax\\|_2 \\le \\|A\\|_2 \\|x\\|_2$ 中等号成立。2-范数界中的等号成立，当且仅当 $x$ 是与 $A$ 的最大奇异值相关联的右奇异向量。我们的 $x$ 是任意的，并不满足使等号成立的条件；从数值上看，$\\|Ax\\|_2 \\approx 3.606$ 而 $\\|A\\|_2 \\|x\\|_2 \\approx 4.514$，所以严格不等式成立。结论：不正确。", "answer": "$$\\boxed{ABCD}$$", "id": "3201809"}, {"introduction": "我们已经知道存在不同的范数，但在实际应用中，选择哪种范数真的重要吗？这个动手编程练习 [@problem_id:3201753] 将向你展示，选择不同的范数（例如 $L^1$ 范数与 $L^2$ 范数）会对一个经典的机器学习算法——k-近邻（KNN）分类器产生怎样深远的影响。通过构建一个精巧的数据集并亲手计算，你将直观地看到，“邻居”的定义会随着距离度量方式（范数）的改变而改变，进而影响最终的分类结果，从而深刻理解抽象的几何概念如何塑造数据科学模型的行为。", "problem": "您将在有限维实向量空间 $\\mathbb{R}^d$ 中进行操作，并比较两种范数（$L^1$ 范数和 $L^2$ 范数）所导出的度量的行为。$L^1$ 范数定义为 $\\|\\mathbf{x}\\|_1 = \\sum_{i=1}^d |x_i|$，$L^2$ 范数定义为 $\\|\\mathbf{x}\\|_2 = \\left(\\sum_{i=1}^d x_i^2\\right)^{1/2}$。对于任意范数 $\\|\\cdot\\|$，其在 $\\mathbb{R}^d$ 上导出的度量为 $d(\\mathbf{x},\\mathbf{y}) = \\|\\mathbf{x}-\\mathbf{y}\\|$。\n\n按如下方式构建一个由整数和实数 $d \\in \\mathbb{N}$、$a \\in \\mathbb{R}$、$b \\in \\mathbb{R}$ 和 $k \\in \\mathbb{N}$ 参数化的数据集：\n- 查询点是原点 $\\mathbf{0} \\in \\mathbb{R}^d$。\n- 定义坐标轴对齐点 $\\mathcal{A} = \\{a \\mathbf{e}_i : i \\in \\{1,2,\\dots,d\\}\\}$，其中 $\\mathbf{e}_i$ 是 $\\mathbb{R}^d$ 中的第 $i$ 个标准基向量。将 $\\mathcal{A}$ 中的每个点分配类别标签 $0$。\n- 定义单个对角点 $\\mathbf{u} = b(\\mathbf{e}_1+\\mathbf{e}_2)$ 并为其分配类别标签 $1$。\n- 按以下顺序为点建立索引：首先是坐标轴点，索引为 $1,2,\\dots,d$；然后是对角点，索引为 $d+1$。\n\n比较将在度量 $d_1(\\mathbf{x},\\mathbf{y}) = \\|\\mathbf{x}-\\mathbf{y}\\|_1$ 和 $d_2(\\mathbf{x},\\mathbf{y}) = \\|\\mathbf{x}-\\mathbf{y}\\|_2$ 之间进行。在距离相等的情况下，通过选择索引最小的点来打破僵局。对于下游算法，使用应用于查询点 $\\mathbf{0}$ 的 $k$近邻（KNN）多数投票分类器，其中类别标签是 $k$ 个最近邻标签中的多数；如果多数投票出现平局，则选择较小的整数标签。\n\n您的程序必须：\n- 计算 $\\mathbf{0}$ 在 $d_1$ 和 $d_2$ 度量下的最近邻，并输出它们是否不同，结果为一个整数（如果不同则为 $1$，如果相同则为 $0$）。\n- 计算 $\\mathbf{0}$ 在 $d_1$ 和 $d_2$ 度量下的 $k$ 个最近邻的索引集合，并输出它们对称差的大小，结果为一个整数。\n- 计算查询点 $\\mathbf{0}$ 在 $d_1$ 和 $d_2$ 度量下的 KNN 多数投票类别标签，并输出分类结果是否改变，结果为一个整数（如果不同则为 $1$，如果相同则为 $0$）。\n\n使用以下参数值测试套件来检验不同的行为：\n- 测试用例 1：$d=2$，$a=\\frac{3}{2}$，$b=1$，$k=3$。\n- 测试用例 2：$d=2$，$a=\\sqrt{2}$，$b=1$，$k=2$。\n- 测试用例 3：$d=3$，$a=1$，$b=\\frac{1}{5}$，$k=2$。\n- 测试用例 4：$d=3$，$a=3$，$b=2$，$k=1$。\n\n您的程序应生成单行输出，其中包含每个测试用例结果的逗号分隔列表，每个测试用例的结果本身是一个形如 $[x_1,x_2,x_3]$（无空格）的三元组，顺序与上述测试套件相同。因此，最终输出必须是单个列表的列表，例如 $[[x_{1,1},x_{1,2},x_{1,3}],[x_{2,1},x_{2,2},x_{2,3}],\\dots]$。本问题不涉及物理单位或角度单位，所有返回值必须是整数。", "solution": "用户提供的问题已经过严格验证，并被认为是自洽、科学上合理且适定的。所有必需的数据、定义和条件都已明确说明，不存在矛盾、歧义或违反科学或数学原则的情况。该问题是计算科学中的一个标准练习，特别是探索不同范数对向量空间几何形状的影响及其对基于距离的算法（如 $k$近邻（KNN））的意义。我现在将进行完整的解答。\n\n问题的核心在于，使用两种不同的度量（由 $L^1$ 范数导出的 $d_1$ 和由 $L^2$ 范数导出的 $d_2$）来比较从一个查询点到一组数据点的距离排序。查询点是原点 $\\mathbf{q} = \\mathbf{0} \\in \\mathbb{R}^d$。从原点到任意点 $\\mathbf{p}$ 的距离简化为其范数，即 $d(\\mathbf{0}, \\mathbf{p}) = \\|\\mathbf{p}\\|$。\n\n该数据集包含两种类型的点：\n1.  一组 $d$ 个坐标轴对齐点，$\\mathcal{A} = \\{ \\mathbf{p}_i = a \\mathbf{e}_i : i \\in \\{1, \\dots, d\\} \\}$。\n2.  一个对角点，$\\mathbf{u} = \\mathbf{p}_{d+1} = b(\\mathbf{e}_1 + \\mathbf{e}_2)$。\n\n让我们计算这些点在两种范数下与原点 $\\mathbf{0}$ 的距离。\n\n对于任意坐标轴对齐点 $\\mathbf{p}_i = a \\mathbf{e}_i$：\n$L^1$ 距离是 $d_1(\\mathbf{0}, \\mathbf{p}_i) = \\|a \\mathbf{e}_i\\|_1 = \\sum_{j=1}^d |(a \\mathbf{e}_i)_j| = |a|$。\n$L^2$ 距离是 $d_2(\\mathbf{0}, \\mathbf{p}_i) = \\|a \\mathbf{e}_i\\|_2 = \\left(\\sum_{j=1}^d (a \\mathbf{e}_i)_j^2\\right)^{1/2} = \\sqrt{a^2} = |a|$。\n对于所有坐标轴对齐点，其到原点的 $L^1$ 和 $L^2$ 距离是相同的。\n\n对于对角点 $\\mathbf{u} = b(\\mathbf{e}_1 + \\mathbf{e}_2) = (b, b, 0, \\dots, 0)$：\n$L^1$ 距离是 $d_1(\\mathbf{0}, \\mathbf{u}) = \\|\\mathbf{u}\\|_1 = |b| + |b| = 2|b|$。\n$L^2$ 距离是 $d_2(\\mathbf{0}, \\mathbf{u}) = \\|\\mathbf{u}\\|_2 = \\sqrt{b^2 + b^2} = \\sqrt{2b^2} = \\sqrt{2}|b|$。\n\n邻居的相对顺序取决于 $L^1$ 度量下 $|a|$ 和 $2|b|$ 的比较，以及 $L^2$ 度量下 $|a|$ 和 $\\sqrt{2}|b|$ 的比较。这种差异是问题中观察到的所有变化来源。我们现在分析每个测试用例。\n\n**测试用例 1：$d=2$, $a=3/2$, $b=1$, $k=3$**\n点为 $\\mathbf{p}_1=(3/2, 0)$（索引 $1$，标签 $0$），$\\mathbf{p}_2=(0, 3/2)$（索引 $2$，标签 $0$），以及 $\\mathbf{p}_3=\\mathbf{u}=(1, 1)$（索引 $3$，标签 $1$）。\n到原点的距离是：\n- 对于 $\\mathbf{p}_1, \\mathbf{p}_2$：$d_1 = d_2 = |a| = |3/2| = 1.5$。\n- 对于 $\\mathbf{p}_3=\\mathbf{u}$：$d_1 = 2|b| = 2|1| = 2$ 且 $d_2 = \\sqrt{2}|b| = \\sqrt{2}|1| \\approx 1.414$。\n\n邻居的排序（从近到远，使用最小索引处理平局）：\n- 在 $d_1$ 下：距离为 $1.5$（索引 $1,2$）和 $2$（索引 $3$）。索引的排序列表为：$[1, 2, 3]$。\n- 在 $d_2$ 下：距离为 $1.5$（索引 $1,2$）和 $\\sqrt{2}$（索引 $3$）。由于 $\\sqrt{2}  1.5$，顺序不同。索引的排序列表为：$[3, 1, 2]$。\n\n1.  **最近邻比较 ($x_1$)**：在 $d_1$ 下的最近邻是 $\\mathbf{p}_1$（索引 $1$）。在 $d_2$ 下的最近邻是 $\\mathbf{p}_3$（索引 $3$）。它们不同。因此，$x_1=1$。\n2.  **对称差 ($x_2$)**：对于 $k=3$，在 $d_1$ 下的最近邻集合是 $N_1=\\{1, 2, 3\\}$。在 $d_2$ 下，它是 $N_2=\\{3, 1, 2\\}$。这两个集合是相同的（$N_1=N_2$）。它们对称差的大小是 $0$。因此，$x_2=0$。\n3.  **KNN 分类 ($x_3$)**：对于 $k=3$，我们使用邻居 $\\{1, 2, 3\\}$。标签是 $\\{0, 0, 1\\}$。多数投票结果是标签 $0$。这对 $d_1$ 和 $d_2$ 都成立。分类没有改变。因此，$x_3=0$。\n测试用例 1 的结果：$[1, 0, 0]$。\n\n**测试用例 2：$d=2$, $a=\\sqrt{2}$, $b=1$, $k=2$**\n点为 $\\mathbf{p}_1=(\\sqrt{2}, 0)$（索引 $1$，标签 $0$），$\\mathbf{p}_2=(0, \\sqrt{2})$（索引 $2$，标签 $0$），以及 $\\mathbf{p}_3=\\mathbf{u}=(1, 1)$（索引 $3$，标签 $1$）。\n到原点的距离是：\n- 对于 $\\mathbf{p}_1, \\mathbf{p}_2$：$d_1 = d_2 = |a| = |\\sqrt{2}| = \\sqrt{2}$。\n- 对于 $\\mathbf{p}_3=\\mathbf{u}$：$d_1 = 2|b| = 2|1| = 2$ 且 $d_2 = \\sqrt{2}|b| = \\sqrt{2}|1| = \\sqrt{2}$。\n\n邻居的排序：\n- 在 $d_1$ 下：距离为 $\\sqrt{2}$（索引 $1,2$）和 $2$（索引 $3$）。索引的排序列表为：$[1, 2, 3]$。\n- 在 $d_2$ 下：所有三个点到原点的距离都相等，为 $\\sqrt{2}$。我们通过索引来打破平局。索引的排序列表为：$[1, 2, 3]$。\n\n1.  **最近邻比较 ($x_1$)**：对于两种度量，最近邻都是 $\\mathbf{p}_1$（索引 $1$）。它们是相同的。因此，$x_1=0$。\n2.  **对称差 ($x_2$)**：对于 $k=2$，在 $d_1$ 下的最近邻集合是 $N_1=\\{1, 2\\}$。在 $d_2$ 下，它是 $N_2=\\{1, 2\\}$。这两个集合是相同的。它们对称差的大小是 $0$。因此，$x_2=0$。\n3.  **KNN 分类 ($x_3$)**：对于 $k=2$，我们使用邻居 $\\{1, 2\\}$。标签是 $\\{0, 0\\}$。对于两种度量，多数投票结果都是标签 $0$。分类没有改变。因此，$x_3=0$。\n测试用例 2 的结果：$[0, 0, 0]$。\n\n**测试用例 3：$d=3$, $a=1$, $b=1/5$, $k=2$**\n点为 $\\mathbf{p}_1=(1,0,0)$、$\\mathbf{p}_2=(0,1,0)$、$\\mathbf{p}_3=(0,0,1)$（索引 $1,2,3$，标签 $0$）以及 $\\mathbf{p}_4=\\mathbf{u}=(1/5, 1/5, 0)$（索引 $4$，标签 $1$）。\n到原点的距离是：\n- 对于 $\\mathbf{p}_1, \\mathbf{p}_2, \\mathbf{p}_3$：$d_1 = d_2 = |a| = |1| = 1$。\n- 对于 $\\mathbf{p}_4=\\mathbf{u}$：$d_1 = 2|b| = 2|1/5| = 0.4$ 且 $d_2 = \\sqrt{2}|b| = \\sqrt{2}|1/5| \\approx 0.283$。\n\n邻居的排序：\n- 在 $d_1$ 下：距离为 $1$（索引 $1,2,3$）和 $0.4$（索引 $4$）。索引的排序列表为：$[4, 1, 2, 3]$。\n- 在 $d_2$ 下：距离为 $1$（索引 $1,2,3$）和 $\\sqrt{2}/5$（索引 $4$）。由于 $\\sqrt{2}/5  1$，顺序相同。索引的排序列表为：$[4, 1, 2, 3]$。\n\n1.  **最近邻比较 ($x_1$)**：对于两种度量，最近邻都是 $\\mathbf{p}_4$（索引 $4$）。它们是相同的。因此，$x_1=0$。\n2.  **对称差 ($x_2$)**：对于 $k=2$，两种度量下的最近邻集合都是 $N_1=N_2=\\{4, 1\\}$。对称差为空。因此，$x_2=0$。\n3.  **KNN 分类 ($x_3$)**：对于 $k=2$，我们使用邻居 $\\{4, 1\\}$。标签是 $\\{1, 0\\}$。多数投票出现平局。平局打破规则指定选择较小的整数标签，所以类别是 $0$。这对两种度量都成立。分类没有改变。因此，$x_3=0$。\n测试用例 3 的结果：$[0, 0, 0]$。\n\n**测试用例 4：$d=3$, $a=3$, $b=2$, $k=1$**\n点为 $\\mathbf{p}_1=(3,0,0)$、$\\mathbf{p}_2=(0,3,0)$、$\\mathbf{p}_3=(0,0,3)$（索引 $1,2,3$，标签 $0$）以及 $\\mathbf{p}_4=\\mathbf{u}=(2, 2, 0)$（索引 $4$，标签 $1$）。\n到原点的距离是：\n- 对于 $\\mathbf{p}_1, \\mathbf{p}_2, \\mathbf{p}_3$：$d_1 = d_2 = |a| = |3| = 3$。\n- 对于 $\\mathbf{p}_4=\\mathbf{u}$：$d_1 = 2|b| = 2|2| = 4$ 且 $d_2 = \\sqrt{2}|b| = \\sqrt{2}|2| = 2\\sqrt{2} \\approx 2.828$。\n\n邻居的排序：\n- 在 $d_1$ 下：距离为 $3$（索引 $1,2,3$）和 $4$（索引 $4$）。索引的排序列表为：$[1, 2, 3, 4]$。\n- 在 $d_2$ 下：距离为 $3$（索引 $1,2,3$）和 $2\\sqrt{2}$（索引 $4$）。由于 $2\\sqrt{2}  3$，顺序改变。索引的排序列表为：$[4, 1, 2, 3]$。\n\n1.  **最近邻比较 ($x_1$)**：在 $d_1$ 下的最近邻是 $\\mathbf{p}_1$（索引 $1$）。在 $d_2$ 下，它是 $\\mathbf{p}_4$（索引 $4$）。它们不同。因此，$x_1=1$。\n2.  **对称差 ($x_2$)**：对于 $k=1$，在 $d_1$ 下的最近邻集合是 $N_1=\\{1\\}$。在 $d_2$ 下，它是 $N_2=\\{4\\}$。对称差是 $N_1 \\Delta N_2 = \\{1, 4\\}$，其大小为 $2$。因此，$x_2=2$。\n3.  **KNN 分类 ($x_3$)**：对于 $k=1$，分类由最近邻的标签决定。对于 $d_1$，邻居是 $\\mathbf{p}_1$（标签 $0$）。对于 $d_2$，邻居是 $\\mathbf{p}_4$（标签 $1$）。分类改变。因此，$x_3=1$。\n测试用例 4 的结果：$[1, 2, 1]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the KNN comparison problem for a given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (d, a, b, k)\n        (2, 3/2, 1, 3),\n        (2, np.sqrt(2), 1, 2),\n        (3, 1, 1/5, 2),\n        (3, 3, 2, 1),\n    ]\n\n    all_results = []\n\n    for d, a, b, k in test_cases:\n        # 1. Construct the dataset for the current test case.\n        points = []\n        point_labels = {}\n\n        # Axis-aligned points\n        for i in range(1, d + 1):\n            vector = np.zeros(d)\n            vector[i-1] = a\n            index = i\n            label = 0\n            points.append({'vector': vector, 'index': index, 'label': label})\n            point_labels[index] = label\n\n        # Diagonal point\n        vector_u = np.zeros(d)\n        vector_u[0] = b\n        vector_u[1] = b\n        index_u = d + 1\n        label_u = 1\n        points.append({'vector': vector_u, 'index': index_u, 'label': label_u})\n        point_labels[index_u] = label_u\n        \n        # 2. Calculate distances from the origin (query point)\n        query_point = np.zeros(d)\n        for p in points:\n            p['dist1'] = np.linalg.norm(p['vector'] - query_point, ord=1)\n            p['dist2'] = np.linalg.norm(p['vector'] - query_point, ord=2)\n\n        # 3. Sort points based on each metric, breaking ties by index\n        sorted_points_1 = sorted(points, key=lambda p: (p['dist1'], p['index']))\n        sorted_points_2 = sorted(points, key=lambda p: (p['dist2'], p['index']))\n\n        sorted_indices_1 = [p['index'] for p in sorted_points_1]\n        sorted_indices_2 = [p['index'] for p in sorted_points_2]\n\n        # 4. Compute the three required outputs\n        \n        # x1: Nearest neighbor comparison\n        nn_1 = sorted_indices_1[0]\n        nn_2 = sorted_indices_2[0]\n        x1 = 1 if nn_1 != nn_2 else 0\n\n        # x2: Symmetric difference of k-NN sets\n        k_neighbors_1 = set(sorted_indices_1[:k])\n        k_neighbors_2 = set(sorted_indices_2[:k])\n        x2 = len(k_neighbors_1.symmetric_difference(k_neighbors_2))\n\n        # x3: KNN classification comparison\n        def get_knn_label(neighbor_indices, labels_map):\n            \"\"\"\n            Performs majority vote classification with tie-breaking.\n            \"\"\"\n            neighbor_labels = [labels_map[i] for i in neighbor_indices]\n            count_0 = neighbor_labels.count(0)\n            count_1 = neighbor_labels.count(1)\n            \n            if count_1 > count_0:\n                return 1\n            # If count_0 > count_1 or if count_0 == count_1, return 0.\n            # The second case handles the tie-breaking rule (choose smaller label).\n            else:\n                return 0\n\n        knn_label_1 = get_knn_label(k_neighbors_1, point_labels)\n        knn_label_2 = get_knn_label(k_neighbors_2, point_labels)\n        x3 = 1 if knn_label_1 != knn_label_2 else 0\n\n        all_results.append([x1, x2, x3])\n\n    # Final print statement in the exact required format.\n    # e.g., [[x_1,x_2,x_3],[y_1,y_2,y_3]]\n    result_str = \",\".join([f\"[{','.join(map(str, res))}]\" for res in all_results])\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3201753"}]}