{"hands_on_practices": [{"introduction": "掌握诱导矩阵范数始于将其定义应用于基本矩阵。本练习聚焦于吉文斯旋转矩阵 (Givens rotation matrix)，它是许多数值线性代数算法（如QR分解）的基石。通过直接计算其 $1$-范数、$2$-范数和 $\\infty$-范数，你将为理解矩阵结构如何影响其范数值建立坚实的直观认识。", "problem": "在数值方法和科学计算的许多数值线性代数算法中，使用吉文斯旋转在保持长度的同时引入零。设 $n \\geq 2$ 且 $G \\in \\mathbb{R}^{n \\times n}$ 是一个吉文斯旋转，它通过平面旋转角 $\\theta \\in \\mathbb{R}$ 作用于坐标 $i$ 和 $j$（其中 $1 \\leq i  j \\leq n$），因此，在行和列索引为 $i$ 和 $j$ 的 $2 \\times 2$ 子矩阵中，$G$ 的元素为 $G_{ii} = \\cos \\theta$，$G_{ij} = \\sin \\theta$，$G_{ji} = -\\sin \\theta$，$G_{jj} = \\cos \\theta$，而在其他位置，$G$ 等于单位矩阵。仅使用诱导矩阵范数的定义\n$$\n\\|A\\|_{p} = \\sup_{x \\neq 0} \\frac{\\|A x\\|_{p}}{\\|x\\|_{p}},\n$$\n推导 $G$ 的诱导 $1$-范数、$2$-范数和 $\\infty$-范数，并将其表示为 $\\cos \\theta$ 和 $\\sin \\theta$ 的显式表达式。请提供精确的符号表达式；无需进行舍入。您的最终答案必须是一个单一的复合表达式，按 $1$-范数、$2$-范数、$\\infty$-范数的顺序列出这三个范数。", "solution": "问题要求仅使用诱导矩阵范数的定义，推导吉文斯旋转矩阵 $G \\in \\mathbb{R}^{n \\times n}$ 的诱导 $1$-范数、$2$-范数和 $\\infty$-范数。矩阵 $G$ 作用于坐标 $i$ 和 $j$，其中 $1 \\leq i  j \\leq n$。其非平凡元素构成一个位于行和列索引为 $i$ 和 $j$ 的 $2 \\times 2$ 子矩阵：\n$$\n\\begin{pmatrix} G_{ii}  G_{ij} \\\\ G_{ji}  G_{jj} \\end{pmatrix} = \\begin{pmatrix} \\cos \\theta  \\sin \\theta \\\\ -\\sin \\theta  \\cos \\theta \\end{pmatrix}\n$$\n其中 $\\theta \\in \\mathbb{R}$ 是旋转角。在其他位置，$G$ 是单位矩阵，即当 $k \\notin \\{i, j\\}$ 时 $G_{kk} = 1$，所有其他非对角线元素为 $0$。为记法方便，令 $c = \\cos \\theta$ 且 $s = \\sin \\theta$。\n\n矩阵 $A$ 的诱导 $p$-范数定义为\n$$\n\\|A\\|_{p} = \\sup_{x \\neq 0} \\frac{\\|A x\\|_{p}}{\\|x\\|_{p}} = \\sup_{\\|x\\|_{p}=1} \\|A x\\|_{p}\n$$\n我们将对 $p=1$、$p=2$ 和 $p=\\infty$ 应用此定义。\n\n令 $x \\in \\mathbb{R}^n$ 为任意向量，且 $y = Gx$。$y$ 的分量由以下公式给出：\n当 $k \\notin \\{i, j\\}$ 时，$y_k = x_k$\n$y_i = c x_i + s x_j$\n$y_j = -s x_i + c x_j$\n\n**诱导 $1$-范数 $\\|G\\|_{1}$ 的推导**\n\n诱导 $1$-范数定义为 $\\|G\\|_{1} = \\sup_{\\|x\\|_{1}=1} \\|Gx\\|_{1}$。\n令 $x \\in \\mathbb{R}^n$ 使得 $\\|x\\|_{1} = \\sum_{k=1}^n |x_k| = 1$。$y=Gx$ 的 $1$-范数是：\n$$\n\\|Gx\\|_{1} = \\sum_{k=1}^n |y_k| = \\sum_{k \\notin \\{i,j\\}} |y_k| + |y_i| + |y_j| = \\sum_{k \\notin \\{i,j\\}} |x_k| + |c x_i + s x_j| + |-s x_i + c x_j|\n$$\n对后两项使用三角不等式：\n$|c x_i + s x_j| \\leq |c||x_i| + |s||x_j|$\n$|-s x_i + c x_j| \\leq |-s||x_i| + |c||x_j| = |s||x_i| + |c||x_j|$\n将这些不等式相加，我们得到：\n$|c x_i + s x_j| + |-s x_i + c x_j| \\leq (|c|+|s|)|x_i| + (|s|+|c|)|x_j| = (|c|+|s|)(|x_i|+|x_j|)$。\n将此代入 $\\|Gx\\|_{1}$ 的表达式中：\n$$\n\\|Gx\\|_{1} \\leq \\sum_{k \\notin \\{i,j\\}} |x_k| + (|c|+|s|)(|x_i|+|x_j|)\n$$\n令 $M = |c|+|s| = |\\cos\\theta| + |\\sin\\theta|$。注意到 $M \\geq 1$，因为 $M^2 = (|c|+|s|)^2 = |c|^2+|s|^2+2|c||s| = c^2+s^2+2|cs| = 1+2|\\cos\\theta \\sin\\theta| \\geq 1$。\n令 $\\alpha = |x_i| + |x_j|$。因为 $\\|x\\|_1=1$，我们有 $\\sum_{k \\notin \\{i,j\\}} |x_k| = 1-\\alpha$，其中 $0 \\leq \\alpha \\leq 1$。不等式变为：\n$$\n\\|Gx\\|_{1} \\leq (1-\\alpha) + M\\alpha = 1 + (M-1)\\alpha\n$$\n因为 $M \\geq 1$，表达式 $1 + (M-1)\\alpha$ 在 $\\alpha$ 最大时取最大值。$\\alpha$ 的最大值为 $1$，这发生在当所有 $k \\notin \\{i,j\\}$ 都有 $x_k = 0$ 时，即 $x$ 的支撑集被限制在索引 $\\{i, j\\}$ 上。对于这样的向量，该不等式意味着 $\\|Gx\\|_{1} \\leq M$。\n这建立了一个上界：$\\|G\\|_{1} \\leq |\\cos\\theta| + |\\sin\\theta|$。\n\n为证明此上确界是可达的，我们必须找到一个 $\\|x\\|_{1}=1$ 的向量 $x$，使得 $\\|Gx\\|_{1} = |\\cos\\theta| + |\\sin\\theta|$。考虑标准基向量 $x = e_i$。那么 $\\|e_i\\|_{1}=1$。向量 $Ge_i$ 对应于 $G$ 的第 $i$ 列，即 $c e_i - s e_j$。该向量的 $1$-范数是：\n$$\n\\|Ge_i\\|_{1} = \\|c e_i - s e_j\\|_{1} = |c| + |-s| = |\\cos\\theta| + |\\sin\\theta|\n$$\n既然我们已经找到了一个向量 $x$ 使得 $\\|Gx\\|_{1}$ 等于上界，那么上确界必定是这个值。\n$$\n\\|G\\|_{1} = |\\cos\\theta| + |\\sin\\theta|\n$$\n\n**诱导 $\\infty$-范数 $\\|G\\|_{\\infty}$ 的推导**\n\n诱导 $\\infty$-范数定义为 $\\|G\\|_{\\infty} = \\sup_{\\|x\\|_{\\infty}=1} \\|Gx\\|_{\\infty}$。\n令 $x \\in \\mathbb{R}^n$ 使得 $\\|x\\|_{\\infty} = \\max_k |x_k| = 1$。$y=Gx$ 的 $\\infty$-范数是：\n$$\n\\|Gx\\|_{\\infty} = \\max_{k} |y_k| = \\max\\left(\\max_{k \\notin \\{i,j\\}} |x_k|, |c x_i + s x_j|, |-s x_i + c x_j|\\right)\n$$\n因为 $\\|x\\|_{\\infty}=1$，我们知道对所有 $k$ 都有 $|x_k| \\leq 1$。因此，$\\max_{k \\notin \\{i,j\\}} |x_k| \\leq 1$。\n使用三角不等式以及 $|x_i| \\leq 1$ 和 $|x_j| \\leq 1$ 的事实：\n$|c x_i + s x_j| \\leq |c||x_i| + |s||x_j| \\leq |c|(1) + |s|(1) = |\\cos\\theta| + |\\sin\\theta|$。\n$|-s x_i + c x_j| \\leq |s||x_i| + |c||x_j| \\leq |s|(1) + |c|(1) = |\\cos\\theta| + |\\sin\\theta|$。\n因此，我们得到 $\\|Gx\\|_{\\infty}$ 的一个上界：\n$$\n\\|Gx\\|_{\\infty} \\leq \\max(1, |\\cos\\theta| + |\\sin\\theta|)\n$$\n如前所述，$|\\cos\\theta| + |\\sin\\theta| \\geq 1$。因此，上界为 $\\|G\\|_{\\infty} \\leq |\\cos\\theta| + |\\sin\\theta|$。\n\n为证明这个界是可达的，我们构造一个 $\\|x\\|_{\\infty}=1$ 的向量 $x$。令 $k \\notin \\{i,j\\}$ 时 $x_k = 0$。我们选择 $x_i$ 和 $x_j$ 来最大化 $|y_i| = |c x_i + s x_j|$。令 $x_i = \\mathrm{sgn}(c)$ 且 $x_j = \\mathrm{sgn}(s)$，其中 $\\mathrm{sgn}$ 是符号函数。因为 $c^2+s^2=1$，所以 $c$ 和 $s$ 中至少有一个非零，确保了 $\\|x\\|_\\infty = \\max(|\\mathrm{sgn}(c)|, |\\mathrm{sgn}(s)|, 0) = 1$。\n对于这个 $x$ 的选择，$y=Gx$ 的第 $i$ 个分量是：\n$$\ny_i = c x_i + s x_j = c(\\mathrm{sgn}(c)) + s(\\mathrm{sgn}(s)) = |c| + |s| = |\\cos\\theta| + |\\sin\\theta|\n$$\n结果向量 $y$ 的 $\\infty$-范数是 $\\|y\\|_{\\infty} = \\max_k |y_k|$。由于 $|y_i|$ 是其中一个分量，所以 $\\|y\\|_{\\infty} \\geq |y_i| = |\\cos\\theta| + |\\sin\\theta|$。\n将此与上界结合，我们必须得到等式。\n$$\n\\|G\\|_{\\infty} = |\\cos\\theta| + |\\sin\\theta|\n$$\n\n**诱导 $2$-范数 $\\|G\\|_{2}$ 的推导**\n\n诱导 $2$-范数定义为 $\\|G\\|_{2} = \\sup_{\\|x\\|_{2}=1} \\|Gx\\|_{2}$。\n令 $x \\in \\mathbb{R}^n$。我们计算 $y=Gx$ 的欧几里得范数的平方：\n$$\n\\|Gx\\|_{2}^2 = \\|y\\|_{2}^2 = \\sum_{k=1}^n y_k^2 = \\sum_{k \\notin \\{i,j\\}} y_k^2 + y_i^2 + y_j^2\n$$\n代入 $y$ 的分量表达式：\n$$\n\\|Gx\\|_{2}^2 = \\sum_{k \\notin \\{i,j\\}} x_k^2 + (c x_i + s x_j)^2 + (-s x_i + c x_j)^2\n$$\n展开平方项：\n$$\n(c x_i + s x_j)^2 = c^2 x_i^2 + 2cs x_i x_j + s^2 x_j^2\n$$\n$$\n(-s x_i + c x_j)^2 = s^2 x_i^2 - 2cs x_i x_j + c^2 x_j^2\n$$\n这两项的和是：\n$$\n(c^2 x_i^2 + 2cs x_i x_j + s^2 x_j^2) + (s^2 x_i^2 - 2cs x_i x_j + c^2 x_j^2) = (c^2+s^2)x_i^2 + (s^2+c^2)x_j^2\n$$\n因为 $c^2+s^2 = \\cos^2\\theta + \\sin^2\\theta = 1$，所以这化简为 $x_i^2+x_j^2$。\n将此代回 $\\|Gx\\|_{2}^2$ 的表达式中：\n$$\n\\|Gx\\|_{2}^2 = \\sum_{k \\notin \\{i,j\\}} x_k^2 + (x_i^2 + x_j^2) = \\sum_{k=1}^n x_k^2 = \\|x\\|_{2}^2\n$$\n这表明对于任何向量 $x \\in \\mathbb{R}^n$，都有 $\\|Gx\\|_{2} = \\|x\\|_{2}$。吉文斯旋转矩阵 $G$ 是一个关于 $2$-范数的等距变换；它保持向量的长度不变。\n在诱导 $2$-范数的定义中使用此性质：\n$$\n\\|G\\|_{2} = \\sup_{x \\neq 0} \\frac{\\|Gx\\|_{2}}{\\|x\\|_{2}} = \\sup_{x \\neq 0} \\frac{\\|x\\|_{2}}{\\|x\\|_{2}} = \\sup_{x \\neq 0} 1 = 1\n$$\n因此，诱导 $2$-范数是 $1$。这或许可以写成 $\\cos^2\\theta+\\sin^2\\theta$，但 $1$ 是规范的简化表达式。\n\n综上所述，诱导范数为：\n$\\|G\\|_{1} = |\\cos\\theta| + |\\sin\\theta|$\n$\\|G\\|_{2} = 1$\n$\\|G\\|_{\\infty} = |\\cos\\theta| + |\\sin\\theta|$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n|\\cos\\theta| + |\\sin\\theta|  1  |\\cos\\theta| + |\\sin\\theta|\n\\end{pmatrix}\n}\n$$", "id": "3242259"}, {"introduction": "诱导 $2$-范数具有深刻的几何意义：它是一个矩阵能对向量产生的最大“拉伸”因子。与纯粹基于元素绝对值求和的 $1$-范数和 $\\infty$-范数（如前一个练习 [@problem_id:3242259] 中所计算的）不同，$2$-范数与矩阵的谱性质紧密相关。本练习将引导你探索那些被最大程度拉伸的向量集合，揭示诱导 $2$-范数、矩阵 $A^\\top A$ 的特征值及其对应特征空间维度之间的根本联系。", "problem": "设 $A(\\alpha) \\in \\mathbb{R}^{3 \\times 3}$ 为实对角矩阵\n$$\nA(\\alpha) = \\begin{pmatrix}\n\\alpha  0  0 \\\\\n0  \\alpha  0 \\\\\n0  0  1\n\\end{pmatrix}.\n$$\n考虑由下式定义的诱导算子2-范数 $\\|A(\\alpha)\\|_2$\n$$\n\\|A(\\alpha)\\|_2 = \\sup_{x \\in \\mathbb{R}^3,\\, x \\neq 0} \\frac{\\|A(\\alpha)x\\|_2}{\\|x\\|_2}.\n$$\n定义集合\n$$\nS(\\alpha) = \\left\\{ x \\in \\mathbb{R}^3 : \\|A(\\alpha)x\\|_2 = \\|A(\\alpha)\\|_2\\,\\|x\\|_2 \\right\\}.\n$$\n从诱导算子2-范数的定义和对称半正定矩阵的性质出发，确定子空间 $S(\\alpha)$ 的维数，作为实参数 $\\alpha$ 的函数。将你的最终答案表示为关于 $\\alpha$ 的单个分段闭式表达式。无需四舍五入。", "solution": "问题要求解给定矩阵 $A(\\alpha)$ 的子空间 $S(\\alpha)$ 的维数，作为实参数 $\\alpha$ 的函数。集合 $S(\\alpha)$ 定义为\n$$\nS(\\alpha) = \\left\\{ x \\in \\mathbb{R}^3 : \\|A(\\alpha)x\\|_2 = \\|A(\\alpha)\\|_2\\,\\|x\\|_2 \\right\\}.\n$$\n根据定义，矩阵 $M \\in \\mathbb{R}^{m \\times n}$ 的诱导算子2-范数由下式给出\n$$\n\\|M\\|_2 = \\sup_{x \\in \\mathbb{R}^n,\\, x \\neq 0} \\frac{\\|Mx\\|_2}{\\|x\\|_2}.\n$$\n将此表达式平方，我们得到\n$$\n\\|M\\|_2^2 = \\sup_{x \\neq 0} \\frac{\\|Mx\\|_2^2}{\\|x\\|_2^2} = \\sup_{x \\neq 0} \\frac{x^T M^T M x}{x^T x}.\n$$\n项 $\\frac{x^T M^T M x}{x^T x}$ 是矩阵 $M^T M$ 的瑞利商。矩阵 $M^T M$ 总是对称半正定的。对称矩阵的瑞利商的一个基本性质是其上确界等于该矩阵的最大特征值。因此，$\\|M\\|_2^2$ 是 $M^T M$ 的最大特征值，而 $\\|M\\|_2$ 是 $M$ 的最大奇异值。\n\n集合 $S(\\alpha)$ 由零向量和所有使上确界达到的非零向量 $x$ 组成。这些恰好是矩阵 $M^T M$ 对应于其最大特征值的特征向量。这些特征向量与零向量的并集构成一个子空间，即对应于 $M^T M$ 最大特征值的特征空间。因此，$S(\\alpha)$ 的维数是矩阵 $A(\\alpha)^T A(\\alpha)$ 最大特征值的几何重数。\n\n给定的矩阵是\n$$\nA(\\alpha) = \\begin{pmatrix}\n\\alpha  0  0 \\\\\n0  \\alpha  0 \\\\\n0  0  1\n\\end{pmatrix}.\n$$\n由于 $A(\\alpha)$ 是一个实对角矩阵，它是对称的，所以 $A(\\alpha)^T = A(\\alpha)$。我们来计算矩阵 $A(\\alpha)^T A(\\alpha)$：\n$$\nA(\\alpha)^T A(\\alpha) = A(\\alpha)^2 = \\begin{pmatrix}\n\\alpha  0  0 \\\\\n0  \\alpha  0 \\\\\n0  0  1\n\\end{pmatrix}\n\\begin{pmatrix}\n\\alpha  0  0 \\\\\n0  \\alpha  0 \\\\\n0  0  1\n\\end{pmatrix}\n= \\begin{pmatrix}\n\\alpha^2  0  0 \\\\\n0  \\alpha^2  0 \\\\\n0  0  1\n\\end{pmatrix}.\n$$\n这个对角矩阵的特征值是其对角线元素：$\\alpha^2$（代数重数为2）和 $1$（代数重数为1）。设 $\\lambda_{\\max}$ 为 $A(\\alpha)^T A(\\alpha)$ 的最大特征值。我们有 $\\lambda_{\\max} = \\max(\\alpha^2, 1)$。$S(\\alpha)$ 的维数是与 $\\lambda_{\\max}$ 相关联的特征空间的维数。我们根据参数 $\\alpha$ 的值分析三种情况。\n\n情况1：$|\\alpha| > 1$。\n在这种情况下，$\\alpha^2 > 1$。最大特征值为 $\\lambda_{\\max} = \\alpha^2$。我们需要求矩阵 $A(\\alpha)^T A(\\alpha) - \\lambda_{\\max}I$ 的零空间的维数：\n$$\nA(\\alpha)^T A(\\alpha) - \\alpha^2 I = \\begin{pmatrix}\n\\alpha^2  0  0 \\\\\n0  \\alpha^2  0 \\\\\n0  0  1\n\\end{pmatrix} - \\begin{pmatrix}\n\\alpha^2  0  0 \\\\\n0  \\alpha^2  0 \\\\\n0  0  \\alpha^2\n\\end{pmatrix} = \\begin{pmatrix}\n0  0  0 \\\\\n0  0  0 \\\\\n0  0  1 - \\alpha^2\n\\end{pmatrix}.\n$$\n特征空间是满足 $(A(\\alpha)^T A(\\alpha) - \\alpha^2 I)x = 0$ 的向量 $x = (x_1, x_2, x_3)^T$ 的集合。这给出了方程 $(1 - \\alpha^2)x_3 = 0$。因为 $\\alpha^2 \\neq 1$，我们必须有 $x_3 = 0$。$x_1$ 和 $x_2$ 没有约束。因此，该特征空间由向量 $(1, 0, 0)^T$ 和 $(0, 1, 0)^T$ 张成。这个子空间的维数是 $2$。\n所以，对于 $|\\alpha| > 1$，$\\dim(S(\\alpha)) = 2$。\n\n情况2：$|\\alpha|  1$。\n在这种情况下，$\\alpha^2  1$。最大特征值为 $\\lambda_{\\max} = 1$。我们求矩阵 $A(\\alpha)^T A(\\alpha) - \\lambda_{\\max}I$ 的零空间的维数：\n$$\nA(\\alpha)^T A(\\alpha) - 1 \\cdot I = \\begin{pmatrix}\n\\alpha^2  0  0 \\\\\n0  \\alpha^2  0 \\\\\n0  0  1\n\\end{pmatrix} - \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix} = \\begin{pmatrix}\n\\alpha^2 - 1  0  0 \\\\\n0  \\alpha^2 - 1  0 \\\\\n0  0  0\n\\end{pmatrix}.\n$$\n特征空间是满足 $(A(\\alpha)^T A(\\alpha) - I)x = 0$ 的向量 $x = (x_1, x_2, x_3)^T$ 的集合。这给出了方程 $(\\alpha^2 - 1)x_1 = 0$ 和 $(\\alpha^2 - 1)x_2 = 0$。因为 $\\alpha^2 \\neq 1$，我们必须有 $x_1 = 0$ 和 $x_2 = 0$。$x_3$ 没有约束。该特征空间由向量 $(0, 0, 1)^T$ 张成。这个子空间的维数是 $1$。\n所以，对于 $|\\alpha|  1$，$\\dim(S(\\alpha)) = 1$。\n\n情况3：$|\\alpha| = 1$。\n在这种情况下，$\\alpha^2 = 1$。$A(\\alpha)^T A(\\alpha)$ 的特征值为 $1$（重数为2）和 $1$。因此，只有一个特征值 $\\lambda = 1$，其代数重数为 $3$。最大特征值为 $\\lambda_{\\max} = 1$。我们求矩阵 $A(\\alpha)^T A(\\alpha) - \\lambda_{\\max}I$ 的零空间的维数：\n$$\nA(\\alpha)^T A(\\alpha) - 1 \\cdot I = \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix} - \\begin{pmatrix}\n1  0  0 \\\\\n0  1  0 \\\\\n0  0  1\n\\end{pmatrix} = \\begin{pmatrix}\n0  0  0 \\\\\n0  0  0 \\\\\n0  0  0\n\\end{pmatrix}.\n$$\n方程 $(A(\\alpha)^T A(\\alpha) - I)x = 0$ 变为 $0 \\cdot x = 0$，这对向量 $x \\in \\mathbb{R}^3$ 没有施加任何限制。因此，特征空间是整个空间 $\\mathbb{R}^3$。这个子空间的维数是 $3$。\n所以，对于 $|\\alpha| = 1$，$\\dim(S(\\alpha)) = 3$。\n\n综合所有情况，我们将 $S(\\alpha)$ 的维数表示为关于 $\\alpha$ 的分段函数：\n$$\n\\dim(S(\\alpha)) = \\begin{cases}\n1  \\text{若 } |\\alpha|  1 \\\\\n3  \\text{若 } |\\alpha| = 1 \\\\\n2  \\text{若 } |\\alpha| > 1\n\\end{cases}\n$$\n该函数给出了对于任何实数 $\\alpha$ 值，子空间 $S(\\alpha)$ 的维数。", "answer": "$$\n\\boxed{\n\\begin{cases}\n1  \\text{若 } |\\alpha|  1 \\\\\n3  \\text{若 } |\\alpha| = 1 \\\\\n2  \\text{若 } |\\alpha| > 1\n\\end{cases}\n}\n$$", "id": "3242331"}, {"introduction": "在实际应用中，矩阵范数的选择并非无关紧要，它会显著影响我们的分析与结论。本练习通过一个关于常微分方程数值稳定性的假想情景，展示了不同范数如何可能导致截然不同的判断。通过比较 $1$-范数和 $2$-范数给出的放大因子，你将深入理解为何与谱性质挂钩的 $2$-范数（其几何意义已在练习 [@problem_id:3242331] 中探讨）通常能为系统行为提供更忠实的度量。", "problem": "考虑将前向欧拉法应用于形式为 $\\frac{d\\mathbf{y}}{dt} = A \\mathbf{y}$ 的线性常微分方程 (ODE)，其中 $A \\in \\mathbb{R}^{n \\times n}$。一位分析师提出了一种基于范数的粗略稳定性检验方法，该方法通过 $I + hA$ 的诱导矩阵范数来界定每步的放大率，其中 $h  0$ 是时间步长。为研究不同的诱导范数如何导致关于稳定性的不同结论，令 $n$ 是 2 的幂，并定义 Sylvester 型哈达玛矩阵 $H \\in \\mathbb{R}^{n \\times n}$，其元素取自 $\\{+1,-1\\}$，且满足 $H H^{\\top} = n I$ 和 $H = H^{\\top}$。令 $A = \\frac{1}{\\sqrt{n}} H$。两位分析师分别使用诱导矩阵 1-范数 $\\|I + hA\\|_{1}$ 和诱导矩阵 2-范数 $\\|I + hA\\|_{2}$ 来估计放大率。\n\n请仅使用诱导矩阵 p-范数、向量 p-范数的定义，以及对称正交矩阵的基本谱性质，推导该比率的精确闭式表达式（用 $n$ 和 $h$ 表示）：\n$$\nR(n,h) = \\frac{\\|I + hA\\|_{1}}{\\|I + hA\\|_{2}}.\n$$\n请将 $R(n,h)$ 的最终表达式作为答案。无需进行四舍五入。", "solution": "题目要求推导比率 $R(n,h) = \\frac{\\|I + hA\\|_{1}}{\\|I + hA\\|_{2}}$，其中 $A = \\frac{1}{\\sqrt{n}} H$。矩阵 $H \\in \\mathbb{R}^{n \\times n}$ 是一个对称的 Sylvester 型哈达玛矩阵，其元素取自 $\\{+1, -1\\}$，满足 $H H^{\\top} = nI$，$n$ 是 2 的幂，且 $h0$。\n\n将我们所关注的矩阵记为 $M = I + hA = I + \\frac{h}{\\sqrt{n}} H$。由于单位矩阵 $I$ 和哈达玛矩阵 $H$ 都是对称的，因此矩阵 $M$ 也是对称的。\n\n首先，我们计算诱导矩阵 2-范数 $\\|M\\|_{2}$。对于对称矩阵，其诱导 2-范数等于其谱半径，即其特征值的最大绝对值。\n$$\n\\|M\\|_{2} = \\rho(M) = \\max_i |\\lambda_i(M)|\n$$\n其中 $\\lambda_i(M)$ 是 $M$ 的特征值。\n\n$M$ 的特征值与 $H$ 的特征值相关。设 $\\lambda$ 是 $H$ 的一个特征值，其对应的特征向量为 $\\mathbf{v} \\neq \\mathbf{0}$，因此有 $H\\mathbf{v} = \\lambda\\mathbf{v}$。\n$M$ 作用于 $\\mathbf{v}$ 的结果是：\n$$\nM\\mathbf{v} = \\left(I + \\frac{h}{\\sqrt{n}} H\\right)\\mathbf{v} = I\\mathbf{v} + \\frac{h}{\\sqrt{n}} (H\\mathbf{v}) = \\mathbf{v} + \\frac{h}{\\sqrt{n}} (\\lambda\\mathbf{v}) = \\left(1 + \\frac{h\\lambda}{\\sqrt{n}}\\right)\\mathbf{v}\n$$\n因此，$M$ 的特征值形式为 $1 + \\frac{h\\lambda}{\\sqrt{n}}$，其中 $\\lambda$ 是 $H$ 的特征值。\n\n为了求出 $H$ 的特征值，我们使用给定的性质 $H H^{\\top} = nI$。由于 $H$ 是对称的（$H=H^{\\top}$），该式可简化为 $H^2 = nI$。\n设 $\\lambda$ 是 $H$ 的一个特征值。那么 $H^2\\mathbf{v} = \\lambda^2\\mathbf{v}$。同时，$(nI)\\mathbf{v} = n\\mathbf{v}$。由 $H^2 = nI$ 可知，必有 $\\lambda^2 = n$。这意味着 $H$ 唯一可能的特征值是 $\\lambda = \\sqrt{n}$ 和 $\\lambda = -\\sqrt{n}$。\n\n矩阵 $A = \\frac{1}{\\sqrt{n}}H$ 的特征值为 $\\mu = \\frac{\\lambda}{\\sqrt{n}}$，因此其特征值为 $\\mu=+1$ 和 $\\mu=-1$。\n所以，矩阵 $M = I+hA$ 的特征值是 $1+h(+1) = 1+h$ 和 $1+h(-1) = 1-h$。\n\n$M$ 的谱半径是这些特征值绝对值的最大值：\n$$\n\\rho(M) = \\max(|1+h|, |1-h|)\n$$\n由于 $h0$，$1+h$ 恒为正且大于 1。对于任意 $h0$，不等式 $1+h  |1-h|$ 成立：\n- 如果 $0  h \\le 1$，那么 $1-h \\ge 0$，我们比较 $1+h$ 和 $1-h$。因为 $2h0$，所以 $1+h  1-h$。\n- 如果 $h  1$，那么 $1-h  0$，我们比较 $1+h$ 和 $-(1-h)=h-1$。因为 $20$，所以 $1+h  h-1$。\n因此，对于所有 $h0$，最大值是 $1+h$。\n所以，诱导矩阵 2-范数是：\n$$\n\\|I + hA\\|_{2} = 1+h\n$$\n\n接下来，我们计算诱导矩阵 1-范数 $\\|M\\|_{1}$。该范数定义为最大绝对列和：\n$$\n\\|M\\|_{1} = \\max_{1 \\le j \\le n} \\sum_{i=1}^{n} |M_{ij}|\n$$\n$M = I + \\frac{h}{\\sqrt{n}} H$ 的元素由 $M_{ij} = \\delta_{ij} + \\frac{h}{\\sqrt{n}} H_{ij}$ 给出，其中 $\\delta_{ij}$ 是克罗内克 δ。\n\n对于任意列 $j$，其元素绝对值之和为：\n$$\n\\sum_{i=1}^{n} |M_{ij}| = |M_{jj}| + \\sum_{i=1, i \\ne j}^{n} |M_{ij}|\n$$\n代入元素的表达式：\n- 对角元素为 $M_{jj} = \\delta_{jj} + \\frac{h}{\\sqrt{n}} H_{jj} = 1 + \\frac{h}{\\sqrt{n}} H_{jj}$。\n- 非对角元素（$i \\ne j$）为 $M_{ij} = \\delta_{ij} + \\frac{h}{\\sqrt{n}} H_{ij} = \\frac{h}{\\sqrt{n}} H_{ij}$。\n\n第 $j$ 列的和变为：\n$$\n\\sum_{i=1}^{n} |M_{ij}| = \\left|1 + \\frac{h}{\\sqrt{n}} H_{jj}\\right| + \\sum_{i=1, i \\ne j}^{n} \\left|\\frac{h}{\\sqrt{n}} H_{ij}\\right|\n$$\n$H$ 的元素为 $H_{ij} \\in \\{+1,-1\\}$，所以 $|H_{ij}|=1$。该和可简化为：\n$$\n\\sum_{i=1}^{n} |M_{ij}| = \\left|1 + \\frac{h}{\\sqrt{n}} H_{jj}\\right| + (n-1) \\frac{h}{\\sqrt{n}}\n$$\n此列和取决于对角元素 $H_{jj}$ 的值，它可以是 $+1$ 或 $-1$。对于 $k \\ge 1$，$n=2^k$ 阶的 Sylvester 型哈达玛矩阵，其对角线上同时存在 $+1$ 和 $-1$。对于 $n=1=2^0$，$H=[1]$ 且 $H_{11}=1$。在任何情况下，一个 $H_{jj}=1$ 的列总是存在的。为求得最大列和，我们必须考虑 $H_{jj}$ 的两种可能性。\n\n情况 1：$H_{jj} = +1$。列和为：\n$$\nS_{+} = \\left|1 + \\frac{h}{\\sqrt{n}}\\right| + (n-1) \\frac{h}{\\sqrt{n}} = 1 + \\frac{h}{\\sqrt{n}} + (n-1) \\frac{h}{\\sqrt{n}} = 1 + n\\frac{h}{\\sqrt{n}} = 1 + h\\sqrt{n}\n$$\n（因为 $h0$，所以 $1+\\frac{h}{\\sqrt{n}}  0$）。\n\n情况 2：$H_{jj} = -1$。列和为：\n$$\nS_{-} = \\left|1 - \\frac{h}{\\sqrt{n}}\\right| + (n-1) \\frac{h}{\\sqrt{n}}\n$$\n\n为了求 $\\|M\\|_1$，我们需要找到 $\\max(S_{+}, S_{-})$。让我们比较它们。\n$S_{+} - S_{-} = (1 + h\\sqrt{n}) - \\left(\\left|1 - \\frac{h}{\\sqrt{n}}\\right| + (n-1) \\frac{h}{\\sqrt{n}}\\right)$\n$S_{+} - S_{-} = \\left(1 + \\frac{h}{\\sqrt{n}}\\right) - \\left|1 - \\frac{h}{\\sqrt{n}}\\right|$\n令 $x = \\frac{h}{\\sqrt{n}}$。由于 $h0$ 且 $n \\ge 1$，我们有 $x0$。我们需要比较 $1+x$ 和 $|1-x|$。如前文计算谱半径时所证，对于任何 $x0$，不等式 $1+x  |1-x|$ 均成立。\n这意味着 $S_{+}  S_{-}$。\n\n因此，最大列和是 $S_{+}$。从而，诱导矩阵 1-范数是：\n$$\n\\|I + hA\\|_{1} = 1 + h\\sqrt{n}\n$$\n\n最后，我们可以计算比率 $R(n,h)$：\n$$\nR(n,h) = \\frac{\\|I + hA\\|_{1}}{\\|I + hA\\|_{2}} = \\frac{1 + h\\sqrt{n}}{1+h}\n$$\n这就是该比率的最终闭式表达式。", "answer": "$$\n\\boxed{\\frac{1 + h\\sqrt{n}}{1+h}}\n$$", "id": "3242244"}]}