{"hands_on_practices": [{"introduction": "斐波那契数列由一个简单的递推关系定义：$F_n = F_{n-1} + F_{n-2}$。在数学上，一个朴素的递归算法和一个迭代算法是等价的。然而，在有限精度计算的世界里，它们的稳定性表现却大相径庭。这个练习将让你直接观察到，朴素递归实现中指数级增长的算术运算次数会如何导致舍入误差的大量累积，这与远比其稳定的迭代方法形成鲜明对比。[@problem_id:3205171]", "problem": "要求您通过比较在一个受控的舍入模型下，舍入误差在 Fibonacci 序列的两种实现中的传播方式，来研究算法的鲁棒性和稳定性。请使用以下基本框架来构建您的分析和实现。\n\n- Fibonacci 数由递归关系 $F_0 = 0$，$F_1 = 1$ 以及对于 $n \\ge 2$ 的 $F_n = F_{n-1} + F_{n-2}$ 定义。\n- 采用一个标准的加法浮点舍入模型：每次加法都由一个算子 $\\mathrm{fl}_t(\\cdot)$ 舍入到有限精度，该算子使用“向最近舍入，偶数优先”的规则将任何实数舍入到 $t$ 位有效十进制数字。在分析形式中，可以写作 $\\mathrm{fl}_t(a+b) = (a+b)(1+\\delta)$，其中 $|\\delta| \\le u$，$u$（单位舍入误差）取决于 $t$。\n\n您的任务是实现两种算法，这两种算法在每次加法后都使用相同的舍入算子 $\\mathrm{fl}_t(\\cdot)$：\n\n1) 迭代实现：\n- 初始化 $x_0 = \\mathrm{fl}_t(0)$，$x_1 = \\mathrm{fl}_t(1)$。\n- 对于 $k = 2, 3, \\dots, n$，设置 $x_k = \\mathrm{fl}_t(x_{k-1} + x_{k-2})$。\n- 返回 $x_n$。\n\n2) 朴素递归实现：\n- 定义一个函数 $\\text{fib\\_rec}(n)$ 如下：\n  - 如果 $n = 0$，返回 $\\mathrm{fl}_t(0)$。\n  - 如果 $n = 1$，返回 $\\mathrm{fl}_t(1)$。\n  - 否则，返回 $\\mathrm{fl}_t(\\text{fib\\_rec}(n-1) + \\text{fib\\_rec}(n-2))$。\n\n对于给定的数对 $(n,t)$，计算：\n- 使用不进行舍入的递归关系，计算精确值 $F_n$（作为整数）。\n- 迭代舍入值 $X_n^{\\mathrm{iter}}$ 和递归舍入值 $X_n^{\\mathrm{rec}}$。\n- 相对误差（以小数形式表示，而非百分比，且不含任何单位）：\n  - $r_{\\mathrm{iter}} = \\dfrac{|X_n^{\\mathrm{iter}} - F_n|}{|F_n|}$，\n  - $r_{\\mathrm{rec}} = \\dfrac{|X_n^{\\mathrm{rec}} - F_n|}{|F_n|}$，\n  - 以及它们的差值 $s = r_{\\mathrm{rec}} - r_{\\mathrm{iter}}$。\n\n测试套件：\n使用以下参数对 $(n,t)$：\n- 情况 A：$(n,t) = (1, 3)$，\n- 情况 B：$(n,t) = (12, 4)$，\n- 情况 C：$(n,t) = (20, 6)$，\n- 情况 D：$(n,t) = (24, 6)$，\n- 情况 E：$(n,t) = (24, 3)$。\n\n要求的最终输出格式：\n- 您的程序必须生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的扁平列表。\n- 该列表必须按顺序包含每个测试用例的三元组 $[r_{\\mathrm{iter}}, r_{\\mathrm{rec}}, s]$，并将所有用例的结果连接成一个扁平列表：\n  - $[r_{\\mathrm{iter}}^{(A)}, r_{\\mathrm{rec}}^{(A)}, s^{(A)}, r_{\\mathrm{iter}}^{(B)}, r_{\\mathrm{rec}}^{(B)}, s^{(B)}, \\dots]$。\n- 将每个数字表示为使用科学记数法或定点记数法的小数，并精确到 12 位有效数字。\n- 答案中不包含物理单位。\n\n科学真实性和约束条件：\n- 您必须将 $\\mathrm{fl}_t(\\cdot)$ 精确实现为舍入到 $t$ 位有效十进制数字，并采用“向最近舍入，偶数优先”的规则。\n- 不涉及角度；不需要角度单位。\n- 确保递归实现是上述的朴素版本（没有记忆化或动态规划），以便它会重复计算子问题，从而展示其自身的舍入误差传播特性。\n\n目标是在相同的舍入模型下，经验性地比较两种方法的鲁棒性和稳定性。您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表（例如，`\"[result1,result2,result3,...]\"`）。", "solution": "问题陈述已经过严格验证，并被认为是有效的。这是一个数值分析领域的适定问题，具体涉及算法稳定性及舍入误差传播的研究。该问题具有科学依据，内部逻辑一致，并包含了求解所需的所有必要信息。\n\n核心任务是在一个指定的舍入模型下，比较计算 Fibonacci 序列的两种算法的数值稳定性。一个数值算法的稳定性取决于它如何传播输入误差以及由浮点运算引入的误差（舍入误差）。一个稳定的算法不会过度放大这些误差。\n\n这两种算法的根本区别在于所执行的舍入操作次数。\n1.  迭代算法计算 $F_n$ 大约需要 $n-1$ 次加法，因此有 $n-1$ 次舍入操作。舍入次数随 $n$ 线性增长。\n2.  朴素递归算法会重复计算子问题，其执行的加法（和舍入）次数等于 $F_{n+1}-1$。这个数字随 $n$ 指数增长，是解决此问题的一个典型的低效且数值不稳定的方法。与迭代法相比，大量的舍入操作预计将导致更大的误差累积。\n\n实现将分几步进行：定义舍入模型，实现所需的三种 Fibonacci 函数（精确、迭代、递归），然后为每个测试用例计算指定的误差度量。\n\n**1. 舍入模型 `fl_t(·)`**\n\n问题指定了一个舍入算子 $\\mathrm{fl}_t(\\cdot)$，它使用“向最近舍入，偶数优先”规则将一个实数舍入到 $t$ 位有效十进制数字。在 Python 中实现这一功能最稳健的方法是使用标准库中的 `decimal` 模块。该模块专为十进制浮点运算设计，并能对精度和舍入模式进行精确控制。\n\n函数 `fl_t(x, t)` 将按如下方式实现：\n- 将 `decimal` 上下文的精度设置为 $t$。\n- 将上下文的舍入模式设置为 `ROUND_HALF_EVEN`，这对应于“向最近舍入，偶数优先”。\n- 将输入数字 $x$（一个标准二进制浮点数）转换为一个 `Decimal` 对象。\n- 将上下文的舍入规则应用于此 `Decimal` 对象。对 `Decimal` 对象使用一元加号运算符（`+`）是实现此操作的规范方法。\n- 将生成的 `Decimal` 对象转换回标准浮点数，用于后续计算。\n\n$$ \\mathrm{fl}_t(x) = \\text{float}(\\text{round}_{\\text{prec}=t, \\text{mode}=\\text{HALF\\_EVEN}}(\\text{Decimal}(x))) $$\n\n**2. Fibonacci 算法实现**\n\n需要三个函数来计算 Fibonacci 数。\n\n- **精确值 $F_n$**：将使用一个简单的迭代算法，利用 Python 的任意精度整数来计算精确值 $F_n$。这作为误差计算的基准真相。\n    - $a, b \\leftarrow 0, 1$\n    - 对于 $k$ 从 $2$ 到 $n$：$a, b \\leftarrow b, a+b$\n    - 返回 $b$。\n\n- **迭代舍入值 $X_n^{\\mathrm{iter}}$**：该算法遵循与精确值算法相同的迭代结构，但在每次加法后应用舍入算子 $\\mathrm{fl}_t(\\cdot)$。\n    - $x_0 \\leftarrow \\mathrm{fl}_t(0, t)$, $x_1 \\leftarrow \\mathrm{fl}_t(1, t)$\n    - 对于 $k$ 从 $2$ 到 $n$：\n        - $s \\leftarrow x_{k-1} + x_{k-2}$\n        - $x_k \\leftarrow \\mathrm{fl}_t(s, t)$\n        - 更新存储值：$x_{k-2} \\leftarrow x_{k-1}$, $x_{k-1} \\leftarrow x_k$\n    - 返回 $x_n$。\n\n- **朴素递归舍入值 $X_n^{\\mathrm{rec}}$**：此算法是数学递归关系的直接转译，在每一步都应用舍入。根据问题陈述，它必须是“朴素的”，意味着它会重复计算子问题的值，从而表现出其特有的误差传播特性。\n    - $\\text{fib\\_rec}(k, t)$:\n        - 如果 $k=0$，返回 $\\mathrm{fl}_t(0, t)$。\n        - 如果 $k=1$，返回 $\\mathrm{fl}_t(1, t)$。\n        - 否则，返回 $\\mathrm{fl}_t(\\text{fib\\_rec}(k-1, t) + \\text{fib\\_rec}(k-2, t), t)$。\n\n**3. 误差计算**\n\n对于每个测试对 $(n, t)$，我们计算以下量：\n- 精确值 $F_n$。\n- 迭代舍入结果 $X_n^{\\mathrm{iter}}$。\n- 递归舍入结果 $X_n^{\\mathrm{rec}}$。\n\n然后计算相对误差。由于测试用例的 $n \\ge 1$，精确值 $F_n$ 始终非零，因此无需担心除以零的问题。\n- 迭代相对误差：$r_{\\mathrm{iter}} = \\dfrac{|X_n^{\\mathrm{iter}} - F_n|}{|F_n|}$\n- 递归相对误差：$r_{\\mathrm{rec}} = \\dfrac{|X_n^{\\mathrm{rec}} - F_n|}{|F_n|}$\n- 误差差值：$s = r_{\\mathrm{rec}} - r_{\\mathrm{iter}}$\n\n对于每个测试用例，这三个值都被格式化为 12 位有效数字的科学记数法，并连接成一个单一列表作为最终输出。使用格式化字符串 `\"{:.11e}\"` 来实现这一点，它提供小数点前 1 位和之后 11 位，总共 12 位有效数字。\n\n**4. 执行与分析**\n\n主程序遍历提供的测试套件。对于每对 $(n, t)$，它调用三个 Fibonacci 函数，计算误差 $r_{\\mathrm{iter}}$、$r_{\\mathrm{rec}}$ 和 $s$，格式化结果，并将它们追加到一个列表中。最后，它用逗号连接列表元素，并将它们打印在方括号内，以遵循指定的输出格式。预计结果将显示 $r_{\\mathrm{rec}}$ 显著大于 $r_{\\mathrm{iter}}$，特别是对于较大的 $n$ 或较小的 $t$，这证明了迭代算法具有更优的数值稳定性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom decimal import Decimal, getcontext, ROUND_HALF_EVEN\nimport sys\n\n# Increase recursion limit for larger n in the naive recursive implementation.\nsys.setrecursionlimit(2000)\n\ndef solve():\n    \"\"\"\n    Solves the Fibonacci rounding error comparison problem.\n    \"\"\"\n\n    def fl_t(x: float, t: int) -> float:\n        \"\"\"\n        Rounds a number x to t significant decimal digits using\n        rounding-to-nearest with ties-to-even.\n        \"\"\"\n        if x == 0.0:\n            return 0.0\n        \n        # Set the context for decimal arithmetic\n        getcontext().prec = t\n        getcontext().rounding = ROUND_HALF_EVEN\n        \n        # Convert to Decimal, apply rounding, and convert back to float\n        # The unary '+' applies the precision and rounding from the context.\n        rounded_decimal = +Decimal(x)\n        \n        return float(rounded_decimal)\n\n    def fib_exact(n: int) -> int:\n        \"\"\"\n        Computes the exact n-th Fibonacci number using integer arithmetic.\n        \"\"\"\n        if n = 1:\n            return n\n        a, b = 0, 1\n        for _ in range(2, n + 1):\n            a, b = b, a + b\n        return b\n\n    def fib_iterative(n: int, t: int) -> float:\n        \"\"\"\n        Computes the n-th Fibonacci number using an iterative approach\n        with rounding after each addition.\n        \"\"\"\n        if n == 0:\n            return fl_t(0.0, t)\n        if n == 1:\n            return fl_t(1.0, t)\n        \n        x0 = fl_t(0.0, t)\n        x1 = fl_t(1.0, t)\n        \n        for _ in range(2, n + 1):\n            s = x1 + x0\n            xk = fl_t(s, t)\n            x0, x1 = x1, xk\n            \n        return x1\n\n    def fib_recursive(n: int, t: int) -> float:\n        \"\"\"\n        Computes the n-th Fibonacci number using a naive recursive approach\n        with rounding after each addition.\n        \"\"\"\n        if n == 0:\n            return fl_t(0.0, t)\n        if n == 1:\n            return fl_t(1.0, t)\n        \n        # Recursive calls are made, and the sum is rounded.\n        fib_nm1 = fib_recursive(n - 1, t)\n        fib_nm2 = fib_recursive(n - 2, t)\n        \n        return fl_t(fib_nm1 + fib_nm2, t)\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1, 3),   # Case A\n        (12, 4),  # Case B\n        (20, 6),  # Case C\n        (24, 6),  # Case D\n        (24, 3),  # Case E\n    ]\n\n    results = []\n    for n, t in test_cases:\n        # Calculate the exact value.\n        fn_exact = fib_exact(n)\n        \n        # Calculate the value using the iterative algorithm with rounding.\n        xn_iter = fib_iterative(n, t)\n        \n        # Calculate the value using the naive recursive algorithm with rounding.\n        xn_rec = fib_recursive(n, t)\n        \n        # Calculate relative errors. Denominator fn_exact is > 0 for all n >= 1.\n        if fn_exact != 0:\n            r_iter = abs(xn_iter - fn_exact) / abs(fn_exact)\n            r_rec = abs(xn_rec - fn_exact) / abs(fn_exact)\n        else: # This case is not hit by the provided test suite.\n            r_iter = 0.0 if xn_iter == 0.0 else float('inf')\n            r_rec = 0.0 if xn_rec == 0.0 else float('inf')\n            \n        s = r_rec - r_iter\n        \n        # Format results to 12 significant digits in scientific notation.\n        # Format specifier \".11e\" means 11 digits after the decimal point,\n        # plus one before, totaling 12 significant digits.\n        results.append(f\"{r_iter:.11e}\")\n        results.append(f\"{r_rec:.11e}\")\n        results.append(f\"{s:.11e}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3205171"}, {"introduction": "在误差累积概念的基础上，我们现在转向一个常见的统计任务：计算算术平均值和几何平均值。这个练习揭示了两个关键的数值计算挑战：下溢和求和误差。你将研究直接乘积计算几何平均值对于小数值为何会灾难性地失败，以及对数变换如何提供一个稳健的解决方案；同时，你还将比较标准求和与补偿求和算法在计算算术平均值时的表现。[@problem_id:3205191]", "problem": "您将研究一组正实数的算术平均值和几何平均值的计算在数值上的鲁棒性和稳定性。这些正实数的量级非常接近双精度浮点运算的机器ε。请使用浮点运算的标准舍入模型作为基础：对于实数 $x$ 和 $y$ 的每一次基本运算，计算出的浮点结果 $\\mathrm{fl}(x \\,\\mathrm{op}\\, y)$ 满足 $\\mathrm{fl}(x \\,\\mathrm{op}\\, y) = (x \\,\\mathrm{op}\\, y)(1 + \\delta)$，其中 $|\\delta| \\le u$，$u$ 是单位舍入误差（机器ε的一半）。在遵循电气与电子工程师协会 (IEEE) $754$ 标准的双精度浮点数中，机器ε大约为 $2^{-52}$，单位舍入误差 $u$ 大约为 $2^{-53}$。\n\n正数 $x_1,\\dots,x_n$ 的算术平均值定义为 $(x_1 + \\cdots + x_n)/n$。几何平均值定义为 $(x_1 \\cdots x_n)^{1/n}$。您将评估每种平均值的两种计算策略：一种是直接方法，另一种是基于第一性原理（例如，通过减轻误差累积或通过变换降低动态范围以避免下溢）证明其数值鲁棒性的替代方法。您将通过计算每种策略相对于高精度基准的相对误差来量化其鲁棒性，该基准使用一种能显著减少算术和舍入误差的求和方法，以及一种能避免乘积下溢的变换来计算。\n\n请使用以下定义。如果 $a_{\\text{approx}}$ 是一个正参考值 $a_{\\text{ref}}$ 的近似值，那么相对误差为 $|a_{\\text{approx}} - a_{\\text{ref}}| / a_{\\text{ref}}$。对于算术平均值的基准，如果语言标准库提供高精度求和例程，则使用它来计算和，然后除以 $n$。对于几何平均值的基准，使用高精度求和例程计算自然对数的和，除以 $n$，然后取指数。\n\n您的程序必须为每个测试用例实现以下内容：\n- 一个直接的算术平均值和一个数值鲁棒的算术平均值，每个都通过相对误差与算术基准进行比较。\n- 一个直接的几何平均值和一个数值鲁棒的几何平均值，每个都通过相对误差与几何基准进行比较。\n\n所有输入都是不带物理单位的纯数字。所有角度（如果出现）都必须以弧度为单位，尽管这里不需要角度。\n\n测试套件。令 $\\varepsilon$ 表示 IEEE $754$ 双精度的机器ε。构造以下四个正数的确定性测试用例：\n- 用例 1（理想情况，小 $n$）：$n = 5$，其中 $x_i = \\varepsilon\\,(1 + i \\cdot 10^{-12})$，对于 $i = 0,1,2,3,4$。\n- 用例 2（乘积下溢压力测试）：$n = 300$，其中 $x_i = \\varepsilon$，对于 $i = 1,2,\\dots,300$。\n- 用例 3（大 $n$，轻度异质性）：$n = 20000$，其中奇数 $i$ 对应 $x_i = \\varepsilon$，偶数 $i$ 对应 $x_i = 1.5\\,\\varepsilon$。\n- 用例 4（非常大的 $n$，微小的确定性扰动）：$n = 100000$，其中 $x_i = \\varepsilon\\left(1 + \\left((i \\bmod 10) - 5\\right)\\cdot 10^{-16}\\right)$，对于 $i = 0,1,2,\\dots,99999$。\n\n在这些定义中，所有 $x_i$ 均为严格正数。\n\n对于每个用例，计算以下四个量：\n- 直接算术平均值与其基准的相对误差。\n- 鲁棒算术平均值与其基准的相对误差。\n- 直接几何平均值与其基准的相对误差。\n- 鲁棒几何平均值与其基准的相对误差。\n\n最终输出格式。您的程序应生成单行输出，该输出是一个由方括号括起来的逗号分隔列表，按顺序为每个测试用例包含一个条目。每个条目本身必须是按上述顺序排列的四个浮点数列表。例如，输出必须具有以下形式\n\"[ [a11,a12,a13,a14],[a21,a22,a23,a24],[a31,a32,a33,a34],[a41,a42,a43,a44] ]\"\n此单行前后无任何附加文本。", "solution": "该问题要求研究在计算一组量级接近机器ε的正数的算术平均值和几何平均值时的数值鲁棒性。该分析通过将直接计算方法与更鲁棒的替代方法进行比较来执行，并使用相对误差与高精度基准进行对比来量化性能。\n\n此分析的基础是浮点运算的标准模型，其中对于实数 $x$ 和 $y$ 以及一个基本运算 $\\mathrm{op}$，计算出的结果 $\\mathrm{fl}(x \\,\\mathrm{op}\\, y)$ 由 $\\mathrm{fl}(x \\,\\mathrm{op}\\, y) = (x \\,\\mathrm{op}\\, y)(1 + \\delta)$ 给出，其中 $|\\delta| \\le u$。$u$ 项代表单位舍入误差，对于 IEEE 754 双精度浮点数，其值为 $u \\approx 2^{-53}$。机器ε，即 $\\varepsilon$，是单位舍入误差的两倍，$\\varepsilon = 2u \\approx 2^{-52}$。\n\n**I. 算术平均值**\n\n一组 $n$ 个数 $\\{x_1, x_2, \\dots, x_n\\}$ 的算术平均值 (AM) 定义为 $A = \\frac{1}{n} \\sum_{i=1}^{n} x_i$。\n\n**1. 算术平均值的直接算法**\n\n最直接的方法是首先使用一个简单的循环计算总和 $S = \\sum_{i=1}^{n} x_i$，然后除以 $n$。在浮点运算中，这个和是迭代计算的，即 $\\hat{S}_k = \\mathrm{fl}(\\hat{S}_{k-1} + x_k)$，其中 $\\hat{S}_0 = 0$。每次加法都可能引入一个舍入误差。当对大量数值求和时，这些小误差可能会累积成最终总和中的一个显著误差。当相加的数字量级差异很大时，这个问题尤其严重，但即使像本问题中这样量级相似的数字，在一个长序列（例如，$n=100000$）上累积的误差也可能降低精度。此方法使用 `numpy.sum()` 实现。\n\n**2. 算术平均值的鲁棒算法：Kahan 求和**\n\n为了减轻舍入误差的累积，一种补偿求和算法，特别是 Kahan 求和算法，是一种鲁棒的替代方案。该算法维护一个运行的补偿变量 $c$，用于捕获每次加法中丢失的低位比特。然后将 $c$ 的值合并到求和的下一步中，从而有效地校正累积的和。\n\n对于一个数列 $X = \\{x_1, \\dots, x_n\\}$，Kahan 求和算法按以下步骤进行：\n1. 初始化和 $s = 0.0$ 及补偿 $c = 0.0$。\n2. 对于 $X$ 中的每个 $x_i$：\n   a. $y = x_i - c$\n   b. $t = s + y$\n   c. $c = (t - s) - y$\n   d. $s = t$\n3. 返回 $s$。\n\n关键步骤是 $c = (t - s) - y$。在精确算术中，此式将为 $c = ((s+y)-s) - y = 0$。然而，在浮点运算中，如果 $s$ 远大于 $y$，$t = \\mathrm{fl}(s+y)$ 可能会丢失 $y$ 的低位比特。$(t-s)$ 项恢复了已成功加到 $s$ 上的 $y$ 的高位部分，因此 $(t-s)-y$ 分离出了 $y$ 中丢失部分的负值。这个丢失的部分存储在 $c$ 中，并从下一个项 $x_{i+1}$ 中减去，从而将丢失的精度重新引入计算中。鲁棒平均值随后计算为 $A_{\\text{robust}} = \\text{KahanSum}(X) / n$。\n\n**3. 算术平均值的基准**\n\n算术平均值的参考值 $A_{\\text{ref}}$ 是使用指定的高精度求和例程计算的。Python 的 `math.fsum()` 提供了这样一个例程。它使用 Shewchuk 提出的一种算法，该算法跟踪多个部分和以保持高精度，有效地消除了除了最病态的输入之外的所有舍入误差。因此，基准为 $A_{\\text{ref}} = \\mathrm{math.fsum}(X) / n$。\n\n**II. 几何平均值**\n\n一组正数 $\\{x_1, x_2, \\dots, x_n\\}$ 的几何平均值 (GM) 定义为 $G = (\\prod_{i=1}^{n} x_i)^{1/n}$。\n\n**1. 几何平均值的直接算法**\n\n直接的实现是计算乘积 $P = \\prod_{i=1}^{n} x_i$，然后取 $n$ 次根，即 $G_{\\text{sf}} = P^{1/n}$。这种方法极易受到数值下溢或上溢的影响。测试用例涉及的数 $x_i$ 的量级约为机器ε，即 $\\varepsilon \\approx 2.22 \\times 10^{-16}$。$n$ 个此类数的乘积约为 $\\varepsilon^n$。即使对于中等大小的 $n$，如用例 2 中的 $n=300$，这个值也会变得极小（$\\approx (10^{-16})^{300} = 10^{-4800}$），远低于可表示的最小正双精度数（约 $5 \\times 10^{-324}$）。计算出的乘积会下溢为 0.0，导致得到一个完全不正确的几何平均值 0.0。\n\n**2. 几何平均值的鲁棒算法：对数变换**\n\n一种数值稳定的方法是通过使用对数来避免大乘积。基于恒等式 $\\ln(G) = \\frac{1}{n}\\sum_{i=1}^{n}\\ln(x_i)$，几何平均值可以计算为：\n$G_{\\text{robust}} = \\exp\\left(\\frac{1}{n} \\sum_{i=1}^{n} \\ln(x_i)\\right)$。\n这种变换将乘积转换为和。对于 $x_i \\approx \\varepsilon$，$\\ln(x_i)$ 的值是中等的负数（约为 $\\ln(2.22 \\times 10^{-16}) \\approx -36.0$）。对这些值求和在数值上是稳定的，并避免了直接乘法固有的下溢/上溢问题。对数的和使用标准的 `numpy.sum()` 计算。\n\n**3. 几何平均值的基准**\n\n为了创建最准确的参考值 $G_{\\text{ref}}$，我们将鲁棒的对数变换与用于求和部分的高精度 `math.fsum()` 相结合：\n$G_{\\text{ref}} = \\exp\\left(\\frac{\\mathrm{math.fsum}(\\{\\ln(x_1), \\dots, \\ln(x_n)\\})}{n}\\right)$。\n这作为“真实”值，用于与直接方法和鲁棒方法进行比较。\n\n**III. 误差量化**\n\n每种方法的鲁棒性通过其相对于相应基准值的相对误差来量化。对于一个近似值 $a_{\\text{approx}}$ 和一个参考值 $a_{\\text{ref}}$，相对误差计算为 $\\frac{|a_{\\text{approx}} - a_{\\text{ref}}|}{a_{\\text{ref}}}$。由于所有 $x_i$ 均为严格正数，所有平均值都将是正数，且参考值将非零。\n\n程序将对四个指定的测试用例中的每一个执行此分析，这些测试用例旨在探究数值稳定性的不同方面，包括大 $n$ 和潜在下溢的影响。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef kahan_sum(arr: np.ndarray) -> float:\n    \"\"\"\n    Computes the sum of an array of floats using Kahan's summation algorithm\n    to minimize numerical error.\n    \"\"\"\n    s = 0.0\n    c = 0.0  # A running compensation for lost low-order bits.\n    for x in arr:\n        y = x - c\n        t = s + y\n        # Algebraically, c should be 0.\n        # But in floating point, it recovers the lost low-order part of y.\n        c = (t - s) - y\n        s = t\n    return s\n\ndef relative_error(approx_val: float, ref_val: float) -> float:\n    \"\"\"\n    Computes the relative error of an approximation.\n    \"\"\"\n    if ref_val == 0:\n        # Avoid division by zero. If ref is 0, any non-zero approx is infinite error.\n        # If both are 0, error is 0.\n        return 0.0 if approx_val == 0.0 else np.inf\n    return np.abs(approx_val - ref_val) / np.abs(ref_val)\n\ndef generate_test_cases():\n    \"\"\"\n    Generates the four deterministic test cases as specified in the problem.\n    \"\"\"\n    eps = np.finfo(np.float64).eps\n\n    # Case 1 (happy path, small n)\n    n1 = 5\n    x1 = np.array([eps * (1.0 + i * 1e-12) for i in range(n1)], dtype=np.float64)\n\n    # Case 2 (product underflow stress)\n    n2 = 300\n    x2 = np.full(n2, eps, dtype=np.float64)\n\n    # Case 3 (large n, mild heterogeneity)\n    n3 = 20000\n    x3 = np.full(n3, eps, dtype=np.float64)\n    x3[1::2] = 1.5 * eps  # even indices in 1-based counting\n\n    # Case 4 (very large n, tiny deterministic perturbations)\n    n4 = 100000\n    i = np.arange(n4)\n    perturbations = ((i % 10) - 5) * 1e-16\n    x4 = eps * (1.0 + perturbations)\n\n    return [(n1, x1), (n2, x2), (n3, x3), (n4, x4)]\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all test cases and print the results.\n    \"\"\"\n    test_cases = generate_test_cases()\n    all_results = []\n\n    for n, x in test_cases:\n        case_results = []\n\n        # --- Arithmetic Mean Analysis ---\n        # Baseline AM (high-accuracy sum)\n        am_ref = math.fsum(x) / n\n        \n        # Straightforward AM\n        am_sf = np.sum(x) / n\n        \n        # Robust AM (Kahan sum)\n        am_robust = kahan_sum(x) / n\n\n        # Relative errors for AM\n        err_am_sf = relative_error(am_sf, am_ref)\n        err_am_robust = relative_error(am_robust, am_ref)\n        case_results.extend([err_am_sf, err_am_robust])\n\n        # --- Geometric Mean Analysis ---\n        log_x = np.log(x)\n        \n        # Baseline GM (log-transform with high-accuracy sum)\n        gm_ref = np.exp(math.fsum(log_x) / n)\n        \n        # Straightforward GM (direct product)\n        # This is expected to underflow for large n\n        with np.errstate(under='ignore'): # Suppress underflow warnings for clean output\n            gm_sf = np.prod(x)**(1.0/n)\n        \n        # Robust GM (log-transform with standard sum)\n        gm_robust = np.exp(np.sum(log_x) / n)\n\n        # Relative errors for GM\n        err_gm_sf = relative_error(gm_sf, gm_ref)\n        err_gm_robust = relative_error(gm_robust, gm_ref)\n        case_results.extend([err_gm_sf, err_gm_robust])\n        \n        all_results.append(case_results)\n\n    # Format the final output string exactly as specified.\n    results_str_parts = []\n    for row in all_results:\n        # Use repr() for high-precision floating point string representation\n        # which is suitable for this numerical context.\n        row_str = \",\".join(map(repr, row))\n        results_str_parts.append(f\"[{row_str}]\")\n    \n    final_output = f\"[{','.join(results_str_parts)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3205191"}, {"introduction": "现在我们进阶到线性代数中的一个基本问题：计算矩阵的行列式。本练习对两种方法进行了有力的比较：直接源于数学定义的递归余子式展开法，以及数值软件中作为标准的LU分解法。你将亲身发现，具有阶乘时间复杂度的余子式展开法不仅对于中等大小的矩阵来说计算上不可行，而且在数值上也是不稳定的，而基于LU分解的方法则兼具高效与稳健。[@problem_id:3205186]", "problem": "您的任务是评估两种计算方阵行列式算法的数值稳定性和鲁棒性：代数余子式（Laplace）展开法和带部分主元分解的下三角-上三角（LU）分解的因子乘积法。此任务中所有推理的基本依据是标准浮点算术模型以及带部分主元的高斯消元法的公认性质。\n\n假设浮点算术遵循模型 $fl(x \\ \\mathrm{op} \\ y) = (x \\ \\mathrm{op} \\ y)(1 + \\delta)$，其中 $|\\delta| \\leq \\varepsilon$，$\\varepsilon$ 是机器舍入单位，且 $\\mathrm{op} \\in \\{+, -, \\times, /\\}$。假设在整个计算过程中使用实数双精度算术。代数余子式展开法通过沿第一行使用余子式和交替符号进行递归展开来计算行列式。LU分解法计算分解 $P A = L U$，其中 $P$ 是记录行交换的置换矩阵，$L$ 是单位下三角矩阵，$U$ 是上三角矩阵，然后将行列式计算为 $U$ 对角线元素的带符号乘积。\n\n您的程序必须：\n- 用浮点算术实现通过代数余子式展开计算行列式。\n- 用浮点算术实现通过带部分主元分解的LU分解计算行列式，其中行列式由 $U$ 的对角线元素与置换相关的符号相乘得出。\n- 使用有理数算术中的无分数Bareiss算法（基于Python的精确有理数）精确计算一个参考行列式，作为基准真相。\n\n对于每个测试用例矩阵 $A$，令 $d_{\\mathrm{exact}}$ 表示在有理数算术中计算的精确行列式。令 $d_{\\mathrm{cofactor}}$ 和 $d_{\\mathrm{LU}}$ 分别表示通过代数余子式展开和LU分解在浮点算术中计算的行列式。对于 $d_{\\mathrm{exact}} \\neq 0$ 的矩阵，将一种方法的相对前向误差定义为\n$$\ne = \\frac{|d_{\\mathrm{approx}} - d_{\\mathrm{exact}}|}{|d_{\\mathrm{exact}}|}.\n$$\n对于 $d_{\\mathrm{exact}} = 0$ 的矩阵，将绝对前向误差定义为\n$$\ne = |d_{\\mathrm{approx}}|.\n$$\n对于每个测试用例，报告三个值：代数余子式展开的误差、LU分解的误差，以及一个布尔值，指示LU分解的误差是否严格小于代数余子式展开的误差。\n\n使用以下测试矩阵套件，按指定方式精确编码：\n\n- 案例1（良态整数 $3 \\times 3$ 矩阵）：\n  $$\n  A_1 = \\begin{pmatrix}\n  2  -3  1 \\\\\n  2  0  -1 \\\\\n  1  4  5\n  \\end{pmatrix}.\n  $$\n- 案例2（Hilbert $4 \\times 4$ 矩阵，有理数且病态）：\n  $$\n  A_2(i,j) = \\frac{1}{i + j - 1}, \\quad 1 \\leq i,j \\leq 4.\n  $$\n- 案例3（Vandermonde $5 \\times 5$ 矩阵，节点为间距很小的有理数）：\n  节点 $x_1 = \\frac{10000}{10000}$, $x_2 = \\frac{10001}{10000}$, $x_3 = \\frac{10002}{10000}$, $x_4 = \\frac{10003}{10000}$, $x_5 = \\frac{10004}{10000}$，以及\n  $$\n  A_3(i,j) = x_i^{j-1}, \\quad 1 \\leq i \\leq 5, \\ 1 \\leq j \\leq 5.\n  $$\n- 案例4（奇异 $4 \\times 4$ 矩阵，其中一行是另一行的倍数）：\n  $$\n  A_4 = \\begin{pmatrix}\n  1  2  3  4 \\\\\n  2  4  6  8 \\\\\n  1  -1  0  1 \\\\\n  0  0  0  1\n  \\end{pmatrix}.\n  $$\n- 案例5（大规模整数 $4 \\times 4$ 矩阵）：\n  $$\n  A_5 = \\begin{pmatrix}\n  123456789  987654321  564738291  192837465 \\\\\n  111111111  222222222  333333333  444444444 \\\\\n  135791357  246802468  112233445  556677889 \\\\\n  100000000  100000001  99999999  123456789\n  \\end{pmatrix}.\n  $$\n\n角度单位不适用。不涉及物理单位。所有输出必须是无单位的数值。对于每个案例，输出一个列表 $[e_{\\mathrm{cofactor}}, e_{\\mathrm{LU}}, b]$，其中 $e_{\\mathrm{cofactor}}$ 和 $e_{\\mathrm{LU}}$ 是实数（浮点数），$b$ 是一个布尔值。对于 $d_{\\mathrm{exact}} \\neq 0$ 的案例，报告相对误差；对于 $d_{\\mathrm{exact}} = 0$ 的案例，报告绝对误差。您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表，例如，\n$$\n[\\,[e_{1,\\mathrm{cofactor}}, e_{1,\\mathrm{LU}}, b_1], \\ldots, [e_{5,\\mathrm{cofactor}}, e_{5,\\mathrm{LU}}, b_5]\\,].\n$$", "solution": "该问题要求评估两种计算方阵行列式算法的数值稳定性和鲁棒性：代数余子式展开法和带部分主元分解的LU分解法。评估将通过比较它们的结果与使用有理数算术计算出的精确值来进行。\n\n区分这些算法的核心原则在于它们的计算复杂性以及在标准浮点算术中对舍入误差的敏感性，该算术模型由 $fl(x \\ \\mathrm{op} \\ y) = (x \\ \\mathrm{op} \\ y)(1 + \\delta)$ 且 $|\\delta| \\leq \\varepsilon$（机器ε）描述。\n\n### 方法1：代数余子式（Laplace）展开\n\n一个 $n \\times n$ 矩阵 $A$ 的行列式可以通过沿某一行或某一列递归展开来定义。沿第一行展开可得：\n$$\n\\det(A) = \\sum_{j=1}^{n} (-1)^{1+j} a_{1j} \\det(M_{1j})\n$$\n其中 $a_{1j}$ 是第一行第j列的元素，$M_{1j}$ 是通过从 $A$ 中移除第1行和第j列得到的 $(n-1) \\times (n-1)$ 子矩阵（余子式）。递归的基例是一个 $1 \\times 1$ 矩阵，其行列式为 $\\det([a]) = a$。\n\n**计算成本和稳定性：**\n此方法所需的乘法次数遵循递推关系 $T(n) = n T(n-1) + n$，这导致其计算复杂度为 $O(n!)$。即使对于中等大小的矩阵（例如 $n  20$），这种计算也是不可行的。对数值稳定性而言更为关键的是，该公式涉及 $n$ 个项的求和。这些项可能数值很大且符号交替，极有可能导致**灾难性抵消**——即两个几乎相等的浮点数相减，从而导致有效数字的巨大损失。大量的算术运算也会导致每一步舍入误差的累积。\n\n### 方法2：带部分主元分解的LU分解\n\n此方法基于将矩阵 $A$ 分解为一个下三角矩阵 $L$、一个上三角矩阵 $U$ 和一个置换矩阵 $P$ 的乘积，使得 $PA = LU$。然后，矩阵 $A$ 的行列式可由行列式的性质推导得出：\n$$\n\\det(P) \\det(A) = \\det(L) \\det(U)\n$$\n$$\n\\det(A) = \\det(P)^{-1} \\det(L) \\det(U)\n$$\n在此分解中：\n- $L$ 是一个单位下三角矩阵，因此 $\\det(L) = 1$。\n- $U$ 是一个上三角矩阵，因此其行列式是其对角线元素的乘积：$\\det(U) = \\prod_{i=1}^{n} u_{ii}$。\n- $P$ 是表示行交换的置换矩阵。其行列式为 $\\det(P) = (-1)^s$，其中 $s$ 是执行的行交换次数。因此，$\\det(P)^{-1} = \\det(P) = (-1)^s$。\n\n综合这些，行列式为：\n$$\n\\det(A) = (-1)^s \\prod_{i=1}^{n} u_{ii}\n$$\n**计算成本和稳定性：**\nLU分解算法的复杂度为 $O(n^3)$，远比代数余子式展开法高效。其数值稳定性的关键是**部分主元法**。在消元的每一步，算法选择当前列中绝对值最大的元素作为主元。这确保了消元过程中使用的乘数满足 $|l_{ij}| \\leq 1$，这有助于在计算过程中限制矩阵 $U$ 中元素的增长。控制这种元素的增长对于减轻舍入误差的累积至关重要。最终的行列式通过对 $n$ 个数的一次乘积计算得出，这比代数余子式展开法所需的大量求和运算要稳定得多。带部分主元的高斯消元法是解决此类问题的标准、稳定的方法。\n\n### 方法3：精确有理数算术\n\n为提供一个无可争议的基准线 $d_{\\mathrm{exact}}$，我们使用精确有理数算术来计算行列式。问题描述中提到了Bareiss算法，这是一种在整环上进行无分数行列式计算的优雅方法。对于有理数项矩阵，一个更直接且符合使用“Python精确有理数”精神的方法是，直接对以 `fractions.Fraction` 对象表示的矩阵元素执行带部分主元的高斯消元法。这避免了所有浮点精度问题，从而得到数学上精确的结果。行列式被计算为得到的有理数上三角矩阵对角线元素的带符号乘积。\n\n### 误差分析\n\n浮点近似值（$d_{\\mathrm{approx}} \\in \\{d_{\\mathrm{cofactor}}, d_{\\mathrm{LU}}\\}$）的前向误差相对于精确行列式 $d_{\\mathrm{exact}}$ 进行量化。\n- 对于非奇异矩阵（$d_{\\mathrm{exact}} \\neq 0$），使用相对前向误差：\n$$\ne = \\frac{|d_{\\mathrm{approx}} - d_{\\mathrm{exact}}|}{|d_{\\mathrm{exact}}|}\n$$\n- 对于奇异矩阵（$d_{\\mathrm{exact}} = 0$），使用绝对前向误差：\n$$\ne = |d_{\\mathrm{approx}}|\n$$\n这允许在一个旨在挑战其稳定性的测试矩阵套件上（包括良态、病态和奇异情况），对两种浮点方法的准确性进行公平比较。指示 $e_{\\mathrm{LU}}  e_{\\mathrm{cofactor}}$ 的布尔值 $b$ 将系统地显示基于LU分解的方法的优越性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom fractions import Fraction\nimport sys\n\n# Increase recursion limit for cofactor expansion on larger matrices if needed, though 5x5 is fine.\nsys.setrecursionlimit(2000)\n\ndef solve():\n    \"\"\"\n    Solves the problem by implementing and comparing three determinant algorithms.\n    \"\"\"\n\n    def det_cofactor(A: np.ndarray) -> float:\n        \"\"\"\n        Computes the determinant using cofactor expansion.\n        Implemented recursively.\n        \"\"\"\n        n = A.shape[0]\n        if n == 1:\n            return A[0, 0]\n\n        total = 0.0\n        for j in range(n):\n            minor = np.delete(np.delete(A, 0, axis=0), j, axis=1)\n            sign = 1.0 if j % 2 == 0 else -1.0\n            total += sign * A[0, j] * det_cofactor(minor)\n        return total\n\n    def det_lu_pivot(A: np.ndarray) -> float:\n        \"\"\"\n        Computes the determinant using LU decomposition with partial pivoting.\n        \"\"\"\n        n = A.shape[0]\n        U = A.copy().astype(np.float64)\n        num_swaps = 0\n\n        for k in range(n):\n            # Find pivot in column k\n            pivot_row = k + np.argmax(np.abs(U[k:, k]))\n            \n            # Check for singularity\n            if U[pivot_row, k] == 0.0:\n                return 0.0\n\n            if pivot_row != k:\n                # Swap rows\n                U[[k, pivot_row]] = U[[pivot_row, k]]\n                num_swaps += 1\n\n            # Elimination\n            for i in range(k + 1, n):\n                factor = U[i, k] / U[k, k]\n                U[i, k:] -= factor * U[k, k:]\n        \n        det = (-1.0)**num_swaps\n        for i in range(n):\n            det *= U[i, i]\n            \n        return det\n        \n    def det_exact_rational(matrix_data) -> Fraction:\n        \"\"\"\n        Computes the exact determinant using Gaussian elimination with Fraction objects.\n        \"\"\"\n        # Ensure the matrix is made of Fraction objects\n        M = [[Fraction(x) for x in row] for row in matrix_data]\n        n = len(M)\n        if n == 0:\n            return Fraction(1)\n        \n        sign = Fraction(1)\n\n        for k in range(n):\n            # Find pivot\n            pivot_row_idx = k\n            max_val = abs(M[k][k])\n            for i in range(k + 1, n):\n                if abs(M[i][k]) > max_val:\n                    max_val = abs(M[i][k])\n                    pivot_row_idx = i\n\n            if max_val == 0:\n                return Fraction(0)  # Singular matrix\n\n            # Swap rows if necessary\n            if pivot_row_idx != k:\n                M[k], M[pivot_row_idx] = M[pivot_row_idx], M[k]\n                sign *= -1\n\n            # Elimination\n            pivot_val = M[k][k]\n            for i in range(k + 1, n):\n                if M[i][k] != 0:\n                    factor = M[i][k] / pivot_val\n                    for j in range(k, n):\n                        M[i][j] -= factor * M[k][j]\n\n        # Calculate determinant as the product of the diagonal\n        det = sign\n        for i in range(n):\n            det *= M[i][i]\n        return det\n\n    # Define the test cases\n    A1 = [[2, -3, 1], [2, 0, -1], [1, 4, 5]]\n    \n    A2 = [[Fraction(1, i + j - 1) for j in range(1, 5)] for i in range(1, 5)]\n\n    nodes3 = [Fraction(10000 + i, 10000) for i in range(5)]\n    A3 = [[node ** (j - 1) for j in range(1, 6)] for node in nodes3]\n\n    A4 = [[1, 2, 3, 4], [2, 4, 6, 8], [1, -1, 0, 1], [0, 0, 0, 1]]\n    \n    A5 = [[123456789, 987654321, 564738291, 192837465],\n          [111111111, 222222222, 333333333, 444444444],\n          [135791357, 246802468, 112233445, 556677889],\n          [100000000, 100000001, 99999999, 123456789]]\n\n    test_cases_rational = [A1, A2, A3, A4, A5]\n    \n    results = []\n    \n    for A_rational in test_cases_rational:\n        # Convert rational matrix to numpy float array for FP algorithms\n        A_float = np.array([[float(x) for x in row] for row in A_rational])\n\n        # Compute determinants\n        d_exact = det_exact_rational(A_rational)\n        d_cofactor = det_cofactor(A_float)\n        d_lu = det_lu_pivot(A_float)\n\n        # Calculate errors\n        if d_exact != 0:\n            # Relative error\n            d_exact_float = float(d_exact)\n            e_cofactor = abs(d_cofactor - d_exact_float) / abs(d_exact_float)\n            e_lu = abs(d_lu - d_exact_float) / abs(d_exact_float)\n        else:\n            # Absolute error\n            e_cofactor = abs(d_cofactor)\n            e_lu = abs(d_lu)\n            \n        is_lu_better = e_lu  e_cofactor\n        \n        results.append(f\"[{e_cofactor},{e_lu},{str(is_lu_better).lower()}]\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3205186"}]}