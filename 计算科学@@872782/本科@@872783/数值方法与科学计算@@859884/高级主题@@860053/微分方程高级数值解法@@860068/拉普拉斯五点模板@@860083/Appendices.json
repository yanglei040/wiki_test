{"hands_on_practices": [{"introduction": "理论推导告诉我们，对于足够光滑的函数，五点拉普拉斯模版具有二阶精度。但是，我们如何在实践中验证这一结论呢？本练习将指导您从泰勒级数这一基本原理出发，推导并实现五点离散拉普拉斯算子，并通过网格加密研究来亲自验证其收敛阶。这项基础实践不仅能巩固您对截断误差的理解，还能让您掌握检验数值方法精度的标准技术——“人造解法” ([@problem_id:3230823])。", "problem": "要求您从第一性原理出发，为一个人造解（manufactured solution）分析并实现五点离散拉普拉斯算子，然后执行网格加密研究以验证其二阶收敛性。从拉普拉斯算子的定义和光滑函数的泰勒级数开始。不要使用任何预先推导出的离散公式；相反，请使用下面描述的基本原理进行推导。\n\n基本原理：\n- 拉普拉斯算子的定义：对于一个足够光滑的标量场 $u(x,y)$，其拉普拉斯算子为 $\\Delta u(x,y) = \\dfrac{\\partial^2 u}{\\partial x^2}(x,y) + \\dfrac{\\partial^2 u}{\\partial y^2}(x,y)$。\n- 一个光滑的单变量函数 $u$ 在点 $x_0$ 附近的泰勒级数展开为 $u(x_0 + h) = u(x_0) + h\\,u_x(x_0) + \\dfrac{h^2}{2}\\,u_{xx}(x_0) + \\dfrac{h^3}{6}\\,u_{xxx}(x_0) + \\dfrac{h^4}{24}\\,u_{xxxx}(x_0) + \\mathcal{O}(h^5)$，对于 $u(x_0 - h)$ 同样如此。\n- 一维二阶导数的中心有限差分近似可以从上述泰勒级数展开推导得出。\n\n任务：\n1. 使用在网格点 $(x_i,y_j)$ 附近，$x$ 方向间距为 $h_x$，$y$ 方向间距为 $h_y$ 的泰勒级数展开，推导出五点离散拉普拉斯算子格式。该格式通过 $u(x_{i\\pm 1},y_j)$、$u(x_i,y_{j\\pm 1})$ 和 $u(x_i,y_j)$ 的线性组合来近似 $\\Delta u(x_i,y_j)$。您的推导必须明确指出截断误差的主阶项，并证明对于足够光滑的 $u$，局部截断误差的阶为 $\\mathcal{O}(h_x^2 + h_y^2)$。\n2. 实现一个程序，对于每个人造解 $u(x,y)$ 及其精确的拉普拉斯算子 $\\Delta u(x,y)$，在矩形域上使用来自精确解 $u(x,y)$ 的狄利克雷边界值，计算内部网格点上的离散拉普拉斯算子。误差计算为所有内部网格点上离散拉普拉斯算子与精确拉普拉斯算子之间绝对差的最大值。\n3. 执行网格加密研究：对于一系列网格，其中每个方向上的间距逐次减半，计算误差和观测到的收敛阶 $p_k = \\log_2\\!\\left(\\dfrac{E(h_k)}{E(h_{k+1})}\\right)$，其中 $E(h)$ 是所选的误差范数，$h$ 表示 $x$ 方向的网格间距。在各向异性情况下，在将 $h_x$ 和 $h_y$ 同时缩小2倍时，保持比率 $h_y/h_x$ 不变。\n4. 对于三角函数，角度必须以弧度为单位进行解释。\n5. 将每个观测到的收敛阶 $p_k$ 四舍五入到3位小数。\n\n误差范数：\n- 使用内部节点上的最大范数：$E(h_x,h_y) = \\max_{i,j} \\left| \\Delta_h u(x_i,y_j) - \\Delta u(x_i,y_j) \\right|$，其中 $\\Delta_h$ 是您推导的五点离散拉普拉斯算子，而 $(x_i,y_j)$ 仅遍历内部网格点。\n\n测试套件：\n- 所有测试的定义域：$[0,1]\\times[0,1]$。\n- 边界值：在 $\\partial([0,1]\\times[0,1])$ 上使用精确解 $u(x,y)$。\n- 对于每个测试用例，通过将 $h_x$（以及相应地 $h_y$）减半来进行连续加密，以获得一个包含4个网格的序列，从而产生3个观测到的收敛阶 $p_k$。\n\n提供以下四个测试用例：\n- 情况1（理想路径，各向同性）：\n  - $u_1(x,y) = \\sin(\\pi x)\\sin(\\pi y)$，其拉普拉斯算子为 $\\Delta u_1(x,y) = -2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$。\n  - 初始间距：$h_x = h_y = 1/8$。\n- 情况2（光滑指数函数，各向同性）：\n  - $u_2(x,y) = e^{x+y}$，其拉普拉斯算子为 $\\Delta u_2(x,y) = 2 e^{x+y}$。\n  - 初始间距：$h_x = h_y = 1/8$。\n- 情况3（各向异性网格，固定比率 $h_y/h_x = 2$）：\n  - $u_3(x,y) = \\sin(\\pi x)\\sin(\\pi y)$，其拉普拉斯算子为 $\\Delta u_3(x,y) = -2\\pi^2 \\sin(\\pi x)\\sin(\\pi y)$。\n  - 初始间距：$h_x = 1/16$, $h_y = 1/8$。\n- 情况4（较粗的初始网格，多项式解）：\n  - $u_4(x,y) = x^4 + y^4$，其拉普拉斯算子为 $\\Delta u_4(x,y) = 12 x^2 + 12 y^2$。\n  - 初始间距：$h_x = h_y = 1/4$。\n\n输出规格：\n- 您的程序应生成单行输出，其中包含一个顶级列表，内有四个子列表，每个子列表对应一个测试用例。每个子列表必须包含针对连续加密对的三个四舍五入后的观测收敛阶 $p_k$，格式为逗号分隔的列表，不含空格，并用方括号括起来。这四个子列表必须合并为一个逗号分隔的列表，不含空格，并用方括号括起来。例如：`[[2.000,2.000,2.000],[2.000,2.000,2.000],[2.000,2.000,2.000],[2.000,2.000,2.000]]`。", "solution": "该问题是有效的，因为它在科学上是合理的、适定的，并且基于数值分析的既定原则。它要求推导拉普拉斯算子的五点有限差分格式，并对其收敛阶进行数值验证，这是一个标准且定义明确的任务。\n\n**第1部分：五点拉普拉斯格式和截断误差的推导**\n\n我们寻求在网格点 $(x_i, y_j)$ 处对拉普拉斯算子 $\\Delta u(x,y) = \\dfrac{\\partial^2 u}{\\partial x^2}(x,y) + \\dfrac{\\partial^2 u}{\\partial y^2}(x,y)$ 的近似。我们首先使用从泰勒级数展开推导出的中心差分来近似二阶偏导数 $\\dfrac{\\partial^2 u}{\\partial x^2}$ 和 $\\dfrac{\\partial^2 u}{\\partial y^2}$。\n\n让我们考虑函数 $u(x,y)$ 沿着直线 $y=y_j$ 的行为。$u(x, y_j)$ 在 $x=x_i$ 附近以步长 $h_x$ 进行的泰勒级数展开由下式给出：\n$$ u(x_i + h_x, y_j) = u(x_i, y_j) + h_x \\frac{\\partial u}{\\partial x}(x_i, y_j) + \\frac{h_x^2}{2} \\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) + \\frac{h_x^3}{6} \\frac{\\partial^3 u}{\\partial x^3}(x_i, y_j) + \\frac{h_x^4}{24} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h_x^5) $$\n$$ u(x_i - h_x, y_j) = u(x_i, y_j) - h_x \\frac{\\partial u}{\\partial x}(x_i, y_j) + \\frac{h_x^2}{2} \\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) - \\frac{h_x^3}{6} \\frac{\\partial^3 u}{\\partial x^3}(x_i, y_j) + \\frac{h_x^4}{24} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h_x^5) $$\n\n使用紧凑的索引表示法 $u_{i,j} = u(x_i, y_j)$，$u_{i+1, j} = u(x_i+h_x, y_j)$ 等，并将两个展开式相加，我们消除了奇数阶导数项：\n$$ u_{i+1,j} + u_{i-1,j} = 2u_{i,j} + h_x^2 \\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) + \\frac{h_x^4}{12} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h_x^6) $$\n注意，误差项变为 $\\mathcal{O}(h_x^6)$，因为来自两个级数的 $\\mathcal{O}(h_x^5)$ 项相互抵消。\n\n重新整理此方程以求解关于 $x$ 的二阶偏导数：\n$$ \\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h_x^2} - \\frac{h_x^2}{12} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h_x^4) $$\n这给了我们 $\\dfrac{\\partial^2 u}{\\partial x^2}$ 的中心差分近似：\n$$ \\delta_{xx}u_{i,j} = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h_x^2} $$\n该近似的局部截断误差是精确导数与其近似值之间的差：\n$$ \\tau_{xx} = \\frac{\\partial^2 u}{\\partial x^2}(x_i, y_j) - \\delta_{xx}u_{i,j} = -\\frac{h_x^2}{12} \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + \\mathcal{O}(h_x^4) $$\n主阶项表明，该近似在 $h_x$ 上是二阶精确的。\n\n通过对关于 $y$ 的步长为 $h_y$ 的偏导数进行相同的论证，我们得到：\n$$ \\frac{\\partial^2 u}{\\partial y^2}(x_i, y_j) = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h_y^2} - \\frac{h_y^2}{12} \\frac{\\partial^4 u}{\\partial y^4}(x_i, y_j) + \\mathcal{O}(h_y^4) $$\n相应的近似和截断误差为：\n$$ \\delta_{yy}u_{i,j} = \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h_y^2} $$\n$$ \\tau_{yy} = \\frac{\\partial^2 u}{\\partial y^2}(x_i, y_j) - \\delta_{yy}u_{i,j} = -\\frac{h_y^2}{12} \\frac{\\partial^4 u}{\\partial y^4}(x_i, y_j) + \\mathcal{O}(h_y^4) $$\n\n五点离散拉普拉斯算子，记为 $\\Delta_h u(x_i, y_j)$，是这两个中心差分算子的和：\n$$ \\Delta_h u(x_i, y_j) = \\delta_{xx}u_{i,j} + \\delta_{yy}u_{i,j} = \\frac{u_{i+1,j} - 2u_{i,j} + u_{i-1,j}}{h_x^2} + \\frac{u_{i,j+1} - 2u_{i,j} + u_{i,j-1}}{h_y^2} $$\n这可以重写为中心点 $(i,j)$ 及其四个最近邻点的值的线性组合：\n$$ \\Delta_h u_{i,j} = \\frac{1}{h_x^2} u_{i+1,j} + \\frac{1}{h_x^2} u_{i-1,j} + \\frac{1}{h_y^2} u_{i,j+1} + \\frac{1}{h_y^2} u_{i,j-1} - 2\\left(\\frac{1}{h_x^2} + \\frac{1}{h_y^2}\\right)u_{i,j} $$\n这就完成了五点格式的推导。\n\n拉普拉斯近似的局部截断误差 $\\tau$ 是二阶导数截断误差的和：\n$$ \\tau(x_i, y_j) = \\Delta u(x_i, y_j) - \\Delta_h u(x_i, y_j) = \\tau_{xx} + \\tau_{yy} $$\n$$ \\tau(x_i, y_j) = \\left(-\\frac{h_x^2}{12} \\frac{\\partial^4 u}{\\partial x^4} + \\mathcal{O}(h_x^4)\\right) + \\left(-\\frac{h_y^2}{12} \\frac{\\partial^4 u}{\\partial y^4} + \\mathcal{O}(h_y^4)\\right) $$\n假设函数 $u(x,y)$ 足够光滑（即，其四阶偏导数是连续的，$u \\in C^4$），则主阶截断误差为：\n$$ \\tau(x_i,y_j) = -\\frac{1}{12} \\left( h_x^2 \\frac{\\partial^4 u}{\\partial x^4}(x_i, y_j) + h_y^2 \\frac{\\partial^4 u}{\\partial y^4}(x_i, y_j) \\right) + \\text{H.O.T.} $$\n因此，局部截断误差的阶为 $\\mathcal{O}(h_x^2 + h_y^2)$。对于各向同性网格，其中 $h_x = h_y = h$，误差为 $\\mathcal{O}(h^2)$。\n\n**第2部分：网格加密和收敛阶**\n\n总误差，通过最大范数 $E(h_x, h_y) = \\max_{i,j} \\left| \\Delta_h u(x_i,y_j) - \\Delta u(x_i,y_j) \\right|$ 来衡量，对于稳定格式，预期其行为与局部截断误差成正比。因此，我们预期 $E \\approx C(h_x^2 + h_y^2)$，其中常数 $C$ 取决于 $u$ 的高阶导数。\n\n在我们的网格加密研究中，我们连续将网格间距减半，因此 $h_k \\to h_{k+1} = h_k/2$。考虑一个各向同性网格，其中 $h_x = h_y = h$，我们有 $E(h) \\approx C h^2$。在下一个加密级别上的误差是 $E(h/2) \\approx C (h/2)^2 = (C h^2)/4 = E(h)/4$。理论收敛率 $p$ 计算如下：\n$$ p = \\log_2\\left(\\frac{E(h)}{E(h/2)}\\right) \\approx \\log_2\\left(\\frac{C h^2}{C (h/2)^2}\\right) = \\log_2(4) = 2 $$\n这证实了五点拉普拉斯格式预期的二阶收敛性。同样的推理也适用于各向异性情况，其中比率 $h_y/h_x$ 保持不变，因为误差项 $h_x^2 + h_y^2$ 仍将与 $h_x^2$（或 $h_y^2$）成正比，从而导致观测到的阶数为2。程序将为对应于连续加密网格的一系列误差 $E_k$ 计算这个观测到的阶数 $p_k = \\log_2(E(h_k)/E(h_{k+1}))$。我们预期所有测试用例的 $p_k \\approx 2$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_refinement_study(u_func, lap_u_func, hx_initial, hy_initial):\n    \"\"\"\n    Performs a grid refinement study for a given manufactured solution.\n    Computes errors on 4 successively refined meshes and returns the 3\n    observed convergence orders.\n    \"\"\"\n    errors = []\n    num_meshes = 4\n\n    for k in range(num_meshes):\n        hx = hx_initial / (2**k)\n        hy = hy_initial / (2**k)\n\n        # Determine number of grid points from spacings for the [0,1] domain.\n        # Number of intervals is 1/h. Number of points is num_intervals + 1.\n        # Use rounding to handle potential floating point inaccuracies.\n        nx_intervals = int(round(1.0 / hx))\n        ny_intervals = int(round(1.0 / hy))\n        \n        nx = nx_intervals + 1\n        ny = ny_intervals + 1\n\n        # Create grid coordinates.\n        x = np.linspace(0.0, 1.0, nx)\n        y = np.linspace(0.0, 1.0, ny)\n        \n        # Create 2D grid using 'ij' indexing to align with matrix (row, col) convention.\n        xx, yy = np.meshgrid(x, y, indexing='ij')\n\n        # Evaluate exact solution on the entire grid to get Dirichlet boundary values.\n        U = u_func(xx, yy)\n\n        # Compute the discrete Laplacian on the interior grid points using slicing.\n        # The equation is: (U(i+1,j) - 2U(i,j) + U(i-1,j))/hx^2 + (U(i,j+1) - 2U(i,j) + U(i,j-1))/hy^2\n        # Slices correspond to i from 1 to nx-2 and j from 1 to ny-2.\n        U_center = U[1:-1, 1:-1]\n        term_x = (U[2:, 1:-1] - 2 * U_center + U[:-2, 1:-1]) / (hx**2)\n        term_y = (U[1:-1, 2:] - 2 * U_center + U[1:-1, :-2]) / (hy**2)\n        lap_h_U = term_x + term_y\n\n        # Compute the exact Laplacian on the interior grid points.\n        xx_interior = xx[1:-1, 1:-1]\n        yy_interior = yy[1:-1, 1:-1]\n        lap_U_exact = lap_u_func(xx_interior, yy_interior)\n\n        # Compute the maximum norm of the error over the interior grid.\n        error = np.max(np.abs(lap_h_U - lap_U_exact))\n        errors.append(error)\n\n    # Compute observed orders of convergence, p_k = log2(E_k / E_{k+1}).\n    orders = []\n    for k in range(num_meshes - 1):\n        if errors[k] > 0 and errors[k+1] > 0:\n            order = np.log2(errors[k] / errors[k+1])\n            orders.append(order)\n        else:\n            # This case (zero error) is not expected with the given functions,\n            # but is included for robustness.\n            orders.append(float('nan')) \n    \n    return orders\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the convergence studies.\n    \"\"\"\n    # Define manufactured solutions and their exact Laplacians.\n    u1 = lambda x, y: np.sin(np.pi * x) * np.sin(np.pi * y)\n    lap_u1 = lambda x, y: -2 * np.pi**2 * np.sin(np.pi * x) * np.sin(np.pi * y)\n    \n    u2 = lambda x, y: np.exp(x + y)\n    lap_u2 = lambda x, y: 2 * np.exp(x + y)\n    \n    u4 = lambda x, y: x**4 + y**4\n    lap_u4 = lambda x, y: 12 * x**2 + 12 * y**2\n\n    # Define the test cases as a list of tuples.\n    # Each tuple: (u_function, laplacian_function, initial_hx, initial_hy)\n    test_cases = [\n        # Case 1: Isotropic grid, trigonometric solution\n        (u1, lap_u1, 1/8, 1/8),\n        # Case 2: Isotropic grid, exponential solution\n        (u2, lap_u2, 1/8, 1/8),\n        # Case 3: Anisotropic grid, trigonometric solution\n        (u1, lap_u1, 1/16, 1/8),\n        # Case 4: Isotropic coarse grid, polynomial solution\n        (u4, lap_u4, 1/4, 1/4),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        u_func, lap_u_func, hx0, hy0 = case\n        orders = run_refinement_study(u_func, lap_u_func, hx0, hy0)\n        # Round orders to 3 decimal places as required.\n        rounded_orders = [round(p, 3) for p in orders]\n        all_results.append(rounded_orders)\n\n    # Format the final output string to match the exact specification.\n    # Example: [[2.000,2.000,2.000],[...]]\n    sublist_strings = []\n    for res in all_results:\n        # Format each number to 3 decimal places to ensure consistent output.\n        formatted_numbers = [f\"{x:.3f}\" for x in res]\n        sublist_strings.append(f\"[{','.join(formatted_numbers)}]\")\n    \n    final_output = f\"[{','.join(sublist_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "3230823"}, {"introduction": "上一个练习展示了理想情况下的二阶收敛性。然而，实际问题往往更为复杂，例如当计算区域包含尖角时，解的光滑性可能会被破坏。经典的有限差分理论预测的二阶收敛性依赖于解函数具有足够的连续高阶导数，但几何奇点（如 L 型区域的凹角）会挑战这一假设。通过解决一个在 L 型区域上的拉普拉斯问题 [@problem_id:3230895]，您将亲眼见证解的正则性（光滑度）降低如何导致收敛阶的下降。这个练习揭示了一个深刻的道理：理论精度估计是有前提条件的，理解这些前提是在实际工程问题中成功应用数值方法的关键。", "problem": "考虑 L 形区域上的拉普拉斯方程的狄利克雷边界值问题。设计算区域为正方形 $[-1,1]\\times[-1,1]$，并通过移除第一象限来定义 L 形区域 $\\Omega$，即 $\\Omega = \\{(x,y)\\in[-1,1]\\times[-1,1] : \\neg(x>0 \\wedge y>0)\\}$。控制方程为 $\\Omega$ 内的拉普拉斯方程 $\\Delta u = 0$，并在边界 $\\partial\\Omega$ 上给定狄利克雷边界条件 $u = g$。边界数据是通过限制一个在 $\\Omega$ 的凹角处呈现奇异梯度的解析调和函数来选择的。使用以 $(0,0)$ 为中心、$\\theta$ 以弧度计量的极坐标 $(r,\\theta)$，定义平移角 $\\theta' = \\theta - \\frac{\\pi}{2}$，并在必要时通过加 $2\\pi$ 将其调整到区间 $[0,2\\pi)$。设精确的调和函数为\n$$\nu_{\\text{exact}}(r,\\theta) = r^{\\frac{2}{3}} \\sin\\!\\left(\\frac{2}{3}\\,\\theta'\\right),\n$$\n该函数在远离 $r=0$ 的地方满足 $\\Delta u_{\\text{exact}}=0$，并且与形成内角为 $3\\pi/2$ 的凹角的两条射线上的零边界值相容。狄利克雷边界条件在整个边界 $\\partial\\Omega$上设为 $g = u_{\\text{exact}}$。\n\n从一个足够光滑的函数在均匀笛卡尔网格上的泰勒展开出发，推导出对拉普拉斯算子 $\\Delta u$ 的标准 5 点离散近似，并用它来组装和求解限制在 $\\Omega$ 上的网格上的离散狄利克雷问题。均匀网格间距为 $h = \\frac{1}{m}$，网格节点的坐标为 $x_i = -1 + i h$ 和 $y_j = -1 + j h$，其中整数索引 $i,j \\in \\{0,1,\\dots,2m\\}$。一个网格节点 $(x_i,y_j)$ 如果不在被移除的第一象限内，即 $i \\le m$ 或 $j \\le m$（或两者都满足），则该节点在 $\\Omega$ 内。如果一个网格节点位于外箱边界上（即 $i=0$、$i=2m$、$j=0$ 或 $j=2m$ 中的任意一个），或者位于形成凹角的、与坐标轴对齐的内部边界上（即 $(i=m$ 且 $j\\ge m)$ 或 $(j=m$ 且 $i\\ge m)$），则该节点是狄利克雷边界节点。$\\Omega$ 中所有其他节点都是内部未知数。角度必须以弧度处理。\n\n为了进行误差分析，设 $u_h$ 表示在网格节点上插值的数值解，并使用离散一致范数在内部未知数集合上测量误差\n$$\nE_{\\infty}(h) = \\max_{(x_i,y_j)\\in\\Omega_{\\text{int}}} \\left|u_h(x_i,y_j) - u_{\\text{exact}}(x_i,y_j)\\right|,\n$$\n其中 $\\Omega_{\\text{int}}$ 表示内部未知网格节点的集合。通过以下公式定义两个网格间距 $h_1$ 和 $h_2$ 之间的观测精度阶\n$$\np(h_1\\rightarrow h_2) = \\frac{\\log\\!\\left(E_{\\infty}(h_2)/E_{\\infty}(h_1)\\right)}{\\log\\!\\left(h_2/h_1\\right)}.\n$$\n由于凹角处的奇异性，预计全局收敛率将降低到与光滑解相关的标称二阶以下。\n\n实现一个完整、可运行的程序，该程序：\n- 使用推导出的 5 点模板构建离散系统，并根据 $u_{\\text{exact}}$ 施加狄利克雷边界条件。\n- 求解得到的关于内部未知数的线性系统。\n- 为每个测试网格计算 $E_{\\infty}(h)$。\n\n测试套件：\n- 使用三种网格分辨率，其中 $m\\in\\{4,8,16\\}$，对应于 $h\\in\\{\\frac{1}{4},\\frac{1}{8},\\frac{1}{16}\\}$。\n- 为保证覆盖性：$m=4$ 是粗分辨率（奇异角附近的边缘情况），$m=8$ 是中间情况（理想路径），$m=16$ 是更精细的分辨率。\n\n最终输出规格：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表。\n- 该列表必须按顺序包含以下条目：\n$$\n\\left[E_{\\infty}\\!\\left(\\tfrac{1}{4}\\right),\\;E_{\\infty}\\!\\left(\\tfrac{1}{8}\\right),\\;E_{\\infty}\\!\\left(\\tfrac{1}{16}\\right),\\;p\\!\\left(\\tfrac{1}{4}\\rightarrow\\tfrac{1}{8}\\right),\\;p\\!\\left(\\tfrac{1}{8}\\rightarrow\\tfrac{1}{16}\\right),\\;\\text{flag}_{4\\rightarrow 8},\\;\\text{flag}_{8\\rightarrow 16}\\right],\n$$\n其中每个 $E_{\\infty}(h)$ 和 $p(\\cdot)$ 是一个浮点数，每个 $\\text{flag}$ 是一个布尔值，如果观测阶严格小于 $2$，则为 $\\text{True}$，否则为 $\\text{False}$。用于计算 $u_{\\text{exact}}$ 的角度必须以弧度处理。", "solution": "用户希望在 L 形区域上求解具有奇异解的拉普拉斯方程，并分析 5 点有限差分法的收敛性。\n\n### 步骤 1：5 点拉普拉斯模板的推导\n\n有限差分法的基础是使用函数在邻近点的泰勒级数展开来近似其导数。设 $u(x,y)$ 是定义在某区域上的一个足够光滑的函数。我们考虑一个在 $x$ 和 $y$ 方向上间距均为 $h$ 的均匀笛卡尔网格。\n\n$u(x,y)$ 在点 $(x,y)$ 处沿 x 轴方向对其邻近点的泰勒展开为：\n$$\nu(x+h, y) = u(x,y) + h \\frac{\\partial u}{\\partial x}(x,y) + \\frac{h^2}{2!} \\frac{\\partial^2 u}{\\partial x^2}(x,y) + \\frac{h^3}{3!} \\frac{\\partial^3 u}{\\partial x^3}(x,y) + O(h^4)\n$$\n$$\nu(x-h, y) = u(x,y) - h \\frac{\\partial u}{\\partial x}(x,y) + \\frac{h^2}{2!} \\frac{\\partial^2 u}{\\partial x^2}(x,y) - \\frac{h^3}{3!} \\frac{\\partial^3 u}{\\partial x^3}(x,y) + O(h^4)\n$$\n\n将这两个方程相加可以消去奇数阶导数项：\n$$\nu(x+h, y) + u(x-h, y) = 2u(x,y) + h^2 \\frac{\\partial^2 u}{\\partial x^2}(x,y) + O(h^4)\n$$\n\n求解关于 $x$ 的二阶偏导数，得到二阶精度的中心差分近似：\n$$\n\\frac{\\partial^2 u}{\\partial x^2}(x,y) = \\frac{u(x+h, y) - 2u(x,y) + u(x-h, y)}{h^2} + O(h^2)\n$$\n\n通过对 $y$ 方向进行相同的论证，我们得到：\n$$\n\\frac{\\partial^2 u}{\\partial y^2}(x,y) = \\frac{u(x, y+h) - 2u(x,y) + u(x, y-h)}{h^2} + O(h^2)\n$$\n\n拉普拉斯算子 $\\Delta u$ 定义为 $\\Delta u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}$。代入中心差分近似，我们得到：\n$$\n\\Delta u(x,y) \\approx \\frac{u(x+h, y) - 2u(x,y) + u(x-h, y)}{h^2} + \\frac{u(x, y+h) - 2u(x,y) + u(x, y-h)}{h^2}\n$$\n$$\n\\Delta u(x,y) \\approx \\frac{u(x+h, y) + u(x-h, y) + u(x, y+h) + u(x, y-h) - 4u(x,y)}{h^2}\n$$\n假设 $u$ 足够光滑，此近似的截断误差为 $O(h^2)$。\n\n问题是求解拉普拉斯方程 $\\Delta u = 0$。使用离散近似，对于每个内部网格节点 $(x_i, y_j)$，我们有以下方程：\n$$\n\\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} = 0\n$$\n其中 $u_{i,j}$ 表示数值近似 $u_h(x_i, y_j)$。这可以简化为：\n$$\n4u_{i,j} - u_{i+1,j} - u_{i-1,j} - u_{i,j+1} - u_{i,j-1} = 0\n$$\n这个线性方程将一个节点上的值与其四个基本邻点上的值联系起来，形成了著名的拉普拉斯算子 5 点模板。\n\n### 步骤 2：组装并求解离散系统\n\n问题定义在通过均匀网格离散化的 L 形区域 $\\Omega$ 上。网格节点分为三类：\n1.  **内部节点**：位于 $\\Omega$ 内部、$u$ 的值未知的节点。\n2.  **边界节点**：位于边界 $\\partial\\Omega$ 上、其 $u$ 值由狄利克雷条件 $u=g$ 指定的节点。\n3.  **外部节点**：位于区域 $\\Omega$ 之外（在被移除的第一象限中）的节点，它们不参与计算。\n\n对于每个内部节点，我们写出一个 5 点模板方程实例。这会产生一个线性方程组，可以写成矩阵形式 $A\\mathbf{U} = \\mathbf{b}$，其中：\n-   $\\mathbf{U}$ 是所有内部节点上 $u$ 的未知值构成的向量。\n-   $A$ 是从模板推导出的系数矩阵。\n-   $\\mathbf{b}$ 是右端向量，它包含了来自边界节点的已知值。\n\n假设有 $N_{\\text{int}}$ 个内部节点。我们将每个内部节点的二维网格索引 $(i,j)$ 映射到一个唯一的一维索引 $k \\in \\{0, 1, ..., N_{\\text{int}}-1\\}$。矩阵 $A$ 将是一个 $N_{\\text{int}} \\times N_{\\text{int}}$ 的稀疏矩阵。对于对应于第 $k$ 个内部节点（位于网格位置 $(i,j)$）的方程：\n-   矩阵的对角元素是 $A_{k,k} = 4$。\n-   对于 $(i,j)$ 的每个邻点 $(i', j')$：\n    -   如果邻点也是一个一维索引为 $k'$ 的内部节点，则相应的非对角元素是 $A_{k, k'} = -1$。\n    -   如果邻点是边界节点，其值 $u_{i',j'}$ 从边界条件 $g(x_{i'}, y_{j'})$ 中可知。项 $-u_{i',j'}$ 被移到方程的右边。因此，值 $u_{i',j'}$ 被加到向量 $\\mathbf{b}$ 的第 $k$ 个元素上。\n\n为所有内部节点组装好矩阵 $A$ 和向量 $\\mathbf{b}$ 后，求解线性系统 $A\\mathbf{U} = \\mathbf{b}$ 以得到未知数向量 $\\mathbf{U}$。矩阵 $A$ 是对角占优且非奇异的，这保证了解的唯一性。\n\n### 步骤 3：误差分析\n\n解析解 $u_{\\text{exact}}$ 在极坐标 $(r,\\theta)$ 中给出：\n$$\nu_{\\text{exact}}(r,\\theta) = r^{\\frac{2}{3}} \\sin\\!\\left(\\frac{2}{3}\\,\\theta'\\right)\n$$\n其中 $\\theta' = (\\theta - \\pi/2) \\pmod{2\\pi}$。该函数在原点 $(r=0)$ 处有一个奇异点，其梯度在此处是无界的。对于光滑解，标准有限差分理论预测收敛阶为二阶（$O(h^2)$）。然而，凹角处奇异性的存在降低了全局精度阶。预期的阶为 $\\alpha = 2/3$，这对应于解的主奇异项中 $r$ 的指数。\n\n实现将执行以下操作：\n1.  对于每个网格分辨率 $m \\in \\{4, 8, 16\\}$，构建网格并对节点进行分类。\n2.  将内部节点映射到索引，并确定线性系统的大小 $N_{\\text{int}}$。\n3.  组装 $N_{\\text{int}} \\times N_{\\text{int}}$ 矩阵 $A$ 和 $N_{\\text{int}}$ 维向量 $\\mathbf{b}$。边界值使用提供的 $u_{\\text{exact}}$ 函数计算。\n4.  使用直接求解器求解线性系统 $A\\mathbf{U} = \\mathbf{b}$。\n5.  在所有内部节点上计算最大绝对误差 $E_{\\infty}(h) = \\max |u_h - u_{\\text{exact}}|$。\n6.  使用针对不同 $h$ 值计算出的误差来计算观测精度阶 $p$。\n7.  检查观测阶 $p$ 是否严格小于 $2$。\n\n此过程针对指定的测试套件实现，以生成所需的输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef u_exact_func(x: float, y: float) - float:\n    \"\"\"\n    Computes the value of the exact analytical solution at a point (x, y).\n\n    Args:\n        x: The x-coordinate.\n        y: The y-coordinate.\n\n    Returns:\n        The value of the exact solution u(x, y).\n    \"\"\"\n    r = np.sqrt(x**2 + y**2)\n    if r == 0.0:\n        return 0.0\n    \n    # atan2(y, x) gives angle in (-pi, pi].\n    theta = np.arctan2(y, x)\n    \n    # Shifted angle theta' = theta - pi/2, adjusted to [0, 2pi)\n    theta_prime = theta - np.pi / 2.0\n    if theta_prime  0:\n        theta_prime += 2 * np.pi\n\n    alpha = 2.0 / 3.0\n    return r**alpha * np.sin(alpha * theta_prime)\n\ndef compute_error_for_m(m: int) - float:\n    \"\"\"\n    Solves the Laplace equation on an L-shaped domain for a given grid parameter m\n    and returns the maximum error on the interior nodes.\n\n    Args:\n        m: The grid resolution parameter.\n\n    Returns:\n        The discrete uniform norm of the error, E_infinity(h).\n    \"\"\"\n    h = 1.0 / m\n    dim = 2 * m + 1\n    \n    # Create coordinate vectors for the grid\n    coords = -1.0 + np.arange(dim) * h\n    \n    # Classify nodes and map interior nodes to a 1D index\n    interior_nodes_map = {}  # (i, j) - k\n    interior_nodes_list = []  # k - (i, j)\n    k = 0\n    \n    # Use boolean arrays for efficient node type checking\n    is_boundary_node = np.zeros((dim, dim), dtype=bool)\n    is_domain_node = np.zeros((dim, dim), dtype=bool)\n\n    for j in range(dim):\n        for i in range(dim):\n            # Node is in the computational domain if not in the removed quadrant.\n            # Removed quadrant is x  0 and y  0, which corresponds to i  m and j  m.\n            if not(i > m and j > m):\n                is_domain_node[i, j] = True\n    \n    for j in range(dim):\n        for i in range(dim):\n            if not is_domain_node[i, j]:\n                continue\n            \n            # A node is boundary if on outer box or on the re-entrant corner boundary\n            if (i == 0 or i == 2*m or j == 0 or j == 2*m or\n                (i == m and j >= m) or (j == m and i >= m)):\n                is_boundary_node[i, j] = True\n            else:\n                # It's an interior node\n                interior_nodes_map[(i, j)] = k\n                interior_nodes_list.append((i, j))\n                k += 1\n\n    num_interior = len(interior_nodes_list)\n    A = np.zeros((num_interior, num_interior))\n    b = np.zeros(num_interior)\n\n    # Assemble matrix A and vector b\n    for current_k, (i, j) in enumerate(interior_nodes_list):\n        A[current_k, current_k] = 4.0\n        \n        # Consider the four neighbors\n        neighbors = [(i + 1, j), (i - 1, j), (i, j + 1), (i, j - 1)]\n        for ni, nj in neighbors:\n            if not is_boundary_node[ni, nj]:\n                # Neighbor is an interior node\n                neighbor_k = interior_nodes_map[(ni, nj)]\n                A[current_k, neighbor_k] = -1.0\n            else:\n                # Neighbor is a boundary node, so its value is known\n                x_n, y_n = coords[ni], coords[nj]\n                b[current_k] += u_exact_func(x_n, y_n)\n\n    # Solve the linear system for interior node values\n    if num_interior > 0:\n        U_interior_vec = np.linalg.solve(A, b)\n    else:\n        U_interior_vec = np.array([])\n\n    # Calculate the maximum error on the interior nodes\n    max_error = 0.0\n    for k in range(num_interior):\n        i, j = interior_nodes_list[k]\n        x_i, y_j = coords[i], coords[j]\n        \n        numerical_val = U_interior_vec[k]\n        exact_val = u_exact_func(x_i, y_j)\n        \n        error = np.abs(numerical_val - exact_val)\n        if error > max_error:\n            max_error = error\n            \n    return max_error\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the final results.\n    \"\"\"\n    test_cases = [4, 8, 16]\n    \n    errors = [compute_error_for_m(m) for m in test_cases]\n    \n    h_values = [1.0/m for m in test_cases]\n\n    # Calculate observed orders of accuracy\n    p1 = np.log(errors[1] / errors[0]) / np.log(h_values[1] / h_values[0])\n    p2 = np.log(errors[2] / errors[1]) / np.log(h_values[2] / h_values[1])\n    \n    # Check if a convergence order is strictly less than 2\n    flag1 = p1  2.0\n    flag2 = p2  2.0\n    \n    results = [\n        errors[0],\n        errors[1],\n        errors[2],\n        p1,\n        p2,\n        flag1,\n        flag2\n    ]\n    \n    # Format the final output string\n    # str() on a boolean produces 'True' or 'False' as required.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3230895"}, {"introduction": "我们已经探讨了解的光滑性对收敛性的影响。现在，让我们回到一个具有光滑解的简单区域问题上，来探究该方法另一个更微妙的特性：网格与解特征方向之间的相互作用。标准的五点模版存在固有的网格各向异性，这意味着它在解析不同方向的特征时，其精度表现可能有所不同。通过对比一个与坐标轴对齐的特征和另一个对角线方向的特征所产生的误差 [@problem_id:2393578]，您将发现这种简单模版的一个内在局限性。这个实践旨在培养对数值误差更具批判性和细致的理解，并揭示了为何在某些情况下需要发展更高级的离散格式。", "problem": "考虑单位正方形域上的二维泊松方程，其解具有强但平滑的特征，主方向与网格轴对齐或呈对角线方向。该数学模型是关于标量场 $u(x,y)$ 在 $[0,1]\\times[0,1]$ 上的边值问题，\n$$- \\nabla^2 u(x,y) = f(x,y), \\quad (x,y)\\in (0,1)\\times(0,1),$$\n边界 $\\partial([0,1]\\times[0,1])$ 上具有狄利克雷边界条件 $u(x,y) = u_{\\text{exact}}(x,y)$。拉普拉斯算子 $\\nabla^2$ 定义为 $\\nabla^2 u = \\partial^2 u / \\partial x^2 + \\partial^2 u / \\partial y^2$。您必须在均匀网格上使用标准的五点中心差分有限差分法来近似算子 $\\nabla^2$，并求解得到的线性系统以获得内部网格点上的 $u(x,y)$。\n\n使用人工解法定义两个精确解 $u_{\\text{exact}}(x,y)$，其尖锐度由宽度参数 $\\sigma > 0$ 控制，方向分别为：\n- 与直线 $x=y$ 对齐的对角线脊：\n  $$u_{\\mathrm{diag}}(x,y;\\sigma) = \\exp\\!\\left(-\\frac{(x-y)^2}{2\\sigma^2}\\right).$$\n- 沿 x 轴方向、以 $x=0.5$ 为中心的轴对齐脊：\n  $$u_{\\mathrm{axis}}(x,y;\\sigma) = \\exp\\!\\left(-\\frac{(x-0.5)^2}{2\\sigma^2}\\right).$$\n\n对于每一个人解，通过将连续拉普拉斯算子 $\\nabla^2$ 应用于 $u_{\\text{exact}}$ 来计算其连续的右端项 $f(x,y)$，并设 $f(x,y) = -\\nabla^2 u_{\\text{exact}}(x,y)$。对于对角线脊，请注意 $u_{\\mathrm{diag}}(x,y;\\sigma)$ 仅依赖于 $s=x-y$；对于函数 $g(s)$，使用恒等式 $\\partial^2 g/\\partial x^2 = g''(s)$ 和 $\\partial^2 g/\\partial y^2 = g''(s)$，两者共同意味着 $\\nabla^2 g(s) = 2 g''(s)$。对于轴对齐脊，请注意 $u_{\\mathrm{axis}}(x,y;\\sigma)$ 仅依赖于 $x$，因此 $\\nabla^2 u_{\\mathrm{axis}} = \\partial^2 u_{\\mathrm{axis}}/\\partial x^2$。这些运算都是连续求导；不要使用离散近似来构造 $f(x,y)$。\n\n使用一个包含 $N\\times N$ 个点的均匀笛卡尔网格对域进行离散化，网格间距为 $h = 1/(N-1)$，其中 $N$ 是一个奇数，以保证直线 $y=0.5$ 是一条网格行。在内部点 $(i,j)$ 上组装用于拉普拉斯算子的标准五点模板，并通过将边界值设为精确的人工解来施加狄利克雷边界条件。仅使用标准五点模板为内部未知数构造并求解线性系统；不要使用任何更高阶或九点模板。\n\n在同一网格和相同 $\\sigma$ 值下，计算对角线和轴对齐人工解的数值解后，通过插入精确的边界值来重建完整网格。然后，评估以下两种逐行的最大绝对误差：\n- 对角线误差 $E_{\\mathrm{diag}}$：沿离散对角网格线 $x=y$（即索引为 $i=j$ 的节点）上，数值解与精确解之间的最大绝对差，并用该线上精确解的最大振幅进行归一化。对于 $u_{\\mathrm{diag}}$，沿 $x=y$ 的精确值在该线上的所有点均为 $1$。\n- 轴线误差 $E_{\\mathrm{axis}}$：沿水平线 $y=0.5$（即索引为 $j=(N-1)/2$ 的节点）上，数值解与精确解之间的最大绝对差，并用该线上精确解的最大振幅进行归一化。对于 $u_{\\mathrm{axis}}$，沿 $y=0.5$ 的精确峰值出现在 $x=0.5$ 处，其值为 $1$。\n\n定义失效比\n$$R(N,\\sigma) = \\frac{E_{\\mathrm{diag}}}{E_{\\mathrm{axis}}}.$$\n$R(N,\\sigma) > 1$ 的值表示，对于对角线对齐的尖锐特征，五点模板产生的误差大于轴对齐特征的误差，这证明了其网格对齐的各向异性，以及在相当的分辨率下未能解析对角线方向的尖锐度。\n\n您的程序必须：\n- 实现五点中心差分法，使用相同的网格和 $\\sigma$ 求解 $u_{\\mathrm{diag}}$ 和 $u_{\\mathrm{axis}}$ 的泊松问题。\n- 为每个测试用例计算 $E_{\\mathrm{diag}}$、$E_{\\mathrm{axis}}$ 和 $R(N,\\sigma)$。\n- 按照下文指定的方式，将所有比率作为单个列表输出到一行。\n\n不涉及物理单位。不使用角度。所有浮点输出均以普通十进制表示法表示。\n\n用于评估覆盖范围的测试套件：\n- 用例 1（分辨率不足的对角线特征）：$N=33$, $\\sigma=0.02$。\n- 用例 2（提高的分辨率）：$N=65$, $\\sigma=0.02$。\n- 用例 3（粗网格上的更宽特征）：$N=33$, $\\sigma=0.04$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含与上述用例相对应的三个比率 $R(N,\\sigma)$，格式为用方括号括起来的逗号分隔列表，每个值四舍五入到 6 位小数（例如 $[r_1,r_2,r_3]$）。", "solution": "所提出的问题是一个有效且适定的数值分析练习。它涉及使用五点有限差分法求解二维泊松方程，并使用人工解法来分析该模板的各向异性误差特性。所有必需信息均已提供，物理和数学基础可靠，且目标清晰可验证。\n\n问题是在单位正方形域 $\\Omega = [0,1]\\times[0,1]$ 上求解泊松方程：\n$$ - \\nabla^2 u(x,y) = f(x,y), \\quad (x,y) \\in (0,1)\\times(0,1) $$\n边界条件为狄利克雷边界条件 $u(x,y) = u_{\\text{exact}}(x,y)$，其中 $(x,y) \\in \\partial\\Omega$。算子 $\\nabla^2$ 是拉普拉斯算子，$\\nabla^2 u = \\frac{\\partial^2 u}{\\partial x^2} + \\frac{\\partial^2 u}{\\partial y^2}$。\n\n此处采用了人工解法。我们定义了两个精确解，$u_{\\mathrm{diag}}$ 和 $u_{\\mathrm{axis}}$，并通过应用连续算子推导出相应的强迫函数 $f(x,y)$：$f = -\\nabla^2 u_{\\text{exact}}$。\n\n对于对角线脊，$u_{\\mathrm{diag}}(x,y;\\sigma) = \\exp(-\\frac{(x-y)^2}{2\\sigma^2})$。令 $g(s) = \\exp(-s^2/(2\\sigma^2))$，其中 $s=x-y$。其导数为 $g'(s) = -\\frac{s}{\\sigma^2}g(s)$ 和 $g''(s) = (\\frac{s^2}{\\sigma^4} - \\frac{1}{\\sigma^2})g(s)$。使用恒等式 $\\nabla^2 g(x-y) = 2g''(x-y)$，强迫函数为：\n$$ f_{\\mathrm{diag}}(x,y;\\sigma) = -2 g''(x-y) = -2 \\left(\\frac{(x-y)^2}{\\sigma^4} - \\frac{1}{\\sigma^2}\\right) \\exp\\left(-\\frac{(x-y)^2}{2\\sigma^2}\\right) = 2\\left(\\frac{1}{\\sigma^2} - \\frac{(x-y)^2}{\\sigma^4}\\right) \\exp\\left(-\\frac{(x-y)^2}{2\\sigma^2}\\right) $$\n\n对于轴对齐脊，$u_{\\mathrm{axis}}(x,y;\\sigma) = \\exp(-\\frac{(x-0.5)^2}{2\\sigma^2})$。此函数仅依赖于 $x$。令 $h(x) = \\exp(-(x-0.5)^2/(2\\sigma^2))$。拉普拉斯算子为 $\\nabla^2 h(x) = \\frac{d^2h}{dx^2}$。其二阶导数为 $\\frac{d^2h}{dx^2} = (\\frac{(x-0.5)^2}{\\sigma^4} - \\frac{1}{\\sigma^2})h(x)$。强迫函数为：\n$$ f_{\\mathrm{axis}}(x,y;\\sigma) = -\\frac{d^2u_{\\mathrm{axis}}}{dx^2} = -\\left(\\frac{(x-0.5)^2}{\\sigma^4} - \\frac{1}{\\sigma^2}\\right) \\exp\\left(-\\frac{(x-0.5)^2}{2\\sigma^2}\\right) = \\left(\\frac{1}{\\sigma^2} - \\frac{(x-0.5)^2}{\\sigma^4}\\right) \\exp\\left(-\\frac{(x-0.5)^2}{2\\sigma^2}\\right) $$\n\n域通过一个包含 $N \\times N$ 个点的均匀笛卡尔网格进行离散化，其中 $N$ 为奇数。网格间距为 $h = 1/(N-1)$。设网格点为 $(x_i, y_j) = (ih, jh)$，其中 $i,j \\in \\{0, 1, \\dots, N-1\\}$。设 $U_{i,j}$ 为 $u(x_i, y_j)$ 的数值近似。\n\n在内部网格点 $(x_i, y_j)$（其中 $i,j \\in \\{1, \\dots, N-2\\}$）处，负拉普拉斯算子的标准$5$点中心差分近似为：\n$$ -\\nabla^2 u(x_i, y_j) \\approx \\frac{-U_{i+1,j} - U_{i-1,j} - U_{i,j+1} - U_{i,j-1} + 4U_{i,j}}{h^2} $$\n将其设为等于强迫项 $f(x_i, y_j) = f_{i,j}$，得到离散方程：\n$$ 4U_{i,j} - U_{i+1,j} - U_{i-1,j} - U_{i,j+1} - U_{i,j-1} = h^2 f_{i,j} $$\n必须求解此线性方程组，以获得 $(N-2) \\times (N-2)$ 个未知的内部值 $U_{i,j}$。边界上的值（$i=0$, $i=N-1$, $j=0$ 或 $j=N-1$）由狄利克雷条件 $U_{i,j} = u_{\\text{exact}}(x_i, y_j)$ 给出，是已知的。这些已知的边界值被移到与边界相邻的内部点方程的右侧。\n\n这就形成了一个形如 $A\\mathbf{u} = \\mathbf{b}$ 的线性系统，其中 $\\mathbf{u}$ 是一个包含 $(N-2)^2$ 个未知内部网格值的向量，$A$ 是一个大小为 $(N-2)^2 \\times (N-2)^2$ 的稀疏、对称正定、块三对角矩阵，$\\mathbf{b}$ 是右端项向量，包含了强迫项 $f$ 和边界条件。矩阵 $A$ 的主对角线元素为 $4$，对应于 $5$ 点模板中四个邻居的元素为 $-1$。这个稀疏系统通过数值方法求解。\n\n求解内部值后，通过将内部解嵌入到已知的精确边界值中，来重建完整的数值解网格。\n\n然后沿特定线评估误差。对角线误差 $E_{\\mathrm{diag}}$ 是为 $u_{\\mathrm{diag}}$ 情况计算的：\n$$ E_{\\mathrm{diag}} = \\frac{\\max_{i \\in \\{0, \\dots, N-1\\}} |U_{i,i} - u_{\\mathrm{diag}}(x_i, x_i)|}{\\max_{i} u_{\\mathrm{diag}}(x_i, x_i)} = \\max_{i} |U_{i,i} - 1| $$\n轴线误差 $E_{\\mathrm{axis}}$ 是为 $u_{\\mathrm{axis}}$ 情况沿直线 $y=0.5$ 计算的，该直线对应于网格索引 $j_{\\text{mid}} = (N-1)/2$：\n$$ E_{\\mathrm{axis}} = \\frac{\\max_{i \\in \\{0, \\dots, N-1\\}} |U_{i,j_{\\text{mid}}} - u_{\\mathrm{axis}}(x_i, y_{j_{\\text{mid}}})|}{\\max_{i} u_{\\mathrm{axis}}(x_i, y_{j_{\\text{mid}}})} = \\max_{i} |U_{i,j_{\\text{mid}}} - u_{\\mathrm{axis}}(x_i, y_{j_{\\text{mid}}})| $$\n在这两种情况下，沿各自线上精确解的归一化最大振幅均为 $1$。\n\n最后，计算失效比 $R(N,\\sigma) = E_{\\mathrm{diag}} / E_{\\mathrm{axis}}$ 以量化模板的各向异性误差。所提供的程序为每个指定的测试用例实现了这整个过程。", "answer": "```python\nimport numpy as np\nfrom scipy import sparse\nfrom scipy.sparse.linalg import spsolve\n\ndef u_diag_func(X, Y, sigma):\n    \"\"\"Computes the exact solution for the diagonal ridge case.\"\"\"\n    s_sq = (X - Y)**2\n    sigma_sq = sigma**2\n    return np.exp(-s_sq / (2 * sigma_sq))\n\ndef f_diag_func(X, Y, sigma):\n    \"\"\"Computes the forcing term for the diagonal ridge case.\"\"\"\n    s_sq = (X - Y)**2\n    sigma_sq = sigma**2\n    sigma_4 = sigma**4\n    exp_term = np.exp(-s_sq / (2 * sigma_sq))\n    return 2 * (1 / sigma_sq - s_sq / sigma_4) * exp_term\n\ndef u_axis_func(X, Y, sigma):\n    \"\"\"Computes the exact solution for the axis-aligned ridge case.\"\"\"\n    z_sq = (X - 0.5)**2\n    sigma_sq = sigma**2\n    return np.exp(-z_sq / (2 * sigma_sq))\n\ndef f_axis_func(X, Y, sigma):\n    \"\"\"Computes the forcing term for the axis-aligned ridge case.\"\"\"\n    z_sq = (X - 0.5)**2\n    sigma_sq = sigma**2\n    sigma_4 = sigma**4\n    exp_term = np.exp(-z_sq / (2 * sigma_sq))\n    return (1 / sigma_sq - z_sq / sigma_4) * exp_term\n\ndef solve_poisson(N, sigma, u_exact_func, f_func):\n    \"\"\"\n    Solves the 2D Poisson equation using a 5-point finite difference stencil.\n    \"\"\"\n    h = 1.0 / (N - 1)\n    x = np.linspace(0.0, 1.0, N)\n    y = np.linspace(0.0, 1.0, N)\n    X, Y = np.meshgrid(x, y, indexing='xy')\n\n    # Evaluate exact solution and forcing term on the full grid\n    u_exact = u_exact_func(X, Y, sigma)\n    f = f_func(X, Y, sigma)\n    \n    # Number of interior points in one dimension\n    M = N - 2\n    \n    # Construct the sparse matrix A for the linear system\n    main_diag = np.ones(M) * 4\n    off_diag = np.ones(M - 1) * -1\n    T = sparse.diags([off_diag, main_diag, off_diag], [-1, 0, 1], shape=(M, M), format='csr')\n    I_M = sparse.eye(M, format='csr')\n    A = sparse.kron(I_M, T) + sparse.diags([np.ones(M*(M-1))*-1, np.ones(M*(M-1))*-1], [-M, M], format='csr')\n    A = A.tocsc()\n\n    # Construct the right-hand side vector b\n    b_2d = h**2 * f[1:-1, 1:-1]\n    \n    # Add boundary condition contributions to b\n    # Note: U[j, i] corresponds to u at (x_i, y_j)\n    b_2d[:, 0] += u_exact[1:-1, 0]   # Left boundary (x=0)\n    b_2d[:, -1] += u_exact[1:-1, -1] # Right boundary (x=1)\n    b_2d[0, :] += u_exact[0, 1:-1]   # Bottom boundary (y=0)\n    b_2d[-1, :] += u_exact[-1, 1:-1] # Top boundary (y=1)\n    \n    b = b_2d.flatten(order='F') # Flatten column-major, for (i,j) - k=(i-1)*M+(j-1)\n\n    # Solve the linear system\n    u_vec = spsolve(A, b)\n    \n    # Reshape solution vector to grid and insert into full solution grid\n    U_interior = u_vec.reshape((M, M), order='F')\n    U_numerical = np.copy(u_exact)\n    U_numerical[1:-1, 1:-1] = U_interior\n    \n    return U_numerical, u_exact\n\ndef solve():\n    test_cases = [\n        (33, 0.02),\n        (65, 0.02),\n        (33, 0.04),\n    ]\n\n    results = []\n    for N, sigma in test_cases:\n        # Diagonal case\n        U_diag_numerical, u_exact_diag_grid = solve_poisson(N, sigma, u_diag_func, f_diag_func)\n        diag_numerical = np.diag(U_diag_numerical)\n        diag_exact = np.diag(u_exact_diag_grid)\n        E_diag = np.max(np.abs(diag_numerical - diag_exact))\n\n        # Axis-aligned case\n        U_axis_numerical, u_exact_axis_grid = solve_poisson(N, sigma, u_axis_func, f_axis_func)\n        j_mid = (N - 1) // 2\n        axis_numerical_row = U_axis_numerical[j_mid, :]\n        axis_exact_row = u_exact_axis_grid[j_mid, :]\n        E_axis = np.max(np.abs(axis_numerical_row - axis_exact_row))\n        \n        # Failure ratio\n        R = E_diag / E_axis\n        results.append(R)\n\n    # Format results for printing\n    formatted_results = [f'{r:.6f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2393578"}]}