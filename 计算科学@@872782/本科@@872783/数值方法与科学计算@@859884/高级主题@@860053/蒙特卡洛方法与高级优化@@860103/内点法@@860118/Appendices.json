{"hands_on_practices": [{"introduction": "内点法的核心在于通过一系列迭代逼近最优解。为了具体理解这一过程，本练习将指导你手动完成一次完整的原始-对偶内点法迭代。通过将一个特征值最小化问题转化为半定规划（SDP），你将亲手计算Nesterov–Todd（NT）缩放方向并更新解，从而深入理解算法的内部运作机制。[@problem_id:3242579]", "problem": "您将完成一个分为两部分的任务，该任务将约束特征值最小化问题与半定规划 (SDP) 联系起来，然后使用 Nesterov–Todd (NT) 缩放执行一次原始-对偶内点法的迭代。\n\n第一部分（公式化）。考虑约束特征值最小化问题\n- 最小化对称矩阵 $Z \\in \\mathbb{S}^{2}$ 的最大特征值，\n- 约束条件为线性约束 $\\operatorname{tr}(Z) = 2$。\n\n从最大特征值 $\\lambda_{\\max}(Z)$ 的定义（即满足 $t I - Z \\succeq 0$ 的最小实数 $t$）出发，推导出一个以 $(t, Z)$ 为决策变量的等价线性矩阵不等式 (LMI) 公式作为半定规划 (SDP)，并明确陈述所得的锥形式约束。\n\n第二部分（一次 NT 缩放的原始-对偶迭代和中心性对称）。考虑与锥块 $X \\in \\mathbb{S}^{2}$ 相关联的标准形式半定规划 (SDP)，定义如下\n- 最小化 $C \\bullet X$，\n- 约束条件为 $A \\bullet X = b$，\n- 且 $X \\succ 0$，\n其中 $C = 0 \\cdot I \\in \\mathbb{S}^{2}$，$A = I \\in \\mathbb{S}^{2}$，$b = 2 \\in \\mathbb{R}$，且 $\\bullet$ 表示 Frobenius 内积。其对偶问题是\n- 最大化 $b y$，\n- 约束条件为 $A^{*}(y) + S = C$，\n- 且 $S \\succ 0$，\n其中 $A^{*}(y) = y I$ 且 $S \\in \\mathbb{S}^{2}$。\n\n从严格可行的原始-对偶点 $(X_{0}, y_{0}, S_{0})$ 开始，其中 $X_{0} = I$，$y_{0} = -2$，$S_{0} = 2 I$。将中心化参数设置为 $\\sigma = \\tfrac{1}{2}$。使用 Nesterov–Todd (NT) 缩放的原始-对偶方向，计算一次迭代。如果完整步长能保持正定性，则使用完整步长；否则，使用能维持 $X \\succ 0$ 和 $S \\succ 0$ 的最大步长。然后：\n- 计算更新后的对偶性度量 $\\mu_{1} = \\tfrac{1}{n} \\operatorname{tr}(X_{1} S_{1})$，其中 $n = 2$，\n- 并验证中心性对称条件 $X_{1} S_{1} = \\mu_{1} I$。\n\n报告 $\\mu_{1}$ 的单个标量值作为最终答案。无需四舍五入；请提供精确值。", "solution": "首先验证问题陈述，以确保其具有科学依据、良构且客观。\n\n### 第 1 步：提取已知条件\n**第一部分：**\n- 目标：最小化对称矩阵 $Z \\in \\mathbb{S}^{2}$ 的最大特征值 $\\lambda_{\\max}(Z)$。\n- 约束：$\\operatorname{tr}(Z) = 2$。\n- 定义：$\\lambda_{\\max}(Z)$ 是满足 $t I - Z \\succeq 0$ 的最小实数 $t$。\n- 任务：推导出一个以 $(t, Z)$ 为决策变量的等价半定规划 (SDP)，并陈述其锥形式约束。\n\n**第二部分：**\n- 原始 SDP：最小化 $C \\bullet X$，约束条件为 $A \\bullet X = b$ 且 $X \\succ 0$。\n- 原始数据：$X \\in \\mathbb{S}^{2}$，$C = 0 \\cdot I \\in \\mathbb{S}^{2}$，$A = I \\in \\mathbb{S}^{2}$，$b = 2 \\in \\mathbb{R}$。\n- 对偶 SDP：最大化 $b y$，约束条件为 $A^{*}(y) + S = C$ 且 $S \\succ 0$。\n- 对偶数据：$S \\in \\mathbb{S}^{2}$，$A^{*}(y) = y I$。\n- 初始点：$(X_{0}, y_{0}, S_{0})$，其中 $X_{0} = I$，$y_{0} = -2$，$S_{0} = 2 I$。\n- 中心化参数：$\\sigma = \\frac{1}{2}$。\n- 方法：Nesterov–Todd (NT) 缩放的原始-对偶方向。\n- 任务：\n  1. 如果完整步长可行，则使用完整步长计算一次迭代以找到 $(X_1, S_1, y_1)$，否则使用最大可行步长。\n  2. 计算更新后的对偶性度量 $\\mu_{1} = \\frac{1}{n} \\operatorname{tr}(X_{1} S_{1})$，其中 $n = 2$。\n  3. 验证中心性对称条件 $X_{1} S_{1} = \\mu_{1} I$。\n  4. 报告 $\\mu_1$ 的值。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题定义明确，由两部分组成。\n\n第一部分是凸优化领域的一个标准重构任务，将一个特征值最小化问题转换为 SDP。所提供的定义是正确的。\n\n第二部分建立了一个特定的 SDP，并要求进行一次原始-对偶内点法的迭代。让我们验证初始点 $(X_0, y_0, S_0)$ 的可行性。\n- 原始严格可行性 ($X_0 \\succ 0$)：$X_0 = I$ 是 $\\mathbb{S}^2$ 中的单位矩阵，是正定的。此条件成立。\n- 原始约束满足 ($A \\bullet X_0 = b$)：$A \\bullet X_0 = I \\bullet I = \\operatorname{tr}(I^T I) = \\operatorname{tr}(I) = 2$。给定的 $b=2$。约束得到满足。\n- 对偶严格可行性 ($S_0 \\succ 0$)：$S_0 = 2I$ 是正定的。此条件成立。\n- 对偶约束满足 ($A^{*}(y_0) + S_0 = C$)：$A^{*}(y_0) + S_0 = y_0 I + S_0 = (-2)I + 2I = 0$。给定的 $C = 0 \\cdot I = 0$。约束得到满足。\n\n所有数据都是自洽和一致的。该问题在数值优化方面有科学依据，是客观且良构的。未检测到任何缺陷。\n\n### 第 3 步：结论与行动\n该问题是有效的。将提供完整解答。\n\n### 第一部分：公式化\n\n问题是最小化对称矩阵 $Z \\in \\mathbb{S}^{2}$ 的最大特征值，约束条件是其迹的线性约束。\n$$\n\\begin{array}{ll}\n\\text{minimize}   \\lambda_{\\max}(Z) \\\\\n\\text{subject to}  \\operatorname{tr}(Z) = 2, \\\\\n Z \\in \\mathbb{S}^{2}.\n\\end{array}\n$$\n我们引入一个辅助标量变量 $t \\in \\mathbb{R}$。目标可以重构为最小化 $t$，附加约束为 $t \\ge \\lambda_{\\max}(Z)$。问题变为：\n$$\n\\begin{array}{ll}\n\\text{minimize}   t \\\\\n\\text{subject to}  \\lambda_{\\max}(Z) \\le t, \\\\\n \\operatorname{tr}(Z) = 2, \\\\\n Z \\in \\mathbb{S}^{2}, t \\in \\mathbb{R}.\n\\end{array}\n$$\n问题陈述提供了关键的等价关系：$\\lambda_{\\max}(Z) \\le t$ 等价于线性矩阵不等式 (LMI) $t I - Z \\succeq 0$，其中 $\\succeq 0$ 表示矩阵是半正定的，$I$ 是 $2 \\times 2$ 的单位矩阵。\n\n代入这个等价关系，得到以决策变量 $(t, Z)$ 表示的 SDP 公式：\n$$\n\\begin{array}{ll}\n\\text{minimize}   t \\\\\n\\text{subject to}  \\operatorname{tr}(Z) = 2, \\\\\n t I - Z \\succeq 0.\n\\end{array}\n$$\n所得约束明确如下：\n1.  一个线性等式约束：$\\operatorname{tr}(Z) = 2$。\n2.  一个锥约束（具体来说，是一个 LMI）：矩阵 $t I - Z$ 必须是半正定的。\n\n### 第二部分：一次 NT 缩放的原始-对偶迭代\n\n给定 SDP 的原始-对偶对和一个初始严格可行点 $(X_0, y_0, S_0) = (I, -2, 2I)$。矩阵维度为 $n=2$。\n\n首先，我们计算初始对偶性度量 $\\mu_0$：\n$$ \\mu_0 = \\frac{1}{n} \\operatorname{tr}(X_0 S_0) = \\frac{1}{2} \\operatorname{tr}(I \\cdot 2I) = \\frac{1}{2} \\operatorname{tr}(2I) = \\frac{1}{2}(2+2) = 2. $$\n我们观察到 $X_0 S_0 = I (2I) = 2I$ 且 $\\mu_0 I = 2I$。因此，$X_0 S_0 = \\mu_0 I$，这意味着初始点位于中心路径上。\n\nNesterov-Todd (NT) 方向 $(\\Delta X, \\Delta y, \\Delta S)$ 是通过求解扰动障碍问题的线性化 KKT 系统找到的。由于初始点是可行的，可行性残差为零。用于求解方向的系统是：\n1.  原始可行性：$A \\bullet \\Delta X = 0 \\implies \\operatorname{tr}(\\Delta X) = 0$。\n2.  对偶可行性：$A^{*}(\\Delta y) + \\Delta S = 0 \\implies (\\Delta y)I + \\Delta S = 0$。\n3.  中心性条件：$\\Delta X S_0 + X_0 \\Delta S = \\sigma \\mu_0 I - X_0 S_0$。\n\n对于中心路径上的一个起始点，其中 $X_0$ 和 $S_0$ 是单位矩阵的倍数，它们是可交换的，因此 $X_0 S_0 = S_0 X_0$。在这种情况下，NT 方向系统得以简化，并等价于其他常见的原始-对偶方向。\n\n让我们求解这个系统。\n从(2)可知，我们有 $\\Delta S = -(\\Delta y)I$。\n\n现在，我们计算方程(3)的右侧：\n$$ \\sigma \\mu_0 I - X_0 S_0 = \\frac{1}{2}(2)I - 2I = I - 2I = -I. $$\n将 $X_0 = I$，$S_0 = 2I$ 以及右侧的表达式代入(3)：\n$$ \\Delta X (2I) + I (\\Delta S) = -I \\implies 2\\Delta X + \\Delta S = -I. $$\n现在代入 $\\Delta S = -(\\Delta y)I$：\n$$ 2\\Delta X - (\\Delta y)I = -I. $$\n为了求解 $\\Delta y$，我们对这个方程取迹，并使用来自(1)的条件 $\\operatorname{tr}(\\Delta X)=0$：\n$$ \\operatorname{tr}(2\\Delta X - (\\Delta y)I) = \\operatorname{tr}(-I) $$\n$$ 2\\operatorname{tr}(\\Delta X) - \\Delta y \\operatorname{tr}(I) = -2 $$\n$$ 2(0) - \\Delta y(2) = -2 $$\n$$ -2\\Delta y = -2 \\implies \\Delta y = 1. $$\n根据 $\\Delta y = 1$，我们求得 $\\Delta S$：\n$$ \\Delta S = -(\\Delta y)I = -I. $$\n并且我们求得 $\\Delta X$：\n$$ 2\\Delta X - (1)I = -I \\implies 2\\Delta X = 0 \\implies \\Delta X = 0. $$\n计算出的原始-对偶方向为 $(\\Delta X, \\Delta y, \\Delta S) = (0, 1, -I)$。\n\n接下来，我们求步长 $\\alpha$。问题要求如果完整步长 $\\alpha=1$ 能保持正定性 ($X_1 \\succ 0, S_1 \\succ 0$)，则使用它，否则使用最大可行步长。让我们检查 $\\alpha  0$ 的可行性。\n下一次的迭代结果由以下公式给出：\n$X(\\alpha) = X_0 + \\alpha \\Delta X = I + \\alpha(0) = I$。\n$S(\\alpha) = S_0 + \\alpha \\Delta S = 2I + \\alpha(-I) = (2-\\alpha)I$。\n\n对于 $X(\\alpha) \\succ 0$：由于 $X(\\alpha) = I$ 是正定的，这个条件对任意 $\\alpha$ 都成立。\n对于 $S(\\alpha) \\succ 0$：我们需要 $(2-\\alpha)I \\succ 0$，这要求 $2-\\alpha  0$，即 $\\alpha  2$。\n\n由于最大可行步长为 2，完整步长 $\\alpha = 1$ 是可行的。我们使用 $\\alpha=1$。\n\n我们计算新的迭代点 $(X_1, y_1, S_1)$：\n$y_1 = y_0 + \\alpha \\Delta y = -2 + 1(1) = -1$。\n$X_1 = X_0 + \\alpha \\Delta X = I + 1(0) = I$。\n$S_1 = S_0 + \\alpha \\Delta S = 2I + 1(-I) = I$。\n\n现在，我们计算更新后的对偶性度量 $\\mu_1$：\n$$ \\mu_1 = \\frac{1}{n} \\operatorname{tr}(X_1 S_1) = \\frac{1}{2} \\operatorname{tr}(I \\cdot I) = \\frac{1}{2} \\operatorname{tr}(I) = \\frac{1}{2}(2) = 1. $$\n最后，我们验证中心性对称条件 $X_1 S_1 = \\mu_1 I$：\n$X_1 S_1 = I \\cdot I = I$。\n$\\mu_1 I = 1 \\cdot I = I$。\n条件 $X_1 S_1 = \\mu_1 I$ 得到满足。\n\n最终要求的值是 $\\mu_1$。", "answer": "$$\n\\boxed{1}\n$$", "id": "3242579"}, {"introduction": "理论上完美的模型在现实世界中很少见，冗余约束就是一个常见问题。这个练习是一个思想实验，旨在探究冗余约束如何影响内点法的数学结构和行为。通过分析对数障碍函数及其导数的变化，你将揭示冗余信息如何改变中心路径并可能影响算法的数值稳定性。[@problem_id:3242722]", "problem": "考虑决策向量为 $x \\in \\mathbb{R}^2$ 的线性规划问题：\n最小化 $c^{\\top} x$，其中 $c = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$，并服从不等式约束 $x_1 \\ge 0$，$2 x_1 \\ge 0$ 和 $x_2 \\ge 1$。\n不等式 $2 x_1 \\ge 0$ 相对于 $x_1 \\ge 0$ 是冗余的。使用对数障碍函数对不等式约束实现了一个内点法（IPM），构建了带有参数 $\\mu  0$ 的障碍子问题：\n最小化 $c^{\\top} x - \\mu \\sum_{i=1}^m \\log(g_i(x))$，其中每个 $g_i(x)  0$ 代表对应一个约束的仿射函数，并且障碍子问题的 Karush-Kuhn-Tucker (KKT) 条件定义了中心路径。\n\n分析包含冗余约束对内点法（IPM）的构建和行为有何影响。下列哪些陈述是正确的？选择所有适用的选项。\n\nA. 重复约束 $x_1 \\ge 0$ 和 $2 x_1 \\ge 0$ 不会改变原始可行域，但在对数障碍函数构建中，它们将边界 $x_1 = 0$ 所贡献的曲率放大了2倍，这可能会恶化IPM迭代中求解的牛顿系统的条件数。\n\nB. 对于任意固定的障碍参数 $\\mu  0$，含有重复约束模型的中心路径上的原始点与不含重复约束模型（仅有 $x_1 \\ge 0$）的中心路径上的原始点重合，因为冗余约束带来的加性常数 $-\\mu \\log(2)$ 不影响一阶最优性。\n\nC. 当存在冗余不等式 $2 x_1 \\ge 0$ 时，在原始-对偶IPM线搜索中，为保持松弛变量为正所允许的最大步长会严格变小，因为额外的松弛变量在任何搜索方向上都不可避免地会更快地达到零。\n\nD. 在最优解处，与两个重复约束相关联的拉格朗日乘子可能不唯一，只有它们在平稳性方程中的组合效应必须与目标函数梯度相匹配；因此，冗余会导致对偶退化，而不会影响原始最优解或最优值。\n\nE. 冗余约束使对数障碍函数变为非严格凸，并可能破坏唯一中心路径的存在性。\n\nF. 移除冗余约束会降低每次IPM迭代中求解的KKT线性系统的维度，从而可以减少每次迭代的计算成本，而在标准正则性假设下，当 $\\mu \\to 0$ 时的极限原始解保持不变。", "solution": "用户希望我验证问题陈述，如果有效，则通过分析给定选项来解决问题。\n\n### 问题验证\n\n**第一步：提取已知信息**\n-   该问题是一个线性规划（LP）问题。\n-   决策向量为 $x \\in \\mathbb{R}^2$，分量为 $x_1$ 和 $x_2$。\n-   目标是最小化 $c^{\\top} x$，其中 $c = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$。\n-   约束条件为 $x_1 \\ge 0$，$2 x_1 \\ge 0$ 和 $x_2 \\ge 1$。\n-   注意到约束 $2 x_1 \\ge 0$ 相对于 $x_1 \\ge 0$ 是冗余的。\n-   求解方法是使用对数障碍函数的内点法（IPM）。\n-   对于障碍参数 $\\mu  0$ 的障碍子问题是：最小化 $c^{\\top} x - \\mu \\sum_{i=1}^m \\log(g_i(x))$，其中 $g_i(x)  0$ 是来自不等式约束的仿射函数。\n-   中心路径由障碍子问题的 Karush-Kuhn-Tucker (KKT) 条件定义。\n-   任务是分析冗余约束对IPM的影响，并确定所提供的陈述中哪些是正确的。\n\n**第二步：使用提取的已知信息进行验证**\n-   **科学依据：** 该问题牢固地建立在凸优化和数值方法领域。线性规划、内点法、对数障碍函数、中心路径以及冗余约束的影响都是标准的、公认的概念。\n-   **适定性：** 问题陈述清晰。它提出了一个特定的LP，并要求在标准算法（IPM）的框架内分析冗余约束的后果。这是一个定义明确的问题，可以根据优化理论的原理得到确切的答案。\n-   **客观性：** 语言技术性强且精确。问题设置中没有主观、模棱两可或基于意见的陈述。\n\n**缺陷清单：**\n1.  **科学或事实不健全：** 无。前提和概念在数学和计算机科学中都是标准的。\n2.  **无法形式化或不相关：** 无。该问题是一个形式化的数学问题，与内点法的主题直接相关。\n3.  **不完整或矛盾的设置：** 无。问题提供了所有必要的信息。指出的冗余是分析的主题，而不是问题陈述中的缺陷。\n4.  **不切实际或不可行：** 无。该LP很简单，有明确的解。冗余约束是优化中的一个常见实际问题。\n5.  **不适定或结构不良：** 无。选项中提出的问题是具体的，可以进行严格评估。\n6.  **平凡或同义反复：** 无。冗余在IPM中的影响涉及原始变量和对偶变量、障碍函数的Hessian矩阵以及计算复杂性之间的非平凡相互作用。\n7.  **超出科学可验证性范围：** 无。所有主张都可以通过数学推导来验证。\n\n**第三步：结论与行动**\n问题陈述是有效的。我将继续进行求解。\n\n### 求解推导\n\n首先，我们将有和没有冗余约束的问题形式化，以分析差异。\n\n**模型1：非冗余公式**\n问题是最小化 $x_1 + x_2$，约束条件为 $x_1 \\ge 0$ 和 $x_2 \\ge 1$。\n约束为 $g_1(x) = x_1  0$ 和 $g_2(x) = x_2 - 1  0$。\n对数障碍子问题是：\n$$ \\text{minimize} \\quad f_{NR}(x, \\mu) = (x_1 + x_2) - \\mu (\\log(x_1) + \\log(x_2 - 1)) $$\n中心路径由满足一阶最优性条件 $\\nabla_x f_{NR}(x, \\mu) = 0$ 的点 $x(\\mu)$ 定义：\n$$ \\nabla_x f_{NR}(x, \\mu) = \\begin{bmatrix} 1 - \\frac{\\mu}{x_1} \\\\ 1 - \\frac{\\mu}{x_2 - 1} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} $$\n求解 $x_1$ 和 $x_2$ 得到非冗余模型的中心路径上的点：\n$$ x_{1,NR}(\\mu) = \\mu $$\n$$ x_{2,NR}(\\mu) = 1 + \\mu $$\n障碍目标函数的Hessian矩阵是：\n$$ \\nabla^2 f_{NR}(x, \\mu) = \\begin{bmatrix} \\frac{\\mu}{x_1^2}  0 \\\\ 0  \\frac{\\mu}{(x_2-1)^2} \\end{bmatrix} $$\n\n**模型2：冗余公式**\n问题是最小化 $x_1 + x_2$，约束条件为 $x_1 \\ge 0$，$2x_1 \\ge 0$ 和 $x_2 \\ge 1$。\n约束为 $g_1(x) = x_1  0$，$g_2(x) = 2x_1  0$ 和 $g_3(x) = x_2 - 1  0$。\n对数障碍子问题是：\n$$ \\text{minimize} \\quad f_{R}(x, \\mu) = (x_1 + x_2) - \\mu (\\log(x_1) + \\log(2x_1) + \\log(x_2 - 1)) $$\n使用属性 $\\log(2x_1) = \\log(2) + \\log(x_1)$，我们可以重写目标函数：\n$$ f_{R}(x, \\mu) = (x_1 + x_2) - \\mu (2\\log(x_1) + \\log(x_2 - 1)) - \\mu \\log(2) $$\n常数项 $-\\mu\\log(2)$ 不影响最小值的位置。中心路径由 $\\nabla_x f_{R}(x, \\mu) = 0$ 定义：\n$$ \\nabla_x f_{R}(x, \\mu) = \\begin{bmatrix} 1 - \\frac{2\\mu}{x_1} \\\\ 1 - \\frac{\\mu}{x_2 - 1} \\end{bmatrix} = \\begin{bmatrix} 0 \\\\ 0 \\end{bmatrix} $$\n求解 $x_1$ 和 $x_2$ 得到冗余模型的中心路径上的点：\n$$ x_{1,R}(\\mu) = 2\\mu $$\n$$ x_{2,R}(\\mu) = 1 + \\mu $$\n这个目标函数的Hessian矩阵是：\n$$ \\nabla^2 f_{R}(x, \\mu) = \\begin{bmatrix} \\frac{2\\mu}{x_1^2}  0 \\\\ 0  \\frac{\\mu}{(x_2-1)^2} \\end{bmatrix} $$\n\n现在，我们评估每个选项。\n\n**A. 重复约束 $x_1 \\ge 0$ 和 $2 x_1 \\ge 0$ 不会改变原始可行域，但在对数障碍函数构建中，它们将边界 $x_1 = 0$ 所贡献的曲率放大了2倍，这可能会恶化IPM迭代中求解的牛顿系统的条件数。**\n- 可行域是 $\\{x \\in \\mathbb{R}^2 \\mid x_1 \\ge 0, x_2 \\ge 1\\}$。约束 $2x_1 \\ge 0$ 等价于 $x_1 \\ge 0$，所以可行域不变。这部分是正确的。\n- 目标函数的曲率由其Hessian矩阵给出。目标函数的障碍部分是 $-\\mu \\sum \\log(g_i(x))$。对于非冗余情况，与边界 $x_1=0$ 相关的项是 $-\\mu \\log(x_1)$，其对Hessian矩阵的贡献是 $(1,1)$ 项 $\\frac{\\mu}{x_1^2}$。在冗余情况下，该项是 $-\\mu(\\log(x_1) + \\log(2x_1)) = -2\\mu\\log(x_1) - \\mu\\log(2)$。其对Hessian矩阵 $(1,1)$ 项的贡献是 $\\frac{2\\mu}{x_1^2}$。\n- 这恰好是非冗余公式曲率贡献的两倍。陈述中关于它被放大了2倍是正确的。\n- IPM中求解的牛顿系统基于此Hessian矩阵。相对于其他特征值，增加Hessian矩阵的一个特征值通常会增加矩阵的条件数。例如，$\\nabla^2 f_R$ 的条件数是 $\\frac{\\max(2\\mu/x_1^2, \\mu/(x_2-1)^2)}{\\min(2\\mu/x_1^2, \\mu/(x_2-1)^2)}$。如果 $x_1 \\approx x_2-1$，条件数大约是 $2$，而非冗余情况下的条件数大约是 $1$。更高的条件数意味着系统是更病态的（ill-conditioned）。这部分也是正确的。\n结论：**正确**。\n\n**B. 对于任意固定的障碍参数 $\\mu  0$，含有重复约束模型的中心路径上的原始点与不含重复约束模型（仅有 $x_1 \\ge 0$）的中心路径上的原始点重合，因为冗余约束带来的加性常数 $-\\mu \\log(2)$ 不影响一阶最优性。**\n- 加性常数 $-\\mu\\log(2)$ 不影响一阶最优性条件（梯度），这是正确的。\n- 然而，结论是错误的。如上所述，中心路径上的点是不同的：\n    - 非冗余：$x_{NR}(\\mu) = (\\mu, 1+\\mu)$。\n    - 冗余：$x_{R}(\\mu) = (2\\mu, 1+\\mu)$。\n- 对于任何 $\\mu  0$，这些点都不重合。冗余约束从根本上改变了障碍函数的形状，而不仅仅是通过一个常数来平移它。\n结论：**不正确**。\n\n**C. 当存在冗余不等式 $2 x_1 \\ge 0$ 时，在原始-对偶IPM线搜索中，为保持松弛变量为正所允许的最大步长会严格变小，因为额外的松弛变量在任何搜索方向上都不可避免地会更快地达到零。**\n- 设约束 $x_1 \\ge 0$ 和 $2x_1 \\ge 0$ 的松弛变量分别为 $s_a = x_1$ 和 $s_b = 2x_1$。注意 $s_b=2s_a$。\n- 原始-对偶IPM在方向 $(\\Delta x, \\Delta s)$ 上走一步 $\\alpha$。该步必须保持正性：$s + \\alpha \\Delta s  0$。\n- 我们两个相关松弛变量的条件是：\n    1. $s_a + \\alpha \\Delta s_a  0$\n    2. $s_b + \\alpha \\Delta s_b  0$\n- 由于 $s_b = 2s_a$，松弛变量的变化也通过 $\\Delta s_b = 2 \\Delta s_a$ 相关联。将此代入第二个条件得到：\n    $2s_a + \\alpha (2\\Delta s_a)  0 \\implies 2(s_a + \\alpha \\Delta s_a)  0$\n- 这与第一个条件完全相同。冗余约束没有对步长 $\\alpha$ 施加任何新的或更严格的限制。两个松弛变量以相同的比例速率接近它们的零边界。\n结论：**不正确**。\n\n**D. 在最优解处，与两个重复约束相关联的拉格朗日乘子可能不唯一，只有它们在平稳性方程中的组合效应必须与目标函数梯度相匹配；因此，冗余会导致对偶退化，而不会影响原始最优解或最优值。**\n- 原始最优解是通过在 $x_1\\ge0, x_2\\ge1$ 上最小化 $x_1+x_2$ 找到的。解显然是 $x^*=(0,1)$，最优值为 $1$。这不受冗余约束的影响。\n- 我们来写出冗余LP的KKT条件。拉格朗日函数是 $L(x, \\lambda) = (x_1+x_2) - \\lambda_1 x_1 - \\lambda'_1 (2x_1) - \\lambda_2 (x_2-1)$，其中对偶变量 $\\lambda_1, \\lambda'_1, \\lambda_2 \\ge 0$。\n- 平稳性条件是 $\\nabla_x L = 0$：\n    - $\\frac{\\partial L}{\\partial x_1}: 1 - \\lambda_1 - 2\\lambda'_1 = 0 \\implies \\lambda_1 + 2\\lambda'_1 = 1$。\n    - $\\frac{\\partial L}{\\partial x_2}: 1 - \\lambda_2 = 0 \\implies \\lambda_2 = 1$。\n- 任何满足这些方程的非负乘子集合 $(\\lambda_1, \\lambda'_1, \\lambda_2)$ 都是一个有效的对偶解。我们有 $\\lambda_2=1$。对于其他乘子，我们需要 $\\lambda_1 + 2\\lambda'_1 = 1$ 且 $\\lambda_1, \\lambda'_1 \\ge 0$。这个方程在 $(\\lambda_1, \\lambda'_1)$ 平面中定义了一个线段，端点为 $(1,0)$ 和 $(0, 1/2)$。存在无限多个解。例如，$(\\lambda_1, \\lambda'_1) = (1, 0)$ 和 $(\\lambda_1, \\lambda'_1) = (0, 1/2)$ 都是有效的。\n- 对偶最优解的这种不唯一性被称为对偶退化。原始冗余是对偶退化的一个常见原因。所以，这个陈述完全正确。\n结论：**正确**。\n\n**E. 冗余约束使对数障碍函数变为非严格凸，并可能破坏唯一中心路径的存在性。**\n- 障碍目标函数 $f(x,\\mu)$ 的严格凸性取决于其Hessian矩阵 $\\nabla^2 f(x, \\mu)$ 是否为正定。\n- 障碍部分的Hessian矩阵是 $\\sum_i \\mu \\frac{\\nabla g_i(x) (\\nabla g_i(x))^{\\top}}{(g_i(x))^2}$。这个秩为1的半正定矩阵之和是正定的，如果约束梯度 $\\{\\nabla g_i(x)\\}$ 能张成整个空间 $\\mathbb{R}^n$。\n- 在我们的问题中，$n=2$。约束梯度是 $\\nabla g_1 = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}$，$\\nabla g_2 = \\begin{bmatrix} 2 \\\\ 0 \\end{bmatrix}$ 和 $\\nabla g_3 = \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}$。向量集合 $\\{\\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, \\begin{bmatrix} 0 \\\\ 1 \\end{bmatrix}\\}$ 是这些梯度的一个子集，并且已经能张成 $\\mathbb{R}^2$。\n- 因此，对于任何严格可行的 $x$，Hessian矩阵 $\\nabla^2 f_R(x,\\mu)$ 都是正定的。如前所计算，$\\nabla^2 f_R(x, \\mu) = \\text{diag}(\\frac{2\\mu}{x_1^2}, \\frac{\\mu}{(x_2-1)^2})$，它具有正的特征值。\n- 由于目标函数是严格凸的（在可行集的内部），它对于每个 $\\mu  0$ 都有唯一的最小值。这确保了中心路径是良定义且唯一的。该陈述是错误的。\n结论：**不正确**。\n\n**F. 移除冗余约束会降低每次IPM迭代中求解的KKT线性系统的维度，从而可以减少每次迭代的计算成本，而在标准正则性假设下，当 $\\mu \\to 0$ 时的极限原始解保持不变。**\n- 原始-对偶IPM中的KKT系统涉及变量 $x \\in \\mathbb{R}^n$，对偶变量 $\\lambda \\in \\mathbb{R}^m$ 和松弛变量 $s \\in \\mathbb{R}^m$，其中 $m$ 是不等式的数量。每一步要解的线性系统的大小与 $n+m$ 有关。\n- 在我们的例子中，$n=2$。冗余模型有 $m=3$ 个约束。非冗余模型有 $m=2$ 个约束。移除冗余约束使 $m$ 减少了1，从而降低了KKT系统的维度。求解一个更小的线性系统在计算上更便宜。这部分是正确的。\n- 中心路径的极限点 $\\lim_{\\mu \\to 0} x(\\mu)$ 对应于LP的最优解。由于冗余约束不改变可行集或目标函数，LP的最优解保持不变。\n- 我们用具体的路径验证了这一点：$\\lim_{\\mu \\to 0} x_{NR}(\\mu) = \\lim_{\\mu \\to 0} (\\mu, 1+\\mu) = (0,1)$ 和 $\\lim_{\\mu \\to 0} x_{R}(\\mu) = \\lim_{\\mu \\to 0} (2\\mu, 1+\\mu) = (0,1)$。极限确实是相同的。该陈述是正确的。\n结论：**正确**。", "answer": "$$\\boxed{ADF}$$", "id": "3242722"}, {"introduction": "学习算法的最佳方式之一是亲手实现它。本练习将引导你构建一个完整的、可运行的内点法求解器，采用的是强大的同质自对偶嵌入（HSDE）模型。这个高级实践不仅能让你将所有理论知识（如KKT条件、牛顿法、线搜索）融会贯通，还将让你掌握如何利用HSDE框架来稳健地判断一个问题是可行的、原始不可行的还是对偶不可行的。[@problem_id:3242648]", "problem": "实现一个完整的、可运行的程序，该程序使用内点法构建并求解一小类线性规划的齐次自对偶嵌入 (HSDE)，并将每个问题分类为可行最优、原始不可行或对偶不可行（原始无界）。程序必须产生单行输出，即一个方括号括起来的逗号分隔的整数列表，其中每个整数对应一个测试用例的分类：$0$ 表示可行最优（找到解），$1$ 表示原始不可行，$2$ 表示对偶不可行（原始无界）。\n\n标准形式下的线性规划 (LP) 原始-对偶问题对定义如下。原始问题是\n$$\n\\min_{x \\in \\mathbb{R}^n} \\; c^\\top x \\quad \\text{subject to} \\quad A x = b, \\; x \\ge 0,\n$$\n对偶问题是\n$$\n\\max_{y \\in \\mathbb{R}^m} \\; b^\\top y \\quad \\text{subject to} \\quad A^\\top y + s = c, \\; s \\ge 0,\n$$\n其中 $A \\in \\mathbb{R}^{m \\times n}$，$b \\in \\mathbb{R}^m$，$c \\in \\mathbb{R}^n$，$x \\in \\mathbb{R}^n$ 是原始变量，$y \\in \\mathbb{R}^m$ 是对偶变量，$s \\in \\mathbb{R}^n$ 是对偶松弛变量。齐次自对偶嵌入 (HSDE) 引入了两个额外的非负标量 $\\tau \\ge 0$ 和 $\\kappa \\ge 0$，以创建一个单一的可行性问题，其解可以编码所有结果：可行最优性、原始不可行性或对偶不可行性。\n\n从凸优化和 Karush–Kuhn–Tucker (KKT) 条件的核心定义出发，使用 HSDE 构建一个系统，该系统强制原始和对偶可行性，并带有一个标量互补条件和中心性。具体来说，包括变量 $(x, s, y, \\tau, \\kappa)$，它们服从齐次约束\n$$\nA x - b \\tau = 0, \\quad A^\\top y + s - c \\tau = 0, \\quad c^\\top x - b^\\top y + \\kappa = 0,\n$$\n以及非负约束 $x \\ge 0$、$s \\ge 0$、$\\tau \\ge 0$、$\\kappa \\ge 0$，还有一个连接原始和对偶松弛变量的互补条件，该条件定义了一条内点中心路径。为一个增广障碍系统推导牛顿步，该系统线性化这些方程以及 $(x, s)$ 和 $(\\tau, \\kappa)$ 的互补关系，并使用回溯法来保持严格正性。\n\n您的实现必须：\n- 将 $(x, s, y, \\tau, \\kappa)$ 初始化为严格正值，通过障碍参数强制中心性，并迭代求解线性化的 KKT 系统，直到满足终止准则。\n- 使用残差\n$$\nr_p = A x - b \\tau,\\quad r_d = A^\\top y + s - c \\tau,\\quad r_g = c^\\top x - b^\\top y + \\kappa\n$$\n和平均互补性\n$$\n\\mu = \\frac{x^\\top s + \\tau \\kappa}{n+1}\n$$\n来指导进展。始终保持 $x$、$s$、$\\tau$ 和 $\\kappa$ 的严格正性。\n- 根据 HSDE 的结果实现分类规则：\n    - 可行最优 ($0$)：当 $\\tau$ 远离 $0$，$\\kappa/\\tau$ 很小，并且缩放后的残差 $\\|r_p\\|/\\tau$ 和 $\\|r_d\\|/\\tau$ 很小时。\n    - 原始不可行 ($1$)：当 $\\tau$ 接近 $0$，$\\kappa$ 为正，并且通过对偶变量 $y$ 检测到原始不可行的 Farkas 证明，即 $A^\\top y \\ge 0$ 和 $b^\\top y  0$。\n    - 对偶不可行 ($2$)：当 $\\tau$ 接近 $0$，$\\kappa$ 为正，并且检测到证明 $x \\ge 0$、$A x = 0$、$c^\\top x  0$（原始无界）。\n\n测试套件：\n提供三个 LP 实例 $(A, b, c)$，共同测试可行性、原始不可行性和对偶不可行性。使用以下具体案例：\n1. 案例 F (可行最优):\n   $$\n   A = \\begin{bmatrix} 1   2 \\\\ 1   -1 \\end{bmatrix},\\quad b = \\begin{bmatrix} 4 \\\\ 1 \\end{bmatrix},\\quad c = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}.\n   $$\n   该系统允许一个 $x \\ge 0$ 的严格可行解。\n2. 案例 PI (原始不可行):\n   $$\n   A = \\begin{bmatrix} 1   0 \\end{bmatrix},\\quad b = \\begin{bmatrix} -1 \\end{bmatrix},\\quad c = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}.\n   $$\n   等式 $x_1 = -1$ 与 $x \\ge 0$ 矛盾，因此不存在原始可行点。\n3. 案例 DI (对偶不可行, 原始无界):\n   $$\n   A = \\begin{bmatrix} 1   -1 \\end{bmatrix},\\quad b = \\begin{bmatrix} 0 \\end{bmatrix},\\quad c = \\begin{bmatrix} -1 \\\\ -1 \\end{bmatrix}.\n   $$\n   约束 $A x = 0$ 和 $x \\ge 0$ 允许存在 $c^\\top x  0$ 的非平凡方向，这意味着原始问题无界。\n\n您的程序应按顺序运行这三个案例，并产生一个单行输出，其中包含一个包含三个整数 $[r_F, r_{PI}, r_{DI}]$ 的列表，每个 $r$ 是根据上述分类描述的 $\\{0,1,2\\}$ 之一。\n\n最终输出格式：\n您的程序应产生一个单行，其中包含一个用方括号括起来的逗号分隔列表形式的结果（例如，“[0,1,2]”）。不应打印任何其他文本。", "solution": "用户要求实现一种齐次自对偶嵌入 (HSDE) 内点法，用于求解一系列线性规划 (LP) 问题。该解决方案必须能够将每个 LP 分类为可行最优、原始不可行或对偶不可行。\n\n### 第 1 步：提取已知条件\n\n-   **原始 LP**：$\\min_{x \\in \\mathbb{R}^n} \\; c^\\top x \\quad \\text{subject to} \\quad A x = b, \\; x \\ge 0$。\n-   **对偶 LP**：$\\max_{y \\in \\mathbb{R}^m} \\; b^\\top y \\quad \\text{subject to} \\quad A^\\top y + s = c, \\; s \\ge 0$。\n-   **HSDE 变量**：$(x, s, y, \\tau, \\kappa)$，其中 $x \\in \\mathbb{R}^n, s \\in \\mathbb{R}^n, y \\in \\mathbb{R}^m, \\tau \\in \\mathbb{R}, \\kappa \\in \\mathbb{R}$。\n-   **HSDE 齐次约束**：\n    1.  $A x - b \\tau = 0$\n    2.  $A^\\top y + s - c \\tau = 0$\n    3.  $c^\\top x - b^\\top y + \\kappa = 0$\n-   **非负约束**：$x \\ge 0, s \\ge 0, \\tau \\ge 0, \\kappa \\ge 0$。\n-   **残差定义**：\n    -   $r_p = A x - b \\tau$\n    -   $r_d = A^\\top y + s - c \\tau$\n    -   $r_g = c^\\top x - b^\\top y + \\kappa$\n-   **平均互补性**：$\\mu = \\frac{x^\\top s + \\tau \\kappa}{n+1}$。\n-   **分类规则**：\n    1.  **可行最优 (0)**：$\\tau$ 远离 $0$，$\\kappa/\\tau$ 很小，且缩放后的残差很小。\n    2.  **原始不可行 (1)**：$\\tau$ 接近 $0$，$\\kappa  0$，且有证明 $A^\\top y \\ge 0, b^\\top y  0$。\n    3.  **对偶不可行 (2)**：$\\tau$ 接近 $0$，$\\kappa  0$，且有证明 $x \\ge 0, A x = 0, c^\\top x  0$。\n-   **测试用例**：\n    1.  **案例 F (可行最优)**：$A = \\begin{bmatrix} 1  2 \\\\ 1  -1 \\end{bmatrix}, b = \\begin{bmatrix} 4 \\\\ 1 \\end{bmatrix}, c = \\begin{bmatrix} 1 \\\\ 2 \\end{bmatrix}$。\n    2.  **案例 PI (原始不可行)**：$A = \\begin{bmatrix} 1  0 \\end{bmatrix}, b = \\begin{bmatrix} -1 \\end{bmatrix}, c = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$。\n    3.  **案例 DI (对偶不可行)**：$A = \\begin{bmatrix} 1  -1 \\end{bmatrix}, b = \\begin{bmatrix} 0 \\end{bmatrix}, c = \\begin{bmatrix} -1 \\\\ -1 \\end{bmatrix}$。\n-   **最终输出格式**：一个逗号分隔的整数列表（例如，`[0,1,2]`）。\n\n### 第 2 步：使用提取的已知条件进行验证\n\n问题陈述在科学上是合理的、适定的且客观的。\n-   **科学依据**：该问题描述了齐次自对偶嵌入，这是凸优化和求解线性规划的数值方法领域中一种标准且经过严格证明的技术。所有的数学公式都是正确的，并基于优化理论的基本原理，特别是内点法和 KKT 条件。\n-   **适定性**：问题是适定的。HSDE 框架专门设计用于拥有一个严格可行的起始点，并保证得到一个能够明确分类原始 LP 状态的解。提供的测试用例旨在展示三种可能的结果（可行最优、原始不可行、对偶不可行）。\n-   **客观性**：语言精确且正式。所有术语都是该领域的标准术语。目标是可量化的，分类规则基于可验证的数学条件。\n-   **完整性**：问题是自洽的。它提供了模型的完整数学规范、算法的核心组件（牛顿步、回溯法）、终止和分类逻辑，以及一套完整的测试数据。\n\n### 第 3 步：结论与行动\n\n问题有效。我们将继续提供解决方案。\n\n### 算法推导与实现计划\n\n内点法的核心是迭代求解受扰动的 Karush-Kuhn-Tucker (KKT) 条件的线性化版本，这些条件定义了一条收敛到解的“中心路径”。对于 HSDE，KKT 条件通过由 $\\mu$ 参数化的障碍项进行增广。目标是找到一个牛顿步 $(\\Delta x, \\Delta y, \\Delta s, \\Delta \\tau, \\Delta \\kappa)$，使当前迭代点更接近具有更小障碍参数的中心路径上的点。\n\n每次迭代需求解的方程组是 HSDE 可行性与中心性条件的线性化：\n1.  $A(x + \\Delta x) - b(\\tau + \\Delta \\tau) = 0 \\implies A\\Delta x - b\\Delta\\tau = -r_p$\n2.  $A^\\top(y + \\Delta y) + (s + \\Delta s) - c(\\tau + \\Delta \\tau) = 0 \\implies A^\\top\\Delta y + \\Delta s - c\\Delta\\tau = -r_d$\n3.  $c^\\top(x + \\Delta x) - b^\\top(y + \\Delta y) + (\\kappa + \\Delta \\kappa) = 0 \\implies c^\\top\\Delta x - b^\\top\\Delta y + \\Delta \\kappa = -r_g$\n4.  $(X + \\Delta X)(S + \\Delta S)e = \\sigma\\mu e \\implies S\\Delta x + X\\Delta s = \\sigma\\mu e - XSe$\n5.  $(\\tau + \\Delta \\tau)(\\kappa + \\Delta \\kappa) = \\sigma\\mu \\implies \\kappa\\Delta\\tau + \\tau\\Delta\\kappa = \\sigma\\mu - \\tau\\kappa$\n\n这里，$X$ 和 $S$ 分别是以 $x$ 和 $s$ 的元素为对角元的对角矩阵，$e$ 是元素全为一的向量，$\\sigma \\in [0, 1]$ 是一个中心化参数，用于平衡向可行性/最优性（`\\sigma=0`，仿射伸缩步）和中心性（`\\sigma=1`，中心化步）的进展。\n\n为了高效求解此系统，我们消去 $\\Delta s$ 和 $\\Delta \\kappa$：\n从 (4) 式：$\\Delta s = X^{-1}(\\sigma\\mu e - XSe - S\\Delta x)$\n从 (5) 式：$\\Delta\\kappa = \\tau^{-1}(\\sigma\\mu - \\tau\\kappa - \\kappa\\Delta\\tau)$\n\n将它们代入余下的方程 (1, 2, 3)，得到一个关于 $(\\Delta x, \\Delta y, \\Delta \\tau)$ 的简化线性系统。我们来构建这个系统：\n将 $\\Delta s$ 代入 (2) 式：\n$A^\\top\\Delta y + X^{-1}(\\sigma\\mu e - XSe - S\\Delta x) - c\\Delta\\tau = -r_d$\n$\\implies -X^{-1}S\\Delta x + A^\\top\\Delta y - c\\Delta\\tau = -r_d - X^{-1}(\\sigma\\mu e - XSe) = -r_d - s + \\sigma\\mu X^{-1}e$\n\n将 $\\Delta \\kappa$ 代入 (3) 式：\n$c^\\top\\Delta x - b^\\top\\Delta y + \\tau^{-1}(\\sigma\\mu - \\tau\\kappa - \\kappa\\Delta\\tau) = -r_g$\n$\\implies c^\\top\\Delta x - b^\\top\\Delta y - (\\kappa/\\tau)\\Delta\\tau = -r_g - \\tau^{-1}(\\sigma\\mu - \\tau\\kappa) = -r_g - \\sigma\\mu/\\tau + \\kappa$\n\n这得到以下 $(n+m+1) \\times (n+m+1)$ 线性系统：\n$$\n\\begin{pmatrix}\n    -X^{-1}S  A^\\top  -c \\\\\n    A  0  -b \\\\\n    c^\\top  -b^\\top  -\\kappa/\\tau\n\\end{pmatrix}\n\\begin{pmatrix}\n    \\Delta x \\\\ \\Delta y \\\\ \\Delta \\tau\n\\end{pmatrix}\n=\n\\begin{pmatrix}\n    -r_d + s - \\sigma \\mu X^{-1} e \\\\\n    -r_p \\\\\n    -r_g - \\sigma \\mu/\\tau + \\kappa\n\\end{pmatrix}\n$$\n这个系统可以使用标准的线性求解器求解。一旦找到 $(\\Delta x, \\Delta y, \\Delta \\tau)$，就可以从代换公式中计算出 $(\\Delta s, \\Delta \\kappa)$。\n\n使用回溯线搜索来寻找一个步长 $\\alpha \\in (0, 1]$，以确保严格维持非负约束（$x, s, \\tau, \\kappa  0$）。新的迭代点则为 $(x, y, s, \\tau, \\kappa) \\leftarrow (x, y, s, \\tau, \\kappa) + \\alpha (\\Delta x, \\Delta y, \\Delta s, \\Delta \\tau, \\Delta \\kappa)$。\n\n算法流程如下：\n1.  使用一个严格正点进行初始化，例如 $x=e, s=e, y=0, \\tau=1, \\kappa=1$。\n2.  迭代直至互补间隙 $\\mu  \\text{TOL}$：\n    a. 计算残差 $r_p, r_d, r_g$。\n    b. 计算间隙 $\\mu$。\n    c. 构造并求解简化的牛顿系统以得到 $(\\Delta x, \\Delta y, \\Delta \\tau)$。\n    d. 计算 $\\Delta s$ 和 $\\Delta \\kappa$。\n    e. 找到维持正性的最大步长 $\\alpha$，并乘以一个因子 $\\eta  1$。\n    f. 更新所有变量。\n3.  终止时，根据 $\\tau$ 和 $\\kappa$ 的最终值对结果进行分类：\n    - 如果 $\\tau  \\kappa$（近似于 $\\tau  0, \\kappa \\approx 0$），则原始 LP 是可行最优的（代码 0）。\n    - 如果 $\\tau \\le \\kappa$（近似于 $\\tau \\approx 0, \\kappa  0$），则原始 LP 是不可行的。\n        - 如果 $b^\\top y  0$，则是原始不可行（代码 1）。\n        - 否则，是对偶不可行（原始无界，代码 2）。\n\n下面将为给定的测试用例实现此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define and solve the test cases using the HSDE-IPM.\n    \"\"\"\n\n    def _solve_lp_hsde(A, b, c):\n        \"\"\"\n        Solves a linear program standard form using a Homogeneous Self-Dual\n        Embedding Interior-Point Method.\n        \n        Args:\n            A (np.ndarray): The m x n constraint matrix.\n            b (np.ndarray): The m x 1 constraint vector.\n            c (np.ndarray): The n x 1 objective vector.\n            \n        Returns:\n            int: 0 for feasible-optimal, 1 for primal infeasible, \n                 2 for dual infeasible.\n        \"\"\"\n        m, n = A.shape\n\n        # --- Parameters ---\n        MAX_ITER = 100\n        TOL = 1e-9  # Tolerance for complementarity gap\n        SIGMA = 0.1  # Centering parameter\n        ETA = 0.9995 # Backtracking step-size factor\n\n        # --- Initialization ---\n        x = np.ones(n)\n        s = np.ones(n)\n        y = np.zeros(m)\n        tau = 1.0\n        kappa = 1.0\n\n        for _ in range(MAX_ITER):\n            # --- Calculate Residuals and Gap ---\n            r_p = A @ x - b * tau\n            r_d = A.T @ y + s - c * tau\n            r_g = c @ x - b @ y + kappa\n            \n            mu = (x @ s + tau * kappa) / (n + 1)\n\n            if mu  TOL:\n                break\n\n            # --- Form the Newton System M*dz = R ---\n            # Matrix M\n            M_size = n + m + 1\n            M = np.zeros((M_size, M_size))\n            \n            # Since x and s are vectors, X and S are diagonal matrices.\n            # X^{-1}S is a diagonal matrix with entries s_i/x_i.\n            # -X^{-1}S is the top-left block.\n            M[:n, :n] = np.diag(-s / x)\n            M[:n, n:n+m] = A.T\n            M[:n, n+m] = -c\n            \n            M[n:n+m, :n] = A\n            # M[n:n+m, n:n+m] is already zero\n            M[n:n+m, n+m] = -b\n            \n            M[n+m, :n] = c.T\n            M[n+m, n:n+m] = -b.T\n            M[n+m, n+m] = -kappa / tau\n\n            # RHS vector R\n            R = np.zeros(M_size)\n            R[:n] = -r_d + s - SIGMA * mu / x\n            R[n:n+m] = -r_p\n            R[n+m] = -r_g - (SIGMA * mu / tau) + kappa\n\n            # --- Solve the linear system for the step direction ---\n            try:\n                # Solve for primary step components\n                sol = np.linalg.solve(M, R)\n                dx = sol[:n]\n                dy = sol[n:n+m]\n                dtau = sol[n+m]\n                \n                # Compute remaining step components\n                ds = (SIGMA * mu - x * s - s * dx) / x\n                dkappa = (SIGMA * mu - tau * kappa - kappa * dtau) / tau\n            except np.linalg.LinAlgError:\n                # If matrix is singular, likely numerical issues. Stop iterating.\n                break\n\n            # --- Backtracking Line Search ---\n            alpha = 1.0\n            \n            # Check steps that would violate non-negativity\n            # A small tolerance is used to avoid issues with floating point arithmetic\n            neg_dx_indices = dx  -1e-12\n            if np.any(neg_dx_indices):\n                alpha = min(alpha, np.min(-x[neg_dx_indices] / dx[neg_dx_indices]))\n            \n            neg_ds_indices = ds  -1e-12\n            if np.any(neg_ds_indices):\n                alpha = min(alpha, np.min(-s[neg_ds_indices] / ds[neg_ds_indices]))\n\n            if dtau  -1e-12:\n                alpha = min(alpha, -tau / dtau)\n            \n            if dkappa  -1e-12:\n                alpha = min(alpha, -kappa / dkappa)\n\n            alpha *= ETA\n            \n            # --- Update variables ---\n            x += alpha * dx\n            y += alpha * dy\n            s += alpha * ds\n            tau += alpha * dtau\n            kappa += alpha * dkappa\n\n        # --- Classification ---\n        if tau > kappa:\n            # Feasible-Optimal case: tau > 0, kappa ~ 0\n            return 0\n        else:\n            # Infeasible case: tau ~ 0, kappa > 0\n            # A certificate for primal infeasibility is y s.t. A'y >= 0 and b'y  0\n            if b @ y  0:\n                return 1 # Primal Infeasible\n            else:\n                # Otherwise, it must be dual infeasible (primal unbounded)\n                # A certificate is x s.t. Ax = 0, x >= 0, c'x  0\n                return 2 # Dual Infeasible\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1: Feasible-optimal\n        (\n            np.array([[1.0, 2.0], [1.0, -1.0]]),\n            np.array([4.0, 1.0]),\n            np.array([1.0, 2.0])\n        ),\n        # Case 2: Primal infeasible\n        (\n            np.array([[1.0, 0.0]]),\n            np.array([-1.0]),\n            # The dimension of c must match the number of columns of A.\n            # The original problem statement has c with dimension 2, but A has 2 columns.\n            # Correcting c to match n=2 for case PI.\n            np.array([1.0, 1.0])\n        ),\n        # Case 3: Dual infeasible (primal unbounded)\n        (\n            np.array([[1.0, -1.0]]),\n            np.array([0.0]),\n            np.array([-1.0, -1.0])\n        )\n    ]\n\n    results = []\n    for case in test_cases:\n        A, b, c = case\n        # For Case 2, A is 1x2, so n=2. The provided c is fine.\n        result = _solve_lp_hsde(A, b, c)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3242648"}]}