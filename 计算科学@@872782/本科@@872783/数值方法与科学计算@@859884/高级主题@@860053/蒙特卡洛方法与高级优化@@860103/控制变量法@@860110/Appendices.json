{"hands_on_practices": [{"introduction": "理论学习的最佳方式之一就是亲手实践。本练习将引导你从第一性原理出发，为一个简单的蒙特卡洛积分问题推导控制变量方法的核心内容。通过计算最优控制系数 $c^{\\star}$ 并量化方差缩减的程度，你将直观地理解该技术为何如此有效，并巩固其理论基础[@problem_id:3218918]。", "problem": "考虑使用蒙特卡洛（MC）方法估计定积分 $I = \\int_{0}^{1} x^{2} \\, dx$，其中使用从 $\\text{Uniform}[0,1]$ 分布中抽取的 $n$ 个独立同分布的样本 $U_{1}, \\dots, U_{n}$。定义普通蒙特卡洛估计量为 $\\hat{I}_{\\text{MC}} = \\frac{1}{n} \\sum_{i=1}^{n} X_{i}$，其中 $X_{i} = U_{i}^{2}$。现在，应用控制变量（CV）技术，使用均值已知为 $\\mathbb{E}[Y] = \\frac{1}{2}$ 的控制变量 $Y = U$，并定义调整后的样本 $Z_{c} = X - c\\,(Y - \\mathbb{E}[Y])$ 及相应的估计量 $\\hat{I}_{\\text{CV}}(c) = \\frac{1}{n} \\sum_{i=1}^{n} Z_{c,i}$。\n\n从期望、方差和协方差的定义出发，利用基础的微积分和代数知识，推导出使 $\\operatorname{Var}(Z_{c})$ 最小化的值 $c^{\\star}$，然后计算方差缩减因子\n$$\nR = \\frac{\\operatorname{Var}\\!\\big(\\hat{I}_{\\text{CV}}(c^{\\star})\\big)}{\\operatorname{Var}\\!\\big(\\hat{I}_{\\text{MC}}\\big)}.\n$$\n请以单个有理数的形式给出 $R$ 的精确值。无需四舍五入；请将最终答案表示为一个有理数。", "solution": "用户希望针对一个蒙特卡洛积分问题，找到最优的控制变量系数以及由此产生的方差缩减。\n\n### 第1步：提取已知条件\n- 待估计的积分为 $I = \\int_{0}^{1} x^{2} \\, dx$。\n- 抽样分布为 $U_i \\sim \\text{Uniform}[0,1]$，其中 $i = 1, \\dots, n$。\n- 普通蒙特卡洛估计量为 $\\hat{I}_{\\text{MC}} = \\frac{1}{n} \\sum_{i=1}^{n} X_{i}$，其中 $X_i = U_i^2$。\n- 控制变量为 $Y = U$，其均值已知为 $\\mathbb{E}[Y] = \\frac{1}{2}$。\n- 控制变量的随机变量为 $Z_c = X - c(Y - \\mathbb{E}[Y])$。\n- 控制变量估计量为 $\\hat{I}_{\\text{CV}}(c) = \\frac{1}{n} \\sum_{i=1}^{n} Z_{c,i}$。\n- 目标是找到使 $\\operatorname{Var}(Z_c)$ 最小化的值 $c^{\\star}$，然后计算方差缩减因子 $R = \\frac{\\operatorname{Var}\\!\\big(\\hat{I}_{\\text{CV}}(c^{\\star})\\big)}{\\operatorname{Var}\\!\\big(\\hat{I}_{\\text{MC}}\\big)}$。\n\n### 第2步：使用提取的已知条件进行验证\n该问题是数值方法领域（特别是蒙特卡洛技术）中一个定义明确的标准练习。\n- **科学依据：** 该问题基于概率论、统计学和微积分的既定原理。所有概念（蒙特卡洛积分、控制变量、方差、协方差）都是标准的。\n- **良态问题：** 该问题提供了推导 $c^{\\star}$ 和 $R$ 唯一解所需的所有信息。目标清晰明确。\n- **客观性：** 该问题以精确的数学语言陈述，不含主观或定性陈述。\n\n该问题不违反任何无效性标准。它在科学计算的范围内是一个完整、一致且可解的问题。\n\n### 第3步：结论与行动\n问题有效。将提供完整解法。\n\n### 解法推导\n\n目标是找到使控制变量估计量方差最小化的最优系数 $c^{\\star}$，然后计算方差缩减因子。\n\n控制变量估计量的随机变量是 $Z_c = X - c(Y - \\mathbb{E}[Y])$。其方差是 $c$ 的函数。由于 $\\mathbb{E}[Y]$ 是一个常数，它不影响方差。\n$$\n\\operatorname{Var}(Z_c) = \\operatorname{Var}(X - cY)\n$$\n利用方差的性质，我们可以展开此表达式：\n$$\n\\operatorname{Var}(Z_c) = \\operatorname{Var}(X) + \\operatorname{Var}(cY) - 2\\operatorname{Cov}(X, cY)\n$$\n$$\n\\operatorname{Var}(Z_c) = \\operatorname{Var}(X) + c^2\\operatorname{Var}(Y) - 2c\\operatorname{Cov}(X, Y)\n$$\n该表达式是关于 $c$ 的二次函数。为找到使该方差最小化的值 $c^{\\star}$，我们对 $c$ 求导并令其为 $0$：\n$$\n\\frac{d}{dc}\\operatorname{Var}(Z_c) = 2c\\operatorname{Var}(Y) - 2\\operatorname{Cov}(X, Y)\n$$\n将导数设为零，得到：\n$$\n2c^{\\star}\\operatorname{Var}(Y) - 2\\operatorname{Cov}(X, Y) = 0\n$$\n$$\nc^{\\star} = \\frac{\\operatorname{Cov}(X, Y)}{\\operatorname{Var}(Y)}\n$$\n为计算 $c^{\\star}$，我们必须计算 $\\operatorname{Var}(Y)$ 和 $\\operatorname{Cov}(X, Y)$。这需要计算随机变量 $X = U^2$ 和 $Y = U$ 的矩，其中 $U \\sim \\text{Uniform}[0,1]$。\n\n一个随机变量 $U \\sim \\text{Uniform}[0,1]$ 的 $k$ 阶矩由下式给出：\n$$\n\\mathbb{E}[U^k] = \\int_{0}^{1} u^k \\cdot 1 \\, du = \\left[ \\frac{u^{k+1}}{k+1} \\right]_{0}^{1} = \\frac{1}{k+1}\n$$\n首先，我们计算 $Y=U$ 的矩和方差。\n$$\n\\mathbb{E}[Y] = \\mathbb{E}[U] = \\frac{1}{1+1} = \\frac{1}{2}\n$$\n$$\n\\mathbb{E}[Y^2] = \\mathbb{E}[U^2] = \\frac{1}{2+1} = \\frac{1}{3}\n$$\n$Y$ 的方差为：\n$$\n\\operatorname{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2 = \\frac{1}{3} - \\left(\\frac{1}{2}\\right)^2 = \\frac{1}{3} - \\frac{1}{4} = \\frac{4-3}{12} = \\frac{1}{12}\n$$\n接下来，我们计算 $X=U^2$ 的矩和方差。\n$$\n\\mathbb{E}[X] = \\mathbb{E}[U^2] = \\frac{1}{2+1} = \\frac{1}{3}\n$$\n这就是积分 $I = \\int_0^1 x^2 dx$ 的真实值。\n$$\n\\mathbb{E}[X^2] = \\mathbb{E}[(U^2)^2] = \\mathbb{E}[U^4] = \\frac{1}{4+1} = \\frac{1}{5}\n$$\n$X$ 的方差为：\n$$\n\\operatorname{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2 = \\frac{1}{5} - \\left(\\frac{1}{3}\\right)^2 = \\frac{1}{5} - \\frac{1}{9} = \\frac{9-5}{45} = \\frac{4}{45}\n$$\n现在，我们计算 $X$ 和 $Y$ 之间的协方差。\n$$\n\\operatorname{Cov}(X, Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]\n$$\n$\\mathbb{E}[XY]$ 项为：\n$$\n\\mathbb{E}[XY] = \\mathbb{E}[U^2 \\cdot U] = \\mathbb{E}[U^3] = \\frac{1}{3+1} = \\frac{1}{4}\n$$\n因此，协方差为：\n$$\n\\operatorname{Cov}(X, Y) = \\frac{1}{4} - \\left(\\frac{1}{3}\\right)\\left(\\frac{1}{2}\\right) = \\frac{1}{4} - \\frac{1}{6} = \\frac{3-2}{12} = \\frac{1}{12}\n$$\n我们现在可以计算最优系数 $c^{\\star}$：\n$$\nc^{\\star} = \\frac{\\operatorname{Cov}(X, Y)}{\\operatorname{Var}(Y)} = \\frac{1/12}{1/12} = 1\n$$\n下一步是计算方差缩减因子 $R$。\n估计量 $\\hat{I}_{\\text{MC}}$ 和 $\\hat{I}_{\\text{CV}}(c)$ 是 $n$ 个独立同分布样本的均值。因此，它们的方差与单个样本的方差关系如下：\n$$\n\\operatorname{Var}(\\hat{I}_{\\text{MC}}) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{i=1}^n X_i\\right) = \\frac{1}{n^2} \\sum_{i=1}^n \\operatorname{Var}(X_i) = \\frac{n \\operatorname{Var}(X)}{n^2} = \\frac{\\operatorname{Var}(X)}{n}\n$$\n$$\n\\operatorname{Var}(\\hat{I}_{\\text{CV}}(c^{\\star})) = \\operatorname{Var}\\left(\\frac{1}{n}\\sum_{i=1}^n Z_{c^{\\star},i}\\right) = \\frac{\\operatorname{Var}(Z_{c^{\\star}})}{n}\n$$\n方差缩减因子 $R$ 是这两个方差的比值：\n$$\nR = \\frac{\\operatorname{Var}(\\hat{I}_{\\text{CV}}(c^{\\star}))}{\\operatorname{Var}(\\hat{I}_{\\text{MC}})} = \\frac{\\operatorname{Var}(Z_{c^{\\star}})/n}{\\operatorname{Var}(X)/n} = \\frac{\\operatorname{Var}(Z_{c^{\\star}})}{\\operatorname{Var}(X)}\n$$\n我们需要找到最小化的方差 $\\operatorname{Var}(Z_{c^{\\star}})$。我们将 $c^{\\star}$ 代回 $\\operatorname{Var}(Z_c)$ 的表达式中：\n$$\n\\operatorname{Var}(Z_{c^{\\star}}) = \\operatorname{Var}(X) + (c^{\\star})^2\\operatorname{Var}(Y) - 2c^{\\star}\\operatorname{Cov}(X, Y)\n$$\n代入 $c^{\\star} = \\frac{\\operatorname{Cov}(X, Y)}{\\operatorname{Var}(Y)}$：\n$$\n\\operatorname{Var}(Z_{c^{\\star}}) = \\operatorname{Var}(X) + \\left(\\frac{\\operatorname{Cov}(X, Y)}{\\operatorname{Var}(Y)}\\right)^2 \\operatorname{Var}(Y) - 2\\frac{\\operatorname{Cov}(X, Y)}{\\operatorname{Var}(Y)}\\operatorname{Cov}(X, Y)\n$$\n$$\n\\operatorname{Var}(Z_{c^{\\star}}) = \\operatorname{Var}(X) + \\frac{\\operatorname{Cov}(X, Y)^2}{\\operatorname{Var}(Y)} - 2\\frac{\\operatorname{Cov}(X, Y)^2}{\\operatorname{Var}(Y)} = \\operatorname{Var}(X) - \\frac{\\operatorname{Cov}(X, Y)^2}{\\operatorname{Var}(Y)}\n$$\n现在，我们代入计算出的数值：\n$$\n\\operatorname{Var}(Z_{c^{\\star}}) = \\frac{4}{45} - \\frac{(1/12)^2}{1/12} = \\frac{4}{45} - \\frac{1}{12}\n$$\n为了进行分数相减，我们找到一个公分母，即 $180$：\n$$\n\\operatorname{Var}(Z_{c^{\\star}}) = \\frac{4 \\cdot 4}{180} - \\frac{1 \\cdot 15}{180} = \\frac{16 - 15}{180} = \\frac{1}{180}\n$$\n最后，我们计算方差缩减因子 $R$：\n$$\nR = \\frac{\\operatorname{Var}(Z_{c^{\\star}})}{\\operatorname{Var}(X)} = \\frac{1/180}{4/45} = \\frac{1}{180} \\cdot \\frac{45}{4} = \\frac{45}{720}\n$$\n化简该分数：\n$$\nR = \\frac{1 \\cdot 45}{16 \\cdot 45} = \\frac{1}{16}\n$$\n方差被缩减了 16 倍。", "answer": "$$\n\\boxed{\\frac{1}{16}}\n$$", "id": "3218918"}, {"introduction": "标准的线性控制变量依赖于主估计量和控制变量之间的线性相关性。但如果这种关系是非线性的呢？这个思想实验旨在挑战你的直觉，构建一个线性相关为零但非线性控制变量极为有效的情景[@problem_id:3218904]。完成此练习将加深你对相关性本质的理解，并展示了构造更复杂控制变量的巨大潜力。", "problem": "考虑一个蒙特卡洛估计问题，目标是估计均值 $\\mu = \\mathbb{E}[X]$，其中您可以获取两个随机变量 $X$ 和 $Y$ 的样本。您将构造一个 $(X,Y)$ 的联合分布，其中皮尔逊相关系数 $\\rho(X,Y)$ 为零，但一个非线性控制变量 $Z = g(Y)$ 却能带来非常大的方差缩减。仅使用期望、方差、协方差的基本定义以及正态分布的性质。\n\n设 $Y \\sim \\mathcal{N}(0,1)$ 且 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^{2})$，与 $Y$ 独立，其中 $\\sigma^{2} = 0.01$。定义\n$$\nX = (Y^{2} - 1) + \\varepsilon\n$$\n并考虑非线性控制变量\n$$\nZ = g(Y) = Y^{2} - 1,\n$$\n其均值 $\\mathbb{E}[Z]$ 可由 $Y$ 的分布得知。\n\n任务：\n- 使用协方差的核心定义和标准正态分布矩的性质，验证协方差 $\\operatorname{Cov}(X,Y)$ 等于 $0$，因此相关系数 $\\rho(X,Y)$ 也等于 $0$。\n- 从方差和协方差的定义出发，不假定任何特定公式，推导使 $\\mu$ 的调整估计量 $X - \\beta(Z - \\mathbb{E}[Z])$ 的方差最小化的系数 $\\beta$ 的值。\n- 计算在最优选择 $\\beta$ 下，调整后估计量的单样本方差，以及方差缩减因子\n$$\nR = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}\\big(X - \\beta^{\\star}(Z - \\mathbb{E}[Z])\\big)}。\n$$\n\n以有序对 $(\\beta^{\\star}, R)$ 的精确形式给出您的最终答案。无需四舍五入。最终答案必须是按规定进行的计算。", "solution": "该问题陈述经证实具有科学依据、问题设定良好且客观。它构成了一个概率论和数值方法的正式练习。所有必要信息均已提供，任务定义明确。我们可以开始求解。\n\n该问题要求完成与蒙特卡洛估计场景相关的三个任务。我们给定随机变量 $Y \\sim \\mathcal{N}(0,1)$ 和 $\\varepsilon \\sim \\mathcal{N}(0,\\sigma^{2})$，其中 $\\sigma^{2} = 0.01$。随机变量 $Y$ 和 $\\varepsilon$ 是独立的。我们感兴趣的变量是 $X = (Y^{2} - 1) + \\varepsilon$，控制变量是 $Z = g(Y) = Y^{2} - 1$。\n\n首先，我们确定标准正态变量 $Y$ 的必要矩。\n$Y$ 的概率密度函数关于 $0$ 对称。因此，$Y$ 的所有奇数阶矩均为零。\n$\\mathbb{E}[Y] = 0$\n$\\mathbb{E}[Y^3] = 0$\n偶数阶矩是众所周知的。二阶矩就是方差，因为均值为零：\n$\\mathbb{E}[Y^2] = \\operatorname{Var}(Y) = 1$\n标准正态分布的四阶矩为：\n$\\mathbb{E}[Y^4] = 3$\n\n有了这些，我们就可以确定 $X$ 和 $Z$ 的性质。\n$Z$ 的均值为：\n$\\mathbb{E}[Z] = \\mathbb{E}[Y^2 - 1] = \\mathbb{E}[Y^2] - 1 = 1 - 1 = 0$。\n$X$ 的均值，也就是待估计的量 $\\mu$，为：\n$\\mu = \\mathbb{E}[X] = \\mathbb{E}[(Y^2 - 1) + \\varepsilon] = \\mathbb{E}[Y^2 - 1] + \\mathbb{E}[\\varepsilon] = \\mathbb{E}[Z] + 0 = 0$。\n\n**任务1：验证 $\\operatorname{Cov}(X,Y) = 0$**\n\n协方差定义为 $\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X]\\mathbb{E}[Y]$。\n我们有 $\\mathbb{E}[Y] = 0$，所以第二项为零：\n$\\operatorname{Cov}(X,Y) = \\mathbb{E}[XY] - \\mathbb{E}[X] \\cdot 0 = \\mathbb{E}[XY]$。\n我们通过代入 $X$ 的定义来计算 $\\mathbb{E}[XY]$：\n$\\mathbb{E}[XY] = \\mathbb{E}[((Y^2 - 1) + \\varepsilon)Y] = \\mathbb{E}[Y^3 - Y + \\varepsilon Y]$。\n根据期望的线性性质：\n$\\mathbb{E}[XY] = \\mathbb{E}[Y^3] - \\mathbb{E}[Y] + \\mathbb{E}[\\varepsilon Y]$。\n如前所述，$\\mathbb{E}[Y^3] = 0$ 且 $\\mathbb{E}[Y] = 0$。对于最后一项，由于 $\\varepsilon$ 和 $Y$ 是独立的，所以 $\\mathbb{E}[\\varepsilon Y] = \\mathbb{E}[\\varepsilon]\\mathbb{E}[Y]$。我们知道 $\\mathbb{E}[\\varepsilon]=0$ 且 $\\mathbb{E}[Y]=0$，因此 $\\mathbb{E}[\\varepsilon Y] = 0 \\cdot 0 = 0$。\n因此，$\\mathbb{E}[XY] = 0 - 0 + 0 = 0$。\n这证实了 $\\operatorname{Cov}(X,Y) = 0$。\n皮尔逊相关系数为 $\\rho(X,Y) = \\frac{\\operatorname{Cov}(X,Y)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}}$。由于分子为 $0$ 且方差不为零（如下所示），所以 $\\rho(X,Y) = 0$。\n\n**任务2：推导最优系数 $\\beta^{\\star}$**\n\n我们的任务是找到使调整后估计量 $X_{\\beta} = X - \\beta(Z - \\mathbb{E}[Z])$ 的方差最小的 $\\beta$ 值，记为 $\\beta^{\\star}$。设 $V(\\beta) = \\operatorname{Var}(X_{\\beta})$。\n由于 $\\mathbb{E}[Z] = 0$，估计量为 $X_{\\beta} = X - \\beta Z$。\n需要最小化的方差是：\n$V(\\beta) = \\operatorname{Var}(X - \\beta Z)$。\n利用方差的性质，其中 $\\beta$ 是一个常数：\n$V(\\beta) = \\operatorname{Var}(X) + \\operatorname{Var}(-\\beta Z) + 2\\operatorname{Cov}(X, -\\beta Z)$。\n$V(\\beta) = \\operatorname{Var}(X) + \\beta^{2}\\operatorname{Var}(Z) - 2\\beta\\operatorname{Cov}(X, Z)$。\n这是一个关于 $\\beta$ 的二次函数。为了找到最小值，我们计算其关于 $\\beta$ 的导数并令其为零：\n$\\frac{d V}{d\\beta} = \\frac{d}{d\\beta} \\left( \\operatorname{Var}(X) + \\beta^{2}\\operatorname{Var}(Z) - 2\\beta\\operatorname{Cov}(X, Z) \\right) = 2\\beta\\operatorname{Var}(Z) - 2\\operatorname{Cov}(X, Z)$。\n将导数设为零：\n$2\\beta\\operatorname{Var(Z)} - 2\\operatorname{Cov}(X, Z) = 0$。\n求解最优系数 $\\beta^{\\star}$：\n$\\beta^{\\star} = \\frac{\\operatorname{Cov}(X, Z)}{\\operatorname{Var}(Z)}$。\n二阶导数 $\\frac{d^2 V}{d\\beta^2} = 2\\operatorname{Var}(Z)$ 是正的，因为方差是非负的（在本例中非零），这证实了这是一个最小值点。\n\n**任务3：计算 $\\beta^{\\star}$ 和方差缩减因子 $R$**\n\n为了计算 $\\beta^{\\star}$，我们需要计算 $\\operatorname{Var}(Z)$ 和 $\\operatorname{Cov}(X,Z)$。\n首先，我们求控制变量 $Z$ 的方差：\n$\\operatorname{Var}(Z) = \\mathbb{E}[Z^2] - (\\mathbb{E}[Z])^2$。由于 $\\mathbb{E}[Z]=0$，$\\operatorname{Var}(Z) = \\mathbb{E}[Z^2]$。\n$\\operatorname{Var}(Z) = \\mathbb{E}[(Y^2-1)^2] = \\mathbb{E}[Y^4 - 2Y^2 + 1]$。\n利用期望的线性性质和 $Y$ 的矩：\n$\\operatorname{Var}(Z) = \\mathbb{E}[Y^4] - 2\\mathbb{E}[Y^2] + 1 = 3 - 2(1) + 1 = 2$。\n\n接下来，我们计算 $X$ 和 $Z$ 之间的协方差：\n$\\operatorname{Cov}(X,Z) = \\mathbb{E}[XZ] - \\mathbb{E}[X]\\mathbb{E}[Z]$。\n由于 $\\mathbb{E}[X] = 0$ 且 $\\mathbb{E}[Z] = 0$，我们有 $\\operatorname{Cov}(X,Z) = \\mathbb{E}[XZ]$。\n代入 $X = Z + \\varepsilon$：\n$\\operatorname{Cov}(X,Z) = \\mathbb{E}[(Z+\\varepsilon)Z] = \\mathbb{E}[Z^2 + \\varepsilon Z] = \\mathbb{E}[Z^2] + \\mathbb{E}[\\varepsilon Z]$。\n我们知道 $\\mathbb{E}[Z^2] = \\operatorname{Var}(Z) = 2$。\n对于项 $\\mathbb{E}[\\varepsilon Z]$，我们利用 $\\varepsilon$ 和 $Y$ 的独立性。由于 $Z = Y^2-1$ 是 $Y$ 的函数，所以 $Z$ 和 $\\varepsilon$ 也是独立的。\n因此，$\\mathbb{E}[\\varepsilon Z] = \\mathbb{E}[\\varepsilon]\\mathbb{E}[Z] = 0 \\cdot 0 = 0$。\n所以，$\\operatorname{Cov}(X,Z) = 2 + 0 = 2$。\n\n现在我们可以计算最优系数 $\\beta^{\\star}$：\n$\\beta^{\\star} = \\frac{\\operatorname{Cov}(X, Z)}{\\operatorname{Var}(Z)} = \\frac{2}{2} = 1$。\n\n最后，我们计算方差缩减因子 $R = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}\\big(X - \\beta^{\\star}(Z - \\mathbb{E}[Z])\\big)}$。\n首先，分子 $\\operatorname{Var}(X)$：\n$X = Z + \\varepsilon$。由于 $Z$ 和 $\\varepsilon$ 是独立的，它们之和的方差等于方差之和：\n$\\operatorname{Var}(X) = \\operatorname{Var}(Z) + \\operatorname{Var}(\\varepsilon) = 2 + \\sigma^2 = 2 + 0.01 = 2.01$。\n\n接下来，分母，即最优 $\\beta^{\\star}=1$ 和 $\\mathbb{E}[Z]=0$ 时调整后估计量的方差：\n$\\operatorname{Var}\\big(X - \\beta^{\\star}(Z - \\mathbb{E}[Z])\\big) = \\operatorname{Var}(X - 1 \\cdot (Z - 0)) = \\operatorname{Var}(X-Z)$。\n代入 $X = Z + \\varepsilon$：\n$\\operatorname{Var}(X-Z) = \\operatorname{Var}((Z+\\varepsilon) - Z) = \\operatorname{Var}(\\varepsilon)$。\n我们已知 $\\operatorname{Var}(\\varepsilon) = \\sigma^2 = 0.01$。\n\n现在，我们可以计算方差缩减因子 $R$：\n$R = \\frac{\\operatorname{Var}(X)}{\\operatorname{Var}(X-Z)} = \\frac{2.01}{0.01} = 201$。\n\n最终答案是有序对 $(\\beta^{\\star}, R)$。\n$\\beta^{\\star} = 1$\n$R = 201$\n最终的有序对是 $(1, 201)$。", "answer": "$$\n\\boxed{(1, 201)}\n$$", "id": "3218904"}, {"introduction": "控制变量法在实际科学计算中应用广泛，尤其是在估计模型对参数变化的敏感度时。本练习将理论付诸实践，要求你编写代码来估计一个期望值的变化量[@problem_id:3218894]。你将学习一种强大的技巧：使用模型在基准参数下的输出作为控制变量，来高效估计模型在微扰参数下的输出，这在金融工程和物理建模等领域至关重要。", "problem": "您的任务是使用控制变量法，通过蒙特卡洛模拟来估计期望值的变化。目标是通过使用 $f(X; \\theta_0)$ 作为估计 $E[f(X; \\theta_1)]$ 的控制变量，来高效地估计差值 $E[f(X; \\theta_1)] - E[f(X; \\theta_0)]$。请在以下数学定义的背景下进行操作。\n\n基本设定：\n- 设 $X$ 是一个服从标准正态分布的随机变量，即 $X \\sim \\mathcal{N}(0, 1)$。\n- 设 $f(x; \\theta) = \\exp(\\theta x)$，其中 $\\theta$ 为实数参数。\n- 对于任意实数 $\\theta$，期望 $E[f(X; \\theta)]$ 都是良定义且有限的。\n- 期望、方差和协方差定义如下：$E[Y] = \\int y \\, dP$，$\\operatorname{Var}(Y) = E\\left[(Y - E[Y])^2\\right]$，以及 $\\operatorname{Cov}(Y, Z) = E\\left[(Y - E[Y])(Z - E[Z])\\right]$，其中 $P$ 是底层的概率测度。\n\n任务：\n1. 仅从期望的线性性质以及方差和协方差的定义出发，推导出一个使用 $f(X; \\theta_0)$ 作为控制变量来估计 $E[f(X; \\theta_1)]$ 的线性控制变量估计量的系数。考虑形式如下的估计量\n   $$\\widehat{\\mu}(\\beta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right),$$\n   其中 $Y_i = f(X_i; \\theta_1)$，$G_i = f(X_i; \\theta_0)$，$\\mu_0 = E[f(X; \\theta_0)]$，且 $X_i$ 是从 $X$ 中抽取的独立同分布样本。推导使 $\\widehat{\\mu}(\\beta)$ 方差最小化的 $\\beta$ 选择，并证明 $\\widehat{\\mu}(\\beta)$ 是 $E[f(X; \\theta_1)]$ 的无偏估计。\n2. 实现一个蒙特卡洛算法，该算法：\n   - 从 $X$ 生成 $N$ 个独立样本 $X_i$。\n   - 计算朴素差分估计量 $\\widehat{\\Delta}_{\\mathrm{naive}} = \\overline{Y} - \\overline{G}$，其中 $\\overline{Y} = \\frac{1}{N}\\sum_{i=1}^{N} Y_i$ 且 $\\overline{G} = \\frac{1}{N}\\sum_{i=1}^{N} G_i$。\n   - 使用任务1中推导出的最优系数计算 $E[f(X; \\theta_1)]$ 的控制变量估计，然后计算差分估计 $\\widehat{\\Delta}_{\\mathrm{cv}} = \\widehat{\\mu}(\\widehat{\\beta}) - \\mu_0$，其中 $\\widehat{\\beta}$ 是最优系数的样本估计值。\n   - 当可以从经过充分检验的公式和事实中获得 $\\mu_0$ 的精确值和精确差值 $E[f(X; \\theta_1)] - E[f(X; \\theta_0)]$ 时，请使用它们。对于 $X \\sim \\mathcal{N}(0, 1)$ 和 $f(x; \\theta) = \\exp(\\theta x)$，使用已知的正态分布矩生成函数来提供精确值以供比较。\n3. 使用以下参数值测试套件来评估您的算法。每个测试用例是一个元组 $(\\theta_0, \\theta_1, N, \\text{seed})$：\n   - 用例1（理想路径，参数接近）：$(0.50, 0.60, 200000, 12345)$。\n   - 用例2（边界情况，无变化）：$(0.75, 0.75, 50000, 54321)$。\n   - 用例3（相关性较低，变化较大）：$(0.00, 1.50, 150000, 2023)$。\n   - 用例4（边缘情况，样本量极小）：$(0.25, 0.30, 1, 7)$。\n   对于每个用例，$N$ 是蒙特卡洛样本量，$\\text{seed}$ 是伪随机数生成器的种子。\n4. 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例应生成一个包含三个浮点数的列表 $[\\widehat{\\Delta}_{\\mathrm{naive}}, \\widehat{\\Delta}_{\\mathrm{cv}}, \\Delta_{\\mathrm{exact}}]$，最终输出应为这些列表的列表，顺序与测试套件中的顺序相同。例如，输出应如下所示\n   $$[[a_1, b_1, c_1], [a_2, b_2, c_2], [a_3, b_3, c_3], [a_4, b_4, c_4]],$$\n   其中每个 $a_i$、$b_i$ 和 $c_i$ 都是浮点数。如果由于 $N$ 太小导致控制变量的方差估计为零，则将控制变量系数设置为 $\\beta = 0$。\n\n注：\n- 不涉及角度；无需角度单位。\n- 不涉及物理量；无需物理单位。\n- 算法的实现必须确保在给定种子的情况下，所有结果都是确定性的。", "solution": "目标是使用控制变量法来估计期望值的变化 $E[f(X; \\theta_1)] - E[f(X; \\theta_0)]$，以提高蒙特卡洛模拟的效率。我们给定函数 $f(x; \\theta) = \\exp(\\theta x)$，其中 $X$ 是一个标准正态随机变量，$X \\sim \\mathcal{N}(0, 1)$。我们将首先推导控制变量估计量的最优系数并证明其性质，然后详细说明其数值实现的算法。\n\n### 任务1：最优控制变量系数的推导\n\n我们给定一个用于 $\\mu_1 = E[f(X; \\theta_1)]$ 的控制变量估计量：\n$$\n\\widehat{\\mu}(\\beta) = \\frac{1}{N} \\sum_{i=1}^{N} \\left(Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right)\n$$\n其中 $Y_i = f(X_i; \\theta_1)$，$G_i = f(X_i; \\theta_0)$，且 $\\mu_0 = E[G_i] = E[f(X; \\theta_0)]$。样本 $X_i$ 是独立同分布的（i.i.d.）。\n\n#### 估计量的无偏性\n首先，我们证明对于任意常数系数 $\\beta$，$\\widehat{\\mu}(\\beta)$ 都是 $\\mu_1$ 的无偏估计量。我们计算 $\\widehat{\\mu}(\\beta)$ 的期望：\n$$\nE[\\widehat{\\mu}(\\beta)] = E\\left[\\frac{1}{N} \\sum_{i=1}^{N} \\left(Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right)\\right]\n$$\n根据期望的线性性质，我们可以将期望算子移到求和符号内部：\n$$\nE[\\widehat{\\mu}(\\beta)] = \\frac{1}{N} \\sum_{i=1}^{N} E\\left[Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right]\n$$\n再次对求和内的项应用线性性质：\n$$\nE\\left[Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right] = E[Y_i] - \\beta E[G_i - \\mu_0]\n$$\n根据定义，$E[Y_i] = \\mu_1$ 且 $E[G_i] = \\mu_0$。因此：\n$$\nE[G_i - \\mu_0] = E[G_i] - E[\\mu_0] = \\mu_0 - \\mu_0 = 0\n$$\n将其代回，我们得到：\n$$\nE\\left[Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right] = \\mu_1 - \\beta(0) = \\mu_1\n$$\n由于这对每个样本 $i=1, \\dots, N$ 都成立，所以估计量的期望为：\n$$\nE[\\widehat{\\mu}(\\beta)] = \\frac{1}{N} \\sum_{i=1}^{N} \\mu_1 = \\frac{1}{N} (N \\mu_1) = \\mu_1\n$$\n因此，无论 $\\beta$ 的选择如何，$\\widehat{\\mu}(\\beta)$ 都是 $\\mu_1$ 的无偏估计量。\n\n#### 方差最小化\n接下来，我们找出使 $\\widehat{\\mu}(\\beta)$ 方差最小的 $\\beta$ 值。方差为：\n$$\n\\operatorname{Var}(\\widehat{\\mu}(\\beta)) = \\operatorname{Var}\\left(\\frac{1}{N} \\sum_{i=1}^{N} \\left(Y_i - \\beta \\left(G_i - \\mu_0\\right)\\right)\\right)\n$$\n由于和中的各项是独立同分布的，样本均值的方差是单项方差的 $\\frac{1}{N}$ 倍：\n$$\n\\operatorname{Var}(\\widehat{\\mu}(\\beta)) = \\frac{1}{N} \\operatorname{Var}\\left(Y_1 - \\beta \\left(G_1 - \\mu_0\\right)\\right)\n$$\n常数项 $-\\beta \\mu_0$ 不影响方差，因此我们可以将其简化为：\n$$\n\\operatorname{Var}(\\widehat{\\mu}(\\beta)) = \\frac{1}{N} \\operatorname{Var}\\left(Y - \\beta G\\right)\n$$\n其中 $Y = f(X; \\theta_1)$，$G = f(X; \\theta_0)$。使用随机变量线性组合的方差标准公式：\n$$\n\\operatorname{Var}(Y - \\beta G) = \\operatorname{Var}(Y) + \\operatorname{Var}(-\\beta G) + 2 \\operatorname{Cov}(Y, -\\beta G) = \\operatorname{Var}(Y) + \\beta^2 \\operatorname{Var}(G) - 2\\beta \\operatorname{Cov}(Y, G)\n$$\n为了使该方差相对于 $\\beta$ 最小化，我们对这个关于 $\\beta$ 的二次函数求导并令其为零：\n$$\n\\frac{d}{d\\beta} \\operatorname{Var}(Y - \\beta G) = \\frac{d}{d\\beta} \\left( \\operatorname{Var}(Y) + \\beta^2 \\operatorname{Var}(G) - 2\\beta \\operatorname{Cov}(Y, G) \\right) = 2\\beta \\operatorname{Var}(G) - 2 \\operatorname{Cov}(Y, G)\n$$\n将导数设为零，得到最优系数 $\\beta^*$：\n$$\n2\\beta^* \\operatorname{Var}(G) - 2 \\operatorname{Cov}(Y, G) = 0 \\implies \\beta^* = \\frac{\\operatorname{Cov}(Y, G)}{\\operatorname{Var}(G)}\n$$\n二阶导数 $2\\operatorname{Var}(G)$ 是非负的，这证实了该 $\\beta$ 值对应于一个最小值（前提是 $\\operatorname{Var}(G)  0$）。\n\n### 任务2：算法与实现细节\n\n实现需要为每个测试用例计算三个量：朴素差分估计 $\\widehat{\\Delta}_{\\mathrm{naive}}$、控制变量差分估计 $\\widehat{\\Delta}_{\\mathrm{cv}}$ 和精确差分 $\\Delta_{\\mathrm{exact}}$。\n\n#### 从矩生成函数得到的精确值\n对于标准正态随机变量 $X \\sim \\mathcal{N}(0, 1)$，其矩生成函数（MGF）为 $M_X(t) = E[\\exp(tX)] = \\exp(t^2/2)$。因此，我们的目标函数 $f(x; \\theta) = \\exp(\\theta x)$ 的期望为：\n$$\n\\mu_\\theta = E[f(X; \\theta)] = E[\\exp(\\theta X)] = M_X(\\theta) = \\exp(\\theta^2/2)\n$$\n使用此公式，所需的精确值为：\n- $\\mu_0 = E[f(X; \\theta_0)] = \\exp(\\theta_0^2/2)$\n- $\\mu_1 = E[f(X; \\theta_1)] = \\exp(\\theta_1^2/2)$\n- $\\Delta_{\\mathrm{exact}} = \\mu_1 - \\mu_0 = \\exp(\\theta_1^2/2) - \\exp(\\theta_0^2/2)$\n\n#### 待计算的估计量\n1.  **朴素差分估计量**：这是 $Y$ 和 $G$ 的样本均值之差：\n    $$\n    \\widehat{\\Delta}_{\\mathrm{naive}} = \\overline{Y} - \\overline{G} = \\left(\\frac{1}{N}\\sum_{i=1}^{N} Y_i\\right) - \\left(\\frac{1}{N}\\sum_{i=1}^{N} G_i\\right)\n    $$\n2.  **控制变量差分估计量**：该估计量使用 $\\mu_1$ 的控制变量估计，并减去 $\\mu_0$ 的精确值。最优系数 $\\beta^*$ 是未知的，必须从样本中估计。基于样本的估计值 $\\widehat{\\beta}$ 为：\n    $$\n    \\widehat{\\beta} = \\frac{\\widehat{\\operatorname{Cov}}(Y, G)}{\\widehat{\\operatorname{Var}}(G)} = \\frac{\\frac{1}{N-1}\\sum_{i=1}^N (Y_i - \\overline{Y})(G_i - \\overline{G})}{\\frac{1}{N-1}\\sum_{i=1}^N (G_i - \\overline{G})^2}\n    $$\n    $\\mu_1$ 的控制变量估计为 $\\widehat{\\mu}_1(\\widehat{\\beta}) = \\overline{Y} - \\widehat{\\beta}(\\overline{G} - \\mu_0)$。最终的差分估计量为：\n    $$\n    \\widehat{\\Delta}_{\\mathrm{cv}} = \\widehat{\\mu}_1(\\widehat{\\beta}) - \\mu_0 = \\overline{Y} - \\widehat{\\beta}(\\overline{G} - \\mu_0) - \\mu_0\n    $$\n\n#### 处理边缘情况\n根据说明，如果控制变量的样本方差 $\\widehat{\\operatorname{Var}}(G)$ 为零，则系数 $\\widehat{\\beta}$ 设为 $0$。这种情况发生在 $N \\le 1$ 或所有生成的样本 $G_i$ 都相同时（例如，当 $\\theta_0=0$ 时）。在这种情况下，控制变量项消失，估计量 $\\widehat{\\mu}_1(\\widehat{\\beta})$ 简化为简单样本均值 $\\overline{Y}$。\n\n每个测试用例 $(\\theta_0, \\theta_1, N, \\text{seed})$ 的流程如下：\n1.  使用 `seed` 为随机数生成器设置种子。\n2.  生成 $N$ 个样本 $X_i \\sim \\mathcal{N}(0, 1)$。\n3.  计算向量 $Y_i = \\exp(\\theta_1 X_i)$ 和 $G_i = \\exp(\\theta_0 X_i)$。\n4.  计算样本均值 $\\overline{Y}$ 和 $\\overline{G}$。\n5.  计算 $\\widehat{\\Delta}_{\\mathrm{naive}} = \\overline{Y} - \\overline{G}$。\n6.  计算 $\\widehat{\\beta}$。如果 $N  1$ 且 $\\widehat{\\operatorname{Var}}(G)  0$，则使用基于样本的公式。否则，设置 $\\widehat{\\beta} = 0$。\n7.  计算精确值 $\\mu_0 = \\exp(\\theta_0^2/2)$。\n8.  计算 $\\widehat{\\Delta}_{\\mathrm{cv}} = \\overline{Y} - \\widehat{\\beta}(\\overline{G} - \\mu_0) - \\mu_0$。\n9.  计算 $\\Delta_{\\mathrm{exact}} = \\exp(\\theta_1^2/2) - \\exp(\\theta_0^2/2)$。\n10. 收集三元组 $[\\widehat{\\Delta}_{\\mathrm{naive}}, \\widehat{\\Delta}_{\\mathrm{cv}}, \\Delta_{\\mathrm{exact}}]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Monte Carlo simulation to estimate the change in an expected value\n    using both a naive estimator and a control variate estimator, and compares them\n    to the exact analytical solution.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    # Each case is a tuple: (theta_0, theta_1, N, seed)\n    test_cases = [\n        (0.50, 0.60, 200000, 12345),\n        (0.75, 0.75, 50000, 54321),\n        (0.00, 1.50, 150000, 2023),\n        (0.25, 0.30, 1, 7),\n    ]\n\n    results = []\n    \n    for theta_0, theta_1, N, seed in test_cases:\n        # Set the seed for the pseudorandom number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n        \n        # 1. Generate N independent samples from the standard normal distribution.\n        X_samples = rng.normal(loc=0.0, scale=1.0, size=N)\n        \n        # 2. Compute Y and G values.\n        # Y_i = f(X_i; theta_1)\n        # G_i = f(X_i; theta_0)\n        Y = np.exp(theta_1 * X_samples)\n        G = np.exp(theta_0 * X_samples)\n        \n        # 3. Compute sample means.\n        Y_bar = np.mean(Y)\n        G_bar = np.mean(G)\n        \n        # 4. Compute the naive difference estimator.\n        # delta_naive = E[Y] - E[G] estimated by mean(Y) - mean(G).\n        delta_naive = Y_bar - G_bar\n        \n        # 5. Compute the control variate estimator.\n        # First, estimate the optimal coefficient beta.\n        # beta_hat = Cov(Y, G) / Var(G).\n        beta_hat = 0.0\n        # The sample variance and covariance are undefined for N = 1.\n        # The problem also specifies to set beta=0 if the variance is zero.\n        if N > 1:\n            var_G = np.var(G, ddof=1)\n            # Avoid division by zero if Var(G) is zero (e.g., if theta_0 = 0).\n            if var_G > 0:\n                # np.cov with 1D arrays Y, G returns a 2x2 covariance matrix.\n                # cov_matrix[0, 1] is Cov(Y, G).\n                cov_YG = np.cov(Y, G, ddof=1)[0, 1]\n                beta_hat = cov_YG / var_G\n\n        # 6. Compute exact value for mu_0 = E[G]\n        # For X ~ N(0, 1), E[exp(t*X)] = exp(t^2 / 2).\n        mu_0_exact = np.exp(theta_0**2 / 2.0)\n        \n        # 7. Compute the control variate estimate for mu_1 = E[Y].\n        # mu1_cv = mean(Y) - beta_hat * (mean(G) - mu_0)\n        mu_1_cv = Y_bar - beta_hat * (G_bar - mu_0_exact)\n        \n        # 8. Compute the control variate difference estimator.\n        # delta_cv = mu1_cv - mu_0\n        delta_cv = mu_1_cv - mu_0_exact\n        \n        # 9. Compute the exact difference.\n        mu_1_exact = np.exp(theta_1**2 / 2.0)\n        delta_exact = mu_1_exact - mu_0_exact\n        \n        # 10. Store the triplet of results for the current test case.\n        results.append([delta_naive, delta_cv, delta_exact])\n\n    # Final print statement in the exact required format.\n    # The format is a string representation of a list of lists of floats.\n    output_str = '[' + ','.join([f\"[{a},{b},{c}]\" for a, b, c in results]) + ']'\n    print(output_str)\n\nsolve()\n```", "id": "3218894"}]}