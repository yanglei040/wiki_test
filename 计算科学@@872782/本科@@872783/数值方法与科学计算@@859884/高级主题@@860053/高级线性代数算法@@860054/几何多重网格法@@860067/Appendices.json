{"hands_on_practices": [{"introduction": "要真正理解多重网格循环的工作原理，没有什么比亲手计算一遍更好的方法了。本练习 [@problem_id:3235102] 将引导您为一个简单的一维问题逐步计算一个完整的V-循环，让您清晰地看到误差和残差如何通过光滑、限制、粗网格校正和插值等步骤进行变换。通过手动追踪这些变化，您将为多重网格方法的内部机制建立起具体的直观认识。", "problem": "考虑一维泊松方程 $-u''(x) = f(x)$，定义在区间 $(0,1)$ 上，并带有齐次狄利克雷边界条件 $u(0) = u(1) = 0$。使用标准的二阶中心有限差分法，在具有 $N=15$ 个内部点的最细网格上进行离散化，因此网格间距为 $h = \\frac{1}{N+1} = \\frac{1}{16}$。设最细网格上的离散算子为 $A_h = \\frac{1}{h^2} T$，其中 $T \\in \\mathbb{R}^{15 \\times 15}$ 是一个三对角矩阵，其主对角线上的元素为 $2$，第一副对角线和第一超对角线上的元素为 $-1$。\n\n执行一个双网格 V-循环，包含以下组成部分：\n- 预平滑：一次权重为 $\\omega = \\frac{2}{3}$ 的加权雅可比迭代。\n- 限制：从 15 点网格到 7 点粗网格的全加权限制 $R$（即 $(R r)_j = \\frac{1}{4}\\big(r_{2j-1} + 2 r_{2j} + r_{2j+1}\\big)$，对于 $j=1,\\dots,7$）。\n- 粗网格算子：伽辽金选择 $A_{2h} = R A_h P$，其中 $P$ 是从 7 点网格到 15 点网格的线性插值（值在偶数索引的细网格点处注入，在奇数索引的细网格点处线性插值）。\n- 粗网格求解：精确求解粗网格系统。\n- 延长：如上所述的线性插值 $P$。\n- 后平滑：一次权重为 $\\omega = \\frac{2}{3}$ 的加权雅可比迭代。\n\n假设右端项为零，$f \\equiv 0$，因此精确解为 $u \\equiv 0$。在最细网格上，取初始猜测为中间内部点的克罗内克 delta：$u^{(0)}_i = \\delta_{i,8}$，对于 $i=1,\\dots,15$。等价地，初始误差为 $e^{(0)} = u^{(0)}$。\n\n在最细网格上，用手算明确计算 V-循环每个阶段的以下量：\n- 预平滑后的误差 $e^{(1)}$ 和相应的细网格残差 $r^{(1)} = -A_h e^{(1)}$。\n- 限制后的粗网格残差 $r_{2h} = R r^{(1)}$ 和求解 $A_{2h} d_{2h} = r_{2h}$ 得到的精确粗网格校正量 $d_{2h}$。\n- 细网格校正量 $P d_{2h}$ 和后平滑前的校正误差 $e^{(1,\\mathrm{cc})} = e^{(1)} + P d_{2h}$。\n- 经过最后一次加权雅可比迭代后的后平滑误差 $e^{(V)}$。\n\n在报告残差时，为避免混乱，可以忽略公因子 $\\frac{1}{h^2}$，并报告未缩放的量 $-T e$ 来代替 $-A_h e$。最后，设 $\\|\\cdot\\|_2$ 表示 $\\mathbb{R}^{15}$ 上的欧几里得范数。比值 $\\|e^{(V)}\\|_2 / \\|e^{(0)}\\|_2$ 的精确值是多少？将最终答案表示为简化的精确表达式。无需四舍五入。", "solution": "该问题要求对一维泊松方程详细、分步地计算一个双网格 V-循环。我们将系统地计算循环中每个阶段的误差向量状态。\n\n**步骤 0：初始状态**\n\n问题在具有 $N=15$ 个内部点的细网格上离散化。网格间距为 $h = \\frac{1}{16}$。设 $e^{(0)}$ 为 $\\mathbb{R}^{15}$ 中的初始误差向量。精确解为 $u \\equiv 0$，因此误差等于初始猜测。\n初始猜测给定为 $u^{(0)}_i = \\delta_{i,8}$，其中 $\\delta_{i,j}$ 是克罗内克 delta。因此，初始误差向量 $e^{(0)}$ 是一个标准基向量：\n$$e^{(0)} = (0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0)^T \\equiv e_8$$\n初始误差的欧几里得范数为 $\\|e^{(0)}\\|_2 = \\sqrt{1^2} = 1$。\n\n**步骤 1：预平滑和细网格残差**\n\n对初始误差 $e^{(0)}$ 应用一次权重为 $\\omega = \\frac{2}{3}$ 的加权雅可比预平滑步骤。误差变换由迭代矩阵 $S = I - \\omega D_h^{-1} A_h$ 给出。\n细网格算子为 $A_h = \\frac{1}{h^2} T$，其中 $T = \\text{tridiag}(-1, 2, -1)$ 是 $15 \\times 15$ 的离散拉普拉斯算子。$A_h$ 的对角部分为 $D_h = \\frac{2}{h^2}I$。\n因此，平滑算子矩阵为：\n$$S = I - \\frac{2}{3} \\left(\\frac{h^2}{2}I\\right) \\left(\\frac{1}{h^2}T\\right) = I - \\frac{1}{3}T$$\n预平滑后的误差 $e^{(1)}$ 为：\n$$e^{(1)} = S e^{(0)} = \\left(I - \\frac{1}{3}T\\right) e_8 = e_8 - \\frac{1}{3} (T e_8)$$\n向量 $T e_8$ 对应于 $T$ 的第 8 列，即 $(0, \\dots, -1, 2, -1, \\dots, 0)^T$，其非零项位于索引 $i=7, 8, 9$ 处。\n$$T e_8 = -e_7 + 2e_8 - e_9$$\n因此，\n$$e^{(1)} = e_8 - \\frac{1}{3}(-e_7 + 2e_8 - e_9) = \\frac{1}{3}e_7 + \\left(1-\\frac{2}{3}\\right)e_8 + \\frac{1}{3}e_9 = \\frac{1}{3}(e_7 + e_8 + e_9)$$\n所以，预平滑后的误差为 $e^{(1)} = (0, 0, 0, 0, 0, 0, \\frac{1}{3}, \\frac{1}{3}, \\frac{1}{3}, 0, 0, 0, 0, 0, 0)^T$。\n\n接下来，我们计算细网格残差 $r^{(1)} = -A_h e^{(1)}$。根据问题陈述的允许，我们将计算未缩放的残差 $\\tilde{r}^{(1)} = -T e^{(1)}$。\n$$\\tilde{r}^{(1)} = -T \\left(\\frac{1}{3}(e_7 + e_8 + e_9)\\right) = -\\frac{1}{3}(T e_7 + T e_8 + T e_9)$$\n使用 $T e_i = -e_{i-1} + 2e_i - e_{i+1}$（其中 $e_0=e_{16}=0$）：\n\\begin{align*} T e_7 = -e_6 + 2e_7 - e_8 \\\\ T e_8 = -e_7 + 2e_8 - e_9 \\\\ T e_9 = -e_8 + 2e_9 - e_{10} \\end{align*}\n将这些相加得到：\n$$T(e_7+e_8+e_9) = -e_6 + (-1+2)e_7 + (-1+2-1)e_8 + (-1+2)e_9 - e_{10} = -e_6 + e_7 + e_9 - e_{10}$$\n因此，未缩放的残差为：\n$$\\tilde{r}^{(1)} = -\\frac{1}{3}(-e_6 + e_7 + e_9 - e_{10}) = \\frac{1}{3}(e_6 - e_7 - e_9 + e_{10})$$\n具体来说，$\\tilde{r}^{(1)} = (0, 0, 0, 0, 0, \\frac{1}{3}, -\\frac{1}{3}, 0, -\\frac{1}{3}, \\frac{1}{3}, 0, 0, 0, 0, 0)^T$。\n\n**步骤 2：限制和粗网格求解**\n\n使用全加权算子 $R$ 将未缩放的细网格残差 $\\tilde{r}^{(1)}$ 限制到粗网格（7 个内部点）上：\n$$(r_{2h})_j = (R \\tilde{r}^{(1)})_j = \\frac{1}{4}\\left(\\tilde{r}^{(1)}_{2j-1} + 2\\tilde{r}^{(1)}_{2j} + \\tilde{r}^{(1)}_{2j+1}\\right) \\quad \\text{对于 } j=1, \\dots, 7$$\n$\\tilde{r}^{(1)}$ 的非零分量位于索引 $6, 7, 9, 10$ 处。\n\\begin{align*} (r_{2h})_1 = (R\\tilde{r}^{(1)})_1 = \\frac{1}{4}(0+0+0)=0 \\\\ (r_{2h})_2 = (R\\tilde{r}^{(1)})_2 = \\frac{1}{4}(0+0+0)=0 \\\\ (r_{2h})_3 = (R\\tilde{r}^{(1)})_3 = \\frac{1}{4}(\\tilde{r}^{(1)}_5 + 2\\tilde{r}^{(1)}_6 + \\tilde{r}^{(1)}_7) = \\frac{1}{4}\\left(0 + 2\\left(\\frac{1}{3}\\right) - \\frac{1}{3}\\right) = \\frac{1}{12} \\\\ (r_{2h})_4 = (R\\tilde{r}^{(1)})_4 = \\frac{1}{4}(\\tilde{r}^{(1)}_7 + 2\\tilde{r}^{(1)}_8 + \\tilde{r}^{(1)}_9) = \\frac{1}{4}\\left(-\\frac{1}{3} + 2(0) - \\frac{1}{3}\\right) = -\\frac{2}{12} = -\\frac{1}{6} \\\\ (r_{2h})_5 = (R\\tilde{r}^{(1)})_5 = \\frac{1}{4}(\\tilde{r}^{(1)}_9 + 2\\tilde{r}^{(1)}_{10} + \\tilde{r}^{(1)}_{11}) = \\frac{1}{4}\\left(-\\frac{1}{3} + 2\\left(\\frac{1}{3}\\right) + 0\\right) = \\frac{1}{12} \\\\ (r_{2h})_6 = (R\\tilde{r}^{(1)})_6 = 0 \\\\ (r_{2h})_7 = (R\\tilde{r}^{(1)})_7 = 0 \\end{align*}\n限制后的粗网格残差为 $r_{2h} = (0, 0, \\frac{1}{12}, -\\frac{1}{6}, \\frac{1}{12}, 0, 0)^T$。\n\n需要精确求解的粗网格方程是 $A_{2h} d_{2h} = R r^{(1)}$，其中 $r^{(1)} = -A_h e^{(1)}$。\n$A_{2h} = R A_h P = R \\left(\\frac{1}{h^2} T\\right) P = \\frac{1}{h^2} RTP$。\n$R r^{(1)} = R \\left(-\\frac{1}{h^2} T e^{(1)}\\right) = \\frac{1}{h^2} R \\tilde{r}^{(1)} = \\frac{1}{h^2} r_{2h}$。\n粗网格方程是 $(\\frac{1}{h^2} RTP) d_{2h} = \\frac{1}{h^2} r_{2h}$，它简化为 $(RTP) d_{2h} = r_{2h}$。\n对于标准的1D问题，伽辽金粗网格算子 $A_{2h} = R A_h P$ 与在粗网格上直接离散化得到的算子 $A_{2h}^{FD} = \\frac{1}{(2h)^2}T_{2h}$ 相同。这意味着 $R A_h P = \\frac{1}{4h^2}T_{2h}$。\n因此，粗网格方程为 $\\frac{1}{4h^2}T_{2h} d_{2h} = R r^{(1)} = \\frac{1}{h^2}r_{2h}$，简化为 $T_{2h} d_{2h} = 4 r_{2h}$。\n$$T_{2h} d_{2h} = 4 \\left(0, 0, \\frac{1}{12}, -\\frac{1}{6}, \\frac{1}{12}, 0, 0\\right)^T = \\left(0, 0, \\frac{1}{3}, -\\frac{2}{3}, \\frac{1}{3}, 0, 0\\right)^T$$\n设 $b_c$ 为右端项。我们注意到 $b_c = \\frac{1}{3}(e_3 - 2e_4 + e_5)$，其中 $e_j$ 是 $\\mathbb{R}^7$ 中的基向量。\n我们求解 $T_{2h} d_{2h} = b_c$。让我们尝试设 $d_{2h} = c \\cdot e_4$，其中 $c$ 为某个常数。\n$$T_{2h} (c \\cdot e_4) = c(-e_3 + 2e_4 - e_5) = -c(e_3 - 2e_4 + e_5)$$\n将其与 $b_c = \\frac{1}{3}(e_3 - 2e_4 + e_5)$ 比较，我们得到 $-c = \\frac{1}{3}$，所以 $c = -\\frac{1}{3}$。\n精确的粗网格校正量为 $d_{2h} = -\\frac{1}{3}e_4 = (0, 0, 0, -\\frac{1}{3}, 0, 0, 0)^T$。\n\n**步骤 3：延长和校正**\n\n使用线性插值 $P$ 将粗网格校正量 $d_{2h}$ 延长回细网格：\n$$d_h = P d_{2h} = P \\left(-\\frac{1}{3}e_4\\right) = -\\frac{1}{3} (P e_4)$$\n向量 $P e_4$ 是延长矩阵的第 4 列。它对应于从一个在索引 $j=4$ 处为 $1$、其他地方为 $0$ 的粗网格向量进行插值。\n该值被注入到相应的细网格点 $i=2j = 8$ 处：$(P e_4)_8 = 1$。\n在奇数索引的细网格点上的值通过插值得到：\n$(P e_4)_7 = \\frac{1}{2}((d_{2h})_3 + (d_{2h})_4) = \\frac{1}{2}(0+1) = \\frac{1}{2}$。\n$(P e_4)_9 = \\frac{1}{2}((d_{2h})_4 + (d_{2h})_5) = \\frac{1}{2}(1+0) = \\frac{1}{2}$。\n所以，$P e_4 = \\frac{1}{2}e_7 + e_8 + \\frac{1}{2}e_9$。\n细网格校正量为：\n$$d_h = -\\frac{1}{3}\\left(\\frac{1}{2}e_7 + e_8 + \\frac{1}{2}e_9\\right) = -\\frac{1}{6}e_7 - \\frac{1}{3}e_8 - \\frac{1}{6}e_9$$\n具体来说，$d_h = (0,0,0,0,0,0, -\\frac{1}{6}, -\\frac{1}{3}, -\\frac{1}{6}, 0,0,0,0,0,0)^T$。这个量就是 $P d_{2h}$。\n\n后平滑前的校正误差为 $e^{(1,\\mathrm{cc})} = e^{(1)} + d_h$。\n$$e^{(1,\\mathrm{cc})} = \\left(\\frac{1}{3}e_7 + \\frac{1}{3}e_8 + \\frac{1}{3}e_9\\right) + \\left(-\\frac{1}{6}e_7 - \\frac{1}{3}e_8 - \\frac{1}{6}e_9\\right)$$\n$$e^{(1,\\mathrm{cc})} = \\left(\\frac{1}{3}-\\frac{1}{6}\\right)e_7 + \\left(\\frac{1}{3}-\\frac{1}{3}\\right)e_8 + \\left(\\frac{1}{3}-\\frac{1}{6}\\right)e_9 = \\frac{1}{6}e_7 + \\frac{1}{6}e_9$$\n校正后的误差为 $e^{(1,\\mathrm{cc})} = (0,0,0,0,0,0, \\frac{1}{6}, 0, \\frac{1}{6}, 0,0,0,0,0,0)^T$。\n\n**步骤 4：后平滑和最终误差**\n\n对 $e^{(1,\\mathrm{cc})}$ 应用一次后平滑步骤（加权雅可比，$\\omega=2/3$）。经过一个 V-循环后的最终误差 $e^{(V)}$ 为：\n$$e^{(V)} = S e^{(1,\\mathrm{cc})} = \\left(I - \\frac{1}{3}T\\right) e^{(1,\\mathrm{cc})} = e^{(1,\\mathrm{cc})} - \\frac{1}{3}T e^{(1,\\mathrm{cc})}$$\n$$e^{(1,\\mathrm{cc})} = \\frac{1}{6}(e_7+e_9)$$\n$$T e^{(1,\\mathrm{cc})} = \\frac{1}{6} T(e_7+e_9) = \\frac{1}{6}((-e_6+2e_7-e_8) + (-e_8+2e_9-e_{10}))$$\n$$T e^{(1,\\mathrm{cc})} = \\frac{1}{6}(-e_6+2e_7-2e_8+2e_9-e_{10})$$\n现在，我们计算 $e^{(V)}$：\n$$e^{(V)} = \\frac{1}{6}(e_7+e_9) - \\frac{1}{3}\\left(\\frac{1}{6}(-e_6+2e_7-2e_8+2e_9-e_{10})\\right)$$\n$$e^{(V)} = \\frac{1}{6}(e_7+e_9) - \\frac{1}{18}(-e_6+2e_7-2e_8+2e_9-e_{10})$$\n合并每个基向量的项：\n\\begin{align*} e_6:  \\quad \\frac{1}{18} \\\\ e_7:  \\quad \\frac{1}{6} - \\frac{2}{18} = \\frac{3}{18} - \\frac{2}{18} = \\frac{1}{18} \\\\ e_8:  \\quad \\frac{2}{18} = \\frac{1}{9} \\\\ e_9:  \\quad \\frac{1}{6} - \\frac{2}{18} = \\frac{1}{18} \\\\ e_{10}: \\quad \\frac{1}{18} \\end{align*}\n经过一个 V-循环后的最终误差为：\n$$e^{(V)} = \\frac{1}{18}e_6 + \\frac{1}{18}e_7 + \\frac{2}{18}e_8 + \\frac{1}{18}e_9 + \\frac{1}{18}e_{10} = \\frac{1}{18}(e_6 + e_7 + 2e_8 + e_9 + e_{10})$$\n\n**步骤 5：误差范数比**\n\n最后，我们计算比值 $\\|e^{(V)}\\|_2 / \\|e^{(0)}\\|_2$。\n我们知道 $\\|e^{(0)}\\|_2 = 1$。\n最终误差的范数平方为：\n$$\\|e^{(V)}\\|_2^2 = \\left(\\frac{1}{18}\\right)^2 (1^2 + 1^2 + 2^2 + 1^2 + 1^2) = \\frac{1}{18^2}(1+1+4+1+1) = \\frac{8}{18^2}$$\n范数为：\n$$\\|e^{(V)}\\|_2 = \\sqrt{\\frac{8}{18^2}} = \\frac{\\sqrt{8}}{18} = \\frac{2\\sqrt{2}}{18} = \\frac{\\sqrt{2}}{9}$$\n最终误差范数与初始误差范数的比值为：\n$$\\frac{\\|e^{(V)}\\|_2}{\\|e^{(0)}\\|_2} = \\frac{\\sqrt{2}/9}{1} = \\frac{\\sqrt{2}}{9}$$\n这个值表示对于此特定初始误差，经过一个 V-循环后的误差缩减因子。", "answer": "$$\\boxed{\\frac{\\sqrt{2}}{9}}$$", "id": "3235102"}, {"introduction": "多重网格方法的有效性源于一种“分而治之”的策略，其中光滑子和粗网格校正扮演着互补的角色。这个思想实验 [@problem_id:3235139] 挑战了一个直观的观念，即迭代求解器的每个组件本身都必须是收敛的。通过分析一个发散的光滑子是否能构成一个收敛的多重网格方法，您将对光滑性质有更深刻的理解，并认识到它仅要求光滑子对高频误差有效。", "problem": "考虑求解一个对称正定线性系统 $A u = f$，该系统由在均匀网格上使用狄利克雷边界条件的泊松方程的标准有限差分离散化产生。令 $A$ 表示刚度矩阵，加权雅可比迭代由迭代矩阵 $S = I - \\omega D^{-1} A$ 定义，其中 $D$ 是 $A$ 的对角部分，$\\omega$ 是松弛参数。对于某些 $\\omega$ 的选择，例如 $\\omega = 2.0$，独立的加权雅可比迭代是发散的，即谱半径 $\\rho(S) > 1$。\n\n一个几何双网格方法由一个限制算子 $R$、一个延拓算子 $P$ 和由 Galerkin 公式 $A_c = R A P$ 给出的粗网格算子构成。一个带有一个前平滑步骤和一个后平滑步骤的 V-循环可以在双网格层面上由误差传播算子建模\n$$\nE_{\\mathrm{TG}} = S \\,\\bigl(I - P A_c^{-1} R A\\bigr)\\, S,\n$$\n其中 $I - P A_c^{-1} R A$ 是粗网格校正。\n\n经典的双网格收敛理论区分了一个低频子空间 $\\mathcal{L} = \\mathrm{range}(P)$（可在粗网格上表示的误差）及其 $A$-正交补空间 $\\mathcal{H}$（高频误差），并断言该方法收敛，如果：\n- 粗网格校正在 $\\mathcal{L}$ 上是准确的（逼近性质）。\n- 平滑子在 $\\mathcal{H}$ 上是严格压缩的（平滑性质）。\n\n问题：确定以下关于在几何多重网格 V-循环中使用一个作为独立迭代发散的逐点平滑子（例如，$\\omega = 2.0$ 的加权雅可比）的陈述中，哪一个是正确的。\n\nA. 是的。即使独立平滑子是发散的，V-循环仍然可以收敛，前提是平滑子在高频子空间 $\\mathcal{H}$ 上是严格压缩的，并且粗网格校正能准确地消除低频子空间 $\\mathcal{L}$ 中的误差。这正是平滑加逼近的机制。\n\nB. 不是。如果在整个空间上 $\\rho(S) > 1$，那么任何使用 $S$ 的 V-循环都必须发散，因为粗网格校正不能改变谱半径，并且实际上与 $S$ 可交换。\n\nC. 是的，但仅当转移算子不是基于 Galerkin 的。使用 $A_c = R A P$ 会使粗网格校正在低频子空间上成为一个恒等算子，因此当平滑子发散时会阻止收敛。\n\nD. 对于标准的泊松问题，使用线性插值/延拓和完全加权限制，将 $\\omega = 2.0$ 的加权雅可比同时用作前平滑子和后平滑子会产生一个一致收敛的 V-循环，因为 $\\omega = 2.0$ 能最大程度地衰减最高频率的模式。\n\n选择所有正确的选项。你的推理应从迭代矩阵、双网格误差传播算子以及分解为 $\\mathcal{L}$ 和 $\\mathcal{H}$ 的定义开始，并且不应假设超出这些定义的任何特定快捷公式。确保任何关于收敛或发散的主张都通过算子如何作用于 $\\mathcal{L}$ 和 $\\mathcal{H}$ 来证明。", "solution": "用户希望我验证一个关于几何多重网格方法的问题陈述，然后提供一个详细的解决方案来评估给定的选项。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n- 线性系统是 $A u = f$，其中 $A$ 是对称正定（SPD）的，来自于在均匀网格上使用狄利克雷边界条件的泊松方程的有限差分离散化。\n- 平滑子是加权雅可比迭代，迭代矩阵为 $S = I - \\omega D^{-1} A$，其中 $D$ 是 $A$ 的对角部分。\n- 考虑了一个特殊情况，其中独立平滑子是发散的，即谱半径 $\\rho(S) > 1$，例如当 $\\omega = 2.0$ 时。\n- 一个几何双网格方法由一个限制算子 $R$、一个延拓算子 $P$ 和一个粗网格算子 $A_c = R A P$（Galerkin 公式）构成。\n- 带有一个前平滑和一个后平滑步骤的 V-循环的双网格误差传播算子是 $E_{\\mathrm{TG}} = S \\,(I - P A_c^{-1} R A)\\, S$。\n- 粗网格校正算子是 $C = I - P A_c^{-1} R A$。\n- 经典的收敛理论使用将向量空间分解为一个低频子空间 $\\mathcal{L} = \\mathrm{range}(P)$ 及其 $A$-正交补空间，即高频子空间 $\\mathcal{H}$。\n- 该理论断言，如果两个性质成立，则方法收敛：\n    1. **逼近性质**：粗网格校正在 $\\mathcal{L}$ 上是准确的。\n    2. **平滑性质**：平滑子在 $\\mathcal{H}$ 上是严格压缩的。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题牢固地植根于偏微分方程数值方法的标准理论，特别是几何多重网格方法。所有术语——泊松方程、有限差分、加权雅可比、Galerkin 粗网格算子、双网格循环、误差传播以及高/低频子空间的分解——在该领域都是标准且明确定义的。\n- **适定性：** 该问题是适定的。它要求基于一个明确定义的理论框架来评估几个陈述。通过对照多重网格理论的原则分析所提供的陈述，可以得出一个明确的答案。\n- **客观性：** 语言是技术性的、精确的，并且没有主观内容。\n- **不完整或矛盾的设置：** 该设置是自洽和一致的。加权雅可比迭代可能发散（即 $\\rho(S) > 1$）的前提是正确的。例如，对于一维泊松问题，$D^{-1}A$ 的特征值在 $(0, 2)$ 区间内。平滑子 $S$ 的特征值是 $1 - \\omega\\lambda(D^{-1}A)$。如果 $\\omega$ 选择得足够大（例如，$\\omega > 2/\\lambda_{min}$），那么 $|1-\\omega \\lambda_{min}| > 1$，导致发散。双网格算子和理论框架的描述是标准的。\n\n**步骤3：结论与行动**\n问题陈述是**有效的**。它提出了一个关于多重网格收敛机制的标准且概念上重要的问题。我现在将进行求解。\n\n### 推导与逐项分析\n\n多重网格方法的核心原理是使用不同的机制来消除误差的不同分量。误差被分解为低频（光滑）分量和高频（振荡）分量。\n\n1. **在低频（$\\mathcal{L}$）上的粗网格校正：** 粗网格校正旨在处理低频误差分量，这些分量在粗网格上是“可见”的。算子为 $C = I - P A_c^{-1} R A$。对于低频子空间 $\\mathcal{L} = \\mathrm{range}(P)$ 中的误差向量 $e_L$，我们可以写成 $e_L = P e_c$，其中 $e_c$ 是某个粗网格向量。使用 Galerkin 算子 $A_c = R A P$ 应用粗网格校正得到：\n    $$C e_L = (I - P (R A P)^{-1} R A) (P e_c) = P e_c - P (R A P)^{-1} (R A P) e_c = P e_c - P e_c = 0$$\n    这表明，根据构造，粗网格校正能完全消除低频子空间 $\\mathcal{L}$ 中的任何误差。这就是问题中提到的“逼近性质”。\n\n2. **在高频（$\\mathcal{H}$）上的平滑子：** 平滑子的作用是减少高频误差分量，这些分量在粗网格上表示不佳，因此无法由粗网格校正有效处理。“平滑性质”要求平滑子在子空间 $\\mathcal{H}$ 上充当一个压缩映射。也就是说，对于某个范数 $\\|\\cdot\\|$，我们需要对所有 $e_H \\in \\mathcal{H}$ 都有 $\\|S e_H\\| \\le \\eta \\|e_H\\|$，其中平滑因子 $\\eta  1$。对于 SPD 问题，此分析通常在能量范数或 $A$-范数中进行，定义为 $\\|v\\|_A = \\sqrt{v^T A v}$。\n\n整个 V-循环的收敛性取决于这两个部分的成功相互作用。它*不*要求平滑子在整个空间上是一个收敛的方法（即 $\\rho(S)  1$）。平滑子可以在低频模式上发散，因为这些模式本应由粗网格校正来消除。\n\n一个关键问题是，一个平滑子在满足平滑性质（在 $\\mathcal{H}$ 上是压缩的）的同时，是否可能具有 $\\rho(S) > 1$。是的，这是可能的。谱半径 $\\rho(S)$ 由 $S$ 在整个空间上的作用决定。平滑性质是关于 $S$ 在子空间 $\\mathcal{H}$ 上的行为的一个条件。一个特征值幅度大于1的 $S$ 的特征向量可能存在，导致 $\\rho(S)>1$，但这个特征向量可能主要位于低频子空间 $\\mathcal{L}$ 中，而不是在 $\\mathcal{H}$ 中。因此，“$\\rho(S) > 1$” 和 “$S$ 在 $\\mathcal{H}$ 上是压缩的”这两个条件不是相互排斥的。\n\n现在，我们来评估每个选项。\n\n**A. 是的。即使独立平滑子是发散的，V-循环仍然可以收敛，前提是平滑子在高频子空间 $\\mathcal{H}$ 上是严格压缩的，并且粗网格校正能准确地消除低频子空间 $\\mathcal{L}$ 中的误差。这正是平滑加逼近的机制。**\n\n这个陈述准确地描述了多重网格收敛的基本原理。它正确地指出，平滑子作为独立方法的收敛性（即 $\\rho(S)1$）不是必需的。相反，重要的是平滑子在高频子空间上的性能（平滑性质）以及粗网格校正在低频子空间上的性能（逼近性质）。这两种性质的结合正是使多重网格方法有效的原因。该陈述是对该理论的正确而简洁的总结。\n\n**结论：正确。**\n\n**B. 不是。如果在整个空间上 $\\rho(S) > 1$，那么任何使用 $S$ 的 V-循环都必须发散，因为粗网格校正不能改变谱半径，并且实际上与 $S$ 可交换。**\n\n这个陈述是错误的。它否定了选项 A 中阐述的基本原理。其提供的推理在多个方面也存在缺陷：\n- “粗网格校正不能改变谱半径”：什么的谱半径？最终 V-循环算子的谱半径是 $\\rho(E_{TG})=\\rho(SCS)$，这与 $\\rho(S)$ 没有简单的关系。算子 $C$ 是一个投影，可以极大地改变谱。\n- “实际上与 $S$ 可交换”：这是错误的。通常情况下，$SC \\neq CS$。这两个算子不可交换，它们的顺序至关重要。如果平滑子发散，V-循环就必定发散这一主要论点是一个常见的误解，它忽略了平滑子和粗网格校正的互补作用。\n\n**结论：错误。**\n\n**C. 是的，但仅当转移算子不是基于 Galerkin 的。使用 $A_c = R A P$ 会使粗网格校正在低频子空间上成为一个恒等算子，因此当平滑子发散时会阻止收敛。**\n\n该陈述的推理基于一个错误的前提。如上所述，使用 Galerkin 算子 $A_c = R A P$ 会使粗网格校正算子 $C = I - P A_c^{-1} R A$ 在低频子空间 $\\mathcal{L}$ 上等于*零*算子，而不是恒等算子。它完美地消除了 $\\mathcal{L}$ 中的误差。这是逼近性质所要求的理想行为，而不是收敛的障碍。因为其推理从根本上是错误的，所以整个陈述无效。\n\n**结论：错误。**\n\n**D. 对于标准的泊松问题，使用线性插值/延拓和完全加权限制，将 $\\omega = 2.0$ 的加权雅可比同时用作前平滑子和后平滑子会产生一个一致收敛的 V-循环，因为 $\\omega = 2.0$ 能最大程度地衰减最高频率的模式。**\n\n这个陈述包含一个具体的主张和一个理由。让我们先分析这个理由。对于一维泊松问题，$D^{-1}A$ 的特征值是 $\\lambda_k = 1 - \\cos(k \\pi h)$，其中 $h$ 是网格尺寸。平滑子 $S$ 的特征值是 $\\mu_k = 1 - \\omega \\lambda_k$。高频模式对应于大的 $k$，此时 $\\lambda_k \\approx 2$。当 $\\omega = 2.0$ 时，这些高频模式的特征值约为 $\\mu_k \\approx 1 - 2.0 \\times 2 = -3$。-3 的特征值表示显著的*放大*，而不是衰减。衰减高频的最佳选择是 $\\omega \\approx 2/3$（在一维情况下），它试图平衡不同高频模式的放大。因此，“因为 $\\omega = 2.0$ 能最大程度地衰减最高频率的模式”这一理由在事实上是错误的。\n\n现在来看主张本身。由于 $\\omega=2.0$ 的平滑子会放大高频误差，它违反了平滑性质。标准分析表明该方法不会收敛。对于最高频率的“锯齿”模式（标准粗网格校正对此模式是盲目的），误差在前平滑步骤中乘以 $\\mu_N \\approx -3$，在后平滑步骤中再次乘以该值，导致在每个 V-循环中乘以 $(\\mu_N)^2 \\approx 9$。因此，该方法是强发散的。\n\n**结论：错误。**", "answer": "$$\\boxed{A}$$", "id": "3235139"}, {"introduction": "逐点光滑子虽然简单，但在问题表现出强烈的方向各向异性时会失效，而这在物理和工程仿真中是常见情况。这个动手编程练习 [@problem_id:3235026] 要求您实现一个更鲁棒的线-雅可比光滑子，它通过隐式耦合网格线上的未知数来有效抑制强耦合方向上的误差。通过构建和测试此光滑子，您将学会如何在实际的多重网格应用中诊断和克服挑战。", "problem": "您需要为一个定义在矩形网格上的二维各向异性椭圆算子实现一个线雅可比（line-Jacobi）光滑子，该光滑子适用于几何多重网格方法。该光滑子应沿着网格线进行独立的三对角求解，以处理方向各向异性。您的程序必须计算几种指定场景下的残差缩减因子，并将所有结果以逗号分隔列表的形式单行输出，并用方括号括起来。\n\n考虑单位正方形域 $[0,1] \\times [0,1]$ 上的各向异性泊松型算子，其边界条件为齐次狄利克雷（Dirichlet）边界条件 $u=0$ on $\\partial \\Omega$。在一个均匀的内部网格上， $x$ 方向有 $n_x$ 个点， $y$ 方向有 $n_y$ 个点，设网格间距为 $h_x = \\frac{1}{n_x+1}$ 和 $h_y = \\frac{1}{n_y+1}$。对于正常数系数 $a_x > 0$ 和 $a_y > 0$，算子 $A$ 应用于内部点 $(i,j)$ 处的网格函数 $u$ 的标准5点有限差分离散为\n$$\n(Au)_{i,j} \\;=\\; \\frac{a_x}{h_x^2}\\left(2u_{i,j} - u_{i-1,j} - u_{i+1,j}\\right) \\;+\\; \\frac{a_y}{h_y^2}\\left(2u_{i,j} - u_{i,j-1} - u_{i,j+1}\\right),\n$$\n由于狄利克雷边界条件，内部区域外的边界邻近点被视为零。\n\n为在保持边界条件的同时获得一个非平凡的右端项，使用在内部网格点 $(x_i, y_j) = (i h_x, j h_y)$ 处采样的构造内部解 $u_{\\text{true}}(x,y) = \\sin(\\pi x)\\sin(\\pi y)$。通过将相同的离散算子应用于 $u_{\\text{true}}$ 来定义离散右端项 $f$，即 $f = A u_{\\text{true}}$。\n\n定义迭代值 $u$ 的残差向量为 $r = f - A u$。线雅可比光滑子是一种块雅可比方法，其中每个块对应于一条直网格线上的所有未知数。对于沿 $x$ 方向（行）的光滑，将每个固定的 $j$ 的块矩阵 $D_x$ 定义为关于索引 $i$ 的常系数三对角系统：对角线元素为 $b_x = \\frac{2a_x}{h_x^2} + \\frac{2a_y}{h_y^2}$，非对角线元素为 $c_x = -\\frac{a_x}{h_x^2}$。对于沿 $y$ 方向（列）的光滑，将每个固定的 $i$ 的块矩阵 $D_y$ 定义为关于索引 $j$ 的三对角系统，其对角线元素为 $b_y = \\frac{2a_y}{h_y^2} + \\frac{2a_x}{h_x^2}$，非对角线元素为 $c_y = -\\frac{a_y}{h_y^2}$。线雅可比更新公式为\n$$\nu^{(k+1)} \\;=\\; u^{(k)} \\;+\\; p^{(k)}, \\quad \\text{其中} \\quad D \\, p^{(k)} \\;=\\; r^{(k)} \\;=\\; f - A u^{(k)},\n$$\n其中 $D$ 表示 $D_x$ 或 $D_y$，具体取决于所选的线方向。每个块求解都是一个三对角系统，必须使用直接三对角求解器精确求解该线上的 $p$。\n\n实现以下组件：\n- 计算内部网格点上的 $u_{\\text{true}}$，然后使用上述离散算子计算 $f = A u_{\\text{true}}$。\n- 实现一个函数，将离散算子 $A$ 应用于任何内部网格函数 $u$。\n- 实现线雅可比光滑子，对于指定的平滑步数 $ \\nu$，通过求解沿行（$x$线）或列（$y$线）的独立三对角系统来执行更新 $u \\leftarrow u + p$，其中使用从当前迭代值形成的残差。这是一个真正的块雅可比方法：在求解任何块之前，从当前的 $u$ 组装残差 $r$，并用它们各自的解 $p$ 同时更新所有块。\n- 为每条线实现一个用于常系数三对角系统的稳定直接求解器（Thomas算法）。\n\n将 $u^{(0)}$ 初始化为内部网格上的零向量。执行 $\\nu$ 次光滑步骤后，计算残差缩减因子\n$$\n\\rho \\;=\\; \\frac{\\|r^{(\\nu)}\\|_2}{\\|r^{(0)}\\|_2},\n$$\n其中 $\\|\\cdot\\|_2$ 表示欧几里得范数，且 $r^{(k)} = f - A u^{(k)}$。\n\n测试套件：\n对以下每个参数集 $(n_x,n_y,a_x,a_y,\\nu,\\text{direction})$ 计算 $\\rho$，其中 $\\text{direction}$ 为 $x$ 或 $y$，表示逐行或逐列的线雅可比光滑：\n- 案例 1: $(32, 32, 1, 1, 4, x)$。\n- 案例 2: $(64, 64, 1000, 1, 4, x)$。\n- 案例 3: $(64, 64, 1, 1000, 4, x)$。\n- 案例 4: $(64, 64, 1, 1000, 4, y)$。\n- 案例 5: $(3, 3, 500, 1, 2, x)$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含五个案例的结果，形式为一个由方括号括起来的逗号分隔的浮点数列表，每个浮点数四舍五入到六位小数（例如，$[0.123456,0.234567,0.345678,0.456789,0.567890]$）。不应打印任何其他文本。此问题不涉及角度或物理单位。", "solution": "用户提供的问题已被分析并验证为偏微分方程数值方法领域内一个适定且科学上合理的任务。本解答将介绍一个用于二维各向异性椭圆算子的线雅可比光滑子的设计与实现。\n\n### 1. 问题阐述\n\n我们考虑单位正方形 $\\Omega = [0,1] \\times [0,1]$ 上的各向异性泊松型方程，其边界条件为齐次狄利克雷边界条件（在 $\\partial\\Omega$ 上 $u=0$）。其控制偏微分方程为：\n$$\n-\\nabla \\cdot (K \\nabla u) = f_{\\text{cont}} \\quad \\text{其中} \\quad K = \\begin{pmatrix} a_x  0 \\\\ 0  a_y \\end{pmatrix}\n$$\n其中 $a_x > 0$ 和 $a_y > 0$ 为正常数系数。\n\n定义一个均匀网格，在 $x$ 和 $y$ 方向上分别有 $n_x$ 和 $n_y$ 个内部点。网格间距为 $h_x = \\frac{1}{n_x+1}$ 和 $h_y = \\frac{1}{n_y+1}$。内部网格点为 $(x_i, y_j) = (i h_x, j h_y)$，其中 $i=1,\\dots,n_x$ 且 $j=1,\\dots,n_y$。\n\n使用标准的5点有限差分格式，将连续算子离散化，得到一个线性方程组 $A u = f$。离散算子 $A$ 在内部点 $(i, j)$ 对网格函数 $u$ 的作用由下式给出：\n$$\n(Au)_{i,j} = \\frac{a_x}{h_x^2}(2u_{i,j} - u_{i-1,j} - u_{i+1,j}) + \\frac{a_y}{h_y^2}(2u_{i,j} - u_{i,j-1} - u_{i,j+1})\n$$\n网格函数 $u$ 表示为一个 $n_y \\times n_x$ 矩阵，其中 $u_{j,i}$ 对应于点 $(x_i, y_j)$ 处的值。边界值的处理方法是：将任何索引在内部域之外的 $u_{k,l}$ 设为0。\n\n### 2. 构造解法\n\n为了建立一个具有已知解的适定问题，我们使用构造解法。我们选择一个满足齐次边界条件的解析内部解 $u_{\\text{true}}$：\n$$\nu_{\\text{true}}(x,y) = \\sin(\\pi x)\\sin(\\pi y)\n$$\n然后通过将离散算子 $A$ 应用于 $u_{\\text{true}}$ 的网格函数表示来“构造”右端向量 $f$：\n$$\nf = A u_{\\text{true}}\n$$\n这确保了 $u_{\\text{true}}$ 是离散系统 $Au = f$ 的精确解。\n\n### 3. 线雅可比光滑子\n\n线雅可比光滑子是求解 $Au=f$ 的一种迭代方法。它是一种特殊的块雅可比方法，其中每个块对应于一条网格线（行或列）上的所有未知数。从第 $k$ 步到第 $k+1$ 步的迭代更新由下式给出：\n$$\nu^{(k+1)} = u^{(k)} + p^{(k)}\n$$\n其中 $p^{(k)}$ 是校正向量。该校正是通过求解从残差 $r^{(k)} = f - A u^{(k)}$ 导出的简化系统来计算的：\n$$\nD p^{(k)} = r^{(k)}\n$$\n矩阵 $D$ 是一个块对角矩阵，其中每个块对应一条线。 $A$ 的所有非块对角项（不同线之间的耦合）都进行显式处理。\n\n#### 3.1. $x$方向光滑（逐行）\n对于沿水平线的光滑，矩阵 $D$（记为 $D_x$）耦合了每行内的所有未知数。对于给定的行 $j$，我们求解一个独立的系统以获得校正向量 $p_{j,:}^{(k)}$。相应的系统是一个大小为 $n_x \\times n_x$ 的三对角线性系统。根据规定，每行的三对角矩阵 $T_x$ 具有：\n- 对角线元素：$b_x = \\frac{2a_x}{h_x^2} + \\frac{2a_y}{h_y^2}$\n- 非对角线元素：$c_x = -\\frac{a_x}{h_x^2}$\n第 $j$ 行的系统为 $T_x p_{j,:}^{(k)} = r_{j,:}^{(k)}$。\n\n#### 3.2. $y$方向光滑（逐列）\n对于沿垂直线的光滑，矩阵 $D$（记为 $D_y$）耦合了每列内的所有未知数。对于给定的列 $i$，我们求解一个独立的系统以获得校正向量 $p_{:,i}^{(k)}$。相应的系统是一个大小为 $n_y \\times n_y$ 的三对角线性系统。每列的三对角矩阵 $T_y$ 具有：\n- 对角线元素：$b_y = \\frac{2a_x}{h_x^2} + \\frac{2a_y}{h_y^2}$\n- 非对角线元素：$c_y = -\\frac{a_y}{h_y^2}$\n第 $i$ 列的系统为 $T_y p_{:,i}^{(k)} = r_{:,i}^{(k)}$。\n\n### 4. 三对角系统求解器：Thomas算法\n\n每个逐线系统都是三对角的。由于算子系数 $a_x$ 和 $a_y$ 为正，所得到的三对角矩阵 $T_x$ 和 $T_y$ 是严格对角占优的。此类系统可以使用Thomas算法高效且稳定地求解，该算法是高斯消元法的一种特殊形式。对于一个系统 $T\\mathbf{x} = \\mathbf{d}$，其中 $T$ 的次对角线为 $a$，主对角线为 $b$，超对角线为 $c$（在我们的案例中均为常数），该算法包括一个前向消元过程和一个后向代入过程。\n\n### 5. 算法与评估\n\n每个测试案例的总体算法如下：\n1.  初始化网格参数 $(n_x, n_y)$、算子系数 $(a_x, a_y)$、迭代次数 $\\nu$ 和光滑方向。\n2.  计算网格间距 $h_x, h_y$ 并创建网格。\n3.  计算 $u_{\\text{true}}$，然后计算右端项 $f = A u_{\\text{true}}$。\n4.  将解的迭代初始值设为零：$u^{(0)} = \\mathbf{0}$。\n5.  计算初始残差 $r^{(0)} = f - A u^{(0)} = f$ 及其欧几里得范数 $\\|r^{(0)}\\|_2$。\n6.  执行 $\\nu$ 次光滑迭代。在从 $0$ 到 $\\nu-1$ 的每次迭代 $k$ 中：\n    a. 计算当前残差 $r^{(k)} = f - A u^{(k)}$。\n    b. 根据指定方向，（概念上）并行求解所有线的三对角系统以获得校正向量 $p^{(k)}$。具体来说，对于每条线，提取 $r^{(k)}$ 的相应子向量，并使用Thomas算法求解三对角系统，以得到 $p^{(k)}$ 的子向量。\n    c. 更新解：$u^{(k+1)} = u^{(k)} + p^{(k)}$。\n7.  经过 $\\nu$ 次迭代后，计算最终残差 $r^{(\\nu)} = f - A u^{(\\nu)}$ 及其范数 $\\|r^{(\\nu)}\\|_2$。\n8.  计算残差缩减因子 $\\rho = \\frac{\\|r^{(\\nu)}\\|_2}{\\|r^{(0)}\\|_2}$。\n\n线光滑子的有效性关键取决于各向异性与光滑方向之间的关系。当沿强耦合方向（即系数与网格间距平方之比较大的方向）进行光滑时，预计其效果会非常好。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef _thomas_solver(a, b, c, d):\n    \"\"\"\n    Solves a constant-coefficient tridiagonal system Tx = d.\n\n    Args:\n        a (float): Sub-diagonal element.\n        b (float): Main-diagonal element.\n        c (float): Super-diagonal element.\n        d (np.ndarray): Right-hand side vector.\n\n    Returns:\n        np.ndarray: The solution vector x.\n    \"\"\"\n    n = len(d)\n    if n == 0:\n        return np.array([])\n    \n    c_prime = np.zeros(n)\n    d_prime = np.zeros(n)\n    \n    # Forward elimination\n    # T is guaranteed to be strictly diagonally dominant, so b != 0\n    # and (b - a * c_prime[i-1]) != 0\n    c_prime[0] = c / b\n    d_prime[0] = d[0] / b\n    \n    for i in range(1, n):\n        denom = b - a * c_prime[i - 1]\n        c_prime[i] = c / denom\n        d_prime[i] = (d[i] - a * d_prime[i - 1]) / denom\n\n    # Backward substitution\n    x = np.zeros(n)\n    x[-1] = d_prime[-1]\n    \n    for i in range(n - 2, -1, -1):\n        x[i] = d_prime[i] - c_prime[i] * x[i + 1]\n        \n    return x\n\ndef _apply_operator_A(u, hx, hy, ax, ay):\n    \"\"\"\n    Applies the 5-point discrete operator A to a grid function u.\n    Homogeneous Dirichlet boundary conditions are assumed.\n\n    Args:\n        u (np.ndarray): The interior grid function (shape ny x nx).\n        hx (float): Grid spacing in x.\n        hy (float): Grid spacing in y.\n        ax (float): Anisotropy coefficient in x.\n        ay (float): Anisotropy coefficient in y.\n\n    Returns:\n        np.ndarray: The result of A*u (shape ny x nx).\n    \"\"\"\n    ny, nx = u.shape\n    u_padded = np.zeros((ny + 2, nx + 2))\n    u_padded[1:-1, 1:-1] = u\n    \n    # Central difference for the second derivative in x\n    laplacian_x = (2 * u - u_padded[1:-1, :-2] - u_padded[1:-1, 2:]) / (hx**2)\n    \n    # Central difference for the second derivative in y\n    laplacian_y = (2 * u - u_padded[:-2, 1:-1] - u_padded[2:, 1:-1]) / (hy**2)\n    \n    return ax * laplacian_x + ay * laplacian_y\n\ndef _compute_reduction_factor(nx, ny, ax, ay, nu, direction):\n    \"\"\"\n    Computes the residual reduction factor for a line-Jacobi smoother.\n    \"\"\"\n    hx = 1.0 / (nx + 1)\n    hy = 1.0 / (ny + 1)\n\n    # Set up grid and manufactured solution\n    x_coords = np.linspace(hx, 1.0 - hx, nx)\n    y_coords = np.linspace(hy, 1.0 - hy, ny)\n    xx, yy = np.meshgrid(x_coords, y_coords)  # xx, yy have shape (ny, nx)\n\n    u_true = np.sin(np.pi * xx) * np.sin(np.pi * yy)\n    \n    # Compute right-hand side f = A * u_true\n    f = _apply_operator_A(u_true, hx, hy, ax, ay)\n\n    # Initialize solution u\n    u = np.zeros((ny, nx))\n\n    # Initial residual r^(0) = f - A*u^(0) = f, since u^(0)=0\n    norm_r0 = np.linalg.norm(f)\n    if norm_r0 == 0:\n        return 0.0\n\n    # Perform nu smoothing steps\n    for _ in range(nu):\n        r = f - _apply_operator_A(u, hx, hy, ax, ay)\n        p = np.zeros_like(u)\n\n        diag_val = 2 * ax / hx**2 + 2 * ay / hy**2\n        \n        if direction == 'x':\n            offdiag_val = -ax / hx**2\n            for j in range(ny):\n                d_vec = r[j, :]\n                p[j, :] = _thomas_solver(offdiag_val, diag_val, offdiag_val, d_vec)\n        elif direction == 'y':\n            offdiag_val = -ay / hy**2\n            for i in range(nx):\n                d_vec = r[:, i]\n                p[:, i] = _thomas_solver(offdiag_val, diag_val, offdiag_val, d_vec)\n\n        u += p\n\n    # Compute final residual and reduction factor\n    r_nu = f - _apply_operator_A(u, hx, hy, ax, ay)\n    norm_r_nu = np.linalg.norm(r_nu)\n\n    return norm_r_nu / norm_r0\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (32, 32, 1, 1, 4, 'x'),        # Case 1\n        (64, 64, 1000, 1, 4, 'x'),     # Case 2\n        (64, 64, 1, 1000, 4, 'x'),     # Case 3\n        (64, 64, 1, 1000, 4, 'y'),     # Case 4\n        (3, 3, 500, 1, 2, 'x'),        # Case 5\n    ]\n\n    results = []\n    for case in test_cases:\n        nx, ny, ax, ay, nu, direction = case\n        rho = _compute_reduction_factor(nx, ny, ax, ay, nu, direction)\n        results.append(rho)\n\n    # Format output as a comma-separated list rounded to 6 decimal places\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3235026"}]}