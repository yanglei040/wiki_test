{"hands_on_practices": [{"introduction": "这项练习旨在让您亲手实践CP分解的基本定义。您将通过编程从其组成的秩-1分量（因子矩阵）构建一个张量，然后通过将张量展开成矩阵来逆转该过程。通过验证这些展开矩阵的属性（例如它们的秩）与理论预测相符，您将具体地理解张量、其因子及其矩阵化表示之间的关系 [@problem_id:3282221]。", "problem": "给定正整数 $I$、$J$、$K$ 和 $R$，请从第一性原理出发，构造一个三阶张量 $X \\in \\mathbb{R}^{I \\times J \\times K}$，其CP秩根据定义恰好为 $R$。CP分解将一个张量表示为有限个秩-1外积之和。根据定义，一个三模态的秩-1张量是三个非零向量的外积。具体来说，如果对于 $r \\in \\{1,\\dots,R\\}$，有 $a_r \\in \\mathbb{R}^{I}$、$b_r \\in \\mathbb{R}^{J}$ 和 $c_r \\in \\mathbb{R}^{K}$，那么张量\n$$\nX \\;=\\; \\sum_{r=1}^{R} \\; a_r \\circ b_r \\circ c_r\n$$\n是一个最多包含 $R$ 项的CP表示，其中外积 $a_r \\circ b_r \\circ c_r$ 的元素为\n$$\n\\left(a_r \\circ b_r \\circ c_r\\right)_{i,j,k} \\;=\\; a_{r,i}\\, b_{r,j}\\, c_{r,k}, \\quad \\text{for } i \\in \\{1,\\dots,I\\}, \\; j \\in \\{1,\\dots,J\\}, \\; k \\in \\{1,\\dots,K\\}.\n$$\n您的任务是编写一个完整的程序，在给定一小组参数集 $(I,J,K,R)$ 和用于确保可复现性的种子的情况下，对每个参数集执行以下操作：\n\n1) 生成因子矩阵 $A \\in \\mathbb{R}^{I \\times R}$、$B \\in \\mathbb{R}^{J \\times R}$ 和 $C \\in \\mathbb{R}^{K \\times R}$，其元素为从标准正态分布中抽取的独立同分布样本，并使用提供的随机种子以确保可复现性。然后，严格遵循上述定义，通过对 $A$、$B$ 和 $C$ 的列所隐含的 $R$ 个秩-1外积求和来构成张量 $X$。\n\n2) 仅使用张量沿某一模态进行矩阵化（也称展开）的核心定义，将 $X$ 实现为模-1、模-2和模-3展开，分别得到矩阵 $X_{(1)} \\in \\mathbb{R}^{I \\times (JK)}$、$X_{(2)} \\in \\mathbb{R}^{J \\times (IK)}$ 和 $X_{(3)} \\in \\mathbb{R}^{K \\times (IJ)}$。展开操作应通过按字典序排列 $X$ 的元素来构建，这与常规定义一致，即所选模态的索引保留为行索引，其余索引合并为列索引。从 $(i,j,k)$ 到线性列索引的精确映射在您的展开和折叠操作中必须是自洽的。\n\n3) 从第一性原理出发，使用 $A$、$B$ 和 $C$ 推导出一个由外积定义所隐含的、$X$ 在模-1下的代数等价矩阵化表达式，并利用该表达式将所得矩阵折叠回一个与您所选展开定义一致的三维数组，从而重构张量 $\\widehat{X}$。计算残差的弗罗贝尼乌斯范数\n$$\n\\| X - \\widehat{X} \\|_F \\;=\\; \\sqrt{ \\sum_{i=1}^{I} \\sum_{j=1}^{J} \\sum_{k=1}^{K} \\left( X_{i,j,k} - \\widehat{X}_{i,j,k} \\right)^2 }.\n$$\n将此残差报告为浮点数。一个正确实现的推导必须产生一个接近 $0$ 的残差，误差在数值舍入范围内。\n\n4) 计算每个展开矩阵 $X_{(1)}$、$X_{(2)}$ 和 $X_{(3)}$ 的数值矩阵秩（使用奇异值分解 (SVD) 这一经过充分测试的数值方法）。使用标准的数值秩判据：如果矩阵 $M$ 的奇异值为 $\\sigma_1 \\ge \\sigma_2 \\ge \\cdots$，则数值秩是大于某个容差的奇异值的数量，其中一个安全的容差为\n$$\n\\tau \\;=\\; \\max\\{m,n\\} \\,\\varepsilon \\,\\sigma_1,\n$$\n对于一个 $m \\times n$ 矩阵 $M$ 和双精度算术的机器精度 $\\varepsilon$。将每个秩报告为整数。\n\n测试套件。按此确切顺序，对以下参数集运行您的程序。对于每种情况，按指定设置随机种子。仅在第四种情况中，在对随机因子进行采样后，将 $A$、$B$ 和 $C$ 各自的第二列替换为第一列（从而创建一个两个秩-1项变得相同的依赖列边缘情况）：\n- 情况 1：$(I,J,K,R) = (4,5,6,3)$，种子为 $101$。\n- 情况 2：$(I,J,K,R) = (3,3,3,1)$，种子为 $202$。\n- 情况 3：$(I,J,K,R) = (5,4,4,6)$，种子为 $303$。\n- 情况 4：$(I,J,K,R) = (3,4,2,2)$，种子为 $404$，并进行上述的依赖列修改。\n\n对于每种情况，生成一个包含四个输出的元组：\n- 弗罗贝尼乌斯残差 $\\|X - \\widehat{X}\\|_F$（浮点数）。\n- $X_{(1)}$ 的数值秩（整数）。\n- $X_{(2)}$ 的数值秩（整数）。\n- $X_{(3)}$ 的数值秩（整数）。\n\n最终输出格式。您的程序应生成单行输出，其中包含四个情况的结果，形式为一个由四个四元素列表组成的逗号分隔列表，不含空格，并用方括号括起来，例如：\n$$\n\\text{print } [[r_{1},r_{2},r_{3},r_{4}],\\,[r_{1},r_{2},r_{3},r_{4}],\\,[r_{1},r_{2},r_{3},r_{4}],\\,[r_{1},r_{2},r_{3},r_{4}]].\n$$\n您的程序不得读取任何输入。此问题中没有物理单位。所有角度（若有使用）必须以弧度为单位。所有分数必须以小数形式报告，而非百分比。", "solution": "此问题被评估为**有效**。这是一个适定、科学上合理且客观的问题，源于张量分解的数值方法领域。所有定义和参数都已明确说明，从而能够得出唯一且可复现的解。这些任务要求对典型多项式 (CP) 分解、张量展开（矩阵化）、Khatri-Rao 积以及数值秩计算有基本的理解，这些都是数值与科学计算中的标准概念。\n\n解决方案如问题中所述，分四个阶段进行：\n1. 从其 CP 因子构造一个三阶张量。\n2. 实现所有三个模态的张量展开。\n3. 从矩阵化表示重构张量，以验证代数等价性。\n4. 计算已展开张量的数值矩阵秩。\n\n**1. 从CP分解构造张量**\n\n一个三阶张量 $X \\in \\mathbb{R}^{I \\times J \\times K}$ 是基于给定的典型多项式 (CP) 秩 $R$ 构造的。该张量定义为 $R$ 个秩-1张量之和：\n$$\nX = \\sum_{r=1}^{R} a_r \\circ b_r \\circ c_r\n$$\n向量 $a_r \\in \\mathbb{R}^{I}$、$b_r \\in \\mathbb{R}^{J}$ 和 $c_r \\in \\mathbb{R}^{K}$ 分别是三个因子矩阵 $A \\in \\mathbb{R}^{I \\times R}$、$B \\in \\mathbb{R}^{J \\times R}$ 和 $C \\in \\mathbb{R}^{K \\times R}$ 的列。这些矩阵的元素从标准正态分布中生成，并使用指定的种子以保证可复现性。张量 $X$ 的元素级定义为：\n$$\nX_{i,j,k} = \\sum_{r=1}^{R} A_{i,r} B_{j,r} C_{k,r}\n$$\n其中 $i \\in \\{0, \\dots, I-1\\}$、$j \\in \\{0, \\dots, J-1\\}$ 和 $k \\in \\{0, \\dots, K-1\\}$（为与实现保持一致，使用0基索引）。这个求和过程可以使用爱因斯坦求和约定高效实现，例如通过 `numpy.einsum('ir,jr,kr->ijk', A, B, C)`。\n\n**2. 张量展开（矩阵化）**\n\n展开或矩阵化，是将张量元素重排成矩阵的过程。张量的模-n 展开将沿模 n 的纤维（fiber）排列为结果矩阵的列。然而，题目要求将所选模态的索引保留为行索引。对于一个三阶张量 $X \\in \\mathbb{R}^{I \\times J \\times K}$：\n\n- **模-1 展开**：$X_{(1)} \\in \\mathbb{R}^{I \\times (JK)}$。元素 $X_{i,j,k}$ 映射到条目 $(X_{(1)})_{i,p}$，其中 $p$ 是对应于对 $(j,k)$ 的线性索引。我们采用标准的字典序，其中最后一个索引变化最快（C风格排序），因此 $p = j \\cdot K + k$。这通过重塑张量来实现。\n- **模-2 展开**：$X_{(2)} \\in \\mathbb{R}^{J \\times (IK)}$。元素 $X_{i,j,k}$ 映射到 $(X_{(2)})_{j,p}$，其中 $p = i \\cdot K + k$。这通过首先将张量维度从 $(I,J,K)$ 转置为 $(J,I,K)$，然后重塑来实现。\n- **模-3 展开**：$X_{(3)} \\in \\mathbb{R}^{K \\times (IJ)}$。元素 $X_{i,j,k}$ 映射到 $(X_{(3)})_{k,p}$，其中 $p = i \\cdot J + j$。这通过将维度转置为 $(K,I,J)$ 并重塑来实现。\n\n**3. CP表示的矩阵化与重构**\n\nCP分解的一个基本性质是其在矩阵化形式下的简洁表示。$X$ 的模-1展开可以表示为：\n$$\nX_{(1)} = A (B \\odot C)^T\n$$\n这里，$\\odot$ 表示Khatri-Rao积，它是一种列向的克罗内克积。矩阵 $B \\odot C \\in \\mathbb{R}^{(JK) \\times R}$ 的第 $r$ 列是 $B$ 和 $C$ 的第 $r$ 列的克罗内克积，即 $(B \\odot C)_{:,r} = b_r \\otimes c_r$。此公式与我们选择的展开约定（列索引为 $p=jK+k$）是一致的。\n\n为验证我们的实现，我们首先计算矩阵化形式 $\\widehat{X}_{(1)} = A (B \\odot C)^T$。然后，我们将这个矩阵“折叠”回一个大小为 $I \\times J \\times K$ 的张量 $\\widehat{X}$。这个折叠操作是展开的逆过程，通过将 $\\widehat{X}_{(1)}$ 重塑为维度 $(I, J, K)$ 来完成。最后，我们计算残差的弗罗贝尼乌斯范数 $\\|X - \\widehat{X}\\|_F$。一个正确实现的过程将得到一个接近机器精度的残差，从而证实代数等价性。\n\n**4. 数值秩计算**\n\n矩阵的数值秩是通过计算其大于指定容差的奇异值的数量来确定的。奇异值通过奇异值分解 (SVD) 获得。对于一个 $m \\times n$ 矩阵 $M$，其奇异值为 $\\sigma_1 \\ge \\sigma_2 \\ge \\dots$，容差由 $\\tau = \\max\\{m,n\\} \\cdot \\varepsilon \\cdot \\sigma_1$ 给出，其中 $\\varepsilon$ 是双精度浮点数的机器精度。数值秩是满足 $\\sigma_i > \\tau$ 的奇异值 $\\sigma_i$ 的数量。\n\n对于一个由具有 $R$ 个线性无关分量（对于随机生成的因子，此条件以概率1成立）的CP分解构造的张量 $X$，其模-n 展开的秩由 $\\text{rank}(X_{(n)}) = \\min(\\text{dim}_n, R)$ 给出，其中 $\\text{dim}_n$ 是模 n 的维度。因此，我们期望 $\\text{rank}(X_{(1)}) = \\min(I, R)$、$\\text{rank}(X_{(2)}) = \\min(J, R)$ 和 $\\text{rank}(X_{(3)}) = \\min(K, R)$。在情况4中，两个分量被故意设为相同，从而将张量的有效秩降至 $1$。因此，所有展开的数值秩预计都为 $1$。", "answer": "```python\nimport numpy as np\n\ndef construct_tensor(A, B, C):\n    \"\"\"\n    Constructs a 3rd-order tensor from its CP factor matrices.\n    X_ijk = sum_r A_ir * B_jr * C_kr\n    \"\"\"\n    return np.einsum('ir,jr,kr->ijk', A, B, C)\n\ndef unfold(tensor, mode):\n    \"\"\"\n    Unfolds a 3rd-order tensor into a matrix.\n    mode 0: I x (JK)\n    mode 1: J x (IK)\n    mode 2: K x (IJ)\n    \"\"\"\n    if mode == 0:\n        return tensor.reshape(tensor.shape[0], -1)\n    if mode == 1:\n        return np.transpose(tensor, (1, 0, 2)).reshape(tensor.shape[1], -1)\n    if mode == 2:\n        return np.transpose(tensor, (2, 0, 1)).reshape(tensor.shape[2], -1)\n    raise ValueError(\"Mode must be 0, 1, or 2.\")\n\ndef fold(matrix, mode, shape):\n    \"\"\"\n    Folds a matrix back into a 3rd-order tensor.\n    This is the inverse of the unfold operation.\n    \"\"\"\n    I, J, K = shape\n    if mode == 0:\n        return matrix.reshape((I, J, K))\n    if mode == 1:\n        return np.transpose(matrix.reshape((J, I, K)), (1, 0, 2))\n    if mode == 2:\n        return np.transpose(matrix.reshape((K, I, J)), (2, 0, 1))\n    raise ValueError(\"Mode must be 0, 1, or 2.\")\n\ndef khatri_rao(A, B):\n    \"\"\"\n    Computes the Khatri-Rao product of two matrices A and B.\n    This is a column-wise Kronecker product.\n    If A is (I, R) and B is (J, R), the result is (I*J, R).\n    The r-th column of the result is kron(A[:,r], B[:,r]).\n    \"\"\"\n    if A.shape[1] != B.shape[1]:\n        raise ValueError(\"Matrices must have the same number of columns.\")\n    \n    # Efficient implementation using Einstein summation and reshaping.\n    # einsum produces a tensor T of shape (I, J, R) where T[i,j,r] = A[i,r] * B[j,r].\n    # Reshaping to (I*J, R) flattens the first two dimensions, with the second\n    # index (j) varying fastest, which corresponds to the Kronecker product.\n    return np.einsum('ir,jr->ijr', A, B).reshape(A.shape[0] * B.shape[0], A.shape[1])\n\ndef numerical_rank(matrix):\n    \"\"\"\n    Computes the numerical rank of a matrix using SVD.\n    \"\"\"\n    if matrix.size == 0 or np.all(matrix==0):\n        return 0\n        \n    m, n = matrix.shape\n    s = np.linalg.svd(matrix, compute_uv=False)\n    \n    if s[0] == 0:\n        return 0\n\n    eps = np.finfo(float).eps\n    tolerance = max(m, n) * eps * s[0]\n    \n    return np.sum(s > tolerance)\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    test_cases = [\n        {'I': 4, 'J': 5, 'K': 6, 'R': 3, 'seed': 101, 'mod': False},\n        {'I': 3, 'J': 3, 'K': 3, 'R': 1, 'seed': 202, 'mod': False},\n        {'I': 5, 'J': 4, 'K': 4, 'R': 6, 'seed': 303, 'mod': False},\n        {'I': 3, 'J': 4, 'K': 2, 'R': 2, 'seed': 404, 'mod': True},\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        I, J, K, R, seed, mod = case['I'], case['J'], case['K'], case['R'], case['seed'], case['mod']\n        \n        # 1. Generate factor matrices and construct the tensor X\n        np.random.seed(seed)\n        A = np.random.randn(I, R)\n        B = np.random.randn(J, R)\n        C = np.random.randn(K, R)\n        \n        if mod:\n            # Special modification for Case 4\n            A[:, 1] = A[:, 0]\n            B[:, 1] = B[:, 0]\n            C[:, 1] = C[:, 0]\n            \n        X = construct_tensor(A, B, C)\n\n        # 2. Unfold X along all three modes\n        X1 = unfold(X, 0)\n        X2 = unfold(X, 1)\n        X3 = unfold(X, 2)\n\n        # 3. Reconstruct X from matricized form and compute residual\n        # The unfolding convention used (last index fastest) corresponds to X_1 = A (B \\odot C)^T\n        KR_BC = khatri_rao(B, C)\n        X1_hat_mat = A @ KR_BC.T\n        X_hat = fold(X1_hat_mat, 0, (I, J, K))\n        residual = np.linalg.norm(X - X_hat)\n\n        # 4. Compute numerical ranks of unfoldings\n        rank1 = numerical_rank(X1)\n        rank2 = numerical_rank(X2)\n        rank3 = numerical_rank(X3)\n        \n        all_results.append((residual, rank1, rank2, rank3))\n\n    # Format the final output string as specified\n    formatted_results = []\n    for res_tuple in all_results:\n        # Use repr() for the float to get a standard, high-precision representation\n        s = f\"[{repr(res_tuple[0])},{res_tuple[1]},{res_tuple[2]},{res_tuple[3]}]\"\n        formatted_results.append(s)\n        \n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3282221"}, {"introduction": "矩阵的秩在从实数域扩展到复数域时保持不变，但张量的秩并非如此。本练习通过一个经典例子来探讨这种微妙而深刻的区别，揭示当底层域从实数（$\\mathbb{R}$）扩展到复数（$\\mathbb{C}$）时，张量的秩实际上可能会降低。通过分析一个特定的 $2 \\times 2 \\times 2$ 张量及其相关的矩阵束，您将揭示这种现象发生的原因，并对张量秩的代数复杂性有更深入的理解 [@problem_id:3282140]。", "problem": "设一个三阶张量 $\\mathcal{T} \\in \\mathbb{F}^{2 \\times 2 \\times 2}$ 由其沿第三个模态的正面切片表示，记为 $\\mathbf{A}$ 和 $\\mathbf{B}$，因此，对于一个CP表示 $\\mathcal{T} = \\sum_{p=1}^{r} \\mathbf{u}_{p} \\otimes \\mathbf{v}_{p} \\otimes \\mathbf{w}_{p}$，其切片满足 $\\mathbf{A} = \\sum_{p=1}^{r} w_{p,1}\\,\\mathbf{u}_{p}\\mathbf{v}_{p}^{\\top}$ 和 $\\mathbf{B} = \\sum_{p=1}^{r} w_{p,2}\\,\\mathbf{u}_{p}\\mathbf{v}_{p}^{\\top}$，其中 $\\mathbf{u}_{p}, \\mathbf{v}_{p} \\in \\mathbb{F}^{2}$ 且 $\\mathbf{w}_{p} = \\begin{pmatrix} w_{p,1} \\\\ w_{p,2} \\end{pmatrix} \\in \\mathbb{F}^{2}$，$\\mathbb{F}$ 表示一个域。张量 $\\mathcal{T}$ 在域 $\\mathbb{F}$ 上的CP秩，记作 $\\operatorname{rank}_{\\mathbb{F}}(\\mathcal{T})$，是使得这种表示存在的最小整数 $r$，其中所有元素都在 $\\mathbb{F}$ 中。\n\n考虑一个特定的张量 $\\mathcal{T} \\in \\mathbb{R}^{2 \\times 2 \\times 2}$，其正面切片为\n$$\n\\mathbf{A} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}, \n\\qquad\n\\mathbf{B} = \\begin{pmatrix} 0  -1 \\\\ 1  0 \\end{pmatrix}.\n$$\n仅从CP秩的定义、秩-1矩阵的性质以及关于 $2 \\times 2$ 矩阵束的基本事实出发，完成以下任务：\n\n- 确定在 $\\mathbb{R}$ 上表示 $\\mathcal{T}$ 所需的秩-1外积的最小数量 $r_{\\mathbb{R}}$，以及在 $\\mathbb{C}$ 上所需的最小数量 $r_{\\mathbb{C}}$。\n- 显式地构造一个在 $\\mathbb{C}$ 上实现 $r_{\\mathbb{C}}$ 的 $\\mathcal{T}$ 的CP分解，以及一个证明 $r_{\\mathbb{R}} \\leq 3$ 的实数CP分解。\n- 通过分析矩阵束 $\\mathbf{A} + x \\mathbf{B}$ 以及当 $x$ 在基域中变化时秩下降的发生情况，证明 $r_{\\mathbb{R}} \\neq 2$。\n\n最后，报告单个数值\n$$\n\\Delta \\;=\\; r_{\\mathbb{R}} - r_{\\mathbb{C}}.\n$$\n无需四舍五入。将 $\\Delta$ 作为单个数字提供。", "solution": "该问题要求确定一个特定的三阶张量 $\\mathcal{T} \\in \\mathbb{R}^{2 \\times 2 \\times 2}$ 在实数域 ($\\mathbb{R}$) 和复数域 ($\\mathbb{C}$) 上的典范多项式（CP）秩。张量 $\\mathcal{T}$ 由其正面切片 $\\mathbf{A} = \\mathcal{T}(:,:,1)$ 和 $\\mathbf{B} = \\mathcal{T}(:,:,2)$ 定义，具体如下：\n$$\n\\mathbf{A} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix}, \\qquad \\mathbf{B} = \\begin{pmatrix} 0  -1 \\\\ 1  0 \\end{pmatrix}\n$$\n在域 $\\mathbb{F}$ 上的CP秩，记作 $\\operatorname{rank}_{\\mathbb{F}}(\\mathcal{T})$，是最小的整数 $r$，使得 $\\mathcal{T}$ 可以写成 $r$ 个秩-1张量的和：$\\mathcal{T} = \\sum_{p=1}^{r} \\mathbf{u}_{p} \\otimes \\mathbf{v}_{p} \\otimes \\mathbf{w}_{p}$，其中 $\\mathbf{u}_{p}, \\mathbf{v}_{p}, \\mathbf{w}_{p}$ 的元素属于 $\\mathbb{F}$。这些切片是秩-1矩阵 $\\mathbf{M}_p = \\mathbf{u}_{p}\\mathbf{v}_{p}^{\\top}$ 的线性组合：\n$$\n\\mathbf{A} = \\sum_{p=1}^{r} w_{p,1}\\,\\mathbf{M}_p, \\qquad \\mathbf{B} = \\sum_{p=1}^{r} w_{p,2}\\,\\mathbf{M}_p\n$$\n其中 $\\mathbf{w}_p = \\begin{pmatrix} w_{p,1} \\\\ w_{p,2} \\end{pmatrix}$。\n\n分析一个大小为 $I_1 \\times I_2 \\times 2$ 的三维张量的CP秩的一个基本工具是矩阵束，它是由一个标量 $x$ 参数化的一族矩阵。对于给定的张量，我们构造矩阵束 $\\mathbf{P}(x) = \\mathbf{A} + x\\mathbf{B}$：\n$$\n\\mathbf{P}(x) = \\begin{pmatrix} 1  0 \\\\ 0  1 \\end{pmatrix} + x\\begin{pmatrix} 0  -1 \\\\ 1  0 \\end{pmatrix} = \\begin{pmatrix} 1  -x \\\\ x  1 \\end{pmatrix}\n$$\n如果 $\\mathcal{T}$ 的CP秩为 $r$，则 $\\mathbf{P}(x) = \\sum_{p=1}^{r} (w_{p,1} + x w_{p,2}) \\mathbf{M}_p$。矩阵束的秩最多为 $r$。当 $x$ 的值使 $\\mathbf{P}(x)$ 奇异时，其秩会下降。对于一个 $2 \\times 2$ 矩阵，当其行列式为零时发生这种情况。\n$$\n\\det(\\mathbf{P}(x)) = \\det\\begin{pmatrix} 1  -x \\\\ x  1 \\end{pmatrix} = (1)(1) - (-x)(x) = 1 + x^2\n$$\n使秩下降的 $x$ 值是特征方程 $\\det(\\mathbf{P}(x))=0$ 的根。\n\n首先，我们可以确定秩的一个下界。一个秩-1张量 $\\mathcal{T} = \\mathbf{u} \\otimes \\mathbf{v} \\otimes \\mathbf{w}$ 将意味着两个切片 $\\mathbf{A} = w_1 \\mathbf{u}\\mathbf{v}^\\top$ 和 $\\mathbf{B} = w_2 \\mathbf{u}\\mathbf{v}^\\top$ 都是秩-1矩阵（或零矩阵）。然而，切片 $\\mathbf{A}$ 是单位矩阵 $\\mathbf{I}$，其秩为 2。因此，对于任何域 $\\mathbb{F}$，都有 $\\operatorname{rank}_{\\mathbb{F}}(\\mathcal{T}) \\geq 2$。\n\n**在复数域 $\\mathbb{C}$ 上的分析**\n我们寻求找到在 $\\mathbb{C}$ 上表示 $\\mathcal{T}$ 所需的秩-1项的最小数量 $r_{\\mathbb{C}}$。特征方程为 $1+x^2=0$。在复数域中，该方程有两个不同的根：\n$$\nx_1 = i, \\quad x_2 = -i\n$$\n存在两个不同的根，使得矩阵束的秩降为 1，这对于秩为 2 是一个必要条件，而对于 $2 \\times 2 \\times 2$ 的张量，这也是一个充分条件。由于我们知道秩至少为 2，我们得出结论 $r_{\\mathbb{C}} = \\operatorname{rank}_{\\mathbb{C}}(\\mathcal{T}) = 2$。\n\n为了构造分解，我们使用在这些使秩下降的 $x$ 值处形成的矩阵：\n$\\mathbf{P}(i) = \\mathbf{A} + i\\mathbf{B} = \\begin{pmatrix} 1  -i \\\\ i  1 \\end{pmatrix}$\n$\\mathbf{P}(-i) = \\mathbf{A} - i\\mathbf{B} = \\begin{pmatrix} 1  i \\\\ -i  1 \\end{pmatrix}$\n这些矩阵是秩-1的。我们可以将 $\\mathbf{A}$ 和 $\\mathbf{B}$ 表示为它们的线性组合：\n$$\n\\mathbf{A} = \\frac{1}{2}(\\mathbf{P}(i) + \\mathbf{P}(-i)), \\qquad \\mathbf{B} = \\frac{1}{2i}(\\mathbf{P}(i) - \\mathbf{P}(-i)) = -\\frac{i}{2}\\mathbf{P}(i) + \\frac{i}{2}\\mathbf{P}(-i)\n$$\n令 $\\mathbf{M}_1 = \\mathbf{P}(i)$ 和 $\\mathbf{M}_2 = \\mathbf{P}(-i)$。我们将它们分解为外积：\n$\\mathbf{M}_1 = \\begin{pmatrix} 1  -i \\\\ i  1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ i \\end{pmatrix}\\begin{pmatrix} 1  -i \\end{pmatrix}$。令 $\\mathbf{u}_1 = \\begin{pmatrix} 1 \\\\ i \\end{pmatrix}$ 且 $\\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ -i \\end{pmatrix}$。\n$\\mathbf{M}_2 = \\begin{pmatrix} 1  i \\\\ -i  1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -i \\end{pmatrix}\\begin{pmatrix} 1  i \\end{pmatrix}$。令 $\\mathbf{u}_2 = \\begin{pmatrix} 1 \\\\ -i \\end{pmatrix}$ 且 $\\mathbf{v}_2 = \\begin{pmatrix} 1 \\\\ i \\end{pmatrix}$。\n\n将 $\\mathbf{A}$ 和 $\\mathbf{B}$ 的表达式与一般形式进行比较，我们确定系数 $w_{p,k}$：\n$\\mathbf{A} = \\frac{1}{2}\\mathbf{M}_1 + \\frac{1}{2}\\mathbf{M}_2 \\implies w_{1,1} = \\frac{1}{2}, w_{2,1} = \\frac{1}{2}$。\n$\\mathbf{B} = -\\frac{i}{2}\\mathbf{M}_1 + \\frac{i}{2}\\mathbf{M}_2 \\implies w_{1,2} = -\\frac{i}{2}, w_{2,2} = \\frac{i}{2}$。\n秩-2复数CP分解的因子向量是：\n$$\n\\mathbf{u}_1 = \\begin{pmatrix} 1 \\\\ i \\end{pmatrix}, \\mathbf{v}_1 = \\begin{pmatrix} 1 \\\\ -i \\end{pmatrix}, \\mathbf{w}_1 = \\begin{pmatrix} 1/2 \\\\ -i/2 \\end{pmatrix}\n$$\n$$\n\\mathbf{u}_2 = \\begin{pmatrix} 1 \\\\ -i \\end{pmatrix}, \\mathbf{v}_2 = \\begin{pmatrix} 1 \\\\ i \\end{pmatrix}, \\mathbf{w}_2 = \\begin{pmatrix} 1/2 \\\\ i/2 \\end{pmatrix}\n$$\n\n**在实数域 $\\mathbb{R}$ 上的分析**\n我们现在确定在 $\\mathbb{R}$ 上的秩 $r_{\\mathbb{R}}$。特征方程 $1+x^2=0$ 在 $\\mathbb{R}$ 中没有解。这意味着对于任何 $x \\in \\mathbb{R}$，都有 $1+x^2 \\ge 1$，因此 $\\det(\\mathbf{A}+x\\mathbf{B})$ 永不为零。因此，对于所有 $x \\in \\mathbb{R}$，矩阵束 $\\mathbf{A}+x\\mathbf{B}$ 的秩都为 2。\n\n我们来证明 $r_{\\mathbb{R}} \\neq 2$。假设存在一个秩-2的实数分解（用于反证）：$\\mathcal{T} = \\sum_{p=1}^2 \\mathbf{u}_p \\otimes \\mathbf{v}_p \\otimes \\mathbf{w}_p$，其中因子向量都是实数。这意味着 $\\mathbf{A} + x\\mathbf{B} = (w_{1,1}+xw_{1,2})\\mathbf{u}_1\\mathbf{v}_1^\\top + (w_{2,1}+xw_{2,2})\\mathbf{u}_2\\mathbf{v}_2^\\top$。\n向量 $\\mathbf{w}_1$ 和 $\\mathbf{w}_2$ 必须是线性无关的，否则 $\\mathbf{A}$ 和 $\\mathbf{B}$ 将是线性相关的，而这是错误的（$\\mathbf{A}=\\mathbf{I}$ 是对称的，$\\mathbf{B}$ 是斜对称的）。如果 $\\mathbf{w}_1, \\mathbf{w}_2$ 线性无关，那么多项式 $(w_{1,1}+xw_{1,2})$ 和 $(w_{2,1}+xw_{2,2})$ 也线性无关。必须存在一个实数 $x$ 使这些系数中至少有一个为零。例如，如果 $w_{1,2} \\neq 0$，那么 $x = -w_{1,1}/w_{1,2}$ 是一个使第一个系数为零的实根。在这个 $x$ 值下，矩阵束 $\\mathbf{A}+x\\mathbf{B}$ 将成为秩-1矩阵 $\\mathbf{u}_2\\mathbf{v}_2^\\top$ 的一个倍数，因此其秩最多为 1。这与我们发现的对于所有实数 $x$，$\\mathbf{A}+x\\mathbf{B}$ 的秩始终为 2 相矛盾。因此，关于秩-2实数分解的假设是错误的，即 $r_{\\mathbb{R}} \\neq 2$。\n\n由于 $r_{\\mathbb{R}} \\geq 2$ 且 $r_{\\mathbb{R}} \\neq 2$，我们必然有 $r_{\\mathbb{R}} \\geq 3$。我们现在证明存在一个在 $\\mathbb{R}$ 上的秩-3分解，这将确定 $r_{\\mathbb{R}} = 3$。我们需要找到三个实秩-1矩阵 $\\mathbf{M}_1, \\mathbf{M}_2, \\mathbf{M}_3$，使得 $\\mathbf{A}$ 和 $\\mathbf{B}$ 都在它们的生成空间内。我们选择两个简单的秩-1矩阵，它们的和是 $\\mathbf{A}$：\n$$\n\\mathbf{M}_1 = \\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix}, \\quad \\mathbf{M}_2 = \\begin{pmatrix} 0  0 \\\\ 0  1 \\end{pmatrix}\n$$\n那么 $\\mathbf{A} = \\mathbf{M}_1 + \\mathbf{M}_2$。我们可以将 $\\mathbf{A}$ 的分解系数写为 $w_{1,1}=1, w_{2,1}=1, w_{3,1}=0$。$\\mathbf{B}$ 的分解将是 $\\mathbf{B} = w_{1,2}\\mathbf{M}_1 + w_{2,2}\\mathbf{M}_2 + w_{3,2}\\mathbf{M}_3$。这意味着矩阵 $\\mathbf{B} - w_{1,2}\\mathbf{M}_1 - w_{2,2}\\mathbf{M}_2$ 必须是一个秩-1矩阵（$\\mathbf{M}_3$ 的一个倍数）。我们来计算这个矩阵：\n$$\n\\begin{pmatrix} 0  -1 \\\\ 1  0 \\end{pmatrix} - w_{1,2}\\begin{pmatrix} 1  0 \\\\ 0  0 \\end{pmatrix} - w_{2,2}\\begin{pmatrix} 0  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} -w_{1,2}  -1 \\\\ 1  -w_{2,2} \\end{pmatrix}\n$$\n为使该矩阵为秩-1，其行列式必须为零：\n$(-w_{1,2})(-w_{2,2}) - (-1)(1) = 0 \\implies w_{1,2}w_{2,2} + 1 = 0$。\n我们可以选择满足此条件的任何实数值，例如，$w_{1,2}=1$ 和 $w_{2,2}=-1$。通过这个选择，秩-1矩阵变为：\n$$\n\\mathbf{M}'_3 = \\begin{pmatrix} -1  -1 \\\\ 1  1 \\end{pmatrix}\n$$\n我们将其设为我们的第三个秩-1分量，由 $w_{3,2}$ 缩放，所以令 $w_{3,2}=1$ 且 $\\mathbf{M}_3 = \\mathbf{M}'_3$。\n线性组合是：\n$\\mathbf{A} = 1 \\cdot \\mathbf{M}_1 + 1 \\cdot \\mathbf{M}_2 + 0 \\cdot \\mathbf{M}_3$\n$\\mathbf{B} = 1 \\cdot \\mathbf{M}_1 - 1 \\cdot \\mathbf{M}_2 + 1 \\cdot \\mathbf{M}_3$\n我们现在可以写出这个秩-3实数CP分解的因子向量：\n$\\mathbf{M}_1 = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 1  0 \\end{pmatrix} \\implies \\mathbf{u}_1=\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\mathbf{v}_1=\\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$。\n$\\mathbf{M}_2 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 0  1 \\end{pmatrix} \\implies \\mathbf{u}_2=\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\mathbf{v}_2=\\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。\n$\\mathbf{M}_3 = \\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix} \\begin{pmatrix} 1  1 \\end{pmatrix} \\implies \\mathbf{u}_3=\\begin{pmatrix} -1 \\\\ 1 \\end{pmatrix}, \\mathbf{v}_3=\\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n因子 $\\mathbf{w}_p$ 由系数给出：\n$\\mathbf{w}_1 = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$，$\\mathbf{w}_2 = \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix}$，$\\mathbf{w}_3 = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$。\n这个显式构造证明了 $r_{\\mathbb{R}} \\leq 3$。由于我们已经证明了 $r_{\\mathbb{R}} \\geq 3$，我们得出结论 $r_{\\mathbb{R}} = 3$。\n\n最后，我们计算所要求的差值 $\\Delta$：\n$$\n\\Delta = r_{\\mathbb{R}} - r_{\\mathbb{C}} = 3 - 2 = 1.\n$$", "answer": "$$\n\\boxed{1}\n$$", "id": "3282140"}, {"introduction": "张量分解不仅是理论上的构造，它们也是现实世界数据分析的强大工具，尤其是在处理不完整数据集时。这项高级练习要求您实现一种算法，为含有缺失项的张量寻找CP分解，这个问题被称为张量补全。通过使用交替优化方案最小化加权最小二乘目标函数，您将开发一种实用的数据插补方法，并亲身体验张量模型如何从稀疏数据中提取有意义的结构 [@problem_id:3282166]。", "problem": "您必须在 Python 中实现一个完整的、可运行的程序，该程序通过最小化加权最小二乘 (WLS) 目标函数，计算含缺失数据的规范多元 (CP) 分解。其数学基础始于 CP 分解的核心定义和加权最小二乘目标函数。设张量是一个 $N$ 阶数组 $ \\mathcal{X} \\in \\mathbb{R}^{I_0 \\times I_1 \\times \\cdots \\times I_{N-1}} $，CP 分解将 $ \\mathcal{X} $ 近似为 $R$ 个秩-1 分量的和。该近似由下式给出：\n$$\n\\mathcal{\\hat{X}}[i_0,i_1,\\dots,i_{N-1}] = \\sum_{r=1}^{R} \\prod_{n=0}^{N-1} A^{(n)}[i_n, r],\n$$\n其中 $ A^{(n)} \\in \\mathbb{R}^{I_n \\times R} $ 是因子矩阵。加权最小二乘目标函数（其中权重 $ W[i_0,\\dots,i_{N-1}] \\in \\{0,1\\} $ 表示缺失 ($0$) 或观测 ($1$) 的条目）为：\n$$\n\\min_{\\{A^{(n)}\\}} \\; \\sum_{i_0=0}^{I_0-1} \\cdots \\sum_{i_{N-1}=0}^{I_{N-1}-1} W[i_0,\\dots,i_{N-1}] \\, \\left( \\mathcal{X}[i_0,\\dots,i_{N-1}] - \\mathcal{\\hat{X}}[i_0,\\dots,i_{N-1}] \\right)^2.\n$$\n您必须从第一性原理出发，设计一种科学上合理且数值上可靠的优化方法。使用针对因子矩阵的交替块坐标下降法，其中每个子问题都作为一个带有 $ \\ell_2 $ 正则化项 $ \\lambda = 10^{-6} $ 的加权最小二乘问题来求解，以确保数值稳定性。您必须避免使用问题陈述中的任何捷径公式；您使用的所有更新规则都应从所述目标函数中一致地推导出来。当某个模态中一整行的权重均为零时，您必须实现鲁棒的处理方式，例如保持该行不变或将其设置为零，以确保在这种退化情况下的行为是明确定义的。\n\n实现所需的定义：\n- 设两个矩阵 $ U \\in \\mathbb{R}^{I \\times R} $ 和 $ V \\in \\mathbb{R}^{J \\times R} $ 的 Khatri-Rao 积是列式 Kronecker 积 $ U \\odot V \\in \\mathbb{R}^{(I J) \\times R} $。\n- 设 $ \\mathcal{X} $ 的模-$n$ 展开是矩阵 $ X_{(n)} \\in \\mathbb{R}^{I_n \\times \\prod_{m \\neq n} I_m} $，该矩阵通过置换轴使得模态 $n$ 成为第一个维度，并按特定、一致的顺序展平其余轴而得到。您必须在所有模态中使用一致的展开方案，并使其与其余因子矩阵的相应 Khatri-Rao 积顺序相匹配。\n\n您的程序必须为以下测试套件实现上述优化方法。每个测试用例通过对给定因子矩阵的外积求和并添加具有指定标准差 $ \\sigma $ 和随机种子的高斯噪声来构造一个合成张量。然后，形成一个二元权重张量 $ W $，在指定的缺失索引处为零，在其他地方为一。CP-WLS 算法必须以等于生成秩的秩 $ R $ 运行 $ T = 200 $ 次迭代，$ \\lambda = 10^{-6} $，并使用指定的种子对因子矩阵进行固定的随机初始化。拟合后，计算观测均方根误差 (RMSE)，定义为\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{ \\sum_{i_0,\\dots,i_{N-1}} W[i_0,\\dots,i_{N-1}] \\, \\left( \\mathcal{X}[i_0,\\dots,i_{N-1}] - \\mathcal{\\hat{X}}[i_0,\\dots,i_{N-1}] \\right)^2 }{ \\sum_{i_0,\\dots,i_{N-1}} W[i_0,\\dots,i_{N-1}] } }.\n$$\n返回每个测试用例的 RMSE。\n\n测试套件规范：\n\n- 案例 $1$ (正常路径，含部分缺失条目):\n  - 阶数 $N = 3$，维度 $ (I_0,I_1,I_2) = (4,3,2) $，秩 $ R = 2 $。\n  - 生成因子矩阵：\n    $$\n    A^{(0)} = \\begin{bmatrix}\n    1.0  0.5 \\\\\n    0.8  -0.2 \\\\\n    0.3  1.2 \\\\\n    1.1  0.7\n    \\end{bmatrix}, \\quad\n    A^{(1)} = \\begin{bmatrix}\n    0.9  -0.4 \\\\\n    0.1  0.5 \\\\\n    1.0  0.3\n    \\end{bmatrix}, \\quad\n    A^{(2)} = \\begin{bmatrix}\n    1.0  0.2 \\\\\n    0.5  -1.0\n    \\end{bmatrix}.\n    $$\n  - 噪声标准差 $ \\sigma = 0.01 $，种子为 $ 42 $。\n  - 缺失条目 (在这些索引处将权重设置为零):\n    $ (0,0,1), (1,2,0), (2,1,1), (3,0,0) $。\n  - 算法的初始化种子：$ 202 $。\n\n- 案例 $2$ (所有条目均被观测，秩更高):\n  - 阶数 $N = 3$，维度 $ (I_0,I_1,I_2) = (3,3,3) $，秩 $ R = 3 $。\n  - 生成因子矩阵：\n    $$\n    A^{(0)} = \\begin{bmatrix}\n    0.5  1.0  -0.5 \\\\\n    0.2  -0.3  0.7 \\\\\n    1.2  0.1  0.4\n    \\end{bmatrix}, \\quad\n    A^{(1)} = \\begin{bmatrix}\n    -0.6  0.9  0.3 \\\\\n    0.8  0.1  -0.2 \\\\\n    0.5  -1.1  0.6\n    \\end{bmatrix}, \\quad\n    A^{(2)} = \\begin{bmatrix}\n    0.7  0.4  -0.9 \\\\\n    1.0  -0.5  0.2 \\\\\n    0.3  0.8  0.1\n    \\end{bmatrix}.\n    $$\n  - 噪声标准差 $ \\sigma = 0.02 $，种子为 $ 0 $。\n  - 所有条目均被观测：对所有索引，权重 $ W[i_0,i_1,i_2] = 1 $。\n  - 算法的初始化种子：$ 202 $。\n\n- 案例 $3$ (边缘情况，一个模态中存在完全缺失的切片以及其他缺失条目):\n  - 阶数 $N = 3$，维度 $ (I_0,I_1,I_2) = (5,4,3) $，秩 $ R = 2 $。\n  - 生成因子矩阵：\n    $$\n    A^{(0)} = \\begin{bmatrix}\n    0.9  -0.1 \\\\\n    0.4  0.2 \\\\\n    -0.3  0.8 \\\\\n    1.0  0.5 \\\\\n    0.7  -0.6\n    \\end{bmatrix}, \\quad\n    A^{(1)} = \\begin{bmatrix}\n    0.5  1.1 \\\\\n    -0.2  0.3 \\\\\n    0.9  -0.4 \\\\\n    0.1  0.6\n    \\end{bmatrix}, \\quad\n    A^{(2)} = \\begin{bmatrix}\n    1.0  0.2 \\\\\n    -0.5  0.7 \\\\\n    0.3  -0.9\n    \\end{bmatrix}.\n    $$\n  - 噪声标准差 $ \\sigma = 0.015 $，种子为 $ 123 $。\n  - 缺失条目：所有 $ i_0 = 0 $ 的索引均缺失，外加 $ (2,1,2) $ 和 $ (4,3,1) $。\n  - 算法的初始化种子：$ 202 $。\n\n实现要求：\n- 仅使用 Python $3.12$ 和 NumPy 库 $1.23.5$。\n- 实现一个通用的 $N$ 模 CP-WLS 算法，该算法具有模态交替更新、一致的展开方案以及与该方案对齐的 Khatri-Rao 积。\n- 使用 $T = 200$ 次迭代和 $ \\lambda = 10^{-6} $ 正则化。\n- 在每次对所有模态进行完整扫描后，进行列归一化：将除 $ A^{(0)} $ 外所有因子矩阵的列除以它们的 $ \\ell_2 $ 范数，并将每个分量的范数乘积吸收到 $ A^{(0)} $ 中，以维持尺度稳定性。\n- 计算如上定义的最终观测 RMSE。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含三个测试用例的 RMSE 值，格式为方括号括起来的逗号分隔列表，例如 $ [r_1,r_2,r_3] $。每个 $ r_k $ 必须是浮点值。", "solution": "该问题要求实现一种规范多元 (CP) 分解算法，用于处理含缺失条目的张量，方法是最小化加权最小二乘 (WLS) 目标函数。该解决方案从第一性原理出发，采用交替优化方案进行开发。\n\n### 数学公式\n\nCP 分解通过一个由 $R$ 个秩-1 分量组成的模型张量 $ \\mathcal{\\hat{X}} $ 来近似给定的 $N$ 阶张量 $ \\mathcal{X} \\in \\mathbb{R}^{I_0 \\times \\cdots \\times I_{N-1}} $。$ \\mathcal{\\hat{X}} $ 的元素由下式给出：\n$$\n\\mathcal{\\hat{X}}[i_0,i_1,\\dots,i_{N-1}] = \\sum_{r=1}^{R} \\prod_{n=0}^{N-1} A^{(n)}[i_n, r]\n$$\n其中 $ A^{(n)} \\in \\mathbb{R}^{I_n \\times R} $ 是因子矩阵。\n\n对于一个包含缺失数据的张量，我们给定一个权重张量 $ W \\in \\{0, 1\\}^{I_0 \\times \\cdots \\times I_{N-1}} $，其中 $W[\\dots] = 1$ 表示观测条目，$W[\\dots] = 0$ 表示缺失条目。优化问题是找到能够最小化 $\\ell_2$ 正则化加权平方误差和的因子矩阵：\n$$\n\\min_{\\{A^{(n)}\\}} \\; \\frac{1}{2} \\sum_{i_0=0}^{I_0-1} \\cdots \\sum_{i_{N-1}=0}^{I_{N-1}-1} W[\\dots] \\left( \\mathcal{X}[\\dots] - \\mathcal{\\hat{X}}[\\dots] \\right)^2 + \\frac{\\lambda}{2} \\sum_{n=0}^{N-1} \\|A^{(n)}\\|_F^2\n$$\n其中 $ \\| \\cdot \\|_F $ 是 Frobenius 范数，$ \\lambda $ 是正则化参数。\n\n### 通过交替块坐标下降进行优化\n\n该目标函数是非凸的，这使得同时求解所有因子矩阵的全局解变得棘手。一种标准且有效的启发式方法是使用交替块坐标下降，通常称为交替最小二乘 (ALS)。在这种方法中，我们一次只优化一个因子矩阵 $ A^{(k)} $，同时保持所有其他因子矩阵 $ \\{A^{(n)}\\}_{n \\neq k} $ 固定。这个过程对所有模态 $k = 0, \\dots, N-1$ 迭代重复。\n\n### 更新规则的推导\n\n我们来推导特定因子矩阵 $ A^{(k)} $ 的更新规则。当所有其他因子都固定时，目标函数可以使用张量的模-$k$ 展开来重写。模-$k$ 展开，表示为 $X_{(k)}$，是一个大小为 $I_k \\times (\\prod_{m \\neq k} I_m)$ 的矩阵，其行对应于模态 $k$ 的索引。\n\nCP 模型可以用矩阵化形式表示为：\n$$\nX_{(k)} \\approx A^{(k)} \\left( \\mathbf{C}^{(k)} \\right)^T\n$$\n这里，$\\mathbf{C}^{(k)}$ 是除 $A^{(k)}$ 外所有因子矩阵的 Khatri-Rao 积。此乘积中矩阵的具体顺序必须与展开张量的列顺序一致。如果我们将 $\\mathcal{X}$ 展开为 $X_{(k)}$，使得列索引 $j$ 对应于多重索引 $(i_m)_{m \\neq k}$，且最低模态索引变化最快（在 NumPy 中为 `order='F'`），那么 $\\mathbf{C}^{(k)}$ 必须构造为：\n$$\n\\mathbf{C}^{(k)} = A^{(m_p)} \\odot A^{(m_{p-1})} \\odot \\cdots \\odot A^{(m_1)}\n$$\n其中 $m_1  m_2  \\dots  m_p$ 是除 $k$ 之外的模态的排序索引。在实现中，这是通过对其他因子矩阵的排序列表迭代应用 Khatri-Rao 积来实现的。\n\n利用这种公式，仅作为 $A^{(k)}$ 函数的目标函数可以按行解耦。对于 $A^{(k)}$ 的每一行 $i_k$（表示为行向量 $a_{i_k}^{(k)}$），子问题是一个独立的正则化加权最小二乘问题：\n$$\n\\min_{a_{i_k}^{(k)}} \\frac{1}{2} \\| \\sqrt{w_{i_k}} \\odot (x_{i_k} - a_{i_k}^{(k)} (\\mathbf{C}^{(k)})^T) \\|_2^2 + \\frac{\\lambda'}{2} \\|a_{i_k}^{(k)}\\|_2^2\n$$\n其中 $x_{i_k}$ 和 $w_{i_k}$ 分别是展开矩阵 $X_{(k)}$ 和 $W_{(k)}$ 的第 $i_k$ 行，$\\odot$ 是逐元素乘积。原始的正则化项被分配到各个子问题中；我们用参数 $\\lambda$ 来解决这个问题。\n\n这是一个标准的岭回归问题。通过将关于 $a_{i_k}^{(k)}$ 的梯度设置为零来找到解，这为行向量的转置 $(a_{i_k}^{(k)})^T$ 产生了以下 $R \\times R$ 线性系统：\n$$\n\\left( (\\mathbf{C}^{(k)})^T \\mathrm{diag}(w_{i_k}) \\mathbf{C}^{(k)} + \\lambda I_R \\right) (a_{i_k}^{(k)})^T = (\\mathbf{C}^{(k)})^T \\mathrm{diag}(w_{i_k}) (x_{i_k})^T\n$$\n其中 $I_R$ 是 $R \\times R$ 单位矩阵。\n\n### 算法设计与实现\n\n算法流程如下：\n\n1.  **初始化**: 因子矩阵 $\\{A^{(n)}\\}$ 使用指定随机种子从标准正态分布中抽取的值进行初始化。\n2.  **迭代更新**: 对于固定次数的迭代 ($T=200$):\n    a.  **模态迭代**: 对于每个模态 $n = 0, \\dots, N-1$:\n        i.  **形成 $\\mathbf{C}^{(n)}$**: 计算除 $A^{(n)}$ 外的因子矩阵 $\\{A^{(m)}\\}_{m \\neq n}$ 的 Khatri-Rao 积。矩阵按模态索引排序以匹配展开约定。\n        ii. **展开张量**: 数据张量 $\\mathcal{X}$ 和权重张量 $W$ 被展开为 $X_{(n)}$ 和 $W_{(n)}$。\n        iii. **逐行更新**: 对于 $A^{(n)}$ 的每一行 $i_n = 0, \\dots, I_n-1$:\n            - 从 $W_{(n)}$ 中提取权重向量 $w_{i_n}$。\n            - **边缘情况处理**: 如果 $w_{i_n}$ 中的所有权重都为零（即整个切片缺失），则矩阵 $(\\mathbf{C}^{(n)})^T \\mathrm{diag}(w_{i_n}) \\mathbf{C}^{(n)}$ 和线性系统右侧的向量都将变为零。系统简化为 $\\lambda I_R (a_{i_n}^{(n)})^T = 0$，这意味着 $(a_{i_n}^{(n)})^T=0$。因此，该行被设置为零向量。\n            - **求解线性系统**: 对于非退化行，形成并求解 $R \\times R$ 系统以得到 $(a_{i_n}^{(n)})^T$。为避免显式形成大的对角矩阵 $\\mathrm{diag}(w_{i_n})$，使用广播（broadcasting）高效地计算乘积：`(C_n.T * w_i) @ C_n` 和 `(C_n.T * w_i) @ x_i.T`。\n    b.  **归一化**: 在完成所有模态的一次完整扫描后，将因子矩阵的列归一化为单位 $\\ell_2$ 范数。这是确保数值稳定性和管理 CP 分解固有的尺度模糊性（即可以将 $A^{(n)}$ 的一列乘以 $\\alpha$ 并将 $A^{(m)}$ 的一列乘以 $1/\\alpha$ 而不改变乘积）的关键步骤。范数被累积并吸收到第一个因子矩阵 $A^{(0)}$ 的列中。\n3.  **重构与评估**: 在最后一次迭代之后，从拟合的因子矩阵重构模型张量 $\\hat{\\mathcal{X}}$。使用指定公式计算最终的观测均方根误差 (RMSE)：\n$$\n\\mathrm{RMSE} = \\sqrt{ \\frac{ \\sum_{i_0,\\dots,i_{N-1}} W[\\dots] \\, \\left( \\mathcal{X}[\\dots] - \\mathcal{\\hat{X}}[\\dots] \\right)^2 }{ \\sum_{i_0,\\dots,i_{N-1}} W[\\dots] } }\n$$\n\n这种基于第一性原理的方法确保了 CP-WLS 算法的鲁棒和正确实现，该算法直接从其数学定义推导而来。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef khatri_rao(matrices):\n    \"\"\"\n    Computes the Khatri-Rao product of a list of matrices.\n    The product is computed iteratively: M_1 @ M_2 @ ... @ M_k.\n    \"\"\"\n    if not matrices:\n        return None\n    if len(matrices) == 1:\n        return matrices[0]\n\n    result = matrices[0]\n    for i in range(1, len(matrices)):\n        mat = matrices[i]\n        I_res, R = result.shape\n        I_mat, _ = mat.shape\n        \n        # Use einsum for column-wise outer products, then reshape.\n        # 'ir,jr->ijr' computes the outer product of each corresponding column r.\n        # reshape with 'F' order ensures the first index (from `result`) varies fastest,\n        # matching the unfolding convention.\n        result = np.einsum('ir,jr->ijr', result, mat).reshape(I_res * I_mat, R, order='F')\n    return result\n\ndef reconstruct(factors):\n    \"\"\"\n    Reconstructs a full tensor from its CP factor matrices.\n    \"\"\"\n    if not factors:\n        return None\n    \n    R = factors[0].shape[1]\n    N = len(factors)\n    shape = tuple(f.shape[0] for f in factors)\n    \n    full_tensor = np.zeros(shape)\n    for r in range(R):\n        # Start with the first factor's r-th column\n        rank1_tensor = factors[0][:, r]\n        # Successively compute outer products with other factors' r-th columns\n        for n in range(1, N):\n            rank1_tensor = np.multiply.outer(rank1_tensor, factors[n][:, r])\n        full_tensor += rank1_tensor\n        \n    return full_tensor\n\ndef cp_wls(X, W, R, T, lmbda, init_seed):\n    \"\"\"\n    Computes the CP decomposition for a tensor with missing data using\n    Weighted Alternating Least Squares (WALS).\n    \"\"\"\n    N = X.ndim\n    dims = X.shape\n    \n    rng = np.random.default_rng(init_seed)\n    factors = [rng.standard_normal((dims[n], R)) for n in range(N)]\n\n    for _ in range(T):\n        for n in range(N):\n            # 1. Form the Khatri-Rao product of all other factor matrices.\n            modes_other = sorted([m for m in range(N) if m != n])\n            kr_matrices = [factors[m] for m in modes_other]\n            C_n = khatri_rao(kr_matrices)\n            \n            # 2. Unfold data and weight tensors along mode n with Fortran ordering.\n            Xn = np.moveaxis(X, n, 0).reshape((dims[n], -1), order='F')\n            Wn = np.moveaxis(W, n, 0).reshape((dims[n], -1), order='F')\n            \n            # 3. Update each row of the factor matrix A^{(n)}.\n            new_An = np.zeros_like(factors[n])\n            for i in range(dims[n]):\n                wi = Wn[i, :]\n                \n                if np.sum(wi)  1e-12:\n                    continue  # Row remains zero\n                \n                # Setup and solve the regularized weighted linear least squares for the row.\n                M = (C_n.T * wi) @ C_n + lmbda * np.eye(R)\n                v = (C_n.T * wi) @ Xn[i, :].T\n                \n                try:\n                    solved_row = np.linalg.solve(M, v)\n                    new_An[i, :] = solved_row\n                except np.linalg.LinAlgError:\n                    # Failsafe for singular matrix, unlikely with regularization.\n                    new_An[i, :] = 0.0\n\n            factors[n] = new_An\n\n        # 4. Column normalization after a full sweep.\n        col_norms_product = np.ones(R)\n        for mode_idx in range(1, N):\n            norms = np.linalg.norm(factors[mode_idx], axis=0)\n            non_zero_indices = norms  1e-12\n            factors[mode_idx][:, non_zero_indices] /= norms[non_zero_indices]\n            norms[norms  1e-12] = 1.0\n            col_norms_product *= norms\n        \n        factors[0] *= col_norms_product\n    \n    return factors\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    # Global algorithm parameters\n    T = 200\n    lmbda = 1e-6\n    init_seed = 202\n\n    test_cases = [\n        # Case 1: Happy path\n        {\n            \"dims\": (4, 3, 2), \"R\": 2, \"sigma\": 0.01, \"noise_seed\": 42,\n            \"gen_factors\": [\n                np.array([[1.0, 0.5], [0.8, -0.2], [0.3, 1.2], [1.1, 0.7]]),\n                np.array([[0.9, -0.4], [0.1, 0.5], [1.0, 0.3]]),\n                np.array([[1.0, 0.2], [0.5, -1.0]])\n            ],\n            \"missing_indices\": [(0, 0, 1), (1, 2, 0), (2, 1, 1), (3, 0, 0)]\n        },\n        # Case 2: Fully observed\n        {\n            \"dims\": (3, 3, 3), \"R\": 3, \"sigma\": 0.02, \"noise_seed\": 0,\n            \"gen_factors\": [\n                np.array([[0.5, 1.0, -0.5], [0.2, -0.3, 0.7], [1.2, 0.1, 0.4]]),\n                np.array([[-0.6, 0.9, 0.3], [0.8, 0.1, -0.2], [0.5, -1.1, 0.6]]),\n                np.array([[0.7, 0.4, -0.9], [1.0, -0.5, 0.2], [0.3, 0.8, 0.1]])\n            ],\n            \"missing_indices\": []\n        },\n        # Case 3: Edge case with a missing slice\n        {\n            \"dims\": (5, 4, 3), \"R\": 2, \"sigma\": 0.015, \"noise_seed\": 123,\n            \"gen_factors\": [\n                np.array([[0.9, -0.1], [0.4, 0.2], [-0.3, 0.8], [1.0, 0.5], [0.7, -0.6]]),\n                np.array([[0.5, 1.1], [-0.2, 0.3], [0.9, -0.4], [0.1, 0.6]]),\n                np.array([[1.0, 0.2], [-0.5, 0.7], [0.3, -0.9]])\n            ],\n            \"missing_indices\": [\n                (0, i1, i2) for i1 in range(4) for i2 in range(3)\n            ] + [(2, 1, 2), (4, 3, 1)]\n        }\n    ]\n\n    rmse_results = []\n    \n    for case in test_cases:\n        # 1. Generate synthetic data\n        X_true = reconstruct(case[\"gen_factors\"])\n        rng_noise = np.random.default_rng(case[\"noise_seed\"])\n        noise = rng_noise.standard_normal(size=case[\"dims\"]) * case[\"sigma\"]\n        X_noisy = X_true + noise\n        \n        # 2. Create weight tensor W\n        W = np.ones(case[\"dims\"])\n        if case[\"missing_indices\"]:\n            # Need to handle combined list and generator\n            indices_to_set = list(case[\"missing_indices\"])\n            for idx in indices_to_set:\n                W[idx] = 0\n            \n        # 3. Run CP-WLS algorithm\n        fitted_factors = cp_wls(X_noisy, W, case[\"R\"], T, lmbda, init_seed)\n        \n        # 4. Reconstruct tensor from fitted factors\n        X_hat = reconstruct(fitted_factors)\n        \n        # 5. Compute observed RMSE\n        squared_error = W * (X_noisy - X_hat)**2\n        sum_sq_err = np.sum(squared_error)\n        num_observed = np.sum(W)\n        \n        rmse = np.sqrt(sum_sq_err / num_observed) if num_observed  0 else 0.0\n        rmse_results.append(rmse)\n\n    print(f\"[{','.join(f'{r:.8f}' for r in rmse_results)}]\")\n\nsolve()\n```", "id": "3282166"}]}