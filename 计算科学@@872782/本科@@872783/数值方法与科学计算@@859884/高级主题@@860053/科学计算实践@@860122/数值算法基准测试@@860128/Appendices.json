{"hands_on_practices": [{"introduction": "理论上的算法复杂度（大O符号）为我们提供了性能的宏观视角，但在实践中，一个算法的真实表现还受到常数因子和实现开销的显著影响。本练习将通过比较经典的矩阵乘法与理论上更优的 Strassen 算法，来具体探索这一现象。通过动手实现和计时基准测试，你将亲身体验到如何确定一个算法从理论优势转化为实际优势的“交叉点”，这对于在真实世界的应用中做出明智的算法选择至关重要。[@problem_id:3209812]", "problem": "本任务要求实现一个可复现的基准测试程序，用以在给定的有限测试网格内，根据经验确定经典的三次方时间矩阵乘法与 Strassen 算法在处理实数稠密方阵时的有限规模交叉点。目标是量化在何种规模下，由于实现开销在小规模时占主导地位，经典算法的运行速度不慢于 Strassen 算法。基准测试必须以秒为单位进行，为保证稳健性应使用多次运行时间的中位数，且过程中无需任何用户输入。\n\n从以下基本前提开始：\n- 在标准算术成本模型下（即实数的加法和乘法成本为常数），两个大小为 $N \\times N$ 的稠密方阵的经典乘法时间复杂度为 $\\mathcal{O}(N^3)$。\n- 在相同模型下，Strassen 算法在每次递归中使用 $7$ 次分块乘法来减少子乘法的数量，同时伴有分块加法和减法，其每层递归的组合成本上限为常数乘以 $N^2$。\n- 经验性基准测试测量的是以秒为单位的实际运行时间 $t(N)$，该时间可建模为一个正函数，其值取决于渐近表示法未捕捉到的实现常数和开销。\n\n定义和要求：\n- 实现两种算法：\n  1. 经典乘法：计算 $C = A \\times B$，其中 $A, B \\in \\mathbb{R}^{N \\times N}$，时间复杂度为 $\\mathcal{O}(N^3)$。\n  2. Strassen 乘法：在方块上使用标准的 $7$ 次乘法递归，并带有一个基准情形阈值参数 $b$。当 $N \\le b$ 时，乘法将委托给经典算法处理。对于通用大小 $N$，需将输入用零填充至下一个二次幂大小，以确保分块始终有效；返回结果时需将其裁剪回 $N \\times N$ 大小。\n- 对于每个候选规模 $N$，使用固定的随机种子从标准正态分布 $\\mathcal{N}(0,1)$ 中抽取独立元素生成输入矩阵 $A, B$，以确保可复现性。为缓解冷启动效应，在每次计时前，需对每个算法和每个规模执行一次不计时的预热调用。\n- 对于每个 $N$ 和每种算法，使用单调高精度时钟测量以秒为单位的运行时间，并记录 $r$ 次重复计时运行的中位数。将中位数分别表示为 $t_{\\mathrm{classical}}(N)$ 和 $t_{\\mathrm{Strassen}}(N)$。\n- 对给定的参数集，定义有限网格交叉点决策如下：在提供的候选规模中，返回满足 $t_{\\mathrm{classical}}(N) \\le t_{\\mathrm{Strassen}}(N)$ 的最大 $N$。如果候选列表中不存在这样的 $N$，则返回 $-1$。\n- 对每个 $N$ 验证一次数值正确性，检查两种算法输出之间逐元素最大绝对差是否最多为 $\\tau = 10^{-8}$；不要将此检查包含在任何计时运行中。如果发生违反情况，将其视为实现错误，但不要改变计时行为；您的程序仍应完成并为测试套件生成输出。\n\n单位与度量：\n- 所有时间必须以秒为单位进行内部测量和报告。\n- 不涉及角度。\n- 任何用于内部决策的比率都必须视为纯数（无量纲），且不应打印。\n\n测试套件：\n为以下五个参数集运行基准测试；每个集是一个元组 $(\\text{sizes}, b, r, s)：$\n- 情况 1：规模 sizes $=[\\,16,32,64\\,]$，基准情形阈值 $b=16$，重复次数 $r=3$，种子 $s=0$。\n- 情况 2：规模 sizes $=[\\,24,32,48\\,]$，基准情形阈值 $b=8$，重复次数 $r=3$，种子 $s=1$。\n- 情况 3：规模 sizes $=[\\,8,16,32\\,]$，基准情形阈值 $b=64$，重复次数 $r=5$，种子 $s=2$。\n- 情况 4：规模 sizes $=[\\,32,64\\,]$，基准情形阈值 $b=32$，重复次数 $r=2$，种子 $s=3$。\n- 情况 5：规模 sizes $=[\\,16\\,]$，基准情形阈值 $b=8$，重复次数 $r=5$，种子 $s=4$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含五个情况的交叉点决策，格式为方括号括起来的逗号分隔列表，例如 $[n_1,n_2,n_3,n_4,n_5]$，其中每个 $n_i$ 是对应候选列表中满足 $t_{\\mathrm{classical}}(N) \\le t_{\\mathrm{Strassen}}(N)$ 的最大 $N$ 的整数值，如果该情况下不存在这样的 $N$，则为 $-1$。\n- 除此之外不要打印任何其他内容。", "solution": "该问题要求实现经典的矩阵乘法算法和 Strassen 矩阵乘法算法，并对其进行经验性基准测试，以确定性能上的交叉点。该交叉点定义为：在给定的有限集合中，使得经典算法（得益于其较低的开销）运行速度不慢于渐近更优的 Strassen 算法的最大矩阵规模 $N$。\n\n首先，我们考虑这两种算法的理论基础。用于计算两个矩阵 $A, B \\in \\mathbb{R}^{N \\times N}$ 的乘积 $C = A \\times B$ 的经典算法由逐元素公式 $C_{ij} = \\sum_{k=1}^{N} A_{ik} B_{kj}$ 定义。这需要 $N^3$ 次标量乘法和 $N^2(N-1)$ 次标量加法，最终时间复杂度为 $\\mathcal{O}(N^3)$。相比之下，Strassen 算法是一种递归的分治方法。它将 $N \\times N$ 的矩阵划分为四个 $N/2 \\times N/2$ 的子块，并仅使用 $7$ 次递归乘法和固定次数的矩阵加法和减法来计算乘积矩阵。其计算成本由递推关系 $T(N) = 7 T(N/2) + \\mathcal{O}(N^2)$ 描述，解得时间复杂度为 $\\mathcal{O}(N^{\\log_2 7}) \\approx \\mathcal{O}(N^{2.807})$。尽管 Strassen 算法具有更好的渐近伸缩性，但其递归函数调用和额外的矩阵加减运算会带来显著的开销，这使其在处理小规模 $N$ 时效率较低。\n\n实现包含两个主要函数（每种算法各一个）以及一个用于执行比较的基准测试框架。\n\n经典矩阵乘法被实现为一个函数 `classical_matmul(A, B)`。为提供一个实际且高性能的基线，该函数利用了 `numpy.dot`。当使用 `Python` 语言及其 `numpy` 库时，这通常是经典矩阵乘法的标准实现，它会链接到优化的基础线性代数子程序 (BLAS) 库。\n\nStrassen 矩阵乘法在一个递归函数 `strassen_matmul(A, B, b)` 中实现。该函数根据问题规范设计如下：\n1.  **基准情形**：当矩阵大小 $N$ 满足 $N \\le b$ 时（其中 $b$ 是基准情形阈值），递归终止。在这种情况下，计算将委托给 `classical_matmul` 函数。这创建了一个混合算法，避免了在小规模矩阵上使用无益的递归所带来的开销。\n2.  **填充与裁剪**：Strassen 算法的递归划分要求矩阵的维度是二次幂。该实现通过首先检查 $N$ 是否为二次幂来处理大小为 $N \\times N$ 的通用输入矩阵。如果不是，则用零填充输入矩阵 $A$ 和 $B$，以创建大小为 $m \\times m$ 的新方阵，其中 $m$ 是大于或等于 $N$ 的最小二次幂。然后对这些填充后的矩阵调用递归算法。得到的 $m \\times m$ 乘积矩阵在返回前会被裁剪回原始大小 $N \\times N$。这个填充和裁剪的包装器确保了核心递归逻辑可以专一地处理维度为二次幂的矩阵。\n3.  **递归步骤**：如果 $N  b$ 且 $N$ 是二次幂，矩阵 $A$ 和 $B$ 各自被划分为四个大小为 $N/2 \\times N/2$ 的子块。然后算法通过对 `strassen_matmul` 的递归调用来计算 $7$ 个中间乘积 $M_1, \\dots, M_7$。例如，$M_1$ 计算为 `strassen_matmul(A11 + A22, B11 + B22, b)`。最后，根据 Strassen 的公式组合这 $7$ 个乘积来计算结果矩阵 $C$ 的子块（例如，$C_{11} = M_1 + M_4 - M_5 + M_7$）。\n\n基准测试框架被封装在一个主函数 `solve` 中，该函数处理一套测试用例。对于每个由参数元组 $(\\text{sizes}, b, r, s)$ 定义的测试用例：\n1.  **可复现性**：使用 `numpy.random.seed(s)` 以种子 $s$ 初始化随机数生成器。然后生成大小为 $N \\times N$ 的输入矩阵 $A$ 和 $B$，其元素从标准正态分布 $\\mathcal{N}(0,1)$ 中抽取。\n2.  **计时测量**：在计时运行之前，对每种算法进行一次不计时的“预热”调用，以减轻冷启动效应。为获得准确的性能测量，每种算法执行 $r$ 次。每次执行的挂钟时间使用高精度单调时钟 `time.perf_counter()` 以秒为单位进行测量。取这 $r$ 次时间测量的中位数作为代表性运行时间，分别表示为 $t_{\\mathrm{classical}}(N)$ 和 $t_{\\mathrm{Strassen}}(N)$。使用中位数是因其对系统相关的计时噪声具有稳健性。\n3.  **数值验证**：作为一项合理性检查，每种规模 $N$ 都会验证一次 Strassen 实现的正确性，方法是计算其输出与经典算法输出之间的最大逐元素绝对差，确保其不超过容差 $\\tau = 10^{-8}$。此检查不包含在基准测试的计时部分。\n4.  **交叉点决策**：在获得一个测试用例中所有指定规模 $N$ 的中位运行时间后，程序会确定满足 $t_{\\mathrm{classical}}(N) \\le t_{\\mathrm{Strassen}}(N)$ 的规模集合。该测试用例的最终结果是此集合中的最大 $N$。如果该集合为空（即对于所有测试规模，Strassen 算法都更快），则结果为 $-1$。\n\n程序为所有五个测试用例系统地执行此过程，并整理所得的交叉点值。最终输出是包含这五个整数结果的单行文本，格式为方括号括起来的逗号分隔列表，例如 $[n_1,n_2,n_3,n_4,n_5]$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport time\n\ndef classical_matmul(A, B):\n    \"\"\"\n    Computes the matrix product C = A @ B using NumPy's optimized dot product.\n    This serves as the baseline classical O(N^3) algorithm.\n    \"\"\"\n    return np.dot(A, B)\n\ndef strassen_matmul(A, B, b):\n    \"\"\"\n    Computes the matrix product C = A @ B using Strassen's algorithm.\n    - b: The base-case threshold. If N = b, switches to classical_matmul.\n    - Handles non-power-of-two matrices by padding and cropping.\n    \"\"\"\n    N = A.shape[0]\n\n    # Base case: If the matrix size is below or at the threshold,\n    # delegate to the classical algorithm.\n    if N = b:\n        return classical_matmul(A, B)\n\n    # If N is not a power of two, pad it to the next power of two.\n    is_power_of_two = (N > 0) and ((N  (N - 1)) == 0)\n    if not is_power_of_two:\n        # Find the next power of two\n        m = 1  (N - 1).bit_length()\n        \n        # Create padded matrices\n        A_pad = np.zeros((m, m))\n        A_pad[:N, :N] = A\n        B_pad = np.zeros((m, m))\n        B_pad[:N, :N] = B\n        \n        # Perform Strassen multiplication on the padded matrices\n        C_pad = strassen_matmul(A_pad, B_pad, b)\n        \n        # Crop the result back to the original size\n        return C_pad[:N, :N]\n\n    # --- Recursive Step ---\n    # At this point, N is guaranteed to be a power of two and N > b.\n    mid = N // 2\n    \n    # Partition matrices into four sub-blocks of size mid x mid\n    A11, A12 = A[:mid, :mid], A[:mid, mid:]\n    A21, A22 = A[mid:, :mid], A[mid:, mid:]\n    B11, B12 = B[:mid, :mid], B[:mid, mid:]\n    B21, B22 = B[mid:, :mid], B[mid:, mid:]\n\n    # 7 recursive calls as per Strassen's algorithm\n    M1 = strassen_matmul(A11 + A22, B11 + B22, b)\n    M2 = strassen_matmul(A21 + A22, B11, b)\n    M3 = strassen_matmul(A11, B12 - B22, b)\n    M4 = strassen_matmul(A22, B21 - B11, b)\n    M5 = strassen_matmul(A11 + A12, B22, b)\n    M6 = strassen_matmul(A21 - A11, B11 + B12, b)\n    M7 = strassen_matmul(A12 - A22, B21 + B22, b)\n\n    # Combine the 7 products to form the sub-blocks of the result matrix C\n    C11 = M1 + M4 - M5 + M7\n    C12 = M3 + M5\n    C21 = M2 + M4\n    C22 = M1 - M2 + M3 + M6\n\n    # Assemble the final result matrix C from its sub-blocks\n    C = np.empty((N, N), dtype=A.dtype)\n    C[:mid, :mid] = C11\n    C[:mid, mid:] = C12\n    C[mid:, :mid] = C21\n    C[mid:, mid:] = C22\n\n    return C\n\ndef solve():\n    \"\"\"\n    Main function to run the benchmarking suite and find crossover points.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (sizes, base_case_threshold, repeats, seed)\n        ([16, 32, 64], 16, 3, 0),\n        ([24, 32, 48], 8, 3, 1),\n        ([8, 16, 32], 64, 5, 2),\n        ([32, 64], 32, 2, 3),\n        ([16], 8, 5, 4),\n    ]\n\n    results = []\n    tau = 1e-8\n\n    for sizes, b, r, s in test_cases:\n        np.random.seed(s)\n        \n        crossover_candidates = []\n        \n        for N in sizes:\n            # Generate reproducible random matrices\n            A = np.random.randn(N, N)\n            B = np.random.randn(N, N)\n            \n            # Untimed warm-up calls to mitigate cold-start artifacts\n            _ = classical_matmul(A, B)\n            _ = strassen_matmul(A, B, b)\n            \n            # Benchmark classical algorithm\n            classical_times = []\n            for _ in range(r):\n                start = time.perf_counter()\n                C_classical = classical_matmul(A, B)\n                end = time.perf_counter()\n                classical_times.append(end - start)\n            t_classical = np.median(classical_times)\n            \n            # Benchmark Strassen algorithm\n            strassen_times = []\n            for _ in range(r):\n                start = time.perf_counter()\n                C_strassen = strassen_matmul(A, B, b)\n                end = time.perf_counter()\n                strassen_times.append(end - start)\n            t_strassen = np.median(strassen_times)\n            \n            # Verify numerical correctness (not part of timing)\n            max_abs_diff = np.max(np.abs(C_classical - C_strassen))\n            if max_abs_diff > tau:\n                # Per problem spec, this is an implementation error but should not\n                # alter program completion or output format.\n                pass \n\n            # Check if classical is no slower than Strassen\n            if t_classical = t_strassen:\n                crossover_candidates.append(N)\n        \n        # Determine the crossover decision for the current case\n        if not crossover_candidates:\n            case_result = -1\n        else:\n            case_result = max(crossover_candidates)\n            \n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3209812"}, {"introduction": "在了解了实现开销如何影响性能之后，我们进一步探究问题的内在数学结构如何决定算法的效率。对于求解大型线性系统的迭代方法，如共轭梯度法（CG），其收敛速度与系统矩阵的条件数 $\\kappa_2(A)$ 密切相关。本练习通过精确构建具有特定条件数的矩阵族，让你能够量化地观察和验证这一核心原则。你将通过测量CG方法达到预设精度所需的迭代次数，直观地理解为什么“病态”系统（即条件数大的系统）的求解要困难得多。[@problem_id:3209858]", "problem": "您将研究迭代求解器的迭代次数如何随着系统矩阵条件数的增加而下降。请完全使用精确、无量纲的纯数学术语进行研究。\n\n从以下基本原理开始：\n- 对于一个实对称正定矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其在谱范数下的谱条件数为 $\\kappa_2(A) = \\lambda_{\\max}(A)/\\lambda_{\\min}(A)$，其中 $\\lambda_{\\max}(A)$ 和 $\\lambda_{\\min}(A)$ 分别表示 $A$ 的最大和最小特征值。\n- 用于求解 $A$ 为对称正定矩阵的方程 $A x = b$ 的共轭梯度法（简称CG）在一个Krylov子空间上迭代地最小化 $A$-范数下的误差，并在残差 $r_k = b - A x_k$ 满足指定的停止准则时终止。\n\n任务。实现一个完整、可运行的程序，该程序：\n1. 对于每个指定的目标条件数 $\\kappa$，通过指定特征值并与一个固定的正交矩阵混合，构造一个大小为 $n \\times n$ 的实对称正定矩阵族的一个成员 $A(\\kappa)$，使得 $\\kappa_2(A(\\kappa)) = \\kappa$：\n   - 使用 $n = 64$。\n   - 设特征值 $\\lambda_i$（其中 $i = 1, \\dots, n$）在 $1$ 和 $\\kappa$ 之间线性分布。\n   - 构造 $A(\\kappa) = Q^\\top \\operatorname{diag}(\\lambda_1,\\dots,\\lambda_n) Q$，其中 $Q$ 是一个固定的正交矩阵，按以下方式可复现地生成：使用固定的种子 $0$ 构造一个稠密矩阵 $M \\in \\mathbb{R}^{n \\times n}$，其条目为独立同分布的标准正态分布；计算一个简约QR分解 $M = \\widehat{Q} R$；定义 $D = \\operatorname{diag}(\\operatorname{sign}(R_{11}), \\dots, \\operatorname{sign}(R_{nn}))$，并约定 $\\operatorname{sign}(0)=1$，然后设置 $Q = \\widehat{Q} D$。这保证了 $R$ 的对角线元素为正，并确定性地固定了 $Q$ 的列符号。\n2. 使用共轭梯度法求解 $A(\\kappa) x = b$，参数如下：\n   - 右端项 $b = \\mathbf{1} \\in \\mathbb{R}^n$（全为1）。\n   - 初始猜测 $x_0 = 0$。\n   - 停止准则为 $\\lVert r_k \\rVert_2 \\le \\text{tol} \\cdot \\lVert b \\rVert_2$，其中 $\\text{tol} = 10^{-8}$，$\\lVert \\cdot \\rVert_2$ 是欧几里得范数。\n   - 最大迭代次数等于 $n$。\n3. 报告每个测试用例中，共轭梯度法满足停止准则所用的迭代次数 $k$，或者如果在 $n$ 次迭代内未满足停止准则，则报告最大值 $n$。\n\n测试套件。对以下参数值运行程序：\n- 用例 1：$(n, \\kappa, \\text{tol}) = (64, 1, 10^{-8})$。\n- 用例 2：$(n, \\kappa, \\text{tol}) = (64, 10, 10^{-8})$。\n- 用例 3：$(n, \\kappa, \\text{tol}) = (64, 100, 10^{-8})$。\n- 用例 4：$(n, \\kappa, \\text{tol}) = (64, 1000, 10^{-8})$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的结果与测试套件的顺序相同，例如 $[k_1,k_2,k_3,k_4]$，其中每个 $k_i$ 是用例 $i$ 的整数迭代次数。\n\n您的实现不得读取任何输入，也不得使用任何外部文件或网络访问。所有计算必须使用双精度算术。不涉及物理单位，也不使用角度。报告的量为整数。", "solution": "该问题是有效的。它提出了一个适定且科学上合理的数值实验，以研究矩阵条件数对共轭梯度法收敛性的影响。所有参数和过程都得到了精确且明确的规定。\n\n目标是量化一个实对称正定（SPD）矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的谱条件数 $\\kappa_2(A)$ 与共轭梯度（CG）法求解线性系统 $A x = b$ 所需迭代次数之间的关系。该实验被设计为完全可复现的，并针对一系列条件数递增的矩阵进行。\n\n首先，我们必须构造一个大小为 $n \\times n$ 的矩阵族 $A(\\kappa)$，其条件数 $\\kappa$ 受到精确控制。问题指定 $n=64$。实现这一目标的标准方法是通过其特征分解来定义矩阵，$A(\\kappa) = Q \\Lambda(\\kappa) Q^\\top$，或者等效地，$A(\\kappa) = Q^\\top \\Lambda(\\kappa) Q$，因为 $Q$ 是正交的。矩阵 $\\Lambda(\\kappa) = \\operatorname{diag}(\\lambda_1, \\dots, \\lambda_n)$ 是一个包含 $A(\\kappa)$ 特征值的对角矩阵。条件数定义为 $\\kappa_2(A) = \\lambda_{\\max}(A)/\\lambda_{\\min}(A)$。为了达到目标条件数 $\\kappa$，我们可以设置 $\\lambda_{\\min} = 1$ 和 $\\lambda_{\\max} = \\kappa$。问题指定 $n$ 个特征值 $\\lambda_i$ 在 $1$ 和 $\\kappa$ 之间线性分布。因此，特征值集合为 $\\{\\lambda_i\\}_{i=1}^n$，其中 $\\lambda_i = 1 + (i-1)\\frac{\\kappa-1}{n-1}$。由于所有 $\\kappa \\ge 1$，所有特征值 $\\lambda_i$ 都大于或等于 $1$，确保了所得矩阵 $A(\\kappa)$ 是正定的。构造 $A(\\kappa) = Q^\\top \\Lambda(\\kappa) Q$ 保证了 $A(\\kappa)$ 是对称的。\n\n正交矩阵 $Q$ 对所有测试用例都是固定的，以确保对特征系统应用一致的旋转变换。这分离出了特征值分布的影响。矩阵 $Q$ 是确定性地生成的，以确保可复现性。这是通过首先创建一个稠密矩阵 $M \\in \\mathbb{R}^{n \\times n}$ 来实现的，其条目从标准正态分布中抽取，使用固定的随机种子 $0$。然后计算 $M$ 的QR分解，$M = \\widehat{Q}R$。矩阵 $\\widehat{Q}$ 是正交的，但QR分解不是唯一的；$\\widehat{Q}$ 的列和 $R$ 的相应行的符号可以翻转。为了获得一个唯一的、确定性的 $Q$，我们强制执行一个约定，即 $R$ 的对角元素必须为非负。这是通过创建一个对角矩阵 $D = \\operatorname{diag}(\\operatorname{sign}(R_{11}), \\dots, \\operatorname{sign}(R_{nn}))$ 来实现的，并遵循指定的约定 $\\operatorname{sign}(0)=1$。最终的固定正交矩阵即为 $Q = \\widehat{Q}D$。\n\n构造好矩阵 $A(\\kappa)$ 后，我们使用共轭梯度法求解线性系统 $A(\\kappa)x = b$。求解器的参数为：右端向量 $b = \\mathbf{1} \\in \\mathbb{R}^n$（一个全为1的向量），初始猜测 $x_0 = 0 \\in \\mathbb{R}^n$，以及最大 $n=64$ 次迭代。CG算法迭代地生成一系列解的近似值。该过程从初始残差 $r_0 = b - Ax_0 = b$ 和初始搜索方向 $p_0 = r_0$ 开始。对于每次迭代 $k = 0, 1, 2, \\dots$，算法计算：\n$$ \\alpha_k = \\frac{r_k^\\top r_k}{p_k^\\top A p_k} $$\n$$ x_{k+1} = x_k + \\alpha_k p_k $$\n$$ r_{k+1} = r_k - \\alpha_k A p_k $$\n当残差的欧几里得范数 $\\lVert r_{k+1} \\rVert_2$ 满足停止准则 $\\lVert r_{k+1} \\rVert_2 \\le \\text{tol} \\cdot \\lVert b \\rVert_2$ 时，迭代终止，其中容差为 $\\text{tol} = 10^{-8}$。如果在步骤 $k+1$ 达到收敛，则迭代次数记录为 $k+1$。为了继续迭代，计算一个新的搜索方向：\n$$ \\beta_k = \\frac{r_{k+1}^\\top r_{k+1}}{r_k^\\top r_k} $$\n$$ p_{k+1} = r_{k+1} + \\beta_k p_k $$\n\n对每个指定的测试用例（对应于 $\\kappa \\in \\{1, 10, 100, 1000\\}$）执行这整个过程。收集并报告每种情况下的迭代次数。对于 $\\kappa=1$，$A(1)=I$，预计CG方法将在单次迭代中收敛。随着 $\\kappa$ 的增加，问题变得更加病态，预计迭代次数会增加，可能会达到最大限制 $n=64$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef conjugate_gradient(A, b, tol, max_iter):\n    \"\"\"\n    Solves the system Ax=b using the Conjugate Gradient method.\n\n    Args:\n        A (np.ndarray): The symmetric positive definite matrix of the system.\n        b (np.ndarray): The right-hand side vector.\n        tol (float): The relative tolerance for the stopping criterion.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        int: The number of iterations performed.\n    \"\"\"\n    n = A.shape[0]\n    x = np.zeros(n, dtype=np.float64)\n\n    r = b - A @ x  # Since x is zero, r = b\n    p = r.copy()\n    rs_old = np.dot(r, r)\n\n    norm_b = np.linalg.norm(b)\n    # Handle the trivial case where b is the zero vector.\n    if norm_b == 0.0:\n        return 0\n\n    stop_threshold = tol * norm_b\n\n    # The initial residual r_0 is b. If it already meets the criterion,\n    # 0 iterations are needed. This is unlikely for the given problem.\n    if np.linalg.norm(r) = stop_threshold:\n        return 0\n\n    for k in range(1, max_iter + 1):\n        Ap = A @ p\n        \n        # Numerator for alpha is r_k^T * r_k\n        # Denominator is p_k^T * A * p_k\n        alpha = rs_old / np.dot(p, Ap)\n        \n        # Update solution and residual\n        x = x + alpha * p\n        r = r - alpha * Ap\n        \n        # Check for convergence using the L2-norm of the residual\n        if np.linalg.norm(r) = stop_threshold:\n            return k\n            \n        rs_new = np.dot(r, r)\n        \n        # Update search direction\n        beta = rs_new / rs_old\n        p = r + beta * p\n        \n        rs_old = rs_new\n        \n    # If the loop completes, the method did not converge within max_iter.\n    return max_iter\n\ndef solve():\n    \"\"\"\n    Main function to run the numerical experiment and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (n, kappa, tol)\n        (64, 1.0, 1e-8),\n        (64, 10.0, 1e-8),\n        (64, 100.0, 1e-8),\n        (64, 1000.0, 1e-8),\n    ]\n\n    results = []\n    \n    # Common parameters\n    n = test_cases[0][0]\n    seed = 0\n\n    # 1. Construct the fixed orthogonal matrix Q, as per the problem description.\n    # Use the modern, preferred way of seeding for reproducibility.\n    rng = np.random.default_rng(seed)\n    M = rng.normal(size=(n, n))\n    \n    # Compute the QR factorization. For a square matrix, 'reduced' is default.\n    Q_hat, R = np.linalg.qr(M)\n    \n    # Create the sign-correction diagonal matrix D to ensure Q is unique.\n    # The problem specifies sign(0) = 1. numpy.sign(0) is 0, so we correct for it.\n    signs = np.sign(np.diag(R))\n    signs[signs == 0] = 1.0\n    # The final fixed orthogonal matrix Q.\n    Q = Q_hat @ np.diag(signs)\n\n    for n_case, kappa, tol in test_cases:\n        # 2. Construct the SPD matrix A(kappa) for the current case.\n        # Eigenvalues are linearly spaced between 1 and kappa.\n        eigenvalues = np.linspace(1.0, kappa, n, dtype=np.float64)\n        Lambda = np.diag(eigenvalues)\n        \n        # Form A = Q^T * Lambda * Q\n        A = Q.T @ Lambda @ Q\n\n        # 3. Define the linear system and solve it.\n        # Right-hand side is a vector of all ones.\n        b = np.ones(n, dtype=np.float64)\n        \n        # The maximum number of iterations is n.\n        max_iterations = n_case\n        \n        # Run the Conjugate Gradient solver.\n        iterations_count = conjugate_gradient(A, b, tol, max_iterations)\n        results.append(iterations_count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3209858"}, {"introduction": "在效率和问题结构的基础上，我们转向求解微分方程，这是一个稳定性成为首要考虑因素的领域。对于所谓的“刚性”方程组，算法的选择不仅关乎计算速度，更决定了数值解是否稳定和有意义。本练习通过对比显式方法（如经典的四阶龙格-库塔法RK4）和隐式方法（如后向欧拉法）来阐明这一关键权衡。你将通过寻找在满足精度要求下各自方法所允许的最大稳定时间步长，深刻理解刚性问题的本质，以及为何隐式方法在处理这类问题时尽管单步计算成本更高，却往往是唯一可行的选择。[@problem_id:3209907]", "problem": "考虑一个二维、解耦、线性刚性常微分方程组（ODEs）的初值问题：\n$$\n\\frac{d}{dt}\n\\begin{bmatrix}\ny_1(t) \\\\\ny_2(t)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n\\lambda_{\\text{slow}}  0 \\\\\n0  \\lambda_{\\text{fast}}\n\\end{bmatrix}\n\\begin{bmatrix}\ny_1(t) \\\\\ny_2(t)\n\\end{bmatrix}, \\quad\n\\begin{bmatrix}\ny_1(0) \\\\\ny_2(0)\n\\end{bmatrix}\n=\n\\begin{bmatrix}\n1 \\\\\n1\n\\end{bmatrix},\n$$\n其中 $\\lambda_{\\text{slow}}  0$，$\\lambda_{\\text{fast}}  0$，刚度比定义为 $S = \\left|\\lambda_{\\text{fast}}\\right| / \\left|\\lambda_{\\text{slow}}\\right|$。精确解为 $y_i(t) = \\exp\\left(\\lambda_i t\\right)$，其中 $i \\in \\{\\text{slow}, \\text{fast}\\}$。您将在此系列问题上，对显式经典四阶 Runge–Kutta 方法 (RK4) 和隐式向后欧拉方法进行基准测试。\n\n使用的基本定义：\n- 将单步法应用于标量线性测试方程 $y'(t) = \\lambda y(t)$，可得到形式为 $y_{n+1} = R(z)\\,y_n$ 的更新，其中 $z = \\lambda \\Delta t$，$R(z)$ 是与方法相关的稳定性函数。\n- 对于给定的步长 $\\Delta t$，如果对于系统矩阵的所有特征值 $\\lambda$ 都有 $\\left|R(\\lambda \\Delta t)\\right| \\leq 1$，则称该方法是线性稳定的。对于上述二维对角系统，这简化为要求对 $\\lambda_{\\text{slow}}$ 和 $\\lambda_{\\text{fast}}$ 都稳定。\n- 经过 $N$ 个大小为 $\\Delta t$ 的完整步和一个大小为 $\\Delta t_{\\text{last}} \\in [0,\\Delta t)$ 的最终部分步后的数值解满足 $t_N + \\Delta t_{\\text{last}} = T$，并且可以按分量表示为 $y_i^{\\text{num}}(T) = R\\left(\\lambda_i \\Delta t\\right)^N \\, R\\left(\\lambda_i \\Delta t_{\\text{last}}\\right) \\, y_i(0)$，而精确解为 $y_i^{\\text{exact}}(T) = \\exp\\left(\\lambda_i T\\right)\\,y_i(0)$。\n\n您的任务：\n1. 为上述对角线性系统实现显式四阶 Runge–Kutta 方法 (RK4) 和隐式向后欧拉方法。\n2. 对于每个求解器和每个测试用例，确定同时满足以下条件的最大步长 $\\Delta t_{\\max}$：\n   - 所有分量的线性稳定性，即 $\\left|R\\left(\\lambda_{\\text{slow}} \\Delta t\\right)\\right| \\leq 1$ 和 $\\left|R\\left(\\lambda_{\\text{fast}} \\Delta t\\right)\\right| \\leq 1$。\n   - 在最终时间 $T$ 的精度约束，由误差的无穷范数给出，\n     $$\n     \\left\\| y^{\\text{num}}(T) - y^{\\text{exact}}(T) \\right\\|_{\\infty}\n     =\n     \\max\\left(\n       \\left| y_1^{\\text{num}}(T) - y_1^{\\text{exact}}(T) \\right|,\n       \\left| y_2^{\\text{num}}(T) - y_2^{\\text{exact}}(T) \\right|\n     \\right)\n     \\leq \\varepsilon.\n     $$\n   最终时间表示为 $T$，容差表示为 $\\varepsilon$。使用 $N = \\left\\lfloor T / \\Delta t \\right\\rfloor$ 个完整步和一个大小为 $\\Delta t_{\\text{last}} = T - N\\,\\Delta t$ 的最终部分步（可能为零）。您必须通过在 $\\Delta t \\in (0, \\Delta t_{\\text{upper}}]$ 上的单调搜索（例如，二分法）来确定 $\\Delta t_{\\max}$，其中 $\\Delta t_{\\text{upper}}$ 是一个安全的上界。对于刚性问题上的 RK4，通过稳定性限制 $\\Delta t_{\\text{upper}}$；对于向后欧拉方法，限制为 $\\Delta t_{\\text{upper}} \\leq T$。\n3. 使用以下测试套件。每个测试用例指定 $(\\lambda_{\\text{slow}}, S, T, \\varepsilon)$；设置 $\\lambda_{\\text{fast}} = -S \\left|\\lambda_{\\text{slow}}\\right|$。\n   - 测试 A (理想情况): $(\\lambda_{\\text{slow}}, S, T, \\varepsilon) = (-1, 100, 1, 10^{-6})$。\n   - 测试 B (强刚性，较宽松的精度): $(\\lambda_{\\text{slow}}, S, T, \\varepsilon) = (-1, 1000, 1, 10^{-4})$。\n   - 测试 C (长时域，中等刚性，高精度): $(\\lambda_{\\text{slow}}, S, T, \\varepsilon) = (-0.1, 50, 10, 10^{-8})$。\n4. 对于每个测试用例，计算两个浮点数：RK4 的最大稳定且精确的步长 $\\Delta t_{\\max}^{\\text{RK4}}$，以及向后欧拉方法的最大稳定且精确的步长 $\\Delta t_{\\max}^{\\text{BE}}$。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含六个结果，以逗号分隔的列表形式，并用方括号括起来，顺序如下\n$$\n\\left[\n\\Delta t_{\\max}^{\\text{RK4}}(\\text{A}),\n\\Delta t_{\\max}^{\\text{BE}}(\\text{A}),\n\\Delta t_{\\max}^{\\text{RK4}}(\\text{B}),\n\\Delta t_{\\max}^{\\text{BE}}(\\text{B}),\n\\Delta t_{\\max}^{\\text{RK4}}(\\text{C}),\n\\Delta t_{\\max}^{\\text{BE}}(\\text{C})\n\\right].\n$$\n所有值都必须是浮点数。在这个纯数学设置中不涉及任何单位。", "solution": "问题陈述已经过严格审查，并被确定为**有效**。这是一个适定 (well-posed) 且具有科学依据的数值分析练习，旨在对显式和隐式数值方法在刚性常微分方程组 (ODEs) 上的性能进行基准测试。所有参数、定义和约束都已明确给出，从而可以得到唯一且有意义的解。\n\n任务是为两种数值方法——四阶 Runge-Kutta 方法 (RK4) 和向后欧拉方法 (BE)——找到最大步长 $\\Delta t_{\\max}$，该步长对于给定的线性二维系统同时满足稳定性和精度约束。该系统定义为\n$$\n\\frac{d\\mathbf{y}}{dt} = \\mathbf{A}\\mathbf{y}, \\quad \\mathbf{A} = \\begin{bmatrix} \\lambda_{\\text{slow}}  0 \\\\ 0  \\lambda_{\\text{fast}} \\end{bmatrix}, \\quad \\mathbf{y}(0) = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}.\n$$\n该解决方案涉及对每个测试用例在预定区间内对 $\\Delta t_{\\max}$ 进行单调搜索（特别是二分搜索）。\n\n首先，我们必须为每种方法定义稳定性函数 $R(z)$，其中 $z = \\lambda \\Delta t$。对于标量测试方程 $y' = \\lambda y$，数值格式给出 $y_{n+1} = R(\\lambda \\Delta t) y_n$。\n\n对于隐式向后欧拉方法，更新规则是 $y_{n+1} = y_n + \\Delta t (\\lambda y_{n+1})$。求解 $y_{n+1}$ 可得 $y_{n+1} = (1 - \\lambda \\Delta t)^{-1} y_n$。因此，稳定性函数为：\n$$\nR_{\\text{BE}}(z) = \\frac{1}{1 - z}\n$$\n\n对于显式经典四阶 Runge-Kutta 方法，稳定性函数是指数函数到四阶的截断泰勒级数：\n$$\nR_{\\text{RK4}}(z) = 1 + z + \\frac{z^2}{2!} + \\frac{z^3}{3!} + \\frac{z^4}{4!}\n$$\n\n接下来，我们分析步长 $\\Delta t$ 的约束条件。\n\n第一个约束是线性稳定性，要求对系统的所有特征值都有 $|R(\\lambda \\Delta t)| \\leq 1$。由于 $\\lambda_{\\text{slow}}$ 和 $\\lambda_{\\text{fast}}$ 都是实数且为负，因此 $z = \\lambda \\Delta t$ 是实数且为负。\n对于向后欧拉方法，当 $z  0$ 时，我们有 $1 - z > 1$，所以 $|R_{\\text{BE}}(z)| = \\frac{1}{1-z}$ 总是在 0 和 1 之间。因此，向后欧拉方法是 A-稳定的，并且对于此问题没有对 $\\Delta t$ 施加稳定性限制。因此，如问题所述，对 BE 的 $\\Delta t_{\\max}$ 的搜索上界为积分时间 $T$。\n\n对于 RK4 方法，实轴上的绝对稳定区域约为 $[-2.785, 0]$。对于 $z  0$，$|R_{\\text{RK4}}(z)| \\leq 1$ 的条件要求 $z \\geq z_{\\text{stab}}$，其中 $z_{\\text{stab}} \\approx -2.785287335359$。这必须对 $z_{\\text{slow}} = \\lambda_{\\text{slow}} \\Delta t$ 和 $z_{\\text{fast}} = \\lambda_{\\text{fast}} \\Delta t$ 都成立。由于 $|\\lambda_{\\text{fast}}| \\geq |\\lambda_{\\text{slow}}|$，更严格的条件是 $\\lambda_{\\text{fast}} \\Delta t \\geq z_{\\text{stab}}$，这意味着 $\\Delta t \\leq \\frac{z_{\\text{stab}}}{\\lambda_{\\text{fast}}} = \\frac{|z_{\\text{stab}}|}{|\\lambda_{\\text{fast}}|}$。此值作为 RK4 二分搜索的上界 $\\Delta t_{\\text{upper}}$。\n\n第二个约束是精度。在最终时间 $T$ 的误差无穷范数不能超过容差 $\\varepsilon$：\n$$\n\\left\\| \\mathbf{y}^{\\text{num}}(T) - \\mathbf{y}^{\\text{exact}}(T) \\right\\|_{\\infty} \\leq \\varepsilon\n$$\n问题提供了精确解和数值解的显式公式。分量精确解为 $y_i^{\\text{exact}}(T) = \\exp(\\lambda_i T) y_i(0)$。考虑到最终的部分步，数值解为 $y_i^{\\text{num}}(T) = R(\\lambda_i \\Delta t)^N R(\\lambda_i \\Delta t_{\\text{last}}) y_i(0)$，其中 $N = \\lfloor T / \\Delta t \\rfloor$ 且 $\\Delta t_{\\text{last}} = T - N \\Delta t$。由于 $y_i(0)=1$，每个分量 $i$ 的条件是：\n$$\n\\left| R(\\lambda_i \\Delta t)^N \\, R(\\lambda_i \\Delta t_{\\text{last}}) - \\exp(\\lambda_i T) \\right| \\leq \\varepsilon\n$$\n\n总体任务是找到满足这两个约束的最大 $\\Delta t > 0$。对于给定的方法和问题参数，我们定义一个函数 `is_valid(Δt)`，当且仅当稳定性和精度约束都满足时，该函数返回 true。对于 RK4，稳定性约束通过将搜索空间限制在 $\\Delta t \\in (0, \\Delta t_{\\text{upper}}]$ 来处理。对于 BE，稳定性总是满足的。精度约束通过计算给定 $\\Delta t$ 的误差并将其与 $\\varepsilon$ 比较来检查。\n\n`is_valid(Δt)` 函数应是单调的：如果步长 $\\Delta t$ 有效，任何更小的步长 $\\Delta t'  \\Delta t$ 也将有效，因为对于稳定积分，数值误差通常随步长减小而减小。这种单调性使我们能够使用二分搜索来有效地找到 $\\Delta t_{\\max}$。\n\n二分算法如下：\n1. 初始化一个搜索区间 $[\\Delta t_{\\text{low}}, \\Delta t_{\\text{high}}]$，其中 $\\Delta t_{\\text{low}} = 0$ 且 $\\Delta t_{\\text{high}} = \\Delta t_{\\text{upper}}$。\n2. 迭代固定次数（例如，100 次，足以达到双精度准确度）：\n   a. 计算中点 $\\Delta t_{\\text{mid}} = (\\Delta t_{\\text{low}} + \\Delta t_{\\text{high}}) / 2$。\n   b. 如果 `is_valid(Δt_mid)` 为 true，则意味着步长 $\\Delta t_{\\text{mid}}$ 是可接受的，我们或许可以找到更好的步长。我们设置 $\\Delta t_{\\text{low}} = \\Delta t_{\\text{mid}}$。\n   c. 如果 `is_valid(Δt_mid)` 为 false，则步长过大。我们设置 $\\Delta t_{\\text{high}} = \\Delta t_{\\text{mid}}$。\n3. 迭代结束后，$\\Delta t_{\\text{low}}$ 是所需 $\\Delta t_{\\max}$ 的一个非常精确的近似值。\n\n此过程将应用于 RK4 和 BE 方法的三个测试用例中的每一个，以计算所需的六个值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the maximum stable and accurate step size for RK4 and Backward Euler\n    methods on a stiff ODE system for a suite of test cases.\n    \"\"\"\n\n    # The stability boundary for the RK4 method on the negative real axis.\n    # Root of 1 + z + z^2/2 + z^3/6 + z^4/24 = -1.\n    RK4_STABILITY_BOUNDARY = 2.785287335359041\n\n    def R_rk4(z: float) -> float:\n        \"\"\"Stability function for the classical 4th order Runge-Kutta method.\"\"\"\n        return 1.0 + z * (1.0 + z * (1/2.0 + z * (1/6.0 + z / 24.0)))\n\n    def R_be(z: float) -> float:\n        \"\"\"Stability function for the implicit Backward Euler method.\"\"\"\n        return 1.0 / (1.0 - z)\n\n    def find_max_dt(params: tuple, method_type: str) -> float:\n        \"\"\"\n        Finds the largest step size dt for a given method and problem parameters\n        that satisfies both stability and accuracy constraints, using bisection search.\n        \"\"\"\n        lambda_slow, S, T, epsilon = params\n        lambda_fast = -S * abs(lambda_slow)\n\n        if method_type == 'RK4':\n            stability_func = R_rk4\n            # For RK4, the step size is limited by the stability region.\n            # |lambda_fast * dt| = RK4_STABILITY_BOUNDARY\n            dt_upper = RK4_STABILITY_BOUNDARY / abs(lambda_fast)\n        elif method_type == 'BE':\n            stability_func = R_be\n            # Backward Euler is A-stable, no stability restriction for these lambda  0.\n            # The problem specifies using T as the upper bound for the search.\n            dt_upper = T\n        else:\n            raise ValueError(f\"Unknown method type: {method_type}\")\n\n        def is_valid(dt: float) -> bool:\n            \"\"\"\n            Checks if a given step size dt satisfies the accuracy constraint.\n            Stability is enforced by the search range of the bisection method.\n            \"\"\"\n            if dt = 1e-15:  # Effectively zero dt, considered valid but we search for dt > 0.\n                return True\n\n            N = np.floor(T / dt)\n            dt_last = T - N * dt\n\n            # Component 1 (slow)\n            z_slow = lambda_slow * dt\n            z_slow_last = lambda_slow * dt_last\n            y1_num = (stability_func(z_slow)**N) * stability_func(z_slow_last)\n            y1_exact = np.exp(lambda_slow * T)\n            err1 = abs(y1_num - y1_exact)\n\n            # Component 2 (fast)\n            z_fast = lambda_fast * dt\n            z_fast_last = lambda_fast * dt_last\n            y2_num = (stability_func(z_fast)**N) * stability_func(z_fast_last)\n            y2_exact = np.exp(lambda_fast * T)\n            err2 = abs(y2_num - y2_exact)\n            \n            return max(err1, err2) = epsilon\n\n        # Bisection search to find the boundary of the valid dt region.\n        low = 0.0\n        high = dt_upper\n\n        # Bisection loop for a fixed number of iterations for high precision.\n        for _ in range(100):\n            mid = (low + high) / 2.0\n            if mid == low or mid == high: # Reached floating point precision limit\n                break\n            \n            if is_valid(mid):\n                low = mid  # mid is valid, so it's a candidate. Try for a larger dt.\n            else:\n                high = mid # mid is invalid, dt must be smaller.\n        \n        return low\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (lambda_slow, S, T, epsilon)\n        (-1.0, 100.0, 1.0, 1e-6),    # Case A\n        (-1.0, 1000.0, 1.0, 1e-4),   # Case B\n        (-0.1, 50.0, 10.0, 1e-8),   # Case C\n    ]\n\n    results = []\n    for params in test_cases:\n        dt_max_rk4 = find_max_dt(params, 'RK4')\n        results.append(dt_max_rk4)\n        \n        dt_max_be = find_max_dt(params, 'BE')\n        results.append(dt_max_be)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3209907"}]}