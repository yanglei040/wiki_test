{"hands_on_practices": [{"introduction": "我们的第一个练习是应用欧拉方法进行单步计算。这个练习旨在帮助你熟悉核心的迭代公式 $y_{n+1} = y_n + h f(t_n, y_n)$，这是所有数值求解微分方程方法的基础。通过这个简单的例子 [@problem_id:2172233]，你将学会如何根据给定的微分方程和初始条件，计算出解在下一个时间点的近似值。", "problem": "考虑由一阶常微分方程定义的初值问题：\n$$y'(t) = y - t^2$$\n初始条件为 $y(0) = 1$。\n\n您的任务是执行一步欧拉法，来近似求解在 $t = 0.2$ 时的解。使用步长 $h = 0.2$。请以数值形式给出您的最终答案。", "solution": "我们对初值问题 $y'(t)=f(t,y)=y-t^{2}$（其中 $y(0)=1$，步长 $h=0.2$）应用一步显式欧拉法。欧拉更新公式为\n$$\ny_{n+1}=y_{n}+h\\,f(t_{n},y_{n}).\n$$\n当 $t_{0}=0$, $y_{0}=1$, 且 $h=0.2$ 时，我们计算\n$$\nf(t_{0},y_{0})=f(0,1)=1-0^{2}=1,\n$$\n所以\n$$\ny_{1}=y_{0}+h\\,f(t_{0},y_{0})=1+0.2\\cdot 1=1.2.\n$$\n因此，在 $t=0.2$ 处的欧拉近似值为 $y(0.2)\\approx 1.2$。", "answer": "$$\\boxed{1.2}$$", "id": "2172233"}, {"introduction": "掌握了基本步骤后，我们来探讨一个更核心的概念：步长 $h$ 对近似精度的影响。这个练习 [@problem_id:2172241] 要求你对同一个初值问题使用两种不同的步长进行计算，并比较结果。这将直观地展示欧拉方法的一个关键特性——步长越小，通常结果越精确，但同时也揭示了选择不当步长可能带来的稳定性问题。", "problem": "考虑由常微分方程 $y'(t) = -2y(t)$ 和初始条件 $y(0) = 1$ 给出的初值问题 (IVP)。我们希望使用欧拉方法来近似 $y(1)$ 的值。\n\n令 $A_1$ 为使用步长 $h=1$ 的单步欧拉方法得到的 $y(1)$ 的近似值。\n令 $A_{0.5}$ 为使用步长均为 $h=0.5$ 的两步欧拉方法得到的 $y(1)$ 的近似值。\n\n计算表达式 $3A_1 - 2A_{0.5}$ 的值。", "solution": "我们应用显式欧拉方法，对于一个步长为 $h$ 的初值问题 $y'(t)=f(t,y)$，其更新公式为\n$$\ny_{n+1}=y_{n}+h\\,f(t_{n},y_{n}).\n$$\n此处 $f(t,y)=-2y$，所以\n$$\ny_{n+1}=y_{n}+h(-2y_{n})=y_{n}(1-2h).\n$$\n\n从 $t_{0}=0$ 到 $t_{1}=1$，使用 $h=1$ 的单步：\n$$\ny_{1}=y_{0}(1-2\\cdot 1)=1\\cdot(-1)=-1,\n$$\n所以 $A_{1}=-1$。\n\n从 $t_{0}=0$ 到 $t_{2}=1$，使用 $h=0.5$ 的两步：\n第一步到 $t_{1}=0.5$：\n$$\ny_{1}=y_{0}(1-2\\cdot 0.5)=1\\cdot(1-1)=0.\n$$\n第二步到 $t_{2}=1$：\n$$\ny_{2}=y_{1}(1-2\\cdot 0.5)=0\\cdot(1-1)=0,\n$$\n所以 $A_{0.5}=0$。\n\n因此，\n$$\n3A_{1}-2A_{0.5}=3(-1)-2(0)=-3.\n$$", "answer": "$$\\boxed{-3}$$", "id": "2172241"}, {"introduction": "手动计算有助于理解概念，但在实际科研和工程中，我们通常编写程序来执行成千上万次的迭代。这个练习 [@problem_id:3226253] 将引导你从手动计算过渡到编程实现。更重要的是，你将学习如何利用欧拉方法误差与步长 $h$ 呈线性关系的特性，通过理查德森外推法（Richardson extrapolation）来构造一个更高精度的解，这是数值分析中一种强大而通用的思想。", "problem": "考虑一个常微分方程 (ODE) 的初值问题 (IVP)，其形式为 $y'(t) = f(t, y(t))$，初始条件为 $y(t_0) = y_0$。前向欧拉法源于导数作为有限差分极限的基本定义，以及一阶泰勒展开的应用。在实践中，前向欧拉法从 $t_0$ 开始，以大小为 $h$ 的步长推进求解，直到指定的最终时间 $T$ 结束，从而更新精确解 $y(t_n)$ 的近似值 $y_n$，并得到在 $T$ 处的近似值，我们记为 $y_h(T)$。已知在对 $f$ 和 $y(t)$ 的标准正则性假设下，前向欧拉法的全局离散误差与步长 $h$ 呈线性关系。\n\n你的任务是：\n1. 实现一个函数，该函数使用前向欧拉法，为任意给定的函数 $f(t,y)$、初始条件 $y_0$、初始时间 $t_0$、最终时间 $T$ 和统一的步长 $h$ 计算 $y_h(T)$，并假设 $T - t_0$ 是 $h$ 的整数倍。\n2. 假设欧拉法在 $T$ 处的近似值具有渐近误差展开式 $y_h(T) = y(T) + C h + D h^2 + \\mathcal{O}(h^3)$，其中常数 $C$ 和 $D$ 依赖于 $f$ 和解，但不依赖于 $h$。利用输出 $y_h(T)$ 和 $y_{h/2}(T)$，推导这两个近似值的一个线性组合（其常数权重与 $h$ 无关），该组合能消除主导的 $\\mathcal{O}(h)$ 误差项，从而得到一个对 $y(T)$ 的 $\\mathcal{O}(h^2)$ 精度的估计。然后在代码中实现这个 Richardson 外推估计器。\n3. 对于下面的每个测试用例，计算绝对误差 $\\lvert y_{\\text{extrap}}(T) - y(T) \\rvert$，其中 $y_{\\text{extrap}}(T)$ 是你的外推估计值，$y(T)$ 是时间 $T$ 处的精确解。\n\n使用以下测试套件。在所有情况下，取 $t_0 = 0$ 并使用提供的 $h$，使得 $(T - t_0)/h$ 为整数：\n\n- 测试 1 (理想路径，线性齐次 ODE)：$f(t,y) = y$，$y_0 = 1$，$T = 1$，$h = 0.2$。精确解为 $y(t) = e^{t}$ 在 $t = T$ 处的值。\n- 测试 2 (线性非齐次 ODE)：$f(t,y) = y + t$，$y_0 = 0$，$T = 2$，$h = 0.4$。精确解为 $y(t) = e^{t} - t - 1$ 在 $t = T$ 处的值。\n- 测试 3 (非线性逻辑斯谛增长)：$f(t,y) = r y \\left(1 - \\frac{y}{K}\\right)$，参数为 $r = 1$ 和 $K = 10$，$y_0 = 1$，$T = 3$，$h = 0.5$。精确解为 $y(t) = \\frac{K}{1 + A e^{-r t}}$，其中 $A = \\frac{K - y_0}{y_0}$，在 $t = T$ 处求值。\n- 测试 4 (边界情况，零导数)：$f(t,y) = 0$，$y_0 = 3$，$T = 1$，$h = 0.5$。精确解为常数函数 $y(t) = 3$ 在 $t = T$ 处的值。\n\n你的程序应该：\n- 为每个测试用例实现前向欧拉法以计算 $y_h(T)$ 和 $y_{h/2}(T)$。\n- 使用两个近似值 $y_h(T)$ 和 $y_{h/2}(T)$ 实现推导出的 Richardson 外推估计器，以获得在 $T$ 处的 $\\mathcal{O}(h^2)$ 估计。\n- 计算并记录每个测试用例的绝对误差，四舍五入到十位小数。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表（例如，\"[0.0123456789,0.0000001234,0.0012340000,0.0000000000]\"），列表中的条目是测试 1 到测试 4 的绝对误差，每个都四舍五入到十位小数。", "solution": "问题被评估为有效。\n\n### 步骤 1：提取已知条件\n- **问题类型**：常微分方程 (ODE) 的初值问题 (IVP)。\n- **ODE 形式**：$y'(t) = f(t, y(t))$。\n- **初始条件**：$y(t_0) = y_0$。\n- **数值方法**：前向欧拉法，其中 $y_{n+1} = y_n + h f(t_n, y_n)$。\n- **在最终时间 $T$ 处的近似值**：$y_h(T)$。\n- **渐近误差展开**：$y_h(T) = y(T) + C h + D h^2 + \\mathcal{O}(h^3)$。\n- **约束条件**：$T - t_0$ 是步长 $h$ 的整数倍。\n- **任务 1**：实现一个用于前向欧拉法的函数，以计算 $y_h(T)$。\n- **任务 2**：使用 $y_h(T)$ 和 $y_{h/2}(T)$ 推导并实现一个对 $y(T)$ 具有 $\\mathcal{O}(h^2)$ 精度的 Richardson 外推估计器。\n- **任务 3**：为四个测试用例计算绝对误差 $\\lvert y_{\\text{extrap}}(T) - y(T) \\rvert$。\n- **所有用例的初始时间**：$t_0 = 0$。\n\n- **测试用例 1**：\n  - $f(t,y) = y$\n  - $y_0 = 1$\n  - $T = 1$\n  - $h = 0.2$\n  - 精确解：$y(t) = e^{t}$\n\n- **测试用例 2**：\n  - $f(t,y) = y + t$\n  - $y_0 = 0$\n  - $T = 2$\n  - $h = 0.4$\n  - 精确解：$y(t) = e^{t} - t - 1$\n\n- **测试用例 3**：\n  - $f(t,y) = r y \\left(1 - \\frac{y}{K}\\right)$，其中 $r = 1, K = 10$\n  - $y_0 = 1$\n  - $T = 3$\n  - $h = 0.5$\n  - 精确解：$y(t) = \\frac{K}{1 + A e^{-r t}}$，其中 $A = \\frac{K - y_0}{y_0}$\n\n- **测试用例 4**：\n  - $f(t,y) = 0$\n  - $y_0 = 3$\n  - $T = 1$\n  - $h = 0.5$\n  - 精确解：$y(t) = 3$\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题具有科学依据，是适定且客观的。\n1.  **科学或事实的可靠性**：该问题建立在常微分方程数值分析的基本概念之上。前向欧拉法、其误差分析以及 Richardson 外推法都是标准的、数学上可靠的技术。所提供的常微分方程是教学和研究中使用的经典示例。该问题没有任何科学或事实错误。\n2.  **适定性**：该问题是适定的。对于每个测试用例，函数 $f(t,y)$ 都足够光滑（关于 $y$ 是 Lipschitz 连续的），这保证了该初值问题解的存在性和唯一性。任务定义清晰，并提供了所有必要的数据（初始条件、参数、时间区间）。\n3.  **客观性**：语言精确且无偏见。任务是定量的，需要进行具体的计算，没有主观解释的余地。\n4.  **完整性**：该问题是自包含的。它指定了用于误差比较的常微分方程、初始条件、步长、最终时间以及精确解。约束条件 $(T - t_0)/h$ 是一个整数简化了实现过程并避免了歧义。\n\n### 步骤 3：结论与行动\n该问题是 **有效的**。将提供一个完整的解决方案。\n\n### 基于原理的解决方案\n解决方案分三个阶段展开：首先，实现前向欧拉法；其次，推导 Richardson 外推公式；第三，将这些方法应用于指定的测试用例以计算所需的误差。\n\n**1. 前向欧拉法**\n前向欧拉法是求解形如 $y'(t) = f(t, y(t))$ 且满足 $y(t_0) = y_0$ 的初值问题的一阶数值方法。它在离散时间点 $t_n = t_0 + n h$（其中 $h$ 是步长）上近似连续解 $y(t)$。该方法由 $y(t_{n+1})$ 在 $t_n$ 附近的一阶泰勒展开推导得出：\n$y(t_{n+1}) = y(t_n) + h y'(t_n) + \\mathcal{O}(h^2) = y(t_n) + h f(t_n, y(t_n)) + \\mathcal{O}(h^2)$。\n通过忽略 $\\mathcal{O}(h^2)$ 项，我们得到近似值 $y_n \\approx y(t_n)$ 的迭代公式：\n$$y_{n+1} = y_n + h f(t_n, y_n)$$\n从初始条件 $y_0$ 开始，我们可以对 $n = 0, 1, 2, \\dots, N-1$（其中 $N = (T-t_0)/h$）迭代应用此公式，以找到一个近似值 $y_N \\approx y(T)$。这就定义了函数 $y_h(T)$。\n\n**2. Richardson 外推法**\nRichardson 外推法是一种提高数值近似精度的通用技术。我们已知前向欧拉法得到的近似值 $y_h(T)$ 具有渐近误差展开式：\n$$y_h(T) = y(T) + C h + D h^2 + \\mathcal{O}(h^3)$$\n这里，$y(T)$ 是精确解，而 $C$ 和 $D$ 是依赖于函数 $f$ 及其导数但不依赖于步长 $h$ 的常数。\n\n如果我们使用减半的步长 $h/2$ 再次计算近似值，公式变为：\n$$y_{h/2}(T) = y(T) + C \\left(\\frac{h}{2}\\right) + D \\left(\\frac{h}{2}\\right)^2 + \\mathcal{O}(h^3)$$\n$$y_{h/2}(T) = y(T) + \\frac{1}{2} C h + \\frac{1}{4} D h^2 + \\mathcal{O}(h^3)$$\n我们的目标是找到 $y_h(T)$ 和 $y_{h/2}(T)$ 的一个线性组合，我们将其记为 $y_{\\text{extrap}}(T)$，它能提供一个更精确的 $y(T)$ 的估计。设 $y_{\\text{extrap}}(T) = \\alpha y_h(T) + \\beta y_{h/2}(T)$。代入误差展开式：\n$$y_{\\text{extrap}}(T) = \\alpha \\left(y(T) + C h + D h^2\\right) + \\beta \\left(y(T) + \\frac{1}{2} C h + \\frac{1}{4} D h^2\\right) + \\mathcal{O}(h^3)$$\n$$y_{\\text{extrap}}(T) = (\\alpha + \\beta) y(T) + \\left(\\alpha + \\frac{\\beta}{2}\\right) C h + \\left(\\alpha + \\frac{\\beta}{4}\\right) D h^2 + \\mathcal{O}(h^3)$$\n为了得到一个对 $y(T)$ 的 $\\mathcal{O}(h^2)$ 精度的估计，我们要求 $y(T)$ 的系数为 $1$，并且主导误差项 $Ch$ 的系数为 $0$。这给出了一个关于 $\\alpha$ 和 $\\beta$ 的双线性方程组：\n1. $\\alpha + \\beta = 1$\n2. $\\alpha + \\frac{\\beta}{2} = 0$\n从方程 (2)，我们得到 $\\alpha = -\\beta/2$。将其代入方程 (1) 得出 $-\\beta/2 + \\beta = 1$，化简为 $\\beta/2 = 1$，所以 $\\beta = 2$。因此，$\\alpha = -1$。\n因此，外推估计器为：\n$$y_{\\text{extrap}}(T) = 2 y_{h/2}(T) - y_h(T)$$\n让我们验证这个新估计的误差：\n$$y_{\\text{extrap}}(T) - y(T) = (2 y_{h/2}(T) - y_h(T)) - y(T)$$\n$$= \\left(2\\left(y(T) + \\frac{1}{2}Ch + \\frac{1}{4}Dh^2\\right) - \\left(y(T) + Ch + Dh^2\\right)\\right) - y(T) + \\mathcal{O}(h^3)$$\n$$= (2y(T) + Ch + \\frac{1}{2}Dh^2) - y(T) - Ch - Dh^2 - y(T) + \\mathcal{O}(h^3)$$\n$$= (2-1-1)y(T) + (1-1)Ch + (\\frac{1}{2}-1)Dh^2 + \\mathcal{O}(h^3) = -\\frac{1}{2} D h^2 + \\mathcal{O}(h^3)$$\n误差确实是 $h^2$ 阶的，因此该方法成功地消除了主导误差项。\n\n**3. 计算步骤**\n对于四个测试用例中的每一个，应用以下算法：\n1.  定义函数 $f(t,y)$、初始条件 $y_0, t_0$、最终时间 $T$ 和步长 $h$。\n2.  实现一个函数 `forward_euler(f, y0, t0, T, h)`，该函数执行迭代的欧拉更新并返回在时间 $T$ 处的最终近似值。步数 $N$ 计算为整数 `(T - t0) / h`。\n3.  用给定的步长 $h$ 计算近似值：$A_h = \\text{forward_euler}(f, y_0, t_0, T, h)$。\n4.  用减半的步长 $h/2$ 计算近似值：$A_{h/2} = \\text{forward_euler}(f, y_0, t_0, T, h/2)$。\n5.  计算 Richardson 外推值：$y_{\\text{extrap}}(T) = 2 A_{h/2} - A_h$。\n6.  使用为特定测试用例提供的公式计算精确解 $y(T)$。\n7.  计算绝对误差：$E = \\lvert y_{\\text{extrap}}(T) - y(T) \\rvert$。\n8.  测试用例的最终结果是此误差，四舍五入到十位小数。对所有测试用例重复此过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes absolute errors for Richardson-extrapolated Euler method solutions\n    for a suite of ODE test cases.\n    \"\"\"\n\n    def forward_euler(f, y0, t0, T, h):\n        \"\"\"\n        Computes the solution of an IVP y'(t) = f(t, y) with y(t0) = y0 at time T\n        using the forward Euler method with step size h.\n        \"\"\"\n        t = t0\n        y = y0\n        \n        # The problem statement guarantees (T - t0) / h is an integer.\n        # Using int() directly is safe, but rounding is more robust for floats.\n        num_steps = int(round((T - t0) / h))\n\n        for _ in range(num_steps):\n            y = y + h * f(t, y)\n            t = t + h\n        \n        return y\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"f\": lambda t, y: y,\n            \"y0\": 1.0,\n            \"t0\": 0.0,\n            \"T\": 1.0,\n            \"h\": 0.2,\n            \"exact_sol\": lambda t: np.exp(t)\n        },\n        {\n            \"f\": lambda t, y: y + t,\n            \"y0\": 0.0,\n            \"t0\": 0.0,\n            \"T\": 2.0,\n            \"h\": 0.4,\n            \"exact_sol\": lambda t: np.exp(t) - t - 1.0\n        },\n        {\n            \"f\": lambda t, y: 1.0 * y * (1.0 - y / 10.0), # r=1, K=10\n            \"y0\": 1.0,\n            \"t0\": 0.0,\n            \"T\": 3.0,\n            \"h\": 0.5,\n            \"exact_sol\": lambda t: 10.0 / (1.0 + ((10.0 - 1.0) / 1.0) * np.exp(-1.0 * t))\n        },\n        {\n            \"f\": lambda t, y: 0.0,\n            \"y0\": 3.0,\n            \"t0\": 0.0,\n            \"T\": 1.0,\n            \"h\": 0.5,\n            \"exact_sol\": lambda t: 3.0\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        f = case[\"f\"]\n        y0 = case[\"y0\"]\n        t0 = case[\"t0\"]\n        T = case[\"T\"]\n        h = case[\"h\"]\n        exact_sol_func = case[\"exact_sol\"]\n\n        # 1. Compute approximations with step sizes h and h/2\n        y_h = forward_euler(f, y0, t0, T, h)\n        y_h_half = forward_euler(f, y0, t0, T, h / 2.0)\n\n        # 2. Apply Richardson extrapolation\n        y_extrap = 2.0 * y_h_half - y_h\n\n        # 3. Compute the exact solution\n        y_exact = exact_sol_func(T)\n        \n        # 4. Compute the absolute error\n        abs_error = abs(y_extrap - y_exact)\n        \n        results.append(abs_error)\n\n    # Format the results as strings rounded to 10 decimal places\n    # The f-string formatting ensures trailing zeros as in the example.\n    # The rounding prior to formatting correctly handles cases near the rounding boundary.\n    results_str = [f\"{round(res, 10):.10f}\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "3226253"}]}