{"hands_on_practices": [{"introduction": "我们首先从加权雅可比法（Weighted Jacobi method）这一基础迭代技术开始。在第一个练习中，我们将探索两种不同的策略来估算矩阵的谱，以确定最优松弛参数 $\\omega$。通过这个练习，你将深入理解在计算简单的分析界（如格什戈林圆盘）与计算成本更高但更精确的迭代估计算法（如幂法）之间存在的实际权衡。[@problem_id:3266561]", "problem": "考虑一个线性系统，其包含一个对称正定 (SPD) 矩阵 $A \\in \\mathbb{R}^{n \\times n}$，该矩阵由带狄利克雷边界条件的泊松方程的标准有限差分法离散化产生。令 $D$ 表示 $A$ 的对角部分，并定义 $B = D^{-1} A$。对于加权雅可比（也称为预处理理查森）迭代法，\n$$\n\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} + \\omega D^{-1} \\left(\\mathbf{b} - A \\mathbf{x}^{(k)}\\right),\n$$\n其误差传播由迭代矩阵 $M_\\omega = I - \\omega B$ 控制，其中 $I$ 是单位矩阵，$\\omega  0$ 是松弛参数。\n\n您将比较两种选择 $\\omega$ 的策略，并分析它们预测的收敛速率中的误差：\n- 一种基于 Gershgorin 的策略，该策略使用 $B$ 的谱上的 Gershgorin 圆盘界来选择 $\\omega$。\n- 一种基于瑞利商的策略，该策略使用迭代瑞利商来估计 $B$ 的极值特征值。\n\n仅使用以下基本假设和事实：\n- 在所提供的测试用例中，$A$ 是对称正定 (SPD) 且严格对角占优的，其对角线为常数，因此对于某个 $c  0$ 有 $D = c I$，这使得 $B$ 也是对称且正定的。\n- 迭代的收敛性由 $M_\\omega$ 的谱半径 $\\rho(M_\\omega)$ 决定。\n- Gershgorin 圆盘定理保证 $B$ 的所有特征值 $\\lambda$ 都位于圆盘 $\\{ z \\in \\mathbb{C} : |z - b_{ii}| \\leq r_i \\}$ 的并集中，其中 $b_{ii}$ 是 $B$ 在第 $i$ 行的对角元素，$r_i = \\sum_{j \\neq i} |b_{ij}|$ 是对应的非对角元素绝对值之和。\n- 对于对称矩阵 $B$，非零向量 $\\mathbf{x}$ 的瑞利商为 $R_B(\\mathbf{x}) = \\dfrac{\\mathbf{x}^\\top B \\mathbf{x}}{\\mathbf{x}^\\top \\mathbf{x}}$，其在所有非零 $\\mathbf{x}$ 上的极值是 $B$ 的最小和最大特征值。\n\n每个测试用例的任务：\n1. 根据测试用例的规范构造 $A$ 并形成 $B = D^{-1} A$。\n2. 使用\n   $$\n   L_G = \\max\\left(0, \\min_i \\left(b_{ii} - r_i\\right)\\right), \\quad U_G = \\max_i \\left(b_{ii} + r_i\\right).\n   $$\n   公式计算 $B$ 的特征值的 Gershgorin 下界和上界。使用这些界来选择一个松弛参数 $\\omega_G$，以最小化 $\\rho(M_\\omega)$ 的一个形如 $\\max\\left(|1 - \\omega L_G|, |1 - \\omega U_G|\\right)$ 的上界。\n3. 使用迭代瑞利商估计 $B$ 的最小和最大特征值：\n   - 使用幂迭代法估计 $\\lambda_{\\max}(B)$，并在最终向量 $\\mathbf{x}$ 上计算 $R_B(\\mathbf{x})$。\n   - 使用反幂迭代法（求解以 $B$ 为系数矩阵的线性系统）来估计 $\\lambda_{\\min}(B)$，并在最终向量 $\\mathbf{y}$ 上计算 $R_B(\\mathbf{y})$。\n   选择一个松弛参数 $\\omega_R$，以最小化代理 $\\max\\left(|1 - \\omega \\widehat{\\lambda}_{\\min}|, |1 - \\omega \\widehat{\\lambda}_{\\max}|\\right)$。\n4. 对于每种策略，计算预测的收敛速率：\n   - Gershgorin 预测：$\\rho_{\\text{pred},G} = \\max\\left(|1 - \\omega_G L_G|, |1 - \\omega_G U_G|\\right)$。\n   - Rayleigh 预测：$\\rho_{\\text{pred},R} = \\max\\left(|1 - \\omega_R \\widehat{\\lambda}_{\\min}|, |1 - \\omega_R \\widehat{\\lambda}_{\\max}|\\right)$。\n5. 使用 $B$ 的真实特征值 $\\{\\lambda_i\\}$，为每个选定的 $\\omega$ 计算实际收敛速率：\n   $$\n   \\rho_{\\text{actual}}(\\omega) = \\max_i \\left|1 - \\omega \\lambda_i\\right|.\n   $$\n6. 为每种策略计算预测收敛速率与实际收敛速率之间的绝对误差：\n   $$\n   \\varepsilon_G = \\left|\\rho_{\\text{pred},G} - \\rho_{\\text{actual}}(\\omega_G)\\right|, \\quad \\varepsilon_R = \\left|\\rho_{\\text{pred},R} - \\rho_{\\text{actual}}(\\omega_R)\\right|.\n   $$\n7. 同时，使用 $B$ 的真实极值特征值计算最小化 $\\rho(M_\\omega)$ 的真实最优松弛参数 $\\omega_\\star$，并将其与 $\\omega_G$ 和 $\\omega_R$ 一起报告。\n\n测试套件：\n- 案例 1（理想情况）：一维泊松矩阵 $A \\in \\mathbb{R}^{10 \\times 10}$，对角线元素为 $2$，第一副对角线和第一超对角线元素为 $-1$。\n- 案例 2（小尺寸边界条件）：如上定义的一维泊松矩阵 $A \\in \\mathbb{R}^{3 \\times 3}$。\n- 案例 3（二维离散化）：用于 $6 \\times 6$ 网格的二维泊松矩阵 $A \\in \\mathbb{R}^{36 \\times 36}$，采用五点模板，即对角线元素为 $4$，每个相邻耦合为 $-1$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个列表，每个测试用例对应一个条目。每个条目必须是列表\n  $[\\omega_G, \\omega_R, \\omega_\\star, \\varepsilon_G, \\varepsilon_R]$，\n  按此顺序，使用无单位的实数。整个输出必须是单个逗号分隔的列表，并用方括号括起来，例如 \n  $[[\\cdots],[\\cdots],[\\cdots]]$。", "solution": "用户提供了一个来自数值线性代数领域的有效且适定的问题陈述。任务是比较两种为加权雅可比迭代法选择松弛参数 $\\omega$ 的策略，该方法应用于源自泊松方程的线性系统。\n\n### 问题表述\n\n我们考虑线性系统 $A\\mathbf{x}=\\mathbf{b}$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是一个对称正定 (SPD) 矩阵。加权雅可比迭代法由下式给出：\n$$\n\\mathbf{x}^{(k+1)} = \\mathbf{x}^{(k)} + \\omega D^{-1} \\left(\\mathbf{b} - A \\mathbf{x}^{(k)}\\right)\n$$\n其中 $D$ 是 $A$ 的对角部分，$\\omega  0$ 是松弛参数。此迭代的收敛性由迭代矩阵 $M_\\omega = I - \\omega B$ 的谱半径决定，其中 $B = D^{-1}A$，$I$ 是单位矩阵。目标是选择 $\\omega$ 以最小化 $\\rho(M_\\omega)$。\n\n$M_\\omega$ 的特征值为 $\\mu_i = 1 - \\omega \\lambda_i$，其中 $\\{\\lambda_i\\}_{i=1}^n$ 是 $B$ 的特征值。因此，谱半径为：\n$$\n\\rho(M_\\omega) = \\max_i |1 - \\omega \\lambda_i|\n$$\n由于 $A$ 是对称正定的且其对角元素为正，因此 $D$ 也是对称正定的。问题陈述指明，对于标量 $c0$，有 $D=cI$，因此 $B = \\frac{1}{c}A$。由于 $A$ 是对称正定的，$B$ 也是对称正定的，其特征值 $\\lambda_i$ 均为实数且为正。令 $\\lambda_{\\min}$ 和 $\\lambda_{\\max}$ 分别为 $B$ 的最小和最大特征值。谱半径可以表示为：\n$$\n\\rho(M_\\omega) = \\max \\left( |1 - \\omega \\lambda_{\\min}|, |1 - \\omega \\lambda_{\\max}| \\right)\n$$\n为了最小化该量，我们设置 $\\max$ 函数的两个参数大小相等但符号相反：\n$$\n1 - \\omega \\lambda_{\\min} = -(1 - \\omega \\lambda_{\\max}) = -1 + \\omega \\lambda_{\\max}\n$$\n求解 $\\omega$ 可得到最优松弛参数：\n$$\n\\omega_\\star = \\frac{2}{\\lambda_{\\min} + \\lambda_{\\max}}\n$$\n将此代回谱半径的表达式，得到可能的最小谱半径，即最优收敛速率：\n$$\n\\rho(M_{\\omega_\\star}) = \\frac{\\lambda_{\\max} - \\lambda_{\\min}}{\\lambda_{\\max} + \\lambda_{\\min}}\n$$\n问题的核心是比较两种估计 $\\lambda_{\\min}$ 和 $\\lambda_{\\max}$ 以找到合适 $\\omega$ 的策略。\n\n### 策略 1：Gershgorin 圆盘界\n\nGershgorin 圆盘定理指出，$B$ 的每个特征值都位于圆盘 $G_i = \\{ z \\in \\mathbb{C} : |z - b_{ii}| \\leq r_i \\}$ 的并集中，其中 $r_i = \\sum_{j \\neq i} |b_{ij}|$。由于 $B$ 是对称的，其特征值是实数，因此它们位于区间 $[b_{ii} - r_i, b_{ii} + r_i]$ 的并集中。这为 $B$ 的谱提供了界：\n$$\n\\lambda_{\\min} \\geq \\min_i (b_{ii} - r_i) \\quad \\text{和} \\quad \\lambda_{\\max} \\leq \\max_i (b_{ii} + r_i)\n$$\n问题将基于 Gershgorin 的极值特征值估计定义为 $L_G = \\max(0, \\min_i(b_{ii} - r_i))$ 和 $U_G = \\max_i(b_{ii} + r_i)$。这些估计导致了松弛参数 $\\omega_G$ 的选择：\n$$\n\\omega_G = \\frac{2}{L_G + U_G}\n$$\n该策略的预测收敛速率为：\n$$\n\\rho_{\\text{pred},G} = \\frac{U_G - L_G}{U_G + L_G}\n$$\n\n### 策略 2：瑞利商估计\n\n该策略使用迭代方法直接估计极值特征值。\n1.  **$\\lambda_{\\max}$ 的幂迭代**：将幂法应用于 $B$。从一个随机向量 $\\mathbf{x}_0$ 开始，迭代 $\\mathbf{x}_{k+1} = B\\mathbf{x}_k / \\|B\\mathbf{x}_k\\|_2$ 产生一个向量序列，该序列收敛于与主特征值 $\\lambda_{\\max}$ 对应的特征向量。然后使用最终迭代向量 $\\mathbf{x}_f$ 的瑞利商计算估计值 $\\widehat{\\lambda}_{\\max}$：\n    $$\n    \\widehat{\\lambda}_{\\max} = R_B(\\mathbf{x}_f) = \\frac{\\mathbf{x}_f^\\top B \\mathbf{x}_f}{\\mathbf{x}_f^\\top \\mathbf{x}_f}\n    $$\n2.  **$\\lambda_{\\min}$ 的反幂迭代**：应用反幂法寻找 $B$ 的最小特征值。这等同于对 $B^{-1}$ 应用幂法。从一个随机向量 $\\mathbf{y}_0$ 开始，迭代 $\\mathbf{y}_{k+1} = B^{-1}\\mathbf{y}_k / \\|B^{-1}\\mathbf{y}_k\\|_2$ 收敛于 $B$ 的最小特征值 $\\lambda_{\\min}$ 对应的特征向量。在每一步中，求解一个线性系统 $B\\mathbf{y}_{k+1}' = \\mathbf{y}_k$，然后进行归一化。使用最终迭代向量 $\\mathbf{y}_f$ 的瑞利商计算估计值 $\\widehat{\\lambda}_{\\min}$：\n    $$\n    \\widehat{\\lambda}_{\\min} = R_B(\\mathbf{y}_f) = \\frac{\\mathbf{y}_f^\\top B \\mathbf{y}_f}{\\mathbf{y}_f^\\top \\mathbf{y}_f}\n    $$\n这些估计产生了松弛参数 $\\omega_R$ 和预测速率 $\\rho_{\\text{pred},R}$：\n$$\n\\omega_R = \\frac{2}{\\widehat{\\lambda}_{\\min} + \\widehat{\\lambda}_{\\max}}, \\quad \\rho_{\\text{pred},R} = \\frac{\\widehat{\\lambda}_{\\max} - \\widehat{\\lambda}_{\\min}}{\\widehat{\\lambda}_{\\min} + \\widehat{\\lambda}_{\\max}}\n$$\n\n### 分析与误差计算\n\n对于每个测试用例，我们执行以下计算：\n1.  构造矩阵 $A$ 并形成 $B = D^{-1}A$。\n2.  使用 Gershgorin 策略计算 $\\omega_G$ 和 $\\rho_{\\text{pred},G}$。\n3.  使用瑞利商策略计算 $\\omega_R$ 和 $\\rho_{\\text{pred},R}$。\n4.  使用数值特征值求解器计算 $B$ 的真实极值特征值，记为 $\\lambda_{\\min}^{\\text{true}}$ 和 $\\lambda_{\\max}^{\\text{true}}$。这些值决定了真实最优参数 $\\omega_\\star = \\frac{2}{\\lambda_{\\min}^{\\text{true}} + \\lambda_{\\max}^{\\text{true}}}$。\n5.  使用 $B$ 的全谱计算所选参数 $\\omega_G$ 和 $\\omega_R$ 的实际收敛速率：\n    $$\n    \\rho_{\\text{actual}}(\\omega_G) = \\max_i |1 - \\omega_G \\lambda_i^{\\text{true}}|\n    $$\n    $$\n    \\rho_{\\text{actual}}(\\omega_R) = \\max_i |1 - \\omega_R \\lambda_i^{\\text{true}}|\n    $$\n6.  最后，计算预测速率中的绝对误差：\n    $$\n    \\varepsilon_G = |\\rho_{\\text{pred},G} - \\rho_{\\text{actual}}(\\omega_G)|\n    $$\n    $$\n    \\varepsilon_R = |\\rho_{\\text{pred},R} - \\rho_{\\text{actual}}(\\omega_R)|\n    $$\n\n将此过程应用于三个测试用例，这些用例涉及来自一维和二维泊松方程有限差分法离散化的矩阵。结果提供了两种估计策略准确性的定量比较。Gershgorin 界虽然易于计算，但通常是悲观的，导致对收敛速率的估计不够准确。相比之下，迭代瑞利商方法虽然计算量更大，但通常能产生高度准确的极值特征值估计，从而更精确地预测收敛行为。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef construct_1d_poisson(n):\n    \"\"\"Constructs the n x n 1D Poisson matrix.\"\"\"\n    A = np.zeros((n, n), dtype=float)\n    np.fill_diagonal(A, 2.0)\n    if n  1:\n        off_diag = np.full(n - 1, -1.0)\n        A += np.diag(off_diag, k=1)\n        A += np.diag(off_diag, k=-1)\n    return A\n\ndef construct_2d_poisson(m):\n    \"\"\"Constructs the n x n (n=m*m) 2D Poisson matrix for an m x m grid.\"\"\"\n    n = m * m\n    A_1d = construct_1d_poisson(m)\n    np.fill_diagonal(A_1d, 2.0)\n    Im = np.eye(m)\n    # The standard 5-point stencil Laplacian is kron(I, A_1d_lap) + kron(A_1d_lap, I).\n    # Since A_1d_lap has 2 on the diagonal, this results in 4 on the main diagonal.\n    A = np.kron(Im, A_1d) + np.kron(A_1d, Im)\n    return A\n\ndef gershgorin_strategy(B):\n    \"\"\"Computes omega and predicted rate using Gershgorin bounds.\"\"\"\n    n = B.shape[0]\n    b_ii = np.diag(B)\n    r_i = np.sum(np.abs(B), axis=1) - np.abs(b_ii)\n    \n    L_g = max(0.0, np.min(b_ii - r_i))\n    U_g = np.max(b_ii + r_i)\n    \n    # Handle case where L_g + U_g is zero\n    if L_g + U_g == 0:\n        omega_g = 1.0 # Default value, though this case is unlikely for SPD matrices\n        rho_pred_g = 1.0\n    else:\n        omega_g = 2.0 / (L_g + U_g)\n        rho_pred_g = (U_g - L_g) / (L_g + U_g)\n        \n    return omega_g, rho_pred_g\n\ndef rayleigh_strategy(B, n, num_iter=100):\n    \"\"\"Computes omega and predicted rate using iterative Rayleigh quotients.\"\"\"\n    # Ensure a non-zero random start vector\n    np.random.seed(42) # for reproducibility\n    x = np.random.rand(n)\n    if np.linalg.norm(x) == 0:\n         x = np.ones(n)\n    x /= np.linalg.norm(x)\n\n    # Power iteration for lambda_max\n    for _ in range(num_iter):\n        Bx = B @ x\n        x = Bx / np.linalg.norm(Bx)\n    lambda_max_hat = (x.T @ B @ x) # x.T @ x is 1\n\n    # Inverse power iteration for lambda_min\n    y = np.random.rand(n)\n    if np.linalg.norm(y) == 0:\n         y = np.ones(n)\n    y /= np.linalg.norm(y)\n\n    for _ in range(num_iter):\n        try:\n            y_new = np.linalg.solve(B, y)\n        except np.linalg.LinAlgError:\n            # If B is singular, lambda_min is 0.\n            # This shouldn't happen for the given problem context (SPD matrices).\n            lambda_min_hat = 0.0\n            break\n        y = y_new / np.linalg.norm(y_new)\n    else: # Only runs if loop completes without break\n        lambda_min_hat = (y.T @ B @ y) # y.T @ y is 1\n\n    # Handle case where sum is zero\n    if lambda_min_hat + lambda_max_hat == 0:\n        omega_r = 1.0\n        rho_pred_r = 1.0\n    else:\n        omega_r = 2.0 / (lambda_min_hat + lambda_max_hat)\n        rho_pred_r = (lambda_max_hat - lambda_min_hat) / (lambda_min_hat + lambda_max_hat)\n        \n    return omega_r, rho_pred_r\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        {'n': 10, 'grid_dim': None}, # Case 1\n        {'n': 3, 'grid_dim': None},  # Case 2\n        {'n': 36, 'grid_dim': 6}     # Case 3\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        n = case['n']\n        grid_dim = case['grid_dim']\n        # Step 1: Construct A and B\n        if grid_dim is None:  # 1D case\n            A = construct_1d_poisson(n)\n            c = 2.0\n        else:  # 2D case\n            A = construct_2d_poisson(grid_dim)\n            c = 4.0\n        B = A / c\n\n        # Step 2: Gershgorin Strategy\n        omega_g, rho_pred_g = gershgorin_strategy(B)\n\n        # Step 3: Rayleigh-Quotient Strategy\n        omega_r, rho_pred_r = rayleigh_strategy(B, n)\n        \n        # Step 4: True Optimal Parameter and Actual Rates\n        true_eigenvalues = np.linalg.eigvalsh(B)\n        lambda_min_true = np.min(true_eigenvalues)\n        lambda_max_true = np.max(true_eigenvalues)\n        \n        # Guard against division by zero if matrix is zero matrix\n        if lambda_min_true + lambda_max_true == 0:\n            omega_star = 1.0\n        else:\n            omega_star = 2.0 / (lambda_min_true + lambda_max_true)\n        \n        # Step 5: Actual Convergence Rates\n        rho_actual_g = np.max(np.abs(1.0 - omega_g * true_eigenvalues))\n        rho_actual_r = np.max(np.abs(1.0 - omega_r * true_eigenvalues))\n        \n        # Step 6: Absolute Errors\n        err_g = np.abs(rho_pred_g - rho_actual_g)\n        err_r = np.abs(rho_pred_r - rho_actual_r)\n        \n        # Step 7: Collate results\n        all_results.append([omega_g, omega_r, omega_star, err_g, err_r])\n\n    # Format and print the final output\n    # Example format: [[1.00, 1.01, 1.02, 0.01, 0.001], [....]]\n    output_str = \"[\" + \",\".join([f\"[{','.join(f'{val:.8f}' for val in res)}]\" for res in all_results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3266561"}, {"introduction": "在掌握了简单的雅可比法之后，我们转向更广泛应用的逐次超松弛（Successive Over-Relaxation, SOR）方法。这个练习将揭示一个关键且常令人意外的特性：最优松弛参数 $\\omega^\\star$ 会如何根据线性方程组中方程的顺序而发生显著变化。通过对比不同的排序方案，你将更深刻地体会到，决定迭代性能的不仅是矩阵的特征值，还有矩阵分裂的结构。[@problem_id:3266531]", "problem": "考虑线性系统 $A \\mathbf{x} = \\mathbf{b}$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是一个对称正定 (SPD) 矩阵。求解 $A \\mathbf{x} = \\mathbf{b}$ 的迭代方法通常始于分解 $A = D - L - U$，其中 $D$ 是 $A$ 的对角部分，$L$ 是 $A$ 的严格下三角部分（选择符号以使 $A = D - L - U$ 成立），$U$ 是具有相同符号约定的严格上三角部分。逐次超松弛 (SOR) 方法通过使用松弛参数 $\\omega \\in (0,2)$ 对高斯-赛德尔 (Gauss–Seidel) 步骤进行加权来更新迭代值，其线性误差传播算子取决于 $\\omega$ 和分裂 $A = D - L - U$。通过置换矩阵 $P$ 对未知数进行置换，会将系统重排为 $\\tilde{A} = P A P^{\\top}$，并引入一个相对于新排序定义的新分裂 $\\tilde{A} = \\tilde{D} - \\tilde{L} - \\tilde{U}$。\n\n从分解 $A = D - L - U$ 和作为加权高斯-赛德尔迭代的 SOR 方法的定义出发，推导误差传播算子作为依赖于分裂和松弛参数的函数 $T(\\omega)$ 的表达式。然后，通过计算其在 $\\omega \\in (0,2)$ 上的谱半径 $\\rho(T(\\omega))$，确定一个数值最优的松弛参数 $\\omega^\\star$，使得 $\\rho(T(\\omega))$ 最小。\n\n您必须构建并分析以下由矩阵和置换组成的测试套件。对于每种情况，您必须：\n1. 构造矩阵 $A$。\n2. 应用指定的置换向量 $p$，通过 $\\tilde{A}_{ij} = A_{p(i), p(j)}$ 获得 $\\tilde{A}$。\n3. 从 $\\tilde{A}$ 构造 $\\tilde{D}$、$\\tilde{L}$ 和 $\\tilde{U}$，使得 $\\tilde{A} = \\tilde{D} - \\tilde{L} - \\tilde{U}$。\n4. 从第一性原理推导 $T(\\omega)$，并在开区间 $(0,2)$ 上以步长 $0.01$ 的均匀网格计算 $\\omega$ 的谱半径 $\\rho(T(\\omega))$，并选择使 $\\rho(T(\\omega))$ 最小的网格值作为 $\\omega^\\star$。\n5. 将 $\\omega^\\star$ 和最小谱半径 $\\min_{\\omega} \\rho(T(\\omega))$ 报告为四舍五入到六位小数的浮点数。\n\n测试套件：\n- 情况 1（二维泊松问题，字典序）：$A$ 是在带有狄利克雷 (Dirichlet) 边界条件的 $N \\times N$ 内部网格上，通过五点有限差分拉普拉斯算子得到的 $N^2 \\times N^2$ 对称正定矩阵，其中 $N = 6$。对角线元素为 $4$，每个内部点以 $-1$ 与其四个网格邻居耦合。置换为单位置换（字典序，行主序）。\n- 情况 2（二维泊松问题，红黑排序）：$A$ 与情况 1 相同。该置换首先列出所有 $(i+j)$ 为偶数的网格点，然后列出所有 $(i+j)$ 为奇数的网格点，其中 $i$ 和 $j$ 是从零开始的行和列索引。\n- 情况 3（一维泊松问题，字典序）：$A$ 是通过在一维情况下使用带狄利克雷 (Dirichlet) 边界条件的有限差分拉普拉斯算子得到的 $n \\times n$ 对称正定三对角矩阵，其中 $n = 20$，对角线元素为 $2$，第一副对角线和第一超对角线元素为 $-1$。置换为单位置换。\n- 情况 4（一维泊松问题，奇偶排序）：$A$ 与情况 3 相同。该置换首先列出所有偶数索引，然后列出所有奇数索引（从零开始）。\n- 情况 5（对角对称正定矩阵，单位排序）：$A$ 是一个大小为 $10 \\times 10$ 的对角矩阵 $\\operatorname{diag}(1,2,\\dots,10)$。置换为单位置换。\n- 情况 6（对角对称正定矩阵，随机排序）：$A$ 与情况 5 相同。置换是 $\\{0,1,\\dots,9\\}$ 的任意一个固定的非平凡置换。\n\n您的程序必须实现以上步骤，并生成单行输出，其中包含一个用方括号括起来的逗号分隔的浮点数列表，顺序如下：\n$[\\omega^\\star_{1}, \\rho_{\\min,1}, \\omega^\\star_{2}, \\rho_{\\min,2}, \\omega^\\star_{3}, \\rho_{\\min,3}, \\omega^\\star_{4}, \\rho_{\\min,4}, \\omega^\\star_{5}, \\rho_{\\min,5}, \\omega^\\star_{6}, \\rho_{\\min,6}]$。\n\n所有数字必须报告为四舍五入到六位小数的浮点数。此问题不涉及任何物理单位或角度；请勿在输出中包含任何单位。您的实现必须是一个完整的、可运行的程序，不需要任何输入，并且只使用指定的库。\n\n目标是构造一个例子，其中最优松弛参数强烈依赖于未知数的置换，并通过取严格下/上三角部分操作相对于重排序的非交换性来解释这种行为，这种非交换性改变了 SOR 迭代算子及其谱。", "solution": "所提出的问题是数值线性代数中一个有效且适定的练习。它具有科学依据，是客观的，并包含了为每个测试用例推导出唯一解所需的所有必要信息。其目标是分析用于求解线性系统 $A \\mathbf{x} = \\mathbf{b}$ 的逐次超松弛 (SOR) 迭代方法，重点关注未知数的排序如何影响最优松弛参数 $\\omega^\\star$ 的选择。\n\n我们首先从第一性原理推导 SOR 迭代矩阵，即误差传播算子 $T(\\omega)$。出发点是线性系统 $A \\mathbf{x} = \\mathbf{b}$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是一个给定矩阵。SOR 方法基于将矩阵 $A$ 分裂为其对角、严格下三角和严格上三角部分。根据问题陈述，我们将此分裂定义为 $A = D - L - U$，其中 $D$ 是包含 $A$ 对角线元素的对角矩阵，$-L$ 是 $A$ 的严格下三角部分，$-U$ 是 $A$ 的严格上三角部分。\n\n在第 $k+1$ 次迭代中，解向量的第 $i$ 个分量（表示为 $x_i^{(k+1)}$）的 SOR 更新法则是前一次迭代值 $x_i^{(k)}$ 和高斯-赛德尔 (Gauss-Seidel) 更新的加权平均值：\n$$\nx_i^{(k+1)} = (1-\\omega) x_i^{(k)} + \\frac{\\omega}{a_{ii}} \\left( b_i - \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \\right)\n$$\n其中 $\\omega \\in (0,2)$ 是松弛参数。为了以矩阵形式表示，我们可以为所有分量 $i=1, \\dots, n$ 重新排列该方程：\n$$\na_{ii} x_i^{(k+1)} + \\omega \\sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} = (1-\\omega) a_{ii} x_i^{(k)} - \\omega \\sum_{j=i+1}^{n} a_{ij} x_j^{(k)} + \\omega b_i\n$$\n使用矩阵分裂的定义，求和可以用矩阵 $L$ 和 $U$ 来表示。左侧是 $(D - \\omega L) \\mathbf{x}^{(k+1)}$，右侧是 $((1-\\omega)D + \\omega U) \\mathbf{x}^{(k)} + \\omega \\mathbf{b}$。这给出了 SOR 迭代的矩阵形式：\n$$\n(D - \\omega L) \\mathbf{x}^{(k+1)} = ((1-\\omega)D + \\omega U) \\mathbf{x}^{(k)} + \\omega \\mathbf{b}\n$$\n因此，下一次的迭代值 $\\mathbf{x}^{(k+1)}$ 是：\n$$\n\\mathbf{x}^{(k+1)} = (D - \\omega L)^{-1} ((1-\\omega)D + \\omega U) \\mathbf{x}^{(k)} + \\omega (D - \\omega L)^{-1} \\mathbf{b}\n$$\n这是一种形式为 $\\mathbf{x}^{(k+1)} = T(\\omega) \\mathbf{x}^{(k)} + \\mathbf{c}$ 的定常迭代法。矩阵 $T(\\omega)$ 是误差传播算子，由下式给出：\n$$\nT(\\omega) = (D - \\omega L)^{-1} ((1-\\omega)D + \\omega U)\n$$\n该方法的收敛性由该算子的谱半径 $\\rho(T(\\omega)) = \\max_i |\\lambda_i(T(\\omega))|$ 决定，其中 $\\{\\lambda_i\\}$ 是 $T(\\omega)$ 的特征值。该方法收敛当且仅当 $\\rho(T(\\omega))  1$。最优松弛参数 $\\omega^\\star$ 是在区间 $(0,2)$ 内使该谱半径最小化的 $\\omega$ 值。\n\n由置换向量 $p$ 表示的未知数置换将系统 $A \\mathbf{x} = \\mathbf{b}$ 转换为 $\\tilde{A} \\tilde{\\mathbf{x}} = \\tilde{\\mathbf{b}}$，其中 $\\tilde{A} = P A P^{\\top}$、$\\tilde{\\mathbf{x}} = P\\mathbf{x}$ 和 $\\tilde{\\mathbf{b}} = P\\mathbf{b}$。问题使用向量 $p$ 定义置换，使得新矩阵元素为 $\\tilde{A}_{ij} = A_{p(i), p(j)}$。这种重排序会引出置换后矩阵的新分裂 $\\tilde{A} = \\tilde{D} - \\tilde{L} - \\tilde{U}$。关键在于，取矩阵的严格下（或上）三角部分的操作通常与置换操作不可交换。也就是说，$\\tilde{L}$ 不一定等于 $P L P^{\\top}$。因此，置换后系统的 SOR 迭代算子，\n$$\n\\tilde{T}(\\omega) = (\\tilde{D} - \\omega \\tilde{L})^{-1} ((1-\\omega)\\tilde{D} + \\omega \\tilde{U})\n$$\n与原始系统的算子不同，其谱 $\\rho(\\tilde{T}(\\omega))$ 也将不同。这意味着最优松弛参数 $\\omega^\\star$ 依赖于方程组的排序。\n\n该问题要求对六个不同情况进行 $\\omega^\\star$ 的数值搜索。对于每种情况，首先形成置换后的矩阵 $\\tilde{A}$。然后，构造其分裂 $\\tilde{A} = \\tilde{D} - \\tilde{L} - \\tilde{U}$。在 $(0,2)$ 的均匀网格上，以 $0.01$ 为步长，计算不同 $\\omega$ 值对应的谱半径 $\\rho(\\tilde{T}(\\omega))$。选择产生最小谱半径的网格点作为 $\\omega^\\star$ 的值。\n\n- **情况 1 和 2** 以及 **情况 3 和 4** 将标准字典序与重排序（红黑、奇偶）进行比较，对于给定的拉普拉斯矩阵，已知这些重排序是“一致有序”的。对于此类排序，存在一个计算 $\\omega^\\star$ 的解析公式，可用于检验数值结果。从任意排序变为一致有序排序会显著改变 $\\tilde{L}$ 和 $\\tilde{U}$ 的结构，从而改变最优参数。\n- **情况 5 和 6** 提供了一个反例。对于对角矩阵 $A$，任何置换 $P$ 都会得到另一个对角矩阵 $\\tilde{A} = P A P^{\\top}$。对于任何对角矩阵，其严格三角部分 $L$ 和 $U$ 都是零矩阵。因此，$\\tilde{L} = \\tilde{U} = 0$，正如 $L=U=0$ 一样。在这个特殊情况下，分裂操作与置换操作是可交换的。SOR 算子简化为 $T(\\omega) = (1-\\omega)I$，其谱半径为 $|1-\\omega|$。无论置换如何，该谱半径在 $\\omega=1$ 时最小。这些情况展示了重排序对 $\\omega^\\star$ 没有影响的场景。\n\n数值实现将通过为每种情况构造矩阵和置换，执行对 $\\omega^\\star$ 的网格搜索，并报告所需的值来继续进行。", "answer": "```python\nimport numpy as np\n\ndef solve_case(A, p):\n    \"\"\"\n    Solves for the optimal SOR parameter for a given matrix and permutation.\n\n    Args:\n        A (np.ndarray): The original matrix.\n        p (np.ndarray): The permutation vector.\n\n    Returns:\n        tuple: A tuple containing the optimal omega and the minimum spectral radius.\n    \"\"\"\n    # Apply permutation: A_perm[i, j] = A[p[i], p[j]]\n    A_perm = A[np.ix_(p, p)]\n    \n    # Decompose the permuted matrix\n    D_tilde = np.diag(np.diag(A_perm))\n    # Note on sign convention: A = D - L - U, so L is the negative of the strictly lower part.\n    L_tilde = -np.tril(A_perm, k=-1)\n    U_tilde = -np.triu(A_perm, k=1)\n\n    omegas = np.arange(0.01, 2.0, 0.01)\n    min_rho = float('inf')\n    omega_star = -1.0\n\n    for omega in omegas:\n        # Construct the SOR iteration matrix T_omega\n        # T_omega = inv(D - omega*L) * ((1-omega)*D + omega*U)\n        M = D_tilde - omega * L_tilde\n        N_mat = (1 - omega) * D_tilde + omega * U_tilde\n        \n        # Using linalg.solve is more stable than computing the inverse explicitly\n        try:\n            # Check if M is non-singular before solving\n            if np.linalg.det(M) == 0:\n                continue\n            T_omega = np.linalg.solve(M, N_mat)\n        except np.linalg.LinAlgError:\n            continue # Matrix M is singular for this omega, skip\n\n        # Compute spectral radius\n        eigenvalues = np.linalg.eigvals(T_omega)\n        rho = np.max(np.abs(eigenvalues))\n\n        if rho  min_rho:\n            min_rho = rho\n            omega_star = omega\n            \n    return omega_star, min_rho\n\ndef make_laplacian_2d(N):\n    \"\"\"Creates the 2D finite-difference Laplacian matrix.\"\"\"\n    n = N * N\n    A = np.zeros((n, n))\n    for i in range(N):\n        for j in range(N):\n            k = i * N + j\n            A[k, k] = 4\n            if i > 0: A[k, (i-1)*N + j] = -1 # Up\n            if i  N-1: A[k, (i+1)*N + j] = -1 # Down\n            if j > 0: A[k, i*N + (j-1)] = -1 # Left\n            if j  N-1: A[k, i*N + (j+1)] = -1 # Right\n    return A\n\ndef make_laplacian_1d(n):\n    \"\"\"Creates the 1D finite-difference Laplacian matrix.\"\"\"\n    A = np.zeros((n, n))\n    for i in range(n):\n        A[i, i] = 2\n        if i > 0: A[i, i-1] = -1\n        if i  n-1: A[i, i+1] = -1\n    return A\n\ndef get_red_black_perm(N):\n    \"\"\"Generates the red-black ordering permutation for an N x N grid.\"\"\"\n    n = N * N\n    red_indices = []\n    black_indices = []\n    for i in range(N):\n        for j in range(N):\n            k = i * N + j\n            if (i + j) % 2 == 0:\n                red_indices.append(k)\n            else:\n                black_indices.append(k)\n    return np.array(red_indices + black_indices, dtype=int)\n\ndef get_even_odd_perm(n):\n    \"\"\"Generates the even-odd ordering permutation for a 1D vector of size n.\"\"\"\n    even_indices = [i for i in range(n) if i % 2 == 0]\n    odd_indices = [i for i in range(n) if i % 2 != 0]\n    return np.array(even_indices + odd_indices, dtype=int)\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    \n    # Case 1: 2D Poisson, N=6, lexicographic\n    N1 = 6\n    n1 = N1 * N1\n    A1 = make_laplacian_2d(N1)\n    p1 = np.arange(n1)\n    \n    # Case 2: 2D Poisson, N=6, red-black\n    A2 = A1\n    p2 = get_red_black_perm(N1)\n    \n    # Case 3: 1D Poisson, n=20, lexicographic\n    n3 = 20\n    A3 = make_laplacian_1d(n3)\n    p3 = np.arange(n3)\n    \n    # Case 4: 1D Poisson, n=20, even-odd\n    A4 = A3\n    p4 = get_even_odd_perm(n3)\n    \n    # Case 5: Diagonal SPD, identity ordering\n    n5 = 10\n    A5 = np.diag(np.arange(1, n5 + 1).astype(float))\n    p5 = np.arange(n5)\n    \n    # Case 6: Diagonal SPD, random (reversed) ordering\n    A6 = A5\n    p6 = np.arange(n5 - 1, -1, -1)\n\n    test_cases = [\n        (A1, p1),\n        (A2, p2),\n        (A3, p3),\n        (A4, p4),\n        (A5, p5),\n        (A6, p6),\n    ]\n\n    results = []\n    for A, p in test_cases:\n        omega_star, min_rho = solve_case(A, p)\n        results.append(round(omega_star, 6))\n        results.append(round(min_rho, 6))\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3266531"}]}