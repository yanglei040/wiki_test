{"hands_on_practices": [{"introduction": "任何Householder变换的核心都是“Householder向量”$v$，它定义了反射的超平面。第一个练习 [@problem_id:18019] 将引导你完成这个向量的基本推导，展示如何构造它以将给定向量转换为具有零元素的期望形式。", "problem": "豪斯霍尔德反射是一种描述关于超平面反射的线性变换。在数值线性代数中，豪斯霍尔德反射用于将向量的特定元素置零，这是 QR 分解等算法中的一个关键步骤。\n\n豪斯霍尔德矩阵 $P$ 定义为：\n$$P = I - 2 \\frac{vv^T}{v^T v}$$\n其中 $I$ 是单位矩阵，$v$ 是一个非零向量，称为豪斯霍尔德向量，它垂直于反射超平面。\n\n考虑一个列向量 $x \\in \\mathbb{R}^n$。目标是找到一个豪斯霍尔德向量 $v$，使得变换 $Px$ 得到一个与第一个标准基向量 $e_1 = [1, 0, \\dots, 0]^T$ 共线的向量。即，对于某个标量 $\\alpha$，有 $Px = \\alpha e_1$。\n\n由于反射是一种等距变换，它保持欧几里得范数不变，因此我们必须有 $\\|Px\\| = \\|x\\|$。这意味着 $|\\alpha| = \\|x\\|$。为确保数值稳定性，一个标准的约定是选择 $\\alpha$ 的符号与 $x$ 的第一个分量的符号相反，即 $\\alpha = -\\text{sign}(x_1)\\|x\\|$。\n\n实现此变换的豪斯霍尔德向量 $v$ 由原始向量 $x$ 与其目标像 $y = \\alpha e_1$ 之间的差给出：\n$$v = x - y = x - \\alpha e_1$$\n这也可以写成 $v = x + \\text{sign}(x_1)\\|x\\| e_1$。\n\n**问题：**\n对于一个一般的二维向量 $x = \\begin{bmatrix} x_1 \\\\ x_2 \\end{bmatrix}$，其中 $x_1 > 0$，推导将 $x$ 变换为形如 $[k, 0]^T$ 的向量的未归一化豪斯霍尔德向量 $v = \\begin{bmatrix} v_1 \\\\ v_2 \\end{bmatrix}$ 的分量之和的表达式。你的最终答案应为一个关于 $x_1$ 和 $x_2$ 的表达式。", "solution": "我们选择反射目标  \n$$y = \\alpha e_1,\\qquad \\alpha = -\\mathrm{sign}(x_1)\\|x\\| = -\\sqrt{x_1^2 + x_2^2}$$  \n因为 $x_1>0$。未归一化的豪斯霍尔德向量是  \n$$v = x - y = \\begin{bmatrix}x_1 - \\alpha \\\\ x_2\\end{bmatrix} \n= \\begin{bmatrix}x_1 + \\sqrt{x_1^2 + x_2^2} \\\\ x_2\\end{bmatrix}.$$  \n因此，其分量之和为  \n$$S = v_1 + v_2 = x_1 + \\sqrt{x_1^2 + x_2^2} + x_2.$$", "answer": "$$\\boxed{x_1 + x_2 + \\sqrt{x_1^2 + x_2^2}}$$", "id": "18019"}, {"introduction": "掌握了如何构造Householder向量后，我们现在可以将其应用于QR分解的第一步。这个练习 [@problem_id:17992] 涉及在一个小矩阵上进行具体计算，它将矩阵第一列元素清零的抽象过程变得具体化，并巩固了算法的力学原理。", "problem": "### 问题描述\n\n矩阵 $A$ 的QR分解是一种将矩阵分解为 $A=QR$ 的方法，其中 $Q$ 是一个正交矩阵，$R$ 是一个上三角矩阵。实现这种分解的一种方法是通过一系列Householder反射。\n\nHouseholder反射是由矩阵 $H = I - 2 \\frac{\\mathbf{v}\\mathbf{v}^T}{\\mathbf{v}^T\\mathbf{v}}$ 定义的一种线性变换，其中 $\\mathbf{v}$ 为某个非零向量，$I$ 是单位矩阵。该变换将任意向量关于与 $\\mathbf{v}$ 正交的超平面进行反射。\n\n对于一个 $m \\times n$ 的矩阵 $A$ 进行QR分解，第一步是应用一个Householder变换 $H_1$，将 $A$ 的第一列（记为 $\\mathbf{a}_1$）映射到一个与标准基向量 $\\mathbf{e}_1 = (1, 0, \\dots, 0)^T$ 成比例的向量。这将使第一列中第一个元素下方的所有元素都变为零。\n\n所需的Householder矩阵为 $H_1 = I - 2 \\frac{\\mathbf{v}_1\\mathbf{v}_1^T}{\\mathbf{v}_1^T\\mathbf{v}_1}$，其中Householder向量 $\\mathbf{v}_1$ 的构造如下：\n$$\n\\mathbf{v}_1 = \\mathbf{a}_1 - \\alpha \\mathbf{e}_1\n$$\n标量 $\\alpha$ 由下式给出：\n$$\n\\alpha = -\\text{sgn}(a_{11})\\|\\mathbf{a}_1\\|_2\n$$\n此处，$a_{11}$ 是 $\\mathbf{a}_1$ 的第一个元素，$\\|\\cdot\\|_2$ 表示欧几里得范数，符号函数 $\\text{sgn}(x)$ 在 $x \\ge 0$ 时为 $1$，在 $x  0$ 时为 $-1$。完成这第一步后，变换后的矩阵为 $A' = H_1 A$。\n\n给定矩阵：\n$$\nA = \\begin{pmatrix} 1   1  1 \\\\ 1  2  4 \\\\ 1  3  9 \\end{pmatrix}\n$$\n计算矩阵 $A' = H_1 A$ 的元素 $(A')_{2,2}$。", "solution": "我们有 $A\\in\\mathbb{R}^{3\\times3}$，其第一列为 $\\mathbf a_1=(1,1,1)^T$。我们要求解 $H_1=I-2\\frac{\\mathbf v\\mathbf v^T}{\\mathbf v^T\\mathbf v}$，其中\n$$\n\\alpha=-\\sgn(a_{11})\\|\\mathbf a_1\\|_2=-1\\cdot\\sqrt{1^2+1^2+1^2}=-\\sqrt3,\n$$\n$$\n\\mathbf v=\\mathbf a_1-\\alpha\\mathbf e_1\n=\\begin{pmatrix}1\\\\1\\\\1\\end{pmatrix}-(-\\sqrt3)\\begin{pmatrix}1\\\\0\\\\0\\end{pmatrix}\n=\\begin{pmatrix}1+\\sqrt3\\\\1\\\\1\\end{pmatrix}.\n$$\n\n接下来，令 $\\mathbf a_2=(1,2,3)^T$ 为 $A$ 的第二列。那么\n$$\n\\mathbf v^T\\mathbf v=(1+\\sqrt3)^2+1^2+1^2\n=1+2\\sqrt3+3+1+1=6+2\\sqrt3,\n$$\n$$\n\\mathbf v^T\\mathbf a_2=(1+\\sqrt3)\\cdot1+1\\cdot2+1\\cdot3\n=6+\\sqrt3.\n$$\n因此\n$$\nH_1\\mathbf a_2\n=\\mathbf a_2-2\\,\\frac{\\mathbf v(\\mathbf v^T\\mathbf a_2)}{\\mathbf v^T\\mathbf v}\n=\\begin{pmatrix}1\\\\2\\\\3\\end{pmatrix}\n-2\\,\\frac{6+\\sqrt3}{6+2\\sqrt3}\\begin{pmatrix}1+\\sqrt3\\\\1\\\\1\\end{pmatrix}.\n$$\n化简该标量：\n$$\n2\\,\\frac{6+\\sqrt3}{6+2\\sqrt3}\n=\\frac{12+2\\sqrt3}{6+2\\sqrt3}\n=\\frac{6+\\sqrt3}{3+\\sqrt3}\n=\\frac{(6+\\sqrt3)(3-\\sqrt3)}{6}\n=\\frac{15-3\\sqrt3}{6}\n=\\frac{5-\\sqrt3}{2}.\n$$\n因此\n$$\n(H_1\\mathbf a_2)_2\n=2-\\frac{5-\\sqrt3}{2}\\cdot1\n=\\frac{4-(5-\\sqrt3)}{2}\n=\\frac{\\sqrt3-1}{2}.\n$$\n所以，$A'=H_1A$ 的 $(2,2)$ 位置的元素是 $\\displaystyle\\frac{\\sqrt3-1}{2}$。", "answer": "$$\\boxed{\\frac{\\sqrt3-1}{2}}$$", "id": "17992"}, {"introduction": "为什么豪斯霍尔德变换是现代数值线性代数的基石？这最后一个练习 [@problem_id:3240095] 通过一个动手编程实验给出了一个强有力的答案。通过比较豪斯霍尔德QR分解和经典格拉姆-施密特方法在处理近共线向量时的性能，你将亲眼见证豪斯霍尔德方法卓越的数值稳定性，正是这种稳定性使其至关重要。", "problem": "设 $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ 是一个实矩阵。$\\mathbf{A}$ 的正交三角分解 (QR) 旨在寻求矩阵 $\\mathbf{Q} \\in \\mathbb{R}^{m \\times m}$ 和 $\\mathbf{R} \\in \\mathbb{R}^{m \\times n}$，使得 $\\mathbf{Q}$ 是正交的，即 $\\mathbf{Q}^{\\top} \\mathbf{Q} = \\mathbf{I}$，并且 $\\mathbf{R}$ 在其前导 $n \\times n$ 块中是上三角矩阵，满足 $\\mathbf{A} = \\mathbf{Q} \\mathbf{R}$。Householder 反射是一个形如 $\\mathbf{H} = \\mathbf{I} - 2 \\mathbf{u} \\mathbf{u}^{\\top}$ 的矩阵，其中 $\\mathbf{u} \\in \\mathbb{R}^{m}$ 是任意单位向量，并且满足 $\\mathbf{H}^{\\top} = \\mathbf{H}$ 和 $\\mathbf{H}^{2} = \\mathbf{I}$；它将向量关于与 $\\mathbf{u}$ 正交的超平面进行反射。经典格拉姆-施密特 (CGS) 正交化通过依次投影并减去沿先前已形成的基向量的分量来构造一个标准正交基。这两种方法在数值方法和科学计算中都得到了广泛研究。\n\n您将构造一个矩阵族 $\\mathbf{A}(\\epsilon)$，其列向量几乎共线，然后当 $\\epsilon \\to 0$ 时，比较基于 Householder 的正交三角分解 (QR) 和经典格拉姆-施密特 (CGS) 的后向误差。使用以下基本定义：\n- 向量 $\\mathbf{x}$ 的欧几里得范数是 $\\lVert \\mathbf{x} \\rVert_{2} = \\sqrt{\\sum_{i} x_{i}^{2}}$。\n- 矩阵 $\\mathbf{M}$ 的弗罗贝尼乌斯范数是 $\\lVert \\mathbf{M} \\rVert_{F} = \\sqrt{\\sum_{i,j} M_{ij}^{2}}$。\n- 对于 $\\mathbf{A}$ 的一个计算出的分解 $(\\mathbf{Q}, \\mathbf{R})$，其后向误差是残差的相对弗罗贝尼乌斯范数，定义为\n$$\n\\mathrm{err}_{\\mathrm{bwd}}(\\mathbf{A}, \\mathbf{Q}, \\mathbf{R}) = \\frac{\\lVert \\mathbf{A} - \\mathbf{Q} \\mathbf{R} \\rVert_{F}}{\\lVert \\mathbf{A} \\rVert_{F}}。\n$$\n\n按如下方式构造矩阵族 $\\mathbf{A}(\\epsilon) \\in \\mathbb{R}^{7 \\times 4}$。设\n$$\n\\mathbf{u}_{\\mathrm{raw}} = [1, 2, 3, 4, 5, 6, 7]^{\\top}, \\quad \\mathbf{d}_{2,\\mathrm{raw}} = [7, 6, 5, 4, 3, 2, 1]^{\\top},\n$$\n$$\n\\mathbf{d}_{3,\\mathrm{raw}} = [1, 0, 1, 0, 1, 0, 1]^{\\top}, \\quad \\mathbf{d}_{4,\\mathrm{raw}} = [0, 1, 0, 1, 0, 1, 0]^{\\top}。\n$$\n定义 $\\mathbf{u} = \\mathbf{u}_{\\mathrm{raw}} / \\lVert \\mathbf{u}_{\\mathrm{raw}} \\rVert_{2}$。对于 $k \\in \\{2,3,4\\}$，定义\n$$\n\\mathbf{d}_{k} = \\mathbf{d}_{k,\\mathrm{raw}} - (\\mathbf{u}^{\\top} \\mathbf{d}_{k,\\mathrm{raw}}) \\mathbf{u},\n\\quad\n\\mathbf{d}_{k} \\leftarrow \\frac{\\mathbf{d}_{k}}{\\lVert \\mathbf{d}_{k} \\rVert_{2}},\n$$\n使得每个 $\\mathbf{d}_{k}$ 都与 $\\mathbf{u}$ 正交且范数为1。对于给定的 $\\epsilon \\ge 0$，将 $\\mathbf{A}(\\epsilon)$ 的列向量设置为\n$$\n\\mathbf{a}_{1}(\\epsilon) = \\mathbf{u}, \\quad\n\\mathbf{a}_{2}(\\epsilon) = \\mathbf{u} + \\epsilon \\mathbf{d}_{2}, \\quad\n\\mathbf{a}_{3}(\\epsilon) = \\mathbf{u} + \\epsilon^{2} \\mathbf{d}_{3}, \\quad\n\\mathbf{a}_{4}(\\epsilon) = \\mathbf{u} - \\epsilon \\mathbf{d}_{4},\n$$\n并令 $\\mathbf{A}(\\epsilon) = [\\mathbf{a}_{1}(\\epsilon)\\ \\mathbf{a}_{2}(\\epsilon)\\ \\mathbf{a}_{3}(\\epsilon)\\ \\mathbf{a}_{4}(\\epsilon)]$。这种构造确保了当 $\\epsilon$ 很小时列向量几乎共线，而当 $\\epsilon = 0$ 时则完全共线。\n\n任务：\n1. 通过逐次应用 Householder 反射，将 $\\mathbf{A}(\\epsilon)$ 变换为上三角矩阵 $\\mathbf{R}$，同时将正交矩阵 $\\mathbf{Q}$ 累积为反射矩阵的乘积，从而实现基于 Householder 的正交三角分解 (QR)。不要调用任何内置的 QR 例程。\n2. 实现经典格拉姆-施密特 (CGS) 来计算 $\\mathbf{Q}$ 和 $\\mathbf{R}$，并遵循以下约定：如果在此过程中某一列向量变成了零向量，则将 $\\mathbf{R}$ 中对应的对角线元素设为 $0$，并将 $\\mathbf{Q}$ 中对应的列向量设为零向量。\n3. 对于下面测试套件中的每个 $\\epsilon$，计算基于 Householder QR 的 $\\mathrm{err}_{\\mathrm{bwd}}(\\mathbf{A}(\\epsilon), \\mathbf{Q}_{\\mathrm{HQR}}(\\epsilon), \\mathbf{R}_{\\mathrm{HQR}}(\\epsilon))$ 和经典格拉姆-施密特的 $\\mathrm{err}_{\\mathrm{bwd}}(\\mathbf{A}(\\epsilon), \\mathbf{Q}_{\\mathrm{CGS}}(\\epsilon), \\mathbf{R}_{\\mathrm{CGS}}(\\epsilon))$。\n\n测试套件：\n- $\\epsilon_{1} = 10^{-1}$ (一般情况)，\n- $\\epsilon_{2} = 10^{-4}$ (中等小)，\n- $\\epsilon_{3} = 10^{-8}$ (接近双精度舍入尺度)，\n- $\\epsilon_{4} = 10^{-12}$ (非常接近共线)，\n- $\\epsilon_{5} = 0$ (完全共线，秩亏边界)。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。每个条目按所列顺序对应一个 $\\epsilon$，其本身是一个包含两个浮点数 $[\\mathrm{err}_{\\mathrm{HQR}}, \\mathrm{err}_{\\mathrm{CGS}}]$ 的列表。例如，输出必须具有以下形式\n$$\n[\\,[e_{1,\\mathrm{HQR}}, e_{1,\\mathrm{CGS}}],\\,[e_{2,\\mathrm{HQR}}, e_{2,\\mathrm{CGS}}],\\,[e_{3,\\mathrm{HQR}}, e_{3,\\mathrm{CGS}}],\\,[e_{4,\\mathrm{HQR}}, e_{4,\\mathrm{CGS}}],\\,[e_{5,\\mathrm{HQR}}, e_{5,\\mathrm{CGS}}]\\,].\n$$\n本问题不涉及任何物理单位或角度；数值应以标准浮点小数形式打印。", "solution": "问题的核心是研究计算矩阵 $\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ 的 QR 分解的两种算法的数值稳定性。该分解由 $\\mathbf{A} = \\mathbf{Q} \\mathbf{R}$ 给出，其中 $\\mathbf{Q} \\in \\mathbb{R}^{m \\times m}$ 是正交矩阵（$\\mathbf{Q}^\\top \\mathbf{Q} = \\mathbf{I}$），$\\mathbf{R} \\in \\mathbb{R}^{m \\times n}$ 是上三角矩阵（即所有 $i > j$ 的元素 $R_{ij}$ 都为零）。我们将比较一种基于豪斯霍尔德反射的方法（以其卓越的数值稳定性而闻名）与经典格拉姆-施密特过程（以其数值不稳定性而著称）。比较的度量是后向误差 $\\mathrm{err}_{\\mathrm{bwd}} = \\frac{\\lVert \\mathbf{A} - \\mathbf{Q} \\mathbf{R} \\rVert_{F}}{\\lVert \\mathbf{A} \\rVert_{F}}$，它衡量计算出的因子之积与原始矩阵的接近程度（相对于原始矩阵的大小）。\n\n首先，我们按照规定构造测试矩阵族 $\\mathbf{A}(\\epsilon) \\in \\mathbb{R}^{7 \\times 4}$。当 $\\epsilon \\to 0$ 时，$\\mathbf{A}(\\epsilon)$ 的列向量变得几乎线性相关，从而产生一个病态问题，对数值算法的稳定性构成挑战。\n\n指定的原始向量是：\n$$\n\\mathbf{u}_{\\mathrm{raw}} = [1, 2, 3, 4, 5, 6, 7]^{\\top}, \\quad \\mathbf{d}_{2,\\mathrm{raw}} = [7, 6, 5, 4, 3, 2, 1]^{\\top}\n$$\n$$\n\\mathbf{d}_{3,\\mathrm{raw}} = [1, 0, 1, 0, 1, 0, 1]^{\\top}, \\quad \\mathbf{d}_{4,\\mathrm{raw}} = [0, 1, 0, 1, 0, 1, 0]^{\\top}\n$$\n我们首先归一化 $\\mathbf{u}_{\\mathrm{raw}}$ 以获得单位向量 $\\mathbf{u} = \\mathbf{u}_{\\mathrm{raw}} / \\lVert \\mathbf{u}_{\\mathrm{raw}} \\rVert_{2}$。\n然后，对于每个 $\\mathbf{d}_{k,\\mathrm{raw}}$ ($k \\in \\{2,3,4\\}$)，我们通过格拉姆-施密特步骤使其与 $\\mathbf{u}$ 正交并将其归一化：\n1.  将 $\\mathbf{d}_{k,\\mathrm{raw}}$ 投影到 $\\mathbf{u}$ 上：$\\mathrm{proj}_{\\mathbf{u}}(\\mathbf{d}_{k,\\mathrm{raw}}) = (\\mathbf{u}^{\\top} \\mathbf{d}_{k,\\mathrm{raw}}) \\mathbf{u}$。\n2.  减去该投影以获得一个与 $\\mathbf{u}$ 正交的向量：$\\mathbf{d}_{k, \\perp} = \\mathbf{d}_{k,\\mathrm{raw}} - (\\mathbf{u}^{\\top} \\mathbf{d}_{k,\\mathrm{raw}}) \\mathbf{u}$。\n3.  归一化以获得最终的单位向量：$\\mathbf{d}_{k} = \\mathbf{d}_{k, \\perp} / \\lVert \\mathbf{d}_{k, \\perp} \\rVert_{2}$。\n\n$\\mathbf{A}(\\epsilon)$ 的列向量随后定义为：\n$$\n\\mathbf{a}_{1}(\\epsilon) = \\mathbf{u}, \\quad\n\\mathbf{a}_{2}(\\epsilon) = \\mathbf{u} + \\epsilon \\mathbf{d}_{2}, \\quad\n\\mathbf{a}_{3}(\\epsilon) = \\mathbf{u} + \\epsilon^{2} \\mathbf{d}_{3}, \\quad\n\\mathbf{a}_{4}(\\epsilon) = \\mathbf{u} - \\epsilon \\mathbf{d}_{4}\n$$\n矩阵为 $\\mathbf{A}(\\epsilon) = [\\mathbf{a}_{1}(\\epsilon)\\ \\mathbf{a}_{2}(\\epsilon)\\ \\mathbf{a}_{3}(\\epsilon)\\ \\mathbf{a}_{4}(\\epsilon)]$。\n\n接下来，我们详细介绍两种分解算法。\n\n**1. 豪斯霍尔德QR分解**\n\n此方法使用一系列豪斯霍尔德反射在矩阵 $\\mathbf{A}$ 的对角线下方引入零，将其变换为上三角矩阵 $\\mathbf{R}$。对于一个非零向量 $\\mathbf{v}$，豪斯霍尔德反射由 $\\mathbf{H} = \\mathbf{I} - 2\\frac{\\mathbf{v}\\mathbf{v}^\\top}{\\mathbf{v}^\\top\\mathbf{v}}$ 给出。它将任何向量关于与 $\\mathbf{v}$ 正交的超平面进行反射。\n\n算法按 $k = 1, \\dots, n$ 进行：\n1.  设当前矩阵为 $\\mathbf{A}^{(k-1)}$ (其中 $\\mathbf{A}^{(0)}=\\mathbf{A}$)。我们关注第 $k$ 列。令 $\\mathbf{x}$ 为从对角线开始的子列向量，即 $\\mathbf{x} = \\mathbf{A}^{(k-1)}[k-1:m, k-1]$。\n2.  我们构造一个反射矩阵 $\\mathbf{H}'_k$，将 $\\mathbf{x}$ 变换为一个与 $\\mathbf{e}_1 = [1, 0, \\dots, 0]^\\top$ 平行的向量。具体来说，$\\mathbf{H}'_k \\mathbf{x} = \\alpha \\mathbf{e}_1$，其中 $\\alpha = -\\mathrm{sgn}(x_1) \\lVert \\mathbf{x} \\rVert_2$。选择该符号是为了在形成反射向量 $\\mathbf{v}_k = \\mathbf{x} - \\alpha \\mathbf{e}_1$ 时避免灾难性抵消。\n3.  这个大小为 $(m-k+1) \\times (m-k+1)$ 的反射矩阵 $\\mathbf{H}'_k$ 被嵌入到一个 $m \\times m$ 的矩阵中 $\\mathbf{H}_k = \\begin{pmatrix} \\mathbf{I}_{k-1}  \\mathbf{0} \\\\ \\mathbf{0}  \\mathbf{H}'_k \\end{pmatrix}$。\n4.  更新矩阵：$\\mathbf{A}^{(k)} = \\mathbf{H}_k \\mathbf{A}^{(k-1)}$。这将第 $k$ 列对角线以下的元素置零。\n经过 $n$ 步后，我们得到 $\\mathbf{R} = \\mathbf{A}^{(n)} = \\mathbf{H}_n \\cdots \\mathbf{H}_1 \\mathbf{A}$。\n由此，$\\mathbf{A} = (\\mathbf{H}_1 \\cdots \\mathbf{H}_n)\\mathbf{R}$，因为 $\\mathbf{H}_k^{-1} = \\mathbf{H}_k$。\n因此正交矩阵为 $\\mathbf{Q} = \\mathbf{H}_1 \\cdots \\mathbf{H}_n$。\n为了计算 $\\mathbf{Q}$，可以从 $\\mathbf{Q} = \\mathbf{I}_{m \\times m}$ 开始，并从右侧逐次应用反射：$\\mathbf{Q} \\leftarrow \\mathbf{Q} \\mathbf{H}_k$，其中 $k=1, \\dots, n$。\n\n**2. 经典格拉姆-施密特 (CGS) QR分解**\n\nCGS 依次构建 $\\mathbf{Q}$ 的列。对于 $\\mathbf{A}$ 的每一列 $\\mathbf{a}_j$，它减去其在先前计算出的标准正交向量 $\\mathbf{q}_1, \\dots, \\mathbf{q}_{j-1}$ 上的投影，然后将结果归一化。\n\n算法按 $j = 1, \\dots, n$ 进行：\n1.  初始化一个正交化过程的向量 $\\mathbf{v}_j = \\mathbf{a}_j$。\n2.  对于 $i = 1, \\dots, j-1$，计算投影并减去：\n    *   $R_{ij} = \\mathbf{q}_i^{\\top} \\mathbf{a}_j$。\n    *   $\\mathbf{v}_j \\leftarrow \\mathbf{v}_j - R_{ij} \\mathbf{q}_i$。\n3.  计算所得向量的范数：$R_{jj} = \\lVert \\mathbf{v}_j \\rVert_2$。\n4.  归一化以找到下一个标准正交向量：$\\mathbf{q}_j = \\mathbf{v}_j / R_{jj}$。\n如果在任何时候 $R_{jj}$ 变为零（或在数值上与零无法区分），这表示 $\\mathbf{a}_j$ 线性依赖于前面的列。根据问题规范，我们设 $R_{jj}=0$ 并且对应的列向量 $\\mathbf{q}_j$ 为零向量。这样得到的 $\\mathbf{Q}_{\\mathrm{CGS}}$ 不保证具有标准正交的列，特别是对于病态或秩亏的矩阵。后向误差将量化此缺陷。该过程产生简约QR分解，其中 $\\mathbf{Q} \\in \\mathbb{R}^{m \\times n}$ 和 $\\mathbf{R} \\in \\mathbb{R}^{n \\times n}$，这对于计算后向误差是足够的。\n\n**比较与预期结果**\n对于小的 $\\epsilon$，$\\mathbf{A}(\\epsilon)$ 的列向量几乎是平行的。在 CGS 中，当计算 $\\mathbf{q}_j$ 时，减法 $\\mathbf{v}_j \\leftarrow \\mathbf{v}_j - R_{ij} \\mathbf{q}_i$ 涉及两个几乎相同的向量。这会导致灾难性抵消，大部分有效数字会丢失。得到的 $\\mathbf{v}_j$ 具有较大的相对误差，计算出的向量 $\\{\\mathbf{q}_j\\}$ 将失去其正交性。这种正交性的丧失会降低分解的质量，导致较大的后向误差。\n\n豪斯霍尔德QR分解使用正交变换对整列和整行进行操作。这些变换保持矩阵的弗罗贝尼乌斯范数，并且是数值后向稳定的。因此，即使对于病态矩阵，计算出的 $\\mathbf{Q}_{\\mathrm{HQR}}$ 仍然非常接近一个真正的正交矩阵，而后向误差 $\\mathrm{err}_{\\mathrm{bwd}}(\\mathbf{A}, \\mathbf{Q}_{\\mathrm{HQR}}, \\mathbf{R}_{\\mathrm{HQR}})$ 也保持很小，通常在机器精度的量级上。\n\n对于 $\\epsilon = 0$，矩阵 $\\mathbf{A}(0)$ 是秩为1的。两种算法都应根据其定义处理这种极限情况。然而，对于 $\\epsilon \\approx 10^{-8}$（接近双精度下机器精度的平方根），预计 CGS 的性能会非常差，而豪斯霍尔德QR分解在所有测试的 $\\epsilon$ 值上都应保持稳健。\n以下代码实现了这些算法，并为指定的测试套件计算了后向误差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef construct_A(epsilon: float) - np.ndarray:\n    \"\"\"\n    Constructs the matrix A(epsilon) as specified in the problem.\n    \"\"\"\n    m, n = 7, 4\n    \n    u_raw = np.array([1, 2, 3, 4, 5, 6, 7], dtype=float)\n    d_raw_list = [\n        np.array([7, 6, 5, 4, 3, 2, 1], dtype=float),\n        np.array([1, 0, 1, 0, 1, 0, 1], dtype=float),\n        np.array([0, 1, 0, 1, 0, 1, 0], dtype=float)\n    ]\n    \n    u = u_raw / np.linalg.norm(u_raw)\n    \n    d_list = []\n    for d_raw in d_raw_list:\n        d_ortho = d_raw - (u.T @ d_raw) * u\n        d_norm = np.linalg.norm(d_ortho)\n        d_list.append(d_ortho / d_norm)\n        \n    a1 = u\n    a2 = u + epsilon * d_list[0]\n    a3 = u + epsilon**2 * d_list[1]\n    a4 = u - epsilon * d_list[2]\n    \n    A = np.zeros((m, n))\n    A[:, 0] = a1\n    A[:, 1] = a2\n    A[:, 2] = a3\n    A[:, 3] = a4\n    \n    return A\n\ndef householder_qr(A: np.ndarray) - tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Performs QR factorization using Householder reflectors.\n    Returns Q (m x m) and R (m x n).\n    \"\"\"\n    m, n = A.shape\n    Q = np.identity(m)\n    R = A.copy()\n\n    for j in range(n):\n        # Extract the vector to be reflected\n        x = R[j:, j]\n        norm_x = np.linalg.norm(x)\n\n        # Numerically stable choice for alpha\n        alpha = -np.copysign(norm_x, x[0]) if norm_x != 0 else 0\n        \n        v = x.copy()\n        v[0] -= alpha\n        \n        norm_v = np.linalg.norm(v)\n\n        # If the reflector vector is zero, the transformation is identity\n        if norm_v  1e-16:\n            continue\n\n        # Normalize the reflector vector to get u\n        u = v / norm_v\n        u = u.reshape(-1, 1) # Ensure u is a column vector\n\n        # Apply the reflection to the relevant submatrix of R\n        R_sub = R[j:, j:]\n        R[j:, j:] = R_sub - 2 * u @ (u.T @ R_sub)\n\n        # Apply the reflection to the relevant columns of Q (from the right)\n        Q_sub = Q[:, j:]\n        Q[:, j:] = Q_sub - 2 * (Q_sub @ u) @ u.T\n    \n    # Return Q and the R part of the final matrix\n    return Q, R[:m, :n]\n\ndef cgs_qr(A: np.ndarray) - tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Performs QR factorization using Classical Gram-Schmidt.\n    Returns Q (m x n, reduced) and R (n x n, reduced).\n    \"\"\"\n    m, n = A.shape\n    Q = np.zeros((m, n))\n    R = np.zeros((n, n))\n\n    for j in range(n):\n        v = A[:, j].copy()\n        \n        # Subtract projections onto previous q vectors\n        for i in range(j):\n            # CGS uses projection of a_j, not the intermediate v\n            R[i, j] = Q[:, i].T @ A[:, j]\n            v -= R[i, j] * Q[:, i]\n            \n        norm_v = np.linalg.norm(v)\n\n        if norm_v  1e-16: # Handle linear dependence as per problem spec\n            R[j, j] = 0\n            # Q[:, j] is already zero\n        else:\n            R[j, j] = norm_v\n            Q[:, j] = v / norm_v\n\n    return Q, R\n\ndef solve():\n    \"\"\"\n    Main function to run the comparison and print results.\n    \"\"\"\n    # Test suite of epsilon values\n    test_suite = [10**-1, 10**-4, 10**-8, 10**-12, 0.0]\n    \n    results = []\n    \n    for epsilon in test_suite:\n        A = construct_A(epsilon)\n        norm_A = np.linalg.norm(A, 'fro')\n\n        # Householder QR\n        Q_hqr, R_hqr = householder_qr(A)\n        residual_hqr = A - Q_hqr @ R_hqr\n        err_hqr = np.linalg.norm(residual_hqr, 'fro') / norm_A if norm_A > 0 else 0.0\n        \n        # Classical Gram-Schmidt QR\n        Q_cgs, R_cgs = cgs_qr(A)\n        residual_cgs = A - Q_cgs @ R_cgs\n        err_cgs = np.linalg.norm(residual_cgs, 'fro') / norm_A if norm_A > 0 else 0.0\n\n        results.append([err_hqr, err_cgs])\n\n    # Format the output as specified\n    formatted_results = [f\"[{hqr:.16e}, {cgs:.16e}]\" for hqr, cgs in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3240095"}]}