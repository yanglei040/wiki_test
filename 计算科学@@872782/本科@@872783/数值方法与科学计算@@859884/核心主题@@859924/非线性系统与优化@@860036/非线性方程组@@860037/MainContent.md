## 引言
在科学与工程的广阔天地中，我们常常需要面对并解决由多个相互关联的[非线性方程](@entry_id:145852)构成的复杂系统。这些问题无处不在，小到确定几何曲线的交点，大到模拟复杂物理系统的[稳态](@entry_id:182458)行为。与可以通过高斯消元等直接法求得精确解的线性方程组不同，[非线性系统](@entry_id:168347)通常没有通用的解析解法，这构成了数值分析领域的一大核心挑战。因此，我们必须依赖数值迭代方法，从一个初始猜测出发，逐步逼近系统的真实解。

本文旨在系统地介绍[求解非线性方程](@entry_id:177343)组的核心理论与实用方法。您将学习到：

在第一章“原理与机制”中，我们将深入探讨[非线性系统](@entry_id:168347)的数学表述，并介绍两种基础而重要的迭代思想：[不动点迭代法](@entry_id:168837)和更为强大、收敛更快的牛顿法。我们将详细分析这些方法的收敛性条件、计算成本，以及如何通过线搜索和拟牛顿法等技术克服其固有的局限性。

在第二章“应用与跨学科联系”中，我们将展示这些数学工具的真正威力，通过一系列来自工程、物理、计算科学乃至经济学等领域的真实案例，阐明如何将具体问题“翻译”为标准的[非线性方程组](@entry_id:178110)。您将看到，[求解非线性方程](@entry_id:177343)组是连接理论与实践、推动现代科技发展的关键桥梁。

最后，在“动手实践”部分，您将有机会通过解决具体问题，亲手实现和分析这些算法，从而将理论知识转化为可操作的技能。现在，让我们从理解这些方法背后的基本原理开始。

## 原理与机制

在科学与工程的众多领域中，我们经常遇到需要同时求解多个相互关联的非线性方程的问题。这些问题可以小到确定两条几何曲线的交点，大到模拟复杂物理系统的[稳态](@entry_id:182458)行为。与线性方程组可以通过直接法（如高斯消元法）在有限步骤内求得精确解不同，非线性系统通常需要依赖迭代法来逐步逼近其解。本章将深入探讨[求解非线性方程](@entry_id:177343)组的核心原理与关键机制，为后续章节介绍具体算法奠定坚实的理论基础。

### 问题的数学表述

一个包含 $n$ 个方程和 $n$ 个未知数 $(x_1, x_2, \ldots, x_n)$ 的非线性方程组，其一般形式可以写为：
$$
\begin{cases}
    f_1(x_1, x_2, \ldots, x_n)  = 0 \\
    f_2(x_1, x_2, \ldots, x_n)  = 0 \\
    \vdots  \\
    f_n(x_1, x_2, \ldots, x_n)  = 0
\end{cases}
$$
为了简化表示，我们引入向量记法。令 $\mathbf{x} = (x_1, x_2, \ldots, x_n)^T$ 为未知数向量，并定义一个向量函数 $F: \mathbb{R}^n \to \mathbb{R}^n$：
$$
F(\mathbf{x}) = \begin{pmatrix} f_1(\mathbf{x}) \\ f_2(\mathbf{x}) \\ \vdots \\ f_n(\mathbf{x}) \end{pmatrix}
$$
这样，整个[方程组](@entry_id:193238)就可以简洁地表示为寻找一个向量 $\mathbf{x}^*$，使其满足：
$$
F(\mathbf{x}^*) = \mathbf{0}
$$
这个向量 $\mathbf{x}^*$ 被称为[方程组](@entry_id:193238)的一个 **根** 或 **解**。

问题的构建过程本身就是将物理或几何问题转化为这种标准数学形式的第一步。例如，考虑在[计算机辅助设计](@entry_id:157566)中寻找两条曲线交点的问题 [@problem_id:2207882]。假设一条曲线是[伯努利双纽线](@entry_id:165485) $(x^2+y^2)^2 = 2a^2(x^2-y^2)$，另一条是圆 $(x-h)^2 + (y-k)^2 = r^2$。交点 $(x, y)$ 必须同时满足这两个方程。为了将其转化为 $F(\mathbf{x}) = \mathbf{0}$ 的形式，我们将每个方程的所有项移到等号的同一侧：
$$
f_1(x, y) = (x^2+y^2)^2 - 2a^2(x^2-y^2) = 0
$$
$$
f_2(x, y) = (x-h)^2 + (y-k)^2 - r^2 = 0
$$
于是，求解这两条曲线的交点就等价于寻找向量函数 $F(x, y) = \begin{pmatrix} f_1(x, y) & f_2(x, y) \end{pmatrix}^T$ 的根。

在实际求解过程中，我们通常从一个初始猜测 $\mathbf{x}_0$ 开始，通过迭代算法生成一系列逼近解的向量 $\mathbf{x}_1, \mathbf{x}_2, \ldots$。一个自然的问题是：如何评估一个近似解 $\mathbf{x}_k$ 的好坏？一个直接的度量是检查它在多大程度上“满足”了方程。为此，我们定义 **残差向量**（residual vector）为 $F(\mathbf{x}_k)$。如果 $\mathbf{x}_k$ 是一个精确解，那么残差向量将是零向量。因此，残差[向量的范数](@entry_id:154882)，如[欧几里得范数](@entry_id:172687) $\|F(\mathbf{x}_k)\|_2$，可以作为衡量近似程度的指标。这个值越小，说明 $\mathbf{x}_k$ 越接近一个真解。例如，对于一个描述机器人路径的[方程组](@entry_id:193238)，工程师可能会提出一个近似交点，通过计算该点的[残差范数](@entry_id:754273)来评估其有效性 [@problem_id:2207890]。

### [不动点迭代法](@entry_id:168837)：一种基本的迭代思想

最直观的迭代方法之一是 **[不动点迭代法](@entry_id:168837)**（Fixed-Point Iteration）。其核心思想是将原始方程 $F(\mathbf{x}) = \mathbf{0}$ 进行代数变换，得到一个等价的 **[不动点](@entry_id:156394)形式**：
$$
\mathbf{x} = G(\mathbf{x})
$$
其中 $G$ 是一个从 $\mathbb{R}^n$ 到 $\mathbb{R}^n$ 的函数。如果 $\mathbf{x}^* = G(\mathbf{x}^*)$，则称 $\mathbf{x}^*$ 是函数 $G$ 的一个 **[不动点](@entry_id:156394)**（fixed point）。显然，$G$ 的任何[不动点](@entry_id:156394)都是原[方程组](@entry_id:193238) $F(\mathbf{x})=\mathbf{0}$ 的解。

一旦得到[不动点](@entry_id:156394)形式，我们就可以构造一个简单的迭代序列：
$$
\mathbf{x}_{k+1} = G(\mathbf{x}_k)
$$
从一个初始猜测 $\mathbf{x}_0$ 开始，我们希望这个序列能够收敛到[不动点](@entry_id:156394) $\mathbf{x}^*$。

然而，一个[非线性系统](@entry_id:168347)可以有多种不同的[不动点](@entry_id:156394)形式，而并非所有形式都能保证收敛。考虑系统 [@problem_id:2207851]：
$$
\begin{cases}
    x = \exp(-y) \\
    y = \cos(x)
\end{cases}
$$
这个系统已经天然地处于[不动点](@entry_id:156394)形式 $\mathbf{x} = G_1(\mathbf{x})$，其中 $\mathbf{x} = (x, y)^T$ 且 $G_1(x, y) = (\exp(-y), \cos(x))^T$。我们也可以通过反函数将其改写为另一种形式 $\mathbf{x} = G_2(\mathbf{x})$，其中 $G_2(x, y) = (\arccos(y), -\ln(x))^T$。这两种迭代格式 $G_1$ 和 $G_2$ 在同一点附近可能表现出截然不同的收敛行为。这就引出了一个核心问题：迭代何时收敛？

#### [收敛性分析](@entry_id:151547)：[雅可比矩阵](@entry_id:264467)的作用

[不动点迭代](@entry_id:749443)的局部收敛性由 **[巴拿赫不动点定理](@entry_id:146620)**（或称 **[压缩映射定理](@entry_id:147019)**）所支配。该定理指出，如果 $G$ 在一个包含[不动点](@entry_id:156394) $\mathbf{x}^*$ 的[闭集](@entry_id:136446) $D$ 上是一个 **[压缩映射](@entry_id:139989)**（contraction mapping），即存在一个常数 $L  1$ 使得对于 $D$ 中任意的 $\mathbf{x}, \mathbf{y}$，都有 $\|G(\mathbf{x}) - G(\mathbf{y})\| \le L \|\mathbf{x} - \mathbf{y}\|$，那么对于任何初始点 $\mathbf{x}_0 \in D$，迭代序列 $\mathbf{x}_{k+1} = G(\mathbf{x}_k)$ 都将收敛到 $\mathbf{x}^*$。

在实践中，检验[压缩映射](@entry_id:139989)的条件可能很困难。一个更易于操作的局部收敛性判据依赖于函数 $G$ 在[不动点](@entry_id:156394) $\mathbf{x}^*$ 处的 **[雅可比矩阵](@entry_id:264467)**（Jacobian matrix），记为 $J_G(\mathbf{x}^*)$。[雅可比矩阵](@entry_id:264467)是一个由 $G$ 的所有一阶偏导数组成的 $n \times n$ 矩阵：
$$
(J_G)_{ij} = \frac{\partial g_i}{\partial x_j}
$$
迭代的局部收敛性由 $J_G(\mathbf{x}^*)$ 的 **谱半径**（spectral radius）$\rho(J_G(\mathbf{x}^*))$ 决定。[谱半径](@entry_id:138984)定义为其所有[特征值](@entry_id:154894)[绝对值](@entry_id:147688)的最大值。

**局部收敛定理**：设 $\mathbf{x}^*$ 是 $\mathbf{x} = G(\mathbf{x})$ 的一个[不动点](@entry_id:156394)，且 $G$ 在 $\mathbf{x}^*$ 的邻域内连续可微。
1.  如果 $\rho(J_G(\mathbf{x}^*))  1$，则[不动点迭代](@entry_id:749443)在 $\mathbf{x}^*$ 附近是 **局部收敛** 的。也就是说，存在一个包含 $\mathbf{x}^*$ 的邻域，从该邻域内任意初始点 $\mathbf{x}_0$ 出发的迭代序列都会收敛到 $\mathbf{x}^*$。[收敛速度](@entry_id:636873)是 **线性的**，其收敛因子近似为谱半径。
2.  如果 $\rho(J_G(\mathbf{x}^*)) > 1$，则迭代在 $\mathbf{x}^*$ 附近是 **发散** 的。$\mathbf{x}^*$ 是一个[排斥不动点](@entry_id:189650)。

在问题 [@problem_id:2207851] 中，通过计算 $G_1$ 和 $G_2$ 在某点 $(0.5, 0.9)$ 的[雅可比矩阵](@entry_id:264467)的[谱半径](@entry_id:138984)，可以预测它们的收敛行为。计算结果显示 $\rho(J_{G_1}) \approx 0.4415  1$，而 $\rho(J_{G_2}) \approx 2.142 > 1$，这表明迭代方案1很可能收敛，而方案2则会发散。

更深入地分析[雅可比矩阵的特征值](@entry_id:264008)可以揭示更多关于收敛过程的细节 [@problem_id:3281115]。如果一个[特征值](@entry_id:154894) $\lambda$ 是负数且 $|\lambda|  1$，那么误差向量中与该[特征值](@entry_id:154894)对应的分量将在每一步迭代中反号，导致收敛路径呈现[振荡](@entry_id:267781)或螺旋状。如果所有[特征值](@entry_id:154894)的[绝对值](@entry_id:147688)都小于1，即谱半径小于1，那么根据[矩阵分析](@entry_id:204325)的结论，总能找到一个特殊的[向量范数](@entry_id:140649)，使得[雅可比矩阵](@entry_id:264467)在该范数下的[诱导矩阵范数](@entry_id:636174)小于1，从而满足压缩映射的条件。

### [牛顿法](@entry_id:140116)：利用线性化进行快速收敛

虽然[不动点迭代法](@entry_id:168837)概念简单，但其收敛速度通常只是线性的，并且严重依赖于[方程组](@entry_id:193238)的改写形式。**牛顿法**（Newton's Method）是一种更为强大且应用广泛的算法，它通常具有更快的 **二次收敛** 速度。

[牛顿法](@entry_id:140116)的思想是，在当前近似解 $\mathbf{x}_k$ 的附近，用一个[线性模型](@entry_id:178302)来近似[非线性](@entry_id:637147)函数 $F(\mathbf{x})$。这个线性模型就是 $F$ 在 $\mathbf{x}_k$ 处的一阶[泰勒展开](@entry_id:145057)：
$$
F(\mathbf{x}) \approx F(\mathbf{x}_k) + J_F(\mathbf{x}_k)(\mathbf{x} - \mathbf{x}_k)
$$
其中 $J_F(\mathbf{x}_k)$ 是函数 $F$ 在 $\mathbf{x}_k$ 处的雅可比矩阵。我们的目标是找到下一个近似解 $\mathbf{x}_{k+1}$，使得 $F(\mathbf{x}_{k+1})$ 接近于零。于是，我们令[泰勒展开](@entry_id:145057)式为零，并用 $\mathbf{x}_{k+1}$ 代替 $\mathbf{x}$：
$$
F(\mathbf{x}_k) + J_F(\mathbf{x}_k)(\mathbf{x}_{k+1} - \mathbf{x}_k) = \mathbf{0}
$$
定义 **[牛顿步](@entry_id:177069)** 或 **修正向量** $\Delta\mathbf{x}_k = \mathbf{x}_{k+1} - \mathbf{x}_k$，上述方程可以重写为一个关于 $\Delta\mathbf{x}_k$ 的 **[线性方程组](@entry_id:148943)**：
$$
J_F(\mathbf{x}_k) \Delta\mathbf{x}_k = -F(\mathbf{x}_k)
$$
牛顿法的每一次迭代都包含以下步骤：
1.  在当前点 $\mathbf{x}_k$ 计算[残差向量](@entry_id:165091) $F(\mathbf{x}_k)$ 和雅可比矩阵 $J_F(\mathbf{x}_k)$。
2.  求解上述[线性方程组](@entry_id:148943)得到修正向量 $\Delta\mathbf{x}_k$。
3.  更新近似解：$\mathbf{x}_{k+1} = \mathbf{x}_k + \Delta\mathbf{x}_k$。

例如，对于系统 $\sin(x) + y^2 - 1 = 0$ 和 $x + \cos(y) - 1 = 0$，从初始点 $(0, \pi/2)$ 开始，我们可以计算出该点的[雅可比矩阵](@entry_id:264467) $J$ 和残差向量 $F$，然后[求解线性系统](@entry_id:146035) $J \Delta\mathbf{x} = -F$ 得到第一个[牛顿步](@entry_id:177069) [@problem_id:2207875]。这个过程将一个复杂的[非线性](@entry_id:637147)问题在每一步都转化为一个我们熟悉的线性代数问题。

#### [全局化策略](@entry_id:177837)：[回溯线搜索](@entry_id:166118)

牛顿法的二次收敛性仅在解的足够近的邻域内才能保证。如果初始猜测点离解较远，完整的[牛顿步](@entry_id:177069)（即步长为1）可能会导致[残差范数](@entry_id:754273)不减反增，使得迭代发散。为了增强牛顿法的 **[全局收敛性](@entry_id:635436)**（即从远离解的初始点开始也能收敛的能力），需要引入 **[全局化策略](@entry_id:177837)**。

**[回溯线搜索](@entry_id:166118)**（Backtracking Line Search）是一种常用的[全局化策略](@entry_id:177837)。其思想是，在求得牛顿方向 $\Delta\mathbf{x}_k$后，不直接取 $\mathbf{x}_{k+1} = \mathbf{x}_k + \Delta\mathbf{x}_k$，而是引入一个 **步长** $\alpha_k \in (0, 1]$，使得更新公式变为：
$$
\mathbf{x}_{k+1} = \mathbf{x}_k + \alpha_k \Delta\mathbf{x}_k
$$
步长 $\alpha_k$ 的选择目标是保证[残差范数](@entry_id:754273)有足够的下降。一个简单的准则是 **充分下降条件**，例如 $\|F(\mathbf{x}_k + \alpha_k \Delta\mathbf{x}_k)\|_2  \|F(\mathbf{x}_k)\|_2$。[回溯算法](@entry_id:636493)通常从 $\alpha=1$（完整的[牛顿步](@entry_id:177069)）开始尝试，如果条件不满足，则将 $\alpha$ 按一个固定的比例（如 $\rho=0.5$）缩小，即 $\alpha \leftarrow \rho \alpha$，然后重新检验，直到找到第一个满足条件的 $\alpha$ 为止。

在问题 [@problem_id:2207877] 中，对一个特定系统，从 $x_0 = (2, 0)^T$ 开始的完整[牛顿步](@entry_id:177069)并不能使[残差范数](@entry_id:754273)下降。通过[回溯线搜索](@entry_id:166118)，步长被逐步缩减，最终找到一个 $\alpha_0  1$ 的步长，它能够保证迭代向解的方向前进。

#### [奇异雅可比矩阵](@entry_id:147569)：牛顿法的失效与对策

标[准牛顿法](@entry_id:138962)的一个致命弱点是当雅可比矩阵 $J_F(\mathbf{x}_k)$ **奇异**（singular）或接近奇异时，算法会失效。奇异的雅可比矩阵意味着线性系统 $J_F(\mathbf{x}_k) \Delta\mathbf{x}_k = -F(\mathbf{x}_k)$ 可能无解或有无穷多解，导致[牛顿步](@entry_id:177069) $\Delta\mathbf{x}_k$ 无法唯一确定。

考虑一个初始点 $x_0$，其雅可比矩阵 $J(x_0)$ 是奇异的 [@problem_id:2441984]。此时，解的存在性取决于右端项 $-F(x_0)$ 是否位于 $J(x_0)$ 的值域（列空间）中。
- 如果 $-F(x_0)$ 不在 $J(x_0)$ 的值域中，[线性系统](@entry_id:147850)不相容，不存在任何[牛顿步](@entry_id:177069)。
- 如果 $-F(x_0)$ 在 $J(x_0)$ 的值域中，线性系统相容，但由于 $J(x_0)$ 奇异，解不唯一，存在无穷多个满足[线性模型](@entry_id:178302)的修正向量。

在这后一种情况下，标[准牛顿法](@entry_id:138962)无法继续，因为它没有规定如何从无穷多个可能的方向中选择一个。为了解决这个问题，需要更稳健的算法：
1.  **[伪逆](@entry_id:140762)法**：使用 **摩尔-彭若斯[伪逆](@entry_id:140762)**（Moore-Penrose pseudoinverse）$J^+$ 来定义[牛顿步](@entry_id:177069)：$\Delta\mathbf{x}_k = -J_F(\mathbf{x}_k)^+ F(\mathbf{x}_k)$。这会得到所有可行解中[欧几里得范数](@entry_id:172687)最小的那个解，从而唯一地确定了步进方向。
2.  **Levenberg-Marquardt (LM) 法**：该方法通过求解一个正则化的[线性系统](@entry_id:147850)来确定步长，即 $(J_F^T J_F + \lambda I) \Delta\mathbf{x} = -J_F^T F$，其中 $\lambda > 0$ 是一个阻尼参数，$I$ 是[单位矩阵](@entry_id:156724)。矩阵 $(J_F^T J_F + \lambda I)$ 总是正定的（只要 $J$ 的列线性无关或者 $\lambda>0$），因此总是可逆的，保证了修正向量 $\Delta\mathbf{x}$ 的唯一存在。LM方法可以看作是牛顿法和[梯度下降法](@entry_id:637322)之间的一种混合。

这些高级技术确保了即使在[雅可比矩阵](@entry_id:264467)表现不佳的情况下，迭代也能以一种有意义的方式继续进行。

### 拟牛顿法：当雅可比矩阵难以获得时

[牛顿法](@entry_id:140116)的一个主要实际障碍是需要计算和存储雅可比矩阵，并在每一步求解一个线性方程组。在许多大规模问题或“黑箱”模型中，雅可比矩阵的解析表达式可能非常复杂、计算成本高昂，甚至根本无法获得。

**拟牛顿法**（Quasi-Newton Methods）应运而生，其核心思想是避免直接计算真实的[雅可比矩阵](@entry_id:264467) $J_F(\mathbf{x}_k)$，而是用一个更容易计算的矩阵 $B_k$ 来近似它。迭代步变为求解：
$$
B_k \Delta\mathbf{x}_k = -F(\mathbf{x}_k)
$$
然后更新 $\mathbf{x}_{k+1} = \mathbf{x}_k + \Delta\mathbf{x}_k$。关键在于如何构造和更新矩阵 $B_k$。

#### [有限差分](@entry_id:167874)牛顿法

一种最简单的近似方法是使用 **有限差分**（finite differences）来估计[雅可比矩阵](@entry_id:264467)的列。例如，使用[前向差分](@entry_id:173829)公式：
$$
(J_F(\mathbf{x}_k))_{:,j} \approx \frac{F(\mathbf{x}_k + h \mathbf{e}_j) - F(\mathbf{x}_k)}{h}
$$
其中 $\mathbf{e}_j$ 是第 $j$ 个[标准基向量](@entry_id:152417)，$h$ 是一个小的步长。通过对每个变量进行微小扰动并观察函数值的变化，我们可以逐列构建出近似的[雅可比矩阵](@entry_id:264467)。这种方法被称为 **[有限差分](@entry_id:167874)[牛顿法](@entry_id:140116)** [@problem_id:2207899]。它将雅可比矩阵的计算完全转化为函数值的计算，但代价是需要额外的 $n$ 次函数求值，并且需要小心选择步长 $h$ 以[平衡截断](@entry_id:172737)误差和[舍入误差](@entry_id:162651)。

#### Broyden 方法

更高效的拟牛顿法通过一个低秩矩阵对前一步的[雅可比](@entry_id:264467)近似 $B_k$ 进行更新，从而得到 $B_{k+1}$。这种方法的动机是让新的近似矩阵 $B_{k+1}$ 满足所谓的 **[割线条件](@entry_id:164914)**（secant condition）：
$$
B_{k+1}(\mathbf{x}_{k+1} - \mathbf{x}_k) = F(\mathbf{x}_{k+1}) - F(\mathbf{x}_k)
$$
令 $\delta_k = \mathbf{x}_{k+1} - \mathbf{x}_k$ 和 $y_k = F(\mathbf{x}_{k+1}) - F(\mathbf{x}_k)$，[割线条件](@entry_id:164914)写为 $B_{k+1} \delta_k = y_k$。这个条件是单变量割线法思想的直接推广，它要求新的雅可比近似在最近的迭代方向上能够精确地反映函数的变化率。

**Broyden 的“好”方法** 是最著名的拟牛顿更新公式之一。它构造了一个与 $B_k$ 相差一个 **[秩一矩阵](@entry_id:199014)**（rank-one matrix）的 $B_{k+1}$ 来满足[割线条件](@entry_id:164914)：
$$
B_{k+1} = B_k + \frac{(y_k - B_k \delta_k)\delta_k^T}{\delta_k^T \delta_k}
$$
这个更新公式 [@problem_id:2207846] 巧妙地平衡了保留 $B_k$ 的大部分信息和满足新的[割线条件](@entry_id:164914)之间的关系。与有限差分法不同，Broyden 方法不需要额外的函数求值来更新雅可比近似，它利用了上一步迭代已经计算出的信息。

### 实践中的考量：计算成本与问题缩放

在选择求解器时，除了[收敛速度](@entry_id:636873)，计算成本也是一个决定性因素，尤其是在处理大规模问题时。

#### 计算复杂度比较

让我们比较牛顿法和[Broyden方法](@entry_id:138747)在处理一个含有 $n$ 个方程的稠密系统时的单步计算成本 [@problem_id:2207879]。
- **[牛顿法](@entry_id:140116)**：每一步需要：
    1.  计算 $n^2$ 个偏导数来形成[雅可比矩阵](@entry_id:264467) $J_F$。
    2.  通过 LU 分解等方法求解一个 $n \times n$ 的线性系统 $J_F \Delta\mathbf{x} = -F$，其成本约为 $O(n^3)$ 次浮点运算。
- **[Broyden方法](@entry_id:138747)**：每一步需要：
    1.  使用 Sherman-Morrison 公式对 $B_k$ 的 LU 分解进行[秩一更新](@entry_id:137543)，成本约为 $O(n^2)$。
    2.  利用更新后的分解[求解线性系统](@entry_id:146035)，成本也为 $O(n^2)$。

对于大的 $n$，[牛顿法](@entry_id:140116)的 $O(n^3)$ 成本远高于[Broyden方法](@entry_id:138747)的 $O(n^2)$ 成本。因此，尽管牛顿法具有二次收敛性（通常比[拟牛顿法](@entry_id:138962)的[超线性收敛](@entry_id:141654)更快），但其每一步的高昂计算成本可能使其在总计算时间上处于劣势。这解释了为什么在许多实际应用中，特别是在[雅可比矩阵](@entry_id:264467)计算困难或系统规模庞大时，拟牛顿法是首选。

#### 缩放的重要性

数值算法的性能对问题的 **缩放**（scaling）非常敏感。如果系统中的不同方程或变量的尺度相差悬殊，可能会导致[雅可比矩阵](@entry_id:264467) **病态**（ill-conditioned）。一个病态的雅可比矩阵其 **条件数**（condition number）非常大，这意味着对输入的微小扰动会导致解的巨大变化，从而严重影响数值求解的精度和稳定性。

条件数 $\text{cond}(A) = \|A\| \|A^{-1}\|$ 衡量了矩阵求逆对于扰动的敏感性。一个理想的矩阵其[条件数](@entry_id:145150)接近于1。考虑系统 [@problem_id:2207876]，其中一个方程的系数是 $10^4$，而另一个是1。这导致在解点附近的雅可比矩阵具有巨大的[条件数](@entry_id:145150)。

通过对系统进行缩放可以显著改善其条件数。这包括 **行缩放**（乘以一个[对角矩阵](@entry_id:637782) $D_r$ 在左侧，相当于缩放方程）和 **列缩放**（乘以一个对角矩阵 $D_c$ 在右侧，相当于缩放变量）。缩放后的[雅可比矩阵](@entry_id:264467)为 $J_s = D_r J D_c$。通过明智地选择[缩放矩阵](@entry_id:188350)，例如，使得缩放后矩阵的每一行和每一列的范数都接近1，可以将一个[病态矩阵](@entry_id:147408)转化为一个良态矩阵。在问题 [@problem_id:2207876] 的例子中，适当的缩放将雅可比矩阵的条件数降低了七个[数量级](@entry_id:264888)以上。因此，在面对实际问题时，[预处理](@entry_id:141204)和缩放是保证数值方法成功应用的关键步骤。