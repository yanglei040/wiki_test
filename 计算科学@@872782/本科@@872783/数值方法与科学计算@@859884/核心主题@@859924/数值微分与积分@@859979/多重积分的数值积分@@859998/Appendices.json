{"hands_on_practices": [{"introduction": "对于特定类型的积分，尤其是那些在无穷域上且带有特定权重函数的积分，通用积分方法可能效率不高。本练习将探讨如何利用高斯-埃尔米特（Gauss-Hermite）求积法来高效处理带有高斯权重函数的积分。通过利用埃尔米特多项式的正交性，该方法能够通过在这些多项式的根部策略性地放置求积节点，从而以极少的计算量达到非凡的精度。通过这个动手实践 [@problem_id:3258802]，你将亲手实现一个强大的张量积求积法则，并直观地感受其快速收敛的威力。", "problem": "考虑一个平滑函数在二维高斯权重下的积分。设 $f(x,y)$ 为一个函数，其积分\n$$I = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} e^{-(x^2+y^2)} f(x,y)\\,dx\\,dy$$\n是有限的。一种经过充分检验的用于此类积分的数值方法是使用基于埃尔米特多项式的乘积求积：首先为权重 $e^{-x^2}$ 构建一维高斯求积，然后将其独立应用于每个坐标，从而形成多重积分的张量积法则。该方法利用了埃尔米特多项式相对于高斯权重的正交性以及权重在各维度上的可分离性。\n\n在本问题中，您将实现此方法来近似计算\n$$I^\\star = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} e^{-(x^2+y^2)} \\cos(x+y)\\,dx\\,dy,$$\n其中余弦函数使用弧度制来度量角度。您设计的基础是：\n- 黎曼积分的定义和在满足可积条件时交换积分顺序的 Fubini 定理。\n- 埃尔米特多项式族在 $(-\\infty,\\infty)$ 上相对于高斯权重 $e^{-x^2}$ 的正交性，这是高斯求积法则的基础，该法则能够精确地对乘以 $e^{-x^2}$ 权重后最高为特定次数的多项式进行积分。\n- 通过对可分离权重按维度应用一维法则来构建多元乘积求积。\n\n您的程序必须：\n- 使用乘积高斯-埃尔米特求积法则来近似 $I^\\star$。\n- 以弧度处理 $\\cos(\\cdot)$。\n- 为以下测试套件生成结果，该套件通过改变每个维度的求积节点数来评估收敛性、边界行为和各向异性采样：\n    1. $(n_x,n_y) = (1,1)$\n    2. $(n_x,n_y) = (2,3)$\n    3. $(n_x,n_y) = (4,4)$\n    4. $(n_x,n_y) = (8,16)$\n    5. $(n_x,n_y) = (32,32)$\n\n对于每个测试用例，计算 $I^\\star$ 的单个浮点近似值。您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。将每个近似值表示为四舍五入到十位小数的浮点数。例如，包含三个结果的输出应如下所示：\n$$[r_1,r_2,r_3],$$\n其中每个 $r_k$ 是第 $k$ 个测试用例四舍五入到十位小数的近似值。\n\n不涉及物理单位；所有角度均为弧度。程序必须完全自包含，不需要用户输入，并且只使用指定的库。", "solution": "问题陈述已经过验证，被确定为数值分析领域中一个适定且科学上合理的问题。它要求使用一种标准的、明确定义的方法对一个特定的二维积分进行数值近似。所有必要的数据和参数均已提供。\n\n目标是近似二维积分\n$$I^\\star = \\int_{-\\infty}^{\\infty}\\int_{-\\infty}^{\\infty} e^{-(x^2+y^2)} \\cos(x+y)\\,dx\\,dy$$\n被积函数由一个高斯权重函数 $w(x,y) = e^{-(x^2+y^2)}$ 和一个函数 $f(x,y) = \\cos(x+y)$ 组成。指定的数值方法是乘积高斯-埃尔米特求积法则，由于埃尔米特多项式的性质和权重函数的可分离性，该方法特别适用于此类积分。\n\n其基本原理是一维高斯-埃尔米特求积法则。该法则将带有高斯权重的实线上的积分近似为一个离散的加权和：\n$$ \\int_{-\\infty}^{\\infty} e^{-t^2} g(t)\\,dt \\approx \\sum_{k=1}^{n} w_k g(t_k) $$\n在此公式中，$n$ 代表求积节点的数量。节点 $\\{t_k\\}_{k=1}^n$ 是 $n$ 阶物理学家埃尔米特多项式 $H_n(t)$ 的根。相关的权重 $\\{w_k\\}_{k=1}^n$ 经过专门计算，使得当 $g(t)$ 是次数最高为 $2n-1$ 的任意多项式时，该近似是精确的。这种对多项式被积函数的高精度特性使得该方法在近似平滑函数的积分时非常强大，因为平滑函数可以被多项式在局部很好地近似。\n\n对于二维积分 $I^\\star$，权重函数 $w(x,y) = e^{-x^2}e^{-y^2}$ 的可分离性允许构建乘积法则。通过应用 Fubini 定理，我们可以将二重积分表示为累次积分：\n$$ I^\\star = \\int_{-\\infty}^{\\infty} e^{-y^2} \\left( \\int_{-\\infty}^{\\infty} e^{-x^2} \\cos(x+y)\\,dx \\right) dy $$\n数值近似是分层执行的。首先，对于一个固定的 $y$ 值，关于 $x$ 的内层积分使用具有节点 $\\{x_i\\}_{i=1}^{n_x}$ 和权重 $\\{w_i^{(x)}\\}_{i=1}^{n_x}$ 的 $n_x$ 点高斯-埃尔米特法则来近似：\n$$ \\int_{-\\infty}^{\\infty} e^{-x^2} \\cos(x+y)\\,dx \\approx \\sum_{i=1}^{n_x} w_i^{(x)} \\cos(x_i+y) $$\n然后将此近似值代入关于 $y$ 的外层积分中：\n$$ I^\\star \\approx \\int_{-\\infty}^{\\infty} e^{-y^2} \\left( \\sum_{i=1}^{n_x} w_i^{(x)} \\cos(x_i+y) \\right) dy $$\n和的有限性允许交换积分和求和算子：\n$$ I^\\star \\approx \\sum_{i=1}^{n_x} w_i^{(x)} \\int_{-\\infty}^{\\infty} e^{-y^2} \\cos(x_i+y)\\,dy $$\n最后，对于每个固定的 $x_i$，剩余的关于 $y$ 的积分使用具有节点 $\\{y_j\\}_{j=1}^{n_y}$ 和权重 $\\{w_j^{(y)}\\}_{j=1}^{n_y}$ 的 $n_y$ 点高斯-埃尔米特法则来近似：\n$$ \\int_{-\\infty}^{\\infty} e^{-y^2} \\cos(x_i+y)\\,dy \\approx \\sum_{j=1}^{n_y} w_j^{(y)} \\cos(x_i+y_j) $$\n结合这些步骤，得到近似 $I^\\star$ 的最终张量积求积公式：\n$$ I^\\star \\approx \\sum_{i=1}^{n_x} \\sum_{j=1}^{n_y} w_i^{(x)} w_j^{(y)} \\cos(x_i+y_j) $$\n该公式指导我们在二维点网格 $(x_i, y_j)$ 上计算函数 $f(x,y) = \\cos(x+y)$ 的值，然后计算一个加权和，其中每个点的权重是相应的一维求积权重之积 $w_i^{(x)} w_j^{(y)}$。\n\n实现将利用 `numpy.polynomial.hermite.hermgauss` 函数，该函数为给定的点数 $n$ 提供必要的节点和权重。如问题陈述中所指定的，对每个测试用例 $(n_x, n_y)$ 计算双重求和。由于函数 $\\cos(x+y)$ 的平滑性，随着 $n_x$ 和 $n_y$ 的增加，近似值预期会快速收敛到积分的真值，该真值可以解析地证明为 $I^\\star = \\pi e^{-1/2} \\approx 1.9045137660$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes approximations of a 2D integral using product Gauss-Hermite quadrature\n    for a series of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple represents (n_x, n_y), the number of quadrature nodes in\n    # the x and y dimensions, respectively.\n    test_cases = [\n        (1, 1),\n        (2, 3),\n        (4, 4),\n        (8, 16),\n        (32, 32),\n    ]\n\n    results = []\n    for nx, ny in test_cases:\n        # The integral to approximate is:\n        # I = integral from -inf to inf, integral from -inf to inf of\n        #     e^-(x^2+y^2) * cos(x+y) dx dy\n        # This is approximated by the sum:\n        # Sum_i Sum_j w_i * w_j * cos(x_i + y_j)\n        # where (x_i, w_i) and (y_j, w_j) are Gauss-Hermite nodes and weights.\n\n        # Fetch the 1D Gauss-Hermite quadrature nodes and weights.\n        # The function np.polynomial.hermite.hermgauss is designed for integrals\n        # with the weight function e^(-x^2).\n        x_nodes, x_weights = np.polynomial.hermite.hermgauss(nx)\n        y_nodes, y_weights = np.polynomial.hermite.hermgauss(ny)\n\n        # To implement the double summation efficiently, we use NumPy's broadcasting\n        # and outer products.\n\n        # 1. Create a matrix of product weights.\n        #    The element at (j, i) will be y_weights[j] * x_weights[i].\n        weights_matrix = np.outer(y_weights, x_weights)\n\n        # 2. Create a matrix of node sums for the function argument.\n        #    The element at (j, i) will be y_nodes[j] + x_nodes[i].\n        nodes_sum_matrix = np.add.outer(y_nodes, x_nodes)\n\n        # 3. Evaluate the function cos(x+y) on the grid of nodes.\n        #    The angles are in radians, as is standard for `np.cos`.\n        integrand_values = np.cos(nodes_sum_matrix)\n\n        # 4. Compute the final sum by element-wise multiplication and summation.\n        integral_approximation = np.sum(weights_matrix * integrand_values)\n\n        # Round the result to ten decimal places as specified.\n        rounded_result = round(integral_approximation, 10)\n        results.append(rounded_result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3258802"}, {"introduction": "当积分的维度增加时，传统的基于网格的求积方法会遭遇“维度灾难”，即所需的计算节点数量会呈指数级增长。为了解决高维问题，我们需要一种全新的思路。本练习将介绍蒙特卡洛积分法，这是一种通过随机采样来估计积分值的随机方法，其收敛速度与维度无关，使其成为许多高维问题的首选。通过动手估算一个四维超球体的体积 [@problem_id:3258918]，你将直接实现一个蒙特卡洛估计器，并将其结果与解析解进行比较，从而对该方法的强大功能和概率特性获得直观的理解。", "problem": "考虑一个$4$维分析单元：半径为$R$的$4$维球体（超球面）的体积。该体积可以表示为在$\\mathbb{R}^4$上对一个指示函数的多重积分，并使用蒙特卡洛积分进行估计。您的任务是设计并实现一个完整的程序，用蒙特卡洛积分数值估计该体积，并将其与从一个经过充分检验的通用公式推导出的解析结果进行比较。\n\n从以下基本原理出发：\n- 一个可测区域 $\\Omega \\subset \\mathbb{R}^d$ 的体积等于其指示函数 $I_{\\Omega}(\\mathbf{x})$ 在 $\\mathbb{R}^d$ 上的积分，即 $\\mathrm{Vol}(\\Omega) = \\int_{\\mathbb{R}^d} I_{\\Omega}(\\mathbf{x}) \\, d\\mathbf{x}$，其中当 $\\mathbf{x} \\in \\Omega$ 时 $I_{\\Omega}(\\mathbf{x}) = 1$，否则 $I_{\\Omega}(\\mathbf{x}) = 0$。\n- 蒙特卡洛积分通过从一个测度有限的域 $D$（测度为 $|D|$）中均匀采样 $\\mathbf{X}_1,\\dots,\\mathbf{X}_N$ 来估计 $\\int_{D} f(\\mathbf{x}) \\, d\\mathbf{x}$，并计算 $\\widehat{I}_N = |D|\\cdot \\frac{1}{N}\\sum_{i=1}^{N} f(\\mathbf{X}_i)$。\n- 半径为 $R$ 的 $n$ 维球体的体积的经过充分检验的通用公式是 $V_n(R) = \\dfrac{\\pi^{n/2} R^n}{\\Gamma\\!\\left(\\frac{n}{2}+1\\right)}$，其中 $\\Gamma$ 是伽马函数。\n\n程序中需要完成的任务：\n1. 将半径为 $R$ 的4维球体的体积表示为在包围超立方体 $D = [-R,R]^4$ 上的指示函数的积分，并设计一个蒙特卡洛估计器，使用从 $D$ 中均匀抽取的 $N$ 个独立同分布样本来估计此积分。\n2. 使用通用的 $n$ 维球体公式和伽马函数的性质，推导出在维度 $n=4$ 时精确体积关于 $R$ 的解析闭式解。\n3. 对下面的每个测试用例，计算：\n   - 使用您的估计器计算出的体积的蒙特卡洛估计值 $\\widehat{V}$。\n   - 精确解析体积 $V_{\\text{exact}}$。\n   - 按如下方式定义的误差度量 $E$：\n     - 如果 $V_{\\text{exact}} > 0$，使用相对误差 $E = \\dfrac{|\\widehat{V} - V_{\\text{exact}}|}{V_{\\text{exact}}}$。\n     - 如果 $V_{\\text{exact}} = 0$，使用绝对误差 $E = |\\widehat{V} - V_{\\text{exact}}|$。\n   - 将每个误差 $E$ 四舍五入到6位小数。\n\n实现要求：\n- 程序必须是一个独立的脚本，仅使用 Python 标准库和 NumPy 库。\n- 程序不得读取任何输入；必须将下方的测试套件硬编码，并产生单行输出。\n- 必须通过使用提供的种子初始化伪随机数生成器来确保随机性是可复现的。\n\n测试套件：\n- 用例 1：$R = 1.0$， $N = 200000$， $\\text{seed} = 12345$。\n- 用例 2：$R = 0.0$， $N = 10000$， $\\text{seed} = 2023$。\n- 用例 3：$R = 1.0$， $N = 1$， $\\text{seed} = 7$。\n- 用例 4：$R = 1.5$， $N = 150000$， $\\text{seed} = 314159$。\n- 用例 5：$R = 2.0$， $N = 120000$， $\\text{seed} = 424242$。\n\n最终输出格式：\n- 您的程序应产生单行输出，其中包含测试用例的误差，格式为一个用方括号括起来的逗号分隔列表，顺序与上面列出的用例相同，每个误差四舍五入到6位小数，例如 $[e_1,e_2,e_3,e_4,e_5]$，其中每个 $e_i$ 是一个十进制数。", "solution": "该问题要求使用蒙特卡洛积分对半径为 $R$ 的4维球体（超球面）的体积进行数值估计。此估计值将与精确的解析体积进行比较，以计算误差度量。该过程涉及三个主要步骤：推导体积的解析公式，设计蒙特卡洛估计器，以及为一组给定的测试用例实现计算。\n\n### 1. 4维球体的解析体积\n\n问题提供了半径为 $R$ 的 $n$ 维球体的通用体积公式：\n$$V_n(R) = \\frac{\\pi^{n/2} R^n}{\\Gamma\\left(\\frac{n}{2}+1\\right)}$$\n其中 $\\Gamma(z)$ 是伽马函数。\n\n对于我们的特定情况，维度是 $n=4$。将 $n=4$ 代入公式可得：\n$$V_4(R) = \\frac{\\pi^{4/2} R^4}{\\Gamma\\left(\\frac{4}{2}+1\\right)} = \\frac{\\pi^2 R^4}{\\Gamma(2+1)} = \\frac{\\pi^2 R^4}{\\Gamma(3)}$$\n伽马函数具有以下性质：对于任何正整数 $k$，$\\Gamma(k) = (k-1)!$。因此，对于 $k=3$：\n$$\\Gamma(3) = (3-1)! = 2! = 2 \\cdot 1 = 2$$\n将此结果代回体积公式，得到半径为 $R$ 的4维球体的精确解析表达式：\n$$V_{\\text{exact}} = V_4(R) = \\frac{\\pi^2 R^4}{2}$$\n\n### 2. 蒙特卡洛估计器设计\n\n区域 $\\Omega \\subset \\mathbb{R}^4$ 的体积可以表示为其指示函数 $I_{\\Omega}(\\mathbf{x})$ 的积分：\n$$V = \\int_{\\mathbb{R}^4} I_{\\Omega}(\\mathbf{x}) \\, d\\mathbf{x}$$\n其中，如果 $\\mathbf{x} \\in \\Omega$，则 $I_{\\Omega}(\\mathbf{x}) = 1$，否则 $I_{\\Omega}(\\mathbf{x}) = 0$。对于以原点为中心、半径为 $R$ 的4维球体，该区域为 $\\Omega = \\{ \\mathbf{x} \\in \\mathbb{R}^4 : \\|\\mathbf{x}\\|_2 \\le R \\}$，或 $\\Omega = \\{ (x_1, x_2, x_3, x_4) : x_1^2 + x_2^2 + x_3^2 + x_4^2 \\le R^2 \\}$。\n\n为了应用蒙特卡洛积分，我们选择一个简单的采样域 $D$，它包围 $\\Omega$ 并且体积 $|D|$ 已知。一个自然的选择是超立方体 $D = [-R, R]^4$。该超立方体的体积是：\n$$|D| = (R - (-R))^4 = (2R)^4 = 16R^4$$\n$\\Omega$ 的体积积分可以重写在该域 $D$ 上：\n$$V = \\int_{D} I_{\\Omega}(\\mathbf{x}) \\, d\\mathbf{x}$$\n因为对于 $\\Omega$ 之外的任何 $\\mathbf{x}$（因此也包括 $D \\setminus \\Omega$ 中的任何 $\\mathbf{x}$），都有 $I_{\\Omega}(\\mathbf{x})=0$。\n\n蒙特卡洛方法通过从 $D$ 中独立且均匀地采样 $N$ 个点 $\\mathbf{X}_1, \\dots, \\mathbf{X}_N$ 来估计该积分。该积分的估计器由下式给出：\n$$\\widehat{V} = |D| \\cdot \\frac{1}{N} \\sum_{i=1}^N I_{\\Omega}(\\mathbf{X}_i)$$\n设 $N_{in}$ 是落在超球面 $\\Omega$ 内部或边界上的采样点数量。这个计数恰好是 $N_{in} = \\sum_{i=1}^N I_{\\Omega}(\\mathbf{X}_i)$。那么体积的估计器可以写成：\n$$\\widehat{V} = |D| \\cdot \\frac{N_{in}}{N} = 16R^4 \\cdot \\frac{N_{in}}{N}$$\n这是超球体的体积与超立方体体积之比，通过“命中点”数与总样本数之比来近似，再乘以超立方体的体积。\n\n对于 $R=0$ 的特殊情况，超球面是一个体积为 $V_{\\text{exact}}=0$ 的单点。其包围盒 $D = [0,0]^4$ 的体积 $|D|$ 也为0，估计器正确地得出 $\\widehat{V}=0$。\n\n### 3. 计算过程和误差度量\n\n对于由参数 $(R, N, \\text{seed})$ 定义的每个测试用例，执行以下过程：\n1.  **初始化随机数生成器（RNG）**：使用给定的种子（seed）为伪随机数生成器提供种子，以确保可复现性。\n2.  **计算精确体积**：使用公式 $V_4(R) = \\frac{1}{2}\\pi^2 R^4$ 计算 $V_{\\text{exact}}$。\n3.  **生成样本**：生成 $N$ 个随机向量 $\\mathbf{X}_i$，每个向量有4个分量。每个分量从区间 $[-R, R]$ 上的均匀分布中抽取。\n4.  **统计“命中点”**：对于每个样本 $\\mathbf{X}_i = (x_{i1}, x_{i2}, x_{i3}, x_{i4})$，我们通过检验条件 $x_{i1}^2 + x_{i2}^2 + x_{i3}^2 + x_{i4}^2 \\le R^2$ 来检查它是否落在4维球体内。统计满足此条件的样本数量 $N_{in}$。\n5.  **计算蒙特卡洛估计值**：使用公式 $\\widehat{V} = 16R^4 \\cdot (N_{in} / N)$ 计算估计体积 $\\widehat{V}$。如果 $R=0$，这个计算是平凡的，因为 $\\widehat{V}=0$。\n6.  **计算误差**：根据 $V_{\\text{exact}}$ 的值计算误差度量 $E$：\n    -   如果 $V_{\\text{exact}} > 0$：相对误差计算为 $E = \\dfrac{|\\widehat{V} - V_{\\text{exact}}|}{V_{\\text{exact}}}$。\n    -   如果 $V_{\\text{exact}} = 0$：绝对误差计算为 $E = |\\widehat{V} - V_{\\text{exact}}|$。这种情况在 $R=0$ 时发生，此时 $\\widehat{V}$ 和 $V_{\\text{exact}}$ 均为0，导致误差 $E=0$。\n7.  **存储结果**：将计算出的误差 $E$ 四舍五入到6位小数。\n\n对所有测试用例重复此过程，并将得到的四舍五入后的误差列表格式化为最终输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating the volume of a 4D ball using Monte Carlo integration\n    and comparing it to the analytical result for a suite of test cases.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (R, N, seed)\n        (1.0, 200000, 12345),\n        (0.0, 10000, 2023),\n        (1.0, 1, 7),\n        (1.5, 150000, 314159),\n        (2.0, 120000, 424242),\n    ]\n\n    results = []\n    for R, N, seed in test_cases:\n        # Task 2: Calculate the exact analytical volume V_exact.\n        # The volume of an n-ball is V_n(R) = (pi^(n/2) * R^n) / Gamma(n/2 + 1).\n        # For n=4, this simplifies to V_4(R) = (pi^2 * R^4) / Gamma(3) = (pi^2 * R^4) / 2.\n        v_exact = (np.pi**2 * R**4) / 2.0\n\n        # Task 1: Design and run the Monte Carlo estimator.\n        \n        # Initialize the pseudorandom number generator for reproducibility.\n        rng = np.random.default_rng(seed)\n\n        v_hat = 0.0\n        # The Monte Carlo simulation is only meaningful for R > 0.\n        # If R = 0, the volume of the ball and bounding box are both 0.\n        if R > 0.0:\n            # Generate N random points in a 4-dimensional space.\n            # The points are sampled from a hypercube D = [-R, R]^4.\n            # rng.uniform generates values in [low, high). Here, [-R, R).\n            # The shape (N, 4) creates N points, each with 4 coordinates.\n            points = rng.uniform(low=-R, high=R, size=(N, 4))\n\n            # Calculate the squared Euclidean distance from the origin for each point.\n            # This is more efficient than calculating the Euclidean distance as it avoids sqrt.\n            # np.sum(points**2, axis=1) calculates x1^2+x2^2+x3^2+x4^2 for each point.\n            squared_distances = np.sum(points**2, axis=1)\n\n            # Count the number of points that fall inside or on the surface of the 4-ball.\n            # The condition is ||x||^2 = R^2.\n            n_in = np.sum(squared_distances = R**2)\n\n            # The volume of the sampling hypercube D = [-R, R]^4 is (2R)^4.\n            volume_of_domain = (2.0 * R)**4\n\n            # The Monte Carlo estimate is the volume of the sampling domain\n            # times the ratio of points inside the hypersphere to the total number of points.\n            v_hat = volume_of_domain * (n_in / N)\n        \n        # Task 3: Compute the error metric E.\n        error = 0.0\n        if v_exact > 0:\n            # Relative error\n            error = np.abs(v_hat - v_exact) / v_exact\n        else:\n            # Absolute error (for the R=0 case)\n            error = np.abs(v_hat - v_exact)\n        \n        # Round the error to 6 decimal places.\n        rounded_error = round(error, 6)\n        results.append(str(rounded_error))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3258918"}, {"introduction": "对于高维问题，蒙特卡洛方法是唯一的选择吗？当被积函数具有特定结构，例如在某些方向上的变化远比其他方向剧烈（即各向异性）时，我们可以设计出比标准蒙特卡洛方法更高效的“智能”网格方法。本项高级实践深入探讨了各向异性稀疏网格，它利用Smolyak构造来构建一个高效的积分网格。该方法巧妙地将更多的网格点分配到函数变化最剧烈的维度上，从而避免了张量积网格带来的完全指数级计算成本。这个练习 [@problem_id:3258801] 将挑战你实现一种前沿的数值方法，并通过实验证明，将网格的各向异性与函数的各向异性对齐，能够带来显著的计算资源节省。", "problem": "考虑使用嵌套稀疏网格对立方体 $[-1,1]^3$ 上的三维多重积分进行数值逼近。设被积函数为各向异性函数 $f(\\mathbf{x})=\\exp(-x_1^2-100 x_2^2- x_3^2)$，其中 $\\mathbf{x}=(x_1,x_2,x_3)$。目标是设计并实现一个基于 Smolyak 构造和嵌套一维规则的各向异性稀疏网格求积方法，研究如何通过重排维度权重以匹配各向异性来影响唯一网格节点的数量，并量化节点数的节省量。\n\n从以下基础出发：积分的线性性、用于多重积分的张量积求积、基于 Chebyshev 极值点（Clenshaw–Curtis 节点）的插值型一维求积，以及 Smolyak 构造的定义，即由嵌套一维求积构建的张量积差分规则的线性组合。利用这些基础推导出一个算法，该算法能够：\n- 在 $[-1,1]$ 上构建递增层级 $\\ell\\in\\mathbb{N}$（$\\ell\\ge 1$）的嵌套一维求积规则，其中层级 $\\ell$ 具有 $N_\\ell$ 个节点，且规则是嵌套的，即层级 $\\ell-1$ 的节点是层级 $\\ell$ 节点的子集。\n- 将一维差分规则形式化为层级 $\\ell$ 和 $\\ell-1$ 上连续嵌套求积规则之差，利用伸缩求和的特性来组合稀疏网格求积，该求积是可接受多重指标上的一维差分张量积之和。\n- 使用加权层级预算约束来选择可接受的多重指标 $\\boldsymbol{\\ell}=(\\ell_1,\\ell_2,\\ell_3)$，该约束通过非负权重 $\\mathbf{a}=(a_1,a_2,a_3)$ 来编码各向异性：\n$$\n\\sum_{i=1}^3 a_i(\\ell_i-1)\\le L,\n$$\n其中 $L$ 是一个非负预算参数，$\\ell_i\\ge 1$ 是整数。为避免一维规则大小的无界增长，对层级施加一个上限：对所有 $i$ 都有 $\\ell_i\\le \\ell_{\\max}$。此上限必须在所有维度上一致应用。\n\n通过在所选节点上对最高 $N_\\ell-1$ 次的多项式强制精确性来实现一维插值求积权重，使用矩条件 $\\int_{-1}^{1} x^j\\,dx$（其中 $j=0,1,\\dots,N_\\ell-1$）。对所有层级使用嵌套的 Clenshaw–Curtis 节点（Chebyshev 极值点）。通过在可接受多重指标集上聚合一维差分规则的笛卡尔积来组装三维稀疏网格，对重复的节点和权重求和，形成一个包含其聚合权重的唯一节点集。通过将聚合权重与唯一节点上的函数值相乘并求和，来逼近积分 $\\int_{[-1,1]^3} f(\\mathbf{x})\\,d\\mathbf{x}$。\n\n通过置换维度权重 $\\mathbf{a}$ 和坐标索引 $(x_1,x_2,x_3)$ 之间的关联来研究变量重排。对于给定的 $\\mathbf{a}$ 和预算 $L$，定义两种配置：\n- 一种未对齐配置，其中最小的权重被分配给各向异性较低的维度，以及\n- 一种对齐配置，其中最小的权重被分配给各向异性最强的维度 $x_2$。\n\n对于每种配置，计算：\n- $[-1,1]^3$ 上 $f$ 的近似积分值（无单位），\n- 唯一稀疏网格节点的数量，\n- 通过重排节省的节点数（整数），定义为未对齐节点数与对齐节点数之差。\n\n设计一个测试套件，用于测试边界条件、正常路径和各向异性中的边缘情况：\n- 测试用例 1：$L=0$，$\\ell_{\\max}=6$，未对齐权重 $\\mathbf{a}=[0.5,1.0,1.0]$，对齐权重 $\\mathbf{a}=[1.0,0.5,1.0]$。\n- 测试用例 2：$L=2$，$\\ell_{\\max}=6$，未对齐权重 $\\mathbf{a}=[0.5,1.0,1.0]$，对齐权重 $\\mathbf{a}=[1.0,0.5,1.0]$。\n- 测试用例 3：$L=4$，$\\ell_{\\max}=6$，未对齐权重 $\\mathbf{a}=[0.5,1.0,1.0]$，对齐权重 $\\mathbf{a}=[1.0,0.5,1.0]$。\n- 测试用例 4：$L=4$，$\\ell_{\\max}=6$，未对齐权重 $\\mathbf{a}=[0.3,1.0,1.0]$，对齐权重 $\\mathbf{a}=[1.0,0.3,1.0]$。\n\n对于每个测试用例，您的程序必须生成一个列表，其中包含 $[\\text{approx\\_misaligned},\\ \\text{nodes\\_misaligned},\\ \\text{approx\\_aligned},\\ \\text{nodes\\_aligned},\\ \\text{savings}]$，其中 $\\text{approx\\_misaligned}$ 和 $\\text{approx\\_aligned}$ 是浮点数，其余条目是整数。最终输出必须是单行文本，其中包含所有测试用例的结果，形式为方括号括起来的逗号分隔列表，例如 $[[\\dots],[\\dots],[\\dots],[\\dots]]$，不含任何额外文本。不出现角度，也没有物理单位；所有量纲均为无量纲。", "solution": "该问题是数值分析领域一个有效练习，具体涉及应用各向异性稀疏网格求积来逼近一个三维积分。问题陈述具有科学依据，是适定的、客观的。它提供了构建唯一、可验证解所需的所有要素。\n\n任务是逼近各向异性函数 $f(\\mathbf{x})=\\exp(-x_1^2-100 x_2^2- x_3^2)$ 在定义域 $[-1,1]^3$ 上的积分。各向异性源于与变量 $x_2$ 相关的大系数 $100$，这导致函数在该方向上的变化远比其他方向剧烈。为了高效地处理这种情况，我们采用基于 Smolyak 构造的各向异性稀疏网格求积方法。该方法通过一组权重 $\\mathbf{a}=(a_1, a_2, a_3)$ 控制，智能地在变化剧烈的方向上分配更多的网格点。\n\n**1. 一维求积规则**\n\n稀疏网格的基础是一系列嵌套的一维求积规则。对于每个层级 $\\ell \\in \\mathbb{N}$（$\\ell \\ge 1$），我们定义一个求积算子 $\\mathcal{Q}^{(\\ell)}$，用于逼近一维积分 $\\int_{-1}^{1} g(x)\\,dx$。\n$$\n\\mathcal{Q}^{(\\ell)}[g] = \\sum_{j=1}^{N_\\ell} w_j^{(\\ell)} g(x_j^{(\\ell)})\n$$\n节点 $\\{x_j^{(\\ell)}\\}$ 被选为嵌套的 Clenshaw-Curtis 点（$[-1,1]$ 上的 Chebyshev 极值点），这确保了层级 $\\ell-1$ 的节点集是层级 $\\ell$ 节点集的子集。点数 $N_\\ell$ 及其位置由以下公式给出：\n- 对于层级 $\\ell=1$：$N_1 = 1$ 个节点，位于 $x_1^{(1)} = 0$。\n- 对于层级 $\\ell  1$：$N_\\ell = 2^{\\ell-1}+1$ 个节点，位于 $x_j^{(\\ell)} = \\cos\\left(\\frac{(j-1)\\pi}{N_\\ell-1}\\right)$，其中 $j=1, \\dots, N_\\ell$。\n\n权重 $\\{w_j^{(\\ell)}\\}$ 通过强制该规则对所有次数最高为 $N_\\ell-1$ 的多项式都精确来确定。这导出了一个包含 $N_\\ell$ 个线性方程的方程组，称为矩条件：\n$$\n\\sum_{j=1}^{N_\\ell} w_j^{(\\ell)} (x_j^{(\\ell)})^k = \\int_{-1}^{1} x^k \\,dx \\quad \\text{for } k = 0, 1, \\dots, N_\\ell-1\n$$\n对于偶数 $k$，右侧的值为 $2/(k+1)$；对于奇数 $k$，右侧的值为 $0$。该系统可以表示为矩阵形式 $V\\mathbf{w}^{(\\ell)} = \\mathbf{m}$，其中 $V$ 是范德蒙矩阵，其元素为 $V_{kj} = (x_j^{(\\ell)})^{k-1}$，$\\mathbf{m}$ 是矩向量。求解该系统即可得到层级 $\\ell$ 的权重。\n\n**2. 各向异性 Smolyak 构造**\n\n稀疏网格逼近是通过一维求积规则的张量积的线性组合来构造的。包含哪些张量积网格的选择由一个各向异性可接受性条件控制。一个多重指标 $\\boldsymbol{\\ell}=(\\ell_1, \\ell_2, \\ell_3)$（其中 $\\ell_i$ 是维度 $i$ 的层级）如果满足预算约束，则被认为是可接受的：\n$$\n\\sum_{i=1}^3 a_i(\\ell_i-1) \\le L\n$$\n这里，$L \\ge 0$ 是总预算，$\\mathbf{a}=(a_1, a_2, a_3)$ 是一个控制各向异性的正权重向量。较小的权重 $a_i$ 允许在维度 $i$ 上使用更高的层级 $\\ell_i$，从而在该方向上更精细地加密网格。此外，还施加了一个最大层级 $\\ell_{\\max}$，因此对所有 $i$ 都有 $1 \\le \\ell_i \\le \\ell_{\\max}$。设 $I(L, \\mathbf{a}, \\ell_{\\max})$ 表示所有此类可接受多重指标的集合。\n\n使用组合技术，各向异性稀疏网格求积算子 $\\mathcal{A}_{L, \\mathbf{a}}$ 由下式给出：\n$$\n\\mathcal{A}_{L, \\mathbf{a}}[f] = \\sum_{\\boldsymbol{\\ell} \\in I(L, \\mathbf{a}, \\ell_{\\max})} c_{\\boldsymbol{\\ell}} \\left(\\mathcal{Q}^{(\\ell_1)} \\otimes \\mathcal{Q}^{(\\ell_2)} \\otimes \\mathcal{Q}^{(\\ell_3)}\\right)[f]\n$$\n符号 $\\otimes$ 表示算子的张量积。张量积求积对函数 $f(x_1, x_2, x_3)$ 的作用如下：\n$$\n\\left(\\mathcal{Q}^{(\\ell_1)} \\otimes \\mathcal{Q}^{(\\ell_2)} \\otimes \\mathcal{Q}^{(\\ell_3)}\\right)[f] = \\sum_{j_1=1}^{N_{\\ell_1}} \\sum_{j_2=1}^{N_{\\ell_2}} \\sum_{j_3=1}^{N_{\\ell_3}} w_{j_1}^{(\\ell_1)} w_{j_2}^{(\\ell_2)} w_{j_3}^{(\\ell_3)} f\\left(x_{j_1}^{(\\ell_1)}, x_{j_2}^{(\\ell_2)}, x_{j_3}^{(\\ell_3)}\\right)\n$$\n组合系数 $c_{\\boldsymbol{\\ell}}$ 由多重指标格上的容斥原理确定：\n$$\nc_{\\boldsymbol{\\ell}} = \\sum_{\\mathbf{j} \\in \\{0, 1\\}^3 \\text{ s.t. } \\boldsymbol{\\ell}+\\mathbf{j} \\in I(L, \\mathbf{a}, \\ell_{\\max})} (-1)^{|\\mathbf{j}|_1}\n$$\n其中 $|\\mathbf{j}|_1 = j_1+j_2+j_3$。此公式确保每个张量积网格以正确的重数贡献，以抵消被重复计算的低阶项。\n\n**3. 算法实现与各向异性**\n\n整体算法流程如下：\n1.  **生成可接受指标**：对于给定的预算 $L$、权重 $\\mathbf{a}$ 和上限 $\\ell_{\\max}$，生成满足约束的所有多重指标 $\\boldsymbol{\\ell}=(\\ell_1, \\ell_2, \\ell_3)$ 的集合 $I(L, \\mathbf{a}, \\ell_{\\max})$。\n2.  **组装稀疏网格**：初始化一个空字典，用于存储最终的唯一网格点及其聚合权重。遍历可接受集合中的每个 $\\boldsymbol{\\ell}$。\n    a. 计算组合系数 $c_{\\boldsymbol{\\ell}}$。\n    b. 如果 $c_{\\boldsymbol{\\ell}} \\neq 0$，则构建对应于 $\\boldsymbol{\\ell}$ 的张量积网格。对于该网格中的每个点 $(x_{j_1}, x_{j_2}, x_{j_3})$，计算其复合权重 $c_{\\boldsymbol{\\ell}} \\cdot w_{j_1}^{(\\ell_1)} w_{j_2}^{(\\ell_2)} w_{j_3}^{(\\ell_3)}$。\n    c. 将此复合权重加到全局字典中相应节点上，对任何重复节点累加权重。\n3.  **逼近积分**：一旦组装好最终的唯一节点和聚合权重集，通过对这些节点上的权重与函数值的乘积求和来逼近积分。\n\n该问题研究了将网格的各向异性与函数的各向异性对齐的效果。函数 $f(\\mathbf{x})=\\exp(-x_1^2-100 x_2^2- x_3^2)$ 在 $x_2$ 方向上最敏感（各向异性最强）。为了高效地达到高精度，我们必须在该方向上使用更精细的网格（更高的层级 $\\ell_2$）。这通过将最小的权重 $a_i$ 分配给各向异性最强的维度来实现。\n- **对齐配置**：将小权重分配给 $a_2$，例如 $\\mathbf{a}=[1.0, 0.5, 1.0]$。这会优先在 $x_2$ 方向进行加密。\n- **未对齐配置**：将小权重分配给一个不太敏感的维度，例如 $\\mathbf{a}=[0.5, 1.0, 1.0]$ 将其分配给 $x_1$。\n\n我们期望对于给定的预算 $L$，对齐配置能用更少的总网格点数产生更精确的逼近，因为计算精力被集中在最需要的地方。节点数的“节省量”量化了这种效率增益。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem as specified.\n    It runs through the test cases, builds the sparse grids,\n    computes the approximations and node counts, and prints the results.\n    \"\"\"\n\n    # Define the integrand function\n    def integrand(x):\n        return np.exp(-x[0]**2 - 100*x[1]**2 - x[2]**2)\n\n    # Memoization cache for 1D quadrature rules\n    rule_cache = {}\n\n    def get_1d_rule(level):\n        \"\"\"\n        Computes or retrieves from cache the nodes and weights for a 1D\n        Clenshaw-Curtis quadrature rule of a given level.\n        \"\"\"\n        if level in rule_cache:\n            return rule_cache[level]\n\n        if level == 1:\n            nodes = np.array([0.0])\n            weights = np.array([2.0])\n            rule_cache[level] = (nodes, weights)\n            return nodes, weights\n\n        n_points = 2**(level - 1) + 1\n        # Nodes are Chebyshev extrema, ordered from 1 to -1\n        nodes = np.cos(np.arange(n_points) * np.pi / (n_points - 1))\n\n        # Solve Vandermonde system for weights\n        V = np.vander(nodes, n_points, increasing=True).T\n        m = np.zeros(n_points)\n        for k in range(n_points):\n            if k % 2 == 0:\n                m[k] = 2.0 / (k + 1.0)\n        \n        weights = np.linalg.solve(V, m)\n        \n        rule_cache[level] = (nodes, weights)\n        return nodes, weights\n\n    def find_admissible_indices(L, a, l_max):\n        \"\"\"\n        Generates the set of admissible multi-indices.\n        \"\"\"\n        indices = set()\n        for l1 in range(1, l_max + 1):\n            for l2 in range(1, l_max + 1):\n                for l3 in range(1, l_max + 1):\n                    if a[0] * (l1 - 1) + a[1] * (l2 - 1) + a[2] * (l3 - 1) = L:\n                        indices.add((l1, l2, l3))\n        return indices\n\n    def build_sparse_grid(L, a, l_max):\n        \"\"\"\n        Constructs the sparse grid and computes the integral approximation.\n        \"\"\"\n        admissible_indices = find_admissible_indices(L, a, l_max)\n        sparse_grid_points = {}\n\n        # Loop over admissible multi-indices to build the grid\n        for l_vec in admissible_indices:\n            # Calculate combination coefficient\n            c_l = 0\n            for i in range(8): # Iterate through j in {0,1}^3\n                j_vec = ((i >> 2)  1, (i >> 1)  1, i  1)\n                neighbor_l_vec = (l_vec[0] + j_vec[0], l_vec[1] + j_vec[1], l_vec[2] + j_vec[2])\n                if neighbor_l_vec in admissible_indices:\n                    c_l += (-1)**sum(j_vec)\n            \n            if abs(c_l)  1e-15:\n                continue\n\n            # Get 1D rules for the current multi-index\n            nodes1, weights1 = get_1d_rule(l_vec[0])\n            nodes2, weights2 = get_1d_rule(l_vec[1])\n            nodes3, weights3 = get_1d_rule(l_vec[2])\n\n            # Add tensor product points to the sparse grid\n            for i1, n1 in enumerate(nodes1):\n                for i2, n2 in enumerate(nodes2):\n                    for i3, n3 in enumerate(nodes3):\n                        node = (n1, n2, n3)\n                        # Round nodes to handle floating point inaccuracies in dict keys\n                        key = (round(node[0], 15), round(node[1], 15), round(node[2], 15))\n                        weight = c_l * weights1[i1] * weights2[i2] * weights3[i3]\n                        \n                        sparse_grid_points[key] = sparse_grid_points.get(key, 0.0) + weight\n\n        # Approximate integral by summing over the final grid\n        integral_approx = 0.0\n        # Filter out points with negligible weights before summing\n        final_grid = {node: weight for node, weight in sparse_grid_points.items() if abs(weight) > 1e-15}\n        for node, weight in final_grid.items():\n            integral_approx += weight * integrand(node)\n                \n        num_nodes = len(final_grid)\n        \n        return integral_approx, num_nodes\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0, 6, [0.5, 1.0, 1.0], [1.0, 0.5, 1.0]),\n        (2, 6, [0.5, 1.0, 1.0], [1.0, 0.5, 1.0]),\n        (4, 6, [0.5, 1.0, 1.0], [1.0, 0.5, 1.0]),\n        (4, 6, [0.3, 1.0, 1.0], [1.0, 0.3, 1.0]),\n    ]\n    \n    results = []\n    for case in test_cases:\n        L_val, l_max_val, a_misaligned, a_aligned = case\n        \n        # Misaligned configuration\n        approx_misaligned, nodes_misaligned = build_sparse_grid(L_val, a_misaligned, l_max_val)\n        \n        # Aligned configuration\n        approx_aligned, nodes_aligned = build_sparse_grid(L_val, a_aligned, l_max_val)\n        \n        # Savings\n        savings = nodes_misaligned - nodes_aligned\n        \n        results.append([approx_misaligned, nodes_misaligned, approx_aligned, nodes_aligned, savings])\n\n    # Final print statement in the exact required format.\n    # Convert list of lists to the specific string format\n    result_str = ','.join(map(str, results))\n    print(f\"[{result_str}]\")\n\nsolve()\n\n```", "id": "3258801"}]}