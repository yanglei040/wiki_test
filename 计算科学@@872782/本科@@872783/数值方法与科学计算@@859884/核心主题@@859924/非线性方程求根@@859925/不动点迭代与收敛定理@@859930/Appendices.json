{"hands_on_practices": [{"introduction": "理论的生命力在于实践。方程 $x = \\cos x$ 是不动点迭代的一个经典案例，它直观地展示了压缩映射定理的威力。通过这个练习，你不仅将从理论上证明迭代为何必然收敛于唯一不动点，还将通过编程亲眼观察其收敛过程，并分析其序列有趣的振荡收敛行为。[@problem_id:3231288]", "problem": "考虑在闭区间 $[0,1]$ 上定义的不动点方程 $x=\\cos x$ 和不动点迭代 $x_{k+1}=\\cos x_k$。使用以下基本依据：对于函数 $g$，满足 $x^\\star=g(x^\\star)$ 的不动点 $x^\\star$ 的定义、中值定理 (MVT) 和压缩映射定理 (CMT)（也称为 Banach 不动点定理）。迭代使用弧度作为角度单位。您的程序必须实现该迭代，并对指定的测试套件验证其收敛性和单调性。\n\n任务：\n- 从基本定义出发，证明函数 $g(x)=\\cos x$ 将 $[0,1]$ 映射到自身。使用导数 $g'(x)=-\\sin x$ 以及 $\\sin(1)1$ 的界 $\\sup_{x\\in[0,1]}|\\sin x|=\\sin(1)$，论证 $g$ 是 $[0,1]$ 上的一个压缩映射，因此存在唯一的不动点 $x^\\star\\in[0,1]$，对于任何 $x_0\\in[0,1]$，序列 $\\{x_k\\}$ 都收敛于该不动点。\n- 分析迭代序列的单调行为。由于 $g$ 在 $[0,1]$ 上是严格递减的，因此完整序列 $\\{x_k\\}$ 通常不是单调的。然而，需要证明偶子序列 $\\{x_{2k}\\}$ 和奇子序列 $\\{x_{2k+1}\\}$ 各自是单调的，并且收敛到相同的极限 $x^\\star$。\n- 实现一个程序，对于提供的测试套件中的每个初始值 $x_0$，执行不动点迭代 $x_{k+1}=\\cos x_k$，直到相邻迭代值之差满足 $|x_{k+1}-x_k|10^{-12}$ 或达到最多1000次迭代。存储每个测试用例的完整迭代序列。角度单位必须是弧度。\n- 对每个测试用例，计算并报告：\n  1. 初始值 $x_0$。\n  2. 停止后不动点的最终近似值，记为 $x_{\\text{approx}}$。\n  3. 执行的迭代次数 $N$。\n  4. 一个布尔值，指示完整序列 $\\{x_k\\}_{k=0}^N$ 是否是单调的（非递减或非递增）。\n  5. 一个布尔值，指示偶数索引子序列 $\\{x_{2k}\\}$ 是否是单调的（非递减或非递增）。\n  6. 一个布尔值，指示奇数索引子序列 $\\{x_{2k+1}\\}$ 是否是单调的（非递减或非递增）。\n- 使用以下初始值测试套件（均为弧度）：$x_0\\in\\{0,\\,\\tfrac{1}{2},\\,1,\\,0.7390851332151607\\}$。最后一个值是唯一不动点 $x^\\star$ 的一个高精度近似值。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表。每个测试用例的结果本身必须是一个列表，其形式为 $[x_0,x_{\\text{approx}},N,\\text{is\\_monotone\\_full},\\text{is\\_monotone\\_even},\\text{is\\_monotone\\_odd}]$。例如，总输出将类似于 $[[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot,\\cdot,\\cdot,\\cdot]]$，其中四个内部列表对应四个测试用例。\n\n在您的程序中，所有上述数值必须作为标量处理。程序不得读取任何输入，并且必须打印所需的单行作为其唯一输出。", "solution": "我们首先回顾基本定义和事实。函数 $g$ 的不动点是一个满足 $x^\\star=g(x^\\star)$ 的值 $x^\\star$。数值不动点迭代通过 $x_{k+1}=g(x_k)$ 构造一个序列 $\\{x_k\\}$，并寻找一个极限 $x^\\star$，使得 $x_k\\to x^\\star$ 且 $x^\\star=g(x^\\star)$。压缩映射定理 (CMT) 指出，如果 $g$ 将一个完备度量空间映射到自身，并且对于定义域中的所有 $x,y$ 和某个常数 $L1$，满足 Lipschitz 界 $|g(x)-g(y)|\\le L|x-y|$，那么 $g$ 有一个唯一的不动点 $x^\\star$，并且对于定义域中的任何初始值 $x_0$，迭代 $x_{k+1}=g(x_k)$ 都收敛到 $x^\\star$。\n\n我们分析闭区间 $[0,1]$ 上的函数 $g(x)=\\cos x$。首先，我们证明 $g$ 将 $[0,1]$ 映射到自身。对于 $x\\in[0,1]$，我们有 $\\cos x\\in[\\cos 1,\\,\\cos 0]=[\\cos 1,\\,1]$。由于 $\\cos 10$，因此 $g([0,1])\\subset[0,1]$。接下来，我们计算导数 $g'(x)=-\\sin x$。在 $[0,1]$上，函数 $\\sin x$ 是非负的，并以 $\\sin 1$ 为上界，所以\n$$\n\\sup_{x\\in[0,1]}|g'(x)|=\\sup_{x\\in[0,1]}|\\sin x|=\\sin(1).\n$$\n因为 $\\sin(1)1$，我们可以使用中值定理 (MVT) 推导出一个 Lipschitz 界：对于任意 $x,y\\in[0,1]$，\n$$\n|g(x)-g(y)|=|\\cos x-\\cos y|=|g'(\\xi)|\\,|x-y|\\le \\sin(1)\\,|x-y|,\n$$\n对于某个介于 $x$ 和 $y$ 之间的 $\\xi$。因此，$g$ 是在 $[0,1]$ 上的一个压缩映射，其压缩常数为 $L=\\sin(1)1$。根据压缩映射定理，存在一个唯一的不动点 $x^\\star\\in[0,1]$，并且对于任何 $x_0\\in[0,1]$，由 $x_{k+1}=\\cos x_k$ 定义的序列收敛于 $x^\\star$。\n\n我们接下来分析单调行为。注意 $g$ 在 $[0,1]$ 上是严格递减的，因为 $g'(x)=-\\sin x\\le 0$ 并且对于 $x\\in(0,1]$ 我们有 $\\sin x0$。设 $x^\\star$ 是唯一不动点。考虑误差 $e_k=x_k-x^\\star$。使用中值定理，存在某个在 $x_k$ 和 $x^\\star$ 之间的 $\\xi_k$，使得\n$$\ne_{k+1}=x_{k+1}-x^\\star=g(x_k)-g(x^\\star)=g'(\\xi_k)\\,(x_k-x^\\star)=-\\sin(\\xi_k)\\,e_k.\n$$\n在 $[0,1]$ 上，$\\sin(\\xi_k)\\in[0,\\sin(1)]$，并且只要 $\\sin(\\xi_k)0$，$e_{k+1}$ 的符号就与 $e_k$ 的符号相反。因此，除非 $e_k=0$，否则误差的符号会交替变化，所以完整序列 $\\{x_k\\}$ 通常是振荡的而不是单调的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef fixed_point_cos(x0, tol=1e-12, max_iter=1000):\n    \"\"\"\n    Perform fixed-point iteration x_{k+1} = cos(x_k) starting from x0.\n    Angles are in radians.\n    Returns:\n        x_approx: final approximation\n        iterations: number of iterations performed\n        seq: list of iterates including the initial value\n    \"\"\"\n    seq = [float(x0)]\n    x_prev = float(x0)\n    iterations = 0\n    for k in range(max_iter):\n        x_next = float(np.cos(x_prev))\n        seq.append(x_next)\n        iterations += 1\n        if abs(x_next - x_prev)  tol:\n            break\n        x_prev = x_next\n    return seq[-1], iterations, seq\n\ndef is_monotone(sequence, tol=0.0):\n    \"\"\"\n    Check if a sequence is monotone nondecreasing or monotone nonincreasing.\n    Equality is allowed.\n    tol can be used to soften comparisons, but defaults to strict.\n    \"\"\"\n    if len(sequence) = 1:\n        return True\n    diffs = [sequence[i+1] - sequence[i] for i in range(len(sequence)-1)]\n    nondecreasing = all(d >= -tol for d in diffs)\n    nonincreasing = all(d = tol for d in diffs)\n    return nondecreasing or nonincreasing\n\ndef solve():\n    # Define the test cases from the problem statement (radians).\n    test_cases = [\n        0.0,\n        0.5,\n        1.0,\n        0.7390851332151607,  # high-precision approximation to the fixed point\n    ]\n\n    results = []\n    for x0 in test_cases:\n        x_approx, iters, seq = fixed_point_cos(x0, tol=1e-12, max_iter=1000)\n        # Full sequence monotonicity\n        mono_full = is_monotone(seq, tol=0.0)\n        # Even-indexed subsequence: indices 0,2,4,...\n        even_seq = seq[0::2]\n        mono_even = is_monotone(even_seq, tol=0.0)\n        # Odd-indexed subsequence: indices 1,3,5,...\n        odd_seq = seq[1::2]\n        mono_odd = is_monotone(odd_seq, tol=0.0)\n        # Assemble result for this test case\n        results.append([x0, x_approx, iters, mono_full, mono_even, mono_odd])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3231288"}, {"introduction": "理解了成功的案例后，我们来探讨一个警示性的例子，以加深对收敛条件的理解。即使是强大的牛顿法，其本质也是一种不动点迭代，同样受制于收敛定理。本练习将分析一个特殊函数，在该函数上牛顿法意外地失效了，其根本原因在于迭代函数在不动点处的导数绝对值恰好为 $1$，这揭示了收敛理论中的一个关键边界条件。[@problem_id:3231260]", "problem": "令 $f:\\mathbb{R}\\to\\mathbb{R}$ 定义为 $f(x)=\\operatorname{sign}(x)\\sqrt{|x|}$，其中当 $x0$ 时 $\\operatorname{sign}(x)=-1$，当 $x=0$ 时 $\\operatorname{sign}(0)=0$，当 $x0$ 时 $\\operatorname{sign}(x)=1$。考虑应用牛顿法来近似求解位于 $x=0$ 的根。请仅使用牛顿法作为不动点迭代的基本定义以及基于不动点处导数的不动点迭代的标准局部收敛准则。\n\n从牛顿法的定义出发，写出此函数 $f$ 在 $\\mathbb{R}\\setminus\\{0\\}$ 上的相关不动点迭代 $x_{k+1}=g(x_{k})$，并确定 $g$ 在 $x=0$ 处是否存在连续延拓。然后，利用 $g$ 在 $x=0$ 附近的导数以及不动点收敛定理（在其压缩形式下也称为 Banach 不动点定理 (BFPT)），从第一性原理出发，推断该迭代是否预期会局部收敛到 $x=0$，以及二次收敛是否可能成立。\n\n对于由牛顿法生成的序列 $\\{x_{k}\\}$，其中任意初始猜测值 $x_{0}\\neq 0$ 且充分接近 $0$，定义误差 $e_{k}=x_{k}-0=x_{k}$，并分析渐近比率 $\\lim_{k\\to\\infty}\\frac{|e_{k+1}|}{|e_{k}|}$，前提是该比率在轨道上是良定义的。你的最终答案必须是该极限的精确值，以单个实数表示。无需四舍五入。", "solution": "问题要求分析将牛顿法应用于函数 $f(x) = \\operatorname{sign}(x)\\sqrt{|x|}$ 以寻找位于 $x=0$ 的根。牛顿法通过递推关系 $x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}$ 生成序列 $\\{x_k\\}$。这是一个不动点迭代 $x_{k+1} = g(x_k)$，其迭代函数为 $g(x) = x - \\frac{f(x)}{f'(x)}$。\n\n首先，我们必须计算当 $x \\neq 0$ 时 $f(x)$ 的导数。该函数定义如下：\n$$\nf(x) =\n\\begin{cases}\n\\sqrt{x}  \\text{若 } x  0 \\\\\n0  \\text{若 } x = 0 \\\\\n-\\sqrt{-x}  \\text{若 } x  0\n\\end{cases}\n$$\n对于 $x0$，我们有 $f(x) = x^{1/2}$，因此导数为 $f'(x) = \\frac{1}{2}x^{-1/2} = \\frac{1}{2\\sqrt{x}}$。\n对于 $x0$，我们有 $f(x) = -(-x)^{1/2}$。使用链式法则，导数为 $f'(x) = -\\frac{1}{2}(-x)^{-1/2} \\cdot (-1) = \\frac{1}{2\\sqrt{-x}}$。\n在两种情况下，对于任何 $x \\in \\mathbb{R}\\setminus\\{0\\}$，导数可以紧凑地写作 $f'(x) = \\frac{1}{2\\sqrt{|x|}}$。\n注意 $f'(x)$ 在 $x=0$ 处未定义，因为 $\\lim_{x\\to 0} f'(x) = +\\infty$。\n\n现在，我们为 $x \\neq 0$ 构建不动点迭代函数 $g(x)$：\n$$g(x) = x - \\frac{f(x)}{f'(x)} = x - \\frac{\\operatorname{sign}(x)\\sqrt{|x|}}{\\frac{1}{2\\sqrt{|x|}}}$$\n化简该表达式，我们得到：\n$$g(x) = x - 2\\operatorname{sign}(x)(\\sqrt{|x|})^2 = x - 2\\operatorname{sign}(x)|x|$$\n对于所有 $x \\in \\mathbb{R}$，项 $\\operatorname{sign}(x)|x|$ 恒等于 $x$。因此，对于所有 $x \\neq 0$，迭代函数为：\n$$g(x) = x - 2x = -x$$\n\n问题询问 $g$ 在 $x=0$ 处是否存在连续延拓。函数 $g(x)=-x$ 对于所有 $x \\in \\mathbb{R}$ 都是有定义且连续的。当 $x$ 趋近于 $0$ 时的极限是 $\\lim_{x\\to 0} g(x) = \\lim_{x\\to 0} (-x) = 0$。因此，可以通过定义 $g(0)=0$ 将 $g(x)$ 连续延拓到 $x=0$。延拓后的函数就是对于所有 $x \\in \\mathbb{R}$ 的 $g(x)=-x$。\n\n接下来，我们分析不动点迭代 $x_{k+1} = g(x_k) = -x_k$ 到不动点 $x^*=0$ 的局部收敛性。不动点收敛定理指出，如果 $g$ 在不动点 $x^*$ 的邻域内连续可微，并且 $|g'(x^*)|  1$，则迭代是局部收敛的。如果 $|g'(x^*)|  1$，则它是局部发散的。如果 $|g'(x^*)|=1$，则该定理无法得出结论。\n\n我们的迭代函数 $g(x)=-x$ 的导数是 $g'(x)=-1$，对于所有 $x \\in \\mathbb{R}$ 均成立。在不动点 $x^*=0$ 处，我们有：\n$$|g'(0)| = |-1| = 1$$\n由于在不动点处的导数的绝对值恰好为 $1$，标准的收敛准则无法得出结论。我们必须从第一性原理直接分析序列的行为。\n\n设初始猜测值为 $x_0 \\neq 0$。由迭代 $x_{k+1} = -x_k$ 生成的序列是：\n$x_1 = -x_0$\n$x_2 = -x_1 = -(-x_0) = x_0$\n$x_3 = -x_2 = -x_0$\n依此类推。该序列为 $\\{x_0, -x_0, x_0, -x_0, \\dots\\}$。这个序列在两个值之间振荡，对于任何 $x_0 \\neq 0$ 的选择，它都不会收敛到 $0$。因此，对于此函数，牛顿法未能收敛到位于 $x=0$ 的根。\n\n问题还询问二次收敛是否可能成立。对于一个不动点迭代 $x_{k+1}=g(x_k)$ 要二次收敛到不动点 $x^*$，一个必要条件是 $g'(x^*)=0$。在我们的例子中，$g'(0)=-1 \\neq 0$。因此，该迭代不可能是二次收敛的。事实上，如上所示，它根本不收敛。\n\n最后，我们被要求分析渐近比率 $\\lim_{k\\to\\infty}\\frac{|e_{k+1}|}{|e_{k}|}$，其中误差定义为 $e_k = x_k - 0 = x_k$。该比率为：\n$$\\frac{|e_{k+1}|}{|e_k|} = \\frac{|x_{k+1}|}{|x_k|}$$\n代入迭代规则 $x_{k+1}=-x_k$，我们得到：\n$$\\frac{|x_{k+1}|}{|x_k|} = \\frac{|-x_k|}{|x_k|} = \\frac{|x_k|}{|x_k|}$$\n对于任何初始猜测值 $x_0 \\neq 0$，序列 $\\{x_k\\}$ 永远不会达到 $0$。因此，对于所有 $k \\geq 0$，都有 $x_k \\neq 0$，并且该比率是良定义的，且对于所有 $k$ 都等于 $1$。\n$$\\frac{|e_{k+1}|}{|e_k|} = 1 \\quad \\text{对于所有 } k \\in \\{0, 1, 2, \\dots\\}$$\n这个常数序列的极限是：\n$$\\lim_{k\\to\\infty}\\frac{|e_{k+1}|}{|e_{k}|} = \\lim_{k\\to\\infty} 1 = 1$$\n这个结果，即极限误差比为 $1$，与误差不减小且方法不收敛的观察结果是一致的。", "answer": "$$\\boxed{1}$$", "id": "3231260"}, {"introduction": "当迭代序列收敛但速度缓慢时，我们能否主动进行干预，使其“跑得更快”？艾特肯 $\\Delta^2$ 方法为线性收敛序列提供了一个强有力的加速方案。这个练习将引导你从第一性原理出发，推导并实现这一著名算法，你将直观地感受到它如何用极少的计算成本换来收敛效率的巨大提升。[@problem_id:3231237]", "problem": "给定由映射 $g(x) = \\dfrac{x + 2}{2}$ 和迭代规则 $x_{k+1} = g(x_k)$ 定义的不动点迭代。考虑满足 $x^\\star = g(x^\\star)$ 的唯一不动点 $x^\\star$。您将从基本原理分析收敛性，并实现一个使用Aitken's delta-squared方法的算法来加速收敛。\n\n任务 A (理论基础):\n1. 从不动点的定义和压缩映射原理出发，证明方程 $x = g(x)$ 有唯一解，并且不动点迭代 $x_{k+1} = g(x_k)$ 局部收敛于该解。使用 $g$ 的可微性以及条件 $\\lvert g'(x^\\star) \\rvert  1$ 作为局部线性收敛的核心判据。\n2. 通过解代数方程 $x = g(x)$ 来确定精确的不动点 $x^\\star$。\n3. 使用线性收敛的定义，分析误差序列 $e_k = x_k - x^\\star$，并确定未加速的不动点迭代的渐进速率（线性收敛因子）。\n\n任务 B (加速的算法设计):\n1. 从线性收敛序列的一般模型出发，用序列 $\\{x_k\\}$ 的前向差分来推导Aitken's delta-squared加速法。您的推导必须仅依赖于误差渐进行为类似于几何级数的假设以及前向差分的基本定义。不要假设或引用任何预先推导出的闭式加速公式；相反，应从第一性原理出发构建它。\n2. 设计一个鲁棒的算法，该算法给定一个初始值 $x_0$ 和一个容差 $\\text{tol} > 0$，使用基础迭代中的连续三元组 $(x_k, x_{k+1}, x_{k+2})$ 来生成一个Aitken加速估计值。您的算法必须：\n   - 当当前近似值满足 $\\lvert x - x^\\star \\rvert \\le \\text{tol}$ 时，将计算视为成功。\n   - 将计算成本计为 $g$ 的求值次数。\n   - 当二阶前向差分为零或在数值上与零无法区分时，通过检测此条件来处理退化情况，并将其视为迭代已达到不动点或无法从该三元组可靠地形成Aitken更新的标志。在这种情况下，算法应要么终止（如果已在容差范围内），要么安全地继续进行额外的基础迭代以形成新的三元组。\n\n任务 C (编程与评估):\n1. 实现两个过程：\n   - 一个基础不动点迭代器，它返回从 $x_0$ 开始满足 $\\lvert x - x^\\star \\rvert \\le \\text{tol}$ 所需的 $g$ 的最小求值次数。\n   - 一个Aitken加速过程，它从基础迭代的连续三元组中重复形成Aitken更新，并返回加速序列中首次达到 $\\lvert x - x^\\star \\rvert \\le \\text{tol}$ 所需的 $g$ 的最小求值次数（计算用于生成所需迭代的每一次 $g$ 的求值）。\n2. 使用 $10^6$ 次 $g$ 求值的最大上限，以保证在病态场景下能够终止。\n3. 测试套件。对以下四个测试用例运行这两个过程，其中每个测试用例是一对 $(x_0, \\text{tol})$：\n   - $(0.0, 10^{-8})$\n   - $(-100.0, 10^{-12})$\n   - $(2.0, 10^{-14})$\n   - $(10.0, 10^{-10})$\n4. 对于每个测试用例，计算并返回一个由以下部分组成的三元组：\n   - 基础不动点迭代满足容差所需的 $g$ 的求值整数次数。\n   - Aitken加速过程首次满足容差所需的 $g$ 的求值整数次数。\n   - 一个布尔值，指示Aitken加速过程使用的 $g$ 求值次数是否严格少于基础过程。\n5. 最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，列表中的每个元素是按上述顺序排列的测试用例三元组。例如，一个有效的输出格式如下：\n   - $[[n_{b,1},n_{a,1},\\text{flag}_1],[n_{b,2},n_{a,2},\\text{flag}_2],[n_{b,3},n_{a,3},\\text{flag}_3],[n_{b,4},n_{a,4},\\text{flag}_4]]$\n此处 $n_{b,i}$ 和 $n_{a,i}$ 是整数，而 $\\text{flag}_i$ 是一个布尔值。此任务不涉及任何物理单位。角度不适用。不使用百分比。", "solution": "问题陈述已经过分析，被认为是有效的。这是一个在数值分析领域中提得很好的问题，它有科学依据、内容自洽且客观。\n\n### 任务A（理论基础）：唯一不动点与线性收敛\n\n1.  **存在性、唯一性与收敛性：**\n    不动点迭代由函数 $g(x) = \\dfrac{x + 2}{2}$ 定义。不动点 $x^\\star$ 满足方程 $x^\\star = g(x^\\star)$。\n    为了分析收敛性，我们应用压缩映射定理。该定理指出，如果函数 $g$ 将一个完备度量空间映射到其自身并且是一个压缩映射，那么它拥有一个唯一的不动点，并且对于任何起始点 $x_0$，迭代 $x_{k+1} = g(x_k)$ 都收敛到这个不动点。\n    函数 $g(x)$ 定义在 $\\mathbb{R}$上，这是一个完备度量空间。为了检查 $g$ 是否为压缩映射，我们考察其导数：\n    $$\n    g'(x) = \\frac{d}{dx}\\left(\\frac{x}{2} + 1\\right) = \\frac{1}{2}\n    $$\n    $g(x)$ 的Lipschitz常数 $L$ 由 $L = \\sup_{x \\in \\mathbb{R}} |g'(x)|$ 给出。在这种情况下，$L = |\\frac{1}{2}| = \\frac{1}{2}$。\n    由于 $L = \\frac{1}{2}  1$，函数 $g(x)$ 在整个 $\\mathbb{R}$ 上是一个压缩映射。因此，根据压缩映射定理，存在一个唯一的不动点 $x^\\star \\in \\mathbb{R}$，并且对于任何初始值 $x_0 \\in \\mathbb{R}$，迭代 $x_{k+1} = g(x_k)$ 都收敛到 $x^\\star$。\n    如果 $|g'(x^\\star)|  1$，则在不动点 $x^\\star$ 附近的局部收敛性得到保证。正如我们所发现的，对于所有的 $x$ (包括 $x^\\star$)，都有 $|g'(x)| = \\frac{1}{2}$。因此，$|g'(x^\\star)| = \\frac{1}{2}  1$，这证明了迭代是局部线性收敛的。\n\n2.  **不动点的确定：**\n    不动点 $x^\\star$ 通过解代数方程 $x = g(x)$ 求得：\n    $$\n    x = \\frac{x + 2}{2}\n    $$\n    $$\n    2x = x + 2\n    $$\n    $$\n    x = 2\n    $$\n    唯一的不动点是 $x^\\star = 2$。\n\n3.  **误差分析与收敛速率：**\n    第 $k$ 次迭代的误差定义为 $e_k = x_k - x^\\star$。下一步的误差是 $e_{k+1} = x_{k+1} - x^\\star$。代入迭代规则和不动点定义：\n    $$\n    e_{k+1} = g(x_k) - x^\\star = g(x_k) - g(x^\\star)\n    $$\n    根据中值定理，在 $x_k$ 和 $x^\\star$ 之间存在一个值 $\\xi_k$，使得 $g(x_k) - g(x^\\star) = g'(\\xi_k)(x_k - x^\\star)$。这导出了误差关系 $e_{k+1} = g'(\\xi_k)e_k$。\n    当 $k \\to \\infty$ 时，我们有 $x_k \\to x^\\star$，因此 $\\xi_k \\to x^\\star$。渐进误差关系为：\n    $$\n    \\lim_{k \\to \\infty} \\frac{|e_{k+1}|}{|e_k|} = |g'(x^\\star)|\n    $$\n    这证明了线性收敛。常数 $\\lambda = |g'(x^\\star)|$ 是渐进收敛速率。\n    对于给定的函数 $g(x)$，其导数 $g'(x) = \\frac{1}{2}$ 是一个常数。因此，该关系对所有 $k$ 都精确成立：\n    $$\n    e_{k+1} = g(x_k) - g(x^\\star) = \\left(\\frac{x_k+2}{2}\\right) - \\left(\\frac{x^\\star+2}{2}\\right) = \\frac{1}{2}(x_k - x^\\star) = \\frac{1}{2}e_k\n    $$\n    收敛速率是常数 $\\lambda = \\frac{1}{2}$，而不仅仅是渐进的。\n\n### 任务B（加速的算法设计）：Aitken's Delta-Squared方法\n\n1.  **从第一性原理推导：**\n    Aitken方法加速已知线性收敛的序列 $\\{x_k\\}$ 的收敛。其基本假设是，对于较大的 $k$，误差 $e_k = x_k - x^\\star$ 的行为类似于几何级数。这意味着连续误差的比率近似为常数：\n    $$\n    \\frac{e_{k+1}}{e_k} \\approx \\lambda \\quad \\implies \\quad x_{k+1} - x^\\star \\approx \\lambda(x_k - x^\\star)\n    $$\n    为了构建一个加速估计值，我们使用序列的三个连续项 $(x_k, x_{k+1}, x_{k+2})$。我们假设下一对项也保持相同的比率：\n    $$\n    x_{k+1} - x^\\star \\approx \\lambda(x_k - x^\\star) \\quad (1)\n    $$\n    $$\n    x_{k+2} - x^\\star \\approx \\lambda(x_{k+1} - x^\\star) \\quad (2)\n    $$\n    我们可以通过消去 $\\lambda$ 来求解未知极限 $x^\\star$。由 (1) 和 (2)可得：\n    $$\n    \\frac{x_{k+1} - x^\\star}{x_k - x^\\star} \\approx \\lambda \\approx \\frac{x_{k+2} - x^\\star}{x_{k+1} - x^\\star}\n    $$\n    交叉相乘得到：\n    $$\n    (x_{k+1} - x^\\star)^2 \\approx (x_k - x^\\star)(x_{k+2} - x^\\star)\n    $$\n    展开各项：\n    $$\n    x_{k+1}^2 - 2x_{k+1}x^\\star + (x^\\star)^2 \\approx x_k x_{k+2} - x_k x^\\star - x_{k+2} x^\\star + (x^\\star)^2\n    $$\n    整理以求解 $x^\\star$：\n    $$\n    x_{k+1}^2 - x_k x_{k+2} \\approx (2x_{k+1} - x_k - x_{k+2})x^\\star\n    $$\n    $$\n    x^\\star \\approx \\frac{x_k x_{k+2} - x_{k+1}^2}{x_{k+2} - 2x_{k+1} + x_k}\n    $$\n    这个公式给出了不动点的一个改进估计值。为了用前向差分表示它，我们定义 $\\Delta x_k = x_{k+1} - x_k$ 和二阶前向差分 $\\Delta^2 x_k = \\Delta(\\Delta x_k) = (x_{k+2} - x_{k+1}) - (x_{k+1} - x_k) = x_{k+2} - 2x_{k+1} + x_k$。\n    Aitken加速估计值（记为 $\\hat{x}_k$）可以写成：\n    $$\n    \\hat{x}_k = x_k - \\frac{(\\Delta x_k)^2}{\\Delta^2 x_k} = x_k - \\frac{(x_{k+1} - x_k)^2}{x_{k+2} - 2x_{k+1} + x_k}\n    $$\n    这是标准的Aitken's delta-squared公式。对于本问题中的特定线性函数 $g(x)$，该比率是精确的而非近似的，这意味着该公式将从任何非平凡的迭代三元组中得到精确的不动点 $x^\\star$。\n\n2.  **算法设计：**\n    设计一个算法来计算Aitken加速估计值序列。\n    -   **初始化**：给定 $x_0$ 和 `tol`，精确的不动点是 $x^\\star = 2.0$。$g$ 的求值次数是成本度量。\n    -   **迭代**：算法顺序地生成基础迭代项 $x_{k+1} = g(x_k)$。在至少两次 $g$ 求值后，我们得到一个可用的三元组 $(x_k, x_{k+1}, x_{k+2})$ 来形成Aitken估计值。\n    -   **Aitken更新**：对于每个生成的新基础迭代项 $x_{k+2}$，都会形成一个新的三元组，并计算公式 $\\hat{x}_k = x_k - (\\Delta x_k)^2 / (\\Delta^2 x_k)$。\n    -   **收敛检查**：每次Aitken更新后，检查条件 $|\\hat{x}_k - x^\\star| \\le \\text{tol}$。如果满足条件，过程终止，并返回用于生成所需基础迭代项的 $g$ 的总求值次数。\n    -   **退化处理**：$\\hat{x}_k$ 的公式涉及除以二阶差分 $\\Delta^2 x_k$。如果此分母为零或在数值上非常接近于零，则无法可靠地计算更新。这通常发生在序列已经收敛时（即 $x_k = x_{k+1} = x_{k+2}$）。算法必须检测此情况。如果 $\\Delta^2 x_k \\approx 0$，它会检查最后一个基础迭代项是否在容差范围内。如果不在，它会放弃对该三元组的Aitken更新，并继续生成更多的基础迭代项，直到 $\\Delta^2 x_k$ 再次变得不可忽略。\n\n### 任务 C (编程与评估): 实现与结果\n\n实现了两个过程：一个用于基础不动点迭代，另一个用于Aitken加速迭代。两个函数都计算获得一个估计值 $x$ 使得 $|x - x^\\star| \\le \\text{tol}$ 所需的 $g(x)$ 的求值次数。\n\n-   **基础迭代器**：这是一个直接的循环。从 $x_0$ 开始，它重复应用 $x_{k+1} = g(x_k)$，并增加一个求值计数器，直到满足误差容差为止。\n-   **Aitken迭代器**：此过程生成基础迭代项 $x_0, x_1, x_2, \\dots$。从第一个可用的三元组 $(x_0, x_1, x_2)$（需要2次 $g$ 的求值）开始，它计算一个Aitken估计值 $\\hat{x}_0$。如果 $\\hat{x}_0$ 未收敛，它会生成 $x_3$（总共3次求值），从 $(x_1, x_2, x_3)$ 形成一个新的Aitken估计值 $\\hat{x}_1$，依此类推，直到一个加速估计值满足容差为止。\n\n任务B中的分析预测，对于给定的线性函数 $g(x)$，从任何非平凡的起始点出发，第一个Aitken估计值都将是精确的。这意味着只要 $x_0 \\neq x^\\star$，加速过程应总是在2次 $g$ 求值后终止。基础迭代的性能取决于初始误差和容差。\n\n测试套件的数值结果如下：\n1.  **$(x_0, \\text{tol}) = (0.0, 10^{-8})$**：基础迭代器需要 $28$ 次求值。Aitken迭代器需要 $2$ 次。\n2.  **$(x_0, \\text{tol}) = (-100.0, 10^{-12})$**：基础迭代器需要 $47$ 次求值。Aitken迭代器需要 $2$ 次。\n3.  **$(x_0, \\text{tol}) = (2.0, 10^{-14})$**：两个迭代器都从不动点开始，因此需要 $0$ 次求值。\n4.  **$(x_0, \\text{tol}) = (10.0, 10^{-10})$**：基础迭代器需要 $37$ 次求值。Aitken迭代器需要 $2$ 次。\n\n在所有非平凡的情况下，Aitken加速过程都严格更快，这证实了它对于线性收敛序列的有效性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the fixed-point iteration problem with base and Aitken-accelerated methods.\n    \"\"\"\n    \n    # The mapping function for the fixed-point iteration.\n    g = lambda x: (x + 2.0) / 2.0\n    \n    # The exact fixed point.\n    x_star = 2.0\n    \n    # Maximum number of evaluations to prevent infinite loops.\n    max_evals = 1000000\n    \n    # Epsilon for degeneracy check in Aitken's method.\n    degeneracy_eps = 1e-15\n\n    def base_iterator(x0, tol):\n        \"\"\"\n        Calculates the number of g evaluations for the base fixed-point method.\n        \"\"\"\n        x_k = float(x0)\n        \n        # Check if already converged at x0.\n        if abs(x_k - x_star) = tol:\n            return 0\n        \n        for num_evals in range(1, max_evals + 1):\n            x_k = g(x_k)\n            if abs(x_k - x_star) = tol:\n                return num_evals\n        \n        return max_evals\n\n    def aitken_iterator(x0, tol):\n        \"\"\"\n        Calculates the number of g evaluations for the Aitken-accelerated method.\n        \"\"\"\n        x_k = float(x0)\n\n        # Check if already converged at x0.\n        if abs(x_k - x_star) = tol:\n            return 0\n\n        x_seq = [x_k]\n\n        # Generate the first two points to form the first triplet.\n        # Eval 1:\n        x_k_plus_1 = g(x_seq[-1])\n        x_seq.append(x_k_plus_1)\n        num_evals = 1\n        # Aitken cannot be applied yet.\n\n        # Eval 2 and subsequent:\n        for num_evals in range(2, max_evals + 1):\n            x_k_plus_2 = g(x_seq[-1])\n            x_seq.append(x_k_plus_2)\n\n            # We have a triplet (x_k, x_{k+1}, x_{k+2})\n            # which are x_seq[-3], x_seq[-2], x_seq[-1]\n            xk, xk1, xk2 = x_seq[-3], x_seq[-2], x_seq[-1]\n            \n            delta_sq_x = xk2 - 2 * xk1 + xk\n\n            # Degeneracy check\n            if abs(delta_sq_x)  degeneracy_eps:\n                # This indicates convergence or numerical instability.\n                # Check if the last base iterate is converged.\n                if abs(xk2 - x_star) = tol:\n                    return num_evals\n                # Otherwise, continue generating base iterates as Aitken update is not reliable.\n                continue\n\n            delta_x = xk1 - xk\n            x_aitken = xk - (delta_x**2) / delta_sq_x\n            \n            if abs(x_aitken - x_star) = tol:\n                return num_evals\n        \n        return max_evals\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 1e-8),\n        (-100.0, 1e-12),\n        (2.0, 1e-14),\n        (10.0, 1e-10)\n    ]\n\n    results = []\n    for case in test_cases:\n        x0, tol = case\n        \n        base_evals = base_iterator(x0, tol)\n        aitken_evals = aitken_iterator(x0, tol)\n        \n        aitken_is_faster = aitken_evals  base_evals\n        \n        results.append([base_evals, aitken_evals, aitken_is_faster])\n\n    # Final print statement in the exact required format.\n    # The default string representation of a list in Python is used, as per the template.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3231237"}]}