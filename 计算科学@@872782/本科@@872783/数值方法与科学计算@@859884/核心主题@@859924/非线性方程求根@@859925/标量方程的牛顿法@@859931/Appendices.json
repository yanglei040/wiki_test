{"hands_on_practices": [{"introduction": "牛顿法虽然在根附近收敛速度很快，但其收敛性并非总是全局保证的。对于某些函数，例如 $f(x)=\\arctan(x)$，如果初始猜测值距离根太远，朴素的牛顿迭代步长会“过冲”，导致迭代发散。本练习 [@problem_id:3255187] 将通过一个经典的“过冲”案例，引导你分析并实现一种带回溯线搜索的阻尼牛顿法，这是确保算法全局收敛性的关键技术。", "problem": "考虑由函数 $f(x)=\\arctan(x)$ 定义的标量非线性方程，其中 $\\arctan(\\cdot)$ 返回以弧度为单位的角度。您的任务是分析为什么经典牛顿迭代法的直接应用在 $|x|$ 较大时会表现出“过冲”行为，并实现一个能够避免此问题的全局收敛的阻尼牛顿算法。\n\n从以下基本点出发：可微函数 $f(x)$ 在点 $x$ 附近的一阶泰勒展开式，即 $f(x+s)\\approx f(x)+f^{\\prime}(x)\\,s$，以及求根迭代试图通过求解局部线性模型来选择一个增量 $s$ 以逼近 $f(x+s)=0$ 的原理。利用这个基础，推导出无阻尼牛顿法的搜索方向，过程中不依赖任何预先引用的快捷公式。然后，对于 $f(x)=\\arctan(x)$，分析当 $|x|$ 很大时该方向的渐近行为，并解释为什么会发生“过冲”（即步长非常大，导致迭代点远远越过根）。\n\n为求解 $f(x)=\\arctan(x)$ 设计并实现两个迭代求解器：\n\n- 一个无阻尼牛顿法，该方法以完整步长应用推导出的搜索方向，残差 $|f(x)| \\le \\varepsilon$ 的停止容差为 $\\varepsilon=10^{-12}$，最大迭代次数为 $50$ 次。如果在任何时候，任何迭代值变为非有限数或 $|x|$ 超过 $10^{16}$，则视为迭代失败。\n\n- 一个阻尼牛顿法，该方法使用相同的搜索方向，但通过回溯线搜索（Backtracking Line Search, BLS）选择一个步长 $\\lambda\\in(0,1]$，以确保价值函数 $\\phi(x)=\\tfrac{1}{2}f(x)^{2}$ 得到充分下降。使用充分下降（Armijo）条件\n$$\n\\phi(x+\\lambda p)\\le \\phi(x)-2c\\,\\lambda\\,\\phi(x),\n$$\n其中 $c=10^{-4}$，几何回溯因子 $\\beta=\\tfrac{1}{2}$，初始试探步长 $\\lambda=1$。如果线搜索在 $100$ 次回溯缩减内未能找到合适的步长，或者任何候选迭代值变为非有限数或满足 $|x|10^{16}$，则宣告失败。使用与无阻尼方法相同的残差容差 $\\varepsilon=10^{-12}$ 和最大外层迭代次数 $50$。\n\n测试套件和输出规范：\n\n- 使用起始值 $x_{0}\\in\\{0,1,10,10^{3},-10^{3}\\}$。\n\n- 对每个起始值，运行无阻尼和阻尼求解器。报告每个求解器达到 $|f(x)|\\le \\varepsilon$ 所需的整数迭代次数。如果某个求解器在上述标准下失败，则对该起始值的该求解器报告 $-1$。\n\n- 最终的程序输出必须是单行，包含一个用方括号括起来的逗号分隔列表，按以下顺序汇总结果：\n$[k_{\\text{undamped}}(0),k_{\\text{damped}}(0),k_{\\text{undamped}}(1),k_{\\text{damped}}(1),k_{\\text{undamped}}(10),k_{\\text{damped}}(10),k_{\\text{undamped}}(10^{3}),k_{\\text{damped}}(10^{3}),k_{\\text{undamped}}(-10^{3}),k_{\\text{damped}}(-10^{3})]$,\n其中 $k_{\\text{undamped}}(x_{0})$ 和 $k_{\\text{damped}}(x_{0})$ 表示对应起始值 $x_{0}$ 的如上定义的迭代次数。每个条目必须是一个整数。\n\n您的实现必须是完全自包含的。不允许用户输入。您的程序打印的最后一行必须严格符合指定的列表格式。", "solution": "我们从一阶泰勒模型开始。对于一个可微的标量函数 $f(x)$ 和当前迭代点 $x$，一个小的增量 $s$ 满足\n$$\nf(x+s)\\approx f(x)+f^{\\prime}(x)\\,s.\n$$\n为了寻找根，我们设定模型方程 $f(x)+f^{\\prime}(x)\\,s=0$ 并求解 $s$，这得到了无阻尼牛顿法的搜索方向\n$$\np=-\\frac{f(x)}{f^{\\prime}(x)}.\n$$\n相应的全步长无阻尼迭代是 $x_{+}=x+p$。\n\n对于特定函数 $f(x)=\\arctan(x)$，我们有 $f^{\\prime}(x)=\\dfrac{1}{1+x^{2}}$。因此，无阻尼牛顿方向的形式为\n$$\np=-\\frac{\\arctan(x)}{\\tfrac{1}{1+x^{2}}}=-(1+x^{2})\\,\\arctan(x).\n$$\n为了理解过冲现象，考虑当 $|x|$ 很大时 $\\arctan(x)$ 的渐近行为。当 $x\\to+\\infty$ 时，$\\arctan(x)\\to \\frac{\\pi}{2}$；当 $x\\to-\\infty$ 时，$\\arctan(x)\\to -\\frac{\\pi}{2}$。更精确地，当 $|x|\\to\\infty$ 时，可以使用展开式 $\\arctan(x)=\\operatorname{sgn}(x)\\,\\frac{\\pi}{2}-\\frac{1}{x}+O(x^{-3})$。将其与 $f^{\\prime}(x)=\\dfrac{1}{1+x^{2}}$ 结合，对于大的 $|x|$，可得\n$$\np\\approx -\\left(1+x^{2}\\right)\\left(\\operatorname{sgn}(x)\\,\\frac{\\pi}{2}\\right)\\sim -\\operatorname{sgn}(x)\\,\\frac{\\pi}{2}\\,x^{2}.\n$$\n因此，全步长更新 $x_{+}=x+p$ 的行为类似于\n$$\nx_{+}\\sim x-\\operatorname{sgn}(x)\\,\\frac{\\pi}{2}\\,x^{2},\n$$\n其量值随 $|x|$呈二次方增长。这会在根 $x=0$ 附近产生非常大的跳跃，并通常导致迭代值在符号交替的同时量值不断增长，这是无阻尼方法从远离根的位置开始时出现“过冲”和发散的典型特征。\n\n为了获得一个全局收敛的方法，我们保留牛顿方向 $p$，但使用基于某个价值函数的线搜索来对步长进行阻尼。一个标准的选择是残差平方的价值函数\n$$\n\\phi(x)=\\frac{1}{2}\\,f(x)^{2}.\n$$\n它的导数是 $\\phi^{\\prime}(x)=f(x)\\,f^{\\prime}(x)$。沿牛顿方向 $p$ 的方向导数是\n$$\n\\phi^{\\prime}(x)\\,p=f(x)\\,f^{\\prime}(x)\\,\\left(-\\frac{f(x)}{f^{\\prime}(x)}\\right)=-f(x)^{2}=-2\\,\\phi(x)  0\n$$\n只要 $f(x)\\neq 0$，因此 $p$ 是 $\\phi$ 的一个严格下降方向。回溯线搜索（Backtracking Line Search, BLS）通过选择一个步长 $\\lambda\\in(0,1]$ 来确保充分下降，使得 Armijo 条件成立：\n$$\n\\phi(x+\\lambda p)\\le \\phi(x)+c\\,\\lambda\\,\\phi^{\\prime}(x)\\,p=\\phi(x)-c\\,\\lambda\\,f(x)^{2}=\\phi(x)-2c\\,\\lambda\\,\\phi(x),\n$$\n其中 $c\\in(0,1/2)$。从 $\\lambda=1$ 开始，并以 $\\beta\\in(0,1)$ 的比例缩小 $\\lambda\\leftarrow\\beta\\,\\lambda$，直到不等式满足为止，这将产生一个单调递减且下界为 $0$ 的序列 $\\{\\phi(x_{k})\\}$，从而保证了价值函数的收敛性，并为牛顿法提供了一个鲁棒的全局化策略。对于 $f(x)=\\arctan(x)$，这种阻尼方法通过在 $|x|$ 很大时大幅减小 $\\lambda$，避免了二次方量级的大步长，从而将迭代值推向根。\n\n算法设计：\n\n- 无阻尼方法：用 $x_{0}$ 初始化，并迭代 $x_{k+1}=x_{k}+p_{k}$，其中 $p_{k}=-\\dfrac{f(x_{k})}{f^{\\prime}(x_{k})}$，直到 $|f(x_{k})|\\le \\varepsilon$ 或 $k$ 达到最大值。如果任何 $x_{k}$ 变为非有限数或 $|x_{k}|10^{16}$，则宣告失败。\n\n- 阻尼方法：在每次迭代中，计算相同的 $p_{k}$，并从 $\\lambda=1$ 开始，使用 $\\beta=\\tfrac{1}{2}$ 和 $c=10^{-4}$ 进行回溯搜索，接受第一个满足以下条件的 $\\lambda$：\n$$\n\\phi(x_{k}+\\lambda p_{k})\\le \\phi(x_{k})-2c\\,\\lambda\\,\\phi(x_{k}).\n$$\n更新 $x_{k+1}=x_{k}+\\lambda p_{k}$。使用相同的停止和失败条件，并将回溯次数限制为 $100$ 次缩减。\n\n测试套件：\n\n- 起始点 $x_{0}\\in\\{0,1,10,10^{3},-10^{3}\\}$ 用于探测一个平凡的精确根、一个中等距离的情况，以及无阻尼牛顿法会发生过冲的严重大数值情况。\n\n预期的定性结果：\n\n- 对于 $x_{0}=0$，由于 $f(0)=0$，两种方法都会立即以 $0$ 次迭代终止。\n\n- 对于 $x_{0}=1$，无阻尼方法在几次迭代内快速收敛；阻尼方法在接近解时通常会接受完整步长，其迭代次数与无阻尼方法相匹配或相近。\n\n- 对于 $x_{0}=10$、$x_{0}=10^{3}$ 和 $x_{0}=-10^{3}$，无阻尼方法会表现出过冲并在给定的安全措施下失败，而阻尼方法则通过回溯来控制步长，并在允许的迭代次数内收敛。\n\n程序必须打印单行列表\n$[k_{\\text{undamped}}(0),k_{\\text{damped}}(0),k_{\\text{undamped}}(1),k_{\\text{damped}}(1),k_{\\text{undamped}}(10),k_{\\text{damped}}(10),k_{\\text{undamped}}(10^{3}),k_{\\text{damped}}(10^{3}),k_{\\text{undamped}}(-10^{3}),k_{\\text{damped}}(-10^{3})]$,\n其中每个 $k$ 是一个整数，表示收敛时的迭代次数，或者在失败时为 $-1$（如定义）。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef f(x: float) -> float:\n    # f(x) = arctan(x)\n    return float(np.arctan(x))\n\ndef fprime(x: float) -> float:\n    # f'(x) = 1 / (1 + x^2)\n    return 1.0 / (1.0 + x * x)\n\ndef phi(x: float) -> float:\n    # phi(x) = 0.5 * f(x)^2\n    fx = f(x)\n    return 0.5 * fx * fx\n\ndef is_finite_scalar(x: float) -> bool:\n    return np.isfinite(x)\n\ndef newton_undamped(x0: float, tol: float = 1e-12, max_iter: int = 50,\n                    blowup: float = 1e16) -> int:\n    # Return iteration count to reach |f(x)| = tol, else -1 on failure\n    x = float(x0)\n    fx = f(x)\n    if not is_finite_scalar(x) or not is_finite_scalar(fx):\n        return -1\n    if abs(fx) = tol:\n        return 0\n    for k in range(1, max_iter + 1):\n        fpx = fprime(x)\n        # For arctan, f'(x) > 0 always; check safety anyway.\n        if not is_finite_scalar(fpx) or fpx == 0.0:\n            return -1\n        step = -fx / fpx\n        x_new = x + step\n        if not is_finite_scalar(x_new) or abs(x_new) > blowup:\n            return -1\n        x = x_new\n        fx = f(x)\n        if not is_finite_scalar(fx):\n            return -1\n        if abs(fx) = tol:\n            return k\n    return -1\n\ndef newton_damped(x0: float, tol: float = 1e-12, max_iter: int = 50,\n                  c: float = 1e-4, beta: float = 0.5, max_backtrack: int = 100,\n                  blowup: float = 1e16) -> int:\n    # Return iteration count to reach |f(x)| = tol, else -1 on failure\n    x = float(x0)\n    fx = f(x)\n    if not is_finite_scalar(x) or not is_finite_scalar(fx):\n        return -1\n    if abs(fx) = tol:\n        return 0\n    for k in range(1, max_iter + 1):\n        fpx = fprime(x)\n        if not is_finite_scalar(fpx) or fpx == 0.0:\n            return -1\n        p = -fx / fpx\n        phi_x = 0.5 * fx * fx\n        lam = 1.0\n        accepted = False\n        for _ in range(max_backtrack):\n            x_trial = x + lam * p\n            if not is_finite_scalar(x_trial) or abs(x_trial) > blowup:\n                lam *= beta\n                continue\n            phi_trial = phi(x_trial)\n            # Armijo: phi(x + lam p) = phi(x) - 2 c lam phi(x)\n            if phi_trial = phi_x - 2.0 * c * lam * phi_x:\n                x = x_trial\n                fx = f(x)\n                accepted = True\n                break\n            lam *= beta\n        if not accepted:\n            return -1\n        if not is_finite_scalar(fx):\n            return -1\n        if abs(fx) = tol:\n            return k\n    return -1\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [0.0, 1.0, 10.0, 1.0e3, -1.0e3]\n\n    results = []\n    for x0 in test_cases:\n        ku = newton_undamped(x0, tol=1e-12, max_iter=50, blowup=1e16)\n        kd = newton_damped(x0, tol=1e-12, max_iter=50, c=1e-4, beta=0.5,\n                           max_backtrack=100, blowup=1e16)\n        results.append(int(ku))\n        results.append(int(kd))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3255187"}, {"introduction": "除了发散问题，牛顿法在求解“病态”问题时也会遇到困难。当函数在根附近的导数值接近于零时，问题变得对微小扰动非常敏感，同时牛顿法的收敛也会变得非常缓慢。本练习 [@problem_id:3255046] 将通过一个精心设计的函数 $f(x) = \\varepsilon x - \\sin x$ 来模拟这种情况，让你亲手分析病态性对算法性能的影响。", "problem": "考虑标量非线性方程 $f(x) = \\varepsilon x - \\sin x$，其中 $x$ 以弧度为单位。目标是分析当 $\\varepsilon$ 极小时，近水平交叉点与 Newton 法在求解标量方程时的性能之间的相互作用。使用一阶泰勒展开（线性化 $f(x+\\Delta) \\approx f(x) + f'(x)\\Delta$）作为基本依据，推导出一个迭代方法来近似 $f(x)=0$ 的一个根。您必须在一个无需用户输入的、完整可运行的程序中实现此方法，并用它来研究收敛行为和条件数。\n\n为了创建一个近水平交叉点，选择参数值，使得方程在一个斜率 $f'(x)$ 极小的点上有一个精确的单根。对于一个非负整数 $n$，令 $x_m = \\frac{\\pi}{2} + 2\\pi n$，并设置 $\\varepsilon = \\frac{1}{x_m}$。这样，$f(x_m) = 0$ 且 $f'(x_m) = \\varepsilon - \\cos x_m = \\frac{1}{x_m}$，当 $x_m$ 很大时，该值很小。角度必须以弧度为单位进行解释。\n\n实现从一阶泰勒原理推导出的迭代格式，包含一个基于残差 $\\lvert f(x_k)\\rvert \\leq 10^{-12}$ 或最大 $100$ 次迭代（以先到者为准）的停止规则，并使用纯 Newton 步长，不带启发式阻尼。对于每个测试用例，从初始猜测 $x_0 = x_m + \\delta$（具有指定的偏移量 $\\delta$）开始，并运行您的算法。\n\n为每个测试用例报告以下量：\n- 一个布尔值，指示是否在迭代预算内满足了基于残差的停止规则。\n- 执行的迭代次数（整数）。\n- 根的最终浮点近似值。\n- 相对于已知精确根 $x_m$ 的浮点绝对误差 $\\lvert x_{\\text{approx}} - x_m\\rvert$。\n- 在精确根处计算的灵敏度（条件数）的浮点量级 $\\left\\lvert \\frac{\\partial x^*}{\\partial \\varepsilon} \\right\\rvert$，该值通过对 $f(x)=0$ 关于 $\\varepsilon$ 进行隐式微分得到。\n- 在精确根处计算的 Newton 渐近二次误差常数 $c = \\left\\lvert \\frac{f''(x^*)}{2 f'(x^*)} \\right\\rvert$ 的浮点量级，其中 $x^*$ 表示精确根。\n\n使用以下测试套件，它涵盖一个一般情况、一个条件数越来越差的情况，以及一个可能在迭代预算内不收敛的具有挑战性的极端情况：\n- 测试 1：$n = 3$, $\\delta = 10^{-2}$。\n- 测试 2：$n = 50$, $\\delta = 10^{-3}$。\n- 测试 3：$n = 2000$, $\\delta = 10^{-2}$。\n\n所有角度均以弧度为单位。灵敏度和渐近常数必须使用 $f'(x) = \\varepsilon - \\cos x$ 和 $f''(x) = \\sin x$ 进行符号计算，然后在精确根 $x_m$ 处（其中 $\\varepsilon = \\frac{1}{x_m}$）求值。您的程序应生成单行输出，其中包含聚合结果，格式为方括号括起来的逗号分隔列表，每个测试用例一个列表，顺序为：$[\\,[\\text{case 1 results}], [\\text{case 2 results}], [\\text{case 3 results}]\\,]$。每个用例的列表必须按 $[\\text{converged}, \\text{iterations}, x_{\\text{approx}}, \\lvert x_{\\text{approx}} - x_m\\rvert, \\left\\lvert \\frac{\\partial x^*}{\\partial \\varepsilon} \\right\\rvert, c]$ 的顺序排列。", "solution": "此问题已经过验证。\n\n### 第 1 步：提取已知信息\n- **方程：** $f(x) = \\varepsilon x - \\sin x$，其中 $x$ 以弧度为单位。\n- **根的构造：** 通过设置参数 $\\varepsilon = \\frac{1}{x_m}$，在 $x_m = \\frac{\\pi}{2} + 2\\pi n$（对于非负整数 $n$）处构造一个精确单根 $x_m$。\n- **方法论：** 从一阶泰勒展开 $f(x+\\Delta) \\approx f(x) + f'(x)\\Delta$ 推导出一个迭代方法。\n- **算法：** 推导出的方法（Newton 法）将以纯步长（无阻尼）实现。\n- **初始猜测：** 迭代从 $x_0 = x_m + \\delta$ 开始。\n- **终止标准：** 如果残差量级 $\\lvert f(x_k)\\rvert \\leq 10^{-12}$ 或达到最大迭代次数 100 次，则迭代停止。\n- **提供的导数：** $f'(x) = \\varepsilon - \\cos x$ 和 $f''(x) = \\sin x$。\n- **每个测试用例的所需输出：**\n    1. 一个表示收敛的布尔值。\n    2. 执行的迭代次数。\n    3. 最终根的近似值 $x_{\\text{approx}}$。\n    4. 绝对误差 $\\lvert x_{\\text{approx}} - x_m\\rvert$。\n    5. 在精确根 $x^*=x_m$ 处的灵敏度量级 $\\left\\lvert \\frac{\\partial x^*}{\\partial \\varepsilon} \\right\\rvert$。\n    6. 在精确根 $x^*=x_m$ 处的渐近二次误差常数量级 $c = \\left\\lvert \\frac{f''(x^*)}{2 f'(x^*)} \\right\\rvert$。\n- **测试用例：**\n    1. $n = 3$, $\\delta = 10^{-2}$。\n    2. $n = 50$, $\\delta = 10^{-3}$。\n    3. $n = 2000$, $\\delta = 10^{-2}$。\n- **输出格式：** 一个表示列表的列表的单行：`[[case 1 results], [case 2 results], [case 3 results]]`。\n\n### 第 2 步：使用提取的已知信息进行验证\n该问题在数值分析方面有科学依据，重点是成熟的 Newton 法。该问题是适定的，所有必要组成部分——函数、其导数、初始条件和终止标准——都得到了清晰而精确的定义。该设置在数学上是一致的；选择 $\\varepsilon = \\frac{1}{x_m}$ 和 $x_m = \\frac{\\pi}{2} + 2\\pi n$ 可以在 $x_m$ 处正确地建立一个根，因为 $f(x_m) = \\frac{1}{x_m}x_m - \\sin(\\frac{\\pi}{2} + 2\\pi n) = 1 - 1 = 0$。此根处的导数 $f'(x_m) = \\varepsilon - \\cos(x_m) = \\frac{1}{x_m} - 0 = \\frac{1}{x_m}$ 非零，证实了 $x_m$ 是一个单根。该问题是客观的，没有歧义。它没有违反任何科学或逻辑原则，是分析算法在病态条件下（即当 $n$ 很大时 $f'(x_m)$ 很小）性能的标准练习。\n\n### 第 3 步：结论与行动\n该问题是 **有效的**。将提供一个完整的解决方案。\n\n### 解决方案推导\n解决方案涉及推导迭代算法和必要的解析量，然后实现该算法以处理指定的测试用例。\n\n**1. 迭代方法的推导**\n该问题要求从 $f(x)$ 在迭代点 $x_k$ 附近的一阶泰勒展开推导迭代方法：\n$$f(x_k + \\Delta x) \\approx f(x_k) + f'(x_k)\\Delta x$$\n为了找到根，我们寻找一个修正量 $\\Delta x$ 使得 $f(x_k + \\Delta x) = 0$。将线性近似设为零可得：\n$$f(x_k) + f'(x_k)\\Delta x = 0$$\n求解 $\\Delta x$ 得到修正步长：\n$$\\Delta x = -\\frac{f(x_k)}{f'(x_k)}$$\n这导出了下一个近似值 $x_{k+1} = x_k + \\Delta x$ 的迭代公式：\n$$x_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}$$\n这就是 Newton 法。对于给定的函数 $f(x) = \\varepsilon x - \\sin x$ 及其导数 $f'(x) = \\varepsilon - \\cos x$，具体的迭代公式是：\n$$x_{k+1} = x_k - \\frac{\\varepsilon x_k - \\sin x_k}{\\varepsilon - \\cos x_k}$$\n\n**2. 根灵敏度的推导**\n根 $x^*$ 对参数 $\\varepsilon$ 变化的灵敏度由导数 $\\frac{\\partial x^*}{\\partial \\varepsilon}$ 给出。我们从根的隐式定义 $f(x^*(\\varepsilon), \\varepsilon) = 0$ 开始，即 $\\varepsilon x^*(\\varepsilon) - \\sin(x^*(\\varepsilon)) = 0$。使用乘法法则和链式法则对 $\\varepsilon$ 求导：\n$$\\frac{d}{d\\varepsilon} \\left( \\varepsilon x^* - \\sin(x^*) \\right) = (1 \\cdot x^* + \\varepsilon \\cdot \\frac{dx^*}{d\\varepsilon}) - \\cos(x^*) \\cdot \\frac{dx^*}{d\\varepsilon} = 0$$\n将含有 $\\frac{dx^*}{d\\varepsilon}$ 的项组合在一起：\n$$x^* + (\\varepsilon - \\cos x^*) \\frac{dx^*}{d\\varepsilon} = 0$$\n认识到 $\\varepsilon - \\cos x^* = f'(x^*)$，我们有 $x^* + f'(x^*) \\frac{dx^*}{d\\varepsilon} = 0$。求解灵敏度：\n$$\\frac{dx^*}{d\\varepsilon} = -\\frac{x^*}{f'(x^*)}$$\n这必须在精确根 $x^* = x_m$ 处求值。在这一点上，$f'(x_m) = \\frac{1}{x_m}$。\n$$\\left. \\frac{\\partial x^*}{\\partial \\varepsilon} \\right|_{x_m} = -\\frac{x_m}{1/x_m} = -x_m^2$$\n问题要求的是量级，即 $\\left\\lvert -x_m^2 \\right\\rvert = x_m^2$。\n\n**3. 渐近误差常数的推导**\nNewton 法的渐近二次误差常数是 $c = \\left\\lvert \\frac{f''(x^*)}{2 f'(x^*)} \\right\\rvert$。二阶导数是 $f''(x) = \\frac{d}{dx}(\\varepsilon - \\cos x) = \\sin x$。\n我们在精确根 $x^* = x_m$ 处计算 $c$：\n- $f'(x_m) = \\frac{1}{x_m}$\n- $f''(x_m) = \\sin(x_m) = \\sin(\\frac{\\pi}{2} + 2\\pi n) = 1$\n将这些代入 $c$ 的公式：\n$$c = \\left\\lvert \\frac{1}{2(1/x_m)} \\right\\rvert = \\left\\lvert \\frac{x_m}{2} \\right\\rvert$$\n由于对于非负 $n$，$x_m = \\frac{\\pi}{2} + 2\\pi n > 0$，所以常数是 $c = \\frac{x_m}{2}$。\n\n**4. 实现计划**\n将编写一个程序，为每个测试用例 $(n, \\delta)$ 执行以下逻辑：\n1. 计算 $x_m = \\frac{\\pi}{2} + 2\\pi n$ 和 $\\varepsilon = 1/x_m$。\n2. 初始化迭代值 $x_k = x_m + \\delta$。\n3. 循环最多 100 次迭代：\n    a. 计算残差 $f(x_k)$。如果 $\\lvert f(x_k) \\rvert \\le 10^{-12}$，则将收敛状态设为真，记录迭代次数，并终止循环。\n    b. 计算导数 $f'(x_k)$。如果它为零，则方法失败；终止循环。\n    c. 使用 Newton 步长更新迭代值：$x_{k+1} = x_k - f(x_k)/f'(x_k)$。\n4. 循环终止后（因收敛、失败或达到 100 次迭代限制），计算所需的输出量：收敛状态、迭代次数、最终近似值 $x_{\\text{approx}}$、绝对误差 $\\lvert x_{\\text{approx}} - x_m\\rvert$、灵敏度 $x_m^2$ 和渐近常数 $x_m/2$。\n5. 收集所有测试用例的结果，并按指定格式打印。$n$ 的值从 3 增加到 2000，使得根的条件数逐渐恶化，因为灵敏度 $x_m^2$ 和误差常数 $c = x_m/2$ 都在增长，这为算法的行为提供了一个稳健的测试。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem, orchestrating the test cases and printing the final result.\n    \"\"\"\n\n    def run_newton_for_case(n, delta):\n        \"\"\"\n        Executes Newton's method for a single test case (n, delta).\n        \n        Args:\n            n (int): The non-negative integer parameter for defining the root.\n            delta (float): The initial offset from the exact root.\n            \n        Returns:\n            A list containing the results for the case in the specified format.\n        \"\"\"\n        # Setup problem parameters based on the test case\n        pi = np.pi\n        xm = pi / 2.0 + 2.0 * pi * float(n)\n        eps = 1.0 / xm\n        \n        # Algorithm parameters from the problem statement\n        x_k = xm + delta\n        max_iterations = 100\n        tolerance = 1e-12\n        \n        # Run Newton's method\n        for k in range(max_iterations):\n            # Calculate the residual f(x_k)\n            f_val = eps * x_k - np.sin(x_k)\n            \n            # Check for convergence based on the residual tolerance\n            if np.abs(f_val) = tolerance:\n                # Convergence achieved, calculate final metrics and return\n                abs_error = np.abs(x_k - xm)\n                sensitivity = xm**2\n                asymptotic_constant = xm / 2.0\n                return [True, k, x_k, abs_error, sensitivity, asymptotic_constant]\n            \n            # Calculate the derivative f'(x_k) for the Newton step\n            fp_val = eps - np.cos(x_k)\n            \n            # Check for division by zero (catastrophic failure)\n            if fp_val == 0.0:\n                # Iteration failed. Report non-convergence.\n                abs_error = np.abs(x_k - xm)\n                sensitivity = xm**2\n                asymptotic_constant = xm / 2.0\n                # k+1 iterations were attempted before failure.\n                return [False, k + 1, x_k, abs_error, sensitivity, asymptotic_constant]\n            \n            # Perform the Newton update step\n            x_k = x_k - f_val / fp_val\n\n        # If the loop completes, the maximum number of iterations was reached without convergence\n        abs_error = np.abs(x_k - xm)\n        sensitivity = xm**2\n        asymptotic_constant = xm / 2.0\n        return [False, max_iterations, x_k, abs_error, sensitivity, asymptotic_constant]\n\n    # Define the test suite from the problem statement.\n    test_cases = [\n        (3, 1e-2),\n        (50, 1e-3),\n        (2000, 1e-2),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        n_val, delta_val = case\n        result = run_newton_for_case(n_val, delta_val)\n        all_results.append(result)\n\n    # Final print statement. The default string representation of a list of lists \n    # in Python matches the required output format \"[ [case1], [case2], ... ]\".\n    print(all_results)\n\n# Execute the solver\nsolve()\n```", "id": "3255046"}, {"introduction": "在了解了牛顿法可能遇到的“过冲”和“病态”问题后，一个自然的想法是如何构建一个既快速又绝对可靠的求解器。本练习 [@problem_id:3255029] 将指导你实现一种混合算法，它将牛顿法的快速局部收敛性与区间套法（如二分法）的全局收敛保证相结合。通过实现这种“带安全保护”的牛顿法，你将学会构建在实际应用中更为稳健的数值工具。", "problem": "考虑由函数 $f(x) = \\cos(x) - x$ 及其导数 $f'(x) = -\\sin(x) - 1$ 定义的标量求根问题。目标是通过设计一个遵循以下基本约束的算法，来近似求解 $f(x^\\star) = 0$ 的解 $x^\\star$。基本出发点是：非线性方程 $f(x) = 0$ 的解可以通过基于当前迭代点附近 $f$ 的局部线性化推导出的迭代方法来求解，并且将未知根限定在满足 $f(a) \\cdot f(b) \\le 0$ 的区间 $[a,b]$ 内可以提供防止发散的保障。\n\n根据以下要求，为标量方程构建一个结合了区间限定和牛顿法的程序。在每次迭代中，通过在当前迭代点 $x_n$ 周围对 $f$ 进行线性近似，并令下一个迭代点 $x_{n+1}$ 为该局部近似的零点，来推导更新。每当計算出的 $x_{n+1}$ 超出当前限定区间 $[a,b]$ 时，通过裁剪将其投影回 $[a,b]$ 上，确保 $x_{n+1} \\in [a,b]$。计算出 $x_{n+1}$ 后，通过替换 $a$ 或 $b$ 来更新区间，以保持不变量 $f(a) \\cdot f(b) \\le 0$ 成立，同时使区间单调地向根收缩。基于函数残差、步长和区间宽度设计终止条件，并将它们分别与给定的容差进行比较。\n\n角度必须以弧度为单位进行解释。本任务中不涉及物理单位。您的程序必须专门为 $f(x) = \\cos(x) - x$ 和 $f'(x) = -\\sin(x) - 1$ 实现这种带保障的迭代方法，并且必须通过首先将任何初始猜测值 $x_0$ 投影到所提供的区间 $[a,b]$ 上来处理它。\n\n您的程序必须在以下测试集上运行该算法，每个测试用例产生一个浮点输出：\n- 测试用例 $1$：$a = 0$， $b = 1$， $x_0 = 0.5$， $\\text{tol} = 10^{-12}$， $\\text{max\\_iter} = 50$。\n- 测试用例 $2$：$a = 0$， $b = 2$， $x_0 = 2.0$， $\\text{tol} = 10^{-12}$， $\\text{max\\_iter} = 50$。\n- 测试用例 $3$：$a = 0.7$， $b = 0.8$， $x_0 = 10.0$， $\\text{tol} = 10^{-12}$， $\\text{max\\_iter} = 50$。\n- 测试用例 $4$：$a = 0.73$， $b = 0.75$， $x_0 = 0.75$， $\\text{tol} = 10^{-12}$， $\\text{max\\_iter} = 50$。\n\n每个测试用例必须返回一个根的单浮点近似值，四舍五入到 $12$ 位小数。您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表，例如 $[0.739085133215,0.739085133215,0.739085133215,0.739085133215]$。", "solution": "该问题要求为标量方程 $f(x)=0$ 构建并实现一种带保障的求根算法。该算法结合了从局部线性化推导出的牛顿法和一个防止发散并保证收敛的区间限定保障机制。\n\n迭代过程的核心是牛顿法。对于一个给定的函数 $f(x)$，我们使用一阶泰勒展开在当前迭代点 $x_n$ 附近对其进行近似，这代表了函数在该点的切线：\n$$L(x) = f(x_n) + f'(x_n)(x - x_n)$$\n下一个迭代点 $x_{n+1}$ 被选为该线性近似的根，即 $L(x_{n+1}) = 0$ 的位置。求解 $x_{n+1}$ 得到标准的牛顿法更新规则：\n$$x_{n+1} = x_n - \\frac{f(x_n)}{f'(x_n)}$$\n对于特定函数 $f(x) = \\cos(x) - x$ 及其导数 $f'(x) = -\\sin(x) - 1$，此步骤变为：\n$$x_{n+1} = x_n - \\frac{\\cos(x_n) - x_n}{-\\sin(x_n) - 1}$$\n\n为了解决牛顿法可能产生发散或远离根的迭代点的问题，我们引入了一个基于限定区间的保障机制。该算法维持一个已知包含根的区间 $[a_n, b_n]$，这一点由不变量 $f(a_n) \\cdot f(b_n) \\le 0$ 保证。这是基于介值定理。\n\n算法流程如下：\n\n1.  **初始化**：给定初始区间 $[a, b]$ 和初始猜测值 $x_0$。通过将 $x_0$ 投影到初始区间上确定第一个迭代点，确保它位于有效范围内：$x_0 \\leftarrow \\max(a, \\min(b, x_0))$。迭代计数器从 $n=0$ 开始。循环的初始限定区间为 $[a_0, b_0] = [a, b]$。\n\n2.  **迭代**：对于每次迭代 $n=0, 1, 2, \\dots$，最多到 $\\text{max\\_iter}$ 次：\n    a.  从当前迭代点 $x_n$ 计算一个标准的牛顿步，以找到下一个迭代点的候选值，我们称之为 $x_{newton} = x_n - f(x_n)/f'(x_n)$。\n    b.  **保障 1 (裁剪)**：将此候选值与当前限定区间 $[a_n, b_n]$ 进行比较。如果 $x_{newton}$ 落在该区间之外，则将其“裁剪”或投影回最近的端点。这确保下一个迭代点 $x_{n+1}$ 始终在根的已知界限内：$x_{n+1} = \\max(a_n, \\min(b_n, x_{newton}))$。此步骤可防止可能导致发散的大幅、无效跳跃。\n    c.  **保障 2 (区间更新)**：收缩限定区间，以保持不变量并逼近根。新点 $x_{n+1}$ 用于形成一个新的、更小的子区间。通过评估 $f(x_{n+1})$ 的符号，我们决定替换哪个端点：\n        - 如果 $f(a_n) \\cdot f(x_{n+1}) \\le 0$，则根位于 $[a_n, x_{n+1}]$ 内，因此新区间变为 $[a_{n+1}, b_{n+1}] = [a_n, x_{n+1}]$。\n        - 否则（因为 $f(a_n)$ 和 $f(b_n)$ 符号相反），必然有 $f(x_{n+1}) \\cdot f(b_n) \\le 0$，因此根位于 $[x_{n+1}, b_n]$ 内，新区间变为 $[a_{n+1}, b_{n+1}] = [x_{n+1}, b_n]$。\n        这个过程保证了限定区间的宽度 $|b_n - a_n|$ 是单调不增的。\n    d.  **更新**：更新当前迭代点以进行下一轮循环：$x_n \\leftarrow x_{n+1}$。\n\n3.  **终止**：如果满足以下任一条件，循环终止，其中 $\\text{tol}$ 是指定的容差：\n    - 函数残差足够小：$|f(x_n)| \\le \\text{tol}$。\n    - 步长足够小：$|x_{n+1} - x_n| \\le \\text{tol}$。这表明已收敛到一个点。\n    - 限定区间足够小：$|b_n - a_n| \\le \\text{tol}$。这保证了根的位置已在所需精度之内。\n    - 达到最大迭代次数 $\\text{max\\_iter}$。这可以防止在无法实现收敛的情况下出现无限循环。\n\n最终返回的值是最后计算的迭代点，它代表了算法对根 $x^\\star$ 的最佳近似。该实现将此逻辑应用于给定的测试用例，使用提供的初始区间 $[a, b]$、初始猜测值 $x_0$、容差 $\\text{tol}$ 和最大迭代次数 $\\text{max\\_iter}$ 等参数。所有涉及角度的计算都按规定以弧度为单位执行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases and print the results.\n    \"\"\"\n    \n    def safeguarded_newton(a, b, x0, tol, max_iter):\n        \"\"\"\n        Implements the safeguarded Newton's method as described in the problem.\n\n        Args:\n            a (float): The lower bound of the initial bracketing interval.\n            b (float): The upper bound of the initial bracketing interval.\n            x0 (float): The initial guess for the root.\n            tol (float): The tolerance for termination conditions.\n            max_iter (int): The maximum number of iterations.\n\n        Returns:\n            float: The approximated root.\n        \"\"\"\n        # Define the specific function and its derivative for the problem.\n        def f(x):\n            return np.cos(x) - x\n\n        def f_prime(x):\n            return -np.sin(x) - 1\n\n        # Initialize the bracketing interval.\n        a_n, b_n = a, b\n        \n        # Per instruction, project the initial guess onto the provided bracket.\n        x_n = np.clip(x0, a_n, b_n)\n\n        for _ in range(max_iter):\n            fx = f(x_n)\n            \n            # Termination condition 1: function residual is close to zero.\n            if abs(fx) = tol:\n                return x_n\n\n            fpx = f_prime(x_n)\n            # A general-purpose solver would check if fpx is near zero.\n            # For f'(x) = -sin(x) - 1, the derivative is never zero in the\n            # region of interest, so we can safely divide.\n            \n            # Calculate the Newton step.\n            x_newton = x_n - fx / fpx\n            \n            # Safeguard 1: Project/clip the Newton step into the current bracket.\n            x_next = np.clip(x_newton, a_n, b_n)\n\n            # Termination condition 2: step size is sufficiently small.\n            if abs(x_next - x_n) = tol:\n                return x_next\n            \n            # Safeguard 2: Update the bracketing interval.\n            f_next = f(x_next)\n            \n            # To ensure the logic works correctly, we check against one\n            # endpoint. The other case is handled by the else clause,\n            # leveraging the invariant f(a_n) * f(b_n) = 0.\n            if f(a_n) * f_next = 0:\n                b_n = x_next\n            else:\n                a_n = x_next\n            \n            # Termination condition 3: bracket width is sufficiently small.\n            if abs(b_n - a_n) = tol:\n                return x_next\n                \n            # Update the iterate for the next step.\n            x_n = x_next\n            \n        # If max_iter is reached, return the last computed iterate as the best guess.\n        return x_n\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (a, b, x0, tol, max_iter)\n        (0.0, 1.0, 0.5, 1e-12, 50),\n        (0.0, 2.0, 2.0, 1e-12, 50),\n        (0.7, 0.8, 10.0, 1e-12, 50),\n        (0.73, 0.75, 0.75, 1e-12, 50),\n    ]\n\n    results = []\n    for case in test_cases:\n        a, b, x0, tol, max_iter = case\n        root = safeguarded_newton(a, b, x0, tol, max_iter)\n        results.append(root)\n\n    # Final print statement in the exact required format.\n    # The f-string format specifier ':.12f' handles rounding to 12 decimal places.\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```", "id": "3255029"}]}