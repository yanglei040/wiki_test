{"hands_on_practices": [{"introduction": "差异基因表达分析的核心产出是效应大小（如倍数变化，Fold Change）和统计显著性（p值）。初学者常常混淆这两者，但区分它们对于准确解读结果至关重要。本练习 [@problem_id:2281817] 将引导你分析一个常见情景：一个基因表现出巨大的表达变化，但其p值却不显著，这能帮助你深入理解统计功效、样本量和数据变异性在决定分析结果中的作用。", "problem": "一个计算生物学团队正在使用核糖核酸（RNA）测序数据进行差异基因表达分析。他们的目标是鉴定在癌细胞系中，其表达水平因一种新实验药物而改变的基因。他们将药物处理过的细胞中的基因表达与未经处理的对照组细胞进行比较。对于每个基因，他们的分析流程会计算两个关键指标：\n\n1.  **log$_{2}$(Fold Change)**：该值量化了表达变化的幅度和方向。正值表示上调（表达增加），而负值表示下调。例如，log$_{2}$(Fold Change)为 2.0 对应于表达量增加了 $2^{2} = 4$ 倍。\n2.  **p值**：该值评估观测到的倍数变化的统计显著性。它表示在假设药物没有实际效果（零假设）的情况下，观测到至少与实测值一样极端的倍数变化的概率。p值越小，表明反对零假设的证据越强。通常，p值小于 0.05 被认为具有统计显著性。\n\n该团队对一个名为 `REG-17` 的特定基因的分析得出的 log$_{2}$(Fold Change)为 4.5，p值为 0.38。\n\n下列哪项陈述为 `REG-17` 基因的这一结果提供了最准确和合理的解释？\n\nA. 该药物导致 `REG-17` 的表达量非常大幅度且具有统计显著性的上调，使其成为需要优先进一步研究的候选基因。\n\nB. 实验中观察到 `REG-17` 的表达量大幅上调，但由于数据的高度可变性或样本量不足，我们无法确信这种变化是药物的真实效果，而非随机偶然的结果。\n\nC. 该药物对 `REG-17` 没有有意义的影响，因为观察到的变化不具有统计显著性。\n\nD. 计算肯定有误，因为高达 4.5 的 log$_{2}$(Fold Change)不可能与高达 0.38 的 p值相关联。\n\nE. `REG-17` 是一个生物学上不重要的基因，这就是为什么其表达变化未达到统计显著性的原因。", "solution": "为了确定正确的解释，我们必须仔细考虑 log$_{2}$(Fold Change)和 p值的含义。\n\n1.  **解读 log$_{2}$(Fold Change)：** log$_{2}$(Fold Change)是效应大小的度量。`REG-17` 的值为 4.5 意味着药物处理组中该基因的平均表达量比对照组高约 $2^{4.5} \\approx 22.6$ 倍。从生物学角度来看，这是一个非常大的变化幅度。这表明在收集的数据中确实*观察到*了强烈的上调。\n\n2.  **解读 p值：** p值评估观测效应的统计可靠性。p值为 0.38 意味着，即使药物对基因表达没有真实效果（即，如果零假设为真），纯粹由随机偶然因素导致观测到如此幅度（或更大）的倍数变化的概率为 38%。在生物医学研究中，统计显著性的常规阈值为 p值小于 0.05。由于 0.38 远大于 0.05，该结果被认为**不具有统计显著性**。这个高 p值表明我们不能自信地排除随机变异是观测到变化的原因。缺乏统计显著性通常源于组内重复样本之间的高度可变性（例如，一些处理过的细胞反应强烈，而另一些则没有）或重复样本数量不足，这降低了实验检测真实效应的统计功效。\n\n3.  **综合两个指标：** 我们面临一个看似矛盾的情况：一个非常大的效应大小（log$_{2}$(Fold Change) = 4.5）与缺乏统计显著性（p值 = 0.38）并存。正确的解释综合了这两个事实。它承认在数据中看到的大幅变化，但同时也承认围绕这一观察结果的高度不确定性。我们观察到了显著的现象，但我们不能确定这是否是药物真实、可重复的效果。\n\n现在，让我们基于这一理解来评估给出的选项：\n\n*   **A. 该药物导致 `REG-17` 的表达量非常大幅度且具有统计显著性的上调，使其成为需要优先进一步研究的候选基因。** 这是不正确的。虽然上调幅度很大，但它明确**不具有**统计显著性（p值 = 0.38  0.05）。\n\n*   **B. 实验中观察到 `REG-17` 的表达量大幅上调，但由于数据的高度可变性或样本量不足，我们无法确信这种变化是药物的真实效果，而非随机偶然的结果。** 这是正确的解释。它准确地报告了观察到的大效应（大幅上调），同时正确地将高 p值解释为对结果缺乏信心，并恰当地指出了高可变性或小样本量等常见原因。\n\n*   **C. 该药物对 `REG-17` 没有有意义的影响，因为观察到的变化不具有统计显著性。** 这是一个错误的结论。“没有证据不等于没有（效应）的证据。” 实验未能提供效应的*统计显著证据*，但这并不能证明*没有效应*。大的倍数变化表明可能存在效应，但实验缺乏证实它的统计功效。\n\n*   **D. 计算肯定有误，因为高达 4.5 的 log$_{2}$(Fold Change)不可能与高达 0.38 的 p值相关联。** 这是不正确的。这在生物学实验中是一种非常常见的情况，特别是在重复次数少或生物系统本身就“嘈杂”（即组内方差大）的实验中。\n\n*   **E. `REG-17` 是一个生物学上不重要的基因，这就是为什么其表达变化未达到统计显著性的原因。** 这是一个没有依据的逻辑跳跃。单个实验中的统计显著性并不能说明一个基因的整体生物学重要性。一个基因可能至关重要，但药物可能不影响它，或者实验可能不够稳健以检测到这种变化。", "answer": "$$\\boxed{B}$$", "id": "2281817"}, {"introduction": "在分析数千个基因时，我们会得到数千个p值，这带来了“多重检验问题”。简单地使用传统的 $p \\lt 0.05$ 阈值会导致大量假阳性结果。这个实践练习 [@problem_id:2385494] 将指导你从零开始实现Benjamini-Hochberg（BH）程序，这是一种控制伪发现率（False Discovery Rate, FDR）的关键算法，是现代基因组学数据分析的基石。", "problem": "在一个比较两种条件的差异基因表达实验中，您会得到来自 $m$ 个独立的基因水平零假设的原始 $p$ 值集合。设零假设集为 $\\{H_1,\\dots,H_m\\}$，对应的原始 $p$ 值为 $p_1,\\dots,p_m \\in [0,1]$。对于一个目标水平 $q \\in (0,1)$，用于将错误发现率（FDR）控制在水平 $q$ 的 Benjamini–Hochberg（BH）程序定义如下。将 $p$ 值按非递减顺序排列为 $p_{(1)} \\le \\dots \\le p_{(m)}$，其中下标表示顺序统计量。定义索引\n$$\nk \\;=\\; \\max\\left\\{ i \\in \\{1,\\dots,m\\} \\;:\\; p_{(i)} \\le \\frac{i}{m}\\,q \\right\\},\n$$\n并约定如果该集合为空，则不拒绝任何假设。那么，BH 拒绝集是所有原始 $p$ 值不超过阈值 $p_{(k)}$ 的假设，即\n$$\n\\mathcal{R} \\;=\\; \\{ j \\in \\{1,\\dots,m\\} \\;:\\; p_j \\le p_{(k)} \\},\n$$\n当 $k$ 存在时，否则 $\\mathcal{R}=\\varnothing$。BH 调整后的 $p$ 值（在某些情况下也称为 BH $q$ 值）是为每个假设定义的，首先为第 $i$ 个顺序统计量赋值\n$$\n\\tilde{p}_{(i)} \\;=\\; \\min_{j \\in \\{i,\\dots,m\\}} \\left( \\frac{m}{j}\\,p_{(j)} \\right),\n$$\n然后通过 $\\min\\{\\tilde{p}_{(i)},1\\}$ 在 $1$ 处截断，最后映射回原始假设的顺序。为了在存在相等 $p$ 值的情况下使排序分配具有确定性，请使用稳定的排序方式，通过增加原始索引来打破平局。", "solution": "问题陈述经评估有效。它提出了一个清晰、明确的计算任务，该任务基于标准且科学可靠的 Benjamini-Hochberg 程序，用于控制错误发现率，这是计算生物学和统计学中的一种基本方法。定义、条件和测试用例是完整、一致且客观的，从而能够得出一个唯一且可验证的解。\n\n任务是实现 Benjamini-Hochberg (BH) 程序。给定来自多个假设检验的一组 $m$ 个原始 $p$ 值 $\\{p_1, \\dots, p_m\\}$ 和一个目标错误发现率 (FDR) 水平 $q$，我们必须计算 BH 调整后的 $p$ 值并确定被拒绝的假设集。该程序是确定性的，将通过一系列直接源自所提供数学定义的原则性步骤来实现。\n\n设 $m$ 为假设的总数。算法流程如下：\n\n1.  **数据结构化与排序**：每个原始 $p$ 值 $p_j$ 都与其原始的从 0 开始的索引 $j$ 相关联。然后将得到的配对 $(p_j, j)$ 按 $p_j$ 的非递减顺序排序。问题指定了一种稳定的排序机制来处理平局：如果对于原始索引 $ab$ 有 $p_a = p_b$，则 $(p_a, a)$ 在排序列表中位于 $(p_b, b)$ 之前。\n\n2.  **确定拒绝阈值**：我们通过找到满足 $p_{(i)} \\le \\frac{i}{m}q$ 的最大秩 $k$ 来计算拒绝阈值，其中 $i$ 是从 1 到 $m$ 的秩，$p_{(i)}$ 是第 $i$ 个排序后的 $p$ 值。所有原始 $p$ 值小于或等于 $p_{(k)}$ 的假设都被拒绝。\n\n3.  **计算调整后的 $p$ 值**：BH 调整后的 $p$ 值 $\\tilde{p}$ 的计算要复杂一些，以确保单调性。对于第 $i$ 个排序后的 $p$ 值 $p_{(i)}$，原始的调整值是 $\\frac{m}{i} p_{(i)}$。然而，为了确保调整后的 $p$ 值列表是非递减的，第 $i$ 个调整后的 $p$ 值被定义为从第 $i$ 个到第 $m$ 个的原始调整值的最小值：$\\tilde{p}_{(i)} = \\min_{j=i}^m \\left( \\frac{m}{j} p_{(j)} \\right)$。这等价于从右到左（从 $m$ 到 $1$）计算累积最小值。\n\n4.  **最终化与返回**：将调整后的 $p$ 值截断在 1.0，并将它们重新排序以匹配原始输入顺序。被拒绝的假设的索引也以其原始形式返回，并按升序排序。\n\n此过程将被实现并应用于提供的测试用例，以生成所需的输出格式。", "answer": "```python\nimport numpy as np\n\ndef _format_output(data):\n    \"\"\"\n    Custom recursive function to format the final list into a string\n    without spaces and with floats formatted to 6 decimal places.\n    \"\"\"\n    if isinstance(data, list):\n        return f\"[{','.join(_format_output(item) for item in data)}]\"\n    if isinstance(data, float):\n        return f\"{data:.6f}\"\n    return str(data)\n\ndef benjamini_hochberg(p_values: np.ndarray, q: float):\n    \"\"\"\n    Performs the Benjamini-Hochberg procedure for FDR control.\n\n    Args:\n        p_values: A numpy array of raw p-values.\n        q: The target False Discovery Rate level.\n\n    Returns:\n        A tuple containing:\n        - A list of BH adjusted p-values, rounded to 6 decimal places, in original order.\n        - A sorted list of 0-based indices of rejected hypotheses.\n    \"\"\"\n    m = len(p_values)\n    if m == 0:\n        return [], []\n        \n    original_indices = np.arange(m)\n    \n    # Sort p-values while keeping track of original indices.\n    # The 'stable' kind ensures that for equal p-values, the original order is preserved,\n    # satisfying the problem's tie-breaking rule.\n    sorted_order_indices = np.argsort(p_values, kind='stable')\n    sorted_p_values = p_values[sorted_order_indices]\n    \n    # --- Step 1: Find rejection threshold ---\n    ranks = np.arange(1, m + 1)\n    bh_thresholds = (ranks / m) * q\n    \n    significant_mask = sorted_p_values = bh_thresholds\n    \n    rejected_indices = []\n    if np.any(significant_mask):\n        # Find the largest rank k satisfying the BH condition\n        k = np.max(ranks[significant_mask])\n        \n        # The rejection threshold is the p-value at this rank k\n        rejection_threshold = sorted_p_values[k - 1]\n        \n        # Identify all hypotheses with original p-values = threshold\n        rejected_mask = p_values = rejection_threshold\n        rejected_indices = sorted(original_indices[rejected_mask].tolist())\n\n    # --- Step 2: Calculate adjusted p-values ---\n    # Calculate raw scaled p-values: (m/i) * p_(i)\n    scaled_p_values = (m / ranks) * sorted_p_values\n    \n    # Enforce monotonicity by taking the cumulative minimum from the end (right-to-left)\n    adj_p_sorted = np.minimum.accumulate(scaled_p_values[::-1])[::-1]\n    \n    # Truncate values at 1.0\n    adj_p_sorted = np.minimum(adj_p_sorted, 1.0)\n    \n    # Unsort the adjusted p-values to match the original p-value order\n    adj_p_original = np.empty(m)\n    adj_p_original[sorted_order_indices] = adj_p_sorted\n    \n    # Round to 6 decimal places for final output\n    adj_p_rounded = [round(p, 6) for p in adj_p_original]\n\n    return adj_p_rounded, rejected_indices\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the final result.\n    \"\"\"\n    test_cases = [\n        ((0.001, 0.04, 0.03, 0.2, 0.5, 0.0005, 0.07, 0.9), 0.1),\n        ((0.0, 1.0, 0.5, 0.05, 0.2), 0.05),\n        ((0.02, 0.02, 0.02, 0.5, 0.8, 0.9), 0.1),\n        ((0.2, 0.3, 0.4, 0.6, 0.8), 0.01),\n    ]\n\n    results = []\n    for p_tuple, q_val in test_cases:\n        p_values_np = np.array(p_tuple)\n        adj_p, rej_idx = benjamini_hochberg(p_values_np, q_val)\n        results.append([adj_p, rej_idx])\n    \n    # Print the final result in the specified single-line format\n    print(_format_output(results))\n\nsolve()\n```", "id": "2385494"}, {"introduction": "我们已经学会了解读p值并使用BH程序对其进行校正，但如果p值本身从一开始就是有问题的呢？实验设计中的隐藏变量，如“批次效应”（batch effects），可能会严重干扰结果。通过这个高级编程实践 [@problem_id:2385475]，你将通过模拟数据亲眼见证一个未校正的混杂因素如何导致假阳性结果泛滥，从而深刻理解良好实验设计和正确统计建模的至关重要性。", "problem": "编写一个完整、可运行的程序，该程序模拟在线性模型下具有强批次效应的基因表达数据，并评估在差异基因表达分析中省略批次协变量的影响。您的程序必须实现以下具有科学依据且被广泛接受的基本原理，不得依赖问题陈述中提供的任何快捷公式。\n\n使用的基本原理：\n- 在适当转换的尺度（例如，对数尺度）上，基因表达可以通过带有高斯噪声的线性模型进行建模。对于基因索引 $g$ 和样本索引 $i$，令 $y_{g i}$ 表示表达量。该模型包括一个基因特异性基线项、一个条件项、一个批次项以及一个独立的噪声项。\n- 在高斯噪声假设下，普通最小二乘法 (OLS) 在正确设定的线性模型中产生无偏估计量，并为关于模型系数的假设提供检验统计量，该统计量在零假设下服从学生 $t$ 分布。\n- 对众多基因进行的多重假设检验应使用错误发现率 (FDR) 进行控制。使用 Benjamini–Hochberg (BH) 程序，目标水平为 $q = 0.05$。\n\n模拟设计和假设检验：\n- 所有基因共享相同的生成模型结构，并在两种生物学条件之间没有真实差异表达的全局零假设下进行模拟。具体来说，对于每个基因 $g$，条件效应为 $0$；批次效应作为两个批次之间的固定偏移量在所有基因中共享；基线水平可能因基因而异；噪声在基因内的样本间是独立同分布的高斯噪声，且方差恒定。\n- 程序必须对每个基因，使用以下两种模型来估计条件系数为零的零假设的双侧 $p$ 值：\n  1. 一个省略了批次协变量的错误设定模型（仅条件分析）。\n  2. 一个包含了条件和批次协变量的正确设定模型（条件加批次分析）。\n- 在每次分析中，对所有基因应用目标水平为 $q = 0.05$ 的 Benjamini–Hochberg (BH) 程序，以获得发现的数量（这些都是错误发现，因为数据是在全局零假设下模拟的）。\n\n需要证明的科学原理：\n- 当条件和批次协变量相关（混杂）且批次效应很强时，省略批次协变量会导致估计的条件效应产生偏误，并夸大错误发现；而包含批次协变量则能消除偏误，并将错误发现控制在目标 FDR 水平附近。\n- 当条件和批次协变量正交时，省略批次协变量不会在估计的条件效应中引入偏误；即使不进行校正，错误发现也应接近目标 FDR 水平。\n- 作为一个边界情况，当批次效应为零时，包含或省略批次协变量应产生相似的行为。\n\n测试套件：\n在每种情况下模拟 $m = 2000$ 个基因。对 $g = 1, \\dots, m$ 使用独立的基线水平 $\\mu_g \\sim \\mathcal{N}(0, 1)$。对于每种情况，生成独立的的高斯噪声 $\\varepsilon_{g i} \\sim \\mathcal{N}(0, \\sigma^2)$，其中 $\\sigma = 0.5$。\n\n将二元条件协变量编码为 $x_i \\in \\{0, 1\\}$（对应两种条件），将二元批次协变量编码为 $z_i \\in \\{0, 1\\}$（对应两个批次）。批次偏移是一个常数 $\\gamma$，当 $z_i = 1$ 时加上该值，当 $z_i = 0$ 时为 $0$。所有基因的真实条件效应均为 $0$。使用以下三种情况，每种情况都有跨条件和批次的特定样本构成：\n- 情况 $1$（高度混杂，强批次效应）：批次 $1$ 有 $19$ 个来自条件 $0$ 的样本和 $1$ 个来自条件 $1$ 的样本；批次 $2$ 有 $1$ 个来自条件 $0$ 的样本和 $19$ 个来自条件 $1$ 的样本；$\\gamma = 1.5$；总样本数 $n = 40$。\n- 情况 $2$（正交设计，强批次效应）：批次 $1$ 有 $10$ 个来自条件 $0$ 的样本和 $10$ 个来自条件 $1$ 的样本；批次 $2$ 有 $10$ 个来自条件 $0$ 的样本和 $10$ 个来自条件 $1$ 的样本；$\\gamma = 1.5$；总样本数 $n = 40$。\n- 情况 $3$（高度混杂，无批次效应）：批次 $1$ 有 $9$ 个来自条件 $0$ 的样本和 $1$ 个来自条件 $1$ 的样本；批次 $2$ 有 $1$ 个来自条件 $0$ 的样本和 $9$ 个来自条件 $1$ 的样本；$\\gamma = 0.0$；总样本数 $n = 20$。\n\n随机性与可复现性：\n- 使用固定的随机种子 $20240513$ 来初始化情况 $1$ 的生成器。对于情况 $2$ 和情况 $3$，您必须将情况索引添加到基础种子中（即 $20240513 + 2$ 和 $20240513 + 3$），以确保各情况之间的独立性，同时保持可复现性。\n\n统计分析要求：\n- 对于每个基因和每种情况，使用以下模型计算检验条件系数等于 $0$ 的零假设的双侧 $p$ 值：\n  1. 一个带截距的仅条件线性模型。\n  2. 一个带截距的条件加批次线性模型。\n- 在每次分析中，对 $m$ 个 $p$ 值集合使用水平为 $q = 0.05$ 的 Benjamini–Hochberg (BH) 程序，以确定发现（拒绝）的数量。由于根据构建，所有零假设都为真，因此每个发现都是一个假阳性。报告两种分析的发现数量。\n\n要求的最终输出格式：\n- 您的程序应生成一行输出，其中包含 $6$ 个用逗号分隔的整数，并用方括号括起来，顺序如下：$[\\text{case1\\_naive}, \\text{case1\\_adjusted}, \\text{case2\\_naive}, \\text{case2\\_adjusted}, \\text{case3\\_naive}, \\text{case3\\_adjusted}]$，其中“naive”表示仅条件分析，“adjusted”表示条件加批次分析。\n\n无外部输入：\n- 程序必须完全自包含，不得读取任何输入或文件，也不得访问任何网络资源。所有数值必须按上述规定进行硬编码。\n\n角度单位和物理单位：\n- 不涉及角度或物理单位。\n\n答案类型：\n- 报告的 $6$ 个值中的每一个都必须是整数。\n\n您的目标是实现模拟和分析，以便通过这些测试案例证明，在差异基因表达分析中，省略一个强的、混杂的批次效应会如何夸大错误发现，而包含批次指示符则能恢复有效的推断。", "solution": "所提出的问题是计算统计学中一个有效且定义明确的练习，旨在展示分析高通量生物数据时的一个关键原则：遗漏变量偏误的危险。具体背景是差异基因表达分析，其中未测量或未建模的技术因素（如实验批次）可能会混淆感兴趣的生物信号。该问题具有科学依据，使用了标准的线性模型、普通最小二乘法 (OLS)、学生 $t$ 检验以及用于错误发现率 (FDR) 控制的 Benjamini-Hochberg (BH) 程序，这些都是该领域的基础方法。模拟参数被明确指定，确保了问题的自包含性和可复现性。我们将着手解决。\n\n问题的核心在于通用线性模型，我们将其写成单个基因的矩阵形式 $Y = X\\beta + \\epsilon$。在这里，$Y$ 是一个 $n \\times 1$ 的向量，表示 $n$ 个样本的表达量测量值；$X$ 是一个 $n \\times p$ 的设计矩阵，编码了 $p$ 个参数的实验协变量；$\\beta$ 是一个 $p \\times 1$ 的系数向量，待估计；$\\epsilon$ 是一个 $n \\times 1$ 的独立同分布误差项向量，假设服从高斯分布 $\\mathcal{N}(0, \\sigma^2)$。\n\n数据是在“全局零”情景下模拟的，意味着没有真实的差异表达。对于 $m=2000$ 个基因中的每一个（由 $g$ 索引）和 $n$ 个样本中的每一个（由 $i$ 索引），表达量 $y_{gi}$ 根据真实模型生成：\n$$y_{gi} = \\mu_g + \\gamma z_i + \\varepsilon_{gi}$$\n其中 $\\mu_g \\sim \\mathcal{N}(0, 1)$ 是基因特异性基线表达，$\\gamma$ 是批次效应的大小，$z_i \\in \\{0, 1\\}$ 是批次指示协变量，$\\varepsilon_{gi} \\sim \\mathcal{N}(0, \\sigma^2)$ 是噪声项，其中 $\\sigma=0.5$。生物学条件的真实系数为零。\n\n我们将使用两种不同的模型对每个基因的这些模拟数据进行分析：\n\n1.  一个**错误设定或“朴素”模型**，它省略了批次协变量：\n    $y_{gi} = \\beta_{g0} + \\beta_{g1} x_i + e_{gi}$。设计矩阵 $X_{\\text{naive}}$ 有两列：一个截距（全为 1 的向量）和条件协变量向量 $x$。我们检验零假设 $H_0: \\beta_{g1} = 0$。\n\n2.  一个**正确设定或“校正”模型**，它包含了批次协变量：\n    $y_{gi} = \\beta'_{g0} + \\beta'_{g1} x_i + \\beta'_{g2} z_i + e'_{gi}$。设计矩阵 $X_{\\text{adj}}$ 有三列：一个截距、条件向量 $x$ 和批次向量 $z$。我们检验零假设 $H_0: \\beta'_{g1} = 0$。\n\n对于这两种模型，系数 $\\beta$ 都使用普通最小二乘法 (OLS) 进行估计，其解为 $\\hat{\\beta} = (X^T X)^{-1}X^T Y$。这可以同时对所有 $m$ 个基因进行高效求解。\n\n为了检验条件系数 $\\hat{\\beta}_1$ 的显著性（其中下标 $1$ 表示条件协变量 $x$ 的系数），我们计算学生 $t$ 统计量：\n$$t = \\frac{\\hat{\\beta}_1}{\\text{SE}(\\hat{\\beta}_1)}$$\n标准误 $\\text{SE}(\\hat{\\beta}_1)$ 是该系数估计量方差估计值的平方根。估计量的方差-协方差矩阵由 $\\text{Var}(\\hat{\\beta}) = \\sigma^2 (X^T X)^{-1}$ 给出。我们用其无偏估计量，即均方误差，来估计未知的误差方差 $\\sigma^2$：\n$$\\hat{\\sigma}^2 = \\frac{1}{n-p} \\sum_{i=1}^n (y_i - \\hat{y}_i)^2 = \\frac{\\text{RSS}}{n-p}$$\n其中 $\\hat{y}_i$ 是模型的拟合值，$\\text{RSS}$ 是残差平方和，$n$ 是样本数，$p$ 是模型中的参数数量（$X$ 的列数）。令 $C = (X^T X)^{-1}$。$\\hat{\\beta}_1$ 的特定方差是 $\\hat{\\sigma}^2 C_{11}$（假设条件协变量是 $X$ 的第二列，索引为 1）。因此，标准误为 $\\text{SE}(\\hat{\\beta}_1) = \\sqrt{\\hat{\\sigma}^2 C_{11}}$。在零假设下，此 $t$ 统计量服从自由度为 $n-p$ 的学生 $t$ 分布。根据此分布，我们为每个基因计算一个双侧 $p$ 值。\n\n由于我们正在执行 $m=2000$ 个假设检验（每个基因一个），我们必须进行多重检验校正，以控制错误发现的数量。我们将使用 Benjamini-Hochberg (BH) 程序，目标错误发现率 (FDR) 为 $q = 0.05$。该程序如下：\n1.  将 $m$ 个 $p$ 值按升序排序：$p_{(1)} \\le p_{(2)} \\le \\dots \\le p_{(m)}$。\n2.  找到满足 $p_{(k)} \\le \\frac{k}{m} q$ 的最大整数 $k$。\n3.  如果存在这样的 $k$，则拒绝与 $p_{(1)}, \\dots, p_{(k)}$ 对应的所有零假设。发现的数量为 $k$。如果不存在这样的 $k$，则不拒绝任何假设，发现的数量为 $0$。\n\n我们将为三种指定的情况完整地实现此过程，这些情况在实验设计（混杂 vs. 正交）和批次效应的强度上有所不同。\n\n-   **情况 1 (混杂):** 条件和批次协变量强相关。当批次效应 $\\gamma$ 很大时，省略批次协变量 $z$ 将导致对条件系数 $\\beta_1$ 的估计有偏。这种偏误，称为遗漏变量偏误，与真实批次效应以及批次与条件协变量之间的相关性成正比。这种偏误将系统地使估计的条件效应偏离零，导致大量的小 $p$ 值和朴素分析中错误发现的急剧增加。校正模型通过考虑 $z$ 将消除这种偏误并提供有效的推断，使错误发现的数量被适当地控制在预期水平附近。\n\n-   **情况 2 (正交):** 条件和批次协变量不相关（正交设计）。在这种情况下，遗漏变量偏误项为零。因此，即使存在强烈的批次效应，朴素模型中条件系数的估计仍然是无偏的。预计朴素分析和校正分析都能正确控制错误发现率。\n\n-   **情况 3 (混杂，无批次效应):** 设计与情况 1 一样是混杂的，但批次效应大小 $\\gamma$ 为零。遗漏变量偏误与 $\\gamma$ 成正比，因此如果 $\\gamma=0$，则没有偏误。朴素模型和校正模型都应该表现正确，类似于情况 2。\n\n程序将系统地执行这些模拟，对每种情况进行朴素和校正分析，应用 BH 程序，并报告由此产生的错误发现数量，从而定量地展示这些基本的统计学原理。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation suite and print the final results.\n    \"\"\"\n\n    # Global parameters\n    m = 2000  # Number of genes\n    sigma = 0.5  # Noise standard deviation\n    q_level = 0.05  # Target FDR level for BH procedure\n\n    # Case 1: High confounding, strong batch\n    case1_params = {\n        'n_cond0_batch1': 19, 'n_cond1_batch1': 1,\n        'n_cond0_batch2': 1, 'n_cond1_batch2': 19\n    }\n    case1_gamma = 1.5\n    case1_seed = 20240513\n    \n    # Case 2: Orthogonal design, strong batch\n    case2_params = {\n        'n_cond0_batch1': 10, 'n_cond1_batch1': 10,\n        'n_cond0_batch2': 10, 'n_cond1_batch2': 10\n    }\n    case2_gamma = 1.5\n    case2_seed = 20240513 + 2\n\n    # Case 3: High confounding, no batch effect\n    case3_params = {\n        'n_cond0_batch1': 9, 'n_cond1_batch1': 1,\n        'n_cond0_batch2': 1, 'n_cond1_batch2': 9\n    }\n    case3_gamma = 0.0\n    case3_seed = 20240513 + 3\n    \n    test_cases = [\n        (case1_params, case1_gamma, m, sigma, q_level, case1_seed),\n        (case2_params, case2_gamma, m, sigma, q_level, case2_seed),\n        (case3_params, case3_gamma, m, sigma, q_level, case3_seed),\n    ]\n\n    results = []\n    for params in test_cases:\n        naive_discoveries, adjusted_discoveries = run_simulation(*params)\n        results.extend([naive_discoveries, adjusted_discoveries])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef run_simulation(case_params, gamma, m, sigma, q, seed):\n    \"\"\"\n    Runs a single simulation case.\n    \n    Generates data, performs naive and adjusted analyses, and returns the number of discoveries for each.\n    \"\"\"\n    np.random.seed(seed)\n\n    # 1. Construct design vectors (x for condition, z for batch)\n    n01 = case_params['n_cond0_batch1']\n    n11 = case_params['n_cond1_batch1']\n    n02 = case_params['n_cond0_batch2']\n    n12 = case_params['n_cond1_batch2']\n    \n    n_batch1 = n01 + n11\n    n_batch2 = n02 + n12\n    n = n_batch1 + n_batch2\n\n    x = np.array([0]*n01 + [1]*n11 + [0]*n02 + [1]*n12)\n    z = np.array([0]*n_batch1 + [1]*n_batch2)\n\n    # 2. Generate gene expression data\n    # True model: y = mu + gamma*z + noise\n    mu_g = np.random.normal(0, 1, size=(m, 1))\n    noise = np.random.normal(0, sigma, size=(m, n))\n    Y = mu_g + gamma * z[np.newaxis, :] + noise\n\n    # 3. Define design matrices\n    X_naive = np.vstack([np.ones(n), x]).T\n    X_adjusted = np.vstack([np.ones(n), x, z]).T\n\n    # 4. Perform analyses and get discovery counts\n    naive_discoveries = perform_analysis(Y, X_naive, q)\n    adjusted_discoveries = perform_analysis(Y, X_adjusted, q)\n\n    return naive_discoveries, adjusted_discoveries\n\ndef perform_analysis(Y, X, q):\n    \"\"\"\n    Performs OLS regression and multiple testing correction for a set of genes.\n    \"\"\"\n    n, p = X.shape # n = samples, p = parameters\n    m = Y.shape[0] # m = genes\n    \n    # 1. Fit linear model for all genes at once using np.linalg.lstsq\n    # Y is (m, n), X is (n, p). We need to solve X @ B.T = Y.T for B.\n    # B will be (m, p). lstsq returns coefficients as (p, m).\n    beta_hat, rss_per_gene, _, _ = np.linalg.lstsq(X, Y.T, rcond=None)\n\n    # 2. Calculate t-statistics for the condition coefficient (at index 1)\n    df = n - p\n    sigma_sq_hat = rss_per_gene / df\n    \n    # The variance of beta_hat is diag(inv(X'X)) * sigma_hat^2\n    # We are interested in the coefficient for the condition 'x', which is at index 1\n    C = np.linalg.inv(X.T @ X)\n    se_beta1 = np.sqrt(sigma_sq_hat * C[1, 1])\n\n    # Avoid division by zero if standard error is somehow zero\n    # This should not happen in this problem's setup\n    t_stats = np.zeros(m)\n    valid_se = se_beta1 > 0\n    t_stats[valid_se] = beta_hat[1, valid_se] / se_beta1[valid_se]\n    \n    # 3. Calculate two-sided p-values\n    p_values = 2 * t.sf(np.abs(t_stats), df=df)\n\n    # 4. Apply Benjamini-Hochberg procedure\n    num_discoveries = bh_procedure(p_values, q)\n    \n    return num_discoveries\n\ndef bh_procedure(p_values, q):\n    \"\"\"\n    Applies the Benjamini-Hochberg procedure to control FDR.\n    \"\"\"\n    m = len(p_values)\n    if m == 0:\n        return 0\n        \n    p_values_sorted = np.sort(p_values)\n    ranks = np.arange(1, m + 1)\n    thresholds = (ranks / m) * q\n    \n    # Find all p-values that are below the BH threshold\n    significant_mask = p_values_sorted = thresholds\n    \n    if np.any(significant_mask):\n        # The number of discoveries is the rank of the last p-value\n        # that is below its threshold\n        k = np.max(np.where(significant_mask))\n        num_discoveries = k + 1\n    else:\n        num_discoveries = 0\n        \n    return num_discoveries\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2385475"}]}