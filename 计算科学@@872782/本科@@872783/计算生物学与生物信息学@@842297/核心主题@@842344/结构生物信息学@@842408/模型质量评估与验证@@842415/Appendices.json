{"hands_on_practices": [{"introduction": "ROC曲线下面积（AUC）是衡量分类器性能的常用指标，但它是否是唯一的标准？本练习将探讨一个关键问题：当两个模型的AUC值相同时，我们应如何选择。通过分析一个有实际约束的临床场景，你将学会超越单一指标，根据具体应用需求做出更明智的模型评估。", "problem": "一个临床实验室正在验证两个二元分类器 $C_1$ 和 $C_2$，用于从高通量测序数据中筛查一种罕见的致病性变异。性能通过受试者工作特征 (ROC) 曲线进行总结，该曲线绘制了真阳性率 ($\\mathrm{TPR}$) 相对于假阳性率 ($\\mathrm{FPR}$) 的关系。对于每个分类器，ROC 曲线由以下各点之间的线性插值定义：\n\n- 对于 $C_1$：$(0, 0)$、$(0.05, 0.55)$、$(1, 1)$。\n- 对于 $C_2$：$(0, 0)$、$(0.20, 0.70)$、$(1, 1)$。\n\n假设评估队列足够大，以至于这些分段线性曲线可以被视为精确的。监管机构规定，任何部署的筛查阈值都必须满足 $\\mathrm{FPR} \\le 0.05$。\n\n哪个选项是正确的？\n\nA. ROC 曲线下的面积相等，且在 $\\mathrm{FPR} \\le 0.05$ 的约束下，$C_1$ 更优。\n\nB. ROC 曲线下的面积相等，且在 $\\mathrm{FPR} \\le 0.05$ 的约束下，$C_2$ 更优。\n\nC. $C_1$ 的 ROC 曲线下面积超过 $C_2$，因此在任何约束下 $C_1$ 都更优。\n\nD. ROC 曲线下的面积相等，因此在任何约束下 $C_1$ 和 $C_2$ 在临床上都无法区分。", "solution": "题目陈述经过验证。\n\n**步骤1：提取已知条件**\n- 两个二元分类器，记为 $C_1$ 和 $C_2$。\n- 性能由受试者工作特征 (ROC) 曲线衡量，该曲线绘制了真阳性率 ($\\mathrm{TPR}$) 相对于假阳性率 ($\\mathrm{FPR}$) 的关系。\n- ROC 曲线是分段线性的。\n- 对于分类器 $C_1$，ROC 曲线经过点 $(0, 0)$、$(0.05, 0.55)$ 和 $(1, 1)$。\n- 对于分类器 $C_2$，ROC 曲线经过点 $(0, 0)$、$(0.20, 0.70)$ 和 $(1, 1)$。\n- 这些曲线被认为是性能的精确表示。\n- 施加了一个监管约束：任何部署的筛查阈值都必须满足 $\\mathrm{FPR} \\le 0.05$。\n\n**步骤2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题使用了统计分类和医学诊断中的标准基石概念，即 ROC 分析、$\\mathrm{TPR}$ 和 $\\mathrm{FPR}$。筛查致病性变异的背景是生物信息学中的一个主要应用。该问题是科学合理的。\n- **适定性：** 问题定义明确。两个分类器的 ROC 曲线都由一组点和线性插值规则明确给出。目标是基于这些曲线和一个给定的精确约束来比较分类器。唯一解所需的所有信息都已提供。\n- **客观性：** 问题使用该领域标准的精确、明确的术语进行陈述。它不包含主观或基于意见的陈述。\n\n**步骤3：结论与行动**\n该问题具有科学依据、适定、客观且内部一致。因此它是 **有效的**。我将继续推导解决方案。\n\n解决方案需要两个主要步骤：首先，为每个分类器计算整体性能指标，即 ROC 曲线下面积 (AUC)（旧称“曲线下面积”），其次，在给定的假阳性率约束下专门评估其性能。\n\n**第1部分：计算 ROC 曲线下面积 (AUC)**\n分段线性 ROC 曲线下的面积通过对线段形成的梯形面积求和来计算。由点 $(x_{i-1}, y_{i-1})$ 和 $(x_i, y_i)$ 定义的梯形面积由公式 $(x_i - x_{i-1}) \\times \\frac{y_{i-1} + y_i}{2}$ 给出。\n\n对于分类器 $C_1$，其点为 $(0, 0)$、$(0.05, 0.55)$ 和 $(1, 1)$。\n总面积 $\\mathrm{AUC}_1$ 是两个梯形面积之和。\n- 第一个梯形的面积（从 $\\mathrm{FPR}=0$ 到 $\\mathrm{FPR}=0.05$）：\n$A_1 = (0.05 - 0) \\times \\frac{0 + 0.55}{2} = 0.05 \\times 0.275 = 0.01375$\n- 第二个梯形的面积（从 $\\mathrm{FPR}=0.05$ 到 $\\mathrm{FPR}=1$）：\n$A_2 = (1 - 0.05) \\times \\frac{0.55 + 1}{2} = 0.95 \\times \\frac{1.55}{2} = 0.95 \\times 0.775 = 0.73625$\n- $C_1$ 的总 AUC：\n$\\mathrm{AUC}_1 = A_1 + A_2 = 0.01375 + 0.73625 = 0.75$\n\n对于分类器 $C_2$，其点为 $(0, 0)$、$(0.20, 0.70)$ 和 $(1, 1)$。\n总面积 $\\mathrm{AUC}_2$ 也是两个梯形面积之和。\n- 第一个梯形的面积（从 $\\mathrm{FPR}=0$ 到 $\\mathrm{FPR}=0.20$）：\n$A_1' = (0.20 - 0) \\times \\frac{0 + 0.70}{2} = 0.20 \\times 0.35 = 0.07$\n- 第二个梯形的面积（从 $\\mathrm{FPR}=0.20$ 到 $\\mathrm{FPR}=1$）：\n$A_2' = (1 - 0.20) \\times \\frac{0.70 + 1}{2} = 0.80 \\times \\frac{1.70}{2} = 0.80 \\times 0.85 = 0.68$\n- $C_2$ 的总 AUC：\n$\\mathrm{AUC}_2 = A_1' + A_2' = 0.07 + 0.68 = 0.75$\n\n计算证实 $\\mathrm{AUC}_1 = \\mathrm{AUC}_2 = 0.75$。ROC 曲线下的面积相等。\n\n**第2部分：在 $\\mathrm{FPR} \\le 0.05$ 约束下的评估**\n监管机构规定只有 $\\mathrm{FPR} \\le 0.05$ 的工作点是允许的。为了在此约束下比较分类器，我们必须确定在区间 $[0, 0.05]$ 内，对于任何给定的 $\\mathrm{FPR}$，哪个分类器提供更高的 $\\mathrm{TPR}$。\n\n对于分类器 $C_1$，该区域内的 ROC 曲线是连接 $(0, 0)$ 和 $(0.05, 0.55)$ 的线段。$C_1$ 的 $\\mathrm{TPR}$ 作为 $\\mathrm{FPR}$ 函数的方程是：\n$$ \\mathrm{TPR}_1(\\mathrm{FPR}) = \\frac{0.55 - 0}{0.05 - 0} \\times \\mathrm{FPR} = 11 \\times \\mathrm{FPR} \\quad \\text{对于 } 0 \\le \\mathrm{FPR} \\le 0.05 $$\n\n对于分类器 $C_2$，其 ROC 曲线的相关部分是连接 $(0, 0)$ 和 $(0.20, 0.70)$ 的线段。$C_2$ 在该区域的 $\\mathrm{TPR}$ 方程是：\n$$ \\mathrm{TPR}_2(\\mathrm{FPR}) = \\frac{0.70 - 0}{0.20 - 0} \\times \\mathrm{FPR} = 3.5 \\times \\mathrm{FPR} \\quad \\text{对于 } 0 \\le \\mathrm{FPR} \\le 0.20 $$\n\n现在，我们在约束区间 $(0, 0.05]$ 内比较这两个函数对于任何 $\\mathrm{FPR}$ 值的表现。\n$$ \\mathrm{TPR}_1(\\mathrm{FPR}) = 11 \\times \\mathrm{FPR} $$\n$$ \\mathrm{TPR}_2(\\mathrm{FPR}) = 3.5 \\times \\mathrm{FPR} $$\n由于 $11 > 3.5$，因此在允许范围内的任何正值 $\\mathrm{FPR}$ 下，都有 $\\mathrm{TPR}_1(\\mathrm{FPR}) > \\mathrm{TPR}_2(\\mathrm{FPR})$。这意味着在目标工作区域内，分类器 $C_1$ 严格优于分类器 $C_2$。例如，在允许的最大 $\\mathrm{FPR}$ 为 0.05 时，$C_1$ 达到的 $\\mathrm{TPR}$ 为 0.55，而 $C_2$ 达到的 $\\mathrm{TPR}$ 仅为 $3.5 \\times 0.05 = 0.175$。\n\n因此，在监管约束下，分类器 $C_1$ 无疑是更优的选择。\n\n**逐项分析**\n\nA. ROC 曲线下的面积相等，且在 $\\mathrm{FPR} \\le 0.05$ 的约束下，$C_1$ 更优。\n- 根据计算，$\\mathrm{AUC}_1 = \\mathrm{AUC}_2 = 0.75$。陈述的第一部分是正确的。\n- 如前所示，对于任何给定的 $\\mathrm{FPR} \\in (0, 0.05]$，$C_1$ 提供的 $\\mathrm{TPR}$ 都高于 $C_2$。因此，在该约束下 $C_1$ 更优。陈述的第二部分也是正确的。\n- 结论：**正确**。\n\nB. ROC 曲线下的面积相等，且在 $\\mathrm{FPR} \\le 0.05$ 的约束下，$C_2$ 更优。\n- 第一部分正确。\n- 第二部分错误。分类器 $C_1$ 更优，而不是 $C_2$。\n- 结论：**错误**。\n\nC. $C_1$ 的 ROC 曲线下面积超过 $C_2$，因此在任何约束下 $C_1$ 都更优。\n- 前提“$C_1$ 的 ROC 曲线下面积超过 $C_2$”是错误的。两个面积相等。\n- 结论“因此在任何约束下 $C_1$ 都更优”在逻辑上也是不成立的。即使一个 AUC 更高，也不能保证在所有可能的约束下都更优。\n- 结论：**错误**。\n\nD. ROC 曲线下的面积相等，因此在任何约束下 $C_1$ 和 $C_2$ 在临床上都无法区分。\n- 前提“ROC 曲线下的面积相等”是正确的。\n- 结论“因此在任何约束下 $C_1$ 和 $C_2$ 在临床上都无法区分”是一个常见但严重的推理错误。相同的总 AUC 并不意味着在 ROC 空间的特定子区域内性能相同。我们的分析表明，在给定约束下，$C_1$ 有着明显的临床优势且更受青睐。对于不同的约束，例如 $\\mathrm{FPR} \\ge 0.1$，$C_2$ 可能更优。因此，它们并非无法区分。\n- 结论：**错误**。", "answer": "$$\\boxed{A}$$", "id": "2406412"}, {"introduction": "在全基因组关联研究（GWAS）中，系统性偏差（如群体分层）可能导致统计数据膨胀，从而产生大量假阳性结果。本练习介绍了一种重要的诊断和校正工具——基因组膨胀因子（$\\lambda_{GC}$）。你将动手计算$\\lambda_{GC}$并用它来校正p值，这是确保GWAS结果可靠性的基本技能。", "problem": "一项全基因组关联研究使用得分检验来测试 $M$ 个单核苷酸多态性，其零分布是自由度为 $1$ 的 $\\chi^{2}$ 分布。为了评估模型校准和潜在的群体分层，基因组膨胀因子 $\\lambda_{GC}$ 被定义为观察到的 $\\chi^{2}$ 检验统计量的中位数与零假设下的 $\\chi^{2}$ 分布中位数之比。在这项研究中，观察到的检验统计量的中位数为 $m_{\\text{obs}} = 0.62$。在自由度为 $1$ 的 $\\chi^{2}$ 分布的零假设下，中位数为 $m_{\\text{null}} = 0.4549364231$。对于一个特定的变异，未经校正的检验统计量为 $X^2 = 6.635$。对于自由度为 $1$ 的 $\\chi^{2}$ 分布，回想一下，它是 $Z^{2}$ 的分布，其中 $Z \\sim \\mathcal{N}(0,1)$，并令 $\\Phi$ 表示 $\\mathcal{N}(0,1)$ 的累积分布函数。\n\n使用 $\\lambda_{GC}$ 通过将检验统计量重新缩放为 $X^2_{\\text{corr}} = X^2/\\lambda_{GC}$ 来校正膨胀，计算此变异的经 $\\lambda_{GC}$ 校正的 $p$ 值，即 $P(\\chi^2_1 \\ge X^2_{\\text{corr}})$，并将其报告为小数。将您的答案四舍五入到三位有效数字。", "solution": "问题陈述已经过验证。\n\n已知条件逐字提取如下：\n- 一项研究测试了 $M$ 个单核苷酸多态性。\n- 得分检验的零分布是自由度为 $1$ 的 $\\chi^{2}$ 分布。\n- 基因组膨胀因子 $\\lambda_{GC}$ 被定义为观察到的 $\\chi^{2}$ 检验统计量的中位数与零假设下的 $\\chi^{2}$ 分布中位数之比。\n- 观察到的检验统计量的中位数为 $m_{\\text{obs}} = 0.62$。\n- 自由度为 $1$ 的零假设下的 $\\chi^{2}$ 分布的中位数为 $m_{\\text{null}} = 0.4549364231$。\n- 对于一个特定的变异，未经校正的检验统计量为 $X^2 = 6.635$。\n- 一个服从自由度为 $1$ 的 $\\chi^{2}$ 分布的随机变量在分布上等同于 $Z^{2}$，其中 $Z \\sim \\mathcal{N}(0,1)$。\n- $\\Phi$ 表示标准正态分布 $\\mathcal{N}(0,1)$ 的累积分布函数 (CDF)。\n- 基因组控制校正将检验统计量重新缩放为 $X^2_{\\text{corr}} = X^2/\\lambda_{GC}$。\n- 目标是计算经 $\\lambda_{GC}$ 校正的 $p$ 值，定义为 $P(\\chi^2_1 \\ge X^2_{\\text{corr}})$，并将结果四舍五入到三位有效数字。\n\n验证评估：\n该问题在科学上是合理的，描述了在全基因组关联研究中诊断和校正混杂因素的标准和公认程序。所有组成部分——得分检验、$\\chi^{2}$ 分布、基因组膨胀因子 $\\lambda_{GC}$ 的定义和应用——在统计遗传学中都是标准的。所提供的数据是一致的，并且足以得到唯一解。该问题是适定的、客观的，并且直接属于计算生物学领域。该问题被认为是有效的，并将提供一个解决方案。\n\n第一步是使用提供的中位数计算基因组膨胀因子 $\\lambda_{GC}$。\n$$\n\\lambda_{GC} = \\frac{m_{\\text{obs}}}{m_{\\text{null}}}\n$$\n代入给定值：\n$$\n\\lambda_{GC} = \\frac{0.62}{0.4549364231} \\approx 1.362835\n$$\n该因子大于 $1$，表明检验统计量存在膨胀，这与问题的前提一致。\n\n接下来，我们通过将未经校正的统计量 $X^2$ 除以计算出的膨胀因子 $\\lambda_{GC}$ 来计算校正后的检验统计量 $X^2_{\\text{corr}}$。\n$$\nX^2_{\\text{corr}} = \\frac{X^2}{\\lambda_{GC}}\n$$\n代入数值：\n$$\nX^2_{\\text{corr}} = \\frac{6.635}{1.362835} \\approx 4.86862\n$$\n校正后的 $p$ 值是从自由度为 $1$ 的 $\\chi^{2}$ 分布中观察到大于或等于 $X^2_{\\text{corr}}$ 的值的概率。令 $Y$ 是一个随机变量，使得 $Y \\sim \\chi^{2}_{1}$。那么 $p$ 值为：\n$$\np = P(Y \\geq X^2_{\\text{corr}})\n$$\n如问题所述，一个服从 $\\chi^{2}_{1}$ 分布的随机变量是一个标准正态随机变量 $Z \\sim \\mathcal{N}(0,1)$ 的平方。因此，事件 $Y \\geq X^2_{\\text{corr}}$ 等价于 $Z^{2} \\geq X^2_{\\text{corr}}$。这个不等式成立当且仅当 $|Z| \\geq \\sqrt{X^2_{\\text{corr}}}$。\n该概率可以表示为：\n$$\np = P(|Z| \\geq \\sqrt{X^2_{\\text{corr}}}) = P(Z \\geq \\sqrt{X^2_{\\text{corr}}}) + P(Z \\leq -\\sqrt{X^2_{\\text{corr}}})\n$$\n由于标准正态分布关于 $0$ 的对称性，我们有 $P(Z \\leq -z) = P(Z \\geq z)$。因此：\n$$\np = 2 \\times P(Z \\geq \\sqrt{X^2_{\\text{corr}}})\n$$\n使用标准正态分布的累积分布函数 (CDF)，$\\Phi(z) = P(Z \\leq z)$，我们可以写出 $P(Z \\geq z) = 1 - \\Phi(z)$。因此，$p$ 值为：\n$$\np = 2 \\times (1 - \\Phi(\\sqrt{X^2_{\\text{corr}}}))\n$$\n我们现在代入计算出的 $X^2_{\\text{corr}}$ 的值：\n$$\n\\sqrt{X^2_{\\text{corr}}} \\approx \\sqrt{4.86862} \\approx 2.2065\n$$\n$p$ 值为：\n$$\np \\approx 2 \\times (1 - \\Phi(2.2065))\n$$\n标准正态表或计算函数给出 $\\Phi(2.2065) \\approx 0.986323$。\n$$\np \\approx 2 \\times (1 - 0.986323) = 2 \\times 0.013677 = 0.027354\n$$\n问题要求答案四舍五入到三位有效数字。第一位有效数字是 $2$，第二位是 $7$，第三位是 $3$。随后的数字是 $5$，这要求将第三位有效数字向上舍入。\n$$\np \\approx 0.0274\n$$\n这是指定变异的最终校正后的 $p$ 值。", "answer": "$$\n\\boxed{0.0274}\n$$", "id": "2406474"}, {"introduction": "评估时间序列数据模型时，一个常见的陷阱是使用标准交叉验证，这会因“窥探未来”而导致过于乐观的结果。本练习将指导你实现一种正确的方法——前向链式交叉验证（forward-chaining cross-validation）。通过模拟预测未来流感毒株的任务，你将掌握如何为依赖时间顺序的数据设计和执行有效的验证策略。", "problem": "给定一个按时间顺序排列的流感季节序列，以整数 $t \\in \\{1,2,\\dots,T\\}$ 为索引，其特征向量为 $\\mathbf{x}_t \\in \\mathbb{R}^d$，对应的主导毒株标签为 $y_t \\in \\{0,1,2\\}$。共有 $K=3$ 种可能的毒株。考虑一个线性概率模型，其定义如下。对于一个参数矩阵 $\\mathbf{W} \\in \\mathbb{R}^{K \\times (d+1)}$ 和一个通过将常数项 $1$ 与 $\\mathbf{x}$ 拼接而成的增广特征向量 $\\tilde{\\mathbf{x}} \\in \\mathbb{R}^{d+1}$，未归一化的分数为 $\\mathbf{z} = \\mathbf{W}\\tilde{\\mathbf{x}} \\in \\mathbb{R}^K$。预测的类别概率向量 $\\mathbf{p} \\in \\mathbb{R}^K$ 由 softmax 函数给出，其分量为\n$$\np_k = \\frac{\\exp(z_k)}{\\sum_{j=1}^{K} \\exp(z_j)} \\quad \\text{for } k \\in \\{1,\\dots,K\\}.\n$$\n训练使用平方误差代理 one-hot 目标，并对非截距参数进行平方欧几里得范数正则化（也称为 $L_2$ 正则化）。令 $\\mathbf{X} \\in \\mathbb{R}^{n \\times (d+1)}$ 是通过堆叠 $n$ 个训练季节的增广特征而形成的设计矩阵，令 $\\mathbf{Y} \\in \\mathbb{R}^{n \\times K}$ 是对应的标签的 one-hot 编码，其中第 $i$ 行为标准基向量 $\\mathbf{e}_{y_i+1}^\\top$。对于给定的非负正则化强度 $\\lambda \\in \\mathbb{R}_{\\ge 0}$，在 $n$ 个样本上对 $\\mathbf{W}$ 的训练目标是\n$$\n\\mathcal{L}(\\mathbf{W}) = \\sum_{i=1}^{n} \\left\\| \\mathbf{W}\\tilde{\\mathbf{x}}_i - \\mathbf{y}_i \\right\\|_2^2 \\;+\\; \\lambda \\sum_{k=1}^{K} \\sum_{j=2}^{d+1} W_{k,j}^2,\n$$\n其中截距列 $j=1$ 不被正则化。假设解 $\\mathbf{W}^\\star$ 取为 $\\mathcal{L}(\\mathbf{W})$ 的任意一个最小化子。\n\n定义前向链式交叉验证方案如下。给定一个最小训练集大小 $m \\in \\mathbb{Z}$，其中 $1 \\le m  T$，对于每个划分索引 $k \\in \\{m, m+1, \\dots, T-1\\}$，在季节 $\\{1,2,\\dots,k\\}$ 上训练模型以获得 $\\mathbf{W}^\\star_{(k)}$，然后在季节 $k+1$ 上进行评估以获得预测概率向量 $\\mathbf{p}^{(k+1)}$ 和预测类别 $\\hat{y}_{k+1} = \\operatorname*{arg\\,max}_{c \\in \\{0,1,2\\}} p^{(k+1)}_{c+1}$。如果最大值出现平局，则使用最小的索引 $c$。\n\n对于每个划分，定义 top-1 正确性指示符为 $I_{k+1} = 1$（如果 $\\hat{y}_{k+1} = y_{k+1}$）和 $I_{k+1} = 0$（否则）。定义每个划分的负对数似然（多分类交叉熵）为\n$$\n\\ell_{k+1} = -\\log \\left( p^{(k+1)}_{y_{k+1}+1} \\right),\n$$\n其中使用自然对数。将所有划分的这些值聚合起来，以获得平均 top-1 准确率\n$$\nA = \\frac{1}{T- m} \\sum_{k=m}^{T-1} I_{k+1}\n$$\n和平均负对数似然\n$$\nL = \\frac{1}{T- m} \\sum_{k=m}^{T-1} \\ell_{k+1}.\n$$\n$A$ 和 $L$ 均为无量纲实数。准确率 $A$ 必须以小数形式报告，而不是百分比。\n\n使用以下按时间顺序排列的数据，其中 $T = 10$，$d = 4$，且 $K = 3$。季节 $t$ 的增广特征为 $\\tilde{\\mathbf{x}}_t = [1, x_{t,1}, x_{t,2}, x_{t,3}, x_{t,4}]^\\top$。\n\n特征 $\\mathbf{x}_t$，$t = 1, \\dots, 10$：\n- $t=1$: $[0.6, 0.2, 0.1, 0.3]$\n- $t=2$: $[0.7, 0.1, 0.15, 0.25]$\n- $t=3$: $[0.2, 0.8, 0.05, 0.4]$\n- $t=4$: $[0.1, 0.85, 0.1, 0.35]$\n- $t=5$: $[0.3, 0.4, 0.2, 0.5]$\n- $t=6$: $[0.25, 0.3, 0.6, 0.6]$\n- $t=7$: $[0.2, 0.25, 0.7, 0.55]$\n- $t=8$: $[0.5, 0.3, 0.2, 0.45]$\n- $t=9$: $[0.4, 0.35, 0.25, 0.5]$\n- $t=10$: $[0.15, 0.6, 0.35, 0.65]$\n\n标签 $y_t$，$t = 1, \\dots, 10$：\n- $[0, 0, 1, 1, 1, 2, 2, 0, 1, 2]$\n\n您的程序必须实现上述前向链式评估，并为下面给出的测试套件中的每个参数设置计算 $(A,L)$。\n\n参数设置 $(\\lambda, m)$ 的测试套件：\n- 情况 1：$(\\lambda = 0.5, \\; m = 5)$\n- 情况 2：$(\\lambda = 0.0, \\; m = 5)$\n- 情况 3：$(\\lambda = 10.0, \\; m = 5)$\n- 情况 4：$(\\lambda = 0.1, \\; m = 8)$\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。对于上述顺序中的情况 $i$，输出平均 top-1 准确率 $A_i$，后跟平均负对数似然 $L_i$，两者均四舍五入到六位小数，从而得到一个长度为 $8$ 的扁平列表，顺序为 $[A_1, L_1, A_2, L_2, A_3, L_3, A_4, L_4]$。", "solution": "问题陈述经验证。\n\n### 步骤 1：提取已知信息\n- **时间序列**：流感季节以 $t \\in \\{1, 2, \\dots, T\\}$ 索引，其中 $T=10$。\n- **特征和标签**：特征向量 $\\mathbf{x}_t \\in \\mathbb{R}^d$，其中 $d=4$。主导毒株标签 $y_t \\in \\{0, 1, 2\\}$，因此共有 $K=3$ 种毒株。\n- **模型定义**：\n    - 增广特征向量：$\\tilde{\\mathbf{x}} \\in \\mathbb{R}^{d+1}$，通过在前面添加常数项 $1$ 得到。\n    - 参数矩阵：$\\mathbf{W} \\in \\mathbb{R}^{K \\times (d+1)}$。\n    - 未归一化分数：$\\mathbf{z} = \\mathbf{W}\\tilde{\\mathbf{x}} \\in \\mathbb{R}^K$。\n    - 预测概率 (softmax)：$p_k = \\frac{\\exp(z_k)}{\\sum_{j=1}^{K} \\exp(z_j)}$，其中 $k \\in \\{1, \\dots, K\\}$。\n- **训练目标**：对于具有设计矩阵 $\\mathbf{X} \\in \\mathbb{R}^{n \\times (d+1)}$ 和 one-hot 标签矩阵 $\\mathbf{Y} \\in \\mathbb{R}^{n \\times K}$ 的 $n$ 个训练样本，目标函数为：\n  $$\n  \\mathcal{L}(\\mathbf{W}) = \\sum_{i=1}^{n} \\left\\| \\mathbf{W}\\tilde{\\mathbf{x}}_i - \\mathbf{y}_i \\right\\|_2^2 \\;+\\; \\lambda \\sum_{k=1}^{K} \\sum_{j=2}^{d+1} W_{k,j}^2\n  $$\n  其中 $\\lambda \\ge 0$ 是正则化强度。截距列 $j=1$ 不被正则化。解 $\\mathbf{W}^\\star$ 是 $\\mathcal{L}(\\mathbf{W})$ 的任意一个最小化子。\n- **评估方案**：使用最小训练集大小为 $m$ 的前向链式交叉验证。\n    - 对于每个划分索引 $k \\in \\{m, m+1, \\dots, T-1\\}$：\n        - 在季节 $\\{1, 2, \\dots, k\\}$ 上训练以获得 $\\mathbf{W}^\\star_{(k)}$。\n        - 在季节 $k+1$ 上进行评估。\n    - 预测：$\\hat{y}_{k+1} = \\operatorname*{arg\\,max}_{c \\in \\{0,1,2\\}} p^{(k+1)}_{c+1}$，平局时选择最小的索引 $c$。\n- **性能指标**：\n    - Top-1 正确性指示符：如果 $\\hat{y}_{k+1} = y_{k+1}$，则 $I_{k+1} = 1$，否则 $I_{k+1} = 0$。\n    - 每个划分的负对数似然 (NLL)：$\\ell_{k+1} = -\\log(p^{(k+1)}_{y_{k+1}+1})$。\n    - 平均 top-1 准确率：$A = \\frac{1}{T-m} \\sum_{k=m}^{T-1} I_{k+1}$。\n    - 平均 NLL：$L = \\frac{1}{T-m} \\sum_{k=m}^{T-1} \\ell_{k+1}$。\n- **数据**：$T=10, d=4, K=3$。\n    - 特征 $\\mathbf{x}_t$，$t \\in \\{1, \\dots, 10\\}$：\n      $[0.6, 0.2, 0.1, 0.3], [0.7, 0.1, 0.15, 0.25], [0.2, 0.8, 0.05, 0.4], [0.1, 0.85, 0.1, 0.35], [0.3, 0.4, 0.2, 0.5], [0.25, 0.3, 0.6, 0.6], [0.2, 0.25, 0.7, 0.55], [0.5, 0.3, 0.2, 0.45], [0.4, 0.35, 0.25, 0.5], [0.15, 0.6, 0.35, 0.65]$。\n    - 标签 $y_t$，$t \\in \\{1, \\dots, 10\\}$：$[0, 0, 1, 1, 1, 2, 2, 0, 1, 2]$。\n- **测试套件**：$(\\lambda, m)$ 对：$(0.5, 5)$, $(0.0, 5)$, $(10.0, 5)$, $(0.1, 8)$。\n- **输出格式**：一个扁平列表 $[A_1, L_1, A_2, L_2, A_3, L_3, A_4, L_4]$，值四舍五入到六位小数。\n\n### 步骤 2：使用提取的已知信息进行验证\n该问题具有科学依据，定义明确且客观。它描述了一个标准的机器学习任务：带 $L_2$ 正则化（岭回归）的多输出线性回归，使用平方误差损失进行训练，并使用前向链式交叉验证进行评估。目标函数是凸函数，并且有明确定义的闭式解最小值。所有数据、参数和程序都已明确规定，没有歧义。不存在矛盾、科学不准确性或无法形式化的元素。\n\n### 步骤 3：结论与行动\n问题有效。将提供解答。\n\n### 求解推导\n\n问题的核心是找到参数矩阵 $\\mathbf{W}^\\star$，该矩阵在给定的训练集和正则化强度 $\\lambda$ 下，能够最小化目标函数 $\\mathcal{L}(\\mathbf{W})$。\n\n目标函数为：\n$$\n\\mathcal{L}(\\mathbf{W}) = \\sum_{i=1}^{n} \\left\\| \\mathbf{W}\\tilde{\\mathbf{x}}_i - \\mathbf{y}_i \\right\\|_2^2 \\;+\\; \\lambda \\sum_{k=1}^{K} \\sum_{j=2}^{d+1} W_{k,j}^2\n$$\n令 $\\mathbf{w}_k^\\top$ 为矩阵 $\\mathbf{W} \\in \\mathbb{R}^{K \\times (d+1)}$ 的第 $k$ 行。向量 $\\mathbf{w}_k \\in \\mathbb{R}^{d+1}$ 包含第 $k$ 类的参数。令 $y_{i,k}$ 为 one-hot 编码向量 $\\mathbf{y}_i$ 的第 $k$ 个分量。平方范数可以展开为关于类别的总和：\n$$\n\\left\\| \\mathbf{W}\\tilde{\\mathbf{x}}_i - \\mathbf{y}_i \\right\\|_2^2 = \\sum_{k=1}^{K} (\\mathbf{w}_k^\\top \\tilde{\\mathbf{x}}_i - y_{i,k})^2\n$$\n将此代入目标函数并重新排列求和顺序，可以发现优化问题对每个类别是解耦的：\n$$\n\\mathcal{L}(\\mathbf{W}) = \\sum_{k=1}^{K} \\left( \\sum_{i=1}^{n} (\\mathbf{w}_k^\\top \\tilde{\\mathbf{x}}_i - y_{i,k})^2 + \\lambda \\sum_{j=2}^{d+1} W_{k,j}^2 \\right)\n$$\n这意味着我们可以独立求解每个行向量 $\\mathbf{w}_k$。对于每个类别 $k \\in \\{1, \\dots, K\\}$，我们必须解决一个独立的岭回归问题。令 $\\tilde{\\mathbf{X}} \\in \\mathbb{R}^{n \\times (d+1)}$ 为设计矩阵，其行是 $\\tilde{\\mathbf{x}}_i^\\top$，令 $\\mathbf{y}^{(k)} \\in \\mathbb{R}^n$ 是 one-hot 标签的第 $k$ 个分量组成的向量，即矩阵 $\\mathbf{Y}$ 的第 $k$ 列。$\\mathbf{w}_k$ 的目标函数为：\n$$\n\\mathcal{L}_k(\\mathbf{w}_k) = \\| \\tilde{\\mathbf{X}}\\mathbf{w}_k - \\mathbf{y}^{(k)} \\|_2^2 + \\lambda \\mathbf{w}_k^\\top \\mathbf{I}' \\mathbf{w}_k\n$$\n其中 $\\mathbf{I}'$ 是一个 $(d+1) \\times (d+1)$ 的对角矩阵，其对角线元素为 $I'_{1,1}=0$ 且对于 $j \\in \\{2, \\dots, d+1\\}$ 有 $I'_{j,j}=1$，这强制截距项不被正则化。\n\n这是一个标准的二次型，其最小值可以通过将其关于 $\\mathbf{w}_k$ 的梯度设为零来找到：\n$$\n\\nabla_{\\mathbf{w}_k} \\mathcal{L}_k = 2\\tilde{\\mathbf{X}}^\\top (\\tilde{\\mathbf{X}}\\mathbf{w}_k - \\mathbf{y}^{(k)}) + 2\\lambda\\mathbf{I}'\\mathbf{w}_k = 0\n$$\n$$\n(\\tilde{\\mathbf{X}}^\\top \\tilde{\\mathbf{X}} + \\lambda\\mathbf{I}') \\mathbf{w}_k = \\tilde{\\mathbf{X}}^\\top \\mathbf{y}^{(k)}\n$$\n因此，类别 $k$ 的最优参数向量为：\n$$\n\\mathbf{w}_k^\\star = (\\tilde{\\mathbf{X}}^\\top \\tilde{\\mathbf{X}} + \\lambda\\mathbf{I}')^{-1} \\tilde{\\mathbf{X}}^\\top \\mathbf{y}^{(k)}\n$$\n这个线性系统可以为每个类别 $k=1, 2, 3$ 分别求解。一个更紧凑的计算方式是将这些组合成一个单一的矩阵方程。令 $\\mathbf{W}^\\top = [\\mathbf{w}_1^\\star, \\dots, \\mathbf{w}_K^\\star] \\in \\mathbb{R}^{(d+1) \\times K}$ 并且 $\\mathbf{Y} = [\\mathbf{y}^{(1)}, \\dots, \\mathbf{y}^{(K)}] \\in \\mathbb{R}^{n \\times K}$。然后我们可以一次性求解所有权重向量：\n$$\n\\mathbf{W}^{\\star\\top} = (\\tilde{\\mathbf{X}}^\\top \\tilde{\\mathbf{X}} + \\lambda\\mathbf{I}')^{-1} \\tilde{\\mathbf{X}}^\\top \\mathbf{Y}\n$$\n最终的权重矩阵是 $\\mathbf{W}^\\star = (\\mathbf{W}^{\\star\\top})^\\top$。\n\n总体流程如下：\n1.  对于每个测试用例 $(\\lambda, m)$：\n2.  初始化聚合指标 $A_{\\text{sum}} = 0$ 和 $L_{\\text{sum}} = 0$。\n3.  遍历前向链式划分，索引 $k$ 从 $m$ 到 $T-1$。\n    a.  使用季节 $t=1, \\dots, k$ 的数据构建训练集。这给出了设计矩阵 $\\tilde{\\mathbf{X}}$ 和 one-hot 目标矩阵 $\\mathbf{Y}$。训练样本数量为 $n=k$。\n    b.  使用季节 $t=k+1$ 的数据构建测试集。这给出了向量 $\\tilde{\\mathbf{x}}_{k+1}$ 和标签 $y_{k+1}$。\n    c.  使用上面推导的闭式解计算最优权重矩阵 $\\mathbf{W}^\\star_{(k)}$。\n    d.  对于测试样本 $\\tilde{\\mathbf{x}}_{k+1}$，计算分数 $\\mathbf{z} = \\mathbf{W}^\\star_{(k)} \\tilde{\\mathbf{x}}_{k+1}$。\n    e.  使用 softmax 函数计算概率向量 $\\mathbf{p}$。为保持数值稳定性，我们使用变换 $p_c = \\exp(z_c - \\max(\\mathbf{z})) / \\sum_j \\exp(z_j - \\max(\\mathbf{z}))$。\n    f.  确定预测类别 $\\hat{y}_{k+1} = \\operatorname*{arg\\,max}_{c \\in \\{0,1,2\\}} p_{c+1}$。\n    g.  计算正确性指示符 $I_{k+1}$ 和负对数似然 $\\ell_{k+1} = -\\log(p_{y_{k+1}+1})$。\n    h.  将这些值加到运行总和 $A_{\\text{sum}}$ 和 $L_{\\text{sum}}$ 中。\n4.  循环结束后，计算平均准确率 $A = A_{\\text{sum}} / (T-m)$ 和平均负对数似然 $L = L_{\\text{sum}} / (T-m)$。\n5.  为当前测试用例存储对 $(A, L)$。\n6.  最后，按规定格式化所有结果值并打印。\n\n该算法直接实现了指定的过程，并利用推导出的解析解进行模型训练。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the forward-chaining cross-validation for a linear probabilistic model\n    and computes mean accuracy and mean negative log-likelihood.\n    \"\"\"\n    \n    # Data from the problem statement\n    # T = 10, d = 4, K = 3\n    T = 10\n    d = 4\n    K = 3\n\n    # Feature vectors x_t for t = 1, ..., 10\n    features = np.array([\n        [0.6, 0.2, 0.1, 0.3],     # t=1\n        [0.7, 0.1, 0.15, 0.25],  # t=2\n        [0.2, 0.8, 0.05, 0.4],   # t=3\n        [0.1, 0.85, 0.1, 0.35],  # t=4\n        [0.3, 0.4, 0.2, 0.5],    # t=5\n        [0.25, 0.3, 0.6, 0.6],   # t=6\n        [0.2, 0.25, 0.7, 0.55],  # t=7\n        [0.5, 0.3, 0.2, 0.45],   # t=8\n        [0.4, 0.35, 0.25, 0.5],  # t=9\n        [0.15, 0.6, 0.35, 0.65]   # t=10\n    ])\n\n    # Labels y_t for t = 1, ..., 10\n    labels = np.array([0, 0, 1, 1, 1, 2, 2, 0, 1, 2])\n\n    # Augment feature vectors by prepending a constant term of 1\n    aug_features = np.hstack([np.ones((T, 1)), features])\n\n    # Test suite of parameter settings (lambda, m)\n    test_cases = [\n        (0.5, 5),   # Case 1\n        (0.0, 5),   # Case 2\n        (10.0, 5),  # Case 3\n        (0.1, 8)    # Case 4\n    ]\n\n    # Regularization matrix I' (does not regularize the intercept)\n    I_prime = np.diag([0.0] + [1.0] * d)\n    \n    results = []\n\n    for lam, m in test_cases:\n        total_I = 0.0\n        total_L = 0.0\n        \n        # Number of splits for forward-chaining CV\n        num_splits = T - m\n        \n        # Iterate through splits k = m, m+1, ..., T-1\n        # In 0-based indexing, this corresponds to training on [0..k-1] and testing on [k].\n        # The problem uses 1-based indexing for seasons, so season k is at index k-1.\n        # Training on {1..k} -> indices {0..k-1}. Test on {k+1} -> index {k}.\n        # Split index k in problem goes from m to T-1.\n        for k_split_idx in range(m, T):\n            # n is the number of training samples for the current split\n            n_train = k_split_idx\n            train_indices = np.arange(n_train)\n            test_index = k_split_idx\n\n            # Construct training data\n            X_train_aug = aug_features[train_indices, :]\n            y_train_raw = labels[train_indices]\n\n            # One-hot encode training labels\n            Y_train_onehot = np.zeros((n_train, K))\n            Y_train_onehot[np.arange(n_train), y_train_raw] = 1.0\n\n            # Construct test data\n            x_test_aug = aug_features[test_index, :]\n            y_test = labels[test_index]\n\n            # Solve for W using the closed-form solution\n            # (X_T * X + lambda * I') * w = X_T * y\n            XTX = X_train_aug.T @ X_train_aug\n            M = XTX + lam * I_prime\n            \n            # Use numpy's solver. For small matrices, inv is fine.\n            M_inv = np.linalg.inv(M)\n            \n            # W_T = (d+1) x K matrix where columns are the weight vectors\n            W_T = M_inv @ X_train_aug.T @ Y_train_onehot\n            \n            # W is K x (d+1), rows correspond to classes\n            W = W_T.T\n\n            # Predict on the test sample\n            # z = W * x_test_aug\n            z = W @ x_test_aug\n\n            # Compute probabilities using numerically stable softmax\n            z_shifted = z - np.max(z)\n            exps = np.exp(z_shifted)\n            p = exps / np.sum(exps)\n            \n            # Predicted class (arg max)\n            y_pred = np.argmax(p)\n            \n            # Calculate metrics for this split\n            I_k = 1.0 if y_pred == y_test else 0.0\n            # NLL: -log(probability of true class)\n            # Add a small epsilon to log to prevent log(0) if p[y_test] is numerically zero\n            epsilon = 1e-15\n            l_k = -np.log(p[y_test] + epsilon)\n            \n            total_I += I_k\n            total_L += l_k\n\n        # Compute mean metrics over all splits\n        mean_A = total_I / num_splits\n        mean_L = total_L / num_splits\n        \n        results.extend([mean_A, mean_L])\n\n    # Format the final output string\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2406492"}]}