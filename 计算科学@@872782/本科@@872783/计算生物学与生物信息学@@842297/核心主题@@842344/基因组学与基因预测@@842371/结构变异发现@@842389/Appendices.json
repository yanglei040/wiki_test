{"hands_on_practices": [{"introduction": "在结构变异检测中，成对末端测序读数是最基本但也是最强大的信息来源之一。通过分析读数对在参考基因组上的比对方向和距离，我们可以推断出样本基因组中潜在的缺失或插入事件。本练习将指导您基于成对末端读数的两个关键特征——比对方向和推断的插入片段大小——构建一个决策算法，以区分大的基因组缺失和新颖的逆转录转座子插入。这是一个将生物学原理转化为具体计算逻辑的基础训练，能有效培养您解读测序数据特征的直觉。[@problem_id:2431909]", "problem": "给定一个基于双末端测序（paired-end sequencing）用于结构变异发现的决策问题。考虑一个 DNA 测序文库，其中正确配对的读段（read）的物理片段长度（插入片段大小）分布近似为高斯分布，其均值为 $\\mu$ 个碱基对（bp），标准差为 $\\sigma$ 个碱基对（bp）。在某个基因组位点，你观察到双末端测序比对结果，其特征由以下两个可观察量决定：(i) 每个比对上的读段对相对于参考基因组的方向（类别：FR, RF, FF, RR），以及 (ii) 对于 FR 方向的读段对，其两条读段在参考基因组上比对的距离（即比对插入片段大小）。你的任务是仅使用这两个可观察量，为每个位点判断其证据更符合样本相对于参考基因组存在一个大片段缺失（输出整数 $0$），还是更符合样本相对于参考基因组存在一个新的逆转录转座子插入（输出整数 $1$）。\n\n定义和假设：\n- 双末端（Paired-End, PE）测序产生读段对。FR 方向表示一种朝向彼此的构型，这是标准 Illumina 方案下预期的正确配对方向；RF、FF 和 RR 表示朝向外侧或同向的构型，被认为是与文库预期方向不一致的（discordant）。\n- 样本相对于参考基因组的大片段缺失倾向于产生富集的 FR 配对，其在参考基因组上的比对插入片段大小随机地大于以 $\\mu$ 和 $\\sigma$ 为特征的文库分布，同时 FR 仍然是局部的主要方向。\n- 样本相对于参考基因组的新逆转录转座子插入倾向于产生富集的非 FR 方向（RF, FF, RR）以及 FR 配对，其在参考基因组上的比对插入片段大小随机地小于以 $\\mu$ 和 $\\sigma$ 为特征的文库分布。\n\n每个测试用例的输入规范：\n- 文库参数 $\\mu$ 和 $\\sigma$（单位均为 bp）。\n- 在位点周围的固定窗口内测得的方向计数 $c_{\\mathrm{FR}}$、$c_{\\mathrm{RF}}$、$c_{\\mathrm{FF}}$、$c_{\\mathrm{RR}}$。\n- 在该位点观察到的 FR 方向读段对子集的比对插入片段大小列表（单位为 bp）。\n\n输出规范：\n- 对每个测试用例，输出一个整数：如果位点被分类为缺失，则输出 $0$；如果被分类为新的逆转录转座子插入，则输出 $1$。\n- 你的程序应生成单行输出，包含所有测试用例的结果，格式为方括号内由逗号分隔的列表，且无空格，例如：`\"[0,1,1,0]\"`。\n\n测试套件：\n- 测试用例 $1$：\n  - $\\mu = 350$, $\\sigma = 50$。\n  - $c_{\\mathrm{FR}} = 40$, $c_{\\mathrm{RF}} = 1$, $c_{\\mathrm{FF}} = 0$, $c_{\\mathrm{RR}} = 0$。\n  - FR 插入片段大小：$\\{520,540,560,590,610\\}$。\n- 测试用例 $2$：\n  - $\\mu = 350$, $\\sigma = 50$。\n  - $c_{\\mathrm{FR}} = 10$, $c_{\\mathrm{RF}} = 25$, $c_{\\mathrm{FF}} = 5$, $c_{\\mathrm{RR}} = 3$。\n  - FR 插入片段大小：$\\{150,160,170,180,190,200,210\\}$。\n- 测试用例 $3$：\n  - $\\mu = 350$, $\\sigma = 50$。\n  - $c_{\\mathrm{FR}} = 22$, $c_{\\mathrm{RF}} = 2$, $c_{\\mathrm{FF}} = 1$, $c_{\\mathrm{RR}} = 1$。\n  - FR 插入片段大小：$\\{410,430,420,380,370\\}$。\n- 测试用例 $4$：\n  - $\\mu = 400$, $\\sigma = 40$。\n  - $c_{\\mathrm{FR}} = 8$, $c_{\\mathrm{RF}} = 30$, $c_{\\mathrm{FF}} = 4$, $c_{\\mathrm{RR}} = 2$。\n  - FR 插入片段大小：$\\{260,280,300,310\\}$。\n- 测试用例 $5$：\n  - $\\mu = 300$, $\\sigma = 30$。\n  - $c_{\\mathrm{FR}} = 15$, $c_{\\mathrm{RF}} = 14$, $c_{\\mathrm{FF}} = 3$, $c_{\\mathrm{RR}} = 3$。\n  - FR 插入片段大小：$\\{200,210,190,205,195\\}$。\n\n最终输出格式：\n- 你的程序必须为上述每个测试用例计算一个分类，并打印单行结果，格式为方括号内由逗号分隔的整数列表，且无空格，例如：`\"[0,1,0,1,1]\"`。", "solution": "该问题已经过验证，被确定为具有科学依据、定义明确且客观。它提出了一个计算生物学领域的标准二元分类任务，具体而言是利用双末端 DNA 测序数据分析结构变异。\n\n任务是将一个基因组位点分类为相对于参考基因组包含大片段缺失（输出 $0$）或新的逆转录转座子插入（输出 $1$）。我们被提供了两类证据来进行此决策：\n$1$. 相对于参考基因组的不同方向的读段对计数：朝向彼此的（$c_{\\mathrm{FR}}$）和不一致方向的（$c_{\\mathrm{RF}}$, $c_{\\mathrm{FF}}$, $c_{\\mathrm{RR}}$）。\n$2$. 在 FR 方向观察到的 $n$ 个读段对子集的比对插入片段大小样本，$\\{x_1, x_2, \\ldots, x_n\\}$。\n这些观察结果需要在特定测序文库的背景下进行解释，该文库中正确配对的读段呈现出物理片段长度分布为均值为 $\\mu$、标准差为 $\\sigma$ 的高斯分布。\n\n决策算法直接源于问题陈述中描述的两种相互排斥的基因组特征的形式化。\n\n**假设 $H_0$：大片段缺失**\n大片段缺失的特征由两种同时发生的现象描述：\n- **方向证据：** FR 方向的配对富集，FR 仍是主要方向。形式化表示为 FR 配对的计数超过所有非 FR（不一致）配对的总数。\n$$c_{\\mathrm{FR}} > c_{\\mathrm{RF}} + c_{\\mathrm{FF}} + c_{\\mathrm{RR}}$$\n- **插入片段大小证据：** FR 配对的比对插入片段大小随机地大于文库的物理片段长度分布。这是因为跨越样本基因组中缺失区域的读段会比对到参考基因组上相距较远的位置，从而人为地产生了较大的比对插入片段大小。这通过比较观察到的 FR 插入片段大小的样本均值 $\\bar{x}_{\\mathrm{FR}}$ 与文库均值 $\\mu$ 来形式化。\n$$ \\bar{x}_{\\mathrm{FR}} = \\frac{1}{n} \\sum_{i=1}^{n} x_i > \\mu $$\n\n**假设 $H_1$：新的逆转录转座子插入**\n新的逆转录转座子插入的特征由与缺失显著不同的现象描述：\n- **方向证据：** 非 FR 方向的富集。发生这种情况是因为跨越插入位点的读段对中，一条读段比对到侧翼的基因组序列，而另一条读段比对到基因组其他地方的逆转录转座子的不同拷贝上，从而导致不一致的方向。形式化表示为 FR 配对的计数不超过非 FR 配对的计数。\n$$c_{\\mathrm{FR}} \\le c_{\\mathrm{RF}} + c_{\\mathrm{FF}} + c_{\\mathrm{RR}}$$\n- **插入片段大小证据：** FR 配对的比对插入片段大小随机地小于文库的分布。这适用于完全包含在新插入片段内部的片段对，当它们被比对回单拷贝的参考序列时，看起来像是源于比实际更小的片段。形式化表示为：\n$$ \\bar{x}_{\\mathrm{FR}}  \\mu $$\n\n**决策规则**\n该问题要求进行决定性的分类。对缺失特征的描述意味着其两个证据成分的逻辑合取。一个位点当且仅当其方向证据和插入片段大小证据都与缺失一致时，才被分类为缺失。鉴于这是一个在两个明确定义的备选项之间的二元分类任务，任何不满足缺失严格标准的情况因此被分类为插入。这导出了以下稳健且完备的决策规则：\n\n如果以下两个条件都为真，则位点被分类为**缺失（输出 $0$）**：\n$1$. $c_{\\mathrm{FR}} > (c_{\\mathrm{RF}} + c_{\\mathrm{FF}} + c_{\\mathrm{RR}})$\n$2$. $\\bar{x}_{\\mathrm{FR}} > \\mu$\n\n否则，该位点被分类为**新的逆转录转座子插入（输出 $1$）**。\n\n这个逻辑框架对于所有提供的测试用例都是充分的，因为没有一个案例表现出矛盾的证据（例如，FR 占主导但插入片段大小却小于平均值）。使用更复杂的模型，例如结合标准差 $\\sigma$ 来计算 Z-scores 或似然值，将需要关于不同证据类型相对权重的额外假设，而这些假设在问题陈述中并未提供。所选算法代表了对所述问题最直接且科学上合理的解释。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the structural variant classification problem based on paired-end sequencing data.\n    \"\"\"\n    \n    # Test cases defined in the problem statement.\n    test_cases = [\n        # (mu, sigma, c_fr, c_rf, c_ff, c_rr, fr_sizes)\n        (350, 50, 40, 1, 0, 0, [520, 540, 560, 590, 610]),\n        (350, 50, 10, 25, 5, 3, [150, 160, 170, 180, 190, 200, 210]),\n        (350, 50, 22, 2, 1, 1, [410, 430, 420, 380, 370]),\n        (400, 40, 8, 30, 4, 2, [260, 280, 300, 310]),\n        (300, 30, 15, 14, 3, 3, [200, 210, 190, 205, 195]),\n    ]\n\n    results = []\n    for case in test_cases:\n        mu, _, c_fr, c_rf, c_ff, c_rr, fr_sizes = case\n        \n        # Calculate the total count of non-FR (discordant) read pairs.\n        c_non_fr = c_rf + c_ff + c_rr\n        \n        # Calculate the sample mean of the FR insert sizes.\n        # Handle the edge case of an empty list of FR sizes, though not present in tests.\n        if not fr_sizes:\n            # If no FR sizes are available, the insert size criterion cannot be tested.\n            # The decision rule defaults to 'insertion' as the strict 'deletion' criteria cannot be met.\n            x_bar_fr = -np.inf # Ensures the comparison 'x_bar_fr  mu' is false.\n        else:\n            x_bar_fr = np.mean(fr_sizes)\n        \n        # A deletion signature requires FR orientation to be predominant AND\n        # the mean FR insert size to be larger than the library mean.\n        is_deletion_signature = (c_fr  c_non_fr) and (x_bar_fr  mu)\n        \n        if is_deletion_signature:\n            # Output 0 for a deletion.\n            results.append(0)\n        else:\n            # Otherwise, classify as an insertion (output 1).\n            # This covers cases where orientation or insert size (or both)\n            # are consistent with an insertion signature.\n            results.append(1)\n\n    # Print the final results in the specified format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2431909"}, {"introduction": "虽然裂读（split-read）比对是精确定位结构变异断点的关键证据，但它们也很容易受到基因组中重复序列的干扰，从而产生大量的假阳性信号。为了区分真正的变异信号和比对假象，我们需要对证据的可靠性进行量化评估。本练习将引导您实现一个评分函数，该函数综合了两个核心指标：代表序列复杂度的香农熵（Shannon entropy）和代表比对置信度的Phred质量分。通过这个实践，您将学会如何运用信息论和统计学概念来过滤数据噪声，这是所有生物信息学分析流程中至关重要的一步。[@problem_id:2431938]", "problem": "给定一个分数的正式定义，该分数使用两个比对上的读段的脱氧核糖核酸（DNA）序列复杂度和它们的比对质量，来量化据称支持基因组倒位的裂读比对的可靠性。DNA字母表仅限于符号集合 {A, C, G, T}。对于每个裂读比对，都有两个侧翼（左侧和右侧），它们具有相应的序列和Phred标度的比对质量。\n\n对于一个长度为 $n$ 的DNA序列 $s$，其单核苷酸计数为 $c_A$、$c_C$、$c_G$、$c_T$，满足 $c_A + c_C + c_G + c_T = n$，定义经验碱基频率为 $p_b = c_b / n$，其中 $b \\in \\{A,C,G,T\\}$。定义以比特为单位的香农熵为\n$$\nH(s) = - \\sum_{b \\in \\{A,C,G,T\\}} p_b \\log_2 p_b,\n$$\n约定当 $p_b = 0$ 时，该项贡献为 $0$。定义归一化熵为\n$$\nh(s) = \\frac{H(s)}{\\log_2 4} = \\frac{H(s)}{2},\n$$\n使得 $h(s) \\in [0,1]$。\n\n设左侧翼和右侧翼的序列分别为 $s_L$ 和 $s_R$，Phred标度的比对质量分别为 $Q_L$ 和 $Q_R$。使用以下公式将每个比对质量 $Q$ 转换为正确比对的概率：\n$$\nP(Q) = 1 - 10^{-Q/10}.\n$$\n\n定义综合可靠性分数为\n$$\nS(s_L,s_R,Q_L,Q_R) = \\min\\{ h(s_L), h(s_R) \\} \\times \\min\\{ P(Q_L), P(Q_R) \\}.\n$$\n\n给定一个决策阈值 $\\tau$，当且仅当 $S \\ge \\tau$ 时，将一个裂读比对分类为真正的倒位支持信号，否则分类为比对假象，从而产生一个布尔结果。\n\n实现一个程序，对以下测试套件，使用阈值 $\\tau = 0.7$ 计算每种情况的布尔分类：\n\n- 情况1：$s_L=$ \"ACGTACGTACGT\", $s_R=$ \"TGCATGCATGCA\", $Q_L = 40$, $Q_R = 42$。\n- 情况2：$s_L=$ \"ATATATATATAT\", $s_R=$ \"ATATATATATAT\", $Q_L = 10$, $Q_R = 10$。\n- 情况3：$s_L=$ \"GATTACAGATTACA\", $s_R=$ \"TCGATCGATCGA\", $Q_L = 35$, $Q_R = 5$。\n- 情况4：$s_L=$ \"AAAAAAAAAAAA\", $s_R=$ \"ACGTACGTACGT\", $Q_L = 60$, $Q_R = 60$。\n- 情况5：$s_L=$ \"CG\", $s_R=$ \"CG\", $Q_L = 20$, $Q_R = 20$。\n- 情况6：$s_L=$ \"ACGTACGT\", $s_R=$ \"GTACGTAC\", $Q_L = 20$, $Q_R = 20$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序与上述情况相同。例如，一个有效的输出格式是“[True,False,True]”。输出必须精确包含对应于情况1到6的六个布尔值。", "solution": "首先对问题陈述进行严格验证。\n\n步骤1：提取已知信息\n问题提供了以下定义和数据：\n- DNA字母表：$\\Sigma = \\{A, C, G, T\\}$。\n- 对于长度为 $n$ 的序列 $s$，其单核苷酸计数为 $c_A, c_C, c_G, c_T$，使得 $\\sum_{b \\in \\Sigma} c_b = n$。\n- 经验碱基频率：$p_b = c_b / n$，其中 $b \\in \\Sigma$。\n- 以比特为单位的香农熵：$H(s) = - \\sum_{b \\in \\Sigma} p_b \\log_2 p_b$，其中 $0 \\log_2 0 = 0$。\n- 归一化熵：$h(s) = H(s) / \\log_2 4 = H(s) / 2$，其中 $h(s) \\in [0,1]$。\n- 左侧翼和右侧翼序列：$s_L, s_R$。\n- Phred标度的比对质量：$Q_L, Q_R$。\n- 正确比对的概率：$P(Q) = 1 - 10^{-Q/10}$。\n- 综合可靠性分数：$S(s_L, s_R, Q_L, Q_R) = \\min\\{ h(s_L), h(s_R) \\} \\times \\min\\{ P(Q_L), P(Q_R) \\}$。\n- 决策阈值：$\\tau = 0.7$。\n- 分类规则：如果 $S \\ge \\tau$，则为True，否则为False。\n- 测试用例：\n    1. $s_L=$ \"ACGTACGTACGT\", $s_R=$ \"TGCATGCATGCA\", $Q_L = 40$, $Q_R = 42$。\n    2. $s_L=$ \"ATATATATATAT\", $s_R=$ \"ATATATATATAT\", $Q_L = 10$, $Q_R = 10$。\n    3. $s_L=$ \"GATTACAGATTACA\", $s_R=$ \"TCGATCGATCGA\", $Q_L = 35$, $Q_R = 5$。\n    4. $s_L=$ \"AAAAAAAAAAAA\", $s_R=$ \"ACGTACGTACGT\", $Q_L = 60$, $Q_R = 60$。\n    5. $s_L=$ \"CG\", $s_R=$ \"CG\", $Q_L = 20$, $Q_R = 20$。\n    6. $s_L=$ \"ACGTACGT\", $s_R=$ \"GTACGTAC\", $Q_L = 20$, $Q_R = 20$。\n\n步骤2：使用提取的已知信息进行验证\n根据指定标准对问题进行评估。\n- **科学依据充分**：该问题具有良好的科学基础。它采用了信息论（香农熵）和生物信息学（Phred质量分数，序列复杂度）的标准定义。所提出的可靠性分数是评估结构变异证据的一种合乎逻辑的（尽管简化的）启发式方法。它不含伪科学。\n- **适定性良好**：该问题是适定的。所有数学关系都已明确定义。测试套件的所有常数和输入数据都已提供。每个案例都期望一个唯一的布尔输出。\n- **客观性**：该问题以客观、数学精确的方式陈述。没有主观或含糊的术语。\n\n该问题没有表现出科学上不健全、不可形式化、不完整、矛盾、不可行或结构不良等缺陷。\n\n步骤3：结论与行动\n该问题被认定为**有效**。将提供一个解决方案。\n\n该解决方案要求实现一个基于综合可靠性分数 $S$ 的分类程序。必须为六个测试用例中的每一个计算该分数，并与决策阈值 $\\tau = 0.7$ 进行比较。\n\n分数 $S$ 的计算由两个主要部分组成：由归一化熵 $h(s)$ 衡量的序列复杂度，以及由正确比对概率 $P(Q)$ 衡量的比对可靠性。\n\n首先，我们定义归一化熵 $h(s)$ 的计算。对于给定长度为 $n$ 的序列 $s$，我们计算每个碱基 $b \\in \\{A, C, G, T\\}$ 的出现次数 $c_b$。频率为 $p_b = c_b/n$。香农熵则为 $H(s) = - \\sum p_b \\log_2 p_b$。对于一个DNA序列，当所有四个碱基出现的可能性均等时（$p_b=0.25$），熵达到最大值，得到 $H_{max} = \\log_2 4 = 2$ 比特。通过这个最大值进行归一化，得到 $h(s) = H(s)/2$，这将复杂度映射到区间 $[0,1]$。$h(s)=0$ 的值对应于均聚物（例如“AAAA”），代表最低复杂度。$h(s)=1$ 的值对应于具有均匀碱基分布的序列，代表最高复杂度。\n\n其次，我们定义比对概率 $P(Q)$ 的计算。Phred标度的质量分数 $Q$ 与错误概率 $P_{error}$ 呈对数关系。具体来说，$Q = -10 \\log_{10} P_{error}$，这意味着 $P_{error} = 10^{-Q/10}$。因此，正确比对的概率为 $P(Q) = 1 - P_{error} = 1 - 10^{-Q/10}$。\n\n综合分数 $S$ 结合了这两个指标：$S = \\min\\{h(s_L), h(s_R)\\} \\times \\min\\{P(Q_L), P(Q_R)\\}$。这种表述是保守的；最终分数受限于具有较低序列复杂度的侧翼和具有较低比对质量的侧翼。如果 $S \\ge \\tau$，则一个比对被分类为真实信号。\n\n现在我们将此程序应用于每个案例，其中 $\\tau = 0.7$。\n\n情况1：$s_L=$ \"ACGTACGTACGT\", $s_R=$ \"TGCATGCATGCA\", $Q_L = 40$, $Q_R = 42$。\n- 对于 $s_L$ 和 $s_R$，$n=12$ 且 $c_A=c_C=c_G=c_T=3$。因此，对于所有碱基，$p_b = 3/12 = 0.25$。\n- $H(s_L) = H(s_R) = -4 \\times (0.25 \\log_2 0.25) = -4 \\times (0.25 \\times -2) = 2$。\n- $h(s_L) = h(s_R) = 2/2 = 1$。$\\min\\{h\\} = 1$。\n- $P(Q_L) = 1 - 10^{-40/10} = 1 - 10^{-4} = 0.9999$。\n- $P(Q_R) = 1 - 10^{-42/10} = 1 - 10^{-4.2} \\approx 0.999937$。\n- $\\min\\{P\\} = 0.9999$。\n- $S = 1 \\times 0.9999 = 0.9999$。\n- $0.9999 \\ge 0.7$。分类：**True**。\n\n情况2：$s_L=$ \"ATATATATATAT\", $s_R=$ \"ATATATATATAT\", $Q_L = 10$, $Q_R = 10$。\n- 对于两个序列，$n=12$, $c_A=6, c_T=6$。$p_A=p_T=0.5$。\n- $H(s_L) = H(s_R) = -2 \\times (0.5 \\log_2 0.5) = -2 \\times (0.5 \\times -1) = 1$。\n- $h(s_L) = h(s_R) = 1/2 = 0.5$。$\\min\\{h\\} = 0.5$。\n- $P(Q_L) = P(Q_R) = 1 - 10^{-10/10} = 1 - 0.1 = 0.9$。$\\min\\{P\\} = 0.9$。\n- $S = 0.5 \\times 0.9 = 0.45$。\n- $0.45  0.7$。分类：**False**。\n\n情况3：$s_L=$ \"GATTACAGATTACA\", $s_R=$ \"TCGATCGATCGA\", $Q_L = 35$, $Q_R = 5$。\n- 对于 $s_L$，$n=14$, $c_A=6, c_C=2, c_G=2, c_T=4$。频率：$p_A=6/14, p_C=2/14, p_G=2/14, p_T=4/14$。\n- $H(s_L) \\approx -(\\frac{6}{14}\\log_2\\frac{6}{14} + \\frac{2}{14}\\log_2\\frac{2}{14} + \\frac{2}{14}\\log_2\\frac{2}{14} + \\frac{4}{14}\\log_2\\frac{4}{14}) \\approx 1.8423$。\n- $h(s_L) \\approx 1.8423 / 2 \\approx 0.9212$。\n- 对于 $s_R$，$n=12$，所有碱基的 $p_b = 0.25$，所以 $h(s_R)=1$。\n- $\\min\\{h\\} \\approx 0.9212$。\n- $P(Q_L) = 1 - 10^{-35/10} = 1 - 10^{-3.5} \\approx 0.9997$。\n- $P(Q_R) = 1 - 10^{-5/10} = 1 - 10^{-0.5} \\approx 0.6838$。\n- $\\min\\{P\\} \\approx 0.6838$。\n- $S \\approx 0.9212 \\times 0.6838 \\approx 0.6299$。\n- $0.6299  0.7$。分类：**False**。\n\n情况4：$s_L=$ \"AAAAAAAAAAAA\", $s_R=$ \"ACGTACGTACGT\", $Q_L = 60$, $Q_R = 60$。\n- 对于 $s_L$，一个均聚物，$p_A=1$ 且其他 $p_b=0$。\n- $H(s_L) = -(1 \\log_2 1) = 0$。$h(s_L) = 0$。\n- 对于 $s_R$，$p_b=0.25$，所以 $h(s_R)=1$。\n- $\\min\\{h\\} = 0$。\n- $S = 0 \\times \\min\\{P(60), P(60)\\} = 0$。\n- $0  0.7$。分类：**False**。\n\n情况5：$s_L=$ \"CG\", $s_R=$ \"CG\", $Q_L = 20$, $Q_R = 20$。\n- 对于两个序列，$n=2, c_C=1, c_G=1$。$p_C=p_G=0.5$。\n- 在频率方面与情况2类似：$H(s_{L,R})=1$, $h(s_{L,R})=0.5$。\n- $\\min\\{h\\} = 0.5$。\n- $P(Q_{L,R}) = 1 - 10^{-20/10} = 1 - 10^{-2} = 0.99$。$\\min\\{P\\}=0.99$。\n- $S = 0.5 \\times 0.99 = 0.495$。\n- $0.495  0.7$。分类：**False**。\n\n情况6：$s_L=$ \"ACGTACGT\", $s_R=$ \"GTACGTAC\", $Q_L = 20$, $Q_R = 20$。\n- 对于两个序列，$n=8, c_A=c_C=c_G=c_T=2$。$p_b=2/8=0.25$。\n- 在频率方面与情况1类似：$H(s_{L,R})=2$, $h(s_{L,R})=1$。\n- $\\min\\{h\\} = 1$。\n- $P(Q_{L,R}) = 1 - 10^{-20/10} = 0.99$。$\\min\\{P\\}=0.99$。\n- $S = 1 \\times 0.99 = 0.99$。\n- $0.99 \\ge 0.7$。分类：**True**。\n\n最终结果是：[True, False, False, False, False, True]。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom collections import Counter\n\ndef calculate_normalized_entropy(s: str) - float:\n    \"\"\"\n    Calculates the normalized Shannon entropy for a DNA sequence.\n    The entropy is normalized by log2(4) = 2.\n    \"\"\"\n    n = len(s)\n    if n == 0:\n        return 0.0\n\n    counts = Counter(s)\n    dna_bases = {'A', 'C', 'G', 'T'}\n    entropy = 0.0\n    \n    for base in dna_bases:\n        count = counts.get(base, 0)\n        if count  0:\n            p_b = count / n\n            entropy -= p_b * np.log2(p_b)\n    \n    # Normalize by log2(4), which is 2.\n    h_s = entropy / 2.0\n    return h_s\n\ndef calculate_mapping_probability(Q: int) - float:\n    \"\"\"\n    Converts a Phred-scaled mapping quality score to a probability of correct mapping.\n    \"\"\"\n    # The problem specifies Q as an integer (from the test cases), so we can treat it as such.\n    return 1.0 - 10**(-float(Q) / 10.0)\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test suite and prints the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (s_L, s_R, Q_L, Q_R).\n    test_cases = [\n        (\"ACGTACGTACGT\", \"TGCATGCATGCA\", 40, 42),\n        (\"ATATATATATAT\", \"ATATATATATAT\", 10, 10),\n        (\"GATTACAGATTACA\", \"TCGATCGATCGA\", 35, 5),\n        (\"AAAAAAAAAAAA\", \"ACGTACGTACGT\", 60, 60),\n        (\"CG\", \"CG\", 20, 20),\n        (\"ACGTACGT\", \"GTACGTAC\", 20, 20),\n    ]\n\n    # The decision threshold tau.\n    tau = 0.7\n    \n    results = []\n    \n    for s_L, s_R, Q_L, Q_R in test_cases:\n        # Calculate normalized entropies for left and right flanks.\n        h_L = calculate_normalized_entropy(s_L)\n        h_R = calculate_normalized_entropy(s_R)\n        \n        # Calculate mapping probabilities for left and right flanks.\n        P_L = calculate_mapping_probability(Q_L)\n        P_R = calculate_mapping_probability(Q_R)\n        \n        # Determine the minimum of each pair of metrics.\n        min_h = min(h_L, h_R)\n        min_P = min(P_L, P_R)\n        \n        # Calculate the composite reliability score S.\n        S = min_h * min_P\n        \n        # Classify the alignment based on the threshold tau.\n        classification = S = tau\n        results.append(classification)\n\n    # Final print statement in the exact required format.\n    # The str() of a bool in Python is 'True' or 'False'.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2431938"}, {"introduction": "除了断点证据，读数深度（read depth）的区域性变化是检测大尺度结构变异（特别是拷贝数变异，CNV）的有力信号。然而，测序过程本身会引入随机噪声，使得从原始读数深度信号中直接判断拷贝数变得困难。本练习将向您介绍一种强大的统计工具——隐马尔可夫模型（Hidden Markov Model, HMM），用于从带噪声的读数深度数据中推断最可能的拷贝数状态序列。您将通过实现经典的维特比（Viterbi）算法，亲身体验如何运用动态规划来解决这一生物学问题，这对于理解现代基因组学中的许多建模方法至关重要。[@problem_id:2431910]", "problem": "给定一个用于结构变异发现的读数深度信号生成模型，其中每个基因组窗口的隐藏状态是绝对拷贝数。该模型是一个隐马尔可夫模型（HMM），其隐藏状态空间是绝对拷贝数集合 $\\{0,1,2,\\ldots,8\\}$，发射是固定大小的连续基因组窗口的归一化读数深度。任务是为每个提供的观测序列，确定在该模型下最大化后验概率的隐藏状态序列。\n\n模型说明：\n- 隐藏状态空间： $\\mathcal{C}=\\{0,1,2,\\ldots,8\\}$。\n- 窗口 $t$ 处的观测值：一个实数 $D_t \\in \\mathbb{R}$，表示归一化的读数深度。\n- $c \\in \\mathcal{C}$ 上的初始分布 $\\pi(c)$：\n  $$\\pi(c) \\propto \\exp\\!\\left(-\\beta\\,(c-c_0)^2\\right), \\quad \\text{参数为 } \\beta=1.0 \\text{ 和 } c_0=2,$$\n  经过归一化，使得 $\\sum_{c \\in \\mathcal{C}} \\pi(c) = 1$。\n- 从 $i \\in \\mathcal{C}$ 到 $j \\in \\mathcal{C}$ 的转移概率 $T(i,j)$ 由未归一化的权重定义\n  $$w(i,j)=\\begin{cases}\n  \\kappa  \\text{若 } j=i,\\\\\n  \\exp\\!\\left(-\\gamma \\,\\lvert j-i \\rvert \\right)  \\text{若 } j \\neq i,\n  \\end{cases}$$\n  参数为 $\\kappa=20.0$ 和 $\\gamma=\\ln 2$。那么，行随机的转移概率为\n  $$T(i,j)=\\frac{w(i,j)}{\\sum\\limits_{j' \\in \\mathcal{C}} w(i,j')}.$$\n- 给定状态 $c$ 时观测值 $d$ 的发射密度是高斯（正态）分布，其均值与拷贝数成正比：\n  $$f(d \\mid c) = \\frac{1}{\\sigma \\sqrt{2\\pi}}\\exp\\!\\left(-\\frac{(d-\\mu_c)^2}{2\\sigma^2}\\right), \\quad \\mu_c = \\frac{c}{2}, \\quad \\sigma = 0.15.$$\n\n对于一个观测序列 $D_{1:n}=(D_1,D_2,\\ldots,D_n)$ 和一个隐藏序列 $C_{1:n}=(C_1,C_2,\\ldots,C_n)$，联合概率为\n$$P(C_{1:n},D_{1:n})=\\pi(C_1)\\left(\\prod_{t=2}^{n} T(C_{t-1},C_t)\\right)\\left(\\prod_{t=1}^{n} f(D_t \\mid C_t)\\right).$$\n你的任务是：对于下面的每个观测序列，确定一个序列 $C_{1:n} \\in \\mathcal{C}^n$ 来最大化后验概率 $P(C_{1:n} \\mid D_{1:n}) \\propto P(C_{1:n},D_{1:n})$。如果存在多个最大化序列，则根据 $\\mathbb{Z}^{n}$ 上的常规顺序选择字典序最小的序列（即，从左到右逐元素比较两个序列，并选择在第一个不同位置上值较小的那个）。\n\n测试套件：\n- 情况 A（带有单拷贝缺失片段的平衡二倍体）：$D_{1:8}=(\\,0.98,\\,1.03,\\,1.01,\\,0.51,\\,0.48,\\,0.50,\\,0.99,\\,1.02\\,)$。\n- 情况 B（纯合缺失片段）：$D_{1:4}=(\\,0.08,\\,0.05,\\,0.04,\\,0.07\\,)$。\n- 情况 C（二倍体中的局灶性高级别扩增）：$D_{1:5}=(\\,1.01,\\,1.99,\\,2.49,\\,2.51,\\,1.02\\,)$。\n- 情况 D（与奇数拷贝一致的中间信号）：$D_{1:4}=(\\,1.40,\\,1.60,\\,1.45,\\,1.55\\,)$。\n- 情况 E（上边界高拷贝）：$D_{1:2}=(\\,3.95,\\,4.05\\,)$。\n\n要求的最终输出格式：\n- 你的程序必须生成单行输出，其中包含所有情况的结果，形式为用方括号括起来的逗号分隔列表，不含任何空白字符。\n- 每个情况的结果必须是最大化隐藏状态序列，表示为用方括号括起来的整数列表，同样不含空白字符。例如，一个包含两种情况的有效整体输出结构将是 $[[0,1],[2,2,3]]$。\n- 本问题中没有物理单位。所有数值结果都是无量纲的。\n\n你的程序必须为每个测试用例计算如上所述的最大化隐藏状态序列，并按 A、B、C、D、E 的顺序输出这五个序列，汇总成如上所述的单行。", "solution": "所呈现的问题是计算生物学领域一个有效且适定的科学问题。它要求在隐马尔可夫模型（HMM）中找到最可能的隐藏状态序列，这是一个存在标准算法的经典问题。所有模型参数和数据都已完整且一致地指定。我将着手解决该问题。\n\n目标是对于给定的观测读数深度序列 $D_{1:n} = (D_1, D_2, \\ldots, D_n)$，找到隐藏的拷贝数状态序列 $C_{1:n} = (C_1, C_2, \\ldots, C_n)$，以最大化后验概率 $P(C_{1:n} \\mid D_{1:n})$。因为对于固定的观测序列，证据 $P(D_{1:n})$ 是常数，所以最大化后验概率等同于最大化联合概率 $P(C_{1:n}, D_{1:n})$。联合概率由以下公式给出：\n$$P(C_{1:n},D_{1:n})=\\pi(C_1)\\left(\\prod_{t=2}^{n} T(C_{t-1},C_t)\\right)\\left(\\prod_{t=1}^{n} f(D_t \\mid C_t)\\right)$$\n其中 $\\pi$ 是初始状态分布，$T$ 是转移概率矩阵，$f$ 是发射概率密度。\n\n直接评估所有可能的状态序列在计算上是不可行的，因为存在 $|\\mathcal{C}|^n$ 个这样的序列。维特比（Viterbi）算法提供了一种高效的动态规划方法来找到这条最优路径。为了防止因乘以许多小概率而导致的数值下溢，所有计算都在对数空间中进行。目标变为最大化联合对数概率：\n$$\\log P(C_{1:n},D_{1:n}) = \\log\\pi(C_1) + \\sum_{t=2}^{n} \\log T(C_{t-1},C_t) + \\sum_{t=1}^{n} \\log f(D_t \\mid C_t)$$\n\n首先，我们预先计算所有模型参数的对数：\n1.  **对数初始概率**：未归一化的初始概率为 $\\pi'(c) = \\exp(-\\beta(c-c_0)^2)$，其中 $c \\in \\mathcal{C}=\\{0,1,\\ldots,8\\}$，$\\beta=1.0$ 且 $c_0=2$。我们计算归一化常数 $Z_\\pi = \\sum_{c \\in \\mathcal{C}} \\pi'(c)$，然后计算对数概率 $\\log\\pi(c) = \\log(\\pi'(c)) - \\log(Z_\\pi)$。\n\n2.  **对数转移概率**：未归一化的转移权重为：当 $i=j$ 时 $w(i,j) = \\kappa$；当 $i \\neq j$ 时 $w(i,j) = \\exp(-\\gamma|j-i|)$，其中 $\\kappa=20.0$ 且 $\\gamma=\\ln 2$。对于每个状态 $i$，我们计算归一化常数 $Z_T(i) = \\sum_{j \\in \\mathcal{C}} w(i,j)$。然后，对数转移概率为 $\\log T(i,j) = \\log w(i,j) - \\log Z_T(i)$。这将得到一个 $|\\mathcal{C}| \\times |\\mathcal{C}|$ 的对数概率矩阵。\n\n3.  **对数发射概率**：发射密度是一个高斯分布 $f(d \\mid c) = \\mathcal{N}(d; \\mu_c, \\sigma^2)$，均值为 $\\mu_c = c/2$，标准差为 $\\sigma = 0.15$。其对数密度为：\n    $$\\log f(d \\mid c) = -\\log(\\sigma\\sqrt{2\\pi}) - \\frac{(d - \\mu_c)^2}{2\\sigma^2}$$\n    对于每个观测序列 $D_{1:n}$，我们计算一个大小为 $n \\times |\\mathcal{C}|$ 的对数发射概率矩阵。\n\n维特比（Viterbi）算法的流程如下：\n\n令 $\\delta_t(j)$ 为任何长度为 $t$ 且结束于状态 $j$ 的路径的最大对数概率，$\\psi_t(j)$ 为该路径上的前驱状态。\n\n**1. 初始化（$t=1$）：**\n对于每个状态 $j \\in \\mathcal{C}$：\n$$\\delta_1(j) = \\log \\pi(j) + \\log f(D_1 \\mid j)$$\n\n**2. 递归（对于 $t=2, \\ldots, n$）：**\n对于每个状态 $j \\in \\mathcal{C}$：\n$$\\delta_t(j) = \\log f(D_t \\mid j) + \\max_{i \\in \\mathcal{C}} \\left( \\delta_{t-1}(i) + \\log T(i,j) \\right)$$\n$$\\psi_t(j) = \\arg\\max_{i \\in \\mathcal{C}} \\left( \\delta_{t-1}(i) + \\log T(i,j) \\right)$$\n如果 $\\arg\\max$ 存在平局，我们选择索引最小的前驱 $i$。\n\n**3. 终止：**\n任何完整路径的最大对数概率为 $P^* = \\max_{j \\in \\mathcal{C}} \\delta_n(j)$。\n\n**4. 路径回溯和打破平局：**\n问题要求在多个序列产生相同最大概率时，选择字典序最小的序列。在递归过程中简单的打破平局规则不足以全局保证这一点。正确的步骤是：\na. 识别所有可能结束最大概率路径的最终状态 $J^* = \\{j \\in \\mathcal{C} \\mid \\delta_n(j) \\text{ 与 } P^* \\text{ 接近}\\}$。浮点数比较需要一个小的容差。\nb. 对于每个 $j \\in J^*$，通过从 $t=n$ 回溯到 $t=1$ 来重建整个路径：$C_n^* = j$，并且对于 $t=n-1, \\ldots, 1$，$C_t^* = \\psi_{t+1}(C_{t+1}^*)$。\nc. 这会产生一组候选路径，它们都具有相同的最大概率。\nd. 对这些路径进行字典序比较，并选择最小的一个作为最终答案。\n\n对每个提供的测试用例执行此程序，以确定唯一的最优隐藏状态序列。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the HMM decoding problem for structural variant discovery.\n    \"\"\"\n\n    # --- Model Specification ---\n    BETA = 1.0\n    C0 = 2.0\n    KAPPA = 20.0\n    GAMMA = np.log(2.0)\n    SIGMA = 0.15\n    STATES = np.arange(9)\n    NUM_STATES = len(STATES)\n\n    # --- Pre-compute HMM Parameters ---\n\n    # 1. Log Initial Probabilities\n    unnorm_pi = np.exp(-BETA * (STATES - C0)**2)\n    pi = unnorm_pi / np.sum(unnorm_pi)\n    log_pi = np.log(pi)\n\n    # 2. Log Transition Matrix\n    W = np.zeros((NUM_STATES, NUM_STATES))\n    for i in range(NUM_STATES):\n        for j in range(NUM_STATES):\n            if i == j:\n                W[i, j] = KAPPA\n            else:\n                W[i, j] = np.exp(-GAMMA * np.abs(i - j))\n    \n    T = W / W.sum(axis=1, keepdims=True)\n    # Avoid log(0) for impossible transitions, though not expected here\n    log_T = np.log(np.where(T > 0, T, 1e-300))\n\n    def viterbi_solver(D):\n        \"\"\"\n        Finds the most likely state sequence using the Viterbi algorithm.\n        Handles lexicographical tie-breaking.\n        \"\"\"\n        n = len(D)\n\n        # 3. Log Emission Probabilities for the given sequence D\n        mu = STATES / 2.0\n        log_em_prefactor = -np.log(SIGMA) - 0.5 * np.log(2 * np.pi)\n        inv_2_sig_sq = 1.0 / (2.0 * SIGMA**2)\n        log_E = np.zeros((n, NUM_STATES))\n        for t in range(n):\n            d_t = D[t]\n            log_E[t, :] = log_em_prefactor - ((d_t - mu)**2 * inv_2_sig_sq)\n\n        # --- Viterbi Algorithm ---\n        delta = np.zeros((n, NUM_STATES))\n        psi = np.zeros((n, NUM_STATES), dtype=int)\n\n        # Initialization (t=0)\n        delta[0, :] = log_pi + log_E[0, :]\n\n        # Recursion (t=1 to n-1)\n        for t in range(1, n):\n            for j in range(NUM_STATES):\n                scores = delta[t-1, :] + log_T[:, j]\n                # In numpy.argmax, ties are broken by returning the first index,\n                # which corresponds to the smallest state index.\n                best_prev_state = np.argmax(scores)\n                psi[t, j] = best_prev_state\n                delta[t, j] = scores[best_prev_state] + log_E[t, j]\n\n        # Termination  Tie-Breaking\n        max_logp = np.max(delta[n-1, :])\n        # Find all states that achieve the max probability within a tolerance\n        potential_last_states = np.where(np.isclose(delta[n-1, :], max_logp))[0]\n\n        optimal_paths = []\n        for last_state in potential_last_states:\n            path = [0] * n\n            path[n-1] = last_state\n            for t in range(n-2, -1, -1):\n                path[t] = psi[t+1, path[t+1]]\n            optimal_paths.append(path)\n\n        # Sort paths lexicographically and select the first one\n        optimal_paths.sort()\n        return optimal_paths[0]\n\n    # --- Test Suite ---\n    test_cases = [\n        (0.98, 1.03, 1.01, 0.51, 0.48, 0.50, 0.99, 1.02), # Case A\n        (0.08, 0.05, 0.04, 0.07),                         # Case B\n        (1.01, 1.99, 2.49, 2.51, 1.02),                   # Case C\n        (1.40, 1.60, 1.45, 1.55),                         # Case D\n        (3.95, 4.05),                                     # Case E\n    ]\n    \n    results = []\n    for D_tuple in test_cases:\n        D_array = np.array(D_tuple)\n        result_path = viterbi_solver(D_array)\n        results.append(result_path)\n\n    # --- Format Output ---\n    results_str = []\n    for path in results:\n        results_str.append(f\"[{','.join(map(str, path))}]\")\n    \n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "2431910"}]}