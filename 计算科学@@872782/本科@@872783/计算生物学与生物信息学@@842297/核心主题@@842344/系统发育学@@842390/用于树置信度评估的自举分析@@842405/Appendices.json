{"hands_on_practices": [{"introduction": "这项练习将自举分析剥离至其本质。我们将看到，在重抽样数据集中，单个决定性位点的存在与否如何直接转化为对某个分支的支持率，从而在原始数据和最终的置信度得分之间建立起切实的联系。本练习将巩固您对“支持率根本上是对信号一致性的概率度量”这一核心概念的理解。[@problem_id:2377065]", "problem": "给定一个系统发育场景，其中包含 $4$ 个标记为 $A$、$B$、$C$ 和 $D$ 的分类单元的脱氧核糖核酸（DNA）比对。目标是精确量化将一个高信息量位点替换为模糊字符 $N$（意为“未知核苷酸”）后，分支 $\\{A,B\\}$ 的非参数自举支持率会如何变化。你的程序必须计算在替换 $N$ 之前和之后 $\\{A,B\\}$ 的支持率，并报告支持率的下降值。该计算必须基于自举重采样和四分类单元推断的基本原理，并且结果必须以小数（而非百分比）形式表示。\n\n基本依据和定义：\n- DNA 比对是一个包含 $4$ 行（分类单元）和 $L$ 列（位点）的矩阵。每个条目是 $\\{A,C,G,T,N\\}$ 中的一个。\n- 一个自举重复是通过从原始比对中有放回地抽样 $L$ 列而形成的。这种抽样在所有位置上是独立同分布的，每次抽取时，每个原始列被选中的概率为 $1/L$。\n- 对于任何重复比对，定义分类单元 $X$ 和 $Y$ 之间的成对 $p$-距离 $d(X,Y)$ 为 $X$ 和 $Y$ 存在差异的位点所占的比例（在 $L$ 个抽样列中），忽略任何 $X$ 或 $Y$ 具有 $N$ 的位点。如果在忽略 $N$ 之后一对分类单元没有有效位点，则设 $d(X,Y)=0$。\n- 对于任何重复中的四分类单元组 $\\{A,B,C,D\\}$，通过严格四点条件推断无根分裂：当且仅当\n$$\nd(A,B) + d(C,D) \\lt \\min\\big(d(A,C)+d(B,D),\\ d(A,D)+d(B,C)\\big).\n$$\n时，选择分裂 $\\{A,B\\}|\\{C,D\\}$。如果不是严格达到最小值（即，出现任何相等情况），则将该重复视为不为 $\\{A,B\\}$ 提供支持。\n- $\\{A,B\\}$ 的自举支持率是其推断出的分裂为 $\\{A,B\\}|\\{C,D\\}$ 的自举重复所占的比例。在本问题中，你必须计算由所提供比对的重采样方案所隐含的精确值，而不是一个渐近置信度或启发式分数。\n\n位点操作规则：\n- “用 $N$ 替换一个位点”是指：选择一个指定的列索引，并将该列中所有 $4$ 个分类单元的字符替换为 $N$。所有其他列保持不变。\n\n任务要求：\n- 对于每个测试用例，计算分支 $\\{A,B\\}$ 的两种支持率：在用 $N$ 替换指定列之前和之后（替换集可以是一列或多列，如测试用例中所指定）。然后计算下降值\n$$\n\\Delta = \\text{support}_{\\text{before}} - \\text{support}_{\\text{after}},\n$$\n以 $[0,1]$ 范围内的小数表示。报告每个 $\\Delta$ 值，四舍五入到恰好 $3$ 位小数。\n- 重要约束：下面的所有测试用例都被构造成这样：每个位点要么在所有分类单元中是恒定的，要么是 $\\{A,B\\}$ 对 $\\{C,D\\}$ 形式为 $A/A$ 对 $G/G$ 的简约性信息位点（没有其他信息模式出现），并且最初没有 $N$ 符号。在这些条件下，一个自举重复支持 $\\{A,B\\}$ 当且仅当至少一个这样的信息位点在该重复中被至少抽样一次。你的程序必须使用与上述定义普遍一致的正确逻辑。\n\n测试套件：\n- 测试用例 $1$（具有一个决定性位点的理想路径）：\n  - 分类单元：$A,B,C,D$。\n  - 比对长度 $L=20$。\n  - 比对：所有分类单元的所有位点均为 $A$，但在列索引 $3$（从零开始）处除外，该处 $A$ 和 $B$ 拥有 $A$，而 $C$ 和 $D$ 拥有 $G$。\n  - 替换：将所有分类单元的列索引 $3$ 替换为 $N$。\n- 测试用例 $2$（具有多个决定性位点的稳健信号）：\n  - 分类单元：$A,B,C,D$。\n  - 比对长度 $L=40$。\n  - 比对：所有分类单元的所有位点均为 $A$，但在 $10$ 个列索引 $\\{1,5,9,13,17,21,25,29,33,37\\}$（从零开始）处除外，在这些位置上 $A$ 和 $B$ 拥有 $A$，而 $C$ 和 $D$ 拥有 $G$。\n  - 替换：仅将所有分类单元的列索引 $1$ 替换为 $N$。\n- 测试用例 $3$（只有一个位点的边界情况）：\n  - 分类单元：$A,B,C,D$。\n  - 比对长度 $L=1$。\n  - 比对：在列索引 $0$ 处，$A$ 和 $B$ 拥有 $A$，而 $C$ 和 $D$ 拥有 $G$。\n  - 替换：将所有分类单元的列索引 $0$ 替换为 $N$。\n\n最终输出格式：\n- 你的程序应生成一行输出，其中包含按顺序排列的三个测试用例的下降值 $\\Delta$，形式为用方括号括起来的逗号分隔列表。每个值必须四舍五入到恰好 $3$ 位小数。例如，一个可接受的格式是“[0.123,0.456,0.789]”。", "solution": "问题陈述已经过严格验证，被认为是具有科学依据、良定且客观的。它在系统发育推断中呈现了一个标准的（尽管是简化的）场景，提供了推导唯一、可验证解所需的所有定义和数据。该问题是有效的，并将按陈述进行解决。\n\n问题的核心是计算一个分支的自举支持率，即一个自举重复满足给定拓扑条件的概率。该分析需要从基本原理进行推导。\n\n首先，让我们形式化一个重复支持分裂 $\\{A,B\\}|\\{C,D\\}$ 的条件。问题规定，当且仅当满足严格四点条件时，这种支持才存在：\n$$\nd(A,B) + d(C,D)  \\min\\big(d(A,C)+d(B,D),\\ d(A,D)+d(B,C)\\big)\n$$\n其中 $d(X,Y)$ 是成对 $p$-距离。该问题受约束，使得原始比对中的所有位点要么在所有四个分类单元中是恒定的，要么是对于分裂 $\\{A,B\\}|\\{C,D\\}$ 而言是简约性信息的。\n\n让我们分析在长度为 $L$ 的自举重复中，每种位点类型对成对距离的贡献。\n一个自举重复是通过从原始比对中有放回地抽样 $L$ 列而形成的。假设一个给定的重复包含 $k_I$ 个信息位点，$k_C$ 个恒定位点，以及 $k_N$ 个所有字符均为 $N$ 的位点。抽样位点的总数为 $L=k_I + k_C + k_N$。\n\n$p$-距离 $d(X,Y)$ 定义为不同位点所占的比例，忽略任何一个分类单元具有 'N' 的位点。\n对于类型为 $(c,c,c,c)$（恒定）或 $(X,X,Y,Y)$（对 $\\{A,B\\}|\\{C,D\\}$ 具有信息性）的任何位点，所有字符都来自 $\\{A,C,G,T\\}$。对于类型为 $(N,N,N,N)$ 的位点，在所有距离计算中都会被忽略。\n因此，用于计算任何成对距离 $d(X,Y)$ 的有效位点数为 $L_{\\text{valid}} = k_I + k_C$。\n\n如果 $L_{\\text{valid}} = 0$，这种情况当且仅当一个重复仅由所有分类单元均为 $N$ 的列组成时发生，那么所有成对距离都定义为 $0$。支持条件变为 $0  \\min(0,0)$，这是不成立的。这样的重复不提供任何支持。\n\n如果 $L_{\\text{valid}} > 0$：\n- 对于分类单元 $A$ 和 $B$，它们的序列在所有信息位点和恒定位点上都是相同的。差异数为 $0$。因此，$d(A,B) = 0/L_{\\text{valid}} = 0$。\n- 同样，对于分类单元 $C$ 和 $D$，它们的序列是相同的。因此，$d(C,D) = 0$。\n- 不等式的左侧是 $d(A,B) + d(C,D) = 0$。\n\n- 对于分类单元 $A$ 和 $C$，它们的序列在恒定位点上相同，但在所有 $k_I$ 个信息位点上不同。差异数为 $k_I$。因此，$d(A,C) = k_I / L_{\\text{valid}}$。\n- 根据信息模式的对称性，$d(B,D) = d(A,D) = d(B,C) = k_I / L_{\\text{valid}}$。\n- 不等式的右侧是 $\\min(d(A,C)+d(B,D), d(A,D)+d(B,C)) = \\min(2k_I/L_{\\text{valid}}, 2k_I/L_{\\text{valid}}) = 2k_I/L_{\\text{valid}}$。\n\n支持的四点条件变为 $0  2k_I/L_{\\text{valid}}$。这个不等式当且仅当 $k_I > 0$ 时成立。因此，一个自举重复支持分支 $\\{A,B\\}$ 当且仅当它包含至少一个信息位点。这验证了问题陈述中的断言。\n\n现在任务简化为一个概率计算。设 $L$ 为比对中的总位点数，$I$ 为信息位点数。剩下的 $L-I$ 个位点是非信息性的（恒定的或全为 $N$）。\n在单次抽取中选中一个非信息位点的概率是 $p_{\\text{non-I}} = (L-I)/L$。\n由于一个自举重复由 $L$ 次独立抽取组成，所有 $L$ 个抽样位点都是非信息性的概率是：\n$$\nP(\\text{no support}) = \\left(\\frac{L-I}{L}\\right)^L\n$$\n自举支持率是互补事件的概率，即至少抽样到一个信息位点：\n$$\n\\text{Support}(L, I) = 1 - P(\\text{no support}) = 1 - \\left(\\frac{L-I}{L}\\right)^L\n$$\n该公式提供了精确的支持率值。我们将其应用于每个测试用例。\n\n测试用例 1：\n- 比对长度 $L=20$。\n- 替换前：有一个信息位点在列索引 $3$ 处。因此，$I_{\\text{before}} = 1$。\n  $\\text{Support}_{\\text{before}} = 1 - \\left(\\frac{20-1}{20}\\right)^{20} = 1 - (0.95)^{20}$。\n- 替换后：该信息位点被替换为 $N$，变为非信息性位点。因此，$I_{\\text{after}} = 0$。\n  $\\text{Support}_{\\text{after}} = 1 - \\left(\\frac{20-0}{20}\\right)^{20} = 1 - 1^{20} = 0$。\n- 支持率下降值：$\\Delta_1 = \\text{Support}_{\\text{before}} - \\text{Support}_{\\text{after}} = 1 - (0.95)^{20} \\approx 0.641514$。\n\n测试用例 2：\n- 比对长度 $L=40$。\n- 替换前：有 $10$ 个信息位点。因此，$I_{\\text{before}} = 10$。\n  $\\text{Support}_{\\text{before}} = 1 - \\left(\\frac{40-10}{40}\\right)^{40} = 1 - (0.75)^{40}$。\n- 替换后：其中一个信息位点被替换为 $N$。剩下 $9$ 个信息位点。因此，$I_{\\text{after}} = 9$。\n  $\\text{Support}_{\\text{after}} = 1 - \\left(\\frac{40-9}{40}\\right)^{40} = 1 - (0.775)^{40}$。\n- 支持率下降值：$\\Delta_2 = \\left(1 - (0.75)^{40}\\right) - \\left(1 - (0.775)^{40}\\right) = (0.775)^{40} - (0.75)^{40} \\approx 0.0000155$。\n\n测试用例 3：\n- 比对长度 $L=1$。\n- 替换前：单个位点是信息位点。因此，$I_{\\text{before}} = 1$。\n  $\\text{Support}_{\\text{before}} = 1 - \\left(\\frac{1-1}{1}\\right)^1 = 1 - 0^1 = 1$。\n- 替换后：单个信息位点被移除。因此，$I_{\\text{after}} = 0$。\n  $\\text{Support}_{\\text{after}} = 1 - \\left(\\frac{1-0}{1}\\right)^1 = 1 - 1^1 = 0$。\n- 支持率下降值：$\\Delta_3 = 1 - 0 = 1$。\n\n最终结果是这些 $\\Delta$ 值，四舍五入到 3 位小数。\n$\\Delta_1 \\approx 0.642$\n$\\Delta_2 \\approx 0.000$\n$\\Delta_3 = 1.000$", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the drop in bootstrap support for the clade {A,B} for three test cases.\n    The support is calculated based on the exact probability of sampling at least one \n    informative site in a bootstrap replicate.\n    \"\"\"\n\n    def calculate_support(L, I):\n        \"\"\"\n        Calculates the exact bootstrap support.\n\n        Args:\n            L (int): The total number of sites in the alignment.\n            I (int): The number of informative sites for the clade of interest.\n\n        Returns:\n            float: The bootstrap support value, a probability in [0, 1].\n        \"\"\"\n        if L == 0:\n            return 0.0\n        if I == 0:\n            return 0.0\n\n        # The probability of not sampling an informative site in a single draw.\n        prob_non_informative_draw = (L - I) / L\n        \n        # The probability of not sampling any informative site in L draws.\n        prob_no_support = np.power(prob_non_informative_draw, L)\n        \n        # The support is the complementary probability.\n        return 1.0 - prob_no_support\n\n    # Define the test cases from the problem statement.\n    # Each tuple contains: (L, I_before, I_after)\n    test_cases = [\n        # Test Case 1: L=20, 1 informative site, which is then removed.\n        (20, 1, 0),\n        # Test Case 2: L=40, 10 informative sites, 1 of which is removed.\n        (40, 10, 9),\n        # Test Case 3: L=1, 1 informative site, which is then removed.\n        (1, 1, 0),\n    ]\n\n    results = []\n    for case in test_cases:\n        L, I_before, I_after = case\n        \n        support_before = calculate_support(L, I_before)\n        support_after = calculate_support(L, I_after)\n        \n        delta = support_before - support_after\n        results.append(delta)\n\n    # Format the results as specified: a list of strings rounded to 3 decimal places.\n    formatted_results = [f\"{r:.3f}\" for r in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2377065"}, {"introduction": "一个常见的误解是，如果最大似然法等方法产生了一棵单一、完全解析的树，那么这棵树必定得到了很好的支持。本练习挑战了这一观念，要求您构建一个场景：尽管最佳拟合树很明确，但自举重抽样显示，其潜在信号太弱，无法在与其他替代方案的竞争中稳定胜出。这揭示了在原始数据上的最优性与对数据扰动的稳健性之间的关键区别。[@problem_id:2377058]", "problem": "要求您通过计算构建并验证一个包含四个分类单元的小型多序列比对。对于该比对，在Jukes-Cantor (JC)模型下推断的最大似然(ML)树是完全解析的（二叉树），但其非参数自举多数决一致树却是一个完全未解析的星状树（即没有任何内部分割满足严格多数阈值）。\n\n您的程序必须从第一性原理出发实现以下内容。\n\n1) 用作基础的基本定义：\n- 系统发育的非参数自举法通过有放回地重采样比对列来创建重复比对，每个重复比对的长度与原始比对相同，然后对每个重复比对推断一棵树。内部分割在各重复比对中出现的频率是其抽样支持度的一个估计量。\n- 最大似然法(ML)：给定一个固定的树拓扑和一个替换模型，枝长会使观测到的比对的似然值最大化。在候选拓扑中，ML树是具有最高优化似然值的拓扑。\n- Jukes-Cantor (JC)模型：对于长度为 $t$ （以每个位点的期望替换数计）的枝和任意一对核苷酸 $i$ 和 $j$，在速率为 $1$ 的JC模型下，转移概率为\n$$\nP_{ij}(t) =\n\\begin{cases}\n\\frac{1}{4} + \\frac{3}{4} e^{-\\frac{4}{3} t},   i=j, \\\\\\\\\n\\frac{1}{4} - \\frac{1}{4} e^{-\\frac{4}{3} t},   i\\neq j.\n\\end{cases}\n$$\n平稳分布是均匀的，对于所有 $i$，$\\pi_i = \\frac{1}{4}$。\n- Felsenstein剪枝算法：对于一个有根树和一个具有观测叶节点状态的位点，位点似然值为\n$$\n\\mathcal{L}_{\\text{site}} = \\sum_{r\\in\\{A,C,G,T\\}} \\pi_r \\prod_{c \\in \\text{children(root)}} \\left( \\sum_{k} P_{rk}(t_{rc}) \\, L_c(k) \\right),\n$$\n其中，$L_c(k)$ 是在父节点状态为 $k$ 时子节点 $c$ 处的部分似然值，而在一个观测状态为 $s$ 的叶节点处，我们设置 $L_{\\text{leaf}}(k)=\\mathbb{I}[k=s]$。时间可逆性确保了似然值与任意的根位置无关。\n\n2) 数据集设计空间与决策规则：\n- 考虑四个分类单元，记为 $A$、$B$、$C$ 和 $D$。限定于三种完全解析的无根二叉拓扑，它们由其唯一的内部分割表示：\n  - $T_1$: $(A,B)\\mid(C,D)$,\n  - $T_2$: $(A,C)\\mid(B,D)$,\n  - $T_3$: $(A,D)\\mid(B,C)$.\n- 构建一个仅由简约性信息位点模式组成的比对，这些模式在JC模型下强烈且对称地支持其中一个分割：\n  - 支持 $T_1$ 的模式：$A=A$, $B=A$, $C=G$, $D=G$（编码为状态 $[0,0,2,2]$），\n  - 支持 $T_2$ 的模式：$A=A$, $C=A$, $B=G$, $D=G$（编码为 $[0,2,0,2]$），\n  - 支持 $T_3$ 的模式：$A=A$, $D=A$, $B=G$, $C=G$（编码为 $[0,2,2,0]$）。\n- 设该比对由这三种模式的计数 $(c_1,c_2,c_3)$ 决定。记 $L=c_1+c_2+c_3$。\n- 对于完整数据集，通过枚举三种拓扑 $T_1$、$T_2$ 和 $T_3$，优化其枝长，并选择具有最大优化对数似然值的拓扑，来计算JC模型下的ML树。如果单个拓扑严格地最大化了优化对数似然值，则该树是“完全解析的”。\n- 对于自举分析，通过从原始比对中有放回地抽样 $L$ 列来获得重复比对。每个自举重复样本通过相同的JC-ML过程从 $\\{T_1,T_2,T_3\\}$ 中选择一个ML拓扑。在严格阈值 $0.5$ 下的多数决一致树包含任何在重复样本中选择频率严格大于 $0.5$ 的分割。如果没有分割满足此条件，则一致树为星状树（完全未解析）。\n\n3) 自举选择频率的精确评估：\n- 设类别概率为 $p_i = c_i/L$，$i\\in\\{1,2,3\\}$。一个自举重复样本中三种信息性类别的计数 $(k_1,k_2,k_3)$ 服从三项分布：\n$$\n\\Pr[k_1,k_2,k_3] = \\frac{L!}{k_1!\\,k_2!\\,k_3!} \\, p_1^{k_1} p_2^{k_2} p_3^{k_3}, \\quad k_1+k_2+k_3=L, \\; k_i\\ge 0.\n$$\n- 假设重复样本的拓扑决策由 $k_1,k_2,k_3$ 中哪个最大来决定（这与JC模型下受限模式的ML结果相匹配）。在固定顺序 $(T_1,T_2,T_3)$ 下按字典序解决平局，即，如果 $k_1\\ge k_2$ 且 $k_1\\ge k_3$，则选择 $T_1$；否则，如果 $k_2k_1$ 且 $k_2\\ge k_3$，则选择 $T_2$；否则选择 $T_3$。\n- 拓扑 $T_i$ 的精确选择概率是通过在此规则下选择 $T_i$ 的 $(k_1,k_2,k_3)$ 区域上对三项概率求和得到的。您必须通过枚举精确计算这些概率，而不是通过蒙特卡洛方法。\n\n4) 您必须计算和报告的内容：\n- 将为您提供一个小型测试套件，其中包含定义 $(c_1,c_2,c_3)=(m+\\delta,\\,m,\\,m)$ 的参数 $(m,\\delta)$，您必须对这些参数执行以下操作：\n  - 按所述构建比对。\n  - 使用Felsenstein剪枝算法，通过JC模型和枝长优化来计算完整数据集上的ML拓扑。\n  - 通过三项枚举和上述字典序平局决胜规则，计算精确的自举选择概率 $(P_1,P_2,P_3)$。\n  - 判断严格多数决自举一致树是否为星状树，即 $\\max(P_1,P_2,P_3) \\le 0.5$ 是否成立。\n  - 对每个测试用例，输出一个布尔值，指示两个条件是否同时成立：完整数据的ML树是完全解析的，并且自举严格多数决一致树是星状树。\n\n5) 测试套件：\n使用以下测试用例，它们分别测试了一个平衡但有偏的“理想路径”、一个强偏的“非星状”边界情况，以及一个短比对的边缘案例：\n- 案例1：$(m,\\delta)=(10,1)$，因此 $(c_1,c_2,c_3)=(11,10,10)$。\n- 案例2：$(m,\\delta)=(10,20)$，因此 $(c_1,c_2,c_3)=(30,10,10)$。\n- 案例3：$(m,\\delta)=(3,1)$，因此 $(c_1,c_2,c_3)=(4,3,3)$。\n\n6) 最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，“[result1,result2,result3]”），其中每个结果是按测试用例顺序排列的布尔值。不应打印任何其他文本。不涉及角度，也没有物理单位。所有阈值都必须视为纯小数（例如，$0.5$）。", "solution": "该问题陈述已经过严格验证，并被确定为有效。它在科学上基于分子系统发育学的原理，特别是最大似然(ML)推断和非参数自举法。该问题是良定的，提供了无歧义的定义、如Jukes-Cantor (JC)模型等明确的模型，以及一个具有确定输入和输出的清晰计算任务。所有术语都是客观且精确指定的。不存在矛盾、缺失数据或不符合科学原理的假设。对于给定的参数，该计算任务是可行的。\n\n目标是确定对于特定的多序列比对，是否同时满足两个条件：\n$1$. 从完整比对估计的ML树是完全解析的。\n$2$. 来自非参数自举分析的严格多数决一致树是一个完全未解析的星状拓扑。\n\n解决方案通过实现问题陈述所要求的逻辑来进行。问题提供了一个关键的简化：无论是对于完整数据集还是任何自举重复样本，ML拓扑都是通过确定三个指定的简约性信息位点模式中哪个计数最高来决定的。据称，这是JC模型下问题对称构造的结果，并允许我们绕过使用Felsenstein剪枝算法进行显式枝长优化的计算密集型步骤。\n\n设三种位点模式的计数为 $(c_1, c_2, c_3)$，分别对应于对拓扑 $T_1$、$T_2$ 和 $T_3$ 的支持。位点总数为 $L = c_1 + c_2 + c_3$。测试用例的形式为 $(c_1, c_2, c_3) = (m+\\delta, m, m)$，其中 $\\delta > 0$。\n\n首先，我们验证完整数据ML树“完全解析”的条件。如果一个拓扑唯一地最大化了对数似然值，则它是完全解析的。根据问题的简化，ML拓扑是与最大计数相对应的那个。对于给定的测试用例，$c_1 = m+\\delta$ 严格大于 $c_2 = m$ 和 $c_3 = m$。因此，拓扑 $T_1$ 是唯一的ML选择。第一个条件——ML树是完全解析的——对于所有提供的测试用例都满足。\n\n其次，我们评估自举一致树。如果没有任何一个拓扑在超过 $50\\%$ 的自举重复样本中被选中，则一致树是星状树。这需要计算每个拓扑的精确选择概率 $P_1, P_2, P_3$。\n\n一个自举重复样本是通过从原始比对中有放回地抽样 $L$ 个位点生成的。重复样本中三种模式的计数，记为 $(k_1, k_2, k_3)$，服从三项分布，其中 $k_1+k_2+k_3=L$。观测到一组特定计数的概率由概率质量函数给出：\n$$ \\Pr[k_1, k_2, k_3] = \\frac{L!}{k_1!\\,k_2!\\,k_3!} p_1^{k_1} p_2^{k_2} p_3^{k_3} $$\n其中 $p_i = c_i/L$ 是原始比对中模式的比例。\n\n对于具有计数 $(k_1, k_2, k_3)$ 的重复样本，所选的拓扑由以下规则确定，该规则包括一个字典序平局决胜法：\n- 如果 $k_1 \\ge k_2$ 且 $k_1 \\ge k_3$，则选择 $T_1$。\n- 如果 $k_2 > k_1$ 且 $k_2 \\ge k_3$，则选择 $T_2$。\n- 否则选择 $T_3$。\n\n拓扑 $T_i$ 的总选择概率，记为 $P_i$，是所有导致选择 $T_i$ 的元组 $(k_1, k_2, k_3)$ 的 $\\Pr[k_1, k_2, k_3]$ 之和。我们通过枚举 $L$ 的所有可能的整数分区 $(k_1, k_2, k_3)$ 来计算这些概率。为了数值稳定性，计算使用对数进行。三项概率的对数为：\n$$ \\ln(\\Pr[k_1, k_2, k_3]) = \\ln(\\Gamma(L+1)) - \\sum_{i=1}^{3} \\ln(\\Gamma(k_i+1)) + \\sum_{i=1}^{3} k_i \\ln(p_i) $$\n其中 $\\Gamma$ 是伽马函数，且 $\\ln(\\Gamma(n+1)) = \\ln(n!)$。\n\n在计算出 $P_1, P_2$ 和 $P_3$ 之后，我们检查星状一致树的条件：$\\max(P_1, P_2, P_3) \\le 0.5$。\n\n每个测试用例的最终布尔结果是这两个条件的逻辑与。由于对于给定的测试用例，第一个条件总是为真，因此结果简化为自举一致树是否为星状树。对每个指定的 $(m,\\delta)$ 对执行该计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import gammaln\n\ndef solve():\n    \"\"\"\n    Constructs and verifies alignments for which the ML tree is resolved\n    but the bootstrap majority-rule consensus is a star.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (10, 1),  # Case 1: (m,d)=(10,1) - (c1,c2,c3)=(11,10,10)\n        (10, 20), # Case 2: (m,d)=(10,20) - (c1,c2,c3)=(30,10,10)\n        (3, 1),   # Case 3: (m,d)=(3,1) - (c1,c2,c3)=(4,3,3)\n    ]\n\n    results = []\n    for m, delta in test_cases:\n        # Full-data ML tree resolution check\n        # Counts are (m+delta, m, m). Since delta  0, c1 is strictly maximal.\n        # The problem states this implies the ML topology is T1 and thus resolved.\n        ml_tree_is_resolved = True\n\n        # Bootstrap consensus check\n        c1, c2, c3 = m + delta, m, m\n        L = c1 + c2 + c3\n        \n        # Proportions of each site pattern\n        p1, p2, p3 = c1 / L, c2 / L, c3 / L\n\n        # Pre-compute logs for efficiency in the loops\n        log_L_fact = gammaln(L + 1)\n        # Note: All test cases have c_i  0, so p_i  0. No need to handle log(0).\n        log_p1 = np.log(p1)\n        log_p2 = np.log(p2)\n        log_p3 = np.log(p3)\n\n        # Probabilities for selecting T1, T2, T3\n        P = np.zeros(3)\n\n        # Enumerate all possible bootstrap replicate compositions (k1, k2, k3)\n        for k1 in range(L + 1):\n            for k2 in range(L - k1 + 1):\n                k3 = L - k1 - k2\n\n                # Calculate the trinomial probability for the composition (k1, k2, k3)\n                log_prob = (log_L_fact - gammaln(k1 + 1) - gammaln(k2 + 1) - gammaln(k3 + 1) +\n                            k1 * log_p1 + k2 * log_p2 + k3 * log_p3)\n                prob = np.exp(log_prob)\n\n                # Apply the specified topology selection rule with tie-breaking\n                if k1 >= k2 and k1 >= k3:\n                    P[0] += prob  # T1 is selected\n                elif k2 > k1 and k2 >= k3:\n                    P[1] += prob  # T2 is selected\n                else:\n                    P[2] += prob  # T3 is selected\n\n        # Check if the consensus is a star (no split has  50% support)\n        is_star_consensus = np.max(P) = 0.5\n\n        # The final result is the conjunction of the two conditions\n        results.append(ml_tree_is_resolved and is_star_consensus)\n\n    # Final print statement in the exact required format.\n    # The boolean values are automatically converted to \"True\" or \"False\" strings.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2377058"}, {"introduction": "高自举值通常被解释为某个分支存在的强有力证据。然而，本练习将探讨一个名为“自举天堂”的关键现象，即在没有任何冲突信息的情况下，少量一致的位点也可能产生具有欺骗性的高支持率。这将教会您在评估高支持率时，结合数据本身所含信息量的背景进行批判性思考。[@problem_id:2377030]", "problem": "要求你研究系统发育推断中一种有时被称为“自举天堂”（bootstrap paradise）的现象，即极低的噪音和极少的信息位点却可能产生具有误导性的高自举支持率。在四个标记为 $A$、$B$、$C$ 和 $D$ 的分类单元的设定下进行研究，并以每个位点为基础使用最大简约性准则。该问题的基本依据如下：\n\n- 一个位点是简约性信息的（对于四个分类单元），当且仅当它在分类单元间表现出相同状态的 $2$–$2$ 分裂。这样一个位点恰好支持三种可能的无根分裂中的一种：$A B \\mid C D$、$A C \\mid B D$ 或 $A D \\mid B C$。\n- 对于四个分类单元的最大简约性分析，对于一个包含 $N$ 个位点的比对，如果所有简约性信息位点都是 $2$–$2$ 类型，那么一个拓扑结构的总简约性分数仅因支持该拓扑结构的此类位点数量而不同。非信息位点（恒定或单一模式）对所有拓扑结构的贡献相同，因此不影响哪种拓扑结构能使总分最小化。\n\n自举重采样的定义如下：\n\n- 通过从原始 $N$ 列中进行有放回地抽样 $N$ 个比对列，可以获得一个非参数自举重复。\n- 对于每个重复，计算三种无根拓扑结构中的哪一种使简约性分数最小。如果存在唯一的最小化者，则记录所选的拓扑结构；如果出现平局（包括没有抽到简约性信息位点的情况），则将该重复视为未解决的，不计为支持任何特定拓扑结构。\n\n你将模拟位点类别层面的比对，而不是明确的核苷酸。每个长度为 $N$ 的比对由以下部分组成：\n- $m_{\\text{corr}}$ 个简约性信息列，支持焦点分裂 $A B \\mid C D$，\n- $m_{\\text{conf}}$ 个简约性信息列，支持冲突分裂 $A C \\mid B D$，\n- $m_{\\text{oth}}$ 个简约性信息列，支持剩余分裂 $A D \\mid B C$，\n- 以及 $N - m_{\\text{corr}} - m_{\\text{conf}} - m_{\\text{oth}}$ 个非信息列。\n\n在一个大小为 $N$ 的自举重复中，这四个位点类别的抽样计数向量服从多项式分布，其参数为 $N$ 和类别概率 $\\left(\\frac{m_{\\text{corr}}}{N}, \\frac{m_{\\text{conf}}}{N}, \\frac{m_{\\text{oth}}}{N}, 1 - \\frac{m_{\\text{corr}} + m_{\\text{conf}} + m_{\\text{oth}}}{N}\\right)$。设 $X_{\\text{corr}}$、$X_{\\text{conf}}$ 和 $X_{\\text{oth}}$ 为三个信息类别的抽样计数。在最大简约性准则下，所选的拓扑结构是其计数在 $\\left\\{X_{\\text{corr}}, X_{\\text{conf}}, X_{\\text{oth}}\\right\\}$ 中严格最大的那个。如果最大值不唯一，则该重复是未解决的。\n\n你的任务是编写一个完整、可运行的程序，该程序：\n- 为了效率，使用多项式分布实现所述的自举过程。\n- 每个测试用例使用相同数量 $B$ 的自举重复（每个重复的重采样大小为 $N$）。\n- 计算焦点分裂 $A B \\mid C D$ 的自举支持率，即 $X_{\\text{corr}}$ 严格大于 $X_{\\text{conf}}$ 和 $X_{\\text{oth}}$ 的自举重复所占的比例。\n\n重要细节和约束：\n- 将支持率表示为小数比例（而非百分比），四舍五入到小数点后恰好 $6$ 位。\n- 每个测试用例使用固定的伪随机种子，以确保结果的确定性。\n- 每个自举重复的重采样大小必须恰好为 $N$。\n- 如果 $m_{\\text{corr}} + m_{\\text{conf}} + m_{\\text{oth}} = 0$，则没有重复可以支持任何拓扑结构；支持率必须为 $0.0$。\n\n测试套件：\n- 对以下四个参数集中的每一个，使用 $B = 20000$ 次自举重复，并使用指定的种子：\n    1. $N = 100$, $m_{\\text{corr}} = 4$, $m_{\\text{conf}} = 0$, $m_{\\text{oth}} = 0$, 种子 $= 1$。\n    2. $N = 100$, $m_{\\text{corr}} = 0$, $m_{\\text{conf}} = 0$, $m_{\\text{oth}} = 0$, 种子 $= 2$。\n    3. $N = 100$, $m_{\\text{corr}} = 5$, $m_{\\text{conf}} = 1$, $m_{\\text{oth}} = 0$, 种子 $= 3$。\n    4. $N = 100$, $m_{\\text{corr}} = 3$, $m_{\\text{conf}} = 3$, $m_{\\text{oth}} = 0$, 种子 $= 4$。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含按顺序排列的四个自举支持率，形式为用方括号括起来的逗号分隔列表。每个支持率必须打印为四舍五入到小数点后恰好 $6$ 位的小数比例。例如：$[0.981684,0.000000,0.951000,0.487000]$（仅为示例；请勿硬编码数值）。\n\n你的实现必须是自包含的，且不得读取输入或写入任何文件。它必须完全按照上述规定为每个测试用例使用固定的伪随机种子。唯一允许使用的库是 Python 标准库和指定的数值库。", "solution": "我们从第一性原理出发，将“自举天堂”机制形式化，并推导出一个与四个分类单元上的最大简约性和非参数自举法相一致的算法。\n\n基本定义和事实：\n- 对于四个分类单元，简约性信息位点是指表现出相同状态的 $2$–$2$ 模式的位点；这样的位点恰好支持三种可能的无根分裂中的一种：$A B \\mid C D$、$A C \\mid B D$ 或 $A D \\mid B C$。\n- 对于四个分类单元，当所有信息位点都是 $2$–$2$ 类型时，最大简约性准则选择在整个比对中受最多 $2$–$2$ 位点支持的拓扑结构。非信息位点（恒定或单一）不影响哪种拓扑结构具有最小的总变化数，因为它们对所有拓扑结构的贡献是相同的。\n- 在非参数自举法中，我们从一个长度为 $N$ 的比对中有放回地抽取 $N$ 列来形成一个重复，并使用相同的准则在该重复上推断最佳拓扑结构。重复此过程 $B$ 次，会产生一个推断出的拓扑结构的分布。\n\n在类别层面建模重采样：\n- 设比对有 $N$ 列，由 $m_{\\text{corr}}$ 个支持 $A B \\mid C D$ 的列，$m_{\\text{conf}}$ 个支持 $A C \\mid B D$ 的列，$m_{\\text{oth}}$ 个支持 $A D \\mid B C$ 的列，以及 $N - m_{\\text{corr}} - m_{\\text{conf}} - m_{\\text{oth}}$ 个非信息列组成。\n- 在单个自举重复（大小为 $N$）中，四个类别的计数向量服从多项式分布：\n$$\n(X_{\\text{corr}}, X_{\\text{conf}}, X_{\\text{oth}}, X_{\\text{non}}) \\sim \\mathrm{Multinomial}\\!\\left(N;\\ \\frac{m_{\\text{corr}}}{N},\\ \\frac{m_{\\text{conf}}}{N},\\ \\frac{m_{\\text{oth}}}{N},\\ 1 - \\frac{m_{\\text{corr}} + m_{\\text{conf}} + m_{\\text{oth}}}{N}\\right).\n$$\n- 根据最大简约性准则，推断的拓扑结构由 $\\{X_{\\text{corr}}, X_{\\text{conf}}, X_{\\text{oth}}\\}$ 中的严格最大值确定。如果最大值由这些计数中的多个（包括它们都为零的情况）达到，则该重复是未解决的，不支持任何单一拓扑结构。\n\n因此，焦点分裂 $A B \\mid C D$ 的自举支持率为\n$$\n\\hat{s} \\;=\\; \\frac{1}{B} \\sum_{b=1}^{B} \\mathbf{1}\\!\\left( X_{\\text{corr}}^{(b)} > \\max\\{X_{\\text{conf}}^{(b)}, X_{\\text{oth}}^{(b)}\\} \\right),\n$$\n其中 $\\mathbf{1}(\\cdot)$ 是指示函数，上标 $(b)$ 表示自举重复的索引。\n\n“自举天堂”现象为何会发生：\n- 考虑 $m_{\\text{conf}} = 0$ 和 $m_{\\text{oth}} = 0$ 的情况。此时，一个重复不支持 $A B \\mid C D$ 的唯一方式是，没有抽到任何 $A B \\mid C D$ 信息列，即 $X_{\\text{corr}} = 0$。因为 $N$ 次抽样中的每一次，抽到 $m_{\\text{corr}}$ 个信息列之一的概率为 $m_{\\text{corr}}/N$，所以某个特定信息列未被抽中的概率是 $(1 - 1/N)^{N} \\approx e^{-1}$，而 $m_{\\text{corr}}$ 个信息列全都没被抽中的概率近似为 $(1 - m_{\\text{corr}}/N)^{N} \\approx e^{-m_{\\text{corr}}}$。因此，\n$$\n\\mathbb{E}[\\hat{s}] \\approx 1 - e^{-m_{\\text{corr}}}.\n$$\n即使对于非常小的 $m_{\\text{corr}}$，这个值也可能具有欺骗性地接近 $1$：对于 $m_{\\text{corr}} = 4$，$1 - e^{-4} \\approx 0.981684$，对于 $m_{\\text{corr}} = 5$，$1 - e^{-5} \\approx 0.993262$。这说明了尽管数据中固有的信息量很弱，但极少数一致的信息位点和几乎没有噪音的情况如何能产生非常高的自举支持率。\n\n算法设计：\n- 对于每个测试用例 $(N, m_{\\text{corr}}, m_{\\text{conf}}, m_{\\text{oth}}, B, \\text{seed})$：\n    1. 使用指定的种子设置伪随机数生成器，以确保可复现性。\n    2. 定义类别概率 $p_{\\text{corr}} = m_{\\text{corr}}/N$，$p_{\\text{conf}} = m_{\\text{conf}}/N$，$p_{\\text{oth}} = m_{\\text{oth}}/N$，$p_{\\text{non}} = 1 - p_{\\text{corr}} - p_{\\text{conf}} - p_{\\text{oth}}$。\n    3. 从多项式分布 $\\mathrm{Multinomial}(N, [p_{\\text{corr}}, p_{\\text{conf}}, p_{\\text{oth}}, p_{\\text{non}}])$ 中抽取 $B$ 个独立的重复样本。\n    4. 对于每个重复，计算 $X_{\\text{corr}}$ 是否严格大于 $X_{\\text{conf}}$ 和 $X_{\\text{oth}}$；如果是，则计为对 $A B \\mid C D$ 的支持。\n    5. 计算支持性重复的比例，作为自举支持率 $\\hat{s}$。\n    6. 将 $\\hat{s}$ 四舍五入到小数点后恰好 $6$ 位。\n\n计算方面的考虑：\n- 可以使用数值库将多项式抽样向量化，即使对于 $B = 20000$ 和 $N = 100$ 的情况，模拟也非常高效。\n- 每个测试用例的时间复杂度是 $O(B)$，由于向量化操作，常数因子很小；临时存储抽样结果的内存是 $O(B)$，对于给定的大小来说是适中的。\n\n测试套件解释与预期：\n- 情况 1 ($N = 100$, $m_{\\text{corr}} = 4$, 无冲突)：根据上述近似，预期的支持率接近 $1 - e^{-4} \\approx 0.981684$，这展示了“自举天堂”现象。\n- 情况 2 ($N = 100$, 无信息位点)：不可能有任何支持；支持率必须为 $0.000000$。\n- 情况 3 ($N = 100$, $m_{\\text{corr}} = 5$, $m_{\\text{conf}} = 1$)：噪音极低；大多数重复将有 $X_{\\text{corr}} > X_{\\text{conf}}$，支持率会很高（接近但略低于无冲突情况的近似值）。\n- 情况 4 ($N = 100$, $m_{\\text{corr}} = 3$, $m_{\\text{conf}} = 3$)：两种竞争性分裂的计数平均上是平衡的；支持率将接近 $0.5$，但会因 $X_{\\text{corr}} = X_{\\text{conf}}$ 的平局概率而降低，这种情况被视为未解决。\n\n最终程序精确地实现了这个算法，使用了指定的种子，并将四个支持率以方括号括起的逗号分隔列表形式单行打印，每个值都四舍五入到小数点后 6 位。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef bootstrap_support(N: int, m_corr: int, m_conf: int, m_oth: int, B: int, seed: int) -> float:\n    \"\"\"\n    Compute bootstrap support for the AB|CD split under maximum parsimony\n    given counts of site categories, using multinomial resampling.\n\n    Parameters:\n        N      : alignment length (number of columns)\n        m_corr : number of AB|CD-informative columns (supports focal split)\n        m_conf : number of AC|BD-informative columns (conflicting split)\n        m_oth  : number of AD|BC-informative columns (other split)\n        B      : number of bootstrap replicates\n        seed   : RNG seed for reproducibility\n\n    Returns:\n        support proportion as a float (not percentage)\n    \"\"\"\n    # Category probabilities for multinomial sampling\n    p_corr = m_corr / N\n    p_conf = m_conf / N\n    p_oth = m_oth / N\n    p_non = 1.0 - (p_corr + p_conf + p_oth)\n    # Guard for numerical drift\n    if p_non  0 and not np.isclose(p_non, 0):\n        raise ValueError(\"Sum of informative sites exceeds N.\")\n    p_non = max(0, p_non) # ensure non-negative\n    pvals = np.array([p_corr, p_conf, p_oth, p_non], dtype=float)\n    pvals /= pvals.sum() # ensure sum is exactly 1\n\n    rng = np.random.default_rng(seed)\n    # Draw B multinomial samples: shape (B, 4)\n    counts = rng.multinomial(n=N, pvals=pvals, size=B)\n    # Extract counts for the three informative categories\n    X_corr = counts[:, 0]\n    X_conf = counts[:, 1]\n    X_oth = counts[:, 2]\n\n    # Determine unique maximum among the three categories\n    # Compute maximum and count how many attain it\n    max_vals = np.maximum.reduce([X_corr, X_conf, X_oth])\n    is_max_corr = (X_corr == max_vals)\n    is_max_conf = (X_conf == max_vals)\n    is_max_oth = (X_oth == max_vals)\n    # Count of categories attaining the maximum per replicate\n    max_ties = (is_max_corr.astype(int) +\n                is_max_conf.astype(int) +\n                is_max_oth.astype(int))\n\n    # Unique winner mask (no ties)\n    unique_winner = (max_ties == 1)\n    # Among unique winners, check if AB|CD (corr) is the winner\n    support_mask = unique_winner  is_max_corr\n\n    support = support_mask.mean()\n    return float(support)\n\ndef solve():\n    # Define the test cases from the problem statement: (N, m_corr, m_conf, m_oth, B, seed)\n    B = 20000\n    test_cases = [\n        (100, 4, 0, 0, B, 1),  # Bootstrap paradise: few informative, no noise\n        (100, 0, 0, 0, B, 2),  # Boundary: no informative sites\n        (100, 5, 1, 0, B, 3),  # Very low noise\n        (100, 3, 3, 0, B, 4),  # Balanced conflicting signal\n    ]\n\n    results = []\n    for case in test_cases:\n        N, m_corr, m_conf, m_oth, B_rep, seed = case\n        val = bootstrap_support(N, m_corr, m_conf, m_oth, B_rep, seed)\n        results.append(f\"{val:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2377030"}]}