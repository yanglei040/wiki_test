{"hands_on_practices": [{"introduction": "L-BFGS 算法的核心思想是利用最近几次迭代的信息来近似目标函数的曲率，从而避免了计算和存储庞大的 Hessian 矩阵。这些关键信息被编码成向量对 $(s_k, y_k)$，其中 $s_k$ 代表位置的变化，而 $y_k$ 代表梯度的变化。通过这个练习 [@problem_id:2184596]，你将亲手计算这些基本的构建模块，从而为理解算法如何“学习”函数几何特性打下坚实的基础。", "problem": "您正在分析有限内存Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) 算法的行为，这是一种流行的用于无约束优化的拟牛顿法。该算法通过存储最近的 $m$ 对向量 $(s_k, y_k)$ 来构建逆Hessian矩阵的近似。其中，$x_k$ 是第 $k$ 步的迭代点，$s_k = x_{k+1} - x_k$ 是位移向量，$y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$ 是某个目标函数 $f(x)$ 的梯度向量的变化量。\n\n考虑对二维凸二次函数 $f(x) = f(x_1, x_2) = (x_1 - 2)^2 + 3(x_2 + 1)^2$ 进行优化。一个优化程序生成了以下由三个迭代点（位置向量）组成的序列：\n$$\nx_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\quad x_1 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}, \\quad x_2 = \\begin{pmatrix} 2 \\\\ -1.5 \\end{pmatrix}\n$$\n计算L-BFGS算法会基于此迭代序列存储的两对历史向量 $(s_0, y_0)$ 和 $(s_1, y_1)$。\n\n将您的答案表示为一个 $2 \\times 4$ 的矩阵，其中各列按特定顺序分别代表向量 $s_0$、$y_0$、$s_1$ 和 $y_1$。对任何非整数值使用分数表示。", "solution": "目标是计算当 $k=0$ 和 $k=1$ 时的位移向量 $s_k = x_{k+1} - x_k$ 和梯度差分向量 $y_k = \\nabla f(x_{k+1}) - \\nabla f(x_k)$。\n\n首先，我们需要求出目标函数 $f(x_1, x_2) = (x_1 - 2)^2 + 3(x_2 + 1)^2$ 的梯度。偏导数如下：\n$$\n\\frac{\\partial f}{\\partial x_1} = 2(x_1 - 2)\n$$\n$$\n\\frac{\\partial f}{\\partial x_2} = 3 \\cdot 2(x_2 + 1) = 6(x_2 + 1)\n$$\n因此，梯度向量为：\n$$\n\\nabla f(x_1, x_2) = \\begin{pmatrix} 2(x_1 - 2) \\\\ 6(x_2 + 1) \\end{pmatrix}\n$$\n\n接下来，我们计算在给定的每个迭代点 $x_0$、$x_1$ 和 $x_2$ 处的梯度。我们将这些梯度记为 $g_0$、$g_1$ 和 $g_2$。\n\n对于 $x_0 = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$：\n$$\ng_0 = \\nabla f(0, 0) = \\begin{pmatrix} 2(0 - 2) \\\\ 6(0 + 1) \\end{pmatrix} = \\begin{pmatrix} -4 \\\\ 6 \\end{pmatrix}\n$$\n\n对于 $x_1 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$：\n$$\ng_1 = \\nabla f(1, -2) = \\begin{pmatrix} 2(1 - 2) \\\\ 6(-2 + 1) \\end{pmatrix} = \\begin{pmatrix} 2(-1) \\\\ 6(-1) \\end{pmatrix} = \\begin{pmatrix} -2 \\\\ -6 \\end{pmatrix}\n$$\n\n对于 $x_2 = \\begin{pmatrix} 2 \\\\ -1.5 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -\\frac{3}{2} \\end{pmatrix}$：\n$$\ng_2 = \\nabla f(2, -1.5) = \\begin{pmatrix} 2(2 - 2) \\\\ 6(-1.5 + 1) \\end{pmatrix} = \\begin{pmatrix} 2(0) \\\\ 6(-0.5) \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix}\n$$\n\n现在我们可以计算位移向量 $s_0$ 和 $s_1$。\n\n对于 $k=0$：\n$$\ns_0 = x_1 - x_0 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} - \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}\n$$\n\n对于 $k=1$：\n$$\ns_1 = x_2 - x_1 = \\begin{pmatrix} 2 \\\\ -1.5 \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} 2 - 1 \\\\ -1.5 - (-2) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0.5 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\frac{1}{2} \\end{pmatrix}\n$$\n\n接下来，我们计算梯度差分向量 $y_0$ 和 $y_1$。\n\n对于 $k=0$：\n$$\ny_0 = g_1 - g_0 = \\begin{pmatrix} -2 \\\\ -6 \\end{pmatrix} - \\begin{pmatrix} -4 \\\\ 6 \\end{pmatrix} = \\begin{pmatrix} -2 - (-4) \\\\ -6 - 6 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -12 \\end{pmatrix}\n$$\n\n对于 $k=1$：\n$$\ny_1 = g_2 - g_1 = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} - \\begin{pmatrix} -2 \\\\ -6 \\end{pmatrix} = \\begin{pmatrix} 0 - (-2) \\\\ -3 - (-6) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}\n$$\n\n最后，我们将结果组合成一个 $2 \\times 4$ 的矩阵，其中各列分别为 $s_0, y_0, s_1, y_1$。\n$$\ns_0 = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}, \\quad y_0 = \\begin{pmatrix} 2 \\\\ -12 \\end{pmatrix}, \\quad s_1 = \\begin{pmatrix} 1 \\\\ \\frac{1}{2} \\end{pmatrix}, \\quad y_1 = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}\n$$\n得到的矩阵是：\n$$\n\\begin{pmatrix} 1  2  1  2 \\\\ -2  -12  \\frac{1}{2}  3 \\end{pmatrix}\n$$", "answer": "$$\n\\boxed{\\begin{pmatrix} 1  2  1  2 \\\\ -2  -12  \\frac{1}{2}  3 \\end{pmatrix}}\n$$", "id": "2184596"}, {"introduction": "在存储了历史向量 $(s_k, y_k)$ 之后，L-BFGS 算法必须利用它们来生成新的搜索方向。这一过程是通过一个高效且不涉及矩阵求逆的巧妙算法——双循环递归（two-loop recursion）——来完成的。这个练习 [@problem_id:2184578] 将引导你逐步完成双循环递归的计算，让你清晰地看到算法如何仅通过一系列向量运算，就能得到一个蕴含了二阶信息的优化搜索方向。", "problem": "有限内存Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) 算法是一种流行的用于无约束优化的拟牛顿法。在每次迭代 $k$ 中，该算法通过将逆Hessian矩阵的近似应用于当前梯度 $g_k = \\nabla f(x_k)$ 的负值来计算搜索方向 $p_k$。这个近似是使用最近 $m$ 步的有限历史隐式构造的。\n\n历史数据以向量对 $(s_i, y_i)$ 的形式存储，其中 $i=k-m, \\dots, k-1$，$s_i = x_{i+1} - x_i$ 是位置的变化量，$y_i = g_{i+1} - g_i$ 是梯度的变化量。然后通过一个称为L-BFGS双循环递归的过程找到搜索方向 $p_k$。\n\n考虑在步骤 $k$ 进行一次L-BFGS更新，内存大小为 $m=2$。从先前步骤中获得的相关数据如下：\n- 当前梯度: $g_k = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$\n- 来自步骤 $k-1$ 的历史数据: $s_{k-1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$, $y_{k-1} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$\n- 来自步骤 $k-2$ 的历史数据: $s_{k-2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}$, $y_{k-2} = \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix}$\n\n您的任务是计算本次迭代的搜索方向向量 $p_k$。请将您的答案表示为一个包含精确有理数分量的 $2 \\times 1$ 列向量。", "solution": "L-BFGS的搜索方向 $p_k$ 是通过近似计算乘积 $-H_k g_k$ 得到的，其中 $H_k$ 是逆Hessian矩阵的近似。这可以通过双循环递归算法高效地实现。我们已知 $m=2$，梯度 $g_k$，以及历史向量 $(s_{k-1}, y_{k-1})$ 和 $(s_{k-2}, y_{k-2})$。\n\n算法如下：\n\n1.  用当前梯度初始化向量 $q$：\n    $q = g_k = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix}$。\n\n2.  **第一个循环（向后传递）：** 此循环从 $i = k-1$ 向下迭代到 $i = k-m$。在我们的例子中，$i$ 从 $k-1$ 到 $k-2$。\n    我们首先预先计算标量 $\\rho_i = \\frac{1}{y_i^T s_i}$。\n    对于 $i = k-1$：\n    $y_{k-1}^T s_{k-1} = \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = (1)(1) + (1)(0) = 1$。\n    因此，$\\rho_{k-1} = \\frac{1}{1} = 1$。\n\n    对于 $i = k-2$：\n    $y_{k-2}^T s_{k-2} = \\begin{pmatrix} -1  2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} = (-1)(0) + (2)(1) = 2$。\n    因此，$\\rho_{k-2} = \\frac{1}{2}$。\n\n    现在，我们执行循环更新。我们还将存储计算出的 $\\alpha_i$ 值，因为它们在第二个循环中需要用到。\n    -   **对于 $i = k-1$**：\n        $\\alpha_{k-1} = \\rho_{k-1} s_{k-1}^T q = (1) \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} = (1)((1)(1) + (0)(-2)) = 1$。\n        $q \\leftarrow q - \\alpha_{k-1} y_{k-1} = \\begin{pmatrix} 1 \\\\ -2 \\end{pmatrix} - (1) \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1-1 \\\\ -2-1 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix}$。\n\n    -   **对于 $i = k-2$**：\n        $\\alpha_{k-2} = \\rho_{k-2} s_{k-2}^T q = \\left(\\frac{1}{2}\\right) \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} = \\left(\\frac{1}{2}\\right)((0)(0) + (1)(-3)) = -\\frac{3}{2}$。\n        $q \\leftarrow q - \\alpha_{k-2} y_{k-2} = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} - \\left(-\\frac{3}{2}\\right) \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ -3 \\end{pmatrix} + \\frac{3}{2} \\begin{pmatrix} -1 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 0 - \\frac{3}{2} \\\\ -3 + 3 \\end{pmatrix} = \\begin{pmatrix} -\\frac{3}{2} \\\\ 0 \\end{pmatrix}$。\n\n3.  **初始Hessian缩放：** 初始逆Hessian近似 $H_k^0$ 是一个对角矩阵 $\\gamma_k I$，其中 $\\gamma_k = \\frac{s_{k-1}^T y_{k-1}}{y_{k-1}^T y_{k-1}}$。我们通过将这个缩放后的单位矩阵与当前的 $q$ 相乘来初始化我们的结果向量 $r$。\n    $s_{k-1}^T y_{k-1} = (1)(1) + (0)(1) = 1$。\n    $y_{k-1}^T y_{k-1} = (1)^2 + (1)^2 = 2$。\n    $\\gamma_k = \\frac{1}{2}$。\n    $r = \\gamma_k q = \\frac{1}{2} \\begin{pmatrix} -\\frac{3}{2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -\\frac{3}{4} \\\\ 0 \\end{pmatrix}$。\n\n4.  **第二个循环（向前传递）：** 此循环从 $i = k-m$ 向上迭代到 $i = k-1$。在我们的例子中，$i$ 从 $k-2$ 到 $k-1$。\n    -   **对于 $i = k-2$**：\n        $\\beta = \\rho_{k-2} y_{k-2}^T r = \\left(\\frac{1}{2}\\right) \\begin{pmatrix} -1  2 \\end{pmatrix} \\begin{pmatrix} -\\frac{3}{4} \\\\ 0 \\end{pmatrix} = \\left(\\frac{1}{2}\\right)((-1)(-\\frac{3}{4}) + (2)(0)) = \\frac{3}{8}$。\n        $r \\leftarrow r + s_{k-2} (\\alpha_{k-2} - \\beta) = \\begin{pmatrix} -\\frac{3}{4} \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\left(-\\frac{3}{2} - \\frac{3}{8}\\right) = \\begin{pmatrix} -\\frac{3}{4} \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix} \\left(-\\frac{12}{8} - \\frac{3}{8}\\right) = \\begin{pmatrix} -\\frac{3}{4} \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ -\\frac{15}{8} \\end{pmatrix} = \\begin{pmatrix} -\\frac{6}{8} \\\\ -\\frac{15}{8} \\end{pmatrix}$。\n\n    -   **对于 $i = k-1$**：\n        $\\beta = \\rho_{k-1} y_{k-1}^T r = (1) \\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} -\\frac{6}{8} \\\\ -\\frac{15}{8} \\end{pmatrix} = (1)(-\\frac{6}{8}) + (1)(-\\frac{15}{8}) = -\\frac{21}{8}$。\n        $r \\leftarrow r + s_{k-1} (\\alpha_{k-1} - \\beta) = \\begin{pmatrix} -\\frac{6}{8} \\\\ -\\frac{15}{8} \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\left(1 - \\left(-\\frac{21}{8}\\right)\\right) = \\begin{pmatrix} -\\frac{6}{8} \\\\ -\\frac{15}{8} \\end{pmatrix} + \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} \\left(\\frac{8}{8} + \\frac{21}{8}\\right) = \\begin{pmatrix} -\\frac{6}{8} \\\\ -\\frac{15}{8} \\end{pmatrix} + \\begin{pmatrix} \\frac{29}{8} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{23}{8} \\\\ -\\frac{15}{8} \\end{pmatrix}$。\n\n5.  双循环递归的最终结果是向量 $r = H_k g_k$。搜索方向是 $p_k = -r$。\n    $p_k = - \\begin{pmatrix} \\frac{23}{8} \\\\ -\\frac{15}{8} \\end{pmatrix} = \\begin{pmatrix} -\\frac{23}{8} \\\\ \\frac{15}{8} \\end{pmatrix}$。", "answer": "$$\\boxed{\\begin{pmatrix} -\\frac{23}{8} \\\\ \\frac{15}{8} \\end{pmatrix}}$$", "id": "2184578"}, {"introduction": "我们已经学习了 L-BFGS 的基本构件和核心机制，但它相比于更简单的最速下降法究竟有何优势？最速下降法仅仅沿着负梯度方向进行搜索，而 L-BFGS 则试图走一条更“聪明”的路径。通过这个练习 [@problem_id:2184555]，你将为一个具体的函数计算并比较这两种方法给出的搜索方向，从而直观地感受到 L-BFGS 如何利用历史曲率信息来修正搜索方向，使其更有效地逼近最优点。", "problem": "在数值优化领域，拟牛顿法是寻找函数最小值的常用方法。其中一种方法是限制内存的 Broyden-Fletcher-Goldfarb-Shanno (L-BFGS) 算法，该算法利用有限数量的先前迭代信息来近似逆 Hessian 矩阵。\n\n考虑最小化二次目标函数 $f: \\mathbb{R}^2 \\to \\mathbb{R}$，其定义为：\n$$f(x_1, x_2) = x_1^2 + 4x_2^2$$\n一个优化算法当前位于迭代点 $\\mathbf{x}_1 = (2, -0.5)^T$。前一个迭代点是 $\\mathbf{x}_0 = (4, 1)^T$。我们希望比较两种不同方法在点 $\\mathbf{x}_1$ 处提出的搜索方向。\n\n第一种方法是最速下降法，其搜索方向 $\\mathbf{p}_{\\text{SD}}$ 就是当前点梯度的负方向，即 $\\mathbf{p}_{\\text{SD}} = -\\nabla f(\\mathbf{x}_1)$。\n\n第二种方法是内存为 $m=1$ 的 L-BFGS。在当前迭代点 $\\mathbf{x}_1$ 的搜索方向 $\\mathbf{p}_{\\text{L-BFGS}}$ 计算为 $\\mathbf{p}_{\\text{L-BFGS}} = -\\mathbf{r}$，其中向量 $\\mathbf{r}$ 是通过以下过程（称为双循环递归）得到的结果：\n令 $\\mathbf{g}_1 = \\nabla f(\\mathbf{x}_1)$ 为当前梯度。根据上一步，我们有向量 $\\mathbf{s}_0 = \\mathbf{x}_1 - \\mathbf{x}_0$ 和 $\\mathbf{y}_0 = \\nabla f(\\mathbf{x}_1) - \\nabla f(\\mathbf{x}_0)$。\n1.  初始化临时向量 $\\mathbf{q} \\leftarrow \\mathbf{g}_1$。\n2.  计算标量 $\\rho_0 = \\frac{1}{\\mathbf{y}_0^T \\mathbf{s}_0}$。\n3.  计算标量 $\\alpha_0 = \\rho_0 (\\mathbf{s}_0^T \\mathbf{q})$。\n4.  更新临时向量：$\\mathbf{q} \\leftarrow \\mathbf{q} - \\alpha_0 \\mathbf{y}_0$。\n5.  计算初始 Hessian 缩放因子 $\\gamma_0 = \\frac{\\mathbf{s}_0^T \\mathbf{y}_0}{\\mathbf{y}_0^T \\mathbf{y}_0}$。\n6.  初始化结果向量 $\\mathbf{r} \\leftarrow \\gamma_0 \\mathbf{q}$。\n7.  计算标量 $\\beta_0 = \\rho_0 (\\mathbf{y}_0^T \\mathbf{r})$。\n8.  更新结果向量：$\\mathbf{r} \\leftarrow \\mathbf{r} + (\\alpha_0 - \\beta_0) \\mathbf{s}_0$。\n\n你的任务是计算在点 $\\mathbf{x}_1$ 处，最速下降搜索方向 $\\mathbf{p}_{\\text{SD}}$ 与 L-BFGS 搜索方向 $\\mathbf{p}_{\\text{L-BFGS}}$ 之间夹角 $\\theta$ 的余弦值。将你的答案以数值形式报告，并四舍五入到四位有效数字。", "solution": "目标函数为 $f(x_{1},x_{2})=x_{1}^{2}+4x_{2}^{2}$，所以梯度为 $\\nabla f(x_{1},x_{2})=(2x_{1},\\,8x_{2})^{T}$。\n\n在 $\\mathbf{x}_{0}=(4,1)^{T}$ 处，梯度为 $\\mathbf{g}_{0}=\\nabla f(\\mathbf{x}_{0})=(8,8)^{T}$。在 $\\mathbf{x}_{1}=(2,-0.5)^{T}$ 处，梯度为 $\\mathbf{g}_{1}=\\nabla f(\\mathbf{x}_{1})=(4,-4)^{T}$。\n\n在 $\\mathbf{x}_{1}$ 处的最速下降方向是\n$$\n\\mathbf{p}_{\\text{SD}}=-\\mathbf{g}_{1}=(-4,\\,4)^{T}.\n$$\n\n对于内存为 $m=1$ 的 L-BFGS，定义 $\\mathbf{s}_{0}=\\mathbf{x}_{1}-\\mathbf{x}_{0}=(-2,\\,-\\tfrac{3}{2})^{T}$ 和 $\\mathbf{y}_{0}=\\mathbf{g}_{1}-\\mathbf{g}_{0}=(-4,\\,-12)^{T}$。计算\n$$\n\\mathbf{y}_{0}^{T}\\mathbf{s}_{0}=(-4)(-2)+(-12)\\!\\left(-\\tfrac{3}{2}\\right)=26,\\qquad \\rho_{0}=\\frac{1}{\\mathbf{y}_{0}^{T}\\mathbf{s}_{0}}=\\frac{1}{26}.\n$$\n初始化 $\\mathbf{q}\\leftarrow\\mathbf{g}_{1}=(4,-4)^{T}$ 并计算\n$$\n\\alpha_{0}=\\rho_{0}(\\mathbf{s}_{0}^{T}\\mathbf{q})=\\frac{1}{26}\\big[(-2)(4)+\\left(-\\tfrac{3}{2}\\right)(-4)\\big]=-\\frac{1}{13}.\n$$\n更新\n$$\n\\mathbf{q}\\leftarrow \\mathbf{q}-\\alpha_{0}\\mathbf{y}_{0}=(4,-4)^{T}-\\left(-\\frac{1}{13}\\right)(-4,-12)^{T}=\\left(\\frac{48}{13},\\,-\\frac{64}{13}\\right)^{T}.\n$$\n计算缩放因子\n$$\n\\gamma_{0}=\\frac{\\mathbf{s}_{0}^{T}\\mathbf{y}_{0}}{\\mathbf{y}_{0}^{T}\\mathbf{y}_{0}}=\\frac{26}{16+144}=\\frac{13}{80},\n$$\n并初始化\n$$\n\\mathbf{r}\\leftarrow \\gamma_{0}\\mathbf{q}=\\frac{13}{80}\\left(\\frac{48}{13},\\,-\\frac{64}{13}\\right)^{T}=\\left(\\frac{3}{5},\\,-\\frac{4}{5}\\right)^{T}.\n$$\n然后\n$$\n\\beta_{0}=\\rho_{0}(\\mathbf{y}_{0}^{T}\\mathbf{r})=\\frac{1}{26}\\left[(-4)\\!\\left(\\frac{3}{5}\\right)+(-12)\\!\\left(-\\frac{4}{5}\\right)\\right]=\\frac{18}{65}.\n$$\n更新\n$$\n\\mathbf{r}\\leftarrow \\mathbf{r}+(\\alpha_{0}-\\beta_{0})\\mathbf{s}_{0}=\\left(\\frac{3}{5},-\\frac{4}{5}\\right)^{T}+\\left(-\\frac{1}{13}-\\frac{18}{65}\\right)\\!\\left(-2,-\\frac{3}{2}\\right)^{T}=\\left(\\frac{17}{13},-\\frac{7}{26}\\right)^{T}.\n$$\n因此 L-BFGS 方向是\n$$\n\\mathbf{p}_{\\text{L-BFGS}}=-\\mathbf{r}=\\left(-\\frac{17}{13},\\,\\frac{7}{26}\\right)^{T}.\n$$\n\n$\\mathbf{p}_{\\text{SD}}$ 和 $\\mathbf{p}_{\\text{L-BFGS}}$ 之间夹角的余弦值为\n$$\n\\cos\\theta=\\frac{\\mathbf{p}_{\\text{SD}}^{T}\\mathbf{p}_{\\text{L-BFGS}}}{\\|\\mathbf{p}_{\\text{SD}}\\|\\,\\|\\mathbf{p}_{\\text{L-BFGS}}\\|}.\n$$\n计算分子和范数：\n$$\n\\mathbf{p}_{\\text{SD}}^{T}\\mathbf{p}_{\\text{L-BFGS}}=(-4,4)\\cdot\\left(-\\frac{17}{13},\\frac{7}{26}\\right)=\\frac{82}{13},\n$$\n$$\n\\|\\mathbf{p}_{\\text{SD}}\\|=\\sqrt{(-4)^{2}+4^{2}}=4\\sqrt{2},\\qquad\n\\|\\mathbf{p}_{\\text{L-BFGS}}\\|=\\sqrt{\\left(-\\frac{17}{13}\\right)^{2}+\\left(\\frac{7}{26}\\right)^{2}}=\\frac{\\sqrt{1205}}{26}.\n$$\n因此\n$$\n\\cos\\theta=\\frac{\\frac{82}{13}}{4\\sqrt{2}\\,\\frac{\\sqrt{1205}}{26}}\n=\\frac{41}{\\sqrt{2410}}.\n$$\n数值上，$\\cos\\theta=\\frac{41}{\\sqrt{2410}}\\approx 0.8352$（四舍五入到四位有效数字）。", "answer": "$$\\boxed{0.8352}$$", "id": "2184555"}]}