{"hands_on_practices": [{"introduction": "在任何最小二乘优化问题中，第一步都是量化模型预测与实际数据之间的“误差”或“失配”。这个误差由残差向量捕捉，而高斯-牛顿法的目标正是最小化这些残差的平方和。通过这个练习[@problem_id:2214281]，你将实践计算这个基本量，为理解整个优化过程打下坚实的基础。", "problem": "在非线性最小二乘拟合的背景下，一个常见的任务是最小化残差平方和。考虑一个描述某种物理现象的模型，由函数 $f(x, \\beta) = \\beta_1 \\sqrt{x} + \\beta_2$ 给出，其中 $\\beta = (\\beta_1, \\beta_2)^T$ 是待确定的参数向量。\n\n一次实验得到两个数据点 $(x_i, y_i)$：第一个点是 $(4, 5)$，第二个点是 $(9, 7)$。\n\n第 $i$ 个数据点的残差定义为 $r_i(\\beta) = y_i - f(x_i, \\beta)$。残差向量 $r(\\beta)$ 是一个列向量，其分量是各个残差 $r_i(\\beta)$。\n\n给定参数的初始估计值 $\\beta^{(0)} = (1, 3)^T$，计算相应的残差向量 $r(\\beta^{(0)})$。将你的最终答案表示为一个包含两个元素的行矩阵，这两个元素对应于残差向量的分量。", "solution": "给定模型 $f(x,\\beta)=\\beta_{1}\\sqrt{x}+\\beta_{2}$，残差 $r_{i}(\\beta)=y_{i}-f(x_{i},\\beta)$，数据点 $(x_{1},y_{1})=(4,5)$ 和 $(x_{2},y_{2})=(9,7)$，以及初始估计值 $\\beta^{(0)}=(\\beta_{1}^{(0)},\\beta_{2}^{(0)})^{T}=(1,3)^{T}$。\n\n使用 $\\beta^{(0)}$ 计算在给定 $x_{i}$ 处的模型预测值：\n$$\nf(x_{1},\\beta^{(0)})=\\beta_{1}^{(0)}\\sqrt{x_{1}}+\\beta_{2}^{(0)}=1\\cdot\\sqrt{4}+3=2+3=5,\n$$\n$$\nf(x_{2},\\beta^{(0)})=\\beta_{1}^{(0)}\\sqrt{x_{2}}+\\beta_{2}^{(0)}=1\\cdot\\sqrt{9}+3=3+3=6.\n$$\n\n计算残差：\n$$\nr_{1}(\\beta^{(0)})=y_{1}-f(x_{1},\\beta^{(0)})=5-5=0,\n$$\n$$\nr_{2}(\\beta^{(0)})=y_{2}-f(x_{2},\\beta^{(0)})=7-6=1.\n$$\n\n因此，残差向量的分量为 $0$ 和 $1$。表示为一个包含两个元素的行矩阵，即 $\\begin{pmatrix}0  1\\end{pmatrix}$。", "answer": "$$\\boxed{\\begin{pmatrix}0  1\\end{pmatrix}}$$", "id": "2214281"}, {"introduction": "理解了残差之后，下一步就是观察高斯-牛顿法的实际运作。这个练习[@problem_id:2214282]将带你完整地执行一个更新步骤，这不仅需要计算残差，还需要计算雅可比矩阵——它衡量了模型对参数变化的敏感度。通过这个实践，你将揭开该算法核心迭代过程的神秘面纱。", "problem": "在一个实验研究中，某个物理过程由函数 $y(x) = \\frac{x}{1+ax}$ 建模，其中 $a$ 是一个待确定的未知参数。一位研究人员收集了两个数据点 $(x_i, y_i)$：第一个点是 $(1, 0.5)$，第二个点是 $(2, 0.8)$。\n\n为了在最小二乘意义下找到最佳拟合数据的参数 $a$ 的最优值，该研究人员决定使用高斯-牛顿法。从初始猜测值 $a_0 = 1$ 开始，执行恰好一次高斯-牛顿法迭代，以找到参数的更新估计值，记为 $a_1$。\n\n请将您的答案 $a_1$ 表示为最简精确分数。", "solution": "我们用 $y(x;a)=\\dfrac{x}{1+a x}$ 对数据进行建模。对于残差为 $r_{i}(a)=y(x_{i};a)-y_{i}$ 的最小二乘问题，从 $a_{0}$ 开始对单个参数 $a$ 的高斯-牛顿更新为\n$$\n\\Delta a=-(J^{\\top}J)^{-1}J^{\\top}r,\n$$\n其中 $J_{i}=\\dfrac{\\partial r_{i}}{\\partial a}=\\dfrac{\\partial y(x_{i};a)}{\\partial a}$ 是在 $a_{0}$ 处计算的值，而 $r$ 是在 $a_{0}$ 处计算的残差向量。那么 $a_{1}=a_{0}+\\Delta a$。\n\n首先，计算模型关于 $a$ 的导数。将 $y(x;a)$ 写为 $x(1+a x)^{-1}$，我们得到\n$$\n\\frac{\\partial y}{\\partial a}=-x^{2}(1+a x)^{-2}.\n$$\n\n给定数据点 $(x_{1},y_{1})=(1,\\tfrac{1}{2})$ 和 $(x_{2},y_{2})=(2,\\tfrac{4}{5})$，以及初始猜测值 $a_{0}=1$，雅可比矩阵的元素为\n$$\nJ_{1}=\\left.-\\frac{x_{1}^{2}}{(1+a x_{1})^{2}}\\right|_{a=1}=-\\frac{1}{(1+1)^{2}}=-\\frac{1}{4},\\quad\nJ_{2}=\\left.-\\frac{x_{2}^{2}}{(1+a x_{2})^{2}}\\right|_{a=1}=-\\frac{4}{(1+2)^{2}}=-\\frac{4}{9}.\n$$\n\n在 $a_{0}=1$ 处的残差为\n$$\nr_{1}=y(1;1)-\\frac{1}{2}=\\frac{1}{2}-\\frac{1}{2}=0,\\quad\nr_{2}=y(2;1)-\\frac{4}{5}=\\frac{2}{3}-\\frac{4}{5}=-\\frac{2}{15}.\n$$\n\n计算标量 $J^{\\top}r$ 和 $J^{\\top}J$：\n$$\nJ^{\\top}r=J_{1}r_{1}+J_{2}r_{2}=0+\\left(-\\frac{4}{9}\\right)\\left(-\\frac{2}{15}\\right)=\\frac{8}{135},\n$$\n$$\nJ^{\\top}J=J_{1}^{2}+J_{2}^{2}=\\frac{1}{16}+\\frac{16}{81}=\\frac{81+256}{1296}=\\frac{337}{1296}.\n$$\n\n因此，\n$$\n\\Delta a=-\\frac{J^{\\top}r}{J^{\\top}J}=-\\frac{\\frac{8}{135}}{\\frac{337}{1296}}=-\\frac{8}{135}\\cdot\\frac{1296}{337}=-\\frac{8\\cdot 48}{5\\cdot 337}=-\\frac{384}{1685}.\n$$\n\n所以，更新后的估计值为\n$$\na_{1}=a_{0}+\\Delta a=1-\\frac{384}{1685}=\\frac{1685-384}{1685}=\\frac{1301}{1685}.\n$$", "answer": "$$\\boxed{\\frac{1301}{1685}}$$", "id": "2214282"}, {"introduction": "高斯-牛顿法虽然功能强大，但并非万无一失。这个练习探讨了一个经典场景：算法非但没有收敛，反而陷入了振荡。通过解决这个问题[@problem_id:2214263]，你将对该方法的局限性有更深刻的认识，并理解为何在实际应用中，阻尼或信赖域等更高级的策略是必不可少的。", "problem": "一位工程师正在使用高斯-牛顿算法来求解一个简单的非线性最小二乘问题。目标是将模型 $g(t; x) = A \\arctan(x t)$ 拟合到单个数据点 $(t_1, y_1) = (1, 0)$。待定参数为 $x$，常数 $A$ 固定为 $A=1$。目标是找到使残差平方和 $F(x) = \\frac{1}{2} [g(t_1; x) - y_1]^2$ 最小化的 $x$ 值。该问题的真正最小值显然在 $x = 0$ 处。\n\n然而，当工程师从一个特定的初始猜测值 $x_0 > 0$ 开始应用高斯-牛顿方法时，他们观察到算法未能收敛到最小值。相反，迭代值陷入了一个稳定的2-周期，在初始猜测值 $x_0$ 及其相反数 $-x_0$ 之间永久振荡。\n\n确定导致高斯-牛顿方法立即进入这个2-周期的特定初始猜测值 $x_0$。将你的答案表示为一个四舍五入到四位有效数字的数。", "solution": "模型为 $g(t; x) = \\arctan(x t)$（其中 $A=1$），单个数据点为 $(t_{1}, y_{1}) = (1, 0)$。因此，残差为\n$$\nr(x) = g(1; x) - y_{1} = \\arctan(x).\n$$\n用于最小化 $F(x) = \\frac{1}{2} r(x)^{2}$ 的标量高斯-牛顿步求解线性化的最小二乘问题 $r(x) + J(x) p \\approx 0$，其中 $J(x) = \\frac{dr}{dx}$。因此\n$$\np = -\\frac{r(x)}{J(x)}, \\quad x_{+} = x + p = x - \\frac{r(x)}{J(x)}.\n$$\n这里 $J(x) = \\frac{d}{dx}\\arctan(x) = \\frac{1}{1 + x^{2}}$，所以高斯-牛顿迭代映射为\n$$\nT(x) = x - \\frac{\\arctan(x)}{\\frac{1}{1 + x^{2}}} = x - (1 + x^{2}) \\arctan(x).\n$$\n当 $T(x_{0}) = -x_{0}$ 时，会立即出现一个2-周期 $\\{x_{0}, -x_{0}\\}$，这得到\n$$\n-x_{0} = x_{0} - (1 + x_{0}^{2}) \\arctan(x_{0}) \\;\\;\\Longrightarrow\\;\\; (1 + x_{0}^{2}) \\arctan(x_{0}) = 2 x_{0}.\n$$\n令 $x_{0} = \\tan(\\theta)$，其中 $\\theta \\in (0, \\frac{\\pi}{2})$。使用 $1 + \\tan^{2}(\\theta) = \\sec^{2}(\\theta)$ 和 $\\arctan(\\tan(\\theta)) = \\theta$，方程变为\n$$\n\\sec^{2}(\\theta)\\,\\theta = 2 \\tan(\\theta) \\;\\;\\Longrightarrow\\;\\; \\theta = 2 \\sin(\\theta)\\cos(\\theta) = \\sin(2\\theta).\n$$\n除了平凡解 $\\theta = 0$（对应于 $x=0$），在 $(0, \\frac{\\pi}{2})$ 中的唯一非零解满足 $\\theta = \\sin(2\\theta)$。数值求解得到\n$$\n\\theta \\approx 0.947745,\n$$\n所以\n$$\nx_{0} = \\tan(\\theta) \\approx 1.391740\\ldots\n$$\n四舍五入到四位有效数字后，得到所需的初始猜测值。", "answer": "$$\\boxed{1.392}$$", "id": "2214263"}]}