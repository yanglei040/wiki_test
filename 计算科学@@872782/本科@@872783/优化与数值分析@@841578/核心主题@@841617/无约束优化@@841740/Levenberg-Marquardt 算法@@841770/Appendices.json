{"hands_on_practices": [{"introduction": "要掌握列文伯格-马夸特（Levenberg-Marquardt, LM）算法，第一步是理解如何量化模型与数据之间的“误差”。这个误差的核心就是残差向量，它代表了模型预测与实际观测值之间的差异。本练习将通过一个常见的几何拟合问题——将圆形拟合到二维平面上的一组数据点，来引导你亲手计算残差，这是构建LM算法中目标函数的基础 [@problem_id:2217008]。", "problem": "优化中的一个常见任务是将几何模型拟合到一组数据点。考虑将一个圆拟合到二维平面上的一组点的问题。该圆由一个参数向量 $\\mathbf{p} = [x_c, y_c, R]^T$ 定义，其中 $(x_c, y_c)$ 是圆心，而 $R$ 是其半径。\n\n对于一组 $n$ 个数据点 $(x_i, y_i)$，非线性最小二乘拟合的目标是找到参数向量 $\\mathbf{p}$，使得残差平方和最小。第 $i$ 个数据点的残差 $r_i(\\mathbf{p})$ 定义为该点到拟议圆心 $(x_c, y_c)$ 的距离与拟议半径 $R$ 之间的差值。\n\n给定三个数据点，代表笛卡尔坐标系中的测量值，所有坐标的单位均为米：\n$P_1 = (1.0, 7.0)$\n$P_2 = (6.0, 2.0)$\n$P_3 = (9.0, 8.0)$\n\n一个迭代优化算法，例如 Levenberg-Marquardt 算法，从参数的初始猜测值开始。圆的参数初始猜测值给定为 $\\mathbf{p}_0 = [x_{c,0}, y_{c,0}, R_0]^T = [5.0, 5.0, 4.0]^T$。\n\n计算此初始猜测值的残差向量 $\\mathbf{r}(\\mathbf{p}_0) = [r_1(\\mathbf{p}_0), r_2(\\mathbf{p}_0), r_3(\\mathbf{p}_0)]^T$。将所得向量的每个分量以米为单位表示，并四舍五入到四位有效数字。将最终答案表示为单个行矩阵。", "solution": "对于参数为 $\\mathbf{p} = [x_{c}, y_{c}, R]^{T}$ 的圆和一个数据点 $(x_{i}, y_{i})$，残差定义为该点到圆心的欧几里得距离与半径之差：\n$$\nr_{i}(\\mathbf{p}) = \\sqrt{(x_{i} - x_{c})^{2} + (y_{i} - y_{c})^{2}} - R.\n$$\n根据初始猜测值 $\\mathbf{p}_{0} = [5.0, 5.0, 4.0]^{T}$，计算每个残差。\n\n对于 $P_{1} = (1.0, 7.0)$：\n$$\nd_{1} = \\sqrt{(1.0 - 5.0)^{2} + (7.0 - 5.0)^{2}} = \\sqrt{(-4.0)^{2} + (2.0)^{2}} = \\sqrt{16 + 4} = \\sqrt{20} \\approx 4.4721,\n$$\n$$\nr_{1}(\\mathbf{p}_{0}) = 4.4721 - 4.0 = 0.4721 \\text{ m}.\n$$\n\n对于 $P_{2} = (6.0, 2.0)$：\n$$\nd_{2} = \\sqrt{(6.0 - 5.0)^{2} + (2.0 - 5.0)^{2}} = \\sqrt{(1.0)^{2} + (-3.0)^{2}} = \\sqrt{1 + 9} = \\sqrt{10} \\approx 3.1623,\n$$\n$$\nr_{2}(\\mathbf{p}_{0}) = 3.1623 - 4.0 = -0.8377 \\text{ m}.\n$$\n\n对于 $P_{3} = (9.0, 8.0)$：\n$$\nd_{3} = \\sqrt{(9.0 - 5.0)^{2} + (8.0 - 5.0)^{2}} = \\sqrt{(4.0)^{2} + (3.0)^{2}} = \\sqrt{16 + 9} = \\sqrt{25} = 5.0,\n$$\n$$\nr_{3}(\\mathbf{p}_{0}) = 5.0 - 4.0 = 1.000 \\text{ m}.\n$$\n\n将结果四舍五入到四位有效数字后，残差向量表示为行矩阵为：\n$$\n\\begin{pmatrix}\n0.4721  -0.8377  1.000\n\\end{pmatrix}.\n$$", "answer": "$$\\boxed{\\begin{pmatrix} 0.4721   -0.8377  1.000 \\end{pmatrix}}$$", "id": "2217008"}, {"introduction": "定义了误差之后，下一步我们需要知道当调整模型参数时，误差会如何变化。这正是雅可比矩阵（Jacobian matrix）的作用，它描述了模型对每个参数的局部敏感度。本练习将指导你为一个非线性有理函数模型计算雅可比矩阵，这是构建LM算法核心方程 $(J^T J + \\lambda I) p = -J^T r$ 的关键一步 [@problem_id:2217052]。", "problem": "在非线性优化领域，像Levenberg-Marquardt算法这样的算法通过最小化残差平方和，将模型函数拟合到一组数据点。此过程中的一个关键组成部分是雅可比矩阵。\n\n考虑一个用于描述物质浓度随时间变化的模型，该模型由以下双参数有理函数给出：\n$$f(t; a, b) = \\frac{a}{1 + bt}$$\n其中 $t$ 是自变量（例如，时间），而 $\\mathbf{p} = [a, b]^T$ 是待确定的参数向量。\n\n假设我们收集了以下三个数据点 $(t_i, y_i)$：\n- $(t_1, y_1) = (1.0, 2.5)$\n- $(t_2, y_2) = (2.0, 1.8)$\n- $(t_3, y_3) = (4.0, 1.1)$\n\n对于这个拟合问题，雅可比矩阵 $\\mathbf{J}$ 是一个 $m \\times n$ 矩阵，其中 $m$ 是数据点的数量，$n$ 是参数的数量。为了与正文中的定义保持一致，其元素定义为残差对参数的偏导数：$J_{ij} = \\frac{\\partial r_i(\\mathbf{p})}{\\partial p_j}$，其中残差 $r_i(\\mathbf{p}) = y_i - f(t_i; \\mathbf{p})$。\n\n计算雅可比矩阵 $\\mathbf{J}$ 在初始参数猜测值 $\\mathbf{p}_0 = [a_0, b_0]^T = [3.0, 0.5]^T$ 处的数值。所有给定的数值都是无量纲的。\n\n将您的最终答案表示为一个 $3 \\times 2$ 矩阵，每个元素四舍五入到三位有效数字。", "solution": "根据问题定义，雅可比矩阵的元素为 $J_{ij} = \\frac{\\partial r_i(\\mathbf{p})}{\\partial p_j}$，其中残差为 $r_i(\\mathbf{p}) = y_i - f(t_i; \\mathbf{p})$，模型函数为 $f(t; a, b) = \\frac{a}{1 + bt}$。\n\n首先，我们以符号方式计算残差关于参数的偏导数。根据链式法则：\n$$\n\\frac{\\partial r_i}{\\partial a} = -\\frac{\\partial f}{\\partial a} = -\\frac{1}{1 + bt_i}\n$$\n$$\n\\frac{\\partial r_i}{\\partial b} = -\\frac{\\partial f}{\\partial b} = - \\left( -\\frac{a t_i}{(1 + bt_i)^{2}} \\right) = \\frac{a t_i}{(1 + bt_i)^{2}}\n$$\n因此，对于每个数据点 $t_{i}$，雅可比矩阵的对应行为：\n$$\n\\left[-\\frac{1}{1 + b t_{i}},\\ \\frac{a t_{i}}{(1 + b t_{i})^{2}}\\right]\n$$\n现在，在初始猜测值 $\\mathbf{p}_{0} = [a_{0}, b_{0}]^{T} = [3.0, 0.5]^{T}$ 和给定的 $t$ 值处进行计算。\n\n对于 $t_{1} = 1.0$：\n$$ \\frac{\\partial r_1}{\\partial a} = -\\frac{1}{1 + 0.5 \\cdot 1.0} = -\\frac{1}{1.5} \\approx -0.667 $$\n$$ \\frac{\\partial r_1}{\\partial b} = \\frac{3.0 \\cdot 1.0}{(1 + 0.5 \\cdot 1.0)^{2}} = \\frac{3.0}{2.25} \\approx 1.33 $$\n\n对于 $t_{2} = 2.0$：\n$$ \\frac{\\partial r_2}{\\partial a} = -\\frac{1}{1 + 0.5 \\cdot 2.0} = -\\frac{1}{2} = -0.500 $$\n$$ \\frac{\\partial r_2}{\\partial b} = \\frac{3.0 \\cdot 2.0}{(1 + 0.5 \\cdot 2.0)^{2}} = \\frac{6.0}{4.0} = 1.50 $$\n\n对于 $t_{3} = 4.0$：\n$$ \\frac{\\partial r_3}{\\partial a} = -\\frac{1}{1 + 0.5 \\cdot 4.0} = -\\frac{1}{3} \\approx -0.333 $$\n$$ \\frac{\\partial r_3}{\\partial b} = \\frac{3.0 \\cdot 4.0}{(1 + 0.5 \\cdot 4.0)^{2}} = \\frac{12.0}{9.0} \\approx 1.33 $$\n\n组合成雅可比矩阵，并将每个元素四舍五入到三位有效数字：\n$$\n\\mathbf{J}(\\mathbf{p}_{0}) \\approx\n\\begin{pmatrix}\n-0.667  1.33 \\\\\n-0.500  1.50 \\\\\n-0.333  1.33\n\\end{pmatrix}\n$$", "answer": "$$\\boxed{\\begin{pmatrix}-0.667  1.33 \\\\ -0.500  1.50 \\\\ -0.333  1.33\\end{pmatrix}}$$", "id": "2217052"}, {"introduction": "当我们拥有了残差向量和雅可比矩阵，就可以计算参数的更新步长。这个最终练习将深入探讨LM更新步长的内在机制。通过分析一个特殊的线性最小二乘问题，你将推导出LM步长与通往精确解的“理想”步长之间的数学关系，从而揭示阻尼参数 $\\lambda$ 是如何巧妙地调节算法行为的 [@problem_id:2216994]。", "problem": "考虑最小化函数平方和的一般问题，$S(x) = \\frac{1}{2} \\sum_{i=1}^{m} [r_i(x)]^2 = \\frac{1}{2}\\|r(x)\\|_2^2$，其中 $x \\in \\mathbb{R}^n$ 是一个参数向量，$r(x) \\in \\mathbb{R}^m$ 是一个残差函数向量。\n\nLevenberg-Marquardt (LM) 算法是求解此类问题的一种迭代方法。从一个初始猜测值 $x_k$ 开始，下一个迭代点 $x_{k+1}$ 通过 $x_{k+1} = x_k + p_k$ 找到，其中更新步长 $p_k$ 是以下线性系统的解：\n$$(J_k^T J_k + \\lambda I) p_k = -J_k^T r_k$$\n此处，$J_k$ 是残差向量 $r(x)$ 在 $x_k$ 处求值的雅可比矩阵，$r_k = r(x_k)$，$I$ 是单位矩阵，$\\lambda  0$ 是一个阻尼参数。\n\n现在，我们来分析一个特殊情况，即优化问题是一个线性最小二乘问题。残差向量由 $r(x) = Ax - b$ 给出，其中 $A$ 是一个满列秩的实 $m \\times n$ 矩阵（$n \\le m$），$b$ 是 $\\mathbb{R}^m$ 中的一个向量。该问题有一个唯一的极小值点，我们将其表示为 $x^*$。\n\n设 $x_0$ 为算法的任意起始点。在单次迭代中达到解所需的精确步长为 $p_{exact} = x^* - x_0$。设 $p_{LM}$ 是 LM 算法从 $x_0$ 开始，使用给定的阻尼参数 $\\lambda$ 计算出的第一个更新步长。\n\n你的任务是推导 LM 步长和精确步长之间的关系。请用矩阵 $A$、阻尼参数 $\\lambda$ 和向量 $p_{exact}$ 来表示向量 $p_{LM}$。", "solution": "我们考虑残差为 $r(x) = Ax - b$ 的线性最小二乘问题。该问题的雅可比矩阵为 $J = \\frac{\\partial r}{\\partial x} = A$。由于 $A \\in \\mathbb{R}^{m \\times n}$ 具有满列秩，因此 $A^{T}A$ 是对称正定且可逆的。唯一极小值点 $x^{*}$ 满足正规方程组：\n$$\nA^{T}(Ax^{*} - b) = 0 \\quad \\Longleftrightarrow \\quad A^{T}A\\,x^{*} = A^{T}b.\n$$\n从任意起始点 $x_{0}$ 开始，Levenberg-Marquardt 步长 $p_{LM}$ 通过求解以下方程得到：\n$$\n(J^T J + \\lambda I)\\,p_{LM} = -J^{T}r_{0}\n$$\n将 $J=A$ 和 $r_0 = Ax_0 - b$ 代入，方程变为：\n$$\n(A^{T}A + \\lambda I)\\,p_{LM} = -A^{T}(Ax_{0} - b) = -A^{T}A\\,x_{0} + A^{T}b.\n$$\n使用正规方程组的结论 $A^{T}b = A^{T}A\\,x^{*}$，上式右侧可以写为：\n$$\n-A^{T}A\\,x_{0} + A^{T}A\\,x^{*} = A^{T}A\\,(x^{*} - x_{0}) = A^{T}A\\,p_{exact}.\n$$\n因此，LM 步长满足以下关系：\n$$\n(A^{T}A + \\lambda I)\\,p_{LM} = A^{T}A\\,p_{exact}.\n$$\n由于当 $\\lambda  0$ 且 $A^T A$ 为半正定矩阵时，$A^{T}A + \\lambda I$ 总是可逆的，我们可以解出 $p_{LM}$：\n$$\np_{LM} = (A^{T}A + \\lambda I)^{-1}A^{T}A\\,p_{exact}.\n$$\n这就将 $p_{LM}$ 用 $A$、$\\lambda$ 和 $p_{exact}$ 表示了出来，符合要求。", "answer": "$$\\boxed{p_{LM} = (A^{T}A+\\lambda I)^{-1}A^{T}A\\,p_{exact}}$$", "id": "2216994"}]}