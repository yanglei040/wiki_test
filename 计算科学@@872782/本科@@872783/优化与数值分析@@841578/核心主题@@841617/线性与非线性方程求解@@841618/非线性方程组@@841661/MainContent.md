## 引言
[非线性方程组](@entry_id:178110)是描述现实世界复杂现象的通用数学语言。从工程设计中的结构平衡，到经济学中的[市场均衡](@entry_id:138207)，再到物理学中的[自洽场](@entry_id:136549)模型，当系统各部分之间的关系不再是简单的线性叠加时，非线性方程便成为不可或缺的建模工具。与[线性系统](@entry_id:147850)不同，这些[方程组](@entry_id:193238)通常无法通过直接代数运算求得精确解，这构成了一个重大的知识鸿沟和计算挑战。因此，开发和理解高效的数值求解方法显得至关重要。

本文旨在系统地介绍[求解非线性方程](@entry_id:177343)组的核心原理、应用与实践。读者将踏上一段从理论到应用的旅程：
- 在“原理与机制”一章中，我们将深入剖析[不动点迭代](@entry_id:749443)、牛顿法及其变体（如拟牛顿法）的数学基础和算法流程，并探讨其收敛性、计算成本和数值稳定性等关键问题。
- 接着，在“应用与跨学科联系”一章中，我们将展示这些数学工具如何在经济学、[化学工程](@entry_id:143883)、[机器人学](@entry_id:150623)和机器学习等多个领域中，用于解决寻找[平衡点](@entry_id:272705)、优化设计和模拟连续系统等实际问题。
- 最后，通过“动手实践”部分，你将有机会亲手应用所学知识，解决具体的数值问题，从而巩固理解并掌握关键的计算技能。

通过这三个章节的学习，你将能够建立起对[非线性系统](@entry_id:168347)求解方法的全面认识，并有能力将其应用于自己的研究或工程实践中。

## 原理与机制

在理解了[非线性方程组](@entry_id:178110)在科学与工程领域的普遍性之后，本章将深入探讨求解这些[方程组](@entry_id:193238)的核心原理与数值方法。与线性系统不同，[非线性系统](@entry_id:168347)通常没有直接的解析解法，因此我们必须依赖于[迭代算法](@entry_id:160288)，从一个初始猜测出发，逐步逼近真实解。我们将从问题的数学表述开始，然后系统地介绍[不动点迭代](@entry_id:749443)、[牛顿法](@entry_id:140116)及其重要的变体和改进。

### 构建非线性方程组

[求解非线性方程](@entry_id:177343)组的第一步是将其形式化。一个包含 $n$ 个变量 $(x_1, x_2, \dots, x_n)$ 和 $n$ 个方程的系统，可以统一表示为一个向量函数 $F: \mathbb{R}^n \to \mathbb{R}^n$ 的[求根问题](@entry_id:174994)：

$F(\mathbf{x}) = \mathbf{0}$

其中 $\mathbf{x} = (x_1, \dots, x_n)^T$ 是变量向量，而 $F(\mathbf{x})$ 是一个分量为各个方程的向量函数：

$F(\mathbf{x}) = \begin{pmatrix} f_1(x_1, \dots, x_n) \\ f_2(x_1, \dots, x_n) \\ \vdots \\ f_n(x_1, \dots, x_n) \end{pmatrix} = \begin{pmatrix} 0 \\ 0 \\ \vdots \\ 0 \end{pmatrix}$

寻找满足此向量方程的 $\mathbf{x}$ 就是我们的目标。

这些[方程组](@entry_id:193238)常常源于几何、物理或经济模型。一个典型的例子是求解几条曲线的交点。例如，在计算机辅助设计中，我们可能需要找到一个[伯努利双纽线](@entry_id:165485) $(x^2+y^2)^2 = 2a^2(x^2-y^2)$ 和一个一般圆 $(x-h)^2 + (y-k)^2 = r^2$ 的交点。交点 $(x, y)$ 必须同时满足这两个方程。为了将其转化为标准的[求根问题](@entry_id:174994)形式，我们将每个方程的所有项移到一边，使其等于零 [@problem_id:2207882]。这样，我们可以定义向量函数 $F(x, y) = \begin{pmatrix} f_1(x,y) & f_2(x,y) \end{pmatrix}^T$，其中：

$f_1(x,y) = (x^2+y^2)^2 - 2a^2(x^2-y^2) = 0$
$f_2(x,y) = (x-h)^2 + (y-k)^2 - r^2 = 0$

这个系统的解，即 $F(x, y) = \mathbf{0}$ 的根，就对应着两条曲线的精确交点。一旦问题被表述为这种标准形式，我们就可以应用各种数值方法来求解。

### [不动点迭代法](@entry_id:168837)

最直观的迭代方法之一是**[不动点迭代法](@entry_id:168837)**。其思想是将[方程组](@entry_id:193238) $F(\mathbf{x}) = \mathbf{0}$ 代数地重排成等价的**[不动点](@entry_id:156394)形式** $\mathbf{x} = G(\mathbf{x})$。一旦得到这样的**迭代函数** $G(\mathbf{x})$，我们就可以从一个初始猜测 $\mathbf{x}_0$ 开始，生成一个序列：

$\mathbf{x}_{k+1} = G(\mathbf{x}_k), \quad k = 0, 1, 2, \dots$

如果这个序列收敛于某个点 $\mathbf{x}^*$，并且函数 $G$ 是连续的，那么[极限点](@entry_id:177089) $\mathbf{x}^*$ 必然满足 $\mathbf{x}^* = G(\mathbf{x}^*)$，因此它就是原[方程组](@entry_id:193238)的一个解。

然而，[不动点迭代](@entry_id:749443)的收敛性并非理所当然，它严重依赖于迭代函数 $G$ 的选择。根据[压缩映射原理](@entry_id:153489)，迭代在解 $\mathbf{x}^*$ 附近局部收敛的一个充分条件是 $G$ 在该点附近的“收缩”程度。对于[多维系统](@entry_id:274301)，这个“收缩”程度由 $G$ 的雅可比矩阵 $J_G(\mathbf{x})$ 的谱半径 $\rho(J_G)$ 来衡量。**谱半径**定义为[矩阵特征值](@entry_id:156365)[绝对值](@entry_id:147688)的最大值。如果在一个包含[不动点](@entry_id:156394) $\mathbf{x}^*$ 的区域内，始终有 $\rho(J_G(\mathbf{x}))  1$，则对于该区域内的任意初始点 $\mathbf{x}_0$，迭代序列都将收敛到 $\mathbf{x}^*$。

值得注意的是，同一个[方程组](@entry_id:193238)可以有多种不同的[不动点](@entry_id:156394)形式。例如，考虑系统 [@problem_id:2207851]：
$x = \exp(-y)$
$y = \cos(x)$

这个系统天然地给出了一种[不动点](@entry_id:156394)形式 $\mathbf{x} = G_1(\mathbf{x})$，其中 $\mathbf{x} = (x, y)^T$ 且 $G_1(x, y) = (\exp(-y), \cos(x))^T$。我们也可以通过反函数将其改写为另一种形式 $\mathbf{x} = G_2(\mathbf{x})$，其中 $G_2(x, y) = (\arccos(y), -\ln(x))^T$。

这两种迭代格式的收敛行为可能截然不同。通过计算它们在某点（例如 $(0.5, 0.9)$）的雅可比矩阵的谱半径，我们可以预测其收敛性。对于 $G_1$，其[雅可比矩阵](@entry_id:264467)为 $J_1(x,y) = \begin{pmatrix} 0  -\exp(-y) \\ -\sin(x)  0 \end{pmatrix}$，在 $(0.5, 0.9)$ 附近的[谱半径](@entry_id:138984) $\rho_1$ 约为 $0.4415$，小于 $1$，预示着良好的局部收敛性。而对于 $G_2$，其[雅可比矩阵](@entry_id:264467)为 $J_2(x,y) = \begin{pmatrix} 0  -1/\sqrt{1-y^2} \\ -1/x  0 \end{pmatrix}$，在同一点的[谱半径](@entry_id:138984) $\rho_2$ 约为 $2.142$，远大于 $1$，预示着迭代会发散。这个例子清楚地表明，[不动点迭代法](@entry_id:168837)的成功与否高度依赖于如何巧妙地构造迭代函数 $G(\mathbf{x})$，这在实践中往往缺乏系统性的指导。

### 牛顿法[求解方程组](@entry_id:152624)

为了克服[不动点迭代法](@entry_id:168837)对函数形式的依赖以及通常较慢的[收敛速度](@entry_id:636873)，**[牛顿法](@entry_id:140116)**提供了一种更强大、更系统化的途径。其核心思想是在当前点 $\mathbf{x}_k$ 附近，用一个[线性模型](@entry_id:178302)来近似[非线性](@entry_id:637147)的函数 $F(\mathbf{x})$。这个[线性模型](@entry_id:178302)是 $F$ 在 $\mathbf{x}_k$ 处的一阶[泰勒展开](@entry_id:145057)：

$F(\mathbf{x}) \approx F(\mathbf{x}_k) + J(\mathbf{x}_k)(\mathbf{x} - \mathbf{x}_k)$

这里的 $J(\mathbf{x}_k)$ 是函数 $F$ 在 $\mathbf{x}_k$ 处的**雅可比矩阵**。雅可比矩阵是 $F$ 的所有一阶[偏导数](@entry_id:146280)构成的矩阵，其第 $i$ 行第 $j$ 列的元素为 $\frac{\partial f_i}{\partial x_j}$。它描述了函数 $F$ 在点 $\mathbf{x}_k$ 附近的[局部线性](@entry_id:266981)行为。

牛顿法的思想是，我们不直接解非线性方程 $F(\mathbf{x}) = \mathbf{0}$，而是解其线性近似方程 $F(\mathbf{x}_k) + J(\mathbf{x}_k)(\mathbf{x} - \mathbf{x}_k) = \mathbf{0}$。我们期望这个[线性模型](@entry_id:178302)的解能比 $\mathbf{x}_k$ 更接近 $F(\mathbf{x})$ 的真实根。我们将这个解定义为下一个迭代点 $\mathbf{x}_{k+1}$。

令**[牛顿步](@entry_id:177069)**或**修正向量**为 $\Delta \mathbf{x}_k = \mathbf{x}_{k+1} - \mathbf{x}_k$。代入上述线性模型并整理，我们得到牛顿法的核心计算步骤：求解一个关于 $\Delta \mathbf{x}_k$ 的线性方程组：

$J(\mathbf{x}_k) \Delta \mathbf{x}_k = -F(\mathbf{x}_k)$

一旦求得 $\Delta \mathbf{x}_k$，新的迭代点就由下式更新：

$\mathbf{x}_{k+1} = \mathbf{x}_k + \Delta \mathbf{x}_k$

这个过程不断重复，直到 $\Delta \mathbf{x}_k$ 或 $F(\mathbf{x}_{k+1})$ 的范数足够小为止。

让我们通过一个具体例子来完整地执行一次牛顿迭代。考虑求解单位圆 $x^2 + y^2 - 1 = 0$ 和抛物线 $y - x^2 = 0$ 的交点 [@problem_id:2207858]。
我们的向量函数为 $F(x,y) = \begin{pmatrix} x^2+y^2-1 \\ y-x^2 \end{pmatrix}$。
其雅可比矩阵为 $J(x,y) = \begin{pmatrix} 2x  2y \\ -2x  1 \end{pmatrix}$。

假设我们的初始猜测是 $\mathbf{x}_0 = \begin{pmatrix} 1 \\ 1 \end{pmatrix}$。迭代步骤如下：
1.  **计算 $F(\mathbf{x}_0)$ 和 $J(\mathbf{x}_0)$**：
    $F(\mathbf{x}_0) = \begin{pmatrix} 1^2+1^2-1 \\ 1-1^2 \end{pmatrix} = \begin{pmatrix} 1 \\ 0 \end{pmatrix}$
    $J(\mathbf{x}_0) = \begin{pmatrix} 2(1)  2(1) \\ -2(1)  1 \end{pmatrix} = \begin{pmatrix} 2  2 \\ -2  1 \end{pmatrix}$
2.  **[求解线性系统](@entry_id:146035) $J(\mathbf{x}_0) \Delta \mathbf{x}_0 = -F(\mathbf{x}_0)$**：
    $\begin{pmatrix} 2  2 \\ -2  1 \end{pmatrix} \begin{pmatrix} \Delta x_0 \\ \Delta y_0 \end{pmatrix} = -\begin{pmatrix} 1 \\ 0 \end{pmatrix} = \begin{pmatrix} -1 \\ 0 \end{pmatrix}$
    解这个 $2 \times 2$ [线性系统](@entry_id:147850)得到 $\Delta x_0 = -1/6$ 和 $\Delta y_0 = -1/3$。因此，$\Delta \mathbf{x}_0 = \begin{pmatrix} -1/6 \\ -1/3 \end{pmatrix}$。
3.  **更新迭代点**：
    $\mathbf{x}_1 = \mathbf{x}_0 + \Delta \mathbf{x}_0 = \begin{pmatrix} 1 \\ 1 \end{pmatrix} + \begin{pmatrix} -1/6 \\ -1/3 \end{pmatrix} = \begin{pmatrix} 5/6 \\ 2/3 \end{pmatrix} \approx \begin{pmatrix} 0.833 \\ 0.667 \end{pmatrix}$。

新的点 $\mathbf{x}_1$ 已经比 $\mathbf{x}_0$ 更接近其中一个真实解 $(\sqrt{(\sqrt{5}-1)/2}, (\sqrt{5}-1)/2) \approx (0.786, 0.618)$。这个过程展示了[牛顿法](@entry_id:140116)如何系统地利用局部导数信息来指导搜索方向。该方法同样适用于更复杂的函数，例如包含三角函数的系统 [@problem_id:2207875]。

只要初始猜测足够接近解，并且解附近的[雅可比矩阵](@entry_id:264467)非奇异，[牛顿法](@entry_id:140116)就能展现出**二次收敛**的优异特性。这意味着每次迭代后，解的有效数字位数大约会翻倍，[收敛速度](@entry_id:636873)极快。

### [牛顿法](@entry_id:140116)的实际应用与改进

尽管[牛顿法](@entry_id:140116)理论上非常高效，但在实际应用中，其“纯粹”形式面临两大挑战：一是它可能不收敛，甚至会远离解，特别是当初始猜测 $\mathbf{x}_0$ 质量不高时；二是其对数值稳定性的要求较高。因此，一系列的改进和“全局化”策略被发展出来，以增强牛顿法的鲁棒性和[适用范围](@entry_id:636189)。

#### [全局化策略](@entry_id:177837)：[线搜索](@entry_id:141607)与信赖域

为了防止[牛顿步](@entry_id:177069) $\Delta \mathbf{x}_k$ 过大而导致迭代发散，我们需要确保每一步都能带来某种形式的“进步”。这通常通过**[全局化策略](@entry_id:177837)**来实现，最常见的两种是线搜索和[信赖域方法](@entry_id:138393)。

**[线搜索方法](@entry_id:172705) (Line Search Methods)** 的思想是不完全采纳[牛顿步](@entry_id:177069)，而是在牛顿方向上进行搜索，寻找一个合适的步长。迭代格式被修改为：

$\mathbf{x}_{k+1} = \mathbf{x}_k + \alpha_k \Delta \mathbf{x}_k$

其中 $\alpha_k \in (0, 1]$ 是**步长**。我们的目标是选择 $\alpha_k$，使得目标函数值得到充分下降。对于求解 $F(\mathbf{x})=\mathbf{0}$，一个自然的[目标函数](@entry_id:267263)是残差的范数平方，即 $f(\mathbf{x}) = \frac{1}{2}\|F(\mathbf{x})\|_2^2$。

**[回溯线搜索](@entry_id:166118) (Backtracking Line Search)** 是一种简单而有效的步长选择策略。它从一个完整的[牛顿步](@entry_id:177069)（即 $\alpha = 1$）开始尝试，检查是否满足一个下降条件，例如确保[残差范数](@entry_id:754273)减小：$\|F(\mathbf{x}_k + \alpha \Delta \mathbf{x}_k)\|_2  \|F(\mathbf{x}_k)\|_2$。如果不满足，就将 $\alpha$ 乘以一个缩减因子（如 $0.5$），然后再次尝试，直到条件满足为止 [@problem_id:2207877]。这种策略保证了每次迭代至少不会使情况变得更糟，从而大大提高了算法从任意初始点收敛的可能性，即**[全局收敛性](@entry_id:635436)**。

**[信赖域方法](@entry_id:138393) (Trust-Region Methods)** 提供了另一种全局化思路。它在每一步迭代中，首先在当前点 $\mathbf{x}_k$ 周围定义一个“信赖域”，通常是一个半径为 $\Delta_k$ 的球体，我们相信在这个区域内，我们的函数模型是可靠的。然后，我们求解一个**[信赖域子问题](@entry_id:168153)**：在信赖域内寻找一个步长 $\mathbf{s}$，使模型函数 $m_k(\mathbf{s})$ 最小化。

对于非线性方程组的求解，通常使用**高斯-牛顿模型 (Gauss-Newton model)**：

$m_k(\mathbf{s}) = \frac{1}{2}\|F(\mathbf{x}_k) + J(\mathbf{x}_k)\mathbf{s}\|_2^2$

这个模型是目标函数 $f(\mathbf{x}) = \frac{1}{2}\|F(\mathbf{x})\|_2^2$ 在 $\mathbf{x}_k$ 处的一个二次近似。通过展开，它可以写成标准二次型 $m_k(\mathbf{s}) = c + \mathbf{g}^T \mathbf{s} + \frac{1}{2} \mathbf{s}^T B \mathbf{s}$，其中梯度向量 $\mathbf{g} = J(\mathbf{x}_k)^T F(\mathbf{x}_k)$，而海森矩阵的近似 $B = J(\mathbf{x}_k)^T J(\mathbf{x}_k)$ [@problem_id:2207872]。[信赖域方法](@entry_id:138393)通过动态调整信赖域半径 $\Delta_k$ 来[平衡模型](@entry_id:636099)下降量和实际函数下降量，从而实现稳健的[全局收敛](@entry_id:635436)。

#### [数值稳定性](@entry_id:146550)与缩放

[牛顿法](@entry_id:140116)的每一步都依赖于求解一个[线性系统](@entry_id:147850)。如果雅可比矩阵 $J(\mathbf{x}_k)$ 是病态的（ill-conditioned），即其**条件数**非常大，那么求解该[线性系统](@entry_id:147850)时，微小的输入误差（如[浮点](@entry_id:749453)计算误差或 $F(\mathbf{x}_k)$ 的计算误差）可能会被放大，导致计算出的[牛顿步](@entry_id:177069) $\Delta \mathbf{x}_k$ 极不准确，进而影响算法的收敛和精度。

病态问题常常源于系统本身的**尺度不均衡 (poor scaling)**。例如，如果一个方程的量级是 $10^8$，而另一个是 $10^{-8}$，或者一个变量的变化范围远大于另一个，那么[雅可比矩阵](@entry_id:264467)的行或列之间就会出现巨大的数值差异，导致[条件数](@entry_id:145150)过大。

一个有效的解决方案是**缩放 (scaling)**。我们可以通过引入[对角缩放](@entry_id:748382)矩阵 $D_r$ 和 $D_c$ 来重新调整方程（行缩放）和变量（列缩放）的尺度。变换后的雅可比矩阵为 $J_s = D_r J D_c$。通过精心选择 $D_r$ 和 $D_c$，我们常常可以使得 $J_s$ 的[条件数](@entry_id:145150)远小于原始矩阵 $J$ 的[条件数](@entry_id:145150)。

例如，对于一个描述[单位圆](@entry_id:267290)和一条斜率极大的直线相交的系统，其在解 $(1,0)$ 处的雅可比矩阵[条件数](@entry_id:145150)可能高达 $5 \times 10^7$。然而，通过对方程和变量进行适当的缩放，例如将第二个方程整体除以 $10^4$，并将变量 $y$ 乘以 $10^4$，可以将新系统的[雅可比矩阵](@entry_id:264467)条件数降低到 $4$ [@problem_id:2207876]。这种[数量级](@entry_id:264888)的改善对于[数值算法](@entry_id:752770)的稳定性和最终解的精度至关重要，凸显了在应用数值方法前进行问题分析和预处理的重要性。

### 拟牛顿法

[牛顿法](@entry_id:140116)虽然收敛快，但有两个主要缺点，尤其是在处理大规模问题时：
1.  **导数计算**：需要显式地计算并提供雅可比矩阵 $J(\mathbf{x}_k)$ 的所有 $n^2$ 个[偏导数](@entry_id:146280)。对于复杂的模型，这可能是非常困难甚至不可能的。
2.  **计算成本**：在每次迭代中，都需要求解一个 $n \times n$ 的稠密[线性系统](@entry_id:147850) $J \Delta \mathbf{x} = -F$。使用标准的 LU 分解法，其计算成本约为 $O(n^3)$，当 $n$ 很大时，这个成本会变得无法承受。

**拟牛顿法 (Quasi-Newton Methods)** 正是为解决这些问题而设计的。其核心思想是，避免直接计算雅可比矩阵，而是通过迭代来构造和更新一个对[雅可比矩阵](@entry_id:264467)的近似 $B_k$。

#### 有限差分牛顿法

最直接的近似方法是使用**有限差分**来估计雅可比矩阵的元素。例如，可以使用[前向差分](@entry_id:173829)公式：

$J_{ij}(\mathbf{x}) \approx \frac{f_i(\mathbf{x} + h \mathbf{e}_j) - f_i(\mathbf{x})}{h}$

其中 $\mathbf{e}_j$ 是第 $j$ 个[标准基向量](@entry_id:152417)，$h$ 是一个小的步长。通过对每个变量进行微小的扰动，我们可以通过 $n$ 次额外的函数求值来构建整个雅可比矩阵的近似 [@problem_id:2207899]。这种方法避免了编写解析导数代码，但每次迭代仍然需要 $O(n^3)$ 的计算量来[求解线性系统](@entry_id:146035)，并且需要小心选择步长 $h$ 以[平衡截断](@entry_id:172737)误差和舍入误差。

#### Broyden 法

更高效的拟牛顿法，如**Broyden法**，则走得更远。它们不仅避免了直接计算雅可比矩阵，还通过低成本的更新来维护近似矩阵 $B_k$，从而避免了每次迭代 $O(n^3)$ 的求解成本。

Broyden法基于**[割线条件](@entry_id:164914) (secant condition)**，即新的近似[雅可比](@entry_id:264467) $B_{k+1}$ 应该在我们刚刚走过的那一步上精确地模拟函数的真实变化：$B_{k+1} (\mathbf{x}_{k+1} - \mathbf{x}_k) = F(\mathbf{x}_{k+1}) - F(\mathbf{x}_k)$。令 $\mathbf{s}_k = \mathbf{x}_{k+1} - \mathbf{x}_k$ 和 $\mathbf{y}_k = F(\mathbf{x}_{k+1}) - F(\mathbf{x}_k)$，[割线条件](@entry_id:164914)即为 $B_{k+1} \mathbf{s}_k = \mathbf{y}_k$。

在满足[割线条件](@entry_id:164914)的前提下，Broyden法选择对 $B_k$ 做最小的改动（在某种范数意义下）来得到 $B_{k+1}$。这导出了著名的 **Broyden "good" update** 公式，这是一个**[秩一更新](@entry_id:137543) (rank-one update)**：

$$B_{k+1} = B_k + \frac{(\mathbf{y}_k - B_k \mathbf{s}_k) \mathbf{s}_k^T}{\mathbf{s}_k^T \mathbf{s}_k}$$

从一个初始的[雅可比](@entry_id:264467)近似 $B_0$（通常是单位矩阵或[有限差分近似](@entry_id:749375)）开始，该公式允许我们仅通过向量运算（成本为 $O(n^2)$）来逐步更新[雅可比](@entry_id:264467)近似 [@problem_id:2207846]。更重要的是，利用 Sherman-Morrison 公式，我们可以直接更新 $B_k$ 的[逆矩阵](@entry_id:140380)或 LU 分解，使得求解牛顿方程 $B_k \mathbf{s}_k = -F(\mathbf{x}_k)$ 的成本从 $O(n^3)$ 降低到 $O(n^2)$。

#### 计算成本比较

牛顿法与拟牛顿法（如Broyden法）之间的选择，本质上是在**收敛速度**和**单步迭代成本**之间的权衡。
-   **牛顿法**：单步成本高，主要由 $O(n^2)$ 的[雅可比](@entry_id:264467)求值（假设解析形式已知）和 $O(n^3)$ 的线性求解构成。但其[收敛速度](@entry_id:636873)是二次的。
-   **Broyden法**：单步成本低，主要由 $O(n^2)$ 的矩阵-向量乘法和[秩一更新](@entry_id:137543)构成。但其收敛速度通常是超线性的（比线性快，比二次慢）。

对于一个大规模的稠密系统，当 $n \to \infty$ 时，牛顿法的成本 $C_N(n) \approx \frac{2}{3}n^3$，而 Broyden 法的成本 $C_B(n) \approx 5n^2$（具体系数取决于实现细节）。两者成本之比 $\frac{C_N(n)}{C_B(n)}$ 渐近地与 $n$ 成正比 [@problem_id:2207879]。这意味着当系统规模 $n$ 增大时，牛顿法每一步的成本会比 Broyden 法快得多地增长。

因此，在实际应用中，如果函数求值和[雅可比](@entry_id:264467)求值非常昂贵，或者系统规模 $n$ 巨大，那么尽管需要更多的迭代次数，Broyden法等拟牛顿法通常在总计算时间上更具优势。反之，如果函数和雅可比计算廉价，且需要极高的最终精度，[牛顿法](@entry_id:140116)则可能是更好的选择。