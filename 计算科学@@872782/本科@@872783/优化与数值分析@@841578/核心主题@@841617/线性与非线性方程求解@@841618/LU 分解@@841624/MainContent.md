## 引言
在线性代数和[科学计算](@entry_id:143987)的广阔领域中，高效、准确地求解大规模[线性方程组](@entry_id:148943) $A\mathbf{x}=\mathbf{b}$ 始终是一个核心挑战。无论是模拟电路、分析建筑结构，还是构建经济模型，这些问题最终都归结于对[矩阵方程](@entry_id:203695)的求解。直接求解，尤其是对于大型矩阵，计算成本高昂且可能存在数值不稳定的风险。[LU分解](@entry_id:144767)作为一种强大的[矩阵分解](@entry_id:139760)技术，正是为了应对这一挑战而生。它通过将一个方阵优雅地分解为两个[三角矩阵](@entry_id:636278)的乘积，将复杂问题转化为一系列简单、可快速求解的步骤，从而彻底改变了我们处理线性系统的方式。

本文将带领您深入探索[LU分解](@entry_id:144767)的世界，从基本原理到实际应用。在**“原理与机制”**一章中，我们将揭示[LU分解](@entry_id:144767)的数学本质，探讨其与高斯消元法的深刻联系，并理解为保证计算稳定性而引入的[选主元策略](@entry_id:169556)。随后，在**“应用与交叉学科联系”**一章中，我们将展示[LU分解](@entry_id:144767)如何作为基石，支撑起从数值分析到工程、金融等多个领域的复杂算法和模型。最后，通过**“动手实践”**部分，您将有机会将理论知识应用于具体问题，巩固对[LU分解](@entry_id:144767)计算过程和应用的理解。学完本文，您将不仅掌握一种计算方法，更能领会其背后所蕴含的[计算效率](@entry_id:270255)与数值智慧。

## 原理与机制

在上一章的引言中，我们初步了解了[LU分解](@entry_id:144767)作为一种强大的矩阵分解技术，在[求解线性方程组](@entry_id:169069)、计算[行列式](@entry_id:142978)和求[逆矩阵](@entry_id:140380)等领域具有核心作用。本章将深入探讨[LU分解](@entry_id:144767)的数学原理、核心机制、应用方法及其在实际计算中面临的挑战与对策。我们将从分解的基本思想出发，逐步揭示其与[高斯消元法](@entry_id:153590)的深刻联系，并最终讨论确保其在有限精度计算机上稳定执行的关键技术——[选主元策略](@entry_id:169556)。

### [LU分解](@entry_id:144767)的核心思想：矩阵的三角化

[LU分解](@entry_id:144767)的目标是将一个方阵 $A$ 表示为一个**下[三角矩阵](@entry_id:636278)** ($L$) 和一个**[上三角矩阵](@entry_id:150931)** ($U$) 的乘积。这种分解的价值在于，三角矩阵构成的线性方程组极其容易求解。

#### 定义与形式

对于一个给定的 $n \times n$ 矩阵 $A$，我们寻求找到一个下[三角矩阵](@entry_id:636278) $L$ 和一个上三角矩阵 $U$，使得：

$A = LU$

其中，$L$ 和 $U$ 的形式如下：

$L = \begin{pmatrix} L_{11}  0  \dots  0 \\ L_{21}  L_{22}  \dots  0 \\ \vdots  \vdots  \ddots  \vdots \\ L_{n1}  L_{n2}  \dots  L_{nn} \end{pmatrix}, \quad U = \begin{pmatrix} U_{11}  U_{12}  \dots  U_{1n} \\ 0  U_{22}  \dots  U_{2n} \\ \vdots  \vdots  \ddots  \vdots \\ 0  0  \dots  U_{nn} \end{pmatrix}$

这个简单的表达式 $A = LU$ 实际上包含 $n^2$ 个方程，但 $L$ 和 $U$ 中总共有 $n^2+n$ 个待定元素。这表明，若无额外约束，解并非唯一。为了得到确定的分解，通常会施加一些约束。两种最常见的分解形式是：

1.  **Doolittle 分解**：要求 $L$ 为**单位下[三角矩阵](@entry_id:636278)**，即其主对角线上的所有元素均为1 ($L_{ii} = 1$)。
2.  **Crout 分解**：要求 $U$ 为**单位上三角矩阵**，即其主对角线上的所有元素均为1 ($U_{ii} = 1$)。

在本书中，如无特殊说明，**[LU分解](@entry_id:144767)**将特指[Doolittle分解](@entry_id:634235)。

#### 分[解的唯一性](@entry_id:143619)

一个自然的问题是：对于一个给定的可逆矩阵 $A$，其[Doolittle分解](@entry_id:634235)是否唯一？答案是肯定的。这个唯一性是[LU分解](@entry_id:144767)在理论和实践中得以广泛应用的基础。

我们可以通过一个简单的证明来理解这一点。假设矩阵 $A$ 有两个[Doolittle分解](@entry_id:634235)：

$A = L_1 U_1 = L_2 U_2$

其中 $L_1$ 和 $L_2$ 是单位下三角矩阵，$U_1$ 和 $U_2$ 是[上三角矩阵](@entry_id:150931)。由于 $A$ 是可逆的，其[行列式](@entry_id:142978) $\det(A) = \det(L_1)\det(U_1) \neq 0$。因为 $L_1$ 是单位下[三角矩阵](@entry_id:636278)，其[行列式](@entry_id:142978) $\det(L_1) = 1$，所以必然有 $\det(U_1) \neq 0$。这意味着 $U_1$ 是可逆的。同理，$L_1, L_2, U_2$ 也都是可逆的。

我们可以将等式 $L_1 U_1 = L_2 U_2$ 左右两边分别乘以 $L_2^{-1}$ 和 $U_1^{-1}$，得到：

$L_2^{-1} L_1 = U_2 U_1^{-1}$

现在，我们来分析这个等式两边的矩阵类型。
*   左侧：单位下[三角矩阵](@entry_id:636278)的逆仍然是单位下[三角矩阵](@entry_id:636278)，两个单位下[三角矩阵](@entry_id:636278)的乘积也还是单位下三角矩阵。因此，$L_2^{-1} L_1$ 是一个单位下[三角矩阵](@entry_id:636278)。
*   右侧：[上三角矩阵](@entry_id:150931)的逆仍然是[上三角矩阵](@entry_id:150931)，两个[上三角矩阵](@entry_id:150931)的乘积也还是上三角矩阵。因此，$U_2 U_1^{-1}$ 是一个[上三角矩阵](@entry_id:150931)。

一个矩阵同时是下[三角矩阵](@entry_id:636278)和[上三角矩阵](@entry_id:150931)，那么它必然是一个**[对角矩阵](@entry_id:637782)**。更进一步，由于左侧的矩阵主对角线元素全为1，所以这个[对角矩阵](@entry_id:637782)只能是**单位矩阵** $I$。

因此，我们得出结论：

$L_2^{-1} L_1 = I \quad \implies \quad L_1 = L_2$
$U_2 U_1^{-1} = I \quad \implies \quad U_1 = U_2$

这证明了对于一个可逆矩阵，如果其Doolittle [LU分解](@entry_id:144767)存在，那么这个分解是唯一的 [@problem_id:2186357]。

### [LU分解](@entry_id:144767)的计算方法

既然我们知道了[LU分解](@entry_id:144767)的定义和唯一性，接下来的关键问题是如何计算出 $L$ 和 $U$。

#### 直接法：匹配[矩阵元](@entry_id:186505)素

最直观的方法是直接利用矩阵乘法的定义。我们将 $A=LU$ 展开，然后逐个求解 $L$ 和 $U$ 中的未知元素。让我们以一个 $3 \times 3$ 矩阵为例：

$\begin{pmatrix} a_{11}  a_{12}  a_{13} \\ a_{21}  a_{22}  a_{23} \\ a_{31}  a_{32}  a_{33} \end{pmatrix} = \begin{pmatrix} 1  0  0 \\ l_{21}  1  0 \\ l_{31}  l_{32}  1 \end{pmatrix} \begin{pmatrix} u_{11}  u_{12}  u_{13} \\ 0  u_{22}  u_{23} \\ 0  0  u_{33} \end{pmatrix}$

展开矩阵乘法，我们可以得到一个[计算顺序](@entry_id:749112)：
1.  计算 $U$ 的第一行：
    $u_{11} = a_{11}, \quad u_{12} = a_{12}, \quad u_{13} = a_{13}$
2.  计算 $L$ 的第一列：
    $l_{21}u_{11} = a_{21} \implies l_{21} = a_{21}/u_{11}$
    $l_{31}u_{11} = a_{31} \implies l_{31} = a_{31}/u_{11}$
3.  计算 $U$ 的第二行：
    $l_{21}u_{12} + u_{22} = a_{22} \implies u_{22} = a_{22} - l_{21}u_{12}$
    $l_{21}u_{13} + u_{23} = a_{23} \implies u_{23} = a_{23} - l_{21}u_{13}$
4.  计算 $L$ 的第二列：
    $l_{31}u_{12} + l_{32}u_{22} = a_{32} \implies l_{32} = (a_{32} - l_{31}u_{12})/u_{22}$
5.  计算 $U$ 的第三行：
    $l_{31}u_{13} + l_{32}u_{23} + u_{33} = a_{33} \implies u_{33} = a_{33} - l_{31}u_{13} - l_{32}u_{23}$

这个过程揭示了一种系统性的计算模式：交替计算 $U$ 的一行和 $L$ 的一列。

**示例：** 考虑矩阵 $A = \begin{pmatrix} 2  1  -1 \\ 4  5  -5 \\ -6  -1  0 \end{pmatrix}$ [@problem_id:2186352]。
*   $U$ 的第一行：$u_{11}=2, u_{12}=1, u_{13}=-1$。
*   $L$ 的第一列：$l_{21} = 4/2=2$, $l_{31} = -6/2=-3$。
*   $U$ 的第二行：$u_{22} = 5 - l_{21}u_{12} = 5 - 2 \cdot 1 = 3$, $u_{23} = -5 - l_{21}u_{13} = -5 - 2 \cdot (-1) = -3$。
*   $L$ 的第二列：$l_{32} = (-1 - l_{31}u_{12})/u_{22} = (-1 - (-3) \cdot 1)/3 = 2/3$。
*   $U$ 的第三行：$u_{33} = 0 - l_{31}u_{13} - l_{32}u_{23} = 0 - (-3)(-1) - (2/3)(-3) = -3 + 2 = -1$。

最终得到分解：
$L = \begin{pmatrix} 1  0  0 \\ 2  1  0 \\ -3  2/3  1 \end{pmatrix}, \quad U = \begin{pmatrix} 2  1  -1 \\ 0  3  -3 \\ 0  0  -1 \end{pmatrix}$

从这个计算过程中我们可以看到，每个元素的计算都依赖于之前已计算出的元素。例如，在求解 $l_{32}$ 时，我们需要用到 $u_{12}$ 和 $u_{22}$。在一个符号矩阵中，这种依赖关系更为清晰。例如，对于矩阵 $A = \begin{pmatrix} 2  1  c \\ 4  a  1 \\ 6  b  2 \end{pmatrix}$，我们可以推导出 $l_{32} = \frac{b-3}{a-2}$ [@problem_id:12929]。这个表达式明确显示了 $l_{32}$ 是如何由原始矩阵 $A$ 的元素 $a$ 和 $b$ 决定的，同时也暗示了当 $a=2$ 时，计算可能会遇到问题。

#### [高斯消元法](@entry_id:153590)视角

[LU分解](@entry_id:144767)与[高斯消元法](@entry_id:153590)之间存在着深刻而优美的联系。事实上，对矩阵 $A$ 进行高斯消元的过程，正是在“制造”[上三角矩阵](@entry_id:150931) $U$。

回顾高斯消元法的第一步，我们用第一行乘以一个**乘子** $m_{i1} = a_{i1}/a_{11}$，然后从第 $i$ 行中减去，以消除第 $i$ 行第一列的元素。这个过程对所有 $i  1$ 的行重复进行。例如，`Row` $i \leftarrow$ `Row` $i - m_{i1} \cdot$ `Row` $1$。

令人惊奇的是，这些在消元过程中使用的乘子 $m_{ij}$，恰好就是单位下[三角矩阵](@entry_id:636278) $L$ 中对应位置的元素 $l_{ij}$！

具体来说：
*   **$U$ 矩阵**：是对矩阵 $A$ 进行标准高斯消元（无行交换）后得到的上三角矩阵。对角线上的元素 $u_{kk}$ 就是消元过程中的**主元 (pivot)**。
*   **$L$ 矩阵**：是一个单位下三角矩阵，其对角线以下元素 $l_{ij}$ ($ij$) 就是在消元第 $j$ 列时，用于消除第 $i$ 行元素的乘子 $m_{ij} = a_{ij}^{(j-1)}/a_{jj}^{(j-1)}$。

这个视角提供了一个更富洞察力的观点：[LU分解](@entry_id:144767)可以看作是将高斯消元的过程以矩阵形式记录了下来。$U$ 记录了消元的结果，而 $L$ 记录了消元的操作本身。

从这个角度看，基础的[LU分解](@entry_id:144767)（无行交换）能够成功进行的条件是：在高斯消元的每一步中，主元 $a_{kk}^{(k-1)}$ 都不能为零。如果主元为零，除法将无法进行，算法失败。主元的非零性是[LU分解](@entry_id:144767)存在性的关键 [@problem_id:1375012]。

### [LU分解的应用](@entry_id:182836)：高效[求解线性方程组](@entry_id:169069)

[LU分解](@entry_id:144767)最核心的应用之一是高效地[求解线性方程组](@entry_id:169069) $A\mathbf{x} = \mathbf{b}$。

#### 两步求解法：[前向代入](@entry_id:139277)与后向代入

一旦我们获得了 $A=LU$ 分解，求解过程就变得异常简单。原始方程 $A\mathbf{x} = \mathbf{b}$ 可以改写为：

$LU\mathbf{x} = \mathbf{b}$

我们可以引入一个中间向量 $\mathbf{y} = U\mathbf{x}$。这样，原问题就被分解为两个更简单的三角系统：

1.  **[前向代入](@entry_id:139277) (Forward Substitution)**：求解 $L\mathbf{y} = \mathbf{b}$。
2.  **后向代入 (Backward Substitution)**：求解 $U\mathbf{x} = \mathbf{y}$。

由于 $L$ 和 $U$ 都是三角矩阵，这两个[方程组](@entry_id:193238)的求解非常高效。

**示例：** 考虑系统 $A\mathbf{x} = \mathbf{b}$，其中 $A = \begin{pmatrix} 2  -1  3 \\ 4  -1  8 \\ -2  4  2 \end{pmatrix}$ 和 $\mathbf{b} = \begin{pmatrix} 4 \\ 6 \\ -5 \end{pmatrix}$ [@problem_id:1375035]。
该矩阵的[Doolittle分解](@entry_id:634235)为：
$L = \begin{pmatrix} 1  0  0 \\ 2  1  0 \\ -1  3  1 \end{pmatrix}, \quad U = \begin{pmatrix} 2  -1  3 \\ 0  1  2 \\ 0  0  -1 \end{pmatrix}$

**第一步：求解 $L\mathbf{y} = \mathbf{b}$**
$\begin{pmatrix} 1  0  0 \\ 2  1  0 \\ -1  3  1 \end{pmatrix} \begin{pmatrix} y_1 \\ y_2 \\ y_3 \end{pmatrix} = \begin{pmatrix} 4 \\ 6 \\ -5 \end{pmatrix}$
从第一行开始，我们可以直接得到：
$y_1 = 4$
代入第二行：$2y_1 + y_2 = 6 \implies 2(4) + y_2 = 6 \implies y_2 = -2$
代入第三行：$-y_1 + 3y_2 + y_3 = -5 \implies -4 + 3(-2) + y_3 = -5 \implies y_3 = 5$
于是，我们得到中间向量 $\mathbf{y} = \begin{pmatrix} 4  -2  5 \end{pmatrix}^T$。

**第二步：求解 $U\mathbf{x} = \mathbf{y}$**
$\begin{pmatrix} 2  -1  3 \\ 0  1  2 \\ 0  0  -1 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ x_3 \end{pmatrix} = \begin{pmatrix} 4 \\ -2 \\ 5 \end{pmatrix}$
从最后一行开始，我们可以进行后向代入：
$-x_3 = 5 \implies x_3 = -5$
代入第二行：$x_2 + 2x_3 = -2 \implies x_2 + 2(-5) = -2 \implies x_2 = 8$
代入第一行：$2x_1 - x_2 + 3x_3 = 4 \implies 2x_1 - 8 + 3(-5) = 4 \implies 2x_1 = 27 \implies x_1 = 13.5$
最终解为 $\mathbf{x} = \begin{pmatrix} 13.5 \\ 8 \\ -5 \end{pmatrix}$。

#### 计算效率优势

[LU分解](@entry_id:144767)的真正威力体现在需要求解具有相同系数矩阵 $A$ 但不同右端项 $\mathbf{b}$ 的一系列[线性方程组](@entry_id:148943)时。这种情况在工程和[科学计算](@entry_id:143987)中非常普遍，例如在结构分析中评估不同载荷下的响应，或在电路模拟中分析不同输入信号的影响。

**核心优势**：矩阵 $A$ 的[LU分解](@entry_id:144767)（计算成本主要部分）只需要进行一次。对于每一个新的向量 $\mathbf{b}_i$，我们只需要执行一次廉价的前向和后向代入即可求得解 $\mathbf{x}_i$。

让我们通过计算操作数（[FLOPS](@entry_id:171702)，[浮点运算次数](@entry_id:749457)）来量化这一优势。对于一个 $N \times N$ 的稠密矩阵：
*   **[LU分解](@entry_id:144767)**：大约需要 $\frac{2}{3}N^3$ [FLOPS](@entry_id:171702)。
*   **前向和后向代入**：总共大约需要 $2N^2$ [FLOPS](@entry_id:171702)。
*   **矩阵求逆** (例如通过Gauss-Jordan法)：大约需要 $2N^3$ [FLOPS](@entry_id:171702)。
*   **矩阵-向量乘法**：大约需要 $2N^2$ [FLOPS](@entry_id:171702)。

现在，比较两种策略来求解 $K$ 个[方程组](@entry_id:193238) $A\mathbf{x}_i = \mathbf{b}_i$ [@problem_id:2160743]：

*   **方法1：先求逆再相乘**
    1.  计算 $A^{-1}$：成本 $2N^3$。
    2.  对每个 $\mathbf{b}_i$，计算 $\mathbf{x}_i = A^{-1}\mathbf{b}_i$：成本 $K \times 2N^2$。
    总成本 $T_1 = 2N^3 + 2KN^2$。

*   **方法2：[LU分解](@entry_id:144767)**
    1.  计算 $A=LU$：成本 $\frac{2}{3}N^3$。
    2.  对每个 $\mathbf{b}_i$，通过前向/后向代入求解：成本 $K \times 2N^2$。
    总成本 $T_2 = \frac{2}{3}N^3 + 2KN^2$。

显而易见，$T_2  T_1$。对于大的 $N$（例如 $N=500, K=100$），成本比率可以达到 $\frac{T_1}{T_2} = \frac{N+K}{N/3+K} = \frac{600}{500/3+100} = 2.25$。这意味着[LU分解](@entry_id:144767)法比求逆法快了一倍多。更重要的是，直接计算[矩阵的逆](@entry_id:140380)在数值上通常不如[LU分解](@entry_id:144767)稳定，因此在实际应用中，即使只求解一个[方程组](@entry_id:193238)，也应优先选择[LU分解](@entry_id:144767)而非求逆。多次求解同一矩阵的系统时，[LU分解](@entry_id:144767)的效率优势更加凸显 [@problem_id:2186367]。

### 数值稳定性与[选主元策略](@entry_id:169556)

到目前为止，我们都假设高斯消元或直接法中的除法步骤总是可行的。然而，在实际的计算机浮点运算中，我们面临着新的挑战：[数值稳定性](@entry_id:146550)。

#### 小主元的挑战：数值不稳定性

当高斯消元过程中的主元 $u_{kk}$ 等于零时，算法会因除零错误而失败。更微妙且危险的情况是，当主元非常接近于零时，算法虽然可以继续，但会产生灾难性的数值误差。

一个非常小的主元会导致一个非常大的乘子 $l_{ij}$。在后续的行更新操作 $a_{ik} \leftarrow a_{ik} - l_{ij}a_{jk}$ 中，这相当于用一个大数减去另一个大数来得到一个小数，这种操作被称为**[灾难性抵消](@entry_id:146919) (catastrophic cancellation)**，它会极大地放大舍入误差，导致计算结果毫无意义。

让我们通过一个在有限精度计算机上的例子来直观感受这个问题 [@problem_id:2186360]。考虑系统：
$A = \begin{pmatrix} 4.0 \times 10^{-4}  1 \\ 1  1 \end{pmatrix}, \quad \mathbf{b} = \begin{pmatrix} 3 \\ 5 \end{pmatrix}$

该系统的精确解约为 $\mathbf{x}_{\text{exact}} \approx \begin{pmatrix} 2.0008 \\ 2.9992 \end{pmatrix}$。

现在，假设我们在一个只能保留三位[有效数字](@entry_id:144089)的计算机上进行[LU分解](@entry_id:144767)。
1.  $u_{11} = 4.00 \times 10^{-4}$。这是一个非常小的主元。
2.  计算乘子 $l_{21} = a_{21}/u_{11} = 1 / (4.00 \times 10^{-4}) = 2.50 \times 10^3$。这是一个非常大的乘子。
3.  更新 $u_{22} = a_{22} - l_{21}u_{12} = 1 - (2.50 \times 10^3) \cdot 1 = -2499$。在三位精度下，这被截断为 $-2.49 \times 10^3$。

用得到的 $\hat{L}$ 和 $\hat{U}$ 求解系统，最终会得到一个近似解 $\mathbf{x}_{\text{approx}} = \begin{pmatrix} 0 \\ 3 \end{pmatrix}$。这个结果与精确解相差甚远，尤其是 $x_1$ 分量完全错误。误差的根本原因就是起始的小主元 $4.0 \times 10^{-4}$。

#### 部分选主元：$PA=LU$ 分解

为了克服小主元问题，标准的[LU分解](@entry_id:144767)算法引入了**选主元 (pivoting)** 策略。最常用的是**部分选主元 (partial pivoting)**。

其思想很简单：在消元的第 $k$ 步，不再默认使用 $a_{kk}^{(k-1)}$ 作为主元，而是在第 $k$ 列中从第 $k$ 行到最后一行的所有元素 $\{a_{ik}^{(k-1)} \mid i \ge k\}$ 中，寻找[绝对值](@entry_id:147688)最大的那个元素。然后，通过**行交换**，将该元素所在的行与第 $k$ 行互换。这样可以确保被选为的新主元是当前列（对角线及以下部分）中[绝对值](@entry_id:147688)最大的元素。

这种策略保证了所有乘子 $l_{ij}$ 的[绝对值](@entry_id:147688)都小于或等于1，从而有效避免了数值的剧烈增长和灾难性抵消，极大地提高了算法的[数值稳定性](@entry_id:146550)。

由于进行了行交换，分解的形式也从 $A=LU$ 变成了：

$PA = LU$

这里的 $P$ 是一个**[置换矩阵](@entry_id:136841) (permutation matrix)**，它记录了所有行交换的操作。[置换矩阵](@entry_id:136841)是[单位矩阵](@entry_id:156724)经过行重排得到的，其每一行每一列都只有一个1，其余为0。

当使用 $PA=LU$ 分解求解 $A\mathbf{x}=\mathbf{b}$ 时，过程稍作调整：
1.  将方程 $A\mathbf{x}=\mathbf{b}$ 两边同时左乘 $P$：$PA\mathbf{x} = P\mathbf{b}$。
2.  代入分解：$LU\mathbf{x} = P\mathbf{b}$。
3.  同样地，令 $\mathbf{y} = U\mathbf{x}$，分两步求解：
    *   [前向代入](@entry_id:139277)：$L\mathbf{y} = P\mathbf{b}$
    *   后向代入：$U\mathbf{x} = \mathbf{y}$

**示例：** 给定一个系统的 $PA=LU$ 分解及向量 $\mathbf{b}$ [@problem_id:1375001]：
$P = \begin{pmatrix} 1  0  0 \\ 0  0  1 \\ 0  1  0 \end{pmatrix}, L = \begin{pmatrix} 1  0  0 \\ 3  1  0 \\ 2  0  1 \end{pmatrix}, U = \begin{pmatrix} 2  1  -1 \\ 0  -4  6 \\ 0  0  7 \end{pmatrix}, \mathbf{b} = \begin{pmatrix} -3 \\ 15 \\ 17 \end{pmatrix}$

首先计算 $P\mathbf{b}$：$P\mathbf{b} = \begin{pmatrix} -3 \\ 17 \\ 15 \end{pmatrix}$。
然后解 $L\mathbf{y} = P\mathbf{b}$ 得到 $\mathbf{y} = \begin{pmatrix} -3 \\ 26 \\ 21 \end{pmatrix}$。
最后解 $U\mathbf{x} = \mathbf{y}$ 得到 $\mathbf{x} = \begin{pmatrix} 1 \\ -2 \\ 3 \end{pmatrix}$。

#### 存在性保证与[舍入误差](@entry_id:162651)

带部分选主元的[LU分解](@entry_id:144767)算法是一个非常稳健的算法。对于任何[非奇异矩阵](@entry_id:171829) $A$，其 $PA=LU$ 分解总是存在的。

然而，在某些特殊类型的矩阵中，我们甚至不需要进行选主元操作就能保证[数值稳定性](@entry_id:146550)。一个重要的例子是**[严格对角占优](@entry_id:154277) (strictly diagonally dominant)** 矩阵。这类矩阵的定义是：对于每一行，其对角元素的[绝对值](@entry_id:147688)都严格大于该行所有其他非对角元素[绝对值](@entry_id:147688)之和。可以证明，[严格对角占优矩阵](@entry_id:198320)进行高斯消元时，主元绝不会是零，且不会有数值上的剧烈增长，因此无需选主元 [@problem_id:1375012]。

最后，即使使用了部分选主元，计算机的有限精度仍然意味着计算出的 $\hat{L}$ 和 $\hat{U}$ 并非精确的。它们的乘积 $\hat{L}\hat{U}$ 通常不完[全等](@entry_id:273198)于 $PA$。它们之间存在一个**残差矩阵 (residual matrix)** $E = PA - \hat{L}\hat{U}$。这个残差矩阵的大小是衡量[LU分解](@entry_id:144767)计算质量的一个指标。在[后向误差分析](@entry_id:136880)的框架下，可以证明，通过选主元得到的解 $\hat{\mathbf{x}}$ 是一个略微扰动过的系统 $(A+\Delta A)\hat{\mathbf{x}} = \mathbf{b}$ 的精确解，而[选主元策略](@entry_id:169556)的目标就是让这个扰动 $\Delta A$ 的范数尽可能小。对残差 $E$ 的计算（如在 [@problem_id:2186341] 中的[模拟计算](@entry_id:273038)）可以帮助我们理解和量化浮点运算对最终结果的影响。

总而言之，[LU分解](@entry_id:144767)不仅是一种优雅的数学工具，更是一种经过精心设计、能够应对实际计算中数值挑战的强大算法。理解其原理、效率和稳定性问题，是掌握现代科学与工程计算的关键一步。