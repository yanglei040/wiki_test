## 引言
求解形如 $A\mathbf{x} = \mathbf{b}$ 的[线性方程组](@entry_id:148943)是贯穿科学与工程计算的核心任务。虽然高斯消元等直接法对于中小型问题行之有效，但当面临源于[偏微分方程离散化](@entry_id:175821)、大规模[网络分析](@entry_id:139553)或复杂经济模型的数百万维[稀疏系统](@entry_id:168473)时，其巨大的计算和存储开销使其变得不切实际。正是在这种背景下，[迭代法](@entry_id:194857)作为一种强大且高效的替代方案应运而生，其核心思想并非一步到位求得精确解，而是从一个初始猜测出发，通过一系列重复步骤逐步逼近真实解。

本文旨在系统性地介绍线性系统[迭代法](@entry_id:194857)的世界。在接下来的内容中，我们将分三个部分展开：
- **原理与机制**：我们将深入剖析经典迭代法（如[雅可比法](@entry_id:147508)、[高斯-赛德尔法](@entry_id:145727)）的数学构造，揭示它们如何通过[不动点迭代](@entry_id:749443)逼近解，并探讨决定其成败的关键——收敛性理论。
- **应用与[交叉](@entry_id:147634)学科联系**：我们将跨越多个学科，展示[迭代法](@entry_id:194857)如何为[电路分析](@entry_id:261116)、[结构力学](@entry_id:276699)、[图像修复](@entry_id:268249)、经济建模等实际问题提供解决方案，彰显其作为[通用计算](@entry_id:275847)工具的价值。
- **动手实践**：通过一系列精心设计的练习，您将有机会亲手应用这些方法，从而将理论知识转化为可操作的技能。

通过本次学习，您将不仅掌握[迭代法](@entry_id:194857)的基本原理，更能体会到其在现代计算科学中不可或缺的地位。让我们从迭代法的基本哲学思想开始，踏上这段探索之旅。

## 原理与机制

在[数值线性代数](@entry_id:144418)领域，求解形如 $A\mathbf{x} = \mathbf{b}$ 的[线性方程组](@entry_id:148943)是一个核心问题。尽管[高斯消元法](@entry_id:153590)等直接法为中小型稠密矩阵系统提供了精确的解决方案（在不考虑[舍入误差](@entry_id:162651)的情况下），但当面临大规模或[稀疏系统](@entry_id:168473)时，例如在[偏微分方程离散化](@entry_id:175821)、[计算流体力学](@entry_id:747620)或大规模经济建模中出现的系统，直接法的计算成本和内存需求可能变得令人望而却步。在这些情景下，迭代法提供了一种强大且高效的替代方案。本章将深入探讨[迭代法](@entry_id:194857)的基本原理和核心机制，从经典方法到现代方法，揭示它们是如何从一个初始猜测开始，逐步逼近真实解的。

### 迭代的哲学：从[不动点](@entry_id:156394)到解

迭代法的基本思想与直接法截然不同。直接法通过一系列有限的、确定的代数运算来求得解，而迭代法则是生成一个近似解的序列 $\{\mathbf{x}^{(k)}\}_{k=0}^{\infty}$，这个序列在满足特定条件时会收敛于真实的解 $\mathbf{x}$。

许多经典的迭代法，被称为**[定常迭代法](@entry_id:144014)**（Stationary Iterative Methods），都可以统一表示为一种**[不动点迭代](@entry_id:749443)**（Fixed-Point Iteration）形式：
$$
\mathbf{x}^{(k+1)} = T\mathbf{x}^{(k)} + \mathbf{c}
$$
其中，$\mathbf{x}^{(k)}$ 是第 $k$ 次迭代得到的近似解向量， $T$ 是一个固定的 $n \times n$ 矩阵，称为**[迭代矩阵](@entry_id:637346)**（Iteration Matrix），$\mathbf{c}$ 是一个固定的向量。该过程从一个初始猜测 $\mathbf{x}^{(0)}$ 开始。

如果这个序列收敛到一个向量 $\mathbf{x}$，即 $\lim_{k \to \infty} \mathbf{x}^{(k)} = \mathbf{x}$，那么这个极限向量 $\mathbf{x}$ 必定是迭代映射的[不动点](@entry_id:156394)，满足：
$$
\mathbf{x} = T\mathbf{x} + \mathbf{c}
$$
迭代法的构造巧妙之处在于，矩阵 $T$ 和向量 $\mathbf{c}$ 是根据原始方程 $A\mathbf{x} = \mathbf{b}$ 设计的，以确保该[不动点方程](@entry_id:203270)的解恰好就是原始[线性系统](@entry_id:147850)的解。

为了理解收敛过程的内在机制，我们定义第 $k$ 步的**误差向量**为 $\mathbf{e}^{(k)} = \mathbf{x} - \mathbf{x}^{(k)}$，它表示近似解与真实解之间的偏差。通过简单的代数推导，我们可以揭示误差的传播规律。从[不动点方程](@entry_id:203270) $\mathbf{x} = T\mathbf{x} + \mathbf{c}$ 中减去迭代公式 $\mathbf{x}^{(k+1)} = T\mathbf{x}^{(k)} + \mathbf{c}$，我们得到：
$$
\mathbf{x} - \mathbf{x}^{(k+1)} = (T\mathbf{x} + \mathbf{c}) - (T\mathbf{x}^{(k)} + \mathbf{c}) = T(\mathbf{x} - \mathbf{x}^{(k)})
$$
根据误差向量的定义，这可以写成一个简洁而深刻的关系 [@problem_id:1369779]：
$$
\mathbf{e}^{(k+1)} = T\mathbf{e}^{(k)}
$$
反复应用此关系，我们可以将第 $k$ 步的误差与初始误差 $\mathbf{e}^{(0)}$联系起来：
$$
\mathbf{e}^{(k)} = T\mathbf{e}^{(k-1)} = T(T\mathbf{e}^{(k-2)}) = \dots = T^k \mathbf{e}^{(0)}
$$
这个关系是理解迭代法收敛性的基石。它清楚地表明，迭代过程能否收敛，即误差 $\mathbf{e}^{(k)}$ 是否随着 $k$ 的增大而趋于零，完全取决于[迭代矩阵](@entry_id:637346) $T$ 的幂次 $T^k$ 的行为。

### 经典[定常迭代法](@entry_id:144014)

[定常迭代法](@entry_id:144014)的构造源于对[系数矩阵](@entry_id:151473) $A$ 的不同分解方式。最经典的三种方法是[雅可比法](@entry_id:147508)、[高斯-赛德尔法](@entry_id:145727)和[逐次超松弛法](@entry_id:142488)。

#### [雅可比法](@entry_id:147508)：[同步更新](@entry_id:271465)

雅可比（Jacobi）法是最简单直观的迭代方法之一。其核心思想源于将线性方程组的第 $i$ 个方程改写为求解变量 $x_i$ 的表达式。对于一个 $n \times n$ 的线性系统 $A\mathbf{x} = \mathbf{b}$，其第 $i$ 个方程为：
$$
\sum_{j=1}^{n} a_{ij} x_{j} = b_{i}
$$
我们可以将包含 $x_i$ 的对角项 $a_{ii}x_i$ 分离出来：
$$
a_{ii} x_{i} + \sum_{j \neq i} a_{ij} x_{j} = b_{i}
$$
假设所有对角元素 $a_{ii}$ 均不为零，我们可以解出 $x_i$：
$$
x_i = \frac{1}{a_{ii}} \left( b_i - \sum_{j \neq i} a_{ij} x_j \right)
$$
这个方程给出了变量 $x_i$ 与其他所有变量之间的精确关系。[雅可比法](@entry_id:147508)的迭代思想就是将这个关系式转化为一个更新规则：用上一步的近似解 $\mathbf{x}^{(k)}$ 来计算下一步的近似解 $\mathbf{x}^{(k+1)}$。具体来说，计算 $x_i^{(k+1)}$ 时，右侧的所有变量都取其在第 $k$ 次迭代中的值 [@problem_id:2182332]。这就得到了[雅可比法](@entry_id:147508)的分量形式更新公式：
$$
x_i^{(k+1)} = \frac{1}{a_{ii}} \left( b_i - \sum_{j \neq i} a_{ij} x_j^{(k)} \right) \quad \text{for } i = 1, 2, \dots, n
$$
一个关键特征是，在计算 $\mathbf{x}^{(k+1)}$ 的所有分量时，我们只使用来自前一步迭代 $\mathbf{x}^{(k)}$ 的值。这意味着所有分量 $x_i^{(k+1)}$ 的计算可以**并行**或**同步**进行，因为它们之间[相互独立](@entry_id:273670)。

**示例：** 考虑线性系统 $A\mathbf{x} = \mathbf{b}$ [@problem_id:2182306]：
$$
\begin{pmatrix} 5  -1  2 \\ 2  8  -1 \\ -1  1  4 \end{pmatrix} \begin{pmatrix} x_1 \\ x_2 \\ x_3 \end{pmatrix} = \begin{pmatrix} 12 \\ -16.5 \\ 7 \end{pmatrix}
$$
[雅可比法](@entry_id:147508)的迭代公式为：
$$
x_1^{(k+1)} = \frac{1}{5}(12 - (-1)x_2^{(k)} - 2x_3^{(k)})
$$
$$
x_2^{(k+1)} = \frac{1}{8}(-16.5 - 2x_1^{(k)} - (-1)x_3^{(k)})
$$
$$
x_3^{(k+1)} = \frac{1}{4}(7 - (-1)x_1^{(k)} - x_2^{(k)})
$$
从初始猜测 $\mathbf{x}^{(0)} = (0, 0, 0)^T$ 开始，第一次迭代 $(k=0)$ 产生：
$$
x_1^{(1)} = \frac{1}{5}(12) = 2.4
$$
$$
x_2^{(1)} = \frac{1}{8}(-16.5) = -2.0625
$$
$$
x_3^{(1)} = \frac{1}{4}(7) = 1.75
$$
第二次迭代 $(k=1)$ 时，我们使用 $\mathbf{x}^{(1)}$ 的值来计算 $\mathbf{x}^{(2)}$。例如，分量 $x_2^{(2)}$ 的计算如下：
$$
x_2^{(2)} = \frac{1}{8}(-16.5 - 2x_1^{(1)} + x_3^{(1)}) = \frac{1}{8}(-16.5 - 2(2.4) + 1.75) = \frac{1}{8}(-19.55) = -2.44375
$$
通过不断重复此过程，近似解序列将（在收敛的情况下）越来越接近真实解。这种迭代更新的思想在许多物理问题中都有自然的体现，例如在模拟芯片上的[稳态热分布](@entry_id:167804)时，每个网格点的温度可以近似为其周围邻近点在上一时刻温度的平均值，这正是[雅可比迭代](@entry_id:139235)的一种形式 [@problem_id:2182368]。

#### [高斯-赛德尔法](@entry_id:145727)：序贯更新

高斯-赛德尔（Gauss-Seidel）法是对[雅可比法](@entry_id:147508)的一个简单而通常更有效的改进。其动机是：在计算第 $(k+1)$ 次迭代的近似解时，我们应该尽可能使用最新的信息。

在[雅可比法](@entry_id:147508)中，计算 $x_i^{(k+1)}$ 时，即使我们已经算出了 $x_1^{(k+1)}, \dots, x_{i-1}^{(k+1)}$，我们仍然使用它们在第 $k$ 步的旧值。[高斯-赛德尔法](@entry_id:145727)修正了这一点。当按[顺序计算](@entry_id:273887) $x_1^{(k+1)}, x_2^{(k+1)}, \dots, x_n^{(k+1)}$ 时，一旦某个分量的新值被计算出来，它就会立刻被用于后续分量的计算中。

具体来说，在计算 $x_i^{(k+1)}$ 时，对于所有 $j  i$，我们已经获得了新的值 $x_j^{(k+1)}$，因此可以直接使用它们。对于所有 $j  i$，我们还没有计算出它们的新值，所以只能继续使用旧值 $x_j^{(k)}$。这导致了[高斯-赛德尔法](@entry_id:145727)的更新公式 [@problem_id:2182322]：
$$
x_i^{(k+1)} = \frac{1}{a_{ii}} \left( b_i - \sum_{j=1}^{i-1} a_{ij} x_j^{(k+1)} - \sum_{j=i+1}^{n} a_{ij} x_j^{(k)} \right)
$$
**示例：** 对于一个 $3 \times 3$ 系统，在计算 $x_2^{(k+1)}$ 时，我们已经算出了 $x_1^{(k+1)}$，但 $x_3$ 的值仍然是 $x_3^{(k)}$。因此，更新公式为 [@problem_id:2182322]：
$$
x_2^{(k+1)} = \frac{1}{a_{22}} \left( b_2 - a_{21}x_1^{(k+1)} - a_{23}x_3^{(k)} \right)
$$
这种“即算即用”的策略通常会加速收敛过程，因为它更快地将新信息传播到整个系统中。然而，与[雅可比法](@entry_id:147508)不同，[高斯-赛德尔法](@entry_id:145727)的计算本质上是**序贯的**，无法直接[并行化](@entry_id:753104)。

#### [逐次超松弛法](@entry_id:142488)：加速收敛

[逐次超松弛法](@entry_id:142488)（Successive Over-Relaxation, SOR）可以被看作是[高斯-赛德尔法](@entry_id:145727)的一种推广，旨在进一步加速收敛。SOR引入了一个**松弛参数**（Relaxation Parameter） $\omega$。

其更新过程可以理解为两步。首先，像[高斯-赛德尔法](@entry_id:145727)一样，计算一个临时的中间值，我们称之为 $x_{i, \text{GS}}^{(k+1)}$：
$$
x_{i, \text{GS}}^{(k+1)} = \frac{1}{a_{ii}} \left( b_i - \sum_{j=1}^{i-1} a_{ij}x_j^{(k+1)} - \sum_{j=i+1}^{n} a_{ij}x_j^{(k)} \right)
$$
然后，最终的更新值 $x_i^{(k+1)}$ 并不是直接取这个中间值，而是取上一步的值 $x_i^{(k)}$ 和这个中间值 $x_{i, \text{GS}}^{(k+1)}$ 的加权平均：
$$
x_i^{(k+1)} = (1-\omega) x_i^{(k)} + \omega x_{i, \text{GS}}^{(k+1)}
$$
这个表达式清晰地揭示了SOR的本质 [@problem_id:2182358]：它是在旧的近似值 $x_i^{(k)}$ 和高斯-赛德尔更新方向上的新近似值之间进行[线性插值](@entry_id:137092)（或外插）。参数 $\omega$ 就是插值系数。
*   当 $\omega=1$ 时，SOR完全退化为[高斯-赛德尔法](@entry_id:145727)。
*   当 $0  \omega  1$ 时，称为**[欠松弛](@entry_id:756302)**（Under-relaxation），这会取一个介于旧值和GS更新值之间的值，可以用于稳定某些不稳定系统的收敛。
*   当 $\omega  1$ 时，称为**超松弛**（Over-relaxation），它会沿着GS更新的方向“前进”得更远一些。对于许多类型的问题，选择一个最优的 $\omega_{opt}  1$ 可以显著地提高收敛速度。

选择最优的 $\omega$ 是一个复杂的问题，依赖于矩阵 $A$ 的性质，但在实践中，一个好的 $\omega$ 值可以带来巨大的性能提升。

### 收敛性理论

迭代法是否有效，关键在于它是否收敛。即使收敛，收敛的速度也同样重要。收敛性理论为我们提供了判断和分析这些问题的数学工具。

#### 谱半径的角色

我们之[前推](@entry_id:158718)导出[误差传播](@entry_id:147381)关系 $\mathbf{e}^{(k)} = T^k \mathbf{e}^{(0)}$。为了使迭代收敛，我们要求对于任意的初始误差 $\mathbf{e}^{(0)}$，误差向量 $\mathbf{e}^{(k)}$ 的范数都必须随着 $k \to \infty$ 而趋于零。这等价于要求矩阵的幂 $T^k$ 趋近于零矩阵。

线性代数中的一个基本定理指出，$\lim_{k \to \infty} T^k = 0$ 的充分必要条件是 $T$ 的**谱半径**（Spectral Radius）小于1。[谱半径](@entry_id:138984) $\rho(T)$ 定义为 $T$ 的所有[特征值](@entry_id:154894)（可以是复数）的模长的最大值：
$$
\rho(T) = \max_{i} |\lambda_i| \quad \text{其中 } \lambda_i \text{ 是 } T \text{ 的特征值}
$$
因此，我们得到了[定常迭代法](@entry_id:144014)收敛的**黄金法则**：
 一个[定常迭代法](@entry_id:144014) $\mathbf{x}^{(k+1)} = T\mathbf{x}^{(k)} + \mathbf{c}$ 对任意初始猜测 $\mathbf{x}^{(0)}$ 都收敛的充分必要条件是其[迭代矩阵](@entry_id:637346)的[谱半径](@entry_id:138984) $\rho(T)  1$。

例如，如果一个[高斯-赛德尔迭代](@entry_id:136271)矩阵的谱半径经计算为 $\rho(T_G) = \cos(\frac{\pi}{8})$ 或 $\rho(T_G) = e/3 \approx 0.906$，由于这些值都小于1，该方法保证收敛。但如果谱半径为 $\rho(T_G) = 1$ 或 $\rho(T_G) = \ln(3) \approx 1.099$，则不能保证对所有初始猜测都收敛 [@problem_id:1369793]。谱半径不仅决定了是否收敛，其值的大小也决定了收敛的快慢：$\rho(T)$ 越接近0，收敛通常越快。

#### 实用的充分条件

在实践中，计算一个大矩阵的谱半径本身可能是一项计算量巨大的任务。因此，能够通过简单检查矩阵 $A$ 的性质来判断收敛性的充分条件就显得尤为宝贵。

**[严格对角占优矩阵](@entry_id:198320)：**
一个矩阵 $A$ 被称为**[严格对角占优](@entry_id:154277)**（Strictly Diagonally Dominant, SDD），如果对于每一行，对角元素的[绝对值](@entry_id:147688)都**严格大于**该行所有其他元素（非对角元素）的[绝对值](@entry_id:147688)之和。
$$
|a_{ii}|  \sum_{j \neq i} |a_{ij}| \quad \text{for all } i=1, \dots, n
$$
**定理（Levy–Desplanques）：** 如果一个矩阵 $A$ 是[严格对角占优](@entry_id:154277)的，那么 $A$ 是非奇异的，并且[雅可比法](@entry_id:147508)和[高斯-赛德尔法](@entry_id:145727)都保证收敛。

例如，对于矩阵 [@problem_id:2182352]：
$$
A = \begin{pmatrix} 10  -3  5 \\ 4  -8  -2.5 \\ 6  -5  12 \end{pmatrix}
$$
我们逐行检查：
*   行1: $|10| = 10  |-3| + |5| = 8$
*   行2: $|-8| = 8  |4| + |-2.5| = 6.5$
*   行3: $|12| = 12  |6| + |-5| = 11$
由于每一行都满足条件，该矩阵是[严格对角占优](@entry_id:154277)的。因此，我们无需计算[谱半径](@entry_id:138984)就可以断定，应用于此系统的[雅可比法](@entry_id:147508)和[高斯-赛德尔法](@entry_id:145727)都将收敛。

**对称正定矩阵：**
另一个重要的矩阵类别是**对称正定**（Symmetric Positive-Definite, SPD）矩阵。一个矩阵 $A$ 是对称的，如果 $A=A^T$。一个[对称矩阵](@entry_id:143130)是正定的，如果对于所有非[零向量](@entry_id:156189) $\mathbf{x}$，二次型 $\mathbf{x}^T A \mathbf{x}$ 恒为正。
**定理：** 如果一个矩阵 $A$ 是[对称正定](@entry_id:145886)的，那么[高斯-赛德尔法](@entry_id:145727)和[SOR法](@entry_id:142488)（对于所有 $0  \omega  2$）都保证收敛。

判断一个对称矩阵是否为正定，可以使用**[西尔维斯特准则](@entry_id:150939)**（Sylvester's Criterion），即矩阵的所有**[顺序主子式](@entry_id:154227)**（leading principal minors）都必须为正。[顺序主子式](@entry_id:154227)是矩阵左上角的 $k \times k$ 子矩阵的行列式。

**示例：** 考虑依赖于参数 $\alpha$ 的矩阵 [@problem_id:2182341]：
$$
A = \begin{pmatrix} 2  \alpha \\ \alpha  8 \end{pmatrix}
$$
该矩阵对于任何实数 $\alpha$ 都是对称的。为保证[高斯-赛德尔法](@entry_id:145727)收敛，我们要求它也是正定的。根据[西尔维斯特准则](@entry_id:150939)：
1.  第一个[顺序主子式](@entry_id:154227)：$\Delta_1 = 2$。显然 $2  0$。
2.  第二个[顺序主子式](@entry_id:154227)：$\Delta_2 = \det(A) = (2)(8) - (\alpha)(\alpha) = 16 - \alpha^2$。

我们必须有 $\Delta_2  0$，即 $16 - \alpha^2  0$，这给出 $\alpha^2  16$，或 $|\alpha|  4$。因此，只要参数 $\alpha$ 在区间 $(-4, 4)$ 内，矩阵 $A$ 就是对称正定的，[高斯-赛德尔法](@entry_id:145727)就保证收敛。

### [克雷洛夫子空间方法](@entry_id:144111)简介

经典[定常迭代法](@entry_id:144014)虽然简单，但收敛速度可能较慢，且其收敛性强烈依赖于矩阵 $A$ 的特定属性。为了克服这些局限性，一系列更强大、更通用的现代[迭代法](@entry_id:194857)被发展出来，统称为**[克雷洛夫子空间方法](@entry_id:144111)**（Krylov Subspace Methods）。

这类方法的基本思想是，在每一步迭代中，在一个精心构造的、维度不断增长的[子空间](@entry_id:150286)内寻找“最优”的近似解。这个[子空间](@entry_id:150286)就是**克雷洛夫子空间**，对于矩阵 $A$ 和初始残差 $\mathbf{r}_0 = \mathbf{b} - A\mathbf{x}_0$，第 $k$ 维[克雷洛夫子空间](@entry_id:751067)定义为：
$$
\mathcal{K}_k(A, \mathbf{r}_0) = \text{span}\{\mathbf{r}_0, A\mathbf{r}_0, A^2\mathbf{r}_0, \dots, A^{k-1}\mathbf{r}_0\}
$$
这些方法在 $x_0 + \mathcal{K}_k(A, \mathbf{r}_0)$ 空间中寻找近似解 $x_k$，使得某种误差度量达到最小。

#### 共轭梯度法（CG）
共轭梯度法（Conjugate Gradient, CG）是[克雷洛夫子空间方法](@entry_id:144111)中最著名和最基础的一个。它通过在克雷洛夫子空间中执行一系列巧妙的优化步骤来求解。然而，标准的[共轭梯度法](@entry_id:143436)有一个严格的要求：它仅适用于系数矩阵 $A$ 是**对称正定**的系统。

#### [广义最小残差法](@entry_id:139566)（GMRES）
当矩阵 $A$ **非对称**时，CG方法不再适用。[广义最小残差法](@entry_id:139566)（Generalized Minimal Residual Method, GMRES）是为解决这类更一般的问题而设计的。其核心思想非常直观：在第 $k$ 次迭代时，GMRES在[仿射空间](@entry_id:152906) $x_0 + \mathcal{K}_k(A, \mathbf{r}_0)$ 中寻找一个近似解 $x_k$，使得该解对应的**残差的欧几里得范数** $\|\mathbf{b} - A\mathbf{x}_k\|_2$ 最小化。

为了实现这一点，GMRES的一个关键步骤是为[克雷洛夫子空间](@entry_id:751067) $\mathcal{K}_k(A, \mathbf{r}_0)$ 构建一个[标准正交基](@entry_id:147779) $\{q_1, q_2, \dots, q_k\}$。这个过程通常通过**阿诺尔迪迭代**（Arnoldi Iteration）来完成，它本质上是施密特（Gram-Schmidt）正交化过程的一种形式。阿诺尔迪迭代不仅生成了[标准正交基](@entry_id:147779)向量 $q_i$，还同时生成了一个[上海森堡矩阵](@entry_id:756367)（upper Hessenberg matrix）$H$ 的元素 $h_{ij}$，这些元素记录了[基向量](@entry_id:199546)之间的关系。

例如，阿诺尔迪迭代的前几步如下 [@problem_id:2182305]：
1.  计算初始残差 $\mathbf{r}_0 = \mathbf{b} - A\mathbf{x}_0$。
2.  归一化得到第一个[基向量](@entry_id:199546): $q_1 = \mathbf{r}_0 / \|\mathbf{r}_0\|_2$。
3.  计算下一个候选向量: $w = Aq_1$。
4.  将 $w$ 与已有的[基向量](@entry_id:199546) $q_1$ 正交化。这涉及到计算投影系数 $h_{11} = q_1^T w$，然后得到正交化后的向量 $\hat{w} = w - h_{11}q_1$。
5.  这个正交化[向量的范数](@entry_id:154882)就是下一个海森堡矩阵元素 $h_{21} = \|\hat{w}\|_2$。
6.  新的[基向量](@entry_id:199546)就是 $q_2 = \hat{w} / h_{21}$。

通过这个过程，GMRES将原始的大型非对称系统的求解问题，转化为在一系列维度逐渐增大的[子空间](@entry_id:150286)上求解一个规模小得多的[最小二乘问题](@entry_id:164198)。这使得它成为处理一般[大型稀疏线性系统](@entry_id:137968)的强大工具。

总而言之，从简单的[雅可比法](@entry_id:147508)到复杂但高效的GMRES法，[迭代法](@entry_id:194857)的世界为求解大规模[线性系统](@entry_id:147850)提供了一个丰富而深刻的工具箱。理解这些方法背后的数学原理和收敛机制，对于在科学与工程计算中做出明智的算法选择至关重要。