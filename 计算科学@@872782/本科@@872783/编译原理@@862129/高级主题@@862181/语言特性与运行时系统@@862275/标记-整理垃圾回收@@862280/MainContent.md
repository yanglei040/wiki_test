## 引言
在[自动内存管理](@entry_id:746589)的世界里，垃圾收集（Garbage Collection, GC）是确保程序稳定性和性能的关键技术。然而，简单的GC算法，如[标记-清除](@entry_id:633975)，虽然能够回收不再使用的内存，却常常留下一个严重的问题：[内存碎片](@entry_id:635227)。随着时间的推移，堆内存会变得千疮百孔，导致即使总空闲空间充足，也无法为新的大对象分配连续的内存块。为了解决这一根本性缺陷，标记-整理（Mark-Compact）算法应运而生。

本文旨在系统性地剖析标记-整理算法。我们将超越其基本定义，深入探讨其内部机制、性能优势以及在现代复杂计算环境中的应用和挑战。读者将学习到该算法不仅是回收垃圾，更是通过整理操作主动优化[内存布局](@entry_id:635809)，从而提升程序性能的强大工具。

文章将分为三个核心部分展开。在“原理与机制”一章中，我们将详细阐述标记阶段的[可达性](@entry_id:271693)分析、三色抽象，以及整理阶段的指针修复策略。接下来，在“应用与跨学科关联”一章中，我们将探讨该算法在对抗[内存碎片](@entry_id:635227)、与其他GC策略的权衡、以及与编译器和[运行时系统](@entry_id:754463)协同工作中的关键作用。最后，“动手实践”部分将提供一系列精心设计的问题，帮助读者巩固理论知识，并将其应用于解决实际的工程挑战。

## 原理与机制

继前一章介绍了[自动内存管理](@entry_id:746589)的基本概念之后，本章将深入探讨一种重要且广泛应用的垃圾收集算法——**标记-整理（Mark-Compact）**。与仅回收内存的[标记-清除](@entry_id:633975)（Mark-Sweep）算法不同，标记-整理算法在识别存活对象后，还会执行一个额外的**整理（Compaction）**步骤，将所有存活对象移动到内存的一端，从而消除[内存碎片](@entry_id:635227)。这一过程不仅能提高[内存分配](@entry_id:634722)效率，还能显著改善程序的局部性。本章将系统地阐述标记-整理算法的核心原理、关键机制、性能考量以及在现代多核并发环境下的演进。

### 标记阶段：识别存活对象

标记-整理算法的第一步是**标记（Marking）**，其目标是准确地识别出程序当前所有**可达（reachable）**的对象。一个对象被认为是可达的，当且仅当存在一条从**根集合（Root Set）**出发，经过一系列指针引用，最终能够到达该对象的路径。

#### 可达性与根集合

根集合是垃圾收集器进行[可达性](@entry_id:271693)分析的起点，通常包括以下几类引用：
- **全局变量**：静态变量中存储的对象引用。
- **CPU 寄存器**：当前执行线程的寄存器中存储的对象引用。
- **执行栈**：所有线程的[调用栈](@entry_id:634756)上，每个[栈帧](@entry_id:635120)中的局部变量和函数参数所包含的对象引用。

为了精确地识别根集合，垃圾收集器（GC）需要与编译器紧密协作。现代编译器能够在代码的特定位置——**安全点（Safepoint）**——生成**栈映射（Stack Maps）**。安全点是程序执行过程中可以安全地暂停并进行垃圾收集的点，例如在[函数调用](@entry_id:753765)或循环回边处。栈映射则精确地描述了在某个安全点，执行栈和寄存器中哪些位置存放的是对象引用。

这种精确识别根集合的能力对GC的效率和正确性至关重要。例如，在一个采用**[静态单赋值](@entry_id:755378)（Static Single Assignment, SSA）**形式进行优化的编译器中，可以通过对SSA变量进行**存活分析（Liveness Analysis）**来确定在任意安全点哪些指针类型的变量是存活的，从而构成精确的根集合。一个变量在某点是存活的，意味着它的值可能会在未来的某条执行路径上被使用。

考虑一个使用`phi`函数的场景，如果`phi`函数的结果在一个基本块的入口处是存活的，那么根据`phi`函数的语义，其所有来自不同前驱块的对应操作数在各自前驱块的出口处也必须是存活的。这意味着存活信息会沿着[控制流图](@entry_id:747825)向后传播。因此，即使一个指针变量在当前基本块内未被直接使用，但如果它将在后续的合并点（`phi`函数）被使用，它在当前块的安全点也必须被视为根，并被记录在栈映射中，以防止其引用的对象被错误回收 [@problem_id:3657477]。

#### 标记机制与[数据结构](@entry_id:262134)

一旦根集合确定，GC便开始遍历对象图，标记所有可达对象。如何记录一个对象“已被标记”的状态，是标记机制的核心。主要有两种设计方案：

1.  **对象头内的标记位（In-object Mark Bit）**：在每个对象的头部预留一小块空间（通常是一个比特或一个字节）来存储标记状态。这是最直接的方法，但会带来一定的空间开销。

2.  **外部[位图](@entry_id:746847)（Side Bitmap）**：在内存中维护一个独立的、与堆空间对应的[位图](@entry_id:746847)。[位图](@entry_id:746847)中的每一个比特对应堆中的一个可分配单元（例如一个固定大小的槽或特定字节数的内存块）。如果某个内存单元被一个标记过的对象占据，其对应的比特位就被设置。

这两种方案在空间开销和扫描性能上各有优劣。我们可以通过一个假设场景来量化分析 [@problem_id:3657499]。假设一个256 MiB的堆，所有对象大小固定为32字节。在GC时，堆中75%（即$f = \frac{3}{4}$）的空间被存活对象占据。

-   **[位图](@entry_id:746847)方案的开销**：
    堆中总共的槽位数量为 $N_{\text{slots}} = \frac{256 \times 2^{20} \text{ 字节}}{32 \text{ 字节/槽}} = 2^{23}$ 个。
    每个槽对应一个比特，因此[位图](@entry_id:746847)总大小为 $2^{23}$ 比特。换算成字节，即 $\frac{2^{23}}{8} = 2^{20}$ 字节，也就是 **1 MiB**。

-   **对象头方案的开销**：
    假设每个标记位占用1字节。空间开销仅存在于存活对象上。存活对象数量为 $N_{\text{live}} = N_{\text{slots}} \times f = 2^{23} \times \frac{3}{4} = 6 \times 2^{20}$ 个。
    总空间开销为 $6 \times 2^{20} \times 1 \text{ 字节} = 6 \times 2^{20}$ 字节，即 **6 MiB**。

在这个场景中，[位图](@entry_id:746847)方案的空间效率远高于对象头方案。

在整理阶段，GC需要进行一次**识别遍历（Identification Pass）**来确定哪些槽位是存活的。在理想化的模型下，这次遍历的成本与读取的总字节数成正比。

-   **[位图](@entry_id:746847)方案的扫描成本**：GC只需连续读取整个[位图](@entry_id:746847)，即读取 **1 MiB** 数据。
-   **对象头方案的扫描成本**：GC必须检查堆中的每一个槽位，以确定其是否包含一个存活对象并读取其标记位。这需要访问 $N_{\text{slots}} = 2^{23}$ 个槽位，每次读取1字节，总计读取 **8 MiB** 数据。

由此可见，[位图](@entry_id:746847)方案不仅空间开销更小，而且由于其数据的连续性和紧凑性，在扫描性能上也具有显著优势，其数据读取量仅为对象头方案的 $\frac{1}{8}$ [@problem_id:3657499]。

#### 三色抽象

为了严谨地描述标记过程，尤其是为了后续讨论并发GC，我们引入**三色抽象（Tri-Color Abstraction）**。在追踪过程中，所有对象被划分为三个集合：

-   **白色（White）**：尚未被GC访问到的对象。在标记开始时，除根对象外，所有对象都是白色的。在标记结束时，所有白色对象都可被回收。
-   **灰色（Gray）**：已被GC发现，但其内部的指针字段尚未被完全扫描的对象。灰色对象构成了标记过程的“波前”。
-   **黑色（Black）**：已被GC发现，并且其所有指针字段都已被扫描完毕的对象。

标记过程可以描述为：
1.  初始时，所有对象为白色。根集合直接引用的对象被置为灰色。
2.  GC不断从灰色集合中取出一个对象，将其置为黑色。
3.  然后，G[C扫描](@entry_id:747037)该对象的所有指针字段。对于每个字段引用的白色对象，将其置为灰色。
4.  重复步骤2和3，直到灰色集合为空。

在整个过程中，必须维持一个至关重要的**三色不变式（Tri-Color Invariant）**：**不存在从黑色对象到白色对象的直接引用**。这个不变式的维持是确保所有存活对象最终都能被正确标记（变为黑色）的关键。

### 整理阶段：重定位对象与更新指针

标记阶段完成后，所有存活对象都被标记。整理阶段的目标是将这些存活对象移动到内存的一端，从而形成一个大的连续空闲区域。这个过程分为两步：计算新地址和移动对象，但其核心挑战在于**指针修复（Pointer Fix-up）**。

#### 重定位的根本挑战

当一个对象从旧地址 $addr(O)$ 被移动到新地址 $addr'(O)$ 时，所有指向 $addr(O)$ 的指针都失效了。这些指针必须被精确地更新为新的地址 $addr'(O)$。这个[更新过程](@entry_id:273573)必须覆盖所有引用，包括根集合中的引用，以及其他存活对象内部的引用，甚至包括那些深层嵌套的引用（例如，对象A引用对象B，对象B引用对象C，C的指针也需要更新）[@problem_id:3657461]。

一个常见的误解是，只要更新了根集合的直接引用，嵌套的引用就能通过[可达性](@entry_id:271693)“自动”修复。这是错误的。指针的本质是一个地址值，移动对象不会改变内存中存储的这个数值。因此，任何一个正确的整理算法都必须包含一个系统性的策略，来计算每个存活对象的**转发地址（Forwarding Address）**，并在移动对象后，找到并更新所有指向该对象的引用。这个更新必须**不多不少，恰好一次**。更新两次会导致错误，例如对一个已经是新地址的指针再次应用转发函数，会得到一个无意义的地址 [@problem_id:3657461]。

#### 整理算法

根据实现方式的不同，整理算法主要分为几类。

**1. 多遍整理算法（Multi-Pass Compaction）**

这类算法通过多次遍历堆来完成整理，其逻辑清晰，易于理解。一个经典的实现是使用**转发指针（Forwarding Pointers）** [@problem_id:3657496]，通常包含三个阶段：

-   **第一遍：计算转发地址**。GC顺序扫描堆，为每个存活对象计算其新地址。这个新地址（即转发地址）被存储在原对象的对象头中。此时，对象尚未移动，旧地址空间扮演了新旧[地址映射](@entry_id:170087)表的角色。
-   **第二遍：更新指针**。GC再次扫描所有存活对象（以及根集合）。对于遇到的每一个指针，它会查找该指针所指向的旧地址，从其对象头中读取转发地址，并将指针值更新为该转发地址。
-   **第三遍：移动对象**。GC最后一次遍历堆，将每个存活对象从其旧地址按位复制到其转发地址。

这个策略的正确性在于，在所有指针都被更新之前，旧对象的内容和新地址信息都得以保留，确保了信息不会丢失 [@problem_id:3657461]。

**2. 滑动整理算法（Sliding Compaction）**

滑动整理算法试图在更少的遍历中完成任务，其基本思想是维持一个指向当前空闲位置的指针 `free_ptr`，然后将存活对象“滑动”到这个位置。

一个简单的例子是**双指针算法（Two-Finger Algorithm）** [@problem_id:3657483]。该算法使用两个指针：一个左指针 `L` 从堆的低地址开始向右移动，寻找空闲槽位；一个右指针 `R` 从高地址开始向左移动，寻找存活对象。当 `L` 找到一个空闲槽位且 `R` 找到一个存活对象时，就将 `R` 指向的对象移动到 `L` 指向的位置，然后继续扫描。这个过程不断进行，直到 `L` 和 `R` 相遇或交错，此时堆的低地址部分就形成了一个紧凑的存活对象区域。

更复杂的单遍滑动算法需要处理一个棘手的问题：在扫描过程中，一个对象内部的指针可能指向一个尚未被移动的对象（**前向引用**）或一个已经被移动的对象（**后向引用**）。对于后向引用，由于其目标对象的新地址已知，可以直接更新。对于前向引用，则必须将该指针的位置记录在一个**待修复集合（Fix-up Set）**中，等到其目标对象被移动时，再回来更新这些记录在案的指针 [@problem_id:3657496]。

### 整理的特性与优势

整理阶段不仅仅是为了消除碎片，它还带来了其他重要的性能优势。

#### 提升[缓存局部性](@entry_id:637831)

将存活对象紧密地[排列](@entry_id:136432)在一起，极大地改善了程序的**空间局部性（Spatial Locality）**。当程序访问一个对象后，它很可能会接着访问在内存中邻近的对象。在整理过的堆上，这些邻近访问更有可能命中同一个[CPU缓存](@entry_id:748001)行（Cache Line），从而减少昂贵的内存访问延迟。

我们可以通过一个简单的模型来量化这一效应 [@problem_id:3657484]。假设程序的[平均内存访问时间](@entry_id:746603) $\bar{t}$ 由缓存命中时间 $t_h$ 和未命中惩罚 $t_m$ 决定：$\bar{t} = H \cdot t_h + (1 - H) \cdot t_m$，其中 $H$ 是缓存命中率。假设每次访问一个新缓存行导致一次未命中，而对该行内其他字的访问都是命中。如果一个缓存行可以容纳 $L$ 个字，那么命中率 $H = (L-1)/L$。

-   **整理前**：堆高度碎片化，访问不连续，假设平均每次访问只能利用到缓存行的 $1.2$ 个字，即 $L_{\text{before}} = 1.2$。此时命中率 $H_{\text{before}} = (1.2-1)/1.2 = 1/6$。
-   **整理后**：对象连续存放，访问是顺序的。如果缓存行大小为64字节，字大小为8字节，则 $L_{\text{after}} = 64/8 = 8$。此时命中率 $H_{\text{after}} = (8-1)/8 = 7/8$。

假设 $t_h = 4$ ns, $t_m = 60$ ns，则整理前的平均访问时间 $\bar{t}_{\text{before}} = \frac{1}{6} \cdot 4 + \frac{5}{6} \cdot 60 \approx 50.67$ ns，而整理后为 $\bar{t}_{\text{after}} = \frac{7}{8} \cdot 4 + \frac{1}{8} \cdot 60 = 11$ ns。由于整理过程本身的内存访问也受益于这种局部性改善，GC暂停时间会显著缩短，性能提升可达数倍之多（在此例中为 $50.67 / 11 \approx 4.606$ 倍）[@problem_id:3657484]。

#### 稳定整理

一个整理算法被称为**稳定的（Stable）**，如果它能保持存活对象集合的相对地址顺序。也就是说，如果在整理前 $addr(X)  addr(Y)$，那么整理后必然有 $addr'(X)  addr'(Y)$。

典型的滑动整理算法，如基于前缀和计算新地址的算法，是稳定的。相反，一些试[图优化](@entry_id:261938)空间布局的算法，例如按对象尺寸从大到小[排列](@entry_id:136432)，则是**不稳定的（Unstable）** [@problem_id:3657478]。

稳定性具有以下优点：
-   **指针[单调性](@entry_id:143760)（Pointer Monotonicity）**：所有对象的地址要么保持不变，要么向低地址方向移动，但相对顺序不变。这使得程序的行为更可预测。
-   **简化数据结构维护**：对于某些依赖于对象地址序的[数据结构](@entry_id:262134)（例如，以对象地址为键的[二叉搜索树](@entry_id:635006)或[B树](@entry_id:635716)），稳定的GC允许直接在原地更新键值，而无需进行复杂的[树旋转](@entry_id:636182)或重平衡操作，因为所有键的相对大小关系都得到了保持 [@problem_id:3657478]。
-   **减小对象间距**：稳定整理确保任意两个存活对象之间的距离不会增加，这有助于维持已有的良好局部性 [@problem_id:3657478]。

### 高级主题：并发、并行与延迟

传统的标记-整理GC在执行期间需要完全暂停应用程序，这被称为**Stop-The-World (STW)**。对于追求低延迟的现代应用（如交互式服务、游戏等），长时间的STW暂停是不可接受的。因此，GC的设计演化出了并发、并行和增量技术。

#### 延迟问题与并发标记

对于一个中等大小的堆（例如512 MiB），即使采用[多线程](@entry_id:752340)并行执行，一次完整的STW标记-整理暂停也可能持续十几毫秒，这通常会超出严格的延迟预算（例如15ms）[@problem_id:3657465]。这迫使我们将GC的大部分工作与应用程序**并发（concurrently）**或**增量（incrementally）**执行。

标记阶段是并发化的首选目标。当GC线程在后台进行对象[图追踪](@entry_id:263851)时，应用程序线程（**mutator**）可以继续运行。然而，这引入了一个严峻的挑战：mutator可能会在G[C扫描](@entry_id:747037)过程中修改对象图，从而破坏三色不变式。最危险的情况是，一个已经被扫描完毕的黑色对象，被mutator修改为指向一个尚未被发现的白色对象。如果没有特殊机制，GC将不会重新扫描这个黑色对象，从而导致这个白色对象及其可达的[子图](@entry_id:273342)被错误地回收，这就是著名的**“丢失对象问题”** [@problem_id:3657422]。

为了解决这个问题，编译器会插入**[写屏障](@entry_id:756777)（Write Barrier）**。[写屏障](@entry_id:756777)是一段在每次指针写入操作时执行的特殊代码，用于通知GC对象图发生了变化。常见的[写屏障](@entry_id:756777)策略包括：
-   **[增量更新](@entry_id:750602)（Incremental Update）**：当一个写操作 `x.f = y` 发生时，如果 `x` 是黑色而 `y` 是白色，[写屏障](@entry_id:756777)会立即将 `y` 涂成灰色，确保GC能够扫描它。
-   **基于快照的屏障（Snapshot-At-The-Beginning, SATB）**：[写屏障](@entry_id:756777)不关心新值 `y`，而是捕获被覆盖的旧指针值。它确保在本次GC周期中，所有在标记开始时（逻辑上的“快照”时刻）可达的对象最终都会被标记。这相当于保留了标记开始时的对象图，防止对象丢失。

不同的[写屏障](@entry_id:756777)有不同的性能开销。例如，SATB屏障通常比[增量更新](@entry_id:750602)屏障更快。在选择时，必须评估其对应用程序[吞吐量](@entry_id:271802)的影响是否在可接受的预算之内 [@problem_id:3657465]。相比之下，在每次读操作时都进行检查的**[读屏障](@entry_id:754124)（Read Barrier）**通常开销过大，难以在通用场景下接受 [@problem_id:3657465]。

#### 并行与增量整理

整理阶段由于涉及大规模的对象移动和指针修改，并发执行的难度极高。因此，更常见的做法是在STW暂停中进行，但通过**[并行化](@entry_id:753104)（Parallelism）**和**增量化（Incrementalism）**来缩短暂停时间。

-   **并行整理**：在[多核处理器](@entry_id:752266)上，整理工作可以被划分给多个GC线程同时执行。例如，计算转发地址这一步，可以通过将堆分成多个块（chunk），各线程并行计算块内对象的存活大小，然后通过一次**并行前缀和（Parallel Prefix Sum）**计算出每个块在整理后的起始地址，最后各线程再并行地进行对象移动和指针修复 [@problem_id:3657426]。并行前缀和是一种高效的[并行算法](@entry_id:271337)，其时间复杂度（span）为对数级别，远非“固有串行”。

-   **增量整理**：如果整个整理工作即使并行化后暂停时间仍然过长，可以将其分解为多次更短的STW暂停。每次暂停只整理堆的一小部分（一个**切片（slice）**或一个**区域（region）**）。这种方法被称为**增量整理**或**分代整理**中的**疏散（Evacuation）**。为了确保正确性，GC必须精确追踪跨区域的指针（例如，从未整理区域指向已整理区域的指针），这通常需要借助一种特殊的[写屏障](@entry_id:756777)（如**卡片标记，Card Marking**）来维护**记忆集（Remembered Sets）** [@problem_id:3657465]。

通过这些先进技术的组合，现代标记-整理垃圾收集器能够在满足严苛延迟要求的同时，有效管理内存，消除碎片，并为应用程序提供优异的性能。