## 引言
在追求极致程序性能的道路上，消除不必要的计算是[编译器优化](@entry_id:747548)永恒的主题。然而，许多冗余并非在所有执行路径上都显而易见。部分冗余消除（Partial Redundancy Elimination, PRE）正是为了解决这一挑战而生的一项精妙技术，它超越了传统的[公共子表达式消除](@entry_id:747511)，能够处理那些仅在部分执行路径上重复出现的计算。本文旨在系统性地揭示PRE的内在机制与广泛影响，填补从理论理解到实践应用的知识鸿沟。

本文将引导您完成三个层次的学习旅程。首先，在“原理与机制”一章，我们将深入PRE的核心思想，剖析其赖以成立的数据流分析基础，如可用性与可预期性，并探讨在真实世界编译器中必须克服的副作用、[内存别名](@entry_id:174277)和异常等挑战。接着，在“应用与跨学科关联”一章，我们将展示PRE并非孤立的技术，而是如何与过程内联、[循环优化](@entry_id:751480)等其他编译技术协同工作，并将其优化思想延伸至分布式系统、计算机安全等多个领域。最后，通过“动手实践”环节，您将有机会通过具体案例，加深对PRE在不同场景下应用和权衡的理解。

让我们从PRE最根本的原理开始，探索它如何智能地重塑代码以提升效率。

## 原理与机制

在编译器的优化阶段，一个核心目标是消除程序中的冗余计算，从而提升执行效率。部分冗余消除（Partial Redundancy Elimination, PRE）是一项强大而基础的[优化技术](@entry_id:635438)，它旨在移除那些在某些执行路径上（但非全部）重复出现的计算。与处理完全冗余计算的传统[公共子表达式消除](@entry_id:747511)不同，PRE 的精妙之处在于它能够通过在某些路径上主动插入计算，将“部分”冗余转化为“完全”冗余，然后再将其消除。本章将深入探讨 PRE 的核心原理、形式化基础及其在现实世界[编译器设计](@entry_id:271989)中必须应对的各种约束。

### 部分冗余消除的核心思想

让我们从一个典型的场景开始理解部分冗余消除。考虑一个[条件语句](@entry_id:261295)，其中一个表达式在 `if` 分支中被计算，并且在 `if-else` 结构之后的[汇合](@entry_id:148680)点再次被需要。

例如，在一个具有菱形[控制流图](@entry_id:747825)的程序片段中，代码块 $B_1$ 根据某个[条件跳转](@entry_id:747665)到 $B_2$ 或 $B_3$，而 $B_2$ 和 $B_3$ 最终都会[汇合](@entry_id:148680)到代码块 $B_4$。假设表达式 $e = x + y$ 在 $B_2$ 分支和汇合点 $B_4$ 中都被计算了，但在 $B_3$ 分支中没有。

```
// B1: (x, y 在此之前已定义)
if (condition) goto B2; else goto B3;

// B2:
t1 = x + y;
...
goto B4;

// B3:
...
goto B4;

// B4: (B2 和 B3 的[汇合](@entry_id:148680)点)
t2 = x + y;
use(t2);
```

在这种情况下，沿着路径 $B_1 \rightarrow B_2 \rightarrow B_4$，表达式 $x+y$ 被计算了两次，这显然是冗余的。然而，沿着路径 $B_1 \rightarrow B_3 \rightarrow B_4$，表达式只在 $B_4$ 中计算了一次，因此 $B_4$ 中的计算并非“完全”冗余。这就是**部分冗余**。

PRE 的目标是通过[代码移动](@entry_id:747440)来消除这种部分冗余。一个直观的策略是将计算从出现冗余的分支（$B_2$）中“向上”移动到一个公共的祖先节点。在上述例子中，最理想的位置是 $B_1$ 的末尾。通过在 $B_1$ 的末尾计算一次 $r = x+y$，我们可以用这个临时变量 $r$ 的值来替换 $B_2$ 和 $B_4$ 中的原始计算。

然而，这种[代码移动](@entry_id:747440)必须保证程序的语义不变。一个关键的挑战是，在移动计算之后，我们必须仔细确定哪些后续的表达式可以被安全地替换。如果表达式的某个操作数（例如 $x$ 或 $y$）在 hoisted 计算点和原始使用点之间被重新定义，那么原始表达式的值就已经发生了变化，不能再用 hoisted 的结果来替换。

考虑一个更复杂的场景 [@problem_id:3661929]：表达式 $x+y$ 在两个分支 $B_2$ 和 $B_3$ 中都出现了。如果在 $B_1$ 的末尾插入 $r := x+y$，那么在 $B_2$ 和 $B_3$ 中，只要 $x$ 和 $y$ 的值没有改变，我们就可以用 $r$ 来替换 $x+y$。但是，如果在 $B_2$ 中间存在一条语句 `x := h(x)`，那么这条语句之后的所有 $x+y$ 计算都不能再被 $r$ 替换，因为 $x$ 的值已经改变。同样，如果在 $B_3$ 中存在 `y := k(y)`，其后的 $x+y$ 计算也不能被替换。最终，在汇合点 $B_4$，由于两条路径都修改了 $x$ 或 $y$，所以 $B_4$ 中的 $x+y$ 也不能被 $r$ 替换。这个例子清晰地表明，PRE 不仅仅是移动代码，还必须精确地追踪变量的定义和值的可用性。

### 形式化基础：PRE 的数据流分析

为了系统地、安全地实施 PRE，编译器依赖于严谨的数据流分析。几个核心概念是 PRE 算法的基石。

#### 可用性 (Availability)

一个表达式 $e$ 在程序点 $p$ 是**可用的**（available），如果从程序入口到点 $p$ 的**所有**路径上，$e$ 都已经被计算过，并且自最后一次计算以来，它的任何操作数都未被重新定义。

可用性对应于**完全冗余**。如果一个表达式在某点是可用的，那么在该点的计算就是完全多余的，可以直接用之前计算的结果替换。

#### 可预期性 (Anticipatability)

一个表达式 $e$ 在程序点 $p$ 是**可预期的**（anticipatable），如果从点 $p$ 出发到程序出口的**所有**路径上，都会在 $e$ 的任何操作数被重新定义之前计算 $e$。这个性质有时也被称为**下行安全性**（down-safety），因为它保证了将计算“向下”移动或在当前点插入计算不会是徒劳的——这个计算的结果未来一定会被用到。

可预期性是保证[代码移动](@entry_id:747440)安全性的关键。将一个计算提升到一个更早的位置（hoisting），只有当这个计算在提升点是可预期的，才能确保这种移动不会在某些原本不需要该计算的路径上引入不必要的计算。

让我们通过一个对比鲜明的例子 [@problem_id:3661891] 来深入理解可预期性。假设我们考虑两个表达式，$e_x = \text{hash}(x)$ 和 $e_y = \text{hash}(y)$。在一个菱形控制流中，从 $B_0$ 分支到 $B_1$ 和 $B_2$。在 $B_1$ 路径上，$e_x$ 和 $e_y$ 都被计算。在 $B_2$ 路径上，首先有 `y := y + 1` 的赋值，然后计算 $e_x$。在[汇合](@entry_id:148680)点 $J$，$e_x$ 和 $e_y$ 都被使用。

我们能否将 $e_x$ 和 $e_y$ 都提升到 $B_0$ 的末尾呢？

*   对于 $e_x = \text{hash}(x)$：从 $B_0$ 出发的所有路径（无论是经过 $B_1$ 还是 $B_2$）最终都会在操作数 $x$ 被修改之前计算 $\text{hash}(x)$。因此，$e_x$ 在 $B_0$ 的出口是**可预期的**。提升是安全的。

*   对于 $e_y = \text{hash}(y)$：沿着 $B_0 \rightarrow B_2 \rightarrow J$ 这条路径，操作数 $y$ 在 $B_2$ 中被 `y := y + 1` 重新定义了。这个重定义发生在[汇合](@entry_id:148680)点 $J$ 使用 $\text{hash}(y)$ 之前。因此，如果在 $B_0$ 计算了基于旧 $y$ 值的 $\text{hash}(y)$，这个结果对于 $B_2$ 路径来说是错误的。由于存在一条路径在计算表达式之前修改了其操作数，$e_y$ 在 $B_0$ 的出口就**不是可预期的**。提升是不安全的。

这个例子清晰地揭示了，一个操作数的重定义会“杀死”表达式的可预期性，从而阻止其被安全地提升。

基于这些概念，一个经典的 PRE 算法框架可以概括为：
1.  通过数据流分析，计算出在各个程序点哪些表达式是可用的、哪些是可预期的。
2.  识别出部分冗余的表达式（即在某个汇合点的入口处，只在部分前驱路径上可用的表达式）。
3.  在那些缺少该表达式计算的路径上，找到一个满足可预期性的、最晚的程序点，并在此插入该表达式的计算。这个插入操作将部分冗余转化为了完全冗余。
4.  最后，利用可用性分析，消除现在已是完全冗余的原始计算。

现代 PRE 算法，如“懒惰[代码移动](@entry_id:747440)”（Lazy Code Motion），通过结合“最早”和“最晚”放置策略，能够找到最优的插入点，既消除了冗余，又最小化了临时变量的生命周期，从而减轻了后续[寄存器分配](@entry_id:754199)的压力 [@problem_id:3661875]。

### 实践中的 PRE：约束与挑战

理论上的 PRE 算法是优雅的，但在应用于真实世界的程序时，编译器必须处理一系列复杂的现实约束。

#### 副作用处理

PRE 的基本假设是它所优化的表达式是**纯函数**的，即计算过程不产生任何可观测的**副作用**（side effects），如修改全局变量、执行 I/O 操作或改变系统状态。如果一个表达式带有副作用，对其进行移动、复制或删除都可能改变程序的原始语义。

一个典型的例子是[函数调用](@entry_id:753765) [@problem_id:3661844]。假设我们有一个[函数调用](@entry_id:753765) `g(z)`，在程序的两个分支中都被计算。如果 `g` 是一个纯粹的数学函数，PRE 可以安全地将其提升到分支之前，将两次调用合并为一次。但是，如果 `g` 函数内部包含一个副作用，例如向日志文件写入一条记录，情况就完全不同了。原始程序在每个分支都会执行一次 `g(z)`，总共会写入两条日志。如果 PRE 将其优化为一次调用，那么最终只会写入一条日志。这种可观测行为的改变是不可接受的，因此，对于带有副作用的表达式，PRE 必须禁用或采取极其保守的策略。

#### 内存操作与[别名](@entry_id:146322)分析

当表达式涉及内存访问时，例如数组访问 `arr[i]` 或指针解引用 `*p`，情况会变得更加复杂。这是因为内存状态是全局的，一次内存写入（store）可能会影响后续任意一次内存读取（load）的结果。

一个 `arr[k] = h` 这样的存储操作会“杀死”任何可能依赖于 `arr[k]` 值的表达式。为了安全地移动一个加载操作，如 `load arr[j]`，编译器必须确保在移动路径上没有可能修改 `arr[j]` 所指向内存的存储操作。这就引出了**[别名](@entry_id:146322)分析**（Alias Analysis）的需求。

别名分析试图回答：两个内存引用（如 `arr[j]` 和 `arr[k]`）是否可能、必然或绝不可能指向同一内存位置。

*   **May-alias**：`arr[j]` 和 `arr[k]` 可能指向同一位置（例如，当编译器无法确定 `j` 是否等于 `k` 时）。
*   **Must-alias**：`arr[j]` 和 `arr[k]` 必然指向同一位置（例如，当 `j` 和 `k` 是同一个变量时）。
*   **No-alias**：`arr[j]` 和 `arr[k]` 绝不可能指向同一位置。

在进行 PRE 时，如果一个加载操作 `load arr[j]` 的移动路径上遇到了一个存储操作 `store arr[k]`，只有当[别名](@entry_id:146322)分析能够证明 `arr[j]` 和 `arr[k]` 是 **no-alias** 时，这次移动才是安全的 [@problem_id:3661807]。如果它们是 **may-alias**，编译器必须保守地假设存储操作改变了加载操作的值，从而禁止[代码移动](@entry_id:747440)。此外，如果分析证明了 **must-alias**（例如，`i` 和 `j` 必然相等），PRE 甚至可以进行更激进的优化，例如将 `arr[i] + arr[j]` 优化为 `tmp = arr[i]; tmp + tmp;`，将两次加载合并为一次。

#### 异常指令与[推测执行](@entry_id:755202)

某些指令，如[整数除法](@entry_id:154296)、浮点数运算或内存解引用，可能会在特定条件下触发异常或陷阱（trap）。例如，`p/q` 在 `q=0` 时会触发除零异常。对这类**可能陷阱的指令**（trapping instructions）进行[代码移动](@entry_id:747440)必须格外小心，因为不当的移动可能会在原本不会发生异常的路径上引入新的异常。

例如，考虑表达式 `p/q` [@problem_id:3661903]。它在程序的某些路径上被计算，但不是所有路径。如果我们简单地将其提升到一个所有路径都经过的公共祖先节点，那么当程序走到一条原本不计算 `p/q` 的路径时，如果恰好 `q=0`，就会触发一个本不该出现的异常。这违反了**精确异常**（precise exceptions）的语义。

为了在保证安全的前提下进行优化，编译器可以采用**受保护的[推测执行](@entry_id:755202)**（guarded speculation）。其思想是：
1.  将计算（如 `t := p/q`）提升到一个较早的位置。
2.  同时，在这个位置为其加上一个“保护”，即一个条件检查，该检查精确地复现了原始程序中执行该计算所需满足的[控制流](@entry_id:273851)条件。
3.  只有当保护条件成立时，才执行这个可能陷阱的计算。

例如，如果原始程序在条件 `c` 为真或条件 `d` 为真时计算 `p/q`，那么其路径谓词就是 `c OR d`。安全的[推测执行](@entry_id:755202)会将计算转化为：`if (c OR d) { t := p/q; }`。这样，计算被提前了，但触发异常的条件与原始程序完全一致，保证了语义的正确性。

#### 与其他优化的交互

最后，PRE 并非孤立存在，它必须与编译器的其他优化阶段协同工作，并权衡不同优化目标之间的冲突。

*   **与[寄存器分配](@entry_id:754199)的交互**：PRE 通过消除计算来减少指令数，但它通常会引入新的临时变量，并且延长这些变量的**生命周期**（live range）。一个变量的生命周期越长，它与其他变量同时“存活”的可能性就越大，从而增加了对寄存器的需求，即**[寄存器压力](@entry_id:754204)**（register pressure）。在一个寄存器数量有限的机器上，如果 PRE 导致的[寄存器压力](@entry_id:754204)超过了可用寄存器数量，[寄存器分配](@entry_id:754199)器就不得不将某些变量**溢出**（spill）到内存中。一次[溢出](@entry_id:172355)操作（存储+加载）的开销可能远高于一次算术运算。因此，一个精良的编译器必须建立成本模型，权衡 PRE 节省的计算成本与可能带来的溢出成本 [@problem_id:3661819]。如果$节省的计算开销  增加的溢出开销$，那么这次 PRE 优化就是得不偿失的。

*   **对代码大小的影响**：在嵌入式系统或对缓存性能敏感的应用中，代码大小也是一个重要的优化目标。如前所述，当处理可能陷阱的指令时，PRE 可能需要复制保护条件。如果一个汇合点有 $k$ 个前驱路径都需要插入受保护的计算，而原始代码中只有 $r$ 个冗余计算被消除，那么代码大小的变化大致为 $k \times (\text{size_guard} + \text{size_expr}) - r \times \text{size_expr}$。如果这个值大于零，意味着优化会增加代码体积。因此，一个关注代码大小的编译器可能会采用启发式规则，仅当代码大小不增加或增加在可接受范围内时才执行 PRE [@problem_id:3661906]。

### [静态单赋值形式](@entry_id:755286)（SSA）下的 PRE

[静态单赋值](@entry_id:755378)（Static Single Assignment, SSA）是一种[中间表示](@entry_id:750746)（IR），它要求每个变量只被赋值一次。在 SSA 形式下，PRE 的概念与**[全局值编号](@entry_id:749934)**（Global Value Numbering, GVN）紧密地融合在一起。GVN 的目标是为程序中每个计算出的唯一值分配一个编号，并消除所有重复计算相同值的表达式。

在 SSA 中，由于每个变量只有一个定义点，词法上相同的表达式（如 `x+y`）如果其操作数版本也相同（如 `x_1 + y_1`），那么它们必然计算出相同的值。PRE 的问题在很大程度上转化为识别和消除具有相同[值编号](@entry_id:756409)的计算。

一个特别优雅的例子是当不同路径计算出不同但相关的表达式时 [@problem_id:3661877]。假设在分支 $B_1$ 中计算了 $e_1 = x_1 \times y_0$，在分支 $B_2$ 中计算了 $e_2 = x_0 \times y_2$。在[汇合](@entry_id:148680)点 $B_3$，需要的值是 $x_3 \times y_3$，其中 $x_3 = \phi(x_1, x_0)$，$y_3 = \phi(y_0, y_2)$。通过分析可以发现，汇合点所需的计算其实就是对前面两条路径计算结果的合并。在 SSA 中，这可以非常自然地通过为表达式本身引入一个 $\phi$ 函数来解决：
$$ e_3 = \phi(e_1, e_2) $$
这样，在 $B_3$ 中的乘法计算就被完全消除了，取而代之的是一个无计算成本的 $\phi$ [合并操作](@entry_id:636132)。

当然，并非所有情况都如此理想。如果不同路径上的表达式是根本不相关的，例如一条路径计算 $x_0 + y_0$，另一条计算 $x_1 + y_0$（其中 $x_1$ 是 $x_0$ 的新版本），那么这两个表达式的值是不同的。在这种情况下，无法通过简单的提升来消除冗余。计算必须在[汇合](@entry_id:148680)点之后，在使用合并后的操作数值（如 $x_J = \phi(x_0, x_1)$）的地方进行 [@problem_id:3661842]。

综上所述，部分冗余消除是一项体现了编译器智能与权衡艺术的经典优化。它不仅依赖于严谨的[数据流](@entry_id:748201)分析理论，还需要在实践中精巧地处理副作用、[内存别名](@entry_id:174277)、异常语义以及与其他优化阶段的复杂交互，最终在保证程序正确性的前提下，实现性能的显著提升。