## 引言
[代码生成器](@entry_id:747435)是编译器的最后阶段，也是连接高级语言抽象与底层硬件现实的关键桥梁。它的任务是将平台无关的[中间表示](@entry_id:750746)（IR）转化为特定目标机器的可执行代码。然而，这一过程远非简单的机械翻译，而是一个充满挑战与权衡的复杂决策过程，直接决定了软件的最终性能、效率和安全性。许多开发者视其为一个“黑盒”，不了解其内部的优化决策是如何做出的，从而错失了编写更高效代码的机会。

本文旨在揭开[代码生成器](@entry_id:747435)的神秘面纱，系统性地阐述其核心职责与工作原理。读者将通过本文学习到：
- **第一章：原理与机制**，将深入剖析[代码生成器](@entry_id:747435)的三大基石——[指令选择](@entry_id:750687)、[寄存器分配](@entry_id:754199)和[指令调度](@entry_id:750686)，理解它们如何通过精确的代价模型和算法来优化代码。
- **第二章：应用和跨学科联系**，将展示这些原理如何在[高性能计算](@entry_id:169980)、[密码学](@entry_id:139166)、系统编程等不同领域中发挥作用，揭示[代码生成](@entry_id:747434)在满足多样化需求时的适应性与权衡。
- **第三章：动手实践**，将通过一系列精心设计的练习，引导读者亲身体验[代码生成](@entry_id:747434)中的关键决策过程。

通过这趟从理论到应用的旅程，我们将共同探索[代码生成器](@entry_id:747435)如何将高级编程思想精雕细琢，铸造成在硅片上高效、可靠运行的指令序列。

## 原理与机制

[代码生成器](@entry_id:747435)作为编译器的后端，其核心使命是将独立于具体机器的[中间表示](@entry_id:750746)（Intermediate Representation, IR）转化为目标机器的可执行代码。这一过程远非简单的逐条翻译，而是一个涉及多重权衡与优化的复杂决策过程。一个优秀的[代码生成器](@entry_id:747435)必须承担三大核心职责：**[指令选择](@entry_id:750687) (Instruction Selection)**、**[寄存器分配](@entry_id:754199) (Register Allocation)** 和 **[指令调度](@entry_id:750686) (Instruction Scheduling)**。这三项任务相互交织，共同决定了最终生成代码的正确性、效率和体积。本章将深入探讨这些职责背后的基本原理和关键机制，并通过一系列具体的计算和决策问题来阐明它们在实践中的应用。

### [指令选择](@entry_id:750687)：将[中间表示](@entry_id:750746)映射为机器指令

[指令选择](@entry_id:750687)是[代码生成](@entry_id:747434)的第一步，其目标是为[中间表示](@entry_id:750746)的每个操作或操作序列，从目标机器的指令集中选择一个等价且高效的指令序列。这项任务看似直接，实则充满了优化机会和必须遵守的语义约束。

#### 强度削减：选择代价更低的计算方式

一个常见的优化原则是**强度削减 (Strength Reduction)**，即用计算上更“便宜”的操作来替代更“昂贵”的操作。一个经典的例子是使用位移和加减法来替代整数乘法。

例如，考虑将表达式 $y = k \cdot x$ 编译到目标代码，其中 $k$ 是一个已知的编译期常量。如果目标机器的乘法指令代价高昂，[代码生成器](@entry_id:747435)就需要探索是否存在更优的实现。假设一个体系结构的静态代价模型如下：整数乘法 `mul` 耗时 $c_{mul} = 6$ 个周期，而加法 `add`、减法 `sub` 和常数位移 `shift` 均耗时 $1$ 个周期。对于计算 $y = 23 \cdot x$，[代码生成器](@entry_id:747435)面临选择：是直接使用 `mul` 指令，还是合成一个等价的位移-加法网络？[@problem_id:3628202]

直接使用[硬件乘法器](@entry_id:176044)的代价是固定的 $6$ 个周期。作为替代方案，我们可以利用 $k=23$ 的二[进制](@entry_id:634389)表示 $10111_2$。这对应于 $23 = 16 + 4 + 2 + 1$。因此，$23 \cdot x$ 可以被分解为 $(x \ll 4) + (x \ll 2) + (x \ll 1) + x$。这个序列需要 $3$ 次位移和 $3$ 次加法，总代价为 $3 \times 1 + 3 \times 1 = 6$ 个周期，与硬件乘法相同，并无优势。

然而，更高级的[代码生成器](@entry_id:747435)会考虑使用减法，利用数的**规范有符位 (Canonical Signed Digit, CSD)** 表示来最小化非零项的数量。例如，$23$ 可以表示为 $32 - 8 - 1$，即 $2^5 - 2^3 - 1$。这启发我们用表达式 $(x \ll 5) - (x \ll 3) - x$ 来计算 $23 \cdot x$。这个序列包含 $2$ 次位移和 $2$ 次减法，总代价为 $1+1+1+1 = 4$ 个周期。由于 $4  6$，这个使用位移和减法的指令序列显然是更优的选择。[代码生成器](@entry_id:747435)通过这种基于代价模型的分析，选择最低成本的指令序列来覆盖 IR。

#### 复杂[模式匹配](@entry_id:137990)：利用高级[寻址模式](@entry_id:746273)

现代[指令集架构](@entry_id:172672)（ISA）通常提供复杂的[寻址模式](@entry_id:746273)，允许在单个指令中完成计算和内存访问。例如，C 语言中的指针后增量 `*(p++)` 和前减量 `*(--p)` 等常见模式，就可以被高效地映射到支持基址寄存器更新的[寻址模式](@entry_id:746273)上。

假设一个目标机器支持以下两种[寻址模式](@entry_id:746273)：[@problem_id:3628211]
- **后索引更新 (Post-indexed update)**：有效地址为基址寄存器 $R_n$ 的当前值，内存访问完成后，再将 $R_n$ 更新为 $R_n + d$。
- **前索引更新 (Pre-indexed update)**：先将基址寄存器 $R_n$ 的值加上偏移 $d$ 得到有效地址，进行内存访问后，再将 $R_n$ 更新为这个新地址。

对于 `*(p++)`，其语义是先使用指针 $p$ 的当前值进行解引用，然后将 $p$ 增加一个元素大小 $s$。这与**后索引更新**模式完美匹配：将 $p$ 存入 $R_n$，使用 $R_n$ 作为地址加载数据，然后以位移 $d=+s$ 更新 $R_n$。

对于 `*(--p)`，其语义是先将指针 $p$ 减去一个元素大小 $s$，然后使用更新后的指针值进行解引用。这与**前索引更新**模式[完美匹配](@entry_id:273916)：将 $p$ 存入 $R_n$，以位移 $d=-s$ 计算新地址并加载数据，然后将 $R_n$ 更新为该新地址。

然而，这种[指令选择](@entry_id:750687)的“收缩”优化并非无条件合法。[代码生成器](@entry_id:747435)必须确保此转换不改变程序的**可观察行为**。其合法性依赖于以下几个关键条件：
1.  **副作用定序**：在 `f(*(p++), g(p))` 这样的表达式中，C 标准对 `*(p++)` 的副作用（即 $p$ 的更新）与 `g(p)` 的[求值顺序](@entry_id:749112)可能没有严格规定。为了安全地收缩指令，编译器必须确保指针 $p$ 在当前完整表达式中没有其他读写，这样 $p$ 的更新时机相对于其他子表达式的求值就不再可观察。
2.  **`volatile` 语义**：如果指针 $p$ 或其指向的内存是 `volatile` 类型，编译器被禁止进行任何可能改变访存顺序或次数的优化。将独立的访存和[地址计算](@entry_id:746276)合并为一个[原子指令](@entry_id:746562)改变了可观察的事件序列，因此是非法的。
3.  **架构约束**：目标架构可能规定，在使用基址寄存器更新的指令中，加载的目标寄存器 $R_t$ 不能与基址寄存器 $R_n$ 相同（$R_t \neq R_n$），以避免写回冲突。

只有在满足所有这些条件时，[代码生成器](@entry_id:747435)才能合法地选择这些高级寻址指令，从而生成更紧凑、更高效的代码。

#### [控制流](@entry_id:273851)选择：分支与条件传送的权衡

对于高级语言中的选择结构，如 `t = c ? a : b`，[代码生成器](@entry_id:747435)通常有两种实现策略：使用条件分支，或使用条件传送指令（如 `cmov`）。这个选择对性能有显著影响，尤其是在现代深度流水线的处理器上。

- **条件分支 (Branch)**：当条件 $c$ 成立时，跳转到计算 $a$ 的代码块；否则，执行计算 $b$ 的代码块。这种方式的优点是通常只执行两条路径中的一条。其代价与处理器的**分支预测**能力密切相关。
- **条件传送 (Conditional Move)**：先无条件地计算出 $a$ 和 $b$ 的值，然后根据条件 $c$ 的结果，使用一条 `cmov` 指令从两个结果中选择一个赋给 $t$。这种方式避免了分支和潜在的分支预测错误惩罚，但代价是必须计算两边的表达式。

[代码生成器](@entry_id:747435)必须基于一个代价模型来做决策。假设：计算 $a$ 的延迟为 $C_a$，计算 $b$ 的延迟为 $C_b$；分支指令本身开销为 $B$，预测错误的概率为 $1-q$，惩罚为 $M$ 个周期；`cmov` 指令延迟为 $C_{cmov}$。[@problem_id:3628179]

分支策略的期望执行时间 $E_{branch}$ 为：
$$E_{branch} = (r \cdot C_a + (1-r) \cdot C_b) + (B + (1-q)M)$$
其中 $r$ 是条件 $c$ 为真的概率。第一部分是计算的期望时间，第二部分是[控制流](@entry_id:273851)的期望开销。

条件传送策略的期望执行时间 $E_{cmov}$ 为（假设 $a$ 和 $b$ [顺序计算](@entry_id:273887)）：
$$E_{cmov} = C_a + C_b + C_{cmov}$$
（在可以并行计算的[超标量处理器](@entry_id:755658)上，代价可能是 $\max(C_a, C_b) + C_{cmov}$）。

通过比较 $E_{branch}$ 和 $E_{cmov}$，[代码生成器](@entry_id:747435)可以做出明智的选择。例如，在一个场景中，条件 $c$ 高度不可预测（即 $r \approx 0.5$ 且分支预测准确率 $q$ 很低），导致 $(1-q)M$ 惩罚项很大，$E_{branch}$ 可能会远高于 $E_{cmov}$。此时，选择条件传送是更优的。反之，如果条件非常偏向某一侧（$r$ 接近 $0$ 或 $1$）且预测器准确率 $q$ 很高，分支的代价就会很小，成为更好的选择。这个决策过程体现了[代码生成器](@entry_id:747435)如何利用微体系结构特性（如分支预测）和程序行为特征（如分支偏[向性](@entry_id:144651)）来进行[性能优化](@entry_id:753341)。

#### 语义保持：处理异常与陷阱的正确性

[指令选择](@entry_id:750687)和优化的最高准则是**正确性**。一个转换是否合法，取决于它是否在所有情况下都保持了原始程序的**可观察行为 (Observable Behavior)**。可观察行为不仅包括程序的最终输出，还包括它在何处以及何时因错误（如除以零）而终止。

考虑一个简单的语言，其中 `print(n)` 是唯一的可观察操作，而除以零或模零会引发一个立即中止程序的运行时陷阱。[@problem_id:3628230]

- **合法的转换**：[常量折叠](@entry_id:747743)，如将 `print(2 * 3)` 替换为 `print(6)`，是合法的。因为乘法不会产生陷阱，表达式的求值是纯粹的，用其结果替换它不会改变任何可观察行为。同样，将一个已知的会产生陷阱的表达式，如 `1 / 0`，替换为一个在程序相同位置触发的显式 `trap` 指令，也是合法的。因为程序的输出序列和陷阱发生点相对于输出序列的位置都保持不变。

- **非法的转换**：
    1.  **错误地消除陷阱**：在 `print(1); t = x % 0; print(2);` 中，`x % 0` 必定引发陷阱。如果编译器错误地认为 `t` 未被使用而将此语句作为死代码消除，程序就会继续执行 `print(2)`。原始程序的行为是打印 `(1)` 然后陷阱，而转换后的程序行为是打印 `(1, 2)`。可观察行为被改变，故此转换非法。
    2.  **不安全的[代码移动](@entry_id:747440)**：在 `print(1); print(x / y);` 中，如果 $y=0$，程序会先打印 `(1)` 再陷阱。若编译器将 `print(x/y)` 移动到 `print(1)` 之前，那么当 $y=0$ 时，程序会立即陷阱，什么也不打印。这种代码重排将陷阱提前到了可观察输出之前，改变了行为，因此非法。同样，将 `t = 1 / 0` 从一个 `else` 分支中提升（hoist）到 `if` 语句之前，会导致在 `if` 分支本应安全执行的情况下提前触发陷阱。

[代码生成器](@entry_id:747435)必须具备精确的语义模型，以区分哪些转换是安全的，哪些会改变程序的异常行为，从而保证优化的正确性。

### [寄存器分配](@entry_id:754199)：管理稀缺的硬件资源

在选择了合适的指令后，[代码生成器](@entry_id:747435)必须决定这些指令的操作数存放在何处。由于处理器中的寄存器数量有限，而程序中的变量和临时值数量可能非常多，**[寄存器分配](@entry_id:754199) (Register Allocation)** 成为一项核心挑战。其目标是尽可能将值保存在寄存器中以获得高性能，同时在寄存器不足时，通过将值临时存入内存（称为**[溢出](@entry_id:172355) (Spilling)**）来解决冲突。

#### 寄存器需求分析与[溢出](@entry_id:172355)决策

对于一个给定的表达式，我们可以静态地计算出无[溢出](@entry_id:172355)执行所需的最小寄存器数量。Sethi-Ullman 算法为此提供了一个经典方法。

考虑表达式 $t_1 \leftarrow (a+b) \cdot (c-d)$，我们需要在一台只有 $2$ 个[通用寄存器](@entry_id:749779)（$R_0, R_1$）的机器上计算它。[@problem_id:3628172] 该算法通过给[表达式树](@entry_id:267225)的每个节点标注所需寄存器数量来工作：
1.  叶子节点（变量或常量）需要 $1$ 个寄存器来加载其值。
2.  对于一个内部节点，如果其左右子树需要的寄存器数不同，则该节点需要 $\max(SU(l), SU(r))$ 个寄存器（先计算需要更多寄存器的一侧）。
3.  如果左右子树需要的寄存器数相同，均为 $k$，则该节点需要 $k+1$ 个寄存器（因为计算一侧后其结果需占用一个寄存器，此时计算另一侧仍需 $k$ 个寄存器）。

应用此算法：
- $a, b, c, d$ 节点的需求均为 $1$。
- 加法节点 $(a+b)$ 的左右子节点需求均为 $1$，因此其需求为 $1+1=2$。
- 减法节点 $(c-d)$ 的左右子节点需求也均为 $1$，因此其需求也为 $2$。
- 最终的乘法节点，其左右子树（加法和减法子树）的需求均为 $2$。因此，整个[表达式树](@entry_id:267225)的根节点需求为 $2+1=3$ 个寄存器。

由于表达式的最小寄存器需求（$3$）超过了机器可用的寄存器数量（$2$），我们得出结论：**[溢出](@entry_id:172355)是不可避免的**。[代码生成器](@entry_id:747435)必须插入指令将某个中间结果存入内存。一个实现此目标的最小溢出策略如下：
1.  计算 $(a+b)$：`LOAD R0, a; LOAD R1, b; ADD R0, R0, R1`。结果 $(a+b)$ 在 $R_0$ 中。
2.  **溢出**：`STORE R0, M`。将 $(a+b)$ 的结果存到内存位置 $M$，释放 $R_0$ 和 $R_1$。这是必需的溢出操作。
3.  计算 $(c-d)$：`LOAD [R0](@entry_id:186827), c; LOAD R1, d; SUB [R0](@entry_id:186827), [R0](@entry_id:186827), R1`。结果 $(c-d)$ 在 $R_0$ 中。
4.  **重载**：`LOAD R1, M`。将之前溢出的值 $(a+b)$ 重新加载到 $R_1$ 中。
5.  最终计算：`MUL R1, R1, R0`。计算最终结果。

通过这种系统性分析，[代码生成器](@entry_id:747435)可以确定何时以及为何必须进行溢出，并生成相应的存取指令。

#### 溢出后的恢复：重载 vs. 再物质化

当一个被溢出的值再次被需要时，最直接的方法是从其内存[溢出](@entry_id:172355)槽中**重载 (Reload)** 回寄存器。然而，对于某些值，特别是可以由一小段指令[序列生成](@entry_id:635570)的常量，还存在另一种选择：**再物质化 (Rematerialization)**，即重新执行一遍生成该值的指令序列。

[代码生成器](@entry_id:747435)需要权衡这两种策略的代价。[@problem_id:3628208] 假设：
- 重载一个值需要执行一条 `load` 指令，其延迟依赖于缓存状态。例如，L1 缓存命中的延迟为 $L_1 = 4$ 周期，L2 缓存命中的延迟为 $L_2 = 12$ 周期。如果 L1 未命中率为 $m = 0.1$，那么 `load` 的期望延迟为 $\mathbb{E}[L] = (1 - m) \cdot L_1 + m \cdot L_2 = 0.9 \cdot 4 + 0.1 \cdot 12 = 4.8$ 周期。
- 再物质化一个常量需要执行一个包含 $n=3$ 条指令的依赖序列，每条指令延迟 $1$ 周期，总延迟为 $3$ 周期。
- 此外，再物质化可能会增加**[寄存器压力](@entry_id:754204) (Register Pressure)**，因为它引入了额外的临时值，可能导致周围代码产生更多溢出。模型为此增加了一个 $C_R = 2$ 周期的惩罚。

因此，总代价比较如下：
- **重载代价**：$C_{load} = \mathbb{E}[L] = 4.8$ 周期。
- **再物质化代价**：$C_{mat} = (\text{指令序列延迟}) + (\text{寄存器压力惩罚}) = 3 + 2 = 5$ 周期。

由于 $4.8  5$，在这种情况下，从内存重载是更优的选择。这个决策展示了现代[代码生成器](@entry_id:747435)如何结合体系结构特性（缓存层次）和编译时分析（[寄存器压力](@entry_id:754204)）来做出细致的优化选择。

#### 遵守[调用约定](@entry_id:753766)：调用者保存 vs. 被调用者保存

[寄存器分配](@entry_id:754199)还必须严格遵守**[应用程序二进制接口](@entry_id:746491) (Application Binary Interface, ABI)** 中定义的**[调用约定](@entry_id:753766) (Calling Convention)**。ABI 将寄存器划分为两类：
- **调用者保存 (Caller-Saved) / 调用易变 (Call-Clobbered)** 寄存器：函数调用可能会破坏这些寄存器中的值。如果调用者希望在[函数调用](@entry_id:753765)后继续使用其中的值，必须由**调用者**在调用前保存、调用后恢复。
- **被调用者保存 (Callee-Saved)** 寄存器：函数必须保证在返回时这些寄存器的值与进入时相同。如果被调用的函数需要使用这些寄存器，必须由**被调用者**在函数入口处保存、在出口处恢复。

当一个变量的生命周期跨越了一次或多次[函数调用](@entry_id:753765)时，[代码生成器](@entry_id:747435)必须决定是将其分配给[调用者保存寄存器](@entry_id:747092)还是[被调用者保存寄存器](@entry_id:747091)。这个决策是一个经典的代价权衡问题。[@problem_id:3628231]

假设一个临时变量 $t$ 在函数 $f$ 中跨越了 $C_1, C_2, C_3$ 三个调用点。
- **策略1：使用[被调用者保存寄存器](@entry_id:747091)**。函数 $f$（作为被调用者）需要在其入口（prologue）保存该寄存器一次，并在出口（epilogue）恢复一次。这个代价是固定的，与内部调用次数无关。设每次保存/恢复代价为 $c_s=3$ 周期，总代价为 $Cost_{callee} = 2 \cdot c_s = 6$ 周期。
- **策略2：使用[调用者保存寄存器](@entry_id:747092)**。函数 $f$（作为调用者）必须在每次调用 $C_i$ 之前保存 $t$，之后恢复 $t$。如果利用性能剖析数据（Profile Data）得知 $C_1, C_2, C_3$ 在每次调用 $f$ 期间的平均执行次数分别为 $w_1=0.6, w_2=0.5, w_3=0.6$，并且每次调用点的保存/恢复代价为 $c_m=2$ 周期，那么期望总代价为：
$$Cost_{caller} = (w_1 + w_2 + w_3) \cdot (2 \cdot c_m) = (0.6 + 0.5 + 0.6) \times (2 \cdot 2) = 1.7 \times 4 = 6.8 \text{ 周期}$$

比较两者代价，$6  6.8$，因此选择**[被调用者保存寄存器](@entry_id:747091)**更为有利。这个决策的通用法则是：当一个值跨越的动态调用次数的总保存/恢复代价，超过了一次性的函数级保存/恢复代价时，就应该优先考虑使用[被调用者保存寄存器](@entry_id:747091)。

### [指令调度](@entry_id:750686)与函数管理

选定了指令并分配了寄存器后，[代码生成器](@entry_id:747435)还需决定这些指令的执行顺序，即**[指令调度](@entry_id:750686) (Instruction Scheduling)**。其目标是在不违反数据依赖和资源约束的前提下，重排指令以最大化[指令级并行](@entry_id:750671)（Instruction-Level Parallelism, ILP），从而缩短程序的总执行时间。此外，[代码生成器](@entry_id:747435)还负责生成管理[函数调用](@entry_id:753765)的**函数序言 (prologue)** 和**函数尾声 (epilogue)**。

#### 基础块内的[指令调度](@entry_id:750686)

在一个没有分支的基础块（basic block）内，调度器试图将指令尽可能紧密地打包到每个时钟周期中。这需要仔细分析指令间的依赖关系和处理器资源。

- **数据依赖**：
    - **写后读 (Read-After-Write, RAW)**：真依赖。一条指令必须等待另一条指令写完结果后才能读取。这是最根本的约束。
    - **读[后写](@entry_id:756770) (Write-After-Read, WAR)**：反依赖。一条指令必须在另一条指令读取其操作数之后才能写入同一个位置。
    - **写[后写](@entry_id:756770) (Write-After-Write, WAW)**：输出依赖。两条指令写入同一个位置，必须保持原始的写入顺序。
    对于[乱序执行](@entry_id:753020)（Out-of-Order）核心，硬件[寄存器重命名](@entry_id:754205)可以消除 WAR 和 WAW 依赖，但对于[静态调度](@entry_id:755377)器，这些依赖必须被遵守以保证语义正确性。

- **资源约束**：处理器每个周期只能使用有限的功能单元（如 ALU、LSU、乘法器）和发射槽。

考虑一个双发射（dual-issue）处理器，调度器需要为一段指令序列构建一个依赖关系图（DAG），并使用一种策略（如**[列表调度](@entry_id:751360) List Scheduling**）来逐周期填充指令。[@problem_id:3628153] 调度器维护一个“就绪”指令列表，这些指令的所有依赖都已满足。在每个周期，它从就绪列表中选择指令进行发射，同时遵守资源约束。通常会优先选择位于**[关键路径](@entry_id:265231) (critical path)** 上的指令，因为这些指令的延迟直接决定了整个块的执行时间。通过精心调度，独立的指令可以与长延迟指令（如加载或乘法）并行执行，从而有效隐藏延迟，缩短整体执行时间。

#### 函数序言与尾声的生成

每个函数调用都需要一个**[栈帧](@entry_id:635120) (Stack Frame)** 来存储局部变量、传递参数以及保存寄存器。[代码生成器](@entry_id:747435)负责在函数入口生成**序言**代码来建立这个[栈帧](@entry_id:635120)，并在函数出口生成**尾声**代码来拆除它。

序言的主要工作包括：
1.  保存调用者传入的返回地址。
2.  保存需要保护的**被调用者保存**寄存器。
3.  在栈上为局部变量、数组和溢出槽分配空间。

尾声则执行相反的操作：
1.  将返回值放入指定寄存器。
2.  恢复之前保存的[被调用者保存寄存器](@entry_id:747091)。
3.  释放[栈帧](@entry_id:635120)空间。
4.  跳转回收到的返回地址。

生成这些代码时，一个至关重要的细节是**数据对齐 (Data Alignment)**。ABI 通常规定[栈指针](@entry_id:755333)在[函数调用](@entry_id:753765)前必须对齐到特定边界（如 16 字节），以支持 SIMD 指令等需要对齐访存的操作。[代码生成器](@entry_id:747435)必须精确计算栈帧中所有元素的大小，并插入适当的**填充 (padding)** 字节来保证局部变量（特别是数组和结构体）的对齐要求，并最终确保整个[栈帧](@entry_id:635120)的大小满足调用前的对齐约束。[@problem_id:3628169]

例如，在一个 64 位系统上（字长 $w=8$ 字节），ABI 可能规定 `call` 指令前 $sp \equiv 0 \pmod{16}$。`call` 会压入 8 字节的返回地址，导致被调用者入口处的[栈指针](@entry_id:755333) $sp_{entry} \equiv 8 \pmod{16}$。[代码生成器](@entry_id:747435)在分配局部变量时，必须：
- 在需要对齐的数组（如 16 字节对齐的 SIMD 数据）前插入最小的填充 $p_A, p_B$。
- 计算所有局部变量、填充和[溢出](@entry_id:172355)槽的总大小 $S_{local}$。
- 最后，计算并插入一个最终的填充 $P$，使得整个[栈帧](@entry_id:635120)分配的大小 $S_{frame} = S_{local} + P$ 满足 $(sp_{base} - S_{frame}) \equiv 0 \pmod{16}$，其中 $sp_{base}$ 是保存寄存器后的栈顶。这一步确保了在函数内部发起的任何嵌套调用都满足 ABI 的对齐要求。

#### 尾声代码的[微架构](@entry_id:751960)优化

就连函数尾声这样看似固定的代码序列，也存在微调优化的空间，这需要[代码生成器](@entry_id:747435)具备对目标微体系结构的深刻理解。

考虑一个函数返回的实现。假设 ABI 要求在函数序言中将返回地址寄存器保存在栈上。在尾声中，[代码生成器](@entry_id:747435)需要恢复这个地址并跳转。有两种常见的策略：[@problem_id:3628237]
- **策略 A (pop-then-indirect-jump)**：执行一系列 `pop` 指令恢复所有[被调用者保存寄存器](@entry_id:747091)，包括将返回地址 `pop` 回一个[通用寄存器](@entry_id:749779)，然后通过该寄存器执行一次间接跳转 `jr`。
- **策略 B (epilogue-then-return)**：执行 `pop` 恢复除返回地址外的所有寄存器，然后使用一条专用的 `ret` 指令，该指令原子地从栈上弹出返回地址并跳转。

在许多现代处理器上，策略 B 的性能远优于策略 A。这是因为处理器内部有一个专门用于预测函数返回地址的硬件结构，称为**返回地址栈 (Return Address Stack, RAS)**。`call` 指令会将返回地址推入 RAS，而 `ret` 指令会从 RAS 弹出地址进行预测。这种预测几乎总是准确的。相比之下，策略 A 中的通用间接跳转 `jr` 不会被识别为函数返回，处理器会使用通用[间接分支](@entry_id:750608)预测器来处理它，其预测准确率通常远低于 RAS。

因此，[代码生成器](@entry_id:747435)在选择尾声序列时，应计算两种策略的期望执行成本。策略 A 的成本包括了所有 `pop` 的时间，以及间接跳转的预测正确成本与预测错误惩罚的[期望值](@entry_id:153208) $E_j = c_j + pL$（其中 $p$ 是误判率，$L$ 是惩罚）。策略 B 的成本则包括 `pop` 的时间和 `ret` 指令的时间，由于 RAS 的存在，其误判率接近于零。通过比较，[代码生成器](@entry_id:747435)会发现，尽管 `ret` 指令本身的延迟可能略高于 `pop` 和 `jr`，但它避免了高昂的分支预测错误惩罚，从而在整体上获得了显著的性能优势。这个例子完美地展示了[代码生成器](@entry_id:747435)如何通过选择对微体系结构更“友好”的指令序列来实现深度优化。