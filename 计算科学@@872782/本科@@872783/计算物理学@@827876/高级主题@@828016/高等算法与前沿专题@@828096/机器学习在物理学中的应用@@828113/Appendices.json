{"hands_on_practices": [{"introduction": "机器学习如何帮助我们从观测数据中发现基本物理定律？本练习将引导你完成一个简化的符号回归任务，以找出天体的轨道周期与其到恒星距离之间的关系。通过对数据进行变换并应用线性回归，你将看到我们如何能够从数据中恢复开普勒第三定律（Kepler's Third Law）的精确指数，这展示了数据驱动科学发现的核心原理。[@problem_id:2410557]", "problem": "您的任务是构建一个最小化的符号回归流程，仅使用标准数值工具，从模拟的天文数据中恢复轨道周期与半长轴之间的幂律关系。物理背景是一个二体系统，其中一个小天体在牛顿引力作用下围绕一个中心质量体运行。您必须使用的基本原理包括牛顿万有引力定律和向心加速度的定义，并结合联系圆周运动中轨道速度与周期的运动学关系。由此可以推导出一个联系轨道周期和半长轴的幂律。您必须从这些原理出发推导出该幂律的形式，然后实现一个机器学习模型，该模型能直接从带噪声的模拟数据中发现该幂律的指数。\n\n您必须执行以下任务：\n\n1. 从第一性原理出发，推导在一个点质量 $M$（单位：千克）周围作圆周轨道的物体的轨道周期 $P$（单位：秒）与半长轴 $a$（单位：米）之间的关系。推导需使用牛顿万有引力定律，其中引力常数 $G$ 采用国际单位制（SI units）。推导过程必须从引力加速度与向心加速度相等以及经过充分检验的运动学事实出发。请勿假定任何已知的联系 $P$ 和 $a$ 的目标公式。\n\n2. 设计一个符号回归模型，其假设类别限定为 $P = C a^n$ 形式的幂律，其中 $C$ 和 $n$ 为常数。展示如何通过取自然对数将其转换为线性模型，以便您可以通过对变换后的变量使用普通最小二乘法来估计 $n$。假设 $P$ 存在一个乘性噪声模型，该模型在 $\\ln P$ 中变为加性的零均值噪声。\n\n3. 实现一个完整、可运行的程序，该程序能够：\n   - 根据物理模型模拟数据集，具体细节如下：\n     - 使用任务1中推导出的轨道周期 $P$ 的精确公式。\n     - 对于每个数据集，在指定的边界 $a_{\\min}$ 和 $a_{\\max}$ 之间对数均匀地采样 $a$ 值。\n     - 通过向 $\\ln P$ 添加标准差为 $\\sigma$ 的零均值高斯噪声（等效于对 $P$ 施加乘性对数正态噪声）来生成带噪声的观测值。为确保确定性并消除估计斜率中的有限样本偏差，所构造的噪声必须与 $\\ln a$ 具有零样本协方差。为实现此目的，若 $\\epsilon_{\\text{raw}} \\sim \\mathcal{N}(0,\\sigma^2)$ 表示初始噪声向量，$x=\\ln a$ 且 $x_c = x - \\overline{x}$，则使用\n       $$\\epsilon \\leftarrow \\epsilon_{\\text{raw}} - \\frac{x_c^\\top \\epsilon_{\\text{raw}}}{x_c^\\top x_c} x_c,$$\n       然后设置 $\\ln P_{\\text{obs}} = \\ln P_{\\text{true}} + \\epsilon$ 和 $P_{\\text{obs}} = \\exp(\\ln P_{\\text{obs}})$。\n     - 使用以下物理常数（国际单位制）：引力常数 $G = 6.67430 \\times 10^{-11}\\ \\text{m}^3\\ \\text{kg}^{-1}\\ \\text{s}^{-2}$，太阳质量 $M_\\odot = 1.98847 \\times 10^{30}\\ \\text{kg}$，木星质量 $M_J = 1.89813 \\times 10^{27}\\ \\text{kg}$，天文单位 $\\mathrm{AU} = 1.495978707 \\times 10^{11}\\ \\text{m}$。\n     - 使用固定的随机种子以保证结果可复现。\n   - 通过普通最小二乘法拟合模型 $\\ln P = \\beta_0 + n \\ln a$，并为每个数据集返回估计的指数 $n$。\n   - 将报告的每个指数四舍五入到三位小数。\n   - 生成最终输出，格式为单行文本，其中包含所有测试用例的指数，以逗号分隔，并用方括号括起。\n\n测试套件：\n使用以下参数集模拟四个数据集。在所有情况下，报告发现的指数 $n$（无量纲），并四舍五入到三位小数。\n\n- 案例1（理想情况，太阳质量，宽动态范围，低噪声）：\n  - $M = 1.0 \\times M_\\odot$\n  - $a_{\\min} = 0.3 \\times \\mathrm{AU}$, $a_{\\max} = 5.0 \\times \\mathrm{AU}$\n  - 样本数量 $N = 64$\n  - 对数噪声标准差 $\\sigma = 0.02$\n\n- 案例2（更大质量恒星，极宽动态范围，较高噪声）：\n  - $M = 5.0 \\times M_\\odot$\n  - $a_{\\min} = 0.1 \\times \\mathrm{AU}$, $a_{\\max} = 10.0 \\times \\mathrm{AU}$\n  - 样本数量 $N = 128$\n  - 对数噪声标准差 $\\sigma = 0.05$\n\n- 案例3（更小质量恒星，窄动态范围，低噪声）：\n  - $M = 0.1 \\times M_\\odot$\n  - $a_{\\min} = 0.5 \\times \\mathrm{AU}$, $a_{\\max} = 1.0 \\times \\mathrm{AU}$\n  - 样本数量 $N = 40$\n  - 对数噪声标准差 $\\sigma = 0.02$\n\n- 案例4（木星为中心质量体，米级输入）：\n  - $M = 1.0 \\times M_J$\n  - $a_{\\min} = 1.0 \\times 10^{7}\\ \\text{m}$, $a_{\\max} = 1.0 \\times 10^{9}\\ \\text{m}$\n  - 样本数量 $N = 50$\n  - 对数噪声标准差 $\\sigma = 0.03$\n\n最终输出格式：\n您的程序应生成单行输出，其中按顺序包含案例1到4的四个四舍五入后的指数，以逗号分隔并用方括号括起。例如，输出格式必须与\n\"[1.500,1.500,1.500,1.500]\"\n完全相同，每个值都四舍五入到三位小数。\n\n所有物理量必须在内部以国际单位制（SI units）处理。最终报告的指数是无量纲的；最终输出不需要物理单位。此任务不涉及角度。最终输出是四舍五入到三位小数的浮点数，并按规定汇总到一行的单个列表中。", "solution": "问题已经过分析，并被确定为有效。它在科学上以牛顿力学为基础，问题设定良好，目标和方法清晰，没有歧义或矛盾。我们将提供一个完整的解决方案。\n\n任务是从第一性原理出发，推导支配轨道运动的物理定律，然后利用这一理解构建一个计算模型，从模拟的、带噪声的数据中恢复该定律的参数。这个过程是科学方法本身的一个缩影，它连接了理论物理与数据分析。\n\n### 第一部分：轨道周期-半径关系的推导\n\n我们从经典力学的基本原理出发，推导一个物体在围绕中心质量 $M$ 作圆周轨道运动时的轨道周期 $P$ 与半长轴 $a$ 之间的关系。对于圆周轨道，半长轴就是恒定的轨道半径，即 $r = a$。\n\n1.  **力平衡**：处于稳定圆周轨道上的物体受到一个恒定的引力，该引力提供了维持其圆形路径所需的向心力。我们将牛顿万有引力定律的表达式 $F_g$ 与向心力表达式 $F_c$ 相等。\n    $$F_g = F_c$$\n    设 $m$ 为轨道物体的质量，$M$ 为中心天体的质量，$v$ 为轨道速度，$a$ 为轨道半径。引力常数为 $G$。\n    $$G \\frac{M m}{a^2} = \\frac{m v^2}{a}$$\n\n2.  **分离速度**：轨道物体的质量 $m$ 被消去，这是等效原理的一种体现。然后我们可以重新整理方程，解出轨道速度的平方 $v^2$。\n    $$v^2 = \\frac{G M}{a}$$\n\n3.  **运动学关系**：轨道速度 $v$ 等于轨道周长 $2 \\pi a$ 除以完成一圈轨道所需的时间，即周期 $P$。\n    $$v = \\frac{2 \\pi a}{P}$$\n\n4.  **代入与最终形式**：我们将这个关于 $v$ 的运动学表达式代入从力平衡推导出的方程中。\n    $$\\left(\\frac{2 \\pi a}{P}\\right)^2 = \\frac{G M}{a}$$\n    $$\\frac{4 \\pi^2 a^2}{P^2} = \\frac{G M}{a}$$\n    我们现在通过代数变换来分离出周期 $P$。首先，我们解出 $P^2$。\n    $$P^2 = \\left(\\frac{4 \\pi^2}{G M}\\right) a^3$$\n    最后，对两边取平方根，得到 $P$ 和 $a$ 之间的显式关系：\n    $$P = \\sqrt{\\frac{4 \\pi^2}{G M}} a^{3/2}$$\n    这就是圆周轨道的开普勒第三定律。该方程的形式为 $P = C a^n$，其中常数系数为 $C = \\sqrt{4 \\pi^2 / (G M)}$，指数为 $n = 3/2 = 1.5$。这个理论上推导出的指数 $n=1.5$ 正是我们的机器学习模型必须恢复的量。\n\n### 第二部分：通过线性化实现的符号回归模型\n\n任务要求使用一个限定在幂律假设类别 $P = C a^n$ 内的符号回归模型。虽然更复杂的符号回归可能涉及使用遗传算法来搜索数学表达式空间，但对于这个受限的类别，通过线性化可以采用一种更简单、更直接的方法。\n\n1.  **对数变换**：我们对幂律方程两边同时取自然对数 $\\ln$。\n    $$\\ln(P) = \\ln(C a^n)$$\n    利用对数的性质 $\\ln(xy) = \\ln(x) + \\ln(y)$ 和 $\\ln(x^k) = k \\ln(x)$，我们变换该方程：\n    $$\\ln(P) = \\ln(C) + \\ln(a^n) = \\ln(C) + n \\ln(a)$$\n\n2.  **线性模型构建**：这个变换后的方程是一个线性方程。我们定义新变量：$y = \\ln(P)$，$x = \\ln(a)$，截距 $\\beta_0 = \\ln(C)$，以及斜率 $\\beta_1 = n$。模型变为：\n    $$y = \\beta_0 + \\beta_1 x$$\n    这是一个简单的线性回归模型。原始的指数 $n$ 现在是这个对数-对数空间中直线的斜率。\n\n3.  **噪声模型**：问题指定了 $P$ 的一个乘性噪声模型，这对于恒为正的物理量来说很常见。一个观测周期 $P_{obs}$ 与真实周期 $P_{true}$ 的关系为 $P_{obs} = P_{true} \\cdot e^{\\epsilon_{raw}}$，其中 $\\epsilon_{raw}$ 是从高斯分布 $\\mathcal{N}(0, \\sigma^2)$ 中抽取的随机变量。对观测值取对数可得：\n    $$\\ln(P_{obs}) = \\ln(P_{true} \\cdot e^{\\epsilon_{raw}}) = \\ln(P_{true}) + \\ln(e^{\\epsilon_{raw}}) = \\ln(P_{true}) + \\epsilon_{raw}$$\n    因此，原始空间中的乘性对数正态噪声模型在对数变换后的空间中变成了一个简单的加性高斯噪声模型。\n\n4.  **参数估计**：未知参数 $\\beta_0$ 和 $\\beta_1$（即我们的指数 $n$）可以使用普通最小二乘法（OLS）进行估计。对于一组 $N$ 个数据点 $(x_i, y_i)$，斜率 $\\beta_1$ 的 OLS 估计量由下式给出：\n    $$\\hat{\\beta_1} = n_{est} = \\frac{\\sum_{i=1}^{N} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sum_{i=1}^{N} (x_i - \\bar{x})^2} = \\frac{\\text{Cov}(x, y)}{\\text{Var}(x)}$$\n    问题指定了一个非标准但确定性的噪声生成过程。添加到 $\\ln(P_{true})$ 的噪声向量 $\\epsilon$ 被构造成与中心化的预测变量向量 $x_c = x - \\bar{x}$ 正交。这意味着 $x$ 和 $\\epsilon$ 之间的样本协方差恰好为零。如 OLS 估计量的推导所示，斜率估计的误差项与此样本协方差成正比。通过强制该协方差为零，只要计算具有足够的数值精度，OLS 斜率估计量将精确地恢复真实参数 $n = 1.5$，而与噪声方差 $\\sigma$ 或样本大小 $N$ 无关。噪声只会影响截距 $\\beta_0$ 的估计。这种构造为验证实现的正确性提供了一个精确的分析测试。\n\n### 第三部分：实现大纲\n\n该程序将对每个测试案例执行以下步骤：\n1.  以国际单位制定义所有必要的物理常数：$G$、$M_\\odot$、$M_J$、$\\mathrm{AU}$。\n2.  设置固定的随机种子以保证可复现性。\n3.  对每个案例，设定参数：中心质量 $M$、半长轴边界 $a_{min}$ 和 $a_{max}$、样本数量 $N$ 以及噪声标准差 $\\sigma$。所有输入（如 AU）都转换为国际单位制（米）。\n4.  在 $a_{min}$ 和 $a_{max}$ 之间对数均匀地生成 $N$ 个 $a$ 的样本。这可以通过使用 `numpy.logspace` 创建一个等比数列来实现。\n5.  使用推导出的公式 $P = \\sqrt{4\\pi^2 / (GM)} a^{3/2}$，为每个 $a$ 计算“真实”轨道周期 $P_{true}$。\n6.  将数据转换到对数空间：$x = \\ln(a)$ 和 $y_{true} = \\ln(P_{true})$。\n7.  生成噪声向量 $\\epsilon$。首先，从 $\\mathcal{N}(0, \\sigma^2)$ 分布中抽取一个原始噪声向量 $\\epsilon_{raw}$。然后，使用提供的公式 $\\epsilon \\leftarrow \\epsilon_{raw} - \\frac{x_c^\\top \\epsilon_{raw}}{x_c^\\top x_c} x_c$ 使其与中心化的预测变量向量 $x_c = x - \\bar{x}$ 正交化。\n8.  创建“观测”的对数周期数据：$y_{obs} = y_{true} + \\epsilon$。\n9.  使用 OLS 公式计算数据 $(x, y_{obs})$ 的最佳拟合线的斜率。该斜率即为估计的指数 $n$。\n10. 将估计的 $n$ 四舍五入到三位小数并存储。\n11. 处理完所有案例后，将指数列表格式化为所需的字符串 `\"[n1,n2,n3,n4]\"`。\n该过程将使用 `numpy` 库封装在一个 Python 程序中。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of recovering the power-law exponent in Kepler's Third Law\n    from simulated data using a linearized model and ordinary least squares.\n    \"\"\"\n\n    # Physical constants in SI units\n    G = 6.67430e-11  # m^3 kg^-1 s^-2\n    M_SOLAR = 1.98847e30  # kg\n    M_JUPITER = 1.89813e27  # kg\n    AU = 1.495978707e11  # m\n\n    # Test cases defined in the problem statement\n    test_cases = [\n        {\n            \"M\": 1.0 * M_SOLAR,\n            \"a_min\": 0.3 * AU,\n            \"a_max\": 5.0 * AU,\n            \"N\": 64,\n            \"sigma\": 0.02,\n        },\n        {\n            \"M\": 5.0 * M_SOLAR,\n            \"a_min\": 0.1 * AU,\n            \"a_max\": 10.0 * AU,\n            \"N\": 128,\n            \"sigma\": 0.05,\n        },\n        {\n            \"M\": 0.1 * M_SOLAR,\n            \"a_min\": 0.5 * AU,\n            \"a_max\": 1.0 * AU,\n            \"N\": 40,\n            \"sigma\": 0.02,\n        },\n        {\n            \"M\": 1.0 * M_JUPITER,\n            \"a_min\": 1.0e7, # Already in meters\n            \"a_max\": 1.0e9, # Already in meters\n            \"N\": 50,\n            \"sigma\": 0.03,\n        },\n    ]\n\n    # Set a fixed random seed for reproducibility\n    np.random.seed(42)\n\n    results = []\n\n    for case in test_cases:\n        M = case[\"M\"]\n        a_min = case[\"a_min\"]\n        a_max = case[\"a_max\"]\n        N = case[\"N\"]\n        sigma = case[\"sigma\"]\n\n        # 1. Simulate dataset: sample semi-major axis `a` log-uniformly\n        a_samples = np.logspace(np.log10(a_min), np.log10(a_max), N)\n\n        # 2. Calculate true orbital period `P` using the derived formula\n        # P^2 = (4 * pi^2 / (G * M)) * a^3\n        C_squared = (4 * np.pi**2) / (G * M)\n        p_true_samples = np.sqrt(C_squared * a_samples**3)\n\n        # 3. Transform to log-space for linear regression\n        # ln(P) = ln(C_sqrt) + (3/2) * ln(a)\n        x = np.log(a_samples)  # ln(a)\n        y_true = np.log(p_true_samples) # ln(P_true)\n\n        # 4. Generate and orthogonalize noise\n        # Generate raw Gaussian noise\n        eps_raw = np.random.normal(loc=0.0, scale=sigma, size=N)\n        \n        # Center the predictor variable x = ln(a)\n        x_centered = x - np.mean(x)\n\n        # Orthogonalize the noise vector with respect to the centered predictor vector\n        # This ensures the sample covariance between x and the final noise is zero.\n        # eps_ortho = eps_raw - proj_of_eps_raw_onto_x_centered\n        # projection = (x_c.T @ eps_raw / x_c.T @ x_c) * x_c\n        dot_product_xc_eps = np.dot(x_centered, eps_raw)\n        dot_product_xc_xc = np.dot(x_centered, x_centered)\n        \n        # Handle case where x_centered has zero variance (e.g., N=1 or all x are same)\n        if dot_product_xc_xc == 0:\n            eps_ortho = eps_raw\n        else:\n            projection_scalar = dot_product_xc_eps / dot_product_xc_xc\n            eps_ortho = eps_raw - projection_scalar * x_centered\n\n        # 5. Create the observed log-period data with the orthogonalized noise\n        y_obs = y_true + eps_ortho\n\n        # 6. Fit the model ln(P) = beta_0 + n * ln(a) using Ordinary Least Squares\n        # We only need the slope 'n' (beta_1).\n        # The OLS formula for the slope is Cov(x, y) / Var(x).\n        # We use ddof=0 for sample covariance/variance, not unbiased estimates.\n        cov_matrix = np.cov(x, y_obs, ddof=0)\n        # The slope is cov(x,y) / var(x)\n        estimated_n = cov_matrix[0, 1] / cov_matrix[0, 0]\n\n        # 7. Round the result to three decimal places\n        rounded_n = round(estimated_n, 3)\n        results.append(str(f\"{rounded_n:.3f}\"))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2410557"}, {"introduction": "这个练习阐释了将物理洞察力与机器学习相结合的威力。你将不再使用一个“黑箱”模型，而是基于半经验质量公式（Semi-Empirical Mass Formula）来构建特征，并训练一个简单的线性模型以“学习”公式中的系数。通过这个实践，你将体会到如何将物理知识融入特征工程，从而实现模型的可解释性与高精度的统一。[@problem_id:2410513]", "problem": "您的任务是构建一个完整、可运行的程序，采用基于第一性原理的数据驱动方法，根据质子数和中子数学习预测原子核的结合能。目标量是具有质子数 $Z$ 和中子数 $N$ 的原子核的总结合能，单位为兆电子伏特 (MeV)。用于训练和评估的物理基准真值映射由半经验质量公式 (SEMF) 定义，该公式也称为魏茨泽克公式 (Weizsäcker formula)，并使用指定的系数。目标是仅根据此公式生成的数据来训练一个模型，然后对一组指定的测试原子核进行预测。\n\n目标的物理定义：\n对于一个质子数为 $Z$、中子数为 $N$、质量数为 $A=Z+N$ 的原子核，其总结合能 $B(Z,N)$（单位为兆电子伏特）由以下公式给出\n$$\nB(Z,N) \\;=\\; a_v A \\;-\\; a_s A^{2/3} \\;-\\; a_c \\frac{Z(Z-1)}{A^{1/3}} \\;-\\; a_a \\frac{(A-2Z)^2}{A} \\;+\\; \\delta(A,Z,N),\n$$\n其中，对偶项为\n$$\n\\delta(A,Z,N) \\;=\\; \n\\begin{cases}\n+\\dfrac{a_p}{\\sqrt{A}},  \\text{$Z$ 和 $N$ 为偶数}, \\\\[6pt]\n-\\dfrac{a_p}{\\sqrt{A}},  \\text{$Z$ 和 $N$ 为奇数}, \\\\[6pt]\n0,  \\text{$A$ 为奇数}.\n\\end{cases}\n$$\n使用以下 SEMF 系数（单位均为兆电子伏特）：$a_v=15.8$、$a_s=18.3$、$a_c=0.714$、$a_a=23.2$、$a_p=12.0$。所有输出必须以兆电子伏特 (MeV) 表示。\n\n训练数据的生成：\n- 通过在 $Z \\in \\{2,3,\\dots,60\\}$ 和 $N \\in \\{2,3,\\dots,90\\}$ 的网格上计算 $B(Z,N)$ 来构建训练集。$Z$ 和 $N$ 的值为整数。\n- 每个训练样本包含一个输入对 $(Z,N)$ 和使用给定系数根据上述公式（其中 $A=Z+N$）计算出的相应目标值 $B(Z,N)$。\n\n学习任务：\n- 训练一个模型（您可以选择任何架构）以根据精确指定生成的训练数据来近似映射 $(Z,N)\\mapsto B(Z,N)$。\n\n用于评估已训练模型的测试集：\n为以下八个原子核提供预测，每个原子核以一对 $(Z,N)$ 的形式给出：\n- $(1,1)$\n- $(2,2)$\n- $(3,3)$\n- $(8,9)$\n- $(26,30)$\n- $(50,70)$\n- $(82,126)$\n- $(92,146)$\n\n答案规格和单位：\n- 对于每个测试用例，输出模型预测的总结合能 $B(Z,N)$，单位为兆电子伏特 (MeV)。\n- 将每个结果表示为四舍五入到三位小数的浮点数。\n- 此问题不涉及角度，因此没有适用的角度单位。\n\n最终输出格式：\n- 您的程序必须生成单行输出，其中包含八个结果，格式为方括号内的逗号分隔列表，例如 $[x_1,x_2,\\dots,x_8]$，其中每个 $x_i$ 是对应于上面所列顺序中第 $i$ 个测试用例的四舍五入后的浮点数结果（单位为 MeV）。\n\n测试集覆盖性设计：\n- 该集合包括轻核（例如 $(1,1)$ 和 $(2,2)$）、一个奇-奇偶质量数核 $(3,3)$、一个对偶项为零的奇质量数核 $(8,9)$、中等质量核 $(26,30)$，以及重幻数核和近幻数核 $(82,126)$ 和 $(92,146)$，还有一个中等重核 $(50,70)$。这确保了对不同对偶机制、质量尺度和结构机制的覆盖。\n\n您提交的必须是一个完整的程序，该程序在指定的网格上进行训练，并以所需的确切格式打印测试集的预测结果。运行时不允许用户输入。所有计算必须以兆电子伏特 (MeV) 为单位，最终打印的数字必须四舍五入到三位小数。", "solution": "问题陈述已经过评估并被认为是有效的。它具有科学依据，问题定义明确、客观，并包含进行求解所需的所有必要信息。它基于核物理学中公认的半经验质量公式 (SEMF)，并提出了一个清晰、可解的计算任务。\n\n该问题要求构建一个模型，以预测具有质子数 $Z$ 和中子数 $N$ 的原子核的结合能 $B(Z, N)$。该学习任务的基准真值由 SEMF（也称为魏茨泽克公式）明确定义。结合能 $B$（单位为兆电子伏特，MeV）由以下公式给出：\n$$\nB(Z,N) = a_v A - a_s A^{2/3} - a_c \\frac{Z(Z-1)}{A^{1/3}} - a_a \\frac{(A-2Z)^2}{A} + \\delta(A,Z,N)\n$$\n其中 $A = Z+N$ 是质量数。提供的系数为 $a_v=15.8$、$a_s=18.3$、$a_c=0.714$、$a_a=23.2$ 和 $a_p=12.0$，单位均为 MeV。对偶项 $\\delta(A,Z,N)$ 定义如下：\n$$\n\\delta(A,Z,N) = \n\\begin{cases}\n+a_p/\\sqrt{A},   \\text{如果 $Z$ 和 $N$ 是偶数} \\\\\n-a_p/\\sqrt{A},   \\text{如果 $Z$ 和 $N$ 是奇数} \\\\\n0,   \\text{如果 $A$ 是奇数}\n\\end{cases}\n$$\n\n该任务被构建为一个机器学习问题：在根据此公式生成的数据上训练一个模型，然后用它进行预测。对于此任务，最严谨和合适的“架构”是线性回归模型，因为 SEMF 本质上是从 $Z$ 和 $N$ 导出的具有物理动机的基函数（特征）的线性组合。\n\n让我们定义一个具有 5 个分量的特征向量 $\\boldsymbol{x}$，对应于 SEMF 的五个项：\n1.  **体积项特征**：$x_1 = A$\n2.  **表面项特征**：$x_2 = A^{2/3}$\n3.  **库仑项特征**：$x_3 = \\frac{Z(Z-1)}{A^{1/3}}$\n4.  **不对称项特征**：$x_4 = \\frac{(A-2Z)^2}{A}$\n5.  **对偶项特征**：$x_5 = p(Z,N)A^{-1/2}$，其中对于偶偶核，$p(Z,N) = +1$；对于奇奇核，$p(Z,N) = -1$；对于奇 A 核，$p(Z,N) = 0$。\n\n利用这些特征，结合能可以表示为一个线性模型：\n$$\nB(\\boldsymbol{x}) = \\boldsymbol{w}^T \\boldsymbol{x} = w_1 x_1 + w_2 x_2 + w_3 x_3 + w_4 x_4 + w_5 x_5\n$$\n与 SEMF 对应的理想权重向量 $\\boldsymbol{w}_{\\text{ideal}}$ 是 $\\boldsymbol{w}_{\\text{ideal}} = [a_v, -a_s, -a_c, -a_a, a_p]^T = [15.8, -18.3, -0.714, -23.2, 12.0]^T$。\n\n步骤如下：\n1.  **数据生成**：我们生成一个输入-输出对的训练集。输入是来自 $Z \\in \\{2, 3, \\dots, 60\\}$ 和 $N \\in \\{2, 3, \\dots, 90\\}$ 所定义网格上的整数对 $(Z,N)$。对于每对 $(Z_i, N_i)$，我们构建特征向量 $\\boldsymbol{x}_i$，并使用给定的 SEMF 公式和系数计算相应的“真实”结合能 $y_i = B(Z_i, N_i)$。\n\n2.  **模型训练**：训练过程在于找到能够最佳拟合训练数据的最优权重向量 $\\boldsymbol{w}$。给定特征矩阵 $\\boldsymbol{X}$（其中每行是一个特征向量 $\\boldsymbol{x}_i^T$）和目标向量 $\\boldsymbol{y}$（包含值 $y_i$），我们求解普通最小二乘问题。解由正规方程给出：\n$$\n\\boldsymbol{w} = (\\boldsymbol{X}^T \\boldsymbol{X})^{-1} \\boldsymbol{X}^T \\boldsymbol{y}\n$$\n通过求解这个线性系统来获得学习到的模型参数 $\\boldsymbol{w}$。此计算使用数值稳定的方法，例如 `numpy.linalg.lstsq` 提供的方法。\n\n3.  **预测**：一旦模型训练完成（即权重向量 $\\boldsymbol{w}$ 被确定），我们就可以预测任何原子核 $(Z_{\\text{test}}, N_{\\text{test}})$ 的结合能。我们首先为测试核构建特征向量 $\\boldsymbol{x}_{\\text{test}}$。然后，预测的结合能 $\\hat{B}$ 通过点积计算得出：\n$$\n\\hat{B} = \\boldsymbol{w}^T \\boldsymbol{x}_{\\text{test}}\n$$\n此过程应用于八个指定的测试核中的每一个。所得预测值按要求四舍五入到三位小数。由于所选的模型架构与数据生成函数的形式完全匹配，且数据无噪声，因此学习到的权重 $\\boldsymbol{w}$ 将与 $\\boldsymbol{w}_{\\text{ideal}}$ 几乎相同，模型的预测将忠实地再现 SEMF 的输出。即使对于训练范围之外的测试核，这也成立，证明了植根于正确物理原理的模型的泛化能力。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs a model to predict nuclear binding energy based on the Semi-Empirical Mass Formula (SEMF).\n    The program generates training data from the SEMF, trains a linear model, and predicts the binding\n    energy for a specified set of test nuclei.\n    \"\"\"\n\n    # SEMF coefficients (in MeV)\n    COEFFS = {\n        'a_v': 15.8,\n        'a_s': 18.3,\n        'a_c': 0.714,\n        'a_a': 23.2,\n        'a_p': 12.0\n    }\n\n    def get_pairing_factor(Z, N):\n        \"\"\"Calculates the sign of the pairing term.\"\"\"\n        if Z % 2 == 0 and N % 2 == 0:\n            return 1.0  # even-even\n        if Z % 2 != 0 and N % 2 != 0:\n            return -1.0  # odd-odd\n        return 0.0  # odd-A\n\n    def get_semf_features(Z, N):\n        \"\"\"\n        Calculates the 5 feature terms of the SEMF for a given nucleus (Z, N).\n        \"\"\"\n        if Z  0 or N  0 or (Z == 0 and N == 0):\n            return np.zeros(5)\n\n        A = float(Z + N)\n\n        # Handle cases where A is zero to avoid division by zero, though not expected here.\n        if A == 0:\n            return np.zeros(5)\n\n        # 1. Volume term feature\n        f1 = A\n        # 2. Surface term feature\n        f2 = A**(2/3)\n        # 3. Coulomb term feature\n        f3 = Z * (Z - 1) / (A**(1/3)) if A > 0 else 0\n        # 4. Asymmetry term feature\n        f4 = (A - 2 * Z)**2 / A if A > 0 else 0\n        # 5. Pairing term feature\n        f5 = get_pairing_factor(Z, N) / np.sqrt(A) if A > 0 else 0\n\n        return np.array([f1, f2, f3, f4, f5])\n\n    def get_semf_binding_energy(Z, N, coeffs):\n        \"\"\"\n        Calculates the ground-truth binding energy using the SEMF formula.\n        \"\"\"\n        features = get_semf_features(Z, N)\n        \n        # The ideal weights include the signs from the formula\n        ideal_weights = np.array([\n            coeffs['a_v'],\n            -coeffs['a_s'],\n            -coeffs['a_c'],\n            -coeffs['a_a'],\n            coeffs['a_p']\n        ])\n        \n        return np.dot(features, ideal_weights)\n\n    # --- 1. Data Generation ---\n    # Generate training data from the specified grid.\n    Z_range = range(2, 61)  # Z from 2 to 60\n    N_range = range(2, 91)  # N from 2 to 90\n    \n    X_train_list = []\n    y_train_list = []\n\n    for Z_val in Z_range:\n        for N_val in N_range:\n            features = get_semf_features(Z_val, N_val)\n            target = get_semf_binding_energy(Z_val, N_val, COEFFS)\n            X_train_list.append(features)\n            y_train_list.append(target)\n\n    X_train = np.array(X_train_list)\n    y_train = np.array(y_train_list)\n\n    # --- 2. Model Training ---\n    # Train a linear regression model by solving for the weights.\n    # weights = (X^T X)^-1 X^T y\n    # np.linalg.lstsq is a numerically stable way to do this.\n    weights, _, _, _ = np.linalg.lstsq(X_train, y_train, rcond=None)\n\n    # --- 3. Prediction ---\n    # Test suite of nuclei (Z, N)\n    test_cases = [\n        (1, 1),\n        (2, 2),\n        (3, 3),\n        (8, 9),\n        (26, 30),\n        (50, 70),\n        (82, 126),\n        (92, 146)\n    ]\n    \n    results = []\n    for Z_test, N_test in test_cases:\n        test_features = get_semf_features(Z_test, N_test)\n        # Predict binding energy using the trained model (learned weights)\n        prediction = np.dot(test_features, weights)\n        # Round the result to three decimal places\n        rounded_prediction = round(prediction, 3)\n        results.append(str(f\"{rounded_prediction:.3f}\"))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2410513"}, {"introduction": "本项高级练习将带你进入计算物理的前沿领域，在这里，神经网络正被用于解决以往难以处理的复杂量子多体问题。你将亲自实现一个“神经量子态”（Neural Quantum State），并将其作为变分波函数，来求解一个自旋链模型的基态能量。通过这个实践，你将掌握驱动该领域现代研究的核心技术——神经网络变分法。[@problem_id:2410566]", "problem": "设计并实现一个完整的、可运行的程序，通过在神经网络拟设上最小化变分能量来近似求解一个量子自旋系统的基态，并报告指定测试组的最小化能量。考虑一个由 $N$ 个自旋-$\\frac{1}{2}$ 自由度组成的一维环，在计算基 $\\{ \\lvert s \\rangle \\}$ 中，其中 $s = (s_1,\\dots,s_N)$ 且 $s_i \\in \\{-1,+1\\}$ 表示 $\\hat{\\sigma}_i^z$ 的本征值。其哈密顿量为\n$$\n\\hat{H} = -J \\sum_{i=1}^{N} \\hat{\\sigma}_i^z \\hat{\\sigma}_{i+1}^z - h \\sum_{i=1}^{N} \\hat{\\sigma}_i^x \\,,\n$$\n并具有周期性边界条件 $\\hat{\\sigma}_{N+1}^z \\equiv \\hat{\\sigma}_1^z$。使用一个实值人工神经网络（ANN）变分拟设来表示计算基中的波函数振幅，\n$$\n\\Psi_\\theta(s) = \\exp\\!\\Big( w_2^\\top \\tanh(W_1 s + b_1) + b_2 \\Big) \\,,\n$$\n其中 $W_1 \\in \\mathbb{R}^{H \\times N}$，$b_1 \\in \\mathbb{R}^{H}$，$w_2 \\in \\mathbb{R}^{H}$，$b_2 \\in \\mathbb{R}$ 是集中在 $\\theta$ 中的变分参数，$H \\in \\mathbb{N}$ 是隐藏单元的数量，$\\tanh(\\cdot)$ 逐元素应用。需要最小化的变分能量是 Rayleigh 商\n$$\nE(\\theta) = \\frac{\\langle \\Psi_\\theta \\lvert \\hat{H} \\rvert \\Psi_\\theta \\rangle}{\\langle \\Psi_\\theta \\vert \\Psi_\\theta \\rangle} \\,,\n$$\n其中内积是在整个希尔伯特空间上计算的。在计算基中，分子和分母可以写为\n$$\n\\langle \\Psi_\\theta \\lvert \\Psi_\\theta \\rangle = \\sum_{s} \\Psi_\\theta(s)^2 \\,,\n$$\n$$\n\\langle \\Psi_\\theta \\lvert \\hat{H} \\rvert \\Psi_\\theta \\rangle = \\sum_{s} \\Psi_\\theta(s)^2 \\left( -J \\sum_{i=1}^{N} s_i s_{i+1} \\right) + \\sum_{s} \\sum_{i=1}^{N} \\left( -h \\right) \\Psi_\\theta(s) \\Psi_\\theta\\!\\big(s^{(i)}\\big) \\,,\n$$\n其中 $s^{(i)}$ 表示从 $s$ 通过翻转第 $i$ 个自旋 $s_i \\mapsto -s_i$ 得到的构型，在键项 $s_{i+1}$ 中，索引对 $N$ 取模。在该模型中，所有量都是无量纲的；请将能量报告为无量纲的实数。\n\n您的程序必须对下面的每个测试用例，在 $\\theta$ 上进行搜索以近似 $E(\\theta)$ 的最小值，所有用例均使用相同的固定架构大小 $H = 8$，然后仅以精确要求的格式输出最小化的能量。希尔伯特空间是有限的，所有求和必须精确地对所有基构型进行；不允许进行随机抽样。\n\n测试组：\n- 用例 1：$N = 3$, $J = 1.0$, $h = 0.5$。\n- 用例 2：$N = 4$, $J = 1.0$, $h = 1.0$。\n- 用例 3：$N = 5$, $J = 1.0$, $h = 0.0$。\n- 用例 4：$N = 6$, $J = 0.0$, $h = 1.0$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，顺序与测试组相同（用例 1 到 4）。每个条目必须是保留小数点后六位的十进制浮点数。例如，一个有效的输出如下所示\n$$\n[-3.224745, -5.027341, -5.000000, -6.000000]\n$$\n输出中不允许包含额外的文本或行。", "solution": "所述问题是有效的。它在计算物理学领域，特别是在将机器学习方法应用于量子多体问题方面，提出了一个适定且有科学依据的任务。其目标是使用神经网络变分拟设来寻找一维横向场伊辛模型基态能量的近似值。所有必要的组成部分——哈密顿量、拟设的形式、变分能量的定义以及测试用例的参数——都以数学上的精确性给出。在整个希尔伯特空间上进行精确求和的约束对于指定的系统大小（$N \\le 6$，希尔伯特空间维度 $2^N \\le 64$）在计算上是可行的，这使得问题自洽且可解，无需借助随机抽样方法。\n\n该解决方案通过最小化变分能量来进行，变分能量是哈密顿量相对于变分态的期望值，并由该态的范数进行归一化。这是 Rayleigh-Ritz 变分原理的应用，该原理保证计算出的能量 $E(\\theta)$ 是真实基态能量 $E_0$ 的一个上界，即 $E(\\theta) \\ge E_0$。在给定的拟设族内，最优近似是通过数值最小化 $E(\\theta)$ 相对于网络参数 $\\theta$ 来找到的。\n\n总体流程如下：\n\n1.  **希尔伯特空间构建**：对于一个包含 $N$ 个自旋的系统，其计算基由 $2^N$ 个态组成。每个基态都是一个构型 $s = (s_1, \\dots, s_N)$，其中 $s_i \\in \\{-1, +1\\}$。这 $2^N$ 个构型被显式生成和存储。\n\n2.  **变分波函数拟设**：问题指定了一个用于波函数振幅的实值神经网络拟设：\n    $$\n    \\Psi_\\theta(s) = \\exp\\!\\Big( w_2^\\top \\tanh(W_1 s + b_1) + b_2 \\Big)\n    $$\n    此处，$\\theta = \\{W_1, b_1, w_2, b_2\\}$ 是变分参数，其中 $W_1 \\in \\mathbb{R}^{H \\times N}$，$b_1 \\in \\mathbb{R}^{H}$，$w_2 \\in \\mathbb{R}^{H}$，$b_2 \\in \\mathbb{R}$。对于固定的隐藏单元数 $H=8$，参数总数为 $H(N+2)+1$。这些参数被扁平化为一个单一向量，以便与标准数值优化器一起使用。实现一个函数，用于计算任何给定构型 $s$ 和参数向量 $\\theta$ 的波函数振幅 $\\Psi_\\theta(s)$。\n\n3.  **变分能量计算**：任务的核心是评估目标函数，即变分能量 $E(\\theta)$，它由 Rayleigh 商给出：\n    $$\n    E(\\theta) = \\frac{\\langle \\Psi_\\theta \\lvert \\hat{H} \\rvert \\Psi_\\theta \\rangle}{\\langle \\Psi_\\theta \\vert \\Psi_\\theta \\rangle}\n    $$\n    分母是波函数的范数平方，$\\langle \\Psi_\\theta \\vert \\Psi_\\theta \\rangle = \\sum_s \\Psi_\\theta(s)^2$，其中求和遍历所有 $2^N$ 个构型。\n\n    分子是哈密顿量 $\\hat{H} = -J \\sum_{i} \\hat{\\sigma}_i^z \\hat{\\sigma}_{i+1}^z - h \\sum_{i} \\hat{\\sigma}_i^x$ 的期望值，它被计算为两个独立的项：\n    \n    a.  **对角（伊辛）项**：算符 $\\hat{\\sigma}_i^z \\hat{\\sigma}_{i+1}^z$ 在计算基中是对角的。其期望值为：\n    $$\n    E_{\\text{diag}} = \\frac{\\sum_s \\Psi_\\theta(s)^2 \\left( -J \\sum_{i=1}^{N} s_i s_{i+1} \\right)}{\\sum_s \\Psi_\\theta(s)^2}\n    $$\n    这通过为每个构型 $s$ 评估经典能量 $-J \\sum_i s_i s_{i+1}$，用 $\\Psi_\\theta(s)^2$ 对其加权，然后将结果求和来计算。\n\n    b.  **非对角（场）项**：算符 $\\hat{\\sigma}_i^x$ 是非对角的。它翻转第 $i$ 个自旋，即 $\\hat{\\sigma}_i^x |s\\rangle = |s^{(i)}\\rangle$。其期望值为：\n    $$\n    E_{\\text{off-diag}} = \\frac{\\sum_{s} \\sum_{i=1}^{N} (-h) \\Psi_\\theta(s) \\Psi_\\theta(s^{(i)})}{\\sum_s \\Psi_\\theta(s)^2}\n    $$\n    为了高效计算此项，预先计算每个自旋构型到其在状态向量中对应索引的映射。这允许对任何翻转后的构型快速检索其振幅 $\\Psi_\\theta(s^{(i)})$。\n\n    总能量为 $E(\\theta) = E_{\\text{diag}} + E_{\\text{off-diag}}$。\n\n4.  **数值优化**：采用 `L-BFGS-B` 算法（一种在 `scipy.optimize.minimize` 中可用的拟牛顿法）来寻找最小化能量函数 $E(\\theta)$ 的参数向量 $\\theta$。优化过程使用一个小的、随机生成的参数向量进行初始化，以打破对称性。该算法迭代地调整参数，在能量景观上下降，直到梯度和函数值的收敛标准被满足。\n\n整个过程被封装并对所提供的四个测试用例中的每一个执行，为每组物理参数 $(N, J, h)$ 得出最小化的变分能量。最终结果按要求四舍五入到小数点后六位。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nimport itertools\n\ndef solve():\n    \"\"\"\n    Calculates the ground state energy of the 1D transverse-field Ising model\n    using a neural network variational ansatz and exact summation.\n    \"\"\"\n    \n    H = 8 # Fixed number of hidden units\n\n    def get_spin_configs(N):\n        \"\"\"Generates all 2**N spin configurations for a chain of length N.\"\"\"\n        # Use float64 for compatibility with matrix multiplication\n        return np.array(list(itertools.product([-1.0, 1.0], repeat=N)), dtype=np.float64)\n\n    def unpack_params(params_flat, N, H):\n        \"\"\"Unflattens the parameter vector into network weights and biases.\"\"\"\n        idx = 0\n        W1 = params_flat[idx : idx + H * N].reshape((H, N))\n        idx += H * N\n        b1 = params_flat[idx : idx + H]\n        idx += H\n        w2 = params_flat[idx : idx + H]\n        idx += H\n        b2 = params_flat[idx]\n        return W1, b1, w2, b2\n\n    def psi_theta(params_flat, spins, N, H):\n        \"\"\"Computes the ANN wavefunction amplitude for a batch of spin configurations.\"\"\"\n        W1, b1, w2, b2 = unpack_params(params_flat, N, H)\n        # spins shape: (num_configs, N), W1.T shape: (N, H)\n        hidden_input = spins @ W1.T + b1\n        hidden_output = np.tanh(hidden_input)\n        # hidden_output shape: (num_configs, H), w2 shape: (H,)\n        log_psi = hidden_output @ w2 + b2\n        return np.exp(log_psi)\n\n    def create_objective_function(N, J, h, H, spin_configs, config_to_index_map):\n        \"\"\"\n        Factory to create the energy function for a given set of physical parameters.\n        This function will be the target for the numerical optimizer.\n        \"\"\"\n        def energy_function(params_flat):\n            # Calculate wavefunction amplitudes for all 2**N states\n            psi = psi_theta(params_flat, spin_configs, N, H)\n            psi_sq = np.square(psi)\n            norm_sq = np.sum(psi_sq)\n\n            # Defensive check for numerical stability\n            if norm_sq  1e-12:\n                return 0.0\n\n            # 1. Diagonal part of H (Ising term)\n            # Roll spin configs to get neighbors for periodic boundary conditions\n            s_ip1 = np.roll(spin_configs, shift=-1, axis=1)\n            # Sum over bonds for each configuration\n            ising_interaction = np.sum(spin_configs * s_ip1, axis=1)\n            E_diag = np.sum(psi_sq * (-J * ising_interaction))\n\n            # 2. Off-diagonal part of H (Transverse-field term)\n            E_offdiag = 0.0\n            num_configs = 2**N\n            # Iterate over each configuration s\n            for k in range(num_configs):\n                config_s = spin_configs[k]\n                psi_s = psi[k]\n                # Iterate over each spin site i to flip\n                for i in range(N):\n                    s_flipped = config_s.copy()\n                    s_flipped[i] *= -1.0\n                    # Find the index of the flipped config using the pre-built map\n                    k_flipped = config_to_index_map[tuple(s_flipped)]\n                    psi_s_flipped = psi[k_flipped]\n                    E_offdiag += -h * psi_s * psi_s_flipped\n            \n            # Total energy is the sum of parts divided by the norm\n            total_energy = (E_diag + E_offdiag) / norm_sq\n            return total_energy\n\n        return energy_function\n\n    def solve_case(N, J, h):\n        \"\"\"\n        Sets up and runs the optimization for a single test case.\n        \"\"\"\n        # 1. Generate all basis states and a lookup map for efficiency\n        spin_configs = get_spin_configs(N)\n        config_to_index_map = {tuple(config): i for i, config in enumerate(spin_configs)}\n        \n        # 2. Create the specific objective function for this case\n        objective = create_objective_function(N, J, h, H, spin_configs, config_to_index_map)\n        \n        # 3. Perform the optimization\n        num_params = H * (N + 2) + 1\n        # Use a fixed random seed for reproducibility of the initial guess\n        np.random.seed(42)\n        initial_params = np.random.randn(num_params) * 0.1\n        \n        # L-BFGS-B is a good choice for this type of unconstrained optimization\n        res = minimize(\n            objective, \n            initial_params, \n            method='L-BFGS-B', \n            options={'maxiter': 2000, 'ftol': 1e-12, 'gtol': 1e-9}\n        )\n        \n        return res.fun\n\n    test_cases = [\n        (3, 1.0, 0.5), # Case 1\n        (4, 1.0, 1.0), # Case 2\n        (5, 1.0, 0.0), # Case 3\n        (6, 0.0, 1.0), # Case 4\n    ]\n\n    results = []\n    for N, J, h in test_cases:\n        minimized_energy = solve_case(N, J, h)\n        results.append(f\"{minimized_energy:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2410566"}]}