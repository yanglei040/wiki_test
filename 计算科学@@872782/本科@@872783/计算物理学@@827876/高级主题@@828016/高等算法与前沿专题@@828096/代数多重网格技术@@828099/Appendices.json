{"hands_on_practices": [{"introduction": "代数多重网格（AMG）的核心在于其在不同网格层次间传递信息的能力，其中插值算子扮演着至关重要的角色，负责将粗网格上的校正“插值”回细网格。这个练习将带你深入AMG的内部机制，通过一个源于计算电磁学的具体物理问题——各向异性泊松方程，亲手推导插值权重。通过这个实践，你将不再仅仅是使用一个给定的公式，而是能理解这些权重是如何从问题的离散化形式中自然产生的。[@problem_id:22396]", "problem": "在计算静电学中，在网格上求解泊松方程通常会产生一个大型稀疏线性方程组 $A\\mathbf{x} = \\mathbf{b}$。代数多重网格 (AMG) 方法是求解此类系统的强大迭代求解器。AMG 的一个关键组成部分是构建一个插值算子 $P$，它将粗网格上的值与细网格上的值联系起来。\n\n网格点（节点）被划分为一组粗 (C) 点和细 (F) 点。在细点 $i$ 处的误差值 $e_i$ 通过其相邻粗点 $j \\in N_i^C$ 处的误差值的加权和来近似：\n$$ e_i = \\sum_{j \\in N_i^C} w_{ij} e_j $$\n权重 $w_{ij}$ 构成了插值算子 $P$ 的各项。\n\n推导细点 $i$ 的这些权重的一种标准方法是利用其在系统矩阵 $A$ 中对应的行。对于光滑误差向量 $e$，其模板方程为 $(Ae)_i \\approx 0$。通过近似来自相邻细点的贡献，可以得到以下插值权重公式：\n$$ w_{ij} = \\frac{-A_{ij}}{A_{ii} + \\sum_{k \\in N_i^F} A_{ik}} \\quad \\text{for } j \\in N_i^C $$\n其中 $N_i^C$ 是 $i$ 的粗相邻点集，而 $N_i^F$ 是 $i$ 的细相邻点集。\n\n考虑具有常数 $\\alpha > 0$ 和 $\\beta > 0$ 的二维各向异性泊松方程：\n$$ \\alpha \\frac{\\partial^2 \\phi}{\\partial x^2} + \\beta \\frac{\\partial^2 \\phi}{\\partial y^2} = -\\rho(x,y) $$\n使用标准的五点有限差分模板，在间距为 $h=1$ 的均匀方形网格上对此方程进行离散化。这会产生一个系统矩阵 $A$。\n\n设点 $P_0$ 为一个细点。其四个邻点分别表示为 $P_N$ (北)、$P_S$ (南)、$P_E$ (东) 和 $P_W$ (西)。邻点的粗/细点划分如下：\n-   $P_N$ 和 $P_E$ 是粗 (C) 点。\n-   $P_S$ 和 $P_W$ 是细 (F) 点。\n\n您的任务是计算插值权重 $w_{0N}$，它将细点 $P_0$ 与其粗北邻点 $P_N$ 连接起来。用 $\\alpha$ 和 $\\beta$ 表示您的答案。", "solution": "1. 细点 $i$ 和粗邻点 $j$ 的插值权重公式：\n   $$w_{ij}=\\frac{-A_{ij}}{A_{ii}+\\sum_{k\\in N_i^F}A_{ik}}\\,. $$\n\n2. 各向异性五点模板的各项：\n   $$A_{ii}=2\\alpha+2\\beta,\\quad\n     A_{i,E}=A_{i,W}=-\\alpha,\\quad\n     A_{i,N}=A_{i,S}=-\\beta.$$\n\n3. 对于点 $P_0$，粗邻点为 $N, E$；细邻点为 $S, W$：\n   $$\\sum_{k\\in N_0^F}A_{0k}=A_{0,S}+A_{0,W}=(-\\beta)+(-\\alpha)=-(\\alpha+\\beta).$$\n\n4. $w_{0N}$ 的分子：\n   $$-A_{0,N}=-(-\\beta)=\\beta.$$\n\n5. 分母：\n   $$A_{00}+\\sum_{F}A_{0k}=2(\\alpha+\\beta)-(\\alpha+\\beta)=\\alpha+\\beta.$$\n\n6. 因此，\n   $$w_{0N}=\\frac{\\beta}{\\alpha+\\beta}.$$", "answer": "$$\\boxed{\\frac{\\beta}{\\alpha+\\beta}}$$", "id": "22396"}, {"introduction": "一个高效的多重网格方法不仅依赖于其组件的正确构建，更依赖于这些组件之间协同工作的质量，尤其是插值算子的设计。这个练习是一个富有启发性的思想实验：如果我们故意选择一个“糟糕”的插值算子会发生什么？通过为一个简单的一维问题构建这样一个不佳的双网格系统，并精确计算其迭代误差传播矩阵的光谱半径，我们能够定量地分析该方法为何会收敛缓慢甚至失效。这个过程能让你深刻理解双网格分析的精髓，以及为何一个好的插值策略对于实现快速收敛至关重要。[@problem_id:2372552]", "problem": "考虑一个线性系统，该系统由一维泊松方程 $-u'' = f$ 在单位区间上采用齐次狄利克雷边界条件，并使用 $N=3$ 个内点通过标准二阶有限差分法离散化得到。得到的刚度矩阵为\n$$\nA \\in \\mathbb{R}^{3 \\times 3}, \\quad\nA = \\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix}.\n$$\n在代数多重网格 (AMG) 框架内定义一个两网格方法。选择一个由中间节点的单个粗变量构成的、特意选择的较差的粗空间，并定义插值算子\n$$\nP \\in \\mathbb{R}^{3 \\times 1}, \\quad P = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}.\n$$\n使用转置作为限制算子，即 $R = P^{\\top}$，以及伽辽金粗算子 $A_{c} = R A P \\in \\mathbb{R}^{1 \\times 1}$。使用一步权重为 $\\omega = \\frac{2}{3}$ 的加权雅可比法进行后平滑，其平滑算子为\n$$\nS = I - \\omega D^{-1} A, \\quad D = \\operatorname{diag}(A).\n$$\n设两网格误差传播矩阵为\n$$\nE = \\bigl(I - P A_{c}^{-1} R A\\bigr)\\, S.\n$$\n精确计算谱半径 $\\rho(E)$，并以精确数（无四舍五入）的形式给出最终答案。答案无单位，且必须是一个实数。", "solution": "如问题所述，这是一个数学上适定的问题，并为求得唯一解提供了所有必要信息。我们需要计算一个特定定义的矩阵的谱半径。给定条件如下：\n细网格系统矩阵 $A \\in \\mathbb{R}^{3 \\times 3}$：\n$$\nA = \\begin{pmatrix}\n2  -1  0 \\\\\n-1  2  -1 \\\\\n0  -1  2\n\\end{pmatrix}\n$$\n插值算子 $P \\in \\mathbb{R}^{3 \\times 1}$：\n$$\nP = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix}\n$$\n限制算子是插值算子的转置，即 $R = P^{\\top}$。粗网格算子由伽辽金投影定义，即 $A_{c} = R A P$。平滑过程是权重为 $\\omega = \\frac{2}{3}$ 的加权雅可比迭代，其平滑算子为 $S = I - \\omega D^{-1} A$，其中 $D = \\operatorname{diag}(A)$。两网格误差传播矩阵明确定义为 $E = \\bigl(I - P A_{c}^{-1} R A\\bigr)\\, S$。\n\n必须指出，问题文本指定了“一步后平滑”，其误差传播矩阵通常写作 $S \\bigl(I - P A_{c}^{-1} R A\\bigr)$。所给公式 $E = \\bigl(I - P A_{c}^{-1} R A\\bigr)S$ 对应于一步前平滑。然而，$E$ 的定义是明确且无歧义的，因此我们将按照给定的定义进行计算。对于方阵，$XY$ 和 $YX$ 的谱半径是相同的，因此这个术语上的不准确性不会影响最终结果。\n\n计算过程分为以下几步。\n\n首先，我们计算平滑算子 $S$。对角矩阵 $D$ 为：\n$$\nD = \\operatorname{diag}(A) = \\begin{pmatrix}\n2  0  0 \\\\\n0  2  0 \\\\\n0  0  2\n\\end{pmatrix} = 2I\n$$\n其逆矩阵为 $D^{-1} = \\frac{1}{2}I$。\n使用松弛权重 $\\omega = \\frac{2}{3}$，平滑算子 $S$ 为：\n$$\nS = I - \\omega D^{-1} A = I - \\frac{2}{3} \\left(\\frac{1}{2}I\\right) A = I - \\frac{1}{3} A\n$$\n$$\nS = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} - \\frac{1}{3} \\begin{pmatrix} 2  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  2 \\end{pmatrix} = \\begin{pmatrix} 1-\\frac{2}{3}  \\frac{1}{3}  0 \\\\ \\frac{1}{3}  1-\\frac{2}{3}  \\frac{1}{3} \\\\ 0  \\frac{1}{3}  1-\\frac{2}{3} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3}  \\frac{1}{3}  0 \\\\ \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\\\ 0  \\frac{1}{3}  \\frac{1}{3} \\end{pmatrix}\n$$\n\n接下来，我们构建粗网格校正算子，记为 $C = I - P A_{c}^{-1} R A$。\n限制算子 $R$ 为：\n$$\nR = P^{\\top} = \\begin{pmatrix} 0  1  0 \\end{pmatrix}\n$$\n粗网格算子 $A_c$ 是一个 $1 \\times 1$ 矩阵：\n$$\nA_{c} = R A P = \\begin{pmatrix} 0  1  0 \\end{pmatrix} \\begin{pmatrix} 2  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  2 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} -1  2  -1 \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} = [2]\n$$\n其逆为 $A_c^{-1} = [\\frac{1}{2}]$。\n现在我们计算 $P A_c^{-1} R A$ 这一项：\n$$\nP A_c^{-1} R = \\begin{pmatrix} 0 \\\\ 1 \\\\ 0 \\end{pmatrix} [\\frac{1}{2}] \\begin{pmatrix} 0  1  0 \\end{pmatrix} = \\begin{pmatrix} 0  0  0 \\\\ 0  \\frac{1}{2}  0 \\\\ 0  0  0 \\end{pmatrix}\n$$\n$$\nP A_c^{-1} R A = \\begin{pmatrix} 0  0  0 \\\\ 0  \\frac{1}{2}  0 \\\\ 0  0  0 \\end{pmatrix} \\begin{pmatrix} 2  -1  0 \\\\ -1  2  -1 \\\\ 0  -1  2 \\end{pmatrix} = \\begin{pmatrix} 0  0  0 \\\\ -\\frac{1}{2}  1  -\\frac{1}{2} \\\\ 0  0  0 \\end{pmatrix}\n$$\n因此，粗网格校正算子 $C$ 为：\n$$\nC = I - P A_c^{-1} R A = \\begin{pmatrix} 1  0  0 \\\\ 0  1  0 \\\\ 0  0  1 \\end{pmatrix} - \\begin{pmatrix} 0  0  0 \\\\ -\\frac{1}{2}  1  -\\frac{1}{2} \\\\ 0  0  0 \\end{pmatrix} = \\begin{pmatrix} 1  0  0 \\\\ \\frac{1}{2}  0  \\frac{1}{2} \\\\ 0  0  1 \\end{pmatrix}\n$$\n\n现在我们计算两网格误差传播矩阵 $E = C S$：\n$$\nE = \\begin{pmatrix} 1  0  0 \\\\ \\frac{1}{2}  0  \\frac{1}{2} \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} \\frac{1}{3}  \\frac{1}{3}  0 \\\\ \\frac{1}{3}  \\frac{1}{3}  \\frac{1}{3} \\\\ 0  \\frac{1}{3}  \\frac{1}{3} \\end{pmatrix} = \\begin{pmatrix}\n1 \\cdot \\frac{1}{3}  1 \\cdot \\frac{1}{3}  0 \\\\\n\\frac{1}{2} \\cdot \\frac{1}{3}  \\frac{1}{2} \\cdot \\frac{1}{3} + \\frac{1}{2} \\cdot \\frac{1}{3}  \\frac{1}{2} \\cdot \\frac{1}{3} \\\\\n0  1 \\cdot \\frac{1}{3}  1 \\cdot \\frac{1}{3}\n\\end{pmatrix} = \\begin{pmatrix} \\frac{1}{3}  \\frac{1}{3}  0 \\\\ \\frac{1}{6}  \\frac{1}{3}  \\frac{1}{6} \\\\ 0  \\frac{1}{3}  \\frac{1}{3} \\end{pmatrix}\n$$\n\n最后，我们通过求解 $E$ 的特征值来计算其谱半径 $\\rho(E)$。特征方程为 $\\det(E - \\lambda I) = 0$。\n$$\n\\det\\begin{pmatrix} \\frac{1}{3}-\\lambda  \\frac{1}{3}  0 \\\\ \\frac{1}{6}  \\frac{1}{3}-\\lambda  \\frac{1}{6} \\\\ 0  \\frac{1}{3}  \\frac{1}{3}-\\lambda \\end{pmatrix} = 0\n$$\n为简化计算，我们先求 $3E$ 的特征值 $\\mu$，其中 $\\lambda = \\mu/3$。\n$$\n3E = \\begin{pmatrix} 1  1  0 \\\\ \\frac{1}{2}  1  \\frac{1}{2} \\\\ 0  1  1 \\end{pmatrix}\n$$\n特征方程为 $\\det(3E - \\mu I) = 0$：\n$$\n\\det\\begin{pmatrix} 1-\\mu  1  0 \\\\ \\frac{1}{2}  1-\\mu  \\frac{1}{2} \\\\ 0  1  1-\\mu \\end{pmatrix} = 0\n$$\n$$\n(1-\\mu) \\left| \\begin{matrix} 1-\\mu  \\frac{1}{2} \\\\ 1  1-\\mu \\end{matrix} \\right| - 1 \\left| \\begin{matrix} \\frac{1}{2}  \\frac{1}{2} \\\\ 0  1-\\mu \\end{matrix} \\right| = 0\n$$\n$$\n(1-\\mu)\\left( (1-\\mu)^2 - \\frac{1}{2} \\right) - \\left( \\frac{1}{2}(1-\\mu) \\right) = 0\n$$\n$$\n(1-\\mu)\\left( (1-\\mu)^2 - \\frac{1}{2} - \\frac{1}{2} \\right) = 0\n$$\n$$\n(1-\\mu)\\left( (1-\\mu)^2 - 1 \\right) = 0\n$$\n此方程对 $\\mu$ 有三个解：\n1. $1-\\mu = 0 \\implies \\mu_1 = 1$。\n2. $(1-\\mu)^2 - 1 = 0 \\implies (1-\\mu)^2 = 1 \\implies 1-\\mu = \\pm 1$。\n   - $1-\\mu = 1 \\implies \\mu_2 = 0$。\n   - $1-\\mu = -1 \\implies \\mu_3 = 2$。\n\n$3E$ 的特征值为 $\\{0, 1, 2\\}$。$E$ 的特征值为 $\\lambda_i = \\mu_i/3$，即 $\\{\\frac{0}{3}, \\frac{1}{3}, \\frac{2}{3}\\} = \\{0, \\frac{1}{3}, \\frac{2}{3}\\}$。\n\n谱半径 $\\rho(E)$ 是特征值绝对值的最大值：\n$$\n\\rho(E) = \\max\\left(|0|, \\left|\\frac{1}{3}\\right|, \\left|\\frac{2}{3}\\right|\\right) = \\frac{2}{3}\n$$", "answer": "$$\n\\boxed{\\frac{2}{3}}\n$$", "id": "2372552"}, {"introduction": "在理解了代数多重网格的核心部件（如插值）和分析工具（如双网格分析）之后，是时候将这些理论知识付诸实践，观察一个完整的多层次V循环是如何运作的。这个练习旨在搭建一座从理论到应用的桥梁，你将为一个典型的一维泊松问题构建一个简单的AMG求解器。更重要的是，你将开发一个诊断工具，用于测量V循环中每一层的误差缩减因子，这是调试和优化复杂数值求解器性能的一项关键技能。通过这个实践，你将对整个AMG算法流程获得一个全面而具体的操作性理解。[@problem_id:2372556]", "problem": "设计并实现一个完整的、可运行的程序，为对称正定线性系统构建一个简单的代数多重网格 (AMG) 层次结构，并执行单次V循环，同时在每个单独的层级上测量误差缩减因子。目标是创建一个诊断工具，通过量化每个层级上误差减少的程度，来调试性能不佳的多重网格求解器。\n\n从以下基本概念开始：\n- 线性系统的形式为 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是对称正定 (SPD) 矩阵。精确解为 $x^\\star = A^{-1} b$。\n- 在迭代步 $x$ 处的误差为 $e = x^\\star - x$。残差为 $r = b - A x$。\n- 松弛法通过 $x^{k+1} = x^k + M r^k$ 更新迭代步，其中 $M$ 是某个迭代矩阵。对于加权雅可比松弛法，$M = \\omega D^{-1}$，其中 $D$ 等于 $A$ 的对角线，且 $0 < \\omega \\leq 1$。\n- 多重网格层次结构由层级 $\\ell = 0, 1, \\dots, L$ 组成，包含矩阵 $A_\\ell$、限制算子 $R_\\ell$ 和插值算子 $P_\\ell$，它们通过伽辽金关系 $A_{\\ell+1} = R_\\ell A_\\ell P_\\ell$ 相关联。层级 $\\ell = 0$ 是最细层，$\\ell = L$ 是最粗层。\n- 在层级 $\\ell$ 上，带有 $\\nu_1$ 次预松弛和 $\\nu_2$ 次后松弛的V循环过程如下：对 $x_\\ell$ 进行预松弛，形成残差 $r_\\ell = b_\\ell - A_\\ell x_\\ell$，限制 $b_{\\ell+1} = R_\\ell r_\\ell$，在粗网格上近似求解 $A_{\\ell+1} y_{\\ell+1} = b_{\\ell+1}$（在最粗层上递归或精确求解），插值并校正 $x_\\ell \\leftarrow x_\\ell + P_\\ell y_{\\ell+1}$，然后进行后松弛。\n\n所需的定义和测量：\n- 对于每个层级 $\\ell$，将“每层缩减因子”定义为：在同一次V循环中，完成层级 $\\ell$ 的所有工作后误差的欧几里得范数，与开始层级 $\\ell$ 的工作前误差的欧几里得范数之比：\n$$\\rho_\\ell \\equiv \\frac{\\lVert e_\\ell^{\\text{out}} \\rVert_2}{\\lVert e_\\ell^{\\text{in}} \\rVert_2}.$$\n- 此处 $e_\\ell^{\\text{in}} = x_\\ell^\\star - x_\\ell^{\\text{in}}$ 且 $e_\\ell^{\\text{out}} = x_\\ell^\\star - x_\\ell^{\\text{out}}$，其中 $x_\\ell^\\star$ 是 $A_\\ell x_\\ell^\\star = b_\\ell$ 的精确解，而 $x_\\ell^{\\text{in}}$ 和 $x_\\ell^{\\text{out}}$ 分别是V循环中进入该层级时的迭代值和离开该层级时的迭代值。在最粗层级，求解被认为是精确的，因此 $\\rho_L = 0$。\n\n实现细节和约束：\n- 在最细层级上，将 $A$ 构建为作用于 $n$ 个内部点的标准一维泊松算子，带有狄利克雷边界条件，即主对角线元素为 $2$，次对角线和超对角线元素为 $-1$ 的三对角矩阵。\n- 使用简单聚合构建代数多重网格层次结构：\n  - 将连续的细网格变量划分为大小为 $2$ 的聚合体（如果 $n$ 是奇数，最后一个聚合体的大小可能为 $1$）。\n  - 将插值算子 $P_\\ell$ 定义为分段常数插值：每个细网格变量从其聚合体对应的粗网格变量处获得权重 $1$。\n  - 使用 $R_\\ell = P_\\ell^\\top$ 和伽辽金积 $A_{\\ell+1} = R_\\ell A_\\ell P_\\ell$。\n  - 当 $n_\\ell \\leq n_{\\min}$ 时停止粗化，其中 $n_{\\min}$ 是一个固定的较小阈值。\n- 对预松弛和后松弛均使用加权雅可比松弛法，松弛权重为 $\\omega$。每个松弛步骤更新 $x \\leftarrow x + \\omega D^{-1} (b - A x)$，其中 $D$ 是该层级上矩阵 $A$ 的对角线。\n- 在每个层级上通过直接稀疏求解来计算 $x_\\ell^\\star$，以便可以精确地测量 $\\ell^2$ 范数下的误差。这确保了 $\\rho_\\ell$ 是良定义且数值上可复现的。\n\n测试套件与最终输出：\n- 实现该诊断工具，并对以下三个测试案例评估每层缩减因子。对于每个案例，使用指定的未知数数量 $n$、预松弛次数 $\\nu_1$、后松弛次数 $\\nu_2$、雅可比松弛权重 $\\omega$、粗网格尺寸阈值 $n_{\\min} = 5$ 以及以下右端项 $b$：\n  - 案例 A (一般性能): $n = 63$, $\\nu_1 = 2$, $\\nu_2 = 2$, $\\omega = \\tfrac{2}{3}$，以及对于所有 $i$，$b_i = 1$。\n  - 案例 B (边界规模问题): $n = 3$, $\\nu_1 = 1$, $\\nu_2 = 1$, $\\omega = 0.8$，以及对于 $i = 1, \\dots, n$，$b_i = i + 1$。\n  - 案例 C (不良平滑选择): $n = 127$, $\\nu_1 = 1$, $\\nu_2 = 0$, $\\omega = 1$，以及对于所有 $i$，$b_i = 1$。\n- 对于每个案例，以零向量作为最细层级的初始猜测值开始V循环。\n- 您的程序必须输出单行内容，包含一个以逗号分隔的列表的列表，每个测试案例一个列表，其中每个内部列表包含该案例从最细层到最粗层的每层缩減因子 $\\rho_\\ell$。例如，输出格式必须严格遵循\n  \"[[rA0,rA1,...],[rB0,rB1,...],[rC0,rC1,...]]\"\n  的形式，其中每个 $r$ 是一个浮点数。本问题不涉及单位。", "solution": "该问题是有效的。它在科学上基于数值线性代数和代数多重网格方法的既定理论。问题陈述是适定 (well-posed) 的，提供了构建一个唯一的、确定性的、可验证的计算解所需的所有定义、约束和参数。其语言客观、精确，没有歧义或矛盾。\n\n该解决方案通过开发一个Python程序来实现，该程序分为三个主要部分：一个用于构建代数多重网格 (AMG) 层次结构的函数，一个执行单次V循环同时测量每层误差缩减的递归函数，以及一个处理指定测试案例的主驱动程序。\n\n**1. 代数多重网格层次结构构建**\n矩阵和网格转移算子的层次结构从最细层（表示为层级 $\\ell=0$）开始构建。\n\n- **最细网格算子 ($A_0$)**：对于一个有 $n$ 个内部点的问题，矩阵 $A_0$ 是一个 $n \\times n$ 的对称正定矩阵，对应于带齐次狄利克雷边界条件的负拉普拉斯算子的一维有限差分離散。其元素由下式给出：\n    $$\n    (A_0)_{ij} = \\begin{cases} 2  \\text{if } i = j \\\\ -1  \\text{if } |i-j| = 1 \\\\ 0  \\text{otherwise} \\end{cases}\n    $$\n- **粗化过程**：层次结构是通过反复粗化网格生成的。从层级 $\\ell$ 创建层级 $\\ell+1$ 的过程如下，当层级 $\\ell$ 的矩阵大小 $n_\\ell$ 小于或等于指定的阈值 $n_{\\min}$ 时，该过程停止。\n    - **聚合与插值 ($P_\\ell$)**：使用了一个简单的聚合方案，其中索引为 $(2j, 2j+1)$ 的连续细网格变量对被分组形成第 $j$ 个粗网格变量。将粗网格向量映射到细网格向量的插值算子 $P_\\ell$ 被定义为分段常数插值矩阵。它是一个 $n_\\ell \\times n_{\\ell+1}$ 矩阵，其中粗网格变量的数量为 $n_{\\ell+1} = \\lceil n_\\ell / 2 \\rceil$。如果细网格变量 $i$ 属于由粗网格变量 $k$ 表示的聚合体，则条目 $(P_\\ell)_{ik}$ 为 $1$，否则为 $0$。\n    - **限制 ($R_\\ell$)**：将细网格向量转移到粗网格的限制算子 $R_\\ell$ 被定义为插值算子的转置，即 $R_\\ell = P_\\ell^\\top$。\n    - **伽辽金算子 ($A_{\\ell+1}$)**：粗网格算子 $A_{\\ell+1}$ 使用伽辽金积计算。这种构造确保了对称性和正定性等性质得以保持。\n        $$ A_{\\ell+1} = R_\\ell A_\\ell P_\\ell $$\n    重复这一系列操作以生成矩阵 $A_1, A_2, \\dots, A_L$，直到最粗层 $L$ 的矩阵大小满足 $n_L \\le n_{\\min}$。\n\n**2. 带有每层诊断功能的V循环算法**\n单次V循环实现为一个递归函数，它从给定的层级 $\\ell$ 向下遍历到最粗层级 $L$，然后再返回。该诊断工具的核心是在每个层级上测量误差缩减因子 $\\rho_\\ell$。\n\n- **递归函数与状态**：定义了一个函数 `v_cycle(level, x, b)`，它接受当前层级索引 $\\ell$、当前迭代值 $x_\\ell$ 和对应的右端向量 $b_\\ell$。\n\n- **$\\rho_\\ell$ 的测量**：缩减因子定义为 $\\rho_\\ell \\equiv \\lVert e_\\ell^{\\text{out}} \\rVert_2 / \\lVert e_\\ell^{\\text{in}} \\rVert_2$。为了计算它，在进入和退出层级 $\\ell$ 的函数时测量状态：\n    - 进入时，初始迭代值为 $x_\\ell^{\\text{in}} = x_\\ell$。为了计算初始误差 $e_\\ell^{\\text{in}} = x_\\ell^\\star - x_\\ell^{\\text{in}}$，首先使用直接求解器计算特定层级线性系统 $A_\\ell x_\\ell = b_\\ell$ 的精确解：$x_\\ell^\\star = A_\\ell^{-1} b_\\ell$。然后计算并存储初始误差的欧几里得范数 $\\lVert e_\\ell^{\\text{in}} \\rVert_2$。\n    - 执行V循环逻辑（詳见下文），得到最终迭代值 $x_\\ell^{\\text{out}}$。\n    - 计算最终误差 $e_\\ell^{\\text{out}} = x_\\ell^\\star - x_\\ell^{\\text{out}}$ 及其范数 $\\lVert e_\\ell^{\\text{out}} \\rVert_2$。\n    - 最后，计算缩减因子 $\\rho_\\ell$。\n\n- **递归V循环步骤**：\n    1. **基本情况（最粗层级）**：如果当前层级是最粗层级 ($ \\ell = L $)，系统 $A_L x_L = b_L$ 被精确求解。输出的迭代值为 $x_L^{\\text{out}} = x_L^\\star = A_L^{-1} b_L$。根据规定，该层级的缩减因子取为 $\\rho_L = 0$。\n    2. **预松弛**：进行 $\\nu_1$ 步，使用松弛权重为 $\\omega$ 的加权雅可比方法平滑当前迭代值 $x_\\ell$：\n        $$ x_\\ell \\leftarrow x_\\ell + \\omega D_\\ell^{-1} (b_\\ell - A_\\ell x_\\ell) $$\n        此处，$D_\\ell$ 是矩阵 $A_\\ell$ 的对角线。\n    3. **粗网格校正**：\n        - 计算平滑后迭代值的残差：$r_\\ell = b_\\ell - A_\\ell x_\\ell$。\n        - 残差被限制到下一个更粗的层级，构成粗网格问题的右端项：$b_{\\ell+1} = R_\\ell r_\\ell$。\n        - 递归调用 `v_cycle` 函数来求解粗网格校正方程 $A_{\\ell+1} y_{\\ell+1} = b_{\\ell+1}$，校正量的初始猜测值为零，$y_{\\ell+1} = 0$。此调用返回计算出的校正量 $y_{\\ell+1}^{\\text{solved}}$。\n    4. **插值与校正**：粗网格校正被插值回细网格，并加到当前迭代值上：$x_\\ell \\leftarrow x_\\ell + P_\\ell y_{\\ell+1}^{\\text{solved}}$。\n    5. **后松弛**：对校正后的迭代值应用 $\\nu_2$ 步加权雅可比平滑，以平滑由插值步骤引入的高频误差。\n\n该递归函数返回最终迭代值 $x_\\ell^{\\text{out}}$ 和一个列表，该列表包含计算出的 $\\rho_\\ell$ 以及在其之前拼接的从更粗层级接收到的缩减因子列表。\n\n**3. 测试案例的执行**\n程序的主体部分设置并运行三个指定的测试案例。对每个案例，它定义参数 ($n, \\nu_1, \\nu_2, \\omega$)，构造初始矩阵 $A_0$ 和右端向量 $b_0$，基于粗网格尺寸阈值 $n_{\\min}=5$ 构建完整的AMG层次结构，并以零向量作为最细层级的初始猜测值来启动诊断性V循环。得到的每层缩减因子列表被收集起来，并以指定的字符串格式打印到标准输出。", "answer": "```python\nimport numpy as np\n\ndef construct_poisson_1d(n):\n    \"\"\"\n    Constructs the n x n matrix for the 1D Poisson problem.\n    \"\"\"\n    if n == 1:\n        return np.array([[2.0]])\n    A = 2.0 * np.eye(n) - 1.0 * np.eye(n, k=1) - 1.0 * np.eye(n, k=-1)\n    return A\n\ndef build_hierarchy(A0, n_min):\n    \"\"\"\n    Builds the AMG hierarchy using simple aggregation.\n    Returns a list of dictionaries, one for each level.\n    \"\"\"\n    hierarchy = []\n    A = A0\n    while A.shape[0] > n_min:\n        n_fine = A.shape[0]\n        n_coarse = (n_fine + 1) // 2\n\n        P = np.zeros((n_fine, n_coarse))\n        for j in range(n_coarse):\n            fine_idx1 = 2 * j\n            fine_idx2 = 2 * j + 1\n            P[fine_idx1, j] = 1.0\n            if fine_idx2  n_fine:\n                P[fine_idx2, j] = 1.0\n        \n        R = P.T\n        A_coarse = R @ A @ P\n        \n        hierarchy.append({'A': A, 'P': P, 'R': R})\n        A = A_coarse\n    \n    hierarchy.append({'A': A})\n    return hierarchy\n\ndef jacobi_relax(A, x, b, omega, nu):\n    \"\"\"\n    Performs nu steps of weighted Jacobi relaxation.\n    \"\"\"\n    # Using np.diag(A) is safe as A is SPD and small, so diagonal is positive.\n    D_inv = 1.0 / np.diag(A)\n    x_new = x.copy()\n    for _ in range(nu):\n        r = b - A @ x_new\n        x_new += omega * D_inv * r\n    return x_new\n\ndef v_cycle_recursive(level, x, b, hierarchy, nu1, nu2, omega):\n    \"\"\"\n    Performs one recursive V-cycle and measures per-level reduction factors.\n    \"\"\"\n    A = hierarchy[level]['A']\n    \n    try:\n        x_star = np.linalg.solve(A, b)\n    except np.linalg.LinAlgError:\n        # For singular matrices that might appear due to floating point issues,\n        # use pseudo-inverse. A should be SPD, but as a safeguard.\n        x_star = np.linalg.pinv(A) @ b\n\n    norm_e_in = np.linalg.norm(x_star - x)\n\n    # Base case: coarsest level\n    if level == len(hierarchy) - 1:\n        x_out = x_star  # Exact solve on the coarsest level\n        rho_level = 0.0 # Per problem specification\n        return x_out, [rho_level]\n\n    # --- Downward stroke of V ---\n    # 1. Pre-relaxation\n    x_pre_relaxed = jacobi_relax(A, x, b, omega, nu1)\n    \n    # 2. Coarse-grid correction\n    r = b - A @ x_pre_relaxed\n    R = hierarchy[level]['R']\n    b_coarse = R @ r\n    \n    y_coarse = np.zeros(hierarchy[level+1]['A'].shape[0])\n    \n    y_coarse_solved, rhos_coarser = v_cycle_recursive(\n        level + 1, y_coarse, b_coarse, hierarchy, nu1, nu2, omega\n    )\n    \n    # --- Upward stroke of V ---\n    # 3. Prolongation and correction\n    P = hierarchy[level]['P']\n    x_corrected = x_pre_relaxed + P @ y_coarse_solved\n    \n    # 4. Post-relaxation\n    x_out = jacobi_relax(A, x_corrected, b, omega, nu2)\n    \n    # --- Measurement for current level ---\n    norm_e_out = np.linalg.norm(x_star - x_out)\n    \n    if norm_e_in > 1e-15:\n      rho_level = norm_e_out / norm_e_in\n    else:\n      rho_level = 0.0\n\n    all_rhos = [rho_level] + rhos_coarser\n    \n    return x_out, all_rhos\n\ndef solve_case(n, nu1, nu2, omega, b_func, n_min):\n    \"\"\"\n    Sets up and solves one test case, returning the list of reduction factors.\n    \"\"\"\n    A0 = construct_poisson_1d(n)\n    b0 = b_func(n)\n    \n    hierarchy = build_hierarchy(A0, n_min)\n    \n    x0 = np.zeros(n)\n    \n    _, rhos = v_cycle_recursive(0, x0, b0, hierarchy, nu1, nu2, omega)\n    \n    return rhos\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = [\n        # Case A: n=63, nu1=2, nu2=2, omega=2/3, b_i=1\n        (63, 2, 2, 2.0/3.0, lambda n: np.ones(n, dtype=float)),\n        # Case B: n=3, nu1=1, nu2=1, omega=0.8, b_i = i+1 for i=1..n\n        (3, 1, 1, 0.8, lambda n: np.arange(2, n + 2, dtype=float)),\n        # Case C: n=127, nu1=1, nu2=0, omega=1, b_i=1\n        (127, 1, 0, 1.0, lambda n: np.ones(n, dtype=float))\n    ]\n    \n    n_min = 5\n    all_results = []\n\n    for case_params in test_cases:\n        n, nu1, nu2, omega, b_func = case_params\n        rhos = solve_case(n, nu1, nu2, omega, b_func, n_min)\n        all_results.append(rhos)\n\n    # Format the final output string exactly as required.\n    # The str() representation of a list of lists is already very close.\n    # Remove spaces to be perfectly compliant.\n    output_str = str(all_results).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n```", "id": "2372556"}]}