{"hands_on_practices": [{"introduction": "哈密尔顿蒙特卡洛（HMC）的魅力在于它利用模拟的物理过程来探索概率分布。该过程的第一步是定义一个“势能” $U(q) = -\\ln \\pi(q)$，其中“力” $-\\nabla U(q)$ 会引导我们的采样器。这个练习 [@problem_id:791690] 为这一关键步骤提供了基础训练，要求你为学生t分布（一种比高斯分布具有更重尾部的常见分布）推导出力。", "problem": "在哈密顿蒙特卡洛（HMC）这一马尔可夫链蒙特卡洛（MCMC）方法的背景下，我们的目标是通过引入一个辅助动量变量 $p$ 从目标概率分布 $\\pi(q)$ 中采样。系统的状态由 $(q, p)$ 描述，其动力学由哈密顿量 $H(q, p) = U(q) + K(p)$ 控制。\n\n势能 $U(q)$ 定义为目标概率密度的负对数，相差一个可加常数：$U(q) = -\\log \\pi(q)$。动能 $K(p)$ 通常对于一个“质量”参数 $m$ 定义为 $K(p) = \\frac{p^2}{2m}$。\n\n系统随时间的演化由哈密顿方程描述：\n$$\n\\frac{dq}{dt} = \\frac{\\partial H}{\\partial p}\n$$\n$$\n\\frac{dp}{dt} = -\\frac{\\partial H}{\\partial q} = -\\frac{\\partial U}{\\partial q}\n$$\n项 $-\\frac{\\partial U}{\\partial q}$ 充当引导采样器轨迹的“力”。实现 HMC 的一个关键步骤是推导这个力项的解析表达式，即势能的梯度。\n\n考虑从一个具有 $\\nu > 0$ 个自由度的单变量学生t分布中采样。随机变量 $q$ 的概率密度函数（PDF）由下式给出：\n$$\n\\pi(q) = \\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\sqrt{\\nu\\pi} \\, \\Gamma\\left(\\frac{\\nu}{2}\\right)} \\left(1 + \\frac{q^2}{\\nu}\\right)^{-\\frac{\\nu+1}{2}}\n$$\n其中 $\\Gamma(\\cdot)$ 是伽马函数。\n\n针对此目标分布，推导势能梯度 $\\frac{\\partial U}{\\partial q}$ 的表达式。您的最终表达式应以位置变量 $q$ 和自由度参数 $\\nu$ 表示。", "solution": "我们有势能\n$$\nU(q)=-\\ln\\pi(q)\n=-\\ln\\Bigl[\\tfrac{\\Gamma\\bigl(\\tfrac{\\nu+1}{2}\\bigr)}{\\sqrt{\\nu\\pi}\\,\\Gamma\\bigl(\\tfrac{\\nu}{2}\\bigr)}\\Bigr]\n+\\frac{\\nu+1}{2}\\ln\\Bigl(1+\\frac{q^2}{\\nu}\\Bigr)\\,.\n$$\n前置因子是关于 $q$ 的常数，所以相差一个可加常数的情况下\n$$\nU(q)=\\frac{\\nu+1}{2}\\ln\\Bigl(1+\\frac{q^2}{\\nu}\\Bigr)\\,.\n$$\n对 $q$ 求导：\n\n$$\n\\frac{\\partial U}{\\partial q}\n=\\frac{\\nu+1}{2}\\cdot\\frac{1}{1+\\tfrac{q^2}{\\nu}}\\cdot\\frac{d}{dq}\\Bigl(\\tfrac{q^2}{\\nu}\\Bigr)\n=\\frac{\\nu+1}{2}\\cdot\\frac{1}{1+\\tfrac{q^2}{\\nu}}\\cdot\\frac{2q}{\\nu}\n=\\frac{(\\nu+1)\\,q}{\\nu+q^2}\\,.\n$$", "answer": "$$\\boxed{\\frac{(\\nu+1)\\,q}{\\nu+q^2}}$$", "id": "791690"}, {"introduction": "定义了力之后，我们现在可以构建一个完整的 HMC 采样器。这个实践 [@problem_id:2399525] 将指导你实现核心的 HMC 算法，包括蛙跳积分器和 Metropolis-Hastings 校正步骤。通过将你的采样器应用于一个具有近奇异点的势能，你将亲身体验复杂系统中出现的数值稳定性挑战，并学会如何通过监控能量守恒和接受率来诊断这些问题。", "problem": "您需要设计并实现一个哈密顿蒙特卡洛采样器，以研究近奇异势对数值稳定性和接受行为的影响。工作将在一个空间维度上进行，质量等于 $1$，您的推导必须严格基于哈密顿方程和 Metropolis–Hastings 准则，从第一性原理出发。\n\n考虑一维吸引性库仑势的一个正则化且具有约束性的版本。将势能定义为\n$$\nU(q;a) \\equiv \\frac{1}{2}\\,q^2 - \\frac{c}{\\sqrt{q^2 + a^2}},\n$$\n其中 $c = 1$。参数 $a > 0$ 软化了 $q=0$ 处的奇异点，而二次项确保了目标分布的可归一性。目标概率密度正比于 $\\exp\\!\\left(-U(q;a)\\right)$。使用动能\n$$\nK(p) \\equiv \\frac{1}{2} p^2,\n$$\n因此哈密顿量为 $H(q,p) \\equiv U(q;a) + K(p)$。\n\n您的任务是：\n- 为与 $H(q,p)$ 相关的哈密顿方程推导一个时间可逆、保体积的积分器，该积分器需与哈密顿蒙特卡洛所需的性质一致。您的构建应基于源自哈密顿方程的分裂原理，并避免任何非辛离散化。\n- 通过对 $U(q;a)$ 关于 $q$ 求导来计算力项。\n- 实现一个哈密顿蒙特卡洛核，该核在给定当前位置 $q$ 的情况下，从零均值单位方差的高斯分布中抽取一个新的动量 $p$，使用给定的步长 $\\epsilon$ 和步数 $L$ 对哈密顿动力学进行积分，然后使用轨道起点和终点的精确哈密顿量 $H(q,p)$ 应用 Metropolis–Hastings 接受/拒绝步骤。\n- 对于每个提议，通过追踪离散路径上访问到的 $q$ 的最小绝对值，并将其与一个固定的阈值 $\\delta$ 进行比较，记录数值轨道是否接近了软化奇异点。\n- 对于每组参数集，在固定数量 $N$ 次提议之后，报告三个指标：接受率、平均哈密顿量绝对误差（所有提议中 $\\lvert \\Delta H \\rvert$ 的平均值），以及其数值轨道满足 $\\min \\lvert q \\rvert  \\delta$ 的提议所占的比例。\n\n必须使用的约束和固定选择：\n- 使用 $c = 1$ 和质量等于 $1$。\n- 对每个参数集使用 $N = 300$ 次哈密顿蒙特卡洛提议。\n- 使用阈值 $\\delta = 10^{-2}$。\n- 为保证可复现性，使用固定的随机数生成器种子 $12345$。如果您选择在不同测试用例中改变种子，您必须以一种确定性的、有文档记录的方式进行，该方式仅依赖于测试用例索引和固定的基础种子。\n- 为了接受步骤的数值稳定性，请在对数空间中进行比较，利用接受条件等价于比较 $\\log u$ 和 $- \\Delta H$ 这一事实，其中 $u$ 从 $(0,1)$ 上的均匀分布中抽取。\n- 每个测试用例的初始位置 $q_0$ 在下面的测试套件中指定。始终从这个 $q_0$ 开始马尔可夫链，并精确运行 $N$ 次提议，不进行预烧期移除。\n\n参数值测试套件：\n- 情况 1：$\\epsilon = 0.05$，$L = 50$，$a = 0.1$，$q_0 = 1.0$。\n- 情况 2：$\\epsilon = 0.2$，$L = 50$，$a = 0.1$，$q_0 = 1.0$。\n- 情况 3：$\\epsilon = 0.05$，$L = 50$，$a = 0.001$，$q_0 = 0.1$。\n- 情况 4：$\\epsilon = 0.2$，$L = 50$，$a = 0.001$，$q_0 = 0.1$。\n\n指标定义：\n- 接受率是在 $N$ 次提议中被接受的提议所占的比例，表示为 $[0,1]$ 内的一个小数。\n- 平均哈密顿量绝对误差是 $N$ 次提议中 $\\lvert \\Delta H \\rvert$ 的算术平均值，其中 $\\Delta H \\equiv H(q^{\\star},p^{\\star}) - H(q,p)$ 是数值轨道终点和起点之间的哈密顿量变化，无论提议是否被接受。\n- 近奇异点比例是其数值轨道在至少一个离散积分步骤中满足 $\\min \\lvert q \\rvert  \\delta$ 的提议所占的比例。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含四个测试用例的结果，形式为一个由方括号括起来的逗号分隔列表。每个测试用例的结果本身必须是一个包含三个小数的列表，顺序为 $[$接受率$, $平均哈密顿量绝对误差$, $近奇异点比例$]$，四舍五入到恰好 $6$ 位小数。例如，您的程序必须打印类似以下形式的内容：\n$$\n\\big[\\,[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3],[a_4,b_4,c_4]\\,\\big],\n$$\n其中每个 $a_i$、$b_i$、$c_i$ 都是四舍五入到 $6$ 位的小数。不应打印任何额外文本。", "solution": "问题陈述已经过评估并被确定为有效。这是一个在计算物理学领域中提法明确、有科学依据的问题，包含了获得唯一确定性解所需的所有必要信息。我将继续进行推导和实现。\n\n主要任务是为一个一维单位质量（$m=1$）的粒子构建一个哈密顿蒙特卡洛（HMC）采样器，该粒子由一个特定的势能函数控制。目标是在控制数值积分步长和与势奇异点接近程度的不同参数下，分析采样器的性能。\n\n系统的哈密顿量 $H(q,p)$ 是动能 $K(p)$ 和势能 $U(q;a)$ 的和：\n$$\nH(q,p) = K(p) + U(q;a)\n$$\n给定 $m=1$，动能为：\n$$\nK(p) = \\frac{1}{2} p^2\n$$\n势能给定为：\n$$\nU(q;a) = \\frac{1}{2}q^2 - \\frac{c}{\\sqrt{q^2 + a^2}}\n$$\n其中常数 $c=1$。参数 $a > 0$ 正则化了吸引性的类库仑项，防止在 $q=0$ 处出现真正的奇异点。二次项 $\\frac{1}{2}q^2$ 确保了目标概率密度 $\\pi(q) \\propto \\exp(-U(q;a))$ 是可归一化的。\n\n描述系统在相空间 $(q,p)$ 中演化的哈密顿运动方程为：\n$$\n\\frac{dq}{dt} = \\frac{\\partial H}{\\partial p} = p\n$$\n$$\n\\frac{dp}{dt} = -\\frac{\\partial H}{\\partial q} = -\\frac{\\partial U}{\\partial q}\n$$\n项 $-\\frac{\\partial U}{\\partial q}$ 是力，$F(q)$。我们计算这个导数：\n$$\n\\frac{\\partial U}{\\partial q} = \\frac{\\partial}{\\partial q} \\left(\\frac{1}{2}q^2 - (q^2 + a^2)^{-1/2}\\right) = q - \\left(-\\frac{1}{2}\\right)(q^2 + a^2)^{-3/2}(2q) = q + \\frac{q}{(q^2 + a^2)^{3/2}}\n$$\n因此，力为：\n$$\nF(q;a) = -q - \\frac{q}{(q^2 + a^2)^{3/2}}\n$$\n\n为了数值模拟这些动力学，需要一个辛积分器。蛙跳法（或 Störmer-Verlet 方法）是一个标准选择，因为它既是时间可逆的又是保体积的，这些性质对于 HMC 算法的正确性至关重要。该方法源于哈密顿演化算子的二阶 Trotter-Suzuki 分解，它将演化分解为在哈密顿量的动能和势能部分下的一系列步骤。大小为 $\\epsilon$ 的单个蛙跳步骤按如下方式更新位置 $q$ 和动量 $p$：\n$1$. 动量的半步更新：\n$$\np(t + \\epsilon/2) = p(t) + F(q(t);a) \\cdot \\frac{\\epsilon}{2}\n$$\n$2$. 位置的整步更新：\n$$\nq(t + \\epsilon) = q(t) + p(t + \\epsilon/2) \\cdot \\epsilon\n$$\n$3$. 动量的第二个半步更新：\n$$\np(t + \\epsilon) = p(t + \\epsilon/2) + F(q(t+\\epsilon);a) \\cdot \\frac{\\epsilon}{2}\n$$\n为生成长度为 $L\\epsilon$ 的轨道，此过程迭代 $L$ 次。为了计算效率，相邻步骤的完整动量更新被合并。\n\nHMC 算法从一个给定的位置 $q_{current}$ 开始，对每个提议按以下步骤进行：\n$1$. **动量采样**：从其条件分布中抽取一个新的动量 $p_{current}$，由于 $K(p) = p^2/2$，该分布是标准高斯分布，即 $p_{current} \\sim \\mathcal{N}(0, 1)$。\n$2$. **轨道积分**：从 $(q_{current}, p_{current})$ 开始，系统以步长 $\\epsilon$ 演化 $L$ 个蛙跳步骤。这会产生一个提议状态 $(q_{proposal}, p_{proposal})$。在此积分过程中，我们必须沿着离散路径 $q_0, q_1, \\ldots, q_L$ 追踪位置的最小绝对值 $\\min_i |q_i|$。\n$3$. **Metropolis-Hastings 接受**：基于哈密顿量的变化 $\\Delta H = H(q_{proposal}, p_{proposal}) - H(q_{current}, p_{current})$ 来接受或拒绝提议。接受概率为 $\\alpha = \\min(1, \\exp(-\\Delta H))$。这个简单的形式是有效的，因为蛙跳积分器是保体积且时间可逆的。时间可逆性属性意味着，如果从 $(q_{proposal}, -p_{proposal})$ 开始并向后积分时间，将恢复到 $(q_{current}, -p_{current})$，这使得提议在适当的意义上是对称的。抽取一个随机变量 $u \\sim U(0,1)$，如果 $u  \\exp(-\\Delta H)$，或等价地 $\\log u  -\\Delta H$，则接受提议。如果接受，新状态为 $q_{proposal}$；否则，状态保持为 $q_{current}$。\n\n对于每个测试用例的 $N=300$ 次提议中的每一次，我们将记录三个量：（1）提议是否被接受，（2）哈密顿量绝对误差 $|\\Delta H|$，以及（3）轨道的最小绝对位置是否低于阈值 $\\delta = 10^{-2}$。最终报告的指标将是这些量在所有 $N$ 次提议上的平均值。实现将按照规定使用固定的随机种子以保证可复现性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and runs a Hamiltonian Monte Carlo simulation for a 1D particle\n    with a regularized Coulomb-like potential, as specified in the problem statement.\n    \"\"\"\n\n    # --- Fixed Parameters ---\n    C_CONST = 1.0\n    N_PROPOSALS = 300\n    DELTA_THRESHOLD = 1e-2\n    BASE_SEED = 12345\n\n    # --- Test Suite ---\n    test_cases = [\n        # (epsilon, L, a, q0)\n        (0.05, 50, 0.1, 1.0),\n        (0.2, 50, 0.1, 1.0),\n        (0.05, 50, 0.001, 0.1),\n        (0.2, 50, 0.001, 0.1),\n    ]\n\n    all_results = []\n\n    # --- Physics and HMC Functions ---\n    def potential_energy(q, a):\n        \"\"\"Computes the potential energy U(q;a).\"\"\"\n        return 0.5 * q**2 - C_CONST / np.sqrt(q**2 + a**2)\n\n    def kinetic_energy(p):\n        \"\"\"Computes the kinetic energy K(p).\"\"\"\n        return 0.5 * p**2\n\n    def hamiltonian(q, p, a):\n        \"\"\"Computes the total energy H(q,p).\"\"\"\n        return potential_energy(q, a) + kinetic_energy(p)\n\n    def force(q, a):\n        \"\"\"Computes the force F = -dU/dq.\"\"\"\n        return -q - (C_CONST * q) / (q**2 + a**2)**(3/2)\n\n    for i, case in enumerate(test_cases):\n        epsilon, L, a, q0 = case\n        \n        # Use a deterministic seed for each case to ensure reproducibility\n        rng = np.random.default_rng(BASE_SEED + i)\n\n        q_current = q0\n        \n        accepted_count = 0\n        total_abs_h_error = 0.0\n        near_singularity_count = 0\n        \n        for _ in range(N_PROPOSALS):\n            # 1. Momentum Resampling\n            p_current = rng.normal(0, 1)\n\n            # Store initial state for MH step\n            q_initial, p_initial = q_current, p_current\n            h_initial = hamiltonian(q_initial, p_initial, a)\n\n            # --- 2. Trajectory Integration (Leapfrog) ---\n            q_prop, p_prop = q_initial, p_initial\n            \n            # Track if trajectory approaches singularity\n            min_abs_q = abs(q_prop)\n\n            # Initial half-step for momentum\n            p_prop += 0.5 * epsilon * force(q_prop, a)\n\n            # L-1 full steps for position and momentum\n            for _ in range(L - 1):\n                q_prop += epsilon * p_prop\n                min_abs_q = min(min_abs_q, abs(q_prop))\n                p_prop += epsilon * force(q_prop, a)\n            \n            # Final full step for position\n            q_prop += epsilon * p_prop\n            min_abs_q = min(min_abs_q, abs(q_prop))\n\n            # Final half-step for momentum\n            p_prop += 0.5 * epsilon * force(q_prop, a)\n            \n            # Record if trajectory passed the threshold\n            if min_abs_q  DELTA_THRESHOLD:\n                near_singularity_count += 1\n\n            # --- 3. Metropolis-Hastings Acceptance Step ---\n            h_proposal = hamiltonian(q_prop, p_prop, a)\n            delta_h = h_proposal - h_initial\n            total_abs_h_error += abs(delta_h)\n\n            # Acceptance check in log space for numerical stability\n            if np.log(rng.uniform(0, 1))  -delta_h:\n                q_current = q_prop\n                accepted_count += 1\n            # If rejected, q_current remains unchanged\n\n        # Calculate metrics for this test case\n        acceptance_rate = accepted_count / N_PROPOSALS\n        mean_abs_h_error = total_abs_h_error / N_PROPOSALS\n        near_singularity_fraction = near_singularity_count / N_PROPOSALS\n        \n        all_results.append([\n            acceptance_rate, \n            mean_abs_h_error, \n            near_singularity_fraction\n        ])\n\n    # Format the final output string exactly as required\n    outer_parts = []\n    for res in all_results:\n        inner_str = f\"[{res[0]:.6f},{res[1]:.6f},{res[2]:.6f}]\"\n        outer_parts.append(inner_str)\n    final_output_str = f\"[{','.join(outer_parts)}]\"\n\n    print(final_output_str)\n\nsolve()\n```", "id": "2399525"}, {"introduction": "对于复杂的高维模型，手动计算梯度可能既繁琐又容易出错。这个练习 [@problem_id:2399583] 介绍了一种强大的解决方案：自动微分（AD），这是现代机器学习框架背后的引擎。你将从头开始实现一个前向模式的 AD 引擎，并看到它如何无缝地提供 HMC 所需的精确梯度，从而将其使用与手动推导进行对比，并体会其强大功能与便利性。", "problem": "您需要从基本原理出发，设计并实现一个哈密顿蒙特卡洛（HMC）采样器，用于从未归一化的目标密度中进行采样。您的实现必须基于以下基本事实。\n\n1. 哈密顿动力学：为位置 $q \\in \\mathbb{R}^d$ 引入一个辅助动量 $p$，其质量矩阵 $M$ 为对称正定矩阵。将势能定义为 $U(q) = -\\log \\pi(q)$（不计一个加法常数），动能定义为 $K(p) = \\tfrac{1}{2} p^\\top M^{-1} p$。哈密顿量为 $H(q,p) = U(q) + K(p)$。哈密顿方程为\n$$\n\\frac{dq}{dt} = \\frac{\\partial H}{\\partial p} = M^{-1} p, \\qquad \\frac{dp}{dt} = -\\frac{\\partial H}{\\partial q} = -\\nabla U(q).\n$$\n\n2. 辛积分：为了对哈密顿方程进行数值积分，请使用您选择的一种与上述方程兼容的辛、时间可逆方法。该方法必须具有二阶精度，并且只应需要计算 $\\nabla U(q)$ 和与 $M^{-1}$ 的矩阵-向量乘积。\n\n3. Metropolis修正：为了校正离散化误差，给定一个通过数值积分动力学时间间隔 $\\tau$ 得到的提议 $(q', p')$，以如下概率接受该提议\n$$\n\\alpha = \\min\\left(1, \\exp\\big(-H(q', p') + H(q, p)\\big)\\right).\n$$\n如果拒绝，则保持当前状态 $q$。\n\n4. 动量重采样：在每次迭代中，从密度正比于 $\\exp\\left(-\\tfrac{1}{2} p^\\top M^{-1} p\\right)$ 的高斯分布中独立采样 $p$。\n\n您的任务是实现：\n\n- 一个通用的HMC采样器，其参数包括势能 $U(q)$、其梯度 $\\nabla U(q)$、一个对角质量矩阵 $M = \\mathrm{diag}(m_1, \\dots, m_d)$、一个步长 $\\epsilon$、积分步数 $L$、迭代次数 $N$、预烧期 $B$ 以及一个初始位置 $q_0$。\n\n- 两种 $\\nabla U(q)$ 的梯度提供器：\n  1) 根据指定的 $U(q)$ 定义手动计算的解析梯度，以及\n  2) 在您的程序中实现的前向模式自动微分引擎，使用对偶数，并通过基本标量运算传播一个长度为 $d$ 的导数向量。您的自动微分引擎应在单次前向传播中，为向量输入 $q \\in \\mathbb{R}^d$ 返回标量值 $U(q)$ 和梯度 $\\nabla U(q)$。\n\n目标分布与势能：\n\n- 情况A（$\\mathbb{R}^2$ 中的相关高斯分布）：设目标为一个相关高斯分布，其均值为 $\\mu = (1.0, -1.0)$，协方差为\n$$\n\\Sigma = \\begin{bmatrix}\n1.0  0.8\\\\\n0.8  2.0\n\\end{bmatrix}.\n$$\n令\n$$\nU(q) = \\tfrac{1}{2} (q - \\mu)^\\top \\Sigma^{-1} (q - \\mu),\n$$\n使得 $\\pi(q) \\propto \\exp\\big(-U(q)\\big)$。提供其解析梯度 $\\nabla U(q) = \\Sigma^{-1} (q - \\mu)$。\n\n- 情况B（与情况A相同的相关高斯分布，但积分器故意调校不当）：使用与情况A中相同的 $U(q)$ 和解析梯度，但采用一个有意设置的大步长来探究HMC的接受行为。\n\n- 情况C（$\\mathbb{R}^2$ 中的Rosenbrock型势能）：令 $q = (x,y)$ 且\n$$\nU(q) = \\frac{(1 - x)^2 + 100 (y - x^2)^2}{20}.\n$$\n提供其从基本原理推导出的解析梯度。注意，此目标是未归一化的，但对HMC有效，因为仅使用 $U(q)$ 的差值。\n\n实现要求：\n\n- 辛积分器必须与上述哈密顿系统一致，且只能使用 $\\nabla U(q)$ 的求值和与 $M^{-1}$ 的乘法。\n\n- 自动微分引擎必须实现带有导数向量的前向模式对偶数，并支持上述势能所需的标量算术运算（加、减、乘、除和整数次幂），为向量输入 $q$ 生成完整的梯度 $\\nabla U(q)$。\n\n- 随机性必须是可复现的：为每种情况使用固定的随机种子，以确保结果是确定性的。不涉及角度；无需单位转换。\n\n测试套件参数：\n\n- 情况A（“理想路径”）：\n  - 维度 $d = 2$。\n  - 均值 $\\mu = (1.0, -1.0)$ 和协方差 $\\Sigma$ 如上；使用其精确的逆矩阵 $\\Sigma^{-1}$。\n  - 对角质量 $M = \\mathrm{diag}(1.0, 1.0)$。\n  - 初始位置 $q_0 = (0.0, 0.0)$。\n  - 步长 $\\epsilon = 0.15$。\n  - 积分步数 $L = 20$。\n  - 迭代次数 $N = 1500$，预烧期 $B = 300$。\n  - 种子 $s = 42$。\n\n- 情况B（边界压力测试的大步长）：\n  - 相同的 $\\mu$、$\\Sigma$ 和 $M$。\n  - $q_0 = (0.0, 0.0)$。\n  - 步长 $\\epsilon = 0.9$。\n  - 积分步数 $L = 25$。\n  - 迭代次数 $N = 800$，预烧期 $B = 200$。\n  - 种子 $s = 43$。\n\n- 情况C（Rosenbrock势能）：\n  - $U(q) = \\big((1 - x)^2 + 100 (y - x^2)^2\\big)/20$，在 $\\mathbb{R}^2$ 中，且 $q_0 = (0.0, 0.0)$。\n  - 对角质量 $M = \\mathrm{diag}(1.0, 1.0)$。\n  - 步长 $\\epsilon = 0.02$。\n  - 积分步数 $L = 30$。\n  - 迭代次数 $N = 1200$，预烧期 $B = 300$。\n  - 种子 $s = 44$。\n\n要求的输出：\n\n对于每种情况，运行两个采样器：一个使用解析梯度，另一个使用自动微分梯度。计算并报告以下数值结果：\n\n- 情况A：\n  1) 使用解析梯度的接受率（浮点数）。\n  2) 使用自动微分梯度的接受率（浮点数）。\n  3) 预烧期后的链（解析梯度）的样本均值与真实均值 $\\mu$ 之间差值的欧几里得范数（浮点数）。\n\n- 情况B：\n  4) 使用解析梯度的接受率（浮点数）。\n  5) 使用自动微分梯度的接受率（浮点数）。\n  6) 此情况下两种接受率之间的绝对差（浮点数）。\n\n- 情况C：\n  7) 使用解析梯度的接受率（浮点数）。\n  8) 使用自动微分梯度的接受率（浮点数）。\n  9) 在 $q^\\star = (1.0, 1.0)$ 处求值的解析梯度与自动微分梯度之间逐分量的最大绝对差（浮点数）。\n\n最终输出格式：\n\n您的程序必须生成单行输出，其中包含按上述顺序列出的9个结果，形式为一个用方括号括起来的逗号分隔列表，每个浮点数四舍五入到六位小数，例如：\n\"[0.712000,0.708667,0.054321,0.053750,0.057500,0.003750,0.635000,0.628333,0.000000]\"。", "solution": "任务是从基本原理出发，构建并实现一个哈密顿蒙特卡洛（HMC）采样器。这需要综合运用经典力学、数值积分和统计模拟中的概念。问题陈述的有效性已确认；其科学上合理，问题提法恰当，并提供了所有必要的参数。我们着手进行求解。\n\nHMC的核心是通过一个辅助动量变量 $p \\in \\mathbb{R}^d$ 来增强目标变量 $q \\in \\mathbb{R}^d$（其概率密度为 $\\pi(q)$）。这就创建了一个综合物理系统。联合空间 $(q, p)$ 上的概率密度定义为 $\\pi(q, p) = \\pi(q) \\pi(p)$。我们定义一个势能 $U(q) = -\\log \\pi(q)$ 和一个动能 $K(p)$。按照规定，动能的一个标准选择是 $K(p) = \\frac{1}{2} p^\\top M^{-1} p$，其中 $M$ 是一个对称正定的“质量”矩阵，通常为对角矩阵。这对应于动量分布为一个零均值高斯分布，$p \\sim \\mathcal{N}(0, M)$。\n\n该系统的总能量由哈密顿量给出，$H(q, p) = U(q) + K(p)$。系统随时间的演化由哈密顿方程控制：\n$$\n\\frac{dq}{dt} = \\frac{\\partial H}{\\partial p} = M^{-1} p\n$$\n$$\n\\frac{dp}{dt} = -\\frac{\\partial H}{\\partial q} = -\\nabla U(q)\n$$\n在理想物理系统中，这种演化会保持总能量 $H(q,p)$ 守恒，并且在相空间 $(q,p)$ 中是保体积的。HMC利用了这一性质。为生成一个样本，我们首先从其高斯分布中抽取一个新的动量 $p$，然后使用数值积分器将系统 $(q, p)$ 演化一段固定的时间 $\\tau$ 以获得一个提议 $(q', p')$。由于数值误差，$H(q', p')$ 不会完全等于 $H(q, p)$，因此使用一个Metropolis-Hastings修正步骤，以概率 $\\alpha = \\min(1, \\exp(-H(q', p') + H(q, p)))$ 接受该提议。这确保了得到的马尔可夫链具有正确的平稳分布 $\\pi(q)$。\n\n一个关键组成部分是数值积分器。为了尽可能地保持哈密顿动力学的理想性质，需要使用辛、时间可逆的积分器。蛙跳法（或Störmer-Verlet方法）是标准选择。这是一种二阶方法，以交错或“蛙跳”的方式更新位置和动量。对于大小为 $\\epsilon$ 的单步更新，步骤如下：\n1. 动量的半步更新：$p(t + \\epsilon/2) = p(t) - (\\epsilon/2) \\nabla U(q(t))$\n2. 位置的全步更新：$q(t + \\epsilon) = q(t) + \\epsilon M^{-1} p(t + \\epsilon/2)$\n3. 动量的最终半步更新：$p(t + \\epsilon) = p(t + \\epsilon/2) - (\\epsilon/2) \\nabla U(q(t + \\epsilon))$\n\n该序列重复 $L$ 次，以积分总时间 $\\tau = L\\epsilon$。该方法是时间可逆和辛的，这使得HMC算法具有出色的长期能量守恒性和高接受率。\n\nHMC算法需要对数后验的梯度，$\\nabla U(q)$。这可以解析地提供或数值地计算。我们将实现这两种方法。对于后者，我们使用带对偶数的前向模式自动微分（AD）。一个对偶数是形式为 $z = (u, \\nabla u)$ 的对象，其中 $u$ 是函数的标量值，$\\nabla u \\in \\mathbb{R}^d$ 是其梯度向量。在这些对象上定义了算术运算，以根据微积分法则传播导数：\n-   加法：$(u, \\nabla u) + (v, \\nabla v) = (u+v, \\nabla u + \\nabla v)$\n-   乘法：$(u, \\nabla u) \\cdot (v, \\nabla v) = (uv, v \\nabla u + u \\nabla v)$\n-   幂法则：$(u, \\nabla u)^n = (u^n, n u^{n-1} \\nabla u)$\n\n通过将输入变量 $q_i$ 表示为对偶数 $(q_i, e_i)$，其中 $e_i$ 是第 $i$ 个标准基向量，并使用对偶数算术来评估函数 $U(q)$，最终结果是一个对偶数 $(U(q), \\nabla U(q))$。这在单次前向传播中以机器精度同时提供了函数值及其完整梯度。\n\n指定势能函数的解析梯度如下：\n-   对于高斯情况，$U(q) = \\frac{1}{2} (q - \\mu)^\\top \\Sigma^{-1} (q - \\mu)$，其梯度为 $\\nabla U(q) = \\Sigma^{-1} (q - \\mu)$。\n-   对于Rosenbrock型情况，$U(x,y) = \\frac{1}{20}((1 - x)^2 + 100 (y - x^2)^2)$，其梯度为：\n$$\n\\nabla U(q) = \\begin{pmatrix} \\frac{\\partial U}{\\partial x} \\\\ \\frac{\\partial U}{\\partial y} \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{10}(x - 1 - 200x(y - x^2)) \\\\ 10(y - x^2) \\end{pmatrix}\n$$\n\n实现将包括一个 `DualNumber` 类、一个通用的 `hmc_sampler` 函数，以及针对每种势能和梯度来源的特定函数。采样器将迭代地重采样动量，使用蛙跳法积分轨迹，并应用Metropolis修正，在预烧期后收集样本以计算所需的统计数据。", "answer": "```python\nimport numpy as np\n\nclass DualNumber:\n    \"\"\"\n    Implements a dual number for forward-mode automatic differentiation.\n    A dual number z = (value, grad) stores a value and its gradient vector.\n    \"\"\"\n    def __init__(self, value, grad):\n        self.value = float(value)\n        self.grad = np.asarray(grad, dtype=float)\n\n    def __repr__(self):\n        return f\"DualNumber(value={self.value}, grad={self.grad})\"\n\n    def __add__(self, other):\n        if isinstance(other, DualNumber):\n            return DualNumber(self.value + other.value, self.grad + other.grad)\n        return DualNumber(self.value + other, self.grad)\n\n    def __radd__(self, other):\n        return self.__add__(other)\n\n    def __sub__(self, other):\n        if isinstance(other, DualNumber):\n            return DualNumber(self.value - other.value, self.grad - other.grad)\n        # Case: self - constant\n        return DualNumber(self.value - other, self.grad)\n\n    def __rsub__(self, other):\n        # Case: constant - self\n        return DualNumber(other - self.value, -self.grad)\n\n    def __mul__(self, other):\n        if isinstance(other, DualNumber):\n            # (uv)' = u'v + uv'\n            return DualNumber(self.value * other.value, self.grad * other.value + self.value * other.grad)\n        # Case: self * constant\n        return DualNumber(self.value * other, self.grad * other)\n\n    def __rmul__(self, other):\n        return self.__mul__(other)\n\n    def __truediv__(self, other):\n        if isinstance(other, DualNumber):\n            # (u/v)' = (u'v - uv') / v^2\n            return DualNumber(self.value / other.value, (self.grad * other.value - self.value * other.grad) / (other.value**2))\n        # Case: self / constant\n        return DualNumber(self.value / other, self.grad / other)\n    \n    def __rtruediv__(self, other):\n        # Case: constant / self\n        return DualNumber(other / self.value, (-other * self.grad) / (self.value**2))\n\n    def __pow__(self, power):\n        if not isinstance(power, (int, float)):\n            raise TypeError(\"Power must be a numeric type.\")\n        # (u^n)' = n*u^(n-1)*u'\n        return DualNumber(self.value**power, power * (self.value**(power - 1)) * self.grad)\n    \n    def __neg__(self):\n        return DualNumber(-self.value, -self.grad)\n\ndef hmc_sampler(potential_grad_func, M, epsilon, L, N, B, q0, seed):\n    \"\"\"\n    A general Hamiltonian Monte Carlo sampler.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    q_current = np.copy(q0)\n    d = len(q0)\n    samples = []\n    accepted_count = 0\n    \n    M_inv_diag = 1.0 / M\n    M_sqrt_diag = np.sqrt(M)\n\n    for i in range(N):\n        # 1. Resample momentum\n        p_current = rng.normal(size=d) * M_sqrt_diag\n\n        q = np.copy(q_current)\n        p = np.copy(p_current)\n\n        # Calculate current Hamiltonian\n        U_current, grad_current = potential_grad_func(q)\n        K_current = 0.5 * np.sum(p**2 * M_inv_diag)\n        H_current = U_current + K_current\n\n        # 2. Symplectic integration (Leapfrog)\n        # Initial half-step for momentum\n        p -= 0.5 * epsilon * grad_current\n\n        for _ in range(L - 1):\n            # Full step for position\n            q += epsilon * p * M_inv_diag\n            # Full step for momentum (requires new gradient)\n            _, grad = potential_grad_func(q)\n            p -= epsilon * grad\n        \n        # Final full step for position\n        q += epsilon * p * M_inv_diag\n        # Final half-step for momentum\n        U_proposal, grad_proposal = potential_grad_func(q)\n        p -= 0.5 * epsilon * grad_proposal\n\n        # Proposal state is (q, p)\n        \n        # 3. Metropolis-Hastings correction\n        K_proposal = 0.5 * np.sum(p**2 * M_inv_diag)\n        H_proposal = U_proposal + K_proposal\n\n        # Acceptance probability\n        log_alpha = -H_proposal + H_current\n        \n        if np.log(rng.uniform())  log_alpha:\n            q_current = q\n            accepted_count += 1\n\n        if i >= B:\n            samples.append(q_current)\n\n    acceptance_rate = accepted_count / N if N > 0 else 0.0\n    return np.array(samples), acceptance_rate\n\ndef solve():\n    results = []\n\n    # --- Case A: Correlated Gaussian, happy path ---\n    d_A = 2\n    mu_A = np.array([1.0, -1.0])\n    Sigma_A = np.array([[1.0, 0.8], [0.8, 2.0]])\n    Sigma_A_inv = np.linalg.inv(Sigma_A)\n    M_A = np.array([1.0, 1.0])\n    q0_A = np.array([0.0, 0.0])\n    epsilon_A = 0.15\n    L_A = 20\n    N_A = 1500\n    B_A = 300\n    seed_A = 42\n\n    def potential_grad_gauss_analytic(q):\n        delta = q - mu_A\n        U = 0.5 * delta.T @ Sigma_A_inv @ delta\n        grad = Sigma_A_inv @ delta\n        return U, grad\n\n    def make_gauss_ad_provider(mu, Sigma_inv):\n        d = len(mu)\n        sig_inv_a, sig_inv_b, sig_inv_c = Sigma_inv[0, 0], Sigma_inv[0, 1], Sigma_inv[1, 1]\n\n        def potential_grad_func(q_vec):\n            q_duals = [DualNumber(q_vec[i], np.eye(d)[i]) for i in range(d)]\n            x, y = q_duals\n            mu_x, mu_y = mu\n            delta_x, delta_y = x - mu_x, y - mu_y\n            U_dual = 0.5 * (sig_inv_a * delta_x**2 + sig_inv_c * delta_y**2 + 2 * sig_inv_b * delta_x * delta_y)\n            return U_dual.value, U_dual.grad\n        return potential_grad_func\n\n    potential_grad_gauss_ad = make_gauss_ad_provider(mu_A, Sigma_A_inv)\n\n    # 1. Case A, analytic gradient\n    samples_A_analytic, acc_rate_A_analytic = hmc_sampler(\n        potential_grad_gauss_analytic, M_A, epsilon_A, L_A, N_A, B_A, q0_A, seed_A\n    )\n    results.append(acc_rate_A_analytic)\n\n    # 2. Case A, AD gradient\n    _, acc_rate_A_ad = hmc_sampler(\n        potential_grad_gauss_ad, M_A, epsilon_A, L_A, N_A, B_A, q0_A, seed_A\n    )\n    results.append(acc_rate_A_ad)\n\n    # 3. Case A, sample mean error\n    mean_A_analytic = np.mean(samples_A_analytic, axis=0)\n    error_A = np.linalg.norm(mean_A_analytic - mu_A)\n    results.append(error_A)\n\n    # --- Case B: Correlated Gaussian, large step size ---\n    epsilon_B = 0.9\n    L_B = 25\n    N_B = 800\n    B_B = 200\n    seed_B = 43\n\n    # 4. Case B, analytic gradient\n    _, acc_rate_B_analytic = hmc_sampler(\n        potential_grad_gauss_analytic, M_A, epsilon_B, L_B, N_B, B_B, q0_A, seed_B\n    )\n    results.append(acc_rate_B_analytic)\n\n    # 5. Case B, AD gradient\n    _, acc_rate_B_ad = hmc_sampler(\n        potential_grad_gauss_ad, M_A, epsilon_B, L_B, N_B, B_B, q0_A, seed_B\n    )\n    results.append(acc_rate_B_ad)\n\n    # 6. Case B, difference in acceptance rates\n    diff_acc_rate_B = abs(acc_rate_B_analytic - acc_rate_B_ad)\n    results.append(diff_acc_rate_B)\n\n    # --- Case C: Rosenbrock potential ---\n    M_C = np.array([1.0, 1.0])\n    q0_C = np.array([0.0, 0.0])\n    epsilon_C = 0.02\n    L_C = 30\n    N_C = 1200\n    B_C = 300\n    seed_C = 44\n\n    def potential_grad_rosen_analytic(q):\n        x, y = q\n        U = ((1 - x)**2 + 100 * (y - x**2)**2) / 20.0\n        grad_x = (x - 1 - 200 * x * (y - x**2)) / 10.0\n        grad_y = 10 * (y - x**2)\n        return U, np.array([grad_x, grad_y])\n    \n    def make_rosen_ad_provider():\n        d = 2\n        def potential_grad_func(q_vec):\n            q_duals = [DualNumber(q_vec[i], np.eye(d)[i]) for i in range(d)]\n            x, y = q_duals\n            U_dual = ((1 - x)**2 + 100 * (y - x**2)**2) / 20.0\n            return U_dual.value, U_dual.grad\n        return potential_grad_func\n\n    potential_grad_rosen_ad = make_rosen_ad_provider()\n\n    # 7. Case C, analytic gradient\n    _, acc_rate_C_analytic = hmc_sampler(\n        potential_grad_rosen_analytic, M_C, epsilon_C, L_C, N_C, B_C, q0_C, seed_C\n    )\n    results.append(acc_rate_C_analytic)\n\n    # 8. Case C, AD gradient\n    _, acc_rate_C_ad = hmc_sampler(\n        potential_grad_rosen_ad, M_C, epsilon_C, L_C, N_C, B_C, q0_C, seed_C\n    )\n    results.append(acc_rate_C_ad)\n\n    # 9. Case C, gradient difference at q*=(1,1)\n    q_star = np.array([1.0, 1.0])\n    _, grad_C_analytic = potential_grad_rosen_analytic(q_star)\n    _, grad_C_ad = potential_grad_rosen_ad(q_star)\n    grad_diff_C = np.max(np.abs(grad_C_analytic - grad_C_ad))\n    results.append(grad_diff_C)\n\n    # Final output formatting\n    output_str = \",\".join([f\"{r:.6f}\" for r in results])\n    print(f\"[{output_str}]\")\n\nsolve()\n```", "id": "2399583"}]}