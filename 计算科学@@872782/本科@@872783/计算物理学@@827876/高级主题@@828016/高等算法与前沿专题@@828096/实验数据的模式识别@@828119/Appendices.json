{"hands_on_practices": [{"introduction": "最直接的模式识别形式之一是模板匹配。在高能物理学中，研究人员常常需要在海量数据中寻找特定粒子相互作用的印记，这些印记可以用费曼图来表示。这个练习将这种搜索任务抽象为一个图论问题 [@problem_id:2425431]，你将开发一个算法来寻找一个特定的子图拓扑结构。通过这个过程，你将锻炼自己将物理模型转化为精确计算搜索任务的能力。", "problem": "给定一个简化的、图论形式的表述，用于在模拟散射事件中识别一个特定的费曼图拓扑。每个模拟事件表示为一个有限、简单、无向、节点标记的图。该图由一个对角线为零的对称邻接矩阵 $\\mathbf{A} \\in \\{0,1\\}^{n \\times n}$ 和一个长度为 $n$ 的标签向量 $\\mathbf{L}$ 指定，其中 $\\mathbf{L}[i]$ 是节点 $i$ 的标签。标签从有限集合 $\\{\\mathrm{Z}, \\mathrm{e^+}, \\mathrm{e^-}, \\mu^+, \\mu^-, \\gamma\\}$ 中选取；在程序表示中，这些是 ASCII 字符串 $\\texttt{'Z'}$、$\\texttt{'e+'}$、$\\texttt{'e-'}$、$\\texttt{'mu+'}$、$\\texttt{'mu-'}$ 和 $\\texttt{'gamma'}$。\n\n目标拓扑是一个特定的导出子图，它抽象了一个 s-通道共振：一个具有 5 个顶点的星形图（同构于 $K_{1,4}$），其中心节点标记为 $\\mathrm{Z}$，并与恰好四个叶节点相连，这四个叶节点的标签分别为 $\\mathrm{e^+}$、$\\mathrm{e^-}$、$\\mu^+$ 和 $\\mu^-$，每个标签恰好出现一次。在这个导出子图中，叶节点之间没有边。形式上，一个出现实例是在节点集 $\\{c, \\ell_1, \\ell_2, \\ell_3, \\ell_4\\}$ 上的一个导出子图，满足：\n- $\\mathbf{L}[c] = \\mathrm{Z}$，\n- 在完整图中，$\\deg(c) = 4$，其邻居集恰好为 $\\{\\ell_1, \\ell_2, \\ell_3, \\ell_4\\}$，\n- 多重集 $\\{\\mathbf{L}[\\ell_1], \\mathbf{L}[\\ell_2], \\mathbf{L}[\\ell_3], \\mathbf{L}[\\ell_4]\\}$ 等于 $\\{\\mathrm{e^+}, \\mathrm{e^-}, \\mu^+, \\mu^-\\}$，\n- 对于 $\\{1,2,3,4\\}$ 中所有不同的 $i,j$，有 $\\mathbf{A}[\\ell_i,\\ell_j] = 0$。\n\n你的任务是编写一个完整的程序，该程序：\n- 对每个事件，计算实现这种导出子图的不同中心节点 $c$ 的数量。每个合格的中心节点只计数一次，不考虑其邻居的顺序。\n\n你可以依赖的基本原理：\n- 一个简单、无向图由一个对角线为零的对称 $\\{0,1\\}$ 邻接矩阵表示。\n- 节点 $i$ 的度 $\\deg(i)$ 等于 $\\sum_{j=1}^{n} \\mathbf{A}[i,j]$。\n- 节点集 $S$ 上的导出子图恰好包含原图中节点集 $S$ 内部的所有边。\n\n测试集。使用以下 $6$ 个事件，每个事件由其邻接矩阵 $\\mathbf{A}^{(k)}$ 和标签向量 $\\mathbf{L}^{(k)}$ 指定。\n\n事件 $1$ ($n=5$)。一个有效的以 $\\mathrm{Z}$ 为中心的星形图。\n$$\n\\mathbf{A}^{(1)}=\n\\begin{bmatrix}\n0  1  1  1  1\\\\\n1  0  0  0  0\\\\\n1  0  0  0  0\\\\\n1  0  0  0  0\\\\\n1  0  0  0  0\n\\end{bmatrix},\\quad\n\\mathbf{L}^{(1)}=(\\mathrm{Z}, \\mathrm{e^+}, \\mathrm{e^-}, \\mu^+, \\mu^-).\n$$\n\n事件 $2$ ($n=10$)。两个不相交的有效星形图。\n$$\n\\mathbf{A}^{(2)}=\n\\begin{bmatrix}\n0  1  1  1  1  0  0  0  0  0\\\\\n1  0  0  0  0  0  0  0  0  0\\\\\n1  0  0  0  0  0  0  0  0  0\\\\\n1  0  0  0  0  0  0  0  0  0\\\\\n1  0  0  0  0  0  0  0  0  0\\\\\n0  0  0  0  0  0  1  1  1  1\\\\\n0  0  0  0  0  1  0  0  0  0\\\\\n0  0  0  0  0  1  0  0  0  0\\\\\n0  0  0  0  0  1  0  0  0  0\\\\\n0  0  0  0  0  1  0  0  0  0\n\\end{bmatrix},\\quad\n\\mathbf{L}^{(2)}=(\\mathrm{Z}, \\mathrm{e^+}, \\mathrm{e^-}, \\mu^+, \\mu^-,\n\\mathrm{Z}, \\mathrm{e^+}, \\mathrm{e^-}, \\mu^+, \\mu^-).\n$$\n\n事件 $3$ ($n=5$)。一个以 $\\mathrm{Z}$ 为中心的星形图，但其叶节点多重集不正确（重复的 $\\mathrm{e^+}$ 和缺失的 $\\mu^+$），不应计数。\n$$\n\\mathbf{A}^{(3)}=\n\\begin{bmatrix}\n0  1  1  1  1\\\\\n1  0  0  0  0\\\\\n1  0  0  0  0\\\\\n1  0  0  0  0\\\\\n1  0  0  0  0\n\\end{bmatrix},\\quad\n\\mathbf{L}^{(3)}=(\\mathrm{Z}, \\mathrm{e^+}, \\mathrm{e^-}, \\mathrm{e^+}, \\mu^-).\n$$\n\n事件 $4$ ($n=6$)。一个度为 $5$ 的 $\\mathrm{Z}$ 节点，连接到四个正确的叶节点和一个额外的 $\\gamma$ 邻居；违反了度约束，不应计数。\n$$\n\\mathbf{A}^{(4)}=\n\\begin{bmatrix}\n0  1  1  1  1  1\\\\\n1  0  0  0  0  0\\\\\n1  0  0  0  0  0\\\\\n1  0  0  0  0  0\\\\\n1  0  0  0  0  0\\\\\n1  0  0  0  0  0\n\\end{bmatrix},\\quad\n\\mathbf{L}^{(4)}=(\\mathrm{Z}, \\mathrm{e^+}, \\mathrm{e^-}, \\mu^+, \\mu^-, \\gamma).\n$$\n\n事件 $5$ ($n=5$)。一个以 $\\mathrm{Z}$ 为中心的星形图，但在叶节点之间存在一条额外的边（破坏了导出星形图的条件），不应计数。\n$$\n\\mathbf{A}^{(5)}=\n\\begin{bmatrix}\n0  1  1  1  1\\\\\n1  0  0  1  0\\\\\n1  0  0  0  0\\\\\n1  1  0  0  0\\\\\n1  0  0  0  0\n\\end{bmatrix},\\quad\n\\mathbf{L}^{(5)}=(\\mathrm{Z}, \\mathrm{e^+}, \\mathrm{e^-}, \\mu^+, \\mu^-).\n$$\n\n事件 $6$ ($n=5$)。一个以 $\\gamma$ 为中心的星形图，具有正确的叶节点多重集；违反了中心标签约束，不应计数。\n$$\n\\mathbf{A}^{(6)}=\n\\begin{bmatrix}\n0  1  1  1  1\\\\\n1  0  0  0  0\\\\\n1  0  0  0  0\\\\\n1  0  0  0  0\\\\\n1  0  0  0  0\n\\end{bmatrix},\\quad\n\\mathbf{L}^{(6)}=(\\gamma, \\mathrm{e^+}, \\mathrm{e^-}, \\mu^+, \\mu^-).\n$$\n\n你的程序必须实现由导出子图定义所蕴含的识别规则，并为每个事件 $k \\in \\{1,2,3,4,5,6\\}$ 计算实现目标拓扑的不同中心节点的整数数量 $c^{(k)}$。最终输出必须是一行，包含所有六个计数，以逗号分隔并用方括号括起来，例如，格式应为 $\\texttt{[result1,result2,result3,result4,result5,result6]}$。\n\n本问题不要求物理单位或角度单位。所有答案均为整数。", "solution": "该问题是有效的。这是一个定义明确的图计算模式识别任务，其基础是实验物理数据分析中使用的常规抽象。其条件是精确、完整且逻辑一致的。\n\n任务是为给定的 6 个基于图的事件中的每一个，计算可作为特定导出子图拓扑中心的节点数量。该拓扑模拟了一个 s-通道共振，其中一个 $\\texttt{'Z'}$ 玻色子衰变为四个特定的轻子。假设一个给定事件由一个具有 $n$ 个顶点的图的对称邻接矩阵 $\\mathbf{A}$ 和一个节点标签向量 $\\mathbf{L}$ 表示。算法必须识别并计算满足一组严格标准的独立节点 $c$ 的数量。\n\n解决方案的核心是一个算法，它遍历给定图的每个节点 $i$（其中 $i \\in \\{0, 1, \\dots, n-1\\}$），将每个节点视为一个潜在的中心 $c$。对于每个候选节点 $i$，会执行一系列验证检查。如果任何检查失败，该节点将被取消资格，算法将继续处理下一个候选节点。只有通过所有检查的节点才会使计数器递增。\n\n对候选中心节点 $i$ 的验证步骤如下：\n\n$1$。 **中心标签验证**：第一个条件涉及中心粒子的身份。候选节点 $i$ 的标签 $\\mathbf{L}[i]$ 必须是 $\\texttt{'Z'}$。如果 $\\mathbf{L}[i] \\neq \\texttt{'Z'}$，则节点 $i$ 不是一个有效的中心，无需对该节点进行进一步检查。\n\n$2$。 **度验证**：问题指定了一个具有恰好四个叶节点的星形图拓扑，这意味着中心节点的度必须恰好为 $4$。节点 $i$ 的度计算为 $\\deg(i) = \\sum_{j=0}^{n-1} \\mathbf{A}[i,j]$。如果 $\\deg(i) \\neq 4$，则该节点不合格。\n\n$3$。 **邻居识别**：如果节点 $i$ 的度为 $4$，则识别其四个邻居。设邻居索引集为 $N(i) = \\{\\ell_1, \\ell_2, \\ell_3, \\ell_4\\}$，即满足 $\\mathbf{A}[i,j] = 1$ 的索引 $j$。\n\n$4$。 **叶节点标签多重集验证**：四个邻居必须对应于特定的衰变产物。邻居标签的多重集 $\\{\\mathbf{L}[\\ell_1], \\mathbf{L}[\\ell_2], \\mathbf{L}[\\ell_3], \\mathbf{L}[\\ell_4]\\}$ 必须等于目标多重集 $\\{\\texttt{'e+'}, \\texttt{'e-'}, \\texttt{'mu+'}, \\texttt{'mu-'}\\}$。一个高效的检查方法是对收集到的邻居标签列表进行排序，并将其与一个预先排序的目标标签列表进行比较。如果它们不完全相同，则不满足此条件。\n\n$5$。 **导出子图验证**：指定的拓扑是一个*导出*子图，这意味着叶节点之间不能有任何边相连。这是一个关键约束。对于所有不同的邻居对 $\\ell_j, \\ell_k \\in N(i)$，邻接矩阵中的条目必须为零：$\\mathbf{A}[\\ell_j, \\ell_k] = 0$。此检查需对所有 $\\binom{4}{2} = 6$ 对邻居进行。如果发现任何边（即，对于任何一对邻居，$\\mathbf{A}[\\ell_j, \\ell_k] = 1$），则节点 $i$ 不合格。\n\n当且仅当一个节点 $i$ 成功通过所有这五个连续检查时，它才被计为一个有效的中心。一个事件的总计数是在其相应图中找到的所有此类有效中心的总和。然后对问题陈述中指定的所有 $6$ 个测试事件重复此整个过程。\n\n例如，在事件 1 中，评估节点 0。其标签为 $\\texttt{'Z'}$（通过），度为 $4$（通过），邻居为节点 $\\{1, 2, 3, 4\\}$，它们的标签 $\\{\\texttt{'e+'}, \\texttt{'e-'}, \\texttt{'mu+'}, \\texttt{'mu-'}\\}$ 构成了正确的多重集（通过）。最后，对应于这些邻居的 $\\mathbf{A}$ 的子矩阵是一个零矩阵，因此它们之间不存在边（通过）。因此，节点 0 是一个有效的中心，事件 1 的计数为 $1$。相反，事件 4 未通过度检查，事件 3 未通过叶节点标签检查，事件 5 未通过导出子图检查，导致它们的计数均为 $0$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the graph pattern recognition problem by counting valid Z-boson\n    decay topologies in a series of simulated events.\n    \"\"\"\n    \n    # Define the 6 test cases from the problem statement.\n    test_cases = [\n        # Event 1: n=5, a single valid Z-centered star.\n        (\n            np.array([\n                [0, 1, 1, 1, 1],\n                [1, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0]\n            ]),\n            ['Z', 'e+', 'e-', 'mu+', 'mu-']\n        ),\n        # Event 2: n=10, two disjoint valid stars.\n        (\n            np.array([\n                [0, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 0, 1, 1, 1, 1],\n                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0],\n                [0, 0, 0, 0, 0, 1, 0, 0, 0, 0]\n            ]),\n            ['Z', 'e+', 'e-', 'mu+', 'mu-', 'Z', 'e+', 'e-', 'mu+', 'mu-']\n        ),\n        # Event 3: n=5, incorrect leaf multiset.\n        (\n            np.array([\n                [0, 1, 1, 1, 1],\n                [1, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0]\n            ]),\n            ['Z', 'e+', 'e-', 'e+', 'mu-']\n        ),\n        # Event 4: n=6, center degree is 5.\n        (\n            np.array([\n                [0, 1, 1, 1, 1, 1],\n                [1, 0, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0, 0]\n            ]),\n            ['Z', 'e+', 'e-', 'mu+', 'mu-', 'gamma']\n        ),\n        # Event 5: n=5, extra edge between leaves.\n        (\n            np.array([\n                [0, 1, 1, 1, 1],\n                [1, 0, 0, 1, 0],\n                [1, 0, 0, 0, 0],\n                [1, 1, 0, 0, 0],\n                [1, 0, 0, 0, 0]\n            ]),\n            ['Z', 'e+', 'e-', 'mu+', 'mu-']\n        ),\n        # Event 6: n=5, incorrect center label.\n        (\n            np.array([\n                [0, 1, 1, 1, 1],\n                [1, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0],\n                [1, 0, 0, 0, 0]\n            ]),\n            ['gamma', 'e+', 'e-', 'mu+', 'mu-']\n        )\n    ]\n\n    results = []\n    target_leaf_labels = sorted(['e+', 'e-', 'mu+', 'mu-'])\n\n    for A, L in test_cases:\n        num_nodes = A.shape[0]\n        valid_centers_count = 0\n\n        for i in range(num_nodes):\n            # Let node i be the potential center c.\n            \n            # 1. Check center label: Must be 'Z'.\n            if L[i] != 'Z':\n                continue\n\n            # 2. Check center degree: Must be 4.\n            degree = np.sum(A[i, :])\n            if degree != 4:\n                continue\n\n            # 3. Identify neighbors and check their labels.\n            neighbors = np.where(A[i, :] == 1)[0]\n            \n            leaf_labels = sorted([L[j] for j in neighbors])\n            if leaf_labels != target_leaf_labels:\n                continue\n            \n            # 4. Check induced subgraph condition: No edges between leaves.\n            has_leaf_edge = False\n            for j1_idx in range(4):\n                for j2_idx in range(j1_idx + 1, 4):\n                    n1 = neighbors[j1_idx]\n                    n2 = neighbors[j2_idx]\n                    if A[n1, n2] == 1:\n                        has_leaf_edge = True\n                        break\n                if has_leaf_edge:\n                    break\n            \n            if has_leaf_edge:\n                continue\n\n            # If all checks pass, this is a valid center.\n            valid_centers_count += 1\n            \n        results.append(valid_centers_count)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2425431"}, {"introduction": "从固定的模板匹配过渡到更具统计性的模式识别，许多实验会产生时间序列数据，而数据的底层特性可能会发生突变（例如，传感器性能退化）。本练习将介绍贝叶斯推断 [@problem_id:2425429]，它不仅能检测变化是否发生，还能量化我们对此的确定性，并精确定位最可能的变化时间点。这对于监控和诊断实验系统来说是一项至关重要的技能。", "problem": "您将执行一个模式识别任务，处理综合实验性时间序列数据。该数据模拟了一个物理传感器在发生退化事件前，于稳定运行状态下测量的标量值。数据由一个分段常数均值过程生成，并叠加了加性高斯噪声。这是一个常见且经过充分检验的模型，其合理性由中心极限定理保证。您的目标是基于第一性原理，执行贝叶斯变点检测，以推断是否存在变点，如果存在，其最可能发生的位置。\n\n假设生成模型如下。对于时间索引 $t = 1, 2, \\dots, N$，观测值 $y_t$ 的分布为\n- $y_t \\sim \\mathcal{N}(\\mu_1, \\sigma^2)$ 对 $t \\le \\tau$ 成立，\n- $y_t \\sim \\mathcal{N}(\\mu_2, \\sigma^2)$ 对 $t > \\tau$ 成立，\n\n其中 $\\sigma^2$ 已知，$\\mu_1$ 和 $\\mu_2$ 是未知均值，$\\tau \\in \\{1, 2, \\dots, N-1\\}$ 是一个未知变点。在每个分段内，测量值是独立同分布的。使用以下贝叶斯先验假设：$\\mu_1 \\sim \\mathcal{N}(m_0, s_0^2)$ 和 $\\mu_2 \\sim \\mathcal{N}(m_0, s_0^2)$ 相互独立，且 $\\tau$ 在 $\\{1, \\dots, N-1\\}$ 上均匀分布。为评估是否存在变化，考虑两个模型：$M_1$（如上所述，存在一个变点和两个均值）和 $M_0$（不存在变点，所有 $t$ 共享一个均值），其先验概率为 $p(M_1) = p(M_0) = 1/2$。在 $M_0$ 模型下，$y_t \\sim \\mathcal{N}(\\mu, \\sigma^2)$ 对所有 $t$ 成立，且 $\\mu \\sim \\mathcal{N}(m_0, s_0^2)$。\n\n仅从贝叶斯定理、给定参数下观测值的独立性以及高斯分布的性质出发，推导所需的表达式以实现以下目标：\n- 通过在已知方差 $\\sigma^2$ 的高斯先验下对未知分段均值进行解析积分，计算一个分段的边际似然。\n- 计算整个序列在 $M_0$ 模型下（单分段）和在 $M_1$ 模型下对每个候选变点 $\\tau$ 的边际似然。\n- 通过将模型证据与先验模型概率相结合，计算变点 $\\tau$ 的后验分布 $p(\\tau \\mid \\mathbf{y}, M_1)$（可相差一个乘法常数）、最大后验估计 $\\hat{\\tau}$ 以及模型 $M_1$ 的后验概率 $p(M_1 \\mid \\mathbf{y})$。\n\n算法约束：\n- 当对候选 $\\tau$ 值求和时，必须在对数域中进行计算，以保证对于中等大小的 $N$ 值的计算数值稳定性。\n- 为确保效率，您的实现应使用累积和来计算每个分段的充分统计量（例如样本均值和残差平方和），使得对于任何候选 $\\tau$ 的计算都能在常数时间内完成。\n- 每个测试用例的结果必须是一个包含两个元素的列表 $[\\hat{\\tau}, p(M_1 \\mid \\mathbf{y})]$，其中 $\\hat{\\tau}$ 是集合 $\\{1, \\dots, N-1\\}$ 中的一个整数，$p(M_1 \\mid \\mathbf{y})$ 是一个四舍五入到六位小数的浮点数。\n\n数据模拟协议：\n- 对于每个测试用例，按如下方式生成一个长度为 $N$ 的序列。对于 $t \\le \\tau_{\\text{true}}$，从 $y_t \\sim \\mathcal{N}(\\mu_1, \\sigma^2)$ 中抽样；对于 $t > \\tau_{\\text{true}}$，从 $y_t \\sim \\mathcal{N}(\\mu_2, \\sigma^2)$ 中抽样。如果某个测试用例指定 $\\mu_2 = \\mu_1$，即使提供了 $\\tau_{\\text{true}}$，数据也遵循无变化模型；在这种情况下，正确的推斷应反映出变化证据较弱。为确保可复现性，请为每个测试用例使用下面指定的固定随机种子。\n- 对所有测试用例使用相同的高斯先验：$m_0 = 0$ 且 $s_0 = 1$。\n\n测试套件：\n- 案例A（明显变化，内部）：$N = 200$，$\\tau_{\\text{true}} = 120$，$\\mu_1 = 0$，$\\mu_2 = 0.8$，$\\sigma = 0.3$，种子 $= 2021$。\n- 案例B（早期变化）：$N = 200$，$\\tau_{\\text{true}} = 5$，$\\mu_1 = 0.1$，$\\mu_2 = 0.6$，$\\sigma = 0.4$，种子 $= 2022$。\n- 案例C（晚期变化）：$N = 200$，$\\tau_{\\text{true}} = 195$，$\\mu_1 = 0.2$，$\\mu_2 = -0.5$，$\\sigma = 0.35$，种子 $= 2023$。\n- 案例D（无变化）：$N = 200$，$\\tau_{\\text{true}} = 100$，$\\mu_1 = 0$，$\\mu_2 = 0$，$\\sigma = 0.5$，种子 $= 2024$。\n\n最终输出规范：\n- 对于每个测试用例，计算 $M_1$ 模型下的最大后验估计 $\\hat{\\tau}$，以及通过结合模型证据 $p(\\mathbf{y} \\mid M_1)$ 和 $p(\\mathbf{y} \\mid M_0)$ 与先验模型概率 $p(M_1) = p(M_0) = 1/2$ 得到的后验概率 $p(M_1 \\mid \\mathbf{y})$。\n- 您的程序应生成单行输出，其中包含四个测试用例的结果。结果是一个用方括号括起来的逗号分隔列表，其中每个元素本身是一个双元素列表 $[\\hat{\\tau}, p(M_1 \\mid \\mathbf{y})]$，并且概率值四舍五入到六位小数。例如，一个语法上有效的输出形式为 $[[a,b],[c,d],[e,f],[g,h]]$，逗号后没有空格。\n\n不涉及角度单位。输出不需要物理单位。所有数值答案必须以纯数字形式提供，不带单位符号。", "solution": "所提出的问题是贝叶斯模型选择和参数估计中的一个标准练习。它在科学上基于概率论和贝叶斯推断的原理，问题提法清晰，提供了所有必要的信息，并且表述客观。该问题是有效的。我们接下来进行推导和求解。\n\n任务是推断时间序列中变点的存在和位置。我们有两个竞争模型：模型 $M_0$ 假设没有变点，所有数据点共享一个均值；模型 $M_1$ 假设存在一个变点 $\\tau$，将数据分为具有不同均值的两个分段。我们的目标是计算模型 $M_1$ 下变点的最大后验 (MAP) 估计 $\\hat{\\tau}$，并在给定观测数据 $\\mathbf{y} = (y_1, \\dots, y_N)$ 的情况下，计算模型 $M_1$ 的后验概率 $p(M_1 \\mid \\mathbf{y})$。\n\n我们分析的基础是贝叶斯定理。为了比较模型 $M_0$ 和 $M_1$，我们必须计算它们各自的证据（evidence），即数据在每个模型下的边际似然 $p(\\mathbf{y} \\mid M_0)$ 和 $p(\\mathbf{y} \\mid M_1)$。\n\n首先，我们推导单个数据分段 $\\mathbf{x} = (x_1, \\dots, x_k)$ 的边际似然。该数据段由一个已知方差的高斯分布生成，其未知均值服从高斯先验分布。\n设数据由 $x_t \\sim \\mathcal{N}(\\mu, \\sigma^2)$（$t=1, \\dots, k$）生成。方差 $\\sigma^2$ 已知。均值的先验分布为 $\\mu \\sim \\mathcal{N}(m_0, s_0^2)$。\n该分段的边际似然（或证据）通过对未知均值 $\\mu$ 进行积分得到：\n$$p(\\mathbf{x} \\mid \\sigma^2, m_0, s_0^2) = \\int p(\\mathbf{x} \\mid \\mu, \\sigma^2) p(\\mu \\mid m_0, s_0^2) d\\mu$$\n给定 $\\mu$ 时数据的似然函数为：\n$$p(\\mathbf{x} \\mid \\mu, \\sigma^2) = \\prod_{t=1}^k \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x_t - \\mu)^2}{2\\sigma^2}\\right) = (2\\pi\\sigma^2)^{-k/2} \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{t=1}^k (x_t - \\mu)^2\\right)$$\n$\\mu$ 的先验分布为：\n$$p(\\mu \\mid m_0, s_0^2) = \\frac{1}{\\sqrt{2\\pi s_0^2}} \\exp\\left(-\\frac{(\\mu - m_0)^2}{2s_0^2}\\right)$$\n被积函数中的乘积项为：\n$$p(\\mathbf{x} \\mid \\mu, \\sigma^2) p(\\mu) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{t=1}^k (x_t - \\mu)^2 - \\frac{1}{2s_0^2} (\\mu - m_0)^2\\right)$$\n指数部分是关于 $\\mu$ 的二次函数。通过对 $\\mu$ 配方法，我们可以确定后验分布 $p(\\mu \\mid \\mathbf{x})$ 的参数，该后验分布也是高斯分布 $\\mathcal{N}(m_k, s_k^2)$。后验精度是先验精度与数据精度之和：$1/s_k^2 = 1/s_0^2 + k/\\sigma^2$。后验均值是先验均值和样本均值的加权平均：$m_k = s_k^2 (m_0/s_0^2 + k\\bar{x}/\\sigma^2)$，其中 $\\bar{x} = \\frac{1}{k}\\sum_{t=1}^k x_t$。\n一个未归一化的高斯分布的积分等于其归一化常数。边际似然可以通过恒等式 $p(\\mathbf{x}) = p(\\mathbf{x} \\mid \\mu)p(\\mu)/p(\\mu \\mid \\mathbf{x})$ 求得。更直接的计算可得出对数边际似然的以下表达式：\n$$ \\log p(\\mathbf{x}) = -\\frac{k}{2}\\log(2\\pi\\sigma^2) + \\frac{1}{2}\\log(s_k^2) - \\frac{1}{2}\\log(s_0^2) - \\frac{1}{2\\sigma^2}\\sum_{t=1}^k x_t^2 - \\frac{m_0^2}{2s_0^2} + \\frac{m_k^2}{2s_k^2} $$\n其中\n$$ s_k^2 = \\left(\\frac{1}{s_0^2} + \\frac{k}{\\sigma^2}\\right)^{-1} $$\n$$ m_k = s_k^2 \\left(\\frac{m_0}{s_0^2} + \\frac{k\\bar{x}}{\\sigma^2}\\right) $$\n该表达式使得对任何数据分段的证据进行数值稳定的计算成为可能。\n\n现在，我们将此结果应用于我们的两个模型。\n\n模型 $M_0$（无变化）：整个数据序列 $\\mathbf{y} = (y_1, \\dots, y_N)$ 被视为单个分段。$M_0$ 的证据就是完整序列的边际似然：\n$$ \\log p(\\mathbf{y} \\mid M_0) = \\log p(\\mathbf{y}_{1:N}) $$\n该值使用上述公式并设 $k=N$ 进行计算。\n\n模型 $M_1$（一个变点）：对于给定的变点 $\\tau \\in \\{1, \\dots, N-1\\}$，数据被分为两个独立的分段：$\\mathbf{y}_{1:\\tau}$（长度为 $\\tau$）和 $\\mathbf{y}_{\\tau+1:N}$（长度为 $N-\\tau$）。由于均值 $\\mu_1$ 和 $\\mu_2$ 的先验是独立的，给定 $\\tau$ 的条件证据是两个分段证据的乘积：\n$$ p(\\mathbf{y} \\mid \\tau, M_1) = p(\\mathbf{y}_{1:\\tau}) p(\\mathbf{y}_{\\tau+1:N}) $$\n在对数域中：\n$$ \\log p(\\mathbf{y} \\mid \\tau, M_1) = \\log p(\\mathbf{y}_{1:\\tau}) + \\log p(\\mathbf{y}_{\\tau+1:N}) $$\n模型 $M_1$ 的完整证据通过对所有可能的变点 $\\tau$ 进行边际化得到：\n$$ p(\\mathbf{y} \\mid M_1) = \\sum_{\\tau=1}^{N-1} p(\\mathbf{y} \\mid \\tau, M_1) p(\\tau \\mid M_1) $$\n给定变点的均匀先验 $p(\\tau \\mid M_1) = 1/(N-1)$，上式变为：\n$$ p(\\mathbf{y} \\mid M_1) = \\frac{1}{N-1} \\sum_{\\tau=1}^{N-1} p(\\mathbf{y} \\mid \\tau, M_1) $$\n为避免数值下溢，这个指数和使用 log-sum-exp 技巧进行计算。令 $L_\\tau = \\log p(\\mathbf{y} \\mid \\tau, M_1)$。那么\n$$ \\log p(\\mathbf{y} \\mid M_1) = -\\log(N-1) + \\text{logsumexp}_{\\tau} (L_\\tau) $$\n其中 $\\text{logsumexp}(L) = L_{\\max} + \\log(\\sum e^{L_\\tau - L_{\\max}})$。\n\n计算出模型证据后，我们就可以求得所需的后验量。\n\n模型 $M_1$ 下变点的后验分布由贝叶斯定理给出：\n$$ p(\\tau \\mid \\mathbf{y}, M_1) = \\frac{p(\\mathbf{y} \\mid \\tau, M_1)p(\\tau \\mid M_1)}{p(\\mathbf{y} \\mid M_1)} $$\n由于先验 $p(\\tau \\mid M_1)$ 和分母 $p(\\mathbf{y} \\mid M_1)$ 相对于 $\\tau$ 是常数，后验分布正比于似然：\n$$ p(\\tau \\mid \\mathbf{y}, M_1) \\propto p(\\mathbf{y} \\mid \\tau, M_1) $$\nMAP 估计 $\\hat{\\tau}$ 是使该后验概率最大化的 $\\tau$ 值。这等价于最大化对数似然 $\\log p(\\mathbf{y} \\mid \\tau, M_1)$：\n$$ \\hat{\\tau} = \\arg\\max_{\\tau \\in \\{1, \\dots, N-1\\}} \\log p(\\mathbf{y} \\mid \\tau, M_1) $$\n\n最后，模型 $M_1$ 的后验概率通过将其证据与总证据进行比较来计算：\n$$ p(M_1 \\mid \\mathbf{y}) = \\frac{p(\\mathbf{y} \\mid M_1) p(M_1)}{p(\\mathbf{y} \\mid M_0) p(M_0) + p(\\mathbf{y} \\mid M_1) p(M_1)} $$\n在先验概率相等 $p(M_0) = p(M_1) = 1/2$ 的情况下，该式简化为：\n$$ p(M_1 \\mid \\mathbf{y}) = \\frac{p(\\mathbf{y} \\mid M_1)}{p(\\mathbf{y} \\mid M_0) + p(\\mathbf{y} \\mid M_1)} = \\frac{1}{1 + \\frac{p(\\mathbf{y} \\mid M_0)}{p(\\mathbf{y} \\mid M_1)}} $$\n使用先前推导的对数证据 $\\log p(\\mathbf{y} \\mid M_0)$ 和 $\\log p(\\mathbf{y} \\mid M_1)$，计算如下：\n$$ p(M_1 \\mid \\mathbf{y}) = \\frac{1}{1 + \\exp(\\log p(\\mathbf{y} \\mid M_0) - \\log p(\\mathbf{y} \\mid M_1))} $$\n\n为了高效实现，每个分段的充分统计量——和 $\\sum x_t$ 与平方和 $\\sum x_t^2$——通过使用数据序列 $\\mathbf{y}$ 的预计算累积和，可以在 $O(1)$ 时间内计算出来。这将寻找 $\\hat{\\tau}$ 和模型证据的总复杂度降低到 $O(N)$。", "answer": "```python\nimport numpy as np\nfrom scipy.special import logsumexp\n\ndef log_marginal_likelihood_segment(sum_y, sum_y2, k, m0, s0, sigma):\n    \"\"\"\n    Computes the log marginal likelihood for a single segment of data.\n    \"\"\"\n    if k == 0:\n        return 0.0\n\n    s02 = s0**2\n    sigma2 = sigma**2\n    mean_y = sum_y / k\n\n    # Posterior variance of the mean mu\n    sk2_inv = 1.0 / s02 + k / sigma2\n    sk2 = 1.0 / sk2_inv\n\n    # Posterior mean of mu\n    mk = sk2 * (m0 / s02 + k * mean_y / sigma2)\n\n    # Log marginal likelihood expression from derivation\n    log_p = (-k / 2.0 * np.log(2.0 * np.pi * sigma2) +\n             0.5 * np.log(sk2) -\n             0.5 * np.log(s02) -\n             sum_y2 / (2.0 * sigma2) -\n             m0**2 / (2.0 * s02) +\n             mk**2 / (2.0 * sk2))\n\n    return log_p\n\ndef analyze_sequence(y, m0, s0, sigma):\n    \"\"\"\n    Performs Bayesian change-point analysis on a time series.\n    \"\"\"\n    N = len(y)\n    \n    # Pre-compute cumulative sums for efficient segment statistic calculation\n    # cum_y[j] = sum(y_i) for i from 0 to j-1\n    cum_y = np.concatenate(([0.0], np.cumsum(y)))\n    cum_y2 = np.concatenate(([0.0], np.cumsum(y**2)))\n\n    # --- Evidence for M0 (no change-point) ---\n    sum_y_total = cum_y[N] - cum_y[0]\n    sum_y2_total = cum_y2[N] - cum_y2[0]\n    log_evidence_m0 = log_marginal_likelihood_segment(sum_y_total, sum_y2_total, N, m0, s0, sigma)\n\n    # --- Likelihoods for M1 (one change-point) for each tau ---\n    log_p_tau = np.zeros(N - 1)\n    \n    # tau is the change-point index from 1 to N-1\n    # a change at tau means y[:tau] is segment 1, y[tau:] is segment 2\n    for tau in range(1, N):\n        # Segment 1: y[0...tau-1] (length tau)\n        k1 = tau\n        sum_y1 = cum_y[tau] - cum_y[0]\n        sum_y2_1 = cum_y2[tau] - cum_y2[0]\n        log_p1 = log_marginal_likelihood_segment(sum_y1, sum_y2_1, k1, m0, s0, sigma)\n\n        # Segment 2: y[tau...N-1] (length N-tau)\n        k2 = N - tau\n        sum_y2 = cum_y[N] - cum_y[tau]\n        sum_y2_2 = cum_y2[N] - cum_y2[tau]\n        log_p2 = log_marginal_likelihood_segment(sum_y2, sum_y2_2, k2, m0, s0, sigma)\n\n        log_p_tau[tau - 1] = log_p1 + log_p2\n\n    # --- MAP estimate for tau under M1 ---\n    # np.argmax returns 0-based index. tau is 1-based.\n    hat_tau = np.argmax(log_p_tau) + 1\n\n    # --- Evidence for M1 ---\n    # Marginalize over tau using uniform prior p(tau)=1/(N-1)\n    # log p(y|M1) = log( sum_tau p(y|tau,M1) * p(tau|M1) )\n    #             = log( sum_tau exp(log_p_tau) * 1/(N-1) )\n    #             = logsumexp(log_p_tau) - log(N-1)\n    log_evidence_m1 = logsumexp(log_p_tau) - np.log(N - 1)\n\n    # --- Posterior probability of M1 ---\n    # p(M1|y) = 1 / (1 + p(y|M0)/p(y|M1))\n    # p(y|M0)/p(y|M1) = exp(log_evidence_m0 - log_evidence_m1)\n    log_bayes_factor_01 = log_evidence_m0 - log_evidence_m1\n    p_m1_posterior = 1.0 / (1.0 + np.exp(log_bayes_factor_01))\n\n    return [int(hat_tau), round(p_m1_posterior, 6)]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and produce the final output.\n    \"\"\"\n    test_cases = [\n        {'N': 200, 'tau_true': 120, 'mu1': 0.0, 'mu2': 0.8, 'sigma': 0.3, 'seed': 2021},\n        {'N': 200, 'tau_true': 5, 'mu1': 0.1, 'mu2': 0.6, 'sigma': 0.4, 'seed': 2022},\n        {'N': 200, 'tau_true': 195, 'mu1': 0.2, 'mu2': -0.5, 'sigma': 0.35, 'seed': 2023},\n        {'N': 200, 'tau_true': 100, 'mu1': 0.0, 'mu2': 0.0, 'sigma': 0.5, 'seed': 2024},\n    ]\n\n    # Shared prior parameters for all cases\n    m0 = 0.0\n    s0 = 1.0\n\n    results = []\n    for case in test_cases:\n        # Generate synthetic data\n        rng = np.random.default_rng(case['seed'])\n        y = np.zeros(case['N'])\n        seg1_len = case['tau_true']\n        seg2_len = case['N'] - case['tau_true']\n        \n        y[:seg1_len] = rng.normal(loc=case['mu1'], scale=case['sigma'], size=seg1_len)\n        if seg2_len > 0:\n            y[seg1_len:] = rng.normal(loc=case['mu2'], scale=case['sigma'], size=seg2_len)\n\n        # Perform analysis\n        result = analyze_sequence(y, m0, s0, case['sigma'])\n        results.append(result)\n\n    # Format output as specified\n    # e.g., [[120,0.999999],[5,0.987654],...]\n    output_str = '['\n    for i, res in enumerate(results):\n        output_str += f'[{res[0]},{res[1]}]'\n        if i  len(results) - 1:\n            output_str += ','\n    output_str += ']'\n    \n    print(output_str)\n\nsolve()\n\n```", "id": "2425429"}, {"introduction": "最后，我们将探索由集体行为产生的“涌现模式”。物理学中一些最有趣的模式并非预先定义，而是由简单组件的集体行为涌现出来的。这个练习使用森林火灾模拟（一个逾渗模型）来寻找一个“临界点” [@problem_id:2425393]，即一个局部火灾能够蔓延到整个系统的临界植被密度。你将结合蒙特卡洛模拟和图像分析技术来识别这种涌现的大尺度结构模式，从而深入理解相变和临界现象。", "problem": "您将通过将每个模拟晶格视为二值图像，并使用连通分量标记来评估火势是否能贯穿系统，从而为一个森林火灾渗流模型实现一个可复现的临界植被密度蒙特卡洛（MC）估计器。森林是一个 $N \\times N$ 的方形晶格。每个晶格位点以概率 $p$ 独立地被植被覆盖，以概率 $1-p$ 为空。火势被假定为通过最近邻接触（四邻域冯·诺依曼连通性）在相邻的植被位点之间确定性地蔓延。火势能否从森林的一侧穿越到另一侧的问题，等同于植被位点的二值图像是否包含一个同时接触到图像左右边界的连通分量。对于固定的晶格尺寸 $N$，临界密度 $p_c$ 被定义为左右贯穿概率约等于 $1/2$ 时的值。\n\n基本原理：\n- 每个位点的占据情况是一个独立的伯努利随机变量，其成功（植被覆盖）概率为 $p$。\n- 二值图像中的一个连通分量是指一个位点的极大集合，其中每个位点都可以通过一条由最近邻（四邻域）位点构成的路径从另一个位点到达。\n- 贯穿事件定义为存在至少一个与晶格的最左列和最右列都相交的连通分量。\n- 在给定 $p$ 的情况下，有限尺寸 $N$ 的贯穿概率是一个指示随机变量的期望。如果抽样的晶格是贯穿的，该变量为 $1$，否则为 $0$。MC估计器是该指示变量在多次独立试验中的样本均值，根据大数定律，它会收敛到真实概率。\n\n实现任务：\n1. 对于给定的 $N$、$p$ 和整数种子 $s$，通过对 $[0,1)$ 上的独立同分布均匀随机数进行阈值处理，生成 $T$ 个独立的二值图像。将小于 $p$ 的值视为植被位点（$1$），否则为空（$0$）。每个图像是一个 $N \\times N$ 的数组。\n2. 对于每个图像，使用基于四邻域连通性的连通分量标记算法来标记植被位点簇。当且仅当存在一个已标记的连通分量同时接触到左边界（$x=0$）和右边界（$x=N-1$）时，宣布该图像为贯穿图像。计算MC估计值 $\\hat{\\pi}_N(p)$，即贯穿图像所占的比例。\n3. 对于一个固定的 $N$，使用对 $p$ 的二分法在区间 $[p_{\\mathrm{lo}}, p_{\\mathrm{hi}}]$ 内估计 $p_c(N)$，使得 $\\hat{\\pi}_N(p_{\\mathrm{lo}})  1/2$ 且 $\\hat{\\pi}_N(p_{\\mathrm{hi}}) \\ge 1/2$。在每个二分步骤中，使用相同的种子 $s$ 和试验次数 $T$ 来评估 $\\hat{\\pi}_N(p)$，并根据 $\\hat{\\pi}_N(p) \\ge 1/2$ 是否成立来更新区间。当区间宽度小于指定的容差 $\\varepsilon$ 时终止，并报告中点作为 $p_c(N)$ 的估计值。\n4. 为确保在二分法过程中MC估计值对 $p$ 的可复现性和单调性，对于一个给定的 $N$，在所有不同 $p$ 值下调用贯穿概率函数时都使用相同的基础种子 $s$，这样每次试验都使用相同的均匀随机数，只有阈值发生改变。\n\n不涉及角度单位。不涉及物理单位。所有概率必须以小数形式报告，而非百分比。\n\n测试套件和要求输出：\n- 测试用例1：使用 $T=64$，$p_{\\mathrm{lo}}=0.3$，$p_{\\mathrm{hi}}=0.8$，$\\varepsilon=10^{-3}$ 和种子 $s=12345$ 估计 $N=32$ 时的 $p_c$。输出一个四舍五入到4位小数的浮点数。\n- 测试用例2：使用 $T=64$，$p_{\\mathrm{lo}}=0.3$，$p_{\\mathrm{hi}}=0.8$，$\\varepsilon=10^{-3}$ 和种子 $s=24680$ 估计 $N=64$ 时的 $p_c$。输出一个四舍五入到4位小数的浮点数。\n- 测试用例3：在 $p=0.2$、$N=64$、$T=200$ 和种子 $s=98765$ 的条件下，计算贯穿概率 $\\hat{\\pi}_N(p)$。输出一个四舍五入到4位小数的浮点数。\n- 测试用例4：在 $p=0.8$、$N=64$、$T=200$ 和种子 $s=54321$ 的条件下，计算贯穿概率 $\\hat{\\pi}_N(p)$。输出一个四舍五入到4位小数的浮点数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔的结果列表，按测试用例1到4的顺序排列，每个结果都四舍五入到4位小数。例如，一个有效的输出格式是 `[0.5925,0.5929,0.0125,0.9975]`。", "solution": "所呈现的问题是一个定义明确的计算统计物理学练习，特别关注渗流现象。它是有效的，并具备严谨求解所需的所有要素。我们的任务是为一个有限的 $N \\times N$ 离散晶格数值估计临界植被密度 $p_c$，这是一个基础模型，用于描述诸如多孔介质中的流体流动、流行病传播以及本案例中的森林火灾等现象。该估计将使用蒙特卡洛方法，并结合连通分量分析和二分搜索算法来执行。\n\n问题的核心在于估计贯穿概率 $\\pi_N(p)$，即一个尺寸为 $N \\times N$、植被密度为 $p$ 的随机生成的森林，包含一条连接左边界和右边界的连续植被位点路径的概率。临界密度 $p_c(N)$ 定义为使该概率约等于 $1/2$ 的密度。\n\n让我们将流程形式化。\n\n1.  **晶格生成与蒙特卡洛方法**\n\n森林表示为一个 $N \\times N$ 的网格 $\\mathcal{L}$。该网格上的每个位点 $(i, j)$（其中 $i, j \\in \\{0, 1, \\dots, N-1\\}$）要么被植被覆盖，要么为空。位点的状态由一个伯努利随机变量 $\\sigma_{i,j}$ 决定，其成功（植被覆盖）的概率为 $p$。因此，$P(\\sigma_{i,j}=1) = p$ 且 $P(\\sigma_{i,j}=0) = 1-p$。所有位点的状态都是独立的。\n\n为了估计贯穿概率 $\\pi_N(p)$，我们采用蒙特卡洛模拟。我们生成 $T$ 个独立的晶格实现，称之为试验。对于每次试验 $k \\in \\{1, \\dots, T\\}$，我们生成一个 $N \\times N$ 的占据数矩阵。我们为每次试验定义一个指示变量 $I_k(p)$：\n$$\nI_k(p) = \\begin{cases} 1  \\text{如果试验 } k \\text{ 产生了一个贯穿构型} \\\\ 0  \\text{否则} \\end{cases}\n$$\n贯穿概率的蒙特卡洛估计器 $\\hat{\\pi}_N(p)$ 是这个指示变量在 $T$ 次试验中的样本平均值：\n$$\n\\hat{\\pi}_N(p) = \\frac{1}{T} \\sum_{k=1}^T I_k(p)\n$$\n根据大数定律，当试验次数 $T \\to \\infty$ 时，该估计器收敛于真实的贯穿概率 $\\pi_N(p)$。\n\n2.  **贯穿簇检测**\n\n为了确定一个给定的晶格构型是否贯穿，我们必须识别出植被位点的连通簇。一个簇是一组植被位点，其中簇内的任意一个位点都可以通过一条由相邻植被位点构成的路径到达簇内的任何其他位点。邻接关系由四邻域（冯·诺依曼，von Neumann）规则定义：一个位点 $(i, j)$ 与其在 $(i\\pm1, j)$ 和 $(i, j\\pm1)$ 的邻居相邻，前提是这些邻居在晶格边界内。\n\n这个任务在算法上等同于二值图像中的连通分量标记（CCL）。我们将使用一个成熟的CCL算法，该算法为每个不同的簇分配一个唯一的整数标签。该算法处理由植被位点（值为$1$）和背景（值为$0$）组成的二值晶格。标记后，我们得到一个新的 $N \\times N$ 整数矩阵，其中所有属于同一簇的位点共享相同的正整数标签，而空位点标记为$0$。\n\n如果存在至少一个簇同时存在于最左列（$j=0$）和最右列（$j=N-1$），则发生贯穿事件。我们可以通过以下方式验证：\n-   提取第 $0$ 列中存在的非零唯一标签集合，记为 $\\mathcal{C}_{\\text{left}}$。\n-   提取第 $N-1$ 列中存在的非零唯一标签集合，记为 $\\mathcal{C}_{\\text{right}}$。\n-   当且仅当这两个集合的交集非空时，晶格发生贯穿：$\\mathcal{C}_{\\text{left}} \\cap \\mathcal{C}_{\\text{right}} \\neq \\emptyset$。\n\n3.  **为二分搜索保证可复现性和单调性**\n\n临界密度 $p_c(N)$ 由条件 $\\pi_N(p_c(N)) \\approx 1/2$ 定义。为了找到 $p_c$，我们必须求解关于 $p$ 的方程 $\\hat{\\pi}_N(p) - 1/2 = 0$。由于 $\\hat{\\pi}_N(p)$ 是一个阶跃函数（因为它是指示变量之和），只要该函数是单调的，二分搜索就是一种合适的方法。\n\n标准的蒙特卡洛估计器 $\\hat{\\pi}_N(p)$ 在有限的 $T$ 下，如果对不同 $p$ 的每次评估都使用独立的随机数，则不保证是单调的。为了强制实现单调性，我们使用同一组底层随机数。我们使用一个固定的种子 $s$ 一次性生成一个大小为 $T \\times N \\times N$ 的大型随机数数组 $U_{k,i,j} \\sim \\mathcal{U}[0,1)$。对于任何给定的概率阈值 $p$，通过设置 $\\sigma_{k,i,j} = 1$（如果 $U_{k,i,j}  p$）和 $\\sigma_{k,i,j} = 0$（否则）来生成一个晶格构型。\n\n通过这种构造，如果我们考虑两个概率 $p_1$ 和 $p_2$ 且 $p_1  p_2$，那么对应于 $p_1$ 的植被位点集合是对应于 $p_2$ 的植被位点集合的子集。因此，如果一个簇在 $p_1$ 时贯穿，那么它在 $p_2$ 时也必定贯穿。这保证了我们的估计器 $\\hat{\\pi}_N(p)$ 是一个关于 $p$ 的非递减函数，这是二分算法可靠工作的一个必要条件。\n\n4.  **用于 $p_c(N)$ 的二分算法**\n\n二分法按以下步骤进行：\n-   选择一个初始区间 $[p_{\\mathrm{lo}}, p_{\\mathrm{hi}}]$，使得 $\\hat{\\pi}_N(p_{\\mathrm{lo}})  1/2$ 且 $\\hat{\\pi}_N(p_{\\mathrm{hi}}) \\ge 1/2$。\n-   算法迭代地细化这个区间：\n    1.  计算中点 $p_{\\mathrm{mid}} = (p_{\\mathrm{lo}} + p_{\\mathrm{hi}})/2$。\n    2.  使用固定的随机数集评估贯穿概率 $\\hat{\\pi}_N(p_{\\mathrm{mid}})$。\n    3.  如果 $\\hat{\\pi}_N(p_{\\mathrm{mid}})  1/2$，则临界点必定位于区间的上半部分。我们更新下界：$p_{\\mathrm{lo}} \\leftarrow p_{\\mathrm{mid}}$。\n    4.  否则，如果 $\\hat{\\pi}_N(p_{\\mathrm{mid}}) \\ge 1/2$，则临界点在下半部分。我们更新上界：$p_{\\mathrm{hi}} \\leftarrow p_{\\mathrm{mid}}$。\n-   重复此过程，直到区间宽度 $p_{\\mathrm{hi}} - p_{\\mathrm{lo}}$ 小于指定的容差 $\\varepsilon$。\n-   $p_c(N)$ 的最终估计值是最终区间的中点 $(p_{\\mathrm{lo}} + p_{\\mathrm{hi}})/2$。\n\n这套完整的方法论使得能够对指定的有限系统的临界渗流阈值进行可复现且科学可靠的估计。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.ndimage import label\n\ndef _check_span(lattice: np.ndarray) -> bool:\n    \"\"\"\n    Checks for a left-right spanning cluster in a single binary lattice.\n    A spanning cluster is a connected component of 1s that touches both\n    the first and last columns of the lattice.\n    \"\"\"\n    if not np.any(lattice):\n        return False\n        \n    # Define 4-neighbor (von Neumann) connectivity\n    structure = np.array([[0, 1, 0], [1, 1, 1], [0, 1, 0]])\n    \n    # Perform connected-component labeling\n    labeled_lattice, num_labels = label(lattice, structure=structure)\n    \n    # If there are no vegetated clusters, it cannot span\n    if num_labels == 0:\n        return False\n\n    # Get unique labels on left and right boundaries\n    # The `_` is to handle the case where a boundary is all 0s\n    left_labels = np.unique(labeled_lattice[:, 0])\n    right_labels = np.unique(labeled_lattice[:, -1])\n\n    # Remove background label (0), which corresponds to empty sites\n    left_labels = left_labels[left_labels != 0]\n    right_labels = right_labels[right_labels != 0]\n    \n    # If either boundary has no clusters, no spanning is possible\n    if left_labels.size == 0 or right_labels.size == 0:\n        return False\n\n    # Check for any common labels between the left and right boundaries\n    return np.intersect1d(left_labels, right_labels, assume_unique=True).size > 0\n\ndef compute_spanning_prob(N: int, p: float, T: int, seed: int) -> float:\n    \"\"\"\n    Computes spanning probability via Monte Carlo simulation for given parameters.\n    Each trial uses an independent set of random numbers.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    spanning_count = 0\n    for _ in range(T):\n        # Generate one lattice configuration\n        lattice = rng.random((N, N))  p\n        if _check_span(lattice):\n            spanning_count += 1\n    return spanning_count / T\n\ndef estimate_pc(N: int, T: int, p_lo: float, p_hi: float, epsilon: float, seed: int) -> float:\n    \"\"\"\n    Estimates the critical probability p_c using a bisection search.\n    Crucially, it uses the same set of base random numbers for all evaluations\n    of the spanning probability to ensure monotonicity of the estimator with p.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    # Generate one large block of random numbers to be used for all p values\n    base_random_numbers = rng.random((T, N, N))\n    \n    # Internal helper function that computes spanning probability for a given p\n    # using the pre-generated random numbers.\n    def _get_pi_monotonic(p_val: float) -> float:\n        # Create T lattices by thresholding the base random numbers\n        lattices = base_random_numbers  p_val\n        spanning_count = 0\n        for i in range(T):\n            if _check_span(lattices[i, :, :]):\n                spanning_count += 1\n        return spanning_count / T\n\n    # Bisection search loop\n    current_p_lo, current_p_hi = p_lo, p_hi\n    while (current_p_hi - current_p_lo) >= epsilon:\n        p_mid = (current_p_lo + current_p_hi) / 2.0\n        pi_mid = _get_pi_monotonic(p_mid)\n        \n        if pi_mid  0.5:\n            current_p_lo = p_mid\n        else:\n            current_p_hi = p_mid\n            \n    return (current_p_lo + current_p_hi) / 2.0\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'type': 'pc', 'params': {'N': 32, 'T': 64, 'p_lo': 0.3, 'p_hi': 0.8, 'epsilon': 1e-3, 'seed': 12345}},\n        {'type': 'pc', 'params': {'N': 64, 'T': 64, 'p_lo': 0.3, 'p_hi': 0.8, 'epsilon': 1e-3, 'seed': 24680}},\n        {'type': 'pi', 'params': {'N': 64, 'p': 0.2, 'T': 200, 'seed': 98765}},\n        {'type': 'pi', 'params': {'N': 64, 'p': 0.8, 'T': 200, 'seed': 54321}},\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'pc':\n            result = estimate_pc(**case['params'])\n        elif case['type'] == 'pi':\n            result = compute_spanning_prob(**case['params'])\n        results.append(result)\n\n    # Format results to 4 decimal places for the final output\n    formatted_results = [f\"{res:.4f}\" for res in results]\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\n# Execute the solution\nsolve()\n```", "id": "2425393"}]}