## 引言
在计算物理中，我们使用的模型是对复杂现实世界的高度简化。从预测行星轨道到模拟材料属性，这些模型都依赖于我们无法完美知晓的参数和假设。因此，任何严谨的科学探索都不能满足于提供单一的“最佳”预测值；它必须同时量化该预测的可信度。[不确定性量化](@entry_id:138597)（Uncertainty Quantification, UQ）正是应对这一挑战的科学框架，它使我们能够从“这个模型的预测是什么？”转向“我们对这个预测有多大信心？”这一更深层次的问题。

本文旨在为计算物理领域的学生和研究者提供一条从理论到实践的清晰学习路径。我们将系统性地解决从单一确定性预测到概率性理解的认知跨越。在“原理与机制”一章中，我们将深入探讨不确定性的根本来源，并建立[前向传播](@entry_id:193086)和逆向[贝叶斯推断](@entry_id:146958)的核心数学工具。接着，在“应用与跨学科连接”一章中，我们将看到这些理论如何在[光学工程](@entry_id:272219)、天体物理学、量子力学等多样化领域中发挥作用，展示UQ作为解决实际问题的强大能力。最后，通过“动手实践”部分提供的具体计算问题，你将有机会亲手应用所学知识，巩固和深化理解。

通过这一结构化的学习过程，本文将帮助你掌握不确定性量化的基本思想和关键技术，从而以更全面、更严谨的视角来构建、评估和信任你的计算模型。

## 原理与机制

在计算物理领域，我们构建的模型本质上是对复杂现实的简化。无论是描述行星运动的方程，还是模拟材料特性的[本构关系](@entry_id:186508)，都包含我们无法完美确定的参数和假设。因此，任何严谨的科学探究不仅需要提供预测值，还必须量化这些预测的不确定性。本章将系统地阐述[不确定性量化](@entry_id:138597)的核心原理与机制，从[不确定性的来源](@entry_id:164809)与传播，到用于从数据中学习参数的贝叶斯方法，为理解和应用不确定性量化提供坚实的理论基础。

### [不确定性的来源](@entry_id:164809)

在深入探讨量化方法之前，我们首先需要识别[计算模型](@entry_id:152639)中不确定性的主要来源。这些来源可以大致分为几类：

**[参数不确定性](@entry_id:264387) (Parameter Uncertainty)** 是指模型输入参数的精确值未知。这些参数可能是从实验中测量得到的物理常数（如引力常数 $G$），也可能是描述特定系统状态的变量（如[热力学](@entry_id:141121)中的温度 $T$）。由于测量误差或内在变异性，这些参数最好用[概率分布](@entry_id:146404)来描述，而非单一的确定值。

**[模型形式不确定性](@entry_id:752061) (Model-Form Uncertainty)**，也称为结构不确定性，源于我们用来描述物理现象的数学模型本身是一种近似。对于同一现象，可能存在多个理论上合理但形式不同的模型。例如，在描述材料的光学响应时，我们可能会在简单的 **德鲁德模型 (Drude model)** 和更复杂的 **[洛伦兹模型](@entry_id:144803) (Lorentz model)** 之间选择 [@problem_id:2448347]。[德鲁德模型](@entry_id:141896)将传导电子视为[自由电子气](@entry_id:145649)体，而[洛伦兹模型](@entry_id:144803)则考虑了束缚电子的共振吸收。这两种模型对介电函数 $\varepsilon_r(\omega)$ 的预测不同：

德鲁德模型： $\varepsilon_D(\omega) = \varepsilon_\infty - \frac{\omega_p^2}{\omega^2 + i \gamma \omega}$

[洛伦兹模型](@entry_id:144803)： $\varepsilon_L(\omega) = \varepsilon_\infty + \frac{\Delta\varepsilon\,\omega_0^2}{\omega_0^2 - \omega^2 - i \Gamma \omega}$

其中各项参数代表了不同的物理效应。如果我们认为这两种模型在特定应用场景下“同样可信”，那么它们预测结果的差异就构成了[模型形式不确定性](@entry_id:752061)。一种简单的量化方法是，将这两个模型的预测（例如，对[反射率](@entry_id:155393) $R$ 的预测 $R_D$ 和 $R_L$）视为一个集合，并计算其[标准差](@entry_id:153618) $\sigma_R = \frac{1}{2} |R_D - R_L|$ [@problem_id:2448347]。这种方法承认没有任何一个模型是完全“正确”的，而是通过评估模型集合的离散程度来量化我们对“正确”物理描述的未知程度。

**初始与边界条件不确定性 (Initial/Boundary Condition Uncertainty)** 在研究动力系统（即随[时间演化](@entry_id:153943)的系统）时尤为重要。无论是天体物理学中的多体问题，还是[流体力学](@entry_id:136788)中的[湍流模拟](@entry_id:187401)，系统的初始状态（如位置、速度）都无法被无限精确地测量。这种微小的不确定性如何在系统中演化，是[不确定性量化](@entry_id:138597)研究的核心问题之一。

### 前向[不确定性传播](@entry_id:146574)：从输入到输出

一旦我们用[概率分布](@entry_id:146404)描述了输入的不确定性，接下来的任务就是“[前向传播](@entry_id:193086)”这些不确定性，以确定模型输出的不确定性。

#### 线性[误差传播](@entry_id:147381)（[德尔塔方法](@entry_id:276272)）

最直接的方法之一是 **线性[误差传播](@entry_id:147381) (Linear Error Propagation)**，也称为 **[德尔塔方法](@entry_id:276272) (Delta Method)**。该方法基于一个核心假设：输出量 $Y$ 是输入变量 $X_1, X_2, \dots, X_n$ 的一个足够平滑的函数 $f(X_1, \dots, X_n)$，并且输入变量的波动（[标准差](@entry_id:153618)）相对于其均值来说足够小。在这种情况下，我们可以用函数在输入均值点 $(\mu_1, \dots, \mu_n)$ 附近的一阶泰勒展开来近似函数本身。

由此，输出量 $Y$ 的[方差](@entry_id:200758) $\sigma_Y^2$ 可以近似为：
$$
\sigma_Y^2 \approx \sum_{i=1}^n \sum_{j=1}^n \left. \frac{\partial f}{\partial X_i} \right|_{\boldsymbol{\mu}} \left. \frac{\partial f}{\partial X_j} \right|_{\boldsymbol{\mu}} \mathrm{Cov}(X_i, X_j)
$$
其中，$\frac{\partial f}{\partial X_i}$ 是函数 $f$ 对变量 $X_i$ 的[偏导数](@entry_id:146280)，在所有输入的均值 $\boldsymbol{\mu}$ 处求值。$\mathrm{Cov}(X_i, X_j)$ 是输入 $X_i$ 和 $X_j$ 的协[方差](@entry_id:200758)。如果输入变量是相互独立的，则交叉项 ($i \neq j$) 为零，公式简化为[方差](@entry_id:200758)的加权和。

让我们通过一个具体的物理示例来理解这个公式。考虑一个[卡诺热机](@entry_id:140598)，其效率 $\eta = 1 - T_C/T_H$ 取决于冷热两个热源的温度 $T_C$ 和 $T_H$ [@problem_id:2448350]。假设这两个温度由于环境波动而是[随机变量](@entry_id:195330)，它们的均值分别为 $\mu_C$ 和 $\mu_H$，[标准差](@entry_id:153618)为 $\sigma_C$ 和 $\sigma_H$，并且它们之间存在相关性，[相关系数](@entry_id:147037)为 $\rho$。效率 $\eta$ 的[方差](@entry_id:200758) $\sigma_\eta^2$ 是多少？

首先，我们计算 $\eta$ 对 $T_C$ 和 $T_H$ 的偏导数，并在均值点求值：
$$
\frac{\partial \eta}{\partial T_C} = -\frac{1}{T_H} \quad \implies \quad \left.\frac{\partial \eta}{\partial T_C}\right|_{(\mu_C, \mu_H)} = -\frac{1}{\mu_H}
$$
$$
\frac{\partial \eta}{\partial T_H} = \frac{T_C}{T_H^2} \quad \implies \quad \left.\frac{\partial \eta}{\partial T_H}\right|_{(\mu_C, \mu_H)} = \frac{\mu_C}{\mu_H^2}
$$
协[方差](@entry_id:200758)为 $\mathrm{Cov}(T_C, T_H) = \rho \sigma_C \sigma_H$。将这些代入通用公式，我们得到 $\eta$ 的[方差](@entry_id:200758)：
$$
\sigma_\eta^2 \approx \left(-\frac{1}{\mu_H}\right)^2 \sigma_C^2 + \left(\frac{\mu_C}{\mu_H^2}\right)^2 \sigma_H^2 + 2 \left(-\frac{1}{\mu_H}\right) \left(\frac{\mu_C}{\mu_H^2}\right) \rho \sigma_C \sigma_H
$$
这个例子清晰地展示了如何系统地计算一个[多变量函数](@entry_id:145643)的输出不确定性，并正确地包含了输入变量之间相关性的影响。

输入相关性的影响可能不总是直观的。考虑一个[悬臂梁](@entry_id:174096)的[共振频率](@entry_id:265742) $f_1 = C \sqrt{E/\rho}$，其中 $C$ 是几何常数，杨氏模量 $E$ 和密度 $\rho$ 是不确定参数 [@problem_id:2448344]。$E$ 的增加会提高频率，而 $\rho$ 的增加会降低频率。[偏导数](@entry_id:146280) $\frac{\partial f_1}{\partial E}$ 为正，而 $\frac{\partial f_1}{\partial \rho}$ 为负。在这种情况下，协[方差](@entry_id:200758)项 $2 (\frac{\partial f_1}{\partial E})(\frac{\partial f_1}{\partial \rho})\mathrm{Cov}(E, \rho)$ 的符号与 $\mathrm{Cov}(E, \rho)$ 的符号相反。这意味着，如果 $E$ 和 $\rho$ 是正相关的（例如，更坚固的材料通常也更密），它们的波动对频率的影响会部分抵消，从而 *减小* 最终频率的不确定性。反之，如果它们是负相关的，则会加剧不确定性。这个例子揭示了理解输入相关性及其与模型灵敏度相互作用的重要性。

#### 线性传播的局限性

尽管线性[误差传播](@entry_id:147381)方法简单实用，但其有效性依赖于函数在均值点附近表现良好。当模型高度[非线性](@entry_id:637147)，或我们关心的点恰好是系统的“[临界点](@entry_id:144653)”时，该方法可能会完全失效。

一个经典的例子是结构力学中的[欧拉屈曲](@entry_id:262697)问题 [@problem_id:2448407]。一根细长的弹性柱在受到轴向压缩载荷 $\lambda$ 时，当载荷小于临界值 $\lambda_c$ 时，柱子保持笔直，其横向挠度幅值 $a(\lambda)=0$。当载荷超过 $\lambda_c$ 时，柱子发生屈曲，挠度幅值变为 $a(\lambda) = \sqrt{(\lambda - \lambda_c)/\gamma}$。这个在 $\lambda = \lambda_c$ 处的行为被称为 **[超临界叉式分岔](@entry_id:269920)**。

现在，假设施加的载荷 $\Lambda$ 是一个[随机变量](@entry_id:195330)，其均值恰好是[临界载荷](@entry_id:193340) $\mu_\Lambda = \lambda_c$，并具有很小的[标准差](@entry_id:153618) $\sigma$。如果我们尝试应用线性[误差传播](@entry_id:147381)来估计挠度 $A = a(\Lambda)$ 的[方差](@entry_id:200758)，我们会遇到一个根本性问题：函数 $a(\lambda)$ 在 $\lambda = \lambda_c$ 处是不可微的。它的左导数为0，而右导数趋于无穷大。

如果天真地使用屈曲前分支的导数 (0)，线性方法会预测输出[方差](@entry_id:200758)为零。然而，这是完全错误的。由于载荷[分布](@entry_id:182848) $\Lambda \sim \mathcal{N}(\lambda_c, \sigma^2)$ 是对称的，总有 $0.5$ 的概率 $\Lambda > \lambda_c$，从而产生非零的挠度。通过直接积分计算，可以证明挠度的[期望值](@entry_id:153208) $\mathbb{E}[A]$ 和标准差 $\mathrm{Std}[A]$ 都与 $\sigma^{1/2}$ 成正比。这与线性方法预测的 $\mathrm{Std}[A] \propto \sigma$（或在此例中为0）截然不同。这个例子深刻地警示我们：在分岔点、[相变](@entry_id:147324)点或其他非光滑行为附近，线性近似是不可靠的，必须使用更先进的方法来传播整个[概率分布](@entry_id:146404)。

#### 动力系统中的[不确定性传播](@entry_id:146574)

对于随时间演化的动力系统，[初始条件](@entry_id:152863)中的微小不确定性会如何发展？答案取决于系统的内在性质。

对于稳定的线性或可线性化系统，小的扰动通常会随时间衰减或保持有界。然而，我们用于求解微分方程的数值方法本身会影响不确定性的传播。以经典的 **捕食者-被食者模型** 为例，其非平凡[平衡点](@entry_id:272705)是一个中心点，意味着附近的扰动会以稳定的[轨道](@entry_id:137151)[振荡](@entry_id:267781)，既不增长也不衰减 [@problem_id:2448316]。如果我们使用 **[显式欧拉法](@entry_id:141307)** 这样的简单数值积分方案，即使是很小的时间步长，也会因为其数值特性而错误地放大这种[振荡](@entry_id:267781)，导致计算出的不确定性随时间无限增长。相反，**[隐式欧拉法](@entry_id:176177)** 虽然在数值上是稳定的，但它会引入人为的[数值耗散](@entry_id:168584)，错误地使不确定性衰减至零。这两种方法都无法准确再现真实[连续动力学](@entry_id:268176)中不确定性的[中性演化](@entry_id:172700)。

与稳定系统形成鲜明对比的是 **[混沌系统](@entry_id:139317) (Chaotic Systems)**。在这些系统中，存在对[初始条件](@entry_id:152863)的 **敏感依赖性**，即所谓的“[蝴蝶效应](@entry_id:143006)”。以牛顿引力下的 **[N体问题](@entry_id:142540)** 为例 [@problem_id:2448337]，两个初始状态极为接近的系统，其轨迹也会随着时间呈指数级分离。这种分离的速率由系统的最大 **[李雅普诺夫指数](@entry_id:136828) (Lyapunov Exponent)** $\lambda$ 来表征。如果 $\lambda > 0$，系统就是混沌的。在这种情况下，任何初始不确定性都会被指数放大，使得对系统的长期精确预测变得不可能。[不确定性量化](@entry_id:138597)的目标不再是为预测附加一个小的[误差棒](@entry_id:268610)，而是转为描述系统在相空间中的长期统计行为。

### 基于抽样的[蒙特卡洛方法](@entry_id:136978)

当模型过于复杂或高度[非线性](@entry_id:637147)，以至于解析或线性近似方法不再适用时，基于抽样的方法成为了一种强大而通用的替代方案。其核心思想简单而直接：
1.  根据输入参数的[概率分布](@entry_id:146404)，生成大量的随机样本。
2.  为每一个输入样本运行一次计算模型，得到一个相应的输出。
3.  收集所有输出样本，形成一个输出的[经验分布](@entry_id:274074)。
4.  通过分析这个输出样本集合，计算其统计特性，如均值、[方差](@entry_id:200758)、分位数等。

这种方法被称为 **蒙特卡洛 (Monte Carlo, MC)** 方法。其最显著的优点是收敛速度的普适性。对于一个估计量（如均值），其[均方根误差](@entry_id:170440) (RMSE) 的[收敛速度](@entry_id:636873)为 $O(N^{-1/2})$，其中 $N$ 是样本数量。这个速度与问题[参数空间](@entry_id:178581)的维度无关，从而有效规避了所谓的“[维度灾难](@entry_id:143920)”。

为了提高效率，发展出了多种“[方差缩减](@entry_id:145496)”技术，**[拉丁超立方抽样](@entry_id:751167) (Latin Hypercube Sampling, LHS)** 是其中最著名的一种。与纯随机的MC抽样不同，LHS通过将每个输入参数的[分布](@entry_id:182848)范围划分为 $N$ 个等概率的“层”，并确保每个层中都恰好有一个样本点，从而强制样本在整个[参数空间](@entry_id:178581)中[分布](@entry_id:182848)得更加均匀。对于光滑的响应函数，LHS的收敛速度可以显著快于MC，有时可达到近 $O(N^{-1})$。

然而，LHS的优势并非无条件的。考虑一个本身就具有随机性的模型，例如，模拟一个随机分形的体积 [@problem_id:2448402]。在这个问题中，即使输入参数 $\theta$ 固定，每次[函数调用](@entry_id:753765)（即分形的几何构造）本身也是一个[随机过程](@entry_id:159502)。这种内在的、不可约的随机性给每次输出都增加了一个“噪声”项。这个噪声项的[方差](@entry_id:200758)贡献使得任何基于抽样的方法（包括LHS）的总体RMSE收敛速度都被限制在 $O(N^{-1/2})$。尽管LHS仍然可以通过更有效地探索[参数空间](@entry_id:178581)来减小[误差常数](@entry_id:168754)，但它无法改变基本的收敛速率。这揭示了不确定性来源的一个重要区别：[参数不确定性](@entry_id:264387)（可通过LHS等方法高效处理）与模型内在随机性（其[方差](@entry_id:200758)贡献只能通过增加样本量 $N$ 来“平均掉”）。

### 逆向不确定性量化：[贝叶斯推断](@entry_id:146958)

到目前为止，我们讨论的都是“前向”问题：给定输入不确定性，推断输出不确定性。然而，在科学实践中，我们更常面对“逆向”问题：给定一系列实验观测数据，我们能反过来推断模型的未知参数吗？**贝叶斯推断 (Bayesian Inference)** 为此提供了一个严谨的数学框架。

#### 贝叶斯定理与先验选择

[贝叶斯推断](@entry_id:146958)的核心是 **贝叶斯定理**：
$$
p(\boldsymbol{\theta} | D, \mathcal{M}) = \frac{p(D | \boldsymbol{\theta}, \mathcal{M}) p(\boldsymbol{\theta} | \mathcal{M})}{p(D | \mathcal{M})}
$$
其中：
-   $\boldsymbol{\theta}$ 是模型的未知参数。
-   $D$ 是观测到的数据。
-   $\mathcal{M}$ 代表我们所使用的模型。
-   $p(\boldsymbol{\theta} | D, \mathcal{M})$ 是 **[后验概率](@entry_id:153467)[分布](@entry_id:182848) (Posterior)**，它表示在看到数据后，我们对参数 $\boldsymbol{\theta}$ 的信念。这是我们推断的目标。
-   $p(D | \boldsymbol{\theta}, \mathcal{M})$ 是 **[似然函数](@entry_id:141927) (Likelihood)**，它描述了在给定参数 $\boldsymbol{\theta}$ 的情况下，观测到数据 $D$ 的概率。
-   $p(\boldsymbol{\theta} | \mathcal{M})$ 是 **[先验概率](@entry_id:275634)[分布](@entry_id:182848) (Prior)**，它表示在看到任何数据之前，我们对参数 $\boldsymbol{\theta}$ 的初始信念。
-   $p(D | \mathcal{M})$ 是 **证据 (Evidence)** 或[边际似然](@entry_id:636856)，在[参数推断](@entry_id:753157)中通常是一个[归一化常数](@entry_id:752675)。

公式可以简写为：**后验 $\propto$ [似然](@entry_id:167119) $\times$ 先验**。

先验的选择是[贝叶斯分析](@entry_id:271788)的一个关键方面。它允许我们将先前的知识（或缺乏知识）正式地融入到分析中。以一个泊松过程为例，比如测量放射性衰变，观测到在时间 $T$ 内有 $k$ 次计数。我们希望推断[衰变率](@entry_id:156530) $\lambda$ [@problem_id:2448348]。似然函数是[泊松分布](@entry_id:147769) $p(k|\lambda) \propto (\lambda T)^k e^{-\lambda T}$。

我们可以选择不同的先验。一种是 **不当均匀先验 (improper uniform prior)**，$p(\lambda) \propto \text{constant}$，它表达了对 $\lambda$ 的任何值都一视同仁的“无知”。另一种是 **[杰弗里斯先验](@entry_id:164583) (Jeffreys prior)**，它是一种基于[费雪信息](@entry_id:144784)量构造的“无信息”先验，对于泊松[率参数](@entry_id:265473)，其形式为 $p(\lambda) \propto \lambda^{-1/2}$。

将这两个先验分别与似然函数相乘，我们发现后验分布都是伽马[分布](@entry_id:182848) (Gamma distribution)，但参数不同：
-   均匀先验 $\implies$ 后验 $\sim \text{Gamma}(k+1, T)$
-   [杰弗里斯先验](@entry_id:164583) $\implies$ 后验 $\sim \text{Gamma}(k+1/2, T)$

这意味着，在数据稀疏的情况下（例如，当 $k=0$ 时），两种先验得到的[后验均值](@entry_id:173826)不同（分别为 $1/T$ 和 $1/(2T)$）。这个差异反映了先验选择的影响。然而，随着数据的增多（$k$ 变大），[似然函数](@entry_id:141927)的作用会越来越强，最终主导后验分布，使得不同先验带来的差异变得可以忽略不计。

#### [贝叶斯模型选择](@entry_id:147207)与奥卡姆剃刀

贝叶斯框架的威力不止于[参数推断](@entry_id:753157)，它还提供了一种优雅的 **模型选择 (Model Selection)** 方法。当我们有两个或多个竞争模型来解释同一组数据时，我们如何客观地判断哪个模型更好？

答案在于贝叶斯定理中的分母项——**证据 (Evidence)** $p(D | \mathcal{M})$。证据是通过在模型的整个先验参数空间上对[似然函数](@entry_id:141927)进行积分得到的：
$$
p(D | \mathcal{M}) = \int p(D | \boldsymbol{\theta}, \mathcal{M}) p(\boldsymbol{\theta} | \mathcal{M}) d\boldsymbol{\theta}
$$
证据代表了模型 $\mathcal{M}$ 预测出我们观测到的数据的平均能力。一个好的模型，其高似然区域应该与高先验概率区域重合，从而得到较高的证据值。

我们可以通过计算 **[贝叶斯因子](@entry_id:143567) (Bayes Factor)** $K_{10} = p(D | \mathcal{M}_1) / p(D | \mathcal{M}_0)$ 来比较两个模型 $\mathcal{M}_1$ 和 $\mathcal{M}_0$。如果 $K_{10} > 1$，则数据支持模型 $\mathcal{M}_1$；如果 $K_{10}  1$，则数据支持模型 $\mathcal{M}_0$。

证据的计算内在地实现了 **[奥卡姆剃刀](@entry_id:147174) (Occam's Razor)** 原则：如无必要，勿增实体。一个参数更多的复杂模型 $\mathcal{M}_1$ 可能会在某个最佳参数点上比简单模型 $\mathcal{M}_0$ 更好地拟合数据（即具有更高的[最大似然](@entry_id:146147)值）。但是，由于其[参数空间](@entry_id:178581)更大，它的[先验概率](@entry_id:275634)被分散在更广的范围内。除非这个高[似然](@entry_id:167119)区域在参数空间中足够大，否则积分得到的总证据值可能反而会低于更简单的模型。这种对复杂度的惩罚是自动且完全由数据和先验决定的。

考虑一个在[中微子探测](@entry_id:752459)器中寻找微弱信号的例子 [@problem_id:2448317]。我们比较两个模型：$\mathcal{M}_0$（只有已知的背景事件）和 $\mathcal{M}_1$（背景加一个未知的信号）。模型 $\mathcal{M}_1$ 更复杂，因为它引入了一个新的参数——信号率 $\lambda_s$。通过计算，我们发现尽管观测到的事件数（5个）略高于背景预期（3个），但[贝叶斯因子](@entry_id:143567) $K_{10} \approx 1.39$。这个值仅略大于1，表明数据对更复杂的“信号+背景”模型只有微弱的支持。更好的拟合带来的优势，很大程度上被引入新参数所带来的“奥卡姆惩罚”所抵消。

在天体物理学等领域，证据积分往往难以直接计算。这时可以采用 **[拉普拉斯近似](@entry_id:636859) (Laplace Approximation)** [@problem_id:2448386]。该近似将证据分解为两个直观的部分：
$$
Z(\mathcal{M}) \approx L_{\max} \times \pi(\hat{\boldsymbol{\theta}}) \times (2\pi)^{d/2} \sqrt{\det(\Sigma_{\text{post}})}
$$
这里，$L_{\max}$ 是最大似然值（衡量最佳[拟合优度](@entry_id:637026)），而后面的项可以被看作是“后验体积”与“先验体积”的比值，代表了 **奥卡姆因子**。在比较宇宙学中的 $\Lambda$CDM 模型（参数少）和 $w$CDM 模型（参数多）时，我们看到 $w$CDM 模型以 $\Delta\chi^2=3$ 的优势获得了更好的拟合（$L_{\max}$ 更高）。然而，由于它多了一个参数 $w$，其参数空间更大，导致奥卡姆因子小于1。最终的[贝叶斯因子](@entry_id:143567)约为2，再次表明数据仅为更复杂的模型提供了微弱的支持。

通过这些原理和机制的学习，我们能够以更加严谨和全面的方式对待计算物理中的模型和数据，不仅给出预测，更能科学地评估这些预测的可信度。