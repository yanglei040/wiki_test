{"hands_on_practices": [{"introduction": "像牛顿法这样的开放方法虽然功能强大，但其成功与否往往严重依赖于初始猜测值。本练习将引导你通过解析方法，确定一个简单多项式的“吸引盆”[@problem_id:1677773]，从而深入探究这种敏感性。通过精确识别该方法成功与失败的边界，你将对迭代求根算法的动态行为以及收敛性分析的重要性建立更深刻的直觉。", "problem": "牛顿法是一种求解可微函数 $f(x)$ 根的常用算法。该方法从一个初始猜测值 $x_0$ 开始，通过以下迭代公式生成一个近似序列：\n$$x_{k+1} = N(x_k) = x_k - \\frac{f(x_k)}{f'(x_k)}$$\n这个过程可以看作一个离散动力系统。对于一个给定的函数，所有使得序列收敛到某个特定根的初始点 $x_0$ 的集合，被称为该根的吸引盆。\n\n考虑函数 $f(x) = x^3 - x$。该函数有三个不同的实根。实数轴可以被划分为这三个根的吸引盆。由于该函数的对称性，根 $x=0$ 的吸引盆是一个形如 $(-\\beta, \\beta)$ 的连通开区间，其中 $\\beta$ 为某个正常数。根 $x=1$ 的吸引盆包含区间 $(\\beta, \\infty)$，而根 $x=-1$ 的吸引盆包含区间 $(-\\infty, -\\beta)$。边界点 $\\pm\\beta$ 本身形成一个周期轨道，并且不收敛于任何一个根。\n\n求出这个边界点 $\\beta$ 的精确正值。", "solution": "计算 $f(x)=x^{3}-x$ 的牛顿映射。使用 $N(x)=x-\\frac{f(x)}{f'(x)}$ 以及 $f'(x)=3x^{2}-1$，我们得到\n$$\nN(x)=x-\\frac{x^{3}-x}{3x^{2}-1}\n=\\frac{x(3x^{2}-1)-(x^{3}-x)}{3x^{2}-1}\n=\\frac{3x^{3}-x-x^{3}+x}{3x^{2}-1}\n=\\frac{2x^{3}}{3x^{2}-1}.\n$$\n映射 $N$ 是奇函数，因为 $N(-x)=-N(x)$。其不动点满足 $N(x)=x$，这可以简化为 $f(x)=0$，因此仅有的不动点是 $x\\in\\{-1,0,1\\}$。\n\n根据给定的对称性，$0$ 的直接吸引盆是 $(-\\beta,\\beta)$，其边界点 $\\pm\\beta$ 不收敛于任何根，并形成一个周期轨道。因为 $N$ 是奇函数，由这两个边界点组成的唯一可能的非平凡周期轨道是一个 2-周期轨道，满足\n$$\nN(\\beta)=-\\beta\\quad\\text{and}\\quad N(-\\beta)=\\beta.\n$$\n令 $N(\\beta)=-\\beta$ (其中 $\\beta0$ 且 $\\beta\\neq 0$) 可得\n$$\n\\frac{2\\beta^{3}}{3\\beta^{2}-1}=-\\beta.\n$$\n两边乘以 $3\\beta^{2}-1$ (在我们找到的解处该项非零) 并化简，\n$$\n2\\beta^{3}=-\\beta(3\\beta^{2}-1)\\quad\\Longrightarrow\\quad 2\\beta^{3}=-3\\beta^{3}+\\beta,\n$$\n$$\n5\\beta^{3}-\\beta=0\\quad\\Longrightarrow\\quad \\beta\\left(5\\beta^{2}-1\\right)=0.\n$$\n排除 $\\beta=0$ 的情况，我们得到\n$$\n\\beta^{2}=\\frac{1}{5}\\quad\\Longrightarrow\\quad \\beta=\\frac{1}{\\sqrt{5}}.\n$$\n在此 $\\beta$ 值下，$3\\beta^{2}-1=\\frac{3}{5}-1=-\\frac{2}{5}\\neq 0$，因此计算有效。此外，该轨道是排斥性的，因为\n$$\nN'(x)=\\frac{6x^{2}(x^{2}-1)}{(3x^{2}-1)^{2}},\\quad N'(\\beta)=\\frac{6\\cdot\\frac{1}{5}\\left(\\frac{1}{5}-1\\right)}{\\left(3\\cdot\\frac{1}{5}-1\\right)^{2}}=-6,\n$$\n所以边界点不收敛于任何根，符合要求。因此，边界点的精确正值为 $\\beta=\\frac{1}{\\sqrt{5}}$。", "answer": "$$\\boxed{\\frac{1}{\\sqrt{5}}}$$", "id": "1677773"}, {"introduction": "现在，让我们从理论转向实践，解决一个计算物理学中的经典问题：求解切比雪夫多项式的根。这项练习要求你从零开始编写牛顿法和割线法，并将它们应用于一个高次多项式[@problem_id:2422749]。这个任务不仅能巩固你的编程技能，还能让你在处理数值稳定性、使用递推关系以及对照已知的解析解验证数值结果方面获得宝贵经验。", "problem": "你的任务是设计并实现一个完整的、可运行的程序，该程序能数值计算第一类切比雪夫多项式的根，并量化其与已知的解析结果的一致性。你的实现必须使用开放方法进行求根（例如，牛顿法和割线法），并且不得依赖于区间法。所有使用的角度都必须以弧度表示。\n\n起点与基本依据：使用以下基本事实和定义，不要在问题陈述中提供任何快捷公式。第一类切比雪夫多项式，记为 $T_n(x)$，是在区间 $[-1,1]$ 上关于权重 $(1-x^2)^{-1/2}$ 的一个正交多项式序列。它们满足三项递推关系\n$$\nT_0(x)=1,\\quad T_1(x)=x,\\quad T_{k+1}(x)=2x\\,T_k(x)-T_{k-1}(x),\n$$\n并且余弦的倍角恒等式意味着其具有如下表示\n$$\nT_n(\\cos\\theta)=\\cos(n\\theta),\n$$\n对于任意实数 $\\theta$。其导数与第二类切比雪夫多项式 $U_n(x)$ 相关，关系为\n$$\n\\frac{d}{dx}T_n(x)=n\\,U_{n-1}(x),\n$$\n其中 $U_n(x)$ 遵循递推关系\n$$\nU_0(x)=1,\\quad U_1(x)=2x,\\quad U_{k+1}(x)=2x\\,U_k(x)-U_{k-1}(x).\n$$\n基于这些依据以及 $T_n(\\cos\\theta)=\\cos(n\\theta)$ 这一事实，$T_n(x)$ 在 $(-1,1)$ 内的解析根具有已知的闭式解；你必须使用这个经过充分检验的事实来构建用于比较的参考值，所有角度均以弧度表示。\n\n需要实现的开放方法：为一个标量函数 $f(x)$ 实现至少两种开放求根方法：由迭代公式给出的牛顿法\n$$\nx_{m+1}=x_m-\\frac{f(x_m)}{f'(x_m)},\n$$\n和由迭代公式给出的割线法\n$$\nx_{m+1}=x_m - f(x_m)\\,\\frac{x_m-x_{m-1}}{f(x_m)-f(x_{m-1})}.\n$$\n这些公式必须在你的解答中从第一性原理推导得出，而不能仅仅作为公式陈述。\n\n数值任务：对于每个指定的测试用例，执行以下操作。\n- 对于给定的阶数 $n$，使用 $T_n(x)$ 的稳定三项递推关系定义 $f(x)=T_n(x)$。\n- 对于牛顿法，使用 $U_{n-1}(x)$ 的稳定三项递推关系定义 $f'(x)=n\\,U_{n-1}(x)$。\n- 为 $(-1,1)$ 内的 $n$ 个不同根生成初始猜测值。你可以使用已知的 $n$ 个根的精确表达式作为初始种子，可能加上微小的扰动。对于割线法，为每个根提供两个初始值。\n- 应用所选的开放方法来收敛到每个根。使用基于 $|f(x)|\\le \\varepsilon$ 或 $|x_{m+1}-x_m|\\le \\varepsilon$ 的停止准则，其中 $\\varepsilon$ 是一个预设的容差。\n- 使用已知的精确表达式（角度以弧度为单位）计算解析根以进行比较，并将数值根和解析根都按升序排序。\n- 对于每个测试用例，报告一个实数，该实数等于所有 $n$ 个根中，对应的数值根和解析根之间的最大绝对差。\n\n测试套件：你的程序必须在没有任何外部输入的情况下运行以下四个测试用例，并以双精度生成结果。\n- 用例 A（顺利路径，最小的非平凡阶数）：$n=1$，方法 = 牛顿法，容差 $\\varepsilon=10^{-13}$。\n- 用例 B（中等阶数）：$n=5$，方法 = 牛顿法，容差 $\\varepsilon=10^{-13}$。\n- 用例 C（较高阶数，根在端点附近聚集）：$n=32$，方法 = 牛顿法，容差 $\\varepsilon=10^{-13}$。\n- 用例 D（较高阶数，使用不同的开放方法）：$n=50$，方法 = 割线法，容差 $\\varepsilon=10^{-13}$。\n\n角度单位要求：每当你从闭式表达式计算解析根时，所有角度均按弧度处理。\n\n最终输出格式：你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，\"[r_A,r_B,r_C,r_D]\"）。每个条目必须是一个浮点数，等于对应测试用例（按 A, B, C, D 的顺序）的最大绝对差。\n\n所有计算必须在无量纲单位下进行。不允许用户交互；程序必须完全自包含且确定性。", "solution": "所述问题已经过验证，被认为是科学上合理、适定且客观的。它不包含任何逻辑矛盾，为得到唯一解提供了所有必要的数据，并且完全属于计算物理和数值分析的范畴。因此，我将着手提供一个完整的解答。任务是使用指定的开放方法计算第一类切比雪夫多项式的根，并量化这些数值结果与已知解析解的精确度。\n\n首先，必须从基本原理推导开放求根方法所需的迭代公式。\n\n牛顿法的推导\n\n令 $x^{*}$ 为可微函数 $f(x)$ 的一个根，使得 $f(x^{*}) = 0$。令 $x_m$ 为根 $x^{*}$ 的当前近似值。我们寻求一个更好的近似值 $x_{m+1}$。我们可以使用围绕点 $x_m$ 的一阶泰勒级数展开来表示 $f(x)$：\n$$\nf(x) \\approx f(x_m) + f'(x_m)(x - x_m)\n$$\n我们正在寻找使 $f(x) = 0$ 的 $x$ 值。让这个值成为我们的下一个近似值 $x_{m+1}$。通过将 $x = x_{m+1}$ 代入泰勒展开并将其设为零，我们得到：\n$$\n0 \\approx f(x_m) + f'(x_m)(x_{m+1} - x_m)\n$$\n假设导数 $f'(x_m)$ 非零，可以解出 $x_{m+1}$：\n$$\nf'(x_m)(x_{m+1} - x_m) = -f(x_m)\n$$\n$$\nx_{m+1} = x_m - \\frac{f(x_m)}{f'(x_m)}\n$$\n这是众所周知的牛顿法迭代公式。只要初始猜测值 $x_0$ 足够接近根且根是单根，其收敛通常是二次的。\n\n割线法的推导\n\n牛顿法的一个实际限制是需要导数 $f'(x)$ 的解析表达式。当导数不可用或计算成本高昂时，可以对其进行近似。割线法用基于最近两次迭代值 $x_m$ 和 $x_{m-1}$ 的有限差分近似来代替导数。导数 $f'(x_m)$ 由连接点 $(x_{m-1}, f(x_{m-1}))$ 和 $(x_m, f(x_m))$ 的割线斜率来近似：\n$$\nf'(x_m) \\approx \\frac{f(x_m) - f(x_{m-1})}{x_m - x_{m-1}}\n$$\n将此近似代入牛顿法公式，得到割线法迭代公式：\n$$\nx_{m+1} = x_m - \\frac{f(x_m)}{\\left(\\frac{f(x_m) - f(x_{m-1})}{x_m - x_{m-1}}\\right)} = x_m - f(x_m)\\frac{x_m - x_{m-1}}{f(x_m) - f(x_{m-1})}\n$$\n该方法需要两个初始猜测值 $x_0$ 和 $x_1$，并表现出超线性收敛，比牛顿法慢但比线性收敛快。\n\n在切比雪夫多项式上的应用\n\n我们必须为其求根的函数是第一类切比雪夫多项式 $T_n(x)$。\n\n$T_n(x)$ 的解析根\n问题提供了恒等式 $T_n(\\cos\\theta) = \\cos(n\\theta)$。我们寻找区间 $(-1, 1)$ 内使 $T_n(x) = 0$ 的根 $x$。通过设 $x = \\cos\\theta$，其中 $\\theta \\in (0, \\pi)$，我们将问题转化为寻找满足以下条件的 $\\theta$：\n$$\n\\cos(n\\theta) = 0\n$$\n该三角方程的通解是 $n\\theta = (k + \\frac{1}{2})\\pi$，其中 $k$ 是一个整数。按规定，所有角度必须以弧度为单位。这给出：\n$$\n\\theta_k = \\frac{(k + \\frac{1}{2})\\pi}{n} = \\frac{(2k+1)\\pi}{2n}\n$$\n为了在区间 $x \\in (-1, 1)$ 中获得 $n$ 个不同的根，我们需要在区间 $(0, \\pi)$ 中有 $n$ 个不同的角度 $\\theta_k$。选择 $k = 0, 1, \\dots, n-1$ 会产生此范围内的 $n$ 个唯一角度。相应的根 $x_k$ 是：\n$$\nx_k = \\cos\\left(\\frac{(2k+1)\\pi}{2n}\\right), \\quad k = 0, 1, \\dots, n-1\n$$\n这些是 $T_n(x)$ 的 $n$ 个解析根，并将作为我们精度评估的参考值。\n\n$T_n(x)$ 及其导数的数值计算\n为了实现求根方法，我们需要计算 $T_n(x)$，以及对于牛顿法，计算其导数。\n函数 $f(x) = T_n(x)$ 使用提供的三项递推关系进行计算：\n$$\nT_0(x)=1, \\quad T_1(x)=x, \\quad T_{k+1}(x)=2x\\,T_k(x)-T_{k-1}(x)\n$$\n对于 $x \\in [-1, 1]$，这个递推关系是数值稳定的。\n对于牛顿法，导数 $f'(x)$ 由 $\\frac{d}{dx}T_n(x) = n\\,U_{n-1}(x)$ 给出，其中 $U_{n-1}(x)$ 是 $n-1$ 阶的第二类切比雪夫多项式。它使用其自身的三项递推关系进行计算：\n$$\nU_0(x)=1, \\quad U_1(x)=2x, \\quad U_{k+1}(x)=2x\\,U_k(x)-U_{k-1}(x)\n$$\n为了效率，这两个多项式都将通过迭代算法而不是递归来实现。\n\n计算流程\n对于由阶数 $n$、方法和容差 $\\varepsilon$ 指定的每个测试用例，执行以下步骤：\n1. 使用上面推导的公式计算 $n$ 个解析根 $x_k^{\\text{exact}}$。将它们按升序排序作为参考。\n2. 对 $n$ 个根中的每一个，启动数值搜索。\n    - 从相应的解析根生成一个（或多个）初始猜测值。这确保了每次搜索都收敛到一个唯一的、预先识别的根，从而可以直接比较精度。\n    - 对于牛顿法，初始猜测值设为 $x_0 = x_k^{\\text{exact}}$。\n    - 对于割线法，需要两个初始猜测值。我们使用 $x_1 = x_k^{\\text{exact}}$ 和一个略微扰动的点 $x_0 = x_1 - \\delta$，其中 $\\delta$ 是一个小常数（例如 $\\delta = 10^{-8}$）。\n3. 应用所选的迭代方法（牛顿法或割线法）直到满足停止准则。准则是 $|f(x_m)| \\le \\varepsilon$ 或作为保障的 $|x_{m+1} - x_m| \\le \\varepsilon$。同时也会施加最大迭代次数，以防止在不收敛的情况下出现无限循环。\n4. 收集数值计算出的根并按升序排序。\n5. 计算排序后的数值根和排序后的解析根之间的最大绝对差：$\\max_{k} |x_k^{\\text{numerical}} - x_k^{\\text{exact}}|$。这个单一值量化了该方法在给定测试用例下的精度。\n\n对所有四个测试用例重复此过程：\n- 用例 A：$n=1$，牛顿法，$\\varepsilon=10^{-13}$。\n- 用例 B：$n=5$，牛顿法，$\\varepsilon=10^{-13}$。\n- 用例 C：$n=32$，牛顿法，$\\varepsilon=10^{-13}$。\n- 用例 D：$n=50$，割线法，$\\varepsilon=10^{-13}$。\n\n最终输出将是一个列表，包含四个最大绝对差值，每个用例一个。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\n# No scipy is needed as the methods are implemented from first principles.\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the entire process.\n    It runs the specified test cases and prints the final result.\n    \"\"\"\n\n    def T(n, x):\n        \"\"\"\n        Computes the Chebyshev polynomial of the first kind, T_n(x),\n        using the three-term recurrence relation.\n        \"\"\"\n        if n == 0:\n            return 1.0\n        if n == 1:\n            return x\n        \n        T_k_minus_1 = 1.0  # T_0\n        T_k = x            # T_1\n        for _ in range(2, n + 1):\n            T_k_plus_1 = 2.0 * x * T_k - T_k_minus_1\n            T_k_minus_1 = T_k\n            T_k = T_k_plus_1\n        return T_k\n\n    def U(n, x):\n        \"\"\"\n        Computes the Chebyshev polynomial of the second kind, U_n(x),\n        using the three-term recurrence relation.\n        \"\"\"\n        if n == 0:\n            return 1.0\n        if n == 1:\n            return 2.0 * x\n            \n        U_k_minus_1 = 1.0  # U_0\n        U_k = 2.0 * x      # U_1\n        for _ in range(2, n + 1):\n            U_k_plus_1 = 2.0 * x * U_k - U_k_minus_1\n            U_k_minus_1 = U_k\n            U_k = U_k_plus_1\n        return U_k\n\n    def newton_method(f, df, x0, tol, max_iter=50):\n        \"\"\"\n        Finds a root of f(x) using Newton's method.\n        f: function\n        df: derivative of the function\n        x0: initial guess\n        tol: tolerance for stopping\n        max_iter: maximum number of iterations\n        \"\"\"\n        x = x0\n        for _ in range(max_iter):\n            fx = f(x)\n            if abs(fx) = tol:\n                return x\n            \n            dfx = df(x)\n            if dfx == 0:\n                # Derivative is zero, method fails. Unlikely for this problem.\n                break\n                \n            x_next = x - fx / dfx\n            if abs(x_next - x) = tol:\n                return x_next\n            x = x_next\n        return x\n\n    def secant_method(f, x0, x1, tol, max_iter=50):\n        \"\"\"\n        Finds a root of f(x) using the secant method.\n        f: function\n        x0, x1: two initial guesses\n        tol: tolerance for stopping\n        max_iter: maximum number of iterations\n        \"\"\"\n        fx0 = f(x0)\n        fx1 = f(x1)\n        for _ in range(max_iter):\n            if abs(fx1) = tol:\n                return x1\n            \n            # Avoid division by zero\n            if (fx1 - fx0) == 0:\n                break\n            \n            x_next = x1 - fx1 * (x1 - x0) / (fx1 - fx0)\n            \n            if abs(x_next - x1) = tol:\n                return x_next\n            \n            x0, x1 = x1, x_next\n            fx0, fx1 = fx1, f(x1)\n        return x1\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {'n': 1, 'method': 'newton', 'tol': 1e-13},  # Case A\n        {'n': 5, 'method': 'newton', 'tol': 1e-13},  # Case B\n        {'n': 32, 'method': 'newton', 'tol': 1e-13}, # Case C\n        {'n': 50, 'method': 'secant', 'tol': 1e-13}, # Case D\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        n = case['n']\n        method = case['method']\n        tol = case['tol']\n\n        # 1. Compute analytical roots for reference and seeding\n        # Formula: x_k = cos((2k+1)pi / (2n)) for k=0, ..., n-1\n        k = np.arange(n)\n        analytical_roots = np.cos((2 * k + 1) * np.pi / (2 * n))\n        analytical_roots.sort() # Ensure ascending order\n\n        numerical_roots = []\n\n        # 2. Find roots numerically\n        for i in range(n):\n            initial_seed = analytical_roots[i]\n            \n            if method == 'newton':\n                # Define function f(x) = T_n(x) and its derivative f'(x) = n*U_{n-1}(x)\n                f = lambda x: T(n, x)\n                df = lambda x: n * U(n - 1, x) if n > 0 else 0.0\n                root = newton_method(f, df, initial_seed, tol)\n                numerical_roots.append(root)\n            \n            elif method == 'secant':\n                f = lambda x: T(n, x)\n                # Two initial guesses: the analytical root and a slightly perturbed version\n                x1 = initial_seed\n                x0 = initial_seed - 1e-8 # Small perturbation\n                root = secant_method(f, x0, x1, tol)\n                numerical_roots.append(root)\n        \n        numerical_roots = np.array(numerical_roots)\n        numerical_roots.sort()\n\n        # 3. Compute the maximum absolute difference\n        max_abs_diff = np.max(np.abs(numerical_roots - analytical_roots))\n        results.append(max_abs_diff)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.15e}' for r in results)}]\")\n\nsolve()\n```", "id": "2422749"}, {"introduction": "开放方法虽然速度快，但如果初始猜测不佳，可能会失败。相比之下，区间法虽然稳健但速度较慢。最后的这项练习将挑战你构建一个“两全其美”的混合求解器，它能智能地在不同算法之间切换[@problem_id:2402195]。通过设计一个在远离根时使用安全方法、在靠近根时使用快速方法的方案，你将学到一种在专业数值库中用于实现速度与可靠性兼得的先进策略。", "problem": "设计并实现一种三元混合求根算法，该算法结合了区间平分、基于斜率的外推和线性化局部校正，用于求解标量非线性方程。目标是在给定的有根区间 $[a,b]$（其中 $f(a)\\,f(b)\\le 0$）内，计算连续函数 $f(x)$ 的一个实根的近似值。该算法使用一个有原则的切换方案，在三个阶段之间切换：当远离根时，采用保守的区间平分阶段；当相当接近根时，采用基于斜率的方法阶段；最后，在基于线性化局部模型的最终修正阶段。所有涉及三角函数的函数参数必须以弧度表示。\n\n从以下基本基础出发，推导并论证一种鲁棒的切换策略，指明为保持安全性所需的接受和回退条件，并实现一个完整的程序，在提供的测试套件上执行此策略。\n\n基本基础：\n- 根的定义：一个点 $x^\\ast$，使得 $f(x^\\ast)=0$。\n- 连续性与介值定理 (IVT)：如果 $f$ 在 $[a,b]$ 上连续，且 $f(a)\\,f(b)\\le 0$，则在 $[a,b]$ 中至少存在一个根。\n- 可微函数的一阶泰勒展开：对于在 $x_k$ 点可微的函数 $f$，当 $x$ 接近 $x_k$ 时，有 $f(x)\\approx f(x_k)+f'(x_k)\\,(x-x_k)$。\n- 区间上导数的有限差分近似：对于不同的 $x_1$ 和 $x_2$，有 $f'(x)\\approx \\dfrac{f(x_2)-f(x_1)}{x_2-x_1}$。\n\n三元混合切换方案的要求：\n- 有根区间不变性：始终保持区间 $[a,b]$ 满足 $f(a)\\,f(b)\\le 0$。\n- 第一阶段（区间平分）：当当前区间长度 $L=b-a$ 相对于初始长度 $L_0=b_0-a_0$ 较大时，选择中点候选值 $m=(a+b)/2$。当 $L\\tau_{\\text{far}}\\,L_0$ 时应使用此阶段。\n- 第二阶段（基于斜率的方法）：当区间中等小但非极小时，使用根据当前有根区间数据构建的线性模型来提出一个严格位于 $[a,b]$ 内部的候选点。当 $\\tau_{\\text{near}}\\,L_0  L \\le \\tau_{\\text{far}}\\,L_0$ 时应使用此阶段。\n- 第三阶段（局部修正）：当区间非常小时，使用围绕当前内部点的一阶局部线性化来提出一个精化步骤。仅当该步骤的结果仍在 $[a,b]$ 内部且局部斜率的绝对值不太小时才接受该步骤；否则，回退到更安全的第二阶段或第一阶段步骤。\n- 接受与回退策略：任何在 $[a,b]$ 之外的候选值都必须被拒绝；如果局部斜率的绝对值低于指定阈值，则避免局部线性化步骤；如果线性模型步骤不可接受，则恢复到区间平分法。\n- 区间更新：计算出候选值 $x_c$ 后，评估 $f(x_c)$。如果 $f(a)\\,f(x_c)\\le 0$，则设 $b\\leftarrow x_c$；否则设 $a\\leftarrow x_c$。这可以保持有根区间的不变性。\n\n停止准则：\n- 如果当前中点的绝对残差 $|f(m)|$ 至多为 $f_{\\text{tol}}$，或者区间长度 $L=b-a$ 至多为 $x_{\\text{tol}}$，则停止。\n- 使用 $x_{\\text{tol}}=10^{-12}$ 和 $f_{\\text{tol}}=10^{-12}$。\n- 最多使用 $N_{\\max}=200$ 次迭代。\n\n切换阈值和安全保障：\n- 使用 $\\tau_{\\text{far}}=0.25$ 和 $\\tau_{\\text{near}}=10^{-3}$。\n- 对于局部线性化，要求 $|f'(x)|\\ge \\delta_{\\min}$（其中 $\\delta_{\\min}=10^{-14}$）才能尝试进行修正步骤。\n\n您的程序必须实现上述算法，并将其应用于以下由函数和区间组成的测试套件。所有角度必须以弧度为单位。测试套件中的每个函数在指定区间上都是连续可微的。请在您的实现中提供解析一阶导数 $f'(x)$。\n\n测试套件：\n- 案例 1：$f_1(x)=x^3-x-2$，区间为 $[1,2]$，其导数为 $f_1'(x)=3x^2-1$。\n- 案例 2：$f_2(x)=\\cos(x)-x$，区间为 $[0,1]$，其导数为 $f_2'(x)=-\\sin(x)-1$。\n- 案例 3：$f_3(x)=e^{x}-3x$，区间为 $[1,2]$，其导数为 $f_3'(x)=e^{x}-3$。\n- 案例 4：$f_4(x)=x-\\tanh(x)$，区间为 $[-2,2]$，其导数为 $f_4'(x)=1-\\operatorname{sech}^2(x)=1-\\dfrac{1}{\\cosh^2(x)}$。\n\n最终输出规范：\n- 对于每个案例，将近似根输出为精确到小数点后 $10$ 位的浮点数。\n- 将四个结果按顺序聚合为一个不含内嵌空格的 Python 风格列表字面量，即单行输出应为 $[r_1,r_2,r_3,r_4]$ 的形式，其中每个 $r_i$ 在小数点后恰好有 $10$ 位数字。\n\n您的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表（例如，$[r_1,r_2,r_3,r_4]$）。不允许用户输入；所有常量和函数都必须在程序内部定义。答案没有物理单位，也不涉及百分比。三角函数中的角度必须以弧度为单位。", "solution": "所提出的问题要求设计并实现一种三元混合算法，用于在指定的有根区间 $[a, b]$ 内寻找标量非线性函数 $f(x)$ 的根。对问题陈述的严格验证证实了其科学和数学上的合理性。它基于数值分析的既定原则——介值定理、泰勒定理和迭代法——并提供了一套完整、一致且明确的要求。因此，该问题被认为是有效的，我们继续进行所需算法的推导和实现。\n\n**1. 有根区间不变性与基本原理**\n\n该算法的基础是维持一个有根区间 $[a, b]$，使得根 $x^\\ast$ 始终包含在其中。这一点由介值定理保证，该定理指出，对于连续函数 $f$，如果 $f(a)$ 和 $f(b)$ 异号，即 $f(a)f(b) \\le 0$，则在 $[a, b]$ 中必然存在至少一个根 $x^\\ast$。\n\n在每次迭代中，我们提出一个候选根 $x_c \\in (a, b)$。然后我们计算 $f(x_c)$ 的值并更新区间以保持不变性：\n- 如果 $f(a)f(x_c) \\le 0$，根必定在 $[a, x_c]$ 中，因此我们通过更新 $b \\leftarrow x_c$ 将新区间设为 $[a, x_c]$。\n- 否则，必然有 $f(x_c)f(b) \\le 0$，所以根在 $[x_c, b]$ 中，我们更新 $a \\leftarrow x_c$。\n此过程保证了区间 $[a, b]$ 始终包含一个根，并且其长度 $L = b-a$ 会系统地减小。\n\n**2. 三元混合切换方案**\n\n候选点 $x_c$ 的选择取决于当前区间长度 $L$ 相对于初始长度 $L_0 = b_0 - a_0$ 的大小。这定义了三阶段策略。\n\n**第一阶段：区间平分（二分法）**\n\n这是最保守且全局收敛的阶段。候选点就是区间的中点：\n$$\nx_c = m = \\frac{a+b}{2}\n$$\n二分法呈现线性收敛，每一步区间长度减半。只要保持有根区间不变性，它就是无条件安全的。由于其收敛速度慢，它最适用于区间较大且我们远离根的情况。\n**激活条件：**当区间较大，$L  \\tau_{\\text{far}} L_0$ 时，或当更激进的方法失败时作为回退方案，使用此阶段。给定的阈值为 $\\tau_{\\text{far}} = 0.25$。\n\n**第二阶段：基于斜率的外推（割线法）**\n\n当区间已充分缩小时，我们可以通过使用基于两个端点 $(a, f(a))$ 和 $(b, f(b))$ 的函数线性模型来加速收敛。通过这两点的直线（割线）的根给出下一个候选值：\n$$\nx_c = b - f(b) \\frac{b-a}{f(b)-f(a)} = \\frac{a f(b) - b f(a)}{f(b) - f(a)}\n$$\n割线法具有超线性收敛率，阶数约为 $\\phi \\approx 1.618$。\n**激活条件：**此阶段用于中等大小的区间，即 $\\tau_{\\text{near}} L_0  L \\le \\tau_{\\text{far}} L_0$，阈值为 $\\tau_{\\text{near}} = 10^{-3}$ 和 $\\tau_{\\text{far}} = 0.25$。\n**安全保障：**仅当割线法步骤是“可接受的”，即提议的候选值 $x_c$ 严格位于当前区间内部，即 $x_c \\in (a, b)$ 时，才接受该步骤。如果 $x_c$ 落在此范围之外，则拒绝该步骤，算法必须回退到更安全的二分法。\n\n**第三阶段：局部线性化（牛顿-拉夫逊法）**\n\n当区间非常小时，我们假设我们离根足够近，以至于基于泰勒定理的局部模型非常精确。函数 $f(x)$ 在点 $x_k$ 周围的一阶泰勒展开为：\n$$\nf(x) \\approx f(x_k) + f'(x_k)(x-x_k)\n$$\n令 $f(x)=0$ 并求解 $x$ 可得到牛顿-拉夫逊更新规则：\n$$\nx_{k+1} = x_k - \\frac{f(x_k)}{f'(x_k)}\n$$\n该方法对单根提供二次收敛。对于我们的算法，我们选择当前区间的中点 $m=(a+b)/2$ 作为线性化点，即 $x_k=m$。候选值为：\n$$\nx_c = m - \\frac{f(m)}{f'(m)}\n$$\n**激活条件：**对于非常小的区间，$L \\le \\tau_{\\text{near}} L_0$，激活此修正阶段。\n**安全保障：**牛顿-拉夫逊步骤功能强大但可能不稳定。需要两个关键的安全保障：\n1.  **可接受性：**与割线法一样，候选值 $x_c$ 必须位于区间 $(a, b)$ 内部。\n2.  **导数大小：**一个非常小的导数，即 $|f'(m)| \\approx 0$，表示切线几乎是水平的，这可能导致步长巨大且不收敛。因此，只有当导数的绝对值高于最小阈值时，我们才尝试牛顿步骤：$|f'(m)| \\ge \\delta_{\\min}$，其中 $\\delta_{\\min}=10^{-14}$。\n如果任一安全保障失败，算法必须回退到更安全的方法——首先是第二阶段（割线法），如果该方法也失败，则回退到第一阶段（二分法）。\n\n**3. 集成算法与回退逻辑**\n\n完整的算法将这三个阶段与清晰的回退层次结构相结合，以确保鲁棒性。在每次迭代中，检查停止准则（$L \\le x_{\\text{tol}}$ 或 $|f(m)| \\le f_{\\text{tol}}$）后，按如下方式确定候选值 $x_c$：\n\n1.  计算当前区间长度 $L = b-a$。\n2.  **尝试第三阶段（牛顿法）：**如果 $L \\le \\tau_{\\text{near}} L_0$，计算中点 $m$ 处的导数 $f'(m)$。如果 $|f'(m)| \\ge \\delta_{\\min}$，则计算牛顿法候选值 $x_c$。如果 $a  x_c  b$，则接受它。\n3.  **尝试第二阶段（割线法）：**如果牛顿法候选值未被接受且 $L \\le \\tau_{\\text{far}} L_0$，则计算割线法候选值 $x_c$。为防止数值不稳定，只有在分母 $|f(b)-f(a)|$ 不会过小的情况下才应执行此操作。如果 $a  x_c  b$，则接受它。\n4.  **使用第一阶段（二分法）：**如果牛顿法和割线法的步骤都未被接受，则回退到二分法候选值 $x_c = m$。此步骤始终有效并确保进展。\n\n一旦选择了有效的 $x_c$，就更新有根区间 $[a, b]$，然后重复该过程，直到满足停止准则或超过最大迭代次数 $N_{\\max}=200$。最终解取为最后计算区间的中点。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the hybrid root-finding algorithm.\n    The results are printed in the specified format.\n    \"\"\"\n\n    def hybrid_solver(f, df, a, b, xtol, ftol, n_max, tau_far, tau_near, delta_min):\n        \"\"\"\n        Implements the ternary hybrid root-finding algorithm.\n\n        Args:\n            f (callable): The function for which to find a root.\n            df (callable): The analytic derivative of the function f.\n            a (float): The lower bound of the bracketing interval.\n            b (float): The upper bound of the bracketing interval.\n            xtol (float): Tolerance for the interval length.\n            ftol (float): Tolerance for the function value at the midpoint.\n            n_max (int): Maximum number of iterations.\n            tau_far (float): Threshold for switching to/from bisection.\n            tau_near (float): Threshold for switching to/from Newton's method.\n            delta_min (float): Minimum slope magnitude for Newton/Secant steps.\n\n        Returns:\n            float: The approximated root.\n        \"\"\"\n        a0, b0 = float(a), float(b)\n        L0 = b0 - a0\n        \n        fa = f(a0)\n        fb = f(b0)\n\n        if fa * fb > 0:\n            # Per problem spec, this should not happen for the given test cases.\n            raise ValueError(\"Root not bracketed or function has same sign at endpoints.\")\n\n        for _ in range(n_max):\n            L = b0 - a0\n            # Use a stable midpoint calculation\n            m = a0 + (b0 - a0) / 2.0\n            fm = f(m)\n\n            # Check stopping criteria\n            if L = xtol or abs(fm) = ftol:\n                return m\n\n            candidate_found = False\n            xc = None\n\n            # Phase III: Newton-Raphson Method\n            if L = tau_near * L0:\n                dfm = df(m)\n                if abs(dfm) >= delta_min:\n                    xc_newton = m - fm / dfm\n                    # Admissibility check\n                    if a0  xc_newton  b0:\n                        xc = xc_newton\n                        candidate_found = True\n\n            # Phase II: Secant Method (also serves as fallback for Phase III)\n            if not candidate_found and L = tau_far * L0:\n                # Denominator safety check\n                if abs(fb - fa) >= delta_min:\n                    xc_secant = (a0 * fb - b0 * fa) / (fb - fa)\n                    # Admissibility check\n                    if a0  xc_secant  b0:\n                        xc = xc_secant\n                        candidate_found = True\n\n            # Phase I: Bisection Method (ultimate fallback)\n            if not candidate_found:\n                xc = m\n            \n            fc = f(xc)\n\n            # Update bracket\n            if fa * fc = 0:\n                b0 = xc\n                fb = fc\n            else:\n                a0 = xc\n                fa = fc\n        \n        # Return best guess if max iterations reached\n        return (a0 + b0) / 2.0\n\n    # Test Suite Definition\n    test_cases = [\n        {'func': lambda x: x**3 - x - 2, 'dfunc': lambda x: 3*x**2 - 1, 'bracket': (1, 2)},\n        {'func': lambda x: np.cos(x) - x, 'dfunc': lambda x: -np.sin(x) - 1, 'bracket': (0, 1)},\n        {'func': lambda x: np.exp(x) - 3*x, 'dfunc': lambda x: np.exp(x) - 3, 'bracket': (1, 2)},\n        {'func': lambda x: x - np.tanh(x), 'dfunc': lambda x: 1 - (1/np.cosh(x))**2, 'bracket': (-2, 2)}\n    ]\n\n    # Algorithm Parameters\n    params = {\n        'xtol': 1e-12,\n        'ftol': 1e-12,\n        'n_max': 200,\n        'tau_far': 0.25,\n        'tau_near': 1e-3,\n        'delta_min': 1e-14\n    }\n\n    results = []\n    for case in test_cases:\n        root = hybrid_solver(\n            f=case['func'],\n            df=case['dfunc'],\n            a=case['bracket'][0],\n            b=case['bracket'][1],\n            **params\n        )\n        results.append(f\"{root:.10f}\")\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2402195"}]}