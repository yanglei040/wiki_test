{"hands_on_practices": [{"introduction": "理论知识是基础，但要真正掌握数值误差，没有什么比亲眼见证其影响更有效了。第一个实践练习将从一个看似简单却极具启发性的问题开始：使用浮点数作为循环计数器。这个练习 [@problem_id:2447428] 将引导你模拟一个简单的累加过程，并精确量化计算值与理论真值之间的偏差，从而揭示二进制浮点表示法中普遍存在的表示误差和累积舍入误差的微妙陷阱。", "problem": "给定实标量 $s$、$h$ 和 $t$，以及一个正整数 $M$。考虑由 $x_0 = s$ 和 $x_{n+1} = x_n + h$（对于 $n \\ge 0$）定义的序列 $\\{x_n\\}_{n\\ge 0}$。当 $x_n$ 使用二进制浮点算术计算时，由于表示和舍入效应，检查 $x_n = t$ 是否成立的朴素终止条件可能不可靠。你的任务是编写一个程序，对每个提供的测试用例，模拟该浮点序列，并报告等式 $x_n = t$ 是否在有界次数的模拟迭代中成立。\n\n对于每个测试用例，执行以下步骤：\n1. 在双精度浮点算术中初始化 $x_0 = s$。\n2. 对于 $n = 0,1,2,\\dots$，在浮点算术中精确检查 $x_n = t$ 是否成立。如果对于某个 $n \\le M$ 等式成立，记录最小的此类 $n$ 并终止该测试用例的模拟。\n3. 如果在 $0 \\le n \\le M$ 范围内没有发生相等，则在 $M$ 次增量后终止模拟。\n4. 令 $n_{\\mathrm{exec}}$ 表示你的模拟对该测试用例实际执行的增量次数，其中 $n_{\\mathrm{exec}}$ 等于观察到相等的最小 $n$（如果存在），否则为 $M$。\n5. 使用精确实数算术计算理论精确值 $x_{\\mathrm{exact}} = s + n_{\\mathrm{exec}}\\,h$，而不是在中间步骤使用浮点舍入。\n6. 令 $x_{\\mathrm{float}}$ 表示你的模拟在 $n_{\\mathrm{exec}}$ 次增量后获得的浮点值。计算绝对误差 $e = |x_{\\mathrm{float}} - x_{\\mathrm{exact}}|$，作为实数。\n\n对于每个测试用例，你的程序必须按顺序输出一个包含以下字段的列表：\n- 一个布尔值，指示是否存在 $n \\in \\{0,1,\\dots,M\\}$ 使得在浮点算术中 $x_n = t$。\n- 如果存在，则为最小的此类 $n$；否则为整数 $-1$。\n- 整数 $n_{\\mathrm{exec}}$。\n- $n_{\\mathrm{exec}}$ 次增量后的浮点值 $x_{\\mathrm{float}}$。\n- 理论精确值 $x_{\\mathrm{exact}}$，转换为浮点数用于报告。\n- 绝对误差 $e$，作为浮点数。\n\n使用以下五个测试用例。在所有测试用例中，不出现角度，也没有物理单位。以十进制写出的实数（如 $0.1$）表示以十为基的精确实数值，而涉及二的幂的表达式（如 $2^{-55}$）表示精确实数值。\n\n- 测试用例 1 (使用十进制步长的典型相等性判断失败):\n  $s = 0.0$, $h = 0.1$, $t = 1.0$, $M = 12$.\n- 测试用例 2 (步长可精确表示且目标可达):\n  $s = 0.0$, $h = 0.125$, $t = 1.0$, $M = 8$.\n- 测试用例 3 (步长不能整除区间):\n  $s = 0.0$, $h = 0.3$, $t = 1.0$, $M = 10$.\n- 测试用例 4 (使用十进制步长向零的负步长):\n  $s = 1.0$, $h = -0.1$, $t = 0.0$, $M = 12$.\n- 测试用例 5 (增量小于一个末位单位直至累积):\n  $s = 1.0$, $h = 2^{-55}$, $t = 1 + 2^{-52}$, $M = 8$.\n\n你的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果，其中每个元素本身是对应一个测试用例的列表，顺序与上文相同。例如，输出必须具有以下形式：\n$[r_1,r_2,r_3,r_4,r_5]$\n其中每个 $r_i$ 是对应于测试用例 $i$ 的列表，并且该行中任何地方都不能有空格。每个列表 $r_i$ 必须是以下形式：\n$[\\text{hit}, n_{\\min}, n_{\\mathrm{exec}}, x_{\\mathrm{float}}, x_{\\mathrm{exact}}, e]$\n字段类型如上定义。此行上的所有数值输出必须表示为十进制浮点数或整数。", "solution": "问题陈述已经过严格验证，并被确定为有效。它在科学上基于数值计算的原理，问题定义明确，具有清晰和确定性的过程，并且其表述是客观的。它提出了计算工程中一个关于浮点算术局限性的标准而又基本的问题。我们现在将着手解决。\n\n这个问题的核心在于精确实数算术与基于计算机的浮点算术之间的根本区别，后者由双精度数的 IEEE $754$ 标准规定。在模拟序列 $x_{n+1} = x_n + h$ 时，会出现两个主要的误差来源：\n\n$1$. **表示误差 (Representation Error)**：许多十进制分数，如 $0.1$ 或 $0.3$，在二进制中没有精确的有限表示。它们被存储为最接近的可表示二进制浮点数。例如，十进制数 $0.1$ 在二进制中是一个无限循环小数 ($0.0001100110011\\dots_2$)，必须被截断以适应双精度浮点数的 $52$ 位有效数。这在任何计算开始之前就引入了初始误差。相反，那些是 2 的幂的有限和的数，如 $0.125 = 1/8 = 2^{-3}$，则可以被精确表示。\n\n$2$. **舍入误差 (Round-off Error)**：每个算术运算（在此例中是加法）都以有限精度执行。$x_n + h$ 的数学精确结果会被舍入到最接近的可表示浮点数。这个在每一步引入的小误差，会在多次迭代中累积，导致计算出的序列 $x_n$ 偏离其理论路径。\n\n给定的问题要求通过模拟来展示这些效应。方法如下：\n\n首先，我们必须仔细处理输入值。提供的测试用例参数 $s$、$h$ 和 $t$ 被定义为精确实数。为了计算理论值 $x_{\\mathrm{exact}}$，我们必须使用一个高精度算术库，以避免标准的浮点不精确性。为此，我们使用 Python 的 `decimal` 模块，并配置足够高的精度，以将所有计算都当作精确计算来处理。每个测试用例的输入都被转换为这些高精度对象。\n\n其次，对每个测试用例使用标准的双精度浮点算术进行模拟，在 Python 中由 `float` 类型或 `numpy.float64` 表示。模拟遵循以下算法：\n$1$. 初始化浮点序列值 $x_{\\mathrm{float}} \\leftarrow \\text{float}(s)$。初始化 `hit` 为 `False` 和 `n_min` 为 $-1$。\n$2$. 使用索引 $n$ 从 $0$ 到 $M$（含）进行迭代。在每次迭代中，序列的当前值 $x_n$ 由 $x_{\\mathrm{float}}$ 表示。\n$3$. 在每一步 $n$，执行一次精确相等性检查：if $x_{\\mathrm{float}} == \\text{float}(t)$。\n$4$. 如果等式成立，则目标已达到。我们将 `hit` 设为 `True`，将当前索引记录为 $n_{\\mathrm{min}} = n$，将执行的增量次数设为 $n_{\\mathrm{exec}} = n$，存储 $x_{\\mathrm{float}}$ 的当前值作为最终值，并终止该测试用例的模拟循环。\n$5$. 如果等式不成立且 $n  M$，则序列前进一步：$x_{\\mathrm{float}} \\leftarrow x_{\\mathrm{float}} + \\text{float}(h)$。\n$6$. 如果循环完成而没有找到相等的情况（即，对于所有 $n \\in \\{0, 1, \\dots, M\\}$），我们将 $n_{\\mathrm{exec}} = M$。$x_{\\mathrm{float}}$ 的最终值是经过 $M$ 次增量后的结果。\n\n第三，在模拟确定了 $n_{\\mathrm{exec}}$ 和最终 $x_{\\mathrm{float}}$ 的值之后，我们计算理论量。\n$1$. 使用高精度的 `Decimal` 对象计算精确的最终值：$x_{\\mathrm{exact}} = s_{\\mathrm{exact}} + n_{\\mathrm{exec}} \\cdot h_{\\mathrm{exact}}$。\n$2$. 然后，绝对误差为 $e = |x_{\\mathrm{float}} - \\text{float}(x_{\\mathrm{exact}})|$。\n\n最后，对于每个测试用例，将六个所需的输出字段（`hit`、$n_{\\mathrm{min}}$、$n_{\\mathrm{exec}}$、$x_{\\mathrm{float}}$、$\\text{float}(x_{\\mathrm{exact}})$ 和 $e$）收集到一个列表中。\n\n具体的测试用例旨在说明不同的行为：\n- **案例 1、3 和 4**：这些案例使用的步长（$h = \\pm 0.1$, $h = 0.3$）在二进制中无法精确表示。表示误差和舍入误差的累积将导致浮点序列精确地错过目标值 $t$。因此，我们预期 `hit` 为 `False`。\n- **案例 2**：在这里，$s, h, t$（`0.0`, `0.125`, `1.0`）都是可精确表示的，因为 $h=2^{-3}$。所有加法都是精确的。序列将在 $n=8$ 时精确地达到目标 $t=1.0$。因此，我们预期 `hit` 为 `True`。\n- **案例 5**：这个案例很微妙。起始值是 $s=1.0$。对于 $1.0$ 来说，其末位单位 (ULP) 是 $2^{-52}$。增量是 $h = 2^{-55}$，它小于 $1.0$ 的 ULP 的一半。根据 IEEE 754 中的“向最近偶数舍入”规则，运算 $1.0 + 2^{-55}$ 会舍入回 $1.0$。因此，模拟的 $x_n$ 值将保持在 $1.0$ 不变，永远不会达到目标 $t = 1.0 + 2^{-52}$。然而，精确的和确实会累积。这展示了一种显著的截断误差，其中微小的增量会丢失。我们预期 `hit` 为 `False`，并且存在一个等于丢失增量总和的非零误差 $e$。", "answer": "```python\nimport numpy as np\nfrom decimal import Decimal, getcontext\n\ndef solve():\n    \"\"\"\n    Simulates a floating-point sequence and compares it with exact arithmetic.\n    \"\"\"\n    # Set a high precision for the Decimal module for \"exact\" calculations.\n    getcontext().prec = 100\n\n    def run_case_simulation(s_exact, h_exact, t_exact, M):\n        \"\"\"\n        Runs the simulation for a single test case.\n        \"\"\"\n        # Convert exact Decimal inputs to double-precision floats for simulation.\n        s_f = np.float64(s_exact)\n        h_f = np.float64(h_exact)\n        t_f = np.float64(t_exact)\n\n        x_n_float = s_f\n        hit = False\n        n_min = -1\n        \n        # Loop from n=0 to M, checking the sequence value x_n at each step.\n        for n in range(M + 1):\n            # Per problem, check for exact floating-point equality.\n            if x_n_float == t_f:\n                hit = True\n                n_min = n\n                n_exec = n\n                x_float_final = x_n_float\n                break\n            \n            # If not hit and not the last iteration, perform one increment.\n            if n  M:\n                x_n_float += h_f\n        else:  # This 'else' clause executes if the 'for' loop completes without a 'break'.\n            n_exec = M\n            # The final value is the result after M increments.\n            x_float_final = x_n_float\n\n        # Calculate the theoretical exact value and the absolute error.\n        x_exact_val = s_exact + Decimal(n_exec) * h_exact\n        error = np.abs(x_float_final - np.float64(x_exact_val))\n\n        return [hit, n_min, n_exec, x_float_final, np.float64(x_exact_val), error]\n\n    # Define test cases using Decimal for exact representation of inputs.\n    test_cases = [\n        # Test case 1: Canonical failure with decimal step.\n        (Decimal('0.0'), Decimal('0.1'), Decimal('1.0'), 12),\n        # Test case 2: Exactly representable step and reachable target.\n        (Decimal('0.0'), Decimal('0.125'), Decimal('1.0'), 8),\n        # Test case 3: Step does not subdivide the interval.\n        (Decimal('0.0'), Decimal('0.3'), Decimal('1.0'), 10),\n        # Test case 4: Negative step toward zero with decimal step.\n        (Decimal('1.0'), Decimal('-0.1'), Decimal('0.0'), 12),\n        # Test case 5: Increments below one ULP until accumulation.\n        (Decimal('1.0'), Decimal(1) / (Decimal(2)**55), Decimal(1) + Decimal(1) / (Decimal(2)**52), 8)\n    ]\n    \n    all_results = []\n    for case_params in test_cases:\n        s, h, t, M = case_params\n        result = run_case_simulation(s, h, t, M)\n        all_results.append(result)\n\n    # Format the output string to be a list of lists with no spaces.\n    # Each inner list is manually formatted to avoid spaces from default str(list).\n    result_strings = []\n    for res in all_results:\n        # Note: res[0] is a boolean, str(res[0]) is 'True' or 'False'.\n        res_str = f\"[{res[0]},{res[1]},{res[2]},{res[3]},{res[4]},{res[5]}]\"\n        result_strings.append(res_str)\n    \n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2447428"}, {"introduction": "在了解了简单的误差累积后，我们将探讨一种更为剧烈的误差形式——灾难性抵消（catastrophic cancellation）。在许多科学计算中，数学上等价的公式可能具有截然不同的数值稳定性。本练习 [@problem_id:2447454] 以计算方差为例，要求你实现并比较两种不同的算法，从而亲眼见证当数据均值远大于其标准差时，一个数值不稳定的公式会如何导致计算结果的灾难性失败。", "problem": "你需要实现一个完整的、可运行的程序，该程序演示在计算具有大均值和小偏差的数据集的方差时，由于两种不同计算公式所导致的截断和舍入误差。其理论基础是方差作为实值随机变量的二阶中心矩的定义，以及标准的浮点舍入模型。请使用以下事实作为出发点：\n- 对于一个具有有限二阶矩的实值随机变量 $X$，其方差由二阶中心矩定义：$\\operatorname{Var}(X) = \\mathbb{E}\\big[(X - \\mu)^2\\big]$，其中 $\\mu = \\mathbb{E}[X]$。\n- 对于实数，二阶原始矩满足 $\\mathbb{E}[X^2] = \\operatorname{Var}(X) + \\mu^2$。\n- 在电气和电子工程师协会 (IEEE) 的 binary64 格式（通常称为双精度）下的浮点运算，近似遵循舍入模型 $ \\operatorname{fl}(a \\,\\circ\\, b) = (a \\,\\circ\\, b)(1 + \\delta)$，其中 $|\\delta| \\le \\epsilon_{\\text{mach}}$，$\\epsilon_{\\text{mach}}$ 是机器 ε (epsilon)，而 $\\circ$ 是一种算术运算。两个几乎相等的数相减会导致灾难性抵消，从而丢失有效数字。\n\n你的程序必须：\n- 构建指定的数据集，其元素具有大均值和小偏差。\n- 使用 IEEE binary64 算术通过两种方法计算方差：\n  1. 原始矩单遍形式：计算 $\\mathbb{E}[X]$ 和 $\\mathbb{E}[X^2]$，然后构成 $\\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$。\n  2. 中心化双遍形式：首先计算 $\\mu = \\mathbb{E}[X]$，然后在第二遍中计算 $\\mathbb{E}[(X-\\mu)^2]$。\n- 使用十进制算术计算一个高精度参考方差，其精度需足够高，以至于运算中的舍入误差与 IEEE binary64 相比可以忽略不计。在高精度计算中使用中心矩定义 $\\mathbb{E}[(X-\\mu)^2]$。\n- 量化每种浮点方法相对于高精度参考值的绝对误差。\n- 为测试套件中的每个数据集，按顺序生成单行输出，其中包含一个包含五个值的列表：单遍算法方差、双遍算法方差、高精度参考方差、单遍算法结果的绝对误差以及双遍算法结果的绝对误差。\n\n所有数据集均为纯数字；本问题不涉及物理单位。也不涉及角度。\n\n测试套件，旨在覆盖正常路径、边界重点和灾难性抵消的边缘情况：\n- 测试 1（大均值周围的对称小偏差，使用整数以避免输入量化）：设 $M = 10^{8}$ 和 $D = \\{-3,-1,0,1,3\\}$。数据集为 $X = \\{ M + d \\mid d \\in D\\}$。对于精确实数，其真实方差等于偏差平方的平均值，即 $4$。\n- 测试 2（非对称小偏差，且偏差的均值非零）：设 $M = 10^{8}$ 和 $D = \\{0,1,2,3,4\\}$。数据集为 $X = \\{ M + d \\mid d \\in D\\}$。对于精确实数，其真实方差等于 $2$。\n- 测试 3（样本量更大，偏差微小且平滑变化）：设 $M = 10^{8}$ 和 $D = \\left\\{ \\frac{k-500}{1000} \\;\\middle|\\; k=0,1,\\dots,999 \\right\\}$。数据集为 $X = \\{ M + d \\mid d \\in D\\}$。对于精确实数，其真实方差是该算术网格的总体方差；它接近于 $1/12$ 减去微小偏差均值的平方，并且必须由你的高精度程序精确计算。\n- 测试 4（极端小偏差，接近于相对于均值的分辨率极限）：设 $M = 10^{8}$ 和 $D = \\{10^{-8},-10^{-8}\\}$。数据集为 $X = \\{ M + d \\mid d \\in D\\}$。对于精确实数，其真实方差等于 $10^{-16}$。\n\n高精度参考值要求：\n- 使用至少 $p = 100$ 位精度的十进制算术构建参考值。按照上述规定，使用 $M$ 和 $D$ 的精确十进制值构建数据集（例如，精确使用 $M = 100000000$ 和诸如 $(k-500)/1000$ 的有理数偏差作为精确小数）。使用双遍中心矩定义 $\\mathbb{E}[(X-\\mu)^2]$ 计算总体方差，其中 $\\mathbb{E}[\\cdot]$ 是有限集上的算术平均值。\n\n浮点计算要求：\n- 通过数值库中的标准数组，使用 IEEE binary64（双精度）计算单遍原始矩和双遍中心矩的总体方差。不要应用任何补偿求和或数值稳定技巧；以直接明了的方式使用均值和求和，以便截断和舍入误差能够显现出来。\n\n最终输出格式：\n- 你的程序应生成单行输出，其中包含一个类似 Python 列表的结构，内含四个子列表，按测试 1 到 4 的顺序对应每个测试用例。每个子列表必须包含五个浮点数：$[\\text{var\\_one\\_pass}, \\text{var\\_two\\_pass}, \\text{var\\_ref}, \\text{abs\\_err\\_one}, \\text{abs\\_err\\_two}]$。例如，一个语法上有效的输出行看起来像 $[[v_{11},v_{12},v_{13},e_{11},e_{12}],[v_{21},v_{22},v_{23},e_{21},e_{22}],\\dots]$，其中的数值由你的程序填充。\n\n不得有任何用户输入或外部文件。程序必须完全确定测试数据，执行计算，并打印所需的单行输出。输出必须是浮点数。", "solution": "用户提出了一个计算工程领域的问题，要求分析方差计算中的数值稳定性。该问题是有效的、适定的，并且具有科学依据。它探讨了数值方法中的一个基本问题：浮点运算中因灾难性抵消导致的精度损失。\n\n核心任务是比较计算数据集 $X = \\{x_1, x_2, \\dots, x_N\\}$ 的总体方差的两种公式：\n\n1.  **单遍（或原始矩）公式：** 此方法源于代数恒等式 $\\operatorname{Var}(X) = \\mathbb{E}[X^2] - (\\mathbb{E}[X])^2$。在计算上，它涉及单次遍历数据以计算值的总和与平方的总和，并由此计算出均值。该公式为：\n    $$ \\sigma^2 = \\frac{1}{N}\\sum_{i=1}^{N} x_i^2 - \\left(\\frac{1}{N}\\sum_{i=1}^{N} x_i\\right)^2 $$\n    虽然对于实数而言，该公式在数学上是精确的，但当标准差 $\\sigma$ 相对于均值 $\\mu = \\mathbb{E}[X]$ 很小时，它在数值上是不稳定的。$\\mathbb{E}[X^2]$ 和 $(\\mathbb{E}[X])^2$ 这两项会变得非常接近。具体来说，$\\mathbb{E}[X^2] = \\sigma^2 + \\mu^2$，因此该公式相当于计算 $\\sigma^2 = (\\sigma^2 + \\mu^2) - \\mu^2$。当使用有限精度浮点算术（如 IEEE binary64）进行求值时，这涉及两个非常大且几乎相等的数相减。此操作是灾难性抵消的典型例子。两个数的首部有效数字相互抵消，导致微小差值的大部分甚至全部有效数字丢失。在计算 $\\mathbb{E}[X^2]$ 和 $(\\mathbb{E}[X])^2$ 时的舍入误差（量级约为 $\\mu^2 \\epsilon_{\\text{mach}}$）成为最终结果的主导部分，可能产生一个非常不准确甚至为负的方差值。\n\n2.  **双遍（或中心矩）公式：** 此方法更紧密地遵循方差的定义，即离均差平方的均值。它需要对数据进行两次遍历。\n    $$ \\mu = \\frac{1}{N}\\sum_{i=1}^{N} x_i $$\n    $$ \\sigma^2 = \\frac{1}{N}\\sum_{i=1}^{N} (x_i - \\mu)^2 $$\n    在第一遍中，计算均值 $\\mu$。在第二遍中，使用这个计算出的均值来找到平方偏差 $(x_i - \\mu)^2$，然后对其求平均。这种方法在数值上要稳健得多。虽然仍然执行减法 $x_i - \\mu$，但结果是一组小数（偏差）。对这些小数进行平方和求和不涉及大数相减。误差的主要来源是初始 $\\mu$ 的计算。计算出的均值 $\\hat{\\mu}$ 中的误差会传播到偏差中。然而，这个误差通常很小。对于具有大均值 $M$ 和小偏差的数据，计算出的均值的误差量级约为 $M\\epsilon_{\\text{mach}}$。只要此误差相对于真实偏差的量级而言很小，双遍算法就能得出准确的结果。\n\n对于此问题，还需要进行高精度参考计算。这将使用 Python 的 `decimal` 模块，以 $p=100$ 位的精度来执行。在此精度水平上，与标准的 binary64 浮点运算相比，舍入误差可以忽略不计，从而提供了一个“基准真相”(ground truth)，用以比较另外两种方法。\n\n程序将被结构化以处理四个特定的测试用例。每个用例都使用一个具有大均值（$M=10^8$）和小偏差的数据集，旨在暴露单遍公式的数值缺陷。\n\n-   **测试 1 和 2：** 偏差为小整数。预计双遍方法将非常准确。预计单遍方法将因灾难性抵消而失败。\n-   **测试 3：** 一个具有平滑变化的微小有理数偏差的较大数据集。预计行为相似。\n-   **测试 4：** 偏差极小（$d = \\pm 10^{-8}$），接近 binary64 相对于均值的分辨率极限。对于 $x = M+d$，$d$ 的值小于量级为 $M$ 的数可能有的最小增量（即 $M \\cdot \\epsilon_{\\text{mach}} \\approx 10^8 \\cdot 2.22 \\times 10^{-16} = 2.22 \\times 10^{-8}$）。因此，$fl(M+d)$ 将被舍入为 $M$ 本身。这揭示了另一种误差来源：初始数据表示中的信息丢失，这将导致两种浮点方法计算出的方差都为 $0$。\n\n实现将通过定义一个函数来进行，该函数接收一个数据集，使用三种方法（单遍浮点、双遍浮点和高精度参考）计算方差，计算浮点方法的绝对误差，并返回结果。将为每个测试用例调用此函数，并将收集到的结果格式化为指定的输出字符串。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom decimal import Decimal, getcontext\n\ndef solve():\n    \"\"\"\n    Computes and compares variance using three different methods to demonstrate\n    truncation and round-off errors.\n    \"\"\"\n    # Set the precision for decimal arithmetic to 100 digits, as required.\n    getcontext().prec = 100\n\n    def analyze_dataset(M_str: str, D_list: list):\n        \"\"\"\n        Performs the full analysis for a given dataset definition.\n\n        Args:\n            M_str: The large mean component as a string for exact Decimal conversion.\n            D_list: A list of deviation values (as Decimal objects).\n\n        Returns:\n            A list containing the five required values:\n            [var_one_pass, var_two_pass, var_ref, abs_err_one, abs_err_two]\n        \"\"\"\n        # 1. High-precision reference calculation using the decimal module.\n        # This serves as the ground truth.\n        M_dec = Decimal(M_str)\n        X_dec = [M_dec + d for d in D_list]\n        N_dec = Decimal(len(X_dec))\n        \n        # Use two-pass formula for the reference calculation.\n        mu_dec = sum(X_dec) / N_dec\n        var_ref = sum([(x - mu_dec)**2 for x in X_dec]) / N_dec\n\n        # 2. Floating-point calculations using numpy (IEEE binary64).\n        # Construct the dataset using standard float64.\n        # Note: float() conversion from Decimal can introduce small errors,\n        # but the dominant error source is the variance algorithm itself.\n        X_fp = np.array([float(x) for x in X_dec], dtype=np.float64)\n        \n        # Method 1: One-pass (raw-moment) formula. Prone to catastrophic cancellation.\n        # sigma^2 = E[X^2] - (E[X])^2\n        mean_of_squares = np.mean(X_fp**2)\n        square_of_mean = np.mean(X_fp)**2\n        var_one_pass = mean_of_squares - square_of_mean\n        \n        # Method 2: Two-pass (centered-moment) formula. More numerically stable.\n        # sigma^2 = E[(X - E[X])^2]\n        mu_fp = np.mean(X_fp)\n        var_two_pass = np.mean((X_fp - mu_fp)**2)\n        \n        # 3. Quantify absolute errors.\n        abs_err_one = abs(var_one_pass - float(var_ref))\n        abs_err_two = abs(var_two_pass - float(var_ref))\n        \n        return [var_one_pass, var_two_pass, float(var_ref), abs_err_one, abs_err_two]\n\n    # --- Define and run all test cases ---\n    test_cases_defs = [\n        # Test 1: Symmetric small integer deviations. True Var = 4.\n        {'M': '1e8', 'D': [Decimal(s) for s in ['-3', '-1', '0', '1', '3']]},\n        \n        # Test 2: Non-symmetric small integer deviations. True Var = 2.\n        {'M': '1e8', 'D': [Decimal(s) for s in ['0', '1', '2', '3', '4']]},\n        \n        # Test 3: Larger sample with small rational deviations.\n        {'M': '1e8', 'D': [(Decimal(k) - Decimal(500)) / Decimal(1000) for k in range(1000)]},\n        \n        # Test 4: Extremely small deviations at the limit of float64 resolution. True Var = 1e-16.\n        {'M': '1e8', 'D': [Decimal('1e-8'), Decimal('-1e-8')]}\n    ]\n\n    all_results = []\n    for case in test_cases_defs:\n        result = analyze_dataset(case['M'], case['D'])\n        all_results.append(result)\n\n    # Final print statement in the exact required format.\n    # The format is a list of lists, e.g., [[v1,v2,...],[v1,v2,...]]\n    formatted_inner_lists = []\n    for res_list in all_results:\n        # Format each inner list as \"[v1,v2,v3,e1,e2]\"\n        formatted_list_str = f\"[{','.join(map(str, res_list))}]\"\n        formatted_inner_lists.append(formatted_list_str)\n    \n    # Join the inner lists into the final output format \"[ [...], [...], ... ]\"\n    final_output = f\"[{','.join(formatted_inner_lists)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2447454"}, {"introduction": "最后，我们将视野从单个算术运算扩展到整个迭代算法的稳定性。递推关系是计算物理中生成函数序列（如勒让德多项式）的强大工具，但其数值稳定性取决于所计算的解是数学上的“主导解”还是“极小解”。本练习 [@problem_id:2435686] 将让你深入研究计算勒让德多项式 $P_n(x)$ 的标准前向递推公式的稳定性，你将发现对于某些输入值 $x$，这个看似直接的计算方法为何会产生巨大的误差，从而理解算法稳定性在实践中的重要性。", "problem": "要求你研究在使用浮点运算通过三项递推关系计算勒让德多项式 $P_n(x)$ 时，舍入误差的数值传播情况。勒让德多项式对所有实数 $x$ 定义，其初始条件为 $P_0(x)=1$，$P_1(x)=x$，以及递推关系\n$$(n+1)P_{n+1}(x)=(2n+1)\\,x\\,P_n(x)-n\\,P_{n-1}(x),\\quad n\\ge 1.$$\n假设一个程序使用标准双精度浮点运算，从 $P_0(x)$ 和 $P_1(x)$ 开始，通过正向使用该递推关系来计算 $\\widehat{P}_n(x)$。将 $n$ 次的相对误差定义为\n$$E(n;x)=\\frac{\\left|\\widehat{P}_n(x)-P_n(x)\\right|}{\\max\\{1,\\left|P_n(x)\\right|\\}}.$$\n对于一个固定的容差 $\\tau$，如果 $E(n;x)\\tau$，则称数对 $(x,n)$ 是不稳定的。在本任务中，取 $\\tau=10^{-12}$。\n\n你的程序必须对每个输入数对 $(x,N_{\\max})$，计算满足 $E(n;x)\\tau$ 的最小次数 $n\\in\\{0,1,\\dots,N_{\\max}\\}$。如果不存在这样的 $n$，程序必须对该数对返回 $N_{\\max}+1$。所有计算都应以无量纲单位进行。\n\n使用以下输入数对 $(x,N_{\\max})$ 测试集：\n- $(0.0,100)$,\n- $(0.5,150)$,\n- $(0.99,200)$,\n- $(1.0,300)$,\n- $(-1.0,300)$,\n- $(1.1,50)$,\n- $(-1.2,50)$.\n\n最终输出格式：你的程序应产生单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表，顺序与测试集相同（例如 $[r_1,r_2,\\dots,r_7]$），其中每个 $r_i$ 是对应测试对所需返回的整数。不允许有其他输出。", "solution": "该问题要求分析勒让德多项式 $P_n(x)$ 的三项正向递推关系的数值稳定性。这是数值分析中的一个标准课题，其解决方案基于线性差分方程的数学理论。\n\n主导的递推关系由下式给出\n$$ (n+1)P_{n+1}(x)=(2n+1)xP_n(x) - nP_{n-1}(x), \\quad n \\ge 1 $$\n初始条件为 $P_0(x)=1$ 和 $P_1(x)=x$。这是一个二阶线性齐次差分方程。因此，对于给定的 $x$，它有两个线性无关的解。对其中一个解进行数值计算的稳定性，关键取决于当 $n$ 很大时两个解的渐近行为。\n\n设两个基本解为 $f_n$ 和 $g_n$。如果当 $n$ 很大时，一个解的量级增长，而另一个解衰减或增长得更慢（即 $\\lim_{n \\to \\infty} f_n/g_n = 0$），那么 $f_n$ 被称为*极小*（或隐性）解，而 $g_n$ 是*主导*解。\n- 正向递推仅在计算主导解时是稳定的。任何舍入误差都不可避免地会将主导解的一个小分量引入计算中，如果我们试图计算的是极小解，这个误差将在后续步骤中被放大。这个寄生分量最终会压倒我们想要计算的极小解，导致数值精度的损失。\n- 相反地，反向递推是计算极小解的稳定方法。\n\n勒让德递推关系的两个基本解是勒让德多项式 $P_n(x)$ 和第二类勒让德函数 $Q_n(x)$。它们的渐近行为决定了给定正向递推的稳定性：\n1.  对于 $|x| > 1$：多项式 $P_n(x)$ 随 $n$ 指数增长，其行为类似于 $P_n(x) \\sim (x+\\sqrt{x^2-1})^n$。函数 $Q_n(x)$ 衰减到零。因此，$P_n(x)$ 是主导解。预计正向递推在计算 $P_n(x)$ 时是数值稳定的。\n2.  对于 $|x|  1$：多项式是有界的，$|P_n(x)| \\le 1$。然而，当 $n \\to \\infty$ 时，函数 $Q_n(x)$ 是无界的。在这种情况下，$P_n(x)$ 是极小解。因此，正向递推是计算 $P_n(x)$ 的一种不稳定方法。我们预期随着 $n$ 的增加，数值计算出的序列 $\\widehat{P}_n(x)$ 将会偏离真实的序列 $P_n(x)$。\n3.  对于 $|x| = 1$：在 $x=1$ 处，对所有 $n$ 都有 $P_n(1)=1$。在 $x=-1$ 处，$P_n(-1)=(-1)^n$。这些量级恒定的序列能精确满足递推关系。对一个小误差 $\\epsilon$ 的传播进行分析表明，误差增长最多是关于 $n$ 的代数增长（线性或二次）。如此缓慢的增长，在给定的 $n \\le 300$ 范围内，不太可能导致误差超过微小的容差 $\\tau=10^{-12}$。\n4.  对于 $x=0$：递推关系简化为 $(n+1)P_{n+1}(0) = -nP_{n-1}(0)$。从 $P_0(0)=1$ 和 $P_1(0)=0$ 开始，计算只涉及简单的有理数，并且预计是稳定的。\n\n为了执行所需的验证，必须将数值计算的值 $\\widehat{P}_n(x)$ 与真实值 $P_n(x)$ 进行比较。“真实”值是使用高保真度的稳定算法获得的。`scipy.special.eval_legendre` 函数通过采用诸如反向递推或渐近级数等方法（这些方法在各自的定义域内是稳定的）来提供这样一个参考值。\n\n对每个输入数对 $(x, N_{\\text{max}})$ 解决该问题的算法如下：\n- 设定容差 $\\tau = 10^{-12}$。\n- 用 $\\widehat{P}_0(x)=1.0$ 和 $\\widehat{P}_1(x)=x$ 初始化数值计算序列。\n- 对于从 $0$ 到 $N_{\\text{max}}$ 的每个次数 $n$：\n    1. 使用正向递推计算 $\\widehat{P}_n(x)$。对于 $n \\ge 2$，即 $\\widehat{P}_n(x) = \\frac{(2n-1)x\\widehat{P}_{n-1}(x) - (n-1)\\widehat{P}_{n-2}(x)}{n}$。\n    2. 从 `scipy.special.eval_legendre(n, x)` 获取参考值 $P_n(x)$。\n    3. 计算误差 $E(n;x) = \\frac{|\\widehat{P}_n(x) - P_n(x)|}{\\max\\{1, |P_n(x)|\\}}$。\n    4. 如果 $E(n;x) > \\tau$，则 $n$ 是第一个观察到不稳定性的次数。返回值 $n$，并终止对该 $(x, N_{\\text{max}})$ 数对的处理。\n- 如果循环完成而对于任何 $n \\in \\{0, 1, \\dots, N_{\\text{max}}\\}$ 误差条件都未满足，则认为在该给定范围内计算是稳定的。在这种情况下，返回 $N_{\\text{max}}+1$。\n\n这个过程在一个 Python 程序中实现，使用标准双精度浮点运算。分析预测，在 $|x|  1$ 的情况下（即 $x=0.5$ 和 $x=0.99$）会发现不稳定性，而在指定限制内的其他情况下则不会。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import special\n\ndef solve():\n    \"\"\"\n    Computes the smallest degree n for which the forward recurrence of\n    Legendre polynomials becomes unstable for given (x, N_max) pairs.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        (0.0, 100),\n        (0.5, 150),\n        (0.99, 200),\n        (1.0, 300),\n        (-1.0, 300),\n        (1.1, 50),\n        (-1.2, 50),\n    ]\n\n    results = []\n    for x_val, N_max in test_cases:\n        result = find_unstable_n(float(x_val), N_max)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef find_unstable_n(x, N_max):\n    \"\"\"\n    For a given x and N_max, find the smallest n where the numerical\n    computation of P_n(x) via forward recurrence becomes unstable.\n    \"\"\"\n    tau = 1e-12\n\n    # We compute P_hat_n and compare with P_true_n for n=0, 1, ..., N_max.\n    # The true value is obtained from scipy's stable implementation.\n\n    # Case n = 0\n    P_hat_0 = 1.0\n    P_true_0 = special.eval_legendre(0, x)\n    error_0 = abs(P_hat_0 - P_true_0) / max(1.0, abs(P_true_0))\n    if error_0 > tau:\n        return 0\n    \n    if N_max == 0:\n        return N_max + 1\n\n    # Case n = 1\n    P_hat_1 = x\n    P_true_1 = special.eval_legendre(1, x)\n    error_1 = abs(P_hat_1 - P_true_1) / max(1.0, abs(P_true_1))\n    if error_1 > tau:\n        return 1\n\n    # Setup for recurrence loop\n    # P_hat_prev corresponds to P_{n-2} and P_hat_curr to P_{n-1} when computing P_n\n    P_hat_prev = P_hat_0\n    P_hat_curr = P_hat_1\n\n    # Loop for degree n = 2, 3, ..., N_max.\n    # The recurrence is (k+1)P_{k+1} = (2k+1)xP_k - kP_{k-1}.\n    # To compute P_hat_n, we use k=n-1.\n    for n in range(2, N_max + 1):\n        k = n - 1\n        \n        # Forward recurrence computation\n        P_hat_next = ((2 * k + 1) * x * P_hat_curr - k * P_hat_prev) / (k + 1)\n\n        # Get the \"true\" value for comparison\n        P_true_next = special.eval_legendre(n, x)\n\n        # Calculate the relative error\n        denominator = max(1.0, abs(P_true_next))\n        error = abs(P_hat_next - P_true_next) / denominator\n\n        # Check for instability\n        if error > tau:\n            return n\n\n        # Update values for the next iteration\n        P_hat_prev = P_hat_curr\n        P_hat_curr = P_hat_next\n\n    # If the loop completes, no instability was found up to N_max.\n    return N_max + 1\n\nsolve()\n```", "id": "2435686"}]}