{"hands_on_practices": [{"introduction": "我们将通过实现两个基础算法——幂迭代和反幂迭代——来开启我们的实践之旅。这个练习 [@problem_id:2428639] 将让你把这些方法应用于一个代表离散化二维拉普拉斯算子的矩阵上，这是物理学和工程学中的一个基石算子。通过找到其最大和最小的特征值，你将获得实现这些迭代技术的实践经验，并了解它们如何被用于分析基本的物理系统。", "problem": "给定一个由实对称正定矩阵组成的族，该族矩阵由矩形上带齐次狄利克雷边界条件的负二维拉普拉斯算子经有限差分法离散化后得到。对于整数 $n_x \\ge 1$ 和 $n_y \\ge 1$，以及正实数边长 $L_x > 0$ 和 $L_y > 0$，定义均匀网格间距 $h_x = L_x/(n_x+1)$ 和 $h_y = L_y/(n_y+1)$。设 $T_x \\in \\mathbb{R}^{n_x \\times n_x}$ 和 $T_y \\in \\mathbb{R}^{n_y \\times n_y}$ 为三对角矩阵\n$$\nT_x = \\frac{1}{h_x^2}\\,\\mathrm{tridiag}(-1,\\,2,\\,-1),\\qquad\nT_y = \\frac{1}{h_y^2}\\,\\mathrm{tridiag}(-1,\\,2,\\,-1),\n$$\n并设 $I_x \\in \\mathbb{R}^{n_x \\times n_x}$ 和 $I_y \\in \\mathbb{R}^{n_y \\times n_y}$ 为单位矩阵。离散算子矩阵 $A \\in \\mathbb{R}^{(n_x n_y) \\times (n_x n_y)}$ 由克罗内克和定义\n$$\nA = I_y \\otimes T_x \\;+\\; T_y \\otimes I_x.\n$$\n这表示在矩形 $[0,L_x]\\times[0,L_y]$ 边界上施加齐次狄利克雷边界条件时，内部网格点上负拉普拉斯算子的标准五点差分格式。\n\n设 $n = n_x n_y$ 并设 $x_0 \\in \\mathbb{R}^{n}$ 是一个所有分量均为 $1$ 的向量。考虑以下由 $A$ 和 $x_0$ 构造的两个单位向量序列：\n\n1. 定义 $u_0 = x_0/\\|x_0\\|_2$，并对整数 $t_{\\mathrm{up}} \\ge 1$，为 $k=0,1,\\dots,t_{\\mathrm{up}}-1$ 递归定义 $u_k$ 如下：\n$$\n\\tilde{u}_{k+1} = A u_k,\\qquad u_{k+1} = \\frac{\\tilde{u}_{k+1}}{\\|\\tilde{u}_{k+1}\\|_2}.\n$$\n令 $\\lambda_{\\mathrm{up}}$ 为瑞利商\n$$\n\\lambda_{\\mathrm{up}} = \\frac{u_{t_{\\mathrm{up}}}^\\top A\\,u_{t_{\\mathrm{up}}}}{u_{t_{\\mathrm{up}}}^\\top u_{t_{\\mathrm{up}}}}.\n$$\n\n2. 定义 $w_0 = x_0/\\|x_0\\|_2$，并对整数 $t_{\\mathrm{low}} \\ge 1$，为 $k=0,1,\\dots,t_{\\mathrm{low}}-1$ 递归定义 $w_k$ 如下：\n$$\n\\tilde{w}_{k+1} \\text{ 是 } A \\tilde{w}_{k+1} = w_k \\text{ 的唯一解},\\qquad w_{k+1} = \\frac{\\tilde{w}_{k+1}}{\\|\\tilde{w}_{k+1}\\|_2}.\n$$\n令 $\\lambda_{\\mathrm{low}}$ 为瑞利商\n$$\n\\lambda_{\\mathrm{low}} = \\frac{w_{t_{\\mathrm{low}}}^\\top A\\,w_{t_{\\mathrm{low}}}}{w_{t_{\\mathrm{low}}}^\\top w_{t_{\\mathrm{low}}}}.\n$$\n\n您的任务是编写一个程序，对于下方的每个测试案例，严格按照定义构建矩阵 $A$，使用相同的初始向量 $x_0$ 和指定的迭代次数生成上述两个序列，并输出按规定计算的两个标量 $\\lambda_{\\mathrm{up}}$ 和 $\\lambda_{\\mathrm{low}}$。所有计算都是纯数值且无量纲的；不需要任何物理单位。如果您的方法内部引入了角度，应以弧度为单位，尽管本问题不要求使用角度。\n\n测试套件 (每个元组为 $(n_x,n_y,L_x,L_y,t_{\\mathrm{up}},t_{\\mathrm{low}})$):\n- 案例 1: $(20,\\,20,\\,1.0,\\,1.0,\\,80,\\,80)$\n- 案例 2: $(1,\\,1,\\,1.0,\\,1.0,\\,10,\\,10)$\n- 案例 3: $(12,\\,8,\\,2.0,\\,1.0,\\,100,\\,100)$\n\n您的程序必须生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表。对于每个测试案例，输出一个双元素列表 $[\\lambda_{\\mathrm{up}},\\lambda_{\\mathrm{low}}]$，两个值都四舍五入到小数点后恰好六位。因此，总输出应为一个包含三个双元素列表的列表，顺序与上述案例一致，例如：\n$[[\\ell_{1,\\mathrm{up}},\\ell_{1,\\mathrm{low}}],[\\ell_{2,\\mathrm{up}},\\ell_{2,\\mathrm{low}}],[\\ell_{3,\\mathrm{up}},\\ell_{3,\\mathrm{low}}]]$，其中每个 $\\ell$ 是一个四舍五入到小数点后六位的十进制表示。", "solution": "该问题陈述已经过验证，并被认定为有效。它具有科学依据、是适定的，并为获得唯一、可验证的解提供了所有必要信息。该问题要求实现线性代数中的两个基本数值算法——幂迭代法和反幂迭代法——以找到表示离散物理算子的矩阵的极端特征值。\n\n矩阵 $A$ 表示在矩形域 $[0, L_x] \\times [0, L_y]$ 上带有齐次狄利克雷边界条件的负二维拉普拉斯算子 $-\\nabla^2 = -(\\partial^2/\\partial x^2 + \\partial^2/\\partial y^2)$ 的五点有限差分格式离散化。该区域被离散化为一个 $(n_x+2) \\times (n_y+2)$ 的点网格，其中有 $n_x n_y$ 个内部点。矩阵 $A$ 作用于这些内部点上的函数值向量。\n\n将 $A$ 构造为克罗内克和 $A = I_y \\otimes T_x + T_y \\otimes I_x$ 是可分离二维算子的标准数学表述。矩阵 $T_x$ 和 $T_y$ 分别是其各自坐标轴上的一维二阶导数算子 $-d^2/dx^2$ 的缩放离散化。具体来说，矩阵 $\\mathrm{tridiag}(-1, 2, -1)$ 是离散一维拉普拉斯算子的一个缩放版本。由于 $A$ 是对称正定矩阵之和（因为 $T_x$ 和 $T_y$ 是缩放后的对角占优M-矩阵），因此可以保证 $A$ 是对称正定的，并拥有实数正特征值。\n\n用于计算 $\\lambda_{\\mathrm{up}}$ 的第一个序列是幂迭代法。该迭代算法将矩阵 $A$ 重复应用于一个向量。对于一个给定的初始向量 $u_0$，若其在对应于主特征值（模最大的特征值）的特征向量方向上具有非零分量，则序列 $u_k = A^k u_0 / \\|A^k u_0\\|_2$ 会收敛到该特征向量。对于一个正定矩阵 $A$，主特征值就是最大特征值 $\\lambda_{\\max}$。该方法的核心是递推关系 $\\tilde{u}_{k+1} = A u_k$，随后进行归一化 $u_{k+1} = \\tilde{u}_{k+1} / \\|\\tilde{u}_{k+1}\\|_2$。经过足够多的迭代次数 $t_{\\mathrm{up}}$ 后，向量 $u_{t_{\\mathrm{up}}}$ 就是相应特征向量的一个良好近似。\n\n用于计算 $\\lambda_{\\mathrm{low}}$ 的第二个序列是反幂迭代法。这在数学上等同于将幂迭代法应用于逆矩阵 $A^{-1}$。$A^{-1}$ 的特征值是 $A$ 的特征值的倒数。因此，$A^{-1}$ 的最大特征值对应于 $A$ 的最小特征值。迭代步骤需要求解线性方程组 $A \\tilde{w}_{k+1} = w_k$ 以得到 $\\tilde{w}_{k+1}$，这比显式计算逆矩阵 $A^{-1}$ 再执行矩阵-向量乘法在计算上更高效。随后的归一化 $w_{k+1} = \\tilde{w}_{k+1} / \\|\\tilde{w}_{k+1}\\|_2$ 完成一次迭代。经过 $t_{\\mathrm{low}}$ 次迭代后，向量 $w_{t_{\\mathrm{low}}}$ 收敛到与 $A$ 的最小特征值 $\\lambda_{\\min}$ 相关联的特征向量。\n\n最后，瑞利商 $R_A(v) = (v^\\top A v) / (v^\\top v)$ 在给定一个近似特征向量 $v$ 时，提供了对 $A$ 的一个特征值的估计。对于一个归一化向量 $v$（即 $v^\\top v = \\|v\\|_2^2 = 1$），该式简化为 $R_A(v) = v^\\top A v$。问题正确地将 $\\lambda_{\\mathrm{up}}$ 和 $\\lambda_{\\mathrm{low}}$ 定义为最终迭代向量 $u_{t_{\\mathrm{up}}}$ 和 $w_{t_{\\mathrm{low}}}$ 的瑞利商。这些值将是 $\\lambda_{\\max}$ 和 $\\lambda_{\\min}$ 的高精度近似。\n\n算法流程如下：\n$1$. 对于每个测试案例，定义参数 $n_x$、$n_y$、$L_x$、$L_y$、$t_{\\mathrm{up}}$ 和 $t_{\\mathrm{low}}$。\n$2$. 计算网格间距 $h_x = L_x / (n_x+1)$ 和 $h_y = L_y / (n_y+1)$。\n$3$. 按规定构建一维算子矩阵 $T_x \\in \\mathbb{R}^{n_x \\times n_x}$ 和 $T_y \\in \\mathbb{R}^{n_y \\times n_y}$。\n$4$. 使用克罗内克和 $A = I_y \\otimes T_x + T_y \\otimes I_x$ 构建完整的二维算子矩阵 $A \\in \\mathbb{R}^{(n_x n_y) \\times (n_x n_y)}$。\n$5$. 计算 $\\lambda_{\\mathrm{up}}$：初始化一个单位向量 $u_0$，使用幂迭代法递推公式 $u_{k+1} \\propto A u_k$ 迭代 $t_{\\mathrm{up}}$ 次。然后计算瑞利商 $\\lambda_{\\mathrm{up}} = u_{t_{\\mathrm{up}}}^\\top A u_{t_{\\mathrm{up}}}$。\n$6$. 计算 $\\lambda_{\\mathrm{low}}$：初始化一个单位向量 $w_0$，通过求解 $A \\tilde{w}_{k+1} = w_k$ 并归一化 $w_{k+1} = \\tilde{w}_{k+1} / \\|\\tilde{w}_{k+1}\\|_2$ 迭代 $t_{\\mathrm{low}}$ 次。然后计算瑞利商 $\\lambda_{\\mathrm{low}} = w_{t_{\\mathrm{low}}}^\\top A w_{t_{\\mathrm{low}}}$。\n$7$. 收集并按要求格式化结果。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve as sp_solve\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases by constructing the discrete\n    Laplacian matrix and applying power and inverse power iterations to find\n    approximations of the largest and smallest eigenvalues.\n    \"\"\"\n    test_cases = [\n        (20, 20, 1.0, 1.0, 80, 80),\n        (1, 1, 1.0, 1.0, 10, 10),\n        (12, 8, 2.0, 1.0, 100, 100),\n    ]\n\n    results = []\n    for params in test_cases:\n        nx, ny, Lx, Ly, t_up, t_low = params\n\n        # Grid spacings\n        hx = Lx / (nx + 1)\n        hy = Ly / (ny + 1)\n\n        # Construct 1D tridiagonal matrices\n        diag_x = 2 * np.ones(nx)\n        offdiag_x = -1 * np.ones(nx - 1)\n        Tx = (1 / hx**2) * (np.diag(diag_x) + np.diag(offdiag_x, k=1) + np.diag(offdiag_x, k=-1))\n\n        diag_y = 2 * np.ones(ny)\n        offdiag_y = -1 * np.ones(ny - 1)\n        Ty = (1 / hy**2) * (np.diag(diag_y) + np.diag(offdiag_y, k=1) + np.diag(offdiag_y, k=-1))\n\n        # Identity matrices\n        Ix = np.eye(nx)\n        Iy = np.eye(ny)\n\n        # Construct 2D operator matrix A using Kronecker sum\n        A = np.kron(Iy, Tx) + np.kron(Ty, Ix)\n\n        # Dimension of the system\n        n = nx * ny\n\n        # Initial vector of all ones\n        x0 = np.ones(n)\n\n        # --- Power Iteration for lambda_up ---\n        u = x0 / np.linalg.norm(x0)\n        for _ in range(t_up):\n            u_tilde = A @ u\n            u = u_tilde / np.linalg.norm(u_tilde)\n        \n        # Rayleigh quotient for lambda_up\n        # Since u is a unit vector, u.T @ u = 1\n        lambda_up = u.T @ (A @ u)\n\n        # --- Inverse Iteration for lambda_low ---\n        w = x0 / np.linalg.norm(x0)\n        for _ in range(t_low):\n            # Solve A * w_tilde = w\n            w_tilde = sp_solve(A, w, assume_a='pos')\n            w = w_tilde / np.linalg.norm(w_tilde)\n            \n        # Rayleigh quotient for lambda_low\n        # Since w is a unit vector, w.T @ w = 1\n        lambda_low = w.T @ (A @ w)\n        \n        results.append([lambda_up, lambda_low])\n\n    # Format output\n    results_str = [f\"[{res[0]:.6f},{res[1]:.6f}]\" for res in results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "2428639"}, {"introduction": "尽管幂法和反幂法擅长寻找极端的特征值，但我们常常需要找到谱“中间”的特征值。这需要使用带位移的反幂迭代技术。在实现该算法之前，这个概念性练习 [@problem_id:2427117] 挑战你确定理论上的最优位移 $\\sigma$ 以分离出特定的特征值。理解这一原理是最大化算法收敛速度的关键，并为更高级的方法奠定了基础。", "problem": "一个实对称矩阵 $A \\in \\mathbb{R}^{4 \\times 4}$ 具有不同的特征值 $\\{10,\\, 9.9,\\, 5,\\, 0.1\\}$。你将应用带有恒定偏移量 $\\sigma \\in \\mathbb{R}$ 的偏移反迭代法来计算与特征值 $9.9$ 相关联的特征向量。确定在偏移反迭代法下，原则上能最有效地分离特征值 $9.9$ 的 $\\sigma$ 值。请以单个实数的形式提供你的答案。无需四舍五入。", "solution": "对问题陈述进行验证。\n\n**步骤 1：提取已知条件**\n- 矩阵 $A$ 是一个实对称矩阵，$A \\in \\mathbb{R}^{4 \\times 4}$。\n- $A$ 的不同特征值集合为 $\\{\\lambda_1, \\lambda_2, \\lambda_3, \\lambda_4\\} = \\{10,\\, 9.9,\\, 5,\\, 0.1\\}$。\n- 使用的方法是带有恒定偏移量 $\\sigma \\in \\mathbb{R}$ 的偏移反迭代法。\n- 目标是计算与特征值 $9.9$ 相关联的特征向量。\n- 目的是找到“最有效地分离”特征值 $9.9$ 的 $\\sigma$ 值。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据，因为它基于计算工程和线性代数中成熟的数值方法——偏移反迭代法。该问题是适定的；术语“最有效地分离”在此上下文中有一个标准的解释，即指收敛速度的最大化。该问题是客观的，不包含主观或模糊的语言。所有必要的数据（矩阵的完整谱）都已提供，并且没有矛盾之处。因此，该问题被认为是有效的。\n\n**步骤 3：结论与行动**\n问题有效。将提供完整的解答。\n\n**解答推导**\n我们首先陈述偏移反迭代法的原理。该方法是幂迭代算法的一个变体，应用于矩阵 $B = (A - \\sigma I)^{-1}$，其中 $A$ 是原始矩阵，$\\sigma$ 是一个标量偏移量，$I$ 是单位矩阵。\n\n设矩阵 $A$ 的特征值为 $\\lambda_k$。则矩阵 $(A - \\sigma I)$ 的特征值为 $(\\lambda_k - \\sigma)$。因此，迭代矩阵 $B = (A - \\sigma I)^{-1}$ 的特征值为 $\\mu_k = \\frac{1}{\\lambda_k - \\sigma}$。\n\n幂迭代法应用于矩阵 $B$ 时，会收敛到与 $B$ 的最大模特征值相对应的特征向量。设 $B$ 的这个主特征值为 $\\mu_{dom}$。为了使偏移反迭代法收敛到与 $A$ 的特定特征值 $\\lambda_{target}$ 相关联的特征向量，对应的特征值 $\\mu_{target} = \\frac{1}{\\lambda_{target} - \\sigma}$ 必须是 $B$ 的主特征值。该条件表示为：\n$$|\\mu_{target}| > |\\mu_k| \\quad \\forall k \\text{ such that } \\lambda_k \\neq \\lambda_{target}$$\n这个不等式等价于：\n$$\\frac{1}{|\\lambda_{target} - \\sigma|} > \\frac{1}{|\\lambda_k - \\sigma|} \\quad \\forall k \\text{ such that } \\lambda_k \\neq \\lambda_{target}$$\n这可以简化为 $\\sigma$ 必须比任何其他特征值 $\\lambda_k$ 更接近 $\\lambda_{target}$ 的条件：\n$$|\\lambda_{target} - \\sigma|  |\\lambda_k - \\sigma| \\quad \\forall k \\text{ such that } \\lambda_k \\neq \\lambda_{target}$$\n\n问题要求找到“最有效地分离”特征值 $\\lambda_{target} = 9.9$ 的偏移量 $\\sigma$。在迭代方法的背景下，“最有效”被解释为实现最快的收敛速度。幂迭代法的收敛速度由迭代矩阵的第二大模特征值（次主特征值，$\\mu_{sub}$）与主特征值的模之比决定。收敛因子为 $R = \\frac{|\\mu_{sub}|}{|\\mu_{dom}|}$。为了最大化收敛速度，必须最小化这个比率 $R$。\n\n在我们的例子中，$\\mu_{dom} = \\mu_{target} = \\frac{1}{9.9 - \\sigma}$。次主特征值 $\\mu_{sub}$ 对应于 $A$ 的某个特征值，我们称之为 $\\lambda_{other}$，它是距离偏移量 $\\sigma$ 第二近的特征值。因此，$\\mu_{sub} = \\frac{1}{\\lambda_{other} - \\sigma}$。\n\n因此，需要最小化的收敛比率为：\n$$R(\\sigma) = \\frac{|\\mu_{sub}|}{|\\mu_{dom}|} = \\frac{\\left| \\frac{1}{\\lambda_{other} - \\sigma} \\right|}{\\left| \\frac{1}{9.9 - \\sigma} \\right|} = \\frac{|9.9 - \\sigma|}{|\\lambda_{other} - \\sigma|}$$\n总的收敛因子由“最坏情况”的邻近特征值决定，因此我们必须寻求最小化可能的最大比率：\n$$\\min_{\\sigma} \\left( \\max_{k \\neq target} \\frac{|9.9 - \\sigma|}{|\\lambda_k - \\sigma|} \\right)$$\n其他特征值的集合是 $\\{10, 5, 0.1\\}$。\n通过简单的观察可以看出，当比率 $R(\\sigma)$ 的分子 $|9.9 - \\sigma|$ 被最小化时，$R(\\sigma)$ 的表达式也达到最小值。一个非负量 $|x|$ 的最小值为 $0$，这在 $x=0$ 时发生。\n因此，当以下条件成立时，比率 $R(\\sigma)$ 达到其绝对最小值 $0$：\n$$|9.9 - \\sigma| = 0$$\n这意味着最优的偏移量是 $\\sigma = 9.9$。\n\n选择 $\\sigma = 9.9$ 时，收敛比率 $R$ 变为 $0$，这对应于无限快的收敛速度。这代表了对所需特征向量的最有效的可能分离。问题要求的是“原则上”能实现这一点的 $\\sigma$ 值。这种措辞表明我们关心的是理论上的最优解，而不是数值实现中的实际限制。在实践中，选择 $\\sigma$ 精确等于一个特征值会使矩阵 $(A - \\sigma I)$ 成为奇异矩阵，其逆矩阵无定义。实际的实现会使用一个非常接近但并不等于 $9.9$ 的 $\\sigma$ 值。然而，所提出的问题是一个原则性问题，理论上的最优解明确是 $\\sigma = 9.9$。", "answer": "$$\\boxed{9.9}$$", "id": "2427117"}, {"introduction": "在我们对基本迭代和位移迭代的理解之上，我们现在将在一个现实的场景中探索和比较它们的性能。在这个综合性练习 [@problem_id:2427128] 中，你不仅将实现幂法和固定位移的反幂法，还将实现高效的瑞利商迭代（RQI）。通过在具有不同性质的矩阵上测试这些算法，你将亲眼见证 RQI 惊人的三次方收敛速度，并理解为什么它在实际应用中常常是首选方法。", "problem": "实现一个算法，使用以瑞利商作为可变位移的逆迭代法来近似求解实对称矩阵的特征对。设非零向量 $x \\in \\mathbb{R}^n$ 的瑞利商定义为 $R(x) = \\dfrac{x^\\mathsf{T} A x}{x^\\mathsf{T} x}$。考虑以下三种应用于实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的迭代方案，给定非零初始向量 $x_0 \\in \\mathbb{R}^n$ 和容差 $\\varepsilon  0$：\n\n- 幂迭代法：$x_{k+1} \\leftarrow \\dfrac{A x_k}{\\lVert A x_k \\rVert_2}$，其中残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n- 固定位移的逆迭代法：固定 $\\sigma_0 = R(x_0)$，通过求解 $(A - \\sigma_0 I) y = x_k$ 计算 $x_{k+1}$，并设 $x_{k+1} \\leftarrow \\dfrac{y}{\\lVert y \\rVert_2}$，其中残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n- 位移等于瑞利商的可变位移逆迭代法（瑞利商迭代法）：在每次迭代中，计算 $\\sigma_k = R(x_k)$，求解 $(A - \\sigma_k I) y = x_k$，并设 $x_{k+1} \\leftarrow \\dfrac{y}{\\lVert y \\rVert_2}$，其中残差范数使用 $\\lambda_k = R(x_k)$ 定义为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n\n对于每种方案，当残差范数首次满足 $\\lVert A x_k - \\lambda_k x_k \\rVert_2 \\le \\varepsilon$ 时停止，或者达到预设的最大迭代次数时停止。所有向量范数均为欧几里得范数，$I$ 表示大小为 $n$ 的单位矩阵。\n\n使用以下测试套件。在每种情况下，设置 $n = 5$，容差 $\\varepsilon = 10^{-10}$，最大迭代次数为 $1000$。\n\n- 测试用例 $\\#1$（三对角对称正定矩阵）：\n  - 矩阵 $A_1 \\in \\mathbb{R}^{5 \\times 5}$：\n    $$\n    A_1 =\n    \\begin{bmatrix}\n    6  2  0  0  0 \\\\\n    2  5  2  0  0 \\\\\n    0  2  4  2  0 \\\\\n    0  0  2  3  2 \\\\\n    0  0  0  2  2\n    \\end{bmatrix}.\n    $$\n  - 初始向量 $x_0^{(1)} = \\dfrac{1}{\\sqrt{5}} [1, 1, 1, 1, 1]^\\mathsf{T}$。\n\n- 测试用例 $\\#2$（具有两个非常接近的特征值的对称矩阵）：\n  - 定义对角矩阵 $D = \\mathrm{diag}(1, 1 + 10^{-6}, 2, 3, 4)$。\n  - 定义角度为 $\\theta$ 的平面旋转，使得 $\\cos \\theta = \\dfrac{4}{5}$ 且 $\\sin \\theta = \\dfrac{3}{5}$，并设置\n    $$\n    Q = \\begin{bmatrix}\n    \\cos \\theta  -\\sin \\theta  0  0  0 \\\\\n    \\sin \\theta  \\phantom{-}\\cos \\theta  0  0  0 \\\\\n    0  0  1  0  0 \\\\\n    0  0  0  1  0 \\\\\n    0  0  0  0  1\n    \\end{bmatrix}.\n    $$\n  - 矩阵 $A_2 = Q^\\mathsf{T} D Q$。\n  - 初始向量 $x_0^{(2)} = [1, 0, 0, 0, 0]^\\mathsf{T}$。\n\n- 测试用例 $\\#3$（希尔伯特矩阵）：\n  - 矩阵 $A_3 \\in \\mathbb{R}^{5 \\times 5}$，其元素为 $(A_3)_{ij} = \\dfrac{1}{i + j - 1}$，其中 $i,j \\in \\{1, 2, 3, 4, 5\\}$。\n  - 初始向量 $x_0^{(3)} = \\dfrac{1}{\\sqrt{5}} [1, -1, 1, -1, 1]^\\mathsf{T}$。\n\n对于每个测试用例，使用相同的 $A$ 和 $x_0$ 独立运行这三种方案，并记录残差范数首次满足 $\\lVert A x_k - \\lambda_k x_k \\rVert_2 \\le \\varepsilon$ 时的最小迭代次数 $k$。如果在最大迭代次数内未收敛，则记录最大迭代次数。\n\n你的程序必须输出单行内容，包含一个由方括号括起来的、逗号分隔的 9 个整数列表，顺序如下：\n$[k_{\\mathrm{RQI}}^{(1)}, k_{\\mathrm{fixed}}^{(1)}, k_{\\mathrm{power}}^{(1)}, k_{\\mathrm{RQI}}^{(2)}, k_{\\mathrm{fixed}}^{(2)}, k_{\\mathrm{power}}^{(2)}, k_{\\mathrm{RQI}}^{(3)}, k_{\\mathrm{fixed}}^{(3)}, k_{\\mathrm{power}}^{(3)}]$，其中 $k_{\\mathrm{RQI}}^{(i)}$ 是瑞利商迭代法在测试用例 $i$ 上的迭代次数，$k_{\\mathrm{fixed}}^{(i)}$ 是固定位移 $\\sigma_0 = R(x_0^{(i)})$ 的逆迭代法的迭代次数，$k_{\\mathrm{power}}^{(i)}$ 是幂迭代法的迭代次数。输出必须是此格式的单行内容，除了列表表示所需的结构性字符外，不应包含任何额外的字符或空格。", "solution": "问题陈述经评估有效。它在科学上基于数值线性代数的既定原理，特别是特征值问题的迭代方法。问题提法清晰，所有必要的参数、矩阵、初始条件和停止准则都得到了明确无误的定义。语言客观且正式。因此，将提供一个解决方案。\n\n该问题要求实现并比较三种迭代算法，以近似求解实对称矩阵 $A$ 的一个特征对 $(\\lambda, v)$，其中 $A v = \\lambda v$。一个特征对由一个特征值 $\\lambda$ 及其对应的特征向量 $v$ 组成。所考虑的方法是幂法、固定位移反幂法和可变位移反幂法，后者也称为瑞利商迭代（RQI）。对于一个实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其所有特征值都是实数，并且存在一个由特征向量构成的标准正交基。对于非零向量 $x \\in \\mathbb{R}^n$，瑞利商定义为 $R(x) = \\frac{x^\\mathsf{T} A x}{x^\\mathsf{T} x}$，它提供了对特征值的估计。如果 $x$ 是一个特征向量，那么 $R(x)$ 就是对应的精确特征值。对于所有算法，我们从一个初始向量 $x_0$ 开始，生成一个收敛到某个特征向量的向量序列 $\\{x_k\\}$，以及一个收敛到相应特征值的瑞利商序列 $\\{\\lambda_k = R(x_k)\\}$。\n\n1.  **幂迭代法**\n\n    幂迭代法是寻找矩阵主特征对（即特征值 $|\\lambda_1|$ 在所有特征值中最大的特征对 $(\\lambda_1, v_1)$）的最简单算法。迭代步骤定义为：\n    $$\n    x_{k+1} = \\frac{A x_k}{\\lVert A x_k \\rVert_2}\n    $$\n    从一个在主特征向量 $v_1$ 方向上具有非零分量的初始向量 $x_0$ 开始，序列 $x_k$ 会收敛到 $v_1$。收敛是线性的，收敛速率由比率 $|\\lambda_2 / \\lambda_1|$ 决定，其中 $\\lambda_2$ 是模第二大的特征值。如果这个比率接近于 1，收敛可能会非常慢。在每一步中，特征值由瑞利商 $\\lambda_k = R(x_k)$ 近似。\n\n2.  **固定位移的逆迭代法**\n\n    逆迭代法是一种寻找与给定偏移量 $\\sigma$ 最近的特征值所对应的特征对的方法。它将幂法应用于矩阵 $(A - \\sigma I)^{-1}$。$(A - \\sigma I)^{-1}$ 的特征值是 $(\\lambda_i - \\sigma)^{-1}$，其中 $\\lambda_i$ 是 $A$ 的特征值。$(A - \\sigma I)^{-1}$ 的主特征值对应于 $|\\lambda_i - \\sigma|$ 的最小值，这意味着 $\\lambda_i$ 是 $A$ 的最接近 $\\sigma$ 的特征值。迭代步骤为：\n    $$\n    x_{k+1} = \\frac{(A - \\sigma I)^{-1} x_k}{\\lVert (A - \\sigma I)^{-1} x_k \\rVert_2}\n    $$\n    在实践中，我们避免计算矩阵的逆。而是解线性方程组 $(A - \\sigma I) y_k = x_k$ 来求 $y_k$，然后进行归一化：\n    $$\n    x_{k+1} = \\frac{y_k}{\\lVert y_k \\rVert_2}\n    $$\n    在本问题中，整个过程使用固定的位移 $\\sigma_0 = R(x_0)$。收敛是线性的，但收敛速率由 $(A-\\sigma_0 I)^{-1}$ 的两个模最大特征值的比率决定。如果 $\\sigma_0$ 比其他任何特征值都更接近某个特征值 $\\lambda_j$，那么向特征向量 $v_j$ 的收敛会非常快。\n\n3.  **瑞利商迭代法（RQI）**\n\n    瑞利商迭代法是逆迭代法的一种强大改进，其中位移在每一步都使用当前对特征值的最佳估计——瑞利商——进行更新。迭代过程定义如下：\n    1.  计算位移：$\\sigma_k = R(x_k) = \\frac{x_k^\\mathsf{T} A x_k}{x_k^\\mathsf{T} x_k}$。\n    2.  求解 $y_{k+1}$：$(A - \\sigma_k I) y_{k+1} = x_k$。\n    3.  归一化：$x_{k+1} = \\frac{y_{k+1}}{\\lVert y_{k+1} \\rVert_2}$。\n\n    对于对称矩阵，一旦迭代向量 $x_k$ 足够接近一个特征向量，RQI 会表现出三次收敛。这意味着近似值中正确数字的位数在每次迭代后大约增加两倍，从而导致极快的收敛速度。\n\n**停止准则**\n\n对于所有三种方法，当残差向量的范数 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$ 小于指定的容差 $\\varepsilon$ 时，迭代终止，其中 $\\lambda_k = R(x_k)$。这个残差衡量了当前近似对 $( \\lambda_k, x_k )$ 满足特征值方程的程度。首次满足此条件的迭代次数 $k$ 是所需的输出。如果未在最大迭代次数内满足条件，则记录最大迭代次数。\n\n实现将通过定义三个函数来进行，每种算法一个。每个函数将迭代生成向量序列，并在每一步检查停止准则，返回迭代次数。然后将这些函数应用于三个指定的测试用例。", "answer": "```python\nimport numpy as np\n\ndef power_iteration(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates a dominant eigenpair using Power Iteration.\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    for k in range(1, max_iter + 1):\n        v = A @ x\n        x_k = v / np.linalg.norm(v)\n\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n\n        if residual_norm = tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef inverse_iteration_fixed_shift(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates an eigenpair using inverse iteration with a fixed shift.\n    The shift is the Rayleigh quotient of the initial vector.\n    \"\"\"\n    sigma0 = x0.T @ A @ x0\n    \n    try:\n        M = A - sigma0 * np.eye(A.shape[0])\n    except np.linalg.LinAlgError:\n        return max_iter\n\n    x = x0 / np.linalg.norm(x0)\n\n    for k in range(1, max_iter + 1):\n        try:\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            return max_iter\n\n        x_k = y / np.linalg.norm(y)\n\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n\n        if residual_norm = tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef rayleigh_quotient_iteration(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates an eigenpair using Rayleigh Quotient Iteration.\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    \n    for k in range(1, max_iter + 1):\n        sigma = x.T @ A @ x\n\n        try:\n            M = A - sigma * np.eye(A.shape[0])\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            # If the shift is an eigenvalue, the previous iterate was the eigenvector.\n            # Its residual should have been small enough to stop the loop.\n            # This case handles a sudden exact hit.\n            return k - 1 if k > 1 else 1\n\n        x_k = y / np.linalg.norm(y)\n\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n        \n        if residual_norm = tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    n = 5\n    tol = 1e-10\n    max_iter = 1000\n\n    # Test Case 1\n    A1 = np.array([\n        [6, 2, 0, 0, 0],\n        [2, 5, 2, 0, 0],\n        [0, 2, 4, 2, 0],\n        [0, 0, 2, 3, 2],\n        [0, 0, 0, 2, 2]\n    ], dtype=float)\n    x0_1 = np.ones(n) / np.sqrt(n)\n\n    # Test Case 2\n    D = np.diag([1.0, 1.0 + 1e-6, 2.0, 3.0, 4.0])\n    cos_theta = 4.0 / 5.0\n    sin_theta = 3.0 / 5.0\n    Q = np.eye(n)\n    Q[0, 0] = cos_theta\n    Q[0, 1] = -sin_theta\n    Q[1, 0] = sin_theta\n    Q[1, 1] = cos_theta\n    A2 = Q.T @ D @ Q\n    x0_2 = np.zeros(n)\n    x0_2[0] = 1.0\n\n    # Test Case 3\n    A3 = np.fromfunction(lambda i, j: 1 / (i + j + 1), (n, n), dtype=float)\n    x0_3 = np.array([1, -1, 1, -1, 1]) / np.sqrt(n)\n    \n    test_cases = [\n        (A1, x0_1),\n        (A2, x0_2),\n        (A3, x0_3)\n    ]\n\n    results = []\n    for A, x0 in test_cases:\n        k_rqi = rayleigh_quotient_iteration(A, x0, tol, max_iter)\n        k_fixed = inverse_iteration_fixed_shift(A, x0, tol, max_iter)\n        k_power = power_iteration(A, x0, tol, max_iter)\n        \n        results.extend([k_rqi, k_fixed, k_power])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2427128"}]}