{"hands_on_practices": [{"introduction": "理解一个算法的最好方法就是亲手实现它。第一个练习将聚焦于雅可比(Jacobi)迭代的核心机制。你将通过实现其矩阵-向量形式，并利用几个测试案例，来验证其基本收敛准则——即迭代矩阵的谱半径必须小于1。这个实践将为你理解雅可比方法何时收敛以及为何收敛打下坚实的基础[@problem_id:2404665]。", "problem": "给定形式为 $A x = b$ 的方形线性系统，其中 $A \\in \\mathbb{R}^{n \\times n}$ 且 $b \\in \\mathbb{R}^{n}$。定义对角矩阵 $D = \\mathrm{diag}(A)$，线性算子 $T_J = I - D^{-1} A$，以及向量 $c = D^{-1} b$。考虑定点迭代 $x^{(k+1)} = T_J x^{(k)} + c$，初始向量为 $x^{(0)} = 0$。对于下述每个系统，计算谱半径 $\\rho(T_J)$，并通过将迭代结果与由 $A x^\\star = b$ 定义的精确解 $x^\\star$ 进行比较来评估收敛行为。\n\n对于每个系统，用纯数学术语执行以下步骤：\n1. 计算 $\\rho(T_J)$，其中 $\\rho(T_J) = \\max_i |\\lambda_i(T_J)|$ 且 $\\{\\lambda_i(T_J)\\}$ 是 $T_J$ 的特征值。\n2. 如果 $\\rho(T_J) < 1$，则通过 $x^{(k+1)} = T_J x^{(k)} + c$ 生成序列 $\\{x^{(k)}\\}_{k=0}^{\\infty}$，直到达到相对误差 $\\|x^{(k)} - x^\\star\\|_2 / \\|x^\\star\\|_2 \\le \\varepsilon$ 的第一个索引 $k_{\\min}$，其中容差为 $\\varepsilon = 10^{-8}$，$\\|\\cdot\\|_2$ 是欧几里得范数。报告此最小索引 $k_{\\min}$、最终相对误差 $\\|x^{(k_{\\min})} - x^\\star\\|_2 / \\|x^\\star\\|_2$，以及一个布尔值，如果在最多 $K_{\\max}$ 次迭代内满足容差，则为 `True`，否则为 `False`。使用 $K_{\\max} = 50000$ 作为迭代上限。\n3. 如果 $\\rho(T_J) \\ge 1$，则不进行迭代。在这种情况下，报告布尔值 `False`，将迭代次数设置为 $0$，并报告初始猜测 $x^{(0)}$ 的相对误差，即 $\\|x^{(0)} - x^\\star\\|_2 / \\|x^\\star\\|_2$。\n4. 在所有情况下，精确解 $x^\\star$ 是满足 $A x^\\star = b$ 的唯一向量。所有量纲均为无量纲。\n\n测试套件：\n- 案例 1（平凡标量系统）：$A_1 = [\\,3\\,] \\in \\mathbb{R}^{1 \\times 1}$，$b_1 = [\\,1\\,] \\in \\mathbb{R}^{1}$。\n- 案例 2（一维离散拉普拉斯算子，带狄利克雷边界，大小为 n）：对于 $n = 50$，$A_2 \\in \\mathbb{R}^{n \\times n}$ 的对角线上为 $2$，第一亚对角线和第一超对角线上为 $-1$，其他位置为零；$b_2 = \\mathbf{1} \\in \\mathbb{R}^{n}$，所有元素均为 $1$。\n- 案例 3（严格对角占优三对角矩阵，大小为 n）：对于 $n = 50$，$A_3 \\in \\mathbb{R}^{n \\times n}$ 的对角线上为 $5$，第一亚对角线和第一超对角线上为 $-1$，其他位置为零；$b_3 = \\mathbf{1} \\in \\mathbb{R}^{n}$，所有元素均为 $1$。\n- 案例 4（在此迭代下不收敛）：$A_4 = \\begin{bmatrix} 1  2 \\\\ 2  1 \\end{bmatrix} \\in \\mathbb{R}^{2 \\times 2}$，$b_4 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix} \\in \\mathbb{R}^{2}$。\n\n要求的最终输出格式：\n- 您的程序必须生成单行输出，该输出按顺序汇总了四个案例的结果，形式为列表的列表。对于每个案例，输出四元组 $[\\rho(T_J), k, \\text{rel\\_err}, \\text{converged}]$，其中 $\\rho(T_J)$ 和 $\\text{rel\\_err}$ 是四舍五入到六位小数的浮点数，$k$ 是一个整数，$\\text{converged}$ 是一个布尔值，其值为 `True` 或 `False`。\n- 单行输出必须采用以下形式\n  $[[\\rho_1,k_1,e_1,flag_1],[\\rho_2,k_2,e_2,flag_2],[\\rho_3,k_3,e_3,flag_3],[\\rho_4,k_4,e_4,flag_4]]$\n  行内任何地方都没有空格。", "solution": "用户提交了一个关于分析雅可比迭代法求解形式为 $A x = b$ 的方形线性系统的问题。该任务要求验证问题陈述，如果有效，则提供一个包含理论分析和数值实现的全面解决方案。\n\n### 第 1 步：提取已知条件\n问题提供了以下定义和数据：\n- 一个方形线性系统 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 且 $b \\in \\mathbb{R}^{n}$。\n- 对角矩阵 $D = \\mathrm{diag}(A)$。\n- 雅可比迭代算子 $T_J = I - D^{-1} A$。\n- 向量 $c = D^{-1} b$。\n- 雅可比定点迭代定义为 $x^{(k+1)} = T_J x^{(k)} + c$。\n- 初始向量为 $x^{(0)} = \\mathbf{0}$。\n- $T_J$ 的谱半径为 $\\rho(T_J) = \\max_i |\\lambda_i(T_J)|$，其中 $\\{\\lambda_i(T_J)\\}$ 是 $T_J$ 的特征值。\n- 精确解为 $x^\\star$，满足 $A x^\\star = b$。\n- 相对误差的收敛容差为 $\\varepsilon = 10^{-8}$。\n- 相对误差定义为 $\\|x^{(k)} - x^\\star\\|_2 / \\|x^\\star\\|_2$，其中 $\\|\\cdot\\|_2$ 是欧几里得范数。\n- 最大迭代次数为 $K_{\\max} = 50000$。\n- 所有量纲均为无量纲。\n\n指定了四个测试案例：\n1.  **案例 1**：$A_1 = [\\,3\\,]$, $b_1 = [\\,1\\,]$。\n2.  **案例 2**：$n = 50$，$A_2$ 是一维离散拉普拉斯矩阵（对角线元素为 $2$，第一副对角线元素为 $-1$），$b_2 = \\mathbf{1}$。\n3.  **案例 3**：$n = 50$，$A_3$ 是一个严格对角占优三对角矩阵（对角线元素为 $5$，第一副对角线元素为 $-1$），$b_3 = \\mathbf{1}$。\n4.  **案例 4**：$A_4 = \\begin{bmatrix} 1  2 \\\\ 2  1 \\end{bmatrix}$, $b_4 = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$。\n\n每个案例要求的输出是一个四元组 $[\\rho(T_J), k, \\text{rel\\_err}, \\text{converged}]$。这包括谱半径、迭代次数、最终相对误差以及一个指示是否在 $K_{\\max}$ 次迭代内实现收敛的布尔值。\n\n### 第 2 步：使用提取的已知条件进行验证\n根据验证标准对问题陈述进行评估：\n\n-   **科学依据**：该问题基于雅可比方法，这是数值线性代数和计算物理学中的一个基本迭代算法。谱半径、定点迭代的收敛准则以及矩阵特征值等概念都是标准且完善的数学原理。测试案例，特别是离散拉普拉斯算子，是该领域的典型例子。该问题在科学上是合理的。\n-   **适定性**：问题定义清晰。对于每个案例，矩阵 $A$ 都是可逆的，保证了唯一精确解 $x^\\star$ 的存在。对角矩阵 $D$ 也是可逆的，因此雅可比迭代算子 $T_J$ 定义良好。迭代和终止的条件都是明确的。每个案例都存在唯一且有意义的结果。\n-   **客观性**：问题使用精确、客观的数学语言陈述。没有主观论断或含糊不清之处。\n\n该问题没有任何诸如科学上不合理、不可形式化、不完整、矛盾或不可行等缺陷。它是一个标准的、可验证的计算问题。\n\n### 第 3 步：结论与行动\n问题是**有效的**。将提供一个解决方案。\n\n### 基于原理的解决方案\n雅可比方法是一种用于求解线性系统 $A x = b$ 的定点迭代法。矩阵 $A$ 被分解为 $A = D + L + U$，其中 $D$ 是 $A$ 的对角部分，$L$ 和 $U$ 分别是 $A$ 的严格下三角和上三角部分。方程 $A x = b$ 可以写成 $(D+L+U)x=b$，整理后得到 $Dx = -(L+U)x+b$。假设 $D$ 可逆，这就产生了迭代格式：\n$$x^{(k+1)} = -D^{-1}(L+U)x^{(k)} + D^{-1}b$$\n迭代矩阵是 $T_J = -D^{-1}(L+U)$。由于 $A = D+L+U$，我们可以写出 $L+U = A-D$，所以 $T_J = -D^{-1}(A-D) = -D^{-1}A + D^{-1}D = I - D^{-1}A$。向量是 $c = D^{-1}b$。因此，迭代过程为 $x^{(k+1)} = T_J x^{(k)} + c$。\n\n迭代方法的一个基本定理指出，对于任意初始猜测 $x^{(0)}$，此定点迭代收敛的充分必要条件是迭代矩阵 $T_J$ 的谱半径小于 1，即 $\\rho(T_J) < 1$。\n\n总体步骤如下：\n1.  对于每个系统 $(A, b)$，构造迭代矩阵 $T_J = I - D^{-1}A$。\n2.  计算 $T_J$ 的特征值并确定谱半径 $\\rho(T_J)$。\n3.  计算精确解 $x^\\star = A^{-1}b$。\n4.  如果 $\\rho(T_J) \\ge 1$，迭代发散。我们报告谱半径、迭代次数 $k=0$、初始猜测 $x^{(0)}=\\mathbf{0}$ 的相对误差（对于 $x^\\star \\neq \\mathbf{0}$，该误差为 $\\|-\\|x^\\star\\|_2/\\|x^\\star\\|_2 = 1$），以及一个 `False` 收敛标志。\n5.  如果 $\\rho(T_J) < 1$，迭代收敛。我们从 $x^{(0)} = \\mathbf{0}$ 开始，生成序列 $x^{(k+1)} = T_J x^{(k)} + c$，$k=0, 1, 2, \\dots$。在每一步 $k$，我们计算相对误差 $e_k = \\|x^{(k)} - x^\\star\\|_2 / \\|x^\\star\\|_2$。该过程在 $e_{k_{min}} \\le 10^{-8}$ 的第一个迭代 $k_{min}$ 处停止。如果到 $k=K_{max}$ 仍未发生，则终止过程并报告为在指定限制内未收敛。\n\n**逐个案例分析：**\n\n**案例 1:** $A_1 = [\\,3\\,], b_1 = [\\,1\\,]$。\n- $D_1 = [\\,3\\,]$, $D_1^{-1} = [\\,1/3\\,]$。\n- $T_J = I - D_1^{-1}A_1 = [\\,1\\,] - [\\,1/3\\,][\\,3\\,] = [\\,0\\,]$。\n- 唯一的特征值是 $0$，所以 $\\rho(T_J) = 0$。\n- 由于 $\\rho(T_J) < 1$，该方法收敛。\n- $x^\\star = A_1^{-1}b_1 = [\\,1/3\\,]$。\n- $c = D_1^{-1}b_1 = [\\,1/3\\,]$。\n- $x^{(0)} = [\\,0\\,]$。\n- $x^{(1)} = T_J x^{(0)} + c = [\\,0\\,][\\,0\\,] + [\\,1/3\\,] = [\\,1/3\\,]$。\n- 迭代在 $k=1$ 步内精确收敛。相对误差为 $\\|x^{(1)} - x^\\star\\|_2 / \\|x^\\star\\|_2 = 0$。\n\n**案例 2:** $n=50$，$A_2$ 是一维离散拉普拉斯算子。\n- $A_2$ 是一个三对角矩阵，对角线上为 $2$，亚对角线和超对角线上为 $-1$。\n- $D_2 = 2I$，所以 $D_2^{-1} = (1/2)I$。\n- $T_J = I - (1/2)A_2$。该矩阵对角线上为 $0$，亚对角线和超对角线上为 $1/2$。\n- 已知这类矩阵的特征值为 $\\lambda_j(T_J) = \\cos\\left(\\frac{j\\pi}{n+1}\\right)$，对于 $j=1, \\dots, n$。\n- 对于 $n=50$，谱半径为 $\\rho(T_J) = \\max_j|\\lambda_j| = \\cos\\left(\\frac{\\pi}{51}\\right)$。\n- 数值上，$\\rho(T_J) \\approx 0.998104$。由于 $\\rho(T_J) < 1$，迭代收敛，但谱半径非常接近 1，表明收敛速度很慢。数值实现将找到满足容差所需的精确迭代次数。\n\n**案例 3:** $n=50$，$A_3$ 是一个严格对角占优矩阵。\n- $A_3$ 是一个三对角矩阵，对角线上为 $5$，亚对角线和超对角线上为 $-1$。\n- $D_3 = 5I$，所以 $D_3^{-1} = (1/5)I$。\n- $T_J = I - (1/5)A_3$。该矩阵对角线上为 $0$，亚对角线和超对角线上为 $1/5$。\n- 其特征值为 $\\lambda_j(T_J) = \\frac{2}{5}\\cos\\left(\\frac{j\\pi}{n+1}\\right)$，对于 $j=1, \\dots, n$。\n- 对于 $n=50$，谱半径为 $\\rho(T_J) = \\frac{2}{5}\\cos\\left(\\frac{\\pi}{51}\\right)$。\n- 数值上，$\\rho(T_J) \\approx 0.4 \\times 0.998104 \\approx 0.399242$。这个值明显小于 1，这保证了快速收敛。矩阵 $A_3$ 是严格对角占优的，这是雅可比方法收敛的充分条件。\n\n**案例 4:** $A_4 = \\begin{bmatrix} 1  2 \\\\ 2  1 \\end{bmatrix}$。\n- $D_4 = \\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix} = I$。\n- $T_J = I - D_4^{-1}A_4 = I - A_4 = \\begin{pmatrix} 0  -2 \\\\ -2  0 \\end{pmatrix}$。\n- 特征方程是 $\\det(T_J - \\lambda I) = \\lambda^2 - 4 = 0$，得到特征值 $\\lambda_1 = -2, \\lambda_2 = 2$。\n- 谱半径是 $\\rho(T_J) = \\max(|-2|, |2|) = 2$。\n- 由于 $\\rho(T_J) \\ge 1$，对于该系统，雅可比迭代不收敛。\n- 精确解是 $x^\\star = A_4^{-1} b_4 = \\begin{pmatrix} -1/3  2/3 \\\\ 2/3  -1/3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1/3 \\\\ 1/3 \\end{pmatrix}$。\n- 初始猜测是 $x^{(0)} = \\mathbf{0}$。相对误差是 $\\|x^{(0)} - x^\\star\\|_2 / \\|x^\\star\\|_2 = \\|-x^\\star\\|_2 / \\|x^\\star\\|_2 = 1.0$。\n\n以下程序实现了这一逻辑，以数值方式计算所需的结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Jacobi iteration problem for four specified linear systems.\n    \"\"\"\n    K_max = 50000\n    epsilon = 1e-8\n\n    def solve_case(A, b, K_max, epsilon):\n        \"\"\"\n        Analyzes a single linear system with the Jacobi method.\n\n        Args:\n            A (np.ndarray): The coefficient matrix.\n            b (np.ndarray): The constant vector.\n            K_max (int): Maximum number of iterations.\n            epsilon (float): Convergence tolerance.\n\n        Returns:\n            tuple: A tuple containing (rho_T_J, k, rel_err, converged).\n        \"\"\"\n        n = A.shape[0]\n        \n        # Extract the diagonal of A to form D\n        diag_A = np.diag(A)\n        if np.any(diag_A == 0):\n            # This case is excluded by problem constraints but is a necessary check.\n            raise ValueError(\"Matrix has a zero on its diagonal; Jacobi method is not applicable.\")\n        \n        D_inv = np.diag(1.0 / diag_A) # More efficient than np.linalg.inv for diagonal\n        \n        # Construct the Jacobi iteration matrix T_J\n        T_J = np.identity(n) - D_inv @ A\n        \n        # Compute the spectral radius of T_J\n        eigenvalues = np.linalg.eigvals(T_J)\n        rho_T_J = np.max(np.abs(eigenvalues))\n        \n        # Compute the exact solution x_star\n        x_star = np.linalg.solve(A, b)\n        norm_x_star = np.linalg.norm(x_star, 2)\n        \n        if norm_x_star == 0:\n            # If x_star is the zero vector, the initial guess is exact.\n            return rho_T_J, 0, 0.0, True\n            \n        # Case 1: Iteration is not guaranteed to converge\n        if rho_T_J >= 1:\n            x0 = np.zeros_like(b)\n            # Initial relative error for x^(0) = 0\n            rel_err = np.linalg.norm(x0 - x_star, 2) / norm_x_star\n            return rho_T_J, 0, rel_err, False\n        \n        # Case 2: Iteration converges\n        else:\n            c = D_inv @ b\n            xk = np.zeros_like(b)\n            for k in range(K_max + 1):\n                rel_err = np.linalg.norm(xk - x_star, 2) / norm_x_star\n                \n                # Check for convergence\n                if rel_err = epsilon:\n                    return rho_T_J, k, rel_err, True\n                \n                # Check if max iterations reached without convergence\n                if k == K_max:\n                    return rho_T_J, k, rel_err, False\n                \n                # Update for next iteration\n                xk = T_J @ xk + c\n        \n        # This part of the code should be unreachable given the logic above.\n        return rho_T_J, K_max, np.nan, False\n\n    # Define the test cases from the problem statement.\n    test_cases = []\n\n    # Case 1: Trivial scalar system\n    A1 = np.array([[3.0]], dtype=float)\n    b1 = np.array([1.0], dtype=float)\n    test_cases.append((A1, b1))\n\n    # Case 2: 1D discrete Laplacian\n    n2 = 50\n    diag2 = np.full(n2, 2.0, dtype=float)\n    off_diag2 = np.full(n2 - 1, -1.0, dtype=float)\n    A2 = np.diag(diag2) + np.diag(off_diag2, k=1) + np.diag(off_diag2, k=-1)\n    b2 = np.ones(n2, dtype=float)\n    test_cases.append((A2, b2))\n\n    # Case 3: Strictly diagonally dominant tridiagonal\n    n3 = 50\n    diag3 = np.full(n3, 5.0, dtype=float)\n    off_diag3 = np.full(n3 - 1, -1.0, dtype=float)\n    A3 = np.diag(diag3) + np.diag(off_diag3, k=1) + np.diag(off_diag3, k=-1)\n    b3 = np.ones(n3, dtype=float)\n    test_cases.append((A3, b3))\n    \n    # Case 4: Non-convergent case\n    A4 = np.array([[1.0, 2.0], [2.0, 1.0]], dtype=float)\n    b4 = np.array([1.0, 1.0], dtype=float)\n    test_cases.append((A4, b4))\n\n    results = []\n    for A, b in test_cases:\n        result = solve_case(A, b, K_max, epsilon)\n        results.append(result)\n\n    # Format the results into the required single-line string.\n    formatted_results = []\n    for rho, k, err, conv in results:\n        # Each sub-list is formatted as a string \"[rho,k,err,conv]\"\n        formatted_results.append(f\"[{rho:.6f},{k},{err:.6f},{str(conv)}]\")\n\n    # The final output is a string representation of a list of these sub-lists.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2404665"}, {"introduction": "如果我们不知道何时停止，一个收敛的迭代过程是无用的。这个实践将从理论转向定义一个可靠停止准则的实际挑战。你将实现一个基于残差范数的停止准则，并探究它与真实误差之间的关系，从而发现一个小的残差并不总能保证一个小的误差，尤其是在面对病态系统时。这次探索将突显矩阵条件数在数值稳定性中的关键作用[@problem_id:2404697]。", "problem": "您的任务是为雅可比迭代实现一个基于残差范数的停止准则，并研究该准则在何时能可靠地替代迭代的真实误差。考虑一个线性方程组 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是一个方阵，$b \\in \\mathbb{R}^{n}$ 是一个向量。雅可比迭代产生一个近似解序列 $x^{(k)}$，该序列逼近真实解 $x^{\\star}$。第 $k$ 次迭代的残差定义为 $r^{(k)} = b - A x^{(k)}$，其欧几里得范数为 $\\lVert r^{(k)} \\rVert_{2}$。您必须实现的停止准则是，一旦 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$（其中 $\\tau  0$ 是给定的容差）即终止，或者当达到指定的最大迭代次数时终止。您还必须在终止时（如果未收敛，则在达到迭代次数上限时）计算真实误差范数 $\\lVert x^{(k)} - x^{\\star} \\rVert_{2}$，其中 $x^{\\star}$ 对于下面的测试用例是已知的。\n\n从基本的线性代数定义和事实出发，特别是：方程 $A x = b$、欧几里得范数 $\\lVert \\cdot \\rVert_{2}$ 和残差定义 $r^{(k)} = b - A x^{(k)}$。除此之外，不要假定任何专门的快捷结果。您应该为具有非零对角线元素的一般非奇异矩阵 $A$ 正确实现雅可比迭代，使用初始猜测 $x^{(0)} = 0$。您的实现必须是通用的，并且无需硬编码针对特定用例的行为即可对每个测试用例有效。\n\n您的研究必须评估使用残差范数作为真实误差范数替代指标的可靠性。对于每个测试用例，在终止后，评估定义为 $\\lVert x^{(k)} - x^{\\star} \\rVert_{2} \\le \\tau$ 的布尔语句“朴素可靠性”；即，实际误差是否不大于用作停止阈值的残差容差。同时，计算欧几里得范数下的谱条件数 $\\kappa_{2}(A)$，以便将可靠性置于具体情境中分析。\n\n测试套件：\n- 测试用例 1（良态，严格对角占优）：\n  - $A_{1} = \\begin{bmatrix} 4  1  1 \\\\ 1  3  0 \\\\ 1  0  2 \\end{bmatrix}$，\n  - $x^{\\star}_{1} = \\begin{bmatrix} 1 \\\\ -2 \\\\ 3 \\end{bmatrix}$，\n  - $b_{1} = A_{1} x^{\\star}_{1}$，\n  - 残差容差 $\\tau_{1} = 10^{-10}$，\n  - 最大迭代次数 $N_{1} = 1000$。\n- 测试用例 2（病态但雅可比迭代收敛）：\n  - $A_{2} = \\begin{bmatrix} 1  9 \\times 10^{-4} \\\\ 9 \\times 10^{-4}  10^{-6} \\end{bmatrix}$，\n  - $x^{\\star}_{2} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$，\n  - $b_{2} = A_{2} x^{\\star}_{2}$，\n  - 残差容差 $\\tau_{2} = 10^{-8}$，\n  - 最大迭代次数 $N_{2} = 5000$。\n- 测试用例 3（雅可比迭代发散）：\n  - $A_{3} = \\begin{bmatrix} 1  2 \\\\ 2  1 \\end{bmatrix}$，\n  - $x^{\\star}_{3} = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix}$，\n  - $b_{3} = A_{3} x^{\\star}_{3}$，\n  - 残差容差 $\\tau_{3} = 10^{-8}$，\n  - 最大迭代次数 $N_{3} = 200$。\n\n对每个测试用例，使用 $x^{(0)} = 0$ 和停止规则 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$ 或达到迭代上限来运行雅可比迭代。在终止时，计算：\n- 一个收敛布尔值，指示是否在达到上限前满足 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$,\n- 一个朴素可靠性布尔值，指示是否满足 $\\lVert x^{(k)} - x^{\\star} \\rVert_{2} \\le \\tau$,\n- 执行的迭代次数（一个整数），\n- 最终残差范数 $\\lVert r^{(k)} \\rVert_{2}$（一个浮点数），\n- 最终误差范数 $\\lVert x^{(k)} - x^{\\star} \\rVert_{2}$（一个浮点数），\n- 谱条件数 $\\kappa_{2}(A)$（一个浮点数），\n- 放大因子 $\\gamma = \\lVert x^{(k)} - x^{\\star} \\rVert_{2} / \\lVert r^{(k)} \\rVert_{2}$（一个浮点数，如果分母为 $0$，则定义 $\\gamma = 0$）。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个逗号分隔的各用例结果列表，不含空格，并用方括号括起来。每个用例的结果列表必须严格按以下顺序排列：\n$[$收敛布尔值, 朴素可靠性布尔值, 迭代次数整数, 残差范数浮点数, 误差范数浮点数, 条件数浮点数, 放大因子浮点数$]$。\n例如，一个有效的整体输出结构是 $[[\\text{True},\\text{False},10,1.0,2.0,3.0,2.0],[\\dots],[\\dots]]$。\n\n不涉及角度。不涉及物理单位。所有数值结果都是无量纲实数。输出必须是严格指定的单行格式，只包含布尔值和数字，并使用这些类型的规范文本形式。", "solution": "所提出的问题是有效的。这是一个定义明确的数值线性代数计算练习，基于既定的科学原理，没有歧义或矛盾。我们将着手解决。\n\n核心任务是使用雅可比迭代法求解线性方程组 $A x = b$，其中给定一个方形非奇异矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 和向量 $b \\in \\mathbb{R}^{n}$。然后，我们将分析用作停止准则的残差范数与真实误差范数之间的关系。\n\n首先，我们建立雅可比迭代公式。将矩阵 $A$ 分解为其对角部分 $D$、严格下三角部分 $L$ 和严格上三角部分 $U$，使得 $A = D + L + U$。原始方程 $A x = b$ 可以写成 $(D + L + U) x = b$。为得到迭代解，重新整理方程可得：\n$$D x = b - (L + U) x$$\n假设矩阵 $A$ 的对角元素均不为零，则对角矩阵 $D$ 是可逆的。因此，我们可以定义一个迭代序列 $x^{(k)}$，并期望它收敛到真实解 $x^{\\star}$：\n$$x^{(k+1)} = D^{-1} (b - (L + U) x^{(k)})$$\n其中 $k$ 是迭代指数，从初始猜测 $x^{(0)}$ 开始。问题指定 $x^{(0)} = 0$。用分量形式表示，在第 $k+1$ 次迭代中，向量 $x$ 的第 $i$ 个元素的更新规则是：\n$$x_{i}^{(k+1)} = \\frac{1}{A_{ii}} \\left( b_i - \\sum_{j \\neq i} A_{ij} x_j^{(k)} \\right)$$\n这个公式凸显了新迭代向量 $x^{(k+1)}$ 的每个分量的计算仅依赖于前一个迭代向量 $x^{(k)}$ 的分量。\n\n雅可比方法的收敛性由雅可比迭代矩阵 $T_J = -D^{-1}(L+U)$ 的谱半径决定。当且仅当谱半径 $\\rho(T_J)  1$ 时，对于任何初始猜测 $x^{(0)}$，迭代都保证收敛。一个保证收敛的充分但非必要条件是矩阵 $A$ 是严格对角占优的。\n\n问题要求一个基于残差向量欧几里得范数的停止准则。在每次迭代 $k$ 中，残差 $r^{(k)}$ 定义为右端项 $b$ 与矩阵 $A$ 作用于当前近似解 $x^{(k)}$ 的结果之差：\n$$r^{(k)} = b - A x^{(k)}$$\n当 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$（其中 $\\tau$ 是给定的容差）时，或当超过最大迭代次数 $N$ 时，迭代终止。\n\n本研究的一个核心部分是理解残差 $r^{(k)}$ 与真实误差 $e^{(k)} = x^{(k)} - x^{\\star}$ 之间的关系。根据真实解的定义 $A x^{\\star} = b$，我们可以写出：\n$$r^{(k)} = A x^{\\star} - A x^{(k)} = A (x^{\\star} - x^{(k)}) = -A e^{(k)}$$\n由于 $A$ 是非奇异的，其逆矩阵 $A^{-1}$ 存在。我们可以用残差来表示误差：\n$$e^{(k)} = -A^{-1} r^{(k)}$$\n对两边取欧几里得范数，并利用诱导矩阵范数的性质（$\\lVert M v \\rVert \\le \\lVert M \\rVert \\lVert v \\rVert$），我们得到一个重要的不等式：\n$$\\lVert e^{(k)} \\rVert_{2} = \\lVert A^{-1} r^{(k)} \\rVert_{2} \\le \\lVert A^{-1} \\rVert_{2} \\lVert r^{(k)} \\rVert_{2}$$\n这个不等式提供了基于残差范数的误差范数的上界。对称地，从 $r^{(k)} = -A e^{(k)}$，我们有 $\\lVert r^{(k)} \\rVert_{2} \\le \\lVert A \\rVert_{2} \\lVert e^{(k)} \\rVert_{2}$，这给出了误差范数的一个下界：\n$$\\lVert e^{(k)} \\rVert_{2} \\ge \\frac{\\lVert r^{(k)} \\rVert_{2}}{\\lVert A \\rVert_{2}}$$\n将这些结合起来，得到完整的界定关系：\n$$\\frac{\\lVert r^{(k)} \\rVert_{2}}{\\lVert A \\rVert_{2}} \\le \\lVert e^{(k)} \\rVert_{2} \\le \\lVert A^{-1} \\rVert_{2} \\lVert r^{(k)} \\rVert_{2}$$\n使用残差范数 $\\lVert r^{(k)} \\rVert_{2}$ 作为误差范数 $\\lVert e^{(k)} \\rVert_{2}$ 的替代指标的可靠性，关键取决于 $\\lVert A \\rVert_{2}$ 和 $\\lVert A^{-1} \\rVert_{2}$ 的值。谱条件数 $\\kappa_{2}(A) = \\lVert A \\rVert_{2} \\lVert A^{-1} \\rVert_{2}$ 概括了这种关系。大的条件数表示矩阵是病态的，这意味着 $\\lVert A^{-1} \\rVert_{2}$ 可能很大。\n\n如果满足停止准则 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$，误差界变为：\n$$\\lVert e^{(k)} \\rVert_{2} \\le \\lVert A^{-1} \\rVert_{2} \\tau$$\n问题中定义的“朴素可靠性”准则 $\\lVert e^{(k)} \\rVert_{2} \\le \\tau$ 仅在 $\\lVert A^{-1} \\rVert_{2} \\le 1$ 时才能得到保证。对于病态矩阵，$\\lVert A^{-1} \\rVert_{2}$ 可能远大于 $1$，导致真实误差远大于残差容差 $\\tau$。放大因子 $\\gamma = \\lVert e^{(k)} \\rVert_{2} / \\lVert r^{(k)} \\rVert_{2}$ 直接量化了这种效应，我们预期 $\\gamma$ 与 $\\lVert A^{-1} \\rVert_{2}$ 相关。\n\n将要实现的算法会对每个测试用例执行以下步骤：\n1. 初始化迭代计数器 $k=0$ 和解向量 $x^{(0)} = 0$。\n2. 循环 $k$ 从 $1$ 到最大迭代次数 $N$。\n3. 在每次迭代中，使用 $x^{(k-1)}$ 通过雅可比公式计算下一个近似解 $x^{(k)}$。\n4. 计算残差 $r^{(k)} = b - A x^{(k)}$ 及其欧几里得范数 $\\lVert r^{(k)} \\rVert_{2}$。\n5. 检查是否 $\\lVert r^{(k)} \\rVert_{2} \\le \\tau$。如果为真，则迭代已收敛。终止循环。\n6. 如果循环完成而未满足容差，则表示在 $N$ 次迭代内未达到收敛。\n7. 在终止时（无论是通过收敛还是达到迭代上限），计算以下量：\n    - `converged`：一个布尔值，指示是否满足了容差。\n    - `naive-reliability`：一个用于测试 $\\lVert x^{(k)} - x^{\\star} \\rVert_{2} \\le \\tau$ 的布尔值。\n    - `iterations`：最终的迭代次数 $k$。\n    - `residual_norm`：$\\lVert r^{(k)} \\rVert_{2}$ 的最终值。\n    - `error_norm`：$\\lVert x^{(k)} - x^{\\star} \\rVert_{2}$ 的最终值。\n    - `condition_number`：矩阵的谱条件数 $\\kappa_{2}(A)$。\n    - `amplification_factor`：比率 $\\gamma = \\lVert e^{(k)} \\rVert_{2} / \\lVert r^{(k)} \\rVert_{2}$。\n\n此过程将应用于提供的三个测试用例，这三个用例旨在说明不同的行为：一个良态的收敛情况，一个病态但仍然收敛的情况，以及一个发散的情况。结果将为残差、误差和条件数之间的理论关系提供经验证据。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_jacobi_test(A, x_star, tau, N_max):\n    \"\"\"\n    Performs the Jacobi iteration for a given linear system Ax=b.\n\n    Args:\n        A (np.ndarray): The system matrix.\n        x_star (np.ndarray): The true solution vector.\n        tau (float): The residual norm tolerance for stopping.\n        N_max (int): The maximum number of iterations.\n\n    Returns:\n        list: A list containing the seven required result metrics.\n    \"\"\"\n    # Ensure inputs are numpy arrays with float type for precision\n    A = np.array(A, dtype=float)\n    x_star = np.array(x_star, dtype=float)\n    b = A @ x_star  # Calculate b from A and the known true solution\n\n    n = A.shape[0]\n    x_current = np.zeros(n, dtype=float)\n    \n    # Pre-calculate matrices for Jacobi iteration\n    diag_A = np.diag(A)\n    # The problem guarantees non-zero diagonal entries\n    D_inv = np.diag(1.0 / diag_A)\n    R = A - np.diag(diag_A)\n\n    num_iter = 0\n    converged = False\n\n    # The main iteration loop\n    for k in range(1, N_max + 1):\n        num_iter = k\n        \n        # Jacobi update: x_k = D^-1 * (b - (L+U) * x_{k-1})\n        x_next = D_inv @ (b - R @ x_current)\n        x_current = x_next\n        \n        # Calculate residual and its norm for the current iterate\n        r_current = b - A @ x_current\n        r_norm_current = np.linalg.norm(r_current, 2)\n        \n        # Check stopping criterion\n        if r_norm_current = tau:\n            converged = True\n            break\n    else:\n        # This block executes if the for loop completes without a 'break'\n        converged = False\n        r_current = b - A @ x_current\n        r_norm_current = np.linalg.norm(r_current, 2)\n\n    # Post-iteration calculations\n    error_current = x_current - x_star\n    error_norm_current = np.linalg.norm(error_current, 2)\n\n    naive_reliability = error_norm_current = tau\n    \n    cond_A = np.linalg.cond(A, 2)\n    \n    if r_norm_current == 0.0:\n        amplification_factor = 0.0\n    else:\n        amplification_factor = error_norm_current / r_norm_current\n        \n    return [\n        converged,\n        naive_reliability,\n        num_iter,\n        float(r_norm_current),\n        float(error_norm_current),\n        float(cond_A),\n        float(amplification_factor)\n    ]\n\ndef solve():\n    \"\"\"\n    Defines the test cases from the problem statement and runs the analysis.\n    \"\"\"\n    # Test case 1 (well-conditioned, strictly diagonally dominant)\n    A1 = [[4, 1, 1], [1, 3, 0], [1, 0, 2]]\n    x_star1 = [1, -2, 3]\n    tau1 = 1e-10\n    N1 = 1000\n\n    # Test case 2 (ill-conditioned but convergent Jacobi)\n    A2 = [[1, 9e-4], [9e-4, 1e-6]]\n    x_star2 = [1, 1]\n    tau2 = 1e-8\n    N2 = 5000\n\n    # Test case 3 (Jacobi diverges)\n    A3 = [[1, 2], [2, 1]]\n    x_star3 = [1, -1]\n    tau3 = 1e-8\n    N3 = 200\n\n    test_cases = [\n        (A1, x_star1, tau1, N1),\n        (A2, x_star2, tau2, N2),\n        (A3, x_star3, tau3, N3),\n    ]\n\n    results = []\n    for case in test_cases:\n        A, x_star, tau, N_max = case\n        result_list = run_jacobi_test(A, x_star, tau, N_max)\n        results.append(result_list)\n\n    # Format the final output string exactly as specified\n    per_case_strings = [f\"[{','.join(map(str, res))}]\" for res in results]\n    final_output = f\"[{','.join(per_case_strings)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```", "id": "2404697"}, {"introduction": "最后，让我们将雅可比方法置于更广阔的数值算法背景中进行考量。迭代法并非总是最佳选择。本练习将让雅可比方法与直接求解法（LU分解）在计算成本上进行直接比较。通过分析它们的算法复杂度，你将确定一个“交叉”问题规模，超过这个规模后，每次迭代较慢但内存效率更高的雅可比方法会变得比计算密集型的直接法更经济。这将为在真实科学计算中如何选择算法提供至关重要的洞察力[@problem_id:2404653]。", "problem": "您将研究在求解源于二维泊松问题的模型线性系统时，迭代Jacobi方法与直接LU（Lower–Upper）分解之间的算法权衡。考虑一个具有齐次Dirichlet边界条件的边值问题，该问题在一个包含$N \\times N$个内部点的均匀网格上进行离散化，从而得到一个大小为$M \\times M$的线性系统，其中$M = N^2$。系数矩阵$A$对应于拉普拉斯算子的标准五点差分格式，其对角线上的元素为$4$，四个直接相邻位置的元素为$-1$。右端向量对应于一个经过一致离散化的恒定源$f \\equiv 1$。所有三角函数中的角度必须以弧度处理。\n\n您必须：\n\n- 为该问题实现一个Jacobi迭代求解器。给定$N$和容差$\\varepsilon \\in (0,1)$，该求解器从零向量开始迭代，直到残差的相对$\\ell_2$范数$\\|r_k\\|_2 / \\|r_0\\|_2$小于或等于$\\varepsilon$，其中$r_k = b - A x_k$。该求解器必须对任何$N \\ge 2$和任何$\\varepsilon \\in (0,1)$都正确，并以无量纲量表示。此任务不涉及物理单位。\n- 使用标准例程为同一线性系统实现一个直接稠密LU分解求解器（注意：此处有意使用稠密矩阵方法，而非针对稀疏结构的特化方法）。\n- 使用第一性原理运算计数模型，确定对于不同的容差$\\varepsilon$，当Jacobi方法和稠密LU分解都应用于上述二维$N \\times N$内部网格泊松系统时，Jacobi方法变得比稠密LU分解更快的最小网格尺寸$N$。成本模型定义如下：\n  - 令$M = N^2$为未知量的数量。将Jacobi方法的总成本建模为\n    $$\\mathcal{C}_{\\text{J}}(N,\\varepsilon) = M \\times K_{\\text{J}}(N,\\varepsilon),$$\n    其中$K_{\\text{J}}(N,\\varepsilon)$是将相对残差减小到$\\varepsilon$以下所需的Jacobi迭代次数。\n  - 将稠密LU的总成本建模为\n    $$\\mathcal{C}_{\\text{LU}}(N; r) = r \\left(\\tfrac{2}{3} M^3 + 2 M^2 \\right),$$\n    其中$r  0$是一个无量纲常数，用于捕捉相对实现效率和机器相关效应（较小的$r$意味着与Jacobi相比，每个运算单元的LU相对更快）。\n  - 在本练习中，将交叉点$N^\\star(\\varepsilon,r)$定义为满足以下条件的最小整数$N \\ge 2$：\n    $$\\mathcal{C}_{\\text{J}}(N,\\varepsilon) \\le \\mathcal{C}_{\\text{LU}}(N; r)。$$\n- 您的程序必须通过结合您对Jacobi实现的理解与一个基于该模型问题Jacobi迭代矩阵谱性质推导出的$K_{\\text{J}}(N,\\varepsilon)$的数学合理估计，来计算$N^\\star(\\varepsilon,r)$。您必须从第一性原理出发进行推理。不要对代码计时；请使用指定的成本模型。\n\n测试套件：\n对以下四对参数$(\\varepsilon, r)$，评估交叉网格尺寸$N^\\star(\\varepsilon,r)$：\n- $(10^{-6}, 1.0)$,\n- $(10^{-8}, 0.5)$,\n- $(10^{-2}, 2.0)$,\n- $(10^{-12}, 0.25)$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个逗号分隔的四个整数列表，用方括号括起，顺序与测试套件中的顺序相同（例如，“[3,4,2,7]”）。不应打印任何其他文本。\n\n注：\n- 角度必须以弧度为单位。\n- 所有量均为无量纲量；不涉及物理单位。\n- 每个测试用例的答案都是一个整数。", "solution": "所述问题是数值分析中的一个标准练习，其提法是适定的、有科学依据且内部一致的。所有提供的数据和定义足以得出一个唯一的解。因此，我们将直接进行推导和求解。\n\n该问题要求比较求解线性系统$A\\mathbf{x} = \\mathbf{b}$的计算成本。该系统源于单位正方形上带有齐次Dirichlet边界条件的二维泊松方程$\\nabla^2 u = f$。该区域被离散化为一个包含$N \\times N$个内部点的均匀网格。因此，系统大小为$M = N^2$。矩阵$A$代表负拉普拉斯算子$-\\nabla^2$的五点有限差分格式，这导致一个矩阵，其对角线上元素为$4$，对应于四个最近网格邻居的非对角线元素为$-1$。右端向量$\\mathbf{b}$对应于一个恒定源项$f \\equiv 1$。\n\n问题的核心是，根据指定的成本模型，找到一个交叉网格尺寸$N^\\star$，在该尺寸下，Jacobi迭代方法在计算上比直接稠密LU分解更高效。这需要推导出达到给定容差$\\varepsilon$所需的Jacobi迭代次数$K_{\\text{J}}$的解析估计。\n\n首先，我们分析Jacobi方法。矩阵$A$被分解为$A = D - L - U$，其中$D$是$A$的对角部分，$-L$和$-U$分别是其严格下三角和上三角部分。对于我们这个特定的矩阵，$D$是一个标量矩阵，$D = 4I_M$，其中$I_M$是大小为$M$的单位矩阵。Jacobi迭代由以下递推关系定义：\n$$D\\mathbf{x}_{k+1} = (L+U)\\mathbf{x}_k + \\mathbf{b}$$\n这可以重写为$\\mathbf{x}_{k+1} = D^{-1}(L+U)\\mathbf{x}_k + D^{-1}\\mathbf{b}$。迭代矩阵为$T_J = D^{-1}(L+U)$。由于$L+U = D-A$，我们有$T_J = D^{-1}(D-A) = I_M - D^{-1}A$。给定$D = 4I_M$，这可以简化为：\n$$T_J = I_M - \\tfrac{1}{4}A$$\n\nJacobi方法的收敛速度由迭代矩阵的谱半径$\\rho(T_J)$决定，即其特征值的最大绝对值。对于$N \\times N$网格上的二维离散泊松问题，矩阵$A$的特征值是众所周知的：\n$$\\lambda_{p,q}(A) = 4 - 2\\left(\\cos\\left(\\frac{p\\pi}{N+1}\\right) + \\cos\\left(\\frac{q\\pi}{N+1}\\right)\\right) \\quad \\text{for } p,q = 1, 2, \\ldots, N$$\n因此，Jacobi矩阵$T_J$的特征值为：\n$$\\lambda_{p,q}(T_J) = 1 - \\frac{1}{4}\\lambda_{p,q}(A) = 1 - \\frac{1}{4}\\left[4 - 2\\left(\\cos\\left(\\frac{p\\pi}{N+1}\\right) + \\cos\\left(\\frac{q\\pi}{N+1}\\right)\\right)\\right]$$\n$$\\lambda_{p,q}(T_J) = \\frac{1}{2}\\left(\\cos\\left(\\frac{p\\pi}{N+1}\\right) + \\cos\\left(\\frac{q\\pi}{N+1}\\right)\\right)$$\n谱半径$\\rho(T_J)$对应于模最大的特征值。由于余弦函数的参数位于区间$(0, \\pi)$内，所有特征值都是实数且为正。当参数最小时，即$p=1$和$q=1$时，获得最大值：\n$$\\rho(T_J) = \\lambda_{1,1}(T_J) = \\frac{1}{2}\\left(\\cos\\left(\\frac{\\pi}{N+1}\\right) + \\cos\\left(\\frac{\\pi}{N+1}\\right)\\right) = \\cos\\left(\\frac{\\pi}{N+1}\\right)$$\n\n问题指定了基于相对残差范数的停止准则：$\\|\\mathbf{r}_k\\|_2 / \\|\\mathbf{r}_0\\|_2 \\le \\varepsilon$，其中$\\mathbf{r}_k = \\mathbf{b} - A\\mathbf{x}_k$。初始猜测为$\\mathbf{x}_0 = \\mathbf{0}$，因此$\\mathbf{r}_0 = \\mathbf{b}$。残差更新方式为$\\mathbf{r}_{k+1} = T_J \\mathbf{r}_k$，这导致$\\mathbf{r}_k = T_J^k \\mathbf{r}_0$。该准则变为$\\|T_J^k \\mathbf{r}_0\\|_2 / \\|\\mathbf{r}_0\\|_2 \\le \\varepsilon$。\n使用矩阵范数可以建立一个标准上界：$\\|T_J^k \\mathbf{r}_0\\|_2 \\le \\|T_J^k\\|_2 \\|\\mathbf{r}_0\\|_2$。由于$T_J$是对称的，所以$\\|T_J\\|_2 = \\rho(T_J)$，因此$\\|T_J^k\\|_2 = (\\rho(T_J))^k$。如果$(\\rho(T_J))^k \\le \\varepsilon$，则条件满足。为了求解迭代次数$k$，我们取对数：\n$$k \\ln(\\rho(T_J)) \\le \\ln(\\varepsilon)$$\n由于对于任何有限的$N \\ge 1$，都有$\\rho(T_J)  1$，其对数为负。因此，在除法时我们必须反转不等号：\n$$k \\ge \\frac{\\ln(\\varepsilon)}{\\ln(\\rho(T_J))}$$\n所需的迭代次数$K_{\\text{J}}$是满足此条件的最小整数，即右侧表达式的向上取整。\n$$K_{\\text{J}}(N,\\varepsilon) = \\left\\lceil \\frac{\\ln(\\varepsilon)}{\\ln\\left(\\cos\\left(\\frac{\\pi}{N+1}\\right)\\right)} \\right\\rceil$$\n\n现在我们来构建成本模型。Jacobi方法的成本给出如下：\n$$\\mathcal{C}_{\\text{J}}(N,\\varepsilon) = M \\times K_{\\text{J}}(N,\\varepsilon) = N^2 \\left\\lceil \\frac{\\ln(\\varepsilon)}{\\ln\\left(\\cos\\left(\\frac{\\pi}{N+1}\\right)\\right)} \\right\\rceil$$\n稠密LU分解的成本给出如下：\n$$\\mathcal{C}_{\\text{LU}}(N; r) = r \\left(\\frac{2}{3} M^3 + 2 M^2 \\right) = r \\left(\\frac{2}{3} (N^2)^3 + 2 (N^2)^2 \\right) = r \\left(\\frac{2}{3} N^6 + 2 N^4 \\right)$$\n\n交叉网格尺寸$N^\\star(\\varepsilon, r)$是使得Jacobi方法变得更快的最小整数$N \\ge 2$，即$\\mathcal{C}_{\\text{J}}(N,\\varepsilon) \\le \\mathcal{C}_{\\text{LU}}(N; r)$。这给出了不等式：\n$$N^2 \\left\\lceil \\frac{\\ln(\\varepsilon)}{\\ln\\left(\\cos\\left(\\frac{\\pi}{N+1}\\right)\\right)} \\right\\rceil \\le r \\left(\\frac{2}{3} N^6 + 2 N^4 \\right)$$\n对于$N \\ge 1$，我们可以两边同除以$N^2$：\n$$\\left\\lceil \\frac{\\ln(\\varepsilon)}{\\ln\\left(\\cos\\left(\\frac{\\pi}{N+1}\\right)\\right)} \\right\\rceil \\le r \\left(\\frac{2}{3} N^4 + 2 N^2 \\right)$$\n代表迭代次数的左侧部分近似以$O(N^2)$增长，而右侧项则以$O(N^4)$增长。对于较小的$N$，Jacobi成本$\\mathcal{C}_{\\text{J}} \\approx O(N^4)$将超过LU成本$\\mathcal{C}_{\\text{LU}} \\approx O(N^6)$，但由于多项式的高阶增长，LU成本最终将占主导地位。我们正在寻找不等式开始成立的第一个整数$N \\ge 2$。\n由于向上取整函数和超越项的存在，这个不等式不易求得$N$的封闭解。然而，我们可以通过从$N=2$开始迭代整数值并停在第一个满足条件的数值处，以计算方式找到解。这些函数是单调的，确保了唯一的交叉点。我们将为测试套件中提供的每一对参数$(\\varepsilon, r)$实现这个搜索过程。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the crossover grid size N* for which the Jacobi method becomes\n    more efficient than dense LU factorization for a 2D Poisson problem.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (1e-6, 1.0),\n        (1e-8, 0.5),\n        (1e-2, 2.0),\n        (1e-12, 0.25),\n    ]\n\n    results = []\n    for epsilon, r_factor in test_cases:\n        n_star = find_crossover_n(epsilon, r_factor)\n        results.append(n_star)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef find_crossover_n(epsilon, r):\n    \"\"\"\n    Searches for the smallest integer N >= 2 that satisfies the crossover condition.\n\n    Args:\n        epsilon (float): The tolerance for the Jacobi solver.\n        r (float): The relative efficiency factor for the LU solver.\n\n    Returns:\n        int: The smallest grid size N for which Jacobi is more efficient.\n    \"\"\"\n    n = 2\n    while True:\n        # Calculate the number of Jacobi iterations, K_J.\n        # The spectral radius of the Jacobi iteration matrix is rho_J = cos(pi / (N+1)).\n        arg_cos = np.pi / (n + 1)\n        \n        # For N >= 2, 0  arg_cos  pi/2, so cos is in (0, 1) and its log is negative.\n        rho_j = np.cos(arg_cos)\n        k_j = np.ceil(np.log(epsilon) / np.log(rho_j))\n\n        # Calculate the computational cost for Jacobi, C_J.\n        # The system size is M = N*N. Cost model is M * K_J.\n        cost_j = (n**2) * k_j\n\n        # Calculate the computational cost for dense LU, C_LU.\n        # Cost model is r * (2/3 * M^3 + 2 * M^2).\n        m = n**2\n        cost_lu = r * ((2/3) * (m**3) + 2 * (m**2))\n\n        # Check for the crossover condition.\n        if cost_j = cost_lu:\n            return n\n        \n        n += 1\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "2404653"}]}