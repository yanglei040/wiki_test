{"hands_on_practices": [{"introduction": "在计算物理和实验数据分析中，一个常见的任务是通过拟合数据来确定物理常数。Bootstrap方法是一个强大的工具，它可以在不对数据误差分布做强假设的情况下，量化拟合参数的不确定性。本练习将指导你通过对(应力, 应变)数据对进行自助法重采样，来估算从拟合直线斜率得到的杨氏模量的不确定性[@problem_id:2404303]。", "problem": "您面临一个计算物理任务，需要根据拟合的应力-应变曲线的斜率，估计模拟纳米线的杨氏模量的不确定性。假设在小应变情况下，适用线性弹性理论，应力-应变关系遵循胡克定律，即轴向应力与轴向应变成正比，比例常数即为杨氏模量。您将通过在一个具有已知真实模量的线性关系上添加独立同分布的测量噪声，来模拟在给定应变下的应力测量值。根据这些模拟的 $(\\text{应变}, \\text{应力})$ 数据对，您将通过零截距线性拟合的斜率来估计杨氏模量。然后，您将使用自助法，通过对数据对进行有放回重抽样并为每次重抽样重新计算斜率，来估计该斜率的不确定性。您的任务是为几个测试用例实现这一端到端流程，并报告估计的杨氏模量的自助法标准误。所有应力必须以吉帕（GPa）表示，应变为无量纲。所有答案必须以吉帕（GPa）报告，并四舍五入到小数点后恰好六位。\n\n使用以下基本依据：\n- 小应变范围内的胡克定律：轴向应力 $\\sigma$ 通过杨氏模量 $E$ 与轴向应变 $\\varepsilon$ 成正比。\n- 普通最小二乘法，作为从含噪声数据中估计线性关系的标准方法。\n- 自助法原理：估计量的抽样分布可以通过从观测数据中有放回地重抽样，并在每个重抽样样本上重新计算该估计量来近似。\n\n实现一个程序，该程序：\n1. 按如下方式为每个测试用例生成合成的 $(\\varepsilon_i, \\sigma_i)$ 数据。对每个用例，在最小应变和最大应变之间（含两端）取 $n$ 个线性间隔的应变值，然后使用真实模量计算无噪声应力，最后向应力值添加具有指定标准差的独立高斯噪声。使用提供的随机种子以确保可复现性。\n2. 通过使用普通最小二乘法拟合一个零截距的线性模型（即直线通过原点），从模拟数据中估计杨氏模量 $E$。\n3. 通过从观测到的 $(\\varepsilon_i,\\sigma_i)$ 数据对中有放回地抽取 $n$ 个数据对，对每个重抽样样本重新拟合零截距线性模型，并收集自助法斜率，来进行非参数自助法重抽样。使用提供的自助法种子和指定的自助法重复次数 $B$。\n4. 为每个测试用例报告斜率估计的自助法标准误，其定义为自助法斜率的样本标准差（自由度为 $1$）。以吉帕（GPa）为单位报告标准误，并四舍五入到小数点后恰好六位。\n\n物理和数值单位：\n- 应变 $\\varepsilon$ 是无量纲的。\n- 应力 $\\sigma$ 必须以吉帕（GPa）为单位。\n- 杨氏模量 $E$ 必须以吉帕（GPa）为单位报告。\n- 所有角度均与此问题无关，无需使用。\n\n测试套件：\n使用以下三个用例。每个用例都指定了真实模量、数据点数量、应变范围、应力噪声水平、自助法重复次数以及用于数据生成和自助法重抽样的种子。所有数值都应以上述单位进行解释。\n\n- 用例 1（一般情况，中等噪声）：\n  - 真实模量 $E_{\\text{true}} = 200$ 吉帕。\n  - 数据点数量 $n = 25$.\n  - 应变范围 $[\\varepsilon_{\\min}, \\varepsilon_{\\max}] = [0.002, 0.010]$.\n  - 应力噪声标准差 $\\sigma_{\\text{noise}} = 0.5$ 吉帕。\n  - 自助法重复次数 $B = 5000$.\n  - 数据生成种子 $s_{\\text{data}} = 12345$, 自助法种子 $s_{\\text{boot}} = 54321$.\n\n- 用例 2（数据点较少，噪声较高）：\n  - 真实模量 $E_{\\text{true}} = 70$ 吉帕。\n  - 数据点数量 $n = 12$.\n  - 应变范围 $[\\varepsilon_{\\min}, \\varepsilon_{\\max}] = [0.005, 0.025]$.\n  - 应力噪声标准差 $\\sigma_{\\text{noise}} = 2.0$ 吉帕。\n  - 自助法重复次数 $B = 5000$.\n  - 数据生成种子 $s_{\\text{data}} = 24680$, 自助法种子 $s_{\\text{boot}} = 86420$.\n\n- 用例 3（边界情况，无噪声）：\n  - 真实模量 $E_{\\text{true}} = 150$ 吉帕。\n  - 数据点数量 $n = 8$.\n  - 应变范围 $[\\varepsilon_{\\min}, \\varepsilon_{\\max}] = [0.003, 0.015]$.\n  - 应力噪声标准差 $\\sigma_{\\text{noise}} = 0.0$ 吉帕。\n  - 自助法重复次数 $B = 5000$.\n  - 数据生成种子 $s_{\\text{data}} = 13579$, 自助法种子 $s_{\\text{boot}} = 97531$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含与上述三个测试用例按顺序列出的三个自助法标准误（以吉帕为单位），形式为一个用方括号括起来的逗号分隔列表，每个值都四舍五入到小数点后恰好六位，例如 `[0.123456,0.234567,0.000000]`。", "solution": "该问题陈述已经过验证，被认为是有效的。它具有科学依据，是适定的、客观的，并包含了推导出唯一、可验证解所需的所有信息。该问题是计算物理学中的一个标准练习，涉及从模拟的含噪声数据中估计物理参数及其不确定性。\n\n任务是计算从应力-应变曲线估计出的杨氏模量 $E$ 的标准误。该估计将使用自助法进行。整个流程基于三个核心原则：作为物理模型的胡克定律，用于参数拟合的普通最小二乘法，以及用于不确定性量化的自助法重抽样。\n\n物理模型是胡克定律，该定律指出，对于小形变，轴向应力 $\\sigma$ 与轴向应变 $\\varepsilon$ 呈线性正比关系：\n$$ \\sigma = E \\varepsilon $$\n比例常数 $E$ 即为杨氏模量。该模型表示一条通过原点的直线，因为零应变必须对应零应力。\n\n首先，我们必须为每个测试用例生成合成数据。给定真实模量 $E_{\\text{true}}$、数据点数量 $n$、应变范围 $[\\varepsilon_{\\min}, \\varepsilon_{\\max}]$ 和应力噪声标准差 $\\sigma_{\\text{noise}}$。对于 $i=1, \\dots, n$，应变值 $\\varepsilon_i$ 是从 $\\varepsilon_{\\min}$ 到 $\\varepsilon_{\\max}$（含两端）的 $n$ 个线性间隔点。相应的应力值 $\\sigma_i$ 通过从胡克定律得到的理想应力 $\\sigma_{i, \\text{true}} = E_{\\text{true}} \\varepsilon_i$ 加上随机噪声 $\\delta_i$ 来模拟测量误差。\n$$ \\sigma_i = E_{\\text{true}} \\varepsilon_i + \\delta_i $$\n噪声项 $\\delta_i$ 是从均值为 $0$、标准差为 $\\sigma_{\\text{noise}}$ 的高斯（正态）分布中抽取的独立同分布随机变量，形式上记为 $\\delta_i \\sim \\mathcal{N}(0, \\sigma_{\\text{noise}}^2)$。使用 `data-generation seed` $s_{\\text{data}}$ 来确保此随机过程的可复现性。\n\n接下来，从生成的包含 $n$ 个数据对 $\\{(\\varepsilon_i, \\sigma_i)\\}_{i=1}^n$ 的数据集中，我们必须估计杨氏模量。对于通过原点的线性模型 $\\sigma = E \\varepsilon$，普通最小二乘（OLS）估计量 $\\hat{E}$ 是使残差平方和 $S(E) = \\sum_{i=1}^{n} (\\sigma_i - E \\varepsilon_i)^2$ 最小化的值。为找到此最小值，我们将关于 $E$ 的导数设为零：\n$$ \\frac{dS}{dE} = \\sum_{i=1}^{n} 2(\\sigma_i - E \\varepsilon_i)(-\\varepsilon_i) = 0 $$\n解此方程得到 $E$ 的 OLS 估计量：\n$$ \\hat{E} = \\frac{\\sum_{i=1}^{n} \\varepsilon_i \\sigma_i}{\\sum_{i=1}^{n} \\varepsilon_i^2} $$\n此公式为约束通过原点的直线提供了最佳拟合斜率。\n\n问题的核心是估计此估计量 $\\hat{E}$ 的不确定性。我们使用非参数自助法。原始数据集 $\\{(\\varepsilon_i, \\sigma_i)\\}_{i=1}^n$ 被视为一个经验分布。我们对 $B$ 次自助法重复执行以下步骤，在此问题中 $B=5000$：\n1.  通过从原始数据集中有放回地抽取 $n$ 个数据对来生成一个*自助样本*。设这个新样本为 $\\{(\\varepsilon_j^*, \\sigma_j^*)\\}_{j=1}^n$。\n2.  对于这个自助样本，使用相同的 OLS 公式计算模量的自助估计值 $\\hat{E}^*$：\n    $$ \\hat{E}^* = \\frac{\\sum_{j=1}^{n} \\varepsilon_j^* \\sigma_j^*}{\\sum_{j=1}^{n} (\\varepsilon_j^*)^2} $$\n3.  存储这个值 $\\hat{E}^*$。\n\n重复此过程 $B$ 次后，我们得到一个包含 $B$ 个自助估计值的集合，$\\{\\hat{E}_1^*, \\hat{E}_2^*, \\dots, \\hat{E}_B^*\\}$。这个集合可作为我们估计量 $\\hat{E}$ 的抽样分布的经验近似。`bootstrap-seed` $s_{\\text{boot}}$ 确保了此重抽样过程也是可复现的。\n\n最后，我们计算自助法标准误 $\\text{SE}_{\\text{boot}}(\\hat{E})$，即自助估计值的样本标准差。它是我们估计值 $\\hat{E}$ 中统计不确定性的一个度量。按规定使用 $B-1$ 自由度的公式为：\n$$ \\text{SE}_{\\text{boot}}(\\hat{E}) = \\sqrt{\\frac{1}{B-1} \\sum_{b=1}^{B} (\\hat{E}_b^* - \\bar{E}^*)^2} $$\n其中 $\\bar{E}^* = \\frac{1}{B} \\sum_{b=1}^{B} \\hat{E}_b^*$ 是自助估计值的均值。\n\n一个需要特别考虑的是用例 $3$，其中 $\\sigma_{\\text{noise}} = 0.0$. 在这种情况下，初始数据点完美地位于直线 $\\sigma = E_{\\text{true}} \\varepsilon$ 上。任何自助样本都将由同样位于这条精确直线上的点组成。因此，每个自助斜率估计值 $\\hat{E}_b^*$ 在解析上都将等于 $E_{\\text{true}}$。一组常数值的标准差恰好为 $0$。因此，对于此用例，自助法标准误必须为 $0.000000$. 这可以作为算法逻辑的一个验证检查。\n\n实现将通过为指定的三个测试用例中的每一个执行此完整流程，并按要求格式化最终的标准误来完成。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for all given test cases.\n    It calculates the bootstrap standard error for Young's modulus estimates\n    and prints the results in the specified format.\n    \"\"\"\n    test_cases = [\n        # Case 1 (general case, moderate noise)\n        (200.0, 25, [0.002, 0.010], 0.5, 5000, 12345, 54321),\n        # Case 2 (fewer points, higher noise)\n        (70.0, 12, [0.005, 0.025], 2.0, 5000, 24680, 86420),\n        # Case 3 (boundary case, no noise)\n        (150.0, 8, [0.003, 0.015], 0.0, 5000, 13579, 97531),\n    ]\n\n    results = []\n    for case in test_cases:\n        E_true, n, strain_range, sigma_noise, B, s_data, s_boot = case\n\n        # Step 1: Generate synthetic (strain, stress) data\n        # Use the data-generation seed for reproducibility.\n        rng_data = np.random.default_rng(s_data)\n        \n        strains = np.linspace(strain_range[0], strain_range[1], n)\n        stress_true = E_true * strains\n        noise = rng_data.normal(loc=0.0, scale=sigma_noise, size=n)\n        stress_obs = stress_true + noise\n\n        # Step 2: Perform nonparametric bootstrap resampling\n        # Use the bootstrap seed for reproducibility.\n        rng_boot = np.random.default_rng(s_boot)\n        bootstrap_slopes = np.zeros(B)\n        \n        # Original data indices for resampling\n        data_indices = np.arange(n)\n\n        for i in range(B):\n            # Create a bootstrap sample by sampling indices with replacement.\n            boot_indices = rng_boot.choice(data_indices, size=n, replace=True)\n            strains_boot = strains[boot_indices]\n            stress_boot = stress_obs[boot_indices]\n            \n            # Estimate the slope (Young's modulus) for the bootstrap sample\n            # using the OLS formula for a zero-intercept model.\n            sum_x_squared = np.sum(strains_boot**2)\n            \n            # This check prevents division by zero, although it is not expected\n            # to occur with the given problem inputs.\n            if sum_x_squared == 0:\n                slope_b = 0.0\n            else:\n                slope_b = np.sum(strains_boot * stress_boot) / sum_x_squared\n            \n            bootstrap_slopes[i] = slope_b\n            \n        # Step 3: Compute the bootstrap standard error\n        # The standard error is the standard deviation of the bootstrap slopes.\n        # ddof=1 specifies the use of N-1 in the denominator for sample std dev.\n        std_error = np.std(bootstrap_slopes, ddof=1)\n        results.append(std_error)\n\n    # Final print statement in the exact required format.\n    # The f-string format specifier '{:.6f}' rounds to 6 decimal places.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "2404303"}, {"introduction": "来自计算物理模拟（如蒙特卡洛或分子动力学）的数据通常是时间序列，其中连续的数据点是相关的。如果将为独立数据设计的重采样方法直接应用于此类数据，会低估真实误差。本练习将介绍分块Jackknife方法，这是一种从相关数据中正确估计统计误差的关键技术，并以通过能量涨落计算热容为例进行具体说明[@problem_id:2404291]。", "problem": "您的任务是构建一个完整的、可运行的程序，该程序利用合成的正则系综能量时间序列，通过刀切法（jackknife method）估计定容热容的统计误差。从以下基本原理开始：在正则系综中，定容热容（缩写为 CV）满足将热响应与能量涨落联系起来的涨落-耗散关系。具体来说，如果 $E$ 表示能量，$\\langle \\cdot \\rangle$ 表示系综平均，那么在玻尔兹曼常数 $k_B=1$ 的单位制下，定容热容 $C_V$ 遵循一个将其与能量涨落和绝对温度 $T$ 联系起来的恒等式。在产生有限能量时间序列的数值模拟中，期望值由样本平均值来近似。您的任务是通过能量涨落路径，从能量时间序列中估计 $C_V$，然后使用刀切法估计该 $C_V$ 估计量的标准误。\n\n您的程序必须实现以下功能：\n\n- 使用正则系综的涨落-耗散关系构建定容热容的估计量。使用样本能量时间序列来产生所需的平均值。所有量都采用 $k_B=1$ 的约化单位进行处理，因此报告的 $C_V$ 是无量纲的 $C_V/k_B$。\n\n- 为独立样本实现删除一个（留一法）刀切法，以及为相关时间序列实现分块刀切法。在分块刀切法中，将时间序列划分为大小相等、连续且不重叠的块，并通过一次删除一整个块来形成刀切法重采样样本。如果时间序列的长度 $N$ 不是块大小 $b$ 的整数倍，则在为刀切法形成 $\\lfloor N/b \\rfloor$ 个完整块后，忽略尾部数据。使用标准的刀切法构造来获得热容估计量的标准误的刀切法估计（刀切法方差估计的平方根）。对于分块刀切法，刀切法重采样样本的数量等于块的数量，并适用相同的标准刀切法方差构造。\n\n- 最终输出必须是刀切法标准误（每个测试用例一个），每个都表示为浮点数。因为我们在 $k_B=1$ 的约化单位下工作，所以输出是无量纲的。\n\n合成数据生成（测试套件）：\n\n您的程序必须使用指定的随机种子和模型在内部生成以下三个能量时间序列。使用按规定确定性播种的伪随机数生成器，以确保结果是可复现的。\n\n- 测试用例 1（独立同分布数据，“理想情况”）：在温度 $T=1$ 时，从均值为 $\\mu=0$、标准差为 $\\sigma=2$ 的正态分布中生成 $N=400$ 个能量。使用种子 $314159$。使用留一法刀切法，即块大小 $b=1$。\n\n- 测试用例 2（小样本边界情况）：在温度 $T=1$ 时，从均值为 $\\mu=0.3$、标准差为 $\\sigma=1$ 的正态分布中生成 $N=8$ 个能量。使用种子 $271828$。使用留一法刀切法，即块大小 $b=1$。\n\n- 测试用例 3（强相关时间序列）：通过平稳一阶自回归过程（缩写为 AR(1)）生成 $N=1000$ 个能量，其参数为 $\\phi=0.9$，新息噪声 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma_\\varepsilon^2)$ 且 $\\sigma_\\varepsilon=1$。通过从 AR(1) 过程的平稳分布中抽样来初始化 $E_0$。然后，对于 $t=1,\\dots,N-1$，演化 $E_t=\\phi E_{t-1}+\\varepsilon_t$。使用温度 $T=1$ 和种子 $424242$。使用块大小为 $b=20$ 的分块刀切法。\n\n计算细节和约束：\n\n- 对于每个时间序列，在 $k_B=1$ 的单位制下，使用能量涨落路径和样本平均值计算热容估计量。然后计算此估计量的刀切法标准误。对于分块刀切法，将数据划分为大小为 $b$ 的连续块，如果最后有剩余的 $N - b \\lfloor N/b \\rfloor$ 个能量值，则将其忽略。确保至少形成 2 个刀切法重采样样本；否则，标准误未定义，程序在所提供的测试套件上不得失败。\n\n- 角度单位不适用。除了所述的约化单位外，不需要其他物理单位；报告无量纲数。\n\n要求的最终输出格式：\n\n- 您的程序应生成单行输出，其中包含三个刀切法标准误（按顺序对应测试用例 1、2 和 3），格式为方括号括起来的逗号分隔列表，每个数字四舍五入到恰好 6 位小数，例如 `[0.123456,0.234567,0.345678]`。\n\n您的解决方案必须是自包含的，不需要任何输入，并严格遵循指定的种子和参数。唯一允许使用的库是 Python 标准库和所列出的数值库。", "solution": "用户要求编写一个程序，用于从合成的时间序列数据中计算定容热容 $C_V$ 的刀切法标准误。这需要应用统计力学和计算统计学中的原理。\n\n首先，我们必须将热容的估计量形式化。在正则系综中，配分函数由 $Z = \\sum_{i} \\exp(-\\beta E_i)$ 给出，其中 $E_i$ 表示微观态 $i$ 的能量，$\\beta = (k_B T)^{-1}$ 是逆温度，$T$ 是绝对温度，$k_B$ 是玻尔兹曼常数。根据问题规范，我们在 $k_B=1$ 的约化单位下操作，使得 $\\beta = 1/T$。能量的系综平均值 $\\langle E \\rangle$ 可由配分函数得到：\n$$\n\\langle E \\rangle = -\\frac{\\partial \\ln Z}{\\partial \\beta}\n$$\n定容热容 $C_V$ 定义为平均能量对温度的导数：\n$$\nC_V = \\frac{\\partial \\langle E \\rangle}{\\partial T}\n$$\n通过应用链式法则，$\\frac{\\partial}{\\partial T} = \\frac{\\partial \\beta}{\\partial T} \\frac{\\partial}{\\partial \\beta} = -\\frac{1}{k_B T^2} \\frac{\\partial}{\\partial \\beta}$，并设 $k_B=1$，我们发现：\n$$\nC_V = -\\frac{1}{T^2} \\frac{\\partial \\langle E \\rangle}{\\partial \\beta} = -\\frac{1}{T^2} \\frac{\\partial}{\\partial \\beta} \\left( -\\frac{\\partial \\ln Z}{\\partial \\beta} \\right) = \\frac{1}{T^2} \\frac{\\partial^2 \\ln Z}{\\partial \\beta^2}\n$$\n进行微分可得到热容的涨落-耗散定理：\n$$\nC_V = \\frac{1}{T^2} \\left( \\langle E^2 \\rangle - \\langle E \\rangle^2 \\right) = \\frac{\\text{Var}(E)}{T^2}\n$$\n其中 $\\text{Var}(E)$ 是能量的方差。对于一个包含 $N$ 个能量测量值的有限时间序列 $\\{E_i\\}_{i=1}^N$，系综平均 $\\langle \\cdot \\rangle$ 被其样本估计量所替代。因此，$C_V$ 的估计量（表示为 $\\hat{\\theta}$）为：\n$$\n\\hat{\\theta} = \\frac{1}{T^2} \\left[ \\left(\\frac{1}{N}\\sum_{i=1}^N E_i^2\\right) - \\left(\\frac{1}{N}\\sum_{i=1}^N E_i\\right)^2 \\right]\n$$\n\n其次，我们采用刀切法来估计 $\\hat{\\theta}$ 的统计误差。刀切法是一种重采样技术，可提供估计量方差的估计值。\n\n对于独立同分布（i.i.d.）数据，如测试用例 1 和 2，我们使用删除一个刀切法。这等价于块大小 $b=1$ 的分块刀切法。给定一个大小为 $N$ 的样本，我们创建 $N$ 个刀切法重采样样本。第 $j$ 个重采样样本的估计量 $\\hat{\\theta}_{(j)}$ 是通过将估计量公式应用于移除了第 $j$ 个观测值的样本来计算的。刀切法方差则计算如下：\n$$\n\\widehat{\\text{Var}}_{\\text{jack}}(\\hat{\\theta}) = \\frac{N-1}{N} \\sum_{j=1}^N \\left(\\hat{\\theta}_{(j)} - \\hat{\\theta}_{(\\cdot)}\\right)^2\n$$\n其中 $\\hat{\\theta}_{(\\cdot)} = \\frac{1}{N} \\sum_{j=1}^N \\hat{\\theta}_{(j)}$ 是刀切法重采样样本估计量的均值。\n\n对于相关的时间序列数据，如测试用例 3，删除一个方法是不合适的，因为它未能保留相关性结构，导致对真实方差的低估。正确的方法是分块刀切法。将长度为 $N$ 的时间序列划分为 $L = \\lfloor N/b \\rfloor$ 个不重叠的块，每个块的大小为 $b$。块大小 $b$ 理想情况下应大于序列的自相关时间。刀切法重采样样本是通过一次删除一整个块来形成的。分块刀切法方差的公式是类似的，只是有 $L$ 个重采样样本而不是 $N$ 个：\n$$\n\\widehat{\\text{Var}}_{\\text{block-jack}}(\\hat{\\theta}) = \\frac{L-1}{L} \\sum_{j=1}^L \\left(\\hat{\\theta}_{(j)} - \\hat{\\theta}_{(\\cdot)}\\right)^2\n$$\n其中 $\\hat{\\theta}_{(j)}$ 是从移除了第 $j$ 个块的样本中计算出的估计量，而 $\\hat{\\theta}_{(\\cdot)}$ 是这 $L$ 个重采样样本估计量的均值。在两种情况下，标准误都是估计方差的平方根，即 $\\hat{\\sigma} = \\sqrt{\\widehat{\\text{Var}}}$。\n\n对于每个测试用例，实现将执行以下操作：\n1.  **数据生成**：根据指定的模型（正态或 AR(1)）和参数（$N, T, \\mu, \\sigma, \\phi, \\sigma_\\varepsilon$）以及给定的随机种子，生成能量时间序列 $\\{E_i\\}_{i=1}^N$。对于 AR(1) 过程 $E_t = \\phi E_{t-1} + \\varepsilon_t$，初始值 $E_0$ 从其平稳分布中抽取，该分布为 $\\mathcal{N}(0, \\sigma_E^2)$，方差为 $\\sigma_E^2 = \\sigma_\\varepsilon^2 / (1-\\phi^2)$。\n2.  **分块**：将数据划分为 $L = \\lfloor N/b \\rfloor$ 个大小为 $b$ 的块。尾部任何剩余的数据点都将被丢弃。\n3.  **重采样样本计算**：对于 $L$ 个块中的每一个，从移除了该块的数据集中计算一个刀切法重采样样本的估计量 $\\hat{\\theta}_{(j)}$。这可以通过为每个块预先计算能量总和和能量平方和来高效完成。\n4.  **误差估计**：使用 $L$ 个重采样样本的估计量集合 $\\{\\hat{\\theta}_{(j)}\\}_{j=1}^L$ 来计算刀切法方差，并随后计算标准误。\n\n程序将此过程应用于所有三个具有特定参数的测试用例：\n-   **用例 1**：i.i.d. 数据，$N=400$，$T=1$，来自 $\\mathcal{N}(\\mu=0, \\sigma=2)$。块大小 $b=1$，因此 $L=400$。\n-   **用例 2**：小型 i.i.d. 样本，$N=8$，$T=1$，来自 $\\mathcal{N}(\\mu=0.3, \\sigma=1)$。块大小 $b=1$，因此 $L=8$。\n-   **用例 3**：相关的 AR(1) 数据，$N=1000$，$T=1$，$\\phi=0.9$，新息噪声来自 $\\mathcal{N}(0, 1)$。块大小为 $b=20$，因此 $L = \\lfloor 1000/20 \\rfloor = 50$。\n\n最终结果是这三种不同物理场景的标准误。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of estimating the jackknife standard error for the\n    constant-volume heat capacity from synthetic energy time series.\n    \"\"\"\n    \n    test_cases = [\n        {\n            \"id\": 1, \"type\": \"iid\", \"N\": 400, \"mu\": 0.0, \"sigma\": 2.0, \"T\": 1.0, \n            \"seed\": 314159, \"block_size\": 1\n        },\n        {\n            \"id\": 2, \"type\": \"iid\", \"N\": 8, \"mu\": 0.3, \"sigma\": 1.0, \"T\": 1.0, \n            \"seed\": 271828, \"block_size\": 1\n        },\n        {\n            \"id\": 3, \"type\": \"ar1\", \"N\": 1000, \"phi\": 0.9, \"sigma_eps\": 1.0, \"T\": 1.0, \n            \"seed\": 424242, \"block_size\": 20\n        },\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        rng = np.random.default_rng(case[\"seed\"])\n        \n        # Step 1: Generate a synthetic energy time series\n        if case[\"type\"] == \"iid\":\n            energies = rng.normal(loc=case[\"mu\"], scale=case[\"sigma\"], size=case[\"N\"])\n        elif case[\"type\"] == \"ar1\":\n            N = case[\"N\"]\n            phi = case[\"phi\"]\n            sigma_eps = case[\"sigma_eps\"]\n            \n            # Variance of the stationary distribution of AR(1) process\n            var_E_stationary = sigma_eps**2 / (1 - phi**2)\n            \n            # Initialize E_0 from the stationary distribution\n            E0 = rng.normal(loc=0, scale=np.sqrt(var_E_stationary))\n            \n            # Generate innovations\n            epsilons = rng.normal(loc=0, scale=sigma_eps, size=N - 1)\n            \n            # Generate the AR(1) time series\n            energies = np.zeros(N)\n            energies[0] = E0\n            for t in range(1, N):\n                energies[t] = phi * energies[t-1] + epsilons[t-1]\n        \n        # Step 2: Implement the jackknife error estimation\n        N = len(energies)\n        b = case[\"block_size\"]\n        T = case[\"T\"]\n        \n        # Number of blocks\n        L = N // b\n        \n        if L  2:\n            results.append(0.0) # Or handle as an error, but problem implies L>=2\n            continue\n\n        # Truncate the time series to be a multiple of the block size\n        truncated_energies = energies[:L * b]\n        \n        # Reshape data into blocks for efficient computation\n        blocks_E = truncated_energies.reshape((L, b))\n        \n        # Pre-compute sums over blocks\n        block_sums_E = np.sum(blocks_E, axis=1)\n        block_sums_E2 = np.sum(blocks_E**2, axis=1)\n        \n        # Total sums for the entire (truncated) dataset\n        total_sum_E = np.sum(block_sums_E)\n        total_sum_E2 = np.sum(block_sums_E2)\n        \n        # Size of each jackknife replicate sample\n        N_rep = (L - 1) * b\n        \n        replicates_cv = np.zeros(L)\n        \n        # Step 3: Compute jackknife replicates of the C_V estimator\n        for i in range(L):\n            # Sums for the sample with block i removed\n            sum_E_rep = total_sum_E - block_sums_E[i]\n            sum_E2_rep = total_sum_E2 - block_sums_E2[i]\n            \n            # Means for the replicate sample\n            mean_E_rep = sum_E_rep / N_rep\n            mean_E2_rep = sum_E2_rep / N_rep\n            \n            # C_V estimator for replicate i, using C_V = (Var(E)) / T^2\n            replicates_cv[i] = (mean_E2_rep - mean_E_rep**2) / (T**2)\n\n        # Step 4: Calculate the jackknife standard error\n        mean_replicates_cv = np.mean(replicates_cv)\n        # Jackknife variance formula: ((L-1)/L) * sum((theta_i - theta_mean)^2)\n        jackknife_var = (L - 1) / L * np.sum((replicates_cv - mean_replicates_cv)**2)\n        std_error = np.sqrt(jackknife_var)\n        results.append(std_error)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "2404291"}, {"introduction": "在通过编程应用了重采样方法之后，理解其内部工作原理至关重要。本练习提供了一个机会，让你从第一性原理出发，推导并计算Jackknife对偏差和标准误的估计。通过处理一个非标准的估计量（中程数），你将更深入地洞察“删除一个”过程的机制，以及它如何量化一个估计量的统计特性[@problem_id:2404332]。", "problem": "在一个计算物理实验中，一个一维探测器记录了被限制在一个中心 $c$ 未知的矩形陷阱区域中的中性原子的撞击位置。陷阱势确保了撞击位置 $X$ 在区间 $[c - w, c + w]$ 上均匀分布，其中半宽 $w  0$。在一次实验运行中，你获得了 $n = 9$ 个独立的位置测量值\n$$\nx_1 = -1.02,\\; x_2 = -0.83,\\; x_3 = -0.50,\\; x_4 = -0.12,\\; x_5 = 0.05,\\; x_6 = 0.31,\\; x_7 = 0.47,\\; x_8 = 0.88,\\; x_9 = 1.20.\n$$\n为了估计中心 $c$，你考虑使用中程数估计量：\n$$\n\\hat{\\theta} = \\frac{\\max(x_1,\\dots,x_n) + \\min(x_1,\\dots,x_n)}{2}.\n$$\n仅使用Jackknife方法的基本定义（删除一个样本的重抽样和由此产生的留一法估计），从第一性原理推导出 $\\hat{\\theta}$ 偏差的Jackknife估计和 $\\hat{\\theta}$ 标准误的Jackknife估计。然后计算它们对于上述数据集的数值。\n\n将你的最终结果以单行向量 $[\\hat{b}_{\\mathrm{jack}},\\;\\hat{s}_{\\mathrm{jack}}]$ 的形式报告，其中 $\\hat{b}_{\\mathrm{jack}}$ 是Jackknife偏差估计，$\\hat{s}_{\\mathrm{jack}}$ 是Jackknife标准误。将两个条目均四舍五入至四位有效数字。最终数值中无需物理单位。", "solution": "对问题陈述进行验证。\n\n**步骤 1：提取已知条件**\n- **物理系统**：一维探测器记录中性原子的撞击位置。\n- **分布**：撞击位置 $X$ 是一个在区间 $[c - w, c + w]$ 上均匀分布的随机变量，其中 $c$ 是未知中心，$w  0$ 是半宽。\n- **数据集**：提供了一组 $n = 9$ 个独立测量值：$x_1 = -1.02$, $x_2 = -0.83$, $x_3 = -0.50$, $x_4 = -0.12$, $x_5 = 0.05$, $x_6 = 0.31$, $x_7 = 0.47$, $x_8 = 0.88$, $x_9 = 1.20$。\n- **估计量**：中心 $c$ 的估计量是中程数，由 $\\hat{\\theta} = \\frac{\\max(x_1,\\dots,x_n) + \\min(x_1,\\dots,x_n)}{2}$ 给出。\n- **任务**：从第一性原理推导并计算 $\\hat{\\theta}$ 偏差的Jackknife估计和 $\\hat{\\theta}$ 标准误的Jackknife估计。\n- **报告**：最终结果必须是一个行向量 $[\\hat{b}_{\\mathrm{jack}},\\;\\hat{s}_{\\mathrm{jack}}]$，其数值四舍五入到四位有效数字。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据**：该问题在科学上是合理的。它提出了实验物理学中一个简化但合理的情景（粒子俘获和探测），并建议使用一种标准的、成熟的统计技术（Jackknife重抽样）对其进行分析。均匀分布是一种有效且常见的概率模型。\n- **适定性**：该问题是适定的。它提供了所有必要信息：一个特定的数据集、一个明确定义的估计量和一个指定的统计方法。其目标——计算偏差和标准误的估计——是明确无误的。\n- **客观性**：该问题以精确、客观的语言陈述，没有主观论断或歧义。\n\n**步骤 3：结论与行动**\n该问题是有效的。它有科学依据、适定、客观，并包含足够的信息以获得唯一解。继续进行求解。\n\nJackknife方法是一种用于估计估计量的偏差和标准误的重抽样技术。按要求从第一性原理进行推导。\n\n设完整数据集为 $X = \\{x_1, x_2, \\dots, x_n\\}$，其中 $n=9$。参数 $\\theta=c$ 的估计量为 $\\hat{\\theta} = \\hat{\\theta}(X)$。\n给定的估计量是中程数：\n$$\n\\hat{\\theta} = \\frac{x_{(n)} + x_{(1)}}{2}\n$$\n其中 $x_{(1)} = \\min(x_1, \\dots, x_n)$ 和 $x_{(n)} = \\max(x_1, \\dots, x_n)$ 是样本的顺序统计量。\n\n首先，我们计算完整样本的估计量 $\\hat{\\theta}$ 的值。通过检查数据，我们发现：\n$x_{(1)} = -1.02$\n$x_{(n)} = x_{(9)} = 1.20$\n因此，完整样本的估计值为：\n$$\n\\hat{\\theta} = \\frac{1.20 + (-1.02)}{2} = \\frac{0.18}{2} = 0.09\n$$\nJackknife过程需要计算留一法估计。设 $X_{(i)}$ 是移除了第 $i$ 个观测值 $x_i$ 后的数据集。相应的估计值为 $\\hat{\\theta}_{(i)} = \\hat{\\theta}(X_{(i)})$。共有 $n=9$ 个这样的估计值。\n\n估计量 $\\hat{\\theta}$ 仅依赖于样本的最小值和最大值。设排序后的样本为 $x_{(1)}, x_{(2)}, \\dots, x_{(n)}$。\n- 如果我们移除一个不是极值的观测值 $x_j$（即 $x_{(1)}  x_j  x_{(n)}$），子样本的最小值和最大值仍然是 $x_{(1)}$ 和 $x_{(n)}$。对于给定的数据集，这对从 $x_2 = -0.83$ 到 $x_8 = 0.88$ 的 $n-2 = 7$ 个点都成立。对于这些点，留一法估计值保持不变：\n$$\n\\hat{\\theta}_{(i)} = \\frac{x_{(n)} + x_{(1)}}{2} = \\hat{\\theta} = 0.09 \\quad \\text{for } i \\in \\{2, 3, 4, 5, 6, 7, 8\\}\n$$\n- 如果我们移除样本的最小值 $x_1 = x_{(1)} = -1.02$，新的最小值是第二小的值 $x_{(2)} = -0.83$，而最大值保持为 $x_{(9)} = 1.20$。\n$$\n\\hat{\\theta}_{(1)} = \\frac{x_{(9)} + x_{(2)}}{2} = \\frac{1.20 + (-0.83)}{2} = \\frac{0.37}{2} = 0.185\n$$\n- 如果我们移除样本的最大值 $x_9 = x_{(n)} = 1.20$，新的最大值是第二大的值 $x_{(8)} = 0.88$，而最小值保持为 $x_{(1)} = -1.02$。\n$$\n\\hat{\\theta}_{(9)} = \\frac{x_{(8)} + x_{(1)}}{2} = \\frac{0.88 + (-1.02)}{2} = \\frac{-0.14}{2} = -0.07\n$$\n留一法估计值的集合是：$\\{0.185, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, 0.09, -0.07\\}$。\n\n偏差的Jackknife估计 $\\hat{b}_{\\mathrm{jack}}$ 是从这些留一法估计的均值推导出来的。$\\hat{\\theta}$ 的偏差 $B(\\hat{\\theta}) = E[\\hat{\\theta}] - \\theta$ 可由 $(n-1)(\\bar{\\theta}_{(\\cdot)} - \\hat{\\theta})$ 近似，其中 $\\bar{\\theta}_{(\\cdot)}$ 是 $\\hat{\\theta}_{(i)}$ 值的均值。\n$$\n\\hat{b}_{\\mathrm{jack}} = (n-1)(\\bar{\\theta}_{(\\cdot)} - \\hat{\\theta})\n$$\n其中 $\\bar{\\theta}_{(\\cdot)} = \\frac{1}{n} \\sum_{i=1}^n \\hat{\\theta}_{(i)}$。首先，我们计算 $\\bar{\\theta}_{(\\cdot)}$：\n$$\n\\sum_{i=1}^9 \\hat{\\theta}_{(i)} = \\hat{\\theta}_{(1)} + \\hat{\\theta}_{(9)} + 7 \\times \\hat{\\theta} = 0.185 + (-0.07) + 7 \\times 0.09 = 0.115 + 0.63 = 0.745\n$$\n$$\n\\bar{\\theta}_{(\\cdot)} = \\frac{0.745}{9} \\approx 0.082777...\n$$\n现在，我们计算偏差估计：\n$$\n\\hat{b}_{\\mathrm{jack}} = (9-1) \\left(\\frac{0.745}{9} - 0.09\\right) = 8 \\left(\\frac{0.745 - 0.81}{9}\\right) = 8 \\left(\\frac{-0.065}{9}\\right) = \\frac{-0.52}{9} \\approx -0.057777...\n$$\n四舍五入到四位有效数字，$\\hat{b}_{\\mathrm{jack}} = -0.05778$。\n\n$\\hat{\\theta}$ 的标准误的Jackknife估计，记作 $\\hat{s}_{\\mathrm{jack}}$，是从留一法估计的方差推导出来的。$\\hat{\\theta}$ 的Jackknife方差估计为：\n$$\n\\hat{s}_{\\mathrm{jack}}^2 = \\widehat{\\mathrm{Var}}_{\\mathrm{jack}}(\\hat{\\theta}) = \\frac{n-1}{n} \\sum_{i=1}^n (\\hat{\\theta}_{(i)} - \\bar{\\theta}_{(\\cdot)})^2\n$$\n该公式来自于“伪值” $\\psi_i = n\\hat{\\theta} - (n-1)\\hat{\\theta}_{(i)}$ 的样本方差，因为伪值均值的标准误被视为 $\\hat{\\theta}$ 的标准误。\n我们计算离差平方和：\n$$\n\\sum_{i=1}^9 (\\hat{\\theta}_{(i)} - \\bar{\\theta}_{(\\cdot)})^2 = (\\hat{\\theta}_{(1)} - \\bar{\\theta}_{(\\cdot)})^2 + (\\hat{\\theta}_{(9)} - \\bar{\\theta}_{(\\cdot)})^2 + \\sum_{i \\in \\{2..8\\}} (\\hat{\\theta}_{(i)} - \\bar{\\theta}_{(\\cdot)})^2\n$$\n使用数值：\n$$\n(0.185 - \\frac{0.745}{9})^2 + (-0.07 - \\frac{0.745}{9})^2 + 7 \\times (0.09 - \\frac{0.745}{9})^2\n$$\n$$\n\\approx (0.185 - 0.082778)^2 + (-0.07 - 0.082778)^2 + 7 \\times (0.09 - 0.082778)^2\n$$\n$$\n\\approx (0.102222)^2 + (-0.152778)^2 + 7 \\times (0.007222)^2\n$$\n$$\n\\approx 0.01044938 + 0.02334105 + 7 \\times 0.000052157\n$$\n$$\n\\approx 0.01044938 + 0.02334105 + 0.00036510\n$$\n$$\n\\sum_{i=1}^9 (\\hat{\\theta}_{(i)} - \\bar{\\theta}_{(\\cdot)})^2 \\approx 0.03415553\n$$\n现在，我们计算方差估计：\n$$\n\\hat{s}_{\\mathrm{jack}}^2 = \\frac{9-1}{9} \\times 0.03415553 = \\frac{8}{9} \\times 0.03415553 \\approx 0.03036047\n$$\n标准误是方差的平方根：\n$$\n\\hat{s}_{\\mathrm{jack}} = \\sqrt{0.03036047} \\approx 0.1742426\n$$\n四舍五入到四位有效数字，$\\hat{s}_{\\mathrm{jack}} = 0.1742$。\n\n最终结果是包含Jackknife偏差和标准误估计的行向量。", "answer": "$$\n\\boxed{\\begin{pmatrix} -0.05778  0.1742 \\end{pmatrix}}\n$$", "id": "2404332"}]}