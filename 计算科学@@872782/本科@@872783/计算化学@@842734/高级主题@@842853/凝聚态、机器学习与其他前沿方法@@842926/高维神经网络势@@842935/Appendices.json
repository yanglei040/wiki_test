{"hands_on_practices": [{"introduction": "要让神经网络预测原子能量，我们首先需要一种方法来向网络描述每个原子周围的化学环境。这种描述，即“描述符”，必须对系统的平移、旋转和相同种类原子的置换保持不变。这个练习 [@problem_id:2457438] 将指导你从第一性原理出发，实现一种最基本和重要的高维神经网络势描述符——Behler-Parrinello 型的对称函数，从而将抽象的对称性要求与具体的数学和编程实践联系起来。", "problem": "实现一个程序，用于推导和计算氩（Ar）原子的基本双体 Behler–Parrinello 型对称函数，并在一个小的几何结构测试集上对其进行评估。其目的是将机器学习原子间势的不变性要求与一个具体的描述符联系起来，并展示在不同参数选择下的数值行为。其总体背景是，系统的总势能面可以近似为原子贡献的总和，每个贡献都取决于其邻域的局部、对称不变的表示，正如在高维神经网络势（HDNNP）中那样。您的任务是根据不变性原理推导出一个双体径向对称函数，并将其实现。\n\n从以下基本基础开始：\n- 标量势能的平移和旋转不变性意味着原子的局部描述符必须由内部坐标（如原子间距离）构建。\n- 对于有限范围的相互作用和学习映射中的局域性，在有限半径处施加一个平滑的截断，这样超出截断半径的远距离原子就不会产生贡献，并且力也能保持良好的行为。\n- 为了解析原子周围的径向分布，使用具有可调宽度和中心参数的径向基，以便该表示能够区分不同长度尺度下的环境。\n\n根据这些原理，为一个选定的中心原子 $i$ 推导并实现一个双体径向对称函数 $G^2$，其形式为\n- 对邻近原子 $j \\neq i$ 的求和，\n- 一个平滑的、有限范围的截断函数，该函数是 $C^1$ 连续的，并且在截断半径处等于零，\n- 以及一个可以在选定距离周围移动和锐化的局部径向权重。\n\n在您的推导和实现中，具体指定并使用以下形式：\n- 使用余弦截断\n$$\nf_c(r; R_c) = \n\\begin{cases}\n\\dfrac{1}{2}\\left[\\cos\\!\\left(\\dfrac{\\pi r}{R_c}\\right) + 1\\right],  r \\le R_c,\\\\\n0,  r > R_c,\n\\end{cases}\n$$\n其中余弦函数的参数以弧度为单位。\n- 使用类高斯径向基\n$$\n\\exp\\!\\left[-\\eta\\,(r - R_s)^2\\right],\n$$\n其宽度参数为 $\\eta$，位移参数为 $R_s$。\n- 将它们组合成双体对称函数\n$$\nG_i^{2}(\\eta, R_s, R_c) = \\sum_{j \\ne i} \\exp\\!\\left[-\\eta\\,(r_{ij} - R_s)^2\\right]\\, f_c(r_{ij}; R_c),\n$$\n其中 $r_{ij}$ 是原子 $i$ 和 $j$ 之间的欧几里得距离。\n\n所有原子均为氩（Ar），被视为单一化学物种，因此不需要依赖于物种的加权。距离 $r_{ij}$、截断半径 $R_c$ 和位移 $R_s$ 必须以埃（Ångström）为单位表示，$\\eta$ 以 $\\text{Å}^{-2}$ 为单位。余弦函数必须以弧度作为其参数。\n\n程序要求：\n- 实现一个函数，在给定一组笛卡尔坐标（单位为埃）、中心原子的索引 $i$ 以及参数 $(\\eta, R_s, R_c)$ 的情况下，使用上述公式计算 $G_i^{2}(\\eta, R_s, R_c)$。\n- 使用标准三维欧几里得距离。不要应用周期性边界条件。\n- 数值稳定性：排除自相互作用（$j = i$）。距离 $r_{ij}$ 严格非负；除了排除自相互作用外，不要对 $r_{ij} = 0$ 进行特殊处理。\n\n测试集：\n对以下五个案例中的每一个评估 $G_i^{2}$。每个案例都指定了 $(\\text{positions}, i, R_c, \\eta, R_s)$，所有距离单位均为埃，$\\eta$ 的单位为 $\\text{Å}^{-2}$：\n- 案例 A：\n  - 位置：$\\big[(0,0,0),(2.0,0,0),(0,3.0,0),(0,0,4.0)\\big]$\n  - $i = 0$\n  - $R_c = 5.0$\n  - $\\eta = 0.5$\n  - $R_s = 0.0$\n- 案例 B：\n  - 位置：$\\big[(0,0,0)\\big]$\n  - $i = 0$\n  - $R_c = 3.0$\n  - $\\eta = 1.0$\n  - $R_s = 0.0$\n- 案例 C：\n  - 位置：$\\big[(0,0,0),(5.0,0,0),(-5.0,0,0)\\big]$\n  - $i = 0$\n  - $R_c = 5.0$\n  - $\\eta = 1.0$\n  - $R_s = 0.0$\n- 案例 D：\n  - 位置：$\\big[(0,0,0),(2.0,0,0),(0,3.0,0),(0,0,4.0)\\big]$\n  - $i = 0$\n  - $R_c = 5.0$\n  - $\\eta = 2.0$\n  - $R_s = 2.5$\n- 案例 E：\n  - 位置：$\\big[(0,0,0),(2.0,0,0),(0,3.0,0),(0,0,4.0)\\big]$\n  - $i = 1$\n  - $R_c = 5.0$\n  - $\\eta = 0.5$\n  - $R_s = 0.0$\n\n输出规范：\n- 对于每个案例，计算一个单一的浮点值 $G_i^{2}$。\n- 使用标准四舍五入将每个结果精确到 $6$ 位小数。\n- 您的程序应生成单行输出，其中包含按 A、B、C、D、E 顺序排列的结果，形式为方括号内以逗号分隔的列表。例如，一个带有通用占位符的输出应如下所示：\"[0.123456,0.000000,0.000000,1.234567,0.654321]\"。", "solution": "所提出的问题是有效的、科学合理的且定义明确的。它要求推导和实现一个双体径向对称函数，这是现代机器学习原子间势（如高维神经网络势，HDNNPs）的一个基本组成部分。我们将首先从第一性原理推导出该函数的形式，然后详细说明其计算算法。\n\n原子系统的势能 $E$ 是一个标量。为了使其具有物理意义，它必须在整个系统的平移和旋转以及相同原子的置换下保持不变。在 HDNNP 方案中，总能量被分解为原子贡献 $E_i$，其中 $E = \\sum_i E_i$。每个原子能量 $E_i$ 是原子 $i$ 局部环境的函数，由一组描述符或“对称函数” $\\{G_i\\}$ 来表征。因此，这些对称函数本身必须对上述变换保持不变。\n\n1.  **平移和旋转不变性**：这些对称性要求原子 $i$ 的描述符必须仅依赖于其局部环境的内部坐标，而不是全局坐标系中原子的绝对笛卡尔坐标。最简单的内部坐标集由中心原子 $i$ 与其邻近原子 $j$ 之间的标量距离 $r_{ij}$ 组成。这些距离的任何函数 $G_i = F(\\{r_{ij}\\}_{j \\neq i})$ 都自动对原子组合的刚性平移和旋转保持不变。\n\n2.  **置换不变性**：原子 $i$ 的能量贡献不得依赖于其相同邻近原子的任意标记。如果原子 $j$ 和 $k$ 是同一物种，交换它们不能改变描述符的值。满足此条件的最简单数学构造是 对所有邻近原子的求和。因此，我们提出一种形式为 $G_i = \\sum_{j \\neq i} g(r_{ij})$ 的描述符，其中 $g$ 是原子间距离的某个函数。这种形式是双体对称函数的基础。\n\n3.  **局域性与平滑性**：物理相互作用本质上是局域的；非常遥远的原子的影响可以忽略不计。为了对此进行建模，我们引入一个平滑的截断函数 $f_c(r_{ij}; R_c)$，它乘以每个邻近原子的贡献。该函数对于小距离必须等于 $1$，并随着距离 $r_{ij}$ 接近截断半径 $R_c$ 而平滑地趋于 $0$。对于距离 $r_{ij} > R_c$，贡献恰好为零。对平滑性的要求，特别是 $C^1$ 连续性（一阶导数连续），至关重要。原子上的力计算为势能的负梯度，$\\mathbf{F}_k = -\\nabla_{\\mathbf{r}_k} E$。能量一阶导数的不连续性会导致不合物理的、无穷大的力。所提供的余弦截断函数为：\n    $$\n    f_c(r; R_c) = \n    \\begin{cases}\n    \\frac{1}{2}\\left[\\cos\\left(\\frac{\\pi r}{R_c}\\right) + 1\\right],  r \\le R_c,\\\\\n    0,  r > R_c.\n    \\end{cases}\n    $$\n    在截断半径 $r = R_c$ 处，函数值为 $f_c(R_c; R_c) = \\frac{1}{2}[\\cos(\\pi) + 1] = \\frac{1}{2}[-1 + 1] = 0$，确保了连续性。其导数为 $f'_c(r; R_c) = -\\frac{\\pi}{2R_c}\\sin(\\frac{\\pi r}{R_c})$。在 $r = R_c$ 处，导数为 $f'_c(R_c; R_c) = -\\frac{\\pi}{2R_c}\\sin(\\pi) = 0$，这与 $r > R_c$ 时零函数的导数相匹配。因此，该函数按要求是 $C^1$ 连续的。\n\n4.  **径向解析度**：一个简单的截断函数求和只能提供截断球内邻近原子的加权计数。为了创建一个能够区分不同径向结构的描述符，我们引入了一个径向基函数。指定的类高斯形式 $\\exp[-\\eta(r_{ij} - R_s)^2]$ 即为此目的服务。该函数以距离 $R_s$ 为中心，其特征宽度由参数 $\\eta$ 控制。更大的 $\\eta$ 对应于一个更窄、更尖锐的高斯峰。通过使用一组具有不同参数 $(\\eta, R_s)$ 的此类函数，可以解析中心原子 $i$ 周围邻近原子的径向分布。\n\n结合这四个原理——使用距离带来的不变性、求和带来的置换对称性、平滑截断带来的局域性以及径向基带来的解析度——我们得到了指定的双体径向对称函数，记为 $G_i^2$：\n$$\nG_i^{2}(\\eta, R_s, R_c) = \\sum_{j \\ne i} \\exp\\!\\left[-\\eta\\,(r_{ij} - R_s)^2\\right]\\, f_c(r_{ij}; R_c)\n$$\n求和遍及系统中的所有原子 $j$，不包括中心原子 $i$。对于每个邻近原子 $j$，我们仅当其与原子 $i$ 的距离 $r_{ij}$ 小于或等于截断半径 $R_c$ 时才计算其贡献。\n\n计算过程如下：\n给定 $N$ 个原子的笛卡尔坐标集 $\\{\\mathbf{r}_k\\}_{k=0,..,N-1}$、一个中心原子索引 $i$ 以及参数 $\\eta$、$R_s$ 和 $R_c$：\n1.  将对称函数值 $G_i^2$ 初始化为 $0$。\n2.  确定中心原子的坐标向量 $\\mathbf{r}_i$。\n3.  遍历所有其他原子 $j$，其中 $j \\in \\{0, 1, ..., N-1\\}$ 且 $j \\neq i$。\n4.  对于每个邻近原子 $j$，计算欧几里得距离 $r_{ij} = ||\\mathbf{r}_j - \\mathbf{r}_i|| = \\sqrt{(x_j-x_i)^2 + (y_j-y_i)^2 + (z_j-z_i)^2}$。\n5.  检查是否 $r_{ij} \\le R_c$。如果不是，则原子 $j$ 的贡献为 $0$，我们继续处理下一个邻近原子。\n6.  如果 $r_{ij} \\le R_c$，计算该项的两个分量：\n    -   径向基项：$T_{\\text{rad}} = \\exp[-\\eta(r_{ij} - R_s)^2]$。\n    -   截断函数项：$T_{\\text{cut}} = \\frac{1}{2}[\\cos(\\frac{\\pi r_{ij}}{R_c}) + 1]$。\n7.  将这些项的乘积 $T_{\\text{rad}} \\times T_{\\text{cut}}$ 加到 $G_i^2$ 的运行总和中。\n8.  遍历所有邻近原子 $j$ 后，最终的总和即为原子 $i$ 的对称函数值。\n\n现在将实施此过程，并将其应用于五个指定的测试案例。所有单位必须一致；距离（$r_{ij}$、$R_s$、$R_c$）以埃（$\\text{Å}$）为单位，参数 $\\eta$ 以 $\\text{Å}^{-2}$ 为单位，以确保指数的参数是无量纲的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem by computing the Behler-Parrinello G2 symmetry function\n    for a series of test cases.\n    \"\"\"\n\n    def compute_g2(positions, i, R_c, eta, R_s):\n        \"\"\"\n        Computes the G2 symmetry function for a central atom i.\n        \n        Args:\n            positions (np.ndarray): Array of shape (N, 3) with Cartesian coordinates.\n            i (int): Index of the central atom.\n            R_c (float): Cutoff radius in Angstrom.\n            eta (float): Width parameter in Angstrom^-2.\n            R_s (float): Shift parameter in Angstrom.\n        \n        Returns:\n            float: The computed value of the G2 symmetry function.\n        \"\"\"\n        if positions.shape[0] == 1:\n            return 0.0\n\n        central_atom_pos = positions[i]\n        g2_value = 0.0\n\n        for j in range(positions.shape[0]):\n            if i == j:\n                continue\n\n            neighbor_pos = positions[j]\n            # Calculate Euclidean distance\n            r_ij = np.linalg.norm(central_atom_pos - neighbor_pos)\n\n            # Apply the cutoff condition\n            if r_ij = R_c:\n                # Cosine cutoff function\n                fc = 0.5 * (np.cos(np.pi * r_ij / R_c) + 1.0)\n                \n                # Gaussian-like radial basis function\n                radial_term = np.exp(-eta * (r_ij - R_s)**2)\n                \n                # Add contribution to the sum\n                g2_value += radial_term * fc\n        \n        return g2_value\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {'positions': np.array([[0.0, 0.0, 0.0], [2.0, 0.0, 0.0], [0.0, 3.0, 0.0], [0.0, 0.0, 4.0]]),\n         'i': 0, 'R_c': 5.0, 'eta': 0.5, 'R_s': 0.0},\n        # Case B\n        {'positions': np.array([[0.0, 0.0, 0.0]]),\n         'i': 0, 'R_c': 3.0, 'eta': 1.0, 'R_s': 0.0},\n        # Case C\n        {'positions': np.array([[0.0, 0.0, 0.0], [5.0, 0.0, 0.0], [-5.0, 0.0, 0.0]]),\n         'i': 0, 'R_c': 5.0, 'eta': 1.0, 'R_s': 0.0},\n        # Case D\n        {'positions': np.array([[0.0, 0.0, 0.0], [2.0, 0.0, 0.0], [0.0, 3.0, 0.0], [0.0, 0.0, 4.0]]),\n         'i': 0, 'R_c': 5.0, 'eta': 2.0, 'R_s': 2.5},\n        # Case E\n        {'positions': np.array([[0.0, 0.0, 0.0], [2.0, 0.0, 0.0], [0.0, 3.0, 0.0], [0.0, 0.0, 4.0]]),\n         'i': 1, 'R_c': 5.0, 'eta': 0.5, 'R_s': 0.0},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_g2(\n            positions=case['positions'],\n            i=case['i'],\n            R_c=case['R_c'],\n            eta=case['eta'],\n            R_s=case['R_s']\n        )\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # The format string \"{:.6f}\" handles rounding to 6 decimal places.\n    print(f\"[{','.join([f'{r:.6f}' for r in results])}]\")\n\nsolve()\n```", "id": "2457438"}, {"introduction": "在拥有了描述原子环境的描述符之后，下一步就是训练神经网络，使其能够将这些描述符映射到准确的能量上。这个练习 [@problem_id:2456326] 探讨了一个在构建机器学习势函数时至关重要的实际问题：训练数据的质量。你将通过一个“毒化”数据集的案例，亲手验证并量化少数几个错误的训练数据点（模拟第一性原理计算中可能出现的异常值）如何不成比例地破坏整个势能面，进而影响对平衡键长和力等关键物理量的预测。", "problem": "给定一个双原子分子的一维基准模型，其真实势能面（PES）由莫尔斯势定义。设真实能量作为键长函数的表达式为\n$$\nE_{\\text{true}}(r) = D_e \\left(1 - e^{-a (r - r_e)}\\right)^2 - D_e,\n$$\n其中参数 $D_e = 4.744$ 电子伏特 (eV)，$r_e = 0.7414$ 埃 ($\\text{\\AA}$)，以及 $a = 1.942$ $\\text{\\AA}^{-1}$。所有距离必须以埃（$\\text{\\AA}$）表示，所有能量必须以电子伏特（eV）表示。\n\n考虑一个高维神经网络势（NNP）模型，该模型将一个对称函数向量映射到一个预测能量。定义长度为 $M = 8$ 的以原子为中心的径向描述符向量 $\\mathbf{G}(r) \\in \\mathbb{R}^M$ 为 $G_i(r) = f_c(r)\\,\\exp\\!\\left(-\\eta \\left(r - R_{s,i}\\right)^2\\right)$, 其中平滑截断函数 $f_c(r)$ 为\n$$\nf_c(r) =\n\\begin{cases}\n\\frac{1}{2}\\left[\\cos\\!\\left(\\pi \\frac{r}{R_c}\\right) + 1\\right],  r \\le R_c,\\\\\n0,  r > R_c,\n\\end{cases}\n$$\n其中 $R_c = 3.0$ $\\text{\\AA}$，$\\eta = 4.0$ $\\text{\\AA}^{-2}$，且中心点 $R_{s,i}$ 由列表 $R_{s} = \\{0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7\\}$（单位为 $\\text{\\AA}$）给出（即，$R_{s,1} = 0.6$, $R_{s,2} = 0.9$, $R_{s,3} = 1.2$, $R_{s,4} = 1.5$, $R_{s,5} = 1.8$, $R_{s,6} = 2.1$, $R_{s,7} = 2.4$, $R_{s,8} = 2.7$）。\n\n定义神经网络势为 $E_{\\boldsymbol{\\theta}}(r) = \\mathbf{w}_2^\\top \\,\\phi\\!\\left(\\mathbf{W}_1\\,\\mathbf{G}(r) + \\mathbf{b}_1\\right) + b_2,$ 其中 $\\phi(x) = \\tanh(x)$ 按元素应用，$\\mathbf{W}_1 \\in \\mathbb{R}^{H \\times M}$，$\\mathbf{b}_1 \\in \\mathbb{R}^{H}$，$\\mathbf{w}_2 \\in \\mathbb{R}^{H}$，$b_2 \\in \\mathbb{R}$，且隐藏层大小为 $H = 10$。模型参数 $\\boldsymbol{\\theta} = \\{\\mathbf{W}_1, \\mathbf{b}_1, \\mathbf{w}_2, b_2\\}$ 通过最小化均方误差目标函数来获得 $\\mathcal{L}(\\boldsymbol{\\theta}) = \\frac{1}{N}\\sum_{n=1}^{N}\\left(E_{\\boldsymbol{\\theta}}(r_n) - E_{\\text{true}}(r_n)\\right)^2,$ 给定训练数据对 $\\{(r_n, E_{\\text{true}}(r_n))\\}_{n=1}^{N}$。使用 $N_{\\text{train}} = 64$ 个训练距离 $r_n$，这些距离在闭区间 $[0.5, 2.8]$ $\\text{\\AA}$ 上均匀分布。\n\n参数估计必须通过批量梯度下降法进行，并遵循以下确切规范：学习率 $\\alpha = 10^{-2}$，迭代次数 $T = 3000$，使用固定伪随机种子 $42$ 进行权重初始化，其中 $\\mathbf{W}_1$ 和 $\\mathbf{w}_2$ 的条目分别从均值为零、标准差为 $\\sigma_{W_1} = 1/\\sqrt{M}$ 和 $\\sigma_{w_2} = 1/\\sqrt{H}$ 的独立正态分布中抽取，而 $\\mathbf{b}_1$ 和 $b_2$ 进行零初始化。不允许存在其他随机性。\n\n通过在干净数据集 $\\{(r_n, E_{\\text{true}}(r_n))\\}_{n=1}^{N}$ 上训练，构建一个基线模型。然后，通过将特定训练距离处的能量值替换为旨在模拟高度错误的密度泛函理论（DFT）标记的错误值，构建四个投毒数据集。对于给定的目标距离 $r^\\star$ 和偏移量 $\\Delta$，找到使 $|r_k - r^\\star|$ 最小化的训练索引 $k$，并将其对应的能量标记设置为 $E_{\\text{true}}(r_k) + \\Delta$；如果多个目标映射到同一个 $k$，则通过加法累积偏移量。四种投毒情景如下：\n- 情景 $1$（边界情况）：无投毒（目标集为空）。\n- 情景 $2$：在 $r^\\star = 0.7414$ $\\text{\\AA}$ 处有一个投毒点，偏移量为 $\\Delta = +8.0$ eV。\n- 情景 $3$：在 $r^\\star = 2.2$ $\\text{\\AA}$ 和 $r^\\star = 2.4$ $\\text{\\AA}$ 处有两个投毒点，每个点的偏移量均为 $\\Delta = -4.0$ eV。\n- 情景 $4$（边缘情况）：在 $r^\\star = 0.6$ $\\text{\\AA}$ 处有一个投毒点，偏移量为 $\\Delta = -10.0$ eV。\n\n对于每种投毒情景，使用与基线模型相同的优化设置和初始化种子，从头重新训练一个新模型。为进行评估，在闭区间 $[0.5, 3.0]$ $\\text{\\AA}$ 上定义一个包含 $N_{\\text{eval}} = 201$ 个距离的均匀网格，并计算以下三个定量指标，这些指标捕捉了投毒模型的预测PES与基线模型的预测PES之间的差异：\n1. 均方根能量偏差 $m_1 = \\sqrt{\\frac{1}{N_{\\text{eval}}}\\sum_{j=1}^{N_{\\text{eval}}}\\left(E_{\\boldsymbol{\\theta}^{\\text{poison}}}(r_j) - E_{\\boldsymbol{\\theta}^{\\text{base}}}(r_j)\\right)^2}\\ \\text{（单位：eV）}$。\n2. 在评估网格上预测的平衡键长（最小能量位置）的绝对位移，$m_2 = \\left|\\operatorname*{argmin}_{j}\\,E_{\\boldsymbol{\\theta}^{\\text{poison}}}(r_j) - \\operatorname*{argmin}_{j}\\,E_{\\boldsymbol{\\theta}^{\\text{base}}}(r_j)\\right|\\ \\text{（单位：}\\text{\\AA}\\text{）},$ 其中 $\\operatorname*{argmin}_{j}$ 返回出现离散最小值的网格值 $r_j$。\n3. 在网格上预测的力的最大绝对偏差，$m_3 = \\max_{j}\\,\\left|F_{\\boldsymbol{\\theta}^{\\text{poison}}}(r_j) - F_{\\boldsymbol{\\theta}^{\\text{base}}}(r_j)\\right|\\ \\text{（单位：eV}/\\text{\\AA}\\text{）},$ 其中力定义为 $F_{\\boldsymbol{\\theta}}(r) = -\\frac{d}{dr}E_{\\boldsymbol{\\theta}}(r)$，并且导数必须使用均匀网格所隐含的网格间距，通过有限差分法在评估网格上进行近似计算。\n\n角度未在此一维问题中出现。所有输出都必须以上述指定单位报告。您的程序必须按所列顺序为四种情景中的每一种计算 $(m_1, m_2, m_3)$。将每个标量值四舍五入到恰好六位小数。\n\n您的程序应生成单行输出，其中包含形如\n$$\n\\big[\\,[m_{1,1}, m_{2,1}, m_{3,1}],\\ [m_{1,2}, m_{2,2}, m_{3,2}],\\ [m_{1,3}, m_{2,3}, m_{3,3}],\\ [m_{1,4}, m_{2,4}, m_{3,4}]\\,\\big],\n$$\n的列表之列表的结果，其中每个数值条目都四舍五入到六位小数，对应于情景1到4。", "solution": "对问题陈述进行验证。\n\n**第一步：提取的已知条件**\n\n- **真实势能面（PES）：** 莫尔斯势，$E_{\\text{true}}(r) = D_e \\left(1 - e^{-a (r - r_e)}\\right)^2 - D_e$。\n  - 参数：$D_e = 4.744$ eV, $r_e = 0.7414$ Å, $a = 1.942$ Å⁻¹。\n- **对称函数描述符：** 对于键长为 $r$ 的双原子系统，描述符向量为 $\\mathbf{G}(r) \\in \\mathbb{R}^M$，其中 $M=8$。\n  - 分量：$G_i(r) = f_c(r)\\,\\exp\\!\\left(-\\eta \\left(r - R_{s,i}\\right)^2\\right)$。\n  - 截断函数：当 $r \\le R_c$ 时，$f_c(r) = \\frac{1}{2}\\left[\\cos\\!\\left(\\pi \\frac{r}{R_c}\\right) + 1\\right]$，否则为 $0$。\n  - 参数：$R_c = 3.0$ Å, $\\eta = 4.0$ Å⁻², 中心点 $R_{s} = \\{0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7\\}$ Å。\n- **神经网络势（NNP）模型：** 单隐藏层感知机。\n  - 架构：$E_{\\boldsymbol{\\theta}}(r) = \\mathbf{w}_2^\\top \\,\\phi\\!\\left(\\mathbf{W}_1\\,\\mathbf{G}(r) + \\mathbf{b}_1\\right) + b_2$。\n  - 隐藏层大小：$H = 10$。\n  - 激活函数：$\\phi(x) = \\tanh(x)$。\n  - 参数：$\\boldsymbol{\\theta} = \\{\\mathbf{W}_1, \\mathbf{b}_1, \\mathbf{w}_2, b_2\\}$。\n- **训练过程：**\n  - 目标：最小化均方误差，$\\mathcal{L}(\\boldsymbol{\\theta}) = \\frac{1}{N}\\sum_{n=1}^{N}\\left(E_{\\boldsymbol{\\theta}}(r_n) - E_{\\text{true}}(r_n)\\right)^2$。\n  - 数据集：$N_{\\text{train}} = 64$ 个点，距离 $r_n$ 在 $[0.5, 2.8]$ Å 区间内均匀分布。\n  - 优化器：批量梯度下降。\n  - 超参数：学习率 $\\alpha = 10^{-2}$，迭代次数 $T = 3000$。\n  - 初始化：固定的伪随机种子 $42$。权重 $\\mathbf{W}_1$ 和 $\\mathbf{w}_2$ 从均值为零、标准差分别为 $\\sigma_{W_1} = 1/\\sqrt{M}$ 和 $\\sigma_{w_2} = 1/\\sqrt{H}$ 的正态分布中抽样。偏置 $\\mathbf{b}_1, b_2$ 初始化为零。\n- **数据投毒情景：** 在索引为 $k$（使 $|r_k - r^\\star|$ 最小化）的位置，将训练能量标记 $E_{\\text{true}}(r_k)$ 修改为 $E_{\\text{true}}(r_k) + \\Delta$。\n  - 情景 $1$：无投毒。\n  - 情景 $2$：$r^\\star = 0.7414$ Å，$\\Delta = +8.0$ eV。\n  - 情景 $3$：$r^\\star = 2.2$ Å，$\\Delta = -4.0$ eV 以及 $r^\\star = 2.4$ Å，$\\Delta = -4.0$ eV。\n  - 情景 $4$：$r^\\star = 0.6$ Å，$\\Delta = -10.0$ eV。\n- **评估指标：** 在 $[0.5, 3.0]$ Å 区间内包含 $N_{\\text{eval}} = 201$ 个距离的网格上，将每个投毒模型与基线模型（在未投毒数据上训练）进行比较。\n  1. $m_1$：均方根能量偏差（eV）。\n  2. $m_2$：平衡键长的绝对位移（Å）。\n  3. $m_3$：预测力的最大绝对偏差（eV/Å），其中力 $F = -dE/dr$ 通过有限差分法近似。\n\n**第二步：已知条件的验证**\n\n对问题进行有效性审查。\n- **科学上合理：** 是。该问题描述了一个计算化学中用于测试神经网络势的简化但标准的基准测试。莫尔斯势是双原子相互作用的经典模型，而Behler-Parrinello类型的NNP架构代表了该领域的基础方法。所有参数和单位在物理上都是一致的。\n- **问题明确：** 是。该任务是一个定义明确的监督回归问题，具有确定性的训练过程（从固定初始化开始的批量梯度下降）。这保证了唯一、可计算解的存在。\n- **目标客观：** 是。该问题使用精确的数学定义和定量指标进行陈述，没有任何主观或模棱两可的语言。\n\n该问题不违反任何无效标准。它是一个完整、一致且具有科学意义的计算任务。\n\n**第三步：结论与行动**\n\n问题有效。将提供解答。\n\n**基于原理的解答**\n\n目标是通过训练多个模型并将其预测结果与基线进行比较，来量化错误训练数据点对神经网络势（NNP）的影响。解决方案的核心涉及实现一个完整的机器学习工作流程：数据生成、特征化、模型训练和评估。\n\n首先，我们使用莫尔斯势定义真实势能面（PES）：\n$$\nE_{\\text{true}}(r) = D_e \\left(1 - e^{-a (r - r_e)}\\right)^2 - D_e\n$$\n该函数为我们的训练数据集提供目标能量标记，该数据集包含 $N_{\\text{train}} = 64$ 个在区间 $[0.5, 2.8]$ Å 内均匀采样的距离 $r_n$。\n\n接下来，我们定义从键长 $r$ 到特征向量 $\\mathbf{G}(r) \\in \\mathbb{R}^M$ 的转换，该向量作为NNP的输入。这是通过一组 $M=8$ 个以原子为中心的径向对称函数完成的：\n$$\nG_i(r) = f_c(r)\\,\\exp\\!\\left(-\\eta \\left(r - R_{s,i}\\right)^2\\right)\n$$\n其中，基于余弦的截断函数 $f_c(r)$ 确保描述符在截断半径 $R_c = 3.0$ Å 处平滑地趋于零。这种特征化将原始几何信息转换为适合机器学习模型的格式，并且对相同原子的排列具有不变性（这在双原子情况下是一个微不足道的性质，但对于通用的NNP来说是一个关键的设计原则）。\n\nNNP本身是一个标准的前馈神经网络，有一个大小为 $H=10$ 的隐藏层和双曲正切激活函数 $\\phi(x) = \\tanh(x)$。对于输入描述符向量 $\\mathbf{G}(r)$，预测的能量由下式给出：\n$$\nE_{\\boldsymbol{\\theta}}(r) = \\mathbf{w}_2^\\top \\,\\phi\\!\\left(\\mathbf{W}_1\\,\\mathbf{G}(r) + \\mathbf{b}_1\\right) + b_2\n$$\n参数 $\\boldsymbol{\\theta} = \\{\\mathbf{W}_1, \\mathbf{b}_1, \\mathbf{w}_2, b_2\\}$ 通过最小化整个数据集上预测能量与训练标记之间的均方误差（MSE）损失函数来进行优化：\n$$\n\\mathcal{L}(\\boldsymbol{\\theta}) = \\frac{1}{N_{\\text{train}}}\\sum_{n=1}^{N_{\\text{train}}}\\left(E_{\\boldsymbol{\\theta}}(r_n) - E_{\\text{label}}(r_n)\\right)^2\n$$\n优化使用批量梯度下降法进行，迭代次数为 $T=3000$，学习率为 $\\alpha=10^{-2}$。损失函数关于参数的梯度通过反向传播算法导出。对于参数 $P \\in \\boldsymbol{\\theta}$，更新规则为：\n$$\nP \\leftarrow P - \\alpha \\frac{\\partial \\mathcal{L}}{\\partial P}\n$$\n梯度（例如 $\\frac{\\partial \\mathcal{L}}{\\partial \\mathbf{W}_1}$）是通过从输出层到输入层反向应用链式法则来计算的。例如，第一层权重 $\\mathbf{W}_1$ 的梯度是输入描述符 $\\mathbf{G}$、输出端的误差以及激活函数导数的函数。固定的随机种子确保了每次训练运行的初始参数值都是相同的，从而隔离了数据投毒的影响。\n\n我们首先通过在干净数据集（其中 $E_{\\text{label}}(r_n) = E_{\\text{true}}(r_n)$）上训练一个模型 $\\boldsymbol{\\theta}^{\\text{base}}$ 来建立基线。然后，对于三种投毒情景中的每一种，我们通过更改特定点上的能量标记来创建一个新的训练数据集。对于每个“投毒”数据集，我们都从相同的初始状态训练一个新模型 $\\boldsymbol{\\theta}^{\\text{poison}}$。\n\n最后，我们评估投毒的影响。我们在 $[0.5, 3.0]$ Å 区间内生成一个包含 $N_{\\text{eval}} = 201$ 个距离的精细评估网格。对于每个投毒模型，我们计算相对于基线模型在该网格上预测的三个指标：\n1. 能量的均方根偏差 $m_1$，衡量预测PES的平均全局变化。\n2. 预测平衡键长的位移 $m_2$，探究对分子关键物理性质的影响。这是通过为每个模型找出使预测能量最小化的网格点 $r_j$ 来确定的。\n3. 力的最大绝对偏差 $m_3$，评估对能量导数的影响，这对于分子动力学等应用至关重要。力 $F(r) = -dE/dr$ 在评估网格上使用中心有限差分进行数值近似。\n\n第一种情景（无投毒）作为对照组。“投毒”模型与基线模型完全相同，因此所有三个偏差指标 $(m_1, m_2, m_3)$ 显然都为零。对于其他情景，这些指标为NNP对训练数据中局部错误的敏感性提供了定量的见解。", "answer": "```python\nimport numpy as np\n\n# Global constants defined in the problem statement\nDE = 4.744\nRE = 0.7414\nA = 1.942\nRC = 3.0\nETA = 4.0\nRS = np.array([0.6, 0.9, 1.2, 1.5, 1.8, 2.1, 2.4, 2.7])\nM = 8\nH = 10\nN_TRAIN = 64\nN_EVAL = 201\nR_TRAIN_MIN, R_TRAIN_MAX = 0.5, 2.8\nR_EVAL_MIN, R_EVAL_MAX = 0.5, 3.0\nLR = 1e-2\nT = 3000\nSEED = 42\n\ndef morse_potential(r):\n    \"\"\"Calculates the Morse potential energy.\"\"\"\n    return DE * (1 - np.exp(-A * (r - RE)))**2 - DE\n\ndef cutoff_function(r):\n    \"\"\"Calculates the smooth cutoff function value.\"\"\"\n    return np.where(r = RC, 0.5 * (np.cos(np.pi * r / RC) + 1), 0)\n\ndef compute_G_matrix(r_vec):\n    \"\"\"Computes the matrix of symmetry function vectors for a vector of distances.\"\"\"\n    r_vec = r_vec.reshape(-1, 1)\n    fc_r = cutoff_function(r_vec)\n    G = fc_r * np.exp(-ETA * (r_vec - RS)**2)\n    return G\n\ndef initialize_parameters(rng):\n    \"\"\"Initializes NNP parameters according to the specification.\"\"\"\n    # Using HxM for W1 to match problem's math notation\n    W1 = rng.normal(0, 1 / np.sqrt(M), size=(H, M))\n    b1 = np.zeros((H, 1))\n    w2 = rng.normal(0, 1 / np.sqrt(H), size=(H, 1))\n    b2 = 0.0\n    return {\"W1\": W1, \"b1\": b1, \"w2\": w2, \"b2\": b2}\n\ndef forward_pass(G, params):\n    \"\"\"Performs a forward pass through the NNP.\"\"\"\n    # G is (N, M), W1 is (H, M) - W1 @ G.T is (H, N)\n    Z1 = params[\"W1\"] @ G.T + params[\"b1\"]  # Shape (H, N)\n    A1 = np.tanh(Z1)  # Shape (H, N)\n    # A1.T is (N, H), w2 is (H, 1) - A1.T @ w2 is (N, 1)\n    E_pred = A1.T @ params[\"w2\"] + params[\"b2\"]  # Shape (N, 1)\n    \n    # an_z1 contains intermediate values needed for backpropagation\n    cache = {\"Z1\": Z1, \"A1\": A1}\n    return E_pred, cache\n\ndef train_model(r_train, E_train):\n    \"\"\"Trains an NNP model using batch gradient descent.\"\"\"\n    rng = np.random.default_rng(SEED)\n    params = initialize_parameters(rng)\n    \n    N = len(r_train)\n    G_train = compute_G_matrix(r_train)\n    E_train_col = E_train.reshape(-1, 1)\n\n    for _ in range(T):\n        # Forward pass\n        E_pred, cache = forward_pass(G_train, params)\n        \n        # Backward pass (Gradient Calculation)\n        d_E_pred = (2 / N) * (E_pred - E_train_col)  # Shape (N, 1)\n        \n        # Gradients for output layer\n        d_b2 = np.sum(d_E_pred)\n        d_w2 = cache[\"A1\"] @ d_E_pred  # A1 is (H,N), d_E_pred is (N,1) - (H,1)\n        \n        # Backpropagate to hidden layer\n        d_A1_T = d_E_pred @ params[\"w2\"].T # (N,1) @ (1,H) - (N,H)\n        d_Z1_T = d_A1_T * (1 - cache[\"A1\"].T**2) # (N,H) * (N,H) - (N,H)\n        \n        # Gradients for input layer\n        d_b1 = np.sum(d_Z1_T, axis=0, keepdims=True).T # (H,1)\n        d_W1 = d_Z1_T.T @ G_train # (H,N) @ (N,M) - (H,M)\n        \n        # Update parameters\n        params[\"W1\"] -= LR * d_W1\n        params[\"b1\"] -= LR * d_b1\n        params[\"w2\"] -= LR * d_w2\n        params[\"b2\"] -= LR * d_b2\n        \n    return params\n\ndef poison_dataset(E_base, r_train, targets):\n    \"\"\"Modifies the energy labels based on poisoning targets.\"\"\"\n    E_poisoned = np.copy(E_base)\n    # Accumulate offsets for targets that map to the same point\n    modifications = {}\n    for r_star, delta in targets:\n        k = np.argmin(np.abs(r_train - r_star))\n        modifications[k] = modifications.get(k, 0) + delta\n    \n    for k, total_delta in modifications.items():\n        E_poisoned[k] += total_delta\n        \n    return E_poisoned\n    \ndef solve():\n    # 1. Setup grids and true data\n    r_train = np.linspace(R_TRAIN_MIN, R_TRAIN_MAX, N_TRAIN)\n    r_eval = np.linspace(R_EVAL_MIN, R_EVAL_MAX, N_EVAL)\n    dr_eval = (R_EVAL_MAX - R_EVAL_MIN) / (N_EVAL - 1)\n    E_true_train = morse_potential(r_train)\n    \n    # 2. Define poisoning scenarios\n    scenarios = [\n        {\"targets\": []},\n        {\"targets\": [(0.7414, 8.0)]},\n        {\"targets\": [(2.2, -4.0), (2.4, -4.0)]},\n        {\"targets\": [(0.6, -10.0)]},\n    ]\n\n    # 3. Train baseline model\n    params_base = train_model(r_train, E_true_train)\n    G_eval = compute_G_matrix(r_eval)\n    E_pred_base, _ = forward_pass(G_eval, params_base)\n    \n    # Pre-calculate baseline properties for evaluation\n    idx_min_base = np.argmin(E_pred_base)\n    r_min_base = r_eval[idx_min_base]\n    F_base = -np.gradient(E_pred_base.flatten(), dr_eval)\n\n    all_results = []\n\n    # 4. Handle all scenarios\n    for i, scen in enumerate(scenarios):\n        if i == 0:\n            # Scenario 1 is the baseline vs itself, so deviations are zero.\n            results = [0.0, 0.0, 0.0]\n        else:\n            # Create poisoned dataset\n            E_train_poisoned = poison_dataset(E_true_train, r_train, scen[\"targets\"])\n            \n            # Train model from scratch on poisoned data\n            params_poison = train_model(r_train, E_train_poisoned)\n            \n            # Evaluate on the fine grid\n            E_pred_poison, _ = forward_pass(G_eval, params_poison)\n            \n            # Compute metrics\n            m1 = np.sqrt(np.mean((E_pred_poison - E_pred_base)**2))\n            \n            idx_min_poison = np.argmin(E_pred_poison)\n            r_min_poison = r_eval[idx_min_poison]\n            m2 = np.abs(r_min_poison - r_min_base)\n\n            F_poison = -np.gradient(E_pred_poison.flatten(), dr_eval)\n            m3 = np.max(np.abs(F_poison - F_base))\n            \n            results = [m1, m2, m3]\n\n        all_results.append([round(x, 6) for x in results])\n\n    # 5. Format and print final output\n    print(str(all_results).replace(\" \", \"\"))\n\nsolve()\n\n```", "id": "2456326"}, {"introduction": "我们为什么要在构建描述符时，不遗余力地确保其满足各种对称性要求？这个练习 [@problem_id:2456269] 通过分子动力学模拟，为这个问题提供了一个深刻而直观的答案。根据诺特定理（Noether's theorem），物理系统的对称性与守恒定律直接对应。你将通过比较一个严格满足对称性的势函数和一个包含微小对称性破缺项的势函数，亲眼见证能量对平移和旋转不变性是如何直接导致线性动量和角动量守恒的，从而理解对称性在确保物理模拟长期稳定性中的核心作用。", "problem": "给定一个分子动力学（MD）的约化单位模型，其中势能是按照高维神经网络势（NNP）的风格构建的，并对完美的平移和旋转不变性进行了小的受控违背，以模拟一个非完美不变的学习模型。所有量都应在没有物理维度的约化单位中处理。考虑 $N$ 个粒子，其位置为 $\\mathbf{r}_i \\in \\mathbb{R}^3$，速度为 $\\mathbf{v}_i \\in \\mathbb{R}^3$，且所有 $i \\in \\{1,\\dots,N\\}$ 的质量均为 $m_i = 1$。总势能为\n$$\nE(\\{\\mathbf{r}_i\\}_{i=1}^N) = \\sum_{i=1}^N \\left[g\\!\\left(S_i\\right) + \\varepsilon_t\\,\\boldsymbol{c}\\cdot \\mathbf{r}_i + \\varepsilon_r\\,\\mathbf{r}_i^\\mathsf{T}\\mathbf{Q}\\,\\mathbf{r}_i\\right],\n$$\n其中\n$$\nS_i = \\sum_{\\substack{j=1 \\\\ j\\neq i}}^N \\exp\\!\\left(-\\alpha\\left(\\|\\mathbf{r}_i - \\mathbf{r}_j\\| - r_0\\right)\\right), \\quad g(x) = a\\,x + b\\,\\tanh(x),\n$$\n且常数为\n$$\n\\alpha = 1.2,\\quad r_0 = 1.0,\\quad a = 0.5,\\quad b = 0.2,\n$$\n$$\n\\boldsymbol{c} = \\begin{bmatrix}0.3\\\\-0.2\\\\0.1\\end{bmatrix},\\quad\n\\mathbf{Q} = \\begin{bmatrix}0.3  0.1  0.0\\\\ 0.1  -0.2  0.05\\\\ 0.0  0.05  -0.1\\end{bmatrix}.\n$$\n令 $\\mathbf{F}_i = -\\nabla_{\\mathbf{r}_i} E$ 为作用在粒子 $i$ 上的力。运动方程为牛顿方程\n$$\n\\frac{d\\mathbf{r}_i}{dt} = \\mathbf{v}_i,\\qquad \\frac{d\\mathbf{v}_i}{dt} = \\mathbf{F}_i.\n$$\n您必须使用以下时间离散化更新，以时间步长 $\\Delta t$ 和 $K$ 步来演化系统：\n1. 设置加速度 $\\mathbf{a}_i^{(n)} = \\mathbf{F}_i(\\{\\mathbf{r}_k^{(n)}\\}_{k=1}^N)$。\n2. 更新位置\n$$\n\\mathbf{r}_i^{(n+1)} = \\mathbf{r}_i^{(n)} + \\Delta t\\,\\mathbf{v}_i^{(n)} + \\tfrac{1}{2}\\,\\Delta t^2\\,\\mathbf{a}_i^{(n)}.\n$$\n3. 评估新加速度 $\\mathbf{a}_i^{(n+1)} = \\mathbf{F}_i(\\{\\mathbf{r}_k^{(n+1)}\\}_{k=1}^N)$。\n4. 更新速度\n$$\n\\mathbf{v}_i^{(n+1)} = \\mathbf{v}_i^{(n)} + \\tfrac{1}{2}\\,\\Delta t\\,\\left(\\mathbf{a}_i^{(n)} + \\mathbf{a}_i^{(n+1)}\\right).\n$$\n将在步骤 $n$ 的总线动量和绕原点的总角动量定义为\n$$\n\\mathbf{P}^{(n)} = \\sum_{i=1}^N \\mathbf{v}_i^{(n)},\\qquad\n\\mathbf{L}^{(n)} = \\sum_{i=1}^N \\mathbf{r}_i^{(n)} \\times \\mathbf{v}_i^{(n)}.\n$$\n对于下方的每个测试用例，从指定的初始条件开始，以时间步长 $\\Delta t$ 演化系统 $K$ 步，并计算漂移幅度\n$$\np_{\\mathrm{drift}} = \\left\\|\\mathbf{P}^{(K)} - \\mathbf{P}^{(0)}\\right\\|_2,\\qquad\n\\ell_{\\mathrm{drift}} = \\left\\|\\mathbf{L}^{(K)} - \\mathbf{L}^{(0)}\\right\\|_2.\n$$\n所有输出必须以约化单位报告，并四舍五入到 $6$ 位小数。\n\n测试套件（每行指定一个用例 $[N,\\{\\mathbf{r}_i(0)\\}_{i=1}^N,\\{\\mathbf{v}_i(0)\\}_{i=1}^N,\\varepsilon_t,\\varepsilon_r,\\Delta t,K]$）：\n- 用例 A（名义不变性，多粒子）：\n$[\\,3,\\ \\{(-0.8,0.0,0.0),\\ (0.4,0.692820323,0.0),\\ (0.4,-0.692820323,0.0)\\},\\ \\{(0.0,0.0,0.0),\\ (0.0,0.0,0.0),\\ (0.0,0.0,0.0)\\},\\ 0.0,\\ 0.0,\\ 0.002,\\ 5000\\,]$.\n- 用例 B（小的不变性泄漏，多粒子）：\n$[\\,3,\\ \\{(-0.8,0.0,0.0),\\ (0.4,0.692820323,0.0),\\ (0.4,-0.692820323,0.0)\\},\\ \\{(0.0,0.0,0.0),\\ (0.0,0.0,0.0),\\ (0.0,0.0,0.0)\\},\\ 0.001,\\ 0.0005,\\ 0.002,\\ 5000\\,]$.\n- 用例 C（带泄漏的单粒子边界情况）：\n$[\\,1,\\ \\{(0.3,0.4,0.1)\\},\\ \\{(0.0,0.0,0.0)\\},\\ 0.002,\\ 0.001,\\ 0.002,\\ 4000\\,]$.\n\n您的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果\n$[[p_A,\\ell_A],[p_B,\\ell_B],[p_C,\\ell_C]]$，其中 $p_X$ 和 $\\ell_X$ 是对应情况 $X\\in\\{\\mathrm{A},\\mathrm{B},\\mathrm{C}\\}$ 的漂移幅度，每个都以约化单位四舍五入到 $6$ 位小数。不允许有其他输出。", "solution": "该问题要求使用速度Verlet积分算法，对一个由自定义势能函数控制的、在约化单位下的 $N$ 粒子系统进行模拟。任务是为三个不同的测试用例计算在固定数量的时间步长内总线动量和总角动量的漂移。该问题具有科学依据，提法明确，并提供了所有必要的参数和初始条件。它代表了一个有效的计算物理问题。\n\n解决方案如下：\n1.  通过对势能 $E$ 关于粒子位置 $\\mathbf{r}_i$ 取负梯度，推导作用在每个粒子 $i$ 上的力 $\\mathbf{F}_i$ 的解析表达式。\n2.  实现一个数值函数，用于计算任何给定粒子位置配置 $\\{\\mathbf{r}_i\\}$ 下的这些力。\n3.  实现速度Verlet算法，以随时间演化系统的位置 $\\{\\mathbf{r}_i\\}$ 和速度 $\\{\\mathbf{v}_i\\}$。\n4.  为三个指定的测试用例中的每一个执行模拟。\n5.  按照问题陈述中的定义，计算总线动量漂移幅度 $p_{\\mathrm{drift}}$ 和总角动量漂移幅度 $\\ell_{\\mathrm{drift}}$。\n\n首先，我们必须推导作用在任意粒子 $k$ 上的力 $\\mathbf{F}_k = -\\nabla_{\\mathbf{r}_k} E$。势能 $E$ 由以下公式给出：\n$$\nE(\\{\\mathbf{r}_i\\}) = \\sum_{i=1}^N \\left[g\\!\\left(S_i\\right) + \\varepsilon_t\\,\\boldsymbol{c}\\cdot \\mathbf{r}_i + \\varepsilon_r\\,\\mathbf{r}_i^\\mathsf{T}\\mathbf{Q}\\,\\mathbf{r}_i\\right]\n$$\n梯度 $\\nabla_{\\mathbf{r}_k}$ 作用于每一项。带有 $\\varepsilon_t$ 和 $\\varepsilon_r$ 的项仅在 $i=k$ 时有贡献，因为当 $i \\neq k$ 时，它们与 $\\mathbf{r}_i$ 无关。这些“泄漏”项的梯度很简单：\n$$\n\\nabla_{\\mathbf{r}_k} (\\varepsilon_t\\,\\boldsymbol{c}\\cdot \\mathbf{r}_k) = \\varepsilon_t \\boldsymbol{c}\n$$\n$$\n\\nabla_{\\mathbf{r}_k} (\\varepsilon_r\\,\\mathbf{r}_k^\\mathsf{T}\\mathbf{Q}\\,\\mathbf{r}_k) = \\varepsilon_r (\\mathbf{Q} + \\mathbf{Q}^\\mathsf{T})\\mathbf{r}_k = 2\\varepsilon_r \\mathbf{Q}\\,\\mathbf{r}_k\n$$\n其中我们利用了给定矩阵 $\\mathbf{Q}$ 是对称的这一事实。\n\n多体项 $\\sum_{i=1}^N g(S_i)$ 的梯度更为复杂。使用链式法则：\n$$\n\\nabla_{\\mathbf{r}_k} \\sum_{i=1}^N g(S_i) = \\sum_{i=1}^N \\frac{dg}{dS_i} \\nabla_{\\mathbf{r}_k} S_i = \\sum_{i=1}^N g'(S_i) \\nabla_{\\mathbf{r}_k} S_i\n$$\n梯度 $\\nabla_{\\mathbf{r}_k} S_i$ 仅在 $S_i$ 依赖于 $\\mathbf{r}_k$ 时非零。$S_i = \\sum_{j\\neq i} \\exp(-\\alpha(\\|\\mathbf{r}_i - \\mathbf{r}_j\\| - r_0)) = \\sum_{j\\neq i} f_{ij}$。当 $i=k$ 或求和索引 $j$ 中的一个等于 $k$ 时，会出现这种依赖关系。\n\n对于 $i=k$：\n$$\n\\nabla_{\\mathbf{r}_k} S_k = \\nabla_{\\mathbf{r}_k} \\sum_{j\\neq k} f_{kj} = \\sum_{j\\neq k} f_{kj} (-\\alpha) \\nabla_{\\mathbf{r}_k} \\|\\mathbf{r}_k - \\mathbf{r}_j\\| = \\sum_{j\\neq k} \\left(-\\alpha f_{kj} \\frac{\\mathbf{r}_k - \\mathbf{r}_j}{\\|\\mathbf{r}_k - \\mathbf{r}_j\\|}\\right)\n$$\n对于 $i \\neq k$：$S_i$ 的求和中唯一依赖于 $\\mathbf{r}_k$ 的项是 $f_{ik}$。\n$$\n\\nabla_{\\mathbf{r}_k} S_i = \\nabla_{\\mathbf{r}_k} f_{ik} = f_{ik} (-\\alpha) \\nabla_{\\mathbf{r}_k} \\|\\mathbf{r}_i - \\mathbf{r}_k\\| = f_{ik} (-\\alpha) \\frac{\\mathbf{r}_k - \\mathbf{r}_i}{\\|\\mathbf{r}_i - \\mathbf{r}_k\\|} = \\alpha f_{ik} \\frac{\\mathbf{r}_i - \\mathbf{r}_k}{\\|\\mathbf{r}_i - \\mathbf{r}_k\\|}\n$$\n结合这些结果，能量对称部分的梯度为：\n$$\n\\nabla_{\\mathbf{r}_k} \\left(\\sum_i g(S_i)\\right) = g'(S_k) \\nabla_{\\mathbf{r}_k} S_k + \\sum_{i\\neq k} g'(S_i) \\nabla_{\\mathbf{r}_k} S_i\n$$\n代入梯度的表达式，并将第二项中的求和索引 $i$ 重新标记为 $j$ 可得：\n$$\n= g'(S_k) \\sum_{j\\neq k} \\left(-\\alpha f_{kj} \\frac{\\mathbf{r}_k - \\mathbf{r}_j}{r_{kj}}\\right) + \\sum_{j\\neq k} g'(S_j) \\left(\\alpha f_{jk} \\frac{\\mathbf{r}_j - \\mathbf{r}_k}{r_{jk}}\\right)\n$$\n其中 $r_{kj} = \\|\\mathbf{r}_k-\\mathbf{r}_j\\|$。由于 $f_{kj}=f_{jk}$，$r_{kj}=r_{jk}$，且 $\\mathbf{r}_j-\\mathbf{r}_k = -(\\mathbf{r}_k-\\mathbf{r}_j)$，这可以简化为：\n$$\n= -\\alpha \\sum_{j\\neq k} (g'(S_k) + g'(S_j)) f_{kj} \\frac{\\mathbf{r}_k - \\mathbf{r}_j}{r_{kj}}\n$$\n$g(x) = a\\,x + b\\,\\tanh(x)$ 的导数是 $g'(x) = a + b\\,\\mathrm{sech}^2(x) = a+b(1-\\tanh^2(x))$。\n\n作用在粒子 $k$ 上的总力是总梯度的负值：\n$$\n\\mathbf{F}_k = \\alpha \\sum_{j\\neq k} \\left(g'(S_k) + g'(S_j)\\right) f_{kj} \\frac{\\mathbf{r}_k - \\mathbf{r}_j}{r_{kj}} - \\varepsilon_t\\boldsymbol{c} - 2\\varepsilon_r\\mathbf{Q}\\mathbf{r}_k\n$$\n对于单粒子情况（$N=1$），对 $j\\neq k$ 的求和为空，因此 $S_1=0$。力简化为 $\\mathbf{F}_1 = - \\varepsilon_t \\boldsymbol{c} - 2\\varepsilon_r \\mathbf{Q} \\mathbf{r}_1$。\n\n使用速度Verlet算法，以时间步长 $\\Delta t$ 演化动力学 $K$ 步。由于质量 $m_i=1$，加速度为 $\\mathbf{a}_i = \\mathbf{F}_i$。\n1.  初始化 $\\mathbf{r}^{(0)}, \\mathbf{v}^{(0)}$。计算 $\\mathbf{a}^{(0)} = \\mathbf{F}(\\{\\mathbf{r}_k^{(0)}\\})$。\n2.  对于 $n=0, \\dots, K-1$：\n    a.  $\\mathbf{r}_i^{(n+1)} = \\mathbf{r}_i^{(n)} + \\Delta t\\,\\mathbf{v}_i^{(n)} + \\tfrac{1}{2}\\,\\Delta t^2\\,\\mathbf{a}_i^{(n)}$\n    b.  $\\mathbf{a}_i^{(n+1)} = \\mathbf{F}_i(\\{\\mathbf{r}_k^{(n+1)}\\})$\n    c.  $\\mathbf{v}_i^{(n+1)} = \\mathbf{v}_i^{(n)} + \\tfrac{1}{2}\\,\\Delta t\\,\\left(\\mathbf{a}_i^{(n)} + \\mathbf{a}_i^{(n+1)}\\right)$\n计算初始总线动量 $\\mathbf{P}^{(0)} = \\sum_i \\mathbf{v}_i^{(0)}$ 和角动量 $\\mathbf{L}^{(0)} = \\sum_i \\mathbf{r}_i^{(0)} \\times \\mathbf{v}_i^{(0)}$。经过 $K$ 步后，计算最终值 $\\mathbf{P}^{(K)}$ 和 $\\mathbf{L}^{(K)}$，并确定差值的欧几里得范数，$p_{\\mathrm{drift}} = \\|\\mathbf{P}^{(K)} - \\mathbf{P}^{(0)}\\|$ 和 $\\ell_{\\mathrm{drift}} = \\|\\mathbf{L}^{(K)} - \\mathbf{L}^{(0)}\\|$。\n该实现使用 `numpy` 进行高效的矢量化力和状态更新计算。\n\n-   用例 A ($\\varepsilon_t = 0, \\varepsilon_r = 0$)：势能对于平移和旋转是完全不变的。预期线动量和角动量守恒，因此漂移应接近于零，仅受数值精度的限制。\n-   用例 B ($\\varepsilon_t  0, \\varepsilon_r  0$)：不变性被明确破坏。合力 $\\sum_i \\mathbf{F}_i$ 和合力矩 $\\sum_i \\mathbf{r}_i \\times \\mathbf{F}_i$ 非零，导致 $\\mathbf{P}$ 和 $\\mathbf{L}$ 的长期漂移。预期漂移幅度非零。\n-   用例 C ($N=1$)：粒子受到外场作用。由于它从静止开始，它会加速，导致非零的最终动量和角动量，因此产生显著的漂移。\n\n所提供的Python代码实现了此逻辑以解决这三种情况。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print results.\n    \"\"\"\n\n    def calculate_forces(r, N, alpha, r0, a, b, eps_t, eps_r, c_vec, Q_mat):\n        \"\"\"\n        Calculates the forces on all particles.\n        \"\"\"\n        if N == 1:\n            force = -eps_t * c_vec - 2 * eps_r * (Q_mat @ r[0])\n            return force.reshape(1, 3)\n\n        # Vectorized calculation for N  1\n        # Pairwise differences and distances\n        diffs = r[:, np.newaxis, :] - r[np.newaxis, :, :]  # Shape (N, N, 3)\n        dists = np.linalg.norm(diffs, axis=2)  # Shape (N, N)\n        \n        # Avoid division by zero for diagonal elements, which are not used anyway\n        dists_safe = np.copy(dists)\n        np.fill_diagonal(dists_safe, 1.0)\n        unit_vectors = diffs / dists_safe[:, :, np.newaxis]\n\n        # Calculate exponential term f_ij\n        f_exp = np.exp(-alpha * (dists - r0))\n        np.fill_diagonal(f_exp, 0)  # Sum is over j != i\n\n        # Calculate S_i and g'(S_i)\n        S = np.sum(f_exp, axis=1)  # Shape (N,)\n        tanh_S = np.tanh(S)\n        g_prime_S = a + b * (1 - tanh_S**2)  # Shape (N,)\n\n        # Calculate symmetric part of the force\n        g_prime_sum = g_prime_S[:, np.newaxis] + g_prime_S[np.newaxis, :] # Shape (N, N)\n        term_scalar = alpha * g_prime_sum * f_exp  # Shape (N, N)\n        \n        force_sym_contrib = term_scalar[:, :, np.newaxis] * unit_vectors\n        force_sym = np.sum(force_sym_contrib, axis=1)\n\n        # Calculate leak part of the force\n        force_leak = -eps_t * c_vec - 2 * eps_r * (r @ Q_mat)\n\n        forces = force_sym + force_leak\n        return forces\n\n    def run_simulation(N, r_init, v_init, eps_t, eps_r, dt, K):\n        \"\"\"\n        Runs a single MD simulation for a given set of parameters.\n        \"\"\"\n        # Constants\n        alpha = 1.2\n        r0_const = 1.0\n        a = 0.5\n        b = 0.2\n        c_vec = np.array([0.3, -0.2, 0.1])\n        Q_mat = np.array([[0.3, 0.1, 0.0], \n                          [0.1, -0.2, 0.05], \n                          [0.0, 0.05, -0.1]])\n\n        # Initial state\n        r = np.array(r_init, dtype=float)\n        v = np.array(v_init, dtype=float)\n        \n        # Initial momentum and angular momentum (masses m_i = 1)\n        P0 = np.sum(v, axis=0) if N > 0 else np.zeros(3)\n        L0 = np.sum(np.cross(r, v), axis=0) if N > 0 else np.zeros(3)\n\n        # Initial acceleration\n        acc = calculate_forces(r, N, alpha, r0_const, a, b, eps_t, eps_r, c_vec, Q_mat)\n\n        # Main loop (Velocity Verlet)\n        for _ in range(K):\n            # Update positions\n            r += dt * v + 0.5 * dt**2 * acc\n            # Store old acceleration\n            acc_old = acc\n            # Calculate new acceleration\n            acc = calculate_forces(r, N, alpha, r0_const, a, b, eps_t, eps_r, c_vec, Q_mat)\n            # Update velocities\n            v += 0.5 * dt * (acc_old + acc)\n\n        # Final momentum and angular momentum\n        PK = np.sum(v, axis=0) if N > 0 else np.zeros(3)\n        LK = np.sum(np.cross(r, v), axis=0) if N > 0 else np.zeros(3)\n\n        # Calculate drifts\n        p_drift = np.linalg.norm(PK - P0)\n        l_drift = np.linalg.norm(LK - L0)\n\n        return p_drift, l_drift\n\n    # Test cases from the problem statement\n    test_cases = [\n        (3, [(-0.8, 0.0, 0.0), (0.4, 0.692820323, 0.0), (0.4, -0.692820323, 0.0)], \n            [(0.0, 0.0, 0.0), (0.0, 0.0, 0.0), (0.0, 0.0, 0.0)], \n            0.0, 0.0, 0.002, 5000), # Case A\n        (3, [(-0.8, 0.0, 0.0), (0.4, 0.692820323, 0.0), (0.4, -0.692820323, 0.0)], \n            [(0.0, 0.0, 0.0), (0.0, 0.0, 0.0), (0.0, 0.0, 0.0)], \n            0.001, 0.0005, 0.002, 5000), # Case B\n        (1, [(0.3, 0.4, 0.1)], \n            [(0.0, 0.0, 0.0)], \n            0.002, 0.001, 0.002, 4000) # Case C\n    ]\n    \n    results = []\n    for case in test_cases:\n        p_drift, l_drift = run_simulation(*case)\n        results.append((p_drift, l_drift))\n\n    formatted_results = [f\"[{p:.6f},{l:.6f}]\" for p, l in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2456269"}]}