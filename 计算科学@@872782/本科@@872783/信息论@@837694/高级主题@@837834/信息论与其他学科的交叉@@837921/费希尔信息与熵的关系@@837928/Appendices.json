{"hands_on_practices": [{"introduction": "费雪信息衡量了数据中包含的关于未知参数的信息量。本练习以物理学中一个具体的例子——用指数分布建模的粒子衰变——为例，让您亲手计算费雪信息。掌握这项计算是理解我们如何量化估计精度的基础步骤。", "problem": "在粒子物理学中，某一特定类型的不稳定粒子的衰变时间可以被建模为一个随机变量。这种衰变时间的一个常用模型是指数分布。单个衰变时间 $X$ 的概率密度函数 (PDF) 由下式给出\n$$ f(x; \\lambda) = \\lambda \\exp(-\\lambda x) $$\n对于 $x \\ge 0$，其中 $\\lambda > 0$ 是衰变率参数。较大的 $\\lambda$ 意味着粒子平均衰变得更快。\n\n为估计一种新发现粒子的衰变率 $\\lambda$，进行了一项实验。在这个实验中，一位物理学家观测了一组 $n$ 个独立同分布 (i.i.d.) 的衰变时间，记为 $X_1, X_2, \\ldots, X_n$。\n\n费雪信息提供了一种方法，用于衡量一个可观测的随机变量所携带的、关于其模型分布中未知参数的信息量。对于一组 $n$ 个独立同分布的观测值，费雪信息 $I_n(\\lambda)$ 量化了从数据中估计参数 $\\lambda$ 的精度。\n\n计算这组 $n$ 个衰变时间测量值关于衰变率参数 $\\lambda$ 的费雪信息 $I_n(\\lambda)$。请用 $n$ 和 $\\lambda$ 表示你的答案。", "solution": "我们将每个衰变时间 $X_{i}$ 建模为独立同分布，其密度函数为 $f(x;\\lambda)=\\lambda \\exp(-\\lambda x)$（$x\\ge 0$），其中 $\\lambda>0$。对于观测值 $x_{1},\\ldots,x_{n}$，似然函数为\n$$\nL(\\lambda;x_{1:n})=\\prod_{i=1}^{n}\\lambda \\exp(-\\lambda x_{i})=\\lambda^{n}\\exp\\!\\Big(-\\lambda\\sum_{i=1}^{n}x_{i}\\Big).\n$$\n对数似然函数为\n$$\n\\ell(\\lambda)=\\ln L(\\lambda;x_{1:n})=\\sum_{i=1}^{n}\\big(\\ln \\lambda-\\lambda x_{i}\\big)=n\\ln \\lambda-\\lambda\\sum_{i=1}^{n}x_{i}.\n$$\n得分函数（一阶导数）为\n$$\n\\frac{\\partial \\ell(\\lambda)}{\\partial \\lambda}=\\frac{n}{\\lambda}-\\sum_{i=1}^{n}x_{i},\n$$\n二阶导数为\n$$\n\\frac{\\partial^{2} \\ell(\\lambda)}{\\partial \\lambda^{2}}=-\\frac{n}{\\lambda^{2}}.\n$$\n根据在标准正则性条件下独立同分布样本的费雪信息定义，我们有\n$$\nI_{n}(\\lambda)=-\\mathbb{E}\\!\\left[\\frac{\\partial^{2} \\ell(\\lambda)}{\\partial \\lambda^{2}}\\right].\n$$\n由于 $\\partial^{2}\\ell/\\partial \\lambda^{2}=-n/\\lambda^{2}$ 不依赖于数据，其期望值等于其本身，从而得到\n$$\nI_{n}(\\lambda)=-\\Big(-\\frac{n}{\\lambda^{2}}\\Big)=\\frac{n}{\\lambda^{2}}.\n$$\n等价地，单个观测值的费雪信息为 $I_{1}(\\lambda)=\\frac{1}{\\lambda^{2}}$，根据 $n$ 个独立同分布观测值的可加性，我们得到 $I_{n}(\\lambda)=n I_{1}(\\lambda)=\\frac{n}{\\lambda^{2}}$。", "answer": "$$\\boxed{\\frac{n}{\\lambda^{2}}}$$", "id": "1653754"}, {"introduction": "费雪信息衡量可估计性，而熵衡量不确定性。本练习在一个简单的二元系统中探讨了这两个概念之间的关系。通过找到最大不确定性的点并计算那里的费雪信息，您将深入理解一个系统的随机性与其内在属性的可学习性之间的基本权衡。[@problem_id:1653764]", "problem": "考虑一个简单的二进制系统，例如内存位或数字信号，它可以处于两种状态之一：“开”（用 1 表示）或“关”（用 0 表示）。设随机变量 $X$ 描述该系统的状态，遵循参数为 $p$ 的伯努利分布。即，系统处于“开”状态的概率为 $P(X=1) = p$，而处于“关”状态的概率为 $P(X=0) = 1-p$，其中 $p \\in (0, 1)$。\n\n系统状态的不确定性由香农熵来衡量，其函数为 $H(p) = -p \\ln(p) - (1-p) \\ln(1-p)$，其中 $\\ln$ 表示自然对数。\n\n费雪信息用于量化对 $X$ 的一次观测能提供多少关于参数 $p$ 的信息，对于伯努利分布，其定义为 $I(p) = \\frac{1}{p(1-p)}$。\n\n您的任务是分析最大不确定性点。首先，找到使熵 $H(p)$ 最大化的 $p$ 值。其次，计算在该特定 $p$ 值下的费雪信息 $I(p)$。\n\n请提供两个数字作为您的最终答案：使熵最大化的 $p$ 值，以及相应的费雪信息值。请将这两个值表示为精确的分数或整数。", "solution": "我们已知伯努利熵为 $H(p) = -p \\ln(p) - (1-p) \\ln(1-p)$（其中 $p \\in (0,1)$）以及费雪信息为 $I(p) = \\frac{1}{p(1-p)}$。为了找到使 $H(p)$ 最大化的 $p$ 值，我们对 $p$ 求导，并令导数为零。\n\n使用标准求导法则计算一阶导数：\n$$\n\\frac{d}{dp}\\big[-p \\ln p\\big] = -(\\ln p + 1), \\quad \\frac{d}{dp}\\big[-(1-p)\\ln(1-p)\\big] = \\ln(1-p) + 1.\n$$\n因此，\n$$\nH'(p) = -(\\ln p + 1) + (\\ln(1-p) + 1) = \\ln(1-p) - \\ln p = \\ln\\!\\left(\\frac{1-p}{p}\\right).\n$$\n令 $H'(p) = 0$ 以寻找临界点：\n$$\n\\ln\\!\\left(\\frac{1-p}{p}\\right) = 0 \\quad \\Longrightarrow \\quad \\frac{1-p}{p} = 1 \\quad \\Longrightarrow \\quad 1 - p = p \\quad \\Longrightarrow \\quad p = \\frac{1}{2}.\n$$\n为了验证该临界点为最大值点，计算二阶导数：\n$$\nH''(p) = \\frac{d}{dp}\\big[\\ln(1-p) - \\ln p\\big] = -\\frac{1}{1-p} - \\frac{1}{p} = -\\left(\\frac{1}{1-p} + \\frac{1}{p}\\right).\n$$\n对于 $p \\in (0,1)$，括号内的两项均为正，因此 $H''(p) < 0$，这证实了 $p = \\frac{1}{2}$ 是一个熵最大的点。\n\n接下来，计算在该 $p$ 值下的费雪信息：\n$$\nI\\!\\left(\\frac{1}{2}\\right) = \\frac{1}{\\left(\\frac{1}{2}\\right)\\left(1 - \\frac{1}{2}\\right)} = \\frac{1}{\\frac{1}{4}} = 4.\n$$\n因此，使熵最大化的 $p$ 值为 $\\frac{1}{2}$，相应的费雪信息为 $4$。", "answer": "$$\\boxed{\\begin{pmatrix} \\frac{1}{2} & 4 \\end{pmatrix}}$$", "id": "1653764"}, {"introduction": "最后的这个练习将深入探讨无处不在的高斯分布中，费雪信息与微分熵之间更深层、更优雅的联系。您将计算这两个量并将它们结合起来，揭示一个令人惊讶的结果：一个与分布参数无关的普适常数。这个练习展示了支撑信息论的深刻而优美的数学结构。[@problem_id:1653753]", "problem": "对一个物理量的测量由一个服从高斯（正态）分布的随机变量 $X$ 建模。该分布的概率密度函数 (PDF) 由下式给出：\n$$p(x; \\mu, \\sigma^2) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(x-\\mu)^2}{2\\sigma^2}\\right)$$\n其中，$\\mu$ 是分布的均值，代表该物理量的真实值；$\\sigma^2$ 是方差，代表测量的不确定度。方差 $\\sigma^2$ 是一个已知的正常数，而均值 $\\mu$ 是我们希望获得其相关信息的参数。\n\n对于这样的分布，信息论中有两个重要的分析量，分别是费雪信息和微分熵。\n\n费雪信息 $I(\\theta)$ 量化了一个可观测的随机变量 $X$ 所携带的、关于对 $X$ 建模的分布中未知参数 $\\theta$ 的信息量。对于参数 $\\theta$，它被定义为计分函数（score）平方的期望：\n$$I(\\theta) = \\mathbb{E}\\left[\\left(\\frac{\\partial}{\\partial \\theta} \\ln p(x; \\theta)\\right)^2\\right]$$\n其中期望 $\\mathbb{E}[\\cdot]$ 是对分布 $p(x; \\theta)$ 取的。\n\n微分熵 $h(X)$ 是衡量一个连续随机变量平均不确定性的度量。它的定义如下：\n$$h(X) = -\\int_{-\\infty}^{\\infty} p(x) \\ln p(x) \\, dx$$\n这也可以使用期望算子表示为 $h(X) = -\\mathbb{E}[\\ln p(X)]$。\n\n你的任务是计算乘积 $I(\\mu) \\cdot \\exp(2h(X))$ 的值，其中 $I(\\mu)$ 是高斯分布关于其均值 $\\mu$ 的费雪信息，而 $h(X)$ 是其微分熵。最终结果应该是一个用基本数学常数表示的符号表达式。", "solution": "我们从高斯密度函数开始\n$$\np(x;\\mu,\\sigma^{2})=\\frac{1}{\\sqrt{2\\pi\\sigma^{2}}}\\exp\\!\\left(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\right),\n$$\n其中 $\\sigma^{2}$ 已知，$\\mu$ 是我们感兴趣的参数。\n\n关于 $\\mu$ 的费雪信息：\n对数密度函数为\n$$\n\\ln p(x;\\mu,\\sigma^{2})=-\\frac{1}{2}\\ln(2\\pi\\sigma^{2})-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}.\n$$\n关于 $\\mu$ 的计分函数为\n$$\n\\frac{\\partial}{\\partial \\mu}\\ln p(x;\\mu,\\sigma^{2})=\\frac{x-\\mu}{\\sigma^{2}}.\n$$\n因此，使用 $\\mathbb{E}[(X-\\mu)^{2}]=\\sigma^{2}$，\n$$\nI(\\mu)=\\mathbb{E}\\!\\left[\\left(\\frac{\\partial}{\\partial \\mu}\\ln p(X;\\mu,\\sigma^{2})\\right)^{2}\\right]\n=\\mathbb{E}\\!\\left[\\left(\\frac{X-\\mu}{\\sigma^{2}}\\right)^{2}\\right]\n=\\frac{1}{\\sigma^{4}}\\mathbb{E}[(X-\\mu)^{2}]=\\frac{1}{\\sigma^{2}}.\n$$\n\n微分熵：\n根据定义，\n$$\nh(X)=-\\mathbb{E}[\\ln p(X;\\mu,\\sigma^{2})]\n=\\mathbb{E}\\!\\left[\\frac{1}{2}\\ln(2\\pi\\sigma^{2})+\\frac{(X-\\mu)^{2}}{2\\sigma^{2}}\\right]\n=\\frac{1}{2}\\ln(2\\pi\\sigma^{2})+\\frac{1}{2},\n$$\n这里我们使用了 $\\mathbb{E}[(X-\\mu)^{2}]=\\sigma^{2}$。等价地，\n$$\nh(X)=\\frac{1}{2}\\ln\\!\\big(2\\pi\\,\\exp(1)\\,\\sigma^{2}\\big).\n$$\n因此，\n$$\n\\exp\\big(2h(X)\\big)=\\exp\\!\\left(\\ln\\!\\big(2\\pi\\,\\exp(1)\\,\\sigma^{2}\\big)\\right)=2\\pi\\,\\exp(1)\\,\\sigma^{2}.\n$$\n\n乘积：\n$$\nI(\\mu)\\cdot \\exp\\big(2h(X)\\big)=\\frac{1}{\\sigma^{2}}\\cdot\\big(2\\pi\\,\\exp(1)\\,\\sigma^{2}\\big)=2\\pi\\,\\exp(1).\n$$\n这个最终表达式只依赖于基本常数。", "answer": "$$\\boxed{2 \\pi \\exp(1)}$$", "id": "1653753"}]}