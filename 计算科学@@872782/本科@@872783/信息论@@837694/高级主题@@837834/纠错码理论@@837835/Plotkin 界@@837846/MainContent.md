## 引言
在信息论和编码理论中，一个根本性的挑战是在噪声信道中实现可靠的通信。[纠错码](@entry_id:153794)通过在数据中添加冗余信息来应对这一挑战，但其设计面临着固有的参数权衡。我们总希望在固定的码长 $n$ 下，既能纠正尽可能多的错误（即拥有较大的最小距离 $d$），又能传输尽可能多的信息（即拥有较大的码字数量 $M$）。那么，对于给定的 $n$ 和 $d$，一个编码最多能包含多少个码字？这个问题引出了编码理论中的各种“界”，而普洛特金界（Plotkin Bound）正是其中一个强有力的回答，尤其是在要求高[纠错](@entry_id:273762)能力的场景下。
本文旨在系统性地剖析普洛特金界。我们将首先深入其核心，揭示其巧妙的推导过程；随后，我们将探索其在实际编码设计、理论评估以及[量子信息](@entry_id:137721)等前沿领域的广泛应用；最后，通过实践练习巩固理解。通过这三个章节的学习，读者将不仅掌握一个重要的数学公式，更能深刻理解编码设计中效率与可靠性之间不可避免的张力，以及理论工具如何指导工程实践。
第一章将从“原理与机制”出发，详细介绍普洛特金界背后的均值法思想，阐明其适用条件，并将其与其他基本界限进行比较，为您奠定坚实的理论基础。

## 原理与机制

在[编码理论](@entry_id:141926)中，一个核心问题是在给定的码长 $n$ 和最小距离 $d$ 的约束下，一个编码最多能包含多少个码字 $M$。Plotkin界为这个问题提供了一个强有力的解答，尤其是在高密度纠错（即 $d$ 相对较大）的场景下。本章将深入探讨Plotkin界的原理、推导过程、实际应用及其理论推广，揭示其背后的核心机制——均值法。

### Plotkin界的核心思想：均值法

Plotkin界的推导不直接从单个码字对的最小距离入手，而是采用一个更为全局的视角，这个方法被称为**均值法 (averaging argument)**。其核心思想是计算编码中所有码字对之间[汉明距离](@entry_id:157657)的总和，并从两个不同的角度对这个总和进行估算，从而建立一个包含码尺寸 $M$ 的不等式。

我们考虑一个 $(n, M, d)_q$ 码，其码字集合为 $C = \{c_1, c_2, \dots, c_M\}$。令 $S$ 代表所有 $\binom{M}{2}$ 个不同码字对的汉明距离之和：
$$ S = \sum_{1 \le i  j \le M} d_H(c_i, c_j) $$

第一步是为 $S$ 建立一个**下界**。根据最小距离 $d$ 的定义，任意两个不同码字之间的汉明距离至少为 $d$。由于总共有 $\binom{M}{2} = \frac{M(M-1)}{2}$ 对不同的码字，距离总和 $S$ 必然满足：
$$ S \ge d \binom{M}{2} $$
这个下界直观地反映了最小距离对全体码字“分离度”的保证。

第二步，也是均值法中最精妙的一步，是为 $S$ 建立一个**[上界](@entry_id:274738)**。为此，我们将总距离 $S$ 的计算分解到每个坐标位置上。对于长度为 $n$ 的码，总距离等于在所有 $n$ 个位置上，码字对符号差异的总和。

考虑第 $i$ 个坐标位置（$1 \le i \le n$）。假设在该位置上，来自 $q$ 元字母表的符号 $a$ 出现了 $n_{i,a}$ 次。显然，所有符号的出现次数之和等于码字总数，即 $\sum_{a=0}^{q-1} n_{i,a} = M$。在第 $i$ 个位置上，一对码字的符号如果相同，它们对总距离 $S$ 的贡献为0；如果不同，则贡献为1。因此，我们只需计算在第 $i$ 个位置上符号不同的码字对的数量。

在第 $i$ 个位置上，符号相同的码字对总数为 $\sum_{a=0}^{q-1} \binom{n_{i,a}}{2}$。由于总码字对数为 $\binom{M}{2}$，因此在该位置上符号不同的码字对数量为：
$$ \binom{M}{2} - \sum_{a=0}^{q-1} \binom{n_{i,a}}{2} = \frac{M(M-1)}{2} - \sum_{a=0}^{q-1} \frac{n_{i,a}(n_{i,a}-1)}{2} = \frac{1}{2} \left( M^2 - \sum_{a=0}^{q-1} n_{i,a}^2 \right) $$
为了使这个值最大化以得到 $S$ 的上界，我们需要最小化平方和 $\sum_{a=0}^{q-1} n_{i,a}^2$。根据柯西-[施瓦茨不等式](@entry_id:202153)（或均方不等式），在和 $\sum n_{i,a} = M$ 固定的条件下，当所有 $n_{i,a}$ 尽可能相等时（即 $n_{i,a} = M/q$），平方和取得最小值。该最小值为：
$$ \sum_{a=0}^{q-1} n_{i,a}^2 \ge \frac{1}{q} \left( \sum_{a=0}^{q-1} n_{i,a} \right)^2 = \frac{M^2}{q} $$
将此结果代入，我们得到在第 $i$ 位置上不同码字对数量的上限：
$$ \frac{1}{2} \left( M^2 - \frac{M^2}{q} \right) = \frac{M^2}{2} \left( 1 - \frac{1}{q} \right) $$
将所有 $n$ 个位置的贡献相加，我们就得到了总距离 $S$ 的[上界](@entry_id:274738)：
$$ S \le \sum_{i=1}^n \frac{M^2}{2} \left( 1 - \frac{1}{q} \right) = \frac{n M^2 (q-1)}{2q} $$

### Plotkin界的推导与适用条件

现在我们拥有了 $S$ 的下界和上界，可以将它们结合起来：
$$ d \binom{M}{2} \le S \le \frac{n M^2 (q-1)}{2q} $$
展开 $\binom{M}{2}$ 并假设 $M \ge 2$，我们得到：
$$ \frac{d M(M-1)}{2} \le \frac{n M^2 (q-1)}{2q} $$
两边同乘以 $2/M$ 进行化简：
$$ d(M-1) \le \frac{n M(q-1)}{q} $$
为了解出关于 $M$ 的不等式，我们将含有 $M$ 的项移到同一边：
$$ M \left( d - \frac{n(q-1)}{q} \right) \le d $$
这个不等式的含义至关重要。要从中得到一个对 $M$ 的有意义的（即有限的）[上界](@entry_id:274738)， $M$ 的系数必须为正。这引出了 Plotkin 界的**适用条件** [@problem_id:1646694]：
$$ d - \frac{n(q-1)}{q}  0 \quad \iff \quad qd  n(q-1) $$
当这个条件满足时，我们可以将该正系数除到不等式右边，得到**Plotkin界**：
$$ M \le \frac{d}{d - \frac{n(q-1)}{q}} = \frac{qd}{qd - n(q-1)} $$
如果 $qd \le n(q-1)$，那么 $M$ 的系数为非正数，该不等式对任何 $M$ 都成立（或仅给出 $0 \le d$ 这样的平凡结果），因此无法提供对 $M$ 的有效[上界](@entry_id:274738)。例如，对于一个[二进制码](@entry_id:266597)（$q=2$），适用条件为 $2d  n$。若有一个码的参数为 $n=20, d=9$，则 $2d=18 \ngtr 20$，不满足该条件。此时，界限公式的分母为 $9 - 20(1-1/2) = -1$，得出的“界”为负数，这清晰地表明在此参数下Plotkin界是无信息量的 [@problem_id:1646702]。

### Plotkin界的实践应用与解读

Plotkin界不仅是一个理论公式，它也深刻地揭示了编码设计中参数之间的[基本权](@entry_id:200855)衡关系。

#### [二进制码](@entry_id:266597)的特例与参数权衡

对于最重要的[二进制码](@entry_id:266597)（$q=2$），Plotkin界的适用条件简化为 $2d  n$，其形式为：
$$ M \le \frac{2d}{2d - n} $$
由于 $M$ 必须是整数，实际的界限是 $M \le \lfloor \frac{2d}{2d - n} \rfloor$。这个公式清晰地量化了码尺寸 $M$ 和最小距离 $d$ 之间的对立关系。

一方面，要求极高的纠错能力（即 $d$ 非常大）会极大地限制码的尺寸。例如，考虑一个码长为 $n=150$ 的[二进制码](@entry_id:266597)。如果要求一个极高的最小距离，如 $d_A=145$，那么 $2d_A=290  150$，满足条件。Plotkin界给出 $M_A \le \lfloor \frac{2 \cdot 145}{290 - 150} \rfloor = \lfloor \frac{290}{140} \rfloor = 2$。这意味着最多只能有两个码字。而如果将要求放宽到 $d_B=100$，则 $M_B \le \lfloor \frac{2 \cdot 100}{200 - 150} \rfloor = \lfloor \frac{200}{50} \rfloor = 4$。这个例子生动地说明，当最小距离接近码长时，能够容纳的码字数量会急剧下降 [@problem_id:1646682]。

另一方面，如果系统要求一个较大的码尺寸 $M$，则必然会对可实现的最小距离 $d$ 构成上限。假设一个系统要求码长 $n=21$，且至少需要 $M=40$ 个码字。如果我们希望设计一个处于Plotkin界[适用范围](@entry_id:636189)（$2d  n$）内的码，那么必须满足 $40 \le \frac{2d}{2d-21}$。解这个不等式得到 $d \le 140/13 \approx 10.77$。然而，适用条件 $2d > 21$ 要求 $d > 10.5$。综合来看，能够满足 $d > 10.5$ 的最小整数是 $d=11$，但这个值不满足 $d \le 10.77$。因此，不存在满足 $2d > n$ 的整数 $d$ 能使码尺寸达到40 [@problem_id:1646695]。

#### 与其他界的比较

将Plotkin界与其他编码界限比较，可以更好地理解其适用范围和强度。一个基础的界是**[Singleton界](@entry_id:269293)**：$M \le q^{n-d+1}$。

考虑一个[二进制码](@entry_id:266597) $(n=7, d=5)$。[Singleton界](@entry_id:269293)给出 $M \le 2^{7-5+1} = 2^3 = 8$。而对于这个码，$2d = 10  7 = n$，满足Plotkin界的条件。使用一个更精确的Plotkin界变体 $M \le 2 \lfloor \frac{d}{2d-n} \rfloor$，我们得到 $M \le 2 \lfloor \frac{5}{10-7} \rfloor = 2 \lfloor 5/3 \rfloor = 2 \cdot 1 = 2$。显然，$M \le 2$ 是一个比 $M \le 8$ 更紧的界。这说明，在适用区域内，Plotkin界通常远比[Singleton界](@entry_id:269293)更强 [@problem_id:1646647]。

有趣的是，在某些极端情况下，这两个界会重合。考虑 $d=n$ 的情况，这代表任意两个不同的码字在所有位置上都不同。Plotkin界的条件 $qn  n(q-1)$ 对于 $q \ge 2$ 恒成立。将 $d=n$ 代入Plotkin界公式：
$$ M \le \frac{qn}{qn - n(q-1)} = \frac{qn}{n} = q $$
而[Singleton界](@entry_id:269293)此时也给出 $M \le q^{n-n+1} = q^1 = q$。两个界在此点上的一致性，为[编码理论](@entry_id:141926)的内在和谐提供了佐证 [@problem_id:1646688]。

### 推广与渐近行为

Plotkin界背后的均值法思想具有很强的普适性，可以被推广到更复杂的情形，并用于分析编码的渐近性能。

#### 从最小距离到平均距离

回顾Plotkin界的推导，我们会发现，对距离总和 $S$ 的下界估计 $S \ge d \binom{M}{2}$，实际上是其最弱的一环。如果我们拥有关于码字间距离更精细的信息，例如**平均汉明距离** $d_{avg}$，我们就可以得到一个更紧的界。
$$ d_{avg} = \frac{S}{\binom{M}{2}} $$
将 $S$ 的上界和这个定义结合起来，对于[二进制码](@entry_id:266597)，我们有：
$$ d_{avg} \binom{M}{2} \le \frac{nM^2}{4} \implies d_{avg} \frac{M(M-1)}{2} \le \frac{nM^2}{4} $$
当 $2d_{avg}  n$ 时，可解得 $M \le \frac{2d_{avg}}{2d_{avg}-n}$。这表明Plotkin界本质上是一个基于平均距离的界 [@problem_id:1646679]。

这种推广在分析复合码时尤其有用。考虑一个由两个不相交的子码 $C_1$ 和 $C_2$ 联合构成的码 $C = C_1 \cup C_2$。设它们的尺寸分别为 $M_1, M_2$，内部最小距离为 $d_1, d_2$，相互间的最小距离为 $d_{12}$。我们可以为该复合码的平均距离 $\bar{d}$ 建立一个下界，即有效平均距离 $d_{eff}$：
$$ \bar{d} \ge d_{eff} = \frac{\binom{M_1}{2} d_1 + \binom{M_2}{2} d_2 + M_1 M_2 d_{12}}{\binom{M_1+M_2}{2}} $$
这个 $d_{eff}$ 是通过对所有码字对（$C_1$内部、 $C_2$内部、以及 $C_1$与$C_2$之间）的最小距离进行加权平均得到的。将这个 $d_{eff}$ 代入基于平均距离的Plotkin界公式，便可得到关于复合码尺寸 $M=M_1+M_2$ 的一个更紧的界限 [@problem_id:1646659]。

#### [渐近行为](@entry_id:160836)：码率与相对距离的极限

Plotkin界在[渐近分析](@entry_id:160416)中扮演着重要角色，它揭示了[码率](@entry_id:176461) $R = \frac{\log_q M}{n}$ 与相对距离 $\delta = d/n$ 之间的根本限制。将Plotkin界用这些相对参数重写：
$$ M \le \frac{q \delta n}{q \delta n - n(1-1/q)} = \frac{q \delta}{q\delta - (q-1)} $$
两边取 $\log_q$ 再除以 $n$：
$$ R \le \frac{1}{n} \log_q \left( \frac{q \delta}{q\delta - (q-1)} \right) $$
考虑一个码族，其码长 $n \to \infty$，且其相对距离 $\delta(n)$ 从上方逼近临界值 $1-1/q$。例如，设 $\delta(n) = (1 - 1/q) + c/n$，其中 $c  0$ 是一个常数。将此代入Plotkin界，我们发现 $M(n) \le \frac{n(1-1/q)+c}{c}$。这意味着 $M(n)$ 随 $n$ [线性增长](@entry_id:157553)。
因此，码率 $R(n)$ 的[上界](@entry_id:274738)为：
$$ R(n) \le \frac{1}{n} \log_q\left(\frac{n(1-1/q)+c}{c}\right) $$
当 $n \to \infty$ 时，$\log(n)/n \to 0$。因此，我们得出结论：
$$ \lim_{n \to \infty} R(n) = 0 $$
这个重要的渐近结果表明，对于一个码族，如果其相对距离达到或超过Plotkin界的临界值 $1-1/q$，那么其[码率](@entry_id:176461)必须趋于零。换言之，我们不可能同时拥有高码率和达到Plotkin阈值的高纠错能力。这构成了[编码理论](@entry_id:141926)中一个著名的**上界**，限定了“好码”存在的范围 [@problem_id:1646652]。