{"hands_on_practices": [{"introduction": "本练习是强大数定律最核心和直接的应用。通过分析一个假设的信号处理器输出，我们能亲眼见证，当收集的数据越来越多时，样本的平均值是如何稳定地趋向一个理论上的常数。这个过程不仅能加深你对强大数定律的理解，还能让你练习从概率密度函数计算期望值的基本技能。[@problem_id:1460774]", "problem": "一个研究团队正在研究一种新型信号处理器的输出。每当处理器运行时，它会生成一个归一化值，该值可以建模为一个随机变量。这些值的一个序列 $X_1, X_2, X_3, \\dots$ 被记录下来。这些值被认为是独立同分布 (i.i.d.) 的随机变量。任何单个值 $X_i$ 的概率分布的理论模型由以下概率密度函数 (PDF) 描述：\n$$\nf(x) = \\begin{cases} 3x^2  \\text{for } 0 \\le x \\le 1 \\\\ 0  \\text{otherwise} \\end{cases}\n$$\n经过 $n$ 次试验后，这些测量的长期平均值由样本均值 $S_n = \\frac{1}{n}\\sum_{i=1}^{n} X_i$ 给出。随着试验次数 $n$ 趋于无穷大，$S_n$ 的值将几乎必然地收敛到一个特定的常数。\n\n求这个常数的值。请用最简分数形式表示你的答案。", "solution": "给定独立同分布的随机变量 $X_{1},X_{2},\\dots$，其共同的密度函数为\n$$\nf(x)=\\begin{cases}\n3x^{2},  0\\le x\\le 1,\\\\\n0,  \\text{otherwise.}\n\\end{cases}\n$$\n首先，通过检查归一性来验证 $f$ 是一个有效的概率密度函数：\n$$\n\\int_{-\\infty}^{\\infty} f(x)\\,dx=\\int_{0}^{1}3x^{2}\\,dx=3\\left[\\frac{x^{3}}{3}\\right]_{0}^{1}=1.\n$$\n根据强大数定律，由于 $X_{i}$ 是独立同分布且具有有限均值 $E[|X_{1}|]  \\infty$（这一点成立是因为 $0\\le X_{1}\\le 1$ 几乎必然成立），样本均值\n$$\nS_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}\n$$\n当 $n\\to\\infty$ 时，几乎必然地收敛到 $E[X_{1}]$。\n\n计算期望值：\n$$\nE[X_{1}]=\\int_{-\\infty}^{\\infty} x f(x)\\,dx=\\int_{0}^{1} x\\cdot 3x^{2}\\,dx=3\\int_{0}^{1} x^{3}\\,dx=3\\left[\\frac{x^{4}}{4}\\right]_{0}^{1}=\\frac{3}{4}.\n$$\n因此，\n$$\n\\lim_{n\\to\\infty} S_{n}=\\frac{3}{4}\\quad \\text{almost surely}.\n$$", "answer": "$$\\boxed{\\frac{3}{4}}$$", "id": "1460774"}, {"introduction": "在数据分析中，我们常常需要处理原始数据的变换形式。本练习探讨了当我们将强大数定律应用于随机变量的函数（例如，取平方根）时会发生什么。它揭示了该定律的普适性：只要变换后变量的期望有限，样本均值仍会收敛到一个确定的期望值，这展示了将基本理论应用于更复杂数据处理场景的方法。[@problem_id:1957052]", "problem": "一个研究团队正在研究一种新发现的微生物的能量排放。在短暂的观察期内，单个微生物释放的能量是一个随机变量。该团队进行了一系列独立的实验，每次实验都测量一个新随机选取的微生物的能量排放 $X_i$。这些测量值 $X_1, X_2, X_3, \\dots$ 可以被建模为一系列独立同分布（i.i.d.）的正随机变量。根据理论模型可知，期望能量排放是有限的，即 $E[X_i] = \\mu$，其中 $\\mu > 0$ 是一个有限常数。\n\n在一项数据处理任务中，一位分析师关心的不是能量本身，而是一个相关的量 $Y_i = \\sqrt{X_i}$。分析师计算了这 $n$ 次实验中这些转换后数值的样本均值：\n$$S_n = \\frac{1}{n}\\sum_{i=1}^n Y_i = \\frac{1}{n}\\sum_{i=1}^n \\sqrt{X_i}$$\n当实验次数 $n$ 趋于无穷大时，样本均值 $S_n$ 几乎必然收敛到什么值？请用随机变量 $X_1$ 来表示你的答案。", "solution": "问题要求解当 $n \\to \\infty$ 时，样本均值 $S_n = \\frac{1}{n}\\sum_{i=1}^n \\sqrt{X_i}$ 的几乎必然极限。\n\n让我们定义一个新的随机变量序列 $Y_i = \\sqrt{X_i}$，其中 $i=1, 2, 3, \\dots$。由于随机变量 $X_1, X_2, \\dots$ 是独立同分布（i.i.d.）的，所以随机变量 $Y_1 = \\sqrt{X_1}, Y_2 = \\sqrt{X_2}, \\dots$ 也是独立同分布的。这是因为独立同分布随机变量的任何函数都会产生一个新的独立同分布随机变量序列。\n\n样本均值可以用 $Y_i$ 变量重写为：\n$$S_n = \\frac{1}{n}\\sum_{i=1}^n Y_i$$\n这是 i.i.d. 序列 $Y_i$ 的样本均值。\n\n我们可以对序列 $\\{Y_i\\}$ 应用强大数定律（SLLN）。强大数定律指出，如果 $Y_1, Y_2, \\dots$ 是一个具有有限期望值（即 $E[|Y_1|]  \\infty$）的 i.i.d. 随机变量序列，那么样本均值几乎必然收敛于真实均值：\n$$\\frac{1}{n}\\sum_{i=1}^n Y_i \\xrightarrow{\\text{a.s.}} E[Y_1] \\quad \\text{as } n \\to \\infty$$\n\n为了使用强大数定律，我们必须验证 $E[|Y_1|]$ 是有限的。\n我们有 $Y_1 = \\sqrt{X_1}$。问题陈述 $X_i$ 是正随机变量，所以 $X_1 > 0$。这意味着 $\\sqrt{X_1}$ 是一个正实数，所以 $|Y_1| = |\\sqrt{X_1}| = \\sqrt{X_1}$。我们需要检查 $E[\\sqrt{X_1}]$ 是否有限。\n\n我们可以使用琴生不等式（Jensen's inequality）将 $E[\\sqrt{X_1}]$ 与已知的有限均值 $E[X_1] = \\mu$ 联系起来。对于凹函数 $g(x)$ 和随机变量 $X$，琴生不等式表明 $E[g(X)] \\le g(E[X])$。\n\n对于 $x > 0$，函数 $g(x) = \\sqrt{x}$ 是一个凹函数。这可以通过检查其二阶导数来证明：\n$g'(x) = \\frac{1}{2}x^{-1/2}$\n$g''(x) = -\\frac{1}{4}x^{-3/2}$\n由于 $x > 0$，我们有 $g''(x)  0$，这证实了 $g(x) = \\sqrt{x}$ 是严格凹函数。\n\n将琴生不等式应用于函数 $g(x) = \\sqrt{x}$ 和随机变量 $X_1$，我们得到：\n$$E[\\sqrt{X_1}] \\le \\sqrt{E[X_1]}$$\n问题陈述 $E[X_1] = \\mu$，且 $\\mu$ 是一个有限的正数。因此，\n$$E[\\sqrt{X_1}] \\le \\sqrt{\\mu}$$\n由于 $\\mu$ 是有限的，$\\sqrt{\\mu}$ 也是有限的。这表明 $E[\\sqrt{X_1}]$ 是有限的。\n因为 $Y_1 = \\sqrt{X_1}$ 是一个正随机变量，我们有 $E[|Y_1|] = E[Y_1] = E[\\sqrt{X_1}]$，这是有限的。\n\n强大数定律的条件对于序列 $\\{Y_i\\}$ 是满足的。因此，我们可以得出结论，样本均值 $S_n$ 几乎必然收敛于 $Y_1$ 的期望：\n$$\\lim_{n \\to \\infty} S_n = \\lim_{n \\to \\infty} \\frac{1}{n}\\sum_{i=1}^n Y_i \\xrightarrow{\\text{a.s.}} E[Y_1]$$\n将 $Y_1 = \\sqrt{X_1}$ 代回，我们找到极限：\n$$\\lim_{n \\to \\infty} S_n \\xrightarrow{\\text{a.s.}} E[\\sqrt{X_1}]$$\n问题要求 $S_n$ 几乎必然收敛到的值。这个值是 $E[\\sqrt{X_1}]$。", "answer": "$$\\boxed{E[\\sqrt{X_1}]}$$", "id": "1957052"}, {"introduction": "标准强大数定律的基石是变量的独立性，但许多真实系统并非如此。本练习将带你挑战一个变量间存在依赖关系（相邻项相依）的进阶情景。它旨在启发一种重要的解题策略：当标准条件不满足时，尝试将复杂序列分解为更简单的、满足定律条件的子序列。通过解决这个问题，你将学会如何将理论知识灵活应用于更广泛、更现实的随机过程中。[@problem_id:1460782]", "problem": "考虑一个定义在同一概率空间上的独立同分布（i.i.d.）随机变量序列 $\\{X_n\\}_{n=1}^{\\infty}$。对于所有 $n \\ge 1$，这些变量的特征是其均值为 $E[X_n] = 0$，二阶矩为 $E[X_n^2] = 1$。\n\n我们构建一个新的样本均值序列，定义为 $A_n = \\frac{1}{n} \\sum_{i=1}^{n-1} X_i X_{i+1}$，其中 $n \\ge 2$。\n\n求当 $n$ 趋于无穷时，序列 $A_n$ 几乎必然收敛到的值。", "solution": "定义 $Y_{i} = X_{i}X_{i+1}$，其中 $i \\ge 1$。那么对于 $n \\ge 2$，有 $A_{n} = \\frac{1}{n} \\sum_{i=1}^{n-1} Y_{i}$。根据 $X_{i}$ 的独立性和同分布性，每个 $Y_{i}$ 都具有相同的分布，且\n$$\nE[Y_{i}] = E[X_{i}X_{i+1}] = E[X_{i}]\\,E[X_{i+1}] = 0,\n$$\n以及\n$$\nE[Y_{i}^{2}] = E[X_{i}^{2}X_{i+1}^{2}] = E[X_{i}^{2}]\\,E[X_{i+1}^{2}] = 1.\n$$\n因此，根据 Cauchy–Schwarz 不等式，有 $E[|Y_{i}|] \\le \\sqrt{E[Y_{i}^{2}]} = 1$，所以 $Y_{i}$ 是可积的。\n\n接下来，观察其依赖结构：族 $\\{Y_{i}\\}_{i \\ge 1}$ 是 1-相依的。更具体地说，子序列 $\\{Y_{2j-1}\\}_{j \\ge 1}$ 和 $\\{Y_{2j}\\}_{j \\ge 1}$ 各自由相互独立的随机变量组成，因为它们依赖于不相交的独立 $X_{i}$ 集合。此外，每个子序列都是同分布的，均值为 0，且具有有限的二阶矩。通过将 Kolmogorov 强大数定律分别应用于每个子序列，可得\n$$\n\\frac{1}{k} \\sum_{j=1}^{k} Y_{2j-1} \\to 0 \\quad \\text{a.s.}, \n\\qquad\n\\frac{1}{k} \\sum_{j=1}^{k} Y_{2j} \\to 0 \\quad \\text{a.s.}\n$$\n\n对于每个 $n \\ge 2$，令 $N_{o}(n)$ 为 $\\{1,\\dots,n-1\\}$ 中奇数下标的数量，令 $N_{e}(n)$ 为 $\\{1,\\dots,n-1\\}$ 中偶数下标的数量。则有 $N_{o}(n) + N_{e}(n) = n-1$，其中 $N_{o}(n) = \\lceil (n-1)/2 \\rceil$，$N_{e}(n) = \\lfloor (n-1)/2 \\rfloor$。因此，当 $n \\to \\infty$ 时，$N_{o}(n)/n \\to \\frac{1}{2}$ 和 $N_{e}(n)/n \\to \\frac{1}{2}$ 是确定性收敛的。将 $A_n$ 分解为\n$$\nA_{n} \n= \\frac{1}{n} \\sum_{i=1}^{n-1} Y_{i}\n= \\frac{N_{o}(n)}{n} \\left( \\frac{1}{N_{o}(n)} \\sum_{j=1}^{N_{o}(n)} Y_{2j-1} \\right)\n+ \\frac{N_{e}(n)}{n} \\left( \\frac{1}{N_{e}(n)} \\sum_{j=1}^{N_{e}(n)} Y_{2j} \\right).\n$$\n当 $n \\to \\infty$ 时，我们有 $N_{o}(n) \\to \\infty$ 和 $N_{e}(n) \\to \\infty$。因此，根据子序列均值的几乎必然极限和权重的确定性极限，可以得出 $A_{n} \\to 0$ 几乎必然。\n\n因此，序列 $A_{n}$ 几乎必然收敛于 $0$。", "answer": "$$\\boxed{0}$$", "id": "1460782"}]}