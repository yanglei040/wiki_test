{"hands_on_practices": [{"introduction": "中心极限定理的核心思想是，大量独立同分布的随机变量之和近似服从正态分布，无论原始分布是什么。这个练习将带你应用该定理来解决一个具体问题：估算泊松分布变量之和的概率，这是对计数数据建模时的经典场景。通过这个练习[@problem_id:480135]，你将掌握中心极限定理最直接的应用。", "problem": "设 $Y_1, Y_2, \\dots$ 为一个独立同分布的随机变量序列，每个变量都服从参数为 $\\lambda = 1$ 的泊松分布。对于 $n \\in \\mathbb{N}$，定义部分和 $S_n = \\sum_{k=1}^n Y_k$。使用中心极限定理，近似计算概率 $P(90 \\leq S_{100} \\leq 110)$。给出近似的数值，并四舍五入到10位有效数字。", "solution": "1. 对于独立同分布的 $Y_k\\sim\\mathrm{Poisson}(1)$，和 $S_{100}=\\sum_{k=1}^{100}Y_k$ 的均值和方差为\n$$\\mu=\\mathbb{E}[S_{100}]=100\\cdot1=100,\\quad\\sigma^2=\\mathrm{Var}(S_{100})=100\\cdot1=100.$$\n2. 根据中心极限定理，对于 $Z\\sim N(0,1)$，\n$$P(90\\le S_{100}\\le110)\\approx P\\Bigl(\\frac{90-\\mu}{\\sigma}\\le Z\\le\\frac{110-\\mu}{\\sigma}\\Bigr).$$\n3. 计算标准化边界：\n$$\\frac{90-100}{10}=-1,\\quad\\frac{110-100}{10}=1.$$\n4. 因此\n$$P(90\\le S_{100}\\le110)\\approx \\Phi(1)-\\Phi(-1)=2\\Phi(1)-1.$$\n5. 使用 $\\Phi(1)\\approx0.8413447461$ 可得\n$$2\\cdot0.8413447461-1=0.6826894921370859\\approx0.6826894921\\quad(\\text{10位有效数字})。$$", "answer": "$$\\boxed{0.6826894921}$$", "id": "480135"}, {"introduction": "当我们用连续的正态分布来近似离散分布的和时，会产生一个微小的系统性误差。为了提高近似的精度，我们引入了“连续性校正”这一重要技巧。这个练习[@problem_id:852436]将引导你为一个自定义的离散分布计算其和的概率，并应用连续性校正来获得更准确的结果。", "problem": "一个离散随机变量 $X$ 的取值集合为 $S = \\{-2, -1, 0, 1, 3\\}$。其概率质量函数 (PMF) 为 $P(X=k) = C(k^2+1)$，其中 $k \\in S$，$C$ 是一个归一化常数。\n\n设 $X_1, X_2, \\dots, X_n$ 是一个由 $n$ 个独立同分布 (i.i.d.) 的随机变量组成的序列，每个变量都与 $X$ 具有相同的分布。考虑它们的和 $S_n = \\sum_{i=1}^n X_i$。\n\n对于 $n=470$，使用带连续性校正的中心极限定理，计算概率 $P(S_{470} > 540)$。\n\n已知对于标准正态随机变量 $Z \\sim N(0,1)$，其在 $z=1.5$ 处的累积分布函数 (CDF) 值为 $\\Phi(1.5) \\approx 0.9331927987$。", "solution": "1. 归一化常数：\n$$\\sum_{k\\in\\{-2,-1,0,1,3\\}}(k^2+1)=5+2+1+2+10=20,\\quad C=\\frac1{20}.$$\n2. 均值：\n$$\\mu=E[X]=C\\sum k\\,(k^2+1)\n=\\frac1{20}(-2\\cdot5-1\\cdot2+0\\cdot1+1\\cdot2+3\\cdot10)\n=\\frac{20}{20}=1.$$\n3. 二阶矩：\n$$E[X^2]=C\\sum k^2\\,(k^2+1)\n=\\frac1{20}(20+2+0+2+90)=\\frac{114}{20}=5.7.$$\n方差：\n$$\\sigma^2=E[X^2]-\\mu^2=5.7-1^2=4.7.$$\n4. 和 $S_{470}$：均值为 $470\\mu=470$，方差为 $470\\sigma^2=470\\cdot4.7=2209$，因此 $\\sigma_{S}=47$。\n5. 连续性校正：\n$$P(S_{470}>540)\\approx P\\bigl(S_{470}>540.5\\bigr)\n= P\\!\\Bigl(Z>\\frac{540.5-470}{47}\\Bigr)\n= P(Z>1.5)=1-\\Phi(1.5)\\approx1-0.9331927987=0.0668072013.$$", "answer": "$$\\boxed{0.0668072013}$$", "id": "852436"}, {"introduction": "中心极限定理的威力远不止于处理简单的和，它可以通过“德尔塔方法”(Delta Method)推广，用于确定样本均值的复杂函数的分布。本练习[@problem_id:852421]将探讨对数优势比 (log-odds ratio)，这是一个在医学和流行病学等领域至关重要的统计量。你将学习如何运用德尔塔方法推导其渐近方差，从而将概率论与实际的统计推断联系起来。", "problem": "考虑从两个不同的伯努利总体中分别抽取的两个独立随机样本，其大小分别为 $n_1$ 和 $n_2$。第一个总体的成功概率为 $p_1$，第二个总体的成功概率为 $p_2$。设 $X_1$ 和 $X_2$ 分别为在第一个和第二个样本中观测到的成功次数。样本比例则由 $\\hat{p}_1 = \\frac{X_1}{n_1}$ 和 $\\hat{p}_2 = \\frac{X_2}{n_2}$ 给出。\n\n在许多统计分析中，特别是在流行病学和临床试验中，对数优势比是一个非常重要的量。真实的对数优势比定义为 $\\theta = \\log\\left(\\frac{p_1/(1-p_1)}{p_2/(1-p_2)}\\right)$。基于样本比例，该量的一个估计量是样本对数优势比：\n$$\n\\hat{\\theta} = \\log\\left(\\frac{\\hat{p}_1/(1-\\hat{p}_1)}{\\hat{p}_2/(1-\\hat{p}_2)}\\right)\n$$\n假设样本量 $n_1$ 和 $n_2$ 足够大，中心极限定理可以通过 Delta 方法进行扩展，以找到 $\\hat{\\theta}$ 的近似分布。\n\n推导对数优势比估计量 $\\hat{\\theta}$ 的渐近方差 $\\text{Var}(\\hat{\\theta})$。", "solution": "问题要求解对数优势比估计量 $\\hat{\\theta}$ 的渐近方差。我们可以使用多元 Delta 方法来求解。\n\n首先，根据中心极限定理，对于大样本量 $n_1$ 和 $n_2$，样本比例 $\\hat{p}_1$ 和 $\\hat{p}_2$ 近似服从正态分布：\n$$\n\\hat{p}_1 \\approx N\\left(p_1, \\frac{p_1(1-p_1)}{n_1}\\right)\n$$\n$$\n\\hat{p}_2 \\approx N\\left(p_2, \\frac{p_2(1-p_2)}{n_2}\\right)\n$$\n由于两个样本是独立的，随机变量 $\\hat{p}_1$ 和 $\\hat{p}_2$ 也是独立的。因此，样本比例向量 $\\hat{\\mathbf{p}} = (\\hat{p}_1, \\hat{p}_2)^T$ 服从渐近二元正态分布，其均值向量为 $\\boldsymbol{\\mu}$，协方差矩阵为 $\\boldsymbol{\\Sigma}$：\n$$\n\\boldsymbol{\\mu} = E[\\hat{\\mathbf{p}}] = \\begin{pmatrix} p_1 \\\\ p_2 \\end{pmatrix}\n$$\n$$\n\\boldsymbol{\\Sigma} = \\text{Cov}(\\hat{\\mathbf{p}}) = \\begin{pmatrix} \\text{Var}(\\hat{p}_1) & \\text{Cov}(\\hat{p}_1, \\hat{p}_2) \\\\ \\text{Cov}(\\hat{p}_1, \\hat{p}_2) & \\text{Var}(\\hat{p}_2) \\end{pmatrix} = \\begin{pmatrix} \\frac{p_1(1-p_1)}{n_1} & 0 \\\\ 0 & \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix}\n$$\n估计量 $\\hat{\\theta}$ 是 $\\hat{p}_1$ 和 $\\hat{p}_2$ 的函数。设此函数为 $g(x, y)$：\n$$\ng(x, y) = \\log\\left(\\frac{x/(1-x)}{y/(1-y)}\\right) = \\log(x) - \\log(1-x) - \\log(y) + \\log(1-y)\n$$\n多元 Delta 方法指出，函数 $g(\\hat{\\mathbf{p}})$ 的渐近方差由下式给出：\n$$\n\\text{Var}(g(\\hat{\\mathbf{p}})) \\approx (\\nabla g(\\boldsymbol{\\mu}))^T \\boldsymbol{\\Sigma} (\\nabla g(\\boldsymbol{\\mu}))\n$$\n其中 $\\nabla g(\\boldsymbol{\\mu})$ 是函数 $g$ 在均值向量 $\\boldsymbol{\\mu} = (p_1, p_2)^T$ 处计算的梯度。\n\n首先，我们计算 $g(x, y)$ 的梯度：\n$$\n\\frac{\\partial g}{\\partial x} = \\frac{1}{x} - \\frac{1}{1-x}(-1) = \\frac{1}{x} + \\frac{1}{1-x} = \\frac{1-x+x}{x(1-x)} = \\frac{1}{x(1-x)}\n$$\n$$\n\\frac{\\partial g}{\\partial y} = -\\frac{1}{y} + \\frac{1}{1-y}(-1) = -\\frac{1}{y} - \\frac{1}{1-y} = -\\frac{1-y+y}{y(1-y)} = -\\frac{1}{y(1-y)}\n$$\n所以梯度向量为 $\\nabla g(x,y) = \\left(\\frac{1}{x(1-x)}, -\\frac{1}{y(1-y)}\\right)^T$。\n\n接下来，我们在均值 $\\boldsymbol{\\mu} = (p_1, p_2)^T$ 处计算梯度：\n$$\n\\nabla g(\\boldsymbol{\\mu}) = \\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\\\ -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n$$\n现在，我们可以将梯度和协方差矩阵代入 Delta 方法的方差公式中：\n$$\n\\text{Var}(\\hat{\\theta}) \\approx \n\\begin{pmatrix} \\frac{1}{p_1(1-p_1)} & -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n\\begin{pmatrix} \\frac{p_1(1-p_1)}{n_1} & 0 \\\\ 0 & \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix}\n\\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\\\ -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n$$\n我们从左到右进行矩阵乘法。首先，将行向量（梯度的转置）与协方差矩阵相乘：\n$$\n\\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\cdot \\frac{p_1(1-p_1)}{n_1} + (-\\frac{1}{p_2(1-p_2)}) \\cdot 0 & \\frac{1}{p_1(1-p_1)} \\cdot 0 + (-\\frac{1}{p_2(1-p_2)}) \\cdot \\frac{p_2(1-p_2)}{n_2} \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} \\frac{1}{n_1} & -\\frac{1}{n_2} \\end{pmatrix}\n$$\n最后，将得到的行向量与列向量（梯度）相乘：\n$$\n\\text{Var}(\\hat{\\theta}) \\approx \\begin{pmatrix} \\frac{1}{n_1} & -\\frac{1}{n_2} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{p_1(1-p_1)} \\\\ -\\frac{1}{p_2(1-p_2)} \\end{pmatrix}\n$$\n$$\n= \\left(\\frac{1}{n_1}\\right) \\left(\\frac{1}{p_1(1-p_1)}\\right) + \\left(-\\frac{1}{n_2}\\right) \\left(-\\frac{1}{p_2(1-p_2)}\\right)\n$$\n$$\n= \\frac{1}{n_1 p_1 (1-p_1)} + \\frac{1}{n_2 p_2 (1-p_2)}\n$$\n这就是对数优势比估计量的渐近方差。", "answer": "$$\n\\boxed{\\frac{1}{n_1 p_1 (1-p_1)} + \\frac{1}{n_2 p_2 (1-p_2)}}\n$$", "id": "852421"}]}