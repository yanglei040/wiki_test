{"hands_on_practices": [{"introduction": "数据处理不等式最基本、最直观的推论是：处理过程无法无中生有地创造信息。这个练习 [@problem_id:1613376] 提供了一个具体场景，用以证明如果一个信号与我们感兴趣的变量无关，那么对该信号进行任何计算都无法使其变得相关。这巩固了“无源之水，无本之木”的核心思想，即信息不能凭空产生。", "problem": "在一个半导体生产线的质量控制系统中，我们监控一个特定蚀刻过程的状态。该状态由一个离散随机变量 $X$ 表示，其中 $X=0$ 表示过程成功，$X=1$ 表示过程失败。历史数据显示，失败的概率为 $P(X=1) = \\frac{1}{5}$。\n\n独立地，一个传感器监测洁净室中的环境压力，已知该压力与蚀刻过程的结果无关。压力被量化为四个离散水平之一，由随机变量 $Y \\in \\{1, 2, 3, 4\\}$ 表示。这些压力水平的概率分布为 $P(Y=1) = \\frac{1}{2}$，$P(Y=2) = \\frac{1}{4}$，$P(Y=3) = \\frac{1}{8}$，以及 $P(Y=4) = \\frac{1}{8}$。\n\n一个实时分析引擎接收原始压力水平 $Y$，并使用一个确定性函数计算一个汇总统计量 $Z$：$Z = (Y^2 - 1) \\pmod 3$。该汇总统计量被记录下来以供后续分析。\n\n一位工程师想要确定汇总统计量 $Z$ 中是否包含有关过程状态 $X$ 的任何信息。计算过程状态和汇总统计量之间的互信息 $I(X; Z)$。请用比特（bits）表示您的答案。", "solution": "两个离散随机变量 $X$ 和 $Z$ 之间的互信息定义为：\n$$I(X; Z) = \\sum_{x \\in \\mathcal{X}} \\sum_{z \\in \\mathcal{Z}} p(x, z) \\log_2 \\left( \\frac{p(x, z)}{p(x) p(z)} \\right)$$\n其中 $p(x, z)$ 是 $(X, Z)$ 的联合概率质量函数，$p(x)$ 和 $p(z)$ 分别是 $X$ 和 $Z$ 的边缘概率质量函数。计算结果以比特为单位，因此我们使用以 2 为底的对数。\n\n我们已知过程状态 $X$ 的概率分布：\n$P(X=1) = \\frac{1}{5}$\n$P(X=0) = 1 - P(X=1) = 1 - \\frac{1}{5} = \\frac{4}{5}$。\n\n我们也已知压力水平 $Y$ 的概率分布：\n$P(Y=1) = \\frac{1}{2}$\n$P(Y=2) = \\frac{1}{4}$\n$P(Y=3) = \\frac{1}{8}$\n$P(Y=4) = \\frac{1}{8}$\n\n汇总统计量 $Z$ 是 $Y$ 的一个确定性函数，由 $Z = g(Y) = (Y^2 - 1) \\pmod 3$ 给出。首先，我们必须确定 $Z$ 的可能值及其概率分布 $p(z)$。\n- 当 $Y=1$ 时：$Z = (1^2 - 1) \\pmod 3 = 0 \\pmod 3 = 0$。\n- 当 $Y=2$ 时：$Z = (2^2 - 1) \\pmod 3 = 3 \\pmod 3 = 0$。\n- 当 $Y=3$ 时：$Z = (3^2 - 1) \\pmod 3 = 8 \\pmod 3 = 2$。\n- 当 $Y=4$ 时：$Z = (4^2 - 1) \\pmod 3 = 15 \\pmod 3 = 0$。\n$Z$ 的可能值集合是 $\\mathcal{Z} = \\{0, 2\\}$。\n\n现在我们可以计算边缘概率分布 $p(z)$：\n$P(Z=0) = P(Y=1) + P(Y=2) + P(Y=4) = \\frac{1}{2} + \\frac{1}{4} + \\frac{1}{8} = \\frac{4}{8} + \\frac{2}{8} + \\frac{1}{8} = \\frac{7}{8}$。\n$P(Z=2) = P(Y=3) = \\frac{1}{8}$。\n作为检验，$P(Z=0) + P(Z=2) = \\frac{7}{8} + \\frac{1}{8} = 1$。\n\n接下来，我们需要求联合概率分布 $p(x, z)$。对于任意一对值 $(x, z)$：\n$p(x, z) = P(X=x, Z=z) = P(X=x, g(Y)=z)$。\n我们可以将其写成对所有映射到 $z$ 的 $y$ 值的求和：\n$P(X=x, g(Y)=z) = \\sum_{y: g(y)=z} P(X=x, Y=y)$。\n\n题目说明过程状态 $X$ 和压力水平 $Y$ 是独立的。因此，它们的联合概率是其边缘概率的乘积：$P(X=x, Y=y) = P(X=x) P(Y=y)$。\n将此代入 $p(x, z)$ 的表达式中：\n$p(x, z) = \\sum_{y: g(y)=z} \\left( P(X=x) P(Y=y) \\right)$。\n由于 $P(X=x)$ 不依赖于 $y$，我们可以将其从求和中提出来：\n$p(x, z) = P(X=x) \\left( \\sum_{y: g(y)=z} P(Y=y) \\right)$。\n括号中的求和项正是 $P(g(Y)=z)$ 的定义，也就是 $P(Z=z)$。\n因此，我们证明了 $p(x, z) = P(X=x) P(Z=z) = p(x) p(z)$。\n\n这个结果意味着随机变量 $X$ 和 $Z$ 是独立的。\n\n现在我们可以计算互信息 $I(X; Z)$。将 $p(x, z) = p(x) p(z)$ 代入互信息的定义中：\n$$I(X; Z) = \\sum_{x \\in \\mathcal{X}} \\sum_{z \\in \\mathcal{Z}} p(x) p(z) \\log_2 \\left( \\frac{p(x) p(z)}{p(x) p(z)} \\right)$$\n$$I(X; Z) = \\sum_{x \\in \\mathcal{X}} \\sum_{z \\in \\mathcal{Z}} p(x) p(z) \\log_2(1)$$\n由于 $\\log_2(1) = 0$，整个表达式变为：\n$$I(X; Z) = \\sum_{x \\in \\mathcal{X}} \\sum_{z \\in \\mathcal{Z}} p(x) p(z) \\cdot 0 = 0$$\n\n或者，可以认识到由于 $Z$ 是 $Y$ 的确定性函数，这些变量构成一个马尔可夫链 $X \\to Y \\to Z$。数据处理不等式指出，对于任何这样的马尔可夫链，都有 $I(X; Z) \\le I(X; Y)$。\n我们已知 $X$ 和 $Y$ 是独立的。两个独立变量之间的互信息为零，所以 $I(X; Y) = 0$。\n结合这些事实，我们得到 $I(X; Z) \\le 0$。由于互信息总是非负的 ($I(X;Z) \\ge 0$)，唯一可能的值是 $I(X; Z) = 0$。\n\n两种方法都得到相同的结果。过程状态 $X$ 和汇总统计量 $Z$ 之间的互信息是 0 比特。", "answer": "$$\\boxed{0}$$", "id": "1613376"}, {"introduction": "接下来，我们探讨当数据处理过程可逆时会发生什么。这个练习 [@problem_id:1613402] 以常见的图像压缩为例，展示了数据处理不等式的一个关键特例。它表明，无损处理（允许完美重建数据）不会导致互信息的任何损失，从而达成等式$I(X; Z) = I(X; Y)$。", "problem": "考虑一个涉及大型数字照片的数据处理流水线。原始的、未压缩的图像数据由一个离散随机变量 $X$ 表示。\n\n首先，使用*有损*压缩算法将此原始图像转换为更常见的格式。此过程会永久性地丢弃部分原始图像信息以减小文件大小。这个新的、经过有损压缩的图像的数据由一个随机变量 $Y$ 表示。因为此步骤是有损的，所以无法从 $Y$ 中完美恢复原始数据 $X$。\n\n其次，使用*无损*数据压缩算法（例如常用于 ZIP 存档的 Lempel-Ziv 算法）对与 $Y$ 对应的文件进行进一步压缩。这将生成一个由随机变量 $Z$ 表示的最终文件。这第二步是完全可逆的，意味着可以从数据 $Z$ 中精确地重建数据 $Y$，而没有任何信息损失。\n\n令 $I(A; B)$ 表示两个随机变量 $A$ 和 $B$ 之间的互信息。鉴于这个两步过程，互信息 $I(X; Y)$ 和互信息 $I(X; Z)$ 之间保证成立的最具体关系是什么？\n\nA. $I(X; Y)  I(X; Z)$\n\nB. $I(X; Y)  I(X; Z)$\n\nC. $I(X; Y) = I(X; Z)$\n\nD. $I(X; Y) \\ge I(X; Z)$\n\nE. 根据给定信息无法确定其关系。", "solution": "令 $X$ 表示原始图像数据，$Y$ 表示有损压缩后的图像，$Z$ 表示对 $Y$ 进行无损压缩后的版本。该处理链意味着一个马尔可夫链 $X \\to Y \\to Z$，因为 $Z$ 仅通过 $Y$ 依赖于 $X$。由于第二步是无损且完全可逆的，因此存在一个双射 $f$，使得 $Z=f(Y)$ 并且 $Y=f^{-1}(Z)$。因此 $Y$ 是 $Z$ 的确定性函数，并且 $Z$ 是 $Y$ 的确定性函数。\n\n对马尔可夫链 $X \\to Y \\to Z$（其中 $Z=f(Y)$）使用数据处理不等式，我们得到\n$$\nI(X;Z) \\le I(X;Y).\n$$\n因为 $Y=f^{-1}(Z)$，我们​​也得到了一个反向的马尔可夫链 $X \\to Z \\to Y$，这给出\n$$\nI(X;Y) \\le I(X;Z).\n$$\n结合这两个不等式可得\n$$\nI(X;Y) = I(X;Z).\n$$\n\n等价地，使用定义 $I(X;Y)=H(X)-H(X|Y)$ 和 $I(X;Z)=H(X)-H(X|Z)$，并注意到 $Z$ 和 $Y$ 是双射相关的，因此以 $Z$ 为条件等价于以 $Y$ 为条件。形式上，由于 $Z=f(Y)$ 且 $Y=f^{-1}(Z)$，\n$$\nH(X|Z) = H\\bigl(X \\mid f^{-1}(Z)\\bigr) = H(X|Y),\n$$\n这直接得出\n$$\nI(X;Z) = H(X) - H(X|Z) = H(X) - H(X|Y) = I(X;Y).\n$$\n\n因此，保证成立的最具体关系是相等。", "answer": "$$\\boxed{C}$$", "id": "1613402"}, {"introduction": "最后，我们来考察最常见的情况：不可逆的“有损”处理。通过一个两阶段噪声信道的具体例子 [@problem_id:1613411]，这个练习展示了信息不仅可能被削弱，甚至可能被完全摧毁。这突显了数据处理不等式中的严格不等关系$I(X;Z) \\lt I(X;Y)$，并强化了其核心主旨，即数据处理通常会导致信息退化。", "problem": "考虑一个简化的两级数字通信系统模型。一个信源产生二进制信号 $X$，其值可以为 0 或 1。信源的先验概率分布是对称的，即 $P(X=0) = P(X=1) = 1/2$。\n\n信号 $X$ 首先通过一个噪声信道传输到一个中间节点，产生信号 $Y \\in \\{0, 1\\}$。该信道是一个交叉概率为 $\\epsilon = 1/3$ 的二进制对称信道。这意味着比特翻转的概率为 $P(Y \\neq x | X = x) = 1/3$。\n\n信号 $Y$ 随后由中间节点处理并重新传输到最终目的地，产生信号 $Z \\in \\{+, -\\}$。这第二级也是一个噪声信道，其由以下条件概率决定：\n- $P(Z = + | Y = 0) = 1/4$\n- $P(Z = + | Y = 1) = 1/4$\n\n整个过程构成一个马尔可夫链 $X \\rightarrow Y \\rightarrow Z$。\n\n计算原始信号与中间信号之间的互信息 $I(X;Y)$，以及原始信号与最终信号之间的互信息 $I(X;Z)$。请用比特（bits）表示互信息的答案。你的最终答案应该是一个行矩阵，按顺序包含 $I(X;Y)$ 和 $I(X;Z)$ 的值。", "solution": "我们给定一个马尔可夫链 $X \\rightarrow Y \\rightarrow Z$，其中 $X \\in \\{0,1\\}$，$P(X=0)=P(X=1)=\\frac{1}{2}$，第一级是一个交叉概率为 $\\epsilon=\\frac{1}{3}$ 的二进制对称信道（BSC），第二级中 $P(Z=+ \\mid Y=0)=P(Z=+ \\mid Y=1)=\\frac{1}{4}$。\n\n首先，计算 $I(X;Y)$。根据定义，$I(X;Y)=H(Y)-H(Y \\mid X)$。\n\n对于 $\\epsilon=\\frac{1}{3}$ 且输入对称的 BSC，给定 $X=x$ 时 $Y$ 的条件分布为 $P(Y=x \\mid X=x)=\\frac{2}{3}$ 和 $P(Y \\neq x \\mid X=x)=\\frac{1}{3}$。$Y$ 的边缘概率为\n$$\nP(Y=0)=P(Y=0 \\mid X=0)P(X=0)+P(Y=0 \\mid X=1)P(X=1)=\\frac{2}{3}\\cdot \\frac{1}{2}+\\frac{1}{3}\\cdot \\frac{1}{2}=\\frac{1}{2},\n$$\n同样地，$P(Y=1)=\\frac{1}{2}$。因此\n$$\nH(Y)=-\\frac{1}{2}\\log_{2}\\!\\left(\\frac{1}{2}\\right)-\\frac{1}{2}\\log_{2}\\!\\left(\\frac{1}{2}\\right)=1.\n$$\n条件熵为\n$$\nH(Y \\mid X)=\\sum_{x \\in \\{0,1\\}}P(X=x)\\,H(Y \\mid X=x)=H\\!\\left(\\tfrac{2}{3},\\tfrac{1}{3}\\right)\n= -\\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right)-\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right).\n$$\n因此\n$$\nI(X;Y)=H(Y)-H(Y \\mid X)=1+\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right)+\\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right).\n$$\n\n接下来，计算 $I(X;Z)$。我们已知 $P(Z=+ \\mid Y=0)=P(Z=+ \\mid Y=1)=\\frac{1}{4}$，所以 $P(Z=- \\mid Y=0)=P(Z=- \\mid Y=1)=\\frac{3}{4}$。因此 $Z$ 的分布不依赖于 $Y$，这意味着 $Z$ 与 $Y$ 是独立的。因为 $X \\rightarrow Y \\rightarrow Z$ 是一个马尔可夫链，所以 $Z$ 也与 $X$ 独立，因此\n$$\nI(X;Z)=0.\n$$\n等价地，可以验证 $P(Z=+)=\\sum_{y}P(Z=+ \\mid Y=y)P(Y=y)=\\frac{1}{4}$ 且 $H(Z \\mid X)=H(Z)$，这也得出 $I(X;Z)=H(Z)-H(Z \\mid X)=0$。\n\n因此，以比特为单位的互信息为 $I(X;Y)=1+\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right)+\\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right)$ 和 $I(X;Z)=0$。", "answer": "$$\\boxed{\\begin{pmatrix}1+\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right)+\\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right)  0\\end{pmatrix}}$$", "id": "1613411"}]}