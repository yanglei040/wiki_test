{"hands_on_practices": [{"introduction": "我们首先通过一个基本场景来理解数据处理不等式。这个练习模拟了一个信号连续通过两个噪声信道的过程，旨在从根本上证明，对数据进行后续处理（即通过第二个信道）不会增加我们对原始信号的了解。这是理解信息在处理链中如何衰减的关键第一步 [@problem_id:1613405]。", "problem": "一个二进制信号 $X$ 来自一个分布，其中 $P(X=0) = \\alpha$ 且 $P(X=1) = 1-\\alpha$，并且 $0  \\alpha  1$。该信号通过两个级联的独立噪声信道。第一个信道是一个二进制对称信道（BSC），它以交叉概率 $p_1$ 翻转传输的比特，产生一个中间信号 $Y$。该信号 $Y$ 随后立即作为输入送入第二个独立的BSC，其交叉概率为 $p_2$，产生最终信号 $Z$。假设信道既不是完美的，也不是完全随机的，因此它们的交叉概率在范围 $0  p_1  1$ 和 $0  p_2  1$ 内。\n\n令 $I(X; Y)$ 表示信源 $X$ 和中间信号 $Y$ 之间的互信息，令 $I(X; Z)$ 表示信源 $X$ 和最终信号 $Z$ 之间的互信息。所有互信息值都以比特为单位计算。在给定条件下，对于所描述的系统，以下哪种关系是普遍成立的？\n\nA. $I(X; Z) > I(X; Y)$\n\nB. $I(X; Z) = I(X; Y)$\n\nC. $I(X; Z)  I(X; Y)$\n\nD. $I(X; Z) \\le I(X; Y)$\n\nE. $I(X; Z) \\ge I(X; Y)$", "solution": "该问题描述了一个系统，其中信号 $X$ 被处理以生成 $Y$，然后 $Y$ 被进一步处理以生成 $Z$。关键的洞察力在于认识到三个随机变量 $X$、$Y$ 和 $Z$ 之间的关系。\n\n第一个信道的输出 $Y$ 仅依赖于其输入 $X$。第二个信道的输出 $Z$ 仅依赖于其输入 $Y$。这意味着如果我们知道中间信号 $Y$，则最终信号 $Z$ 条件独立于原始信号 $X$。这种结构被称为马尔可夫链，表示为 $X \\to Y \\to Z$。这种链的联合概率分布可以分解为 $p(x, y, z) = p(x) p(y|x) p(z|y)$。\n\n我们可以使用互信息的链式法则来分析 $I(X;Y)$ 和 $I(X;Z)$ 之间的关系。$X$ 和对 $(Y, Z)$ 之间的互信息可以按两种方式展开：\n\n1.  $I(X; Y, Z) = I(X; Y) + I(X; Z|Y)$\n2.  $I(X; Y, Z) = I(X; Z) + I(X; Y|Z)$\n\n根据马尔可夫链 $X \\to Y \\to Z$ 的定义，我们知道在给定 $Y$ 的条件下，$X$ 和 $Z$ 是条件独立的。这个性质意味着条件互信息 $I(X; Z|Y)$ 为零。\n$$I(X; Z|Y) = 0$$\n\n将此结果代入第一个展开式可得：\n$$I(X; Y, Z) = I(X; Y) + 0 = I(X; Y)$$\n\n现在我们可以将 $I(X; Y, Z)$ 的两个表达式相等：\n$$I(X; Y) = I(X; Z) + I(X; Y|Z)$$\n\n互信息的一个基本性质是它总是非负的。这也适用于条件互信息。因此：\n$$I(X; Y|Z) \\ge 0$$\n\n这一项 $I(X; Y|Z)$ 表示即使在已知 $Z$ 的情况下，通过了解 $X$ 所解决的关于 $Y$ 的剩余不确定性。直观地说，它是在第二个信道中“丢失”的信息。\n\n将我们的方程与非负性相结合，我们得到：\n$$I(X; Y) \\ge I(X; Z)$$\n或等价地，\n$$I(X; Z) \\le I(X; Y)$$\n\n这个结果是信息论中一个著名的定理，称为数据处理不等式。它指出，对数据的后处理（在本例中，将 $Y$ 通过第二个BSC得到 $Z$）不能增加与原始信源 $X$ 相关的互信息。\n\n让我们基于这个不等式来分析给定的选项：\n- 选项 A ($I(X; Z) > I(X; Y)$) 和选项 E ($I(X; Z) \\ge I(X; Y)$) 是不正确的，因为它们与数据处理不等式相矛盾（除非等式成立）。\n- 选项 B ($I(X; Z) = I(X; Y)$) 并不总是成立。等式成立当且仅当 $I(X; Y|Z) = 0$。这意味着可以从 $Z$ 完全确定 $Y$。对于交叉概率为 $p_2 \\in (0, 1)$ 的BSC，从 $Y$ 到 $Z$ 的映射不是一对一的，因此通常无法从 $Z$ 中无不确定性地恢复 $Y$。例如，如果 $p_1=0.1, p_2=0.1, \\alpha=0.5$，直接计算会显示严格的不等式。\n- 选项 C ($I(X; Z)  I(X; Y)$) 也并不总是成立。虽然它在大多数非平凡情况下成立，但等式也有可能出现。例如，如果第一个信道使得 $I(X; Y) = 0$（例如，如果 $p_1=0.5$ 且 $\\alpha=0.5$），那么由于 $Z$ 是 $Y$ 的进一步处理版本，我们也必然有 $I(X; Z) = 0$。在这种情况下，$I(X; Z) = I(X; Y) = 0$。\n- 选项 D ($I(X; Z) \\le I(X; Y)$) 是唯一在指定范围内对任何 $\\alpha$、$p_1$ 和 $p_2$ 的选择都普遍成立的关系，因为它正确地捕捉了数据处理不等式，包括在特定边缘情况下等式成立的可能性。", "answer": "$$\\boxed{D}$$", "id": "1613405"}, {"introduction": "在掌握了数据处理不等式的基本概念后，我们将其应用到更具体的连续信号模型中。这个练习将引导你计算在高斯噪声信道中信号的互信息，通过量化比较来直观地展示增加噪声如何必然导致信息量的减少 [@problem_id:1613384]。这个例子将理论不等式转化为了一个可以精确计算和验证的物理现实。", "problem": "考虑一个通信系统中的简化信号级联模型。一个初始连续信号，由随机变量 $X$ 建模，是一个均值为零、方差为 $\\sigma_X^2$ 的高斯随机变量。该信号通过第一个噪声信道，该信道加入了独立的、均值为零、方差为 $\\sigma_{N_1}^2$ 的高斯噪声 $N_1$。得到的信号为 $Y = X + N_1$。然后，该信号 $Y$ 被输入到第二个信道，该信道又加入了独立的、均值为零、方差为 $\\sigma_{N_2}^2$ 的高斯噪声 $N_2$。最终的输出信号为 $Z = Y + N_2$。随机变量 $X$、$N_1$ 和 $N_2$ 相互独立。假设所有方差 $\\sigma_X^2$、$\\sigma_{N_1}^2$ 和 $\\sigma_{N_2}^2$ 都严格为正。\n\n所有的信息论量都以奈特（nats）为单位，这意味着所有的对数都是自然对数（$\\ln$）。令 $I(X;Y)$ 为原始信号 $X$ 和第一级之后信号 $Y$ 之间的互信息。令 $I(X;Z)$ 为原始信号 $X$ 和最终信号 $Z$ 之间的互信息。\n\n下列哪个陈述正确地描述了 $I(X;Y)$ 和 $I(X;Z)$ 之间的关系？\n\nA. $I(X;Y)  I(X;Z)$\n\nB. $I(X;Y) > I(X;Z)$\n\nC. $I(X;Y) = I(X;Z)$\n\nD. 在不知道方差的具体数值的情况下，无法确定它们之间的关系。\n\nE. $I(X;Y)$ 和 $I(X;Z)$ 均为无穷大。", "solution": "我们已知 $X \\sim \\mathcal{N}(0,\\sigma_{X}^{2})$、$N_{1} \\sim \\mathcal{N}(0,\\sigma_{N_{1}}^{2})$、$N_{2} \\sim \\mathcal{N}(0,\\sigma_{N_{2}}^{2})$，它们都相互独立且方差严格为正。信道模型为 $Y = X + N_{1}$ 和 $Z = Y + N_{2} = X + (N_{1}+N_{2})$。因为 $N_{1}$ 和 $N_{2}$ 是独立的高斯变量，所以 $N_{1}+N_{2} \\sim \\mathcal{N}(0,\\sigma_{N_{1}}^{2}+\\sigma_{N_{2}}^{2})$ 并且独立于 $X$。\n\n我们使用 $I(U;V) = h(V) - h(V|U)$ 以及零均值高斯变量 $W \\sim \\mathcal{N}(0,\\sigma^{2})$ 的微分熵公式 $h(W) = \\frac{1}{2} \\ln\\!\\big(2\\pi e\\,\\sigma^{2}\\big)$ 来计算互信息。\n\n第一级：\n- $Y = X + N_{1}$ 是高斯变量，其方差为 $\\sigma_{X}^{2} + \\sigma_{N_{1}}^{2}$，所以\n$$\nh(Y) = \\frac{1}{2} \\ln\\!\\big(2\\pi e\\,(\\sigma_{X}^{2} + \\sigma_{N_{1}}^{2})\\big).\n$$\n- 给定 $X$，$Y|X = X + N_{1}$ 与 $N_{1}$ 具有相同的分布，所以\n$$\nh(Y|X) = h(N_{1}) = \\frac{1}{2} \\ln\\!\\big(2\\pi e\\,\\sigma_{N_{1}}^{2}\\big).\n$$\n因此\n$$\nI(X;Y) = h(Y) - h(Y|X) = \\frac{1}{2} \\ln\\!\\left(\\frac{\\sigma_{X}^{2} + \\sigma_{N_{1}}^{2}}{\\sigma_{N_{1}}^{2}}\\right) = \\frac{1}{2} \\ln\\!\\left(1 + \\frac{\\sigma_{X}^{2}}{\\sigma_{N_{1}}^{2}}\\right).\n$$\n\n第二级：\n- $Z = X + (N_{1}+N_{2})$ 是高斯变量，其方差为 $\\sigma_{X}^{2} + \\sigma_{N_{1}}^{2} + \\sigma_{N_{2}}^{2}$，所以\n$$\nh(Z) = \\frac{1}{2} \\ln\\!\\big(2\\pi e\\,(\\sigma_{X}^{2} + \\sigma_{N_{1}}^{2} + \\sigma_{N_{2}}^{2})\\big).\n$$\n- 给定 $X$，$Z|X$ 与 $N_{1}+N_{2}$ 具有相同的分布，所以\n$$\nh(Z|X) = h(N_{1}+N_{2}) = \\frac{1}{2} \\ln\\!\\big(2\\pi e\\,(\\sigma_{N_{1}}^{2} + \\sigma_{N_{2}}^{2})\\big).\n$$\n因此\n$$\nI(X;Z) = h(Z) - h(Z|X) = \\frac{1}{2} \\ln\\!\\left(\\frac{\\sigma_{X}^{2} + \\sigma_{N_{1}}^{2} + \\sigma_{N_{2}}^{2}}{\\sigma_{N_{1}}^{2} + \\sigma_{N_{2}}^{2}}\\right) = \\frac{1}{2} \\ln\\!\\left(1 + \\frac{\\sigma_{X}^{2}}{\\sigma_{N_{1}}^{2} + \\sigma_{N_{2}}^{2}}\\right).\n$$\n\n比较：\n因为 $\\sigma_{N_{2}}^{2} > 0$，我们有 $\\sigma_{N_{1}}^{2} + \\sigma_{N_{2}}^{2} > \\sigma_{N_{1}}^{2}$，这意味着\n$$\n\\frac{\\sigma_{X}^{2}}{\\sigma_{N_{1}}^{2} + \\sigma_{N_{2}}^{2}}  \\frac{\\sigma_{X}^{2}}{\\sigma_{N_{1}}^{2}}.\n$$\n因为 $\\ln$ 函数是严格单调递增的，\n$$\n\\frac{1}{2} \\ln\\!\\left(1 + \\frac{\\sigma_{X}^{2}}{\\sigma_{N_{1}}^{2} + \\sigma_{N_{2}}^{2}}\\right)  \\frac{1}{2} \\ln\\!\\left(1 + \\frac{\\sigma_{X}^{2}}{\\sigma_{N_{1}}^{2}}\\right),\n$$\n所以 $I(X;Z)  I(X;Y)$。\n\n这也与马尔可夫链 $X \\to Y \\to Z$ 的数据处理不等式相符，该不等式保证了 $I(X;Z) \\leq I(X;Y)$；此处严格不等式成立，因为在第二级中加入了额外的独立高斯噪声，并且所有方差都严格为正。\n\n因此，正确选项是 B。", "answer": "$$\\boxed{B}$$", "id": "1613384"}, {"introduction": "为了进一步深化理解，我们来探讨一个有趣的极端情况。这个练习要求我们构建一个特定的两阶段系统，其中第二阶段的处理会完全抹除关于原始信号的所有信息 [@problem_id:1613411]。通过解决这个问题，你将亲身体会到信息是如何在处理过程中被“销毁”的，并理解数据处理不等式中严格不等的深刻含义。", "problem": "考虑一个简化的两级数字通信系统模型。一个信源产生二元信号 $X$，其取值可以为 0 或 1。信源的先验概率分布是对称的，即 $P(X=0) = P(X=1) = 1/2$。\n\n信号 $X$ 首先通过一个噪声信道传输到一个中间节点，产生信号 $Y \\in \\{0, 1\\}$。该信道是一个二元对称信道，其交叉概率为 $\\epsilon = 1/3$。这意味着比特翻转的概率为 $P(Y \\neq x | X = x) = 1/3$。\n\n信号 $Y$ 随后由中间节点处理并重新传输到最终目的地，产生信号 $Z \\in \\{+, -\\}$。这第二级也是一个噪声信道，由以下条件概率决定：\n- $P(Z = + | Y = 0) = 1/4$\n- $P(Z = + | Y = 1) = 1/4$\n\n整个过程形成一个马尔可夫链 $X \\rightarrow Y \\rightarrow Z$。\n\n计算原始信号与中间信号之间的互信息 $I(X;Y)$，以及原始信号与最终信号之间的互信息 $I(X;Z)$。用比特表示您的互信息答案。您的最终答案应该是一个行矩阵，按顺序包含 $I(X;Y)$ 和 $I(X;Z)$ 的值。", "solution": "我们给定一个马尔可夫链 $X \\rightarrow Y \\rightarrow Z$，其中 $X \\in \\{0,1\\}$，$P(X=0)=P(X=1)=\\frac{1}{2}$，第一级是一个交叉概率为 $\\epsilon=\\frac{1}{3}$ 的二元对称信道（BSC），第二级中 $P(Z=+ \\mid Y=0)=P(Z=+ \\mid Y=1)=\\frac{1}{4}$。\n\n首先，计算 $I(X;Y)$。根据定义，$I(X;Y)=H(Y)-H(Y \\mid X)$。\n\n对于交叉概率为 $\\epsilon=\\frac{1}{3}$ 且输入对称的 BSC，给定 $X=x$ 时 $Y$ 的条件分布为 $P(Y=x \\mid X=x)=\\frac{2}{3}$ 和 $P(Y \\neq x \\mid X=x)=\\frac{1}{3}$。$Y$ 的边缘分布是\n$$\nP(Y=0)=P(Y=0 \\mid X=0)P(X=0)+P(Y=0 \\mid X=1)P(X=1)=\\frac{2}{3}\\cdot \\frac{1}{2}+\\frac{1}{3}\\cdot \\frac{1}{2}=\\frac{1}{2},\n$$\n类似地 $P(Y=1)=\\frac{1}{2}$。因此\n$$\nH(Y)=-\\frac{1}{2}\\log_{2}\\!\\left(\\frac{1}{2}\\right)-\\frac{1}{2}\\log_{2}\\!\\left(\\frac{1}{2}\\right)=1.\n$$\n条件熵为\n$$\nH(Y \\mid X)=\\sum_{x \\in \\{0,1\\}}P(X=x)\\,H(Y \\mid X=x)=H_{2}\\!\\left(\\frac{1}{3}\\right)\n= -\\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right)-\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right).\n$$\n因此\n$$\nI(X;Y)=H(Y)-H(Y \\mid X)=1+\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right)+\\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right).\n$$\n\n接下来，计算 $I(X;Z)$。我们给定 $P(Z=+ \\mid Y=0)=P(Z=+ \\mid Y=1)=\\frac{1}{4}$，所以 $P(Z=- \\mid Y=0)=P(Z=- \\mid Y=1)=\\frac{3}{4}$。因此 $Z$ 的分布不依赖于 $Y$，这意味着 $Z$ 与 $Y$ 独立。由于 $X \\rightarrow Y \\rightarrow Z$ 是一个马尔可夫链， $Z$ 也与 $X$ 独立，因此\n$$\nI(X;Z)=0.\n$$\n等价地，可以验证 $P(Z=+)=\\sum_{y}P(Z=+ \\mid Y=y)P(Y=y)=\\frac{1}{4}$ 并且 $H(Z \\mid X)=H(Z)$，这再次得出 $I(X;Z)=H(Z)-H(Z \\mid X)=0$。\n\n因此，以比特为单位的互信息为 $I(X;Y)=1+\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right)+\\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right)$ 和 $I(X;Z)=0$。\n\n在解题过程中，$H(Y \\mid X)$ 计算有误，应为：\n$H(Y|X) = H_2(1/3) = -(1/3)\\log_2(1/3)-(2/3)\\log_2(2/3)$\n$I(X;Y) = H(Y) - H(Y|X) = 1 - (-(1/3)\\log_2(1/3)-(2/3)\\log_2(2/3)) = 1 + (1/3)\\log_2(1/3) + (2/3)\\log_2(2/3)$\n原解答中的公式是正确的，但在$H(Y \\mid X)$的表达式中，混淆了$H(Y \\mid X=x)$和$H(Y \\mid X)$。对于对称输入BSC，$H(Y \\mid X)$等于$H_2(\\epsilon)$。\n$H_2(\\epsilon) = -\\epsilon \\log_2(\\epsilon) - (1-\\epsilon)\\log_2(1-\\epsilon)$\n对于 $\\epsilon=1/3$, $H_2(1/3) = -1/3\\log_2(1/3) - 2/3\\log_2(2/3)$.\n$I(X;Y) = 1 - H_2(1/3) = 1 - (-1/3\\log_2(1/3) - 2/3\\log_2(2/3)) = 1+1/3\\log_2(1/3)+2/3\\log_2(2/3)$.\n原解答中将 $H(Y \\mid X)$ 写作 $H(2/3, 1/3)$，并展开为 $-(2/3)\\log_2(2/3)-(1/3)\\log_2(1/3)$，这与标准二进制熵函数的定义一致。因此，最终$I(X;Y)$的表达式是正确的。\n\n最终答案中的$I(X;Y)$表达式是正确的。\n$I(X;Y) = 1 - H_2(1/3) \\approx 1 - 0.918 = 0.082$ 比特。", "answer": "$$\\boxed{\\begin{pmatrix}1+\\frac{1}{3}\\log_{2}\\!\\left(\\frac{1}{3}\\right)+\\frac{2}{3}\\log_{2}\\!\\left(\\frac{2}{3}\\right)  0\\end{pmatrix}}$$", "id": "1613411"}]}