{"hands_on_practices": [{"introduction": "理论是抽象的，但实践使其变得具体。要真正理解典型集，最好的方法就是亲自动手检验一个序列是否具有典型性。下面的练习将指导你计算一个给定序列的样本熵，并将其与信源的真实熵进行比较，从而判断它是否属于典型集。", "problem": "在数据压缩的研究中，一个基本概念是“典型集”（typical set），它包含对于一个随机信源而言“统计上具有代表性”的序列。考虑一个生成比特（'0' 或 '1'）序列的无记忆二进制信源。发出 '0' 的概率为 $P(0) = \\frac{1}{4}$，发出 '1' 的概率为 $P(1) = \\frac{3}{4}$。\n\n该信源的香农熵（Shannon entropy），记作 $H(X)$，量化了每个符号的平均不确定性，由以下公式给出：\n$$H(X) = -P(0) \\log_2(P(0)) - P(1) \\log_2(P(1))$$\n\n对于一个长度为 $n$ 的特定输出序列 $\\mathbf{x}$，我们可以定义其样本熵（sample entropy），$H(\\mathbf{x})$，为：\n$$H(\\mathbf{x}) = -\\frac{1}{n} \\log_2(P(\\mathbf{x}))$$\n其中 $P(\\mathbf{x})$ 是观测到该特定序列的概率。\n\n对于给定的容差 $\\epsilon > 0$，如果一个序列 $\\mathbf{x}$ 的样本熵与真实信源熵足够接近，满足条件：\n$$|H(\\mathbf{x}) - H(X)| \\le \\epsilon$$\n则称该序列属于典型集 $A_\\epsilon^{(n)}$。\n\n假设信源发出了以下长度为 $n=8$ 的序列：\n$$\\mathbf{x} = 01101011$$\n使用容差 $\\epsilon = 0.2$，计算此序列的样本熵 $H(\\mathbf{x})$，并判断它是否属于典型集 $A_{0.2}^{(8)}$。下列哪个陈述是正确的？\n\nA. 样本熵为 $2 - \\frac{3}{4}\\log_2(3)$，且该序列属于典型集。\n\nB. 样本熵为 $2 - \\frac{5}{8}\\log_2(3)$，且该序列属于典型集。\n\nC. 样本熵为 $2 - \\frac{5}{8}\\log_2(3)$，且该序列不属于典型集。\n\nD. 样本熵为 $\\frac{1}{8}\\log_2(3)$，且该序列不属于典型集。\n\nE. 样本熵为 $2 - \\frac{3}{4}\\log_2(3)$，且该序列不属于典型集。", "solution": "该信源是无记忆的，且 $P(0)=\\frac{1}{4}$，$P(1)=\\frac{3}{4}$。对于长度为 $n=8$ 的序列 $\\mathbf{x}=01101011$，'1' 的数量为 $k=5$，'0' 的数量为 $n-k=3$。根据无记忆性，\n$$\nP(\\mathbf{x})=\\left(\\frac{3}{4}\\right)^{5}\\left(\\frac{1}{4}\\right)^{3}.\n$$\n样本熵为\n$$\nH(\\mathbf{x})=-\\frac{1}{8}\\log_{2}P(\\mathbf{x})=-\\frac{1}{8}\\left[5\\log_{2}\\left(\\frac{3}{4}\\right)+3\\log_{2}\\left(\\frac{1}{4}\\right)\\right].\n$$\n使用 $\\log_{2}\\left(\\frac{3}{4}\\right)=\\log_{2}3-2$ 和 $\\log_{2}\\left(\\frac{1}{4}\\right)=-2$，我们得到\n$$\nH(\\mathbf{x})=-\\frac{1}{8}\\left[5(\\log_{2}3-2)+3(-2)\\right]\n=-\\frac{1}{8}\\left(5\\log_{2}3-16\\right)\n=2-\\frac{5}{8}\\log_{2}3.\n$$\n信源熵为\n$$\nH(X)=-\\frac{1}{4}\\log_{2}\\left(\\frac{1}{4}\\right)-\\frac{3}{4}\\log_{2}\\left(\\frac{3}{4}\\right)\n=2-\\frac{3}{4}\\log_{2}3.\n$$\n因此，\n$$\n|H(\\mathbf{x})-H(X)|=\\left|2-\\frac{5}{8}\\log_{2}3-\\left(2-\\frac{3}{4}\\log_{2}3\\right)\\right|\n=\\left(\\frac{3}{4}-\\frac{5}{8}\\right)\\log_{2}3=\\frac{1}{8}\\log_{2}3.\n$$\n我们将此值与 $\\epsilon=0.2=\\frac{1}{5}$ 进行比较。不等式\n$$\n\\frac{1}{8}\\log_{2}3\\le\\frac{1}{5}\n$$\n等价于 $\\log_{2}3\\le\\frac{8}{5}$，即 $3\\le 2^{8/5}$。将两边同时取五次方，得到 $3^{5}\\le 2^{8}$。因为 $3^5=243$ 且 $2^8=256$，所以 $243  256$ 是成立的。这意味着 $\\frac{1}{8}\\log_2 3  \\frac{1}{5}$ 也成立，因此该序列满足典型性条件，属于典型集 $A_{0.2}^{(8)}$。\n\n综上所述，样本熵为 $2-\\frac{5}{8}\\log_{2}3$，且该序列是典型的。正确选项是 B。", "answer": "$$\\boxed{B}$$", "id": "1648667"}, {"introduction": "确认了单个序列的典型性后，一个自然而然的问题是：这样的典型序列有多少？这个问题引出了渐近均分特性（AEP）的核心思想。本练习将让你估算典型集的大小，你会发现，尽管可能序列的总数是天文数字，但典型序列的数量相对而言要小得多，这正是数据压缩得以实现的理论基石。", "problem": "在信息论中，渐近均分特性（Asymptotic Equipartition Property, AEP）为表征长随机变量序列的行为提供了一种强有力的方法。对于熵为 $H(X)$ 的离散无记忆信源，长度为 $n$ 的“典型”序列集合（记为 $A_{\\epsilon}^{(n)}$）包含其经验熵接近真实熵的序列。AEP 确立了对于任意 $\\epsilon > 0$，此集合中的序列数量 $|A_{\\epsilon}^{(n)}|$ 存在一个最大可能值，由上界 $2^{n(H(X) + \\epsilon)}$ 给出，其中熵 $H(X)$ 以比特（bits）为单位度量。\n\n考虑一个信源，其模型为掷一个均匀的六面骰子一次的结果。我们观测到来自该信源的一个长度为 $n=100$ 的独立同分布结果序列。对于选定的偏差参数 $\\epsilon = 0.1$，计算典型集 $A_{\\epsilon}^{(n)}$ 中序列的最大可能数量。\n\n在计算中，请使用以下常数：\n$\\ln(2) = 0.6931$\n$\\ln(6) = 1.7918$\n$\\log_{10}(2) = 0.3010$\n\n将最终答案以科学记数法表示，并四舍五入至三位有效数字。", "solution": "我们使用渐近均分特性（AEP）为独立同分布（i.i.d.）离散无记忆信源的典型集基数提供的上界：\n$$\n|A_{\\epsilon}^{(n)}| \\leq 2^{n \\left(H(X)+\\epsilon\\right)}.\n$$\n对于一个均匀的六面骰子，其熵（以比特为单位）为\n$$\nH(X) = -\\sum_{i=1}^{6} \\frac{1}{6} \\log_{2}\\left(\\frac{1}{6}\\right) = \\log_{2}(6).\n$$\n当 $n=100$ 且 $\\epsilon=0.1$ 时，最大数量因此为\n$$\n|A_{\\epsilon}^{(n)}|_{\\max} = 2^{100\\left(\\log_{2}(6)+0.1\\right)}.\n$$\n为将其表示为科学记数法，使用 $2^{y} = 10^{y \\log_{10}(2)}$ 转换为以 10 为底：\n$$\n|A_{\\epsilon}^{(n)}|_{\\max} = 10^{100\\left(\\log_{2}(6)+0.1\\right)\\log_{10}(2)}.\n$$\n使用所给的自然对数计算 $\\log_{2}(6)$：\n$$\n\\log_{2}(6) = \\frac{\\ln(6)}{\\ln(2)} = \\frac{1.7918}{0.6931} \\approx 2.5852.\n$$\n接着\n$$\n100\\left(\\log_{2}(6)+0.1\\right) = 100\\left(2.5852+0.1\\right) = 268.52,\n$$\n于是以 10 为底的指数变为\n$$\nb = 268.52 \\cdot \\log_{10}(2) = 268.52 \\cdot 0.3010 = 80.82452.\n$$\n因此\n$$\n|A_{\\epsilon}^{(n)}|_{\\max} = 10^{80.82452} = 10^{0.82452} \\times 10^{80}.\n$$\n现在计算尾数 $10^{0.82452}$。直接计算可得 $10^{0.82452} \\approx 6.6768$。\n或者，使用题目提供的常数进行估算：\n$$\n10^{0.82452} = 2^{\\frac{0.82452}{0.3010}} \\approx 2^{2.73927} = 4 \\cdot 2^{0.73927} = 4 \\cdot \\exp\\!\\left(0.73927 \\ln(2)\\right).\n$$\n已知 $\\ln(2)=0.6931$，\n$$\n0.73927 \\ln(2) \\approx 0.73927 \\cdot 0.6931 \\approx 0.51239,\n$$\n使用泰勒级数近似 $\\exp(x) \\approx 1+x+x^2/2! + \\dots$ 给出\n$$\n\\exp(0.51239) \\approx 1 + 0.51239 + \\frac{0.51239^{2}}{2} + \\frac{0.51239^{3}}{6} + \\dots \\approx 1.6692.\n$$\n因此，\n$$\n10^{0.82452} \\approx 4 \\times 1.6692 \\approx 6.6768.\n$$\n四舍五入到三位有效数字，我们得到 $6.68$。\n因此，\n$$\n|A_{\\epsilon}^{(n)}|_{\\max} \\approx 6.68 \\times 10^{80}.\n$$", "answer": "$$\\boxed{6.68 \\times 10^{80}}$$", "id": "1648656"}, {"introduction": "现在，我们将所有概念融会贯通。我们已经知道什么是典型序列，也了解了典型集的规模。那么，我们如何利用这些知识来设计一个高效的编码方案呢？本练习将引导你分析一个基于典型集划分的编码策略的性能。通过推导其期望码长，你将亲眼见证平均码长是如何逼近信源熵这一理论极限的，从而直观地理解香non信源编码定理的精髓。", "problem": "正在为一个离散无记忆信源 (DMS) 设计一个数据压缩系统。该信源从一个大小为 $|\\mathcal{X}|$ 的有限字母表 $\\mathcal{X}$ 中产生符号，其已知熵为每个符号 $H(X)$ 比特。该系统采用分组编码策略，每次对 $n$ 个符号的序列进行编码，其中 $n$ 是一个大整数。\n\n编码算法根据一个小的正常数 $\\epsilon$ 将所有可能的长度为 $n$ 的信源序列 $x^n$ 划分为两组：一个“典型集” $A_{\\epsilon}^{(n)}$ 和一个“非典型集”。分配给序列 $x^n$ 的二进制码字的长度记为 $L(x^n)$。\n\n码字长度按如下方式分配：\n- 对于典型集中的任何序列 ($x^n \\in A_{\\epsilon}^{(n)}$)，分配的码字长度为 $L_{typ} = \\lceil n(H(X) + \\epsilon) \\rceil$ 比特。\n- 对于非典型集中的任何序列 ($x^n \\notin A_{\\epsilon}^{(n)}$)，分配的码字长度为恒定长度 $L_{non\\_typ} = B$ 比特，其中 $B$ 是一个大于 $L_{typ}$ 的固定整数。\n\n令 $P_{nt}$ 表示非典型集的总概率，即 $P_{nt} = P(X^n \\notin A_{\\epsilon}^{(n)})$。为了代数简化，假设 $n$ 足够大，使得向上取整函数可以用其参数来近似，即 $\\lceil z \\rceil \\approx z$。\n\n推导每个信源符号的期望码字长度 $\\bar{L} = \\frac{1}{n} E[L(X^n)]$ 的解析表达式。用 $H(X)$, $\\epsilon$, $P_{nt}$, $n$ 和 $B$ 来表示你的答案。", "solution": "长度为 $n$ 的序列的期望码字长度，记为 $E[L(X^n)]$，是通过对每个可能序列的码字长度 $L(x^n)$ 按其出现概率 $p(x^n)$ 进行加权求和来计算的。该求和是对信源字母表空间 $\\mathcal{X}^n$ 中所有可能的序列 $x^n$ 进行的。\n$$ E[L(X^n)] = \\sum_{x^n \\in \\mathcal{X}^n} p(x^n) L(x^n) $$\n我们可以将这个求和分成两部分：一部分是对典型集 $A_{\\epsilon}^{(n)}$ 的求和，另一部分是对非典型集（即 $A_{\\epsilon}^{(n)}$ 的补集）的求和。\n$$ E[L(X^n)] = \\sum_{x^n \\in A_{\\epsilon}^{(n)}} p(x^n) L(x^n) + \\sum_{x^n \\notin A_{\\epsilon}^{(n)}} p(x^n) L(x^n) $$\n根据问题描述，码字长度在每个集合内是恒定的。对于所有典型序列，$L(x^n) = L_{typ} = \\lceil n(H(X) + \\epsilon) \\rceil$。对于所有非典型序列，$L(x^n) = L_{non\\_typ} = B$。因此，我们可以将这些恒定的长度从求和中提取出来。\n$$ E[L(X^n)] = L_{typ} \\sum_{x^n \\in A_{\\epsilon}^{(n)}} p(x^n) + L_{non\\_typ} \\sum_{x^n \\notin A_{\\epsilon}^{(n)}} p(x^n) $$\n根据定义，这些概率之和分别是序列属于典型集和非典型集的总概率。\n$$ \\sum_{x^n \\in A_{\\epsilon}^{(n)}} p(x^n) = P(X^n \\in A_{\\epsilon}^{(n)}) $$\n$$ \\sum_{x^n \\notin A_{\\epsilon}^{(n)}} p(x^n) = P(X^n \\notin A_{\\epsilon}^{(n)}) = P_{nt} $$\n由于这两个集合是互补的，属于典型集的概率是 $P(X^n \\in A_{\\epsilon}^{(n)}) = 1 - P(X^n \\notin A_{\\epsilon}^{(n)}) = 1 - P_{nt}$。\n将这些概率和码字长度的定义代回到期望长度的表达式中，我们得到：\n$$ E[L(X^n)] = \\lceil n(H(X) + \\epsilon) \\rceil (1 - P_{nt}) + B \\cdot P_{nt} $$\n问题说明当 $n$ 很大时使用近似 $\\lceil z \\rceil \\approx z$。将此应用于第一项，我们有：\n$$ E[L(X^n)] \\approx n(H(X) + \\epsilon)(1 - P_{nt}) + B \\cdot P_{nt} $$\n问题要求的是每个信源符号的期望码字长度 $\\bar{L}$，这通过将总期望长度除以分组大小 $n$ 来获得。\n$$ \\bar{L} = \\frac{E[L(X^n)]}{n} \\approx \\frac{n(H(X) + \\epsilon)(1 - P_{nt}) + B \\cdot P_{nt}}{n} $$\n我们可以分开各项来简化表达式：\n$$ \\bar{L} \\approx \\frac{n(H(X) + \\epsilon)(1 - P_{nt})}{n} + \\frac{B \\cdot P_{nt}}{n} $$\n$$ \\bar{L} \\approx (H(X) + \\epsilon)(1 - P_{nt}) + \\frac{B}{n} P_{nt} $$\n这就是给定近似条件下每个信源符号的期望码字长度的最终表达式。", "answer": "$$\\boxed{(H(X) + \\epsilon)(1 - P_{nt}) + \\frac{B}{n} P_{nt}}$$", "id": "1648687"}]}