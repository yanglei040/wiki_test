{"hands_on_practices": [{"introduction": "我们从一个基础练习开始，这个练习将帮助我们理解信道容量的核心概念。此问题涉及一个确定性信道，即输出完全由输入决定，没有任何随机性。通过解决这个问题[@problem_id:1609635]，你将学会一个关键思想：对于确定性信道，信道容量的计算简化为寻找一种输入概率分布，以最大化输出的熵$H(Y)$。", "problem": "一个专门的数字通信系统被设计用于传输关于单个十进制数字的信息。该信道的输入是一个随机变量 $X$，它可以取集合 $\\mathcal{X} = \\{0, 1, 2, 3, 4, 5, 6, 7, 8, 9\\}$ 中的任何整数值。该信道确定性地将输入数字 $X$ 映射到一个二进制输出 $Y \\in \\{0, 1\\}$。映射规则如下：如果输入数字 $X$ 是偶数，则输出为 $Y=0$；如果输入数字 $X$ 是奇数，则输出为 $Y=1$。计算该通信信道的容量。你的最终答案请用比特表示。", "solution": "该信道确定性地将每个输入数字 $X \\in \\{0,1,\\dots,9\\}$ 映射到其奇偶性：对于偶数 $X$，输出 $Y=0$；对于奇数 $X$，输出 $Y=1$。离散无记忆信道的容量定义为\n$$\nC=\\max_{p(x)} I(X;Y).\n$$\n对于确定性信道 $Y=f(X)$，条件熵满足 $H(Y|X)=0$，因此\n$$\nI(X;Y)=H(Y)-H(Y|X)=H(Y).\n$$\n因此，\n$$\nC=\\max_{p(x)} H(Y).\n$$\n令 $p \\triangleq \\Pr(Y=1)$ 表示分配给奇数数字的总输入概率质量。因为我们可以任意选择这十个数字的输入分布，所以通过相应地在五个奇数和五个偶数之间分配总概率质量，可以实现任何 $p \\in [0,1]$。因此 $Y$ 是一个参数为 $p$ 的伯努利随机变量，且\n$$\nH(Y)=-p \\log_{2}(p) - (1-p) \\log_{2}(1-p).\n$$\n为了在 $p \\in [0,1]$ 上最大化 $H(Y)$，我们求导：\n$$\n\\frac{d}{dp}H(Y)=\\log_{2}\\!\\left(\\frac{1-p}{p}\\right).\n$$\n令导数为零可得 $\\log_{2}\\!\\left(\\frac{1-p}{p}\\right)=0$，因此 $\\frac{1-p}{p}=1$ 且 $p=\\frac{1}{2}$。二阶导数为\n$$\n\\frac{d^{2}}{dp^{2}}H(Y)=-\\frac{1}{\\ln(2)}\\left(\\frac{1}{p}+\\frac{1}{1-p}\\right)  0 \\quad \\text{for } p \\in (0,1),\n$$\n所以 $p=\\frac{1}{2}$ 是最大值点。在 $p=\\frac{1}{2}$ 处求值，\n$$\nH(Y)=-\\frac{1}{2}\\log_{2}\\!\\left(\\frac{1}{2}\\right)-\\frac{1}{2}\\log_{2}\\!\\left(\\frac{1}{2}\\right)=1.\n$$\n因此信道容量是 $1$ 比特。", "answer": "$$\\boxed{1}$$", "id": "1609635"}, {"introduction": "在掌握了基础确定性信道的概念后，我们来处理一个输出符号更多的场景。这个问题[@problem_id:1609652]同样是一个确定性信道，但它的输出不再是简单的二进制，而是有三个可能的值。这个练习旨在强调，信道容量的上限由信道能够产生的不同输出结果的数量决定，即输出字母表的大小$|\\mathcal{Y}|$。", "problem": "考虑一个作为通信信道的专用数字处理单元。该单元接受来自集合 $\\mathcal{X} = \\{1, 2, 3, 4, 5, 6\\}$ 的整数输入 $X$。该单元的输出（记为 $Y$）由输入 $X$ 除以 3 的余数确定。也就是说，变换由规则 $Y = X \\pmod{3}$ 给出。\n\n该信道的容量（记为 $C$）定义为在输入集合 $\\mathcal{X}$ 上所有可能的概率分布下，互信息 $I(X;Y)$ 的最大值。\n\n确定该信道的容量 $C$。请用单位为“比特/信道使用”的封闭形式解析表达式表示您的最终答案。", "solution": "该信道从 $\\mathcal{X}=\\{1,2,3,4,5,6\\}$ 中获取输入，并输出 $Y=X \\bmod 3$。因此，输出字母表为 $\\mathcal{Y}=\\{0,1,2\\}$，其原像为\n$$\n\\{y=0\\}=\\{3,6\\},\\quad \\{y=1\\}=\\{1,4\\},\\quad \\{y=2\\}=\\{2,5\\}.\n$$\n该信道是确定性的，因此对于任何输入分布 $p_{X}$，我们都有 $H(Y\\mid X)=0$，互信息简化为\n$$\nI(X;Y)=H(Y)-H(Y\\mid X)=H(Y).\n$$\n因此，容量为\n$$\nC=\\max_{p_{X}} I(X;Y)=\\max_{p_{X}} H(Y).\n$$\n令 $p_{X}(i)$ 表示 $i\\in\\{1,2,3,4,5,6\\}$ 的输入概率，令 $p_{Y}(y)$ 表示导出的输出分布。根据映射关系，\n$$\np_{Y}(0)=p_{X}(3)+p_{X}(6),\\quad p_{Y}(1)=p_{X}(1)+p_{X}(4),\\quad p_{Y}(2)=p_{X}(2)+p_{X}(5).\n$$\n对于 $\\{0,1,2\\}$ 上的任何目标分布 $(q_{0},q_{1},q_{2})$（其中 $q_{y}\\ge 0$ 且 $q_{0}+q_{1}+q_{2}=1$），可以通过为任意分割参数 $\\alpha_{0},\\alpha_{1},\\alpha_{2}\\in[0,1]$ 选择以下方式来实现它：\n$$\np_{X}(3)=\\alpha_{0}q_{0},\\quad p_{X}(6)=(1-\\alpha_{0})q_{0},\\quad p_{X}(1)=\\alpha_{1}q_{1},\\quad p_{X}(4)=(1-\\alpha_{1})q_{1},\n$$\n$$\np_{X}(2)=\\alpha_{2}q_{2},\\quad p_{X}(5)=(1-\\alpha_{2})q_{2}.\n$$\n因此，可实现的 $p_{Y}$ 集合与 $\\mathcal{Y}$ 上的整个概率单纯形重合。因此\n$$\nC=\\max_{p_{Y}} H(Y),\n$$\n其中最大化是在三个结果上的所有分布上进行的。根据最大熵性质，对于有限字母表 $\\mathcal{Y}$，$H(Y)\\le \\log_{2}|\\mathcal{Y}|$，当且仅当 $Y$ 在 $\\mathcal{Y}$ 上均匀分布时取等号。此处 $|\\mathcal{Y}|=3$，因此在 $p_{Y}(0)=p_{Y}(1)=p_{Y}(2)=\\frac{1}{3}$ 时达到最大值，得到\n$$\nC=\\log_{2}(3)\\ \\text{bits per channel use}.\n$$", "answer": "$$\\boxed{\\log_{2}(3)}$$", "id": "1609652"}, {"introduction": "现在，让我们从确定性信道迈向更复杂的带噪信道。这个问题[@problem_id:1609620]引入了一个经典的二进制附加噪声模型，但有一个重要的转折：接收端拥有关于噪声的“边信息”。这个练习揭示了一个深刻的信息论原理：如果接收端完全了解噪声的实现，它就可以完全消除噪声的影响，从而使信道容量达到理想的最大值。", "problem": "考虑一个二进制通信信道，其输入字母表为 $\\mathcal{X} = \\{0, 1\\}$，输出字母表为 $\\mathcal{Y} = \\{0, 1\\}$。该信道受到加性二进制噪声的影响。设发送端选择的输入为随机变量 $X$，噪声为随机变量 $Z$。$X$ 和 $Z$ 均可在 $\\{0, 1\\}$ 中取值。信道输出 $Y$ 由关系式 $Y = X \\oplus Z$ 给出，其中 $\\oplus$ 表示模2加法（异或运算）。\n\n噪声变量 $Z$ 在统计上独立于输入 $X$，并服从伯努利分布，其中 $P(Z=1) = q$，$q$ 是一个满足 $0  q  1$ 的常数。\n\n此通信设置的一个特殊之处在于接收端拥有关于噪声的完美旁路信息。这意味着对于每次信道使用，接收端不仅观测到输出 $Y$，还能观测到噪声实现 $Z$ 的确切值。然而，发送端对 $Z$ 一无所知。\n\n计算在接收端具有旁路信息的情况下该信道的容量 $C$。请以“比特/信道使用”为单位表示你的答案。", "solution": "信道容量定义为输入和输出之间的最大互信息，该最大值是在所有可能的输入分布上取得的。在这个具体问题中，接收端同时观测到信道输出 $Y$ 和噪声值 $Z$。因此，接收端可用的总信息是随机变量对 $(Y, Z)$。因此，信道容量 $C$ 由输入 $X$ 和随机变量对 $(Y, Z)$ 之间的最大互信息给出。\n\n$$C = \\max_{p(x)} I(X; Y, Z)$$\n\n我们可以使用互信息的链式法则展开互信息项 $I(X; Y, Z)$：\n\n$$I(X; Y, Z) = I(X; Z) + I(X; Y | Z)$$\n\n问题陈述指明输入 $X$ 和噪声 $Z$ 是统计独立的。两个独立随机变量之间的互信息为零。因此：\n\n$$I(X; Z) = 0$$\n\n将此结果代入我们的互信息表达式中，我们得到：\n\n$$I(X; Y, Z) = 0 + I(X; Y | Z) = I(X; Y | Z)$$\n\n现在我们来分析条件互信息项 $I(X; Y | Z)$。我们可以用条件熵来表示它：\n\n$$I(X; Y | Z) = H(X | Z) - H(X | Y, Z)$$\n\n因为 $X$ 和 $Z$ 是独立的，所以知道 $Z$ 的值并不能提供关于 $X$ 的任何信息。因此，条件熵 $H(X | Z)$ 等于 $X$ 的熵：\n\n$$H(X | Z) = H(X)$$\n\n接下来，我们计算 $H(X | Y, Z)$ 这一项。这表示在接收端观测到输出 $Y$ 和噪声 $Z$ 之后，关于输入 $X$ 的剩余不确定性。信道关系式为 $Y = X \\oplus Z$。利用异或运算的性质，我们可以解出 $X$：\n\n$$X = Y \\oplus Z$$\n\n由于接收端在每次传输中都知道 $Y$ 和 $Z$ 的确切值，因此它可以完全确定地计算出 $X$。一旦知道了 $Y$ 和 $Z$，关于 $X$ 就没有任何不确定性了。因此，条件熵 $H(X | Y, Z)$ 为零：\n\n$$H(X | Y, Z) = 0$$\n\n将这些熵的结果代回互信息的表达式中：\n\n$$I(X; Y, Z) = I(X; Y | Z) = H(X|Z) - H(X|Y,Z) = H(X) - 0 = H(X)$$\n\n所以，对于任意给定的输入分布 $p(x)$，互信息就是输入 $X$ 的熵 $H(X)$。为了求出信道容量 $C$，我们必须在所有可能的输入分布上最大化这个互信息。\n\n$$C = \\max_{p(x)} H(X)$$\n\n输入 $X$ 是一个二进制随机变量。当二进制随机变量的各种结果等可能时，其熵达到最大值，即 $P(X=0) = P(X=1) = 1/2$。熵的最大值为：\n\n$$H_{\\text{max}}(X) = -P(X=0)\\log_2(P(X=0)) - P(X=1)\\log_2(P(X=1))$$\n$$H_{\\text{max}}(X) = -\\frac{1}{2}\\log_2\\left(\\frac{1}{2}\\right) - \\frac{1}{2}\\log_2\\left(\\frac{1}{2}\\right) = - (1)\\log_2\\left(\\frac{1}{2}\\right) = -(-\\log_2(2)) = \\log_2(2) = 1 \\text{ bit}$$\n\n因此，该信道的容量是 1 比特/信道使用。值得注意的是，信道容量与噪声概率 $q$ 无关，这是接收端拥有关于噪声的完美旁路信息的直接结果。", "answer": "$$\\boxed{1}$$", "id": "1609620"}]}