{"hands_on_practices": [{"introduction": "理论联系实践是掌握知识的关键。以下练习将帮助你巩固关于反馈不增加离散无记忆信道（DMC）容量的核心概念。我们将从一个概念辨析题开始，它旨在检验我们对基本原理的直观理解。在信息论中，将复杂系统视为其各部分之和的直觉有时会产生误导。这个练习 [@problem_id:1624728] 挑战了一个看似合理但存在根本缺陷的论点，迫使我们精确地辨析为什么对于一个复合无记忆信道，其容量的计算方式并非简单的加权平均。", "problem": "一位通信工程师正在为一个表现出复杂噪声行为的信道设计一个系统。对于每个传输的比特，信道会以两种方式之一运行，每次传输的选择是随机且独立的。\n- 以概率 $\\alpha$，信道表现为二进制对称信道 (BSC($p$))，其具有二进制输入 $\\{0, 1\\}$ 和二进制输出 $\\{0, 1\\}$。输入比特以交叉概率 $p$ 翻转为相反的值。BSC($p$) 的容量为 $C_{BSC} = 1 - H_2(p)$，其中 $H_2(p) = -p \\log_2(p) - (1-p) \\log_2(1-p)$ 是二进制熵函数。\n- 以概率 $1-\\alpha$，信道表现为二进制删除信道 (BEC($\\epsilon$))，其具有二进制输入 $\\{0, 1\\}$ 和三元输出 $\\{0, 1, e\\}$。输入比特以概率 $\\epsilon$ 被删除（输出为 $e$），否则被正确传输。BEC($\\epsilon$) 的容量为 $C_{BEC} = 1-\\epsilon$。\n\n团队中的一名初级工程师分析了从接收器到发送器添加一个完美的、无延迟的反馈链路的潜在好处。该工程师提出了以下论点，以得出反馈不会增加这个复合信道容量的结论：\n\n1.  对于 BSC($p$) 子信道，一个已知的结果是其带反馈的容量 $C_{BSC, fb}$ 等于其不带反馈的容量 $C_{BSC}$。\n2.  对于 BEC($\\epsilon$) 子信道，同样已知其带反馈的容量 $C_{BEC, fb}$ 等于其不带反馈的容量 $C_{BEC}$。\n3.  整个信道是两个子信道的概率混合。因此，其不带反馈的容量 $C$ 必须是各个容量的加权平均值：$C = \\alpha C_{BSC} + (1-\\alpha) C_{BEC}$。\n4.  类似地，带反馈的容量 $C_{fb}$ 必须是各个带反馈容量的加权平均值：$C_{fb} = \\alpha C_{BSC, fb} + (1-\\alpha) C_{BEC, fb}$。\n5.  综合以上几点，很明显 $C_{fb} = \\alpha C_{BSC} + (1-\\alpha) C_{BEC} = C$。因此，反馈不会增加容量。\n\n高级工程师确认最终结论是正确的（即 $C_{fb} = C$），但指出初级工程师的论证存在根本性缺陷。以下哪个陈述正确地指出了初级工程师推理中的缺陷？\n\nA. 初级工程师错了；反馈*可以*增加这个复合信道的容量，因为发送器可以利用反馈来了解哪一次传输使用了哪个子信道（BSC或BEC），并为未来的传输调整其策略。\n\nB. 初级工程师的论证是有缺陷的，因为信道的概率混合的容量，在一般情况下，不是它们各自容量的加权平均值。\n\nC. 初级工程师的论证是有缺陷的，因为虽然反馈不增加BSC的容量，但它*确实*增加了BEC的容量，因为它允许通过重传被删除的比特来实现完美传输。\n\nD. 初级工程师的论证在其所有步骤中都是完全正确的，并为容量不变的原因提供了正确的理由。\n\nE. 初级工程师的论证是有缺陷的，因为复合信道不是无记忆的，而反馈不增加容量的定理仅适用于无记忆信道。", "solution": "令 $X \\in \\{0,1\\}$ 表示信道输入，$Y \\in \\{0,1,e\\}$ 表示信道输出，并令 $S \\in \\{\\text{BSC},\\text{BEC}\\}$ 为随机的子信道选择器，在每次使用中独立，且 $\\Pr[S=\\text{BSC}]=\\alpha$ 和 $\\Pr[S=\\text{BEC}]=1-\\alpha$。在给定 $S$ 的条件下，信道是无记忆的；由于 $S$ 在每次使用中是独立同分布的(i.i.d.)，因此整个复合信道是一个单一的离散无记忆信道 (DMC)，其转移定律为\n$$\n\\Pr[Y=e \\mid X=x] = (1-\\alpha)\\epsilon,\\quad\n\\Pr[Y=1-x \\mid X=x] = \\alpha p,\\quad\n\\Pr[Y=x \\mid X=x] = \\alpha(1-p) + (1-\\alpha)(1-\\epsilon).\n$$\n因此，不带反馈的容量为\n$$\nC \\;=\\; \\max_{P_{X}} I(X;Y).\n$$\n根据 Shannon 的关于DMC的反馈定理，完美的、无延迟的反馈不会增加容量；因此\n$$\nC_{\\text{fb}} \\;=\\; C.\n$$\n因此，高级工程师接受结论 $C_{\\text{fb}}=C$ 是有充分理由的。\n\n初级工程师推理的缺陷在于步骤3和4，这两个步骤断言概率混合的容量等于各个容量的加权平均值。在一般情况下，容量运算与概率混合运算是不可交换的。为了看到正确的关系，引入选择器 $S$；对于任何输入分布 $P_{X}$，应用链式法则：\n$$\nI(X;Y) \\;=\\; I(X;Y,S) - I(X;S \\mid Y)\n\\;=\\; I(X;S) + I(X;Y \\mid S) - I(X;S \\mid Y).\n$$\n由于 $X$ 和 $S$ 是独立的，所以 $I(X;S)=0$，因此\n$$\nI(X;Y) \\;=\\; \\alpha\\, I_{\\text{BSC}}(X;Y) + (1-\\alpha)\\, I_{\\text{BEC}}(X;Y) - I(X;S \\mid Y),\n$$\n其中 $I_{\\text{BSC}}(X;Y)$ 和 $I_{\\text{BEC}}(X;Y)$ 分别表示当信道是 BSC 或 BEC 时，在相同的 $P_{X}$ 下计算的互信息。因为 $I(X;S \\mid Y) \\geq 0$，我们得到\n$$\nI(X;Y) \\;\\leq\\; \\alpha\\, I_{\\text{BSC}}(X;Y) + (1-\\alpha)\\, I_{\\text{BEC}}(X;Y).\n$$\n对两边关于 $P_{X}$ 取最大值，得到\n$$\nC \\;=\\; \\max_{P_{X}} I(X;Y)\n\\;\\leq\\; \\max_{P_{X}} \\big[ \\alpha\\, I_{\\text{BSC}}(X;Y) + (1-\\alpha)\\, I_{\\text{BEC}}(X;Y) \\big]\n\\;\\leq\\; \\alpha\\, C_{\\text{BSC}} + (1-\\alpha)\\, C_{\\text{BEC}}.\n$$\n因此，加权平均值 $\\alpha C_{\\text{BSC}} + (1-\\alpha) C_{\\text{BEC}}$ 在一般情况下只是复合信道容量的一个上界，而不是其确切值。因此，初级工程师的步骤3（以及根据相同逻辑的步骤4）是根本错误的：信道的概率混合的容量，在一般情况下，不是各个容量的加权平均值。这指出了缺陷，同时与基于DMC反馈定理的正确最终结论 $C_{\\text{fb}}=C$ 保持一致。\n\n因此，在提出的选项中，对缺陷的正确识别是，概率混合的容量不是各个容量的加权平均值。", "answer": "$$\\boxed{B}$$", "id": "1624728"}, {"introduction": "在确立了反馈不改变离散无记忆信道容量这一原则后，下一步自然是将其应用于具体的计算中。这个实践问题 [@problem_id:1669160] 要求你计算一个常见的非对称信道模型——Z信道的容量。题目中明确指出存在一个完美的反馈链路，这看似增加了问题的复杂性，但根据核心定理，它实际上简化了你的分析起点，让你能够专注于信道本身特性的计算。", "problem": "一个数字通信系统由一个被称为Z信道的二元非对称信道建模。输入符号集为 $\\mathcal{X} = \\{0, 1\\}$，输出符号集为 $\\mathcal{Y} = \\{0, 1\\}$。该信道的行为由以下条件概率定义：\n- 发送的“0”总能被正确接收为“0”。\n- 发送的“1”以概率 $1-p$ 被正确接收为“1”，但以概率 $p$ 被错误地翻转为“0”，其中 $0  p  1$。\n\n针对该系统提出了一种增强方案：每接收一个符号后，在接收端和发送端之间建立一个完美的、瞬时的、无噪声的反馈路径。该反馈将刚刚在输出端接收到的确切符号（$0$或$1$）通知给发送端。发送端可以自由使用此信息来调整其传输策略。\n\n您的任务是确定具有所述反馈机制的Z信道的信道容量。容量是指能够以任意低的错误概率传输信息的最大速率，单位为比特/信道使用。\n\n请用交叉概率 $p$ 的闭式解析表达式来表示您的答案。在您的最终答案中，所有对数均以2为底。", "solution": "根据信息论的核心原理，对于离散无记忆信道（DMC），一个完美的反馈链路并不能增加其香农容量。因此，该Z信道的容量 $C$ 等于无反馈时的容量。我们的任务是计算标准Z信道的容量。\n容量定义为 $C = \\max_{p(x)} I(X;Y)$。设输入 $X$ 的分布为 $P(X=1) = q$，$P(X=0) = 1-q$。\n互信息为 $I(X;Y) = H(Y) - H(Y|X)$。\n\n1.  **计算条件熵 $H(Y|X)$**：\n    $H(Y|X) = P(X=0)H(Y|X=0) + P(X=1)H(Y|X=1)$。\n    当 $X=0$ 时，输出 $Y=0$ 是确定的，因此 $H(Y|X=0) = 0$。\n    当 $X=1$ 时，输出 $Y$ 是一个伯努利随机变量，概率为 $p$ 和 $1-p$，因此 $H(Y|X=1) = H(p)$，其中 $H(p) = -p\\log_2(p) - (1-p)\\log_2(1-p)$ 是二进制熵函数。\n    所以，$H(Y|X) = (1-q) \\cdot 0 + q \\cdot H(p) = qH(p)$。\n\n2.  **计算输出熵 $H(Y)$**：\n    输出概率为 $P(Y=1) = P(Y=1|X=1)P(X=1) = (1-p)q$。\n    $P(Y=0) = 1 - P(Y=1) = 1 - q(1-p)$。\n    所以，$H(Y) = H(q(1-p))$。\n\n3.  **最大化互信息**：\n    我们需要最大化 $I(q) = H(q(1-p)) - qH(p)$。\n    一个已知的Z信道容量的闭式解公式为 $C = \\log_2(1 + 2^{-H(p)/(1-p)})$。我们可以通过化简指数项来验证它是否与答案匹配。\n    指数项为：\n    $$ \\frac{-H(p)}{1-p} = \\frac{-(-p\\log_2(p) - (1-p)\\log_2(1-p))}{1-p} = \\frac{p\\log_2(p) + (1-p)\\log_2(1-p)}{1-p} = \\frac{p}{1-p}\\log_2(p) + \\log_2(1-p) $$\n    利用对数性质 $\\log(a) + \\log(b) = \\log(ab)$ 和 $c\\log(a) = \\log(a^c)$，上式变为：\n    $$ \\frac{-H(p)}{1-p} = \\log_2(p^{\\frac{p}{1-p}}) + \\log_2(1-p) = \\log_2\\left((1-p)p^{\\frac{p}{1-p}}\\right) $$\n\n4.  **代入容量公式**：\n    $$ C = \\log_2\\left(1 + 2^{\\log_2\\left((1-p)p^{\\frac{p}{1-p}}\\right)}\\right) = \\log_2\\left(1 + (1-p)p^{\\frac{p}{1-p}}\\right) $$\n    这个结果与最终答案的表达式完全匹配。", "answer": "$$\\boxed{\\log_{2}\\!\\left(1+(1-p)\\,p^{\\frac{p}{1-p}}\\right)}$$", "id": "1669160"}, {"introduction": "信道容量定理告诉我们通信速率的上限，而其逆定理则揭示了超出这个极限后不可避免的后果。这个练习 [@problem_id:1624717] 深入探讨了这一“硬性限制”。当信源产生信息的速率 $H(p)$ 超过信道容量 $C$ 时，即使拥有完美的反馈系统，可靠通信也无法实现。这个问题将引导你结合费诺不等式（Fano's Inequality）和信道容量的定义，推导出在这种情况下系统性能所能达到的理论极限，即最小平均错误概率的下界。", "problem": "一位信息论学者正在分析一个通信系统的基本限制，该系统设计用于传输来自一个被建模为参数为 $p$ 的独立同分布（i.i.d.）伯努利过程的信源数据。传输通过一个二进制对称信道（BSC）进行，该信道以 $\\epsilon$ 的交叉概率翻转每个传输的比特。系统以每个信道使用传输一个信源符号的速率运行。\n\n该学者考虑了一种强大的编码方案，该方案对非常长的数据块执行信源信道联合编码。该方案还可以使用一个理想的（零延迟、无差错）反馈信道，允许发送端对给定符号的编码策略依赖于所有先前接收到的信道输出。主要性能指标是平均比特错误概率 $p_b$，定义为解码后的比特与原始信源比特不同的长期平均概率。\n\n假设一个场景，其中信源产生信息的速率从根本上快于信道能够可靠处理的速率；具体来说，信源的熵大于信道的容量。\n\n令 $H(x) = -x \\log_2(x) - (1-x) \\log_2(1-x)$ 为对于 $x \\in (0,1)$ 的二进制熵函数。令 $H^{-1}(y)$ 为此函数的反函数，其定义域为 $y \\in [0, 1]$，值域为 $x \\in [0, 1/2]$。\n\n在这些条件下，以下哪个表达式代表*任何*此类通信系统可以实现的平均比特错误概率 $p_b$ 的最紧可能下界？\n\nA. $p_b \\ge \\epsilon$\n\nB. 使用足够复杂的编码方案，可以实现任意小的 $p_b > 0$ 的通信。\n\nC. $p_b \\ge H^{-1}(H(p))$\n\nD. $p_b \\ge H^{-1}(H(p) + H(\\epsilon) - 1)$\n\nE. $p_b \\ge H^{-1}(1 - H(\\epsilon))$", "solution": "问题要求在信源熵 $H(p)$ 大于信道容量 $C$ 的条件下，以每个信道使用传输一个信源符号的速率，将伯努利($p$)信源通过BSC($\\epsilon$)传输时的平均比特错误概率 $p_b$ 的下界。\n\n步骤1：关联信源熵、信息传输和信道容量。\n令 $X^n = (X_1, ..., X_n)$ 为一个包含 $n$ 个信源符号的序列，$\\hat{X}^n = (\\hat{X}_1, ..., \\hat{X}_n)$ 为对应的解码符号序列。由于信源是独立同分布的伯努利($p$)过程，信源序列的熵为 $H(X^n) = nH(p)$。\n\n信源熵、信源与其估计值之间的互信息以及条件熵（含糊度）之间的关系由下式给出：\n$$H(X^n) = I(X^n; \\hat{X}^n) + H(X^n | \\hat{X}^n)$$\n其中 $I(X^n; \\hat{X}^n)$ 是互信息。\n\n数据处理不等式指出，对于任何为得到 $\\hat{X}^n$ 而对信道输出 $Y^n$ 进行的处理，互信息都不会增加。编码和信道传输构成一个马尔可夫链 $X^n \\to U^n \\to Y^n \\to \\hat{X}^n$，其中 $U^n$ 是信道输入序列。因此，\n$$I(X^n; \\hat{X}^n) \\le I(U^n; Y^n)$$\n即使有反馈，在时间 $i$ 的信道输入 $U_i$ 也可以依赖于 $X^n$ 和先前的信道输出 $Y^{i-1}$。然而，信息论的一个基本结果是，对于离散无记忆信道（DMC），反馈不会增加信道容量。跨越DMC的 $n$ 次使用的互信息受限于 $n$ 倍的容量 $C$：\n$$I(U^n; Y^n) \\le nC$$\n交叉概率为 $\\epsilon$ 的BSC的容量由 $C = 1 - H(\\epsilon)$ 给出。\n\n结合这些不等式，我们得到：\n$$I(X^n; \\hat{X}^n) \\le nC$$\n将此代回熵方程：\n$$n H(p) = I(X^n; \\hat{X}^n) + H(X^n | \\hat{X}^n) \\le nC + H(X^n | \\hat{X}^n)$$\n重新排列此式，得到含糊度的一个下界：\n$$H(X^n | \\hat{X}^n) \\ge n H(p) - nC = n(H(p) - C)$$\n\n步骤2：使用法诺不等式（Fano's Inequality）将含糊度与比特错误概率关联起来。\n我们需要根据平均比特错误概率 $p_b$ 找到 $H(X^n | \\hat{X}^n)$ 的一个上界。\n使用熵的链式法则以及条件作用会减少熵的事实：\n$$H(X^n | \\hat{X}^n) = H(X_1, ..., X_n | \\hat{X}_1, ..., \\hat{X}_n) = \\sum_{i=1}^{n} H(X_i | X_1, ..., X_{i-1}, \\hat{X}^n) \\le \\sum_{i=1}^{n} H(X_i | \\hat{X}_i)$$\n对于单个比特，条件熵 $H(X_i | \\hat{X}_i)$ 与该比特的错误概率 $p_{e,i} = P(X_i \\ne \\hat{X}_i)$ 通过单个变量的法诺不等式相关联：\n$$H(X_i | \\hat{X}_i) \\le H(p_{e,i})$$\n因此，我们有：\n$$H(X^n | \\hat{X}^n) \\le \\sum_{i=1}^{n} H(p_{e,i})$$\n二进制熵函数 $H(x)$ 是凹函数。根据琴生不等式（Jensen's inequality）：\n$$\\frac{1}{n} \\sum_{i=1}^{n} H(p_{e,i}) \\le H\\left(\\frac{1}{n} \\sum_{i=1}^{n} p_{e,i}\\right)$$\n右侧熵函数内部的项是平均比特错误概率 $p_b$ 的定义。所以，\n$$\\sum_{i=1}^{n} H(p_{e,i}) \\le n H(p_b)$$\n这给出了含糊度的上界：\n$$H(X^n | \\hat{X}^n) \\le n H(p_b)$$\n\n步骤3：合并界限并求解 $p_b$。\n我们有两个关于 $H(X^n | \\hat{X}^n)$ 的界限：\n$$n(H(p) - C) \\le H(X^n | \\hat{X}^n) \\le n H(p_b)$$\n这意味着：\n$$n(H(p) - C) \\le n H(p_b)$$\n$$H(p) - C \\le H(p_b)$$\n现在代入BSC的容量，$C = 1 - H(\\epsilon)$：\n$$H(p) - (1 - H(\\epsilon)) \\le H(p_b)$$\n$$H(p) + H(\\epsilon) - 1 \\le H(p_b)$$\n问题假设我们处于 $H(p) > C$ 的情况下，这意味着 $H(p) + H(\\epsilon) - 1 > 0$。按照惯例，比特错误概率 $p_b$ 被假定为小于或等于 $1/2$（如果大于此值，可以通过翻转所有比特来获得更低的错误率）。二进制熵函数 $H(x)$ 在区间 $[0, 1/2]$ 上是单调递增的。因此，我们可以将它的反函数 $H^{-1}(y)$ 应用于不等式的两边，而不会改变不等式的方向：\n$$H^{-1}(H(p) + H(\\epsilon) - 1) \\le H^{-1}(H(p_b))$$\n鉴于 $H^{-1}$ 是 $H$ 在值域 $[0, 1/2]$ 上的反函数，这可以简化为：\n$$p_b \\ge H^{-1}(H(p) + H(\\epsilon) - 1)$$\n这提供了基于这些信息论论证的 $p_b$ 的最紧可能下界。\n\n步骤4：评估选项。\n推导出的表达式与选项D匹配。我们来分析其他选项：\nA. $p_b \\ge \\epsilon$：这是一个貌似合理的干扰项。没有编码的天真传输将产生 $p_b=\\epsilon$。编码有时可以将错误率降低到 $\\epsilon$ 以下，但这个界限并非普遍紧致。我们推导出的界限可能小于或大于 $\\epsilon$，具体取决于参数。\nB. 可以实现任意小的 $p_b$：这是信道编码定理的陈述，它仅在信息速率小于容量时成立。在这里，信息速率是 $H(p)$（因为我们每个信道使用发送1个信源比特），并且问题陈述了 $H(p)C$。因此，这个陈述是错误的。\nC. $p_b \\ge H^{-1}(H(p)) = p$：这对应于信源的统计特性，而不是信道的限制。它代表了对原理的错误应用。\nE. $p_b \\ge H^{-1}(1 - H(\\epsilon)) = H^{-1}(C)$：这个界限忽略了信源产生信息的速率 $H(p)$，只考虑了信道容量。它会是不完整分析的结果。\n\n因此，选项中唯一正确且最紧的界限是D。", "answer": "$$\\boxed{D}$$", "id": "1624717"}]}