{"hands_on_practices": [{"introduction": "与始终为非负的离散香农熵不同，微分熵的一个关键特性是它可以取负值。这个练习旨在通过一个具体的计算来揭示这一反直觉的性质，帮助你理解当一个高斯随机变量的概率分布高度集中（即方差很小）时，其不确定性可以为负值。这个练习将巩固你对微分熵公式的掌握，并加深对连续随机变量不确定性度量的理解。[@problem_id:1617961]", "problem": "在信息论中，连续随机变量的微分熵衡量了其平均不确定性。与离散随机变量的香农熵（其值总是非负的）不同，微分熵可以取负值。\n\n考虑一个随机变量 $X$，它服从均值为零、方差为 $\\sigma^2$ 的一维高斯（或正态）分布，记作 $X \\sim \\mathcal{N}(0, \\sigma^2)$。该变量的微分熵以奈特（nats）为单位，由以下公式给出：\n$$h(X) = \\frac{1}{2}\\ln(2\\pi e \\sigma^2)$$\n其中 $\\ln$ 是自然对数，$e$ 是欧拉数，即自然对数的底。\n\n从以下给出的方差 $\\sigma^2$ 的可能值中，选择一个使得微分熵为负值（即 $h(X)  0$）的选项。\n\nA. $\\sigma^2 = 1$\nB. $\\sigma^2 = \\frac{1}{\\pi}$\nC. $\\sigma^2 = \\frac{1}{2e}$\nD. $\\sigma^2 = \\frac{1}{2\\pi e}$\nE. $\\sigma^2 = \\frac{1}{4\\pi e}$", "solution": "我们已知对于 $X \\sim \\mathcal{N}(0,\\sigma^{2})$，其以奈特为单位的微分熵为\n$$\nh(X) = \\frac{1}{2}\\ln\\!\\big(2\\pi e \\sigma^{2}\\big).\n$$\n我们要求 $h(X)  0$。由于 $\\ln$ 是一个严格单调递增函数，因此不等式\n$$\n\\frac{1}{2}\\ln\\!\\big(2\\pi e \\sigma^{2}\\big)  0\n$$\n等价于\n$$\n\\ln\\!\\big(2\\pi e \\sigma^{2}\\big)  0 \\iff 2\\pi e \\sigma^{2}  1 \\iff \\sigma^{2}  \\frac{1}{2\\pi e}.\n$$\n我们现在将每个选项与阈值 $\\frac{1}{2\\pi e}$ 进行比较：\n- A: $\\sigma^{2} = 1  \\frac{1}{2\\pi e}$，所以 $h(X)  0$。\n- B: $\\sigma^{2} = \\frac{1}{\\pi}  \\frac{1}{2\\pi e}$，因为 $\\frac{1}{\\pi}  \\frac{1}{2\\pi e} \\iff 1  \\frac{1}{2e}$，而该不等式成立。\n- C: $\\sigma^{2} = \\frac{1}{2e}  \\frac{1}{2\\pi e}$，因为 $\\pi  1$。\n- D: $\\sigma^{2} = \\frac{1}{2\\pi e}$ 得到 $h(X) = \\frac{1}{2}\\ln(1) = 0$，不是负数。\n- E: $\\sigma^{2} = \\frac{1}{4\\pi e}  \\frac{1}{2\\pi e}$，所以 $h(X)  0$。\n\n因此，唯一能使微分熵为负的选项是E。", "answer": "$$\\boxed{E}$$", "id": "1617961"}, {"introduction": "在信号处理和数据分析中，一个核心技术是通过对多次独立测量取平均来降低噪声、提高精度。本练习将从信息论的视角来量化这一过程的收益，你将推导出样本均值的微分熵如何随着样本数量 $n$ 的增加而变化，从而直观地理解不确定性是如何被有效降低的。这个过程展示了中心极限定理在信息论中的一个有趣推论。[@problem_id:1618009]", "problem": "在数字信号处理和数据分析中，一种提高测量精度的常用技术是对多次独立的读数取平均。这个过程有助于减小随机噪声的影响。\n\n考虑一个场景，一位科学家收集了 $n$ 次测量，这些测量被建模为独立同分布 (i.i.d.) 的随机变量 $X_1, X_2, \\dots, X_n$。已知每次测量 $X_i$ 都服从标准正态分布，即均值为0、方差为1的高斯分布。\n\n这位科学家通过对这 $n$ 个值取样本均值来计算聚合测量值 $\\bar{X}_n$：\n$$\n\\bar{X}_n = \\frac{1}{n}\\sum_{i=1}^{n} X_i\n$$\n与这个新随机变量 $\\bar{X}_n$ 相关的不确定性或“惊奇度”可以用其微分熵来量化。对于一个方差为 $\\sigma^2$ 的一般高斯随机变量 $Y$，其微分熵 $h(Y)$ 由以下公式给出：\n$$\nh(Y) = \\frac{1}{2} \\ln(2\\pi e \\sigma^2)\n$$\n其中 $\\ln$ 表示自然对数。\n\n确定样本均值的微分熵 $h(\\bar{X}_n)$，将其作为测量次数 $n$ 的函数。你的答案应该是一个符号表达式。", "solution": "给定独立同分布的 $X_{1},\\dots,X_{n}$，其中 $X_{i}\\sim \\mathcal{N}(0,1)$，且样本均值为 $\\bar{X}_{n}=\\frac{1}{n}\\sum_{i=1}^{n}X_{i}$。独立高斯随机变量的线性组合仍是高斯随机变量，因此 $\\bar{X}_{n}$ 服从高斯分布。其均值为\n$$\n\\mathbb{E}[\\bar{X}_{n}]=\\frac{1}{n}\\sum_{i=1}^{n}\\mathbb{E}[X_{i}]=\\frac{1}{n}\\cdot n\\cdot 0=0.\n$$\n利用独立性以及方差的尺度变换性质 $\\operatorname{Var}(cZ)=c^{2}\\operatorname{Var}(Z)$，其方差为\n$$\n\\operatorname{Var}(\\bar{X}_{n})=\\operatorname{Var}\\!\\left(\\frac{1}{n}\\sum_{i=1}^{n}X_{i}\\right)=\\frac{1}{n^{2}}\\sum_{i=1}^{n}\\operatorname{Var}(X_{i})=\\frac{1}{n^{2}}\\cdot n\\cdot 1=\\frac{1}{n}.\n$$\n对于方差为 $\\sigma^{2}$ 的高斯随机变量 $Y$，其微分熵为\n$$\nh(Y)=\\frac{1}{2}\\ln\\!\\left(2\\pi e\\,\\sigma^{2}\\right).\n$$\n将 $\\sigma^{2}=\\frac{1}{n}$ 代入，得到：\n$$\nh(\\bar{X}_{n})=\\frac{1}{2}\\ln\\!\\left(2\\pi e\\,\\frac{1}{n}\\right)=\\frac{1}{2}\\ln\\!\\left(\\frac{2\\pi e}{n}\\right).\n$$\n这就将样本均值的微分熵表示成了 $n$ 的函数。", "answer": "$$\\boxed{\\frac{1}{2}\\ln\\!\\left(\\frac{2\\pi e}{n}\\right)}$$", "id": "1618009"}, {"introduction": "现在我们将微分熵的概念应用于一个实际的工程优化问题中。在通信系统中，我们常常需要在有限的资源（如总功率）下，最大化信道的信息传输能力。这个练习将指导你如何分配功率到两个独立的信道，以最大化它们的联合微分熵，这直接关系到系统的总信息吞吐量。通过这个练习，你将学会如何应用优化方法来解决信息论中的资源分配问题。[@problem_id:1617989]", "problem": "考虑一个设计用于传输两个独立信号的双通道通信系统。这些信号被建模为零均值高斯随机变量 $X_1$ 和 $X_2$，其功率分别对应于它们的方差 $\\sigma_1^2$ 和 $\\sigma_2^2$。\n\n该系统在资源约束下运行。总加权功耗不得超过总预算 $P$。此关系表示为 $a_1 \\sigma_1^2 + a_2 \\sigma_2^2 = P$，其中 $a_1  0$ 和 $a_2  0$ 是给定的正常数，表示每个信道单位功率的资源成本。\n\n为了最大化总信息吞吐量，必须最大化两个信号的联合微分熵 $h(X_1, X_2)$。作为参考，方差为 $\\sigma^2$ 的单个高斯随机变量 $X$ 的微分熵由公式 $h(X) = \\frac{1}{2} \\ln(2\\pi e \\sigma^2)$ 给出。\n\n确定在功率预算约束下，使联合微分熵最大化的各自信道方差 $\\sigma_1^2$ 和 $\\sigma_2^2$ 的值。请先给出 $\\sigma_1^2$ 的答案，然后给出 $\\sigma_2^2$ 的答案。", "solution": "给定两个独立的零均值高斯随机变量 $X_{1}$ 和 $X_{2}$，其方差分别为 $\\sigma_{1}^{2}$ 和 $\\sigma_{2}^{2}$。对于独立变量，联合微分熵等于各个熵的总和：\n$$\nh(X_{1},X_{2})=h(X_{1})+h(X_{2}).\n$$\n对于方差为 $\\sigma^{2}$ 的高斯随机变量，$h(X)=\\frac{1}{2}\\ln\\!\\big(2\\pi e\\,\\sigma^{2}\\big)$。因此，\n$$\nh(X_{1},X_{2})=\\frac{1}{2}\\ln\\!\\big(2\\pi e\\,\\sigma_{1}^{2}\\big)+\\frac{1}{2}\\ln\\!\\big(2\\pi e\\,\\sigma_{2}^{2}\\big)\n=\\ln(2\\pi e)+\\frac{1}{2}\\ln\\!\\big(\\sigma_{1}^{2}\\sigma_{2}^{2}\\big).\n$$\n在资源约束 $a_{1}\\sigma_{1}^{2}+a_{2}\\sigma_{2}^{2}=P$ 下，对 $\\sigma_{1}^{2},\\sigma_{2}^{2}0$ 最大化 $h(X_{1},X_{2})$，等价于在相同约束下最大化 $\\ln(\\sigma_{1}^{2})+\\ln(\\sigma_{2}^{2})$，因为常数不影响最优点。这是一个带有线性等式约束的凹函数最大化问题；我们使用拉格朗日乘子法。\n\n定义\n$$\n\\mathcal{L}=\\frac{1}{2}\\ln(\\sigma_{1}^{2})+\\frac{1}{2}\\ln(\\sigma_{2}^{2})-\\lambda\\big(a_{1}\\sigma_{1}^{2}+a_{2}\\sigma_{2}^{2}-P\\big).\n$$\n平稳性条件为\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\sigma_{1}^{2}}=\\frac{1}{2}\\frac{1}{\\sigma_{1}^{2}}-\\lambda a_{1}=0\n\\quad\\Rightarrow\\quad \\sigma_{1}^{2}=\\frac{1}{2\\lambda a_{1}},\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\sigma_{2}^{2}}=\\frac{1}{2}\\frac{1}{\\sigma_{2}^{2}}-\\lambda a_{2}=0\n\\quad\\Rightarrow\\quad \\sigma_{2}^{2}=\\frac{1}{2\\lambda a_{2}}.\n$$\n代入约束条件 $a_{1}\\sigma_{1}^{2}+a_{2}\\sigma_{2}^{2}=P$ 可得\n$$\na_{1}\\left(\\frac{1}{2\\lambda a_{1}}\\right)+a_{2}\\left(\\frac{1}{2\\lambda a_{2}}\\right)=P\n\\;\\Rightarrow\\;\n\\frac{1}{2\\lambda}+\\frac{1}{2\\lambda}=P\n\\;\\Rightarrow\\;\n\\frac{1}{\\lambda}=P\n\\;\\Rightarrow\\;\n\\lambda=\\frac{1}{P}.\n$$\n代回可得\n$$\n\\sigma_{1}^{2}=\\frac{P}{2a_{1}},\\qquad \\sigma_{2}^{2}=\\frac{P}{2a_{2}}.\n$$\n因为目标函数对于 $(\\sigma_{1}^{2},\\sigma_{2}^{2})$ 是严格凹函数，并且可行集是仿射的（其中 $a_{1},a_{2}0$），所以这个平稳点是唯一的全局最大化点，并且它用尽了全部预算。", "answer": "$$\\boxed{\\begin{pmatrix}\\frac{P}{2 a_{1}}  \\frac{P}{2 a_{2}}\\end{pmatrix}}$$", "id": "1617989"}]}