{"hands_on_practices": [{"introduction": "在多核处理器上编写高性能程序，不仅仅关乎算法设计，更在于深刻理解数据与底层硬件缓存系统的交互方式。一个常见而隐蔽的性能陷阱是“伪共享”（false sharing）：当两个或多个核心频繁写入逻辑上独立、但物理上位于同一缓存行（cache line）的数据时，会导致缓存行在核心之间不必要的来回传递，产生大量的缓存一致性开销。这个练习 [@problem_id:3661029] 将通过一个具体场景，指导你计算避免伪共享所需的内存填充（padding），这是每一位追求极致性能的并行程序员都应掌握的基本功。", "problem": "一个在共享内存多核处理器上运行的并行应用程序使用一个每线程记录的数组，每个线程一个记录，这些记录在内存中连续存储。为了在缓存行大小为 $L$ 的缓存一致性协议下防止伪共享，可以通过附加 $p$ 字节的尾部填充来选择性地增加记录大小，以使每个记录都从一个独立的缓存行开始。分配器为该数组返回一个基地址，该地址与 $L$ 字节的缓存行边界对齐。\n\n每个记录按所列顺序包含以下C风格的字段，并具有指定的尺寸和自然对齐要求（假设在一个常规的应用程序二进制接口中，每个字段都与其自身大小对齐，最大对齐为8字节，并且总记录大小向上取整为任何字段所用最大对齐值的倍数）：\n- 一个 $64$-位浮点值（大小 $8$ 字节，对齐 $8$ 字节），\n- 一个 $64$-位无符号整数（大小 $8$ 字节，对齐 $8$ 字节），\n- 一个 $32$-位有符号整数（大小 $4$ 字节，对齐 $4$ 字节），\n- 一个 $16$-位有符号整数（大小 $2$ 字节，对齐 $2$ 字节），\n- 一个 $8$-位无符号整数（大小 $1$ 字节，对齐 $1$ 字节），\n- 一个 $3$ 字节的数组（大小 $3$ 字节，对齐 $1$ 字节）。\n\n令 $s$ 表示记录在经过字段对齐所需的内部填充以及为满足记录自身对齐而向上取整后的字节大小。令 $p$ 为附加到每个记录的尾部填充字节数，以使数组中每个记录的起始地址都位于一个独立的缓存行上。\n\n给定 $L = 64$ 字节，确定最小非负整数 $p$（以字节为单位），以保证当数组连续布局时，每个记录都从一个新的缓存行开始。以字节为单位，用一个数字表示你的答案。", "solution": "问题要求我们确定添加到数据记录中的最小非负尾部填充 $p$，以使连续数组中的每个记录都从一个新的缓存行开始。解决方案包括两个主要步骤：首先，计算记录在考虑了内部填充和对齐规则后的大小 $s$；其次，使用 $s$ 和缓存行大小 $L$ 来推导 $p$ 的条件并找到其最小值。\n\n第1部分：计算未填充的记录大小 $s$。\n大小 $s$ 由记录内字段的布局、它们各自的对齐要求以及记录结构本身的最终对齐要求决定。我们假设记录从偏移量 $0$ 开始，依次计算每个字段的偏移量。一个字段的偏移量必须是其对齐要求的倍数。\n\n字段按顺序给出其大小和对齐要求：\n1.  `field1`：一个 $64$-位浮点数（大小 $8$ 字节，对齐 $8$ 字节）。\n    从偏移量 $0$ 开始。占据字节 $[0, 7]$。下一个可用偏移量是 $8$。\n2.  `field2`：一个 $64$-位无符号整数（大小 $8$ 字节，对齐 $8$ 字节）。\n    下一个偏移量 $8$ 是对齐值 $8$ 的倍数。它从偏移量 $8$ 开始。占据字节 $[8, 15]$。下一个可用偏移量是 $16$。\n3.  `field3`：一个 $32$-位有符号整数（大小 $4$ 字节，对齐 $4$ 字节）。\n    下一个偏移量 $16$ 是对齐值 $4$ 的倍数。它从偏移量 $16$ 开始。占据字节 $[16, 19]$。下一个可用偏移量是 $20$。\n4.  `field4`：一个 $16$-位有符号整数（大小 $2$ 字节，对齐 $2$ 字节）。\n    下一个偏移量 $20$ 是对齐值 $2$ 的倍数。它从偏移量 $20$ 开始。占据字节 $[20, 21]$。下一个可用偏移量是 $22$。\n5.  `field5`：一个 $8$-位无符号整数（大小 $1$ 字节，对齐 $1$ 字节）。\n    下一个偏移量 $22$ 是对齐值 $1$ 的倍数。它从偏移量 $22$ 开始。占据字节 $22$。下一个可用偏移量是 $23$。\n6.  `field6`：一个 $3$ 字节的数组（大小 $3$ 字节，对齐 $1$ 字节）。\n    下一个偏移量 $23$ 是对齐值 $1$ 的倍数。它从偏移量 $23$ 开始。占据字节 $[23, 25]$。下一个可用偏移量是 $26$。\n\n布局完所有字段后，总占用空间为 $26$ 字节。然而，问题指出，总记录大小 $s$ 必须向上取整为任何字段所用最大对齐值的倍数。字段的对齐要求分别为 $8$、$8$、$4$、$2$、$1$ 和 $1$ 字节。这些值中的最大值是 $8$ 字节。\n因此，$s$ 必须是大于或等于 $26$ 的最小的 $8$ 的倍数。\n$8$ 的倍数有 $8, 16, 24, 32, \\dots$。大于等于 $26$ 的最小的 $8$ 的倍数是 $32$。\n因此，未填充的记录大小为 $s = 32$ 字节。\n\n第2部分：计算最小尾部填充 $p$。\n填充后记录的总大小为 $S' = s + p$。这些记录连续存储在一个数组中，其基地址 $A_{base}$ 与 $L = 64$ 字节的缓存行边界对齐。这意味着 $A_{base}$ 是 $L$ 的倍数。\n数组中第 $i$ 个记录（对于 $i \\ge 0$）的地址由 $A_i = A_{base} + i \\cdot S'$ 给出。\n条件是每个记录都从一个独立的缓存行开始。地址 $A$ 的缓存行索引是 $\\lfloor \\frac{A}{L} \\rfloor$。因此，我们要求对于任何 $i \\neq j$，都有 $\\lfloor \\frac{A_i}{L} \\rfloor \\neq \\lfloor \\frac{A_j}{L} \\rfloor$。由于地址随 $i$ 单调递增，这等效于要求每个记录的缓存行索引严格大于前一个记录的缓存行索引：\n$$ \\left\\lfloor \\frac{A_{i+1}}{L} \\right\\rfloor > \\left\\lfloor \\frac{A_i}{L} \\right\\rfloor \\quad \\text{for all } i \\ge 0 $$\n代入 $A_i$ 的表达式：\n$$ \\left\\lfloor \\frac{A_{base} + (i+1)S'}{L} \\right\\rfloor > \\left\\lfloor \\frac{A_{base} + iS'}{L} \\right\\rfloor $$\n由于 $A_{base}$ 是 $L$ 的倍数，令 $A_{base} = k \\cdot L$ (其中 $k$ 为某个整数)。不等式变为：\n$$ \\left\\lfloor \\frac{kL + (i+1)S'}{L} \\right\\rfloor > \\left\\lfloor \\frac{kL + iS'}{L} \\right\\rfloor $$\n$$ k + \\left\\lfloor \\frac{(i+1)S'}{L} \\right\\rfloor > k + \\left\\lfloor \\frac{iS'}{L} \\right\\rfloor $$\n$$ \\left\\lfloor \\frac{(i+1)S'}{L} \\right\\rfloor > \\left\\lfloor \\frac{iS'}{L} \\right\\rfloor $$\n这个不等式必须对所有非负整数 $i$ 成立。我们测试 $i=0$ 的情况：\n$$ \\left\\lfloor \\frac{S'}{L} \\right\\rfloor > \\left\\lfloor 0 \\right\\rfloor \\implies \\left\\lfloor \\frac{S'}{L} \\right\\rfloor > 0 $$\n由于 $\\lfloor \\frac{S'}{L} \\rfloor$ 必须是整数，这导出一个必要条件：\n$$ \\left\\lfloor \\frac{S'}{L} \\right\\rfloor \\ge 1 \\implies \\frac{S'}{L} \\ge 1 \\implies S' \\ge L $$\n这个条件也是充分的。如果 $S' \\ge L$，那么令 $c = \\frac{S'}{L} \\ge 1$。我们必须满足的不等式是 $\\lfloor (i+1)c \\rfloor > \\lfloor ic \\rfloor$。令 $f(i) = \\lfloor ic \\rfloor$。那么我们需要证明 $f(i+1) > f(i)$。\n差值为 $f(i+1) - f(i) = \\lfloor ic + c \\rfloor - \\lfloor ic \\rfloor$。\n使用性质 $\\lfloor x+y \\rfloor \\ge \\lfloor x \\rfloor + \\lfloor y \\rfloor$，我们有：\n$$ \\lfloor ic + c \\rfloor \\ge \\lfloor ic \\rfloor + \\lfloor c \\rfloor $$\n因此，$f(i+1) - f(i) \\ge \\lfloor c \\rfloor$。由于 $c = \\frac{S'}{L} \\ge 1$，我们有 $\\lfloor c \\rfloor \\ge 1$。\n所以，$f(i+1) - f(i) \\ge 1$，这证实了 $f(i+1) > f(i)$。因此，条件 $S' \\ge L$ 是充分且必要的。\n\n我们需要找到满足此条件的最小非负整数 $p$。\n$$ s + p \\ge L $$\n代入已知值 $s = 32$ 和 $L = 64$：\n$$ 32 + p \\ge 64 $$\n$$ p \\ge 64 - 32 $$\n$$ p \\ge 32 $$\n满足此不等式的最小非负整数值 $p$ 是 $32$。因此，所需的尾部填充为 $p = 32$ 字节。\n填充后记录的总大小变为 $s+p = 32+32 = 64$ 字节，这正好是缓存行的大小。这确保了每个记录都从一个新的缓存行边界开始。", "answer": "$$\\boxed{32}$$", "id": "3661029"}, {"introduction": "解决了数据布局问题后，我们还需面对另一个更微妙的挑战：不同核心的内存操作以何种顺序对其他核心可见。这个顺序并非总是符合直觉，其规则由“内存一致性模型”（memory consistency model）定义。不同的处理器架构可能采用不同的模型，例如从严格的顺序一致性（Sequential Consistency, SC）到更宽松的总存储顺序（Total Store Order, TSO）或释放一致性（Release Consistency, RC），这为编写可移植的正确并发代码带来了挑战。本练习 [@problem_id:3660971] 运用经典的“石蕊测试”（litmus tests）来探索这些模型的细微行为，并演示如何使用内存屏障（memory fences）来强制执行期望的程序顺序，从而确保程序的正确性。", "problem": "考虑一个多核芯片处理器，其具有两个共享内存位置 $x$ 和 $y$，初始值均为 $0$。以下是两个用于探测存储-加载重排序和线程间通信的基准测试（litmus test）。假设每个核心在本地按其自身的程序顺序执行。观测结果由读入寄存器的值定义，并且所有加载和存储操作都是针对普通内存位置的（没有原子读-改-写操作）。\n\n测试 $SB$（存储缓冲）：\n- 核心 $0$：$x \\leftarrow 1$；然后 $r_0 \\leftarrow y$。\n- 核心 $1$：$y \\leftarrow 1$；然后 $r_1 \\leftarrow x$。\n- 关注的观测结果：$O_{SB}$ 是事件 $r_0 = 0$ 且 $r_1 = 0$。\n\n测试 $MP$（消息传递）：\n- 核心 $0$（生产者）：$x \\leftarrow 1$；然后 $y \\leftarrow 1$。\n- 核心 $1$（消费者）：$r_1 \\leftarrow y$；然后 $r_2 \\leftarrow x$。\n- 关注的观测结果：$O_{MP}$ 是事件 $r_1 = 1$ 且 $r_2 = 0$。\n\n在以下内存模型下：\n- 释放一致性 (Release Consistency, RC)，\n- 全局存储定序 (Total Store Order, TSO)，\n- 顺序一致性 (Sequential Consistency, SC)，\n\n确定哪些模型允许 $O_{SB}$ 和 $O_{MP}$，并找出恢复预期顺序的最小化屏障（fence）放置方案：\n- 对于测试 $SB$：确保每个核心的存储操作在其后续的加载操作之前定序，从而禁止 $O_{SB}$。\n- 对于测试 $MP$：确保如果核心 $1$ 观测到 $y = 1$，那么它也必须观测到 $x = 1$。\n\n选择唯一一个正确分类了哪些模型可能出现 $O_{SB}$ 和 $O_{MP}$，并指定了能以最小代价恢复预期顺序的屏障放置方案的选项。\n\nA. $O_{SB}$ 在释放一致性和全局存储定序下可能发生，但在顺序一致性下不可能。$O_{MP}$ 仅在释放一致性下可能发生。为禁止 $O_{SB}$，在每个核心的存储与其后续加载之间放置一个屏障。为在释放一致性下禁止 $O_{MP}$，在核心 $0$ 的 $x \\leftarrow 1$ 和 $y \\leftarrow 1$ 之间放置一个释放屏障（release fence），并在核心 $1$ 的 $r_1 \\leftarrow y$ 和 $r_2 \\leftarrow x$ 之间放置一个获取屏障（acquire fence）。\n\nB. $O_{SB}$ 仅在释放一致性下可能发生；全局存储定序和顺序一致性禁止它。$O_{MP}$ 在释放一致性和全局存储定序下可能发生。在全局存储定序下，不需要屏障来禁止这两种结果。\n\nC. $O_{SB}$ 仅在全局存储定序下可能发生；释放一致性和顺序一致性禁止它。$O_{MP}$ 在顺序一致性和释放一致性下可能发生。在每次加载后放置一个屏障（在存储和加载之间没有屏障）足以禁止这两种结果。\n\nD. $O_{SB}$ 在释放一致性和全局存储定序下可能发生，在顺序一致性下不可能。$O_{MP}$ 在释放一致性和全局存储定序下可能发生。为禁止这两种结果，在两个核心的每次存储之前都放置屏障。", "solution": "我们根据多核处理器上下文中内存模型的标准定义进行推理：\n\n- 顺序一致性 (SC)：所有内存操作看起来都像是以一个单一的、与每个核心的程序顺序一致的全局总序来执行的。等价地，存在一个所有操作的线性化序列，使得每个核心的操作都按其程序顺序出现，并且每次加载都从该地址在全局顺序中的最近一次存储中读取数据。\n\n- 全局存储定序 (TSO)：每个核心的写入操作都会被缓冲，从而对其他核心保留了存储到存储的程序顺序可见性，而加载操作可以绕过同一核心上对不同地址的旧存储操作。这允许在同一核心上进行存储到加载的重排序。加载到加载、加载到存储以及存储到存储的程序顺序在可见性方面是保留的；但是，一次加载可能会看到过时的数据，因为它自己之前对另一个地址的存储可能仍驻留在存储缓冲区中。\n\n- 释放一致性 (RC)：普通的加载和存储操作可以自由重排序，除非受到显式同步操作的约束。释放操作（或释放屏障）确保在释放之前的所有内存操作都变得可见，而获取操作（或获取屏障）确保后续的内存操作不会重排到获取操作之前。没有这些操作，跨地址的顺序是无法保证的。\n\n我们现在分析每个测试。\n\n对测试 $SB$ 的分析：\n\n程序：\n- 核心 $0$：$x \\leftarrow 1$；$r_0 \\leftarrow y$。\n- 核心 $1$：$y \\leftarrow 1$；$r_1 \\leftarrow x$。\n观测 $O_{SB}$：$r_0 = 0$ 且 $r_1 = 0$。\n\n- 在 SC 模型下：假设 $r_0 = 0$。那么在全局顺序中，核心 $0$ 对 $y$ 的加载必须发生在核心 $1$ 的存储 $y \\leftarrow 1$ 之前。类似地，如果 $r_1 = 0$，那么在全局顺序中，核心 $1$ 对 $x$ 的加载必须发生在核心 $0$ 的存储 $x \\leftarrow 1$ 之前。要使两者同时为真，全局顺序将要求核心 $0$ 对 $y$ 的加载在核心 $1$ 对 $y$ 的存储之前，并且核心 $1$ 对 $x$ 的加载在核心 $0$ 对 $x$ 的存储之前。但 SC 也要求每个核心的存储操作在其后续的加载操作之前，以遵守程序顺序。因此，核心 $0$ 的全局顺序必须是 $x \\leftarrow 1$ 在 $r_0 \\leftarrow y$ 之前，而核心 $1$ 的全局顺序必须是 $y \\leftarrow 1$ 在 $r_1 \\leftarrow x$ 之前。这些约束排除了两个加载都读到 $0$ 的可能性：至少有一个加载必须在另一个核心的存储之后发生，从而读到 $1$。因此，在 SC 模型下，$O_{SB}$ 是被禁止的。\n\n- 在 TSO 模型下：每个核心对一个地址的存储可以保留在其存储缓冲区中，而后续对另一个地址的加载操作则执行并绕过缓冲的存储。一个允许的执行过程是：\n  - 核心 $0$ 执行 $x \\leftarrow 1$（被缓冲，尚未全局可见），然后 $r_0 \\leftarrow y$ 读取 $0$，因为核心 $1$ 的存储 $y \\leftarrow 1$ 也被缓冲了。\n  - 核心 $1$ 执行 $y \\leftarrow 1$（被缓冲），然后 $r_1 \\leftarrow x$ 读取 $0$，因为核心 $0$ 的存储 $x \\leftarrow 1$ 也被缓冲了。\n  在任一缓冲的存储刷新到内存之前，两个加载都读取了 $0$。这是 TSO 允许的典型的存储到加载重排序，因此在 TSO 模型下，$O_{SB}$ 是允许的。\n\n- 在 RC 模型下：如果没有获取/释放同步，对不同地址的普通存储和加载可以自由重排序。两个核心都可以先执行加载，再执行存储，而存储操作对另一个核心还不可见，从而允许两个加载都读到 $0$。因此，在 RC 模型下，$O_{SB}$ 是允许的。\n\n测试 $SB$ 的屏障：\n为禁止 $O_{SB}$，需在每个核心上确保存储操作在后续的加载操作之前变得可见。在 TSO 模型下，在核心 $0$ 的 $x \\leftarrow 1$ 和 $r_0 \\leftarrow y$ 之间，以及在核心 $1$ 的 $y \\leftarrow 1$ 和 $r_1 \\leftarrow x$ 之间放置一个完整的内存屏障（例如 $mfence$），会强制存储缓冲区在加载执行前清空，从而消除产生 $O_{SB}$ 的存储到加载重排序。在 RC 模型下，在每个核心的存储和其后续加载之间放置一个适当的屏障同样可以使存储在其后续加载之前定序。仅在一个核心上放置屏障是不够的：未设置屏障的核心仍然可以在另一个核心的存储变得可见之前执行其加载操作，而设置了屏障的核心的加载仍然可能读到 $0$（如果未设置屏障的核心的存储被缓冲了），因此两个加载仍然可能观测到 $0$。因此，在每个核心的存储和后续加载之间各放置一个屏障是最小且必要的。\n\n对测试 $MP$ 的分析：\n\n程序：\n- 核心 $0$：$x \\leftarrow 1$；$y \\leftarrow 1$。\n- 核心 $1$：$r_1 \\leftarrow y$；$r_2 \\leftarrow x$。\n观测 $O_{MP}$：$r_1 = 1$ 且 $r_2 = 0$。\n\n意图：使用 $y$ 作为标志，指示 $x$ 已被写入；如果消费者看到 $y = 1$，它也应该能看到 $x = 1$。\n\n- 在 SC 模型下：核心 $0$ 的程序顺序，$x \\leftarrow 1$ 在 $y \\leftarrow 1$ 之前，必须在全局顺序中得以保留。如果核心 $1$ 的 $r_1 \\leftarrow y$ 返回 $1$，那么在全局顺序中，$y \\leftarrow 1$ 位于该加载之前。由于在同一个全局顺序中，$x \\leftarrow 1$ 比 $y \\leftarrow 1$ 更早，因此 $x \\leftarrow 1$ 也必须在 $r_2 \\leftarrow x$ 之前可见，所以 $r_2$ 不可能为 $0$。因此，在 SC 模型下，$O_{MP}$ 是被禁止的。\n\n- 在 TSO 模型下：TSO 对其他核心保留了存储到存储的顺序可见性；来自一个核心的存储操作是按程序顺序被全局观测到的。因此，如果核心 $1$ 看到 $y=1$，那么存储 $y \\leftarrow 1$ 必定已被观测到，并且因为在核心 $0$ 的程序顺序中 $x \\leftarrow 1$ 先于 $y \\leftarrow 1$，所以 $x \\leftarrow 1$ 此时也必须对核心 $1$ 可见。因此，如果 $r_1 = 1$，则 $r_2$ 不可能为 $0$，于是在 TSO 模型下，$O_{MP}$ 是被禁止的。\n\n- 在 RC 模型下：如果没有释放/获取同步，核心 $0$ 对 $x$ 和 $y$ 的存储可以以任意顺序对核心 $1$ 可见。核心 $1$ 可能先观测到 $y = 1$（标志已设置），但同时仍然观测到 $x = 0$（数据尚不可见），从而导致 $r_1 = 1$ 和 $r_2 = 0$。因此，在没有同步的情况下，RC 模型允许 $O_{MP}$。\n\n测试 $MP$ 的屏障：\n在 RC 模型下，为强制实现“看到标志意味着看到数据”的预期顺序：\n- 在核心 $0$ 的 $x \\leftarrow 1$ 和 $y \\leftarrow 1$ 之间放置一个释放屏障（release fence）。这确保了所有先前的普通写入（包括 $x \\leftarrow 1$）在释放操作或任何后续对 $y$ 的释放存储被观测到之前变得可见。\n- 在核心 $1$ 的 $r_1 \\leftarrow y$ 和 $r_2 \\leftarrow x$ 之间放置一个获取屏障（acquire fence）。这确保了在观测到 $y = 1$ 之后，后续的加载（包括 $r_2 \\leftarrow x$）不会被重排到获取操作之前，并且它们会观测到与生产者释放操作一致的内存，使得 $x=1$ 可见。\n这些屏障是最小的，因为在 RC 模型下，移除释放屏障或获取屏障中的任何一个都可能重新引入 $O_{MP}$。\n\n逐个选项分析：\n\nA. 论述：$O_{SB}$ 在释放一致性和全局存储定序下可能发生，但在顺序一致性下不可能；$O_{MP}$ 仅在释放一致性下可能发生；按规定放置屏障（在 $SB$ 中，每个存储和后续加载之间放置一个；在 $MP$ 中，围绕标志变量使用释放-获取屏障）可以禁止这些结果。这与上述分析相符。结论 — 正确。\n\nB. 论述：$O_{SB}$ 仅在释放一致性下发生；全局存储定序禁止它。这与 TSO 分析相矛盾，在 TSO 中，存储到加载的重排序会产生 $O_{SB}$。还声称 $O_{MP}$ 在全局存储定序下可能发生，这是错误的，因为 TSO 保留了存储到存储的顺序可见性。结论 — 错误。\n\nC. 论述：$O_{SB}$ 仅在全局存储定序下发生；释放一致性和顺序一致性禁止它。这是错误的：RC 也允许 $O_{SB}$，而 SC 禁止它。此外，它建议在每次加载后放置屏障就足够了，但在加载后放置屏障并不能使之前的存储在加载之前定序；因此它不能阻止 $O_{SB}$ 或强制实现 $MP$ 的顺序。结论 — 错误。\n\nD. 论述：$O_{SB}$ 在释放一致性和全局存储定序下可能发生（到此为止正确），而 $O_{MP}$ 在释放一致性和全局存储定序下可能发生（错误，因为 TSO 禁止 $O_{MP}$）。它还提议在每次存储前放置屏障，但这并不能使存储在其后续的加载之前定序，也无法强制实现 $MP$ 所需的线程间释放-获取语义。结论 — 错误。\n\n因此，选项 A 是唯一正确的选择。", "answer": "$$\\boxed{A}$$", "id": "3660971"}, {"introduction": "掌握了底层的数据布局与内存排序规则后，我们可以将目光投向更高层次的并行算法设计，以实现真正的可扩展性。一个常见的并行编程任务，如对全局计数器进行递增，在多核环境下会因锁的串行化而迅速成为性能瓶颈。本练习 [@problem_id:3660990] 引导我们分析一种高效的设计模式：将共享数据分片（sharding），让每个核心在本地副本上操作，并周期性地将结果合并回全局状态。通过对这种模式进行性能建模，你将学会如何量化其吞吐量，并亲身感受优秀的软件架构所带来的巨大性能提升。", "problem": "考虑一个芯片多处理器，其上有 $N=8$ 个相同的核心，运行时钟频率为 $f = 3.2\\,\\mathrm{GHz}$。一个工作负载重复地对一个全局计数器进行增量操作。现有两种实现方式：\n\n- 基准实现：一个单一的共享计数器，在一个由自旋锁保护的临界区内进行更新。在稳态下，每次增量操作的临界区的串行化服务时间（包括加锁/解锁和一致性效应）为 $t_{s} = 120$ 个时钟周期。假设这使得基准吞吐量完全受串行化限制。\n\n- 重构实现：每个核心维护一个私有的核心专属计数器，并执行本地增量操作，每次增量操作的成本为 $t_{\\ell} = 6$ 个时钟周期。在每个核心上每执行一批 $K$ 次本地增量操作后，一个合并例程会获取同一个自旋锁，并将该批次的增量值加到全局计数器上。合并操作的串行化服务时间是一个未知的常数 $m$ 个时钟周期，且与 $K$ 无关。假设合并操作完全由该锁串行化，并且在稳态下，系统除了串行化区域的服务时间外，沒有额外的排队延迟。\n\n当以 $K = 100$ 运行重构实现时，测得的聚合稳态吞吐量为 $R_{100} = 150 \\times 10^{6}$ 次增量/秒，并且硬件性能计数器表明锁已饱和（合并操作是瓶颈）。\n\n任务：\n- 从吞吐量是每次操作平均时间倒数的基本定义出发，并利用任何完全串行化的区域都会施加一个等于其服务容量的上限这一概念，推导重构实现的聚合吞吐量 $R(K)$ 作为 $N$、$f$、$t_{\\ell}$、$m$ 和 $K$ 的函数表达式。\n- 利用 $K=100$ 时的测量数据和所述的瓶颈条件，估算合并服务时间 $m$（以时钟周期为单位）。\n- 使用相同的 $m$，在相同假设下预测 $K=400$ 时的聚合吞吐量，然后计算重构实现相对于基准实现的吞吐量增益 $G$，定义为 $G = \\dfrac{R_{400}}{R_{\\mathrm{base}}}$。\n\n将 $m$ 以时钟周期表示，$G$ 以无量纲比率表示。将 $m$ 和 $G$ 两者均四舍五入至三位有效数字。最终答案必须在一行中以 $\\bigl[m,\\,G\\bigr]$ 的顺序列出两个值。", "solution": "用户希望我解决一个关于芯片多处理器性能的计算机体系结构多部分问题。我将首先验证问题陈述，如果问题被认为是有效的，则继续进行完整解答。\n\n### 第一步：提取已知条件\n- 核心数：$N=8$\n- 时钟频率：$f = 3.2\\,\\mathrm{GHz} = 3.2 \\times 10^9\\,\\mathrm{s}^{-1}$\n- 基准串行化服务时间：$t_s = 120$ 个时钟周期\n- 重构的本地增量成本：$t_{\\ell} = 6$ 个时钟周期\n- 重构的合并串行化服务时间：$m$ 个时钟周期（未知）\n- 批次大小：$K$ 次增量\n- 当 $K=100$ 时，测得的聚合吞吐量为 $R_{100} = 150 \\times 10^6$ 次增量/秒。\n- 当 $K=100$ 时，系统受串行化限制（锁饱和）。\n- 基准吞吐量完全受串行化限制。\n- 系统在服务时间之外没有额外的排队延迟。\n\n### 第二步：使用提取的已知条件进行验证\n该问题在科学上植根于计算机体系结构的原理，特别是多核处理器性能、竞争和串行化。所使用的概念——如时钟频率、时钟周期、吞吐量、自旋锁和临界区——都是标准且定义明确的。给定的数值对于现代硬件是合理的。问题陈述清晰，提供了明确的目标和足够的数据来推导未知数。语言客观且正式。所提供的假设（例如，“完全受串行化限制”、“没有额外排队”）用于创建一个简化但一致的分析模型，这是一种常见且有效的教学方法。该问题没有违反任何无效性标准。\n\n### 第三步：结论与行动\n问题有效。我将继续进行解答。\n\n### 详细解答\n\n问题要求推导吞吐量表达式，估算未知参数 $m$，并预测性能增益。问题的核心在于将系统吞吐量建模为受其瓶颈组件限制。\n\n#### 第一部分：聚合吞吐量 $R(K)$ 的推导\n\n重构实现涉及两个不同的工作阶段：\n1.  **本地增量**：$N$ 个核心中的每一个都对其私有计数器执行增量操作。这部分工作是并行的。\n2.  **全局合并**：在一批 $K$ 次本地增量之后，每个核心必须获取一个全局锁，以将其本地计数合并到全局计数器中。这部分工作是串行的。\n\n系统的总吞吐量由这两个阶段吞吐量容量的最小值决定。这类似于一个流水线，其总速率由最慢的阶段决定。\n\n**并行阶段（本地增量）的容量：**\n单个核心每 $t_{\\ell}$ 个时钟周期可以执行一次本地增量。因此，一个核心的增量速率为每秒 $\\frac{f}{t_{\\ell}}$ 次增量。在 $N$ 个核心并行操作的情况下，如果只有这一个阶段，最大聚合吞吐量将是：\n$$R_{\\mathrm{parallel}} = N \\frac{f}{t_{\\ell}}$$\n\n**串行阶段（全局合并）的容量：**\n单个合并操作需要 $m$ 个时钟周期，并由一个锁进行串行化。这意味着系统最多每 $m$ 个时钟周期可以完成一次合并。合并的最大速率是每秒 $\\frac{f}{m}$ 次合并。每次合并操作对应于一批 $K$ 次本地增量的完成。因此，如果受合并过程限制，最大聚合吞吐量为：\n$$R_{\\mathrm{serial}}(K) = K \\left(\\frac{f}{m}\\right) = \\frac{K f}{m}$$\n\n**总吞吐量 $R(K)$：**\n整个系统的稳态聚合吞吐量 $R(K)$是并行和串行阶段容量的最小值。\n$$R(K) = \\min\\left(R_{\\mathrm{parallel}}, R_{\\mathrm{serial}}(K)\\right) = \\min\\left(\\frac{N f}{t_{\\ell}}, \\frac{K f}{m}\\right)$$\n这也可以写作：\n$$R(K) = f \\cdot \\min\\left(\\frac{N}{t_{\\ell}}, \\frac{K}{m}\\right)$$\n这个表达式表示了聚合吞吐量作为给定参数的函数。\n\n#### 第二部分：合并服务时间 $m$ 的估算\n\n我们已知当批次大小为 $K=100$ 时，测得的吞吐量为 $R_{100} = 150 \\times 10^6$ 次增量/秒，并且在该工作点，“锁已饱和”。饱和的锁意味着串行阶段是瓶颈。这意味着：\n$$R_{100} = R_{\\mathrm{serial}}(100) = \\frac{100 f}{m}$$\n我们可以重新整理这个方程来求解未知的合并服务时间 $m$：\n$$m = \\frac{100 f}{R_{100}}$$\n代入给定值：\n$$m = \\frac{100 \\cdot (3.2 \\times 10^9\\,\\mathrm{s}^{-1})}{150 \\times 10^6\\,\\mathrm{s}^{-1}} = \\frac{3.2 \\times 10^{11}}{1.5 \\times 10^8} = \\frac{3.2}{1.5} \\times 10^3 \\approx 2133.33\\,\\text{cycles}$$\n四舍五入到三位有效数字，我们得到：\n$$m \\approx 2.13 \\times 10^3\\,\\text{cycles}$$\n\n我们应该验证饱和条件。如果 $\\frac{N}{t_{\\ell}} \\geq \\frac{K}{m}$，则系统受串行化限制。\n使用我们计算出的 $m$：\n$$\\frac{N}{t_{\\ell}} = \\frac{8}{6} \\approx 1.333$$\n$$\\frac{K}{m} = \\frac{100}{2133.33...} \\approx 0.046875$$\n由于 $1.333 > 0.046875$，条件 $\\frac{N}{t_{\\ell}} > \\frac{K}{m}$ 成立，证实了对于 $K=100$ 的情况，锁确实是瓶颈。\n\n#### 第三部分：吞吐量增益 $G$ 的预测\n\n首先，我们预测 $K=400$ 时的聚合吞吐量，记为 $R_{400}$。使用推导出的 $R(K)$ 表达式和估算出的 $m$ 值：\n$$R_{400} = R(400) = f \\cdot \\min\\left(\\frac{N}{t_{\\ell}}, \\frac{400}{m}\\right)$$\n我们比较最小值函数内部的两项：\n$$\\frac{N}{t_{\\ell}} = \\frac{8}{6} \\approx 1.333$$\n$$\\frac{400}{m} = \\frac{400}{2133.33...} \\approx 0.1875$$\n由于 $1.333 > 0.1875$，串行部分仍然是瓶颈。因此：\n$$R_{400} = \\frac{400 f}{m}$$\n我们可以相对于 $R_{100}$ 来计算它：\n$$R_{400} = \\frac{400 f}{m} = 4 \\cdot \\left(\\frac{100 f}{m}\\right) = 4 \\cdot R_{100}$$\n$$R_{400} = 4 \\cdot (150 \\times 10^6\\,\\mathrm{s}^{-1}) = 600 \\times 10^6\\,\\mathrm{s}^{-1}$$\n\n接下来，我们计算基准吞吐量 $R_{\\mathrm{base}}$。问题陈述中指出，基准实现完全受服务时间为 $t_s = 120$ 个时钟周期的临界区限制。\n$$R_{\\mathrm{base}} = \\frac{f}{t_s} = \\frac{3.2 \\times 10^9\\,\\mathrm{s}^{-1}}{120} = \\frac{32 \\times 10^8}{120} = \\frac{8}{3} \\times 10^7\\,\\mathrm{s}^{-1}$$\n$$R_{\\mathrm{base}} \\approx 26.67 \\times 10^6\\,\\mathrm{s}^{-1}$$\n\n最后，我们计算当 $K=400$ 时，重构实现相对于基准实现的吞吐量增益 $G$。\n$$G = \\frac{R_{400}}{R_{\\mathrm{base}}} = \\frac{600 \\times 10^6\\,\\mathrm{s}^{-1}}{\\frac{8}{3} \\times 10^7\\,\\mathrm{s}^{-1}}$$\n$$G = \\frac{60 \\times 10^7}{\\frac{8}{3} \\times 10^7} = \\frac{60 \\cdot 3}{8} = \\frac{180}{8} = \\frac{45}{2} = 22.5$$\n值 $22.5$ 具有三位有效数字。\n\n最终值为 $m \\approx 2.13 \\times 10^3$ 个时钟周期和 $G = 22.5$。", "answer": "$$ \\boxed{[2.13 \\times 10^3, 22.5]} $$", "id": "3660990"}]}