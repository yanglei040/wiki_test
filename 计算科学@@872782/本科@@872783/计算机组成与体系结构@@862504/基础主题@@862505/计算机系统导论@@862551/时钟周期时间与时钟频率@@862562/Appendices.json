{"hands_on_practices": [{"introduction": "在运用时钟频率来分析性能之前，我们首先要理解这个基本参数的物理来源。处理器的最高时钟频率并非任意设定，它受到信号在电子电路中传播延迟的物理限制，特别是在最慢的流水线阶段。这项实践将引导你解决一个流水线平衡问题，这是数字设计中的一项核心任务，帮助你理解决定CPU时钟速度的物理约束，以及为什么设计者致力于创建深度均衡的流水线阶段。[@problem_id:3627441]", "problem": "同步流水线是通过在固定的组合逻辑块序列之间插入触发器寄存器来构建的，因此每个流水线阶段都包含一个连续的块子序列。一个阶段内的路径延迟是分配给该阶段的块的延迟之和。时钟周期必须足够长，以使发送的数据能够传播通过最慢的阶段，并满足接收寄存器的捕获要求，同时要考虑到寄存器时序开销，例如时钟到输出延迟、建立时间和时钟偏斜/不确定性。假设保持时间约束已通过设计满足，并且互连延迟已包含在每个给定块的延迟中。\n\n给定一个由 $8$ 个按固定顺序排列的组合逻辑块组成的严格前馈数据路径。门级时序分析报告了这些块按顺序的最坏情况传播延迟（单位：纳秒）如下：\n$1.4$, $0.9$, $0.7$, $1.1$, $0.6$, $0.8$, $1.0$, $0.5$。\n\n您可以插入恰好 $2$ 组寄存器以形成 $d=3$ 个流水线阶段，且各阶段必须由按给定顺序排列的连续块组构成。每个阶段间寄存器都会带来以下开销：时钟到输出延迟为 $0.10\\,\\mathrm{ns}$，建立时间为 $0.05\\,\\mathrm{ns}$，以及时钟偏斜/不确定性预算为 $0.02\\,\\mathrm{ns}$。假设所有阶段的开销都相同。\n\n哪个选项给出了一个将电路划分为 $3$ 个阶段的最佳连续划分方案，该方案能最小化每个阶段的最大组合延迟，并基于此给出最小可实现的时钟周期和相应的最大时钟频率？请以吉赫兹 (GHz) 和兆赫兹 (MHz) 为单位报告时钟频率，其中吉赫兹 (GHz) 和兆赫兹 (MHz) 分别表示每秒 $10^{9}$ 和 $10^{6}$ 个周期。\n\nA. 划分: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$。最小可实现的时钟周期 $T_{\\min}=2.57\\,\\mathrm{ns}$；最大时钟频率 $f_{\\max}\\approx 0.389\\,\\mathrm{GHz}=389\\,\\mathrm{MHz}$。\n\nB. 划分: $\\{1.4,\\,0.9,\\,0.7\\}\\,|\\,\\{1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$。最小可实现的时钟周期 $T_{\\min}=3.17\\,\\mathrm{ns}$；最大时钟频率 $f_{\\max}\\approx 0.316\\,\\mathrm{GHz}=316\\,\\mathrm{MHz}$。\n\nC. 划分: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1\\}\\,|\\,\\{0.6,\\,0.8,\\,1.0,\\,0.5\\}$。最小可实现的时钟周期 $T_{\\min}=3.07\\,\\mathrm{ns}$；最大时钟频率 $f_{\\max}\\approx 0.326\\,\\mathrm{GHz}=326\\,\\mathrm{MHz}$。\n\nD. 划分: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$。最小可实现的时钟周期 $T_{\\min}=2.40\\,\\mathrm{ns}$；最大时钟频率 $f_{\\max}\\approx 0.417\\,\\mathrm{GHz}=417\\,\\mathrm{MHz}$。", "solution": "该问题要求找到一个将 8 个组合逻辑块序列划分为 3 个连续流水线阶段的最佳方案，以最小化时钟周期。最小可实现的时钟周期由最慢的阶段决定，即具有最大总延迟的阶段。一个阶段的总延迟包括其组合逻辑的传播延迟和与流水线寄存器相关的开销。\n\n首先，我们验证问题陈述。\n\n### 步骤 1：提取已知条件\n- 组合逻辑块数量：$n=8$。\n- 块的顺序传播延迟（$t_1, \\dots, t_8$），单位为纳秒（$\\mathrm{ns}$）：$1.4$, $0.9$, $0.7$, $1.1$, $0.6$, $0.8$, $1.0$, $0.5$。\n- 流水线阶段数量：$d=3$。这需要插入 2 组寄存器。\n- 阶段必须由连续的块组成。\n- 寄存器时序开销（所有阶段相同）：\n  - 时钟到输出延迟, $t_{CQ} = 0.10\\,\\mathrm{ns}$。\n  - 建立时间, $t_{setup} = 0.05\\,\\mathrm{ns}$。\n  - 时钟偏斜/不确定性, $t_{skew} = 0.02\\,\\mathrm{ns}$。\n- 目标是找到能最小化每个阶段最大组合延迟的划分方案，然后计算可实现的最小时钟周期（$T_{\\min}$）和最大时钟频率（$f_{\\max}$）。\n\n### 步骤 2：使用提取的已知条件进行验证\n问题陈述在科学上是合理的、提法恰当且客观的。它描述了数字流水线设计中的一个标准优化问题。所使用的概念（组合延迟、寄存器开销、时钟周期）是计算机体系结构的基础。提供的值是现实的。所有必要的信息都已给出，且没有矛盾。该问题是有效的。\n\n### 步骤 3：求解推导\n\n第一步是找到将 8 个块划分为 3 个连续阶段的最佳方案。一个划分由两个切割点定义。设第一个切割点在块 $i$ 之后，第二个在块 $j$ 之后，其中 $1 \\le i  j  8$。三个阶段将分别由块 $\\{1, \\dots, i\\}$、$\\{i+1, \\dots, j\\}$ 和 $\\{j+1, \\dots, 8\\}$ 组成。我们需要找到划分 $(i, j)$，以最小化三个阶段中的最大组合延迟。设 $T_k$ 为阶段 $k$ 的组合延迟。我们想要找到 $\\min_{partitions} \\max(T_1, T_2, T_3)$。\n\n块的延迟为 $t_1=1.4$, $t_2=0.9$, $t_3=0.7$, $t_4=1.1$, $t_5=0.6$, $t_6=0.8$, $t_7=1.0$, $t_8=0.5$（单位均为 $\\mathrm{ns}$）。总组合延迟为 $1.4+0.9+0.7+1.1+0.6+0.8+1.0+0.5 = 7.0\\,\\mathrm{ns}$。\n\n让我们评估这些划分方案，重点关注选项中提出的方案，以找到具有最小最大阶段延迟的方案。\n\n1.  **选项 A 和 D 的划分:** $\\{1.4, 0.9\\} | \\{0.7, 1.1, 0.6\\} | \\{0.8, 1.0, 0.5\\}$\n    - 阶段 1 延迟: $T_1 = 1.4 + 0.9 = 2.3\\,\\mathrm{ns}$。\n    - 阶段 2 延迟: $T_2 = 0.7 + 1.1 + 0.6 = 2.4\\,\\mathrm{ns}$。\n    - 阶段 3 延迟: $T_3 = 0.8 + 1.0 + 0.5 = 2.3\\,\\mathrm{ns}$。\n    - 此划分的最大组合延迟为 $t_{max\\_comb} = \\max(2.3, 2.4, 2.3) = 2.4\\,\\mathrm{ns}$。\n\n2.  **选项 B 的划分:** $\\{1.4, 0.9, 0.7\\} | \\{1.1, 0.6\\} | \\{0.8, 1.0, 0.5\\}$\n    - 阶段 1 延迟: $T_1 = 1.4 + 0.9 + 0.7 = 3.0\\,\\mathrm{ns}$。\n    - 阶段 2 延迟: $T_2 = 1.1 + 0.6 = 1.7\\,\\mathrm{ns}$。\n    - 阶段 3 延迟: $T_3 = 0.8 + 1.0 + 0.5 = 2.3\\,\\mathrm{ns}$。\n    - 此划分的最大组合延迟为 $t_{max\\_comb} = \\max(3.0, 1.7, 2.3) = 3.0\\,\\mathrm{ns}$。\n\n3.  **选项 C 的划分:** $\\{1.4, 0.9\\} | \\{0.7, 1.1\\} | \\{0.6, 0.8, 1.0, 0.5\\}$\n    - 阶段 1 延迟: $T_1 = 1.4 + 0.9 = 2.3\\,\\mathrm{ns}$。\n    - 阶段 2 延迟: $T_2 = 0.7 + 1.1 = 1.8\\,\\mathrm{ns}$。\n    - 阶段 3 延迟: $T_3 = 0.6 + 0.8 + 1.0 + 0.5 = 2.9\\,\\mathrm{ns}$。\n    - 此划分的最大组合延迟为 $t_{max\\_comb} = \\max(2.3, 1.8, 2.9) = 2.9\\,\\mathrm{ns}$。\n\n比较最大组合延迟：$2.4\\,\\mathrm{ns}$（对于划分 A/D），$3.0\\,\\mathrm{ns}$（对于 B），和 $2.9\\,\\mathrm{ns}$（对于 C）。来自 A/D 的划分产生了可能的最小最大阶段延迟。更详尽的搜索将确认 $2.4\\,\\mathrm{ns}$ 确实是最佳值。例如，一个在块 2 和 5 之后切割的划分 $\\{1.4, 0.9\\}, \\{0.7, 1.1, 0.6\\}, \\{0.8, 1.0, 0.5\\}$ 产生的延迟为 $\\{2.3, 2.4, 2.3\\}$，其最大值为 $2.4$。另一个划分 $\\{1.4\\}, \\{0.9, 0.7, 1.1\\}, \\{0.6, 0.8, 1.0, 0.5\\}$ 产生的延迟为 $\\{1.4, 2.7, 2.9\\}$，其最大值为 $2.9$。来自 A/D 的划分确实是最佳的。\n\n问题要求基于此最佳划分计算可实现的最小时钟周期。最小时钟周期 $T_{\\min}$ 的公式是最大组合阶段延迟与总寄存器开销之和：\n$$T_{\\min} = t_{max\\_comb} + t_{CQ} + t_{setup} + t_{skew}$$\n总寄存器开销为：\n$$t_{overhead} = 0.10\\,\\mathrm{ns} + 0.05\\,\\mathrm{ns} + 0.02\\,\\mathrm{ns} = 0.17\\,\\mathrm{ns}$$\n使用最佳的最大组合延迟 $t_{max\\_comb} = 2.4\\,\\mathrm{ns}$：\n$$T_{\\min} = 2.4\\,\\mathrm{ns} + 0.17\\,\\mathrm{ns} = 2.57\\,\\mathrm{ns}$$\n可实现的最大时钟频率 $f_{\\max}$ 是最小时钟周期的倒数：\n$$f_{\\max} = \\frac{1}{T_{\\min}} = \\frac{1}{2.57 \\times 10^{-9}\\,\\mathrm{s}}$$\n$$f_{\\max} \\approx 0.389105... \\times 10^9\\,\\mathrm{Hz}$$\n转换为吉赫兹 (GHz) 和兆赫兹 (MHz)：\n$$f_{\\max} \\approx 0.389\\,\\mathrm{GHz} = 389\\,\\mathrm{MHz}$$\n\n现在，我们根据这些计算来评估每个选项。\n\n### 逐项分析\n\n**A. 划分: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$。最小可实现的时钟周期 $T_{\\min}=2.57\\,\\mathrm{ns}$；最大时钟频率 $f_{\\max}\\approx 0.389\\,\\mathrm{GHz}=389\\,\\mathrm{MHz}$。**\n- **划分:** 这是最小化最大组合阶段延迟 ($2.4\\,\\mathrm{ns}$) 的最佳划分。\n- **最小时钟周期:** 计算出的 $T_{\\min} = 2.57\\,\\mathrm{ns}$ 与此选项中给出的值相匹配。\n- **最大时钟频率:** 计算出的 $f_{\\max} \\approx 0.389\\,\\mathrm{GHz}=389\\,\\mathrm{MHz}$ 也与给出的值相匹配。\n- **结论:** 正确。\n\n**B. 划分: $\\{1.4,\\,0.9,\\,0.7\\}\\,|\\,\\{1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$。最小可实现的时钟周期 $T_{\\min}=3.17\\,\\mathrm{ns}$；最大时钟频率 $f_{\\max}\\approx 0.316\\,\\mathrm{GHz}=316\\,\\mathrm{MHz}$。**\n- **划分:** 这个划分不是最优的。它的最大组合延迟是 $3.0\\,\\mathrm{ns}$，大于最优值 $2.4\\,\\mathrm{ns}$。因此，它不会得到最小可实现的时钟周期。给出的数字（$T_{\\min} = 3.0\\,\\mathrm{ns} + 0.17\\,\\mathrm{ns} = 3.17\\,\\mathrm{ns}$ 和 $f_{\\max} = 1/3.17\\,\\mathrm{ns} \\approx 0.316\\,\\mathrm{GHz}$）对于这个特定的划分是一致的，但这个划分本身是次优的。\n- **结论:** 错误。\n\n**C. 划分: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1\\}\\,|\\,\\{0.6,\\,0.8,\\,1.0,\\,0.5\\}$。最小可实现的时钟周期 $T_{\\min}=3.07\\,\\mathrm{ns}$；最大时钟频率 $f_{\\max}\\approx 0.326\\,\\mathrm{GHz}=326\\,\\mathrm{MHz}$。**\n- **划分:** 这个划分不是最优的。它的最大组合延迟是 $2.9\\,\\mathrm{ns}$，大于最优值 $2.4\\,\\mathrm{ns}$。它不会得到最小可实现的时钟周期。与选项 B 类似，后续的计算（$T_{\\min} = 2.9\\,\\mathrm{ns} + 0.17\\,\\mathrm{ns} = 3.07\\,\\mathrm{ns}$ 和 $f_{\\max} = 1/3.07\\,\\mathrm{ns} \\approx 0.326\\,\\mathrm{GHz}$）对于给定的次优划分是一致的，但这并不能回答问题。\n- **结论:** 错误。\n\n**D. 划分: $\\{1.4,\\,0.9\\}\\,|\\,\\{0.7,\\,1.1,\\,0.6\\}\\,|\\,\\{0.8,\\,1.0,\\,0.5\\}$。最小可实现的时钟周期 $T_{\\min}=2.40\\,\\mathrm{ns}$；最大时钟频率 $f_{\\max}\\approx 0.417\\,\\mathrm{GHz}=417\\,\\mathrm{MHz}$。**\n- **划分:** 这是正确的最佳划分。\n- **最小时钟周期:** 给出的值是 $T_{\\min} = 2.40\\,\\mathrm{ns}$。这是最大组合延迟 $t_{max\\_comb}$，但它错误地忽略了 $0.17\\,\\mathrm{ns}$ 的总寄存器开销。正确的的最小时钟周期是 $2.57\\,\\mathrm{ns}$。\n- **最大时钟频率:** 给出的频率是基于不正确的周期：$1/(2.40\\,\\mathrm{ns}) \\approx 0.417\\,\\mathrm{GHz}$。由于周期不正确，频率也就不正确。\n- **结论:** 错误。\n\n根据分析，只有选项 A 提供了正确的最佳划分方案以及由此正确计算出的最小时钟周期和最大时钟频率。", "answer": "$$\\boxed{A}$$", "id": "3627441"}, {"introduction": "一旦确定了时钟频率，我们就可以用它将抽象的性能指标（如“时钟周期数”）转换为具体的时间单位。$T = 1/f$ 这个关系是连接处理器内部节拍（周期）和我们所经历的真实时间（挂钟时间）的桥梁。这个练习将巩固你对时钟频率和周期时间之间关系的理解，并将其应用于一个真实的内存层级结构中，通过计算内存访问的期望时间来培养性能分析的关键技能。[@problem_id:3627533]", "problem": "中央处理器 (CPU) 在离散的时钟周期内执行指令。根据定义，时钟频率 $f$ 是每秒完成的周期数，而周期时间 $T$ 是一个周期的持续时间，以秒为单位。\n\n考虑一台机器，其缓存层次结构具有以下以周期为单位测量的延迟行为：一级 (L1) 缓存命中需要 $4$ 个周期，二级 (L2) 缓存命中需要 $12$ 个周期，三级 (L3) 缓存命中需要 $40$ 个周期，而未命中转而访问动态随机存取存储器 (DRAM) 需要 $200$ 个周期。对于一个特定的工作负载，内存访问在各级缓存命中或访问 DRAM 的概率分别为：L1 为 $0.92$，L2 为 $0.06$，L3 为 $0.015$，DRAM 为 $0.005$。每次循环迭代包含一个需要 $6$ 个周期的计算阶段和一次遵循这些概率的内存访问。\n\n任务：\n1. 从上述定义出发，推导出一个关联周期时间 $T$ 和时钟频率 $f$ 的表达式。\n2. 使用你的表达式，确定当 $f \\in \\{1,2,3,4\\}\\ \\mathrm{GHz}$ 时，周期时间 $T$ 的值。\n3. 当 $f=3\\ \\mathrm{GHz}$ 时，以周期和纳秒为单位解释缓存和内存事件的持续时间。\n4. 对于以 $f=3\\ \\mathrm{GHz}$ 运行的处理器，计算每次循环迭代的期望时间（以纳秒为单位）。\n\n将任务4的最终答案以纳秒表示，并将最终结果四舍五入到四位有效数字。", "solution": "问题陈述内部一致，科学上基于计算机体系结构原理，并且问题设定良好，为获得唯一解提供了所有必要数据。我们按概述的任务进行处理。\n\n给定的数据如下：\n- L1 缓存命中延迟：$L_1 = 4$ 个周期\n- L2 缓存命中延迟：$L_2 = 12$ 个周期\n- L3 缓存命中延迟：$L_3 = 40$ 个周期\n- DRAM 访问延迟：$L_M = 200$ 个周期\n- L1 命中概率：$P_1 = 0.92$\n- L2 命中概率：$P_2 = 0.06$\n- L3 命中概率：$P_3 = 0.015$\n- DRAM 访问概率：$P_M = 0.005$\n- 计算阶段持续时间：$C_{compute} = 6$ 个周期\n\n首先，对概率进行一致性检查：$P_1 + P_2 + P_3 + P_M = 0.92 + 0.06 + 0.015 + 0.005 = 1.00$。这些事件构成了一个完备的概率空间，符合要求。\n\n**任务1：推导出一个关联周期时间 $T$ 和时钟频率 $f$ 的表达式。**\n\n根据定义，时钟频率 $f$ 是单位时间（秒）内执行的周期数。其单位是赫兹 ($\\mathrm{Hz}$)，等同于 $s^{-1}$。\n$$f \\left[ \\frac{\\text{周期}}{\\text{秒}} \\right]$$\n周期时间 $T$ 是单个周期的持续时间，或每个周期所经过的时间。其单位是秒 ($s$)。\n$$T \\left[ \\frac{\\text{秒}}{\\text{周期}} \\right]$$\n从这些定义可以明显看出，一个量是另一个量的倒数。\n$$T = \\frac{1}{f}$$\n\n**任务2：确定当 $f \\in \\{1,2,3,4\\}\\ \\mathrm{GHz}$ 时，周期时间 $T$ 的值。**\n\n我们使用表达式 $T = \\frac{1}{f}$。注意 $1\\ \\mathrm{GHz} = 1 \\times 10^9\\ \\mathrm{Hz}$。得到的时间 $T$ 的单位是秒，可以方便地表示为纳秒（$1 \\text{ ns} = 10^{-9} \\text{ s}$）。\n\n- 对于 $f = 1\\ \\mathrm{GHz} = 1 \\times 10^9\\ \\mathrm{s}^{-1}$：\n$$T = \\frac{1}{1 \\times 10^9\\ \\mathrm{s}^{-1}} = 1 \\times 10^{-9}\\ \\mathrm{s} = 1\\ \\mathrm{ns}$$\n- 对于 $f = 2\\ \\mathrm{GHz} = 2 \\times 10^9\\ \\mathrm{s}^{-1}$：\n$$T = \\frac{1}{2 \\times 10^9\\ \\mathrm{s}^{-1}} = 0.5 \\times 10^{-9}\\ \\mathrm{s} = 0.5\\ \\mathrm{ns}$$\n- 对于 $f = 3\\ \\mathrm{GHz} = 3 \\times 10^9\\ \\mathrm{s}^{-1}$：\n$$T = \\frac{1}{3 \\times 10^9\\ \\mathrm{s}^{-1}} = \\frac{1}{3} \\times 10^{-9}\\ \\mathrm{s} \\approx 0.333\\ \\mathrm{ns}$$\n- 对于 $f = 4\\ \\mathrm{GHz} = 4 \\times 10^9\\ \\mathrm{s}^{-1}$：\n$$T = \\frac{1}{4 \\times 10^9\\ \\mathrm{s}^{-1}} = 0.25 \\times 10^{-9}\\ \\mathrm{s} = 0.25\\ \\mathrm{ns}$$\n\n**任务3：当 $f=3\\ \\mathrm{GHz}$ 时，以周期和纳秒为单位解释缓存和内存事件的持续时间。**\n\n当 $f = 3\\ \\mathrm{GHz}$ 时，周期时间为 $T = \\frac{1}{3}\\ \\mathrm{ns}$。一个需要 $C$ 个周期的事件，其持续时间（以纳秒为单位）由 $D = C \\times T$ 给出。\n\n- L1 缓存命中：$L_1 = 4$ 个周期。持续时间 $D_1 = 4 \\times \\frac{1}{3}\\ \\mathrm{ns} = \\frac{4}{3}\\ \\mathrm{ns} \\approx 1.33\\ \\mathrm{ns}$。\n- L2 缓存命中：$L_2 = 12$ 个周期。持续时间 $D_2 = 12 \\times \\frac{1}{3}\\ \\mathrm{ns} = 4\\ \\mathrm{ns}$。\n- L3 缓存命中：$L_3 = 40$ 个周期。持续时间 $D_3 = 40 \\times \\frac{1}{3}\\ \\mathrm{ns} = \\frac{40}{3}\\ \\mathrm{ns} \\approx 13.33\\ \\mathrm{ns}$。\n- DRAM 访问：$L_M = 200$ 个周期。持续时间 $D_M = 200 \\times \\frac{1}{3}\\ \\mathrm{ns} = \\frac{200}{3}\\ \\mathrm{ns} \\approx 66.67\\ \\mathrm{ns}$。\n\n**任务4：对于以 $f=3\\ \\mathrm{GHz}$ 运行的处理器，计算每次循环迭代的期望时间（以纳秒为单位）。**\n\n单次循环迭代包含一个计算阶段和一次内存访问。一次循环迭代的总时间是这两部分时间之和。由于内存访问时间是概率性的，我们必须计算内存访问的期望周期数。\n\n单次内存访问的期望周期数，记为 $E[C_{mem}]$，是每个可能事件延迟的加权平均值，其中权重是这些事件的概率。\n$$E[C_{mem}] = P_1 L_1 + P_2 L_2 + P_3 L_3 + P_M L_M$$\n代入给定值：\n$$E[C_{mem}] = (0.92 \\times 4) + (0.06 \\times 12) + (0.015 \\times 40) + (0.005 \\times 200)$$\n$$E[C_{mem}] = 3.68 + 0.72 + 0.60 + 1.00$$\n$$E[C_{mem}] = 6.00 \\text{ 个周期}$$\n这也被称为以周期表示的平均内存访问时间 (AMAT)。\n\n每次循环迭代的总期望周期数 $E[C_{loop}]$，是计算周期数和期望内存访问周期数之和。\n$$E[C_{loop}] = C_{compute} + E[C_{mem}]$$\n$$E[C_{loop}] = 6 + 6 = 12 \\text{ 个周期}$$\n为了求出每次循环迭代的期望时间 $E[T_{loop}]$，我们将期望周期数乘以周期时间 $T$。对于 $f=3\\ \\mathrm{GHz}$，我们有 $T = \\frac{1}{3}\\ \\mathrm{ns}$。\n$$E[T_{loop}] = E[C_{loop}] \\times T$$\n$$E[T_{loop}] = 12 \\text{ 个周期} \\times \\frac{1}{3}\\ \\frac{\\mathrm{ns}}{\\mathrm{周期}}$$\n$$E[T_{loop}] = 4\\ \\mathrm{ns}$$\n问题要求答案四舍五入到四位有效数字。确切答案是 $4$。为了用四位有效数字表示，我们写作 $4.000$。", "answer": "$$\n\\boxed{4.000}\n$$", "id": "3627533"}, {"introduction": "提高时钟频率似乎是提升性能的直接方法，但其效果可能相当复杂，尤其是在处理不同工作负载的现代系统中。程序的总执行时间是频率相关部分（CPU计算）和频率无关部分（如主内存访问延迟）的总和，这两者之间的平衡决定了频率变化的实际效果。这个问题探讨了改变时钟速度一个不那么直观的后果：程序的性能瓶颈可能会随之转移。通过分析两个特性不同的函数，你将理解为什么仅凭周期数来判断性能有时会产生误导，以及内存密集型任务与核心频率之间是如何相互作用的。[@problem_id:3627421]", "problem": "在现代处理器上运行的软件性能分析器会报告每个函数的周期数，其中包括所有流水线活动和停顿。考虑一个包含两个主要函数的工作负载，标记为 $A$ 和 $B$。在一个抑制了主内存延迟的微架构模型中，函数 $A$ 每次运行执行 $c_{A} = 2.0 \\times 10^{9}$ 个非内存周期，函数 $B$ 每次运行执行 $c_{B} = 1.0 \\times 10^{9}$ 个非内存周期。在真实硬件上的一次典型运行中，由于外部存储设备的原因，每次主内存访问都会产生 $L = 50 \\times 10^{-9}$ 秒的绝对延迟，这与核心频率无关。函数 $A$ 每次运行执行 $m_{A} = 12{,}000{,}000$ 次主内存访问，函数 $B$ 每次运行执行 $m_{B} = 18{,}666{,}667$ 次主内存访问。假设处理器使用动态电压和频率缩放 (DVFS) 技术，因此核心时钟频率 $f$ 可以在不同运行之间变化，时钟周期时间为 $T = 1/f$。\n\n仅从“执行时间等于周期数乘以时钟周期时间”以及“每次主内存访问都会为运行贡献一个固定的绝对延迟 $L$”这两个核心定义出发，从第一性原理推导出函数 $i \\in \\{A, B\\}$ 的执行时间 $t_{i}(f)$ 作为 $f$、$c_{i}$、$m_{i}$ 和 $L$ 的函数表达式。然后，确定阈值频率 $f^{\\*}$，在该频率下 $t_{A}(f^{\\*}) = t_{B}(f^{\\*})$。最后，简要解释为什么当频率 $f$ 跨越 $f^{\\*}$ 变化时，按时间排序的热点排名会在不同运行之间有所不同。\n\n将 $f^{\\*}$ 的最终数值答案四舍五入到四位有效数字，并以千兆赫兹 (GHz) 为单位表示。", "solution": "问题陈述经核实具有科学依据、提法明确且客观，是计算机体系结构领域一个标准的性能建模练习。\n\n一个函数的总执行时间被建模为非内存处理器周期所花费的时间与主内存访问总延迟之和。\n\n设 $t_{i}(f)$ 为函数 $i \\in \\{A, B\\}$ 在核心时钟频率为 $f$ 的处理器上运行的执行时间。设 $c_{i}$ 为函数 $i$ 的非内存周期数，$m_{i}$ 为其主内存访问次数。时钟周期时间为 $T = 1/f$。每次主内存访问产生一个固定的绝对延迟 $L$。\n\n非内存周期所花费的时间是周期数与每个周期持续时间的乘积：\n$$\n\\text{Time}_{\\text{cycles}} = c_{i} \\times T = \\frac{c_{i}}{f}\n$$\n主内存访问的总延迟是访问次数与每次访问固定延迟的乘积：\n$$\n\\text{Time}_{\\text{memory}} = m_{i} \\times L\n$$\n根据问题的定义，总执行时间 $t_{i}(f)$ 是这两个部分的总和。这就给出了函数 $i$ 的执行时间作为 $f$ 的函数的表达式：\n$$\nt_{i}(f) = \\frac{c_{i}}{f} + m_{i}L\n$$\n这就是从第一性原理推导出的所要求的表达式。对于函数 $A$ 和 $B$，其执行时间分别为：\n$$\nt_{A}(f) = \\frac{c_{A}}{f} + m_{A}L\n$$\n$$\nt_{B}(f) = \\frac{c_{B}}{f} + m_{B}L\n$$\n接下来，我们确定两个函数执行时间相等的阈值频率 $f^{\\*}$，即 $t_{A}(f^{\\*}) = t_{B}(f^{\\*})$。\n$$\n\\frac{c_{A}}{f^{\\*}} + m_{A}L = \\frac{c_{B}}{f^{\\*}} + m_{B}L\n$$\n为了解出 $f^{\\*}$，我们重新排列各项以分离出 $f^{\\*}$：\n$$\n\\frac{c_{A}}{f^{\\*}} - \\frac{c_{B}}{f^{\\*}} = m_{B}L - m_{A}L\n$$\n$$\n\\frac{c_{A} - c_{B}}{f^{\\*}} = (m_{B} - m_{A})L\n$$\n在 $c_A \\neq c_B$ 且 $m_A \\neq m_B$ 的条件下，我们可以写出：\n$$\nf^{\\*} = \\frac{c_{A} - c_{B}}{(m_{B} - m_{A})L}\n$$\n现在，我们代入给定的数值：\n-   $c_{A} = 2.0 \\times 10^{9}$\n-   $c_{B} = 1.0 \\times 10^{9}$\n-   $m_{A} = 12,000,000 = 1.2 \\times 10^{7}$\n-   $m_{B} = 18,666,667$\n-   $L = 50 \\times 10^{-9}$ s\n\n首先，我们计算差值：\n$$\nc_{A} - c_{B} = (2.0 \\times 10^{9}) - (1.0 \\times 10^{9}) = 1.0 \\times 10^{9}\n$$\n$$\nm_{B} - m_{A} = 18,666,667 - 12,000,000 = 6,666,667\n$$\n现在，将这些值代入 $f^{\\*}$ 的表达式中：\n$$\nf^{\\*} = \\frac{1.0 \\times 10^{9}}{6,666,667 \\times (50 \\times 10^{-9})} = \\frac{1.0 \\times 10^{9}}{333,333,350 \\times 10^{-9}} = \\frac{1.0 \\times 10^{9}}{0.33333335}\n$$\n$$\nf^{\\*} \\approx 2,999,999,850 \\text{ Hz}\n$$\n这个频率等效于 $2.999999850$ GHz。问题要求将此值四舍五入到四位有效数字。\n$$\nf^{\\*} \\approx 3.000 \\text{ GHz} = 3.000 \\times 10^{9} \\text{ Hz}\n$$\n\n最后，我们解释为什么当时钟频率 $f$ 跨越阈值 $f^{\\*}$ 变化时，按时间排序的热点排名会发生变化。\n热点是消耗最多执行时间的函数。排名取决于 $t_{A}(f)$ 和 $t_{B}(f)$ 之间的比较。执行时间由一个频率相关的项（计算时间，$c_{i}/f$）和一个频率无关的项（内存访问时间，$m_{i}L$）组成。\n\n函数 $A$ 更偏向于计算密集型 ($c_{A}  c_{B}$)，而函数 $B$ 更偏向于内存密集型 ($m_{B}  m_{A}$)。\n-   当频率 $f$ 较低 ($f  f^{\\*}$) 且周期时间 $T=1/f$ 较长时，计算时间部分 $c_{i}/f$ 会很大，并往往主导总执行时间。由于 $c_{A}  c_{B}$，因此 $t_{A}(f)  t_{B}(f)$。在这种情况下，函数 $A$ 是主要热点。\n-   当频率 $f$ 较高 ($f  f^{\\*}$) 且周期时间 $T=1/f$ 较短时，计算时间 $c_{i}/f$ 变小，而恒定的内存访问时间 $m_{i}L$ 成为总执行时间中一个更重要的组成部分。由于 $m_{B}  m_{A}$，函数 $B$ 的总内存延迟大于函数 $A$。对于足够高的 $f$，这一项将占主导地位，导致 $t_{B}(f)  t_{A}(f)$。在这种情况下，函数 $B$ 成为主要热点。\n\n阈值频率 $f^{\\*}$ 正是函数计算密集型和内存密集型特性的相对主导地位发生反转的交叉点。因此，跨越这个阈值 $f^{\\*}$ 改变处理器频率，可以改变哪个函数需要更长的执行时间，从而改变热点排名。", "answer": "$$\\boxed{3.000}$$", "id": "3627421"}]}