## 引言
在现代高性能处理器的设计中，[多级缓存](@entry_id:752248)（Cache）体系结构是弥合处理器速度与主存延迟之间巨大鸿沟的关键。然而，如何管理各级缓存之间的数据关系，即采用何种“包含策略”（Inclusion Policy），是一个对系统性能、容量和复杂性产生深远影响的核心设计决策。设计师们主要面临一个根本性的选择：是采用“包含式”（Inclusive）策略，让低级别缓存成为高级别缓存的[子集](@entry_id:261956)以简化一致性管理；还是采用“排他式”（Exclusive）策略，让各级缓存内容[互斥](@entry_id:752349)以最大化总[有效容量](@entry_id:748806)？这个看似简单的选择背后，隐藏着一系列复杂的工程权衡。

本文旨在系统性地剖析包含式与排他式[缓存层次结构](@entry_id:747056)的利弊。在接下来的“原理与机制”章节中，我们将深入探讨这两种策略的核心定义、运行机制，以及它们对有效缓存容量和数据移动效率的直接影响。随后，在“应用与跨学科连接”部分，我们会将这些理论置于更广阔的实践背景下，考察它们如何与多核一致性协议、[操作系统](@entry_id:752937)乃至芯片物理设计等领域相互作用。最后，通过一系列精心设计的“动手实践”问题，您将有机会运用所学知识，定量分析和解决现实世界中的架构设计挑战。让我们首先从这两种策略的基本原理出发。

## 原理与机制

在[多级缓存](@entry_id:752248)（Cache）体系结构的设计中，各级缓存之间的数据包含关系，即**包含策略**（Inclusion Policy），是一个核心的设计决策。它深刻影响着系统的[有效容量](@entry_id:748806)、数据移动效率、一致性协议的实现复杂度乃至整体性能。本章将深入探讨两种主流的包含策略——**包含式缓存（Inclusive Cache）**和**排他式缓存（Exclusive Cache）**——的核心原理、运行机制及其在[系统设计](@entry_id:755777)中的权衡。

### 核心定义：包含原则

现代处理器通常采用[多级缓存](@entry_id:752248)结构，例如L1、L2和L3缓存。包含策略定义了存储在不同缓存级别中的[数据块](@entry_id:748187)（通常称为缓存行）之间的关系。

- **包含式（Inclusive）策略**：该策略要求低级别缓存（如L1）中的内容必须是高级别缓存（如L2或L3）内容的**[子集](@entry_id:261956)**。如果一个缓存行存在于L1中，那么它必须同时存在于L2中。形式上，若 $S_{L1}$ 和 $S_{L2}$ 分别代表L1和L2缓存中缓存行的集合，则必须始终满足 $S_{L1} \subseteq S_{L2}$。

- **排他式（Exclusive）策略**：该策略正好相反，它要求不同级别缓存中的内容是**互斥的**。一个缓存行要么在L1中，要么在L2中，但绝不会同时存在于两者之中。形式上，这意味着 $S_{L1} \cap S_{L2} = \emptyset$。

此外，还存在一种**非包含非排他式（Non-Inclusive, Non-Exclusive, NINE）**策略，它对各级缓存之间的内容关系不作严格要求。本章我们将聚焦于包含式和排他式这两种对比鲜明的策略，因为它们最能揭示设计中的[基本权](@entry_id:200855)衡。

### 对有效缓存容量的影响

包含策略最直接的影响体现在整个缓存体系的**[有效容量](@entry_id:748806)**（Effective Capacity）上，即它能容纳的独一无二的缓存行的总数。

在**包含式**体系结构中，由于L1的内容完全是L2内容的副本，整个L1+L2缓存系统能够存储的独特数据量实际上受限于L2的容量。L1缓存只是为L2中部分“热门”数据提供了一个更快速的访问路径。因此，其总[有效容量](@entry_id:748806)近似等于最后一级缓存（LLC）的容量。对于一个两级系统，[有效容量](@entry_id:748806) $C_{\text{eff, inc}} \approx C_{L2}$。这个特性带来一个显著的性能瓶颈：如果一个程序的工作集（Working Set）大小 $W$ 超过了L2的容量（即 $W > C_{L2}$），即使 $W$ 仍然小于L1和L2容量之和（$W \le C_{L1} + C_{L2}$），系统也会因为无法容纳整个工作集而发生持续的容量缺失（Capacity Misses），这种现象称为**[缓存颠簸](@entry_id:747071)（Thrashing）** [@problem_id:3649239]。

为了更精确地量化包含式缓存的容量损失，我们可以引入**复制比率（Duplication Ratio）** $d$ 的概念。该比率定义为L2缓存中同时也在L1中存在的数据行所占的比例，即 $d(t) = \frac{|S_{L1}(t)|}{|S_{L2}(t)|}$。因此，L2中仅为L2自身存储、未在L1中复制的数据行数量的上限为 $C_{L2}(1-d)$。这清晰地表明，L1的存在“侵占”了L2的容量，复制比率越高，L2能提供的独立存储空间就越小 [@problem_id:3649314]。

相比之下，**排他式**体系结构通过避免数据重复，最大化了存储效率。在理想情况下，L1和L2存储完全不同的数据，使得总[有效容量](@entry_id:748806)等于两级缓存容量之和：$C_{\text{eff, exc}} \approx C_{L1} + C_{L2}$。这意味着，只有当工作集大小 $W$ 超过 $C_{L1} + C_{L2}$ 时，系统才会开始出现颠簸 [@problem_id:3649239]。

这种容量上的优势可以直接转化为命中率的提升。在一个简化的独立引用模型（Independent Reference Model, IRM）下，一个大小为 $C$ 的缓存对于一个[均匀分布](@entry_id:194597)在 $W$ 个[数据块](@entry_id:748187)上的[工作集](@entry_id:756753)，其命中率近似为 $\frac{C}{W}$。因此，从包含式切换到排他式设计，带来的命中率提升 $\Delta H$ 直接源于L1缓存提供的额外[有效容量](@entry_id:748806)，其值为 $\Delta H = H_{\text{excl}} - H_{\text{incl}} = \frac{C_{L1} + C_{L2}}{W} - \frac{C_{L2}}{W} = \frac{C_{L1}}{W}$ [@problem_id:3649295]。这个简单的公式有力地证明了排他式缓存在容量利用上的根本优势。

### 数据移动与互连流量

包含策略不仅影响容量，还决定了数据在[缓存层次结构](@entry_id:747056)和[主存](@entry_id:751652)之间移动的方式，从而对片上互连（On-chip Interconnect）的带宽提出了不同要求。

#### 填充（Fill）机制

当发生一次缓存缺失（Miss），且所需数据在整个缓存体系中都不存在时，需要从[主存](@entry_id:751652)中获取数据。
- 在**包含式**设计中，为了维持包含关系，数据行通常首先被填入L2缓存，然后再从L2复制一份到L1缓存。这个过程涉及两次片上互连传输：一次是从[内存控制器](@entry_id:167560)到L2，第二次是从L2到L1。
- 在**排他式**设计中，数据行可以直接从[主存](@entry_id:751652)填入L1缓存，而无需在L2中保留副本。这通常只需要一次互连传输。

这意味着，对于同样的L1缺失率，包含式设计产生的填充流量可能是排他式设计的两倍。我们可以量化这一影响。假设处理器[指令执行](@entry_id:750680)率为 $I$ (IPC)，时钟频率为 $f$，L1缺失率为 $m$ (misses/instruction)，缓存行大小为 $L$ 字节。每次缺失所需的传输次数为 $T$（包含式为2，排他式为1）。那么，所需的互连带宽为 $B_{\text{req}} = m \times (I \times f) \times (T \times L)$。在一个具体场景中，若片上总线带宽为 $B_{\text{bus}} = 25.6 \times 10^9$ B/s，处理器以 $2$ IPC @ $2.5$ GHz 运行，缓存行大小为 $64$ 字节，采用包含式策略（$T=2$）的系统，其能承受的最大L1缺失率（MPKI，每千条指令的缺失次数）仅为 $40.00$ MPKI。若采用排他式策略（$T=1$），则可承受的缺失率将翻倍，达到 $80.00$ MPKI，显示出更高的[带宽效率](@entry_id:261584) [@problem_id:3649264]。

#### 替换与逐出（Eviction）机制

数据的逐出机制同样存在显著差异。
- 在**排他式**设计中，当一个[数据块](@entry_id:748187)因容量问题被从L1中逐出时，它并不会被丢弃，而是被移入L2缓存。这使得L2自然而然地扮演了L1的**[受害者缓存](@entry_id:756499)（Victim Cache）**角色。这种机制非常高效，因为它能将被L1替换掉但可能很快会再次被访问的[数据保留](@entry_id:174352)在离处理器更近的L2中，从而将许多原本会导致访问主存的L1容量缺失转化为快速的L2命中。

- 在**包含式**设计中，当L1逐出一个[数据块](@entry_id:748187)时，这个操作本身通常不会影响L2（该数据块在L2中依然存在）。然而，关键在于当一个[数据块](@entry_id:748187)被从L2中逐出时，为了维持包含原则，系统必须向所有低级别缓存（如L1）发送一个**反向无效（Back Invalidation）**命令，强制它们也丢弃该[数据块](@entry_id:748187)的任何副本。这是包含式设计的一个核心开销。

### [多级缓存](@entry_id:752248)中的性能交互

反向无效和[受害者缓存](@entry_id:756499)这两种机制导致了两种策略在复杂系统中的性能表现差异巨大。

#### 反向无效的性能惩罚（包含式）

反向无效机制是包含式缓存最主要的性能短板之一。它可能在L1缓存看来“不合时宜”地逐出一个非常有用的数据块（例如L1中的最近使用项），仅仅因为L2的容量压力。这种强制性的外部干预降低了L1的**[有效容量](@entry_id:748806)**和性能。

这种效应的微妙之处在于，它使得L1的性能与L2的容量产生了耦合。在一个包含式结构中，如果我们增加L2的容量（$C_2$），L2的缺失率会下降，从而导致L2的逐出事件减少。更少的L2逐出意味着发送到L1的反向无效命令也随之减少。这使得数据能在L1中停留更长时间，L1的行为更接近一个理想的、不受干扰的缓存。因此，增加L2的容量反而可能间接**降低L1的缺失率**。相反，在排他式结构中，L1的运行与其[受害者缓存](@entry_id:756499)L2的大小无关，L1的缺失率 $M_{L1}$ 基本上保持不变。增加L2的容量只会影响L2自身的命中率 [@problem_id:3649276]。

在[多核处理器](@entry_id:752266)中，这个问题会被进一步放大。当多个核心共享一个包含式的最后一级缓存（LLC，如L3）时，一个核心（“攻击者”）的内存访问可能导致LLC发生逐出，而这个逐出事件可能会触发对另一个核心（“受害者”）的私有L1缓存的反向无效。这种**跨核干扰（Cross-core Interference）**是共享包含式缓存的一个严重扩展性问题。我们可以构建一个模型来量化这种干扰。在一个有 $N$ 个核心、共享容量为 $C_{L3}$ 的LLC的系统中，假设LLC中的数据归属[均匀分布](@entry_id:194597)，那么在一个完整的LLC容量更新周期（$C_{L3}$次逐出）内，一个“受害者”核心因其他核心活动而导致的L1平均缓存逐出次数（ACE）可以表示为 $ACE = C_{L3} \frac{N-1}{N^2}$ [@problem_id:3649205]。

这种反向无效的发生频率也可以通过[概率模型](@entry_id:265150)来估计。在一个拥有 $C$ 个核心的系统中，如果L2容量为 $S_2$，L1容量为 $M$，且L1的内容可以看作是从L2中随机抽取的样本，那么一个L2逐出事件在某个特定L1中找到对应副本的概率约为 $\frac{M}{S_2}$。因此，在 $N$ 次L2逐出事件中，预期将产生大约 $\frac{NCM}{S_2}$ 次L1无效化事件 [@problem_id:3649235]。这些分析都指向一个共同的结论：包含式缓存中的反向无效机制会引入显著的性能开销和不可预测性。

### 一致性维护与元数据开销

尽管包含式缓存在容量和性能上存在诸多劣势，但它在多核**[缓存一致性](@entry_id:747053)（Cache Coherence）**维护方面提供了一个巨大的实现优势，这正是它被广泛采用的关键原因。

现代[多核处理器](@entry_id:752266)需要一个机制来追踪哪个核心的缓存中存有特定内存地址的副本，这个机制通常被称为**目录（Directory）**。
- 在**包含式**设计中，由于LLC是所有私有缓存的超集，因此目录信息可以非常经济地与LLC的标签存储（Tag Store）集成在一起。对于LLC中的每一行，只需附加一个**存在[位向量](@entry_id:746852)（Presence Bit Vector）**，其中每一位对应一个核心，用于标识该核心的私有缓存中是否也拥有此行的副本。这种设计避免了为目录建立一个独立的、昂贵的标签查找结构。例如，在一个8核系统、8 MiB的L2缓存、64字节行大小的配置中，为所有L2行存储这种8位的存在向量，总共只需要 $128 \text{ KiB}$ 的额外存储空间 [@problem_id:3649236]。

- 在**排他式（或NINE）**设计中，LLC并不知道私有缓存中的内容。为了实现高效的一致性（避免向所有核心广播每一个一致性请求），系统必须维护一个独立的**[窥探过滤器](@entry_id:754994)（Snoop Filter）**或一个功能完整的目录。这个结构必须为所有存在于任何私有缓存中的数据行存储其完整的物理地址标签，以便进行查找。这种设计的存储开销非常高昂。其每个条目除了需要存储与包含式目录相同的状态位和共享向量外，还必须额外存储完整的物理标签。其与包含式目录每个条目的存储开销之差，恰好就是物理标签的位数，即 $P - \log_2(L)$，其中 $P$ 是物理地址位数，$L$ 是行大小。在一个拥有48位物理地址和64字节行的系统中，这个差异高达42位 [@problem_id:3649260]。对于一个需要追踪数十万个缓存行的系统来说，这会带来巨大的芯片面积和功耗成本。

包含式设计中的存在[位向量](@entry_id:746852)不仅节省了空间，还直接优化了一致性通信。当一个核心需要对某数据行执行读取或写入操作时，一致性控制器可以查询LLC中的存在[位向量](@entry_id:746852)，并只向那些实际持有该数据副本的核心发送窥探（Snoop）请求，而不是向所有核心进行广播。这大大减少了不必要的窥探流量和[功耗](@entry_id:264815)。值得注意的是，这种优化减少的是**窥探请求的数量**，而非**窥探命中（Snoop Hit）**的数量。无论采用广播还是定向窥探，最终响应的（即持有副本的）核心数量是相同的。因此，包含式设计的主要优势在于提升了[互连网络](@entry_id:750720)的效率和能效，而非改变一致性事件的逻辑结果 [@problem_id:3649270]。

### 总结与权衡

包含式与排他式[缓存策略](@entry_id:747066)的选择是一个典型的工程设计权衡，没有绝对的最优解。

**包含式缓存（Inclusive Caches）**
- **优点**:
    - 简化了一致性协议的实现，目录信息可与LLC标签高效集成。
    - 显著降低了目录的存储开销。
    - 通过定向窥探减少了一致性通信流量和功耗。
- **缺点**:
    - 有效缓存容量受限于最后一级缓存，容量利用率低。
    - 缓存填充时可能产生更高的互连带宽需求。
    - 反向无效机制会降低L1的有效性能，并引发严重的跨核干扰问题，影响系统扩展性。

**排他式缓存（Exclusive Caches）**
- **优点**:
    - 最大化有效缓存容量，等于各级缓存容量之和。
    - 缓存填充时互连流量较低。
    - L2自然成为L1的[受害者缓存](@entry_id:756499)，提高了整体命中率。
- **缺点**:
    - 一致性维护复杂，需要一个独立的、存储开销巨大的[窥探过滤器](@entry_id:754994)或目录。
    - 独立的[目录结构](@entry_id:748458)可能成为性能瓶颈，并消耗大量芯片面积和[功耗](@entry_id:264815)。

历史上，许多商用处理器（如Intel和AMD的主流CPU系列）都采用了包含式最后一级缓存，主要就是看中了其在一致性管理上的简洁性和成本效益。然而，随着处理器核心数量的不断增加，包含式缓存的[容量瓶](@entry_id:200949)颈和跨核干扰问题变得愈发突出。这促使架构师们重新评估和探索排他式或NINE策略，以期在未来众核（Many-core）时代实现更佳的性能和扩展性。