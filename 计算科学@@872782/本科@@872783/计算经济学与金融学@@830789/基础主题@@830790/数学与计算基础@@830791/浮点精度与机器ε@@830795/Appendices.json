{"hands_on_practices": [{"introduction": "理论概念通常通过动手实践才能更好地理解。这个练习将机器精度这个抽象概念与一个具体的金融问题联系起来：在单精度浮点数运算中，计算机能识别的最小正利率 $r$ 是多少？通过编写程序来寻找这个值，你将亲身体验到 $1+r$ 何时在计算上能与 $1$ 区分开，并理解机器精度（machine epsilon）的实际意义 [@problem_id:2394219]。", "problem": "您的任务是编写一个完整、可运行的程序，用以确定有限精度算术如何影响在单精度浮点算术中对小利率的可检测性。请在国际电工委员会（IEC）和电气和电子工程师协会（IEEE）的浮点算术标准（IEEE 754）的单精度模型（基数为$2$，采用向最近偶数舍入规则）下进行操作，并将利率视为纯小数（不带百分号）。在此模型中，接近$1$的可表示数是离散分布的，在单位尺度上，当且仅当将$r$与$1$相加的单精度结果严格大于$1$时，利率$r$在计算上才可与$0$区分。您的目标是仅使用遵循单精度语义的浮点运算，来稳健地推断出满足此条件的最小$r \\gt 0$。\n\n使用的基本原理：\n- IEEE 754 单精度算术使用基数$2$和固定精度，并将结果舍入到最接近的可表示值，当出现平局时则朝向偶数尾数舍入。您可以将此舍入规则、舍入的单调性以及非规格化数的作为经过充分测试的事实来使用。\n\n约束条件：\n- 所有旨在反映单精度行为的加法、乘法和除法都必须在单精度下执行。不要依赖解析公式来获得答案。相反，您应基于 IEEE 754 舍入模型实现一个算法搜索，以找到满足单精度计算 $1 + r$ 严格大于 $1$ 的最小 $r \\gt 0$。\n- 将利率表示为小数（例如，百分之五写为 $0.05$）。无需单位。\n\n需要实现的必做任务：\n1. 计算最小利率 $r \\gt 0$，使得 $1 + r$ 的单精度结果严格大于 $1$。使用完全由单精度运算驱动的迭代对分（二分法风格）方法：从一个单精度 $r$ 开始，不断减小 $r$，直到将其一半与 $1$ 相加不再使 $1$ 在单精度下增加；当减半时仍能使 $1$ 增加的最后一个 $r$ 即为所求值。\n2. 通过检查步骤1中得到的 $r_{\\min}$，验证边界条件：$1 + \\frac{r_{\\min}}{2}$ 的单精度结果等于 $1$。\n3. 交叉检验计算出的 $r_{\\min}$ 是否与从可信的单精度浮点元数据源获得的、紧邻 $1$ 之上的单精度间距相匹配。\n4. 确认将最小的正单精度非规格化数 $s$ 与 $1$ 相加后，其单精度结果等于 $1$。\n5. 应用金融检验：对于在时间 $T = 360$（可理解为月，但无需单位）时收到的一笔大小为 $C = 1$ 的收益，用单精度计算差值 $\\frac{1}{(1 + r_{\\min})^{T}} - 1$ 并返回这个数值。将该值报告为小数（而非百分比）。\n\n测试套件和预期输出：\n- 程序必须按顺序计算以下五个输出，并将它们聚合到一个列表中：\n  - 情况A（正常路径）：任务1中得到的 $r_{\\min}$ 值，以浮点数形式表示。\n  - 情况B（边界条件）：一个布尔值，表示在单精度下 $1 + \\frac{r_{\\min}}{2} = 1$ 是否成立。\n  - 情况C（一致性）：一个布尔值，表示 $r_{\\min}$ 是否等于 $1$ 之上的单精度元数据间距。\n  - 情况D（边界情况）：一个布尔值，表示对于最小的正非规格化数 $s$，在单精度下 $1 + s = 1$ 是否成立。\n  - 情况E（应用）：完全在单精度下计算出的 $\\frac{1}{(1 + r_{\\min})^{360}} - 1$ 的值，以浮点数形式表示。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表（例如，$[result\\_A,result\\_B,result\\_C,result\\_D,result\\_E]$）。该列表必须严格包含上述五个值，并按此顺序排列。所有与任务1到5相关的浮点算术都必须在单精度下执行，所有比较都必须反映单精度的结果。所有输出都必须报告为纯数字或布尔值，不带单位，也不带百分号。", "solution": "该问题要求在涉及小利率的金融计算背景下，研究有限精度算术的局限性，特别是 IEEE 754 单精度标准。核心任务是确定当与$1$相加时，在计算上可与$0$区分的最小正利率$r$（记为 $r_{\\min}$）。这等价于找到最小的正单精度数$r_{\\min}$，使得浮点运算 $fl(1 + r_{\\min})$ 产生一个严格大于$1$的结果。然后，我们将使用这个值执行几项验证检查和一个简单的金融计算。\n\n在单精度浮点数（binary32）的 IEEE 754 标准中，一个数字使用一个符号位、一个8位偏置指数和一个23位小数部分来表示。一个规格化数的形式为 $(-1)^S \\times 2^{E-127} \\times (1.f)_{2}$，其中 $S$ 是符号位，$E$ 是指数，$f$ 是小数部分。\n\n数字 $1.0$ 在此系统中可以精确表示。它的符号是 $0$，无偏指数是 $0$（因此偏置指数 $E$ 是 $127$），小数部分全为零。其尾数隐式地为 $1.0$。比它大的下一个可表示数具有相同的指数，但小数部分的最后一位会增加。这个数是 $1 + 2^{-23}$。因此，$1.0$ 与下一个可表示数之间的间距是 $2^{-23}$。这个量被称为“最后一位的单位”（Unit in the Last Place），或写作 $ulp(1.0)$。根据默认的“向最近偶数舍入”规则，任何加到 $1.0$ 上的正数 $x \\le ulp(1.0)/2 = 2^{-24}$ 都将被舍入回 $1.0$。如果 $x = 2^{-24}$，则出现平局情况，结果会舍入到“偶数”尾数，也就是 $1.0$ 的尾数。因此，使得 $fl(1 + r_{\\min}) > 1$ 的最小数 $r_{\\min}$ 必须是 $ulp(1.0) = 2^{-23}$。\n\n问题要求通过算法发现这个值，而不是通过解析推导。\n\n**任务 1：$r_{\\min}$ 的算法计算**\n\n我们被要求使用迭代搜索来找到 $r_{\\min}$。该搜索必须找到使 $fl(1+r) > 1$ 的最小数 $r$。所描述的方法是一种二次幂递减法，我们通过从候选值 $r = 1.0$ 开始并反复将其减半来实现。其逻辑是找到这样一个值 $r$，它满足 $fl(1 + r) > 1$ 但 $fl(1 + r/2) = 1$。这可以通过一个循环来实现，只要将当前候选值 $r$ 的一半加到 $1$ 上仍然产生大于 $1$ 的结果，循环就继续。当条件不满足时，当前的 $r_k$ 就是我们所期望的 $r_{\\min}$。\n\n设 $r_0 = 1.0_{f32}$。我们生成一个序列 $r_{k+1} = r_k / 2.0_{f32}$。只要 $fl(1.0_{f32} + fl(r_k / 2.0_{f32})) > 1.0_{f32}$，循环就继续。当条件不满足时，当前的 $r_k$ 就是我们所期望的 $r_{\\min}$。\n\n**任务 2：边界条件验证**\n\n根据任务1的构造，$r_{\\min}$ 是序列 $1, 1/2, 1/4, \\dots$ 中使 $fl(1+r_{\\min})>1$ 成立的最小值。算法恰好在 $fl(1 + r_{\\min}/2) = 1$ 时终止。此检查旨在确认我们的算法正确地识别了相对于 $1$ 的机器精度边界。我们将计算 $fl(1.0_{f32} + fl(r_{\\min} / 2.0_{f32}))$ 并验证它等于 $1.0_{f32}$。\n\n**任务 3：与浮点元数据交叉检验**\n\n我们通过算法确定的 $r_{\\min}$ 值，应与被称为单精度机器ε的基本机器常量相同，即从 $1.0$ 到下一个更大的可表示浮点数之间的距离。标准的数值库提供了访问该值的途径。我们将计算出的 $r_{\\min}$ 与 `numpy.spacing(numpy.float32(1.0))` 的值进行比较，后者是 $ulp(1.0)$ 的一个可信来源。这证实了我们算法和理解的正确性。\n\n**任务 4：使用最小非规格化数的边界情况**\n\n非规格化数（或次正规数）用于表示比最小规格化数还小的值，填补了 $0$ 和 $\\pm 2^{E_{min}}$ 之间的空白。最小的正单精度非规格化数，我们称之为 $s$，是 $2^{-149}$。这个值比 $r_{\\min} = 2^{-23}$ 小得惊人。当我们计算 $fl(1.0 + s)$ 时，结果会舍入到最接近的可表示数。由于 $s \\ll r_{\\min}/2$，和 $1.0 + s$ 远比下一个可表示数 $1.0 + r_{\\min}$ 更接近 $1.0$。因此，浮点加法的结果必须是 $1.0$。此任务验证了我们对极小数在浮点加法中如何处理的理解。\n\n**任务 5：应用金融检验**\n\n此任务要求我们计算这个最小利率 $r_{\\min}$ 在很长一段时间内的影响。我们必须计算一个金融表达式的值，$D = \\frac{1}{(1 + r_{\\min})^T} - 1$，其中时间周期 $T$ 为 $360$（例如，30年期中的月数）。所有运算都必须在单精度下执行。这表明即使是计算上可检测到的最小利率，在复利作用下，也会导致与零利率情景相比可测量的偏差。运算顺序如下：\n1.  计算 $v_1 = fl(1.0_{f32} + r_{\\min})$。\n2.  计算 $v_2 = fl(v_1^{360.0_{f32}})$。这是一个重复乘法或库函数幂运算，全部在单精度下进行。\n3.  计算 $v_3 = fl(1.0_{f32} / v_2)$。\n4.  计算最终结果 $D = fl(v_3 - 1.0_{f32})$。\n结果将是一个小的负数，表示对于时间 $T=360$ 处的现金流，其现值贴现因子与 $1$ 的偏差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Performs a series of tasks related to single-precision floating-point\n    arithmetic and its application in finance, adhering to strict computational\n    and formatting rules.\n    \"\"\"\n\n    # Define single-precision constants to ensure all arithmetic is performed\n    # in the correct domain.\n    one_f32 = np.float32(1.0)\n    two_f32 = np.float32(2.0)\n\n    # --- Task 1: Compute the smallest rate r_min  0 ---\n    # We are looking for the smallest r  0 such that 1 + r  1 in single precision.\n    # The problem specifies a bisection-style search. We start with r=1 and\n    # repeatedly halve it until adding r/2 to 1 no longer produces a result  1.\n    # At that point, the current r is the minimal value, r_min.\n    r = one_f32\n    while (one_f32 + (r / two_f32))  one_f32:\n        r = r / two_f32\n    r_min = r\n    result_A = r_min\n\n    # --- Task 2: Verify the boundary condition ---\n    # Check that adding half of r_min to 1 results in 1, confirming r_min is\n    # the minimal representable increment.\n    is_boundary_correct = (one_f32 + (r_min / two_f32)) == one_f32\n    result_B = is_boundary_correct\n\n    # --- Task 3: Cross-check with floating-point metadata ---\n    # Compare r_min with the value of ULP(1.0) (unit in the last place) for\n    # single precision, also known as machine epsilon relative to 1.\n    # np.spacing(1.0) gives the distance between 1.0 and the next larger float.\n    spacing_at_one = np.spacing(one_f32)\n    is_consistent = (r_min == spacing_at_one)\n    result_C = is_consistent\n\n    # --- Task 4: Confirm edge case with smallest subnormal number ---\n    # The smallest positive single-precision number is np.finfo.tiny.\n    # Adding this to 1 should result in 1 due to rounding.\n    s_subnormal = np.finfo(np.float32).tiny\n    is_subnormal_rounded = (one_f32 + s_subnormal) == one_f32\n    result_D = is_subnormal_rounded\n\n    # --- Task 5: Applied finance check ---\n    # Compute the discount factor deviation over 360 periods using r_min.\n    # All calculations must be performed in single precision.\n    T = np.float32(360.0)\n    one_plus_r_min = one_f32 + r_min\n    # The power operation must also respect single precision.\n    # numpy's ** operator on float32 types maintains float32 precision.\n    compounded_factor = one_plus_r_min ** T\n    inverse_factor = one_f32 / compounded_factor\n    finance_result = inverse_factor - one_f32\n    result_E = finance_result\n\n    # Aggregate results into a list for final output.\n    results = [\n        result_A,\n        result_B,\n        result_C,\n        result_D,\n        result_E\n    ]\n\n    # Final print statement in the exact required format.\n    # The map(str, ...) converts each element, including booleans, to its\n    # string representation ('True', 'False', or the number as a string).\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2394219"}, {"introduction": "在金融计算中，直接将数学公式翻译成代码有时会隐藏着数值陷阱。本练习将通过对一个浮动利率债券进行估值来展示这一点，其中债券的利差（margin）非常小 [@problem_id:2394271]。你将比较一个直接的（“天真”）计算方法和一个经过代数重构的数值稳定方法，从而揭示当小数值与大数值相加时可能发生的精度损失（即灾难性抵消）。", "problem": "你的任务是编写一个完整、可运行的程序，在风险中性定价下对浮动利率债券进行估值，同时揭示浮点精度和机器ε对此计算的影响。请从风险中性测度下现金流折现的第一性原理出发：现值等于所有付息日的折现预期现金流之和，加上折现后的本金偿还。使用以下基本原理。\n1. 风险中性测度下的现值：现值等于现金流之和乘以相应的折现因子。\n2. 第 $i$ 个时期的浮动利率票息等于 $(L_i + m)\\,\\alpha_i\\,N$，其中 $L_i$ 是给定的第 $i$ 个时期的远期利率， $m$ 是每次重置时增加的固定利差， $\\alpha_i$ 是该时期的计息天数分数， $N$ 是名义本金。\n3. 当折现因子由单利远期利率 $L_i$ 和计息期 $\\alpha_i$ 构建时，它们满足递归关系 $D_0 = 1$ 和 $D_i = \\dfrac{D_{i-1}}{1 + L_i \\alpha_i}$ （$i = 1,\\dots,T$），其中 $D_i$ 是到时间 $i$ 的折现因子， $T$ 是总期数。\n4. 于是，现值为 $PV = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)$，其中 $D_i$ 通过上述递归关系获得， $D_T$ 用于对本金 $N$ 的偿还进行折现。\n\n你的任务是实现两种数值上不同的现值计算方法：\n- 一种朴素求值方法，在每次票息计算中直接使用 $(L_i + m)$。\n- 一种代数上等价的求值方法，通过使用在实数算术中有效的恒等式重新排列项，避免将一个非常小的数与一个大得多的数相加；特别地，在计算利差的贡献时，不要先将其加到 $L_i$ 上。两种方法都必须使用相同的折现因子 $D_i$。\n\n你的程序必须执行以下测试套件，每个测试用例都由名义本金 $N$、利差 $m$、远期利率 $\\{L_i\\}_{i=1}^T$ 的列表或规则，以及计息天数分数 $\\{\\alpha_i\\}_{i=1}^T$ 的列表完全指定。在所有情况下，用于估值的折现因子 $D_i$ 都必须通过递归关系 $D_0 = 1$，$D_i = \\dfrac{D_{i-1}}{1 + L_i \\alpha_i}$（$i = 1,\\dots,T$）从给定的 $L_i$ 和 $\\alpha_i$ 导出。\n\n测试用例 A（正常路径，利差不可忽略）：\n- $N = 1{,}000{,}000$。\n- $T = 8$，季度计息：对所有 $i$，$\\alpha_i = 0.25$。\n- 远期利率：$L = [0.021,\\, 0.022,\\, 0.0235,\\, 0.024,\\, 0.025,\\, 0.026,\\, 0.027,\\, 0.028]$。\n- 利差：$m = 0.0005$。\n\n测试用例 B（利差远低于典型利率附近的舍入单位；说明浮点精度造成的损失）：\n- $N = 1{,}000{,}000{,}000$。\n- $T = 8$，季度计息：对所有 $i$，$\\alpha_i = 0.25$。\n- 远期利率：使用与测试用例 A 相同的列表。\n- 利差：$m = 1 \\times 10^{-20}$。\n\n测试用例 C（边界情况：零利差）：\n- $N = 2{,}000{,}000$。\n- $T = 8$，季度计息：对所有 $i$，$\\alpha_i = 0.25$。\n- 远期利率：$L = [0.018,\\, 0.019,\\, 0.0195,\\, 0.020,\\, 0.0205,\\, 0.021,\\, 0.0215,\\, 0.022]$。\n- 利差：$m = 0$。\n\n测试用例 D（期数多，远期利率小且逐渐变化；利差微小但非零）：\n- $N = 100{,}000{,}000$。\n- $T = 40$，季度计息：对所有 $i$，$\\alpha_i = 0.25$。\n- 远期利率由规则 $L_i = 0.015 + 0.0001\\,i$ 给出（$i = 1,\\dots,40$）。\n- 利差：$m = 1 \\times 10^{-12}$。\n\n你的程序必须为每个测试用例计算：\n- 朴素现值 $PV_{\\text{naive}} = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)$。\n- 另一种现值 $PV_{\\text{stable}}$，其计算不将 $m$ 加到 $L_i$ 上，同时在精确算术中保持代数等价性，并使用相同的 $D_i$。\n- 绝对差 $\\lvert PV_{\\text{naive}} - PV_{\\text{stable}} \\rvert$。\n\n此问题中没有物理单位。所有利率必须视为小数，而不是百分比。不涉及角度。最终输出格式必须是单行，包含一个用方括号括起来的逗号分隔列表，按顺序连接四个测试用例的三元组：$[PV_{\\text{naive}}^{(A)}, PV_{\\text{stable}}^{(A)}, \\lvert \\cdot \\rvert^{(A)}, PV_{\\text{naive}}^{(B)}, PV_{\\text{stable}}^{(B)}, \\lvert \\cdot \\rvert^{(B)}, PV_{\\text{naive}}^{(C)}, PV_{\\text{stable}}^{(C)}, \\lvert \\cdot \\rvert^{(C)}, PV_{\\text{naive}}^{(D)}, PV_{\\text{stable}}^{(D)}, \\lvert \\cdot \\rvert^{(D)}]$。", "solution": "本问题的核心是比较两种计算浮动利率债券现值的方法：一种是直接实现公式的“朴素”方法，另一种是经过代数重构的数值稳定方法。\n\n**方法1：朴素求值**\n\n第一种方法是直接实现所提供的公式：\n$$\nPV_{\\text{naive}} = N \\left( \\sum_{i=1}^{T} (L_i + m)\\,\\alpha_i\\,D_i + D_T \\right)\n$$\n在这里，对于每个票息期 $i$，在进行乘法之前，将利差 $m$ 加到远期利率 $L_i$ 上。当 $m$ 远小于 $L_i$ 时（例如，在测试用例B和D中），这种加法可能会导致严重的浮点精度损失。如果 $m$ 的大小不足以影响 $L_i$ 的最低有效位，那么在浮点运算中，和 $L_i + m$ 就会被舍入为 $L_i$，导致利差 $m$ 的贡献完全丢失。这种现象被称为**数值吸收**。\n\n**方法2：数值稳定的求值**\n\n为了构建一个更稳定的方法，我们通过代数变换重新排列公式，以避免直接将小量 $m$ 与较大量的 $L_i$ 相加。首先，将求和内的项展开：\n$$\nPV = N \\left( \\sum_{i=1}^{T} L_i\\alpha_i D_i + \\sum_{i=1}^{T} m\\alpha_i D_i + D_T \\right)\n$$\n这个重构将涉及 $L_i$ 的计算与利差 $m$ 的贡献分离开来。接下来，我们利用折现因子的递归定义 $D_i = \\frac{D_{i-1}}{1 + L_i \\alpha_i}$。整理该式可得 $D_i(1 + L_i \\alpha_i) = D_{i-1}$，即 $D_i + L_i \\alpha_i D_i = D_{i-1}$。这提供了一个关键恒等式：\n$$\nL_i \\alpha_i D_i = D_{i-1} - D_i\n$$\n将此恒等式代入求和中，会产生一个伸缩级数（telescoping series）：\n$$\n\\sum_{i=1}^{T} L_i \\alpha_i D_i = \\sum_{i=1}^{T} (D_{i-1} - D_i) = (D_0 - D_1) + (D_1 - D_2) + \\dots + (D_{T-1} - D_T) = D_0 - D_T\n$$\n由于定义 $D_0 = 1$，该求和简化为 $1 - D_T$。将此结果代回展开的 $PV$ 表达式中：\n$$\nPV = N \\left( (1 - D_T) + m \\sum_{i=1}^{T} \\alpha_i D_i + D_T \\right)\n$$\n$D_T$ 项相互抵消，得到最终的、数值稳定的公式：\n$$\nPV_{\\text{stable}} = N \\left( 1 + m \\sum_{i=1}^{T} \\alpha_i D_i \\right)\n$$\n这个公式在数值上更为优越，因为它完全避免了 $L_i$ 和 $m$ 的相加。利差 $m$ 的总贡献是单独计算的，通过先求和折现的计息期分数，然后才乘以 $m$。这种方法保留了极小利差项的精度，确保其对最终价格的贡献不会因浮点算术的限制而丢失。\n\n对于每个测试用例，实现过程如下：\n1.  设置参数 $N$, $m$, $T$, 以及 $L_i$ 和 $\\alpha_i$ 数组。\n2.  使用指定的递归关系计算折现因子数组 $D_i$ (for $i=0, \\dots, T$)。\n3.  使用朴素公式计算 $PV_{\\text{naive}}$。\n4.  使用推导出的稳定公式计算 $PV_{\\text{stable}}$。\n5.  计算两个结果之间的绝对差，以量化朴素方法中的精度损失。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the floating-rate bond valuation problem for all test cases\n    and prints the results in the specified format.\n    \"\"\"\n\n    def generate_test_cases():\n        \"\"\"\n        Generates and returns the test cases as a list of dictionaries.\n        \"\"\"\n        # Test Case A\n        case_a = {\n            \"N\": 1_000_000.0,\n            \"T\": 8,\n            \"alpha\": np.full(8, 0.25),\n            \"L\": np.array([0.021, 0.022, 0.0235, 0.024, 0.025, 0.026, 0.027, 0.028]),\n            \"m\": 0.0005\n        }\n\n        # Test Case B\n        case_b = {\n            \"N\": 1_000_000_000.0,\n            \"T\": 8,\n            \"alpha\": np.full(8, 0.25),\n            \"L\": np.array([0.021, 0.022, 0.0235, 0.024, 0.025, 0.026, 0.027, 0.028]),\n            \"m\": 1e-20\n        }\n\n        # Test Case C\n        case_c = {\n            \"N\": 2_000_000.0,\n            \"T\": 8,\n            \"alpha\": np.full(8, 0.25),\n            \"L\": np.array([0.018, 0.019, 0.0195, 0.020, 0.0205, 0.021, 0.0215, 0.022]),\n            \"m\": 0.0\n        }\n\n        # Test Case D\n        T_d = 40\n        L_d = np.array([0.015 + 0.0001 * (i + 1) for i in range(T_d)])\n        case_d = {\n            \"N\": 100_000_000.0,\n            \"T\": T_d,\n            \"alpha\": np.full(T_d, 0.25),\n            \"L\": L_d,\n            \"m\": 1e-12\n        }\n\n        return [case_a, case_b, case_c, case_d]\n\n    def calculate_pvs(N, m, L, alpha):\n        \"\"\"\n        Calculates the present value of a floating-rate bond using two different methods.\n\n        Args:\n            N (float): Notional amount.\n            m (float): Margin.\n            L (np.ndarray): Array of forward rates.\n            alpha (np.ndarray): Array of accrual fractions.\n\n        Returns:\n            tuple: A tuple containing (pv_naive, pv_stable, abs_diff).\n        \"\"\"\n        T = len(L)\n        \n        # Calculate discount factors D_i for i=0,...,T\n        # D_0 = 1, D_i = D_{i-1} / (1 + L_i * alpha_i)\n        D = np.empty(T + 1, dtype=np.float64)\n        D[0] = 1.0\n        for i in range(1, T + 1):\n            D[i] = D[i - 1] / (1.0 + L[i - 1] * alpha[i - 1])\n        \n        # We need discount factors D_1, ..., D_T for the sums\n        D_coupon_periods = D[1:]\n\n        # Method 1: Naive PV calculation\n        # PV_naive = N * ( sum_{i=1 to T} (L_i + m) * alpha_i * D_i + D_T )\n        coupon_sum_naive = np.sum((L + m) * alpha * D_coupon_periods)\n        pv_naive = N * (coupon_sum_naive + D[T])\n\n        # Method 2: Stable PV calculation\n        # PV_stable = N * ( 1 + m * sum_{i=1 to T} alpha_i * D_i )\n        margin_sum_stable = np.sum(alpha * D_coupon_periods)\n        pv_stable = N * (1.0 + m * margin_sum_stable)\n\n        # Absolute difference\n        abs_diff = np.abs(pv_naive - pv_stable)\n\n        return pv_naive, pv_stable, abs_diff\n\n    test_cases = generate_test_cases()\n    results = []\n    \n    for case in test_cases:\n        pv_naive, pv_stable, abs_diff = calculate_pvs(\n            N=case[\"N\"], \n            m=case[\"m\"], \n            L=case[\"L\"], \n            alpha=case[\"alpha\"]\n        )\n        results.extend([pv_naive, pv_stable, abs_diff])\n\n    # Format the final output as a comma-separated list in a single line.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2394271"}, {"introduction": "并非所有的数值不稳定性都源于算法本身；有些问题在本质上就是“病态的”（ill-conditioned）。本练习探讨了一个具有八重根的多项式 $f(x) = (x-c)^8$，这种情况在某些经济模型的特征方程中可能出现 [@problem_id:2394189]。你将看到，即使一个根在理论上是明确的，有限精度计算也会导致标准求根算法收敛缓慢，甚至将单个根“打散”成一簇复数根，从而深刻理解问题条件数和不同数学表达形式对数值稳定性的巨大影响。", "problem": "考虑单变量多项式 $f(x) = (x - c)^{8}$，它在 $x = c$ 处有一个8重根。在计算经济学和金融学中，当重复的最优性条件或特征方程在多项式近似下产生高重根时，就会出现此类问题。在有限精度算术中，众所周知，重根在数值上是相当棘手的。假设采用遵循电气与电子工程师协会 (Institute of Electrical and Electronics Engineers, IEEE) $754$ 标准的标准双精度浮点算术。\n\n您必须编写一个完整的程序，对于每个测试用例，从第一性原理计算以下量：\n\n1. 计算机器ε $\\varepsilon$，其定义为在当前算术中满足 $1 + \\varepsilon > 1$ 的最小正浮点数，通过在运行时进行对半平分来确定。\n\n2. 令 $f(x) = (x-c)^{8}$，$f'(x)$ 表示其关于 $x$ 的导数。定义迭代映射 $a_{k+1} = a_{k} - \\dfrac{f(a_{k})}{f'(a_{k})}$，初始值 $a_{0}$ 由测试用例指定。经过 $T$ 步后，记录 $E_{\\text{std}} = |a_{T} - c|$。使用 $T = 12$。\n\n3. 定义迭代映射 $b_{k+1} = b_{k} - m \\dfrac{f(b_{k})}{f'(b_{k})}$，初始值 $b_{0} = a_{0}$，重数 $m = 8$。经过 $S$ 步后，记录 $E_{\\text{mod}} = |b_{S} - c|$。使用 $S = 2$。\n\n4. 构造展开式多项式\n$$\np(x) = \\sum_{k=0}^{8} \\binom{8}{k} (-c)^{8-k} x^{k}\n= x^{8} - 8 c x^{7} + 28 c^{2} x^{6} - 56 c^{3} x^{5} + 70 c^{4} x^{4} - 56 c^{5} x^{3} + 28 c^{6} x^{2} - 8 c^{7} x + c^{8}.\n$$\n使用标准浮点线性代数计算 $p(x)$ 的八个复根 $\\{z_{i}\\}_{i=1}^{8}$，并记录\n- $R_{\\text{avg}} = \\left| \\dfrac{1}{8} \\sum_{i=1}^{8} z_{i} - c \\right|$，\n- $R_{\\text{spread}} = \\max_{1 \\le i \\le 8} |z_{i} - c|$，\n其中作用于复数的 $|\\cdot|$ 表示复模。\n\n5. 令 $\\delta = \\sqrt{\\varepsilon} \\cdot \\max\\{1, |c|\\}$。计算 $f_{\\text{fact}} = ( (c + \\delta) - c )^{8}$，并使用第4项中展开的系数表示来计算 $f_{\\text{exp}} = p(c + \\delta)$。记录相对差异\n$$\nC_{\\text{rel}} = \\frac{|f_{\\text{exp}} - f_{\\text{fact}}|}{|f_{\\text{fact}}|}.\n$$\n\n您的程序必须对以下测试套件中的每个测试用例执行上述计算：\n- 测试 1：$(c, a_{0}) = (1.0, 2.0)$。\n- 测试 2：$(c, a_{0}) = (10^{-8}, 0.0)$。\n- 测试 3：$(c, a_{0}) = (10^{8}, 0.0)$。\n- 测试 4：$(c, a_{0}) = (10^{16}, 0.0)$。\n\n对于每个测试用例，所需的输出是五个实数 $[E_{\\text{std}}, E_{\\text{mod}}, R_{\\text{avg}}, R_{\\text{spread}}, C_{\\text{rel}}]$，需严格按照上述定义计算。您的程序应生成单行输出，其中包含四个测试的这五个数组块的串联，形式为方括号内以逗号分隔的列表，并按测试顺序排列。具体来说，最终输出必须是\n$$\n[E_{\\text{std}}^{(1)}, E_{\\text{mod}}^{(1)}, R_{\\text{avg}}^{(1)}, R_{\\text{spread}}^{(1)}, C_{\\text{rel}}^{(1)}, E_{\\text{std}}^{(2)}, E_{\\text{mod}}^{(2)}, R_{\\text{avg}}^{(2)}, R_{\\text{spread}}^{(2)}, C_{\\text{rel}}^{(2)}, E_{\\text{std}}^{(3)}, E_{\\text{mod}}^{(3)}, R_{\\text{avg}}^{(3)}, R_{\\text{spread}}^{(3)}, C_{\\text{rel}}^{(3)}, E_{\\text{std}}^{(4)}, E_{\\text{mod}}^{(4)}, R_{\\text{avg}}^{(4)}, R_{\\text{spread}}^{(4)}, C_{\\text{rel}}^{(4)}].\n$$\n\n所有输出均为无单位的实数。不涉及角度。不得使用百分比；所有比率必须以实数形式报告。", "solution": "本问题旨在探讨在有限精度浮点运算中，处理具有高重数根的多项式时所面临的数值挑战。我们以多项式 $f(x) = (x - c)^{8}$ 为例，它在 $x=c$ 处有一个重数为 $m=8$ 的根。我们将分析和比较几种不同方法的数值行为。\n\n**1. 机器 Epsilon ($\\varepsilon$)**\n机器 Epsilon ($\\varepsilon$) 是衡量浮点数系统相对精度的基本常数。它定义为1与大于1的下一个可表示浮点数之间的差值。根据问题要求，我们通过算法确定该值：从1.0开始，反复将其除以2，直到 $1.0 + (\\varepsilon/2)$ 在计算上等于1.0为止。最后一个满足 $1.0 + \\varepsilon > 1.0$ 的值即为机器 Epsilon。对于双精度浮点数，其理论值为 $2^{-52}$。\n\n**2. 标准牛顿-拉夫逊迭代 ($E_{\\text{std}}$)**\n牛顿-拉夫逊法通过迭代公式 $a_{k+1} = a_k - f(a_k)/f'(a_k)$ 寻找根。对于 $f(x) = (x-c)^8$，其导数为 $f'(x) = 8(x-c)^7$。迭代步骤在精确算术下简化为：\n$$\na_{k+1} = a_k - \\frac{a_k-c}{8} = \\frac{7}{8}a_k + \\frac{1}{8}c\n$$\n这表明误差 $e_k = a_k - c$ 随着每步迭代以常数因子 $\\frac{7}{8}$ 缩小 ($e_{k+1} = \\frac{7}{8}e_k$)。这是典型的**线性收敛**，其收敛因子为 $1 - 1/m$。对于重根，这种收敛速度非常慢。\n\n**3. 修正的牛顿-拉夫逊迭代 ($E_{\\text{mod}}$)**\n当根的重数 $m$ 已知时，可以通过修正迭代公式来恢复牛顿法的二次收敛性：$b_{k+1} = b_k - m \\cdot f(b_k)/f'(b_k)$。对于本例，$m=8$，迭代变为：\n$$\nb_{k+1} = b_k - 8 \\cdot \\frac{(b_k-c)^8}{8(b_k-c)^7} = b_k - (b_k - c) = c\n$$\n理论上，此方法仅需一步即可收敛到精确解。在实际的浮点运算中，它会极快地（二次）收敛到真根 $c$ 的一个极小邻域内。\n\n**4. 展开式多项式求根 ($R_{\\text{avg}}$, $R_{\\text{spread}}$)**\n问题要求计算二项式展开后的多项式 $p(x) = \\sum_{k=0}^{8} \\binom{8}{k} (-c)^{8-k} x^{k}$ 的根。用系数表示多项式对于高重根问题是数值不稳定的。当这些系数以有限精度存储时，它们会受到微小的舍入误差扰动。根据多项式求根的条件数理论，系数的微小扰动会导致根位置的巨大变化。因此，单个重根 $x=c$ 在计算上会“碎裂”成一个由八个不同的复数根 $\\{z_i\\}$ 组成的“簇”，分布在 $c$ 的周围。我们使用标准数值库（如 NumPy 的 `roots` 函数）来计算这些根，并通过计算它们与真根 $c$ 的平均偏差 ($R_{\\text{avg}}$) 和最大偏差 ($R_{\\text{spread}}$) 来量化这种不稳定性。\n\n**5. 条件数分析 ($C_{\\text{rel}}$)**\n最后一部分直接对比了两种多项式表示形式的数值稳定性：因式分解形式 $f(x)=(x-c)^8$ 和展开形式 $p(x)$。我们引入一个微小的扰动 $\\delta = \\sqrt{\\varepsilon} \\cdot \\max\\{1, |c|\\}$ 来进行测试。\n- 在因式分解形式下求值，$f_{\\text{fact}} = ((c+\\delta)-c)^8$，是数值稳定的。减法 $(c+\\delta)-c$ 能精确恢复 $\\delta$，结果非常接近真实的数学值 $\\delta^8$。\n- 在展开形式下求值，$p(c+\\delta)$，是数值不稳定的。计算过程涉及对许多符号交替的大数求和，它们相互抵消以产生一个非常小的最终结果。这种现象是**灾难性抵消**的典型例子，它会急剧放大初始的舍入误差。\n相对差异 $C_{\\text{rel}} = |f_{\\text{exp}} - f_{\\text{fact}}| / |f_{\\text{fact}}|$ 衡量了这种不稳定性的程度。一个大的 $C_{\\text{rel}}$ 值表明，多项式的展开形式在接近其重根处求值是病态的。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the numerical analysis problem for the given test cases.\n    \"\"\"\n\n    test_cases = [\n        # (c, a0)\n        (1.0, 2.0),\n        (1e-8, 0.0),\n        (1e8, 0.0),\n        (1e16, 0.0),\n    ]\n\n    all_results = []\n    \n    # Binomial coefficients B(8,j) for j=0..8\n    # These correspond to B(n,k) for n=8 and k=0, 1, ..., 8\n    binomial_coeffs = np.array([1, 8, 28, 56, 70, 56, 28, 8, 1], dtype=np.float64)\n\n    for c, a0 in test_cases:\n        c_f64 = np.float64(c)\n        a0_f64 = np.float64(a0)\n\n        # 1. Compute machine epsilon\n        eps = np.float64(1.0)\n        while np.float64(1.0) + eps / np.float64(2.0)  np.float64(1.0):\n            eps /= np.float64(2.0)\n\n        # 2. Standard Newton's Method\n        T = 12\n        a_k = a0_f64\n        for _ in range(T):\n            diff = a_k - c_f64\n            # Prevent division by zero if a_k becomes numerically equal to c\n            if diff == 0.0:\n                break\n            f_val = diff**8\n            f_prime_val = 8.0 * (diff**7)\n            # Prevent NaN from 0/0 and halt if derivative is numerically zero\n            if f_prime_val == 0.0:\n                break\n            a_k -= f_val / f_prime_val\n        E_std = np.abs(a_k - c_f64)\n\n        # 3. Modified Newton's Method\n        S = 2\n        m = 8.0\n        b_k = a0_f64\n        for _ in range(S):\n            diff = b_k - c_f64\n            if diff == 0.0:\n                break\n            f_val = diff**8\n            f_prime_val = 8.0 * (diff**7)\n            if f_prime_val == 0.0:\n                break\n            b_k -= m * f_val / f_prime_val\n        E_mod = np.abs(b_k - c_f64)\n\n        # 4. Expanded Polynomial Root Finding\n        # The coefficient for x^k is binom(8,k) * (-c)^(8-k).\n        # numpy.roots needs coefficients for [x^8, x^7, ..., x^0].\n        # The coefficient for x^(8-j) is binom(8, 8-j) * (-c)^j = binom(8,j) * (-c)^j.\n        p_coeffs = np.zeros(9, dtype=np.float64)\n        for j in range(9):\n            p_coeffs[j] = binomial_coeffs[j] * ((-c_f64)**j)\n        \n        roots = np.roots(p_coeffs)\n        \n        R_avg = np.abs(np.mean(roots) - c_f64)\n        R_spread = np.max(np.abs(roots - c_f64))\n\n        # 5. Conditioning Analysis\n        delta = np.sqrt(eps) * np.max([1.0, np.abs(c_f64)])\n        \n        # Factored form evaluation (numerically stable)\n        f_fact = ((c_f64 + delta) - c_f64)**8\n        \n        # Expanded form evaluation using Horner's method (numerically unstable)\n        x_eval = c_f64 + delta\n        f_exp = p_coeffs[0]\n        for i in range(1, 9):\n            f_exp = f_exp * x_eval + p_coeffs[i]\n        \n        # Relative discrepancy\n        if f_fact == 0.0:\n            C_rel = np.inf if f_exp != 0.0 else 0.0\n        else:\n            C_rel = np.abs(f_exp - f_fact) / np.abs(f_fact)\n\n        all_results.extend([E_std, E_mod, R_avg, R_spread, C_rel])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "2394189"}]}