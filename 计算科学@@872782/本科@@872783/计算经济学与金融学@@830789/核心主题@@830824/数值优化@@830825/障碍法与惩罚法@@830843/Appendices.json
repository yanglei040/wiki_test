{"hands_on_practices": [{"introduction": "第一个动手实践将作为一项基础练习，指导你实现序列二次罚函数法。你将发现“热启动”（warm-starting）的实际重要性——即利用前一个子问题的解作为下一个子问题的初始猜测。这项练习 ([@problem_id:2423453]) 不仅能让你掌握一项核心算法技能，还展示了在求解一系列相关优化问题时提高计算效率的关键技巧。", "problem": "要求您实现用于约束优化的序列二次罚函数法，并通过实验量化“热启动”（即将前一个子问题的解作为下一个罚参数的初始猜测值）的优势。实现一个带有回溯 Armijo 线搜索的基于梯度的求解器，以最小化一系列无约束的惩罚子问题。对于固定的罚参数序列 $\\{\\rho_k\\}_{k=1}^K$（其中 $\\rho_1  \\rho_2  \\dots  \\rho_K$），请对每个测试用例比较两种策略：（i）从相同的初始点对每个子问题进行“冷启动”，以及（ii）从子问题 $k$ 的计算出的最小化器开始对子问题 $k+1$ 进行“热启动”。报告在整个罚函数序列中，“冷启动”所占用的梯度下降总迭代次数与“热启动”所占用的总迭代次数之比所定义的加速因子。\n\n使用的基本原理和定义：\n- 一个约束最小化问题具有目标函数 $f:\\mathbb{R}^n\\to\\mathbb{R}$，不等式约束 $g_i(x)\\le 0$（$i\\in\\{1,\\dots,m\\}$），以及等式约束 $h_j(x)=0$（$j\\in\\{1,\\dots,p\\}$）。\n- 经典二次罚函数对不等式的惩罚应用于其违反部分，形式为 $\\max\\{0, g_i(x)\\}^2$，对等式的惩罚形式为 $h_j(x)^2$。\n- 对于给定的 $\\rho0$，惩罚子问题是最小化\n$$\n\\Phi_\\rho(x)=f(x)+\\rho\\left(\\sum_{i=1}^m \\max\\{0,g_i(x)\\}^2+\\sum_{j=1}^p h_j(x)^2\\right).\n$$\n- 使用带有回溯 Armijo 法则的梯度下降法：给定当前点 $x$、梯度 $\\nabla\\Phi_\\rho(x)$、初始步长 $t_0$、收缩因子 $\\beta\\in(0,1)$ 和 Armijo 参数 $c\\in(0,1)$，从序列 $\\{t_0, \\beta t_0, \\beta^2 t_0,\\dots\\}$ 中选择满足以下条件的最大 $t$：\n$$\n\\Phi_\\rho(x - t \\nabla \\Phi_\\rho(x)) \\le \\Phi_\\rho(x) - c\\,t\\,\\|\\nabla \\Phi_\\rho(x)\\|_2^2.\n$$\n- 当 $\\|\\nabla \\Phi_\\rho(x)\\|_2\\le \\varepsilon$ 时，停止内部求解器。\n\n实现要求：\n- 严格按照上述定义实现二次罚函数法和带有回溯 Armijo 线搜索的梯度下降法。\n- 对于不等式约束，仅通过在罚函数值及其梯度中使用 $\\max\\{0,\\cdot\\}$ 结构来处理正的违反部分。对于等式约束，惩罚其残差的平方。\n- 使用罚函数序列 $\\rho\\in\\{10,10^2,10^3\\}$，即 $\\rho \\in \\{10,100,1000\\}$。\n- 对所有子问题，使用梯度容差 $\\varepsilon=10^{-6}$、Armijo 参数 $c=10^{-4}$、收缩因子 $\\beta=\\tfrac{1}{2}$ 和初始步长 $t_0=1$。每个子问题的最大梯度迭代次数上限为 $N_{\\max}=10^4$。\n- 计算使一个子问题收敛所需的外部梯度下降迭代次数（每次线搜索后接受的步数）；不要单独计算线搜索的回溯步数。\n\n测试套件：\n实现并求解以下三个二维测试用例。在每个用例中，返回加速因子\n$$\nS=\\frac{N_{\\mathrm{cold}}}{N_{\\mathrm{warm}}},\n$$\n其中 $N_{\\mathrm{cold}}$ 是从指定初始点对每个子问题进行“冷启动”时，在所有罚参数上累加的梯度下降总迭代次数；$N_{\\mathrm{warm}}$ 是从前一个子问题的解对每个子问题进行“热启动”时的总迭代次数。\n\n- 用例 $\\mathbf{A}$（带有约束性线性不等式的凸二次问题）：\n  - 目标函数：$f(x,y)=(x-1)^2+2\\,(y+2)^2$。\n  - 不等式约束：$g_1(x,y)=1-x-y\\le 0$。\n  - 无等式约束。\n  - 初始点：$x_0=(0,0)$。\n\n- 用例 $\\mathbf{B}$（带有等式约束的凸二次问题）：\n  - 目标函数：$f(x,y)=(x-3)^2+(y-1)^2$。\n  - 等式约束：$h_1(x,y)=x-y=0$。\n  - 无不等式约束。\n  - 初始点：$x_0=(0,0)$。\n\n- 用例 $\\mathbf{C}$（带有曲线不等式约束的凸二次问题）：\n  - 目标函数：$f(x,y)=(x+2)^2+y^2$。\n  - 不等式约束：$g_1(x,y)=x^2+y^2-1\\le 0$。\n  - 无等式约束。\n  - 初始点：$x_0=(0,0)$。\n\n输出规范：\n- 对每个用例，计算如上定义的加速因子 $S$。\n- 您的程序应生成单行输出，其中包含三个加速因子，格式为方括号内的逗号分隔列表，顺序为 $\\left[S_A,S_B,S_C\\right]$，其中 $S_A$ 对应于用例 $\\mathbf{A}$，$S_B$ 对应于用例 $\\mathbf{B}$，$S_C$ 对应于用例 $\\mathbf{C}$。例如，输出形式为 $\\left[\\text{result}_1,\\text{result}_2,\\text{result}_3\\right]$，其中包含数值。\n- 将每个加速因子表示为浮点数。您可以在内部进行四舍五入，但打印出的值必须是标准的十进制浮点数。\n\n不涉及物理单位。不使用角度。不使用百分比。\n\n最终程序必须是自包含的，不需要任何输入，并遵守指定的运行时环境。其正确性将通过验证实现是否遵循定义，以及热启动产生的迭代次数是否严格更少或至少不更多（从而为指定用例产生有意义的加速因子）来评估。输出必须严格为指定格式的一行。", "solution": "该问题要求实现序列二次罚函数法来求解约束优化问题。任务的核心是比较两种用于一系列无约束子问题的初始化策略的计算效率：“冷启动”策略与“热启动”策略。效率将通过一个加速因子来量化，该因子定义为总梯度下降迭代次数之比。\n\n约束优化问题的一般形式是，在满足一系列不等式约束 $g_i(x) \\le 0$（$i \\in \\{1, \\dots, m\\}$）和等式约束 $h_j(x) = 0$（$j \\in \\{1, \\dots, p\\}$）的条件下，最小化目标函数 $f(x)$，其中 $x \\in \\mathbb{R}^n$。\n\n二次罚函数法通过求解一系列无约束最小化问题来逼近此问题的解。对于给定的罚参数 $\\rho  0$，通过向原始目标函数添加惩罚违反约束的项来构造惩罚目标函数 $\\Phi_\\rho(x)$。惩罚函数的具体形式为：\n$$\n\\Phi_\\rho(x) = f(x) + \\rho \\left( \\sum_{i=1}^m \\left(\\max\\{0, g_i(x)\\}\\right)^2 + \\sum_{j=1}^p \\left(h_j(x)\\right)^2 \\right)\n$$\n然后，此函数 $\\Phi_\\rho(x)$ 相对于 $x$ 进行最小化。通过为一系列递增的罚参数 $\\rho_1  \\rho_2  \\dots  \\rho_K$ 求解这个无约束问题，最小化器序列 $x^*(\\rho_k)$ 将收敛到原始约束问题的解。\n\n为了最小化每个无约束子问题 $\\min_x \\Phi_\\rho(x)$，需要一种基于梯度的方法。惩罚目标函数的梯度 $\\nabla \\Phi_\\rho(x)$ 使用链式法则推导。对于不等式约束项 $P_i(x) = \\rho (\\max\\{0, g_i(x)\\})^2$，其梯度为 $\\nabla P_i(x) = 2 \\rho \\max\\{0, g_i(x)\\} \\nabla g_i(x)$。对于等式约束项 $Q_j(x) = \\rho (h_j(x))^2$，其梯度为 $\\nabla Q_j(x) = 2 \\rho h_j(x) \\nabla h_j(x)$。将这些与目标函数的梯度相结合，完整的梯度为：\n$$\n\\nabla \\Phi_\\rho(x) = \\nabla f(x) + 2\\rho \\left( \\sum_{i=1}^m \\max\\{0, g_i(x)\\} \\nabla g_i(x) + \\sum_{j=1}^p h_j(x) \\nabla h_j(x) \\right)\n$$\n无约束最小化使用梯度下降法执行。从点 $x_k$ 开始，下一个点 $x_{k+1}$ 通过沿负梯度方向移动找到：\n$$\nx_{k+1} = x_k - t \\nabla \\Phi_\\rho(x_k)\n$$\n步长 $t  0$ 由采用 Armijo 条件的回溯线搜索确定。对于给定的下降方向 $d_k = -\\nabla \\Phi_\\rho(x_k)$，我们从序列 $\\{t_0, \\beta t_0, \\beta^2 t_0, \\dots\\}$ 中寻找满足以下条件的最大 $t$：\n$$\n\\Phi_\\rho(x_k + t d_k) \\le \\Phi_\\rho(x_k) + c \\, t \\, \\nabla \\Phi_\\rho(x_k)^T d_k\n$$\n使用 $d_k = -\\nabla \\Phi_\\rho(x_k)$，这可简化为问题描述中给出的形式：\n$$\n\\Phi_\\rho(x_k - t \\nabla \\Phi_\\rho(x_k)) \\le \\Phi_\\rho(x_k) - c \\, t \\, \\|\\nabla \\Phi_\\rho(x_k)\\|_2^2\n$$\n算法迭代进行，直到梯度的范数低于指定的容差 $\\varepsilon$，即 $\\|\\nabla \\Phi_\\rho(x)\\|_2 \\le \\varepsilon$。此求解器的参数是固定的：初始步长 $t_0=1$，Armijo 参数 $c=10^{-4}$，收缩因子 $\\beta=0.5$，以及梯度范数容差 $\\varepsilon=10^{-6}$。每个子问题的最大迭代次数上限为 $N_{\\max}=10^4$。\n\n该实验在罚参数序列 $\\rho \\in \\{10, 100, 1000\\}$ 上比较两种策略：\n1.  **冷启动（Cold-Start）：** 每个针对 $\\rho_k$ 的子问题都从相同的起始点 $x_0$ 初始化。总迭代次数 $N_{\\mathrm{cold}}$ 是独立求解每个子问题所需迭代次数的总和。\n2.  **热启动（Warm-Start）：** 第一个子问题（针对 $\\rho_1=10$）从 $x_0$ 初始化。每个后续的 $\\rho_{k+1}$ 的子问题使用从前一个 $\\rho_k$ 子问题获得的解进行初始化。总迭代次数 $N_{\\mathrm{warm}}$ 是此序列中所有迭代次数的总和。\n\n“热启动”的基本原理是，解 $x^*(\\rho_k)$ 有望成为 $\\Phi_{\\rho_{k+1}}(x)$ 最小化器的一个良好初始猜测，特别是当 $\\rho_{k+1}$ 不比 $\\rho_k$ 大很多时。这应该会带来更快的收敛。性能增益通过加速因子 $S = N_{\\mathrm{cold}} / N_{\\mathrm{warm}}$ 来衡量。\n\n实现将通过为每个测试用例的目标函数、约束函数及其各自的梯度定义 Python 函数来进行。一个通用的求解器函数将执行带有 Armijo 线搜索的梯度下降。一个顶层函数将管理罚参数序列，应用冷启动和热启动策略，计算每种策略的总迭代次数，并计算加速比。对所有三个提供的测试用例重复此过程。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases and print the results.\n    \"\"\"\n    \n    # --- Solver Parameters ---\n    SOLVER_PARAMS = {\n        'epsilon': 1e-6,\n        'c_armijo': 1e-4,\n        'beta': 0.5,\n        't0': 1.0,\n        'n_max': 10000\n    }\n    PENALTY_PARAMS = [10.0, 100.0, 1000.0]\n\n    # --- Test Case Definitions ---\n    \n    # Case A: (x-1)^2 + 2(y+2)^2, s.t. 1-x-y = 0\n    case_A = {\n        'f': lambda x: (x[0] - 1.0)**2 + 2.0 * (x[1] + 2.0)**2,\n        'grad_f': lambda x: np.array([2.0 * (x[0] - 1.0), 4.0 * (x[1] + 2.0)]),\n        'g': [lambda x: 1.0 - x[0] - x[1]],\n        'grad_g': [lambda x: np.array([-1.0, -1.0])],\n        'h': [],\n        'grad_h': [],\n        'x0': np.array([0.0, 0.0])\n    }\n\n    # Case B: (x-3)^2 + (y-1)^2, s.t. x-y = 0\n    case_B = {\n        'f': lambda x: (x[0] - 3.0)**2 + (x[1] - 1.0)**2,\n        'grad_f': lambda x: np.array([2.0 * (x[0] - 3.0), 2.0 * (x[1] - 1.0)]),\n        'g': [],\n        'grad_g': [],\n        'h': [lambda x: x[0] - x[1]],\n        'grad_h': [lambda x: np.array([1.0, -1.0])],\n        'x0': np.array([0.0, 0.0])\n    }\n    \n    # Case C: (x+2)^2 + y^2, s.t. x^2+y^2-1 = 0\n    case_C = {\n        'f': lambda x: (x[0] + 2.0)**2 + x[1]**2,\n        'grad_f': lambda x: np.array([2.0 * (x[0] + 2.0), 2.0 * x[1]]),\n        'g': [lambda x: x[0]**2 + x[1]**2 - 1.0],\n        'grad_g': [lambda x: np.array([2.0 * x[0], 2.0 * x[1]])],\n        'h': [],\n        'grad_h': [],\n        'x0': np.array([0.0, 0.0])\n    }\n\n    test_cases = [case_A, case_B, case_C]\n    \n    def get_penalized_funcs(case, rho):\n        \"\"\"Creates the penalized function and its gradient for a given case and rho.\"\"\"\n        \n        def phi(x):\n            f_val = case['f'](x)\n            g_sum = sum(max(0, g_func(x))**2 for g_func in case['g'])\n            h_sum = sum(h_func(x)**2 for h_func in case['h'])\n            return f_val + rho * (g_sum + h_sum)\n\n        def grad_phi(x):\n            grad_f_val = case['grad_f'](x)\n            \n            grad_g_sum = np.zeros_like(x)\n            for g_func, grad_g_func in zip(case['g'], case['grad_g']):\n                g_val = g_func(x)\n                if g_val > 0:\n                    grad_g_sum += 2.0 * g_val * grad_g_func(x)\n\n            grad_h_sum = np.zeros_like(x)\n            for h_func, grad_h_func in zip(case['h'], case['grad_h']):\n                h_val = h_func(x)\n                grad_h_sum += 2.0 * h_val * grad_h_func(x)\n                \n            return grad_f_val + rho * (grad_g_sum + grad_h_sum)\n        \n        return phi, grad_phi\n\n    def gradient_descent(phi, grad_phi, x_init, params):\n        \"\"\"\n        Performs gradient descent with backtracking Armijo line search.\n        \"\"\"\n        x = np.copy(x_init)\n        n_iters = 0\n        \n        for k in range(params['n_max']):\n            grad = grad_phi(x)\n            grad_norm_sq = np.dot(grad, grad)\n\n            if np.sqrt(grad_norm_sq) = params['epsilon']:\n                break\n            \n            # Backtracking line search\n            t = params['t0']\n            phi_x = phi(x)\n            \n            while True:\n                x_new = x - t * grad\n                phi_new = phi(x_new)\n                armijo_check = phi_x - params['c_armijo'] * t * grad_norm_sq\n                \n                if phi_new = armijo_check:\n                    break\n                t *= params['beta']\n            \n            x = x_new\n            n_iters += 1\n        \n        return x, n_iters\n\n    def run_penalty_method(case, solver_params, penalty_params):\n        \"\"\"\n        Runs the full sequential penalty method for a case,\n        calculating iterations for both cold and warm starts.\n        \"\"\"\n        # Cold start\n        total_iters_cold = 0\n        for rho in penalty_params:\n            phi, grad_phi = get_penalized_funcs(case, rho)\n            _, n_iters = gradient_descent(phi, grad_phi, case['x0'], solver_params)\n            total_iters_cold += n_iters\n            \n        # Warm start\n        total_iters_warm = 0\n        x_warm = np.copy(case['x0'])\n        for rho in penalty_params:\n            phi, grad_phi = get_penalized_funcs(case, rho)\n            x_sol, n_iters = gradient_descent(phi, grad_phi, x_warm, solver_params)\n            total_iters_warm += n_iters\n            x_warm = x_sol\n            \n        if total_iters_warm == 0:\n             # This case should not happen in this problem, but is a safeguard.\n             # If cold is also 0, speedup is 1. If cold > 0, speedup is \"infinite\".\n            return 1.0 if total_iters_cold == 0 else float('inf')\n            \n        return float(total_iters_cold) / float(total_iters_warm)\n\n    results = []\n    for case in test_cases:\n        speedup = run_penalty_method(case, SOLVER_PARAMS, PENALTY_PARAMS)\n        results.append(speedup)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2423453"}, {"introduction": "在罚函数法的基础上，本实践将其应用于计算金融领域的一个常见挑战：寻找一个满足多个（通常是相互冲突的）约束条件的初始投资组合。这通常被称为“第一阶段”（Phase I）问题或可行性问题。通过这项练习 ([@problem_id:2374527])，你将学会如何将一个带约束的可行性搜索问题转化为一个无约束的优化问题，这是初始化更复杂的投资组合优化算法的一项关键技术。", "problem": "考虑构建一个满足一系列经济和金融约束的初始投资组合向量的任务。令 $n \\in \\mathbb{N}$ 表示资产数量，$\\mu \\in \\mathbb{R}^n$ 为预期收益率向量，$\\Sigma \\in \\mathbb{R}^{n \\times n}$ 为对称正定的收益率协方差矩阵。令 $u \\in \\mathbb{R}^n$ 为一个分量级别的权重上限向量。投资组合权重为 $w \\in \\mathbb{R}^n$。需要满足的约束条件如下：\n- 预算等式：$\\sum_{i=1}^n w_i = 1$。\n- 下限（无卖空）：对于所有 $i \\in \\{1,\\dots,n\\}$，有 $w_i \\ge 0$。\n- 上限：对于所有 $i \\in \\{1,\\dots,n\\}$，有 $w_i \\le u_i$。\n- 要求预期收益率：$\\mu^\\top w \\ge R_{\\text{target}}$。\n- 风险上限：$w^\\top \\Sigma w \\le V_{\\max}$。\n\n将不等式函数定义为标准形式 $g(w) \\le 0$，等式函数定义为 $h(w) = 0$ 如下：\n- $g_{\\text{ret}}(w) = R_{\\text{target}} - \\mu^\\top w$，\n- $g_{\\text{var}}(w) = w^\\top \\Sigma w - V_{\\max}$，\n- $g_{\\text{lo},i}(w) = -w_i$（对于每个 $i \\in \\{1,\\dots,n\\}$），\n- $g_{\\text{up},i}(w) = w_i - u_i$（对于每个 $i \\in \\{1,\\dots,n\\}$），\n- $h_{\\text{bud}}(w) = \\mathbf{1}^\\top w - 1$，其中 $\\mathbf{1}$ 是 $\\mathbb{R}^n$ 中全为1的向量。\n\n对于任意惩罚参数 $\\rho  0$，定义价值函数\n$$\nM_\\rho(w) \\;=\\; \\rho \\left( \\sum_{i=1}^n \\bigl(\\max\\{0, g_{\\text{lo},i}(w)\\}\\bigr)^2 \\;+\\; \\sum_{i=1}^n \\bigl(\\max\\{0, g_{\\text{up},i}(w)\\}\\bigr)^2 \\;+\\; \\bigl(\\max\\{0, g_{\\text{ret}}(w)\\}\\bigr)^2 \\;+\\; \\bigl(\\max\\{0, g_{\\text{var}}(w)\\}\\bigr)^2 \\;+\\; \\bigl(h_{\\text{bud}}(w)\\bigr)^2 \\right) \\;+\\; \\lambda \\,\\|w\\|_2^2,\n$$\n其中 $\\lambda  0$ 是一个固定的正则化参数，$\\|\\cdot\\|_2$ 表示欧几里得范数。\n\n对于给定的容差 $\\tau  0$，将在任意 $w$ 处的最大约束违反度定义为\n$$\n\\mathrm{vio}(w) \\;=\\; \\max\\!\\left( \\left| h_{\\text{bud}}(w) \\right|, \\;\\max\\{0, g_{\\text{ret}}(w)\\}, \\;\\max\\{0, g_{\\text{var}}(w)\\}, \\;\\max_{i=1,\\dots,n}\\max\\{0, g_{\\text{lo},i}(w)\\}, \\;\\max_{i=1,\\dots,n}\\max\\{0, g_{\\text{up},i}(w)\\} \\right).\n$$\n\n对于下方的每个测试实例，您的程序必须从序列 $\\{10^1, 10^2, 10^3, 10^4, 10^5, 10^6\\}$ 中选择某个 $\\rho$ 来生成一个近似最小化 $M_\\rho(w)$ 的向量 $w$，然后报告所获得的 $w$ 对应的 $\\mathrm{vio}(w)$ 值。对于每个测试实例，从序列中选择能够使 $\\mathrm{vio}(w) \\le \\tau$ 的最小 $\\rho$（如果存在）；如果没有这样的 $\\rho$ 能满足 $\\mathrm{vio}(w) \\le \\tau$，则报告在最大 $\\rho = 10^6$ 时实现的 $\\mathrm{vio}(w)$。使用固定的容差 $\\tau = 10^{-6}$ 和正则化参数 $\\lambda = 10^{-8}$。\n\n测试套件：\n- 测试用例 A：\n  - $n = 3$，\n  - $\\mu = [\\,0.06,\\; 0.10,\\; 0.14\\,]$，\n  - $\\Sigma = \\begin{bmatrix} 0.010  0.002  0.001 \\\\ 0.002  0.020  0.003 \\\\ 0.001  0.003  0.030 \\end{bmatrix}$，\n  - $u = [\\,0.8,\\; 0.8,\\; 0.8\\,]$，\n  - $R_{\\text{target}} = 0.09$，\n  - $V_{\\max} = 0.025$。\n- 测试用例 B：\n  - $n = 3$，\n  - $\\mu = [\\,0.03,\\; 0.05,\\; 0.07\\,]$，\n  - $\\Sigma = \\begin{bmatrix} 0.008  0.001  0.0005 \\\\ 0.001  0.012  0.001 \\\\ 0.0005  0.001  0.015 \\end{bmatrix}$，\n  - $u = [\\,0.8,\\; 0.8,\\; 0.8\\,]$，\n  - $R_{\\text{target}} = 0.07$，\n  - $V_{\\max} = 0.05$。\n- 测试用例 C：\n  - $n = 4$，\n  - $\\mu = [\\,0.05,\\; 0.08,\\; 0.12,\\; 0.04\\,]$，\n  - $\\Sigma = \\begin{bmatrix}\n  0.005  0.001  0.001  0.0005 \\\\\n  0.001  0.010  0.002  0.001 \\\\\n  0.001  0.002  0.020  0.0015 \\\\\n  0.0005  0.001  0.0015  0.004\n  \\end{bmatrix}$，\n  - $u = [\\,0.6,\\; 0.6,\\; 0.5,\\; 1.0\\,]$，\n  - $R_{\\text{target}} = 0.08$，\n  - $V_{\\max} = 0.012$。\n\n所有测试实例的初始条件：使用任意确定性的 $w^{(0)} \\in \\mathbb{R}^n$；例如，分量为 $w^{(0)}_i = 1/n$ 的等权重向量 $w^{(0)}$。\n\n您的程序必须在单行中输出三个测试用例的最大约束违反度，格式完全如下：一个列表中包含三个浮点数，每个浮点数四舍五入到小数点后六位，用逗号分隔，并用方括号括起来，顺序为测试用例 A、B、C。例如，输出行必须类似于 $[v_A,v_B,v_C]$，其中 $v_A$、$v_B$、$v_C$ 均为四舍五入到六位小数的浮点数。不得打印任何额外文本。", "solution": "该问题要求找到一个投资组合权重向量 $w \\in \\mathbb{R}^n$，该向量需满足一组线性和二次等式及不等式约束。这是一个计算金融学中的可行性问题。为找到此向量而提出的方法是惩罚方法，它将约束问题转化为一系列无约束优化问题。\n\n该方法的核心是构建一个必须被最小化的价值函数 $M_\\rho(w)$。对于给定的惩罚参数 $\\rho  0$，该函数定义为：\n$$\nM_\\rho(w) \\;=\\; \\rho \\cdot P(w) \\;+\\; \\lambda \\,\\|w\\|_2^2\n$$\n其中 $P(w)$ 是惩罚项，$\\lambda \\|w\\|_2^2$ 是正则化项。惩罚项汇总了所有约束的违反情况：\n$$\nP(w) \\;=\\; \\sum_{j} \\bigl(\\max\\{0, g_j(w)\\}\\bigr)^2 \\;+\\; \\sum_{k} \\bigl(h_k(w)\\bigr)^2\n$$\n此处，$g_j(w) \\le 0$ 是不等式约束，$h_k(w) = 0$ 是等式约束。问题陈述为该投资组合问题明确定义了这些约束：\n- 不等式：$g_{\\text{ret}}(w) = R_{\\text{target}} - \\mu^\\top w$，$g_{\\text{var}}(w) = w^\\top \\Sigma w - V_{\\max}$，$g_{\\text{lo},i}(w) = -w_i$ 和 $g_{\\text{up},i}(w) = w_i - u_i$。\n- 等式：$h_{\\text{bud}}(w) = \\mathbf{1}^\\top w - 1$。\n\n函数 $M_\\rho(w)$ 是一个无约束的连续可微（$C^1$）函数。其性质至关重要。定义约束的函数 $g_j(w)$ 和 $h_k(w)$ 是仿射函数，或者在 $g_{\\text{var}}(w)$ 的情况下是凸函数，因为协方差矩阵 $\\Sigma$ 是正定的。函数 $\\max\\{0, \\cdot\\}$ 是凸且非递减的。一个凸函数与一个非负、非递减的凸函数（如当 $x \\ge 0$ 时的 $x \\mapsto x^2$）的复合会保持凸性。因此，每一项 $\\bigl(\\max\\{0, g_j(w)\\}\\bigr)^2$ 都是凸的。同样，仿射函数的平方 $\\bigl(h_k(w)\\bigr)^2$ 也是凸的。由于当 $\\lambda  0$ 时正则化项 $\\lambda \\|w\\|_2^2$ 是强凸的，价值函数 $M_\\rho(w)$ 作为包含一个强凸项的凸函数的非负和，其本身也是强凸的。这是一个关键性质，因为它保证了对于任何给定的 $\\rho  0$，$M_\\rho(w)$ 都有一个唯一的全局最小值点。\n\n为了数值求解这个最小值点，我们可以采用一种基于梯度的优化算法。Broyden–Fletcher–Goldfarb–Shanno (BFGS) 算法是解决此无约束 $C^1$ 最小化问题的合适选择。为使算法高效且准确，我们必须提供价值函数的解析梯度 $\\nabla M_\\rho(w)$。使用链式法则，梯度为：\n$$\n\\nabla M_\\rho(w) = 2\\rho \\left( \\sum_{j} \\max\\{0, g_j(w)\\} \\nabla g_j(w) \\;+\\; \\sum_{k} h_k(w) \\nabla h_k(w) \\right) \\;+\\; 2\\lambda w\n$$\n各个约束函数的梯度很容易计算：\n- $\\nabla g_{\\text{lo},i}(w) = -e_i$（其中 $e_i$ 是第 $i$ 个标准基向量）\n- $\\nabla g_{\\text{up},i}(w) = e_i$\n- $\\nabla g_{\\text{ret}}(w) = -\\mu$\n- $\\nabla g_{\\text{var}}(w) = 2 \\Sigma w$（因为 $\\Sigma$ 是对称的）\n- $\\nabla h_{\\text{bud}}(w) = \\mathbf{1}$（一个全为1的向量）\n\n将这些代入 $\\nabla M_\\rho(w)$ 的表达式，可以得到一个可用于数值实现的梯度向量的完整公式。\n\n根据问题规定，整体流程如下：\n1. 使用等权重向量初始化投资组合，即 $w^{(0)}_i = 1/n$。\n2. 遍历预设的惩罚参数序列 $\\rho \\in \\{10^1, 10^2, \\dots, 10^6\\}$。\n3. 在每次迭代中，使用 BFGS 算法数值求解无约束最小化问题 $w^* = \\arg\\min_w M_\\rho(w)$，并以上一次迭代的解作为初始值（一种热启动策略）。\n4. 找到当前 $\\rho$ 的最优解 $w^*$ 后，计算问题陈述中定义的最大约束违反度 $\\mathrm{vio}(w^*)$。\n5. 如果 $\\mathrm{vio}(w^*) \\le \\tau = 10^{-6}$，则当前测试用例的处理终止，并将此违反度值作为结果。\n6. 如果未满足容差，则继续使用下一个更大的 $\\rho$ 值。如果循环完成仍未满足容差，则报告最后一步（$\\rho = 10^6$ 时）的违反度。\n\n这种系统化的方法确保了，如果在给定的 $\\rho$ 序列中能够找到解，我们就能找到一个满足所需精度的可行解；否则，我们报告对应于最高惩罚的“尽力而为”的解。由于所有测试用例的可行域都是非空的，我们期望该算法能够找到满足容差 $\\tau$ 的解。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main solver function to run all test cases and print the final results.\n    \"\"\"\n    \n    # Global parameters as specified in the problem\n    LAMBDA = 1e-8\n    TAU = 1e-6\n    RHO_SEQUENCE = np.array([1e1, 1e2, 1e3, 1e4, 1e5, 1e6])\n\n    # Test cases data\n    test_cases = [\n        # Case A\n        {\n            \"n\": 3,\n            \"mu\": np.array([0.06, 0.10, 0.14]),\n            \"Sigma\": np.array([[0.010, 0.002, 0.001],\n                               [0.002, 0.020, 0.003],\n                               [0.001, 0.003, 0.030]]),\n            \"u\": np.array([0.8, 0.8, 0.8]),\n            \"R_target\": 0.09,\n            \"V_max\": 0.025,\n            \"lambda\": LAMBDA,\n            \"tau\": TAU\n        },\n        # Case B\n        {\n            \"n\": 3,\n            \"mu\": np.array([0.03, 0.05, 0.07]),\n            \"Sigma\": np.array([[0.008, 0.001, 0.0005],\n                               [0.001, 0.012, 0.001],\n                               [0.0005, 0.001, 0.015]]),\n            \"u\": np.array([0.8, 0.8, 0.8]),\n            \"R_target\": 0.07,\n            \"V_max\": 0.05,\n            \"lambda\": LAMBDA,\n            \"tau\": TAU\n        },\n        # Case C\n        {\n            \"n\": 4,\n            \"mu\": np.array([0.05, 0.08, 0.12, 0.04]),\n            \"Sigma\": np.array([[0.005, 0.001, 0.001, 0.0005],\n                               [0.001, 0.010, 0.002, 0.001],\n                               [0.001, 0.002, 0.020, 0.0015],\n                               [0.0005, 0.001, 0.0015, 0.004]]),\n            \"u\": np.array([0.6, 0.6, 0.5, 1.0]),\n            \"R_target\": 0.08,\n            \"V_max\": 0.012,\n            \"lambda\": LAMBDA,\n            \"tau\": TAU\n        }\n    ]\n\n    results = []\n    for case_params in test_cases:\n        violation = solve_one_case(case_params, RHO_SEQUENCE)\n        # Format to exactly 6 digits after the decimal point\n        results.append(f\"{violation:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\ndef get_constraint_values(w, params):\n    \"\"\"Calculates the values of all constraint functions.\"\"\"\n    mu, Sigma, u, R_target, V_max = params['mu'], params['Sigma'], params['u'], params['R_target'], params['V_max']\n    \n    g_lo = -w\n    g_up = w - u\n    g_ret = R_target - mu.dot(w)\n    g_var = w.dot(Sigma.dot(w)) - V_max\n    h_bud = np.sum(w) - 1.0\n    \n    return g_lo, g_up, g_ret, g_var, h_bud\n\ndef merit_function(w, rho, params):\n    \"\"\"Calculates the value of the merit function M_rho(w).\"\"\"\n    lam = params['lambda']\n    g_lo, g_up, g_ret, g_var, h_bud = get_constraint_values(w, params)\n    \n    p_lo = np.maximum(0, g_lo)\n    p_up = np.maximum(0, g_up)\n    p_ret = np.maximum(0, g_ret)\n    p_var = np.maximum(0, g_var)\n    \n    penalty_term = np.sum(p_lo**2) + np.sum(p_up**2) + p_ret**2 + p_var**2 + h_bud**2\n    regularization_term = lam * np.sum(w**2)\n    \n    return rho * penalty_term + regularization_term\n\ndef merit_gradient(w, rho, params):\n    \"\"\"Calculates the gradient of the merit function M_rho(w).\"\"\"\n    n, mu, Sigma, lam = params['n'], params['mu'], params['Sigma'], params['lambda']\n    g_lo, g_up, g_ret, g_var, h_bud = get_constraint_values(w, params)\n    \n    p_lo = np.maximum(0, g_lo)\n    p_up = np.maximum(0, g_up)\n    p_ret = np.maximum(0, g_ret)\n    p_var = np.maximum(0, g_var)\n    \n    # Gradient of penalty term for lo/up bounds\n    grad_bounds = p_up - p_lo # component-wise\n    \n    # Gradient of penalty term for return\n    grad_ret = p_ret * (-mu)\n    \n    # Gradient of penalty term for variance\n    grad_var = p_var * (2 * Sigma.dot(w))\n    \n    # Gradient of penalty term for budget\n    grad_bud = h_bud * np.ones(n)\n    \n    # Combine all gradient components\n    grad = 2 * rho * (grad_bounds + grad_ret + grad_var + grad_bud)\n    \n    # Add gradient of regularization term\n    grad += 2 * lam * w\n    \n    return grad\n\ndef calculate_violation(w, params):\n    \"\"\"Calculates the maximum constraint violation vio(w).\"\"\"\n    g_lo, g_up, g_ret, g_var, h_bud = get_constraint_values(w, params)\n    \n    vio_lo = np.max(np.maximum(0, g_lo))\n    vio_up = np.max(np.maximum(0, g_up))\n    vio_ret = np.maximum(0, g_ret)\n    vio_var = np.maximum(0, g_var)\n    vio_bud = np.abs(h_bud)\n    \n    return np.max([vio_lo, vio_up, vio_ret, vio_var, vio_bud])\n\ndef solve_one_case(params, rho_sequence):\n    \"\"\"Solves a single test case using the penalty method.\"\"\"\n    n = params['n']\n    tau = params['tau']\n    w0 = np.ones(n) / n\n    final_violation = -1.0\n    \n    for rho in rho_sequence:\n        res = minimize(\n            fun=merit_function,\n            x0=w0,\n            args=(rho, params),\n            method='BFGS',\n            jac=merit_gradient,\n            options={'gtol': 1e-9} \n        )\n        \n        w_opt = res.x\n        final_violation = calculate_violation(w_opt, params)\n        \n        if final_violation = tau:\n            break\n        \n        w0 = w_opt # Warm start for the next iteration\n        \n    return final_violation\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2374527"}, {"introduction": "最后的这项实践在一个统一的优化问题中综合了罚函数法和障碍函数法的概念。通过为学生的学习计划建模，你将使用对数障碍函数来强制执行严格的每日学习上限，同时使用二次罚函数来鼓励达到总学习目标。这个问题 ([@problem_id:2374575]) 展示了组合使用这些技术的灵活性和强大功能，可以精确地模拟同时包含“硬”边界和“软”目标的真实世界场景。", "problem": "考虑一个时间分配问题，其中一名学生选择每日学习时长，以平衡学习收益和填鸭式学习的成本。设决策变量为每日学习时长 $x_t$（对于 $t \\in \\{1,\\dots,T\\}$），每天 $x_t \\in (0,M)$。学生的每日学习收益被建模为一个凹增函数 $u_t(x_t) = b_t \\log(1 + x_t)$，其中 $b_t  0$ 代表第 $t$ 天的效率权重。每日的填鸭式学习会受到一个凸的“平方合页”惩罚，形式为 $\\rho \\max\\{0, x_t - h\\}^2$，其中 $h  0$ 是填鸭式学习阈值，$\\rho  0$ 是惩罚权重。\n\n为强制执行定义域 $x_t \\in (0,M)$（对每个 $t$），使用参数为 $\\mu  0$ 的对数障碍；为鼓励总学习目标 $\\sum_{t=1}^T x_t \\approx S$，使用权重为 $\\eta  0$ 的二次惩罚。定义无约束最小化目标\n$$\nf(x) \\;=\\; -\\sum_{t=1}^T b_t \\log(1 + x_t) \\;+\\; \\rho \\sum_{t=1}^T \\max\\{0, x_t - h\\}^2 \\;-\\; \\mu \\sum_{t=1}^T \\left[\\log x_t + \\log(M - x_t)\\right] \\;+\\; \\eta\\left(\\sum_{t=1}^T x_t - S\\right)^2,\n$$\n并求解\n$$\n\\min_{x \\in (0,M)^T} \\; f(x).\n$$\n\n您的任务是编写一个完整的、可运行的程序，对下面的每个测试用例，近似最小化关于 $x = (x_1,\\dots,x_T)$ 的函数 $f(x)$，并返回最终的每日学习时长向量。该程序必须实现一种带有线搜索的基于梯度的方法，通过严格保持在界限内来维持可行性 $x_t \\in (0,M)$，并且当梯度的无穷范数低于 $10^{-6}$ 或达到 $20000$ 次迭代上限时终止，以先到者为准。为保证数值稳定性，您可以假设一个内部边际，即强制 $x_t \\in [\\varepsilon, M - \\varepsilon]$，其中 $\\varepsilon$ 是一个小的正数，$\\varepsilon \\in (0,10^{-6}]$。\n\n对于每个测试用例，输出优化后的向量 $x^\\star$，四舍五入到 $4$ 位小数。最终输出必须是单行，包含一个列表的列表，每个内部列表对应一个测试用例，顺序与提供的一致。不应打印任何额外文本。\n\n测试套件（每个用例指定 $(T, b, S, M, h, \\mu, \\rho, \\eta)$）：\n- 用例 1：$T = 7$，$b = [1,1,1,1,1,1,1]$，$S = 21$，$M = 10$，$h = 4$，$\\mu = 10^{-3}$，$\\rho = 1.0$，$\\eta = 5.0$。\n- 用例 2：$T = 5$，$b = [1.0,1.5,0.8,1.2,0.7]$，$S = 25$，$M = 10$，$h = 5$，$\\mu = 10^{-3}$，$\\rho = 0.5$，$\\eta = 10.0$。\n- 用例 3：$T = 4$，$b = [1,1,1,1]$，$S = 35$，$M = 10$，$h = 6$，$\\mu = 10^{-6}$，$\\rho = 0.1$，$\\eta = 2.0$。\n- 用例 4：$T = 6$，$b = [0.9,1.4,0.6,1.1,1.3,0.7]$，$S = 30$，$M = 12$，$h = 4$，$\\mu = 10^{-3}$，$\\rho = 5.0$，$\\eta = 15.0$。\n\n要求的最终输出格式：\n- 您的程序应生成单行输出，其中包含一个列表的列表形式的结果，每个内部列表包含 $T$ 个优化后的每日学习时长，四舍五入到 $4$ 位小数，例如 $[[x_{1,1},\\dots,x_{1,T_1}],[x_{2,1},\\dots],\\dots]$，其中 $x_{i,j}$ 表示测试用例 $i$ 中的第 $j$ 天。不需要空格，但允许使用。", "solution": "所述问题是有效的。这是一个基于既定数学原理的良构优化问题。其目标是在凸域 $x \\in (0,M)^T$ 上最小化函数 $f(x)$。函数 $f(x)$ 是几项之和。我们来逐一分析。\n学习收益项 $-\\sum_{t=1}^T b_t \\log(1 + x_t)$ 是凸的，因为 $\\log(z)$ 是一个凹函数，这使得 $-\\log(z)$ 是凸的，并且凸函数的和仍然是凸的（$b_t  0$）。\n填鸭式学习惩罚项 $\\rho \\sum_{t=1}^T \\max\\{0, x_t - h\\}^2$ 是凸的。函数 $g(z) = z^2$ 对 $z \\ge 0$ 是凸且非递减的，而 $h(z) = \\max\\{0, z\\}$ 是凸的。因此，复合函数 $g(h(z))$ 是凸的。\n对数障碍项 $-\\mu \\sum_{t=1}^T [\\log x_t + \\log(M - x_t)]$ 是一个标准的、严格凸的障碍函数，用于强制执行定义域约束。\n总学习目标惩罚项 $\\eta(\\sum_{t=1}^T x_t - S)^2$ 是凸的，因为它是凸二次函数 $z^2$ 与一个仿射函数的复合。\n由于目标函数 $f(x)$ 是凸函数的和，并且对数障碍项确保了其严格凸性，因此 $f(x)$ 是一个严格凸函数。在凸集上对严格凸函数进行最小化会得到唯一解。因此，该问题在科学上是合理的且是良构的。\n\n为了解决这个无约束最小化问题，我们将实现一个带有回溯线搜索的梯度下降算法。该方法是合适的，因为目标函数 $f(x)$ 在其定义域 $(0,M)^T$ 上是连续可微的。\n\n梯度下降的核心原理是通过沿着负梯度方向（即目标函数的最速下降方向）迈出一步来迭代更新当前解 $x^{(k)}$。更新规则是：\n$$\nx^{(k+1)} = x^{(k)} + s_k p^{(k)}\n$$\n其中 $p^{(k)} = -\\nabla f(x^{(k)})$ 是搜索方向，$s_k  0$ 是步长。\n\n目标函数由下式给出：\n$$\nf(x) = -\\sum_{t=1}^T b_t \\log(1 + x_t) + \\rho \\sum_{t=1}^T \\max\\{0, x_t - h\\}^2 - \\mu \\sum_{t=1}^T \\left[\\log x_t + \\log(M - x_t)\\right] + \\eta\\left(\\sum_{t=1}^T x_t - S\\right)^2\n$$\n为了计算搜索方向，我们必须首先推导 $f(x)$ 的梯度 $\\nabla f(x)$。梯度的第 $t$ 个分量 $\\frac{\\partial f}{\\partial x_t}$ 是每一项偏导数的和：\n$$\n(\\nabla f(x))_t = \\frac{\\partial}{\\partial x_t}f(x) = -\\frac{b_t}{1 + x_t} + 2\\rho \\max\\{0, x_t - h\\} - \\mu \\left( \\frac{1}{x_t} - \\frac{1}{M - x_t} \\right) + 2\\eta \\left(\\sum_{j=1}^T x_j - S\\right)\n$$\n平方合页项 $\\max\\{0, x_t - h\\}^2$ 关于 $x_t$ 的导数是 $2 \\max\\{0, x_t - h\\}$，它对所有 $x_t$ 都是连续的。\n\n步长 $s_k$ 由回溯线搜索过程确定。这至关重要，原因有二：确保每一步目标函数值有足够的下降，以及维持可行性，即将 $x^{(k+1)}$ 保持在定义域 $(0,M)^T$ 内。线搜索从一个初始步长（例如 $s=1$）开始，并以因子 $\\beta \\in (0,1)$ 迭代地减小它，直到满足两个条件：\n1.  **可行性**：新点 $x_{new} = x^{(k)} + s p^{(k)}$ 必须严格位于定义域内。为保证数值稳定性，我们强制 $x_t \\in [\\varepsilon, M - \\varepsilon]$，其中 $\\varepsilon$ 是一个小的正常数。\n2.  **Armijo 条件**：该步长必须能使目标函数有足够的下降。这通过以下条件来验证：\n    $$\n    f(x^{(k)} + s p^{(k)}) \\le f(x^{(k)}) + \\alpha s (\\nabla f(x^{(k)}))^T p^{(k)}\n    $$\n    其中 $\\alpha \\in (0, 0.5)$ 是一个控制参数。由于 $p^{(k)} = -\\nabla f(x^{(k)})$，该条件简化为 $f(x_{new}) \\le f(x^{(k)}) - \\alpha s ||\\nabla f(x^{(k)})||_2^2$。\n\n算法流程如下：\n1.  将 $x^{(0)}$ 初始化为一个可行点，例如，对所有 $t=1,...,T$，$x_t^{(0)} = S/T$，并将其裁剪到可行范围 $[\\varepsilon, M-\\varepsilon]$ 内。设置迭代计数器 $k=0$。\n2.  对于 $k=0, 1, 2, \\dots$ 直到最大迭代次数：\n    a.  计算梯度 $\\nabla f(x^{(k)})$。\n    b.  检查收敛性：如果无穷范数 $||\\nabla f(x^{(k)})||_\\infty$ 低于容差 $\\tau$（例如 $10^{-6}$），则终止并返回 $x^{(k)}$。\n    c.  设置搜索方向 $p^{(k)} = -\\nabla f(x^{(k)})$。\n    d.  执行回溯线搜索以找到合适的步长 $s_k$。\n    e.  更新解：$x^{(k+1)} = x^{(k)} + s_k p^{(k)}$。\n3.  如果达到最大迭代次数，算法终止并返回最后计算的解。\n该过程保证收敛到严格凸目标函数的唯一极小值点。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases.\n    \"\"\"\n    \n    # --- Algorithm Parameters ---\n    MAX_ITER = 20000\n    TOL = 1e-6\n    # Epsilon for numerical stability at boundaries\n    EPS = 1e-7\n    # Backtracking line search parameters\n    ALPHA = 0.3\n    BETA = 0.8\n    # --------------------------\n\n    def objective_function(x, b, S, M, h, mu, rho, eta):\n        \"\"\"\n        Computes the value of the objective function f(x).\n        \"\"\"\n        # Barrier terms implicitly handle domain, but we can return inf for robustness\n        if np.any(x = 0) or np.any(x >= M):\n            return np.inf\n            \n        term1_benefit = -np.sum(b * np.log(1 + x))\n        term2_cramming = rho * np.sum(np.maximum(0, x - h)**2)\n        term3_barrier = -mu * np.sum(np.log(x) + np.log(M - x))\n        term4_target = eta * (np.sum(x) - S)**2\n        \n        return term1_benefit + term2_cramming + term3_barrier + term4_target\n\n    def gradient(x, b, S, M, h, mu, rho, eta):\n        \"\"\"\n        Computes the gradient of the objective function f(x).\n        \"\"\"\n        grad = np.zeros_like(x)\n        \n        grad_term1 = -b / (1 + x)\n        grad_term2 = 2 * rho * np.maximum(0, x - h)\n        grad_term3 = -mu * (1/x - 1/(M - x))\n        grad_term4 = 2 * eta * (np.sum(x) - S)\n        \n        grad = grad_term1 + grad_term2 + grad_term3 + grad_term4\n        return grad\n\n    def optimize_case(T, b, S, M, h, mu, rho, eta):\n        \"\"\"\n        Performs gradient descent with backtracking line search for a single case.\n        \"\"\"\n        # Initialize x to a feasible starting point\n        x = np.full(T, S / T)\n        x = np.clip(x, EPS, M - EPS)\n        \n        for k in range(MAX_ITER):\n            grad_x = gradient(x, b, S, M, h, mu, rho, eta)\n            \n            # Check for convergence using the infinity norm of the gradient\n            if np.linalg.norm(grad_x, ord=np.inf) = TOL:\n                break\n                \n            # Set search direction (steepest descent)\n            p = -grad_x\n            \n            # --- Backtracking Line Search ---\n            s = 1.0\n            f_x = objective_function(x, b, S, M, h, mu, rho, eta)\n            grad_dot_p = np.dot(grad_x, p)\n\n            while True:\n                x_new = x + s * p\n                \n                # 1. Feasibility Check (stay within stable interior domain)\n                if np.any(x_new = EPS) or np.any(x_new >= M - EPS):\n                    s *= BETA\n                    continue\n                \n                # 2. Armijo Condition (sufficient decrease)\n                f_x_new = objective_function(x_new, b, S, M, h, mu, rho, eta)\n                if f_x_new = f_x + ALPHA * s * grad_dot_p:\n                    break  # Step size is acceptable\n                \n                s *= BETA\n                # Failsafe to prevent excessive shrinking of step size\n                if s  1e-15:\n                    break\n            \n            if s  1e-15:\n                # If step size becomes too small, terminate to avoid stalling\n                break\n\n            # Update solution\n            x = x + s * p\n            \n        return x\n\n    # --- Test Cases ---\n    test_cases = [\n        # (T, b, S, M, h, mu, rho, eta)\n        (7, np.array([1.0, 1.0, 1.0, 1.0, 1.0, 1.0, 1.0]), 21.0, 10.0, 4.0, 1e-3, 1.0, 5.0),\n        (5, np.array([1.0, 1.5, 0.8, 1.2, 0.7]), 25.0, 10.0, 5.0, 1e-3, 0.5, 10.0),\n        (4, np.array([1.0, 1.0, 1.0, 1.0]), 35.0, 10.0, 6.0, 1e-6, 0.1, 2.0),\n        (6, np.array([0.9, 1.4, 0.6, 1.1, 1.3, 0.7]), 30.0, 12.0, 4.0, 1e-3, 5.0, 15.0),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        T, b, S, M, h, mu, rho, eta = case\n        x_star = optimize_case(T, b, S, M, h, mu, rho, eta)\n        # Round the final vector to 4 decimal places and convert to a list\n        rounded_result = list(np.round(x_star, 4))\n        all_results.append(rounded_result)\n\n    # Format the final output string as a list of lists.\n    # str() on a list produces the desired bracketed, comma-separated format.\n    # Ex: str([1.23, 4.56]) -> '[1.23, 4.56]'\n    output_str = f\"[{','.join(map(str, all_results))}]\"\n    print(output_str)\n\nsolve()\n```", "id": "2374575"}]}