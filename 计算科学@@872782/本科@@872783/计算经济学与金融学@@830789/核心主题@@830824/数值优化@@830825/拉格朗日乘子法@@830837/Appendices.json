{"hands_on_practices": [{"introduction": "理论学习需要通过实践来巩固。本节的练习将带你从经典的资源配置问题入手，逐步构建对拉格朗日乘子法的直观理解。第一个练习是一个具体的农业经济学问题，我们将通过求解一个受资源限制的收益最大化问题，来学习如何应用拉格朗日方法。此练习的重点在于计算拉格朗日乘子，并理解其作为约束的“影子价格”的经济含义 [@problem_id:2442060]。", "problem": "爱荷华州的一位农民计划在连续两年内分配玉米和大豆的种植。设 $x_1 \\in [0,1]$ 和 $x_2 \\in [0,1]$ 分别表示第1年和第2年种植玉米的面积占总种植面积的比例。剩余的 $1 - x_t$ 部分在第 $t \\in \\{1,2\\}$ 年种植大豆。\n\n对于每一年 $t$，整个农场的预期单位面积收入是玉米种植份额 $x_t$ 的函数：\n$$\nR_t(x_t) \\;=\\; x_t\\big(\\alpha_c - \\beta_c x_t\\big) \\;+\\; \\big(1 - x_t\\big)\\big(\\alpha_s - \\beta_s\\big(1 - x_t\\big)\\big),\n$$\n其中参数以美元/英亩为单位给出，分别为 $\\alpha_c = 800$，$\\beta_c = 200$，$\\alpha_s = 600$ 和 $\\beta_s = 100$。该农民的两年目标是最大化总预期单位面积收入 $R_1(x_1) + R_2(x_2)$，并受到一个轮作约束的限制，该约束要求两年内玉米的平均种植面积不超过总面积的 $60\\%$：\n$$\n\\frac{x_1 + x_2}{2} \\;\\le\\; 0.6,\n$$\n以及可行性条件 $0 \\le x_1 \\le 1$，$0 \\le x_2 \\le 1$。\n\n确定在最优分配下，与轮作约束相关的拉格朗日乘子（影子价值）。以美元/英亩为单位，用一个实数表示你的答案。最终答案中不要包含单位。", "solution": "所给问题是农业经济学领域的一个约束优化问题。该问题具有科学依据，提法明确，且是客观的。所有必要的数据和条件都已给出，没有矛盾之处。因此，我们可以进行形式化的求解。\n\n目标是最大化两年内的总预期收入 $Z(x_1, x_2) = R_1(x_1) + R_2(x_2)$，其中 $x_1$ 和 $x_2$ 分别是第1年和第2年分配给玉米种植的面积比例。任何一年 $t$ 的单位面积收入函数如下：\n$$\nR_t(x_t) = x_t(\\alpha_c - \\beta_c x_t) + (1 - x_t)(\\alpha_s - \\beta_s(1 - x_t))\n$$\n由于参数在两年内是恒定的，所以函数形式对两年来说是相同的。我们用 $R(x)$ 表示这个函数。我们可以展开并简化 $R(x)$：\n$$\nR(x) = \\alpha_c x - \\beta_c x^2 + \\alpha_s - \\alpha_s x - \\beta_s(1 - 2x + x^2)\n$$\n$$\nR(x) = -(\\beta_c + \\beta_s)x^2 + (\\alpha_c - \\alpha_s + 2\\beta_s)x + (\\alpha_s - \\beta_s)\n$$\n问题给出了参数值：$\\alpha_c = 800$，$\\beta_c = 200$，$\\alpha_s = 600$ 和 $\\beta_s = 100$。所有值的单位都是美元/英亩。将这些值代入 $R(x)$ 的表达式中：\n$$\n\\beta_c + \\beta_s = 200 + 100 = 300\n$$\n$$\n\\alpha_c - \\alpha_s + 2\\beta_s = 800 - 600 + 2(100) = 400\n$$\n$$\n\\alpha_s - \\beta_s = 600 - 100 = 500\n$$\n因此，收入函数简化为一个凹二次函数：\n$$\nR(x) = -300x^2 + 400x + 500\n$$\n二阶导数 $\\frac{d^2R}{dx^2} = -600$ 为负，证实了 $R(x)$ 的严格凹性。因此，总目标函数 $Z(x_1, x_2) = R(x_1) + R(x_2)$ 也是严格凹的。\n\n优化问题是：\n$$\n\\max_{x_1, x_2} Z(x_1, x_2) = (-300x_1^2 + 400x_1 + 500) + (-300x_2^2 + 400x_2 + 500)\n$$\n约束条件为：\n1. 轮作约束： $g(x_1, x_2) = \\frac{x_1 + x_2}{2} - 0.6 \\le 0$\n2. 可行性约束： $0 \\le x_1 \\le 1$ 和 $0 \\le x_2 \\le 1$\n\n首先，我们通过求 $R(x)$ 的最大值来确定无约束最优解。一阶条件是 $\\frac{dR}{dx} = 0$：\n$$\n\\frac{dR}{dx} = -600x + 400 = 0 \\implies x = \\frac{400}{600} = \\frac{2}{3}\n$$\n$Z(x_1, x_2)$ 的无约束最大值将在 $x_1 = x_2 = \\frac{2}{3}$ 处取得。我们来检查该点是否满足轮作约束：\n$$\n\\frac{x_1 + x_2}{2} = \\frac{\\frac{2}{3} + \\frac{2}{3}}{2} = \\frac{2}{3} \\approx 0.667\n$$\n由于 $\\frac{2}{3}  0.6$，无约束解违反了轮作约束。由于目标函数是凹的，约束集是凸的，最优解必须位于紧约束所定义的边界上。也就是说，在最优点，我们必须有 $\\frac{x_1 + x_2}{2} = 0.6$。\n\n为了求出与此约束相关的拉格朗日乘子（影子价值），我们构造拉格朗日函数 $\\mathcal{L}$。设 $\\lambda$ 是轮作约束的乘子。我们暂时忽略箱式约束，因为无约束最优解 $x_i = 2/3$ 在 $[0,1]$ 区间内，而有约束最优解将更接近可行集的中心。\n$$\n\\mathcal{L}(x_1, x_2, \\lambda) = Z(x_1, x_2) - \\lambda \\left(\\frac{x_1 + x_2}{2} - 0.6\\right)\n$$\n最优解 $(x_1^*, x_2^*)$ 的 Karush-Kuhn-Tucker (KKT) 条件是：\n1. 平稳性 (Stationarity):\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial x_1} = \\frac{dR(x_1^*)}{dx_1} - \\frac{\\lambda}{2} = -600x_1^* + 400 - \\frac{\\lambda}{2} = 0\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial x_2} = \\frac{dR(x_2^*)}{dx_2} - \\frac{\\lambda}{2} = -600x_2^* + 400 - \\frac{\\lambda}{2} = 0\n$$\n2. 原始可行性 (Primal Feasibility): $\\frac{x_1^* + x_2^*}{2} - 0.6 \\le 0$\n3. 对偶可行性 (Dual Feasibility): $\\lambda \\ge 0$\n4. 互补松弛性 (Complementary Slackness): $\\lambda \\left(\\frac{x_1^* + x_2^*}{2} - 0.6\\right) = 0$\n\n从平稳性条件，我们得到 $-600x_1^* + 400 = -600x_2^* + 400$，这意味着 $x_1^* = x_2^*$。由于目标函数和约束的对称性，这个结果是预料之中的。\n\n如前所述，该约束必须是紧约束，所以 $\\frac{x_1^* + x_2^*}{2} = 0.6$。将 $x_1^* = x_2^*$ 代入此方程可得：\n$$\n\\frac{x_1^* + x_1^*}{2} = x_1^* = 0.6\n$$\n因此，最优分配是 $x_1^* = x_2^* = 0.6$。该解满足可行性条件 $0 \\le 0.6 \\le 1$。\n\n现在我们使用其中一个平稳性条件来求解拉格朗日乘子 $\\lambda$：\n$$\n-600x_1^* + 400 - \\frac{\\lambda}{2} = 0\n$$\n代入 $x_1^* = 0.6$：\n$$\n-600(0.6) + 400 - \\frac{\\lambda}{2} = 0\n$$\n$$\n-360 + 400 - \\frac{\\lambda}{2} = 0\n$$\n$$\n40 - \\frac{\\lambda}{2} = 0\n$$\n$$\n\\frac{\\lambda}{2} = 40 \\implies \\lambda = 80\n$$\n拉格朗日乘子的值为 $\\lambda = 80$。该值为非负，满足对偶可行性条件。此乘子表示，当平均种植面积约束边际放宽时，最大总收入的增加率，单位为美元/英亩。", "answer": "$$\\boxed{80}$$", "id": "2442060"}, {"introduction": "在最优化问题中，并非所有约束在最优点都是紧的（即有效的）。这个练习旨在通过一个巧妙的设定来加深你对这一概念的理解。我们将探讨当约束在最优点恰好不产生限制时的情况，并通过卡罗需-库恩-塔克（KKT）条件来证明，其对应的拉格朗日乘子为何必须为零 [@problem_id:2442053]。这进一步强化了乘子作为“放松约束的边际价值”的经济解释。", "problem": "一家竞争性企业生产单一产品。设产量为 $q \\ge 0$，市场价格为 $p0$，总成本函数为 $C(q)=\\frac{1}{2} c q^{2}$，其中 $c0$。企业选择 $q$ 以最大化利润 $\\pi(q)=p q - C(q)$，同时受资源（产能）约束 $q \\le \\bar{Q}$ 的限制。假设可用资源水平恰好等于无约束条件下的利润最大化产量：$\\bar{Q}=\\frac{p}{c}$。在有约束的利润最大化点，与不等式约束 $q \\le \\bar{Q}$ 相关联的拉格朗日乘子 $\\lambda$ 的值是多少？请用一个精确的数字表示你的答案。无需四舍五入。", "solution": "企业的问题是最大化标量目标函数 $\\pi(q)=p q - \\frac{1}{2} c q^{2}$，受标量不等式约束 $q \\le \\bar{Q}$ 的限制，其中 $p0$，$c0$，且 $\\bar{Q}=\\frac{p}{c}$。首先，从基本原理出发，确定无约束条件下的最优解。函数 $\\pi(q)$ 是可微的且是严格凹的，因为其关于 $q$ 的二阶导数为 $\\frac{\\partial^{2} \\pi}{\\partial q^{2}}=-c0$。无约束最大化的一阶条件是\n$$\n\\frac{\\partial \\pi}{\\partial q}=p - c q = 0,\n$$\n这表明唯一的无约束最大化产量为\n$$\nq^{u}=\\frac{p}{c}.\n$$\n根据假设，资源限制为 $\\bar{Q}=\\frac{p}{c}$，因此无约束最大化产量恰好满足约束条件：$q^{u}=\\bar{Q}$。\n\n为了确定与不等式约束相关的拉格朗日乘子，我们使用不等式约束的标准符号约定来构建有约束问题的拉格朗日函数。设约束函数为 $g(q)=q-\\bar{Q} \\le 0$，$\\lambda \\ge 0$ 为其关联的拉格朗日乘子。拉格朗日函数是\n$$\n\\mathcal{L}(q,\\lambda) = p q - \\frac{1}{2} c q^{2} - \\lambda \\big( q - \\bar{Q} \\big).\n$$\nKarush–Kuhn–Tucker 条件（在此由于凹性，它们是一阶充要条件）是：\n- 平稳性：\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial q}= p - c q - \\lambda = 0.\n$$\n- 互补松弛性：\n$$\n\\lambda \\big(q - \\bar{Q}\\big)=0.\n$$\n- 原始可行性：$q \\le \\bar{Q}$。\n- 对偶可行性：$\\lambda \\ge 0$。\n\n我们已经确定最优产量 $q^{\\star}$ 等于无约束最大化产量，并且满足 $q^{\\star}=\\bar{Q}=\\frac{p}{c}$。将 $q^{\\star}=\\frac{p}{c}$ 代入平稳性条件可得\n$$\np - c\\left(\\frac{p}{c}\\right) - \\lambda = 0 \\quad \\Longrightarrow \\quad 0 - \\lambda = 0 \\quad \\Longrightarrow \\quad \\lambda = 0.\n$$\n互补松弛性也得到满足，因为 $q^{\\star}-\\bar{Q}=0$ 意味着 $\\lambda \\big(q^{\\star}-\\bar{Q}\\big)=\\lambda \\cdot 0 = 0$。目标函数的严格凹性保证了这些条件刻画了唯一的全局最大化解。因此，在有约束最优解处的拉格朗日乘子的值为 $0$。", "answer": "$$\\boxed{0}$$", "id": "2442053"}, {"introduction": "前面的练习展示了如何通过解析方法求解问题，但在现实世界中，许多复杂的经济和金融问题需要借助数值算法。这个高级练习将理论与计算实践联系起来，展示了如何将拉格朗日函数本身作为构建迭代算法（即原始-对偶方法）的基础。通过为一个资产定价问题实现求解器，你将亲身体验现代计算金融学如何运用拉格朗日框架解决实际问题 [@problem_id:2442029]。", "problem": "考虑一个具有 $S$ 个状态和 $K$ 种资产的静态、有限状态、离散时间的资产定价环境。令 $A \\in \\mathbb{R}^{S \\times K}$ 为支付矩阵，其 $(s,k)$ 元素 $A_{s,k}$ 是资产 k 在状态 s 的支付。令 $c \\in \\mathbb{R}^{K}$ 为这 $K$ 种资产的观测价格向量。一个无套利定价核可以由一个状态概率向量 $p \\in \\mathbb{R}^{S}$ 表示，该向量满足逐元素 $p \\ge 0$ 且 $\\mathbf{1}^\\top p = 1$，其中 $\\mathbf{1}$ 表示 $\\mathbb{R}^{S}$ 中的全一向量。在无套利条件下，资产价格应满足 $A^\\top p = c$。当 $c$ 含有噪声或市场不完备时，等式 $A^\\top p = c$ 可能不严格成立，一种标准的稳健校准方法是选择 $p$ 在概率单纯形约束下，在最小二乘意义上最佳拟合 $c$。\n\n您的任务是为以下凸规划问题，从第一性原理出发，推导并实现一个简单的原始-对偶梯度法，以寻找其拉格朗日函数的鞍点\n$$\n\\min_{p \\in \\mathbb{R}^{S}} \\;\\; \\frac{1}{2}\\,\\lVert A^\\top p - c \\rVert_2^2 \\quad \\text{约束条件为} \\quad \\mathbf{1}^\\top p = 1,\\;\\; p \\ge 0.\n$$\n从约束凸优化的核心定义（二次目标的凸性、线性等式和不等式约束以及 Karush-Kuhn-Tucker (KKT) 条件）开始，为等式约束构造一个标量乘子，为不等式约束构造一个非负乘子向量，从而构建拉格朗日函数。然后，通过对原始变量和对偶变量求梯度，设计一个一阶迭代方法，该方法在原始变量上进行下降，在对偶变量上进行上升，并包含一个强制不等式乘子非负性的显式投影步骤。您必须从这些原理出发对每一步进行论证，不得援引任何现成的快捷公式。\n\n实现要求：\n- 使用恒定步长以确保数值稳定性，步长基于光滑目标函数梯度的 Lipschitz 界。您必须从 $A A^\\top$ 的谱性质角度解释您选择步长的理由。\n- 使用均匀分布 $p^{(0)} = \\left(\\frac{1}{S},\\dots,\\frac{1}{S}\\right)$ 进行初始化，不等式乘子和等式乘子均初始化为零，并运行固定次数的迭代，该次数应足以在所有提供的测试中确保收敛。\n- 迭代终止后，对 $p$ 执行一次最终的可行性投影，将其投影到概率单纯形上，以报告一个有效的定价核。此后处理步骤必须与原始-对偶迭代明确分开，并且必须进行论证。\n\n数值细节：\n- 本问题不涉及角度。\n- 不涉及物理单位。\n- 所有最终概率向量必须报告为四舍五入到六位小数的十进制数。\n\n测试套件：\n对于每个测试，$S = 3$。支付矩阵 $A$（行由状态索引，列由资产索引）和价格向量 $c$ 如下：\n- 测试 1（良定，内部解）：\n  - $A = \\begin{bmatrix} 1.0  0.5 \\\\ 2.0  1.5 \\\\ 0.5  2.0 \\end{bmatrix}$, $c = \\begin{bmatrix} 1.35 \\\\ 1.45 \\end{bmatrix}$。存在一个严格为正的 $p$ 使得可行精确拟合。\n- 测试 2（边界解，有一个零概率状态）：\n  - $A = \\begin{bmatrix} 1.0  2.0 \\\\ 2.0  1.0 \\\\ 3.0  0.0 \\end{bmatrix}$, $c = \\begin{bmatrix} 2.4 \\\\ 0.6 \\end{bmatrix}$。存在一个可行精确拟合，其解中 $p$ 的一个分量为零。\n- 测试 3（超定最小二乘拟合，三种资产）：\n  - $A = \\begin{bmatrix} 1.0  0.5  1.5 \\\\ 0.0  1.0  0.2 \\\\ 2.0  1.0  0.7 \\end{bmatrix}$, $c = \\begin{bmatrix} 1.0 \\\\ 0.77 \\\\ 0.79 \\end{bmatrix}$。程序必须找到在单纯形约束下使定价平方误差最小化的 $p$。\n\n程序输出规范：\n- 对每个测试，返回计算出的最优概率向量 $p$，四舍五入到六位小数。\n- 将所有测试的结果按测试 1、2、3 的顺序汇总到单行中，该行包含一个列表的列表。\n- 确切的输出格式必须是单行：\n  - 一个带逗号的 Python 风格的列表的列表，例如：$[\\,[p_{1,1},p_{1,2},p_{1,3}],\\,[p_{2,1},p_{2,2},p_{2,3}],\\,[p_{3,1},p_{3,2},p_{3,3}]\\,]$\n  - 每个 $p_{i,j}$ 必须打印小数点后六位数字。\n\n您的程序必须是一个完整、可运行的脚本，执行基于推导的算法，并仅以指定格式打印最后一行。不需要用户输入。确保所有常数和数组与上面指定的值相匹配，以保证结果是确定性的。", "solution": "对所述问题进行验证。\n\n**步骤 1：提取已知条件**\n- 优化问题：$\\min_{p \\in \\mathbb{R}^{S}} \\;\\; \\frac{1}{2}\\,\\lVert A^\\top p - c \\rVert_2^2$。\n- 约束条件：$\\mathbf{1}^\\top p = 1$ 和 $p \\ge 0$。\n- 变量与数据：\n    - $S$：状态数量。\n    - $K$：资产数量。\n    - $A \\in \\mathbb{R}^{S \\times K}$：支付矩阵。\n    - $c \\in \\mathbb{R}^{K}$：资产价格向量。\n    - $p \\in \\mathbb{R}^{S}$：状态概率向量（定价核）。\n- 方法：从拉格朗日函数和 Karush-Kuhn-Tucker (KKT) 条件推导的原始-对偶梯度法。\n- 算法规范：\n    - 初始化 $p^{(0)} = (\\frac{1}{S}, \\dots, \\frac{1}{S})$，不等式乘子 $\\lambda^{(0)} = 0$，以及等式乘子 $\\mu^{(0)} = 0$。\n    - 使用基于目标函数梯度 Lipschitz 常数的恒定步长。\n    - 运行固定次数的迭代。\n    - 将得到的 $p$ 做最终投影到概率单纯形上。\n- 测试套件：为 $S=3$ 提供了三对 $(A, c)$。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据**：该问题是在离散状态金融模型中校准随机折现因子（或定价核）的标准公式。使用最小二乘目标是处理含噪声价格或市场不完备性的一种稳健方法。通过拉格朗日函数和原始-对偶方法的优化途径是现代凸优化的基石。该问题在科学上是合理的。\n- **良定性**：目标函数 $f(p) = \\frac{1}{2}\\,\\lVert A^\\top p - c \\rVert_2^2$ 是一个二次函数。其 Hessian 矩阵 $\\nabla^2 f(p) = AA^\\top$ 是一个 Gram 矩阵，因此是半正定的，这使得 $f(p)$ 是一个凸函数。约束是线性的，定义了概率单纯形，它是一个凸、闭、有界（紧）集。该问题是一个凸规划，具体来说是一个二次规划 (QP)。由于一个非空紧集（单纯形）上的连续函数 ($f(p)$) 必然会达到其最小值，因此最小值的存在性得到保证。\n- **客观性**：所有术语都具有数学上的精确定义。数据以数值形式提供。没有主观性。\n\n**步骤 3：结论与行动**\n该问题是有效的，因为它具有科学依据、良定、客观，并包含获得唯一、可验证解所需的所有信息。我们可以着手求解。\n\n**原始-对偶梯度法的推导**\n\n优化问题是一个凸规划：\n$$\n\\min_{p \\in \\mathbb{R}^{S}} \\;\\; f(p) = \\frac{1}{2}\\,\\lVert A^\\top p - c \\rVert_2^2 \\quad \\text{约束条件为} \\quad h(p) = \\mathbf{1}^\\top p - 1 = 0, \\;\\; g_s(p) = -p_s \\le 0 \\text{ for } s=1,\\dots,S.\n$$\n函数 $f(p)$ 是凸的。等式和不等式约束是仿射的，因此可行域（概率单纯形）是一个凸集。强对偶性成立。\n\n我们通过将一个拉格朗日乘子 $\\mu \\in \\mathbb{R}$ 与等式约束相关联，以及一个拉格朗日乘子向量 $\\lambda \\in \\mathbb{R}^S$ 与不等式约束相关联来构造拉格朗日函数 $\\mathcal{L}(p, \\lambda, \\mu)$，其中 $\\lambda \\ge 0$ 是逐分量成立的。\n$$\n\\mathcal{L}(p, \\lambda, \\mu) = f(p) + \\mu h(p) + \\lambda^\\top g(p) = \\frac{1}{2}\\,\\lVert A^\\top p - c \\rVert_2^2 + \\mu(\\mathbf{1}^\\top p - 1) - \\lambda^\\top p.\n$$\n原问题的解对应于拉格朗日函数的一个鞍点，该鞍点通过求解 $\\sup_{\\lambda \\ge 0, \\mu} \\inf_p \\mathcal{L}(p, \\lambda, \\mu)$ 得到。原始-对偶梯度法通过在原始变量 $p$ 上执行梯度下降，在对偶变量 $\\lambda$ 和 $\\mu$ 上执行梯度上升来找到这个鞍点。\n\n首先，我们计算拉格朗日函数的梯度：\n- 关于原始变量 $p$ 的梯度：\n  目标函数是 $f(p) = \\frac{1}{2}(p^\\top A A^\\top p - 2c^\\top A^\\top p + c^\\top c)$。\n  $$\n  \\nabla_p \\mathcal{L}(p, \\lambda, \\mu) = \\nabla_p f(p) + \\mu\\nabla_p(\\mathbf{1}^\\top p) - \\nabla_p(\\lambda^\\top p) = A(A^\\top p - c) + \\mu\\mathbf{1} - \\lambda.\n  $$\n- 关于对偶变量 $\\mu$ 的梯度：\n  $$\n  \\nabla_\\mu \\mathcal{L}(p, \\lambda, \\mu) = \\mathbf{1}^\\top p - 1.\n  $$\n- 关于对偶变量 $\\lambda$ 的梯度：\n  $$\n  \\nabla_\\lambda \\mathcal{L}(p, \\lambda, \\mu) = -p.\n  $$\n\n原始-对偶（Arrow-Hurwicz）方法包含以下使用步长 $\\alpha  0$ 的迭代更新：\n1.  **原始变量更新（下降）：** $p^{(t+1)} = p^{(t)} - \\alpha \\nabla_p \\mathcal{L}(p^{(t)}, \\lambda^{(t)}, \\mu^{(t)})$。\n    $$\n    p^{(t+1)} = p^{(t)} - \\alpha \\left( A(A^\\top p^{(t)} - c) + \\mu^{(t)}\\mathbf{1} - \\lambda^{(t)} \\right).\n    $$\n2.  **对偶变量 $\\mu$ 更新（上升）：** $\\mu^{(t+1)} = \\mu^{(t)} + \\alpha \\nabla_\\mu \\mathcal{L}(p^{(t)}, \\lambda^{(t)}, \\mu^{(t)})$。\n    $$\n    \\mu^{(t+1)} = \\mu^{(t)} + \\alpha \\left( \\mathbf{1}^\\top p^{(t)} - 1 \\right).\n    $$\n3.  **对偶变量 $\\lambda$ 更新（投影上升）：** 该更新必须满足非负约束 $\\lambda \\ge 0$。这通过将梯度上升步骤投影到非负象限上来实现。操作 $[v]_+$ 表示 $v$ 和 $0$ 的逐元素最大值。\n    $$\n    \\lambda^{(t+1)} = \\left[ \\lambda^{(t)} + \\alpha \\nabla_\\lambda \\mathcal{L}(p^{(t)}, \\lambda^{(t)}, \\mu^{(t)}) \\right]_+ = \\left[ \\lambda^{(t)} - \\alpha p^{(t)} \\right]_+.\n    $$\n这个更新方案旨在收敛到一个鞍点，该鞍点满足最优性的 Karush-Kuhn-Tucker (KKT) 条件。如果某个分量 $p_s^{(t)}$ 变为负数，项 $-\\alpha p_s^{(t)}$ 就会变为正数，从而增加相应的乘子 $\\lambda_s^{(t+1)}$。这反过来在下一次原始变量更新中提供了一个正的恢复力 $\\alpha \\lambda_s^{(t+1)}$，将 $p_s^{(t+1)}$ 推向非负值。\n\n**步长选择**\n该方法的稳定性和收敛性关键取决于步长 $\\alpha$。目标函数的梯度 $\\nabla f(p) = A(A^\\top p - c)$ 的 Hessian 矩阵为 $\\nabla^2 f(p) = AA^\\top$。$\\nabla f(p)$ 的 Lipschitz 常数是该 Hessian 矩阵的最大特征值，即 $L = \\lambda_{\\max}(AA^\\top) = \\lVert AA^\\top \\rVert_2$，这也等于 $A$ 的谱范数的平方 $\\lVert A \\rVert_2^2$。对于耦合的原始-对偶系统，必须选择与此常数相关的稳定步长。一个能确保稳定性的保守且标准的选择是 $\\alpha = 1/L$。\n\n**到单纯形上的最终投影**\n原始-对偶迭代在每一步中并不强制执行对 $p$ 的约束。尽管算法的动态过程旨在将 $p$ 引导至可行域，但最终的迭代结果 $p^{(N_{\\text{iter}})}$ 可能存在微小的违规（例如，负分量或总和不为 1）。因此，需要一个后处理步骤，将最终迭代结果投影到概率单纯形 $\\Delta^S = \\{ p \\in \\mathbb{R}^S \\mid \\mathbf{1}^\\top p = 1, p \\ge 0 \\}$ 上。这个投影找到了 $\\Delta^S$ 中与算法输出 $p_{raw}$ 在欧几里得距离上最近的点 $p^*$。它是以下二次规划（QP）的解：\n$$\n\\min_{p^*} \\frac{1}{2} \\lVert p^* - p_{raw} \\rVert_2^2 \\quad \\text{约束条件为} \\quad \\mathbf{1}^\\top p^* = 1, \\;\\; p^* \\ge 0.\n$$\n该问题的解由 $p_s^* = \\max(0, p_{raw, s} - \\theta)$ 给出，其中标量 $\\theta$ 的选择要使得 $\\sum_s \\max(0, p_{raw, s} - \\theta) = 1$。存在一个高效的算法来找到这个 $\\theta$，该算法涉及对 $p_{raw}$ 进行排序并找到解中正分量的正确数量。\n\n**完整算法总结**\n1.  **初始化**：设置 $p^{(0)} = \\frac{1}{S}\\mathbf{1}$，$\\lambda^{(0)} = \\mathbf{0}$，$\\mu^{(0)} = 0$。选择足够多的迭代次数 $N_{iter}$。\n2.  **步长计算**：计算 $L = \\lVert AA^\\top \\rVert_2$ 并设置步长 $\\alpha = 1/L$。\n3.  **迭代**：对于 $t = 0, \\dots, N_{iter}-1$：\n    - $p^{(t+1)} = p^{(t)} - \\alpha \\left( A(A^\\top p^{(t)} - c) + \\mu^{(t)}\\mathbf{1} - \\lambda^{(t)} \\right)$\n    - $\\mu^{(t+1)} = \\mu^{(t)} + \\alpha \\left( \\mathbf{1}^\\top p^{(t)} - 1 \\right)$\n    - $\\lambda^{(t+1)} = \\left[ \\lambda^{(t)} - \\alpha p^{(t)} \\right]_+$\n4.  **投影**：将最终迭代结果 $p^{(N_{iter})}$ 投影到概率单纯形上以获得解 $p^*$。\n该过程按要求实现。", "answer": "```python\nimport numpy as np\n\ndef project_to_simplex(p_raw: np.ndarray) - np.ndarray:\n    \"\"\"Projects a vector onto the probability simplex.\n\n    This solves the problem:\n    min_{p} 0.5 * ||p - p_raw||_2^2\n    s.t. p = 0, sum(p) = 1\n\n    The algorithm stems from the KKT conditions of this problem.\n    \"\"\"\n    if np.all(p_raw = 0) and np.isclose(np.sum(p_raw), 1):\n        return p_raw # Already on the simplex\n\n    S = len(p_raw)\n    p_sorted = np.sort(p_raw)[::-1]\n    p_cumsum = np.cumsum(p_sorted)\n    \n    # Find rho: the largest index j such that p_sorted[j-1]  (p_cumsum[j-1] - 1)/j\n    # We use 0-based indexing, so j becomes i+1.\n    rho = 0\n    for i in range(S):\n        if p_sorted[i]  (p_cumsum[i] - 1) / (i + 1):\n            rho = i + 1\n    \n    theta = (p_cumsum[rho - 1] - 1) / rho\n    p_proj = np.maximum(0, p_raw - theta)\n    \n    return p_proj\n\ndef solve_primal_dual(A: np.ndarray, c: np.ndarray, S: int, iterations: int) - np.ndarray:\n    \"\"\"\n    Solves the pricing kernel calibration problem using a primal-dual gradient method.\n\n    min_{p} 0.5 * ||A.T @ p - c||_2^2\n    s.t. sum(p) = 1, p = 0\n    \"\"\"\n    # 1. Initialization\n    p = np.ones(S) / S\n    lambda_ = np.zeros(S)\n    mu = 0.0\n    \n    # 2. Step Size Calculation\n    # The gradient of the smooth part of the objective is grad(f(p)) = A(A^T p - c).\n    # The Hessian is AA^T. The Lipschitz constant of the gradient is the maximum\n    # eigenvalue of the Hessian (its spectral norm).\n    Q = A @ A.T\n    L = np.linalg.norm(Q, ord=2)\n    # A robust step size choice is 1/L.\n    # Add a small epsilon to avoid division by zero if A is a zero matrix.\n    alpha = 1.0 / (L + 1e-9)\n    \n    one_vec = np.ones(S)\n\n    # 3. Iteration\n    for _ in range(iterations):\n        # Calculate gradients at the current point (p, lambda_, mu)\n        grad_p = A @ (A.T @ p - c) + mu * one_vec - lambda_\n        grad_mu = np.sum(p) - 1.0\n        grad_lambda = -p\n        \n        # Update primal and dual variables\n        p = p - alpha * grad_p\n        mu = mu + alpha * grad_mu\n        lambda_ = np.maximum(0.0, lambda_ + alpha * grad_lambda)\n\n    # 4. Final Projection\n    p_star = project_to_simplex(p)\n    \n    return p_star\n\ndef solve():\n    \"\"\"\n    Main function to run test cases and print results.\n    \"\"\"\n    S = 3\n    num_iterations = 100000\n\n    test_cases = [\n        {\n            \"A\": np.array([[1.0, 0.5], [2.0, 1.5], [0.5, 2.0]]),\n            \"c\": np.array([1.35, 1.45])\n        },\n        {\n            \"A\": np.array([[1.0, 2.0], [2.0, 1.0], [3.0, 0.0]]),\n            \"c\": np.array([2.4, 0.6])\n        },\n        {\n            \"A\": np.array([[1.0, 0.5, 1.5], [0.0, 1.0, 0.2], [2.0, 1.0, 0.7]]),\n            \"c\": np.array([1.0, 0.77, 0.79])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        A = case[\"A\"]\n        c = case[\"c\"]\n        p_optimal = solve_primal_dual(A, c, S, num_iterations)\n        \n        # Format the result to six decimal places\n        formatted_p = [f\"{x:.6f}\" for x in p_optimal]\n        results.append(f\"[{','.join(formatted_p)}]\")\n\n    # Print the final output in the specified format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2442029"}]}