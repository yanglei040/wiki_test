{"hands_on_practices": [{"introduction": "我们将从最简单的移动平均模型 MA(1) 开始我们的动手实践之旅。本练习通过体育运动中一个直观的概念——“手感火热”——来探索 MA 模型的基本属性：其内在的记忆性，这种记忆性表现为自相关。通过模拟数据并检验“手感火热”效应，您将亲身体会 MA(1) 过程如何在其连续观测值之间产生依赖性，并学习如何从统计上检测这种依赖 [@problem_id:2412526]。", "problem": "给定一个单变量离散时间序列，表示一名篮球运动员每场比赛得分与其长期平均得分的偏差。设时间指数 $t$ 处的偏差表示为 $y_t$。假设 $y_t$ 服从一阶移动平均 (MA) 模型，记作移动平均 (MA)($1$)，定义为\n$$\ny_t = \\varepsilon_t + \\theta \\varepsilon_{t-1},\n$$\n其中 $\\{\\varepsilon_t\\}$ 是一个独立同分布序列，满足 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$，并且 $\\theta \\in \\mathbb{R}$ 是一个常数。\n\n“手感火热”效应定义为 $y_t$ 中存在正的一阶序列相关性，这对应于中心化序列的正一阶自相关。对于下方的每个测试用例，你必须在单侧显著性水平 $\\alpha$ 下，判断数据是否为“手感火热”效应提供了证据。\n\n对于每个测试用例，你必须：\n- 使用指定的参数 $(N,\\theta,\\sigma^2)$ 和随机数种子，模拟一次实现 $\\{y_t\\}_{t=1}^N$。\n- 将 $y_t$ 视为与长期平均值的偏差，并使用中心化序列（减去样本均值）来评估一阶序列相关性。\n- 在显著性水平 $\\alpha$ 下，判断是否存在“手感火热”效应的证据。\n\n你必须使用以下测试套件。对于每个案例，在模拟之前，使用给定的整数随机种子初始化你的随机数生成器：\n- 案例 1：$N=400$，$\\theta=0.8$，$\\sigma^2=9$，$\\alpha=0.05$，种子 $=1729$。\n- 案例 2：$N=400$，$\\theta=0.0$，$\\sigma^2=9$，$\\alpha=0.05$，种子 $=31415$。\n- 案例 3：$N=400$，$\\theta=-0.8$，$\\sigma^2=9$，$\\alpha=0.05$，种子 $=271828$。\n- 案例 4：$N=30$，$\\theta=0.6$，$\\sigma^2=9$，$\\alpha=0.05$，种子 $=123456$。\n- 案例 5：$N=2$，$\\theta=0.7$，$\\sigma^2=9$，$\\alpha=0.05$，种子 $=7$。\n\n你的程序应生成一行输出，其中包含一个布尔值列表，按上述顺序列出每个案例的测试决策。如果数据在水平 $\\alpha$ 下为“手感火热”效应提供了证据，则布尔值为 $True$，否则为 $False$。输出必须是单行，且格式必须为“[result1,result2,result3,result4,result5]”。", "solution": "对问题陈述进行验证。\n\n**步骤 1：提取已知信息**\n- 一个单变量离散时间序列 $\\{y_t\\}$ 服从一阶移动平均模型 MA($1$)：$y_t = \\varepsilon_t + \\theta \\varepsilon_{t-1}$。\n- $\\{\\varepsilon_t\\}$ 是一个独立同分布 (i.i.d.) 序列，满足 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$。\n- “手感火热”效应定义为 $y_t$ 中存在正的一阶序列相关性，对应于正的滞后一阶自相关。\n- 任务是在单侧显著性水平 $\\alpha$ 下检验此效应。\n- 检验过程包括：模拟一个序列 $\\{y_t\\}_{t=1}^N$，通过减去样本均值将其中心化，然后进行假设检验。\n- 测试用例：\n    - 案例 1：$N=400$，$\\theta=0.8$，$\\sigma^2=9$，$\\alpha=0.05$，种子$=1729$。\n    - 案例 2：$N=400$，$\\theta=0.0$，$\\sigma^2=9$，$\\alpha=0.05$，种子$=31415$。\n    - 案例 3：$N=400$，$\\theta=-0.8$，$\\sigma^2=9$，$\\alpha=0.05$，种子$=271828$。\n    - 案例 4：$N=30$，$\\theta=0.6$，$\\sigma^2=9$，$\\alpha=0.05$，种子$=123456$。\n    - 案例 5：$N=2$，$\\theta=0.7$，$\\sigma^2=9$，$\\alpha=0.05$，种子$=7$。\n\n**步骤 2：使用提取的已知信息进行验证**\n根据科学依据、适定性和客观性标准对问题进行评估。\n\n- **科学依据**：该问题基于时间序列分析中的标准 MA($1$) 模型，这是计量经济学和统计学的核心课题。自相关、假设检验和显著性水平等概念是基本的统计学原理。“手感火热”概念提供了一个主题背景，但被严格定义为一个可检验的统计属性。该问题在科学上是合理的。\n- **适定性**：该问题为可复现的时间序列模拟提供了所有必要的参数（$N, \\theta, \\sigma^2$）和随机种子。它清晰地指明了任务：在给定的显著性水平 $\\alpha$ 下，对正自相关进行单侧假设检验。检验过程明确。对于每个测试用例，使用标准的自相关检验统计方法，都存在唯一的解。\n- **客观性**：该问题使用精确、客观的数学语言进行陈述。它避免了主观或模棱两可的术语。\n\n该问题未违反任何无效条件。案例 5 中 $N=2$ 是一个极端但有效的统计情景。对于大小为 $N=2$ 的样本，样本自相关在代数上是固定的，这是该统计量的一个可证实的属性，而非问题表述中的缺陷。因此，该问题被认定为有效。\n\n**步骤 3：结论与行动**\n问题有效。将提供完整解答。\n\n**理论框架与方法**\n\n给定的时间序列 $\\{y_t\\}$ 由一阶移动平均过程生成，记作 MA($1$)：\n$$\ny_t = \\varepsilon_t + \\theta \\varepsilon_{t-1}\n$$\n其中 $\\varepsilon_t$ 是一个白噪声过程，满足 $\\varepsilon_t \\sim \\mathcal{N}(0, \\sigma^2)$。此过程的理论一阶自相关系数 $\\rho_1$ 由下式给出：\n$$\n\\rho_1 = \\frac{\\text{Cov}(y_t, y_{t-1})}{\\text{Var}(y_t)} = \\frac{\\theta}{1+\\theta^2}\n$$\n“手感火热”效应定义为正的一阶序列相关性，这转化为对 $\\rho_1 > 0$ 的统计检验。假设检验的公式如下：\n- 原假设 $H_0: \\rho_1 = 0$（无一阶自相关）。\n- 备择假设 $H_A: \\rho_1 > 0$（存在正的一阶自相关）。\n\n此检验在模拟数据 $\\{y_t\\}_{t=1}^N$ 上进行。检验统计量是样本滞后-1 自相关系数 $\\hat{\\rho}_1$，由中心化序列 $\\tilde{y}_t = y_t - \\bar{y}$ 计算得出，其中 $\\bar{y}$ 是样本均值。$\\hat{\\rho}_1$ 的计算公式为：\n$$\n\\hat{\\rho}_1 = \\frac{\\sum_{t=2}^{N} (y_t - \\bar{y})(y_{t-1} - \\bar{y})}{\\sum_{t=1}^{N} (y_t - \\bar{y})^2}\n$$\n在原假设 $H_0$ 下，对于足够大的样本量 $N$，$\\hat{\\rho}_1$ 的分布可以近似为正态分布：\n$$\n\\hat{\\rho}_1 \\approx \\mathcal{N}\\left(0, \\frac{1}{N}\\right)\n$$\n由此，我们构建一个标准化检验统计量 $Z = \\hat{\\rho}_1 \\sqrt{N}$，在 $H_0$ 下，它服从标准正态分布 $Z \\sim \\mathcal{N}(0, 1)$。\n\n对于显著性水平为 $\\alpha$ 的单侧检验，如果观测到的检验统计量超过临界值 $z_{1-\\alpha}$（即标准正态分布的 $(1-\\alpha)$-分位数），我们则拒绝原假设 $H_0$。决策规则是：\n$$\n\\text{如果 } \\hat{\\rho}_1 \\sqrt{N} > z_{1-\\alpha} \\text{ 则拒绝 } H_0\n$$\n这种大样本近似适用于 $N$ 较大的情况（例如，$N=400$）。对于较小的 $N$，其准确性会降低。对于 $N=30$ 的情况，它仍被认为是可接受的。对于 $N=2$ 的情况，该近似效果很差。然而，对于 $N=2$，分析性检验表明，对于任意两个不同的点 $y_1, y_2$，样本自相关固定为 $\\hat{\\rho}_1 = -1/2$。负的样本自相关永远不能为正的总体自相关提供证据。因此，对于 $N=2$，我们总是无法拒绝 $H_0: \\rho_1 = 0$ 以支持 $H_A: \\rho_1 > 0$。\n\n每个测试用例的步骤如下：\n1. 设置随机种子以保证可复现性。\n2. 从 $\\mathcal{N}(0, \\sigma^2)$ 生成一个包含 $N+1$ 个独立同分布随机变量的序列 $\\{\\varepsilon_t\\}_{t=0}^N$。\n3. 构建长度为 $N$ 的 MA($1$) 序列 $\\{y_t\\}_{t=1}^N$。\n4. 计算样本均值 $\\bar{y}$ 并将序列中心化。\n5. 计算样本自相关 $\\hat{\\rho}_1$。如果分母为零（对于连续数据，其发生概率为零），则说明没有变异，因此没有相关的证据。\n6. 计算检验统计量 $Z = \\hat{\\rho}_1 \\sqrt{N}$。\n7. 从标准正态分布中确定临界值 $z_{1-\\alpha}$。\n8. 如果 $Z > z_{1-\\alpha}$，则存在“手感火热”效应的证据 (True)；否则，不存在 (False)。", "answer": "```python\n# language: Python\n# version: 3.12\n# libraries:\n#   name: numpy\n#   version: 1.23.5\n#   name: scipy\n#   version: 1.11.4\n\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the Moving Average (MA)(1) model.\n    \"\"\"\n\n    def analyze_hot_hand(N, theta, sigma_sq, alpha, seed):\n        \"\"\"\n        Simulates an MA(1) series and tests for positive first-order autocorrelation.\n\n        Args:\n            N (int): The length of the time series.\n            theta (float): The MA(1) parameter.\n            sigma_sq (float): The variance of the white noise term.\n            alpha (float): The significance level for the one-sided test.\n            seed (int): The random seed for reproducibility.\n\n        Returns:\n            bool: True if there is evidence of a hot hand, False otherwise.\n        \"\"\"\n        # 1. Set the random seed\n        np.random.seed(seed)\n\n        sigma = np.sqrt(sigma_sq)\n\n        # 2. Generate N+1 white noise terms to produce a series of length N\n        # We need eps_0, ..., eps_N to compute y_1, ..., y_N\n        eps = np.random.normal(loc=0.0, scale=sigma, size=N + 1)\n\n        # 3. Construct the MA(1) series y_t = eps_t + theta * eps_{t-1}\n        # The resulting series 'y' has length N, corresponding to t=1,...,N\n        y = eps[1:] + theta * eps[:-1]\n\n        # 4. Center the series by subtracting the sample mean\n        y_mean = np.mean(y)\n        y_centered = y - y_mean\n        \n        # 5. Compute the sample lag-1 autocorrelation coefficient, rho_hat_1\n        # Denominator of rho_hat_1: sum of squared deviations\n        denominator = np.sum(y_centered**2)\n        \n        # If variance is zero, all y_t are identical.\n        # Autocorrelation is undefined, and there is no evidence of dependence.\n        if denominator == 0.0:\n            return False\n\n        # Numerator of rho_hat_1: sum of cross-products of lagged centered values\n        # y_centered[1:] corresponds to (y_2-y_bar), ..., (y_N-y_bar)\n        # y_centered[:-1] corresponds to (y_1-y_bar), ..., (y_{N-1}-y_bar)\n        numerator = np.sum(y_centered[1:] * y_centered[:-1])\n        \n        rho_hat_1 = numerator / denominator\n\n        # For N = 1, autocorrelation is not well-defined.\n        if N = 1:\n            return False\n\n        # 6. Compute the test statistic Z = rho_hat_1 * sqrt(N)\n        # This is based on the large-sample approximation.\n        test_statistic = rho_hat_1 * np.sqrt(N)\n        \n        # 7. Determine the critical value for a one-sided test\n        # This is the (1-alpha) quantile of the standard normal distribution.\n        critical_value = norm.ppf(1 - alpha)\n        \n        # 8. Perform the test: reject H0 if test_statistic > critical_value\n        return test_statistic > critical_value\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (N, theta, sigma^2, alpha, seed)\n        (400, 0.8, 9.0, 0.05, 1729),\n        (400, 0.0, 9.0, 0.05, 31415),\n        (400, -0.8, 9.0, 0.05, 271828),\n        (30, 0.6, 9.0, 0.05, 123456),\n        (2, 0.7, 9.0, 0.05, 7),\n    ]\n\n    results = []\n    for case in test_cases:\n        N, theta, sigma_sq, alpha, seed = case\n        result = analyze_hot_hand(N, theta, sigma_sq, alpha, seed)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2412526"}, {"introduction": "在理解了 MA 模型结构的基础上，我们现在转向一个核心应用：预测和异常检测。这个练习模拟了一个信用卡欺诈检测的真实场景，其中一个 MA(3) 模型被用来描述正常的消费行为。您的任务是实现一个算法，识别那些对于模型而言“出乎意料”的交易——这些交易会表现为巨大的预测误差，从而展示 MA 模型在真实世界监控系统中的实际应用价值 [@problem_id:2412539]。", "problem": "给定一个形式化模型，该模型将单个用户的正常信用卡消费行为描述为一个三阶移动平均（MA(3)）时间序列。MA(3)模型由弱平稳性和序列不相关新息下的线性时间序列的核心概率结构定义：一个标量过程 $\\{y_t\\}$ 满足 $y_t = \\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3}$，其中 $\\mu$ 是一个常数均值，$\\{\\varepsilon_t\\}$ 是一个零均值、序列不相关的创新序列，其方差为 $\\sigma^2$，而 $\\theta_1, \\theta_2, \\theta_3$ 是实数系数。在此模型和迭代期望定律下，单步向前预测 $E[y_t \\mid \\mathcal{F}_{t-1}]$ 在所有 $\\mathcal{F}_{t-1}$-可测的预测器中，能最小化均方预测误差。其中 $\\mathcal{F}_{t-1}$ 是由 $\\{y_s: s \\le t-1\\}$ 生成的sigma代数。如果在时间 $t$ 的一笔交易导致相对于新息方差而言较大的单步向前预测误差，则该交易被标记为潜在欺诈。您必须设计一个算法，对于每个时间 $t$，该算法能根据MA(3)结构从 $\\mathcal{F}_{t-1}$ 中生成单步向前预测，计算由此产生的预测误差，用已知的标准差 $\\sigma$ 对其进行标准化，并且如果标准化误差的绝对值超过以标准差表示的预设阈值 $\\tau$，则标记时间 $t$。在预测中，任何不可用的过去新息的条件期望（例如，当 $t \\le 3$ 时）必须被视为零，因为它是零均值且独立于 $\\mathcal{F}_{t-1}$。您的算法应仅使用截至前一时刻的可用信息，来顺序计算单步向前预测和由此产生的预测误差。\n\n程序要求：\n1) 输入是硬编码的：您必须为一个下面定义的固定测试套件实现您的算法。不允许用户输入。不允许访问外部文件或网络。\n2) 对于每个测试用例，给定 $(\\mu, \\boldsymbol{\\theta}, \\sigma^2, \\tau, \\mathbf{y})$，其中 $\\boldsymbol{\\theta} = (\\theta_1,\\theta_2,\\theta_3)$ 且 $\\mathbf{y} = [y_1,\\dots,y_T]$。将所有量视为实数。新息的标准差为 $\\sigma = \\sqrt{\\sigma^2}$。对于每个时间索引 $t \\in \\{1,\\dots,T\\}$，仅使用 $\\{y_s: s \\le t-1\\}$ 来计算MA(3)结构所蕴含的单步向前预测 $\\widehat{y}_{t \\mid t-1}$，定义预测误差 $e_t = y_t - \\widehat{y}_{t \\mid t-1}$，计算标准化误差 $z_t = e_t / \\sigma$，并在 $|z_t| > \\tau$ 时标记时间 $t$。对于每个测试用例，以升序整数列表的形式输出被标记的索引。\n3) 您必须使用以下测试套件：\n- 用例 A（具有单个大峰值的常规行为）：$\\mu = 100$, $\\boldsymbol{\\theta} = (0.5,-0.2,0.1)$, $\\sigma^2 = 25$, $\\tau = 3$, $\\mathbf{y} = [98,102,99,140,118,95,106,101]$。\n- 用例 B（短序列边界情况，早期时间点）：$\\mu = 50$, $\\boldsymbol{\\theta} = (0.7,0.1,-0.4)$, $\\sigma^2 = 4$, $\\tau = 2$, $\\mathbf{y} = [50,56,46]$。\n- 用例 C（交替符号参数，一个临界值和一个峰值）：$\\mu = 200$, $\\boldsymbol{\\theta} = (-0.4,0.3,-0.2)$, $\\sigma^2 = 16$, $\\tau = 2.5$, $\\mathbf{y} = [205,194,195,180,210,193]$。\n- 用例 D（白噪声基线，预计无标记）：$\\mu = 0$, $\\boldsymbol{\\theta} = (0,0,0)$, $\\sigma^2 = 9$, $\\tau = 3$, $\\mathbf{y} = [1,-2,4,-5,6,-3]$。\n- 用例 E（连续的大偏差）：$\\mu = 75$, $\\boldsymbol{\\theta} = (0.9,0.4,0.2)$, $\\sigma^2 = 100$, $\\tau = 2.5$, $\\mathbf{y} = [70,120,65,50]$。\n4) 最终输出格式：您的程序应生成单行输出，其中包含结果，格式为一个由逗号分隔的整数列表的列表，用方括号括起来，且不含任何空格。例如，一个有效的输出形式是 `[[1,3],[2],[]]`。对于给定的测试套件，输出必须是 `[L_A,L_B,L_C,L_D,L_E]` 形式的单行，其中每个 $L_\\cdot$ 是相应案例的已标记索引列表（按升序排列）。\n\n您的任务是：实现一个完整、可运行的程序，该程序遵循MA(3)模型定义所蕴含的算法，为整个测试套件计算标记，并以要求的格式精确打印单行聚合输出。所有数值答案都是无量纲的（没有物理单位）。不涉及角度。不使用百分比。每个案例结果唯一可接受的数据类型是整数列表（可能为空）。", "solution": "问题陈述已经过验证，并被认定为有效。这是一个在计算时间序列分析领域中，基于成熟的移动平均（MA）模型理论和最优预测的、提法恰当且有科学依据的问题。所有参数和条件都已完全指定，从而可以得到一个唯一且可验证的解。\n\n该问题要求为一个被建模为三阶移动平均过程（记为MA(3)）的时间序列 $\\{y_t\\}$ 实现一个异常检测算法。该模型由以下方程定义：\n$$y_t = \\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3}$$\n此处，$\\mu$ 是过程的常数均值，$\\{\\varepsilon_t\\}$ 是一个序列不相关的随机变量（新息或冲击）序列，其均值为 $E[\\varepsilon_t] = 0$，常数方差为 $Var(\\varepsilon_t) = \\sigma^2$。系数 $\\theta_1, \\theta_2, \\theta_3$ 是模型的实数值参数。\n\n任务的核心是为每个时间 $t \\in \\{1, 2, \\dots, T\\}$ 计算单步向前预测 $\\widehat{y}_{t \\mid t-1}$。该预测是在给定截至时间 $t-1$ 的可用信息（由sigma代数 $\\mathcal{F}_{t-1} = \\sigma(\\{y_s: s \\le t-1\\})$ 表示）下，$y_t$ 的条件期望。条件期望是最小化均方预测误差的预测器。\n该预测计算如下：\n$$\\widehat{y}_{t \\mid t-1} = E[y_t \\mid \\mathcal{F}_{t-1}] = E[\\mu + \\varepsilon_t + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3} \\mid \\mathcal{F}_{t-1}]$$\n根据期望的线性和条件期望的性质，上式变为：\n$$\\widehat{y}_{t \\mid t-1} = E[\\mu \\mid \\mathcal{F}_{t-1}] + E[\\varepsilon_t \\mid \\mathcal{F}_{t-1}] + \\theta_1 E[\\varepsilon_{t-1} \\mid \\mathcal{F}_{t-1}] + \\theta_2 E[\\varepsilon_{t-2} \\mid \\mathcal{F}_{t-1}] + \\theta_3 E[\\varepsilon_{t-3} \\mid \\mathcal{F}_{t-1}]$$\n我们来逐项评估：\n1. 因为 $\\mu$ 是一个常数，所以 $E[\\mu \\mid \\mathcal{F}_{t-1}] = \\mu$。\n2. 根据定义，新息 $\\varepsilon_t$ 是无法从过去的信息中预测的。因此，其在给定过去信息下的条件期望等于其无条件均值，$E[\\varepsilon_t \\mid \\mathcal{F}_{t-1}] = E[\\varepsilon_t] = 0$。\n3. 对于过去的创新 $\\varepsilon_{t-k}$（其中 $k > 0$），我们必须确定在时间 $t-1$ 它们是否已知。模型方程可以被反转，以用当前观测值和过去的创新来表示当前创新：\n$$\\varepsilon_t = y_t - \\mu - \\theta_1 \\varepsilon_{t-1} - \\theta_2 \\varepsilon_{t-2} - \\theta_3 \\varepsilon_{t-3}$$\n该关系允许递归地计算新息序列。给定观测值 $\\{y_s: s \\le t-1\\}$，就可以确定 $\\{\\varepsilon_s: s \\le t-1\\}$ 的值。因此，对于 $k \\in \\{1, 2, 3\\}$，新息 $\\varepsilon_{t-k}$ 相对于 $\\mathcal{F}_{t-1}$ 是可测的，其条件期望就是它自身的值：$E[\\varepsilon_{t-k} \\mid \\mathcal{F}_{t-1}] = \\varepsilon_{t-k}$。\n\n然而，这仅在 $\\varepsilon_{t-k}$ 的值可以被计算时才成立。对于早期的时步（例如，$t=1$），所需的过去新息 $\\varepsilon_0, \\varepsilon_{-1}, \\varepsilon_{-2}$ 无法由从 $y_1$ 开始的观测序列确定。问题陈述正确地指明，任何不可用的过去新息的条件期望必须被视为其无条件均值，即 $0$。这是初始化预测函数的标准处理方法。\n\n综合这些事实，预测方程为：\n$$\\widehat{y}_{t \\mid t-1} = \\mu + \\theta_1 \\varepsilon_{t-1}^* + \\theta_2 \\varepsilon_{t-2}^* + \\theta_3 \\varepsilon_{t-3}^*$$\n其中，如果 $\\varepsilon_{t-k}$ 的值已由先前的观测计算得出，则 $\\varepsilon_{t-k}^* = \\varepsilon_{t-k}$，否则 $\\varepsilon_{t-k}^* = 0$。\n\n单步向前预测误差为 $e_t = y_t - \\widehat{y}_{t \\mid t-1}$。代入 $\\widehat{y}_{t \\mid t-1}$ 的表达式并使用 $y_t$ 的模型定义：\n$$e_t = (\\mu + \\varepsilon_t + \\sum_{k=1}^{3} \\theta_k \\varepsilon_{t-k}) - (\\mu + \\sum_{k=1}^{3} \\theta_k \\varepsilon_{t-k}) = \\varepsilon_t$$\n这证实了预测误差恰好就是时间 $t$ 的新息。这是一个基本结果。因此，算法必须迭代地计算新息序列。\n\n算法流程如下：\n1. 初始化新息历史。对于时间 $t \\le 0$，新息是未知的，因此我们使用其期望值 $0$。\n2. 对于从 $1$ 到 $T$ 的每个时步 $t$：\n    a. 确定预测所需的过去新息 $\\varepsilon_{t-1}, \\varepsilon_{t-2}, \\varepsilon_{t-3}$ 的值。如果历史记录太短，则对缺失值使用 $0$。\n    b. 计算单步向前预测：$\\widehat{y}_{t \\mid t-1} = \\mu + \\theta_1 \\varepsilon_{t-1} + \\theta_2 \\varepsilon_{t-2} + \\theta_3 \\varepsilon_{t-3}$。\n    c. 使用当前观测值 $y_t$ 计算当前新息：$\\varepsilon_t = y_t - \\widehat{y}_{t \\mid t-1}$。\n    d. 存储新计算出的 $\\varepsilon_t$，以供后续预测使用。\n    e. 计算标准化误差 $z_t = \\varepsilon_t / \\sigma$，其中 $\\sigma = \\sqrt{\\sigma^2}$。\n    f. 如果 $|z_t| > \\tau$，其中 $\\tau$ 是给定的阈值，则将索引 $t$（使用基于1的索引）记录为已标记。\n3. 将所有测试用例的已标记索引列表整理成指定的输出格式。\n这个顺序过程正确地实现了MA(3)模型下的预测和异常检测逻辑。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the MA(3) fraud detection problem for a fixed test suite.\n    \"\"\"\n    test_cases = [\n        # Case A: General behavior with a single large spike\n        {\n            'mu': 100.0, 'theta': (0.5, -0.2, 0.1), 'sigma2': 25.0, 'tau': 3.0,\n            'y': [98.0, 102.0, 99.0, 140.0, 118.0, 95.0, 106.0, 101.0]\n        },\n        # Case B: Short series edge case, early times\n        {\n            'mu': 50.0, 'theta': (0.7, 0.1, -0.4), 'sigma2': 4.0, 'tau': 2.0,\n            'y': [50.0, 56.0, 46.0]\n        },\n        # Case C: Alternating-sign parameters, borderline and one spike\n        {\n            'mu': 200.0, 'theta': (-0.4, 0.3, -0.2), 'sigma2': 16.0, 'tau': 2.5,\n            'y': [205.0, 194.0, 195.0, 180.0, 210.0, 193.0]\n        },\n        # Case D: White noise baseline, no flags expected\n        {\n            'mu': 0.0, 'theta': (0.0, 0.0, 0.0), 'sigma2': 9.0, 'tau': 3.0,\n            'y': [1.0, -2.0, 4.0, -5.0, 6.0, -3.0]\n        },\n        # Case E: Back-to-back large deviations\n        {\n            'mu': 75.0, 'theta': (0.9, 0.4, 0.2), 'sigma2': 100.0, 'tau': 2.5,\n            'y': [70.0, 120.0, 65.0, 50.0]\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        mu = case['mu']\n        theta1, theta2, theta3 = case['theta']\n        sigma = np.sqrt(case['sigma2'])\n        tau = case['tau']\n        y_series = case['y']\n\n        eps_history = []\n        flagged_indices = []\n\n        for t_idx, y_t in enumerate(y_series):\n            # Time t is 1-based\n            t = t_idx + 1\n\n            # Get past innovations, using 0 for unavailable history\n            eps_tm1 = eps_history[t_idx - 1] if t_idx - 1 >= 0 else 0.0\n            eps_tm2 = eps_history[t_idx - 2] if t_idx - 2 >= 0 else 0.0\n            eps_tm3 = eps_history[t_idx - 3] if t_idx - 3 >= 0 else 0.0\n\n            # Compute the one-step-ahead forecast\n            y_hat = mu + theta1 * eps_tm1 + theta2 * eps_tm2 + theta3 * eps_tm3\n\n            # Compute the current innovation (forecast error)\n            eps_t = y_t - y_hat\n            eps_history.append(eps_t)\n\n            # Standardize the error\n            z_t = eps_t / sigma\n\n            # Check if it exceeds the threshold\n            if abs(z_t) > tau:\n                flagged_indices.append(t)\n        \n        all_results.append(flagged_indices)\n\n    # Format the final output string exactly as required (no spaces)\n    result_strings = [f\"[{','.join(map(str, r))}]\" for r in all_results]\n    final_output = f\"[{','.join(result_strings)}]\"\n    \n    print(final_output)\n\nsolve()\n```", "id": "2412539"}, {"introduction": "我们的最后一个练习将模型设定、参数估计和诊断检验整合到一个完整的工作流程中。您需要从零开始，在不依赖现有软件包的情况下，为金融收益率数据拟合一个更高阶的 MA(5) 模型。其中关键的最后一步，是检验模型残差中是否存在任何剩余的可预测性。这是判断模型是否成功捕捉了数据动态的核心诊断步骤，它强化了这样一个原则：一个好的模型应该只留下白噪声 [@problem_id:2412549]。", "problem": "您需要为移动平均 (MA) 模型在计算经济学和金融学背景下实现一个端到端的估计与诊断检验流程。该流程必须完全自包含，并产生单行可验证的输出。您的程序必须仅从第一性原理和核心定义出发，实现以下内容。\n\n考虑一个单变量时间序列 $\\{x_t\\}_{t=1}^T$，代表股票指数的日对数收益率。在有效市场中，日收益率的传统均值模型使用一个 $q$ 阶移动平均过程 (MA($q$)) 来描述均值动态：对于 $q \\in \\mathbb{N}$，MA($q$) 模型为\n$$\nx_t \\;=\\; \\mu \\;+\\; \\epsilon_t \\;+\\; \\theta_1 \\epsilon_{t-1} \\;+\\; \\cdots \\;+\\; \\theta_q \\epsilon_{t-q},\n$$\n其中 $\\mu \\in \\mathbb{R}$ 是无条件均值，$\\{\\epsilon_t\\}$ 是一个独立同分布的白噪声序列，满足 $E[\\epsilon_t] = 0$ 和 $\\operatorname{Var}(\\epsilon_t) = \\sigma^2 \\in \\mathbb{R}_{+}$，并且 $\\boldsymbol{\\theta}=(\\theta_1,\\ldots,\\theta_q) \\in \\mathbb{R}^q$。在有效市场中，单步向前预测误差（即估计出的新息）应是不可预测的，这意味着 $\\hat{\\epsilon}_t$ 对 $\\hat{\\epsilon}_{t+1}$ 没有线性预测能力。\n\n您的任务是：\n- 对每个提供的数据集，使用条件平方和 (CSS) 拟合一个 MA($5$) 模型。CSS 的定义是通过模型恒等式递归计算残差，并对参数最小化残差平方和。具体来说，在初始条件 $\\hat{\\epsilon}_t = 0$ (当 $t \\le 0$) 下，定义\n$$\n\\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta}) \\;=\\; x_t \\;-\\; \\mu \\;-\\; \\sum_{j=1}^{5} \\theta_j \\hat{\\epsilon}_{t-j}(\\mu, \\boldsymbol{\\theta}),\n$$\n并在 $(\\mu, \\boldsymbol{\\theta}) \\in \\mathbb{R}^{6}$ 上最小化 $\\sum_{t=1}^{T} \\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta})^2$。\n- 在估计参数并从拟合的 MA($5$) 模型中构建出估计的单步向前新息序列 $\\{\\hat{\\epsilon}_t\\}$ 后，使用普通最小二乘 (OLS) 回归将 $\\hat{\\epsilon}_{t+1}$ 对一个常数项和 $\\hat{\\epsilon}_t$ 进行回归，以检验原假设“$\\hat{\\epsilon}_t$ 对 $\\hat{\\epsilon}_{t+1}$ 没有线性预测能力”：\n$$\n\\hat{\\epsilon}_{t+1} \\;=\\; \\alpha \\;+\\; \\beta \\hat{\\epsilon}_t \\;+\\; u_{t+1}.\n$$\n在原假设 $H_0: \\beta = 0$ 下，基于常规的 OLS t 统计量（其自由度为 $T-2$）计算 $\\beta$ 的双边 p 值。使用显著性水平 $\\alpha_{\\text{test}} = 0.05$。\n- 为每个数据集报告一个布尔决策，遵循以下约定：如果在 $\\alpha_{\\text{test}}$ 水平上未能拒绝 $H_0$（解释为“残差是不可预测的”），则输出 $\\text{True}$；如果拒绝 $H_0$（解释为“残差对 $\\hat{\\epsilon}_{t+1}$ 具有预测能力”），则输出 $\\text{False}$。\n\n您必须遵守的基本原则和约束：\n- 仅使用白噪声的定义、MA($q$) 模型的定义以及通过模型恒等式构建 CSS 残差作为估计主干。不要使用预构建的时间序列估计黑箱。\n- OLS 回归及其 t 检验必须遵循标准线性回归原理，其中 t 统计量从估计的斜率系数及其标准误计算得出，双边 p 值也相应计算。\n- 本问题中没有物理单位。不出现角度单位。不应打印百分比。\n\n测试套件：\n模拟四个数据集，模拟标准普尔 $500$ 指数的日收益率，其日波动率在 $1\\%$ 的量级上是符合实际的。对于每种情况，模拟一个新息序列 $\\{w_t\\}$，其中 $w_t \\sim \\mathcal{N}(0,\\sigma^2)$ 且 $\\sigma = 0.01$，并为了一般性，将过程构建为自回归移动平均 (ARMA) 模型：\n$$\nx_t - \\mu \\;=\\; \\phi (x_{t-1} - \\mu) \\;+\\; w_t \\;+\\; \\sum_{j=1}^{5} \\theta_j w_{t-j},\n$$\n初始条件为 $x_0 = \\mu$ 和 $w_t = 0$ (当 $t \\le 0$)。这包含了 MA($5$) 作为 $\\phi = 0$ 的特例。对每个数据集使用以下参数：\n\n- 情况 1 (基准 MA($5$), “有效”均值模型):\n  - 种子 $= 202311$，长度 $T = 900$，$\\mu = 0$，$\\phi = 0$，$\\boldsymbol{\\theta} = (0.4, -0.3, 0.2, -0.1, 0.05)$，$\\sigma = 0.01$。\n- 情况 2 (ARMA($1,5$) 带有温和自回归，若仅拟合 MA($5$) 则模型设定不当):\n  - 种子 $= 202312$，长度 $T = 900$，$\\mu = 0$，$\\phi = 0.3$，$\\boldsymbol{\\theta} = (0.4, -0.3, 0.2, -0.1, 0.05)$，$\\sigma = 0.01$。\n- 情况 3 (白噪声均值动态, MA($0$)):\n  - 种子 $= 202313$，长度 $T = 600$，$\\mu = 0$，$\\phi = 0$，$\\boldsymbol{\\theta} = (0, 0, 0, 0, 0)$，$\\sigma = 0.01$。\n- 情况 4 (纯自回归 AR($1$) 带有中度持续性，若仅拟合 MA($5$) 则模型设定不当):\n  - 种子 $= 202314$，长度 $T = 250$，$\\mu = 0$，$\\phi = 0.6$，$\\boldsymbol{\\theta} = (0, 0, 0, 0, 0)$，$\\sigma = 0.01$。\n\n您的程序必须：\n- 使用给定的种子和参数，精确地模拟每个数据集。\n- 对每个数据集通过 CSS 拟合一个 MA($5$) 模型，以获得 $\\{\\hat{\\epsilon}_t\\}$。\n- 在 $\\hat{\\epsilon}_{t+1}$ 对常数项和 $\\hat{\\epsilon}_t$ 的回归中，使用显著性水平为 $\\alpha_{\\text{test}} = 0.05$ 的双边检验，检验 $H_0: \\beta = 0$，并按所述形成决策。\n- 生成单行输出，其中包含一个 Python 风格的布尔值列表，按情况 1,2,3,4 的顺序排列，例如 $[\\,\\text{True},\\text{False},\\text{True},\\text{False}\\,]$。\n\n您的程序必须是一个完整、可运行的脚本，并且不应需要任何用户输入或外部文件。最终输出格式必须是且仅是一行，即一个用方括号括起来的、以逗号分隔的布尔值列表。", "solution": "问题陈述已经过严格评估，被认为是有效的。它具有科学依据，定义明确且客观。它为时间序列计量经济学中的一个标准练习提供了完整且一致的指导：移动平均 (MA) 模型的估计及其残差的诊断检验。该过程要求从第一性原理实现，这是对基础理解的严格考验。注意到的唯一微小不一致之处——为 t 检验指定的自由度是 $T-2$ 而非对长度为 $T-1$ 的时间序列进行简单回归时规范的 $T-3$——被解释为一个直接且明确无误的指令，而不是一个使问题无效的缺陷。我们按照规定进行求解。\n\n解决方案分为三个主要阶段：\n1. 根据指定的自回归移动平均 (ARMA) 过程模拟时间序列数据。\n2. 对每个数据集使用条件平方和 (CSS) 方法估计一个 5 阶移动平均模型，即 MA($5$)。\n3. 使用基于普通最小二乘 (OLS) 回归的检验，对估计模型的残差进行一阶序列自相关的诊断检验。\n\n**1. 时间序列模拟**\n\n问题要求从一个通用的 ARMA($1,5$) 过程生成四个数据集。时间序列 $\\{x_t\\}$ 的模型由下式给出：\n$$\nx_t - \\mu \\;=\\; \\phi (x_{t-1} - \\mu) \\;+\\; w_t \\;+\\; \\sum_{j=1}^{5} \\theta_j w_{t-j}\n$$\n其中 $\\mu$ 是均值，$\\phi$ 是自回归系数，$\\boldsymbol{\\theta} = (\\theta_1, \\ldots, \\theta_5)$ 是移动平均系数，而 $\\{w_t\\}$ 是一个高斯白噪声过程，满足 $w_t \\sim \\mathcal{N}(0, \\sigma^2)$。模拟从初始条件 $x_0 = \\mu$ 和 $w_t = 0$（当 $t \\le 0$）开始。数据 $\\{x_t\\}_{t=1}^T$ 是为四组指定的参数集递归生成的。这种设置允许检验 MA($5$) 估计过程在模型设定正确（情况1和3）和设定不当（情况2和4）下的性能。\n\n**2. 通过条件平方和 (CSS) 进行 MA(5) 估计**\n\n对于每个模拟的时间序列 $\\{x_t\\}_{t=1}^T$，我们拟合一个 MA($5$) 模型：\n$$\nx_t \\;=\\; \\mu \\;+\\; \\epsilon_t \\;+\\; \\sum_{j=1}^{5} \\theta_j \\epsilon_{t-j}\n$$\n需要估计的参数是均值 $\\mu$ 和 MA 系数 $\\boldsymbol{\\theta} = (\\theta_1, \\ldots, \\theta_5)$。估计通过最小化条件平方和 (CSS) 来执行。这涉及递归计算模型的残差 $\\{\\hat{\\epsilon}_t\\}$ 并最小化它们的平方和。\n\n残差通过重新排列模型方程来定义：\n$$\n\\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta}) \\;=\\; x_t \\;-\\; \\mu \\;-\\; \\sum_{j=1}^{5} \\theta_j \\hat{\\epsilon}_{t-j}(\\mu, \\boldsymbol{\\theta})\n$$\n为了启动递归，我们施加初始条件 $\\hat{\\epsilon}_t = 0$（对于所有 $t \\le 0$）。要最小化的目标函数是残差平方和：\n$$\nS(\\mu, \\boldsymbol{\\theta}) = \\sum_{t=1}^{T} \\hat{\\epsilon}_t(\\mu, \\boldsymbol{\\theta})^2\n$$\n这是一个关于 6 个参数 $(\\mu, \\theta_1, \\ldots, \\theta_5)$ 的非线性优化问题。我们采用一个数值拟牛顿优化算法（具体是 `scipy.optimize` 中可用的 L-BFGS-B）来找到最小化 $S(\\mu, \\boldsymbol{\\theta})$ 的参数估计值 $(\\hat{\\mu}, \\hat{\\boldsymbol{\\theta}})$。一旦找到这些估计值，就计算出最终的估计新息序列，即残差 $\\{\\hat{\\epsilon}_t\\}_{t=1}^T$。\n\n**3. 残差自相关的诊断检验**\n\n一个设定正确并被准确估计的时间序列模型应该留下无法从其自身历史预测的残差；也就是说，它们应该近似于一个白噪声过程。为了检验这一点，我们考察在时间 $t$ 的估计新息 $\\hat{\\epsilon}_t$ 是否对时间 $t+1$ 的新息 $\\hat{\\epsilon}_{t+1}$ 具有任何线性预测能力。这通过 OLS 回归进行检验：\n$$\n\\hat{\\epsilon}_{t+1} \\;=\\; \\alpha \\;+\\; \\beta \\hat{\\epsilon}_t \\;+\\; u_{t+1}, \\quad t = 1, \\ldots, T-1\n$$\n无一阶序列自相关的原假设是 $H_0: \\beta = 0$。我们计算 OLS 估计值 $\\hat{\\beta}$ 及其相关的 t 统计量。\n\n$\\beta$ 的 OLS 估计值是向量 $\\hat{\\mathbf{b}} = (\\hat{\\alpha}, \\hat{\\beta})'$ 的一个分量，由下式给出：\n$$\n\\hat{\\mathbf{b}} = (X'X)^{-1}X'Y\n$$\n其中 $Y$ 是因变量向量 $(\\hat{\\epsilon}_2, \\ldots, \\hat{\\epsilon}_T)'$，而 $X$ 是设计矩阵，其行为 $(1, \\hat{\\epsilon}_t)$，其中 $t=1, \\ldots, T-1$。\n\n$\\hat{\\beta}$ 的 t 统计量计算如下：\n$$\nt_{\\hat{\\beta}} = \\frac{\\hat{\\beta}}{\\text{s.e.}(\\hat{\\beta})}\n$$\n标准误 $\\text{s.e.}(\\hat{\\beta})$ 是估计系数协方差矩阵 $\\hat{\\sigma}_u^2 (X'X)^{-1}$ 中对应对角元素的平方根。回归误差的方差 $\\sigma_u^2$ 通过 $s_u^2 = \\frac{1}{N_{\\text{reg}}-2} \\sum u_t^2$ 来估计，其中 $N_{\\text{reg}}=T-1$ 是回归中的观测数量，而 $u_t$ 是 OLS 残差。\n\n然后我们计算该 t 统计量的双边 p 值。根据问题的明确指令，我们使用具有 $T-2$ 个自由度的学生 t 分布。\n\n最终决策通过将 p 值与显著性水平 $\\alpha_{\\text{test}} = 0.05$ 进行比较来做出：\n- 如果 p 值 $\\ge 0.05$，我们未能拒绝原假设 $H_0$。这表明残差是序列不相关的，模型在这一维度上是充分的。输出为 `True`。\n- 如果 p 值 $ 0.05$，我们拒绝 $H_0$。这表明残差中存在显著的序列相关性，暗示模型设定不当。输出为 `False`。\n\n这个完整的流程被应用于四个模拟数据集中的每一个，布尔决策序列作为最终答案被报告。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import t\n\ndef solve():\n    \"\"\"\n    Main function to run the entire estimation and testing pipeline for all test cases.\n    \"\"\"\n    # Define the test cases as per the problem statement.\n    test_cases = [\n        {\n            \"name\": \"Case 1: MA(5)\",\n            \"seed\": 202311, \"T\": 900, \"mu\": 0.0, \"phi\": 0.0,\n            \"theta\": np.array([0.4, -0.3, 0.2, -0.1, 0.05]), \"sigma\": 0.01\n        },\n        {\n            \"name\": \"Case 2: ARMA(1,5)\",\n            \"seed\": 202312, \"T\": 900, \"mu\": 0.0, \"phi\": 0.3,\n            \"theta\": np.array([0.4, -0.3, 0.2, -0.1, 0.05]), \"sigma\": 0.01\n        },\n        {\n            \"name\": \"Case 3: MA(0) / White Noise\",\n            \"seed\": 202313, \"T\": 600, \"mu\": 0.0, \"phi\": 0.0,\n            \"theta\": np.array([0.0, 0.0, 0.0, 0.0, 0.0]), \"sigma\": 0.01\n        },\n        {\n            \"name\": \"Case 4: AR(1)\",\n            \"seed\": 202314, \"T\": 250, \"mu\": 0.0, \"phi\": 0.6,\n            \"theta\": np.array([0.0, 0.0, 0.0, 0.0, 0.0]), \"sigma\": 0.01\n        }\n    ]\n    \n    alpha_test = 0.05\n    results = []\n\n    for case in test_cases:\n        # Step 1: Simulate time series data\n        x_t = simulate_arma_process(\n            T=case[\"T\"], mu=case[\"mu\"], phi=case[\"phi\"], \n            theta=case[\"theta\"], sigma=case[\"sigma\"], seed=case[\"seed\"]\n        )\n        \n        # Step 2: Fit an MA(5) model and get residuals\n        residuals = estimate_ma_and_get_residuals(x_t, q=5)\n        \n        # Step 3: Perform diagnostic test on residuals\n        decision = perform_diagnostic_test(residuals, alpha_test)\n        results.append(decision)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\ndef simulate_arma_process(T, mu, phi, theta, sigma, seed):\n    \"\"\"\n    Simulates an ARMA(1, q) process given parameters.\n    \"\"\"\n    np.random.seed(seed)\n    q = len(theta)\n    \n    # Generate white noise innovations\n    w = np.random.normal(loc=0.0, scale=sigma, size=T)\n    \n    # Initialize the time series array\n    x = np.zeros(T)\n    \n    # Create padded arrays for past values\n    x_padded = np.concatenate((np.full(1, mu), x)) # x_padded[t] corresponds to x_{t-1}\n    w_padded = np.concatenate((np.zeros(q), w)) # w_padded[t+q] corresponds to w_t\n    \n    for t_idx in range(T): # t_idx from 0 to T-1\n        # In math notation, this corresponds to t = t_idx + 1\n        \n        # AR term: phi * (x_{t-1} - mu)\n        ar_term = phi * (x_padded[t_idx] - mu)\n        \n        # MA term: sum_{j=1 to q} theta_j * w_{t-j}\n        ma_term = 0\n        for j in range(q): # j from 0 to q-1\n            # lag j+1, theta_{j+1}, w_{t-(j+1)}\n            ma_term += theta[j] * w_padded[t_idx + q - (j + 1)]\n            \n        x[t_idx] = mu + ar_term + w[t_idx] + ma_term\n        x_padded[t_idx+1] = x[t_idx]\n        \n    return x\n\ndef estimate_ma_and_get_residuals(x, q):\n    \"\"\"\n    Estimates an MA(q) model using CSS and returns the residuals.\n    \"\"\"\n    # Objective function for CSS minimization\n    def css_objective(params, x_data, q_order):\n        T = len(x_data)\n        mu = params[0]\n        theta = params[1:]\n        eps_hat = np.zeros(T)\n        \n        for i in range(T): # i from 0 to T-1, corresponds to time t=i+1\n            ma_term = 0\n            for j in range(q_order): # j from 0 to q-1, corresponds to lag j+1\n                idx = i - (j + 1)\n                if idx >= 0:\n                    ma_term += theta[j] * eps_hat[idx]\n            eps_hat[i] = x_data[i] - mu - ma_term\n        \n        return np.sum(eps_hat**2)\n\n    # Initial guess for parameters (mu, theta_1, ..., theta_q)\n    initial_params = np.zeros(q + 1)\n    \n    # Minimize the CSS\n    opt_result = minimize(\n        css_objective, \n        initial_params, \n        args=(x, q),\n        method='L-BFGS-B'\n    )\n    \n    # Get estimated parameters\n    estimated_params = opt_result.x\n    \n    # Compute final residuals with estimated parameters\n    T = len(x)\n    mu_hat = estimated_params[0]\n    theta_hat = estimated_params[1:]\n    residuals = np.zeros(T)\n    for i in range(T):\n        ma_term = 0\n        for j in range(q):\n            idx = i - (j + 1)\n            if idx >= 0:\n                ma_term += theta_hat[j] * residuals[idx]\n        residuals[i] = x[i] - mu_hat - ma_term\n        \n    return residuals\n\ndef perform_diagnostic_test(eps_hat, alpha_level):\n    \"\"\"\n    Tests H0: beta=0 in eps_{t+1} = alpha + beta*eps_t + u_{t+1}.\n    Returns True if we fail to reject H0, False otherwise.\n    \"\"\"\n    T = len(eps_hat)\n    \n    # Prepare data for OLS regression\n    y = eps_hat[1:]       # eps_{t+1} for t=1,...,T-1\n    x_reg = eps_hat[:-1]  # eps_t for t=1,...,T-1\n    \n    N_reg = len(y) # Number of observations in regression, T-1\n    \n    # Add a constant (intercept) to the regressor\n    X_reg = np.vstack([np.ones(N_reg), x_reg]).T\n    \n    # OLS estimator: (X'X)^{-1}X'y\n    try:\n        XTX_inv = np.linalg.inv(X_reg.T @ X_reg)\n        b_hat = XTX_inv @ X_reg.T @ y\n    except np.linalg.LinAlgError:\n        # Handle cases of perfect multicollinearity (unlikely with this data)\n        return True # Cannot reject H0 if test cannot be performed\n\n    beta_hat = b_hat[1]\n    \n    # Calculate t-statistic\n    ols_residuals = y - X_reg @ b_hat\n    \n    # Estimate variance of regression error term u\n    # Degrees of freedom for residual variance is N_reg - number of parameters (2)\n    df_residual = N_reg - 2\n    if df_residual = 0:\n        return True # Not enough data to perform test\n    \n    s2_u = np.sum(ols_residuals**2) / df_residual\n    \n    # Covariance matrix of beta estimates\n    var_b_hat = s2_u * XTX_inv\n    se_beta_hat = np.sqrt(var_b_hat[1, 1])\n    \n    if se_beta_hat == 0:\n        return True # Avoid division by zero\n        \n    t_stat = beta_hat / se_beta_hat\n    \n    # Calculate p-value using t-distribution\n    # As per problem, degrees of freedom is T-2\n    df_test = T - 2\n    p_value = 2 * t.sf(np.abs(t_stat), df=df_test)\n    \n    # Decision rule\n    return p_value >= alpha_level\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "2412549"}]}