{"hands_on_practices": [{"introduction": "要真正掌握单位根检验，没有什么比从头开始构建它更好的方法了。这项练习将指导你从第一性原理出发，实现增强迪基-福勒（ADF）检验，内容涵盖从使用信息准则进行滞后阶数选择到通过自助法（bootstrapping）生成临界值。通过完成这项练习，你将对该检验背后的机制有更深刻、更实践性的理解。[@problem_id:2445580]", "problem": "编写一个完整、可运行的程序，使用增广迪基-福勒（ADF）方法实现单位根检验，以确定一个单变量时间序列是稳定的（零阶单整，$I(0)$）还是不稳定的（一阶单整，$I(1)$）。此任务必须从基本原理出发，使用基础的时间序列定义和标准的计算步骤来解决，不得依赖于预先封装的单位根检验函数。对于提供的几个合成时间序列，您的程序必须在显著性水平 $\\alpha = 0.05$ 下判断是否拒绝单位根原假设，然后报告该序列是 $I(0)$（拒绝）还是 $I(1)$（不拒绝）。\n\n需要使用的基本依据和定义：\n- 如果一个单变量过程 $\\{y_t\\}$ 是弱平稳的，具有有限且不随时间变化的均值和自协方差，则该过程是 $I(0)$。如果 $\\Delta y_t = y_t - y_{t-1}$ 是 $I(0)$，但 $y_t$ 本身不是 $I(0)$，则该过程是 $I(1)$。\n- 增广迪基-福勒（ADF）检验基于普通最小二乘回归，该回归将一阶差分 $\\Delta y_t$ 对滞后水平 $y_{t-1}$、有限数量的滞后差分 $\\Delta y_{t-i}$（其中 $i \\in \\{1,\\dots,p\\}$，用于吸收短期序列相关性）以及允许的确定性回归量（一个截距项，以及可选的线性时间趋势项）进行回归。检验统计量是 $y_{t-1}$ 的估计系数与其估计标准误的常规比率。由于原假设是单位根，该统计量服从一个非标准分布，其临界值取决于回归中包含了哪些确定性回归量。\n- 为了在不调用预制临界值表的情况下保持科学真实性，通过参数自助法，在单位根原假设下，使用相同的样本量和相同的确定性回归量集来近似ADF统计量的零分布。\n\n必需的算法选择和约束：\n- 在ADF回归中始终包含截距项。仅在测试用例指定时才包含线性趋势回归量。\n- 通过赤池信息准则（AIC）在集合 $\\{0,1,\\dots,p_{\\max}\\}$ 中选择滞后阶数 $p$，其中 $p_{\\max} = \\left\\lfloor 12\\,(T/100)^{1/4}\\right\\rfloor$，$T$ 是样本量。若出现平局，则选择最小的 $p$。\n- 通过普通最小二乘法估计每个回归，并计算 $y_{t-1}$ 系数的检验统计量，即估计系数除以其估计标准误。\n- 在单位根原假设下，使用 $B = 1200$ 次重复的自助法来近似水平 $\\alpha = 0.05$ 的左尾临界值。在原假设下，将 $y_t$ 模拟为一个随机游走过程，初始值为 $0$，新息项为独立同分布的、均值为零、方差为一的高斯分布。在ADF回归中包含相同的确定性回归量（截距项，如果用例需要，还包括趋势项）。在该用例的所有自助法重复中，均使用从原始序列中选择的 $p$。\n- 如果观测到的ADF检验统计量小于或等于自助法得到的 $\\alpha$-分位数，则拒绝原假设（分类为 $I(0)$）；否则，不拒绝原假设（分类为 $I(1)$）。\n\n需要实现和评估的测试套件：\n生成以下四个合成时间序列，每个序列长度为 $T = 400$，使用方差为 $1$ 的独立同分布高斯新息项，并使用指定的种子以确保可复现性。对于每个序列，指明是否在ADF回归中包含线性趋势回归量。\n\n- 案例 $1$（稳定自回归）：$y_t = \\phi y_{t-1} + \\varepsilon_t$，其中 $\\phi = 0.6$，$y_0 = 0$，数据生成过程中无确定性趋势，ADF回归中包含截距项，无趋势项。使用种子 $s_1 = 202405$。\n- 案例 $2$（带漂移的随机游走）：$y_t = y_{t-1} + \\delta + \\varepsilon_t$，其中 $\\delta = 0.1$，$y_0 = 0$，ADF回归中包含截距项，无趋势项。使用种子 $s_2 = 202406$。\n- 案例 $3$（趋势平稳自回归）：$y_t = \\beta t + u_t$，其中 $u_t = \\phi u_{t-1} + \\varepsilon_t$，且 $\\phi = 0.7$，$\\beta = 0.05$，$u_0 = 0$，ADF回归中包含截距项和线性趋势项。使用种子 $s_3 = 202407$。\n- 案例 $4$（增量为移动平均过程的单位根）：$y_t = y_{t-1} + v_t$，其中 $v_t = \\varepsilon_t + \\theta \\varepsilon_{t-1}$ 且 $\\theta = 0.5$，$y_0=0$，$\\varepsilon_{-1}=0$，ADF回归中包含截距项，无趋势项。使用种子 $s_4 = 202408$。\n\n需要强制执行的实现细节：\n- 在所有案例中，新息序列 $\\{\\varepsilon_t\\}$ 均为均值为 $0$、方差为 $1$ 的高斯分布。\n- 自助法必须使用固定的种子，以确保结果是可复现的。\n- 每个案例的输出是一个布尔值：如果序列被分类为 $I(0)$（在 $\\alpha = 0.05$ 水平上拒绝单位根原假设），则输出 $\\text{True}$；如果被分类为 $I(1)$（不拒绝），则输出 $\\text{False}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个Python风格的布尔值列表，按案例1,2,3,4的顺序排列，元素以逗号分隔，并用方括号括起来，例如，形如“[True,False,True,False]”的一行。", "solution": "该问题要求从基本原理出发，实现增广迪基-福勒（ADF）检验，以将几个合成时间序列分类为零阶单整（$I(0)$）或一阶单整（$I(1)$）。该过程涉及回归估计、模型选择，以及使用参数自助法进行临界值估计的假设检验。\n\n问题陈述经评估后被认为是有效的。它在科学上基于已建立的时间序列计量经济学，问题设定良好，具有完整且一致的规范集，并以客观、正式的语言表述。所有必要的参数、数据生成过程和算法选择均已提供，从而可以构建一个唯一且可验证的计算解决方案。因此，我们可以着手解决该问题。\n\n解决方案的方法论包括以下步骤：\n\n1.  **构建增广迪基-福勒回归**\n    ADF检验研究时间序列 $\\{y_t\\}$ 中存在单位根的原假设。这是通过估计一个回归模型来完成的。对于一个选定的滞后阶数 $p$，模型为：\n    $$ \\Delta y_t = \\gamma y_{t-1} + \\sum_{i=1}^p \\beta_i \\Delta y_{t-i} + \\mathbf{d}_t^T \\boldsymbol{\\delta} + u_t $$\n    其中 $\\Delta y_t = y_t - y_{t-1}$ 是序列的一阶差分，$y_{t-1}$ 是滞后水平，$\\Delta y_{t-i}$ 是滞后差分，用于处理误差项 $u_t$ 中的序列相关性，而 $\\mathbf{d}_t$ 是确定性项的向量（例如，一个常数项和/或一个线性时间趋势）。关键参数是 $\\gamma$。单位根的原假设对应于 $H_0: \\gamma = 0$，其备择假设为平稳性的单边假设 $H_a: \\gamma  0$。\n\n2.  **普通最小二乘（OLS）估计与检验统计量**\n    该回归模型可以表示为矩阵形式 $\\mathbf{z} = \\mathbf{X}\\boldsymbol{\\theta} + \\mathbf{u}$，其中 $\\mathbf{z}$ 是因变量 $\\Delta y_t$ 的观测值向量，$\\mathbf{X}$ 是所有回归量（$y_{t-1}$、滞后差分和确定性项）的观测值矩阵，$\\boldsymbol{\\theta}$ 是待估计的参数向量（$\\gamma$、$\\beta_i$ 和 $\\boldsymbol{\\delta}$）。\n\n    参数向量的OLS估计量由下式给出：\n    $$ \\hat{\\boldsymbol{\\theta}} = (\\mathbf{X}^T \\mathbf{X})^{-1} \\mathbf{X}^T \\mathbf{z} $$\n    残差计算为 $\\mathbf{e} = \\mathbf{z} - \\mathbf{X}\\hat{\\boldsymbol{\\theta}}$。回归误差的估计方差为 $s^2 = \\frac{\\mathbf{e}^T \\mathbf{e}}{N - k}$，其中 $N$ 是回归中使用的观测数量，$k$ 是估计参数的数量（即 $\\mathbf{X}$ 的列数）。\n\n    ADF检验统计量是系数 $\\gamma$（即 $\\boldsymbol{\\theta}$ 的第一个元素）的标准 $t$-统计量。其计算公式为：\n    $$ t_\\gamma = \\frac{\\hat{\\gamma}}{\\widehat{\\text{SE}}(\\hat{\\gamma})} $$\n    其中 $\\hat{\\gamma}$ 是 $\\gamma$ 的OLS估计值，其标准误为 $\\widehat{\\text{SE}}(\\hat{\\gamma}) = \\sqrt{s^2 (\\mathbf{X}^T \\mathbf{X})^{-1}_{11}}$，而 $(\\mathbf{X}^T \\mathbf{X})^{-1}_{11}$ 是回归量交叉乘积矩阵的逆矩阵的第一个对角线元素。\n\n3.  **通过赤池信息准则（AIC）选择滞后阶数**\n    必须选择滞后阶数 $p$ 以确保残差 $u_t$ 近似为白噪声。我们在范围 $\\{0, 1, \\dots, p_{\\max}\\}$ 中选择 $p$，其中 $p_{\\max} = \\lfloor 12 (T/100)^{1/4} \\rfloor$。对于样本量 $T=400$，这得到 $p_{\\max} = \\lfloor 12 (400/100)^{1/4} \\rfloor = \\lfloor 12 \\cdot 4^{1/4} \\rfloor = \\lfloor 12 \\sqrt{2} \\rfloor = 16$。\n\n    对于每个候选的滞后阶数 $p$，我们估计ADF回归并计算AIC，其定义为：\n    $$ \\text{AIC}(p) = N_p \\ln\\left(\\frac{\\text{RSS}_p}{N_p}\\right) + 2k_p $$\n    其中 $N_p = T-1-p$ 是具有 $p$ 阶滞后的模型的有效观测数量，$\\text{RSS}_p$ 是残差平方和 $(\\mathbf{e}^T \\mathbf{e})$，$k_p$ 是回归量的总数（包括确定性项）。最优滞后阶数 $p^*$ 是使AIC最小化的阶数。如果出现平局，则选择最小的 $p$。\n\n4.  **通过参数自助法近似临界值**\n    在原假设 $H_0: \\gamma = 0$ 下，$t$-统计量 $t_\\gamma$ 不服从标准的学生t分布。其分布通常被称为迪基-福勒分布，它依赖于样本量和回归中包含的确定性项。我们使用参数自助法来近似这个分布。\n\n    该过程如下：\n    a. 生成 $B=1200$ 个自助样本 $\\{y_t^*\\}_{t=1}^T$，每个样本均来自零假设的数据生成过程，即一个简单的随机游走：$y_t^* = y_{t-1}^* + \\eta_t$，其中 $y_0^*=0$，新息项 $\\eta_t \\sim \\mathcal{N}(0,1)$ 是独立同分布的标准高斯变量。\n    b. 对每个自助样本，使用与原始数据相同的设定进行ADF检验：即相同的确定性回归量和上一步中选择的相同最优滞后阶数 $p^*$。\n    c. 对 $B$ 次重复中的每一次，计算并存储得到的 $t$-统计量 $t_\\gamma^*$。\n    d. 这 $B$ 个统计量的集合构成了一个经验分布，该分布近似于ADF统计量的真实零分布。对于显著性水平 $\\alpha=0.05$，左尾临界值（表示为 $c_{0.05}$）是该经验分布的第5百分位数。\n\n5.  **假设检验与分类**\n    决策规则是将从原始数据计算出的ADF统计量 $t_\\gamma$ 与自助法得到的临界值 $c_{0.05}$ 进行比较。\n    - 如果 $t_\\gamma \\le c_{0.05}$，我们拒绝原假设 $H_0$。这提供了反对单位根存在的证据，序列被分类为平稳的，或 $I(0)$。结果为 $\\text{True}$。\n    - 如果 $t_\\gamma > c_{0.05}$，我们无法拒绝原假设 $H_0$。没有足够的证据排除单位根的存在，序列被分类为非平稳的，或 $I(1)$。结果为 $\\text{False}$。\n\n这完成了该过程的逻辑设计，现在将为每个指定的测试用例实施该过程。", "answer": "```python\nimport numpy as np\n\ndef _generate_series(case_params: dict) - np.ndarray:\n    \"\"\"Generates a time series based on the specified case parameters.\"\"\"\n    T = case_params[\"T\"]\n    seed = case_params[\"seed\"]\n    dgp_type = case_params[\"dgp_type\"]\n    \n    rng = np.random.default_rng(seed)\n    eps = rng.standard_normal(T)\n    \n    y = np.zeros(T)\n\n    if dgp_type == 1:  # Stable AR(1)\n        phi = 0.6\n        y[0] = 0\n        for t in range(1, T):\n            y[t] = phi * y[t-1] + eps[t]\n    elif dgp_type == 2:  # Random walk with drift\n        delta = 0.1\n        y[0] = 0\n        for t in range(1, T):\n            y[t] = y[t-1] + delta + eps[t]\n    elif dgp_type == 3:  # Trend-stationary AR\n        phi = 0.7\n        beta = 0.05\n        u = np.zeros(T)\n        u[0] = 0\n        for t in range(1, T):\n            u[t] = phi * u[t-1] + eps[t]\n        time_trend = np.arange(1, T + 1)\n        y = beta * time_trend + u\n    elif dgp_type == 4:  # Unit root with MA(1) noise\n        theta = 0.5\n        v = np.zeros(T)\n        v[0] = eps[0]  # eps_{-1} = 0\n        for t in range(1, T):\n            v[t] = eps[t] + theta * eps[t-1]\n        y = np.cumsum(v)\n\n    return y\n\ndef _run_adf_regression(y: np.ndarray, p: int, include_trend: bool) - tuple:\n    \"\"\"\n    Constructs matrices and performs OLS for the ADF regression.\n    \n    Returns:\n        t_stat (float): The t-statistic for the lagged level coefficient.\n        aic (float): The Akaike Information Criterion value.\n    \"\"\"\n    T = len(y)\n    delta_y = np.diff(y)\n    \n    # Effective number of observations\n    n_eff = T - 1 - p\n    \n    # Dependent variable: delta_y[t] for t = p, ..., T-2\n    # This corresponds to Delta y_{p+1} ... Delta y_{T-1}\n    z = delta_y[p:]\n    \n    # Regressors\n    # 1. Lagged level: y[t-1] for t=p+1,...,T-1. Corresponds to y[p:T-1]\n    regressors = [y[p:-1]]\n    \n    # 2. Lagged differences: Delta y_{t-i} for i=1..p\n    for i in range(1, p + 1):\n        # For a given t, Delta y_{t-i} is delta_y[t-1-i]\n        # For t running from p+1 to T-1, this is a slice\n        # from (p+1)-1-i to (T-1)-1-i, i.e., p-i to T-2-i\n        regressors.append(delta_y[p - i : n_eff + p - i])\n\n    # 3. Deterministic terms\n    regressors.append(np.ones(n_eff))\n    if include_trend:\n        # Time index t runs from p+1 to T-1\n        regressors.append(np.arange(p + 1, T))\n\n    X = np.stack(regressors, axis=1)\n    k = X.shape[1]\n    \n    try:\n        # OLS estimation: beta_hat = (X'X)^{-1} X'z\n        beta_hat = np.linalg.solve(X.T @ X, X.T @ z)\n        \n        residuals = z - X @ beta_hat\n        rss = residuals @ residuals\n        \n        # AIC\n        if n_eff > 0:\n            aic = n_eff * np.log(rss / n_eff) + 2 * k\n        else:\n            aic = np.inf\n\n        # T-statistic for gamma (coefficient on y_{t-1})\n        sigma2 = rss / (n_eff - k)\n        var_cov = sigma2 * np.linalg.inv(X.T @ X)\n        se_gamma = np.sqrt(var_cov[0, 0])\n        t_stat = beta_hat[0] / se_gamma\n\n    except np.linalg.LinAlgError:\n        # Handle cases of perfect multicollinearity (unlikely but possible)\n        t_stat, aic = np.nan, np.inf\n\n    return t_stat, aic\n\ndef solve():\n    \"\"\"\n    Main function to run the ADF tests for all specified cases.\n    \"\"\"\n    test_cases = [\n        {\"dgp_type\": 1, \"T\": 400, \"seed\": 202405, \"include_trend\": False, \"B\": 1200, \"alpha\": 0.05},\n        {\"dgp_type\": 2, \"T\": 400, \"seed\": 202406, \"include_trend\": False, \"B\": 1200, \"alpha\": 0.05},\n        {\"dgp_type\": 3, \"T\": 400, \"seed\": 202407, \"include_trend\": True, \"B\": 1200, \"alpha\": 0.05},\n        {\"dgp_type\": 4, \"T\": 400, \"seed\": 202408, \"include_trend\": False, \"B\": 1200, \"alpha\": 0.05},\n    ]\n\n    results = []\n    \n    # Fixed seed for bootstrap to ensure reproducibility\n    BOOTSTRAP_SEED = 12345\n    boot_rng = np.random.default_rng(BOOTSTRAP_SEED)\n\n    for case in test_cases:\n        # 1. Generate the time series\n        y = _generate_series(case)\n        T = case[\"T\"]\n        \n        # 2. Select optimal lag order p using AIC\n        p_max = int(12 * (T / 100)**(1/4))\n        aics = []\n        for p in range(p_max + 1):\n            _, aic = _run_adf_regression(y, p, case[\"include_trend\"])\n            aics.append((aic, p))\n        \n        # Smallest p wins ties due to stable sort nature or explicit handling.\n        # min() on tuples (aic, p) naturally prefers smaller p for same aic.\n        best_p = min(aics)[1]\n        \n        # 3. Calculate ADF statistic for the original series\n        observed_t_stat, _ = _run_adf_regression(y, best_p, case[\"include_trend\"])\n        \n        # 4. Run bootstrap to find the critical value\n        bootstrap_t_stats = []\n        for _ in range(case[\"B\"]):\n            # Generate a series under the null (random walk)\n            innovations = boot_rng.standard_normal(T)\n            y_star = np.cumsum(innovations)\n            \n            # Calculate t-stat on this bootstrapped series\n            t_stat_star, _ = _run_adf_regression(y_star, best_p, case[\"include_trend\"])\n            if not np.isnan(t_stat_star):\n                 bootstrap_t_stats.append(t_stat_star)\n        \n        # 5. Determine the critical value and make a decision\n        critical_value = np.quantile(bootstrap_t_stats, case[\"alpha\"])\n        \n        is_I0 = observed_t_stat = critical_value\n        results.append(is_I0)\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2445580"}, {"introduction": "掌握了检验的机制后，让我们将其应用于一个实际问题：一个事件对时间序列造成的是永久性变化还是暂时性变化？本练习使用一个易于理解的在线游戏玩家数量场景，来演示如何使用ADF检验来区分冲击（shock）的影响。你将学会如何将单位根检验的统计结果与有意义的现实世界解释联系起来。[@problem_id:2445622]", "problem": "考虑三个合成时间序列，它们代表了一款在线游戏的每日并发玩家数。每个序列都在指定的一天包含一次内容更新。对于每个序列，通过基于增广迪基-福勒（ADF）框架的单位根检验，确定内容更新是产生永久性的水平变化还是暂时性的峰值。\n\n定义和检验规则：\n- 设 $\\{y_t\\}_{t=0}^{T}$ 为一个单变量时间序列。定义 $\\Delta y_t \\equiv y_t - y_{t-1}$。\n- 带有截距项（无确定性趋势）且恰好有 $p=2$ 个增广滞后项的ADF回归方程为\n$$\n\\Delta y_t \\;=\\; \\alpha \\;+\\; \\gamma \\, y_{t-1} \\;+\\; \\beta_1 \\, \\Delta y_{t-1} \\;+\\; \\beta_2 \\, \\Delta y_{t-2} \\;+\\; \\varepsilon_t,\\quad t=3,4,\\dots,T,\n$$\n其中 $\\varepsilon_t$ 是回归扰动项。\n- 原假设是存在单位根：$H_0: \\gamma = 0$。备择假设是围绕一个常数平稳：$H_1: \\gamma  0$。\n- 计算上述回归中 $\\gamma$ 的普通最小二乘 $t$-统计量，并将其与带有截距项（无趋势）设定下的 Dickey–Fuller $5\\%$ 临界值 $-2.86$ 进行比较。当且仅当 $t$-统计量小于或等于 $-2.86$ 时，拒绝 $H_0$。\n- 内容更新的分类规则：如果 $H_0$ 被拒绝，则将更新效应分类为暂时性的（过程是平稳的，冲击会衰减）；如果 $H_0$ 未被拒绝，则将效应分类为永久性的（过程具有单位根，冲击会持续存在）。\n\n数据生成过程（测试套件）：\n所有创新项都是独立同分布的高斯随机变量。为保证可复现性，使用固定的伪随机数生成器种子 $12345$。对于以下每种情况，取指定的 $y_0$ 并为每个 $t$ 独立生成 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$。\n\n- 情况A（带漂移的随机游走和永久性更新跳跃）：\n  - 参数：$T = 500$, $y_0 = 1000$, $\\mu = 0.2$, $\\sigma = 5$, $\\Delta = 50$, 更新日 $\\tau = 300$。\n  - $t=1,2,\\dots,T$ 的递推公式：\n    $$\n    y_t \\;=\\; y_{t-1} \\;+\\; \\mu \\;+\\; \\varepsilon_t \\;+\\; \\Delta \\cdot \\mathbf{1}\\{t=\\tau\\}.\n    $$\n- 情况B（带有脉冲更新冲击的平稳自回归）：\n  - 参数：$T = 500$, $y_0 = 1000$, $\\phi = 0.6$, 目标均值 $\\bar{y}=1000$，因此截距项 $c = \\bar{y}\\,(1-\\phi) = 400$, $\\sigma = 10$, 脉冲大小 $A=120$, 更新日 $\\tau = 300$。\n  - $t=1,2,\\dots,T$ 的递推公式：\n    $$\n    y_t \\;=\\; c \\;+\\; \\phi\\, y_{t-1} \\;+\\; \\varepsilon_t \\;+\\; A \\cdot \\mathbf{1}\\{t=\\tau\\}.\n    $$\n- 情况C（高度持续但平稳的自回归，带有脉冲更新冲击）：\n  - 参数：$T = 1200$, $y_0 = 1000$, $\\phi = 0.9$, 目标均值 $\\bar{y}=1000$，因此截距项 $c = \\bar{y}\\,(1-\\phi) = 100$, $\\sigma = 5$, 脉冲大小 $A=100$, 更新日 $\\tau = 800$。\n  - $t=1,2,\\dots,T$ 的递推公式：\n    $$\n    y_t \\;=\\; c \\;+\\; \\phi\\, y_{t-1} \\;+\\; \\varepsilon_t \\;+\\; A \\cdot \\mathbf{1}\\{t=\\tau\\}.\n    $$\n\n任务：\n- 对于这三种情况中的每一种，使用指定的参数和种子生成序列，按照上述定义计算恰好有 $p=2$ 个增广滞后项和截距项的ADF $t$-统计量，使用临界值 $-2.86$ 在 $\\alpha = 0.05$ 的显著性水平上执行假设检验，并根据上文所述规则将更新的效应分类为永久性或暂时性。\n\n要求的最终输出格式：\n- 你的程序应生成单行输出，其中按顺序包含三种情况的分类结果 $\\text{[情况 A, 情况 B, 情况 C]}$，格式化为逗号分隔、无空格的Python风格布尔值列表，例如 $\\text{[True,False,True]}$，其中 $\\text{True}$ 表示永久性效应，$\\text{False}$ 表示暂时性效应。", "solution": "对提出的问题进行验证。\n\n### 步骤1：提取给定信息\n问题提供了以下数据、定义和规则：\n- 一个单变量时间序列 $\\{y_t\\}_{t=0}^{T}$。\n- 一阶差分算子：$\\Delta y_t \\equiv y_t - y_{t-1}$。\n- 带有截距项和 $p=2$ 个滞后项的增广迪基-福勒（ADF）回归模型：\n$$\n\\Delta y_t \\;=\\; \\alpha \\;+\\; \\gamma \\, y_{t-1} \\;+\\; \\beta_1 \\, \\Delta y_{t-1} \\;+\\; \\beta_2 \\, \\Delta y_{t-2} \\;+\\; \\varepsilon_t,\\quad t=3,4,\\dots,T.\n$$\n- 单位根的原假设为 $H_0: \\gamma = 0$。\n- 平稳性的备择假设为 $H_1: \\gamma  0$。\n- 决策规则是，如果在 $5\\%$ 的显著性水平上，$\\gamma$ 的普通最小二乘（OLS）$t$-统计量小于或等于临界值 $-2.86$，则拒绝 $H_0$。\n- 定义了一个分类规则：如果 $H_0$ 未被拒绝，效应为‘永久性’；如果 $H_0$ 被拒绝，效应为‘暂时性’。\n- 必须使用固定的伪随机数生成器种子 $12345$。\n- 指定了三种具有特定数据生成过程（DGP）的情况：\n    - 情况A：$y_t = y_{t-1} + \\mu + \\varepsilon_t + \\Delta \\cdot \\mathbf{1}\\{t=\\tau\\}$，其中 $T = 500$, $y_0 = 1000$, $\\mu = 0.2$, $\\sigma = 5$, $\\Delta = 50$, $\\tau = 300$。\n    - 情况B：$y_t = c + \\phi y_{t-1} + \\varepsilon_t + A \\cdot \\mathbf{1}\\{t=\\tau\\}$，其中 $T = 500$, $y_0 = 1000$, $\\phi = 0.6$, $c = 400$, $\\sigma = 10$, $A = 120$, $\\tau = 300$。\n    - 情况C：$y_t = c + \\phi y_{t-1} + \\varepsilon_t + A \\cdot \\mathbf{1}\\{t=\\tau\\}$，其中 $T = 1200$, $y_0 = 1000$, $\\phi = 0.9$, $c = 100$, $\\sigma = 5$, $A = 100$, $\\tau = 800$。\n- 要求的输出是一个布尔值列表 `[情况A结果, 情况B结果, 情况C结果]`，其中 `True` 表示‘永久性’效应，`False` 表示‘暂时性’效应。\n\n### 步骤2：使用提取的信息进行验证\n根据指定的验证标准对问题进行评估。\n- **科学性**：该问题基于时间序列计量经济学的标准、成熟的原理，特别是单位根过程理论和增广迪基-福勒检验的应用。DGP代表了经典模型：带漂移的随机游走（非平稳）和自回归过程（平稳）。\n- **适定性**：问题是完全指定的。数据生成（$T, y_0, \\sigma$ 等）和ADF检验（$p=2$，仅含截距项模型，临界值）所需的所有必要参数都已提供。该任务是一个直接的计算过程，对于给定的随机种子，其结果清晰且唯一。\n- **客观性**：问题以精确、量化的术语陈述，没有任何主观或模糊的语言。\n- **其他缺陷**：问题设置在内部是一致的。例如，在情况B中，截距项 $c$ 与目标均值 $\\bar{y}$ 和自回归参数 $\\phi$ 一致：$c = \\bar{y}(1-\\phi) = 1000(1-0.6) = 400$。同样，对于情况C，$c = 1000(1-0.9) = 100$。不存在矛盾、信息缺失或不符合科学原理的前提。\n\n### 步骤3：结论与行动\n问题是有效的。这是一个定义明确的计量经济学计算任务。将提供一个解决方案。\n\n### 求解推导\n任务是为三个合成时间序列，将内容更新的效应分类为‘永久性’或‘暂时性’。分类取决于增广迪基-福勒（ADF）单位根检验的结果。每种情况的步骤如下。\n\n1.  **时间序列生成**：对于每种情况，根据其指定的数据生成过程（DGP）生成一个长度为 $T+1$ 的时间序列 $\\{y_t\\}_{t=0}^T$。从重置的种子 $12345$ 开始，为每个序列生成一组不同的伪随机高斯创新项 $\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$。\n\n2.  **ADF回归设置**：ADF检验回归方程指定为：\n    $$\n    \\Delta y_t = \\alpha + \\gamma y_{t-1} + \\beta_1 \\Delta y_{t-1} + \\beta_2 \\Delta y_{t-2} + \\varepsilon_t\n    $$\n    回归针对 $t = 3, 4, \\dots, T$ 进行。这为回归提供了 $N = T-2$ 个观测值。我们将因变量的观测向量定义为 $Y = [\\Delta y_3, \\Delta y_4, \\dots, \\Delta y_T]^T$。自变量的设计矩阵 $X$ 由 $N$ 行和 $k=4$ 列构成：\n    $$\n    X = \\begin{bmatrix}\n    1  y_2  \\Delta y_2  \\Delta y_1 \\\\\n    1  y_3  \\Delta y_3  \\Delta y_2 \\\\\n    \\vdots  \\vdots  \\vdots  \\vdots \\\\\n    1  y_{T-1}  \\Delta y_{T-1}  \\Delta y_{T-2}\n    \\end{bmatrix}\n    $$\n    模型可以写成矩阵形式 $Y = X \\mathbf{\\theta} + \\mathbf{\\varepsilon}$，其中 $\\mathbf{\\theta} = [\\alpha, \\gamma, \\beta_1, \\beta_2]^T$。\n\n3.  **OLS估计与t-统计量计算**：回归系数向量 $\\hat{\\mathbf{\\theta}}$ 使用普通最小二乘法（OLS）进行估计：\n    $$\n    \\hat{\\mathbf{\\theta}} = (X^T X)^{-1} X^T Y\n    $$\n    我们关心的系数是 $\\hat{\\gamma}$，即 $\\hat{\\mathbf{\\theta}}$ 的第二个元素。为了计算其 $t$-统计量，我们首先需要它的标准误 $\\text{SE}(\\hat{\\gamma})$。\n    回归误差的方差 $\\sigma^2_\\varepsilon$ 是根据残差平方和（SSR）估计的：\n    $$\n    \\hat{\\sigma}^2_\\varepsilon = \\frac{\\text{SSR}}{N-k} = \\frac{(Y-X\\hat{\\mathbf{\\theta}})^T(Y-X\\hat{\\mathbf{\\theta}})}{N-k}\n    $$\n    系数向量的估计协方差矩阵为：\n    $$\n    \\widehat{\\text{Cov}}(\\hat{\\mathbf{\\theta}}) = \\hat{\\sigma}^2_\\varepsilon (X^T X)^{-1}\n    $$\n    $\\hat{\\gamma}$ 的方差是该矩阵的第二个对角元素（索引为1,1），我们称之为 $\\widehat{\\text{Var}}(\\hat{\\gamma})$。标准误是其平方根：\n    $$\n    \\text{SE}(\\hat{\\gamma}) = \\sqrt{\\widehat{\\text{Var}}(\\hat{\\gamma})}\n    $$\n    然后，$\\gamma$ 的 $t$-统计量计算如下：\n    $$\n    t_{\\gamma} = \\frac{\\hat{\\gamma}}{\\text{SE}(\\hat{\\gamma})}\n    $$\n\n4.  **假设检验与分类**：将计算出的 $t$-统计量 $t_{\\gamma}$ 与给定的 $5\\%$ 临界值 $c_{0.05} = -2.86$ 进行比较。\n    - 如果 $t_{\\gamma} \\le -2.86$，则拒绝原假设 $H_0: \\gamma=0$。检验表明序列是平稳的。根据问题的规则，更新效应被分类为‘暂时性’，对应布尔值 `False`。\n    - 如果 $t_{\\gamma} > -2.86$，我们未能拒绝原假设。检验未能提供充分证据来反驳单位根的存在。效应被分类为‘永久性’，对应布尔值 `True`。\n\n整个过程通过计算实现，并应用于所定义的三个案例中的每一个。\n\n- **情况A**代表随机游走，根据定义这是一个具有单位根（$\\gamma=0$）的过程。我们预期检验将无法拒绝原假设，从而得出‘永久性’的分类（`True`）。\n- **情况B**是一个平稳的AR(1)过程，其中 $\\phi=0.6$，远离单位根边界。真实的 $\\gamma = \\phi - 1 = -0.4$。该检验应有很强的功效来拒绝原假设，从而得出‘暂时性’的分类（`False`）。\n- **情况C**是一个平稳的AR(1)过程，其中 $\\phi=0.9$，具有高度持续性且接近单位根。真实的 $\\gamma = \\phi - 1 = -0.1$。已知ADF检验在此类情况下的功效较低，这意味着即使原假设是错误的，它们也常常无法拒绝原假设。因此，检验很可能将此过程分类为具有单位根，从而得出‘永久性’的分类（`True`）。\n\n最终输出将是这三个布尔结果的列表。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_adf_test(params):\n    \"\"\"\n    Generates a time series based on a given DGP and performs an ADF test.\n\n    Args:\n        params (dict): A dictionary containing parameters for the DGP and the test.\n                       Keys: 'T', 'y0', 'sigma', 'tau', 'type', and other DGP-specific params.\n\n    Returns:\n        bool: True if the effect is classified as 'permanent', False otherwise.\n    \"\"\"\n    # Unpack parameters\n    T = params['T']\n    y0 = params['y0']\n    sigma = params['sigma']\n    tau = params['tau']\n    dgp_type = params['type']\n\n    # Set seed for reproducibility for this specific case\n    rng = np.random.default_rng(12345)\n    \n    # Generate random innovations\n    eps = rng.normal(0, sigma, size=T)\n\n    # Generate the time series y from t=0 to T\n    y = np.zeros(T + 1)\n    y[0] = y0\n\n    if dgp_type == 'A':\n        mu = params['mu']\n        delta = params['delta']\n        for t in range(1, T + 1):\n            jump = delta if t == tau else 0\n            y[t] = y[t-1] + mu + eps[t-1] + jump\n    elif dgp_type in ['B', 'C']:\n        c = params['c']\n        phi = params['phi']\n        A = params['A']\n        for t in range(1, T + 1):\n            impulse = A if t == tau else 0\n            y[t] = c + phi * y[t-1] + eps[t-1] + impulse\n            \n    # Prepare data for ADF regression\n    # The regression uses observations from t=3 to T\n    # Total observations in regression: N = T - 2\n    \n    # First differences: delta_y_t = y_t - y_{t-1} for t=1,...,T\n    delta_y = y[1:] - y[:-1]\n\n    # Dependent variable: Y = [delta_y_3, ..., delta_y_T]\n    # Corresponds to delta_y[2:]\n    Y = delta_y[2:]\n    \n    # Number of observations and parameters in the regression\n    N = T - 2\n    k = 4 # alpha, gamma, beta1, beta2\n\n    # Design matrix X\n    # Columns: intercept, y_{t-1}, delta_y_{t-1}, delta_y_{t-2}\n    # For t=3..T, this corresponds to:\n    # y[2:-1] for y_{t-1}\n    # delta_y[1:-1] for delta_y_{t-1}\n    # delta_y[0:-2] for delta_y_{t-2}\n    X = np.zeros((N, k))\n    X[:, 0] = 1.0  # Intercept alpha\n    X[:, 1] = y[2:-1]  # Lagged level y_{t-1}\n    X[:, 2] = delta_y[1:-1]  # Lagged difference delta_y_{t-1}\n    X[:, 3] = delta_y[0:-2]  # Second lagged difference delta_y_{t-2}\n\n    # Perform OLS regression to find coefficients theta_hat\n    # theta_hat = (X.T @ X)^-1 @ X.T @ Y\n    # Using np.linalg.lstsq is more numerically stable\n    coeffs, ssr_array, _, _ = np.linalg.lstsq(X, Y, rcond=None)\n    \n    gamma_hat = coeffs[1]\n    \n    # Calculate t-statistic for gamma\n    if ssr_array.size == 0:\n        # This case happens if the model is a perfect fit, which is highly unlikely\n        # with random data. Return a default to avoid crashing.\n        return True\n\n    ssr = ssr_array[0]\n    dof = N - k\n    sigma_eps_sq_hat = ssr / dof\n\n    # Covariance matrix of coefficients\n    try:\n        X_T_X_inv = np.linalg.inv(X.T @ X)\n    except np.linalg.LinAlgError:\n        # In case of perfect multicollinearity\n        return True # Cannot reject H0 if test cannot be computed\n\n    var_gamma_hat = sigma_eps_sq_hat * X_T_X_inv[1, 1]\n    se_gamma_hat = np.sqrt(var_gamma_hat)\n\n    if se_gamma_hat == 0:\n        return True # Avoid division by zero, non-rejection is a safe default\n\n    t_statistic = gamma_hat / se_gamma_hat\n    \n    # Critical value from the problem\n    critical_value = -2.86\n    \n    # Decision rule\n    # H0 not rejected -> permanent -> True\n    # H0 rejected -> temporary -> False\n    return t_statistic > critical_value\n\n\ndef solve():\n    \"\"\"\n    Main function to run the analysis for all three cases and print the result.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            'type': 'A', 'T': 500, 'y0': 1000, 'mu': 0.2, 'sigma': 5,\n            'delta': 50, 'tau': 300\n        },\n        {\n            'type': 'B', 'T': 500, 'y0': 1000, 'phi': 0.6, 'c': 400,\n            'sigma': 10, 'A': 120, 'tau': 300\n        },\n        {\n            'type': 'C', 'T': 1200, 'y0': 1000, 'phi': 0.9, 'c': 100,\n            'sigma': 5, 'A': 100, 'tau': 800\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        is_permanent = run_adf_test(case)\n        results.append(is_permanent)\n\n    # Format output as specified: [True,False,True]\n    result_str = f\"[{','.join(map(str, results))}]\"\n    print(result_str)\n\nsolve()\n```", "id": "2445622"}, {"introduction": "统计工具虽然功能强大，但其有效性依赖于特定的假设。这项练习是一个至关重要的警示案例，它将探讨当我们对一个纯粹确定性但呈混沌状态的序列应用为随机过程设计的单位根检验时会发生什么。这将挑战你批判性地思考计量经济学检验的局限性，以及理解数据内在性质的重要性。[@problem_id:2433700]", "problem": "确定性混沌序列可以通过逻辑斯蒂映射产生。设逻辑斯蒂映射定义为 $x_{t+1} = r\\,x_t\\,(1-x_t)$，其中 $t \\ge 0$，参数 $r \\in (0,4]$，初始条件 $x_0 \\in (0,1)$。考虑当使用单位根检验评估从此映射派生的序列时，其平稳性与非平稳性的问题。\n\n为给定的样本量为 $T \\ge 3$ 的单变量时间序列 $\\{y_t\\}_{t=1}^T$ 定义以下形式假设检验。构建一阶差分 $\\Delta y_t = y_t - y_{t-1}$（对于 $t=2,\\dots,T$），并考虑线性模型\n$$\n\\Delta y_t = \\alpha + \\gamma\\,y_{t-1} + \\varepsilon_t \\quad \\text{for } t=2,\\dots,T,\n$$\n其中 $\\alpha$ 和 $\\gamma$ 是未知常数，$\\varepsilon_t$ 是未观测到的扰动项。令 $\\widehat{\\gamma}$ 为 $\\gamma$ 的普通最小二乘估计量，并令 $\\operatorname{se}(\\widehat{\\gamma})$ 为从该回归中计算出的其普通最小二乘标准误。定义 Dickey–Fuller 统计量\n$$\n\\tau = \\frac{\\widehat{\\gamma}}{\\operatorname{se}(\\widehat{\\gamma})}.\n$$\n在显著性水平 $\\alpha_{\\text{test}} = 0.05$ 下，使用仅含截距项的 Dickey–Fuller $5\\%$ 临界值 $c_{0.05} = -2.86$。决策规则是：当且仅当 $\\tau \\le c_{0.05}$ 时，拒绝单位根原假设；否则，不拒绝。在本题中，按如下方式报告每种情况的布尔分类“单位根”：如果原假设未被拒绝（解释为“分类为单位根”），则返回 $\\text{True}$；如果原假设被拒绝（解释为“分类为水平平稳”），则返回 $\\text{False}$。\n\n为以下测试套件构建序列并应用该检验。在所有情况下，均需严格使用指定的参数值和样本量，且除明确定义外，不应用任何预过滤。\n\n- 情况 A（确定性混沌，水平序列）：逻辑斯蒂映射，参数 $r=4$, $x_0=0.123456789$，生成 $\\{x_t\\}_{t=1}^T$（$T=2000$），并设 $y_t = x_t$。\n\n- 情况 B（确定性混沌，中心化水平序列的积分）：逻辑斯蒂映射，参数 $r=4$, $x_0=0.123456789$，生成 $\\{x_t\\}_{t=1}^T$（$T=2000$），定义 $z_t = x_t - \\tfrac{1}{2}$（对于 $t=1,\\dots,T$），并设 $y_t = \\sum_{i=1}^t z_i$（对于 $t=1,\\dots,T$）。\n\n- 情况 C（随机单位根，随机游走）：定义 $y_1 = 0$ 和 $y_t = y_{t-1} + \\varepsilon_t$（对于 $t=2,\\dots,T$，$T=2000$），其中 $\\{\\varepsilon_t\\}$ 是独立同分布的正态随机变量，均值为 $0$，方差为 $1$，使用种子为 $s = 314159$ 的伪随机数生成器生成。\n\n- 情况 D（边界条件，短混沌样本）：逻辑斯蒂映射，参数 $r=4$, $x_0=0.123456789$，生成 $\\{x_t\\}_{t=1}^T$（$T=64$），并设 $y_t = x_t$。\n\n您的程序必须严格按照所述实现检验统计量和决策规则，并按 A、B、C、D 的顺序计算四种情况各自的布尔结果。要求的最终输出格式为单行文本，包含一个由方括号括起来的、逗号分隔的四个布尔值列表，例如 $[\\text{False},\\text{True},\\text{True},\\text{False}]$。不应打印任何其他文本。", "solution": "问题陈述已经过严格评估，被认为是有效的。它具有科学依据，提法明确，客观，并包含了获得唯一解所需的所有必要信息。它提出了一个计算计量经济学中的标准练习，旨在研究单位根检验在随机和确定性时间序列上的行为。我们现在开始提供正式解法。\n\n该问题要求实现一个简化的 Dickey-Fuller 检验，将四个不同的时间序列分类为具有单位根（“非平稳”，`True`）或不具有单位根（“平稳”，`False`）。该决策基于一个固定的临界值。\n\n该检验的核心是对以下模型进行普通最小二乘（OLS）估计：\n$$\n\\Delta y_t = \\alpha + \\gamma\\,y_{t-1} + \\varepsilon_t\n$$\n时间指数为 $t=2, \\dots, T$。此处，$\\{y_t\\}_{t=1}^T$ 是我们关心的样本量为 $T$ 的时间序列，$\\Delta y_t = y_t - y_{t-1}$ 是其一阶差分。令 $N_{reg} = T-1$ 为可用于回归的观测数量。\n\n我们可以将此回归表示为矩阵形式 $\\mathbf{Y}_{\\text{reg}} = \\mathbf{X}_{\\text{reg}}\\boldsymbol{\\beta} + \\boldsymbol{\\varepsilon}$，其中：\n- $\\mathbf{Y}_{\\text{reg}} = (\\Delta y_2, \\Delta y_3, \\dots, \\Delta y_T)^T$ 是因变量的 $(N_{reg} \\times 1)$ 向量。\n- $\\mathbf{X}_{\\text{reg}}$ 是 $(N_{reg} \\times 2)$ 的设计矩阵，其第一列是全为1的向量（对应截距项 $\\alpha$），第二列是滞后水平向量 $(y_1, y_2, \\dots, y_{T-1})^T$。\n- $\\boldsymbol{\\beta} = (\\alpha, \\gamma)^T$ 是待估计参数的 $(2 \\times 1)$ 向量。\n- $\\boldsymbol{\\varepsilon} = (\\varepsilon_2, \\varepsilon_3, \\dots, \\varepsilon_T)^T$ 是未观测到的扰动项向量。\n\n$\\boldsymbol{\\beta}$ 的 OLS 估计量由标准公式给出：\n$$\n\\widehat{\\boldsymbol{\\beta}} = \\begin{pmatrix} \\widehat{\\alpha} \\\\ \\widehat{\\gamma} \\end{pmatrix} = (\\mathbf{X}_{\\text{reg}}^T \\mathbf{X}_{\\text{reg}})^{-1} \\mathbf{X}_{\\text{reg}}^T \\mathbf{Y}_{\\text{reg}}\n$$\n我们关心的是估计值 $\\widehat{\\gamma}$。下一步是计算其标准误 $\\operatorname{se}(\\widehat{\\gamma})$。首先，我们计算回归残差 $\\widehat{\\varepsilon}_t = \\Delta y_t - (\\widehat{\\alpha} + \\widehat{\\gamma}y_{t-1})$ 并估计扰动项的方差：\n$$\n\\widehat{\\sigma}^2 = \\frac{1}{N_{reg} - p} \\sum_{t=2}^T \\widehat{\\varepsilon}_t^2 = \\frac{1}{T-3} \\sum_{t=2}^T \\widehat{\\varepsilon}_t^2\n$$\n其中 $p=2$ 是估计参数（$\\alpha$ 和 $\\gamma$）的数量。估计系数的方差-协方差矩阵是：\n$$\n\\widehat{\\operatorname{Var}}(\\widehat{\\boldsymbol{\\beta}}) = \\widehat{\\sigma}^2 (\\mathbf{X}_{\\text{reg}}^T \\mathbf{X}_{\\text{reg}})^{-1}\n$$\n$\\widehat{\\gamma}$ 的方差是该矩阵的第二个对角线元素。标准误是其平方根：\n$$\n\\operatorname{se}(\\widehat{\\gamma}) = \\sqrt{\\left[\\widehat{\\operatorname{Var}}(\\widehat{\\boldsymbol{\\beta}})\\right]_{2,2}}\n$$\n最后，Dickey-Fuller 统计量是 $\\widehat{\\gamma}$ 的 t-比率：\n$$\n\\tau = \\frac{\\widehat{\\gamma}}{\\operatorname{se}(\\widehat{\\gamma})}\n$$\n原假设是序列具有单位根（在潜在的数据生成过程 $y_t = y_{t-1} + \\dots$ 中 $\\gamma=0$）。决策规则是如果 $\\tau \\le c_{0.05} = -2.86$ 则拒绝此原假设。拒绝意味着序列是平稳的，得出结果 `False`。未能拒绝则意味着序列被分类为具有单位根，得出结果 `True`。\n\n我们现在将此程序应用于指定的四种情况中的每一种。\n\n**情况 A：确定性混沌，水平序列**\n序列是由逻辑斯蒂映射 $x_{t+1} = 4x_t(1-x_t)$（初始值 $x_0=0.123456789$）生成的 $\\{y_t\\}_{t=1}^{2000}$。当 $r=4$ 时，逻辑斯蒂映射是遍历的，并产生一个有界于 $(0,1)$ 内的混沌但平稳的序列。一个设定正确且数据充足的检验应该能将该序列识别为平稳的。当 $T=2000$ 时，样本量很大，我们预期该检验具有较高的功效。因此，我们预计 $\\tau \\le -2.86$，从而拒绝单位根原假设。分类应为 `False`。\n\n**情况 B：确定性混沌，中心化水平序列的积分**\n该序列通过对一个中心化的混沌序列求累积和而构建，$y_t = \\sum_{i=1}^t z_i$，其中 $z_t = x_t - 0.5$。序列 $\\{z_t\\}$ 是平稳的，均值为零。累积（或积分）过程会引入非平稳性。这种构造是随机游走的确定性模拟。Dickey-Fuller 检验旨在检测此类积分过程。我们预期该检验将无法拒绝原假设，从而正确识别出序列的非平稳性质。分类应为 `True`。\n\n**情况 C：随机单位根，随机游走**\n该序列是一个典型的随机游走：$y_t = y_{t-1} + \\varepsilon_t$，其中 $y_1=0$ 且 $\\varepsilon_t \\sim \\text{i.i.d. } N(0,1)$。这是 Dickey-Fuller 检验设计的原型过程。根据构造，它包含一个单位根。该检验应以高概率无法拒绝原假设。分类应为 `True`。\n\n**情况 D：边界条件，短混沌样本**\n该序列由与情况 A 相同的平稳混沌过程生成，但样本量被严格限制为 $T=64$。Dickey-Fuller 检验的一个众所周知的特性是其在小样本中统计功效较低。这意味着当数据稀少时，该检验通常无法区分具有高持续性的平稳过程和真正的单位根过程。混沌序列可以表现出强烈的短期相关性，模仿随机游走的行为。因此，该检验很可能（甚至可以说，是预期之中地）无法拒绝原假设，从而将平稳的混沌序列错误地分类为非平稳的单位根过程。分类应为 `True`。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Dickey-Fuller test statistic and classification for four specified time series.\n    \"\"\"\n\n    def compute_dickey_fuller_tau(y_series: np.ndarray) - float:\n        \"\"\"\n        Calculates the Dickey-Fuller tau statistic for a given time series.\n        The regression model is Delta(y_t) = alpha + gamma * y_{t-1} + eps_t.\n\n        Args:\n            y_series: A 1D numpy array representing the time series {y_t}.\n\n        Returns:\n            The calculated tau statistic.\n        \"\"\"\n        T = len(y_series)\n        if T  3:\n            raise ValueError(\"Series must have at least 3 observations for the test.\")\n\n        # Construct variables for regression\n        # Y_reg = Delta(y_t) for t=2,...,T\n        # X_reg = [1, y_{t-1}] for t=2,...,T\n        y_reg = y_series[1:] - y_series[:-1]  # Delta(y_t)\n        x_lagged = y_series[:-1]  # y_{t-1}\n\n        N_reg = T - 1  # Number of observations in the regression\n        \n        # Design matrix includes a constant and the lagged variable\n        X_reg = np.vstack((np.ones(N_reg), x_lagged)).T\n\n        # OLS estimation: beta_hat = (X'X)^-1 * X'Y\n        try:\n            XTX_inv = np.linalg.inv(X_reg.T @ X_reg)\n        except np.linalg.LinAlgError:\n            # This would happen if X'X is singular, e.g., if y_lagged is constant.\n            # For the given problems, this is highly unlikely.\n            return np.nan\n\n        beta_hat = XTX_inv @ X_reg.T @ y_reg\n        gamma_hat = beta_hat[1]\n\n        # Calculate standard error of gamma_hat\n        residuals = y_reg - X_reg @ beta_hat\n        p = 2  # Number of parameters (alpha, gamma)\n        df = N_reg - p\n        if df = 0:\n            return np.nan\n\n        sigma2_hat = np.sum(residuals**2) / df\n        \n        # Variance of gamma_hat is sigma2_hat * (2,2)-element of (X'X)^-1\n        var_gamma_hat = sigma2_hat * XTX_inv[1, 1]\n        se_gamma_hat = np.sqrt(var_gamma_hat)\n        \n        if se_gamma_hat == 0:\n            # Avoid division by zero\n            return np.inf if gamma_hat != 0 else np.nan\n\n        tau_statistic = gamma_hat / se_gamma_hat\n        return tau_statistic\n\n    def generate_logistic_map_series(r, x0, T):\n        \"\"\"Generates a series from the logistic map.\"\"\"\n        series = np.zeros(T)\n        x_current = x0\n        # Iterate T times to get T points, starting from x_1\n        for i in range(T):\n            x_current = r * x_current * (1 - x_current)\n            series[i] = x_current\n        return series\n\n    # Test parameters\n    r_val = 4.0\n    x0_val = 0.123456789\n    c_critical = -2.86\n    prng_seed = 314159\n\n    results = []\n\n    # Case A\n    T_A = 2000\n    # Generate T data points for y_t where t=1,...,T\n    y_A = generate_logistic_map_series(r_val, x0_val, T_A)\n    tau_A = compute_dickey_fuller_tau(y_A)\n    results.append(tau_A > c_critical)\n    \n    # Case B\n    T_B = 2000\n    x_B = generate_logistic_map_series(r_val, x0_val, T_B)\n    z_B = x_B - 0.5\n    y_B = np.cumsum(z_B)\n    tau_B = compute_dickey_fuller_tau(y_B)\n    results.append(tau_B > c_critical)\n    \n    # Case C\n    T_C = 2000\n    rng = np.random.default_rng(prng_seed)\n    # Generate T-1 shocks for t=2...T\n    epsilon_shocks = rng.normal(loc=0.0, scale=1.0, size=T_C - 1)\n    # y_1 = 0, y_t = y_{t-1} + eps_t for t>=2\n    # y_t = sum_{i=2 to t} eps_i\n    y_C = np.concatenate(([0.0], np.cumsum(epsilon_shocks)))\n    tau_C = compute_dickey_fuller_tau(y_C)\n    results.append(tau_C > c_critical)\n    \n    # Case D\n    T_D = 64\n    y_D = generate_logistic_map_series(r_val, x0_val, T_D)\n    tau_D = compute_dickey_fuller_tau(y_D)\n    results.append(tau_D > c_critical)\n    \n    # Format and print the final output\n    print(f\"[{','.join(str(r).capitalize() for r in results)}]\")\n\nsolve()\n```", "id": "2433700"}]}