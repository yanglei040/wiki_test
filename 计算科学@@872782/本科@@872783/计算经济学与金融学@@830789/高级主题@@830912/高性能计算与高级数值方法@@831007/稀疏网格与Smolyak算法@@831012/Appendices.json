{"hands_on_practices": [{"introduction": "理论是基础，但真正的理解来自于实践。在处理金融中的高维问题，如多资产期权定价时，“维度灾难”是一个无法回避的挑战。这项练习将指导你将期望估值问题转化为一个高斯-赫尔米特（Gaussian-Hermite）求积问题，并亲手构建一个完整的张量积网格和一个Smolyak稀疏网格。通过直接比较两者的计算成本和精度 [@problem_id:2396782]，你将深刻体会到稀疏网格在高维积分中的强大优势。", "problem": "考虑一个基于风险中性 Black–Scholes 框架的，由 $d$ 种风险资产组成的资产篮子上的欧式看涨期权。令 $S_i(0)$ 表示资产 $i$ 的初始价格，$r$ 为恒定无风险利率，$\\sigma_i$ 为资产 $i$ 的波动率，$T$ 为到期时间。在风险中性测度下，资产 $i$ 的到期价格由下式给出\n$$\nS_i(T) = S_i(0)\\,\\exp\\!\\Big( \\big(r - \\tfrac{1}{2}\\sigma_i^2\\big)T + \\sigma_i \\sqrt{T}\\, Z_i \\Big),\n$$\n其中 $Z_i$ 是相互独立标准正态随机变量。该篮子看涨期权的收益为\n$$\n\\Pi = \\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(T) - K,\\, 0\\Big),\n$$\n执行价格为 $K$。$0$ 时刻的无套利价格为\n$$\nV_0 = e^{-rT}\\,\\mathbb{E}\\big[\\Pi\\big].\n$$\n\n您的任务是使用高斯求积法对 $d=5$ 的情况下的 $V_0$ 进行近似，并通过比较完全张量积高斯求积与基于相同一维规则构建的 Smolyak 稀疏网格，来数值化地展示维数灾难。\n\n您必须从第一性原理出发，将标准正态分布下的 $d$ 维期望转化为高斯-埃尔米特(Gaussian–Hermite)求积。回顾一维 $n$ 阶高斯-埃尔米特求积法则，\n$$\n\\int_{-\\infty}^{\\infty} e^{-x^2} f(x)\\,dx \\approx \\sum_{j=1}^{n} w_j f(x_j),\n$$\n其中 $x_j$ 是节点，$w_j$ 是权重。证明对于一个标准正态随机变量 $Z$，\n$$\n\\mathbb{E}[g(Z)] = \\frac{1}{\\sqrt{\\pi}}\\int_{-\\infty}^{\\infty} e^{-x^2}\\, g\\!\\big(\\sqrt{2}\\,x\\big)\\,dx,\n$$\n并将其推广到 $d$ 个独立的标准正态变量，以证明使用一维高斯-埃尔米特法则的 $d$ 维张量积是合理的。基于此，生成：\n\n- 一个每维有 $n$ 个节点（总节点数为 $n^d$）的 $d$ 维张量积高斯-埃尔米特求积。\n- 一个由相同的一维高斯-埃尔米特法则族 $\\{Q_\\ell\\}_{\\ell \\ge 1}$ 构建的各向同性水平为 $L$ 的 Smolyak 稀疏网格，其中一维阶数为 $m(\\ell) = 2\\ell - 1$。使用具有以下索引集的 Smolyak 组合公式\n$$\n\\mathcal{I}(L,d) = \\big\\{\\boldsymbol{\\ell}\\in \\mathbb{N}^d : 1 \\le \\ell_k, \\ \\ |\\boldsymbol{\\ell}|_1 \\le L + d - 1 \\big\\},\n$$\n以及系数\n$$\nc(\\boldsymbol{\\ell}) = (-1)^{L + d - 1 - |\\boldsymbol{\\ell}|_1}\\binom{d-1}{L + d - 1 - |\\boldsymbol{\\ell}|_1}.\n$$\n此处 $Q_{\\ell}$ 表示阶数为 $m(\\ell)$ 的一维高斯-埃尔米特法则，而 $d$ 维算子是张量积 $\\bigotimes_{k=1}^d Q_{\\ell_k}$。\n\n基于以上基础，设计一个算法：\n- 通过在每个维度上进行变量替换 $z = \\sqrt{2}\\,x$，将期望映射到高斯-埃尔米特加权积分。\n- 对 $d$ 维情况正确应用归一化因子 $\\pi^{-d/2}$。\n- 构建张量网格和 Smolyak 稀疏网格，并在所有必需的节点上评估贴现后的收益。\n- 计算每种方法的函数求值次数，作为计算成本的代理指标。\n\n测试套件。实现以下两个计算测试用例和一个比较任务：\n\n- 用例 A (正常路径, $d=5$):\n  - 参数: $S_0 = (100,\\, 90,\\, 110,\\, 95,\\, 105)$, $\\sigma = (0.2,\\, 0.25,\\, 0.15,\\, 0.3,\\, 0.18)$, $r = 0.02$, $T = 1.0$, $K = 100$。\n  - 每维 $n=3$ 个节点的张量积高斯-埃尔米特求积。\n  - 各向同性水平 $L=3$ 且一维阶数 $m(\\ell) = 2\\ell - 1$ 的 Smolyak 稀疏网格。\n  - 一个通过每维 $n_{\\text{ref}}=9$ 个节点的张量积高斯-埃尔米特求积计算的高精度参考值。\n  - 需要计算的输出：\n    - 张量积近似值相对于参考值的绝对误差（浮点数）。\n    - 稀疏网格近似值相对于参考值的绝对误差（浮点数）。\n    - 张量积的节点数（整数）。\n    - 稀疏网格的节点数（整数），取 Smolyak 组合中所有组成项的张量积大小之和。\n\n- 用例 B (零波动率的边界条件, $d=5$):\n  - 参数: 与用例 A 相同的 $S_0$, $r$, $T$, $K$，但 $\\sigma = (0,\\,0,\\,0,\\,0,\\,0)$。\n  - 精确价格由确定性值给出\n    $$\n    V_0^{\\text{det}} = e^{-rT}\\,\\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(0)\\,e^{rT} - K,\\, 0\\Big) = \\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(0) - K e^{-rT},\\, 0\\Big).\n    $$\n  - 验证 $n=3$ 的张量积求积和 $L=3$ 的稀疏网格计算结果是否都在 $10^{-10}$ 的绝对容差内与 $V_0^{\\text{det}}$ 匹配。输出一个布尔值，指示两者是否都通过测试。\n\n- 效率比较：\n  - 对于用例 A，输出一个布尔值，指示稀疏网格是否在节点数严格少于张量积的情况下，达到了小于或等于张量积的绝对误差。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。列表条目必须按顺序为：\n- 用例 A 的张量积绝对误差（浮点数）。\n- 用例 A 的稀疏网格绝对误差（浮点数）。\n- 用例 A 的张量积节点数（整数）。\n- 用例 A 的稀疏网格节点数（整数）。\n- 用例 B 的边界条件检查（布尔值）。\n- 用例 A 的效率比较检查（布尔值）。\n\n例如，输出格式必须为\n$$\n[\\text{err\\_tensor},\\text{err\\_sparse},\\text{nodes\\_tensor},\\text{nodes\\_sparse},\\text{boundary\\_ok},\\text{efficiency\\_ok}],\n$$\n其中两个误差为十进制数，两个节点数为整数，最后两个条目为布尔值。不应打印任何额外文本。", "solution": "我们从欧式衍生品的风险中性定价原理开始：在 $T$ 时刻收益为 $\\Pi$ 的产品，其 $0$ 时刻价格 $V_0$ 由 $V_0 = e^{-rT}\\,\\mathbb{E}[\\Pi]$ 给出，其中期望是在风险中性测度下计算的。在具有独立标准正态变量 $Z_i \\sim \\mathcal{N}(0,1)$ 的 Black–Scholes 框架中，到期资产价值为\n$$\nS_i(T) = S_i(0)\\,\\exp\\!\\Big( \\big(r - \\tfrac{1}{2}\\sigma_i^2\\big)T + \\sigma_i \\sqrt{T}\\, Z_i \\Big),\n$$\n篮子看涨期权的收益为\n$$\n\\Pi = \\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(T) - K,\\, 0\\Big).\n$$\n因此，\n$$\nV_0 = e^{-rT}\\,\\mathbb{E}\\left[\\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(0)\\,\\exp\\!\\big( \\big(r - \\tfrac{1}{2}\\sigma_i^2\\big)T + \\sigma_i \\sqrt{T}\\, Z_i \\big) - K,\\, 0\\Big)\\right].\n$$\n\n为了与高斯-埃尔米特求积联系起来，我们将标准正态定律下的期望转换为带有高斯-埃尔米特权重的积分。对于单个标准正态随机变量 $Z \\sim \\mathcal{N}(0,1)$ 和一个合适的测试函数 $g$，我们有\n$$\n\\mathbb{E}[g(Z)] = \\int_{-\\infty}^{\\infty} \\frac{1}{\\sqrt{2\\pi}} e^{-z^2/2} g(z)\\,dz.\n$$\n通过变量替换 $z = \\sqrt{2}\\,x$（因此 $dz = \\sqrt{2}\\,dx$），可以得到\n$$\n\\mathbb{E}[g(Z)] = \\frac{1}{\\sqrt{2\\pi}} \\int_{-\\infty}^{\\infty} e^{-(\\sqrt{2}x)^2/2} g(\\sqrt{2}x)\\,\\sqrt{2}\\,dx = \\frac{1}{\\sqrt{\\pi}}\\int_{-\\infty}^{\\infty} e^{-x^2} g(\\sqrt{2}\\,x)\\,dx.\n$$\n在 $d$ 维空间中，对于独立标准正态变量 $\\boldsymbol{Z} = (Z_1,\\dots,Z_d)$，其联合密度可以分解，通过逐分量应用变量替换，我们得到\n$$\n\\mathbb{E}[g(\\boldsymbol{Z})] = \\frac{1}{\\pi^{d/2}} \\int_{\\mathbb{R}^d} e^{-\\|\\boldsymbol{x}\\|_2^2}\\, g(\\sqrt{2}\\,\\boldsymbol{x})\\, d\\boldsymbol{x}.\n$$\n因此，$d$ 维高斯-埃尔米特张量积求积可得\n$$\n\\mathbb{E}[g(\\boldsymbol{Z})] \\approx \\frac{1}{\\pi^{d/2}} \\sum_{j_1=1}^{n}\\cdots \\sum_{j_d=1}^{n} \\Big(\\prod_{k=1}^{d} w_{j_k}\\Big)\\, g\\!\\Big(\\sqrt{2}\\,x_{j_1},\\dots,\\sqrt{2}\\,x_{j_d}\\Big),\n$$\n其中 $(x_{j},w_{j})$ 是与权重 $e^{-x^2}$ 相关联的 $n$ 阶一维高斯-埃尔米特节点和权重。\n\n将此应用于篮子期权的收益，我们定义\n$$\ng(\\boldsymbol{z}) = \\max\\!\\Big(\\frac{1}{d}\\sum_{i=1}^{d} S_i(0)\\,\\exp\\!\\big( \\big(r - \\tfrac{1}{2}\\sigma_i^2\\big)T + \\sigma_i \\sqrt{T}\\, z_i \\big) - K,\\, 0\\Big),\n$$\n价格的近似值为\n$$\nV_0 \\approx e^{-rT}\\,\\frac{1}{\\pi^{d/2}} \\sum_{j_1=1}^{n}\\cdots \\sum_{j_d=1}^{n} \\Big(\\prod_{k=1}^{d} w_{j_k}\\Big)\\, g\\!\\Big(\\sqrt{2}\\,x_{j_1},\\dots,\\sqrt{2}\\,x_{j_d}\\Big).\n$$\n\n这个张量积法则需要 $n^d$ 次函数求值。对于 $d=5$，节点数以 $n^5$ 的速度增长，这是维数灾难的一种表现：即使 $n$ 的适度增加也会导致成本的指数级增长。\n\n为了缓解这个问题，我们考虑一个由相同的一维高斯-埃尔米特法则族构建的 Smolyak 稀疏网格。令 $Q_{\\ell}$ 表示水平 $\\ell \\in \\mathbb{N}$ 的阶数为 $m(\\ell)=2\\ell-1$ 的一维高斯-埃尔米特求积。对于 $d$ 维空间中的各向同性水平 $L \\in \\mathbb{N}$，Smolyak 算子为\n$$\nA(L,d) = \\sum_{\\boldsymbol{\\ell}\\in \\mathcal{I}(L,d)} c(\\boldsymbol{\\ell}) \\bigotimes_{k=1}^{d} Q_{\\ell_k},\n$$\n其索引集为\n$$\n\\mathcal{I}(L,d) = \\big\\{\\boldsymbol{\\ell}\\in \\mathbb{N}^d : 1 \\le \\ell_k,\\ \\ |\\boldsymbol{\\ell}|_1 \\le L + d - 1\\big\\},\n$$\n组合系数为\n$$\nc(\\boldsymbol{\\ell}) = (-1)^{L + d - 1 - |\\boldsymbol{\\ell}|_1}\\binom{d-1}{L + d - 1 - |\\boldsymbol{\\ell}|_1}.\n$$\n由此得到的期望的稀疏网格近似为\n$$\n\\mathbb{E}[g(\\boldsymbol{Z})] \\approx \\frac{1}{\\pi^{d/2}} \\sum_{\\boldsymbol{\\ell}\\in \\mathcal{I}(L,d)} c(\\boldsymbol{\\ell}) \\sum_{j_1=1}^{m(\\ell_1)} \\cdots \\sum_{j_d=1}^{m(\\ell_d)} \\left(\\prod_{k=1}^{d} w_{j_k}^{(\\ell_k)}\\right) g\\!\\Big(\\sqrt{2}\\,x_{j_1}^{(\\ell_1)},\\dots,\\sqrt{2}\\,x_{j_d}^{(\\ell_d)}\\Big),\n$$\n其中 $(x_j^{(\\ell)}, w_j^{(\\ell)})$ 是阶数为 $m(\\ell)$ 的一维高斯-埃尔മി特节点和权重。请注意，这种组合利用了与张量积相同的一维法则，但通过 Smolyak 系数混合了不同阶数的张量积。计算成本是所有 $\\boldsymbol{\\ell} \\in \\mathcal{I}(L,d)$ 的张量积大小 $\\prod_{k=1}^d m(\\ell_k)$ 的总和；在可比的精度下，该成本随 $d$ 的增长比 $n^d$ 更为平缓。\n\n算法设计：\n\n- 通过一个稳定的正交多项式生成器，预先计算所有所需阶数的一维高斯-埃尔米特节点和权重。这些节点和权重能够精确积分最高 $2n-1$ 次的多项式乘以 $e^{-x^2}$，并且权重之和等于 $\\sqrt{\\pi}$，从而确保了对常数被积函数的精确性。\n- 通过形成一维节点和权重的笛卡尔积，应用 $\\sqrt{2}$ 缩放以映射到标准正态变量，并乘以权重乘积来实现张量积求积。将累加和乘以 $\\pi^{-d/2}$ 和 $e^{-rT}$。\n- 通过遍历 $\\mathcal{I}(L,d)$ 中的所有多重索引 $\\boldsymbol{\\ell}$，计算组合系数 $c(\\boldsymbol{\\ell})$，对每个 $\\boldsymbol{\\ell}$ 使用第 $k$ 维的 $m(\\ell_k)$ 个点形成张量网格，使用相同的归一化因子评估并累加加权贡献，来实现 Smolyak 稀疏网格。将计算工作量计为所有 $\\boldsymbol{\\ell}$ 的张量大小之和。\n- 对于 $\\sigma_i=0$ 的边界情况，到期价格是确定性的，$S_i(T) = S_i(0)e^{rT}$，因此精确价格为 $V_0^{\\text{det}} = \\max\\!\\big(\\frac{1}{d}\\sum_i S_i(0) - K e^{-rT}, 0\\big)$。由于高斯-埃尔米特法则能精确积分常数，张量积和稀疏网格的近似值都应与该值匹配，误差仅限于舍入误差。\n\n测试套件实现：\n\n- 用例 A: $d=5$, $S_0=(100,90,110,95,105)$, $\\sigma=(0.2,0.25,0.15,0.3,0.18)$, $r=0.02$, $T=1.0$, $K=100$。计算：\n  - 使用张量积 $n_{\\text{ref}}=9$ 的参考值。\n  - 使用张量积 $n=3$；记录绝对误差和节点数 $3^5$。\n  - 使用 $L=3$ 和 $m(\\ell)=2\\ell-1$ 的 Smolyak 方法；记录相对于参考值的绝对误差以及作为 $\\mathcal{I}(L,d)$ 上张量大小总和的稀疏网格节点数。\n- 用例 B: 与用例 A 相同，但 $\\sigma=\\boldsymbol{0}$。验证 $n=3$ 的张量积和 $L=3$ 的稀疏网格结果是否都在 $V_0^{\\text{det}}$ 的 $10^{-10}$ 容差范围内。\n- 效率比较：对于用例 A，检查稀疏网格是否在节点数严格少于张量积的情况下，达到了小于或等于张量积的误差。\n\n程序将生成单行输出：\n$[\\text{err\\_tensor},\\text{err\\_sparse},\\text{nodes\\_tensor},\\text{nodes\\_sparse},\\text{boundary\\_ok},\\text{efficiency\\_ok}]$,\n其中条目如上定义。此设计通过张量网格的 $n^5$ 缩放展示了维数灾难，并将其与 Smolyak 稀疏网格进行对比，后者对于相同的一维高斯-埃尔米特法则族，能够以显著更少的函数求值次数达到具有竞争力的精度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom numpy.polynomial.hermite import hermgauss\nimport math\nfrom itertools import product\n\ndef gh_rule(n):\n    # One-dimensional Gauss-Hermite nodes and weights for weight e^{-x^2}\n    x, w = hermgauss(n)\n    return x, w\n\ndef basket_payoff(Z, S0, sigmas, r, T, K):\n    # Z: shape (N, d)\n    d = Z.shape[1]\n    S0 = np.asarray(S0, dtype=float)\n    sigmas = np.asarray(sigmas, dtype=float)\n    mu = (r - 0.5 * sigmas**2) * T\n    sgsqrtT = sigmas * math.sqrt(T)\n    # exponent per point and dimension\n    exponents = mu + sgsqrtT * Z  # shape (N, d)\n    ST = S0 * np.exp(exponents)   # broadcasting over (N, d)\n    avg = np.mean(ST, axis=1)\n    payoff = np.maximum(avg - K, 0.0)\n    return payoff\n\ndef tensor_gauss_hermite_price(S0, sigmas, r, T, K, n):\n    d = len(S0)\n    x, w = gh_rule(n)\n    # Build tensor grid via meshgrid\n    grids_x = np.meshgrid(*([x]*d), indexing='ij')\n    grids_w = np.meshgrid(*([w]*d), indexing='ij')\n    # Flatten\n    X_cols = [g.ravel() for g in grids_x]  # list length d, each shape (n**d,)\n    W_arrays = [gw.ravel() for gw in grids_w]\n    # Product weights\n    W_prod = np.ones_like(W_arrays[0])\n    for Wa in W_arrays:\n        W_prod *= Wa\n    # Map to standard normals: Z = sqrt(2) * x\n    Z = np.sqrt(2.0) * np.column_stack(X_cols)  # shape (N, d)\n    payoff = basket_payoff(Z, S0, sigmas, r, T, K)\n    # Normalization factor for d-dim expectation\n    factor = math.pi ** (-d / 2.0)\n    expectation = factor * np.sum(W_prod * payoff)\n    price = math.exp(-r * T) * expectation\n    nodes = n ** d\n    return price, nodes\n\ndef generate_multi_indices_sum_d(s, d, min_level=1):\n    # Generate all tuples of length d of positive integers >= min_level with sum s\n    # Use recursive backtracking\n    result = []\n    def backtrack(prefix, remaining, k):\n        if k == d - 1:\n            last = remaining\n            if last >= min_level:\n                result.append(tuple(prefix + [last]))\n            return\n        # Each component at least min_level\n        min_val = min_level\n        # Remaining must allow at least min_level for remaining dims\n        max_val = remaining - (d - k - 1) * min_level\n        for val in range(min_val, max_val + 1):\n            backtrack(prefix + [val], remaining - val, k + 1)\n    backtrack([], s, 0)\n    return result\n\ndef smolyak_sparse_price(S0, sigmas, r, T, K, L):\n    d = len(S0)\n    # Precompute 1D rules for levels 1..(L + d - 1) because indices can reach that in sum, but each component level is bounded by sum\n    # However, for efficiency we build on demand and cache by level\n    rule_cache = {}\n    def one_d_rule_for_level(level):\n        if level not in rule_cache:\n            n = 2 * level - 1\n            rule_cache[level] = gh_rule(n)\n        return rule_cache[level]\n\n    total_nodes_cost = 0\n    factor = math.pi ** (-d / 2.0)\n    acc = 0.0\n    # Iterate sums s from d to L + d - 1\n    for s in range(d, L + d):\n        # Binomial coefficient for all multi-indices with |ell|_1 = s\n        comb_coeff = math.comb(d - 1, L + d - 1 - s)\n        sign = -1 if ((L + d - 1 - s) % 2 == 1) else 1\n        c_s = sign * comb_coeff\n        if c_s == 0:\n            continue\n        # All multi-indices with sum s\n        for ell in generate_multi_indices_sum_d(s, d, min_level=1):\n            # Build per-dimension nodes and weights at levels in ell\n            x_list = []\n            w_list = []\n            n_points_list = []\n            for lev in ell:\n                xk, wk = one_d_rule_for_level(lev)\n                x_list.append(xk)\n                w_list.append(wk)\n                n_points_list.append(len(xk))\n            # Tensor product for this multi-index\n            grids_x = np.meshgrid(*x_list, indexing='ij')\n            grids_w = np.meshgrid(*w_list, indexing='ij')\n            # Flatten\n            X_cols = [g.ravel() for g in grids_x]\n            W_arrays = [gw.ravel() for gw in grids_w]\n            # Product weights\n            W_prod = np.ones_like(W_arrays[0])\n            for Wa in W_arrays:\n                W_prod *= Wa\n            # Map to Z\n            Z = np.sqrt(2.0) * np.column_stack(X_cols)\n            payoff = basket_payoff(Z, S0, sigmas, r, T, K)\n            contrib = factor * np.sum(W_prod * payoff)\n            acc += c_s * contrib\n            # Cost accumulation: number of nodes in this tensor product\n            nodes_this = 1\n            for npt in n_points_list:\n                nodes_this *= npt\n            total_nodes_cost += nodes_this\n    price = math.exp(-r * T) * acc\n    return price, total_nodes_cost\n\ndef solve():\n    # Define the test cases from the problem statement.\n\n    # Case A parameters\n    S0 = [100.0, 90.0, 110.0, 95.0, 105.0]\n    sigmas_A = [0.2, 0.25, 0.15, 0.3, 0.18]\n    r = 0.02\n    T = 1.0\n    K = 100.0\n    d = len(S0)\n\n    # Reference with tensor n_ref=9\n    price_ref, nodes_ref = tensor_gauss_hermite_price(S0, sigmas_A, r, T, K, n=9)\n\n    # Tensor with n=3\n    price_tensor, nodes_tensor = tensor_gauss_hermite_price(S0, sigmas_A, r, T, K, n=3)\n    err_tensor = abs(price_tensor - price_ref)\n\n    # Sparse grid with L=3\n    price_sparse, nodes_sparse = smolyak_sparse_price(S0, sigmas_A, r, T, K, L=3)\n    err_sparse = abs(price_sparse - price_ref)\n\n    # Case B: zero volatility boundary\n    sigmas_B = [0.0, 0.0, 0.0, 0.0, 0.0]\n    # Deterministic price\n    mean_S0 = sum(S0) / d\n    price_det = max(mean_S0 - K * math.exp(-r * T), 0.0)\n\n    price_tensor_B, _ = tensor_gauss_hermite_price(S0, sigmas_B, r, T, K, n=3)\n    price_sparse_B, _ = smolyak_sparse_price(S0, sigmas_B, r, T, K, L=3)\n\n    tol = 1e-10\n    boundary_ok = (abs(price_tensor_B - price_det) = tol) and (abs(price_sparse_B - price_det) = tol)\n\n    # Efficiency comparison for Case A\n    efficiency_ok = (err_sparse = err_tensor) and (nodes_sparse  nodes_tensor)\n\n    results = [\n        float(err_tensor),\n        float(err_sparse),\n        int(nodes_tensor),\n        int(nodes_sparse),\n        bool(boundary_ok),\n        bool(efficiency_ok),\n    ]\n\n    # Final print statement in the exact required format.\n    # Ensure default Python representation for floats and booleans.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2396782"}, {"introduction": "各向异性网格要求我们对函数结构有先验知识，但如果这种知识难以获得呢？自适应稀疏网格提供了一个强大的全自动解决方案。在此练习中，你将实现一个自适应算法，该算法使用分层残差（hierarchical surpluses）作为误差指标，动态地在函数变化剧烈或不光滑的区域加密网格。通过解决一系列具有挑战性的测试用例，包括局部特征和非光滑函数 [@problem_id:2432623]，你将掌握一种能够“学习”函数特性并自动构建优化网格的尖端技术。", "problem": "您的任务是使用基于 Smolyak 构造的各向异性稀疏网格来逼近超立方体上的高维函数。定义域为单位超立方体 $[0,1]^{10}$。令 $d = 10$。对于每个维度 $i \\in \\{1,\\dots,d\\}$ 和每个层级 $\\ell_i \\in \\mathbb{N}$（其中 $\\ell_i \\ge 1$），定义一维嵌套二进网格\n$$\nX_{\\ell_i} = \\left\\{ \\frac{j}{2^{\\ell_i - 1}} \\,:\\, j = 0,1,\\dots,2^{\\ell_i - 1} \\right\\} \\subset [0,1].\n$$\n对于一个多重指标 $\\boldsymbol{\\ell} = (\\ell_1,\\dots,\\ell_d)$，定义全张量网格\n$$\nG_{\\boldsymbol{\\ell}} = X_{\\ell_1} \\times \\cdots \\times X_{\\ell_d}.\n$$\n令 $U_{\\boldsymbol{\\ell}}$ 为 $G_{\\boldsymbol{\\ell}}$ 上的 $d$ 元多线性节点插值算子，其定义为二进网格上的一维线性拉格朗日基函数的张量积。\n\n令 $\\boldsymbol{\\alpha} = (\\alpha_1,\\dots,\\alpha_d)$ 为一个正整数各向异性权重向量，并令 $Q \\in \\mathbb{N}$ 且 $Q \\ge 0$。定义向下闭合的指标集\n$$\n\\mathcal{I}(\\boldsymbol{\\alpha}, Q) = \\left\\{ \\boldsymbol{\\ell} \\in \\mathbb{N}^d \\,:\\, \\ell_i \\ge 1 \\text{ for all } i, \\ \\sum_{i=1}^d \\alpha_i (\\ell_i - 1) \\le Q \\right\\}.\n$$\n考虑全网格插值算子的线性组合\n$$\n\\mathcal{S}_{\\boldsymbol{\\alpha},Q} = \\sum_{\\boldsymbol{\\ell} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q)} c_{\\boldsymbol{\\ell}} \\, U_{\\boldsymbol{\\ell}},\n$$\n其中系数 $\\{c_{\\boldsymbol{\\ell}}\\}$ 由插值一致性条件所刻画\n$$\n\\sum_{\\boldsymbol{k} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q), \\, \\boldsymbol{k} \\ge \\boldsymbol{\\ell}} c_{\\boldsymbol{k}} = 1 \\quad \\text{for every } \\boldsymbol{\\ell} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q),\n$$\n其中 $\\boldsymbol{k} \\ge \\boldsymbol{\\ell}$ 表示分量偏序，即对所有 $i$ 都有 $k_i \\ge \\ell_i$。此条件确保 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$ 在 $\\bigcup_{\\boldsymbol{\\ell} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q)} G_{\\boldsymbol{\\ell}}$ 中的每个节点上都对目标函数进行插值。\n\n您的程序必须在 $[0,1]^{10}$ 上实现 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$，并在指定的点上对其进行求值。使用以下两个目标函数，每个函数都针对 $\\boldsymbol{x} = (x_1,\\dots,x_{10}) \\in [0,1]^{10}$ 定义：\n- $f_1(\\boldsymbol{x}) = \\exp(x_1) + \\sin(2\\pi x_2) + 0.1 \\sum_{i=3}^{10} 0.5^{\\,i} \\, x_i^2$。\n- $f_2(\\boldsymbol{x}) = \\log(1 + 5 x_1) + \\sqrt{1 + x_2} + 0.01 \\sum_{i=3}^{10} x_i$。\n所有三角函数参数都应解释为弧度。自然对数函数为 $\\log(\\cdot)$，主平方根为 $\\sqrt{\\cdot}$。\n\n使用以下求值集合 $\\mathcal{E} = \\{\\boldsymbol{y}^{(k)}\\}_{k=1}^{5} \\subset [0,1]^{10}$，其中每个 $\\boldsymbol{y}^{(k)}$ 都明确给出：\n- $\\boldsymbol{y}^{(1)} = (0.13,\\,0.77,\\,0.50,\\,0.20,\\,0.80,\\,0.33,\\,0.66,\\,0.10,\\,0.90,\\,0.42)$,\n- $\\boldsymbol{y}^{(2)} = (0.31,\\,0.62,\\,0.25,\\,0.75,\\,0.40,\\,0.60,\\,0.20,\\,0.80,\\,0.35,\\,0.65)$,\n- $\\boldsymbol{y}^{(3)} = (0.73,\\,0.27,\\,0.15,\\,0.85,\\,0.55,\\,0.45,\\,0.05,\\,0.95,\\,0.22,\\,0.78)$,\n- $\\boldsymbol{y}^{(4)} = (0.50,\\,0.50,\\,0.10,\\,0.90,\\,0.30,\\,0.70,\\,0.25,\\,0.75,\\,0.40,\\,0.60)$,\n- $\\boldsymbol{y}^{(5)} = (0.21,\\,0.84,\\,0.63,\\,0.37,\\,0.12,\\,0.88,\\,0.47,\\,0.53,\\,0.19,\\,0.81)$.\n\n将偏向于前两个维度的各向异性权重定义为\n$$\n\\boldsymbol{\\alpha}^{\\mathrm{aniso}} = (1,\\,1,\\,4,\\,4,\\,4,\\,4,\\,4,\\,4,\\,4,\\,4),\n$$\n以及将各向同性权重定义为\n$$\n\\boldsymbol{\\alpha}^{\\mathrm{iso}} = (1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1,\\,1).\n$$\n\n测试套件。您的程序必须执行以下四个测试用例，并为每个用例报告一个标量结果：\n- 测试 1：使用 $\\boldsymbol{\\alpha} = \\boldsymbol{\\alpha}^{\\mathrm{aniso}}$ 和 $Q=8$ 为 $f_1$ 构建 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$。计算在 $\\mathcal{E}$ 上的最大绝对误差，\n$$\n\\max_{\\boldsymbol{y} \\in \\mathcal{E}} \\left| \\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f_1](\\boldsymbol{y}) - f_1(\\boldsymbol{y}) \\right|.\n$$\n- 测试 2：使用 $\\boldsymbol{\\alpha} = \\boldsymbol{\\alpha}^{\\mathrm{iso}}$ 和 $Q=3$ 为 $f_1$ 构建 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$。计算在 $\\mathcal{E}$ 上的最大绝对误差。\n- 测试 3：使用 $\\boldsymbol{\\alpha} = \\boldsymbol{\\alpha}^{\\mathrm{aniso}}$ 和 $Q=6$ 为 $f_2$ 构建 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$。计算在 $\\mathcal{E}$ 上的最大绝对误差。\n- 测试 4：使用 $\\boldsymbol{\\alpha} = \\boldsymbol{\\alpha}^{\\mathrm{aniso}}$ 和 $Q=8$ 为 $f_1$ 构建 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}$。计算在单点 $\\boldsymbol{0} = (0,0,0,0,0,0,0,0,0,0)$ 处的绝对误差，\n$$\n\\left| \\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f_1](\\boldsymbol{0}) - f_1(\\boldsymbol{0}) \\right|.\n$$\n\n最终输出格式。您的程序应生成单行输出，其中包含按顺序排列的四个结果，以逗号分隔并用方括号括起来，例如\n$$\n[{\\tt r1},{\\tt r2},{\\tt r3},{\\tt r4}],\n$$\n其中每个 ${\\tt rj}$ 是一个实数（一个浮点值）。", "solution": "用户提供了一个定义明确的数值分析问题，具体涉及使用各向异性稀疏网格逼近高维函数。该问题具有科学依据，内部逻辑一致，并包含了解决该问题所需的所有信息。因此，我将着手提供一个完整的解决方案。\n\n核心任务是在指定点 $\\boldsymbol{y} \\in [0,1]^{10}$ 上计算稀疏网格插值 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f]$ 的值。该插值使用组合技术公式定义：\n$$\n\\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f](\\boldsymbol{y}) = \\sum_{\\boldsymbol{\\ell} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q)} c_{\\boldsymbol{\\ell}} \\, U_{\\boldsymbol{\\ell}}[f](\\boldsymbol{y})\n$$\n其中 $f$ 是目标函数，$\\boldsymbol{y}$ 是一个求值点，$\\mathcal{I}(\\boldsymbol{\\alpha}, Q)$ 是一个向下闭合的多重指标集，$c_{\\boldsymbol{\\ell}}$ 是组合系数，$U_{\\boldsymbol{\\ell}}[f](\\boldsymbol{y})$ 是一个全张量积多线性插值式的值。\n\n对于每个测试用例，该解决方案通过一系列模块化步骤实现：\n1.  **生成指标集**：构建集合 $\\mathcal{I}(\\boldsymbol{\\alpha}, Q) = \\left\\{ \\boldsymbol{\\ell} \\in \\mathbb{N}^d \\,:\\, \\ell_i \\ge 1, \\ \\sum_{i=1}^d \\alpha_i (\\ell_i - 1) \\le Q \\right\\}$。为了高效地实现这一点，我们定义层级向量 $\\boldsymbol{k} = (\\ell_1-1, \\dots, \\ell_d-1)$，其中每个 $k_i \\ge 0$。条件变为 $\\sum_{i=1}^d \\alpha_i k_i \\le Q$。采用递归回溯算法来查找满足此不等式的所有有效向量 $\\boldsymbol{k} \\in \\mathbb{N}_0^d$。对应的多重指标 $\\boldsymbol{\\ell} = \\boldsymbol{k} + \\mathbf{1}$ 构成了集合 $\\mathcal{I}(\\boldsymbol{\\alpha}, Q)$。该集合存储在哈希集中以便进行高效查找。\n\n2.  **计算组合系数**：系数 $c_{\\boldsymbol{\\ell}}$ 由确保算子具有插值性的一致性条件确定。对于一个向下闭合的指标集 $\\mathcal{I}$，此条件意味着 $c_{\\boldsymbol{\\ell}}$ 有一个由容斥原理给出的唯一解：\n    $$\n    c_{\\boldsymbol{\\ell}} = \\sum_{J \\subseteq \\{1, \\dots, d\\}} (-1)^{|J|} \\mathbb{I}(\\boldsymbol{\\ell} + \\mathbf{e}_J \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q))\n    $$\n    其中 $\\mathbf{e}_J = \\sum_{j \\in J} \\mathbf{e}_j$，而 $\\mathbf{e}_j$ 是第 $j$ 个标准基向量。$\\mathbb{I}(\\cdot)$ 是指示函数，如果条件成立则为 $1$，否则为 $0$。对于每个 $\\boldsymbol{\\ell} \\in \\mathcal{I}$，我们遍历维度的所有 $2^d$ 个子集 $J$，检查相邻指标 $\\boldsymbol{\\ell}+\\mathbf{e}_J$ 是否在 $\\mathcal{I}$ 中，并对带符号的贡献求和。对于 $d=10$，每个系数需要进行 $2^{10} = 1024$ 次检查，这在计算上是可行的。\n\n3.  **全张量积插值求值**：项 $U_{\\boldsymbol{\\ell}}[f](\\boldsymbol{y})$ 表示在点 $\\boldsymbol{y}$ 处对全张量网格 $G_{\\boldsymbol{\\ell}} = X_{\\ell_1} \\times \\cdots \\times X_{\\ell_d}$ 上的多线性插值进行求值。这是通过递归实现的。$d$ 维插值的值是通过在第一个维度上执行一维线性插值获得的，其中两个所需网格点上的值本身是通过在剩余变量中进行 $(d-1)$ 维插值计算得出的。这个过程在 $d$ 步后终止，需要在 $G_{\\boldsymbol{\\ell}}$ 中包围 $\\boldsymbol{y}$ 的超矩形单元的 $2^d$ 个角点上进行函数求值。\n\n4.  **通过记忆化进行优化**：由于冗余计算，一个朴素的实现方式在计算上是不可行的。对于不同的 $\\boldsymbol{\\ell}$，$U_{\\boldsymbol{\\ell}}[f](\\boldsymbol{y})$ 的求值会重复需要在相同网格点上 $f$ 的值。为了消除这种冗余，所有的函数求值 $f(\\boldsymbol{x})$ 都被记忆化（缓存）在一个字典中。当需要特定网格点 $\\boldsymbol{x}$ 上的 $f$ 值时，会首先检查缓存，只有在之前没有计算过该值时才进行函数求值。\n\n5.  **组装与误差计算**：对于每个测试用例和每个求值点 $\\boldsymbol{y}$，通过对所有 $\\boldsymbol{\\ell} \\in \\mathcal{I}(\\boldsymbol{\\alpha}, Q)$ 的贡献 $c_{\\boldsymbol{\\ell}} U_{\\boldsymbol{\\ell}}[f](\\boldsymbol{y})$求和来组装最终的逼近值。然后计算绝对误差为 $|\\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f](\\boldsymbol{y}) - f(\\boldsymbol{y})|$。按要求报告在求值集 $\\mathcal{E}$ 上这些误差的最大值。\n\n对于测试用例 4，求值点为 $\\boldsymbol{y} = \\boldsymbol{0} = (0,\\dots,0)$。点 $\\boldsymbol{0}$ 是每个网格 $G_{\\boldsymbol{\\ell}}$ 的成员，因为一维网格 $X_{\\ell_i}$ 总是包含 $0$。稀疏网格构造保证了在稀疏网格并集 $\\mathcal{H}_{\\boldsymbol{\\alpha},Q} = \\bigcup_{\\boldsymbol{\\ell} \\in \\mathcal{I}} G_{\\boldsymbol{\\ell}}$ 中的所有点上都具有插值性。由于 $\\boldsymbol{0} \\in \\mathcal{H}_{\\boldsymbol{\\alpha},Q}$，我们必须有 $\\mathcal{S}_{\\boldsymbol{\\alpha},Q}[f_1](\\boldsymbol{0}) = f_1(\\boldsymbol{0})$，这意味着绝对误差恰好为 $0$。这可以作为对实现正确性的分析性检验。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom itertools import combinations\nimport math\n\ndef solve():\n    \"\"\"\n    Implements and evaluates an anisotropic sparse grid interpolant.\n    \"\"\"\n    d = 10\n\n    # Define target functions\n    def f1(x_tuple):\n        x = np.array(x_tuple)\n        term1 = np.exp(x[0])\n        term2 = np.sin(2 * np.pi * x[1])\n        term3 = 0.1 * np.sum([0.5**(i + 3) * x[i + 2]**2 for i in range(8)])\n        return term1 + term2 + term3\n\n    def f2(x_tuple):\n        x = np.array(x_tuple)\n        term1 = np.log(1 + 5 * x[0])\n        term2 = np.sqrt(1 + x[1])\n        term3 = 0.01 * np.sum(x[2:])\n        return term1 + term2 + term3\n\n    # Define evaluation points\n    evaluation_set = [\n        (0.13, 0.77, 0.50, 0.20, 0.80, 0.33, 0.66, 0.10, 0.90, 0.42),\n        (0.31, 0.62, 0.25, 0.75, 0.40, 0.60, 0.20, 0.80, 0.35, 0.65),\n        (0.73, 0.27, 0.15, 0.85, 0.55, 0.45, 0.05, 0.95, 0.22, 0.78),\n        (0.50, 0.50, 0.10, 0.90, 0.30, 0.70, 0.25, 0.75, 0.40, 0.60),\n        (0.21, 0.84, 0.63, 0.37, 0.12, 0.88, 0.47, 0.53, 0.19, 0.81),\n    ]\n\n    # Define anisotropy weights\n    alpha_aniso = (1, 1, 4, 4, 4, 4, 4, 4, 4, 4)\n    alpha_iso = (1, 1, 1, 1, 1, 1, 1, 1, 1, 1)\n\n    # Define test cases\n    test_cases = [\n        {'f': f1, 'alpha': alpha_aniso, 'Q': 8, 'eval_points': evaluation_set},\n        {'f': f1, 'alpha': alpha_iso,   'Q': 3, 'eval_points': evaluation_set},\n        {'f': f2, 'alpha': alpha_aniso, 'Q': 6, 'eval_points': evaluation_set},\n        {'f': f1, 'alpha': alpha_aniso, 'Q': 8, 'eval_points': [tuple([0.0]*d)]},\n    ]\n\n    memo_indices = {}\n    memo_coeffs = {}\n\n    def generate_indices(alpha, Q):\n        indices = set()\n        k_levels = []\n\n        def find_k(dim_idx, current_sum):\n            if dim_idx == d:\n                indices.add(tuple(k + 1 for k in k_levels))\n                return\n\n            max_k = (Q - current_sum) // alpha[dim_idx]\n            for ki in range(max_k + 1):\n                k_levels.append(ki)\n                find_k(dim_idx + 1, current_sum + alpha[dim_idx] * ki)\n                k_levels.pop()\n        \n        find_k(0, 0)\n        return indices\n\n    def calculate_coeffs(index_set):\n        coeffs = {}\n        e_vectors = np.identity(d, dtype=int)\n        for l_tuple in index_set:\n            l_vec = np.array(l_tuple)\n            c_l = 0\n            for size in range(d + 1):\n                for J in combinations(range(d), size):\n                    l_prime_vec = l_vec.copy()\n                    for j_idx in J:\n                        l_prime_vec[j_idx] += 1\n                    \n                    if tuple(l_prime_vec) in index_set:\n                        c_l += (-1)**size\n            coeffs[l_tuple] = c_l\n        return coeffs\n    \n    def get_interpolant_evaluator(f_func, y_tuple, l_tuple, memo_f):\n        def recursive_eval(dim, partial_point):\n            if dim == d:\n                point = tuple(partial_point)\n                if point not in memo_f:\n                    memo_f[point] = f_func(point)\n                return memo_f[point]\n\n            k = l_tuple[dim]\n            y_i = y_tuple[dim]\n\n            if k == 1:\n                # Grid is {0, 1}\n                weight = y_i\n                if abs(weight)  1e-15: return recursive_eval(dim + 1, partial_point + [0.0])\n                if abs(weight - 1.0)  1e-15: return recursive_eval(dim + 1, partial_point + [1.0])\n                \n                val_left = recursive_eval(dim + 1, partial_point + [0.0])\n                val_right = recursive_eval(dim + 1, partial_point + [1.0])\n                return (1.0 - weight) * val_left + weight * val_right\n            \n            m = 1  (k - 1)\n            \n            if abs(y_i - 1.0)  1e-15:\n                return recursive_eval(dim + 1, partial_point + [1.0])\n\n            pos = y_i * m\n            j = int(pos)\n            weight = pos - j\n\n            left_coord = j / m\n            \n            if weight  1e-15:\n                return recursive_eval(dim + 1, partial_point + [left_coord])\n\n            right_coord = (j + 1) / m\n            \n            val_left = recursive_eval(dim + 1, partial_point + [left_coord])\n            val_right = recursive_eval(dim + 1, partial_point + [right_coord])\n            return (1.0 - weight) * val_left + weight * val_right\n\n        return recursive_eval(0, [])\n\n    results = []\n    for case in test_cases:\n        f_func = case['f']\n        alpha = case['alpha']\n        Q = case['Q']\n        eval_points = case['eval_points']\n        \n        case_key = (alpha, Q)\n        \n        if case_key in memo_indices:\n            index_set = memo_indices[case_key]\n        else:\n            index_set = generate_indices(alpha, Q)\n            memo_indices[case_key] = index_set\n\n        if case_key in memo_coeffs:\n            coeffs = memo_coeffs[case_key]\n        else:\n            coeffs = calculate_coeffs(index_set)\n            memo_coeffs[case_key] = coeffs\n        \n        memo_f = {}\n        max_abs_error = 0.0\n\n        for y_tuple in eval_points:\n            approx_val = 0.0\n            for l_tuple in index_set:\n                c_l = coeffs[l_tuple]\n                if abs(c_l)  1e-15:\n                    continue\n                \n                u_l_f_y = get_interpolant_evaluator(f_func, y_tuple, l_tuple, memo_f)\n                approx_val += c_l * u_l_f_y\n            \n            true_val = f_func(y_tuple)\n            abs_error = abs(approx_val - true_val)\n            \n            if abs_error > max_abs_error:\n                max_abs_error = abs_error\n        \n        results.append(max_abs_error)\n\n    print(f\"[{','.join(f'{r:.12f}' for r in results)}]\")\n\nsolve()\n```", "id": "2432646"}, {"introduction": "各向异性网格要求我们对函数结构有先验知识，但如果这种知识难以获得呢？自适应稀疏网格提供了一个强大的全自动解决方案。在此练习中，你将实现一个自适应算法，该算法使用分层残差（hierarchical surpluses）作为误差指标，动态地在函数变化剧烈或不光滑的区域加密网格。通过解决一系列具有挑战性的测试用例，包括局部特征和非光滑函数 [@problem_id:2432623]，你将掌握一种能够“学习”函数特性并自动构建优化网格的尖端技术。", "problem": "您需要设计并实现一种自适应稀疏网格插值器，该插值器基于 Smolyak 构造，在超立方体域 $[0,1]^d$ 上使用分层、分段线性（帽函数）基。该算法必须以分层盈余系数的大小作为加密指标，自适应地加密网格。您的实现必须是一个完整的、可运行的程序，能够为定义的测试套件计算指定的量化输出。\n\n所需的算法元素必须源自以下基础：\n- 一维分层基的核心定义：对于层级 $l \\in \\mathbb{N}$ 和奇数索引 $i \\in \\{1,3,\\dots,2^l - 1\\}$，定义一维节点 $x_{l,i} = i / 2^l$ 和帽函数基函数\n$$\n\\varphi_{l,i}(x) = \\max\\left(1 - 2^l \\left| x - \\frac{i}{2^l} \\right|, 0\\right).\n$$\n- 多维张量基：对于 $d \\in \\mathbb{N}$，多层级 $\\boldsymbol{l} = (l_1,\\dots,l_d)$ 和多重索引 $\\boldsymbol{i} = (i_1,\\dots,i_d)$，其中每个 $i_j \\in \\{1,3,\\dots,2^{l_j}-1\\}$，节点为 $\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}} = (i_1 2^{-l_1},\\dots,i_d 2^{-l_d})$，基函数分解为\n$$\n\\Phi_{\\boldsymbol{l},\\boldsymbol{i}}(\\boldsymbol{x}) = \\prod_{j=1}^d \\varphi_{l_j,i_j}(x_j).\n$$\n- 分层插值：给定一个多重索引 $(\\boldsymbol{l},\\boldsymbol{i})$ 的集合 $\\mathcal{A}$，插值函数为\n$$\n\\mathcal{I} f(\\boldsymbol{x}) = \\sum_{(\\boldsymbol{l},\\boldsymbol{i}) \\in \\mathcal{A}} \\alpha_{\\boldsymbol{l},\\boldsymbol{i}} \\, \\Phi_{\\boldsymbol{l},\\boldsymbol{i}}(\\boldsymbol{x}),\n$$\n其中分层盈余系数通过以下方式递归定义\n$$\n\\alpha_{\\boldsymbol{l},\\boldsymbol{i}} = f\\!\\left(\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}}\\right) - \\mathcal{I}_{\\text{prev}} f\\!\\left(\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}}\\right),\n$$\n其中 $\\mathcal{I}_{\\text{prev}}$ 表示由所有先前添加的、在向下闭合意义上对应于严格更粗糙节点的基函数所构成的插值函数。\n\n您的自适应算法必须：\n1. 使用层级为 $\\boldsymbol{l} = (1,\\dots,1)$ 和索引为 $\\boldsymbol{i} = (1,\\dots,1)$ 的单个内部节点进行初始化，计算其分层盈余，并将其插入一个以盈余绝对值为键的自适应队列中。\n2. 迭代地从队列中选择具有最大绝对盈余的节点，并通过添加其可接受的子节点来对其进行加密。沿坐标 $j$ 的子节点将 $l_j$ 增加 1，并将 $i_j$ 替换为 $\\{2 i_j - 1, 2 i_j + 1\\}$ 中的一个，同时保持所有其他坐标不变。对于每个新添加的子节点，使用当前插值函数计算其分层盈余，并将该子节点插入队列中。\n3. 当所有当前可用节点的最大绝对盈余低于给定容差 $ \\tau  0$ 时，或达到指定的网格点最大数量 $N_{\\max}$ 时，终止算法。\n\n使用此算法为以下测试套件构建插值函数，并为每种情况计算在指定验证网格上的最大绝对插值误差。所有角度（如适用）必须解释为弧度。\n\n对于每个测试，定义：\n- 维度 $d$。\n- 目标函数 $f : [0,1]^d \\to \\mathbb{R}$。\n- 容差 $\\tau$ 和上限 $N_{\\max}$。\n- 一个验证网格，由开区间 $(0,1)$ 内每个维度上 $m$ 个等距点的笛卡尔积形成，具体点位于 $x_k = \\frac{k}{m+1}$，其中 $k = 1,2,\\dots,m$。\n- 需要计算的最终输出：实际使用的网格点数（一个整数）和在验证网格上的最大绝对误差（一个浮点数），即，\n$$\nE_{\\max} = \\max_{\\boldsymbol{x} \\in \\mathcal{G}_m} \\left| f(\\boldsymbol{x}) - \\mathcal{I} f(\\boldsymbol{x}) \\right|.\n$$\n\n测试套件：\n- 情况 A（理想情况，三维光滑可分函数）：\n  - $d = 3$。\n  - $f(\\boldsymbol{x}) = \\exp\\!\\left(0.5\\,x_1 - 0.3\\,x_2 + 0.2\\,x_3\\right)$。\n  - $\\tau = 10^{-3}$, $N_{\\max} = 500$。\n  - 验证网格参数 $m = 9$。\n- 情况 B（二维各向异性局部高斯凸起）：\n  - $d = 2$。\n  - $f(\\boldsymbol{x}) = \\exp\\!\\left(-40 \\sum_{j=1}^2 (x_j - c_j)^2\\right)$，其中 $\\boldsymbol{c} = (0.2, 0.8)$。\n  - $\\tau = 5 \\times 10^{-4}$, $N_{\\max} = 600$。\n  - 验证网格参数 $m = 25$。\n- 情况 C（一维非光滑绝对值扭折）：\n  - $d = 1$。\n  - $f(x) = |x - 0.3|$。\n  - $\\tau = 2 \\times 10^{-4}$, $N_{\\max} = 300$。\n  - 验证网格参数 $m = 200$。\n- 情况 D（具有温和振荡的适中四维光滑函数）：\n  - $d = 4$。\n  - $f(\\boldsymbol{x}) = \\prod_{j=1}^4 \\left(1 + 0.1\\,x_j\\right) + 0.01 \\sum_{j=1}^4 \\sin(2\\pi x_j)$，角度以弧度计。\n  - $\\tau = 2 \\times 10^{-3}$, $N_{\\max} = 400$。\n  - 验证网格参数 $m = 7$。\n\n实现约束和最终输出格式：\n- 您的程序必须是自包含的，并且不得读取任何输入。它必须实现上述自适应稀疏网格插值算法，并为每个测试用例计算对 $(N, E_{\\max})$，其中 $N$ 是终止时实际使用的网格点数。\n- 您的程序应生成单行输出，包含一个扁平的、逗号分隔的 Python 列表中的所有结果，格式为 [N_A,E_A,N_B,E_B,N_C,E_C,N_D,E_D]，其中 $N_\\cdot$ 是整数，$E_\\cdot$ 是浮点数。误差值必须以十进制数（而非分数）报告，角度（如果存在）必须解释为弧度。", "solution": "问题陈述已经过验证，并被认为是合理的。它具有科学依据，问题提法适定且客观。它提出了一个明确的任务：设计并实现一种基于 Smolyak 构造和分段线性分层基的自适应稀疏网格插值算法。\n\n目标是为函数 $f: [0,1]^d \\to \\mathbb{R}$ 构建一个自适应稀疏网格插值。定义域是 $d$ 维超立方体 $[0,1]^d$。该插值方案建立在分段线性“帽”函数的分层基之上。\n\n在一维情况下，对于给定的层级 $l \\in \\mathbb{N} = \\{1, 2, 3, \\dots\\}$，在奇数索引 $i \\in \\{1, 3, \\dots, 2^l - 1\\}$ 处定义了一组节点 $x_{l,i} = i / 2^l$。与每个这样的节点相关联的是一个帽函数基函数：\n$$\n\\varphi_{l,i}(x) = \\max\\left(1 - 2^l \\left| x - x_{l,i} \\right|, 0\\right)\n$$\n该基仅在区间 $(0,1)$ 的内部定义，这意味着最终的插值函数在边界上将为零。\n\n对于 $d$ 维问题，基函数由张量积构造形成。分层网格中的一个点由多层级 $\\boldsymbol{l} = (l_1, \\dots, l_d) \\in \\mathbb{N}^d$ 和多重索引 $\\boldsymbol{i} = (i_1, \\dots, i_d)$ 确定，其中每个分量 $i_j$ 是满足 $1 \\le i_j \\le 2^{l_j}-1$ 的奇数。相应的网格节点是 $\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}} = (x_{l_1,i_1}, \\dots, x_{l_d,i_d})$，多维基函数为：\n$$\n\\Phi_{\\boldsymbol{l},\\boldsymbol{i}}(\\boldsymbol{x}) = \\prod_{j=1}^d \\varphi_{l_j,i_j}(x_j)\n$$\n\n稀疏网格插值函数 $\\mathcal{I}f(\\boldsymbol{x})$ 是这些基函数对于选定的多重索引 $(\\boldsymbol{l}, \\boldsymbol{i})$ 集合 $\\mathcal{A}$ 的线性组合：\n$$\n\\mathcal{I} f(\\boldsymbol{x}) = \\sum_{(\\boldsymbol{l},\\boldsymbol{i}) \\in \\mathcal{A}} \\alpha_{\\boldsymbol{l},\\boldsymbol{i}} \\, \\Phi_{\\boldsymbol{l},\\boldsymbol{i}}(\\boldsymbol{x})\n$$\n系数 $\\alpha_{\\boldsymbol{l},\\boldsymbol{i}}$ 是分层盈余，以递归方式定义。对于一个新添加到网格中的点 $\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}}$，其盈余是真实函数值与由所有先前包含的、更粗糙的点构成的插值函数在该点的值之差：\n$$\n\\alpha_{\\boldsymbol{l},\\boldsymbol{i}} = f(\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}}) - \\sum_{(\\boldsymbol{l}',\\boldsymbol{i}') \\in \\mathcal{A}_{\\text{prev}}} \\alpha_{\\boldsymbol{l}',\\boldsymbol{i}'} \\, \\Phi_{\\boldsymbol{l}',\\boldsymbol{i}'}(\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}})\n$$\n\n指定任务的核心是算法的自适应性。自适应性由作为误差指标的分层盈余的大小驱动。算法流程如下：\n\n1. 初始化：过程始于最粗糙层级上的单个内部节点，由多层级 $\\boldsymbol{l} = (1, \\dots, 1)$ 和多重索引 $\\boldsymbol{i} = (1, \\dots, 1)$ 指定。这对应于点 $\\boldsymbol{x} = (0.5, \\dots, 0.5)$。其盈余就是 $\\alpha_{\\boldsymbol{l},\\boldsymbol{i}} = f(\\boldsymbol{x}_{\\boldsymbol{l},\\boldsymbol{i}})$，因为初始插值函数为零。该点及其盈余被添加到网格和优先队列中，该队列按盈余的绝对值大小排序。\n\n2. 迭代加密：算法进入一个循环，直到满足终止条件。在每次迭代中：\n   a. 选择：从优先队列中选择并移除具有最大绝对盈余 $|\\alpha|$ 的网格点 $(\\boldsymbol{l}_{\\text{p}}, \\boldsymbol{i}_{\\text{p}})$。这是用于加密的父点。\n   b. 加密：通过生成父点的可接受子点来加密网格。对于每个维度 $j \\in \\{1, \\dots, d\\}$，生成两个子点。子点的多层级是通过在维度 $j$ 上增加层级从父点派生出来的，即 $l'_j = l_j+1$ 且对于 $k \\neq j$ 有 $l'_k = l_k$。新层级 $l'_j$ 对应的索引 $i'_j$ 由 $\\{2i_j-1, 2i_j+1\\}$ 给出，而对于 $k \\neq j$ 有 $i'_k=i_k$。\n   c. 更新：对于每个新生成的子点，使用上述公式计算其分层盈余，其中求和遍及当前网格中的所有点。新点及其盈余被添加到网格数据结构中，并插入到优先队列中。\n\n3. 终止：如果满足以下任一条件，迭代过程将停止：\n   a. 优先队列中的最大绝对盈余降至指定容差 $\\tau$ 以下。\n   b. 网格中的总点数达到定义的最大值 $N_{\\max}$。\n\n终止时，算法已经构建了一个稀疏网格和相应的插值函数 $\\mathcal{I}f(\\boldsymbol{x})$。最后一步是评估其准确性。这通过在预定义的验证网格 $\\mathcal{G}_m$ 上计算最大绝对误差 $E_{\\max}$ 来完成：\n$$\nE_{\\max} = \\max_{\\boldsymbol{x} \\in \\mathcal{G}_m} \\left| f(\\boldsymbol{x}) - \\mathcal{I} f(\\boldsymbol{x}) \\right|\n$$\n验证网格 $\\mathcal{G}_m$ 是每个维度在 $(0,1)$ 区间内 $m$ 个等距点的笛卡尔积。\n\n该实现将包含一个主驱动函数，用于遍历指定的测试用例。对于每个用例，一个专用的求解函数将执行自适应算法。关键数据结构将包括一个用于存储网格点及其相关数据（盈余、坐标）的字典，以及一个来自 Python 的 `heapq` 模块的最小堆，用作优先队列。将实现辅助函数来评估一维和多维基函数以及整个插值函数。最终输出将是每个测试用例中网格使用的点数 $N$ 和计算出的最大误差 $E_{\\max}$。", "answer": "```python\nimport numpy as np\nimport heapq\nimport itertools\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to define test cases and run the adaptive sparse grid solver for each.\n    \"\"\"\n\n    # --- Test Case Definitions ---\n    # Case A: Smooth separable function\n    def f_A(x):\n        return np.exp(0.5 * x[0] - 0.3 * x[1] + 0.2 * x[2])\n\n    # Case B: Anisotropic localized Gaussian bump\n    def f_B(x):\n        c = np.array([0.2, 0.8])\n        return np.exp(-40.0 * np.sum((x - c)**2))\n\n    # Case C: Non-smooth absolute value kink\n    def f_C(x):\n        return np.abs(x[0] - 0.3)\n\n    # Case D: Smooth function with mild oscillation\n    def f_D(x):\n        prod_term = np.prod(1.0 + 0.1 * x)\n        sin_term = 0.01 * np.sum(np.sin(2.0 * np.pi * x))\n        return prod_term + sin_term\n        \n    test_cases = [\n        {'d': 3, 'f': f_A, 'tau': 1e-3, 'n_max': 500, 'm': 9},\n        {'d': 2, 'f': f_B, 'tau': 5e-4, 'n_max': 600, 'm': 25},\n        {'d': 1, 'f': f_C, 'tau': 2e-4, 'n_max': 300, 'm': 200},\n        {'d': 4, 'f': f_D, 'tau': 2e-3, 'n_max': 400, 'm': 7}\n    ]\n\n    results = []\n    for case in test_cases:\n        N, E_max = solve_case(case['d'], case['f'], case['tau'], case['n_max'], case['m'])\n        results.extend([N, E_max])\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n\ndef solve_case(d, f, tau, n_max, m):\n    \"\"\"\n    Solves a single adaptive sparse grid interpolation problem.\n    \"\"\"\n    \n    # Memoization caches for basis function calculations\n    phi_1d_cache = {}\n    phi_multi_d_cache = {}\n\n    def phi_1d(x, l, i):\n        \"\"\"Evaluates the 1D hierarchical hat basis function.\"\"\"\n        cache_key = (x, l, i)\n        if cache_key in phi_1d_cache:\n            return phi_1d_cache[cache_key]\n\n        # Using 1  l which is equivalent to 2**l for integers\n        val = max(0.0, 1.0 - abs((1  l) * x - i))\n        phi_1d_cache[cache_key] = val\n        return val\n\n    def phi_multi_d(x_vec, l_vec, i_vec):\n        \"\"\"Evaluates the multidimensional tensor-product basis function.\"\"\"\n        cache_key = (tuple(x_vec), l_vec, i_vec)\n        if cache_key in phi_multi_d_cache:\n            return phi_multi_d_cache[cache_key]\n        \n        prod = 1.0\n        for j in range(d):\n            prod *= phi_1d(x_vec[j], l_vec[j], i_vec[j])\n        phi_multi_d_cache[cache_key] = prod\n        return prod\n\n    def evaluate_interpolant(x_vec, grid_points):\n        \"\"\"Evaluates the sparse grid interpolant at a point x_vec.\"\"\"\n        total = 0.0\n        for (l_vec, i_vec), data in grid_points.items():\n            alpha = data['surplus']\n            basis_val = phi_multi_d(x_vec, l_vec, i_vec)\n            total += alpha * basis_val\n        return total\n\n    grid_points = {}\n    priority_queue = []\n\n    # 1. Initialize with the first point\n    l0 = tuple([1] * d)\n    i0 = tuple([1] * d)\n    \n    x0 = tuple(i / (1  l) for l, i in zip(l0, i0))\n    f_val = f(np.array(x0))\n    alpha0 = f_val  # I_prev is 0\n    \n    grid_points[(l0, i0)] = {'surplus': alpha0, 'coords': x0}\n    heapq.heappush(priority_queue, (-abs(alpha0), l0, i0))\n\n    # 2. Main adaptive loop\n    while priority_queue:\n        if len(grid_points) >= n_max:\n            break\n        \n        neg_abs_alpha_max, _, _ = priority_queue[0]\n        if -neg_abs_alpha_max  tau:\n            break\n\n        # Pop parent point with largest surplus\n        _, l_parent, i_parent = heapq.heappop(priority_queue)\n\n        # Generate and add children\n        for j in range(d):  # Dimension to refine\n            l_child_list = list(l_parent)\n            l_child_list[j] += 1\n            l_child = tuple(l_child_list)\n            \n            i_child_val_1 = 2 * i_parent[j] - 1\n            i_child_val_2 = 2 * i_parent[j] + 1\n            \n            for i_child_val in [i_child_val_1, i_child_val_2]:\n                if len(grid_points) >= n_max:\n                    break\n\n                i_child_list = list(i_parent)\n                i_child_list[j] = i_child_val\n                i_child = tuple(i_child_list)\n\n                if (l_child, i_child) in grid_points:\n                    continue\n                \n                # Calculate surplus for the new child point\n                x_child = tuple(i / (1  l) for l, i in zip(l_child, i_child))\n                f_val_child = f(np.array(x_child))\n                \n                # Clear evaluation caches for new point evaluation\n                phi_1d_cache.clear()\n                phi_multi_d_cache.clear()\n                \n                I_prev_at_child = evaluate_interpolant(x_child, grid_points)\n                alpha_child = f_val_child - I_prev_at_child\n\n                # Add child to grid and priority queue\n                grid_points[(l_child, i_child)] = {'surplus': alpha_child, 'coords': x_child}\n                heapq.heappush(priority_queue, (-abs(alpha_child), l_child, i_child))\n            \n            if len(grid_points) >= n_max:\n                break\n    \n    # Final number of grid points used\n    N = len(grid_points)\n\n    # 3. Error calculation on validation grid\n    axis_pts = (np.arange(1, m + 1, dtype=float)) / (m + 1.0)\n    validation_grid = itertools.product(*([axis_pts] * d))\n    \n    max_error = 0.0\n    for x_val_tuple in validation_grid:\n        x_val = np.array(x_val_tuple)\n        f_true = f(x_val)\n        \n        phi_1d_cache.clear()\n        phi_multi_d_cache.clear()\n        \n        f_interp = evaluate_interpolant(x_val, grid_points)\n        max_error = max(max_error, abs(f_true - f_interp))\n            \n    return N, max_error\n\nif __name__ == \"__main__\":\n    solve()\n\n```", "id": "2432623"}]}