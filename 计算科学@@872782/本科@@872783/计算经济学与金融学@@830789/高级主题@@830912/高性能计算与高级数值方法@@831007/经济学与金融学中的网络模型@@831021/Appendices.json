{"hands_on_practices": [{"introduction": "金融市场可以被看作一个复杂的网络，其中资产是节点，它们之间的关系是连边。本练习将指导您如何将原始的资产收益率相关性数据转化为一个有意义的网络结构——最小生成树 (Minimum Spanning Tree, MST)。通过构建并分析这个网络，您可以揭示市场的“骨架”结构，并比较其在危机前后的变化，从而直观地理解市场中抽象的系统性依赖关系 [@problem_id:2413946]。", "problem": "要求您设计并实现一个程序，该程序根据相关性数据构建股票市场的网络表示，并使用经济学和金融学中网络模型的核心概念来比较市场崩盘前后的结构。您必须从基本原理出发，避免使用任何临时的或未经证实的捷径。仅可使用以下事实：对于标准化收益向量，其内积对应于皮尔逊积矩相关系数，且由内积导出的欧几里得距离构成一个度量。在此基础上，推导一个从相关性到距离的有效变换，该变换在相关性上是严格递减的，并满足度量公理，然后计算由此产生的完全加权图的最小生成树（MST）。\n\n任务说明：\n- 输入是隐式的，以相关性矩阵测试套件的形式在下方给出。每个矩阵 $\\boldsymbol{\\rho} = (\\rho_{ij})$ 都是对称的，且对于所有 $i$ 都有 $\\rho_{ii} = 1$，代表在给定时期（市场崩盘前后）资产标准化收益之间的成对皮尔逊积矩相关系数。没有单独的数据输入；您的程序必须嵌入并使用下面提供的矩阵。\n- 步骤 $1$：仅使用以下基本事实：对于中心化的、单位方差的向量，其内积等于它们的皮尔逊相关性，且欧几里得范数导出一个度量。由此推导出一个关于 $\\rho_{ij}$ 的有效函数 $d_{ij}$，该函数在资产集合上产生一个度量距离，并且关于 $\\rho_{ij}$ 严格递减。您的程序必须实现您推导出的距离。\n- 步骤 $2$：对于每个给定的相关性矩阵，在资产集上构建一个完全加权图，其中资产 $i$ 和 $j$ 之间的权重等于推导出的距离 $d_{ij}$。计算此图的最小生成树（MST）。可使用任何正确的算法，如Kruskal算法或Prim算法。为确保在边权重完全相等时结果的确定性，请通过对无序对 $(i,j)$（其中 $i < j$）进行字典序排序来打破平局。\n- 步骤 $3$：对于测试套件中的每个市场，计算：\n  - MST的总权重，定义为具有 $n$ 个资产的MST中 $n-1$ 条边权重之和。\n  - MST的图直径，定义为MST中任意两个节点之间最短路径上的最大边数，即所有节点对的未加权最短路径长度的最大值。\n  - 对于每个市场，计算崩盘前MST和崩盘后MST之间的公共边数量，其中边被视为由从零开始的索引组成的无序对 $\\{i,j\\}$。\n- 输出：对于每个市场，输出一个元组 $[w_{\\text{pre}}, w_{\\text{post}}, c, \\delta_{\\text{pre}}, \\delta_{\\text{post}}]$，其中 $w_{\\text{pre}}$ 和 $w_{\\text{post}}$ 分别是崩盘前后的MST总权重，各自四舍五入到 $6$ 位小数；$c$ 是公共边的整数数量；$\\delta_{\\text{pre}}$ 和 $\\delta_{\\text{post}}$ 分别是崩盘前后的整数直径。您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来，并按测试套件给出的顺序汇总所有市场的结果，例如：$[[w_{\\text{pre},1}, w_{\\text{post},1}, c_1, \\delta_{\\text{pre},1}, \\delta_{\\text{post},1}],[w_{\\text{pre},2}, w_{\\text{post},2}, c_2, \\delta_{\\text{pre},2}, \\delta_{\\text{post},2}]]$。\n\n测试套件：\n- 市场 $\\mathcal{A}$（五个资产，索引从 $0$ 到 $4$）：\n  - 崩盘前相关性矩阵 $\\boldsymbol{\\rho}^{\\text{pre}}_{\\mathcal{A}}$:\n  $$\n  \\begin{bmatrix}\n  1  0.82  0.31  0.27  0.14 \\\\\n  0.82  1  0.24  0.33  0.12 \\\\\n  0.31  0.24  1  0.78  0.58 \\\\\n  0.27  0.33  0.78  1  0.52 \\\\\n  0.14  0.12  0.58  0.52  1\n  \\end{bmatrix}\n  $$\n  - 崩盘后相关性矩阵 $\\boldsymbol{\\rho}^{\\text{post}}_{\\mathcal{A}}$:\n  $$\n  \\begin{bmatrix}\n  1  0.88  0.72  0.62  0.40 \\\\\n  0.88  1  0.64  0.71  0.42 \\\\\n  0.72  0.64  1  0.85  0.70 \\\\\n  0.62  0.71  0.85  1  0.68 \\\\\n  0.40  0.42  0.70  0.68  1\n  \\end{bmatrix}\n  $$\n- 市场 $\\mathcal{B}$（四个资产，索引从 $0$ 到 $3$）：\n  - 崩盘前相关性矩阵 $\\boldsymbol{\\rho}^{\\text{pre}}_{\\mathcal{B}}$:\n  $$\n  \\begin{bmatrix}\n  1  0.60  -0.20  0.10 \\\\\n  0.60  1  0.05  -0.25 \\\\\n  -0.20  0.05  1  0.40 \\\\\n  0.10  -0.25  0.40  1\n  \\end{bmatrix}\n  $$\n  - 崩盘后相关性矩阵 $\\boldsymbol{\\rho}^{\\text{post}}_{\\mathcal{B}}$:\n  $$\n  \\begin{bmatrix}\n  1  0.82  0.10  0.30 \\\\\n  0.82  1  0.20  -0.05 \\\\\n  0.10  0.20  1  0.65 \\\\\n  0.30  -0.05  0.65  1\n  \\end{bmatrix}\n  $$\n\n附加要求：\n- 索引是基于零的整数 $0,1,2,\\dots$。\n- 此问题中没有物理单位。\n- 将 $w_{\\text{pre}}$ 和 $w_{\\text{post}}$ 四舍五入到恰好 $6$ 位小数。将 $\\delta_{\\text{pre}}$、$\\delta_{\\text{post}}$ 和 $c$ 报告为整数，不进行四舍五入。\n- 您的程序必须是自包含的，并严格按照上述规定格式生成一行输出 $[[\\cdot],[\\cdot]]$，除逗号和括号外不含多余空格，也不含其他文本。", "solution": "问题陈述经评估有效。它在经济物理学领域有科学依据，定义明确且客观。它提出了一个基于网络理论应用于金融数据的既定原则的标准、可形式化的任务。我们接下来进行求解。\n\n解决方案按指定分三个阶段构建。首先，从相关系数推导出距离度量。其次，详细说明从该度量构建最小生成树（MST）的算法。第三，描述计算所需网络属性的步骤。\n\n**步骤 1：距离度量的推导**\n\n问题要求从相关系数 $\\rho_{ij}$ 推导出一个距离函数 $d_{ij}$，该函数需满足度量公理且关于 $\\rho_{ij}$ 严格递减。推导必须基于两个基本原则：\n$1$. 对于一组资产，存在相应的标准化收益向量 $\\mathbf{v}_i$，这些向量位于一个内积空间中，并且是单位向量，即 $\\|\\mathbf{v}_i\\|^2 = \\langle \\mathbf{v}_i, \\mathbf{v}_i \\rangle = \\rho_{ii} = 1$，它们的内积是皮尔逊相关系数，$\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle = \\rho_{ij}$。\n$2$. 由内积导出的欧几里得距离 $d(\\mathbf{v}_i, \\mathbf{v}_j) = \\|\\mathbf{v}_i - \\mathbf{v}_j\\|$ 是一个有效的度量。\n\n我们首先展开两个此类向量 $\\mathbf{v}_i$ 和 $\\mathbf{v}_j$ 之间欧几里得距离的平方：\n$$\nd(\\mathbf{v}_i, \\mathbf{v}_j)^2 = \\|\\mathbf{v}_i - \\mathbf{v}_j\\|^2\n$$\n根据内积导出的范数定义：\n$$\n\\|\\mathbf{v}_i - \\mathbf{v}_j\\|^2 = \\langle \\mathbf{v}_i - \\mathbf{v}_j, \\mathbf{v}_i - \\mathbf{v}_j \\rangle\n$$\n利用内积的双线性性质，上式展开为：\n$$\n\\langle \\mathbf{v}_i, \\mathbf{v}_i \\rangle - 2\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle + \\langle \\mathbf{v}_j, \\mathbf{v}_j \\rangle\n$$\n代入前提条件 $\\|\\mathbf{v}_i\\|^2 = 1$ 和 $\\langle \\mathbf{v}_i, \\mathbf{v}_j \\rangle = \\rho_{ij}$：\n$$\nd(\\mathbf{v}_i, \\mathbf{v}_j)^2 = 1 - 2\\rho_{ij} + 1 = 2(1 - \\rho_{ij})\n$$\n取平方根，得到作为 $\\rho_{ij}$ 函数的距离函数 $d_{ij}$：\n$$\nd_{ij} = \\sqrt{2(1 - \\rho_{ij})}\n$$\n我们必须验证该函数 $d_{ij}$ 是一个度量，并且关于 $\\rho_{ij}$ 严格递减。\n\n度量公理的验证：\n- **非负性**：由于 $\\rho_{ij} \\in [-1, 1]$，项 $1 - \\rho_{ij}$ 的取值范围是 $[0, 2]$。因此，$d_{ij}$ 是实数且非负。$d_{ij} \\ge 0$。\n- **不可辨识者同一性**：$d_{ij} = 0 \\iff 2(1 - \\rho_{ij}) = 0 \\iff \\rho_{ij} = 1$。这对应于完全相关的资产，在此向量表示中意味着 $\\mathbf{v}_i = \\mathbf{v}_j$。对于 $i \\neq j$，我们假设 $\\rho_{ij}  1$，因此 $d_{ij}  0$。同时，$d_{ii} = \\sqrt{2(1 - \\rho_{ii})} = \\sqrt{2(1 - 1)} = 0$。\n- **对称性**：相关性矩阵是对称的，$\\rho_{ij} = \\rho_{ji}$。因此，$d_{ij} = \\sqrt{2(1 - \\rho_{ij})} = \\sqrt{2(1 - \\rho_{ji})} = d_{ji}$。\n- **三角不等式**：$d_{ik} \\le d_{ij} + d_{jk}$。这个不等式成立，因为 $d_{ij}$ 正是欧几里得空间中向量之间的欧几里得距离，而三角不等式是欧几里得空间的一个基本性质。\n\n单调性验证：\n为了确认 $d_{ij}$ 关于 $\\rho_{ij}$ 严格递减，我们考察它对 $\\rho$ 的一阶导数：\n$$\n\\frac{\\mathrm{d}}{\\mathrm{d}\\rho} \\left( \\sqrt{2(1 - \\rho)} \\right) = -\\frac{1}{\\sqrt{2(1 - \\rho)}}\n$$\n对于 $\\rho  1$，分母是实数且为正，因此导数严格为负。这证实了所推导的距离 $d_{ij}$ 是相关性 $\\rho_{ij}$ 的严格递减函数。因此，函数 $d_{ij} = \\sqrt{2(1 - \\rho_{ij})}$ 是应使用的正确度量。\n\n**步骤 2：最小生成树的构建**\n\n对于每个相关性矩阵 $\\boldsymbol{\\rho}$，我们构建一个完全加权图 $G = (V, E)$，其中顶点集 $V$ 代表资产，任意两个顶点 $i$ 和 $j$ 之间边的权重由距离 $d_{ij}$ 给出。该图的最小生成树（MST）是一个连接所有顶点且边权重之和最小的无环子图。\n\n我们将使用Kruskal算法来计算MST。该算法操作如下：\n$1$. 创建图中所有边的列表，表示为元组 $(w, u, v)$，其中 $w$ 是权重 $d_{uv}$，$u, v$ 是顶点索引且 $u  v$。对于一个有 $n$ 个资产的图，共有 $\\binom{n}{2} = \\frac{n(n-1)}{2}$ 条这样的边。\n$2$. 按权重的升序对这个边列表进行排序。为保证确定性，权重相等的平局通过顶点对 $(u,v)$ 的字典序来打破。对于权重相同的两条边，字典序较小的对 $(u, v)$ 对应的边被优先选择。\n$3$. 初始化一个不相交集联合（DSU）数据结构，每个顶点初始时在各自的集合中。\n$4$. 遍历排序后的边列表。对于每条边 $(w, u, v)$：\n    - 使用DSU的`find`操作检查顶点 $u$ 和 $v$ 是否属于同一个集合。\n    - 如果不属于，则该边不会形成环路。将此边添加到MST中，并使用DSU的`union`操作合并包含 $u$ 和 $v$ 的集合。\n$5$. 当已向MST添加 $n-1$ 条边时，算法终止。\n\n**步骤 3：网络属性的计算**\n\n在为每个市场的崩盘前和崩盘后两种状态构建好MST后，我们计算以下属性：\n\n- **MST总权重 ($w$)**：这是MST中所有边权重之和。对于一个边集为 $E_{\\text{MST}}$ 的MST，其总权重为 $w = \\sum_{\\{i,j\\} \\in E_{\\text{MST}}} d_{ij}$。该值对崩盘前（$w_{\\text{pre}}$）和崩盘后（$w_{\\text{post}}$）的MST分别计算，并四舍五入到6位小数。\n\n- **MST直径 ($\\delta$)**：树的直径是其任意两个节点之间最长最短路径的长度。路径长度按边数（未加权）计算。我们使用以下标准的两遍算法来计算它：\n    $1$. 构建MST的邻接表表示。\n    $2$. 从任意节点 $s$ 开始执行一次广度优先搜索（BFS），找到离它最远的节点 $u$。\n    $3$. 从节点 $u$ 开始执行第二次BFS，找到离它最远的节点 $v$。从 $u$ 到 $v$ 的距离即为树的直径。\n    此值对崩盘前（$\\delta_{\\text{pre}}$）和崩盘后（$\\delta_{\\text{post}}$）的MST分别计算。\n\n- **公共边数量 ($c$)**：这是一个整数值，代表崩盘前MST和崩盘后MST边集的交集大小。边被视为基于零的索引的无序对 $\\{i, j\\}$。通过将每条边规范地表示为元组 $(i, j)$（其中 $i  j$），我们可以找到两个MST边集的交集。\n\n这些步骤被系统地应用于测试套件中每个市场的数据，以生成最终输出。", "answer": "```python\nimport numpy as np\nimport math\n\n# No other libraries are permitted as per instructions.\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    It processes each market's pre- and post-crash correlation matrices,\n    computes the required metrics, and prints the formatted result.\n    \"\"\"\n\n    class DSU:\n        \"\"\"A simple Disjoint Set Union data structure for Kruskal's algorithm.\"\"\"\n        def __init__(self, n):\n            self.parent = list(range(n))\n            self.num_sets = n\n\n        def find(self, i):\n            \"\"\"Find the representative of the set containing element i with path compression.\"\"\"\n            if self.parent[i] == i:\n                return i\n            self.parent[i] = self.find(self.parent[i])\n            return self.parent[i]\n\n        def union(self, i, j):\n            \"\"\"Merge the sets containing elements i and j.\"\"\"\n            root_i = self.find(i)\n            root_j = self.find(j)\n            if root_i != root_j:\n                self.parent[root_i] = root_j\n                self.num_sets -= 1\n                return True\n            return False\n\n    def get_mst_diameter(n, mst_edges):\n        \"\"\"\n        Computes the diameter of a tree (given as an MST edge list).\n        The diameter is the longest shortest path between any two nodes.\n        Path length is the number of edges.\n        \"\"\"\n        if n = 1:\n            return 0\n        \n        adj = [[] for _ in range(n)]\n        for u, v in mst_edges:\n            adj[u].append(v)\n            adj[v].append(u)\n\n        def bfs(start_node):\n            \"\"\"Performs a BFS to find the farthest node and distance from a start node.\"\"\"\n            distances = [-1] * n\n            queue = [(start_node, 0)]\n            distances[start_node] = 0\n            \n            head = 0\n            farthest_node = start_node\n            max_dist = 0\n\n            while head  len(queue):\n                u, dist = queue[head]\n                head += 1\n\n                if dist > max_dist:\n                    max_dist = dist\n                    farthest_node = u\n\n                for v in adj[u]:\n                    if distances[v] == -1:\n                        distances[v] = dist + 1\n                        queue.append((v, dist + 1))\n            \n            return farthest_node, max_dist\n\n        # 1. First BFS from an arbitrary node (0) to find one endpoint of a diameter.\n        node_u, _ = bfs(0)\n        # 2. Second BFS from that endpoint to find the actual diameter.\n        _, diameter = bfs(node_u)\n        \n        return diameter\n\n    def process_correlation_matrix(rho_matrix):\n        \"\"\"\n        Takes a correlation matrix and returns MST properties:\n        total weight, diameter, and the set of edges.\n        \"\"\"\n        n = rho_matrix.shape[0]\n        \n        # Step 1: Derive distance and create a list of edges with weights.\n        # d_ij = sqrt(2 * (1 - rho_ij))\n        # The tie-breaking is handled by sorting on (weight, u, v).\n        edges = []\n        for i in range(n):\n            for j in range(i + 1, n):\n                rho_ij = rho_matrix[i, j]\n                # Defensive check for floating point inaccuracies leading to rho > 1\n                if rho_ij > 1.0:\n                    rho_ij = 1.0\n                dist = math.sqrt(2.0 * (1.0 - rho_ij))\n                edges.append((dist, i, j))\n        \n        # Sort edges: primary key is weight, secondary keys are i then j.\n        edges.sort()\n\n        # Step 2: Compute MST using Kruskal's algorithm.\n        dsu = DSU(n)\n        mst_edges = []\n        mst_weight = 0.0\n        \n        for dist, u, v in edges:\n            if dsu.union(u, v):\n                mst_edges.append((u, v))\n                mst_weight += dist\n                if len(mst_edges) == n - 1:\n                    break\n        \n        # Step 3: Compute MST diameter.\n        mst_diameter = get_mst_diameter(n, mst_edges)\n        \n        # Return canonical representation of edges (sorted tuples) for comparison\n        mst_edge_set = {tuple(sorted(edge)) for edge in mst_edges}\n\n        return mst_weight, mst_diameter, mst_edge_set\n\n    # Test suite provided in the problem description.\n    test_cases = [\n        # Market A\n        {\n            \"name\": \"Market A\",\n            \"pre\": np.array([\n                [1.00, 0.82, 0.31, 0.27, 0.14],\n                [0.82, 1.00, 0.24, 0.33, 0.12],\n                [0.31, 0.24, 1.00, 0.78, 0.58],\n                [0.27, 0.33, 0.78, 1.00, 0.52],\n                [0.14, 0.12, 0.58, 0.52, 1.00]\n            ]),\n            \"post\": np.array([\n                [1.00, 0.88, 0.72, 0.62, 0.40],\n                [0.88, 1.00, 0.64, 0.71, 0.42],\n                [0.72, 0.64, 1.00, 0.85, 0.70],\n                [0.62, 0.71, 0.85, 1.00, 0.68],\n                [0.40, 0.42, 0.70, 0.68, 1.00]\n            ])\n        },\n        # Market B\n        {\n            \"name\": \"Market B\",\n            \"pre\": np.array([\n                [1.00, 0.60, -0.20, 0.10],\n                [0.60, 1.00, 0.05, -0.25],\n                [-0.20, 0.05, 1.00, 0.40],\n                [0.10, -0.25, 0.40, 1.00]\n            ]),\n            \"post\": np.array([\n                [1.00, 0.82, 0.10, 0.30],\n                [0.82, 1.00, 0.20, -0.05],\n                [0.10, 0.20, 1.00, 0.65],\n                [0.30, -0.05, 0.65, 1.00]\n            ])\n        }\n    ]\n\n    result_strings = []\n    \n    for market_data in test_cases:\n        w_pre, d_pre, edges_pre = process_correlation_matrix(market_data[\"pre\"])\n        w_post, d_post, edges_post = process_correlation_matrix(market_data[\"post\"])\n        \n        # Calculate number of common edges\n        common_edges_count = len(edges_pre.intersection(edges_post))\n        \n        # Format the result tuple for this market\n        w_pre_str = f\"{w_pre:.6f}\"\n        w_post_str = f\"{w_post:.6f}\"\n        \n        market_result_str = (\n            f\"[{w_pre_str},{w_post_str},{common_edges_count},\"\n            f\"{d_pre},{d_post}]\"\n        )\n        result_strings.append(market_result_str)\n\n    # Print the final output in the exact required format\n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "2413946"}, {"introduction": "在了解了如何分析现有网络结构之后，我们自然会问：网络结构为何会如此形成？本练习构建了一个模型，用于探索经济学中的一个基本权衡：分散化投资（降低风险）的好处与维持多重关系（监控成本）的代价。通过求解一个代表性代理人的最优连接数，您将理解理性决策如何在一个充满风险与成本的环境中塑造网络的基本形态 [@problem_id:2413958]。", "problem": "考虑一个单一的代表性金融中介机构，它将单位风险敞口分配给 $n$ 个相同的交易对手。该代理人必须选择一个整数 $n \\in \\{1,2,\\dots,N_{\\max}\\}$，其中 $n$ 代表交易对手（关联）的数量。每个选定的交易对手都获得相同的权重，因此权重向量为 $w_i = 1/n$，$i = 1,\\dots,n$。维持每个关联会产生每个关联 $k \\in \\mathbb{R}_{+}$ 的监控成本。每个交易对手 $i$ 都可能违约，这由一个伯努利随机变量 $X_i \\in \\{0,1\\}$ 表示，其共同违约概率为 $\\mathbb{P}(X_i=1)=p \\in (0,1)$。这些违约指标是可交换的，其组内相关系数为 $\\rho \\in [0,1]$，意味着对于 $i \\neq j$，有 $\\mathrm{Cov}(X_i,X_j) = \\rho\\,p(1-p)$。单位权重风险敞口的违约会导致代理人遭受 $\\ell \\in \\mathbb{R}_{+}$ 的损失，该损失与该交易对手的权重成线性比例。因此，随机损失为\n$$\nL(n) = \\ell \\sum_{i=1}^{n} w_i X_i = \\ell \\sum_{i=1}^{n} \\frac{1}{n} X_i.\n$$\n假设由期望效用的二阶泰勒近似所证明的均值-方差偏好：代理人最大化\n$$\nJ(n) = \\mathbb{E}[\\Pi(n)] - \\frac{\\gamma}{2}\\,\\mathrm{Var}(\\Pi(n)),\n$$\n其中 $\\Pi(n)$ 是利润。唯一的随机部分是 $L(n)$，因此 $\\mathrm{Var}(\\Pi(n)) = \\mathrm{Var}(L(n))$，而 $\\mathbb{E}[\\Pi(n)]$ 在不同 $n$ 之间的差异仅在于确定性的监控成本 $k n$。违约相关结构是可交换的，因此在等权重的情况下，我们有\n$$\n\\mathrm{Var}\\!\\left(\\sum_{i=1}^{n} w_i X_i\\right)\n= p(1-p)\\left(\\sum_{i=1}^{n} w_i^2 + \\rho\\Big(\\Big(\\sum_{i=1}^{n} w_i\\Big)^2 - \\sum_{i=1}^{n} w_i^2\\Big)\\right).\n$$\n在等权重 $w_i = 1/n$ 的情况下，这可以简化为\n$$\n\\mathrm{Var}\\!\\left(\\sum_{i=1}^{n} \\frac{1}{n} X_i\\right)\n= p(1-p)\\left(\\frac{1}{n} + \\rho\\left(1 - \\frac{1}{n}\\right)\\right).\n$$\n因此，\n$$\n\\mathrm{Var}(L(n)) = \\ell^2\\,p(1-p)\\left(\\frac{1}{n} + \\rho\\left(1 - \\frac{1}{n}\\right)\\right).\n$$\n舍去不依赖于 $n$ 的常数，该决策问题等价于在整数 $n \\in \\{1,\\dots,N_{\\max}\\}$ 上最小化函数\n$$\nC(n) \\equiv k\\,n + \\frac{\\gamma}{2}\\,\\ell^2\\,p(1-p)\\left(\\frac{1}{n} + \\rho\\left(1 - \\frac{1}{n}\\right)\\right).\n$$\n解释：选择一个更大的 $n$（多个弱关联）会减少与 $1/n$ 成正比的异质性方差项，但会增加与 $n$ 成正比的监控成本项，而与 $\\rho$ 成正比的相关部分基本上是不可分散的。代理人应选择使 $C(n)$ 最小化的 $n$；如果存在多个最小值点，则选择其中最小的 $n$。\n\n您的任务是编写一个完整的、可运行的程序，为下面的每个测试用例计算最优整数\n$$\nn^{\\star} = \\arg\\min_{n \\in \\{1,\\dots,N_{\\max}\\}} C(n),\n$$\n并遵循平局决胜规则，即如果有多个 $n$ 达到了 $C(n)$ 的相同最小值，您必须返回其中最小的那个 $n$。\n\n所有概率都必须作为小数处理（例如，百分之五使用 $0.05$）。此问题不涉及任何物理单位。\n\n程序中要实现的测试套件：\n- 案例A（代表性混合情景）：$p = 0.05$，$\\rho = 0.2$，$\\gamma = 8.0$，$k = 0.01$，$\\ell = 1.0$，$N_{\\max} = 40$。\n- 案例B（高度独立，关联成本极低）：$p = 0.05$，$\\rho = 0.0$，$\\gamma = 8.0$，$k = 0.0005$，$\\ell = 1.0$，$N_{\\max} = 100$。\n- 案例C（完全系统性冲击占主导）：$p = 0.05$，$\\rho = 1.0$，$\\gamma = 8.0$，$k = 0.005$，$\\ell = 1.0$，$N_{\\max} = 50$。\n- 案例D（违约概率较高，关联成本昂贵）：$p = 0.1$，$\\rho = 0.0$，$\\gamma = 8.0$，$k = 0.02$，$\\ell = 1.0$，$N_{\\max} = 50$。\n- 案例E（无关联成本，独立违约）：$p = 0.05$，$\\rho = 0.0$，$\\gamma = 8.0$，$k = 0.0$，$\\ell = 1.0$，$N_{\\max} = 60$。\n\n您的程序应生成单行输出，其中包含五个案例的最优 $n^{\\star}$，顺序与案例相同，格式为逗号分隔的列表，并用方括号括起，例如 $[n_A,n_B,n_C,n_D,n_E]$。输出必须是整数。", "solution": "在尝试解决方案之前，对问题陈述进行验证。\n\n步骤1：提取已知条件。\n该问题为金融中介机构的优化问题提供了以下数据、定义和条件：\n- 交易对手数量：一个整数 $n \\in \\{1, 2, \\dots, N_{\\max}\\}$。\n- 每个交易对手的权重：$w_i = 1/n$，$i=1, \\dots, n$。\n- 每个关联的监控成本：$k \\in \\mathbb{R}_{+}$。\n- 交易对手 $i$ 的违约事件：一个伯努利随机变量 $X_i \\in \\{0, 1\\}$。\n- 共同违约概率：$\\mathbb{P}(X_i=1) = p \\in (0, 1)$。\n- 组内相关系数：对于 $i \\neq j$，有 $\\mathrm{Cov}(X_i, X_j) = \\rho\\,p(1-p)$，其中 $\\rho \\in [0, 1]$。\n- 单位权重风险敞口违约的损失：$\\ell \\in \\mathbb{R}_{+}$。\n- 总随机损失函数：$L(n) = \\ell \\sum_{i=1}^{n} w_i X_i = \\frac{\\ell}{n} \\sum_{i=1}^{n} X_i$。\n- 代理人要最大化的目标函数：$J(n) = \\mathbb{E}[\\Pi(n)] - \\frac{\\gamma}{2}\\,\\mathrm{Var}(\\Pi(n))$，其中 $\\gamma$ 是一个风险规避系数。\n- 总损失的方差：$\\mathrm{Var}(L(n)) = \\ell^2\\,p(1-p)\\left(\\frac{1}{n} + \\rho\\left(1 - \\frac{1}{n}\\right)\\right)$。\n- 等价的要最小化的成本函数：$C(n) \\equiv k\\,n + \\frac{\\gamma}{2}\\,\\ell^2\\,p(1-p)\\left(\\frac{1}{n} + \\rho\\left(1 - \\frac{1}{n}\\right)\\right)$。\n- 最小化定义域：整数 $n \\in \\{1, \\dots, N_{\\max}\\}$。\n- 平局决胜规则：如果多个 $n$ 值产生相同的最小成本，则选择其中最小的 $n$。\n- 测试用例：\n    1. 案例A：$p = 0.05$，$\\rho = 0.2$，$\\gamma = 8.0$，$k = 0.01$，$\\ell = 1.0$，$N_{\\max} = 40$。\n    2. 案例B：$p = 0.05$，$\\rho = 0.0$，$\\gamma = 8.0$，$k = 0.0005$，$\\ell = 1.0$，$N_{\\max} = 100$。\n    3. 案例C：$p = 0.05$，$\\rho = 1.0$，$\\gamma = 8.0$，$k = 0.005$，$\\ell = 1.0$，$N_{\\max} = 50$。\n    4. 案例D：$p = 0.1$，$\\rho = 0.0$，$\\gamma = 8.0$，$k = 0.02$，$\\ell = 1.0$，$N_{\\max} = 50$。\n    5. 案例E：$p = 0.05$，$\\rho = 0.0$，$\\gamma = 8.0$，$k = 0.0$，$\\ell = 1.0$，$N_{\\max} = 60$。\n\n步骤2：使用提取的已知条件进行验证。\n根据验证标准对问题进行评估。\n- **科学依据**：该问题是均值-方差偏好下的投资组合优化标准练习，是现代金融理论的基石。通过可交换结构对相关违约进行建模是信用风险建模中一种常见且有效的简化方法。投资组合方差和由此产生的成本函数的推导在数学上是正确的。该问题牢固地建立在公认的经济学和数学原理之上。\n- **适定性**：任务是在一个有限的非空整数集 $\\{1, \\dots, N_{\\max}\\}$ 上找到函数 $C(n)$ 的最小值。最小值保证存在。明确的平局决胜规则确保解是唯一的。因此，该问题是适定的。\n- **客观性**：问题陈述使用了精确的数学定义和客观的语言，没有主观或模糊的术语。\n- **完整性与一致性**：定义函数 $C(n)$ 和搜索空间所需的所有参数均已提供。设置中没有矛盾之处。\n- **现实性与可行性**：参数值在经济建模目的的现实范围内。该问题不违反任何物理或逻辑约束。\n\n步骤3：结论与行动。\n问题有效。这是一个适定的、有科学依据的、自洽的优化问题。将提供一个解决方案。\n\n目标是找到最小化成本函数的整数 $n^{\\star}$\n$$\nn^{\\star} = \\arg\\min_{n \\in \\{1,\\dots,N_{\\max}\\}} C(n)\n$$\n其中\n$$\nC(n) = k\\,n + \\frac{\\gamma}{2}\\,\\ell^2\\,p(1-p)\\left(\\frac{1}{n} + \\rho\\left(1 - \\frac{1}{n}\\right)\\right).\n$$\n我们可以重写函数 $C(n)$ 以更好地理解其结构。让我们将依赖于 $n$ 的项分组：\n$$\nC(n) = k\\,n + \\frac{\\gamma}{2}\\,\\ell^2\\,p(1-p)\\left(\\frac{1-\\rho}{n} + \\rho\\right)\n$$\n$$\nC(n) = k\\,n + \\left(\\frac{\\gamma}{2}\\,\\ell^2\\,p(1-p)(1-\\rho)\\right)\\frac{1}{n} + \\left(\\frac{\\gamma}{2}\\,\\ell^2\\,p(1-p)\\rho\\right).\n$$\n最后一项是关于 $n$ 的常数，在最小化过程中可以忽略。我们寻求最小化函数\n$$\n\\tilde{C}(n) = A\\,n + \\frac{B}{n}\n$$\n其中 $A = k$ 且 $B = \\frac{\\gamma}{2}\\,\\ell^2\\,p(1-p)(1-\\rho)$。由于 $k \\in \\mathbb{R}_{+}$，$\\gamma > 0$，且 $p, \\rho \\in [0,1]$，所以参数满足 $A \\ge 0$ 和 $B \\ge 0$。\n\n该问题要求在离散集 $\\{1, 2, \\dots, N_{\\max}\\}$ 中找到 $C(n)$ 的最小值。虽然可以通过将导数设为零来找到实变量 $n$ 的解析解 $n_{\\text{real}}^{\\star} = \\sqrt{B/A}$，然后检查相邻的整数，但这种方法需要仔细处理边界和特殊情况（例如，$k=0$ 或 $\\rho=1$）。\n\n鉴于测试套件中 $N_{\\max}$ 的最大值为 $100$，在整个定义域上进行直接计算搜索是最稳健和直接的方法。这种方法避免了涉及浮点运算的解析解的任何潜在陷阱，并正确处理了定义域的离散性。\n\n算法如下：\n对于每组参数 $(p, \\rho, \\gamma, k, \\ell, N_{\\max})$：\n1. 初始化一个变量用于存储迄今为止找到的最小成本 $C_{\\min}$，将其设为一个非常大的值（或 $n=1$ 时的成本），并将最优交易对手数量 $n^{\\star}$ 初始化为 $1$。\n2. 遍历从 $1$ 到 $N_{\\max}$ 的所有可能的整数值 $n$。\n3. 对于每个 $n$，计算成本函数 $C(n)$ 的值。\n4. 如果计算出的 $C(n)$ 严格小于当前的 $C_{\\min}$，则更新 $C_{\\min} = C(n)$ 和 $n^{\\star} = n$。\n5. 平局决胜规则要求在出现平局时选择最小的 $n$，这一规则通过此程序自动得到满足。因为我们按递增顺序迭代 $n$，所以只有在成本严格更低时才会更新 $n^{\\star}$。相等的成本不会触发更新，从而保留了较小的 $n$ 值。\n\n这种暴力搜索保证了根据问题规范找到正确的整数最小值点。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves for the optimal number of counterparties n* for a series of test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (p, rho, gamma, k, l, N_max)\n        (0.05, 0.2, 8.0, 0.01, 1.0, 40),      # Case A\n        (0.05, 0.0, 8.0, 0.0005, 1.0, 100),   # Case B\n        (0.05, 1.0, 8.0, 0.005, 1.0, 50),     # Case C\n        (0.1, 0.0, 8.0, 0.02, 1.0, 50),       # Case D\n        (0.05, 0.0, 8.0, 0.0, 1.0, 60),       # Case E\n    ]\n\n    results = []\n    for case in test_cases:\n        p, rho, gamma, k, l, N_max = case\n\n        optimal_n = 1\n        # Initialize min_cost with the cost for n=1\n        \n        # C(n) = k*n + (gamma/2)*l^2*p*(1-p) * (1/n + rho*(1 - 1/n))\n        # C(n) = k*n + (gamma/2)*l^2*p*(1-p) * ((1-rho)/n + rho)\n        \n        const_factor = (gamma / 2.0) * (l**2) * p * (1.0 - p)\n        \n        # Cost for n=1:\n        cost_n1 = k * 1.0 + const_factor * ( (1.0 - rho) / 1.0 + rho )\n        min_cost = cost_n1\n\n        # Iterate from n=2 to N_max since n=1 is our starting point\n        for n in range(2, N_max + 1):\n            # Calculate the cost for the current n\n            variance_term = (1.0 / n) + rho * (1.0 - 1.0 / n)\n            current_cost = k * n + const_factor * variance_term\n            \n            # The problem asks for the smallest n in case of a tie.\n            # By using '', we only update if the new cost is strictly smaller,\n            # which naturally satisfies the tie-breaking rule because we iterate n\n            # in increasing order.\n            if current_cost  min_cost:\n                min_cost = current_cost\n                optimal_n = n\n\n        results.append(optimal_n)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2413958"}, {"introduction": "现实世界中的金融网络并非静止不变，它们会持续受到各种冲击的影响。最后的这个练习将模拟一次“压力测试”，通过逐一移除网络中最重要的节点（根据 PageRank 中心性确定）来检验网络的韧性。通过这个过程，您可以量化评估网络的稳健性，并深入理解少数关键节点的失败如何引发连锁反应，最终导致系统性风险的爆发 [@problem_id:2413880]。", "problem": "考虑一个有向加权金融网络，由一个邻接矩阵 $W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$ 表示，其条目为 $W_{ij}$，其中 $W_{ij}$ 表示从节点 $i$到节点 $j$ 的非负风险暴露权重。设步骤 $t$ 时的活跃节点集合为 $V_t \\subseteq \\{0,1,\\dots,n-1\\}$，其大小为 $|V_t| = m_t$。对于任意活跃集合 $V_t$，定义行随机转移矩阵 $P^{(t)} \\in \\mathbb{R}^{m_t \\times m_t}$ 如下：\n- 对于每个活跃节点 $i \\in V_t$，令 $s_i^{(t)} = \\sum_{j \\in V_t} W_{ij}$，\n- 如果 $s_i^{(t)}  0$，则对 $j \\in V_t$ 设 $P_{ij}^{(t)} = W_{ij} / s_i^{(t)}$，\n- 如果 $s_i^{(t)} = 0$（一个悬挂节点），则对所有 $j \\in V_t$ 设 $P_{ij}^{(t)} = 1/m_t$。\n\n固定一个阻尼因子 $d \\in (0,1)$。步骤 $t$ 时的 PageRank 向量 $\\pi^{(t)} \\in \\mathbb{R}^{m_t}$ 定义为\n$$\n\\pi^{(t)} = (1-d)\\frac{\\mathbf{1}}{m_t} + d \\left(P^{(t)}\\right)^\\top \\pi^{(t)},\n$$\n的唯一解，并满足归一化条件 $\\sum_{i \\in V_t} \\pi^{(t)}_i = 1$ 和对所有 $i \\in V_t$ 均有 $\\pi^{(t)}_i \\ge 0$。\n\n定义一个压力测试序列如下。初始化 $V_0 = \\{0,1,\\dots,n-1\\}$。在每个步骤 $t \\in \\{0,1,2,\\dots\\}$：\n1. 在由 $V_t$ 诱导的子网络上计算 $\\pi^{(t)}$。\n2. 选择 $v_t \\in \\arg\\max_{i \\in V_t} \\pi^{(t)}_i$；通过选择 $\\{0,1,\\dots,n-1\\}$ 中的最小索引来打破平局。\n3. 移除所选节点：$V_{t+1} = V_t \\setminus \\{v_t\\}$。\n\n对于任意活跃集合 $V_t$，如果 $W_{ij}  0$ 或 $W_{ji}  0$ 且 $i,j \\in V_t$，则在 $i$ 和 $j$ 之间放置一条无向边，从而定义诱导子图的无向版本。令 $C^{(t)}$ 为该无向子图的最大弱连通分量的大小（节点数），其中孤立节点计为大小为 $1$ 的分量，空图的分量大小为 $0$。\n\n给定一个初始网络 $(W, n)$、一个阻尼因子 $d \\in (0,1)$ 和一个阈值 $\\theta \\in (0,1]$，定义失效时间\n$$\nk^\\star = \\min \\left\\{ t \\in \\{0,1,\\dots,n\\} \\,:\\, C^{(t)} \\le \\theta \\cdot n \\right\\}.\n$$\n如果初始网络已经满足 $C^{(0)} \\le \\theta \\cdot n$，则 $k^\\star = 0$。每个测试用例所需的输出是整数 $k^\\star$。\n\n你的任务是编写一个程序，对于下面的每个测试用例，根据上述定义计算出相应的整数 $k^\\star$。PageRank中心性必须在每一步对当前的活跃集合 $V_t$ 重新计算。最大化集合中的平局必须通过选择在 $\\{0,1,\\dots,n-1\\}$ 中具有最小原始索引的节点来解决。\n\n测试套件（每个用例指定 $n$、具有单位权重的 $W$ 的非零边、阻尼因子 $d$ 和阈值 $\\theta$）：\n- 用例 A：\n  - $n = 4$，\n  - 具有单位权重的非零有向边：$(1,0)$、$(2,0)$、$(3,0)$，所有其他条目为 $0$，\n  - $d = 0.85$，\n  - $\\theta = 0.5$。\n- 用例 B：\n  - $n = 5$，\n  - 具有单位权重的有向环：$(0,1)$、$(1,2)$、$(2,3)$、$(3,4)$、$(4,0)$，\n  - $d = 0.85$，\n  - $\\theta = 0.6$。\n- 用例 C：\n  - $n = 6$，\n  - 完全有向网络，所有 $i \\ne j$ 的有序对 $(i,j)$ 上权重为单位权重，对角线上为零，\n  - $d = 0.9$，\n  - $\\theta = 0.5$。\n- 用例 D：\n  - $n = 5$，\n  - 具有单位权重的两个弱连通分量：$(0,1)$、$(1,0)$、$(2,3)$、$(3,4)$，所有其他条目为 $0$，\n  - $d = 0.85$，\n  - $\\theta = 0.8$。\n\n最终输出格式：你的程序应生成一行输出，其中包含四个整数 $[k_A,k_B,k_C,k_D]$ 的结果，按 A、B、C、D 的顺序排列，以逗号分隔，并用方括号括起来，例如 $[1,2,3,4]$。不应打印任何额外文本。", "solution": "问题陈述已经过验证，被认为是科学上合理、良构、客观且计算上可行的。它描述了一个有向网络上的离散时间节点移除过程，其中每一步被选中移除的节点由其 PageRank 中心性确定。当网络的结构完整性（以其最大弱连通分量的大小衡量）降至指定阈值以下时，该过程终止。\n\n解决方案是对这一压力测试序列的直接模拟。模拟从步骤 $t=0$ 开始迭代进行，最多到 $t=n$。在每个步骤 $t$，网络的状态由活跃节点集合 $V_t$ 定义。执行以下计算序列。\n\n首先，评估主要终止准则。这需要计算 $C^{(t)}$，即由活跃节点 $V_t$ 诱导的子图的最大弱连通分量的大小。从活跃节点概念性地构建一个无向图，如果原始权重矩阵 $W$ 满足 $W_{ij}  0$ 或 $W_{ji}  0$，则在节点 $i, j \\in V_t$ 之间存在一条边。使用标准的图遍历算法（如广度优先搜索 (BFS) 或深度优先搜索 (DFS)）找到该无向图的连通分量的大小。这些大小的最大值即为 $C^{(t)}$。如果 $C^{(t)} \\le \\theta \\cdot n$，则过程终止，失效时间为 $k^\\star = t$。\n\n如果未满足终止条件，模拟将继续以确定下一个要移除的节点。这需要为由 $V_t$ 诱导的子网络计算 PageRank 向量 $\\pi^{(t)}$。设 $m_t = |V_t|$ 为活跃节点的数量。根据提供的规则构建行随机转移矩阵 $P^{(t)} \\in \\mathbb{R}^{m_t \\times m_t}$。对于一个有出链到 $V_t$ 中其他节点的节点 $i \\in V_t$，其在 $P^{(t)}$ 中对应的行通过其出度权重和 $s_i^{(t)} = \\sum_{j \\in V_t} W_{ij}$进行归一化。对于悬挂节点 ($s_i^{(t)}=0$)，对应的行为均匀分布，$P_{ij}^{(t)} = 1/m_t$ 对所有 $j \\in V_t$ 成立。\n\nPageRank 向量 $\\pi^{(t)}$ 是以下线性系统的解：\n$$\n\\left(I - d \\left(P^{(t)}\\right)^\\top\\right) \\pi^{(t)} = (1-d)\\frac{\\mathbf{1}}{m_t}\n$$\n其中 $I$ 是 $m_t \\times m_t$ 的单位矩阵，$d \\in (0,1)$ 是阻尼因子，$\\mathbf{1}$ 是全一向量。该系统是非奇异的，并且对 $\\pi^{(t)}$ 有唯一的非负解，可以使用标准的线性方程求解器数值求解。\n\n接下来，选择要移除的节点 $v_t$。$v_t$ 是 $V_t$ 中具有最高 PageRank 分数的节点。形式上，$v_t$ 从集合 $\\arg\\max_{i \\in V_t} \\pi^{(t)}_i$ 中选择。如果多个节点共享最高的 PageRank 分数，则通过从集合 $\\{0, 1, \\dots, n-1\\}$ 中选择具有最小原始索引的节点来打破平局。\n\n最后，通过移除所选节点来更新下一步的活跃节点集：$V_{t+1} = V_t \\setminus \\{v_t\\}$。然后模拟进入步骤 $t+1$。对每个测试用例重复此整个过程，直到确定相应的 $k^\\star$。", "answer": "```python\nimport numpy as np\n\ndef get_largest_wcc_size(W, active_nodes):\n    \"\"\"\n    Computes the size of the largest weakly connected component (WCC).\n    An undirected graph is formed on the active_nodes, with an edge (i, j)\n    if W[i,j] > 0 or W[j,i] > 0.\n    \"\"\"\n    m = len(active_nodes)\n    if m == 0:\n        return 0\n\n    # Map from original node index to its index in the active_nodes list (0 to m-1)\n    node_to_idx = {node: i for i, node in enumerate(active_nodes)}\n    \n    # Adjacency list for the undirected version of the subgraph\n    adj = [[] for _ in range(m)]\n    has_edges = False\n    for i in range(m):\n        for j in range(i + 1, m):\n            u, v = active_nodes[i], active_nodes[j]\n            if W[u, v] > 0 or W[v, u] > 0:\n                adj[i].append(j)\n                adj[j].append(i)\n                has_edges = True\n\n    # If no edges, all nodes are isolated components of size 1\n    if not has_edges and m > 0:\n        return 1\n    elif not has_edges and m == 0:\n        return 0\n\n    visited = [False] * m\n    max_size = 0\n    for i in range(m):\n        if not visited[i]:\n            current_size = 0\n            q = [i]\n            visited[i] = True\n            head = 0\n            while head  len(q):\n                u_idx = q[head]\n                head += 1\n                current_size += 1\n                for v_idx in adj[u_idx]:\n                    if not visited[v_idx]:\n                        visited[v_idx] = True\n                        q.append(v_idx)\n            max_size = max(max_size, current_size)\n    return max_size\n\ndef compute_pagerank(W_full, active_nodes, d):\n    \"\"\"\n    Computes the PageRank vector for the subgraph induced by active_nodes.\n    \"\"\"\n    m = len(active_nodes)\n    if m == 0:\n        return np.array([])\n\n    # Create the submatrix of W corresponding to active nodes\n    W_sub = W_full[np.ix_(active_nodes, active_nodes)]\n    \n    # Calculate row sums for normalization\n    row_sums = W_sub.sum(axis=1)\n    \n    P = np.zeros((m, m))\n    \n    # Handle non-dangling nodes\n    non_dangling_mask = row_sums > 0\n    if np.any(non_dangling_mask):\n      P[non_dangling_mask] = W_sub[non_dangling_mask] / row_sums[non_dangling_mask, np.newaxis]\n\n    # Handle dangling nodes\n    dangling_mask = ~non_dangling_mask\n    if np.any(dangling_mask):\n        P[dangling_mask, :] = 1.0 / m\n        \n    # Solve the linear system (I - d*P^T) * pi = (1-d)/m * 1\n    I = np.identity(m)\n    A = I - d * P.T\n    b = (1.0 - d) / m * np.ones(m)\n    \n    pi = np.linalg.solve(A, b)\n    return pi\n\ndef solve_case(n, W, d, theta):\n    \"\"\"\n    Runs the stress-testing simulation for a single test case.\n    \"\"\"\n    active_nodes = list(range(n))\n    threshold_size = theta * n\n    \n    for t in range(n + 1):\n        # 1. Compute largest WCC size C^(t)\n        C_t = get_largest_wcc_size(W, active_nodes)\n        \n        # 2. Check failure condition\n        if C_t = threshold_size:\n            return t\n        \n        # This check is for the case when loop finishes after removing all nodes\n        if not active_nodes:\n            continue\n            \n        # 3. Compute PageRank\n        pi = compute_pagerank(W, active_nodes, d)\n        \n        # 4. Select node to remove\n        max_pi = -1.0\n        # Find the maximum PageRank value\n        if pi.size > 0:\n            max_pi = np.max(pi)\n\n        # Find all nodes that achieve this maximum value\n        candidates = []\n        for i, p_val in enumerate(pi):\n            if np.isclose(p_val, max_pi):\n                candidates.append(active_nodes[i])\n        \n        # Tie-break by choosing the smallest original index\n        node_to_remove = min(candidates)\n        \n        # 5. Update active set\n        active_nodes.remove(node_to_remove)\n    \n    # This part should not be reached given the problem constraints that\n    # C^{(n)} = 0, so the loop will always find a k* = n.\n    return n\n\ndef solve():\n    \"\"\"\n    Defines test cases and computes the failure time k* for each.\n    \"\"\"\n    # Case A\n    n_A = 4\n    W_A = np.zeros((n_A, n_A))\n    W_A[1, 0] = 1\n    W_A[2, 0] = 1\n    W_A[3, 0] = 1\n    d_A = 0.85\n    theta_A = 0.5\n    \n    # Case B\n    n_B = 5\n    W_B = np.zeros((n_B, n_B))\n    edges_B = [(0, 1), (1, 2), (2, 3), (3, 4), (4, 0)]\n    for i, j in edges_B:\n        W_B[i, j] = 1\n    d_B = 0.85\n    theta_B = 0.6\n    \n    # Case C\n    n_C = 6\n    W_C = np.ones((n_C, n_C)) - np.identity(n_C)\n    d_C = 0.9\n    theta_C = 0.5\n    \n    # Case D\n    n_D = 5\n    W_D = np.zeros((n_D, n_D))\n    edges_D = [(0, 1), (1, 0), (2, 3), (3, 4)]\n    for i, j in edges_D:\n        W_D[i, j] = 1\n    d_D = 0.85\n    theta_D = 0.8\n\n    test_cases = [\n        (n_A, W_A, d_A, theta_A),\n        (n_B, W_B, d_B, theta_B),\n        (n_C, W_C, d_C, theta_C),\n        (n_D, W_D, d_D, theta_D),\n    ]\n\n    results = []\n    for case in test_cases:\n        n, W, d, theta = case\n        k_star = solve_case(n, W, d, theta)\n        results.append(k_star)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2413880"}]}