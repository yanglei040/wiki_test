{"hands_on_practices": [{"introduction": "两阶段最小二乘法（2SLS）和广义矩估计（GMM）是工具变量估计的两个核心方法。本练习将通过编程，引导您从第一性原理出发，验证在同方差假设下两者在数值上的等价性([@problem_id:2402325])。这个过程不仅能加深您对两种方法内在机制的理解，还能在2SLS直观的投影解释与GMM更普适的矩条件框架之间建立起一座桥梁。", "problem": "考虑具有潜在内生回归变量的线性工具变量 (IV) 模型。令 $y \\in \\mathbb{R}^{n}$ 表示结果， $X \\in \\mathbb{R}^{n \\times k}$ 为回归变量矩阵， $Z \\in \\mathbb{R}^{n \\times \\ell}$ 为工具变量矩阵，其中 $\\ell \\ge k$。矩条件为 $E[Z^{\\top}(y - X\\beta)] = 0$，其中参数向量为 $\\beta \\in \\mathbb{R}^{k}$。广义矩估计 (GMM) 估计量最小化一个二次型，该二次型由 $Z$ 和残差构成的样本矩构成。在同方差性 (homoskedasticity) 的假设下，有效 GMM 估计量在数值上等价于两阶段最小二乘法 (2SLS)，但这必须通过从第一性原理推导估计量来证明，然后通过计算进行验证。你的任务是编写一个完整的、可运行的程序，该程序：\n\n- 实现一个满足 $E[Z^{\\top}u]=0$ 的数据生成过程 (DGP)，并允许 $X$ 通过构造具有内生性。\n- 为一个过度识别的 IV 模型实现两阶段最小二乘法 (2SLS) 估计量和 GMM 估计量，使用基于工具变量的同方差权重矩阵。\n- 通过报告一组测试用例（包括一个边界情况）中二者差异的欧几里得范数，来数值验证在同方差情况下，同方差最优 GMM 估计量在数值精度范围内等于 2SLS。\n\n你必须将你的推导和算法建立在以下基本定义和事实上：\n- IV 矩条件 $E[Z^{\\top}(y - X\\beta)] = 0$。\n- 由样本矩的二次型定义的 GMM 准则，其中使用一个正定权重矩阵。\n- 在同方差性下，最优 GMM 权重矩阵与工具变量二阶矩的逆成正比，该二阶矩可以通过 $Z$ 的样本二阶矩进行一致估计。\n\n不要在本问题陈述中使用或引用任何 IV 或 GMM 估计量的封闭形式表达式；你必须在你的解决方案中从上述定义出发进行推导。\n\n为每个测试用例在代码中实现的数据生成过程：\n- 从一个零均值的多元正态分布中抽取 $Z \\in \\mathbb{R}^{n \\times \\ell}$，其协方差为 $\\Sigma_{Z}$，其中对于指定的 $0 \\le \\rho < 1$，有 $(\\Sigma_{Z})_{ij} = \\rho^{|i-j|}$。\n- 抽取 $u \\in \\mathbb{R}^{n}$ 作为同方差噪声 $u \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$，且与 $Z$ 独立。\n- 抽取 $\\eta \\in \\mathbb{R}^{n \\times k}$，其元素为独立的标准正态分布，并选择一个固定的 $\\gamma \\in \\mathbb{R}^{k}$ 来引入内生性。\n- 用一个固定的矩阵 $\\Pi \\in \\mathbb{R}^{\\ell \\times k}$ 构造 $X = Z\\Pi + \\eta + u \\gamma^{\\top}$，以确保工具变量的相关性并通过 $u$ 保证 $X$ 的内生性。\n- 固定一个真实的参数向量 $\\beta \\in \\mathbb{R}^{k}$ 并生成 $y = X\\beta + u$。\n\n在代码中实现的估计量定义：\n- 两阶段最小二乘法 (2SLS)：使用由 $Z$ 所张成的工具变量空间上的投影，并计算 $\\beta$ 的 2SLS 估计值。\n- 广义矩估计 (GMM)：使用矩向量 $g_{n}(\\beta) = \\frac{1}{n} Z^{\\top}(y - X\\beta)$，在 $g_{n}(\\beta)$ 中最小化二次型，其正定权重矩阵 $W_{n}$ 在相差一个比例常数的情况下由 $Z$ 的样本二阶矩的逆矩阵给出。使用此方法计算 $\\beta$ 的同方差最优 GMM 估计值。\n\n对于每个测试用例，你的程序必须计算并返回 2SLS 和同方差最优 GMM 估计值之差的欧几里得范数，如果二者在数值上等价，该范数应接近于零。\n\n测试套件：\n- 案例 1 (过度识别，理想路径): $n = 1000$, $k = 2$, $\\ell = 4$, $\\rho = 0.3$, $\\sigma = 1.0$, 随机种子 $= 42$, $\\gamma = (0.4, -0.2)$, $\\beta = (1.0, -0.5)$。\n- 案例 2 (过度识别，工具变量中存在近似共线性): $n = 200$, $k = 2$, $\\ell = 4$, $\\rho = 0.95$, $\\sigma = 1.0$, 随机种子 $= 123$, $\\gamma = (0.5, 0.5)$, $\\beta = (0.7, 1.2)$。\n- 案例 3 (边界，恰好识别): $n = 800$, $k = 2$, $\\ell = 2$, $\\rho = 0.5$, $\\sigma = 0.8$, 随机种子 $= 7$, $\\gamma = (0.3, -0.1)$, $\\beta = (-0.2, 0.9)$。\n- 案例 4 (过度识别，小样本): $n = 50$, $k = 2$, $\\ell = 5$, $\\rho = 0.7$, $\\sigma = 1.0$, 随机种子 $= 99$, $\\gamma = (0.6, -0.4)$, $\\beta = (1.5, -1.0)$。\n\n实现要求：\n- 每个案例使用相同的随机种子，以确保结果可复现。\n- 在需要处理近似奇异矩阵时，使用 Moore–Penrose 伪逆来确保数值稳定性。\n- 所有计算必须以双精度浮点数进行。\n\n最终输出格式：\n- 你的程序应生成单行输出，包含一个含有 4 个浮点值的列表，每个值等于相应测试用例的欧几里得范数 $\\lVert \\hat{\\beta}_{\\text{2SLS}} - \\hat{\\beta}_{\\text{GMM, homo}} \\rVert_{2}$，顺序与上面列出的测试用例相同。该行必须严格格式化为 Python 列表，例如 $[\\text{result}_{1},\\text{result}_{2},\\text{result}_{3},\\text{result}_{4}]$。", "solution": "所提出的问题要求在同方差性条件下，推导并随后数值验证两阶段最小二乘法 (2SLS) 估计量与有效广义矩估计 (GMM) 估计量之间的等价性。在继续之前，必须对问题陈述进行严格的验证。\n\n首先，我们必须逐字提取给定的信息。\n模型是一个线性结构：$y = X\\beta + u$，其中 $y \\in \\mathbb{R}^{n}$ 是结果向量，$X \\in \\mathbb{R}^{n \\times k}$ 是回归变量矩阵，$\\beta \\in \\mathbb{R}^{k}$ 是待估计的参数向量，$u \\in \\mathbb{R}^{n}$ 是不可观测的误差项向量。\n一个工具变量矩阵 $Z \\in \\mathbb{R}^{n \\times \\ell}$ 可用，其中 $\\ell \\ge k$。\n基本矩条件由 $E[Z^{\\top}(y - X\\beta)] = 0$ 给出。\n问题指定了一个数据生成过程 (DGP)：\n- $Z$ 从多元正态分布 $\\mathcal{N}(0, \\Sigma_{Z})$ 中抽取，其中 $(\\Sigma_{Z})_{ij} = \\rho^{|i-j|}$。\n- $u$ 从 $\\mathcal{N}(0, \\sigma^{2} I_{n})$ 中抽取，且与 $Z$ 独立。\n- $\\eta \\in \\mathbb{R}^{n \\times k}$ 由独立的标准正态分布项组成。\n- 回归变量构造为 $X = Z\\Pi + \\eta + u \\gamma^{\\top}$，其中 $\\Pi \\in \\mathbb{R}^{\\ell \\times k}$ 是某个固定矩阵，$\\gamma \\in \\mathbb{R}^{k}$ 是某个固定向量。这种构造引入了内生性，因为如果 $\\gamma$ 的相应元素非零，则 $Cov(X_{j}, u) \\ne 0$。\n需要实现的估计量是：\n1.  两阶段最小二乘法 (2SLS)，由一个两步投影和回归过程定义。\n2.  广义矩估计 (GMM)，定义为二次型 $g_{n}(\\beta)^{\\top} W_{n} g_{n}(\\beta)$ 的最小化者，其中 $g_{n}(\\beta) = \\frac{1}{n} Z^{\\top}(y - X\\beta)$，且在同方差情况下，权重矩阵 $W_{n}$ 与 $(E[Z_i Z_i^{\\top}])^{-1}$ 成正比，并由 $(\\frac{1}{n}Z^{\\top}Z)^{-1}$ 估计。\n\n任务是为一组指定的测试用例，计算两个估计参数向量之差的欧几里得范数 $\\lVert \\hat{\\beta}_{\\text{2SLS}} - \\hat{\\beta}_{\\text{GMM, homo}} \\rVert_{2}$。\n\n现在，我们评估问题陈述的有效性。\n该问题具有**科学依据**。它植根于关于工具变量估计的基础计量经济学理论。2SLS、GMM、矩条件和内生性等概念都是标准的教科书内容。DGP 是一个用于模拟内生回归变量模型的有效构造。\n该问题是**适定 (well-posed) 的**。它提供了明确的目标和实现该目标所需的所有必要信息。在标准的满秩假设下，估计量的存在性和唯一性得到保证，而指定的随机数据生成过程很大概率会满足这些假设。数值验证的任务是明确无误的。问题没有指定矩阵 $\\Pi$，但正确地指出它应该是一个确保工具变量相关性的“固定矩阵”。选择这样的矩阵是标准模拟设置的一部分；一个固定的随机抽取是一种有效且可复现的方法。\n该问题是**客观的**。它使用精确的数学和统计语言，没有主观或含糊的术语。\n该问题满足所有有效性标准。没有科学缺陷，没有妨碍解决方案的缺失信息，也没有矛盾之处。因此，该问题被认为是**有效的**，我们可以继续进行求解。\n\n问题的核心是在同方差性下证明 2SLS 估计量和有效 GMM 估计量之间的代数等价性。我们从推导开始。\n\n我们首先推导 GMM 估计量。GMM 准则是最小化样本矩的二次型。令样本矩向量为 $g_n(\\beta) = \\frac{1}{n} Z^{\\top}(y - X\\beta)$。GMM 目标函数为 $J(\\beta) = g_n(\\beta)^{\\top} W_n g_n(\\beta)$，其中 $W_n$ 是一个正定权重矩阵。为方便计算，我们可以将 $1/n$ 缩放因子吸收到权重矩阵中，并最小化等价的目标函数：\n$$Q(\\beta) = (y - X\\beta)^{\\top}Z W Z^{\\top}(y - X\\beta)$$\n其中 $W$ 是一个权重矩阵。在同方差性以及 $u_i$ 和 $Z_i$ 独立的条件下，GMM 估计量的渐近方差的最优选择是通过一个权重矩阵 $W_n$ 实现的，该矩阵是 $(E[Z_i Z_i^{\\top}])^{-1}$ 的一致估计量。一个自然的样本类比是 $W_n = (\\frac{1}{n}Z^{\\top}Z)^{-1}$。将其代入目标函数（并忽略不影响最小化者的标量 $1/n$），我们设定 $W=(Z^{\\top}Z)^{-1}$。目标函数变为：\n$$Q(\\beta) = (y - X\\beta)^{\\top}Z (Z^{\\top}Z)^{-1} Z^{\\top}(y - X\\beta)$$\n我们定义矩阵 $P_Z = Z(Z^{\\top}Z)^{-1}Z^{\\top}$。这是到 $Z$ 的列空间上的正交投影矩阵。目标函数简化为：\n$$Q(\\beta) = (y - X\\beta)^{\\top}P_Z(y - X\\beta)$$\n这是关于 $\\beta$ 的一个二次函数。为了找到最小值，我们计算关于 $\\beta$ 的梯度并将其设为零。\n$$\\frac{\\partial Q(\\beta)}{\\partial \\beta} = \\frac{\\partial}{\\partial \\beta} \\left( y^{\\top}P_Z y - 2\\beta^{\\top}X^{\\top}P_Z y + \\beta^{\\top}X^{\\top}P_Z X \\beta \\right) = -2X^{\\top}P_Z y + 2X^{\\top}P_Z X \\beta$$\n将梯度设为零得到一阶条件：\n$$X^{\\top}P_Z X \\hat{\\beta}_{\\text{GMM}} = X^{\\top}P_Z y$$\n假设矩阵 $X^{\\top}P_Z X$ 是可逆的，则 GMM 估计量为：\n$$\\hat{\\beta}_{\\text{GMM}} = (X^{\\top}P_Z X)^{-1}X^{\\top}P_Z y$$\n在实现中，应使用数值稳定的方法（如 Moore-Penrose 伪逆）来计算逆矩阵，以处理潜在的近似奇异性，正如问题所规定的。\n\n接下来，我们推导 2SLS 估计量。该估计量通过普通最小二乘法 (OLS) 的两个相继阶段计算得出。\n**第一阶段：** 将回归变量矩阵 $X$ 的每一列对工具变量矩阵 $Z$ 进行回归。该回归的拟合值（我们记为 $\\hat{X}$）是 $X$ 在 $Z$ 的列空间上的投影。此回归的系数的 OLS 公式为 $\\hat{\\Pi} = (Z^{\\top}Z)^{-1}Z^{\\top}X$。因此，拟合值矩阵为：\n$$\\hat{X} = Z\\hat{\\Pi} = Z(Z^{\\top}Z)^{-1}Z^{\\top}X = P_Z X$$\n**第二阶段：** 将结果变量 $y$ 对第一阶段的拟合值 $\\hat{X}$ 进行回归。得到的 $\\beta$ 的 OLS 估计量即为 2SLS 估计量。\n$$\\hat{\\beta}_{\\text{2SLS}} = (\\hat{X}^{\\top}\\hat{X})^{-1}\\hat{X}^{\\top}y$$\n现在，将 $\\hat{X}$ 的表达式代入此公式。\n$$\\hat{\\beta}_{\\text{2SLS}} = ((P_Z X)^{\\top}(P_Z X))^{-1}(P_Z X)^{\\top}y$$\n投影矩阵 $P_Z$ 是对称的（$P_Z^{\\top} = P_Z$）和幂等的（$P_Z^2 = P_Z$）。利用这些性质，我们简化表达式中的项。\n第一项变为： $(\\hat{X}^{\\top}\\hat{X}) = (P_Z X)^{\\top}(P_Z X) = X^{\\top}P_Z^{\\top}P_Z X = X^{\\top}P_Z P_Z X = X^{\\top}P_Z X$。\n第二项变为： $\\hat{X}^{\\top}y = (P_Z X)^{\\top}y = X^{\\top}P_Z^{\\top}y = X^{\\top}P_Z y$。\n将这些简化形式代回 $\\hat{\\beta}_{\\text{2SLS}}$ 的表达式，得到：\n$$\\hat{\\beta}_{\\text{2SLS}} = (X^{\\top}P_Z X)^{-1}X^{\\top}P_Z y$$\n该表达式与为 $\\hat{\\beta}_{\\text{GMM}}$ 推导出的表达式完全相同。因此，理论上的等价性得以建立。\n\n任务的最后一部分是数值验证这种等价性。程序将实现所述的 DGP，然后根据各自的定义计算两种估计量，最后计算所得向量之间的欧几里得距离。\n对于 2SLS 估计量，代码将首先计算 $\\hat{X} = P_Z X$，然后在第二阶段回归公式 $\\hat{\\beta}_{\\text{2SLS}} = (\\hat{X}^{\\top}\\hat{X})^{-1}\\hat{X}^{\\top}y$ 中使用它。\n对于 GMM 估计量，代码将直接计算推导出的公式 $\\hat{\\beta}_{\\text{GMM}} = (X^{\\top}P_Z X)^{-1}X^{\\top}P_Z y$ 的各个组成部分。\n尽管在代数上是相同的，但这种独立的实现路径验证了两种概念上的程序在机器精度范围内产生相同的数值结果。使用 Moore-Penrose 伪逆 `np.linalg.pinv` 对于确保稳定性至关重要，尤其是在工具变量近似共线的案例 2 中，以及在所涉及的矩阵可能为方阵但病态的恰好识别案例 3 中。每个测试用例的固定随机种子确保了模拟数据和最终结果的可复现性。预期的结果是一组非常接近于零的范数差异值。", "answer": "```python\nimport numpy as np\n\ndef generate_toeplitz_covariance(dim, rho):\n    \"\"\"\n    Generates a Toeplitz covariance matrix Sigma_Z where Sigma_ij = rho^|i-j|.\n    \"\"\"\n    indices = np.arange(dim)\n    row_col_diff = np.abs(indices[:, np.newaxis] - indices)\n    return rho ** row_col_diff\n\ndef run_simulation(n, k, l, rho, sigma, seed, gamma, beta_true):\n    \"\"\"\n    Runs a single simulation to compute the difference between 2SLS and GMM estimators.\n    \n    Args:\n        n (int): Number of observations.\n        k (int): Number of regressors.\n        l (int): Number of instruments.\n        rho (float): Autocorrelation parameter for instruments.\n        sigma (float): Standard deviation of the error term.\n        seed (int): Random seed for reproducibility.\n        gamma (np.ndarray): Parameter vector for inducing endogeneity.\n        beta_true (np.ndarray): True parameter vector for the outcome equation.\n    \n    Returns:\n        float: The Euclidean norm of the difference between 2SLS and GMM estimates.\n    \"\"\"\n    # Set seed for reproducibility\n    rng = np.random.default_rng(seed)\n\n    # 1. Data-Generating Process (DGP)\n    # Generate covariance matrix for instruments Z\n    sigma_z = generate_toeplitz_covariance(l, rho)\n    # Generate instruments Z from a multivariate normal distribution\n    Z = rng.multivariate_normal(np.zeros(l), sigma_z, size=n, check_valid='warn') # Z is n x l\n\n    # Generate homoskedastic error term u\n    u = rng.normal(0, sigma, size=n) # u is (n,)\n\n    # Generate exogenous part of X\n    eta = rng.standard_normal(size=(n, k)) # eta is n x k\n\n    # Generate fixed Pi matrix for instrument relevance\n    # Pi is generated once per simulation run based on the seed\n    pi_matrix = rng.standard_normal(size=(l, k)) # Pi is l x k\n    \n    # Construct endogenous regressors X\n    # u is (n,), gamma is (k,). np.outer(u, gamma) gives an (n,k) matrix\n    endogeneity_term = np.outer(u, gamma)\n    X = Z @ pi_matrix + eta + endogeneity_term # X is n x k\n\n    # Generate outcome variable y\n    # X @ beta_true results in a vector of shape (n,)\n    y = X @ beta_true + u # y is (n,)\n\n    # 2. Estimation\n    # Both estimators use the projection matrix P_Z = Z @ inv(Z.T @ Z) @ Z.T\n    # We use pseudoinverse for numerical stability as required.\n    try:\n        ZtZ_inv = np.linalg.pinv(Z.T @ Z)\n    except np.linalg.LinAlgError:\n        # This case is unlikely with pinv but handled for robustness.\n        return np.nan\n\n    # For GMM, we can compute P_Z implicitly to save memory, though for the given n,\n    # explicit computation is fine.\n    # P_Z = Z @ ZtZ_inv @ Z.T\n\n    # 2a. Two-Stage Least Squares (2SLS) Estimator\n    # Stage 1: Project X onto the space of instruments Z to get X_hat\n    X_hat = Z @ ZtZ_inv @ (Z.T @ X)\n    \n    # Stage 2: Regress y on X_hat\n    try:\n        Xhat_t_Xhat = X_hat.T @ X_hat\n        Xhat_t_Xhat_inv = np.linalg.pinv(Xhat_t_Xhat)\n        beta_2sls = Xhat_t_Xhat_inv @ (X_hat.T @ y)\n    except np.linalg.LinAlgError:\n        beta_2sls = np.full(k, np.nan)\n\n    # 2b. Homoskedastic-Optimal GMM Estimator\n    # The derived formula is beta_gmm = (X.T @ P_Z @ X)^-1 @ (X.T @ P_Z @ y)\n    # Using P_Z = Z(Z'Z)^-1Z'\n    # And properties of P_Z (symmetric, idempotent): X.T @ P_Z @ X = X_hat.T @ X_hat\n    # And X.T @ P_Z @ y = X_hat.T @ y\n    # We will compute it via the GMM formula structure to verify the implementation path.\n    try:\n        X_t_PZ = X.T @ Z @ ZtZ_inv @ Z.T\n        X_t_PZ_X = X_t_PZ @ X\n        X_t_PZ_y = X_t_PZ @ y\n        \n        X_t_PZ_X_inv = np.linalg.pinv(X_t_PZ_X)\n        beta_gmm = X_t_PZ_X_inv @ X_t_PZ_y\n    except np.linalg.LinAlgError:\n        beta_gmm = np.full(k, np.nan)\n\n    # 3. Comparison\n    # Calculate the Euclidean norm of the difference\n    norm_diff = np.linalg.norm(beta_2sls - beta_gmm)\n    \n    return norm_diff\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # Case 1: n=1000, k=2, l=4, rho=0.3, sigma=1.0, seed=42, gamma=(0.4, -0.2), beta=(1.0, -0.5)\n        {\"n\": 1000, \"k\": 2, \"l\": 4, \"rho\": 0.3, \"sigma\": 1.0, \"seed\": 42, \n         \"gamma\": np.array([0.4, -0.2]), \"beta_true\": np.array([1.0, -0.5])},\n        \n        # Case 2: n=200, k=2, l=4, rho=0.95, sigma=1.0, seed=123, gamma=(0.5, 0.5), beta=(0.7, 1.2)\n        {\"n\": 200, \"k\": 2, \"l\": 4, \"rho\": 0.95, \"sigma\": 1.0, \"seed\": 123, \n         \"gamma\": np.array([0.5, 0.5]), \"beta_true\": np.array([0.7, 1.2])},\n        \n        # Case 3: n=800, k=2, l=2, rho=0.5, sigma=0.8, seed=7, gamma=(0.3, -0.1), beta=(-0.2, 0.9)\n        {\"n\": 800, \"k\": 2, \"l\": 2, \"rho\": 0.5, \"sigma\": 0.8, \"seed\": 7, \n         \"gamma\": np.array([0.3, -0.1]), \"beta_true\": np.array([-0.2, 0.9])},\n        \n        # Case 4: n=50, k=2, l=5, rho=0.7, sigma=1.0, seed=99, gamma=(0.6, -0.4), beta=(1.5, -1.0)\n        {\"n\": 50, \"k\": 2, \"l\": 5, \"rho\": 0.7, \"sigma\": 1.0, \"seed\": 99, \n         \"gamma\": np.array([0.6, -0.4]), \"beta_true\": np.array([1.5, -1.0])}\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_simulation(**case)\n        results.append(result)\n\n    # Format output as specified\n    # The repr() function provides high precision for floating-point numbers.\n    print(f\"[{','.join(map(repr, results))}]\")\n\nsolve()\n```", "id": "2402325"}, {"introduction": "一个有效的工具变量不仅需要满足外生性，还必须与内生变量相关，即具备“相关性”。本练习使用蒙特卡洛模拟，探讨使用“弱工具变量”（即相关性很弱的工具变量）的后果([@problem_id:2402339])。通过观察当工具变量相关性降低时统计检验功效如何随之减弱，您将对为何在任何IV分析中诊断工具变量强度（通常使用第一阶段$F$统计量）是如此关键的一步，获得切身的体会。", "problem": "构建一个程序，使用蒙特卡洛模拟来量化在线性工具变量设定中，弱工具变量如何影响零假设 $H_0:\\ \\beta=0$ 检验的经验功效。考虑以下针对单个内生回归量和单个工具变量（无截距项）的数据生成过程：\n- 对于每次重复和每个观测索引 $i \\in \\{1,\\dots,n\\}$，抽取 $z_i \\sim \\mathcal{N}(0,1)$。\n- 抽取独立的标准正态冲击 $e_{1i} \\sim \\mathcal{N}(0,1)$ 和 $e_{2i} \\sim \\mathcal{N}(0,1)$，并通过设置 $v_i = e_{1i}$ 和 $u_i = \\rho\\,e_{1i} + \\sqrt{1-\\rho^2}\\,e_{2i}$ 来构建相关系数为 $\\rho$ 的配对 $(v_i,u_i)$。\n- 设置 $x_i = \\pi\\,z_i + v_i$ 和 $y_i = \\beta\\,x_i + u_i$。\n\n对于每个大小为 $n$ 的模拟数据集，计算：\n1. 由样本矩条件 $\\frac{1}{n}\\sum_{i=1}^n z_i(y_i-\\beta x_i)=0$ 定义的 $\\beta$ 的恰好识别工具变量估计量，即\n$$\n\\hat{\\beta} = \\frac{\\sum_{i=1}^n z_i y_i}{\\sum_{i=1}^n z_i x_i}.\n$$\n2. 基于标量矩条件的相关联的常规大样本标准误，\n$$\n\\widehat{V}(\\hat{\\beta}) \\;=\\; \\frac{\\widehat{S}}{n\\,\\widehat{Q}^2},\\quad \\widehat{S}=\\frac{1}{n}\\sum_{i=1}^n (z_i\\hat{u}_i)^2,\\quad \\widehat{Q}=\\frac{1}{n}\\sum_{i=1}^n z_i x_i,\\quad \\hat{u}_i = y_i - \\hat{\\beta} x_i,\n$$\n以及相应的用于检验 $H_0:\\ \\beta=0$ 的检验统计量，\n$$\nT \\;=\\; \\frac{\\hat{\\beta}-0}{\\sqrt{\\widehat{V}(\\hat{\\beta})}}.\n$$\n使用基于标准正态分位数 $c_\\alpha$ 的双边拒绝法则，如果 $|T|>c_\\alpha$ 则拒绝 $H_0$，其中 $c_\\alpha$ 满足 $\\Pr(|Z|>c_\\alpha)=\\alpha$ 对于 $Z\\sim \\mathcal{N}(0,1)$。\n\n3. 在 $x_i$ 对 $z_i$ 的回归中（无截距项），用于检验工具变量相关性的第一阶段 $F$-统计量，由普通最小二乘斜率 $\\hat{a} = \\frac{\\sum_{i=1}^n z_i x_i}{\\sum_{i=1}^n z_i^2}$，残差 $r_i = x_i - \\hat{a} z_i$，残差方差 $\\hat{\\sigma}^2 = \\frac{1}{n-1}\\sum_{i=1}^n r_i^2$，标准误 $\\operatorname{se}(\\hat{a})=\\sqrt{\\hat{\\sigma}^2 / \\sum_{i=1}^n z_i^2}$，相应的 $t$-统计量 $t_1=\\hat{a}/\\operatorname{se}(\\hat{a})$，以及 $F = t_1^2$ 计算得出。\n\n对于下面的每个参数集，将上述步骤重复 $R$ 次独立实验，并报告：\n- 经验功效，定义为当真实 $\\beta$ 不等于 $0$ 时，在显著性水平 $\\alpha$ 下拒绝原假设的重复实验所占的比例。\n- $R$ 次重复实验中的平均第一阶段 $F$-统计量。\n\n使用以下参数值测试套件，每个都指定为一个元组 $(n,\\pi,\\rho,\\beta,\\alpha,R,\\text{seed})$：\n- 情况 A（强工具变量，较大样本）：$(500,\\,0.5,\\,0.6,\\,1.0,\\,0.05,\\,1000,\\,123)$。\n- 情况 B（弱工具变量，较大样本）：$(500,\\,0.05,\\,0.6,\\,1.0,\\,0.05,\\,1000,\\,456)$。\n- 情况 C（中等强度工具变量，较小样本）：$(100,\\,0.35,\\,0.6,\\,1.0,\\,0.05,\\,1000,\\,789)$。\n\n您的程序必须：\n- 完全按照描述实现模拟。\n- 对于每种情况，计算 $R$ 次重复实验中的经验功效和平均第一阶段 $F$-统计量。\n- 将报告的每个值四舍五入到三位小数。\n- 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果本身必须是按 $[\\text{功效}, \\text{平均F值}]$ 顺序排列的双元素列表。例如，一个包含三种情况的有效输出看起来像 $[[0.842,12.531],[0.121,1.472],[0.563,6.214]]$。\n\n不涉及物理单位。所有数值答案必须是纯数字。不涉及角度。百分比必须表示为小数，而不是带百分号。", "solution": "问题陈述经证实具有科学合理性、定义明确且客观。它提出了一个计算计量经济学中的标准练习，旨在分析弱工具变量对假设检验统计功效的影响。解决方案通过指定的蒙特卡洛模拟构建。\n\n模拟的核心是针对一个包含一个内生回归量 $x_i$ 和一个工具变量 $z_i$ 的线性模型的数据生成过程 (DGP)。该模型由两个方程定义：\n第一阶段方程 $x_i = \\pi z_i + v_i$ 将内生回归量 $x_i$ 与工具变量 $z_i$ 联系起来。参数 $\\pi$ 控制工具变量的强度。$\\pi$ 的值接近于零表示“弱工具变量”，意味着 $z_i$ 对 $x_i$ 的解释能力很弱。\n结构方程 $y_i = \\beta x_i + u_i$ 定义了结果变量 $y_i$。内生性源于误差项 $v_i$ 和 $u_i$ 是相关的，其相关性为 $\\text{Corr}(v_i, u_i) = \\rho$。这种相关性是通过独立标准正态冲击 $e_{1i} \\sim \\mathcal{N}(0,1)$ 和 $e_{2i} \\sim \\mathcal{N}(0,1)$ 显式构建的，具体设置为 $v_i = e_{1i}$ 和 $u_i = \\rho e_{1i} + \\sqrt{1-\\rho^2} e_{2i}$。这种相关性违反了普通最小二乘法中回归量与误差项不相关的假设，因此有必要使用工具变量估计量。\n\n对于一次模拟运行中的 $R$ 次重复实验，每次都会根据此 DGP 生成一个大小为 $n$ 的数据集。然后，计算以下量：\n\n1.  **工具变量估计量**：$\\beta$ 的恰好识别 IV 估计量由矩条件 $E[z_i(y_i - \\beta x_i)]=0$ 的样本模拟得出。这产生了表达式 $\\hat{\\beta} = \\left(\\sum_{i=1}^n z_i y_i\\right) / \\left(\\sum_{i=1}^n z_i x_i\\right)$。如果工具变量是有效的，即相关的（$\\pi \\neq 0$）和外生的（$E[z_i u_i] = 0$，这由构造保证），那么该估计量是 $\\beta$ 的一致估计量。\n\n2.  **假设检验**：对原假设 $H_0: \\beta=0$ 进行 $t$-检验。检验统计量为 $T = (\\hat{\\beta} - 0) / \\sqrt{\\widehat{V}(\\hat{\\beta})}$，其中 $\\widehat{V}(\\hat{\\beta})$ 是 $\\hat{\\beta}$ 的估计方差。所提供的方差公式 $\\widehat{V}(\\hat{\\beta}) = \\widehat{S} / (n \\widehat{Q}^2)$，其中 $\\widehat{S}=\\frac{1}{n}\\sum_{i=1}^n (z_i\\hat{u}_i)^2$ 且 $\\widehat{Q}=\\frac{1}{n}\\sum_{i=1}^n z_i x_i$，是一种异方差稳健形式。如果在显著性水平 $\\alpha$ 下，检验统计量的绝对值 $|T|$ 超过了来自标准正态分布的临界值 $c_\\alpha$，则拒绝原假设，其中 $c_\\alpha$ 由 $\\Pr(|Z| > c_\\alpha) = \\alpha$ 定义，对于 $Z \\sim \\mathcal{N}(0,1)$。该检验的经验功效是在模拟中真实值为 $\\beta \\neq 0$ 的情况下，$H_0$ 被正确拒绝的 $R$ 次重复实验所占的比例。\n\n3.  **第一阶段 F-统计量**：作为工具变量强度的诊断工具，计算了 $x_i$ 对 $z_i$ 的第一阶段回归的 $F$-统计量。因为只有一个工具变量，这等同于 $z_i$ 系数 $\\hat{a}$ 的 $t$-统计量的平方。这个 $t$-统计量是 $t_1 = \\hat{a} / \\operatorname{se}(\\hat{a})$。一个低的平均 $F$-统计量（通常，低于 10 的值被用作经验法则）是弱工具变量的一个广泛使用的指标。已知此类工具变量会导致许多问题，包括有限样本中 IV 估计量的偏差和检验规模的扭曲。\n\n该程序对三个不同的参数集实现了此模拟。这些情况旨在突出不同的情景：强工具变量（情况 A：$\\pi=0.5$）、弱工具变量（情况 B：$\\pi=0.05$）以及样本量较小的中等强度工具变量（情况 C：$n=100$，$\\pi=0.35$）。最终输出报告了每种情况下计算出的经验功效和平均第一阶段 $F$-统计量，从而定量地说明了工具变量强度和样本大小如何影响 IV 模型中统计推断的可靠性。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef run_simulation(n, pi, rho, beta, alpha, R, seed):\n    \"\"\"\n    Runs a Monte Carlo simulation for the instrumental variables model.\n\n    Args:\n        n (int): Sample size.\n        pi (float): Instrument strength parameter.\n        rho (float): Correlation between structural and first-stage errors.\n        beta (float): True coefficient of the endogenous regressor.\n        alpha (float): Significance level for the hypothesis test.\n        R (int): Number of repetitions.\n        seed (int): Seed for the random number generator.\n\n    Returns:\n        tuple: A tuple containing the empirical power and the average F-statistic.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    rejection_count = 0\n    total_f_stat = 0.0\n\n    # Calculate the two-sided critical value from the standard normal distribution.\n    c_alpha = norm.ppf(1 - alpha / 2)\n\n    for _ in range(R):\n        # Step 1: Generate data according to the DGP\n        z = rng.normal(loc=0, scale=1, size=n)\n        e1 = rng.normal(loc=0, scale=1, size=n)\n        e2 = rng.normal(loc=0, scale=1, size=n)\n\n        v = e1\n        u = rho * e1 + np.sqrt(1 - rho**2) * e2\n        x = pi * z + v\n        y = beta * x + u\n\n        # Step 2: Compute the IV estimator for beta\n        sum_zy = np.dot(z, y)\n        sum_zx = np.dot(z, x)\n        \n        # Avoid division by zero, though highly unlikely with continuous variables\n        if sum_zx == 0:\n            continue\n            \n        beta_hat = sum_zy / sum_zx\n\n        # Step 3: Compute the t-statistic for H_0: beta = 0\n        u_hat = y - beta_hat * x\n        Q_hat = sum_zx / n\n        S_hat = np.mean((z * u_hat)**2)\n        \n        # Denominator of variance estimator\n        var_denom = n * Q_hat**2\n        if var_denom == 0:\n            continue\n\n        V_hat_beta_hat = S_hat / var_denom\n        \n        # Ensure variance is non-negative before taking square root\n        if V_hat_beta_hat < 0:\n            continue\n        \n        se_beta_hat = np.sqrt(V_hat_beta_hat)\n        \n        if se_beta_hat == 0:\n            continue\n            \n        t_stat = beta_hat / se_beta_hat\n\n        # Step 4: Perform the hypothesis test\n        if np.abs(t_stat) > c_alpha:\n            rejection_count += 1\n\n        # Step 5: Compute the first-stage F-statistic\n        sum_zz = np.dot(z, z)\n        \n        if sum_zz == 0:\n            continue\n\n        a_hat = sum_zx / sum_zz\n        r = x - a_hat * z\n        sigma2_hat = np.sum(r**2) / (n - 1)\n        se_a_hat = np.sqrt(sigma2_hat / sum_zz)\n        \n        if se_a_hat == 0:\n            continue\n\n        t1_stat = a_hat / se_a_hat\n        f_stat = t1_stat**2\n        total_f_stat += f_stat\n\n    empirical_power = rejection_count / R\n    average_f_stat = total_f_stat / R\n\n    return empirical_power, average_f_stat\n\ndef solve():\n    \"\"\"\n    Main function to run simulations for all test cases and print results.\n    \"\"\"\n    test_cases = [\n        # (n, pi, rho, beta, alpha, R, seed)\n        (500, 0.5, 0.6, 1.0, 0.05, 1000, 123),  # Case A\n        (500, 0.05, 0.6, 1.0, 0.05, 1000, 456), # Case B\n        (100, 0.35, 0.6, 1.0, 0.05, 1000, 789), # Case C\n    ]\n\n    results = []\n    for case in test_cases:\n        power, avg_f = run_simulation(*case)\n        # Format each result pair to 3 decimal places\n        power_str = f\"{power:.3f}\"\n        avg_f_str = f\"{avg_f:.3f}\"\n        results.append(f\"[{power_str},{avg_f_str}]\")\n\n    # Format the final output string as a list of lists\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "2402339"}, {"introduction": "工具变量最核心的假设是“外生性”——它必须与结构方程中的误差项不相关。本练习直面这一假设被违反的情景，即工具变量本身是“坏的”或内生的([@problem_id:2402354])。通过推导并模拟由此产生的渐进偏误，您将精确地理解一个有瑕疵的工具变量会如何以及为何导致错误的结论，从而强化在研究中审慎论证外生性假设的重要性。", "problem": "考虑一个标量线性结构模型，其中一个经济结果由一个潜在的内生回归量和一个不可观测的扰动项生成。对于由 $i \\in \\{1,\\dots,N\\}$ 索引的每个观测值，其数据生成过程服从以下系统：\n1. 结构方程：$y_i = \\beta x_i + u_i$。\n2. 内生回归量的第一阶段方程：$x_i = \\pi w_i + \\gamma u_i + \\varepsilon_i$。\n3. 作为代理变量构建的、违反了排他性约束的候选工具变量：$z_i = w_i + \\rho u_i + \\nu_i$。\n\n所有随机变量均为实数值且均值为零。扰动项 $u_i$、$\\varepsilon_i$ 和 $\\nu_i$ 相互独立，且独立于 $w_i$。工具变量构建参数 $\\rho$ 调节 $z_i$ 和 $u_i$ 之间的相关程度，因此当 $|\\rho| > 0$ 时，矩条件 $\\mathbb{E}[z_i u_i] = 0$ 被违反。假设 $(w_i,u_i,\\varepsilon_i,\\nu_i)$ 在所有 $i$ 上是独立同分布的，其方差分别为 $\\operatorname{Var}(w_i) = \\sigma_w^2$、$\\operatorname{Var}(u_i) = \\sigma_u^2$、$\\operatorname{Var}(\\varepsilon_i) = \\sigma_\\varepsilon^2$ 和 $\\operatorname{Var}(\\nu_i) = \\sigma_\\nu^2$。\n\n您的任务是研究当使用单一有缺陷的工具变量 $z_i$ 通过两阶段最小二乘法（2SLS）估计参数 $\\beta$ 时产生的渐近偏误。请专注于无截距项的单工具变量、单回归量情形。\n\n您可以无需证明即假设以下基本前提：\n- 如果 $\\{a_i\\}_{i=1}^N$ 是独立同分布的，且 $\\mathbb{E}[a_i] = \\mu$，那么根据大数定律，当 $N \\to \\infty$ 时，$\\frac{1}{N}\\sum_{i=1}^N a_i \\to \\mu$ 依概率收敛。\n- 如果 $(a_i,b_i)$ 是独立同分布且平方可积的，那么当 $N \\to \\infty$ 时，$\\frac{1}{N}\\sum_{i=1}^N a_i b_i \\to \\mathbb{E}[a_i b_i]$ 依概率收敛。\n- 样本矩比率的概率极限等于相应概率极限的比率，前提是分母收敛到一个非零极限。\n\n您的程序必须执行以下步骤：\n1. 使用上述基本前提，推导单工具变量2SLS估计量 $\\hat{\\beta}_{\\text{IV}}$ 的概率极限（作为总体协方差的函数），并由此推导出渐近偏误 $B_\\infty = \\operatorname{plim}(\\hat{\\beta}_{\\text{IV}}) - \\beta$ 关于参数 $(\\rho,\\pi,\\gamma,\\sigma_u^2,\\sigma_w^2)$ 的闭式表达式。\n2. 实现一个随机模拟，对于一个大样本容量 $N$，该模拟抽取所有独立的 $w_i \\sim \\mathcal{N}(0,\\sigma_w^2)$、$u_i \\sim \\mathcal{N}(0,\\sigma_u^2)$、$\\varepsilon_i \\sim \\mathcal{N}(0,\\sigma_\\varepsilon^2)$ 和 $\\nu_i \\sim \\mathcal{N}(0,\\sigma_\\nu^2)$，根据上述系统构建 $x_i$、$y_i$ 和 $z_i$，并计算单工具变量2SLS估计量 $\\hat{\\beta}_{\\text{IV}} = \\frac{\\sum_{i=1}^N z_i y_i}{\\sum_{i=1}^N z_i x_i}$。在所有测试用例中使用相同的固定随机种子和相同的 $N$，通过模拟的绝对差值 $|\\hat{\\beta}_{\\text{IV}} - \\beta|$ 来近似渐近偏误的大小。此模拟需要用于数值验证您推导所蕴含的方向和数量级。\n3. 对于每个测试用例，还需使用给定的参数值，计算您在步骤1中推导所蕴含的渐近偏误的解析大小，即从总体协方差中获得的 $\\left|B_\\infty\\right|$。\n\n测试套件。在所有情况下，使用 $\\sigma_u^2 = 1$，$\\sigma_w^2 = 1$，$\\sigma_\\varepsilon^2 = 1$，$\\sigma_\\nu^2 = 1$，$\\beta = 1$，样本容量 $N = 200000$，以及固定的随机种子等于 $2025$。参数元组 $(\\pi,\\gamma,\\rho)$ 按用例变化如下：\n- 案例1：$(\\pi,\\gamma,\\rho) = (1.0, 0.5, 0.0)$。\n- 案例2：$(\\pi,\\gamma,\\rho) = (1.0, 0.5, 0.2)$。\n- 案例3：$(\\pi,\\gamma,\\rho) = (0.8, 0.4, -0.3)$。\n- 案例4：$(\\pi,\\gamma,\\rho) = (0.1, 0.5, -0.05)$。\n- 案例5：$(\\pi,\\gamma,\\rho) = (1.0, 0.3, 0.8)$。\n\n要求的最终输出。您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，列表中的每个条目是对应案例的渐近偏误的解析大小 $\\left|B_\\infty\\right|$，按上述顺序列出。将每个数字四舍五入到6位小数。例如，输出行的格式为 $[a_1,a_2,a_3,a_4,a_5]$，其中每个 $a_j$ 是一个四舍五入到6位小数的浮点数。\n\n本问题不涉及物理单位。", "solution": "问题陈述提出了计量经济学理论中的一个标准问题，即当工具变量的排他性约束被违反时，两阶段最小二乘法（2SLS）估计量的渐近性质。该问题定义明确、科学上合理且内部一致。这是一个关于推导和计算估计量概率极限的形式化练习。我将继续进行推导和后续的计算。\n\n该模型由每个观测值 $i$ 的以下方程组定义：\n1. 结构方程：$y_i = \\beta x_i + u_i$\n2. 第一阶段方程：$x_i = \\pi w_i + \\gamma u_i + \\varepsilon_i$\n3. 工具变量定义：$z_i = w_i + \\rho u_i + \\nu_i$\n\n随机变量 $w_i, u_i, \\varepsilon_i, \\nu_i$ 是独立同分布（i.i.d.）、相互独立的，均值为零，各自的方差为 $\\sigma_w^2, \\sigma_u^2, \\sigma_\\varepsilon^2, \\sigma_\\nu^2$。参数 $\\beta$ 是 $x_i$ 对 $y_i$ 的真实因果效应。回归量 $x_i$ 是内生的，因为只要 $\\gamma \\neq 0$，它就与结构误差项 $u_i$ 相关，即 $\\mathbb{E}[x_i u_i] = \\mathbb{E}[(\\pi w_i + \\gamma u_i + \\varepsilon_i)u_i] = \\gamma \\sigma_u^2$。只要 $\\rho \\neq 0$，工具变量 $z_i$ 就是无效的（非外生的），因为它与结构误差项的相关性非零：$\\mathbb{E}[z_i u_i] = \\mathbb{E}[(w_i + \\rho u_i + \\nu_i)u_i] = \\rho \\sigma_u^2$。\n\n无截距项的单工具变量、单回归量2SLS的 $\\beta$ 估计量由下式给出：\n$$\n\\hat{\\beta}_{\\text{IV}} = \\frac{\\sum_{i=1}^N z_i y_i}{\\sum_{i=1}^N z_i x_i}\n$$\n为了找到渐近偏误，我们首先推导当样本容量 $N \\to \\infty$ 时 $\\hat{\\beta}_{\\text{IV}}$ 的概率极限 ($\\operatorname{plim}$)。根据大数定律和连续映射定理（特别是对于比率的情况），估计量的概率极限是分子和分母中样本矩的概率极限之比：\n$$\n\\operatorname{plim}_{N \\to \\infty} \\hat{\\beta}_{\\text{IV}} = \\frac{\\operatorname{plim}_{N \\to \\infty} \\frac{1}{N}\\sum_{i=1}^N z_i y_i}{\\operatorname{plim}_{N \\to \\infty} \\frac{1}{N}\\sum_{i=1}^N z_i x_i} = \\frac{\\mathbb{E}[z_i y_i]}{\\mathbb{E}[z_i x_i]}\n$$\n期望 $\\mathbb{E}[z_i y_i]$ 和 $\\mathbb{E}[z_i x_i]$ 分别等价于协方差 $\\operatorname{Cov}(z_i, y_i)$ 和 $\\operatorname{Cov}(z_i, x_i)$，因为所有原始随机变量的均值都为零，这意味着 $\\mathbb{E}[x_i] = \\mathbb{E}[y_i] = \\mathbb{E}[z_i] = 0$。\n\n首先，我们计算分子 $\\mathbb{E}[z_i y_i]$。代入结构方程 $y_i = \\beta x_i + u_i$：\n$$\n\\mathbb{E}[z_i y_i] = \\mathbb{E}[z_i (\\beta x_i + u_i)] = \\beta \\mathbb{E}[z_i x_i] + \\mathbb{E}[z_i u_i]\n$$\n这个表达式依赖于另外两个矩。让我们来推导它们。\n\n第一个矩是分母项 $\\mathbb{E}[z_i x_i]$。代入 $z_i$ 和 $x_i$ 的定义：\n$$\n\\mathbb{E}[z_i x_i] = \\mathbb{E}[(w_i + \\rho u_i + \\nu_i)(\\pi w_i + \\gamma u_i + \\varepsilon_i)]\n$$\n展开乘积并应用期望算子，我们使用 $w_i, u_i, \\varepsilon_i, \\nu_i$ 的相互独立性和零均值性质。所有如 $\\mathbb{E}[w_i u_i]$、$\\mathbb{E}[w_i \\varepsilon_i]$ 等交叉乘积项均为零。唯一非零的项来自于变量平方的期望：\n$$\n\\mathbb{E}[z_i x_i] = \\pi \\mathbb{E}[w_i^2] + \\rho \\gamma \\mathbb{E}[u_i^2] = \\pi \\sigma_w^2 + \\rho \\gamma \\sigma_u^2\n$$\n这是工具变量和内生回归量之间的协方差。为使工具变量具有相关性，该协方差必须非零。\n\n第二个矩是 $\\mathbb{E}[z_i u_i]$，它量化了工具变量的内生性：\n$$\n\\mathbb{E}[z_i u_i] = \\mathbb{E}[(w_i + \\rho u_i + \\nu_i)u_i]\n$$\n同样，由于独立性，$\\mathbb{E}[w_i u_i] = 0$ 且 $\\mathbb{E}[\\nu_i u_i] = 0$。表达式简化为：\n$$\n\\mathbb{E}[z_i u_i] = \\rho \\mathbb{E}[u_i^2] = \\rho \\sigma_u^2\n$$\n现在，将这些矩代回到 $\\operatorname{plim} \\hat{\\beta}_{\\text{IV}}$ 的表达式中：\n$$\n\\operatorname{plim} \\hat{\\beta}_{\\text{IV}} = \\frac{\\beta(\\pi \\sigma_w^2 + \\rho \\gamma \\sigma_u^2) + \\rho \\sigma_u^2}{\\pi \\sigma_w^2 + \\rho \\gamma \\sigma_u^2} = \\beta + \\frac{\\rho \\sigma_u^2}{\\pi \\sigma_w^2 + \\rho \\gamma \\sigma_u^2}\n$$\n渐近偏误 $B_\\infty$ 定义为估计量的概率极限与真实参数值 $\\beta$ 之间的差值：\n$$\nB_\\infty = \\operatorname{plim} \\hat{\\beta}_{\\text{IV}} - \\beta = \\frac{\\rho \\sigma_u^2}{\\pi \\sigma_w^2 + \\rho \\gamma \\sigma_u^2}\n$$\n这是渐近偏误的闭式表达式。请注意，如果 $\\rho=0$，偏误为零，这对应于满足排他性约束 $\\mathbb{E}[z_i u_i] = 0$ 的有效工具变量的情况。\n\n给定的问题指定了参数值 $\\sigma_u^2 = 1$ 和 $\\sigma_w^2 = 1$。渐近偏误的公式简化为：\n$$\nB_\\infty = \\frac{\\rho}{\\pi + \\rho \\gamma}\n$$\n程序将为每个测试用例计算此量的绝对值 $\\left|B_\\infty\\right|$。按要求，该实现还包含一个随机模拟，它根据指定的过程生成数据并计算估计量 $\\hat{\\beta}_{\\text{IV}}$。这可以作为所推导的解析公式的数值验证，因为对于大样本容量 $N$，模拟偏误 $\\hat{\\beta}_{\\text{IV}} - \\beta$ 应该是对渐近偏误 $B_\\infty$ 的一个精确近似。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Derives and simulates the asymptotic bias of a 2SLS estimator with a faulty instrument.\n    \"\"\"\n    # Fixed parameters for all test cases\n    beta = 1.0\n    sigma_u2 = 1.0\n    sigma_w2 = 1.0\n    sigma_eps2 = 1.0\n    sigma_nu2 = 1.0\n    N = 200000\n    seed = 2025\n\n    # Parameter tuples (pi, gamma, rho) for each test case\n    test_cases = [\n        (1.0, 0.5, 0.0),\n        (1.0, 0.5, 0.2),\n        (0.8, 0.4, -0.3),\n        (0.1, 0.5, -0.05),\n        (1.0, 0.3, 0.8),\n    ]\n\n    # Generate base random shocks once using the fixed seed\n    # This ensures that the variation between test cases is due only to the parameters (pi, gamma, rho)\n    rng = np.random.default_rng(seed)\n    w = rng.normal(0, np.sqrt(sigma_w2), N)\n    u = rng.normal(0, np.sqrt(sigma_u2), N)\n    eps = rng.normal(0, np.sqrt(sigma_eps2), N)\n    nu = rng.normal(0, np.sqrt(sigma_nu2), N)\n    \n    analytical_results = []\n\n    for case in test_cases:\n        pi, gamma, rho = case\n\n        # Step 1: Analytical calculation of asymptotic bias\n        # B_inf = (rho * sigma_u^2) / (pi * sigma_w^2 + rho * gamma * sigma_u^2)\n        numerator = rho * sigma_u2\n        denominator = pi * sigma_w2 + rho * gamma * sigma_u2\n        \n        # The problem statement ensures the denominator is non-zero for all test cases.\n        if denominator == 0:\n            # This case represents an irrelevant instrument, where plim is undefined.\n            # Based on problem parameters, this should not be reached.\n            asymptotic_bias = float('nan') \n        else:\n            asymptotic_bias = numerator / denominator\n        \n        analytical_results.append(abs(asymptotic_bias))\n\n        # Step 2: Stochastic simulation for numerical validation (results not printed)\n        # This part of the code is required by the problem description to be implemented,\n        # but its output is not part of the final answer. It serves to verify the\n        # analytical derivation.\n        \n        # Construct model variables based on the current case's parameters\n        x = pi * w + gamma * u + eps\n        y = beta * x + u\n        z = w + rho * u + nu\n\n        # Compute the 2SLS estimator\n        sum_zy = np.sum(z * y)\n        sum_zx = np.sum(z * x)\n        \n        if sum_zx != 0:\n            beta_hat_iv = sum_zy / sum_zx\n            # The simulated bias for a large N should be close to the asymptotic bias\n            _simulated_bias = beta_hat_iv - beta # underscore to indicate it's not used in final output\n\n    # Format the final output as a comma-separated list of strings, rounded to 6 decimal places.\n    print(f\"[{','.join([f'{x:.6f}' for x in analytical_results])}]\")\n\nsolve()\n\n```", "id": "2402354"}]}