{"hands_on_practices": [{"introduction": "Metropolis-Hastings 算法的效率在很大程度上取决于其“探索”参数空间的方式，这需要在提议步长和接受率之间找到精妙的平衡。本练习 [@problem_id:2408760] 是一个思想实验，旨在帮助您建立关于提议步长大小如何影响 MCMC 链的自相关性及最终采样效率的直观理解。理解这种权衡关系是调试采样器并从有限的计算预算中获得高质量后验样本的关键第一步。", "problem": "考虑一个基于似然的资产定价模型中，标量结构参数 $\\theta$ 的贝叶斯估计。其后验密度 $\\pi(\\theta)$ 是适度的、单峰且大致呈钟形。你运行一个随机游走Metropolis马尔可夫链蒙特卡洛（MCMC）算法，其建议（proposal）为对称高斯分布，\n$$\n\\theta' \\,=\\, \\theta_t \\,+\\, \\varepsilon, \\quad \\varepsilon \\sim \\mathcal{N}(0, s^2),\n$$\n接受概率为\n$$\n\\alpha(\\theta_t,\\theta') \\,=\\, \\min\\!\\left\\{\\,1,\\, \\frac{\\pi(\\theta')}{\\pi(\\theta_t)} \\,\\right\\}。\n$$\n对于在平稳状态下长度为 $T$ 的两次独立的长时运行，你选择（i）一个相对于后验曲率过大的建议尺度 $s$，以及（ii）一个相对于后验曲率过小的建议尺度 $s$。令 $\\rho(k)$ 表示马尔可夫链 $\\{\\theta_t\\}_{t=1}^T$ 的滞后-$k$ 自相关函数（ACF），定义为\n$$\n\\rho(k) \\,=\\, \\frac{\\mathrm{Cov}(\\theta_t, \\theta_{t+k})}{\\mathrm{Var}(\\theta_t)}, \\quad k \\in \\{1,2,\\ldots\\}。\n$$\n哪种说法最能描述这两种情况下经验ACF和接受率的定性行为，以及其对有效样本量的影响？\n\nA. 在这两种情况下，$\\rho(1)$ 都是大的正数，并随 $k$ 缓慢衰减，但接受率不同：当 $s$ 过大时，接受率非常低，链表现出重复的状态；当 $s$ 过小时，接受率非常高，但连续的状态非常接近。在这两种情况下，积分自相关时间都很大，有效样本量都很小，只有在适中的 $s$ 值下才会改善。\n\nB. 当 $s$ 过大时，链会频繁地来回跳跃，产生负的 $\\rho(1)$；当 $s$ 过小时，大多数移动都被接受，因此对于所有 $k \\ge 1$，$\\rho(k) \\approx 0$，有效样本量最大化。\n\nC. 当 $s$ 极大时，ACF衰减最快，因为大的跳跃使链去相关，并且在这种情况下接受率很高，从而导致最大的有效样本量。\n\nD. 对于平稳运行，ACF $\\rho(k)$ 对于 $s$ 的选择是不变的；只有预烧期（burn-in）的长度受 $s$ 的影响。\n\nE. 对于对称建议，任何 $s$ 的接受率都等于0.5，这意味着在不同 $s$ 选择下观察到的 $\\rho(k)$ 的任何差异都是由蒙特卡洛误差引起的，而不是步长选择。", "solution": "这个问题要求对随机游走Metropolis（RWM）算法在两种极端的建议尺度 $s$ 选择下的性能进行定性分析。性能将通过接受率、生成链的自相关函数（ACF）以及由此产生的有效样本量（ESS）来表征。\n\n任何马尔可夫链蒙特卡洛（MCMC）算法的目标都是生成一个抽样序列 $\\{\\theta_t\\}_{t=1}^T$，其分布收敛于目标分布，在本例中即后验分布 $\\pi(\\theta)$。为了使从此链中得出的估计值（例如后验均值 $\\frac{1}{T}\\sum_{t=1}^T \\theta_t$）精确，我们需要一个大的有效样本量。ESS 定义为\n$$\n\\text{ESS} = \\frac{T}{1 + 2\\sum_{k=1}^{\\infty} \\rho(k)} = \\frac{T}{\\tau}\n$$\n其中 $T$ 是名义样本量，$\\tau = 1 + 2\\sum_{k=1}^{\\infty} \\rho(k)$ 是积分自相关时间（IAT）。为了在固定链长 $T$ 的情况下最大化ESS，必须最小化IAT。当自相关 $\\rho(k)$ 很小并且随着滞后 $k$ 的增加而迅速衰减到零时，就可以实现这一点。因此，采样器的效率与链中的持续性成反比。\n\nRWM算法使用建议 $\\theta' = \\theta_t + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, s^2)$。参数 $s$ 是一个关键的调整参数，它决定了算法的效率。让我们分析这两种指定的情况。\n\n情况（i）：建议尺度 $s$ 过大。\n在这种情况下，建议的跳跃 $\\varepsilon$ 很大。由于目标后验分布 $\\pi(\\theta)$ 是单峰且呈钟形的，它将其质量集中在众数周围一个相对较小的区域内。从当前状态 $\\theta_t$（在平稳状态下，很可能位于后验密度高的区域）进行一次大的跳跃，很可能会使建议值 $\\theta'$ 落入分布的尾部，那里的 $\\pi(\\theta')$ 非常小。\n因此，接受率 $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ 将远小于1。接受概率 $\\alpha(\\theta_t, \\theta') = \\min\\{1, \\frac{\\pi(\\theta')}{\\pi(\\theta_t)}\\}$ 因此会非常低。\n大多数建议都被拒绝，这意味着链在许多连续的迭代中都保持在当前状态：$\\theta_{t+1} = \\theta_t$。这种“卡住”的行为导致连续状态之间产生极高的正相关。因此，滞后-1自相关 $\\rho(1)$ 将非常接近1，整个ACF $\\rho(k)$ 将会极其缓慢地衰减。这导致非常大的IAT和非常小的ESS。该链探索后验空间的效率非常低。\n\n情况（ii）：建议尺度 $s$ 过小。\n在这种情况下，建议的跳跃 $\\varepsilon$ 很小。建议值 $\\theta'$ 将非常接近当前状态 $\\theta_t$。只要后验密度 $\\pi(\\theta)$ 是连续的（这是一个标准假设），$\\pi(\\theta')$ 将非常接近 $\\pi(\\theta_t)$。\n接受率 $\\frac{\\pi(\\theta')}{\\pi(\\theta_t)}$ 将非常接近1。因此，接受概率 $\\alpha(\\theta_t, \\theta')$ 将非常高，当 $s \\to 0$ 时接近1。\n尽管大多数建议都被接受，但每一步都非常微小。链在参数空间中移动，就像一个缓慢的扩散过程。$\\theta_{t+1}$ 与 $\\theta_t$ 只有微小的差别。这再次意味着连续状态是高度相关的。滞后-1自相关 $\\rho(1)$ 也将非常接近1，ACF $\\rho(k)$ 将非常缓慢地衰减。这也导致了大的IAT和小的ESS。该链探索后验空间的效率也非常低，但原因与情况（i）不同。\n\n总之，建议尺度 $s$ 的两个极端都对采样效率有害。最高效率（最小的IAT，最大的ESS）是在一个中间的 $s$ 值下实现的，该值平衡了接受率和步长，使链能够有效地探索后验分布的整个支撑集。对于像这样的一维问题，已知的最优接受率约为0.44。\n\n现在，我们评估所提供的选项。\n\nA. 在这两种情况下，$\\rho(1)$ 都是大的正数，并随 $k$ 缓慢衰减，但接受率不同：当 $s$ 过大时，接受率非常低，链表现出重复的状态；当 $s$ 过小时，接受率非常高，但连续的状态非常接近。在这两种情况下，积分自相关时间都很大，有效样本量都很小，只有在适中的 $s$ 值下才会改善。\n这个陈述准确地总结了上述推导的两种情况下的行为。它正确地指出了高正自相关是共同的病理现象，但正确地区分了其机制：对于大的 $s$ 是低接受率和“卡住”，对于小的 $s$ 是高接受率但步长微小。它正确地得出结论，两种情况都会导致较差的ESS，而ESS在中间的 $s$ 值时得到优化。这个陈述与MCMC的理论是一致的。\n结论：**正确**。\n\nB. 当 $s$ 过大时，链会频繁地来回跳跃，产生负的 $\\rho(1)$；当 $s$ 过小时，大多数移动都被接受，因此对于所有 $k \\ge 1$，$\\rho(k) \\approx 0$，有效样本量最大化。\n这个陈述在多个方面都是不正确的。首先，对于RWM，大的 $s$ 不会导致“来回跳跃”和负的 $\\rho(1)$。它会导致拒绝和停滞不前，从而产生高的*正*自相关。负自相关更像是其他采样器（如Gibbs或具有特定参数化的HMC）的特征。其次，对于小的 $s$，链移动缓慢，因此对于小的 $k$，$\\theta_t$ 和 $\\theta_{t+k}$ 高度相关，意味着 $\\rho(k)$ 接近1，而不是0。这会最小化而不是最大化有效样本量。\n结论：**不正确**。\n\nC. 当 $s$ 极大时，ACF衰减最快，因为大的跳跃使链去相关，并且在这种情况下接受率很高，从而导致最大的有效样本量。\n这个陈述在事实上是错误的。当 $s$ 极大时，接受率是极*低*的，而不是高的。虽然一次成功的大跳跃是去相关的，但链的行为被更频繁发生的拒绝事件所主导。其结果是一个缓慢混合的链，其ACF衰减非常缓慢，而不是最快。这导致了最小的，而不是最大的ESS。\n结论：**不正确**。\n\nD. 对于平稳运行，ACF $\\rho(k)$ 对于 $s$ 的选择是不变的；只有预烧期（burn-in）的长度受 $s$ 的影响。\n这从根本上是错误的。建议尺度 $s$ 定义了马尔可夫链的转移核。虽然平稳分布 $\\pi(\\theta)$ 对于 $s$ 是不变的（根据M-H算法的构造），但链的动态特性，如其收敛速度和在平稳状态下的自相关结构，都严重依赖于 $s$。调整 $s$ 正是为了优化这些由ACF衡量的动态特性。\n结论：**不正确**。\n\nE. 对于对称建议，任何 $s$ 的接受率都等于0.5，这意味着在不同 $s$ 选择下观察到的 $\\rho(k)$ 的任何差异都是由蒙特卡洛误差引起的，而不是步长选择。\n这个陈述是错误的。接受率不是一个常数0.5。它是一个通过比率 $\\pi(\\theta')/\\pi(\\theta_t)$ 与建议尺度 $s$ 相关的函数。关于最优接受率有众所周知的理论文献，这些率不是0.5（例如，高维时约为0.234，一维时约为0.44），但这些是通过*调整* $s$ 来实现的*目标*，而不是固定的常数。观察到的 $\\rho(k)$ 的差异是选择 $s$ 的直接和真实后果。\n结论：**不正确**。\n\n基于这一严谨的分析，只有选项A对这一现象提供了正确而完整的描述。", "answer": "$$\\boxed{A}$$", "id": "2408760"}, {"introduction": "在运行多个 MCMC 链后，一个核心问题是：我们如何判断它们是否已收敛到目标后验分布？Gelman-Rubin 诊断（或称 $\\hat{R}$）是回答此问题的标准工具，但它并非万无一失。本练习 [@problem_id:2408731] 构建了一个重要的警示案例，展示了在存在多峰分布的情况下，即使所有链都未能完全探索整个后验空间，$\\hat{R}$ 统计量也可能错误地显示收敛。这个例子强调了批判性地评估收敛性诊断结果的重要性，并提醒我们始终需要结合后验分布的可视化来做出最终判断。", "problem": "考虑一个计算经济学和金融学中的贝叶斯估计问题，其中标量结构参数 $\\theta$ 仅通过 $\\theta^{2}$ 进入似然函数（例如，因子定价方程中符号不确定的载荷），产生一个对称、分离良好的双峰后验分布\n$$\np(\\theta \\mid y) \\;=\\; \\tfrac{1}{2}\\,\\mathcal{N}\\!\\left(+\\mu,\\sigma^{2}\\right)\\;+\\;\\tfrac{1}{2}\\,\\mathcal{N}\\!\\left(-\\mu,\\sigma^{2}\\right),\n$$\n其中 $\\mu>0$，$\\sigma>0$，且 $\\mu/\\sigma$ 很大，使得两个峰分离良好。\n\n假设运行了 $m$ 条独立的马尔可夫链蒙特卡洛 (MCMC) 链，每条链在预烧期后的长度为 $n$，使用的核在一个峰内混合迅速，但极少穿越两峰之间的低后验区域。所有链都在 $+\\mu$ 附近初始化，并且在有限的运行时间内，从不访问另一个峰。因此，在预烧期后，可以认为抽样在链间是独立的，并且在每条链内是服从 $\\mathcal{N}\\!\\left(\\mu,\\sigma^{2}\\right)$ 的同分布。\n\n令 $\\bar{\\theta}_{j\\cdot}$ 表示链 $j\\in\\{1,\\dots,m\\}$ 的样本均值，$s_{j}^{2}$ 表示链 $j$ 的样本方差，$\\bar{\\theta}_{\\cdot\\cdot}$ 表示所有链的总均值。Gelman–Rubin 潜在尺度缩减因子 (PSRF)，也称为 Gelman–Rubin 诊断，定义如下\n$$\nW \\;=\\; \\frac{1}{m}\\sum_{j=1}^{m} s_{j}^{2},\\qquad\nB \\;=\\; \\frac{n}{m-1}\\sum_{j=1}^{m}\\left(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}\\right)^{2},\n$$\n$$\n\\widehat{\\operatorname{Var}}^{+} \\;=\\; \\frac{n-1}{n}\\,W \\;+\\; \\frac{1}{n}\\,B,\\qquad\n\\hat{R} \\;=\\; \\sqrt{\\frac{\\widehat{\\operatorname{Var}}^{+}}{W}}.\n$$\n\n当 $n\\to\\infty$ 且 $m$ 固定，并且上述所有假设都成立时，关于 $\\hat{R}$ 的哪一个陈述是正确的？\n\nA. $\\hat{R}$ 依概率收敛于 $1$，尽管链没有探索整个后验支撑集，因此该诊断未能检测出多峰问题。\n\nB. $\\hat{R}$ 收敛于 $\\sqrt{2}$，因为第二个峰未被访问，所以该诊断正确地标记了不收敛。\n\nC. 随着 $n$ 的增长，$\\hat{R}$ 发散到 $+\\infty$，因为 $B$ 随 $n$ 线性增长。\n\nD. $\\hat{R}$ 收敛于 $0$，因为对于大的 $n$，$W$ 主导 $B$。", "solution": "首先必须验证问题陈述的科学合理性和一致性。\n\n**步骤 1：提取已知条件**\n\n-   **后验分布：** $p(\\theta \\mid y) = \\frac{1}{2}\\,\\mathcal{N}(+\\mu,\\sigma^{2}) + \\frac{1}{2}\\,\\mathcal{N}(-\\mu,\\sigma^{2})$，其中 $\\theta$ 是一个标量参数，$\\mu > 0$，$\\sigma > 0$，且 $\\mu/\\sigma$ 很大。\n-   **MCMC 模拟：** $m$ 条独立的链，每条链在预烧期后的长度为 $n$。\n-   **链的行为：** 所有链都在 $+\\mu$ 附近初始化并停留在那里。对于每条链 $j \\in \\{1, \\dots, m\\}$，其抽样被视为来自 $\\mathcal{N}(\\mu, \\sigma^2)$ 的独立同分布 (i.i.d.) 样本。\n-   **统计量：**\n    -   链内均值： $\\bar{\\theta}_{j\\cdot} = \\frac{1}{n}\\sum_{i=1}^{n}\\theta_{ji}$。\n    -   链内样本方差： $s_{j}^{2} = \\frac{1}{n-1}\\sum_{i=1}^{n}(\\theta_{ji}-\\bar{\\theta}_{j\\cdot})^{2}$。\n    -   总均值： $\\bar{\\theta}_{\\cdot\\cdot} = \\frac{1}{m}\\sum_{j=1}^{m}\\bar{\\theta}_{j\\cdot}$。\n    -   平均链内方差： $W = \\frac{1}{m}\\sum_{j=1}^{m} s_{j}^{2}$。\n    -   链间方差因子： $B = \\frac{n}{m-1}\\sum_{j=1}^{m}(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot})^{2}$。\n    -   估计的后验方差： $\\widehat{\\operatorname{Var}}^{+} = \\frac{n-1}{n}\\,W + \\frac{1}{n}\\,B$。\n    -   潜在尺度缩减因子 (PSRF)： $\\hat{R} = \\sqrt{\\frac{\\widehat{\\operatorname{Var}}^{+}}{W}}$。\n-   **问题：** 确定当 $n\\to\\infty$ 且 $m$ 固定时 $\\hat{R}$ 的行为。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n该问题具有科学依据。它描述了 MCMC 采样器在多峰后验分布情境下一种常见且重要的失效模式。Gelman-Rubin 诊断 ($\\hat{R}$) 是评估 MCMC 收敛性的标准工具，其在此场景下的潜在失效是计算统计学中一个有充分文献记载的课题。所提供的 $W$、$B$、$\\widehat{\\operatorname{Var}}^{+}$ 和 $\\hat{R}$ 的定义都是标准的。整个设置是自洽的、数学上适定的和客观的。它在特定假设下，提出了一个关于统计量渐近行为的明确问题。\n\n**步骤 3：结论与行动**\n\n问题是有效的。将推导解答。\n\n**推导**\n\n目标是求出当 $n \\to \\infty$ 且 $m$ 固定时 $\\hat{R}$ 的极限。$\\hat{R}$ 的表达式可以改写为：\n$$\n\\hat{R} = \\sqrt{\\frac{\\frac{n-1}{n}\\,W + \\frac{1}{n}\\,B}{W}} = \\sqrt{\\frac{n-1}{n} + \\frac{B}{nW}}\n$$\n我们必须确定 $W$ 和 $B/n$ 的依概率收敛极限。\n\n1.  **链内方差 $W$ 的极限：**\n    对于每条链 $j$，抽样 $\\{\\theta_{j1}, \\dots, \\theta_{jn}\\}$ 是来自 $\\mathcal{N}(\\mu, \\sigma^2)$ 的独立同分布样本。样本方差 $s_j^2$ 是总体方差的一致估计量。根据大数定律，当 $n \\to \\infty$ 时：\n    $$\n    s_j^2 \\xrightarrow{p} \\operatorname{Var}(\\theta) = \\sigma^2\n    $$\n    其中 $\\xrightarrow{p}$ 表示依概率收敛。\n    由于 $W$ 是 $m$ 个这样的一致估计量的平均值（$m$ 固定），因此它也是 $\\sigma^2$ 的一个一致估计量：\n    $$\n    W = \\frac{1}{m}\\sum_{j=1}^{m} s_{j}^{2} \\xrightarrow{p} \\frac{1}{m}\\sum_{j=1}^{m} \\sigma^2 = \\sigma^2\n    $$\n\n2.  **链间方差项 $B/n$ 的极限：**\n    统计量 $B$ 由 $B = \\frac{n}{m-1}\\sum_{j=1}^{m}(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot})^{2}$ 给出。我们关心 $B/n$ 的行为：\n    $$\n    \\frac{B}{n} = \\frac{1}{m-1}\\sum_{j=1}^{m}\\left(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}\\right)^{2}\n    $$\n    这是链均值 $\\{\\bar{\\theta}_{1\\cdot}, \\dots, \\bar{\\theta}_{m\\cdot}\\}$ 的样本方差。\n    对于每条链 $j$，$\\bar{\\theta}_{j\\cdot}$ 是来自 $\\mathcal{N}(\\mu, \\sigma^2)$ 的 $n$ 个独立同分布抽样的样本均值。根据大数定律，当 $n \\to \\infty$ 时：\n    $$\n    \\bar{\\theta}_{j\\cdot} \\xrightarrow{p} E[\\theta] = \\mu\n    $$\n    总均值 $\\bar{\\theta}_{\\cdot\\cdot} = \\frac{1}{m}\\sum_{j=1}^{m}\\bar{\\theta}_{j\\cdot}$ 也依概率收敛于 $\\mu$。\n    因此，对于每个 $j$，差值 $(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}) \\xrightarrow{p} (\\mu - \\mu) = 0$。\n    由于这对和中的所有项都成立且 $m$ 是固定的，所以整个和收敛于 $0$：\n    $$\n    \\frac{B}{n} = \\frac{1}{m-1}\\sum_{j=1}^{m}\\left(\\bar{\\theta}_{j\\cdot}-\\bar{\\theta}_{\\cdot\\cdot}\\right)^{2} \\xrightarrow{p} 0\n    $$\n\n3.  **$\\hat{R}$ 的极限：**\n    现在我们可以组合求出 $\\hat{R}^2$ 的极限。当 $n \\to \\infty$ 时：\n    -   $\\frac{n-1}{n} \\to 1$。\n    -   $W \\xrightarrow{p} \\sigma^2$。\n    -   $B/n \\xrightarrow{p} 0$。\n    \n    对 $\\hat{R}^2$ 的表达式应用 Slutsky 定理：\n    $$\n    \\hat{R}^2 = \\frac{n-1}{n} + \\frac{B/n}{W} \\xrightarrow{p} 1 + \\frac{0}{\\sigma^2} = 1\n    $$\n    由于平方根函数在 $1$ 处是连续的，我们可以应用连续映射定理：\n    $$\n    \\hat{R} = \\sqrt{\\hat{R}^2} \\xrightarrow{p} \\sqrt{1} = 1\n    $$\n\n**解释与选项评估**\n\n分析表明 $\\hat{R}$ 收敛于 $1$。在实践中，$\\hat{R} \\approx 1$ 被用作诊断标准，以宣告 MCMC 链已收敛到目标平稳分布。\n\n然而，在所描述的场景中，这些链显然未能正确收敛。它们只探索了双峰后验分布中的一个峰。后验 $p(\\theta|y)$ 的真实方差是 $\\operatorname{Var}(\\theta) = E[\\theta^2] - (E[\\theta])^2 = (\\sigma^2 + \\mu^2) - 0^2 = \\sigma^2 + \\mu^2$。因为 $\\mu/\\sigma$ 很大，这个真实方差远大于 $\\sigma^2$。\n\n估计方差 $\\widehat{\\operatorname{Var}}^{+} = \\frac{n-1}{n}W + \\frac{1}{n}B$ 依概率收敛于 $\\sigma^2$。这个估计量严重低估了真实的后验方差。Gelman-Rubin 诊断将这个有缺陷的总方差估计值 ($\\widehat{\\operatorname{Var}}^{+}$) 与有缺陷的链内方差估计值 ($W$) 进行比较，发现它们渐近地相同 ($\\sigma^2$)，并得出它们的比率为 $1$ 的结论。这表明收敛，从而掩盖了 MCMC 采样器未能探索整个后验支撑集的关键失败。\n\n**逐项分析选项**\n\nA. **$\\hat{R}$ 依概率收敛于 $1$，尽管链没有探索整个后验支撑集，因此该诊断未能检测出多峰问题。**\n此陈述与我们的推导完全一致。$\\hat{R}$ 收敛于 $1$，而这个结果错误地表明了收敛，因此未能标记出采样器无法找到位于 $-\\mu$ 的峰。**正确**。\n\nB. **$\\hat{R}$ 收敛于 $\\sqrt{2}$，因为第二个峰未被访问，所以该诊断正确地标记了不收敛。**\n极限是 $1$，而不是 $\\sqrt{2}$。极限的前提是错误的。**错误**。\n\nC. **随着 $n$ 的增长，$\\hat{R}$ 发散到 $+\\infty$，因为 $B$ 随 $n$ 线性增长。**\n我们的分析表明 $B/n \\xrightarrow{p} 0$。这意味着 $B$ 不随 $n$ 线性增长。事实上，$B$ 依分布收敛到一个均值为 $\\sigma^2$ 的随机变量，并且不发散。因此，$\\hat{R}$ 不会发散。**错误**。\n\nD. **$\\hat{R}$ 收敛于 $0$，因为对于大的 $n$，$W$ 主导 $B$。**\n$\\hat{R}$ 的极限是 $1$，而不是 $0$。$\\hat{R}^2$ 中的首项是 $\\frac{n-1}{n}$，它趋近于 $1$。涉及 $B$ 的项消失了，但它并没有使总极限趋于 $0$。**错误**。", "answer": "$$\\boxed{A}$$", "id": "2408731"}, {"introduction": "掌握了 MCMC 的核心原理和诊断方法后，是时候将这些工具应用于真实的经济学问题了。相对风险规避系数（$\\gamma$）是宏观金融学中的一个核心结构性参数，但它无法被直接观测。本实践练习 [@problem_id:2408673] 将指导您如何运用 Metropolis-Hastings 算法，从消费与资产回报数据中估计这一关键参数，这是一个将理论模型与实证分析相结合的典型计算经济学研究任务。", "problem": "编写一个完整、可运行的程序，使用马尔可夫链蒙特卡洛 (MCMC) 方法，在基于消费的资产定价框架中为代表性代理人估计相对风险厌恶系数 $ \\gamma $。从跨期优化的核心一阶条件开始，该条件在恒定相对风险厌恶 (CRRA) 偏好下导出资产回报的欧拉方程：随机折现因子为 $ m_{t+1} = \\beta \\left( \\dfrac{C_{t+1}}{C_t} \\right)^{-\\gamma} $，无套利条件为 $ \\mathbb{E}_t \\left[ m_{t+1} R_{t+1} \\right] = 1 $，其中 $ \\beta \\in (0,1) $ 是折现因子，$ C_t $ 是消费，$ R_{t+1} $ 是在时间 $ t+1 $ 可观测到的总回报率。为将此条件与有限样本的含噪数据联系起来，假设欧拉残差存在一个加性正态测量方程，\n$$\n\\beta \\, G_t^{-\\gamma} \\, R_{t+1} - 1 = \\varepsilon_t, \\quad \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma^2),\n$$\n其中 $ G_t = \\dfrac{C_{t+1}}{C_t} $ 表示总消费增长率，$ \\sigma^2 $ 是一个已知的方差参数。假设 $ \\gamma $ 的先验分布为 Gamma 分布，形状参数为 $ k $，尺度参数为 $ \\theta $，即 $ \\gamma \\sim \\text{Gamma}(k,\\theta) $，其支撑集为 $ (0,\\infty) $。给定一个样本 $ \\{(G_t,R_{t+1})\\}_{t=1}^T $，使用 Metropolis–Hastings 算法对对数参数 $ z = \\log \\gamma $ 进行随机游走，从而从 $ \\gamma $ 的后验分布中抽样。在对数尺度上，提议为 $ z' = z + \\eta $，其中 $ \\eta \\sim \\mathcal{N}(0,s^2) $。\n\n你的程序必须：\n- 使用下面指定的数据生成过程 (DGP) 为每个测试用例模拟合成数据 $ (G_t, R_{t+1}) $。\n- 结合由测量方程所隐含的高斯似然和 $ \\gamma $ 的 Gamma 先验来构建后验核。\n- 在 $ z $ 空间中运行 Metropolis–Hastings 采样器（等价于对 $ \\gamma $ 进行对数正态随机游走），并在丢弃预烧期样本后计算 $ \\gamma $ 的后验均值估计。\n- 仅使用指定的随机种子以确保可复现性。\n\n每个测试用例的数据生成过程 (DGP)：\n- 生成消费增长率 $ G_t = \\exp(\\mu_c + \\sigma_c \\epsilon_t) $，其中 $ \\epsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,1) $。\n- 生成测量误差 $ \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0,\\sigma_e^2) $。\n- 通过逐期强制执行含噪欧拉方程来生成回报率：\n$$\nR_{t+1} = \\frac{1 + \\varepsilon_t}{\\beta \\, G_t^{-\\gamma_{\\text{true}}}}.\n$$\n每个测试用例的所有抽样都必须使用指定的种子。为确保确定性的可复现性，用给定的种子初始化一个伪随机数生成器用于模拟 $ G_t $ 和 $ R_{t+1} $，并用种子加上 $ +\\,10{,}000 $ 的值初始化第二个伪随机数生成器用于 Metropolis–Hastings 提议。本问题不涉及物理单位。\n\n对数参数的后验目标：\n- 定义 $ z = \\log \\gamma $。$ z $ 的目标密度与在 $ \\gamma = e^z $ 处评估的 Gamma 先验密度、残差的高斯似然以及由变量变换引起的雅可比项 $ e^z $ 的乘积成正比。你必须基于 $ z $ 的对数后验来实现 Metropolis–Hastings 接受准则。\n\n测试套件：\n对于以下三种情况，请使用提供的设置模拟数据并运行采样器。请完全按照下面给出的确切值进行操作。\n\n- 情况 A (理想情况):\n    - 种子 $ = 7 $\n    - 样本量 $ T = 200 $\n    - 真实风险厌恶 $ \\gamma_{\\text{true}} = 2.0 $\n    - 消费增长参数 $ \\mu_c = 0.01 $, $ \\sigma_c = 0.02 $\n    - 折现因子 $ \\beta = 0.99 $\n    - 测量标准差 $ \\sigma_e = 0.01 $\n    - $ \\gamma $ 的先验：Gamma 形状参数 $ k = 2.0 $，尺度参数 $ \\theta = 1.0 $\n    - Metropolis–Hastings：链长 $ N = 16000 $，预烧期 $ B = 4000 $，对数尺度提议标准差 $ s = 0.12 $\n\n- 情况 B (较低风险厌恶，更高噪声数据):\n    - 种子 $ = 101 $\n    - 样本量 $ T = 120 $\n    - 真实风险厌恶 $ \\gamma_{\\text{true}} = 0.5 $\n    - 消费增长参数 $ \\mu_c = 0.005 $, $ \\sigma_c = 0.015 $\n    - 折现因子 $ \\beta = 0.99 $\n    - 测量标准差 $ \\sigma_e = 0.02 $\n    - $ \\gamma $ 的先验：Gamma 形状参数 $ k = 1.5 $，尺度参数 $ \\theta = 1.0 $\n    - Metropolis–Hastings：链长 $ N = 16000 $，预烧期 $ B = 4000 $，对数尺度提议标准差 $ s = 0.15 $\n\n- 情况 C (较高风险厌恶，更重尾的先验):\n    - 种子 $ = 2025 $\n    - 样本量 $ T = 200 $\n    - 真实风险厌恶 $ \\gamma_{\\text{true}} = 5.0 $\n    - 消费增长参数 $ \\mu_c = 0.01 $, $ \\sigma_c = 0.02 $\n    - 折现因子 $ \\beta = 0.99 $\n    - 测量标准差 $ \\sigma_e = 0.01 $\n    - $ \\gamma $ 的先验：Gamma 形状参数 $ k = 2.0 $，尺度参数 $ \\theta = 2.0 $\n    - Metropolis–Hastings：链长 $ N = 16000 $，预烧期 $ B = 4000 $，对数尺度提议标准差 $ s = 0.12 $\n\n所需输出：\n- 对于每种情况，使用预烧期后保留的抽样计算 $ \\gamma $ 的后验均值。\n- 将每个后验均值四舍五入到恰好三位小数。\n- 你的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果（例如，$ [x_1,x_2,x_3] $）。\n\n不需要也不允许用户输入。程序必须是自包含的，并且在指定的种子和设置下是确定性的。最终输出为浮点数。请严格遵守 DGP 和上述贝叶斯构造，以确保科学真实性。", "solution": "所提出的问题是计算经济学中一个结构模型贝叶斯估计的适定性练习。它具有科学依据，内部一致，并为获得唯一、可验证的解提供了所有必要信息。因此，我们可以进行推导和实现。\n\n基本的经济关系是具有恒定相对风险厌恶 (CRRA) 偏好的代表性代理人的欧拉方程。效用函数为 $u(C) = \\frac{C^{1-\\gamma}}{1-\\gamma}$，其中 $\\gamma > 0$ 是相对风险厌恶系数。代理人进行最优跨期消费和资产配置的一阶条件意味着无套利条件 $\\mathbb{E}_t [m_{t+1} R_{t+1}] = 1$，其中 $R_{t+1}$ 是资产的总回报率，$m_{t+1}$ 是随机折现因子 (SDF)。对于 CRRA 效用，SDF 由 $m_{t+1} = \\beta \\left( \\frac{C_{t+1}}{C_t} \\right)^{-\\gamma}$ 给出，其中 $\\beta \\in (0,1)$ 是主观折现因子。将总消费增长率定义为 $G_t = C_{t+1}/C_t$，该条件变为 $\\mathbb{E}_t[\\beta G_t^{-\\gamma} R_{t+1}] = 1$。\n\n为了使该模型在有限的含噪样本数据 $D = \\{(G_t, R_{t+1})\\}_{t=1}^T$ 下易于实证处理，我们采用指定的测量方程：\n$$\n\\beta \\, G_t^{-\\gamma} \\, R_{t+1} - 1 = \\varepsilon_t, \\quad \\varepsilon_t \\stackrel{\\text{i.i.d.}}{\\sim} \\mathcal{N}(0, \\sigma_e^2)\n$$\n其中 $\\sigma_e^2$ 是欧拉方程误差的已知方差。此设定意味着观测数据的似然函数为高斯分布。对于给定的 $\\gamma$，单个观测值 $(G_t, R_{t+1})$ 的似然是在残差 $\\varepsilon_t$ 处评估的均值为 $0$、方差为 $\\sigma_e^2$ 的正态随机变量的概率密度。因此，整个样本的对数似然为：\n$$\n\\log L(\\gamma | D) = C_L - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-\\gamma} R_{t+1} - 1 \\right)^2\n$$\n其中 $C_L$ 是一个不依赖于 $\\gamma$ 的常数。\n\n我们要对 $\\gamma$ 进行贝叶斯推断。$\\gamma$ 的先验分布被指定为 Gamma 分布，$\\gamma \\sim \\text{Gamma}(k,\\theta)$，其概率密度函数为：\n$$\np(\\gamma|k, \\theta) = \\frac{1}{\\Gamma(k)\\theta^k} \\gamma^{k-1} e^{-\\gamma/\\theta}, \\quad \\text{for } \\gamma > 0\n$$\n对数先验（不含相加常数）为：\n$$\n\\log p(\\gamma|k,\\theta) = C_p + (k-1)\\log\\gamma - \\frac{\\gamma}{\\theta}\n$$\n根据贝叶斯定理，$\\gamma$ 的后验密度与似然和先验的乘积成正比，$p(\\gamma| D) \\propto L(\\gamma|D) p(\\gamma|k,\\theta)$。因此，对数后验与它们的对数之和成正比：\n$$\n\\log p(\\gamma|D) \\propto (k-1)\\log\\gamma - \\frac{\\gamma}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-\\gamma} R_{t+1} - 1 \\right)^2\n$$\n\n估计将使用 Metropolis-Hastings 算法进行。为满足约束 $\\gamma > 0$，我们进行变量替换，令 $z = \\log\\gamma \\in (-\\infty, \\infty)$，这意味着 $\\gamma = e^z$。变换后参数 $z$ 的后验密度由 $p(z|D) = p(\\gamma=e^z|D) \\left| \\frac{d\\gamma}{dz} \\right|$ 给出。此变换的雅可比行列式为 $\\left| \\frac{d(e^z)}{dz} \\right| = e^z$。因此，$z$ 的对数后验为：\n$$\n\\log p(z|D) \\propto \\log p(\\gamma=e^z|D) + \\log(e^z) = \\log p(\\gamma=e^z|D) + z\n$$\n将 $\\gamma = e^z$ 代入 $\\gamma$ 的对数后验表达式，并加上雅可比项 $z$，我们得到采样器的目标对数密度：\n$$\n\\pi(z) \\equiv \\log p(z|D) \\propto (k-1)z - \\frac{e^z}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta G_t^{-e^z} R_{t+1} - 1 \\right)^2 + z\n$$\n化简后，我们得到必须评估的核的最终形式：\n$$\n\\pi(z) \\propto kz - \\frac{e^z}{\\theta} - \\frac{1}{2\\sigma_e^2} \\sum_{t=1}^T \\left( \\beta R_{t+1} G_t^{-e^z} - 1 \\right)^2\n$$\n使用随机游走提议的 Metropolis-Hastings 算法实现如下：\n$1$. 在 $z^{(0)}$ 处初始化链。一个合理的起始点是先验均值的对数，$z^{(0)} = \\log(k\\theta)$。\n$2$. 对于每一步 $i=1, \\dots, N$：\n    a. 从对称提议分布中提议一个新状态 $z' = z^{(i-1)} + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, s^2)$。\n    b. 计算接受率 $A = \\frac{p(z'|D)}{p(z^{(i-1)}|D)}$。在对数项中，即为 $\\log A = \\pi(z') - \\pi(z^{(i-1)})$。\n    c. 以概率 $\\alpha = \\min(1, A)$ 接受该提议（设置 $z^{(i)} = z'$）。否则，拒绝该提议（设置 $z^{(i)} = z^{(i-1)}$）。\n$3$. 得到的序列 $\\{\\gamma^{(i)} = e^{z^{(i)}}\\}_{i=1}^N$ 是从 $\\gamma$ 的后验分布中抽取的一组样本。\n$4$. 丢弃初始的预烧期样本 $\\{ \\gamma^{(i)} \\}_{i=1}^B$ 后，$\\gamma$ 的后验均值通过剩余抽样的样本均值进行估计：\n$$\n\\hat{\\mathbb{E}}[\\gamma|D] = \\frac{1}{N-B} \\sum_{i=B+1}^N \\gamma^{(i)}\n$$\n此过程应用于三个测试用例中的每一个，使用根据指定的数据生成过程 (DGP) 生成的合成数据，并为数据生成和 MCMC 采样使用不同的随机数生成器种子以确保可复现性。最终结果是每种情况下 $\\gamma$ 的后验均值，并四舍五入到指定精度。", "answer": "```python\nimport numpy as np\n\ndef estimate_gamma(params):\n    \"\"\"\n    Simulates data and estimates the risk aversion coefficient gamma using MCMC.\n    \"\"\"\n    # Unpack parameters for conciseness\n    seed = params['seed']\n    T = params['T']\n    gamma_true = params['gamma_true']\n    mu_c = params['mu_c']\n    sigma_c = params['sigma_c']\n    beta = params['beta']\n    sigma_e = params['sigma_e']\n    k = params['k']\n    theta = params['theta']\n    N = params['N']\n    B = params['B']\n    s = params['s']\n\n    # 1. Data-Generating Process (DGP)\n    # Initialize a dedicated pseudo-random number generator for data simulation\n    rng_dgp = np.random.default_rng(seed)\n    \n    # Generate consumption growth G_t\n    eps_c = rng_dgp.standard_normal(T)\n    G = np.exp(mu_c + sigma_c * eps_c)\n    \n    # Generate returns R_{t+1} from the noisy Euler equation\n    eps_r = rng_dgp.normal(loc=0.0, scale=sigma_e, size=T)\n    R = (1.0 + eps_r) / (beta * G**(-gamma_true))\n\n    # Pre-calculate log(G) for efficiency in the sampler\n    G_log = np.log(G)\n\n    # 2. Define the Log-Posterior Kernel for z = log(gamma)\n    # The kernel is the log-posterior density up to an additive constant.\n    # log p(z|D) is proportional to:\n    # kz - exp(z)/theta - (1/(2*sigma_e^2)) * sum( (beta*R*G**(-exp(z)) - 1)**2 )\n    def log_posterior_kernel(z):\n        # Handle cases where z might lead to numerical instability\n        if np.isneginf(z): # Corresponds to gamma=0, which has zero prior probability\n            return -np.inf\n        \n        gamma = np.exp(z)\n        \n        if np.isinf(gamma): # z is too large, exp(z) overflows\n            return -np.inf\n        \n        # Log-prior for z (from Gamma prior on gamma + Jacobian term)\n        # log_prior is proportional to k*z - exp(z)/theta\n        log_prior = k * z - gamma / theta\n        \n        # Log-likelihood\n        # G**(-gamma) is numerically more stable as exp(-gamma * log(G))\n        residuals = beta * R * np.exp(-gamma * G_log) - 1.0\n        log_likelihood = -0.5 * np.sum(residuals**2) / (sigma_e**2)\n        \n        return log_prior + log_likelihood\n\n    # 3. Metropolis-Hastings Sampler\n    # Initialize a second PRNG for the MCMC proposals, as specified\n    rng_mcmc = np.random.default_rng(seed + 10000)\n    \n    # Sensible initial value from the prior mean\n    z_current = np.log(k * theta)\n    log_post_current = log_posterior_kernel(z_current)\n\n    gamma_chain = np.empty(N)\n\n    for i in range(N):\n        # Propose a new state using a random walk on the log-scale\n        z_proposal = z_current + rng_mcmc.normal(loc=0.0, scale=s)\n        \n        # Evaluate the log posterior at the proposal\n        log_post_proposal = log_posterior_kernel(z_proposal)\n        \n        # Calculate the log of the acceptance ratio\n        log_alpha = log_post_proposal - log_post_current\n        \n        # Accept or reject the proposal\n        if np.log(rng_mcmc.uniform())  log_alpha:\n            z_current = z_proposal\n            log_post_current = log_post_proposal\n        \n        # Store the current state of the chain (in terms of gamma)\n        gamma_chain[i] = np.exp(z_current)\n\n    # 4. Compute Posterior Mean\n    # Discard the burn-in samples and compute the mean of the rest\n    posterior_mean = np.mean(gamma_chain[B:])\n    \n    return posterior_mean\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        { # Case A\n            \"seed\": 7, \"T\": 200, \"gamma_true\": 2.0, \"mu_c\": 0.01, \"sigma_c\": 0.02,\n            \"beta\": 0.99, \"sigma_e\": 0.01, \"k\": 2.0, \"theta\": 1.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.12\n        },\n        { # Case B\n            \"seed\": 101, \"T\": 120, \"gamma_true\": 0.5, \"mu_c\": 0.005, \"sigma_c\": 0.015,\n            \"beta\": 0.99, \"sigma_e\": 0.02, \"k\": 1.5, \"theta\": 1.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.15\n        },\n        { # Case C\n            \"seed\": 2025, \"T\": 200, \"gamma_true\": 5.0, \"mu_c\": 0.01, \"sigma_c\": 0.02,\n            \"beta\": 0.99, \"sigma_e\": 0.01, \"k\": 2.0, \"theta\": 2.0,\n            \"N\": 16000, \"B\": 4000, \"s\": 0.12\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = estimate_gamma(case)\n        results.append(result)\n\n    # Format the output as a comma-separated list of floats with 3 decimal places\n    # enclosed in square brackets, with no trailing whitespace.\n    output_str = f\"[{','.join([f'{res:.3f}' for res in results])}]\"\n    print(output_str)\n\nsolve()\n```", "id": "2408673"}]}