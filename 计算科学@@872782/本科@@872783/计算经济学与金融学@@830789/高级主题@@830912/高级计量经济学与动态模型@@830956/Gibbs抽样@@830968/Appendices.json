{"hands_on_practices": [{"introduction": "吉布斯抽样的第一步是从联合分布中推导出全条件分布。这个练习将帮助你掌握一项核心技能：通过关注与目标变量相关的项，从复杂的联合概率密度函数中识别出已知分布的“核”。通过完成这个练习[@problem_id:1920315]，你将学会如何为一个双变量正态类模型建立吉布斯抽样器所需的条件分布。", "problem": "在一个统计模型中，已知两个连续随机变量 $X$ 和 $Y$ 的联合概率密度函数 (PDF) 与一个关于 $x$ 和 $y$ 的函数成正比。对于所有实数 $x$ 和 $y$，$f_{X,Y}(x,y)$ 定义的联合概率密度函数由以下关系式给出：\n$$\nf_{X,Y}(x,y) \\propto \\exp(-(x^2 - 2xy + 4y^2))\n$$\n从此类联合分布中生成样本的一个常用方法是吉布斯抽样，该方法需要从全条件分布中进行抽样。您的任务是确定在随机变量 $Y$ 取特定值 $y$ 的条件下，随机变量 $X$ 的全条件分布。\n\n下列哪一项正确描述了在给定 $Y=y$ 时 $X$ 的分布？\n\nA. 均值为 $y$，方差为 $1/2$ 的正态分布。\n\nB. 均值为 $y$，方差为 $1$ 的正态分布。\n\nC. 均值为 $2y$，方差为 $1/4$ 的正态分布。\n\nD. 均值为 $-y$，方差为 $1/2$ 的正态分布。\n\nE. 率参数为 $1/y$ 的指数分布。", "solution": "我们给定的联合密度正比于\n$$\nf_{X,Y}(x,y)\\propto \\exp\\big(-(x^{2}-2xy+4y^{2})\\big).\n$$\n对于给定 $Y=y$ 时 $X$ 的全条件分布，将 $y$ 视为固定值，并考虑关于 $x$ 的核：\n$$\nf_{X|Y}(x|y)\\propto f_{X,Y}(x,y)\\propto \\exp\\big(-(x^{2}-2xy+4y^{2})\\big).\n$$\n舍去不依赖于 $x$ 的因子，我们得到\n$$\nf_{X|Y}(x|y)\\propto \\exp\\big(-(x^{2}-2xy)\\big).\n$$\n对 $x$ 进行配方：\n$$\nx^{2}-2xy=(x-y)^{2}-y^{2},\n$$\n所以\n$$\n\\exp\\big(-(x^{2}-2xy)\\big)=\\exp\\big(-((x-y)^{2}-y^{2})\\big)=\\exp(y^{2})\\,\\exp\\big(-(x-y)^{2}\\big).\n$$\n因子 $\\exp(y^{2})$ 对于 $x$ 是常数，并被吸收到归一化常数中。所以，\n$$\nf_{X|Y}(x|y)\\propto \\exp\\big(-(x-y)^{2}\\big).\n$$\n与高斯核 $\\exp\\big(-\\frac{(x-\\mu)^{2}}{2\\sigma^{2}}\\big)$ 进行比较，我们确定\n$$\n\\mu=y,\\quad \\frac{1}{2\\sigma^{2}}=1\\;\\Rightarrow\\;\\sigma^{2}=\\frac{1}{2}.\n$$\n因此，$X|Y=y$ 服从均值为 $y$、方差为 $\\frac{1}{2}$ 的正态分布，这对应于选项 A。", "answer": "$$\\boxed{A}$$", "id": "1920315"}, {"introduction": "在推导出全条件分布之后，下一步就是利用它们来迭代生成样本。这个练习[@problem_id:1920320]模拟了吉布斯抽样器的一次完整迭代，你需要从给定的初始值出发，依次对每个变量进行抽样更新。通过这个动手实践，你将具体地了解抽样过程的机制，包括如何使用逆变换抽样法从指数分布和泊松分布中生成随机数。", "problem": "考虑一个二维随机向量 $(X, Y)$，其联合概率分布由以下全条件分布定义：\n- 给定 $Y=y$ 时 $X$ 的条件分布是速率参数为 $y$ 的指数分布。其概率密度函数为 $p(x|y) = y \\exp(-yx)$，其中 $x > 0$。\n- 给定 $X=x$ 时 $Y$ 的条件分布是均值参数为 $x$ 的泊松分布。其概率质量函数为 $p(y=k|x) = \\frac{x^k \\exp(-x)}{k!}$，其中 $k \\in \\{0, 1, 2, \\dots\\}$。\n\n您的任务是执行一次完整的吉布斯抽样。从初始状态 $(x^{(0)}, y^{(0)}) = (2, 3)$ 开始，您将生成一个新状态 $(x^{(1)}, y^{(1)})$。迭代过程如下：首先，从分布 $p(x|y^{(0)})$ 中为 $x^{(1)}$ 抽取一个样本；然后，使用这个新值 $x^{(1)}$，从分布 $p(y|x^{(1)})$ 中为 $y^{(1)}$ 抽取一个样本。\n\n为生成所需的随机变量，您必须使用逆变换抽样法。请使用以下从 Uniform(0,1) 分布中抽取的随机数：\n- 为生成 $x^{(1)}$，使用均匀随机数 $u_x = 0.600$。\n- 为生成 $y^{(1)}$，使用均匀随机数 $u_y = 0.750$。\n\n新状态 $(x^{(1)}, y^{(1)})$ 的数值是多少？$x^{(1)}$ 的值必须四舍五入到四位有效数字。", "solution": "我们使用逆变换抽样法执行一次吉布斯更新。\n\n1) 从 $p(x \\mid y^{(0)}=3)$ 中抽取 $x^{(1)}$。\n对于速率为 $y$ 的指数分布，其条件累积分布函数 (CDF) 为\n$$\nF(x \\mid y)=1-\\exp(-yx), \\quad x>0.\n$$\n逆变换抽样法使用 $u_{x}=F(x \\mid y)$，因此\n$$\nx^{(1)}=F^{-1}(u_{x})=-\\frac{1}{y^{(0)}}\\ln\\!\\bigl(1-u_{x}\\bigr).\n$$\n当 $y^{(0)}=3$ 且 $u_{x}=0.600$ 时，\n$$\nx^{(1)}=-\\frac{1}{3}\\ln(1-0.600)=-\\frac{1}{3}\\ln(0.4)=\\frac{1}{3}\\ln(2.5)\\approx 0.3054302439.\n$$\n四舍五入到四位有效数字：$x^{(1)}=0.3054$。\n\n2) 使用 $u_{y}=0.750$ 从 $p(y \\mid x^{(1)})$ 中抽取 $y^{(1)}$。\n对于均值为 $x$ 的泊松分布，其概率质量函数 (pmf) 为\n$$\np(y=k \\mid x)=\\frac{x^{k}\\exp(-x)}{k!}, \\quad k\\in\\{0,1,2,\\dots\\}.\n$$\n对于离散分布，逆变换抽样法选择满足 $F(k \\mid x)=\\sum_{j=0}^{k}p(j \\mid x)\\ge u_{y}$ 的最小整数 $k$。\n\n当 $x=x^{(1)}=\\frac{1}{3}\\ln(2.5)$ 时，计算\n$$\np(0 \\mid x)=\\exp(-x)=\\exp\\!\\Bigl(-\\tfrac{1}{3}\\ln(2.5)\\Bigr)=2.5^{-1/3}\\approx 0.7368.\n$$\n由于 $p(0 \\mid x)=0.7368<0.750$，我们继续计算 $k=1$ 的情况：\n$$\np(1 \\mid x)=x\\exp(-x)=x\\,2.5^{-1/3}\\approx 0.30543\\times 0.7368\\approx 0.2250.\n$$\n然后\n$$\nF(1 \\mid x)=p(0 \\mid x)+p(1 \\mid x)\\approx 0.7368+0.2250=0.9618>0.750,\n$$\n因此，满足 $F(k \\mid x)\\ge 0.750$ 的最小整数 $k$ 是 $1$。所以 $y^{(1)}=1$。\n\n因此，新状态为 $(x^{(1)},y^{(1)})=(0.3054,1)$，其中 $x^{(1)}$ 已四舍五入到四位有效数字。", "answer": "$$\\boxed{\\begin{pmatrix}0.3054  1\\end{pmatrix}}$$", "id": "1920320"}, {"introduction": "理论的最终目的是应用于解决实际问题。这个综合性练习[@problem_id:2398229]将吉布斯抽样应用于一个在计算经济学中常见的马尔可夫转换模型，用于识别GDP增长中的扩张和衰退周期。你需要实现一个完整的多模块吉布斯抽样器，这不仅能巩固你对算法的理解，还能让你体验到它在分析真实世界经济时间序列数据时的强大功能。", "problem": "给定一个用于季度实际国内生产总值（GDP）增长率的两状态马尔可夫区制转换模型，该模型旨在捕捉经济扩张和衰退两种区制。在时间 $t$ 的隐藏状态（记为 $s_t \\in \\{0,1\\}$）遵循一个时间同质的一阶马尔可夫链。在给定状态的条件下，观测到的增长率 $y_t$ 服从高斯分布，其均值依赖于区制，方差为已知的共同值。完整的模型设定如下：\n- 状态动态：$s_{t} \\mid s_{t-1} \\sim \\text{Categorical}\\left(P_{s_{t-1},\\cdot}\\right)$，转移矩阵为 $P = \\begin{pmatrix} p_{00}  1-p_{00} \\\\ 1-p_{11}  p_{11} \\end{pmatrix}$，其中 $p_{00} = \\mathbb{P}(s_t = 0 \\mid s_{t-1} = 0)$，$p_{11} = \\mathbb{P}(s_t = 1 \\mid s_{t-1} = 1)$。\n- 观测模型：$y_t \\mid s_t = k \\sim \\mathcal{N}(\\mu_k, \\sigma^2)$，对于 $k \\in \\{0,1\\}$ 和已知方差 $\\sigma^2$。\n- 先验分布：$\\mu_0 \\sim \\mathcal{N}(m_0, V_0)$，$\\mu_1 \\sim \\mathcal{N}(m_1, V_1)$，$p_{00} \\sim \\text{Beta}(a_{00}, b_{00})$，$p_{11} \\sim \\text{Beta}(a_{11}, b_{11})$。初始状态 $s_1$ 具有固定的先验概率 $\\mathbb{P}(s_1=0) = \\mathbb{P}(s_1=1) = 0.5$。\n\n您的任务是实现一个吉布斯抽样器，该抽样器交替进行以下操作：使用前向滤波-后向抽样（Forward-Filtering Backward-Sampling）对隐藏状态序列 $\\{s_t\\}_{t=1}^T$ 进行抽样，使用共轭高斯后验分布对区制均值 $\\mu_0$ 和 $\\mu_1$ 进行抽样，以及使用共轭 Beta 后验分布对转移概率 $p_{00}$ 和 $p_{11}$ 进行抽样。使用以下经过充分检验的事实和定义作为基本依据：\n- 用于条件概率的贝叶斯法则以及高斯分布和 Beta 分布的标准性质。\n- 一阶马尔可夫链的定义以及具有高斯发射的隐马尔可夫模型（HMM）结构。\n- 用于在 HMM 中抽样隐藏状态的前向滤波-后向抽样恒等式。\n\n对于下述每个测试用例，使用固定的随机种子、固定的迭代次数和指定的预烧期（burn-in）来运行吉布斯抽样器。在收敛预烧期之后，通过对预烧期后的抽样进行 Monte Carlo 频率计算，来估计每个时间的衰退边际后验概率 $\\hat{\\pi}_t = \\mathbb{P}(s_t = 1 \\mid y_{1:T})$。如果 $\\hat{\\pi}_t \\geq 0.5$，则将时间 $t$ 归类为衰退。对于每个测试用例，输出被归类为衰退的时间点总数。\n\n所有 GDP 增长值 $y_t$ 均以每季度的小数形式给出（例如，$0.008$ 表示小数形式的 $0.8$，而不是百分比）。最终答案中无需报告物理单位，因为要求的输出是计数。此问题不涉及角度。\n\n测试套件参数集：\n\n- 案例 A（区制分离清晰，中等持续性）：\n  - 观测值 $y_{1:20} = \\left(0.010, 0.008, 0.009, 0.007, 0.006, 0.007, -0.004, -0.006, -0.005, -0.007, -0.006, -0.004, 0.005, 0.006, 0.008, 0.009, 0.007, 0.006, 0.005, 0.007\\right)$。\n  - 已知方差 $\\sigma^2 = 0.000025$。\n  - 先验分布：$(m_0, V_0) = (0.007, 0.0001)$，$(m_1, V_1) = (-0.006, 0.0001)$，$(a_{00}, b_{00}) = (8, 2)$，$(a_{11}, b_{11}) = (8, 2)$。\n  - 吉布斯抽样器设置：迭代次数 $N = 6000$，预烧期 $B = 3000$，种子 $= 12345$。\n\n- 案例 B（单观测值边界情况，对称先验）：\n  - 观测值 $y_{1:1} = \\left(0.000\\right)$。\n  - 已知方差 $\\sigma^2 = 0.000025$。\n  - 先验分布：$(m_0, V_0) = (0.004, 0.0001)$，$(m_1, V_1) = (-0.004, 0.0001)$，$(a_{00}, b_{00}) = (5, 5)$，$(a_{11}, b_{11}) = (5, 5)$。\n  - 吉布斯抽样器设置：迭代次数 $N = 6000$，预烧期 $B = 3000$，种子 $= 12345$。\n\n- 案例 C（区制模糊，较低持续性的先验）：\n  - 观测值 $y_{1:12} = \\left(0.003, 0.004, 0.002, -0.001, 0.000, -0.002, -0.003, 0.001, 0.002, 0.003, -0.002, -0.001\\right)$。\n  - 已知方差 $\\sigma^2 = 0.000025$。\n  - 先验分布：$(m_0, V_0) = (0.002, 0.0002)$，$(m_1, V_1) = (-0.002, 0.0002)$，$(a_{00}, b_{00}) = (2, 2)$，$(a_{11}, b_{11}) = (2, 2)$。\n  - 吉布斯抽样器设置：迭代次数 $N = 6000$，预烧期 $B = 3000$，种子 $= 12345$。\n\n实现您的程序以完成以下任务：\n- 对于每种情况，使用指定的参数运行上述吉布斯抽样器。\n- 在预烧期之后，计算 $\\hat{\\pi}_t$ 作为样本中 $s_t = 1$ 的 Monte Carlo 频率。\n- 计算满足 $\\hat{\\pi}_t \\geq 0.5$ 的索引 $t$ 的数量。\n- 将对应于三种情况的三个整数计数汇总到一个列表中。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，例如 $[x_A,x_B,x_C]$，其中 $x_A$、$x_B$ 和 $x_C$ 分别是案例 A、案例 B 和案例 C 的整数计数。", "solution": "该问题要求为一个实际 GDP 增长率的两状态马尔可夫区制转换模型实现一个吉布斯抽样器。模型参数，包括特定区制的均值和状态转移概率，将在贝叶斯框架内从观测数据中进行估计。最终目标是根据后验概率将每个时间点分类为“衰退”状态（$s_t = 1$），并计算三个不同测试用例中此类时期的总数。\n\n该问题在科学上是适定的，提供了模型、先验、数据和所需算法的完整说明。它代表了马尔可夫链蒙特卡洛（MCMC）方法（特别是吉布斯抽样）在隐马尔可夫模型（HMM）上的标准应用，这是计算计量经济学中的一个常见任务。所有参数都已指定，任务明确。因此，该问题被认为是有效的，并将构建一个解决方案。\n\n解决方案的核心在于从未知的变量的完全条件后验分布中迭代抽样：隐藏状态序列 $\\{s_t\\}_{t=1}^T$、区制均值 $\\mu_0$ 和 $\\mu_1$，以及转移概率 $p_{00}$ 和 $p_{11}$。这个过程构成了吉布斯抽样器。\n\n设所有参数的集合为 $\\theta = \\{\\mu_0, \\mu_1, p_{00}, p_{11}\\}$，状态序列为 $S = \\{s_t\\}_{t=1}^T$。吉布斯抽样器通过初始化参数，然后迭代以下步骤来进行：\n1. 抽样 $S^{(i+1)} \\sim p(S \\mid y_{1:T}, \\theta^{(i)})$。\n2. 抽样 $\\mu_0^{(i+1)}, \\mu_1^{(i+1)} \\sim p(\\mu_0, \\mu_1 \\mid y_{1:T}, S^{(i+1)}, \\sigma^2)$。\n3. 抽样 $p_{00}^{(i+1)}, p_{11}^{(i+1)} \\sim p(p_{00}, p_{11} \\mid S^{(i+1)})$。\n\n每个步骤详述如下。\n\n**1. 抽样状态序列 $S = \\{s_t\\}_{t=1}^T$**\n\n状态序列是使用前向滤波-后向抽样（FFBS）算法从其条件后验分布 $p(S \\mid y_{1:T}, \\theta)$ 中抽样的。\n\n_前向滤波_：\n我们首先计算滤波概率 $\\alpha_t(k) = p(s_t = k, y_{1:t} \\mid \\theta)$，其中 $k \\in \\{0, 1\\}$ 且 $t=1, \\dots, T$。\n- **初始化 ($t=1$)**：初始状态先验给定为 $\\mathbb{P}(s_1=k) = 0.5$。滤波步骤从以下开始：\n  $$\n  \\alpha_1(k) = \\mathbb{P}(s_1=k) \\cdot p(y_1 \\mid s_1=k, \\theta) = 0.5 \\cdot \\mathcal{N}(y_1; \\mu_k, \\sigma^2)\n  $$\n  其中 $\\mathcal{N}(y; \\mu, \\sigma^2)$ 是正态分布的概率密度函数。\n- **递归 ($t=2, \\dots, T$)**：对于后续的时间步，使用马尔可夫属性更新滤波概率：\n  $$\n  \\alpha_t(k) = p(y_t \\mid s_t=k, \\theta) \\sum_{j=0}^{1} p(s_t=k \\mid s_{t-1}=j, \\theta) \\cdot \\alpha_{t-1}(j)\n  $$\n  $$\n  \\alpha_t(k) = \\mathcal{N}(y_t; \\mu_k, \\sigma^2) \\sum_{j=0}^{1} P_{jk} \\cdot \\alpha_{t-1}(j)\n  $$\n  其中 $P_{jk}$ 是从状态 $j$ 到状态 $k$ 的转移概率。为防止数值下溢，向量 $\\alpha_t = (\\alpha_t(0), \\alpha_t(1))$ 通常在每一步进行归一化。令 $\\hat{\\alpha}_t(k) = p(s_t=k \\mid y_{1:t}, \\theta) \\propto \\alpha_t(k)$。这种归一化不影响后向抽样步骤。\n\n_后向抽样_：\n在计算出直到 $T$ 的滤波概率后，我们按逆时间顺序对状态进行抽样。\n- **初始化 ($t=T$)**：从最终的滤波分布中抽样 $s_T$：\n  $$\n  p(s_T=k \\mid y_{1:T}, \\theta) \\propto \\alpha_T(k)\n  $$\n- **递归 ($t=T-1, \\dots, 1$)**：对于每个之前的时间步，在已抽样的未来状态 $s_{t+1}$ 和滤波概率的条件下抽样 $s_t$：\n  $$\n  p(s_t=j \\mid s_{t+1}=k, y_{1:T}, \\theta) \\propto p(s_{t+1}=k \\mid s_t=j) \\cdot p(s_t=j, y_{1:t}) \\propto P_{jk} \\cdot \\alpha_t(j)\n  $$\n  这给出了一个分类分布，从中抽取 $s_t$。\n\n**2. 抽样区制均值 $\\mu_k$**\n\n均值 $\\mu_0$ 和 $\\mu_1$ 在状态序列 $S$ 的条件下独立抽样。给定共轭先验设置（正态先验，正态似然），每个 $\\mu_k$ 的后验分布也是正态分布。\n设 $S$ 为抽样得到的状态序列。设 $Y_k = \\{y_t \\mid s_t = k\\}$ 是在状态 $k$ 中出现的观测值子集，并设 $T_k = |Y_k|$ 是此类观测值的数量。$\\mu_k$ 的先验分布是 $\\mathcal{N}(m_k, V_k)$。\n$\\mu_k$ 的后验分布为 $p(\\mu_k \\mid S, y_{1:T}) \\sim \\mathcal{N}(\\mu_{k, post}, V_{k, post})$，其中后验方差 $V_{k, post}$ 和后验均值 $\\mu_{k, post}$ 由下式给出：\n$$\nV_{k, \\text{post}} = \\left( \\frac{1}{V_k} + \\frac{T_k}{\\sigma^2} \\right)^{-1}\n$$\n$$\n\\mu_{k, \\text{post}} = V_{k, \\text{post}} \\left( \\frac{m_k}{V_k} + \\frac{1}{\\sigma^2} \\sum_{y_t \\in Y_k} y_t \\right)\n$$\n如果在某次迭代中未访问状态 $k$（即 $T_k=0$），则 $\\mu_k$ 的后验分布等于其先验分布 $\\mathcal{N}(m_k, V_k)$。我们从此后验分布中为 $\\mu_k$ 抽取一个新样本。\n\n**3. 抽样转移概率 $p_{kk}$**\n\n转移概率 $p_{00}$ 和 $p_{11}$ 在状态序列 $S$ 的条件下独立抽样。先验分布是 Beta 分布，它是状态转移的二项（或伯努利）似然的共轭先验。\n设 $N_{jk} = \\sum_{t=2}^T \\mathbb{I}(s_{t-1}=j, s_t=k)$ 为抽样序列 $S$ 中观测到的从状态 $j$ 到状态 $k$ 的转移次数。\n- $p_{00}$ 的先验分布是 $\\text{Beta}(a_{00}, b_{00})$。数据提供了 $N_{00}$ 次从状态 0 到 0 的转移和 $N_{01}$ 次从状态 0 到 1 的转移。$p_{00}$ 的后验分布是：\n  $$\n  p(p_{00} \\mid S) \\sim \\text{Beta}(a_{00} + N_{00}, b_{00} + N_{01})\n  $$\n- 类似地，$p_{11}$ 的后验分布是：\n  $$\n  p(p_{11} \\mid S) \\sim \\text{Beta}(a_{11} + N_{11}, b_{11} + N_{10})\n  $$\n我们从这些 Beta 后验分布中为 $p_{00}$ 和 $p_{11}$ 抽取新样本。如果 $T=1$，则没有转移，后验分布与先验分布相同。\n\n**4. 估计和分类**\n\n运行吉布斯抽样器进行 $N$ 次迭代并丢弃前 $B$ 次作为预烧期后，我们得到 $N-B$ 个来自联合后验分布的样本。在时间 $t$ 处于衰退状态（$s_t = 1$）的边际后验概率通过对状态序列的预烧期后样本 $\\{S^{(i)}\\}_{i=B+1}^N$ 进行 Monte Carlo 平均来估计：\n$$\n\\hat{\\pi}_t = \\mathbb{P}(s_t = 1 \\mid y_{1:T}) \\approx \\frac{1}{N-B} \\sum_{i=B+1}^{N} \\mathbb{I}(s_t^{(i)}=1)\n$$\n如果此估计概率大于或等于 $0.5$，则将时间点 $t$ 分类为衰退。每个测试用例的最终结果是归类为衰退的时间索引的总数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import norm\n\n# No other libraries outside the Python standard library are permitted.\n\ndef run_gibbs_sampler(y, sigma_sq, priors, settings):\n    \"\"\"\n    Runs a Gibbs sampler for the specified Markov-switching model.\n    \"\"\"\n    T = len(y)\n    m0, V0 = priors['mu0']\n    m1, V1 = priors['mu1']\n    a00, b00 = priors['p00']\n    a11, b11 = priors['p11']\n    \n    num_iter = settings['N']\n    burn_in = settings['B']\n    seed = settings['seed']\n    \n    rng = np.random.default_rng(seed)\n\n    # 1. Initialize parameters by drawing from priors\n    mu0 = rng.normal(m0, np.sqrt(V0))\n    mu1 = rng.normal(m1, np.sqrt(V1))\n    p00 = rng.beta(a00, b00)\n    p11 = rng.beta(a11, b11)\n    \n    # Storage for post-burn-in state samples\n    num_samples_to_store = num_iter - burn_in\n    if num_samples_to_store = 0:\n        raise ValueError(\"Number of iterations must be greater than burn-in.\")\n    state_samples = np.zeros((num_samples_to_store, T), dtype=np.int8)\n    \n    # 2. Gibbs sampling iterations\n    for i in range(num_iter):\n        mus = np.array([mu0, mu1])\n        P = np.array([[p00, 1.0 - p00], [1.0 - p11, p11]])\n\n        # a. Sample states S = {s_t} using Forward-Filtering Backward-Sampling (FFBS)\n        \n        # Forward filtering\n        alpha_hat = np.zeros((T, 2))\n        \n        # t=1\n        likelihood_1 = norm.pdf(y[0], loc=mus, scale=np.sqrt(sigma_sq))\n        # Initial state prob = 0.5 for both states\n        alpha_hat[0, :] = 0.5 * likelihood_1\n        sum_alpha = np.sum(alpha_hat[0, :])\n        if sum_alpha > 0:\n            alpha_hat[0, :] /= sum_alpha\n\n        # t > 1\n        for t in range(1, T):\n            likelihood_t = norm.pdf(y[t], loc=mus, scale=np.sqrt(sigma_sq))\n            alpha_hat[t, :] = likelihood_t * (alpha_hat[t-1, :] @ P)\n            sum_alpha = np.sum(alpha_hat[t, :])\n            if sum_alpha > 0:\n                alpha_hat[t, :] /= sum_alpha\n        \n        # Backward sampling\n        states = np.zeros(T, dtype=np.int8)\n        \n        # t=T\n        p_sT = alpha_hat[T-1, :]\n        states[T-1] = rng.choice([0, 1], p=p_sT)\n\n        # t  T\n        for t in range(T-2, -1, -1):\n            s_next = states[t+1]\n            p_st = alpha_hat[t, :] * P[:, s_next]\n            sum_p = np.sum(p_st)\n            if sum_p > 0:\n                 p_st /= sum_p\n            else: # Fallback if probabilities are zero\n                p_st = np.array([0.5, 0.5])\n            states[t] = rng.choice([0, 1], p=p_st)\n\n        # b. Sample means mu_k\n        y_s0 = y[states == 0]\n        T0 = len(y_s0)\n        if T0 > 0:\n            V0_inv = 1.0 / V0\n            sigma_sq_inv = 1.0 / sigma_sq\n            V0_post_inv = V0_inv + T0 * sigma_sq_inv\n            V0_post = 1.0 / V0_post_inv\n            mu0_post = V0_post * (V0_inv * m0 + sigma_sq_inv * np.sum(y_s0))\n            mu0 = rng.normal(mu0_post, np.sqrt(V0_post))\n        else: # Sample from prior if state is not visited\n            mu0 = rng.normal(m0, np.sqrt(V0))\n\n        y_s1 = y[states == 1]\n        T1 = len(y_s1)\n        if T1 > 0:\n            V1_inv = 1.0 / V1\n            sigma_sq_inv = 1.0 / sigma_sq\n            V1_post_inv = V1_inv + T1 * sigma_sq_inv\n            V1_post = 1.0 / V1_post_inv\n            mu1_post = V1_post * (V1_inv * m1 + sigma_sq_inv * np.sum(y_s1))\n            mu1 = rng.normal(mu1_post, np.sqrt(V1_post))\n        else:\n            mu1 = rng.normal(m1, np.sqrt(V1))\n\n        # c. Sample transition probabilities p_kk\n        if T > 1:\n            N00 = np.sum((states[:-1] == 0)  (states[1:] == 0))\n            N01 = np.sum((states[:-1] == 0)  (states[1:] == 1))\n            N11 = np.sum((states[:-1] == 1)  (states[1:] == 1))\n            N10 = np.sum((states[:-1] == 1)  (states[1:] == 0))\n            \n            p00 = rng.beta(a00 + N00, b00 + N01)\n            p11 = rng.beta(a11 + N11, b11 + N10)\n        else: # T=1, no transitions, sample from priors\n            p00 = rng.beta(a00, b00)\n            p11 = rng.beta(a11, b11)\n\n        # Store sample if past burn-in\n        if i >= burn_in:\n            state_samples[i - burn_in, :] = states\n\n    # 3. Post-processing\n    # Estimate marginal posterior probability of recession (state 1)\n    # This is the mean of the indicator variable (0 or 1) across samples\n    pi_hat = np.mean(state_samples, axis=0)\n    \n    # Classify as recession if prob >= 0.5 and count\n    recession_count = np.sum(pi_hat >= 0.5)\n    \n    return int(recession_count)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        { # Case A\n            'y': np.array([0.010, 0.008, 0.009, 0.007, 0.006, 0.007, -0.004, -0.006, -0.005, -0.007, -0.006, -0.004, 0.005, 0.006, 0.008, 0.009, 0.007, 0.006, 0.005, 0.007]),\n            'sigma_sq': 0.000025,\n            'priors': {'mu0': (0.007, 0.0001), 'mu1': (-0.006, 0.0001), 'p00': (8, 2), 'p11': (8, 2)},\n            'settings': {'N': 6000, 'B': 3000, 'seed': 12345}\n        },\n        { # Case B\n            'y': np.array([0.000]),\n            'sigma_sq': 0.000025,\n            'priors': {'mu0': (0.004, 0.0001), 'mu1': (-0.004, 0.0001), 'p00': (5, 5), 'p11': (5, 5)},\n            'settings': {'N': 6000, 'B': 3000, 'seed': 12345}\n        },\n        { # Case C\n            'y': np.array([0.003, 0.004, 0.002, -0.001, 0.000, -0.002, -0.003, 0.001, 0.002, 0.003, -0.002, -0.001]),\n            'sigma_sq': 0.000025,\n            'priors': {'mu0': (0.002, 0.0002), 'mu1': (-0.002, 0.0002), 'p00': (2, 2), 'p11': (2, 2)},\n            'settings': {'N': 6000, 'B': 3000, 'seed': 12345}\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_gibbs_sampler(case['y'], case['sigma_sq'], case['priors'], case['settings'])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2398229"}]}