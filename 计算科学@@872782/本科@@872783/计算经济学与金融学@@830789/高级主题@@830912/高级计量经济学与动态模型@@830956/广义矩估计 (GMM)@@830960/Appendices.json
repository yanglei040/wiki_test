{"hands_on_practices": [{"introduction": "为了坚实地理解广义矩估计 (GMM) 的原理，我们从一个基础练习开始。这个问题超越了标准的线性模型范例，在一个独特的循环数据 (circular data) 情景中展示 GMM 的核心思想。通过为一组角度数据推导平均方向的估计量，你将体会到 GMM 如何普适地应用其最小化样本矩准则的逻辑，仅需基本的解析工具即可得到一个清晰的闭式解 [@problem_id:2397110]。", "problem": "考虑一个计算金融学中的情景，其中周期性行为在单位圆上建模。您观察到 $T$ 个独立同分布的角度 $X_1, X_2, \\ldots, X_T \\in (-\\pi, \\pi]$，它们表示日内市场活动中一个潜在周期性因子的相位。真实相位参数为 $\\theta \\in (-\\pi, \\pi]$。模型所隐含的结构性矩条件是\n$$\n\\mathbb{E}\\!\\left[\\sin(X_t - \\theta)\\right] = 0.\n$$\n使用广义矩估计法（GMM），并采用单位权重矩阵（一个等于 $1$ 的标量），推导出估计量 $\\hat{\\theta}_T$ 关于样本 $\\{X_t\\}_{t=1}^T$ 的闭式解析表达式。假设 $\\sum_{t=1}^{T} \\cos(X_t) > 0$，从而使得估计量在主值范围 $(-\\pi, \\pi]$ 内被唯一确定。请以单一解析表达式的形式提供您的最终答案。无需四舍五入，且无适用单位。", "solution": "根据GMM的定义，我们旨在找到参数 $\\theta$ 的值，以最小化样本矩与理论矩（零）之间的二次距离。对于此问题，GMM的目标函数 $Q_T(\\theta)$ 使用单位权重矩阵（即标量1）定义为：\n$$\nQ_T(\\theta) = \\left( \\frac{1}{T} \\sum_{t=1}^{T} \\sin(X_t - \\theta) \\right)^2\n$$\n为了最小化 $Q_T(\\theta)$，我们等价于求解以下方程：\n$$\n\\frac{1}{T} \\sum_{t=1}^{T} \\sin(X_t - \\theta) = 0\n$$\n应用三角恒等式 $\\sin(A-B) = \\sin(A)\\cos(B) - \\cos(A)\\sin(B)$，我们得到：\n$$\n\\sum_{t=1}^{T} \\left( \\sin(X_t)\\cos(\\theta) - \\cos(X_t)\\sin(\\theta) \\right) = 0\n$$\n分离包含 $\\theta$ 的项：\n$$\n\\cos(\\theta) \\sum_{t=1}^{T} \\sin(X_t) = \\sin(\\theta) \\sum_{t=1}^{T} \\cos(X_t)\n$$\n假设 $\\sum_{t=1}^{T} \\cos(X_t) \\neq 0$，我们可以将两边同除以 $\\cos(\\theta)$ 和 $\\sum_{t=1}^{T} \\cos(X_t)$，得到：\n$$\n\\tan(\\theta) = \\frac{\\sum_{t=1}^{T} \\sin(X_t)}{\\sum_{t=1}^{T} \\cos(X_t)}\n$$\nGMM估计量 $\\hat{\\theta}_T$ 是该方程的解，因此由反正切函数给出：\n$$\n\\hat{\\theta}_T = \\arctan\\left(\\frac{\\sum_{t=1}^{T} \\sin(X_t)}{\\sum_{t=1}^{T} \\cos(X_t)}\\right)\n$$\n这与提供的答案相匹配。", "answer": "$$\n\\boxed{\\arctan\\left(\\frac{\\sum_{t=1}^{T} \\sin(X_t)}{\\sum_{t=1}^{T} \\cos(X_t)}\\right)}\n$$", "id": "2397110"}, {"introduction": "在掌握了 GMM 的基本方法后，我们现在将其应用于现代金融学中的一个核心问题：估计和检验资产定价模型。本练习将指导你模拟一个具有已知定价核 (pricing kernel) 的经济体，然后尝试使用 GMM 估计一个被刻意设定错误的模型。此处的关键洞察力在于，GMM 目标函数在最小值点的取值——即 J-统计量——可以作为一个强大的诊断工具，用于检测模型何时与数据不符 [@problem_id:2421339]。", "problem": "给定一个具有线性定价核的离散时间资产定价经济。设随机折现因子（SDF）由线性定价核定义\n$$ m_{t+1} = a - b^{\\prime} f_{t+1}, $$\n其中 $a \\in \\mathbb{R}$，$b \\in \\mathbb{R}^{K}$，并且 $f_{t+1} \\in \\mathbb{R}^{K}$ 是一个包含 $K$ 个经济因子的向量。资产定价的基本欧拉方程指出，对于任何总回报 $R_{t+1}$，\n$$ \\mathbb{E}\\left[ m_{t+1} R_{t+1} \\right] = 1. $$\n在整个问题中，假设 $K=2$，并假设因子向量是高斯分布的，并且在时间上是独立的，其分布为\n$$ f_{t+1} \\sim \\mathcal{N}(\\mu, \\Sigma), $$\n其中 $\\mu \\in \\mathbb{R}^{2}$ 且 $\\Sigma \\in \\mathbb{R}^{2 \\times 2}$ 是一个正定矩阵。\n\n有 $N$ 个风险资产，其回报由下式给出\n$$ R_{i,t+1} = c_i + d_i^{\\prime} f_{t+1} + u_{i,t+1}, \\quad i \\in \\{1,\\dots,N\\}, $$\n其中 $d_i \\in \\mathbb{R}^{2}$ 是资产 $i$ 的因子载荷，$c_i \\in \\mathbb{R}$ 是一个常数，而 $u_{i,t+1} \\sim \\mathcal{N}(0,\\sigma_{u,i}^{2})$ 在资产 $i$ 和时间 $t$ 上是独立的，并且独立于 $f_{t+1}$。此外，还有一个无风险资产，其总回报为恒定的 $R_{f}$。您必须确定 $c_i$ 和 $R_f$，使得欧拉方程在真实的SDF下精确成立，即\n$$ \\mathbb{E}\\left[m_{t+1} R_{i,t+1}\\right] = 1 \\quad \\text{for all } i \\in \\{1,\\dots,N\\}, \\quad \\text{and} \\quad \\mathbb{E}\\left[m_{t+1} R_{f}\\right] = 1. $$\n假设 $u_{i,t+1}$ 具有已知的标准差 $\\sigma_{u,i}$ 和零均值。\n\n您必须模拟样本 $\\{f_{t+1}\\}_{t=1}^{T}$ 和 $\\{u_{i,t+1}\\}_{t=1,i=1}^{T,N}$，生成 $\\{R_{i,t+1}\\}$ 和常数 $R_f$，然后尝试使用一个故意设定错误的模型来恢复SDF。具体来说，估计设定错误的SDF的参数 $\\theta = (\\alpha,\\beta) \\in \\mathbb{R}^{2}$\n$$ \\tilde{m}_{t+1}(\\theta) = \\alpha - \\beta \\cdot f_{1,t+1}, $$\n该模型仅使用第一个真实因子 $f_{1,t+1}$ 而忽略了第二个真实因子。使用广义矩估计（GMM），以单位权重矩阵和以下矩条件进行估计\n$$ \\mathbb{E}\\left[\\tilde{m}_{t+1}(\\theta) R_{j,t+1}\\right] = 1, \\quad j \\in \\{0,1,\\dots,N\\}, $$\n其中 $j=0$ 表示无风险资产，其回报 $R_{0,t+1} \\equiv R_{f}$，$j \\in \\{1,\\dots,N\\}$ 表示 $N$ 个风险资产。定义样本矩\n$$ g_{T,j}(\\theta) = \\frac{1}{T}\\sum_{t=1}^{T} \\tilde{m}_{t+1}(\\theta) R_{j,t+1} - 1, $$\n以及一步GMM目标函数\n$$ J_T(\\theta) = \\sum_{j=0}^{N} \\left[g_{T,j}(\\theta)\\right]^2. $$\n对于测试套件中的每一组参数，计算 $J_T(\\theta)$ 在 $\\theta \\in \\mathbb{R}^{2}$ 上的最小化子 $\\hat{\\theta}_T$，并报告最小值 $J_T(\\hat{\\theta}_T)$。\n\n所有量都是无单位的。不涉及角度。输出必须是实数。\n\n测试套件：\n每个测试案例指定 $(T,N,\\mu,\\Sigma,a,b,\\{d_i\\}_{i=1}^{N},\\sigma_{u,i},\\text{seed})$。对于以下所有案例，初始价格通过总回报隐式归一化，$\\sigma_{u,i}$ 对所有资产均相等，并由单个标准差 $\\sigma_u$ 指定，且 $K=2$。在所有案例中，通过施加真实SDF下的欧拉方程来内生地确定 $R_f$ 和 $c_i$。\n\n- 案例A（顺利路径下的模型设定错误）：\n  - $T = 3000$, $N = 6$, $\\text{seed} = 12345$.\n  - $\\mu = \\begin{bmatrix} 0.02 \\\\ 0.01 \\end{bmatrix}$, $\\Sigma = \\begin{bmatrix} 0.04  0.008 \\\\ 0.008  0.01 \\end{bmatrix}$.\n  - $a = 1.0$, $b = \\begin{bmatrix} 0.5 \\\\ 1.0 \\end{bmatrix}$.\n  - $d_1 = \\begin{bmatrix} 0.8 \\\\ 0.2 \\end{bmatrix}$, $d_2 = \\begin{bmatrix} 1.0 \\\\ -0.2 \\end{bmatrix}$, $d_3 = \\begin{bmatrix} -0.5 \\\\ 0.5 \\end{bmatrix}$, $d_4 = \\begin{bmatrix} 0.3 \\\\ 1.2 \\end{bmatrix}$, $d_5 = \\begin{bmatrix} 1.5 \\\\ -0.7 \\end{bmatrix}$, $d_6 = \\begin{bmatrix} -1.0 \\\\ -0.4 \\end{bmatrix}$.\n  - $\\sigma_u = 0.05$.\n\n- 案例B（边界情况：被忽略的因子没有风险价格）：\n  - $T = 3000$, $N = 6$, $\\text{seed} = 67890$.\n  - $\\mu = \\begin{bmatrix} 0.02 \\\\ 0.01 \\end{bmatrix}$, $\\Sigma = \\begin{bmatrix} 0.04  0.008 \\\\ 0.008  0.01 \\end{bmatrix}$.\n  - $a = 1.0$, $b = \\begin{bmatrix} 0.5 \\\\ 0.0 \\end{bmatrix}$.\n  - $d_1$ 到 $d_6$ 与案例A相同。\n  - $\\sigma_u = 0.05$.\n\n- 案例C（边缘情况：真实因子高度相关）：\n  - $T = 800$, $N = 6$, $\\text{seed} = 24680$.\n  - $\\mu = \\begin{bmatrix} 0.015 \\\\ 0.015 \\end{bmatrix}$, $\\Sigma = \\begin{bmatrix} 0.02  0.019 \\\\ 0.019  0.02 \\end{bmatrix}$.\n  - $a = 1.0$, $b = \\begin{bmatrix} 0.8 \\\\ 0.6 \\end{bmatrix}$.\n  - $d_1$ 到 $d_6$ 与案例A相同。\n  - $\\sigma_u = 0.05$.\n\n对于每个测试案例，您必须：\n- 根据指定的参数和种子模拟 $\\{f_{t+1}\\}_{t=1}^{T}$ 和 $\\{u_{i,t+1}\\}_{t=1,i=1}^{T,N}$。\n- 计算 $R_f$ 和 $\\{c_i\\}$，使得欧拉方程在真实的SDF下精确成立。\n- 使用指定的线性因子结构为所有风险资产生成 $\\{R_{i,t+1}\\}$。\n- 使用如上定义的设定错误的SDF和广义矩估计（GMM）来估计 $\\hat{\\theta}_T$，并计算 $J_T(\\hat{\\theta}_T)$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。该列表必须按 $[J_T(\\hat{\\theta}_T)\\text{ for Case A}, J_T(\\hat{\\theta}_T)\\text{ for Case B}, J_T(\\hat{\\theta}_T)\\text{ for Case C}]$ 的顺序排列。例如，一个语法上有效的输出看起来像 $[x_1,x_2,x_3]$，其中每个 $x_k$ 是一个实数。", "solution": "解决方案分三个阶段进行：\n1.  解析地确定无风险利率 $R_f$ 和常数 $c_i$。\n2.  模拟因子和回报数据。\n3.  通过GMM估计设定错误的模型的参数，并计算目标函数。\n\n**1. 确定 $R_f$ 和 $c_i$**\n\n常数 $R_f$ 和 $c_i$ 必须满足真实SDF下的欧拉方程，$m_{t+1} = a - b'f_{t+1}$。\n\n对于回报为 $R_f$ 的无风险资产：\n$$ \\mathbb{E}[m_{t+1} R_f] = 1 $$\n由于 $R_f$ 是常数，我们有 $R_f \\mathbb{E}[m_{t+1}] = 1$。SDF的期望是：\n$$ \\mathbb{E}[m_{t+1}] = \\mathbb{E}[a - b'f_{t+1}] = a - b'\\mathbb{E}[f_{t+1}] = a - b'\\mu $$\n因此，无风险利率是：\n$$ R_f = \\frac{1}{a - b'\\mu} $$\n\n对于第 $i$ 个风险资产，其回报为 $R_{i,t+1} = c_i + d_i' f_{t+1} + u_{i,t+1}$：\n$$ \\mathbb{E}[m_{t+1} R_{i,t+1}] = 1 $$\n$$ \\mathbb{E}[(a - b'f_{t+1})(c_i + d_i'f_{t+1} + u_{i,t+1})] = 1 $$\n展开期望，并利用 $f_{t+1}$ 和 $u_{i,t+1}$ 的独立性以及 $\\mathbb{E}[u_{i,t+1}]=0$：\n$$ \\mathbb{E}[a c_i + a d_i'f_{t+1} - c_i b'f_{t+1} - (b'f_{t+1})(d_i'f_{t+1})] = 1 $$\n利用期望的线性性质：\n$$ a c_i + a d_i'\\mathbb{E}[f_{t+1}] - c_i b'\\mathbb{E}[f_{t+1}] - \\mathbb{E}[(b'f_{t+1})(f_{t+1}'d_i)] = 1 $$\n代入 $\\mathbb{E}[f_{t+1}]=\\mu$ 和 $\\mathbb{E}[f_{t+1}f_{t+1}'] = \\Sigma + \\mu\\mu'$：\n$$ c_i(a - b'\\mu) + a d_i'\\mu - b'(\\Sigma + \\mu\\mu')d_i = 1 $$\n求解 $c_i$：\n$$ c_i(a - b'\\mu) = 1 - a d_i'\\mu + b'\\Sigma d_i + b'\\mu\\mu'd_i $$\n注意到 $a-b'\\mu = 1/R_f$ 且 $b'\\mu\\mu'd_i = (b'\\mu)(\\mu'd_i)$：\n$$ c_i = R_f \\left(1 - a (d_i'\\mu) + b'\\Sigma d_i + (b'\\mu)(\\mu'd_i)\\right) $$\n这些关于 $R_f$ 和 $c_i$ 的表达式允许我们构建与真实基础经济一致的资产回报。\n\n**2. 数据模拟**\n\n对于每个具有参数 $(T, N, \\mu, \\Sigma, a, b, \\{d_i\\}_{i=1}^{N}, \\sigma_u, \\text{seed})$ 的测试案例：\n- 使用指定的种子初始化一个随机数生成器。\n- 从多元正态分布 $\\mathcal{N}(\\mu, \\Sigma)$ 中抽取 $T$ 个向量 $\\{f_{t+1}\\}_{t=1}^T$。\n- 对于 $N$ 个资产中的每一个，从正态分布 $\\mathcal{N}(0, \\sigma_u^2)$ 中抽取 $T$ 个异质性冲击 $\\{u_{i,t+1}\\}_{t=1}^T$。\n- 使用上一步的公式计算常数 $R_f$ 和 $\\{c_i\\}_{i=1}^N$。\n- 使用 $R_{i,t+1} = c_i + d_i' f_{t+1} + u_{i,t+1}$ 生成风险资产回报的时间序列 $\\{R_{i,t+1}\\}_{t=1,i=1}^{T,N}$。\n\n**3. GMM估计**\n\n目标是找到最小化目标函数 $J_T(\\theta) = \\sum_{j=0}^{N} [g_{T,j}(\\theta)]^2$ 的 $\\hat{\\theta} = (\\hat{\\alpha}, \\hat{\\beta})'$。样本矩为：\n$$ g_{T,j}(\\theta) = \\frac{1}{T}\\sum_{t=1}^{T} (\\alpha - \\beta f_{1,t+1}) R_{j,t+1} - 1 $$\n该表达式对 $\\theta = (\\alpha, \\beta)'$ 是线性的。我们定义：\n$$ A_j = \\frac{1}{T}\\sum_{t=1}^{T} R_{j,t+1} \\quad \\text{and} \\quad B_j = \\frac{1}{T}\\sum_{t=1}^{T} f_{1,t+1} R_{j,t+1} $$\n那么，$g_{T,j}(\\theta) = \\alpha A_j - \\beta B_j - 1$。\n目标函数变为：\n$$ J_T(\\theta) = \\sum_{j=0}^{N} (\\alpha A_j - \\beta B_j - 1)^2 $$\n这是一个标准的线性最小二乘问题。我们希望找到能最好地求解以下 $N+1$ 个线性方程组的 $\\theta$：\n$$ A_j \\alpha - B_j \\beta = 1, \\quad j=0, \\dots, N $$\n以矩阵形式，我们寻求最小化 $\\|X\\theta - y\\|^2_2$，其中：\n$$ X = \\begin{pmatrix} A_0  -B_0 \\\\ A_1  -B_1 \\\\ \\vdots  \\vdots \\\\ A_N  -B_N \\end{pmatrix}, \\quad \\theta = \\begin{pmatrix} \\alpha \\\\ \\beta \\end{pmatrix}, \\quad y = \\begin{pmatrix} 1 \\\\ 1 \\\\ \\vdots \\\\ 1 \\end{pmatrix} $$\n矩阵 $X$ 的维度是 $(N+1) \\times 2$，$y$ 是一个 $(N+1)$ 维的全1向量。量 $A_j$ 和 $B_j$ 是从模拟数据中计算出来的。对于无风险资产（$j=0$），$R_{0,t+1} = R_f$ 是恒定的。\n\n最小二乘解 $\\hat{\\theta}_T$ 最小化这个目标函数。最小值 $J_T(\\hat{\\theta}_T)$ 是这个线性回归的残差平方和。对每个测试案例计算此值。\n\n实现将使用 `numpy.linalg.lstsq`，它为解决此问题提供了一种高效且数值稳定的方法，并直接返回残差平方和，这正是 $J_T(\\hat{\\theta}_T)$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the GMM estimation problem for the three specified test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"name\": \"Case A\",\n            \"T\": 3000, \"N\": 6, \"seed\": 12345,\n            \"mu\": np.array([0.02, 0.01]),\n            \"Sigma\": np.array([[0.04, 0.008], [0.008, 0.01]]),\n            \"a\": 1.0, \"b\": np.array([0.5, 1.0]),\n            \"d\": np.array([\n                [0.8, 0.2], [1.0, -0.2], [-0.5, 0.5],\n                [0.3, 1.2], [1.5, -0.7], [-1.0, -0.4]\n            ]),\n            \"sigma_u\": 0.05\n        },\n        {\n            \"name\": \"Case B\",\n            \"T\": 3000, \"N\": 6, \"seed\": 67890,\n            \"mu\": np.array([0.02, 0.01]),\n            \"Sigma\": np.array([[0.04, 0.008], [0.008, 0.01]]),\n            \"a\": 1.0, \"b\": np.array([0.5, 0.0]),\n            \"d\": np.array([\n                [0.8, 0.2], [1.0, -0.2], [-0.5, 0.5],\n                [0.3, 1.2], [1.5, -0.7], [-1.0, -0.4]\n            ]),\n            \"sigma_u\": 0.05\n        },\n        {\n            \"name\": \"Case C\",\n            \"T\": 800, \"N\": 6, \"seed\": 24680,\n            \"mu\": np.array([0.015, 0.015]),\n            \"Sigma\": np.array([[0.02, 0.019], [0.019, 0.02]]),\n            \"a\": 1.0, \"b\": np.array([0.8, 0.6]),\n            \"d\": np.array([\n                [0.8, 0.2], [1.0, -0.2], [-0.5, 0.5],\n                [0.3, 1.2], [1.5, -0.7], [-1.0, -0.4]\n            ]),\n            \"sigma_u\": 0.05\n        }\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        # Unpack parameters\n        T, N, seed = case[\"T\"], case[\"N\"], case[\"seed\"]\n        mu, Sigma = case[\"mu\"], case[\"Sigma\"]\n        a, b = case[\"a\"], case[\"b\"]\n        d_matrices = case[\"d\"]\n        sigma_u = case[\"sigma_u\"]\n\n        rng = np.random.default_rng(seed=seed)\n\n        # 1. Analytical determination of Rf and c_i\n        b_mu = b @ mu\n        Rf = 1.0 / (a - b_mu)\n        \n        c_i = np.zeros(N)\n        for i in range(N):\n            d_i = d_matrices[i]\n            d_i_mu = d_i @ mu\n            b_Sigma_d = b @ Sigma @ d_i\n            c_i[i] = Rf * (1.0 - a * d_i_mu + b_Sigma_d + b_mu * d_i_mu)\n            \n        # 2. Data Simulation\n        # Simulate economic factors f_t+1\n        factors = rng.multivariate_normal(mu, Sigma, size=T)\n        \n        # Simulate idiosyncratic shocks u_i,t+1\n        shocks = rng.normal(0, sigma_u, size=(T, N))\n        \n        # Generate risky asset returns R_i,t+1\n        risky_returns = c_i + factors @ d_matrices.T + shocks\n        \n        # 3. GMM Estimation (as OLS)\n        # Construct the design matrix X and target vector y\n        num_assets_total = N + 1\n        X = np.zeros((num_assets_total, 2))\n        y = np.ones(num_assets_total)\n        \n        f1 = factors[:, 0]\n        \n        # Row for the risk-free asset (j=0)\n        A0 = Rf\n        B0 = Rf * np.mean(f1)\n        X[0, :] = [A0, -B0]\n        \n        # Rows for risky assets (j=1 to N)\n        for j in range(N):\n            R_j = risky_returns[:, j]\n            Aj = np.mean(R_j)\n            Bj = np.mean(f1 * R_j)\n            X[j + 1, :] = [Aj, -Bj]\n            \n        # Solve the linear least squares problem: min ||X*theta - y||^2\n        # The second return value is the sum of squared residuals, which is J_T\n        _, residuals, _, _ = np.linalg.lstsq(X, y, rcond=None)\n        \n        # The value of the GMM objective function at the minimum\n        J_T_minimized = residuals[0]\n        results.append(J_T_minimized)\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2421339"}, {"introduction": "前一个练习介绍了 J-统计量可作为检验模型整体设定是否正确的工具。现在，我们将通过比较不同检验的功效 (power)，更深入地探讨基于 GMM 的假设检验的精妙之处。这个基于模拟的练习将比较通用的 J-检验与一个更具针对性的“差分检验”（D-检验），后者旨在检验特定工具变量的有效性。通过比较它们在检测模型设定错误时的表现，你将获得关于通用检验与特定检验之间权衡取舍的实践经验，并理解为何选择正确的诊断工具对于稳健的计量经济学分析至关重要 [@problem_id:2397116]。", "problem": "给定一个线性工具变量环境，其中一个标量结构参数 $ \\beta \\in \\mathbb{R} $ 由一组无条件矩来识别。对于每个观测值 $ t \\in \\{1,\\dots,n\\} $，令 $ z_{1t}, z_{2t}, z_{3t} \\in \\mathbb{R} $ 为工具变量，$ x_t \\in \\mathbb{R} $ 为回归量，$ y_t \\in \\mathbb{R} $ 为结果变量。考虑以下数据生成过程，其中所有随机变量除非明确关联，否则相互独立，并且所有期望都是关于抽样的联合分布计算的：\n- 工具变量：$ z_{1t} \\sim \\mathcal{N}(0,1) $，$ z_{2t} \\sim \\mathcal{N}(0,1) $，$ z_{3t} \\sim \\mathcal{N}(0,1) $。\n- 第一阶段扰动项：$ v_t \\sim \\mathcal{N}(0,1) $。\n- 结构扰动项：$ e_t \\sim \\mathcal{N}(0,1) $。\n- 回归量：$ x_t = z_{1t} + 0.5 z_{3t} + v_t $。\n- 包含 $ z_{2t} $ 潜在无效性的结构误差项：$ u_t = \\delta \\, z_{2t} + e_t $，其中 $ \\delta \\in \\mathbb{R} $。\n- 结果变量：$ y_t = \\beta_0 \\, x_t + u_t $，其中真实参数为 $ \\beta_0 = 1 $。\n\n定义 $ 3 \\times 1 $ 的工具变量向量 $ Z_t = \\big(z_{1t}, z_{2t}, z_{3t}\\big)^{\\prime} $。对于任意候选 $ \\beta \\in \\mathbb{R} $，定义 $ 3 \\times 1 $ 的矩函数 $ g_t(\\beta) = Z_t \\, \\big(y_t - \\beta x_t\\big) $。令 $ \\mathbb{E}[g_t(\\beta)] = 0 $ 表示目标矩条件。当 $ \\delta = 0 $ 时，所有三个工具变量对于线性模型都是有效的，并且矩条件被正确设定。当 $ \\delta \\neq 0 $ 时，工具变量 $ z_{2t} $ 无效，而 $ z_{1t} $ 和 $ z_{3t} $ 仍然有效。\n\n使用广义矩估计 (GMM)，定义样本平均矩 $ \\bar{g}_n(\\beta) = \\frac{1}{n} \\sum_{t=1}^n g_t(\\beta) $ 以及 GMM 准则 $ J_n(\\beta; W) = n \\, \\bar{g}_n(\\beta)^{\\prime} W \\, \\bar{g}_n(\\beta) $，其中 $ W \\in \\mathbb{R}^{3 \\times 3} $ 是任意对称正定加权矩阵。有效 GMM 加权矩阵是矩函数的长期协方差的逆矩阵。令 $ \\widehat{\\beta}_{\\text{full}} $ 是使用完整的 $ 3 \\times 1 $ 矩向量 $ g_t(\\beta) $ 的有效 GMM 估计量，并令 $ J_{\\text{full}} = J_n\\big(\\widehat{\\beta}_{\\text{full}}; \\widehat{W}_{\\text{full}}\\big) $ 为最小化的准则值，其中 $ \\widehat{W}_{\\text{full}} $ 是完整矩集的最优加权矩阵的有效估计。类似地，令 $ \\widehat{\\beta}_{\\text{rest}} $ 是仅使用与 $ (z_{1t}, z_{3t}) $ 对应的受限 $ 2 \\times 1 $ 矩子集的有效 GMM 估计量，并令 $ J_{\\text{rest}} = J_n\\big(\\widehat{\\beta}_{\\text{rest}}; \\widehat{W}_{\\text{rest}}\\big) $ 为其最小化的准则值，其中 $ \\widehat{W}_{\\text{rest}} $ 是相应的有效权重。定义：\n- 过度识别约束检验统计量（J检验）：$ J_{\\text{full}} $，在原假设下，其渐近服从自由度为 $ 3 - 1 = 2 $ 的 $ \\chi^2 $ 分布。\n- 针对与 $ z_{2t} $ 相关的矩子集的目标差异检验（D检验，也称C检验）：$ D = J_{\\text{full}} - J_{\\text{rest}} $，在原假设下，其渐近服从自由度为 $ 1 $ 的 $ \\chi^2 $ 分布。\n\n对于显著性水平 $ \\alpha = 0.05 $，您必须通过模拟计算以下检验的经验拒绝概率（当 $ \\delta \\neq 0 $ 时解释为经验功效，当 $ \\delta = 0 $ 时解释为经验大小）：\n- 使用全部三个矩的J检验。\n- 通过比较完整集合 $ \\{z_{1t}, z_{2t}, z_{3t}\\} $ 与受限集合 $ \\{z_{1t}, z_{3t}\\} $，针对包含涉及 $ z_{2t} $ 的矩的子集的D检验。\n\n对于每个检验，当相应的统计量超过其参考 $ \\chi^2 $ 分布在指定自由度下的 $ (1-\\alpha) $ 分位数时，发生拒绝。\n\n根据上述数据生成过程，使用独立同分布的抽样实现一个模拟。为保证可复现性，请使用固定的随机种子 $ 123456 $。对于下面测试套件中的每个参数元组 $ (n,\\delta,R) $，生成 $ R $ 个大小为 $ n $ 的独立样本，为每次重复计算 $ J_{\\text{full}} $ 和 $ D $，记录每个检验是否在水平 $ \\alpha $ 下拒绝，并报告经验拒绝概率，即 $ R $ 次重复中二元拒绝指标的平均值。\n\n测试套件：\n- 情况 $ 1 $: $ (n,\\delta,R) = (400, 0.0, 500) $。\n- 情况 $ 2 $: $ (n,\\delta,R) = (400, 0.3, 500) $。\n- 情况 $ 3 $: $ (n,\\delta,R) = (400, 0.6, 500) $。\n- 情况 $ 4 $: $ (n,\\delta,R) = (120, 0.6, 500) $。\n\n您的程序必须输出单行，该行是一个用方括号括起来的逗号分隔列表，按顺序包含每种情况下J检验和D检验的经验拒绝概率，四舍五入到三位小数。要求的输出格式为：\n$ \\big[ p_{J,1}, p_{D,1}, p_{J,2}, p_{D,2}, p_{J,3}, p_{D,3}, p_{J,4}, p_{D,4} \\big] $，\n其中 $ p_{J,i} $ 是情况 $ i $ 下J检验的经验拒绝概率，$ p_{D,i} $ 是情况 $ i $ 下D检验的经验拒绝概率。", "solution": "目标是在线性工具变量 (IV) 环境中，通过模拟计算两种假设检验的经验大小和功效——即过度识别约束的J检验和矩子集的D检验。给定了一个数据生成过程 (DGP)，用于生成 $R$ 次重复，每次重复的样本大小为 $n$。对于每次重复，我们必须使用 GMM 估计模型参数并计算指定的检验统计量。\n\n结构模型由 $y_t = \\beta_0 x_t + u_t$ 给出，其中真实参数为 $\\beta_0 = 1$。回归量 $x_t$ 是内生的，意味着 $\\mathbb{E}[x_t u_t] \\neq 0$，因为 $x_t$ 和 $u_t$ 都以可能相关的方式依赖于其他随机变量。具体来说，$x_t = z_{1t} + 0.5 z_{3t} + v_t$ 且 $u_t = \\delta z_{2t} + e_t$。当 $\\delta \\neq 0$ 时，内生性源于 $x_t$ 和 $u_t$ 之间通过遗漏变量 $z_{2t}$ 产生的相关性，或者如果 $v_t$ 和 $e_t$ 相关（尽管在此处它们被指定为独立的）。问题在向量 $Z_t = (z_{1t}, z_{2t}, z_{3t})'$ 中指定了三个工具变量，用于形成矩条件。这些工具变量的有效性取决于参数 $\\delta$。\n\nGMM 框架基于总体矩条件 $\\mathbb{E}[g_t(\\beta_0)] = 0$。对于此问题， $3 \\times 1$ 的矩函数向量为 $g_t(\\beta) = Z_t (y_t - \\beta x_t)$。当所有工具变量都有效时（即 $\\mathbb{E}[Z_t u_t]=0$，这在 $\\delta=0$ 时发生），所有三个矩条件在真实参数 $\\beta_0=1$ 处都成立。当 $\\delta \\neq 0$ 时，第二个工具变量 $z_{2t}$ 变得无效，因为 $\\mathbb{E}[z_{2t}u_t] = \\mathbb{E}[z_{2t}(\\delta z_{2t} + e_t)] = \\delta \\mathbb{E}[z_{2t}^2] = \\delta \\neq 0$。矩条件 $\\mathbb{E}[z_{2t}(y_t - \\beta_0 x_t)] = 0$ 被违反。\n\n对于给定的对称正定加权矩阵 $W$，GMM 估计量 $\\widehat{\\beta}$ 通过最小化二次型 $J_n(\\beta; W) = n \\, \\bar{g}_n(\\beta)' W \\bar{g}_n(\\beta)$ 得到，其中 $\\bar{g}_n(\\beta) = \\frac{1}{n} \\sum_{t=1}^n g_t(\\beta)$ 是总体矩的样本模拟。对于这个线性模型，样本矩为 $\\bar{g}_n(\\beta) = \\frac{1}{n}(Z'y - Z'x\\beta)$。GMM 估计量具有解析解 $\\widehat{\\beta}(W) = (x'Z W Z'x)^{-1} (x'Z W Z'y)$。\n\n该问题要求使用有效 GMM 估计量，该估计量采用最优加权矩阵 $W^* = S^{-1}$，其中 $S = \\mathbb{E}[g_t(\\beta_0) g_t(\\beta_0)']$ 是矩函数的长期协方差矩阵。由于 $S$ 是未知的，因此采用两步程序：\n1.  **第一步**：使用一个次优但有效的加权矩阵，例如单位矩阵 $W^{(1)}=I$ 或对应于两阶段最小二乘法 (2SLS) 估计量的矩阵 $W^{(1)}=(Z'Z/n)^{-1}$，来获得 $\\beta$ 的一致估计，记为 $\\widehat{\\beta}^{(1)}$。2SLS 估计量是此步骤的常规选择。\n2.  **第二步**：使用 $\\widehat{\\beta}^{(1)}$ 形成残差 $\\widehat{u}_t = y_t - \\widehat{\\beta}^{(1)} x_t$，并构造 $S$ 的一致估计量，由 $\\widehat{S} = \\frac{1}{n} \\sum_{t=1}^n Z_t Z_t' \\widehat{u}_t^2$ 给出。估计的最优加权矩阵则为 $\\widehat{W} = \\widehat{S}^{-1}$。然后，有效 GMM 估计量计算为 $\\widehat{\\beta}_{\\text{GMM}} = (x'Z \\widehat{W} Z'x)^{-1} (x'Z \\widehat{W} Z'y)$。\n\n模拟需要计算两个检验统计量：\n\n1.  **J检验统计量**：$J_{\\text{full}} = n \\cdot \\bar{g}_n(\\widehat{\\beta}_{\\text{full}})' \\widehat{W}_{\\text{full}} \\bar{g}_n(\\widehat{\\beta}_{\\text{full}})$。该统计量检验所有矩条件均被正确设定的原假设。此处，$\\widehat{\\beta}_{\\text{full}}$ 和 $\\widehat{W}_{\\text{full}}$ 是从全部 $k=3$ 个工具变量集合中推导出的估计量和最优权重矩阵。在原假设下，$J_{\\text{full}}$ 服从自由度为 $k - m = 3 - 1 = 2$ 的渐近 $\\chi^2$ 分布，其中 $m=1$ 是估计参数的数量。拒绝则表明模型设定有误。\n\n2.  **D检验（或C检验）统计量**：$D = J_{\\text{full}} - J_{\\text{rest}}$。该统计量检验特定矩条件子集的有效性——在本例中，是与工具变量 $z_{2t}$ 相关的那一个。它比较了完整模型的最小化 GMM 准则 $J_{\\text{full}}$ 与受限模型的最小化准则 $J_{\\text{rest}}$。受限模型仅使用在备择假设下被认为是有效的工具变量子集 $\\{z_{1t}, z_{3t}\\}$。相应地，$J_{\\text{rest}}$ 是使用这个较小的 $k_{rest}=2$ 个工具变量集合，通过两步有效 GMM 程序计算得出的。在附加的矩条件（来自 $z_{2t}$）有效的原假设下，D 统计量服从自由度为 $k - k_{rest} = 3 - 2 = 1$ 的渐近 $\\chi^2$ 分布。对于检测被测特定矩条件的失效，该检验通常比总括性的J检验更具功效。\n\n对于每个参数元组 $(n, \\delta, R)$，模拟算法按以下步骤进行：\n1.  为保证可复现性，将随机数生成器种子设置为 $123456$。\n2.  在 $\\alpha = 0.05$ 显著性水平下，从 $\\chi^2(2)$ 和 $\\chi^2(1)$ 分布中确定检验的临界值。\n3.  将两个检验的拒绝计数器初始化为零。\n4.  执行一个包含 $R=500$ 次重复的循环。在每次重复中：\n    a.  使用指定的 $\\delta$ 值和 $\\beta_0=1$，从 DGP 生成大小为 $n$ 的样本。\n    b.  使用完整的工具变量集 $Z=(z_1, z_2, z_3)$，计算两步有效 GMM 估计量 $\\widehat{\\beta}_{\\text{full}}$ 和相应的J统计量 $J_{\\text{full}}$。\n    c.  使用受限的工具变量集 $Z_{\\text{rest}}=(z_1, z_3)$，计算两步有效 GMM 估计量 $\\widehat{\\beta}_{\\text{rest}}$ 和相应的J统计量 $J_{\\text{rest}}$。\n    d.  计算 D 统计量为 $D = J_{\\text{full}} - J_{\\text{rest}}$。\n    e.  如果 $J_{\\text{full}}$ 超过其临界值，则 J 检验拒绝计数器加一。\n    f.  如果 $D$ 超过其临界值，则 D 检验拒绝计数器加一。\n5.  循环结束后，通过将其拒绝计数除以总重复次数 $R$，计算每个检验的经验拒绝概率。\n6.  收集所有四个测试用例的结果，并按指定格式报告。在 $\\delta=0$ 的情况下，拒绝概率代表检验的经验大小。当 $\\delta \\neq 0$ 时，它代表经验功效。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\n\ndef gmm_solver(y, x, Z):\n    \"\"\"\n    Computes the two-step efficient GMM estimator, J-statistic, and optimal weight matrix.\n\n    Args:\n        y (np.ndarray): Dependent variable, shape (n, 1).\n        x (np.ndarray): Endogenous regressor, shape (n, 1).\n        Z (np.ndarray): Matrix of instruments, shape (n, k).\n\n    Returns:\n        tuple: (J-statistic, GMM beta estimate). Returns (np.nan, np.nan) on failure.\n    \"\"\"\n    n, k = Z.shape\n    if n  k:\n        return np.nan, np.nan\n\n    # Step 1: First-step consistent estimation using 2SLS (W = (Z'Z)^-1)\n    try:\n        ZTZ = Z.T @ Z\n        if np.linalg.matrix_rank(ZTZ)  k:\n            return np.nan, np.nan\n        inv_ZTZ = np.linalg.inv(ZTZ)\n    except np.linalg.LinAlgError:\n        return np.nan, np.nan\n\n    xTZ = x.T @ Z\n    ZTx = Z.T @ x\n    ZTy = Z.T @ y\n\n    den_b1 = (xTZ @ inv_ZTZ @ ZTx)[0, 0]\n    if np.isclose(den_b1, 0):\n        return np.nan, np.nan\n    num_b1 = (xTZ @ inv_ZTZ @ ZTy)[0, 0]\n    beta1 = num_b1 / den_b1\n\n    # Step 2: Form optimal weighting matrix\n    u_hat = y - x * beta1\n    # S_hat = (1/n) * Sum(u_hat_t^2 * Z_t @ Z_t.T)\n    # This is equivalent to (1/n) * Z_with_residuals.T @ Z_with_residuals\n    S_hat = (Z * u_hat).T @ (Z * u_hat) / n\n\n    try:\n        if np.linalg.matrix_rank(S_hat)  k:\n            return np.nan, np.nan\n        W_hat = np.linalg.inv(S_hat)\n    except np.linalg.LinAlgError:\n        return np.nan, np.nan\n\n    # Step 3: Efficient GMM estimator\n    den_b2 = (xTZ @ W_hat @ ZTx)[0, 0]\n    if np.isclose(den_b2, 0):\n        return np.nan, np.nan\n    num_b2 = (xTZ @ W_hat @ ZTy)[0, 0]\n    beta_gmm = num_b2 / den_b2\n\n    # J-statistic calculation\n    g_bar = (ZTy - ZTx * beta_gmm) / n\n    J_stat = n * g_bar.T @ W_hat @ g_bar\n\n    return J_stat[0, 0], beta_gmm\n\ndef solve():\n    \"\"\"\n    Main function to run the Monte Carlo simulation for GMM tests.\n    \"\"\"\n    seed = 123456\n    rng = np.random.default_rng(seed)\n    alpha = 0.05\n\n    # Test cases: (n, delta, R)\n    test_cases = [\n        (400, 0.0, 500),\n        (400, 0.3, 500),\n        (400, 0.6, 500),\n        (120, 0.6, 500),\n    ]\n\n    # Chi-squared critical values\n    crit_val_j = chi2.ppf(1 - alpha, df=2)  # Full model: 3 instruments, 1 param -> df=2\n    crit_val_d = chi2.ppf(1 - alpha, df=1)  # D-test: 3-2=1 df\n\n    # True parameter value\n    beta_0 = 1.0\n    \n    final_results = []\n\n    for n, delta, R in test_cases:\n        j_reject_count = 0\n        d_reject_count = 0\n\n        for _ in range(R):\n            # 1. Generate data\n            z1 = rng.normal(size=(n, 1))\n            z2 = rng.normal(size=(n, 1))\n            z3 = rng.normal(size=(n, 1))\n            v = rng.normal(size=(n, 1))\n            e = rng.normal(size=(n, 1))\n            \n            Z_full = np.hstack([z1, z2, z3])\n            \n            x = z1 + 0.5 * z3 + v\n            u = delta * z2 + e\n            y = beta_0 * x + u\n\n            # 2. GMM Estimation for the full model\n            J_full, _ = gmm_solver(y, x, Z_full)\n            \n            # 3. GMM Estimation for the restricted model\n            Z_rest = Z_full[:, [0, 2]]\n            J_rest, _ = gmm_solver(y, x, Z_rest)\n\n            # Skip replication if GMM fails (e.g., singular matrix)\n            if np.isnan(J_full) or np.isnan(J_rest):\n                continue\n\n            # 4. Compute D-statistic\n            D = J_full - J_rest\n\n            # 5. Perform tests\n            if J_full > crit_val_j:\n                j_reject_count += 1\n            # Note: D can be negative in finite samples. The test is D > crit,\n            # so a negative value correctly results in non-rejection.\n            if D > crit_val_d:\n                d_reject_count += 1\n\n        # 6. Calculate empirical rejection probabilities\n        p_j = j_reject_count / R\n        p_d = d_reject_count / R\n        \n        final_results.extend([p_j, p_d])\n    \n    # Format and print the final output\n    formatted_results = [f\"{res:.3f}\" for res in final_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "2397116"}]}