{"hands_on_practices": [{"introduction": "本次练习将通过一个动手实践，介绍间接推断的核心机制。我们将使用一个直观的物理模型——“普林科”弹珠台——来模拟一个随机过程，其中弹珠穿过钉子阵列向下掉落。练习的挑战在于，仅通过观察弹珠的最终落点分布，来估计弹珠台背后“看不见”的结构参数（例如向右偏转的概率），从而展示我们如何从可观测统计量（如均值和方差）的间接影响中推断出结构参数。[@problem_id:2401820]", "problem": "考虑一个简化的“弹珠”游戏（plinko）式高尔顿（Galton）板模型，用于阐释随机过程。大量相同的球从顶部逐一落下。每个球会经过 $T$ 行钉子。在每颗钉子处，球会向左或向右偏转。令 $S_{it}\\in\\{-d, +d\\}$ 表示球 $i$ 在第 $t$ 行的水平增量，其中 $d>0$ 是固定的水平步长。假设 $\\mathbb{P}(S_{it}=+d)=p$ 且 $\\mathbb{P}(S_{it}=-d)=1-p$，其中 $0\\le p\\le 1$，且各球、各行的偏转相互独立。经过 $T$ 行后，球 $i$ 的最终水平位置为 $X_i=\\sum_{t=1}^{T} S_{it}$。\n\n令 $\\theta=(p,d)$ 为未知的结构参数向量。您观测到一个由 $N_{\\text{obs}}$ 个独立最终位置组成的数据集 $\\{X_i\\}_{i=1}^{N_{\\text{obs}}}$，该数据集由真实参数 $\\theta_0=(p_0,d_0)$ 生成。您需要使用间接推断（Indirect Inference, II）方法来估计 $\\theta$，其定义如下。选择一个辅助模型：正态分布 $\\mathcal{N}(\\mu,\\sigma^2)$，其辅助参数为根据最终位置计算出的样本均值和样本方差。将辅助统计量映射 $m(\\cdot)$ 定义为 $m(\\{x_i\\}) = \\big(\\bar{x}, s^2\\big)$，其中 $\\bar{x}$ 是样本均值，$s^2$ 是除数为 $N$ 的样本方差（总体方差）。对于一个候选参数 $\\theta$，令 $m_{\\text{sim}}(\\theta)$ 表示在参数为 $\\theta$ 的结构模型下生成的数据计算出的辅助统计量。II 估计量通过最小化二次距离得到\n$$\nQ(\\theta)=\\big(m_{\\text{obs}}-m_{\\text{sim}}(\\theta)\\big)^{\\top} W \\big(m_{\\text{obs}}-m_{\\text{sim}}(\\theta)\\big),\n$$\n其中权重矩阵 $W=I_2$，$m_{\\text{obs}}=m(\\{X_i\\}_{i=1}^{N_{\\text{obs}}})$。\n\n您的任务是编写一个完整的程序，针对下面指定的每个测试用例，从基本原理出发完成以下所有操作：\n- 使用给定的真实参数 $\\theta_0$ 和指定的随机种子，通过结构模型生成观测数据集 $\\{X_i\\}_{i=1}^{N_{\\text{obs}}}$。\n- 计算观测到的辅助统计量 $m_{\\text{obs}}$。\n- 将间接推断估计值 $\\hat{\\theta}=(\\hat{p},\\hat{d})$ 作为 $Q(\\theta)$ 在可行集 $\\{(p,d): 0\\le p\\le 1, \\ d>0\\}$ 上的最小化者进行计算。\n- 按照最终输出格式要求，为每个测试用例返回 $\\hat{\\theta}$。\n\n所有概率必须表示为 $[0,1]$ 范围内的小数。不涉及物理单位。任何角度（如果有的话）都与本问题无关。估计过程必须严格按照上述定义进行。\n\n测试套件。对于每个项目，给定行数 $T$、真实概率 $p_0$、真实步长 $d_0$、观测样本量 $N_{\\text{obs}}$ 以及用于生成观测数据的随机种子。生成观测数据时，必须使用提供的种子初始化随机数生成器。最终的样本方差必须使用除数 $N_{\\text{obs}}$（总体方差）。\n- 测试用例 1：$T=20$，$p_0=0.6$，$d_0=1.2$，$N_{\\text{obs}}=50000$，种子 $=13579$。\n- 测试用例 2：$T=30$，$p_0=0.5$，$d_0=1.0$，$N_{\\text{obs}}=50000$，种子 $=24680$。\n- 测试用例 3：$T=25$，$p_0=0.9$，$d_0=0.8$，$N_{\\text{obs}}=50000$，种子 $=11235$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个列表的列表形式的结果，每个内部列表对应一个测试用例，顺序与上面列出的一致。每个内部列表必须包含两个十进制数 $[\\hat{p},\\hat{d}]$，四舍五入到小数点后六位。例如，输出行必须如下所示：\n[[p1,d1],[p2,d2],[p3,d3]]\n不含任何空格，其中每个 $p_j$ 和 $d_j$ 都是四舍五入到六位小数的十进制数。", "solution": "所提出的问题是一个有效且定义明确的练习，旨在通过间接推断方法进行参数估计。它在科学上基于概率论和统计估计，并提供了解决该问题所需的所有信息。我们将给出一个完整的解法。\n\n问题的核心是，在给定随机过程最终状态的一组观测值的情况下，估计该过程的结构参数 $\\theta=(p,d)$。该结构模型描述了一个球在高尔顿板上经过 $T$ 行钉子的运动。在每一行 $t \\in \\{1, \\dots, T\\}$，球的水平位置发生增量 $S_t$ 的变化，该增量以概率 $p$ 为 $+d$，以概率 $1-p$ 为 $-d$。经过 $T$ 行后的最终水平位置是 $X = \\sum_{t=1}^{T} S_t$。\n\n首先，我们建立结构参数 $\\theta=(p,d)$ 与最终位置 $X$ 的矩之间的解析关系。令 $K$ 为一个随机变量，表示向右偏转的次数，它服从二项分布，$K \\sim \\text{Binomial}(T,p)$。总偏转次数为 $T$，因此有 $T-K$ 次向左偏转。最终位置 $X$ 可以表示为：\n$$\nX = K \\cdot (+d) + (T-K) \\cdot (-d) = d(K - (T-K)) = d(2K - T)\n$$\n二项变量 $K$ 的均值和方差分别为 $\\mathbb{E}[K] = Tp$ 和 $\\text{Var}(K) = Tp(1-p)$。利用期望和方差的性质，我们可以求出最终位置 $X$ 的均值 $\\mu_X$ 和方差 $\\sigma_X^2$：\n$$\n\\mu(p, d) = \\mathbb{E}[X] = \\mathbb{E}[d(2K - T)] = d(2\\mathbb{E}[K] - T) = d(2Tp - T) = Td(2p-1)\n$$\n$$\n\\sigma^2(p, d) = \\text{Var}(X) = \\text{Var}(d(2K - T)) = d^2 \\text{Var}(2K) = 4d^2\\text{Var}(K) = 4d^2Tp(1-p)\n$$\n这两个方程构成了将结构参数 $\\theta=(p,d)$ 映射到可观测数据理论矩的函数关系。\n\n该问题要求通过间接推断（II）进行估计。我们给定一个辅助模型，即正态分布 $\\mathcal{N}(\\mu, \\sigma^2)$，辅助统计量为样本均值 $\\bar{x}$ 和样本方差 $s^2$（除数为 $N_{\\text{obs}}$）。我们有一个由真实参数 $\\theta_0=(p_0,d_0)$ 生成的包含 $N_{\\text{obs}}$ 个观测值的数据集 $\\{X_i\\}_{i=1}^{N_{\\text{obs}}}$。我们计算观测到的辅助统计量向量 $m_{\\text{obs}} = (\\bar{x}_{\\text{obs}}, s^2_{\\text{obs}})$。\n\nII 估计量 $\\hat{\\theta}$ 是通过最小化目标函数找到的：\n$$\nQ(\\theta) = (m_{\\text{obs}} - m_{\\text{sim}}(\\theta))^{\\top} W (m_{\\text{obs}} - m_{\\text{sim}}(\\theta))\n$$\n其中权重矩阵是单位矩阵，$W=I_2$。项 $m_{\\text{sim}}(\\theta)$ 表示由参数为 $\\theta$ 的模型产生的辅助统计量。一个关键点是如何评估 $m_{\\text{sim}}(\\theta)$。虽然可以在优化过程中对每个 $\\theta$ 值进行模拟，但这会给目标函数引入随机性，使最小化过程变得复杂，并且需要指定内部模拟的规模，而题目并未提供此信息。在这种情况下，正确且标准的方法是使用上面推导出的解析矩，这对应于当模拟规模趋于无穷大时辅助统计量的期望值。\n因此，$m_{\\text{sim}}(\\theta) = (\\mu(p,d), \\sigma^2(p,d))$。目标函数变为：\n$$\nQ(p,d) = (\\bar{x}_{\\text{obs}} - \\mu(p,d))^2 + (s^2_{\\text{obs}} - \\sigma^2(p,d))^2\n$$\n$$\nQ(p,d) = (\\bar{x}_{\\text{obs}} - Td(2p-1))^2 + (s^2_{\\text{obs}} - 4Td^2p(1-p))^2\n$$\n估计任务是找到使函数 $Q(p,d)$ 在约束条件 $p \\in [0,1]$ 和 $d > 0$ 下最小化的值 $(\\hat{p}, \\hat{d})$。这是一个标准的非线性约束优化问题。\n\n解决每个测试用例的算法步骤如下：\n1.  **生成观测数据**：对于给定的测试用例，其参数为 $T, p_0, d_0, N_{\\text{obs}}$ 和一个特定的随机种子，生成 $N_{\\text{obs}}$ 个观测值。这可以通过首先从分布 $\\text{Binomial}(T, p_0)$ 中抽取 $N_{\\text{obs}}$ 个值 $\\{K_i\\}_{i=1}^{N_{\\text{obs}}}$ 来高效实现。然后，计算观测到的最终位置为 $X_i = d_0(2K_i - T)$。\n2.  **计算观测统计量**：从生成的数据集 $\\{X_i\\}$ 中，计算观测到的辅助统计量 $m_{\\text{obs}}=(\\bar{x}_{\\text{obs}}, s^2_{\\text{obs}})$。具体来说，$\\bar{x}_{\\text{obs}} = \\frac{1}{N_{\\text{obs}}} \\sum_{i=1}^{N_{\\text{obs}}} X_i$ 且 $s^2_{\\text{obs}} = \\frac{1}{N_{\\text{obs}}} \\sum_{i=1}^{N_{\\text{obs}}} (X_i - \\bar{x}_{\\text{obs}})^2$。\n3.  **数值优化**：关于 $p$ 和 $d$ 最小化目标函数 $Q(p,d)$。我们采用适合带约束问题的数值优化算法，例如带箱式约束的拟牛顿法（如 L-BFGS-B）。搜索空间由边界 $p \\in [0,1]$ 和 $d \\in (0, \\infty)$ 定义。为保证数值稳定性，为 $d$ 使用一个小的正数下界。\n4.  **报告估计值**：最小化 $Q(p,d)$ 的一对值 $(\\hat{p}, \\hat{d})$ 构成了给定测试用例的间接推断估计值。然后收集所有测试用例的结果，并按要求格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\n\ndef solve():\n    \"\"\"\n    Main function to solve the Indirect Inference estimation problem for all test cases.\n    \"\"\"\n\n    # Test cases as specified in the problem statement.\n    test_cases = [\n        # (T, p0, d0, N_obs, seed)\n        (20, 0.6, 1.2, 50000, 13579),\n        (30, 0.5, 1.0, 50000, 24680),\n        (25, 0.9, 0.8, 50000, 11235),\n    ]\n\n    all_results = []\n\n    for T, p0, d0, N_obs, seed in test_cases:\n        # Step 1: Generate the observed dataset {X_i}\n        # Use a more efficient method based on the Binomial distribution.\n        # k ~ Binomial(T, p) represents the number of right steps.\n        # X = k * (+d) + (T - k) * (-d) = d * (2k - T)\n        rng = np.random.default_rng(seed)\n        k_obs = rng.binomial(T, p0, size=N_obs)\n        x_obs = d0 * (2 * k_obs - T)\n\n        # Step 2: Compute the observed auxiliary statistics m_obs = (mean, variance)\n        mu_obs = np.mean(x_obs)\n        # Use population variance (divisor N), as specified (ddof=0 is default for np.var)\n        var_obs = np.var(x_obs)\n        m_obs = (mu_obs, var_obs)\n        \n        # Step 3: Define the objective function Q(theta) for minimization.\n        # theta is a tuple (p, d).\n        def objective_function(theta, T_val, m_obs_val):\n            p, d = theta\n            mu_obs_val, var_obs_val = m_obs_val\n\n            # Analytical moments from the structural model\n            mu_sim = T_val * d * (2 * p - 1)\n            var_sim = 4 * T_val * (d**2) * p * (1 - p)\n            \n            # Quadratic objective function Q(theta)\n            q_val = (mu_obs_val - mu_sim)**2 + (var_obs_val - var_sim)**2\n            return q_val\n\n        # Step 4: Perform numerical optimization to find the II estimate.\n        # Initial guess for the parameters (p, d)\n        initial_guess = [0.5, 1.0]\n\n        # Bounds for the parameters: 0 = p = 1 and d > 0.\n        # Use a small positive number for the lower bound of d for numerical stability.\n        bounds = [(0.0, 1.0), (1e-9, None)]\n\n        # Minimize the objective function. L-BFGS-B is suitable for box constraints.\n        result = minimize(\n            fun=objective_function,\n            x0=initial_guess,\n            args=(T, m_obs),\n            method='L-BFGS-B',\n            bounds=bounds\n        )\n\n        # The optimized parameters are the II estimates\n        p_hat, d_hat = result.x\n        all_results.append([p_hat, d_hat])\n\n    # Final print statement in the exact required format.\n    # Create the list of lists with rounded values.\n    # e.g., [[0.600012, 1.199998], [0.500001, 1.000003], [0.900005, 0.799989]]\n    # Then convert to string and remove spaces to match the output format.\n    final_list_formatted = [[round(p, 6), round(d, 6)] for p, d in all_results]\n    output_str = str(final_list_formatted).replace(\" \", \"\")\n    print(output_str)\n\nsolve()\n\n```", "id": "2401820"}, {"introduction": "接下来的练习将我们带向更接近现实世界的计量经济学应用，它采用了一个更复杂的辅助模型。在这里，辅助模型的参数不再是简单的样本矩，而是通过广义矩估计（GMM）方法得到的。这个练习要求你实现一个更复杂的多阶段估计流程，并引入关键的计算技术，例如使用“共同随机数”来确保模拟估算过程的稳定性和可靠性。[@problem_id:2401827]", "problem": "给定一个结构时间序列模型和一个辅助模型，其参数通过广义矩估计 (GMM) 进行估计。您的任务是实现一个间接推断估计量，其中辅助参数是通过 GMM 而非最大似然估计 (MLE) 获得的，并为一组指定的数据生成过程和模拟设置生成间接推断估计值。\n\n结构模型是一阶自回归模型，其已知创新方差等于 1。对于每个时间指数 $t$，该过程满足\n$$\ny_t = \\theta \\, y_{t-1} + \\varepsilon_t,\n$$\n其中 $\\varepsilon_t \\sim \\mathcal{N}(0,1)$ 是独立同分布的。使用初始条件 $y_0 = 0$，并在收集 $T$ 个观测值之前进行 $B = 200$ 个周期的预烧 (burn-in)。对于观测样本路径和辅助样本路径的模拟，角度单位不适用，也不涉及物理单位。\n\n辅助模型是线性回归\n$$\ny_t = \\beta_0 + \\beta_1 \\, y_{t-1} + u_t,\n$$\n辅助参数 $\\beta = (\\beta_0,\\beta_1)^\\top$ 是通过基于工具向量的过度识别矩条件定义的\n$$\nz_t = \\begin{bmatrix} 1 \\\\ y_{t-1} \\\\ y_{t-2} \\end{bmatrix}.\n$$\n对于每个样本 $y_1,\\dots,y_T$，将 $t=3,\\dots,T$ 的样本矩函数定义为\n$$\ng_T(\\beta) = \\frac{1}{n} \\sum_{t=3}^T z_t \\, \\left(y_t - \\beta_0 - \\beta_1 \\, y_{t-1}\\right),\n$$\n其中 $n = T-2$。$\\beta$ 的 GMM 估计量使用维度为 $3 \\times 3$ 的单位权重矩阵定义为\n$$\n\\widehat{\\beta}(y_{1:T}) = \\arg \\min_{\\beta \\in \\mathbb{R}^2} \\; g_T(\\beta)^\\top g_T(\\beta).\n$$\n\n对于一个候选结构参数 $\\theta$，间接推断目标函数使用从结构模型生成的 $S$ 个长度为 $T$ 的独立模拟样本，并采用相同的预烧期 $B$。令 $\\widehat{\\beta}^{\\text{obs}}$ 表示从观测数据集中获得的辅助 GMM 估计值。对于一个给定的 $\\theta$，定义\n$$\n\\overline{\\beta}(\\theta) = \\frac{1}{S} \\sum_{s=1}^S \\widehat{\\beta}(y^{(s)}_{1:T}(\\theta)),\n$$\n其中 $y^{(s)}_{1:T}(\\theta)$ 是在 $\\theta$ 下生成的第 $s$ 个长度为 $T$ 的模拟样本。间接推断准则为\n$$\nQ(\\theta) = \\left(\\widehat{\\beta}^{\\text{obs}} - \\overline{\\beta}(\\theta)\\right)^\\top W \\left(\\widehat{\\beta}^{\\text{obs}} - \\overline{\\beta}(\\theta)\\right),\n$$\n其中 $W = I_2$。对于下面的每个测试用例，将 $\\theta$ 限制在离散搜索网格上\n$$\n\\mathcal{G}_i = \\{-0.95, -0.95 + \\delta_i, \\dots, 0.95\\},\n$$\n其中 $\\delta_i$ 是测试用例中指定的网格步长。间接推断估计值为\n$$\n\\widehat{\\theta}_i \\in \\arg \\min_{\\theta \\in \\mathcal{G}_i} Q(\\theta),\n$$\n若存在多个解，则选择最小的 $\\theta$ 来打破僵局。\n\n模拟和可复现性要求如下：\n- 对于每个测试用例 $i$，使用真实参数 $\\theta^{\\star}_i$、样本大小 $T_i$、等于 $1$ 的创新方差、预烧期 $B=200$ 以及指定的观测数据种子 $s^{\\text{obs}}_i$ 来生成观测数据集。\n- 为了在测试用例 $i$ 的网格上评估 $Q(\\theta)$，通过为每个重复索引 $s \\in \\{1,\\dots,S_i\\}$ 使用种子 $s^{\\text{sim}}_i + s$ 预先生成一个长度为 $T_i + B$ 的标准正态创新序列，从而在不同的 $\\theta$ 值之间使用共同随机数。对于所有 $\\theta \\in \\mathcal{G}_i$，重复使用这些预先生成的创新。\n\n实现上述过程，并为以下四个测试用例计算 $\\widehat{\\theta}_i$：\n- 测试用例 1：$T_1 = 300$, $\\theta^{\\star}_1 = 0.6$, $S_1 = 20$, $\\delta_1 = 0.01$, $s^{\\text{obs}}_1 = 1729$, $s^{\\text{sim}}_1 = 20231$。\n- 测试用例 2：$T_2 = 300$, $\\theta^{\\star}_2 = 0.9$, $S_2 = 25$, $\\delta_2 = 0.01$, $s^{\\text{obs}}_2 = 1730$, $s^{\\text{sim}}_2 = 20232$。\n- 测试用例 3：$T_3 = 150$, $\\theta^{\\star}_3 = 0.0$, $S_3 = 40$, $\\delta_3 = 0.02$, $s^{\\text{obs}}_3 = 1731$, $s^{\\text{sim}}_3 = 20233$。\n- 测试用例 4：$T_4 = 300$, $\\theta^{\\star}_4 = -0.5$, $S_4 = 20$, $\\delta_4 = 0.01$, $s^{\\text{obs}}_4 = 1732$, $s^{\\text{sim}}_4 = 20234$。\n\n您的程序应生成单行输出，其中包含四个估计值 $\\widehat{\\theta}_1, \\widehat{\\theta}_2, \\widehat{\\theta}_3, \\widehat{\\theta}_4$，以逗号分隔的列表形式包含在方括号内，每个值四舍五入到小数点后四位，例如 $[\\widehat{\\theta}_1,\\widehat{\\theta}_2,\\widehat{\\theta}_3,\\widehat{\\theta}_4]$。", "solution": "该问题要求为一阶自回归过程 AR(1) 的参数 $\\theta$ 实现一个间接推断估计量。该估计过程基于一个辅助模型，其参数通过广义矩估计 (GMM) 进行估计。首先评估问题陈述的有效性。\n\n### 第 1 步：提取给定信息\n\n- **结构模型**：$y_t = \\theta \\, y_{t-1} + \\varepsilon_t$，其中 $\\varepsilon_t \\sim \\mathcal{N}(0,1)$ 是独立同分布 (i.i.d.) 的创新。\n- **初始条件**：$y_0 = 0$。\n- **模拟参数**：预烧期 $B = 200$。预烧后收集的样本大小为 $T$。\n- **辅助模型**：$y_t = \\beta_0 + \\beta_1 \\, y_{t-1} + u_t$，参数为 $\\beta = (\\beta_0,\\beta_1)^\\top$。\n- **工具向量**：$z_t = [1, y_{t-1}, y_{t-2}]^\\top$。\n- **GMM 样本矩函数**：$g_T(\\beta) = \\frac{1}{n} \\sum_{t=3}^T z_t \\, (y_t - \\beta_0 - \\beta_1 y_{t-1})$，其中 $n = T-2$。\n- **GMM 估计量**：$\\widehat{\\beta}(y_{1:T}) = \\arg \\min_{\\beta \\in \\mathbb{R}^2} \\; g_T(\\beta)^\\top g_T(\\beta)$。这对应于使用单位权重矩阵。\n- **间接推断准则**：$Q(\\theta) = (\\widehat{\\beta}^{\\text{obs}} - \\overline{\\beta}(\\theta))^\\top W (\\widehat{\\beta}^{\\text{obs}} - \\overline{\\beta}(\\theta))$，权重矩阵 $W = I_2$。\n- **模拟辅助参数**：$\\overline{\\beta}(\\theta) = \\frac{1}{S} \\sum_{s=1}^S \\widehat{\\beta}(y^{(s)}_{1:T}(\\theta))$，其中 $y^{(s)}_{1:T}(\\theta)$ 是从参数为 $\\theta$ 的结构模型生成的 $S$ 个独立样本。\n- **估计网格**：$\\mathcal{G}_i = \\{-0.95, -0.95 + \\delta_i, \\dots, 0.95\\}$。\n- **间接推断估计量**：$\\widehat{\\theta}_i \\in \\arg \\min_{\\theta \\in \\mathcal{G}_i} Q(\\theta)$，若有多个解则选择最小的 $\\theta$。\n- **可复现性**：在评估不同 $\\theta$ 值的 $Q(\\theta)$ 时，使用共同随机数。对于测试用例 $i$，使用种子 $s^{\\text{obs}}_i$ 生成观测数据。使用种子 $s^{\\text{sim}}_i + 1, \\dots, s^{\\text{sim}}_i + S_i$ 生成 $S_i$ 个模拟路径。\n- **测试用例**：\n    1.  $T_1 = 300$, $\\theta^{\\star}_1 = 0.6$, $S_1 = 20$, $\\delta_1 = 0.01$, $s^{\\text{obs}}_1 = 1729$, $s^{\\text{sim}}_1 = 20231$。\n    2.  $T_2 = 300$, $\\theta^{\\star}_2 = 0.9$, $S_2 = 25$, $\\delta_2 = 0.01$, $s^{\\text{obs}}_2 = 1730$, $s^{\\text{sim}}_2 = 20232$。\n    3.  $T_3 = 150$, $\\theta^{\\star}_3 = 0.0$, $S_3 = 40$, $\\delta_3 = 0.02$, $s^{\\text{obs}}_3 = 1731$, $s^{\\text{sim}}_3 = 20233$。\n    4.  $T_4 = 300$, $\\theta^{\\star}_4 = -0.5$, $S_4 = 20$, $\\delta_4 = 0.01$, $s^{\\text{obs}}_4 = 1732$, $s^{\\text{sim}}_4 = 20234$。\n\n### 第 2 步：使用提取的给定信息进行验证\n\n- **科学依据**：该问题在计量经济学和统计学原理方面有充分的依据。AR(1) 模型、GMM 估计和间接推断都是标准的、广泛使用的方法。\n- **适定性**：问题是适定的。目标函数 $Q(\\theta)$ 定义清晰，其在离散网格上的最小化保证了解的存在性。指定的打破僵局规则确保了解的唯一性。\n- **客观性**：问题以精确、客观的数学语言陈述，没有任何主观或含糊的术语。\n- **完整性和一致性**：所有必需的模型、参数、种子和程序步骤都已明确提供。设置内部一致，没有矛盾。GMM 使用单位权重矩阵是一种有效（尽管可能效率不高）的选择，可以得到一个明确定义的估计量。\n\n### 第 3 步：结论与行动\n\n问题陈述是有效的，具有科学合理性、适定性和自包含性。将提供一个合理的解决方案。\n\n### 基于原理的解决方案设计\n\n通过实施指定的间接推断程序来构建解决方案。这涉及几个不同的逻辑步骤：数据模拟、辅助参数估计、间接推断准则的评估以及结构参数的网格搜索。\n\n1.  **辅助参数的解析 GMM 估计量**\n    辅助参数 $\\beta = (\\beta_0, \\beta_1)^\\top$ 通过最小化 $J(\\beta) = g_T(\\beta)^\\top g_T(\\beta)$ 来估计。设样本表示为 $y_1, \\dots, y_T$。矩条件针对 $t=3, \\dots, T$ 进行评估，包含 $n=T-2$ 个观测值。我们可以用矩阵形式表示该问题。令\n    $$\n    y_{\\text{vec}} = \\begin{bmatrix} y_3 \\\\ y_4 \\\\ \\vdots \\\\ y_T \\end{bmatrix}, \\quad\n    X = \\begin{bmatrix} 1  y_2 \\\\ 1  y_3 \\\\ \\vdots  \\vdots \\\\ 1  y_{T-1} \\end{bmatrix}, \\quad\n    Z = \\begin{bmatrix} 1  y_2  y_1 \\\\ 1  y_3  y_2 \\\\ \\vdots  \\vdots  \\vdots \\\\ 1  y_{T-1}  y_{T-2} \\end{bmatrix}.\n    $$\n    GMM 目标函数，忽略常数因子 $1/n^2$，是最小化 $(Z'y_{\\text{vec}} - Z'X\\beta)^\\top (Z'y_{\\text{vec}} - Z'X\\beta)$。这是一个形如 $\\min_{\\beta} \\|b - A\\beta \\|_2^2$ 的线性最小二乘问题，其中 $A = Z'X$ 且 $b = Z'y_{\\text{vec}}$。解由正规方程给出：$\\beta = (A^\\top A)^{-1} A^\\top b$。代回后，GMM 估计量为\n    $$\n    \\widehat{\\beta} = \\left( (X'Z)(Z'X) \\right)^{-1} (X'Z)(Z'y_{\\text{vec}}).\n    $$\n    对于非共线数据，此解析公式计算效率高且数值稳定，将用于估计 $\\widehat{\\beta}$。\n\n2.  **从结构模型进行数据模拟**\n    需要一个函数从结构模型 $y_t = \\theta y_{t-1} + \\varepsilon_t$ 生成时间序列数据。生成单个长度为 $T$ 的样本的过程如下：\n    - 初始化一个长度为 $B+T+1$ 的路径，其中 $y_0 = 0$。\n    - 使用一个预先生成的长度为 $B+T$ 的独立同分布标准正态创新序列 $\\varepsilon_1, \\dots, \\varepsilon_{B+T}$。\n    - 从 $t=1$ 到 $B+T$ 迭代：$y_t = \\theta y_{t-1} + \\varepsilon_t$。\n    - 最终样本由最后 $T$ 个观测值组成，即 $\\{y_{B+1}, \\dots, y_{B+T}\\}$，有效丢弃了初始的 $B$ 个预烧期和 $y_0$。\n\n3.  **间接推断过程**\n    问题的核心是每个测试用例的四步过程：\n    - **步骤 A：“观测”数据和参数**。对于给定的测试用例 $i$，其真实参数为 $\\theta^\\star_i$，样本大小为 $T_i$，种子为 $s^{\\text{obs}}_i$，生成单个“观测”时间序列 $y^{\\text{obs}}$。然后将 GMM 估计量应用于此序列，以获得观测的辅助参数向量 $\\widehat{\\beta}^{\\text{obs}}$。\n    - **步骤 B：生成共同随机数**。对于模拟部分，使用种子 $s^{\\text{sim}}_i + 1, \\dots, s^{\\text{sim}}_i + S_i$ 预先生成 $S_i$ 组独立同分布的标准正态创新，每组长度为 $B+T_i$。在评估网格 $\\mathcal{G}_i$ 中所有候选 $\\theta$ 值的 $Q(\\theta)$ 时，这些创新组保持不变（共同）。这是一种方差缩减技术，可以提高估计量的稳定性。\n    - **步骤 C：评估准则函数 $Q(\\theta)$**。对于网格 $\\mathcal{G}_i$ 上的每个候选 $\\theta$，执行以下操作：\n        - 使用参数为 $\\theta$ 的结构模型和 $S_i$ 组预先生成的创新，模拟 $S_i$ 个时间序列。\n        - 对于 $S_i$ 个模拟序列中的每一个，使用解析 GMM 公式估计辅助参数向量 $\\widehat{\\beta}^{(s)}(\\theta)$。\n        - 计算平均辅助参数向量 $\\overline{\\beta}(\\theta) = \\frac{1}{S_i} \\sum_{s=1}^{S_i} \\widehat{\\beta}^{(s)}(\\theta)$。\n        - 间接推断准则计算为欧几里得距离的平方：$Q(\\theta) = \\|\\widehat{\\beta}^{\\text{obs}} - \\overline{\\beta}(\\theta)\\|_2^2$。\n    - **步骤 D：网格搜索**。为每个 $\\theta \\in \\mathcal{G}_i$ 计算 $Q(\\theta)$ 的值。估计值 $\\widehat{\\theta}_i$ 是使 $Q(\\theta)$ 最小化的 $\\theta$ 值。通过按升序遍历网格，并且仅在找到严格更小的 $Q(\\theta)$ 值时才更新最小值，可以自然地处理指定的打破僵局规则（选择最小的 $\\theta$）。\n\n4.  **实现**\n    将使用 Python 的 `numpy` 库进行数值运算来实现。一个主函数 `solve` 将协调整个过程。将为以下任务创建辅助函数：模拟 AR(1) 过程 (`generate_ar1`)、估计 GMM 参数 (`gmm_estimator`)、为单个测试用例运行整个过程 (`run_test_case`)。主函数将遍历四个指定的测试用例，调用案例运行程序，收集估计的 $\\widehat{\\theta}_i$，并按规定格式化最终输出。", "answer": "```python\nimport numpy as np\nfrom scipy import stats\n\ndef generate_ar1(theta, T, B, innovations):\n    \"\"\"\n    Generates a time series from an AR(1) model.\n    \n    Args:\n        theta (float): The AR(1) parameter.\n        T (int): The number of observations in the final sample.\n        B (int): The number of burn-in periods.\n        innovations (np.ndarray): A vector of T+B standard normal innovations.\n\n    Returns:\n        np.ndarray: The simulated time series of length T.\n    \"\"\"\n    path_len = T + B\n    path = np.zeros(path_len + 1)  # path[0] is y_0\n    \n    for t in range(path_len):\n        path[t + 1] = theta * path[t] + innovations[t]\n        \n    return path[B + 1:] # Returns y_{B+1}, ..., y_{B+T} (length T)\n\ndef gmm_estimator(y):\n    \"\"\"\n    Computes the GMM estimator for the auxiliary model.\n    y_t = beta_0 + beta_1 * y_{t-1} + u_t\n    z_t = [1, y_{t-1}, y_{t-2}]\n    \n    Args:\n        y (np.ndarray): The time series data (y_1, ..., y_T), length T.\n        \n    Returns:\n        np.ndarray: The GMM estimate [beta_0_hat, beta_1_hat].\n    \"\"\"\n    T = len(y)\n    n = T - 2 # Number of observations for moment conditions (t=3 to T)\n    \n    if n = 0:\n        raise ValueError(\"Time series is too short for GMM estimation.\")\n\n    # y_vec corresponds to y_t for t in {3..T}\n    y_vec = y[2:T] # shape (n,)\n    \n    # X corresponds to [1, y_{t-1}] for t in {3..T}\n    X = np.zeros((n, 2))\n    X[:, 0] = 1.0\n    X[:, 1] = y[1:T-1] # y_2, ..., y_{T-1}\n    \n    # Z corresponds to [1, y_{t-1}, y_{t-2}] for t in {3..T}\n    Z = np.zeros((n, 3))\n    Z[:, 0] = 1.0\n    Z[:, 1] = y[1:T-1] # y_2, ..., y_{T-1}\n    Z[:, 2] = y[0:T-2] # y_1, ..., y_{T-2}\n    \n    # Analytical solution for GMM with W = I:\n    # beta_hat = ( (X'Z Z'X)^-1 ) * ( X'Z Z'y )\n    XT_Z = X.T @ Z\n    ZT_X = Z.T @ X\n    ZT_y = Z.T @ y_vec\n    \n    # Matrix to be inverted\n    M = XT_Z @ ZT_X\n    \n    try:\n        M_inv = np.linalg.inv(M)\n    except np.linalg.LinAlgError:\n        # Fallback to pseudo-inverse if matrix is singular\n        M_inv = np.linalg.pinv(M)\n        \n    beta_hat = M_inv @ (XT_Z @ ZT_y)\n    \n    return beta_hat\n\ndef run_test_case(params):\n    \"\"\"\n    Performs the full indirect inference estimation for one test case.\n    \n    Args:\n        params (dict): A dictionary with all parameters for the test case.\n        \n    Returns:\n        float: The indirect inference estimate of theta.\n    \"\"\"\n    T, theta_star, S, delta, s_obs, s_sim = params.values()\n    B = 200\n\n    # 1. Generate \"observed\" data and estimate beta_obs\n    rng_obs = np.random.default_rng(s_obs)\n    innovs_obs = rng_obs.standard_normal(T + B)\n    y_obs = generate_ar1(theta_star, T, B, innovs_obs)\n    beta_obs = gmm_estimator(y_obs)\n\n    # 2. Pre-generate common random numbers for simulations\n    sim_innovations = []\n    for s in range(1, S + 1):\n        rng_sim = np.random.default_rng(s_sim + s)\n        sim_innovations.append(rng_sim.standard_normal(T + B))\n\n    # 3. Grid search for theta\n    grid_start = -0.95\n    grid_end = 0.95\n    num_points = int(round((grid_end - grid_start) / delta)) + 1\n    theta_grid = np.linspace(grid_start, grid_end, num_points)\n\n    min_Q = np.inf\n    best_theta = None\n\n    for theta_candidate in theta_grid:\n        beta_sim_list = []\n        for s in range(S):\n            y_sim = generate_ar1(theta_candidate, T, B, sim_innovations[s])\n            beta_sim = gmm_estimator(y_sim)\n            beta_sim_list.append(beta_sim)\n        \n        beta_bar = np.mean(beta_sim_list, axis=0)\n        \n        Q = np.sum((beta_obs - beta_bar)**2)\n        \n        # Tie-breaking: select the smallest theta, so only update on strictly smaller Q\n        if Q  min_Q:\n            min_Q = Q\n            best_theta = theta_candidate\n            \n    return best_theta\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the results.\n    \"\"\"\n    test_cases = [\n        {'T': 300, 'theta_star': 0.6, 'S': 20, 'delta': 0.01, 's_obs': 1729, 's_sim': 20231},\n        {'T': 300, 'theta_star': 0.9, 'S': 25, 'delta': 0.01, 's_obs': 1730, 's_sim': 20232},\n        {'T': 150, 'theta_star': 0.0, 'S': 40, 'delta': 0.02, 's_obs': 1731, 's_sim': 20233},\n        {'T': 300, 'theta_star': -0.5, 'S': 20, 'delta': 0.01, 's_obs': 1732, 's_sim': 20234},\n    ]\n\n    results = []\n    for case in test_cases:\n        estimated_theta = run_test_case(case)\n        results.append(estimated_theta)\n\n    print(f\"[{','.join(f'{x:.4f}' for x in results)}]\")\n\nsolve()\n```", "id": "2401827"}, {"introduction": "最后一个练习通过将间接推断应用于一个高度复杂的结构模型，展示了其真正的强大之处和灵活性。你的任务是估计逻辑斯蒂映射（logistic map）的参数，这是一个以其混沌动力学行为而闻名的系统，传统的估计方法通常难以处理。通过使用一个简单的一阶自回归模型作为辅助“探针”，你将看到间接推断如何能够成功估计这类看似棘手的非线性系统的参数。[@problem_id:2401774]", "problem": "构建一个独立的程序，该程序实现一个基于间接推断 (Indirect Inference, II) 的估计器，以恢复混沌离散时间模型的结构参数。真实数据生成过程 (DGP) 由具有单个未知参数的逻辑斯谛映射 (logistic map) 定义。状态方程为\n$$\nx_{t+1} = r \\, x_t \\, (1 - x_t), \\quad t = 0,1,2,\\dots,T-1,\n$$\n其中初始条件 $x_0 \\in (0,1)$ 为已知固定值，观测方程为\n$$\ny_t = x_t + \\varepsilon_t, \\quad \\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2), \\quad t = 0,1,2,\\dots,T-1,\n$$\n其中 $\\varepsilon_t$ 是独立同分布的高斯扰动，其标准差 $\\sigma  0$ 已知（$\\sigma$ 可能为 0）。唯一的未知结构参数是 $r \\in \\mathbb{R}$。目标是使用间接推断 (II) 来估计 $r$，通过匹配根据观测数据计算的辅助统计量与根据结构模型模拟数据计算的辅助统计量。\n\n将辅助模型定义为带截距的一阶自回归模型 $AR(1)$：\n$$\ny_t = a_0 + a_1 \\, y_{t-1} + u_t, \\quad t=1,2,\\dots,T-1,\n$$\n其中 $u_t$ 是均值为零的残差。对于任何序列 $\\{y_t\\}_{t=0}^{T-1}$，定义辅助统计向量\n$$\n\\hat{b}(y) = \\big(\\hat{a}_0(y), \\hat{a}_1(y), \\hat{s}_u(y)\\big),\n$$\n其中 $\\hat{a}_0(y)$ 和 $\\hat{a}_1(y)$ 是 $a_0$ 和 $a_1$ 的普通最小二乘 (OLS) 估计量，且\n$$\n\\hat{s}_u(y) = \\sqrt{\\frac{1}{T-1}\\sum_{t=1}^{T-1} \\hat{u}_t(y)^2},\n$$\n其中 $\\hat{u}_t(y)$ 是 OLS 残差。$r$ 的间接推断估计量定义为根据观测数据计算的辅助统计量与使用候选参数值从结构模型生成的模拟数据计算的辅助统计量之间的二次距离的最小化子。令 $K \\in \\mathbb{N}$ 为用于求平均的独立模拟数据集的数量。对于一个候选参数 $r$，使用相同的样本量 $T$、相同的初始条件 $x_0$ 以及具有相同已知 $\\sigma$ 的高斯观测噪声来定义 $K$ 个模拟数据集 $\\{y^{(k)}(r)\\}_{k=1}^K$。将平均模拟辅助统计量定义为\n$$\n\\bar{b}(r) = \\frac{1}{K} \\sum_{k=1}^K \\hat{b}\\!\\left(y^{(k)}(r)\\right).\n$$\n使用单位权重矩阵 $W = I_3$，准则函数为\n$$\nQ(r) = \\left(\\hat{b}(y^{obs}) - \\bar{b}(r) \\right)^{\\top} W \\left(\\hat{b}(y^{obs}) - \\bar{b}(r) \\right),\n$$\n其中 $y^{obs}$ 表示观测数据序列。间接推断估计量是\n$$\n\\hat{r} \\in \\arg\\min_{r \\in \\mathcal{R}} Q(r),\n$$\n在预先指定的有限网格 $\\mathcal{R}$ 上。\n\n您的程序必须完全按照上述定义实现此估计器，并使用以下固定的设计元素以确保确定性和可复现性：\n\n- 参数网格：\n$$\n\\mathcal{R} = \\left\\{ 3.50 + 0.0025 \\, j \\,:\\, j = 0,1,2,\\dots,200 \\right\\}.\n$$\n- 模拟重复次数：$K = 15$。\n- 初始条件：$x_0 = 0.123456789$。\n- 权重矩阵：$W = I_3$。\n- 为了在不同候选值 $r \\in \\mathcal{R}$ 之间实现可复现性，请对模拟数据集使用共同随机数：对于每个测试用例，使用固定的种子 $s_{sim}$ 从伪随机数生成器生成恰好 $K$ 个长度为 $T$ 的独立高斯噪声序列，并对所有 $r \\in \\mathcal{R}$ 重复使用这 $K$ 个序列。对于观测数据，使用固定的种子 $s_{obs}$ 从伪随机数生成器生成其高斯噪声序列。在所有情况下，将 $\\varepsilon_t$ 抽取为独立的 $\\mathcal{N}(0,\\sigma^2)$ 变量。所有模拟中的初始条件 $x_0$ 必须相同。\n\n测试套件。为以下每个测试用例实现并求解估计器，其中指定了真实的结构参数、样本量、噪声水平和种子：\n\n- 案例 A (一般情况)：$r^{\\star} = 3.8000$, $T = 1000$, $\\sigma = 0.0200$, $s_{obs} = 1729$, $s_{sim} = 2468$。\n- 案例 B (接近混沌边缘，较低噪声)：$r^{\\star} = 3.5700$, $T = 800$, $\\sigma = 0.0100$, $s_{obs} = 1730$, $s_{sim} = 2469$。\n- 案例 C (最大混沌，无测量噪声)：$r^{\\star} = 4.0000$, $T = 1200$, $\\sigma = 0.0000$, $s_{obs} = 1731$, $s_{sim} = 2470$。\n- 案例 D (较短序列，较高噪声)：$r^{\\star} = 3.9500$, $T = 300$, $\\sigma = 0.0500$, $s_{obs} = 1732$, $s_{sim} = 2471$。\n\n对于每种情况，通过使用指定的 $r^{\\star}$、$x_0$ 和 $T$ 模拟逻辑斯谛映射，并使用指定的 $s_{obs}$ 添加具有指定 $\\sigma$ 的高斯噪声，来生成观测数据 $y^{obs}$。然后，如上所定义，在网格 $\\mathcal{R}$ 上计算间接推断估计量 $\\hat{r}$，每个网格点使用 $K$ 个模拟数据集，这些数据集是使用指定的 $s_{sim}$ 的共同随机数生成的。\n\n最终输出格式。您的程序应生成单行输出，其中包含案例 A–D 的四个估计值 $\\hat{r}$，按顺序排列，形式为方括号括起来的逗号分隔列表。每个值必须打印为小数，精确到小数点后六位。例如，输出格式类似于“[rA,rB,rC,rD]”，其中 $rA$、$rB$、$rC$ 和 $rD$ 是四个四舍五入后的估计值。不涉及单位，也不应打印任何附加文本。", "solution": "该问题要求构建一个基于间接推断 (II) 定义的估计器，并将其应用于一个混沌结构模型。结构 DGP 是带观测噪声的逻辑斯谛映射。该估计器由以下要素定义：\n\n1. 结构模型。状态方程为 $x_{t+1} = r \\, x_t \\, (1 - x_t)$，其中 $t = 0,1,\\dots,T-1$，$x_0 = 0.123456789$。观测数据为 $y_t = x_t + \\varepsilon_t$，其中对于每个 $t$，$\\varepsilon_t \\sim \\mathcal{N}(0,\\sigma^2)$ 都是独立的。\n\n2. 辅助模型。辅助模型是带截距的 $AR(1)$ 模型：$y_t = a_0 + a_1 \\, y_{t-1} + u_t$，其中 $t = 1,\\dots,T-1$。对于任何序列 $y = (y_0,\\dots,y_{T-1})$，使用正规方程定义 OLS 估计。令 $Y = (y_1,\\dots,y_{T-1})^{\\top}$，$X$ 为 $(T-1) \\times 2$ 矩阵，其第一列为 1，第二列为 $(y_0,\\dots,y_{T-2})^{\\top}$。OLS 估计量是\n$$\n\\hat{\\beta}(y) = \\begin{pmatrix} \\hat{a}_0(y) \\\\ \\hat{a}_1(y) \\end{pmatrix} = (X^{\\top}X)^{-1} X^{\\top} Y,\n$$\n残差为 $\\hat{u}(y) = Y - X \\hat{\\beta}(y)$。残差离散度统计量为\n$$\n\\hat{s}_u(y) = \\sqrt{ \\frac{1}{T-1} \\sum_{t=1}^{T-1} \\hat{u}_t(y)^2 }.\n$$\n将辅助统计量集合为 $\\hat{b}(y) = \\big(\\hat{a}_0(y), \\hat{a}_1(y), \\hat{s}_u(y)\\big)$。\n\n3. 间接推断准则。对于一个候选参数 $r$，使用初始状态为 $x_0$ 和已知 $\\sigma$ 的高斯噪声的结构模型，模拟 $K = 15$ 个长度为 $T$ 的数据集 $y^{(k)}(r)$。计算模拟中辅助统计量的平均值，\n$$\n\\bar{b}(r) = \\frac{1}{K} \\sum_{k=1}^K \\hat{b}\\!\\left(y^{(k)}(r)\\right),\n$$\n并使用单位权重矩阵 $W = I_3$ 定义二次距离为\n$$\nQ(r) = \\left(\\hat{b}(y^{obs}) - \\bar{b}(r)\\right)^{\\top} \\left(\\hat{b}(y^{obs}) - \\bar{b}(r)\\right).\n$$\n估计量是 $\\hat{r} \\in \\arg\\min_{r \\in \\mathcal{R}} Q(r)$，在有限网格 $\\mathcal{R} = \\{3.50 + 0.0025 \\, j : j = 0,1,\\dots,200\\}$ 上进行最小化。\n\n4. 可复现性与共同随机数。对于每个测试用例，固定观测噪声种子 $s_{obs}$ 以生成单个观测序列 $\\{\\varepsilon_t^{obs}\\}$，并固定模拟种子 $s_{sim}$ 以生成恰好 $K = 15$ 个独立的高斯噪声序列 $\\{\\varepsilon_t^{(k)}\\}_{k=1}^K$。对所有候选参数 $r \\in \\mathcal{R}$ 使用这相同的 $K$ 个序列。这实现了共同随机数，因此 $Q(r)$ 的变化是由于结构动态的变化，而不是由于模拟噪声的变化。所有模拟的初始条件 $x_0 = 0.123456789$ 都是相同的。\n\n5. 与第一性原理一致的实施计划。对于每个测试用例：\n- 通过模拟 $x_{t+1} = r^{\\star} x_t (1-x_t)$（使用 $x_0$），然后对 $t = 0,\\dots,T-1$ 加上 $\\varepsilon_t^{obs} \\sim \\mathcal{N}(0,\\sigma^2)$ 来生成观测序列 $y^{obs}$。\n- 通过上述 OLS 公式计算 $\\hat{b}(y^{obs})$。\n- 使用指定的 $s_{sim}$ 生成 $K$ 个独立的长度为 $T$ 的高斯噪声序列。对于每个候选 $r \\in \\mathcal{R}$，使用 $x_0$ 从逻辑斯谛映射模拟结构状态路径 $x(r)$，形成 $K$ 个模拟数据集 $y^{(k)}(r) = x(r) + \\varepsilon^{(k)}$，为每个 $k$ 计算 $\\hat{b}\\!\\left(y^{(k)}(r)\\right)$，得到 $\\bar{b}(r)$，评估 $Q(r)$，并选择在 $\\mathcal{R}$ 上的最小化子。如果由于数值上的平局而存在多个最小化子，则选择 $\\mathcal{R}$ 中达到最小值的最小 $r$，这是一个明确定义的规则。\n\n6. 数值和统计考虑。对于 $r \\in [3.50,4.00]$，逻辑斯谛映射表现出复杂且通常是混沌的行为。间接推断利用辅助模型来比较观测数据和模拟数据之间的显著特征（截距、持久性、残差离散度）。在一组使用共同随机数的模拟中匹配这些特征，可以得到一个指导 $r$ 选择的准则。有限网格 $\\mathcal{R}$ 定义了对连续参数空间的筛分式逼近；网格分辨率 $0.0025$ 意味着在理想条件下，$\\hat{r}$ 的可达到精度在 $0.0025$ 之内。测量噪声 $\\sigma$ 和样本量 $T$ 的存在会影响辅助统计量的变异性，从而影响 $\\hat{r}$ 的精度。\n\n7. 输出。最终程序按 A、B、C、D 的顺序计算四个指定案例的 $\\hat{r}$，并打印一行包含四个估计值的方括号逗号分隔列表，每个估计值四舍五入到小数点后六位，没有额外输出。\n\n此解决方案通过指定辅助统计量、模拟框架以及在规定网格上的最小化，直接应用了间接推断的定义，确保每个步骤都基于数学公式，并且由于固定的种子和共同随机数，结果是可复现的。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef simulate_logistic_path(r: float, T: int, x0: float) - np.ndarray:\n    \"\"\"\n    Simulate the logistic map x_{t+1} = r x_t (1 - x_t) for t=0,...,T-2 with x_0 = x0.\n    Returns an array x of length T with x[0]=x0.\n    \"\"\"\n    x = np.empty(T, dtype=float)\n    x[0] = x0\n    for t in range(T - 1):\n        x[t + 1] = r * x[t] * (1.0 - x[t])\n    return x\n\ndef auxiliary_stats_ar1(y: np.ndarray) - np.ndarray:\n    \"\"\"\n    Compute auxiliary statistics from AR(1) with intercept:\n    y_t = a0 + a1 y_{t-1} + u_t, t=1..T-1.\n    Returns [a0_hat, a1_hat, s_u_hat] where s_u_hat = sqrt( (1/(T-1)) sum u_t^2 ).\n    \"\"\"\n    # Ensure 1D float array\n    y = np.asarray(y, dtype=float).ravel()\n    if y.size  2:\n        # Degenerate case: not enough observations; return NaNs (should not occur in this problem)\n        return np.array([np.nan, np.nan, np.nan], dtype=float)\n    y_curr = y[1:]\n    y_lag = y[:-1]\n    # Design matrix with intercept\n    X = np.column_stack((np.ones_like(y_lag), y_lag))\n    # OLS via normal equations\n    XtX = X.T @ X\n    XtY = X.T @ y_curr\n    beta = np.linalg.solve(XtX, XtY)\n    resid = y_curr - X @ beta\n    s_u = np.sqrt(np.mean(resid ** 2))\n    return np.array([beta[0], beta[1], s_u], dtype=float)\n\ndef indirect_inference_estimate_r(\n    r_grid: np.ndarray,\n    K: int,\n    x0: float,\n    T: int,\n    sigma: float,\n    obs_seed: int,\n    sim_seed: int,\n    r_true: float\n) - float:\n    \"\"\"\n    Compute the indirect inference estimate of r over the given grid r_grid.\n    - Generate observed data using r_true, x0, T, sigma with RNG seed obs_seed.\n    - Generate K simulation noise sequences using seed sim_seed (common random numbers).\n    - For each r in r_grid, simulate x path and form K simulated datasets by adding the fixed noise sequences.\n    - Compute auxiliary statistics for observed and average over simulated datasets.\n    - Minimize squared Euclidean distance between observed and average simulated auxiliary stats.\n    Returns the minimizing r (tie broken by smallest r).\n    \"\"\"\n    # Generate observed data\n    x_obs = simulate_logistic_path(r_true, T, x0)\n    rng_obs = np.random.default_rng(obs_seed)\n    eps_obs = rng_obs.normal(loc=0.0, scale=sigma, size=T)\n    y_obs = x_obs + eps_obs\n    b_obs = auxiliary_stats_ar1(y_obs)\n\n    # Pre-generate K noise sequences (common random numbers)\n    rng_sim = np.random.default_rng(sim_seed)\n    eps_bank = rng_sim.normal(loc=0.0, scale=sigma, size=(K, T))\n\n    # For each r, compute Q(r)\n    best_r = None\n    best_Q = np.inf\n\n    # Loop over candidate r\n    for r in r_grid:\n        # Simulate state path once for this r\n        x_sim = simulate_logistic_path(r, T, x0)\n        \n        b_sum = np.zeros(3, dtype=float)\n        # Loop over K replications using common random numbers\n        for k in range(K):\n            y_k = x_sim + eps_bank[k]\n            b_k = auxiliary_stats_ar1(y_k)\n            b_sum += b_k\n        b_bar = b_sum / K\n        \n        diff = b_obs - b_bar\n        Q_r = float(diff @ diff)  # Identity weighting\n        \n        # Update best r if a smaller Q is found. Tie-breaking is handled\n        # by iterating r in increasing order and only updating on strict inequality.\n        if Q_r  best_Q:\n            best_Q = Q_r\n            best_r = r\n\n    return float(best_r)\n\ndef solve():\n    # Fixed design elements\n    x0 = 0.123456789\n    K = 15\n    # Grid: {3.50 + 0.0025 * j, j=0..200}\n    r_grid = 3.50 + 0.0025 * np.arange(201, dtype=float)\n\n    # Define the test cases from the problem statement.\n    # Each tuple: (r_true, T, sigma, s_obs, s_sim)\n    test_cases = [\n        (3.8000, 1000, 0.0200, 1729, 2468),  # Case A\n        (3.5700,  800, 0.0100, 1730, 2469),  # Case B\n        (4.0000, 1200, 0.0000, 1731, 2470),  # Case C\n        (3.9500,  300, 0.0500, 1732, 2471),  # Case D\n    ]\n\n    results = []\n    for r_true, T, sigma, s_obs, s_sim in test_cases:\n        r_hat = indirect_inference_estimate_r(\n            r_grid=r_grid,\n            K=K,\n            x0=x0,\n            T=T,\n            sigma=sigma,\n            obs_seed=s_obs,\n            sim_seed=s_sim,\n            r_true=r_true\n        )\n        results.append(r_hat)\n\n    # Format each result to exactly 6 decimal places\n    formatted = \",\".join(f\"{val:.6f}\" for val in results)\n    # Final print statement in the exact required format.\n    print(f\"[{formatted}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2401774"}]}