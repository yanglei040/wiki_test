{"hands_on_practices": [{"introduction": "在应用超阈值模型（POT）时，最关键也最具挑战性的一步是选择一个合适的阈值 $u$。这个选择本质上是在偏差和方差之间进行权衡：过低的阈值会引入不属于尾部的数据，导致估计有偏；而过高的阈值则会减少样本量，使得估计的方差增大。本练习将通过一个模拟金融时间序列的场景，指导你分析估计出的尾部指数 $\\xi$ 对不同阈值选择的敏感性，这是在任何实际应用中都必不可少的诊断步骤 [@problem_id:2418694]。", "problem": "考虑一个合成的日对数收益率序列，该序列旨在近似标准普尔500指数（S&P 500）日收益率的分布特征，用于尾部风险分析。设日对数收益率为 $R_t$，$t = 1, \\dots, n$，并定义 $R_t = \\mu + \\sigma \\cdot T_\\nu$，其中 $T_\\nu$ 是一个自由度为 $\\nu$、位置为 $0$、单位尺度的学生t（Student’s $t$）随机变量。使用 $n = 6000$，$\\mu = 0$，$\\sigma = 0.01$，$\\nu = 5$ 以及一个固定的伪随机数生成器种子 $s = 20240517$ 以确保可复现性。定义损失为 $L_t = -R_t$。\n\n对于任意阈值 $u$，将超出量（exceedances）定义为 $Y_i = L_i - u$，其中 $i$ 为所有满足 $L_i > u$ 的索引。在超阈值峰值（Peaks-Over-Threshold, POT）模型下，假设超出量 $Y_i$ 服从广义帕累托分布（Generalized Pareto Distribution, GPD），其尾部指数为 $\\xi$，尺度参数为 $\\beta$。\n\n你的任务是通过对下述测试套件中的每个阈值，计算从超过 $u$ 的超出量中获得的 $\\xi$ 的估计值，来量化估计的尾部指数 $\\xi$ 对阈值 $u$ 选择的敏感性。对于每个阈值，将 $u$ 设置为给定分位数水平 $q$ 下损失 $L_t$ 的经验 $q$-分位数。\n\n测试套件（阈值的分位数水平）：$q \\in \\{0.80, 0.90, 0.95, 0.975, 0.99, 0.995, 0.999\\}$。\n\n对于测试套件中的每个 $q$，计算出相应的 $\\xi$ 的估计值，该值为一个实数。最终所需的输出是一行，其中包含按指定顺序排列的各阈值的结果，四舍五入到 $6$ 位小数，并以逗号分隔的列表形式包含在方括号中。例如，一个包含三个结果的输出应类似于 $[x_1,x_2,x_3]$，其中每个 $x_j$ 是一个四舍五入到 $6$ 位小数的数字。\n\n你的程序必须生成单行输出，其中包含按精确格式和顺序排列的估计值，不得包含任何额外文本。不涉及物理单位。不涉及角度。不涉及百分比。答案必须是实值浮点数。", "solution": "提交分析的问题陈述被认为是有效的。它提出了一个在计算金融领域中定义明确、有科学依据的问题，特别是关于应用极值理论（Extreme Value Theory, EVT）中的超阈值峰值（Peaks-Over-Threshold, POT）方法。所有参数和条件都已明确指定，从而可以得到一个唯一且可复现的解。该方法论基于公认的统计学原理。\n\n问题的核心在于 Pickands–Balkema–de Haan 定理的应用。该定理假定，对于一大类具有重尾（heavy tails）的分布，超过一个足够高阈值的超出量的条件分布会收敛于一个广义帕累托分布（GPD）。所指定的数据模型 $R_t = \\mu + \\sigma \\cdot T_\\nu$，其中 $T_\\nu$ 是一个自由度为 $\\nu$ 的学生t分布（Student's $t$-distribution）的随机变量，是此类重尾过程的一个典型例子。对于自由度为 $\\nu$ 的学生t分布，理论上的 GPD 尾部指数为 $\\xi = 1/\\nu$。在这个问题中，$\\nu=5$，因此尾部指数的理论期望值为 $\\xi = 1/5 = 0.2$。本练习旨在从有限样本中估计此参数，并观察其对阈值选择的敏感性。\n\n计算过程如下：\n\n1.  **数据生成**：创建一个合成数据集来模拟金融损失。从自由度为 $\\nu=5$、位置为 $0$、单位尺度的学生t分布中生成一个包含 $n=6000$ 个点的样本。这些点记为 $T_t$，使用给定的参数 $\\mu=0$ 和 $\\sigma=0.01$ 将它们转换为对数收益率 $R_t = \\mu + \\sigma \\cdot T_t$。相应的损失则定义为 $L_t = -R_t$。使用固定的种子 $s=20240517$ 确保了所生成数据的绝对可复现性。\n\n2.  **阈值选择**：问题要求分析对阈值 $u$ 的敏感性。为此，根据生成的损失数据 $L_t$ 的经验分位数选择一系列阈值。对于测试套件 $\\{0.80, 0.90, 0.95, 0.975, 0.99, 0.995, 0.999\\}$ 中的每个分位数水平 $q$，阈值 $u$ 被设置为满足 $P(L_t \\le u) = q$ 的值。\n\n3.  **超出量计算**：对于每个阈值 $u$，编译超出量集合。这些值是 $Y_i = L_i - u$，其中 $L_i$ 是所有严格大于 $u$ 的观测值。这组 $Y_i$ 值代表了将要拟合 GPD 的数据。\n\n4.  **GPD 参数估计**：GPD 的尾部指数 $\\xi$ 是从超出量序列 $\\{Y_i\\}$ 中估计出来的。对此进行估计的标准且最可靠的方法是最大似然估计（Maximum Likelihood Estimation, MLE），此处将采用该方法。GPD 的特征在于一个形状参数（即尾部指数 $\\xi$）和一个尺度参数 $\\beta$。根据 POT 模型，超出量本质上是正的，因此 GPD 的位置参数理论上为 $0$。在拟合过程中强制执行此约束（在 `scipy` 实现中使用 `floc=0`），以提高估计的稳定性和理论正确性。MLE 过程计算使观测到所收集的超出量数据的概率最大化的 $\\xi$ 值。\n\n从阈值选择到 GPD 拟合的整个过程，会对测试套件中的每个分位数水平 $q$ 重复进行。所得的估计尾部指数序列 $\\hat{\\xi}(q)$ 展示了阈值选择对尾部风险度量的实际影响。预期随着 $q$ 趋近于 $1$，阈值 $u$ 会增加，GPD 近似会变得更准确，并且估计的 $\\hat{\\xi}$ 应收敛于理论值 $0.2$。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t, genpareto\n\ndef solve():\n    \"\"\"\n    Computes the sensitivity of the GPD tail index estimate to the threshold choice\n    for a synthetic financial loss series based on the Peaks-Over-Threshold method.\n    \"\"\"\n    # --- Problem Parameters ---\n    n = 6000\n    mu = 0.0\n    sigma = 0.01\n    nu = 5.0\n    seed = 20240517\n    \n    # --- Test Suite ---\n    # The quantile levels for threshold selection define the test cases.\n    test_cases = [0.80, 0.90, 0.95, 0.975, 0.99, 0.995, 0.999]\n    \n    # --- Data Generation ---\n    # Use a specific random number generator for reproducibility as per problem statement.\n    rng = np.random.default_rng(seed)\n    \n    # Generate random variates from Student's t-distribution with nu degrees of freedom.\n    # T_nu is a standard t-distribution (location=0, scale=1).\n    T_nu = t.rvs(df=nu, size=n, random_state=rng)\n    \n    # Calculate log-returns R_t and losses L_t based on the generated variates.\n    R_t = mu + sigma * T_nu\n    L_t = -R_t\n    \n    # --- Main Logic: POT Analysis for each threshold ---\n    results = []\n    for q in test_cases:\n        # 1. Set the threshold 'u' as the empirical q-quantile of the losses.\n        u = np.quantile(L_t, q)\n        \n        # 2. Identify all losses exceeding the threshold and compute the exceedance values.\n        # Exceedances are defined as Y_i = L_i - u for all L_i > u.\n        exceedances = L_t[L_t > u] - u\n        \n        # 3. Fit a Generalized Pareto Distribution (GPD) to the exceedances.\n        # We use Maximum Likelihood Estimation (MLE), as implemented in scipy.\n        # The POT model implies a location parameter of 0 for exceedances, which we fix\n        # using the 'floc=0' argument for theoretical consistency and numerical stability.\n        # The 'c' shape parameter returned by the fit corresponds to the tail index 'xi'.\n        xi, _, _ = genpareto.fit(exceedances, floc=0)\n        \n        results.append(xi)\n\n    # --- Final Output Formatting ---\n    # The problem requires the results to be rounded to 6 decimal places and\n    # formatted as a comma-separated list within square brackets.\n    formatted_results = [f'{r:.6f}' for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "2418694"}, {"introduction": "超阈值（POT）方法的核心理论依据是Pickands–Balkema–de Haan定理，该定理指出，超过一个高阈值的超额损失分布会收敛于广义帕累托分布（GPD）。本练习将对这一理论进行具体检验，通过比较GPD模型与另一个看似合理但缺乏坚实理论基础的替代模型——拉伸指数分布（即Weibull分布）的性能。通过评估哪个模型能更好地拟合极端数据，你将更深刻地理解GPD在极值分析中的独特地位与优势 [@problem_id:2418756]。", "problem": "考虑使用超阈值峰值 (peaks-over-threshold) 方法对重大金融损失进行建模。令 $X \\ge 0$ 表示一个非负损失随机变量。给定一个高阈值 $u$，定义超出量 (exceedances) 为 $Y = X - u \\mid X > u$。您将比较两种尾部模型：\n\n- 使用广义帕累托分布 (Generalized Pareto Distribution, GPD) 对 $Y$ 进行超阈值峰值 (POT) 建模：其理论依据是 Pickands–Balkema–de Haan 定理，该定理指出，对于一大类基础分布，当 $u$ 增加时，条件超出量分布收敛于 GPD。\n\n- 一个简单的拉伸指数模型 (stretched exponential model) 用于尾部建模，实现为形状参数为 $\\beta > 0$、尺度参数为 $\\lambda > 0$ 的威布尔分布 (Weibull distribution)；在此模型下，给定 $X > u$ 时 $X$ 的条件密度为 $f_{\\text{Weibull}}(x;\\beta,\\lambda)/S_{\\text{Weibull}}(u;\\beta,\\lambda)$，其中 $f_{\\text{Weibull}}$ 是威布尔密度函数，$S_{\\text{Weibull}}$ 是威布尔生存函数。\n\n您必须仅使用在指定百分位数 $p \\in (0,1)$ 处从训练样本计算出的阈值 $u$ 以上的超出量，为两种模型实现最大似然估计，然后使用相同的 $u$ 在一个单独的测试样本上评估样本外预测性能。\n\n使用的基本事实和定义：\n\n- 对于超出量 $Y \\ge 0$，形状参数为 $\\xi \\in \\mathbb{R}$、尺度参数为 $\\sigma > 0$ 的广义帕累托分布 (GPD) 的密度函数为\n$$\ng(y;\\xi,\\sigma) = \\begin{cases}\n\\dfrac{1}{\\sigma}\\left(1 + \\dfrac{\\xi y}{\\sigma}\\right)^{-(1/\\xi+1)}, & \\xi \\ne 0,\\; 1+\\dfrac{\\xi y}{\\sigma}>0 \\\\\n\\dfrac{1}{\\sigma}\\exp\\!\\left(-\\dfrac{y}{\\sigma}\\right), & \\xi = 0,\\; y \\ge 0\n\\end{cases}\n$$\n\n- 对于 $X \\ge 0$，形状参数为 $\\beta > 0$、尺度参数为 $\\lambda > 0$ 的威布尔 (拉伸指数) 分布的密度函数和生存函数为\n$$\nf_{\\text{Weibull}}(x;\\beta,\\lambda) = \\dfrac{\\beta}{\\lambda}\\left(\\dfrac{x}{\\lambda}\\right)^{\\beta-1} \\exp\\!\\left(-\\left(\\dfrac{x}{\\lambda}\\right)^{\\beta}\\right), \\quad\nS_{\\text{Weibull}}(x;\\beta,\\lambda) = \\exp\\!\\left(-\\left(\\dfrac{x}{\\lambda}\\right)^{\\beta}\\right).\n$$\n因此，对于 $x>u$，给定 $X>u$ 时 $X$ 的条件密度为 $f_{\\text{Weibull}}(x;\\beta,\\lambda)/S_{\\text{Weibull}}(u;\\beta,\\lambda)$。\n\n您将通过逆变换进行确定性数据生成，以避免随机可变性。对于样本量 $n \\in \\mathbb{N}$，定义一个确定性格点 $u_k = (k-0.5)/n$，其中 $k = 1,2,\\dots,n$。要从累积分布函数为 $F$ 的分布中进行模拟，设置 $x_k = F^{-1}(u_k)$。\n\n使用的逆累积分布函数：\n\n- 对于 $\\xi \\ne 0$ 和 $\\sigma > 0$ 的 GPD，\n$$\nF^{-1}(u) = \\dfrac{\\sigma}{\\xi}\\left((1-u)^{-\\xi} - 1\\right), \\quad u \\in (0,1).\n$$\n对于 $\\xi = 0$ (指数情况)，使用 $F^{-1}(u) = -\\sigma \\ln(1-u)$。\n\n- 对于形状参数 $\\beta>0$、尺度参数 $\\lambda>0$ 的威布尔分布，\n$$\nF^{-1}(u) = \\lambda\\left(-\\ln(1-u)\\right)^{1/\\beta}, \\quad u \\in (0,1).\n$$\n\n任务：\n\n- 对于下述每个测试用例：\n    1. 使用逆累积分布函数在确定性格点 $u_k = (k - 0.5)/n$ 上，从指定的数据生成过程 (DGP) 生成一个训练样本 $\\{x_k^{\\text{train}}\\}_{k=1}^{n_{\\text{train}}}$ 和一个测试样本 $\\{x_k^{\\text{test}}\\}_{k=1}^{n_{\\text{test}}}$。\n    2. 将阈值 $u$ 计算为训练样本在百分位数 $p$ 处的经验分位数。如果需要，使用标准的线性插值。\n    3. 构建训练超出量集合 $\\mathcal{I}_{\\text{train}} = \\{i: x_i^{\\text{train}} > u\\}$，其中对于 $i \\in \\mathcal{I}_{\\text{train}}$，超出量为 $y_i^{\\text{train}} = x_i^{\\text{train}} - u$。类似地，构建测试超出量集合 $\\mathcal{I}_{\\text{test}} = \\{j: x_j^{\\text{test}} > u\\}$，其中对于 $j \\in \\mathcal{I}_{\\text{test}}$，超出量为 $y_j^{\\text{test}} = x_j^{\\text{test}} - u$。\n    4. 仅使用 $\\{y_i^{\\text{train}}\\}_{i \\in \\mathcal{I}_{\\text{train}}}$，通过最大似然法拟合 GPD 参数 $(\\xi,\\sigma)$。通过在 $X \\mid X>u$ 条件下最大化 $\\{x_i^{\\text{train}}: i \\in \\mathcal{I}_{\\text{train}}\\}$ 的条件似然来拟合威布尔参数 $(\\beta,\\lambda)$，即最大化 $f_{\\text{Weibull}}(x_i;\\beta,\\lambda)/S_{\\text{Weibull}}(u;\\beta,\\lambda)$ 在所有 $i \\in \\mathcal{I}_{\\text{train}}$ 上的乘积。\n    5. 通过计算每个模型下的平均对数似然，评估在测试超出量上的预测性能：\n        - POT (GPD)：$\\dfrac{1}{|\\mathcal{I}_{\\text{test}}|} \\sum_{j \\in \\mathcal{I}_{\\text{test}}} \\log g\\!\\left(y_j^{\\text{test}}; \\hat{\\xi}, \\hat{\\sigma}\\right)$。\n        - 拉伸指数 (条件威布尔)：$\\dfrac{1}{|\\mathcal{I}_{\\text{test}}|} \\sum_{j \\in \\mathcal{I}_{\\text{test}}} \\left[\\log f_{\\text{Weibull}}\\!\\left(x_j^{\\text{test}}; \\hat{\\beta}, \\hat{\\lambda}\\right) - \\log S_{\\text{Weibull}}\\!\\left(u; \\hat{\\beta}, \\hat{\\lambda}\\right)\\right]$。\n       如果 $|\\mathcal{I}_{\\text{test}}| = 0$，则将两个平均值都定义为 $0$。\n    6. 此测试用例的决策规则：如果 POT 模型的平均对数似然严格高于拉伸指数模型，则输出整数 $1$，否则输出 $0$。\n\n测试套件：\n\n- 用例 A (拉伸指数 DGP)：\n    - DGP：形状参数 $\\beta = 0.7$、尺度参数 $\\lambda = 1.0$ 的威布尔分布。\n    - 训练集大小 $n_{\\text{train}} = 5000$，测试集大小 $n_{\\text{test}} = 5000$。\n    - 阈值百分位数 $p = 0.95$。\n\n- 用例 B (重尾 GPD DGP)：\n    - DGP：形状参数 $\\xi = 0.3$、尺度参数 $\\sigma = 1.0$ 的 GPD。\n    - 训练集大小 $n_{\\text{train}} = 5000$，测试集大小 $n_{\\text{test}} = 5000$。\n    - 阈值百分位数 $p = 0.95$。\n\n- 用例 C (边界轻尾)：\n    - DGP：指数分布，即 $\\beta = 1.0, \\lambda = 1.0$ 的威布尔分布 (等价于 $\\xi = 0, \\sigma = 1.0$ 的 GPD)。\n    - 训练集大小 $n_{\\text{train}} = 5000$，测试集大小 $n_{\\text{test}} = 5000$。\n    - 阈值百分位数 $p = 0.99$。\n\n最终输出格式：\n\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，按测试用例 $\\left[\\text{用例 A}, \\text{用例 B}, \\text{用例 C}\\right]$ 的顺序列出结果。对于每个用例，如果 POT 模型更好 (平均对数似然更高)，则打印整数 $1$，否则打印 $0$。例如，输出可能看起来像 $[0,1,0]$。", "solution": "问题陈述已经过严格验证，并被确定为有效。它在科学上基于极值理论的原理，在数学上是适定的 (well-posed)，并且所有必要的参数和程序都得到了明确的定义。该任务是计算统计学中的一个标准练习，旨在比较两种尾部模型——广义帕累托分布 (GPD) 和条件威布尔分布——在确定性生成数据上的拟合优度。\n\n解决方案通过为三个测试用例中的每一个实施问题陈述中概述的步骤来进行。\n\n1.  **数据生成**：对于每个用例，从指定的数据生成过程 (DGP) 生成一个训练样本 $\\{x_k^{\\text{train}}\\}_{k=1}^{n_{\\text{train}}}$ 和一个测试样本 $\\{x_k^{\\text{test}}\\}_{k=1}^{n_{\\text{test}}}$。生成过程是确定性的，使用逆变换采样方法在一个均匀格点 $u_k = (k-0.5)/n$（其中 $k=1, \\dots, n$）上进行。由于 $n_{\\text{train}} = n_{\\text{test}}$ 且生成过程相同，因此训练样本和测试样本将是相同的。这是问题规范的直接结果。\n\n2.  **阈值选择**：将高阈值 $u$ 计算为训练样本对应于指定百分位数 $p$ 的分位数。按照标准做法使用线性插值。\n\n3.  **通过最大似然估计 (MLE) 进行模型拟合**：两种模型都仅使用训练样本中超过阈值的部分 $\\{x_i^{\\text{train}} > u\\}$ 进行拟合。\n\n    *   **广义帕累托分布 (GPD)**：将 GPD 拟合到超出量 $y_i^{\\text{train}} = x_i^{\\text{train}} - u$。通过最大化 GPD 对数似然来估计参数 $(\\xi, \\sigma)$。对于一个包含 $N_u$ 个超出量 $\\{y_i\\}_{i=1}^{N_u}$ 的样本，其对数似然函数由下式给出：\n        $$\n        \\ell(\\xi, \\sigma; \\mathbf{y}) = \\sum_{i=1}^{N_u} \\log g(y_i; \\xi, \\sigma) = \n        \\begin{cases}\n        -N_u \\log \\sigma - \\left(\\frac{1}{\\xi} + 1\\right) \\sum_{i=1}^{N_u} \\log\\left(1 + \\frac{\\xi y_i}{\\sigma}\\right), & \\text{if } \\xi \\ne 0 \\\\\n        -N_u \\log \\sigma - \\frac{1}{\\sigma} \\sum_{i=1}^{N_u} y_i, & \\text{if } \\xi = 0\n        \\end{cases}\n        $$\n        约束条件为对所有 $i$ 都有 $\\sigma > 0$ 和 $1 + \\xi y_i / \\sigma > 0$。估计是使用 `scipy.stats.genpareto` 中的 `fit` 方法执行的，该方法提供了一个稳健的 MLE 实现。\n\n    *   **条件威布尔模型**：威布尔分布参数 $(\\beta, \\lambda)$ 是通过最大化观测值 $x_i^{\\text{train}}$ 在超过阈值 $u$ 的条件下的条件对数似然来估计的。需要最大化的对数似然函数是：\n        $$\n        \\ell(\\beta, \\lambda; \\mathbf{x}, u) = \\sum_{i: x_i > u} \\left[ \\log f_{\\text{Weibull}}(x_i; \\beta, \\lambda) - \\log S_{\\text{Weibull}}(u; \\beta, \\lambda) \\right]\n        $$\n        代入威布尔密度函数 $f_{\\text{Weibull}}$ 和生存函数 $S_{\\text{Weibull}}$ 的表达式，我们得到：\n        $$\n        \\ell(\\beta, \\lambda) = N_u \\log \\beta - N_u \\beta \\log \\lambda + (\\beta-1)\\sum_{i: x_i > u} \\log x_i - \\frac{1}{\\lambda^\\beta} \\sum_{i: x_i > u} (x_i^\\beta - u^\\beta)\n        $$\n        使用 `scipy.optimize` 库中的 `minimize` 函数，针对 $\\beta > 0$ 和 $\\lambda > 0$ 对此函数进行数值最大化。为了处理正性约束，优化是针对对数变换后的参数 $\\log\\beta$ 和 $\\log\\lambda$ 进行的。\n\n4.  **性能评估与决策**：在测试集的超出量上评估每个拟合模型的预测性能。评价指标是平均对数似然。\n    *   对于 GPD 模型，分数为 $\\mathcal{S}_{\\text{GPD}} = \\frac{1}{|\\mathcal{I}_{\\text{test}}|} \\sum_{j \\in \\mathcal{I}_{\\text{test}}} \\log g(y_j^{\\text{test}}; \\hat{\\xi}, \\hat{\\sigma})$。\n    *   对于威布尔模型，分数为 $\\mathcal{S}_{\\text{Weibull}} = \\frac{1}{|\\mathcal{I}_{\\text{test}}|} \\sum_{j \\in \\mathcal{I}_{\\text{test}}} \\left[ \\log f_{\\text{Weibull}}(x_j^{\\text{test}}; \\hat{\\beta}, \\hat{\\lambda}) - \\log S_{\\text{Weibull}}(u; \\hat{\\beta}, \\hat{\\lambda}) \\right]$。\n    \n    如果测试集中没有超出量 ($|\\mathcal{I}_{\\text{test}}| = 0$)，则两个分数都定义为 $0$。决策规则是如果 $\\mathcal{S}_{\\text{GPD}} > \\mathcal{S}_{\\text{Weibull}}$ 则输出 $1$，否则输出 $0$。对所有三个测试用例重复这整个过程。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import genpareto, weibull_min\n\ndef solve():\n    \"\"\"\n    Solves the problem by running three test cases to compare POT-GPD and\n    conditional Weibull models for financial loss tail modeling.\n    \"\"\"\n\n    def generate_gpd_data(n, xi, sigma):\n        \"\"\"Generates deterministic data from a GPD distribution.\"\"\"\n        u_k = (np.arange(1, n + 1) - 0.5) / n\n        if np.abs(xi)  1e-9:\n            return -sigma * np.log(1 - u_k)\n        else:\n            return (sigma / xi) * (np.power(1 - u_k, -xi) - 1)\n\n    def generate_weibull_data(n, beta, lambda_):\n        \"\"\"Generates deterministic data from a Weibull distribution.\"\"\"\n        u_k = (np.arange(1, n + 1) - 0.5) / n\n        return lambda_ * np.power(-np.log(1 - u_k), 1.0 / beta)\n    \n    def neg_log_lik_weibull_cond(log_params, x_exceed, u):\n        \"\"\"\n        Calculates the negative conditional log-likelihood for the Weibull\n        distribution, given observations x > u.\n        Optimization is performed over log-transformed parameters.\n        \"\"\"\n        log_beta, log_lambda = log_params\n        beta = np.exp(log_beta)\n        lambda_ = np.exp(log_lambda)\n\n        if beta = 0 or lambda_ = 0:\n            return np.inf\n        \n        n_u = len(x_exceed)\n        log_x_exceed = np.log(x_exceed)\n\n        # Using properties of logarithms for numerical stability\n        # lambda_**(-beta) * x**beta = (x/lambda_)**beta = exp(beta * (log(x) - log(lambda_)))\n        log_lambda_val = np.log(lambda_)\n        \n        term1 = n_u * np.log(beta)\n        term2 = -n_u * beta * log_lambda_val\n        term3 = (beta - 1) * np.sum(log_x_exceed)\n        \n        v_i = np.power(x_exceed / lambda_, beta)\n        v_u = np.power(u / lambda_, beta)\n        \n        term4 = -np.sum(v_i)\n        term5 = n_u * v_u\n        \n        log_likelihood = term1 + term2 + term3 + term4 + term5\n        \n        if np.isnan(log_likelihood) or np.isinf(log_likelihood):\n            return np.inf\n\n        return -log_likelihood\n\n    def solve_case(dgp_type, dgp_params, n_train, n_test, p):\n        \"\"\"Processes a single test case.\"\"\"\n        # 1. Generate data\n        if dgp_type == 'weibull':\n            beta_true, lambda_true = dgp_params\n            train_data = generate_weibull_data(n_train, beta_true, lambda_true)\n            test_data = generate_weibull_data(n_test, beta_true, lambda_true)\n        elif dgp_type == 'gpd':\n            xi_true, sigma_true = dgp_params\n            train_data = generate_gpd_data(n_train, xi_true, sigma_true)\n            test_data = generate_gpd_data(n_test, xi_true, sigma_true)\n        else:\n            raise ValueError(\"Unknown DGP type\")\n\n        # 2. Compute threshold\n        u = np.quantile(train_data, p, interpolation='linear')\n\n        # 3. Form exceedance sets\n        train_exceed_indices = np.where(train_data > u)\n        x_train_exceed = train_data[train_exceed_indices]\n        y_train_exceed = x_train_exceed - u\n\n        test_exceed_indices = np.where(test_data > u)\n        x_test_exceed = test_data[test_exceed_indices]\n        y_test_exceed = x_test_exceed - u\n        \n        n_test_exceed = len(y_test_exceed)\n\n        if n_test_exceed == 0:\n            return 1 if 0.0 > 0.0 else 0\n\n        # 4. Fit models\n        # GPD model (POT)\n        try:\n            # Fit xi and sigma, with location fixed at 0\n            gpd_params = genpareto.fit(y_train_exceed, floc=0)\n            xi_hat, _, sigma_hat = gpd_params\n        except Exception:\n            # Fallback if fitting fails (unlikely)\n            xi_hat, sigma_hat = 0.0, 1.0\n\n        # Weibull model (Stretched Exponential)\n        # Initial guess for log-parameters\n        initial_guess = [np.log(1.0), np.log(np.mean(x_train_exceed))] \n        res = minimize(\n            neg_log_lik_weibull_cond,\n            x0=initial_guess,\n            args=(x_train_exceed, u),\n            method='Nelder-Mead'\n        )\n        if res.success:\n            log_beta_hat, log_lambda_hat = res.x\n            beta_hat, lambda_hat = np.exp(log_beta_hat), np.exp(log_lambda_hat)\n        else:\n            # Fallback if fitting fails\n            beta_hat, lambda_hat = 1.0, 1.0\n            \n        # 5. Evaluate predictive performance\n        # GPD (POT)\n        avg_loglik_gpd = np.mean(genpareto.logpdf(y_test_exceed, c=xi_hat, scale=sigma_hat, loc=0))\n\n        # Conditional Weibull\n        logpdf_weibull = weibull_min.logpdf(x_test_exceed, c=beta_hat, scale=lambda_hat)\n        logsf_weibull_u = weibull_min.logsf(u, c=beta_hat, scale=lambda_hat)\n        avg_loglik_weibull = np.mean(logpdf_weibull - logsf_weibull_u)\n\n        if np.isnan(avg_loglik_gpd): avg_loglik_gpd = -np.inf\n        if np.isnan(avg_loglik_weibull): avg_loglik_weibull = -np.inf\n\n        # 6. Decision rule\n        return 1 if avg_loglik_gpd > avg_loglik_weibull else 0\n\n    # Test suite definition\n    test_cases = [\n        # Case A\n        {'dgp_type': 'weibull', 'dgp_params': (0.7, 1.0), 'n_train': 5000, 'n_test': 5000, 'p': 0.95},\n        # Case B\n        {'dgp_type': 'gpd', 'dgp_params': (0.3, 1.0), 'n_train': 5000, 'n_test': 5000, 'p': 0.95},\n        # Case C\n        {'dgp_type': 'weibull', 'dgp_params': (1.0, 1.0), 'n_train': 5000, 'n_test': 5000, 'p': 0.99},\n    ]\n\n    results = []\n    for case in test_cases:\n        result = solve_case(\n            dgp_type=case['dgp_type'],\n            dgp_params=case['dgp_params'],\n            n_train=case['n_train'],\n            n_test=case['n_test'],\n            p=case['p']\n        )\n        results.append(result)\n\n    # Final print statement\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "2418756"}, {"introduction": "本练习将带你从简单的参数估计迈向解决实际的金融问题：市场的风险结构是否随时间发生了变化？你不仅将学习如何为两个不同时期（例如，金融危机前后）的数据分别估计尾部指数 $\\xi$，更重要的是，你将学习如何量化这些估计的不确定性，并执行一个正式的统计检验来判断其变化是否显著。这项练习为你搭建了从理论估计到严谨统计推断的桥梁，是掌握POT方法在现实世界中应用的关键一步 [@problem_id:2418723]。", "problem": "考虑代表金融市场危机前和危机后时期的两个独立模拟日对数回报率样本。超阈值峰值 (peaks-over-threshold) 框架假设，对于一个高阈值 $u$，超额量 $Y = X - u \\mid X  u$ 的条件分布近似为广义帕累托分布 (Generalized Pareto Distribution)，其形状参数为 $\\xi$，尺度参数为 $\\beta$。参数为 $(\\xi,\\beta)$ 的广义帕累托分布 (GPD) 在 $\\xi \\ge 0$ 时的支撑集为 $y \\ge 0$，在 $\\xi  0$ 时的支撑集为 $0 \\le y  -\\beta/\\xi$，其累积分布函数为\n$$\nF(y \\mid \\xi,\\beta) = \n\\begin{cases}\n1 - \\left(1 + \\dfrac{\\xi y}{\\beta}\\right)^{-1/\\xi},  \\xi \\ne 0, \\\\\n1 - \\exp\\!\\left(-\\dfrac{y}{\\beta}\\right),  \\xi = 0,\n\\end{cases}\n\\quad \\text{for } \\beta  0.\n$$\n在 GPD 模型下，超额量 $(y_1,\\dots,y_k)$ 的有限样本负对数似然为\n$$\n\\ell(\\xi,\\beta; y_{1:k}) =\n\\begin{cases}\nk \\log \\beta + \\left(1+\\dfrac{1}{\\xi}\\right)\\displaystyle\\sum_{i=1}^k \\log\\!\\left(1 + \\dfrac{\\xi y_i}{\\beta}\\right),  \\xi \\ne 0, \\\\\nk \\log \\beta + \\dfrac{1}{\\beta}\\displaystyle\\sum_{i=1}^k y_i,  \\xi = 0,\n\\end{cases}\n$$\n受限于支撑集约束 $1 + \\xi y_i/\\beta  0$ (对所有 $i$) 和 $\\beta  0$。最大似然估计量 $(\\hat{\\xi},\\hat{\\beta})$ 被定义为最小化 $\\ell(\\xi,\\beta; y_{1:k})$ 的任意参数对。观测信息矩阵是在 $(\\hat{\\xi},\\hat{\\beta})$ 处求值的 $\\ell$ 的 Hessian 矩阵，其逆矩阵近似于 $(\\hat{\\xi},\\hat{\\beta})$ 的协方差矩阵；特别地，$\\hat{\\xi}$ 的近似方差是该逆矩阵的 $(1,1)$ 元素。\n\n您将使用双边 Wald 检验，在显著性水平 $\\alpha = 0.05$ 下，检验形状参数（尾部指数）在危机前后时期是否发生变化：\n$$\nH_0: \\ \\xi_{\\text{pre}} = \\xi_{\\text{post}}\n\\quad \\text{versus} \\quad\nH_1: \\ \\xi_{\\text{pre}} \\ne \\xi_{\\text{post}}.\n$$\n设 $\\hat{\\xi}_{\\text{pre}}$ 和 $\\hat{\\xi}_{\\text{post}}$ 分别为来自各自样本的最大似然估计量，其近似标准误 $s_{\\text{pre}}$ 和 $s_{\\text{post}}$ 从观测信息协方差矩阵中获得。Wald 统计量为\n$$\nZ = \\dfrac{\\hat{\\xi}_{\\text{pre}} - \\hat{\\xi}_{\\text{post}}}{\\sqrt{s_{\\text{pre}}^2 + s_{\\text{post}}^2}},\n$$\n如果 $|Z| \\ge z_{1-\\alpha/2}$，则拒绝 $H_0$，其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$ 分位数。\n\n每个时期的数据生成如下。固定一个基础阈值水平 $u_0 = 0$ 和一个尾部混合概率 $p_{\\text{tail}} \\in (0,1)$。通过连接以下部分生成 $n$ 个独立观测值：\n- 大小为 $n - m$（其中 $m = \\lfloor p_{\\text{tail}} n \\rceil$）的“主体”部分，从支撑集为 $(-\\infty, u_0]$ 的连续分布中抽取；使用 $[-3, u_0]$ 上的均匀分布。\n- 大小为 $m$ 的“尾部”部分，构造为 $u_0 + Y$，其中 $Y$ 是独立的 GPD$(\\xi,\\beta)$ 随机变量，其参数 $(\\xi,\\beta)$ 为该时期指定。\n\n对于每个时期和测试用例，将阈值 $u$ 设置为模拟样本的经验 $q$-分位数，其中 $q = 0.9$。对于所有 $X_i  u$，将超额量定义为 $Y_i = X_i - u$。\n\n您的程序必须对下面的每个测试用例执行以下操作：\n1. 使用指定的参数和独立的随机种子模拟危机前和危机后的样本。\n2. 分别为每个时期计算分位数水平 $q = 0.9$ 处的经验阈值 $u$。\n3. 形成各自阈值以上的超额量 $Y_i$。\n4. 通过在支撑集约束下最小化精确的有限样本负对数似然 $\\ell(\\xi,\\beta; y_{1:k})$，为每个时期计算最大似然估计量 $(\\hat{\\xi},\\hat{\\beta})$。\n5. 使用最大似然估计量处的观测信息矩阵的逆，为每个时期近似 $\\hat{\\xi}$ 的标准误。\n6. 在显著性水平 $\\alpha = 0.05$ 下执行 $H_0: \\xi_{\\text{pre}} = \\xi_{\\text{post}}$ 的双边 Wald 检验。\n7. 输出一个布尔值，指示尾部指数是否存在统计上显著的变化（如果 $H_0$ 被拒绝，则输出 true，否则输出 false）。\n\n测试套件（每个元组按 $(\\text{seed}_{\\text{pre}}, \\text{seed}_{\\text{post}}, n_{\\text{pre}}, n_{\\text{post}}, \\xi_{\\text{pre}}, \\beta_{\\text{pre}}, \\xi_{\\text{post}}, \\beta_{\\text{post}})$ 的顺序对应一个测试用例），共同参数为 $u_0 = 0$、$p_{\\text{tail}} = 0.25$、$q = 0.9$ 和 $\\alpha = 0.05$：\n- 案例 A: $(12345, 54321, 5000, 5000, 0.2, 1.0, 0.6, 1.0)$。\n- 案例 B: $(111, 222, 4000, 4000, 0.2, 1.0, 0.2, 1.0)$。\n- 案例 C: $(333, 444, 6000, 6000, 0.01, 1.0, 0.0, 1.0)$。\n- 案例 D: $(555, 666, 6000, 6000, -0.15, 1.2, 0.15, 1.2)$。\n\n最终输出格式。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果的顺序与测试用例相同，例如：“[true,false,true,false]”。布尔值必须全部为小写。", "solution": "该问题要求执行统计假设检验，以确定由广义帕累托分布 (GPD) 建模的金融回报率的尾部行为是否在两个时期之间发生了变化。这是极值理论 (EVT) 在量化金融中的一个标准应用。验证过程确认了问题陈述在科学上是合理的、适定的，并包含获得唯一、可验证解所需的所有必要信息。\n\n解决方案系统地通过数据模拟、最大似然参数估计和使用 Wald 检验进行假设检验来展开。\n\n**1. 数据模拟与预处理**\n\n每个时期（危机前和危机后）的数据都是从一个混合分布中生成的，该分布旨在具有特定的尾部行为。对于大小为 $n$ 的样本，比例为 $p_{\\text{tail}}$ 的数据点构成“尾部”，并从 GPD 中抽取。其余的数据点构成分布的“主体”。\n\n-   **主体**：从 $[-3, u_0]$ 上的均匀分布中抽取 $n - m$ 个样本，其中 $m = \\lfloor p_{\\text{tail}} n \\rceil$，基础阈值为 $u_0 = 0$。\n-   **尾部**：生成 $m$ 个样本，形式为 $u_0 + Y_i$，其中 $Y_i$ 是独立的 GPD$(\\xi, \\beta)$ 随机变量。\n\n为了从 GPD$(\\xi, \\beta)$ 生成随机变量 $Y$，我们使用逆变换采样法。分位数函数 $F^{-1}(p)$ 是通过对 GPD 累积分布函数 (CDF) $F(y)$ 求逆得到的。给定一个均匀随机变量 $U \\sim U(0,1)$，一个 GPD 变量 $Y$ 按如下方式生成：\n$$\nY = F^{-1}(U) = \n\\begin{cases}\n\\dfrac{\\beta}{\\xi} \\left( (1-U)^{-\\xi} - 1 \\right),  \\xi \\ne 0, \\\\\n-\\beta \\log(1-U),  \\xi = 0.\n\\end{cases}\n$$\n由于 $1-U$ 也均匀分布在 $(0,1)$ 上，这等同于在表达式中直接使用 $U$。\n\n在模拟了完整样本 $X = \\{X_1, \\dots, X_n\\}$ 后，我们应用超阈值峰值 (POT) 方法。我们将一个高阈值 $u$ 设定为样本的经验 $q$-分位数，其中 $q=0.9$。然后将超额量定义为所有 $X_i  u$ 的正值 $Y_i = X_i - u$。这些超额量构成了拟合 GPD 模型的数据集。\n\n**2. 最大似然估计 (MLE)**\n\n通过最大化对数似然函数，或等效地，最小化负对数似然函数 $\\ell(\\xi, \\beta)$，来估计每个时期的 GPD 参数 $(\\xi, \\beta)$。对于一组 $k$ 个超额量 $\\{y_1, \\dots, y_k\\}$，负对数似然由下式给出：\n$$\n\\ell(\\xi,\\beta; y_{1:k}) =\n\\begin{cases}\nk \\log \\beta + \\left(1+\\dfrac{1}{\\xi}\\right)\\displaystyle\\sum_{i=1}^k \\log\\!\\left(1 + \\dfrac{\\xi y_i}{\\beta}\\right),  \\xi \\ne 0, \\\\\nk \\log \\beta + \\dfrac{1}{\\beta}\\displaystyle\\sum_{i=1}^k y_i,  \\xi = 0.\n\\end{cases}\n$$\n这个最小化是一个数值优化问题。当 $\\xi \\to 0$ 时，$\\xi \\ne 0$ 的函数收敛到 $\\xi = 0$ 的函数。为确保数值稳定性，我们使用条件分支实现目标函数，对接近于零的 $\\xi$ 值（例如 $|\\xi|  10^{-8}$）使用其极限形式。\n\n最小化受以下约束：$\\beta  0$，并且为使对数项有定义，对于所有超额量 $y_i$，必须满足 $1 + \\xi y_i/\\beta  0$。后一个约束在 $\\xi  0$ 时意味着 $y_i  -\\beta/\\xi$。这些约束在目标函数内部强制执行，如果违反约束，则返回一个大值（代表无穷大），从而有效地创建一个屏障，引导优化器走向有效的参数空间。优化使用 `scipy.optimize.minimize` 提供的 Broyden–Fletcher–Goldfarb–Shanno (BFGS) 算法执行。\n\n**3. 标准误近似**\n\n根据 MLE 的大样本理论，估计量 $(\\hat{\\xi}, \\hat{\\beta})$ 的渐近协方差矩阵可通过观测信息矩阵 $I(\\hat{\\xi}, \\hat{\\beta})$ 的逆来近似。观测信息矩阵是在 MLE 处求值的负对数似然函数的 Hessian 矩阵：\n$$\n\\text{Cov}(\\hat{\\xi}, \\hat{\\beta}) \\approx [I(\\hat{\\xi}, \\hat{\\beta})]^{-1} = \\left[ \\nabla^2 \\ell(\\hat{\\xi}, \\hat{\\beta}) \\right]^{-1}.\n$$\nBFGS 算法作为一种拟牛顿法，在其过程中会计算 Hessian 矩阵逆的近似值。这个近似值可以从优化结果中直接获得。形状参数估计量 $\\hat{\\xi}$ 的方差 $\\text{Var}(\\hat{\\xi})$，由该逆 Hessian 矩阵的左上角元素近似。相应的标准误是其平方根：\n$$\ns_{\\hat{\\xi}} = \\sqrt{\\left( [I(\\hat{\\xi}, \\hat{\\beta})]^{-1} \\right)_{1,1}}.\n$$\n\n**4. 参数相等性的 Wald 检验**\n\n为了检验尾部指数没有变化的假设 $H_0: \\xi_{\\text{pre}} = \\xi_{\\text{post}}$（备择假设为 $H_1: \\xi_{\\text{pre}} \\ne \\xi_{\\text{post}}$），我们使用双边 Wald 检验。该检验统计量由两个独立样本（危机前和危机后）的 MLE 及其标准误构建：\n$$\nZ = \\dfrac{\\hat{\\xi}_{\\text{pre}} - \\hat{\\xi}_{\\text{post}}}{\\sqrt{s_{\\text{pre}}^2 + s_{\\text{post}}^2}}.\n$$\n在原假设下，统计量 $Z$ 服从渐近标准正态分布 $N(0,1)$。如果在显著性水平 $\\alpha$ 下，观测到的统计量的绝对值 $|Z|$ 超过临界值 $z_{1-\\alpha/2}$，则我们拒绝 $H_0$。其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$-分位数。对于 $\\alpha = 0.05$，临界值为 $z_{0.975} \\approx 1.96$。\n\n整个过程被封装在一个程序中，该程序遍历所提供的测试用例，对每个用例执行模拟、估计和检验，并报告原假设是否被拒绝。", "answer": "```python\nimport numpy as np\nfrom scipy.optimize import minimize\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for the GPD tail index comparison.\n    \"\"\"\n    test_cases = [\n        # (seed_pre, seed_post, n_pre, n_post, xi_pre, beta_pre, xi_post, beta_post)\n        (12345, 54321, 5000, 5000, 0.2, 1.0, 0.6, 1.0),\n        (111, 222, 4000, 4000, 0.2, 1.0, 0.2, 1.0),\n        (333, 444, 6000, 6000, 0.01, 1.0, 0.0, 1.0),\n        (555, 666, 6000, 6000, -0.15, 1.2, 0.15, 1.2),\n    ]\n\n    common_params = {\n        'u0': 0.0,\n        'p_tail': 0.25,\n        'q': 0.9,\n        'alpha': 0.05,\n    }\n\n    results = []\n    for case in test_cases:\n        seed_pre, seed_post, n_pre, n_post, xi_pre, beta_pre, xi_post, beta_post = case\n        \n        # Fit pre-crisis period\n        xi_hat_pre, se_pre = fit_gpd_for_period(\n            seed_pre, n_pre, xi_pre, beta_pre, common_params\n        )\n        \n        # Fit post-crisis period\n        xi_hat_post, se_post = fit_gpd_for_period(\n            seed_post, n_post, xi_post, beta_post, common_params\n        )\n        \n        # Perform Wald test\n        wald_statistic = (xi_hat_pre - xi_hat_post) / np.sqrt(se_pre**2 + se_post**2)\n        critical_value = norm.ppf(1 - common_params['alpha'] / 2)\n        \n        reject_h0 = np.abs(wald_statistic) >= critical_value\n        results.append(str(reject_h0).lower())\n\n    print(f\"[{','.join(results)}]\")\n\ndef fit_gpd_for_period(seed, n, xi, beta, params):\n    \"\"\"\n    Simulates data and fits a GPD model for a single period.\n    Returns the estimated shape parameter and its standard error.\n    \"\"\"\n    X = simulate_data(seed, n, xi, beta, params['p_tail'], params['u0'])\n    \n    u = np.quantile(X, params['q'])\n    Y = X[X > u] - u\n    \n    # It's possible, though unlikely, that there are no exceedances\n    if len(Y) == 0:\n        raise ValueError(\"No exceedances found for GPD fitting.\")\n\n    # Objective function: negative log-likelihood for GPD\n    def nll_gpd(p, y_data):\n        _xi, _beta = p\n        \n        # Constraint: beta > 0\n        if _beta = 1e-6:\n            return np.inf\n            \n        # Support constraint: 1 + xi*y/beta > 0\n        terms = 1 + _xi * y_data / _beta\n        if np.any(terms = 0):\n            return np.inf\n\n        k = len(y_data)\n        \n        if abs(_xi)  1e-8:\n            # Case xi -> 0 (Exponential distribution)\n            neg_log_lik = k * np.log(_beta) + np.sum(y_data) / _beta\n        else:\n            # Case xi != 0\n            log_of_terms = np.log(terms)\n            neg_log_lik = k * np.log(_beta) + (1 + 1/_xi) * np.sum(log_of_terms)\n\n        if not np.isfinite(neg_log_lik):\n            return np.inf\n            \n        return neg_log_lik\n\n    # Initial guess for optimization\n    initial_guess = [0.1, np.std(Y) if len(Y) > 1 else 1.0]\n\n    # Run optimizer to find MLE\n    res = minimize(\n        nll_gpd,\n        initial_guess,\n        args=(Y,),\n        method='BFGS',\n        options={'gtol': 1e-8}\n    )\n\n    if not res.success:\n        # A failed optimization might require more robust initial values or optimizer choice\n        # For this problem, we assume `BFGS` with this initial guess suffices.\n        pass\n\n    xi_hat, _ = res.x\n    \n    # Approximate variance from the inverse Hessian\n    var_xi = res.hess_inv[0, 0]\n    \n    # Handle potential numerical instability if variance is negative\n    if var_xi  0:\n        # This shouldn't happen with BFGS, which maintains a positive definite Hess approx.\n        # But as a safeguard:\n        var_xi = np.abs(var_xi)\n\n    se_xi = np.sqrt(var_xi)\n    \n    return xi_hat, se_xi\n\ndef simulate_data(seed, n, xi, beta, p_tail, u0):\n    \"\"\"\n    Generates a sample from the mixture distribution.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    \n    m = int(round(p_tail * n))\n    n_body = n - m\n    \n    # Generate the \"body\" of the distribution\n    body = rng.uniform(-3.0, u0, size=n_body)\n    \n    # Generate the \"tail\" using GPD inverse transform sampling\n    U = rng.uniform(size=m)\n    if abs(xi)  1e-8:\n        tail_excess = -beta * np.log(U)\n    else:\n        tail_excess = (beta / xi) * (np.power(U, -xi) - 1)\n        \n    tail = u0 + tail_excess\n    \n    return np.concatenate((body, tail))\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2418723"}]}