{"hands_on_practices": [{"introduction": "在金融分析中，两个资产的简单相关性可能会被共同的市场因素所混淆，从而掩盖它们之间真正的直接关系。偏相关性提供了一种强大的方法，通过控制第三方变量（如市场指数）的影响，来揭示两个变量之间纯粹的线性关系。这个练习将指导你从普通最小二乘法（OLS）的基本原理出发，推导并实现偏相关性的计算，这对于培养严谨的量化分析技能至关重要 ([@problem_id:2385103])。", "problem": "给定三个金融收益序列，分别代表苹果公司（Apple）、微软公司（Microsoft）的每日对数回报率，以及一个代表纳斯达克100指数的宽基科技交易所交易基金（ETF）的每日对数回报率。您的任务是计算在控制ETF变量后，苹果公司和微软公司每日回报率之间的偏相关性。您必须仅从样本协方差、样本相关性的基本定义以及普通最小二乘法（OLS）的线性投影概念出发，推导出您的方法，并将其实现为一个完整、可运行的程序。\n\n从以下基本依据出发：\n- 两个等长为 $T$ 的实值序列 $x$ 和 $y$ 之间的样本协方差是它们去均值后数值乘積的平均值。\n- 样本相关性是样本协方差除以样本标准差的乘积。\n- 普通最小二乘法（OLS）中的线性投影是一种操作，它将一个随机变量映射到另一个随机变量的线性生成空间上，以最小化均方误差；等价地，它是通过最小化残差平方和来计算的。\n\n您不得假设或使用任何专门的偏相关性闭式表达式；相反，应从上述基本原理出发，推导出如何消除控制变量的线性影响，然后对剩余信息进行相关性计算。您的实现必须对所提供的测试用例保持数值稳定性。\n\n数据生成方式规定如下。对于每个参数为 $(\\text{seed}, T, \\beta_A, \\beta_M, \\sigma_Q, \\sigma_A, \\sigma_M, \\rho_u)$ 的测试用例：\n1. 独立地生成一个市场因子 $q_t \\sim \\mathcal{N}(0, \\sigma_Q^2)$，其中 $t \\in \\{1,\\dots,T\\}$。\n2. 对每个时间 $t$，从一个零均值的二元正态分布中抽取一个二元噪声向量 $(u_{A,t}, u_{M,t})^\\top$，其协方差矩阵为\n$$\n\\Sigma_u \\;=\\; \\begin{bmatrix}\n\\sigma_A^2  \\rho_u \\, \\sigma_A \\sigma_M \\\\\n\\rho_u \\, \\sigma_A \\sigma_M  \\sigma_M^2\n\\end{bmatrix}.\n$$\n3. 构建序列\n$$\n\\text{AAPL}_t \\;=\\; \\beta_A \\, q_t + u_{A,t}, \\quad\n\\text{MSFT}_t \\;=\\; \\beta_M \\, q_t + u_{M,t}, \\quad\n\\text{QQQ}_t \\;=\\; q_t,\n$$\n对于所有 $t \\in \\{1,\\dots,T\\}$。\n\n您的程序必须：\n- 对每个测试用例，计算在控制 $\\text{QQQ}_t$ 后，$\\text{AAPL}_t$ 和 $\\text{MSFT}_t$ 之间的样本偏相关性。\n- 仅使用上面列出的定义来推导正确的算法。在应用任何线性投影之前，所有序列都必须中心化（去均值）。\n- 以指定格式在单行上输出所有测试用例的结果，四舍五入到小数点后六位。\n\n测试套件：\n每个元组为 $(\\text{seed}, T, \\beta_A, \\beta_M, \\sigma_Q, \\sigma_A, \\sigma_M, \\rho_u)$。\n- 情况 1：(12345, 252, 1.2, 1.0, 0.015, 0.020, 0.018, 0.5)。\n- 情况 2：(20201, 252, 1.2, 1.0, 0.015, 0.020, 0.018, 0.0)。\n- 情况 3：(54321, 252, 1.2, 1.0, 0.015, 0.020, 0.018, -0.6)。\n- 情况 4：(777, 12, 1.2, 1.0, 0.015, 0.020, 0.018, 0.4)。\n- 情况 5：(9999, 252, 1.0, 1.0, 0.020, 0.005, 0.005, 0.95)。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含五个测试用例的五个偏相关性，以逗号分隔列表的形式包含在方括号中，每个数字四舍五入到小数点后六位，且无空格。例如：“[0.123456,-0.010203,0.000000,0.876543,-0.333333]”。\n- 不允许用户输入；程序必须完全自包含，并可根据上述参数重现。", "solution": "我们旨在求取以交易所交易基金（ETF）为条件时，苹果公司和微软公司回报序列之间的偏相关性。构建过程仅使用样本协方差、样本相关性和线性投影的定义。\n\n设有三个实值序列 $\\{x_t\\}_{t=1}^T$、$\\{y_t\\}_{t=1}^T$ 和 $\\{z_t\\}_{t=1}^T$，其中 $x_t$ 代表苹果公司的回报率，$y_t$ 代表微软公司的回报率，$z_t$ 代表ETF的回报率。定义中心化序列\n$$\n\\tilde{x}_t \\;=\\; x_t - \\bar{x}, \\quad \\tilde{y}_t \\;=\\; y_t - \\bar{y}, \\quad \\tilde{z}_t \\;=\\; z_t - \\bar{z},\n$$\n其中 $\\bar{x} = \\frac{1}{T}\\sum_{t=1}^T x_t$，对于 $\\bar{y}$ 和 $\\bar{z}$ 也类似。\n\n$x$ 和 $y$ 之间的样本协方差为\n$$\n\\widehat{\\operatorname{Cov}}(x,y) \\;=\\; \\frac{1}{T-1} \\sum_{t=1}^T \\tilde{x}_t \\tilde{y}_t \\;=\\; \\frac{1}{T-1}\\, \\tilde{x}^\\top \\tilde{y}.\n$$\n样本方差为 $\\widehat{\\operatorname{Var}}(x) = \\widehat{\\operatorname{Cov}}(x,x)$，样本相关性为\n$$\n\\widehat{\\rho}(x,y) \\;=\\; \\frac{\\widehat{\\operatorname{Cov}}(x,y)}{\\sqrt{\\widehat{\\operatorname{Var}}(x)\\,\\widehat{\\operatorname{Var}}(y)}}.\n$$\n\n为了控制 ETF $z$ 的影响，我们使用线性投影从 $x$ 和 $y$ 中剔除其线性影响。考虑将 $\\tilde{x}$ 线性投影到 $\\tilde{z}$ 上的问题。我们寻求标量系数 $\\beta_{x\\mid z}$ 以最小化残差平方和：\n$$\n\\beta_{x\\mid z} \\;=\\; \\arg\\min_{\\beta \\in \\mathbb{R}} \\sum_{t=1}^T \\left(\\tilde{x}_t - \\beta \\tilde{z}_t\\right)^2.\n$$\n根据普通最小二乘法（OLS）的正规方程，最优的 $\\beta_{x\\mid z}$ 满足\n$$\n\\tilde{z}^\\top \\left(\\tilde{x} - \\beta_{x\\mid z} \\tilde{z}\\right) \\;=\\; 0,\n$$\n由此得出\n$$\n\\beta_{x\\mid z} \\;=\\; \\frac{\\tilde{z}^\\top \\tilde{x}}{\\tilde{z}^\\top \\tilde{z}} \\;=\\; \\frac{(T-1)\\,\\widehat{\\operatorname{Cov}}(z,x)}{(T-1)\\,\\widehat{\\operatorname{Var}}(z)} \\;=\\; \\frac{\\widehat{\\operatorname{Cov}}(z,x)}{\\widehat{\\operatorname{Var}}(z)}.\n$$\n定义残差\n$$\nr^x_t \\;=\\; \\tilde{x}_t - \\beta_{x\\mid z}\\,\\tilde{z}_t.\n$$\n根据对称性，将 $y$ 投影到 $z$ 上后的残差为\n$$\nr^y_t \\;=\\; \\tilde{y}_t - \\beta_{y\\mid z}\\,\\tilde{z}_t, \\quad \\text{其中} \\quad \\beta_{y\\mid z} \\;=\\; \\frac{\\widehat{\\operatorname{Cov}}(z,y)}{\\widehat{\\operatorname{Var}}(z)}.\n$$\n线性投影的关键性质是正交性：$\\sum_{t=1}^T r^x_t \\tilde{z}_t = 0$ 且 $\\sum_{t=1}^T r^y_t \\tilde{z}_t = 0$。根据定义，控制变量 $z$ 后 $x$ 和 $y$ 之间的偏相关性就是残差 $r^x$ 和 $r^y$ 之间的样本相关性：\n$$\n\\widehat{\\rho}(x,y \\mid z) \\;=\\; \\frac{\\sum_{t=1}^T r^x_t r^y_t}{\\sqrt{\\left(\\sum_{t=1}^T (r^x_t)^2\\right)\\left(\\sum_{t=1}^T (r^y_t)^2\\right)}}.\n$$\n分母使用每次投影的残差平方和。因为所有序列在投影前都已中心化，所以在向 $z$ 进行标量投影时不需要截距项。\n\n这种残差化方法直接从定义推导而来，避免了任何专门的快捷公式。在当前设定下，该方法是数值稳定的，因为分母 $\\sum_{t=1}^T \\tilde{z}_t^2$ 在下面指定的随机化构造中是严格为正的。\n\n每个测试用例的数据生成过程使用一个潜在因子 $q_t$ 和异质性噪声 $(u_{A,t},u_{M,t})^\\top$：\n- 独立地抽取 $q_t \\sim \\mathcal{N}(0, \\sigma_Q^2)$。\n- 抽取 $(u_{A,t},u_{M,t})^\\top \\sim \\mathcal{N}\\left(0, \\Sigma_u\\right)$，其中\n$$\n\\Sigma_u \\;=\\; \\begin{bmatrix}\n\\sigma_A^2  \\rho_u \\, \\sigma_A \\sigma_M \\\\\n\\rho_u \\, \\sigma_A \\sigma_M  \\sigma_M^2\n\\end{bmatrix}.\n$$\n- 设定 $x_t = \\beta_A q_t + u_{A,t}$，$y_t = \\beta_M q_t + u_{M,t}$，以及 $z_t = q_t$。\n\n情况解读：\n- 在情况1中，在剔除ETF影响后，Apple和Microsoft之间存在正向直接关系，因此偏相关性预计为正，并且由于共同的ETF效应已被移除，其值会小于无条件相关性。\n- 在情况2中，除了ETF之外没有直接联系，因此偏相关性预计接近于零。\n- 在情况3中，直接联系是负向的，因此偏相关性预计为负。\n- 在情况4中，小样本凸显了抽样变异性；该方法仍然适用，但估计值噪声更大。\n- 在情况5中，异质性成分高度相关，且其方差相对于ETF较小，导致了高的无条件相关性；在控制ETF后，偏相关性反映了强烈的直接异质性关联。\n\n实现算法摘要：\n1. 对每个测试用例，使用给定的种子按规定生成 $\\{x_t,y_t,z_t\\}_{t=1}^T$。\n2. 对每个序列进行中心化。\n3. 计算 $\\beta_{x\\mid z} = (\\tilde{z}^\\top \\tilde{x})/(\\tilde{z}^\\top \\tilde{z})$ 和 $\\beta_{y\\mid z} = (\\tilde{z}^\\top \\tilde{y})/(\\tilde{z}^\\top \\tilde{z})$。\n4. 构建残差 $r^x = \\tilde{x} - \\beta_{x\\mid z}\\tilde{z}$ 和 $r^y = \\tilde{y} - \\beta_{y\\mid z}\\tilde{z}$。\n5. 计算 $r^x$ 和 $r^y$ 之间的样本相关性，即为偏相关性。\n6. 将每个结果四舍五入到小数点后六位，并按要求格式打印列表。\n\n指定的输出必须是单行：一个逗号分隔的列表，包含五个四舍五入后的偏相关性，用方括号括起来，且无空格。", "answer": "```python\nimport numpy as np\n\ndef generate_data(seed, T, beta_A, beta_M, sigma_Q, sigma_A, sigma_M, rho_u):\n    rng = np.random.default_rng(seed)\n    # Generate market factor q_t ~ N(0, sigma_Q^2)\n    q = rng.normal(loc=0.0, scale=sigma_Q, size=T)\n    # Construct covariance matrix for idiosyncratic noises\n    cov_u = np.array([\n        [sigma_A**2, rho_u * sigma_A * sigma_M],\n        [rho_u * sigma_A * sigma_M, sigma_M**2]\n    ])\n    # Generate idiosyncratic noise (u_A, u_M) ~ N(0, cov_u)\n    U = rng.multivariate_normal(mean=[0.0, 0.0], cov=cov_u, size=T)\n    u_A = U[:, 0]\n    u_M = U[:, 1]\n    # Construct returns\n    AAPL = beta_A * q + u_A\n    MSFT = beta_M * q + u_M\n    QQQ = q.copy()\n    return AAPL, MSFT, QQQ\n\ndef demean(x):\n    return x - np.mean(x)\n\ndef partial_correlation_xy_given_z(x, y, z):\n    # Center all series\n    x_c = demean(x)\n    y_c = demean(y)\n    z_c = demean(z)\n    # Guard against degenerate z variance (should not occur in provided tests)\n    denom_z = np.dot(z_c, z_c)\n    if denom_z == 0:\n        # If z has zero variance, partial correlation reduces to ordinary correlation\n        # But this path should not be taken in test cases.\n        rx = x_c\n        ry = y_c\n    else:\n        beta_xz = np.dot(z_c, x_c) / denom_z\n        beta_yz = np.dot(z_c, y_c) / denom_z\n        rx = x_c - beta_xz * z_c\n        ry = y_c - beta_yz * z_c\n    # Compute correlation between residuals\n    num = np.dot(rx, ry)\n    denom = np.sqrt(np.dot(rx, rx) * np.dot(ry, ry))\n    # Handle potential numerical issues\n    if denom == 0:\n        return 0.0\n    return float(num / denom)\n\ndef solve():\n    # Define the test cases as specified:\n    # Each tuple: (seed, T, beta_A, beta_M, sigma_Q, sigma_A, sigma_M, rho_u)\n    test_cases = [\n        (12345, 252, 1.2, 1.0, 0.015, 0.020, 0.018, 0.5),\n        (20201, 252, 1.2, 1.0, 0.015, 0.020, 0.018, 0.0),\n        (54321, 252, 1.2, 1.0, 0.015, 0.020, 0.018, -0.6),\n        (777,   12,  1.2, 1.0, 0.015, 0.020, 0.018, 0.4),\n        (9999,  252, 1.0, 1.0, 0.020, 0.005, 0.005, 0.95),\n    ]\n\n    results = []\n    for (seed, T, beta_A, beta_M, sigma_Q, sigma_A, sigma_M, rho_u) in test_cases:\n        AAPL, MSFT, QQQ = generate_data(seed, T, beta_A, beta_M, sigma_Q, sigma_A, sigma_M, rho_u)\n        pcorr = partial_correlation_xy_given_z(AAPL, MSFT, QQQ)\n        results.append(f\"{pcorr:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2385103"}, {"introduction": "金融市场数据常常包含极端事件或异常值，这些异常值会对标准协方差和相关性估计产生不成比例的巨大影响，导致结果失真。为了构建更可靠的风险模型，我们需要能够抵御这些极端值影响的稳健估计方法。本练习将引导你从头开始实现一种基于“缩尾处理”（Winsorization）的稳健协方差估计器，这是一种限制极端数据点影响力的实用技术，是处理真实世界金融数据的一项核心技能 ([@problem_id:2385068])。", "problem": "你的任务是实现并测试一个稳健的资产回报协方差和相关性估计器，该估计器通过Winsor化来减轻单个巨大异常值事件的影响。你必须生成一个完整、可运行的程序，将该估计器应用于固定的测试套件，并按如下指定的单行格式打印结果。\n\n该估计器必须基于以下基础，从基本原理出发构建。\n\n1. 定义\n   - 设两个资产的回报序列为有限样本 $\\{x_i\\}_{i=1}^n$ 和 $\\{y_i\\}_{i=1}^n$。\n   - $x$ 和 $y$ 之间的无偏样本协方差为\n     $$\\widehat{\\mathrm{Cov}}(x,y) \\equiv \\frac{1}{n-1} \\sum_{i=1}^n \\left(x_i - \\bar{x}\\right)\\left(y_i - \\bar{y}\\right),$$\n     其中 $\\bar{x} \\equiv \\frac{1}{n} \\sum_{i=1}^n x_i$ 且 $\\bar{y} \\equiv \\frac{1}{n} \\sum_{i=1}^n y_i$。\n   - 无偏样本方差为 $\\widehat{\\mathrm{Var}}(x) \\equiv \\widehat{\\mathrm{Cov}}(x,x)$，皮尔逊相关系数为\n     $$\\widehat{\\rho}(x,y) \\equiv \\frac{\\widehat{\\mathrm{Cov}}(x,y)}{\\sqrt{\\widehat{\\mathrm{Var}}(x)\\,\\widehat{\\mathrm{Var}}(y)}}.$$\n     如果 $\\widehat{\\mathrm{Var}}(x)=0$ 或 $\\widehat{\\mathrm{Var}}(y)=0$，则定义 $\\widehat{\\rho}(x,y) \\equiv 0$。\n\n2. Winsor化算子\n   - 对于给定的Winsor化水平 $\\alpha \\in [0,0.5]$，定义样本 $v \\in \\mathbb{R}^n$ 在概率 $q \\in [0,1]$ 处的线性插值经验分位数为：设 $v_{(1)} \\le \\dots \\le v_{(n)}$ 表示顺序统计量。设 $r \\equiv q\\,(n-1)$，$\\ell \\equiv \\lfloor r \\rfloor$，$u \\equiv \\lceil r \\rceil$ 及 $t \\equiv r - \\ell$。则\n     $$Q_q(v) \\equiv (1-t)\\,v_{(\\ell+1)} + t\\,v_{(u+1)}.$$\n   - 样本 $v$ 的 $\\alpha$-Winsor化序列 $w$ 通过将值限制在对称分位数带内按元素定义：\n     $$w_i \\equiv \\min\\Big(\\max\\big(v_i,\\,Q_\\alpha(v)\\big),\\,Q_{1-\\alpha}(v)\\Big).$$\n\n3. 稳健协方差与相关性\n   - 给定两个序列 $x$ 和 $y$，使用上述定义独立计算它们的 $\\alpha$-Winsor化版本 $x^{(w)}$ 和 $y^{(w)}$。然后使用无偏公式计算 $\\widehat{\\mathrm{Cov}}(x^{(w)},y^{(w)})$ 和 $\\widehat{\\rho}(x^{(w)},y^{(w)})$。这就构成了所需的稳健估计器。\n\n程序要求。\n\n- 完全按照定义实现上述估计器。不要使用任何与指定的线性插值分位数定义不同的内置协方差或分位数例程。\n- 数值输出必须表示为无量纲小数。将报告的每个浮点数四舍五入到 $6$ 位小数。\n\n测试套件。\n\n将您的实现应用于以下五个测试用例，每个用例包含两个回报序列和一个Winsor化水平 $\\alpha$：\n\n- 案例A（共生异常值，正常路径）：\n  - $x = [0.01,\\,0.02,\\,-0.01,\\,0.015,\\,-0.005,\\,0.03,\\,-0.02,\\,0.025,\\,-0.015,\\,0.5]$,\n  - $y = [0.008,\\,0.018,\\,-0.012,\\,0.017,\\,-0.004,\\,0.028,\\,-0.018,\\,0.03,\\,-0.013,\\,0.45]$,\n  - $\\alpha = 0.1$。\n- 案例B（无主要异常值）：\n  - $x = [0.01,\\,0.012,\\,0.009,\\,0.011,\\,0.013,\\,0.008,\\,0.010,\\,0.012]$,\n  - $y = [0.02,\\,0.019,\\,0.021,\\,0.018,\\,0.022,\\,0.020,\\,0.0195,\\,0.0215]$,\n  - $\\alpha = 0.1$。\n- 案例C（无Winsor化基线）：\n  - $x = [0.01,\\,0.02,\\,-0.01,\\,0.015,\\,-0.005,\\,0.03,\\,-0.02,\\,0.025,\\,-0.015,\\,0.5]$,\n  - $y = [0.008,\\,0.018,\\,-0.012,\\,0.017,\\,-0.004,\\,0.028,\\,0.03,\\,-0.013,\\,0.45,\\,-0.018]$,\n  - $\\alpha = 0.0$。\n- 案例D（中位数处的极端Winsor化）：\n  - $x = [-0.01,\\,0.0,\\,0.02,\\,0.0]$,\n  - $y = [0.03,\\,0.0,\\,-0.01,\\,0.0]$,\n  - $\\alpha = 0.5$。\n- 案例E（一个序列中的单侧异常值）：\n  - $x = [0.01,\\,0.012,\\,0.009,\\,0.011,\\,0.013,\\,0.008,\\,0.010,\\,1.0]$,\n  - $y = [0.02,\\,0.019,\\,0.021,\\,0.018,\\,0.022,\\,0.020,\\,0.0195,\\,0.0205]$,\n  - $\\alpha = 0.125$。\n\n对于每个案例，计算并返回一对浮点数：\n- 稳健协方差 $\\widehat{\\mathrm{Cov}}(x^{(w)},y^{(w)})$，\n- 稳健相关系数 $\\widehat{\\rho}(x^{(w)},y^{(w)})$。\n\n最终输出格式。\n\n- 您的程序应生成单行输出，其中包含一个列表的列表形式的结果，每个内部列表对应一个测试用例，顺序为A, B, C, D, E。每个内部列表必须是 $[\\mathrm{cov},\\mathrm{corr}]$ 格式，两个浮点数都四舍五入到 $6$ 位小数。输出中不得有任何空格。例如：\"[[0.000123,0.456789],[...],...]\"。", "solution": "根据既定标准对问题陈述进行验证。\n\n### 步骤1：提取给定信息\n问题提供了以下定义、公式和数据：\n\n- **数据序列**：两个有限样本 $\\{x_i\\}_{i=1}^n$ 和 $\\{y_i\\}_{i=1}^n$。\n- **无偏样本协方差**：\n$$\n\\widehat{\\mathrm{Cov}}(x,y) \\equiv \\frac{1}{n-1} \\sum_{i=1}^n \\left(x_i - \\bar{x}\\right)\\left(y_i - \\bar{y}\\right)\n$$\n其中 $\\bar{x}$ 和 $\\bar{y}$ 是样本均值。\n- **无偏样本方差**：$\\widehat{\\mathrm{Var}}(x) \\equiv \\widehat{\\mathrm{Cov}}(x,x)$。\n- **皮尔逊相关系数**：\n$$\n\\widehat{\\rho}(x,y) \\equiv \\frac{\\widehat{\\mathrm{Cov}}(x,y)}{\\sqrt{\\widehat{\\mathrm{Var}}(x)\\,\\widehat{\\mathrm{Var}}(y)}}\n$$\n附带条件：如果任一方差为零，则 $\\widehat{\\rho}(x,y) \\equiv 0$。\n- **线性插值经验分位数**：对于一个样本 $v$，排序为 $v_{(1)} \\le \\dots \\le v_{(n)}$，在概率 $q \\in [0,1]$ 处的分位数定义为：\n$$\nQ_q(v) \\equiv (1-t)\\,v_{(\\ell+1)} + t\\,v_{(u+1)}\n$$\n其中 $r \\equiv q\\,(n-1)$，$\\ell \\equiv \\lfloor r \\rfloor$，$u \\equiv \\lceil r \\rceil$，以及 $t \\equiv r - \\ell$。\n- **Winsor化算子**：对于一个Winsor化水平 $\\alpha \\in [0,0.5]$，Winsor化后的序列 $w$ 由以下公式给出：\n$$\nw_i \\equiv \\min\\Big(\\max\\big(v_i,\\,Q_\\alpha(v)\\big),\\,Q_{1-\\alpha}(v)\\Big)\n$$\n- **稳健估计器**：该估计器定义为 $\\widehat{\\mathrm{Cov}}(x^{(w)},y^{(w)})$ 和 $\\widehat{\\rho}(x^{(w)},y^{(w)})$，其中 $x^{(w)}$ 和 $y^{(w)}$ 是 $x$ 和 $y$ 的 $\\alpha$-Winsor化版本。\n- **测试套件**：提供了五个特定的测试用例（A-E），每个用例都包含两个数据序列 $x$、$y$ 和一个Winsor化水平 $\\alpha$。\n- **程序要求**：从基本原理出发实现估计器，不使用与给定定义有偏差的库函数来计算协方差或分位数。将数值输出四舍五入到 $6$ 位小数。\n\n### 步骤2：使用提取的给定信息进行验证\n对问题的有效性进行评估：\n\n1.  **科学依据**：该问题基于稳健统计学的标准、公认原则。Winsor化是减轻异常值影响的经典技术。样本协方差、相关性和线性插值分位数的公式是统计学和数据分析中的标准定义。该问题在事实上和科学上都是合理的。\n2.  **良构性**：该问题被构建为一个清晰的计算任务。对于任何给定的有效输入（两个数值序列和一个参数 $\\alpha$），操作序列都得到了明确无误的定义，从而导向唯一的解决方案。对零方差的特殊处理确保了相关系数总是有定义的。\n3.  **客观性**：该问题使用精确的数学语言和定义进行陈述。它完全没有主观、模糊或基于观点的论断。\n4.  **自洽性与一致性**：所有必要的公式、定义和测试数据都在问题陈述中提供。不存在内部矛盾。\n5.  **相关性**：该任务与指定领域直接相关：*计算经济学与金融学*中的*协方差与相关性估计*。\n\n### 步骤3：结论与行动\n问题是**有效的**。这是一个定义明确、科学合理的计算练习。着手解决。\n\n### 基于原理的设计\n解决方案要求从基础定义出发实现一个稳健的统计估计器。逻辑结构将由三个主要部分组成，这种方法确保了清晰性、正确性，并遵循了指定的“从基本原理出发”的构建要求。\n\n1.  **分位数计算**：Winsor化算子的基石是经验分位数 $Q_q(v)$。将实现一个函数，根据指定的线性插值公式计算该值。对于给定的样本 $v$ 和概率 $q$，首先对样本进行排序以获得顺序统计量 $v_{(i)}$。计算秩 $r = q(n-1)$。整数部分 $\\ell = \\lfloor r \\rfloor$ 和小数部分 $t = r - \\ell$ 决定了在索引为 $\\ell+1$ 和 $\\ell+2$ 的顺序统计量之间的插值（使用基于1的顺序统计量索引，对应于基于0的数组索引 `l` 和 `l+1`）。然后应用公式 $Q_q(v) = (1-t)v_{(\\ell+1)} + t v_{(\\ell+2)}$ （根据问题陈述中给出的定义进行调整，该定义可简化为此形式）。这必须从头开始实现，以满足问题约束。\n\n2.  **Winsor化**：Winsor化算子 $w_i = \\min(\\max(v_i, Q_\\alpha(v)), Q_{1-\\alpha}(v))$ 在下分位数和上分位数处截断数据。将创建一个函数来执行此操作。它将首先通过调用先前设计的分位数函数来计算 $\\alpha$-分位数 $q_{low} = Q_\\alpha(v)$ 和 $(1-\\alpha)$-分位数 $q_{high} = Q_{1-\\alpha}(v)$。然后，它会将输入序列 $v$ 的每个元素限制在区间 $[q_{low}, q_{high}]$ 内。\n\n3.  **稳健协方差与相关性**：主要计算过程包括将Winsor化算子独立应用于两个输入序列 $x$ 和 $y$，以获得它们的稳健版本 $x^{(w)}$ 和 $y^{(w)}$。随后，为这些经过Winsor化的序列计算标准的无偏样本协方差和皮尔逊相关系数。直接应用无偏协方差公式 $\\widehat{\\mathrm{Cov}}(a, b) = \\frac{1}{n-1} \\sum (a_i - \\bar{a})(b_i - \\bar{b})$。相关系数由协方差和方差导出，并有特殊情况：如果任一方差为零，则相关系数定义为零。这可以防止除以零，并确保结果确定。\n\n最终程序将协调这些组件。它将遍历提供的测试套件，为每个案例应用完整的估计过程，并将得到的协方差-相关性对格式化为指定的单行字符串输出。所有数值都将按要求四舍五入到六位小数。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n\n    test_cases = [\n        # Case A (co-outlier, happy path)\n        (\n            [0.01, 0.02, -0.01, 0.015, -0.005, 0.03, -0.02, 0.025, -0.015, 0.5],\n            [0.008, 0.018, -0.012, 0.017, -0.004, 0.028, -0.018, 0.03, -0.013, 0.45],\n            0.1\n        ),\n        # Case B (no major outliers)\n        (\n            [0.01, 0.012, 0.009, 0.011, 0.013, 0.008, 0.010, 0.012],\n            [0.02, 0.019, 0.021, 0.018, 0.022, 0.020, 0.0195, 0.0215],\n            0.1\n        ),\n        # Case C (no winsorization baseline)\n        (\n            [0.01, 0.02, -0.01, 0.015, -0.005, 0.03, -0.02, 0.025, -0.015, 0.5],\n            [0.008, 0.018, -0.012, 0.017, -0.004, 0.028, 0.03, -0.013, 0.45, -0.018],\n            0.0\n        ),\n        # Case D (extreme winsorization at median)\n        (\n            [-0.01, 0.0, 0.02, 0.0],\n            [0.03, 0.0, -0.01, 0.0],\n            0.5\n        ),\n        # Case E (single-sided outlier in one series)\n        (\n            [0.01, 0.012, 0.009, 0.011, 0.013, 0.008, 0.010, 1.0],\n            [0.02, 0.019, 0.021, 0.018, 0.022, 0.020, 0.0195, 0.0205],\n            0.125\n        ),\n    ]\n\n    results = []\n    for x, y, alpha in test_cases:\n        cov, corr = compute_robust_estimator(np.asarray(x), np.asarray(y), alpha)\n        results.append((cov, corr))\n\n    # Format the output string precisely as specified.\n    formatted_results = [f\"[{cov:.6f},{corr:.6f}]\" for cov, corr in results]\n    output_string = f\"[{','.join(formatted_results)}]\"\n    print(output_string)\n\ndef _quantile(v: np.ndarray, q: float) -> float:\n    \"\"\"\n    Computes the empirical quantile using linear interpolation as specified.\n    This implementation is from first principles as required.\n    \"\"\"\n    v_sorted = np.sort(v)\n    n = len(v_sorted)\n    \n    if n == 1:\n        return v_sorted[0]\n    \n    r = q * (n - 1)\n    l = int(r)\n    \n    # Handle case where q=1.0, making l=n-1\n    if l >= n - 1:\n        return v_sorted[n-1]\n        \n    t = r - l\n    \n    # The formula from the problem is Q_q(v) = (1-t)v_(l+1) + t*v_(u+1) where u=ceil(r).\n    # If r is not integer, u=l+1, and this becomes (1-t)v_(l+1) + t*v_(l+2).\n    # In 0-indexed arrays, v_(k) is v_sorted[k-1].\n    # So v_(l+1) is v_sorted[l], and v_(l+2) is v_sorted[l+1].\n    # The code implements (1-t)*v_sorted[l] + t*v_sorted[l+1].\n    val1 = v_sorted[l]\n    val2 = v_sorted[l+1]\n    \n    return (1.0 - t) * val1 + t * val2\n\ndef _winsorize(v: np.ndarray, alpha: float) -> np.ndarray:\n    \"\"\"\n    Applies symmetric alpha-winsorization to a data series.\n    \"\"\"\n    if alpha  0.0 or alpha > 0.5:\n        raise ValueError(\"alpha must be in [0, 0.5]\")\n    \n    lower_bound = _quantile(v, alpha)\n    upper_bound = _quantile(v, 1.0 - alpha)\n    \n    return np.clip(v, lower_bound, upper_bound)\n\ndef _compute_unbiased_cov_corr(x: np.ndarray, y: np.ndarray) -> tuple[float, float]:\n    \"\"\"\n    Calculates unbiased sample covariance and Pearson correlation.\n    \"\"\"\n    n = len(x)\n    if n  2:\n        return 0.0, 0.0\n\n    mean_x = np.mean(x)\n    mean_y = np.mean(y)\n\n    # Unbiased covariance (ddof=1)\n    cov = np.sum((x - mean_x) * (y - mean_y)) / (n - 1)\n\n    # Unbiased variances\n    var_x = np.sum((x - mean_x)**2) / (n - 1)\n    var_y = np.sum((y - mean_y)**2) / (n - 1)\n\n    if var_x == 0.0 or var_y == 0.0:\n        corr = 0.0\n    else:\n        corr = cov / np.sqrt(var_x * var_y)\n        \n    return cov, corr\n\ndef compute_robust_estimator(x: np.ndarray, y: np.ndarray, alpha: float) -> tuple[float, float]:\n    \"\"\"\n    Computes the robust covariance and correlation by winsorizing the series first.\n    \"\"\"\n    x_w = _winsorize(x, alpha)\n    y_w = _winsorize(y, alpha)\n    \n    return _compute_unbiased_cov_corr(x_w, y_w)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2385068"}, {"introduction": "当处理大量资产时（即资产数量$p$接近或超过观测时间点数量$n$），传统的样本协方差矩阵会变得极不稳定且充满估计误差，这一问题被称为“维度灾难”。Ledoit-Wolf收缩估计是一种前沿的解决方案，它通过将不稳定的样本协方差矩阵系统性地“拉向”一个结构更稳定、更简单的目标矩阵，从而得到更可靠的估计。这个高级练习将要求你推导并实现Ledoit-Wolf收缩强度的最优估计，这是现代投资组合优化和高维风险管理中的一个关键工具 ([@problem_id:2385059])。", "problem": "您的任务是推导并实现一个线性收缩估计量（linear shrinkage estimator），该估计量适用于当资产数量接近样本大小时的大维度资产收益数据的高维协方差矩阵。该估计量将样本协方差矩阵向一个结构化目标进行收缩。目标是计算最优收缩强度的一个可实现的估计量，并根据经验检验当资产数量接近观测值数量时，该估计量如何变化。\n\n在以下纯数学设置中进行工作。设 $X \\in \\mathbb{R}^{n \\times p}$ 为一个数据矩阵，包含 $p$ 个资产的 $n$ 个观测值，其行为 $x_{i}^{\\top} \\in \\mathbb{R}^{p}$。通过减去列均值来定义中心化数据矩阵，并通过下式定义样本协方差矩阵\n$$\nS \\equiv \\frac{1}{n} \\sum_{i=1}^{n} \\left(x_{i} - \\bar{x}\\right)\\left(x_{i} - \\bar{x}\\right)^{\\top} = \\frac{1}{n} X_{c}^{\\top} X_{c},\n$$\n其中 $\\bar{x} \\in \\mathbb{R}^{p}$ 是样本均值，而 $X_{c}$ 表示均值中心化的矩阵。考虑线性收缩估计量\n$$\n\\widehat{\\Sigma}(\\delta) \\equiv (1 - \\delta) S + \\delta F,\n$$\n其中收缩强度为 $\\delta \\in [0,1]$，收缩目标为 $F \\equiv \\mu I_{p}$，这里 $\\mu \\equiv \\frac{\\operatorname{tr}(S)}{p}$，$I_{p}$ 是 $p \\times p$ 的单位矩阵。目标是选择 $\\delta$ 以最小化期望平方弗罗贝尼乌斯损失（expected squared Frobenius loss）\n$$\n\\mathcal{R}(\\delta) \\equiv \\mathbb{E}\\left[ \\left\\| \\widehat{\\Sigma}(\\delta) - \\Sigma \\right\\|_{F}^{2} \\right],\n$$\n其中 $\\Sigma$ 是真实但未知的协方差矩阵，$\\|\\cdot\\|_{F}$ 是弗罗贝尼乌斯范数，期望是针对数据生成过程计算的。\n\n仅从在此背景下有效的核心定义和性质——即样本协方差矩阵的定义、内积的双线性、$\\mathbb{E}[S] = \\Sigma$、期望的线性以及弗罗贝尼乌斯范数恒等式 $\\|A\\|_{F}^{2} = \\langle A, A \\rangle$——出发，推导出一个最优收缩强度 $\\delta^{*}$ 的可由样本计算的估计量，该估计量不涉及未知的总体量。您的推导必须明确地将任何涉及未知 $\\Sigma$ 的期望转化为仅依赖于 $X$ 的统计量。然后从零开始实现该估计量。\n\n用于测试的数据生成过程如下。对于给定的 $(n,p,\\rho)$ 且 $\\rho \\in (-1,1)$，从一个 $p$ 元正态分布中抽取 $n$ 个独立向量，该分布的均值为零，相关矩阵为 $C_{\\rho} \\in \\mathbb{R}^{p \\times p}$，定义如下\n$$\n\\left(C_{\\rho}\\right)_{ij} \\equiv \\rho^{|i-j|}, \\quad i,j \\in \\{1,\\dots,p\\}.\n$$\n因此，每个模拟数据集都具有单位方差和一个托普利茨（Toeplitz）相关结构。\n\n实现要求：\n- 使用归一化 $S = \\frac{1}{n} X_{c}^{\\top} X_{c}$。\n- 实现一个函数，该函数同时返回估计的 $\\delta^{*}$ 和相应的收缩协方差矩阵 $\\widehat{\\Sigma}(\\delta^{*})$。\n- 为了数值稳定性，如果您最终表达式中 $\\delta^{*}$ 的分母为零，则设置 $\\delta^{*} = 0$，并始终将 $\\delta^{*}$ 裁剪到区间 $[0,1]$ 内。\n- 您不得调用任何预构建的收缩或协方差估计器；所有计算都必须使用基本线性代数从基本原理构建。\n\n测试套件规范：\n- 固定一个随机种子以确保可复现性。\n- 对于 $n = 200$ 和 $\\rho = 0.3$，按顺序为 $p \\in \\{10, 50, 100, 150, 190, 220\\}$ 计算 $\\delta^{*}$，对每个 $p$ 使用在相同种子序列下独立模拟的数据集。\n- 边界情况 A（接近边界 $p \\approx n$ 且弱互相关）：$(n,p,\\rho) = (50, 45, 0.0)$。\n- 边界情况 B（强互相关且 $p  n$）：$(n,p,\\rho) = (200, 250, 0.8)$。\n\n您的程序应生成单行输出，其中包含一个由方括号括起来、逗号分隔的列表形式的结果。该列表必须完全按此顺序包含八个估计的收缩强度 $\\delta^{*}$：对于 $n = 200$ 和 $\\rho = 0.3$ 的六个 $p \\in \\{10, 50, 100, 150, 190, 220\\}$ 的值，然后是边界情况 A 的单个值，最后是边界情况 B 的单个值。每个值都必须打印为浮点数。不应生成任何图形；仅数值本身将作为后续绘图或比较的可视化就绪输出。", "solution": "该问题要求推导并实现一个用于高维协方差矩阵的线性收缩估计量。该估计量的形式为 $\\widehat{\\Sigma}(\\delta) = (1 - \\delta) S + \\delta F$，其中 $S$ 是样本协方差矩阵，$F = \\mu I_p$ 是一个缩放的单位矩阵目标，$\\delta \\in [0,1]$ 是收缩强度。目标是找到最优的 $\\delta$，使其最小化期望平方弗罗贝尼乌斯损失 $\\mathcal{R}(\\delta) = \\mathbb{E}[ \\| \\widehat{\\Sigma}(\\delta) - \\Sigma \\|_{F}^{2} ]$，其中 $\\Sigma$ 是真实的总体协方差矩阵。\n\n推导必须从基本原理开始，并得出一个可由样本计算的最优收缩强度 $\\delta^*$ 的估计量，将所有涉及未知总体量（如 $\\Sigma$）的项转化为可从数据矩阵 $X$ 计算的统计量。\n\n**步骤1：最优收缩强度 $\\delta^*$ 的推导**\n\n损失函数由下式给出：\n$$ \\mathcal{R}(\\delta) = \\mathbb{E}\\left[ \\| (1-\\delta)S + \\delta F - \\Sigma \\|_{F}^{2} \\right] $$\n我们可以将范数内的项重写为与真实协方差 $\\Sigma$ 的偏差：\n$$ (1-\\delta)S + \\delta F - \\Sigma = (S - \\Sigma) - \\delta(S - F) $$\n弗罗贝尼乌斯范数由内积 $\\langle A, B \\rangle_F = \\operatorname{tr}(A^\\top B)$ 导出。利用性质 $\\|A-B\\|_F^2 = \\|A\\|_F^2 - 2\\langle A, B \\rangle_F + \\|B\\|_F^2$ 和期望的线性性质，损失函数变为：\n$$ \\mathcal{R}(\\delta) = \\mathbb{E}[\\|S - \\Sigma\\|_F^2] - 2\\delta \\mathbb{E}[\\langle S - \\Sigma, S - F \\rangle_F] + \\delta^2 \\mathbb{E}[\\|S - F\\|_F^2] $$\n这是一个关于 $\\delta$ 的二次函数。为了找到最小化 $\\mathcal{R}(\\delta)$ 的 $\\delta$ 值，我们对 $\\delta$ 求导并令其为零：\n$$ \\frac{d\\mathcal{R}(\\delta)}{d\\delta} = -2\\mathbb{E}[\\langle S - \\Sigma, S - F \\rangle_F] + 2\\delta \\mathbb{E}[\\|S - F\\|_F^2] = 0 $$\n求解 $\\delta$ 得到最优收缩强度，我们记为 $\\delta^*$：\n$$ \\delta^* = \\frac{\\mathbb{E}[\\langle S - \\Sigma, S - F \\rangle_F]}{\\mathbb{E}[\\|S - F\\|_F^2]} $$\n这个 $\\delta^*$ 的表达式依赖于未知的总体矩阵 $\\Sigma$ 和无法从单个数据样本中计算的期望。我们的下一步是为分子和分母推导基于样本的估计量。\n\n令 $N_{pop} = \\mathbb{E}[\\langle S - \\Sigma, S - F \\rangle_F]$ 和 $D_{pop} = \\mathbb{E}[\\|S - F\\|_F^2]$。我们寻求估计量 $\\hat{N}$ 和 $\\hat{D}$，使得 $\\hat{\\delta}^* = \\hat{N}/\\hat{D}$ 是 $\\delta^*$ 的一个相合估计量。\n\n**步骤2：推导分母的样本估计量 $\\hat{D}$**\n\n分母 $D_{pop} = \\mathbb{E}[\\|S - F\\|_F^2]$ 是样本协方差矩阵 $S$ 与收缩目标 $F$ 之间平方距离的期望值。对此量的一个自然且相合的估计量是其样本模拟，通过去掉期望算子得到：\n$$ \\hat{D} = \\|S - F\\|_F^2 $$\n鉴于收缩目标是 $F = \\mu I_p$，其中 $\\mu = \\frac{\\operatorname{tr}(S)}{p}$，并且 $S$ 和 $F$ 都是对称矩阵，我们可以展开此表达式：\n$$ \\hat{D} = \\operatorname{tr}((S-F)^2) = \\operatorname{tr}(S^2 - 2SF + F^2) $$\n利用迹算子的线性性质：\n$$ \\hat{D} = \\operatorname{tr}(S^2) - 2\\operatorname{tr}(SF) + \\operatorname{tr}(F^2) $$\n涉及 $F$ 的项可以简化：\n$$ \\operatorname{tr}(SF) = \\operatorname{tr}(S(\\mu I_p)) = \\mu \\operatorname{tr}(S) $$\n$$ \\operatorname{tr}(F^2) = \\operatorname{tr}((\\mu I_p)^2) = \\operatorname{tr}(\\mu^2 I_p) = p\\mu^2 $$\n将这些代回 $\\hat{D}$ 的表达式中：\n$$ \\hat{D} = \\operatorname{tr}(S^2) - 2\\mu\\operatorname{tr}(S) + p\\mu^2 $$\n最后，代入 $\\mu = \\frac{\\operatorname{tr}(S)}{p}$ 的定义：\n$$ \\hat{D} = \\operatorname{tr}(S^2) - 2\\frac{\\operatorname{tr}(S)}{p}\\operatorname{tr}(S) + p\\left(\\frac{\\operatorname{tr}(S)}{p}\\right)^2 = \\operatorname{tr}(S^2) - \\frac{2}{p}(\\operatorname{tr}(S))^2 + \\frac{1}{p}(\\operatorname{tr}(S))^2 $$\n$$ \\hat{D} = \\operatorname{tr}(S^2) - \\frac{1}{p}(\\operatorname{tr}(S))^2 $$\n这个 $\\hat{D}$ 的最终形式仅依赖于样本协方差矩阵 $S$，因此可以从数据中计算。\n\n**步骤3：推导分子的样本估计量 $\\hat{N}$**\n\n分子 $N_{pop} = \\mathbb{E}[\\langle S - \\Sigma, S - F \\rangle_F]$ 涉及未知的 $\\Sigma$，无法通过简单的样本模拟来估计。对此项的相合估计量的推导是 Ledoit-Wolf 方法论的基石，并需要高级的渐近论证。根据已有的文献（Ledoit  Wolf, 2004），$N_{pop}$ 的一个相合估计量由下式给出：\n$$ \\hat{N} = \\frac{1}{n}\\sum_{i=1}^{n} \\| (x_i - \\bar{x})(x_i - \\bar{x})^\\top - S \\|_F^2 $$\n其中 $y_i = x_i - \\bar{x}$ 表示第 $i$ 个中心化观测向量。让我们展开此表达式以获得适合计算的公式。\n$$ \\hat{N} = \\frac{1}{n}\\sum_{i=1}^{n} \\operatorname{tr}\\left( (y_i y_i^\\top - S)^2 \\right) = \\frac{1}{n}\\sum_{i=1}^{n} \\left[ \\operatorname{tr}((y_i y_i^\\top)^2) - 2\\operatorname{tr}(y_i y_i^\\top S) + \\operatorname{tr}(S^2) \\right] $$\n我们简化迹项：\n- 第一项使用性质 $\\operatorname{tr}(AB) = \\operatorname{tr}(BA)$：$\\operatorname{tr}((y_i y_i^\\top)^2) = \\operatorname{tr}(y_i (y_i^\\top y_i) y_i^\\top) = (y_i^\\top y_i) \\operatorname{tr}(y_i y_i^\\top) = (y_i^\\top y_i)(y_i^\\top y_i) = \\|y_i\\|_2^4$。\n- 第二项是一个二次型：$\\operatorname{tr}(y_i y_i^\\top S) = \\operatorname{tr}(y_i^\\top S y_i) = y_i^\\top S y_i$。\n将这些代回，我们得到：\n$$ \\hat{N} = \\frac{1}{n}\\sum_{i=1}^{n} \\left( \\|y_i\\|_2^4 - 2 y_i^\\top S y_i + \\operatorname{tr}(S^2) \\right) $$\n进一步分解此式：\n$$ \\hat{N} = \\left(\\frac{1}{n}\\sum_{i=1}^{n} \\|y_i\\|_2^4 \\right) - \\frac{2}{n}\\sum_{i=1}^{n} (y_i^\\top S y_i) + \\operatorname{tr}(S^2) $$\n这个 $\\hat{N}$ 表达式的每个组成部分都可以从中心化数据 $y_i$ 和样本协方差矩阵 $S$ 计算出来。\n\n**步骤4：最终的可计算估计量与算法**\n\n通过组合样本估计量 $\\hat{N}$ 和 $\\hat{D}$，我们得到了最优收缩强度的 Ledoit-Wolf 估计量：\n$$ \\hat{\\delta}^* = \\frac{\\hat{N}}{\\hat{D}} $$\n为确保数值稳定性和有效性，进行了两个调整：\n1. 如果分母 $\\hat{D}$ 为零，这意味着 $S$ 已经与单位矩阵成比例。在这种情况下，不需要收缩，所以我们设置 $\\hat{\\delta}^* = 0$。\n2. 收缩强度 $\\delta$ 必须位于区间 $[0,1]$ 内。因此，计算出的比率被裁剪到该范围内。\n\n最终的估计量是：\n$$ \\hat{\\delta}^*_{\\text{final}} = \\max\\left(0, \\min\\left(1, \\frac{\\hat{N}}{\\hat{D}}\\right)\\right) $$\n一旦计算出 $\\hat{\\delta}^*_{\\text{final}}$，收缩后的协方差矩阵就构造为：\n$$ \\widehat{\\Sigma}(\\hat{\\delta}^*_{\\text{final}}) = (1 - \\hat{\\delta}^*_{\\text{final}})S + \\hat{\\delta}^*_{\\text{final}}F $$\n这完成了线性收缩估计的一个完全可实现的算法的推导。", "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef generate_data(n, p, rho, rng):\n    \"\"\"\n    Generates n samples from a p-variate normal distribution with zero mean\n    and a Toeplitz correlation matrix C_rho.\n    \"\"\"\n    # Construct the first column of the Toeplitz correlation matrix\n    first_col = np.array([rho**i for i in range(p)])\n    \n    # Create the Toeplitz correlation matrix\n    C_rho = linalg.toeplitz(first_col)\n    \n    # Generate data from multivariate normal distribution\n    # Mean is zero, and covariance is the correlation matrix C_rho\n    mean = np.zeros(p)\n    X = rng.multivariate_normal(mean, C_rho, size=n)\n    \n    return X\n\ndef estimate_lw_shrinkage(X):\n    \"\"\"\n    Computes the Ledoit-Wolf linear shrinkage estimator for the covariance matrix.\n\n    Args:\n        X (np.ndarray): Data matrix of shape (n, p), where n is the number of\n                        observations and p is the number of assets.\n\n    Returns:\n        tuple: A tuple containing:\n            - delta_star (float): The estimated optimal shrinkage intensity.\n            - Sigma_hat (np.ndarray): The shrunken covariance matrix.\n    \"\"\"\n    n, p = X.shape\n    \n    # 1. Center the data\n    mean_x = np.mean(X, axis=0)\n    Y = X - mean_x\n    \n    # 2. Compute sample covariance matrix S (using 1/n normalization)\n    S = (Y.T @ Y) / n\n    \n    # 3. Compute shrinkage target parameter mu\n    tr_S = np.trace(S)\n    mu = tr_S / p\n    \n    # 4. Compute denominator estimator d_hat_sq\n    S_sq = S @ S\n    tr_S_sq = np.trace(S_sq)\n    d_hat_sq = tr_S_sq - (tr_S**2) / p\n    \n    # Handle case where d_hat_sq is zero\n    if d_hat_sq == 0:\n        return 0.0, S\n\n    # 5. Compute numerator estimator b_hat_sq (consistent estimator of N_pop)\n    sum_y_norm4_div_n = np.sum(np.sum(Y**2, axis=1)**2) / n\n    sum_ySy_div_n = np.sum(np.diag(Y @ S @ Y.T)) / n\n    \n    b_hat_sq = sum_y_norm4_div_n - 2 * sum_ySy_div_n + tr_S_sq\n\n    # 6. Compute shrinkage intensity delta_star\n    delta_star = b_hat_sq / d_hat_sq\n    \n    # 7. Clip delta_star to the interval [0, 1]\n    delta_star = np.clip(delta_star, 0.0, 1.0)\n    \n    # 8. Compute the shrunken covariance matrix\n    F = mu * np.eye(p)\n    Sigma_hat = (1 - delta_star) * S + delta_star * F\n    \n    return delta_star, Sigma_hat\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    # Fix a random seed for reproducibility\n    seed = 42\n    rng = np.random.default_rng(seed)\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Main test suite: n=200, rho=0.3, vary p\n        (200, 10, 0.3),\n        (200, 50, 0.3),\n        (200, 100, 0.3),\n        (200, 150, 0.3),\n        (200, 190, 0.3),\n        (200, 220, 0.3),\n        # Edge case A: p approx n, weak correlation\n        (50, 45, 0.0),\n        # Edge case B: p > n, strong correlation\n        (200, 250, 0.8),\n    ]\n\n    results = []\n    for n, p, rho in test_cases:\n        # Generate data for the current case\n        X = generate_data(n, p, rho, rng)\n        \n        # Estimate shrinkage intensity\n        delta_star, _ = estimate_lw_shrinkage(X)\n        results.append(delta_star)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "2385059"}]}