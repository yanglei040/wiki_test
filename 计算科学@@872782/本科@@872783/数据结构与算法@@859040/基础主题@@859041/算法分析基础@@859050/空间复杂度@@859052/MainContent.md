## 引言
在评估算法效率时，我们往往首先关注其运行速度，即[时间复杂度](@entry_id:145062)。然而，一个同样关键且有时更具挑战性的维度是算法在执行过程中消耗的内存资源，这由**空间复杂度 (Space Complexity)** 来量化。尤其是在大数据、人工智能和内存受限的嵌入式系统时代，对内存的有效管理直接决定了一个解决方案的可行性与可扩展性。许多对算法的初步理解止步于渐进符号，却忽略了底层实现、语言特性乃至跨学科应用中对空间效率的深刻影响。

本文旨在填补这一认知空白，为读者构建一个关于空间复杂度的完整而深入的知识体系。我们将系统性地探索三个核心层面：首先，在**“原理与机制”**一章中，我们将奠定理论基础，从核心定义和度量模型出发，深入剖析[数据结构](@entry_id:262134)的内存开销和关键的算法[优化技术](@entry_id:635438)。接着，在**“应用与跨学科联系”**一章中，我们将跨越理论，展示空间复杂度如何在机器学习、生物信息学和[分布式系统](@entry_id:268208)等前沿领域扮演决定性角色。最后，通过**“动手实践”**环节，你将有机会将所学知识应用于具体问题，锻炼分析和优化空间占用的能力。通过这一学习路径，你将不仅学会如何计算空间复杂度，更将理解如何设计出真[正空间](@entry_id:754128)高效的算法和系统。

## 原理与机制

在计算科学领域，算法的效率并不仅仅由其运行速度来衡量。同样至关重要的，是算法在执行过程中所消耗的内存资源。**空间复杂度 (Space Complexity)** 正是量化这一资源消耗的关键指标。它描述了算法所需内存空间与其输入规模之间的函数关系。与[时间复杂度](@entry_id:145062)一样，空间复杂度是评估算法性能和可行性的核心维度，尤其是在处理大规模数据集或在内存受限的环境（如嵌入式系统或移动设备）中。

本章将深入探讨空间复杂度的基本原理与关键机制。我们将从其核心定义出发，区分不同的度量约定，并剖析多种[计算模型](@entry_id:152639)下的空间消耗。随后，我们将通过具体的案例，自底向上地分析数据结构在内存中的精确布局，揭示那些在渐进分析中常被忽略的开销。最后，我们将探讨一系列旨在优化空间利用率的算法设计技术，以及在现代编程语言中由[闭包](@entry_id:148169)等高级特性引发的“隐藏”空间成本。

### 定义与[度量空间](@entry_id:138860)复杂度

对空间复杂度的精确理解，始于对其度量标准和[计算模型](@entry_id:152639)的清晰界定。一个看似简单的算法，其空间消耗的评估结果可能会因我们所采纳的“视角”不同而大相径庭。

#### 核心约定：[辅助空间](@entry_id:638067)与总空间

在讨论空间复杂度时，首要的区分在于我们统计的是 **总空间 (Total Space)** 还是 **[辅助空间](@entry_id:638067) (Auxiliary Space)**。

**总空间** 是指算法使用的所有内存，这包括了存储输入数据本身的空间、算法在执行过程中分配的任何额外空间，以及（在某些约定下）存储输出数据的空间。总[空间分析](@entry_id:183208)对于理解一个程序完整的内存足迹至关重要。

**[辅助空间](@entry_id:638067)** 则更为关注算法本身的内在效率，它只计算算法在执行期间额外使用的内存，而不包括输入数据所占用的空间。这使得我们能够独立地评估算法处理数据所需的“工作区”大小，而不受输入表示形式的影响。

为了阐明这一区别，让我们思考一个算法问题：给定一个具有 $N$ 个顶点的[无向图](@entry_id:270905)，判断其中是否存在孤立顶点（即没有任何边与之相连的顶点）。假设该图以一个 $N \times N$ 的 **邻接矩阵 (Adjacency Matrix)** $A$ 的形式提供，且该矩阵存储于只读内存中。一个简单的算法可以逐行扫描这个矩阵，对每一行求和。如果某行的和为零，则意味着对应的顶点没有边，即为孤立顶点。该算法在执行过程中，仅需维护少数几个变量：行索引 $i$、列索引 $j$、行和 $s$ 以及一个布尔标志 $b$。

从 **总空间** 的角度看，由于输入是一个 $N \times N$ 的矩阵，其本身就占用了 $\Theta(N^2)$ 的存储空间。因此，任何包含输入在内的空间度量都将得出该算法的总空间复杂度至少为 $\Omega(N^2)$ [@problem_id:3272679]。

然而，从 **[辅助空间](@entry_id:638067)** 的角度看，情况则完全不同。算法只需要固定数量的变量（$i, j, s, b$），这些变量所占用的空间与输入规模 $N$ 无关。因此，其[辅助空间](@entry_id:638067)复杂度为 $O(1)$。这个 $O(1)$ 的结论揭示了算法在处理数据时的空间效率——它并不需要在输入之外构建任何与输入规模成比例的复杂[数据结构](@entry_id:262134)。在[算法设计与分析](@entry_id:746357)中，[辅助空间](@entry_id:638067)通常是我们更关心的指标，因为它更好地反映了算法的内在空间需求。

#### [计算模型](@entry_id:152639)与度量单位

空间复杂度的具体数值还取决于我们所使用的抽象 **[计算模型](@entry_id:152639) (Model of Computation)** 和 **度量单位 (Units of Measurement)**。

最常见的模型之一是 **字[随机存取机](@entry_id:270308) (Word RAM) 模型**。在该模型中，我们假设[计算机内存](@entry_id:170089)由一系列“字”（words）组成，每个字的大小足以存储一个内存地址或一个输入参数。通常，字长被认为是 $\Theta(\log N)$ 比特，其中 $N$ 是输入规模。在此模型下，对内存的度量通常以“字”为单位。对于前述的孤立顶点检测算法，由于它只使用了常数个变量，每个变量都可以存放在一个机器字中，因此其[辅助空间](@entry_id:638067)复杂度在字 [RAM](@entry_id:173159) 模型下为 $O(1)$ 个字 [@problem_id:3272679]。

另一个更底层的模型是 **[图灵机](@entry_id:153260) (Turing Machine) 模型** 或 **[位复杂度](@entry_id:634832) (Bit-Complexity) 模型**。在这里，空间被精确地度量为所需的 **比特 (bits)** 或磁带单元数。在[图灵机](@entry_id:153260)模型中，输入通常放在一个只读的输入带上，而[辅助空间](@entry_id:638067)则对应于工作带上使用的单元数。对于那个孤立顶点检测算法，变量 $i$ 和 $j$ 需要能表示从 $1$ 到 $N$ 的数字，这需要 $\Theta(\log N)$ 个比特。因此，在[位复杂度](@entry_id:634832)模型下，该算法的[辅助空间](@entry_id:638067)复杂度为 $O(\log N)$ 比特 [@problem_id:3272679]。

这两种模型的区别在处理大数时变得尤为重要。考虑一个生成前 $n$ 个[斐波那契数](@entry_id:267966)的程序。[斐波那契数](@entry_id:267966) $F_k$ 呈指数级增长，其值的比特长度与 $k$ 成正比，即 $\log F_k = \Theta(k)$。

- **Python 生成器 (`yield`) 实现**: 该函数一次只生成一个数，仅需保存前两个数即可计算下一个。
    - 在 **字 [RAM](@entry_id:173159) 模型** 下，我们不考虑数值本身的增长，假设每个数都占用 $O(1)$ 的空间（一个字）。因此，生成器只需常数个变量，[辅助空间](@entry_id:638067)为 $\Theta(1)$。
    - 在更真实的 **[位复杂度](@entry_id:634832)模型** 下（这反映了 Python 等语言中任意精度整数的行为），当计算到第 $n$ 个数时，程序需要存储 $F_{n-1}$ 和 $F_{n-2}$，其大小均为 $\Theta(n)$ 比特。因此，峰值[辅助空间](@entry_id:638067)为 $\Theta(n)$ 比特。

- **返回列表的实现**: 该函数计算所有 $n$ 个数并存入一个列表返回。
    - 在 **字 [RAM](@entry_id:173159) 模型** 下，列表包含 $n$ 个元素，每个元素占用 $\Theta(1)$ 空间，总空间为 $\Theta(n)$。
    - 在 **[位复杂度](@entry_id:634832)模型** 下，存储整个列表所需的总空间是所有[斐波那契数](@entry_id:267966)大小的总和，即 $\sum_{k=0}^{n-1} \Theta(\log F_k) = \sum_{k=1}^{n-1} \Theta(k) = \Theta(n^2)$ 比特。

这个例子 [@problem_id:3272722] 鲜明地揭示了，对空间复杂度的深刻理解不仅要考虑存储元素的数量，还必须考虑元素本身的大小以及底层计算模型和语言特性的影响。抽象的字 RAM 模型在很多情况下是有效的简化，但当数据本身的大小随输入规模变化时，[位复杂度](@entry_id:634832)模型能提供更精确的洞察。

### [数据结构](@entry_id:262134)的空间复杂度

算法依赖于数据结构来组织信息。因此，数据结构本身的空间开销是空间[复杂度分析](@entry_id:634248)的重要组成部分。渐进分析（如[大O表示法](@entry_id:634712)）为我们提供了高层次的视角，但深入到底层的具体实现，可以揭示许多在抽象层面被忽略的成本。

#### 渐进分析与具体实现

让我们通过比较两种常见的[图表示](@entry_id:273102)法来探索这一点：邻接矩阵和[邻接表](@entry_id:266874)。假设我们需要存储一个拥有 $V$ 个顶点的图。

- **邻接矩阵**：对于一个[稠密图](@entry_id:634853)，[邻接矩阵](@entry_id:151010)是一个直观的选择。一个 $V \times V$ 的布尔矩阵可以表示任意两个顶点间是否存在边。如果每个条目用一个字节存储，总空间就是 $V^2$ 字节。其空间复杂度为 $\Theta(V^2)$。

- **[邻接表](@entry_id:266874)**：对于[稀疏图](@entry_id:261439)，[邻接表](@entry_id:266874)通常更节省空间。它由一个包含 $V$ 个头指针的数组和一系列表示边的节点组成。

为了进行精确比较，我们需要一个具体的场景。考虑一个拥有 $V$ 个顶点的 **[极大平面图](@entry_id:266059) (maximal planar graph)**，其边数 $E$ 恰好达到理论上限 $3V - 6$（对于 $V \ge 3$）。我们用[邻接表](@entry_id:266874)来存储它，并假设如下的[内存布局](@entry_id:635809)：指针占8字节，整数占4字节。[邻接表](@entry_id:266874)的头指针数组包含 $V$ 个指针，占用 $8V$ 字节。由于是[无向图](@entry_id:270905)，每条边对应两个邻接节点，总共有 $2E = 2(3V-6) = 6V-12$ 个节点。每个节点包含一个4字节的顶点ID和一个8字节的下一节点指针。假设为了对齐，每个节点还额外填充了4字节，使得节点大小为16字节。那么，所有节点占用的空间为 $16 \times (6V-12) = 96V - 192$ 字节。因此，[邻接表](@entry_id:266874)的总空间为 $8V + (96V - 192) = 104V - 192$ 字节 [@problem_id:3272547]。

现在，我们可以计算用[邻接矩阵](@entry_id:151010)表示的[稠密图](@entry_id:634853)与用[邻接表](@entry_id:266874)表示的[极大平面图](@entry_id:266059)之间的空间占用比：
$$ R(V) = \frac{V^2}{104V - 192} = \frac{V^2}{8(13V - 24)} $$
这个精确的比例公式超越了简单的 $\Theta(V^2)$ 与 $\Theta(V)$ 的比较，它揭示了[数据结构](@entry_id:262134)选择背后的具体数量权衡。当 $V$ 较小时，常数因子和低阶项可能很重要；当 $V$ 增大时，$V^2$ 项将主导增长，使得[邻接表](@entry_id:266874)的优势愈发明显。

#### 底层开销：对齐与填充

内存消耗的精确计算甚至需要深入到比数据结构更低的层次——**[内存对齐](@entry_id:751842) (Memory Alignment)** 与 **填充 (Padding)**。现代处理器为了高效访问数据，通常要求特定类型的数据（如 `int`, `double`）存放在其大小的整数倍地址上。为了满足这一要求，编译器会在[数据结构](@entry_id:262134)成员之间以及结构的末尾插入一些不使用的“填充”字节。

考虑一个在典型的64位系统上定义的C++结构体，其成员按顺序声明为：`char c`，`double d`，`int x`。各类型的大小和对齐要求分别为：`char` (1字节大小，1字节对齐)，`double` (8字节大小，8字节对齐)，`int` (4字节大小，4字节对齐)。

理论上，这些字段的总大小为 $1 + 8 + 4 = 13$ 字节。但实际的[内存布局](@entry_id:635809)如下 [@problem_id:3272554]：
1.  `char c`: 位于偏移量0，占用1字节。下一个可用偏移量是1。
2.  `double d`: 对齐要求为8字节。下一个满足此要求的偏移量是8。因此，编译器在 `c` 和 `d` 之间插入 **7个填充字节**。`d` 位于偏移量8，占用8字节。下一个可用偏移量是16。
3.  `int x`: 对齐要求为4字节。当前偏移量16是4的倍数，无需填充。`x` 位于偏移量16，占用4字节。结构体内容至此结束于偏移量20。

最后，整个结构体的总大小必须是其成员中最大对齐要求（即 `double` 的8字节）的整数倍。大于等于20的最小的8的倍数是24。因此，编译器在结构体末尾再添加 **4个填充字节**。

最终，该结构体的实际大小为24字节，远超理论上的13字节。这11字节的额外开销完全来自于对齐和填充。这个例子说明，即使在微观层面，成员的声明顺序也会影响数据结构的空间效率。如果将成员按对齐要求从大到小[排列](@entry_id:136432)（`double`, `int`, `char`），则可以显著减少甚至消除填充，从而优化空间。

#### 案例研究：哈希表

哈希表是另一个很好的例子，其空间占用依赖于其内部实现和参数。考虑一个使用 **分离链表法 (Separate Chaining)** 的[哈希表](@entry_id:266620)，它由一个大小为 $m$ 的桶数组和 $n$ 个存储键值对的链表节点组成。设指针大小为 $p$，每个节点有大小为 $h$ 的分配器头部开销，键和值的大小分别为 $s_k$ 和 $s_v$。

总空间 $S$ 是桶数组空间 $S_{array}$ 和所有节点空间 $S_{nodes}$ 之和 [@problem_id:3272631]。
-   桶数组是一个指针数组，因此 $S_{array} = m \cdot p$。
-   共有 $n$ 个节点。每个节点包含一个键、一个值、一个 `next` 指针以及头部开销，因此单个节点大小为 $s_{node} = h + s_k + s_v + p$。所有节点的总空间为 $S_{nodes} = n \cdot s_{node}$。

总空间为 $S = m \cdot p + n(h + s_k + s_v + p)$。
[哈希表](@entry_id:266620)的一个关键性能参数是 **[负载因子](@entry_id:637044) (load factor)** $\alpha = \frac{n}{m}$。用 $\alpha$ 来表示 $n$（即 $n = \alpha m$），我们可以将总空间表示为 $m$ 和 $\alpha$ 的函数：
$$ S(\alpha) = m \cdot p + (\alpha m)(h + s_k + s_v + p) = m \left[ p(1 + \alpha) + \alpha (h + s_k + s_v) \right] $$
这个公式清晰地表明，哈希表的空间不仅取决于存储的元素数量 $n$，还取决于其内部设计——桶的数量 $m$。保持较低的[负载因子](@entry_id:637044)（即较大的 $m$）可以提高时间性能，但代价是增加空间开销（更多的桶和未使用的指针空间）。

### 算法技术及其空间影响

除了数据结构的选择，算法的设计策略本身也对空间复杂度有深远影响。优化空间通常需要在算法逻辑层面进行精巧的设计。

#### 递归与栈空间

递归是一种强大的编程[范式](@entry_id:161181)，但其空间成本不容忽视。每次函数调用都会在 **调用栈 (Call Stack)** 上创建一个 **栈帧 (Stack Frame)** 或 **[活动记录](@entry_id:636889) (Activation Record)**，用于存储局部变量、返回地址和其他簿记信息。[递归算法](@entry_id:636816)的[辅助空间](@entry_id:638067)复杂度因此与 **最大递归深度** 成正比。

一个经典的例子是[快速排序](@entry_id:276600)。在标准实现中，一个分区操作后，算法会递归地对左右两个子数组进行排序。在最坏情况下（例如，每次都选中最小或最大的元素作为主元），分区会极不均衡，产生一个大小为 $n-1$ 的子问题和一个大小为 $0$ 的子问题。这会导致递归深度达到 $\Theta(n)$，从而使栈空间复杂度也达到 $\Theta(n)$，这对于大规模输入是不可接受的 [@problem_id:3272541]。

幸运的是，我们有多种技术可以确保[快速排序](@entry_id:276600)的栈空间为 $O(\log N)$：
1.  **优化递归顺序**：一个非常有效的技巧是，在分区后，**总是先对较小的子数组进行递归调用**，然后通过循环（或[尾递归](@entry_id:636825)）来处理较大的子数组。由于每次递归处理的问题规模都小于等于原问题的一半，最大递归深度被限制在 $O(\log N)$。这是一个确定性的保证，与主元选择策略无关。
2.  **显式栈的迭代实现**：我们可以将[递归算法](@entry_id:636816)改写为迭代形式，并使用一个显式的栈（如一个数组或链表）来模拟递归。通过遵循与上述技巧相同的逻辑——总是将较大的子问题后处理（或先压入栈），并将较小的子问题先处理（或后压入栈），我们可以确保显式栈的大小峰值同样被限制在 $O(\log N)$ [@problem_id:3272541]。
3.  **保证划分平衡**：使用如 **[中位数的中位数](@entry_id:636459) (Median-of-Medians)** 算法来确定性地选择一个“好”的主元。该算法能保证每次划分产生的两个子问题的大小都至少是原问题大小的一个常数比例。这使得递归[树的高度](@entry_id:264337)自然地被限制在 $O(\log N)$，从而保证了栈空间 [@problem_id:3272541]。

值得注意的是，**[随机化](@entry_id:198186)主元选择** 策略虽然能以极高概率使递归深度达到 $O(\log N)$，但它并不能提供 **最坏情况下的保证**。在极小概率下，随机选择仍可能连续选出差的主元，导致 $O(N)$ 的深度。

#### [尾调用优化](@entry_id:755798) (TCO)

**[尾递归](@entry_id:636825) (Tail Recursion)** 是递归的一种特殊形式，其中递归调用是函数在返回前执行的最后一个操作。例如，遍历一个[链表](@entry_id:635687)：
```
function traverse(node):
  if node is null: return
  process(node)
  traverse(node.next) // This is a tail call
```
在不支持优化的系统中，这样的代码会为[链表](@entry_id:635687)中的每个节点都创建一个新的栈帧，导致 $O(n)$ 的空间复杂度。然而，许多现代编译器和解释器实现了 **[尾调用优化](@entry_id:755798) (Tail-Call Optimization, TCO)**。TCO 识别出尾调用，并用一个简单的跳转来代替它，同时 **重用当前的栈帧**。这意味着不会有新的[栈帧](@entry_id:635120)被分配。

其效果是惊人的：一个尾[递归函数](@entry_id:634992)在有TCO的系统上执行时，其空间复杂度从 $O(n)$ 降至 $O(1)$，与等效的迭代循环完全相同 [@problem_id:3272584]。这使得程序员可以享受递归表达的清晰性，而无需承担其传统的空间开销。

#### 动态规划的空间优化

动态规划 (DP) 通常涉及填充一个巨大的表格来存储子问题的解。例如，一个典型的二维D[P问题](@entry_id:267898)（如[最长公共子序列](@entry_id:636212)）的递推关系可能如下：
$$ dp[i][j] = f(dp[i-1][j], dp[i][j-1]) $$
一个朴素的实现会创建一个 $N \times N$ 的二维数组，空间复杂度为 $O(N^2)$。然而，仔细观察[递推关系](@entry_id:189264)会发现，计算第 $i$ 行的任何单元格，我们只需要来自第 $i-1$ 行（上一行）和第 $i$ 行（当前行已计算部分）的值。一旦第 $i$ 行计算完毕，第 $i-1$ 行及之前的所有行就再也用不到了。

这个观察是空间优化的关键 [@problem_id:3272607]。
-   **双行法**：我们可以只保留两个长度为 $N$ 的数组：一个 `prev_row` 存储第 $i-1$ 行的值，一个 `curr_row` 用于计算第 $i$ 行的值。计算完一行后，`curr_row` 变成新的 `prev_row`，然后继续计算下一行。这样，空间复杂度从 $O(N^2)$ 降至 $O(N)$。
-   **单行法**：更进一步的优化是只使用一个长度为 $N$ 的数组。当我们从左到右计算第 $i$ 行时，`dp_row[j]` 的旧值代表 $dp[i-1][j]$，而 `dp_row[j-1]` 的新值代表 $dp[i][j-1]$。更新 `dp_row[j]` 时，我们恰好需要这两个值。这种原地更新的策略同样能将空间复杂度降至 $O(N)$。

#### [时空权衡](@entry_id:755997)

**[时空权衡](@entry_id:755997) (Space-Time Tradeoff)** 是算法设计中的一个基本主题：我们可以通过使用更多的内存来换取更快的运行时间，反之亦然。

考虑在一个包含 $N$ 个元素的有序数组中搜索一个键。标准的二分[搜索算法](@entry_id:272182)耗时 $O(\log N)$，[辅助空间](@entry_id:638067)为 $O(1)$。在 **比较模型 (Comparison Model)** 下，这是一个理论最优的时间复杂度，因为任何基于比较的搜索算法都需要至少 $\Omega(\log N)$ 次比较来区分 $N+1$ 种可能的结果。

但是，如果我们跳出比较模型的限制，进入允许我们将键值用作数组索引的 **字 RAM 模型**，我们就可以打破这个界限。假设我们可以使用 $O(\sqrt{N})$ 的额外空间。我们可以设计一种策略：预先处理一部分可能的查询。例如，我们知道线上查询将来自一个大小为 $K = \Theta(\sqrt{N})$ 的特定集合 $S$。在预处理阶段，我们可以构建一个哈希表（或[完美哈希](@entry_id:634548)表），将每个存在于数组 $A$ 中的 $s \in S$ 映射到它在 $A$ 中的索引。这个哈希表本身占用 $O(K) = O(\sqrt{N})$ 的空间。

在查询阶段，对于一个给定的查询键 $x \in S$，我们首先在哈希表中查找它。这是一个 $O(1)$ 的操作。如果找到，我们立即得到答案。这样，对于这个特定的查询[子集](@entry_id:261956) $S$，我们将最坏情况查询时间从 $O(\log N)$ 降至了 $O(1)$ [@problem_id:3272585]。这是一个典型的例子，展示了如何用适度的额外空间（$O(\sqrt{N})$）来换取特定场景下显著的时间性能提升。

#### 隐藏空间：[闭包](@entry_id:148169)与[垃圾回收](@entry_id:637325)

在支持[词法作用域](@entry_id:637670)和[一等函数](@entry_id:749404)（如Python, JavaScript, Lisp）的现代编程语言中，空间复杂度的分析需要警惕一种“隐藏”的成本，它源于 **闭包 (Closures)**。

闭包是一个函数对象，它“记住”了其创建时所在的词法环境。这意味着，闭包可以访问其外部函数中定义的变量，即使外部函数已经执行完毕。当闭包被传递或存储时，它会随身携带对其环境的引用。

在[垃圾回收](@entry_id:637325)（GC）机制下，一个对象只要仍然可以从程序的“根”（如全局变量或调用栈）被访问到，它就不会被回收。[闭包](@entry_id:148169)的这种特性可能导致意想不到的内存占用 [@problem_id:3272652]。

考虑一个高阶函数，它接收一个大小为 $\Theta(n)$ 的庞大配置对象 $C$：

-   **变体 Alpha**：该函数从 $C$ 中计算出一个大小为 $\Theta(1)$ 的摘要 $d$，然后返回一个只依赖于 $d$ 的[闭包](@entry_id:148169)。这个闭包在其环境中只捕获了 $d$，而没有捕获 $C$。当高阶函数返回后，即使闭包被永久保存，由于没有对 $C$ 的引用，GC 就可以回收这个庞大的配置对象。因此，[闭包](@entry_id:148169)所保留的额外空间为 $O(1)$。

-   **变体 Beta**：该函数返回一个闭包，该闭包在其操作中需要直接访问 $C$ 的字段。这意味着闭包的环境中包含了对 $C$ 的引用。当这个[闭包](@entry_id:148169)被永久保存时，它就成了一个“根”，通过它，$C$ 始终是可达的。因此，GC 永远无法回收 $C$。这个小小的闭包对象就像一个锚，将大小为 $\Theta(n)$ 的 $C$ 对象“钉”在了内存中。因此，其保留的额外空间为 $\Theta(n)$。

这种由闭包无意中持有大对象引用而导致的内存不释放，是实际软件开发中一种常见的[内存泄漏](@entry_id:635048)模式。它提醒我们，[空间分析](@entry_id:183208)不仅要关注我们明确创建的[数据结构](@entry_id:262134)，还要理解语言特性所带来的隐式内存依赖关系。