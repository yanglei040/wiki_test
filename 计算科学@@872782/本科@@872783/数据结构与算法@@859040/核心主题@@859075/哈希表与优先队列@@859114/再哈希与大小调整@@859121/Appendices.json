{"hands_on_practices": [{"introduction": "在设计动态数据结构时，理解其操作的真实成本至关重要。此练习将理论付诸实践，要求您精确计算在一系列密集的插入和删除操作中，动态哈希表的总工作量[@problem_id:3266677]。通过手动追踪容量的增长和收缩，您将具体地量化再哈希（rehashing）的成本，从而深刻理解摊销分析背后的直观原理。", "problem": "考虑一个支持动态调整大小的开放定址哈希表，其容量会根据负载因子进行加倍和减半。负载因子定义为 $\\alpha = \\frac{s}{M}$，其中 $s$ 是当前存储的键数，$M$ 是当前哈希表的容量。该表使用以下调整大小的策略：\n- 在插入操作时，如果再插入一个键会导致 $\\alpha$ 超过上限阈值 $\\alpha_{\\max}$，则将哈希表容量加倍，并将所有现有键重新哈希到新表中。\n- 在删除操作后，如果移除一个键导致 $\\alpha$ 严格低于下限阈值 $\\alpha_{\\min}$，则将哈希表容量减半（但绝不低于一个固定的最小容量），并将所有剩余键重新哈希到新表中。\n\n假设使用以下参数和成本模型：\n- 初始容量为 $M_0 = 16$，且哈希表容量永远不会收缩到低于 $M_0$。\n- 上限阈值为 $\\alpha_{\\max} = 1$（当试图向一个已满的表中插入时会发生扩容）。\n- 下限阈值为 $\\alpha_{\\min} = \\frac{1}{2}$。\n- 操作序列是向一个初始为空的表中进行 $N = 1000$ 次插入，紧接着进行 $N = 1000$ 次删除。\n- 每次不触发调整大小的插入或删除操作成本为 $1$ 个工作单位。\n- 一次调整大小（无论是扩容还是缩容）会将当前存储的所有键重新哈希到新表中，每个重新哈希的键成本为 $1$ 个工作单位。忽略内存分配和任何其他开销。\n- 假设哈希是均匀的，因此将一个键放入表中（不调整大小）的预期成本是恒定的，并已计入上述的 $1$ 个工作单位中。\n\n基于这些定义和策略，推导出整个操作序列所执行的总工作量的精确值，以指定单位计算。将最终答案表示为单个实数值，无需四舍五入。", "solution": "用户希望我解决这个问题。我将首先验证问题陈述。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n\n-   负载因子定义为 $\\alpha = \\frac{s}{M}$，其中 $s$ 是存储的键数，$M$ 是哈希表容量。\n-   初始和最小容量为 $M_0 = 16$。\n-   上限调整阈值为 $\\alpha_{\\max} = 1$。如果再插入一个键会导致 $\\alpha > \\alpha_{\\max}$，则会发生扩容。\n-   下限调整阈值为 $\\alpha_{\\min} = \\frac{1}{2}$。如果在删除后 $\\alpha  \\alpha_{\\min}$，则会发生缩容。\n-   操作序列是向一个初始为空的表中进行 $N = 1000$ 次插入，然后进行 $N = 1000$ 次删除。\n-   不调整大小时的插入或删除成本为 $1$ 个工作单位。\n-   调整大小的成本是每个重新哈希的键 $1$ 个工作单位。\n-   扩容操作：哈希表容量加倍 ($M \\to 2M$)。\n-   缩容操作：哈希表容量减半 ($M \\to \\frac{M}{2}$)。\n\n**步骤2：使用提取的已知条件进行验证**\n\n-   **科学依据**：该问题描述了一种经典的动态数组或开放定址哈希表的调整大小策略。其模型和成本分析是计算机科学和算法领域的标准课题。它牢固地基于数据结构分析的既定原则。\n-   **适定性**：初始条件（空表，$M_0=16$）、操作序列（1000次插入，1000次删除）和调整大小的规则都已精确定义。这使得总工作量的计算是唯一的、确定性的。\n-   **客观性**：问题使用了精确、无歧义的数学定义和规则进行陈述。\n\n该问题是自包含、一致的，并且没有违反任何指定的有效性标准。\n\n**步骤3：结论与行动**\n\n该问题被判定为**有效**。将提供完整解答。\n\n### 解答\n\n总工作量是插入阶段和删除阶段所执行工作的总和。我们将分别分析每个阶段。\n\n**1. 插入阶段：$1000$ 次插入**\n\n哈希表初始为空，即 $s=0$，初始容量为 $M=16$。\n1000 次插入操作的基础成本是 $1000 \\times 1 = 1000$ 个工作单位。\n\n我们还必须计算调整大小期间所做的工作。当尝试插入一个键，使得负载因子 $\\alpha = \\frac{s+1}{M}$ 超过 $\\alpha_{\\max} = 1$ 时，会触发扩容。这可以简化为条件 $\\frac{s+1}{M} > 1$，即 $s+1 > M$。由于键的数量 $s$ 不能超过容量 $M$，这个条件只在 $s=M$ 时满足。因此，在插入第 $(M+1)$ 个键之前，哈希表会扩容。这次扩容的成本是表中已有的键数，即 $s=M$。\n\n让我们追踪扩容事件：\n-   **初始状态：** $s=0$, $M=16$。\n-   插入第 $1$ 到第 $16$ 个键。当 $s=16$ 时，哈希表已满。\n-   **第一次扩容：** 在插入第 $17$ 个键之前，$s=16$ 且 $M=16$。触发一次调整大小。\n    -   新容量：$M \\to 2 \\times 16 = 32$。\n    -   调整大小的工作量：$16$ 个键被重新哈希，成本为 $16$ 个单位。\n-   **第二次扩容：** 哈希表再次填满。在插入第 $33$ 个键之前，$s=32$ 且 $M=32$。触发一次调整大小。\n    -   新容量：$M \\to 2 \\times 32 = 64$。\n    -   调整大小的工作量：$32$ 个键被重新哈希，成本为 $32$ 个单位。\n-   **第三次扩容：** 在插入第 $65$ 个键之前（$s=64, M=64$）。\n    -   新容量：$M \\to 2 \\times 64 = 128$。\n    -   调整大小的工作量：$64$ 个单位。\n-   **第四次扩容：** 在插入第 $129$ 个键之前（$s=128, M=128$）。\n    -   新容量：$M \\to 2 \\times 128 = 256$。\n    -   调整大小的工作量：$128$ 个单位。\n-   **第五次扩容：** 在插入第 $257$ 个键之前（$s=256, M=256$）。\n    -   新容量：$M \\to 2 \\times 256 = 512$。\n    -   调整大小的工作量：$256$ 个单位。\n-   **第六次扩容：** 在插入第 $513$ 个键之前（$s=512, M=512$）。\n    -   新容量：$M \\to 2 \\times 512 = 1024$。\n    -   调整大小的工作量：$512$ 个单位。\n\n在第6次扩容后，容量为 $M=1024$。接着插入第 $513$ 到 $1000$ 个键。由于键的数量 $s$ 始终小于 $1024$，因此不会再发生扩容。\n\n插入阶段的总工作量（$W_{\\text{ins}}$）是基础插入工作量和总调整大小工作量之和。\n$$ W_{\\text{resize, ins}} = 16 + 32 + 64 + 128 + 256 + 512 $$\n这是一个几何级数：\n$$ W_{\\text{resize, ins}} = 16(1 + 2 + 4 + 8 + 16 + 32) = 16 \\sum_{i=0}^{5} 2^i = 16 \\left(\\frac{2^6 - 1}{2-1}\\right) = 16(63) = 1008 $$\n插入阶段总工作量：\n$$ W_{\\text{ins}} = 1000 + W_{\\text{resize, ins}} = 1000 + 1008 = 2008 $$\n在此阶段结束时，哈希表中有 $s=1000$ 个键，容量为 $M=1024$。\n\n**2. 删除阶段：$1000$ 次删除**\n\n此阶段开始时，$s=1000$ 且 $M=1024$。\n1000 次删除操作的基础成本是 $1000 \\times 1 = 1000$ 个工作单位。\n\n如果在删除一个键后，新的负载因子 $\\alpha = \\frac{s}{M}$ 严格低于 $\\alpha_{\\min} = \\frac{1}{2}$，则会触发缩容。这个条件是 $\\frac{s}{M}  \\frac{1}{2}$，即 $s  \\frac{M}{2}$。缩容的成本是剩余键的数量 $s$。\n\n让我们追踪缩容事件：\n-   **初始状态：** $s=1000$, $M=1024$。\n-   键被逐一删除。对于 $M=1024$ 的第一次缩容条件是 $s  \\frac{1024}{2}$，即 $s  512$。这发生在元素数量从 $s=512$ 下降到 $s=511$ 时。\n-   **第一次缩容：** 当 $s=512$ 时删除一个键后，新的键数为 $s=511$。\n    -   条件满足：$511  512$。\n    -   新容量：$M \\to \\frac{1024}{2} = 512$。\n    -   调整大小的工作量：$511$ 个剩余键被重新哈希，成本为 $511$ 个单位。\n-   **第二次缩容：** 现在 $s$ 在 $M=512$ 的情况下从 $511$ 开始减少。下一个缩容条件是 $s  \\frac{512}{2}$，即 $s  256$。这发生在 $s$ 从 $256$ 下降到 $255$ 时。\n    -   新容量：$M \\to \\frac{512}{2} = 256$。\n    -   调整大小的工作量：$255$ 个单位。\n-   **第三次缩容：** $s$ 在 $M=256$ 的情况下从 $255$ 开始减少。缩容条件：$s  \\frac{256}{2}$，即 $s  128$。当 $s$ 变为 $127$ 时触发。\n    -   新容量：$M \\to \\frac{256}{2} = 128$。\n    -   调整大小的工作量：$127$ 个单位。\n-   **第四次缩容：** $s$ 在 $M=128$ 的情况下从 $127$ 开始减少。缩容条件：$s  \\frac{128}{2}$，即 $s  64$。当 $s$ 变为 $63$ 时触发。\n    -   新容量：$M \\to \\frac{128}{2} = 64$。\n    -   调整大小的工作量：$63$ 个单位。\n-   **第五次缩容：** $s$ 在 $M=64$ 的情况下从 $63$ 开始减少。缩容条件：$s  \\frac{64}{2}$，即 $s  32$。当 $s$ 变为 $31$ 时触发。\n    -   新容量：$M \\to \\frac{64}{2} = 32$。\n    -   调整大小的工作量：$31$ 个单位。\n-   **第六次缩容：** $s$ 在 $M=32$ 的情况下从 $31$ 开始减少。缩容条件：$s  \\frac{32}{2}$，即 $s  16$。当 $s$ 变为 $15$ 时触发。\n    -   新容量：$M \\to \\frac{32}{2} = 16$。\n    -   调整大小的工作量：$15$ 个单位。\n\n在最后一次缩容后，容量为 $M=16$。问题陈述容量永远不会收缩到低于 $M_0=16$。因此，在删除剩余键的过程中不会再发生缩容。\n\n删除阶段的总工作量（$W_{\\text{del}}$）是基础删除工作量和总调整大小工作量之和。\n$$ W_{\\text{resize, del}} = 511 + 255 + 127 + 63 + 31 + 15 $$\n这个和可以写作：\n$$ W_{\\text{resize, del}} = (512-1) + (256-1) + (128-1) + (64-1) + (32-1) + (16-1) $$\n$$ W_{\\text{resize, del}} = (2^9-1) + (2^8-1) + (2^7-1) + (2^6-1) + (2^5-1) + (2^4-1) $$\n$$ W_{\\text{resize, del}} = \\left(\\sum_{i=4}^{9} 2^i\\right) - 6 $$\n几何级数的和为 $\\sum_{i=4}^{9} 2^i = 2^4 \\sum_{j=0}^{5} 2^j = 16 \\left(\\frac{2^6 - 1}{2-1}\\right) = 16(63) = 1008$。\n$$ W_{\\text{resize, del}} = 1008 - 6 = 1002 $$\n删除阶段总工作量：\n$$ W_{\\text{del}} = 1000 + W_{\\text{resize, del}} = 1000 + 1002 = 2002 $$\n\n**3. 总工作量**\n\n总工作量是两个阶段工作量的总和：\n$$ W_{\\text{total}} = W_{\\text{ins}} + W_{\\text{del}} = 2008 + 2002 = 4010 $$\n所执行的精确总工作量为 $4010$ 个单位。", "answer": "$$\n\\boxed{4010}\n$$", "id": "3266677"}, {"introduction": "一个固定的调整大小策略，即使带有滞后性，也未必能适应所有工作负载。例如，读密集型应用可能从较高的负载因子中受益，而写密集型应用则需要较低的负载因子以减少冲突。此高级练习将指导您构建一个能根据观察到的工作负载动态调整其目标的哈希表[@problem_id:3266666]。通过实现一个能够监控自身冲突率和读写比率的系统，您将学习如何设计出能够自我优化的数据结构，以在多变的环境中实现最佳性能。", "problem": "您必须实现一个完整、可运行的程序，模拟一个支持重哈希（rehashing）和调整大小（resizing）的自适应哈希表。该哈希表必须根据观察到的冲突率和工作负载的读写比动态调整其目标负载因子，并且必须为一组测试用例生成单一、可验证的数值输出。所有数学实体必须使用 LaTeX 格式指定。\n\n此任务的基础由以下广泛接受的定义和事实构成：\n- 一个使用独立链（separate chaining）的哈希表将一组键存储在一个桶（bucket）数组中，其中每个桶是一个容器，用于存放哈希到相同索引的键。哈希函数将一个键映射到表内的一个整数索引。\n- 哈希表的负载因子定义为 $\\alpha = \\frac{n}{m}$，其中 $n$ 是存储的键的数量，$m$ 是桶的数量。\n- 在独立链中，对于均匀分布的键，平均情况下的期望搜索时间与 $1 + \\alpha$ 成正比，而确切的性能还取决于各个桶之间的冲突分布。\n- 调整大小和重哈希是维持期望负载因子和减轻冲突的标准程序：调整大小会改变桶的数量 $m$，而重哈希则使用新的 $m$ 通过哈希函数重新分配所有键。\n\n您必须设计一个自适应机制，该机制根据固定大小窗口内的工作负载观察结果来更新目标负载因子。\n\n要求和精确规范：\n1. 哈希表设计：\n   - 使用独立链（列表数组）。\n   - 使用模哈希函数 $h(k, m) = k \\bmod m$。\n   - 对于插入新键 $k$ 的写操作，如果在插入前的瞬间，索引为 $h(k, m)$ 的桶非空，则计为一次冲突事件。如果键已存在，则写操作为更新（不插入），不计为冲突事件。\n   - 对于读取键 $k$ 的读操作，观察到的扫描长度是为在索引为 $h(k, m)$ 的桶中找到 $k$ 或确认其不存在所需的键比较次数。累加所有读操作的总扫描长度，并跟踪读操作的数量。\n\n2. 自适应目标负载因子：\n   - 哈希表维护一个目标负载因子 $\\alpha_{\\text{target}}$。\n   - 每经过一个包含 $W$ 次操作的窗口后，计算观察到的量：\n     - 观察到的读取比例 $r = \\frac{\\text{窗口内的读操作数}}{W}$。\n     - 新插入操作的观察冲突率 $c = \\begin{cases}\\frac{\\text{窗口内的冲突次数}}{\\text{窗口内的新插入次数}}  \\text{若新插入次数} > 0 \\\\ 0  \\text{其他情况。}\\end{cases}$\n   - 使用以下规则更新目标负载因子\n     $$\\alpha_{\\text{target}} \\leftarrow \\mathrm{clip}\\left(\\alpha_{\\text{base}} + k_w \\cdot (1 - r) - k_c \\cdot c, \\ \\alpha_{\\min}, \\ \\alpha_{\\max}\\right),$$\n     其中 $\\mathrm{clip}(x, a, b)$ 将 $x$ 限制在区间 $[a, b]$ 内。\n   - 调整大小规则：\n     - 如果 $\\frac{n}{m} > \\alpha_{\\text{target}}$，执行向上调整大小（resize-up）：设置 $m \\leftarrow 2m$ 并对所有键进行重哈希。\n     - 如果 $\\frac{n}{m}  \\frac{\\alpha_{\\text{target}}}{2}$ 且 $m > m_{\\min}$，执行向下调整大小（resize-down）：设置 $m \\leftarrow \\max\\left(m_{\\min}, \\left\\lfloor\\frac{m}{2}\\right\\rfloor\\right)$ 并对所有键进行重哈希。\n   - 在每个窗口结束时更新 $\\alpha_{\\text{target}}$ 后，立即应用向下调整大小的检查。\n   - 如果总操作数不是 $W$ 的倍数，则使用不完整的最后一个窗口和相同的公式对 $\\alpha_{\\text{target}}$ 进行最终更新。\n\n3. 工作负载生成：\n   - 使用确定性的线性同余生成器（LCG）生成伪随机数，参数如下：\n     $$M = 2^{31} - 1,\\quad A = 1103515245,\\quad C = 12345,$$\n     以及递推关系 $s \\leftarrow (A \\cdot s + C) \\bmod M$ 从一个种子 $s_0$ 生成序列 $s_1, s_2, \\dots$。对于任何生成的数 $s$，通过 $u = \\frac{s}{M}$ 获得一个均匀实数值 $u$。\n   - 每个测试用例的操作类型选择是通过将 $u$ 与指定的目标读取概率 $q$ 进行比较来确定的：\n     - 如果 $u  q$，则操作为读操作。\n     - 否则，操作为写操作。\n   - 用于写和读的键：\n     - 让用于生成键的 LCG 独立于用于生成操作类型的 LCG，并有其自己的种子。\n     - 对于写操作，键是使用特定于用例的规则生成的（在测试套件中描述）。\n     - 对于读操作，使用键 LCG 生成一个键。如果至少已插入一个键：\n       - 如果 $(\\text{键 LCG 值}) \\bmod 3 = 0$，则读取一个已存在的键，该键通过索引 $(\\text{键 LCG 值}) \\bmod n$ 从插入顺序中选择。\n       - 否则，读取原始的 LCG 键值（很可能未命中）。如果尚未插入任何键，则读取原始的 LCG 键值。\n\n4. 测试套件：\n   实现以下四个测试用例。对于每个用例，模拟所述的操作和自适应机制。模拟结束后，计算以下输出：\n   - 最终容量 $m$。\n   - 最终目标负载因子 $\\alpha_{\\text{target}}$，四舍五入到三位小数。\n   - 向上调整大小事件的数量（整数）。\n   - 向下调整大小事件的数量（整数）。\n   - 平均读取扫描长度，定义为 $\\frac{\\text{总读取比较次数}}{\\text{读取次数}}$，四舍五入到三位小数（如果没有读取操作，则使用 $0$）。\n\n   测试用例：\n   - 用例 1（一般行为）：\n     - 参数：$m_0 = 8$, $\\alpha_{\\text{base}} = 0.75$, $\\alpha_{\\min} = 0.5$, $\\alpha_{\\max} = 0.9$, $k_w = 0.2$, $k_c = 0.3$, $W = 20$, $m_{\\min} = 8$。\n     - 工作负载：$N = 120$ 次操作，目标读取概率 $q = 0.4$。\n     - 种子：操作类型 LCG 种子 $s_{\\text{op}} = 17$，键 LCG 种子 $s_{\\text{key}} = 101$。\n     - 写键规则：$k = s_{\\text{key}}$（原始 LCG 键输出）。\n   - 用例 2（读密集型工作负载，早期插入冲突率高）：\n     - 参数：$m_0 = 32$, $\\alpha_{\\text{base}} = 0.70$, $\\alpha_{\\min} = 0.4$, $\\alpha_{\\max} = 0.85$, $k_w = 0.25$, $k_c = 0.5$, $W = 10$, $m_{\\min} = 16$。\n     - 工作负载：$N = 140$ 次操作，目标读取概率 $q = 0.8$。\n     - 种子：操作类型 LCG 种子 $s_{\\text{op}} = 23$，键 LCG 种子 $s_{\\text{key}} = 202$。\n     - 写键规则：$k = 32 \\cdot i$，其中 $i$ 是从 $0$ 开始的第 $i$ 个写操作索引；这会引发早期聚集，因为 $h(k, m_0) = 0$。\n   - 用例 3（写密集型工作负载）：\n     - 参数：$m_0 = 16$, $\\alpha_{\\text{base}} = 0.80$, $\\alpha_{\\min} = 0.6$, $\\alpha_{\\max} = 0.95$, $k_w = 0.3$, $k_c = 0.2$, $W = 40$, $m_{\\min} = 16$。\n     - 工作负载：$N = 160$ 次操作，目标读取概率 $q = 0.1$。\n     - 种子：操作类型 LCG 种子 $s_{\\text{op}} = 19$，键 LCG 种子 $s_{\\text{key}} = 303$。\n     - 写键规则：$k = s_{\\text{key}}$（原始 LCG 键输出）。\n   - 用例 4（具有激进更新的边界行为）：\n     - 参数：$m_0 = 4$, $\\alpha_{\\text{base}} = 0.75$, $\\alpha_{\\min} = 0.5$, $\\alpha_{\\max} = 0.9$, $k_w = 0.1$, $k_c = 0.4$, $W = 1$, $m_{\\min} = 4$。\n     - 工作负载：$N = 30$ 次操作，目标读取概率 $q = 0.5$。\n     - 种子：操作类型 LCG 种子 $s_{\\text{op}} = 11$，键 LCG 种子 $s_{\\text{key}} = 404$。\n     - 写键规则：$k = i \\bmod 8$，其中 $i$ 是从 $0$ 开始的第 $i$ 个写操作索引；这会频繁地更新现有键。\n\n5. 预期输出格式：\n   - 您的程序应生成单行输出，其中包含一个每用例结果的列表，每个用例的结果都是一个包含上述顺序的五个数字的列表。\n   - 完整的输出必须是单行，不含多余的空白，并以字符串格式打印：\n     $$\\text{``[[m,\\ \\alpha_{\\text{target}},\\ \\text{up},\\ \\text{down},\\ \\text{avg}],[\\dots],\\dots]''}$$\n     使用不带空格的逗号。每个 $\\alpha_{\\text{target}}$ 和 $\\text{avg}$ 都必须四舍五入到三位小数。\n\n不涉及物理单位。不适用角度。百分比必须按规定以小数表示。程序必须是完全确定性的，仅使用上述过程，并且不得读取输入。", "solution": "用户提供的问题是有效的。它在科学上基于计算机科学的原理，特别是数据结构和算法。该问题是适定的（well-posed），为自适应哈希表的确定性模拟提供了一套完整且一致的规则。所有参数、初始条件和行为规则都得到了明确、客观的定义，从而能够得到唯一且可验证的解。\n\n该解决方案通过设计和模拟三个核心组件来实现：一个伪随机数生成器、一个自适应哈希表和一个主模拟控制器。\n\n### 1. 伪随机数生成\n实现了一个线性同余生成器（LCG），以提供确定性的伪随机数源，这对于可复现的工作负载生成至关重要。LCG 遵循指定的递推关系：\n$$s_{i+1} = (A \\cdot s_i + C) \\bmod M$$\n其中常数给定为 $M = 2^{31} - 1$, $A = 1103515245$, 和 $C = 12345$。生成器维护一个内部状态 $s_i$，每次调用时生成一个新的整数。通过对整数输出进行归一化，可以得到一个均匀的浮点数 $u \\in [0, 1)$，$u = \\frac{s_{i+1}}{M}$。使用了该 LCG 的两个独立实例：一个用于确定操作类型（读或写），另一个用于生成键。\n\n### 2. 哈希表数据结构\n哈希表使用独立链冲突解决策略实现。\n- **结构**：该表由一个包含 $m$ 个桶的数组组成，其中每个桶是一个存储键的列表。表的状态由其容量 $m$ 和存储的键数 $n$ 定义。\n- **哈希函数**：指定的模哈希函数 $h(k, m) = k \\bmod m$ 将整数键 $k$ 映射到一个桶索引。\n- **写操作**：当写入一个键 $k$ 时，实现首先在一个专用的集合中检查该键是否已存在，以实现 $O(1)$ 的平均时间查找。如果存在，该操作为更新，不进行任何更改。如果键是新的，它将被附加到索引为 $h(k, m)$ 的桶的列表中。当且仅当键是新的且在插入前桶不为空时，才会记录一次冲突。在新键插入后，表的键计数 $n$ 会增加。\n- **读操作**：要读取一个键 $k$，会对索引为 $h(k, m)$ 的桶进行线性扫描。“扫描长度”是执行的键比较次数，如果找到键，则等于键在桶列表中的位置（从1开始计数）；如果未找到，则等于桶中项目的总数。\n- **重哈希**：当表的容量 $m$ 发生变化时，会执行一次`rehash`操作。这包括创建一个具有新容量的新桶数组，并根据更新了 $m$ 的哈希函数将所有现有键重新插入到这个新数组中。\n\n### 3. 自适应控制与仿真逻辑\n问题的核心在于通过调整其目标负载因子 $\\alpha_{\\text{target}}$ 来控制哈希表性能的自适应机制。\n- **仿真循环**：仿真总共进行 $N$ 次操作。对于每次操作，使用操作类型的 LCG 根据给定的概率 $q$ 选择读操作或写操作。这些操作的键是使用键 LCG 和特定于用例的规则生成的。\n- **基于窗口的自适应**：仿真被划分为包含 $W$ 次操作的窗口。在每个窗口结束时（或者如果最后一个窗口不完整，则在整个仿真结束时），计算两个指标：\n    1.  观察到的读取比例，$r = \\frac{\\text{窗口内的读操作数}}{W}$。\n    2.  观察到的新插入冲突率，$c = \\frac{\\text{窗口内的冲突次数}}{\\text{窗口内的新插入次数}}$。如果没有新插入，则使用 $c=0$ 的值。\n- **目标负载因子更新**：使用这些指标根据以下规则更新目标负载因子 $\\alpha_{\\text{target}}$：\n    $$\\alpha_{\\text{target}} \\leftarrow \\mathrm{clip}\\left(\\alpha_{\\text{base}} + k_w \\cdot (1 - r) - k_c \\cdot c, \\ \\alpha_{\\min}, \\ \\alpha_{\\max}\\right)$$\n    其中 $\\mathrm{clip}(x, a, b)$ 将值 $x$ 约束在闭区间 $[a, b]$ 内。\n- **调整大小逻辑**：表的大小 $m$ 根据当前负载因子 $\\alpha = \\frac{n}{m}$ 和动态的 $\\alpha_{\\text{target}}$ 进行调整。\n    - **向上调整大小（增长）**：在每次成功插入新键后立即检查此项。如果 $\\alpha > \\alpha_{\\text{target}}$，则表容量加倍（$m \\leftarrow 2m$）并对所有键进行重哈希。\n    - **向下调整大小（收缩）**：仅在窗口结束时，在 $\\alpha_{\\text{target}}$ 更新后立即检查此项。如果 $\\alpha  \\frac{\\alpha_{\\text{target}}}{2}$ 且当前容量 $m$ 大于指定的最小值 $m_{\\min}$，则容量减半，直至达到最小限制：$m \\leftarrow \\max\\left(m_{\\min}, \\left\\lfloor\\frac{m}{2}\\right\\rfloor\\right)$。然后对键进行重哈希。\n\n### 4. 输出生成\n一个控制器函数为提供的四个测试用例中的每一个执行仿真。每次仿真完成后，它会计算所需的输出指标：最终容量 $m$、最终的 $\\alpha_{\\text{target}}$、向上和向下调整大小事件的总数，以及平均读取扫描长度，计算公式为 $\\frac{\\text{总读取比较次数}}{\\text{读取次数}}$。浮点数结果 $\\alpha_{\\text{target}}$ 和平均扫描长度按要求四舍五入到三位小数。然后将所有测试用例的最终结果格式化为单个字符串。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport math\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n\n    class LCG:\n        \"\"\"\n        A deterministic Linear Congruential Generator.\n        \"\"\"\n        def __init__(self, seed):\n            self.state = np.int64(seed)\n            self.M = np.int64(2**31 - 1)\n            self.A = np.int64(1103515245)\n            self.C = np.int64(12345)\n\n        def next(self):\n            \"\"\"Generates the next pseudo-random integer.\"\"\"\n            self.state = (self.A * self.state + self.C) % self.M\n            return int(self.state)\n\n        def next_float(self):\n            \"\"\"Generates the next pseudo-random float in [0, 1).\"\"\"\n            return self.next() / float(self.M)\n\n    class AdaptiveHashTable:\n        \"\"\"\n        A hash table with separate chaining that supports resizing and rehashing.\n        \"\"\"\n        def __init__(self, m0):\n            self.m = m0\n            self.n = 0\n            self.buckets = [[] for _ in range(self.m)]\n            self.inserted_keys = []\n            self.key_set = set()\n\n        def _hash(self, key):\n            return key % self.m\n\n        def write(self, key):\n            \"\"\"\n            Inserts a key if new, and reports collision status.\n            Returns: (is_collision, is_new_insertion)\n            \"\"\"\n            if key in self.key_set:\n                return False, False\n\n            idx = self._hash(key)\n            bucket = self.buckets[idx]\n            \n            is_collision = len(bucket) > 0\n            \n            bucket.append(key)\n            self.key_set.add(key)\n            self.inserted_keys.append(key)\n            self.n += 1\n            \n            return is_collision, True\n\n        def read(self, key):\n            \"\"\"\n            Finds a key and returns the scan length (number of comparisons).\n            \"\"\"\n            idx = self._hash(key)\n            bucket = self.buckets[idx]\n            scan_length = 0\n            for item in bucket:\n                scan_length += 1\n                if item == key:\n                    break\n            return scan_length\n\n        def rehash(self, new_m):\n            \"\"\"\n            Resizes the table to a new capacity and rehashes all keys.\n            \"\"\"\n            self.m = new_m\n            new_buckets = [[] for _ in range(self.m)]\n            for key in self.inserted_keys:\n                idx = self._hash(key)\n                new_buckets[idx].append(key)\n            self.buckets = new_buckets\n\n    def run_simulation(params):\n        \"\"\"\n        Executes one full simulation for a given set of parameters.\n        \"\"\"\n        # Unpack parameters\n        m0, alpha_base, alpha_min, alpha_max = params['m0'], params['alpha_base'], params['alpha_min'], params['alpha_max']\n        k_w, k_c, W, m_min = params['k_w'], params['k_c'], params['W'], params['m_min']\n        N, q, s_op, s_key = params['N'], params['q'], params['s_op'], params['s_key']\n        write_key_rule = params['write_key_rule']\n\n        # Initialize simulation components\n        table = AdaptiveHashTable(m0)\n        op_lcg = LCG(s_op)\n        key_lcg = LCG(s_key)\n\n        # Initialize state variables\n        alpha_target = alpha_base\n        resize_up_events = 0\n        resize_down_events = 0\n        total_read_comparisons = 0\n        num_reads = 0\n        write_op_count = 0\n\n        # Window-specific state\n        window_ops = 0\n        window_reads = 0\n        window_new_insertions = 0\n        window_collisions = 0\n\n        for op_idx in range(N):\n            window_ops += 1\n            \n            is_read_op = op_lcg.next_float()  q\n\n            if is_read_op:\n                num_reads += 1\n                window_reads += 1\n                \n                key_lcg_val = key_lcg.next()\n                if table.n > 0 and key_lcg_val % 3 == 0:\n                    existing_key_idx = key_lcg_val % table.n\n                    key_to_read = table.inserted_keys[existing_key_idx]\n                else:\n                    key_to_read = key_lcg_val\n\n                scan_length = table.read(key_to_read)\n                total_read_comparisons += scan_length\n\n            else:  # Write operation\n                if write_key_rule == 'raw_lcg':\n                    key_to_write = key_lcg.next()\n                elif write_key_rule == 'clustered':\n                    key_to_write = 32 * write_op_count\n                else:  # 'modulo'\n                    key_to_write = write_op_count % 8\n                \n                write_op_count += 1\n                \n                was_collision, was_new_insertion = table.write(key_to_write)\n                \n                if was_new_insertion:\n                    window_new_insertions += 1\n                    if was_collision:\n                        window_collisions += 1\n\n                    current_load_factor = table.n / table.m if table.m > 0 else 0\n                    if current_load_factor > alpha_target:\n                        table.rehash(2 * table.m)\n                        resize_up_events += 1\n\n            if window_ops == W or (op_idx == N - 1):\n                r = window_reads / window_ops if window_ops > 0 else 0\n                c = window_collisions / window_new_insertions if window_new_insertions > 0 else 0\n                \n                alpha_target_unclipped = alpha_base + k_w * (1 - r) - k_c * c\n                alpha_target = np.clip(alpha_target_unclipped, alpha_min, alpha_max)\n\n                current_load_factor = table.n / table.m if table.m > 0 else 0\n                if current_load_factor  alpha_target / 2 and table.m > m_min:\n                    new_m = max(m_min, math.floor(table.m / 2))\n                    if new_m  table.m:\n                        table.rehash(new_m)\n                        resize_down_events += 1\n                \n                window_ops = 0\n                window_reads = 0\n                window_new_insertions = 0\n                window_collisions = 0\n            \n        final_m = table.m\n        final_alpha_target = round(alpha_target, 3)\n        avg_scan_len = round(total_read_comparisons / num_reads, 3) if num_reads > 0 else 0.0\n\n        return [final_m, final_alpha_target, resize_up_events, resize_down_events, avg_scan_len]\n\n    test_cases = [\n        {'m0': 8, 'alpha_base': 0.75, 'alpha_min': 0.5, 'alpha_max': 0.9, 'k_w': 0.2, 'k_c': 0.3, 'W': 20, 'm_min': 8, 'N': 120, 'q': 0.4, 's_op': 17, 's_key': 101, 'write_key_rule': 'raw_lcg'},\n        {'m0': 32, 'alpha_base': 0.70, 'alpha_min': 0.4, 'alpha_max': 0.85, 'k_w': 0.25, 'k_c': 0.5, 'W': 10, 'm_min': 16, 'N': 140, 'q': 0.8, 's_op': 23, 's_key': 202, 'write_key_rule': 'clustered'},\n        {'m0': 16, 'alpha_base': 0.80, 'alpha_min': 0.6, 'alpha_max': 0.95, 'k_w': 0.3, 'k_c': 0.2, 'W': 40, 'm_min': 16, 'N': 160, 'q': 0.1, 's_op': 19, 's_key': 303, 'write_key_rule': 'raw_lcg'},\n        {'m0': 4, 'alpha_base': 0.75, 'alpha_min': 0.5, 'alpha_max': 0.9, 'k_w': 0.1, 'k_c': 0.4, 'W': 1, 'm_min': 4, 'N': 30, 'q': 0.5, 's_op': 11, 's_key': 404, 'write_key_rule': 'modulo'}\n    ]\n\n    results = [run_simulation(case) for case in test_cases]\n    \n    # Format the final output string as per requirements: [[m,alpha,up,down,avg],[...],...]\n    output_str = \"[\" + \",\".join([f\"[{r[0]},{r[1]},{r[2]},{r[3]},{r[4]}]\" for r in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3266666"}]}