{"hands_on_practices": [{"introduction": "理论学习之后，最好的检验方式是亲手实践。这项练习将引导你从零开始构建一个完整的Aho-Corasick自动机。你将实现其所有核心组件：Trie树的构建、基于广度优先搜索的失败指针计算，以及输出函数的正确传播。通过这个练习，你将把抽象的理论转化为能够解决实际多模式匹配问题的代码，为后续更复杂的应用打下坚实的基础。[@problem_id:3204919]", "problem": "给定一个有限字母表上的一组有限字符串和一个较长的文本。目标是设计并实现一个程序，该程序构建 Aho–Corasick 自动机（AC 自动机），并修改其输出行为，以便在从左到右逐个符号扫描文本时，为每个模式串维护一个迄今为止找到的总出现次数的动态计数。在处理完文本前缀后的指定检查点，程序必须输出与输入模式串顺序对齐的当前计数向量。\n\n请从以下正式且广泛使用的基础开始：\n- 一个有限字符串集合的 trie（字典树）的定义，其中每个节点对应至少一个字符串的唯一前缀，边由字母表中的单个符号标记。\n- 为 trie 构建用于多模式匹配的有限状态自动机的失败函数：对于每个节点，失败链接指向该节点字符串标签的最长真后缀，该后缀同时也是至少一个模式串的前缀。\n- 将节点映射到在该节点结束的模式串索引集合的输出函数。\n- 用于在线性时间内（与模式串总长度成正比）计算失败链接的标准广度优先搜索（BFS）过程。\n\n您的程序必须：\n- 根据给定模式串集合按其输入顺序构建 trie。设模式串数量为 $m \\ge 1$，所有模式串的总长度为 $L = \\sum_{i=1}^{m} |P_i|$，其中 $P_i$ 表示第 $i$ 个模式串，$|\\cdot|$ 表示字符串长度。假设每个模式串都是非空的。\n- 通过按广度优先顺序处理 trie 来计算失败链接。对于每个节点，通过包含其失败链接节点的输出集来扩充其输出集，以确保在自动机进入一个节点的同时报告后缀匹配。\n- 从左到右处理长度为 $n \\ge 0$ 的文本 $T$。读取第 $k$ 个字符后（即前缀长度为 $k$），对于在当前自动机状态的输出集中结束的每个模式串 $P_i$，将动态计数向量 $C \\in \\mathbb{N}^m$ 中的 $C_i$ 增加 1。必须对重叠出现进行计数，并且多个模式串可能在同一位置匹配。\n- 在指定的检查点（每个检查点等于某个 $k$，其中 $1 \\le k \\le n$），以原始模式串顺序记录当前 $C$ 的快照，形式为一个包含 $m$ 个非负整数的列表。\n\n输入不是从标准输入读取。相反，您的程序必须在内部运行以下测试套件并汇总结果。\n\n测试套件：\n- 测试用例 $1$：\n  - 模式串 $P = [\\text{\"a\"}, \\text{\"ab\"}, \\text{\"bab\"}, \\text{\"bc\"}, \\text{\"bca\"}, \\text{\"c\"}, \\text{\"caa\"}]$。\n  - 文本 $T = \\text{\"abccab\"}$，长度 $n = 6$。\n  - 检查点位于前缀长度 $[1, 3, 6]$ 处。\n  - 此用例的结果是在这些检查点处的快照列表，每个快照是长度为 $m$ 的计数列表 $C$。\n- 测试用例 $2$：\n  - 模式串 $P = [\\text{\"aa\"}, \\text{\"aaa\"}]$。\n  - 文本 $T = \\text{\"aaaaa\"}$，长度 $n = 5$。\n  - 检查点 $[1, 2, 3, 4, 5]$。\n- 测试用例 $3$：\n  - 模式串 $P = [\\text{\"he\"}, \\text{\"she\"}, \\text{\"his\"}, \\text{\"hers\"}]$。\n  - 文本 $T = \\text{\"ushers\"}$，长度 $n = 6$。\n  - 单个检查点 $[6]$。\n- 测试用例 $4$：\n  - 模式串 $P = [\\text{\"xyz\"}, \\text{\"q\"}]$。\n  - 文本 $T = \\text{\"aaaa\"}$，长度 $n = 4$。\n  - 单个检查点 $[4]$。\n- 测试用例 $5$：\n  - 模式串 $P = [\\text{\"aba\"}, \\text{\"ba\"}]$。\n  - 文本 $T = \\text{\"ababa\"}$，长度 $n = 5$。\n  - 检查点 $[2, 5]$。\n\n您的程序必须输出单行内容，其中包含测试套件的聚合结果，形式为单个列表，其元素是按测试用例顺序排列的每个测试用例的结果。每个测试用例的结果是一个快照列表，每个快照是按该测试用例的输入模式串顺序排列的整数列表。要求的最终输出格式是无空白字符的单行，仅使用方括号和逗号表示嵌套列表。具体来说，您的程序应打印形如 $[\\text{R}_1,\\text{R}_2,\\dots,\\text{R}_t]$ 的单行，其中 $\\text{R}_j$ 是测试用例 $j$ 的嵌套列表结果，$t$ 是测试用例的数量。\n\n答案纯粹是整数列表；不涉及物理单位或角度。请确保您的实现能正确处理自动机内的重叠匹配和通过后缀链接的输出，并确保其对每个测试用例的运行时间与 $|T| + L$ 成线性关系。", "solution": "用户提供了一个来自数据结构和算法领域的明确定义的计算问题，要求实现用于多模式字符串匹配的 Aho-Corasick 自动机。问题陈述的有效性验证如下：\n\n-   **科学或事实的可靠性**：该问题基于有限自动机和字符串算法的既定理论。Aho-Corasick 自动机是一个标准的、可靠的计算机科学模型。问题陈述准确地描述了其组成部分和构造方法（trie、失败链接、输出函数）。不存在科学或事实错误。\n-   **适定性**：该问题是适定的。它提供了具体的输入（模式串、文本、检查点），并要求一个清晰、确定性的输出（在指定时间的动态计数向量）。计数的规则，包括处理重叠匹配和后缀匹配（通过失败链接），都有明确定义，确保存在唯一且有意义的解。\n-   **客观性**：问题以正式、客观的语言陈述。所有输入和预期输出都是定量的，没有歧义或主观解释的余地。\n-   **完整性和一致性**：该问题为每个测试用例提供了所有必要的信息——模式串、文本和检查点位置。对算法构造和行为的要求在内部是一致且完整的。\n-   **可行性**：所提供测试用例的规模很小，使得该问题在典型的时限内计算上是可行的。所要求的线性时间复杂度是 Aho-Corasick 算法已知的最优性能，证实了该问题的理论基础。\n\n该问题被认为是有效的，因为它满足了一个正式、可解的科学问题的所有标准。以下解决方案按规定实现了 Aho-Corasick 算法。\n\n### 算法设计\n\n解决方案分为两个主要阶段：自动机构建和文本处理。\n\n1.  **自动机构建**：\n    -   **Trie 构建**：首先，根据输入的模式串集合构建一个 trie（前缀树）。trie 中的每个节点代表一个或多个模式串的唯一前缀。根节点代表空字符串。每条边都用一个字符标记。对应于模式串 $P_i$ 末尾的节点在其 `output` 集合中存储索引 $i$。\n        -   我们将自动机表示为一个节点列表，其中每个节点是一个字典，包含其 `transitions`（从字符到子节点索引的映射）、一个 `output` 列表（模式串索引）和一个 `failure_link`（另一节点的索引）。\n        -   通过遍历每个模式串来构建 trie，对每个字符，从根开始遍历，并根据需要添加新节点。\n\n    -   **失败链接和输出传播**：trie 构建完成后，计算失败链接。对于任何对应于字符串 $w$ 的状态 $s$，其失败链接指向对应于 $w$ 的最长真后缀的状态，该后缀也必须是集合中某个模式串的前缀。\n        -   这些链接通过从深度为 1 的节点开始的广度优先搜索（BFS）来高效计算。对于从其父节点 $u$ 通过字符 $c$ 到达的节点 $v$，我们通过跟随 $u$ 的失败链接到一个状态 $f$ 来找到它的失败链接，并检查 $f$ 是否有对 $c$ 的转移。如果没有，我们用 $f$ 的失败链接重复此过程，直到找到这样的转移或到达根节点。\n        -   根据问题要求，一个关键步骤是扩充输出集。节点 $v$ 的输出集被扩展，以包含其失败链接指向的节点的所有输出。这确保了如果我们匹配像 `\"she\"` 这样的字符串，我们也会报告其后缀 `\"he\"` 的匹配（如果 `\"he\"` 在模式串集合中）。这种传播也在 BFS 期间完成。\n\n2.  **文本处理和计数**：\n    -   输入文本 $T$ 被逐个字符处理。自动机维护一个 `current_state`，初始为根节点。\n    -   对于文本中的每个字符 $c$，自动机尝试从 `current_state` 进行转移。如果存在对 $c$ 的转移，则执行该转移。如果不存在，自动机跟随 `current_state` 的失败链接并重试转移。重复此过程，直到找到转移或到达根状态。如果到达根节点且没有对 $c$ 的转移，则 `current_state` 保持为根。\n    -   每次转移后，`current_state` 代表以文本当前位置结尾的、同时也是某个模式串前缀的最长字符串。\n    -   这个 `current_state` 的 `output` 集合包含所有在此位置结束的模式串的索引。对于 `output` 集合中的每个模式串索引，计数向量 $C$ 中的相应条目会递增。\n    -   在每个指定的检查点（对应于到目前为止已处理的字符数），记录当前 `counts` 向量的快照。\n\n这种设计保证了所有出现（包括重叠的和通过后缀找到的）都被正确计数，并且总时间复杂度与模式串总长度和文本长度之和呈线性关系，即 $O(L+n)$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\ndef solve():\n    \"\"\"\n    Main function to run the Aho-Corasick algorithm on a suite of test cases.\n    It builds the automaton, processes the text, and collects results\n    as per the problem specification.\n    \"\"\"\n    \n    # Helper function to format the final output list without spaces.\n    def format_list_no_spaces(data):\n        if isinstance(data, list):\n            return f\"[{','.join(format_list_no_spaces(item) for item in data)}]\"\n        else:\n            return str(data)\n\n    def build_automaton(patterns):\n        \"\"\"\n        Builds the Aho-Corasick automaton (trie, failure links, and output propagation).\n        \"\"\"\n        # The automaton is a list of nodes.\n        # Each node is a dict: {'transitions': {}, 'output': [], 'failure_link': 0}\n        nodes = [{'transitions': {}, 'output': [], 'failure_link': 0}]\n        \n        # 1. Build the basic trie structure.\n        for i, pattern in enumerate(patterns):\n            node_idx = 0\n            for char in pattern:\n                if char not in nodes[node_idx]['transitions']:\n                    new_node_idx = len(nodes)\n                    nodes[node_idx]['transitions'][char] = new_node_idx\n                    nodes.append({'transitions': {}, 'output': [], 'failure_link': 0})\n                node_idx = nodes[node_idx]['transitions'][char]\n            nodes[node_idx]['output'].append(i)\n\n        # 2. Compute failure links and propagate outputs using BFS.\n        queue = collections.deque()\n        # Start BFS with all nodes at depth 1. Their failure links point to the root (0).\n        for node_idx in nodes[0]['transitions'].values():\n            queue.append(node_idx)\n            # The failure link is already 0 by default, so no explicit set needed here.\n\n        while queue:\n            current_idx = queue.popleft()\n            \n            for char, next_idx in nodes[current_idx]['transitions'].items():\n                queue.append(next_idx)\n                \n                # Find failure link for next_idx.\n                fail_idx = nodes[current_idx]['failure_link']\n                while char not in nodes[fail_idx]['transitions'] and fail_idx != 0:\n                    fail_idx = nodes[fail_idx]['failure_link']\n                \n                if char in nodes[fail_idx]['transitions']:\n                    nodes[next_idx]['failure_link'] = nodes[fail_idx]['transitions'][char]\n                else:\n                    # If we reach the root and still no transition, failure link is root.\n                    nodes[next_idx]['failure_link'] = 0\n                \n                # Propagate output from the failure node.\n                fail_output_idx = nodes[next_idx]['failure_link']\n                nodes[next_idx]['output'].extend(nodes[fail_output_idx]['output'])\n        \n        return nodes\n\n    def run_search(automaton, text, num_patterns, checkpoints):\n        \"\"\"\n        Processes the text using the automaton and records counts at checkpoints.\n        \"\"\"\n        checkpoints_set = set(checkpoints)\n        snapshots = []\n        counts = np.zeros(num_patterns, dtype=int)\n        current_state_idx = 0\n\n        for k, char in enumerate(text, 1):\n            # Follow failure links until a transition is found or we are at the root.\n            while char not in automaton[current_state_idx]['transitions'] and current_state_idx != 0:\n                current_state_idx = automaton[current_state_idx]['failure_link']\n            \n            # If a transition for the character exists, take it. Otherwise, stay at root.\n            current_state_idx = automaton[current_state_idx]['transitions'].get(char, 0)\n            \n            # Collect all outputs from the current state.\n            if automaton[current_state_idx]['output']:\n                for pattern_idx in automaton[current_state_idx]['output']:\n                    counts[pattern_idx] += 1\n            \n            # Record a snapshot if the current position is a checkpoint.\n            if k in checkpoints_set:\n                snapshots.append(counts.tolist())\n        \n        return snapshots\n\n    # The test suite provided in the problem statement.\n    test_cases = [\n        (\n            [\"a\", \"ab\", \"bab\", \"bc\", \"bca\", \"c\", \"caa\"],\n            \"abccab\",\n            [1, 3, 6]\n        ),\n        (\n            [\"aa\", \"aaa\"],\n            \"aaaaa\",\n            [1, 2, 3, 4, 5]\n        ),\n        (\n            [\"he\", \"she\", \"his\", \"hers\"],\n            \"ushers\",\n            [6]\n        ),\n        (\n            [\"xyz\", \"q\"],\n            \"aaaa\",\n            [4]\n        ),\n        (\n            [\"aba\", \"ba\"],\n            \"ababa\",\n            [2, 5]\n        )\n    ]\n\n    all_results = []\n    for patterns, text, checkpoints in test_cases:\n        num_patterns = len(patterns)\n        automaton = build_automaton(patterns)\n        snapshots = run_search(automaton, text, num_patterns, checkpoints)\n        all_results.append(snapshots)\n    \n    # Final print statement in the exact required format.\n    print(format_list_no_spaces(all_results))\n\nsolve()\n\n```", "id": "3204919"}, {"introduction": "在实际应用中，我们常常需要处理非标准化的输入，例如不区分大小写的文本。这项练习将教你一个优雅且高效的技巧：规范化处理。你将学习如何通过将模式串和文本都转换为一种“标准”形式（例如全小写），来利用AC自动机解决看似更复杂的问题，而无需修改其核心结构。这个练习不仅能加深你对AC自动机的理解，还能让你掌握一种通用的算法设计思想。[@problem_id:3205013]", "problem": "给定一个有限字母表上的有限模式集和一个文本。任务是执行大小写不敏感语义下的多模式精确匹配，而无需在底层trie树中显式存储字母的每种大小写变体。形式上，设字母表为 $\\Sigma$，模式集为 $P = \\{p_1, p_2, \\dots, p_k\\}$，其中每个 $p_i \\in \\Sigma^{*}$，文本为 $T \\in \\Sigma^{*}$。考虑一个映射 $\\phi : \\Sigma \\rightarrow \\Sigma$，该映射在标准7位美国信息交换标准代码（ASCII）上定义如下：对于任意字符 $c \\in \\Sigma$，如果 $c$ 是一个大写英文字母，则 $\\phi(c)$ 是其对应的小写形式，否则 $\\phi(c) = c$。通过同态性将 $\\phi$ 扩展到字符串，即对于任意字符串 $s = c_1 c_2 \\cdots c_n$，定义 $\\phi(s) = \\phi(c_1)\\phi(c_2)\\cdots\\phi(c_n)$。在大小写不敏感语义下，当且仅当 $\\phi(p)$ 在 $\\phi(T)$ 的位置 $i$ 处出现时，我们称模式 $p$ 在 $T$ 的位置 $i$ 处出现。一次出现会为该模式的总计数贡献1。\n\n在您的推理和设计中需要使用的基本基础和约束：\n- 字符串是 $\\Sigma$ 上的序列，通过符号的相等性进行比较。\n- trie树是一种有根树，以 $\\Sigma$ 的符号为键，其中从一个节点出发的每条边都由一个符号标记，并且从根到节点的标签序列是唯一的。\n- Aho–Corasick自动机是通过为trie树增加失效链接而得到的。失效链接通过“既是trie树中的前缀，又是最长的真后缀”来定义。此外，每个节点还有一个输出函数，列出在该节点结束的模式。当字母表固定时，它支持同步模式匹配，时间复杂度与文本长度加上匹配数呈线性关系。\n- 您不得在trie树中显式存储同一字母的所有大小写变体。相反，您应根据上述基本原理和映射 $\\phi$ 进行推理，构建一个基于简化的有效字母表的自动机，同时仍然能报告 $P$ 中所有原始模式的出现次数。\n\n您的任务：\n- 设计并实现一个程序，构建一个能够报告在由 $\\phi$ 导出的大小写不敏感语义下，$T$ 中模式出现的总次数的自动机，且不在trie树中复制大小写变体的边。该自动机必须构建在由 $\\phi$ 导出的规范字母表上，并且输出函数必须考虑到 $P$ 中多个不同的原始模式在 $\\phi$ 映射下可能规范化为同一个字符串这一事实。\n- 正确性要求：在大小写不敏感匹配下，$T$ 中任何 $p_i \\in P$ 的每次出现都必须被计数，包括重叠部分。如果两个不同的模式 $p_i$ 和 $p_j$ 满足 $\\phi(p_i) = \\phi(p_j)$，那么 $\\phi(p_i)$ 在 $\\phi(T)$ 中的单次出现将为 $p_i$ 贡献1次计数，为 $p_j$ 贡献1次计数，即总共计数两次。\n\n复杂度目标：\n- 确保构建自动机的时间复杂度相对于所构建的trie树的大小，在 $\\sum_{i=1}^{k} |p_i|$ 上是渐进线性的，并且扫描文本的时间复杂度在 $|T|$ 加上匹配数上是线性的。避免任何将同一字母的大小写变体都插入trie树中的方法。\n\n测试套件：\n实现您的程序，为以下每个测试用例计算总匹配数。每个测试用例是一个序对 $(P, T)$，其中 $P$ 是模式列表，$T$ 是文本字符串。\n- 测试用例 1：$P = [$\"he\", \"she\", \"his\", \"hers\"$]$，$T =$ \"aHiShErS\"。\n- 测试用例 2：$P = [$\"Ab\", \"aB\", \"AB\", \"ab\"$]$，$T =$ \"xxAbYYaBzz\"。\n- 测试用例 3：$P = [$\"a\", \"aa\"$]$，$T =$ \"AaA\"。\n- 测试用例 4：$P = [$\"C++\", \"c+\"$]$，$T =$ \"C++C+\"。\n- 测试用例 5：$P = [$\"Test\"$]$，$T =$ \"\" (空字符串)。\n\n输出规范：\n- 对于每个测试用例，计算一个等于 $P$ 中所有模式总匹配数的整数，计入重叠部分，并且即使多个模式规范化为相同的 $\\phi$ 像，也要对每个模式单独计数。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$\"[r_1,r_2,\\dots]\"$），结果顺序与测试用例1到5的顺序一致。\n\n此问题不涉及物理单位、角度或百分比。确保解决方案是从提供的基本定义和事实推导得出，而不是来自预先给出的快捷公式。", "solution": "该问题要求使用Aho-Corasick自动机执行大小写不敏感的多模式匹配，并带有一个特定约束，即底层trie树不得显式存储大小写变体。这是一个经典的算法任务，涉及将标准算法调整以适应字母表上的特定等价关系。\n\n### 基于原则的设计\n\n解决方案建立在规范化原则之上。问题定义了一个映射 $\\phi$，它将大写英文字母转换为其对应的小写形式，并保持其他字符不变。该映射在字母表 $\\Sigma$ 上导出了一个等价关系，其中两个字符 $c_1$ 和 $c_2$ 在 $\\phi(c_1) = \\phi(c_2)$ 时是等价的。此关系可扩展到字符串：当 $\\phi(s_1) = \\phi(s_2)$ 时，两个字符串 $s_1$ 和 $s_2$ 是等价的。匹配规则——当 $\\phi(p)$ 在 $\\phi(T)$ 中出现时，模式 $p$ 在文本 $T$ 中出现——利用了这种等价性。\n\n我们可以不在原始字母表 $\\Sigma$ 上执行搜索，而是完全在规范字母表内工作，从而简化问题。规范字母表是 $\\Sigma$ 在 $\\phi$ 映射下的像（即小写字母和非字母字符）。Aho-Corasick自动机将使用这些规范字符来构建和操作。\n\n设计分为三个主要阶段：\n1.  **自动机构建（构建阶段）**：此阶段根据模式集 $P$ 构建大小写不敏感的Aho-Corasick自动机。\n2.  **文本处理（搜索阶段）**：此阶段使用构建好的自动机在文本 $T$ 中查找所有模式的出现。\n3.  **正确计数**：一个关键细节是确保每次匹配都根据问题的规范被正确计数，特别是当多个原始模式规范化为同一个字符串时。\n\n#### 1. 自动机构建\n\n自动机构建在由*规范化*模式 $\\{\\phi(p) \\mid p \\in P\\}$ 构成的trie树之上。\n\n**Trie树构建**：我们遍历 $P$ 中的每个模式 $p$，计算其规范化形式 $s = \\phi(p)$，并将 $s$ 插入trie树中。trie树的节点代表规范化模式的前缀。每条边都用规范字母表中的一个字符标记。\n\n**输出函数**：问题规定，如果两个不同的模式 $p_i$ 和 $p_j$ 规范化为同一个字符串（即 $\\phi(p_i) = \\phi(p_j)$），则该规范化字符串的单次匹配应对两者都计数。为处理此问题，我们为trie树中的每个节点关联一个 `direct_output_count`。对于输入集 $P$ 中的每个模式 $p_i$，在沿着 $\\phi(p_i)$ 的路径遍历trie树到达节点 $u$ 后，我们将 `direct_output_count[u]` 增加1。这样，`direct_output_count[u]` 就存储了规范化为节点 $u$ 所代表的精确字符串的原始模式的数量。\n\n**失效链接**：trie树构建完毕后，我们添加失效链接来创建完整的自动机。从节点 $u$（代表字符串 $s$）出发的失效链接指向代表 $s$ 的最长真后缀（该后缀同时也是trie树中的一个前缀）的节点 $v$。这些链接对于线性时间匹配至关重要，因为它们允许自动机在字符不匹配时平滑地转换状态，而无需从文本的开头重新开始搜索。失效链接通过从根节点的子节点开始的广度优先搜索（BFS）来计算。对于一个由父节点 $u$ 通过字符 $c$ 到达的节点 $v$，其失效链接可以通过跟随其父节点的失效链接 `fail[u]` 并尝试在字符 $c$ 上进行转换来找到。此过程重复进行，直到找到一个有效的转换或到达根节点。\n\n**输出传播**：一个模式的匹配也意味着其任何同时也是模式的后缀的匹配。例如，匹配“she”也意味着我们匹配了“he”。为了高效地处理这一点，我们为每个节点计算一个 `aggregated_output_count`。该值是节点自身的 `direct_output_count` 与其失效节点的 `aggregated_output_count` 之和。这可以在计算失效链接的BFS过程中完成，因为节点的失效链接总是指向一个更浅深度的节点，而该节点已经被处理过。递推关系为：\n$$\n\\text{aggregated\\_output\\_count}[u] = \\text{direct\\_output\\_count}[u] + \\text{aggregated\\_output\\_count}[\\text{fail}[u]]\n$$\n这确保了当自动机到达状态 $u$ 时，我们可以通过简单查找 `aggregated_output_count[u]` 在 $O(1)$ 时间内找到在当前文本位置结束的模式总数。\n\n#### 2. 文本处理\n\n搜索阶段涉及将*规范化*后的文本 $\\phi(T)$ 一次一个字符地输入自动机。\n\n**状态转换**：从根节点（状态0）开始，对于 $\\phi(T)$ 中的每个字符 $c$，自动机转换到一个新状态。如果当前状态有一个对应字符 $c$ 的子节点，则转移到该子节点。如果没有，则沿着失效链接回溯，直到找到一个对字符 $c$ 有转换的状态，或者到达根节点。\n\n**计数匹配**：每次转换到状态 $u$ 后，我们将 `aggregated_output_count[u]` 加到一个运行总和中。这会正确地计算出在文本当前位置结束的所有模式（包括重叠的和作为后缀的模式）。\n\n#### 3. 复杂度分析\n\n设 $L = \\sum_{p \\in P} |p|$ 为所有模式的总长度， $N = |T|$ 为文本的长度。规范字母表的大小是一个固定常数（ASCII）。\n\n-   **模式规范化**：$O(L)$。\n-   **Trie树构建**：每个规范化模式的每个字符都被处理一次。这需要 $O(L)$ 时间。trie树中的节点数最多为 $L+1$。\n-   **失效链接和输出计算**：基于BFS的计算需要与trie树大小成摊销线性关系的时间，即 $O(L)$。\n-   **总构建时间**：$O(L)$。\n-   **文本规范化**：$O(N)$。\n-   **搜索时间**：对于规范化文本中的 $N$ 个字符中的每一个，自动机执行一次状态转换。失效链接遍历的总次数在整个搜索过程中被摊销，从而使得总体搜索时间为 $O(N)$。\n-   **总体复杂度**：总时间复杂度为 $O(L+N)$，满足问题的目标。\n\n该设计正确地实现了大小写不敏感匹配，而没有在trie树中显式表示大小写变体，遵守了所有约束并提供了一个高效的解决方案。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the multiple-pattern matching problem for the given test cases.\n    \"\"\"\n\n    class AhoCorasick:\n        \"\"\"\n        An Aho-Corasick automaton for case-insensitive multi-pattern matching.\n        \"\"\"\n        def __init__(self):\n            # The trie is a list of nodes. Each node is a dictionary.\n            # 'children': maps characters to the index of the child node.\n            # 'fail': index of the failure link node.\n            # 'direct_output_count': number of original patterns ending at this node.\n            # 'output_count': total matches found when landing on this state (includes suffixes).\n            self.trie = [{'children': {}, 'fail': 0, 'direct_output_count': 0, 'output_count': 0}]\n            self.patterns_added = False\n\n        def _phi(self, text: str) -> str:\n            \"\"\"Normalizes a string to its canonical form (lowercase).\"\"\"\n            return text.lower()\n\n        def add_pattern(self, pattern: str):\n            \"\"\"\n            Adds a normalized pattern to the trie.\n            The `build_automaton` method should be called after all patterns are added.\n            \"\"\"\n            if self.patterns_added:\n                raise Exception(\"Cannot add patterns after building the automaton.\")\n            \n            normalized_pattern = self._phi(pattern)\n            node_idx = 0\n            for char in normalized_pattern:\n                node = self.trie[node_idx]\n                if char not in node['children']:\n                    node['children'][char] = len(self.trie)\n                    self.trie.append({'children': {}, 'fail': 0, 'direct_output_count': 0, 'output_count': 0})\n                node_idx = node['children'][char]\n            self.trie[node_idx]['direct_output_count'] += 1\n\n        def build_automaton(self):\n            \"\"\"\n            Builds the failure links and computes aggregated output counts.\n            This must be called after all patterns have been added and before searching.\n            \"\"\"\n            if self.patterns_added:\n                return # Avoid rebuilding\n            \n            self.patterns_added = True\n            queue = []\n\n            # Initialize failure links and output counts for depth 1 nodes.\n            for char, child_idx in self.trie[0]['children'].items():\n                self.trie[child_idx]['fail'] = 0\n                queue.append(child_idx)\n                # This direct propagation is the base for the recursive definition\n                self.trie[child_idx]['output_count'] = self.trie[child_idx]['direct_output_count']\n\n            # BFS to build failure links for nodes at depth > 1.\n            head = 0\n            while head < len(queue):\n                current_idx = queue[head]\n                head += 1\n                current_node = self.trie[current_idx]\n\n                for char, next_idx in current_node['children'].items():\n                    queue.append(next_idx)\n                    fail_idx = current_node['fail']\n                    \n                    # Follow failure links until a transition for `char` is found or root is reached.\n                    while char not in self.trie[fail_idx]['children'] and fail_idx != 0:\n                        fail_idx = self.trie[fail_idx]['fail']\n                    \n                    if char in self.trie[fail_idx]['children']:\n                        self.trie[next_idx]['fail'] = self.trie[fail_idx]['children'][char]\n                    else:\n                        self.trie[next_idx]['fail'] = 0\n\n                    # Propagate output counts along the failure links.\n                    fail_node_output = self.trie[self.trie[next_idx]['fail']]['output_count']\n                    self.trie[next_idx]['output_count'] = self.trie[next_idx]['direct_output_count'] + fail_node_output\n\n        def search(self, text: str) -> int:\n            \"\"\"\n            Searches for all occurrences of the patterns in the given text.\n            Returns the total count of matches.\n            \"\"\"\n            if not self.patterns_added:\n                self.build_automaton()\n\n            normalized_text = self._phi(text)\n            current_state_idx = 0\n            total_matches = 0\n\n            for char in normalized_text:\n                # Follow failure links if no direct child for the character exists.\n                while char not in self.trie[current_state_idx]['children'] and current_state_idx != 0:\n                    current_state_idx = self.trie[current_state_idx]['fail']\n                \n                # If a transition exists, take it.\n                if char in self.trie[current_state_idx]['children']:\n                    current_state_idx = self.trie[current_state_idx]['children'][char]\n                \n                # Add the aggregated output count of the current state to the total.\n                total_matches += self.trie[current_state_idx]['output_count']\n            \n            return total_matches\n\n    test_cases = [\n        ({\"patterns\": [\"he\", \"she\", \"his\", \"hers\"], \"text\": \"aHiShErS\"}),\n        ({\"patterns\": [\"Ab\", \"aB\", \"AB\", \"ab\"], \"text\": \"xxAbYYaBzz\"}),\n        ({\"patterns\": [\"a\", \"aa\"], \"text\": \"AaA\"}),\n        ({\"patterns\": [\"C++\", \"c+\"], \"text\": \"C++C+\"}),\n        ({\"patterns\": [\"Test\"], \"text\": \"\"})\n    ]\n\n    results = []\n    for case in test_cases:\n        ac = AhoCorasick()\n        for p in case[\"patterns\"]:\n            ac.add_pattern(p)\n        ac.build_automaton()\n        result = ac.search(case[\"text\"])\n        results.append(result)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3205013"}, {"introduction": "标准的AC自动机会报告在某个位置结束的所有匹配模式，但在某些场景下，我们可能只关心“最佳”匹配，例如最长的那一个。这项练习将挑战你优化自动机的输出机制。你需要在构建自动机时，通过预计算和信息传播，将每个状态的“最佳匹配”信息存储起来，从而在文本扫描阶段实现摊销常数时间的查询。这个过程类似于动态规划，它展示了如何通过增强状态信息来提升自动机的查询效率和功能。[@problem_id:3204893]", "problem": "考虑一个有限字母表 $\\Sigma$，一个定义在 $\\Sigma$ 上的有限模式串集合 $P = \\{p_0, p_1, \\dots, p_{m-1}\\}$，其中 $|p_j|$ 表示模式串 $p_j$ 的长度，以及一个长度为 $n$ 的文本 $T$。Aho–Corasick 自动机基于数据结构与算法中的基础定义构建，包含三个核心组件：一个包含所有模式串的 trie（前缀树）；一个失败函数，它将每个 trie 节点映射到代表该节点字符串的最长真后缀且该后缀同时是 trie 中前缀的状态；以及一个输出函数，它将每个状态与在该状态终止的模式串集合相关联。标准的 Aho–Corasick 自动机通过从左到右扫描文本 $T$，遵循 trie 转移和失败转移，并在当前状态的输出集非空时报告匹配，从而实现同步多模式串匹配。\n\n你的任务是设计并实现一个完整的程序，该程序为给定的模式串集合构建 Aho–Corasick 自动机，然后修改其输出报告机制，使得在扫描文本 $T$ 时，对于任意位置 $i$（其中 $0 \\le i \\le n-1$），自动机仅报告在位置 $i$ 结束的所有模式串中唯一最长的那一个。如果在位置 $i$ 有多个模式串共享此最大长度，则通过选择在 $P$ 中原始索引最小的模式串（使用从 0 开始的索引）来打破平局。报告的顺序必须是文本 $T$ 中位置的时间顺序（从 $i = 0$ 到 $i = n-1$）：在每个至少有一个模式串结束的位置，将一个且仅一个索引（所选模式串的索引）追加到输出序列中；在没有模式串结束的位置，不追加任何内容。\n\n从以下符合上下文的基本原理出发：\n- trie 是一棵基于 $\\Sigma$ 的有根树，其中每条边都由 $\\Sigma$ 中的一个字符标记。每个模式串 $p_j$ 通过跟随或创建与其字符相对应的边来插入。$p_j$ 的终止节点在其输出集中存储索引 $j$。\n- 失败函数通过在 trie 上进行广度优先搜索（BFS; Breadth-First Search）构建：一个节点的失败链接指向代表该节点字符串的最长真后缀，且该后缀在 trie 中作为前缀存在。这确保了在扫描过程中发生不匹配时，自动机可以转移到一个更短的有效状态，而无需重新读取输入。\n- 一个节点的输出函数是其终止模式串索引集合与其失败状态输出的并集，从而确保报告所有在当前位置结束的模式串。\n\n你必须严格基于这些基本定义推导修改后的报告机制，不得调用任何外部的快捷公式。此修改必须保持扫描的渐进时间复杂度，该复杂度应保持为文本长度 $n$ 加上自动机总大小的线性时间。通过适当的预计算来实现这种复杂度的保持，以便在每个位置选择唯一最长模式串的操作不会在匹配数量上引入超线性开销。\n\n程序要求：\n1. 使用上述原则为提供的测试套件模式串构建 Aho–Corasick 自动机。设 $\\ell_j = |p_j|$ 为模式串 $p_j$ 的长度。\n2. 定义修改后的输出语义如下。如果在处理文本位置 $i$ 后，当前自动机状态 $q$ 关联的模式串索引集合为 $out(q)$，则仅报告\n   $$\\boxed{j^\\star = \\min\\left\\{ j \\in out(q) \\,:\\, \\ell_j = \\max_{k \\in out(q)} \\ell_k \\right\\}}$$\n   并将 $j^\\star$ 追加到结果序列中。如果 $out(q)$ 为空，则在该位置 $i$ 不追加任何内容。\n3. 通过基于 trie 和失败函数的适当预计算，确保在运行时选择 $j^\\star$ 的均摊时间复杂度为每个位置 $O(1)$。\n4. 对每个测试用例，输出报告的模式串索引序列（按文本中的时间顺序）。\n\n测试套件：\n- 测试用例 1：$P = [$\"he\", \"she\", \"his\", \"hers\"$]$，$T =$ \"ushers\"。\n- 测试用例 2：$P = [$\"a\", \"aa\", \"aaa\"$]$，$T =$ \"aaaaa\"。\n- 测试用例 3：$P = [$\"aba\", \"aba\", \"ba\"$]$，$T =$ \"caba\"。这包含重复的模式串，以验证按最小索引打破平局的规则。\n- 测试用例 4：$P = [$\"xyz\"$]$，$T =$ \"abc\"。\n- 测试用例 5：$P = [$\"cat\", \"at\", \"t\"$]$，$T =$ \"catcat\"。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。每个元素对应一个测试用例，并且本身必须是一个由方括号括起、逗号分隔的整数列表，不含空格。例如，最外层结构必须如下所示\n$$ [ [\\dots], [\\dots], [\\dots], [\\dots], [\\dots] ] $$\n任何地方都不能有空格，例如 $[[0,2],[1],[],\\dots]$，其中 $[]$ 表示一个空列表。程序必须是自包含的，不需要任何输入。必须为上面给出的测试套件精确计算输出。", "solution": "用户的要求是设计一个基于 Aho-Corasick 自动机的算法，在文本 $T$ 的每个位置找到唯一的最长匹配模式串，并根据最小的模式串索引解决平局问题。这个过程必须是高效的，在每个位置选择最佳模式串的均摊时间应为 $O(1)$。\n\n该问题在计算上是明确定义的，在科学上植根于字符串算法理论，并为唯一解提供了足够的信息。因此，该问题被认为是有效的。解决方案如下。\n\n### 基于原则的设计\n\n该问题要求对标准的 Aho-Corasick 输出机制进行修改。标准的自动机在到达状态 $q$ 时，通过遍历失败链接链（$q, \\text{failure}(q), \\text{failure}(\\text{failure}(q)), \\dots$）直到到达根节点，并收集所有找到的终止模式串，来识别在当前文本位置结束的所有模式串。这种遍历在每个文本字符上可能需要超常数时间，从而违反了性能约束。\n\n为了实现 $O(1)$ 的均摊查找时间，我们必须为自动机的每个状态预计算最优输出。我们为每个状态定义一个 `best_match` 对 $(\\ell, j)$，其中 $\\ell$ 是最佳模式串的长度，而 $j$ 是其原始索引。问题将“最佳”定义为具有最大长度的模式串，并以最小索引打破平局。如果 $\\ell_1 > \\ell_2$ 或者 $(\\ell_1 = \\ell_2 \\text{ 且 } j_1 < j_2)$，则称对 $(\\ell_1, j_1)$ 优于 $(\\ell_2, j_2)$。\n\n解决方案分为三个主要阶段：\n$1$. 构建 trie 和失败函数，这是 Aho-Corasick 自动机的标准组件。\n$2$. 为每个状态预计算 `best_match`。\n$3$. 扫描文本以使用预计算的数据查找匹配项。\n\n#### $1$. 自动机构建（Trie 和失败链接）\n\n首先，我们从模式串集合 $P = \\{p_0, p_1, \\dots, p_{m-1}\\}$ 构建一个 trie。trie 是一棵有根树，其中每条边都用字母表 $\\Sigma$ 中的一个字符标记。每个模式串 $p_j$ 对应于从根节点开始的一条唯一路径。$p_j$ 路径终点到达的节点是一个终止节点，我们在该节点存储其身份信息——具体来说，是它的长度 $|p_j|$ 和索引 $j$。\n\n接下来，我们为每个状态 $q$ 计算失败函数 $\\text{failure}(q)$。失败函数将一个状态 $q$（代表前缀 $s$）映射到代表 $s$ 的最长真后缀且该后缀同时是 trie 中前缀的状态。这是通过从根开始的广度优先搜索（BFS）构建的。根的失败链接是它自身。对于从其父节点 $p$ 通过字符 $c$ 到达的任何其他状态 $q$，其失败链接是通过遍历 $p$ 的失败链接找到的，直到找到一个在 $c$ 上有转移的状态。\n\n#### $2$. 最佳匹配的预计算\n\n关键的洞察在于，在状态 $q$ 匹配的所有模式串集合（表示为 $\\text{out}(q)$）是恰好在 $q$ 结束的模式串集合（我们称之为 $\\text{terminal}(q)$）与其失败状态 $\\text{out}(\\text{failure}(q))$ 处匹配的模式串集合的并集。\n$$ \\text{out}(q) = \\text{terminal}(q) \\cup \\text{out}(\\text{failure}(q)) $$\n\n这个递归定义允许我们使用动态规划来计算每个状态的 `best_match`。设 $\\text{best_match}(q)$ 是从集合 $\\text{out}(q)$ 中选出的最佳匹配对 $(\\ell, j)$。设 $\\text{term_best}(q)$ 是仅从 $\\text{terminal}(q)$ 中的模式串中选出的最佳匹配对。那么：\n$$ \\text{best_match}(q) = \\text{better_of}(\\text{term_best}(q), \\text{best_match}(\\text{failure}(q))) $$\n\n我们可以为自动机中所有状态 $q$ 计算 $\\text{best_match}(q)$。由于 $\\text{failure}(q)$ 总是指向 trie 中深度严格更小的状态，我们可以在一次 BFS 遍历中计算所有状态的 $\\text{best_match}$ 值。在 BFS 期间，当我们处理一个状态 $q$ 时，$\\text{best_match}(\\text{failure}(q))$ 的值将已经被计算出来。\n算法如下：\n$1$. 对所有状态 $q$，初始化 $\\text{best_match}(q) = (-1, -1)$。\n$2$. 对每个状态 $q$，从 $\\text{terminal}(q)$ 中的模式串计算 $\\text{term_best}(q)$。这涉及找到终止模式串中的最大长度，然后是该长度对应的最小索引。\n$3$. 在 trie 状态上执行 BFS。对于访问的每个状态 $q$：\n    a. 令 $f = \\text{failure}(q)$。\n    b. 来自失败链接链的最佳匹配是 $\\text{best_match}(f)$。\n    c. 将 $\\text{best_match}(q)$ 更新为其自身的 $\\text{term_best}(q)$ 和 $\\text{best_match}(f)$ 中较优的一个。\n\n#### $3$. 文本扫描\n\n在 `best_match` 数组被预计算后，扫描文本 $T$ 变得非常高效。我们根据 $T$ 的字符遍历自动机。\n$1$. 从根状态开始，$q_{current} = 0$。\n$2$. 对于 $T$ 中的每个字符 $c$：\n    a. 通过跟随 $c$ 的转移找到下一个状态。如果 $q_{current}$ 没有直接的转移，则跟随失败链接，直到找到一个转移或到达根节点。这是标准的 Aho-Corasick 状态转移逻辑，具有均摊常数时间复杂度。设新状态为 $q_{next}$。\n    b. 更新 $q_{current} \\leftarrow q_{next}$。\n    c. 查找 $q_{current}$ 的预计算 `best_match`：$(\\ell, j) = \\text{best_match}(q_{current})$。\n    d. 如果存在有效匹配（即 $\\ell \\neq -1$），则将索引 $j$ 追加到结果序列中。\n\n这个过程确保在文本的每个位置 $i$，我们都能以 $O(1)$ 的均摊时间找到唯一的最佳匹配模式串，因为它在状态转移后只需要一次数组查找。扫描的总时间复杂度为 $\\mathcal{O}(n)$，其中 $n=|T|$。算法的整体复杂度由构建和预计算阶段主导，即 $\\mathcal{O}(\\sum_{j=0}^{m-1} |p_j|)$，再加上扫描时间。\n\n这种方法正确地实现了所需修改，同时保持了 Aho-Corasick 算法的线性时间复杂度特性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Aho-Corasick longest pattern problem for a suite of test cases.\n    \"\"\"\n\n    class AhoCorasick:\n        \"\"\"\n        An implementation of the Aho-Corasick automaton with a modified output\n        mechanism to report only the longest pattern at each position.\n        \"\"\"\n        def __init__(self, patterns):\n            \"\"\"\n            Initializes the automaton from a list of patterns.\n            Args:\n                patterns (list of str): The patterns to search for.\n            \"\"\"\n            self._patterns = patterns\n            \n            # Trie nodes are represented as dicts\n            # 'children': mapping from char to child node index\n            # 'fail': index of the failure link node\n            # 'terminal': list of (length, index) tuples for patterns ending here\n            self._nodes = [{'children': {}, 'fail': 0, 'terminal': []}]\n            \n            # Stores the best match (length, index) for each state, considering failure links\n            self._best_match = [(-1, -1)]\n\n            self._build_trie()\n            self._build_failure_links_and_best_matches()\n\n        def _build_trie(self):\n            \"\"\"Builds the initial trie from the patterns.\"\"\"\n            for i, pattern in enumerate(self._patterns):\n                node_idx = 0\n                for char in pattern:\n                    node = self._nodes[node_idx]\n                    if char not in node['children']:\n                        node['children'][char] = len(self._nodes)\n                        self._nodes.append({'children': {}, 'fail': 0, 'terminal': []})\n                        self._best_match.append((-1, -1))\n                    node_idx = node['children'][char]\n                self._nodes[node_idx]['terminal'].append((len(pattern), i))\n\n        def _build_failure_links_and_best_matches(self):\n            \"\"\"\n            Computes failure links and precomputes the best match for each state\n            using a single Breadth-First Search (BFS) traversal.\n            \"\"\"\n            queue = []\n            # Initialize queue with children of the root (depth 1)\n            for child_idx in self._nodes[0]['children'].values():\n                queue.append(child_idx)\n\n            head = 0\n            while head < len(queue):\n                node_idx = queue[head]\n                head += 1\n\n                # Compute failure link for node_idx's children\n                for char, child_idx in self._nodes[node_idx]['children'].items():\n                    fail_idx = self._nodes[node_idx]['fail']\n                    while char not in self._nodes[fail_idx]['children'] and fail_idx != 0:\n                        fail_idx = self._nodes[fail_idx]['fail']\n                    \n                    if char in self._nodes[fail_idx]['children']:\n                        self._nodes[child_idx]['fail'] = self._nodes[fail_idx]['children'][char]\n                    else: # fail_idx is root and has no transition for char\n                        self._nodes[child_idx]['fail'] = 0\n                    \n                    queue.append(child_idx)\n\n                # --- Precompute best match for the current node_idx ---\n                \n                # Best match from patterns ending exactly at this node\n                term_best = (-1, -1)\n                if self._nodes[node_idx]['terminal']:\n                    # Find max length first\n                    max_len = 0\n                    for l, _ in self._nodes[node_idx]['terminal']:\n                        if l > max_len:\n                            max_len = l\n                    \n                    # Find min index for that max length\n                    min_idx = float('inf')\n                    for l, i in self._nodes[node_idx]['terminal']:\n                        if l == max_len and i < min_idx:\n                            min_idx = i\n                    term_best = (max_len, min_idx)\n                \n                # Best match from the failure link chain\n                fail_idx = self._nodes[node_idx]['fail']\n                fail_best = self._best_match[fail_idx]\n\n                # The best match for this state is the better of its own terminal\n                # and the one inherited from its failure state.\n                l1, i1 = term_best\n                l2, i2 = fail_best\n                if l1 > l2:\n                    self._best_match[node_idx] = term_best\n                elif l2 > l1:\n                    self._best_match[node_idx] = fail_best\n                elif l1 != -1: # l1 == l2\n                    self._best_match[node_idx] = (l1, min(i1, i2))\n                else: # Both are (-1,-1)\n                    self._best_match[node_idx] = (-1, -1)\n\n        def search(self, text):\n            \"\"\"\n            Scans the text and reports the best match at each position.\n            Args:\n                text (str): The text to scan.\n            Returns:\n                list of int: A list of the indices of the best matching patterns found.\n            \"\"\"\n            current_node_idx = 0\n            results = []\n            \n            for char in text:\n                while char not in self._nodes[current_node_idx]['children'] and current_node_idx != 0:\n                    current_node_idx = self._nodes[current_node_idx]['fail']\n                \n                if char in self._nodes[current_node_idx]['children']:\n                    current_node_idx = self._nodes[current_node_idx]['children'][char]\n                # If still no transition (i.e., we are at the root), current_node_idx remains 0.\n\n                match = self._best_match[current_node_idx]\n                if match[0] != -1:\n                    results.append(match[1])\n\n            return results\n    \n    test_cases = [\n        ({\"patterns\": [\"he\", \"she\", \"his\", \"hers\"], \"text\": \"ushers\"}),\n        ({\"patterns\": [\"a\", \"aa\", \"aaa\"], \"text\": \"aaaaa\"}),\n        ({\"patterns\": [\"aba\", \"aba\", \"ba\"], \"text\": \"caba\"}),\n        ({\"patterns\": [\"xyz\"], \"text\": \"abc\"}),\n        ({\"patterns\": [\"cat\", \"at\", \"t\"], \"text\": \"catcat\"}),\n    ]\n\n    all_results = []\n    for case in test_cases:\n        patterns = case[\"patterns\"]\n        text = case[\"text\"]\n        \n        automaton = AhoCorasick(patterns)\n        result = automaton.search(text)\n        all_results.append(result)\n\n    # Format output as a single string: [[1,3],[0,1,2,2,2],[0],[],[0,0]]\n    # No spaces are allowed in the output.\n    results_str = [f\"[{','.join(map(str, res))}]\" for res in all_results]\n    print(f\"[{','.join(results_str)}]\")\n\nsolve()\n```", "id": "3204893"}]}