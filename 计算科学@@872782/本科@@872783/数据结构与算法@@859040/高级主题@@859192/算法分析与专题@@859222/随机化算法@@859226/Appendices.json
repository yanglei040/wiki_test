{"hands_on_practices": [{"introduction": "我们从一个基础练习开始，这个练习将帮助你掌握分析随机算法性能的核心技术。在这个问题中，我们将计算一个在一维路径上进行随机游走的机器人到达终点的期望时间。通过建立并求解递归关系，你将能够练习分析拉斯维加斯算法期望运行时间的基本方法，这是算法分析中的一个基石技能 [@problem_id:3263292]。", "problem": "考虑一个具有 $n$ 个标记节点 $\\{1,2,\\ldots,n\\}$ 的路径图。一个机器人执行拉斯维加斯随机算法（LVA），这意味着它总能产生正确的结果，但其运行时间是一个由其随机选择决定的随机变量。机器人从节点 $i$ 开始，其中 $1 \\leq i \\leq n$。在每个离散时间步，如果它位于一个内部节点 $j$（$1  j  n$），它会以等概率（$1/2$）移动到节点 $j-1$ 或 $j+1$。算法在机器人首次到达节点 $1$ 或节点 $n$ 时终止。请求出从节点 $i$ 开始的期望运行时间（步数）。", "solution": "确定路径图上的随机游走到达吸收边界所需的期望步数问题是概率论中的一个经典问题，通常被称为赌徒破产问题的一种形式。该问题陈述清晰，具有科学依据，并包含了进行形式化推导所需的所有信息。\n\n设 $E_i$ 为机器人从节点 $i$ 开始，直到首次到达节点 $1$ 或节点 $n$ 所需的期望时间步数（移动次数），其中 $1 \\leq i \\leq n$。\n\n节点 $1$ 和 $n$ 是吸收态。如果机器人从这些节点之一开始，算法立即终止，耗费 $0$ 步。因此，我们有边界条件：\n$$E_1 = 0$$\n$$E_n = 0$$\n\n对于任何内部节点 $j$（$1  j  n$），我们可以为 $E_j$ 建立一个递推关系。机器人移动一步，耗时 $1$ 个单位时间。从节点 $j$，它以概率 $p = 1/2$ 移动到节点 $j-1$，或以概率 $1-p = 1/2$ 移动到节点 $j+1$。在第一步之后，从新位置出发的期望额外步数分别为 $E_{j-1}$ 或 $E_{j+1}$。\n\n根据全期望定律，从节点 $j$ 出发的期望步数是第一步的时间加上未来期望步数的加权平均值：\n$$E_j = 1 + \\left(\\frac{1}{2}\\right)E_{j-1} + \\left(\\frac{1}{2}\\right)E_{j+1}$$\n\n这个方程对 $j = 2, 3, \\ldots, n-1$ 成立。我们的目标是解出这个线性方程组，得到 $E_i$ 作为 $i$ 和 $n$ 的函数。我们可以将该方程重排为二阶线性非齐次差分方程的形式。两边乘以 $2$ 得到：\n$$2E_j = 2 + E_{j-1} + E_{j+1}$$\n整理各项，我们得到：\n$$E_{j+1} - 2E_j + E_{j-1} = -2$$\n\n为了解这个方程，我们首先求出其对应的齐次方程的通解：\n$$E_{j+1} - 2E_j + E_{j-1} = 0$$\n其特征方程可通过代入 $E_j = r^j$ 得到：\n$$r^{j+1} - 2r^j + r^{j-1} = 0$$\n两边除以 $r^{j-1}$（假设 $r \\neq 0$），我们得到：\n$$r^2 - 2r + 1 = 0$$\n$$(r-1)^2 = 0$$\n这个方程有一个重根 $r=1$。对于重根情况，齐次方程的通解形式为：\n$$E_j^{(h)} = A \\cdot (1)^j + B \\cdot j \\cdot (1)^j = A + Bj$$\n其中 $A$ 和 $B$ 是常数。\n\n接下来，我们求非齐次方程 $E_{j+1} - 2E_j + E_{j-1} = -2$ 的一个特解。由于方程右边是常数，并且齐次解包含常数项（$A$）和线性项（$Bj$），我们必须尝试形式为 $E_j^{(p)} = Cj^2$ 的特解。将此代入非齐次方程：\n$$C(j+1)^2 - 2C(j^2) + C(j-1)^2 = -2$$\n$$C(j^2+2j+1) - 2Cj^2 + C(j^2-2j+1) = -2$$\n$$Cj^2 + 2Cj + C - 2Cj^2 + Cj^2 - 2Cj + C = -2$$\n$$2C = -2$$\n$$C = -1$$\n因此，一个特解是 $E_j^{(p)} = -j^2$。\n\n$E_j$ 的通解是齐次解与特解之和：\n$$E_j = E_j^{(h)} + E_j^{(p)} = A + Bj - j^2$$\n\n现在，我们使用边界条件 $E_1=0$ 和 $E_n=0$ 来确定常数 $A$ 和 $B$。\n当 $j=1$ 时：\n$$E_1 = A + B(1) - (1)^2 = 0 \\implies A + B = 1$$\n当 $j=n$ 时：\n$$E_n = A + B(n) - (n)^2 = 0 \\implies A + Bn = n^2$$\n\n我们得到了一个关于 $A$ 和 $B$ 的二元线性方程组：\n1) $A + B = 1$\n2) $A + Bn = n^2$\n\n由方程（1），我们有 $A = 1 - B$。将其代入方程（2）：\n$$(1-B) + Bn = n^2$$\n$$1 + B(n-1) = n^2$$\n$$B(n-1) = n^2 - 1$$\n$$B(n-1) = (n-1)(n+1)$$\n由于路径图至少有两个节点（$1$ 和 $n$），我们有 $n \\ge 2$，因此 $n-1 \\neq 0$。我们可以两边除以 $(n-1)$：\n$$B = n+1$$\n\n现在，我们求出 $A$：\n$$A = 1 - B = 1 - (n+1) = -n$$\n\n将 $A$ 和 $B$ 的值代回通解，我们得到期望运行时间 $E_j$ 的表达式：\n$$E_j = -n + (n+1)j - j^2$$\n\n问题要求解以起始节点 $i$ 表示，因此我们将 $j$ 替换为 $i$：\n$$E_i = (n+1)i - i^2 - n$$\n这个表达式可以通过因式分解来简化：\n$$E_i = ni + i - i^2 - n$$\n$$E_i = n(i-1) - i^2 + i$$\n$$E_i = n(i-1) - i(i-1)$$\n$$E_i = (n-i)(i-1)$$\n\n这就是从节点 $i$ 开始的期望步数的最终闭式表达式。", "answer": "$$\n\\boxed{(n-i)(i-1)}\n$$", "id": "3263292"}, {"introduction": "在掌握了基础的期望分析之后，让我们将随机化应用于一个经典的图论问题：负权环检测。虽然确定性算法（如 Bellman-Ford）为我们提供了最坏情况下的性能保证，但在许多实际情况下，引入随机性可以显著提高平均性能。这个实践练习将指导你实现一个随机化的 Bellman-Ford 变体，让你亲身体验如何通过随机化来优化算法，并解决一个实际的计算问题 [@problem_id:3263300]。", "problem": "给定一个有限加权有向图，由一个顶点集 $V$ 和一个边多重集 $E \\subseteq V \\times V \\times \\mathbb{R}$ 指定，其中每条边 $(u,v,w) \\in E$ 都有一个实值权重 $w$。一个环是顶点序列 $(v_0,v_1,\\dots,v_k)$，其中 $k \\ge 1$，对于所有 $i \\in \\{0,1,\\dots,k-1\\}$ 都有 $(v_i,v_{i+1},w_i) \\in E$，并且 $v_0 = v_k$。如果 $\\sum_{i=0}^{k-1} w_i  0$，则该环是负权环。经典的确定性 Bellman-Ford 算法能检测从一个源点可达的负权环，其时间上限为 $O(|V||E|)$。\n\n设计并实现一个 Las Vegas 随机算法（总是正确的，随机性只影响运行时间），用于检测图中是否存在任何负权环（在任何弱连通分量中），其在典型的稀疏输入上期望时间快于确定性的 Bellman-Ford 算法。使用一种基于队列的随机松弛策略，该策略以随机顺序处理顶点，并以随机顺序访问出边。为确保检测到任何分量中的负权环（而不仅是从特定源点可达的负权环），请使用超级源初始化模型：将所有顶点 $v \\in V$ 的距离 $d(v)$ 初始化为 $0$，并将所有顶点放入初始处理队列。维护一个数组 $\\text{relax\\_count}(v)$，用以记录 $d(v)$ 严格减少的次数。如果某个 $\\text{relax\\_count}(v)$ 达到 $\\lvert V \\rvert$，则声明存在负权环。需要此终止条件来确保正确性，同时防止无限循环。\n\n请基于以下基本定义和经过充分检验的事实进行推导和设计：\n- 加权有向图 $G=(V,E)$ 的定义如上。\n- 负权环是其总权重小于 $0$ 的环。\n- Bellman-Ford 算法执行重复的松弛操作，如果在第 $\\lvert V \\rvert$ 轮中发生改进，则检测到负权环。一次松弛会减少一个暂定的距离估计值。\n- Las Vegas 算法总是输出正确答案；其期望运行时间是基于其内部随机性来衡量的。\n- Monte Carlo 算法可能有非零的错误概率；其运行时间通常是有界的。\n\n您的程序必须实现所述的 Las Vegas 随机算法，并根据以下测试套件产生所需的输出。在每个测试用例中，顶点被连续编号为从 $0$ 到 $n-1$ 的整数，边以三元组 $(u,v,w)$ 的形式给出，其中 $u,v \\in \\{0,1,\\dots,n-1\\}$ 且 $w \\in \\mathbb{R}$。\n\n测试套件：\n- 用例 A（一般负权环）：$n=5$，$E=\\{(0,1,1.0),(1,2,1.0),(2,3,1.0),(3,1,-4.0),(0,4,2.0),(4,3,2.0)\\}$。此图有一个负权环 $1 \\to 2 \\to 3 \\to 1$，总权重为 $1.0 + 1.0 - 4.0 = -2.0$。\n- 用例 B（无负权环，有向无环核心）：$n=4$，$E=\\{(0,1,2.0),(1,2,2.0),(2,3,2.0),(0,3,7.0)\\}$。不存在环。\n- 用例 C（自环负权环）：$n=1$，$E=\\{(0,0,-1.0)\\}$。该边本身就是一个权重为 $-1.0$ 的负权环。\n- 用例 D（不连通图，负权环在独立的连通分量中）：$n=5$，$E=\\{(0,1,1.0),(1,2,1.0),(3,4,-2.0),(4,3,-2.0)\\}$。分量 $\\{3,4\\}$ 包含一个负权环 $3 \\to 4 \\to 3$，总权重为 $-4.0$，而分量 $\\{0,1,2\\}$ 没有环。\n- 用例 E（长链，无环）：$n=10$，$E=\\{(0,1,1.0),(1,2,1.0),(2,3,1.0),(3,4,1.0),(4,5,1.0),(5,6,1.0),(6,7,1.0),(7,8,1.0),(8,9,1.0)\\}$。此图是无环图。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果（例如 $[result\\_A,result\\_B,result\\_C,result\\_D,result\\_E]$），其中每个 $result\\_X$ 是一个布尔值，表示在相应的情况下是否检测到负权环。每个测试用例所需的输出类型是布尔值。此问题不涉及物理单位或角度单位，也不需要百分比。通过使用随机的顶点初始顺序和随机的边松弛顺序来确保您的算法是随机化的，并确保它对每个测试用例都能终止并给出正确的布尔答案。", "solution": "问题陈述已经过验证，被认为是合理的。它具有科学依据，问题提出得当，并包含制定和实施解决方案所需的所有必要信息。图、环和负权环的定义是标准的。所述的随机算法是 Shortest Path Faster Algorithm (SPFA) 的一个有效变体，其正确性依赖于 Bellman-Ford 算法的公认原理。\n\n核心任务是设计一个 Las Vegas 随机算法，用于检测给定的加权有向图 $G=(V,E)$ 中是否存在任何负权重环。负权环是一条路径 $(v_0, v_1, \\dots, v_{k-1}, v_k=v_0)$，其中边权重之和 $\\sum_{i=0}^{k-1} w(v_i, v_{i+1})$ 小于 $0$。\n\n检测负权环的基本原理源于 Bellman-Ford 算法。在一个有 $|V|$ 个顶点且没有负权环的图中，从任意源顶点到任何其他顶点的最短路径最多包含 $|V|-1$ 条边。Bellman-Ford 算法迭代地松弛边，在 $|V|-1$ 轮之后，它会找到所有这样的最短路径。如果在第 $|V|$ 轮中距离估计值仍能被改进，这意味存在一条包含 $|V|$ 条边的路径，该路径比任何边数更少的路径都“更短”。这样的路径必须包含一个环，并且为了其总权重能够导致距离的进一步减少，这个环必须具有负的总权重。\n\n为了检测图中任何位置的负权环，而不仅是那些从特定源点可达的环，我们采用“超级源”模型。这在概念上等同于添加一个新顶点 $s$，并从该顶点到每个顶点 $v \\in V$ 都有一条权重为零的有向边。从 $s$ 运行最短路径算法将会探索图的所有部分。在实践中，这是通过将每个顶点 $v \\in V$ 的距离估计值初始化为 $0$（即 $d(v) \\leftarrow 0$），并将所有顶点放入待处理的初始顶点集中来实现的。\n\n所指定的算法是 Bellman-Ford 的一个基于队列的随机化变体。与在 $|V|-1$ 轮中每一轮都松弛所有 $|E|$ 条边的确定性 Bellman-Ford 算法不同，基于队列的方法只重新处理那些距离估计值已成功松弛（减少）的顶点。这在平均情况下可以带来显著的性能提升。该算法维护一个顶点队列，这些顶点是松弛其邻居的候选者。\n\n算法流程如下：\n$1$. **初始化**：对每个顶点 $v \\in V$，将其距离估计值 $d(v) \\leftarrow 0$ 和松弛计数器 $\\text{relax\\_count}(v) \\leftarrow 0$ 初始化。创建一个队列，并将 $V$ 中的所有顶点添加到队列中。为了按要求引入随机性，所有顶点集合 $V$ 在被添加到队列之前会被打乱顺序。使用一个辅助数据结构（例如哈希集）来跟踪当前哪些顶点在队列中，以避免重复并实现常数时间的成员资格检查。\n\n$2$. **随机松弛循环**：当队列不为空时，执行以下步骤：\n    a. 从队列中取出一个顶点 $u$。\n    b. 获取从 $u$ 出发的所有出边列表。为满足第二个随机性要求，将此边列表打乱顺序。\n    c. 对于打乱顺序后的列表中的每条出边 $(u, v, w)$，尝试进行松弛。如果 $d(u) + w  d(v)$，则满足松弛条件。\n    d. 如果发生松弛，则更新 $d(v) \\leftarrow d(u) + w$ 并将松弛计数器 $\\text{relax\\_count}(v)$ 增加 1，即 $\\text{relax\\_count}(v) \\leftarrow \\text{relax\\_count}(v) + 1$。\n    e. **终止检查**：在增加 $\\text{relax\\_count}(v)$ 后，立即检查 $\\text{relax\\_count}(v) \\ge |V|$ 是否成立。如果此条件满足，则可作为存在负权环的确凿证据。算法终止并报告 `True`。\n    f. 如果发生了松弛且算法尚未终止，则顶点 $v$ 必须被再次处理，因为其新的、更短的距离可能会导致其邻居的进一步松弛。如果 $v$ 尚不在队列中，则将其入队。\n\n$3$. **终止（未找到环）**：如果主循环完成（即队列变空），意味着已达到一个稳定状态，其中对于所有边 $(u, v, w)$，条件 $d(v) \\le d(u) + w$ 均成立。由于没有顶点的松弛计数器达到 $|V|$，可以保证图中不存在负权环。算法终止并报告 `False`。\n\n此算法属于 Las Vegas 类型，因为其正确性是有保证的。如果它报告有负权环，关于 $\\text{relax\\_count}(v)$ 的条件提供了确凿的证明。如果它报告没有负权环，那是因为松弛过程已经收敛，而这只有在不存在负权环的情况下才可能发生。顶点和边处理顺序的随机化只影响操作序列，从而影响运行时间，但不影响最终结果。其期望运行时间通常优于标准 Bellman-Ford 算法的最坏情况 $O(|V||E|)$，特别是对于不存在 SPFA 类算法最坏情况结构的稀疏图。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nimport collections\n\ndef solve():\n    \"\"\"\n    Solves the negative cycle detection problem for a suite of test cases\n    using a randomized Las Vegas algorithm.\n    \"\"\"\n\n    def detect_negative_cycle_randomized(n, edges, rng):\n        \"\"\"\n        Implements a randomized Las Vegas algorithm to detect negative cycles.\n\n        This algorithm is a queue-based variant of Bellman-Ford (similar to SPFA).\n        It uses a \"super-source\" model by initializing all distances to 0.\n        Randomness is introduced by shuffling the initial vertex processing order\n        and shuffling the outgoing edges for each processed vertex.\n\n        A negative cycle is detected if any vertex's distance is relaxed n or more times.\n\n        Args:\n            n (int): The number of vertices, |V|.\n            edges (list): A list of tuples (u, v, w) representing edges.\n            rng (np.random.Generator): A random number generator for shuffling.\n\n        Returns:\n            bool: True if a negative cycle is detected, False otherwise.\n        \"\"\"\n        if n == 0:\n            return False\n\n        # Adjacency list representation of the graph\n        adj = collections.defaultdict(list)\n        for u, v, w in edges:\n            adj[u].append((v, w))\n\n        # Initialize distances to 0 (super-source model)\n        dist = np.zeros(n, dtype=float)\n\n        # Count the number of times each vertex's distance is relaxed\n        relax_count = np.zeros(n, dtype=int)\n\n        # Queue for vertices to be processed\n        queue = collections.deque()\n        \n        # Set for O(1) checking of queue membership\n        in_queue = set()\n\n        # Initial population of the queue with all vertices in a random order\n        initial_nodes = list(range(n))\n        rng.shuffle(initial_nodes)\n        for i in initial_nodes:\n            queue.append(i)\n            in_queue.add(i)\n\n        while queue:\n            u = queue.popleft()\n            in_queue.remove(u)\n\n            # Randomize the order of edge relaxation\n            outgoing_edges = adj[u]\n            rng.shuffle(outgoing_edges)\n\n            for v, w in outgoing_edges:\n                # Relaxation step\n                if dist[u] + w  dist[v]:\n                    dist[v] = dist[u] + w\n                    relax_count[v] += 1\n\n                    # Check for negative cycle detection\n                    # A path can have at most n-1 edges without a cycle.\n                    # If a vertex is relaxed n times, it implies a path of\n                    # length n, which must contain a negative cycle.\n                    if relax_count[v] >= n:\n                        return True\n\n                    if v not in in_queue:\n                        queue.append(v)\n                        in_queue.add(v)\n        \n        # If the queue is empty and no cycle was detected, none exists.\n        return False\n\n    # Instantiate a random number generator. Seeding is not required by the problem.\n    rng = np.random.default_rng()\n\n    # Test Suite\n    test_cases = {\n        'A': {\n            \"n\": 5, \n            \"edges\": [(0, 1, 1.0), (1, 2, 1.0), (2, 3, 1.0), (3, 1, -4.0), (0, 4, 2.0), (4, 3, 2.0)]\n        },\n        'B': {\n            \"n\": 4, \n            \"edges\": [(0, 1, 2.0), (1, 2, 2.0), (2, 3, 2.0), (0, 3, 7.0)]\n        },\n        'C': {\n            \"n\": 1, \n            \"edges\": [(0, 0, -1.0)]\n        },\n        'D': {\n            \"n\": 5, \n            \"edges\": [(0, 1, 1.0), (1, 2, 1.0), (3, 4, -2.0), (4, 3, -2.0)]\n        },\n        'E': {\n            \"n\": 10, \n            \"edges\": [(0, 1, 1.0), (1, 2, 1.0), (2, 3, 1.0), (3, 4, 1.0), (4, 5, 1.0), \n                      (5, 6, 1.0), (6, 7, 1.0), (7, 8, 1.0), (8, 9, 1.0)]\n        }\n    }\n    \n    results = []\n    # The order of execution must match the problem statement's order for the final output.\n    case_order = ['A', 'B', 'C', 'D', 'E']\n    for case_id in case_order:\n        case = test_cases[case_id]\n        n, edges = case[\"n\"], case[\"edges\"]\n        result = detect_negative_cycle_randomized(n, edges, rng)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3263300"}, {"introduction": "最后，我们将注意力从拉斯维加斯算法转移到蒙特卡洛算法，其核心挑战在于理解和控制错误概率。在这个练习中，我们将探讨著名的 Freivalds 算法，这是一种用于验证矩阵乘法的蒙特卡洛方法。通过引入一个能够篡改输入的“对手”，我们将迫使你深入分析算法的稳健性，并确定在最坏情况下其错误概率如何变化 [@problem_id:3263395]。这个练习强调了理解蒙特卡洛算法何时以及为何会失败的关键性。", "problem": "设 $A$、$B$ 和 $C$ 为 $n \\times n$ 的整数矩阵，其中 $n \\geq 2$。考虑一个经典的矩阵乘积验证测试，即通常所说的 Freivalds 算法，它是一种蒙特卡洛 (MC) 随机算法：均匀随机地抽取一个随机向量 $r \\in \\{0,1\\}^{n}$，并且当且仅当 $A(Br) = Cr$ 时，接受 $AB = C$ 这一声明。将单次测试运行的错误事件定义为在 $AB \\neq C$ 的情况下接受。令 $D = AB - C$，则测试接受当且仅当 $D r = 0$。在标准的、未受干扰的情况下，已知单次运行的错误概率的上限是一个小于 1 的固定常数。\n\n现在假设，在抽取 $r$ 之后，一个能观察到 $A$、$B$、$C$ 和 $r$ 的对手被允许通过改变 $r$ 的至多一个坐标的值来篡改该随机向量，从而产生一个被篡改的向量 $r' \\in \\{0,1\\}^{n}$，满足 $|\\{i \\in \\{1,\\dots,n\\} : r'_{i} \\neq r_{i}\\}| \\leq 1$。然后算法使用 $r'$ 继续执行，并且当且仅当 $D r' = 0$ 时接受。对手的行为旨在最大化错误概率。\n\n假设 $AB \\neq C$（等价于 $D \\neq 0$），请确定在随机选择 $r$ 的情况下，单次被篡改测试的最坏情况错误概率。将最终答案表示为一个实数。无需四舍五入。", "solution": "设给定的 $n \\times n$ 整数矩阵为 $A$、$B$ 和 $C$。我们已知 $AB \\neq C$。令 $D = AB - C$。由于 $AB \\neq C$，矩阵 $D$ 是一个非零矩阵，即 $D \\neq 0$。$D$ 的元素均为整数。\n\n算法均匀随机地抽取一个随机向量 $r \\in \\{0,1\\}^{n}$。共有 $2^n$ 个这样的向量，每个向量的概率为 $\\frac{1}{2^n}$。\n\n在选定 $r$ 后，一个知道 $D$ 和 $r$ 的对手可以将 $r$ 篡改为新向量 $r'$。这种篡改是有限制的，即 $r'$ 与 $r$ 最多在一个坐标上不同。这意味着 $r$ 和 $r'$ 之间的汉明距离最多为 1。令 $S(r)$ 为对手可以选择的向量集合：\n$$S(r) = \\{ x \\in \\{0,1\\}^n : |\\{i \\in \\{1,\\dots,n\\} : x_i \\neq r_i \\}| \\leq 1 \\}$$\n这个集合由向量 $r$ 本身（0 个改动）和所有通过翻转 $r$ 中恰好一位而得到的向量（1 个改动）组成。这样的向量有 $n$ 个。因此， $|S(r)| = n+1$。\n\n如果 $Dr' = 0$，算法就接受。由于我们假设 $D \\neq 0$ ($AB \\neq C$)，接受即为错误。对手的目标是，如果存在这样的向量，就从 $S(r)$ 中选择一个 $r'$ 使得 $Dr' = 0$。\n\n对于一个给定的随机向量 $r$，如果对手能够强制算法接受，就会发生错误。这种情况发生在存在至少一个向量 $r' \\in S(r)$ 使得 $Dr' = 0$ 时。\n错误事件 $E$ 是所有使得对手能够成功的随机向量 $r$ 的集合：\n$$E = \\{r \\in \\{0,1\\}^n \\mid \\exists r' \\in S(r), Dr' = 0\\}$$\n对于给定的矩阵 $D$，错误概率为 $P(\\text{错误} | D) = \\frac{|E|}{2^n}$。\n\n问题要求的是最坏情况错误概率。这是在所有有效的非零矩阵 $D$ 的选择中可能出现的最大错误概率。\n$$\\text{最坏情况错误概率} = \\sup_{D \\neq 0} P(\\text{错误} | D)$$\n\n为了找到这个上确界，我们可以构造一个特定的非零 $n \\times n$ 整数矩阵 $D_0$，并计算其错误概率。如果我们能证明这个概率是 1，那么我们就找到了可能的最大值。\n\n让我们构造这样一个矩阵 $D_0$。设 $n \\ge 2$。考虑矩阵 $D_0$，其第一行为 $(1, 0, \\dots, 0)$，所有其他行都为零向量。即 $D_0 = e_1 e_1^T$，其中 $e_1$ 是第一个标准基向量。\n这个矩阵 $D_0$ 是非零的，其元素是整数。\n\n现在，我们来分析对于任意向量 $r' = (r'_1, r'_2, \\ldots, r'_n)^T \\in \\{0,1\\}^n$ 的条件 $D_0r' = 0$。\n$$D_0 r' = \\begin{pmatrix} 1  0  \\dots  0 \\\\ 0  0  \\dots  0 \\\\ \\vdots  \\vdots  \\ddots  \\vdots \\\\ 0  0  \\dots  0 \\end{pmatrix} \\begin{pmatrix} r'_1 \\\\ r'_2 \\\\ \\vdots \\\\ r'_n \\end{pmatrix} = \\begin{pmatrix} r'_1 \\\\ 0 \\\\ \\vdots \\\\ 0 \\end{pmatrix}$$\n该结果向量为零向量当且仅当其第一个分量为零：\n$$D_0r' = 0 \\iff r'_1 = 0$$\n\n因此，对于这个特定的矩阵 $D_0$，对手的任务简化为：给定 $r$，找到一个 $r' \\in S(r)$，使得 $r'$ 的第一个分量 $r'_1$ 为 0。\n\n让我们来考察对于任何随机选择的初始向量 $r \\in \\{0,1\\}^n$，这是否总是可能的。我们考虑 $r$ 的第一个分量 $r_1$ 的两种可能性。\n\n情况 1: $r_1 = 0$。初始随机向量 $r$ 的第一个分量为零。对手可以简单地选择不篡改该向量，即选择 $r' = r$。这是一个有效的选择，因为 $r' \\in S(r)$（零个坐标被改变）。对于这个选择，$r'_1 = r_1 = 0$，所以 $D_0r' = 0$。对手成功了。\n\n情况 2: $r_1 = 1$。初始随机向量 $r$ 的第一个分量为一。对手可以选择通过翻转 $r$ 的第一位来篡改它。设这个新向量为 $r'$。\n$$r' = (1-r_1, r_2, \\ldots, r_n)^T = (0, r_2, \\ldots, r_n)^T$$\n这个向量 $r'$ 与 $r$ 恰好在一个位置（第一个位置）上不同。因此，$r' \\in S(r)$，并且是对手的有效选择。\n这个 $r'$ 的第一个分量是 $r'_1 = 0$。因此，$D_0r' = 0$。对手成功了。\n\n在这两种情况下，无论初始随机向量 $r$ 是什么，对手总能选择一个满足接受条件 $D_0r' = 0$ 的向量 $r' \\in S(r)$。\n这意味着对于我们选择的矩阵 $D_0$，错误事件 $E$ 包含了所有可能的随机向量 $r$。\n$$E = \\{r \\in \\{0,1\\}^n \\mid \\exists r' \\in S(r), D_0r' = 0\\} = \\{0,1\\}^n$$\n$E$ 中的元素数量为 $|E| = 2^n$。\n\n对于这个特定矩阵 $D_0$ 的错误概率是：\n$$P(\\text{错误} | D_0) = \\frac{|E|}{2^n} = \\frac{2^n}{2^n} = 1$$\n\n我们找到了一个有效的非零矩阵 $D_0$，其错误概率为 1。由于概率不能超过 1，这必定是可能的最大错误概率。\n因此，最坏情况错误概率为 1。", "answer": "$$\\boxed{1}$$", "id": "3263395"}]}