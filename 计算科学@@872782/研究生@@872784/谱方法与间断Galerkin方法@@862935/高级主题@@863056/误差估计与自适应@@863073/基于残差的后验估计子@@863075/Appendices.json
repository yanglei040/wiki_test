{"hands_on_practices": [{"introduction": "第一个实践是一项热身练习，重点是基于残差的误差估计量的基本结构。通过根据给定的残差值直接计算指标 $\\eta_K$，您将对单元内部（体积残差）和其边界（通量跳跃）的贡献如何被网格尺寸加权并组合起来有一个切实的理解。在进入更复杂的场景之前，这个动手计算将巩固核心概念。", "problem": "考虑一个稳态标量扩散模型，该模型代表了多物理场耦合模拟中的一个单场子问题，其强形式为 $-\\nabla \\cdot (\\kappa \\nabla u) = f$，定义在一个有界多边形域上，在二维网格上采用协调有限元法（FEM）进行近似，得到 $u_h \\in V_h$。在用于自适应网格细化的基于残差的后验误差估计中，单元指标由单元内部残差及其边上的通量跳跃残差构成。设单元 $K$ 是形状规则的，其直径为 $h_K$，边长为 $\\{h_{e}\\}_{e \\subset \\partial K}$，并设单元内部残差的大小为 $r_K$，边上的通量跳跃大小为 $\\{j_e\\}_{e \\subset \\partial K}$。网格质量度量 $h_K$ 和边长 $\\{h_e\\}$ 通过形状规则网格上的标准反不等式和迹不等式，进入指标的缩放因子中。\n\n假设一个三角形单元 $K$ 具有以下数据：直径 $h_K = 0.1$，单元内部残差的大小为 $r_K = 5$，其三条边的长度分别为 $(0.1, 0.1, 0.141)$，对应边上的通量跳跃大小分别为 $(3, 1, 2)$。使用由弱形式和分部积分残差表示所蕴含的典型基于残差的缩放方法，计算单元 $K$ 的单元指标 $\\eta_K$。将最终答案表示为单个简化的精确表达式。不需要四舍五入。", "solution": "该问题陈述经评估有效。它在科学上基于成熟的有限元法（FEM）后验误差估计理论，问题提法良好，给出的条件完整且一致，并以客观、正式的语言表述。没有违反基本原则、矛盾或含糊不清之处。因此，我们可以着手求解。\n\n问题要求计算二维域中单个三角形单元 $K$ 的局部、基于残差的后验误差指标，记为 $\\eta_K$。其基础物理由稳态标量扩散方程 $-\\nabla \\cdot (\\kappa \\nabla u) = f$ 描述，其中 $u$ 是标量场，$\\kappa$ 是扩散系数，$f$ 是源项。通过有限元法得到的近似解记为 $u_h$。\n\n误差指标 $\\eta_K$ 的“典型基于残差的缩放”方法源于残差方程的弱形式以及在形状规则网格上应用标准迹不等式和反不等式。平方指标 $\\eta_K^2$ 由两部分主要贡献构成：一部分来自单元内部的残差，另一部分来自穿过单元边的通量跳跃。其一般形式为：\n$$\n\\eta_K^2 = C_{\\text{int}}^2 h_K^2 \\|R_K\\|_{L^2(K)}^2 + \\sum_{e \\in \\partial K} C_{edge}^2 h_e \\|J_e\\|_{L^2(e)}^2\n$$\n这里，$h_K$ 是单元 $K$ 的直径，$\\{h_e\\}$ 是其边的长度。项 $R_K = f + \\nabla \\cdot (\\kappa \\nabla u_h)$ 是内部残差，$\\|R_K\\|_{L^2(K)}$ 是其在单元 $K$ 上的 $L^2$-范数。项 $J_e = \\llbracket \\kappa \\nabla u_h \\cdot \\mathbf{n} \\rrbracket$ 表示通量法向分量穿过边 $e$ 的跳跃，$\\|J_e\\|_{L^2(e)}$ 是其在边 $e$ 上的 $L^2$-范数。常数 $C_{int}$ 和 $C_{edge}$ 取决于插值理论和单元形状的规则性，但在指标的标准定义中通常取为 $1$，这一点由术语“典型”所暗示。\n\n问题提供了以下数据，我们将其映射到公式中的各项：\n- 单元直径：$h_K = 0.1$。\n- 单元内部残差的大小（$L^2$-范数）：$r_K = \\|R_K\\|_{L^2(K)} = 5$。\n- 该单元是三角形，因此有三条边，这里用 $i \\in \\{1, 2, 3\\}$ 索引。\n- 边长：$h_{e_1} = 0.1$, $h_{e_2} = 0.1$, $h_{e_3} = 0.141$。\n- 对应边上的通量跳跃大小（$L^2$-范数）：$j_{e_1} = \\|J_{e_1}\\|_{L^2(e_1)} = 3$, $j_{e_2} = \\|J_{e_2}\\|_{L^2(e_2)} = 1$, $j_{e_3} = \\|J_{e_3}\\|_{L^2(e_3)} = 2$。\n\n将常数 $C_{int}$ 和 $C_{edge}$ 设为 $1$，平方指标的公式变为：\n$$\n\\eta_K^2 = h_K^2 r_K^2 + \\sum_{i=1}^3 h_{e_i} j_{e_i}^2\n$$\n现在我们将给定的数值代入此表达式。为按要求保持精确性，我们将使用分数进行计算。\n$h_K = \\frac{1}{10}$, $r_K = 5$\n$h_{e_1} = \\frac{1}{10}$, $j_{e_1} = 3$\n$h_{e_2} = \\frac{1}{10}$, $j_{e_2} = 1$\n$h_{e_3} = \\frac{141}{1000}$, $j_{e_3} = 2$\n\n来自内部残差的贡献是：\n$$\nh_K^2 r_K^2 = \\left(\\frac{1}{10}\\right)^2 (5)^2 = \\frac{1}{100} \\times 25 = \\frac{25}{100} = \\frac{1}{4}\n$$\n来自三条边上通量跳跃的贡献是：\n$$\nh_{e_1} j_{e_1}^2 = \\frac{1}{10} \\times (3)^2 = \\frac{9}{10}\n$$\n$$\nh_{e_2} j_{e_2}^2 = \\frac{1}{10} \\times (1)^2 = \\frac{1}{10}\n$$\n$$\nh_{e_3} j_{e_3}^2 = \\frac{141}{1000} \\times (2)^2 = \\frac{141}{1000} \\times 4 = \\frac{564}{1000} = \\frac{141}{250}\n$$\n现在，我们将这些分量相加得到 $\\eta_K^2$：\n$$\n\\eta_K^2 = \\frac{1}{4} + \\frac{9}{10} + \\frac{1}{10} + \\frac{141}{250}\n$$\n首先合并公分母项：\n$$\n\\eta_K^2 = \\frac{1}{4} + \\left(\\frac{9}{10} + \\frac{1}{10}\\right) + \\frac{141}{250} = \\frac{1}{4} + 1 + \\frac{141}{250} = \\frac{5}{4} + \\frac{141}{250}\n$$\n为了将这些分数相加，我们找到一个公分母，即 $500$：\n$$\n\\eta_K^2 = \\frac{5 \\times 125}{4 \\times 125} + \\frac{141 \\times 2}{250 \\times 2} = \\frac{625}{500} + \\frac{282}{500} = \\frac{625 + 282}{500} = \\frac{907}{500}\n$$\n问题要求的是单元指标 $\\eta_K$，即该值的平方根：\n$$\n\\eta_K = \\sqrt{\\frac{907}{500}}\n$$\n为了提供一个简化的精确表达式，我们可以将分母有理化：\n$$\n\\eta_K = \\frac{\\sqrt{907}}{\\sqrt{500}} = \\frac{\\sqrt{907}}{\\sqrt{100 \\times 5}} = \\frac{\\sqrt{907}}{10\\sqrt{5}}\n$$\n将分子和分母同乘以 $\\sqrt{5}$：\n$$\n\\eta_K = \\frac{\\sqrt{907} \\times \\sqrt{5}}{10\\sqrt{5} \\times \\sqrt{5}} = \\frac{\\sqrt{907 \\times 5}}{10 \\times 5} = \\frac{\\sqrt{4535}}{50}\n$$\n数字 $907$ 是一个素数，所以根式 $\\sqrt{4535}$ 无法进一步简化。这就是单元指标的最终精确表达式。", "answer": "$$\\boxed{\\frac{\\sqrt{4535}}{50}}$$", "id": "3514528"}, {"introduction": "从简单的计算过渡到完整的实现，这个实践将挑战您编写一个计算间断 Galerkin (DG) 误差估计量的程序。一个关键的重点是确定精确积分多项式残差所需的最小求积点数，这对于估计量本身的准确性是至关重要的考量 [@problem_id:3412905]。这个练习将加深您对多项式逼近阶数 $p$ 与 DG 方法中数值求积要求之间相互作用的理解。", "problem": "要求您从第一性原理出发，使用张量积 Gauss-Legendre 求积法，为一个标量模型椭圆问题实现一个逐单元的基于残差的后验估计子，并确定每轴所需的最少求积点数，以使得对于一个 $p$ 次多项式近似，残差积分是精确的。在二维空间中的单个方形单元 $K = [0,1]^2$ 上进行计算。假设几何尺度为单位尺度，因此所有与网格相关的权重都等于 $1$。\n\n从以下基本设定开始：\n- 每个坐标方向上次数为 $p$ 的多项式近似 $u_h$ 和每个坐标方向上次数为 $p$ 的多项式源项 $f$。\n- 对于具有常数扩散的泊松算子，单元上的强残差为 $f + \\Delta u_h$。\n- 一维空间中，$n$ 点 Gauss-Legendre 求积法可以精确地积分任何次数至多为 $2n-1$ 的多项式；张量积 Gauss-Legendre 求积法将这种精确性扩展到多维空间中的每个轴。\n\n对于给定的整数 $p \\ge 0$，定义近似和数据如下：\n- 多项式近似\n$$\nu_h(x,y) \\;=\\; \\sum_{i=0}^{p}\\sum_{j=0}^{p} a_{ij}\\, x^i y^j,\\quad a_{ij} \\;=\\; \\frac{1}{(i+1)(j+1)}.\n$$\n- 多项式源项\n$$\nf(x,y) \\;=\\; \\sum_{i=0}^{p}\\sum_{j=0}^{p} b_{ij}\\, x^i y^j,\\quad b_{ij} \\;=\\; \\frac{(-1)^{i+j}}{i+j+2}.\n$$\n- 四个面上的边界数据：\n    - 在 $\\{x=0\\}$ 上：$g_\\text{left}(y) = \\sum_{j=0}^{p} \\frac{1}{j+1}\\,y^j$ 且法向通量为零 $q_\\text{left}(y) = 0$。\n    - 在 $\\{x=1\\}$ 上：$g_\\text{right}(y) = \\sum_{j=0}^{p} \\frac{(-1)^j}{j+1}\\,y^j$ 且法向通量为零 $q_\\text{right}(y) = 0$。\n    - 在 $\\{y=0\\}$ 上：$g_\\text{bottom}(x) = \\sum_{i=0}^{p} \\frac{1}{i+1}\\,x^i$ 且法向通量为零 $q_\\text{bottom}(x) = 0$。\n    - 在 $\\{y=1\\}$ 上：$g_\\text{top}(x) = \\sum_{i=0}^{p} \\frac{(-1)^i}{i+1}\\,x^i$ 且法向通量为零 $q_\\text{top}(x) = 0$。\n\n考虑典型的基于残差的间断 Galerkin 估计子（在此单单元场景中，所有几何权重都等于 $1$）\n$$\n\\eta(p) \\;=\\; \\int_{K} \\big(f(x,y) + \\Delta u_h(x,y)\\big)^2\\,\\mathrm{d}x\\,\\mathrm{d}y \\;+\\; \\sum_{F\\subset \\partial K} \\left[ \\int_{F} \\big(\\partial_n u_h - q_F\\big)^2\\,\\mathrm{d}s \\;+\\; \\int_{F} \\big(u_h - g_F\\big)^2\\,\\mathrm{d}s \\right],\n$$\n其中 $\\partial_n u_h$ 表示 $u_h$ 在面 $F$ 上的外法向导数，而 $q_F$ 和 $g_F$ 表示该面上给定的边界通量和边界数据。\n\n任务：\n1. 仅使用 Gauss-Legendre 求积法的精确性性质和多项式次数计算，推导精确积分 $\\eta(p)$ 的每一项所需的最少 Gauss-Legendre 点数（每轴）。具体来说：\n    - 对于涉及 $\\big(f + \\Delta u_h\\big)^2$ 的单元内部积分（在 $K$ 上），给出每个坐标所需的最少点数 $n_\\text{elem}$。\n    - 对于每个涉及切向坐标多项式平方的一维面积分，给出最少点数 $n_\\text{face}$。\n2. 实现一个程序，该程序：\n    - 对于给定的 $p$，根据上述定义构造 $u_h$、$f$、$g_F$，并使用 $q_F = 0$。\n    - 使用张量积 Gauss-Legendre 求积法计算单元项，并使用一维 Gauss-Legendre 求积法计算每个面积分项，从而精确计算估计子 $\\eta(p)$，其中每轴的点数采用任务1中确定的最少数量。\n3. 为以下多项式次数 $p$ 的测试套件提供结果：\n    - $p=0$（分片常数近似的边界情况）。\n    - $p=1$（线性情况）。\n    - $p=3$（中等阶情况）。\n    - $p=5$（高阶情况）。\n4. 输出格式要求：\n    - 您的程序应生成单行输出，其中包含一个结果列表，每个 $p$ 按给定顺序对应一个结果。\n    - 每个结果必须是 $[n_\\text{elem}, n_\\text{face}, \\eta]$ 形式的列表，其中 $n_\\text{elem}$ 和 $n_\\text{face}$ 是整数，$\\eta$ 是浮点值。\n    - 最终输出必须是用方括号括起来的逗号分隔列表。例如，对于两个情况，它看起来像 `[[n_1,n'_1,eta_1],[n_2,n'_2,eta_2]]`。\n\n不涉及物理单位或角度单位；所有量都是无量纲且纯数学的。您的推导必须从所述的多项式结构和 Gauss-Legendre 求积法的精确性性质开始。您的实现必须严格遵守指定的定义和输出格式。确保程序是自包含的，并且不需要用户输入。", "solution": "用户提供的问题被评估为 **有效的**。这是一个在偏微分方程数值分析领域内的适定的、有科学依据的客观问题。所有必要的信息都已提供，任务也已明确定义。\n\n### 1. 最少求积点数的推导\n\n该问题要求确定精确积分一个次数为 $d$ 的多项式所需的最少 Gauss-Legendre 求积点数 $n$。Gauss-Legendre 求积法的基本原理是，区间上的 $n$ 个点可以精确积分任何次数最高为 $2n-1$ 的多项式。要找到积分次数为 $d$ 的多项式所需的最少点数 $n$，我们必须满足不等式：\n$$\n2n - 1 \\ge d\n$$\n这意味着 $2n \\ge d+1$，或 $n \\ge \\frac{d+1}{2}$。由于 $n$ 必须是整数，所需的最少点数为 $n = \\lceil \\frac{d+1}{2} \\rceil$。对于二维中的张量积法则，此分析独立地应用于每个坐标轴。\n\n#### 1.1 单元内部项 ($n_\\text{elem}$)\n单元内部项是 $I_K = \\int_{K} \\big(f(x,y) + \\Delta u_h(x,y)\\big)^2\\,\\mathrm{d}x\\,\\mathrm{d}y$。要找到每轴所需的求积点数 $n_\\text{elem}$，我们必须找到被积函数在每个坐标 $x$ 和 $y$ 上的最高多项式次数。\n\n1.  **$u_h(x,y)$ 的次数**：近似 $u_h$ 定义为 $u_h(x,y) = \\sum_{i=0}^{p}\\sum_{j=0}^{p} a_{ij}\\, x^i y^j$。$u_h$ 在 $x$ 上的最高次数为 $p$，在 $y$ 上的最高次数也为 $p$。我们将其记为 $\\deg(u_h) = (p, p)$。\n\n2.  **$f(x,y)$ 的次数**：源项 $f$ 定义为 $f(x,y) = \\sum_{i=0}^{p}\\sum_{j=0}^{p} b_{ij}\\, x^i y^j$。同样，$\\deg(f) = (p, p)$。\n\n3.  **$\\Delta u_h(x,y)$ 的次数**：拉普拉斯算子为 $\\Delta u_h = \\frac{\\partial^2 u_h}{\\partial x^2} + \\frac{\\partial^2 u_h}{\\partial y^2}$。\n    -   $\\frac{\\partial^2 u_h}{\\partial x^2} = \\sum_{i=2}^{p}\\sum_{j=0}^{p} a_{ij}\\, i(i-1) x^{i-2} y^j$。在 $x$ 上的次数是 $p-2$，在 $y$ 上的次数是 $p$。所以，$\\deg(\\partial_{xx} u_h) = (p-2, p)$。（对于 $p  2$，此项为零）。\n    -   $\\frac{\\partial^2 u_h}{\\partial y^2} = \\sum_{i=0}^{p}\\sum_{j=2}^{p} a_{ij}\\, j(j-1) x^i y^{j-2}$。在 $x$ 上的次数是 $p$，在 $y$ 上的次数是 $p-2$。所以，$\\deg(\\partial_{yy} u_h) = (p, p-2)$。（对于 $p  2$，此项为零）。\n    -   和的次数是次数的最大值。因此，对于 $p \\ge 2$，$\\Delta u_h$ 在 $x$ 上的次数是 $\\max(p-2, p) = p$，在 $y$ 上的次数是 $\\max(p, p-2) = p$。对于 $p  2$，$\\Delta u_h=0$。在所有 $p \\ge 0$ 的情况下，$\\deg(\\Delta u_h) \\le (p,p)$。\n\n4.  **被积函数的次数**：令内部残差为 $R(x,y) = f(x,y) + \\Delta u_h(x,y)$。$R(x,y)$ 的次数最多为 $(p, p)$。由于 $f$ 和 $\\Delta u_h$ 中的最高次项通常不会抵消，对于 $p \\ge 2$，其次数恰好为 $(p, p)$。\n    被积函数是 $R(x,y)^2$。平方多项式的次数是原始多项式次数的两倍。\n    -   $\\deg_x(R^2) = 2 \\deg_x(R) = 2p$。\n    -   $\\deg_y(R^2) = 2 \\deg_y(R) = 2p$。\n    对于 $p=0$ 和 $p=1$ 的情况同样适用，此时 $\\Delta u_h=0$，且 $R=f$。$f^2$ 的次数是 $(2p, 2p)$。\n\n5.  **最少点数 $n_\\text{elem}$**：要精确积分每个坐标上次数为 $d = 2p$ 的多项式，我们需要 $n_\\text{elem}$ 个点，使得 $2n_\\text{elem} - 1 \\ge 2p$。\n    $$\n    n_\\text{elem} \\ge p + \\frac{1}{2} \\implies n_\\text{elem} = p+1\n    $$\n    因此，需要一个 $(p+1) \\times (p+1)$ 的张量积 Gauss-Legendre 网格。\n\n#### 1.2 面项 ($n_\\text{face}$)\n面项是一维积分。我们分析被积函数在切向坐标 $s$ 上的次数。让我们考虑一个垂直面，例如 $F=\\{x=1\\}$，其中 $s=y$。对于所有其他面，分析是类似的。\n\n1.  **通量项**：被积函数是 $(\\partial_n u_h - q_F)^2$。在 $F=\\{x=1\\}$ 上，外法向导数是 $\\partial_n u_h = \\partial_x u_h(1,y)$，且 $q_F = q_\\text{right}(y)=0$。\n    -   $\\partial_x u_h(x,y) = \\sum_{i=1}^{p}\\sum_{j=0}^{p} a_{ij}\\, i x^{i-1} y^j$。\n    -   在 $x=1$ 处求值得到 $\\partial_x u_h(1,y) = \\sum_{j=0}^{p} \\left(\\sum_{i=1}^{p} i a_{ij}\\right) y^j$，这是一个关于 $y$ 的次数最多为 $p$ 的多项式。\n    -   被积函数 $(\\partial_x u_h(1,y))^2$ 是一个次数最多为 $2p$ 的多项式。\n\n2.  **Dirichlet 项**：被积函数是 $(u_h - g_F)^2$。在 $F=\\{x=1\\}$ 上，我们有 $g_F=g_\\text{right}(y)$。\n    -   $u_h(1,y) = \\sum_{j=0}^{p} \\left(\\sum_{i=0}^{p} a_{ij}\\right) y^j$，这是一个关于 $y$ 的次数最多为 $p$ 的多项式。\n    -   $g_\\text{right}(y) = \\sum_{j=0}^{p} \\frac{(-1)^j}{j+1}y^j$，这是一个关于 $y$ 的次数为 $p$ 的多项式。\n    -   差 $u_h(1,y) - g_\\text{right}(y)$ 是一个次数最多为 $p$ 的多项式。\n    -   被积函数 $(u_h(1,y) - g_\\text{right}(y))^2$ 是一个次数最多为 $2p$ 的多项式。\n\n3.  **最少点数 $n_\\text{face}$**：面上的两个被积函数都是次数最多为 $d = 2p$ 的多项式。要精确地积分它们，我们需要 $n_\\text{face}$ 个点满足 $2n_\\text{face} - 1 \\ge 2p$。\n    $$\n    n_\\text{face} \\ge p + \\frac{1}{2} \\implies n_\\text{face} = p+1\n    $$\n\n因此，对于给定的多项式次数 $p$，单元积分每轴所需的最少求积点数为 $n_\\text{elem} = p+1$，面积分所需的最少求积点数为 $n_\\text{face} = p+1$。\n\n### 2. 实现策略\n\n对于每个给定的 $p$ 值，将使用上面推导出的最少求积点数来计算估计子 $\\eta(p)$。\n\n1.  **求积法则**：对于给定的 $p$，我们设置 $n=p+1$。我们使用 `scipy.special.roots_legendre(n)` 来获得在区间 $[-1, 1]$ 上的 $n$ 个 Gauss-Legendre 点 $z_k$ 和权重 $w_k$。然后通过变换将它们缩放到积分域 $[0, 1]$：\n    -   点：$x_k = \\frac{1}{2}(z_k + 1)$\n    -   权重：$w'_k = \\frac{1}{2}w_k$\n\n2.  **多项式求值**：实现各种多项式函数（$u_h, f, \\Delta u_h$ 等）。为提高效率，一维多项式使用 `numpy.polyval`，不可分的二维源项 $f(x,y)$ 使用 `numpy.polynomial.polynomial.polyval2d`。这些函数的系数根据给定的定义预先计算。\n    -   利用 $u_h(x,y) = S(x,p)S(y,p)$ 的可分性（其中 $S(z,p) = \\sum_{k=0}^{p} \\frac{z^k}{k+1}$），来简化 $u_h$ 及其导数的计算。\n    -   注意到左侧（$x=0$）和底部（$y=0$）面上的 Dirichlet 残差恒为零，因为 $u_h$ 的构造方式使其在这些面上与边界数据 $g_\\text{left}$ 和 $g_\\text{bottom}$ 匹配。这一点可以通过观察 $u_h(0,y) = S(0,p)S(y,p) = 1 \\cdot S(y,p) = g_\\text{left}(y)$ 来证实，底面的情况也类似。\n\n3.  **积分计算**：\n    -   **单元积分**：使用 `numpy.meshgrid` 构造一个 $n_\\text{elem} \\times n_\\text{elem}$ 的求积点网格和相应的权重网格。在该网格上计算被积函数 $(f + \\Delta u_h)^2$，并通过加权和计算积分：$\\sum_{k,l} (f(x_k,y_l) + \\Delta u_h(x_k,y_l))^2 w'_k w'_l$。\n    -   **面积分**：对于四个面中的每一个，使用一组 $n_\\text{face}$ 个一维求积点和权重。在面上的这些点处计算通量和 Dirichlet 残差被积函数，并将积分计算为加权和。总估计子是单元积分和所有八个面积分（每个面一个通量项和一个 Dirichlet 项）的总和。\n\n4.  **工作流程**：主程序遍历指定的次数列表 $p \\in \\{0, 1, 3, 5\\}$，为每个次数计算 $\\eta(p)$，并将结果 $[n_\\text{elem}, n_\\text{face}, \\eta(p)]$ 存储在一个列表中。最后，按指定格式对结果列表进行格式化并打印。", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_legendre\n\ndef calculate_eta_for_p(p):\n    \"\"\"\n    Calculates the residual-based error estimator eta for a given polynomial degree p.\n    \"\"\"\n    # Task 1: Determine minimal number of quadrature points.\n    # To integrate a polynomial of degree d=2p exactly, we need n points such that\n    # 2n - 1 >= 2p => n >= p + 1/2. Minimal integer n is p+1.\n    n_elem = p + 1\n    n_face = p + 1\n\n    # Get Gauss-Legendre quadrature points and weights for [-1, 1] and scale to [0, 1].\n    z_elem, w_elem_unscaled = roots_legendre(n_elem)\n    xq_elem = 0.5 * (z_elem + 1)\n    wq_elem = 0.5 * w_elem_unscaled\n\n    z_face, w_face_unscaled = roots_legendre(n_face)\n    s_q = 0.5 * (z_face + 1) # Points for face integrals (tangential coordinate)\n    w_q = 0.5 * w_face_unscaled # Weights for face integrals\n\n    # --- Define polynomial coefficients for use with np.polyval ---\n    # np.polyval evaluates p(x) = c[0]*x**n + c[1]*x**(n-1) + ... + c[n]\n    # S(z,p) = sum_{k=0 to p} z^k / (k+1)\n    S_coeffs = 1.0 / (np.arange(p, -1, -1) + 1)\n\n    # S'(z,p) = sum_{k=1 to p} k * z^{k-1} / (k+1), a polynomial of degree p-1\n    if p >= 1:\n        S_prime_coeffs = (np.arange(p, 0, -1)) / (np.arange(p, 0, -1) + 1)\n    else:\n        S_prime_coeffs = []\n\n    # S''(z,p) = sum_{k=2 to p} k(k-1) * z^{k-2} / (k+1), a polynomial of degree p-2\n    if p >= 2:\n        k_vals = np.arange(p, 1, -1)\n        S_prime_prime_coeffs = (k_vals * (k_vals - 1)) / (k_vals + 1)\n    else:\n        S_prime_prime_coeffs = []\n        \n    # f(x,y,p) = sum_{i=0 to p} sum_{j=0 to p} (-1)^{i+j}/(i+j+2) * x^i y^j\n    # Coeffs for numpy.polynomial.polynomial.polyval2d\n    f_coeffs = np.zeros((p + 1, p + 1))\n    for i in range(p + 1):\n        for j in range(p + 1):\n            f_coeffs[i, j] = ((-1)**(i + j)) / (i + j + 2.0)\n\n    # g_right(y, p) = sum_{j=0 to p} (-1)^j/(j+1) * y^j\n    g_right_coeffs = ((-1)**np.arange(p, -1, -1)) / (np.arange(p, -1, -1) + 1)\n    g_top_coeffs = g_right_coeffs # by symmetry\n\n    # --- 1. Element interior integral ---\n    X, Y = np.meshgrid(xq_elem, xq_elem)\n    WX, WY = np.meshgrid(wq_elem, wq_elem)\n\n    f_vals = np.polynomial.polynomial.polyval2d(X, Y, f_coeffs)\n\n    S_X = np.polyval(S_coeffs, X)\n    S_Y = np.polyval(S_coeffs, Y)\n    S_pp_X = np.polyval(S_prime_prime_coeffs, X)\n    S_pp_Y = np.polyval(S_prime_prime_coeffs, Y)\n\n    delta_uh_vals = S_pp_X * S_Y + S_X * S_pp_Y\n    \n    residual_vals = f_vals + delta_uh_vals\n    elem_integral = np.sum((residual_vals**2) * WX * WY)\n\n    # --- 2. Face integrals ---\n    total_face_integral = 0.0\n    q_F = 0.0 # prescribed flux is zero on all faces\n\n    # --- Left face (x=0, n=(-1,0)) ---\n    # Dirichlet term is zero, since u_h(0,y) = g_left(y) by construction.\n    du_dx_at_0 = np.polyval(S_prime_coeffs, 0.0) * np.polyval(S_coeffs, s_q)\n    flux_left = np.sum(((-du_dx_at_0 - q_F)**2) * w_q)\n\n    # --- Right face (x=1, n=(1,0)) ---\n    u_h_at_1 = np.polyval(S_coeffs, 1.0) * np.polyval(S_coeffs, s_q)\n    g_right_vals = np.polyval(g_right_coeffs, s_q)\n    dirichlet_right = np.sum(((u_h_at_1 - g_right_vals)**2) * w_q)\n    \n    du_dx_at_1 = np.polyval(S_prime_coeffs, 1.0) * np.polyval(S_coeffs, s_q)\n    flux_right = np.sum(((du_dx_at_1 - q_F)**2) * w_q)\n\n    # --- Bottom face (y=0, n=(0,-1)) ---\n    # Dirichlet term is zero, since u_h(x,0) = g_bottom(x) by construction.\n    du_dy_at_0 = np.polyval(S_coeffs, s_q) * np.polyval(S_prime_coeffs, 0.0)\n    flux_bottom = np.sum(((-du_dy_at_0 - q_F)**2) * w_q)\n\n    # --- Top face (y=1, n=(0,1)) ---\n    u_h_at_1_top = np.polyval(S_coeffs, s_q) * np.polyval(S_coeffs, 1.0)\n    g_top_vals = np.polyval(g_top_coeffs, s_q)\n    dirichlet_top = np.sum(((u_h_at_1_top - g_top_vals)**2) * w_q)\n\n    du_dy_at_1 = np.polyval(S_coeffs, s_q) * np.polyval(S_prime_coeffs, 1.0)\n    flux_top = np.sum(((du_dy_at_1 - q_F)**2) * w_q)\n    \n    total_face_integral = (flux_left + dirichlet_right + flux_right +\n                           flux_bottom + dirichlet_top + flux_top)\n\n    eta = elem_integral + total_face_integral\n    \n    return [n_elem, n_face, eta]\n\ndef solve():\n    \"\"\"\n    Main function to drive the calculation for the specified test cases.\n    \"\"\"\n    test_cases_p = [0, 1, 3, 5]\n    \n    results = []\n    for p in test_cases_p:\n        result = calculate_eta_for_p(p)\n        # Format the numbers for the final list object\n        # The output format requires a list of lists.\n        # map(str,...) will convert the inner lists to strings.\n        results.append(f\"[{result[0]},{result[1]},{result[2]:.8f}]\")\n    \n    # The final print must be a single string that looks like a list of lists.\n    # The requirement is [[...],[...]], so we join the string-formatted\n    # inner lists with a comma and wrap them in square brackets.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3412905"}, {"introduction": "最后的实践展示了基于残差的估计量的真正威力：驱动自适应算法。您将设计一个策略，该策略不仅使用估计量的分量来衡量误差，而且还用它们来*决定*是通过分割单元（$h$-细化）还是通过增加其多项式阶数（$p$-细化）来对单元进行细化 [@problem_id:3412840]。这个练习模拟了高等计算科学中的一项核心任务，其目标是创建能够自动将计算精力集中在最需要地方的高效、智能求解器。", "problem": "考虑在域 $[0,1]$ 上的齐次狄利克雷边界条件的一维泊松模型问题，由下式给出\n$$\n-\\frac{d^2 u}{dx^2} = f \\quad \\text{in } (0,1), \\qquad u(0)=0, \\quad u(1)=0.\n$$\n在不连续伽辽金 (DG) 离散化中，网格的每个单元 $K$ 上采用分片多项式逼近，离散解 $u_h$ 被允许在单元交界面上不连续。对于每个长度为 $h_K$、多项式次数为 $p_K$ 的单元 $K$，定义内部（强）残差\n$$\nR_K(u_h) := f + \\frac{d^2 u_h}{dx^2} \\quad \\text{on } K,\n$$\n以及跨越由相邻单元 $K^{-}$ 和 $K^{+}$ 共享的、位于节点 $x_e$ 处的内部面 $e$ 的跳跃残差\n$$\nJ_e(u_h) := \\llbracket \\nabla u_h \\cdot n \\rrbracket = \\frac{d u_h}{dx}\\bigg|_{x_e^+} - \\frac{d u_h}{dx}\\bigg|_{x_e^-},\n$$\n在一维且扩散系数等于 $1$ 的情况下，这与通量跳跃一致。对于每个单元 $K$，一个标准的基于残差的后验估计子是量\n$$\n\\eta_K^2 := h_K^2 \\, \\| R_K(u_h) \\|_{L^2(K)}^2 \\;+\\; \\sum_{e \\subset \\partial K \\cap \\mathcal{E}_{\\text{int}}} h_e \\, \\| J_e(u_h) \\|_{L^2(e)}^2,\n$$\n其中 $\\mathcal{E}_{\\text{int}}$ 表示内部面的集合，$h_e$ 是与面 $e$ 相关的特征长度，例如 $h_e := \\frac{1}{2}(h_{K^{-}}+h_{K^{+}})$。\n\n您的任务是设计并实现一个由残差 $\\eta_K(h_K,p_K)$ 驱动的 $hp$-自适应标记策略，该策略为每个单元 $K$ 预测是进行 $h$-细化（分裂单元）还是进行 $p$-加密（提高多项式次数）。该决策必须通过比较跳跃残差 $\\|\\llbracket \\nabla u_h\\cdot n \\rrbracket\\|$ 和内部残差 $\\|R_K(u_h)\\|$ 的衰减行为来做出。该策略应基于以下基本原理：\n\n- 上述 DG 残差的定义。\n- 多项式空间的逼近性质：对于足够光滑的 $u$，内部残差预计会随着 $p_K$ 的增加而迅速衰减，而跨面的大通量跳跃表明分辨率不足，通常受益于 $h$-细化。\n- 谱系数衰减作为光滑度指示子：$u_h$ 在 $K$ 上的高阶模态系数的衰减提供了局部正则性的信号。\n\n实现约束：\n\n- 在每个单元上，通过将构造的精确解 $u$ 局部 $L^2$-投影到该单元上次数为 $p_K$ 的勒让德多项式空间来构造 $u_h$。\n- 通过对 $K$ 上的强残差 $f + \\frac{d^2 u_h}{dx^2}$ 进行数值积分来计算 $\\|R_K(u_h)\\|_{L^2(K)}$。\n- 通过评估 $J_e(u_h)$ 并将 $h_e \\, |J_e(u_h)|^2$ 的一半分配给每个相邻单元来计算每个内部面上的跳跃残差范数。\n- 使用 $u_h$ 的勒让德模态系数 $\\{a_\\ell\\}_{\\ell=0}^{p_K}$ 在每个单元 $K$ 上定义一个光滑度指示子：使用比率 $|a_{p_K}| / \\sum_{\\ell=0}^{p_K} |a_\\ell|$ 来评估谱尾的支配性。\n- 基于跳跃残差与内部残差的相对支配性以及光滑度指示子，决定每个单元 $K$ 的标记操作：\n  - 如果单元应被标记为 $h$-细化，则输出 $0$，\n  - 如果单元应被标记为 $p$-加密，则输出 $1$，\n  - 如果不需要细化（例如，当 $\\eta_K$ 相对于平均估计子量级足够小时），则输出 $2$。\n\n您的程序必须实现上述内容，并将其应用于以下测试套件。在每种情况下，都指定了网格、多项式次数和构造解 $u$（及其对应的右手项 $f = -u''$）。\n\n- 测试用例 1（光滑解，均匀网格）：\n  - 网格节点：$[0, 0.25, 0.5, 0.75, 1]$，因此有 $4$ 个长度为 $h_K = 0.25$ 的单元。\n  - 多项式次数：所有单元上 $p_K = 2$。\n  - 构造解：$u(x) = \\sin(\\pi x)$，因此 $f(x) = \\pi^2 \\sin(\\pi x)$。\n\n- 测试用例 2（靠近网格交界面的陡峭变化，均匀网格）：\n  - 网格节点：$[0, 0.25, 0.5, 0.75, 1]$。\n  - 多项式次数：所有单元上 $p_K = 2$。\n  - 构造解：\n    $$\n    u(x) = \\arctan(\\beta (x - x_0))\n    $$\n    参数为 $\\beta = 300$ 和 $x_0 = 0.5$，因此\n    $$\n    u'(x) = \\frac{\\beta}{1 + \\beta^2 (x - x_0)^2}, \\qquad\n    u''(x) = -\\frac{2 \\beta^3 (x - x_0)}{\\left(1 + \\beta^2 (x - x_0)^2\\right)^2}, \\qquad\n    f(x) = -u''(x) = \\frac{2 \\beta^3 (x - x_0)}{\\left(1 + \\beta^2 (x - x_0)^2\\right)^2}.\n    $$\n\n- 测试用例 3（混合光滑和局部陡峭特征，非均匀 $p$）：\n  - 网格节点：$[0, 0.2, 0.4, 0.6, 0.8, 1]$，因此有 $5$ 个长度为 $h_K = 0.2$ 的单元。\n  - 多项式次数：$p_K = [1, 3, 2, 1, 4]$。\n  - 构造解：\n    $$\n    u(x) = \\sin(3 \\pi x) + 0.1 \\, \\arctan(\\gamma (x - x_1))\n    $$\n    参数为 $\\gamma = 80$ 和 $x_1 = 0.35$。因此，\n    $$\n    u''(x) = -9 \\pi^2 \\sin(3 \\pi x) - \\frac{0.2 \\, \\gamma^3 (x - x_1)}{\\left(1 + \\gamma^2 (x - x_1)^2\\right)^2}, \\qquad\n    f(x) = -u''(x) = 9 \\pi^2 \\sin(3 \\pi x) + \\frac{0.2 \\, \\gamma^3 (x - x_1)}{\\left(1 + \\gamma^2 (x - x_1)^2\\right)^2}.\n    $$\n\n对每个单元 $K$ 的标记决策的算法要求：\n\n- 计算内部残差范数 $\\|R_K(u_h)\\|_{L^2(K)}$ 和分配给 $K$ 的聚合跳跃残差范数（分配的面贡献之和的平方根）。\n- 计算谱尾比率 $|a_{p_K}| / \\sum_{\\ell=0}^{p_K} |a_\\ell|$。\n- 比较跳跃残差与内部残差的量级以及谱尾比率，以决定在增加 $p_K$ 下的预期衰减是否有利（指示 $p$-加密），或者跳跃项是否占主导地位（指示 $h$-细化）。如果总估计子 $\\eta_K$ 相对于测试用例中的平均估计子量级足够小，则返回不更改的决策。\n\n最终输出规范：\n\n- 对于每个测试用例，返回一个与单元数量等长的整数列表，其中条目在 $\\{0,1,2\\}$ 中，分别对应于 $h$-细化、$p$-加密或无变化。\n- 您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，每个测试用例的列表显示为嵌套列表。例如，输出格式应类似于 $[[d_{1,1}, d_{1,2}, \\dots], [d_{2,1}, d_{2,2}, \\dots], [d_{3,1}, d_{3,2}, \\dots]]$，其中 $d_{i,j} \\in \\{0,1,2\\}$。", "solution": "该问题要求为应用于泊松方程的一维不连续伽辽金 (DG) 方法设计并实现一个 $hp$-自适应标记策略。该策略必须为给定网格的每个单元 $K$ 决定是推荐 $h$-细化（分裂单元）、$p$-加密（增加多项式次数）还是不作改变。这个决策将基于从数值解的内部残差和跳跃残差导出的后验误差指示子。\n\n该问题是适定的，并且在科学上植根于偏微分方程数值方法的理论，特别是不连续伽辽金方法的后验误差估计。我将首先概述该策略的理论和算法基础，然后提供实现。\n\n### 1. 理论框架\n\n我们考虑模型问题的 DG 离散化：\n$$\n-\\frac{d^2 u}{dx^2} = f \\quad \\text{in } (0,1), \\qquad u(0)=0, \\quad u(1)=0.\n$$\n数值解 $u_h$ 是在划分域 $[0,1]$ 的网格的每个单元 $K$ 上次数为 $p_K$ 的分片多项式。DG 方法的一个关键特征是 $u_h$ 不需要跨单元交界面连续。这导致了两个主要的误差来源，可以通过残差来衡量：\n\n1.  **内部残差 $R_K(u_h)$**：在每个单元 $K$ 上，PDE 的强形式不被 $u_h$ 精确满足。内部残差定义为：\n    $$\n    R_K(u_h) := f + \\frac{d^2 u_h}{dx^2} \\quad \\text{on } K\n    $$\n    大的内部残差表明多项式 $u_h$ 在单元 $K$ 内部是对真实解 $u$ 的一个较差的逼近。\n\n2.  **跳跃残差 $J_e(u_h)$**：在一个由单元 $K^{-}$ 和 $K^{+}$ 共享的内部面 $e$（在一维中是一个节点）处，通量项（这里是 $\\nabla u_h \\cdot n$）可能是不连续的。跳跃残差衡量了这种不连续性：\n    $$\n    J_e(u_h) := \\llbracket \\nabla u_h \\cdot n \\rrbracket = \\frac{d u_h}{dx}\\bigg|_{x_e^+} - \\frac{d u_h}{dx}\\bigg|_{x_e^-}\n    $$\n    大的跳跃残差表明解在该交界面处没有被网格很好地解析，这通常是由于陡峭的梯度或奇点。\n\n这些残差构成了每个单元 $K$ 的后验误差估计子 $\\eta_K$ 的基础：\n$$\n\\eta_K^2 := h_K^2 \\, \\| R_K(u_h) \\|_{L^2(K)}^2 \\;+\\; \\sum_{e \\subset \\partial K \\cap \\mathcal{E}_{\\text{int}}} h_e \\, |J_e(u_h)|^2\n$$\n这里，$\\| \\cdot \\|_{L^2(e)}$ 在一维中简化为在点 $e$ 处的求值。当对所有单元求和时，这种形式的估计子会重复计算跳跃项。一种局部化误差的常见做法是将跳跃贡献的一半分配给两个相邻单元中的每一个。因此，我们将使用一个局部化的指示子 $\\tilde{\\eta}_K$：\n$$\n\\tilde{\\eta}_K^2 := \\underbrace{h_K^2 \\, \\| R_K(u_h) \\|_{L^2(K)}^2}_{\\text{内部贡献}} \\;+\\; \\underbrace{\\frac{1}{2} \\sum_{e \\subset \\partial K \\cap \\mathcal{E}_{\\text{int}}} h_e \\, |J_e(u_h)|^2}_{\\text{跳跃贡献}}\n$$\n\n### 2. $hp$-标记策略的算法设计\n\n任务的核心是使用 $\\tilde{\\eta}_K$ 和其他可用信息来决定 $h$-细化和 $p$-加密。指导原则是：\n\n-   **$h$-细化** 对于解析像陡峭梯度或不连续性这样的非光滑特征最有效，这些特征表现为大的跳跃残差。当局部解的正则性较低时也首选 $h$-细化，这意味着增加多项式次数只会产生缓慢的收敛。\n-   **$p$-加密** 对于光滑解最有效，此时误差分布在整个单元中。这通常对应于相对于跳跃残差而言较大的内部残差。高次多项式可以用指数收敛速度捕捉光滑函数。\n\n为了形式化这一点，我们引入一个局部光滑度指示子。单元 $K$ 上的数值解 $u_h$ 在勒让德多项式基中表示。模态系数的衰减率提供了局部解正则性的估计。我们将谱光滑度指示子 $S_K$ 定义为最高阶系数的量值与所有系数的量值之和的比率：\n$$\nS_K := \\frac{|a_{p_K}|}{\\sum_{\\ell=0}^{p_K} |a_\\ell|}\n$$\n$S_K$ 的小值表示谱衰减快和局部光滑的解，而大值则表明解没有被当前的多项式空间很好地表示，指示需要解析更精细的特征，这指向 $h$-细化。\n\n标记策略是作为对每个单元 $K$ 的多步算法实现的：\n\n**步骤 1：构造近似解 $u_h$**\n对于每个具有指定多项式次数 $p_K$ 的单元 $K = [x_i, x_{i+1}]$，局部解 $u_h|_K$ 被构造为构造解 $u$ 的 $L^2(K)$ 投影。$K$ 上勒让德基中的系数 $\\{a_\\ell\\}_{\\ell=0}^{p_K}$ 通过数值积分计算。使用从参考区间 $[-1, 1]$到 $K$ 的仿射映射 $\\xi \\mapsto x(\\xi)$，系数为：\n$$\na_\\ell = \\frac{\\langle u, \\hat{P}_\\ell \\rangle_{L^2(K)}}{\\|\\hat{P}_\\ell\\|_{L^2(K)}^2} = \\frac{\\int_{-1}^1 u(x(\\xi)) P_\\ell(\\xi) d\\xi}{\\int_{-1}^1 (P_\\ell(\\xi))^2 d\\xi} = \\frac{2\\ell+1}{2} \\int_{-1}^1 u(x(\\xi)) P_\\ell(\\xi) d\\xi\n$$\n其中 $P_\\ell$ 是 $[-1, 1]$ 上的标准勒让德多项式。该积分使用高阶高斯-勒让德积分来近似。有了系数 $\\{a_\\ell\\}$，$u_h$ 及其在 $K$ 上的导数就定义好了。\n\n**步骤 2：计算残差和指示子**\n-   内部残差的平方 $L^2$-范数，$\\|R_K(u_h)\\|_{L^2(K)}^2 = \\int_K (f + u_h'')^2 dx$，使用高斯-勒让德积分计算。\n-   跳跃残差 $J_e(u_h)$ 在每个内部节点 $x_e$ 处通过评估左右单元多项式的导数来计算。\n-   谱光滑度指示子 $S_K$ 从勒让德系数计算得出。\n-   局部误差指示子 $\\tilde{\\eta}_K$ 由内部和跳跃贡献组装而成。\n\n**步骤 3：应用标记逻辑**\n一组基于经验选择但理论上合理的阈值的规则，应用于每个单元 $K_i$：\n1.  **不细化（标记 2）：** 如果一个单元对总误差的贡献可以忽略不计，则不进行细化。这是通过将其指示子 $\\tilde{\\eta}_{K_i}$ 与所有单元中的最大指示子值进行比较来决定的：\n    若 $\\tilde{\\eta}_{K_i}  \\theta_{\\text{no-ref}} \\cdot \\max_j(\\tilde{\\eta}_{K_j})$, 标记为 2。\n    使用阈值 $\\theta_{\\text{no-ref}} = 0.1$。\n\n2.  **$h$-细化 vs. $p$-加密（标记 0 vs. 1）：** 对于未被标记为不细化的单元，我们在 $h$ 和 $p$ 之间做出决定。\n    -   我们计算跳跃支配比，它衡量跳跃残差项对总局部指示子的相对贡献：\n        $$\n        D_K = \\frac{\\text{跳跃贡献}}{\\tilde{\\eta}_K^2}\n        $$\n    -   我们通过谱指示子 $S_K$ 检查光滑度。\n    -   如果跳跃残差占主导地位或检测到局部解不光滑，则将单元标记为 $h$-细化（标记 0）：\n        若 $D_K > \\theta_{\\text{jump}}$ 或 $S_K > \\theta_{\\text{spectral}}$, 标记为 0。\n        我们使用阈值 $\\theta_{\\text{jump}} = 0.5$ 和 $\\theta_{\\text{spectral}} = 0.1$。\n    -   否则，如果内部残差占主导地位且函数显得光滑，则将该单元标记为 $p$-加密（标记 1）。这是需要细化的单元的默认选项。\n\n该算法为指导 $hp$-自适应网格细化过程提供了一种清晰、果断且合理的方法。它正确地平衡了解析局部尖锐特征的需求与高阶方法对光滑解的效率。", "answer": "```python\nimport numpy as np\nfrom scipy.special import eval_legendre\nfrom numpy.polynomial.legendre import Legendre, leggauss\n\n# Algorithmic parameters for the marking strategy\nN_QUAD = 30  # Number of quadrature points\nTHETA_NO_REFINEMENT = 0.1  # Threshold for not refining an element\nJUMP_DOMINANCE_THRESHOLD = 0.5  # Threshold for jump residual dominance\nSPECTRAL_DECAY_THRESHOLD = 0.1  # Threshold for slow spectral decay\n\ndef get_l2_projection_coeffs(u_func, interval, p_degree):\n    \"\"\"Computes the coefficients of the L2 projection of u_func onto the space\n    of Legendre polynomials of degree p_degree on the given interval.\"\"\"\n    a, b = interval\n    h = b - a\n    jacobian = h / 2.0\n    \n    # Affine map from reference interval [-1, 1] to element [a, b]\n    map_to_interval = lambda xi: jacobian * xi + (a + b) / 2.0\n    \n    quad_points, quad_weights = leggauss(N_QUAD)\n    \n    coeffs = []\n    for l in range(p_degree + 1):\n        # Integrand for L2 projection coefficient calculation\n        integrand_vals = u_func(map_to_interval(quad_points)) * eval_legendre(l, quad_points)\n        integral_val = np.sum(quad_weights * integrand_vals)\n        \n        # Formula for the l-th coefficient\n        coeff_l = (2 * l + 1) / 2.0 * integral_val\n        coeffs.append(coeff_l)\n        \n    return np.array(coeffs)\n\ndef process_test_case(mesh_nodes, p_degrees, u_func, f_func):\n    \"\"\"\n    Applies the hp-marking strategy to a single test case.\n    \"\"\"\n    num_elements = len(mesh_nodes) - 1\n    elements_data = []\n    \n    quad_points, quad_weights = leggauss(N_QUAD)\n\n    # Step 1: Process each element to compute local properties\n    for i in range(num_elements):\n        interval = (mesh_nodes[i], mesh_nodes[i+1])\n        h_k = interval[1] - interval[0]\n        p_k = p_degrees[i]\n\n        # Compute L2 projection to get u_h\n        coeffs = get_l2_projection_coeffs(u_func, interval, p_k)\n        \n        # Build polynomial representation of u_h and its derivatives\n        u_h_poly = Legendre(coeffs, domain=interval)\n        u_h_poly_d2 = u_h_poly.deriv(2)\n\n        # Compute interior residual norm\n        map_to_interval = lambda xi: (h_k / 2.0) * xi + (interval[0] + interval[1]) / 2.0\n        x_quad = map_to_interval(quad_points)\n        \n        residual_vals = f_func(x_quad) + u_h_poly_d2(x_quad)\n        interior_res_sq_norm = np.sum(quad_weights * (residual_vals**2)) * (h_k / 2.0)\n\n        # Compute spectral smoothness indicator\n        if np.sum(np.abs(coeffs)) > 1e-15:\n            spectral_ratio = np.abs(coeffs[-1]) / np.sum(np.abs(coeffs))\n        else:\n            spectral_ratio = 0.0\n\n        elements_data.append({\n            'interval': interval,\n            'h_k': h_k,\n            'p_k': p_k,\n            'coeffs': coeffs,\n            'u_h_poly_d1': u_h_poly.deriv(1),\n            'interior_res_contrib': h_k**2 * interior_res_sq_norm,\n            'spectral_ratio': spectral_ratio,\n            'jump_res_contrib': 0.0,\n        })\n\n    # Step 2: Compute jump residuals at interior faces\n    for i in range(1, num_elements):\n        # Face at x = mesh_nodes[i]\n        face_loc = mesh_nodes[i]\n        \n        # Element K- to the left\n        elem_minus = elements_data[i-1]\n        # Element K+ to the right\n        elem_plus = elements_data[i]\n        \n        grad_uh_minus = elem_minus['u_h_poly_d1'](face_loc)\n        grad_uh_plus = elem_plus['u_h_poly_d1'](face_loc)\n        \n        jump = grad_uh_plus - grad_uh_minus\n        \n        h_e = 0.5 * (elem_minus['h_k'] + elem_plus['h_k'])\n        \n        jump_term = h_e * jump**2\n        \n        # Distribute jump contribution to neighboring elements\n        elem_minus['jump_res_contrib'] += 0.5 * jump_term\n        elem_plus['jump_res_contrib'] += 0.5 * jump_term\n\n    # Step 3: Finalize indicators and apply marking logic\n    eta_k_list = []\n    for data in elements_data:\n        eta_k_sq = data['interior_res_contrib'] + data['jump_res_contrib']\n        eta_k_list.append(np.sqrt(eta_k_sq))\n    \n    eta_max = np.max(eta_k_list) if eta_k_list else 0.0\n    marks = []\n\n    for i in range(num_elements):\n        data = elements_data[i]\n        eta_k = eta_k_list[i]\n        \n        # Rule 1: No refinement if error is small\n        if eta_max > 0 and eta_k  THETA_NO_REFINEMENT * eta_max:\n            marks.append(2)\n            continue\n            \n        # Rule 2: h- vs p-refinement for elements with significant error\n        total_contrib = data['interior_res_contrib'] + data['jump_res_contrib']\n        if total_contrib > 1e-15:\n            jump_dominance_ratio = data['jump_res_contrib'] / total_contrib\n        else:\n            jump_dominance_ratio = 0.0\n\n        spectral_ratio = data['spectral_ratio']\n\n        if (jump_dominance_ratio > JUMP_DOMINANCE_THRESHOLD or \n            spectral_ratio > SPECTRAL_DECAY_THRESHOLD):\n            marks.append(0)  # h-refinement\n        else:\n            marks.append(1)  # p-refinement\n            \n    return marks\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print results.\n    \"\"\"\n    test_cases = []\n\n    # Test Case 1: Smooth solution\n    f1_u = lambda x: np.sin(np.pi * x)\n    f1_f = lambda x: np.pi**2 * np.sin(np.pi * x)\n    case1 = {\n        'mesh_nodes': np.array([0, 0.25, 0.5, 0.75, 1]),\n        'p_degrees': np.array([2, 2, 2, 2]),\n        'u_func': f1_u,\n        'f_func': f1_f\n    }\n    test_cases.append(case1)\n\n    # Test Case 2: Steep gradient\n    beta, x0 = 300.0, 0.5\n    f2_u = lambda x: np.arctan(beta * (x - x0))\n    f2_f = lambda x: (2 * beta**3 * (x - x0)) / (1 + beta**2 * (x - x0)**2)**2\n    case2 = {\n        'mesh_nodes': np.array([0, 0.25, 0.5, 0.75, 1]),\n        'p_degrees': np.array([2, 2, 2, 2]),\n        'u_func': f2_u,\n        'f_func': f2_f\n    }\n    test_cases.append(case2)\n    \n    # Test Case 3: Mixed smooth and steep\n    gamma, x1 = 80.0, 0.35\n    f3_u = lambda x: np.sin(3 * np.pi * x) + 0.1 * np.arctan(gamma * (x - x1))\n    f3_f = lambda x: 9 * np.pi**2 * np.sin(3 * np.pi * x) + (0.2 * gamma**3 * (x - x1)) / (1 + gamma**2 * (x - x1)**2)**2\n    case3 = {\n        'mesh_nodes': np.array([0, 0.2, 0.4, 0.6, 0.8, 1]),\n        'p_degrees': np.array([1, 3, 2, 1, 4]),\n        'u_func': f3_u,\n        'f_func': f3_f\n    }\n    test_cases.append(case3)\n\n    all_results = []\n    for case in test_cases:\n        result = process_test_case(case['mesh_nodes'], case['p_degrees'], case['u_func'], case['f_func'])\n        all_results.append(result)\n\n    print(all_results)\n\nsolve()\n```", "id": "3412840"}]}