{"hands_on_practices": [{"introduction": "要成功实现高阶数值格式，首先必须深刻理解其精度来源。对于像通量重构（FR）这样的方法，当处理非线性问题时，其精度并不仅仅取决于解的多项式阶数。本练习将引导你进行一项基础的理论分析，探讨体积积分中数值积分（quadrature）不精确所导致的混淆（aliasing）效应，这对于确保计算格式达到其设计的收敛阶至关重要 [@problem_id:3386485]。", "problem": "考虑一维守恒律 $u_{t} + \\partial_{x} f(u) = 0$，其定义在周期性域上，并采用通量重构（FR）方法（也称为通过重构的修正程序（CPR））在均匀的仿射映射单元网格上进行离散化，局部坐标为 $\\xi \\in [-1,1]$。在每个单元上，近似解 $u^{h}(\\xi)$ 由一个关于 $\\xi$ 的 $N$ 次多项式表示，该多项式由高斯-洛巴托-勒让德（GLL）点上的节点值构造。体积项的弱形式采用标准的 FR/DG 分部积分形式，并通过体积求积进行计算。\n\n假设非线性通量为 $f(u) = u^{p}$，其中整数 $p \\geq 2$。对于光滑解，在没有求积混叠并且假设修正函数足够正则的情况下，设计的精度阶为 $N+1$。当所选的求积方法不能精确积分体积项的多项式被积函数时，体积项中就会出现积分不足（混叠），从而将形式精度阶降低到 $N+1$ 以下。\n\n仅使用关于复合和乘法下多项式次数的公认事实，以及具有 $Q$ 个点的高斯-洛巴托-勒让德求积（对次数最高为 $2Q-3$ 的多项式精确）和具有 $M$ 个点的高斯-勒让德求积（对次数最高为 $2M-1$ 的多项式精确）的经典精确性，完成以下任务：\n\n1. 对于最高次数为 $N$ 的测试函数，确定弱形式中每个单元上必须被精确积分的体积被积函数的最大多项式次数。\n2. 解释当 $Q=N+1$ 时，对于 $p \\geq 2$ 的情况，这如何导致混叠，从而将形式精度阶从设计的 $N+1$ 阶降低。\n3. 通过选择一个具有 $M$ 个点的高斯-勒让德体积求积方法，提出一个充分的过积分条件，以确保体积项被精确积分，并恢复设计的 $N+1$ 精度阶。\n\n你的最终答案必须是一个单一的封闭形式解析表达式，给出保证体积项精确积分的最小 $M$（用 $N$ 和 $p$ 表示）。不需要数值近似或四舍五入。", "solution": "该问题陈述经评估是科学上合理、适定、客观且自洽的。它代表了偏微分方程高阶数值方法领域中的一个标准分析问题。所有提供的信息都是真实且与任务相关的。因此，有必要给出完整解答。\n\n一般的一维守恒律由下式给出\n$$\nu_{t} + \\partial_{x} f(u) = 0\n$$\n其中 $u$ 是守恒变量，$f(u)$ 是通量函数。对于本问题，通量被指定为非线性函数 $f(u) = u^{p}$，其中整数 $p \\geq 2$。\n\n区域被离散化为单元。在参考单元上，局部坐标为 $\\xi \\in [-1, 1]$，解 $u^{h}(\\xi)$ 被一个最高次数为 $N$ 的多项式近似。弱形式的测试函数 $v^{h}(\\xi)$ 取自相同的多项式空间，因此 $\\deg(v^{h}) \\leq N$。\n\n控制方程的弱形式，在给定单元 $K$ 上进行分部积分并变换到参考单元后，包含一个形式如下的体积积分项：\n$$\n\\int_{-1}^{1} f(u^{h}(\\xi)) \\frac{d v^{h}}{d \\xi} \\, d\\xi\n$$\n为近似此积分，采用了一种数值求积格式。整个数值方法的精度取决于该求积方法对于特定被积多项式的精确性。被积函数是乘积 $I(\\xi) = f(u^{h}(\\xi)) \\frac{d v^{h}}{d \\xi}$。\n\n**1. 体积被积函数的最大多项式次数**\n\n为了确定求积规则所需的精确性，我们必须首先确定被积函数 $I(\\xi)$ 的最大可能多项式次数。此分析依赖于多项式乘法和复合的基本性质。\n\n- 解的近似 $u^{h}(\\xi)$ 是一个最高次数为 $N$ 的多项式。我们记作 $\\deg(u^{h}) \\leq N$。\n- 通量函数为 $f(u) = u^{p}$。当应用于多项式解近似时，我们得到 $f(u^{h}(\\xi)) = (u^{h}(\\xi))^{p}$。复合多项式的次数是各次数的乘积，所以 $\\deg(f(u^{h})) = p \\cdot \\deg(u^{h})$。因此，最大次数为 $p N$。\n- 测试函数 $v^{h}(\\xi)$ 也是一个最高次数为 $N$ 的多项式，所以 $\\deg(v^{h}) \\leq N$。\n- 它关于局部坐标 $\\xi$ 的导数 $\\frac{d v^{h}}{d \\xi}$ 是一个最高次数为 $N-1$ 的多项式。所以，$\\deg(\\frac{d v^{h}}{d \\xi}) \\leq N-1$。\n- 被积函数 $I(\\xi)$ 是 $f(u^{h}(\\xi))$ 和 $\\frac{d v^{h}}{d \\xi}$ 的乘积。多项式乘积的次数是它们各自次数的和。\n- 因此，被积函数的最大次数为：\n$$\n\\deg(I) = \\deg(f(u^{h})) + \\deg\\left(\\frac{d v^{h}}{d \\xi}\\right) = pN + (N-1) = (p+1)N - 1\n$$\n为了在不引入求积误差的情况下满足弱形式，体积积分必须被精确计算。这需要一个对所有次数最高为 $(p+1)N - 1$ 的多项式都精确的求积规则。\n\n**2. 使用标准 GLL 求积的混叠**\n\n问题陈述指出，一种常见的方法是使用 $Q$ 个高斯-洛巴托-勒让德（GLL）点（其中 $Q = N+1$）进行体积求积。数值求积的经典理论表明，一个具有 $Q$ 个点的 GLL 规则能精确积分次数最高为 $2Q-3$ 的多项式。\n\n- 将 $Q = N+1$ 代入 GLL 精确性公式，我们发现该求积规则对次数最高为以下值的多项式是精确的：\n$$\n2(N+1) - 3 = 2N + 2 - 3 = 2N - 1\n$$\n- 当被积函数的次数超过求积规则精确的次数时，就会发生混叠，这会导致形式精度阶的降低。此条件是：\n$$\n\\deg(I) > 2N - 1\n$$\n- 将第1部分中 $\\deg(I)$ 的表达式代入：\n$$\n(p+1)N - 1 > 2N - 1\n$$\n- 这个不等式简化为：\n$$\n(p+1)N > 2N\n$$\n- 假设一个非平凡的多项式近似空间（即 $N \\geq 1$），我们可以两边同除以 $N$：\n$$\np+1 > 2 \\implies p > 1\n$$\n- 问题指定 $p$ 是一个满足 $p \\geq 2$ 的整数。对于任何这样的 $p$，条件 $p > 1$ 都满足。因此，对于任何形式为 $u^p$（其中 $p \\geq 2$）的非线性通量，体积被积函数的次数 $(p+1)N-1$ 严格大于标准 $Q=N+1$ GLL 求积所能提供的精确次数 $2N-1$。这种不精确的积分会引入混叠误差，从而破坏数值解，并阻止该方法达到其设计的 $N+1$ 精度阶。\n\n**3. 充分的过积分条件**\n\n为了恢复设计的精度阶，体积积分必须被精确计算。这可以通过采用具有足够高精确度的求积规则来实现，这种技术被称为过积分。我们的任务是为一个高斯-勒让德（GL）体积求积找到一个充分的点数 $M$。\n\n- 一个具有 $M$ 个点的 GL 求积规则已知对次数最高为 $2M-1$ 的多项式是精确的。\n- 为确保体积项的精确积分，GL 规则的精确次数必须大于或等于被积多项式的最大次数 $\\deg(I)$。\n- 这给出了条件：\n$$\n2M - 1 \\geq \\deg(I)\n$$\n- 代入推导出的被积函数次数：\n$$\n2M - 1 \\geq (p+1)N - 1\n$$\n- 简化不等式：\n$$\n2M \\geq (p+1)N\n$$\n- 解出 $M$：\n$$\nM \\geq \\frac{(p+1)N}{2}\n$$\n- 由于 $M$ 必须是表示求积点数的整数，满足此条件的最小整数值是不小于 $\\frac{(p+1)N}{2}$ 的最小整数。这由向上取整函数（ceiling function）给出。\n- 保证体积项精确积分所需的最小高斯-勒让德点数为：\n$$\nM_{min} = \\left\\lceil \\frac{(p+1)N}{2} \\right\\rceil\n$$\n选择这样的 $M$ 可以确保体积项积分不会引入混叠误差，这是 FR/CPR 格式对光滑解达到其形式设计精度阶 $N+1$ 的一个必要条件。", "answer": "$$\\boxed{\\left\\lceil \\frac{(p+1)N}{2} \\right\\rceil}$$", "id": "3386485"}, {"introduction": "在确保了方法的精度之后，下一个核心议题是数值稳定性。一个数值格式如果不够稳定，即使理论精度再高，计算结果也可能因误差的无节制增长而变得毫无意义。这项实践将要求你动手编写代码，通过能量分析方法，定量地比较不同节点（solution points）分布对FR格式稳定性的影响 [@problem_id:3386483]。这将帮助你直观地理解理论选择（如高斯点或洛巴托点）如何直接转化为可观测的数值行为。", "problem": "考虑周期性域上的一维线性平流守恒律，\n$$\nu_t + a\\,u_x = 0,\\quad x\\in[0,L],\\ t\\ge 0,\n$$\n其中平流速度 $a>0$ 为常数，且边界条件为周期性。将域离散为 $N$ 个大小为 $h=L/N$ 的均匀单元，并在每个单元内使用参考坐标 $\\xi\\in[-1,1]$ 上的 $p$ 次多项式来近似解。在每个单元内，使用具有 $n=p+1$ 个不同节点 $\\{\\xi_i\\}_{i=1}^n$ 的节点表示法，及其由求积权重定义的相应离散质量矩阵。\n\n通量重构 (Flux Reconstruction, FR) 方法，也称为重构校正程序 (Correction Procedure via Reconstruction, CPR)，通过一个由界面通量差和选定的校正函数构建的校正项，来增强插值通量的节点导数。在具有周期性耦合的强形式、单元形式下，对于 $a>0$（左侧界面为入流），半离散格式可以写作\n$$\n\\frac{d\\mathbf{u}_e}{dt} \\;=\\; -\\frac{2a}{h}\\left( \\mathbf{D}\\,\\mathbf{u}_e \\;+\\; c\\,\\mathbf{g}'_L\\left( u^{\\text{num}}_{e-1,R} - u^{\\text{poly}}_{e,L} \\right)\\right),\n$$\n其中 $\\mathbf{u}_e\\in\\mathbb{R}^n$ 是单元 $e$ 中节点解值的向量，$\\mathbf{D}\\in\\mathbb{R}^{n\\times n}$ 是所选节点的节点微分矩阵，$u^{\\text{poly}}_{e,L}$ 是通过插值获得的左边界值，$u^{\\text{num}}_{e-1,R}$ 是通过数值通量从左相邻单元传入的右边界值，$c$ 是一个标量校正振幅。边界值是通过在 $\\xi=-1$ 和 $\\xi=+1$ 处评估节点 Lagrange 基底得到的。将相应的评估行向量分别表示为 $\\mathbf{v}_L^T$ 和 $\\mathbf{v}_R^T$，因此对于 $a>0$ 的迎风格式，有 $u^{\\text{poly}}_{e,L}=\\mathbf{v}_L^T\\mathbf{u}_e$ 和 $u^{\\text{num}}_{e-1,R}=\\mathbf{v}_R^T\\mathbf{u}_{e-1}$。离散质量矩阵 $\\mathbf{M}\\in\\mathbb{R}^{n\\times n}$ 定义为与所选节点分布相关联的求积权重的对角矩阵，它提供了离散内积 $\\langle \\mathbf{u},\\mathbf{v}\\rangle_{\\mathbf{M}}=\\mathbf{u}^T\\mathbf{M}\\mathbf{v}$。\n\n您将比较三种节点分布：\n- Legendre–Gauss 节点及其精确的 Gauss 求积权重。\n- Legendre–Gauss–Lobatto 节点及 Lobatto 求积权重。\n- $[-1,1]$ 上的等距节点，其闭式 Newton–Cotes 求积权重由对最高为 $n-1$ 次的多项式精确积分确定。\n\n对于左侧界面的校正函数，选择由下式定义的唯一的 $p+1$ 次多项式\n$$\ng_L(\\xi) = s_p\\;\\frac{1-\\xi}{2}\\;P_p(\\xi),\\quad s_p := \\frac{1}{P_p(-1)} = (-1)^p,\n$$\n其中 $P_p(\\xi)$ 是 $p$ 次 Legendre 多项式。这种选择强制 $g_L(-1)=1$，$g_L(+1)=0$，并产生一个非恒定的导数\n$$\ng_L'(\\xi) = s_p\\left[ -\\frac{1}{2}P_p(\\xi) + \\frac{1-\\xi}{2}P_p'(\\xi)\\right],\n$$\n其节点采样产生用于 FR 校正的向量 $\\mathbf{g}'_L\\in\\mathbb{R}^n$。\n\n定义全局半离散算子 $\\mathbf{A}\\in\\mathbb{R}^{(Nn)\\times(Nn)}$，该算子用于推进由所有单元节点状态 $\\{\\mathbf{u}_e\\}_{e=0}^{N-1}$ 堆叠而成的拼接状态 $\\mathbf{U}\\in\\mathbb{R}^{Nn}$。在周期性耦合下，该算子具有块结构，其中单元内项涉及 $\\mathbf{D}$，而单元间入流耦合通过 $\\mathbf{g}'_L\\mathbf{v}_R^T$ 实现。设全局块对角质量矩阵为 $\\mathbf{M}_{\\text{glob}}=\\operatorname{diag}(\\mathbf{M},\\dots,\\mathbf{M})\\in\\mathbb{R}^{(Nn)\\times(Nn)}$。\n\n作为基于 $\\mathbf{M}_{\\text{glob}}$ 内积能量的稳定性度量，考虑对称算子\n$$\n\\mathbf{S}_{\\mathbf{M}} = \\frac{1}{2}\\left(\\mathbf{M}_{\\text{glob}}\\mathbf{A} + \\mathbf{A}^T\\mathbf{M}_{\\text{glob}}\\right).\n$$\n其关于 $\\mathbf{M}_{\\text{glob}}$ 的广义特征值表征了瞬时能量增长率：最大特征值的非正性意味着离散能量不增加。为了比较节点分布，您必须：\n1. 对于每种节点分布和给定的 $(p,N)$，在长度为 $L=1$ 的周期域上使用 $a>0$ 的迎风数值通量来构造 $\\mathbf{A}$。\n2. 计算 $\\mathbf{S}_{\\mathbf{M}}$ 关于 $\\mathbf{M}_{\\text{glob}}$ 的最大广义特征值，这等价于对称矩阵 $\\mathbf{C}=\\mathbf{M}_{\\text{glob}}^{-1/2}\\mathbf{S}_{\\mathbf{M}}\\mathbf{M}_{\\text{glob}}^{-1/2}$ 的最大特征值，并将其作为一个实数标量稳定性指标。\n3. 为每种节点分布推导一个校正缩放律 $c_{\\text{norm}}$，通过要求导数校正向量的 $\\mathbf{M}$-加权范数在不同节点集之间相等，来归一化离散质量矩阵在 $n$ 个点上的影响。具体来说，为每个节点集 $S$ 选择\n$$\nc_{\\text{norm}}^{(S)} \\ \\text{such that}\\ \\ \\left\\|\\mathbf{g}'_L\\right\\|_{\\mathbf{M}^{(S)}} \\, c_{\\text{norm}}^{(S)} \\ = \\ \\left\\|\\mathbf{g}'_L\\right\\|_{\\mathbf{M}^{(\\text{ref})}},\n$$\n其中 $\\|\\mathbf{w}\\|_{\\mathbf{M}} := \\sqrt{\\mathbf{w}^T\\mathbf{M}\\mathbf{w}}$ 且 $(\\text{ref})$ 表示一个固定的参考节点集。在此任务中，使用 Legendre–Gauss–Lobatto 作为参考。通过将校正振幅 $c$ 乘以 $c_{\\text{norm}}^{(S)}$，在 FR 算子中实现这种归一化。\n4. 量化归一化前后节点分布对稳定性度量的影响。\n\n您的程序必须实现以上内容，并为以下测试套件生成数值结果，其中 $a=1$ 且 $L=1$：\n- 测试用例 1：$p=2$, $N=10$。\n- 测试用例 2：$p=3$, $N=8$。\n- 测试用例 3：$p=5$, $N=6$。\n\n对于每个测试用例，并按 Legendre–Gauss、Legendre–Gauss–Lobatto、等距节点的顺序，为每种节点分布计算两个实数：\n- 使用 $c=1$（无归一化）时 $\\mathbf{C}$ 的最大特征值。\n- 使用上面推导的归一化校正振幅 $c=c_{\\text{norm}}^{(S)}$ 时 $\\mathbf{C}$ 的最大特征值。\n\n最终输出格式必须是单行，包含一个由三个列表组成的列表，每个子列表对应一个测试用例。每个内部列表必须按顺序包含六个浮点数\n$$\n\\big[\\lambda_{\\max}^{\\text{Gauss}},\\ \\lambda_{\\max}^{\\text{Lobatto}},\\ \\lambda_{\\max}^{\\text{Equid}},\\ \\lambda_{\\max,\\text{norm}}^{\\text{Gauss}},\\ \\lambda_{\\max,\\text{norm}}^{\\text{Lobatto}},\\ \\lambda_{\\max,\\text{norm}}^{\\text{Equid}}\\big],\n$$\n其中每个 $\\lambda_{\\max}$ 是指定配置下 $\\mathbf{C}$ 的最大特征值。该行必须精确地打印为 Python 的列表的列表，例如：\n$$\n\\texttt{[[x_{11},x_{12},x_{13},x_{14},x_{15},x_{16}],[x_{21},\\dots,x_{26}],[x_{31},\\dots,x_{36}]]}\n$$\n此问题不涉及单位。不使用角度。不使用百分比。", "solution": "用户希望分析用于求解一维线性平流方程的通量重构（FR）/ 重构校正程序（CPR）方法的稳定性。该分析涉及比较每个单元内的三种不同节点集：Legendre-Gauss (LG)、Legendre-Gauss-Lobatto (LGL) 和等距节点。稳定性将通过计算从半离散系统导出的特定对称化算子的最大特征值来量化。该问题还要求推导并应用一个归一化因子到校正项，以确保不同节点分布之间的公平比较。\n\n### **问题验证**\n\n**步骤 1：提取已知条件**\n\n- **守恒律**：$u_t + a\\,u_x = 0$，对于 $x\\in[0,L]$, $t\\ge 0$。\n- **平流速度**：常数 $a>0$。\n- **边界条件**：在 $[0,L]$ 上周期性。\n- **离散化**：$N$ 个均匀单元，大小 $h=L/N$。\n- **近似**：在参考单元 $\\xi\\in[-1,1]$ 中，使用 $p$ 次多项式，基于 $n=p+1$ 个节点 $\\{\\xi_i\\}_{i=1}^n$。\n- **节点集**：\n  1. Legendre-Gauss (LG) 节点和权重。\n  2. Legendre-Gauss-Lobatto (LGL) 节点和权重。\n  3. 等距节点，使用闭式 Newton-Cotes 权重（对于最高 $n-1$ 次多项式精确）。\n- **半离散 FR/CPR 格式**：$\\frac{d\\mathbf{u}_e}{dt} = -\\frac{2a}{h}\\left( \\mathbf{D}\\,\\mathbf{u}_e + c\\,\\mathbf{g}'_L\\left( u^{\\text{num}}_{e-1,R} - u^{\\text{poly}}_{e,L} \\right)\\right)$。\n- **FR 格式中的项**：\n  - $\\mathbf{u}_e$：单元 $e$ 中的节点解值向量。\n  - $\\mathbf{D}$：节点微分矩阵。\n  - $u^{\\text{poly}}_{e,L} = \\mathbf{v}_L^T\\mathbf{u}_e$：在左边界（$\\xi=-1$）的插值解。\n  - $u^{\\text{num}}_{e-1,R} = \\mathbf{v}_R^T\\mathbf{u}_{e-1}$：来自左相邻单元右边界的数值通量（$a>0$ 的迎风格式）。\n  - $c$：标量校正振幅。\n  - $\\mathbf{g}'_L$：校正函数 $g_L(\\xi)$ 导数的节点值向量。\n- **校正函数**：$g_L(\\xi) = s_p\\;\\frac{1-\\xi}{2}\\;P_p(\\xi)$，其中 $s_p = (-1)^p$，$P_p(\\xi)$ 为 $p$ 次 Legendre 多项式。\n- **质量矩阵**：$\\mathbf{M}$ 是求积权重的对角矩阵。全局质量矩阵为 $\\mathbf{M}_{\\text{glob}}=\\operatorname{diag}(\\mathbf{M},\\dots,\\mathbf{M})$。\n- **稳定性度量**：对称矩阵 $\\mathbf{C}=\\mathbf{M}_{\\text{glob}}^{-1/2}\\mathbf{S}_{\\mathbf{M}}\\mathbf{M}_{\\text{glob}}^{-1/2}$ 的最大特征值，其中 $\\mathbf{S}_{\\mathbf{M}} = \\frac{1}{2}\\left(\\mathbf{M}_{\\text{glob}}\\mathbf{A} + \\mathbf{A}^T\\mathbf{M}_{\\text{glob}}\\right)$，而 $\\mathbf{A}$ 是全局半离散算子（$\\frac{d\\mathbf{U}}{dt} = \\mathbf{A}\\mathbf{U}$）。\n- **校正归一化**：为每个节点集 $S$ 确定 $c_{\\text{norm}}^{(S)}$，使得 $\\left\\|\\mathbf{g}'_L\\right\\|_{\\mathbf{M}^{(S)}} \\, c_{\\text{norm}}^{(S)} = \\left\\|\\mathbf{g}'_L\\right\\|_{\\mathbf{M}^{(\\text{ref})}}$，其中参考集为 LGL。范数为 $\\|\\mathbf{w}\\|_{\\mathbf{M}} = \\sqrt{\\mathbf{w}^T\\mathbf{M}\\mathbf{w}}$。\n- **常数**：$a=1$, $L=1$。\n- **测试用例**：$(p=2, N=10)$；$(p=3, N=8)$；$(p=5, N=6)$。\n- **要求输出**：对于每个测试用例，一个包含六个特征值的列表：$[\\lambda_{\\max}^{\\text{LG}}, \\lambda_{\\max}^{\\text{LGL}}, \\lambda_{\\max}^{\\text{Equid}}]$（$c=1$），后跟 $[\\lambda_{\\max,\\text{norm}}^{\\text{LG}}, \\lambda_{\\max,\\text{norm}}^{\\text{LGL}}, \\lambda_{\\max,\\text{norm}}^{\\text{Equid}}]$（$c=c_{\\text{norm}}$）。\n\n**步骤 2：使用提取的已知条件进行验证**\n\n对照验证标准检查问题陈述。\n\n- **科学基础**：该问题是偏微分方程高阶数值方法领域的标准练习，特别关注 FR/CPR 公式的谱特性。所有概念（节点基、微分矩阵、FR 校正、能量稳定性分析）在科学文献中都是公认的。\n- **适定性**：该问题在数学上和算法上都是明确定义的。构造算子和后续特征值分析所需的所有组件都已指定。这些任务会导向一组唯一的数值结果。\n- **客观性**：问题以精确、客观的数学语言陈述，没有歧义或主观性。\n- **缺陷清单**：\n  1.  **科学/事实不健全**：无。公式是正确的。\n  2.  **非形式化/不相关**：无。该问题是一个形式化的数值分析任务，与其陈述的主题直接相关。\n  3.  **不完整/矛盾的设置**：无。所有关于节点、权重、矩阵和算子的必要定义均已提供，或可从标准原理中唯一推导得出。\n  4.  **不切实际/不可行**：无。该问题是一个具有可行参数的标准数值实验。\n  5.  **不适定/结构不良**：无。问题结构良好，可导向一个唯一、有意义的数值解（特征值集合）。\n  6.  **伪深奥/琐碎**：无。该问题需要对数值分析和线性代数中的几个概念进行非琐碎的实现，代表了一项合理的计算任务。\n  7.  **超出科学可验证性**：无。结果可通过数值计算得出，并可独立验证。\n\n**步骤 3：结论与行动**\n\n问题是**有效的**。将提供完整的解决方案。\n\n### **求解方法论**\n\n解决方案要求为多项式次数 p、单元数 N 和节点分布的各种配置，构建全局半离散算子 $\\mathbf{A}$ 和全局质量矩阵 $\\mathbf{M}_{\\text{glob}}$。每个配置的核心步骤是：\n\n1.  **生成节点数据**：对于每个节点集 (LG, LGL, 等距) 和 $n=p+1$ 个点：\n    -   计算节点位置 $\\{\\xi_i\\}_{i=1}^n \\in [-1, 1]$。\n    -   计算相应的求积权重 $\\{w_i\\}_{i=1}^n$。这些权重构成单元质量矩阵 $\\mathbf{M}$ 的对角线。\n\n2.  **构建单元矩阵**：\n    -   **微分矩阵 ($\\mathbf{D}$)**：计算 $n \\times n$ 矩阵，其中 $D_{ij} = \\ell_j'(\\xi_i)$，$\\ell_j$ 是第 $j$ 个 Lagrange 多项式。将采用一种使用重心权重的稳定方法。\n    -   **边界求值向量 ($\\mathbf{v}_L^T, \\mathbf{v}_R^T$)**：这些是分别包含 Lagrange 基函数在 $\\xi=-1$ 和 $\\xi=1$ 处值的行向量。对于包含端点的 LGL 节点，这些向量是平凡的（例如，$\\mathbf{v}_L^T = [1, 0, \\dots, 0]$）。对于其他节点，必须进行计算。\n    -   **校正函数向量 ($\\mathbf{g}'_L$)**：在每个节点 $\\xi_i$ 处评估指定校正函数 $g_L'(\\xi) = (-1)^p\\left[ -\\frac{1}{2}P_p(\\xi) + \\frac{1-\\xi}{2}P_p'(\\xi)\\right]$ 的导数，以形成向量 $\\mathbf{g}'_L$。\n\n3.  **归一化因子计算**：\n    -   对于每个节点集 $S \\in \\{\\text{LG, LGL, 等距}\\}$，计算归一化因子 $c_{\\text{norm}}^{(S)} = \\frac{\\|\\mathbf{g}'_L\\|_{\\mathbf{M}^{(\\text{LGL})}}}{\\|\\mathbf{g}'_L\\|_{\\mathbf{M}^{(S)}}}}$。参考范数使用给定次数 $p$ 的 LGL 节点和权重计算。$\\mathbf{M}$-范数为 $\\|\\mathbf{w}\\|_{\\mathbf{M}} = \\sqrt{\\mathbf{w}^T \\mathbf{M} \\mathbf{w}}$。根据定义，$c_{\\text{norm}}^{(\\text{LGL})} = 1$。\n\n4.  **组装全局算子 ($\\mathbf{A}$)**：\n    -   全局算子 $\\mathbf{A}$ 是一个 $(Nn) \\times (Nn)$ 的块循环矩阵。其定义源于将数值通量代入 FR 格式：\n      $$ \\frac{d\\mathbf{u}_e}{dt} = -\\frac{2a}{h}\\left( (\\mathbf{D} - c\\mathbf{g}'_L\\mathbf{v}_L^T)\\mathbf{u}_e + (c\\mathbf{g}'_L\\mathbf{v}_R^T)\\mathbf{u}_{e-1} \\right) $$\n    -   对角块为 $\\mathbf{A}_{ee} = -\\frac{2a}{h}(\\mathbf{D} - c\\mathbf{g}'_L\\mathbf{v}_L^T)$。\n    -   次对角块（以及由于周期性而产生的右上角块）为 $\\mathbf{A}_{e,e-1} = -\\frac{2a}{h}(c\\mathbf{g}'_L\\mathbf{v}_R^T)$。\n    -   此过程对 $c=1$ 和 $c=c_{\\text{norm}}^{(S)}$ 都执行。\n\n5.  **计算稳定性度量**：\n    -   将全局质量矩阵 $\\mathbf{M}_{\\text{glob}}$ 构建为单元质量矩阵 $\\mathbf{M}$ 的块对角矩阵。\n    -   构造质量缩放算子的对称部分：$\\mathbf{S}_{\\mathbf{M}} = \\frac{1}{2}(\\mathbf{M}_{\\text{glob}}\\mathbf{A} + \\mathbf{A}^T\\mathbf{M}_{\\text{glob}})$。\n    -   为了找到 $(\\mathbf{S_M}, \\mathbf{M}_{\\text{glob}})$ 的广义特征值，我们求解对称矩阵 $\\mathbf{C} = \\mathbf{M}_{\\text{glob}}^{-1/2} \\mathbf{S_M} \\mathbf{M}_{\\text{glob}}^{-1/2}$ 的等价标准特征值问题。\n    -   计算 $\\mathbf{C}$ 的最大特征值。由于 $\\mathbf{C}$ 是对称的，其特征值为实数，可以使用高效的算法。非正值意味着能量不增加（稳定）。\n\n整个过程对每个测试用例 $(p, N)$ 和三种节点分布中的每一种都重复进行。", "answer": "```python\nimport numpy as np\nfrom scipy.special import legendre, roots_legendre, roots_jacobi\nfrom scipy.linalg import eigh\n\ndef get_nodes_and_weights(n, node_type):\n    \"\"\"\n    Computes nodal points and quadrature weights for a given type.\n    n: number of points (p+1)\n    node_type: 'gauss', 'lobatto', or 'equidistant'\n    \"\"\"\n    if node_type == 'gauss':\n        nodes, weights = roots_legendre(n)\n        return np.array(nodes), np.array(weights)\n    elif node_type == 'lobatto':\n        p = n - 1\n        if n == 1:\n            return np.array([0.0]), np.array([2.0])\n        if n == 2:\n            return np.array([-1.0, 1.0]), np.array([1.0, 1.0])\n        \n        interior_nodes, _ = roots_jacobi(n - 2, 1, 1)\n        nodes = np.concatenate(([-1.0], np.sort(interior_nodes), [1.0]))\n        \n        P_p = legendre(p)\n        weights = 2.0 / (n * p * P_p(nodes)**2)\n        return nodes, weights\n    elif node_type == 'equidistant':\n        nodes = np.linspace(-1.0, 1.0, n)\n        # Newton-Cotes weights by solving Vandermonde system\n        V = np.vander(nodes, n, increasing=True)\n        rhs = np.zeros(n)\n        for i in range(n):\n            rhs[i] = (1.0 - (-1.0)**(i + 1)) / (i + 1)\n        weights = np.linalg.solve(V.T, rhs)\n        return nodes, weights\n    else:\n        raise ValueError(f\"Unknown node type: {node_type}\")\n\ndef lagrange_diff_matrix(nodes):\n    \"\"\"\n    Computes the differentiation matrix using the barycentric formula.\n    \"\"\"\n    n = len(nodes)\n    D = np.zeros((n, n))\n    \n    # Barycentric weights\n    w = np.ones(n)\n    for j in range(n):\n        for k in range(n):\n            if k != j:\n                w[j] *= (nodes[j] - nodes[k])\n    w = 1.0 / w\n    \n    for i in range(n):\n        for j in range(n):\n            if i != j:\n                D[i, j] = (w[j] / w[i]) / (nodes[i] - nodes[j])\n                \n    for i in range(n):\n        D[i, i] = -np.sum(D[i, :])\n    return D\n\ndef get_boundary_vectors(nodes):\n    \"\"\"\n    Computes Lagrange basis evaluation vectors at xi = -1 and xi = 1.\n    \"\"\"\n    n = len(nodes)\n    # Check if nodes are Lobatto type (endpoints included)\n    if np.isclose(nodes[0], -1.0) and np.isclose(nodes[-1], 1.0):\n        vL = np.zeros(n)\n        vL[0] = 1.0\n        vR = np.zeros(n)\n        vR[-1] = 1.0\n        return vL, vR\n    \n    # Otherwise, compute via explicit Lagrange polynomial evaluation.\n    def lagrange_eval(x, j, eval_nodes):\n        num, den = 1.0, 1.0\n        for m, xm in enumerate(eval_nodes):\n            if m != j:\n                num *= (x - xm)\n                den *= (eval_nodes[j] - xm)\n        return num / den\n\n    vL = np.array([lagrange_eval(-1.0, j, nodes) for j in range(n)])\n    vR = np.array([lagrange_eval(1.0, j, nodes) for j in range(n)])\n    return vL, vR\n\ndef get_correction_vector(p, nodes):\n    \"\"\"\n    Computes the nodal vector for the derivative of the g_L correction function.\n    \"\"\"\n    sp = (-1.0)**p\n    Pp = legendre(p)\n    Pp_prime = Pp.deriv(1)\n    \n    g_prime_vals = sp * (-0.5 * Pp(nodes) + 0.5 * (1.0 - nodes) * Pp_prime(nodes))\n    return g_prime_vals\n\ndef compute_max_eigenvalue(A, M_glob):\n    \"\"\"\n    Computes the largest generalized eigenvalue of (S_M, M_glob).\n    \"\"\"\n    S_M = 0.5 * (M_glob @ A + A.T @ M_glob)\n    # Using scipy.linalg.eigh for generalized symmetric eigenproblem\n    # It is generally more stable than forming C explicitly.\n    # It returns eigenvalues in ascending order.\n    eigvals = eigh(S_M, M_glob, eigvals_only=True)\n    return eigvals[-1]\n\ndef solve_one_case(p, N, a, L):\n    \"\"\"\n    Solves the problem for one (p, N) test case.\n    \"\"\"\n    n = p + 1\n    h = L / N\n    \n    node_types = ['gauss', 'lobatto', 'equidistant']\n    \n    # Calculate normalization constants\n    ref_nodes, ref_weights = get_nodes_and_weights(n, 'lobatto')\n    ref_g_prime = get_correction_vector(p, ref_nodes)\n    ref_M_elem = np.diag(ref_weights)\n    norm_ref = np.sqrt(ref_g_prime.T @ ref_M_elem @ ref_g_prime)\n    \n    c_norms = {}\n    for nt in node_types:\n        nodes_s, weights_s = get_nodes_and_weights(n, nt)\n        g_prime_s = get_correction_vector(p, nodes_s)\n        M_elem_s = np.diag(weights_s)\n        norm_s = np.sqrt(g_prime_s.T @ M_elem_s @ g_prime_s)\n        c_norms[nt] = norm_ref / norm_s if norm_s > 1e-15 else 1.0\n\n    unnormalized_eigs = []\n    normalized_eigs = []\n\n    for node_type in node_types:\n        nodes, weights = get_nodes_and_weights(n, node_type)\n        D = lagrange_diff_matrix(nodes)\n        M_elem = np.diag(weights)\n        vL_T, vR_T = get_boundary_vectors(nodes)\n        g_prime_vec = get_correction_vector(p, nodes)\n        \n        # Calculate for both c=1 and c=c_norm\n        for c_val, eig_list in zip([1.0, c_norms[node_type]], [unnormalized_eigs, normalized_eigs]):\n            dof = N * n\n            \n            # semi-discrete operator blocks\n            prefactor = -2.0 * a / h\n            A_diag_block = prefactor * (D - c_val * np.outer(g_prime_vec, vL_T))\n            A_offdiag_block = prefactor * (c_val * np.outer(g_prime_vec, vR_T))\n            \n            # Assemble global operator A\n            A = np.zeros((dof, dof))\n            for e in range(N):\n                e_slice = slice(e * n, (e + 1) * n)\n                em1 = (e - 1 + N) % N\n                em1_slice = slice(em1 * n, (em1 + 1) * n)\n                \n                A[e_slice, e_slice] = A_diag_block\n                A[e_slice, em1_slice] = A_offdiag_block\n                \n            M_glob = np.kron(np.eye(N), M_elem)\n            \n            max_eig = compute_max_eigenvalue(A, M_glob)\n            eig_list.append(max_eig)\n\n    return unnormalized_eigs + normalized_eigs\n\ndef solve():\n    \"\"\"\n    Main driver function to run test cases and print results.\n    \"\"\"\n    test_cases = [\n        (2, 10),  # p, N\n        (3, 8),\n        (5, 6),\n    ]\n    a = 1.0\n    L = 1.0\n    \n    final_results = []\n    for p, N in test_cases:\n        case_results = solve_one_case(p, N, a, L)\n        final_results.append(case_results)\n        \n    # The output format must be a Python list of lists.\n    # str(list) provides the canonical representation.\n    # The example in the prompt `[[x11,x12,...]]` has no spaces.\n    # We will remove them to match the example's formatting precisely.\n    print(str(final_results).replace(\" \", \"\"))\n\nsolve()\n\n```", "id": "3386483"}, {"introduction": "一个精确且稳定的数值算法仅仅是成功的一半，在现代计算科学中，实现高性能同样至关重要。本练习将你的视角从数值分析理论转向高性能计算实践，特别是针对图形处理器（GPU）的优化。你将通过一个性能模型来分析FR方法中关键的修正步骤，并探讨数据在内存中的布局方式和计算内核的执行顺序如何深刻影响程序的运行速度 [@problem_id:3386482]。这项技能对于将先进的数值方法应用于大规模科学与工程计算中是不可或缺的。", "problem": "考虑通量重构（FR）方法中的校正步骤，该步骤也称为通过重构的校正过程（CPR）。在一维空间中，设每个单元上的多项式次数为 $p$，每个单元的解点数为 $n_p = p + 1$。对于单元索引 $e \\in \\{0,1,\\dots,E-1\\}$ 和节点索引 $i \\in \\{0,1,\\dots,n_p-1\\}$，半离散残差 $R[e,i]$ 的标准FR校正可以写成以下形式：\n$$\nR[e,i] \\leftarrow R[e,i] + G_L[i]\\cdot J_L[e] + G_R[i]\\cdot J_R[e],\n$$\n其中 $G_L[i]$ 和 $G_R[i]$ 是校正函数的节点值，$J_L[e]$ 和 $J_R[e]$ 是每个单元的界面跳跃贡献。此更新应用于所有 $E \\cdot n_p$ 个自由度，是一个复杂度为 $O(N)$ 的核函数，其中 $N = E \\cdot n_p$。\n\n你的任务是为FR校正建立两种图形处理单元（GPU）核函数执行顺序的模型，并分析重新排序计算如何影响内存合并和占用率，进而影响预测的运行时间。定义两种执行顺序：\n- 顺序A（元素主序遍历）：每个线程块更新一个单元；线程遍历节点索引 $i$。\n- 顺序B（节点主序遍历）：每个线程块更新跨多个单元的同一个节点索引 $i$；线程遍历单元索引 $e$。\n\n假设残差数组 $R$ 具有以下内存布局：\n- 元素主序布局（EM）：扁平化索引 $k = e \\cdot n_p + i$。\n- 节点主序布局（NM）：扁平化索引 $k = i \\cdot E + e$。\n\n对于两种执行顺序，假设每个线程在校正步骤中执行以下操作：\n- 算术：$c_{op} = 4$ 次浮点运算（两次乘法和两次加法）。\n- 内存：\n  - 为 $G_L[i], G_R[i]$ 读取两个双精度浮点数，总字节数为 $b_G = 16$（假设可完美缓存，因此完全合并）。\n  - 为 $J_L[e], J_R[e]$ 读取两个双精度浮点数，总字节数为 $b_J = 16$（假设在线程块内广播，因此完全合并）。\n  - 为 $R[e,i]$ 读-修改-写一个双精度浮点数，总字节数为 $b_R = 16$（这是唯一其内存合并依赖于执行顺序和布局的内存访问）。\n\n假设使用以下性能模型：\n- 线程束大小 $W = 32$。\n- 对于 $R$ 的访问，定义步幅 $s$ 为一个线程束中连续线程访问地址之间的差值（以双精度浮点数为单位）。$R$ 访问的合并效率建模为：\n$$\n\\epsilon(s) = \\begin{cases}\n1/s, & 1 \\le s \\le W,\\\\\n1/W, & s \\ge W,\n\\end{cases}\n$$\n并且该效率仅应用于 $b_R$ 的贡献。所有其他字节均被视为完全合并，效率为 $1$。\n- 执行顺序、布局和 $R$ 步幅之间的映射关系：\n  - 对于元素主序布局（EM）：顺序A的步幅为 $s_A = 1$，顺序B的步幅为 $s_B = n_p$。\n  - 对于节点主序布局（NM）：顺序A的步幅为 $s_A = E$，顺序B的步幅为 $s_B = 1$。\n- 流式多处理器（SM）资源限制：\n  - 每个SM的最大线程数 $T_{SM}$，\n  - 每个SM的最大线程束数 $W_{SM}$，\n  - 每个SM的最大常驻线程块数 $B_{SM}$，\n  - 每个SM的寄存器文件大小 $R_{SM}$（以寄存器为单位），\n  - 每个SM的共享内存大小 $S_{SM}$（以字节为单位）。\n- 核函数资源使用情况：\n  - 每个线程块的线程数 $T_b$，\n  - 每个线程的寄存器数 $R_t$，\n  - 每个线程块的共享内存大小 $S_b$。\n- 每个SM的占用率推导：\n  - 每个线程块的线程束数 $w_b = \\lceil T_b / W \\rceil$，\n  - 由线程数限制的线程块数 $B_T = \\left\\lfloor \\dfrac{T_{SM}}{T_b} \\right\\rfloor$，\n  - 由线程束数限制的线程块数 $B_W = \\left\\lfloor \\dfrac{W_{SM}}{w_b} \\right\\rfloor$，\n  - 由寄存器数限制的线程块数 $B_R = \\left\\lfloor \\dfrac{R_{SM}}{R_t \\cdot T_b} \\right\\rfloor$，\n  - 由共享内存限制的线程块数 $B_S = \\left\\lfloor \\dfrac{S_{SM}}{S_b} \\right\\rfloor$（若 $S_b > 0$），否则为 $+\\infty$，\n  - 常驻线程块数 $B_{res} = \\min\\{B_{SM}, B_T, B_W, B_R, B_S\\}$，\n  - 活动线程束数 $W_{act} = B_{res} \\cdot w_b$，\n  - 占用率 $\\mathrm{occ} = \\min\\left(1, \\dfrac{W_{act}}{W_{SM}}\\right)$。\n- 设备峰值计算吞吐量 $P_{peak}$（单位：浮点运算/秒）。\n- 设备峰值内存带宽 $B_{peak}$（单位：字节/秒）。\n- 对于总未知量 $N = E \\cdot n_p$，计算时间建模为\n$$\nt_{comp} = \\frac{N \\cdot c_{op}}{P_{peak} \\cdot \\mathrm{occ}},\n$$\n内存时间建模为\n$$\nt_{mem} = N \\cdot \\left(\\frac{b_R}{B_{peak} \\cdot \\epsilon(s)} + \\frac{b_G + b_J}{B_{peak}}\\right).\n$$\n- 核函数时间是计算时间和内存时间的最大值：\n$$\nt = \\max\\{t_{comp}, t_{mem}\\}.\n$$\n\n你的任务是编写一个程序，该程序针对一个小型测试套件，为每种情况计算通过重新排序FR校正核函数以最大化内存合并所带来的预测加速比，即较慢执行顺序的预测运行时间与较快执行顺序的预测运行时间之比。对每个测试，考虑在指定的布局和硬件约束下，顺序A和顺序B两种情况，并返回较优顺序相对于较差顺序的加速比。\n\n在所有测试中使用以下固定的硬件参数：\n- 线程束大小 $W = 32$，\n- 每个SM的最大线程数 $T_{SM} = 2048$，\n- 每个SM的最大线程束数 $W_{SM} = 64$，\n- 每个SM的最大常驻线程块数 $B_{SM} = 32$，\n- 每个SM的寄存器文件大小 $R_{SM} = 65536$，\n- 每个SM的共享内存大小 $S_{SM} = 65536$ 字节，\n- 设备峰值计算吞吐量 $P_{peak} = 10^{13}$ 浮点运算/秒，\n- 设备峰值内存带宽 $B_{peak} = 6 \\times 10^{11}$ 字节/秒。\n\n在所有测试中使用以下固定的核函数级参数：\n- 每个线程的操作计数 $c_{op} = 4$ 次浮点运算，\n- 每个线程的字节计数 $b_G = 16$, $b_J = 16$, $b_R = 16$。\n\n测试套件：\n- 测试 $1$（理想情况，元素主序布局有利于元素主序遍历）：\n  - $E = 4096$, $p = 7$（因此 $n_p = 8$），布局 $\\text{EM}$，\n  - 顺序 A: $T_b = 32$, $R_t = 48$, $S_b = 0$，\n  - 顺序 B: $T_b = 256$, $R_t = 64$, $S_b = 0$。\n- 测试 $2$（布局翻转，节点主序布局有利于节点主序遍历）：\n  - $E = 4096$, $p = 7$（因此 $n_p = 8$），布局 $\\text{NM}$，\n  - 顺序 A: $T_b = 32$, $R_t = 48$, $S_b = 0$，\n  - 顺序 B: $T_b = 256$, $R_t = 64$, $S_b = 0$。\n- 测试 $3$（寄存器压力边界，大 $p$ 值）：\n  - $E = 8192$, $p = 31$（因此 $n_p = 32$），布局 $\\text{EM}$，\n  - 顺序 A: $T_b = 32$, $R_t = 128$, $S_b = 0$，\n  - 顺序 B: $T_b = 256$, $R_t = 64$, $S_b = 0$。\n- 测试 $4$（小问题规模边界情况）：\n  - $E = 16$, $p = 1$（因此 $n_p = 2$），布局 $\\text{NM}$，\n  - 顺序 A: $T_b = 32$, $R_t = 24$, $S_b = 0$，\n  - 顺序 B: $T_b = 64$, $R_t = 24$, $S_b = 0$。\n- 测试 $5$（顺序A的共享内存占用率限制）：\n  - $E = 2048$, $p = 15$（因此 $n_p = 16$），布局 $\\text{EM}$，\n  - 顺序 A: $T_b = 32$, $R_t = 48$, $S_b = 32768$，\n  - 顺序 B: $T_b = 256$, $R_t = 32$, $S_b = 0$。\n\n对于每个测试，使用上述模型计算预测的运行时间 $t_A$ 和 $t_B$，然后计算加速比为\n$$\nS = \\frac{\\max\\{t_A, t_B\\}}{\\min\\{t_A, t_B\\}}.\n$$\n\n你的程序应生成单行输出，其中包含测试1到5的五个加速比，以逗号分隔的列表形式包含在方括号内，每个加速比四舍五-入到六位小数（例如，$[1.234567,2.000000, \\dots]$）。不涉及角度，因此不需要角度单位。输出中无需报告物理单位；数值是无量纲的比率。", "solution": "该问题要求对通量重构（FR）方法中校正步骤的GPU核函数性能进行分析。具体来说，我们需要在残差数组 $R$ 的两种不同内存布局下——元素主序（EM）和节点主序（NM）——对两种不同的计算顺序（称为顺序A，即元素主序；和顺序B，即节点主序）的运行时间进行建模。目标是预测在给定布局和一组核函数参数的情况下，通过选择性能更优的执行顺序所能获得的加速比。\n\n解决方案涉及逐步应用所提供的性能模型。对于每个测试用例，我们必须计算顺序A和顺序B的预测运行时间 $t$。运行时间定义为计算受限时间 $t_{comp}$ 和内存受限时间 $t_{mem}$ 的最大值。加速比 $S$ 则是较大运行时间与较小运行时间之比。\n\n对于每种执行顺序，计算过程如下：\n\n首先，我们确定占用率 $\\mathrm{occ}$，它表示在给定的核函数启动配置下，流式多处理器（SM）的计算资源被有效利用的比例。占用率受到最受限资源的限制，无论是线程、线程束、寄存器还是共享内存。问题陈述中定义了以下量：\n- 线程束大小: $W$\n- 每个SM的最大线程数: $T_{SM}$\n- 每个SM的最大线程束数: $W_{SM}$\n- 每个SM的最大常驻线程块数: $B_{SM}$\n- 每个SM的寄存器文件大小: $R_{SM}$\n- 每个SM的共享内存: $S_{SM}$\n- 核函数的每个线程块的线程数: $T_b$\n- 每个线程的寄存器数: $R_t$\n- 每个线程块的共享内存: $S_b$\n\n基于这些，我们推导出每个SM上并发线程块数量的资源限制：\n1.  每个线程块的线程束数: $w_b = \\lceil T_b / W \\rceil$。\n2.  由线程数限制的线程块数: $B_T = \\left\\lfloor \\dfrac{T_{SM}}{T_b} \\right\\rfloor$。\n3.  由线程束数限制的线程块数: $B_W = \\left\\lfloor \\dfrac{W_{SM}}{w_b} \\right\\rfloor$。\n4.  由寄存器数限制的线程块数: $B_R = \\left\\lfloor \\dfrac{R_{SM}}{R_t \\cdot T_b} \\right\\rfloor$。\n5.  由共享内存限制的线程块数: $B_S = \\left\\lfloor \\dfrac{S_{SM}}{S_b} \\right\\rfloor$（若 $S_b > 0$），否则 $B_S$ 实际上是无限的。\n\n每个SM的常驻线程块数 $B_{res}$ 是这些限制与架构最大值的最小值：\n$$\nB_{res} = \\min\\{B_{SM}, B_T, B_W, B_R, B_S\\}\n$$\n每个SM的活动线程束数则为 $W_{act} = B_{res} \\cdot w_b$。最后，占用率为：\n$$\n\\mathrm{occ} = \\min\\left(1, \\dfrac{W_{act}}{W_{SM}}\\right)\n$$\n\n第二，我们计算计算受限时间 $t_{comp}$。该时间与有效峰值计算吞吐量成反比，有效峰值计算吞吐量是设备的峰值吞吐量 $P_{peak}$ 乘以占用率。对于一个总自由度为 $N = E \\cdot n_p$（其中 $n_p = p+1$）、每个自由度需要 $c_{op}$ 次浮点运算的问题，计算时间为：\n$$\nt_{comp} = \\frac{N \\cdot c_{op}}{P_{peak} \\cdot \\mathrm{occ}}\n$$\n\n第三，我们计算内存受限时间 $t_{mem}$。该时间取决于传输的数据量和有效内存带宽。区分不同执行顺序的关键因素是访问残差数组 $R$ 时读-修改-写操作的内存合并情况。该模型定义了一个合并效率 $\\epsilon(s)$，它是一个线程束中连续线程访问的内存地址之间的步幅 $s$ 的函数。步幅本身由内存布局（EM或NM）和核函数遍历顺序（A或B）的组合决定。\n给定的映射关系是：\n- 对于元素主序布局（EM）：顺序A的步幅为 $s_A = 1$；顺序B的步幅为 $s_B = n_p$。\n- 对于节点主序布局（NM）：顺序A的步幅为 $s_A = E$；顺序B的步幅为 $s_B = 1$。\n\n$R$ 访问的合并效率由下式给出：\n$$\n\\epsilon(s) = \\begin{cases}\n1/s, & 1 \\le s \\le W,\\\\\n1/W, & s \\ge W,\n\\end{cases}\n$$\n所有 $N$ 个自由度的总内存时间是与合并无关的访问（$G_L, G_R, J_L, J_R$，总字节数为 $b_G + b_J$）和与合并相关的访问（$R$，字节数为 $b_R$）的贡献之和：\n$$\nt_{mem} = N \\cdot \\left(\\frac{b_R}{B_{peak} \\cdot \\epsilon(s)} + \\frac{b_G + b_J}{B_{peak}}\\right)\n$$\n步幅 $s=1$ 产生完美的合并效率 $\\epsilon(1)=1$，从而使内存时间最小化。较大的步幅会降低 $R$ 数组访问的有效带宽，从而降低性能。\n\n第四，预测的核函数运行时间 $t$ 是计算时间和内存时间的最大值，因为核函数可能是计算受限或内存受限的：\n$$\nt = \\max\\{t_{comp}, t_{mem}\\}\n$$\n\n最后，对于每个测试用例，我们计算顺序A的运行时间 $t_A$ 和顺序B的运行时间 $t_B$。加速比 $S$ 是较慢时间与较快时间之比，表示选择最优执行顺序所带来的性能提升：\n$$\nS = \\frac{\\max\\{t_A, t_B\\}}{\\min\\{t_A, t_B\\}}\n$$\n此过程被系统地应用于所有提供的测试用例，以得出最终结果。", "answer": "```python\nimport numpy as np\nimport math\n\n# Define fixed hardware and kernel parameters\nW = 32\nT_SM = 2048\nW_SM = 64\nB_SM = 32\nR_SM = 65536\nS_SM = 65536\nP_peak = 1e13\nB_peak = 6e11\nc_op = 4\nb_G = 16\nb_J = 16\nb_R = 16\n\ndef calculate_time(E, p, layout, T_b, R_t, S_b, ordering):\n    \"\"\"\n    Calculates the predicted runtime for a given configuration based on the provided performance model.\n    \"\"\"\n    # 1. Calculate derived problem-specific values\n    n_p = p + 1\n    N = E * n_p\n\n    # 2. Calculate Occupancy (occ)\n    w_b = math.ceil(T_b / W)\n    \n    B_T = math.floor(T_SM / T_b)\n    B_W = math.floor(W_SM / w_b)\n\n    # Prevent division by zero if T_b or R_t is zero, though not expected from problem statement.\n    if R_t * T_b > 0:\n        B_R = math.floor(R_SM / (R_t * T_b))\n    else:\n        B_R = float('inf')\n\n    if S_b > 0:\n        B_S = math.floor(S_SM / S_b)\n    else:\n        B_S = float('inf')\n\n    B_res = min(B_SM, B_T, B_W, B_R, B_S)\n    W_act = B_res * w_b\n    occ = min(1.0, W_act / W_SM) if W_SM > 0 else 0.0\n\n    # 3. Calculate Compute Time (t_comp)\n    # Prevent division by zero if P_peak or occ is zero\n    if P_peak > 0 and occ > 0:\n        t_comp = (N * c_op) / (P_peak * occ)\n    else:\n        t_comp = float('inf')\n\n    # 4. Calculate Memory Time (t_mem)\n    # Determine stride s\n    if layout == 'EM':\n        s = 1 if ordering == 'A' else n_p\n    elif layout == 'NM':\n        s = E if ordering == 'A' else 1\n    else:\n        raise ValueError(\"Invalid memory layout specified.\")\n\n    # Calculate coalescing efficiency epsilon(s)\n    if 1 = s = W:\n        epsilon_s = 1.0 / s\n    else: # s > W\n        epsilon_s = 1.0 / W\n    \n    # Calculate t_mem\n    # Prevent division by zero if B_peak or epsilon_s is zero\n    if B_peak > 0 and epsilon_s > 0:\n        term_R = b_R / (B_peak * epsilon_s)\n        term_GJ = (b_G + b_J) / B_peak\n        t_mem = N * (term_R + term_GJ)\n    else:\n        t_mem = float('inf')\n\n    # 5. Calculate Kernel Time (t)\n    t = max(t_comp, t_mem)\n\n    return t\n\ndef solve():\n    \"\"\"\n    Processes the test suite to calculate speedups for each case.\n    \"\"\"\n    test_cases = [\n        # Test 1: E, p, layout, (T_b_A, R_t_A, S_b_A), (T_b_B, R_t_B, S_b_B)\n        (4096, 7, 'EM', (32, 48, 0), (256, 64, 0)),\n        # Test 2\n        (4096, 7, 'NM', (32, 48, 0), (256, 64, 0)),\n        # Test 3\n        (8192, 31, 'EM', (32, 128, 0), (256, 64, 0)),\n        # Test 4\n        (16, 1, 'NM', (32, 24, 0), (64, 24, 0)),\n        # Test 5\n        (2048, 15, 'EM', (32, 48, 32768), (256, 32, 0)),\n    ]\n\n    results = []\n    for case in test_cases:\n        E, p, layout, params_A, params_B = case\n        T_b_A, R_t_A, S_b_A = params_A\n        T_b_B, R_t_B, S_b_B = params_B\n\n        t_A = calculate_time(E, p, layout, T_b_A, R_t_A, S_b_A, 'A')\n        t_B = calculate_time(E, p, layout, T_b_B, R_t_B, S_b_B, 'B')\n        \n        if min(t_A, t_B) > 0:\n            speedup = max(t_A, t_B) / min(t_A, t_B)\n        else:\n            speedup = 1.0 # Should not happen with valid inputs\n\n        results.append(f\"{speedup:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3386482"}]}