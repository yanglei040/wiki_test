{"hands_on_practices": [{"introduction": "多重网格方法的第一步是在粗网格上定义一个能够准确反映细网格误差特性的问题。本练习聚焦于此基础环节，您将探究在组装刚度矩阵和载荷向量时，不同的数值积分格式如何引入“混叠误差”(aliasing error)，并影响粗网格残差的准确性。通过这个实践，您将理解精确构建粗网格算子对于多重网格收敛性的重要性 [@problem_id:3401628]。", "problem": "要求您研究在一维谱元法中，为多重网格构建粗网格残差时，多项式阶次粗化如何与求积混叠相互作用。所有工作均在区间 $[-1,1]$ 上的一维空间中进行，使用单个谱元，该谱元在 Gauss–Lobatto–Legendre (GLL) 节点上具有 Lagrange 基函数。考虑具有齐次自然 (Neumann) 边界条件的扩散模型问题的弱形式：寻找一个足够光滑的函数 $u$，使得对于所有测试函数 $v$，满足\n$$\n\\int_{-1}^{1} a(x)\\, u'(x)\\, v'(x)\\, dx = \\int_{-1}^{1} f(x)\\, v(x)\\, dx.\n$$\n使用系数和精确解\n$$\na(x) = 1 + 0.3\\cos(7x), \\quad u(x) = \\bigl(1-x^2\\bigr)^2,\n$$\n因此 $u'(x) = -4x\\bigl(1-x^2\\bigr)$ 且 $u''(x) = -4 + 12x^2$。源项通过代入强形式 $- \\bigl(a(x) u'(x)\\bigr)' = f(x)$ 来定义，即\n$$\nf(x) = -\\Big(a'(x)\\, u'(x) + a(x)\\, u''(x)\\Big), \\quad a'(x) = -2.1\\sin(7x).\n$$\n对于选定的多项式阶次 $p$，有 $N=p+1$ 个 GLL 节点 $\\{x_i\\}_{i=0}^{N-1}$ 和相关的 Lagrange 基 $\\{\\phi_i(x)\\}_{i=0}^{N-1}$，通过求积定义离散刚度矩阵和载荷向量为\n$$\nK_{ij} \\approx \\sum_{q=1}^{Q} w_q\\, a(x_q)\\, \\phi_i'(x_q)\\, \\phi_j'(x_q), \\qquad\nf_i \\approx \\sum_{q=1}^{Q} w_q\\, f(x_q)\\, \\phi_i(x_q),\n$$\n其中求积节点为 $\\{x_q\\}$，权重为 $\\{w_q\\}$。对于固定的系数和在 GLL 节点上插值的固定函数 $u$，粗网格残差为\n$$\nr = f - K\\, u_h, \\quad \\text{where} \\quad u_h = \\bigl(u(x_0),\\dots,u(x_{N-1})\\bigr)^{\\top}.\n$$\n您必须实现三种求积策略来构造 $K$ 和 $f$：\n- 单个单元（粗 $p$）上的 GLL 配置：取 $Q=N$，节点等于 GLL 节点 $\\{x_i\\}$，权重等于 GLL 求积权重。这会表现出求积混叠，因为具有 $N$ 个节点的 GLL 求积仅能精确积分最高为 $2N-3=2p-1$ 次的多项式。\n- 使用 GLL 的复合子划分：将 $[-1,1]$ 划分为 $s$ 个相等的子区间，并在每个子区间上应用 $N$ 点 GLL 求积，通过仿射变换进行映射并求和贡献。这为粗有限维空间保留了相同的 GLL 节点集，但使用复合求积来减轻混叠。\n- 过积分参考：在 $[-1,1]$ 上使用 $Q_{\\mathrm{ref}}=200$ 点的 Gauss–Legendre 求积来近似 $K$ 和 $f$ 中的精确积分；将得到的残差表示为 $r_{\\mathrm{ref}}$。这作为近似精确的基准。\n\n为了分离求积混叠，在所有三种构造中使用相同的试验向量 $u_h$ 并比较残差。通过欧几里得范数来衡量两种粗化构造的粗残差精度\n$$\nE_{\\mathrm{GLL}} = \\lVert r_{\\mathrm{GLL}} - r_{\\mathrm{ref}} \\rVert_2, \\qquad\nE_{\\mathrm{comp}} = \\lVert r_{\\mathrm{comp}} - r_{\\mathrm{ref}} \\rVert_2,\n$$\n其中 $r_{\\mathrm{GLL}}$ 来自单单元 GLL 求积，$r_{\\mathrm{comp}}$ 来自 $s$ 个子区间上的复合 GLL 求积。\n\n实现要求：\n- 使用给定 $N=p+1$ 的标准 GLL 节点和权重。这 $N$ 个 GLL 节点是端点 $\\pm 1$ 和 $(N-1)$ 阶 Legendre 多项式导数的 $(N-2)$ 个内部根。GLL 权重由下式给出\n$$\nw_i = \\frac{2}{N(N-1)\\,\\bigl(P_{N-1}(x_i)\\bigr)^2},\n$$\n其中 $P_{N-1}$ 是 $(N-1)$ 阶 Legendre 多项式。\n- 使用重心 Lagrange 插值在任意求积点 $x$ 处计算基函数 $\\phi_i(x)$ 及其导数 $\\phi_i'(x)$，并仔细处理求积点与节点重合时的极限情况。\n- 通过上述求积规则组装 $K$ 和 $f$。不需要进行边界条件消除，因为弱形式使用自然边界条件，且所选的 $u$ 满足 $u'(\\pm 1)=0$。\n\n测试套件：\n对以下 $(p,s)$ 参数集评估 $(E_{\\mathrm{GLL}}, E_{\\mathrm{comp}})$ 对：\n- $(p,s)=(2,1)$,\n- $(p,s)=(2,4)$,\n- $(p,s)=(4,1)$,\n- $(p,s)=(4,4)$,\n- $(p,s)=(8,1)$,\n- $(p,s)=(8,4)$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个逗号分隔的配对列表，不含空格。每个配对按上述顺序列出，对应一个测试用例，并包含两个浮点数值 $E_{\\mathrm{GLL}}$ 和 $E_{\\mathrm{comp}}$，使用科学记数法表示，小数点后保留八位数字。例如，一个包含两个假设测试用例的有效输出行如下所示\n$$\n[\\,[1.23456789\\mathrm{e}{-04},9.87654321\\mathrm{e}{-06}],[2.46800000\\mathrm{e}{-03},1.23500000\\mathrm{e}{-04}]\\,].\n$$\n角度以弧度为单位。不涉及物理单位。", "solution": "该问题是有效的。这是一个在偏微分方程数值分析领域中，特别涉及谱元法和多重网格技术的适定且有科学依据的问题。所有必要的数据和定义都已提供，不存在内部矛盾或违反科学原理的情况。\n\n问题的核心是研究在一维谱元法中求积混叠对粗网格残差的影响。残差 $r = f - K u_h$ 是多重网格方法中将信息从细网格传递到粗网格的关键组成部分。其精度直接影响多重网格求解器的收敛性。当用于计算离散刚度矩阵 $K$ 和载荷向量 $f$ 的求积规则不足以精确地积分基函数（及其导数）与问题系数的乘积时，就会产生混叠误差。\n\n我们将基于谱元法的原理，在占据域 $[-1, 1]$ 的单个单元上实现一个解决方案。\n\n### 1. 谱离散化和基函数\n\n解 $u(x)$ 由一个 $p$ 阶多项式 $u_p(x)$ 近似。这个近似是在一个由 $N=p+1$ 个 Lagrange 多项式 $\\{\\phi_j(x)\\}_{j=0}^p$ 组成的基中表示的，这些多项式是相对于 $N$ 个 Gauss-Lobatto-Legendre (GLL) 节点 $\\{x_j\\}_{j=0}^p$ 定义的。这些节点是 $(1-x^2)P_p'(x)$ 的零点，其中 $P_p(x)$ 是 $p$ 阶 Legendre 多项式。Lagrange 基具有性质 $\\phi_j(x_i) = \\delta_{ij}$，其中 $\\delta_{ij}$ 是 Kronecker δ。\n\n离散解由其在 GLL 节点上的值组成的向量表示，$u_h = [u(x_0), u(x_1), \\dots, u(x_p)]^\\top$。对于此问题，使用精确解 $u(x) = (1-x^2)^2$ 来构造此向量。\n\n### 2. 弱形式与求积\n\n模型问题的弱形式由下式给出：\n$$\n\\int_{-1}^{1} a(x)\\, u'(x)\\, v'(x)\\, dx = \\int_{-1}^{1} f(x)\\, v(x)\\, dx\n$$\n代入谱近似 $u(x) \\approx \\sum_j u_j \\phi_j(x)$ 并使用测试函数 $v(x) = \\phi_i(x)$，我们得到离散系统 $K u_h = f$。刚度矩阵 $K$ 和载荷向量 $f$ 的项为：\n$$\nK_{ij} = \\int_{-1}^{1} a(x)\\, \\phi_i'(x)\\, \\phi_j'(x)\\, dx\n$$\n$$\nf_i = \\int_{-1}^{1} f(x)\\, \\phi_i(x)\\, dx\n$$\n这些积分是使用具有 $Q$ 个点 $\\{x_q\\}$ 和权重 $\\{w_q\\}$ 的求积规则进行数值计算的：\n$$\nK_{ij} \\approx \\sum_{q=1}^{Q} w_q\\, a(x_q)\\, \\phi_i'(x_q)\\, \\phi_j'(x_q)\n$$\n$$\nf_i \\approx \\sum_{q=1}^{Q} w_q\\, f(x_q)\\, \\phi_i(x_q)\n$$\n\n### 3. 求积策略与混叠\n\n$K$ 和 $f$ 的精度取决于所选的求积规则。$K_{ij}$ 的被积函数涉及基函数导数的乘积 $\\phi_i'(x)\\phi_j'(x)$，这是一个 $2p-2$ 阶的多项式，再乘以非多项式系数 $a(x)$。\n\n比较三种求积策略：\n\n1.  **参考求积 ($r_{\\mathrm{ref}}$)**：使用高阶 $Q_{\\mathrm{ref}}=200$ 点 Gauss-Legendre 规则。该求积足够精确，可被视为对积分的“近似精确”计算，从而提供一个基准残差 $r_{\\mathrm{ref}}$。\n\n2.  **GLL 配置 ($r_{\\mathrm{GLL}}$)**：使用 $N=p+1$ 个 GLL 节点本身作为求积点。该规则能精确积分最高达 $2N-3 = 2p-1$ 阶的多项式。由于 $\\phi_i(x_j) = \\delta_{ij}$ 的性质，对于这种特定求积，载荷向量简化为 $f_i = w_i f(x_i)$。刚度矩阵使用 GLL 微分矩阵 $D$ (其中 $D_{ij} = \\phi'_j(x_i)$) 组装为 $K_{\\mathrm{GLL}} = D^\\top W A D$，其中 $W$ 和 $A$ 分别是在 GLL 节点上求值的 GLL 权重和系数 $a(x)$ 的对角矩阵。\n\n3.  **复合 GLL 求积 ($r_{\\mathrm{comp}}$)**：为了在局部使用相同 GLL 点的同时减轻混叠，将域 $[-1,1]$ 分为 $s$ 个子区间。在每个子区间上，通过仿射变换应用一个 $N$ 点 GLL 求积规则。这产生了一个总共有 $s \\times N$ 个求积点的复合规则，从而显著提高精度并减少混叠。\n\n后两种方法由混叠引起的误差，通过计算其残差与参考残差之差的欧几里得范数来衡量：$E_{\\mathrm{GLL}} = \\lVert r_{\\mathrm{GLL}} - r_{\\mathrm{ref}} \\rVert_2$ 和 $E_{\\mathrm{comp}} = \\lVert r_{\\mathrm{comp}} - r_{\\mathrm{ref}} \\rVert_2$。\n\n### 4. 基函数及其导数的实现\n\n一个关键的实现细节是在任意求积点 $x_q$ 处对基函数 $\\phi_j(x)$ 及其导数 $\\phi_j'(x)$ 进行稳定而精确的计算。\n\n-   **GLL 节点和权重**：对于给定的阶次 $p$，其 $p+1$ 个节点是 $(1-x^2)P'_p(x)$ 的根，权重则由涉及 $P_p(x)$ 的标准公式计算得出。\n-   **节点处的导数**：对于 GLL 求积情况，其中求积点与基节点重合，导数从 GLL 微分矩阵 $D$ 的项中获得，该矩阵是使用已有的公式为保证稳定性和准确性而构造的。\n-   **任意点处的导数**：对于参考求积和复合求积，求积点 $x_q$通常不与 GLL 节点 $\\{x_j\\}$ 重合。在这些情况下，我们采用一个公式来计算 Lagrange 多项式 $\\phi_j(x)$ 在任意点 $x \\ne x_j$ 的导数：\n    $$\n    \\phi_j'(x) = \\frac{l'(x)}{l'(x_j)(x-x_j)} - \\frac{\\phi_j(x)}{x-x_j}\n    $$\n    其中 $l(x) = C(1-x^2)P_p'(x)$ 是以 GLL 节点为根的多项式。这需要计算 $P_p(x)$ 及其最高二阶的导数，这可以通过使用其三项递推关系来高效完成。这种方法规避了 $\\phi_j'(x)$ 朴素乘积法则定义可能带来的不稳定性。\n\n通过遵循此程序，我们可以为每种求积策略系统地组装所需的矩阵和向量，计算残差，并为每个测试用例评估指定的误差范数。", "answer": "```python\nimport numpy as np\nfrom numpy.polynomial.legendre import Legendre\n\ndef solve():\n    \"\"\"\n    Solves the problem of evaluating quadrature aliasing effects on coarse-grid residuals\n    in a 1D spectral element method.\n    \"\"\"\n    \n    test_cases = [\n        (2, 1),\n        (2, 4),\n        (4, 1),\n        (4, 4),\n        (8, 1),\n        (8, 4),\n    ]\n\n    _gll_cache = {}\n    def get_gll_nodes_weights(p):\n        \"\"\"\n        Computes Gauss-Lobatto-Legendre nodes and weights for a given polynomial degree p.\n        Nodes are roots of (1-x^2)P'_p(x).\n        \"\"\"\n        if p in _gll_cache:\n            return _gll_cache[p]\n\n        N = p + 1\n        if p == 0:\n            nodes = np.array([-1.0])\n            weights = np.array([2.0])\n            _gll_cache[p] = (nodes, weights)\n            return nodes, weights\n        if p == 1:\n            nodes = np.array([-1.0, 1.0])\n            weights = np.array([1.0, 1.0])\n            _gll_cache[p] = (nodes, weights)\n            return nodes, weights\n\n        # Interior nodes are roots of P'_p(x)\n        leg_poly = Legendre.basis(p)\n        leg_poly_deriv = leg_poly.deriv(1)\n        interior_nodes = leg_poly_deriv.roots()\n        \n        nodes = np.concatenate(([-1.0], np.sort(interior_nodes), [1.0]))\n        \n        # Weights formula: w_i = 2 / (p*(p+1) * (P_p(x_i))^2)\n        P_p_at_nodes = leg_poly(nodes)\n        weights = 2.0 / (p * (p + 1) * P_p_at_nodes**2)\n        \n        _gll_cache[p] = (nodes, weights)\n        return nodes, weights\n\n    def get_diff_matrix(p, nodes):\n        \"\"\"\n        Computes the GLL differentiation matrix D, where D_ij = phi'_j(x_i).\n        \"\"\"\n        N = p + 1\n        D = np.zeros((N, N))\n        leg_poly = Legendre.basis(p)\n        P_p_at_nodes = leg_poly(nodes)\n\n        for i in range(N):\n            for j in range(N):\n                if i != j:\n                    D[i, j] = (P_p_at_nodes[i] / P_p_at_nodes[j]) * (1.0 / (nodes[i] - nodes[j]))\n        \n        D[0, 0] = -p * (p + 1) / 4.0\n        D[N - 1, N - 1] = p * (p + 1) / 4.0\n        # for i > 0 and i  N-1, D[i,i] is 0 based on Hesthaven text,\n        # but summing off-diagonals is more general.\n        for i in range(1, N - 1):\n             D[i,i] = 0.0 # Standard formula for interior nodes\n        \n        return D\n\n    def legendre_poly_and_derivs(p, x):\n        \"\"\"\n        Computes P_p(x), P'_p(x), P''_p(x) using recurrence relations.\n        \"\"\"\n        if p == 0:\n            return 1.0, 0.0, 0.0\n        \n        p_k_minus_2, p_k_minus_1 = 1.0, x\n        pp_k_minus_2, pp_k_minus_1 = 0.0, 1.0\n        ppp_k_minus_2, ppp_k_minus_1 = 0.0, 0.0\n\n        for k in range(1, p):\n            p_k = ((2 * k + 1) * x * p_k_minus_1 - k * p_k_minus_2) / (k + 1)\n            pp_k = ((2 * k + 1) * (p_k_minus_1 + x * pp_k_minus_1) - k * pp_k_minus_2) / (k + 1)\n            ppp_k = ((2 * k + 1) * (2 * pp_k_minus_1 + x * ppp_k_minus_1) - k * ppp_k_minus_2) / (k + 1)\n            \n            p_k_minus_2, p_k_minus_1 = p_k_minus_1, p_k\n            pp_k_minus_2, pp_k_minus_1 = pp_k_minus_1, pp_k\n            ppp_k_minus_2, ppp_k_minus_1 = ppp_k_minus_1, ppp_k\n\n        return p_k_minus_1, pp_k_minus_1, ppp_k_minus_1\n\n    # Problem-specific functions\n    a = lambda x: 1.0 + 0.3 * np.cos(7.0 * x)\n    a_prime = lambda x: -2.1 * np.sin(7.0 * x)\n    u_exact = lambda x: (1.0 - x**2)**2\n    u_prime = lambda x: -4.0 * x * (1.0 - x**2)\n    u_double_prime = lambda x: -4.0 + 12.0 * x**2\n    f_source = lambda x: -(a_prime(x) * u_prime(x) + a(x) * u_double_prime(x))\n\n    results = []\n    \n    for p, s in test_cases:\n        N = p + 1\n        \n        gll_nodes, gll_weights = get_gll_nodes_weights(p)\n        D = get_diff_matrix(p, gll_nodes)\n        \n        u_h = u_exact(gll_nodes)\n        \n        # Precompute l'(x_j) for arbitrary point derivative evaluation\n        l_prime_at_nodes = np.zeros(N)\n        for j in range(N):\n            xj = gll_nodes[j]\n            _, Pp_prime, Pp_double_prime = legendre_poly_and_derivs(p, xj)\n            l_prime_at_nodes[j] = (1 - xj**2) * Pp_double_prime - 2 * xj * Pp_prime\n            \n        def eval_basis_functions(xq, p_deg, base_nodes, diff_matrix):\n            # Check if xq is one of the base_nodes\n            match_indices = np.where(np.isclose(xq, base_nodes))[0]\n            if len(match_indices) > 0:\n                k = match_indices[0]\n                phis = np.zeros(p_deg + 1)\n                phis[k] = 1.0\n                phi_primes = diff_matrix[k, :]\n                return phis, phi_primes\n            \n            # If xq is not a node, use arbitrary point evaluation formulas\n            phis = np.zeros(p_deg + 1)\n            phi_primes = np.zeros(p_deg + 1)\n\n            _, Pp_prime_xq, Pp_double_prime_xq = legendre_poly_and_derivs(p_deg, xq)\n            l_xq = (1 - xq**2) * Pp_prime_xq\n            l_prime_xq = (1 - xq**2) * Pp_double_prime_xq - 2 * xq * Pp_prime_xq\n\n            for j in range(p_deg + 1):\n                xj = base_nodes[j]\n                phis[j] = l_xq / ((xq - xj) * l_prime_at_nodes[j])\n                phi_primes[j] = (l_prime_xq / (l_prime_at_nodes[j] * (xq - xj))) - (phis[j] / (xq - xj))\n\n            return phis, phi_primes\n\n        # 1. Reference residual (Over-integration)\n        Q_ref = 200\n        xq_ref, wq_ref = np.polynomial.legendre.leggauss(Q_ref)\n        K_ref = np.zeros((N, N))\n        f_ref = np.zeros(N)\n        for xq, wq in zip(xq_ref, wq_ref):\n            phis, phi_primes = eval_basis_functions(xq, p, gll_nodes, D)\n            K_ref += wq * a(xq) * np.outer(phi_primes, phi_primes)\n            f_ref += wq * f_source(xq) * phis\n        r_ref = f_ref - K_ref @ u_h\n\n        # 2. GLL residual (Collocation)\n        K_gll = D.T @ np.diag(gll_weights * a(gll_nodes)) @ D\n        f_gll = gll_weights * f_source(gll_nodes)\n        r_gll = f_gll - K_gll @ u_h\n\n        # 3. Composite GLL residual\n        K_comp = np.zeros((N, N))\n        f_comp = np.zeros(N)\n        sub_interval_bps = np.linspace(-1, 1, s + 1)\n        for i in range(s):\n            a_sub, b_sub = sub_interval_bps[i], sub_interval_bps[i+1]\n            jacobian = (b_sub - a_sub) / 2.0\n            xq_sub = jacobian * gll_nodes + (a_sub + b_sub) / 2.0\n            wq_sub = jacobian * gll_weights\n            \n            for k in range(N):\n                xk = xq_sub[k]\n                wk = wq_sub[k]\n                phis, phi_primes = eval_basis_functions(xk, p, gll_nodes, D)\n                K_comp += wk * a(xk) * np.outer(phi_primes, phi_primes)\n                f_comp += wk * f_source(xk) * phis\n        r_comp = f_comp - K_comp @ u_h\n        \n        e_gll = np.linalg.norm(r_gll - r_ref)\n        e_comp = np.linalg.norm(r_comp - r_ref)\n        results.append([e_gll, e_comp])\n\n    formatted_pairs = [f\"[{e[0]:1.8e},{e[1]:1.8e}]\" for e in results]\n    print(f\"[{','.join(formatted_pairs)}]\")\n\nsolve()\n```", "id": "3401628"}, {"introduction": "在成功构建粗网格算子之后，下一步是在不同层级的网格之间有效地传递信息。本练习将检验两种构建限制算子(restriction operator)的方法：一种是使用质量矩阵、理论上最优但计算成本高昂的方法；另一种是计算上更简便的“质量集中”(mass-lumped)方法。通过量化比较它们的性能，您将深入理解在设计高效多重网格求解器时所面临的实际权衡 [@problem_id:3401559]。", "problem": "考虑参考区间 $[-1,1]$ 上的一个一维对称正定椭圆模型问题，该问题具有齐次 Dirichlet 边界条件。令 $p$ 表示多项式阶数，试探空间为 Legendre–Gauss–Lobatto (LGL) 点上的节点 Lagrange 基。谱元法 (SEM) 的刚度算子 $A$ 由双线性形式 $a(u,v) = \\int_{-1}^{1} u'(x) v'(x) \\, dx$ 定义，该双线性形式通过使用 LGL 节点的权重和由 LGL 节点导出的微分矩阵的 LGL 求积法进行精确计算。令 $M$ 表示相容质量算子，它由双线性形式 $m(u,v) = \\int_{-1}^{1} u(x) v(x) \\, dx$ 定义，并通过使用足够多的点以精确积分阶数为 $2p$ 的多项式的 Gauss–Legendre 求积法进行精确计算。间断 Galerkin (DG) 和谱元法 (SEM) 的单元算子都基于此 Galerkin 基础；为清晰起见，本问题使用具有齐次 Dirichlet 边界条件的单个谱元。\n\n在 $p$-多重网格中，令细空间阶数为 $p_f$，粗空间阶数为 $p_c  p_f$。将延长算子 $P$ 定义为从粗网格内部自由度到细网格内部自由度的节点插值映射，该映射由在细网格内部 LGL 节点上求值的粗网格 Lagrange 基导出。考虑限制算子的两种定义，对应于两种粗空间内积：\n- 相容 $L^2$ 限制算子 $R_{\\mathrm{cons}}$ 由 $L^2$ 投影定义，$R_{\\mathrm{cons}} = M_c^{-1} P^{\\top} M_f$，其中 $M_f$ 和 $M_c$ 是限制在内部自由度上的相容细、粗质量算子。\n- 质量集中粗空间限制算子 $R_{\\mathrm{lump}}$ 使用欧几里得内积，其中粗质量矩阵近似为单位矩阵，$M_c \\approx I$，从而得到 $R_{\\mathrm{lump}} = P^{\\top}$。\n\n对于每种限制算子选择，通过标准 Galerkin 构造 $A_c = R A_f P$ 定义粗算子，其中 $A_f$ 是限制在内部自由度上的细刚度算子，$A_c$ 是相应的粗算子。定义两网格粗校正误差传播算子\n$$\nE = I - P A_c^{-1} R A_f,\n$$\n其中 $I$ 是细网格内部自由度上的单位算子。通过由 $A_f$ 导出的能量范数中的收缩因子来量化粗校正的有效性，该收缩因子定义为\n$$\n\\| E \\|_{A_f} = \\sup_{x \\neq 0} \\sqrt{\\frac{x^{\\top} E^{\\top} A_f E x}{x^{\\top} A_f x}}。\n$$\n该量是矩阵对 $\\left(E^{\\top} A_f E, A_f\\right)$ 的最大广义特征值的平方根。\n\n任务：通过设置 $M_c \\approx I$ 以使 $R_{\\mathrm{lump}} = P^{\\top}$，来提出并实现质量集中粗空间。然后，通过为每个测试用例计算比率\n$$\n\\rho = \\frac{\\| E_{\\mathrm{lump}} \\|_{A_f}}{\\| E_{\\mathrm{cons}} \\|_{A_f}},\n$$\n来量化相对于相容粗质量 $M_c$ 的粗校正精度损失，其中 $E_{\\mathrm{lump}}$ 和 $E_{\\mathrm{cons}}$ 分别是根据 $R_{\\mathrm{lump}}$ 和 $R_{\\mathrm{cons}}$ 构建的误差传播算子。$\\rho \\geq 1$ 的值表示由于质量集中导致粗校正有效性下降。\n\n使用以下多项式阶数组合 $(p_f, p_c)$ 的测试套件：\n- 案例 1 (一般情况): $(8, 4)$。\n- 案例 2 (接近最小粗空间): $(3, 2)$。\n- 案例 3 (激进粗化): $(10, 2)$。\n- 案例 4 (接近恒等粗化): $(12, 11)$。\n\n对于所有计算：\n- 在参考区间 $[-1,1]$ 上进行计算。\n- 通过限制在内部自由度上（即从代数算子中省略边界 LGL 节点）来强制施加齐次 Dirichlet 边界条件。\n- 在此配置点设置下，使用 Legendre–Gauss–Lobatto 节点通过精确求积来构建微分矩阵和刚度算子。\n- 使用具有 $p+1$ 个点的 Gauss–Legendre 求积法来精确组装相容质量算子。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，\"[result1,result2,result3,result4]\"），其中每个条目是按上述顺序列出的相应测试用例的 $\\rho$ 的浮点值。此计算不涉及物理单位或角度，因此无需指定单位。", "solution": "## 问题验证\n\n### 步骤 1：提取已知条件\n- **模型问题**：区间 $[-1,1]$ 上的一维对称正定椭圆模型问题，具有齐次 Dirichlet 边界条件。\n- **离散化方法**：使用单个单元的谱元法 (SEM)。\n- **试探空间**：给定多项式阶数 $p$ 的 Legendre–Gauss–Lobatto (LGL) 点上的节点 Lagrange 基。\n- **刚度算子 $A$**：由 $a(u,v) = \\int_{-1}^{1} u'(x) v'(x) \\, dx$ 定义，使用 LGL 求积法精确计算。\n- **相容质量算子 $M$**：由 $m(u,v) = \\int_{-1}^{1} u(x) v(x) \\, dx$ 定义，使用 $p+1$ 个点的 Gauss-Legendre 求积法精确计算。\n- **边界条件**：齐次 Dirichlet，通过将所有算子限制在内部自由度上施加。\n- **$p$-多重网格空间**：多项式阶数为 $p_f$ 的细空间和阶数为 $p_c  p_f$ 的粗空间。\n- **延长算子 $P$**：从粗网格内部自由度到细网格内部自由度的节点插值。\n- **限制算子**：\n    - 相容限制算子 $R_{\\mathrm{cons}} = M_c^{-1} P^{\\top} M_f$，其中 $M_f$ 和 $M_c$ 是内部自由度上的细、粗相容质量算子。\n    - 质量集中限制算子 $R_{\\mathrm{lump}} = P^{\\top}$，对应于将粗质量矩阵 $M_c$ 近似为单位矩阵 $I$。\n- **粗算子 $A_c$**：由 Galerkin 投影 $A_c = R A_f P$ 定义，其中 $A_f$ 是内部自由度上的细刚度算子。\n- **两网格误差传播算子 $E$**：$E = I - P A_c^{-1} R A_f$，其中 $I$ 是细网格内部空间上的单位算子。\n- **收缩因子 $\\|E\\|_{A_f}$**：误差传播算子的能量范数，定义为 $\\| E \\|_{A_f} = \\sup_{x \\neq 0} \\sqrt{\\frac{x^{\\top} E^{\\top} A_f E x}{x^{\\top} A_f x}}$。这是矩阵对 $(E^{\\top} A_f E, A_f)$ 的最大广义特征值的平方根。\n- **任务**：为给定的测试用例计算比率 $\\rho = \\frac{\\| E_{\\mathrm{lump}} \\|_{A_f}}{\\| E_{\\mathrm{cons}} \\|_{A_f}}$。\n- **测试用例**：$(p_f, p_c)$ 对：$(8, 4)$, $(3, 2)$, $(10, 2)$ 和 $(12, 11)$。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准评估问题：\n- **科学性**：该问题牢固地植根于偏微分方程数值分析的既定理论，特别是谱元离散化的 $p$-多重网格方法。所有定义——算子、范数和网格间传递——都是该领域的标准定义。\n- **良态性**：该问题在数学上是良定义的。它要求一个特定的、可计算的量 $\\rho$，该量由标准矩阵运算和广义特征值问题导出。椭圆问题的底层刚度矩阵是对称正定的，确保了它们的逆和后续计算是良定义的。\n- **客观性**：问题陈述精确、量化，并且没有任何主观或模糊的语言。\n- **完整性和一致性**：提供了所有必要的定义、方程和参数。所定义算子的矩阵维数是一致的，确保了像 $A_c = R A_f P$ 这样的复合运算的有效性。\n\n没有违反科学原理，没有缺失信息，没有矛盾，也没有含糊之处。该问题是计算数学中一个标准的、尽管复杂的数值实验。\n\n### 步骤 3：结论和行动\n问题是 **有效的**。将提供一个解决方案。\n\n---\n\n## 基于原理的设计\n\n解决方案需要实现一维谱元法 $p$ 型两网格求解器的组件，然后分析两种不同粗网格公式的收敛特性。任务的核心是构造指定的矩阵和算子，然后计算生成的两网格误差传播算子的能量范数。\n\n### 1. 节点基和求积法则\n谱元法的基础是基函数和求积法则的选择。\n- **Legendre-Gauss-Lobatto (LGL) 点**：对于多项式阶数 $p$，我们在 $[-1,1]$ 上使用 $p+1$ 个 LGL 点。这些点是 $(1-x^2)P_p'(x)$ 的根，其中 $P_p(x)$ 是阶数为 $p$ 的 Legendre 多项式。内部 LGL 节点是 Jacobi 多项式 $P_{p-1}^{(1,1)}(x)$ 的根。基函数是与这些节点相关的 Lagrange 多项式 $\\{l_j(x)\\}_{j=0}^p$。\n- **LGL 求积**：此求积法则使用 LGL 节点作为横坐标，并具有相关的权重 $w_j = \\frac{2}{p(p+1)[P_p(x_j)]^2}$。它可以精确积分阶数高达 $2p-1$ 的多项式。\n- **Gauss-Legendre (GL) 求积**：此法则使用 $k$ 个点，可以精确积分阶数高达 $2k-1$ 的多项式。\n\n### 2. 算子组装\n刚度算子和质量算子使用适当的求积法则构建。所有算子最初都是为全套 $p+1$ 个自由度组装的。\n- **刚度算子 $A_p$**：双线性形式为 $a(l_j, l_i) = \\int_{-1}^1 l_i'(x) l_j'(x) dx$。这使用 LGL 求积进行计算。使用微分矩阵 $D$，其中 $D_{ij} = l_j'(x_i)$，刚度矩阵由 $A_p = D^T W D$ 给出，其中 $W$ 是 LGL 权重的对角矩阵。该求积是精确的，因为被积函数 $l_i'(x)l_j'(x)$ 是阶数为 $2(p-1)$ 的多项式，而 LGL 求积对阶数高达 $2p-1$ 的多项式是精确的。\n- **相容质量算子 $M_p$**：双线性形式为 $m(l_j, l_i) = \\int_{-1}^1 l_i(x) l_j(x) dx$。被积函数是阶数为 $2p$ 的多项式。为了精确积分，我们需要一个对阶数 $2p$ 精确的求积法则。具有 $k$ 个点的 Gauss-Legendre 求积对阶数 $2k-1$ 精确，因此我们需要 $2k-1 \\geq 2p$，这意味着 $k \\geq p+1/2$。按规定选择 $k=p+1$ 个 GL 点是足够的。质量矩阵组装为 $M_p = V^T \\Omega V$，其中 $\\Omega$ 是 GL 权重的对角矩阵，$V$ 是一个“类 Vandermonde”矩阵，其元素为 $V_{ki} = l_i(y_k)$，即在第 $k$ 个 GL 节点 $y_k$ 处计算 LGL Lagrange 基函数 $l_i$ 的值。\n\n### 3. 边界条件和内部子空间\n齐次 Dirichlet 边界条件 ($u(-1)=u(1)=0$) 通过将问题限制在由内部基函数张成的子空间上来施加。在代数上，这是通过取 $A_p$ 和 $M_p$ 对应于内部节点（即，排除第一行和最后一行以及第一列和最后一列）的子矩阵来实现的。得到的矩阵 $A_f$、$M_f$ 和 $M_c$ 作用于内部自由度向量。\n\n### 4. 网格间传递算子\n- **延长算子 $P$**：该算子将向量从粗网格内部空间映射到细网格内部空间。它通过在细网格内部节点上计算粗空间基函数来构建。粗网格内部空间的基由与粗网格*内部*节点相关的 Lagrange 多项式 $\\{l_{c,j}\\}_{j=1}^{p_c-1}$ 组成。这些基函数本身是使用全套 $p_c+1$ 个粗网格 LGL 节点定义的。因此，矩阵元素 $P_{ij}$ 是第 $j$ 个粗网格内部基函数在第 $i$ 个细网格内部节点上的评价值。重心插值是进行此计算的有效方法。\n- **限制算子 $R$**：限制算子从细空间映射到粗空间。\n    - $R_{\\mathrm{lump}} = P^T$：这是延长算子的转置，对应于值的简单注入，并且等同于在粗空间上使用平凡（单位）内积。\n    - $R_{\\mathrm{cons}} = M_c^{-1} P^T M_f$：这是 $P$ 相对于由质量矩阵 $M_f$ 和 $M_c$ 表示的 $L^2$ 内积的伴随算子。它是 $L^2$ 正交投影的理论上最优选择。\n\n### 5. 两网格分析\n对于每种限制算子选择（$R_{\\mathrm{cons}}$ 和 $R_{\\mathrm{lump}}$），执行以下步骤：\n1.  **粗网格算子 $A_c$**：形成 Galerkin 粗算子 $A_c = R A_f P$。\n2.  **误差传播算子 $E$**：构造两网格误差传播算子 $E = I - P A_c^{-1} R A_f$。该算子描述了误差经过一个粗网格校正循环后的变换（此定义中省略了前平滑，这在仅分析粗校正步骤时很常见）。\n3.  **能量范数计算**：粗校正的有效性通过 $E$ 的 $A_f$-范数来衡量。此范数计算为矩阵对 $(E^T A_f E, A_f)$ 的最大广义特征值 $\\lambda_{\\max}$ 的平方根。此特征值问题使用针对对称定对的数值稳定算法求解。\n4.  **比率 $\\rho$**：最后一步是计算比率 $\\rho = \\|E_{\\mathrm{lump}}\\|_{A_f} / \\|E_{\\mathrm{cons}}\\|_{A_f}$，以量化由于粗空间内积中的质量集中导致的性能下降。\n\n对测试套件中指定的每个 $(p_f, p_c)$ 对执行此结构化过程。", "answer": "```python\nimport numpy as np\nfrom scipy.special import roots_jacobi, eval_legendre\nfrom scipy.linalg import eigh, inv\nfrom scipy.interpolate import BarycentricInterpolator\nfrom numpy.polynomial.legendre import leggauss\n\ndef lgl_nodes_weights(p):\n    \"\"\"\n    Computes Legendre-Gauss-Lobatto (LGL) nodes and weights for a given\n    polynomial degree p. Total number of points is p+1.\n    \"\"\"\n    if p == 0:\n        return np.array([-1.0]), np.array([2.0])\n    if p == 1:\n        return np.array([-1.0, 1.0]), np.array([1.0, 1.0])\n    \n    # Interior nodes are roots of the Jacobi polynomial P_{p-1}^{(1,1)}(x)\n    interior_nodes, _ = roots_jacobi(p - 1, 1, 1)\n    nodes = np.concatenate(([-1.0], interior_nodes, [1.0]))\n    \n    # Weights are computed using the formula involving P_p(x_j)\n    P_p_at_nodes = eval_legendre(p, nodes)\n    weights = 2.0 / (p * (p + 1) * P_p_at_nodes**2)\n    \n    return nodes, weights\n\ndef lgl_diff_matrix(p, nodes):\n    \"\"\"\n    Computes the (p+1)x(p+1) differentiation matrix for LGL nodes.\n    \"\"\"\n    N = p\n    N_plus_1 = N + 1\n    D = np.zeros((N_plus_1, N_plus_1))\n    \n    if p == 0:\n        return np.array([[0.0]])\n        \n    P_N_at_nodes = eval_legendre(N, nodes)\n    \n    # Off-diagonal entries\n    for i in range(N_plus_1):\n        for j in range(N_plus_1):\n            if i != j:\n                D[i, j] = P_N_at_nodes[i] / (P_N_at_nodes[j] * (nodes[i] - nodes[j]))\n    \n    # Diagonal entries\n    D[0, 0] = -N * (N + 1) / 4.0\n    D[N, N] = N * (N + 1) / 4.0\n    \n    return D\n\ndef stiffness_matrix(weights, diff_matrix):\n    \"\"\"\n    Computes the stiffness matrix A = D^T W D.\n    \"\"\"\n    W = np.diag(weights)\n    return diff_matrix.T @ W @ diff_matrix\n\ndef mass_matrix(p, lgl_nodes):\n    \"\"\"\n    Computes the consistent mass matrix M using Gauss-Legendre quadrature\n    with p+1 points for exactness.\n    \"\"\"\n    p_lgl = p\n    num_lgl_nodes = p_lgl + 1\n    \n    # Use k=p+1 GL points for exactness of degree 2p polynomial integration\n    k = p_lgl + 1\n    gl_nodes, gl_weights = leggauss(k)\n    \n    # Create Vandermonde-like matrix V_{ij} = l_j(gl_node_i) where l_j is the\n    # Lagrange polynomial for the j-th LGL node.\n    V = np.zeros((k, num_lgl_nodes))\n    interp = BarycentricInterpolator(lgl_nodes)\n    \n    for j in range(num_lgl_nodes):\n        y = np.zeros(num_lgl_nodes)\n        y[j] = 1.0\n        interp.set_yi(y)\n        V[:, j] = interp(gl_nodes)\n        \n    Omega = np.diag(gl_weights)\n    M = V.T @ Omega @ V\n    return M\n\ndef prolongation_matrix(p_c, nodes_c, nodes_f_int):\n    \"\"\"\n    Computes the prolongation matrix P, which interpolates from coarse\n    interior DoFs to fine interior DoFs.\n    \"\"\"\n    num_fine_int = len(nodes_f_int)\n    num_coarse_int = p_c - 1\n    \n    if num_coarse_int == 0:\n        return np.zeros((num_fine_int, 0))\n\n    P = np.zeros((num_fine_int, num_coarse_int))\n    # Interpolation is based on the full set of coarse nodes\n    interp = BarycentricInterpolator(nodes_c)\n    \n    # Iterate through coarse interior basis functions\n    for j in range(num_coarse_int):\n        coarse_node_idx_full = j + 1\n        y = np.zeros(p_c + 1)\n        y[coarse_node_idx_full] = 1.0\n        interp.set_yi(y)\n        P[:, j] = interp(nodes_f_int)\n\n    return P\n\ndef calculate_energy_norm(E, A_f):\n    \"\"\"\n    Calculates the energy norm ||E||_Af.\n    \"\"\"\n    # We need to solve the generalized eigenvalue problem (E^T A_f E) v = lambda A_f v\n    op = E.T @ A_f @ E\n    # Use eigh for symmetric-definite generalized eigenvalue problems\n    eigvals, _ = eigh(op, A_f)\n    # The norm squared is the largest eigenvalue. Eigenvalues are real.\n    return np.sqrt(np.max(eigvals))\n\n\ndef calculate_rho(p_f, p_c):\n    \"\"\"\n    Calculates the performance ratio rho for a given (p_f, p_c) pair.\n    \"\"\"\n    # 1. Fine grid setup\n    nodes_f, weights_f = lgl_nodes_weights(p_f)\n    D_f = lgl_diff_matrix(p_f, nodes_f)\n    A_f_full = stiffness_matrix(weights_f, D_f)\n    if p_f > 0:\n        M_f_full = mass_matrix(p_f, nodes_f)\n    else: # Should not happen based on problem constraints\n        M_f_full = np.array([[]])\n\n    \n    # 2. Coarse grid setup\n    nodes_c, _ = lgl_nodes_weights(p_c)\n    if p_c > 0:\n        M_c_full = mass_matrix(p_c, nodes_c)\n    else: # Should not happen\n        M_c_full = np.array([[]])\n    \n    # 3. Apply BCs by restricting to interior DoFs\n    nodes_f_int = nodes_f[1:-1]\n    A_f = A_f_full[1:-1, 1:-1]\n    M_f = M_f_full[1:-1, 1:-1]\n    M_c = M_c_full[1:-1, 1:-1]\n    \n    # 4. Prolongation operator\n    P = prolongation_matrix(p_c, nodes_c, nodes_f_int)\n    \n    num_fine_int = p_f - 1\n    I_f = np.eye(num_fine_int)\n    \n    # 5. Consistent case\n    R_cons = inv(M_c) @ P.T @ M_f\n    A_c_cons = R_cons @ A_f @ P\n    E_cons = I_f - P @ inv(A_c_cons) @ R_cons @ A_f\n    norm_cons = calculate_energy_norm(E_cons, A_f)\n\n    # 6. Mass-lumped case\n    R_lump = P.T\n    A_c_lump = R_lump @ A_f @ P\n    E_lump = I_f - P @ inv(A_c_lump) @ R_lump @ A_f\n    norm_lump = calculate_energy_norm(E_lump, A_f)\n    \n    # 7. Ratio\n    if norm_cons == 0:\n        # If consistent correction is exact, ratio is 1 if lumped is also exact, else inf.\n        return 1.0 if norm_lump == 0 else np.inf\n      \n    return norm_lump / norm_cons\n\ndef solve():\n    \"\"\"\n    Main solver function to execute the computation for all test cases.\n    \"\"\"\n    test_cases = [\n        (8, 4),    # general\n        (3, 2),    # near-minimal coarse space\n        (10, 2),   # aggressive coarsening\n        (12, 11),  # near-identity coarsening\n    ]\n\n    results = []\n    for p_f, p_c in test_cases:\n        rho = calculate_rho(p_f, p_c)\n        results.append(rho)\n\n    print(f\"[{','.join(f'{r:.15f}' for r in results)}]\")\n\nsolve()\n```", "id": "3401559"}, {"introduction": "拥有了可靠的粗网格算子和传递算子后，最后一步是将这些组件组织成一个高效的递归算法。本练习使用一个简化的误差模态分析模型，来比较V循环、W循环和F循环等不同多重网格策略的性能。您将通过分析不同循环的收敛能力与其计算成本之间的权衡，学会如何在不同条件下选择最优的算法策略，从而最大化求解器的整体效率 [@problem_id:3401572]。", "problem": "您的任务是为谱方法或间断Galerkin方法中的多项式次数多重网格（也称为 $p$-多重网格）设计并实现一个多重网格循环类型的前瞻性比较。\n\n该比较必须由一个简化但有原则的模态误差传播模型驱动，该模型需捕捉其基本特征：光滑过程对高次模态分量的衰减更强，而粗网格校正减少了可在粗多项式空间上表示的误差分量，但除非最粗层系统被精确求解，否则校正过程是不精确的。\n\n您的程序必须实现以下组件，这些组件源自对称正定问题中模态表示和线性多重网格循环的核心定义：\n\n- 将多项式次数为 $p$ 的单个单元上的误差表示为分层正交多项式基中的模态系数向量 $\\{e_m\\}_{m=0}^{p}$，其中 $m$ 是模态指数。初始误差谱由幂律振幅形状 $e_m \\propto (m+1)^{-\\beta}$ 指定，其中给定 $\\beta \\ge 0$。这与在谱方法或间断Galerkin算子的模态基中展开误差是一致的，并反映了椭圆问题中常见的与光滑度加权的谱。\n\n- 定义一个光滑算子 $S_p$，它对模态分量进行对角作用。对于次数为 $p$ 的单次光滑扫描，模态 $m$ 上的缩减因子为\n$$\n\\rho_s(m;p) \\;=\\; \\exp\\!\\big(-\\sigma\\,\\theta_m^{\\kappa}\\big), \\qquad \\theta_m \\;=\\; \\frac{m}{p},\n$$\n其中参数 $\\sigma0$ 和 $\\kappa0$ 是固定的。设有 $ \\nu_{\\text{pre}} $ 次前光滑扫描和 $ \\nu_{\\text{post}} $ 次后光滑扫描，在次数为 $p$ 的粗网格校正前后，总的光滑因子分别为\n$$\n\\rho_{\\text{pre}}(m;p) \\;=\\; \\exp\\!\\big(-\\sigma\\,\\nu_{\\text{pre}}\\,\\theta_m^{\\kappa}\\big), \\qquad\n\\rho_{\\text{post}}(m;p) \\;=\\; \\exp\\!\\big(-\\sigma\\,\\nu_{\\text{post}}\\,\\theta_m^{\\kappa}\\big).\n$$\n\n- 将 $p$-多重网格的限制算子定义为将模态截断到次数 $p_c$（粗网格次数），将延长算子定义为注入到细网格的低阶模态子空间中。多项式次数缩减策略为以下之一：\n    - 折半 (Halving): $p \\mapsto p_c = \\max(1,\\lfloor p/2 \\rfloor)$。\n    - 递减 (Decrement): $p \\mapsto p_c = \\max(1,p-1)$。\n  粗网格校正是通过在粗层上递归应用一次多重网格循环来计算的，除了在最粗层的递归终止时，这个过程都是不精确的。粗网格校正用在粗网格上计算出的循环后值替换细网格上的低阶模态分量。\n\n- 将最粗次数 $p_{\\min}=1$ 处的递归终止定义为一个不精确求解，它将所有模态按一个统一因子 $\\rho_0$（其中 $0\\rho_01$）进行缩减，即在最粗层上，误差更新为 $e \\leftarrow \\rho_0 e$。这模拟了一个实际的不精确粗网格求解，并确保了循环类型的选择是有意义的。\n\n- 根据在递归深度 $\\ell$ 时每层的递归粗网格调用次数 $\\gamma_{\\ell}$，定义三种多重网格循环类型：\n    - $V$循环：对所有 $\\ell$，$\\gamma_{\\ell}=1$。\n    - $W$循环：对所有 $\\ell$，$\\gamma_{\\ell}=2$。\n    - 嵌套 $F$循环：在最细层（深度 $\\ell=0$）$\\gamma_{0}=1$，在所有更深层 $\\ell \\ge 1$ 时 $\\gamma_{\\ell}=2$。\n  对于次数为 $pp_{\\min}$ 的层，该层的一次循环误差更新过程如下：\n  1. 前光滑：对所有 $m$， $e_m \\leftarrow \\rho_{\\text{pre}}(m;p)\\, e_m$。\n  2. 粗网格校正：令 $p_c$ 为粗网格次数。对于 $i=1,\\dots,\\gamma_{\\ell}$，将当前低阶模态限制到粗网格，在粗网格上应用一次完整循环以获得更新后的粗网格误差，然后通过替换细网格层上的低阶项，将更新后的粗网格低阶模态延长回来。\n  3. 后光滑：$e_m \\leftarrow \\rho_{\\text{post}}(m;p)\\, e_m$。\n\n- 定义一个每次循环的工作量模型以比较不同循环的效率。令成本单位与某一层上的模态系数数量 $(p+1)$ 成正比。在次数为 $p$、递归深度为 $\\ell$ 时的工作量模型为\n$$\nW(p,\\ell) \\;=\\; c_s\\,(\\nu_{\\text{pre}}+\\nu_{\\text{post}})\\,(p+1) \\;+\\; c_{\\text{corr}}\\,(p+1) \\;+\\; \\gamma_{\\ell}\\, W(p_c,\\ell+1),\n$$\n在最粗次数上的基础成本为\n$$\nW(p_{\\min},\\ell) \\;=\\; c_{\\text{coarse}}\\,(p_{\\min}+1).\n$$\n该模型模拟了在次数 $p$ 的每次循环中，执行了前/后光滑、一个粗网格校正阶段以及数量等于 $\\gamma_{\\ell}$ 的递归粗网格循环。\n\n- 对于给定的 $(p,\\beta)$ 和选定的次数缩减策略，将次数 $p$ 的初始模态振幅定义为\n$$\ne_m^{(0)} \\;=\\; (m+1)^{-\\beta}, \\quad m=0,\\dots,p.\n$$\n令 $e^{(1)}$ 表示在最细层上经过一次多重网格循环后的误差向量。将每次循环的能量缩减因子定义为\n$$\nr \\;=\\; \\frac{\\sum_{m=0}^{p} \\left(e_m^{(1)}\\right)^2}{\\sum_{m=0}^{p} \\left(e_m^{(0)}\\right)^2}.\n$$\n将每十倍（以10为底）误差缩减所需的工作量（WPD）定义为\n$$\n\\text{WPD} \\;=\\; \\frac{W(p,0)}{-\\log_{10}(r)},\n$$\n约定如果 $r \\ge 1$，则 $\\text{WPD}=+\\infty$。\n\n- 对于下方的每个测试用例，您的程序必须计算三种循环类型各自的预测 $\\text{WPD}$，并返回最小化 $\\text{WPD}$ 的最优循环类型的索引。使用以下索引编码：$0$ 表示 $V$循环，$1$ 表示 $W$循环，$2$ 表示嵌套 $F$循环。如果在 $10^{-8}$ 的容差范围内出现数值上的平局，选择总工作量 $W(p,0)$ 较小的循环类型；如果在此容差范围内仍然平局，则选择最小的索引。\n\n模型使用以下固定参数：\n- 光滑器参数：$\\nu_{\\text{pre}}=\\nu_{\\text{post}}=2$, $\\sigma=2.5$, $\\kappa=2$。\n- 最粗层缩减率：$\\rho_0=0.2$。\n- 工作量模型系数：$c_s=1.0$, $c_{\\text{corr}}=0.5$, $c_{\\text{coarse}}=2.0$。\n- 最小次数：$p_{\\min}=1$。\n\n您的程序必须评估以下输入测试套件。每个测试是一个元组 $(p,\\beta,\\text{strategy})$，其中 strategy 是上面定义的 halving 或 decrement：\n- 测试 A: $(8, 2.0, \\text{halving})$。\n- 测试 B: $(8, 0.0, \\text{halving})$。\n- 测试 C: $(7, 1.5, \\text{decrement})$。\n- 测试 D: $(3, 1.0, \\text{decrement})$。\n- 测试 E: $(16, 3.0, \\text{decrement})$。\n- 测试 F: $(12, 0.5, \\text{halving})$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[resultA,resultB,resultC,resultD,resultE,resultF]”），列表中的每个结果是对应测试用例的最优循环类型的整数索引。不应打印任何额外文本。此问题不涉及任何物理单位或角度单位；所有输出均为指定的无量纲整数。", "solution": "该问题要求对多项式次数多重网格（$p$-多重网格）方法的三种多重网格循环类型——$V$循环、$W$循环和嵌套$F$循环——进行比较。该比较基于一个简化的模态误差传播模型，其目标是找到能够最小化将误差缩减十倍所需计算工作量的循环类型，该度量标准称为“每十倍误差缩减所需工作量”（Work-Per-Decade, WPD）。\n\n该解决方案通过构建一个计算模型来实现，该模型根据给定规范模拟每种循环类型的行为。整体方法封装在一个Python类 `MultigridModel` 中，该类通过记忆化（memoization）实现了清晰的关注点分离和高效计算。该模型的主要组成部分是计算工作量的递归计算和误差传播算子的递归构建。\n\n首先，我们定义函数来处理多重网格层次结构的递归结构。粗层的多项式次数 $p_c$ 由细层次数 $p$ 通过两种策略之一确定：折半，$p_c = \\max(1, \\lfloor p/2 \\rfloor)$，或递减，$p_c = \\max(1, p-1)$。在给定递归层级 $\\ell$ 的粗网格校正次数，记为 $\\gamma_\\ell$，由循环类型决定：对于$V$循环，$\\gamma_\\ell=1$；对于$W$循环，$\\gamma_\\ell=2$；对于$F$循环，$\\gamma_0=1, \\gamma_{\\ell0}=2$。\n\n在次数为 $p$、递归深度为 $\\ell$ 时，单个循环的计算工作量 $W(p, \\ell)$ 是递归计算的。总工作量是局部操作（光滑和粗网格设置）的工作量与对粗网格的递归调用的工作量之和。公式为：\n$$\nW(p,\\ell) = c_s(\\nu_{\\text{pre}}+\\nu_{\\text{post}})(p+1) + c_{\\text{corr}}(p+1) + \\gamma_{\\ell} W(p_c,\\ell+1)\n$$\n递归在最小多项式次数 $p_{\\min}=1$ 处终止，此时的工作量由一个固定的基础成本给出，$W(p_{\\min},\\ell) = c_{\\text{coarse}}(p_{\\min}+1)$。这个递归计算在一个带记忆化的函数 `calculate_work` 中实现，以避免重复计算。\n\n接下来，我们对误差传播进行建模。误差表示为模态基中的一个系数向量 $\\{e_m\\}_{m=0}^{p}$。单次多重网格循环作为线性算子作用于此误差向量。因此，我们可以构建这个单循环误差传播算子的矩阵表示，称之为 $M(p, \\ell)$。该算子也是递归计算的。\n\n在次数 $p  p_{\\min}$ 的一次循环包括三个阶段：\n1.  **前光滑**：误差乘以预光滑算子 $S_{\\text{pre}}(p)$，这是一个对角矩阵。模态 $m$ 对应的对角线元素是 $(\\rho_s(m;p))^{\\nu_{\\text{pre}}}$，其中 $\\rho_s(m;p) = \\exp(-\\sigma (m/p)^{\\kappa})$。\n2.  **粗网格校正**：此阶段校正低次模态（$m=0, \\dots, p_c$）。它涉及将递归获得的粗网格循环算子 $M(p_c, \\ell+1)$ 应用 $\\gamma_{\\ell}$ 次。\n3.  **后光滑**：误差乘以后光滑算子 $S_{\\text{post}}(p)$，其结构与 $S_{\\text{pre}}(p)$ 相同（因为 $\\nu_{\\text{pre}}=\\nu_{\\text{post}}$）。\n\n由此产生的次数为 $p$ 的单循环算子可以表示为矩阵乘积：$M(p, \\ell) = S_{\\text{post}}(p) \\cdot C(p, \\ell) \\cdot S_{\\text{pre}}(p)$，其中 $C(p, \\ell)$ 是粗网格校正算子。$C(p, \\ell)$ 是一个分块对角矩阵，它将 $(M(p_c, \\ell+1))^{\\gamma_\\ell}$ 应用于低次模态，并对高次模态起单位算子的作用。此递归的基例是 $p=p_{\\min}=1$，此时算子是一个简单的对角矩阵 $M(1, \\ell) = \\rho_0 I$，其中 $\\rho_0=0.2$ 是不精确粗网格求解的统一误差缩减因子。这个递归构建在一个带记忆化的函数 `get_cycle_operator` 中实现。\n\n利用最细层的工作量 $W(p,0)$ 和算子 $M(p,0)$，我们可以计算 WPD。初始误差向量 $e^{(0)}$ 由模态振幅 $e_m^{(0)} = (m+1)^{-\\beta}$ 生成。一次循环后的误差为 $e^{(1)} = M(p,0) e^{(0)}$。能量缩减因子是误差向量的$L^2$范数平方之比：\n$$\nr = \\frac{\\|e^{(1)}\\|_2^2}{\\|e^{(0)}\\|_2^2} = \\frac{\\sum_{m=0}^{p} (e_m^{(1)})^2}{\\sum_{m=0}^{p} (e_m^{(0)})^2}\n$$\n然后，每十倍误差缩减所需工作量（Work-Per-Decade）计算如下：\n$$\n\\text{WPD} = \\frac{W(p,0)}{-\\log_{10}(r)}\n$$\n对于每个测试用例，都对所有三种循环类型（$V$、$W$、$F$）执行此过程。通过找到最小的 WPD 来确定最优循环。在出现平局（容差为 $10^{-8}$）的情况下，选择总工作量 $W(p,0)$ 较小的循环。如果工作量也相同，则选择索引最小的循环（$V$为0，$W$为1，$F$为2）。程序依次处理指定的测试用例列表，并报告每个用例的最优循环索引。", "answer": "```python\nimport numpy as np\nfrom functools import lru_cache\n\n# Define global constants as specified in the problem\nNU_PRE = 2\nNU_POST = 2\nSIGMA = 2.5\nKAPPA = 2.0\nRHO_0 = 0.2\nC_S = 1.0\nC_CORR = 0.5\nC_COARSE = 2.0\nP_MIN = 1\n\nclass MultigridModel:\n    \"\"\"\n    Encapsulates the logic for the p-multigrid model for a specific\n    coarsening strategy, using memoization for efficiency.\n    \"\"\"\n    def __init__(self, strategy):\n        if strategy not in ['halving', 'decrement']:\n            raise ValueError(\"Strategy must be 'halving' or 'decrement'.\")\n        self.strategy = strategy\n\n    @lru_cache(maxsize=None)\n    def get_coarse_p(self, p):\n        \"\"\"Computes the coarse-grid polynomial degree.\"\"\"\n        if self.strategy == 'halving':\n            return max(P_MIN, p // 2)\n        else:  # 'decrement'\n            return max(P_MIN, p - 1)\n\n    @staticmethod\n    @lru_cache(maxsize=None)\n    def get_gamma(level, cycle_type):\n        \"\"\"Determines the number of coarse-grid calls per cycle.\"\"\"\n        if cycle_type == 'V':\n            return 1\n        elif cycle_type == 'W':\n            return 2\n        elif cycle_type == 'F':\n            return 1 if level == 0 else 2\n        else:\n            raise ValueError(\"Unknown cycle type.\")\n\n    @lru_cache(maxsize=None)\n    def calculate_work(self, p, level, cycle_type):\n        \"\"\"Recursively calculates the total work for one multigrid cycle.\"\"\"\n        if p == P_MIN:\n            return C_COARSE * (P_MIN + 1)\n        \n        p_c = self.get_coarse_p(p)\n        gamma = self.get_gamma(level, cycle_type)\n        \n        local_work = (C_S * (NU_PRE + NU_POST) + C_CORR) * (p + 1)\n        recursive_work = gamma * self.calculate_work(p_c, level + 1, cycle_type)\n        \n        return local_work + recursive_work\n\n    @lru_cache(maxsize=None)\n    def get_cycle_operator(self, p, level, cycle_type):\n        \"\"\"\n        Recursively computes the matrix representation of the one-cycle\n        error propagation operator.\n        \"\"\"\n        if p == P_MIN:\n            return RHO_0 * np.identity(p + 1)\n\n        p_c = self.get_coarse_p(p)\n        gamma = self.get_gamma(level, cycle_type)\n\n        # 1. Smoothing operators (diagonal matrices)\n        m_vals = np.arange(p + 1, dtype=float)\n        theta_m = m_vals / p\n        \n        rho_s_vals = np.exp(-SIGMA * (theta_m ** KAPPA))\n        \n        S_pre = np.diag(rho_s_vals ** NU_PRE)\n        S_post = np.diag(rho_s_vals ** NU_POST)\n\n        # 2. Coarse-grid correction operator\n        M_coarse = self.get_cycle_operator(p_c, level + 1, cycle_type)\n        M_coarse_gamma = np.linalg.matrix_power(M_coarse, gamma)\n        \n        C_op = np.identity(p + 1)\n        C_op[0:p_c + 1, 0:p_c + 1] = M_coarse_gamma\n\n        # 3. Combine operators to form the full cycle operator: M = S_post * C * S_pre\n        M = S_post @ C_op @ S_pre\n        \n        return M\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print the results.\n    \"\"\"\n    test_cases = [\n        (8, 2.0, 'halving'),   # Test A\n        (8, 0.0, 'halving'),   # Test B\n        (7, 1.5, 'decrement'), # Test C\n        (3, 1.0, 'decrement'), # Test D\n        (16, 3.0, 'decrement'),# Test E\n        (12, 0.5, 'halving'),  # Test F\n    ]\n\n    final_results = []\n    cycle_types = ['V', 'W', 'F']\n    TOL = 1e-8\n\n    for p, beta, strategy in test_cases:\n        model = MultigridModel(strategy)\n        \n        wpds = np.zeros(len(cycle_types))\n        works = np.zeros(len(cycle_types))\n\n        # Initial error vector\n        m_vals = np.arange(p + 1, dtype=float)\n        e0 = (m_vals + 1) ** (-beta)\n        E0 = np.dot(e0, e0)\n\n        if E0 == 0:\n            final_results.append(0) # Default to V-cycle if no initial error\n            continue\n            \n        for i, cycle_type in enumerate(cycle_types):\n            W = model.calculate_work(p, 0, cycle_type)\n            works[i] = W\n\n            M = model.get_cycle_operator(p, 0, cycle_type)\n            e1 = M @ e0\n            E1 = np.dot(e1, e1)\n\n            r = E1 / E0\n\n            if r >= 1.0:\n                wpds[i] = np.inf\n            elif r = 0.0: # r can be numerically slightly negative due to precision\n                wpds[i] = 0.0\n            else:\n                wpds[i] = W / (-np.log10(r))\n        \n        # Determine the optimal cycle using specified tie-breaking rules\n        min_wpd = np.min(wpds)\n        candidate_indices = np.where(np.abs(wpds - min_wpd) = TOL)[0]\n\n        if len(candidate_indices) == 1:\n            best_idx = candidate_indices[0]\n        else:\n            candidate_works = works[candidate_indices]\n            min_work = np.min(candidate_works)\n            \n            sub_candidate_indices_local = np.where(np.abs(candidate_works - min_work) = TOL)[0]\n            \n            # Map local indices back to original cycle indices\n            final_candidates = candidate_indices[sub_candidate_indices_local]\n\n            # Final tie-break: choose the smallest index\n            best_idx = np.min(final_candidates)\n\n        final_results.append(int(best_idx))\n\n    # Format output string as specified\n    print(f\"[{','.join(map(str, final_results))}]\")\n\nsolve()\n```", "id": "3401572"}]}