{"hands_on_practices": [{"introduction": "在张量积单元上，多维质量矩阵可以分解为一系列一维操作，这极大地提升了计算效率。本练习将指导您推导这种优雅的克罗内克积（Kronecker product）结构，并分析其对计算成本的深远影响。理解这种“求和分解”（sum-factorization）技术是掌握高阶不连续伽辽金方法高效性的基石。[@problem_id:3402879]", "problem": "考虑一个标量守恒律在单个$d$维矩形单元$K = \\prod_{k=1}^{d} [a_k,b_k]$上的间断Galerkin (DG) 离散化。设$n \\geq 2$为每个空间方向上的节点数，并令$\\{ \\ell_{i}^{(k)}(\\xi_k) \\}_{i=1}^{n}$表示与这些节点相关的、在参考区间$[-1,1]$上的一维Lagrange基底，其中每个方向$k \\in \\{1,\\dots,d\\}$都有对应的基底。通过\n$$\n\\phi_{\\boldsymbol{i}}(\\boldsymbol{\\xi}) \\;=\\; \\prod_{k=1}^{d} \\ell_{i_k}^{(k)}(\\xi_k), \\quad \\boldsymbol{i} = (i_1,\\dots,i_d), \\quad i_k \\in \\{1,\\dots,n\\},\n$$\n定义参考超立方体$[-1,1]^d$上的张量积节点基，并通过仿射映射$x_k = \\frac{b_k-a_k}{2}\\,\\xi_k + \\frac{a_k+b_k}{2}$（其中$k=1,\\dots,d$）将其映射到物理单元。局部DG质量矩阵块$M \\in \\mathbb{R}^{N \\times N}$（其中$N = n^d$）由精确积分定义，\n$$\nM_{\\boldsymbol{i},\\boldsymbol{j}} \\;=\\; \\int_{K} \\phi_{\\boldsymbol{i}}(\\boldsymbol{x})\\,\\phi_{\\boldsymbol{j}}(\\boldsymbol{x})\\,\\mathrm{d}\\boldsymbol{x}.\n$$\n由于基函数在单元界面上是不连续的，您可以假设整个网格上的全局质量矩阵是块对角矩阵，每个单元对应一个这样的块。\n\n1. 从$M_{\\boldsymbol{i},\\boldsymbol{j}}$的定义和张量积基的可分离性出发，证明局部质量矩阵可以写成一维质量矩阵的Kronecker积，\n$$\nM \\;=\\; M^{(1)} \\otimes M^{(2)} \\otimes \\cdots \\otimes M^{(d)},\n$$\n其中每个$M^{(k)} \\in \\mathbb{R}^{n \\times n}$是方向$k$上的一维质量矩阵，并包含了适当的仿射缩放。\n\n2. 设$v \\in \\mathbb{R}^{N}$是单元上的任意自由度向量，将其重塑为一个大小为$n \\times \\cdots \\times n$的$d$阶张量。使用求和分解（sum-factorization），通过沿每个张量模态的一系列$d$个一维运算将$M$应用于$v$。类似地，通过每个张量线上的一系列$d$个独立的一维求解来应用$M^{-1}$（假设一维矩阵分解已预先计算好，因此在应用时只计算前向和后向替换的运算量）。计算浮点运算时，将一次乘法计为一次运算，一次加法计为一次运算，因此一个乘加对计为两次运算。忽略所有低阶项和任何预计算成本。\n\n请提供一个关于$d$和$n$的封闭形式解析表达式，作为您的最终答案。该表达式表示使用求和分解在单个单元上将$M$或$M^{-1}$应用于一个向量所需的主阶浮点运算次数。答案必须是单一表达式，不含任何额外评论或条件。", "solution": "所述问题具有科学依据，是适定、客观且自洽的。它是高阶数值方法（特别是谱方法和间断Galerkin (DG) 方法）分析中的一个标准问题。该问题是有效的，下面将提供解答。\n\n问题包括两部分。首先，我们必须证明$d$维矩形单元上的局部DG质量矩阵可以表示为一维质量矩阵的Kronecker积。其次，我们必须确定使用求和分解方法将该质量矩阵或其逆矩阵应用于向量的主阶计算成本。\n\n**第一部分：质量矩阵的Kronecker积结构**\n\n局部质量矩阵$M$的$(\\boldsymbol{i}, \\boldsymbol{j})$元素由两个张量积基函数在物理单元$K = \\prod_{k=1}^{d} [a_k, b_k]$上的乘积积分定义。索引$\\boldsymbol{i}$和$\\boldsymbol{j}$是多重索引，形式为$\\boldsymbol{i} = (i_1, \\dots, i_d)$和$\\boldsymbol{j} = (j_1, \\dots, j_d)$，其中对于所有$k \\in \\{1, \\dots, d\\}$，都有$i_k, j_k \\in \\{1, \\dots, n\\}$。\n\n其定义为：\n$$\nM_{\\boldsymbol{i},\\boldsymbol{j}} = \\int_{K} \\phi_{\\boldsymbol{i}}(\\boldsymbol{x})\\,\\phi_{\\boldsymbol{j}}(\\boldsymbol{x})\\,\\mathrm{d}\\boldsymbol{x}\n$$\n基函数在参考超立方体$[-1, 1]^d$上定义为$\\phi_{\\boldsymbol{i}}(\\boldsymbol{\\xi}) = \\prod_{k=1}^{d} \\ell_{i_k}^{(k)}(\\xi_k)$。我们必须将积分变量从物理坐标$\\boldsymbol{x}$更改为参考坐标$\\boldsymbol{\\xi}$。仿射映射由$x_k = \\frac{b_k-a_k}{2}\\,\\xi_k + \\frac{a_k+b_k}{2}$给出。此变换的Jacobian矩阵是对角矩阵，其元素为：\n$$\n\\frac{\\partial x_k}{\\partial \\xi_j} = \\delta_{kj} \\frac{b_k-a_k}{2}\n$$\n其中$\\delta_{kj}$是Kronecker delta。Jacobian行列式$J$是对角元素的乘积：\n$$\nJ = \\det\\left(\\frac{\\partial \\boldsymbol{x}}{\\partial \\boldsymbol{\\xi}}\\right) = \\prod_{k=1}^{d} \\frac{b_k-a_k}{2}\n$$\n微分体积元的变换为$\\mathrm{d}\\boldsymbol{x} = J\\,\\mathrm{d}\\boldsymbol{\\xi}$。将此式及基函数的定义代入$M_{\\boldsymbol{i},\\boldsymbol{j}}$的积分中，得到：\n$$\nM_{\\boldsymbol{i},\\boldsymbol{j}} = \\int_{[-1,1]^d} \\left(\\prod_{k=1}^{d} \\ell_{i_k}^{(k)}(\\xi_k)\\right) \\left(\\prod_{k=1}^{d} \\ell_{j_k}^{(k)}(\\xi_k)\\right) \\left(\\prod_{k=1}^{d} \\frac{b_k-a_k}{2}\\right) \\mathrm{d}\\boldsymbol{\\xi}\n$$\n我们可以重组积分内的各项：\n$$\nM_{\\boldsymbol{i},\\boldsymbol{j}} = \\int_{[-1,1]^d} \\prod_{k=1}^{d} \\left( \\ell_{i_k}^{(k)}(\\xi_k) \\, \\ell_{j_k}^{(k)}(\\xi_k) \\, \\frac{b_k-a_k}{2} \\right) \\mathrm{d}\\xi_1 \\dots \\mathrm{d}\\xi_d\n$$\n由于被积函数是可分离的，我们可以应用Fubini定理将多维积分分离为一维积分的乘积：\n$$\nM_{\\boldsymbol{i},\\boldsymbol{j}} = \\prod_{k=1}^{d} \\left( \\int_{-1}^{1} \\ell_{i_k}^{(k)}(\\xi_k)\\,\\ell_{j_k}^{(k)}(\\xi_k) \\left(\\frac{b_k-a_k}{2}\\right) \\mathrm{d}\\xi_k \\right)\n$$\n我们为每个方向$k$定义一维质量矩阵$M^{(k)} \\in \\mathbb{R}^{n \\times n}$如下：\n$$\nM^{(k)}_{i_k, j_k} = \\frac{b_k-a_k}{2} \\int_{-1}^{1} \\ell_{i_k}^{(k)}(\\xi_k) \\, \\ell_{j_k}^{(k)}(\\xi_k) \\, \\mathrm{d}\\xi_k\n$$\n根据这个定义，完整的$d$维质量矩阵的元素变为：\n$$\nM_{\\boldsymbol{i},\\boldsymbol{j}} = M^{(1)}_{i_1, j_1} M^{(2)}_{i_2, j_2} \\cdots M^{(d)}_{i_d, j_d}\n$$\n这正是矩阵$M^{(1)}, \\dots, M^{(d)}$的Kronecker积的$(\\boldsymbol{i}, \\boldsymbol{j})$元素的定义，其中多重索引$\\boldsymbol{i}$和$\\boldsymbol{j}$被映射到单个行和列索引（例如，按字典序）。因此，我们证明了：\n$$\nM = M^{(1)} \\otimes M^{(2)} \\otimes \\cdots \\otimes M^{(d)}\n$$\n\n**第二部分：浮点运算计数**\n\n我们需要找到计算矩阵-向量积$u = Mv$或求解方程组$Mu=v$（即计算$u = M^{-1}v$）所需的主阶浮点运算次数（FLOPS），其中向量$v \\in \\mathbb{R}^N$，$N=n^d$。求和分解方法将向量$v$重塑为一个大小为$n \\times \\cdots \\times n$的$d$阶张量$V$。然后，乘积$u$被计算为同样大小的张量$U$。\n\n**情况1：$M$的应用**\n\n对于$M = M^{(1)} \\otimes \\cdots \\otimes M^{(d)}$，乘积$u=Mv$通过一系列$d$次运算完成，每个运算对应张量$V$的一个维度。设初始张量为$V^{(0)} = V$。该序列为：对于$k = 1, \\dots, d$，通过将$M^{(k)}$应用于$V^{(k-1)}$的第$k$个模态来计算$V^{(k)}$。\n我们来分析这样一个步骤的成本，例如，将$M^{(1)}$应用于第一个模态。计算过程如下：\n$$\n(V^{(1)})_{i_1, i_2, \\dots, i_d} = \\sum_{j_1=1}^{n} M^{(1)}_{i_1, j_1} (V^{(0)})_{j_1, i_2, \\dots, i_d}\n$$\n对于每个固定的索引集$(i_2, \\dots, i_d)$，此操作是$n \\times n$矩阵$M^{(1)}$与一个长度为$n$的向量的矩阵-向量积。共有$n^{d-1}$个这样的固定索引集，对应于张量沿第一个模態的$n^{d-1}$条“纤维”（fiber）。\n\n单个$n \\times n$稠密矩阵-向量积的成本计算如下：对于输出向量的$n$行中的每一行，我们执行两个长度为$n$的向量的点积。这涉及$n$次乘法和$n-1$次加法，总共$n + (n-1) = 2n-1$次浮点运算。对于所有$n$行，总成本为$n(2n-1) = 2n^2 - n$次浮点运算。主阶成本为$2n^2$次浮点运算。\n\n求和分解一步（例如，将$M^{(1)}$应用于第一个模态）的成本是纤维数量乘以每条纤维的成本：\n$$\n\\text{Cost per step} = n^{d-1} \\times (2n^2 - n) = 2n^{d+1} - n^d\n$$\n一步的主阶成本是$2n^{d+1}$。由于有$d$个这样的步骤（每个维度一个），应用$M$的总主阶成本是：\n$$\n\\text{Total cost for } Mv = d \\times (2n^{d+1}) = 2dn^{d+1}\n$$\n\n**情况2：$M^{-1}$的应用**\n\nKronecker积的逆是逆的Kronecker积：\n$$\nM^{-1} = (M^{(1)} \\otimes \\cdots \\otimes M^{(d)})^{-1} = (M^{(1)})^{-1} \\otimes \\cdots \\otimes (M^{(d)})^{-1}\n$$\n$M^{-1}$的应用遵循相同的求和分解过程，但每一步都涉及应用一维质量矩阵的逆，即$(M^{(k)})^{-1}$。这等效于求解一个线性方程组。问题指定我们假设每个$M^{(k)}$都有一个预先计算好的分解（例如LU分解）。\n将$(M^{(k)})^{-1}$应用于向量$x$意味着求解$M^{(k)}y=x$以得到$y$。对于预先计算的LU分解$M^{(k)}=L^{(k)}U^{(k)}$，这分两个阶段完成：\n1.  使用前向替换求解$L^{(k)}z=x$。\n2.  使用后向替换求解$U^{(k)}y=z$。\n\n对于一个稠密的$n \\times n$下三角矩阵，前向替换需要$\\sum_{i=1}^{n} (2(i-1)) = n(n-1) = n^2-n$次浮点运算。对于一个稠密的上三角矩阵，后向替换需要$n^2$次浮点运算。求解一个$n \\times n$方程组的总成本是$(n^2-n) + n^2 = 2n^2-n$次浮点运算。主阶成本是$2n^2$次浮点运算。\n\n这个主阶成本与稠密矩阵-向量乘法的成本相同。因此，将$(M^{(k)})^{-1}$应用于一个向量的成本，在主阶上是$2n^2$次浮点运算。\n应用$M^{-1}$的总成本是$d$个步骤的成本之和，每个步骤涉及$n^{d-1}$次一维求解：\n$$\n\\text{Total cost for } M^{-1}v = d \\times (n^{d-1} \\times 2n^2) = 2dn^{d+1}\n$$\n应用$M$或$M^{-1}$的主阶运算次数是相同的。\n\n主阶浮点运算次数的最终表达式是$2dn^{d+1}$。", "answer": "$$\n\\boxed{2dn^{d+1}}\n$$", "id": "3402879"}, {"introduction": "虽然对角化（集中）质量矩阵在计算上极具吸引力，但它本质上是一种近似。本练习探讨了这种近似误差的一个关键来源：单元的几何弯曲（由非恒定的雅可比行列式 $J(\\xi)$ 体现）。通过显式计算精确质量矩阵项与集中质量矩阵项之间的差异，您将对混叠误差（aliasing error）有一个具体的认识。[@problem_id:3402889]", "problem": "考虑一维参考单元 $\\xi \\in [-1,1]$，它通过多项式映射 $x(\\xi)$ 映射到一个弯曲的物理单元，其雅可比行列式为 $J(\\xi) = 1 + \\alpha \\xi + \\beta \\xi^{2}$，其中 $\\alpha$ 和 $\\beta$ 是实数参数。在一个节点间断伽辽金(DG)方法中，该单元上的质量矩阵由矩阵元 $M_{ij} = \\int_{-1}^{1} \\ell_{i}(\\xi)\\,\\ell_{j}(\\xi)\\,J(\\xi)\\,\\mathrm{d}\\xi$ 定义，其中 $\\{\\ell_{i}\\}$ 是拉格朗日节点基多项式。当插值节点与高斯-洛巴托-勒让德(GLL)求积节点配置在同一位置时，通过计算下式可构成一个近似对角质量矩阵：\n$$\n\\tilde{M}_{ii} = \\sum_{q=1}^{N} w_{q}\\,\\ell_{i}(\\xi_{q})\\,\\ell_{i}(\\xi_{q})\\,J(\\xi_{q}),\n$$\n其中 $\\{\\xi_{q}\\}$ 和 $\\{w_{q}\\}$ 分别是GLL节点和权重。取 $N=3$，此时GLL节点为 $\\xi_{1}=-1$, $\\xi_{2}=0$, $\\xi_{3}=1$，相应的权重为 $w_{1}=\\frac{1}{3}$, $w_{2}=\\frac{4}{3}$, $w_{3}=\\frac{1}{3}$。设节点基为经过这些节点的2次拉格朗日多项式。关注与中间节点 $i=2$（位于 $\\xi=0$）相关的对角元。\n\n从以上定义出发，除了给定的映射和节点外，不作任何特殊结构假设，计算：\n- 配置GLL近似值 $\\tilde{M}_{22}$。\n- 精确积分 $M_{22} = \\int_{-1}^{1} \\ell_{2}(\\xi)^{2}\\,J(\\xi)\\,\\mathrm{d}\\xi$。\n\n将配置求积下由雅可比行列式引起的混叠误差定义为\n$$\n\\Delta(\\alpha,\\beta) = M_{22} - \\tilde{M}_{22}.\n$$\n\n提供 $\\Delta(\\alpha,\\beta)$ 的一个闭式解析表达式，并将其简化为只含 $\\beta$ 的形式。你的最终答案必须是单个解析表达式。不需要进行四舍五入。", "solution": "用户希望我解决一个问题。\n\n我的计划如下：\n1.  我将首先验证用户的问题陈述。\n2.  如果问题有效，我将构造与节点 $\\xi=0$ 对应的拉格朗日基多项式 $\\ell_{2}(\\xi)$。\n3.  接下来，我将使用给定的求积法则计算配置GLL近似值 $\\tilde{M}_{22}$。\n4.  然后，我将计算质量矩阵元 $M_{22}$ 的精确积分。\n5.  最后，我将计算它们的差值 $\\Delta(\\alpha,\\beta) = M_{22} - \\tilde{M}_{22}$ 并简化表达式。\n\n**问题验证**\n\n**步骤1：提取已知条件**\n-   一维参考单元：$\\xi \\in [-1,1]$。\n-   映射的雅可比行列式：$J(\\xi) = 1 + \\alpha \\xi + \\beta \\xi^{2}$，其中 $\\alpha, \\beta \\in \\mathbb{R}$。\n-   精确质量矩阵元定义：$M_{ij} = \\int_{-1}^{1} \\ell_{i}(\\xi)\\,\\ell_{j}(\\xi)\\,J(\\xi)\\,\\mathrm{d}\\xi$。\n-   近似对角质量矩阵元定义：$\\tilde{M}_{ii} = \\sum_{q=1}^{N} w_{q}\\,\\ell_{i}(\\xi_{q})\\,\\ell_{i}(\\xi_{q})\\,J(\\xi_{q})$。\n-   GLL点数：$N=3$。\n-   GLL节点：$\\xi_{1}=-1$, $\\xi_{2}=0$, $\\xi_{3}=1$。\n-   GLL权重：$w_{1}=\\frac{1}{3}$, $w_{2}=\\frac{4}{3}$, $w_{3}=\\frac{1}{3}$。\n-   节点基：经过GLL节点的2次拉格朗日多项式 $\\{\\ell_{i}(\\xi)\\}$。\n-   目标矩阵元：中间节点 $i=2$（位于 $\\xi=0$）的对角元。\n-   混叠误差定义：$\\Delta(\\alpha,\\beta) = M_{22} - \\tilde{M}_{22}$。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学上成立**：该问题设置在数值分析这一成熟领域内，具体涉及间断伽辽金方法。所有概念，如拉格朗日基、质量矩阵、GLL求积和雅可比行列式，都是标准的且定义正确。\n-   **适定的**：该问题要求计算两个明确定义的量及其差值。所有必要的信息（节点、权重、函数）都已提供，确保了唯一解的存在。\n-   **客观的**：该问题以精确的数学语言陈述，没有歧义或主观因素。\n-   **完备性**：该问题是自洽的。$M_{22}$、$ \\tilde{M}_{22}$、$J(\\xi)$、基函数和求积法则的定义都已明确给出。\n-   **一致性**：在所提供的数据或定义中没有内部矛盾。\n\n**步骤3：结论与行动**\n该问题是有效的。这是一个计算数学中的标准、适定的问题。我现在将开始求解。\n\n**求解推导**\n\n**1. 确定拉格朗日基多项式 $\\ell_{2}(\\xi)$**\n节点基由经过节点 $\\xi_{1}=-1$, $\\xi_{2}=0$ 和 $\\xi_{3}=1$ 的2次拉格朗日多项式组成。基多项式 $\\ell_{2}(\\xi)$ 由性质 $\\ell_{2}(\\xi_{j}) = \\delta_{2j}$ 定义，其中 $\\delta_{2j}$ 是克罗内克δ函数。这意味着 $\\ell_{2}(\\xi)$ 在 $\\xi_{1}=-1$ 和 $\\xi_{3}=1$ 处必须为零，在 $\\xi_{2}=0$ 处必须等于一。\n\n$\\ell_{2}(\\xi)$ 的形式必为 $C(\\xi - \\xi_{1})(\\xi - \\xi_{3})$，其中 C 是某个常数。\n$$\n\\ell_{2}(\\xi) = C(\\xi - (-1))(\\xi - 1) = C(\\xi+1)(\\xi-1) = C(\\xi^{2} - 1)\n$$\n为了求出 $C$，我们使用条件 $\\ell_{2}(0) = 1$：\n$$\n1 = C(0^{2} - 1) = -C \\implies C = -1\n$$\n因此，所求的拉格朗日多项式为：\n$$\n\\ell_{2}(\\xi) = -( \\xi^{2} - 1) = 1 - \\xi^{2}\n$$\n\n**2. 计算配置GLL近似值 $\\tilde{M}_{22}$**\n问题将近似质量矩阵元定义为：\n$$\n\\tilde{M}_{22} = \\sum_{q=1}^{3} w_{q}\\,\\ell_{2}(\\xi_{q})\\,\\ell_{2}(\\xi_{q})\\,J(\\xi_{q})\n$$\n由于插值节点与求积节点配置在同一位置，我们有 $\\ell_{2}(\\xi_{q}) = \\delta_{2q}$。我们可以对每个求积点计算这个值：\n-   对于 $q=1$：$\\ell_{2}(\\xi_{1}) = \\ell_{2}(-1) = 1 - (-1)^{2} = 0$。\n-   对于 $q=2$：$\\ell_{2}(\\xi_{2}) = \\ell_{2}(0) = 1 - (0)^{2} = 1$。\n-   对于 $q=3$：$\\ell_{2}(\\xi_{3}) = \\ell_{2}(1) = 1 - (1)^{2} = 0$。\n\n求和式得以简化，因为只有 $q=2$ 的项非零：\n$$\n\\tilde{M}_{22} = w_{1}(0)^{2}J(\\xi_{1}) + w_{2}(1)^{2}J(\\xi_{2}) + w_{3}(0)^{2}J(\\xi_{3}) = w_{2}J(\\xi_{2})\n$$\n已知 $w_{2} = \\frac{4}{3}$ 且 $\\xi_{2}=0$。雅可比行列式为 $J(\\xi) = 1 + \\alpha \\xi + \\beta \\xi^{2}$。在 $\\xi_{2}=0$ 处：\n$$\nJ(0) = 1 + \\alpha(0) + \\beta(0)^{2} = 1\n$$\n代入这些值：\n$$\n\\tilde{M}_{22} = \\frac{4}{3} \\cdot 1 = \\frac{4}{3}\n$$\n\n**3. 计算精确积分 $M_{22}$**\n精确质量矩阵元由以下积分给出：\n$$\nM_{22} = \\int_{-1}^{1} \\ell_{2}(\\xi)^{2}\\,J(\\xi)\\,\\mathrm{d}\\xi\n$$\n代入 $\\ell_{2}(\\xi)$ 和 $J(\\xi)$ 的表达式：\n$$\nM_{22} = \\int_{-1}^{1} (1 - \\xi^{2})^{2}\\,(1 + \\alpha \\xi + \\beta \\xi^{2})\\,\\mathrm{d}\\xi\n$$\n首先，展开被积函数：\n$$\n(1 - 2\\xi^{2} + \\xi^{4})(1 + \\alpha \\xi + \\beta \\xi^{2}) = (1 - 2\\xi^{2} + \\xi^{4}) + (\\alpha\\xi - 2\\alpha\\xi^{3} + \\alpha\\xi^{5}) + (\\beta\\xi^{2} - 2\\beta\\xi^{4} + \\beta\\xi^{6})\n$$\n按 $\\xi$ 的幂次分组各项：\n$$\n1 + \\alpha\\xi + (\\beta - 2)\\xi^{2} - 2\\alpha\\xi^{3} + (1 - 2\\beta)\\xi^{4} + \\alpha\\xi^{5} + \\beta\\xi^{6}\n$$\n我们在对称区间 $[-1, 1]$ 上对这个多项式进行积分。所有含 $\\xi$ 奇次幂的项的积分都将为零。因此，涉及 $\\alpha$ 的项会消失。\n$$\nM_{22} = \\int_{-1}^{1} (1 + (\\beta - 2)\\xi^{2} + (1 - 2\\beta)\\xi^{4} + \\beta\\xi^{6})\\,\\mathrm{d}\\xi\n$$\n我们使用通用公式 $\\int_{-1}^{1} \\xi^{2n}\\,\\mathrm{d}\\xi = \\frac{2}{2n+1}$：\n$$\nM_{22} = \\left[ \\xi \\right]_{-1}^{1} + (\\beta - 2) \\left[ \\frac{\\xi^{3}}{3} \\right]_{-1}^{1} + (1 - 2\\beta) \\left[ \\frac{\\xi^{5}}{5} \\right]_{-1}^{1} + \\beta \\left[ \\frac{\\xi^{7}}{7} \\right]_{-1}^{1}\n$$\n$$\nM_{22} = 2 + (\\beta - 2)\\frac{2}{3} + (1 - 2\\beta)\\frac{2}{5} + \\beta\\frac{2}{7}\n$$\n现在，我们简化这个表达式：\n$$\nM_{22} = 2 + \\frac{2\\beta}{3} - \\frac{4}{3} + \\frac{2}{5} - \\frac{4\\beta}{5} + \\frac{2\\beta}{7}\n$$\n分别合并常数项和含 $\\beta$ 的项：\n$$\n\\text{常数项} = 2 - \\frac{4}{3} + \\frac{2}{5} = \\frac{30 - 20 + 6}{15} = \\frac{16}{15}\n$$\n$$\n\\text{含 } \\beta \\text{ 的项} = \\beta\\left(\\frac{2}{3} - \\frac{4}{5} + \\frac{2}{7}\\right) = \\beta\\left(\\frac{2 \\cdot 35 - 4 \\cdot 21 + 2 \\cdot 15}{105}\\right) = \\beta\\left(\\frac{70 - 84 + 30}{105}\\right) = \\frac{16\\beta}{105}\n$$\n所以，精确积分为：\n$$\nM_{22} = \\frac{16}{15} + \\frac{16}{105}\\beta\n$$\n\n**4. 计算混叠误差 $\\Delta(\\alpha,\\beta)$**\n混叠误差是精确值与近似值之间的差：\n$$\n\\Delta(\\alpha,\\beta) = M_{22} - \\tilde{M}_{22}\n$$\n代入我们求得的表达式：\n$$\n\\Delta(\\alpha,\\beta) = \\left(\\frac{16}{15} + \\frac{16}{105}\\beta\\right) - \\frac{4}{3}\n$$\n为了简化，对常数项进行通分：\n$$\n\\Delta(\\alpha,\\beta) = \\frac{16}{15} - \\frac{4 \\cdot 5}{3 \\cdot 5} + \\frac{16}{105}\\beta = \\frac{16 - 20}{15} + \\frac{16}{105}\\beta\n$$\n$$\n\\Delta(\\alpha,\\beta) = -\\frac{4}{15} + \\frac{16}{105}\\beta\n$$\n这就是混叠误差的最终表达式，它如题所求，仅取决于 $\\beta$。", "answer": "$$\\boxed{-\\frac{4}{15} + \\frac{16}{105}\\beta}$$", "id": "3402889"}, {"introduction": "本计算练习旨在连接理论与实践，您将实现不连续伽辽金方法中的一个基本算法——$L^2$ 投影。通过分别使用对角（集中）质量矩阵和一致（完全积分）质量矩阵进行计算，您将能比较这两种方法的结果，从而在真实场景中深入理解计算成本与精度之间的权衡。此练习充分利用了全局质量矩阵的块对角特性，将所有计算都局限在单元内部。[@problem_id:3402900]", "problem": "考虑一个一维分区定义域和一个使用勒让德-高斯-洛巴托（GLL）节点的节点间断伽辽金（DG）方法。您需要设计并实现一个程序，该程序利用质量矩阵的块对角结构来构造单元局部的 $L^2$ 投影，比较对角（集中）质量近似与一致（精确积分）质量矩阵，并定量分析混叠误差。该程序必须为指定的测试套件生成单行数值输出。\n\n使用的基本定义和事实如下：\n- 对于给定的单元 $e$，其局部参考坐标为 $\\xi \\in [-1,1]$，到物理坐标的映射为 $x(\\xi) = \\frac{x_R - x_L}{2}\\,\\xi + \\frac{x_R + x_L}{2}$，其雅可比行列式为 $J_e = \\frac{x_R - x_L}{2}$。\n- 函数 $u$ 在一个次数至多为 $k$ 的多项式空间 $V_k$ 上的单元局部 $L^2$ 投影旨在寻找 $u_k \\in V_k$，使得对于所有单元局部基函数 $\\{\\phi_i\\}_{i=0}^k$，都有 $(\\phi_i, u_k)_{L^2(e)} = (\\phi_i, u)_{L^2(e)}$。这会在每个单元上导出一个以单元局部质量矩阵为左侧的线性系统。\n- 在GLL节点 $\\{\\xi_j\\}_{j=0}^k$ 上的节点DG设置中，拉格朗日基的定义为 $\\phi_j(\\xi_i) = \\delta_{ij}$。质量矩阵可以通过对基函数的乘积进行积分来组装。使用精确积分会得到一个完整的（一致的）质量矩阵。使用与节点集相关联的GLL求积会得到一个对角的（集中的）近似，该近似通常不完全等于一致质量矩阵。\n- 混叠指的是由于积分不足或用低阶离散表示来表示高阶内容而产生的误差。\n\n设计要求：\n- 在一维定义域 $[a,b] = [-1,1]$ 上工作。将其划分为 $E$ 个相等的单元。在每个单元上，令 $V_N$ 为GLL节点上次数至多为 $N$ 的节点多项式空间，令 $V_k$ 为次数至多为 $k$ 的节点多项式空间，除非另有说明，否则 $k  N$。\n- 每个单元上的输入场是在单元上的 $N$ 阶GLL节点处对给定目标函数 $u(x)$ 进行采样，并形成单元局部拉格朗日插值函数而得到的节点 $N$ 阶插值函数 $u_N^h \\in V_N$。这个 $u_N^h$ 是要投影到 $V_k$ 上的场。\n- 实现两种到 $V_k$ 上的单元局部投影算子：\n  1. 使用 $k$ 阶GLL求积和 $k$ 阶GLL基计算的对角（集中）质量的投影。根据构造，该质量矩阵是对角的，并能实现快速的逐单元求解。\n  2. 使用通过足够精确的高斯-勒让德求积组装的一致（精确积分到数值精度）质量矩阵的投影，使得次数高达至少 $N+k$ 的多项式被积函数被积分到机器精度。\n- 对每个单元，对于两种方法，计算投影场在 $k$ 阶GLL节点处的节点系数。\n- 定义一个 $L^2$ 投影的基准参考如下：使用足够精确以处理所涉及被积函数的高阶高斯-勒让德求积来组装 $k$ 阶质量矩阵和右手边，从而使 $u_N^h$ 的投影计算到接近机器精度。将此用作 $u_N^h$ 到 $V_k$ 上的参考“精确”单元局部 $L^2$ 投影。\n- 为了在整个定义域上进行定量比较，函数 $w$ 的定义域 $L^2$ 范数定义为 $\\|w\\|_{L^2([-1,1])} = \\left(\\sum_{e=1}^E \\int_{x_L^e}^{x_R^e} w(x)^2\\,dx\\right)^{1/2}$。范数评估所需的所有积分都必须通过足够高阶的高斯-勒让德求积来计算，以确保精度接近机器精度。\n\n你的程序必须：\n- 为任意非负整数 $m$ 构造 $m$ 阶GLL节点和权重，并根据需要组装拉格朗日插值/求值算子。\n- 在每个单元上实现两种投影方法。通过仅构造和求解逐单元系统来利用块对角结构。确保对角质量版本专门用于计算成本更低的逐单元过程。\n- 对于以下套件中的每个测试用例，计算三个浮点数：\n  1. $e_{\\mathrm{diff}}$：对角质量投影和一致质量投影之差的定义域 $L^2$ 范数，即 $\\|u_k^{\\mathrm{diag}} - u_k^{\\mathrm{cons}}\\|_{L^2([-1,1])}$。\n  2. $e_{\\mathrm{cons}}$：一致质量投影和基准参考投影之差的定义域 $L^2$ 范数，即 $\\|u_k^{\\mathrm{cons}} - u_k^{\\mathrm{ref}}\\|_{L^2([-1,1])}$。\n  3. $e_{\\mathrm{diag}}$：对角质量投影和基准参考投影之差的定义域 $L^2$ 范数，即 $\\|u_k^{\\mathrm{diag}} - u_k^{\\mathrm{ref}}\\|_{L^2([-1,1])}$。\n\n角度单位：当出现三角函数时，自变量以弧度为单位。\n\n测试套件：\n- 案例 A：$E = 3$，$N = 6$，$k = 3$，$u(x) = x^6 - 3 x^2 + 1$。\n- 案例 B：$E = 4$，$N = 7$，$k = 4$，$u(x) = \\sin(7 x)$，其中 $x$ 以弧度为单位。\n- 案例 C：$E = 2$，$N = 5$，$k = 5$，$u(x) = e^{x}$。\n- 案例 D：$E = 1$，$N = 8$，$k = 3$，$u(x) = P_{4}(x)$，其中 $P_{4}$ 是 $[-1,1]$ 上的$4$阶勒让德多项式。\n\n最终输出格式：\n- 您的程序应生成一行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，按A、B、C、D的顺序输出三元组 $[e_{\\mathrm{diff}}, e_{\\mathrm{cons}}, e_{\\mathrm{diag}}]$，并平展成一个单一列表。每个浮点数用科学记数法表示，精确到 $10$ 位有效数字。例如，一个三元组应类似于 $[1.234567890e-03,2.345678901e-04,3.456789012e-05]$，所有四个案例的总体输出应是一个包含 $12$ 个数字的单一括号列表：$[a_1,a_2,a_3,b_1,b_2,b_3,c_1,c_2,c_3,d_1,d_2,d_3]$。\n\n约束和期望：\n- 所有单元局部计算必须是独立的，因此全局质量矩阵在构造上是块对角的。对角质量方法不得组装非对角质量项。\n- 用于组装一致质量和右手边的的高斯-勒让德求积阶数必须选择得足够高，以保证对次数至少为 $N+k$ 的多项式被积函数的精确性；基准求积的阶数必须显著更高，以消除范数计算中的求积误差。\n- 使用行内数学公式（如 $N$, $k$, $E$ 和 $10$）在LaTeX中表示所有数学符号、变量和数字。\n\n您的实现必须是最终答案部分中指定的完整、可运行的程序，并且不需要用户输入。输出必须是所要求格式的单行文本。", "solution": "在尝试任何解决方案之前，需要对提出的问题进行验证。\n\n### 步骤1：提取已知条件\n- **方法**：在一维分区定义域 $[-1,1]$ 上，使用勒让德-高斯-洛巴托（GLL）节点的节点间断伽辽金（DG）方法。\n- **定义域和离散化**：定义域为 $[a,b] = [-1,1]$，被划分为 $E$ 个相等的单元。参考单元为 $\\xi \\in [-1,1]$。雅可比行列式 $J_e = \\frac{x_R - x_L}{2}$。\n- **函数空间**：$V_N$ 是在 $N$ 阶GLL节点上次数至多为 $N$ 的节点多项式空间。$V_k$ 是在 $k$ 阶GLL节点上次数至多为 $k$ 的节点多项式空间，除非另有说明，否则 $k  N$。\n- **输入数据**：对于每个单元，输入是在 $N$ 阶GLL节点上对给定函数 $u(x)$ 进行采样得到的节点 $N$ 阶插值函数 $u_N^h \\in V_N$。\n- **任务**：实现并比较三种从 $V_N$ 到 $V_k$ 的单元局部 $L^2$ 投影算子。\n- **投影1（对角质量）**：质量矩阵和右手边使用 $k$ 阶GLL求积法计算。得到的质量矩阵是对角的。\n- **投影2（一致质量）**：质量矩阵和右手边使用高斯-勒让德求积法计算，其精度足以处理次数高达至少 $N+k$ 的被积函数。\n- **投影3（参考）**：与一致质量投影相同，但使用阶数显著更高的高斯-勒让德求积法，以作为基准标准，精度接近机器精度。\n- **误差度量**：对于每个测试用例，计算得到的投影场（表示为 $u_k^{\\mathrm{diag}}$、$u_k^{\\mathrm{cons}}$ 和 $u_k^{\\mathrm{ref}}$）之间差异的全域 $L^2$ 范数：\n  1. $e_{\\mathrm{diff}} = \\|u_k^{\\mathrm{diag}} - u_k^{\\mathrm{cons}}\\|_{L^2([-1,1])}$\n  2. $e_{\\mathrm{cons}} = \\|u_k^{\\mathrm{cons}} - u_k^{\\mathrm{ref}}\\|_{L^2([-1,1])}$\n  3. $e_{\\mathrm{diag}} = \\|u_k^{\\mathrm{diag}} - u_k^{\\mathrm{ref}}\\|_{L^2([-1,1])}$\n- **范数计算**：定义域 $L^2$ 范数 $\\|w\\|_{L^2([-1,1])}^2 = \\sum_{e=1}^E \\int_{x_L^e}^{x_R^e} w(x)^2\\,dx$，要求积分通过足够高阶的高斯-勒让德求积法计算。\n- **测试套件**：\n    - A: $E = 3$, $N = 6$, $k = 3$, $u(x) = x^6 - 3 x^2 + 1$。\n    - B: $E = 4$, $N = 7$, $k = 4$, $u(x) = \\sin(7 x)$。\n    - C: $E = 2$, $N = 5$, $k = 5$, $u(x) = e^{x}$。\n    - D: $E = 1$, $N = 8$, $k = 3$, $u(x) = P_{4}(x)$。\n- **输出**：包含12个浮点数的单行列表（每个测试用例三个），每个数都用科学记数法表示，并有10位有效数字。\n\n### 步骤2：使用提取的已知条件进行验证\n该问题在数值分析领域具有坚实的科学基础，特别是在谱方法和间断伽辽金方法的研究中。所使用的所有概念——$L^2$ 投影、GLL节点、拉格朗日基、质量矩阵（一致与集中）以及混叠误差——都是标准且定义明确的。该问题可以形式化为一个精确的数值算法。所提供的信息是自洽且充分的，足以构建解决方案；虽然求积阶数的“显著更高”一词没有严格定义，但在建立基准解的背景下其意图是明确的，并且可以选择一个合理的高阶法则来满足此要求。该问题是适定的，因为到有限维空间上的 $L^2$ 投影涉及对一个对称正定质量矩阵求逆，这保证了唯一解的存在。指定的测试用例在计算上是可行的，并包含非平凡场景（例如，案例C中 $k=N$ 和案例D中使用正交多项式），可用于验证实现的正确性。该问题是计算科学中的一个实质性练习，而非一个微不足道或同义反复的任务。\n\n### 步骤3：结论与行动\n该问题是**有效的**。将构建一个解决方案。\n\n### 解决方案\n目标是分析在节点间断伽辽金（DG）框架中，用于计算 $L^2$ 投影的不同数值积分方案所引入的误差。全局DG解是逐个单元构建的，从而形成一个块对角系统。我们专注于单个单元内的计算。\n\n对于一个单元 $e$，函数 $f$ 到多项式空间 $V_k$ 的 $L^2$ 投影旨在寻找一个函数 $f_k \\in V_k$，使得对于所有测试函数 $v \\in V_k$，正交条件 $(f - f_k, v)_{L^2(e)} = 0$ 都得到满足。在 $V_k$ 的节点基中展开 $f_k$，$f_k(\\xi) = \\sum_{j=0}^k \\hat{f}_j \\phi_j^{(k)}(\\xi)$，并选择测试函数为基函数本身，$v = \\phi_i^{(k)}$，会得到一个关于节点系数 $\\hat{\\mathbf{f}} = \\{\\hat{f}_j\\}_{j=0}^k$ 的线性方程组：\n$$\n\\sum_{j=0}^k \\left( \\int_e \\phi_i^{(k)} \\phi_j^{(k)} \\,dx \\right) \\hat{f}_j = \\int_e f \\, \\phi_i^{(k)} \\,dx, \\quad \\text{for } i=0, \\ldots, k.\n$$\n这就是矩阵系统 $\\mathbf{M}_e \\hat{\\mathbf{f}} = \\mathbf{b}_e$，其中 $\\mathbf{M}_e$ 是单元质量矩阵，其元素为 $M_{ij} = (\\phi_i^{(k)}, \\phi_j^{(k)})_{L^2(e)}$，而 $\\mathbf{b}_e$ 是右侧向量，其元素为 $b_i = (f, \\phi_i^{(k)})_{L^2(e)}$。在这个问题中，被投影的函数是 $f = u_N^h$，即 $u(x)$ 的 $N$ 阶插值函数。\n\n所有积分都被变换到参考单元 $\\xi \\in [-1, 1]$，引入了雅可比行列式 $J_e = (x_R^e - x_L^e)/2$。\n$$\nM_{ij} = J_e \\int_{-1}^1 \\phi_i^{(k)}(\\xi) \\phi_j^{(k)}(\\xi) \\,d\\xi, \\quad b_i = J_e \\int_{-1}^1 u_N^h(x(\\xi)) \\phi_i^{(k)}(\\xi) \\,d\\xi.\n$$\n函数 $u_N^h(x(\\xi))$ 本身是 $\\xi$ 的一个 $N$ 阶多项式，表示为对 $N$ 阶基函数的求和：$u_N^h(x(\\xi)) = \\sum_{m=0}^N u_m^{(N)} \\phi_m^{(N)}(\\xi)$，其中 $u_m^{(N)}$ 是 $u(x)$ 在 $N$ 阶GLL节点上的节点值。\n\n三种投影方法的不同之处在于它们如何近似这些积分。\n\n**1. 对角质量投影 ($u_k^{\\mathrm{diag}}$)**\n该方法采用 $k$ 阶GLL求积法则，它使用 $k+1$ 个GLL节点 $\\{\\xi_j^{(k)}\\}_{j=0}^k$ 作为求积点。相应的权重为 $\\{w_j^{(k)}\\}_{j=0}^k$。\n质量矩阵的元素近似为：\n$$\nM_{ij}^{\\mathrm{diag}} = J_e \\sum_{l=0}^k w_l^{(k)} \\phi_i^{(k)}(\\xi_l^{(k)}) \\phi_j^{(k)}(\\xi_l^{(k)}) = J_e \\sum_{l=0}^k w_l^{(k)} \\delta_{il} \\delta_{jl} = J_e w_i^{(k)} \\delta_{ij}.\n$$\n得到的质量矩阵是对角的。右手边为：\n$$\nb_i^{\\mathrm{diag}} = J_e \\sum_{l=0}^k w_l^{(k)} u_N^h(x(\\xi_l^{(k)})) \\phi_i^{(k)}(\\xi_l^{(k)}) = J_e w_i^{(k)} u_N^h(x(\\xi_i^{(k)})).\n$$\n系统 $\\mathbf{M}^{\\mathrm{diag}} \\hat{\\mathbf{u}}^{\\mathrm{diag}} = \\mathbf{b}^{\\mathrm{diag}}$ 的解是平凡的：\n$$\n\\hat{u}_i^{\\mathrm{diag}} = \\frac{b_i^{\\mathrm{diag}}}{M_{ii}^{\\mathrm{diag}}} = u_N^h(x(\\xi_i^{(k)})).\n$$\n这表明，对角质量投影等同于简单地在目标空间的节点上对输入场 $u_N^h$ 进行求值（插值）。具有 $k+1$ 个点的GLL求积法则对于次数高达 $2k-1$ 的多项式是精确的。被积函数 $\\phi_i^{(k)}\\phi_j^{(k)}$ 的次数是 $2k$，因此这个求积是不精确的，这也是“集中”或“混叠”误差的来源。\n\n**2. 一致质量投影 ($u_k^{\\mathrm{cons}}$)**\n该方法使用一个高阶高斯-勒让德求积法则，其点为 $\\{\\xi_q^{\\mathrm{cons}}\\}$，权重为 $\\{w_q^{\\mathrm{cons}}\\}$，选择该法则以确保对次数高达至少 $N+k$ 的多项式是精确的。质量矩阵的被积函数次数为 $2k$，右手边的被积函数次数为 $N+k$。求积点数 $n_{\\mathrm{cons}}$ 必须满足 $2n_{\\mathrm{cons}} - 1 \\ge N+k$，所以我们选择 $n_{\\mathrm{cons}} = \\lceil(N+k+2)/2\\rceil$。\n元素计算如下：\n$$\nM_{ij}^{\\mathrm{cons}} = J_e \\sum_q w_q^{\\mathrm{cons}} \\phi_i^{(k)}(\\xi_q^{\\mathrm{cons}}) \\phi_j^{(k)}(\\xi_q^{\\mathrm{cons}})\n$$\n$$\nb_i^{\\mathrm{cons}} = J_e \\sum_q w_q^{\\mathrm{cons}} \\left(\\sum_{m=0}^N u_m^{(N)} \\phi_m^{(N)}(\\xi_q^{\\mathrm{cons}})\\right) \\phi_i^{(k)}(\\xi_q^{\\mathrm{cons}})\n$$\n这会产生一个密集的、对称正定的质量矩阵 $\\mathbf{M}^{\\mathrm{cons}}$，需要求解一个线性系统 $\\mathbf{M}^{\\mathrm{cons}} \\hat{\\mathbf{u}}^{\\mathrm{cons}} = \\mathbf{b}^{\\mathrm{cons}}$。\n\n**3. 参考投影 ($u_k^{\\mathrm{ref}}$)**\n此方法遵循与一致质量投影相同的过程，但采用一个阶数显著更高的求积法则（$n_{\\mathrm{ref}}$ 个点），以确保积分计算达到近似精确解析结果的精度。它作为衡量其他方法的基准。\n\n**误差范数计算**\n两个投影场（例如 $u_k^A$ 和 $u_k^B$）之间的全域平方 $L^2$ 误差是逐单元平方误差的总和：\n$$\n\\|u_k^A - u_k^B\\|_{L^2([-1,1])}^2 = \\sum_{e=1}^E \\int_e (u_k^A - u_k^B)^2 dx.\n$$\n令 $\\Delta \\hat{\\mathbf{u}}_e = \\hat{\\mathbf{u}}_e^A - \\hat{\\mathbf{u}}_e^B$ 为单元 $e$ 上节点系数的差异。差分函数为 $\\Delta u_k(\\xi) = \\sum_j \\Delta \\hat{u}_{e,j} \\phi_j^{(k)}(\\xi)$。单元上的积分变为：\n$$\n\\int_e (\\Delta u_k)^2 dx = J_e \\int_{-1}^1 \\left(\\sum_i \\Delta \\hat{u}_{e,i} \\phi_i^{(k)}(\\xi)\\right) \\left(\\sum_j \\Delta \\hat{u}_{e,j} \\phi_j^{(k)}(\\xi)\\right) d\\xi = (\\Delta \\hat{\\mathbf{u}}_e)^T \\mathbf{M}_e^{\\mathrm{ref}} (\\Delta \\hat{\\mathbf{u}}_e).\n$$\n根据规定，我们使用高精度的参考质量矩阵 $\\mathbf{M}_e^{\\mathrm{ref}}$ 进行此范数计算。总误差是这些逐单元二次型之和的平方根。\n计算过程首先是准备必要的基函数和求积法则。然后，对于每个测试用例，程序遍历每个单元，计算输入函数 $u_N^h$ 的节点值，求解三个投影解 $\\hat{\\mathbf{u}}^{\\mathrm{diag}}$、$\\hat{\\mathbf{u}}^{\\mathrm{cons}}$ 和 $\\hat{\\mathbf{u}}^{\\mathrm{ref}}$，计算每个单元对总平方误差的贡献，并将它们累加起来。最后，对总和求平方根，得到所需的误差范数 $e_{\\mathrm{diff}}$、$e_{\\mathrm{cons}}$ 和 $e_{\\mathrm{diag}}$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import legendre, eval_legendre\n\ndef get_gll_nodes_weights(p):\n    \"\"\"\n    Computes the p+1 Legendre-Gauss-Lobatto nodes and weights on [-1, 1].\n    \"\"\"\n    if p == 0:\n        return np.array([0.0]), np.array([2.0])\n    if p == 1:\n        return np.array([-1.0, 1.0]), np.array([1.0, 1.0])\n    \n    # Interior nodes are roots of P_p'(x)\n    p_poly = legendre(p)\n    p_prime_poly = p_poly.deriv()\n    interior_nodes = np.sort(p_prime_poly.roots)\n    \n    nodes = np.concatenate(([-1.0], interior_nodes, [1.0]))\n    \n    # Weights\n    weights = 2.0 / (p * (p + 1.0) * eval_legendre(p, nodes)**2)\n    weights[0] = weights[-1] = 2.0 / (p * (p + 1.0))\n    \n    return nodes, weights\n\ndef get_gauss_legendre_nodes_weights(n_pts):\n    \"\"\"\n    Computes n_pts Gauss-Legendre nodes and weights on [-1, 1].\n    \"\"\"\n    if n_pts == 0:\n        return np.array([]), np.array([])\n    return np.polynomial.legendre.leggauss(n_pts)\n\ndef get_lagrange_basis_matrix(eval_points, nodes):\n    \"\"\"\n    Computes the Lagrange basis matrix L_ij = phi_j(eval_points_i).\n    \"\"\"\n    n_eval = len(eval_points)\n    n_nodes = len(nodes)\n    L = np.zeros((n_eval, n_nodes))\n    for j in range(n_nodes):\n        node_j = nodes[j]\n        den = 1.0\n        for m in range(n_nodes):\n            if m != j:\n                den *= (node_j - nodes[m])\n        \n        # Avoid division by zero if eval_points are nodes themselves\n        for i in range(n_eval):\n            pt_i = eval_points[i]\n            if np.isclose(pt_i, node_j):\n                L[i,j] = 1.0\n                continue\n\n            num = 1.0\n            for m in range(n_nodes):\n                if m != j:\n                    num *= (pt_i - nodes[m])\n            L[i, j] = num / den\n    return L\n    \ndef get_legendre_poly(deg):\n    \"\"\"Returns a function for the Legendre polynomial of degree deg.\"\"\"\n    if deg == 4: # Hardcode for P4 as per test case\n      return lambda x: (35 * x**4 - 30 * x**2 + 3) / 8.0\n    # A generic implementation would be needed for other degrees\n    # This is sufficient for the provided test suite.\n    return None\n\ndef compute_projection_errors(E, N, k, u_func):\n    \"\"\"\n    Computes the L2 error norms for the three projection methods.\n    \"\"\"\n    # 1. Domain and element geometry\n    domain = [-1.0, 1.0]\n    elem_width = (domain[1] - domain[0]) / E\n    jacobian = elem_width / 2.0\n\n    # 2. Nodes, weights, and basis functions for V_N and V_k\n    nodes_N, _ = get_gll_nodes_weights(N)\n    nodes_k, _ = get_gll_nodes_weights(k)\n\n    # 3. Quadrature rules\n    # Consistent quadrature (for mass and rhs assembly)\n    n_cons = int(np.ceil((N + k + 2) / 2.0))\n    xi_cons, w_cons = get_gauss_legendre_nodes_weights(n_cons)\n\n    # Reference quadrature (for ground truth and norm calculation)\n    # This must be very high order to serve as 'exact' integration.\n    n_ref = 50 \n    xi_ref, w_ref = get_gauss_legendre_nodes_weights(n_ref)\n\n    # 4. Vandermonde-like interpolation/evaluation matrices\n    L_N_at_k = get_lagrange_basis_matrix(nodes_k, nodes_N)\n    L_k_at_cons = get_lagrange_basis_matrix(xi_cons, nodes_k)\n    L_N_at_cons = get_lagrange_basis_matrix(xi_cons, nodes_N)\n    L_k_at_ref = get_lagrange_basis_matrix(xi_ref, nodes_k)\n    L_N_at_ref = get_lagrange_basis_matrix(xi_ref, nodes_N)\n    \n    # Pre-compute matrices on reference element [-1, 1]\n    # M_cons_ref_elem = (\\phi_i, \\phi_j), integrated with cons quad\n    M_cons_ref_elem = L_k_at_cons.T @ np.diag(w_cons) @ L_k_at_cons\n    \n    # M_ref_elem = (\\phi_i, \\phi_j), integrated with ref quad\n    M_ref_elem = L_k_at_ref.T @ np.diag(w_ref) @ L_k_at_ref\n    \n    M_ref = jacobian * M_ref_elem # This is constant for all elements\n\n    total_err_diff_sq = 0.0\n    total_err_cons_sq = 0.0\n    total_err_diag_sq = 0.0\n\n    for e in range(E):\n        # a. Element-specific data\n        x_L = domain[0] + e * elem_width\n        x_R = x_L + elem_width\n        \n        # Map reference nodes to physical element\n        x_nodes_N = x_L + (nodes_N + 1.0) * jacobian\n        \n        # b. Get input field u_N^h nodal coefficients\n        u_coeffs_N = u_func(x_nodes_N)\n        \n        # c. Diagonal mass projection (interpolation)\n        u_coeffs_diag = L_N_at_k @ u_coeffs_N\n        \n        # d. Consistent mass projection\n        M_cons = jacobian * M_cons_ref_elem\n        # Interpolate u_N^h to consistent quadrature points\n        u_vals_at_cons = L_N_at_cons @ u_coeffs_N\n        f_cons = jacobian * L_k_at_cons.T @ (w_cons * u_vals_at_cons)\n        u_coeffs_cons = np.linalg.solve(M_cons, f_cons)\n\n        # e. Reference projection\n        # M_ref is already computed\n        u_vals_at_ref = L_N_at_ref @ u_coeffs_N\n        f_ref = jacobian * L_k_at_ref.T @ (w_ref * u_vals_at_ref)\n        u_coeffs_ref = np.linalg.solve(M_ref, f_ref)\n\n        # f. Compute and accumulate squared errors\n        diff_diag_cons = u_coeffs_diag - u_coeffs_cons\n        diff_cons_ref = u_coeffs_cons - u_coeffs_ref\n        diff_diag_ref = u_coeffs_diag - u_coeffs_ref\n\n        total_err_diff_sq += diff_diag_cons.T @ M_ref @ diff_diag_cons\n        total_err_cons_sq += diff_cons_ref.T @ M_ref @ diff_cons_ref\n        total_err_diag_sq += diff_diag_ref.T @ M_ref @ diff_diag_ref\n        \n    e_diff = np.sqrt(total_err_diff_sq)\n    e_cons = np.sqrt(total_err_cons_sq)\n    e_diag = np.sqrt(total_err_diag_sq)\n    \n    return e_diff, e_cons, e_diag\n\ndef solve():\n    test_cases = [\n        # E, N, k, u(x)\n        (3, 6, 3, lambda x: x**6 - 3 * x**2 + 1),\n        (4, 7, 4, lambda x: np.sin(7 * x)),\n        (2, 5, 5, lambda x: np.exp(x)),\n        (1, 8, 3, get_legendre_poly(4)),\n    ]\n\n    results = []\n    for E, N, k, u_func in test_cases:\n        e_diff, e_cons, e_diag = compute_projection_errors(E, N, k, u_func)\n        results.extend([e_diff, e_cons, e_diag])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.9e}' for r in results)}]\")\n\nsolve()\n```", "id": "3402900"}]}