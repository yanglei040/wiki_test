{"hands_on_practices": [{"introduction": "粗粒化建模的一个核心目标是确保模型能够复现目标系统的宏观物理性质。本练习 ([@problem_id:3438715]) 将引导你实践一种常见的“性质匹配”方法，即调节耗散粒子动力学（DPD）模型中的微观相互作用参数，以精确匹配一个关键的宏观热力学量——等温压缩模量。通过这个练习，你将深入理解微观参数与宏观性质之间的直接联系，这是构建具有物理真实性的粗粒化模型的关键一步。", "problem": "考虑一个由耗散粒子动力学 (DPD) 建模的单组分流体，其保守相互作用由对力振幅 $a$ 表征，压力作为数密度 $\\rho$ 的函数遵循经验状态方程 $p(\\rho)=\\rho k_{B}T+\\alpha a \\rho^{2}$。此处，$k_{B}$ 是玻尔兹曼常数，$T$ 是绝对温度，$\\alpha$ 是一个由权重函数和截断半径的选择决定的无量纲系数。对于一个粒子数固定的系统，设等温压缩率根据第一性原理定义为 $\\kappa_{T}=-\\frac{1}{V}\\left(\\frac{\\partial V}{\\partial p}\\right)_{T}$。\n\n从此定义和给定的状态方程出发，推导保守力振幅 $a$ 的表达式，该表达式在指定密度 $\\rho$ 下产生目标等温体积模量 $B_{T}=\\kappa_{T}^{-1}$。然后，使用以下以 DPD 约化单位表示的参数，数值计算 $a$：$\\alpha=0.101$，$\\rho=3.000$，$k_{B}T=1.000$，以及目标等温体积模量 $B_{T}=48.45$。将 $a$ 的最终值以 DPD 约化单位表示，并将您的答案四舍五入到四位有效数字。", "solution": "该问题已经过验证，被认为是计算材料科学领域中一个有效的、有科学依据且适定的问题。它基于统计力学和耗散粒子动力学 (DPD) 方法的既定原理。所有必要信息均已提供，目标明确。\n\n主要任务是推导 DPD 模型中保守力振幅 $a$ 的表达式，使得系统在给定密度 $\\rho$ 下表现出目标等温体积模量 $B_T$。\n\n等温体积模量 $B_T$ 定义为等温压缩率 $\\kappa_T$ 的倒数。\n$$B_T = \\frac{1}{\\kappa_T}$$\n等温压缩率根据第一性原理定义为：\n$$\\kappa_{T} = -\\frac{1}{V}\\left(\\frac{\\partial V}{\\partial p}\\right)_{T}$$\n其中 $V$ 是体积，$p$ 是压力，下标 $T$ 表示导数是在恒定温度下求得的。这也意味着粒子数 $N$ 是恒定的。\n\n为了将此定义与给定的状态方程（数密度 $\\rho$ 的函数）联系起来，我们必须用 $\\rho$ 来表示该导数。数密度定义为 $\\rho = \\frac{N}{V}$。对于一个粒子数 $N$ 固定的系统，体积 $V$ 仅是 $\\rho$ 的函数：$V(\\rho) = \\frac{N}{\\rho}$。我们可以使用链式法则来转换关于压力的偏导数：\n$$\\left(\\frac{\\partial V}{\\partial p}\\right)_{T} = \\left(\\frac{\\partial V}{\\partial \\rho}\\right)_{T} \\left(\\frac{\\partial \\rho}{\\partial p}\\right)_{T}$$\n右边的第一项是：\n$$\\left(\\frac{\\partial V}{\\partial \\rho}\\right)_{T} = \\frac{\\partial}{\\partial \\rho}\\left(\\frac{N}{\\rho}\\right) = -\\frac{N}{\\rho^2}$$\n由于 $V = \\frac{N}{\\rho}$，我们可以写成 $\\left(\\frac{\\partial V}{\\partial \\rho}\\right)_{T} = -\\frac{V\\rho}{\\rho^2} = -\\frac{V}{\\rho}$。\n将此代回 $\\kappa_T$ 的表达式中：\n$$\\kappa_T = -\\frac{1}{V}\\left(-\\frac{V}{\\rho}\\right)\\left(\\frac{\\partial \\rho}{\\partial p}\\right)_T = \\frac{1}{\\rho}\\left(\\frac{\\partial \\rho}{\\partial p}\\right)_T$$\n因此，体积模量 $B_T$ 可以表示为：\n$$B_T = \\frac{1}{\\kappa_T} = \\rho\\left(\\frac{\\partial p}{\\partial \\rho}\\right)_T$$\n这是体积模量的一个标准且方便的表达式。\n\n问题提供了一个用于 DPD 流体的经验状态方程：\n$$p(\\rho) = \\rho k_{B}T + \\alpha a \\rho^{2}$$\n其中 $k_B$ 是玻尔兹曼常数，$T$ 是温度，$\\alpha$ 是一个无量纲系数，$a$ 是保守力振幅。\n\n现在我们计算在恒定温度下压力对密度的所需偏导数：\n$$\\left(\\frac{\\partial p}{\\partial \\rho}\\right)_T = \\frac{\\partial}{\\partial \\rho}\\left(\\rho k_{B}T + \\alpha a \\rho^{2}\\right) = k_{B}T + 2\\alpha a \\rho$$\n将此导数代入我们的体积模量 $B_T$ 的表达式中：\n$$B_T = \\rho(k_{B}T + 2\\alpha a \\rho) = \\rho k_{B}T + 2\\alpha a \\rho^{2}$$\n任务是找出振幅 $a$ 的表达式。我们重排方程以求解 $a$：\n$$B_T - \\rho k_{B}T = 2\\alpha a \\rho^{2}$$\n$$a = \\frac{B_T - \\rho k_{B}T}{2\\alpha \\rho^{2}}$$\n这 就是在指定密度 $\\rho$ 和温度 $T$ 下，为达到目标体积模量 $B_T$ 所需的保守力振幅 $a$ 的解析表达式。\n\n接下来，我们使用所提供的以 DPD 约化单位表示的参数，对此表达式进行数值计算：\n- $\\alpha = 0.101$\n- $\\rho = 3.000$\n- $k_{B}T = 1.000$\n- 目标 $B_{T} = 48.45$\n\n将这些值代入 $a$ 的表达式中：\n$$a = \\frac{48.45 - (3.000)(1.000)}{2(0.101)(3.000)^{2}}$$\n首先，我们分别计算分子和分母。\n分子：\n$$48.45 - 3.000 = 45.45$$\n分母：\n$$2(0.101)(3.000)^{2} = 2(0.101)(9.000) = (0.202)(9.000) = 1.818$$\n现在，我们计算该比率：\n$$a = \\frac{45.45}{1.818}$$\n$$a = 25.0$$\n问题要求答案四舍五入到四位有效数字。因此，$a$ 的值为 $25.00$。", "answer": "$$\n\\boxed{25.00}\n$$", "id": "3438715"}, {"introduction": "基于结构的粗粒化方法旨在生成能够再现原子级模拟中观察到的特定结构特征（如分布函数）的有效势。本练习 ([@problem_id:3438692]) 将带你从第一性原理出发，推导并实现一种强大的技术——迭代玻尔兹曼反转（IBI）方法，用于参数化键合与二面角势。你将亲手解决周期性边界、平滑处理和规范自由度等实际数值计算中遇到的挑战，从而掌握将结构信息转化为有效相互作用势的核心技能。", "problem": "考虑一个温度为$T$的正则系综中的粗粒化模型，其内坐标为一个键角 $\\theta \\in [0,\\pi]$ 和一个二面角 $\\phi \\in (-\\pi,\\pi]$。任务是从正则分布和平均力势的定义出发，推导并实现一个迭代玻尔兹曼反转（Iterative Boltzmann Inversion, IBI）过程，用于从预设的目标边缘分布 $P_{\\mathrm{target}}(\\theta)$ 和 $P_{\\mathrm{target}}(\\phi)$ 来参数化一维势能 $U_\\theta(\\theta)$ 和 $U_\\phi(\\phi)$。推导必须从以下事实出发：在正则系综中，具有测度因子 $m(\\xi)$ 的坐标 $\\xi$ 的一维边缘概率密度满足 $P(\\xi) \\propto m(\\xi)\\exp(-\\beta U(\\xi))$，其中 $\\beta = 1/(k_{\\mathrm{B}}T)$；而平均力势在相差一个加性常数的情况下定义为：当 $m(\\xi)=1$ 时，$U_{\\mathrm{PMF}}(\\xi) = -k_{\\mathrm{B}}T\\ln P(\\xi) + C$；当 $m(\\xi)\\neq 1$ 时，$U_{\\mathrm{PMF}}(\\xi) = -k_{\\mathrm{B}}T\\ln\\left(P(\\xi)/m(\\xi)\\right) + C$。对于键角，正确的测度因子是 $m(\\theta)=\\sin\\theta$，而对于二面角，测度因子是 $m(\\phi)=1$。仅使用这些基本陈述，推导一个适用于离散直方图的迭代更新规则，该规则通过调整 $U(\\xi)$ 来驱动模型分布趋向于预设的目标 $P_{\\mathrm{target}}(\\xi)$，并解释如何整合以下几点：\n- $\\phi$ 在圆上的周期性（在 $\\pm\\pi$ 处的回绕处理），\n- $\\theta \\in [0,\\pi]$ 的有界域及其非周期性边界，\n- $P_{\\mathrm{target}}(\\xi)$ 中的多峰性，同时不移动峰值位置，以及\n- $U(\\xi)$ 定义中存在的加性常数规范自由度。\n您的实现必须包括受控的更新阻尼以及尊重域拓扑结构的光滑化处理（对 $\\phi$ 使用循环卷积，对 $\\theta$ 使用反射边界光滑化）。\n\n您必须实现一个自包含的程序，对每个测试用例执行以下步骤，角度使用弧度，并使用气体常数 $R$（单位为 $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\mathrm{K}^{-1}$）来表示每摩尔的能量。使用 $R = 8.314462618\\times 10^{-3}\\,\\mathrm{kJ}\\,\\mathrm{mol}^{-1}\\mathrm{K}^{-1}$ 和 $T=300\\,\\mathrm{K}$，因此每摩尔的 $k_{\\mathrm{B}}T$ 为 $RT$。所有能量都必须以 $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$ 为单位。\n\n所有案例的离散化和数值协议：\n- 在 $[0,\\pi]$（含端点）上将 $\\theta$ 离散化为 $N_\\theta=181$ 个等距点。\n- 在 $(-\\pi,\\pi]$ 上将 $\\phi$ 离散化为 $N_\\phi=360$ 个等距点。\n- 初始化 $U_\\theta(\\theta)=0$ 和 $U_\\phi(\\phi)=0$。\n- 在每次迭代中，使用当前势能和正确的测度因子，通过正则形式计算模型分布 $P_{\\mathrm{model}}(\\theta)$ 和 $P_{\\mathrm{model}}(\\phi)$，并将每个分布在离散化下归一化，使其积分为1。\n- 从第一性原理出发，推导并实现一个更新规则，该规则基于 $P_{\\mathrm{model}}(\\xi)$ 和 $P_{\\mathrm{target}}(\\xi)$ 之间的差异来增量调整 $U(\\xi)$，并包含一个标量阻尼因子 $\\alpha$ 以及对更新场的平滑化。平滑化必须通过与一个尊重域拓扑的零均值核进行离散卷积来完成：对 $\\phi$ 使用循环包裹的高斯核，对 $\\theta$ 使用反射边界的高斯核。使用一个离散高斯核，其标准差以直方图的 bin 数为单位指定。\n- 每次更新后，通过减去其在网格上的平均值来移除 $U(\\xi)$ 中的加性常数，使势能的均值为零；这可以固定规范。\n- 迭代预设的次数 $N_{\\mathrm{iter}}$。\n\n为测试套件定义以下目标分布。在下面的所有定义中，都在各自的网格上对目标分布进行数值归一化，使其在离散化下总和为1。\n\n- 角目标分布 $P_{\\mathrm{target}}(\\theta)$ 定义为\n$$\nP_{\\mathrm{target}}(\\theta) \\propto \\sin\\theta \\sum_{i=1}^{M} w_i \\exp\\!\\left(-\\tfrac{1}{2}\\left(\\frac{\\theta-\\mu_i}{\\sigma_i}\\right)^2\\right),\n$$\n其中权重满足 $\\sum_i w_i = 1$，均值 $\\mu_i\\in[0,\\pi]$，宽度 $\\sigma_i>0$；$\\sin\\theta$ 因子考虑了几何测度。\n\n- 二面角目标分布 $P_{\\mathrm{target}}(\\phi)$ 使用三重循环 von Mises-like 形式定义\n$$\nP_{\\mathrm{target}}(\\phi) \\propto \\exp\\!\\left(\\kappa \\cos(3\\phi)\\right),\n$$\n其中集中参数 $\\kappa\\ge 0$；当 $\\kappa=0$ 时，目标在圆上是均匀分布的。\n\n除非明确覆盖，否则对所有情况使用以下数值参数：阻尼因子 $\\alpha=0.25$，迭代次数 $N_{\\mathrm{iter}}=200$，平滑化标准差 $\\sigma_{\\theta,\\mathrm{bins}}=1.25$ bins（对于 $\\theta$）和 $\\sigma_{\\phi,\\mathrm{bins}}=1.50$ bins（对于 $\\phi$）。在计算离散概率的对数时，使用一个小的下限值 $\\varepsilon=10^{-12}$ 以避免未定义值。\n\n测试套件。为以下四个独立案例实现上述IBI过程，并为每个案例返回一个定量的标量结果：\n\n1. 案例 A（角度，单峰，理想路径）：$\\mu_1=2.09439510239$（即 $120^\\circ$ 的弧度值），$\\sigma_1=0.20$，$M=1$，$w_1=1$。计算最终模型分布与目标分布之间的离散均方根偏差，定义为\n$$\nE_A = \\sqrt{\\sum_{j=1}^{N_\\theta} \\left(P_{\\mathrm{model}}(\\theta_j) - P_{\\mathrm{target}}(\\theta_j)\\right)^2}.\n$$\n将 $E_A$ 报告为一个四舍五入到六位小数的十进制数（无量纲）。\n\n2. 案例 B（二面角，三重多峰）：集中参数 $\\kappa=2.5$。计算类似的离散均方根偏差\n$$\nE_B = \\sqrt{\\sum_{j=1}^{N_\\phi} \\left(P_{\\mathrm{model}}(\\phi_j) - P_{\\mathrm{target}}(\\phi_j)\\right)^2}.\n$$\n将 $E_B$ 报告为一个四舍五入到六位小数的十进制数（无量纲）。确保更新和平滑化处理了周期性，以避免在 $\\pm\\pi$ 处出现人为的边缘效应。\n\n3. 案例 C（二面角，均匀分布边缘案例）：$\\kappa=0$。从零势能开始，目标是均匀分布的。完成指定迭代次数后，报告学习到的势能在移除其均值后的标准差，\n$$\nS_C = \\sqrt{\\frac{1}{N_\\phi}\\sum_{j=1}^{N_\\phi}\\left(U_\\phi(\\phi_j) - \\overline{U_\\phi}\\right)^2},\n$$\n报告为一个四舍五入到六位小数的十进制数，单位为 $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$。对均匀目标进行周期性平滑化的正确处理应能保持势能在模一个常数下是平坦的。\n\n4. 案例 D（角度，具有边界敏感性的双峰分布）：一个双峰目标，其中 $M=2$，权重 $(w_1,w_2)=(0.6,0.4)$，均值 $(\\mu_1,\\mu_2)=(0.15,2.99)$，宽度 $(\\sigma_1,\\sigma_2)=(0.08,0.06)$。计算与 $E_A$ 类似定义的角度分布均方根偏差 $E_D$，并将其报告为一个四舍五入到六位小数的十进制数（无量纲）。此案例旨在探测在 $\\theta=0$ 和 $\\theta=\\pi$ 附近的反射边界平滑化效果，且不偏离峰值位置。\n\n最终输出规范：\n- 您的程序必须生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为 $[E_A,E_B,S_C,E_D]$。\n- 整个过程中角度必须使用弧度；能量必须使用 $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$；报告的 $E_A$、$E_B$ 和 $E_D$ 是无量纲的；报告的 $S_C$ 必须以 $\\mathrm{kJ}\\,\\mathrm{mol}^{-1}$ 为单位。所有四个值在最终输出字符串中都必须四舍五入到六位小数。\n- 程序必须是完全自包含的，且不需要任何输入。", "solution": "该问题要求推导并实现迭代玻尔兹曼反转（Iterative Boltzmann Inversion, IBI）方法，以参数化键角 $\\theta$ 和二面角 $\\phi$ 的一维粗粒化势能。推导和实现必须遵循统计力学原理和特定的数值协议。\n\n### 理论基础与推导\n\n该方法的基础在于正则系综的原理。对于一个广义坐标 $\\xi$，其概率分布 $P(\\xi)$ 通过玻尔兹曼分布与势能 $U(\\xi)$ 和一个测度因子（或雅可比行列式）$m(\\xi)$ 相关联：\n$$\nP(\\xi) = \\frac{1}{Z} m(\\xi) \\exp(-\\beta U(\\xi))\n$$\n其中 $\\beta = 1/(k_{\\mathrm{B}}T)$ 是逆温度，$Z = \\int m(\\xi') \\exp(-\\beta U(\\xi'))d\\xi'$ 是配分函数，它作为归一化常数。键角的测度因子是 $m(\\theta) = \\sin\\theta$，这考虑了球坐标系的雅可比行列式，而二面角的测度因子是 $m(\\phi)=1$。\n\n平均力势（Potential of Mean Force, PMF）$U_{\\mathrm{PMF}}(\\xi)$ 被定义为能够精确再现给定概率分布 $P(\\xi)$ 的势能。通过反转玻尔兹曼关系，我们可以找到 PMF，其定义可相差一个任意的加性常数 $C$：\n$$\nU_{\\mathrm{PMF}}(\\xi) = -k_{\\mathrm{B}}T \\ln\\left(\\frac{P(\\xi)}{m(\\xi)}\\right) + C\n$$\nIBI 的目标是迭代地优化势能的初始猜测 $U_0(\\xi)$，直到其对应的模型分布 $P_{\\mathrm{model}}(\\xi)$ 与预设的目标分布 $P_{\\mathrm{target}}(\\xi)$ 相匹配。\n\n设 $U_i(\\xi)$ 为第 $i$ 次迭代时的势能，$P_{\\mathrm{model},i}(\\xi)$ 为它生成的分布。IBI 过程通过增加一个校正项 $\\Delta U_i(\\xi)$ 来更新势能：\n$$\nU_{i+1}(\\xi) = U_i(\\xi) + \\Delta U_i(\\xi)\n$$\n一个自然的选择是将势能推向目标分布的 PMF，即 $U_{\\mathrm{PMF,target}}(\\xi)$。校正量取为目标 PMF 与当前模型分布的 PMF（$U_{\\mathrm{PMF,model},i}(\\xi)$）之差的一部分：\n$$\n\\Delta U_i(\\xi) = \\alpha \\left[ U_{\\mathrm{PMF,target}}(\\xi) - U_{\\mathrm{PMF,model},i}(\\xi) \\right]\n$$\n其中 $\\alpha$ 是一个阻尼因子（$0  \\alpha \\le 1$），用于控制更新步长并确保稳定性。代入 PMF 的定义：\n$$\n\\Delta U_i(\\xi) = \\alpha \\left[ \\left(-k_{\\mathrm{B}}T \\ln\\frac{P_{\\mathrm{target}}(\\xi)}{m(\\xi)}\\right) - \\left(-k_{\\mathrm{B}}T \\ln\\frac{P_{\\mathrm{model},i}(\\xi)}{m(\\xi)}\\right) \\right]\n$$\n$$\n\\Delta U_i(\\xi) = \\alpha k_{\\mathrm{B}}T \\left[ \\ln\\frac{P_{\\mathrm{model},i}(\\xi)}{m(\\xi)} - \\ln\\frac{P_{\\mathrm{target}}(\\xi)}{m(\\xi)} \\right]\n$$\n使用对数性质 $\\ln a - \\ln b = \\ln(a/b)$，上式可简化为：\n$$\n\\Delta U_i(\\xi) = \\alpha k_{\\mathrmB}T \\ln\\left(\\frac{P_{\\mathrm{model},i}(\\xi)}{P_{\\mathrm{target}}(\\xi)}\\right)\n$$\n这是核心的 IBI 更新规则。对于离散形式，对第 $j$ 个 bin 并用摩尔能量 $RT$ 代替 $k_{\\mathrm{B}}T$，对势能 $U_i(\\xi_j)$ 的更新为：\n$$\n\\Delta U_i(\\xi_j) = \\alpha RT \\ln\\left(\\frac{P_{\\mathrm{model},i}(\\xi_j)}{P_{\\mathrm{target}}(\\xi_j)}\\right)\n$$\n\n### 算法实现与特性处理\n\n迭代过程是作为一个在 $\\theta$ 和 $\\phi$ 的离散网格上运行的数值算法来实现的。\n\n1.  **初始化**：创建 $\\theta$ 和 $\\phi$ 的网格，并将势能 $U_\\theta$ 和 $U_\\phi$ 初始化为 0。根据给定的公式计算目标分布 $P_{\\mathrm{target}}(\\theta)$ 和 $P_{\\mathrm{target}}(\\phi)$，并将其归一化，使其离散值之和为 1。\n\n2.  **迭代优化**：算法迭代 $N_{\\mathrm{iter}}$ 步。在每次迭代 $i$ 中：\n    a.  根据当前势能 $U_i(\\xi_j)$，使用 $P_{\\mathrm{model},i}(\\xi_j) \\propto m(\\xi_j) \\exp(-U_i(\\xi_j)/RT)$ 计算当前的模型分布 $P_{\\mathrm{model},i}(\\xi_j)$，并将其归一化使其总和为 1。\n    b.  使用推导出的 IBI 规则计算原始势能更新 $\\Delta U_i(\\xi_j)$。为防止 $\\ln(0)$ 导致的数值错误，应用一个小的下限值 $\\varepsilon$，使得更新从 $\\ln(\\max(P, \\varepsilon))$ 计算得出。\n    c.  原始更新场 $\\Delta U_i$ 通过与一个归一化的、零均值的高斯核进行卷积来实现平滑化。这个关键步骤可以正则化势能，防止噪声放大，并使势能保持平滑。\n    d.  将平滑后的更新 $\\Delta U_{i, \\text{smooth}}$ 加到势能上：$U'(\\xi_j) = U_i(\\xi_j) + \\Delta U_{i, \\text{smooth}}(\\xi_j)$。\n    e.  通过确保势能的均值为零来固定规范自由度：$U_{i+1}(\\xi_j) = U'(\\xi_j) - \\overline{U'}$。\n\n3.  **边界与域特定处理**：\n    -   **$\\phi$ 的周期性**：二面角 $\\phi$ 存在于一个圆上。为了尊重这种拓扑结构，使用**循环卷积**进行平滑化。这可以通过使用快速傅里叶变换（FFTs）的卷积定理来高效实现。高斯核也被“包裹”到圆形域上。这可以防止在 $\\pm\\pi$ 边界处产生人为的不连续性。\n    -   **$\\theta$ 的有界域**：键角 $\\theta$ 定义在一个带有硬壁的有界区间 $[0, \\pi]$ 上。在这些边界附近的平滑化不能引入偏差。这通过对卷积使用**反射边界条件**来实现。信号（势能更新 $\\Delta U_i$）在概念上于卷积前在边界处被镜像，确保平滑后信号的梯度在边界处为零，从而防止特征（如概率峰）被人为地从边界移开。这是通过在执行标准线性卷积之前，用反射值填充 $\\Delta U_i$ 数组来实现的。\n    -   **多峰性**：IBI 更新本质上是局域的。它根据模型概率与目标概率在同一点的比值来调整该点 $\\xi_j$ 的势能。这自然地塑造了势能，使其具有与 $P_{\\mathrm{target}}$ 中多个模式相对应的多个能量阱，而不会人为地移动这些模式的位置。\n    -   **规范自由度**：一个势能 $U(\\xi)$ 的定义只到一个加性常数为止，因为 $U(\\xi)$ 和 $U(\\xi)+C$ 会产生相同的力和相对概率。这个“规范自由度”通过在每次更新后强制执行 $\\overline{U(\\xi)} = 0$ 来固定，从而使势能唯一。\n\n这个综合过程将理论上推导出的 IBI 更新与数值上稳健的平滑化和边界处理相结合，从而可以从目标分布中准确、稳定地参数化势能。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy import fft\n\ndef solve():\n    \"\"\"\n    Main function to derive coarse-grained potentials using Iterative Boltzmann\n    Inversion (IBI) and report the results for the specified test cases.\n    \"\"\"\n\n    # --- Global Constants and Parameters ---\n    R = 8.314462618e-3  # Gas constant in kJ/mol/K\n    T = 300.0          # Temperature in K\n    RT = R * T         # Molar thermal energy in kJ/mol\n    ALPHA = 0.25       # Damping factor\n    N_ITER = 200       # Number of iterations\n    EPS = 1e-12        # Small floor for logarithm arguments\n\n    # --- Discretization ---\n    N_THETA = 181\n    N_PHI = 360\n    theta_grid = np.linspace(0, np.pi, N_THETA)\n    phi_grid = np.linspace(-np.pi + 2 * np.pi / N_PHI, np.pi, N_PHI)\n\n    # --- Smoothing Parameters ---\n    SIGMA_THETA_BINS = 1.25\n    SIGMA_PHI_BINS = 1.50\n\n    def run_ibi(p_target, grid, measure_factor, sigma_bins, boundary_mode):\n        \"\"\"\n        Executes the Iterative Boltzmann Inversion procedure.\n\n        Args:\n            p_target (np.ndarray): The normalized target probability distribution.\n            grid (np.ndarray): The coordinate grid.\n            measure_factor (np.ndarray): The measure factor m(xi) for the coordinate.\n            sigma_bins (float): Standard deviation for Gaussian smoothing, in bin units.\n            boundary_mode (str): 'circular' or 'reflective'.\n\n        Returns:\n            tuple: Final potential (np.ndarray), final model distribution (np.ndarray).\n        \"\"\"\n        n_bins = len(grid)\n        u = np.zeros(n_bins)\n\n        # --- Setup Smoothing Kernel ---\n        if boundary_mode == 'circular':\n            # Create a wrapped Gaussian kernel for circular convolution\n            x = np.arange(n_bins)\n            dx = np.minimum(x, n_bins - x)\n            kernel = np.exp(-dx**2 / (2 * sigma_bins**2))\n            kernel /= np.sum(kernel)\n            kernel_fft = fft.fft(kernel)\n        elif boundary_mode == 'reflective':\n            # Create a standard Gaussian kernel for linear convolution\n            width = int(np.ceil(4 * sigma_bins))\n            x_ker = np.arange(-width, width + 1)\n            kernel = np.exp(-x_ker**2 / (2 * sigma_bins**2))\n            kernel /= np.sum(kernel)\n        else:\n            raise ValueError(\"Unsupported boundary mode.\")\n\n        # --- IBI Iteration Loop ---\n        for _ in range(N_ITER):\n            # 1. Compute model distribution from current potential U\n            p_model_unnormalized = measure_factor * np.exp(-u / RT)\n            p_sum = np.sum(p_model_unnormalized)\n            p_model = p_model_unnormalized / p_sum if p_sum  0 else p_model_unnormalized\n\n            # 2. Compute the potential update\n            log_p_model = np.log(np.maximum(p_model, EPS))\n            log_p_target = np.log(np.maximum(p_target, EPS))\n            du = ALPHA * RT * (log_p_model - log_p_target)\n\n            # 3. Smooth the update field\n            if boundary_mode == 'circular':\n                du_fft = fft.fft(du)\n                du_smooth_fft = du_fft * kernel_fft\n                du_smooth = np.real(fft.ifft(du_smooth_fft))\n            elif boundary_mode == 'reflective':\n                pad_width = int(np.ceil(4 * sigma_bins))\n                left_pad = du[1:pad_width+1][::-1]\n                right_pad = du[-2:-pad_width-2:-1]\n                padded_du = np.concatenate([left_pad, du, right_pad])\n                du_smooth = np.convolve(padded_du, kernel, mode='valid')\n\n            # 4. Apply the smoothed update and fix the gauge\n            u += du_smooth\n            u -= np.mean(u)\n\n        # --- Final Calculation ---\n        p_model_unnormalized_final = measure_factor * np.exp(-u / RT)\n        p_sum_final = np.sum(p_model_unnormalized_final)\n        p_model_final = p_model_unnormalized_final / p_sum_final if p_sum_final  0 else p_model_unnormalized_final\n            \n        return u, p_model_final\n\n    results = []\n\n    # === Case A: Angle, unimodal ===\n    mu_A = 2.09439510239\n    sigma_A = 0.20\n    p_target_un_A = np.sin(theta_grid) * np.exp(-0.5 * ((theta_grid - mu_A) / sigma_A)**2)\n    p_target_A = p_target_un_A / np.sum(p_target_un_A)\n    m_theta = np.sin(theta_grid)\n    _, p_model_A = run_ibi(p_target_A, theta_grid, m_theta, SIGMA_THETA_BINS, 'reflective')\n    e_A = np.linalg.norm(p_model_A - p_target_A)\n    results.append(f\"{e_A:.6f}\")\n\n    # === Case B: Dihedral, threefold ===\n    kappa_B = 2.5\n    p_target_un_B = np.exp(kappa_B * np.cos(3 * phi_grid))\n    p_target_B = p_target_un_B / np.sum(p_target_un_B)\n    m_phi = np.ones_like(phi_grid)\n    _, p_model_B = run_ibi(p_target_B, phi_grid, m_phi, SIGMA_PHI_BINS, 'circular')\n    e_B = np.linalg.norm(p_model_B - p_target_B)\n    results.append(f\"{e_B:.6f}\")\n\n    # === Case C: Dihedral, uniform ===\n    kappa_C = 0.0\n    p_target_un_C = np.exp(kappa_C * np.cos(3 * phi_grid)) # This is an array of ones\n    p_target_C = p_target_un_C / np.sum(p_target_un_C)\n    u_final_C, _ = run_ibi(p_target_C, phi_grid, m_phi, SIGMA_PHI_BINS, 'circular')\n    s_C = np.std(u_final_C)\n    results.append(f\"{s_C:.6f}\")\n\n    # === Case D: Angle, bimodal near boundaries ===\n    w_D = [0.6, 0.4]\n    mu_D = [0.15, 2.99]\n    sigma_D = [0.08, 0.06]\n    g1 = np.exp(-0.5 * ((theta_grid - mu_D[0]) / sigma_D[0])**2)\n    g2 = np.exp(-0.5 * ((theta_grid - mu_D[1]) / sigma_D[1])**2)\n    p_target_un_D = np.sin(theta_grid) * (w_D[0] * g1 + w_D[1] * g2)\n    p_target_D = p_target_un_D / np.sum(p_target_un_D)\n    _, p_model_D = run_ibi(p_target_D, theta_grid, m_theta, SIGMA_THETA_BINS, 'reflective')\n    e_D = np.linalg.norm(p_model_D - p_target_D)\n    results.append(f\"{e_D:.6f}\")\n    \n    # --- Final Output ---\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3438692"}, {"introduction": "力匹配方法将粗粒化参数化过程视为一个回归问题，其目标是最小化粗粒化力与从高精度原子模拟中映射得到的“真实”力之间的差异。本练习 ([@problem_id:3438724]) 将引导你应用此方法，并引入正则化等现代机器学习技术来防止过拟合，构建更加稳健和可移植的力场。通过实践带交叉验证的吉洪诺夫（Tikhonov）正则化，你将学会如何从统计学的角度优化力场参数，这是连接计算材料科学与数据科学的重要实践。", "problem": "给定一个在无量纲简化单位下的粗粒化力匹配任务。在基于原子（AA）模拟的材料粗粒化（CG）建模中，通常将CG力近似为在粗粒化坐标上求值的基函数的线性组合。令 $\\mathbf{R}_{t} \\in \\mathbb{R}^{d}$ 表示离散时间 $t$ 的粗粒化坐标，令 $F^{\\mathrm{AA}\\rightarrow \\mathrm{CG}}_{t} \\in \\mathbb{R}$ 表示沿选定粗粒化坐标的映射原子级别力的标量分量。考虑一组基函数 $\\{\\phi_{k}(\\mathbf{R})\\}_{k=1}^{K}$，并假设CG力参数化为 $F^{\\mathrm{CG}}(\\mathbf{R};\\boldsymbol{\\theta}) = \\sum_{k=1}^{K} \\theta_{k}\\,\\phi_{k}(\\mathbf{R})$，其中 $\\boldsymbol{\\theta}\\in\\mathbb{R}^{K}$ 是待推断的未知系数。\n\n从最小二乘法原理和 Tikhonov 正则化出发，定义并最小化一个平衡数据拟合和参数大小的目标函数。构建设计矩阵，使其行对应样本 $t$，列对应基函数 $k$。推导最小化器的平稳性条件，并实现一个解决方案，对于给定的正则化强度 $\\lambda$ 返回 $\\boldsymbol{\\theta}$。解释并实现使用 K-折交叉验证来选择 $\\lambda$ 以避免过拟合的方法，包括一个明确的平局打破规则。所有计算都应在无量纲简化单位下进行。\n\n您必须实现一个单一程序，该程序：\n- 从提供的基函数和样本坐标构建设计矩阵。\n- 使用 Tikhonov 正则化求解 $\\boldsymbol{\\theta}$，候选 $\\lambda$ 值通过 K-折交叉验证选出，以最小化平均验证均方误差。\n- 如果平均验证误差出现精确相等（在机器精度范围内），则选择最小的 $\\lambda$。\n- 为所有测试用例生成单行输出，如下文所述汇总结果。\n\n使用以下三个测试用例套件，所有用例均在无量纲简化单位下进行（即，无需进行物理单位转换）：\n\n案例A（良态，留一法）：\n- 基函数：$\\phi_{1}(\\mathbf{R})=1$, $\\phi_{2}(\\mathbf{R})=R$, $\\phi_{3}(\\mathbf{R})=R^{2}$。\n- 真实参数：$\\boldsymbol{\\theta}^{\\mathrm{true}}=[0.4,-1.5,0.7]$。\n- 样本：$R_{t}\\in\\mathbb{R}$，其值为 $[-1.0,-0.5,0.0,0.5,1.0]$。\n- 确定性残差：$\\delta(R)=0.01\\sin(\\pi R)$。\n- 目标值：$F^{\\mathrm{AA}\\rightarrow \\mathrm{CG}}_{t}=\\sum_{k}\\theta^{\\mathrm{true}}_{k}\\,\\phi_{k}(R_{t})+\\delta(R_{t})$。\n- 候选正则化参数：$\\lambda\\in[0.0,10^{-6},10^{-3},10^{-2},10^{-1}]$。\n- 折数：$K=5$。\n\n案例B（近似共线基，中等 K 值）：\n- 基函数：$\\phi_{1}(\\mathbf{R})=1$, $\\phi_{2}(\\mathbf{R})=R$, $\\phi_{3}(\\mathbf{R})=R+10^{-8}$。\n- 真实参数：$\\boldsymbol{\\theta}^{\\mathrm{true}}=[1.0,0.5,-0.5]$。\n- 样本：$R_{t}\\in\\mathbb{R}$，其值为 $[-1.0,-0.75,-0.5,-0.25,0.0,0.25,0.5,0.75,1.0]$。\n- 确定性残差：$\\delta(R)=0.02\\sin(\\pi R)$。\n- 目标值：$F^{\\mathrm{AA}\\rightarrow \\mathrm{CG}}_{t}=\\sum_{k}\\theta^{\\mathrm{true}}_{k}\\,\\phi_{k}(R_{t})+\\delta(R_{t})$。\n- 候选正则化参数：$\\lambda\\in[10^{-6},10^{-4},10^{-2},10^{-1},1.0]$。\n- 折数：$K=3$。\n\n案例C（欠定系统，强正则化）：\n- 基函数：$\\phi_{1}(\\mathbf{R})=1$, $\\phi_{2}(\\mathbf{R})=R$, $\\phi_{3}(\\mathbf{R})=R^{2}$。\n- 真实参数：$\\boldsymbol{\\theta}^{\\mathrm{true}}=[-0.2,0.5,0.3]$。\n- 样本：$R_{t}\\in\\mathbb{R}$，其值为 $[-0.2,0.8]$。\n- 确定性残差：$\\delta(R)=0.05\\sin(\\pi R)$。\n- 目标值：$F^{\\mathrm{AA}\\rightarrow \\mathrm{CG}}_{t}=\\sum_{k}\\theta^{\\mathrm{true}}_{k}\\,\\phi_{k}(R_{t})+\\delta(R_{t})$。\n- 候选正则化参数：$\\lambda\\in[10^{-3},10^{-2},10^{-1},1.0]$。\n- 折数：$K=2$。\n\n算法要求：\n- 对每个案例，执行 K-折交叉验证以从候选 $\\lambda$ 中选出最小化平均验证均方误差的那个。\n- 使用选定的 $\\lambda$ 在完整数据集上拟合 $\\boldsymbol{\\theta}$。\n- 如果给定 $\\lambda$ 的线性系统是病态或奇异的，则使用数值稳定的求解器（如伪逆）来获得 $\\boldsymbol{\\theta}$。\n\n输出规格：\n- 对每个案例，输出一个列表，其中包含选定的 $\\lambda$（浮点数）、平均验证均方误差（浮点数），以及按顺序排列的拟合 $\\boldsymbol{\\theta}$ 的各项。\n- 您的程序应生成单行输出，其中包含三个测试用例的结果，格式为一个以逗号分隔的列表，并用方括号括起。每个元素是上述的单个案例列表，例如 $[[\\lambda_{A},\\mathrm{MSE}_{A},\\theta^{A}_{1},\\theta^{A}_{2},\\theta^{A}_{3}],[\\lambda_{B},\\mathrm{MSE}_{B},\\theta^{B}_{1},\\theta^{B}_{2},\\theta^{B}_{3}],[\\lambda_{C},\\mathrm{MSE}_{C},\\theta^{C}_{1},\\theta^{C}_{2},\\theta^{C}_{3}]]$。\n\n角度单位：残差定义中的所有角度均使用弧度。任何地方都不使用百分比；任何比率都应以十进制数返回。所有量均为无量纲简化单位。\n\n确保科学真实性并从第一性原理出发实现：从最小二乘法和正则化开始，显式构建设计矩阵，推导最小化器的一阶最优性条件，并实现 K-折交叉验证以根据验证误差选择 $\\lambda$。问题陈述本身不提供超出这些原理的公式。", "solution": "问题是通过拟合映射的原子（AA）力数据来确定最优的粗粒化（CG）力参数 $\\boldsymbol{\\theta}$。CG力 $F^{\\mathrm{CG}}$ 被建模为在 CG 坐标 $\\mathbf{R}$ 上求值的 $K$ 个基函数 $\\phi_k(\\mathbf{R})$ 的线性组合。\n\n模型由下式给出：\n$$F^{\\mathrm{CG}}(\\mathbf{R};\\boldsymbol{\\theta}) = \\sum_{k=1}^{K} \\theta_{k}\\,\\phi_{k}(\\mathbf{R})$$\n其中 $\\boldsymbol{\\theta} = [\\theta_1, \\theta_2, \\dots, \\theta_K]^T$ 是未知系数的向量。\n\n给定一组包含 $N$ 个离散时间样本的数据集，在每个时间 $t$，我们有 CG 坐标 $\\mathbf{R}_t$ 和目标映射力 $y_t = F^{\\mathrm{AA}\\rightarrow \\mathrm{CG}}_{t}$，我们可以用矩阵形式表示该问题。令 $\\mathbf{y} \\in \\mathbb{R}^{N}$ 为目标力向量，令 $\\mathbf{\\Phi}$ 为 $N \\times K$ 的设计矩阵，其中每个元素 $\\Phi_{tk} = \\phi_k(\\mathbf{R}_t)$。所有样本的预测力向量则为 $\\hat{\\mathbf{y}} = \\mathbf{\\Phi}\\boldsymbol{\\theta}$。\n\n最小二乘法原理旨在通过最小化残差平方和来找到 $\\boldsymbol{\\theta}$，即目标力与预测力之差的欧几里得范数的平方：\n$$J_{\\text{LS}}(\\boldsymbol{\\theta}) = \\sum_{t=1}^{N} (y_t - \\hat{y}_t)^2 = ||\\mathbf{y} - \\mathbf{\\Phi}\\boldsymbol{\\theta}||_2^2$$\n\n为了防止过拟合，并处理设计矩阵导致病态或奇异系统的情况（例如，近似共线的基函数或 $N  K$ 的欠定系统），我们引入 Tikhonov 正则化。这会在目标函数中增加一个惩罚项，该惩罚项与参数向量的平方大小成正比，由正则化强度参数 $\\lambda \\ge 0$ 控制。新的目标函数是：\n$$J(\\boldsymbol{\\theta}) = ||\\mathbf{y} - \\mathbf{\\Phi}\\boldsymbol{\\theta}||_2^2 + \\lambda ||\\boldsymbol{\\theta}||_2^2$$\n这也被称为岭回归。\n\n为了找到最小化 $J(\\boldsymbol{\\theta})$ 的最优参数向量 $\\hat{\\boldsymbol{\\theta}}$，我们通过计算 $J(\\boldsymbol{\\theta})$ 关于 $\\boldsymbol{\\theta}$ 的梯度并将其设为零来找到平稳性条件。\n展开目标函数：\n$$J(\\boldsymbol{\\theta}) = (\\mathbf{y} - \\mathbf{\\Phi}\\boldsymbol{\\theta})^T(\\mathbf{y} - \\mathbf{\\Phi}\\boldsymbol{\\theta}) + \\lambda \\boldsymbol{\\theta}^T\\mathbf{I}\\boldsymbol{\\theta} = \\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\theta}^T\\mathbf{\\Phi}^T\\mathbf{y} + \\boldsymbol{\\theta}^T\\mathbf{\\Phi}^T\\mathbf{\\Phi}\\boldsymbol{\\theta} + \\lambda \\boldsymbol{\\theta}^T\\mathbf{I}\\boldsymbol{\\theta}$$\n$$J(\\boldsymbol{\\theta}) = \\mathbf{y}^T\\mathbf{y} - 2\\boldsymbol{\\theta}^T\\mathbf{\\Phi}^T\\mathbf{y} + \\boldsymbol{\\theta}^T(\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I})\\boldsymbol{\\theta}$$\n关于 $\\boldsymbol{\\theta}$ 的梯度是：\n$$\\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta}) = -2\\mathbf{\\Phi}^T\\mathbf{y} + 2(\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I})\\boldsymbol{\\theta}$$\n将梯度设为零，$\\nabla_{\\boldsymbol{\\theta}} J(\\boldsymbol{\\theta}) = \\mathbf{0}$，得到正则化系统的正规方程：\n$$(\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I})\\boldsymbol{\\theta} = \\mathbf{\\Phi}^T\\mathbf{y}$$\n$\\boldsymbol{\\theta}$ 的解为：\n$$\\hat{\\boldsymbol{\\theta}} = (\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I})^{-1} \\mathbf{\\Phi}^T\\mathbf{y}$$\n对于 $\\lambda > 0$，矩阵 $(\\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I})$ 保证是可逆的，即使对于不适定问题也能提供唯一解。问题陈述要求使用数值稳定的求解器，这对于病态矩阵至关重要。我们将求解线性系统 $A\\boldsymbol{x}=\\boldsymbol{b}$，其中 $A = \\mathbf{\\Phi}^T\\mathbf{\\Phi} + \\lambda\\mathbf{I}$ 且 $\\boldsymbol{b} = \\mathbf{\\Phi}^T\\mathbf{y}$。\n\n$\\lambda$ 的选择至关重要：如果 $\\lambda$ 太小，模型可能会过拟合；如果太大，则可能会欠拟合。我们采用 K-折交叉验证从候选列表中选择一个最优的 $\\lambda$。步骤如下：\n$1.$ 将包含 $N$ 个样本的数据集划分为 $K$ 个大小近似相等的不相交子集（折）。\n$2.$ 对每个候选值 $\\lambda$：\n    a. 将平均验证误差初始化为零。\n    b. 对每一折 $k \\in \\{1, \\dots, K\\}$：\n        i. 将第 $k$ 折指定为验证集。其余 $K-1$ 折组合成训练集。\n        ii. 使用训练数据和当前的 $\\lambda$ 拟合模型参数 $\\boldsymbol{\\theta}_{\\text{train}}$。\n        iii. 使用拟合的模型为验证集中的每个样本预测力。\n        iv. 计算验证集上的均方误差 (MSE)：$\\text{MSE}_k(\\lambda) = \\frac{1}{N_k} ||\\mathbf{y}_{\\text{val}} - \\mathbf{\\Phi}_{\\text{val}}\\boldsymbol{\\theta}_{\\text{train}}||_2^2$，其中 $N_k$ 是第 $k$ 折中的样本数。\n    c. 计算 $\\lambda$ 的平均验证误差 $\\overline{\\text{MSE}}(\\lambda) = \\frac{1}{K} \\sum_{k=1}^{K} \\text{MSE}_k(\\lambda)$。\n$3.$ 选择使 $\\overline{\\text{MSE}}(\\lambda)$ 最小化的最优正则化强度 $\\lambda^*$。问题指定了平局打破规则：如果多个 $\\lambda$ 值产生相同的最小 $\\overline{\\text{MSE}}$（在机器精度范围内），则选择最小的 $\\lambda$。\n$4.$ 最后，使用选定的 $\\lambda^*$ 在整个数据集上进行训练，得到最终的模型参数 $\\boldsymbol{\\theta}_{\\text{final}}$。\n\n对三个测试用例中的每一个都实施了这一完整过程。该实现为每个案例构建设计矩阵 $\\mathbf{\\Phi}$ 和目标向量 $\\mathbf{y}$，执行 K-折交叉验证以找到 $\\lambda^*$，然后计算最终的 $\\boldsymbol{\\theta}_{\\text{final}}$。结果，包括 $\\lambda^*$、相应的最小平均验证 MSE 以及 $\\boldsymbol{\\theta}_{\\text{final}}$ 的分量，将按照输出规格进行汇总和格式化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the coarse-grained force-matching problem for three test cases,\n    using Tikhonov regularization with lambda selected by K-fold cross-validation.\n    \"\"\"\n\n    # Case A: Well-conditioned, leave-one-out\n    R_A = np.array([-1.0, -0.5, 0.0, 0.5, 1.0])\n    theta_true_A = np.array([0.4, -1.5, 0.7])\n    basis_A = [lambda R: 1.0, lambda R: R, lambda R: R**2]\n    delta_A = lambda R: 0.01 * np.sin(np.pi * R)\n    phi_matrix_A = np.array([[func(r) for func in basis_A] for r in R_A])\n    y_A = phi_matrix_A @ theta_true_A + delta_A(R_A)\n    lambdas_A = [0.0, 1e-6, 1e-3, 1e-2, 1e-1]\n    K_A = 5\n\n    # Case B: Nearly collinear basis, moderate K\n    R_B = np.linspace(-1.0, 1.0, 9)\n    theta_true_B = np.array([1.0, 0.5, -0.5])\n    basis_B = [lambda R: 1.0, lambda R: R, lambda R: R + 1e-8]\n    delta_B = lambda R: 0.02 * np.sin(np.pi * R)\n    phi_matrix_B = np.array([[func(r) for func in basis_B] for r in R_B])\n    y_B = phi_matrix_B @ theta_true_B + delta_B(R_B)\n    lambdas_B = [1e-6, 1e-4, 1e-2, 1e-1, 1.0]\n    K_B = 3\n\n    # Case C: Underdetermined system, strict regularization\n    R_C = np.array([-0.2, 0.8])\n    theta_true_C = np.array([-0.2, 0.5, 0.3])\n    basis_C = [lambda R: 1.0, lambda R: R, lambda R: R**2]\n    delta_C = lambda R: 0.05 * np.sin(np.pi * R)\n    phi_matrix_C = np.array([[func(r) for func in basis_C] for r in R_C])\n    y_C = phi_matrix_C @ theta_true_C + delta_C(R_C)\n    lambdas_C = [1e-3, 1e-2, 1e-1, 1.0]\n    K_C = 2\n\n    test_cases = [\n        (phi_matrix_A, y_A, lambdas_A, K_A),\n        (phi_matrix_B, y_B, lambdas_B, K_B),\n        (phi_matrix_C, y_C, lambdas_C, K_C),\n    ]\n\n    results = []\n    \n    for Phi, y_targets, lambdas, K_folds in test_cases:\n        num_samples, num_basis = Phi.shape\n        indices = np.arange(num_samples)\n        \n        # We need to handle numpy's deprecation warning for ragged arrays\n        # by creating a list of arrays instead of a single object-dtype array\n        if num_samples % K_folds == 0:\n            fold_indices = np.split(indices, K_folds)\n        else:\n            # np.array_split is more general\n            fold_indices = np.array_split(indices, K_folds)\n\n        avg_mses = []\n\n        for lam in lambdas:\n            fold_mses = []\n            for i in range(K_folds):\n                val_idx = fold_indices[i]\n                train_idx = np.concatenate([fold_indices[j] for j in range(K_folds) if i != j])\n                \n                Phi_train, y_train = Phi[train_idx], y_targets[train_idx]\n                Phi_val, y_val = Phi[val_idx], y_targets[val_idx]\n                \n                A = Phi_train.T @ Phi_train + lam * np.identity(num_basis)\n                b = Phi_train.T @ y_train\n                \n                try:\n                    theta_train = np.linalg.solve(A, b)\n                except np.linalg.LinAlgError:\n                    # Fallback to pseudoinverse for singular matrix (e.g., lambda=0)\n                    theta_train = np.linalg.pinv(A) @ b\n\n                y_pred_val = Phi_val @ theta_train\n                mse = np.mean((y_val - y_pred_val)**2)\n                fold_mses.append(mse)\n            \n            avg_mses.append(np.mean(fold_mses))\n\n        # Select best lambda with tie-breaking\n        min_mse = np.min(avg_mses)\n        best_lambda_candidates = [lam for lam, mse in zip(lambdas, avg_mses) if np.isclose(mse, min_mse)]\n        best_lambda = min(best_lambda_candidates)\n        \n        # Retrieve the MSE for the selected lambda\n        best_avg_mse = avg_mses[lambdas.index(best_lambda)]\n\n        # Final fit on all data with the best lambda\n        A_final = Phi.T @ Phi + best_lambda * np.identity(num_basis)\n        b_final = Phi.T @ y_targets\n        try:\n            theta_final = np.linalg.solve(A_final, b_final)\n        except np.linalg.LinAlgError:\n            theta_final = np.linalg.pinv(A_final) @ b_final\n\n        case_result = [best_lambda, best_avg_mse] + theta_final.tolist()\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3438724"}]}