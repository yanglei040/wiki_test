## 应用与[交叉](@entry_id:147634)学科联系

在前面的章节中，我们已经探讨了[高通量材料筛选](@entry_id:750322)和自动化工作流的核心原理与机制。这些原理为我们理解如何系统性地、大规模地计算和预测[材料性质](@entry_id:146723)奠定了理论基础。然而，理论的真正价值在于其应用。本章旨在揭示这些核心原理如何在多样化的真实世界和交叉学科背景下被运用、扩展和整合，从而解决[材料科学](@entry_id:152226)及相关领域中的实际挑战。我们的目标不是重复讲授基本概念，而是通过一系列应用实例，展示这些概念如何成为连接物理学、化学、计算机科学、统计学和工程学等多个学科的桥梁，共同推动新[材料发现](@entry_id:159066)的边界。

### 高通量性质计算的基础效率与准确性

[高通量筛选](@entry_id:271166)的核心在于“通量”——即在给定时间内完成大量计算的能力。然而，仅仅追求速度而牺牲准确性是毫无意义的。因此，任何成功的高通量工作流都必须在计算效率和物理真实性之间取得精妙的平衡。这一部分将探讨两个关键方面：如何通过利用对称性来避免冗余计算，以及如何将复杂的物理现象集成到自动化计算流程中以确保结果的准确性。

#### 对称性与结构唯一性

在[高通量筛选](@entry_id:271166)中，我们常常需要探索给定[化学成分](@entry_id:138867)可能形成的所有[晶体结构](@entry_id:140373)。一个常见的陷阱是，由于对[晶体对称性](@entry_id:198772)的处理不当，导致对同一个[晶体结构](@entry_id:140373)进行多次重复的、计算成本高昂的第一性原理计算。例如，对于一个给定的[晶格和](@entry_id:189839)[化学式](@entry_id:136318)，不同的原子排布方式可能在物理上是等价的，因为它们可以通过旋转、反射或平移等[对称操作](@entry_id:143398)相互转换。为了构建一个高效的工作流，首要任务就是识别并只计算那些对称不等价的、唯一的结构。对于简单的体系，这可以通过直觉得出，但对于复杂的结构，如[尖晶石](@entry_id:183750)，则需要更严谨的数学工具。群论，特别是[Burnside引理](@entry_id:146768)和[轨道-稳定集定理](@entry_id:145230)，为这个问题提供了系统性的解决方案。通过将[晶格](@entry_id:196752)上的原子位置视为一个集合，将晶体的[点群](@entry_id:142456)对称操作视为作用于该集合上的置换群，我们可以精确地计算出在给定原子占据数下，存在多少个非同构的（即对称不等价的）原子构型。例如，在分析[尖晶石结构](@entry_id:154362)（如 $\mathrm{A}_{2}\mathrm{B}\mathrm{O}_{4}$）的阳离子排布时，必须考虑四面体和八面体位置上的不同对称性，并利用群论方法来枚举所有唯一的排布方式。这不仅极大地节约了计算资源，也是确保[材料数据库](@entry_id:182414)完整性与无冗余性的根本保证。[@problem_id:3456762]

#### 高级物理现象的自动化建模

一个可靠的自动化工作流不仅要快，更要准。这意味着它必须能够准确地模拟决定材料关键性质的复杂物理效应。一个典型的例子是极性绝缘体中的[晶格动力学](@entry_id:145448)。在这些材料中，长程的偶极-偶极相互作用会导致在[布里渊区](@entry_id:142395)中心（$\Gamma$点）附近，纵向光学（LO）[声子](@entry_id:140728)和横向光学（TO）[声子](@entry_id:140728)之间出现频率劈裂，即[LO-TO劈裂](@entry_id:138758)。这种效应对于理解材料的介电性质、红外[光谱](@entry_id:185632)和[电子-声子耦合](@entry_id:139197)至关重要。一个简单地计算[短程相互作用](@entry_id:145678)的自动化[声子谱](@entry_id:753408)工作流会完全忽略这一现象，从而产生物理上不正确的预测。为了解决这个问题，高级工作流必须引入对动力学矩阵的非解析修正项。该修正项源于[声子](@entry_id:140728)位移引起的[宏观电场](@entry_id:196409)，其数学形式可以从第一性原理推导得出，并依赖于材料的[玻恩有效电荷](@entry_id:144855)张量（$\mathbf{Z}^*$）和高频[介电张量](@entry_id:194185)（$\boldsymbol{\epsilon}_{\infty}$）。具体而言，当[声子](@entry_id:140728)[波矢](@entry_id:178620) $\mathbf{q}$ 趋近于零时，非解析修正项 $D_{\kappa \alpha, \kappa' \beta}^{\mathrm{NA}}(\mathbf{q})$ 的形式为：
$$
D_{\kappa \alpha, \kappa' \beta}^{\mathrm{NA}}(\mathbf{q}) = \frac{4 \pi}{\Omega \sqrt{M_{\kappa} M_{\kappa'}}} \frac{\left( \sum_{\gamma} q_{\gamma} Z_{\kappa,\alpha \gamma}^{*} \right) \left( \sum_{\delta} q_{\delta} Z_{\kappa',\beta \delta}^{*} \right)}{\sum_{\gamma \delta} q_{\gamma} \epsilon_{\infty,\gamma \delta} q_{\delta}}
$$
其中 $\Omega$ 是[晶胞体积](@entry_id:173348)，$M_{\kappa}$ 是原子质量。这个表达式明确显示了[LO-TO劈裂](@entry_id:138758)的方向依赖性，即[声子频率](@entry_id:753407)取决于 $\mathbf{q}$ 趋近于 $\Gamma$ 点的方向。一个完全自动化的工作流必须能够：（1）通过[密度泛函微扰理论](@entry_id:196807)（DFPT）等方法首先计算出 $\mathbf{Z}^*$ 和 $\boldsymbol{\epsilon}_{\infty}$；（2）通过检查材料的[带隙](@entry_id:191975)和 $\mathbf{Z}^*$ 的大小来判断是否需要应用此修正；（3）在对角化动力学矩阵之前，将此非解析项添加到[短程力](@entry_id:142823)常数矩阵中；（4）最后，通过施加[声学求和规则](@entry_id:746229)（Acoustic Sum Rule）来确保[声学支](@entry_id:138762)在 $\Gamma$ 点的频率为零。这一过程完美地展示了如何将深刻的物理理论与严谨的计算流程相结合，以实现高通量、高保真度的[材料性质预测](@entry_id:751725)。[@problem_id:3456723]

### 用于加速发现的代理建模与[主动学习](@entry_id:157812)

尽管[计算效率](@entry_id:270255)不断提升，但对广阔的材料空间进行穷举式的[第一性原理计算](@entry_id:198754)仍然是不现实的。一个更智能的策略是利用机器学习构建“代理模型”（Surrogate Models）。这些模型能够从少量昂贵的、高保真度的计算数据中学习，并快速预测新材料的性质。在此基础上，主动学习（Active Learning）框架可以利用模型的不确定性来智能地选择下一个最值得计算的材料，从而以最少的计算成本最快地发现目标材料。

#### 构建预测性代理模型

代理模型的核心思想是用一个计算成本低廉的数学函数来近似描述材料性质与结构或成分之间的复杂关系。[团簇展开](@entry_id:154285)（Cluster Expansion）是凝聚态物理中一个历史悠久且极为成功的代理模型，尤其适用于预测合金的能量和相图。其基本思想是将合金的总[能量表示](@entry_id:202173)为由不同大小和形状的原子团簇（如单点、对、三体等）构成的[基函数](@entry_id:170178)的[线性组合](@entry_id:154743)。这些[基函数](@entry_id:170178)通常是占据变量（例如，用 $\sigma_i = +1$ 代表A原子，$\sigma_i = -1$ 代表B原子）的乘积。模型的参数，即[有效团簇相互作用](@entry_id:748808)（ECI），可以通[过拟合](@entry_id:139093)一系列已知构型的小规模第一性原理（如DFT）计算能量来确定。例如，对于一个简单的构型，其能量可以表示为 $E(\boldsymbol{\sigma}) = \sum_{\alpha} J_{\alpha} \phi_{\alpha}(\boldsymbol{\sigma})$，其中 $\phi_{\alpha}$ 是与团簇 $\alpha$ 相关的[基函数](@entry_id:170178)，$J_{\alpha}$ 是待拟合的ECI。这个拟合过程本质上是一个线性回归问题。给定一组 $N$ 个构型的DFT能量 $\mathbf{y}$，以及由这些构型的[基函数](@entry_id:170178)值构成的[设计矩阵](@entry_id:165826) $\mathbf{X}$，ECI向量 $\mathbf{J}$ 可以通过[最小二乘法](@entry_id:137100)估计得出：$\hat{\mathbf{J}} = (\mathbf{X}^\top \mathbf{X})^{-1} \mathbf{X}^\top \mathbf{y}$。为了[防止过拟合](@entry_id:635166)，通常会引入[岭回归](@entry_id:140984)（Ridge Regression）等[正则化技术](@entry_id:261393)，并通过留一交叉验证（[LOOCV](@entry_id:637718)）等方法来选择最优的正则化强度。一旦ECI被确定，这个[团簇展开](@entry_id:154285)模型就可以在几毫秒内预测任意新构型的能量，而无需进行昂贵的DFT计算，从而能够高效地探索合金在不同成分和温度下的[热力学稳定性](@entry_id:142877)。[@problem_id:3456768]

#### 基于[最优实验设计](@entry_id:165340)的[数据采集](@entry_id:273490)

在构建代理模型的过程中，一个关键问题是：我们应该选择哪些构型进行昂贵的DFT计算，以便最有效地约束模型参数？随机选择或基于直觉的选择往往是次优的。[最优实验设计](@entry_id:165340)（Optimal Experimental Design, OED）为这个问题提供了统计学上严谨的答案。其目标是选择一个数据点集合，使得从这些点获得的模型参数具有最小的不确定性。一个广泛使用的标准是D-优化（D-optimality），它旨在最小化模型参数[协方差矩阵](@entry_id:139155) $\boldsymbol{\Sigma}_{\theta}$ 的[行列式](@entry_id:142978)，这等价于最大化Fisher[信息矩阵](@entry_id:750640) $\mathbf{A} = \boldsymbol{\Sigma}_{\theta}^{-1}$ 的[行列式](@entry_id:142978)。在一个多保真度的场景中，我们可以选择对一个构型进行高成本、高精度的DFT计算，或者低成本、低精度的[机器学习力场](@entry_id:192895)计算。每种选择都会以不同的方式和成本对Fisher[信息矩阵](@entry_id:750640)做出贡献。由于寻找全局最优设计在计算上是不可行的，通常采用[贪心算法](@entry_id:260925)：在每一步，选择那个能够以最高“性价比”（即最大的[信息增益](@entry_id:262008)/成本比）更新信息矩阵的测量。利用[矩阵行列式引理](@entry_id:186722)，我们可以高效地计算每次候选测量的边际[信息增益](@entry_id:262008)，从而在有限的计算预算内，逐步构建出一个信息最丰富的[训练集](@entry_id:636396)。这种方法确保了每一个宝贵的计算资源都被用于最大程度地减小最终模型的[参数不确定性](@entry_id:264387)。[@problem_id:3456725]

#### 序贯学习与智能决策

[主动学习](@entry_id:157812)将代理模型和[数据采集](@entry_id:273490)策略结合成一个闭环的“[序贯决策](@entry_id:145234)”过程，其中最著名的框架之一是[贝叶斯优化](@entry_id:175791)（Bayesian Optimization）。它特别适用于优化那些评估成本高昂且没有梯度信息的“黑箱”函数，这正是[材料发现](@entry_id:159066)的典型场景。[贝叶斯优化](@entry_id:175791)使用一个概率性代理模型（通常是高斯过程），该模型不仅提供对[材料性质](@entry_id:146723)的预测值，还提供预测的不确定性。决策的核心在于“[采集函数](@entry_id:168889)”（Acquisition Function），它利用模型的均值和[方差](@entry_id:200758)来评估每个候[选材](@entry_id:161179)料的“价值”，并指导下一步应该在哪里进行昂贵的计算。

常见的[采集函数](@entry_id:168889)各有侧重。例如，[期望提升](@entry_id:749168)（Expected Improvement, EI）关注于超越当前最优值的期望大小；[置信上界](@entry_id:178122)（Upper Confidence Bound, UCB）则乐观地选择那些预测值高或不确定性大的点；汤普森采样（Thompson Sampling, TS）通过从模型后验分布中抽取一个函数样本并优化该样本来进行决策。在面对性质随成分剧烈变化的“崎岖”[目标函数](@entry_id:267263)以及测量噪声不均匀（异[方差](@entry_id:200758)）的真实情况下，UCB和TS通常比标准EI表现得更稳健，因为它们不依赖于单一的、可能被[噪声污染](@entry_id:188797)的当前最优值，而是更全面地利用了全局的后验不确定性。[@problem_id:3456763]

在现代计算和实验平台上，我们通常可以[并行处理](@entry_id:753134)多个任务。因此，将[序贯决策](@entry_id:145234)扩展到“批处理”（Batch）模式至关重要。一个简单的批处理策略可能会选择多个具有高[采集函数](@entry_id:168889)值的点，但这往往导致这些点在材料空间中聚集在一起，造成信息冗余。局部惩罚（Local Penalization）等高级策略通过在选择批处理中的每个后续点时，动态地惩罚那些靠近已选点的区域，从而鼓励批处理内部的多样性。这确保了[并行计算](@entry_id:139241)资源被用于探索材料空间的不同区域，在优化速度（通量）和最终发现材料的质量之间取得了有效平衡。[@problem_id:3456784]

### 构建稳健且可扩展的计算系统

高通量[材料科学](@entry_id:152226)的宏伟蓝图不仅仅建立在巧妙的物理模型和学习算法之上，它同样依赖于坚实的计算机科学与系统工程基础。当计算任务从几百个扩展到数百万个时，资源管理、工作流自动化、容错和[数据管理](@entry_id:635035)的挑战变得至关重要。

#### 资源管理与[任务调度](@entry_id:268244)

[高通量筛选](@entry_id:271166)通常涉及在异构的[高性能计算](@entry_id:169980)（HPC）集群上运行数以万计的独立作业。这些作业可能具有不同的计算需求（如CPU时间、内存），而集群中的机器也可能具有不同的性能（如处理器速度、内存容量）。如何将作业有效地分配给机器，以最小化整个计算 campaign 的完成时间（即“makespan”），是一个经典的调度[优化问题](@entry_id:266749)。这个问题可以被形式化地表述为一个[混合整数线性规划](@entry_id:636618)（MILP）问题，其目标是最小化 makespan，约束条件包括每个作业必须被分配一次、任何机器的总负载不能超过makespan、以及作业的内存需求必须小于其所在机器的内存容量。虽然求解MILP可以得到理论上的最优解，但对于大规模问题来说计算成本极高。因此，在实践中，通常采用高效的[启发式算法](@entry_id:176797)，如“最长[处理时间](@entry_id:196496)优先”（Longest Processing Time, LPT）的变体，即优先调度计算需求最大的作业，并将其分配给能使其最快完成的可用机器。[@problem_id:3456755]

除了静态的作业分配，[动态调度](@entry_id:748751)策略在管理持续到达的任务流时也至关重要。例如，一个工作流可能混合了快速的筛选计算和耗时长的精确计算。为了在最大化系统吞吐量的同时，保证不同类型的任务都能获得公平的计算资源份额，可以设计基于“指数”的[抢占式调度](@entry_id:753698)策略。利用李雅普诺夫优化等先进的[排队论](@entry_id:274141)技术，可以为每个待处理的任务 $j$ 推导出一个优先级指数 $I_j(t)$，例如 $I_j(t) = Q_{c(j)}(t) + V/\hat{r}_j(t)$。该指数巧妙地平衡了两个方面：$Q_{c(j)}(t)$ 项代表任务所属类别 $c(j)$ 的“服务赤字”，优先处理被“饿死”的类别以保证公平性；而 $V/\hat{r}_j(t)$ 项则优先处理剩余计算时间 $\hat{r}_j(t)$ 最短的任务以提高[吞吐量](@entry_id:271802)。参数 $V$ 则用于调节公平性与吞吐量之间的权衡。在每个决策时刻，调度器只需选择指数最高的任务执行即可。[@problem_id:3456721]

#### 工作流自动化与容错机制

高通量工作流的“自动化”意味着它必须能够在无人干预的情况下长时间可靠运行。然而，[第一性原理计算](@entry_id:198754)（如DFT）本质上是复杂的迭代过程，常常会因为各种原因（如[自洽场](@entry_id:136549)（SCF）不收敛、离子步优化停滞）而失败。一个强大的工作流引擎必须具备自动错误恢复的能力。这可以通过一个基于决策理论的系统来实现：首先，对失败的作业进行分类，诊断其失败的根本原因（例如，通过解析输出文件）；然后，根据诊断结果，应用一个预定义的纠正措施（例如，减小电子混合参数、增加斯米尔温度、扰动离子位置等）。我们可以为每个（真实故障类别，纠正措施）对定义一个成功概率，并结合故障分类器的[混淆矩阵](@entry_id:635058)，构建一个[概率模型](@entry_id:265150)。通过这个模型，可以计算出针对每种“预测”的故障类别，哪种纠正措施能带来最高的期望成功率，从而形成一个最优的错误恢复策略。[@problem_id:3456765]

除了计算本身的失败，底层的计算基础设施（如作业调度器、网络[文件系统](@entry_id:749324)）也可能出现瞬时故障，导致任务执行中断或重复。为了保证数据的一致性和完整性，工作流中的每个任务都应被设计成“幂等”的。[幂等性](@entry_id:190768)是指一个操作无论执行一次还是多次，其对系统状态的最终影响都是相同的。例如，一个计算任务在完成后需要将结果写入数据库。如果该任务由于调度器故障而被重复执行，一个非幂等的设计（如简单地向结果表中追加记录）会导致数据重复。而一个幂等的实现，例如使用基于输入参数哈希值的唯一键进行“upsert”（如果记录不存在则插入，否则不做任何事）操作，可以确保即使任务被重复调用，数据库中也只会有一条正确的记录。结合带有指数退避的重试机制，这种幂等设计使得工作流能够在面对瞬时基础设施故障时，既能保证最终完成，又不会破坏数据的完整性。[@problem_id:3456757]

#### [数据管理](@entry_id:635035)与可复现性

高通量计算会产生海量数据，如何有效管理这些数据并确保计算过程的可复现性，是该领域面临的另一个巨大挑战。[FAIR原则](@entry_id:275880)（Findable, Accessible, Interoperable, Reusable）为科学[数据管理](@entry_id:635035)提供了指导框架。实现[FAIR原则](@entry_id:275880)的一个强大技术是使用“内容可寻址”存储，即每个数据或计算的唯一标识符（ID）是根据其内容（而不是其位置或名称）通过加密[哈希函数](@entry_id:636237)（如SHA-256）生成的。为了给一个工作流实例生成一个确定性的、内容衍生的ID，需要定义一个严格的“规范化”流程。该流程将工作流的所有输入（如输入文件、参数设置）转换为一个标准的、有序的字节串，然后对这个字节串进行哈希。这个过程必须对无关的格式差异（如空格、大小写、参数顺序）不敏感。同样，为了避免对结构上等价但原子索引不同的[晶体结构](@entry_id:140373)进行重复计算，需要一个可靠的结构等价性测试。这本质上是图论中的“标记[图同构](@entry_id:143072)”问题。通过结合[图不变量](@entry_id:262729)（如通过Weisfeiler-Lehman颜色精化算法计算的颜色直方图）和必要时的回溯搜索，可以稳健地判断两个[晶体结构](@entry_id:140373)是否在拓扑和原子类型上完全相同。[@problem_id:3456739]

此外，为了确保工作流在不同计算环境下的可移植性和可复现性，软件容器化技术（如[Docker](@entry_id:262723), Singularity）被广泛采用。容器将应用程序及其所有依赖项（库、编译器等）打包到一个隔离的、可移植的单元中。然而，这种便利性并非没有代价。容器化会引入性能开销，包括额外的计算减速、I/O路径变长导致的[吞吐量](@entry_id:271802)下降和延迟增加、每个任务启动容器的开销，以及在不同计算站点之间首次传输容器镜像所需的时间。通过一个简单的性能模型，我们可以量化这些开销。例如，总时间 $T_{\text{cont}}$ 可以建模为多个部分的和：包括基础计算和I/O时间、各项开销的乘性 slowdown 因子、以及与容器镜像缓存未命中概率相关的期望网络传输时间。通过这样的分析，研究人员可以就在特定场景下使用容器的利弊做出明智的决策。[@problem_id:3456713]

### 战略决策与[元分析](@entry_id:263874)

在高通量[材料科学](@entry_id:152226)的实践中，我们不仅要关注单个计算或工作流的设计，还必须能够从更高层次上进行战略规划和评估。这包括如何在多个相互冲突的性能目标之间做出权衡，以及如何客观地衡量和比较不同研究团队或方法论的进展。

#### 多目标权衡的导航

现实世界中的[材料设计](@entry_id:160450)很少是为了优化单一属性。通常，我们需要同时满足多个、甚至相互冲突的目标，例如，我们可能既希望一种新合金具有高强度，又希望它具有低成本和良好的延展性。这种场景被称为[多目标优化](@entry_id:637420)。在这种情况下，通常不存在一个在所有目标上都最优的“完美”解决方案。取而代之的是一个被称为“[帕累托前沿](@entry_id:634123)”（Pareto Front）的解集。帕累托前沿上的每一个点都代表一个“[帕累托最优](@entry_id:636539)”的材料，即任何其他材料如果在一个目标上比它好，就必然在至少另一个目标上比它差。理解和可视化帕累托前沿对于决策者来说至关重要，因为它揭示了不同性能目标之间的根本性权衡。一个简单的方法是将多个目标通过加权求和的方式组合成一个单一的标量目标函数。然而，这种线性[标量化](@entry_id:634761)方法有一个严重的缺陷：如果帕累托前沿是“非凸”的，那么前沿上位于“凹陷”区域的那些有趣的权衡点将永远无法通过任何权重组合被找到。因此，在[高通量筛选](@entry_id:271166)中，必须采用更先进的[多目标优化](@entry_id:637420)算法来完整地揭示整个[帕累托前沿](@entry_id:634123)，从而为[材料选择](@entry_id:161179)提供全面的决策支持。[@problem_id:3456731]

#### 基准测试与社区范围的进展评估

随着越来越多的研究团队开发自己的自动化工作流和[材料发现](@entry_id:159066)平台，一个自然而然的问题是：我们如何客观地比较这些方法的优劣，并衡量整个领域的进展？为此，设计一个严谨的、社区范围的基准测试（Benchmark）和排行榜至关重要。一个好的排行榜评分规则 $L$ 应该综合考虑多个关键性能维度，例如：通量（$R$）、可靠性（失败率 $p_f$）、准确性（[预测误差](@entry_id:753692) $\epsilon$）和可复现性（$S$）。为了确保公平和统计鲁棒性，评分规则必须满足一系列严格的要求。例如，它应当是无量纲的、对各个指标单调、并能处理有限样本带来的[统计不确定性](@entry_id:267672)（例如，使用置信区间的边界而非[点估计](@entry_id:174544)）。此外，为了强调所有维度都很重要，它应该采用乘法聚合，这样任何一个维度的糟糕表现都会严重拉低总分，而不是被其他维度的优异表现所“补偿”。一个满足这些要求的设计可能是这样的形式：$L = C\left( (\frac{R_{\mathrm{LCB}}}{R_{\mathrm{ref}}})(1 - p_{f,\mathrm{UCB}})(1 - \frac{\epsilon_{\mathrm{UCB}}}{\epsilon_{\mathrm{ref}}}) S_{\mathrm{LCB}} \right)$，其中 $C$ 是一个裁剪函数以确保分数在 $[0,1]$ 区间，LCB/UCB 分别是各指标的置信下界/[上界](@entry_id:274738)。这样的设计为评估和驱动整个领域的健康发展提供了坚实的量化基础。[@problem_id:3456715]

### 总结

本章通过一系列应用实例，描绘了[高通量材料筛选](@entry_id:750322)与自动化工作流这一领域的广度与深度。我们看到，现代[材料发现](@entry_id:159066)早已超越了传统的“试错法”，它是一个高度交叉融合的学科，深刻地集成了固体物理学、[量子化学](@entry_id:140193)、[统计学习](@entry_id:269475)、[优化理论](@entry_id:144639)、计算机[系统工程](@entry_id:180583)和数据科学。从利用群论保证[计算效率](@entry_id:270255)，到应用[贝叶斯优化](@entry_id:175791)智能地探索化学空间；从设计[容错](@entry_id:142190)的分布式系统，到制定统计上稳健的社区基准。这些应用不仅展示了核心原理的强大威力，更揭示了未来的挑战与机遇所在。只有通过不断地在这些[交叉](@entry_id:147634)学科的边界上进行创新，我们才能真正实现按需设计新材料的宏伟目标。