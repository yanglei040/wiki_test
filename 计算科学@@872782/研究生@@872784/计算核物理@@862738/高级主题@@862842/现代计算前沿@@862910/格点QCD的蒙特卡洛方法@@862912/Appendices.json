{"hands_on_practices": [{"introduction": "混合蒙特卡洛（HMC）方法的核心是利用时间可逆的辛积分器生成候选构型。[@problem_id:3571194]这个实践将指导你实现一个简化的HMC积分器，并通过可逆性测试来量化数值求解不精确性如何破坏算法的基本属性，例如能量守恒。这项练习对于理解和诊断HMC模拟中的系统误差来源至关重要。", "problem": "你需要实现并验证一个用于格点量子色动力学（Lattice QCD）的混合蒙特卡洛（HMC）分子动力学积分器的可逆性测试，方法是模拟一个紧致规范场和一个需要迭代线性求解器的玩具赝费米子部分。目标是量化精确可逆性的破坏程度以及微正则能量漂移作为求解器残差容忍度的函数。你的程序必须是一个完整的、可运行的程序，能够执行分子动力学在时间上的前进和后退演化，评估微正则能量漂移，并报告一个小型、完全指定的测试集的可逆性误差。所有角度必须以弧度为单位。\n\n从以下基本基础开始。格点量子色动力学的 HMC 方法为每个规范自由度引入一个辅助正则动量，并对一个虚构的分子动力学时间的哈密顿方程进行积分。对于一个紧致阿贝尔规范群，考虑一个尺寸为 $L_x \\times L_y$ 的二维周期性晶格，其中 $L_x = 2$ 且 $L_y = 2$。每个链变量是一个紧致角 $\\theta_{x,\\mu} \\in (-\\pi,\\pi]$，代表一个 $\\mathrm{U}(1)$ 链 $U_{x,\\mu} = e^{i \\theta_{x,\\mu}}$，其中 $\\mu \\in \\{0,1\\}$ 分别表示 $x$ 和 $y$ 方向。引入与 $\\theta_{x,\\mu}$ 共轭的正则动量 $p_{x,\\mu} \\in \\mathbb{R}$。哈密顿量为\n$$\nH(\\theta,p) = T(p) + S_g(\\theta) + V_f(\\theta),\n$$\n其中 $T(p) = \\tfrac{1}{2} \\sum_{x,\\mu} p_{x,\\mu}^2$ 是动能项，$S_g(\\theta)$ 是 $\\mathrm{U}(1)$ 的 Wilson 纯规范作用量，\n$$\nS_g(\\theta) = -\\beta \\sum_{x} \\cos \\phi_x,\n$$\n其中小方块角（plaquette angle）为 $\\phi_x = \\theta_{x,0} + \\theta_{x+\\hat{0},1} - \\theta_{x,1} - \\theta_{x+\\hat{1},0}$，并带有周期性边界条件，而 $V_f(\\theta)$ 是一个玩具赝费米子势，其构造为正定的，并且在每次力的评估时都需要进行线性求解：\n$$\nV_f(\\theta) = \\tfrac{1}{2} \\, b^\\top A(\\theta)^{-1} b, \\quad A(\\theta) = I + c_0 \\sum_{\\ell=1}^{N_\\ell} \\theta_\\ell^2 \\, B_\\ell.\n$$\n这里，$I$ 是 $n \\times n$ 的单位矩阵，其中 $n = 12$，$N_\\ell = 8$ 是 $2 \\times 2$ 晶格上定向链的数量，$c_0 = 0.1$ 是一个固定的正标量，每个 $B_\\ell$ 是一个对称半正定矩阵，定义为 $B_\\ell = v_\\ell v_\\ell^\\top$，其中 $v_\\ell \\in \\mathbb{R}^n$ 是一个随机向量。向量 $b \\in \\mathbb{R}^n$ 是一个固定的随机向量。链索引 $\\ell$ 按 $(x,y,\\mu)$ 的字典序排列，其中 $x \\in \\{0,1\\}$ 在最外层，然后是 $y \\in \\{0,1\\}$，最后是方向 $\\mu \\in \\{0,1\\}$。\n\n分子动力学使用时间可逆、辛结构的蛙跳积分器执行。如果力被精确计算，则该映射是保面积且可逆的，并且微正则哈密顿量 $H$ 在由步长控制的积分误差范围内是守恒的。在实践中，对于带有动力学费米子的格点量子色动力学，费米子力需要求解一个大型线性系统，这通常通过共轭梯度法和一个停止容忍度来完成。非精确求解会破坏精确的可逆性，并可能导致微正则能量漂移的绝对值增加。\n\n你的任务是：\n\n- 为紧致 $\\mathrm{U}(1)$ 规范场 $\\theta_{x,\\mu}$ 和正则动量 $p_{x,\\mu}$ 实现蛙跳积分器，使用哈密顿方程 $\\dot{\\theta}_{x,\\mu} = \\partial H / \\partial p_{x,\\mu}$ 和 $\\dot{p}_{x,\\mu} = - \\partial H / \\partial \\theta_{x,\\mu}$。按照标准的蛙跳方案，每次使用半步动量更新和全步链更新。\n- 在 $2 \\times 2$ 晶格上使用来自 Wilson 作用量的精确解析规范力，并采用周期性边界。每次更新后，角度必须被卷绕回 $(-\\pi,\\pi]$。\n- 对于类费米子力项，如上构造 $A(\\theta)$，并使用共轭梯度法计算近似解 $x \\approx A(\\theta)^{-1} b$，其指定的求解器容忍度 $\\epsilon$ 基于残差的范数。不要进行预处理。在给定的力评估过程中，始终使用相同的 $x$ 来一致地计算费米子力。\n- 微正则能量 $H(\\theta,p)$ 必须使用对 $A(\\theta)^{-1}$ 的直接稠密线性求解来高精度地评估（即，不要使用迭代求解器来计算能量）。这将力的非精确性与能量评估分离开来。\n- 执行一个可逆性测试：从一个固定的初始条件 $(\\theta^{(0)}, p^{(0)})$ 开始，以步长 $\\delta \\tau$ 向前积分 $N_{\\text{steps}}$ 步，然后反转动量 $p \\to -p$，再以步长 $\\delta \\tau$ 积分 $N_{\\text{steps}}$ 步。在后退阶段结束后，将 $(\\theta^{(b)}, p^{(b)})$ 与 $(\\theta^{(0)}, -p^{(0)})$进行比较。测量最大绝对缠绕角差和最大绝对动量差。\n- 量化前向积分段结束后的绝对微正则能量漂移，$\\Delta H = H(\\theta^{(f)}, p^{(f)}) - H(\\theta^{(0)}, p^{(0)})$，其中 $(\\theta^{(f)}, p^{(f)})$ 是前向积分段结束后的状态。\n\n初始化和数据：\n\n- 使用单个随机数生成器种子 $s = 314159$ 使实验可复现。按以下顺序抽取数据：每个 $\\ell = 1,\\dots,N_\\ell$ 的向量 $v_\\ell \\in \\mathbb{R}^{n}$，向量 $b \\in \\mathbb{R}^{n}$，初始链 $\\theta^{(0)}_{x,\\mu}$，以及初始动量 $p^{(0)}_{x,\\mu}$。\n- $v_\\ell$ 和 $b$ 的每个分量都独立地从均值为 $0$、方差为 $1$ 的正态分布中抽样。\n- 每个初始链角 $\\theta^{(0)}_{x,\\mu}$ 独立地从均值为 $0$、方差为 $\\sigma^2$（其中 $\\sigma = 0.3$）的正态分布中抽样，然后卷绕到 $(-\\pi,\\pi]$。每个初始动量 $p^{(0)}_{x,\\mu}$ 独立地从均值为 $0$、方差为 $1$ 的正态分布中抽样。\n\n积分器和作用量参数：\n\n- 晶格尺寸 $L_x = 2$, $L_y = 2$。\n- 规范耦合 $\\beta = 3.0$。\n- 费米子矩阵参数 $c_0 = 0.1$。\n- 赝费米子维度 $n = 12$。\n- 蛙跳步长 $\\delta \\tau = 0.1$ 和步数 $N_{\\text{steps}} = 10$。\n\n共轭梯度求解器的停止准则必须基于相对残差 $\\|r_k\\|_2 / \\|b\\|_2 \\le \\epsilon$，最大迭代次数为 $1000$ 次。线性算子是稠密对称正定矩阵 $A(\\theta)$。不允许进行预处理。\n\n测试集：\n\n对以下四种求解器容忍度 $\\epsilon$ 运行整个前向-后向可逆性协议，同时将所有其他参数固定为上述值：\n\n- $\\epsilon = 10^{-12}$。\n- $\\epsilon = 10^{-8}$。\n- $\\epsilon = 10^{-5}$。\n- $\\epsilon = 10^{-3}$。\n\n对于每个求解器容忍度 $\\epsilon$，计算并报告：\n\n- 前向积分段结束后的绝对微正则能量漂移 $|\\Delta H|$，其中 $H$ 使用对 $A(\\theta)^{-1}$ 的稠密直接求解进行评估。\n- 往返行程后的最大绝对缠绕角差 $E_\\theta = \\max_{\\ell} \\left| \\operatorname{wrap}\\left(\\theta_\\ell^{(b)} - \\theta_\\ell^{(0)}\\right) \\right|$，角度被卷绕到 $(-\\pi,\\pi]$。\n- 往返行程后的最大绝对动量差 $E_p = \\max_{\\ell} \\left| p_\\ell^{(b)} + p_\\ell^{(0)} \\right|$。\n\n角度单位说明：所有角度均以弧度为单位。\n\n最终输出格式：\n\n你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是一个三元素列表 $[|\\Delta H|, E_\\theta, E_p]$。所有浮点数必须以科学记数法格式化，小数点后有八位数字。例如，输出必须看起来像\n$$\n\\big[ [a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3],[a_4,b_4,c_4] \\big],\n$$\n但使用实际数字且没有空格。输出必须是单行，且无其他内容。", "solution": "问题陈述经评估有效。它具有科学依据、提法恰当、客观，并为计算物理中的一个数值实验提供了一套完整且一致的规范。该模型虽然经过简化，但基于格点量子色动力学（Lattice QCD）和哈密顿动力学的既定原理。任务涉及实现一个标准的混合蒙特卡洛（HMC）积分器并执行可逆性测试，这是该领域中一个常规且有意义的诊断程序。所有参数、初始条件和程序都已明确定义，使得该问题完全确定且可验证。\n\n解决方案首先构建模拟所需的组件——哈密顿量、其组成的势能和动能项，以及从势能推导出的力——然后使用指定的蛙跳算法对运动方程进行积分。任务的核心是观察力计算中的非精确性（源于线性系统的迭代求解）如何影响积分器的一个基本属性：时间可逆性。\n\n系统的哈密顿量由下式给出\n$$\nH(\\theta,p) = T(p) + S_g(\\theta) + V_f(\\theta)\n$$\n其中 $\\theta = \\{\\theta_{x,\\mu}\\}$ 是一个 $L_x \\times L_y = 2 \\times 2$ 晶格上的紧致链角，而 $p = \\{p_{x,\\mu}\\}$ 是它们的共轭动量。总链数为 $N_\\ell = L_x \\times L_y \\times 2 = 8$。\n\n动能为 $T(p) = \\tfrac{1}{2} \\sum_{\\ell=1}^{N_\\ell} p_\\ell^2$。势能由纯规范部分 $S_g(\\theta)$ 和赝费米子部分 $V_f(\\theta)$ 组成。\n\n规范作用量是 $\\mathrm{U}(1)$ 规范群的 Wilson 作用量：\n$$\nS_g(\\theta) = -\\beta \\sum_{x} \\cos \\phi_x\n$$\n其中 $\\beta=3.0$ 是耦合常数，求和遍历所有 $4$ 个晶格点 $x=(i_x, i_y)$。在格点 $x$ 处的小方块角（plaquette angle）$\\phi_x$ 定义为\n$$\n\\phi_x = \\theta_{x,0} + \\theta_{x+\\hat{0},1} - \\theta_{x,1} - \\theta_{x+\\hat{1},0}\n$$\n并采用周期性边界条件，其中 $\\mu=0$ 表示 x 方向，$\\mu=1$ 表示 y 方向。此作用量对链变量 $\\theta_{x,\\mu}$ 产生的力为 $F_{g,x,\\mu} = -\\partial S_g / \\partial \\theta_{x,\\mu}$。一个给定的链 $\\theta_{x,\\mu}$ 对两个小方块有贡献。对于在格点 $x=(i_x,i_y)$ 的链 $\\theta_{x,0}$，其对力的贡献为\n$$\nF_{g,x,0} = -\\beta (\\sin \\phi_x - \\sin \\phi_{x-\\hat{1}})\n$$\n其中 $x-\\hat{1}$ 是格点 $(i_x, (i_y-1) \\pmod{L_y})$。对于链 $\\theta_{x,1}$，力为\n$$\nF_{g,x,1} = \\beta(\\sin \\phi_x - \\sin \\phi_{x-\\hat{0}})\n$$\n其中 $x-\\hat{0}$ 是格点 $((i_x-1) \\pmod{L_x}, i_y)$。\n\n赝费米子势 $V_f(\\theta)$ 模拟了费米子行列式的效应，并且是计算复杂性和非精确性的来源。它被定义为\n$$\nV_f(\\theta) = \\tfrac{1}{2} \\, b^\\top A(\\theta)^{-1} b\n$$\n其中 $b \\in \\mathbb{R}^n$（$n=12$）是一个固定的随机向量，而 $A(\\theta)$ 是一个依赖于规范场构型 $\\theta$ 的 $n \\times n$ 矩阵：\n$$\nA(\\theta) = I + c_0 \\sum_{\\ell=1}^{N_\\ell} \\theta_\\ell^2 \\, B_\\ell\n$$\n这里，$c_0=0.1$ 是一个常数，$\\theta_\\ell$ 是按字典序排列的第 $\\ell$ 个链角，而 $B_\\ell = v_\\ell v_\\ell^\\top$ 是由随机向量 $v_\\ell \\in \\mathbb{R}^n$ 构建的固定对称半正定矩阵。由于 $I$ 是正定的，并且每个 $c_0 \\theta_\\ell^2 B_\\ell$ 是半正定的，因此矩阵 $A(\\theta)$ 保证是对称正定（SPD）的，这是共轭梯度（CG）算法稳定性的关键属性。\n\n赝费米子力 $F_{f,\\ell} = -\\partial V_f / \\partial \\theta_\\ell$ 使用矩阵微积分推导得出。令 $x(\\theta) = A(\\theta)^{-1}b$，我们有 $V_f(\\theta) = \\tfrac{1}{2} b^\\top x(\\theta)$。其导数为：\n$$\n\\frac{\\partial V_f}{\\partial \\theta_\\ell} = -\\frac{1}{2} b^\\top A^{-1} \\frac{\\partial A}{\\partial \\theta_\\ell} A^{-1} b = -\\frac{1}{2} x^\\top \\left( 2 c_0 \\theta_\\ell B_\\ell \\right) x = -c_0 \\theta_\\ell \\, (x^\\top B_\\ell x)\n$$\n因此，力为\n$$\nF_{f,\\ell} = c_0 \\theta_\\ell \\, (x^\\top B_\\ell x)\n$$\n计算这个力需要求解 $x = A(\\theta)^{-1}b$。这是通过 CG 算法完成的，当相对残差范数 $\\|A x_k - b\\|_2 / \\|b\\|_2$ 低于指定的容忍度 $\\epsilon$ 时停止。该解的非精确性是问题的核心焦点。\n\n系统使用标准的二阶蛙跳积分器进行演化，当力被精确计算时，该积分器是时间可逆和辛的。单步积分 $\\delta\\tau=0.1$ 的过程如下：\n1.  动量更新半步：$p \\to p + F(\\theta) \\frac{\\delta\\tau}{2}$。\n2.  位置更新全步：$\\theta \\to \\theta + p \\, \\delta\\tau$。然后将角度卷绕到区间 $(-\\pi, \\pi]$。\n3.  动量更新最后半步：$p \\to p + F(\\theta_{new}) \\frac{\\delta\\tau}{2}$。\n此过程重复 $N_{\\text{steps}}=10$ 次。\n\n可逆性测试包括一个时间向前的轨迹（$N_{\\text{steps}}$ 步），然后是动量反转 $p \\to -p$，以及一个时间向后的轨迹（$N_{\\text{steps}}$ 步）。将最终状态 $(\\theta^{(b)}, p^{(b)})$ 与初始状态 $(\\theta^{(0)}, -p^{(0)})$ 进行比较。对每个求解器容忍度 $\\epsilon$ 测量三个量：\n1.  **能量漂移 $|\\Delta H|$**：前向轨迹后哈密顿量的绝对变化，即 $|H(\\theta^{(f)}, p^{(f)}) - H(\\theta^{(0)}, p^{(0)})|$。这是能量守恒的度量。为进行此计算，$H$ 是通过对 $A(\\theta)^{-1}$ 的高精度直接线性求解来计算的，以将积分误差与能量测量误差分离开来。\n2.  **角度可逆性误差 $E_\\theta$**：最终角度与初始角度的最大绝对偏差，$\\max_\\ell |\\operatorname{wrap}(\\theta_\\ell^{(b)} - \\theta_\\ell^{(0)})|$。\n3.  **动量可逆性误差 $E_p$**：最终动量与取反的初始动量的最大绝对偏差，$\\max_\\ell |p_\\ell^{(b)} + p_\\ell^{(0)}|$。\n\n这个数值实验针对一组测试容忍度 $\\epsilon \\in \\{10^{-12}, 10^{-8}, 10^{-5}, 10^{-3}\\}$ 进行，展示了更宽松（更大的 $\\epsilon$）的求解器容忍度如何导致更显著的可逆性和能量守恒的破坏，这与预期相符。所有随机数都由固定的种子生成，以确保可复现性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a reversibility test for a Hybrid Monte Carlo integrator\n    on a toy U(1) lattice gauge theory model.\n    \"\"\"\n    # Problem Parameters\n    L_X, L_Y = 2, 2\n    N_LINKS = L_X * L_Y * 2\n    BETA = 3.0\n    C0 = 0.1\n    N_PF = 12\n    DT = 0.1\n    N_STEPS = 10\n    SIGMA_THETA = 0.3\n    SEED = 314159\n    CG_MAX_ITER = 1000\n    TEST_TOLERANCES = [1e-12, 1e-8, 1e-5, 1e-3]\n\n    # --- Initialization ---\n    rng = np.random.default_rng(SEED)\n\n    # Generate fixed random data for the pseudofermion sector\n    # Vectors v_l used to construct matrices B_l\n    v_vectors = rng.normal(size=(N_LINKS, N_PF))\n    # Matrices B_l = v_l v_l^T\n    B_matrices = np.array([np.outer(v, v) for v in v_vectors])\n    # Fixed pseudofermion source vector b\n    b_vector = rng.normal(size=N_PF)\n    b_norm = np.linalg.norm(b_vector)\n\n    # Generate fixed initial conditions\n    theta_initial = (rng.normal(scale=SIGMA_THETA, size=(L_X, L_Y, 2)) + np.pi) % (2 * np.pi) - np.pi\n    p_initial = rng.normal(size=(L_X, L_Y, 2))\n\n    # --- Helper Functions ---\n    def wrap_angle(angles):\n        \"\"\"Wraps angles to the interval (-pi, pi].\"\"\"\n        return (angles + np.pi) % (2 * np.pi) - np.pi\n\n    def get_plaquettes(theta):\n        \"\"\"Computes plaquette angles for a given gauge field configuration.\"\"\"\n        plaquettes = np.zeros((L_X, L_Y))\n        for ix in range(L_X):\n            for iy in range(L_Y):\n                # phi_x = theta_{x,0} + theta_{x+0,1} - theta_{x,1} - theta_{x+1,0}\n                # with periodic boundary conditions\n                plaquettes[ix, iy] = (\n                    theta[ix, iy, 0]\n                    + theta[(ix + 1) % L_X, iy, 1]\n                    - theta[ix, iy, 1]\n                    - theta[ix, (iy + 1) % L_Y, 0]\n                )\n        return plaquettes\n\n    def cg_solve(A, b, b_norm_val, rel_tol):\n        \"\"\"Solves Ax = b using Conjugate Gradient for a symmetric positive-definite A.\"\"\"\n        x = np.zeros_like(b)\n        r = b.copy()\n        p = r.copy()\n        rs_old = r @ r\n        \n        abs_tol_sq = (rel_tol * b_norm_val)**2\n        if rs_old  abs_tol_sq:\n            return x\n\n        for _ in range(CG_MAX_ITER):\n            Ap = A @ p\n            alpha = rs_old / (p @ Ap)\n            x += alpha * p\n            r -= alpha * Ap\n            rs_new = r @ r\n            if rs_new  abs_tol_sq:\n                break\n            p = r + (rs_new / rs_old) * p\n            rs_old = rs_new\n        return x\n\n    # --- Physics and Integrator Functions ---\n    def compute_A_matrix(theta_flat):\n        \"\"\"Computes the pseudofermion matrix A(theta).\"\"\"\n        A = np.identity(N_PF)\n        theta_sq = theta_flat**2\n        # Sum over links: c0 * theta_l^2 * B_l\n        A += C0 * np.einsum('l,lij->ij', theta_sq, B_matrices)\n        return A\n        \n    def total_force(theta, epsilon):\n        \"\"\"Computes the total force F = -dV/dtheta.\"\"\"\n        # Gauge force\n        plaquettes = get_plaquettes(theta)\n        force_g = np.zeros_like(theta)\n        for ix in range(L_X):\n            for iy in range(L_Y):\n                # F_g,x,0 = -beta * (sin(phi_x) - sin(phi_{x-y_hat}))\n                force_g[ix, iy, 0] = -BETA * (\n                    np.sin(plaquettes[ix, iy]) - np.sin(plaquettes[ix, (iy - 1) % L_Y])\n                )\n                # F_g,x,1 = -beta * (-sin(phi_x) + sin(phi_{x-x_hat}))\n                force_g[ix, iy, 1] = -BETA * (\n                    -np.sin(plaquettes[ix, iy]) + np.sin(plaquettes[(ix - 1) % L_X, iy])\n                )\n        \n        # Pseudofermion force\n        theta_flat = theta.flatten()\n        A = compute_A_matrix(theta_flat)\n        x_sol = cg_solve(A, b_vector, b_norm, epsilon)\n        \n        # F_f,l = c0 * theta_l * (x^T B_l x)\n        xT_B = np.einsum('i,lij->lj', x_sol, B_matrices)\n        xT_B_x = np.einsum('lj,j->l', xT_B, x_sol)\n        force_f_flat = C0 * theta_flat * xT_B_x\n        \n        force_total = force_g.flatten() + force_f_flat\n        return force_total.reshape(L_X, L_Y, 2)\n\n    def calculate_hamiltonian(theta, p):\n        \"\"\"Calculates the Hamiltonian with high precision.\"\"\"\n        # Kinetic energy\n        T = 0.5 * np.sum(p**2)\n        \n        # Gauge action\n        plaquettes = get_plaquettes(theta)\n        S_g = -BETA * np.sum(np.cos(plaquettes))\n        \n        # Pseudofermion potential (high precision solve)\n        theta_flat = theta.flatten()\n        A = compute_A_matrix(theta_flat)\n        x_sol_exact = np.linalg.solve(A, b_vector)\n        V_f = 0.5 * (b_vector @ x_sol_exact)\n        \n        return T + S_g + V_f\n\n    def run_trajectory(theta_start, p_start, epsilon):\n        \"\"\"Integrates the system for N_steps using the leapfrog algorithm.\"\"\"\n        theta, p = theta_start.copy(), p_start.copy()\n        \n        # Standard leapfrog: p(t+dt/2), theta(t+dt), p(t+dt)\n        force_current = total_force(theta, epsilon)\n        p += 0.5 * DT * force_current\n        for _ in range(N_STEPS - 1):\n            theta = wrap_angle(theta + DT * p)\n            force_current = total_force(theta, epsilon)\n            p += DT * force_current\n        \n        # Final full theta step and half p step\n        theta = wrap_angle(theta + DT * p)\n        force_current = total_force(theta, epsilon)\n        p += 0.5 * DT * force_current\n        \n        return theta, p\n\n    # --- Main Test Loop ---\n    results = []\n    H_initial = calculate_hamiltonian(theta_initial, p_initial)\n\n    for epsilon in TEST_TOLERANCES:\n        # Forward trajectory\n        theta_fwd, p_fwd = run_trajectory(theta_initial, p_initial, epsilon)\n        \n        # Energy drift\n        H_final_fwd = calculate_hamiltonian(theta_fwd, p_fwd)\n        delta_H = np.abs(H_final_fwd - H_initial)\n        \n        # Backward trajectory\n        theta_bwd, p_bwd = run_trajectory(theta_fwd, -p_fwd, epsilon)\n        \n        # Reversibility errors\n        E_theta = np.max(np.abs(wrap_angle(theta_bwd - theta_initial)))\n        E_p = np.max(np.abs(p_bwd + p_initial))\n        \n        results.append([delta_H, E_theta, E_p])\n\n    # --- Format and Print Output ---\n    output_str = \",\".join(\n        f\"[{res[0]:.8e},{res[1]:.8e},{res[2]:.8e}]\" for res in results\n    )\n    print(f\"[{output_str}]\")\n\n\nsolve()\n\n```", "id": "3571194"}, {"introduction": "在实际的格点QCD计算中，算法效率是决定性的因素之一。[@problem_id:3571179]这个练习将引导你建立一个模型，用以权衡HMC算法中伪费米子场的数量对计算成本和接受率的影响。通过最大化“吞吐量”这一指标，你将学习到如何在统计精度和计算资源之间做出最优选择，这是大规模模拟中的一个核心优化问题。", "problem": "考虑用于格点量子色动力学 (QCD) 的混合蒙特卡洛 (HMC) 方法，其中费米子行列式由伪费米子场表示。令分子动力学 (MD) 的力是确定性的规范贡献和由伪费米子估计的随机费米子贡献之和。假设以下基本事实，每条都在计算核物理中被广泛使用：\n\n- HMC 的提议是通过对一个可逆、保面积的 MD 流进行积分生成的；Metropolis–Hastings 校正强制实现细致平衡，从而使得接受概率仅依赖于哈密顿量违背值 $\\Delta H$ 在整个轨迹上的分布。\n- 对于一个二阶辛积分器（例如，蛙跳法），能量误差中的主要偏差与 $\\mathcal{O}(\\delta\\tau^{2})$ 成比例，其中 $\\delta\\tau$ 是 MD 步长，并且步间的局部误差近似地以弱相关和的形式累加。\n- 如果使用 $N_{\\rm pf}$ 个独立的伪费米子场来构建费米子力的估计量，并且通过对独立贡献进行平均来组合这些场，那么费米子力估计量的方差将与 $1/N_{\\rm pf}$ 成比例下降。\n\n在归一化单位中对以下内容进行建模：\n\n1) 令规范力的方差为 $\\sigma_{G}^{2}$，单伪费米子费米力估计量的方差为 $\\sigma_{F}^{2}$。对于 $N_{\\rm pf}$ 个独立的伪费米子，费米子力的方差变为 $\\sigma_{F}^{2}/N_{\\rm pf}$。因此，总力的方差为 $\\sigma_{\\rm tot}^{2}(N_{\\rm pf})=\\sigma_{G}^{2}+\\sigma_{F}^{2}/N_{\\rm pf}$。\n\n2) 在长度为 $\\tau$、步数为 $n_{\\rm steps}=\\tau/\\delta\\tau$ 的轨迹上，哈密顿量违背值的方差可近似为\n$$\n\\operatorname{Var}(\\Delta H)\\equiv \\sigma_{\\Delta H}^{2}=\\kappa\\,n_{\\rm steps}\\left(\\delta\\tau^{2}\\right)^{2}\\,\\sigma_{\\rm tot}^{2}(N_{\\rm pf})=\\kappa\\,\\tau\\,\\delta\\tau^{3}\\,\\bigg(\\sigma_{G}^{2}+\\frac{\\sigma_{F}^{2}}{N_{\\rm pf}}\\bigg),\n$$\n其中 $\\kappa$ 是一个无量纲常数，包含了与积分器相关的预因子以及步间的弱相关性。在归一化单位中，取 $\\kappa=1$。\n\n3) 对于可逆、保面积的提议，细致平衡恒等式意味着 $\\langle e^{-\\Delta H}\\rangle=1$。在常见的小步长高斯近似下，将 $\\Delta H$ 建模为均值为 $\\mu$、方差为 $\\sigma_{\\Delta H}^{2}$ 的单变量正态随机变量。约束条件 $\\langle e^{-\\Delta H}\\rangle=1$ 进而将 $\\mu$ 固定为 $\\sigma_{\\Delta H}^{2}$ 的函数。使用此关系推导接受概率\n$$\nP_{\\rm acc}=\\mathbb{E}\\big[\\min(1,e^{-\\Delta H})\\big]\n$$\n使其仅用 $\\sigma_{\\Delta H}^{2}$ 表示。\n\n4) 每个 MD 步的计算成本建模为 $c_{\\rm step}(N_{\\rm pf})=c_{g}+N_{\\rm pf}\\,c_{\\rm solve}$，其中 $c_{g}$ 是规范力的计算成本，$c_{\\rm solve}$ 是每个伪费米子进行一次费米子求解的成本。那么，每条轨迹的总成本为\n$$\nC_{\\rm traj}(N_{\\rm pf})=n_{\\rm steps}\\,c_{\\rm step}(N_{\\rm pf})=\\frac{\\tau}{\\delta\\tau}\\,\\big(c_{g}+N_{\\rm pf}\\,c_{\\rm solve}\\big).\n$$\n\n定义吞吐量泛函\n$$\nT(N_{\\rm pf})=\\frac{P_{\\rm acc}(N_{\\rm pf})}{C_{\\rm traj}(N_{\\rm pf})},\n$$\n并将 $N_{\\rm pf}$ 取为闭区间 $[1,N_{\\rm max}]$ 内的正整数。\n\n任务：使用高斯假设和恒等式 $\\langle e^{-\\Delta H}\\rangle=1$，推导以 $\\sigma_{\\Delta H}^{2}(N_{\\rm pf})$ 表示的 $P_{\\rm acc}(N_{\\rm pf})$，然后实现一个程序，对下面的每个测试用例，评估 $T(N_{\\rm pf})$ 并返回在 $[1,N_{\\rm max}]$ 中使 $T(N_{\\rm pf})$ 最大化的整数 $N_{\\rm pf}$。如果出现完全相同的值，则返回达到最大值的最小 $N_{\\rm pf}$。输出中不需要物理单位。\n\n使用以下测试集，其中每个元组为 $(\\tau,\\delta\\tau,\\sigma_{F},\\sigma_{G},c_{\\rm solve},c_{g},N_{\\rm max})$：\n\n- 测试 $1$：$(1.0,\\,0.20,\\,20.0,\\,1.0,\\,2.0,\\,1000.0,\\,8)$\n- 测试 $2$：$(1.0,\\,0.10,\\,5.0,\\,1.0,\\,200.0,\\,10.0,\\,8)$\n- 测试 $3$：$(2.0,\\,0.15,\\,30.0,\\,5.0,\\,20.0,\\,200.0,\\,8)$\n- 测试 $4$：$(0.5,\\,0.05,\\,40.0,\\,0.5,\\,5.0,\\,0.0,\\,8)$\n- 测试 $5$：$(1.0,\\,0.12,\\,15.0,\\,2.0,\\,50.0,\\,15.0,\\,1)$\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$[n_{1},n_{2},n_{3},n_{4},n_{5}]$），其中每个 $n_{i}$ 是对应测试用例的最优 $N_{\\rm pf}$。", "solution": "目标是确定最优的伪费米子场数量 $N_{\\rm pf}$，以使混合蒙特卡洛模拟的吞吐量泛函 $T(N_{\\rm pf})$ 最大化。该优化是针对一组给定的模拟参数，通过在离散整数域 $N_{\\rm pf} \\in [1, N_{\\rm max}]$ 上评估 $T(N_{\\rm pf})$ 来执行的。此过程包括两个主要阶段：首先，推导接受概率 $P_{\\rm acc}$ 作为哈密顿量违背值方差 $\\sigma_{\\Delta H}^2$ 函数的闭式表达式；其次，构建完整的吞吐量泛函并执行优化。\n\n首先，我们推导接受概率 $P_{\\rm acc}$ 的表达式。问题陈述哈密顿量违背值 $\\Delta H$ 被建模为正态分布的随机变量，$\\Delta H \\sim \\mathcal{N}(\\mu, \\sigma_{\\Delta H}^2)$。均值 $\\mu$ 不是任意的，而是由细致平衡条件 $\\langle e^{-\\Delta H} \\rangle = 1$ 固定的，该条件对于可逆、保面积的提议分布必须成立。期望值是根据 $\\Delta H$ 的分布计算的：\n$$\n\\langle e^{-\\Delta H} \\rangle = \\int_{-\\infty}^{\\infty} e^{-x} \\frac{1}{\\sqrt{2\\pi\\sigma_{\\Delta H}^2}} e^{-\\frac{(x - \\mu)^2}{2\\sigma_{\\Delta H}^2}} dx = 1\n$$\n通过对被积函数指数部分进行配方，该积分的计算结果为 $\\exp(-\\mu + \\sigma_{\\Delta H}^2/2)$。将此结果设为 1，即可得到均值的关系式：\n$$\n-\\mu + \\frac{\\sigma_{\\Delta H}^2}{2} = 0 \\implies \\mu = \\frac{\\sigma_{\\Delta H}^2}{2}\n$$\n因此，$\\Delta H$ 的分布完全由其方差 $\\sigma_{\\Delta H}^2$ 确定。接受概率定义为 $P_{\\rm acc} = \\mathbb{E}[\\min(1, e^{-\\Delta H})]$。我们通过根据 $\\Delta H$ 的值拆分积分来计算这个期望：\n$$\nP_{\\rm acc} = \\int_{-\\infty}^{0} 1 \\cdot p(\\Delta H) d(\\Delta H) + \\int_{0}^{\\infty} e^{-\\Delta H} p(\\Delta H) d(\\Delta H)\n$$\n第一项是概率 $P(\\Delta H  0)$。对于正态分布 $\\mathcal{N}(\\mu, \\sigma_{\\Delta H}^2)$，这由标准正态分布的累积分布函数 (CDF) $\\Phi$ 给出：\n$$\nP(\\Delta H  0) = \\Phi\\left(\\frac{0 - \\mu}{\\sigma_{\\Delta H}}\\right) = \\Phi\\left(\\frac{-\\sigma_{\\Delta H}^2/2}{\\sigma_{\\Delta H}}\\right) = \\Phi\\left(-\\frac{\\sigma_{\\Delta H}}{2}\\right)\n$$\n通过与求解 $\\mu$ 时类似的配方方法，可以证明第二项等于第一项。这得出了一个简单的关系：\n$$\nP_{\\rm acc} = 2\\Phi\\left(-\\frac{\\sigma_{\\Delta H}}{2}\\right)\n$$\n该表达式可以方便地使用互补误差函数 $\\text{erfc}(z)$ 来书写，它与标准正态 CDF 的关系为 $\\text{erfc}(z/\\sqrt{2}) = 2\\Phi(-z)$。这给出了接受概率的最终形式：\n$$\nP_{\\rm acc}(\\sigma_{\\Delta H}) = \\text{erfc}\\left(\\frac{\\sigma_{\\Delta H}}{2\\sqrt{2}}\\right)\n$$\n接下来，我们构建完整的吞吐量泛函 $T(N_{\\rm pf})$。哈密顿量违背值的方差 $\\sigma_{\\Delta H}^2$ 通过总力的方差 $\\sigma_{\\rm tot}^2$ 依赖于 $N_{\\rm pf}$。代入给定的模型并设置常数 $\\kappa=1$：\n$$\n\\sigma_{\\Delta H}^{2}(N_{\\rm pf}) = \\tau\\,\\delta\\tau^{3}\\,\\sigma_{\\rm tot}^{2}(N_{\\rm pf}) = \\tau\\,\\delta\\tau^{3}\\,\\left(\\sigma_{G}^{2}+\\frac{\\sigma_{F}^{2}}{N_{\\rm pf}}\\right)\n$$\n每条轨迹的计算成本也是 $N_{\\rm pf}$ 的函数：\n$$\nC_{\\rm traj}(N_{\\rm pf}) = n_{\\rm steps}\\,c_{\\rm step}(N_{\\rm pf}) = \\frac{\\tau}{\\delta\\tau}\\,\\left(c_{g}+N_{\\rm pf}\\,c_{\\rm solve}\\right)\n$$\n结合这些元素，需要最大化的吞吐量泛函是：\n$$\nT(N_{\\rm pf}) = \\frac{P_{\\rm acc}(N_{\\rm pf})}{C_{\\rm traj}(N_{\\rm pf})} = \\frac{\\text{erfc}\\left(\\frac{\\sqrt{\\tau\\,\\delta\\tau^{3}\\,\\left(\\sigma_{G}^{2}+\\sigma_{F}^{2}/N_{\\rm pf}\\right)}}{2\\sqrt{2}}\\right)}{\\frac{\\tau}{\\delta\\tau}\\,\\left(c_{g}+N_{\\rm pf}\\,c_{\\rm solve}\\right)}\n$$\n优化过程是在指定范围内找到使该函数最大化的整数 $N_{\\rm pf}^*$。由于 $N_{\\rm pf}$ 被限制在一个小的整数范围 $[1, N_{\\rm max}]$ 内，我们执行直接搜索。对于每个测试用例，我们将 $N_{\\rm pf}$ 从 $1$ 迭代到 $N_{\\rm max}$，使用上述公式计算 $T(N_{\\rm pf})$，并确定产生最高吞吐量的 $N_{\\rm pf}$ 值。根据问题说明，如果多个 $N_{\\rm pf}$ 值导致相同的最大吞吐量，则选择其中最小的值。这通过仅在找到严格更大的吞吐量时才更新最优选择来自然地处理。每个测试用例的算法如下：将最大吞吐量变量初始化为负值，并初始化一个最优 $N_{\\rm pf}$ 变量。然后，将 $N_{\\rm pf}$ 从 $1$ 循环到 $N_{\\rm max}$，计算相应的 $T(N_{\\rm pf})$，如果该值大于存储的最大值，则更新最大值和最优 $N_{\\rm pf}$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import erfc\n\ndef solve():\n    \"\"\"\n    Calculates the optimal number of pseudofermion fields (N_pf) that maximizes\n    the throughput functional for a series of Hybrid Monte Carlo simulation test cases.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    # Each tuple is (tau, delta_tau, sigma_F, sigma_G, c_solve, c_g, N_max)\n    test_cases = [\n        (1.0, 0.20, 20.0, 1.0, 2.0, 1000.0, 8),\n        (1.0, 0.10, 5.0, 1.0, 200.0, 10.0, 8),\n        (2.0, 0.15, 30.0, 5.0, 20.0, 200.0, 8),\n        (0.5, 0.05, 40.0, 0.5, 5.0, 0.0, 8),\n        (1.0, 0.12, 15.0, 2.0, 50.0, 15.0, 1),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        tau, delta_tau, sigma_F, sigma_G, c_solve, c_g, N_max = case\n        \n        optimal_npf = -1\n        max_throughput = -1.0\n        \n        # Iterate over all possible integer values of N_pf in [1, N_max]\n        for N_pf in range(1, N_max + 1):\n            \n            # Step 1: Calculate the variance of the Hamiltonian violation sigma_dH^2\n            sigma_F_sq = sigma_F**2\n            sigma_G_sq = sigma_G**2\n            sigma_tot_sq = sigma_G_sq + sigma_F_sq / N_pf\n            \n            # The dimensionless constant kappa is given as 1.\n            sigma_dH_sq = tau * (delta_tau**3) * sigma_tot_sq\n            \n            # Standard deviation of the Hamiltonian violation.\n            sigma_dH = np.sqrt(sigma_dH_sq)\n            \n            # Step 2: Calculate the acceptance probability P_acc.\n            # Derived as erfc(sigma_dH / (2*sqrt(2))).\n            P_acc = erfc(sigma_dH / (2.0 * np.sqrt(2.0)))\n            \n            # Step 3: Calculate the total cost per trajectory C_traj.\n            C_traj = (tau / delta_tau) * (c_g + N_pf * c_solve)\n            \n            # Step 4: Calculate the throughput functional T(N_pf).\n            # Handle potential division by zero if C_traj is zero, though problem \n            # constraints make this scenario highly unlikely (tau, delta_tau, c_solve > 0).\n            if C_traj > 1e-15: # Use a small tolerance for float comparison\n                throughput = P_acc / C_traj\n            else:\n                throughput = float('inf') if P_acc > 0 else 0.0\n\n            # Step 5: Check for a new maximum throughput.\n            # The strict inequality '>' ensures that in case of a tie, the smallest\n            # N_pf value that achieves the maximum is kept, per the problem's tie-breaking rule.\n            if throughput > max_throughput:\n                max_throughput = throughput\n                optimal_npf = N_pf\n\n        results.append(optimal_npf)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3571179"}, {"introduction": "马尔可夫链蒙特卡洛方法产生的构型序列通常具有自相关性，这使得统计误差的估算变得复杂。[@problem_id:3571154]这项实践将指导你通过编程实现“分箱”（binning）和“刀切法”（jackknife）这两种关键的数据分析技术。你将通过处理一个模拟的格点QCD有效质量数据，亲身体验如何正确处理自相关数据，从而获得可靠的物理结果及其不确定度。", "problem": "您的任务是构建一个完整、可运行的程序，为格点量子色动力学（Lattice QCD）中常用的非线性估计量——有效质量，实现一个分箱加刀切法（binning plus jackknife）的流程。其目标是将通常具有自相关的马尔可夫链蒙特卡洛数据的统计行为与分箱和刀切法估计量随分箱大小增加时的行为联系起来。您的任务是从马尔可夫链蒙特卡洛和自相关的基本原理出发，实现一个模拟欧几里得两点关联函数的、科学上合理的合成数据生成器，然后为有效质量构建分箱加刀切法估计量的处理流程。您必须接着量化在不同自相关情景下，估计的刀切法误差是否作为分箱大小的函数而饱和。\n\n从以下基本依据开始，您必须用它来证明您的设计和推理的合理性：\n\n- 马尔可夫链蒙特卡洛生成一个按时间排序的样本序列，对于在蒙特卡洛时间间隔 $k$ 处测量的可观测量 $\\mathcal{O}$，其自相关函数为 $C_{\\mathcal{O}}(k)$，积分自相关时间为 $\\tau_{\\text{int}} = \\frac{1}{2} + \\sum_{k=1}^{\\infty} \\rho_{\\mathcal{O}}(k)$，其中 $\\rho_{\\mathcal{O}}(k) = C_{\\mathcal{O}}(k)/C_{\\mathcal{O}}(0)$。\n- 对于相关样本，在大样本量 $N$ 的极限下，样本均值的方差满足 $\\sigma^2_{\\bar{\\mathcal{O}}} \\approx \\frac{\\sigma^2_{\\mathcal{O}}}{N} \\, 2 \\, \\tau_{\\text{int}}$。\n- 将相邻样本分组到大小为 $B$ 的不重叠的箱中，可以减少箱均值之间的自相关。如果 $B \\gg \\tau_{\\text{int}}$，则箱均值近似独立同分布。\n- 将删一分箱刀切法应用于根据分箱平均数据计算的标量估计量 $\\theta$，即使对于非线性的 $\\theta$，也能为其方差提供一个一致的估计量。\n\n您必须实现以下组件：\n\n1) 两个相邻欧几里得时间点上的欧几里得两点关联函数的合成模型。对于一个固定的时间片 $t_0$，假设一个具有依赖于组态的振幅的单态关联函数模型。设真实关联函数为 $G(t) = A \\, e^{-m t}$，其中质量为 $m$，正振幅 $A$ 因规范噪音而在不同组态间涨落。在蒙特卡洛组态索引 $n$ 处测得的关联函数为：\n$$\nC_t^{(n)} = A^{(n)} e^{-m t_0} \\, \\epsilon_t^{(n)}, \\qquad C_{t+1}^{(n)} = A^{(n)} e^{-m (t_0+1)} \\, \\epsilon_{t+1}^{(n)},\n$$\n其中 $A^{(n)}$ 是一个沿 $n$ 变化的、正的、相关的随机过程，而 $\\epsilon_t^{(n)}$、$\\epsilon_{t+1}^{(n)}$ 是小的、独立的、均值为1的乘性噪音。将 $\\ln A^{(n)}$ 建模为一个系数为 $\\phi$ 的一阶自回归过程（AR(1)），即：\n$$\nX_n = \\phi X_{n-1} + \\eta_n, \\quad \\eta_n \\sim \\mathcal{N}(0, \\sigma_\\eta^2), \\quad A^{(n)} = A_0 \\, e^{s X_n},\n$$\n其中平稳归一化为 $\\sigma_\\eta^2 = 1 - \\phi^2$，使得对于 $|\\phi|  1$，有 $\\operatorname{Var}(X_n) = 1$。乘性测量噪音满足 $\\epsilon \\sim 1 + \\mathcal{N}(0, \\sigma_{\\text{noise}}^2)$，其中 $\\sigma_{\\text{noise}}$ 很小，并且必须强制保证关联函数严格为正。\n\n2) 在 $t_0$ 处的有效质量的非线性估计量：\n$$\nm_{\\text{eff}}(t_0) = \\ln \\left( \\frac{\\langle C_t \\rangle}{\\langle C_{t+1} \\rangle} \\right),\n$$\n其中 $\\langle \\cdot \\rangle$ 表示对所有组态的系综平均。这是数据的非线性函数，因为它涉及比值和对数运算。\n\n3) 分箱和删一分箱刀切法方差估计。将按时间排序的组态划分为 $N_{\\text{bin}}$ 个大小相等、不重叠、连续的箱，每个箱的大小为 $B$。设 $\\widehat{m}_{\\text{eff}}^{(-i)}$ 是从除第 $i$ 个箱之外的所有箱计算得到的有效质量估计量（删一分箱刀切法复制样本）。使用这些复制样本来构建在分箱大小为 $B$ 时 $m_{\\text{eff}}(t_0)$ 的刀切法标准误估计。您必须确保只有当分箱数至少为8个（即 $N_{\\text{bin}} \\ge 8$）时，才使用该分箱大小来产生刀切法误差。\n\n4) 饱和检测准则。考虑一个几何序列的分箱大小 $B \\in \\{ 1, 2, 4, \\dots \\}$，直到能够保证至少有8个箱的最大 $B$ 值。设 $\\sigma(B)$ 表示在分箱大小为 $B$ 时的刀切法标准误。将在两个最大的允许分箱大小 $B_{K-1}$ 和 $B_K$ 处的相对变化定义为\n$$\nr = \\frac{|\\sigma(B_K) - \\sigma(B_{K-1})|}{\\max(\\sigma(B_K), \\varepsilon)},\n$$\n其中 $\\varepsilon$ 是一个小的正则化项以避免除以零。如果对于指定的容差 $\\delta$ 有 $r  \\delta$，则声明误差已饱和。\n\n您的程序必须生成合成数据，应用分箱加刀切法流程，并对以下每个测试用例评估饱和准则。在所有情况下，使用相同的指数质量和噪音参数，仅改变序列长度和 AR(1) 系数：\n\n- 测试用例 1（理想情况，中等自相关）：seed = 12345，$N = 4096$，$\\phi = 0.8$，$A_0 = 1.0$，$s = 0.2$，$m = 0.5$，$t_0 = 5$，$\\sigma_{\\text{noise}} = 0.02$，检测容差 $\\delta = 0.07$。\n- 测试用例 2（几乎不相关）：seed = 54321，$N = 4096$，$\\phi = 0.0$，$A_0 = 1.0$，$s = 0.2$，$m = 0.5$，$t_0 = 5$，$\\sigma_{\\text{noise}} = 0.02$，检测容差 $\\delta = 0.07$。\n- 测试用例 3（强自相关，在可用分箱内不饱和）：seed = 999，$N = 1024$，$\\phi = 0.995$，$A_0 = 1.0$，$s = 0.2$，$m = 0.5$，$t_0 = 5$，$\\sigma_{\\text{noise}} = 0.02$，检测容差 $\\delta = 0.07$。\n- 测试用例 4（边界条件，样本较少但分箱足够）：seed = 2024，$N = 256$，$\\phi = 0.9$，$A_0 = 1.0$，$s = 0.2$，$m = 0.5$，$t_0 = 5$，$\\sigma_{\\text{noise}} = 0.02$，检测容差 $\\delta = 0.07$。\n\n您的程序必须：\n\n- 对于每个测试用例，使用指定的种子，完全按照上述描述模拟数据。\n- 枚举分箱大小 $B \\in \\{ 1, 2, 4, \\dots \\}$，使得完整的箱数 $N_{\\text{bin}} = \\lfloor N / B \\rfloor$ 满足 $N_{\\text{bin}} \\ge 8$。丢弃末尾不足以填满一个完整箱的任何剩余组态。\n- 对每个允许的 $B$ 计算刀切法标准误 $\\sigma(B)$。\n- 根据上述带有容差 $\\delta$ 的准则，使用 $\\varepsilon = 10^{-16}$，判断在最大分箱大小时误差是否已经饱和。\n- 作为唯一的输出，生成一行包含四个测试用例（按顺序 [1,2,3,4]）的布尔值列表，如果检测到饱和，则布尔值为 $true$，否则为 $false$。使用确切的字符串表示 $True$ 和 $False$。\n\n最终输出不涉及物理单位，它们必须是无单位的布尔值。不出现角度。不出现百分比。您的程序应生成单行输出，其中包含一个用方括号括起来的、逗号分隔的结果列表（例如，$[result_1,result_2,result_3,result_4]$）。", "solution": "我们通过将马尔可夫链蒙特卡洛的统计物理学与一个用于格点量子色动力学中相关非线性可观测量分箱和刀切法估计的具体算法构造相结合来展开。\n\n首先，我们确定基本的统计学基础。在马尔可夫链蒙特卡洛中，顺序测量值 $\\{\\mathcal{O}_n\\}_{n=1}^N$ 通常具有非零的自相关，这由自协方差 $C_{\\mathcal{O}}(k) = \\mathbb{E}\\left[(\\mathcal{O}_n - \\mu)(\\mathcal{O}_{n+k} - \\mu)\\right]$ 来描述。归一化自相关函数为 $\\rho_{\\mathcal{O}}(k) = C_{\\mathcal{O}}(k)/C_{\\mathcal{O}}(0)$。积分自相关时间，\n$$\n\\tau_{\\text{int}} = \\frac{1}{2} + \\sum_{k=1}^{\\infty} \\rho_{\\mathcal{O}}(k),\n$$\n决定了样本均值的方差膨胀，这是一个经过充分检验的事实：对于大的 $N$，\n$$\n\\operatorname{Var}(\\bar{\\mathcal{O}}) \\approx \\frac{\\sigma^2_{\\mathcal{O}}}{N} \\, 2 \\, \\tau_{\\text{int}}.\n$$\n这表明，相关性有效地将独立样本的数量减少了大约一个因子 $2 \\tau_{\\text{int}}$。\n\n其次，我们实施分箱以减少相关性。将相邻样本分组到大小为 $B$ 的不重叠箱中，形成 $N_{\\text{bin}} = \\lfloor N/B \\rfloor$ 个箱均值。如果 $B \\gg \\tau_{\\text{int}}$，箱均值近似为独立同分布。因此，从箱均值计算的估计量的误差将不再随 $B$ 的进一步增加而发生显著变化。估计误差作为 $B$ 的函数出现的这种平台期或饱和现象，是一个经验性指标，表明 $B$ 超过了相关尺度，从而产生了去相关的有效样本。\n\n第三，我们定义非线性估计量，即在固定欧几里得时间 $t_0$ 处的有效质量：\n$$\nm_{\\text{eff}}(t_0) = \\ln \\left( \\frac{\\langle C_t \\rangle}{\\langle C_{t+1} \\rangle} \\right),\n$$\n其中 $C_t$ 和 $C_{t+1}$ 分别表示在时间 $t_0$ 和 $t_0 + 1$ 的关联函数测量值，而 $\\langle \\cdot \\rangle$ 是系综平均。由于涉及比值和对数，该估计量是数据的非线性函数，因此需要使用尊重非线性的重采样技术来稳健地估计其不确定性。\n\n为了通过这个非线性估计量传播误差，我们采用删一分箱刀切法。设顺序测量值被划分为 $N_{\\text{bin}}$ 个大小为 $B$ 的连续、不重叠的箱。对于每个箱 $i \\in \\{1,\\dots,N_{\\text{bin}}\\}$，计算留一法估计量 $\\widehat{m}_{\\text{eff}}^{(-i)}$，其定义为从除第 $i$ 个箱之外的所有组态计算得到的 $m_{\\text{eff}}(t_0)$ 的值。然后，从这些复制样本围绕其均值的涨落中构造出 $m_{\\text{eff}}$ 方差的刀切法估计。已知删一分箱刀切法能为均值的光滑非线性泛函提供一致的方差估计。在实践中，我们为每个分箱大小 $B$ 计算刀切法标准误 $\\sigma(B)$。对于小的 $B$，箱之间的残余自相关使得 $\\sigma(B)$ 的膨胀小于其渐近值；随着 $B$ 增加以至于 $B \\gtrsim \\tau_{\\text{int}}$，$\\sigma(B)$ 会增加并饱和到一个平台值，该平台值对应于考虑了相关性之后的真实误差。如果由于 $N$ 有限而导致 $B$ 永远无法达到 $\\tau_{\\text{int}}$，则可能观察不到饱和现象。\n\n为了将此推理与受控环境联系起来，我们生成合成数据。我们通过一阶自回归过程 $X_n = \\phi X_{n-1} + \\eta_n$（其中 $\\eta_n \\sim \\mathcal{N}(0, \\sigma_\\eta^2)$ 且 $\\sigma_\\eta^2 = 1 - \\phi^2$ 以使平稳方差为 $\\operatorname{Var}(X_n) = 1$）来模拟振幅涨落。振幅为 $A^{(n)} = A_0 e^{s X_n}$，确保了正性。在时间 $t_0$ 和 $t_0 + 1$ 测得的关联函数则为\n$$\nC_t^{(n)} = A^{(n)} e^{-m t_0} \\, \\epsilon_t^{(n)}, \\qquad C_{t+1}^{(n)} = A^{(n)} e^{-m (t_0 + 1)} \\, \\epsilon_{t+1}^{(n)},\n$$\n带有乘性噪音 $\\epsilon \\sim 1 + \\mathcal{N}(0, \\sigma_{\\text{noise}}^2)$。我们通过在一个微小的正数下限处进行裁剪来约束数据为严格正值，考虑到 $\\sigma_{\\text{noise}}$ 很小，这是一个可忽略的修正。\n\n算法设计：\n\n- 对每个测试用例，在固定的随机种子下，模拟 $N$ 个 $X_n$ 样本并由此得到 $A^{(n)}$，然后生成 $C_t^{(n)}$ 和 $C_{t+1}^{(n)}$。\n- 考虑分箱大小 $B \\in \\{ 1, 2, 4, \\dots \\}$，使得 $N_{\\text{bin}} = \\lfloor N / B \\rfloor \\ge 8$。对于每个这样的 $B$，计算通过移除第 $i$ 个箱后对 $C_t$ 和 $C_{t+1}$ 的系综平均所构造的 $m_{\\text{eff}}(t_0)$ 的删一分箱刀切法标准误 $\\sigma(B)$。\n- 将两个最大允许分箱大小 $B_{K-1}$ 和 $B_K$ 处的误差相对变化定义为 $r = \\frac{|\\sigma(B_K) - \\sigma(B_{K-1})|}{\\max(\\sigma(B_K), \\varepsilon)}$，其中 $\\varepsilon = 10^{-16}$，如果对于指定的 $\\delta$ 有 $r  \\delta$，则声明饱和。\n- 基于基本原理的预期结果是：\n  - 对于中等或弱自相关，$\\sigma(B)$ 将从 $B=1$ 开始增加，并在最大 $B$ 值附近达到平台期，因此应能检测到饱和。\n  - 对于几乎不相关的数据，$\\sigma(B)$ 从 $B=1$ 开始几乎是恒定的，因此饱和准则仍然成立，因为相对变化很小。\n  - 对于非常强的自相关和有限的 $N$，$B$ 可能永远无法达到 $\\tau_{\\text{int}}$ 的尺度，因此 $\\sigma(B)$ 可能在最大允许 $B$ 值时仍未达到平台期，所以不应检测到饱和。\n\n我们现在将此流程应用于指定的测试套件：\n\n- 测试用例 1：seed = 12345，$N = 4096$，$\\phi = 0.8$，$A_0 = 1.0$，$s = 0.2$，$m = 0.5$，$t_0 = 5$，$\\sigma_{\\text{noise}} = 0.02$，$\\delta = 0.07$。此处 $\\phi = 0.8$ 对应于一个中等的积分自相关时间 $\\tau_{\\text{int}} \\approx \\frac{1+\\phi}{2(1-\\phi)} = \\frac{1.8}{0.4} = 4.5$。由于分箱大小可达 $B = 512$，预期会发生饱和，因此结果为 $True$。\n- 测试用例 2：seed = 54321，$N = 4096$，$\\phi = 0.0$ 产生 $\\tau_{\\text{int}} \\approx 0.5$；刀切法误差在不同 $B$ 值上几乎恒定，满足饱和准则，结果为 $True$。\n- 测试用例 3：seed = 999，$N = 1024$，$\\phi = 0.995$ 给出 $\\tau_{\\text{int}} \\approx \\frac{1+0.995}{2(1-0.995)} \\approx \\frac{1.995}{0.01} \\approx 199.5$。最大允许的分箱大小为 $B = 128$（此时 $N_{\\text{bin}} = 8$），这小于 $\\tau_{\\text{int}}$。因此，不太可能饱和，结果应为 $False$。\n- 测试用例 4：seed = 2024，$N = 256$，$\\phi = 0.9$ 给出 $\\tau_{\\text{int}} \\approx \\frac{1+0.9}{2(1-0.9)} = \\frac{1.9}{0.2} = 9.5$。最大允许的分箱大小为 $B = 32$（此时 $N_{\\text{bin}} = 8$），这超过了 $\\tau_{\\text{int}}$，因此应该能观察到饱和，结果为 $True$。\n\n程序按顺序收集四个布尔值，并打印单行 $[b_1,b_2,b_3,b_4]$，其中 $b_i \\in \\{\\text{True}, \\text{False}\\}$。这表明，随着分箱大小增加，刀切法误差的饱和现象是去相关的一个经验性诊断方法：当 $B$ 远大于自相关尺度时，箱均值实际上是独立的，刀切法误差趋于稳定；而如果 $B$ 相对于相关长度仍然太小，估计的误差会继续变化，因而检测不到饱和。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef ar1_series(N: int, phi: float, rng: np.random.Generator) -> np.ndarray:\n    \"\"\"\n    Generate an AR(1) series X_n = phi * X_{n-1} + eta_n with stationary Var(X)=1.\n    eta_n ~ N(0, 1 - phi^2). Start from stationary distribution.\n    \"\"\"\n    sigma_eta = np.sqrt(max(0.0, 1.0 - phi * phi))\n    X = np.empty(N)\n    # Start at stationary distribution\n    X[0] = rng.normal(0.0, 1.0)\n    for n in range(1, N):\n        X[n] = phi * X[n - 1] + rng.normal(0.0, sigma_eta)\n    return X\n\ndef simulate_correlators(seed: int, N: int, phi: float,\n                         A0: float, s_logamp: float,\n                         m: float, t0: int, sigma_noise: float) -> tuple[np.ndarray, np.ndarray]:\n    \"\"\"\n    Simulate C_t and C_{t+1} arrays for a single-state correlator with\n    log-normal amplitude fluctuations following an AR(1) process.\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    X = ar1_series(N, phi, rng)\n    A = A0 * np.exp(s_logamp * X)  # positive amplitudes\n    base_t = np.exp(-m * t0)\n    base_tp1 = np.exp(-m * (t0 + 1))\n    # Multiplicative noise around 1 with small sigma\n    eps_t = 1.0 + sigma_noise * rng.standard_normal(N)\n    eps_tp1 = 1.0 + sigma_noise * rng.standard_normal(N)\n    Ct = A * base_t * eps_t\n    Ctp1 = A * base_tp1 * eps_tp1\n    # Enforce strict positivity\n    Ct = np.clip(Ct, 1e-12, None)\n    Ctp1 = np.clip(Ctp1, 1e-12, None)\n    return Ct, Ctp1\n\ndef jackknife_error_effective_mass(Ct: np.ndarray, Ctp1: np.ndarray, bin_size: int) -> float:\n    \"\"\"\n    Compute the delete-one-bin jackknife standard error for the nonlinear estimator:\n    m_eff = log( mean(Ct) / mean(Ctp1) ), using contiguous non-overlapping bins of size bin_size.\n    Requires at least 2 bins; caller ensures >=8 for robustness.\n    \"\"\"\n    N = len(Ct)\n    n_bins = N // bin_size\n    if n_bins  2:\n        return np.nan\n    keep = n_bins * bin_size\n    Ct_kept = Ct[:keep]\n    Ctp1_kept = Ctp1[:keep]\n    # Reshape into bins\n    Ct_bins = Ct_kept.reshape(n_bins, bin_size)\n    Ctp1_bins = Ctp1_kept.reshape(n_bins, bin_size)\n    # Precompute total sums\n    total_Ct = Ct_kept.sum()\n    total_Ctp1 = Ctp1_kept.sum()\n    total_count = keep\n    # Bin sums\n    bin_sum_Ct = Ct_bins.sum(axis=1)\n    bin_sum_Ctp1 = Ctp1_bins.sum(axis=1)\n    # Jackknife replicates\n    jk_vals = np.empty(n_bins)\n    count_excl = total_count - bin_size\n    for i in range(n_bins):\n        sum_excl_Ct = total_Ct - bin_sum_Ct[i]\n        sum_excl_Ctp1 = total_Ctp1 - bin_sum_Ctp1[i]\n        mean_excl_Ct = sum_excl_Ct / count_excl\n        mean_excl_Ctp1 = sum_excl_Ctp1 / count_excl\n        # Safety: avoid division by zero (should not occur due to positivity)\n        mean_excl_Ct = max(mean_excl_Ct, 1e-300)\n        mean_excl_Ctp1 = max(mean_excl_Ctp1, 1e-300)\n        jk_vals[i] = np.log(mean_excl_Ct / mean_excl_Ctp1)\n    jk_mean = jk_vals.mean()\n    # Standard jackknife variance: (n_bins - 1) * mean((theta_i - mean(theta_i))^2)\n    var_jk = (n_bins - 1) * np.mean((jk_vals - jk_mean) ** 2)\n    return float(np.sqrt(max(var_jk, 0.0)))\n\ndef bin_sizes_geometric(N: int, min_bins: int = 8) -> list[int]:\n    \"\"\"\n    Generate powers-of-two bin sizes B = 1,2,4,... such that floor(N/B) >= min_bins.\n    \"\"\"\n    sizes = []\n    B = 1\n    while N // B >= min_bins:\n        sizes.append(B)\n        B *= 2\n    return sizes\n\ndef detect_saturation(Ct: np.ndarray, Ctp1: np.ndarray, delta_tol: float) -> bool:\n    \"\"\"\n    Compute jackknife errors over admissible bin sizes and detect saturation using\n    the relative change criterion at the two largest bin sizes.\n    \"\"\"\n    N = len(Ct)\n    B_list = bin_sizes_geometric(N, min_bins=8)\n    if len(B_list)  2:\n        return False\n    errors = []\n    for B in B_list:\n        err = jackknife_error_effective_mass(Ct, Ctp1, B)\n        errors.append(err)\n    # Relative change at the end\n    eps = 1e-16\n    rel = abs(errors[-1] - errors[-2]) / max(errors[-1], eps)\n    return rel  delta_tol\n\ndef run_case(seed: int, N: int, phi: float,\n             A0: float, s: float,\n             m: float, t0: int, sigma_noise: float,\n             delta_tol: float) -> bool:\n    Ct, Ctp1 = simulate_correlators(seed, N, phi, A0, s, m, t0, sigma_noise)\n    return detect_saturation(Ct, Ctp1, delta_tol)\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (seed, N, phi, A0, s, m, t0, sigma_noise, delta_tol)\n    test_cases = [\n        (12345, 4096, 0.8,   1.0, 0.2, 0.5, 5, 0.02, 0.07),   # Case 1: moderate autocorrelation\n        (54321, 4096, 0.0,   1.0, 0.2, 0.5, 5, 0.02, 0.07),   # Case 2: nearly uncorrelated\n        (999,   1024, 0.995, 1.0, 0.2, 0.5, 5, 0.02, 0.07),   # Case 3: strong autocorr, no saturation\n        (2024,   256, 0.9,   1.0, 0.2, 0.5, 5, 0.02, 0.07),   # Case 4: boundary, should saturate\n    ]\n\n    results = []\n    for case in test_cases:\n        seed, N, phi, A0, s, m, t0, sigma_noise, delta_tol = case\n        res = run_case(seed, N, phi, A0, s, m, t0, sigma_noise, delta_tol)\n        results.append(res)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3571154"}]}