## 引言
[离散事件模拟](@entry_id:637852)（Discrete-Event Simulation, DES）是运筹学、计算机科学和工程领域中用于分析复杂随机动态系统的核心方法论。从制造车间的生产流程、计算机网络的通信协议，到金融市场的交易行为，许多现实世界系统的行为都由一系列在离散时间点发生的事件所驱动。由于这些系统内部交互的复杂性和固有的随机性，传统的解析方法往往难以提供精确的性能评估与深刻的洞察。[离散事件模拟](@entry_id:637852)填补了这一知识空白，它通过在计算机上构建一个反映真实系统逻辑与随机性的动态模型，使我们能够进行“假设”分析、优化设计和预测行为。

然而，要构建一个有效且可信的模拟模型，仅仅理解其应用场景是远远不够的。研究人员和工程师必须掌握其背后的严谨原理与机制。本文旨在系统性地剖析[离散事件模拟](@entry_id:637852)的理论基础与实践方法。我们将从最基本的构成要素出发，逐步深入到模拟引擎的内部工作原理，再到如何科学地处理模拟的输入与输出，最终确保模拟结果的可靠性。

为实现这一目标，本文将分为三个核心章节。第一章“原理与机制”将奠定理论基石，深入剖析构成离散事件系统的核心要素、独特的càdlàg状态演化路径、驱动模拟运行的时间推进机制，以及保证模拟结果统计有效性的关键方法。第二章“应用与跨学科联系”将通过一系列来自工程、计算机系统、[运筹学](@entry_id:145535)及新兴领域的丰富案例，展示这些基础原理如何被灵活运用于解决实际问题，彰显其强大的跨学科连接能力。最后，第三章“动手实践”将提供精心设计的编程练习，引导您将理论知识转化为实际的编程技能，从生成[随机变量](@entry_id:195330)到构建一个完整的队列模拟器。通过这一结构化的学习路径，读者将能够构建起一个关于[离散事件模拟](@entry_id:637852)的全面而深入的知识体系。

## 原理与机制

本章将深入探讨[离散事件模拟](@entry_id:637852)（Discrete-Event Simulation, DES）的核心原理与运行机制。继引言部分对 DES 的背景与应用进行初步介绍后，我们将系统地剖析构成一个 DES 模型的 foundational components，阐明其独特的系统状态演化方式，并详细解释驱动模拟运行的时间推进与事件调度机制。此外，我们还将覆盖输入建模、输出分析以及保证模型可信度的关键方法学，为读者构建一个完整而严谨的 DES 知识框架。

### 离散事件系统的剖析

从根本上说，离散事件系统是一个状态仅在离散时间点上发生瞬时变化的系统。为了精确地描述和模拟这类系统，我们需要一个形式化的框架，该框架由几个关键要素组成：状态、实体、资源和事件。

**系统的核心要素**

- **状态 (State)**：系统状态由一组**状态变量**完整描述，这些变量的集合必须足以在任何时刻 $t$ 捕捉系统所有必要的信息，以决定其未来的演化。例如，在一个生产单元的模拟中，[状态变量](@entry_id:138790)可能包括每台机器前排队等待的工件数量、每台机器的运行状态（如空闲、繁忙、故障或维修中）等 [@problem_id:3303613]。

- **实体 (Entities)**：实体是流经系统、请求服务的动态对象。在我们的生产单元示例中，不同类别的**工件**就是实体。它们到达系统，占用资源，并在完成服务后离开。

- **资源 (Resources)**：资源是为实体提供服务的静态对象。在上述例子中，**机器**就是资源。资源通常具有有限的能力（例如，一台机器一次只能处理一个工件）。系统中的**缓冲区**（队列）也可被视为管理实体访问资源的设施的一部分。

- **事件 (Events)**：事件是导致系统状态发生改变的瞬时发生。事件是驱动整个模拟过程的动力。在一个包含机器故障的生产系统中，关键事件类型包括：新工件的到达、某台机器上服务完成、机器发生故障以及机器完成修复等 [@problem_id:3303613]。

**离散事件系统的样本路径语义**

离散事件系统的状态演化在时间上具有独特的数学特性。令 $X(t)$ 为描述系统状态的向量。由于状态仅在事件发生的时刻 $T_1, T_2, \dots$ 发生变化，而在两个相继事件之间保持恒定，因此[状态变量](@entry_id:138790) $X(t)$ 作为时间的函数是一个**分段常数函数**。

这种样本路径在数学上被称为 **càdlàg** 路径（法語 *continue à droite, limites à gauche* 的缩写），意为“右连续有[左极限](@entry_id:139055)”。这意味着在任何时间点 $t$，状态值 $X(t)$ 等于其右侧的极限，并且其[左极限](@entry_id:139055)存在（在事件点上，[左极限](@entry_id:139055)表示事件发生前的状态，而 $X(t)$ 本身表示事件发生后的状态）。

这一特性与许多物理和金融学中由[随机微分方程](@entry_id:146618)（Stochastic Differential Equations, SDEs）描述的[连续时间过程](@entry_id:274437)形成鲜明对比。例如，一个由[伊藤随机微分方程](@entry_id:637785) $dY(t)=a(Y(t))dt + b(Y(t))dW(t)$ 驱动的系统，其样本路径 $t \mapsto Y(t)$ [几乎必然](@entry_id:262518)是**连续**的（但处处不可微）。模拟 SDE 通常需要采用**时间驱动**的[数值积分方法](@entry_id:141406)（如[欧拉-丸山法](@entry_id:142440)），这会引入与时间步长相关的[离散化误差](@entry_id:748522)。相比之下，[离散事件模拟](@entry_id:637852)采用**事件驱动**的方法，时钟直接“跳跃”到下一个事件发生的时间，状态更新仅在这些精确的时刻进行。因此，在给定随机输入（如事件间隔时间）可以精确生成的前提下，DES 在状态演化上不产生[数值积分误差](@entry_id:137490) [@problem_id:3303613]。

### 模拟引擎：时间推进与事件管理

[离散事件模拟](@entry_id:637852)器的核心是一个“引擎”，它负责管理模拟时钟和按时间顺序处理事件。这个引擎的效率和正确性直接决定了模拟的性能和有效性。

**时间推进机制**

模拟器如何推进时间是其设计的核心决策之一。主要有两种机制：

1.  **[下一事件时间推进](@entry_id:752481) (Next-Event Time Advance, NETA)**：这是 DES 最常用的机制。模拟时钟 $t$ 不会平滑地流逝，而是直接跳跃到下一个最近的预定事件的发生时间。假设未来的事件安排在一个列表中，时钟将更新为 $t \leftarrow \min\{T_k\}$，其中 $\{T_k\}$ 是所有未来事件的时间戳集合。然后，所有时间戳等于新时钟值 $t$ 的事件都将被处理。这种方法完美地保持了路径的时间保真度，因为状态恰好在事件发生的精确时刻更新 [@problem_id:3303641]。

2.  **固定增量时间推进 (Fixed-Increment Time Advance, FITA)**：在这种机制下，时钟以一个固定的步长 $h > 0$ 前进，即 $t \leftarrow t + h$。在每个时间步结束时，模拟器会处理所有调度时间落在区间 $(t-h, t]$ 内的事件。这种方法会引入时间上的误差，一个发生在 $T_{event}$ 时刻的事件会被记录为在 $t$ 时刻发生，其最大误差可达 $h$。FITA 的主要优点是实现简单，但在事件稀疏的系统中效率低下，因为它必须在许多没有事件发生的“空”时间步上消耗计算资源。相比之下，NETA 的计算开销主要取决于事件的总数，而非模拟的总时长，因此在事件稀疏时通常更高效 [@problem_id:3303641]。

**[未来事件列表](@entry_id:749677) (Future Event List, FEL)**

在 NETA 机制中，模拟器必须高效地维护一组待处理的未来事件，并能快速地找出其中时间戳最小的事件。这个功能由一个名为**[未来事件列表](@entry_id:749677) (Future Event List, FEL)** 的[数据结构](@entry_id:262134)实现。FEL 本质上是一个以事件时间为优先级的**[优先队列](@entry_id:263183) (priority queue)** [@problem_id:3303629]。

实现 FEL 的[数据结构](@entry_id:262134)选择对模拟器的性能至关重要。设 $n$ 是任何时刻 FEL 中的事件数，常见的数据结构及其平均情况时间复杂度如下：

- **[二叉堆](@entry_id:636601) (Binary Heap)**：插入 (insert) 和删除最小值 (delete-min) 操作的复杂度均为 $O(\log n)$。查看最小值 (peek-min) 的复杂度是 $O(1)$。[二叉堆](@entry_id:636601)是一种稳健且广泛应用的选择。

- **日历队列 (Calendar Queue)**：这是一种基于哈希的[优先队列](@entry_id:263183)。在事件时间戳[分布](@entry_id:182848)相对平稳的理想情况下，通过动态调整“桶”的宽度，可以使得插入、删除最小值和查看最小值的**[期望时间复杂度](@entry_id:634638)都达到 $O(1)$**。这使得它在某些大规模模拟中极具吸[引力](@entry_id:175476)，但其性能对事件[分布](@entry_id:182848)的规律性较为敏感。

- **[伸展树](@entry_id:636608) (Splay Tree)**：这是一种自适应的[二叉搜索树](@entry_id:635006)。插入、删除最小值和查看最小值的**均摊时间复杂度均为 $O(\log n)$**。

选择哪种数据结构取决于具体的模拟应用场景、事件数量的规模以及事件时间戳的统计特性 [@problem_id:3303629]。

**因果关系与并发事件处理**

一个严谨的模拟器必须保证**因果关系 (causality)**：任何事件的影响都不能在其原因发生之前被观察到。NETA 通过按时间戳的非递减顺序处理事件来自然地维护因果关系。然而，当多个事件具有完全相同的时间戳时，即发生**并发事件 (simultaneous events)**，问题就变得复杂起来。

如果不对这些并发事件的执行顺序做出规定，模拟结果可能会依赖于[内存布局](@entry_id:635809)或[线程调度](@entry_id:755948)等不确定性因素，从而导致模拟结果不可复现。因此，一个确定性的 DES 必须包含一个明确的**决断规则 (tie-breaking rule)** 来处理并发事件 [@problem_id:3303641]。

在更复杂的模型中，一个事件的发生可能在零延迟（即同一时刻）内触发另一个事件。例如，一个信号处理模块可能在接收到一个信号的瞬间就产生一个输出信号。为了在同一物理时间 $t$ 内正确地对这种因果链进行排序，可以引入**微步 (microstep)** 的概念。每个事件可以携带一个微步计数器 $\delta$。当一个在 $(t, \delta)$ 发生的事件调度了一个新的、同样在时间 $t$ 发生的事件时，新事件将被赋予微步 $\delta+1$。模拟器则按照 $(t, \delta, p, \dots)$ 的[字典序](@entry_id:143032)来处理事件，其中 $p$ 是可选的静态优先级。这种机制确保了在同一物理时刻内的因果链得以正确展开，保证了模拟的确定性和因果一致性 [@problem_id:3303655]。

### 建模系统输入：[到达过程](@entry_id:263434)与[随机变量生成](@entry_id:756434)

一个[随机模拟](@entry_id:168869)的“随机性”来源于其输入模型，例如工件的[到达间隔时间](@entry_id:271977)、服务时间等。对这些输入进行准确的建模和高效的生成是模拟研究成功的关键。

**[到达过程](@entry_id:263434)模型**

[到达过程](@entry_id:263434)描述了事件（如顾客、工件、数据包）随时间到来的模式。以下是三种基础且重要的模型：

1.  **[齐次泊松过程](@entry_id:263782) (Homogeneous Poisson Process, HPP)**：HPP 由一个常数率 $\lambda$ 定义。它的两个等价定义是：(a) 事件间的间隔时间是独立的、服从参数为 $\lambda$ 的指数分布的[随机变量](@entry_id:195330)；(b) 这是一个具有**[平稳独立增量](@entry_id:635556)**的[计数过程](@entry_id:260664)。平稳性意味着在任何长度为 $T$ 的时间区间内，事件发生的数量[分布](@entry_id:182848)都相同（服从均值为 $\lambda T$ 的泊松分布）。[独立增量](@entry_id:262163)意味着在不相交的时间区间内，事件发生的数量是[相互独立](@entry_id:273670)的。HPP 的一个关键特性是**无记忆性**，其恒定的风险率（hazard rate）意味着下一个事件的到来与已经等待了多久无关。这使其成为对那些到达率稳定且不受历史影响的现象的良好首选模型 [@problem_id:3303672]。

2.  **非[齐次泊松过程](@entry_id:263782) (Nonhomogeneous Poisson Process, NHPP)**：NHPP 由一个随时间变化的确定性[强度函数](@entry_id:755508) $\lambda(t)$ 描述。它仍然具有**[独立增量](@entry_id:262163)**的特性，但在不相交区间上的增量不再是平稳的。在区间 $[s, t]$ 内的事件数量服从泊松分布，其均值为 $\int_s^t \lambda(u) du$。NHPP 非常适合模拟那些具有可预测的周期性变化（如“高峰时段”）的[到达过程](@entry_id:263434) [@problem_id:3303672]。

3.  **[更新过程](@entry_id:273573) (Renewal Process)**：更新过程是一类更广泛的[计数过程](@entry_id:260664)，其事件间隔时间是[独立同分布](@entry_id:169067)（i.i.d.）的[随机变量](@entry_id:195330)，但不要求它们必须服从指数分布。除非间隔时间是指数分布（此时即为 HPP），否则[更新过程](@entry_id:273573)**不具有[独立增量](@entry_id:262163)或[平稳增量](@entry_id:263290)**。它的未来演化不仅依赖于当前状态，还依赖于自上一个事件发生以来所经过的时间（即过程的“年龄”）。一个重要的推论是，对于非泊松的更新过程，**PASTA**（Poisson Arrivals See Time Averages）属性通常不成立。这意味着到达者所观察到的系统状态的[分布](@entry_id:182848)，与系统在任意时刻的状态[分布](@entry_id:182848)不一定相同，这会导致“到达诱导的[抽样偏差](@entry_id:193615)”[@problem_id:3303672]。

**[随机变量生成](@entry_id:756434)方法**

所有[随机变量生成](@entry_id:756434)技术都始于一个能产生标准[均匀分布](@entry_id:194597) $U \sim \text{Uniform}(0,1)$ 随机数的生成器。

1.  **[逆变换法](@entry_id:141695) (Inverse Transform Method)**：这是最基本也是最通用的方法。对于一个给定的[累积分布函数 (CDF)](@entry_id:264700) $F_X(x)$，我们可以通过计算 $X = F_X^{-1}(U)$ 来生成一个服从该[分布](@entry_id:182848)的[随机变量](@entry_id:195330) $X$。这里的 $F_X^{-1}(u) = \inf\{x: F_X(x) \ge u\}$ 是[广义逆](@entry_id:140762)函数。该方法的美妙之处在于其普适性，它对[连续分布](@entry_id:264735)和[离散分布](@entry_id:193344)都有效。对于[离散分布](@entry_id:193344)，CDF 是一个阶梯函数，[广义逆](@entry_id:140762)变换可以正确地将均匀随机数映射到相应的值上 [@problem_id:3303677]。

2.  **复合法人 (Composition Method)**：当目标分布是一个[混合分布](@entry_id:276506)时，即其 CDF 可以写成 $F_X(x) = \sum_i \pi_i F_i(x)$（其中 $\sum \pi_i = 1$），复合法人非常有效。生成一个样本的步骤是：首先，根据概率 $\{\pi_i\}$ 随机选择一个分量 $I$；然后，从对应的分量[分布](@entry_id:182848) $F_I(x)$ 中生成一个样本。该方法也适用于分段定义的概率密度函数，只需将每一段归一化为一个合法的[概率分布](@entry_id:146404)，并以其对应的概率质量来选择段落即可 [@problem_id:3303677]。

3.  **[接受-拒绝法](@entry_id:263903) (Acceptance-Rejection Method)**：当[目标分布](@entry_id:634522)的[概率密度](@entry_id:175496)/[质量函数](@entry_id:158970) $f(x)$ 形式复杂，难以通过[逆变换法](@entry_id:141695)采样时，此方法非常有用。它需要一个易于采样的“[提议分布](@entry_id:144814)” $g(x)$ 和一个常数 $c$，使得 $f(x) \le c \cdot g(x)$ 对所有 $x$ 成立。算法步骤是：从 $g(x)$ 生成一个候选样本 $Y$，再生成一个均匀随机数 $U$；如果 $U \le \frac{f(Y)}{c \cdot g(Y)}$，则接受 $Y$ 作为来自 $f(x)$ 的样本，否则拒绝并重复此过程。该方法生成的样本是精确的、无偏的。其效率取决于常数 $c$（平均需要 $c$ 次尝试才能接受一个样本），因此找到一个紧凑的[包络函数](@entry_id:749028) $c \cdot g(x)$ 至关重要 [@problem_id:3303677]。

### 分析模拟输出：从原始数据到可信洞见

运行模拟只是第一步，如何从充满随机性的输出数据中提取有意义的、统计上可靠的结论，是 DES 方法论的另一个核心。

**初始偏差与[预热](@entry_id:159073)期**

在许多模拟中，我们关心的是系统达到[统计平衡](@entry_id:186577)后的**[稳态](@entry_id:182458) (steady-state)** 行为。然而，模拟通常从一个特定的、非典型的状态（如空系统）开始。从这个初始状态演化到[稳态](@entry_id:182458)的阶段被称为**瞬态 (transient phase)**。如果直接使用整个模拟过程的数据来估计[稳态](@entry_id:182458)性能指标，那么早期瞬态数据会使估计产生系统性偏差，这被称为**初始偏差 (initialization bias)**。

为了减轻这种偏差，一种标准做法是设定一个**[预热](@entry_id:159073)期 (warm-up period)**，即在模拟开始后删除一段时间 $[0, \tau]$ 的数据，只使用 $\tau$ 之后的数据进行统计分析。确定合适的预热期长度 $\tau$ 本身是一个复杂的统计问题，但其基本原理是：对于一个遍历的（ergodic）[随机过程](@entry_id:159502)，当 $t \to \infty$ 时，其瞬态均值 $E[g(X(t))]$ 会收敛到[稳态](@entry_id:182458)均值 $\alpha$。因此，丢弃早期数据可以有效减少[估计量的偏差](@entry_id:168594) [@problem_id:3303697]。值得注意的是，如果能够直接从系统的[稳态分布](@entry_id:149079) $\pi$ 中抽取初始状态 $X(0)$，那么整个过程就是平稳的，理论上不存在初始偏差，也就不需要预热期来消除偏差 [@problem_id:3303697]。

**[稳态](@entry_id:182458)性能估计**

DES 的输出序列通常是自相关的，这意味着不能直接使用[经典统计学](@entry_id:150683)中适用于独立同分布（i.i.d.）样本的公式来计算[置信区间](@entry_id:142297)。为了正确估计[稳态](@entry_id:182458)均值的[方差](@entry_id:200758)，主要有以下几种方法：

1.  **独立重复法 (Independent Replications)**：此方法通过使用不同的随机数种子，独立地运行 $R$ 次模拟。每次运行都包含一个预热期。这样可以得到 $R$ 个独立的[稳态](@entry_id:182458)性能估计值 $Z_1, \dots, Z_R$。由于这些 $Z_r$ 是 i.i.d. 的，我们可以直接应用[中心极限定理](@entry_id:143108)，使用样本均值和样本[方差](@entry_id:200758)来构建置信区间。这种方法概念简单、统计上稳健，且易于并行化，但缺点是每次重复都需要“浪费”一个预热期 [@problem_id:3303627]。

2.  **[批均值法](@entry_id:746698) (Batch Means)**：此方法旨在通过一次长运行来提高数据利用率。在丢弃一个初始预热期后，将剩余的长输出序列分割成 $m$ 个连续的、不重叠的**批次 (batches)**。计算每个批次的均值 $\bar{Y}_j$。其核心思想是，如果批次大小 $b$ 足够大，那么不同批次的均值之间的相关性将变得可以忽略不计，从而可以近似地将这 $m$ 个[批均值](@entry_id:746697)视为 i.i.d. 样本来构建[置信区间](@entry_id:142297)。**重叠[批均值](@entry_id:746697) (Overlapping Batch Means, OBM)** 是该方法的一个变种，它使用所有可能的长度为 $b$ 的连续数据窗口来形成批次。虽然这些重叠的[批均值](@entry_id:746697)是高度相关的，但理论证明其样本[方差](@entry_id:200758)经过适当调整后，仍然是[方差](@entry_id:200758)的[相合估计量](@entry_id:266642)，并且通常比非重叠[批均值法](@entry_id:746698)具有更低的[均方误差](@entry_id:175403) [@problem_id:3303627]。

**提高估计效率：[方差缩减技术](@entry_id:141433)**

为了以更少的计算成本获得更高精度的估计，研究者们开发了多种[方差缩减技术](@entry_id:141433) (Variance Reduction Techniques, VRTs)。

- **[公共随机数](@entry_id:636576) (Common Random Numbers, CRN)**：在比较两个或多个系统配置时，CRN 是一种极其强大的技术。它通过对不同系统配置使用完全相同的随机数流，来诱导不同系统输出之间的正相关性。当估计两个系统性能之差时，$\text{Var}(X_1 - X_2) = \text{Var}(X_1) + \text{Var}(X_2) - 2\text{Cov}(X_1, X_2)$。正相关性使得协[方差](@entry_id:200758)项为正，从而减小了差值[估计量的方差](@entry_id:167223)。这使得我们能更清晰地辨别出[系统设计](@entry_id:755777)差异带来的真实影响，而不是将其淹没在随机噪声中 [@problem_id:3303643]。

- **对偶变量 (Antithetic Variates, AV)**：此技术用于提高单个系统性能的估计精度。它利用了这样一个事实：如果 $U$ 是一个 $U(0,1)$ [随机变量](@entry_id:195330)，那么 $1-U$ 也是。AV 的做法是成对地进行模拟：一次使用随机数流 $\mathbf{U} = (U_1, U_2, \dots)$，另一次使用其对偶流 $1-\mathbf{U} = (1-U_1, 1-U_2, \dots)$。如果系统输出对其输入是单调的，那么这两次运行的输出 $X_1$ 和 $X_2$ 倾向于负相关。此时，配对均值 $(X_1+X_2)/2$ 的[方差](@entry_id:200758)将小于两个独立运行均值的[方差](@entry_id:200758)。然而，如果输出函数是高度非单调的，AV 可能会诱导出正相关，反而增大[方差](@entry_id:200758) [@problem_id:3303643]。

- **[控制变量](@entry_id:137239) (Control Variates, CV)**：此方法利用了模拟输出中我们希望估计的变量 $X$ 与另一个变量 $Y$ （[控制变量](@entry_id:137239)）之间的相关性，而 $Y$ 的期望 $\mu_Y$ 是已知的。新的估计量是 $X_c(b) = X - b(Y - \mu_Y)$。这个估计量是无偏的，其[方差](@entry_id:200758)为 $\text{Var}(X)(1-\rho_{XY}^2)$（当 $b$ 取最优值时），其中 $\rho_{XY}$ 是 $X$ 和 $Y$ 的相关系数。相关性越强（$|\rho_{XY}|$ 越接近1），[方差缩减](@entry_id:145496)的效果越显著 [@problem_id:3303643]。

### 确保模拟可信度：[验证与确认](@entry_id:173817)

一个模拟研究的最终价值取决于其结果的可信度。**[验证与确认](@entry_id:173817) (Verification and Validation, V)** 是确保这种可信度的系统性过程。

- **验证 (Verification)**：关注的是“正确地构建模型”，即确保计算机程序（已实现的模型）忠实地实现了概念模型的所有逻辑和规范。这是一个内部检查过程，旨在发现并修正代码中的错误。验证活动包括代码审查、单元测试（如测试 FEL 操作的正确性）、以及通过与已知解析解（如 M/M/1 [排队模型](@entry_id:275297)的[稳态](@entry_id:182458)结果）进行比较来进行基准测试 [@problem_id:3303630]。

- **确认 (Validation)**：关注的是“构建正确的模型”，即判断概念模型在多大程度上是对真实系统的一个准确的、适用于特定研究目的的表示。这是一个外部检查过程，需要将模型输出与真实世界的数据进行比较。确认活动包括与领域专家讨论模型的假设、使用统计检验（如[拟合优度检验](@entry_id:267868)）比较模拟输出[分布](@entry_id:182848)与历史数据[分布](@entry_id:182848)等 [@problem_id:3303630]。

**[不确定性的来源](@entry_id:164809)**

在模拟研究中，误差或不确定性可以分为两类：

1.  **随机不确定性 (Aleatory Uncertainty)**：这是系统固有的、不可消除的随机性。在模拟中，它表现为由于使用不同随机数种子而导致的多次运行结果之间的变异。通过增加模拟运行次数或时长，可以减小这种不确定性对估计量精度的影响（即减小置信区间宽度），但无法消除它。

2.  **认知不确定性 (Epistemic Uncertainty)**：这源于我们对真实系统知识的缺乏。它包括**结构不确定性**（例如，错误地假设服务时间服从指数分布，而实际上是别的[分布](@entry_id:182848)）和**[参数不确定性](@entry_id:264387)**（例如，[到达率](@entry_id:271803) $\lambda$ 的真实值未知）。[认知不确定性](@entry_id:149866)不能通过增加模拟运行次数来减少，而需要通过从真实世界收集更多数据或增进对系统的理解来解决 [@problem_id:3303630]。

正确区分这两种不确定性，并采用相应的 V 及统计分析技术，是进行严谨、可信的[离散事件模拟](@entry_id:637852)研究的基石。