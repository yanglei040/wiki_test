{"hands_on_practices": [{"introduction": "要真正掌握Metropolis-Adjusted Langevin Algorithm（MALA），理论学习必须与动手实践相结合。第一个练习将引导您完成一个全面的流程，从第一性原理推导接受概率到最终的算法实现。通过将MALA应用于标准正态分布的抽样 [@problem_id:3355276]，您将分析其计算复杂度并观察其在实践中的表现，为更高级的应用打下坚实的基础。", "problem": "您需要在一个高级研究生水平上研究经 Metropolis 调整的朗之万算法 (MALA)。您的任务结合了从第一性原理进行推导、算法设计以及使用确定性测试工具进行实现。\n\n从由随机微分方程 $dX_t = \\frac{1}{2}\\nabla \\log \\pi(X_t)\\,dt + dW_t$ 定义的过阻尼朗之万扩散开始，其中 $W_t$ 是一个标准维纳过程，$\\pi$ 是一个在归一化常数内已知的目标密度，通过应用步长为 $h>0$ 的 Euler–Maruyama 方法，产生了未经调整的朗之万算法。为了校正 Euler–Maruyama 方法引入的离散化偏差并恢复 $\\pi$ 作为其不变分布，可以使用 Metropolis–Hastings 接受/拒绝步骤，其非对称提议由一个高斯分布给出，该分布的中心是一个涉及 $\\nabla \\log \\pi$ 的漂移点。这就得到了经 Metropolis 调整的朗之万算法 (MALA)。提议分布为 $q_h(\\cdot \\mid x) = \\mathcal{N}(x + \\tfrac{h}{2}\\nabla \\log \\pi(x),\\, h I_d)$，其中 $I_d$ 是 $d\\times d$ 的单位矩阵。\n\n任务 A（推导与伪代码）：\n- 结合 Metropolis–Hastings 规则与上述提议核 $q_h(\\cdot \\mid x)$，推导 MALA 的接受概率，仅从以下几点出发：\n  - 过阻尼朗之万扩散的定义，\n  - Euler–Maruyama 离散化，\n  - Metropolis–Hastings 接受概率 $\\alpha(x,y) = \\min\\{1, \\frac{\\pi(y) q_h(x\\mid y)}{\\pi(x) q_h(y\\mid x)}\\}$。\n- 提供一次 MALA 迭代的清晰伪代码，并强调：\n  - 梯度 $\\nabla \\log \\pi(x)$ 的显式计算，\n  - 高斯向量的采样，\n  - Metropolis–Hastings 接受概率的计算。\n- 标注每次迭代的计算复杂度（用维度 $d$ 表示），并计算：\n  - 每次迭代执行多少次梯度评估，\n  - 每次迭代采样多少个维度为 $d$ 的高斯随机向量，\n  - 主导复杂度类别（例如 $O(d)$, $O(d^2)$），假设对于下文的测试目标，评估 $\\nabla \\log \\pi(x)$ 的成本为 $O(d)$ 次操作。\n\n任务 B（实现与测试）：\n- 实现一个程序，对 $d$ 维标准正态目标分布执行 MALA，即 $\\pi(x) \\propto \\exp(-\\tfrac{1}{2}\\|x\\|_2^2)$，因此 $\\log \\pi(x)$ 可以在相差一个加性常数的情况下使用，其梯度为 $\\nabla \\log \\pi(x) = -x$。\n- 使用步长为 $h0$ 的提议核：\n  - 提议均值 $\\mu(x) = x + \\tfrac{h}{2}\\nabla \\log \\pi(x)$，\n  - 提议协方差 $h I_d$。\n- 使用由 $q_h(y\\mid x)$ 和 $q_h(x\\mid y)$ 构建的 Metropolis–Hastings 接受概率，并相应地接受或拒绝。如果拒绝，状态保持不变。\n- 使用种子 $12345$ 初始化随机数生成器，以保证可复现性。计算经验均值 $\\bar{x}_T = \\frac{1}{T}\\sum_{t=1}^T X_t$，其中 $X_t$ 是第 $t$ 次接受/拒绝步骤后的马尔可夫链状态。报告欧几里得范数 $\\|\\bar{x}_T\\|_2$。\n- 对于每次迭代，计算梯度评估的次数和采样的高斯 $d$ 维向量的数量。对于此实现，不要在迭代之间缓存梯度；在同一次迭代内计算提议和接受所需的一切。\n\n测试套件：\n在以下三种情况下运行您的程序。对于每种情况，初始状态为指定的 $x_0$，维度为 $d$，步长为 $h$，迭代次数为 $T$。\n1) 情况 1：$d=1$, $h=0.5$, $T=6000$, $x_0 = [3.0]$。\n2) 情况 2：$d=10$, $h=0.3$, $T=8000$, $x_0 = [2.0,2.0,\\dots,2.0]$（十个元素）。\n3) 情况 3：$d=1$, $h=5.0$, $T=4000$, $x_0 = [0.0]$。\n\n每个测试用例所需的输出：\n- 接受率，作为浮点数，\n- 经验均值的欧几里得范数 $\\|\\bar{x}_T\\|_2$，作为浮点数，\n- 每次迭代的梯度评估次数，作为整数，\n- 每次迭代采样的高斯 $d$ 维向量的数量，作为整数，\n- 此目标下的主导复杂度指数，对于 $O(d)$ 等于 $1$ 的整数。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含所有三种情况的结果，格式为用方括号括起来的逗号分隔列表，按测试用例的顺序排列并展平。也就是说，输出应该是一个包含 $15$ 个数字的列表：对于每种情况，按顺序打印五个输出，然后在各种情况之间连接起来。\n- 浮点数必须四舍五入到恰好六位小数。整数必须打印为不带小数位的形式。\n- 格式示例（仅作示例）：$[\\text{acc}_1,\\|\\bar{x}\\|_{1},g_1,z_1,e_1,\\text{acc}_2,\\|\\bar{x}\\|_{2},g_2,z_2,e_2,\\text{acc}_3,\\|\\bar{x}\\|_{3},g_3,z_3,e_3]$。\n\n角度和物理单位：\n- 不涉及角度或物理单位。\n\n您的程序必须是自包含的，不接受任何输入，使用种子 $12345$，并遵守上述输出格式。唯一允许的库是 Python 标准库、NumPy 和 SciPy；您可以选择不使用 SciPy。", "solution": "该问题要求对 Metropolis 调整朗之万算法 (MALA) 的接受概率进行推导，创建其伪代码，分析其计算复杂度，最后在特定目标分布上进行实现和测试。\n\n### 任务 A：推导、伪代码和复杂度分析\n\n#### MALA 接受概率的推导\n\nMetropolis 调整朗之万算法是一种 Metropolis-Hastings (MH) 算法，旨在从一个目标概率分布中采样，该分布的密度为 $\\pi(x)$，在归一化常数内已知。MALA 使用一种受过阻尼朗之万扩散随机微分方程 (SDE) 离散化启发的提议机制：\n$$\ndX_t = \\frac{1}{2}\\nabla \\log \\pi(X_t)\\,dt + dW_t\n$$\n其中 $W_t$ 是一个标准的 $d$ 维维纳过程。应用步长为 $h>0$ 的 Euler-Maruyama 离散化，从当前状态 $x$ 得到一个提议 $y$：\n$$\ny = x + \\frac{h}{2}\\nabla \\log \\pi(x) + \\sqrt{h}Z\n$$\n其中 $Z \\sim \\mathcal{N}(0, I_d)$ 是一个标准的 $d$ 维正态随机向量。这定义了一个非对称提议核 $q_h(y \\mid x)$，它是一个正态分布的概率密度函数，$y \\sim \\mathcal{N}(\\mu(x), \\Sigma)$，其均值为 $\\mu(x) = x + \\frac{h}{2}\\nabla \\log \\pi(x)$，协方差为 $\\Sigma = hI_d$。该概率密度函数为：\n$$\nq_h(y \\mid x) = \\frac{1}{(2\\pi h)^{d/2}} \\exp\\left(-\\frac{1}{2h} \\|y - \\mu(x)\\|_2^2\\right)\n$$\n\n从状态 $x$ 移动到提议状态 $y$ 的 Metropolis-Hastings 接受概率 $\\alpha(x, y)$ 由下式给出：\n$$\n\\alpha(x,y) = \\min\\left\\{1, \\frac{\\pi(y) q_h(x\\mid y)}{\\pi(x) q_h(y\\mid x)}\\right\\}\n$$\n为了使该表达式更实用，我们处理比率的对数，通常称为对数接受率 $\\log R$：\n$$\n\\log R = \\log\\left(\\frac{\\pi(y)}{\\pi(x)}\\right) + \\log\\left(\\frac{q_h(x\\mid y)}{q_h(y\\mid x)}\\right)\n$$\n第一项是对数目标密度的差值：$\\log\\pi(y) - \\log\\pi(x)$。\n\n第二项涉及提议密度的比率。对数提议密度为：\n$$\n\\log q_h(y \\mid x) = -\\frac{d}{2}\\log(2\\pi h) - \\frac{1}{2h} \\left\\|y - \\left(x + \\frac{h}{2}\\nabla \\log \\pi(x)\\right)\\right\\|_2^2 \\\\\n\\log q_h(x \\mid y) = -\\frac{d}{2}\\log(2\\pi h) - \\frac{1}{2h} \\left\\|x - \\left(y + \\frac{h}{2}\\nabla \\log \\pi(y)\\right)\\right\\|_2^2\n$$\n项 $-\\frac{d}{2}\\log(2\\pi h)$ 是一个常数，在差值 $\\log q_h(x \\mid y) - \\log q_h(y \\mid x)$ 中被抵消：\n$$\n\\log\\left(\\frac{q_h(x\\mid y)}{q_h(y\\mid x)}\\right) = -\\frac{1}{2h} \\left( \\left\\|x - \\left(y + \\frac{h}{2}\\nabla \\log \\pi(y)\\right)\\right\\|_2^2 - \\left\\|y - \\left(x + \\frac{h}{2}\\nabla \\log \\pi(x)\\right)\\right\\|_2^2 \\right)\n$$\n综合所有部分，对数接受率为：\n$$\n\\log R(x,y) = \\log\\pi(y) - \\log\\pi(x) - \\frac{1}{2h} \\left( \\left\\|x - y - \\frac{h}{2}\\nabla \\log \\pi(y)\\right\\|_2^2 - \\left\\|y - x - \\frac{h}{2}\\nabla \\log \\pi(x)\\right\\|_2^2 \\right)\n$$\n最终的接受概率为 $\\alpha(x,y) = \\min\\{1, \\exp(\\log R(x,y))\\}$。对于数值实现，最好将 $\\log u$ 与 $\\log R(x,y)$ 进行比较，其中 $u \\sim \\text{Uniform}(0,1)$。\n\n一种更高效计算对数提议比率项的方法是观察到 $y - (x + \\frac{h}{2}\\nabla \\log \\pi(x)) = \\sqrt{h}Z$，其中 $Z$ 是用于生成提议的标准正态变量。因此，其范数的平方为 $h\\|Z\\|_2^2$，且 $\\log q_h(y \\mid x) = C - \\frac{1}{2}\\|Z\\|_2^2$。这将对数接受率简化为：\n$$\n\\log R(x,y) = \\log\\pi(y) - \\log\\pi(x) - \\frac{1}{2h} \\left\\|x - y - \\frac{h}{2}\\nabla \\log \\pi(y)\\right\\|_2^2 + \\frac{1}{2}\\|Z\\|_2^2\n$$\n这种形式避免了一次范数计算，并且可能在数值上更稳定。\n\n#### 一次 MALA 迭代的伪代码\n\n给定当前状态 $x^{(t)}$、步长 $h$ 和对数目标密度函数 $\\log\\pi$：\n\n1.  **计算当前状态的梯度**：$g^{(t)} \\leftarrow \\nabla \\log \\pi(x^{(t)})$。\n2.  **构建提议均值**：$\\mu^{(t)} \\leftarrow x^{(t)} + \\frac{h}{2} g^{(t)}$。\n3.  **采样提议**：\n    a. 采样一个随机向量 $Z^{(t)} \\sim \\mathcal{N}(0, I_d)$。\n    b. 生成提议状态 $y \\leftarrow \\mu^{(t)} + \\sqrt{h} Z^{(t)}$。\n4.  **计算提议状态的梯度**：$g_y \\leftarrow \\nabla \\log \\pi(y)$。\n5.  **计算对数接受率**：\n    a. 计算前向对数提议项：$\\log q_{fwd} \\leftarrow -\\frac{1}{2} \\|Z^{(t)}\\|_2^2$。\n    b. 计算反向对数提议项：$\\log q_{rev} \\leftarrow -\\frac{1}{2h} \\|x^{(t)} - y - \\frac{h}{2} g_y\\|_2^2$。\n    c. 计算对数比率：$\\log R \\leftarrow (\\log\\pi(y) - \\log\\pi(x^{(t)})) + (\\log q_{rev} - \\log q_{fwd})$。\n6.  **接受或拒绝**：\n    a. 采样一个均匀分布的随机数 $u \\sim \\text{Uniform}(0,1)$。\n    b. 如果 $\\log u  \\log R$：\n        设置 $x^{(t+1)} \\leftarrow y$（接受）。\n    c. 否则：\n        设置 $x^{(t+1)} \\leftarrow x^{(t)}$（拒绝）。\n\n#### 计算复杂度分析\n\n我们根据状态维度 $d$ 分析每次迭代的复杂度。\n\n-   **每次迭代的梯度评估次数**：该算法需要当前状态的梯度 $\\nabla \\log \\pi(x^{(t)})$ 来构建提议。然后，它需要提议状态的梯度 $\\nabla \\log \\pi(y)$ 来计算接受概率。根据问题明确指示不要在迭代之间缓存梯度，这两个评估在每次迭代中都会执行，无论提议是被接受还是被拒绝。\n    - **计数**：2 次梯度评估。\n\n-   **每次迭代采样的高斯随机向量数**：采样一个 $d$ 维标准正态向量 $Z^{(t)}$ 以生成提议 $y$。\n    - **计数**：1 个高斯向量样本。\n\n-   **主导复杂度类别**：我们假设评估 $\\nabla \\log \\pi(x)$ 的成本为 $O(d)$，正如为测试目标所指定的那样。\n    1.  步骤 1（在 $x^{(t)}$ 处的梯度）：$O(d)$。\n    2.  步骤 2（提议均值）：向量加法和标量-向量乘法是 $O(d)$。\n    3.  步骤 3（采样提议）：采样一个 $d$ 维正态向量是 $O(d)$，然后是 $O(d)$ 的向量操作。\n    4.  步骤 4（在 $y$ 处的梯度）：$O(d)$。\n    5.  步骤 5（对数接受率）：这涉及评估 $\\log\\pi$（对于像目标分布这样的可分密度，通常是 $O(d)$）、向量范数（$\\|v\\|_2^2$ 是 $O(d)$）和向量算术（$O(d)$）。总成本是 $O(d)$。\n    6.  步骤 6（接受/拒绝）：这是一个 $O(d)$ 操作（向量复制）。\n\n由于所有步骤的复杂度至多为 $O(d)$，因此一次 MALA 迭代的主导复杂度类别是 $O(d)$。\n- **主导复杂度指数**：对于 $O(d) = O(d^1)$，指数为 $1$。", "answer": "```python\nimport numpy as np\n# No other libraries are needed for this problem.\n\ndef solve():\n    \"\"\"\n    Implements and tests the Metropolis-Adjusted Langevin Algorithm (MALA)\n    for a d-dimensional standard normal target distribution.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (d, h, T, x0)\n        (1, 0.5, 6000, np.array([3.0])),\n        (10, 0.3, 8000, np.full(10, 2.0)),\n        (1, 5.0, 4000, np.array([0.0])),\n    ]\n\n    results = []\n    \n    # Initialize the random number generator with a fixed seed for reproducibility.\n    rng = np.random.default_rng(12345)\n\n    for d, h, T, x0 in test_cases:\n        x_current = np.copy(x0)\n        x_sum = np.zeros(d)\n        accepted_count = 0\n\n        # The number of gradient evaluations and Gaussian samples are constant per iteration.\n        grad_evals_per_iter = 2\n        gauss_samples_per_iter = 1\n        complexity_exponent = 1 # O(d^1)\n\n        for _ in range(T):\n            # 1. Compute gradient at the current state.\n            # For pi(x) propto exp(-0.5*||x||^2), grad(log(pi(x))) = -x.\n            grad_x = -x_current\n\n            # 2. Form proposal by sampling from the proposal distribution.\n            # Proposal mean: mu = x + (h/2) * grad(log(pi(x)))\n            # Proposal distribution: y ~ N(mu, h*I)\n            mu_proposal = x_current + (h / 2.0) * grad_x\n            \n            # Sample a standard normal vector Z\n            z = rng.standard_normal(size=d)\n            y_proposal = mu_proposal + np.sqrt(h) * z\n\n            # 3. Compute gradient at the proposed state.\n            grad_y = -y_proposal\n\n            # 4. Calculate the log of the Metropolis-Hastings acceptance ratio.\n            # log R = log(pi(y)/pi(x)) + log(q(x|y)/q(y|x))\n\n            # Log-target densities (ignoring constants)\n            log_pi_x = -0.5 * np.dot(x_current, x_current)\n            log_pi_y = -0.5 * np.dot(y_proposal, y_proposal)\n\n            # Log-proposal densities (ignoring constants)\n            # Forward: q(y|x)\n            # We can use the generated z to simplify: y-mu_proposal = sqrt(h)*z\n            # The exponent term is -1/(2h) * ||y-mu_proposal||^2 = -1/(2h) * h*||z||^2 = -0.5*||z||^2\n            log_q_y_given_x = -0.5 * np.dot(z, z)\n            \n            # Reverse: q(x|y)\n            # Mean of reverse proposal: mu_rev = y + (h/2)*grad_y\n            mu_reverse = y_proposal + (h / 2.0) * grad_y\n            log_q_x_given_y = -1.0 / (2.0 * h) * np.sum((x_current - mu_reverse)**2)\n\n            # Total log acceptance ratio\n            log_alpha = (log_pi_y - log_pi_x) + (log_q_x_given_y - log_q_y_given_x)\n\n            # 5. Accept or reject the proposal.\n            if np.log(rng.uniform())  log_alpha:\n                x_current = y_proposal\n                accepted_count += 1\n            # If rejected, x_current remains the same.\n            \n            # Add the state of the chain (after accept/reject) to the sum.\n            x_sum += x_current\n\n        # After all iterations, compute the final statistics.\n        acceptance_rate = accepted_count / T\n        empirical_mean = x_sum / T\n        norm_of_mean = np.linalg.norm(empirical_mean)\n\n        results.extend([\n            round(acceptance_rate, 6),\n            round(norm_of_mean, 6),\n            grad_evals_per_iter,\n            gauss_samples_per_iter,\n            complexity_exponent\n        ])\n\n    # Format the final output string as specified.\n    final_output = f\"[{','.join(map(str, results))}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3355276"}, {"introduction": "虽然标准的MALA算法功能强大，但在处理尺度不佳或维度间具有强相关性的目标分布时可能会遇到困难。本练习介绍了预处理（preconditioning）技术，这是在这种情况下提高抽样效率的关键方法。您将推导预处理MALA（pMALA）的接受概率 [@problem_id:3355207]，这是一种通过使提议机制适应目标分布的局部几何形状来进行泛化的方法，也是构建更稳健采样器的基础步骤。", "problem": "考虑一个在 $\\mathbb{R}^{d}$ 上的目标概率密度 $\\pi(x)$，其归一化常数未知，$\\ln\\pi(x)$ 连续可微，以及一个对称正定矩阵 $M \\in \\mathbb{R}^{d \\times d}$。使用预处理的过阻尼朗之万动力学为 Metropolis-Hastings (MH) 方法构建一个提议，该方法的平稳分布为 $\\pi(x)$。从随机微分方程 (SDE) 的基础和 MH 接受机制出发，通过将欧拉-丸山格式应用于以 $\\pi(x)$ 为不变密度的预处理朗之万 SDE，来推导离散时间提议核。利用此结果获得精确的高斯提议密度 $q(x' \\mid x)$，然后写出 MH 接受概率 $\\alpha(x,x')$，该概率考虑了 $q(x' \\mid x)$ 的非对称性。\n\n您的推导必须从以下基本依据开始：\n- 带预处理的過阻尼朗之万 SDE，其漂移项的选择是为了保持 $\\pi(x)$ 为不变密度，扩散项与 $M$ 对齐。\n- Metropolis-Hastings 接受概率，对于可能非对称的提议，该概率由目标密度与提议密度的比值决定。\n\n假设步长 $h>0$ 固定。将最终的接受概率表示为一个单一的闭式解析表达式，其中明确包含由提议非对称性产生的高斯项。最终答案必须是一个符号数学表达式；不要包含任何数值计算或近似。", "solution": "用户希望推导预处理 Metropolis-调整的朗之万算法 (MALA) 的 Metropolis-Hastings 接受概率。推导必须从底层的随机微分方程 (SDE) 开始，使用欧拉-丸山离散化方法找到提议密度，然后应用 Metropolis-Hastings 规则处理非对称提议。\n\n### 第1步：问题验证\n\n**1.1. 提取已知条件**\n-   目标概率密度：$\\pi(x)$，在 $\\mathbb{R}^{d}$ 上，归一化常数未知。\n-   对数密度 $\\ln\\pi(x)$ 连续可微。\n-   预处理矩阵：$M \\in \\mathbb{R}^{d \\times d}$，对称正定。\n-   方法：Metropolis-Hastings (MH)，提议基于预处理的過阻尼朗之万动力学。\n-   离散化：欧拉-丸山格式。\n-   步长：$h>0$，固定。\n-   任务：推导提议密度 $q(x' \\mid x)$ 和 MH 接受概率 $\\alpha(x,x')$。\n\n**1.2. 使用提取的已知条件进行验证**\n-   **科学基础**：该问题基于随机微积分 (朗之万 SDE)、SDE 的数值方法 (欧拉-丸山) 和统计计算 (Metropolis-Hastings 算法) 的基本原理。这些是计算统计学和物理学中标准且成熟的概念。该问题在科学上是合理的。\n-   **良定性**：问题陈述清晰，并提供了推导所求量所需的所有必要信息。对 $\\pi(x)$ 和 $M$ 的假设是标准的，确保了所有数学运算（梯度、矩阵求逆等）都是良定的。存在唯一的解析解。\n-   **客观性**：问题以精确、客观的数学语言表述，没有歧义或主观论断。\n\n**1.3. 结论与行动**\n该问题是有效的，因为它具有科学基础、良定性和客观性。我将进行完整的推导。\n\n### 第2步：接受概率的推导\n\n**2.1. 预处理的朗之万 SDE**\n过阻尼朗之万 SDE 是一个随机过程，其平稳分布是给定的目标密度 $\\pi(x)$。对于目标密度 $\\pi(x) \\propto \\exp(-E(x))$，其中 $E(x)$ 是势能，该 SDE 描述了粒子在该势能景观中受随机热涨落影响的运动。\n\n具有常数预处理器 $M$ 且以 $\\pi(x)$ 为其不变密度的预处理朗之万 SDE 的一般形式为\n$$\ndX_t = \\frac{1}{2} M \\nabla \\ln \\pi(X_t) dt + \\sqrt{M} dW_t\n$$\n其中 $X_t \\in \\mathbb{R}^d$ 是系统在时间 $t$ 的状态，$\\nabla \\ln \\pi(X_t)$ 是对数目标密度的梯度，$M$ 是对称正定预处理矩阵，$dW_t$ 是一个标准的 $d$ 维维纳过程（即，其增量是独立的、均值为 $0$ 且协方差为 $I_d dt$ 的高斯变量，其中 $I_d$ 是 $d \\times d$ 单位矩阵）。\n\n扩散项为 $\\sqrt{M} dW_t$，其中 $\\sqrt{M}$ 是 $M$ 唯一的对称正定平方根。此噪声项的协方差为 $E[(\\sqrt{M} dW_t)(\\sqrt{M} dW_t)^T] = \\sqrt{M} E[dW_t dW_t^T] \\sqrt{M}^T = \\sqrt{M} (I_d dt) \\sqrt{M} = M dt$。漂移项的选择，$\\frac{1}{2} M \\nabla \\ln \\pi(X_t)$，确保了在 SDE 层面满足细致平衡条件，从而使 $\\pi(x)$ 成为不变密度。\n\n**2.2. 离散化与提议核**\n为了给 Metropolis-Hastings 算法生成提议，我们使用欧拉-丸山格式以有限时间步长 $h > 0$ 对 SDE 进行离散化。设 $x$ 为第 $n$ 步的当前状态，$x'$ 为第 $n+1$ 步的提议状态。离散化形式如下：\n$$\nx' = x + h \\left(\\frac{1}{2} M \\nabla \\ln \\pi(x)\\right) + \\sqrt{h} \\sqrt{M} Z\n$$\n其中 $Z \\sim \\mathcal{N}(0, I_d)$ 是一个由 $d$ 个独立标准正态随机变量组成的向量。\n\n该方程定义了提议机制。我们可以看到，$x'$ 是通过将一个确定性的漂移项和一个随机的高斯涨落加到当前状态 $x$ 上生成的。\n\n**2.3. 高斯提议密度 $q(x' \\mid x)$**\n提议规则可以重写，以表明 $x'$ 是从一个多元高斯分布中抽取的。设该分布的均值为 $\\mu(x)$：\n$$\n\\mu(x) = x + \\frac{h}{2} M \\nabla \\ln \\pi(x)\n$$\n提议 $x'$ 于是由 $x' = \\mu(x) + \\sqrt{hM}Z$ 给出。这表明，在给定 $x$ 的条件下，提议状态 $x'$ 服从均值为 $\\mu(x)$、协方差为 $\\Sigma = E[(\\sqrt{hM}Z)(\\sqrt{hM}Z)^T] = h M E[ZZ^T] = hM$ 的高斯分布。\n\n因此，提议密度 $q(x' \\mid x)$ 是多元正态分布 $\\mathcal{N}(\\mu(x), hM)$ 的概率密度函数：\n$$\nq(x' \\mid x) = \\frac{1}{\\sqrt{(2\\pi)^d \\det(hM)}} \\exp\\left( -\\frac{1}{2} (x' - \\mu(x))^T (hM)^{-1} (x' - \\mu(x)) \\right)\n$$\n代入 $\\mu(x)$ 的表达式，我们得到：\n$$\nq(x' \\mid x) = \\frac{1}{\\sqrt{(2\\pi h)^d \\det(M)}} \\exp\\left( -\\frac{1}{2h} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right)^T M^{-1} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right) \\right)\n$$\n该提议密度通常是不对称的，即 $q(x' \\mid x) \\neq q(x \\mid x')$，因为漂移项 $\\frac{h}{2} M \\nabla \\ln \\pi(x)$ 依赖于起始状态 $x$。\n\n**2.4. Metropolis-Hastings 接受概率 $\\alpha(x, x'$)**\nMetropolis-Hastings 算法通过引入一个接受-拒绝步骤，来确保生成的马尔可夫链以 $\\pi(x)$ 为其平稳分布。从 $x$ 到 $x'$ 的提议移动的接受概率 $\\alpha(x, x')$ 由下式给出：\n$$\n\\alpha(x, x') = \\min \\left( 1, \\frac{\\pi(x') q(x \\mid x')}{\\pi(x) q(x' \\mid x)} \\right)\n$$\n为了计算该值，我们需要逆向提议密度 $q(x \\mid x')$，即提议从 $x'$ 移动到 $x$ 的概率。根据推导的对称性，它由下式给出：\n$$\nq(x \\mid x') = \\frac{1}{\\sqrt{(2\\pi h)^d \\det(M)}} \\exp\\left( -\\frac{1}{2h} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right)^T M^{-1} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right) \\right)\n$$\n提议密度的比值为：\n$$\n\\frac{q(x \\mid x')}{q(x' \\mid x)} = \\frac{\\exp\\left( -\\frac{1}{2h} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right)^T M^{-1} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right) \\right)}{\\exp\\left( -\\frac{1}{2h} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right)^T M^{-1} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right) \\right)}\n$$\n注意归一化常数 $\\frac{1}{\\sqrt{(2\\pi h)^d \\det(M)}}$ 会消掉。\n\n将该比值代入接受概率公式，即可得到 $\\alpha(x, x')$ 的最终表达式。由于 $\\pi(x)$ 仅在相差一个常数的情况下已知，我们使用可计算的比率 $\\pi(x')/\\pi(x)$。最终的接受概率是：\n$$\n\\alpha(x, x') = \\min\\left(1, \\frac{\\pi(x')}{\\pi(x)} \\frac{\\exp\\left( -\\frac{1}{2h} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right)^T M^{-1} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right) \\right)}{\\exp\\left( -\\frac{1}{2h} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right)^T M^{-1} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right) \\right)}\\right)\n$$\n该表达式也可以通过合并指数项写得更紧凑：\n$$\n\\alpha(x, x') = \\min\\left(1, \\exp\\left( \\ln\\left(\\frac{\\pi(x')}{\\pi(x)}\\right) + \\ln\\left(\\frac{q(x \\mid x')}{q(x' \\mid x)}\\right) \\right)\\right)\n$$\n其中提议的对数比率由下式给出：\n$$\n\\ln\\left(\\frac{q(x \\mid x')}{q(x' \\mid x)}\\right) = -\\frac{1}{2h} \\left[ \\left\\|x - x' - \\frac{h}{2}M\\nabla\\ln\\pi(x')\\right\\|_{M^{-1}}^2 - \\left\\|x' - x - \\frac{h}{2}M\\nabla\\ln\\pi(x)\\right\\|_{M^{-1}}^2 \\right]\n$$\n其中 $\\|v\\|_{A}^2 = v^T A v$。问题要求的是最先推导出的显式表达式。", "answer": "$$\n\\boxed{\\min\\left(1, \\frac{\\pi(x')}{\\pi(x)} \\frac{\\exp\\left( -\\frac{1}{2h} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right)^T M^{-1} \\left(x - x' - \\frac{h}{2} M \\nabla \\ln\\pi(x')\\right) \\right)}{\\exp\\left( -\\frac{1}{2h} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right)^T M^{-1} \\left(x' - x - \\frac{h}{2} M \\nabla \\ln\\pi(x)\\right) \\right)}\\right)}\n$$", "id": "3355207"}, {"introduction": "算法专业知识的一个关键方面不仅在于理解算法如何工作，还在于了解其相对的优缺点。本练习将MALA与另一种方法——预处理Crank-Nicolson（pCN）算法，在高斯目标的特定背景下进行直接比较。通过推导和对比它们的接受概率 [@problem_id:3355277]，您会发现pCN能够达到完美的接受率，这将为您深入理解MALA中离散化误差的本质以及精确采样器的存在提供深刻的见解。", "problem": "考虑一个在 $\\mathbb{R}^{d}$ 上的目标分布，由一个非退化高斯密度 $\\pi(x) \\propto \\exp\\!\\left(-\\tfrac{1}{2}\\,x^{\\top}\\Sigma^{-1}x\\right)$ 给出，其中 $\\Sigma \\in \\mathbb{R}^{d \\times d}$ 是一个对称正定协方差矩阵。两种马尔可夫链蒙特卡洛提议定义如下。\n\n1. Metropolis-adjusted Langevin algorithm (MALA) 使用提议 $y \\sim q(x,\\cdot)$，其中 $q(x,\\cdot)$ 是均值为 $x + \\tfrac{h}{2}\\,\\nabla\\ln\\pi(x)$、协方差为 $h I_{d}$ 的高斯密度，其中 $h>0$ 且 $I_{d}$ 是 $d\\times d$ 的单位矩阵。其 Metropolis-Hastings 接受概率为 $\\alpha_{\\mathrm{M}}(x,y) = \\min\\!\\left(1, \\frac{\\pi(y)\\,q(y,x)}{\\pi(x)\\,q(x,y)}\\right)$。\n\n2. preconditioned Crank–Nicolson (pCN) 方法使用提议\n$$\ny = \\sqrt{1-\\beta^{2}}\\,x + \\beta\\,\\eta,\n$$\n其中参数 $\\beta \\in (0,1]$，且 $\\eta \\sim \\mathcal{N}(0,\\Sigma)$ 与 $x$ 独立。相应的提议密度 $q_{\\mathrm{pCN}}(x,\\cdot)$ 是均值为 $\\sqrt{1 - \\beta^{2}}\\,x$、协方差为 $\\beta^{2}\\Sigma$ 的高斯分布。其 Metropolis-Hastings 接受概率为 $\\alpha_{\\mathrm{p}}(x,y) = \\min\\!\\left(1, \\frac{\\pi(y)\\,q_{\\mathrm{pCN}}(y,x)}{\\pi(x)\\,q_{\\mathrm{pCN}}(x,y)}\\right)$。\n\n仅从 Metropolis-Hastings 比率的基本定义和给定的高斯目标出发：\n\n- 推导 MALA 对数接受比 $R_{\\mathrm{M}}(x,y) := \\ln\\pi(y) - \\ln\\pi(x) + \\ln q(y,x) - \\ln q(x,y)$ 的精确表达式，该表达式用步长 $h$、当前状态 $x$、提议增量 $\\delta := y - x$ 和矩阵 $\\Sigma$ 表示。通过谱分解 $\\Sigma = Q\\Lambda Q^{\\top}$（其中特征值为 $\\{\\lambda_{i}\\}_{i=1}^{d}$），将 $R_{\\mathrm{M}}$重写为包含标准正态变量的独立贡献之和，从而表达 $R_{\\mathrm{M}}$ 在稳态下的分布，并明确指出其对 $h$ 和 $\\{\\lambda_{i}\\}$ 的依赖关系。\n\n- 然后，通过验证 $q_{\\mathrm{pCN}}(x,y)\\,\\pi(x) = q_{\\mathrm{pCN}}(y,x)\\,\\pi(y)$ 来证明 pCN 提议相对于高斯目标是可逆的，并得出 pCN 的 Metropolis-Hastings 接受概率精确为1的结论。\n\n答案规格：提供在此高斯设定下 preconditioned Crank–Nicolson 方法的接受概率作为最终答案，形式为一个精确的单一数字。无需四舍五入。", "solution": "我们从 Metropolis-Hastings 接受比开始。对于任何提议密度 $q(x,\\cdot)$，接受概率为\n$$\n\\alpha(x,y) = \\min\\!\\left(1, \\exp\\!\\big(R(x,y)\\big)\\right), \\quad R(x,y) := \\ln\\pi(y) - \\ln\\pi(x) + \\ln q(y,x) - \\ln q(x,y).\n$$\n我们将此应用于 Metropolis-adjusted Langevin algorithm (MALA) 和 preconditioned Crank–Nicolson (pCN) 方法。\n\nMetropolis-adjusted Langevin algorithm (MALA):\n\n目标是 $\\pi(x) \\propto \\exp\\!\\left(-\\tfrac{1}{2}\\,x^{\\top}\\Sigma^{-1}x\\right)$，所以 $\\nabla \\ln \\pi(x) = -\\Sigma^{-1}x$。MALA 提议为\n$$\ny = x + \\tfrac{h}{2}\\,\\nabla \\ln \\pi(x) + \\sqrt{h}\\,\\xi = x - \\tfrac{h}{2}\\,\\Sigma^{-1}x + \\sqrt{h}\\,\\xi,\n$$\n其中 $\\xi \\sim \\mathcal{N}(0, I_{d})$ 与 $x$ 独立。令 $\\delta := y - x$，则 $\\delta = - \\tfrac{h}{2}\\,\\Sigma^{-1}x + \\sqrt{h}\\,\\xi$。提议密度为\n$$\nq(x,y) = (2\\pi h)^{-d/2}\\,\\exp\\!\\left(-\\tfrac{1}{2h}\\,\\left\\|y - x + \\tfrac{h}{2}\\,\\Sigma^{-1}x\\right\\|^{2}\\right)\n= (2\\pi h)^{-d/2}\\,\\exp\\!\\left(-\\tfrac{1}{2h}\\,\\left\\|\\delta + \\tfrac{h}{2}\\,\\Sigma^{-1}x\\right\\|^{2}\\right).\n$$\n类似地，\n$$\nq(y,x) = (2\\pi h)^{-d/2}\\,\\exp\\!\\left(-\\tfrac{1}{2h}\\,\\left\\|x - y + \\tfrac{h}{2}\\,\\Sigma^{-1}y\\right\\|^{2}\\right)\n= (2\\pi h)^{-d/2}\\,\\exp\\!\\left(-\\tfrac{1}{2h}\\,\\left\\|-\\delta + \\tfrac{h}{2}\\,\\Sigma^{-1}y\\right\\|^{2}\\right).\n$$\n计算目标对数比：\n$$\n\\ln\\pi(y) - \\ln\\pi(x) = -\\tfrac{1}{2}\\,(y^{\\top}\\Sigma^{-1}y - x^{\\top}\\Sigma^{-1}x)\n= - x^{\\top}\\Sigma^{-1}\\delta - \\tfrac{1}{2}\\,\\delta^{\\top}\\Sigma^{-1}\\delta,\n$$\n这里我们使用了 $y = x + \\delta$ 和 $\\Sigma^{-1}$ 的对称性。接下来计算提议对数比。定义\n$$\na := -\\delta + \\tfrac{h}{2}\\,\\Sigma^{-1}y, \\quad b := \\delta + \\tfrac{h}{2}\\,\\Sigma^{-1}x.\n$$\n于是\n$$\n\\ln q(y,x) - \\ln q(x,y) = -\\tfrac{1}{2h}\\,\\big(\\|a\\|^{2} - \\|b\\|^{2}\\big) = -\\tfrac{1}{2h}\\,(a-b)^{\\top}(a+b).\n$$\n我们计算出 $a - b = -2\\delta + \\tfrac{h}{2}\\,\\Sigma^{-1}\\delta$ 和 $a + b = \\tfrac{h}{2}\\,\\Sigma^{-1}(x + y)$。因此\n$$\n\\ln q(y,x) - \\ln q(x,y)\n= -\\tfrac{1}{2h}\\,\\left(-2\\delta + \\tfrac{h}{2}\\,\\Sigma^{-1}\\delta\\right)^{\\top}\\left(\\tfrac{h}{2}\\,\\Sigma^{-1}(x + y)\\right)\n= -\\tfrac{1}{4}\\,\\left(-2\\delta + \\tfrac{h}{2}\\,\\Sigma^{-1}\\delta\\right)^{\\top}\\Sigma^{-1}(x + y).\n$$\n代入 $y = x + \\delta$ 得到 $x + y = 2x + \\delta$，通过展开和化简，MALA 的总对数接受比可以化简为一个精确且非常简洁的形式\n$$\nR_{\\mathrm{M}}(x,y) = - \\tfrac{h}{4}\\,\\delta^{\\top}\\Sigma^{-2}x \\;-\\; \\tfrac{h}{8}\\,\\delta^{\\top}\\Sigma^{-2}\\delta.\n$$\n在高斯目标的情况下，这个表达式对于所有 $h>0$ 都是精确的。由于 $\\delta = - \\tfrac{h}{2}\\,\\Sigma^{-1}x + \\sqrt{h}\\,\\xi$ 且 $\\xi \\sim \\mathcal{N}(0,I_{d})$，在给定 $x$ 的条件下，增量 $\\delta$ 服从均值为 $-\\tfrac{h}{2}\\,\\Sigma^{-1}x$、协方差为 $h I_{d}$ 的高斯分布。因此，$R_{\\mathrm{M}}$ 是一个高斯随机向量的二次型，并具有非中心广义卡方结构。\n\n为了展示稳态下的显式分布以及其对 $\\Sigma$ 谱的依赖性，对 $\\Sigma$ 进行对角化 $\\Sigma = Q\\Lambda Q^{\\top}$，其中 $Q$ 是正交矩阵，$\\Lambda = \\operatorname{diag}(\\lambda_{1},\\dots,\\lambda_{d})$ 且 $\\lambda_{i} > 0$。令 $x = Q\\Lambda^{1/2}z$ 其中 $z \\sim \\mathcal{N}(0,I_{d})$，并令 $\\xi \\sim \\mathcal{N}(0,I_{d})$ 为独立的。在此基下，\n$$\n\\delta = Q\\left(\\sqrt{h}\\,\\xi - \\tfrac{h}{2}\\,\\Lambda^{-1/2}z\\right), \\qquad\n\\Sigma^{-2} = Q\\Lambda^{-2}Q^{\\top}.\n$$\n因此，\n\\begin{align*}\n\\delta^{\\top}\\Sigma^{-2}x\n= \\left(\\sqrt{h}\\,\\xi - \\tfrac{h}{2}\\,\\Lambda^{-1/2}z\\right)^{\\top}\\Lambda^{-3/2}z\n= \\sum_{i=1}^{d}\\left(\\sqrt{h}\\,\\xi_{i}\\lambda_{i}^{-3/2}z_{i} - \\tfrac{h}{2}\\,\\lambda_{i}^{-2}z_{i}^{2}\\right),\\\\\n\\delta^{\\top}\\Sigma^{-2}\\delta\n= \\left(\\sqrt{h}\\,\\xi - \\tfrac{h}{2}\\,\\Lambda^{-1/2}z\\right)^{\\top}\\Lambda^{-2}\\left(\\sqrt{h}\\,\\xi - \\tfrac{h}{2}\\,\\Lambda^{-1/2}z\\right)\n= \\sum_{i=1}^{d}\\left(h\\,\\lambda_{i}^{-2}\\xi_{i}^{2} - h^{3/2}\\,\\lambda_{i}^{-5/2}\\xi_{i}z_{i} + \\tfrac{h^{2}}{4}\\,\\lambda_{i}^{-3}z_{i}^{2}\\right).\n\\end{align*}\n于是，\n$$\nR_{\\mathrm{M}}(x,y)\n= - \\sum_{i=1}^{d}\\left[ \\tfrac{h^{3/2}}{4}\\,\\lambda_{i}^{-3/2}\\,\\xi_{i}z_{i}\n- \\tfrac{h^{2}}{8}\\,\\lambda_{i}^{-2}\\,z_{i}^{2}\n+ \\tfrac{h^{2}}{8}\\,\\lambda_{i}^{-2}\\,\\xi_{i}^{2}\n- \\tfrac{h^{5/2}}{8}\\,\\lambda_{i}^{-5/2}\\,\\xi_{i}z_{i}\n+ \\tfrac{h^{3}}{32}\\,\\lambda_{i}^{-3}\\,z_{i}^{2} \\right],\n$$\n如果需要，可以重新组合；其紧凑的精确形式为\n$$\nR_{\\mathrm{M}}(x,y) = - \\tfrac{h}{4}\\sum_{i=1}^{d}\\left(\\sqrt{h}\\,\\lambda_{i}^{-3/2}\\,\\xi_{i}z_{i} - \\tfrac{h}{2}\\,\\lambda_{i}^{-2}\\,z_{i}^{2}\\right)\n\\;-\\; \\tfrac{h}{8}\\sum_{i=1}^{d}\\left(h\\,\\lambda_{i}^{-2}\\,\\xi_{i}^{2} - h^{3/2}\\,\\lambda_{i}^{-5/2}\\,\\xi_{i}z_{i} + \\tfrac{h^{2}}{4}\\,\\lambda_{i}^{-3}\\,z_{i}^{2}\\right).\n$$\n在稳态下，$z_{i}$ 和 $\\xi_{i}$ 是独立的标准正态变量。这展示了 MALA 的精确接受分布：$\\alpha_{\\mathrm{M}}(x,y) = \\min\\!\\left(1,\\exp\\!\\big(R_{\\mathrm{M}}(x,y)\\big)\\right)$，其中 $R_{\\mathrm{M}}$ 是关于 $i$ 的双线性和二次项的和，其系数依赖于 $h$ 和特征值 $\\{\\lambda_{i}\\}$。特别地，$R_{\\mathrm{M}}$ 的分布以及因此 $\\alpha_{\\mathrm{M}}$ 的分布都显式地依赖于 $h$ 和 $\\Sigma$ 的谱。\n\nPreconditioned Crank–Nicolson (pCN):\n\npCN 提议密度是\n$$\nq_{\\mathrm{pCN}}(x,y) = \\frac{1}{(2\\pi)^{d/2} (\\det(\\beta^{2}\\Sigma))^{1/2}}\\,\\exp\\!\\left(-\\frac{1}{2\\beta^{2}}\\,(y - \\sqrt{1-\\beta^{2}}\\,x)^{\\top}\\Sigma^{-1}(y - \\sqrt{1-\\beta^{2}}\\,x)\\right).\n$$\n我们通过证明细致平衡条件 $q_{\\mathrm{pCN}}(x,y)\\,\\pi(x) = q_{\\mathrm{pCN}}(y,x)\\,\\pi(y)$ 对所有 $x,y \\in \\mathbb{R}^{d}$ 成立，来展示其关于 $\\pi$ 的可逆性。由于等式两边有相同的归一化常数 $(2\\pi)^{-d/2} (\\det(\\beta^{2}\\Sigma))^{-1/2} (\\det \\Sigma)^{-1/2}$，我们只需证明指数部分相等即可。考虑\n\\begin{align*}\nE_{1} = \\frac{1}{2\\beta^{2}}\\,(y - \\sqrt{1-\\beta^{2}}\\,x)^{\\top}\\Sigma^{-1}(y - \\sqrt{1-\\beta^{2}}\\,x) + \\frac{1}{2}\\,x^{\\top}\\Sigma^{-1}x,\\\\\nE_{2} = \\frac{1}{2\\beta^{2}}\\,(x - \\sqrt{1-\\beta^{2}}\\,y)^{\\top}\\Sigma^{-1}(x - \\sqrt{1-\\beta^{2}}\\,y) + \\frac{1}{2}\\,y^{\\top}\\Sigma^{-1}y.\n\\end{align*}\n展开 $E_{1}$：\n\\begin{align*}\nE_{1}\n= \\frac{1}{2\\beta^{2}}\\left(y^{\\top}\\Sigma^{-1}y - 2\\sqrt{1-\\beta^{2}}\\,x^{\\top}\\Sigma^{-1}y + (1-\\beta^{2})\\,x^{\\top}\\Sigma^{-1}x\\right) + \\frac{1}{2}\\,x^{\\top}\\Sigma^{-1}x\\\\\n= \\frac{1}{2\\beta^{2}}\\,y^{\\top}\\Sigma^{-1}y - \\frac{\\sqrt{1-\\beta^{2}}}{\\beta^{2}}\\,x^{\\top}\\Sigma^{-1}y + \\left(\\frac{1-\\beta^{2}}{2\\beta^{2}} + \\frac{1}{2}\\right)\\,x^{\\top}\\Sigma^{-1}x\\\\\n= \\frac{1}{2\\beta^{2}}\\,y^{\\top}\\Sigma^{-1}y - \\frac{\\sqrt{1-\\beta^{2}}}{\\beta^{2}}\\,x^{\\top}\\Sigma^{-1}y + \\frac{1}{2\\beta^{2}}\\,x^{\\top}\\Sigma^{-1}x.\n\\end{align*}\n类似地，展开 $E_{2}$：\n\\begin{align*}\nE_{2}\n= \\frac{1}{2\\beta^{2}}\\left(x^{\\top}\\Sigma^{-1}x - 2\\sqrt{1-\\beta^{2}}\\,y^{\\top}\\Sigma^{-1}x + (1-\\beta^{2})\\,y^{\\top}\\Sigma^{-1}y\\right) + \\frac{1}{2}\\,y^{\\top}\\Sigma^{-1}y\\\\\n= \\frac{1}{2\\beta^{2}}\\,x^{\\top}\\Sigma^{-1}x - \\frac{\\sqrt{1-\\beta^{2}}}{\\beta^{2}}\\,y^{\\top}\\Sigma^{-1}x + \\left(\\frac{1-\\beta^{2}}{2\\beta^{2}} + \\frac{1}{2}\\right)\\,y^{\\top}\\Sigma^{-1}y\\\\\n= \\frac{1}{2\\beta^{2}}\\,x^{\\top}\\Sigma^{-1}x - \\frac{\\sqrt{1-\\beta^{2}}}{\\beta^{2}}\\,x^{\\top}\\Sigma^{-1}y + \\frac{1}{2\\beta^{2}}\\,y^{\\top}\\Sigma^{-1}y,\n\\end{align*}\n这里使用了对称性 $x^{\\top}\\Sigma^{-1}y = y^{\\top}\\Sigma^{-1}x$。因此 $E_{1} = E_{2}$，这精确地证明了 $q_{\\mathrm{pCN}}(x,y)\\,\\pi(x) = q_{\\mathrm{pCN}}(y,x)\\,\\pi(y)$。因此，Metropolis-Hastings 对数接受比为\n$$\nR_{\\mathrm{p}}(x,y) = \\ln\\pi(y) - \\ln\\pi(x) + \\ln q_{\\mathrm{pCN}}(y,x) - \\ln q_{\\mathrm{pCN}}(x,y) = 0,\n$$\n且接受概率满足\n$$\n\\alpha_{\\mathrm{p}}(x,y) = \\min\\!\\left(1, \\exp(0)\\right) = 1,\n$$\n对所有的 $x,y$ 和任意的 $\\beta \\in (0,1]$ 成立。\n\n结论：\n\n对于高斯目标 $\\pi = \\mathcal{N}(0,\\Sigma)$，preconditioned Crank–Nicolson 提议是精确可逆的并且保持 $\\pi$ 不变，因此其 Metropolis-Hastings 接受概率恒等于一。相比之下，MALA 的接受分布由上面给出的随机变量 $R_{\\mathrm{M}}$ 决定，该变量通过独立标准正态变量中的双线性和二次项显式地依赖于步长 $h$ 和 $\\Sigma$ 的特征值 $\\{\\lambda_{i}\\}$；因此，除非 $h \\to 0$，MALA 的接受概率通常不为一。", "answer": "$$\\boxed{1}$$", "id": "3355277"}]}