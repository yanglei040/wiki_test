{"hands_on_practices": [{"introduction": "要掌握别名方法 (alias method)，我们必须首先理解其核心的构建过程。本练习将引导您针对一个具体给定的离散分布，一步步地应用Walker算法，从零开始构建核心的概率表和别名表 [@problem_id:3350550]。通过亲手对概率进行划分并配对结果，您将对该方法如何巧妙地将任意离散分布转换为适合 $O(1)$ 采样的形式，获得一个具体而直观的理解。", "problem": "考虑一个具有 $n$ 个类别的离散分布，其概率为 $p_{1}, p_{2}, \\dots, p_{n}$，其中 $\\sum_{i=1}^{n} p_{i} = 1$。Walker 的别名方法（alias method）为常数时间采样构建了两个数组：一个概率数组 $q$（其元素在 $[0,1]$ 区间内）和一个别名数组 $a$（由 $\\{1,2,\\dots,n\\}$ 中的整数索引组成）。该构建方法基于通过缩放概率 $s_{i} = n p_{i}$ 将类别划分为“小”类别（$s_{i}  1$）和“大”类别（$s_{i} \\ge 1$），然后将小类别与大类别配对以守恒“质量”（mass），直到所有类别都被处理完毕。得到的数组 $(q,a)$ 在标准的别名采样方案中使用时，必须能重现原始分布 $p$。该采样方案首先从 $\\{1,\\dots,n\\}$ 中均匀选择一列，然后以概率 $q$ 选择该列的主索引，或以概率 $1-q$ 选择其别名索引。\n\n对于 $n=5$ 且 $p=(0.01, 0.01, 0.01, 0.01, 0.96)$ 的具体情况，请从第一性原理出发，从缩放概率 $s_{i} = n p_{i}$ 开始，执行 Walker 的划分和配对步骤。确定最终的概率数组 $q$ 和别名数组 $a$，它们能够通过别名方法精确地编码此分布，并简要证明所构建的 $(q,a)$ 能够重现原始概率。按自然索引顺序 1 到 5 列出其条目来报告最终数组。最终答案必须是单个数学对象；请按 $(q_{1}, q_{2}, q_{3}, q_{4}, q_{5}, a_{1}, a_{2}, a_{3}, a_{4}, a_{5})$ 的顺序将两个数组呈现在一行中。无需四舍五入。", "solution": "用户要求我解决一个关于为别名方法构建查找表的问题。我已经验证了这个问题并且它是合理的。现在我来解决它。\n\n问题要求为具有 $n=5$ 个结果且概率为 $p = (0.01, 0.01, 0.01, 0.01, 0.96)$ 的离散分布构建概率数组 $q$ 和别名数组 $a$。构建过程必须遵循 Walker 别名方法的原理。\n\n首先，我们为 $i \\in \\{1, 2, 3, 4, 5\\}$ 定义缩放概率 $s_i = n p_i$。当 $n=5$ 时，我们有：\n$s_1 = 5 \\times 0.01 = 0.05$\n$s_2 = 5 \\times 0.01 = 0.05$\n$s_3 = 5 \\times 0.01 = 0.05$\n$s_4 = 5 \\times 0.01 = 0.05$\n$s_5 = 5 \\times 0.96 = 4.80$\n\n这些缩放概率的总和是 $\\sum_{i=1}^5 s_i = 4 \\times 0.05 + 4.80 = 0.20 + 4.80 = 5 = n$，符合预期。\n\n该算法的核心在于将类别划分为两个集合：“小”类别（$s_i  1$）和“大”类别（$s_i \\ge 1$）。我们维护两个工作列表，$S$ 用于小类别，$L$ 用于大类别。\n初始时：\n$S = \\{1, 2, 3, 4\\}$ 因为 $s_{1,2,3,4} = 0.05  1$。\n$L = \\{5\\}$ 因为 $s_5 = 4.80 \\ge 1$。\n\n该算法迭代地处理小类别和大类别的配对。在每一步中，我们从 $S$ 中取出一个小类别 $i$，从 $L$ 中取出一个大类别 $j$。第 $i$ 列的概率槽部分由其自身的缩放概率 $s_i$ 填充。剩余的空间 $1 - s_i$ 则由大类别 $j$ “捐赠”的概率质量来填充。\n\n让我们来追踪数组 $q$ 和 $a$ 的迭代构建过程。我们将使用缩放概率 $s_i$ 作为一个工作数组来追踪剩余的概率质量。\n\n**初始状态：**\n工作列表：$S = \\{1, 2, 3, 4\\}$，$L = \\{5\\}$\n缩放概率：$s = (0.05, 0.05, 0.05, 0.05, 4.80)$\n待构建数组：$q, a$\n\n**迭代 1：**\n1. 从 $S$ 中选择一个小类别 $i=1$，从 $L$ 中选择一个大类别 $j=5$。\n2. 第 1 列中主结果的概率被设置为其缩放概率：$q_1 = s_1 = 0.05$。\n3. 第 1 列的别名是捐赠质量的大类别：$a_1 = 5$。\n4. 填满第 1 列所需的质量为 $1 - s_1 = 1 - 0.05 = 0.95$。此质量从大类别的质量中减去：$s_5 \\leftarrow s_5 - (1-s_1) = 4.80 - 0.95 = 3.85$。\n5. 类别 1 现已完全处理。我们将其从 $S$ 中移除。\n迭代 1 后的状态：\n工作列表：$S = \\{2, 3, 4\\}$, $L = \\{5\\}$ (因为 $s_5 = 3.85 \\ge 1$)\n工作概率：$s = (\\text{已处理}, 0.05, 0.05, 0.05, 3.85)$\n数组：$q_1 = 0.05$, $a_1 = 5$。\n\n**迭代 2：**\n1. 从 $S$ 中选择小类别 $i=2$，从 $L$ 中选择大类别 $j=5$。\n2. 设置 $q_2 = s_2 = 0.05$。\n3. 设置 $a_2 = 5$。\n4. 更新 $s_5 \\leftarrow s_5 - (1-s_2) = 3.85 - 0.95 = 2.90$。\n5. 将 $i=2$ 从 $S$ 中移除。\n迭代 2 后的状态：\n工作列表：$S = \\{3, 4\\}$, $L = \\{5\\}$ (因为 $s_5 = 2.90 \\ge 1$)\n工作概率：$s = (\\dots, \\text{已处理}, 0.05, 0.05, 2.90)$\n数组：$q_1 = 0.05, q_2 = 0.05$, $a_1 = 5, a_2 = 5$。\n\n**迭代 3：**\n1. 从 $S$ 中选择小类别 $i=3$，从 $L$ 中选择大类别 $j=5$。\n2. 设置 $q_3 = s_3 = 0.05$。\n3. 设置 $a_3 = 5$。\n4. 更新 $s_5 \\leftarrow s_5 - (1-s_3) = 2.90 - 0.95 = 1.95$。\n5. 将 $i=3$ 从 $S$ 中移除。\n迭代 3 后的状态：\n工作列表：$S = \\{4\\}$, $L = \\{5\\}$ (因为 $s_5 = 1.95 \\ge 1$)\n工作概率：$s = (\\dots, \\text{已处理}, 0.05, 1.95)$\n数组：$q_{1,2,3} = 0.05$, $a_{1,2,3} = 5$。\n\n**迭代 4：**\n1. 从 $S$ 中选择小类别 $i=4$，从 $L$ 中选择大类别 $j=5$。\n2. 设置 $q_4 = s_4 = 0.05$。\n3. 设置 $a_4 = 5$。\n4. 更新 $s_5 \\leftarrow s_5 - (1-s_4) = 1.95 - 0.95 = 1.00$。\n5. 将 $i=4$ 从 $S$ 中移除。\n迭代 4 后的状态：\n工作列表：$S = \\emptyset$, $L = \\{5\\}$\n工作概率：$s = (\\dots, \\text{已处理}, 1.00)$\n数组：$q_{1,2,3,4} = 0.05$, $a_{1,2,3,4} = 5$。\n\n**终止：**\n当小类别工作列表 $S$ 为空时，循环终止。此时，任何剩余的类别（必然都在 $L$ 中）其剩余的缩放概率保证恰好为 1。在我们的例子中，类别 5 剩余的 $s_5 = 1.00$。对于这样的类别 $k$，我们将其概率槽完全由自身填充，因此 $q_k = 1$。别名 $a_k$ 将永远不会被使用，因此通常将其设置为 $k$。\n\n对于 $k=5$：\n设置 $q_5 = 1.0$。\n设置 $a_5 = 5$。\n\n**最终数组：**\n构建的数组是：\n概率数组：$q = (0.05, 0.05, 0.05, 0.05, 1.0)$\n别名数组：$a = (5, 5, 5, 5, 5)$\n\n**验证：**\n为了验证这些数组能够重现原始概率 $p_i$，我们分析采样过程。采样时，我们首先从 $\\{1, \\dots, n\\}$ 中均匀随机地选择一列 $i$（概率为 $1/n$），然后以概率 $q_i$ 采样结果 $i$，或以概率 $1-q_i$ 采样结果 $a_i$。\n\n采样结果 $k$ 的总概率 $p'_k$ 是导致此结果的所有事件的概率之和。结果 $k$ 可以由第 $k$ 列（作为主结果）生成，或者由任何满足 $a_i=k$ 的列 $i$ （作为别名结果）生成。\n从第 $k$ 列得到 $k$ 的概率是 $\\frac{1}{n}q_k$。\n从另一列 $i \\neq k$（其中 $a_i=k$）得到 $k$ 的概率是 $\\frac{1}{n}(1-q_i)$。\n结果 $k$ 的重构概率 $p'_k$ 为：\n$$p'_k = \\frac{q_k}{n} + \\sum_{i: a_i=k, i \\neq k} \\frac{1-q_i}{n}$$\n\n让我们用我们的结果（$n=5$）来检验一下：\n\n对于类别 $k \\in \\{1, 2, 3, 4\\}$：\n在我们的构建中，这些类别都没有出现在别名数组 $a$ 中。因此求和项为零。\n$p'_k = \\frac{q_k}{5} = \\frac{0.05}{5} = 0.01$。这与原始的 $p_k$ 相匹配。\n\n对于类别 $k=5$：\n第 $i=1, 2, 3, 4$ 列的别名是 $a_i=5$。同时，$a_5=5$。在这种情况下，我们的公式应用如下：\n$p'_5 = \\frac{q_5}{5} + \\sum_{i \\in \\{1,2,3,4\\}} \\frac{1-q_i}{5}$\n$p'_5 = \\frac{1.0}{5} + \\frac{(1-0.05) + (1-0.05) + (1-0.05) + (1-0.05)}{5}$\n$p'_5 = \\frac{1.0}{5} + \\frac{4 \\times 0.95}{5} = \\frac{1.0 + 3.8}{5} = \\frac{4.8}{5} = 0.96$\n这与原始的 $p_5$ 相匹配。\n\n验证完成。构建的数组 $(q,a)$ 正确地重现了原始概率分布。最终结果是 $q$ 和 $a$ 中元素的组合列表。", "answer": "$$ \\boxed{ \\begin{pmatrix} 0.05,  0.05,  0.05,  0.05,  1.0,  5,  5,  5,  5,  5 \\end{pmatrix} } $$", "id": "3350550"}, {"introduction": "在实际应用中，算法的实现常常需要处理浮点数精度问题，这些问题可能会破坏算法的先决条件。本练习探讨了这样一种情况：由于计算误差，一组未归一化的权重被错误地用于构建别名表 [@problem_id:3350552]。通过分析这一错误导致的后果，并使用总变差距离 (total variation distance) 来量化由此产生的采样偏差，您将对随机模拟实践中数值稳健性的重要性有更深刻的认识。", "problem": "考虑一个具有三个结果的分类随机变量，其结果由 $i \\in \\{1,2,3\\}$ 索引。由于上游计算中的浮点累积误差，输入的“概率”以非负权重 $w_{i}$ 的形式到达，且这些权重的和不为 $1$。具体而言，假设权重为\n$$\nw_{1} = \\frac{1}{3} + \\epsilon,\\quad w_{2} = \\frac{1}{3},\\quad w_{3} = \\frac{1}{3},\n$$\n其中 $\\epsilon  0$，而目标分布是归一化的分类分布 $p_{i} = w_{i} / \\sum_{j=1}^{3} w_{j}$。你的目标是使用别名方法从 $p$ 中采样，该方法通过将一个单位面积的矩形划分为 $3$ 个等宽的列来表示一个分类分布；每一列被分割为一个主索引和一个别名索引，从而使得分配给每个结果的总面积等于其概率。\n\n假设一位实现者在构建别名表时错误地跳过了归一化步骤，直接使用了未归一化的权重 $w_{i}$。在这个错误下，并使用别名方法的标准列面积解释，请证明为何在此特定场景下，得到的采样器在 $\\{1,2,3\\}$ 上变为均匀分布，然后通过计算目标归一化分布 $p$ 和产生的均匀分布之间的全变差距离来量化由此产生的偏差。在同一有限集上的两个离散分布 $P$ 和 $Q$ 之间的全变差距离定义为\n$$\n\\operatorname{TV}(P,Q) = \\frac{1}{2}\\sum_{i} \\left| P(i) - Q(i) \\right|.\n$$\n请提供 $\\operatorname{TV}(p, U)$ 作为 $\\epsilon$ 的函数的精确闭式表达式，其中 $U$ 表示 $\\{1,2,3\\}$ 上的均匀分布。你的最终答案必须是单一的闭式表达式；不要进行近似或四舍五入。", "solution": "该问题描述了一个场景，其中用于从离散分布中采样的别名方法被错误地实现。具体而言，实现中使用了未归一化的权重，而非和为 $1$ 的概率。我们必须首先证明为什么在此特定情况下，这个错误会导致从均匀分布中进行采样，其次，使用全变差距离来量化由此产生的偏差。\n\n设结果数量为 $n=3$。未归一化的非负权重如下所示：\n$$\nw_{1} = \\frac{1}{3} + \\epsilon, \\quad w_{2} = \\frac{1}{3}, \\quad w_{3} = \\frac{1}{3}\n$$\n其中 $\\epsilon  0$。\n\n标准的别名方法算法首先将输入概率 $p_i$ 乘以结果数量 $n$。在这个错误的实现中，权重 $w_i$ 被用来代替概率。缩放后的权重（我们记为 $w'_i$）是：\n$$\nw'_{i} = n \\cdot w_{i} = 3 \\cdot w_{i}\n$$\n代入给定的值，我们得到：\n$$\nw'_{1} = 3 \\left(\\frac{1}{3} + \\epsilon\\right) = 1 + 3\\epsilon\n$$\n$$\nw'_{2} = 3 \\left(\\frac{1}{3}\\right) = 1\n$$\n$$\nw'_{3} = 3 \\left(\\frac{1}{3}\\right) = 1\n$$\n算法的下一步（例如，Vose 算法）是将索引 $\\{1, 2, 3\\}$ 划分到两个工作列表中：一个 `Small` 列表，用于存放缩放后值小于 $1$ 的索引 $i$；一个 `Large` 列表，用于存放缩放后值大于或等于 $1$ 的索引。根据我们计算出的 $w'_i$：\n- 由于 $w'_{1} = 1 + 3\\epsilon > 1$（因为 $\\epsilon > 0$），索引 $1$ 进入 `Large` 列表。\n- 由于 $w'_{2} = 1$，索引 $2$ 进入 `Large` 列表。\n- 由于 $w'_{3} = 1$，索引 $3$ 进入 `Large` 列表。\n\n`Small` 工作列表为空，而 `Large` 工作列表包含所有索引，即 $\\{1, 2, 3\\}$。\n\n别名表构建算法的主循环通过从 `Small` 列表和 `Large` 列表中各取一项来进行平衡。由于 `Small` 列表为空，这个主循环从未被执行。算法随后完成构建过程。一个标准的实现会通过将其对应的概率表条目设置为 $1$ 来处理 `Large` 列表中的任何剩余项。因此，`Prob` 表被填充为：\n$$\n\\text{Prob}[1] = 1, \\quad \\text{Prob}[2] = 1, \\quad \\text{Prob}[3] = 1\n$$\n`Alias` 表从未被写入，因此其内容是无关紧要的。\n\n现在，我们来分析使用这个错误构建的表的采样过程。为了生成一个样本，别名方法执行以下两个步骤：\n1. 均匀随机地选择一个列索引 $i \\in \\{1, 2, 3\\}$。选择任何特定 $i$ 的概率是 $\\frac{1}{n} = \\frac{1}{3}$。\n2. 生成一个均匀随机数 $U \\sim \\text{Uniform}(0, 1)$。如果 $U  \\text{Prob}[i]$，则采样结果是 $i$。否则，结果是 $\\text{Alias}[i]$。\n\n在我们的情况下，对于所有 $i \\in \\{1, 2, 3\\}$，$\\text{Prob}[i] = 1$。由于一个来自 $[0,1]$ 上连续分布的随机变量 $U$ 满足 $U  1$ 的概率为 $1$，因此条件 $U  \\text{Prob}[i]$ 总是成立的。因此，采样器将总是返回在第一步中选择的索引 $i$。由于索引 $i$ 是从 $\\{1, 2, 3\\}$ 中均匀随机选择的，最终的采样结果服从 $\\{1, 2, 3\\}$ 上的均匀分布。我们将此分布表示为 $U$，其中对于 $i \\in \\{1, 2, 3\\}$，有 $U(i) = \\frac{1}{3}$。\n\n接下来，我们通过计算目标分布 $p$ 和产生的均匀分布 $U$ 之间的全变差距离来量化偏差。目标分布 $p$ 是通过归一化权重 $w_i$ 得到的。权重之和为：\n$$\n\\sum_{j=1}^{3} w_{j} = \\left(\\frac{1}{3} + \\epsilon\\right) + \\frac{1}{3} + \\frac{1}{3} = 1 + \\epsilon\n$$\n因此，目标分布 $p$ 的概率为：\n$$\np_{1} = \\frac{w_{1}}{\\sum w_{j}} = \\frac{\\frac{1}{3} + \\epsilon}{1 + \\epsilon}\n$$\n$$\np_{2} = \\frac{w_{2}}{\\sum w_{j}} = \\frac{\\frac{1}{3}}{1 + \\epsilon}\n$$\n$$\np_{3} = \\frac{w_{3}}{\\sum w_{j}} = \\frac{\\frac{1}{3}}{1 + \\epsilon}\n$$\n均匀分布 $U$ 对每个结果 $i \\in \\{1, 2, 3\\}$ 的概率为 $U(i) = \\frac{1}{3}$。全变差距离定义为：\n$$\n\\operatorname{TV}(p, U) = \\frac{1}{2}\\sum_{i=1}^{3} |p_{i} - U(i)|\n$$\n我们计算差值 $p_i - U(i)$：\n$$\np_{1} - U(1) = \\frac{\\frac{1}{3} + \\epsilon}{1 + \\epsilon} - \\frac{1}{3} = \\frac{3(\\frac{1}{3} + \\epsilon) - (1 + \\epsilon)}{3(1 + \\epsilon)} = \\frac{1 + 3\\epsilon - 1 - \\epsilon}{3(1 + \\epsilon)} = \\frac{2\\epsilon}{3(1+\\epsilon)}\n$$\n$$\np_{2} - U(2) = \\frac{\\frac{1}{3}}{1 + \\epsilon} - \\frac{1}{3} = \\frac{1 - (1 + \\epsilon)}{3(1 + \\epsilon)} = \\frac{-\\epsilon}{3(1+\\epsilon)}\n$$\n$$\np_{3} - U(3) = \\frac{\\frac{1}{3}}{1 + \\epsilon} - \\frac{1}{3} = \\frac{-\\epsilon}{3(1+\\epsilon)}\n$$\n由于 $\\epsilon > 0$，第一个差值为正，另外两个为负。现在我们对这些差值的绝对值求和：\n$$\n\\sum_{i=1}^{3} |p_{i} - U(i)| = \\left|\\frac{2\\epsilon}{3(1+\\epsilon)}\\right| + \\left|\\frac{-\\epsilon}{3(1+\\epsilon)}\\right| + \\left|\\frac{-\\epsilon}{3(1+\\epsilon)}\\right|\n$$\n$$\n= \\frac{2\\epsilon}{3(1+\\epsilon)} + \\frac{\\epsilon}{3(1+\\epsilon)} + \\frac{\\epsilon}{3(1+\\epsilon)} = \\frac{4\\epsilon}{3(1+\\epsilon)}\n$$\n最后，我们将此和代入全变差距离的公式中：\n$$\n\\operatorname{TV}(p, U) = \\frac{1}{2} \\left( \\frac{4\\epsilon}{3(1+\\epsilon)} \\right) = \\frac{2\\epsilon}{3(1+\\epsilon)}\n$$\n这就是目标分布与由错误采样器产生的均匀分布之间的全变差距离的精确闭式表达式。", "answer": "$$\n\\boxed{\\frac{2\\epsilon}{3(1+\\epsilon)}}\n$$", "id": "3350552"}, {"introduction": "许多现实世界的系统，从社交网络到物理模拟，都是动态变化的，这意味着其底层的概率分布会随时间演变。本练习将挑战您将别名方法应用于此类场景——一个动态图，其中采样概率与节点的度 (degree) 相关联 [@problem_id:3350522]。您将实现一种惰性更新 (lazy update) 策略，并分析在重新构建别名表的计算成本与使用过时表格所引入的统计误差之间的关键权衡。", "problem": "给定一个简单无向图节点上的离散分布，其中节点 $i$ 的概率与其度成正比，即 $p_i = d_i / \\sum_{j=1}^n d_j$。您必须实现一个基于别名方法（alias method）的采样器，该采样器支持图的动态更新（边的插入和删除），并分析在惰性更新别名表时，其均摊更新开销和引入的偏差。\n\n使用的基本原理和定义：\n- 对于具有概率 $\\{p_i\\}_{i=1}^n$ 的 $n$ 个类别的分布，可以使用别名方法以每次采样 $O(1)$ 的期望时间进行采样。该方法预先计算两个长度为 $n$ 的数组，为每个类别存储一个主概率和一个别名索引。\n- 对于一个具有度 $\\{d_i\\}_{i=1}^n$ 的简单无向图，度成正比的分布为 $p_i = d_i / W$，其中 $W = \\sum_{j=1}^n d_j = 2m$，$m$ 是边的数量。\n- 在同一有限集上的两个分布 $p$ 和 $q$ 之间的全变差（TV）距离为 $\\mathrm{TV}(p,q) = \\tfrac{1}{2}\\sum_{i=1}^n |p_i - q_i|$。\n- 您可以假设，构建一个涉及所有 $n$ 列的新别名表，每列产生单位工作量；因此，一次重建的成本为 $n$，每次抽样的成本为 $O(1)$。您不能假设除了完全重建之外存在任何高级的动态别名结构。\n\n您的任务：\n1. 为一个在 $n$ 个类别上的离散分布实现经典的别名方法构造函数。该分布由非负权重 $\\{w_i\\}_{i=1}^n$（其中 $\\sum_i w_i > 0$）给出。构造函数应生成一个范围在 $[0,1]$ 内的数组 $\\text{prob}[1..n]$ 和一个整数索引数组 $\\text{alias}[1..n]$。如果 $\\sum_i w_i = 0$，则将分布定义为均匀分布。\n2. 考虑一个具有 $n$ 个节点的动态无向图，该图有一个初始边集和一序列 $U$ 次更新。每次更新要么是插入一条当前不存在的边 $\\{u,v\\}$，要么是删除一条已存在的边 $\\{u,v\\}$。每次更新后，维护度数组 $\\{d_i\\}$ 和总权重 $W=\\sum_i d_i$。\n3. 按如下方式维护别名表：在根据初始度构建初始别名表后，仅在自上次重建以来总权重的相对变化超过用户指定的阈值 $\\epsilon \\in [0,1)$ 时（即 $\\left|W_{\\text{current}} - W_{\\text{last}}\\right| / W_{\\text{last}} > \\epsilon$），或者当达到重建间隔阈值 $K_{\\max} \\in \\mathbb{N}$ 时（即自上次重建以来已进行了 $K_{\\max}$ 次更新），才执行重建。当重建发生时，别名表将根据当前的度重新构建。在两次重建之间，采样器假定使用上一个别名表（也就是上一个分布）。\n4. 对每个测试用例，计算：\n   - 每次更新的均摊重建开销，定义为 $n \\times R / U$，其中 $R$ 是在 $U$ 次更新期间的重建次数，$n$ 是节点数。\n   - 随时间变化，当前真实的度成正比分布与别名采样器使用的上一次重建的分布之间的最大全变差距离。该距离在每次更新应用后、检查重建条件前立即测量。具体来说，如果 $\\{d_i^{(\\text{last})}\\}$ 和 $W_{\\text{last}}$ 是上次重建时的度和总权重，$\\{d_i^{(t)}\\}$ 和 $W_t$ 是第 $t$ 次更新后的度和总权重，那么每一步的距离为\n   $$\\mathrm{TV}_t = \\tfrac{1}{2}\\sum_{i=1}^n \\left| \\frac{d_i^{(\\text{last})}}{W_{\\text{last}}} - \\frac{d_i^{(t)}}{W_t} \\right|,$$\n   按照惯例，如果 $W_{\\text{last}}=0$ 或 $W_t=0$，则相应的分布为均匀分布。报告序列中所有更新的 $\\mathrm{TV}_t$ 的最大值。\n\n设计约束和分析目标：\n- 从别名方法的预计算开始，将其作为您的基础算法，并推理当权重向量变化时必须做出哪些改变。您的分析应论证使用基于 $W$ 的相对变化和/或硬上限 $K_{\\max}$ 的重建条件的合理性，并正确定义偏差度量。\n- 不要假设除了完全重建和简单的簿记之外，还能访问任何专门的动态别名数据结构。\n\n测试套件和输入规范：\n您必须硬编码并执行以下三个测试用例。每个测试用例由一个元组 $(n, E_0, \\mathcal{U}, \\epsilon, K_{\\max})$ 指定，其中 $n$ 是节点数（标记为 $0,1,\\dots,n-1$），$E_0$ 是初始边集，$\\mathcal{U}$ 是形式为 $(\\text{op}, u, v)$（其中 $\\text{op}\\in\\{\\text{\"add\"},\\text{\"del\"}\\}$）的有序更新序列，$\\epsilon$ 是相对变化阈值，$K_{\\max}$ 是重建间隔上限。\n\n- 测试用例 1 (正常路径):\n  - $n=8$,\n  - $E_0 = \\{(0,1),(1,2),(2,3),(3,4),(4,5),(5,6),(6,7),(7,0)\\}$,\n  - $\\mathcal{U} = [(\\text{\"add\"},0,2),(\\text{\"add\"},4,6),(\\text{\"del\"},1,2),(\\text{\"add\"},1,3),(\\text{\"add\"},2,6),(\\text{\"del\"},7,0),(\\text{\"add\"},0,4),(\\text{\"del\"},5,6),(\\text{\"add\"},5,7),(\\text{\"add\"},3,7),(\\text{\"del\"},0,2),(\\text{\"del\"},4,6),(\\text{\"add\"},0,7),(\\text{\"del\"},0,7)]$,\n  - $\\epsilon = 0.05$,\n  - $K_{\\max} = 10^9$.\n- 测试用例 2 (边界情况，强制精确维护):\n  - $n=10$,\n  - $E_0 = \\{(0,1),(0,2),(0,3),(0,4),(0,5),(6,7),(7,8),(8,9)\\}$,\n  - $\\mathcal{U} = [(\\text{\"add\"},0,6),(\\text{\"add\"},5,6),(\\text{\"del\"},0,3),(\\text{\"add\"},1,2),(\\text{\"del\"},8,9),(\\text{\"add\"},2,9),(\\text{\"add\"},3,9),(\\text{\"del\"},0,1),(\\text{\"del\"},0,2),(\\text{\"add\"},4,7),(\\text{\"del\"},7,8),(\\text{\"add\"},8,9),(\\text{\"del\"},6,7),(\\text{\"add\"},0,3),(\\text{\"del\"},2,9),(\\text{\"add\"},7,9)]$,\n  - $\\epsilon = 0.0$,\n  - $K_{\\max} = 1$.\n- 测试用例 3 (边缘情况，涉及孤立节点的出现和消失):\n  - $n=6$,\n  - $E_0 = \\{(0,1)\\}$,\n  - $\\mathcal{U} = [(\\text{\"add\"},2,3),(\\text{\"del\"},0,1),(\\text{\"add\"},4,5),(\\text{\"del\"},2,3),(\\text{\"add\"},0,2),(\\text{\"del\"},4,5),(\\text{\"add\"},1,5)]$,\n  - $\\epsilon = 0.2$,\n  - $K_{\\max} = 10^9$.\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。每个测试用例的结果本身必须是一个双元素列表 $[\\text{amortized\\_work}, \\text{max\\_tv}]$，其中两个条目都是四舍五入到六位小数的浮点数。因此，总输出必须看起来像\n$[[a_1,b_1],[a_2,b_2],[a_3,b_3]]$\n不含多余的空格或文本。\n\n本问题中没有物理单位。所有角度（如果有的话）都将以弧度为单位，但本题并未使用。所有概率和距离必须表示为十进制浮点数，而不是百分比。请确保科学上的真实性，并且实现遵循上述定义。程序必须是完全自包含的，不需要用户输入。", "solution": "该问题要求分析一种基于别名方法的采样器的惰性更新策略。待采样的分布源于一个动态图的度，其中概率与节点度成正比。问题的核心在于重建别名表的计算成本与使用过时表所引入的统计偏差之间的权衡。我们将通过计算在一系列图更新过程中的均摊重建开销以及真实分布与采样分布之间的最大全变差距离来分析这种权衡。\n\n解决方案的结构如下：\n1.  对用于构建常数时间采样器的别名方法的回顾。\n2.  对动态图维护过程的描述。\n3.  惰性更新策略，整合了别名方法和图动态，以及计算所需性能和偏差指标的公式。\n\n### 1. 别名方法\n别名方法提供了一种优雅的方式，在经过 $O(n)$ 的预处理步骤后，以 $O(1)$ 的时间从具有 $n$ 个结果和概率 $\\{p_i\\}_{i=1}^n$ 的离散分布中进行采样。其基本思想是将原始分布表示为 $n$ 个更简单分布的等概率混合，每个简单分布最多只有两个结果。\n\n我们构造两个数组，$\\text{prob}[1..n]$ 和 $\\text{alias}[1..n]$。采样算法如下：\n1.  从 $\\{1, 2, \\dots, n\\}$ 中均匀抽取一个随机整数 $j$。\n2.  抽取一个随机均匀值 $u \\in [0, 1)$。\n3.  如果 $u  \\text{prob}[j]$，则返回 $j$。否则，返回 $\\text{alias}[j]$。\n\n为了从一组非负权重 $\\{w_i\\}_{i=1}^n$ 构建这些表，我们首先将其归一化以获得概率 $p_i = w_i / \\sum_k w_k$。设 $n$ 为结果的数量。这个通常归功于 Vose 的构造算法将索引划分为两个集合：$S = \\{i \\mid p_i \\cdot n  1\\}$ 和 $L = \\{i \\mid p_i \\cdot n \\ge 1\\}$。然后它迭代地将一个索引 $l \\in S$ 与一个索引 $g \\in L$ 配对。对于每个这样的配对：\n-   “欠满”的列 $l$ 被填充。我们设置 $\\text{prob}[l] = p_l \\cdot n$，并将其别名设置为“超满”的索引，即 $\\text{alias}[l] = g$。\n-   填充列 $l$ 所需的概率质量 $1 - (p_l \\cdot n)$ 由结果 $g$“捐赠”。$g$ 的缩放概率被更新：$p_g' \\cdot n = (p_g \\cdot n) - (1 - p_l \\cdot n)$。\n-   然后根据其新的缩放概率对索引 $g$ 进行重新分类。\n这个过程一直持续到两个集合都为空。由于有限精度算术，任何剩余的索引都被设置为 $\\text{prob}[i] = 1.0$。\n\n如果权重之和为零，即 $\\sum_i w_i = 0$，问题指定了均匀分布 $p_i = 1/n$。在这种情况下，对于所有 $i$，$\\text{prob}[i] = p_i \\cdot n = 1$，别名条目不会被使用。\n\n### 2. 动态图维护\n我们考虑一个具有 $n$ 个节点的简单无向图。我们感兴趣的分布是 $p_i = d_i / W$，其中 $d_i$ 是节点 $i$ 的度，$W = \\sum_{j=1}^n d_j$。总度 $W$ 也等于 $2m$，其中 $m$ 是边的数量。我们必须在一系列边的插入和删除过程中维护度数组 $\\{d_i\\}_{i=1}^n$ 和总度 $W$。\n-   **初始状态：** 给定一个初始边集 $E_0$，通过计算每个节点 $i$ 在 $E_0$ 中的关联边数来计算其度 $d_i$。总度为 $W = \\sum_i d_i = 2 |E_0|$。\n-   **边插入 `(\"add\", u, v)`：** 节点 $u$ 和 $v$ 的度增加，$d_u \\leftarrow d_u + 1$ 和 $d_v \\leftarrow d_v + 1$。总度更新为 $W \\leftarrow W + 2$。\n-   **边删除 `(\"del\", u, v)`：** 节点 $u$ 和 $v$ 的度减少，$d_u \\leftarrow d_u - 1$ 和 $d_v \\leftarrow d_v - 1$。总度更新为 $W \\leftarrow W - 2$。\n\n### 3. 惰性重建策略与分析\n我们将别名方法与动态图相结合。一个初始的别名表是根据初始的度 $\\{d_i^{(0)}\\}$ 和总权重 $W_0$ 构建的。这个状态 $(d^{(0)}, W_0)$ 被存储为“上次重建”的状态，即 $(\\{d_i^{(\\text{last})}\\}, W_{\\text{last}})$。\n\n然后我们处理一个包含 $U$ 次更新的序列。对于每次更新 $t \\in \\{1, \\dots, U\\}$：\n1.  **更新图：** 根据边的操作更新度 $\\{d_i^{(t)}\\}$ 和总权重 $W_t$。\n2.  **计算偏差：** 偏差通过当前真实分布 $p^{(t)}$ 与采样器陈旧的别名表所对应的分布 $p^{(\\text{last})}$ 之间的全变差（TV）距离来衡量。这个距离在更新后立即计算：\n    $$ \\mathrm{TV}_t = \\frac{1}{2} \\sum_{i=1}^n \\left| p_i^{(t)} - p_i^{(\\text{last})} \\right| = \\frac{1}{2} \\sum_{i=1}^n \\left| \\frac{d_i^{(t)}}{W_t} - \\frac{d_i^{(\\text{last})}}{W_{\\text{last}}} \\right| $$\n    如果 $W_t=0$ 或 $W_{\\text{last}}=0$，则相应的分布被视为均匀分布，即 $p_i = 1/n$。在所有 $t$ 中最大的 $\\mathrm{TV}_t$ 会被追踪。\n3.  **检查重建条件：** 如果满足以下两个条件之一，则触发别名表的重建：\n    a. 总权重的相对变化超过阈值 $\\epsilon$：$|\\frac{W_t - W_{\\text{last}}}{W_{\\text{last}}}| > \\epsilon$。如果 $W_{\\text{last}} = 0$，当 $W_t > 0$ 时触发重建，因为这代表了无限的相对变化。\n    b. 自上次重建以来的更新次数达到指定的间隔 $K_{\\max}$。\n4.  **执行重建：** 如果触发重建，重建次数 $R$ 增加，根据当前状态 $(\\{d_i^{(t)}\\}, W_t)$ 构建一个新的别名表，该状态成为新的“上次重建”状态，并且自上次重建以来的更新计数器被重置。\n\n在处理完所有 $U$ 次更新后，计算两个所需的指标：\n-   **均摊重建开销：** 重建的总开销为 $n \\times R$，其中 $n$ 是一次重建的成本，$R$ 是更新序列中的总重建次数。每次更新的均摊开销为 $\\frac{n \\times R}{U}$。\n-   **最大全变差距离：** 这是在整个模拟过程中观测到的 $\\mathrm{TV}_t$ 的最大值。\n\n这个框架使我们能够系统地评估给定测试用例下惰性更新方案的性能。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the simulation for all test cases.\n    \"\"\"\n    test_cases = [\n        (\n            8,\n            [(0, 1), (1, 2), (2, 3), (3, 4), (4, 5), (5, 6), (6, 7), (7, 0)],\n            [(\"add\", 0, 2), (\"add\", 4, 6), (\"del\", 1, 2), (\"add\", 1, 3), (\"add\", 2, 6), (\"del\", 7, 0), (\"add\", 0, 4), (\"del\", 5, 6), (\"add\", 5, 7), (\"add\", 3, 7), (\"del\", 0, 2), (\"del\", 4, 6), (\"add\", 0, 7), (\"del\", 0, 7)],\n            0.05,\n            10**9\n        ),\n        (\n            10,\n            [(0, 1), (0, 2), (0, 3), (0, 4), (0, 5), (6, 7), (7, 8), (8, 9)],\n            [(\"add\", 0, 6), (\"add\", 5, 6), (\"del\", 0, 3), (\"add\", 1, 2), (\"del\", 8, 9), (\"add\", 2, 9), (\"add\", 3, 9), (\"del\", 0, 1), (\"del\", 0, 2), (\"add\", 4, 7), (\"del\", 7, 8), (\"add\", 8, 9), (\"del\", 6, 7), (\"add\", 0, 3), (\"del\", 2, 9), (\"add\", 7, 9)],\n            0.0,\n            1\n        ),\n        (\n            6,\n            [(0, 1)],\n            [(\"add\", 2, 3), (\"del\", 0, 1), (\"add\", 4, 5), (\"del\", 2, 3), (\"add\", 0, 2), (\"del\", 4, 5), (\"add\", 1, 5)],\n            0.2,\n            10**9\n        )\n    ]\n\n    all_results = []\n    for n, e0, updates, epsilon, k_max in test_cases:\n        result = run_simulation(n, e0, updates, epsilon, k_max)\n        all_results.append([f\"{res:.6f}\" for res in result])\n\n    # Format the final output string\n    formatted_results = [f\"[{res[0]},{res[1]}]\" for res in all_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef run_simulation(n, e0, updates, epsilon, k_max):\n    \"\"\"\n    Runs the simulation for a single test case.\n    \"\"\"\n    #\n    # Helper functions\n    #\n    def build_alias_table(weights):\n        \"\"\"\n        Constructs the alias and probability tables for a given set of weights.\n        This function simulates the work but doesn't store the tables globally\n        as they are not used for sampling, only for rebuilding cost.\n        \"\"\"\n        w_sum = np.sum(weights)\n        if w_sum == 0:\n            return  # Uniform case, simple setup\n\n        probs = weights / w_sum\n        scaled_probs = probs * n\n        \n        small = [i for i, p in enumerate(scaled_probs) if p  1.0]\n        large = [i for i, p in enumerate(scaled_probs) if p >= 1.0]\n\n        _alias = np.zeros(n, dtype=int)\n        _prob = np.zeros(n)\n\n        while small and large:\n            l, g = small.pop(), large.pop()\n            _prob[l] = scaled_probs[l]\n            _alias[l] = g\n            scaled_probs[g] += scaled_probs[l] - 1.0\n            if scaled_probs[g]  1.0:\n                small.append(g)\n            else:\n                large.append(g)\n        \n        while large:\n            _prob[large.pop()] = 1.0\n        while small:\n            _prob[small.pop()] = 1.0\n\n    def get_probabilities(degrees, W):\n        \"\"\"\n        Calculates the probability distribution from degrees and total weight.\n        Handles the W=0 case by returning a uniform distribution.\n        \"\"\"\n        if W == 0:\n            return np.ones(n) / n\n        return degrees / W\n\n    #\n    # Main simulation logic\n    #\n    degrees = np.zeros(n, dtype=int)\n    for u, v in e0:\n        degrees[u] += 1\n        degrees[v] += 1\n    W = np.sum(degrees)\n    \n    # State at last rebuild\n    degrees_last = degrees.copy()\n    W_last = W\n    \n    # Simulate initial build\n    build_alias_table(degrees_last.astype(float))\n    \n    # Simulation metrics\n    num_rebuilds = 0\n    updates_since_rebuild = 0\n    max_tv = 0.0\n    U = len(updates)\n    \n    if U == 0:\n        return [0.0, 0.0]\n\n    for op, u, v in updates:\n        # 1. Update graph state\n        if op == \"add\":\n            degrees[u] += 1\n            degrees[v] += 1\n            W += 2\n        elif op == \"del\":\n            degrees[u] -= 1\n            degrees[v] -= 1\n            W -= 2\n        \n        updates_since_rebuild += 1\n        \n        # 2. Calculate Total Variation distance\n        p_current = get_probabilities(degrees, W)\n        p_last = get_probabilities(degrees_last, W_last)\n        tv_dist = 0.5 * np.sum(np.abs(p_current - p_last))\n        max_tv = max(max_tv, tv_dist)\n        \n        # 3. Check rebuild condition\n        rebuild_needed = False\n        if W_last > 0:\n            if abs(W - W_last) / W_last > epsilon:\n                rebuild_needed = True\n        elif W > 0: # W_last was 0, but W is now positive\n            rebuild_needed = True\n        \n        if updates_since_rebuild >= k_max:\n            rebuild_needed = True\n\n        # 4. Perform rebuild if needed\n        if rebuild_needed:\n            num_rebuilds += 1\n            updates_since_rebuild = 0\n            \n            degrees_last = degrees.copy()\n            W_last = W\n            \n            # Simulate the work of rebuilding the alias table\n            build_alias_table(degrees_last.astype(float))\n\n    amortized_work = n * num_rebuilds / U\n    \n    return [amortized_work, max_tv]\n\nsolve()\n```", "id": "3350522"}]}