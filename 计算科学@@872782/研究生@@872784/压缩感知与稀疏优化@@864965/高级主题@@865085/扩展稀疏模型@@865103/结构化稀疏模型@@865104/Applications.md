## 应用与跨学科连接

在前面的章节中，我们已经深入探讨了结构化[稀疏模型](@entry_id:755136)的基本原理和核心机制。这些模型通过施加超越传统稀疏性（即简单地计算非零项的个数）的先验知识，为我们提供了更强大、更具解释性的工具来捕捉现实世界信号与数据中蕴含的复杂结构。理论固然重要，但一个模型的真正价值在于其应用。本章旨在展示结构化[稀疏模型](@entry_id:755136)在解决不同学科领域的实际问题中的强大威力与广泛适用性。

我们将不再重复介绍核心概念，而是将[焦点](@entry_id:174388)放在这些概念的实际应用上。通过一系列来自信号处理、机器学习、医学成像、[地球物理学](@entry_id:147342)乃至[优化理论](@entry_id:144639)等领域的应用案例，我们将看到[结构化稀疏性](@entry_id:636211)是如何作为一种统一的语言，来描述和利用从分段平滑性、多尺度关联性到[神经网](@entry_id:276355)络的模块化结构等各种内在规律的。我们的目标是揭示这些模型如何将抽象的数学原理转化为解决具体科学和工程挑战的有效策略，从而弥合理论与实践之间的鸿沟。

### 信号与图像处理：捕捉自然结构

[结构化稀疏性](@entry_id:636211)在信号与图像处理领域找到了最自然、最直观的应用。因为自然信号本身就充满了各种可以用结构化[稀疏模型](@entry_id:755136)精确描述的规律。

#### 分段平滑性与总变分

许多一维信号和二维图像的一个共同特征是它们由大片平滑或近似恒定的区域组成，这些区域之间由清晰的边缘隔开。例如，一张医学CT图像中的不同组织、或是一个音频信号中的静音片段。这类信号被称为“分段平滑”或“分段常数”信号。尽管这类信号本身通常是“稠密”的（即大部分像素或采样点的值都非零），但它们的内在结构可以通过一个简单的变换来揭示。

[分析稀疏模型](@entry_id:746433)为此提供了完美的数学框架。考虑一个[分析算子](@entry_id:746429) $\Omega$，它代表[离散梯度](@entry_id:171970)。当这个算子作用于一个[分段常数信号](@entry_id:753442) $x$ 时，在其值保持恒定的区域内，梯度为零；只有在区域之间的边界处，梯度才非零。因此，信号 $x$ 的梯度 $\Omega x$ 是稀疏的。一个信号是“共稀疏”的，意味着它在某个[分析算子](@entry_id:746429) $\Omega$ 的作用下是稀疏的。

这种结构与信号的复杂度之间存在着精确的数学关系。例如，对于一个长度为 $n$ 的一维[分段常数信号](@entry_id:753442)，如果它由 $m$ 个连续的常数段构成，那么它必然有 $m-1$ 个“跳变”或非零梯度。由于总共有 $n-1$ 个可能的位置可以发生跳变，所以其[梯度向量](@entry_id:141180)中的零元素个数（即共稀疏度）精确地等于 $(n-1) - (m-1) = n-m$。这个简单的关系构成了总变分（Total Variation, TV）正则化的基础，后者通过惩罚[梯度向量](@entry_id:141180)的 $\ell_1$ 范数来促进解的分段常数结构。此外，给定一个梯度为零的位置集合（即共支撑集），所有满足这些零梯度约束的信号构成一个[线性子空间](@entry_id:151815)，其维度恰好等于信号中独立常数段的数量 $m$。这为理解[TV正则化](@entry_id:756242)[解空间](@entry_id:200470)的几何结构提供了深刻的洞见 [@problem_id:3431216]。

#### [多尺度结构](@entry_id:752336)与小波树

自然图像的另一个显著特征是其结构在不同尺度上的持久性。例如，一个物体的轮廓在图像的粗略（低分辨率）版本和精细（高分辨率）版本中都存在。标准的[小波变换](@entry_id:177196)通过将图像分解为不同尺度和方向的细节分量，为捕捉这种[多尺度结构](@entry_id:752336)提供了强有力的工具。

在二维可分离[小波变换](@entry_id:177196)中，一个图像在每个尺度上被分解为一个低频近似[子带](@entry_id:154462)（LL）和三个高频细节[子带](@entry_id:154462)（LH、HL、HH），分别对应水平、垂直和对角线方向的细节。由于尺度之间的二进剖分关系，一个位于较粗尺度 $j$、空间位置为 $[k_1, k_2]$ 的[小波系数](@entry_id:756640)，其空间覆盖区域恰好对应于更精细尺度 $j+1$ 上一个 $2 \times 2$ 的系数块。这些子系数的空间索引为 $[2k_1+\delta_1, 2k_2+\delta_2]$，其中 $(\delta_1, \delta_2) \in \{0,1\}^2$。

这种“一对四”的映射关系，在将同一方向（如LH）的各尺度系数连接起来时，自然地形成了一个[四叉树](@entry_id:753916)结构。图像中的边缘等重要特征，会在小波域中表现为一连串具有较大能量的系数，它们沿着树的路径从根（粗尺度）向叶（细尺度）传播。因此，重要的信息不是以孤立的非零系数形式存在，而是以“活化”的子树形式出现。这就催生了多种基于树的结构化[稀疏模型](@entry_id:755136)，它们假设非零[小波系数](@entry_id:756640)构成一个（或少数几个）连通的、向下闭合的子树。这种模型比简单的[稀疏模型](@entry_id:755136)更能有效地捕捉图像的内在几何结构，并在图像压缩和去噪等领域取得了巨大成功 [@problem_id:3494189]。

#### 在医学成像中的应用：[压缩感知磁共振成像](@entry_id:747584)（CS-MRI）

结构化[稀疏模型](@entry_id:755136)在医学成像领域，尤其是在加速[磁共振成像](@entry_id:153995)（MRI）方面，扮演着至关重要的角色。MRI的原始数据是在频率域（$k$-空间）中采集的，通过[傅里叶逆变换](@entry_id:178300)得到最终的图像。为了缩短扫描时间，[压缩感知](@entry_id:197903)（CS）理论允许我们只采集一部分$k$-空间数据，然后利用图像的[稀疏性](@entry_id:136793)来精确重建。

此时，一个关键问题是：应该选择哪种[稀疏模型](@entry_id:755136)？两种主流的选择分别是：
1. **综合[稀疏模型](@entry_id:755136)**：假设图像 $x$ 可以由一个冗余小波字典 $D$ 和一个稀疏系数向量 $\alpha$ 合成，即 $x=D\alpha$。
2. **[分析稀疏模型](@entry_id:746433)**：假设图像 $x$ 的梯度 $\nabla x$ 是稀疏的（即总变分稀疏）。

虽然当变换是正交基时这两个模型是等价的，但在实践中，无论是冗余小波字典还是[梯度算子](@entry_id:275922)，都不是正交基，因此这两个模型有着本质的区别。综合模型将解空间限制在字典 $D$ 的值域内，而分析模型没有这个限制。在MRI中，由于$k$-空间的[欠采样](@entry_id:272871)模式（例如，[笛卡尔坐标](@entry_id:167698)下的周期性[欠采样](@entry_id:272871)）会产生具有特定结构的相干伪影（aliasing artifacts），这两种模型对伪影的抑制能力也不同。[小波变换](@entry_id:177196)和总变分代表了两种不同的图像先验知识——[小波系数](@entry_id:756640)[稀疏性](@entry_id:136793)对应图像在多尺度上的平滑性，而总变分[稀疏性](@entry_id:136793)对应分段常数结构。因此，它们产生的重建图像可能存在差异。尽管这两个模型通常不等价，但在某些理想情况下，如果真实图像恰好同时满足两种模型的稀疏性假设，并且测量算子也满足相应的恢复条件，那么它们有可能产生相同的重建结果 [@problem_id:3445047]。这凸显了在具体应用中，仔细选择与信号物理特性相匹配的结构化[稀疏模型](@entry_id:755136)的重要性。

### 机器学习与数据科学：从模型剪枝到鲁棒性

[结构化稀疏性](@entry_id:636211)不仅在处理自然信号方面卓有成效，在更广泛的机器学习和数据科学领域，它也成为应对模型复杂性、提升鲁棒性和可解释性的关键技术。

#### 控制[统计模型](@entry_id:165873)的复杂度

在[高维统计](@entry_id:173687)学习中，一个核心挑战是“[维度灾难](@entry_id:143920)”。考虑一个包含 $d$ 个输入特征的[广义线性模型](@entry_id:171019)。为了捕捉特征之间的非[线性关系](@entry_id:267880)，我们可能需要引入交互项。即使只考虑最高 $q$ 阶的交互项，总的潜在特征数量也会呈[组合爆炸](@entry_id:272935)式增长，其数量为 $\sum_{r=1}^{q} \binom{d}{r}$。例如，在一个有 $d=100$ 个原始特征的模型中，仅仅包含二阶和三阶交互项就会产生超过16万个新特征，这使得模型训练和解释变得极为困难。

[结构化稀疏性](@entry_id:636211)为此提供了一个优雅的解决方案。通过引入“强[层次稀疏性](@entry_id:750268)”假设——即一个交互项只有在其所有低阶组成成分（包括主效应）都“活跃”时才能被激活——我们可以极大地削减[模型空间](@entry_id:635763)。例如，如果我们先验地知道只有 $k$ 个主效应是重要的（其中 $k \ll d$），并只允许在这 $k$ 个特征之间构建交互项，那么模型的潜在特征总数将急剧下降至 $\sum_{r=1}^{q} \binom{k}{r}$。在前面的例子中，如果只有 $k=10$ 个特征是活跃的，那么包含到三阶交互项的模型只需要考虑175个特征，相比于无约束情况下的16万多个，这是一个巨大的缩减。这种方法不仅有效控制了模型的复杂度，也体现了“重要特征之间的交互才可能是重要的”这一直观假设 [@problem_id:3181631]。

#### [深度神经网络](@entry_id:636170)的[结构化剪枝](@entry_id:637457)

现代[深度神经网络](@entry_id:636170)模型通常包含数百万甚至数十亿个参数，这给模型的存储、部署和计算带来了巨大挑战。模型剪枝是一种有效的压缩技术，其目标是在不显著影响模型性能的前提下，移除冗余的参数。简单的权重剪枝（将接近零的单个权重设为零）会产生非结构化的稀疏权重矩阵，这种[稀疏性](@entry_id:136793)很难在现代硬件（如GPU）上实现有效加速。

为了解决这个问题，研究者们提出了[结构化剪枝](@entry_id:637457)，其目标是移除整个结构单元，例如[卷积神经网络](@entry_id:178973)中的整个滤波器或通道。这对应于将与该单元相关的一组权重参数同时设为零。组稀疏（Group Sparsity）模型为此提供了完美的正则化工具。通过将每个结构单元（如一个滤波器）的权重作为一个“组”，并使用混合 $\ell_1/\ell_2$ 范数 $\Omega(w) = \sum_j \|w_{G_j}\|_2$ 作为正则化项，我们可以鼓励整个组的权重同时变为零。这种正则化项的[近端算子](@entry_id:635396)（proximal operator）是一种被称为“[块软阈值](@entry_id:746891)”（block soft-thresholding）的操作，它会对每个组的范数进行[软阈值](@entry_id:635249)收缩。如果一个组的范数小于某个阈值，这个组内所有的权重将同时被精确地置为零，从而实现对整个滤波器的剪枝，得到一个更小、计算更高效的模型 [@problem_id:3461736]。

#### 鲁棒矩阵恢复：[推荐系统](@entry_id:172804)与视频分析

在许多[数据科学应用](@entry_id:276818)中，我们面临的问题可以被建模为从不完整或损坏的观测中恢复一个大型矩阵。一个强大的假设是，这个矩阵具有低秩（low-rank）结构。结构化[稀疏模型](@entry_id:755136)在这里以“低秩+稀疏”分解的形式出现。

一个经典的应用是[视频背景减除](@entry_id:756500)。将视频的每一帧拉成一个列向量并堆叠起来，可以形成一个数据矩阵 $M$。如果背景是静态的，那么所有背景帧都是高度相关的，使得构成背景的子矩阵 $L$ 是低秩的。而视频中的前景物体（如移动的行人或车辆）通常只占据每帧图像的一小部分，并在时间上是短暂的，因此构成前景的子矩阵 $S$ 是稀疏的。于是，视频分解问题就变成了[鲁棒主成分分析](@entry_id:754394)（Robust Principal Component Analysis, RPCA）问题：$M = L + S$。理论分析表明，在某些非相干性条件下，只要稀疏分量的非零项数量 $\|S\|_0$ 和低秩分量的秩 $r$ 足够小（例如，满足 $(m+n-r)r + \|S\|_0 \le mn$ 的维度计数界限），这种分解就是唯一可识别的 [@problem_id:3431754]。

同样的想法也适用于[推荐系统](@entry_id:172804)。一个用户对物品的[评分矩阵](@entry_id:172456)通常被认为是近似低秩的，因为用户的偏好可以由少数几个潜在因子（如电影的类型、导演、演员等）来解释。然而，真实数据中可能包含恶意的或错误的评分，这些可以被看作是稀疏的大幅值噪声。在这种情况下，RPC[A模型](@entry_id:158323)再次适用，它将[评分矩阵](@entry_id:172456)分解为一个代表真实用户偏好的低秩矩阵和一个代表恶意评分的[稀疏矩阵](@entry_id:138197)。相比于那些只在单个数据点层面进行鲁棒处理（例如使用Huber损失）但不利用全局结构的方法，RPCA通过显式地分离低秩和稀疏成分，能够更有效地利用所有观测数据之间的共享潜在因子结构，从而更准确地恢复潜在的[评分矩阵](@entry_id:172456)并识别出异常评分 [@problem_id:3468077]。

### 先进科学与工程应用

除了在信号处理和机器学习中的广泛应用，结构化[稀疏模型](@entry_id:755136)也在许多前沿科学与工程领域中成为解决复杂[逆问题](@entry_id:143129)的关键。

#### [地球物理反演](@entry_id:749866)：选择正确的先验

在[地球物理学](@entry_id:147342)中，研究人员通过地表观测数据（如[地震波](@entry_id:164985)记录）来推断地下介质的物理属性（如速度或阻抗）。这是一个典型的逆问题。[结构化稀疏性](@entry_id:636211)在这里的作用是提供符合地球物理规律的正则化先验。

模型的选择至关重要，因为它必须反映我们对地下结构的物理认知。例如，在地震勘探中，地下的层状结构会导致[声阻抗](@entry_id:267232)的突变，从而产生一个稀疏的[反射系数](@entry_id:194350)序列 $r$。在这种情况下，最自然的模型是一个综合[稀疏模型](@entry_id:755136)，它假设 $r$ 本身就是稀疏的（即由少数几个脉冲组成）。相反，如果要反演的是一个由几块不同岩性组成的大尺度速度模型 $x$，那么这个模型本身是“块状”或分段常数的。它本身不稀疏，但其梯度 $\nabla x$ 是稀疏的。此时，一个[分析稀疏模型](@entry_id:746433)（如总[变分正则化](@entry_id:756446)）则是更合适的选择。错误地将[稀疏性](@entry_id:136793)先验用于速度模型 $x$ 本身，会导致模型偏向于产生孤立的尖峰，这与块状的地质结构完全不符。这个例子清晰地说明了，结构化[稀疏模型](@entry_id:755136)的选择必须由问题背后的物理或领域知识来驱动 [@problem_id:3580607]。

#### [核磁共振波谱学](@entry_id:155257)：超越简单[稀疏性](@entry_id:136793)

在化学和生物学中，[多维核磁共振](@entry_id:752272)（NMR）波谱是确定[分子结构](@entry_id:140109)的核心技术之一。为了缩短漫长的实验时间，[非均匀采样](@entry_id:752610)（Non-Uniform Sampling, NUS）结合压缩感知技术被广泛应用。标准的CS-NMR假设NMR谱在傅里叶域（或尖峰基）中是稀疏的，即由少数孤立的尖峰组成。

然而，在许多高级NMR实验（如[NOESY](@entry_id:185702)）中，真实的谱图特征远比孤立的尖峰复杂。由于[标量耦合](@entry_id:203370)（$J$-coupling）、[化学交换](@entry_id:155955)或弛豫效应，谱峰可能表现为结构化的“[多重峰](@entry_id:195830)”（即一簇紧密间隔的[谱线](@entry_id:193408)）或沿某个轴向延伸的“山脊状”特征。在传统的尖峰基下，这些结构化特征不再是稀疏的，一个山脊可能需要横跨数十个[傅里叶基](@entry_id:201167)函数来表示，这严重违反了CS的基本假设，导致重建质量下降。

结构化[稀疏模型](@entry_id:755136)为此提供了两种强大的解决方案。第一种是采用更复杂的分析模型，例如，通过组稀疏或总[变分正则化](@entry_id:756446)来捕捉谱峰系数在[频域](@entry_id:160070)中的聚集或连续性。第二种，也是更根本的一种方法，是放弃通用的尖峰基，转而构建一个更专业的综合字典。这个字典的“原子”不再是简单的尖峰，而是模拟了真实NMR[谱线形状](@entry_id:172308)（如[洛伦兹线型](@entry_id:165845)）或常见多重峰模式的函数。在这样一个量身定制的字典中，一个复杂的[多重峰](@entry_id:195830)或山脊可能只需要一个或几个系数就能精确表示，从而恢复了信号的稀疏性，并显著提高了重建质量 [@problem_id:3715719]。

#### 解决双[线性[逆问](@entry_id:751313)题](@entry_id:143129)：[盲解卷积](@entry_id:265344)

许多逆问题比 $y=Ax$ 形式的线性问题更具挑战性。一个典型的例子是[盲解卷积](@entry_id:265344)问题，其模型为 $y = h \circledast x$，其中观测信号 $y$ 是一个未知信号 $x$ 与一个未知滤波器 $h$ 的卷积。这是一个双线性问题，因为未知量 $h$ 和 $x$ 相乘。这类问题通常是严重不适定的，因为存在无穷多的 $(h,x)$ 对可以产生相同的 $y$。

为了解决这种不确定性，必须引入关于 $h$ 和 $x$ 的强先验知识。[结构化稀疏性](@entry_id:636211)提供了一种强大的正则化手段。例如，我们可以假设滤波器 $h$ 是短支撑的（即只有少数几个非零系数），同时假设信号 $x$ 在某个变换域（如[小波](@entry_id:636492)域）中具有树状[稀疏结构](@entry_id:755138)。这种强结构性约束极大地缩小了可行解的空间，使得从观测 $y$ 中唯一地（在尺度等模糊性之外）恢复 $h$ 和 $x$ 成为可能。理论分析表明，在某些条件下，所需要的样本数量 $N$ 与问题的内在自由度（由 $h$ 的长度和 $x$ 的树稀疏度 $K$ 决定）以及[傅里叶基](@entry_id:201167)与[小波基](@entry_id:265197)之间的非相干性 $\mu$ 相关，例如 $N \gtrsim C \mu^2 (L_h + K \ln(b))$ [@problem_id:3450677]。这展示了结构化[稀疏模型](@entry_id:755136)在解决极具挑战性的[非线性](@entry_id:637147)/双[线性[逆问](@entry_id:751313)题](@entry_id:143129)中的潜力。

#### 学习结构：基于树稀疏的[字典学习](@entry_id:748389)

在前面的例子中，我们大多假设用于[稀疏表示](@entry_id:191553)的字典或变换（如[小波](@entry_id:636492)）是预先给定的。然而，在某些应用中，我们可能希望从数据本身中学习出最适合的原[子集](@entry_id:261956)合，即“[字典学习](@entry_id:748389)”。[结构化稀疏性](@entry_id:636211)同样可以被整合到[字典学习](@entry_id:748389)的框架中。

标准的[字典学习](@entry_id:748389)算法（如[K-SVD](@entry_id:182204)）在[稀疏编码](@entry_id:180626)步骤中通常使用OMP等算法来寻找每个数据样本的[稀疏表示](@entry_id:191553)。我们可以通过将OMP替换为具有结构约束的贪婪算法（如树状OMP, Tree-OMP）来引入结构先验。Tree-OMP在每一步选择原子时，会保证所选的原[子集](@entry_id:261956)合始终构成一个预定义树中的连通子树。随后，在字典更新步骤中，可以借鉴[K-SVD](@entry_id:182204)的思想，通过对残差矩阵进行低秩逼近来更新每个原子及其对应的系数。通过这种方式，学习到的字典和[稀疏编码](@entry_id:180626)会共同遵循给定的树状结构，从而产生更具解释性和可能更高效的表示。这种方法不仅提升了[稀疏表示](@entry_id:191553)的性能，也展示了[结构化稀疏性](@entry_id:636211)可以作为一种强大的先验，指导[表示学习](@entry_id:634436)本身的过程 [@problem_id:3444123]。

### 与[优化理论](@entry_id:144639)的连接：为何算法收敛如此之快？

结构化[稀疏模型](@entry_id:755136)不仅在建模方面表现出色，它们所催生的[优化问题](@entry_id:266749)也具有良好的数学性质，这直接关系到求解算法的效率。许多结构化稀疏问题可以被表述为一个复合凸[优化问题](@entry_id:266749)：最小化 $F(x) = f(x) + g(x)$，其中 $f(x)$ 是一个光滑的数据保真项（如最小二乘损失），$g(x)$ 是一个非光滑但凸的结构化稀疏正则项（如 $\ell_1$ 范数、总变分或核范数）。

解决这类问题的标准算法是[近端梯度法](@entry_id:634891)（Proximal Gradient Method）。对于一般的凸问题，该算法的收敛速率是次线性（sublinear）的，即目标函数的误差以 $\mathcal{O}(1/k)$ 的速度下降，其中 $k$ 是迭代次数。然而，在实践中，人们惊奇地发现，当应用于许多结构化稀疏问题时，[近端梯度法](@entry_id:634891)的收敛速度远快于这个最坏情况的保证，常常表现出线性（linear）收敛，即误差以 $\mathcal{O}(\rho^k)$ 的速度下降，其中 $\rho \in (0,1)$。

这种加速并非偶然，而是源于结构化稀疏正则项赋予目标函数的良好几何特性。尽管 $F(x)$ 可能不是全局强凸的，但它常常在解集附近满足一些更弱的[正则性条件](@entry_id:166962)，例如：
- **误差界（Error Bound）**：该条件将解的距离与某个“残差度量”（如近端梯度映射的范数 $\|G_{\alpha}(x)\|$）联系起来，例如 $\operatorname{dist}(x, X^\star) \le \mu \|G_{\alpha}(x)\|$。
- **二次增长（Quadratic Growth）条件**：该条件要求函数值在其最小值附近至少以二次方的速度增长，即 $F(x) - F^\star \ge \frac{\sigma}{2} \operatorname{dist}(x, X^\star)^2$。
- **Kurdyka-Łojasiewicz (KL) 性质**：这是一个更一般的几何性质，刻画了函数在[临界点](@entry_id:144653)附近的“陡峭”程度。

这些条件中的任何一个，只要成立，就足以保证[近端梯度法](@entry_id:634891)（使用固定步长）的R-[线性收敛](@entry_id:163614)。关键在于，对于许多在信号处理和机器学习中至关重要的结构化[稀疏模型](@entry_id:755136)，例如使用 $\ell_1$ 范数、总变分、组稀疏范数或[核范数](@entry_id:195543)的问题，这些条件（特别是在某些受限强凸性条件下）是成立的。因此，结构化[稀疏模型](@entry_id:755136)不仅为我们提供了强大的建模工具，其良好的几何性质也为高效的算法求解提供了理论保障 [@problem_id:2897806]。

### 更广阔的连接：子[模函数](@entry_id:155728)与组合结构

[结构化稀疏性](@entry_id:636211)的概念还可以被推广到更广泛的组合结构中，其中子[模函数](@entry_id:155728)（submodular function）扮演了核心角色。子[模函数](@entry_id:155728)是定义在集合上的函数，它具有“收益递减”的性质，可以被看作是[凸函数](@entry_id:143075)在离散组合世界中的对应物。

许多[结构化稀疏性](@entry_id:636211)模式，特别是那些涉及元素分组或连通性的模式，都可以通过子[模函数](@entry_id:155728)来描述。一个典型的例子是图上的连通性。考虑一个在一维链图上定义的[信号去噪](@entry_id:275354)问题。标准 $\ell_1$ 范数正则化是可分的，它独立地对每个系数进行惩罚，因此其解的支撑集可能是零散的。然而，如果我们希望解的非零元素形成一个或几个连续的块，我们可以使用一个惩罚支撑集“边界”大小的正则项。这个边界项，即图割（graph cut）函数，是一个典型的子[模函数](@entry_id:155728)。

例如，给定一个观测向量 $y = (0.1, 0.9, 0.4, 0.45, 0.88, 0.1)$，$\ell_1$ 范数去噪（[LASSO](@entry_id:751223)）可能会选择性地保留第2和第5个元素，因为它们的幅值最大，得到一个非连通的支撑集 $\{2, 5\}$。相比之下，使用图割作为惩罚项的结构化模型会发现，虽然将中间的第3和第4个元素也包含进来会增加一些数据拟合误差，但它会显著减少惩罚项（从4个边界边减少到2个边界边）。在适当的正则化参数下，后者得到的总目标函数值更小，从而偏向于选择连通的支撑集 $\{2, 3, 4, 5\}$。这个例子生动地说明了，通过引入基于图的[子模](@entry_id:148922)惩罚，我们可以超越基于范数的稀疏性，直接对解的组合结构（如连通性）进行建模 [@problem_id:3483767]。这为在各种应用中施加更复杂的、[非线性](@entry_id:637147)的结构化先验开辟了新的可能性。