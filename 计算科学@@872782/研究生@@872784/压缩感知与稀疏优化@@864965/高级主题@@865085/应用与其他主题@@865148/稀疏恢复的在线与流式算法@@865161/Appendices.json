{"hands_on_practices": [{"introduction": "在流式应用中，数据和模型参数会随时间漂移。一个关键问题是，在估计器的基本结构（例如所选特征的集合）发生改变之前，它能容忍多大的漂移。本练习 [@problem_id:3463869] 将引导您对 Lasso 解进行稳定性分析，从第一性原理出发，推导稀疏支撑集保持不变的条件，这是设计鲁棒在线算法的一个关键概念。", "problem": "考虑用于时变数据的流式最小绝对收缩和选择算子 (Lasso)，其在时间 $t$ 的目标函数定义为\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2}\\|A_t x - y_t\\|_{2}^{2} + \\lambda_t \\|x\\|_{1},\n$$\n其中 $A_t \\in \\mathbb{R}^{m \\times n}$ 是设计矩阵，$y_t \\in \\mathbb{R}^{m}$ 是观测值，$\\lambda_t > 0$ 是正则化参数。您的任务是开发一种使用热启动的流式同伦 Lasso 更新方法，并分析当 $\\lambda_t$ 在线自适应时，同伦路径避免支持集振荡的条件。您的推导必须从基本的最优性条件出发，并且不能使用跳过推理过程的简化公式。\n\n在科学一致的设定下进行研究，其中设计矩阵为单位矩阵 $A_t = I_{3}$，维度为 $n = m = 3$，在时间 $t$ 的各量为\n$$\ny_t = \\begin{pmatrix} 1.5 \\\\ 2.5 \\\\ -0.3 \\end{pmatrix}, \\quad \\lambda_t = 0.5.\n$$\n设流式更新由下式给出\n$$\ny_{t+1} = y_t + \\Delta y, \\quad \\lambda_{t+1} = \\lambda_t + \\Delta \\lambda,\n$$\n其中数据漂移的界限为 $\\|\\Delta y\\|_{\\infty} \\leq \\eta$，$\\eta$ 是一个已知的非负常数。\n\n任务：\n1. 从 Lasso 的 Karush–Kuhn–Tucker (KKT) 最优性条件出发，推导在单位设计矩阵情况 $A_{t+1} = I_{3}$ 下，作为 $y_{t+1}$ 和 $\\lambda_{t+1}$ 函数的精确流式更新 $x_{t+1}$，并解释当 $\\Delta \\lambda$ 很小时，从 $x_t$ 开始的热启动如何沿着同伦路径进行。\n2. 使用您的推导，建立一个关于 $\\eta$ 和 $\\Delta \\lambda$ 的充分条件，以保证 $x_{t+1}$ 的支持集与 $x_t$ 的支持集相等，且活动系数的符号不发生改变。将此条件解释为在 $\\lambda_t$ 在线自适应下避免支持集振荡。\n3. 对于上述数值设定，在界限 $\\|\\Delta y\\|_{\\infty} \\leq 0.1$ 的情况下，计算最大的非负数 $\\delta$，使得对于任何满足 $\\|\\Delta y\\|_{\\infty} \\leq 0.1$ 的 $\\Delta y$ 和任何满足 $|\\Delta \\lambda| \\leq \\delta$ 的 $\\Delta \\lambda$，Lasso 解的支持集在流式更新过程中保持不变（即不发生支持集振荡）。请以单个实数形式提供您的最终答案，无需四舍五入。", "solution": "该问题要求推导流式 Lasso 更新，分析支持集稳定性，并对特定情况进行数值计算。第一步是验证问题陈述的有效性。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n-   时间 $t$ 的 Lasso 目标函数：$\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2}\\|A_t x - y_t\\|_{2}^{2} + \\lambda_t \\|x\\|_{1}$\n-   设计矩阵：$A_t = I_{3}$，其中 $I_3$ 是 $3 \\times 3$ 单位矩阵。\n-   维度：$n = m = 3$。\n-   时间 $t$ 的数据：$y_t = \\begin{pmatrix} 1.5 \\\\ 2.5 \\\\ -0.3 \\end{pmatrix}$。\n-   时间 $t$ 的正则化参数：$\\lambda_t = 0.5$。\n-   流式更新：$y_{t+1} = y_t + \\Delta y$, $\\lambda_{t+1} = \\lambda_t + \\Delta \\lambda$。\n-   数据漂移界限：$\\|\\Delta y\\|_{\\infty} \\leq \\eta$，其中 $\\eta$ 是一个已知的非负常数。\n-   任务 1：从 KKT 条件推导在 $A_{t+1} = I_3$ 情况下的精确流式更新 $x_{t+1}$，并讨论同伦背景下的热启动。\n-   任务 2：推导一个关于 $\\eta$ 和 $\\Delta \\lambda$ 的充分条件，以保持解的支持集和符号。\n-   任务 3：对于 $\\|\\Delta y\\|_{\\infty} \\leq 0.1$，计算最大的非负数 $\\delta$，使得对于任何满足 $\\|\\Delta y\\|_{\\infty} \\leq 0.1$ 的 $\\Delta y$ 和任何满足 $|\\Delta \\lambda| \\leq \\delta$ 的 $\\Delta \\lambda$，解的支持集保持不变。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题在科学上基于凸优化和稀疏恢复（Lasso）的既有数学理论。目标函数是标准的。使用 Karush–Kuhn–Tucker (KKT) 条件来推导最优性是正确且基本的方法。该问题是适定的；对于 $A_t = I_3$，Lasso 目标函数是严格凸的，保证了唯一解的存在。语言客观，数据精确。问题是自洽的，没有矛盾。该场景虽然通过单位设计矩阵进行了简化，但提出了在扰动下解稳定性的一个非平凡分析，这是同伦方法和流式算法研究中的核心概念。\n\n**步骤 3：结论与行动**\n问题有效。我将继续进行完整解答。\n\n### 任务 1：流式更新的推导\n\n对于指定情况 $A_t = I_n$，Lasso 目标函数为：\n$$\nL(x) = \\frac{1}{2}\\|x - y\\|_{2}^{2} + \\lambda \\|x\\|_{1}\n$$\n为使推导过程中的符号更清晰，我们在此省略时间下标。目标函数是可分的，意味着它可以写成关于 $x$ 的各个分量的函数之和：\n$$\nL(x) = \\sum_{i=1}^{n} \\left( \\frac{1}{2}(x_i - y_i)^2 + \\lambda |x_i| \\right)\n$$\n因此，我们可以通过独立地对每个分量 $x_i$ 进行最小化来最小化目标函数。Karush–Kuhn–Tucker (KKT) 条件由目标函数关于 $x_i$ 的次梯度导出。绝对值函数 $|x_i|$ 在 $x_i$ 处的次微分为 $\\partial|x_i|$，当 $x_i \\neq 0$ 时为 $\\text{sgn}(x_i)$，当 $x_i = 0$ 时为区间 $[-1, 1]$。\n\n对于 $x_i$ 的一维目标的次梯度为：\n$$\n\\frac{\\partial}{\\partial x_i} \\left(\\frac{1}{2}(x_i - y_i)^2 + \\lambda |x_i|\\right) = (x_i - y_i) + \\lambda \\, \\partial|x_i|\n$$\n最优性条件是 $0$ 必须在次梯度中：\n$$\n0 \\in (x_i - y_i) + \\lambda \\, \\partial|x_i| \\implies y_i - x_i \\in \\lambda \\, \\partial|x_i|\n$$\n这导致了最优 $x_i$ 的三种情况：\n1.  如果 $x_i > 0$，则 $\\partial|x_i| = \\{1\\}$。条件变为 $y_i - x_i = \\lambda$，这意味着 $x_i = y_i - \\lambda$。这仅在 $y_i - \\lambda > 0$ 时成立，即 $y_i > \\lambda$。\n2.  如果 $x_i  0$，则 $\\partial|x_i| = \\{-1\\}$。条件变为 $y_i - x_i = -\\lambda$，这意味着 $x_i = y_i + \\lambda$。这仅在 $y_i + \\lambda  0$ 时成立，即 $y_i  -\\lambda$。\n3.  如果 $x_i = 0$，则 $\\partial|x_i| = [-1, 1]$。条件变为 $y_i - 0 \\in [-\\lambda, \\lambda]$，这等价于 $|y_i| \\leq \\lambda$。\n\n综合这三种情况，我们得到每个分量 $x_i$ 作为 $y_i$ 和 $\\lambda$ 的函数的解。该函数被称为软阈值算子，记为 $S_{\\lambda}(\\cdot)$：\n$$\nx_i = S_{\\lambda}(y_i) = \\begin{cases} y_i - \\lambda  \\text{if } y_i > \\lambda \\\\ 0  \\text{if } |y_i| \\leq \\lambda \\\\ y_i + \\lambda  \\text{if } y_i  -\\lambda \\end{cases}\n$$\n这可以更紧凑地写成 $x_i = \\text{sgn}(y_i) \\max(0, |y_i| - \\lambda)$。\n\n因此，精确的流式更新 $x_{t+1}$ 是使用新数据 $y_{t+1}$ 和新正则化参数 $\\lambda_{t+1}$ 的 Lasso 问题的解：\n$$\nx_{t+1} = S_{\\lambda_{t+1}}(y_{t+1})\n$$\n其中每个分量 $(x_{t+1})_i$ 由 $(x_{t+1})_i = \\text{sgn}((y_{t+1})_i) \\max(0, |(y_{t+1})_i| - \\lambda_{t+1})$ 给出。\n\n在这种情况下，“热启动”指的是对于小的变化 $\\Delta y$ 和 $\\Delta \\lambda$，新解 $x_{t+1}$ 预期会接近旧解 $x_t$。解遵循一条“同伦路径”，即当 $y$ 和 $\\lambda$ 连续变化时 $x$ 的轨迹。该路径是分段线性的，路径中的“事件”或“扭结”恰好在解的支持集发生变化时出现。这发生在某个分量 $i$ 的 $|y_i|$ 穿过阈值 $\\lambda$ 时。我们的目标是找到关于更新 $\\Delta y$ 和 $\\Delta \\lambda$ 的条件，以防止此类事件发生。\n\n### 任务 2：支持集保持的条件\n\n解 $x_t$ 的支持集是索引集合 $\\mathcal{S}_t = \\{ i \\mid (x_t)_i \\neq 0 \\}$。活动系数 $(x_t)_i$ 的符号是 $\\text{sgn}((x_t)_i)$。支持集和符号保持意味着对于所有 $i \\in \\mathcal{S}_t$，有 $\\mathcal{S}_{t+1} = \\mathcal{S}_t$ 且 $\\text{sgn}((x_{t+1})_i) = \\text{sgn}((x_t)_i)$。\n\n从任务 1 的推导中，我们有：\n-   一个元素 $i$ 在活动集 $\\mathcal{S}_t$ 中，当且仅当 $|(y_t)_i| > \\lambda_t$。其符号为 $\\text{sgn}((x_t)_i) = \\text{sgn}((y_t)_i)$。\n-   一个元素 $j$ 在非活动集 ($\\mathcal{S}_t^c$) 中，当且仅当 $|(y_t)_j| \\leq \\lambda_t$。\n\n为了保持支持集和符号，这两个条件必须在时间 $t+1$ 对相同的索引集成立。\n\n**条件 1：活动系数必须保持活动且符号不变。**\n对于索引 $i \\in \\mathcal{S}_t$，我们有 $|(y_t)_i| > \\lambda_t$。我们要求 $|(y_{t+1})_i| > \\lambda_{t+1}$ 且 $\\text{sgn}((y_{t+1})_i) = \\text{sgn}((y_t)_i)$。\n$y_i$ 的符号保持要求 $|(\\Delta y)_i|  |(y_t)_i|$。\n代入更新 $y_{t+1}=y_t+\\Delta y$ 和 $\\lambda_{t+1}=\\lambda_t+\\Delta\\lambda$，条件变为：\n$$\n|(y_t)_i + (\\Delta y)_i| > \\lambda_t + \\Delta \\lambda\n$$\n假设 $y_i$ 的符号不翻转，则 $|(y_t)_i + (\\Delta y)_i| = |(y_t)_i| + \\text{sgn}((y_t)_i)(\\Delta y)_i$。不等式变为：\n$$\n|(y_t)_i| + \\text{sgn}((y_t)_i)(\\Delta y)_i > \\lambda_t + \\Delta \\lambda \\implies |(y_t)_i| - \\lambda_t > \\Delta \\lambda - \\text{sgn}((y_t)_i)(\\Delta y)_i\n$$\n为了对任何允许的扰动保证这一点，我们必须为右侧定界。给定 $|(\\Delta y)_i| \\leq \\eta$ 和 $|\\Delta \\lambda| \\leq \\delta$，右侧的最坏情况（最大）值是 $\\delta + \\eta$。这发生在 $\\Delta \\lambda = \\delta$ 且 $(\\Delta y)_i = -\\eta \\cdot \\text{sgn}((y_t)_i)$ 时。\n因此，一个充分条件是：\n$$\n|(y_t)_i| - \\lambda_t > \\eta + \\delta\n$$\n此条件确保 $|(y_t)_i| > \\lambda_t + \\eta + \\delta > \\eta \\geq |(\\Delta y)_i|$，因此 $y_i$ 的符号也得以保持。严格不等式是必要的，以防止系数恰好落在边界上而变为非活动。\n\n**条件 2：非活动系数必须保持非活动。**\n对于索引 $j \\in \\mathcal{S}_t^c$，我们有 $|(y_t)_j| \\leq \\lambda_t$。我们要求 $|(y_{t+1})_j| \\leq \\lambda_{t+1}$。\n$$\n|(y_t)_j + (\\Delta y)_j| \\leq \\lambda_t + \\Delta \\lambda\n$$\n为了对任何允许的扰动保证这一点，我们需要：\n$$\n\\max_{|\\Delta \\lambda|\\leq\\delta, |(\\Delta y)_j|\\leq\\eta} \\left( |(y_t)_j + (\\Delta y)_j| - (\\lambda_t + \\Delta \\lambda) \\right) \\leq 0\n$$\n当 $|(y_t)_j + (\\Delta y)_j|$ 最大化且 $\\Delta \\lambda$ 最小化时，该表达式达到最大值。\n$\\max |(y_t)_j + (\\Delta y)_j| = |(y_t)_j| + \\eta$。\n$\\min (\\lambda_t + \\Delta \\lambda) = \\lambda_t - \\delta$。\n因此条件变为 $(|(y_t)_j| + \\eta) - (\\lambda_t - \\delta) \\leq 0$，整理后得到：\n$$\n\\lambda_t - |(y_t)_j| \\geq \\eta + \\delta\n$$\n\n**条件总结：**\n令 $g_{i}^{\\text{active}} = |(y_t)_i| - \\lambda_t$（对于 $i \\in \\mathcal{S}_t$）和 $g_{j}^{\\text{inactive}} = \\lambda_t - |(y_t)_j|$（对于 $j \\in \\mathcal{S}_t^c$）。这些是到决策边界 $\\lambda_t$ 的“间隙”。\n在扰动 $\\|\\Delta y\\|_{\\infty} \\leq \\eta$ 和 $|\\Delta \\lambda| \\leq \\delta$ 下保持支持集的充分条件是：\n1.  对于所有 $i \\in \\mathcal{S}_t$：$g_{i}^{\\text{active}} > \\eta + \\delta$\n2.  对于所有 $j \\in \\mathcal{S}_t^c$：$g_{j}^{\\text{inactive}} \\geq \\eta + \\delta$\n\n其解释是，任何分量 $|(y_t)_i|$ 到阈值 $\\lambda_t$ 的最小“距离”必须足够大，以吸收数据和正则化参数组合的最坏情况下的漂移。如果此条件成立，则系统对这些变化是鲁棒的，并且可以避免支持集振荡。\n\n### 任务 3：数值计算\n\n我们已知：\n$y_t = \\begin{pmatrix} 1.5 \\\\ 2.5 \\\\ -0.3 \\end{pmatrix}$，$\\lambda_t = 0.5$ 以及 $\\eta = 0.1$。我们需要找到最大的 $\\delta \\ge 0$。\n\n**步骤 1：计算解 $x_t$ 并确定支持集。**\n使用 $x_i = \\text{sgn}(y_i) \\max(0, |y_i| - \\lambda_t)$：\n-   $(x_t)_1 = \\text{sgn}(1.5)\\max(0, 1.5 - 0.5) = 1 \\cdot 1.0 = 1.0$。活动，因为 $|1.5| > 0.5$。\n-   $(x_t)_2 = \\text{sgn}(2.5)\\max(0, 2.5 - 0.5) = 1 \\cdot 2.0 = 2.0$。活动，因为 $|2.5| > 0.5$。\n-   $(x_t)_3 = \\text{sgn}(-0.3)\\max(0, |-0.3| - 0.5) = -1 \\cdot \\max(0, 0.3 - 0.5) = 0$。非活动，因为 $|-0.3| \\leq 0.5$。\n\n支持集为 $\\mathcal{S}_t = \\{1, 2\\}$，非活动集为 $\\{3\\}$。\n\n**步骤 2：计算最小间隙。**\n-   对于活动集 $\\mathcal{S}_t = \\{1, 2\\}$，我们计算 $g_i^{\\text{active}} = |(y_t)_i| - \\lambda_t$：\n    -   $i=1$: $g_1^{\\text{active}} = |1.5| - 0.5 = 1.0$。\n    -   $i=2$: $g_2^{\\text{active}} = |2.5| - 0.5 = 2.0$。\n    最小活动间隙为 $\\min(1.0, 2.0) = 1.0$。\n\n-   对于非活动集 $\\{3\\}$，我们计算 $g_j^{\\text{inactive}} = \\lambda_t - |(y_t)_j|$：\n    -   $j=3$: $g_3^{\\text{inactive}} = 0.5 - |-0.3| = 0.5 - 0.3 = 0.2$。\n    最小非活动间隙为 $0.2$。\n\n**步骤 3：应用条件找到最大的 $\\delta$。**\n任务 2 中的两个条件必须成立：\n1.  $\\min(g^{\\text{active}}) > \\eta + \\delta \\implies 1.0 > 0.1 + \\delta \\implies \\delta  0.9$。\n2.  $\\min(g^{\\text{inactive}}) \\geq \\eta + \\delta \\implies 0.2 \\geq 0.1 + \\delta \\implies \\delta \\leq 0.1$。\n\n为使两个条件都得到满足，我们必须满足更严格的那个，即 $\\delta \\leq 0.1$。问题要求满足条件的最大非负数 $\\delta$。这是满足不等式的 $\\delta$ 的最大值，即 $\\delta = 0.1$。\n\n如果 $\\delta > 0.1$，则可以在其界限内选择 $\\Delta y$ 和 $\\Delta \\lambda$ 来导致支持集发生变化。例如，对于一个小的 $\\epsilon > 0$，令 $\\delta = 0.1 + \\epsilon$。我们可以选择 $\\Delta\\lambda = -(0.1+\\epsilon)$ 和 $(\\Delta y)_3=-0.1$。那么 $\\lambda_{t+1}=0.4-\\epsilon$ 且 $(y_{t+1})_3 = -0.3-0.1=-0.4$。现在 $|(y_{t+1})_3|=0.4$，它大于 $\\lambda_{t+1}=0.4-\\epsilon$。第三个分量变为活动状态。\n\n因此，保证在任何有效扰动下支持集得以保持的 $\\delta$ 的最大值为 $0.1$。", "answer": "$$\n\\boxed{0.1}\n$$", "id": "3463869"}, {"introduction": "前一个问题关注的是稳定性，但许多现实世界的信号本身就是动态的。本实践 [@problem_id:3463870] 要求您设计一种在线算法，通过促进时间稀疏性来显式地建模和跟踪时变信号。您将基于近端方法推导出一个更新规则，并分析其在跟踪突变和渐变时的性能，从而揭示这种建模方法的核心权衡。", "problem": "考虑一个用于时变稀疏信号的流式线性测量模型，其中在每个时间索引 $t$，您观测到 $y_t \\in \\mathbb{R}^{m}$，其由 $y_t = A x_t^{\\star} + w_t$ 给出，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是固定的，$x_t^{\\star} \\in \\mathbb{R}^{n}$ 是随时间演化的真实信号，而 $w_t \\in \\mathbb{R}^{m}$ 是加性噪声。您的任务是设计一个在线估计器 $x_t \\in \\mathbb{R}^{n}$，它通过 $\\ell_1$ 惩罚项来强制增量 $x_t - x_{t-1}$ 的时间稀疏性，并且能在 $y_t$ 到达时进行更新而无需回顾过去的数据。\n\n从凸复合优化的基本原理和邻近算子的定义出发，通过最小化一个复合目标函数来构建一个在时间 $t$ 的单步在线更新。该目标函数由一个最小二乘数据拟合项和一个时间正则化项组成，其中时间正则化项是增量 $x - x_{t-1}$ 上的 $\\ell_1$ 惩罚项和 $\\ell_2$ (二次) 惩罚项之和。数据拟合项应仅对应于当前样本 $(A, y_t)$。您的构建必须得出一个可以以流式形式实现的显式分量更新公式，该公式需从第一性原理推导，并应精确地指出 $\\ell_1$ 增量惩罚项是如何通过邻近映射引入的。\n\n然后，在以下简化的无噪声场景中，分析该估计器跟踪突变与缓变的能力：设 $n = 1$, $m = 1$, $A = 1$, $w_t = 0$，并假设前一时间步的估计是精确的，即 $x_{t-1} = x_{t-1}^{\\star}$。真实信号根据 $x_t^{\\star} = x_{t-1}^{\\star} + D$ 变化，其中 $D \\in \\mathbb{R}$ 模拟了变化的幅度。考虑两种情况：突变 $D_{\\mathrm{a}} = 3$ 和缓变 $D_{\\mathrm{g}} = 0.8$。使用邻近梯度步长 $\\tau = 0.6$，二次增量惩罚系数 $\\gamma = 0.4$，以及 $\\ell_1$ 增量惩罚系数 $\\mu = 1$。在时间 $t$ 进行单次更新后，分别计算突变和缓变情况下的绝对单步跟踪误差大小 $|e_t^{\\mathrm{a}}|$ 和 $|e_t^{\\mathrm{g}}|$，然后计算比率 $R = |e_t^{\\mathrm{a}}| / |e_t^{\\mathrm{g}}|$。将您的最终数值答案 $R$ 四舍五入到四位有效数字。不涉及物理单位；报告一个纯数。", "solution": "我们从流式线性模型 $y_t = A x_t^{\\star} + w_t$ 开始，目标是根据给定的前一个估计 $x_{t-1}$，从 $y_t$ 生成在线估计 $x_t$。为了在增量中强制时间稀疏性，我们考虑在时间 $t$ 的凸复合目标函数：\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\;\\; \\frac{1}{2} \\|A x - y_t\\|_2^2 \\;+\\; \\mu \\|x - x_{t-1}\\|_1 \\;+\\; \\frac{\\gamma}{2} \\|x - x_{t-1}\\|_2^2,\n$$\n其中 $\\mu > 0$ 控制增量 $x - x_{t-1}$ 上的 $\\ell_1$ 惩罚，而 $\\gamma \\ge 0$ 添加了二次稳定项。这是一个凸复合问题：一个光滑的数据拟合项 $\\frac{1}{2}\\|A x - y_t\\|_2^2$ 加上一个在增量 $x - x_{t-1}$ 上的非光滑、可分的正则化项。\n\n为了以流式形式进行在线更新，我们采用邻近梯度法（也称为迭代软阈值算法 (ISTA)）。从 $x_{t-1}$ 开始，步长为 $\\tau > 0$ 的在时间 $t$ 的邻近梯度迭代是\n$$\nz_t \\;=\\; x_{t-1} \\;-\\; \\tau \\nabla \\left( \\frac{1}{2}\\|A x - y_t\\|_2^2 \\right)\\bigg|_{x = x_{t-1}} \\;=\\; x_{t-1} \\;-\\; \\tau A^{\\top} \\left( A x_{t-1} - y_t \\right).\n$$\n引入增量变量 $v = x - x_{t-1}$。非光滑正则化项可以写成 $g(v) = \\mu \\|v\\|_1 + \\frac{\\gamma}{2}\\|v\\|_2^2$，它在坐标上是可分的。邻近更新将 $g$ 的邻近算子应用于梯度步位移 $v_0 = z_t - x_{t-1}$：\n$$\nx_t \\;=\\; x_{t-1} \\;+\\; \\operatorname{prox}_{\\tau g}(v_0),\n$$\n根据邻近算子的定义，对于任何 $v_0 \\in \\mathbb{R}^{n}$ 和 $\\tau > 0$：\n$$\n\\operatorname{prox}_{\\tau g}(v_0) \\;=\\; \\arg\\min_{v \\in \\mathbb{R}^{n}} \\left\\{ \\frac{1}{2} \\|v - v_0\\|_2^2 \\;+\\; \\tau \\mu \\|v\\|_1 \\;+\\; \\frac{\\tau \\gamma}{2} \\|v\\|_2^2 \\right\\}.\n$$\n我们现在推导 $g(v) = \\mu \\|v\\|_1 + \\frac{\\gamma}{2}\\|v\\|_2^2$ 的闭式邻近映射。该优化问题是可分的和严格凸的。对每个坐标进行配方，得到：\n$$\n\\min_{v} \\;\\; \\frac{1 + \\tau \\gamma}{2} \\|v\\|_2^2 \\;-\\; v_0^{\\top} v \\;+\\; \\tau \\mu \\|v\\|_1 \\;+\\; \\text{const}.\n$$\n这等价于\n$$\n\\min_{v} \\;\\; \\frac{1 + \\tau \\gamma}{2} \\left\\| v - \\frac{v_0}{1 + \\tau \\gamma} \\right\\|_2^2 \\;+\\; \\tau \\mu \\|v\\|_1 \\;+\\; \\text{const},\n$$\n其唯一的最小化子是缩放后输入在缩放后阈值下的坐标级软阈值：\n$$\n\\operatorname{prox}_{\\tau g}(v_0) \\;=\\; S_{\\frac{\\tau \\mu}{1 + \\tau \\gamma}} \\!\\left( \\frac{v_0}{1 + \\tau \\gamma} \\right),\n$$\n其中 $S_{\\theta}(u)$ 是软阈值算子，其分量定义为 $S_{\\theta}(u)_i = \\operatorname{sign}(u_i)\\,\\max\\{|u_i| - \\theta,\\,0\\}$。\n\n因此，显式的流式更新为\n$$\nx_t \\;=\\; x_{t-1} \\;+\\; S_{\\frac{\\tau \\mu}{1 + \\tau \\gamma}} \\!\\left( \\frac{z_t - x_{t-1}}{1 + \\tau \\gamma} \\right),\n\\quad \\text{with} \\quad\nz_t \\;=\\; x_{t-1} \\;-\\; \\tau A^{\\top}(A x_{t-1} - y_t).\n$$\n这通过对预测增量 $z_t - x_{t-1}$ 进行软阈值处理来实现时间稀疏性。\n\n我们现在分析简化的标量、无噪声情况下的跟踪问题。设 $n = 1$, $m = 1$, $A = 1$, $w_t = 0$，前一估计是精确的，即 $x_{t-1} = x_{t-1}^{\\star}$，真实信号变化为 $x_t^{\\star} = x_{t-1}^{\\star} + D$。则 $y_t = x_t^{\\star} = x_{t-1}^{\\star} + D$。梯度步变为\n$$\nz_t \\;=\\; x_{t-1} \\;-\\; \\tau \\left( x_{t-1} - y_t \\right) \\;=\\; x_{t-1} \\;+\\; \\tau \\left( y_t - x_{t-1} \\right)\n\\;=\\; x_{t-1} \\;+\\; \\tau D,\n$$\n因此预测增量为 $v_0 = z_t - x_{t-1} = \\tau D$。软阈值的输入和阈值为\n$$\nu \\;=\\; \\frac{v_0}{1 + \\tau \\gamma} \\;=\\; \\frac{\\tau D}{1 + \\tau \\gamma},\n\\qquad\n\\theta \\;=\\; \\frac{\\tau \\mu}{1 + \\tau \\gamma}.\n$$\n更新后的增量为 $v = S_{\\theta}(u)$。单步估计误差为\n$$\ne_t \\;=\\; x_t - x_t^{\\star} \\;=\\; \\big(x_{t-1} + v\\big) - \\big(x_{t-1}^{\\star} + D\\big) \\;=\\; v - D,\n$$\n因为 $x_{t-1} = x_{t-1}^{\\star}$。\n\n我们评估两种情况，参数为 $\\tau = 0.6$, $\\gamma = 0.4$, $\\mu = 1$，变化为 $D_{\\mathrm{a}} = 3$ (突变) 和 $D_{\\mathrm{g}} = 0.8$ (缓变)。首先计算 $1 + \\tau \\gamma = 1 + 0.6 \\cdot 0.4 = 1.24$ 和 $\\theta = \\frac{0.6 \\cdot 1}{1.24} = \\frac{0.6}{1.24} \\approx 0.4838709677419355$。\n\n突变情况 $D = D_{\\mathrm{a}} = 3$：\n- $u_{\\mathrm{a}} = \\frac{\\tau D_{\\mathrm{a}}}{1 + \\tau \\gamma} = \\frac{0.6 \\cdot 3}{1.24} = \\frac{1.8}{1.24} \\approx 1.4516129032258065$。\n- 由于 $u_{\\mathrm{a}} > \\theta$，所以 $v_{\\mathrm{a}} = u_{\\mathrm{a}} - \\theta \\approx 1.4516129032258065 - 0.4838709677419355 = 0.967741935483871$。\n- $e_t^{\\mathrm{a}} = v_{\\mathrm{a}} - D_{\\mathrm{a}} \\approx 0.967741935483871 - 3 = -2.032258064516129$，所以 $|e_t^{\\mathrm{a}}| \\approx 2.032258064516129$。\n\n缓变情况 $D = D_{\\mathrm{g}} = 0.8$：\n- $u_{\\mathrm{g}} = \\frac{\\tau D_{\\mathrm{g}}}{1 + \\tau \\gamma} = \\frac{0.6 \\cdot 0.8}{1.24} = \\frac{0.48}{1.24} \\approx 0.3870967741935484$。\n- 由于 $u_{\\mathrm{g}}  \\theta$，所以 $v_{\\mathrm{g}} = 0$。\n- $e_t^{\\mathrm{g}} = v_{\\mathrm{g}} - D_{\\mathrm{g}} = 0 - 0.8 = -0.8$，所以 $|e_t^{\\mathrm{g}}| = 0.8$。\n\n所要求的比率为\n$$\nR \\;=\\; \\frac{|e_t^{\\mathrm{a}}|}{|e_t^{\\mathrm{g}}|}\n\\;=\\; \\frac{2.032258064516129}{0.8}\n\\;=\\; 2.540322580645161.\n$$\n四舍五入到四位有效数字，$R = 2.540$。", "answer": "$$\\boxed{2.540}$$", "id": "3463870"}, {"introduction": "基于 $\\ell_1$ 正则化的稀疏恢复算法虽然能有效识别正确的特征，但众所周知，它们会通过压缩估计系数的幅度来引入系统性偏差。最后一个练习 [@problem_id:3463824] 旨在解决这个实际问题，要求您构建并分析一个在线去偏程序。您将量化由于支撑集选择中不可避免的错误而持续存在的稳态偏差，从而深入了解两阶段估计算法的性能局限。", "problem": "考虑一个用于稀疏恢复的在线线性测量模型，该模型具有一个固定的字典。在每个离散时间 $t \\in \\mathbb{N}$，通过 $y_t = A x^{\\star} + w_t$ 获取一个观测值 $y_t \\in \\mathbb{R}^{m}$。未知信号 $x^{\\star} \\in \\mathbb{R}^{2}$ 是时不变的，并且是精确稀疏的，其支撑集为 $\\{1,2\\}$，幅度相等，即对于某个 $\\theta \\in \\mathbb{R}$，有 $x^{\\star} = [\\theta,\\theta]^{\\top}$。矩阵 $A = [a_1\\ a_2] \\in \\mathbb{R}^{m \\times 2}$ 的列是单位范数列，满足 $\\|a_1\\|_{2} = \\|a_2\\|_{2} = 1$，且互内积为 $a_1^{\\top} a_2 = \\rho$，其中 $|\\rho|  1$。噪声过程 $w_t \\sim \\mathcal{N}(0,\\sigma^{2} I_{m})$ 在时间上是独立同分布的，并且独立于所有其他随机性。在每个时间 $t$，一个最小绝对收缩和选择算子 (LASSO) 阶段会产生一个估计的支撑集 $\\widehat{S}_t \\subseteq \\{1,2\\}$，其概率模型如下：索引 $1$ 总是被选中，而索引 $2$ 以概率 $1-p$ 被包含，以概率 $p \\in [0,1)$ 被漏选，这在时间上是独立的，且独立于 $w_t$。不会发生 $\\{1,2\\}$ 之外的假发现。\n\n为了校正由 $\\ell_{1}$ 惩罚项引起的幅度收缩，在支撑集选择之后执行一个在线去偏步骤，具体如下。在每个时间 $t$，给定 $\\widehat{S}_t$，通过限制在 $\\widehat{S}_t$ 上的普通最小二乘法 (OLS) 计算索引 $1$ 的瞬时去偏系数：如果 $1 \\in \\widehat{S}_t$，则\n$$\n\\tilde{x}_{1,t} \\triangleq e_1^{\\top} \\arg\\min_{z \\in \\mathbb{R}^{|\\widehat{S}_t|}} \\|y_t - A_{\\widehat{S}_t} z\\|_{2}^{2},\n$$\n其中 $A_{\\widehat{S}_t}$ 是由 $\\widehat{S}_t$ 索引的列组成的 $A$ 的子矩阵，而当解中存在索引 $1$ 的系数时，$e_1$ 会选择该系数。然后，使用遗忘因子 $\\alpha \\in (0,1]$ 的指数平滑法来更新索引 $1$ 的在线估计：\n$$\n\\widehat{x}_{1,t} = (1-\\alpha)\\,\\widehat{x}_{1,t-1} + \\alpha\\,\\tilde{x}_{1,t}, \\quad \\widehat{x}_{1,0} = 0.\n$$\n\n仅从线性模型的定义、普通最小二乘法的性质和基础概率论出发，推导索引 $1$ 的在线去偏估计的稳态期望偏差的闭式解析表达式：\n$$\n\\lim_{t \\to \\infty} \\mathbb{E}\\big[\\widehat{x}_{1,t} - \\theta\\big],\n$$\n该表达式是关于 $\\theta$、$\\rho$、$p$ 和 $\\alpha$ 的函数。请将您的最终答案表示为单个简化的解析表达式。不需要四舍五入，也不涉及单位。", "solution": "问题要求解稀疏信号在线去偏估计的稳态期望偏差。我们将第一个分量的真实信号值表示为 $x_1^{\\star} = \\theta$。待求的量是 $\\lim_{t \\to \\infty} \\mathbb{E}[\\widehat{x}_{1,t} - \\theta]$。\n\n在线估计 $\\widehat{x}_{1,t}$ 通过指数平滑法则更新：\n$$\n\\widehat{x}_{1,t} = (1-\\alpha)\\,\\widehat{x}_{1,t-1} + \\alpha\\,\\tilde{x}_{1,t}\n$$\n初始条件为 $\\widehat{x}_{1,0} = 0$。对该方程取期望，我们得到均值估计 $\\mu_t \\triangleq \\mathbb{E}[\\widehat{x}_{1,t}]$ 的递推关系：\n$$\n\\mu_t = (1-\\alpha)\\,\\mu_{t-1} + \\alpha\\,\\mathbb{E}[\\tilde{x}_{1,t}]\n$$\n初始条件为 $\\mu_0 = \\mathbb{E}[\\widehat{x}_{1,0}] = 0$。\n\n支撑集选择的概率模型和噪声过程在时间 $t$ 上是独立同分布的。因此，瞬时估计 $\\tilde{x}_{1,t}$ 的统计特性是时不变的。我们将其恒定的期望表示为 $\\nu \\triangleq \\mathbb{E}[\\tilde{x}_{1,t}]$。$\\mu_t$ 的递推关系变为：\n$$\n\\mu_t = (1-\\alpha)\\,\\mu_{t-1} + \\alpha\\,\\nu\n$$\n这是一个标准的线性一阶递推关系。其解可以通过展开递推得到：\n$$\n\\mu_t = (1-\\alpha)^t \\mu_0 + \\alpha \\nu \\sum_{k=0}^{t-1} (1-\\alpha)^k = \\alpha \\nu \\frac{1 - (1-\\alpha)^t}{1 - (1-\\alpha)} = (1 - (1-\\alpha)^t)\\nu\n$$\n我们关心的是当 $t \\to \\infty$ 时的稳态极限。由于 $\\alpha \\in (0,1]$，项 $(1-\\alpha)$ 位于区间 $[0,1)$ 内。因此，$\\lim_{t \\to \\infty} (1-\\alpha)^t = 0$。稳态期望值为：\n$$\n\\mu_{\\infty} \\triangleq \\lim_{t \\to \\infty} \\mu_t = \\nu = \\mathbb{E}[\\tilde{x}_{1,t}]\n$$\n因此，问题简化为计算瞬时 OLS 估计 $\\tilde{x}_{1,t}$ 的期望值。遗忘因子 $\\alpha$ 影响收敛到稳态的速度，但本身不影响稳态期望的值。\n\n为求 $\\mathbb{E}[\\tilde{x}_{1,t}]$，我们使用全期望定律，以估计的支撑集 $\\widehat{S}_t$ 的两种可能实现为条件：\n\\begin{enumerate}\n    \\item $\\widehat{S}_t = \\{1\\}$，发生概率为 $p$。\n    \\item $\\widehat{S}_t = \\{1,2\\}$，发生概率为 $1-p$。\n\\end{enumerate}\n于是，我们可以写出：\n$$\n\\mathbb{E}[\\tilde{x}_{1,t}] = P(\\widehat{S}_t=\\{1\\}) \\cdot \\mathbb{E}[\\tilde{x}_{1,t} \\,|\\, \\widehat{S}_t=\\{1\\}] + P(\\widehat{S}_t=\\{1,2\\}) \\cdot \\mathbb{E}[\\tilde{x}_{1,t} \\,|\\, \\widehat{S}_t=\\{1,2\\}]\n$$\n$$\n\\mathbb{E}[\\tilde{x}_{1,t}] = p \\cdot \\mathbb{E}[\\tilde{x}_{1,t} \\,|\\, \\widehat{S}_t=\\{1\\}] + (1-p) \\cdot \\mathbb{E}[\\tilde{x}_{1,t} \\,|\\, \\widehat{S}_t=\\{1,2\\}]\n$$\n题目说明支撑集选择过程独立于噪声 $w_t$。这意味着我们可以对每种情况分别计算 OLS 估计的期望。观测模型为 $y_t = A x^{\\star} + w_t = a_1 \\theta + a_2 \\theta + w_t$。由于 $\\mathbb{E}[w_t]=0$，观测值的期望为 $\\mathbb{E}[y_t] = a_1 \\theta + a_2 \\theta$。\n\n情况 1：$\\widehat{S}_t = \\{1\\}$。\nOLS 问题为 $\\min_{z_1 \\in \\mathbb{R}} \\|y_t - a_1 z_1\\|_2^2$。其解由正规方程组给出：\n$$\n\\tilde{x}_{1,t} = (a_1^{\\top} a_1)^{-1} a_1^{\\top} y_t\n$$\n已知 $\\|a_1\\|_2 = 1$，我们有 $a_1^{\\top} a_1 = 1$。估计变为 $\\tilde{x}_{1,t} = a_1^{\\top} y_t$。\n其条件期望为：\n$$\n\\mathbb{E}[\\tilde{x}_{1,t} \\,|\\, \\widehat{S}_t=\\{1\\}] = \\mathbb{E}[a_1^{\\top} y_t] = a_1^{\\top} \\mathbb{E}[y_t] = a_1^{\\top} (a_1 \\theta + a_2 \\theta)\n$$\n$$\n= (a_1^{\\top} a_1)\\theta + (a_1^{\\top} a_2)\\theta = 1 \\cdot \\theta + \\rho \\cdot \\theta = \\theta(1+\\rho)\n$$\n这是经典的遗漏变量偏差：对系数 $1$ 的估计因遗漏变量 $2$ 的影响而产生偏差，该偏差与其真实系数 $\\theta$ 以及回归量之间的相关性 $\\rho$ 成正比。\n\n情况 2：$\\widehat{S}_t = \\{1,2\\}$。\nOLS 问题为 $\\min_{z \\in \\mathbb{R}^2} \\|y_t - A z\\|_2^2$。向量 $z$ 的解为：\n$$\n\\tilde{z}_t = (A^{\\top} A)^{-1} A^{\\top} y_t\n$$\n瞬时估计 $\\tilde{x}_{1,t}$ 是 $\\tilde{z}_t$ 的第一个分量，即 $\\tilde{x}_{1,t} = e_1^{\\top} \\tilde{z}_t$。\n首先，我们计算矩阵 $A^{\\top} A$ 及其逆矩阵：\n$$\nA^{\\top}A = \\begin{pmatrix} a_1^{\\top}a_1  a_1^{\\top}a_2 \\\\ a_2^{\\top}a_1  a_2^{\\top}a_2 \\end{pmatrix} = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}\n$$\n$$\n(A^{\\top}A)^{-1} = \\frac{1}{\\det(A^{\\top}A)} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix} = \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix}\n$$\n估计量向量的条件期望为：\n$$\n\\mathbb{E}[\\tilde{z}_t \\,|\\, \\widehat{S}_t=\\{1,2\\}] = \\mathbb{E}[(A^{\\top}A)^{-1} A^{\\top} y_t] = (A^{\\top}A)^{-1} A^{\\top} \\mathbb{E}[y_t]\n$$\n$$\n= (A^{\\top}A)^{-1} A^{\\top} (A x^{\\star}) = (A^{\\top}A)^{-1} (A^{\\top}A) x^{\\star} = x^{\\star} = \\begin{pmatrix} \\theta \\\\ \\theta \\end{pmatrix}\n$$\n这表明当支撑集被正确识别时，OLS 估计量是无偏的。第一个分量的期望为：\n$$\n\\mathbb{E}[\\tilde{x}_{1,t} \\,|\\, \\widehat{S}_t=\\{1,2\\}] = e_1^{\\top} x^{\\star} = \\theta\n$$\n现在，我们将两种情况的结果代入全期望定律：\n$$\n\\mathbb{E}[\\tilde{x}_{1,t}] = p \\cdot \\theta(1+\\rho) + (1-p) \\cdot \\theta\n$$\n$$\n= p\\theta + p\\theta\\rho + \\theta - p\\theta = \\theta + p\\theta\\rho = \\theta(1+p\\rho)\n$$\n这是估计 $\\widehat{x}_{1,t}$ 的稳态期望值：\n$$\n\\lim_{t \\to \\infty} \\mathbb{E}[\\widehat{x}_{1,t}] = \\theta(1+p\\rho)\n$$\n最后，稳态期望偏差是该值与真实值 $\\theta$ 之间的差：\n$$\n\\text{偏差} = \\lim_{t \\to \\infty} \\mathbb{E}[\\widehat{x}_{1,t} - \\theta] = \\lim_{t \\to \\infty} \\mathbb{E}[\\widehat{x}_{1,t}] - \\theta\n$$\n$$\n= \\theta(1+p\\rho) - \\theta = \\theta + p\\theta\\rho - \\theta = p\\theta\\rho\n$$\n该偏差与漏选支撑集元素的概率 $p$、信号幅度 $\\theta$ 和字典相关性 $\\rho$ 成正比。", "answer": "$$\n\\boxed{p\\theta\\rho}\n$$", "id": "3463824"}]}