{"hands_on_practices": [{"introduction": "一个好的传感矩阵的关键性能指标之一是其与稀疏基的非相干性。本练习将通过计算一种广泛使用的结构化随机矩阵——部分循环矩阵的互相关性，来实践评估这一指标。通过这个计算，您将看到这些结构如何实现近乎最优的非相干性，这是压缩感知成功的关键特性。 [@problem_id:3482574]", "problem": "考虑一个长度为 $n \\in \\mathbb{N}$ 的离散循环卷积模型。设 $h \\in \\{-1,+1\\}^{n}$ 是一个生成向量，其元素是独立同分布的Rademacher项，并设 $C(h) \\in \\mathbb{R}^{n \\times n}$ 是通过 $h$ 实现循环卷积的循环矩阵，对于任意 $x \\in \\mathbb{R}^{n}$ 定义为 $(C(h)x)_{k} = \\sum_{j=0}^{n-1} h_{(k-j) \\bmod n} x_{j}$。设 $\\Omega \\subset \\{0,1,\\ldots,n-1\\}$ 是一个基数为 $m$ 的均匀随机子集，其中 $1 \\leq m \\leq n$，并设 $R_{\\Omega} \\in \\{0,1\\}^{m \\times n}$ 是行选择算子，用于提取 $C(h)$ 中由 $\\Omega$ 索引的行。定义部分循环系综 $A = R_{\\Omega} C(h) \\in \\mathbb{R}^{m \\times n}$。对于 $k \\in \\Omega$，将 $A$ 的第 $k$ 行表示为 $a_{k} \\in \\mathbb{R}^{n}$，其单位范数版本表示为 $\\tilde{a}_{k} = a_{k}/\\|a_{k}\\|_{2}$。设 $\\mathbb{R}^{n}$ 的规范基为 $\\{e_{j}\\}_{j=0}^{n-1}$，它们共同构成了单位矩阵 $I_{n}$。\n\n两个单位向量集合 $\\{\\tilde{a}_{k}\\}_{k \\in \\Omega}$ 和 $\\{e_{j}\\}_{j=0}^{n-1}$ 之间的互相关性定义为\n$$\\mu(\\tilde{A}, I_{n}) = \\max_{k \\in \\Omega} \\max_{0 \\leq j \\leq n-1} \\left| \\langle \\tilde{a}_{k}, e_{j} \\rangle \\right|.$$\n计算 $\\mu(\\tilde{A}, I_{n})$ 作为 $n$ 的函数的精确值。然后，根据您的计算，从第一性原理出发，论述该相关性值如何影响在卷积字典（例如，位移不变的局部原子集合）中稀疏的信号的压缩感知保证，并明确指出 $\\mu(\\tilde{A}, I_{n})$ 在标准恢复分析中的作用。将 $\\mu(\\tilde{A}, I_{n})$ 的最终答案表示为封闭形式的解析表达式。无需四舍五入，也不涉及单位。", "solution": "用户希望我首先验证一个来自压缩感知领域的问题，然后提供一个解决方案。该问题涉及计算一个特定结构化随机矩阵系综的互相关性并解释其结果。\n\n### 问题验证\n\n**第1步：提取已知条件**\n\n*   $n \\in \\mathbb{N}$：空间维度，循环卷积的长度。\n*   $h \\in \\{-1,+1\\}^{n}$：一个生成向量，其元素是独立同分布（i.i.d.）的Rademacher项。\n*   $C(h) \\in \\mathbb{R}^{n \\times n}$：循环矩阵，使得对于任意 $x \\in \\mathbb{R}^{n}$，$(C(h)x)_{k} = \\sum_{j=0}^{n-1} h_{(k-j) \\bmod n} x_{j}$。\n*   $\\Omega \\subset \\{0,1,\\ldots,n-1\\}$：一个基数为 $m$ 的均匀随机索引子集，其中 $1 \\leq m \\leq n$。\n*   $R_{\\Omega} \\in \\{0,1\\}^{m \\times n}$：对应于 $\\Omega$ 的行选择算子。\n*   $A = R_{\\Omega} C(h) \\in \\mathbb{R}^{m \\times n}$：感知矩阵，一个部分循环矩阵。\n*   $a_{k}$：对于 $k \\in \\Omega$，$A$ 的第 $k$ 行。\n*   $\\tilde{a}_{k} = a_{k}/\\|a_{k}\\|_{2}$：$a_{k}$ 的单位范数版本。\n*   $\\{e_{j}\\}_{j=0}^{n-1}$：$\\mathbb{R}^{n}$ 的规范基向量，它们构成了单位矩阵 $I_{n}$ 的列。\n*   互相关性定义：$\\mu(\\tilde{A}, I_{n}) = \\max_{k \\in \\Omega} \\max_{0 \\leq j \\leq n-1} \\left| \\langle \\tilde{a}_{k}, e_{j} \\rangle \\right|$。\n\n**第2步：使用提取的已知条件进行验证**\n\n该问题具有科学依据，位于压缩感知和线性代数的标准数学框架内。所有术语，如“循环矩阵”、“Rademacher项”和“互相关性”，在该领域都是明确定义且标准的。问题设定是形式化且客观的。\n\n为了检查问题是否适定，我们必须确定量 $\\mu(\\tilde{A}, I_{n})$ 是否可以作为一个确定性值来计算。矩阵 $A$ 依赖于随机向量 $h$ 和随机集合 $\\Omega$。我们来分析最大化内部的项：$\\left| \\langle \\tilde{a}_{k}, e_{j} \\rangle \\right|$。\n\n对于索引 $k \\in \\Omega$，向量 $a_k$ 是完整循环矩阵 $C(h)$ 的第 $k$ 行。根据卷积的定义，$C(h)$ 的第 $k$ 行是向量 $(h_{k \\bmod n}, h_{(k-1) \\bmod n}, \\ldots, h_{(k-(n-1)) \\bmod n})$。我们将其表示为 $c_k^T$。因此，$a_k = c_k$。\n\n首先，我们计算 $a_k$ 的欧几里得范数。$a_k$ 的分量是 $h$ 的分量的循环移位。\n$$\n\\|a_{k}\\|_{2}^{2} = \\sum_{j=0}^{n-1} (h_{(k-j) \\bmod n})^{2}\n$$\n由于当 $j=0, \\ldots, n-1$ 时，索引 $(k-j) \\bmod n$ 恰好覆盖集合 $\\{0, \\ldots, n-1\\}$ 一次，所以这个求和等价于对 $h$ 的所有分量求和。\n$$\n\\|a_{k}\\|_{2}^{2} = \\sum_{l=0}^{n-1} h_{l}^{2}\n$$\n给定 $h_l \\in \\{-1, +1\\}$，对于所有 $l$ 我们有 $h_{l}^{2} = 1$。\n$$\n\\|a_{k}\\|_{2}^{2} = \\sum_{l=0}^{n-1} 1 = n\n$$\n因此，$\\|a_{k}\\|_{2} = \\sqrt{n}$。这个范数是一个确定性值，与 $h$ 的具体实现和索引 $k$ 无关。归一化的行为 $\\tilde{a}_{k} = a_{k} / \\sqrt{n}$。\n\n接下来，我们计算内积 $\\langle a_{k}, e_{j} \\rangle$。这个内积提取了向量 $a_k$ 的第 $j$ 个分量。\n$$\n\\langle a_{k}, e_{j} \\rangle = (a_k)_j = h_{(k-j) \\bmod n}\n$$\n现在，我们可以计算涉及归一化向量的内积的完整表达式。\n$$\n\\langle \\tilde{a}_{k}, e_{j} \\rangle = \\frac{\\langle a_{k}, e_{j} \\rangle}{\\|a_{k}\\|_{2}} = \\frac{h_{(k-j) \\bmod n}}{\\sqrt{n}}\n$$\n取绝对值，我们得到：\n$$\n\\left| \\langle \\tilde{a}_{k}, e_{j} \\rangle \\right| = \\left| \\frac{h_{(k-j) \\bmod n}}{\\sqrt{n}} \\right| = \\frac{|h_{(k-j) \\bmod n}|}{\\sqrt{n}}\n$$\n因为对于所有 $l$，都有 $|h_l|=1$，我们得到：\n$$\n\\left| \\langle \\tilde{a}_{k}, e_{j} \\rangle \\right| = \\frac{1}{\\sqrt{n}}\n$$\n这个值对于所有的 $k \\in \\Omega$ 和所有的 $j \\in \\{0, \\ldots, n-1\\}$ 都是常数，并且它不依赖于 $h$ 或 $\\Omega$ 的随机选择。\n\n最后，我们通过在所有允许的索引上取最大值来计算互相关性：\n$$\n\\mu(\\tilde{A}, I_{n}) = \\max_{k \\in \\Omega} \\max_{0 \\leq j \\leq n-1} \\left( \\frac{1}{\\sqrt{n}} \\right) = \\frac{1}{\\sqrt{n}}\n$$\n结果是 $n$ 的一个唯一的、确定性的函数。因此，该问题是适定的、自洽的，并且科学上是合理的。\n\n**第3步：结论与行动**\n\n问题是有效的。我们将继续提供完整的解决方案。\n\n### 解决方案\n\n问题要求计算互相关性 $\\mu(\\tilde{A}, I_{n})$ 并讨论其对压缩感知的影响。\n\n**第1部分：互相关性的计算**\n\n矩阵 $A$ 的归一化行集合 $\\{\\tilde{a}_{k}\\}_{k \\in \\Omega}$ 与规范基向量集合 $\\{e_{j}\\}_{j=0}^{n-1}$（$I_n$ 的列）之间的互相关性定义为：\n$$\n\\mu(\\tilde{A}, I_{n}) = \\max_{k \\in \\Omega} \\max_{0 \\leq j \\leq n-1} \\left| \\langle \\tilde{a}_{k}, e_{j} \\rangle \\right|\n$$\n计算过程通过分析项 $\\langle \\tilde{a}_{k}, e_{j} \\rangle$ 来进行，该项是感知矩阵的归一化行与规范基中的向量之间的内积。\n\n首先，确定行向量 $a_k$ 的结构。对于任意 $k \\in \\Omega$，$a_k$ 是循环矩阵 $C(h)$ 的第 $k$ 行。根据循环卷积的定义，$C(h)$ 的第 $i$ 行是生成向量 $h$ 的一个循环移位版本。具体来说，第 $k$ 行的第 $j$ 个元素是 $(a_k)_j = h_{(k-j) \\bmod n}$。\n\n第二，我们确定 $a_k$ 的范数。其 $l_2$ 范数的平方是其分量平方的和：\n$$\n\\|a_k\\|_2^2 = \\sum_{j=0}^{n-1} ((a_k)_j)^2 = \\sum_{j=0}^{n-1} (h_{(k-j) \\bmod n})^2\n$$\n索引集合 $\\{(k-j) \\bmod n \\mid j=0, \\ldots, n-1\\}$ 是 $\\{0, \\ldots, n-1\\}$ 的一个排列。因此，该求和等价于 $h$ 中所有元素平方的和：\n$$\n\\|a_k\\|_2^2 = \\sum_{l=0}^{n-1} h_l^2\n$$\n由于每个元素 $h_l$ 来自集合 $\\{-1, +1\\}$，我们有 $h_l^2=1$。\n$$\n\\|a_k\\|_2^2 = \\sum_{l=0}^{n-1} 1 = n\n$$\n这给出了范数 $\\|a_k\\|_2 = \\sqrt{n}$。重要的是，这个值对于所有行 $a_k$ 都是相同的，并且与 Rademacher 向量 $h$ 的具体实现无关。\n归一化的行为 $\\tilde{a}_k = a_k / \\|a_k\\|_2 = a_k / \\sqrt{n}$。\n\n第三，我们计算内积 $\\langle \\tilde{a}_k, e_j \\rangle$。内积 $\\langle a_k, e_j \\rangle$ 只是分离出 $a_k$ 的第 $j$ 个分量。\n$$\n\\langle a_k, e_j \\rangle = (a_k)_j = h_{(k-j) \\bmod n}\n$$\n所以，与归一化向量的内积是：\n$$\n\\langle \\tilde{a}_k, e_j \\rangle = \\frac{\\langle a_k, e_j \\rangle}{\\|a_k\\|_2} = \\frac{h_{(k-j) \\bmod n}}{\\sqrt{n}}\n$$\n第四，我们取这个量的绝对值。\n$$\n\\left| \\langle \\tilde{a}_k, e_j \\rangle \\right| = \\left| \\frac{h_{(k-j) \\bmod n}}{\\sqrt{n}} \\right| = \\frac{|h_{(k-j) \\bmod n}|}{\\sqrt{n}} = \\frac{1}{\\sqrt{n}}\n$$\n最后一步成立是因为对所有 $l$ 都有 $|h_l| = 1$。结果是一个常数值，与 $k$ 和 $j$ 以及 $h$ 和 $\\Omega$ 的随机选择均无关。\n\n最后，互相关性是在指定的 $k$ 和 $j$ 范围内对这个常数值取最大值。\n$$\n\\mu(\\tilde{A}, I_{n}) = \\max_{k \\in \\Omega} \\max_{0 \\leq j \\leq n-1} \\frac{1}{\\sqrt{n}} = \\frac{1}{\\sqrt{n}}\n$$\n\n**第2部分：对压缩感知的解释**\n\n计算出的值 $\\mu(\\tilde{A}, I_{n}) = 1/\\sqrt{n}$ 表示测量系综（$A$ 的行）与规范基 $I_n$ 之间的相关性。在压缩感知（CS）的背景下，这个量对于建立恢复保证至关重要。\n\n在标准 CS 模型中，我们的目标是从有限的测量值 $y = \\Phi x$ 中恢复稀疏信号 $x$。信号 $x$ 通常被假定在某个正交基 $\\Psi$ 中是稀疏的，因此 $x = \\Psi \\alpha$，其中 $\\alpha$ 是一个稀疏系数向量。测量矩阵是 $\\Phi$，用于恢复的“字典”是 $D = \\Phi \\Psi$。CS 恢复算法（如基追踪（$\\ell_1$-最小化））的成功取决于 $D$ 的性质，这些性质通常由相关性或受限等距性质（RIP）来表征。\n\n量 $\\mu(\\tilde{A}, I_{n})$ 测量了感知矩阵 $A$（我们的 $\\Phi$）和规范基 $I_n$（我们的 $\\Psi$）之间的相关性。这对应于信号 $x$ 被假定在标准基本身中是稀疏的情况。这类信号是少数几个规范基向量 $e_j$ 的线性组合，代表脉冲或点源。\n\n压缩感知的一个基本原则是，当感知向量与稀疏基向量尽可能“不相关”或“非相干”时，恢复更鲁棒且需要更少的测量。一个低的相关性值，比如我们计算出的这个，是非常理想的。值 $1/\\sqrt{n}$ 是 $\\mathbb{R}^n$ 中任意两个正交基之间可能达到的最低相关性（称为Welch界，该界也更普遍地适用）。在这里，我们的感知向量 $\\{\\tilde{a}_k\\}$ 不是一个正交基，但它们与规范基达到了这种理想的不相关水平。\n\n$1/\\sqrt{n}$ 的这种低相关性意味着每次测量 $y_k = \\langle a_k, x \\rangle$ 都以一种分布式的、无偏好的方式捕获关于 $x$ 所有分量的信息。没有任何单个稀疏元素（在位置 $j$ 的非零分量）可以逃避测量，因为它对任何测量 $y_k$ 的贡献由 $x_j \\langle a_k, e_j \\rangle$ 给出，其幅度为 $|x_j|$，并且是良好分布的。这种测量的“民主性”是成功稀疏恢复的关键。标准CS理论保证，如果测量次数 $m$ 满足例如 $m \\gtrsim C \\cdot \\mu^2 \\cdot s \\cdot \\log n$（其中 $\\mu$ 是相关性的度量），则可以从 $m$ 次测量中恢复一个 $s$-稀疏信号。我们发现的最小相关性表明，这种测量方案对于在规范基中稀疏的信号是高效的。\n\n问题提到了在“卷积字典”中稀疏的信号。规范基 $I_n = C(e_0)$ 是最简单的此类字典，由单个脉冲原子 $d=e_0$ 生成。对于更一般的原子 $d \\in \\mathbb{R}^n$，稀疏“基”是字典向量的集合 $\\{\\psi_j\\}_{j=0}^{n-1}$，其中 $\\psi_j$ 是循环矩阵 $C(d)$ 的第 $j$ 列。那么相关性将是 $\\max_{k \\in \\Omega, j} |\\langle \\tilde{a}_k, \\psi_j \\rangle|$。正如我们分析的那样，这导致需要分析随机滤波器 $h$ 和原子 $d$ 之间的循环互相关。因为 $h$ 是一个独立同分布的随机向量，它的行为类似于离散白噪声。它与任何固定的、结构化的原子 $d$ 的互相关预计会很小，受测度集中现象的限制。因此，测量系综 $A=R_\\Omega C(h)$ 预计不仅与规范基表现出低相关性，而且与广泛的卷积字典也表现出低相关性。计算出的值 $\\mu(\\tilde{A}, I_{n}) = 1/\\sqrt{n}$ 是一个重要的基准，代表了最大局部化原子（脉冲）的理想情况，并证实了这种结构化随机矩阵族在压缩感知应用中的优异性质。", "answer": "$$\n\\boxed{\\frac{1}{\\sqrt{n}}}\n$$", "id": "3482574"}, {"introduction": "在看了一个良好非相干矩阵的例子之后，理解高相干性会带来什么后果将非常有启发性。本练习通过分析一个具有最大相干性的系统（子采样单位矩阵），具体展示了高相干性如何导致信号几何性质的破坏。这直接导致了对“受限等距性质”（Restricted Isometry Property, RIP）的违背，从而为了解非相干性为何如此重要提供了深刻的直觉。 [@problem_id:3482545]", "problem": "设 $n \\in \\mathbb{N}$ 且 $U \\in \\mathbb{R}^{n \\times n}$ 是一个标准正交系。$U$ 的相干性定义为\n$$\n\\mu(U) \\equiv n \\cdot \\max_{1 \\leq i,j \\leq n} |U_{ij}|^{2}.\n$$\n给定一个从 $\\{1,\\dots,n\\}$ 中无放回均匀选取的基数为 $m$ 的子集 $\\Omega$，定义均匀行子采样算子 $P_{\\Omega} \\in \\mathbb{R}^{m \\times n}$，它选取由 $\\Omega$ 索引的行，并定义测量矩阵 $A = P_{\\Omega} U \\in \\mathbb{R}^{m \\times n}$。对于 $s \\in \\mathbb{N}$，$s$-受限等距常数 $\\delta_{s}(A)$ 是满足以下条件的最小非负数 $\\delta \\geq 0$：对于每个 $s$-稀疏向量 $x \\in \\mathbb{R}^{n}$，\n$$\n(1-\\delta)\\|x\\|_{2}^{2} \\leq \\|A x\\|_{2}^{2} \\leq (1+\\delta)\\|x\\|_{2}^{2}.\n$$\n\n考虑高相干性标准正交系 $U = I_{n}$ (单位矩阵)，其中 $n = 4096$，$m = 1024$。仅使用上述定义作为基础，完成以下任务：\n- 计算 $\\mu(U)$。\n- 构造一个显式的 $1$-稀疏向量 $x^{\\star} \\in \\mathbb{R}^{n}$，在给定 $m$ 和 $n$ 的条件下，该向量在 $A = P_{\\Omega} U$ 的受限等距不等式中表现出最坏情况的下界违背。\n- 从第一性原理出发，确定 $1$-受限等距常数 $\\delta_{1}(A)$ 的精确值。\n\n请提供 $\\delta_{1}(A)$ 的精确值作为最终答案，该答案应为一个实数。不需要四舍五入，也不涉及单位。", "solution": "首先根据指定标准对问题陈述进行验证。\n\n### 第 1 步：提取已知条件\n- $n \\in \\mathbb{N}$\n- $U \\in \\mathbb{R}^{n \\times n}$ 是一个标准正交系。\n- 相干性：$\\mu(U) \\equiv n \\cdot \\max_{1 \\leq i,j \\leq n} |U_{ij}|^{2}$。\n- $\\Omega \\subset \\{1,\\dots,n\\}$, $|\\Omega| = m$，无放回均匀选取。\n- $P_{\\Omega} \\in \\mathbb{R}^{m \\times n}$ 是均匀行子采样算子。\n- $A = P_{\\Omega} U \\in \\mathbb{R}^{m \\times n}$。\n- $s$-受限等距常数 $\\delta_{s}(A)$ 是满足以下条件的最小非负数 $\\delta \\geq 0$：对于每个 $s$-稀疏向量 $x \\in \\mathbb{R}^{n}$，$(1-\\delta)\\|x\\|_{2}^{2} \\leq \\|A x\\|_{2}^{2} \\leq (1+\\delta)\\|x\\|_{2}^{2}$。\n- 具体实例：$U = I_{n}$ ($n \\times n$ 单位矩阵)。\n- 具体数值：$n = 4096$，$m = 1024$。\n- 任务：\n    1. 计算 $\\mu(U)$。\n    2. 构造一个显式的 $1$-稀疏向量 $x^{\\star} \\in \\mathbb{R}^{n}$，该向量表现出最坏情况的下界违背。\n    3. 确定 $1$-受限等距常数 $\\delta_{1}(A)$ 的精确值。\n\n### 第 2 步：使用提取的已知条件进行验证\n该问题具有科学依据，提法恰当且客观。所有定义和常数在压缩感知数学领域都是标准的。该问题是自洽的，并提供了推导所求量的唯一、有意义解所需的所有信息。选择 $U=I_n$ 并进行行子采样是用于说明相干性和受限等距性质 (RIP) 概念的典型例子。该问题并非平凡，因为它需要仔细应用基本定义。因此，该问题被认为是有效的。\n\n### 第 3 步：结论与行动\n问题有效。下面提供一个完整的、有理有据的解答。\n\n解答过程将按问题陈述中指定的三个任务进行。\n\n**第 1 部分：计算相干性 $\\mu(U)$**\n\n给定的标准正交系是单位矩阵，$U = I_n \\in \\mathbb{R}^{n \\times n}$。$U$ 的元素由克罗内克 δ (Kronecker delta) 给出，$U_{ij} = \\delta_{ij}$，其中当 $i=j$ 时 $\\delta_{ij} = 1$，当 $i \\neq j$ 时 $\\delta_{ij} = 0$。\n\n相干性 $\\mu(U)$ 定义为：\n$$\n\\mu(U) \\equiv n \\cdot \\max_{1 \\leq i,j \\leq n} |U_{ij}|^{2}\n$$\n我们首先计算 $U = I_n$ 的最大元素平方值：\n$$\n\\max_{1 \\leq i,j \\leq n} |(I_n)_{ij}|^{2} = \\max_{1 \\leq i,j \\leq n} |\\delta_{ij}|^{2}\n$$\n$|\\delta_{ij}|^2$ 的值在 $i=j$ 时为 $1^2=1$，在 $i \\neq j$ 时为 $0^2=0$。这些值的最大值显然是 $1$。\n$$\n\\max_{1 \\leq i,j \\leq n} |\\delta_{ij}|^{2} = 1\n$$\n将此结果代入相干性的定义，其中 $n=4096$：\n$$\n\\mu(I_n) = n \\cdot 1 = n = 4096\n$$\n该系统具有最大可能的相干性，这是稀疏基在其自身域中的一个特征。\n\n**第 2 部分：构造最坏情况下的 $1$-稀疏向量 $x^{\\star}$**\n\n测量矩阵为 $A = P_{\\Omega} U = P_{\\Omega} I_n = P_{\\Omega}$。$A$ 是一个 $m \\times n$ 矩阵，其中 $m=1024$，$n=4096$。算子 $P_\\Omega$ 选取 $I_n$ 中由集合 $\\Omega \\subset \\{1, \\dots, n\\}$（其中 $|\\Omega| = m$）索引的行。\n\n我们来分析 $A$ 的列。设 $a_j \\in \\mathbb{R}^m$ 为 $A$ 的第 $j$ 列。\n$A e_j = a_j$，其中 $e_j \\in \\mathbb{R}^n$ 是第 $j$ 个标准基向量。\n$A e_j = P_\\Omega e_j$。向量 $P_\\Omega e_j$ 是通过取 $I_n$ 的第 $j$ 列（即 $e_j$）并仅保留索引在 $\\Omega$ 中的行而形成的。\n\n- 如果索引 $j$ 在所选行的集合中，$j \\in \\Omega$，那么第 $j$ 行被选中。向量 $e_j$ 在位置 $j$ 处为 $1$，其他位置为零。当通过 $P_\\Omega$ 进行子采样时，得到的列 $a_j$ 将在对应于行的新编号中索引 $j$ 的位置上包含一个 $1$，其他位置为零。因此，$a_j$ 是 $\\mathbb{R}^m$ 中的一个标准基向量。其欧几里得范数的平方为 $\\|a_j\\|_2^2 = 1$。\n\n- 如果索引 $j$ 不在所选行的集合中，$j \\notin \\Omega$，那么第 $j$ 行被丢弃。由于第 $j$ 列 $e_j$ 仅在第 $j$ 行有一个非零项，而该行未被选中，因此得到的列 $a_j$ 是 $\\mathbb{R}^m$ 中的零向量。其欧几里得范数的平方为 $\\|a_j\\|_2^2 = 0$。\n\n受限等距不等式为 $(1-\\delta)\\|x\\|_{2}^{2} \\leq \\|A x\\|_{2}^{2} \\leq (1+\\delta)\\|x\\|_{2}^{2}$。最坏情况的下界违背发生在使比率 $\\frac{\\|Ax\\|_2^2}{\\|x\\|_2^2}$ 最小化的向量 $x$ 上。\n\n我们考虑一个通用的 $1$-稀疏向量 $x \\in \\mathbb{R}^n$。它可以写成 $x = c e_j$ 的形式，其中标量 $c \\in \\mathbb{R} \\setminus \\{0\\}$，索引 $j \\in \\{1,\\dots,n\\}$。\n对于这样的向量，$\\|x\\|_2^2 = \\|c e_j\\|_2^2 = c^2 \\|e_j\\|_2^2 = c^2$。\n其测量值的范数平方为 $\\|Ax\\|_2^2 = \\|A (c e_j)\\|_2^2 = c^2 \\|A e_j\\|_2^2 = c^2 \\|a_j\\|_2^2$。\n该比率为 $\\frac{\\|Ax\\|_2^2}{\\|x\\|_2^2} = \\|a_j\\|_2^2$。\n\n为了找到最坏情况的违背，我们必须找到使 $\\|a_j\\|_2^2$ 最小化的索引 $j$。根据我们对 $A$ 的列的分析：\n$$\n\\min_{j=1,\\dots,n} \\|a_j\\|_2^2 = 0\n$$\n对于任何满足 $j \\notin \\Omega$ 的索引 $j$，都可以达到这个最小值。由于 $m=1024  n=4096$，集合 $\\{1,\\dots,n\\} \\setminus \\Omega$ 非空，并包含 $n-m = 3072$ 个索引。\n\n因此，我们可以通过选择任意索引 $j_0 \\notin \\Omega$ 来构造一个显式的最坏情况向量 $x^\\star$。设 $j_0$ 是 $\\{1, \\dots, 4096\\} \\setminus \\Omega$ 中的任意整数。一个表现出最坏情况的下界违背的显式向量是：\n$$\nx^{\\star} = e_{j_0}\n$$\n对于这个向量，$\\|x^{\\star}\\|_2^2 = 1$，并且由于 $j_0 \\notin \\Omega$，$\\|A x^{\\star}\\|_2^2 = \\|a_{j_0}\\|_2^2 = 0$。对于 $s=1$ 的下界不等式变为 $(1-\\delta_1)\\|x^{\\star}\\|_2^2 \\leq \\|Ax^{\\star}\\|_2^2$，即 $(1-\\delta_1) \\cdot 1 \\leq 0$，这意味着 $\\delta_1 \\geq 1$。\n\n**第 3 部分：确定 $1$-受限等距常数 $\\delta_1(A)$**\n\n$1$-受限等距常数 $\\delta_1(A)$ 是对所有 $1$-稀疏向量 $x$ 都满足不等式的最小非负数 $\\delta$。如上所示，对于任何 $1$-稀疏向量 $x=ce_j$，该不等式等价于：\n$$\n1-\\delta \\leq \\|a_j\\|_2^2 \\leq 1+\\delta\n$$\n这必须对索引 $j \\in \\{1, \\dots, n\\}$ 的所有可能选择都成立。这等价于同时满足以下两个条件：\n$$\n1 - \\delta \\leq \\min_{j=1,\\dots,n} \\|a_j\\|_2^2\n$$\n$$\n\\max_{j=1,\\dots,n} \\|a_j\\|_2^2 \\leq 1 + \\delta\n$$\n从第 2 部分，我们已经确定了 $A$ 的列的范数平方的最小值和最大值：\n- 由于 $m  n$，至少存在一个列 $a_j$ 是零向量，因此 $\\min_{j=1,\\dots,n} \\|a_j\\|_2^2 = 0$。\n- 由于 $m > 0$，至少存在一个列 $a_j$ 是 $\\mathbb{R}^m$ 中的标准基向量，因此 $\\max_{j=1,\\dots,n} \\|a_j\\|_2^2 = 1$。\n\n将这些值代入不等式中：\n1. $1 - \\delta \\leq 0 \\implies \\delta \\geq 1$。\n2. $1 \\leq 1 + \\delta \\implies \\delta \\geq 0$。\n\n两个条件都必须满足。最严格的条件是 $\\delta \\geq 1$。\n常数 $\\delta_1(A)$ 定义为满足这些条件的*最小*非负 $\\delta$。因此，精确值为：\n$$\n\\delta_1(A) = 1\n$$\n这个结果与子集 $\\Omega$ 的具体选择无关，只要它是 $\\{1, \\dots, n\\}$ 的一个真子集，这一点由 $m  n$ 保证。", "answer": "$$\n\\boxed{1}\n$$", "id": "3482545"}, {"introduction": "结构化随机矩阵的性质不仅取决于其核心结构（如Hadamard或Fourier），还取决于所采用的随机化方法。本练习通过比较两种不同采样方案（有放回和无放回）构建的子采样Hadamard矩阵，深入探讨了这种细微差别。通过分析其能量保持的统计方差，您将揭示随机化策略的选择如何影响测量系统的稳定性。 [@problem_id:3482581]", "problem": "令 $n$ 为 2 的幂，令 $H \\in \\mathbb{R}^{n \\times n}$ 为归一化 Hadamard 矩阵，其元素取自 $\\{\\pm n^{-1/2}\\}$，因此有 $H^{\\top} H = I_{n}$。令 $D \\in \\mathbb{R}^{n \\times n}$ 为一个对角矩阵，其对角线上的元素是独立的 Rademacher 条目，并令 $x \\in \\mathbb{R}^{n}$ 为一个固定向量。定义 $z := H D x \\in \\mathbb{R}^{n}$，并注意根据正交性有 $\\|z\\|_{2}^{2} = \\|x\\|_{2}^{2}$。\n\n对于给定的采样预算 $m \\in \\{1,2,\\dots,n\\}$，根据以下两种模型之一，通过选择单位矩阵的 $m$ 行来构造一个选择器矩阵 $P \\in \\mathbb{R}^{m \\times n}$：\n\n1. 有放回抽样：从 $\\{1,\\dots,n\\}$ 中独立且均匀地选择索引 $I_{1},\\dots,I_{m}$，并令 $P$ 的行为 $e_{I_{1}}^{\\top},\\dots,e_{I_{m}}^{\\top}$。\n2. 无放回抽样：从 $\\{1,\\dots,n\\}$ 中均匀随机地选择一个大小为 $m$ 的子集 $S$，并令 $P$ 的行为 $\\{e_{i}^{\\top} : i \\in S\\}$。\n\n定义结构化随机传感矩阵 $A := \\sqrt{\\frac{n}{m}}\\, P H D$ 和随机二次型 $Y := \\|A x\\|_{2}^{2}$。将 $H$ 和 $D$ 视为固定的，并仅考虑 $P$ 的随机性。从期望和方差的定义、$H$ 的正交性以及关于有放回和无放回抽样的标准事实（这些事实可以使用经典的有限数组集中不等式，如 Hoeffding 或 Serfling 的不等式来证明）出发，推导在两种抽样模型下 $\\operatorname{Var}(Y \\mid z)$ 的显式表达式，该表达式用 $\\{z_{i}^{2}\\}_{i=1}^{n}$ 的经验矩表示。然后，简化以获得精确的比率\n$$\nR := \\frac{\\operatorname{Var}_{\\text{without replacement}}(Y \\mid z)}{\\operatorname{Var}_{\\text{with replacement}}(Y \\mid z)}.\n$$\n以仅依赖于 $n$ 和 $m$ 的封闭形式表达式给出 $R$。不需要数值近似，也不涉及任何单位。将你的最终答案表示为单个简化表达式。", "solution": "该问题提法明确，具有科学依据，并包含足够的信息以获得唯一解。所有参数都已明确定义，任务是抽样理论和统计学中的一个标准推导，应用于压缩感知的背景。\n\n我们首先将随机二次型 $Y$ 形式化。矩阵 $A$ 定义为 $A = \\sqrt{\\frac{n}{m}} P H D$。向量 $x$是固定的，我们以 $z = H D x$ 为条件。这意味着在对抽样矩阵 $P$ 的随机性进行分析时， $z \\in \\mathbb{R}^n$ 被视为一个固定的常数向量。\n\n我们关心的量是 $Y = \\|A x\\|_{2}^{2}$。我们可以用 $z$ 来表示它：\n$$\nY = \\|A x\\|_{2}^{2} = (A x)^{\\top} (A x) = x^{\\top} A^{\\top} A x\n$$\n代入 $A$ 的定义：\n$$\nA^{\\top} A = \\left(\\sqrt{\\frac{n}{m}} P H D\\right)^{\\top} \\left(\\sqrt{\\frac{n}{m}} P H D\\right) = \\frac{n}{m} (HD)^{\\top} P^{\\top} P (HD)\n$$\n因此，\n$$\nY = \\frac{n}{m} x^{\\top} (HD)^{\\top} P^{\\top} P (HD) x = \\frac{n}{m} (HDx)^{\\top} P^{\\top} P (HDx) = \\frac{n}{m} z^{\\top} P^{\\top} P z\n$$\n矩阵 $P \\in \\mathbb{R}^{m \\times n}$ 的行是标准基向量 $e_{I_k}^{\\top}$，其中 $k=1, \\dots, m$。矩阵乘积 $P^{\\top} P$ 是一个对角矩阵，其第 $j$ 个对角元素记录了索引 $j$ 被选择的次数。令 $I_1, \\dots, I_m$ 为被选中的索引。那么 $P^{\\top}P = \\sum_{k=1}^m e_{I_k}e_{I_k}^{\\top}$。\n二次型简化为：\n$$\nY = \\frac{n}{m} z^{\\top} \\left(\\sum_{k=1}^{m} e_{I_k} e_{I_k}^{\\top}\\right) z = \\frac{n}{m} \\sum_{k=1}^{m} z^{\\top} e_{I_k} e_{I_k}^{\\top} z = \\frac{n}{m} \\sum_{k=1}^{m} (z^{\\top} e_{I_k})^2 = \\frac{n}{m} \\sum_{k=1}^{m} z_{I_k}^2\n$$\n我们定义一个包含 $n$ 个值的总体 $\\mathcal{W} = \\{w_1, w_2, \\dots, w_n\\}$，其中 $w_i = z_i^2$。$Y$ 的表达式是从总体 $\\mathcal{W}$ 中抽取的 $m$ 个样本之和的 $\\frac{n}{m}$ 倍。我们需要在两种指定的抽样模型下计算 $\\operatorname{Var}(Y \\mid z)$。随机性来自于对索引 $I_k \\in \\{1,\\dots,n\\}$ 的选择。\n\n令 $\\mathcal{M}_1$ 和 $\\mathcal{M}_2$ 为总体 $\\{w_i\\}$ 的前两个经验矩：\n$$\n\\mathcal{M}_1 = \\frac{1}{n} \\sum_{i=1}^{n} w_i = \\frac{1}{n} \\sum_{i=1}^{n} z_i^2\n$$\n$$\n\\mathcal{M}_2 = \\frac{1}{n} \\sum_{i=1}^{n} w_i^2 = \\frac{1}{n} \\sum_{i=1}^{n} z_i^4\n$$\n总体方差（使用 $1/n$ 缩放）为 $\\sigma_{\\mathcal{W}}^2 = \\frac{1}{n}\\sum_{i=1}^n (w_i - \\mathcal{M}_1)^2 = \\mathcal{M}_2 - \\mathcal{M}_1^2$。\n\n首先，我们计算 $Y$ 的期望，它在两种模型下是相同的。令 $W_k = w_{I_k}$。\n$$\n\\mathbb{E}[Y] = \\mathbb{E}\\left[\\frac{n}{m} \\sum_{k=1}^{m} W_k\\right] = \\frac{n}{m} \\sum_{k=1}^{m} \\mathbb{E}[W_k]\n$$\n对于任何 $k$，$\\mathbb{E}[W_k] = \\sum_{j=1}^n P(I_k=j) w_j$。在两种模型中，$P(I_k=j) = 1/n$。因此，$\\mathbb{E}[W_k] = \\frac{1}{n}\\sum_{j=1}^n w_j = \\mathcal{M}_1$。\n$$\n\\mathbb{E}[Y] = \\frac{n}{m} \\sum_{k=1}^{m} \\mathcal{M}_1 = \\frac{n}{m} \\cdot m \\mathcal{M}_1 = n \\mathcal{M}_1 = \\sum_{i=1}^n z_i^2 = \\|z\\|_2^2\n$$\n\n现在我们为每个模型计算方差。$\\operatorname{Var}(Y) = \\mathbb{E}[Y^2] - (\\mathbb{E}[Y])^2$。\n\n**模型 1：有放回抽样**\n索引 $I_1, \\dots, I_m$ 是独立同分布 (i.i.d.) 的，在 $\\{1, \\dots, n\\}$ 上均匀分布。因此，随机变量 $W_k = w_{I_k}$ 也是独立同分布的。\n这样一个变量 $W_k$ 的方差是：\n$$\n\\operatorname{Var}(W_k) = \\mathbb{E}[W_k^2] - (\\mathbb{E}[W_k])^2\n$$\n$\\mathbb{E}[W_k^2] = \\sum_{j=1}^n P(I_k=j) w_j^2 = \\frac{1}{n}\\sum_{j=1}^n w_j^2 = \\mathcal{M}_2$。\n$$\n\\operatorname{Var}(W_k) = \\mathcal{M}_2 - \\mathcal{M}_1^2 = \\sigma_{\\mathcal{W}}^2\n$$\n由于 $W_k$ 是独立同分布的，它们的和的方差是它们方差的和：\n$$\n\\operatorname{Var}_{\\text{with}}(Y) = \\operatorname{Var}\\left(\\frac{n}{m} \\sum_{k=1}^{m} W_k\\right) = \\left(\\frac{n}{m}\\right)^2 \\operatorname{Var}\\left(\\sum_{k=1}^{m} W_k\\right) = \\frac{n^2}{m^2} \\sum_{k=1}^{m} \\operatorname{Var}(W_k)\n$$\n$$\n\\operatorname{Var}_{\\text{with}}(Y \\mid z) = \\frac{n^2}{m^2} \\cdot m (\\mathcal{M}_2 - \\mathcal{M}_1^2) = \\frac{n^2}{m} (\\mathcal{M}_2 - \\mathcal{M}_1^2)\n$$\n\n**模型 2：无放回抽样**\n索引 $I_1, \\dots, I_m$ 构成一个大小为 $m$ 的集合 $S$，它是从 $\\{1, \\dots, n\\}$ 中均匀随机选择的 $m$ 个不同索引。变量 $W_k = w_{I_k}$ 不是独立的。\n$$\n\\operatorname{Var}_{\\text{without}}(Y) = \\operatorname{Var}\\left(\\frac{n}{m} \\sum_{k=1}^{m} W_k\\right) = \\frac{n^2}{m^2} \\operatorname{Var}\\left(\\sum_{k=1}^{m} W_k\\right)\n$$\n和的方差是 $\\operatorname{Var}\\left(\\sum_{k=1}^{m} W_k\\right) = \\sum_{k=1}^{m} \\operatorname{Var}(W_k) + \\sum_{k \\neq l} \\operatorname{Cov}(W_k, W_l)$。\n有 $m$ 个方差项和 $m(m-1)$ 个协方差项。由于均匀抽样的对称性，$\\operatorname{Var}(W_k)$ 对所有 $k$ 都是相同的，而 $\\operatorname{Cov}(W_k, W_l)$ 对所有 $k \\neq l$ 都是相同的。\n$\\operatorname{Var}(W_1) = \\mathcal{M}_2 - \\mathcal{M}_1^2$。\n对于 $k \\neq l$，我们计算协方差：\n$$\n\\operatorname{Cov}(W_k, W_l) = \\mathbb{E}[W_k W_l] - \\mathbb{E}[W_k]\\mathbb{E}[W_l] = \\mathbb{E}[w_{I_k} w_{I_l}] - \\mathcal{M}_1^2\n$$\n对于两次不同的抽取，选择索引 $i$ 和 $j$（其中 $i \\neq j$）的联合概率是 $P(I_k=i, I_l=j) = P(I_l=j|I_k=i)P(I_k=i) = \\frac{1}{n-1} \\frac{1}{n}$。\n$$\n\\mathbb{E}[w_{I_k} w_{I_l}] = \\sum_{i=1}^n \\sum_{j \\neq i} P(I_k=i, I_l=j) w_i w_j = \\sum_{i=1}^n \\sum_{j \\neq i} \\frac{1}{n(n-1)} w_i w_j\n$$\n这个和可以写成：\n$$\n\\frac{1}{n(n-1)} \\sum_{i \\neq j} w_i w_j = \\frac{1}{n(n-1)} \\left[ \\left(\\sum_i w_i\\right)^2 - \\sum_i w_i^2 \\right]\n$$\n用矩来表示：\n$$\n\\mathbb{E}[w_{I_k} w_{I_l}] = \\frac{1}{n(n-1)} [ (n\\mathcal{M}_1)^2 - n\\mathcal{M}_2 ] = \\frac{n^2\\mathcal{M}_1^2 - n\\mathcal{M}_2}{n(n-1)} = \\frac{n\\mathcal{M}_1^2 - \\mathcal{M}_2}{n-1}\n$$\n所以，协方差是：\n$$\n\\operatorname{Cov}(W_k, W_l) = \\frac{n\\mathcal{M}_1^2 - \\mathcal{M}_2}{n-1} - \\mathcal{M}_1^2 = \\frac{n\\mathcal{M}_1^2 - \\mathcal{M}_2 - (n-1)\\mathcal{M}_1^2}{n-1} = \\frac{\\mathcal{M}_1^2 - \\mathcal{M}_2}{n-1} = -\\frac{\\sigma_{\\mathcal{W}}^2}{n-1}\n$$\n现在我们来组合这个和的方差：\n$$\n\\operatorname{Var}\\left(\\sum_{k=1}^{m} W_k\\right) = m \\cdot \\sigma_{\\mathcal{W}}^2 + m(m-1) \\left(-\\frac{\\sigma_{\\mathcal{W}}^2}{n-1}\\right) = m \\sigma_{\\mathcal{W}}^2 \\left(1 - \\frac{m-1}{n-1}\\right)\n$$\n$$\n= m \\sigma_{\\mathcal{W}}^2 \\left(\\frac{n-1 - (m-1)}{n-1}\\right) = m \\sigma_{\\mathcal{W}}^2 \\frac{n-m}{n-1}\n$$\n最后，我们求出 $Y$ 的方差：\n$$\n\\operatorname{Var}_{\\text{without}}(Y \\mid z) = \\frac{n^2}{m^2} \\left(m (\\mathcal{M}_2 - \\mathcal{M}_1^2) \\frac{n-m}{n-1}\\right) = \\frac{n^2}{m} (\\mathcal{M}_2 - \\mathcal{M}_1^2) \\frac{n-m}{n-1}\n$$\n\n**方差之比**\n我们要求的是比率 $R = \\frac{\\operatorname{Var}_{\\text{without}}(Y \\mid z)}{\\operatorname{Var}_{\\text{with}}(Y \\mid z)}$。\n$$\nR = \\frac{\\frac{n^2}{m} (\\mathcal{M}_2 - \\mathcal{M}_1^2) \\frac{n-m}{n-1}}{\\frac{n^2}{m}(\\mathcal{M}_2 - \\mathcal{M}_1^2)}\n$$\n假设并非所有的 $z_i^2$ 都相等，那么 $\\mathcal{M}_2 - \\mathcal{M}_1^2 \\neq 0$，我们可以消去这一项。\n$$\nR = \\frac{n-m}{n-1}\n$$\n这个因子被称为有限总体校正。它反映了与从有限总体进行有放回抽样相比，无放回抽样所实现的方差减小。", "answer": "$$ \\boxed{\\frac{n-m}{n-1}} $$", "id": "3482581"}]}