{"hands_on_practices": [{"introduction": "原始对偶混合梯度 (PDHG) 算法的强大之处在于它能将复杂问题分解为更简单的原始和对偶步骤。其中一个关键操作是对偶更新，这需要计算共轭函数 $g^*$ 的近端算子。本练习将引导你推导并应用莫罗恒等式 (Moreau's identity)，这是一个将对偶近端算子与我们更熟悉的原始近端算子联系起来的基本工具，它能显著简化像 $\\ell_1$ 范数这类常用正则化项的计算。[@problem_id:3467285]", "problem": "考虑压缩感知和稀疏优化中的复合凸优化模型，其形式为 $\\min_{x \\in \\mathbb{R}^{n}} f(x) + g(Kx)$，其中 $f$ 和 $g$ 是正常(proper)、闭(closed)、凸(convex)函数，而 $K$ 是一个线性算子。原始-对偶混合梯度（PDHG）算法（也称为 Chambolle-Pock (CP) 算法）迭代执行原始-对偶更新，这需要在对偶变量上计算凸共轭函数 $g^{*}$ 的邻近算子。从邻近算子和凸共轭的定义出发，仅使用公认的凸分析事实，推导当 $g(z) = \\lambda \\|z\\|_{1}$ 时 $\\operatorname{prox}_{\\sigma g^{*}}(y)$ 的一个闭式表达式，该表达式应使用在缩放后的参数上计算的原始函数 $g$ 的邻近算子来表示。然后，对于具体参数 $\\lambda = 1$, $\\sigma = 2$ 和对偶向量 $y = (3,\\,-0.6,\\,1.0,\\,-2.2) \\in \\mathbb{R}^{4}$，计算 $\\operatorname{prox}_{\\sigma g^{*}}(y)$ 的值。最后，在PDHG算法对偶变量更新的背景下，解释当 $g(z)=\\lambda\\|z\\|_{1}$ 时，为什么通过原始邻近算子来表示对偶邻近算子在计算上是有利的。将你最终计算出的邻近算子值以单行向量的形式给出。无需四舍五入，不涉及单位。", "solution": "我们从凸分析的基本定义开始。对于一个正常、闭、凸函数 $h \\colon \\mathbb{R}^{m} \\to \\mathbb{R} \\cup \\{+\\infty\\}$ 和一个参数 $\\tau  0$，邻近算子定义为\n$$\n\\operatorname{prox}_{\\tau h}(v) \\triangleq \\arg\\min_{u \\in \\mathbb{R}^{m}} \\left\\{ h(u) + \\frac{1}{2\\tau} \\|u - v\\|_{2}^{2} \\right\\}。\n$$\n凸共轭函数 $h^{*}$ 定义为\n$$\nh^{*}(y) \\triangleq \\sup_{z \\in \\mathbb{R}^{m}} \\big\\{ \\langle y, z \\rangle - h(z) \\big\\}。\n$$\n一个函数及其凸共轭的邻近算子之间的一个基本关系，即 Moreau 分解，可以从这些定义和 Fenchel-Young 不等式中推导出来。具体来说，可以证明对于任何 $y \\in \\mathbb{R}^{m}$ 和 $\\tau  0$，\n$$\n\\operatorname{prox}_{\\tau h^{*}}(y) + \\tau \\operatorname{prox}_{h/\\tau}\\!\\left(\\frac{y}{\\tau}\\right) = y,\n$$\n这等价于\n$$\n\\operatorname{prox}_{\\tau h^{*}}(y) = y - \\tau \\operatorname{prox}_{h/\\tau}\\!\\left(\\frac{y}{\\tau}\\right)。\n$$\n我们将此恒等式用于 $h = g$，其中 $g(z) = \\lambda \\|z\\|_{1}$。为了计算 $\\operatorname{prox}_{g/\\sigma}$，注意到 $g/\\sigma (z) = \\frac{\\lambda}{\\sigma} \\|z\\|_{1}$ 在各个坐标上是可分的，因此对于任何 $u \\in \\mathbb{R}^{m}$，最小化问题\n$$\n\\operatorname{prox}_{g/\\sigma}(u) = \\arg\\min_{z \\in \\mathbb{R}^{m}} \\left\\{ \\frac{\\lambda}{\\sigma} \\|z\\|_{1} + \\frac{1}{2}\\|z - u\\|_{2}^{2} \\right\\}\n$$\n可以分解为 $m$ 个标量问题。对于一个标量变量 $z \\in \\mathbb{R}$ 和一个标量 $u \\in \\mathbb{R}$，最优性条件可以使用绝对值的次微分来写出：$0 \\in \\frac{\\lambda}{\\sigma} \\partial |z| + (z - u)$。求解这个条件可以得到软阈值（也称为收缩）算子\n$$\nS_{\\theta}(u) \\triangleq \\operatorname{sign}(u)\\,\\max\\{|u| - \\theta,\\,0\\},\n$$\n其中阈值为 $\\theta = \\frac{\\lambda}{\\sigma}$，按分量应用。因此，\n$$\n\\operatorname{prox}_{g/\\sigma}(u) = S_{\\lambda/\\sigma}(u) \\quad \\text{(按分量)}。\n$$\n结合为 $h=g$ 推导出的 Moreau 分解，我们得到\n$$\n\\operatorname{prox}_{\\sigma g^{*}}(y) = y - \\sigma\\,\\operatorname{prox}_{g/\\sigma}\\!\\left(\\frac{y}{\\sigma}\\right) = y - \\sigma\\,S_{\\lambda/\\sigma}\\!\\left(\\frac{y}{\\sigma}\\right),\n$$\n按分量应用。作为交叉检验，注意到对于 $g(z)=\\lambda\\|z\\|_{1}$，其凸共轭是 $g^{*}(y) = \\iota_{\\{\\,\\|y\\|_{\\infty} \\le \\lambda\\,\\}}(y)$，即半径为 $\\lambda$ 的闭 $\\ell_{\\infty}$ 球的指示函数。因此 $\\operatorname{prox}_{\\sigma g^{*}}(y)$ 是 $y$ 在 $\\ell_{\\infty}$ 球上的欧几里得投影，对于可分的坐标，这仅仅是按坐标裁剪到 $[-\\lambda, \\lambda]$。这与上面的表达式一致，因为软阈值和裁剪通过 Moreau 分解是互补的。\n\n现在我们为 $\\lambda = 1$, $\\sigma = 2$ 和 $y = (3,\\,-0.6,\\,1.0,\\,-2.2)$ 计算所要求的邻近算子值。阈值为 $\\theta = \\lambda/\\sigma = 1/2 = 0.5$，我们需要按分量计算 $S_{0.5}(y/\\sigma) = S_{0.5}(y/2)$：\n- 第一个坐标：$\\frac{3}{2} = 1.5$；$S_{0.5}(1.5) = \\operatorname{sign}(1.5)\\,\\max\\{1.5 - 0.5, 0\\} = 1.0$。\n- 第二个坐标：$\\frac{-0.6}{2} = -0.3$；$|{-0.3}| = 0.3  0.5$ 所以 $S_{0.5}(-0.3) = 0$。\n- 第三个坐标：$\\frac{1.0}{2} = 0.5$；$|0.5| - 0.5 = 0$ 所以 $S_{0.5}(0.5) = 0$。\n- 第四个坐标：$\\frac{-2.2}{2} = -1.1$；$S_{0.5}(-1.1) = \\operatorname{sign}(-1.1)\\,(1.1 - 0.5) = -0.6$。\n\n现在应用 $\\operatorname{prox}_{\\sigma g^{*}}(y) = y - \\sigma\\,S_{0.5}(y/2)$：\n- 第一个坐标：$3 - 2 \\cdot 1.0 = 1$。\n- 第二个坐标：$-0.6 - 2 \\cdot 0 = -0.6$。\n- 第三个坐标：$1.0 - 2 \\cdot 0 = 1.0$。\n- 第四个坐标：$-2.2 - 2 \\cdot (-0.6) = -2.2 + 1.2 = -1.0$。\n\n因此，\n$$\n\\operatorname{prox}_{\\sigma g^{*}}(y) = (1,\\,-0.6,\\,1.0,\\,-1.0).\n$$\n\n在 PDHG (Chambolle-Pock) 算法中的计算优势：对偶更新通常需要计算 $\\operatorname{prox}_{\\sigma g^{*}}$，对于一般的 $g$，这可能和投影到由 $g^{*}$ 蕴含的复杂凸集上一样困难。对于 $g(z) = \\lambda\\|z\\|_{1}$，$g^{*}$ 是 $\\ell_{\\infty}$ 球的指示函数，因此 $\\operatorname{prox}_{\\sigma g^{*}}$ 是一个涉及按坐标裁剪的投影。使用 Moreau 分解将对偶邻近算子的计算简化为在缩放后的参数上计算原始邻近算子 $\\operatorname{prox}_{g/\\sigma}$，对于一范数而言，这即是软阈值操作。软阈值是一种逐元素的闭式运算，其计算成本为 $O(m)$ 并且各坐标之间没有耦合，因此提供了一种简单、快速且数值稳定的更新方法。在实践中，它还允许在不同算法和参数之间复用原始函数 $g$ 的邻近算子代码，避免了在对偶空间中对 $g^{*}$ 及其几何约束进行显式操作。", "answer": "$$\\boxed{\\begin{pmatrix}1  -0.6  1  -1\\end{pmatrix}}$$", "id": "3467285"}, {"introduction": "理论上的算法在理想的实数世界中运行，而实际的实现则必须应对有限精度算术的挑战。本练习探讨了 PDHG 原始更新中数值鲁棒性的一个关键方面，特别是针对 $\\ell_1$ 正则化所使用的软阈值算子。通过分析一种常见的保护措施——将极小值直接设为零——你将量化这种近似方法在增强稀疏性、提升数值稳定性与引入次优性之间的权衡。[@problem_id:3467272]", "problem": "考虑在原始-对偶分裂框架下使用原始-对偶混合梯度（PDHG，亦称 Chambolle-Pock 算法）的压缩感知目标：最小化复合凸目标 $f(Kx)+g(x)$，其中 $K \\in \\mathbb{R}^{m \\times n}$，$f:\\mathbb{R}^{m} \\to \\mathbb{R}$ 是凸且可微的函数，$g:\\mathbb{R}^{n} \\to \\mathbb{R}$ 是真、凸且下半连续的函数。特别地，考虑最小二乘数据保真项 $f(z) = \\frac{1}{2}\\|z - b\\|_{2}^{2}$（其中 $b \\in \\mathbb{R}^{m}$）和稀疏性促进正则化项 $g(x) = \\lambda \\|x\\|_{1}$（其中 $\\lambda  0$）。设 PDHG 的步长为 $\\tau  0$ 和 $\\sigma  0$，满足稳定性条件 $\\tau \\sigma \\|K\\|^{2}  1$，其中 $\\|K\\|$ 表示由欧几里得范数诱导的算子范数。\n\n在 PDHG 的原始更新中，在输入 $v \\in \\mathbb{R}^{n}$ 上计算由参数 $\\tau$ 缩放的 $g$ 的邻近算子，其精确解为 $x^{\\star} = \\operatorname{prox}_{\\tau g}(v)$，该解是强凸子问题\n$$\nQ(u;v) \\equiv g(u) + \\frac{1}{2\\tau}\\|u - v\\|_{2}^{2}\n$$\n的最小化子。在有限精度运算中，$x^{\\star}$ 中量值非常小的分量容易受到舍入误差和非规格化数的影响，这可能会降低数值稳定性。为缓解此问题，考虑一种安全措施，对邻近算子的计算输出施加一个阈值下界 $\\delta  0$：通过应用逐元素规则定义带安全措施的近似解 $\\widetilde{x}$\n$$\n\\widetilde{x}_{i} =\n\\begin{cases}\nx^{\\star}_{i},  \\text{若 } |x^{\\star}_{i}| \\ge \\delta, \\\\\n0,  \\text{若 } |x^{\\star}_{i}|  \\delta,\n\\end{cases}\n\\quad \\text{对所有 } i \\in \\{1,\\dots,n\\}.\n$$\n这种安全措施确保非常小的坐标恰好为零，从而防止微小量值在迭代中传播。\n\n从邻近算子的定义和 $g$ 的可分性出发，推导用 $\\widetilde{x}$ 替换 $x^{\\star}$ 导致的子问题目标 $Q(\\cdot;v)$ 增量的最坏情况上界。假设在每次迭代中，至多有 $r \\in \\{0,1,\\dots,n\\}$ 个坐标受阈值下界影响（即，因为 $|x^{\\star}_{i}|  \\delta$ 而从一个非零的 $x^{\\star}_{i}$ 被设为 $0$），据此得出一个在 $T \\in \\mathbb{N}$ 次 PDHG 迭代后累积诱导次优性的界。你的最终答案必须是该累积界关于 $\\delta$、$\\tau$、$r$ 和 $T$ 的函数的单一闭式解析表达式。", "solution": "该问题要求推导在原始-对偶混合梯度（PDHG）算法的原始更新步骤中，应用硬阈值安全措施所产生的累积次优性的最坏情况上界。目标函数的形式为 $f(Kx)+g(x)$，具体选择为 $f(z) = \\frac{1}{2}\\|z - b\\|_{2}^{2}$ 和 $g(x) = \\lambda \\|x\\|_{1}$（其中 $\\lambda  0$）。\n\n原始更新涉及计算 $\\tau g$ 的邻近算子，即以下子问题的精确解 $x^{\\star}$：\n$$\n\\min_{u \\in \\mathbb{R}^{n}} Q(u;v) \\equiv g(u) + \\frac{1}{2\\tau}\\|u - v\\|_{2}^{2}\n$$\n对于给定的向量 $v \\in \\mathbb{R}^{n}$。带安全措施的解 $\\widetilde{x}$ 是通过将 $x^{\\star}$ 中任何量值小于阈值 $\\delta  0$ 的分量设为零得到的。我们希望找到子问题目标增量 $Q(\\widetilde{x}; v) - Q(x^{\\star}; v)$ 的一个上界，然后在 $T$ 次迭代中累积这个界。\n\n首先，我们分析单次迭代的次优性。目标函数 $Q(u;v)$ 关于 $u$ 的分量是可分的。给定 $g(x) = \\lambda \\|x\\|_{1} = \\lambda \\sum_{i=1}^{n} |x_i|$，我们可以将 $Q(u;v)$ 写成其分量的和：\n$$\nQ(u;v) = \\sum_{i=1}^{n} \\left( \\lambda |u_i| + \\frac{1}{2\\tau}(u_i - v_i)^{2} \\right) = \\sum_{i=1}^{n} Q_i(u_i; v_i)\n$$\n精确最小化子 $x^{\\star}$ 通过独立地最小化每个 $Q_i(u_i; v_i)$ 找到。$Q_i(u_i; v_i)$ 的最小化子由软阈值算子给出：\n$$\nx^{\\star}_{i} = \\operatorname{prox}_{\\tau \\lambda |\\cdot|}(v_i) = \\operatorname{sign}(v_i) \\max(|v_i| - \\tau\\lambda, 0)\n$$\n带安全措施的解 $\\widetilde{x}$ 逐元素定义为：\n$$\n\\widetilde{x}_{i} =\n\\begin{cases}\nx^{\\star}_{i},  \\text{若 } |x^{\\star}_{i}| \\ge \\delta \\\\\n0,  \\text{若 } |x^{\\star}_{i}|  \\delta\n\\end{cases}\n$$\n子问题目标的增量是每个分量增量的和：\n$$\n\\Delta Q = Q(\\widetilde{x}; v) - Q(x^{\\star}; v) = \\sum_{i=1}^{n} \\left( Q_i(\\widetilde{x}_i; v_i) - Q_i(x^{\\star}_i; v_i) \\right)\n$$\n这个和中的项仅在索引 $i$ 满足 $\\widetilde{x}_i \\neq x^{\\star}_i$ 时非零。根据安全措施规则，这发生在 $|x^{\\star}_{i}|  \\delta$ 时。问题指定我们关心非零值被设为零的情况，因此我们考虑受影响的索引集合 $I_{\\delta} = \\{i \\in \\{1,\\dots,n\\} \\mid 0  |x^{\\star}_i|  \\delta\\}$。对于 $i \\in I_{\\delta}$，我们有 $\\widetilde{x}_i = 0$。对于 $i \\notin I_{\\delta}$，该项为零。因此，总增量为：\n$$\n\\Delta Q = \\sum_{i \\in I_{\\delta}} \\left( Q_i(0; v_i) - Q_i(x^{\\star}_i; v_i) \\right)\n$$\n让我们分析这个和中对于一个受影响的索引 $i \\in I_{\\delta}$ 的单个项：\n$$\n\\Delta Q_i = Q_i(0; v_i) - Q_i(x^{\\star}_i; v_i) = \\left( \\lambda |0| + \\frac{1}{2\\tau}(0 - v_i)^{2} \\right) - \\left( \\lambda |x^{\\star}_i| + \\frac{1}{2\\tau}(x^{\\star}_i - v_i)^{2} \\right)\n$$\n$$\n\\Delta Q_i = \\frac{1}{2\\tau}v_i^2 - \\lambda |x^{\\star}_i| - \\frac{1}{2\\tau}( (x^{\\star}_i)^2 - 2x^{\\star}_i v_i + v_i^2 ) = \\frac{1}{2\\tau}(- (x^{\\star}_i)^2 + 2x^{\\star}_i v_i) - \\lambda |x^{\\star}_i|\n$$\n为简化此式，我们用 $x^{\\star}_i$ 来表示 $v_i$。由于 $i \\in I_{\\delta}$，我们有 $x^{\\star}_i \\neq 0$。软阈值规则 $x^{\\star}_{i} = \\operatorname{sign}(v_i) (|v_i| - \\tau\\lambda)$ 意味着 $\\operatorname{sign}(v_i) = \\operatorname{sign}(x^{\\star}_i)$ 并且 $|v_i| = |x^{\\star}_i| + \\tau\\lambda$。因此，我们可以写出 $v_i = x^{\\star}_i + \\tau\\lambda \\operatorname{sign}(x^{\\star}_i)$。\n将 $v_i$ 的这个表达式代入 $\\Delta Q_i$ 的方程中：\n$$\n\\Delta Q_i = \\frac{1}{2\\tau}(- (x^{\\star}_i)^2 + 2x^{\\star}_i (x^{\\star}_i + \\tau\\lambda \\operatorname{sign}(x^{\\star}_i))) - \\lambda |x^{\\star}_i|\n$$\n$$\n\\Delta Q_i = \\frac{1}{2\\tau}(- (x^{\\star}_i)^2 + 2(x^{\\star}_i)^2 + 2\\tau\\lambda x^{\\star}_i \\operatorname{sign}(x^{\\star}_i)) - \\lambda |x^{\\star}_i|\n$$\n使用恒等式 $x^{\\star}_i \\operatorname{sign}(x^{\\star}_i) = |x^{\\star}_i|$：\n$$\n\\Delta Q_i = \\frac{1}{2\\tau}((x^{\\star}_i)^2 + 2\\tau\\lambda |x^{\\star}_i|) - \\lambda |x^{\\star}_i| = \\frac{1}{2\\tau}(x^{\\star}_i)^2 + \\lambda |x^{\\star}_i| - \\lambda |x^{\\star}_i|\n$$\n$$\n\\Delta Q_i = \\frac{1}{2\\tau}(x^{\\star}_i)^2\n$$\n这就是被阈值化为零的单个分量 $i$ 在目标函数上的精确增量。\n\n现在，我们为这个增量找到一个最坏情况下的界。对于任何受影响的索引 $i \\in I_{\\delta}$，我们有 $|x^{\\star}_i|  \\delta$，这意味着 $(x^{\\star}_i)^2  \\delta^2$。因此，对于每个 $i \\in I_{\\delta}$，\n$$\n\\Delta Q_i  \\frac{\\delta^2}{2\\tau}\n$$\n单次迭代中目标函数的总增量是对所有受影响索引的求和：\n$$\n\\Delta Q = \\sum_{i \\in I_{\\delta}} \\Delta Q_i = \\sum_{i \\in I_{\\delta}} \\frac{1}{2\\tau}(x^{\\star}_i)^2\n$$\n问题陈述，在每次迭代中，至多有 $r$ 个坐标受阈值下界影响，所以集合 $I_{\\delta}$ 的大小，记为 $|I_{\\delta}|$，满足 $|I_{\\delta}| \\le r$。单次迭代中 $\\Delta Q$ 的最坏情况上界是通过假设受影响的分量数量最多，且每个分量的量值都取恰好小于 $\\delta$ 的最大可能值得到的：\n$$\n\\Delta Q = \\sum_{i \\in I_{\\delta}} \\frac{1}{2\\tau}(x^{\\star}_i)^2  \\sum_{i \\in I_{\\delta}} \\frac{\\delta^2}{2\\tau} = |I_{\\delta}| \\frac{\\delta^2}{2\\tau} \\le r \\frac{\\delta^2}{2\\tau}\n$$\n所以，单次 PDHG 迭代中引起的最坏情况次优性以 $r \\frac{\\delta^2}{2\\tau}$ 为界。\n\n最后，问题要求一个在 $T$ 次迭代后累积诱导次优性的界。这是来自 $T$ 个独立的原始更新子问题的次优性增量之和。假设在 $T$ 次迭代中的每一次都发生最坏情况，则累积界 $E_{\\text{cumulative}}$ 是单次迭代界的和：\n$$\nE_{\\text{cumulative}} \\le \\sum_{k=1}^{T} \\left( r \\frac{\\delta^2}{2\\tau} \\right) = T \\cdot r \\frac{\\delta^2}{2\\tau}\n$$\n因此，累积界的最终表达式为 $\\frac{Tr\\delta^2}{2\\tau}$。", "answer": "$$\n\\boxed{\\frac{Tr\\delta^{2}}{2\\tau}}\n$$", "id": "3467272"}, {"introduction": "PDHG 算法的收敛行为不仅由其步长决定，还与底层线性算子 $A$ 的性质深度耦合。这个动手编程实践将挑战你研究这种联系，通过构建特定的测量矩阵来观察其对算法稳定性和振荡行为的影响。通过将线性化系统的理论分析与经验模拟相结合，你将对限制等距性质 (Restricted Isometry Property, RIP) 等特性的破坏如何体现为实际性能问题获得更深刻的直觉。[@problem_id:3467311]", "problem": "考虑压缩感知和稀疏优化中的凸优化模型\n$$\n\\min_{x \\in \\mathbb{R}^n} \\; g(x) + f(Ax),\n$$\n其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个测量矩阵，$f(z) = \\tfrac{1}{2}\\lVert z - b \\rVert_2^2$ 是一个最小二乘数据保真项，而 $g(x) = \\lambda \\lVert x \\rVert_1$ 是一个 $\\ell_1$-正则化项，其中 $\\lambda  0$。原始-对偶混合梯度算法（也称为 Chambolle-Pock 算法）使用超松弛参数 $\\theta$，通过 $g$ 的近端映射（proximal mapping）和 $f$ 的 Fenchel-Legendre 共轭 $f^\\ast$ 来更新原始变量 $x \\in \\mathbb{R}^n$ 和对偶变量 $y \\in \\mathbb{R}^m$。\n\n您的目标是通过构造具有聚集奇异值的对抗性测量矩阵 $A$，并从经验和理论上刻画振荡行为，来分析算法收敛性和振荡对违反限制等距性质（Restricted Isometry Property, RIP）的敏感性。\n\n从以下基础概念开始：\n- 函数 $f$ 的 Fenchel-Legendre 共轭，记为 $f^\\ast$，以及对于一个正常、凸、下半连续函数 $h$ 的近端算子 $\\mathrm{prox}_{\\gamma h}(z) = \\arg\\min_u \\left\\{ h(u) + \\tfrac{1}{2\\gamma} \\lVert u - z \\rVert_2^2 \\right\\}$ 的定义。\n- 矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的奇异值分解（SVD），以及等于 $A$ 的最大奇异值的谱范数 $\\lVert A \\rVert_2$ 的概念。\n- 迭代方法中振荡的概念，通过目标函数序列的连续差分中的符号变化来捕捉。\n\n您必须在单个程序中完全完成以下任务：\n\n1. 通过指定一组奇异值并将它们与随机生成的标准正交基相结合，为每个测试案例构造测量矩阵 $A$：\n   - 对每个测试案例，生成标准正交矩阵 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$，并构造 $A = U \\Sigma V^\\top$，其中 $\\Sigma \\in \\mathbb{R}^{m \\times n}$ 在其主对角线的前 $m$ 列包含奇异值，其他位置为零。每个测试案例使用固定的随机种子以确保可复现性。\n\n2. 生成一个稀疏的真实信号 $x^\\star \\in \\mathbb{R}^n$，其在均匀随机的索引上有 $k$ 个非零项，非零值从标准正态分布中抽取。构造测量值 $b = A x^\\star + \\eta$，其中 $\\eta$ 是均值为零、标准差为 $10^{-3}$ 的独立高斯噪声。\n\n3. 实现超松弛参数 $\\theta = 0$（无外推）的原始-对偶混合梯度算法。从第一性原理推导 $g(x)$ 和 $f^\\ast(y)$ 所需的近端算子，并在更新规则中使用它们。选择步长 $\\sigma = 1$ 和\n$$\n\\tau = \\frac{\\alpha}{\\sigma \\lVert A \\rVert_2^2},\n$$\n对于所有测试案例，取 $\\alpha = 0.99$，使得步长耦合满足 $\\tau \\sigma \\lVert A \\rVert_2^2 = \\alpha  1$。\n\n4. 运行算法 $T$ 次迭代，在每次迭代 $k$ 时记录目标函数值\n$$\nF^k = \\lambda \\lVert x^k \\rVert_1 + \\tfrac{1}{2} \\lVert A x^k - b \\rVert_2^2\n$$\n，并计算后半部分迭代的经验振荡率。具体来说，令 $\\Delta^k = F^k - F^{k-1}$，并将经验振荡率定义为索引 $k$（限制在最后 $\\lfloor T/2 \\rfloor$ 次迭代中）的比例，其中 $\\Delta^k$ 的符号非零，且相对于前一个非零符号发生交替。使用 $10^{-12}$ 的数值容差，将绝对值不大于 $10^{-12}$ 的 $\\Delta^k$ 值视为零。\n\n5. 通过分析当 $g(x) = 0$、$f(z) = \\tfrac{1}{2} \\lVert z - b \\rVert_2^2$ 和 $\\theta = 0$ 时，沿单个奇异方向上的线性化原始-对偶混合梯度迭代来从理论上刻画振荡。推导出一个闭式条件，在该条件下，$2 \\times 2$ 线性递推（耦合了沿一对奇异向量的 $x$ 和 $y$ 的分量）的特征值为复共轭，这表明存在振荡行为。该条件应仅用 $\\tau$、$\\sigma$ 和 $A$ 的一个奇异值 $s$ 来表示。使用此条件计算迭代发生振荡（复特征值）的奇异值 $s$ 的理论比例，在线性化时将对应方向上的 $b$ 视为零。\n\n6. 使用以下参数化测试套件，以涵盖正常路径、边界和对抗性边缘案例：\n   - 维度：$m = 60$，$n = 100$，稀疏度 $k = 10$，迭代次数 $T = 500$，正则化参数 $\\lambda = 10^{-2}$，步长参数 $\\sigma = 1$ 和 $\\alpha = 0.99$，在上述 $\\tau$ 的公式中。\n   - 测试案例 1（正常路径，接近 RIP）：所有奇异值等于 $1.0$。\n   - 测试案例 2（振荡边界以下）：所有奇异值等于 $0.3$。\n   - 测试案例 3（两个紧密集群，对抗性）：一半奇异值等于 $2.2$，剩下的一半等于 $0.1$。\n   - 测试案例 4（严重违反 RIP）：百分之七十五的奇异值等于 $5.0$，剩下的百分之二十五等于 $0.05$。\n   对于每个测试案例，使用不同的固定随机种子来构造 $U$、$V$ 和 $x^\\star$。\n\n7. 对于每个测试案例，计算：\n   - 经验振荡率（在 $[0,1]$ 内的小数），如第 4 项所定义。\n   - 理论振荡分数（在 $[0,1]$ 内的小数），如第 5 项所定义。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含八个结果，格式为方括号内的逗号分隔列表，按测试案例和度量对排序：\n$$\n[\\mathrm{emp}_1,\\mathrm{theory}_1,\\mathrm{emp}_2,\\mathrm{theory}_2,\\mathrm{emp}_3,\\mathrm{theory}_3,\\mathrm{emp}_4,\\mathrm{theory}_4].\n$$\n不应打印任何其他文本。\n\n此问题中没有物理单位或角度，所有结果必须以标准浮点格式的小数形式报告。", "solution": "经评估，用户提供的问题是有效的，因为它在科学上基于凸优化和数值分析的原理，问题定义良好且所有必要参数均已定义，并以客观、正式的语言表述。因此，我们可以进行完整解答。\n\n问题的核心是分析原始-对偶混合梯度（PDHG）算法在特定压缩感知问题上的行为，特别关注测量矩阵 $A$ 的结构如何影响收敛过程中的振荡。\n\n该优化问题由以下公式给出：\n$$\n\\min_{x \\in \\mathbb{R}^n} \\; g(x) + f(Ax)\n$$\n其中 $g(x) = \\lambda \\lVert x \\rVert_1$ 是促进稀疏性的 $\\ell_1$-范数正则化项，而 $f(z) = \\frac{1}{2}\\lVert z - b \\rVert_2^2$ 是最小二乘数据保真项。矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 是测量矩阵。\n\n### 1. 原始-对偶混合梯度（PDHG）算法\nPDHG 算法，也称为 Chambolle-Pock 算法，迭代更新原始变量 $x \\in \\mathbb{R}^n$ 和对偶变量 $y \\in \\mathbb{R}^m$。根据指定的超松弛参数 $\\theta=0$，更新规则如下：\n$$\n\\begin{cases}\ny^{k+1} = \\mathrm{prox}_{\\sigma f^\\ast}(y^k + \\sigma A x^k) \\\\\nx^{k+1} = \\mathrm{prox}_{\\tau g}(x^k - \\tau A^\\top y^{k+1})\n\\end{cases}\n$$\n这里，$\\tau  0$ 和 $\\sigma  0$ 是步长参数。如果 $\\tau \\sigma \\lVert A \\rVert_2^2  1$，则该方案的收敛性得到保证。问题指定了 $\\sigma = 1$ 和 $\\tau = \\frac{\\alpha}{\\sigma \\lVert A \\rVert_2^2}$，其中 $\\alpha = 0.99$，这满足了该条件。\n\n### 2. 近端算子的推导\n为了实现该算法，我们必须推导 $g$ 和 $f$ 的 Fenchel-Legendre 共轭（记为 $f^\\ast$）的近端算子。\n\n**原始近端算子：**\n$g(x) = \\lambda \\lVert x \\rVert_1$ 的近端算子定义为：\n$$\n\\mathrm{prox}_{\\tau g}(z) = \\arg\\min_u \\left\\{ \\lambda \\lVert u \\rVert_1 + \\frac{1}{2\\tau} \\lVert u - z \\rVert_2^2 \\right\\}\n$$\n这个问题是可分的，每个分量 $u_i$ 的解由软阈值算子 $\\mathcal{S}_{\\lambda\\tau}$ 给出：\n$$\n[\\mathrm{prox}_{\\tau g}(z)]_i = \\mathrm{sign}(z_i) \\max(|z_i| - \\lambda\\tau, 0)\n$$\n因此，$x$ 的更新变为 $x^{k+1} = \\mathcal{S}_{\\lambda\\tau}(x^k - \\tau A^\\top y^{k+1})$。\n\n**对偶近端算子：**\n首先，我们求 $f(z) = \\frac{1}{2} \\lVert z - b \\rVert_2^2$ 的 Fenchel-Legendre 共轭 $f^\\ast$：\n$$\nf^\\ast(y) = \\sup_z \\{ \\langle y, z \\rangle - f(z) \\} = \\sup_z \\left\\{ y^\\top z - \\frac{1}{2} \\lVert z - b \\rVert_2^2 \\right\\}\n$$\n通过将关于 $z$ 的梯度设为零来找到最大化点：$y - (z-b) = 0$，这给出 $z = y+b$。将其代回可得：\n$$\nf^\\ast(y) = y^\\top(y+b) - \\frac{1}{2} \\lVert (y+b)-b \\rVert_2^2 = \\frac{1}{2} \\lVert y \\rVert_2^2 + y^\\top b\n$$\n接下来，我们计算 $f^\\ast$ 的近端算子：\n$$\n\\mathrm{prox}_{\\sigma f^\\ast}(w) = \\arg\\min_u \\left\\{ f^\\ast(u) + \\frac{1}{2\\sigma} \\lVert u - w \\rVert_2^2 \\right\\} = \\arg\\min_u \\left\\{ \\frac{1}{2}\\lVert u \\rVert_2^2 + u^\\top b + \\frac{1}{2\\sigma} \\lVert u - w \\rVert_2^2 \\right\\}\n$$\n将关于 $u$ 的梯度设为零可得 $u + b + \\frac{1}{\\sigma}(u-w) = 0$。解出 $u$ 可得：\n$$\nu = \\frac{w - \\sigma b}{1 + \\sigma}\n$$\n使用指定的参数 $\\sigma = 1$，对偶变量 $y$ 的更新变为：\n$$\ny^{k+1} = \\mathrm{prox}_{f^\\ast}(y^k + A x^k) = \\frac{(y^k + A x^k) - b}{2}\n$$\n\n### 3. 理论振荡分析\n为了理解振荡的起源，我们通过将非光滑项设为零（$g(x)=0$，因此 $\\lambda=0$）并假设测量向量为零（$b=0$）来线性化 PDHG 更新。当 $\\lambda=0$ 时，$\\mathrm{prox}_{\\tau g}$ 是恒等映射。对于一般的 $\\sigma$，更新变为：\n$$\n\\begin{cases}\ny^{k+1} = \\frac{1}{1+\\sigma}y^k + \\frac{\\sigma}{1+\\sigma} A x^k \\\\\nx^{k+1} = x^k - \\tau A^\\top y^{k+1}\n\\end{cases}\n$$\n将 $y^{k+1}$ 代入第二个方程得到：\n$$\nx^{k+1} = \\left(I - \\frac{\\tau\\sigma}{1+\\sigma}A^\\top A\\right)x^k - \\frac{\\tau}{1+\\sigma}A^\\top y^k\n$$\n该系统可以通过沿 $A$ 的奇异值进行分解来分析。令 $A = U\\Sigma V^\\top$。对于 $A$ 的每个奇异值 $s_i$，$x$ 和 $y$ 相应分量的动态由一个 $2 \\times 2$ 矩阵控制：\n$$\nM_i = \\begin{pmatrix} 1 - \\frac{\\tau\\sigma s_i^2}{1+\\sigma}  -\\frac{\\tau s_i}{1+\\sigma} \\\\ \\frac{\\sigma s_i}{1+\\sigma}  \\frac{1}{1+\\sigma} \\end{pmatrix}\n$$\n$M_i$ 的复特征值表明存在振荡行为。特征多项式为 $\\det(M_i - \\mu I) = 0$，可简化为：\n$$\n\\mu^2 - \\mathrm{Tr}(M_i)\\mu + \\det(M_i) = 0 \\implies \\mu^2 - \\left(\\frac{2+\\sigma - \\tau\\sigma s_i^2}{1+\\sigma}\\right)\\mu + \\frac{1}{1+\\sigma} = 0\n$$\n如果判别式为负，则特征值为复数：\n$$\nD = \\left(\\frac{2+\\sigma - \\tau\\sigma s_i^2}{1+\\sigma}\\right)^2 - \\frac{4}{1+\\sigma}  0\n$$\n解出 $\\tau\\sigma s_i^2$ 得到振荡的条件：\n$$\n(2+\\sigma) - 2\\sqrt{1+\\sigma}  \\tau\\sigma s_i^2  (2+\\sigma) + 2\\sqrt{1+\\sigma}\n$$\n对于问题中的特定参数 $\\sigma = 1$，该条件变为：\n$$\n3 - 2\\sqrt{2}  \\tau s_i^2  3 + 2\\sqrt{2}\n$$\n数值上，这大约是 $0.17157  \\tau s_i^2  5.82843$。理论振荡分数是使此不等式成立的 $A$ 的奇异值 $s_i$ 的比例。\n\n### 4. 经验振荡测量\n经验振荡率由目标函数序列 $F^k = \\lambda \\lVert x^k \\rVert_1 + \\frac{1}{2} \\lVert A x^k - b \\rVert_2^2$ 计算得出。\n我们计算差分序列 $\\Delta^k = F^k - F^{k-1}$。对于后半部分的迭代，我们识别出所有幅度超过 $10^{-12}$ 容差的 $\\Delta^k$。对于这个非零差分子序列，我们计算连续元素之间符号交替的次数。经验振荡率是总交替次数除以交替机会的数量（非零差分子序列的长度减一）。\n\n### 5. 实现摘要\n该解决方案在单个 Python 程序中实现。\n1.  **矩阵构造：** 对每个测试案例，使用固定的随机种子生成标准正交矩阵 $U \\in \\mathbb{R}^{m \\times m}$ 和 $V \\in \\mathbb{R}^{n \\times n}$。矩阵 $A$ 构造成 $A = U \\Sigma V^\\top$，其中 $\\Sigma \\in \\mathbb{R}^{m \\times n}$ 包含指定的奇异值。\n2.  **信号生成：** 根据问题规范生成稀疏的真实信号 $x^\\star$ 和测量向量 $b = Ax^\\star + \\eta$，同样使用固定的种子。\n3.  **算法执行：** PDHG 算法使用参数 $\\lambda=10^{-2}$、$\\sigma=1$ 和 $\\tau=\\frac{0.99}{\\lVert A \\rVert_2^2}$ 运行 $T=500$ 次迭代。每次迭代的目标函数值 $F^k$ 都被存储。\n4.  **度量计算：** 对每个测试案例，如上所述计算经验振荡率和理论振荡分数。\n然后按要求格式化并打印最终结果。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import ortho_group\n\ndef solve():\n    \"\"\"\n    Main function to execute the analysis for all test cases.\n    \"\"\"\n    \n    # Problem parameters\n    m, n, k, T = 60, 100, 10, 500\n    lambda_reg = 1e-2\n    sigma = 1.0\n    alpha = 0.99\n    noise_std = 1e-3\n    tol = 1e-12\n\n    # Test case definitions\n    test_cases = [\n        {'singular_values': np.full(m, 1.0), 'seed': 1, 'id': 1},\n        {'singular_values': np.full(m, 0.3), 'seed': 2, 'id': 2},\n        {'singular_values': np.concatenate([np.full(m // 2, 2.2), np.full(m - m // 2, 0.1)]), 'seed': 3, 'id': 3},\n        {'singular_values': np.concatenate([np.full(int(0.75 * m), 5.0), np.full(m - int(0.75 * m), 0.05)]), 'seed': 4, 'id': 4},\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        singular_values = case['singular_values']\n        seed = case['seed']\n        \n        # --- 1. Construct Matrix A and Generate Data ---\n        rng = np.random.default_rng(seed)\n\n        # Generate orthonormal bases U and V\n        U = ortho_group.rvs(dim=m, random_state=rng)\n        V = ortho_group.rvs(dim=n, random_state=rng)\n\n        # Construct singular value matrix Sigma\n        Sigma = np.zeros((m, n))\n        np.fill_diagonal(Sigma, singular_values)\n        \n        # Construct matrix A\n        A = U @ Sigma @ V.T\n        A_T = A.T\n        \n        # Spectral norm is the largest singular value\n        norm_A_sq = np.max(singular_values)**2\n        \n        # Generate sparse ground-truth signal x_star\n        x_star = np.zeros(n)\n        nonzero_indices = rng.choice(n, k, replace=False)\n        x_star[nonzero_indices] = rng.standard_normal(k)\n\n        # Generate measurement vector b\n        eta = rng.normal(0, noise_std, m)\n        b = A @ x_star + eta\n\n        # --- 2. Implement PDHG Algorithm ---\n        \n        # Step sizes\n        tau = alpha / (sigma * norm_A_sq)\n\n        # Initialization\n        x = np.zeros(n)\n        y = np.zeros(m)\n        \n        objective_values = []\n\n        def soft_threshold(z, t):\n            return np.sign(z) * np.maximum(np.abs(z) - t, 0)\n\n        def objective_function(x_k):\n            return lambda_reg * np.linalg.norm(x_k, 1) + 0.5 * np.linalg.norm(A @ x_k - b, 2)**2\n\n        # Run PDHG iterations\n        objective_values.append(objective_function(x))\n        for _ in range(T):\n            # Dual update (y)\n            y_next = (y + sigma * (A @ x - b)) / (1 + sigma)\n            \n            # Primal update (x)\n            x_tilde = x - tau * (A_T @ y_next)\n            x_next = soft_threshold(x_tilde, lambda_reg * tau)\n\n            # Update variables\n            x, y = x_next, y_next\n            \n            # Record objective\n            objective_values.append(objective_function(x))\n\n        # --- 3. Compute Empirical Oscillation Rate ---\n        \n        # Differences in objective values\n        deltas = np.diff(np.array(objective_values))\n        \n        # Analyze last half of iterations\n        last_half_deltas = deltas[-(T // 2):]\n        \n        # Filter out \"zero\" differences based on tolerance\n        nonzero_deltas = last_half_deltas[np.abs(last_half_deltas) > tol]\n        \n        if len(nonzero_deltas)  2:\n            emp_osc_rate = 0.0\n        else:\n            signs = np.sign(nonzero_deltas)\n            num_alternations = np.sum(signs[:-1] != signs[1:])\n            emp_osc_rate = num_alternations / (len(nonzero_deltas) - 1)\n\n        # --- 4. Compute Theoretical Oscillation Fraction ---\n\n        # The condition for oscillation is L  tau * sigma * s^2  U\n        lower_bound = (2 + sigma) - 2 * np.sqrt(1 + sigma)\n        upper_bound = (2 + sigma) + 2 * np.sqrt(1 + sigma)\n\n        # Test the condition for each singular value\n        check_vals = tau * sigma * (singular_values**2)\n        oscillating_modes = np.sum((check_vals > lower_bound)  (check_vals  upper_bound))\n        \n        theory_osc_frac = oscillating_modes / m\n        \n        results.extend([emp_osc_rate, theory_osc_frac])\n        \n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3467311"}]}