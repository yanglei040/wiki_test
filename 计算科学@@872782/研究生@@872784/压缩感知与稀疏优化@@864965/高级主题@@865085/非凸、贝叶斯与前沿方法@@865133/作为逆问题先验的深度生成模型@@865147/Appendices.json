{"hands_on_practices": [{"introduction": "在求解任何逆问题时，第一步都是构建一个精确的数学目标。这个目标函数直接源于我们对测量过程，尤其是噪声的统计假设。这个练习 [@problem_id:3442929] 提供了一个推导这些目标函数的基础实践，它对比了广泛使用的高斯噪声模型（对应于最小二乘（$L_2$）问题）和更具鲁棒性的拉普拉斯噪声模型（对应于最小绝对偏差（$L_1$）问题）。通过这个练习，您将亲手建立起从统计模型到优化准则的桥梁。", "problem": "考虑一个带有深度生成先验的线性逆问题。令未知信号被约束在生成器 $G$ 的值域内，具体为 $x = G(z) \\in \\mathbb{R}^{n}$，其中 $z \\in \\mathbb{R}$ 为一维潜码，生成器是线性的 $G(z) = b z$，且 $b \\in \\mathbb{R}^{n}$ 是固定已知的。通过一个已知的前向算子 $A \\in \\mathbb{R}^{m \\times n}$ 获得测量值，得到 $y = A x + \\varepsilon \\in \\mathbb{R}^{m}$，其中 $\\varepsilon$ 对随机测量噪声进行建模。假设潜码 $z$ 是唯一的未知量（即，除了约束 $x \\in \\mathrm{range}(G)$ 之外，没有关于 $z$ 的显式先验分布），我们寻求在给定观测值 $y$ 的情况下 $z$ 的最大似然估计（MLE）。\n\n从两种不同噪声模型下似然 $p(y \\mid x)$ 的基本定义出发，推导出相应的负对数似然（数据保真）项作为 $z$ 的函数（不考虑不依赖于 $z$ 的加性常数），以及相应的关于 $z$ 的最大似然估计问题：\n- 独立同分布（i.i.d.）高斯噪声：$\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I)$。\n- 独立同分布（i.i.d.）拉普拉斯噪声，尺度为 $\\beta$：$\\varepsilon$ 的每个分量的概率密度为 $(2 \\beta)^{-1} \\exp(-|e|/\\beta)$。\n\n然后，使用 $m = 4$ 和 $n = 3$ 的具体数值实例：\n$$\nA = \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\\\ 1  1  0 \\\\ 2  0  1 \\end{pmatrix}, \\quad b = \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix}, \\quad y = \\begin{pmatrix} 5 \\\\ 7 \\\\ 9 \\\\ 6 \\end{pmatrix}\n$$\n执行以下操作：\n- 用 $A$、$b$ 和 $y$ 来表示高斯噪声情况下 $z$ 的最大似然估计的闭式解，并对给定的 $A$、$b$ 和 $y$ 进行数值计算。\n- 将拉普拉斯噪声情况下 $z$ 的最大似然估计表示为一个单变量凸优化问题的解，并使用次微分演算对其进行刻画。然后对给定的 $A$、$b$ 和 $y$ 进行显式计算。\n\n最后，计算高斯噪声最大似然估计和拉普拉斯噪声最大似然估计之间的差值，\n$$z_{\\mathrm{G}} - z_{\\mathrm{L}},$$\n并将此最终量报告为一个最简精确分数。不要四舍五入。不需要单位。", "solution": "该问题有效。我们推导并求解在不同噪声模型下潜变量 $z$ 的最大似然估计。\n\n**一般性推导**\n\n首先，我们将生成先验代入测量模型：$y = A(bz) + \\varepsilon = (Ab)z + \\varepsilon$。为简化符号，我们定义向量 $v = Ab \\in \\mathbb{R}^m$。模型变为 $y = vz + \\varepsilon$。\n\n1.  **高斯噪声情况**：\n    噪声 $\\varepsilon$ 的每个分量 $\\varepsilon_i$ 独立地服从 $\\mathcal{N}(0, \\sigma^2)$ 分布。因此，给定 $z$ 时 $y$ 的似然函数为：\n    $p(y|z) = \\prod_{i=1}^m \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(y_i - v_i z)^2}{2\\sigma^2}\\right) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\sum_{i=1}^m (y_i - v_i z)^2\\right) = \\exp\\left(-\\frac{1}{2\\sigma^2} \\|y - vz\\|_2^2\\right)$\n    负对数似然函数 $\\mathcal{L}_G(z) = -\\log p(y|z)$ 与 $\\|y - vz\\|_2^2$ 成正比（忽略与 $z$ 无关的常数）。因此，最大似然估计问题是最小化数据保真项：\n    $$\n    \\min_z \\|y - vz\\|_2^2\n    $$\n\n2.  **拉普拉斯噪声情况**：\n    噪声 $\\varepsilon$ 的每个分量 $\\varepsilon_i$ 独立地服从拉普拉斯分布，其概率密度为 $(2\\beta)^{-1} \\exp(-|e|/\\beta)$。因此，似然函数为：\n    $p(y|z) = \\prod_{i=1}^m \\frac{1}{2\\beta} \\exp\\left(-\\frac{|y_i - v_i z|}{\\beta}\\right) \\propto \\exp\\left(-\\frac{1}{\\beta} \\sum_{i=1}^m |y_i - v_i z|\\right) = \\exp\\left(-\\frac{1}{\\beta} \\|y - vz\\|_1\\right)$\n    负对数似然函数 $\\mathcal{L}_L(z)$ 与 $\\|y - vz\\|_1$ 成正比。因此，最大似然估计问题是：\n    $$\n    \\min_z \\|y - vz\\|_1\n    $$\n\n**具体求解**\n\n首先，使用给定的 $A$ 和 $b$ 计算向量 $v$：\n$v = Ab = \\begin{pmatrix} 1  0  1 \\\\ 0  1  1 \\\\ 1  1  0 \\\\ 2  0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1(1)+0(2)+1(1) \\\\ 0(1)+1(2)+1(1) \\\\ 1(1)+1(2)+0(1) \\\\ 2(1)+0(2)+1(1) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 3 \\\\ 3 \\\\ 3 \\end{pmatrix}$\n\n1.  **高斯最大似然估计 ($z_G$)**：\n    目标函数是 $f_G(z) = \\|y - vz\\|_2^2 = \\sum_{i=1}^m (y_i - v_i z)^2$。这是一个关于 $z$ 的二次函数。我们通过将其导数设为零来找到最小值：\n    $\\frac{df_G}{dz} = \\sum_{i=1}^m 2(y_i - v_i z)(-v_i) = -2(v^T y - (v^T v)z) = 0$\n    这给出了闭式解：\n    $z_G = \\frac{v^T y}{v^T v}$\n    我们计算 $v^T y$ 和 $v^T v$：\n    $v^T y = (2)(5) + (3)(7) + (3)(9) + (3)(6) = 10 + 21 + 27 + 18 = 76$\n    $v^T v = 2^2 + 3^2 + 3^2 + 3^2 = 4 + 9 + 9 + 9 = 31$\n    因此，\n    $z_G = \\frac{76}{31}$\n\n2.  **拉普拉斯最大似然估计 ($z_L$)**：\n    目标函数是 $f_L(z) = \\|y - vz\\|_1 = \\sum_{i=1}^m |y_i - v_i z| = \\sum_{i=1}^m |v_i| |z - y_i/v_i|$。这是一个单变量凸优化问题，其解是节点 $\\{y_i/v_i\\}$ 的加权中位数，权重为 $\\{|v_i|\\}$。\n    我们使用次微分来刻画解。最优解 $z_L$ 必须满足 $0 \\in \\partial f_L(z_L)$。次微分为：\n    $\\partial f_L(z) = \\sum_{i=1}^m -v_i \\cdot \\text{sign}(y_i - v_i z)$\n    其中 $\\text{sign}(u)$ 在 $u=0$ 时是区间 $[-1, 1]$。\n    我们计算节点 $z_i^* = y_i / v_i$ 和权重 $w_i = |v_i|$：\n    - $z_1^* = 5/2 = 2.5$, $w_1 = |2| = 2$\n    - $z_2^* = 7/3 \\approx 2.333$, $w_2 = |3| = 3$\n    - $z_3^* = 9/3 = 3$, $w_3 = |3| = 3$\n    - $z_4^* = 6/3 = 2$, $w_4 = |3| = 3$\n    \n    将节点排序：$2  7/3  2.5  3$。总权重 $W = \\sum w_i = 2+3+3+3 = 11$。中位数是使累积权重超过 $W/2 = 5.5$ 的点。\n    - 从最小的节点 $z_4^*=2$ 开始，其权重为 3。累积权重为 3。\n    - 下一个节点是 $z_2^*=7/3$，其权重为 3。累积权重为 $3+3=6$。\n    由于累积权重在 $z_2^*=7/3$ 处超过了 5.5，因此加权中位数是 $z_L = 7/3$。\n    我们可以通过检查次微分条件来验证。在 $z_L=7/3$ 处，条件 $\\sum_{i} v_i \\text{sign}(z_L - z_i^*)$ 必须包含0。对于等于 $z_L$ 的节点，$\\text{sign}$ 项是区间 $[-1,1]$，对于其他节点是 $\\pm 1$。\n    $\\sum_{z_i^* > z_L} w_i - \\sum_{z_i^*  z_L} w_i = (w_1+w_3) - w_4 = (2+3) - 3 = 2$。\n    该值必须在 $[-w_2, w_2] = [-3, 3]$ 区间内，这是成立的。因此，$z_L=7/3$ 是正确的解。\n\n**最终计算**\n\n计算 $z_G$ 和 $z_L$ 之间的差值：\n$$\nz_G - z_L = \\frac{76}{31} - \\frac{7}{3} = \\frac{76 \\times 3 - 7 \\times 31}{31 \\times 3} = \\frac{228 - 217}{93} = \\frac{11}{93}\n$$", "answer": "$$\n\\boxed{\\frac{11}{93}}\n$$", "id": "3442929"}, {"introduction": "一个强大的生成先验虽然能有效正则化逆问题的解，但也引入了一个潜在的误差来源：模型失配（model mismatch），也称为偏差。当真实信号并不完全处于生成器的值域内时，这种情况就会发生。本练习 [@problem_id:3442952] 在此背景下，对经典的偏差-方差权衡进行了定量探索，它清晰地揭示了模型复杂度（即先验流形的维度）的选择，如何在拟合数据的保真度与抑制噪声的稳定性之间取得平衡。", "problem": "考虑一个由确定性映射 $G : \\mathbb{R}^{k} \\to \\mathbb{R}^{n}$ 表示的深度生成模型先验，其像为维度为 $k$ 的集合 $S = \\mathrm{Range}(G) \\subset \\mathbb{R}^{n}$。在去噪设定下，您观测到含噪测量值 $y = x^{\\star} + w$，其中 $x^{\\star} \\in \\mathbb{R}^{n}$ 是未知的真实信号，噪声 $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$ 是一个零均值高斯分布，其协方差为 $\\sigma^{2} I_{n}$，且与 $x^{\\star}$ 独立。您通过选择最小距离估计量 $x^{\\wedge} = \\arg\\min_{x \\in S} \\|x - y\\|_{2}^{2}$ 将重建约束在 $S$ 上，该估计量等于将 $y$ 正交投影到 $S$ 上的结果 $x^{\\wedge} = P_{S} y$，其中 $P_{S}$ 是到 $S$ 上的正交投影算子。\n\n假设真实信号不完全在 $S$ 中，并且可以分解为 $x^{\\star} = G(z^{\\star}) + x_{\\perp}$，其中 $G(z^{\\star}) \\in S$ 且 $x_{\\perp} \\in S^{\\perp}$。$x_{\\perp}$ 与 $w$ 独立，其分布为 $x_{\\perp} \\sim \\mathcal{N}(0, \\tau^{2} I_{n-k})$，支撑在 $n-k$ 维正交补空间 $S^{\\perp}$ 上。仅使用正交投影、高斯期望的基本性质以及均方误差的定义，从第一性原理推导当约束到 $S$ 时偏差-方差权衡是如何产生的，并计算在 $w$ 和 $x_{\\perp}$ 的联合随机性下，期望平方重建误差 $\\mathbb{E}\\big[\\|x^{\\wedge} - x^{\\star}\\|_{2}^{2}\\big]$。\n\n请用 $n$、$k$、$\\sigma$ 和 $\\tau$ 将最终答案表示为单个闭式解析表达式。无需四舍五入。", "solution": "该问题已经过验证，被认为是有效的。我们现在开始对期望平方重建误差进行形式化推导。\n\n我们的目标是计算均方误差 (MSE)，其定义为 $\\mathbb{E}\\big[\\|x^{\\wedge} - x^{\\star}\\|_{2}^{2}\\big]$。期望是针对噪声 $w$ 和子空间外分量 $x_{\\perp}$ 的联合分布计算的。\n\n估计量 $x^{\\wedge}$ 是测量值 $y$ 在信号子空间 $S$ 上的正交投影：\n$$x^{\\wedge} = P_{S} y$$\n给定测量模型 $y = x^{\\star} + w$。将其代入 $x^{\\wedge}$ 的表达式中，得到：\n$$x^{\\wedge} = P_{S}(x^{\\star} + w)$$\n真实信号 $x^{\\star}$ 被分解为 $S$ 中的一个分量和其正交补空间 $S^{\\perp}$ 中的一个分量：$x^{\\star} = x_{\\parallel} + x_{\\perp}$，其中为记法清晰，我们定义 $x_{\\parallel} = G(z^{\\star}) \\in S$ 和 $x_{\\perp} \\in S^{\\perp}$。代入此分解，得到：\n$$x^{\\wedge} = P_{S}(x_{\\parallel} + x_{\\perp} + w)$$\n根据投影算子 $P_{S}$ 的线性性质，我们有：\n$$x^{\\wedge} = P_{S}x_{\\parallel} + P_{S}x_{\\perp} + P_{S}w$$\n现在我们使用正交投影的基本性质。由于 $x_{\\parallel}$ 在 $S$ 中，它在 $S$ 上的投影是其自身，即 $P_{S}x_{\\parallel} = x_{\\parallel}$。由于 $x_{\\perp}$ 在正交补空间 $S^{\\perp}$ 中，它在 $S$ 上的投影是零向量，即 $P_{S}x_{\\perp} = 0$。这使得估计量的表达式简化为：\n$$x^{\\wedge} = x_{\\parallel} + P_{S}w$$\n现在我们构建重建误差向量 $x^{\\wedge} - x^{\\star}$：\n$$x^{\\wedge} - x^{\\star} = (x_{\\parallel} + P_{S}w) - (x_{\\parallel} + x_{\\perp}) = P_{S}w - x_{\\perp}$$\n平方重建误差是该向量的平方欧几里得范数：\n$$\\|x^{\\wedge} - x^{\\star}\\|_{2}^{2} = \\|P_{S}w - x_{\\perp}\\|_{2}^{2}$$\n根据投影算子的定义，向量 $P_{S}w$ 位于子空间 $S$ 中。向量 $x_{\\perp}$ 位于正交补空间 $S^{\\perp}$ 中。因此，向量 $P_{S}w$ 和 $-x_{\\perp}$ 是正交的。根据勾股定理，它们和（或差）的平方范数等于它们各自平方范数的和：\n$$\\|x^{\\wedge} - x^{\\star}\\|_{2}^{2} = \\|P_{S}w\\|_{2}^{2} + \\|-x_{\\perp}\\|_{2}^{2} = \\|P_{S}w\\|_{2}^{2} + \\|x_{\\perp}\\|_{2}^{2}$$\n为求期望平方误差，我们对该表达式取期望。根据期望的线性性质：\n$$\\mathbb{E}\\big[\\|x^{\\wedge} - x^{\\star}\\|_{2}^{2}\\big] = \\mathbb{E}\\big[\\|P_{S}w\\|_{2}^{2}\\big] + \\mathbb{E}\\big[\\|x_{\\perp}\\|_{2}^{2}\\big]$$\n这两项分别对应于估计量的方差和偏差的平方。我们分别计算每一项。\n\n第一项（方差）：$\\mathbb{E}\\big[\\|P_{S}w\\|_{2}^{2}\\big]$。\n设 $\\{u_1, \\dots, u_k\\}$ 是 $k$ 维子空间 $S$ 的一个标准正交基。$w$ 在 $S$ 上的投影可以写为 $P_{S}w = \\sum_{i=1}^{k} \\langle w, u_i \\rangle u_i$。其平方范数则为：\n$$\\|P_{S}w\\|_{2}^{2} = \\sum_{i=1}^{k} \\langle w, u_i \\rangle^2$$\n期望为 $\\mathbb{E}\\big[\\|P_{S}w\\|_{2}^{2}\\big] = \\sum_{i=1}^{k} \\mathbb{E}\\big[\\langle w, u_i \\rangle^2\\big]$。噪声向量 $w$ 服从分布 $\\mathcal{N}(0, \\sigma^{2}I_n)$。随机变量 $\\langle w, u_i \\rangle$ 是一个高斯向量的线性变换，因此也是高斯的。其均值为 $\\mathbb{E}[\\langle w, u_i \\rangle] = \\langle \\mathbb{E}[w], u_i \\rangle = \\langle 0, u_i \\rangle = 0$。其方差为 $\\mathrm{Var}(\\langle w, u_i \\rangle) = u_i^T \\mathrm{Cov}(w) u_i = u_i^T (\\sigma^2 I_n) u_i = \\sigma^2 u_i^T u_i = \\sigma^2 \\|u_i\\|_2^2 = \\sigma^2$。对于一个零均值随机变量，其平方的期望等于其方差。因此，$\\mathbb{E}[\\langle w, u_i \\rangle^2] = \\sigma^2$。\n对 $k$ 个基向量求和，我们得到：\n$$\\mathbb{E}\\big[\\|P_{S}w\\|_{2}^{2}\\big] = \\sum_{i=1}^{k} \\sigma^2 = k \\sigma^2$$\n这一项表示由测量噪声 $w$ 引起的误差贡献。更高维度的信号模型（更大的 $k$）更灵活，会“拟合”更多的噪声，从而导致重建的方差更高。\n\n第二项（偏差的平方）：$\\mathbb{E}\\big[\\|x_{\\perp}\\|_{2}^{2}\\big]$。\n这一项表示由于模型无法表示真实信号中位于子空间 $S$ 之外的分量而产生的系统误差。给定 $x_{\\perp}$ 在 $(n-k)$ 维子空间 $S^{\\perp}$ 上服从高斯分布，具体为 $x_{\\perp} \\sim \\mathcal{N}(0, \\tau^{2}I_{n-k})$。\n设 $\\{v_1, \\dots, v_{n-k}\\}$ 是 $S^{\\perp}$ 的一个标准正交基。我们可以将 $x_{\\perp}$ 写为 $x_{\\perp} = \\sum_{j=1}^{n-k} c_j v_j$，其中系数 $c = (c_1, \\dots, c_{n-k})^T$ 服从分布 $\\mathcal{N}(0, \\tau^2 I_{n-k})$。其平方范数为：\n$$\\|x_{\\perp}\\|_{2}^{2} = \\sum_{j=1}^{n-k} c_j^2$$\n期望为 $\\mathbb{E}\\big[\\|x_{\\perp}\\|_{2}^{2}\\big] = \\sum_{j=1}^{n-k} \\mathbb{E}[c_j^2]$。每个系数 $c_j$ 服从 $\\mathcal{N}(0, \\tau^2)$ 分布。和之前一样，$\\mathbb{E}[c_j^2] = \\mathrm{Var}(c_j) + (\\mathbb{E}[c_j])^2 = \\tau^2 + 0^2 = \\tau^2$。\n对 $n-k$ 个基向量求和，我们得到：\n$$\\mathbb{E}\\big[\\|x_{\\perp}\\|_{2}^{2}\\big] = \\sum_{j=1}^{n-k} \\tau^2 = (n-k)\\tau^2$$\n这一项表示由模型失配引起的误差。更高维度的模型（更大的 $k$）会留下一个更低维度的正交补空间，从而减小这一偏差项。\n\n结合这两项，总的期望平方重建误差为：\n$$\\mathbb{E}\\big[\\|x^{\\wedge} - x^{\\star}\\|_{2}^{2}\\big] = k \\sigma^2 + (n-k)\\tau^2$$\n这个表达式清晰地展示了偏差-方差权衡。增加由维度 $k$ 表示的模型复杂度，会增加方差项 $k \\sigma^2$，同时减少偏差项 $(n-k)\\tau^2$。最优的模型复杂度将取决于噪声方差 $\\sigma^2$ 和模型失配方差 $\\tau^2$ 的相对大小。", "answer": "$$\n\\boxed{k \\sigma^{2} + (n-k) \\tau^{2}}\n$$", "id": "3442952"}, {"introduction": "构建正确的目标函数只是成功的一半，我们还必须高效地求解由此产生的优化问题。由先验和前向模型共同决定的潜空间几何形态，可能会导致标准优化算法收敛缓慢。本练习 [@problem_id:3442832] 深入探讨了“曲率感知预条件” (curvature-aware preconditioning) 这一概念，展示了如何利用问题的海森矩阵 (Hessian) 结构信息来改善问题的条件数，从而显著加速梯度类优化算法的收敛。", "problem": "考虑一个在潜空间中线性化的、带有深度生成先验的线性逆问题。设潜变量为 $z \\in \\mathbb{R}^{2}$，生成器是局部线性的，其雅可比矩阵为 $J_{G} = W \\in \\mathbb{R}^{2 \\times 2}$。测量值遵循 $y \\approx A x$，其中 $x = G(z)$ 且 $A \\in \\mathbb{R}^{2 \\times 2}$。假设 $z$ 服从高斯先验，其密度为 $p(z) \\propto \\exp\\!\\left(-\\tfrac{1}{2} z^{\\top} \\Sigma^{-1} z\\right)$，因此 $-\\log p(z) = \\tfrac{1}{2} z^{\\top} \\Sigma^{-1} z + \\text{const}$ 且 $\\nabla^{2}(-\\log p) = \\Sigma^{-1}$。潜空间中的最大后验（MAP）目标函数为\n$$\nf(z) = \\tfrac{1}{2} \\|A G(z) - y\\|_{2}^{2} + \\tfrac{\\lambda}{2} z^{\\top} \\Sigma^{-1} z,\n$$\n其中 $\\lambda  0$，并且在局部线性化 $G(z) \\approx W z$ 下，其（高斯-牛顿）曲率为\n$$\nB \\;=\\; J_{G}^{\\top} A^{\\top} A J_{G} \\;+\\; \\lambda \\,\\nabla^{2}(-\\log p) \\;=\\; W^{\\top} A^{\\top} A W \\;+\\; \\lambda \\,\\Sigma^{-1}.\n$$\n我们考虑对 $z$ 进行一阶优化，并使用一个由度量 $P \\succ 0$ 给出的、感知曲率的预处理器，该预处理器以右预处理梯度步长 $\\Delta z = - \\alpha \\, P^{-1} \\nabla f(z)$ 的形式应用。\n\n假设以下具体的、数值上一致的设置：\n- $W = \\mathrm{diag}(2,\\,1)$，\n- $A = \\mathrm{diag}(3,\\,1)$，\n- $\\Sigma = \\mathrm{diag}\\!\\left(\\tfrac{1}{4},\\,1\\right)$，因此 $\\Sigma^{-1} = \\mathrm{diag}(4,\\,1)$，\n- $\\lambda = 1$。\n\n1. 使用线性最小二乘、高斯先验和高斯-牛顿曲率的基础知识，显式地构造 $B$ 并计算其谱条件数 $\\kappa_{0} = \\lambda_{\\max}(B)/\\lambda_{\\min}(B)$。\n2. 使用先验预处理器 $P = \\lambda \\,\\Sigma^{-1}$，分析预处理后的二次模型并确定有效曲率。计算有效曲率对应的条件数 $\\kappa_{1}$。\n3. 对于梯度下降法，使用强凸二次收敛界，并采用极小极大最优常数步长 $\\alpha^{\\star} = \\tfrac{2}{L + \\mu}$，其中 $L$ 和 $\\mu$ 分别是曲率的最大和最小特征值，最坏情况下的线性收缩因子为 $q = \\tfrac{\\kappa - 1}{\\kappa + 1}$。令 $q_{0}$ 为无预处理时的收缩因子（使用 $\\kappa_{0}$），$q_{1}$ 为使用先验预处理时的收缩因子（使用 $\\kappa_{1}$）。计算精确比率\n$$\nr \\;=\\; \\frac{q_{0}}{q_{1}}.\n$$\n\n将 $r$ 以单个简化的精确有理数形式给出。无需四舍五入。没有需要报告的物理单位。", "solution": "该问题要求计算一个特定的潜空间优化问题的收敛速率之比，比较无预处理方法和使用基于先验的预处理器的方法。解题过程如问题陈述中所述，分三步进行。\n\n首先，我们定义问题中给出的矩阵和参数。\n生成器雅可比矩阵为 $W = \\mathrm{diag}(2, 1)$，可以写成：\n$$\nW = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix}\n$$\n测量矩阵为 $A = \\mathrm{diag}(3, 1)$：\n$$\nA = \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix}\n$$\n潜变量 $z$ 的高斯先验的逆协方差矩阵为 $\\Sigma^{-1} = \\mathrm{diag}(4, 1)$：\n$$\n\\Sigma^{-1} = \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}\n$$\n正则化参数为 $\\lambda = 1$。\n\n**1. 无预处理的曲率和条件数**\n\n（高斯-牛顿）曲率矩阵 $B$ 由以下公式给出：\n$$\nB = W^{\\top} A^{\\top} A W + \\lambda \\Sigma^{-1}\n$$\n由于 $W$ 和 $A$ 是对角矩阵，它们是对称的，因此 $W^{\\top} = W$ 且 $A^{\\top} = A$。\n首先，我们计算数据保真项 $W^{\\top} A^{\\top} A W$：\n$$\nW^{\\top} A^{\\top} A W = W A A W = W A^2 W\n$$\n$$\nA^2 = \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 3  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 3^2  0 \\\\ 0  1^2 \\end{pmatrix} = \\begin{pmatrix} 9  0 \\\\ 0  1 \\end{pmatrix}\n$$\n$$\nW A^2 W = \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 9  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 2  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 2 \\cdot 9 \\cdot 2  0 \\\\ 0  1 \\cdot 1 \\cdot 1 \\end{pmatrix} = \\begin{pmatrix} 36  0 \\\\ 0  1 \\end{pmatrix}\n$$\n接下来，我们计算先验项 $\\lambda \\Sigma^{-1}$：\n$$\n\\lambda \\Sigma^{-1} = 1 \\cdot \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}\n$$\n现在，我们将这两个矩阵相加得到 $B$：\n$$\nB = \\begin{pmatrix} 36  0 \\\\ 0  1 \\end{pmatrix} + \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 36+4  0 \\\\ 0  1+1 \\end{pmatrix} = \\begin{pmatrix} 40  0 \\\\ 0  2 \\end{pmatrix}\n$$\n对于对角矩阵，其特征值即为对角线上的元素。因此，$B$ 的特征值为 $\\lambda_{\\max}(B) = 40$ 和 $\\lambda_{\\min}(B) = 2$。\n谱条件数 $\\kappa_0$ 是最大特征值与最小特征值的比值：\n$$\n\\kappa_0 = \\frac{\\lambda_{\\max}(B)}{\\lambda_{\\min}(B)} = \\frac{40}{2} = 20\n$$\n\n**2. 预处理后的曲率和条件数**\n\n问题定义了一个先验预处理器 $P = \\lambda \\Sigma^{-1}$。对于给定值：\n$$\nP = 1 \\cdot \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix} = \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}\n$$\n右预处理梯度步长涉及到矩阵 $P^{-1} B$。这是预处理后系统的有效曲率。首先，我们求 $P^{-1}$：\n$$\nP^{-1} = \\begin{pmatrix} 4  0 \\\\ 0  1 \\end{pmatrix}^{-1} = \\begin{pmatrix} \\frac{1}{4}  0 \\\\ 0  1 \\end{pmatrix}\n$$\n现在我们计算有效曲率矩阵，记为 $H_{\\text{eff}}$：\n$$\nH_{\\text{eff}} = P^{-1} B = \\begin{pmatrix} \\frac{1}{4}  0 \\\\ 0  1 \\end{pmatrix} \\begin{pmatrix} 40  0 \\\\ 0  2 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{4} \\cdot 40  0 \\\\ 0  1 \\cdot 2 \\end{pmatrix} = \\begin{pmatrix} 10  0 \\\\ 0  2 \\end{pmatrix}\n$$\n有效曲率矩阵 $H_{\\text{eff}}$ 的特征值是其对角线元素，即 $10$ 和 $2$。\n令 $L$ 和 $\\mu$ 为 $H_{\\text{eff}}$ 的最大和最小特征值，因此 $L = 10$ 且 $\\mu = 2$。预处理后系统的条件数 $\\kappa_1$ 为：\n$$\n\\kappa_1 = \\frac{L}{\\mu} = \\frac{10}{2} = 5\n$$\n\n**3. 收缩因子之比**\n\n对于条件数为 $\\kappa$ 的强凸二次目标函数，梯度下降的最坏情况线性收缩因子 $q$ 由下式给出：\n$$\nq = \\frac{\\kappa - 1}{\\kappa + 1}\n$$\n对于无预处理的系统，收缩因子 $q_0$ 基于 $\\kappa_0 = 20$ 计算：\n$$\nq_0 = \\frac{\\kappa_0 - 1}{\\kappa_0 + 1} = \\frac{20 - 1}{20 + 1} = \\frac{19}{21}\n$$\n对于使用先验预处理的系统，收缩因子 $q_1$ 基于 $\\kappa_1 = 5$ 计算：\n$$\nq_1 = \\frac{\\kappa_1 - 1}{\\kappa_1 + 1} = \\frac{5 - 1}{5 + 1} = \\frac{4}{6} = \\frac{2}{3}\n$$\n最后，我们计算所需的比率 $r$：\n$$\nr = \\frac{q_0}{q_1} = \\frac{\\frac{19}{21}}{\\frac{2}{3}} = \\frac{19}{21} \\cdot \\frac{3}{2} = \\frac{19 \\cdot 3}{21 \\cdot 2}\n$$\n由于 $21 = 7 \\cdot 3$，我们可以简化表达式：\n$$\nr = \\frac{19 \\cdot 3}{7 \\cdot 3 \\cdot 2} = \\frac{19}{7 \\cdot 2} = \\frac{19}{14}\n$$\n最终结果是一个精确的有理数。", "answer": "$$\n\\boxed{\\frac{19}{14}}\n$$", "id": "3442832"}]}