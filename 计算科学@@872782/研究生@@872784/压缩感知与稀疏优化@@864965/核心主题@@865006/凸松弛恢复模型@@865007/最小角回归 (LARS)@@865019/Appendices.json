{"hands_on_practices": [{"introduction": "要真正掌握一个算法，亲手执行它是必不可少的。本练习将通过一个具体的数据集，引导你手动完成最小角回归（LARS）算法的最初两个步骤。这有助于你深入理解算法的核心机制，包括如何确定活动集、计算等角方向以及确定步长。[@problem_id:3456897]", "problem": "考虑一个线性模型，其设计矩阵为 $X \\in \\mathbb{R}^{3 \\times 3}$，响应向量为 $y \\in \\mathbb{R}^{3}$。设\n$$\nX \\;=\\; \\begin{pmatrix}\n1  1  0 \\\\\n0  1  1 \\\\\n1  0  1\n\\end{pmatrix},\n\\qquad\ny \\;=\\; \\begin{pmatrix}\n3 \\\\ 1 \\\\ 0\n\\end{pmatrix}.\n$$\n假设 $X$ 的列向量已被归一化，具有单位欧几里得范数。使用经典的最小角回归 (LAR) 算法（无最小绝对收缩和选择算子 (LASSO) 修改），从零系数向量开始，执行 LAR 的前两步。从核心定义出发：在每一步中，选择与当前残差具有最大绝对相关性的预测变量作为活动集，使拟合值沿相对于活动预测变量的等角方向移动，并选择步长以使新的预测变量与活动集达到相等的绝对相关性。对前两步中的每一步，计算：\n- 等角方向 $u_{A}$，\n- 到达下一个事件的步长 $\\gamma$，\n- 以及执行该步后产生的系数更新 $\\beta$。\n\n为所有中间量提供精确的解析值。对于最终答案，报告第二步步长的精确值，记为 $\\gamma_{2}$。不要近似或四舍五入；提供 $\\gamma_{2}$ 的精确闭式表达式。", "solution": "该问题陈述经核实是科学合理、定义明确且客观的。这是最小角回归（LAR）算法的直接应用。我们现在开始求解。\n\n首先，根据规定，我们必须将设计矩阵 $X$ 的列向量归一化，使其具有单位欧几里得范数。给定的矩阵是\n$$\nX_{unnormalized} = \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\\\ 1  0  1 \\end{pmatrix}\n$$\n列向量为 $x_{un,1} = (1, 0, 1)^T$、$x_{un,2} = (1, 1, 0)^T$ 和 $x_{un,3} = (0, 1, 1)^T$。每个列向量的欧几里得范数是 $\\|x_{un,j}\\|_2 = \\sqrt{1^2+1^2} = \\sqrt{2}$。我们将每个列向量除以 $\\sqrt{2}$ 来获得归一化的设计矩阵 $X$：\n$$\nX = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1  1  0 \\\\ 0  1  1 \\\\ 1  0  1 \\end{pmatrix}\n$$\n设归一化后的列向量表示为 $x_1$、$x_2$ 和 $x_3$。响应向量为 $y = (3, 1, 0)^T$。\n\nLAR 算法从零系数向量 $\\beta_0 = (0, 0, 0)^T$ 开始。初始拟合值为 $\\mu_0 = X\\beta_0 = (0, 0, 0)^T$，初始残差为 $r_0 = y - \\mu_0 = y = (3, 1, 0)^T$。\n\n**第1步：LAR第一步**\n\n首先，我们计算预测变量与残差 $r_0$ 的初始相关性。相关性向量为 $c = X^T r_0$：\n$$\nc = X^T r_0 = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1  0  1 \\\\ 1  1  0 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 3 \\\\ 1 \\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 3 \\\\ 4 \\\\ 1 \\end{pmatrix}\n$$\n绝对相关性为 $|\\frac{3}{\\sqrt{2}}|$、 $|\\frac{4}{\\sqrt{2}}|$ 和 $|\\frac{1}{\\sqrt{2}}|$。最大绝对相关性是 $|c_2| = \\frac{4}{\\sqrt{2}}$。因此，初始活动集为 $\\mathcal{A}_1 = \\{2\\}$。\n\n拟合值的等角方向 $u_{\\mathcal{A}_1}$ 与相关性最大的预测变量对齐，并由其相关性符号决定。由于 $c_2  0$，该方向就是单位向量 $x_2$。\n$$\nu_{\\mathcal{A}_1} = x_2 = \\frac{1}{\\sqrt{2}}(1, 1, 0)^T\n$$\n我们将拟合值从 $\\mu_0$ 沿此方向移动：$\\mu(\\gamma) = \\mu_0 + \\gamma u_{\\mathcal{A}_1} = \\gamma x_2$。残差变为 $r(\\gamma) = r_0 - \\gamma x_2$。\n步长 $\\gamma_1$ 是最小的正 $\\gamma$，使得某个其他预测变量 $j \\notin \\mathcal{A}_1$ 与 $r(\\gamma)$ 的相关性大小与预测变量 2 相同：$|x_j^T r(\\gamma)| = |x_2^T r(\\gamma)|$。\n相关性演变为 $c_j(\\gamma) = x_j^T (r_0 - \\gamma x_2) = c_j - \\gamma (x_j^T x_2)$。\n我们需要计算对于 $j \\in \\{1, 3\\}$ 的内积 $x_j^T x_2$：\n$x_1^T x_2 = \\frac{1}{2}(1 \\cdot 1 + 0 \\cdot 1 + 1 \\cdot 0) = \\frac{1}{2}$。\n$x_3^T x_2 = \\frac{1}{2}(0 \\cdot 1 + 1 \\cdot 1 + 1 \\cdot 0) = \\frac{1}{2}$。\n由于 $x_2$ 是归一化的，所以 $x_2^T x_2 = 1$。\n我们必须在以下方程中求解 $\\gamma  0$：\n1. 对于 $j=1$：$|c_1 - \\gamma (x_1^T x_2)| = |c_2 - \\gamma (x_2^T x_2)| \\implies |\\frac{3}{\\sqrt{2}} - \\frac{\\gamma}{2}| = |\\frac{4}{\\sqrt{2}} - \\gamma|$。\n   - $\\frac{3}{\\sqrt{2}} - \\frac{\\gamma}{2} = \\frac{4}{\\sqrt{2}} - \\gamma \\implies \\frac{\\gamma}{2} = \\frac{1}{\\sqrt{2}} \\implies \\gamma = \\sqrt{2}$。\n   - $\\frac{3}{\\sqrt{2}} - \\frac{\\gamma}{2} = -(\\frac{4}{\\sqrt{2}} - \\gamma) \\implies \\frac{7}{\\sqrt{2}} = \\frac{3\\gamma}{2} \\implies \\gamma = \\frac{14}{3\\sqrt{2}} = \\frac{7\\sqrt{2}}{3}$。\n2. 对于 $j=3$：$|c_3 - \\gamma (x_3^T x_2)| = |c_2 - \\gamma (x_2^T x_2)| \\implies |\\frac{1}{\\sqrt{2}} - \\frac{\\gamma}{2}| = |\\frac{4}{\\sqrt{2}} - \\gamma|$。\n   - $\\frac{1}{\\sqrt{2}} - \\frac{\\gamma}{2} = \\frac{4}{\\sqrt{2}} - \\gamma \\implies \\frac{\\gamma}{2} = \\frac{3}{\\sqrt{2}} \\implies \\gamma = 3\\sqrt{2}$。\n   - $\\frac{1}{\\sqrt{2}} - \\frac{\\gamma}{2} = -(\\frac{4}{\\sqrt{2}} - \\gamma) \\implies \\frac{5}{\\sqrt{2}} = \\frac{3\\gamma}{2} \\implies \\gamma = \\frac{10}{3\\sqrt{2}} = \\frac{5\\sqrt{2}}{3}$。\n最小的正值为 $\\gamma_1 = \\sqrt{2}$。\n\n步长为 $\\gamma_1 = \\sqrt{2}$。在此步结束时，拟合值为 $\\mu_1 = \\mu_0 + \\gamma_1 u_{\\mathcal{A}_1} = \\sqrt{2} x_2 = (1, 1, 0)^T$。系数向量 $\\beta_1$ 必须满足 $X\\beta_1 = \\mu_1 = \\sqrt{2} x_2$。这意味着 $\\beta_1$ 仅在索引 2 处有非零元素，其值为 $\\sqrt{2}$。\n$$\n\\beta_1 = (0, \\sqrt{2}, 0)^T\n$$\n\n**第2步：LAR第二步**\n\n在第二步开始时，活动集为 $\\mathcal{A}_2 = \\{1, 2\\}$，因为预测变量 1 现在的绝对相关性已达到与预测变量 2 相同的大小。\n残差为 $r_1 = y - \\mu_1 = (3, 1, 0)^T - (1, 1, 0)^T = (2, 0, 0)^T$。\n我们来验证与 $r_1$ 的相关性：\n$c(r_1) = X^T r_1 = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1  0  1 \\\\ 1  1  0 \\\\ 0  1  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 2 \\\\ 2 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\sqrt{2} \\\\ \\sqrt{2} \\\\ 0 \\end{pmatrix}$。\n正如预期， $|c_1| = |c_2|  |c_3|$。活动集的相关性符号为 $s_{\\mathcal{A}_2} = (\\text{sign}(c_1), \\text{sign}(c_2))^T = (1, 1)^T$。\n\n新的等角方向 $u_{\\mathcal{A}_2}$ 是一个与 $s_1 x_1$ 和 $s_2 x_2$ 形成相等角度的单位向量。它由 $u_{\\mathcal{A}_2} \\propto X_{\\mathcal{A}_2} (X_{\\mathcal{A}_2}^T X_{\\mathcal{A}_2})^{-1} s_{\\mathcal{A}_2}$ 给出。设 $X_{\\mathcal{A}_2} = [x_1, x_2]$。\n$X_{\\mathcal{A}_2}^T X_{\\mathcal{A}_2} = \\begin{pmatrix} x_1^T x_1  x_1^T x_2 \\\\ x_2^T x_1  x_2^T x_2 \\end{pmatrix} = \\begin{pmatrix} 1  1/2 \\\\ 1/2  1 \\end{pmatrix}$。\n逆矩阵为 $(X_{\\mathcal{A}_2}^T X_{\\mathcal{A}_2})^{-1} = \\frac{1}{1-(1/2)^2} \\begin{pmatrix} 1  -1/2 \\\\ -1/2  1 \\end{pmatrix} = \\frac{4}{3} \\begin{pmatrix} 1  -1/2 \\\\ -1/2  1 \\end{pmatrix} = \\begin{pmatrix} 4/3  -2/3 \\\\ -2/3  4/3 \\end{pmatrix}$。\n方向的权重为 $w = (X_{\\mathcal{A}_2}^T X_{\\mathcal{A}_2})^{-1} s_{\\mathcal{A}_2} = \\begin{pmatrix} 4/3  -2/3 \\\\ -2/3  4/3 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 2/3 \\\\ 2/3 \\end{pmatrix}$。\n未归一化的方向是 $u'_{\\mathcal{A}_2} = X_{\\mathcal{A}_2} w = \\frac{2}{3}x_1 + \\frac{2}{3}x_2 = \\frac{2}{3} (\\frac{1}{\\sqrt{2}}(1,0,1)^T + \\frac{1}{\\sqrt{2}}(1,1,0)^T) = \\frac{\\sqrt{2}}{3}(2,1,1)^T$。\n其范数为 $\\|u'_{\\mathcal{A}_2}\\| = \\frac{\\sqrt{2}}{3} \\sqrt{2^2+1^2+1^2} = \\frac{\\sqrt{2}\\sqrt{6}}{3} = \\frac{2\\sqrt{3}}{3}$。\n归一化的等角方向是 $u_{\\mathcal{A}_2} = \\frac{u'_{\\mathcal{A}_2}}{\\|u'_{\\mathcal{A}_2}\\|} = \\frac{\\frac{\\sqrt{2}}{3}(2,1,1)^T}{2\\sqrt{3}/3} = \\frac{\\sqrt{2}}{2\\sqrt{3}}(2,1,1)^T = \\frac{1}{\\sqrt{6}}(2,1,1)^T$。\n\n步长 $\\gamma_2$ 是通过确定非活动预测变量 $x_3$ 何时达到与活动集相同的绝对相关性来找到的。拟合值移动为 $\\mu(\\gamma) = \\mu_1+\\gamma u_{\\mathcal{A}_2}$，残差移动为 $r(\\gamma) = r_1 - \\gamma u_{\\mathcal{A}_2}$。\n相关性演变为 $c_j(\\gamma) = c_j(r_1) - \\gamma(x_j^T u_{\\mathcal{A}_2})$。\n我们需要内积 $x_j^T u_{\\mathcal{A}_2}$：\n$x_1^T u_{\\mathcal{A}_2} = \\frac{1}{\\sqrt{2}}(1,0,1)^T \\cdot \\frac{1}{\\sqrt{6}}(2,1,1)^T = \\frac{3}{\\sqrt{12}} = \\frac{\\sqrt{3}}{2}$。\n$x_2^T u_{\\mathcal{A}_2} = \\frac{1}{\\sqrt{2}}(1,1,0)^T \\cdot \\frac{1}{\\sqrt{6}}(2,1,1)^T = \\frac{3}{\\sqrt{12}} = \\frac{\\sqrt{3}}{2}$。\n$x_3^T u_{\\mathcal{A}_2} = \\frac{1}{\\sqrt{2}}(0,1,1)^T \\cdot \\frac{1}{\\sqrt{6}}(2,1,1)^T = \\frac{2}{\\sqrt{12}} = \\frac{1}{\\sqrt{3}}$。\n我们设 $|c_3(\\gamma)| = |c_1(\\gamma)|$：\n$|c_3(r_1) - \\gamma(x_3^T u_{\\mathcal{A}_2})| = |c_1(r_1) - \\gamma(x_1^T u_{\\mathcal{A}_2})|$\n$|0 - \\gamma \\frac{1}{\\sqrt{3}}| = |\\sqrt{2} - \\gamma \\frac{\\sqrt{3}}{2}|$。\n假设 $\\gamma$ 足够小，使得 $\\sqrt{2} - \\gamma \\frac{\\sqrt{3}}{2} > 0$，我们求解：\n$\\frac{\\gamma}{\\sqrt{3}} = \\sqrt{2} - \\gamma \\frac{\\sqrt{3}}{2} \\implies \\gamma (\\frac{1}{\\sqrt{3}} + \\frac{\\sqrt{3}}{2}) = \\sqrt{2} \\implies \\gamma (\\frac{2+3}{2\\sqrt{3}}) = \\sqrt{2} \\implies \\gamma \\frac{5}{2\\sqrt{3}} = \\sqrt{2}$。\n这得到 $\\gamma = \\frac{2\\sqrt{6}}{5}$。\n另一种可能是 $\\frac{\\gamma}{\\sqrt{3}} = -(\\sqrt{2} - \\gamma\\frac{\\sqrt{3}}{2})$，得出 $\\gamma=2\\sqrt{6}$。步长 $\\gamma_2$ 是这些正解中的最小值。\n因此，第二步的步长是 $\\gamma_2 = \\frac{2\\sqrt{6}}{5}$。\n\n最后，我们找到此步后的系数向量 $\\beta_2$。活动系数 $(\\beta_1, \\beta_2)$ 的变化与权重 $w = (2/3, 2/3)^T$ 成正比。总的系数更新量为 $\\Delta\\beta_{\\mathcal{A}_2} = \\frac{\\gamma_2}{\\|u'_{\\mathcal{A}_2}\\|} w = \\frac{2\\sqrt{6}/5}{2\\sqrt{3}/3} \\begin{pmatrix} 2/3 \\\\ 2/3 \\end{pmatrix} = \\frac{3\\sqrt{2}}{5} \\begin{pmatrix} 2/3 \\\\ 2/3 \\end{pmatrix} = \\begin{pmatrix} 2\\sqrt{2}/5 \\\\ 2\\sqrt{2}/5 \\end{pmatrix}$。\n新的系数向量是 $\\beta_2 = \\beta_1 + \\Delta\\beta = (0, \\sqrt{2}, 0)^T + (\\frac{2\\sqrt{2}}{5}, \\frac{2\\sqrt{2}}{5}, 0)^T$。\n$$\n\\beta_2 = \\left(\\frac{2\\sqrt{2}}{5}, \\sqrt{2}+\\frac{2\\sqrt{2}}{5}, 0\\right)^T = \\left(\\frac{2\\sqrt{2}}{5}, \\frac{7\\sqrt{2}}{5}, 0\\right)^T\n$$\n题目要求的是 $\\gamma_2$ 的值。\n\n前两步计算量的总结：\n第1步：\n- 等角方向 $u_{\\mathcal{A}_1} = \\frac{1}{\\sqrt{2}}(1, 1, 0)^T$\n- 步长 $\\gamma_1 = \\sqrt{2}$\n- 系数向量 $\\beta_1 = (0, \\sqrt{2}, 0)^T$\n\n第2步：\n- 等角方向 $u_{\\mathcal{A}_2} = \\frac{1}{\\sqrt{6}}(2, 1, 1)^T$\n- 步长 $\\gamma_2 = \\frac{2\\sqrt{6}}{5}$\n- 系数向量 $\\beta_2 = (\\frac{2\\sqrt{2}}{5}, \\frac{7\\sqrt{2}}{5}, 0)^T$", "answer": "$$\n\\boxed{\\frac{2\\sqrt{6}}{5}}\n$$", "id": "3456897"}, {"introduction": "除了数值计算，理解最小角回归（LARS）背后的几何原理也至关重要。本练习将从具体的数字转向符号化的抽象，要求你为一个普遍的双预测变量情景推导出等角方向的表达式。通过这个过程，你将更深刻地洞察预测变量之间的相关性是如何塑造解路径的几何形态的。[@problem_id:3456886]", "problem": "考虑一个线性模型，其设计矩阵为 $X \\in \\mathbb{R}^{n \\times 2}$，其列 $x_{1}$ 和 $x_{2}$ 经过标准化，使得格拉姆矩阵 $X^{\\top}X$ 等于\n$$\nG \\equiv X^{\\top}X \\;=\\; \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix},\n$$\n其中 $0  \\rho  1$。在最小角回归 (Least Angle Regression, LARS) 算法的某一步，活动集为 $A = \\{1,2\\}$，符号为 $s_{A} = (1,1)^{\\top}$。定义等角方向 $u_{A}$ 为在 $X_{A} = [x_{1}, x_{2}]$ 的张成空间中的唯一向量，其具有单位欧几里得范数，并与活动预测变量具有相等的带符号相关性，即对于某个标量 $A_{A} > 0$，有 $X_{A}^{\\top} u_{A} = A_{A} s_{A}$。令 $a \\equiv X^{\\top} u_{A}$ 表示所有预测变量与等角方向的相关性向量。\n\n仅从这些定义和基础线性代数（格拉姆矩阵、欧几里得范数和线性无关性）出发，推导以下各项关于 $\\rho$ 的显式表达式：\n- 系数向量 $w_{A} \\in \\mathbb{R}^{2}$，使得 $u_{A} = X_{A} w_{A}$，\n- 向量 $a \\in \\mathbb{R}^{2}$。\n\n将您的最终答案表示为一个单行矩阵，其中按顺序包含 $w_{A}$ 的两个分量，然后是 $a$ 的两个分量。不需要进行数值取整，也不涉及物理单位。", "solution": "该问题已经过有效性检查，被认为是科学上可靠、提法恰当、客观且内部一致的。我们可以开始求解。\n\n问题要求在最小角回归 (LARS) 算法的特定步骤中，给出与等角方向 $u_A$ 相关联的系数向量 $w_A$ 和相关性向量 $a$ 的显式表达式。\n\n我们有以下给定的定义和条件：\n1. 设计矩阵为 $X \\in \\mathbb{R}^{n \\times 2}$，其列为 $x_1$ 和 $x_2$。活动集为 $A = \\{1, 2\\}$，因此活动预测变量矩阵为 $X_A = X$。\n2. 格拉姆矩阵为 $G = X_A^{\\top}X_A = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}$，其中 $0  \\rho  1$。\n3. 等角方向 $u_A$ 位于 $X_A$ 的列向量的张成空间中，因此对于某个向量 $w_A \\in \\mathbb{R}^2$，有 $u_A = X_A w_A$。\n4. 向量 $u_A$ 具有单位欧几里得范数：$\\|u_A\\|_2^2 = 1$。\n5. 向量 $u_A$ 相对于活动预测变量是等角的，其符号由 $s_A = (1, 1)^{\\top}$ 给出。这意味着对于某个标量 $A_A > 0$，有 $X_A^{\\top} u_A = A_A s_A$。\n6. 相关性向量定义为 $a = X^{\\top} u_A$。由于 $X_A = X$，因此 $a = X_A^{\\top} u_A$。\n\n根据定义6和5，我们可以立即将 $a$ 与 $A_A$ 和 $s_A$ 联系起来：\n$$a = X_A^{\\top} u_A = A_A s_A$$\n为了求出 $a$，我们必须首先确定标量 $A_A$ 的值。\n\n让我们结合给定的定义。将 $u_A = X_A w_A$ 代入等角条件，得到：\n$$X_A^{\\top} (X_A w_A) = A_A s_A$$\n$$(X_A^{\\top} X_A) w_A = A_A s_A$$\n使用格拉姆矩阵 $G$ 的定义，这变成了一个关于 $w_A$ 的线性系统：\n$$G w_A = A_A s_A$$\n$G$ 的行列式为 $\\det(G) = 1 \\cdot 1 - \\rho \\cdot \\rho = 1 - \\rho^2$。由于给定 $0  \\rho  1$，因此有 $0  1 - \\rho^2  1$，所以 $\\det(G) \\neq 0$。因此，$G$ 是可逆的，我们可以解出 $w_A$：\n$$w_A = G^{-1} (A_A s_A) = A_A (G^{-1} s_A)$$\n这将 $w_A$ 表示为关于尚未知晓的标量 $A_A$ 的表达式。\n\n为了求出 $A_A$，我们使用单位范数条件 $\\|u_A\\|_2^2 = 1$。让我们用 $w_A$ 来表示范数：\n$$\\|u_A\\|_2^2 = (X_A w_A)^{\\top} (X_A w_A) = w_A^{\\top} (X_A^{\\top} X_A) w_A = w_A^{\\top} G w_A = 1$$\n现在，将表达式 $w_A = A_A G^{-1} s_A$ 代入这个范数方程：\n$$(A_A G^{-1} s_A)^{\\top} G (A_A G^{-1} s_A) = 1$$\n$$A_A^2 (s_A^{\\top} (G^{-1})^{\\top}) G (G^{-1} s_A) = 1$$\n格拉姆矩阵 $G$ 是对称的，所以它的逆矩阵 $G^{-1}$ 也是对称的，即 $(G^{-1})^{\\top} = G^{-1}$。方程简化为：\n$$A_A^2 s_A^{\\top} G^{-1} G G^{-1} s_A = 1$$\n$$A_A^2 s_A^{\\top} G^{-1} s_A = 1$$\n我们可以解出 $A_A^2$：\n$$A_A^2 = \\frac{1}{s_A^{\\top} G^{-1} s_A}$$\n为了继续，我们必须计算 $G^{-1}$ 和二次型 $s_A^{\\top} G^{-1} s_A$。$2 \\times 2$ 矩阵 $G$ 的逆矩阵是：\n$$G^{-1} = \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix}$$\n现在，我们计算向量 $G^{-1}s_A$，其中 $s_A = (1, 1)^{\\top}$：\n$$G^{-1} s_A = \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1  -\\rho \\\\ -\\rho  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{1-\\rho^2} \\begin{pmatrix} 1 - \\rho \\\\ 1 - \\rho \\end{pmatrix}$$\n对 $1 - \\rho^2 = (1-\\rho)(1+\\rho)$ 进行因式分解，并注意到 $1-\\rho \\neq 0$，我们简化得到：\n$$G^{-1} s_A = \\frac{1-\\rho}{(1-\\rho)(1+\\rho)} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{1+\\rho} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n接下来，我们计算标量 $s_A^{\\top} G^{-1} s_A$：\n$$s_A^{\\top} G^{-1} s_A = \\begin{pmatrix} 1  1 \\end{pmatrix} \\left( \\frac{1}{1+\\rho} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right) = \\frac{1}{1+\\rho} (1 \\cdot 1 + 1 \\cdot 1) = \\frac{2}{1+\\rho}$$\n将此结果代回 $A_A^2$ 的表达式中：\n$$A_A^2 = \\frac{1}{2/(1+\\rho)} = \\frac{1+\\rho}{2}$$\n由于给定 $A_A > 0$，我们取正平方根：\n$$A_A = \\sqrt{\\frac{1+\\rho}{2}}$$\n现在，我们已经确定了 $A_A$，可以求出 $w_A$ 和 $a$ 的显式表达式。\n\n对于系数向量 $w_A$：\n$$w_A = A_A (G^{-1}s_A) = \\left(\\sqrt{\\frac{1+\\rho}{2}}\\right) \\left(\\frac{1}{1+\\rho} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}\\right)$$\n$$w_A = \\frac{\\sqrt{1+\\rho}}{\\sqrt{2}} \\frac{1}{(\\sqrt{1+\\rho})^2} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sqrt{2}\\sqrt{1+\\rho}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sqrt{2(1+\\rho)}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n因此，$w_A$ 的分量为 $w_1 = \\frac{1}{\\sqrt{2(1+\\rho)}}$ 和 $w_2 = \\frac{1}{\\sqrt{2(1+\\rho)}}$。\n\n对于相关性向量 $a$：\n$$a = A_A s_A = \\sqrt{\\frac{1+\\rho}{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$$\n因此，$a$ 的分量为 $a_1 = \\sqrt{\\frac{1+\\rho}{2}}$ 和 $a_2 = \\sqrt{\\frac{1+\\rho}{2}}$。\n\n最终答案由四个分量 $[w_1, w_2, a_1, a_2]$ 排列成一个行矩阵组成。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{1}{\\sqrt{2(1+\\rho)}}  \\frac{1}{\\sqrt{2(1+\\rho)}}  \\sqrt{\\frac{1+\\rho}{2}}  \\sqrt{\\frac{1+\\rho}{2}}\n\\end{pmatrix}\n}\n$$", "id": "3456886"}, {"introduction": "最小角回归（LARS）算法与其他稀疏建模技术密切相关，但也存在关键差异。本练习构建了一个特定场景，其中LARS-lasso的路径与无穷小前向逐步回归的路径发生分离。通过计算这两条路径之间的“转角”，你将探索它们在基本约束和行为上的细微而又关键的区别。[@problem_id:3456905]", "problem": "考虑一个线性回归问题，其设计矩阵为 $X \\in \\mathbb{R}^{n \\times 3}$，其列 $x_{1}, x_{2}, x_{3}$ 经过中心化和缩放，使得对于 $j \\in \\{1,2,3\\}$ 有 $\\|x_{j}\\|_{2} = 1$。Gram 矩阵 $G = X^{\\top} X \\in \\mathbb{R}^{3 \\times 3}$ 为\n$$\nG \\;=\\; \\begin{pmatrix}\n1  0.5  0.5 \\\\\n0.5  1  -0.4 \\\\\n0.5  -0.4  1\n\\end{pmatrix}.\n$$\n假设与响应的初始相关性严格为正，并按 $X^{\\top} y = (c_{1}^{(0)}, c_{2}^{(0)}, c_{3}^{(0)})^{\\top}$ 排序，其中 $c_{1}^{(0)}  c_{2}^{(0)}  c_{3}^{(0)}  0$。因此，变量按顺序 $1, 2, 3$ 进入活动集，并且进入时的所有符号均为正。在最小角回归与最小绝对收缩和选择算子修改 (LARS-lasso) 以及无穷小前向逐步回归的无穷小步长极限下进行分析，并通过 $\\ell_{1}$-弧长 $t$ 来参数化系数路径，使得每个无穷小方向向量都被归一化为单位 $\\ell_{1}$-速度。\n\n在第三个变量刚刚进入的时刻，活动集为 $A = \\{1,2,3\\}$，其符号向量为 $s_{A} = (1,1,1)^{\\top}$。令 $d_{\\mathrm{LARS}} \\in \\mathbb{R}^{3}$ 为系数空间中的 LARS-lasso 等角方向，定义为 $G d_{\\mathrm{LARS}} = s_{A}$ 的解。令 $d_{\\mathrm{FS}} \\in \\mathbb{R}^{3}$ 为无穷小前向逐步方向，定义为满足 $d_{\\mathrm{FS}} \\ge 0$ 的非负最小二乘方向，并且在所有此类方向中，它能保持活动集上绝对相关性相等；等价地，$d_{\\mathrm{FS}}$ 是通过在子集 $B \\subseteq A$ 上求解 $G_{BB} d_{B} = s_{B}$ 得到的，其中 $d_{B}  0$ 且 $d_{A \\setminus B} = 0$，选择此子集是为了满足非负性约束。\n\n将两个方向都归一化为单位 $\\ell_{1}$-速度，\n$$\nv_{\\mathrm{LARS}} \\;=\\; \\frac{d_{\\mathrm{LARS}}}{\\|d_{\\mathrm{LARS}}\\|_{1}}, \\qquad v_{\\mathrm{FS}} \\;=\\; \\frac{d_{\\mathrm{FS}}}{\\|d_{\\mathrm{FS}}\\|_{1}}.\n$$\n将此拐点处的基于曲率的差异定义为这两个单位 $\\ell_{1}$-速度切线方向之间的转角，\n$$\n\\theta \\;=\\; \\arccos\\!\\left( \\frac{\\langle v_{\\mathrm{LARS}}, v_{\\mathrm{FS}} \\rangle}{\\|v_{\\mathrm{LARS}}\\|_{2} \\, \\|v_{\\mathrm{FS}}\\|_{2}} \\right),\n$$\n解释为在分歧事件处系数路径的集中曲率。\n\n精确计算 $\\theta$。将最终答案表示为以弧度为单位的封闭形式解析表达式（不要进行数值舍入）。", "solution": "该问题有效。我们继续进行求解。\n\n解答过程分四个阶段计算：\n1.  计算 LARS-lasso 方向向量 $d_{\\mathrm{LARS}}$。\n2.  计算无穷小前向逐步方向向量 $d_{\\mathrm{FS}}$。\n3.  归一化两个向量以获得 $v_{\\mathrm{LARS}}$ 和 $v_{\\mathrm{FS}}$。\n4.  计算归一化向量之间的角度 $\\theta$。\n\n**1. 计算 $d_{\\mathrm{LARS}}$**\nLARS-lasso 方向 $d_{\\mathrm{LARS}}$ 由等角条件 $G d_{\\mathrm{LARS}} = s_{A}$ 定义，其中 $G$ 是 Gram 矩阵，$s_{A} = (1, 1, 1)^{\\top}$ 是活动集 $A=\\{1,2,3\\}$ 的符号向量。为了找到 $d_{\\mathrm{LARS}}$，我们通过计算 $G^{-1}$ 来求解这个线性系统。\nGram 矩阵是 $G = \\begin{pmatrix} 1  0.5  0.5 \\\\ 0.5  1  -0.4 \\\\ 0.5  -0.4  1 \\end{pmatrix}$。\n$G$ 的行列式为 $\\det(G) = 0.14$。\n逆矩阵是 $G^{-1} = \\frac{1}{\\det(G)} \\text{adj}(G)$。伴随矩阵 $\\text{adj}(G)$ 是代数余子式矩阵的转置。由于 $G$ 是对称的，其代数余子式矩阵也是对称的，因此 $\\text{adj}(G)$ 就是代数余子式矩阵本身。\n代数余子式为：\n$C_{11} = 1 - (-0.4)^2 = 1 - 0.16 = 0.84$\n$C_{12} = -(0.5 - (0.5)(-0.4)) = -(0.5 + 0.2) = -0.7$\n$C_{13} = (0.5)(-0.4) - (1)(0.5) = -0.2 - 0.5 = -0.7$\n$C_{22} = 1 - (0.5)^2 = 1 - 0.25 = 0.75$\n$C_{23} = -(-0.4 - (0.5)(0.5)) = -(-0.4 - 0.25) = 0.65$\n$C_{33} = 1 - (0.5)^2 = 1 - 0.25 = 0.75$\n根据对称性，$C_{21}=C_{12}$，$C_{31}=C_{13}$，$C_{32}=C_{23}$。\n所以，$G^{-1} = \\frac{1}{0.14} \\begin{pmatrix} 0.84  -0.7  -0.7 \\\\ -0.7  0.75  0.65 \\\\ -0.7  0.65  0.75 \\end{pmatrix}$。\n现在我们计算 $d_{\\mathrm{LARS}} = G^{-1} s_{A}$：\n$d_{\\mathrm{LARS}} = \\frac{1}{0.14} \\begin{pmatrix} 0.84  -0.7  -0.7 \\\\ -0.7  0.75  0.65 \\\\ -0.7  0.65  0.75 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{0.14} \\begin{pmatrix} 0.84 - 0.7 - 0.7 \\\\ -0.7 + 0.75 + 0.65 \\\\ -0.7 + 0.65 + 0.75 \\end{pmatrix} = \\frac{1}{0.14} \\begin{pmatrix} -0.56 \\\\ 0.70 \\\\ 0.70 \\end{pmatrix} = \\begin{pmatrix} -4 \\\\ 5 \\\\ 5 \\end{pmatrix}$。\n该方向与 $(-4, 5, 5)^{\\top}$ 成比例。我们可以使用这个向量，因为任何正的缩放因子都将在角度计算的归一化步骤中被抵消。设 $d_{\\mathrm{LARS}} = (-4, 5, 5)^{\\top}$。\n\n**2. 计算 $d_{\\mathrm{FS}}$**\n无穷小前向逐步 (FS) 回归在构建模型时有一个约束，即系数是单调不减的。在这里，由于系数以正号进入，它们的路径值必须为非负。因此，移动方向 $d_{\\mathrm{FS}}$ 必须是非负的，即 $d_{\\mathrm{FS}} \\ge 0$。\nLARS 方向 $d_{\\mathrm{LARS}} = (-4, 5, 5)^{\\top}$ 的第一个分量是负的。这意味着为了在所有三个变量中保持等角条件，第一个系数 $\\beta_1$ 将不得不减小。这在 FS 中是不允许的。因此，在这一点上，FS 路径必须与 LARS-lasso 路径分歧。\nLARS 方向违反了约束 $d_{\\mathrm{FS},1} \\ge 0$。对于 FS，我们必须设置 $d_{\\mathrm{FS},1} = 0$。FS 的活动集现在减少到 $B=\\{2,3\\}$，方向 $d_{B}$ 必须保持这个子集的等角条件。\n我们求解 $G_{BB} d_{B} = s_{B}$，其中 $B=\\{2,3\\}$，$G_{BB} = \\begin{pmatrix} 1  -0.4 \\\\ -0.4  1 \\end{pmatrix}$，且 $s_{B} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n$\\det(G_{BB}) = 1 - (-0.4)^2 = 1 - 0.16 = 0.84$。\n$G_{BB}^{-1} = \\frac{1}{0.84} \\begin{pmatrix} 1  0.4 \\\\ 0.4  1 \\end{pmatrix}$。\n$d_{B} = \\frac{1}{0.84} \\begin{pmatrix} 1  0.4 \\\\ 0.4  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{1}{0.84} \\begin{pmatrix} 1.4 \\\\ 1.4 \\end{pmatrix} = \\frac{1.4}{0.84} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{140}{84} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} = \\frac{5}{3} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n分量是正的，所以这是一个有效的 FS 方向。完整的方向向量是 $d_{\\mathrm{FS}} = (0, 5/3, 5/3)^{\\top}$。我们可以使用一个更简单的比例向量 $d_{\\mathrm{FS}} = (0, 1, 1)^{\\top}$。\n\n**3. 方向向量的归一化**\n我们将 $d_{\\mathrm{LARS}}$ 和 $d_{\\mathrm{FS}}$ 归一化，使其具有单位 $\\ell_1$-范数。\n对于 LARS-lasso：\n$d_{\\mathrm{LARS}} = (-4, 5, 5)^{\\top}$\n$\\|d_{\\mathrm{LARS}}\\|_{1} = |-4| + |5| + |5| = 14$。\n$v_{\\mathrm{LARS}} = \\frac{d_{\\mathrm{LARS}}}{\\|d_{\\mathrm{LARS}}\\|_{1}} = \\frac{1}{14} (-4, 5, 5)^{\\top} = (-\\frac{4}{14}, \\frac{5}{14}, \\frac{5}{14})^{\\top} = (-\\frac{2}{7}, \\frac{5}{14}, \\frac{5}{14})^{\\top}$。\n\n对于前向逐步回归：\n$d_{\\mathrm{FS}} = (0, 1, 1)^{\\top}$\n$\\|d_{\\mathrm{FS}}\\|_{1} = |0| + |1| + |1| = 2$。\n$v_{\\mathrm{FS}} = \\frac{d_{\\mathrm{FS}}}{\\|d_{\\mathrm{FS}}\\|_{1}} = \\frac{1}{2} (0, 1, 1)^{\\top} = (0, \\frac{1}{2}, \\frac{1}{2})^{\\top}$。\n\n**4. 计算角度 $\\theta$**\n角度 $\\theta$ 由公式 $\\theta = \\arccos\\left( \\frac{\\langle v_{\\mathrm{LARS}}, v_{\\mathrm{FS}} \\rangle}{\\|v_{\\mathrm{LARS}}\\|_{2} \\|v_{\\mathrm{FS}}\\|_{2}} \\right)$ 给出。\n首先，我们计算内积：\n$\\langle v_{\\mathrm{LARS}}, v_{\\mathrm{FS}} \\rangle = (-\\frac{2}{7})(0) + (\\frac{5}{14})(\\frac{1}{2}) + (\\frac{5}{14})(\\frac{1}{2}) = 0 + \\frac{5}{28} + \\frac{5}{28} = \\frac{10}{28} = \\frac{5}{14}$。\n接下来，我们计算 $\\ell_2$-范数：\n$\\|v_{\\mathrm{LARS}}\\|_{2}^2 = (-\\frac{2}{7})^2 + (\\frac{5}{14})^2 + (\\frac{5}{14})^2 = \\frac{4}{49} + \\frac{25}{196} + \\frac{25}{196} = \\frac{16}{196} + \\frac{25}{196} + \\frac{25}{196} = \\frac{66}{196} = \\frac{33}{98}$。\n$\\|v_{\\mathrm{LARS}}\\|_{2} = \\sqrt{\\frac{33}{98}} = \\frac{\\sqrt{33}}{\\sqrt{49 \\times 2}} = \\frac{\\sqrt{33}}{7\\sqrt{2}}$。\n$\\|v_{\\mathrm{FS}}\\|_{2}^2 = 0^2 + (\\frac{1}{2})^2 + (\\frac{1}{2})^2 = \\frac{1}{4} + \\frac{1}{4} = \\frac{1}{2}$。\n$\\|v_{\\mathrm{FS}}\\|_{2} = \\sqrt{\\frac{1}{2}} = \\frac{1}{\\sqrt{2}}$。\n现在，我们计算角度的余弦值：\n$\\cos(\\theta) = \\frac{\\langle v_{\\mathrm{LARS}}, v_{\\mathrm{FS}} \\rangle}{\\|v_{\\mathrm{LARS}}\\|_{2} \\|v_{\\mathrm{FS}}\\|_{2}} = \\frac{\\frac{5}{14}}{\\left(\\frac{\\sqrt{33}}{7\\sqrt{2}}\\right) \\left(\\frac{1}{\\sqrt{2}}\\right)} = \\frac{\\frac{5}{14}}{\\frac{\\sqrt{33}}{7 \\times 2}} = \\frac{\\frac{5}{14}}{\\frac{\\sqrt{33}}{14}} = \\frac{5}{\\sqrt{33}}$。\n最后，角度 $\\theta$ 是：\n$\\theta = \\arccos\\left(\\frac{5}{\\sqrt{33}}\\right)$。", "answer": "$$\\boxed{\\arccos\\left(\\frac{5}{\\sqrt{33}}\\right)}$$", "id": "3456905"}]}