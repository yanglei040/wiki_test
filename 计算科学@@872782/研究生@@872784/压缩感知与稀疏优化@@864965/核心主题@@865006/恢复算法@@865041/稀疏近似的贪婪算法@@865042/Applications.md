## 应用与跨学科连接

在前面的章节中，我们已经深入探讨了贪婪[稀疏近似](@entry_id:755090)算法（如[正交匹配追踪](@entry_id:202036) OMP）的核心原理和理论保障。这些算法为从[欠定线性系统](@entry_id:756304)中恢复稀疏信号提供了一个计算效率高且概念清晰的框架。然而，这些基本原理的真正威力在于它们能够被扩展、调整和应用于解决众多科学与工程领域中的实际问题。

本章旨在将理论与实践相结合。我们将探索贪婪算法如何超越其基本形式，以适应具有特定结构的信号模型，并解决更复杂的、有时甚至是[非线性](@entry_id:637147)的[逆问题](@entry_id:143129)。此外，我们将揭示这些算法与统计学、机器学习等领域中经典和现代方法的深刻联系。通过展示贪婪算法在不同学科背景下的应用，我们旨在阐明其作为一种通用思想工具的强大功能和广泛适用性。我们的目标不是重复介绍核心概念，而是展示它们在实际应用中的效用、延伸和融合。

### 结构化[稀疏模型](@entry_id:755136)扩展

基础的[稀疏模型](@entry_id:755136)假设信号的非零元素可以任意[分布](@entry_id:182848)。然而，在许多实际应用中，信号的稀疏模式遵循着特定的结构。贪婪算法框架的优雅之处在于它可以被灵活地调整，以利用这些先验知识，从而在更弱的条件下实现更优的恢[复性](@entry_id:162752)能。与简单的 OMP 相比，更高级的贪婪算法，如[压缩采样匹配追踪](@entry_id:747597)（CoSaMP）和[子空间追踪](@entry_id:755617)（SP），采用了更复杂的“识别-合并-剪枝”策略，即在每轮迭代中识别多个候选原子，与现有支持集合并，然后进行剪枝以保持稀疏性，这为处理[结构化稀疏性](@entry_id:636211)提供了更强大的基础。 [@problem_id:2906065]

#### 块[稀疏性](@entry_id:136793)与组[匹配追踪](@entry_id:751721)

在某些应用中，信号的非零系数以“块”或“组”的形式出现。例如，在脑磁图（MEG）或脑电图（EEG）的[源定位](@entry_id:755075)问题中，神经活动通常涉及大脑皮层上的一个区域，而不是单个孤立的点。此时，表示信号的系数向量会表现出块稀疏性，即非零值集中在预定义的几个组内。为了利用这种结构，[正交匹配追踪](@entry_id:202036)（OMP）可以被推广为组[正交匹配追踪](@entry_id:202036)（Group-OMP）。Group-OMP 的核心思想是在每次迭代中选择一个原子的“组”，而不是单个原子。其选择标准是找到与当前[残差相关](@entry_id:754268)性最大的组。这种相关性通常通过计算残差与组内所有原子[内积](@entry_id:158127)所构成的向量的欧几里得范数（$L_2$ 范数）来衡量。具体来说，在第 $t$ 次迭代，算法会选择能最大化 $\|A_{G_j}^\top r^{(t-1)}\|_2$ 的组索引 $j^{(t)}$。选定组后，整个组的索引被加入到支持集中，然后通过[最小二乘法](@entry_id:137100)在更新后的支持集上重新计算系数，最后更新残差。这种方法确保了所选的原子来自于共同的结构块，从而有效融入了信号的先验知识。 [@problem_id:3449212]

#### [联合稀疏性](@entry_id:750955)与[多测量向量](@entry_id:752318)模型

另一个重要的结构化[稀疏模型](@entry_id:755136)是[多测量向量](@entry_id:752318)（MMV）模型，它出现在需要从共享相同稀疏支撑的多个测量中恢复一组信号的场景中。这种情况在[阵列信号处理](@entry_id:197159)、MIMO 通信信道估计以及某些生物医学成像应用中非常普遍。MMV 问题的数学形式为 $Y = AX + E$，其中 $Y \in \mathbb{R}^{m \times L}$ 是测量矩阵（每列是一个测量向量），$X \in \mathbb{R}^{n \times L}$ 是未知的[系数矩阵](@entry_id:151473)。[联合稀疏性](@entry_id:750955)的核心假设是 $X$ 的所有列向量（代表不同任务的信号）共享一个共同的支撑集，这意味着 $X$ 只有少数几行是非零的。

为了解决 MMV 问题，同步[正交匹配追踪](@entry_id:202036)（SOMP）算法应运而生。SOMP 是 OMP 的直接推广，其关键在于选择原子的步骤。在每次迭代中，SOMP 不再是只看单个[残差向量](@entry_id:165091)，而是汇总所有 $L$ 个任务的残差与候选原子的相关性。一种鲁棒的聚合方式是计算每个原子与所有 $L$ 个残差列向量[内积](@entry_id:158127)的[绝对值](@entry_id:147688)之和，即 $\sum_{\ell=1}^L |\langle r_\ell^t, a_j \rangle|$。通过最大化这个[聚合度](@entry_id:160520)量，SOMP 能够选出在所有任务中最具解释力的原子。一旦选定原子，后续的支持集更新和正交投影步骤与 OMP 类似，但操作对象是整个数据矩阵 $Y$。这种同步处理的方式利用了任务间的内在关联，显著提高了恢复的准确性和对噪声的鲁棒性。 [@problem_id:3449249]

#### [树结构稀疏性](@entry_id:756156)

在许多应用中，稀疏模式还表现出层次结构，这可以用树来建模。例如，在图像的小波表示中，[小波系数](@entry_id:756640)的能量倾向于从粗尺度传递到细尺度，形成一棵“能量树”：如果一个父系数很小，其子系数也很可能很小。类似地，在[基因调控网络](@entry_id:150976)或分层[特征选择](@entry_id:177971)中，也存在这种祖先-后代依赖关系。为了利用这种先验，我们可以定义一个树结构模型，其中有效的支撑集必须在树结构下是“闭合”的，即如果一个节点被选中，它的所有祖先节点也必须被选中。

像 CoSaMP 这样的高级贪婪算法可以被巧妙地修改，以强制执行这种树结构约束。这种修改被称为模型-CoSaMP（Model-CoSaMP）。其核心是将标准 CoSaMP 中基于硬阈值的原子识别和剪枝步骤，替换为基于树模型的精确[投影算子](@entry_id:154142) $\mathcal{P}_{\mathcal{T},k}$。这个算子能够找到与给定向量最接近的、支撑集符合树结构模型且稀疏度为 $k$ 的向量。通过在识别和剪枝阶段都使用这种模型投影，算法的每一步都与先验模型保持一致。这种适应性改造的理论优势在于，它可以在更弱的“模型[限制等距性质](@entry_id:184548)”（Model-RIP）条件下保证实例最优的恢复效果，即恢复误差可以被信号本身的“模型不可近似部分”和噪声水平所控制。这展示了贪婪算法框架的高度灵活性，能够通过替换其核心组件来适应复杂的信号模型。 [@problem_id:3449219]

### 从综合到分析：扩展[稀疏性](@entry_id:136793)[范式](@entry_id:161181)

到目前为止，我们讨论的都是“综合”[稀疏模型](@entry_id:755136)，其形式为 $y = Ax$，其中信号 $y$ 由字典 $A$ 中的少数几个原子线性“合成”。然而，另一个强大且互补的框架是“分析”[稀疏模型](@entry_id:755136)。

#### 分析模型与[分段常数信号](@entry_id:753442)

在分析模型中，我们不假设信号本身可以由少数原子合成，而是假设当通过某个[分析算子](@entry_id:746429) $\Omega$ 作用于信号时，其结果是稀疏的，即 $\|\Omega y\|_0 \le s$。一个经典且重要的例子是当 $\Omega$ 为[一阶差分](@entry_id:275675)算子时，即 $(\Omega y)_i = y_{i+1} - y_i$。此时，$\Omega y$ 的[稀疏性](@entry_id:136793)意味着 $y$ 中只有少数相邻元素之间存在差异，这恰好是对[分段常数信号](@entry_id:753442)的精确数学描述。

这两个模型并非等价。例如，一个常数向量 $y = [1, 1, \dots, 1]^\top$ 在差分算子 $D$ 下是分析 $0$-稀疏的（因为 $Dy=0$），但它本身是完全稠密的，在标准基（即 $A=I$）下是综合 $m$-稀疏的。对于这类信号，分析模型显然更具描述力。像 OMP 这样的综合贪婪方法在这种情况下会完全失效，因为它需要 $m$ 步才能恢复信号。相反，专为分析模型设计的贪婪算法则能有效利用这种结构。这种区别凸显了为特定信号类别选择正确[稀疏性](@entry_id:136793)先验的重要性，并推动了算法的相应发展。 [@problem_id:3449202]

#### 分析模型的贪婪算法

分析模型的贪婪恢复思想与综合模型略有不同。综合贪婪算法（如 OMP）旨在逐步“构建”信号的支撑集，而分析贪婪算法则旨在逐步“识别”分析系数为零的位置，即“余支撑集”（co-support）。一个为分析模型设计的贪婪算法，可以称为“贪婪余支撑集追踪”（Greedy Co-support Pursuit, GCoP）。该算法在每次迭代中，不是寻找与残差最“相关”的原子，而是寻找能使分析系数最接近于零的约束。

在有测量矩阵 $\Phi$ 的情况下，即 $y = \Phi x_0$ 且 $\Omega x_0$ 稀疏，GCoP 的一个策略是选择使得 $| \langle \tilde{b}_j, y \rangle |$ 最小的索引 $j$，其中 $\tilde{b}_j$ 是“压缩分析原子”。通过理论推导可以证明，这类算法的成功恢复同样取决于一个类似[互相关](@entry_id:143353)的性质，但这次是针对压缩分析原子。在某些理想条件下，可以推导出保证 GCoP 成功恢复余支撑集的充分条件。例如，在特定假设下，只要压缩分析原子的互相关 $\mu_B$ 小于某个阈值，如 $\frac{1}{2(p-\ell)-1}$（其中 $p$ 是分析原子的总数，$\ell$ 是余稀疏度），算法就能成功。这表明，贪婪选择的思想原则可以被成功地移植到分析稀疏框架中，进一步扩展了其应用范围。 [@problem_id:3449258]

### 在信号与[图像处理](@entry_id:276975)中的应用

贪婪[稀疏近似](@entry_id:755090)算法在现代信号与图像处理的多个前沿领域中扮演着核心角色，尤其是在解决具有挑战性的[非线性](@entry_id:637147)和双[线性[逆问](@entry_id:751313)题](@entry_id:143129)时。

#### 相位恢复

在许多物理成像技术中，如[X射线晶体学](@entry_id:153528)、天文学和光学显微镜，探测器只能记录光的强度（幅值），而丢失了相位信息。这个问题被称为相位恢复，其数学模型为 $y_i = |\langle \phi_i, x \rangle|$，是一个高度[非线性](@entry_id:637147)的逆问题。由于问题的非凸性，找到[全局最优解](@entry_id:175747)非常困难。贪婪算法的思想可以被用来设计一个有效的“初始化”阶段，以获得对真实信号支撑集的良好估计。通过将问题“提升”到一个更高维度的空间，可以构造一个与原始测量平方相关的统计量，例如 $Z_j = \frac{1}{m} \sum_{i=1}^m y_i^2 \phi_{ij}^2$。可以证明，在随机高斯测量模型下，这个统计量的[期望值](@entry_id:153208)在真实支撑集内的索引上会显著高于支撑集外的索引。因此，通过选择具有最大 $Z_j$ 值的 $s$ 个索引，就可以高概率地恢复出真实的支撑集。这个贪婪的初始化步骤极大地简化了后续的恢复过程，为解决这个困难的[非线性](@entry_id:637147)问题提供了一个强大的切入点。 [@problem_id:3449209]

#### [盲解卷积](@entry_id:265344)

[盲解卷积](@entry_id:265344)是另一个经典的挑战，其中观测信号 $y$ 是一个未知信号 $x$ 与一个未知模糊核 $h$ 的卷积，即 $y = h * x$。这是一个双[线性[逆问](@entry_id:751313)题](@entry_id:143129)，因为观测值同时依赖于两个未知量。如果可以假设信号 $x$ 在某个字典 $\Phi$ 下是稀疏的，并且模糊核 $h$ 本身也是稀疏的（例如，只有一个小的支撑集），我们就可以设计一种交替贪婪的求解策略。这个过程可以分解为两个交替执行的[稀疏恢复](@entry_id:199430)子问题：
1.  固定当前的模糊核估计 $\hat{h}$，将问题视为 $y = C(\hat{h}) \Phi \alpha$，然后使用 OMP 来估计稀疏码 $\alpha$（从而得到 $\hat{x}$）。
2.  固定当前的信号估计 $\hat{x}$，将问题视为 $y = T(\hat{x}) h$，其中 $T(\hat{x})$ 是一个由 $\hat{x}$ 构造的卷积矩阵，然后使用贪婪算法来估计稀疏的模糊核 $h$。

通过在这两个步骤之间交替迭代，算法可以逐步逼近真实的信号和模糊核。该方法的成功依赖于两个子问题的字典（即 $C(\hat{h})\Phi$ 和 $T(\hat{x})$）都具有良好的性质，例如足够低的[互相关性](@entry_id:188177)。理论分析表明，为了唯一地识别稀疏度为 $k$ 的信号和支撑尺寸为 $s$ 的模糊核，两个子问题字典的[互相关性](@entry_id:188177) $\mu$ 必须满足 $\mu  \min(\frac{1}{2k-1}, \frac{1}{2s-1})$。这个例子展示了如何将贪婪算法作为模块，嵌入到更复杂的迭代框架中，以解决更具挑战性的问题。 [@problem_id:3449227]

#### 对复值数据的适应

在雷达、[无线通信](@entry_id:266253)、核[磁共振成像](@entry_id:153995)（MRI）等领域，信号和系统本质上是复值的。标准的贪婪算法需要被推广到复数[希尔伯特空间](@entry_id:261193)才能应用于这些场景。这种推广是直接的，但需要注意将所有的实数[内积](@entry_id:158127)替换为厄米特[内积](@entry_id:158127) $\langle u, v \rangle = u^H v$，其中 $H$ 表示共轭转置。因此，原子选择步骤变为最大化 $|a_j^H r|$，而[正交投影](@entry_id:144168)步骤则涉及求解复数[最小二乘问题](@entry_id:164198)。

这种[复数域](@entry_id:153768)的推广能够自然地处理相位信息。一个关键特性是，算法的支撑集恢[复性](@entry_id:162752)能对于字典原子上的任意相位旋转是不变的。这是因为选择标准 $|a_j^H r|$ 的大小不受 $a_j$ 的一个单位模长复数因子影响。此外，对于具有[共轭对称](@entry_id:144131)谱的实值信号（在[傅里叶变换](@entry_id:142120)下），复数 OMP 能够准确地恢复这种对称性，并重建出一个几乎纯实值的信号，其虚部仅受限于[机器精度](@entry_id:756332)。这种对复数数据和相位的稳健处理，使得贪婪算法在电磁学和医学成像等领域的实际应用中至关重要。 [@problem_id:3387251]

### 跨学科桥梁：连接统计学与机器学习

贪婪[稀疏近似](@entry_id:755090)算法并非孤立存在，它们与统计学和机器学习中的许多核心思想有着深刻的联系。理解这些联系有助于我们更全面地认识这些工具的本质及其在更广阔知识体系中的位置。

#### 与[经典统计学](@entry_id:150683)的联系：[前向逐步回归](@entry_id:749533)

贪婪算法与统计学中的一个经典[模型选择](@entry_id:155601)方法——[前向逐步回归](@entry_id:749533)（Forward Stepwise Regression, FSR）——有着惊人的相似性。FSR 也是一种迭代过程，在每一步中，它将能最大程度减小[残差平方和](@entry_id:174395)（RSS）的那个预测变量加入到模型中。可以证明，FSR 的选择标[准等价](@entry_id:149815)于最大化 $\frac{|x_j^\top r_t|^2}{\|(I - P_{S_t})x_j\|_2^2}$，其中分母是对候选变量 $x_j$ 进行残差化（即去除已选变量的影响）后的范数。

这与 OMP 的标准 $|x_j^\top r_t|$ 形成了鲜明对比。在特定理想条件下，例如，当[设计矩阵](@entry_id:165826) $X$ 的列经过[标准化](@entry_id:637219)且具有等相关结构时，可以证明 FSR 的分母项对于所有候选变量是相同的，此时 FSR 和 OMP 的[选择规则](@entry_id:140784)完全等价，并且两者都能精确恢复支撑集。然而，当数据未经标准化，即各列[方差](@entry_id:200758)不同时，两者的行为就会出现分歧。FSR 的归一化步骤使其对列[方差](@entry_id:200758)的异质性不那么敏感，而 OMP 则倾向于选择[方差](@entry_id:200758)更大的列。这揭示了一个深刻的联系：OMP 可以被看作是 FSR 在特定情况下的一个变体，而它们在面对非理想数据时的不同表现，则反映了信号处理与统计学在处理数据尺度问题上的不同侧重。 [@problem_id:3449194]

#### 贝叶斯视角与[正则化方法](@entry_id:150559)的关联

贪婪算法的选择规则也可以从贝叶斯推断的视角来理解。假设我们为信号系数 $x_i$ 赋予一个[稀疏性](@entry_id:136793)诱导先验，例如[拉普拉斯分布](@entry_id:266437) $p(x_i) \propto \exp(-\lambda |x_i|)$，并结合[高斯噪声](@entry_id:260752)[似然](@entry_id:167119)模型。然后，我们可以设计一个贪婪选择规则，即在每一步选择能使对数后验概率增加最多的那个原子。通过推导可以发现，这个“贝叶斯贪婪分数” $\Delta_j$ 与原子和残差的经验相关性 $g_j = a_j^\top r$ 之间存在一个非线性关系。

具体来说，$\Delta_j = \frac{1}{2\sigma^2}(\max(0, |g_j| - \lambda\sigma^2))^2$。这个结果非常富有启发性。首先，一个原子只有在它的相关性大小 $|g_j|$ 超过一个阈值 $\lambda\sigma^2$ 时，才有可能被选中（因为只有此时 $\Delta_j$ 才大于零）。其次，在满足此阈值的原子中，算法会选择相关性 $|g_j|$ 最大的那个。这个过程将 OMP 的纯粹相关性最大化与一个阈值步骤结合了起来。这个阈值恰好是单系数 MAP 估计（即[软阈值](@entry_id:635249)）中的“[死亡区](@entry_id:183758)域”边界。这巧妙地将贪婪算法（如 OMP）与基于 $L_1$ 正则化的方法（如 LASSO 或 ISTA）联系在一起，展示了它们都可以被视为在不同策略下求解同一个潜在的、由[稀疏先验](@entry_id:755119)驱动的[优化问题](@entry_id:266749)。 [@problem_id:3449243]

#### 去偏（Debiasing）的重要性：估计与正则化

贪婪算法（如 OMP）的主要任务是识别正确的稀疏支撑集。然而，一旦支撑集被确定，算法输出的[系数估计](@entry_id:175952)本身可能是有偏的。在信号处理和统计学中，一个完整的恢复流程通常包含两个步骤：[模型选择](@entry_id:155601)（[支撑集识别](@entry_id:755668)）和参数估计（系数计算）。OMP 中的最小二乘投影步骤就是一个“去偏”过程。但在存在噪声且字典子[矩阵条件数](@entry_id:142689)较差（即选出的原子之间存在较强相关性）的情况下，标准的[最小二乘估计](@entry_id:262764)会导致巨大的[方差](@entry_id:200758)，从而严重影响恢复精度。

这时，可以引入正则化思想来改进[系数估计](@entry_id:175952)。例如，可以使用吉洪诺夫（Tikhonov）正则化（或称为岭回归）来代替标准最小二乘，即求解 $\hat{x}_S^\lambda = (\Phi_S^\top\Phi_S + \lambda I)^{-1}\Phi_S^\top y$。这里的正则化参数 $\lambda$ 在[偏差和方差](@entry_id:170697)之间进行权衡。从贝叶斯角度看，如果假设信号系数和噪声都服从高斯分布（信号[方差](@entry_id:200758)为 $\tau^2$，噪声[方差](@entry_id:200758)为 $\sigma^2$），那么可以推导出最优的正则化参数恰好是噪声[方差](@entry_id:200758)与信号[方差](@entry_id:200758)之比，即 $\lambda_{\text{opt}} = \frac{\sigma^2}{\tau^2}$。这个结果不仅为[正则化参数](@entry_id:162917)的选择提供了理论依据，也深刻地揭示了[稀疏恢复](@entry_id:199430)作为一个完整的[统计估计](@entry_id:270031)问题，需要同时考虑[支撑集识别](@entry_id:755668)和[系数估计](@entry_id:175952)的鲁棒性。 [@problem_id:3449207]

### 真实世界的工程考量

将算法从理论模型转化为可靠的工程应用，需要考虑各种现实世界的限制，如硬件精度和传感策略。

#### 对测量量化的鲁棒性

在实际的数字系统中，[模拟信号](@entry_id:200722)在被处理前必须通过[模数转换器](@entry_id:271548)（[ADC](@entry_id:186514)）进行量化。这个过程会引入量化误差，它是一种[非线性](@entry_id:637147)的、有界的噪声源。贪婪算法的性能不可避免地会受到这种误差的影响。以 OMP 为例，其原子选择步骤依赖于计算[内积](@entry_id:158127) $a_j^\top r^{(0)}$，其中残差 $r^{(0)}$ 现在是量化后的测量值 $y_q$。[量化误差](@entry_id:196306) $e_q = y_q - y$ 会直接污染相关性计算。

通过分析可以建立一个保证 OMP 在第一步成功选对原子的充分条件，这个条件将量化误差的贡献显式地分离出来。基于这个条件，可以反解出成功恢复所需的最小量化比特数 $b$。这个比特数依赖于字典的性质、信号的动态范围以及噪声水平等因素。一个典型的结果形式为 $b \ge \log_2(\frac{C}{c_{\min} - \text{interference}})$，其中 $C$ 包含了与量化器动态范围相关的因子。此外，为了减轻[量化误差](@entry_id:196306)带来的系统性偏差，可以在量化前向残差中注入一个零均值的随机信号，即“[抖动](@entry_id:200248)”（dithering）。这种技术可以将量化误差近似地白化，使其与字典原子的相关性降低，从而提高算法的鲁棒性。这为在资源受限的硬件上设计[稀疏恢复](@entry_id:199430)系统提供了重要的指导。 [@problem_id:3449268]

#### 主动测量设计

传统的[压缩感知](@entry_id:197903)框架通常假设测量矩阵 $\Phi$ 是预先设计好的（例如，随机矩阵）。然而，在某些应用中，我们有机会自适应地、序贯地设计测量过程。例如，我们可以一次选择一个测量向量（$\Phi$ 的一行），以期获得关于未知稀疏信号最丰富的信息。这种“主动传感”的思想可以与贪婪算法相结合。

考虑一个简单的场景，我们要区分真实原子 $a_1$ 和竞争原子 $a_2$。我们可以设计下一个测量向量 $\phi$，使其能够最大化地区分这两个假设。一个有效的“短视”标准是最大化由这两个原子产生的信号在 $\phi$ 上投影能量的期望差异，即最大化 $J(\phi) = \mathbb{E}_\alpha[(\alpha(\phi^\top a_1))^2 - (\alpha(\phi^\top a_2))^2]$。在某些假设下，可以解析地找到最优的测量向量 $\phi^\star$。这个 $\phi^\star$ 通常位于 $a_1$ 和 $a_2$ 张成的二维[子空间](@entry_id:150286)中，并且其方向与它们的差向量和和向量相关。与在该[子空间](@entry_id:150286)中随机选择一个测量方向相比，这个最优设计可以显著提高区分能力。这个例子虽然简单，但它开启了将贪婪思想从“[信号恢复](@entry_id:195705)”推广到“实验设计”的可能性，这在自适应雷达成像、网络[断层扫描](@entry_id:756051)和高效医学成像等领域具有巨大的潜力。 [@problem_id:3449225]

### 结论

本章通过一系列应用实例和理论延伸，展示了贪婪[稀疏近似](@entry_id:755090)算法远超其作为基础 OMP 算法的初始范畴。我们看到，这是一个充满活力和高度灵活的框架，能够：
- 通过Group-OMP、SOMP和Model-CoSaMP等变体，有效地融入块稀疏、联合稀疏和树稀疏等复杂的信号结构。
- 从“综合”模型扩展到“分析”模型，为处理如[分段常数信号](@entry_id:753442)等更广泛的信号类别提供了工具。
- 作为核心模块，被用于解决相位恢复和[盲解卷积](@entry_id:265344)等具有挑战性的[非线性](@entry_id:637147)和双[线性[逆问](@entry_id:751313)题](@entry_id:143129)，并能自然地推广到处理雷达和MRI中的复值数据。
- 与统计学中的[前向逐步回归](@entry_id:749533)、贝叶斯推断和正则化理论建立深刻联系，揭示了其作为一种通用[模型选择](@entry_id:155601)和估计算法的本质。
- 考虑现实世界的工程约束，如测量量化，并激发了主动传感等新的[数据采集](@entry_id:273490)[范式](@entry_id:161181)。

总而言之，贪婪算法不仅是[稀疏恢复](@entry_id:199430)工具箱中的一个重要组成部分，更是一种强大而富有启发性的思想，它连接了理论与实践，并持续在众多学科交叉领域中推动着创新。