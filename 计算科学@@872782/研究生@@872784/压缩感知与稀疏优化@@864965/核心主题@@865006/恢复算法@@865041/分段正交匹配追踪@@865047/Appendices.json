{"hands_on_practices": [{"introduction": "我们将从一个具体的数值示例开始，逐步引导你完成一个完整的StOMP阶段。这项练习旨在巩固你对核心步骤的理解：如何计算相关性、如何应用阈值来批量选择原子，以及如何通过最小二乘法更新信号估计。[@problem_id:3481077]", "problem": "考虑线性测量模型 $y = A x^{\\star} + w$，其中包含加性高斯白噪声 $w \\sim \\mathcal{N}(0, \\sigma^{2} I)$。假设我们应用分阶段正交匹配追踪 (Stagewise Orthogonal Matching Pursuit, StOMP) 算法的第一阶段。设传感矩阵 $A \\in \\mathbb{R}^{4 \\times 4}$ 具有单位范数列，由归一化的哈达玛系统 (normalized Hadamard system) 给出\n$$\nA \\;=\\; \\frac{1}{2}\\begin{bmatrix}\n1  & 1  & 1  & 1\\\\\n1  & 1  & -1 & -1\\\\\n1  & -1 & 1  & -1\\\\\n1  & -1 & -1 & 1\n\\end{bmatrix}.\n$$\n设观测数据为\n$$\ny \\;=\\; \\begin{bmatrix} 2 \\\\ 0 \\\\ 0.5 \\\\ -1 \\end{bmatrix},\n$$\n噪声标准差为 $\\sigma = 0.2$。在初始阶段，StOMP 使用残差 $r^{(0)} = y$，相关向量 $c^{(0)} = A^{\\top} r^{(0)}$，一个通用高斯阈值\n$$\n\\tau_0 \\;=\\; \\sigma \\sqrt{2 \\ln n},\n$$\n其中 $n$ 是 $A$ 的列数，并选择索引集\n$$\nJ_0 \\;=\\; \\{\\, j \\in \\{1,\\dots,n\\} \\;\\colon\\; |c^{(0)}_j| > \\tau_0 \\,\\}.\n$$\n然后，它在支撑集 $S_0 = J_0$ 上执行最小二乘更新，以获得 $x^{(1)}_{S_0} = \\arg\\min_{x \\in \\mathbb{R}^{|S_0|}} \\|\\, y - A_{S_0} x \\,\\|_{2}^{2}$（在 $S_0$ 之外的分量为零），接着计算新的残差 $r^{(1)} = y - A_{S_0} x^{(1)}_{S_0}$。\n\n从这些定义和每个条目具有方差 $\\sigma^{2}$ 的高斯噪声假设出发，明确计算：\n- $c^{(0)}$，\n- $\\tau_0$，\n- $J_0$，\n- 在 $S_0$ 上的最小二乘估计，\n- 和新的残差 $r^{(1)}$。\n\n最后，报告单个标量值 $\\| r^{(1)} \\|_{2}^{2}$。请以精确实数（无四舍五入）的形式提供您的答案。", "solution": "该问题要求计算分阶段正交匹配追踪 (StOMP) 算法第一阶段后残差的 $L_2$ 范数的平方。我们将按照问题描述中定义的步骤计算中间量。\n\n给定的线性模型是 $y = A x^{\\star} + w$，传感矩阵为 $A \\in \\mathbb{R}^{4 \\times 4}$，观测数据为 $y$，噪声标准差为 $\\sigma$。\n$$\nA = \\frac{1}{2}\\begin{bmatrix}\n1  & 1  & 1  & 1\\\\\n1  & 1  & -1 & -1\\\\\n1  & -1 & 1  & -1\\\\\n1  & -1 & -1 & 1\n\\end{bmatrix}, \\quad y = \\begin{bmatrix} 2 \\\\ 0 \\\\ 0.5 \\\\ -1 \\end{bmatrix}, \\quad \\sigma = 0.2\n$$\n$A$ 的列数为 $n=4$。矩阵 $A$ 是一个缩放的哈达玛矩阵。我们可以验证它是对称的，$A^{\\top} = A$，并且其列是标准正交的，即 $A^{\\top}A = I$。这使得 $A$ 成为一个正交矩阵。\n\n- **步骤 1：计算初始相关向量 $c^{(0)}$**\n初始残差为 $r^{(0)} = y$。相关向量为 $c^{(0)} = A^{\\top} r^{(0)} = A^{\\top} y$。由于 $A$ 是对称的，所以 $c^{(0)} = A y$。\n$$\nc^{(0)} = \\frac{1}{2}\\begin{bmatrix}\n1  & 1  & 1  & 1\\\\\n1  & 1  & -1 & -1\\\\\n1  & -1 & 1  & -1\\\\\n1  & -1 & -1 & 1\n\\end{bmatrix}\n\\begin{bmatrix} 2 \\\\ 0 \\\\ 0.5 \\\\ -1 \\end{bmatrix}\n= \\frac{1}{2}\\begin{bmatrix}\n1(2) + 1(0) + 1(0.5) + 1(-1) \\\\\n1(2) + 1(0) - 1(0.5) - 1(-1) \\\\\n1(2) - 1(0) + 1(0.5) - 1(-1) \\\\\n1(2) - 1(0) - 1(0.5) + 1(-1)\n\\end{bmatrix}\n= \\frac{1}{2}\\begin{bmatrix}\n1.5 \\\\\n2.5 \\\\\n3.5 \\\\\n0.5\n\\end{bmatrix}\n= \\begin{bmatrix}\n0.75 \\\\\n1.25 \\\\\n1.75 \\\\\n0.25\n\\end{bmatrix}\n$$\n以分数形式表示，这是精确的，$c^{(0)} = \\begin{bmatrix} 3/4 \\\\ 5/4 \\\\ 7/4 \\\\ 1/4 \\end{bmatrix}$。\n\n- **步骤 2：计算阈值 $\\tau_0$**\n阈值定义为 $\\tau_0 = \\sigma \\sqrt{2 \\ln n}$。已知 $\\sigma = 0.2$ 且 $n=4$，我们有：\n$$\n\\tau_0 = 0.2 \\sqrt{2 \\ln 4} = 0.2 \\sqrt{2 \\ln(2^2)} = 0.2 \\sqrt{4 \\ln 2} = 0.4 \\sqrt{\\ln 2}\n$$\n\n- **步骤 3：确定索引集 $J_0$**\n索引集 $J_0$ 包含满足 $|c^{(0)}_j| > \\tau_0$ 的索引 $j$。我们将相关向量各分量幅值的平方 $|c^{(0)}_j|^2$ 与 $\\tau_0^2 = (0.4)^2 \\ln 2 = 0.16 \\ln 2$ 进行比较。\n使用近似值 $\\ln 2 \\approx 0.6931$，$\\tau_0^2 \\approx 0.16 \\times 0.6931 \\approx 0.1109$。\n相关向量幅值的平方为：\n$|c^{(0)}_1|^2 = (0.75)^2 = 0.5625$\n$|c^{(0)}_2|^2 = (1.25)^2 = 1.5625$\n$|c^{(0)}_3|^2 = (1.75)^2 = 3.0625$\n$|c^{(0)}_4|^2 = (0.25)^2 = 0.0625$\n\n将这些值与 $\\tau_0^2 \\approx 0.1109$ 进行比较：\n$|c^{(0)}_1|^2 > \\tau_0^2$\n$|c^{(0)}_2|^2 > \\tau_0^2$\n$|c^{(0)}_3|^2 > \\tau_0^2$\n$|c^{(0)}_4|^2 < \\tau_0^2$\n因此，选定的索引集为 $J_0 = \\{1, 2, 3\\}$。第一次迭代的支撑集为 $S_0 = J_0 = \\{1, 2, 3\\}$。\n\n- **步骤 4：计算最小二乘估计 $x^{(1)}_{S_0}$ 和新的残差 $r^{(1)}$**\n支撑集 $S_0$ 上的最小二乘估计由 $x^{(1)}_{S_0} = \\arg\\min_{x} \\| y - A_{S_0} x \\|_{2}^{2}$ 给出，其中 $A_{S_0}$ 是由 $A$ 的第 $\\{1, 2, 3\\}$ 列组成的矩阵。解由正规方程给出：$x^{(1)}_{S_0} = (A_{S_0}^{\\top} A_{S_0})^{-1} A_{S_0}^{\\top} y$。\n如前所述，$A$ 的列是标准正交的。设 $a_j$ 表示 $A$ 的第 $j$ 列。那么 $a_i^{\\top} a_j = \\delta_{ij}$（克罗内克 δ）。\n对于 $S_0 = \\{1, 2, 3\\}$，子矩阵为 $A_{S_0} = [a_1, a_2, a_3]$。格拉姆矩阵是 $A_{S_0}^{\\top} A_{S_0} = I_3$，即 $3 \\times 3$ 的单位矩阵。\n最小二乘解简化为 $x^{(1)}_{S_0} = A_{S_0}^{\\top} y$。该向量的分量为 $(A_{S_0}^{\\top} y)_i = a_i^{\\top} y = c_i^{(0)}$，其中 $i \\in S_0$。\n所以，$x^{(1)}_{S_0} = \\begin{bmatrix} c_1^{(0)} \\\\ c_2^{(0)} \\\\ c_3^{(0)} \\end{bmatrix} = \\begin{bmatrix} 0.75 \\\\ 1.25 \\\\ 1.75 \\end{bmatrix}$。\n\n新的残差为 $r^{(1)} = y - A_{S_0} x^{(1)}_{S_0}$。项 $A_{S_0} x^{(1)}_{S_0} = A_{S_0} A_{S_0}^{\\top} y$ 是 $y$ 在由 $A_{S_0}$ 中各列（即 $\\mathrm{span}\\{a_1, a_2, a_3\\}$）张成的子空间上的正交投影。\n因此，残差 $r^{(1)}$ 是 $y$ 在该子空间的正交补上的投影。由于 $\\{a_1, a_2, a_3, a_4\\}$ 构成 $\\mathbb{R}^4$ 的一个标准正交基，该正交补由向量 $a_4$ 张成。\n$y$ 在由 $a_4$ 张成的子空间上的投影由下式给出：\n$$ r^{(1)} = (a_4^{\\top} y) a_4 $$\n项 $a_4^{\\top} y$ 正是相关向量的第四个分量 $c_4^{(0)}$。\n根据步骤 1，$c_4^{(0)} = 0.25 = \\frac{1}{4}$。\n所以，$r^{(1)} = c_4^{(0)} a_4 = \\frac{1}{4} a_4$。\n\n- **步骤 5：计算最终量 $\\| r^{(1)} \\|_{2}^{2}$**\n我们需要计算残差 $r^{(1)}$ 的 $L_2$ 范数的平方。\n$$\n\\|r^{(1)}\\|_2^2 = \\left\\| \\frac{1}{4} a_4 \\right\\|_2^2 = \\left(\\frac{1}{4}\\right)^2 \\|a_4\\|_2^2\n$$\n由于 $A$ 的列根据构造是单位范数的（如问题中所述并已验证），我们有 $\\|a_4\\|_2^2 = 1$。\n因此，残差的范数平方简化为：\n$$\n\\|r^{(1)}\\|_2^2 = \\left(\\frac{1}{4}\\right)^2 \\times 1 = \\frac{1}{16}\n$$\n最终答案是一个精确的实数。\n以分数形式为 $\\frac{1}{16}$，或以小数形式为 $0.0625$。我们将提供分数形式。", "answer": "$$\n\\boxed{\\frac{1}{16}}\n$$", "id": "3481077"}, {"introduction": "StOMP的标志性特征是其批量选择原子的策略。本练习将通过与每次迭代只选择一个原子的正交匹配追踪（OMP）算法进行性能对比，来探讨这一策略的深层影响。通过分析一个包含高度相干字典原子的场景，你将深入了解StOMP的方法为何有时能加速恢复过程，同时又面临着哪些独特的挑战。[@problem_id:3481088]", "problem": "考虑一个感知矩阵（字典），其维度为 $m=3$ 和 $n=4$，其单位范数列向量 $\\{a_j\\}_{j=1}^4 \\subset \\mathbb{R}^3$ 具体由下式给出：\n$$\na_1=\\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix},\\quad\na_2=\\begin{bmatrix}0.9\\\\ \\sqrt{1-0.9^2}\\\\ 0\\end{bmatrix},\\quad\na_3=\\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix},\\quad\na_4=\\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix}.\n$$\n设未知信号为 $x^\\star\\in\\mathbb{R}^4$，其 $k$-稀疏支撑集为 $\\operatorname{supp}(x^\\star)=\\{1,3\\}$，值为 $x^\\star_1=1$，$x^\\star_3=1$，以及 $x^\\star_2=x^\\star_4=0$。无噪声测量值为 $y=Ax^\\star=a_1+a_3=\\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$。\n\n比较两种贪心方法：\n\n- 正交匹配追踪 (OMP)：在每次迭代 $t$ 中，计算残差 $r^{(t)}=y-A_{S^{(t)}}\\hat{c}^{(t)}$，其中 $S^{(t)}$ 是经过 $t$ 次迭代后选定的支撑集，$\\hat{c}^{(t)}$ 是在 $S^{(t)}$ 上的最小二乘解；然后选择新索引 $j^{(t+1)}\\in\\arg\\max_j |\\langle a_j,r^{(t)}\\rangle|$，扩充支撑集 $S^{(t+1)}=S^{(t)}\\cup\\{j^{(t+1)}\\}$，在 $S^{(t+1)}$ 上通过最小二乘法重新拟合，并重复此过程。假设在 $\\arg\\max$ 中出现平局时，选择最小的索引。\n\n- 分阶段正交匹配追踪 (StOMP)：在第 $1$ 阶段，计算所有 $j$ 的相关性 $c_j=\\langle a_j,y\\rangle$，并使用固定的阈值因子 $\\alpha=0.85$ 选择批次 $S=\\{j:\\,|c_j|\\ge \\alpha \\max_k |c_k|\\}$。然后在 $S$ 上执行单次最小二乘再拟合以获得系数 $\\hat{c}_S$，设置残差 $r=y-A_S\\hat{c}_S$，如果 $r=0$ 则终止。\n\n从这些定义以及内积和正交投影的线性代数性质出发，分析这两种方法在给定的 $A$ 和 $y$ 上的第一阶段/次迭代。下列哪个/哪些陈述是正确的？\n\nA. StOMP 的第一阶段选择 $S=\\{1,2,3\\}$，因为 $|a_1^\\top y|=|a_3^\\top y|=1$ 且 $|a_2^\\top y|=0.9\\ge 0.85\\cdot 1$，其在 $S$ 上的最小二乘再拟合返回的系数为 $\\hat{c}_2=0$，从而在一个阶段内精确恢复了真实的支撑集 $\\{1,3\\}$；OMP 根据规定的平局打破规则，在第一次迭代中选择 $1$，将残差投影到 $\\operatorname{span}\\{a_1\\}$ 的正交补上得到 $r^{(1)}=a_3$，然后在下一次迭代中选择 $3$，同样实现了精确恢复。\n\nB. OMP 可能会在第一次迭代中选择 $2$，因为 $|a_2^\\top y|$ 等于 $1$，与 $|a_1^\\top y|$ 和 $|a_3^\\top y|$ 相等。\n\nC. StOMP 在批次 $S=\\{1,2,3\\}$ 上的最小二乘问题由于 $a_1$ 和 $a_2$ 之间的高相干性而是奇异的，因此 StOMP 在此阶段无法唯一地恢复系数。\n\nD. 因为 StOMP 在第一阶段包含了高相干性但虚假的原子 $a_2$，所以在无噪声设置下，其最小二乘后的残差不能为零，而 OMP 可以将残差降为零。\n\nE. 如果 OMP 通过首先选择 $3$ 来打破初始平局，那么在第二次迭代中，它必须在 $1$ 之前选择 $2$，因为 $a_2$ 与更新后的残差的相关性仍然高于 $a_1$。\n\n选择所有适用的选项。", "solution": "用户提供了一个压缩感知领域的问题，要求分析两种贪心恢复算法的第一阶段/次迭代：分阶段正交匹配追踪 (StOMP) 和正交匹配追踪 (OMP)。\n\n### 问题陈述验证\n\n首先，我将验证问题陈述。\n\n**步骤 1：提取已知条件**\n- 感知矩阵（字典）$A \\in \\mathbb{R}^{3 \\times 4}$，其中 $m=3$，$n=4$。\n- $A$ 的列向量，记作 $\\{a_j\\}_{j=1}^4$，是 $\\mathbb{R}^3$ 中的单位范数向量：\n$$a_1=\\begin{bmatrix}1\\\\0\\\\0\\end{bmatrix},\\quad a_2=\\begin{bmatrix}0.9\\\\ \\sqrt{1-0.9^2}\\\\ 0\\end{bmatrix},\\quad a_3=\\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix},\\quad a_4=\\begin{bmatrix}0\\\\1\\\\0\\end{bmatrix}.$$\n注意 $\\sqrt{1-0.9^2} = \\sqrt{1-0.81} = \\sqrt{0.19}$。\n- 未知信号为 $x^\\star\\in\\mathbb{R}^4$。\n- 信号是 $k$-稀疏的，其中 $k=2$。\n- 支撑集为 $\\operatorname{supp}(x^\\star)=\\{1,3\\}$。\n- 非零值为 $x^\\star_1=1$ 和 $x^\\star_3=1$。零值为 $x^\\star_2=x^\\star_4=0$。\n- 无噪声测量向量为 $y=Ax^\\star=a_1x^\\star_1 + a_3x^\\star_3 = a_1+a_3=\\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$。\n- OMP 算法定义：在每次迭代 $t$ 中，计算残差 $r^{(t)}=y-A_{S^{(t)}}\\hat{c}^{(t)}$，选择下一个索引 $j^{(t+1)}\\in\\arg\\max_j |\\langle a_j,r^{(t)}\\rangle|$，扩充支撑集 $S^{(t+1)}=S^{(t)}\\cup\\{j^{(t+1)}\\}$，然后重新拟合。平局通过选择最小索引来打破。\n- StOMP 算法定义：在第 1 阶段，计算相关性 $c_j=\\langle a_j,y\\rangle$，使用阈值因子 $\\alpha=0.85$ 选择批次 $S=\\{j:\\,|c_j|\\ge \\alpha \\max_k |c_k|\\}$。在 $S$ 上执行单次最小二乘再拟合。\n\n**步骤 2：使用提取的已知条件进行验证**\n- **科学依据：** 该问题是稀疏信号恢复中的一个标准、定义明确的练习，该领域是信号处理和优化的一个子领域。OMP 和 StOMP 算法是该领域的经典方法。其底层数学基于线性代数。该问题是合理的。\n- **适定性：** 提供了所有必要的数据（矩阵 $A$、信号 $x^\\star$、测量值 $y$）和算法规范（参数 $\\alpha$、平局打破规则）。问题要求直接分析算法的行为，这是一个给定输入的确定性过程。\n- **客观性：** 问题使用精确的数学语言陈述，没有任何主观或模糊的术语。\n- **完整性和一致性：** 让我们检查给定的值。列向量被声明为单位范数。\n  - $\\|a_1\\|_2 = \\sqrt{1^2+0^2+0^2}=1$。\n  - $\\|a_2\\|_2 = \\sqrt{0.9^2 + (\\sqrt{0.19})^2 + 0^2} = \\sqrt{0.81+0.19} = \\sqrt{1} = 1$。\n  - $\\|a_3\\|_2 = \\sqrt{0^2+0^2+1^2}=1$。\n  - $\\|a_4\\|_2 = \\sqrt{0^2+1^2+0^2}=1$。\n这些列向量确实是单位范数。测量向量的计算 $y = a_1+a_3 = [1,0,0]^T + [0,0,1]^T = [1,0,1]^T$ 是正确的。所有数据都是一致且定义明确的。\n\n**步骤 3：结论与行动**\n问题陈述是有效的。它具有科学合理性、适定性、客观性、完整性和内部一致性。我将继续对算法进行分析。\n\n### 推导与分析\n\n我们将根据所提供的数据分别分析 StOMP 和 OMP。\n\n**分阶段正交匹配追踪 (StOMP) 分析**\n\nStOMP 算法按阶段进行。我们分析第一阶段。\n1.  **计算相关性：** 我们计算每个字典原子 $a_j$ 与测量向量 $y=\\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$ 的内积。\n    - $c_1 = \\langle a_1, y \\rangle = a_1^T y = \\begin{bmatrix}1 & 0 & 0\\end{bmatrix} \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix} = 1$。\n    - $c_2 = \\langle a_2, y \\rangle = a_2^T y = \\begin{bmatrix}0.9 & \\sqrt{0.19} & 0\\end{bmatrix} \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix} = 0.9$。\n    - $c_3 = \\langle a_3, y \\rangle = a_3^T y = \\begin{bmatrix}0 & 0 & 1\\end{bmatrix} \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix} = 1$。\n    - $c_4 = \\langle a_4, y \\rangle = a_4^T y = \\begin{bmatrix}0 & 1 & 0\\end{bmatrix} \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix} = 0$。\n\n2.  **阈值化：** 我们识别出绝对相关性 $|c_j|$ 超过阈值的索引集合 $S$。\n    - 最大绝对相关性为 $\\max_k |c_k| = \\max\\{|1|, |0.9|, |1|, |0|\\} = 1$。\n    - 给定的阈值因子为 $\\alpha = 0.85$。\n    - 阈值为 $\\alpha \\max_k |c_k| = 0.85 \\cdot 1 = 0.85$。\n    - 我们选择满足 $|c_j| \\ge 0.85$ 的索引 $j$：\n        - $|c_1| = 1 \\ge 0.85 \\implies 1 \\in S$。\n        - $|c_2| = 0.9 \\ge 0.85 \\implies 2 \\in S$。\n        - $|c_3| = 1 \\ge 0.85 \\implies 3 \\in S$。\n        - $|c_4| = 0 < 0.85 \\implies 4 \\notin S$。\n    - 选定的索引批次为 $S = \\{1, 2, 3\\}$。\n\n3.  **最小二乘再拟合：** 我们求解使 $\\|y - A_S c\\|_2^2$ 最小化的系数 $\\hat{c}_S$，其中 $A_S = \\begin{bmatrix}a_1  & a_2  & a_3\\end{bmatrix}$。\n    - $A_S = \\begin{bmatrix} 1  & 0.9  & 0 \\\\ 0  & \\sqrt{0.19}  & 0 \\\\ 0  & 0  & 1 \\end{bmatrix}$。\n    - 最小二乘问题是求解 $A_S \\hat{c}_S = y$。由于 $A_S$ 是一个 $3 \\times 3$ 矩阵，我们可以检查它是否可逆。其行列式为 $\\det(A_S) = 1 \\cdot (\\sqrt{0.19} \\cdot 1 - 0 \\cdot 0) = \\sqrt{0.19} \\neq 0$。该矩阵是可逆的，因此存在唯一解。\n    - 我们求解关于 $\\hat{c}_S = \\begin{bmatrix} \\hat{c}_1 \\\\ \\hat{c}_2 \\\\ \\hat{c}_3 \\end{bmatrix}$ 的线性方程组：\n    $$ \\begin{bmatrix} 1  & 0.9  & 0 \\\\ 0  & \\sqrt{0.19}  & 0 \\\\ 0  & 0  & 1 \\end{bmatrix} \\begin{bmatrix} \\hat{c}_1 \\\\ \\hat{c}_2 \\\\ \\hat{c}_3 \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 0 \\\\ 1 \\end{bmatrix} $$\n    - 从第三行：$\\hat{c}_3 = 1$。\n    - 从第二行：$\\sqrt{0.19} \\cdot \\hat{c}_2 = 0 \\implies \\hat{c}_2 = 0$。\n    - 从第一行：$1 \\cdot \\hat{c}_1 + 0.9 \\cdot \\hat{c}_2 = 1 \\implies \\hat{c}_1 + 0.9 \\cdot 0 = 1 \\implies \\hat{c}_1 = 1$。\n    - 在支撑集 $S$ 上的系数向量是 $\\hat{c}_S = \\begin{bmatrix}1 \\\\ 0 \\\\ 1\\end{bmatrix}$。\n    - 残差为 $r = y - A_S \\hat{c}_S = y - (1 \\cdot a_1 + 0 \\cdot a_2 + 1 \\cdot a_3) = y - (a_1+a_3)$。因为 $y=a_1+a_3$，所以残差 $r=0$。\n    - 恢复的信号在索引 $\\{1, 3\\}$ 处有非零项，这与真实支撑集 $\\operatorname{supp}(x^\\star)$ 完全匹配。因此，StOMP 在一个阶段内实现了精确恢复。\n\n**正交匹配追踪 (OMP) 分析**\n\nOMP 算法以迭代方式进行。\n- **初始化：** $S^{(0)} = \\emptyset$，残差 $r^{(0)} = y = \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$。\n\n- **迭代 1：**\n    1. **选择：** 找到使 $|\\langle a_j, r^{(0)} \\rangle|$ 最大化的索引 $j^{(1)}$。相关性与 StOMP 分析中相同：$|\\langle a_1, y \\rangle| = 1$，$|\\langle a_2, y \\rangle| = 0.9$，$|\\langle a_3, y \\rangle| = 1$，$|\\langle a_4, y \\rangle| = 0$。\n    2. 最大值为 $1$，在索引 $j=1$ 和 $j=3$ 之间出现平局。问题陈述规定，通过选择最小的索引来打破平局。因此，$j^{(1)} = 1$。\n    3. **扩充支撑集：** $S^{(1)} = S^{(0)} \\cup \\{1\\} = \\{1\\}$。\n    4. **重新拟合：** 求解使 $\\|y - A_{S^{(1)}} c\\|_2^2$ 最小化的 $\\hat{c}^{(1)}$，其中 $A_{S^{(1)}} = a_1$。解为 $\\hat{c}_1^{(1)} = \\frac{\\langle a_1, y \\rangle}{\\|a_1\\|_2^2} = \\frac{1}{1} = 1$。\n    5. **更新残差：** $r^{(1)} = y - A_{S^{(1)}}\\hat{c}^{(1)} = y - 1 \\cdot a_1 = (a_1+a_3) - a_1 = a_3$。因此，$r^{(1)} = \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix}$。\n\n- **迭代 2：**\n    1. **选择：** 找到使 $|\\langle a_j, r^{(1)} \\rangle|$ 最大化的索引 $j^{(2)}$。\n       - $|\\langle a_1, r^{(1)} \\rangle| = |\\langle a_1, a_3 \\rangle| = 0$。\n       - $|\\langle a_2, r^{(1)} \\rangle| = |\\langle a_2, a_3 \\rangle| = \\left| \\begin{bmatrix}0.9 & \\sqrt{0.19} & 0\\end{bmatrix} \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix} \\right| = 0$。\n       - $|\\langle a_3, r^{(1)} \\rangle| = |\\langle a_3, a_3 \\rangle| = \\|a_3\\|_2^2 = 1$。\n       - $|\\langle a_4, r^{(1)} \\rangle| = |\\langle a_4, a_3 \\rangle| = \\left| \\begin{bmatrix}0 & 1 & 0\\end{bmatrix} \\begin{bmatrix}0\\\\0\\\\1\\end{bmatrix} \\right| = 0$。\n    2. 最大相关性明确为 $1$，对应索引 $j^{(2)} = 3$。\n    3. **扩充支撑集：** $S^{(2)} = S^{(1)} \\cup \\{3\\} = \\{1, 3\\}$。\n    4. **重新拟合：** 求解使 $\\|y - A_{S^{(2)}} c\\|_2^2$ 最小化的 $\\hat{c}^{(2)}$，其中 $A_{S^{(2)}} = \\begin{bmatrix} a_1  & a_3 \\end{bmatrix}$。正规方程为 $(A_{S^{(2)}})^T A_{S^{(2)}} \\hat{c}^{(2)} = (A_{S^{(2)}})^T y$。由于 $a_1$ 和 $a_3$ 是正交的（$\\langle a_1, a_3 \\rangle = 0$），所以 $(A_{S^{(2)}})^T A_{S^{(2)}} = \\begin{bmatrix} \\|a_1\\|^2  & 0 \\\\ 0  & \\|a_3\\|^2 \\end{bmatrix} = \\begin{bmatrix} 1  & 0 \\\\ 0  & 1 \\end{bmatrix}$。解为 $\\hat{c}^{(2)} = (A_{S^{(2)}})^T y = \\begin{bmatrix} \\langle a_1, y \\rangle \\\\ \\langle a_3, y \\rangle \\end{bmatrix} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}$。\n    5. **更新残差：** $r^{(2)} = y - A_{S^{(2)}}\\hat{c}^{(2)} = y - (1 \\cdot a_1 + 1 \\cdot a_3) = (a_1+a_3) - (a_1+a_3) = 0$。\n    - 残差现在为零，所以 OMP 终止。它已正确识别支撑集 $\\{1, 3\\}$ 和系数，在 $2$ 次迭代中实现了精确恢复。\n\n### 逐项分析选项\n\n**A. StOMP 的第一阶段选择 $S=\\{1,2,3\\}$，因为 $|a_1^\\top y|=|a_3^\\top y|=1$ 且 $|a_2^\\top y|=0.9\\ge 0.85\\cdot 1$，其在 $S$ 上的最小二乘再拟合返回的系数为 $\\hat{c}_2=0$，从而在一个阶段内精确恢复了真实的支撑集 $\\{1,3\\}$；OMP 根据规定的平局打破规则，在第一次迭代中选择 $1$，将残差投影到 $\\operatorname{span}\\{a_1\\}$ 的正交补上得到 $r^{(1)}=a_3$，然后在下一次迭代中选择 $3$，同样实现了精确恢复。**\n- 对 StOMP 的分析表明，选定的集合是 $S=\\{1,2,3\\}$。给出的理由是正确的。\n- StOMP 的最小二乘再拟合得到 $\\hat{c}_S = \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$，因此 $\\hat{c}_2=0$。这恢复了真实的稀疏支撑集 $\\{1,3\\}$。\n- 对 OMP 的分析表明，由于平局打破规则，索引 $1$ 被首先选中。\n- OMP 第一步后更新的残差是 $r^{(1)} = y - \\text{Proj}_{\\text{span}\\{a_1\\}}(y) = y - a_1 = a_3$。\n- 第二次 OMP 迭代接着选择了索引 $3$，从而实现了精确恢复。\n- 此陈述中的每一项主张都与我们的推导一致。\n- 结论：**正确**。\n\n**B. OMP 可能会在第一次迭代中选择 $2$，因为 $|a_2^\\top y|$ 等于 $1$，与 $|a_1^\\top y|$ 和 $|a_3^\\top y|$ 相等。**\n- 在 OMP 的第一次迭代中，我们计算了与 $y$ 的相关性。我们发现 $|\\langle a_2, y \\rangle| = 0.9$。\n- 索引 $1$ 和 $3$ 的值是 $|\\langle a_1, y \\rangle|=1$ 和 $|\\langle a_3, y \\rangle|=1$。\n- 由于 $0.9 \\neq 1$，声称 $|\\langle a_2, y \\rangle|$ 等于 $1$ 是错误的。因此，OMP 不可能在第一次迭代中选择索引 $2$。\n- 结论：**不正确**。\n\n**C. StOMP 在批次 $S=\\{1,2,3\\}$ 上的最小二乘问题由于 $a_1$ 和 $a_2$ 之间的高相干性而是奇异的，因此 StOMP 在此阶段无法唯一地恢复系数。**\n- 最小二乘问题涉及矩阵 $A_S = \\begin{bmatrix}a_1  & a_2  & a_3\\end{bmatrix}$。我们计算出其行列式为 $\\det(A_S) = \\sqrt{0.19} \\neq 0$。\n- 行列式非零的方阵是非奇异的（可逆的）。因此，列向量 $\\{a_1, a_2, a_3\\}$ 是线性无关的。\n- 非奇异矩阵确保了最小二乘问题有唯一解。该问题不是奇异的。虽然相干性 $|\\langle a_1, a_2 \\rangle| = 0.9$ 很高，但它小于 $1$，所以向量不是共线的，集合 $\\{a_1, a_2, a_3\\}$ 是线性无关的。\n- 结论：**不正确**。\n\n**D. 因为 StOMP 在第一阶段包含了高相干性但虚假的原子 $a_2$，所以在无噪声设置下，其最小二乘后的残差不能为零，而 OMP 可以将残差降为零。**\n- 我们对 StOMP 的分析表明，在支撑集 $S=\\{1,2,3\\}$ 上的最小二乘拟合得到的系数为 $\\hat{c}_S = \\begin{bmatrix}1\\\\0\\\\1\\end{bmatrix}$。\n- 重构的信号是 $A_S \\hat{c}_S = 1 \\cdot a_1 + 0 \\cdot a_2 + 1 \\cdot a_3 = a_1 + a_3 = y$。\n- 残差为 $r = y - A_S \\hat{c}_S = y-y=0$。\n- “残差不能为零”的说法是错误的。当真实信号 $y$ 位于所选原子的张成空间内（这里是成立的，因为 $y=a_1+a_3$ 在 $\\text{span}\\{a_1, a_2, a_3\\}$ 中），$y$ 在该空间上的最小二乘投影就是 $y$ 本身，残差为零。\n- 结论：**不正确**。\n\n**E. 如果 OMP 通过首先选择 $3$ 来打破初始平局，那么在第二次迭代中，它必须在 $1$ 之前选择 $2$，因为 $a_2$ 与更新后的残差的相关性仍然高于 $a_1$。**\n- 让我们分析这个假设情景。\n- **迭代 1（假设）：** 选择 $j^{(1)}=3$。残差为 $r'^{(1)} = y - \\text{Proj}_{\\text{span}\\{a_3\\}}(y) = y - \\frac{\\langle a_3, y \\rangle}{\\|a_3\\|^2}a_3 = (a_1+a_3) - \\frac{1}{1}a_3 = a_1$。\n- **迭代 2（假设）：** 我们计算与新残差 $r'^{(1)} = a_1$ 的相关性。\n  - $|\\langle a_1, r'^{(1)} \\rangle| = |\\langle a_1, a_1 \\rangle| = \\|a_1\\|^2 = 1$。\n  - $|\\langle a_2, r'^{(1)} \\rangle| = |\\langle a_2, a_1 \\rangle| = |0.9|$。\n- 比较相关性，$1 > 0.9$。OMP 会选择索引 $1$，而不是索引 $2$。\n- “$a_2$ 与更新后的残差的相关性仍然高于 $a_1$” 的说法是错误的。\n- 结论：**不正确**。\n\n根据详细分析，只有陈述 A 是正确的。", "answer": "$$\\boxed{A}$$", "id": "3481088"}, {"introduction": "StOMP算法的一个关键组成部分是阈值 $\\tau$ 的选择，它决定了每个阶段要选入多少个原子。本练习将超越固定的或启发式的阈值设定，深入探讨指导这一选择的统计学原理。我们将比较两种严谨的策略——Bonferroni校正和Benjamini-Hochberg程序，以理解它们如何控制错误发现，并分析其性能差异。[@problem_id:3481125]", "problem": "考虑分阶段正交匹配追踪 (StOMP) 的单个阶段。假设一个线性测量模型 $y = A x^{\\star} + w$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 的列具有单位 $\\ell_{2}$ 范数，并且 $w$ 来自一个零均值噪声分布，该分布在标准化后，在原假设下会产生近似独立的标准正态检验统计量。在此阶段，假设恰好有 $s$ 个真正的活跃坐标（$x^{\\star}$ 中尚未被选中部分的支撑集大小为 $s$），而其余的 $n - s$ 个坐标是零坐标（null）。假设在一个强信号分离机制中， $s$ 个活跃坐标产生的双边 $p$ 值实际上为 $0$（被视为确定性地为 $0$），而 $n - s$ 个零坐标的 $p$ 值是独立同分布于 $\\mathrm{Uniform}(0,1)$ 的，这是由于标准正态的零统计量和双边映射 $p = 2 \\left(1 - \\Phi(|z|)\\right)$，其中 $\\Phi$ 是标准正态分布的累积分布函数。\n\n为此阶段选择坐标定义两种阈值策略：\n- Bonferroni 族科错误率控制，水平为 $q \\in (0,1)$：选择所有 $p$ 值至多为 $q/n$ 的坐标。\n- Benjamini–Hochberg (BH) 错误发现率 (FDR) 控制，水平为 $q \\in (0,1)$：将 $n$ 个 $p$ 值排序为 $p_{(1)} \\leq \\cdots \\leq p_{(n)}$，选择满足 $p_{(k)} \\leq (q k)/n$ 的最大索引 $k$，然后选择所有不超过 $p_{(k)}$ 的 $p$ 值。\n\n假设近似正交性，因此零坐标的 $p$ 值是独立的，并使用大数定律平均场近似，其中随机的 BH 阈值可以被其期望值替代，并且给定阈值的情况下，零坐标选择的计数由其期望值近似。\n\n在这些假设下，为以下两种情况推导每个阶段的错误包含（即，被选中的零坐标）的期望数量的闭式表达式：\n1. 水平为 $q$ 的 Bonferroni 方法。\n2. 水平为 $q$ 的 Benjamini–Hochberg 方法。\n\n将每个期望计数表示为 $q$、$n$ 和 $s$ 的解析函数。将你的最终答案以行矩阵 $\\bigl[\\mathbb{E}[V]_{\\mathrm{Bonf}},\\ \\mathbb{E}[V]_{\\mathrm{BH}}\\bigr]$ 的形式报告。不需要数值近似或四舍五入。", "solution": "用户希望我解决以下问题：\n“考虑分阶段正交匹配追踪（StOMP）的单个阶段。假设一个线性测量模型 $y = A x^{\\star} + w$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 的列具有单位 $\\ell_{2}$ 范数，并且 $w$ 来自一个零均值噪声分布，该分布在标准化后，在原假设下会产生近似独立的标准正态检验统计量。在此阶段，假设恰好有 $s$ 个真正的活跃坐标（$x^{\\star}$ 中尚未被选中部分的支撑集大小为 $s$），而其余的 $n - s$ 个坐标是零坐标（null）。假设在一个强信号分离机制中， $s$ 个活跃坐标产生的双边 $p$ 值实际上为 $0$（被视为确定性地为 $0$），而 $n - s$ 个零坐标的 $p$ 值是独立同分布于 $\\mathrm{Uniform}(0,1)$ 的，这是由于标准正态的零统计量和双边映射 $p = 2 \\left(1 - \\Phi(|z|)\\right)$，其中 $\\Phi$ 是标准正态分布的累积分布函数。\n\n为此阶段选择坐标定义两种阈值策略：\n- Bonferroni 族错误率控制，水平为 $q \\in (0,1)$：选择所有 $p$ 值至多为 $q/n$ 的坐标。\n- Benjamini–Hochberg (BH) 假发现率控制，水平为 $q \\in (0,1)$：将 $n$ 个 $p$ 值排序为 $p_{(1)} \\leq \\cdots \\leq p_{(n)}$，选择满足 $p_{(k)} \\leq (q k)/n$ 的最大索引 $k$，然后选择所有不超过 $p_{(k)}$ 的 $p$ 值。\n\n假设近似正交性，因此零坐标的 $p$ 值是独立的，并使用大数定律平均场近似，其中随机的 BH 阈值可以被其期望值替代，并且给定阈值的情况下，零坐标选择的计数由其期望值近似。\n\n在这些假设下，为以下两种情况推导每个阶段的错误包含（即，被选中的零坐标）的期望数量的闭式表达式：\n1. 水平为 $q$ 的 Bonferroni 方法。\n2. 水平为 $q$ 的 Benjamini–Hochberg 方法。\n\n将每个期望计数表示为 $q$、$n$ 和 $s$ 的解析函数。将你的最终答案以行矩阵 $\\bigl[\\mathbb{E}[V]_{\\mathrm{Bonf}},\\ \\mathbb{E}[V]_{\\mathrm{BH}}\\bigr]$ 的形式报告。不需要数值近似或四舍五入。”\n\n### 步骤1：提取已知条件\n-   模型：线性测量 $y = A x^{\\star} + w$。\n-   矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 的列具有单位 $\\ell_2$ 范数。\n-   噪声 $w$ 在原假设下导致独立的标准正态检验统计量。\n-   总坐标数：$n$。\n-   活跃坐标：$s$ 个，其 p 值为 $0$。\n-   零坐标：$n-s$ 个，其 p 值 $P_i \\sim \\mathrm{Uniform}(0,1)$，独立同分布 (i.i.d.)。\n-   Bonferroni 策略：如果 p 值 $p \\leq q/n$ 则选择。\n-   Benjamini–Hochberg (BH) 策略：将 p 值排序为 $p_{(1)} \\leq \\cdots \\leq p_{(n)}$，找到满足 $p_{(k)} \\leq (qk)/n$ 的最大索引 $k$，并选择所有 p 值不超过 $p_{(k)}$ 的坐标。\n-   BH 的近似：使用大数定律平均场近似。\n-   目标：为两种策略推导错误包含的期望数量 $\\mathbb{E}[V]$ 的表达式。\n\n### 步骤2：使用提取的已知条件进行验证\n-   **科学依据：** 该问题使用了统计信号处理和多重假设检验的标准概念（StOMP、Bonferroni 校正、Benjamini-Hochberg 程序、p 值分布）。其假设（强信号、均匀的零 p 值、独立性）是此类算法理论分析中常见的理想化情况。该问题在科学上是合理的。\n-   **适定性：** 该问题定义清晰。它为 p 值提供了一个完整的概率模型，并指定了要使用的统计程序和近似方法。目标——求错误包含的期望数量——在给定模型下是具体且可实现的。\n-   **客观性：** 该问题以精确、正式的语言陈述，没有歧义或主观内容。\n\n所有其他验证检查均已通过。该问题没有表现出任何缺陷，例如不完整、矛盾、不切实际（在数学背景下）或不适定。对“平均场近似”的引用为简化 BH 过程的复杂分析提供了明确的路径。\n\n### 步骤3：结论与行动\n该问题是有效且适定的。我现在将进行完整的解答推导。\n\n### 推导过程\n\n问题要求计算两种不同多重检验校正程序的错误包含期望数量，记为 $\\mathbb{E}[V]$。错误包含是指被选中的坐标实际上是零坐标。我们已知有 $n-s$ 个零坐标，其 p 值是来自 $\\mathrm{Uniform}(0,1)$ 分布的独立同分布随机变量。设这些 p 值为 $P_1, P_2, \\ldots, P_{n-s}$。\n\n设 $V$ 为错误包含的总数。我们可以将 $V$ 写成指示变量的和：$V = \\sum_{i=1}^{n-s} I_i$，其中如果第 $i$ 个零坐标被选中，则 $I_i = 1$，否则 $I_i=0$。根据期望的线性性质，错误包含的期望数量为：\n$$\n\\mathbb{E}[V] = \\mathbb{E}\\left[\\sum_{i=1}^{n-s} I_i\\right] = \\sum_{i=1}^{n-s} \\mathbb{E}[I_i]\n$$\n指示变量的期望是其所指示事件的概率：$\\mathbb{E}[I_i] = P(\\text{零坐标 } i \\text{ 被选中})$。由于零坐标的 p 值是独立同分布的，这个概率对所有零坐标都相同。如果我们将选择阈值记为 $\\tau$，那么 $P(\\text{零坐标 } i \\text{ 被选中}) = P(P_i \\leq \\tau)$。因为 $P_i \\sim \\mathrm{Uniform}(0,1)$，其累积分布函数 (CDF) 是 $F(p) = p$ (对于 $p \\in [0,1]$)。因此，$P(P_i \\leq \\tau) = \\tau$。\n错误包含的期望数量简化为：\n$$\n\\mathbb{E}[V] = (n-s) \\times P(\\text{一个给定的零坐标被选中})\n$$\n\n**1. Bonferroni 校正 ($\\mathbb{E}[V]_{\\mathrm{Bonf}}$)**\n\nBonferroni 程序对所有 p 值使用一个固定的、确定性的阈值。该阈值为 $\\tau_{\\mathrm{Bonf}} = q/n$。如果一个坐标的 p 值最多为这个阈值，它就会被选中。\n\n一个给定的零坐标被选中的概率是：\n$$\nP(\\text{一个给定的零坐标被选中}) = P(P_i \\leq \\tau_{\\mathrm{Bonf}}) = P(P_i \\leq q/n) = q/n\n$$\n最后一个等式成立，因为 $P_i \\sim \\mathrm{Uniform}(0,1)$ 且 $q/n \\in [0,1]$（因为 $q<1$ 且 $n \\geq 1$）。\n\n因此，Bonferroni 方法的错误包含期望数量为：\n$$\n\\mathbb{E}[V]_{\\mathrm{Bonf}} = (n-s) \\times \\frac{q}{n} = \\frac{q(n-s)}{n}\n$$\n\n**2. Benjamini-Hochberg 程序 ($\\mathbb{E}[V]_{\\mathrm{BH}}$)**\n\nBH 程序使用一个依赖于数据的阈值。这使得期望的直接计算更加复杂。然而，题目指示我们使用大数定律平均场近似。这种方法为有效、非随机的阈值 $\\tau$ 建立了一个自洽方程。\n\n设 $\\tau$ 为这个有效阈值。\n被选中的真实信号（p 值为 $0$）的数量总是 $s$，因为 $\\tau > 0$。\n在给定阈值 $\\tau$ 的情况下，被选中的零坐标（错误包含）的期望数量是 $(n-s) \\times P(P_i \\leq \\tau) = (n-s)\\tau$。这使用了假设中的“给定阈值的情况下，零坐标选择的计数由其期望值近似”这一部分。\n\n被选中的坐标总数（发现数）的期望值 $\\mathbb{E}[R]$，是真实信号和期望错误包含数量的和：\n$$\n\\mathbb{E}[R] = s + (n-s)\\tau\n$$\n平均场近似的核心思想是使用 BH 规则将这个期望发现数与阈值 $\\tau$ 联系起来。BH 规则找到满足 $p_{(k)} \\leq qk/n$ 的最大索引 $k$。在我们的近似中，我们用平均场对应量替换随机量。阈值 $\\tau$ 可以看作是最后一个发现的 p 值 $p_{(k)}$，而索引 $k$ 由总期望发现数 $\\mathbb{E}[R]$ 近似。这导出了自洽方程：\n$$\n\\tau = \\frac{q \\times \\mathbb{E}[R]}{n}\n$$\n代入 $\\mathbb{E}[R]$ 的表达式：\n$$\n\\tau = \\frac{q (s + (n-s)\\tau)}{n}\n$$\n我们现在求解这个关于 $\\tau$ 的线性方程：\n$$\nn\\tau = qs + q(n-s)\\tau\n$$\n$$\nn\\tau - q(n-s)\\tau = qs\n$$\n$$\n\\tau (n - q(n-s)) = qs\n$$\n$$\n\\tau = \\frac{qs}{n - q(n-s)}\n$$\n这个 $\\tau$ 值是在平均场近似下的有效阈值。错误包含的期望数量是零坐标的数量乘以在此阈值下被选中的概率：\n$$\n\\mathbb{E}[V]_{\\mathrm{BH}} = (n-s) \\times P(P_i \\leq \\tau) = (n-s)\\tau\n$$\n代入 $\\tau$ 的表达式：\n$$\n\\mathbb{E}[V]_{\\mathrm{BH}} = (n-s) \\frac{qs}{n - q(n-s)} = \\frac{qs(n-s)}{n - q(n-s)}\n$$\n这个表达式对于 $s \\ge 1$ 是有效的。如果 $s=0$，自洽方程会得出 $\\tau=0$，这意味着 $\\mathbb{E}[V]_{\\mathrm{BH}}=0$，这是这种特定近似的一个人为结果。题目中“活跃坐标”的语境意味着我们考虑 $s \\ge 1$。\n\n两种方法的错误包含期望数量的最终结果是：\n-   Bonferroni: $\\mathbb{E}[V]_{\\mathrm{Bonf}} = \\frac{q(n-s)}{n}$\n-   Benjamini-Hochberg (平均场): $\\mathbb{E}[V]_{\\mathrm{BH}} = \\frac{qs(n-s)}{n - q(n-s)}$\n\n这些结果将以行矩阵的形式报告。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{q(n-s)}{n} & \\frac{qs(n-s)}{n - q(n-s)} \\end{pmatrix}}\n$$", "id": "3481125"}]}