{"hands_on_practices": [{"introduction": "坐标下降的计算优势在具有特定结构的问题中最为显著。本练习将引导您量化这种优势在 LASSO 问题中的体现，特别是在数据矩阵 $A$ 是列稀疏的情况下。通过仔细分析计算成本，您将理解为何更新单个坐标的开销远小于计算完整梯度，从而带来巨大的性能提升。[@problem_id:3436973]", "problem": "考虑最小绝对收缩和选择算子 (Lasso) 问题，其定义为最小化复合凸目标函数 $F(x) = \\tfrac{1}{2}\\lVert A x - y \\rVert_2^2 + \\lambda \\lVert x \\rVert_1$，并且 $A \\in \\mathbb{R}^{m \\times n}$，$y \\in \\mathbb{R}^m$，$x \\in \\mathbb{R}^n$，以及 $\\lambda \\ge 0$。假设 $A$ 以列稀疏格式存储，并令 $a_j \\in \\mathbb{R}^m$ 表示第 $j$ 列，其稀疏度为 $s_j = \\mathrm{nnz}(a_j)$，其中 $\\mathrm{nnz}(\\cdot)$ 表示非零元素的数量。假设残差 $r = A x - y$ 在每次坐标更新后被显式地缓存和更新。\n\n仅使用以下基本事实，推导每次更新和每次迭代的计算成本：\n\n- $f(x)$ 的梯度是 $\\nabla f(x) = A^\\top (A x - y)$。\n- 坐标 $j$ 的坐标级利普希茨常数是 $L_j = \\lVert a_j \\rVert_2^2$。\n- 标量函数 $\\lambda |\\cdot|$ 的近端算子是软阈值映射 $S_\\tau(t) = \\mathrm{sign}(t)\\max\\{|t| - \\tau, 0\\}$。\n- 对于一个具有 $s$ 个非零元的稀疏向量和一个稠密向量之间的稀疏点积，其算术成本为 $O(s)$，每个非零元计为一个乘加对。\n- 对于一个具有 $N$ 个非零元的稀疏矩阵向量积，其算术成本为 $O(N)$，每个非零元计为一个乘加对。\n\n第1部分。证明对 $x$ 的第 $j$ 个坐标的精确坐标级近端更新为\n$$\nx_j^+ \\leftarrow S_{\\lambda/L_j}\\!\\left(x_j - \\frac{a_j^\\top r}{L_j}\\right),\n$$\n并且当残差 $r$ 被缓存时，更新单个坐标 $j$ 并刷新残差\n$$\nr^+ \\leftarrow r + a_j (x_j^+ - x_j)\n$$\n的总算术成本为 $O(\\mathrm{nnz}(a_j))$。您的推导必须从 $\\nabla f(x)$、$L_j$ 和近端算子的定义开始，并且必须根据 $s_j = \\mathrm{nnz}(a_j)$ 明确证明算术成本计数的每一步。\n\n第2部分。对于迭代软阈值算法 (ISTA) 和快速迭代软阈值算法 (FISTA)，每次迭代使用两个稀疏矩阵向量积来计算梯度：一个用于 $A x$，一个用于 $A^\\top r$。证明单次 ISTA/FISTA 迭代的算术成本为 $O(\\mathrm{nnz}(A))$，其隐含的常数因子不依赖于 $m$ 或 $n$。解释为什么在列稀疏的情况下，每次迭代的成本主要由与 $\\mathrm{nnz}(A)$ 成比例的运算决定。\n\n第3部分。假设采用以下工作负载模型，以在固定精度下比较计算效率：\n\n- 经过一个短暂的瞬态过程后，坐标下降 (CD) 只重复更新大小为 $k = |S|$ 的活动集 $S \\subset \\{1,\\dots,n\\}$，因为由于软阈值处理，$S$ 之外的坐标保持为零。在此阶段，CD 对每个活动坐标执行 $T$ 次更新，总共进行 $T k$ 次坐标更新。每次完整遍历 $S$ 的总算术成本与 $\\sum_{j \\in S} s_j$ 成正比。\n- ISTA/FISTA 需要 $E$ 次完整迭代才能在目标函数值上达到相同的精度，并且每次迭代的算术成本与 $\\mathrm{nnz}(A)$ 成正比。\n\n在 $E=T$ 的简化假设下（即，两种方法需要相同数量的外部迭代来达到所需精度），CD 相对于 ISTA/FISTA 的预测运行时优势因子为\n$$\n\\rho \\equiv \\frac{\\text{work per ISTA/FISTA iteration}}{\\text{work per CD sweep over }S} = \\frac{\\mathrm{nnz}(A)}{\\sum_{j \\in S} s_j}.\n$$\n为下面的每个测试用例计算 $\\rho$。假设与稀疏算术相比，近端标量运算（软阈值处理）和常数时间标量更新的成本可以忽略不计，并且每个非零元每次乘加对贡献一个工作单位。使用以下定义：\n\n- $\\mathrm{nnz}(A) = \\sum_{j=1}^n s_j$，\n- $s_j = \\mathrm{nnz}(a_j)$，\n- $S$ 是活动集。\n\n测试套件。对于下面的每种情况，计算并报告如上定义的标量 $\\rho$。\n\n- 情况 A（理想情况；高度列稀疏且活动集较小）：令 $m = 100000$, $n = 50000$, 对所有 $j$ 有 $s_j = 5$，且 $S$ 是大小为 $k = 500$ 的任意子集。\n- 情况 B（异构稀疏性；活动集集中在最稀疏的列上）：令 $m = 20000$, $n = 20000$，并定义 $s_j = 2 + \\left\\lfloor 8 \\cdot \\frac{j-1}{n-1} \\right\\rfloor$，使得 $s_j \\in \\{2,3,\\dots,10\\}$ 随 $j$ 近似线性增加。令 $S$ 为具有最小 $s_j$ 值的 $k = 100$ 个索引。\n- 情况 C（边界情况；稠密列且无稀疏优势）：令 $m = 5000$, $n = 5000$, 对所有 $j$ 有 $s_j = m$，且 $S = \\{1,\\dots,n\\}$，因此 $k = n$。\n- 情况 D（偏斜混合；大部分非常稀疏和少数中等密度列；活动集较小且在非常稀疏的列中）：令 $m = 100000$, $n = 100000$，并为前 $90000$ 列定义 $s_j = 3$，为后 $10000$ 列定义 $s_j = 1000$。令 $S$ 为前 $90000$ 列中大小为 $k = 1000$ 的任意子集。\n\n最终输出格式。您的程序应生成单行输出，其中包含按 A、B、C、D 案例顺序排列的结果，形式为方括号内以逗号分隔的列表。每个条目必须是浮点数。例如，包含四个结果的输出必须类似于 $[r_A,r_B,r_C,r_D]$，其中每个 $r_\\cdot$ 是一个用标准十进制表示法编写的浮点数，不带单位或百分号。", "solution": "用户提供了一个包含三部分的问题，涉及针对Lasso优化问题的坐标下降(CD)与迭代软阈值算法(ISTA)的计算成本分析。该问题是有效的，因为它在科学上基于凸优化理论，内部一致，适定，并为完整解答提供了所有必要的信息。\n\n### 第1部分：坐标下降更新和每次更新的成本\n\nLasso 目标函数是 $F(x) = f(x) + g(x)$，其中 $f(x) = \\frac{1}{2}\\lVert A x - y \\rVert_2^2$ 是平滑的最小二乘项，而 $g(x) = \\lambda \\lVert x \\rVert_1 = \\sum_{i=1}^n \\lambda |x_i|$ 是非平滑的正则化项。\n\n坐标下降算法一次更新一个坐标 $x_j$，同时保持所有其他坐标 $x_{i \\neq j}$ 固定。这涉及到求解一个一维优化问题。对此的标准方法是针对单个坐标 $x_j$ 的近端梯度更新。此更新的一般形式是：\n$$\nx_j^+ \\leftarrow \\mathrm{prox}_{\\gamma g_j}(x_j - \\gamma \\nabla_j f(x))\n$$\n其中 $g_j(t) = \\lambda |t|$ 是对应于坐标 $j$ 的正则化项的分量，$\\nabla_j f(x) = \\frac{\\partial f}{\\partial x_j}$ 是 $f(x)$ 的第 $j$ 个偏导数，而 $\\gamma$ 是步长。对于坐标级更新，最优步长是梯度坐标级利普希茨常数的倒数，即 $\\gamma_j = 1/L_j$。问题陈述中给出 $L_j = \\lVert a_j \\rVert_2^2$。\n\n梯度 $\\nabla f(x) = A^\\top(Ax-y)$ 的第 $j$ 个分量由 $A^\\top$ 的第 $j$ 行（即 $A$ 的第 $j$ 列 $a_j$）与残差向量 $r = Ax-y$ 的点积给出。因此，\n$$\n\\nabla_j f(x) = a_j^\\top (Ax - y) = a_j^\\top r\n$$\n函数 $\\alpha |\\cdot|$ 的近端算子是软阈值算子 $S_\\alpha(z) = \\mathrm{sign}(z) \\max\\{|z|-\\alpha, 0\\}$。在我们的情况中，函数是 $\\gamma_j g_j(t) = \\frac{1}{L_j} \\lambda |t|$，因此软阈值算子的参数是 $\\alpha = \\lambda/L_j$。\n\n将 $\\gamma = 1/L_j$、$\\nabla_j f(x) = a_j^\\top r$ 以及近端算子的形式代入更新规则，我们得到：\n$$\nx_j^+ \\leftarrow \\mathrm{prox}_{\\lambda/L_j |\\cdot|}\\left(x_j - \\frac{1}{L_j} a_j^\\top r\\right) = S_{\\lambda/L_j}\\left(x_j - \\frac{a_j^\\top r}{L_j}\\right)\n$$\n这就完成了更新公式的推导。\n\n接下来，我们分析执行此更新和刷新缓存残差 $r$ 的计算成本。该过程包括两个步骤：\n1.  **计算 $x_j$ 的更新**：主要的计算工作是点积 $a_j^\\top r$。鉴于 $a_j$ 是一个具有 $s_j = \\mathrm{nnz}(a_j)$ 个非零项的稀疏向量，而 $r$ 是一个大小为 $m$ 的稠密向量，此操作需要 $O(s_j)$ 次算术运算（具体来说是 $s_j$ 次乘法和 $s_j-1$ 次加法）。所有其他运算（标量减法、除法和软阈值映射）花费常数时间，即 $O(1)$。因此，计算 $x_j^+$ 的成本主要由点积决定，导致成本为 $O(s_j)$。\n2.  **更新残差**：新的残差 $r^+$ 是根据 $x_j$ 的变化量计算的，记为 $\\Delta x_j = x_j^+ - x_j$。\n    $$\n    r^+ = A x^+ - y = A (x + \\Delta x_j e_j) - y = (A x - y) + A(\\Delta x_j e_j) = r + \\Delta x_j a_j\n    $$\n    其中 $e_j$ 是第 $j$ 个标准基向量。更新 $r^+ \\leftarrow r + (\\Delta x_j) a_j$ 是一个缩放向量加法（SAXPY 操作）。由于 $a_j$ 只有 $s_j$ 个非零项，因此 $r$ 中只有 $s_j$ 个元素会被修改。这需要 $s_j$ 次乘法和 $s_j$ 次加法，总成本为 $O(s_j)$。\n\n一次完整的坐标更新（更新 $x_j$ 然后更新 $r$）的总算术成本是这两个步骤成本的总和，即 $O(s_j) + O(s_j) = O(s_j)$。\n\n### 第2部分：ISTA/FISTA 每次迭代的成本\n\n一次 ISTA（和 FISTA）的迭代需要计算完整的梯度 $\\nabla f(x) = A^\\top(Ax-y)$。如问题中所述，这是通过两个稀疏矩阵向量积实现的。\n1.  计算残差 $r=Ax-y$。根据提供的成本模型，当 $A$ 是一个具有 $\\mathrm{nnz}(A)$ 个非零元的稀疏矩阵时，$Ax$ 的乘积成本为 $O(\\mathrm{nnz}(A))$ 次运算。随后的向量减法成本为 $O(m)$。\n2.  计算梯度 $\\nabla f(x) = A^\\top r$。矩阵 $A^\\top$ 同样有 $\\mathrm{nnz}(A)$ 个非零元。类似地，这个乘积的成本为 $O(\\mathrm{nnz}(A))$ 次运算。\n\nISTA/FISTA 迭代的其余部分，例如向量加法和逐元素的近端映射，其成本为 $O(n)$ 或 $O(m)$。在典型的稀疏高维设置中，非零元数量 $\\mathrm{nnz}(A)$ 是主导项，即 $\\mathrm{nnz}(A) \\gg n$ 且 $\\mathrm{nnz}(A) \\gg m$。因此，ISTA 或 FISTA 的每次迭代总成本主要由两个矩阵向量积决定，从而得到 $O(\\mathrm{nnz}(A))$ 的计算复杂度。\n\n### 第3部分：优势因子 $\\rho$ 的计算\n\n优势因子 $\\rho$ 比较了一次 ISTA/FISTA 迭代的工作量与一次 CD 遍历活动集 $S$ 的工作量。根据问题定义和上面推导的成本，我们有：\n$$\n\\rho = \\frac{\\text{Work(ISTA iteration)}}{\\text{Work(CD sweep over } S)} = \\frac{O(\\mathrm{nnz}(A))}{O\\left(\\sum_{j \\in S} s_j\\right)}\n$$\n假设大O表示法中隐藏的常数是可比的并且可以消去，该公式简化为：\n$$\n\\rho = \\frac{\\mathrm{nnz}(A)}{\\sum_{j \\in S} s_j}\n$$\n现在我们为每个给定的测试用例计算 $\\rho$。\n\n**情况 A**：\n-   $n = 50000$, 对所有 $j$ 有 $s_j=5$，$k = |S| = 500$。\n-   $\\mathrm{nnz}(A) = n \\times s_j = 50000 \\times 5 = 250000$。\n-   $\\sum_{j \\in S} s_j = k \\times s_j = 500 \\times 5 = 2500$。\n-   $\\rho_A = \\frac{250000}{2500} = 100.0$。\n\n**情况 B**：\n-   $n = 20000$, $s_j = 2 + \\lfloor 8 \\cdot \\frac{j-1}{n-1} \\rfloor$, $k = |S| = 100$。\n-   活动集 $S$ 由具有最小 $s_j$ 的100个索引组成。最小值为 $s_1 = 2 + \\lfloor 0 \\rfloor = 2$。因此，对于所有 $j \\in S$，$s_j = 2$。\n-   $\\sum_{j \\in S} s_j = k \\times 2 = 100 \\times 2 = 200$。\n-   $\\mathrm{nnz}(A) = \\sum_{j=1}^n s_j = \\sum_{j=1}^{20000} \\left(2 + \\lfloor 8 \\frac{j-1}{19999} \\rfloor\\right) = 2n + \\sum_{k=0}^{19999} \\lfloor \\frac{8k}{19999} \\rfloor$。\n    求和项的计算结果为 70001。\n    $\\mathrm{nnz}(A) = 2 \\times 20000 + 70001 = 40000 + 70001 = 110001$。\n-   $\\rho_B = \\frac{110001}{200} = 550.005$。\n\n**情况 C**：\n-   $n = 5000$, $m=5000$, 对所有 $j$ 有 $s_j = m = 5000$, $S = \\{1, \\dots, n\\}$。\n-   $\\mathrm{nnz}(A) = n \\times m = 5000 \\times 5000 = 25000000$。\n-   由于 $S$ 包括所有列，$\\sum_{j \\in S} s_j = \\sum_{j=1}^n s_j = \\mathrm{nnz}(A)$。\n-   $\\rho_C = \\frac{\\mathrm{nnz}(A)}{\\mathrm{nnz}(A)} = 1.0$。\n\n**情况 D**：\n-   $n = 100000$, $k = |S| = 1000$。$S$ 是前 $90000$ 列的一个子集。\n-   $j \\in \\{1, \\dots, 90000\\}$ 时 $s_j=3$，$j \\in \\{90001, \\dots, 100000\\}$ 时 $s_j=1000$。\n-   $\\mathrm{nnz}(A) = (90000 \\times 3) + (10000 \\times 1000) = 270000 + 10000000 = 10270000$。\n-   对于任意 $j \\in S$，$s_j = 3$。\n-   $\\sum_{j \\in S} s_j = k \\times 3 = 1000 \\times 3 = 3000$。\n-   $\\rho_D = \\frac{10270000}{3000} = \\frac{10270}{3} \\approx 3423.333333$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the predicted runtime advantage factor of Coordinate Descent (CD)\n    over ISTA/FISTA for the Lasso problem under a simplified workload model.\n    \"\"\"\n\n    test_cases = [\n        # Case A: Happy path; highly column-sparse with small active set\n        {\n            \"name\": \"A\",\n            \"params\": {\"m\": 100000, \"n\": 50000, \"k\": 500},\n            \"s_func\": lambda j, n, m: 5,\n            \"s_active_func\": lambda s_all: 5\n        },\n        # Case B: Heterogeneous sparsity; active set on sparsest columns\n        {\n            \"name\": \"B\",\n            \"params\": {\"m\": 20000, \"n\": 20000, \"k\": 100},\n            \"s_func\": lambda j, n, m: 2 + int(8 * (j - 1) / (n - 1)),\n            \"s_active_func\": lambda s_all: 2\n        },\n        # Case C: Boundary; dense columns and no sparsity advantage\n        {\n            \"name\": \"C\",\n            \"params\": {\"m\": 5000, \"n\": 5000, \"k\": 5000},\n            \"s_func\": lambda j, n, m: m,\n            \"s_active_func\": lambda s_all: 5000\n        },\n        # Case D: Skewed mixture; small active set among very sparse columns\n        {\n            \"name\": \"D\",\n            \"params\": {\"m\": 100000, \"n\": 100000, \"k\": 1000},\n            \"s_func\": lambda j, n, m: 3 if j = 90000 else 1000,\n            \"s_active_func\": lambda s_all: 3\n        },\n    ]\n\n    results = []\n    \n    # The advantage factor rho is defined as nnz(A) / sum_{j in S} s_j\n    # where nnz(A) = sum_{j=1 to n} s_j\n\n    # --- Case A ---\n    case_a = test_cases[0]\n    p_a = case_a[\"params\"]\n    n_a, k_a = p_a[\"n\"], p_a[\"k\"]\n    s_j_a = case_a[\"s_func\"](1, n_a, p_a[\"m\"]) # s_j is constant\n    nnz_A_a = n_a * s_j_a\n    sum_s_j_S_a = k_a * case_a[\"s_active_func\"](None)\n    rho_a = nnz_A_a / sum_s_j_S_a\n    results.append(rho_a)\n\n    # --- Case B ---\n    case_b = test_cases[1]\n    p_b = case_b[\"params\"]\n    n_b, k_b = p_b[\"n\"], p_b[\"k\"]\n    s_values_b = [case_b[\"s_func\"](j, n_b, p_b[\"m\"]) for j in range(1, n_b + 1)]\n    nnz_A_b = sum(s_values_b)\n    sum_s_j_S_b = k_b * case_b[\"s_active_func\"](s_values_b)\n    rho_b = nnz_A_b / sum_s_j_S_b\n    results.append(rho_b)\n\n    # --- Case C ---\n    case_c = test_cases[2]\n    p_c = case_c[\"params\"]\n    n_c, m_c, k_c = p_c[\"n\"], p_c[\"m\"], p_c[\"k\"]\n    s_j_c = case_c[\"s_func\"](1, n_c, m_c)\n    nnz_A_c = n_c * s_j_c\n    # S = {1,...,n}, so sum over S is the same as sum over all columns\n    sum_s_j_S_c = nnz_A_c \n    rho_c = nnz_A_c / sum_s_j_S_c\n    results.append(rho_c)\n    \n    # --- Case D ---\n    case_d = test_cases[3]\n    p_d = case_d[\"params\"]\n    n_d, k_d = p_d[\"n\"], p_d[\"k\"]\n    n1, s1 = 90000, 3\n    n2, s2 = 10000, 1000\n    nnz_A_d = n1 * s1 + n2 * s2\n    sum_s_j_S_d = k_d * case_d[\"s_active_func\"](None)\n    rho_d = nnz_A_d / sum_s_j_S_d\n    results.append(rho_d)\n\n    # Format the final output as specified.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3436973"}, {"introduction": "没有任何一种优化算法能在所有情况下都占据绝对优势；最佳选择取决于问题的底层结构。本练习通过一个特殊场景挑战了传统观念：数据矩阵的列是稠密的，但其本身支持快速变换。您将推导出在这种情况下，像 ISTA/FISTA 这样的全梯度方法能够超越坐标下降的条件，从而揭示单步更新成本与利用全局矩阵结构成本之间的关键权衡。[@problem_id:3437000]", "problem": "考虑最小绝对收缩和选择算子 (LASSO) 问题\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2}\\|A x - y\\|_{2}^{2} + \\lambda \\|x\\|_{1},\n$$\n其中 $A \\in \\mathbb{R}^{m \\times n}$ 允许通过结构化变换进行快速乘法，且其列是稠密的。您正在比较两种一阶方法：迭代软阈值算法 (ISTA) 及其加速变体快速迭代软阈值算法 (FISTA)，与坐标下降法 (CD)。假设使用以下计算模型：\n\n- 一次与 $A$ 的乘法耗费 $c_{A} \\, m \\log_{2}(m)$ 次标量运算，一次与 $A^{\\top}$ 的乘法耗费 $c_{A^{\\top}} \\, m \\log_{2}(m)$ 次标量运算，这反映了具有以2为底的对数复杂度的快速变换。相对于变换成本，忽略向量加法和软阈值映射的成本。\n- 一次 ISTA (或 FISTA) 迭代精确地执行一次与 $A$ 的乘法和一次与 $A^{\\top}$ 的乘法。\n- 单个坐标 $j$ 的 CD 更新需要计算 $a_{j}^{\\top} r$（其中 $r := A x - y$），然后更新 $r \\leftarrow r + \\Delta x_{j} a_{j}$。如果矩阵 $A$ 只能通过其快速变换访问（没有显式的列存储）并且其列是稠密的，则每次 CD 更新的成本为 $c_{t} \\, m$ 次标量运算，与 $j$ 无关，因为物化并应用一个稠密列 $a_{j}$ 并不比一次全长向量操作更便宜。如果显式列可用，则成本将与 $a_{j}$ 中的非零元素数量 $\\text{nnz}(a_{j})$ 成正比，但在这种设置下，对所有 $j$ 都有 $\\text{nnz}(a_{j}) = m$。\n\n定义一个 CD 轮次 (epoch) 为 $s$ 次连续的坐标更新（可能使用不同的索引）。设 $m = 16384$，$c_{A} = 3$，$c_{A^{\\top}} = 3$，$c_{t} = 2$。请从第一性原理出发，推导出一个关于临界轮次大小 $s_{\\star}$ 的符号表达式，使得在上述假设下，一个 CD 轮次的总成本等于一次 ISTA 迭代的成本，然后用给定参数对 $s_{\\star}$ 进行数值计算。您的最终答案必须是 $s_{\\star}$ 的单一值。此外，在您的推导中，请用 $\\text{nnz}(a_{j})$ 和变换成本来陈述一个一般性条件，该条件描述了在稠密列、快速变换的情况下，坐标下降法何时会相对于 ISTA/FISTA 失去其计算优势。对于 $s_{\\star}$ 的最终值，无需进行四舍五入。", "solution": "在尝试给出解答之前，将对所述问题进行验证。\n\n**步骤1：提取已知条件**\n问题在于分析 LASSO 问题的优化算法的计算成本：\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\ \\frac{1}{2}\\|A x - y\\|_{2}^{2} + \\lambda \\|x\\|_{1}\n$$\n所提供的数据和计算模型假设如下：\n- 矩阵 $A$ 属于 $\\mathbb{R}^{m \\times n}$，其列是稠密的，且允许快速的矩阵-向量乘法。\n- 一次与 $A$ 的乘法成本为 $c_{A} \\, m \\log_{2}(m)$ 次标量运算。\n- 一次与 $A^{\\top}$ 的乘法成本为 $c_{A^{\\top}} \\, m \\log_{2}(m)$ 次标量运算。\n- 一次 ISTA 或 FISTA 迭代涉及一次与 $A$ 的乘法和一次与 $A^{\\top}$ 的乘法。\n- 与变换成本相比，向量加法和软阈值算子的成本可以忽略不计。\n- 对任何坐标 $j$ 进行单次坐标下降 (CD) 更新的成本为 $c_{t} \\, m$ 次标量运算。该成本是问题的前提，反映了涉及大小为 $m$ 的稠密列的操作成本。\n- 一个 CD 轮次定义为 $s$ 次连续的坐标更新。\n- 提供的数值参数为：$m = 16384$，$c_{A} = 3$，$c_{A^{\\top}} = 3$，$c_{t} = 2$。\n\n**步骤2：使用提取的已知条件进行验证**\n该问题在数值优化和稀疏信号处理领域具有科学依据。LASSO 目标函数以及所提及的算法（ISTA、FISTA、CD）都是标准的。问题的核心是基于一个特定模型对计算成本进行比较。\n\n该模型提出了一个场景，其中矩阵 $A$ 具有快速变换，意味着它具有全局结构（如傅里叶或哈达玛矩阵），但 CD 的单次坐标更新成本却被设定为 $O(m)$。通常情况下，使用列 $a_j = A e_j$ 需要通过变换生成它，成本为 $O(m \\log m)$。该问题通过假定一个 $O(m)$ 的成本来规避这一点，并声明这是“因为物化并应用一个稠密列 $a_j$ 并不比一次全长向量操作更便宜”。这构成了该问题计算模型的一条公理。虽然这可能是对真实世界实现的简化，但它并不构成逻辑矛盾或违反数学原理。它定义了分析的具体背景。\n\n该问题是适定 (well-posed) 的，提供了推导量 $s_{\\star}$ 所需的所有信息。语言客观而精确。问题并非无足轻重，需要正确应用给定的成本模型。它完全可以形式化，并且与其所述主题相关。\n\n一个小观察是，在 CD 残差更新规则的描述中可能存在一个符号错误，“$r \\leftarrow r - \\Delta x_{j} a_{j}$”。如果 $x_j$ 的变化是 $\\Delta x_j$，新的残差 $r_{\\text{new}} = A(x_{\\text{old}} + \\Delta x_j e_j) - y$ 会变成 $r_{\\text{old}} + \\Delta x_j a_j$。然而，这个细节关乎算法的机理，而非其计算成本，而计算成本是问题的唯一焦点。因此，这不影响问题的有效性。\n\n**步骤3：结论与行动**\n该问题被判定为 **有效**。将提供完整的解答。\n\n**解答推导**\n\n主要任务是找到临界轮次大小 $s_{\\star}$，在该值下，一个坐标下降 (CD) 轮次的计算成本等于一次 ISTA/FISTA 迭代的成本。我们从问题计算模型中给出的第一性原理出发。\n\n首先，我们确定 ISTA 或 FISTA 单次迭代的成本。问题陈述，这两种算法的单次迭代都精确地执行一次与 $A$ 的乘法和一次与 $A^{\\top}$ 的乘法。其他操作（如向量加法和收缩）的成本被认为可以忽略不计。\n\n与 $A$ 相乘的成本为 $C_{A} = c_{A} m \\log_{2}(m)$。\n与 $A^{\\top}$ 相乘的成本为 $C_{A^{\\top}} = c_{A^{\\top}} m \\log_{2}(m)$。\n\n因此，一次 ISTA 或 FISTA 迭代的总成本（我们记为 $C_{\\text{ISTA}}$）是这两个成本之和：\n$$\nC_{\\text{ISTA}} = C_{A} + C_{A^{\\top}} = c_{A} m \\log_{2}(m) + c_{A^{\\top}} m \\log_{2}(m) = (c_{A} + c_{A^{\\top}}) m \\log_{2}(m)\n$$\n\n接下来，我们确定一个 CD 轮次的成本。一个 CD 轮次被定义为 $s$ 次连续的坐标更新。问题指定单次坐标更新的成本为 $C_{\\text{CD\\_update}} = c_{t} m$，与坐标索引 $j$ 无关。\n\n一个大小为 $s$ 的 CD 轮次的总成本（记为 $C_{\\text{CD\\_epoch}}(s)$）是单次更新的成本乘以更新次数 $s$：\n$$\nC_{\\text{CD\\_epoch}}(s) = s \\cdot C_{\\text{CD\\_update}} = s \\, c_{t} m\n$$\n\n临界轮次大小 $s_{\\star}$ 定义为使这两个成本相等的 $s$ 值：\n$$\nC_{\\text{CD\\_epoch}}(s_{\\star}) = C_{\\text{ISTA}}\n$$\n代入成本的表达式，我们得到主导方程：\n$$\ns_{\\star} \\, c_{t} m = (c_{A} + c_{A^{\\top}}) m \\log_{2}(m)\n$$\n为了找到 $s_{\\star}$ 的符号表达式，我们求解该方程。项 $m$ 可以方便地从两边消去，得到：\n$$\ns_{\\star} = \\frac{c_{A} + c_{A^{\\top}}}{c_{t}} \\log_{2}(m)\n$$\n这就是临界轮次大小的符号表达式。它表明，对于一组固定的成本系数，$s_{\\star}$ 随问题维度 $m$ 呈对数增长。\n\n现在，我们使用提供的参数对此表达式进行数值计算：$m = 16384$，$c_{A} = 3$，$c_{A^{\\top}} = 3$，$c_{t} = 2$。\n首先，我们计算 $m$ 的对数：\n$$\nm = 16384 = 2^{14}\n$$\n因此，$\\log_{2}(m) = \\log_{2}(2^{14}) = 14$。\n\n将所有数值代入 $s_{\\star}$ 的表达式中：\n$$\ns_{\\star} = \\frac{3 + 3}{2} \\times 14 = \\frac{6}{2} \\times 14 = 3 \\times 14 = 42\n$$\n因此，对于给定的参数，在 CD 中执行 $42$ 次坐标更新的计算成本与执行一次 ISTA 或 FISTA 的完整迭代相同。\n\n最后，我们讨论在稠密列、快速变换的情况下，坐标下降法失去其计算优势的一般条件。CD 的传统优势源于其较低的单次更新成本，特别是当矩阵 $A$ 的列 $a_j$ 是稀疏的时。更新坐标 $x_j$ 的成本与相应列中的非零元素数量 $\\text{nnz}(a_j)$ 成正比。当 $\\text{nnz}(a_j) \\ll m$ 时，此成本很低。\n\n相比之下，像 ISTA/FISTA 这样的方法在每一步都需要进行完整的梯度计算 $A^{\\top}(Ax-y)$。当 $A$ 具有快速变换时，其成本为 $O(m \\log m)$。CD 的一个完整遍或“轮次”涉及更新所有 $n$ 个坐标。一个完整 CD 遍的成本约为 $O(\\sum_{j=1}^{n} \\text{nnz}(a_j))$。\n\n当坐标下降法的单次更新成本相对于基于变换的方法的成本不再小时，其计算优势就丧失了。这发生在 $A$ 的列是稠密的情况下，即 $\\text{nnz}(a_j) \\approx m$。在这种情况下，单次 CD 更新的成本为 $O(m)$，而对所有 $n$ 个坐标进行一整遍的成本变为 $O(nm)$。\n\n因此，在稠密列、快速变换的情况下，CD 相对于 ISTA/FISTA 失去计算优势的条件是：当一个完整 CD 遍的成本 $O(nm)$ 不再显著小于一次 ISTA/FISTA 迭代的成本 $O(m \\log m)$ 时。比较这些成本，如果 $nm \\gtrsim m \\log m$，即简化为 $n \\gtrsim \\log m$，则 CD 处于劣势。由于在大多数实际的高维问题中，特征数量 $n$ 远大于 $\\log m$，因此在稠密列和 $A$ 具有快速变换的条件下，坐标下降法在按遍计算的基准上是不利的。其竞争力将完全取决于它能否用少量更新（$s \\ll n$）在求解过程中取得比单次 ISTA/FISTA 迭代大得多的进展。", "answer": "$$\\boxed{42}$$", "id": "3437000"}, {"introduction": "简单地计算浮点运算次数往往无法准确预测算法的真实世界性能，后者深受数据移动的巨大影响。本练习将指导您使用 roofline 模型构建一个更贴近实际的性能模型，其中考虑了内存带宽和数据存储布局（列主序 vs. 行主序）等硬件细节。通过分析算法的算术强度和内存流量，您将能够预测坐标下降与 ISTA 之间的性能交叉点，从而对计算效率获得更深刻、更具硬件感知能力的理解。[@problem_id:3436942]", "problem": "考虑一个稠密矩阵 $A \\in \\mathbb{R}^{m \\times n}$ 以及最小绝对收缩和选择算子 (LASSO) 的目标函数 $f(x) = \\tfrac{1}{2}\\lVert Ax - b \\rVert_2^2 + \\lambda \\lVert x \\rVert_1$，其中 $x \\in \\mathbb{R}^n$，$b \\in \\mathbb{R}^m$。近似最小化 $f(x)$ 的两种标准迭代方法是：\n- 迭代收缩阈值算法 (Iterative Shrinkage-Thresholding Algorithm, ISTA)。\n- 带残差更新的坐标下降法 (Coordinate Descent, CD)。\n\n您的任务是，在 $A$ 采用列主序和行主序存储的情况下，定量比较这两种方法的每次迭代的算术强度和缓存局部性特征，对中央处理器 (CPU) 的内存带宽限制进行建模，并预测两种方法之间的性能交叉点。\n\n从以下符合上下文的基本依据开始：\n- 算术强度定义为 $I = F/B$，其中 $F$ 计算浮点运算次数 (FLOPs)，$B$ 计算迭代期间主存和缓存之间移动的总字节数。\n- 屋顶线性能模型指出，迭代时间受限于 $T = \\max(F/P, B/\\mathcal{B})$，其中 $P$ 是峰值浮点运算速率（单位：FLOPs/秒），$\\mathcal{B}$ 是持续内存带宽（单位：字节/秒）。\n- 双精度浮点数每个元素使用 $s_e = 8$ 字节。\n- 缓存行大小为 $L$ 字节，主存传输以整个缓存行为单位进行。\n- 在列主序存储下，$A$ 的列在内存中是连续排列的。在行主序存储下，行是连续排列的。\n- 在稠密情况下，一个稠密矩阵向量乘积 $y = Ax$ 使用大约 $F_{mv} = 2mn$ FLOPs，$g = A^\\top r$ 使用 $F_{tmv} = 2mn$ FLOPs，忽略了向量运算的低阶项。ISTA 每次迭代执行 $y = Ax$ 和 $g = A^\\top r$，然后对 $x$ 进行逐分量的软阈值化。\n- 对于单个坐标 $j$，带残差更新的坐标下降法执行 $c = A_{\\cdot j}^\\top r$ 和 $r \\leftarrow r + \\Delta A_{\\cdot j}$，其中 $A_{\\cdot j}$ 是 $A$ 的第 $j$ 列，$\\Delta$ 是坐标更新值。在稠密情况下，每次单坐标更新大约使用 $F_{cd,1} \\approx 4m$ FLOPs（一个长度为 $m$ 的点积加上一个缩放的 axpy 运算）。\n\n使用以下科学上符合实际的假设来为缓存局部性和内存流量建模：\n- 当访问连续内存时（在行主序布局中流式读取一行或在列主序布局中流式读取一列），每个获取的大小为 $L$ 字节的缓存行在其 $L/s_e$ 个元素上都提供有效数据，即除了传输整个缓存行之外没有额外惩罚。\n- 当访问步幅内存，即每个 $L$ 字节的缓存行只触及一个 $s_e$ 字节的元素时（例如，从未经分块的行主序数组中读取一列，或从未经分块的列主序数组中读取一行），有效内存流量会因步幅惩罚因子 $p_s = L/s_e$ 而膨胀，因为每个缓存行中 $L/s_e$ 个元素只有一个是有用的。\n- 假设为写分配行为，因此在字节传输级别上，写操作引起的缓存行流量与读操作相同。\n\n基于以上内容，定义以下每次迭代的内存流量模型：\n- ISTA：两次稠密矩阵向量遍历以及中间量的向量读/写。在列主序存储下，$y = Ax$ 遍历会遭受步幅惩罚 $p_s$，而 $g = A^\\top r$ 遍历是连续的；在行主序存储下，情况相反。向量运算贡献了与 $m$ 和 $n$ 成正比的低阶项。设 ISTA 的总 FLOPs 为 $F_I = 4mn$，总字节数为 $B_I = s_e\\,mn\\,(p_y + p_g) + s_e\\,(5m + 5n)$，其中对于列主序，$(p_y, p_g) = (p_s, 1)$；对于行主序，$(p_y, p_g) = (1, p_s)$。\n- 坐标下降法：考虑单坐标更新。在列主序存储下，读取 $A_{\\cdot j}$ 是连续的；在行主序存储下，读取 $A_{\\cdot j}$ 有步幅惩罚 $p_s$。更新残差 $r$ 是一个连续的读写操作。设单坐标的 FLOPs 为 $F_{C,1} = 4m$，总字节数为 $B_{C,1} = s_e\\,(m\\,p_c + 2m + 2)$，其中对于列主序，$p_c = 1$；对于行主序，$p_c = p_s$，$+2$ 用于计算读取和写入 $x_j$。\n\n使用屋顶线模型计算每次迭代的时间：\n- ISTA 一次完整迭代的时间 $T_I = \\max(F_I/P, B_I/\\mathcal{B})$。\n- CD 单坐标更新的时间 $T_{C,1} = \\max(F_{C,1}/P, B_{C,1}/\\mathcal{B})$。\n\n将性能交叉点定义为在一次 ISTA 迭代的时间内可以执行的 CD 坐标更新次数，\n$$\nk^\\star = \\left\\lfloor \\frac{T_I}{T_{C,1}} \\right\\rfloor,\n$$\n如果 $n \\cdot T_{C,1}  T_I$，则声明 CD 的一个轮次（epoch）更快。\n\n实现一个程序，针对每个测试用例计算：\n- 算术强度 $I_C = F_{C,1}/B_{C,1}$ 和 $I_I = F_I/B_I$。\n- 迭代时间 $T_{C,1}$ 和 $T_I$（以秒为单位）。\n- 如上定义的交叉点计数 $k^\\star$。\n- 一个布尔值，指示对所有 $n$ 个坐标进行一次完整的 CD 扫描是否比一次 ISTA 迭代更快。\n\n您的程序必须使用以下测试套件和参数：\n- 测试用例 1：列主序，$m = 5000$，$n = 1000$，$P = 1.0\\times 10^{11}$ FLOPs/s，$\\mathcal{B} = 5.0\\times 10^{10}$ 字节/秒，$L = 64$ 字节，$s_e = 8$ 字节。\n- 测试用例 2：行主序，$m = 5000$，$n = 1000$，$P = 1.0\\times 10^{11}$ FLOPs/s，$\\mathcal{B} = 5.0\\times 10^{10}$ 字节/秒，$L = 64$ 字节，$s_e = 8$ 字节。\n- 测试用例 3：列主序，$m = 200$，$n = 100$，$P = 1.0\\times 10^{11}$ FLOPs/s，$\\mathcal{B} = 5.0\\times 10^{10}$ 字节/秒，$L = 64$ 字节，$s_e = 8$ 字节。\n- 测试用例 4：行主序，$m = 200$，$n = 100$，$P = 1.0\\times 10^{11}$ FLOPs/s，$\\mathcal{B} = 5.0\\times 10^{10}$ 字节/秒，$L = 64$ 字节，$s_e = 8$ 字节。\n- 测试用例 5：列主序，$m = 8000$，$n = 2000$，$P = 1.0\\times 10^{11}$ FLOPs/s，$\\mathcal{B} = 2.0\\times 10^{11}$ 字节/秒，$L = 64$ 字节，$s_e = 8$ 字节。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个条目对应一个测试用例，本身是一个包含六个值的列表，顺序为 $[I_C, I_I, T_{C,1}, T_I, k^\\star, \\text{CD\\_epoch\\_faster}]$。时间必须以秒表示，强度为浮点数。布尔值必须是 $True$ 或 $False$。", "solution": "该问题要求对迭代收缩阈值算法 (ISTA) 和坐标下降法 (CD) 在求解 LASSO 问题时的单次迭代性能进行定量比较。该比较基于一个简化的屋顶线性能模型，该模型同时考虑了计算吞吐量和内存带宽的限制。分析的关键在于为每种算法的浮点运算 (FLOPs) 和内存流量（移动的字节数）进行建模，并特别关注矩阵的存储布局（列主序 vs. 行主序）如何影响内存访问模式，进而影响性能。\n\n首先，我们根据问题陈述确定参数。双精度浮点数的大小为 $s_e = 8$ 字节。缓存行大小为 $L$ 字节。以大于单个元素大小的步幅访问内存会产生惩罚。具体来说，当访问行主序矩阵的一列或列主序矩阵的一行时，每个获取的 $L$ 字节缓存行中只有一个 $s_e$ 字节的元素是有用的。这会产生一个步幅惩罚因子 $p_s = L/s_e$。对于给定的参数 $L=64$ 和 $s_e=8$，该惩罚因子为 $p_s = 64/8 = 8$。连续内存访问，例如流式读取行主序矩阵的一行或列主序矩阵的一列，则不会产生此惩罚。\n\n一次迭代的性能由屋顶线模型预测，其时间 $T$ 是计算所需时间和内存传输所需时间的最大值：\n$$\nT = \\max\\left(\\frac{F}{P}, \\frac{B}{\\mathcal{B}}\\right)\n$$\n这里，$F$ 是总 FLOPs，$B$ 是传输的总字节数，$P$ 是峰值计算速率 (FLOPs/s)，$\\mathcal{B}$ 是持续内存带宽 (bytes/s)。算术强度 $I = F/B$ 衡量计算与内存流量的比率。\n\n让我们为一次完整的 ISTA 迭代性能建模。\n一次 ISTA 迭代主要包括两次矩阵向量乘积，$y = Ax$ 和 $g = A^\\top(Ax-b)$，以及后续的向量运算。问题陈述给出的总 FLOP 计数为：\n$$\nF_I = 4mn\n$$\n总内存流量 $B_I$ 被建模为矩阵遍历和向量运算流量的总和。两次矩阵遍历的流量取决于存储布局。对于 $y=Ax$ 遍历，设惩罚为 $p_y$；对于 $g=A^\\top r$ 遍历（其中 $r=Ax-b$），设惩罚为 $p_g$。总流量由下式给出：\n$$\nB_I = s_e\\,mn\\,(p_y + p_g) + s_e\\,(5m + 5n)\n$$\n- 在**列主序**存储中，访问 $A$ 的列是连续的。$A^\\top r$ 涉及 $A^\\top$ 的行（即 $A$ 的列）与 $r$ 的点积，这是一种连续访问模式。因此，$p_g=1$。相反，$Ax$ 涉及 $A$ 的列的线性组合，但形成输出 $y$ 的每个元素需要访问 $A$ 的一行，这是一种步幅访问。因此，$p_y=p_s$。所以，$(p_y, p_g) = (p_s, 1)$。\n- 在**行主序**存储中，情况相反。$Ax$ 涉及 $A$ 的行与 $x$ 的点积，是一种连续访问模式，所以 $p_y=1$。$A^\\top r$ 需要访问 $A$ 的列，这是步幅访问，所以 $p_g=p_s$。所以，$(p_y, p_g) = (1, p_s)$。\nISTA 的算术强度为 $I_I = F_I / B_I$，迭代时间为 $T_I = \\max(F_I/P, B_I/\\mathcal{B})$。\n\n接下来，我们为 CD 中单次坐标更新的性能建模。\n对坐标 $j$ 的单次更新涉及计算点积 $A_{\\cdot j}^\\top r$ 和更新残差 $r \\leftarrow r - \\delta_j A_{\\cdot j}$。问题给出的 FLOP 计数为：\n$$\nF_{C,1} = 4m\n$$\n内存流量 $B_{C,1}$ 主要由访问列 $A_{\\cdot j}$ 和对残差向量 $r$ 的一次读/写遍历决定。设 $p_c$ 为访问 $A_{\\cdot j}$ 的步幅惩罚。总流量由下式给出：\n$$\nB_{C,1} = s_e\\,(m\\,p_c + 2m + 2)\n$$\n- 在**列主序**存储中，列 $A_{\\cdot j}$ 是连续存储的。因此，$p_c = 1$。\n- 在**行主序**存储中，访问一列需要跨步访问内存，所以 $p_c = p_s$。\n单次 CD 更新的算术强度为 $I_C = F_{C,1} / B_{C,1}$，时间为 $T_{C,1} = \\max(F_{C,1}/P, B_{C,1}/\\mathcal{B})$。\n\n最后，我们定义比较指标。性能交叉点 $k^\\star$ 是在完成一次 ISTA 迭代的时间内可以执行的 CD 坐标更新的次数。它是一个整数值，由下式给出：\n$$\nk^\\star = \\left\\lfloor \\frac{T_I}{T_{C,1}} \\right\\rfloor\n$$\n较大的 $k^\\star$ 表明，与 ISTA 的完整迭代相比，CD 在每次更新的基础上效率更高。我们还评估 CD 对所有 $n$ 个坐标的一次完整遍历（一个“轮次”）是否比一次 ISTA 迭代更快。如果 $n$ 次 CD 更新的总时间小于一次 ISTA 迭代的时间，则此条件为真：\n$$\nn \\cdot T_{C,1}  T_I\n$$\n以下程序为给定的测试用例实现了这些计算，以得出所需的指标：$[I_C, I_I, T_{C,1}, T_I, k^\\star, \\text{CD\\_epoch\\_faster}]$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the performance comparison problem for the given test cases.\n    \"\"\"\n    test_cases = [\n        # (storage, m, n, P, B, L, s_e)\n        ('column-major', 5000, 1000, 1.0e11, 5.0e10, 64, 8),\n        ('row-major', 5000, 1000, 1.0e11, 5.0e10, 64, 8),\n        ('column-major', 200, 100, 1.0e11, 5.0e10, 64, 8),\n        ('row-major', 200, 100, 1.0e11, 5.0e10, 64, 8),\n        ('column-major', 8000, 2000, 1.0e11, 2.0e11, 64, 8),\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        storage, m, n, P, B_bw, L, s_e = case\n        \n        # Calculate stride penalty factor\n        p_s = L / s_e\n\n        # Determine storage-dependent penalties\n        if storage == 'column-major':\n            p_y, p_g = p_s, 1\n            p_c = 1\n        elif storage == 'row-major':\n            p_y, p_g = 1, p_s\n            p_c = p_s\n        else:\n            # This case should not be reached with the given test suite\n            raise ValueError(\"Invalid storage format specified.\")\n\n        # ISTA performance calculation\n        F_I = 4.0 * m * n\n        B_I = s_e * m * n * (p_y + p_g) + s_e * (5 * m + 5 * n)\n        I_I = F_I / B_I if B_I > 0 else 0.0\n        T_I = max(F_I / P, B_I / B_bw)\n\n        # Coordinate Descent (single coordinate) performance calculation\n        F_C1 = 4.0 * m\n        B_C1 = s_e * (m * p_c + 2 * m + 2)\n        I_C = F_C1 / B_C1 if B_C1 > 0 else 0.0\n        T_C1 = max(F_C1 / P, B_C1 / B_bw)\n\n        # Comparative analysis\n        # Crossover count k_star\n        k_star = int(np.floor(T_I / T_C1)) if T_C1 > 0 else float('inf')\n        \n        # CD epoch faster check\n        cd_epoch_faster = (n * T_C1)  T_I\n\n        case_results = [I_C, I_I, T_C1, T_I, k_star, cd_epoch_faster]\n        results.append(str(case_results))\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3436942"}]}