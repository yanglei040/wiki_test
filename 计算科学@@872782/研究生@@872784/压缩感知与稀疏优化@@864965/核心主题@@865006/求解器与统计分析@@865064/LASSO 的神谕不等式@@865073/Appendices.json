{"hands_on_practices": [{"introduction": "我们从一个简化但极具启发性的设定——正交设计——开始，推导 LASSO 的理论保证。这个练习将引导你完成证明一个“神谕”型不等式的基本步骤，将概率噪声界与 LASSO 的估计误差及其正确识别真实潜在变量的能力联系起来。掌握这一推导过程是理解更复杂理论结果的核心直觉所在。[@problem_id:3464166]", "problem": "考虑固定设计线性模型 $y = X \\beta^{\\star} + w$，其中 $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$，$X \\in \\mathbb{R}^{n \\times p}$ 的列经过正交归一化，满足 $X^{\\top} X = n I_{p}$。令 $S = \\operatorname{supp}(\\beta^{\\star})$ 且 $|S| = s$，并定义 $\\beta_{\\min} = \\min_{j \\in S} |\\beta^{\\star}_{j}|$。最小绝对收缩和选择算子 (LASSO) 估计量 $\\hat{\\beta}$ 定义为以下凸规划的任意一个最小化子：\n\n$$\n\\min_{\\beta \\in \\mathbb{R}^{p}} \\ \\frac{1}{2n} \\|y - X \\beta\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1},\n$$\n\n其中 $\\lambda > 0$ 是一个调节参数。令 $\\delta \\in (0, 1)$ 为一个给定的误差概率，并假设除了所述模型和设计之外没有其他结构。\n\n您的任务是从估计量的定义和高斯随机变量的基本概率尾部界出发，然后执行以下步骤：\n\n(1) 定义 $g = \\frac{1}{n} X^{\\top} w$，并使用标准高斯尾部界和联合界来确定最小的值 $\\tau = \\tau(n, p, \\delta, \\sigma)$，使得事件 $\\mathcal{E} = \\{\\|g\\|_{\\infty} \\le \\tau\\}$ 以至少 $1 - \\delta$ 的概率成立，并用 $n$、$p$、$\\delta$ 和 $\\sigma$ 的闭合形式表示。\n\n(2) 通过分析在正交条件 $X^{\\top} X = n I_{p}$ 下 LASSO 的 Karush–Kuhn–Tucker (KKT) 条件，证明在事件 $\\mathcal{E}$ 上，对于任何选择的 $\\lambda \\ge \\tau$，LASSO 估计量可以按坐标简化为阈值为 $\\lambda$ 的软阈值操作。仅使用此简化结果，推导出：\n- 一个形式为 $\\|\\hat{\\beta} - \\beta^{\\star}\\|_{2} \\le C \\sqrt{s} \\lambda$ 的 $\\ell_{2}$-估计不等式，并找出您可以使用基本不等式和 Cauchy–Schwarz 法证明的最小数值常数 $C$。\n- 一个用于精确符号支撑恢复的充分信号强度条件，表示为 $\\beta_{\\min}$ 关于 $\\lambda$ 和 $\\tau$ 的下界，该条件确保在事件 $\\mathcal{E}$ 上，$\\operatorname{supp}(\\hat{\\beta}) = S$ 且 $\\operatorname{sign}(\\hat{\\beta}_{S}) = \\operatorname{sign}(\\beta^{\\star}_{S})$。\n\n(3) 在选择 $\\lambda \\ge \\tau$ 的条件下，优化第 (2) 部分中的充分条件，以获得保证以至少 $1 - \\delta$ 的概率实现精确符号支撑恢复的 $\\beta_{\\min}$ 的最小显式下界。将此最小 $\\beta_{\\min}$ 的最终答案表示为关于 $n$、$p$、$\\delta$ 和 $\\sigma$ 的单个闭合形式解析表达式。\n\n仅报告最小 $\\beta_{\\min}$ 的表达式作为最终答案。不需要数值近似或四舍五入，也不涉及单位。", "solution": "解决方案根据问题陈述中指定的三个任务进行组织。\n\n**(1) 噪声水平阈值 $\\tau$ 的推导**\n\n问题定义了向量 $g = \\frac{1}{n} X^{\\top} w$，其中 $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$。由于 $g$ 是高斯随机向量的线性变换，因此它也是高斯的。我们首先确定其均值和协方差。\n均值为 $E[g] = \\frac{1}{n} X^{\\top} E[w] = \\frac{1}{n} X^{\\top} 0 = 0$。\n协方差矩阵为：\n$$\n\\operatorname{Cov}(g) = E[g g^{\\top}] = E\\left[ \\left(\\frac{1}{n} X^{\\top} w\\right) \\left(\\frac{1}{n} X^{\\top} w\\right)^{\\top} \\right] = \\frac{1}{n^2} X^{\\top} E[w w^{\\top}] X\n$$\n由于 $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$，其协方差为 $E[w w^{\\top}] = \\sigma^2 I_n$。代入此式和给定的设计条件 $X^{\\top} X = n I_{p}$：\n$$\n\\operatorname{Cov}(g) = \\frac{1}{n^2} X^{\\top} (\\sigma^2 I_n) X = \\frac{\\sigma^2}{n^2} (X^{\\top} X) = \\frac{\\sigma^2}{n^2} (n I_p) = \\frac{\\sigma^2}{n} I_p.\n$$\n此结果表明，对于 $j=1, \\dots, p$，分量 $g_j$ 是独立同分布的，且 $g_j \\sim \\mathcal{N}(0, \\sigma^2/n)$。\n\n我们感兴趣的是事件 $\\mathcal{E} = \\{\\|g\\|_{\\infty} \\le \\tau\\}$，其中 $\\|g\\|_{\\infty} = \\max_{j=1,\\dots,p} |g_j|$。我们希望找到最小的 $\\tau$，使得 $P(\\mathcal{E}) \\ge 1 - \\delta$。这等价于确保补事件 $\\mathcal{E}^c = \\{\\|g\\|_{\\infty} > \\tau\\}$ 的概率最多为 $\\delta$。\n补事件可以写成一个并集：$\\mathcal{E}^c = \\bigcup_{j=1}^{p} \\{|g_j| > \\tau\\}$。\n使用联合界，我们有：\n$$\nP(\\mathcal{E}^c) = P\\left(\\bigcup_{j=1}^{p} \\{|g_j| > \\tau\\}\\right) \\le \\sum_{j=1}^{p} P(|g_j| > \\tau) = p \\cdot P(|g_1| > \\tau),\n$$\n其中最后一个等式成立是因为 $g_j$ 是独立同分布的。\n令 $Z$ 为一个标准正态随机变量，$Z \\sim \\mathcal{N}(0, 1)$。那么我们可以写出 $g_1 = \\frac{\\sigma}{\\sqrt{n}} Z$。概率变为：\n$$\nP(|g_1| > \\tau) = P\\left(\\left|\\frac{\\sigma}{\\sqrt{n}} Z\\right| > \\tau\\right) = P\\left(|Z| > \\frac{\\sqrt{n}\\tau}{\\sigma}\\right).\n$$\n对于 $t > 0$，使用标准高斯尾部界 $P(|Z| > t) \\le 2 \\exp(-t^2/2)$，我们得到：\n$$\nP(\\mathcal{E}^c) \\le p \\cdot 2 \\exp\\left(-\\frac{1}{2} \\left(\\frac{\\sqrt{n}\\tau}{\\sigma}\\right)^2\\right) = 2p \\exp\\left(-\\frac{n\\tau^2}{2\\sigma^2}\\right).\n$$\n为确保 $P(\\mathcal{E}^c) \\le \\delta$，我们可以将上界设为 $\\delta$ 并求解 $\\tau$：\n$$\n2p \\exp\\left(-\\frac{n\\tau^2}{2\\sigma^2}\\right) = \\delta\n$$\n$$\n\\exp\\left(-\\frac{n\\tau^2}{2\\sigma^2}\\right) = \\frac{\\delta}{2p}\n$$\n$$\n-\\frac{n\\tau^2}{2\\sigma^2} = \\ln\\left(\\frac{\\delta}{2p}\\right) = -\\ln\\left(\\frac{2p}{\\delta}\\right)\n$$\n$$\n\\tau^2 = \\frac{2\\sigma^2}{n} \\ln\\left(\\frac{2p}{\\delta}\\right)\n$$\n满足该不等式的最小 $\\tau$ 值为：\n$$\n\\tau = \\sigma \\sqrt{\\frac{2 \\ln(2p/\\delta)}{n}}.\n$$\n\n**(2) KKT 条件、软阈值简化及其推论**\n\nLASSO 目标函数为 $L(\\beta) = \\frac{1}{2n} \\|y - X \\beta\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1}$。Karush–Kuhn–Tucker (KKT) 最优性条件指出，向量 $\\hat{\\beta}$ 是一个最小化子，当且仅当零向量位于 $L$ 在 $\\hat{\\beta}$ 处的次梯度中：\n$$\n0 \\in \\nabla_{\\beta} \\left(\\frac{1}{2n} \\|y - X \\hat{\\beta}\\|_{2}^{2}\\right) + \\lambda \\partial\\|\\hat{\\beta}\\|_{1}.\n$$\n二次项的梯度为 $\\frac{1}{n} X^{\\top}(X\\hat{\\beta} - y)$。代入 $y = X\\beta^{\\star} + w$：\n$$\n0 \\in \\frac{1}{n} X^{\\top}(X\\hat{\\beta} - X\\beta^{\\star} - w) + \\lambda \\partial\\|\\hat{\\beta}\\|_{1}\n$$\n$$\n\\frac{1}{n} X^{\\top}w \\in \\frac{1}{n} X^{\\top}X(\\hat{\\beta} - \\beta^{\\star}) + \\lambda \\partial\\|\\hat{\\beta}\\|_{1}.\n$$\n使用定义 $g = \\frac{1}{n} X^{\\top}w$ 和正交条件 $X^{\\top}X = n I_p$，上式简化为：\n$$\ng \\in (\\hat{\\beta} - \\beta^{\\star}) + \\lambda \\partial\\|\\hat{\\beta}\\|_{1} \\quad \\implies \\quad \\beta^{\\star} + g \\in \\hat{\\beta} + \\lambda \\partial\\|\\hat{\\beta}\\|_{1}.\n$$\n这是问题 $\\min_{\\beta} \\frac{1}{2} \\|\\beta - (\\beta^{\\star} + g)\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1}$ 的 KKT 条件，其唯一解由分量软阈值算子 $S_{\\lambda}(\\cdot)$ 给出。因此，对于每个坐标 $j=1, \\dots, p$：\n$$\n\\hat{\\beta}_j = S_{\\lambda}(\\beta^{\\star}_j + g_j) \\equiv \\operatorname{sign}(\\beta^{\\star}_j + g_j) \\max(0, |\\beta^{\\star}_j + g_j| - \\lambda).\n$$\n这表明，在正交设计下，LASSO 估计量简化为对普通最小二乘估计量 $\\beta^{\\star}+g$ 的简单软阈值操作（因为此处 $(X^\\top X)^{-1}X^\\top y = \\frac{1}{n}X^\\top(X\\beta^\\star+w) = \\beta^\\star+g$）。此简化对任何 $\\lambda > 0$ 都成立。\n\n**$\\ell_2$-估计不等式：**\n我们在事件 $\\mathcal{E}$ 上且对于 $\\lambda \\ge \\tau$ 分析估计误差 $\\Delta = \\hat{\\beta} - \\beta^{\\star}$。\n每个坐标的误差为 $\\Delta_j = \\hat{\\beta}_j - \\beta^{\\star}_j = S_{\\lambda}(\\beta^{\\star}_j + g_j) - \\beta^{\\star}_j$。\n对于 $j \\in S^c$（非支撑集），$\\beta^{\\star}_j = 0$。在事件 $\\mathcal{E}$ 上，我们有 $|g_j| \\le \\|g\\|_{\\infty} \\le \\tau$。由于我们选择了 $\\lambda \\ge \\tau$，我们有 $|g_j| \\le \\lambda$。软阈值算子给出 $\\hat{\\beta}_j = S_{\\lambda}(g_j) = 0$。因此，对于所有 $j \\in S^c$，$\\Delta_j = 0 - 0 = 0$。\n因此，总平方误差为 $\\|\\hat{\\beta} - \\beta^{\\star}\\|_{2}^2 = \\sum_{j \\in S} (\\hat{\\beta}_j - \\beta^{\\star}_j)^2$。\n对于任何 $z$，一个已知性质是 $|S_{\\lambda}(z) - z| \\le \\lambda$。令 $u_j = \\beta^{\\star}_j + g_j$。那么 $\\hat{\\beta}_j = S_{\\lambda}(u_j)$，我们可以将误差写为 $\\Delta_j = S_{\\lambda}(u_j) - (u_j - g_j) = (S_{\\lambda}(u_j) - u_j) + g_j$。\n根据三角不等式，有 $|\\Delta_j| \\le |S_{\\lambda}(u_j) - u_j| + |g_j|$。\n在事件 $\\mathcal{E}$ 上使用 $|S_{\\lambda}(u_j) - u_j| \\le \\lambda$ 和 $|g_j| \\le \\tau$，我们有：\n$|\\Delta_j| \\le \\lambda + \\tau$。\n在条件 $\\lambda \\ge \\tau$ 下，这意味着 $|\\Delta_j| \\le \\lambda + \\lambda = 2\\lambda$。\n对支撑集 $S$ 上的平方求和：\n$$\n\\|\\hat{\\beta} - \\beta^{\\star}\\|_{2}^2 = \\sum_{j \\in S} \\Delta_j^2 \\le \\sum_{j \\in S} (2\\lambda)^2 = s(4\\lambda^2).\n$$\n取平方根得到 $\\ell_2$-估计不等式：\n$$\n\\|\\hat{\\beta} - \\beta^{\\star}\\|_{2} \\le 2\\sqrt{s}\\lambda.\n$$\n从这个推导中，我们可以证明的最小常数是 $C=2$。\n\n**精确符号支撑恢复的充分条件：**\n我们需要两个条件成立：\n(a) 对于所有 $j \\in S^c$，$\\hat{\\beta}_j = 0$。\n(b) 对于所有 $j \\in S$，$\\operatorname{sign}(\\hat{\\beta}_j) = \\operatorname{sign}(\\beta^{\\star}_j)$。\n\n条件 (a)：对于 $j \\in S^c$，$\\beta^{\\star}_j = 0$，所以 $\\hat{\\beta}_j = S_{\\lambda}(g_j)$。我们需要 $S_{\\lambda}(g_j) = 0$，这当且仅当 $|g_j| \\le \\lambda$ 时成立。在事件 $\\mathcal{E}$ 上，我们有 $|g_j| \\le \\tau$。因此，选择任何 $\\lambda \\ge \\tau$ 是条件 (a) 在 $\\mathcal{E}$ 上成立的充分条件。\n\n条件 (b)：对于 $j \\in S$，$\\beta^{\\star}_j \\ne 0$。我们需要 $\\operatorname{sign}(S_{\\lambda}(\\beta^{\\star}_j + g_j)) = \\operatorname{sign}(\\beta^{\\star}_j)$。如果 $\\operatorname{sign}(\\beta^{\\star}_j + g_j) = \\operatorname{sign}(\\beta^{\\star}_j)$ 且 $|\\beta^{\\star}_j + g_j| > \\lambda$，则此条件成立。\n两者的一个充分条件是 $|\\beta^{\\star}_j| - |g_j| > \\lambda$。这是因为如果这个不等式成立，那么 $|g_j|  |\\beta^{\\star}_j|$，这确保了 $\\beta^{\\star}_j + g_j$ 与 $\\beta^{\\star}_j$ 具有相同的符号。此外，根据反三角不等式，有 $|\\beta^{\\star}_j + g_j| \\ge |\\beta^{\\star}_j| - |g_j|  \\lambda$。\n为确保此条件在事件 $\\mathcal{E}$ 上对所有 $j \\in S$ 都成立，我们必须防范最坏情况下的噪声配置，即 $|g_j|$ 达到最大值，即 $|g_j| = \\tau$。该条件变为 $|\\beta^{\\star}_j| - \\tau  \\lambda$，或 $|\\beta^{\\star}_j|  \\lambda + \\tau$。\n这必须对所有 $j \\in S$ 都成立。这种最弱的条件适用于支撑集上最小的系数：$\\min_{j \\in S} |\\beta^{\\star}_j|  \\lambda + \\tau$。\n这正是 $\\beta_{\\min}  \\lambda + \\tau$。\n\n总而言之，在事件 $\\mathcal{E}$ 上，条件 $\\lambda \\ge \\tau$ 和 $\\beta_{\\min}  \\lambda + \\tau$ 是精确符号支撑恢复的充分条件。\n\n**(3) 支撑恢复的最小信号强度**\n\n我们寻求 $\\beta_{\\min}$ 的最小下界，以保证以至少 $1-\\delta$ 的概率实现精确符号支撑恢复。这发生在事件 $\\mathcal{E}$ 上。推导出的充分条件是 $\\beta_{\\min}  \\lambda + \\tau$，并且它要求我们选择一个调节参数 $\\lambda$ 使得 $\\lambda \\ge \\tau$。\n我们可以自由选择 $\\lambda$。为了获得对 $\\beta_{\\min}$ 的最不严格的条件（即最小的下界），我们应该在约束条件 $\\lambda \\ge \\tau$ 下，关于 $\\lambda$ 最小化 $\\lambda+\\tau$。\n函数 $f(\\lambda) = \\lambda + \\tau$ 在 $\\lambda$ 上是单调递增的。因此，它在定义域 $[\\tau, \\infty)$ 上的最小值在下边界 $\\lambda = \\tau$ 处取得。\n将 $\\lambda = \\tau$ 代入关于 $\\beta_{\\min}$ 的条件，我们得到优化后的充分条件：\n$$\n\\beta_{\\min}  \\tau + \\tau = 2\\tau.\n$$\n因此，$\\beta_{\\min}$ 的最小显式下界是 $2\\tau$。将第 (1) 部分中 $\\tau$ 的表达式代入，得到最终答案：\n$$\n\\beta_{\\min}  2 \\sigma \\sqrt{\\frac{2 \\ln(2p/\\delta)}{n}}.\n$$\n此下界的最小值是右侧的表达式。", "answer": "$$\n\\boxed{2\\sigma \\sqrt{\\frac{2 \\ln\\left(\\frac{2p}{\\delta}\\right)}{n}}}\n$$", "id": "3464166"}, {"introduction": "为什么像兼容性常数这样的几何条件对于可靠的变量选择是必要的？本问题通过构建一个预测变量相关性导致不良行为的场景，给出了一个惊人的答案。通过追踪 LASSO 的解路径，你将发现一个临界点，在该点算法会同时丢弃一个真实预测变量并加入一个虚假预测变量，这表明 LASSO 的变量选择并非总是嵌套或单调的。[@problem_id:3464165]", "problem": "考虑线性模型 $y = X \\beta^{\\star} + \\varepsilon$，其中设计矩阵为 $X \\in \\mathbb{R}^{n \\times p}$，$X$的列经过标准化，使得 $\\frac{1}{n} X^{\\top} X = \\Sigma$。在研究最小绝对收缩和选择算子 (LASSO) 时，Oracle 不等式涉及到由支撑集 $S \\subseteq \\{1, \\dots, p\\}$ 和锥约束所编码的几何结构。令 $p = 3$ 并假设经验格拉姆矩阵满足\n$$\n\\Sigma = \\begin{pmatrix}\n1  \\rho  0 \\\\\n\\rho  1  0 \\\\\n0  0  1\n\\end{pmatrix},\n$$\n其中相关系数为 $0 \\le \\rho  1$，并考虑支撑集 $S = \\{1, 2\\}$。由不等式 $\\|v_{S^{c}}\\|_{1} \\leq L \\|v_{S}\\|_{1}$ 定义锥 $C(S)$，其中 $L = 1$，$v \\in \\mathbb{R}^{p}$ 且 $S^{c}$ 表示 $S$ 的补集。与 $S$ 和锥 $C(S)$ 相关联的相容性常数为\n$$\n\\phi_{\\mathrm{comp}}(S) := \\inf_{v \\in C(S) \\setminus \\{0\\}} \\frac{\\sqrt{|S|} \\, \\sqrt{v^{\\top} \\Sigma v}}{\\|v_{S}\\|_{1}}.\n$$\n求 $\\phi_{\\mathrm{comp}}(S)$ 关于 $\\rho$ 的精确闭式表达式。请将最终答案表示为单个简化的解析表达式。", "solution": "问题要求计算在给定支撑集 $S$、格拉姆矩阵 $\\Sigma$ 和锥约束下的相容性常数 $\\phi_{\\mathrm{comp}}(S)$。\n\n相容性常数的定义如下：\n$$\n\\phi_{\\mathrm{comp}}(S) := \\inf_{v \\in C(S) \\setminus \\{0\\}} \\frac{\\sqrt{|S|} \\, \\sqrt{v^{\\top} \\Sigma v}}{\\|v_{S}\\|_{1}}\n$$\n已知条件如下：\n- 维数 $p=3$。\n- 支撑集 $S = \\{1, 2\\}$，所以其基数为 $|S|=2$。其补集为 $S^c = \\{3\\}$。\n- 对于向量 $v = (v_1, v_2, v_3)^{\\top} \\in \\mathbb{R}^3$，支撑集上的子向量为 $v_S = (v_1, v_2)^{\\top}$，其补集上的子向量为 $v_{S^c} = (v_3)$。\n- 相关范数为 $\\ell_1$-范数：$\\|v_S\\|_1 = |v_1| + |v_2|$ 和 $\\|v_{S^c}\\|_1 = |v_3|$。\n- 锥 $C(S)$ 由不等式 $\\|v_{S^c}\\|_1 \\leq L \\|v_S\\|_1$ 定义，其中 $L=1$，可简化为 $|v_3| \\leq |v_1| + |v_2|$。\n- 经验格拉姆矩阵为 $\\Sigma = \\begin{pmatrix} 1  \\rho  0 \\\\ \\rho  1  0 \\\\ 0  0  1 \\end{pmatrix}$，其中 $0 \\le \\rho  1$。\n\n我们来展开二次型 $v^{\\top} \\Sigma v$：\n$$\nv^{\\top} \\Sigma v = \\begin{pmatrix} v_1  v_2  v_3 \\end{pmatrix} \\begin{pmatrix} 1  \\rho  0 \\\\ \\rho  1  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} v_1 \\\\ v_2 \\\\ v_3 \\end{pmatrix} = v_1^2 + v_2^2 + 2\\rho v_1 v_2 + v_3^2\n$$\n将已知值代入相容性常数的定义中，我们得到：\n$$\n\\phi_{\\mathrm{comp}}(S) = \\inf_{v \\in C(S) \\setminus \\{0\\}} \\frac{\\sqrt{2} \\sqrt{v_1^2 + v_2^2 + 2\\rho v_1 v_2 + v_3^2}}{|v_1| + |v_2|}\n$$\n待最小化的表达式是关于 $v$ 的零次齐次式。也就是说，对于任何非零标量 $c$，若将 $v$替换为 $cv$，表达式的值保持不变。这使我们可以通过对 $v$ 施加一个归一化约束来简化问题。一个方便的选择是将搜索范围约束在满足 $\\|v_S\\|_1 = |v_1| + |v_2| = 1$ 的向量 $v$上。在 $v \\in C(S) \\setminus \\{0\\}$ 上的下确界与在子集 $\\|v_S\\|_1 = 1$ 上的下确界相同。\n\n在该约束下，问题变为在以下条件下求 $\\phi_{\\mathrm{comp}}(S) = \\inf \\sqrt{2(v_1^2 + v_2^2 + 2\\rho v_1 v_2 + v_3^2)}$：\n1. $|v_1| + |v_2| = 1$\n2. $|v_3| \\leq |v_1| + |v_2|$，即 $|v_3| \\leq 1$。\n\n求函数的下确界等价于求其平方的下确界。我们来求 $\\phi_{\\mathrm{comp}}(S)^2$ 的最小值：\n$$\n\\phi_{\\mathrm{comp}}(S)^2 = \\inf \\left\\{ 2(v_1^2 + v_2^2 + 2\\rho v_1 v_2 + v_3^2) \\right\\}\n$$\n约束条件为 $|v_1|+|v_2|=1$ 和 $|v_3| \\leq 1$。\n\n为了最小化此表达式，我们应选择 $v_3$ 使 $v_3^2$ 项尽可能小。由于 $v_3^2 \\ge 0$，其最小值为 $0$，在 $v_3=0$ 时取到。这个选择满足约束 $|v_3| \\leq 1$。\n因此，问题简化为一个低维优化问题：\n$$\n\\phi_{\\mathrm{comp}}(S)^2 = \\inf_{|v_1|+|v_2|=1} \\left\\{ 2(v_1^2 + v_2^2 + 2\\rho v_1 v_2) \\right\\}\n$$\n我们来分析二次型 $f(v_1, v_2) = v_1^2 + v_2^2 + 2\\rho v_1 v_2$。它可以写成矩阵形式 $v_S^{\\top} \\Sigma_S v_S$，其中 $\\Sigma_S$ 是 $\\Sigma$ 中对应于 $S$ 中索引的主子矩阵：\n$$\n\\Sigma_S = \\begin{pmatrix} 1  \\rho \\\\ \\rho  1 \\end{pmatrix}\n$$\n约束 $|v_1| + |v_2| = 1$ 在 $(v_1,v_2)$ 平面上定义了一个正方形，其顶点为 $(1,0), (0,1), (-1,0), (0,-1)$。\n\n为了找到 $v_S^{\\top} \\Sigma_S v_S$ 在这个正方形上的最小值，我们可以对 $\\Sigma_S$ 进行对角化。$\\Sigma_S$ 的特征值 $\\lambda$ 由特征方程 $(1-\\lambda)^2 - \\rho^2 = 0$ 给出，解得 $1-\\lambda = \\pm\\rho$，所以 $\\lambda_1 = 1+\\rho$ 和 $\\lambda_2 = 1-\\rho$。对应的归一化特征向量为：\n- 对于 $\\lambda_1 = 1+\\rho$：$e_1 = \\frac{1}{\\sqrt{2}}(1, 1)^{\\top}$\n- 对于 $\\lambda_2 = 1-\\rho$：$e_2 = \\frac{1}{\\sqrt{2}}(1, -1)^{\\top}$\n\n任何向量 $v_S = (v_1, v_2)^{\\top}$ 都可以在该特征基中表示为 $v_S = c_1 e_1 + c_2 e_2$。二次型变为：\n$$\nv_S^{\\top} \\Sigma_S v_S = (c_1 e_1 + c_2 e_2)^{\\top} \\Sigma_S (c_1 e_1 + c_2 e_2) = c_1^2 \\lambda_1 + c_2^2 \\lambda_2 = c_1^2 (1+\\rho) + c_2^2 (1-\\rho)\n$$\n我们需要用 $c_1$ 和 $c_2$ 来表示约束 $\\|v_S\\|_1 = 1$。\n由 $v_S = c_1 e_1 + c_2 e_2$ 可得：\n$v_1 = \\frac{c_1}{\\sqrt{2}} + \\frac{c_2}{\\sqrt{2}}$ 和 $v_2 = \\frac{c_1}{\\sqrt{2}} - \\frac{c_2}{\\sqrt{2}}$。\n约束变为：\n$$\n|\\frac{c_1}{\\sqrt{2}} + \\frac{c_2}{\\sqrt{2}}| + |\\frac{c_1}{\\sqrt{2}} - \\frac{c_2}{\\sqrt{2}}| = 1\n$$\n使用恒等式 $|a+b| + |a-b| = 2\\max(|a|,|b|)$，并令 $a=c_1/\\sqrt{2}$ 和 $b=c_2/\\sqrt{2}$，我们得到：\n$$\n\\frac{1}{\\sqrt{2}} ( |c_1+c_2| + |c_1-c_2| ) = \\frac{2}{\\sqrt{2}} \\max(|c_1|, |c_2|) = \\sqrt{2} \\max(|c_1|, |c_2|) = 1\n$$\n所以，$c_1, c_2$ 上的约束为 $\\max(|c_1|, |c_2|) = \\frac{1}{\\sqrt{2}}$。这描述了 $(c_1, c_2)$ 平面上的一个正方形。\n\n我们的问题现在是在约束 $\\max(|c_1|, |c_2|) = \\frac{1}{\\sqrt{2}}$ 下最小化 $g(c_1, c_2) = c_1^2(1+\\rho) + c_2^2(1-\\rho)$。\n由于给定 $0 \\le \\rho  1$，系数 $(1+\\rho)$ 和 $(1-\\rho)$ 均为正。此外，$(1+\\rho) \\geq (1-\\rho)$。\n为了最小化 $g(c_1, c_2)$，我们应该使具有较大系数的项 $c_1^2(1+\\rho)$ 尽可能小，而具有较小系数的项 $c_2^2(1-\\rho)$ 可能较大。\n在约束集上 $|c_1|$ 的最小值为 $0$。为了满足 $\\max(|c_1|, |c_2|) = \\frac{1}{\\sqrt{2}}$，这迫使 $|c_2|$ 必须为 $\\frac{1}{\\sqrt{2}}$。\n因此，在 $(c_1, c_2) = (0, \\pm \\frac{1}{\\sqrt{2}})$ 处取得最小值。\n\n二次型 $v_S^{\\top} \\Sigma_S v_S$ 的最小值为：\n$$\n\\min (v_S^{\\top} \\Sigma_S v_S) = 0^2(1+\\rho) + \\left(\\pm \\frac{1}{\\sqrt{2}}\\right)^2 (1-\\rho) = \\frac{1}{2}(1-\\rho)\n$$\n现在，我们将此结果代回 $\\phi_{\\mathrm{comp}}(S)^2$ 的表达式中：\n$$\n\\phi_{\\mathrm{comp}}(S)^2 = 2 \\times \\min_{|v_1|+|v_2|=1} (v_1^2 + v_2^2 + 2\\rho v_1 v_2) = 2 \\times \\frac{1-\\rho}{2} = 1-\\rho\n$$\n开平方根即可得到相容性常数：\n$$\n\\phi_{\\mathrm{comp}}(S) = \\sqrt{1-\\rho}\n$$\n由于在给定的 $\\rho$ 范围内 $1-\\rho > 0$，因此该表达式是良定义的。", "answer": "$$\n\\boxed{\\sqrt{1-\\rho}}\n$$", "id": "3464165"}, {"introduction": "为什么像兼容性常数这样的几何条件对于可靠的变量选择是必要的？本问题通过构建一个预测变量相关性导致不良行为的场景，给出了一个惊人的答案。通过追踪 LASSO 的解路径，你将发现一个临界点，在该点算法会同时丢弃一个真实预测变量并加入一个虚假预测变量，这表明 LASSO 的变量选择并非总是嵌套或单调的。[@problem_id:3484723]", "problem": "考虑由以下优化问题定义的最小绝对收缩和选择算子 (LASSO) 估计量\n$$\n\\hat{\\beta}(\\lambda) \\in \\arg\\min_{\\beta \\in \\mathbb{R}^{3}} \\left\\{ \\frac{1}{2}\\|y - X\\beta\\|_{2}^{2} + \\lambda \\|\\beta\\|_{1} \\right\\},\n$$\n其中设计矩阵 $X \\in \\mathbb{R}^{3 \\times 3}$ 具有单位范数列 $x_{1}, x_{2}, x_{3}$，由下式给出\n$$\nx_{1} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}, \\quad x_{3} = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{\\sqrt{3}}{2} \\\\ 0 \\end{pmatrix}, \\quad x_{2} = \\begin{pmatrix} \\frac{7}{10} \\\\ \\frac{9}{10\\sqrt{3}} \\\\ \\frac{\\sqrt{6}}{5} \\end{pmatrix}.\n$$\n设响应向量 $y \\in \\mathbb{R}^{3}$ 由支撑在索引 $\\{1,3\\}$ 上且系数为正的稀疏真实信号生成：\n$$\ny = \\frac{8}{15} x_{1} + \\frac{14}{15} x_{3}.\n$$\n此构造得出经验内积\n$$\nx_{1}^{\\top} x_{3} = \\frac{1}{2}, \\quad x_{1}^{\\top} x_{2} = \\frac{7}{10}, \\quad x_{2}^{\\top} x_{3} = \\frac{4}{5},\n$$\n以及与响应的相关性\n$$\nx_{1}^{\\top} y = 1, \\quad x_{3}^{\\top} y = \\frac{6}{5}, \\quad x_{2}^{\\top} y = \\frac{28}{25}.\n$$\n分析当 $\\lambda$ 从 $0$ 开始增加时 LASSO 路径 $\\hat{\\beta}(\\lambda)$ 的变化，假设初始活动集为 $\\{1,3\\}$ 且系数为正，并且非活动索引 $2$ 满足次梯度最优性条件。使用第一性原理（LASSO 的最优性条件和在固定活动集上路径的线性），确定精确的临界正则化水平 $\\lambda^{\\star}$。在该水平下，增加 $\\lambda$ 会同时导致两个事件发生：索引为 $1$ 的真实变量的系数恰好变为零，并且索引为 $2$ 的非活动伪变量在其次梯度最优性条件中以正号达到等式，从而进入活动集。\n\n请以精确既约分数的形式给出 $\\lambda^{\\star}$ 的最终答案。无需四舍五入，且不使用单位。", "solution": "LASSO 问题的一阶最优性条件 (Karush-Kuhn-Tucker 条件) 指出，在解 $\\hat{\\beta}(\\lambda)$ 处，零向量必须位于目标函数的次梯度中。这意味着：\n$$\n-X^{\\top}(y - X\\hat{\\beta}(\\lambda)) + \\lambda g = 0\n$$\n其中 $g$ 是一个向量，满足当 $\\hat{\\beta}_j(\\lambda) \\neq 0$ 时，$g_j = \\mathrm{sign}(\\hat{\\beta}_j(\\lambda))$，当 $\\hat{\\beta}_j(\\lambda) = 0$ 时，$g_j \\in [-1, 1]$。\n设 $S$ 为 $\\hat{\\beta}_j(\\lambda) \\neq 0$ 的索引 $j$ 的活动集。最优性条件可以写成：\n\\begin{enumerate}\n    \\item 对于 $j \\in S$，$x_j^{\\top}(y - X\\hat{\\beta}(\\lambda)) = \\lambda \\cdot \\mathrm{sign}(\\hat{\\beta}_j(\\lambda))$。\n    \\item 对于 $j \\notin S$，$|x_j^{\\top}(y - X\\hat{\\beta}(\\lambda))| \\le \\lambda$。\n\\end{enumerate}\n问题指出，对于接近 0 的 $\\lambda$，活动集为 $S = \\{1, 3\\}$，且 $\\hat{\\beta}_1(\\lambda)  0$ 和 $\\hat{\\beta}_3(\\lambda)  0$。对于这段 LASSO 路径，$\\hat{\\beta}_2(\\lambda)=0$，解向量为 $\\hat{\\beta}(\\lambda) = (\\hat{\\beta}_1(\\lambda), 0, \\hat{\\beta}_3(\\lambda))^{\\top}$。我们可以写成 $X\\hat{\\beta}(\\lambda) = X_S \\hat{\\beta}_S(\\lambda)$，其中 $X_S = [x_1, x_3]$ 且 $\\hat{\\beta}_S(\\lambda) = (\\hat{\\beta}_1(\\lambda), \\hat{\\beta}_3(\\lambda))^{\\top}$。\n\n活动集的 KKT 条件变为：\n$$\nX_S^{\\top} (y - X_S \\hat{\\beta}_S(\\lambda)) = \\lambda s_S\n$$\n其中 $s_S = (\\mathrm{sign}(\\hat{\\beta}_1(\\lambda)), \\mathrm{sign}(\\hat{\\beta}_3(\\lambda)))^{\\top} = (1, 1)^{\\top}$。\n对 $\\hat{\\beta}_S(\\lambda)$ 进行整理：\n$$\n(X_S^{\\top} X_S) \\hat{\\beta}_S(\\lambda) = X_S^{\\top} y - \\lambda s_S\n$$\n$$\n\\hat{\\beta}_S(\\lambda) = (X_S^{\\top} X_S)^{-1} (X_S^{\\top} y - \\lambda s_S)\n$$\n这证明了对于固定的活动集和符号模式，解路径相对于 $\\lambda$ 是线性的。我们来计算必要的矩阵。\n活动集 $S=\\{1,3\\}$ 的格拉姆子矩阵是：\n$$\nG_S = X_S^{\\top} X_S = \\begin{pmatrix} x_1^{\\top}x_1  x_1^{\\top}x_3 \\\\ x_3^{\\top}x_1  x_3^{\\top}x_3 \\end{pmatrix} = \\begin{pmatrix} 1  \\frac{1}{2} \\\\ \\frac{1}{2}  1 \\end{pmatrix}\n$$\n其逆矩阵是：\n$$\nG_S^{-1} = \\frac{1}{1 - (\\frac{1}{2})^2} \\begin{pmatrix} 1  -\\frac{1}{2} \\\\ -\\frac{1}{2}  1 \\end{pmatrix} = \\frac{1}{\\frac{3}{4}} \\begin{pmatrix} 1  -\\frac{1}{2} \\\\ -\\frac{1}{2}  1 \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{3}  -\\frac{2}{3} \\\\ -\\frac{2}{3}  \\frac{4}{3} \\end{pmatrix}\n$$\n与响应的相关性向量是：\n$$\nc_S = X_S^{\\top} y = \\begin{pmatrix} x_1^{\\top}y \\\\ x_3^{\\top}y \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\frac{6}{5} \\end{pmatrix}\n$$\n现在我们可以写出 $\\hat{\\beta}_S(\\lambda)$ 的显式解路径：\n$$\n\\begin{pmatrix} \\hat{\\beta}_1(\\lambda) \\\\ \\hat{\\beta}_3(\\lambda) \\end{pmatrix} = \\begin{pmatrix} \\frac{4}{3}  -\\frac{2}{3} \\\\ -\\frac{2}{3}  \\frac{4}{3} \\end{pmatrix} \\left( \\begin{pmatrix} 1 \\\\ \\frac{6}{5} \\end{pmatrix} - \\lambda \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix} \\right) = \\begin{pmatrix} \\frac{4}{3}  -\\frac{2}{3} \\\\ -\\frac{2}{3}  \\frac{4}{3} \\end{pmatrix} \\begin{pmatrix} 1 - \\lambda \\\\ \\frac{6}{5} - \\lambda \\end{pmatrix}\n$$\n我们计算 $\\hat{\\beta}_1(\\lambda)$ 的表达式：\n$$\n\\hat{\\beta}_1(\\lambda) = \\frac{4}{3}(1 - \\lambda) - \\frac{2}{3}\\left(\\frac{6}{5} - \\lambda\\right) = \\frac{4}{3} - \\frac{4}{3}\\lambda - \\frac{12}{15} + \\frac{2}{3}\\lambda = \\left(\\frac{4}{3} - \\frac{4}{5}\\right) - \\left(\\frac{4}{3} - \\frac{2}{3}\\right)\\lambda = \\frac{20-12}{15} - \\frac{2}{3}\\lambda = \\frac{8}{15} - \\frac{2}{3}\\lambda\n$$\n以及 $\\hat{\\beta}_3(\\lambda)$ 的表达式：\n$$\n\\hat{\\beta}_3(\\lambda) = -\\frac{2}{3}(1 - \\lambda) + \\frac{4}{3}\\left(\\frac{6}{5} - \\lambda\\right) = -\\frac{2}{3} + \\frac{2}{3}\\lambda + \\frac{24}{15} - \\frac{4}{3}\\lambda = \\left(\\frac{8}{5} - \\frac{2}{3}\\right) - \\left(\\frac{4}{3} - \\frac{2}{3}\\right)\\lambda = \\frac{24-10}{15} - \\frac{2}{3}\\lambda = \\frac{14}{15} - \\frac{2}{3}\\lambda\n$$\n问题指明 $\\lambda^{\\star}$ 是 $\\hat{\\beta}_1(\\lambda)$ 变为零的点。我们求解这个值：\n$$\n\\hat{\\beta}_1(\\lambda^{\\star}) = \\frac{8}{15} - \\frac{2}{3}\\lambda^{\\star} = 0 \\implies \\frac{2}{3}\\lambda^{\\star} = \\frac{8}{15} \\implies \\lambda^{\\star} = \\frac{8}{15} \\cdot \\frac{3}{2} = \\frac{4}{5}\n$$\n这给了我们临界正则化水平的候选值，$\\lambda^{\\star} = \\frac{4}{5}$。此时，在 $S=\\{1,3\\}$ 上定义的路径终止。我们现在必须验证第二个条件在此值下是否也满足。\n\n第二个条件是，非活动变量 2 以正号进入模型，即 $x_2^{\\top}(y - X\\hat{\\beta}(\\lambda^{\\star})) = \\lambda^{\\star}$。\n首先，我们需要完整的解向量 $\\hat{\\beta}(\\lambda^{\\star})$。在 $\\lambda^{\\star} = \\frac{4}{5}$ 时，我们有：\n根据定义，$\\hat{\\beta}_1(\\lambda^{\\star}) = 0$。\n$\\hat{\\beta}_2(\\lambda^{\\star}) = 0$ 因为在通往此点的路径上它一直是非活动的。\n$\\hat{\\beta}_3(\\lambda^{\\star}) = \\frac{14}{15} - \\frac{2}{3}\\lambda^{\\star} = \\frac{14}{15} - \\frac{2}{3} \\cdot \\frac{4}{5} = \\frac{14}{15} - \\frac{8}{15} = \\frac{6}{15} = \\frac{2}{5}$。\n所以，在临界点处的解向量为 $\\hat{\\beta}(\\lambda^{\\star}) = (0, 0, \\frac{2}{5})^{\\top}$。\n\n现在，我们使用这个解向量和 $\\lambda^{\\star}=\\frac{4}{5}$ 来检验第二个条件：\n$$\nx_2^{\\top}(y - X\\hat{\\beta}(\\lambda^{\\star})) = x_2^{\\top}\\left(y - x_3\\hat{\\beta}_3(\\lambda^{\\star})\\right) = x_2^{\\top}y - (x_2^{\\top}x_3)\\hat{\\beta}_3(\\lambda^{\\star})\n$$\n代入给定的值和我们计算出的系数：\n$$\nx_2^{\\top}y - (x_2^{\\top}x_3)\\hat{\\beta}_3(\\lambda^{\\star}) = \\frac{28}{25} - \\left(\\frac{4}{5}\\right)\\left(\\frac{2}{5}\\right) = \\frac{28}{25} - \\frac{8}{25} = \\frac{20}{25} = \\frac{4}{5}\n$$\n我们必须检查这是否等于 $\\lambda^{\\star}$。确实，$\\frac{4}{5} = \\lambda^{\\star}$。\n条件得到满足。由于两个事件——$\\hat{\\beta}_1(\\lambda)$ 达到零以及变量 2 满足以正号进入活动集的标准——在相同的 $\\lambda$ 值处发生，我们已经找到了所需的临界水平。\n\n因此，精确的临界正则化水平是 $\\lambda^{\\star} = \\frac{4}{5}$。", "answer": "$$\n\\boxed{\\frac{4}{5}}\n$$", "id": "3484723"}]}