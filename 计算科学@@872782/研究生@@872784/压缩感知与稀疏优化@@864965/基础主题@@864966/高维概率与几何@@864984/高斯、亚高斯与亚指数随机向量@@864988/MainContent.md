## 引言
在[高维数据](@entry_id:138874)科学的浪潮中，从机器学习、信号处理到统计推断，理解和建模随机性是所有理论分析与算法设计的基石。其中，高斯、亚[高斯和](@entry_id:196588)亚指数随机向量构成了描述这种随机性的核心[概率模型](@entry_id:265150)。[高斯分布](@entry_id:154414)因其优美的数学性质而广为人知，但现实世界中的许多随机现象——例如有界[测量误差](@entry_id:270998)或突发性噪声——虽然并非严格高斯，却表现出类似的“轻尾”或可控的“[重尾](@entry_id:274276)”行为。

本文旨在系统地阐明这些超越经典高斯框架的关键概念。我们将填补从直观理解到严格数学刻画之间的鸿沟，揭示这些随机向量类别的内在联系与本质区别。通过学习本文，读者将不仅掌握它们的定义，更能洞悉其背后强大的集[中性原理](@entry_id:265361)，这是分析几乎所有高维随机算法性能的必备武器。

文章将引导读者踏上一条从理论到实践的清晰路径。在**“原理与机制”**一章，我们将深入这些随机向量的定义、等价刻画以及以Hanson-Wright不等式为代表的关键分析工具。随后，**“应用与[交叉](@entry_id:147634)学科联系”**一章将展示这些理论如何在压缩感知、稳健统计和[高维推断](@entry_id:750277)等前沿领域中解决实际问题，彰显其跨学科的强大威力。最后，**“动手实践”**部分将提供精选的计算和编程练习，帮助读者将抽象的理论知识转化为解决问题的具体技能。这种结构化的学习体验将为您驾驭[高维数据](@entry_id:138874)分析中的随机性提供坚实的理论与实践基础。

## 原理与机制

本章在前一章介绍的背景之上，深入探讨高斯、亚[高斯和](@entry_id:196588)亚指数随机向量的核心原理与关键机制。我们将从这些[随机变量](@entry_id:195330)的基本定义出发，阐明它们的等价刻画，并揭示它们之间深刻的内在联系。随后，我们将聚焦于它们最重要的特性——集中性，并介绍一系列强大的不等式工具，这些工具是分析[高维数据](@entry_id:138874)和随机算法的基石。最后，我们将展示这些理论如何在压缩感知和[高维统计](@entry_id:173687)等前沿领域中发挥作用，用以建立严格的性能保证。

### 亚高斯与[亚指数随机变量](@entry_id:755583)的定义

在概率论和统计学中，**高斯（Gaussian）[随机变量](@entry_id:195330)**（或称正态[随机变量](@entry_id:195330)）因其优美的数学性质和在中心极限定理中的核心地位而无处不在。一个标准正态[随机变量](@entry_id:195330) $Z \sim \mathcal{N}(0, 1)$ 的[矩生成函数](@entry_id:154347)（Moment Generating Function, MGF）为 $M_Z(\lambda) = \mathbb{E}[\exp(\lambda Z)] = \exp(\lambda^2/2)$。这个指数二次方的形式暗示了其尾部概率以超指数速率衰减，即 $P(|Z| > t) \le 2\exp(-t^2/2)$。这种快速衰减的尾部行为是许多理想性质的根源。

然而，在实际应用中，我们遇到的许多[随机变量](@entry_id:195330)并非严格服从[高斯分布](@entry_id:154414)，但可能表现出类似的“轻尾”特性。这就引出了**亚高斯（sub-gaussian）[随机变量](@entry_id:195330)**的概念，它旨在将[高斯变量](@entry_id:276673)的优良性质推广到一个更广泛的类别。

#### 亚高斯[随机变量](@entry_id:195330)

一个[随机变量](@entry_id:195330) $X$ 被称为[亚高斯变量](@entry_id:755587)，如果它的尾部衰减速度至少和某个[高斯变量](@entry_id:276673)一样快。这个概念有多种等价的定义，其中基于[矩生成函数](@entry_id:154347)（MGF）的定义在数学推导中尤为方便。

一个均值为零的[随机变量](@entry_id:195330) $X$ 被称为[亚高斯变量](@entry_id:755587)，如果存在一个常数 $s \ge 0$，使得对于所有的 $\lambda \in \mathbb{R}$，其MGF满足：
$$
\mathbb{E}[\exp(\lambda X)] \le \exp\left(\frac{s^2\lambda^2}{2}\right)
$$
这个不等式直观地表示 $X$ 的MGF被一个[高斯变量](@entry_id:276673)（具体来说是 $\mathcal{N}(0, s^2)$）的MGF所“控制”。所有满足此条件的 $s$ 的[下确界](@entry_id:140118)定义了 $X$ 的**亚高斯范数（sub-gaussian norm）**，记为 $\left\|X\right\|_{\psi_2}$。形式上：
$$
\left\|X\right\|_{\psi_2} := \inf\left\{ s > 0 : \mathbb{E}\left[\exp(\lambda X)\right] \le \exp\left(\frac{1}{2}s^{2}\lambda^{2}\right)\ \text{for all}\ \lambda \in \mathbb{R} \right\}
$$
亚高斯范数是一个衡量[随机变量](@entry_id:195330)“近似高斯程度”的指标，范数越小，其行为越接近高斯。

一个非常重要的[亚高斯变量](@entry_id:755587)类别是**有界[随机变量](@entry_id:195330)**。任何具有有界支撑集的[随机变量](@entry_id:195330)都是亚高斯的。具体来说，我们可以通过[霍夫丁引理](@entry_id:750363)（Hoeffding's Lemma）建立这种联系。该引理指出，如果一个[随机变量](@entry_id:195330) $X$ 满足 $\mathbb{E}[X]=0$ 且几乎必然地落在区间 $[a, b]$ 内，那么它的MGF有如下界：
$$
\mathbb{E}[\exp(\lambda X)] \le \exp\left(\frac{\lambda^2 (b-a)^2}{8}\right)
$$
将此界与亚高斯范数的定义进行比较，我们希望找到最小的 $s$ 使得 $\exp\left(\frac{\lambda^2 (b-a)^2}{8}\right) \le \exp\left(\frac{s^2\lambda^2}{2}\right)$。这等价于 $\frac{(b-a)^2}{8} \le \frac{s^2}{2}$，解得 $s \ge \frac{b-a}{2}$。因此，对于任何支撑在 $[a,b]$ 上的零均值[随机变量](@entry_id:195330) $X$，其亚高斯范数满足 $\left\|X\right\|_{\psi_2} \le \frac{b-a}{2}$。通过构造一个在 $\{-(b-a)/2, (b-a)/2\}$ 上取值的对称[两点分布](@entry_id:266933)（即**Rademacher[随机变量](@entry_id:195330)**的缩放版本），可以证明这个界是紧的。这表明常数 $C=1/2$ 是最优的 [@problem_id:3447505]。这个结论非常实用，因为它将一个容易验证的“有界性”条件与更具技术性的“亚高斯性”联系起来。

#### [亚指数随机变量](@entry_id:755583)

另一类重要的[随机变量](@entry_id:195330)是**亚指数（sub-exponential）[随机变量](@entry_id:195330)**。它们的尾部比[高斯变量](@entry_id:276673)更“重”，但仍然以指数速率衰减。典型地，如果[随机变量](@entry_id:195330) $X$ 的[尾概率](@entry_id:266795) $\mathbb{P}(|X| > t)$ 的衰减速度类似于[指数分布](@entry_id:273894)，即 $\exp(-ct)$，那么它就是亚指数的。

同样，亚指数变量也可以通过其Orlicz范数来定义。**亚指数范数** $\left\|\cdot\right\|_{\psi_1}$ 的一种常用定义是：
$$
\left\|X\right\|_{\psi_1} := \inf\left\{ t > 0 : \mathbb{E}\left[\exp\left(\frac{|X|}{t}\right)\right] \le 2 \right\}
$$
这个定义要求变量在被适当缩放后，其指数矩是有界的。

亚[高斯和](@entry_id:196588)亚指数变量之间存在一个至关重要的联系：**一个零均值亚高斯[随机变量](@entry_id:195330)的平方是亚指数的**。更准确地说，如果 $X$ 是一个零均值亚高斯[随机变量](@entry_id:195330)，那么中心化的 $X^2$，即 $X^2 - \mathbb{E}[X^2]$，是一个[亚指数随机变量](@entry_id:755583)。它们的范数之间存在如下关系：$\left\|X^2 - \mathbb{E}[X^2]\right\|_{\psi_1} \le C \left\|X\right\|_{\psi_2}^2$，其中 $C$ 是一个普适常数。

我们可以通过一个具体的例子来验证这个原理。考虑一个标准正态[随机变量](@entry_id:195330) $Z \sim \mathcal{N}(0,1)$。我们知道 $\mathbb{E}[Z^2]=1$。
首先，计算 $\left\|Z\right\|_{\psi_2}$。根据Orlicz范数的另一种等价定义，$\left\|X\right\|_{\psi_2} = \inf\{t > 0 : \mathbb{E}[\exp(X^2/t^2)] \le 2\}$。对于 $X=Z$，我们需要求解 $\mathbb{E}[\exp(Z^2/t^2)] = 2$。左边是 $\chi^2(1)$ [分布](@entry_id:182848)变量的MGF在点 $1/t^2$ 处的值，即 $(1-2/t^2)^{-1/2}$。令其等于 $2$ 可解得 $t^2 = 8/3$，因此 $\left\|Z\right\|_{\psi_2} = \sqrt{8/3}$。
接着，我们计算 $X=Z^2-1$ 的亚指数范数 $\left\|Z^2-1\right\|_{\psi_1}$。这需要求解一个[超越方程](@entry_id:276279) $\mathbb{E}[\exp(|Z^2-1|/t)] = 2$。通过对标准正[态密度](@entry_id:147894)函数进行积分，可以得到一个依赖于误差函数（error function）的复杂表达式，数值求解后得到 $\left\|Z^2-1\right\|_{\psi_1} \approx 2.418$。
比较这两个结果，我们发现 $\left\|Z^2-1\right\|_{\psi_1} \approx 2.418$ 和 $\left\|Z\right\|_{\psi_2}^2 = 8/3 \approx 2.667$ 的数值在同一个[数量级](@entry_id:264888)，这与理论关系 $\left\|X^2 - \mathbb{E}[X^2]\right\|_{\psi_1} \le C \left\|X\right\|_{\psi_2}^2$ 完全吻合 [@problem_id:3447478]。这个例子生动地展示了从[亚高斯变量](@entry_id:755587)到亚指数变量的转变机制，这在分析随机矩阵的性质时至关重要，因为像 $\left\|Ax\right\|_2^2$ 这样的量正是[亚高斯变量](@entry_id:755587)线性组合的平方和。

### 集中性与关键不等式

亚[高斯和](@entry_id:196588)[亚指数随机变量](@entry_id:755583)之所以如此重要，主要在于它们表现出强大的**集中性（concentration）**。这意味着[随机变量](@entry_id:195330)的值以极高的概率紧密地聚集在其期望周围。这种现象可以用一系列强大的[概率不等式](@entry_id:202750)来精确刻画。

#### 线性组合的集中性

对于[亚高斯变量](@entry_id:755587)的[线性组合](@entry_id:154743)，其表现出的集中性类似于独立[高斯变量](@entry_id:276673)之和。一个基本结果是霍夫丁型不等式，它为[亚高斯变量](@entry_id:755587)和的[尾概率](@entry_id:266795)提供了指数衰减的界。

#### 二次型的集中性

在许多应用中，我们更关心[随机变量](@entry_id:195330)的**二次型（quadratic form）**，例如 $g^\top A g$ 或 $\left\|Ax\right\|_2^2 = x^\top A^\top A x$。分析这些量的集中性是高维概率论的核心课题之一。

首先，理解二次型的基本矩是至关重要的。对于一个零均值高斯向量 $g \sim \mathcal{N}(0, \Sigma)$ 和一个对称矩阵 $A$，其二次型 $Q = g^\top A g$ 的均值和[方差](@entry_id:200758)有简洁的表达式。通过利用迹（trace）的循环性质和高斯向量的矩性质（特别是Isserlis定理），可以推导出 [@problem_id:3447473]：
$$
\mathbb{E}[Q] = \operatorname{tr}(A\Sigma)
$$
$$
\operatorname{Var}(Q) = 2\operatorname{tr}((A\Sigma)^2)
$$
这两个公式为我们提供了二次型随机波动尺度的精确度量。例如，当 $g \sim \mathcal{N}(0, I_n)$ 且 $A=I_n$ 时，$\mathbb{E}[\left\|g\right\|_2^2] = \operatorname{tr}(I_n) = n$，而 $\operatorname{Var}(\left\|g\right\|_2^2) = 2\operatorname{tr}(I_n^2) = 2n$。

为了得到关于二次型偏离其均值的[尾概率界](@entry_id:263956)，我们需要更强大的工具。**Hanson-Wright不等式**是分析亚高斯向量二次型集中性的标准武器。该不等式指出，如果 $\xi \in \mathbb{R}^d$ 的分量是独立的、零均值的1-亚高斯[随机变量](@entry_id:195330)， $M \in \mathbb{R}^{d \times d}$ 是一个确定性矩阵，那么对于任意 $t>0$：
$$
\mathbb{P}\left(\left|\xi^{\top}M\xi - \mathbb{E}\left[\xi^{\top}M\xi\right]\right| \geq t\right) \leq 2 \exp\left(- c \min\left\{\frac{t^{2}}{\left\|M\right\|_{F}^{2}}, \frac{t}{\left\|M\right\|}\right\}\right)
$$
这里，$c$ 是一个绝对常数，$\left\|M\right\|_F$ 是矩阵的[弗罗贝尼乌斯范数](@entry_id:143384)（Frobenius norm），$\left\|M\right\|$ 是[算子范数](@entry_id:752960)（operator norm）。这个不等式的美妙之处在于它同时包含了两种行为：当偏差 $t$ 较小时，[尾概率](@entry_id:266795)呈高斯型衰减（依赖于$t^2/\left\|M\right\|_F^2$）；当偏差 $t$ 较大时，[尾概率](@entry_id:266795)呈指数型衰减（依赖于$t/\left\|M\right\|$）。这个不等式是证明[随机投影](@entry_id:274693)矩阵性质的强大工具 [@problem_id:3447510]。

此外，当我们处理形如 $\left\|Ax\right\|_2^2 = \sum_i (a_i^\top x)^2$ 的量时，我们实际上是在处理一族亚指数变量的和。因为如果 $a_i$ 是亚高斯行向量，那么 $(a_i^\top x)$ 是亚高斯标量，而 $(a_i^\top x)^2 - \mathbb{E}[(a_i^\top x)^2]$ 则是亚指数的。对于这类和，**[伯恩斯坦不等式](@entry_id:637998)（Bernstein's inequality）**提供了相应的集中界，其形式与Hanson-Wright不等式类似，是分析[压缩感知](@entry_id:197903)中RIP性质的关键 [@problem_id:3447474]。

#### 反集中性

除了证明[随机变量](@entry_id:195330)紧密集中在其均值附近（集中性），有时我们还需要证明它以不可忽略的概率“远离”其均值。这种性质被称为**反集中性（anti-concentration）**。**Paley-Zygmund不等式**是提供此类下界的基本工具。对于非负[随机变量](@entry_id:195330) $Z$，该不等式给出：
$$
\mathbb{P}(Z > \theta \mathbb{E}[Z]) \ge (1-\theta)^2 \frac{(\mathbb{E}[Z])^2}{\mathbb{E}[Z^2]}
$$
我们可以利用这个工具来展示[亚高斯变量](@entry_id:755587)并非“过度集中”。例如，对于一个零均值亚高斯[随机变量](@entry_id:195330) $X = u^\top a$，其[方差](@entry_id:200758)为 $\sigma^2 = \mathbb{E}[X^2]$，亚高斯范数为 $\left\|X\right\|_{\psi_2} \le K\sigma$。通过Paley-Zygmund不等式，并利用亚高斯性导出四阶矩的[上界](@entry_id:274738) $\mathbb{E}[X^4] \le 4K^4\sigma^4$，可以推导出其[尾概率](@entry_id:266795)的下界 [@problem_id:3447485]：
$$
\mathbb{P}(|X| > \theta\sigma) = \mathbb{P}(X^2 > \theta^2\sigma^2) \ge \frac{(1-\theta^2)^2}{4K^4}
$$
这个结果表明，尽管[亚高斯变量](@entry_id:755587)的尾部衰减很快，但它仍然有至少是某个不依赖于[分布](@entry_id:182848)维度的常数级别的概率，会取到远离均值的值。这个性质在推导期望范数的下界等问题中非常有用。

### 亚高斯向量及其范数的性质

我们将讨论从亚高斯标量推广到**[亚高斯随机向量](@entry_id:755585)**。一个随机向量 $X \in \mathbb{R}^n$ 被称为亚高斯向量，如果其所有一维投影都是亚高斯[随机变量](@entry_id:195330)。也就是说，对于任意固定的向量 $v \in \mathbb{R}^n$，标量[随机变量](@entry_id:195330) $v^\top X$ 都是亚高斯的。

在高维设定下，随机向量的欧几里得范数 $\left\|X\right\|_2$ 的期望是一个关键的统计量，它描述了该向量在空间中的“典型”尺度。对于具有独立、零均值、[方差](@entry_id:200758)为 $\sigma_i^2$ 的亚高斯分量的随机向量 $X = (X_1, \dots, X_n)$，其期望范数 $\mathbb{E}\left\|X\right\|_2$ 的量级可以被精确地确定。

一方面，通过 Jensen 不等式（由于 $\sqrt{\cdot}$ 是[凹函数](@entry_id:274100)），我们可以得到一个简单的上界：
$$
\mathbb{E}\left\|X\right\|_2 = \mathbb{E}\left[\sqrt{\sum_{i=1}^n X_i^2}\right] \le \sqrt{\mathbb{E}\left[\sum_{i=1}^n X_i^2\right]} = \sqrt{\sum_{i=1}^n \sigma_i^2}
$$
另一方面，我们可以利用前述的 Paley-Zygmund 不等式（反集中性）来推导一个下界。这涉及到对 $\left\|X\right\|_2^2$ 应用该不等式，并利用亚高斯性来控制其四阶矩。最终可以证明存在一个仅依赖于亚高斯参数的常数 $c_1(K) > 0$，使得：
$$
\mathbb{E}\left\|X\right\|_2 \ge c_1(K) \sqrt{\sum_{i=1}^n \sigma_i^2}
$$
综合来看，我们有 $\mathbb{E}\left\|X\right\|_2 \asymp \sqrt{\sum_{i=1}^n \sigma_i^2}$，即期望范数的尺度由其各分量[方差](@entry_id:200758)之和的平方根决定 [@problem_id:3447481]。

对于最典型的情况，即标准高斯向量 $g \sim \mathcal{N}(0, I_n)$，$\mathbb{E}\left\|g\right\|_2$ 的精确值可以通过对 $\chi^2(n)$ [分布](@entry_id:182848)的密度函数积分得到，其结果与伽马函数（Gamma function）有关 [@problem_id:3447481]：
$$
\mathbb{E}\left\|g\right\|_2 = \sqrt{2} \frac{\Gamma\left(\frac{n+1}{2}\right)}{\Gamma\left(\frac{n}{2}\right)}
$$
当维度 $n$ 很大时，该表达式约等于 $\sqrt{n}$，这与我们从一般亚高斯情况得到的量级估计是一致的。

### 在[高维统计](@entry_id:173687)与[压缩感知](@entry_id:197903)中的应用

前面介绍的原理和工具在解决现代数据科学中的问题时威力尽显。亚[高斯和](@entry_id:196588)[亚指数随机变量](@entry_id:755583)的理论是[高维统计](@entry_id:173687)、机器学习和压缩感知等[领域性](@entry_id:180362)能分析的数学基础。

#### [高斯宽度](@entry_id:749763)与[随机过程](@entry_id:159502)的[上确界](@entry_id:140512)

在许多问题中，我们需要分析一个[随机过程](@entry_id:159502)在某个集合上的最大值，即 $\sup_{t \in T} X_t$。**[高斯宽度](@entry_id:749763)（Gaussian width）**是衡量集合 $T$ “大小”或“复杂性”的一个几何量，它与高斯过程上确界的期望密切相关。对于 $T \subset \mathbb{R}^n$，其[高斯宽度](@entry_id:749763)定义为：
$$
w(T) := \mathbb{E}\left[\sup_{t \in T} g^{\top} t\right], \quad \text{其中 } g \sim \mathcal{N}(0, I_n)
$$
在[压缩感知](@entry_id:197903)中，一个核心的几何对象是 $k$-稀疏单位球面 $T = \Sigma_k \cap S^{n-1}$，其中 $\Sigma_k$ 是所有至多 $k$-稀疏向量的集合。计算 $w(\Sigma_k \cap S^{n-1})$ 的量级对于理解[稀疏恢复](@entry_id:199430)的理论极限至关重要。

通过分析[上确界](@entry_id:140512) $\sup_{x \in T} g^\top x$ 的结构，可以发现它等价于在所有可能的 $k$ 维坐标[子空间](@entry_id:150286)上，$g$ 的投影范数的最大值，即 $\max_{|S|=k} \left\|g_S\right\|_2$。这个问题的量级可以从两方面理解：一是任意一个固定的 $\left\|g_S\right\|_2$ 的典型值约为 $\sqrt{k}$；二是在 $\binom{n}{k}$ 个这样的[随机变量](@entry_id:195330)中取最大值所带来的增益，这个增益项的量级为 $\sqrt{\log \binom{n}{k}} \approx \sqrt{k \log(n/k)}$。将这两部分结合起来，我们得到[高斯宽度](@entry_id:749763)的正确尺度 [@problem_id:3447508]：
$$
w(\Sigma_k \cap S^{n-1}) \asymp \sqrt{k\log(en/k)}
$$
这个结果是[高维几何](@entry_id:144192)与概率论结合的典范，它精确地量化了[稀疏信号](@entry_id:755125)集的复杂性。

#### [随机投影](@entry_id:274693)与受限等距性质

**[随机投影](@entry_id:274693)（random projection）**是一种强大的[降维技术](@entry_id:169164)，其思想是可以通过一个随机矩阵 $A \in \mathbb{R}^{m \times n}$（其中 $m \ll n$）将[高维数据](@entry_id:138874)投影到低维空间，同时近似地保持数据点之间的距离。这一性质通常被称为Johnson-Lindenstrauss (JL) 特性。

我们可以使用 Hanson-Wright 不等式来分析这种性质。考虑一个由 $N$ 个点组成的[有限集](@entry_id:145527)合 $S \subset \mathbb{R}^n$。我们希望找到最小的投影维度 $m$，使得对于所有 $x \in S$，$\frac{1}{m}\left\|Ax\right\|_2^2$ 都以高概率近似等于 $\left\|x\right\|_2^2$。
对于固定的 $x$，我们可以将 $\left\|Ax\right\|_2^2 - m\left\|x\right\|_2^2$ 写成[随机矩阵](@entry_id:269622) $A$ 的元素（例如，独立的Rademacher变量）的二次型。然后应用Hanson-Wright不等式得到该偏差的[尾概率界](@entry_id:263956)。最后，通过对集合 $S$ 中的所有 $N$ 个点使用**并集界（union bound）**，我们可以得到保证整个集合的范数都被保持的条件。这个推导过程表明，所需的测量数 $m$ 满足 [@problem_id:3447510]：
$$
m \ge C \frac{\log(N/\delta)}{\epsilon^2}
$$
其中 $\epsilon$ 是允许的失真度，$\delta$ 是允许的失败概率。这个结果表明，投影维度 $m$ 仅对数依赖于点的数量 $N$，这是非常惊人的。

在[压缩感知](@entry_id:197903)中，我们需要一个比JL性质更强的保证，即**受限等距性质（Restricted Isometry Property, RIP）**。RIP要求[随机矩阵](@entry_id:269622) $A$ 能够近似保持**所有** $k$-稀疏向量的欧几里得范数。这是一个对无限集合的统一要求。

RIP常数 $\delta_k$ 定义为满足下式的最小 $\delta$：
$$
(1-\delta)\left\|x\right\|_2^2 \le \left\|Ax\right\|_2^2 \le (1+\delta)\left\|x\right\|_2^2, \quad \text{对所有 } k\text{-稀疏向量 } x
$$
要推导保证RIP成立所需的测量数 $m$，需要一个更精细的论证过程，通常包含三个步骤 [@problem_id:3447474]：
1.  **单点集中**：对于一个固定的稀疏向量 $x$，利用[伯恩斯坦不等式](@entry_id:637998)分析 $\left\|Ax\right\|_2^2$ 对其期望 $m\left\|x\right\|_2^2$ 的偏离。这里利用了 $(a_i^\top x)^2$ 是亚指数变量这一关键事实。
2.  **覆盖网论证**：为了将性质从单个向量推广到某个固定的 $k$ 维稀疏[子空间](@entry_id:150286)中的所有向量，我们使用该[子空间](@entry_id:150286)[单位球](@entry_id:142558)面的**覆盖网（covering net）**，并结合并集界。
3.  **全局并集界**：最后，再次使用并集界，将性质推广到所有 $\binom{n}{k}$ 个可能的稀疏支撑集上。

通过这个过程，可以证明，为了使一个具有亚高斯（如Rademacher或高斯）条目的[随机矩阵](@entry_id:269622) $A$ 以高概率满足RIP性质，所需的测量数 $m$ 的量级为：
$$
m \ge C \frac{k \log(n/k)}{\delta^2}
$$
这个结果是压缩感知理论的基石。它表明，测量数 $m$ 对稀疏度 $k$ 几乎是线性的，对信号的原始维度 $n$ 仅是对数的，这使得从远少于 $n$ 的测量中恢复[稀疏信号](@entry_id:755125)成为可能。

#### 性能比较：亚高斯 vs. 亚指数

最后，我们有必要从更高层次上理解不同类型的[随机矩阵](@entry_id:269622)在应用中的表现差异。假设我们有两个[随机矩阵](@entry_id:269622)系综，它们的行向量都是独立的、均值为零且协[方差](@entry_id:200758)为单位阵（isotropic），但一个系综的行是**亚高斯**的，而另一个是**亚指数**的。
亚[高斯分布](@entry_id:154414)的尾部比[亚指数分布](@entry_id:185367)更轻。这意味着亚高斯[随机变量](@entry_id:195330)产生极端值的可能性更小。在[随机矩阵](@entry_id:269622)的背景下，这种“温和”的行为会转化为更强的集中性。
对于固定的测量数 $m$ 和稀疏度 $k$，由亚高斯行构成的矩阵 $A$ 的 $\frac{1}{m}A^\top A$ 会更紧密地集中在其期望 $I_n$ 附近。因此，它通常会表现出更小的RIP常数 $\delta_k$。反之，由亚指数行构成的矩阵由于其较重的尾部，更容易产生较大的波动，导致 $\delta_k$ 通常更大。
从另一个角度看，为了达到相同的RIP常数 $\delta_k$ 和相同的成功概率，亚指数系综通常需要比亚[高斯系综](@entry_id:187727)更多的测量数 $m$。这是因为需要更多的样本（行）来平均掉由[重尾分布](@entry_id:142737)带来的更大波动。因此，在压缩感知等应用中，亚[高斯随机矩阵](@entry_id:749758)（如高斯或Rademacher矩阵）通常被认为是“黄金标准”，因为它们以最少的资源提供了最强的性能保证 [@problem_id:3447488]。