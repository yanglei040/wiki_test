{"hands_on_practices": [{"introduction": "LASSO 是稀疏恢复的基石，但其解并非单个向量，而是一个由正则化参数 $\\lambda$ 参数化的解族。理解这条“解路径”能够让我们深入洞悉变量是如何被选择的，以及它们的系数是如何变化的。[@problem_id:3457315] 这项练习将超越为单个 $\\lambda$ 求解的范畴，挑战你手动推导整个解路径。通过直接应用 Karush-Kuhn-Tucker (KKT) 最优性条件，你将揭示 LASSO 路径的分段线性本质，并确定活动变量集发生变化时的“断点”，从而对 $\\ell_1$ 正则化的行为建立起根本性的直觉。", "problem": "考虑最小绝对收缩和选择算子 (LASSO) 问题，其中测量矩阵为 $A \\in \\mathbb{R}^{2 \\times 4}$，未知系数向量为 $x \\in \\mathbb{R}^{4}$，观测值为 $y \\in \\mathbb{R}^{2}$：\n$$\n\\min_{x \\in \\mathbb{R}^{4}} \\ \\frac{1}{2} \\| y - A x \\|_{2}^{2} + \\lambda \\| x \\|_{1},\n$$\n其中 $A$ 的列是由以下定义的单位范数原子\n$$\na_{1} = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}, \\quad a_{2} = \\begin{pmatrix} 0 \\\\ 1 \\end{pmatrix}, \\quad a_{3} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}, \\quad a_{4} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1 \\\\ -1 \\end{pmatrix},\n$$\n观测值为\n$$\ny = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}.\n$$\n令 $x(\\lambda)$ 表示对于每个 $\\lambda \\geq 0$ 的唯一 LASSO 解。从 LASSO 最优性的基本 Karush-Kuhn-Tucker (KKT) 条件出发，确定所有使 $x(\\lambda)$ 的活动集和/或符号模式发生变化的断点 $\\lambda$，并推导出当 $\\lambda$ 从最大断点递减至 $0$ 时，在每个分段上 $x(\\lambda)$ 的精确分段线性表达式。对于每个开区间段和每个断点，显式地验证活动坐标和非活动坐标的 KKT 条件。\n\n以精确的封闭形式表示所有量。作为最终答案，请以行矩阵的形式报告按降序排列的断点向量。不要对最终答案进行四舍五入。最终答案必须以单个不带单位的表达式给出。", "solution": "用户希望找到一个特定 LASSO 问题的解路径。\n\nLASSO 问题由下式给出：\n$$ \\min_{x \\in \\mathbb{R}^{4}} \\ \\frac{1}{2} \\| y - A x \\|_{2}^{2} + \\lambda \\| x \\|_{1} $$\n最优性的 Karush-Kuhn-Tucker (KKT) 条件表明，零向量必须位于目标函数的次微分中。这意味着存在一个向量 $s \\in \\partial \\|x\\|_1$ 使得：\n$$ A^T(y - Ax) = \\lambda s $$\n其中 $s$ 是 $\\ell_1$-范数的次梯度，其分量 $s_i$ 满足：\n$$\ns_i = \\begin{cases}\n\\text{sign}(x_i)  \\text{如果 } x_i \\neq 0 \\\\\n\\in [-1, 1]  \\text{如果 } x_i = 0\n\\end{cases}\n$$\n令 $\\mathcal{I} = \\{i \\mid x_i \\neq 0\\}$ 为活动集。KKT 条件可以分为两部分：\n1.  对于活动索引 $i \\in \\mathcal{I}$：$a_i^T(y - Ax) = \\lambda \\cdot \\text{sign}(x_i)$。\n2.  对于非活动索引 $j \\notin \\mathcal{I}$：$|a_j^T(y - Ax)| \\leq \\lambda$。\n\n我们追踪当 $\\lambda$ 从一个较大的值减小时的解路径 $x(\\lambda)$。\n\n**分段 1：寻找第一个断点 $\\lambda_1$**\n\n对于足够大的 $\\lambda$，$\\ell_1$ 惩罚项占主导地位，迫使解为 $x(\\lambda) = 0$。在这种情况下，活动集为空，$\\mathcal{I} = \\emptyset$。KKT 条件简化为对所有 $i=1, 2, 3, 4$ 都有 $|a_i^T(y-A\\cdot 0)| \\leq \\lambda$。这等价于 $\\lambda \\geq \\max_i |a_i^T y|$。\n我们来计算相关性 $c = A^T y$：\n$A = \\begin{pmatrix} 1  0  \\frac{1}{\\sqrt{2}}  \\frac{1}{\\sqrt{2}} \\\\ 0  1  \\frac{1}{\\sqrt{2}}  -\\frac{1}{\\sqrt{2}} \\end{pmatrix}$，$y = \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix}$。\n$c_1 = a_1^T y = \\begin{pmatrix} 1  0 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 2$。\n$c_2 = a_2^T y = \\begin{pmatrix} 0  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = 1$。\n$c_3 = a_3^T y = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1  1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\frac{3}{\\sqrt{2}}$。\n$c_4 = a_4^T y = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1  -1 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ 1 \\end{pmatrix} = \\frac{1}{\\sqrt{2}}$。\n\n第一个（最大的）断点 $\\lambda_1$ 是使其中一个不等式变为等式的 $\\lambda$ 值：\n$$ \\lambda_1 = \\max_{i} |c_i| = \\max \\left\\{ 2, 1, \\frac{3}{\\sqrt{2}}, \\frac{1}{\\sqrt{2}} \\right\\} = \\frac{3}{\\sqrt{2}} $$\n对于所有 $\\lambda \\geq \\lambda_1$，解为 $x(\\lambda) = 0$。在 $\\lambda_1 = 3/\\sqrt{2}$ 处，原子 $a_3$ 变为活动的。$x_3$ 的符号将是 $\\text{sign}(c_3) = +1$。\n\n**分段 2：$\\lambda \\in (\\lambda_2, \\lambda_1)$ 的路径**\n\n对于 $\\lambda  \\lambda_1$，活动集为 $\\mathcal{I} = \\{3\\}$ 且 $x_3$ 的符号为 $s_3=1$。解向量的形式为 $x(\\lambda) = (0, 0, x_3(\\lambda), 0)^T$，其中 $x_3(\\lambda)  0$。\n活动集的 KKT 条件是 $a_3^T(y - a_3 x_3) = \\lambda s_3 = \\lambda$。\n由于原子是单位范数的 ($a_3^T a_3 = 1$)，这变为 $a_3^T y - x_3 = \\lambda$，从而得到：\n$$ x_3(\\lambda) = a_3^T y - \\lambda = \\frac{3}{\\sqrt{2}} - \\lambda $$\n只要 $x_3(\\lambda)>0$ (即 $\\lambda  \\lambda_1$) 并且非活动原子 $i \\in \\{1, 2, 4\\}$ 的 KKT 条件得到满足：$|a_i^T(y - a_3 x_3(\\lambda))| \\leq \\lambda$，这条路径就有效。\n令 $r(\\lambda) = y - a_3 x_3(\\lambda)$。相关性为 $a_i^T r(\\lambda) = a_i^T y - (a_i^T a_3) x_3(\\lambda)$。\n我们需要内积：$a_1^T a_3 = 1/\\sqrt{2}$，$a_2^T a_3 = 1/\\sqrt{2}$，$a_4^T a_3 = 0$。\n\n对于 $i=1$：$a_1^T r(\\lambda) = c_1 - (a_1^T a_3)x_3(\\lambda) = 2 - \\frac{1}{\\sqrt{2}}(\\frac{3}{\\sqrt{2}} - \\lambda) = 2 - \\frac{3}{2} + \\frac{\\lambda}{\\sqrt{2}} = \\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}}$。\n条件 $|a_1^T r(\\lambda)| \\leq \\lambda$ 变为 $\\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}} \\leq \\lambda$ （因为当 $\\lambda>0$ 时该项为正）。\n这得出 $\\frac{1}{2} \\leq \\lambda(1 - \\frac{1}{\\sqrt{2}})$，所以 $\\lambda \\geq \\frac{1/2}{1-1/\\sqrt{2}} = \\frac{\\sqrt{2}}{2(\\sqrt{2}-1)} = \\frac{\\sqrt{2}(\\sqrt{2}+1)}{2} = \\frac{2+\\sqrt{2}}{2}$。\n\n对于 $i=2$：$a_2^T r(\\lambda) = c_2 - (a_2^T a_3)x_3(\\lambda) = 1 - \\frac{1}{\\sqrt{2}}(\\frac{3}{\\sqrt{2}} - \\lambda) = 1 - \\frac{3}{2} + \\frac{\\lambda}{\\sqrt{2}} = -\\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}}$。\n条件是 $|-\\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}}| \\leq \\lambda$。这给出两个不等式：\n(a) $-\\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}} \\leq \\lambda \\implies -\\frac{1}{2} \\leq \\lambda(1-\\frac{1}{\\sqrt{2}})$，对于 $\\lambda>0$ 成立。\n(b) $-\\frac{1}{2} + \\frac{\\lambda}{\\sqrt{2}} \\geq -\\lambda \\implies \\frac{1}{2} \\leq \\lambda(1+\\frac{1}{\\sqrt{2}})$，所以 $\\lambda \\geq \\frac{1/2}{1+1/\\sqrt{2}} = \\frac{\\sqrt{2}}{2(\\sqrt{2}+1)} = \\frac{2-\\sqrt{2}}{2}$。\n\n对于 $i=4$：$a_4^T r(\\lambda) = c_4 - (a_4^T a_3)x_3(\\lambda) = \\frac{1}{\\sqrt{2}} - 0 = \\frac{1}{\\sqrt{2}}$。\n条件是 $|\\frac{1}{\\sqrt{2}}| \\leq \\lambda$，所以 $\\lambda \\geq \\frac{1}{\\sqrt{2}}$。\n\n下一个断点 $\\lambda_2$ 是其中一个不等式变为等式的点。这发生在边界值中最大的 $\\lambda  \\lambda_1$ 处：\n$$ \\lambda_2 = \\max\\left\\{ \\frac{2+\\sqrt{2}}{2}, \\frac{2-\\sqrt{2}}{2}, \\frac{1}{\\sqrt{2}} \\right\\} $$\n数值约为 $1.707$, $0.293$, $0.707$。最大值是 $\\frac{2+\\sqrt{2}}{2}$。\n该值小于 $\\lambda_1 = 3/\\sqrt{2} \\approx 2.121$。\n因此，第二个断点是 $\\lambda_2 = \\frac{2+\\sqrt{2}}{2} = 1 + \\frac{\\sqrt{2}}{2}$。\n在 $\\lambda_2$ 处，我们有 $a_1^T r(\\lambda_2) = \\lambda_2$，原子 $a_1$ 进入活动集。其符号为 $\\text{sign}(a_1^T r(\\lambda_2)) = +1$。\n\n**分段 3：$\\lambda \\in (0, \\lambda_2)$ 的路径**\n\n对于 $\\lambda  \\lambda_2$，活动集为 $\\mathcal{I}=\\{1, 3\\}$，符号为 $s_1=1, s_3=1$。解的形式为 $x(\\lambda)=(x_1(\\lambda), 0, x_3(\\lambda), 0)^T$。\n活动集的 KKT 条件是 $A_{\\mathcal{I}}^T(y - A_{\\mathcal{I}}x_{\\mathcal{I}}) = \\lambda s_{\\mathcal{I}}$，其中 $A_{\\mathcal{I}}=[a_1, a_3]$ 且 $x_{\\mathcal{I}} = [x_1, x_3]^T$。\n这得出 $A_{\\mathcal{I}}^T A_{\\mathcal{I}} x_{\\mathcal{I}} = A_{\\mathcal{I}}^T y - \\lambda s_{\\mathcal{I}}$。\n$A_{\\mathcal{I}}^T A_{\\mathcal{I}} = \\begin{pmatrix} a_1^T a_1  a_1^T a_3 \\\\ a_3^T a_1  a_3^T a_3 \\end{pmatrix} = \\begin{pmatrix} 1  1/\\sqrt{2} \\\\ 1/\\sqrt{2}  1 \\end{pmatrix}$。\n逆矩阵是 $(A_{\\mathcal{I}}^T A_{\\mathcal{I}})^{-1} = \\frac{1}{1-1/2}\\begin{pmatrix} 1  -1/\\sqrt{2} \\\\ -1/\\sqrt{2}  1 \\end{pmatrix} = \\begin{pmatrix} 2  -\\sqrt{2} \\\\ -\\sqrt{2}  2 \\end{pmatrix}$。\n$A_{\\mathcal{I}}^T y = \\begin{pmatrix} c_1 \\\\ c_3 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 3/\\sqrt{2} \\end{pmatrix}$ 且 $s_{\\mathcal{I}} = \\begin{pmatrix} 1 \\\\ 1 \\end{pmatrix}$。\n所以，$x_{\\mathcal{I}}(\\lambda) = (A_{\\mathcal{I}}^T A_{\\mathcal{I}})^{-1} (A_{\\mathcal{I}}^T y - \\lambda s_{\\mathcal{I}}) = \\begin{pmatrix} 2  -\\sqrt{2} \\\\ -\\sqrt{2}  2 \\end{pmatrix} \\begin{pmatrix} 2-\\lambda \\\\ 3/\\sqrt{2}-\\lambda \\end{pmatrix}$。\n$x_1(\\lambda) = 2(2-\\lambda) - \\sqrt{2}(3/\\sqrt{2}-\\lambda) = 4 - 2\\lambda - 3 + \\sqrt{2}\\lambda = 1 + (\\sqrt{2}-2)\\lambda$。\n$x_3(\\lambda) = -\\sqrt{2}(2-\\lambda) + 2(3/\\sqrt{2}-\\lambda) = -2\\sqrt{2} + \\sqrt{2}\\lambda + 3\\sqrt{2} - 2\\lambda = \\sqrt{2} + (\\sqrt{2}-2)\\lambda$。\n\n我们检查下一个断点。当一个活动系数变为零，或者一个非活动原子的相关性达到 $\\pm \\lambda$ 时，就会出现下一个断点。\n- `活动系数`：\n  $x_1(\\lambda) = 1+(\\sqrt{2}-2)\\lambda  0 \\implies 1  (2-\\sqrt{2})\\lambda \\implies \\lambda  \\frac{1}{2-\\sqrt{2}} = \\frac{2+\\sqrt{2}}{2} = \\lambda_2$。因此对于 $\\lambda  \\lambda_2$，$x_1(\\lambda)0$。\n  $x_3(\\lambda) = \\sqrt{2}+(\\sqrt{2}-2)\\lambda  0 \\implies \\sqrt{2}  (2-\\sqrt{2})\\lambda \\implies \\lambda  \\frac{\\sqrt{2}}{2-\\sqrt{2}} = \\frac{\\sqrt{2}(2+\\sqrt{2})}{2} = 1+\\sqrt{2}$。由于 $1+\\sqrt{2}  \\lambda_2$，$x_3(\\lambda)$ 在 $\\lambda \\in (0, \\lambda_2)$ 上保持为正。\n  在 $\\lambda \\in (0, \\lambda_2)$ 上，符号保持一致，没有活动系数变为零。\n\n- `非活动系数` $i \\in \\{2, 4\\}$：\n  残差为 $r(\\lambda) = y - a_1x_1(\\lambda) - a_3x_3(\\lambda)$。\n  对于 $i=2$：$a_2^T r(\\lambda) = c_2 - (a_2^T a_1)x_1(\\lambda) - (a_2^T a_3)x_3(\\lambda) = 1 - 0 - \\frac{1}{\\sqrt{2}}x_3(\\lambda)$。\n  $a_2^T r(\\lambda) = 1 - \\frac{1}{\\sqrt{2}}(\\sqrt{2}+(\\sqrt{2}-2)\\lambda) = 1 - (1+\\frac{\\sqrt{2}-2}{\\sqrt{2}}\\lambda) = - (1-\\sqrt{2})\\lambda = (\\sqrt{2}-1)\\lambda$。\n  条件是 $|a_2^T r(\\lambda)| \\leq \\lambda \\implies |(\\sqrt{2}-1)\\lambda| \\leq \\lambda \\implies (\\sqrt{2}-1)\\lambda \\leq \\lambda$，简化为 $\\sqrt{2}-1 \\leq 1$ 或 $\\sqrt{2} \\leq 2$。对于 $\\lambda>0$，该不等式是严格的，因此原子 2 永远不会变为活动的。\n  对于 $i=4$：$a_4^T r(\\lambda) = c_4 - (a_4^T a_1)x_1(\\lambda) - (a_4^T a_3)x_3(\\lambda) = \\frac{1}{\\sqrt{2}} - \\frac{1}{\\sqrt{2}}x_1(\\lambda) - 0$。\n  $a_4^T r(\\lambda) = \\frac{1}{\\sqrt{2}}(1-x_1(\\lambda)) = \\frac{1}{\\sqrt{2}}(1 - (1+(\\sqrt{2}-2)\\lambda)) = \\frac{1}{\\sqrt{2}}(-(\\sqrt{2}-2)\\lambda) = \\frac{2-\\sqrt{2}}{\\sqrt{2}}\\lambda = (\\sqrt{2}-1)\\lambda$。\n  这与原子 2 的相关性相同，对于 $\\lambda  0$ 也严格小于 $\\lambda$。\n\n对于 $\\lambda \\in (0, \\lambda_2)$ 没有新事件发生。活动集和符号模式一直保持不变直到 $\\lambda=0$。\n因此，对于 $\\lambda>0$ 只有两个断点。\n\n按降序排列的断点是：\n$\\lambda_1 = \\frac{3}{\\sqrt{2}} = \\frac{3\\sqrt{2}}{2}$\n$\\lambda_2 = 1 + \\frac{\\sqrt{2}}{2} = \\frac{2+\\sqrt{2}}{2}$\n\n**解路径 $x(\\lambda)$ 总结：**\n1.  对于 $\\lambda \\geq \\frac{3\\sqrt{2}}{2}$：$x(\\lambda) = (0, 0, 0, 0)^T$。\n2.  对于 $\\lambda \\in [\\frac{2+\\sqrt{2}}{2}, \\frac{3\\sqrt{2}}{2})$：$x(\\lambda) = (0, 0, \\frac{3}{\\sqrt{2}}-\\lambda, 0)^T$。\n3.  对于 $\\lambda \\in [0, \\frac{2+\\sqrt{2}}{2})$：$x(\\lambda) = (1+(\\sqrt{2}-2)\\lambda, 0, \\sqrt{2}+(\\sqrt{2}-2)\\lambda, 0)^T$。\n\n问题要求的是断点向量。", "answer": "$$ \\boxed{ \\begin{pmatrix} \\frac{3\\sqrt{2}}{2}  \\frac{2+\\sqrt{2}}{2} \\end{pmatrix} } $$", "id": "3457315"}, {"introduction": "我们已经看到 LASSO 解如何依赖于 $\\lambda$，但一个关键的实践问题依然存在：如何为一个给定的问题选择最佳的 $\\lambda$？虽然交叉验证是一种常用方法，但在已知噪声特性的情况下，统计方法可以提供一种更高效、更优雅的替代方案。[@problem_id:3457312] 这项练习将介绍斯坦无偏风险估计 (SURE)，这是一个强大的工具，可以在无法获知真实信号的情况下估计一个估计器的预测误差。你将首先从第一性原理出发，为软阈值算子推导 SURE 公式，然后应用它从观测数据中选择最优的 $\\lambda$，从而在优化理论和统计模型选择之间架起一座桥梁。", "problem": "考虑一个带有单位传感矩阵的线性逆问题，其中观测值建模为 $y = x_{0} + w \\in \\mathbb{R}^{n}$，且 $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$。令估计量 $\\widehat{x}_{\\lambda}(y)$ 为最小绝对收缩和选择算子 (LASSO) 的解，即 $\\frac{1}{2} \\|y - x\\|_{2}^{2} + \\lambda \\|x\\|_{1}$ 的最小化子，它在分量上与水平为 $\\lambda$ 的软阈值算子 $S_{\\lambda}(y)$ 一致，因此 $\\widehat{x}_{\\lambda}(y) = S_{\\lambda}(y)$，其中 $(S_{\\lambda}(y))_{i} = \\operatorname{sign}(y_{i}) \\max\\{|y_{i}| - \\lambda, 0\\}$。使用 Stein 无偏风险估计 (SURE)，从第一性原理推导一个关于无噪声响应的均方预测误差的无偏估计量，即 $\\mathbb{E}\\big[\\|S_{\\lambda}(y) - x_{0}\\|_{2}^{2}\\big]$ 的一个无偏估计量，该估计量完全用 $y$、$\\sigma^{2}$ 和 $S_{\\lambda}(\\cdot)$ 的散度表示。证明这个 SURE 可以用软阈值算子的散度显式地写出。\n\n然后，使用您推导出的表达式，对以下数据确定使 SURE 最小化的 $\\lambda$ 值：\n- 维度 $n = 6$，\n- 噪声方差 $\\sigma^{2} = 0.25$，\n- 观测向量 $y \\in \\mathbb{R}^{6}$ 由 $y = (3.10,\\,-2.40,\\,0.95,\\,-1.80,\\,0.12,\\,-0.42)^{\\top}$ 给出。\n\n只报告最小值点 $\\lambda^{\\star}$ 的数值。不要对最终答案进行四舍五入。", "solution": "我们从高斯序列模型 $y = x_{0} + w \\in \\mathbb{R}^{n}$ 开始，其中 $w \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$。在单位设计下，LASSO 估计量是软阈值算子 $S_{\\lambda}(y)$，其分量定义为\n$$\n(S_{\\lambda}(y))_{i} = \\operatorname{sign}(y_{i}) \\max\\{|y_{i}| - \\lambda, 0\\}。\n$$\n我们感兴趣的量是关于无噪声响应 $x_{0}$ 的均方预测误差，\n$$\nR(\\lambda) \\equiv \\mathbb{E}\\big[\\|S_{\\lambda}(y) - x_{0}\\|_{2}^{2}\\big]。\n$$\nStein 无偏风险估计 (SURE) 在 $S_{\\lambda}$ 几乎处处满足的温和正则性条件（弱可微性和可积性）下，提供了 $R(\\lambda)$ 的一个无偏估计量：\n$$\n\\operatorname{SURE}(\\lambda; y) \\equiv \\|S_{\\lambda}(y) - y\\|_{2}^{2} + 2 \\sigma^{2} \\,\\operatorname{div}_{y} S_{\\lambda}(y) - n \\sigma^{2},\n$$\n它满足 $\\mathbb{E}[\\operatorname{SURE}(\\lambda; y)] = R(\\lambda)$。\n\n我们现在计算软阈值算子的散度。对每个分量 $i \\in \\{1,\\dots,n\\}$，当 $|y_{i}| \\neq \\lambda$ 时，映射 $y_{i} \\mapsto (S_{\\lambda}(y))_{i}$ 是可微的，其导数为\n$$\n\\frac{\\partial (S_{\\lambda}(y))_{i}}{\\partial y_{i}} =\n\\begin{cases}\n1,  \\text{如果 } |y_{i}|  \\lambda,\\\\\n0,  \\text{如果 } |y_{i}|  \\lambda.\n\\end{cases}\n$$\n在不可微的拐点 $|y_{i}| = \\lambda$（在高斯定律下一个勒贝格测度为零的集合）处，Stein 公式仍然有效。因此，散度是\n$$\n\\operatorname{div}_{y} S_{\\lambda}(y) = \\sum_{i=1}^{n} \\frac{\\partial (S_{\\lambda}(y))_{i}}{\\partial y_{i}} = \\#\\{i: |y_{i}|  \\lambda\\} \\equiv k(\\lambda),\n$$\n即活跃（非零）的软阈值分量的数量。\n\n接下来，我们简化残差项 $\\|S_{\\lambda}(y) - y\\|_{2}^{2}$。对任意坐标 $i$：\n- 如果 $|y_{i}|  \\lambda$ (活跃)，则 $(S_{\\lambda}(y))_{i} = y_{i} - \\operatorname{sign}(y_{i}) \\lambda$，因此 $(S_{\\lambda}(y))_{i} - y_{i} = -\\operatorname{sign}(y_{i}) \\lambda$，且 $((S_{\\lambda}(y))_{i} - y_{i})^{2} = \\lambda^{2}$。\n- 如果 $|y_{i}| \\leq \\lambda$ (不活跃)，则 $(S_{\\lambda}(y))_{i} = 0$，因此 $(S_{\\lambda}(y))_{i} - y_{i} = -y_{i}$，且 $((S_{\\lambda}(y))_{i} - y_{i})^{2} = y_{i}^{2}$。\n\n因此，\n$$\n\\|S_{\\lambda}(y) - y\\|_{2}^{2} = \\sum_{i: |y_{i}|  \\lambda} \\lambda^{2} + \\sum_{i: |y_{i}| \\leq \\lambda} y_{i}^{2} = \\sum_{i=1}^{n} \\min\\{y_{i}^{2}, \\lambda^{2}\\}。\n$$\n结合散度，我们得到显式的 SURE：\n$$\n\\operatorname{SURE}(\\lambda; y) = \\sum_{i=1}^{n} \\min\\{y_{i}^{2}, \\lambda^{2}\\} + 2 \\sigma^{2} k(\\lambda) - n \\sigma^{2}。\n$$\n\n我们将 $\\operatorname{SURE}(\\lambda; y)$ 作为 $\\lambda$ 的函数来分析其结构。令 $s_{(1)} \\geq s_{(2)} \\geq \\cdots \\geq s_{(n)}$ 为 $\\{|y_{i}|\\}_{i=1}^{n}$ 的顺序统计量。对于 $\\lambda \\in (s_{(t+1)}, s_{(t)}]$，并约定 $s_{(n+1)} \\equiv 0$，活跃系数的数量为 $k(\\lambda) = t$，且\n$$\n\\operatorname{SURE}(\\lambda; y) = t \\lambda^{2} + \\sum_{i=t+1}^{n} s_{(i)}^{2} + (2t - n) \\sigma^{2}。\n$$\n在每个开区间 $(s_{(t+1)}, s_{(t)})$ 内，导数为 $\\frac{d}{d\\lambda} \\operatorname{SURE}(\\lambda; y) = 2 t \\lambda \\geq 0$，因此 $\\operatorname{SURE}(\\lambda; y)$ 在每个这样的区间上关于 $\\lambda$ 是非递减的。因此，任何最小值点都必须出现在某个区间的左端点，即在 $\\lambda \\in \\{0, s_{(n)}, s_{(n-1)}, \\dots, s_{(1)}\\}$。\n\n我们现在将此应用于给定数据。这里 $n = 6$，$\\sigma^{2} = 0.25$，且\n$$\ny = (3.10,\\,-2.40,\\,0.95,\\,-1.80,\\,0.12,\\,-0.42)^{\\top},\n$$\n因此排序后的绝对值为\n$$\ns_{(1)} = 3.10,\\quad s_{(2)} = 2.40,\\quad s_{(3)} = 1.80,\\quad s_{(4)} = 0.95,\\quad s_{(5)} = 0.42,\\quad s_{(6)} = 0.12。\n$$\n我们在候选点 $\\lambda \\in \\{0,\\,0.12,\\,0.42,\\,0.95,\\,1.80,\\,2.40,\\,3.10\\}$ 处计算 $\\operatorname{SURE}(\\lambda; y)$ 的值。\n\n首先，在 $\\lambda = 0$ 时，所有分量都是活跃的，因此 $k(0) = 6$ 且\n$$\n\\operatorname{SURE}(0; y) = \\sum_{i=1}^{n} \\min\\{y_{i}^{2}, 0\\} + (2 \\cdot 6 - 6)\\sigma^{2} = 0 + 6 \\cdot 0.25 = 1.5。\n$$\n\n对于 $\\lambda = s_{(t)}$ 且 $t \\in \\{1,\\dots,6\\}$，在阈值处，活跃集的大小为 $t-1$，我们有\n$$\n\\operatorname{SURE}(s_{(t)}; y) = \\sum_{i=1}^{n} \\min\\{y_i^2, s_{(t)}^2\\} + 2\\sigma^2(t-1) - n\\sigma^2 = \\sum_{j=t}^{n} s_{(j)}^2 + (t-1)s_{(t)}^2 + (2(t-1) - n) \\sigma^{2}。\n$$\n我们预先计算平方项和尾部和：\n$$\ns_{(1)}^{2} = 9.61,\\quad s_{(2)}^{2} = 5.76,\\quad s_{(3)}^{2} = 3.24,\\quad s_{(4)}^{2} = 0.9025,\\quad s_{(5)}^{2} = 0.1764,\\quad s_{(6)}^{2} = 0.0144,\n$$\n以及尾部和\n$$\n\\sum_{i=1}^{6} s_{(i)}^{2} = 19.7033,\\quad \\sum_{i=2}^{6} s_{(i)}^{2} = 10.0933,\\quad \\sum_{i=3}^{6} s_{(i)}^{2} = 4.3333,\\quad \\sum_{i=4}^{6} s_{(i)}^{2} = 1.0933,\\quad \\sum_{i=5}^{6} s_{(i)}^{2} = 0.1908,\\quad \\sum_{i=6}^{6} s_{(i)}^{2} = 0.0144。\n$$\n我们还注意到 $(2(t-1) - n) \\sigma^{2} = (2t - 8) \\cdot 0.25$。\n\n现在计算每个候选值：\n- 对于 $t = 6$ (即 $\\lambda = 0.12$)：$k(0.12)=5$。$\\sum \\min = 5 \\cdot 0.12^2 + 0.12^2 = 6 \\cdot 0.0144 = 0.0864$。$\\operatorname{SURE}(0.12; y) = 0.0864 + (2\\cdot 5 - 6)\\cdot 0.25 = 0.0864 + 4 \\cdot 0.25 = 1.0864$。\n- 对于 $t = 5$ (即 $\\lambda = 0.42$)：$k(0.42)=4$。$\\sum \\min = 4 \\cdot 0.42^2 + 0.1764 + 0.0144 = 5 \\cdot 0.1764 + 0.0144 = 0.8964$。$\\operatorname{SURE}(0.42; y) = 0.8964 + (2\\cdot 4-6)\\cdot 0.25 = 0.8964 + 0.5 = 1.3964$。\n- 对于 $t = 4$ (即 $\\lambda = 0.95$)：$k(0.95)=3$。$\\sum \\min = 3 \\cdot 0.95^2 + 0.9025 + 0.1764 + 0.0144 = 4 \\cdot 0.9025 + 0.1908 = 3.8008$。$\\operatorname{SURE}(0.95; y) = 3.8008 + (2\\cdot 3-6)\\cdot 0.25 = 3.8008$。\n- 对于 $t = 3$ (即 $\\lambda = 1.80$)：$k(1.80)=2$。$\\sum \\min = 2 \\cdot 1.80^2 + 3.24 + 1.0933 = 3 \\cdot 3.24 + 1.0933 = 10.8133$。$\\operatorname{SURE}(1.80; y) = 10.8133 + (2\\cdot 2-6)\\cdot 0.25 = 10.8133 - 0.5 = 10.3133$。\n- 对于 $t = 2$ (即 $\\lambda = 2.40$)：$k(2.40)=1$。$\\sum \\min = 1 \\cdot 2.40^2 + 10.0933 = 15.8533$。$\\operatorname{SURE}(2.40; y) = 15.8533 + (2\\cdot 1-6)\\cdot 0.25 = 15.8533 - 1.0 = 14.8533$。\n- 对于 $t = 1$ (即 $\\lambda = 3.10$)：$k(3.10)=0$。$\\sum \\min = 19.7033$。$\\operatorname{SURE}(3.10; y) = 19.7033 + (2\\cdot 0-6)\\cdot 0.25 = 19.7033 - 1.5 = 18.2033$。\n\n比较所有候选值，我们发现\n$$\n\\operatorname{SURE}(0; y) = 1.5,\\quad \\operatorname{SURE}(0.12; y) = 1.0864,\\quad \\operatorname{SURE}(0.42; y) = 1.3964,\n$$\n而其余候选值会产生更大的值。由于 $\\operatorname{SURE}(\\lambda; y)$ 在断点之间是非递减的，全局最小值点在 $\\lambda^{\\star} = 0.12$ 处达到。\n\n因此，对于给定数据，使 SURE 最小化的 $\\lambda$ 值为 $\\lambda^{\\star} = 0.12$。", "answer": "$$\\boxed{0.12}$$", "id": "3457312"}, {"introduction": "标准 LASSO 促进的是单个特征层面的稀疏性。然而，在许多现实世界的应用中，变量具有天然的分组结构，我们希望能够同时选择或剔除整组变量。组 LASSO (Group LASSO) 将 $\\ell_1$ 惩罚项扩展，以实现这种结构化稀疏性。[@problem_id:3457329] 这项练习旨在挑战你将对 LASSO 的理解推广到组 LASSO 框架。你将为这种更复杂的惩罚项推导 KKT 条件，发现其优化算法的基础——相应的“块软阈值”规则，并应用你的发现来为一个具体实例确定临界正则化值。这项练习将巩固你对次微分理论及其在结构化正则化问题中应用的掌握。", "problem": "考虑一个欠定线性反问题，其数据矩阵为 $A \\in \\mathbb{R}^{m \\times n}$，观测向量为 $b \\in \\mathbb{R}^{m}$，其中 $m  n$。令 $\\mathcal{G}$ 是 $\\{1,2,\\ldots,n\\}$ 的一个划分为不相交的组，对于任意 $x \\in \\mathbb{R}^{n}$，根据此划分记为 $x = [x_{g}]_{g \\in \\mathcal{G}}$。定义组套索范数为 $\\|x\\|_{2,1} = \\sum_{g \\in \\mathcal{G}} \\|x_{g}\\|_{2}$。考虑以下凸优化问题\n$$\n\\min_{x \\in \\mathbb{R}^{n}} \\; \\frac{1}{2}\\|A x - b\\|_{2}^{2} + \\lambda \\|x\\|_{2,1},\n$$\n其中正则化参数 $\\lambda > 0$。\n\n任务：\n1) 仅使用凸函数的一阶最优性条件和范数次微分的定义，推导上述问题极小值点 $x^{\\star}$ 的 Karush-Kuhn-Tucker (KKT) 条件。按组对每个 $g \\in \\mathcal{G}$ 表示这些条件。\n\n2) 从次微分的刻画出发，推导函数 $x \\mapsto \\lambda \\|x\\|_{2,1}$ 的近端算子的块软阈值规则，然后给出最小化目标函数的近端梯度迭代法。你的推导必须从近端子问题的一阶充要最优性条件开始，并通过对每个块进行最小化来继续。\n\n3) 现在特化到以下具体实例：$m = 3$，$n = 4$，以及两个组 $\\mathcal{G} = \\{g_{1}, g_{2}\\}$，其中 $g_{1} = \\{1,4\\}$ 且 $g_{2} = \\{2,3\\}$。令 $A$ 的列向量为\n$$\na_{1} = \\begin{pmatrix}1 \\\\ 0 \\\\ 0\\end{pmatrix}, \\quad\na_{2} = \\begin{pmatrix}0 \\\\ 1 \\\\ 0\\end{pmatrix}, \\quad\na_{3} = \\begin{pmatrix}0 \\\\ 0 \\\\ 1\\end{pmatrix}, \\quad\na_{4} = \\begin{pmatrix}1 \\\\ 1 \\\\ 0\\end{pmatrix},\n$$\n使得 $A = [a_{1} \\; a_{2} \\; a_{3} \\; a_{4}] \\in \\mathbb{R}^{3 \\times 4}$，并令 $b = \\begin{pmatrix}1 \\\\ 2 \\\\ 3\\end{pmatrix} \\in \\mathbb{R}^{3}$。使用你推导的KKT条件，确定使得 $x^{\\star} = 0$ 满足该问题最优性条件的最小 $\\lambda_{0}$ 值。将你的最终答案表示为单个精确的解析表达式。不要进行四舍五入。", "solution": "该问题要求推导组套索优化问题的 Karush-Kuhn-Tucker (KKT) 条件，推导其相关的近端算子，并求解一个特定实例。目标函数为 $F(x) = f(x) + h(x)$，其中 $f(x) = \\frac{1}{2}\\|Ax - b\\|_{2}^{2}$ 是一个可微的凸函数，而 $h(x) = \\lambda \\|x\\|_{2,1}$ 是一个不可微的凸函数。这里 $\\|x\\|_{2,1} = \\sum_{g \\in \\mathcal{G}} \\|x_{g}\\|_{2}$。\n\n**1) KKT 条件的推导**\n\n向量 $x^{\\star} \\in \\mathbb{R}^{n}$ 是凸函数 $F(x)$ 的极小值点，当且仅当它满足一阶最优性条件：\n$$\n0 \\in \\partial F(x^{\\star})\n$$\n由于 $f(x)$ 是可微的，和函数 $F(x) = f(x) + h(x)$ 的次微分由 $f(x)$ 的梯度和 $h(x)$ 的次微分之和给出：\n$$\n\\partial F(x^{\\star}) = \\nabla f(x^{\\star}) + \\partial h(x^{\\star})\n$$\n$f(x)$ 的梯度是 $\\nabla f(x) = A^T(Ax - b)$。最优性条件变为：\n$$\n0 \\in A^T(Ax^{\\star} - b) + \\partial h(x^{\\star})\n$$\n这等价于：\n$$\n-A^T(Ax^{\\star} - b) \\in \\partial h(x^{\\star})\n$$\n函数 $h(x) = \\lambda \\|x\\|_{2,1} = \\lambda \\sum_{g \\in \\mathcal{G}} \\|x_g\\|_2$ 关于组 $\\mathcal{G}$ 是可分的。其次微分是每项次微分的笛卡尔积：\n$$\n\\partial h(x) = \\partial \\left(\\lambda \\sum_{g \\in \\mathcal{G}} \\|x_g\\|_2\\right) = \\lambda \\prod_{g \\in \\mathcal{G}} \\partial \\|x_g\\|_2\n$$\n向量 $z$ 的欧几里得范数 $\\|z\\|_2$ 的次微分是：\n$$\n\\partial \\|z\\|_2 = \\begin{cases} \\{z / \\|z\\|_2\\}  \\text{若 } z \\neq 0 \\\\ \\{u \\mid \\|u\\|_2 \\le 1\\}  \\text{若 } z = 0 \\end{cases}\n$$\n其中 $\\{u \\mid \\|u\\|_2 \\le 1\\}$ 是相应维度中的闭单位球。\n\n令 $r^{\\star} = A^T(b - Ax^{\\star})$ 为残差相关向量。最优性条件 $-A^T(Ax^{\\star} - b) \\in \\partial h(x^{\\star})$ 可写为 $r^{\\star} \\in \\lambda \\partial \\|x^{\\star}\\|_{2,1}$。\n我们根据组 $\\mathcal{G}$ 划分 $r^{\\star}$，$r^{\\star} = [r^{\\star}_g]_{g \\in \\mathcal{G}}$。对应于组 $g$ 中索引的 $A$ 的子矩阵记为 $A_g$。则 $r^{\\star}_g = A_g^T (b - Ax^{\\star})$。最优性条件可以对每个组 $g \\in \\mathcal{G}$ 表示为：\n$$\nA_g^T (b - Ax^{\\star}) \\in \\lambda \\partial \\|x_g^{\\star}\\|_2\n$$\n我们对每个组 $g$ 的这个条件分两种情况进行分析：\n\n情况 1：$x_g^{\\star} \\ne 0$。\n在这种情况下，$\\partial \\|x_g^{\\star}\\|_2 = \\{x_g^{\\star} / \\|x_g^{\\star}\\|_2\\}$。条件变为：\n$$\nA_g^T (b - Ax^{\\star}) = \\lambda \\frac{x_g^{\\star}}{\\|x_g^{\\star}\\|_2}\n$$\n两边取欧几里得范数得到 $\\|A_g^T (b - Ax^{\\star})\\|_2 = \\lambda$。\n\n情况 2：$x_g^{\\star} = 0$。\n在这种情况下，$\\partial \\|x_g^{\\star}\\|_2 = \\{u_g \\mid \\|u_g\\|_2 \\le 1\\}$。条件变为：\n$$\nA_g^T (b - Ax^{\\star}) \\in \\lambda \\{u_g \\mid \\|u_g\\|_2 \\le 1\\}\n$$\n这等价于说左边向量的范数必须小于或等于 $\\lambda$：\n$$\n\\|A_g^T (b - Ax^{\\star})\\|_2 \\le \\lambda\n$$\n这些就是极小值点 $x^{\\star}$ 的按组 KKT 条件。\n\n**2) 近端算子与近端梯度迭代**\n\n函数 $\\psi(x)$ 的近端算子定义为 $\\text{prox}_{\\psi}(v) = \\arg\\min_{x} \\left(\\psi(x) + \\frac{1}{2}\\|x - v\\|_2^2\\right)$。\n我们对 $h(x) = \\lambda \\|x\\|_{2,1}$ 的近端算子感兴趣。令 $\\alpha  0$ 为步长。我们需要计算 $\\text{prox}_{\\alpha h}(v)$。\n$$\n\\text{prox}_{\\alpha h}(v) = \\arg\\min_{x} \\left(\\alpha\\lambda \\|x\\|_{2,1} + \\frac{1}{2}\\|x - v\\|_2^2\\right)\n$$\n目标函数在组 $g \\in \\mathcal{G}$ 之间是可分的：\n$$\n\\alpha\\lambda \\sum_{g \\in \\mathcal{G}} \\|x_g\\|_2 + \\frac{1}{2} \\sum_{g \\in \\mathcal{G}} \\|x_g - v_g\\|_2^2\n$$\n我们可以对每个块 $x_g$ 独立地进行最小化：\n$$\n\\hat{x}_g = \\arg\\min_{x_g} \\left(\\alpha\\lambda \\|x_g\\|_2 + \\frac{1}{2}\\|x_g - v_g\\|_2^2\\right)\n$$\n令 $\\mu = \\alpha\\lambda$。该子问题的一阶最优性条件是：\n$$\n0 \\in \\mu \\partial \\|\\hat{x}_g\\|_2 + (\\hat{x}_g - v_g) \\quad \\iff \\quad v_g - \\hat{x}_g \\in \\mu \\partial \\|\\hat{x}_g\\|_2\n$$\n情况 A：$\\hat{x}_g \\ne 0$。条件是 $v_g - \\hat{x}_g = \\mu \\frac{\\hat{x}_g}{\\|\\hat{x}_g\\|_2}$。\n这意味着 $v_g = \\hat{x}_g \\left(1 + \\frac{\\mu}{\\|\\hat{x}_g\\|_2}\\right)$。由此可见，$\\hat{x}_g$ 必须是 $v_g$ 的正标量倍数。两边取范数：\n$\\|v_g\\|_2 = \\|\\hat{x}_g\\|_2 \\left(1 + \\frac{\\mu}{\\|\\hat{x}_g\\|_2}\\right) = \\|\\hat{x}_g\\|_2 + \\mu$。\n因此，$\\|\\hat{x}_g\\|_2 = \\|v_g\\|_2 - \\mu$。由于 $\\|\\hat{x}_g\\|_2  0$，这种情况只有在 $\\|v_g\\|_2  \\mu$ 时才可能。\n将此代回，我们得到 $v_g = \\hat{x}_g \\frac{\\|v_g\\|_2}{\\|v_g\\|_2 - \\mu}$，这给出 $\\hat{x}_g = \\frac{\\|v_g\\|_2 - \\mu}{\\|v_g\\|_2} v_g = \\left(1 - \\frac{\\mu}{\\|v_g\\|_2}\\right) v_g$。\n\n情况 B：$\\hat{x}_g = 0$。条件是 $v_g \\in \\mu \\partial \\|0\\|_2$，这意味着 $\\|v_g\\|_2 \\le \\mu$。\n\n结合这两种情况，每个块的解是：\n$$\n\\hat{x}_g = \\begin{cases} \\left(1 - \\frac{\\alpha\\lambda}{\\|v_g\\|_2}\\right) v_g  \\text{若 } \\|v_g\\|_2  \\alpha\\lambda \\\\ 0  \\text{若 } \\|v_g\\|_2 \\le \\alpha\\lambda \\end{cases}\n$$\n这可以使用正部函数 $(\\cdot)_+ = \\max(0, \\cdot)$ 紧凑地写为：\n$$\n\\hat{x}_g = \\left(1 - \\frac{\\alpha\\lambda}{\\|v_g\\|_2}\\right)_+ v_g\n$$\n这就是块软阈值规则。\n\n最小化 $f(x) + h(x)$ 的近端梯度法是一种迭代算法，由下式给出：\n$$\nx^{(k+1)} = \\text{prox}_{\\alpha h}\\left(x^{(k)} - \\alpha \\nabla f(x^{(k)})\\right)\n$$\n其中 $\\alpha  0$ 是步长。对于我们的问题，这变为：\n$$\nx^{(k+1)} = \\text{prox}_{\\alpha\\lambda \\|\\cdot\\|_{2,1}}\\left(x^{(k)} - \\alpha A^T(Ax^{(k)} - b)\\right)\n$$\n应用我们推导的块软阈值算子，令 $v^{(k)} = x^{(k)} - \\alpha A^T(Ax^{(k)} - b)$。每个组 $g \\in \\mathcal{G}$ 的更新为：\n$$\nx_g^{(k+1)} = \\left(1 - \\frac{\\alpha\\lambda}{\\|v_g^{(k)}\\|_2}\\right)_+ v_g^{(k)}\n$$\n\n**3) 得到零解的最小 $\\lambda$**\n\n我们寻找最小的 $\\lambda_0  0$，使得 $x^{\\star} = 0$ 是一个极小值点。使用第1部分的KKT条件，我们必须满足非活跃组（即 $x_g^{\\star}=0$）的条件。由于当 $x^{\\star}=0$ 时所有组都是非活跃的，我们必须对所有 $g \\in \\mathcal{G}$ 有：\n$$\n\\|A_g^T (b - A \\cdot 0)\\|_2 \\le \\lambda\n$$\n这简化为对所有 $g \\in \\mathcal{G}$ 都有 $\\|A_g^T b\\|_2 \\le \\lambda$。\n为了对所有组都满足这个条件，$\\lambda$ 必须大于或等于这些范数的最大值。因此，这样的最小 $\\lambda$ 是：\n$$\n\\lambda_0 = \\max_{g \\in \\mathcal{G}} \\|A_g^T b\\|_2\n$$\n现在，我们使用特定实例的数据：$m=3$，$n=4$。\n$A = \\begin{pmatrix} 1  0  0  1 \\\\ 0  1  0  1 \\\\ 0  0  1  0 \\end{pmatrix}$，$b = \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix}$。\n组是 $g_1 = \\{1,4\\}$ 和 $g_2 = \\{2,3\\}$。\n\n列子矩阵是：\n$A_{g_1}$（$A$ 的第 $1$ 和第 $4$ 列）：$A_{g_1} = \\begin{pmatrix} 1  1 \\\\ 0  1 \\\\ 0  0 \\end{pmatrix}$。\n$A_{g_2}$（$A$ 的第 $2$ 和第 $3$ 列）：$A_{g_2} = \\begin{pmatrix} 0  0 \\\\ 1  0 \\\\ 0  1 \\end{pmatrix}$。\n\n接下来，我们为每个组计算 $A_g^T b$。\n对于组 $g_1$：\n$$\nA_{g_1}^T b = \\begin{pmatrix} 1  0  0 \\\\ 1  1  0 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} (1)(1)+(0)(2)+(0)(3) \\\\ (1)(1)+(1)(2)+(0)(3) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 3 \\end{pmatrix}\n$$\n欧几里得范数是 $\\|A_{g_1}^T b\\|_2 = \\sqrt{1^2 + 3^2} = \\sqrt{1+9} = \\sqrt{10}$。\n\n对于组 $g_2$：\n$$\nA_{g_2}^T b = \\begin{pmatrix} 0  1  0 \\\\ 0  0  1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 2 \\\\ 3 \\end{pmatrix} = \\begin{pmatrix} (0)(1)+(1)(2)+(0)(3) \\\\ (0)(1)+(0)(2)+(1)(3) \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 3 \\end{pmatrix}\n$$\n欧几里得范数是 $\\|A_{g_2}^T b\\|_2 = \\sqrt{2^2 + 3^2} = \\sqrt{4+9} = \\sqrt{13}$。\n\n最小的 $\\lambda_0$ 是这些值的最大值：\n$$\n\\lambda_0 = \\max \\left( \\|A_{g_1}^T b\\|_2, \\|A_{g_2}^T b\\|_2 \\right) = \\max(\\sqrt{10}, \\sqrt{13}) = \\sqrt{13}\n$$", "answer": "$$\n\\boxed{\\sqrt{13}}\n$$", "id": "3457329"}]}