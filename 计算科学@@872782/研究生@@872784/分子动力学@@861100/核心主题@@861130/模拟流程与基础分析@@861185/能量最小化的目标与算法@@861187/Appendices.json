{"hands_on_practices": [{"introduction": "能量最小化的本质是在一个高维的势能面上进行搜索。为了直观地理解这一过程，本练习将势能面简化为一个二维玩具模型。通过该模型，我们可以通过解析方法练习识别势能面的关键特征——驻点、局部最小值、全局最小值以及鞍点，并理解Hessian矩阵在表征曲率和分类驻点中的核心作用。这个练习为理解更复杂的优化算法在分子模拟中旨在实现的目标，奠定了坚实的直觉基础。[@problem_id:3410230]", "problem": "在分子动力学能量最小化中，研究者寻找势能面的驻点，并通过局域曲率对其进行分类，以确定极小值点及其吸引盆，这为最速下降法或牛顿类方法等局域最小化算法的初始化提供了信息。考虑一个二维玩具势\n$$\nU(x,y) = (x^{2}-1)^{2} + (y^{2}-1)^{2} + 0.2\\, x y.\n$$\n仅从驻点满足梯度为零以及海森矩阵编码局域曲率以用于分类的定义出发，完成以下任务：\n- 推导驻点条件，并精确求解所有驻点。\n- 计算海森矩阵，并在每个驻点处对其进行评估，利用海森矩阵的定性将每个驻点分类为局域极小值点、局域极大值点或鞍点。\n- 利用能量值，确定哪些极小值点是全局最低的，并讨论在分子动力学的局域能量最小化算法中，哪些极小值点是相关的初始化目标。\n\n对于最终答案，仅报告四个局域极小值点的坐标，并按以下顺序排列：首先是 $x0$ 的全局极小值点，然后是其符号相反的对应点，接着是第一象限中符号相同的极小值点，最后是其符号相反的对应点。所有数值需用根式精确表示，不得四舍五入，并格式化为单行矩阵 $\\big[x_{1},y_{1},x_{2},y_{2},x_{3},y_{3},x_{4},y_{4}\\big]$。无需单位，不允许四舍五入。", "solution": "用户提供的问题经检验，是科学上合理的、适定的、客观且自洽的。该问题是多元微积分和优化理论中的一个标准练习，应用于计算物理和计算化学中的一个核心概念。此问题可利用已有的数学原理解答。\n\n势能由函数 $U(x,y)$ 给出：\n$$\nU(x,y) = (x^{2}-1)^{2} + (y^{2}-1)^{2} + 0.2\\, x y\n$$\n\n**1. 驻点的推导与求解**\n\n驻点是势能梯度 $\\nabla U(x,y)$ 为零向量的位置 $(x,y)$。我们首先计算 $U(x,y)$ 的一阶偏导数。\n\n$$\n\\frac{\\partial U}{\\partial x} = \\frac{\\partial}{\\partial x} \\left( (x^{2}-1)^{2} + (y^{2}-1)^{2} + 0.2xy \\right) = 2(x^{2}-1)(2x) + 0.2y = 4x^{3} - 4x + 0.2y\n$$\n$$\n\\frac{\\partial U}{\\partial y} = \\frac{\\partial}{\\partial y} \\left( (x^{2}-1)^{2} + (y^{2}-1)^{2} + 0.2xy \\right) = 2(y^{2}-1)(2y) + 0.2x = 4y^{3} - 4y + 0.2x\n$$\n\n驻点条件为 $\\frac{\\partial U}{\\partial x} = 0$ 和 $\\frac{\\partial U}{\\partial y} = 0$。这产生了一个由两个耦合多项式方程组成的方程组：\n$$\n(1) \\quad 4x^{3} - 4x + 0.2y = 0\n$$\n$$\n(2) \\quad 4y^{3} - 4y + 0.2x = 0\n$$\n\n为了求解该方程组，我们可以利用其对称性。将方程 $(1)$ 减去方程 $(2)$：\n$$\n(4x^{3} - 4y^{3}) - (4x - 4y) + (0.2y - 0.2x) = 0\n$$\n$$\n4(x^{3} - y^{3}) - 4.2(x - y) = 0\n$$\n$$\n4(x-y)(x^{2}+xy+y^{2}) - 4.2(x-y) = 0\n$$\n$$\n(x-y) \\left[ 4(x^{2}+xy+y^{2}) - 4.2 \\right] = 0\n$$\n这意味着 $x = y$ 或 $4(x^{2}+xy+y^{2}) = 4.2$，可简化为 $x^{2}+xy+y^{2} = 1.05 = \\frac{21}{20}$。\n\n现在，将方程 $(1)$ 和方程 $(2)$ 相加：\n$$\n(4x^{3} + 4y^{3}) - (4x + 4y) + (0.2y + 0.2x) = 0\n$$\n$$\n4(x^{3} + y^{3}) - 3.8(x + y) = 0\n$$\n$$\n4(x+y)(x^{2}-xy+y^{2}) - 3.8(x+y) = 0\n$$\n$$\n(x+y) \\left[ 4(x^{2}-xy+y^{2}) - 3.8 \\right] = 0\n$$\n这意味着 $x = -y$ 或 $4(x^{2}-xy+y^{2}) = 3.8$，可简化为 $x^{2}-xy+y^{2} = 0.95 = \\frac{19}{20}$。\n\n一个驻点必须同时满足一个由减法得到的结果和一个由加法得到的结果。我们分析以下四种可能的情况：\n\n情况 A：$x=y$ 且 $x=-y$。这意味着 $x=0$ 且 $y=0$。我们找到驻点 $(0,0)$。\n\n情况 B：$x=y$ 且 $x^{2}-xy+y^{2} = \\frac{19}{20}$。将 $y=x$ 代入第二个方程，得到 $x^{2}-x^{2}+x^{2} = \\frac{19}{20}$，因此 $x^{2} = \\frac{19}{20}$。这产生两个驻点：$(\\sqrt{\\frac{19}{20}}, \\sqrt{\\frac{19}{20}})$ 和 $(-\\sqrt{\\frac{19}{20}}, -\\sqrt{\\frac{19}{20}})$。\n\n情况 C：$x=-y$ 且 $x^{2}+xy+y^{2} = \\frac{21}{20}$。将 $y=-x$ 代入第二个方程，得到 $x^{2}-x^{2}+x^{2} = \\frac{21}{20}$，因此 $x^{2} = \\frac{21}{20}$。这产生两个驻点：$(\\sqrt{\\frac{21}{20}}, -\\sqrt{\\frac{21}{20}})$ 和 $(-\\sqrt{\\frac{21}{20}}, \\sqrt{\\frac{21}{20}})$。\n\n情况 D：$x^{2}+xy+y^{2} = \\frac{21}{20}$ 且 $x^{2}-xy+y^{2} = \\frac{19}{20}$。这是一个由两个方程组成的方程组。将它们相加得到 $2(x^{2}+y^{2}) = \\frac{21}{20} + \\frac{19}{20} = \\frac{40}{20} = 2$，因此 $x^{2}+y^{2} = 1$。从第一个方程中减去第二个方程得到 $2xy = \\frac{21}{20} - \\frac{19}{20} = \\frac{2}{20} = \\frac{1}{10}$，因此 $xy = \\frac{1}{20}$。\n将 $y=\\frac{1}{20x}$ 代入 $x^{2}+y^{2}=1$：$x^{2} + (\\frac{1}{20x})^{2} = 1 \\implies x^{2} + \\frac{1}{400x^{2}} = 1$。\n令 $u=x^{2}$。则 $u + \\frac{1}{400u} = 1 \\implies 400u^{2} - 400u + 1 = 0$。\n$u$ 的解为 $u = \\frac{400 \\pm \\sqrt{400^{2} - 4(400)(1)}}{800} = \\frac{400 \\pm \\sqrt{160000-1600}}{800} = \\frac{400 \\pm \\sqrt{158400}}{800} = \\frac{400 \\pm 120\\sqrt{11}}{800} = \\frac{10 \\pm 3\\sqrt{11}}{20}$。\n这给出了 $(x^{2}, y^{2})$ 的两对可能值：$(\\frac{10+3\\sqrt{11}}{20}, \\frac{10-3\\sqrt{11}}{20})$ 以及反之亦然。由于 $xy=\\frac{1}{20}0$，$x$ 和 $y$ 必须同号。这产生四个驻点：\n$(\\pm\\sqrt{\\frac{10+3\\sqrt{11}}{20}}, \\pm\\sqrt{\\frac{10-3\\sqrt{11}}{20}})$ 和 $(\\pm\\sqrt{\\frac{10-3\\sqrt{11}}{20}}, \\pm\\sqrt{\\frac{10+3\\sqrt{11}}{20}})$。\n\n总共有 $1+2+2+4=9$ 个驻点。\n\n**2. 海森矩阵与驻点分类**\n\n为了对这些点进行分类，我们计算海森矩阵 $H(x,y)$：\n$$\nH(x,y) = \\begin{pmatrix} \\frac{\\partial^{2} U}{\\partial x^{2}}  \\frac{\\partial^{2} U}{\\partial x \\partial y} \\\\ \\frac{\\partial^{2} U}{\\partial y \\partial x}  \\frac{\\partial^{2} U}{\\partial y^{2}} \\end{pmatrix} = \\begin{pmatrix} 12x^{2}-4  0.2 \\\\ 0.2  12y^{2}-4 \\end{pmatrix}\n$$\n驻点的性质由海森矩阵的特征值决定，而特征值可以通过其行列式 $\\det(H)$ 和迹 $\\text{Tr}(H)$ 来推断。\n- 局域极小值点：$\\det(H)  0$，$\\text{Tr}(H)  0$。\n- 局域极大值点：$\\det(H)  0$，$\\text{Tr}(H)  0$。\n- 鞍点：$\\det(H)  0$。\n\n9个点的分类：\n- 对于 $(0,0)$：$H(0,0) = \\begin{pmatrix} -4  0.2 \\\\ 0.2  -4 \\end{pmatrix}$。$\\det(H) = 16 - 0.04 = 15.96  0$。$\\text{Tr}(H) = -8  0$。这是一个**局域极大值点**。\n\n- 对于 $(\\pm\\sqrt{\\frac{19}{20}}, \\pm\\sqrt{\\frac{19}{20}})$：$x^{2}=y^{2}=\\frac{19}{20}$。\n$12x^{2}-4 = 12(\\frac{19}{20})-4 = \\frac{57}{5}-4 = \\frac{37}{5} = 7.4$。\n$H = \\begin{pmatrix} 7.4  0.2 \\\\ 0.2  7.4 \\end{pmatrix}$。$\\det(H) = (7.4)^{2} - 0.04 = 54.76-0.04 = 54.72  0$。$\\text{Tr}(H) = 14.8  0$。这两点是**局域极小值点**。\n\n- 对于 $(\\pm\\sqrt{\\frac{21}{20}}, \\mp\\sqrt{\\frac{21}{20}})$：$x^{2}=y^{2}=\\frac{21}{20}$。\n$12x^{2}-4 = 12(\\frac{21}{20})-4 = \\frac{63}{5}-4 = \\frac{43}{5} = 8.6$。\n$H = \\begin{pmatrix} 8.6  0.2 \\\\ 0.2  8.6 \\end{pmatrix}$。$\\det(H) = (8.6)^{2} - 0.04 = 73.96-0.04 = 73.92  0$。$\\text{Tr}(H) = 17.2  0$。这两点是**局域极小值点**。\n\n- 对于情况 D 中的四点：我们有 $x^{2}+y^{2}=1$ 和 $xy=\\frac{1}{20}$。\n$\\det(H) = (12x^{2}-4)(12y^{2}-4) - 0.04 = 144x^{2}y^{2} - 48(x^{2}+y^{2}) + 16 - 0.04$。\n$\\det(H) = 144(xy)^{2} - 48(x^{2}+y^{2}) + 15.96 = 144(\\frac{1}{20})^{2} - 48(1) + 15.96 = \\frac{144}{400} - 48 + 15.96 = 0.36 - 48 + 15.96 = -31.68  0$。\n这四点是**鞍点**。\n\n所以，总共有四个局域极小值点。\n\n**3. 全局极小值点与讨论**\n\n我们在四个局域极小值点处计算势能 $U(x,y)$ 以确定全局极小值点。\n$U(x,y) = (x^{2}-1)^{2} + (y^{2}-1)^{2} + 0.2xy$。\n\n对于极小值点 $(\\pm\\sqrt{\\frac{19}{20}}, \\pm\\sqrt{\\frac{19}{20}})$：\n$x^{2}=y^{2}=\\frac{19}{20}$，且对这两点，$xy=x^2=\\frac{19}{20}$。\n$U = (\\frac{19}{20}-1)^{2} + (\\frac{19}{20}-1)^{2} + 0.2(\\frac{19}{20}) = (-\\frac{1}{20})^{2} + (-\\frac{1}{20})^{2} + \\frac{1}{5}\\frac{19}{20} = \\frac{1}{400} + \\frac{1}{400} + \\frac{19}{100} = \\frac{2}{400} + \\frac{76}{400} = \\frac{78}{400} = \\frac{39}{200}$。\n\n对于极小值点 $(\\pm\\sqrt{\\frac{21}{20}}, \\mp\\sqrt{\\frac{21}{20}})$：\n$x^{2}=y^{2}=\\frac{21}{20}$，且对这两点，$xy=-x^2=-\\frac{21}{20}$。\n$U = (\\frac{21}{20}-1)^{2} + (\\frac{21}{20}-1)^{2} - 0.2(\\frac{21}{20}) = (\\frac{1}{20})^{2} + (\\frac{1}{20})^{2} - \\frac{1}{5}\\frac{21}{20} = \\frac{1}{400} + \\frac{1}{400} - \\frac{21}{100} = \\frac{2}{400} - \\frac{84}{400} = -\\frac{82}{400} = -\\frac{41}{200}$。\n\n比较能量值，$-\\frac{41}{200}  \\frac{39}{200}$。因此，两点 $(\\pm\\sqrt{\\frac{21}{20}}, \\mp\\sqrt{\\frac{21}{20}})$ 是简并的全局极小值点。另外两个极小值点是能量较高的局域极小值点。\n\n在分子动力学中，所有极小值点都具有物理意义。全局极小值点代表分子系统最稳定的构型（基态）。像最速下降法这样的局域能量最小化算法将收敛到这些状态之一。能量较高的局域极小值点代表亚稳态，系统可能被困在其中。算法找到的具体极小值点取决于其起始点（初始化），因为它通常会收敛到其起始点所在的吸引盆内的极小值点。寻找全局极小值点对于确定基态结构至关重要，而识别所有局域极小值点对于表征分子的构象景观和亚稳态非常重要。因此，所有四个极小值点都是初始化策略的相关目标。\n\n最终答案要求按指定顺序排列四个局域极小值点的坐标。我们首先将坐标有理化：\n$\\sqrt{\\frac{21}{20}} = \\frac{\\sqrt{21}}{\\sqrt{20}} = \\frac{\\sqrt{21}}{2\\sqrt{5}} = \\frac{\\sqrt{105}}{10}$。\n$\\sqrt{\\frac{19}{20}} = \\frac{\\sqrt{19}}{\\sqrt{20}} = \\frac{\\sqrt{19}}{2\\sqrt{5}} = \\frac{\\sqrt{95}}{10}$。\n\n排序如下：\n1. $x0$ 的全局极小值点：$(\\frac{\\sqrt{105}}{10}, -\\frac{\\sqrt{105}}{10})$。\n2. 其符号相反的对应点：$(-\\frac{\\sqrt{105}}{10}, \\frac{\\sqrt{105}}{10})$。\n3. 第一象限中符号相同的极小值点：$(\\frac{\\sqrt{95}}{10}, \\frac{\\sqrt{95}}{10})$。\n4. 其符号相反的对应点：$(-\\frac{\\sqrt{95}}{10}, -\\frac{\\sqrt{95}}{10})$。\n这为最终答案提供了八个坐标。", "answer": "$$\n\\boxed{\n\\begin{bmatrix}\n\\frac{\\sqrt{105}}{10}  -\\frac{\\sqrt{105}}{10}  -\\frac{\\sqrt{105}}{10}  \\frac{\\sqrt{105}}{10}  \\frac{\\sqrt{95}}{10}  \\frac{\\sqrt{95}}{10}  -\\frac{\\sqrt{95}}{10}  -\\frac{\\sqrt{95}}{10}\n\\end{bmatrix}\n}\n$$", "id": "3410230"}, {"introduction": "在确定了寻找最小值的目标之后，我们接着探索如何高效地达到这一目标。本练习介绍了共轭梯度（Fletcher–Reeves Conjugate Gradient, FR-CG）法，这是一种比最速下降法更强大的优化算法。通过对一个肽分子的能量使用二次模型近似，这个问题揭示了CG算法的一个关键理论特性：在有限步数内找到二次函数的精确最小值。这为我们深入理解该算法的快速收敛性提供了重要启示。[@problem_id:3410248]", "problem": "考虑一个小肽，其缓慢的内运动主要由两个耦合的二面角自由度决定，用角位移向量（单位为弧度）$\\theta = (\\theta_{1}, \\theta_{2})^{\\top}$ 表示。在参考构象附近，势能的键合贡献可以很好地近似为一个二次型，其刚度（海森）矩阵为对称正定矩阵；而由 Lennard-Jones (LJ) 势主导的非键相互作用被线性化，产生一个恒定的力向量。由此产生的近似势能为\n$$\nU(\\theta) \\;=\\; U_{0} \\;+\\; \\frac{1}{2}\\,\\theta^{\\top} H\\,\\theta \\;+\\; f^{\\top}\\theta,\n$$\n其中 $U_{0}$ 是一个常数偏移量，刚度矩阵为\n$$\nH \\;=\\; \\begin{pmatrix} 50  -10 \\\\ -10  20 \\end{pmatrix}\\quad\\text{(单位：kJ/(mol·rad$^{2}$))},\n$$\n线性化的非键力向量为\n$$\nf \\;=\\; \\begin{pmatrix} -40 \\\\ 15 \\end{pmatrix}\\quad\\text{(单位：kJ/(mol·rad))}.\n$$\n从初始二面角位移开始\n$$\n\\theta^{(0)} \\;=\\; \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix}\\quad\\text{(单位：弧度)},\n$$\n使用精确线搜索执行两轮 Fletcher–Reeves 共轭梯度 (FR-CG) 方法来最小化 $U(\\theta)$。可以假设向量使用标准的欧几里得内积和二范数，并且在第 $k$ 次迭代中，精确线搜索会沿着搜索方向 $d^{(k)}$ 找到使 $U(\\theta^{(k)}+\\alpha\\,d^{(k)})$ 最小化的步长 $\\alpha$。\n\n计算：\n- 两次迭代后势能的净减少量 $U(\\theta^{(0)}) - U(\\theta^{(2)})$，以 kJ/mol 为单位。\n- 两次迭代后梯度范数的减少量 $\\|\\nabla U(\\theta^{(0)})\\|_{2} - \\|\\nabla U(\\theta^{(2)})\\|_{2}$，以 kJ/(mol·rad) 为单位。\n\n将你的最终答案以一个双元行矩阵的形式报告，第一个元素等于能量减少量 $U(\\theta^{(0)}) - U(\\theta^{(2)})$，第二个元素等于梯度范数减少量 $\\|\\nabla U(\\theta^{(0)})\\|_{2} - \\|\\nabla U(\\theta^{(2)})\\|_{2}$。矩阵内不要包含单位。无需四舍五入；可接受精确值。", "solution": "系统的势能由以下二次函数给出：\n$$\nU(\\theta) = U_{0} + \\frac{1}{2}\\theta^{\\top} H\\,\\theta + f^{\\top}\\theta\n$$\n其中 $\\theta = (\\theta_1, \\theta_2)^{\\top}$ 是二面角向量。势能的梯度，我们记为 $g(\\theta)$，是：\n$$\ng(\\theta) = \\nabla U(\\theta) = H\\theta + f\n$$\n问题指定了海森矩阵 $H$、力向量 $f$ 和初始位置 $\\theta^{(0)}$：\n$$\nH = \\begin{pmatrix} 50  -10 \\\\ -10  20 \\end{pmatrix}, \\quad f = \\begin{pmatrix} -40 \\\\ 15 \\end{pmatrix}, \\quad \\theta^{(0)} = \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix} = \\begin{pmatrix} 1/5 \\\\ -1/10 \\end{pmatrix}\n$$\n目标函数 $U(\\theta)$ 是一个二维（因为 $\\theta \\in \\mathbb{R}^2$）的二次函数。海森矩阵 $H$ 是对称的。其行列式为 $\\det(H) = (50)(20) - (-10)(-10) = 1000 - 100 = 900  0$，其迹为 $\\text{tr}(H) = 50 + 20 = 70  0$。由于两个特征值都为正，所以 $H$ 是一个正定矩阵。\n\n共轭梯度 (CG) 方法的一个基本性质是，对于一个在 $n$ 维空间中具有正定海森矩阵的二次目标函数，该算法保证在至多 $n$ 次迭代内找到精确的最小值（假设使用精确算术和精确线搜索）。在这个问题中，我们在一个二维空间（$n=2$）中，所以 CG 方法将在至多 2 次迭代内找到精确的最小值 $\\theta^*$。因此，两次迭代后的位置 $\\theta^{(2)}$ 就是势能函数的精确最小值。\n$$\n\\theta^{(2)} = \\theta^*\n$$\n最小值 $\\theta^*$ 是势能梯度为零的点：\n$$\ng(\\theta^*) = \\nabla U(\\theta^*) = H\\theta^* + f = \\mathbf{0}\n$$\n这意味着第二次迭代时的梯度是零向量，$g^{(2)} = g(\\theta^{(2)}) = \\mathbf{0}$。\n\n基于此，我们可以计算所要求的两个量。\n\n首先，我们计算梯度范数的减少量，$\\|\\nabla U(\\theta^{(0)})\\|_{2} - \\|\\nabla U(\\theta^{(2)})\\|_{2}$。\n这等价于 $\\|g^{(0)}\\|_2 - \\|g^{(2)}\\|_2$。\n我们首先计算初始梯度 $g^{(0)}$：\n$$\ng^{(0)} = H\\theta^{(0)} + f = \\begin{pmatrix} 50  -10 \\\\ -10  20 \\end{pmatrix} \\begin{pmatrix} 1/5 \\\\ -1/10 \\end{pmatrix} + \\begin{pmatrix} -40 \\\\ 15 \\end{pmatrix}\n$$\n$$\ng^{(0)} = \\begin{pmatrix} 50(1/5) - 10(-1/10) \\\\ -10(1/5) + 20(-1/10) \\end{pmatrix} + \\begin{pmatrix} -40 \\\\ 15 \\end{pmatrix} = \\begin{pmatrix} 10+1 \\\\ -2-2 \\end{pmatrix} + \\begin{pmatrix} -40 \\\\ 15 \\end{pmatrix} = \\begin{pmatrix} 11 \\\\ -4 \\end{pmatrix} + \\begin{pmatrix} -40 \\\\ 15 \\end{pmatrix} = \\begin{pmatrix} -29 \\\\ 11 \\end{pmatrix}\n$$\n$g^{(0)}$ 的欧几里得范数是：\n$$\n\\|g^{(0)}\\|_2 = \\sqrt{(-29)^2 + 11^2} = \\sqrt{841 + 121} = \\sqrt{962}\n$$\n由于 $g^{(2)} = \\mathbf{0}$，其范数为 $\\|g^{(2)}\\|_2 = 0$。\n梯度范数的减少量是：\n$$\n\\|\\nabla U(\\theta^{(0)})\\|_{2} - \\|\\nabla U(\\theta^{(2)})\\|_{2} = \\sqrt{962} - 0 = \\sqrt{962}\n$$\n\n其次，我们计算势能的净减少量，$U(\\theta^{(0)}) - U(\\theta^{(2)})$。\n由于 $\\theta^{(2)} = \\theta^*$，这等于 $U(\\theta^{(0)}) - U(\\theta^*)$。\n最小值处的能量为 $U(\\theta^*) = U_0 + \\frac{1}{2}(\\theta^*)^{\\top} H\\,\\theta^* + f^{\\top}\\theta^*$。由于 $H\\theta^* = -f$，我们有 $(\\theta^*)^{\\top}H\\theta^* = -(\\theta^*)^{\\top}f$。所以，$U(\\theta^*) = U_0 - \\frac{1}{2}f^{\\top}\\theta^* + f^{\\top}\\theta^* = U_0 + \\frac{1}{2}f^{\\top}\\theta^*$。\n另一种方法是表达相对于最小值的能量差。能量函数可以写成：\n$$\nU(\\theta) - U(\\theta^*) = \\frac{1}{2}(\\theta - \\theta^*)^{\\top} H (\\theta - \\theta^*)\n$$\n因此，能量减少量为：\n$$\nU(\\theta^{(0)}) - U(\\theta^{(2)}) = U(\\theta^{(0)}) - U(\\theta^*) = \\frac{1}{2}(\\theta^{(0)} - \\theta^*)^{\\top} H (\\theta^{(0)} - \\theta^*)\n$$\n我们知道，在任意点 $\\theta$ 的梯度可以表示为 $g(\\theta) = H\\theta + f = H\\theta - H\\theta^* = H(\\theta - \\theta^*)$。\n因此，对于 $\\theta = \\theta^{(0)}$，我们有 $g^{(0)} = H(\\theta^{(0)} - \\theta^*)$。\n将此代入能量减少量的表达式中：\n$$\nU(\\theta^{(0)}) - U(\\theta^{(2)}) = \\frac{1}{2}(\\theta^{(0)} - \\theta^*)^{\\top} g^{(0)}\n$$\n为了计算这个值，我们需要找到 $\\theta^* = -H^{-1}f$。首先，我们计算 $H$ 的逆矩阵：\n$$\nH^{-1} = \\frac{1}{\\det(H)} \\begin{pmatrix} 20  10 \\\\ 10  50 \\end{pmatrix} = \\frac{1}{900} \\begin{pmatrix} 20  10 \\\\ 10  50 \\end{pmatrix} = \\frac{1}{90} \\begin{pmatrix} 2  1 \\\\ 1  5 \\end{pmatrix}\n$$\n现在我们计算 $\\theta^*$：\n$$\n\\theta^* = -H^{-1}f = -\\frac{1}{90} \\begin{pmatrix} 2  1 \\\\ 1  5 \\end{pmatrix} \\begin{pmatrix} -40 \\\\ 15 \\end{pmatrix} = -\\frac{1}{90} \\begin{pmatrix} 2(-40)+1(15) \\\\ 1(-40)+5(15) \\end{pmatrix} = -\\frac{1}{90} \\begin{pmatrix} -80+15 \\\\ -40+75 \\end{pmatrix} = -\\frac{1}{90} \\begin{pmatrix} -65 \\\\ 35 \\end{pmatrix} = \\frac{1}{18} \\begin{pmatrix} 13 \\\\ -7 \\end{pmatrix}\n$$\n所以，$\\theta^* = \\begin{pmatrix} 13/18 \\\\ -7/18 \\end{pmatrix}$。\n接下来，我们计算位移向量 $\\theta^{(0)} - \\theta^*$：\n$$\n\\theta^{(0)} - \\theta^* = \\begin{pmatrix} 1/5 \\\\ -1/10 \\end{pmatrix} - \\begin{pmatrix} 13/18 \\\\ -7/18 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{5} - \\frac{13}{18} \\\\ -\\frac{1}{10} + \\frac{7}{18} \\end{pmatrix} = \\begin{pmatrix} \\frac{18-65}{90} \\\\ \\frac{-9+35}{90} \\end{pmatrix} = \\begin{pmatrix} -47/90 \\\\ 26/90 \\end{pmatrix}\n$$\n最后，我们计算能量减少量：\n$$\nU(\\theta^{(0)}) - U(\\theta^{(2)}) = \\frac{1}{2}(\\theta^{(0)} - \\theta^*)^{\\top} g^{(0)} = \\frac{1}{2} \\begin{pmatrix} -47/90  26/90 \\end{pmatrix} \\begin{pmatrix} -29 \\\\ 11 \\end{pmatrix}\n$$\n$$\n= \\frac{1}{2} \\left( \\frac{(-47)(-29) + (26)(11)}{90} \\right) = \\frac{1}{180} (1363 + 286) = \\frac{1649}{180}\n$$\n势能的减少量为 $\\frac{1649}{180}$ kJ/mol。\n\n最终答案是一个包含能量减少量和梯度范数减少量的行矩阵。\n第一个元素：$U(\\theta^{(0)}) - U(\\theta^{(2)}) = \\frac{1649}{180}$。\n第二个元素：$\\|\\nabla U(\\theta^{(0)})\\|_{2} - \\|\\nabla U(\\theta^{(2)})\\|_{2} = \\sqrt{962}$。", "answer": "$$\n\\boxed{\\begin{bmatrix} \\frac{1649}{180}  \\sqrt{962} \\end{bmatrix}}\n$$", "id": "3410248"}, {"introduction": "对于真实的生物大分子，其能量景观并非完美的二次型，并且存储完整的Hessian矩阵在计算上是不可行的。本练习直面这一挑战，聚焦于L-BFGS (Limited-memory Broyden–Fletcher–Goldfarb–Shanno)算法。作为一种拟牛顿法，L-BFGS利用有限的先前步长历史来近似Hessian矩阵，从而有效解决了内存瓶颈。通过亲手实现其核心的双循环递归算法，你将直接体验到使大规模系统能量最小化在计算上成为可能的关键机制。[@problem_id:3410324]", "problem": "您需要实现一个程序，该程序使用规范的双循环递归计算有限内存 Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) 方法的搜索方向，然后在一组小的、受控的输入上评估有限内存对计算出的方向的影响。其背景是分子动力学中的能量最小化，目标是在原子坐标的构型空间上最小化一个可微的势能函数 $U(\\mathbf{x})$。其基本原理如下：梯度是通过 $\\nabla U(\\mathbf{x})$ 从势能导出的力，牛顿法通过将海森矩阵的逆矩阵应用于梯度来构建搜索方向，而拟牛顿法使用连续步骤中的曲率信息来构造海森矩阵逆矩阵的近似。在 L-BFGS 方法中，仅保留有限数量 $m$ 的近期曲率对。程序必须实现双循环递归来计算搜索方向，并将其用于固定的输入。\n\n目标计算是纯数学的。令 $\\mathbf{g} \\in \\mathbb{R}^n$ 为当前梯度，其中 $n$ 是维度（此处 $n = 3$）。令 $\\{(\\mathbf{s}_i,\\mathbf{y}_i)\\}$ 为最近的步长和梯度差对，其中 $\\mathbf{s}_i = \\mathbf{x}_{i+1} - \\mathbf{x}_i$ 且 $\\mathbf{y}_i = \\nabla U(\\mathbf{x}_{i+1}) - \\nabla U(\\mathbf{x}_i)$。L-BFGS 双循环递归使用最多 $m$ 个最近的对来构造一个近似的海森逆矩阵作用 $H_k \\mathbf{g}$，从而生成搜索方向 $\\mathbf{p}_k = - H_k \\mathbf{g}$。您必须实现标准的双循环递归，并遵循以下鲁棒性规则：为避免除法不稳定，跳过任何满足 $ \\mathbf{y}_i^\\top \\mathbf{s}_i \\le \\epsilon $（其中 $\\epsilon = 10^{-10}$）的对。初始海森逆矩阵 $H_0$ 必须是一个缩放的单位矩阵 $H_0 = \\gamma I$，其中标量 $\\gamma$ 从最后一个有效对中选择，即 $\\gamma = (\\mathbf{s}_{\\ell}^\\top \\mathbf{y}_{\\ell}) / (\\mathbf{y}_{\\ell}^\\top \\mathbf{y}_{\\ell})$，$\\ell$ 是最近有效对的索引；如果没有有效对，则使用 $\\gamma = 1$。\n\n您将为以下测试套件计算搜索方向。在每种情况下，曲率对 $\\mathbf{y}_i$ 都是通过对称正定矩阵 $B$ 生成的，即 $\\mathbf{y}_i = B \\mathbf{s}_i$，这确保了在良态情况下割线关系 $\\mathbf{y}_i^\\top \\mathbf{s}_i  0$ 成立。所有向量和矩阵都在 $\\mathbb{R}^3$ 中。\n\n- 测试用例 1 (理想路径):\n  - $B^{(1)} = \\begin{bmatrix} 4.0  0.1  0.0 \\\\ 0.1  2.0  0.2 \\\\ 0.0  0.2  3.0 \\end{bmatrix}$。\n  - $\\mathbf{s}_1^{(1)} = [\\,0.10,\\,-0.20,\\,0.05\\,]$, $\\mathbf{s}_2^{(1)} = [\\,-0.05,\\,0.10,\\,-0.02\\,]$。\n  - $\\mathbf{y}_i^{(1)} = B^{(1)} \\mathbf{s}_i^{(1)}$ 对于 $i \\in \\{1,2\\}$。\n  - $\\mathbf{g}^{(1)} = [\\,1.00,\\,-2.00,\\,0.50\\,]$, $m^{(1)} = 2$。\n\n- 测试用例 2 (无内存的边界条件):\n  - 没有可用的对，因此集合 $\\{(\\mathbf{s}_i,\\mathbf{y}_i)\\}$ 为空。\n  - $\\mathbf{g}^{(2)} = [\\,-0.30,\\,0.40,\\,0.10\\,]$, $m^{(2)} = 0$。\n  - 结果应简化为使用 $H_0 = I$ 的缩放梯度下降。\n\n- 测试用例 3 (病态对，因阈值而跳过):\n  - $B^{(2)} = \\begin{bmatrix} 2.0  0.05  0.0 \\\\ 0.05  1.8  0.03 \\\\ 0.0  0.03  4.0 \\end{bmatrix}$。\n  - $\\mathbf{s}_1^{(2)} = [\\,10^{-6},\\,-10^{-6},\\,2 \\cdot 10^{-6}\\,]$。\n  - $\\mathbf{y}_1^{(2)} = B^{(2)} \\mathbf{s}_1^{(2)}$。\n  - $\\mathbf{g}^{(3)} = [\\,0.30,\\,-0.10,\\,0.05\\,]$, $m^{(3)} = 1$。\n  - 应用 $\\epsilon = 10^{-10}$ 的跳过规则；如果该对被跳过，则回退到 $H_0 = I$。\n\n- 测试用例 4 (有限内存截断效应):\n  - $B^{(3)} = \\begin{bmatrix} 3.0  0.1  0.2 \\\\ 0.1  2.5  0.0 \\\\ 0.2  0.0  1.8 \\end{bmatrix}$。\n  - $\\mathbf{s}_1^{(3)} = [\\,0.20,\\,-0.10,\\,0.00\\,]$, $\\mathbf{s}_2^{(3)} = [\\,-0.10,\\,0.05,\\,0.10\\,]$, $\\mathbf{s}_3^{(3)} = [\\,0.00,\\,-0.15,\\,0.20\\,]$, $\\mathbf{s}_4^{(3)} = [\\,0.05,\\,0.00,\\,-0.10\\,]$。\n  - $\\mathbf{y}_i^{(3)} = B^{(3)} \\mathbf{s}_i^{(3)}$ 对于 $i \\in \\{1,2,3,4\\}$。\n  - $\\mathbf{g}^{(4)} = [\\,0.50,\\,0.40,\\,-0.30\\,]$, $m^{(4)} = 3$。\n  - 在提供的四个曲率对中，仅使用最后的 $m^{(4)}$ 个。\n\n- 测试用例 5 (内存参数大于可用对数量):\n  - $B^{(4)} = \\begin{bmatrix} 1.5  0.0  0.0 \\\\ 0.0  1.2  0.1 \\\\ 0.0  0.1  2.2 \\end{bmatrix}$。\n  - $\\mathbf{s}_1^{(4)} = [\\,0.30,\\,-0.20,\\,0.10\\,]$, $\\mathbf{s}_2^{(4)} = [\\,-0.20,\\,0.10,\\,-0.05\\,]$。\n  - $\\mathbf{y}_i^{(4)} = B^{(4)} \\mathbf{s}_i^{(4)}$ 对于 $i \\in \\{1,2\\}$。\n  - $\\mathbf{g}^{(5)} = [\\,-1.00,\\,0.50,\\,0.20\\,]$, $m^{(5)} = 5$。\n  - 仅使用可用的对，即 $\\min(m, \\text{对的数量})$。\n\n您的程序必须为每个测试用例计算 L-BFGS 搜索方向 $\\mathbf{p} \\in \\mathbb{R}^3$，并将结果汇总到单行输出中。要求的最终输出格式是包含逗号分隔的结果方向向量列表的单行，其中每个向量表示为包含三个浮点数的 Python 风格列表，所有内容都包含在外层方括号中（例如，$[\\,[p_{11},p_{12},p_{13}],\\,[p_{21},p_{22},p_{23}]\\,]$）。不涉及物理单位，角度也不适用。数值应完全按照算法规定进行计算，除了默认的浮点表示外，没有额外的四舍五入要求。", "solution": "该问题要求实现有限内存Broyden–Fletcher–Goldfarb–Shanno (L-BFGS) 双循环递归算法，以计算用于非线性优化的搜索方向。其背景是分子动力学中的能量最小化，目标是找到原子坐标 $\\mathbf{x} \\in \\mathbb{R}^n$ 的构型空间上势能函数 $U(\\mathbf{x})$ 的一个局部最小值。在迭代 $k$ 次时的搜索方向 $\\mathbf{p}_k$ 是为了找到一个能降低能量的步长而计算的。\n\n在拟牛顿法中，搜索方向由 $\\mathbf{p}_k = -H_k \\mathbf{g}_k$ 给出，其中 $\\mathbf{g}_k = \\nabla U(\\mathbf{x}_k)$ 是势能的梯度（原子上受力的负值），而 $H_k$ 是海森矩阵 $\\nabla^2 U(\\mathbf{x}_k)$ 逆矩阵的近似。L-BFGS 方法是一种特殊的拟牛顿法，它不存储稠密的 $n \\times n$ 矩阵 $H_k$。相反，它存储了 $m$ 个最近的步长向量 $\\mathbf{s}_i = \\mathbf{x}_{i+1} - \\mathbf{x}_i$ 和梯度差向量 $\\mathbf{y}_i = \\mathbf{g}_{i+1} - \\mathbf{g}_i$ 的有限历史记录。这些对 $(\\mathbf{s}_i, \\mathbf{y}_i)$ 捕获了有关势能面曲率的信息。\n\n任务的核心是实现 L-BFGS 双循环递归，该递归使用存储的对通过算法计算矩阵-向量积 $H_k \\mathbf{g}_k$。\n\n算法流程如下：\n令当前梯度为 $\\mathbf{g}$，存储的历史对集合为 $\\{(\\mathbf{s}_i, \\mathbf{y}_i)\\}_{i=1}^M$，其中 $M$ 是正在使用的有效对的数量，按从最旧到最新的顺序排列。要考虑的对的数量由内存参数 $m$ 和可用对的数量决定。只有当一对 $(\\mathbf{s}_i, \\mathbf{y}_i)$ 满足曲率条件 $\\mathbf{y}_i^\\top \\mathbf{s}_i  \\epsilon$ 时，才被认为是有效的，其中 $\\epsilon = 10^{-10}$ 是一个小的正阈值，用以确保数值稳定并使海森矩阵的近似保持正定。\n\n双循环递归算法是：\n1.  初始化向量 $\\mathbf{q} = \\mathbf{g}$。\n2.  **第一个循环（反向传递）：** 此循环从最新的对 ($i=M$) 反向迭代到最旧的对 ($i=1$)。在此循环中，我们基于每次 BFGS 更新的效果依次更新 $\\mathbf{q}$。\n    对于 $i = M, M-1, \\dots, 1$：\n    -   存储标量 $\\alpha_i = \\rho_i \\mathbf{s}_i^\\top \\mathbf{q}$，其中 $\\rho_i = 1 / (\\mathbf{y}_i^\\top \\mathbf{s}_i)$。\n    -   更新向量：$\\mathbf{q} \\leftarrow \\mathbf{q} - \\alpha_i \\mathbf{y}_i$。\n    计算出的 $\\alpha_i$ 值列表被保存下来用于第二个循环。\n\n3.  **初始海森矩阵近似：** 需要一个海森逆矩阵的初始近似 $H_0$。一个常见且有效的选择是缩放的单位矩阵 $H_0 = \\gamma I$。选择缩放因子 $\\gamma$ 是为了基于最近的曲率信息来近似真实海森逆矩阵的量级。它使用最近的有效对 $(\\mathbf{s}_M, \\mathbf{y}_M)$ 计算得出，即 $\\gamma = (\\mathbf{s}_M^\\top \\mathbf{y}_M) / (\\mathbf{y}_M^\\top \\mathbf{y}_M)$。如果没有可用的有效历史对，则使用默认值 $\\gamma=1$，这使得该方法在该步简化为最速下降法。然后，将第一个循环得到的向量 $\\mathbf{q}$ 乘以 $\\gamma$ 以产生新向量 $\\mathbf{r} = \\gamma \\mathbf{q}$。这一步等价于计算 $\\mathbf{r} = H_0 \\mathbf{q}$。\n\n4.  **第二个循环（正向传递）：** 此循环从最旧的对 ($i=1$) 正向迭代到最近的对 ($i=M$)，以重构最终的搜索向量。\n    对于 $i = 1, 2, \\dots, M$：\n    -   计算一个中间标量 $\\beta = \\rho_i \\mathbf{y}_i^\\top \\mathbf{r}$。\n    -   更新向量：$\\mathbf{r} \\leftarrow \\mathbf{r} + (\\alpha_i - \\beta) \\mathbf{s}_i$。$\\alpha_i$ 值是第一个循环中保存的值。\n\n5.  **最终搜索方向：** 得到的向量 $\\mathbf{r}$ 是 $H_k \\mathbf{g}_k$ 的近似。最终的搜索方向是它的负值：$\\mathbf{p} = -\\mathbf{r}$。\n\n对 5 个测试用例中的每一个都执行此过程。每个用例的输入包括梯度 $\\mathbf{g}$、一组步长向量 $\\{\\mathbf{s}_i\\}$、一种通过矩阵 $B$ 生成相应梯度差 $\\{\\mathbf{y}_i\\}$ 的方法，以及内存参数 $m$。实现必须正确处理基于 $m$ 选择对、筛选曲率条件以及为空历史应用回退规则的逻辑。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_lbfgs_direction(g, s_list, y_list, m, epsilon):\n    \"\"\"\n    Computes the L-BFGS search direction using the two-loop recursion.\n\n    Args:\n        g (np.ndarray): The current gradient vector.\n        s_list (list of np.ndarray): List of step vectors, oldest to newest.\n        y_list (list of np.ndarray): List of gradient difference vectors, oldest to newest.\n        m (int): The memory parameter, number of pairs to store.\n        epsilon (float): Threshold for the curvature condition y.s  epsilon.\n\n    Returns:\n        list: The computed search direction vector as a Python list.\n    \"\"\"\n    # 1. Determine which pairs to use based on memory m and availability.\n    num_available = len(s_list)\n    # The problem specifies using min(m, num_available) of the MOST RECENT pairs.\n    num_to_consider = min(m, num_available)\n    \n    if num_to_consider  0:\n        s_to_consider = s_list[-num_to_consider:]\n        y_to_consider = y_list[-num_to_consider:]\n    else:\n        s_to_consider = []\n        y_to_consider = []\n\n    # 2. Filter these pairs for validity (curvature condition).\n    history = []\n    for s, y in zip(s_to_consider, y_to_consider):\n        ys = np.dot(y, s)\n        if ys  epsilon:\n            history.append((s, y))\n    \n    M_hist = len(history)\n    q = np.copy(g)\n\n    # 3. Handle case with no valid history.\n    if M_hist == 0:\n        # Per problem spec, if no valid pairs, use gamma = 1.\n        p = -q\n        return p.tolist()\n\n    # 4. Calculate scaling factor gamma for H_0.\n    s_last, y_last = history[-1]\n    gamma = np.dot(s_last, y_last) / np.dot(y_last, y_last)\n    \n    # 5. First loop (backward pass) to update q.\n    alphas = [0.0] * M_hist\n    for i in range(M_hist - 1, -1, -1):\n        s_i, y_i = history[i]\n        rho_i = 1.0 / np.dot(y_i, s_i)\n        alphas[i] = rho_i * np.dot(s_i, q)\n        q = q - alphas[i] * y_i\n        \n    # 6. Apply initial Hessian approximation.\n    r = gamma * q\n    \n    # 7. Second loop (forward pass) to build the final direction.\n    for i in range(M_hist):\n        s_i, y_i = history[i]\n        rho_i = 1.0 / np.dot(y_i, s_i)\n        beta = rho_i * np.dot(y_i, r)\n        r = r + (alphas[i] - beta) * s_i\n\n    # 8. Final search direction is the negative of the result.\n    p = -r\n    return p.tolist()\n\ndef solve():\n    \"\"\"\n    Sets up and solves the test cases defined in the problem.\n    \"\"\"\n    epsilon = 1e-10\n\n    test_cases = []\n\n    # Case 1\n    B1 = np.array([[4.0, 0.1, 0.0], [0.1, 2.0, 0.2], [0.0, 0.2, 3.0]])\n    s1_list = [np.array([0.10, -0.20, 0.05]), np.array([-0.05, 0.10, -0.02])]\n    y1_list = [B1 @ s for s in s1_list]\n    g1 = np.array([1.00, -2.00, 0.50])\n    m1 = 2\n    test_cases.append({'g': g1, 's_list': s1_list, 'y_list': y1_list, 'm': m1})\n\n    # Case 2\n    g2 = np.array([-0.30, 0.40, 0.10])\n    m2 = 0\n    test_cases.append({'g': g2, 's_list': [], 'y_list': [], 'm': m2})\n\n    # Case 3\n    B2 = np.array([[2.0, 0.05, 0.0], [0.05, 1.8, 0.03], [0.0, 0.03, 4.0]])\n    s2_list = [np.array([1e-6, -1e-6, 2e-6])]\n    y2_list = [B2 @ s for s in s2_list]\n    g3 = np.array([0.30, -0.10, 0.05])\n    m3 = 1\n    test_cases.append({'g': g3, 's_list': s2_list, 'y_list': y2_list, 'm': m3})\n\n    # Case 4\n    B3 = np.array([[3.0, 0.1, 0.2], [0.1, 2.5, 0.0], [0.2, 0.0, 1.8]])\n    s3_list = [\n        np.array([0.20, -0.10, 0.00]),\n        np.array([-0.10, 0.05, 0.10]),\n        np.array([0.00, -0.15, 0.20]),\n        np.array([0.05, 0.00, -0.10]),\n    ]\n    y3_list = [B3 @ s for s in s3_list]\n    g4 = np.array([0.50, 0.40, -0.30])\n    m4 = 3\n    test_cases.append({'g': g4, 's_list': s3_list, 'y_list': y3_list, 'm': m4})\n    \n    # Case 5\n    B4 = np.array([[1.5, 0.0, 0.0], [0.0, 1.2, 0.1], [0.0, 0.1, 2.2]])\n    s4_list = [\n        np.array([0.30, -0.20, 0.10]),\n        np.array([-0.20, 0.10, -0.05]),\n    ]\n    y4_list = [B4 @ s for s in s4_list]\n    g5 = np.array([-1.00, 0.50, 0.20])\n    m5 = 5\n    test_cases.append({'g': g5, 's_list': s4_list, 'y_list': y4_list, 'm': m5})\n\n    results = []\n    for case in test_cases:\n        p = compute_lbfgs_direction(case['g'], case['s_list'], case['y_list'], case['m'], epsilon)\n        results.append(p)\n\n    # The default string representation of a list is exactly what is required.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3410324"}]}