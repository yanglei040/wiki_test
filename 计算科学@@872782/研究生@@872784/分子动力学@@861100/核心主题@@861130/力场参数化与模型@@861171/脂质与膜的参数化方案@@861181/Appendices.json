{"hands_on_practices": [{"introduction": "将模拟结果与实验数据联系起来是力场验证的关键一步。氘序参数（$S_{CD}$）是验证脂质尾链构象的一个核心观测量，可直接通过核磁共振（NMR）实验测得。本练习将指导你从第一性原理出发，通过处理分子轨迹数据来计算 $S_{CD}$，这是评估膜力场准确性的基本功。[@problem_id:3422101]", "problem": "要求您从第一性原理出发，实现一个算法，根据合成轨迹计算脂质酰基链的氘序参数 (S_CD)。在分子动力学 (MD) 的脂质和膜参数化方案中，氘序参数用于对照核磁共振 (NMR) 测量结果来验证力场。氘序参数量化了碳-氢键相对于膜双层法线的平均取向。\n\n从以下基本原理开始：\n- 在帧 $f$ 中的双层法线是一个矢量 $\\mathbf{n}^{(f)}$，不一定经过归一化。\n- 在帧 $f$ 中，碳 $i$ 和氢 $h$ 的键矢量为 $\\mathbf{v}_{i,h}^{(f)} = \\mathbf{r}_{i,h}^{(f)} - \\mathbf{r}_{i}^{(f)}$，其中 $\\mathbf{r}_{i}^{(f)}$ 是碳原子的位置，$\\mathbf{r}_{i,h}^{(f)}$ 是与其成键的氢原子的位置。\n- 瞬时取向由归一化键矢量 $\\hat{\\mathbf{u}}_{i,h}^{(f)} = \\mathbf{v}_{i,h}^{(f)} / \\|\\mathbf{v}_{i,h}^{(f)}\\|$ 和归一化双层法线 $\\hat{\\mathbf{n}}^{(f)} = \\mathbf{n}^{(f)} / \\|\\mathbf{n}^{(f)}\\|$ 之间夹角 $\\theta_{i,h}^{(f)}$ 的余弦值来表征，即 $\\cos \\theta_{i,h}^{(f)} = \\hat{\\mathbf{u}}_{i,h}^{(f)} \\cdot \\hat{\\mathbf{n}}^{(f)}$。\n- 氘序参数定义为 $\\cos \\theta$ 的第二勒让德多项式 $P_{2}(x)$ 的系综平均。第二勒让德多项式为 $P_{2}(x) = \\frac{1}{2}\\left(3x^{2} - 1\\right)$。\n- 每键瞬时序为 $S_{i,h}^{(f)} = P_{2}\\!\\left(\\cos \\theta_{i,h}^{(f)}\\right)$。\n- 每碳瞬时序是在该帧中对与该碳成键的所有氢原子进行平均，即 $S_{i}^{(f)} = \\frac{1}{|H_{i}|} \\sum_{h \\in H_{i}} S_{i,h}^{(f)}$，而最终的每碳序参数是时间平均值 $S_{i} = \\frac{1}{F} \\sum_{f=1}^{F} S_{i}^{(f)}$。\n\n您必须实现一个程序，该程序：\n- 对于每个测试用例，接收一个帧列表。对于每一帧 $f$，给定一个双层法线 $\\mathbf{n}^{(f)}$，以及对于每个碳 $i$，一个碳位置 $\\mathbf{r}_{i}^{(f)}$ 和一组氢位置 $\\{\\mathbf{r}_{i,h}^{(f)}\\}_{h \\in H_{i}}$。\n- 计算 $\\hat{\\mathbf{n}}^{(f)}$、每个 $\\hat{\\mathbf{u}}_{i,h}^{(f)}$、余弦值 $\\cos \\theta_{i,h}^{(f)}$、瞬时 $S_{i,h}^{(f)}$、每帧的 $S_{i}^{(f)}$，以及通过对所有帧进行平均来计算每个碳的最终 $S_{i}$。\n- 如果您显式计算任何角度 $\\theta$（这是可选的），则必须使用弧度。但是，建议您通过点积直接计算 $\\cos \\theta$ 以避免任何角度计算。\n- 对于每个测试用例，输出最终的每碳 $S_{i}$ 列表，四舍五入到六位小数。\n- 将所有测试用例的输出聚合为单行，形式为一个由方括号括起来的逗号分隔列表，其中包含每个测试用例的一个列表，且没有空格（例如 $[$list\\_1$,$list\\_2$,$list\\_3$]$）。每个测试用例的列表本身必须是一个由方括号括起来、逗号分隔的六位小数浮点数列表。\n\n所有位置均以任意长度单位的笛卡尔坐标给出。序参数 $S_{i}$ 是无量纲的，并且必须以四舍五入到六位小数的浮点数形式报告。不使用外部输入；所有测试用例都嵌入在您的代码中。\n\n要实现的测试套件：\n\n- 测试用例 1（两个碳，两个帧，法线固定）：\n  - 帧 1：\n    - 双层法线：$\\mathbf{n}^{(1)} = (0.0, 0.0, 1.0)$。\n    - 碳 1：$\\mathbf{r}_{1}^{(1)} = (0.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{1,1}^{(1)} = (0.866025403784, 0.0, 0.5)$ 和 $\\mathbf{r}_{1,2}^{(1)} = (0.0, 0.866025403784, 0.5)$。\n    - 碳 2：$\\mathbf{r}_{2}^{(1)} = (1.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{2,1}^{(1)} = (1.5, 0.0, 0.866025403784)$ 和 $\\mathbf{r}_{2,2}^{(1)} = (2.0, 0.0, 0.0)$。\n  - 帧 2：\n    - 双层法线：$\\mathbf{n}^{(2)} = (0.0, 0.0, 1.0)$。\n    - 碳 1：$\\mathbf{r}_{1}^{(2)} = (0.1, 0.1, 0.0)$；氢原子 $\\mathbf{r}_{1,1}^{(2)} = (0.807106781187, 0.1, 0.707106781187)$ 和 $\\mathbf{r}_{1,2}^{(2)} = (0.1, 0.807106781187, 0.707106781187)$。\n    - 碳 2：$\\mathbf{r}_{2}^{(2)} = (1.0, 0.2, 0.0)$；氢原子 $\\mathbf{r}_{2,1}^{(2)} = (2.0, 0.2, 0.0)$ 和 $\\mathbf{r}_{2,2}^{(2)} = (1.0, 1.2, 0.0)$。\n\n- 测试用例 2（边界取向以及变化的法线大小和符号）：\n  - 帧 1：\n    - 双层法线：$\\mathbf{n}^{(1)} = (0.0, 0.0, 2.0)$。\n    - 碳 3：$\\mathbf{r}_{3}^{(1)} = (0.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{3,1}^{(1)} = (0.0, 0.0, 1.0)$ 和 $\\mathbf{r}_{3,2}^{(1)} = (0.0, 0.0, 2.0)$。\n    - 碳 4：$\\mathbf{r}_{4}^{(1)} = (1.0, 1.0, 0.0)$；氢原子 $\\mathbf{r}_{4,1}^{(1)} = (2.0, 1.0, 0.0)$ 和 $\\mathbf{r}_{4,2}^{(1)} = (1.0, 2.0, 0.0)$。\n  - 帧 2：\n    - 双层法线：$\\mathbf{n}^{(2)} = (0.0, 0.0, -3.0)$。\n    - 碳 3：$\\mathbf{r}_{3}^{(2)} = (0.0, 0.0, 0.5)$；氢原子 $\\mathbf{r}_{3,1}^{(2)} = (0.0, 0.0, 1.5)$ 和 $\\mathbf{r}_{3,2}^{(2)} = (0.0, 0.0, 2.5)$。\n    - 碳 4：$\\mathbf{r}_{4}^{(2)} = (1.0, 1.0, 0.5)$；氢原子 $\\mathbf{r}_{4,1}^{(2)} = (2.0, 1.0, 0.5)$ 和 $\\mathbf{r}_{4,2}^{(2)} = (1.0, 2.0, 0.5)$。\n\n- 测试用例 3（确定性地实现各向同性取向，使得预期平均值恰好为零）：\n  - 帧 1：\n    - 双层法线：$\\mathbf{n}^{(1)} = (0.0, 0.0, 1.0)$。\n    - 碳 5：$\\mathbf{r}_{5}^{(1)} = (0.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{5,1}^{(1)} = (0.0, 0.0, 1.0)$ 和 $\\mathbf{r}_{5,2}^{(1)} = (0.0, 0.0, -1.0)$。\n  - 帧 2：\n    - 双层法线：$\\mathbf{n}^{(2)} = (0.0, 0.0, 1.0)$。\n    - 碳 5：$\\mathbf{r}_{5}^{(2)} = (0.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{5,1}^{(2)} = (1.0, 0.0, 0.0)$ 和 $\\mathbf{r}_{5,2}^{(2)} = (-1.0, 0.0, 0.0)$。\n  - 帧 3：\n    - 双层法线：$\\mathbf{n}^{(3)} = (0.0, 0.0, 1.0)$。\n    - 碳 5：$\\mathbf{r}_{5}^{(3)} = (0.0, 0.0, 0.0)$；氢原子 $\\mathbf{r}_{5,1}^{(3)} = (0.0, 1.0, 0.0)$ 和 $\\mathbf{r}_{5,2}^{(3)} = (0.0, -1.0, 0.0)$。\n\n您的程序必须生成单行输出，其中包含三个测试用例的结果，格式为由方括号括起来的逗号分隔列表，且无空格，其中每个数字都四舍五入到六位小数，例如：$[[s_{1,1},s_{1,2}],[s_{2,1},s_{2,2}],[s_{3,1}]]$ 但不带空格。具体来说，确切的格式必须类似于 $[[0.000000,0.000000],[0.000000,0.000000],[0.000000]]$。", "solution": "该问题是有效的，因为它具有科学依据、定义明确且客观。它提供了计算氘序参数 $S_{CD}$ 所需的正式定义和所有必要数据，该参数是脂质双层分子动力学模拟中的一个标准度量。\n\n计算最终每碳序参数 $S_i$ 的过程涉及一个分层平均过程，从瞬时键取向开始，对等效的氢原子和时间（模拟帧）进行平均。该算法通过直接应用所提供的公式来实现。\n\n首先，我们定义基本量。对于包含 $F$ 帧的轨迹中的每一帧 $f$，给定一个双层法线矢量 $\\mathbf{n}^{(f)}$，以及对于每个碳原子 $i$，其位置 $\\mathbf{r}_i^{(f)}$ 和与其成键的氢原子的位置 $\\{\\mathbf{r}_{i,h}^{(f)}\\}_{h \\in H_i}$。\n\n关键的取向度量是一个特定的碳-氢键矢量与双层法线之间的夹角 $\\theta_{i,h}^{(f)}$。使用归一化矢量的点积可以最有效地计算该值。\n\n将双层法线矢量 $\\mathbf{n}^{(f)}$ 归一化以获得单位矢量 $\\hat{\\mathbf{n}}^{(f)}$：\n$$\n\\hat{\\mathbf{n}}^{(f)} = \\frac{\\mathbf{n}^{(f)}}{\\|\\mathbf{n}^{(f)}\\|}\n$$\n类似地，对于每个碳-氢对 $(i, h)$，键矢量 $\\mathbf{v}_{i,h}^{(f)}$ 通过从氢原子的位置减去碳原子的位置来计算：\n$$\n\\mathbf{v}_{i,h}^{(f)} = \\mathbf{r}_{i,h}^{(f)} - \\mathbf{r}_{i}^{(f)}\n$$\n然后将该键矢量归一化以得到单位矢量 $\\hat{\\mathbf{u}}_{i,h}^{(f)}$：\n$$\n\\hat{\\mathbf{u}}_{i,h}^{(f)} = \\frac{\\mathbf{v}_{i,h}^{(f)}}{\\|\\mathbf{v}_{i,h}^{(f)}\\|}\n$$\n这两个单位矢量之间夹角 $\\theta_{i,h}^{(f)}$ 的余弦值是它们的点积：\n$$\n\\cos \\theta_{i,h}^{(f)} = \\hat{\\mathbf{u}}_{i,h}^{(f)} \\cdot \\hat{\\mathbf{n}}^{(f)}\n$$\n氘序参数基于第二勒让德多项式 $P_2(x) = \\frac{1}{2}(3x^2 - 1)$ 定义。在帧 $f$ 中单个键 $(i, h)$ 的瞬时序参数为：\n$$\nS_{i,h}^{(f)} = P_2(\\cos \\theta_{i,h}^{(f)}) = \\frac{1}{2}\\left(3(\\cos \\theta_{i,h}^{(f)})^2 - 1\\right)\n$$\n请注意，由于 $\\cos^2(\\theta) = \\cos^2(\\pi-\\theta)$，序参数对法线矢量的方向（例如 $(0,0,1)$ 与 $(0,0,-1)$）不敏感，这是一个物理上必需的性质。\n\n下一步是将此量对与给定碳原子 $i$ 成键的所有氢原子进行平均。这是必要的，因为对于像甲基 ($CH_3$) 或亚甲基 ($CH_2$) 这样的基团，在模拟旨在复现的实验（NMR）的时间尺度上，单个的 C-H 键通常是动态等效的。因此，每碳瞬时序 $S_i^{(f)}$ 为：\n$$\nS_{i}^{(f)} = \\frac{1}{|H_i|} \\sum_{h \\in H_i} S_{i,h}^{(f)}\n$$\n其中 $|H_i|$ 是与碳 $i$ 成键的氢原子数。\n\n最后，模拟提供了这些瞬时值的时间序列。碳 $i$ 的最终序参数 $S_i$ 是系综平均，计算为轨迹所有 $F$ 帧上的时间平均：\n$$\nS_{i} = \\left\\langle S_i^{(f)} \\right\\rangle_f = \\frac{1}{F} \\sum_{f=1}^{F} S_{i}^{(f)}\n$$\n此过程系统地应用于每个测试用例中指定的每个碳原子。实现将使用像 NumPy 这样的数值库来高效地执行矢量运算，如减法、范数计算和点积。每个碳的最终结果被收集并以要求的格式呈现。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the deuterium order parameter (S_CD) for lipid acyl chains \n    from synthetic trajectory data provided in predefined test cases.\n    \"\"\"\n    test_cases = [\n        # Test Case 1: Two carbons, two frames, normal fixed.\n        [\n            # Frame 1\n            {\n                \"n\": np.array([0.0, 0.0, 1.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.0]), \"r_hs\": [np.array([0.866025403784, 0.0, 0.5]), np.array([0.0, 0.866025403784, 0.5])] },\n                    { \"r_c\": np.array([1.0, 0.0, 0.0]), \"r_hs\": [np.array([1.5, 0.0, 0.866025403784]), np.array([2.0, 0.0, 0.0])] }\n                ]\n            },\n            # Frame 2\n            {\n                \"n\": np.array([0.0, 0.0, 1.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.1, 0.1, 0.0]), \"r_hs\": [np.array([0.807106781187, 0.1, 0.707106781187]), np.array([0.1, 0.807106781187, 0.707106781187])] },\n                    { \"r_c\": np.array([1.0, 0.2, 0.0]), \"r_hs\": [np.array([2.0, 0.2, 0.0]), np.array([1.0, 1.2, 0.0])] }\n                ]\n            }\n        ],\n        # Test Case 2: Boundary orientations and varying normal.\n        [\n            # Frame 1\n            {\n                \"n\": np.array([0.0, 0.0, 2.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.0]), \"r_hs\": [np.array([0.0, 0.0, 1.0]), np.array([0.0, 0.0, 2.0])] },\n                    { \"r_c\": np.array([1.0, 1.0, 0.0]), \"r_hs\": [np.array([2.0, 1.0, 0.0]), np.array([1.0, 2.0, 0.0])] }\n                ]\n            },\n            # Frame 2\n            {\n                \"n\": np.array([0.0, 0.0, -3.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.5]), \"r_hs\": [np.array([0.0, 0.0, 1.5]), np.array([0.0, 0.0, 2.5])] },\n                    { \"r_c\": np.array([1.0, 1.0, 0.5]), \"r_hs\": [np.array([2.0, 1.0, 0.5]), np.array([1.0, 2.0, 0.5])] }\n                ]\n            }\n        ],\n        # Test Case 3: Isotropic orientation.\n        [\n            # Frame 1\n            {\n                \"n\": np.array([0.0, 0.0, 1.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.0]), \"r_hs\": [np.array([0.0, 0.0, 1.0]), np.array([0.0, 0.0, -1.0])] }\n                ]\n            },\n            # Frame 2\n            {\n                \"n\": np.array([0.0, 0.0, 1.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.0]), \"r_hs\": [np.array([1.0, 0.0, 0.0]), np.array([-1.0, 0.0, 0.0])] }\n                ]\n            },\n            # Frame 3\n            {\n                \"n\": np.array([0.0, 0.0, 1.0]),\n                \"carbons\": [\n                    { \"r_c\": np.array([0.0, 0.0, 0.0]), \"r_hs\": [np.array([0.0, 1.0, 0.0]), np.array([0.0, -1.0, 0.0])] }\n                ]\n            }\n        ]\n    ]\n\n    all_results = []\n    for case_data in test_cases:\n        num_frames = len(case_data)\n        num_carbons = len(case_data[0][\"carbons\"])\n        s_i_sum_over_frames = np.zeros(num_carbons)\n\n        for frame in case_data:\n            n_vec = frame[\"n\"]\n            # Normalize the bilayer normal\n            n_norm = np.linalg.norm(n_vec)\n            if n_norm == 0: continue # Should not happen with valid data\n            n_hat = n_vec / n_norm\n\n            for i, carbon_data in enumerate(frame[\"carbons\"]):\n                r_c = carbon_data[\"r_c\"]\n                r_hs = carbon_data[\"r_hs\"]\n                num_hydrogens = len(r_hs)\n                s_ih_sum_for_carbon = 0.0\n\n                for r_h in r_hs:\n                    # Calculate and normalize the C-H bond vector\n                    v_ih = r_h - r_c\n                    v_norm = np.linalg.norm(v_ih)\n                    if v_norm == 0: continue # Should not happen\n                    u_hat_ih = v_ih / v_norm\n                    \n                    # Calculate cos(theta) using the dot product\n                    cos_theta = np.dot(u_hat_ih, n_hat)\n                    \n                    # Calculate the instantaneous order parameter for the bond\n                    s_ih = 0.5 * (3 * cos_theta**2 - 1)\n                    s_ih_sum_for_carbon += s_ih\n                \n                # Average over hydrogens for the current carbon and frame\n                s_i_f = s_ih_sum_for_carbon / num_hydrogens if num_hydrogens > 0 else 0.0\n                s_i_sum_over_frames[i] += s_i_f\n        \n        # Average over frames for each carbon\n        final_s_i_values = s_i_sum_over_frames / num_frames if num_frames > 0 else np.zeros(num_carbons)\n        all_results.append(final_s_i_values)\n\n    # Format the final output string exactly as required\n    formatted_case_results = []\n    for result_list in all_results:\n        formatted_numbers = [f\"{val:.6f}\" for val in result_list]\n        formatted_case_results.append(f\"[{','.join(formatted_numbers)}]\")\n    \n    final_output = f\"[{','.join(formatted_case_results)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3422101"}, {"introduction": "生物膜的宏观力学性质，如面积压缩模量（$K_A$），源于其微观层面的热涨落。根据涨落-耗散定理，我们可以通过分析模拟中膜面积的波动来提取这些重要的材料参数。本练习旨在让你推导并实现一个考虑了恒定表面张力（$\\gamma$）的参数拟合流程，从而精确地从模拟数据中确定膜的内在弹性参数。[@problem_id:3422138]", "problem": "要求您在分子动力学 (MD) 的背景下，为脂质双分子层面积模型设计并实现一种恒定表面张力参数化路径。目标是在拟合过程中施加预设的表面张力，并分析该约束如何改变表观面积压缩模量和表观脂质面积。从第一性原理推导拟合算法，并将其实现为一个能够生成可数值检验输出的完整程序。\n\n考虑一个总面积为 $A$ 的膜片，由 $N$ 个相同的脂质分子组成，每个脂质分子的面积为 $a = A/N$。在施加张力为 $\\gamma$ 的恒定表面张力系综中，采用标准的谐波弹性自由能模型来描述面积涨落：\n$$\nF(A) = \\frac{K_A}{2 A_0}\\left(A - A_0\\right)^2 - \\gamma\\,A,\n$$\n其中 $K_A$ 是面积压缩模量，$A_0$ 是零张力下的参考面积。温度为 $T$，玻尔兹曼常数为 $k_B$。假设系统处于充分平衡状态，且围绕平均值的涨落为高斯分布。\n\n从基础统计力学出发，利用 $F(A)$ 的曲率将涨落与热力学联系起来。对于谐波势，自由能对面积的二阶导数决定了刚度，而刚度又通过涨落-耗散关系决定了面积的方差。请用 $K_A$、$A_0$、$\\gamma$、$T$、$k_B$ 和 $N$ 推导出以下量：\n- 张力偏移后的平均单脂质面积 $a_\\mathrm{mean}(\\gamma)$。\n- 单脂质面积的方差 $v(\\gamma)$。\n然后，提出并论证一种在拟合过程中强制施加 $\\gamma$ 的拟合路径：在已知 $\\gamma$、$T$ 和 $N$ 的情况下，根据观测到的 $a_\\mathrm{mean}(\\gamma)$ 和 $v(\\gamma)$ 值，求解参考单脂质面积 $a_0 = A_0/N$ 和面积压缩模量 $K_A$。\n\n此外，定义在恒定张力下，通过将 $a_0$ 替换为张力下的观测平均值 $a_\\mathrm{mean}(\\gamma)$，从涨落中“天真地”估计出的“表观”面积压缩模量：\n$$\nK_A^\\mathrm{app}(\\gamma) \\equiv \\frac{k_B T \\, a_\\mathrm{mean}(\\gamma)}{v(\\gamma)\\,N}.\n$$\n分析恒定张力约束如何改变表观 $K_A$（与真实 $K_A$ 相比），以及 $a_\\mathrm{mean}(\\gamma)$ 与 $a_0$ 有何不同。\n\n您的程序必须：\n- 实现推导出的拟合公式，根据输入 $(\\gamma, T, N, a_\\mathrm{mean}, v)$ 计算 $a_0$ 和 $K_A$。\n- 使用上述定义计算 $K_A^\\mathrm{app}(\\gamma)$。\n- 计算单脂质面积的变异系数 $\\mathrm{CV} = \\sqrt{v}/a_\\mathrm{mean}$，并通过生成布尔标志 $\\mathrm{CV} \\le 0.05$ 来评估涨落的真实性。\n\n使用以下科学一致的测试套件。所有输入和输出必须遵守指定的单位：\n- 温度 $T$，单位为开尔文 (K)。\n- 表面张力 $\\gamma$，单位为牛顿/米 (N/m)。\n- 单脂质面积 $a$，单位为平方纳米 (nm$^2$)。\n- 单脂质方差 $v$，单位为平方纳米的平方 (nm$^4$)。\n- 面积压缩模量 $K_A$，单位为牛顿/米 (N/m)。\n对于每个测试用例，都提供了 $(\\gamma, T, N, a_\\mathrm{mean}, v)$ 的值。这些值是根据一个真实的底层参数集 $K_A = 0.25\\,\\mathrm{N/m}$ 和 $a_0 = 0.65\\,\\mathrm{nm}^2$ 在 $T = 310\\,\\mathrm{K}$ 时构建的，以确保涨落的真实性；然而，您的拟合必须仅依赖于给定的 $(\\gamma, T, N, a_\\mathrm{mean}, v)$。\n\n测试套件：\n1. $\\gamma = 0.0\\,\\mathrm{N/m}$, $T = 310\\,\\mathrm{K}$, $N = 256$, $a_\\mathrm{mean} = 0.650000\\,\\mathrm{nm}^2$, $v = 4.346887084\\times 10^{-5}\\,\\mathrm{nm}^4$.\n2. $\\gamma = 0.010\\,\\mathrm{N/m}$, $T = 310\\,\\mathrm{K}$, $N = 256$, $a_\\mathrm{mean} = 0.676000\\,\\mathrm{nm}^2$, $v = 4.346887084\\times 10^{-5}\\,\\mathrm{nm}^4$.\n3. $\\gamma = 0.040\\,\\mathrm{N/m}$, $T = 310\\,\\mathrm{K}$, $N = 256$, $a_\\mathrm{mean} = 0.754000\\,\\mathrm{nm}^2$, $v = 4.346887084\\times 10^{-5}\\,\\mathrm{nm}^4$.\n4. $\\gamma = -0.005\\,\\mathrm{N/m}$, $T = 310\\,\\mathrm{K}$, $N = 256$, $a_\\mathrm{mean} = 0.637000\\,\\mathrm{nm}^2$, $v = 4.346887084\\times 10^{-5}\\,\\mathrm{nm}^4$.\n5. $\\gamma = 0.010\\,\\mathrm{N/m}$, $T = 310\\,\\mathrm{K}$, $N = 128$, $a_\\mathrm{mean} = 0.676000\\,\\mathrm{nm}^2$, $v = 8.693774172\\times 10^{-5}\\,\\mathrm{nm}^4$.\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，输出列表 $[K_A^\\mathrm{fit}, a_0^\\mathrm{fit}, a_\\mathrm{mean}, K_A^\\mathrm{app}, \\mathrm{CV}, \\mathrm{realistic}]$，其单位为 $(\\mathrm{N/m}, \\mathrm{nm}^2, \\mathrm{nm}^2, \\mathrm{N/m}, \\text{无量纲}, \\text{布尔值})$。所有浮点数必须四舍五入到六位有效数字。最终输出格式应为单行的 $[[\\ldots],[\\ldots],\\ldots]$，不含任何额外文本。", "solution": "我们从一个适用于恒定表面张力下膜片小范围面积涨落的谐波弹性自由能模型开始。膜片面积 $A$ 的自由能为\n$$\nF(A) = \\frac{K_A}{2A_0}(A-A_0)^2 - \\gamma A,\n$$\n其中 $A_0$ 是零张力参考面积，$K_A$ 是面积压缩模量，$\\gamma$ 是施加的表面张力。$F$ 对 $A$ 的二阶导数提供了刚度：\n$$\n\\frac{\\partial^2 F}{\\partial A^2} = \\frac{K_A}{A_0}.\n$$\n在正则系综中，对于二次形式的自由能，$A$ 的概率分布是高斯分布：\n$$\nP(A) \\propto \\exp\\left[-\\beta\\left(\\frac{K_A}{2A_0}(A-A_0)^2 - \\gamma A\\right)\\right],\n$$\n其中 $\\beta = 1/(k_B T)$。与 $\\gamma$ 成正比的线性项会使平均值发生偏移，但不会改变曲率；因此可以得出两个基本结果。\n\n首先，通过最小化 $F(A)$ 来找到平均面积：\n$$\n\\left.\\frac{\\partial F}{\\partial A}\\right|_{A=\\langle A \\rangle} = \\frac{K_A}{A_0}(\\langle A \\rangle - A_0) - \\gamma = 0 \\quad \\Rightarrow \\quad \\langle A \\rangle = A_0\\left(1 + \\frac{\\gamma}{K_A}\\right).\n$$\n因此，平均单脂质面积 $a_\\mathrm{mean}(\\gamma)$ 等于\n$$\na_\\mathrm{mean}(\\gamma) = \\frac{\\langle A \\rangle}{N} = \\frac{A_0}{N}\\left(1 + \\frac{\\gamma}{K_A}\\right) = a_0\\left(1 + \\frac{\\gamma}{K_A}\\right),\n$$\n其中 $a_0 \\equiv A_0/N$ 是零张力下的参考单脂质面积。\n\n其次，面积的方差可以从二次能量的涨落-耗散关系得出：\n$$\n\\sigma_A^2 = \\frac{k_B T}{\\partial^2 F/\\partial A^2} = \\frac{k_B T}{K_A/A_0} = \\frac{k_B T \\, A_0}{K_A}.\n$$\n转换为单脂质变量 $a = A/N$ 得到单脂质方差\n$$\nv(\\gamma) \\equiv \\sigma_a^2 = \\frac{\\sigma_A^2}{N^2} = \\frac{k_B T \\, A_0}{K_A N^2} = \\frac{k_B T \\, a_0}{K_A N}.\n$$\n请注意，在此谐波近似中，$v(\\gamma)$ 与 $\\gamma$ 无关，因为曲率不受线性张力项的影响。这两个关系式，\n$$\na_\\mathrm{mean}(\\gamma) = a_0\\left(1 + \\frac{\\gamma}{K_A}\\right), \\quad v(\\gamma) = \\frac{k_B T \\, a_0}{K_A N},\n$$\n在固定的 $\\gamma$、$T$ 和 $N$ 下，为可观测量 $\\{a_\\mathrm{mean}, v\\}$ 和参数 $\\{a_0, K_A\\}$ 之间提供了一个完整的、基于第一性原理的映射。\n\n在拟合过程中强制施加 $\\gamma$ 意味着我们必须使用上述明确包含 $\\gamma$ 的表达式，并根据可观测量求解 $a_0$ 和 $K_A$。我们有两个方程和两个未知数。从涨落方程可知，\n$$\n\\frac{a_0}{K_A} = \\frac{v\\,N}{k_B T}.\n$$\n将此代入平均面积关系式中：\n$$\na_\\mathrm{mean}(\\gamma) = a_0 + \\gamma \\frac{a_0}{K_A} = a_0 + \\gamma \\frac{v\\,N}{k_B T}.\n$$\n求解 $a_0$：\n$$\na_0^\\mathrm{fit} = a_\\mathrm{mean}(\\gamma) - \\gamma \\frac{v\\,N}{k_B T}.\n$$\n然后求出 $K_A$：\n$$\nK_A^\\mathrm{fit} = \\frac{a_0^\\mathrm{fit}\\,k_B T}{v\\,N}.\n$$\n这些公式在拟合过程中明确地强制施加了张力 $\\gamma$，从而将由 $\\gamma$ 引起的平均值偏移与由涨落捕获的、源于曲率的刚度分离开来。单脂质面积的变异系数计算如下\n$$\n\\mathrm{CV} = \\frac{\\sqrt{v}}{a_\\mathrm{mean}(\\gamma)}.\n$$\n为确保真实性，一个在许多脂质上平均的典型粗粒化膜片应具有较小的 $\\mathrm{CV}$。我们通过布尔准则 $\\mathrm{CV} \\le 0.05$ 来评估其真实性。\n\n为了分析当存在 $\\gamma$ 时，如果有人“天真地”将 $a_0$ 替换为 $a_\\mathrm{mean}(\\gamma)$ 并使用涨落公式时所得到的表观面积压缩模量，我们定义\n$$\nK_A^\\mathrm{app}(\\gamma) \\equiv \\frac{k_B T \\, a_\\mathrm{mean}(\\gamma)}{v(\\gamma)\\,N}.\n$$\n使用 $v(\\gamma)$ 的正确关系式，\n$$\nv(\\gamma) = \\frac{k_B T \\, a_0}{K_A N},\n$$\n我们发现\n$$\nK_A^\\mathrm{app}(\\gamma) = \\frac{k_B T \\, a_\\mathrm{mean}(\\gamma)}{v(\\gamma)\\,N} = \\frac{k_B T \\, a_0\\left(1+\\frac{\\gamma}{K_A}\\right)}{\\left(\\frac{k_B T \\, a_0}{K_A N}\\right) N} = K_A\\left(1+\\frac{\\gamma}{K_A}\\right) = K_A + \\gamma.\n$$\n因此，在恒定张力系综中，通过这种“天真”的方法推断出的表观压缩模量与真实的 $K_A$ 相比，会产生一个等于 $\\gamma$ 的加性偏移。同样，表观脂质面积是经张力偏移的平均值 $a_\\mathrm{mean}(\\gamma) = a_0(1+\\gamma/K_A)$，在正张力下它比 $a_0$ 大，在负张力下则比 $a_0$ 小。\n\n实现细节和单位：\n- 使用 $k_B = 1.380649\\times 10^{-23}\\,\\mathrm{J/K}$ 和以开尔文为单位的给定温度 $T$。\n- 使用 $1\\,\\mathrm{nm}^2 = 10^{-18}\\,\\mathrm{m}^2$ 在 $\\mathrm{nm}^2$ 和 $\\mathrm{m}^2$ 之间转换单脂质面积。\n- 使用 $1\\,\\mathrm{nm}^4 = 10^{-36}\\,\\mathrm{m}^4$ 在 $\\mathrm{nm}^4$ 和 $\\mathrm{m}^4$ 之间转换单脂质面积方差。\n- 拟合公式在一致的国际单位制 (SI) 单位下进行计算，然后转换回要求的单位进行报告。\n- 对于每个测试用例 $(\\gamma, T, N, a_\\mathrm{mean}, v)$，计算 $[K_A^\\mathrm{fit}, a_0^\\mathrm{fit}, a_\\mathrm{mean}, K_A^\\mathrm{app}, \\mathrm{CV}, \\mathrm{realistic}]$，其中浮点值四舍五入到六位有效数字，布尔值为 True 或 False。\n\n最终输出必须是单行文本，是一个包含每个测试用例列表的顶级列表，顺序与测试套件中提供的一致，不含任何额外文本。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef round_sig(x, sig=6):\n    \"\"\"\n    Round a number to 'sig' significant digits.\n    Returns a float. Handles x=0 gracefully.\n    \"\"\"\n    if x == 0 or not np.isfinite(x):\n        return float(x)\n    # Determine decimal places needed to achieve 'sig' significant digits\n    dec = sig - int(np.floor(np.log10(abs(x)))) - 1\n    return float(np.round(x, dec))\n\ndef fit_parameters(gamma_N_per_m, T_K, N, a_mean_nm2, v_nm4):\n    \"\"\"\n    Given gamma, T, N, mean per-lipid area a_mean_nm2, and per-lipid variance v_nm4,\n    compute:\n    - a0_fit_nm2: fitted zero-tension per-lipid area\n    - KA_fit_N_per_m: fitted area compressibility modulus\n    - KA_app_N_per_m: apparent KA computed naively from fluctuations using a_mean\n    - CV: coefficient of variation sqrt(v)/a_mean\n    Also return a realism flag: CV = 0.05\n    \"\"\"\n    # Constants and unit conversions\n    kB = 1.380649e-23  # J/K\n    nm2_to_m2 = 1e-18\n    nm4_to_m4 = 1e-36\n\n    # Convert provided a_mean and v to SI units for fitting\n    a_mean_m2 = a_mean_nm2 * nm2_to_m2\n    v_m4 = v_nm4 * nm4_to_m4\n\n    # Fitting formulas derived from first principles:\n    # a0_fit = a_mean - gamma * (v * N) / (kB * T)\n    a0_fit_m2 = a_mean_m2 - gamma_N_per_m * (v_m4 * N) / (kB * T_K)\n\n    # KA_fit = (a0_fit * kB * T) / (v * N)\n    KA_fit_N_per_m = (a0_fit_m2 * kB * T_K) / (v_m4 * N) if (v_m4 * N) != 0 else 0.0\n\n    # Apparent KA using naive substitution of a_mean into fluctuation formula\n    KA_app_N_per_m = (a_mean_m2 * kB * T_K) / (v_m4 * N) if (v_m4 * N) != 0 else 0.0\n\n    # Coefficient of variation in per-lipid area\n    CV = np.sqrt(v_nm4) / a_mean_nm2 if a_mean_nm2 != 0 else 0.0\n\n    # Realism criterion\n    realistic = (CV = 0.05)\n\n    # Convert a0 back to nm^2\n    a0_fit_nm2 = a0_fit_m2 / nm2_to_m2\n\n    # Round floats to six significant digits\n    KA_fit_r = round_sig(KA_fit_N_per_m, 6)\n    a0_fit_r = round_sig(a0_fit_nm2, 6)\n    a_mean_r = round_sig(a_mean_nm2, 6)\n    KA_app_r = round_sig(KA_app_N_per_m, 6)\n    CV_r = round_sig(float(CV), 6)\n\n    return [KA_fit_r, a0_fit_r, a_mean_r, KA_app_r, CV_r, realistic]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each case: (gamma [N/m], T [K], N [lipids], a_mean [nm^2], v [nm^4])\n    test_cases = [\n        (0.0,    310.0, 256, 0.650000, 4.346887084e-5),\n        (0.010,  310.0, 256, 0.676000, 4.346887084e-5),\n        (0.040,  310.0, 256, 0.754000, 4.346887084e-5),\n        (-0.005, 310.0, 256, 0.637000, 4.346887084e-5),\n        (0.010,  310.0, 128, 0.676000, 8.693774172e-5),\n    ]\n\n    results = []\n    for case in test_cases:\n        gamma, T, N, a_mean, v = case\n        result = fit_parameters(gamma, T, N, a_mean, v)\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    # Produce a single line: top-level list of per-case lists.\n    # Custom formatting to match the unusual boolean output requirement in the example\n    result_strings = []\n    for res in results:\n        # Convert all items to string, handle boolean specifically\n        items = [str(item) for item in res]\n        result_strings.append(f\"[{','.join(items)}]\")\n    print(f\"[{','.join(result_strings)}]\")\n\nsolve()\n```", "id": "3422138"}, {"introduction": "在构建复杂的分子力场时，一个主要的挑战是避免“过拟合”——即模型在训练数据上表现完美，但在预测新情况时表现不佳。交叉验证是评估和提高模型泛化能力的一种强大统计学工具。本高级练习将引导你设计并实现一个交叉验证框架，通过在不同的目标集和脂质组分之间循环训练与验证，来量化模型的泛化误差，从而构建更稳健、可移植性更强的力场。[@problem_id:3422163]", "problem": "要求您形式化并实现一个用于脂质和膜力场参数化的交叉验证框架，该框架通过循环使用训练目标和验证目标，来量化在独立脂质组分间的过拟合程度。该框架必须使用一个关于参数的可观测量的一阶线性响应模型、一个源于高斯误差假设的且符合统计学原理的加权最小二乘目标函数，以及Tikhonov正则化。您编写的程序必须为每个测试用例计算一个标量泛化误差，并按规定将结果以单行列表形式打印。\n\n从以下基本依据和定义开始：\n- 在小参数变化下，分子动力学可观测量预测可以近似为围绕参考点的线性响应：$y \\approx y_0 + J p$，其中 $p \\in \\mathbb{R}^d$ 是参数校正向量，$y \\in \\mathbb{R}^m$ 是可观测量，$J \\in \\mathbb{R}^{m \\times d}$ 是灵敏度（雅可比）矩阵，$y_0$ 是参考预测值。\n- 在具有已知标准差 $\\sigma_i$ 的独立高斯测量误差下，加权最小二乘法是最优的，其损失函数与 $\\sum_i \\left(\\frac{r_i}{\\sigma_i}\\right)^2$ 成正比，其中 $r_i$ 是残差。这构建了一个无量纲、单位一致的目标函数。\n- Tikhonov正则化等价于对参数施加一个高斯先验，它在损失函数中增加了一项 $\\lambda \\lVert \\Gamma p \\rVert_2^2$，其中正则化强度 $\\lambda \\ge 0$，$\\Gamma$ 是一个矩阵。\n\n您将实现一个双向目标循环的留一法（留一成分）交叉验证：\n- 对于每个留出的组分 $c^\\star$，执行两轮：\n  1. 在除 $c^\\star$ 之外的所有组分上聚合的结构目标 $T=\\{A_\\mathrm{lipid}, S_{CD}\\}$ 上进行训练，并在留出的组分 $c^\\star$ 的力学目标 $V=\\{K_A, K_C\\}$ 上进行验证。\n  2. 在除 $c^\\star$ 之外的所有组分上聚合的 $V$ 上进行训练，并在留出的组分 $c^\\star$ 的 $T$ 上进行验证。\n- 对于每个训练轮次，通过在训练集上最小化正则化加权最小二乘目标函数来获得参数估计值 $\\hat p$。具体来说，如果堆叠的训练系统是 $W J \\in \\mathbb{R}^{M \\times d}$ 和 $W b \\in \\mathbb{R}^{M}$，其中 $b = y - y_0$ 是残差目标向量，$W$ 是对角线元素为 $1/\\sigma_i$ 的对角矩阵，则正规方程为\n$$\n\\left( (WJ)^\\top (WJ) + \\lambda \\Gamma^\\top \\Gamma \\right)\\hat p = (WJ)^\\top (Wb).\n$$\n- 定义每个组分、每个目标的平均归一化（无量纲）损失如下。对于任何组分 $c$ 和目标集 $X \\in \\{T,V\\}$，令 $n_X$ 为一个组分在 $X$ 中的可观测量数量。定义\n$$\n\\mathcal{L}_X(c;\\hat p) = \\frac{1}{n_X}\\left\\lVert W_X^{(c)}\\left(J_X^{(c)} \\hat p - b_X^{(c)}\\right)\\right\\rVert_2^2,\n$$\n其中 $W_X^{(c)}$ 是目标集 $X$ 的标准差倒数构成的对角矩阵，$J_X^{(c)}$ 和 $b_X^{(c)}$ 是组分 $c$ 的特定于目标的灵敏度矩阵和残差向量。\n- 对于一个给定的留出组分 $c^\\star$，将在包含的组分 $S = \\{c \\ne c^\\star\\}$ 上的训练平均归一化损失定义为\n$$\n\\overline{\\mathcal{L}}_X^{\\mathrm{train}}(\\hat p) = \\frac{1}{|S|} \\sum_{c \\in S} \\mathcal{L}_X(c;\\hat p).\n$$\n- 将针对留出组分 $c^\\star$ 的特定轮次泛化差距定义为\n$$\n\\Delta_{T \\rightarrow V}(c^\\star) = \\mathcal{L}_V(c^\\star;\\hat p_T) - \\overline{\\mathcal{L}}_T^{\\mathrm{train}}(\\hat p_T),\n$$\n$$\n\\Delta_{V \\rightarrow T}(c^\\star) = \\mathcal{L}_T(c^\\star;\\hat p_V) - \\overline{\\mathcal{L}}_V^{\\mathrm{train}}(\\hat p_V),\n$$\n其中 $\\hat p_T$ 是在 $S$ 上使用 $T$ 训练得到的，$\\hat p_V$ 是在 $S$ 上使用 $V$ 训练得到的。\n- 折的泛化误差是其对称化平均值\n$$\n\\mathcal{E}(c^\\star) = \\frac{1}{2}\\left[\\Delta_{T \\rightarrow V}(c^\\star) + \\Delta_{V \\rightarrow T}(c^\\star)\\right].\n$$\n- 最终泛化误差是所有留出组分的平均值：\n$$\n\\mathcal{E} = \\frac{1}{C} \\sum_{c^\\star=1}^C \\mathcal{E}(c^\\star).\n$$\n\n所有计算必须使用提供的数值测试套件完成。所有残差向量 $b$ 都是差值 $y - y_0$，因此您不需要显式地使用 $y_0$。权重始终是所提供标准差的倒数，并且所有损失都通过此归一化变为无量纲。使用提供的 $\\lambda$ 和 $\\Gamma$ 进行Tikhonov正则化。如果正规方程矩阵是病态的，请使用数值稳定的方法（例如，Moore–Penrose伪逆）来获得 $\\hat p$。\n\n物理单位与标度：\n- $A_\\mathrm{lipid}$ 的单位是 $\\mathrm{nm}^2$，标准差的单位也是 $\\mathrm{nm}^2$。\n- $S_{CD}$ 是无量纲的，其标准差也是无量纲的。\n- $K_A$ 的单位是 $\\mathrm{mN}/\\mathrm{m}$，标准差的单位也是 $\\mathrm{mN}/\\mathrm{m}$。\n- $K_C$ 的单位是 $k_B T$，标准差的单位也是 $k_B T$。\n- 由于通过标准差进行了加权，所有损失都是无单位的。\n\n本问题中不存在角度单位。\n\n您的程序必须实现上述内容，并为每个测试用例生成最终泛化误差 $\\mathcal{E}$。每个结果必须是四舍五入到六位小数的单个浮点数。最终输出必须是包含结果的单行，结果为逗号分隔的列表，并用方括号括起来，例如 `[0.123456,0.000001,2.718282]`。\n\n测试套件：\n- 测试用例 1（良态，实际尺度）：\n  - 参数：$d=2$, $C=3$, $\\lambda = 0.1$, $\\Gamma = \\mathrm{diag}(1,1)$。\n  - 组分 1：\n    - $J_T^{(1)} = \\begin{bmatrix} -0.08  -0.02 \\\\ 0.15  0.05 \\end{bmatrix}$, $b_T^{(1)} = \\begin{bmatrix} 0.05 \\\\ -0.08 \\end{bmatrix}$, $\\sigma_T^{(1)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(1)} = \\begin{bmatrix} 30.0  10.0 \\\\ 1.8  0.6 \\end{bmatrix}$, $b_V^{(1)} = \\begin{bmatrix} -20.0 \\\\ -1.0 \\end{bmatrix}$, $\\sigma_V^{(1)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n  - 组分 2：\n    - $J_T^{(2)} = \\begin{bmatrix} -0.09  -0.01 \\\\ 0.12  0.04 \\end{bmatrix}$, $b_T^{(2)} = \\begin{bmatrix} 0.03 \\\\ -0.05 \\end{bmatrix}$, $\\sigma_T^{(2)} = \\begin{bmatrix} 0.012 \\\\ 0.012 \\end{bmatrix}$。\n    - $J_V^{(2)} = \\begin{bmatrix} 28.0  9.0 \\\\ 1.6  0.5 \\end{bmatrix}$, $b_V^{(2)} = \\begin{bmatrix} -15.0 \\\\ -0.8 \\end{bmatrix}$, $\\sigma_V^{(2)} = \\begin{bmatrix} 12.0 \\\\ 1.2 \\end{bmatrix}$。\n  - 组分 3：\n    - $J_T^{(3)} = \\begin{bmatrix} -0.07  -0.015 \\\\ 0.10  0.03 \\end{bmatrix}$, $b_T^{(3)} = \\begin{bmatrix} 0.04 \\\\ -0.07 \\end{bmatrix}$, $\\sigma_T^{(3)} = \\begin{bmatrix} 0.011 \\\\ 0.011 \\end{bmatrix}$。\n    - $J_V^{(3)} = \\begin{bmatrix} 26.0  8.5 \\\\ 1.4  0.45 \\end{bmatrix}$, $b_V^{(3)} = \\begin{bmatrix} -18.0 \\\\ -0.9 \\end{bmatrix}$, $\\sigma_V^{(3)} = \\begin{bmatrix} 11.0 \\\\ 1.1 \\end{bmatrix}$。\n- 测试用例 2（近奇异的训练雅可比矩阵；测试正则化鲁棒性）：\n  - 参数：$d=2$, $C=3$, $\\lambda = 0.05$, $\\Gamma = \\mathrm{diag}(1,1)$。\n  - 组分 1：\n    - $J_T^{(1)} = \\begin{bmatrix} -0.08  -0.04 \\\\ 0.16  0.08 \\end{bmatrix}$, $b_T^{(1)} = \\begin{bmatrix} 0.02 \\\\ -0.04 \\end{bmatrix}$, $\\sigma_T^{(1)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(1)} = \\begin{bmatrix} 20.0  5.0 \\\\ 1.0  0.25 \\end{bmatrix}$, $b_V^{(1)} = \\begin{bmatrix} -10.0 \\\\ -0.5 \\end{bmatrix}$, $\\sigma_V^{(1)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n  - 组分 2：\n    - $J_T^{(2)} = \\begin{bmatrix} -0.081  -0.0405 \\\\ 0.162  0.081 \\end{bmatrix}$, $b_T^{(2)} = \\begin{bmatrix} 0.018 \\\\ -0.036 \\end{bmatrix}$, $\\sigma_T^{(2)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(2)} = \\begin{bmatrix} 21.0  5.2 \\\\ 1.05  0.26 \\end{bmatrix}$, $b_V^{(2)} = \\begin{bmatrix} -9.0 \\\\ -0.45 \\end{bmatrix}$, $\\sigma_V^{(2)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n  - 组分 3：\n    - $J_T^{(3)} = \\begin{bmatrix} -0.079  -0.0395 \\\\ 0.158  0.079 \\end{bmatrix}$, $b_T^{(3)} = \\begin{bmatrix} 0.022 \\\\ -0.044 \\end{bmatrix}$, $\\sigma_T^{(3)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(3)} = \\begin{bmatrix} 19.0  4.8 \\\\ 0.95  0.24 \\end{bmatrix}$, $b_V^{(3)} = \\begin{bmatrix} -11.0 \\\\ -0.55 \\end{bmatrix}$, $\\sigma_V^{(3)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n- 测试用例 3（完全一致的线性模型；预期泛化误差接近于零）：\n  - 参数：$d=2$, $C=3$, $\\lambda = 0.000001$, $\\Gamma = \\mathrm{diag}(1,1)$。存在一个真实参数向量 $p^\\star = \\begin{bmatrix} 0.5 \\\\ -0.2 \\end{bmatrix}$。残差目标是为每个组分通过 $b = J p^\\star$ 生成的，因此训练和验证目标是联合一致的。\n  - 组分 1：\n    - $J_T^{(1)} = \\begin{bmatrix} -0.06  0.01 \\\\ 0.12  -0.02 \\end{bmatrix}$, $b_T^{(1)} = \\begin{bmatrix} -0.032 \\\\ 0.064 \\end{bmatrix}$, $\\sigma_T^{(1)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(1)} = \\begin{bmatrix} 25.0  -2.0 \\\\ 1.3  -0.12 \\end{bmatrix}$, $b_V^{(1)} = \\begin{bmatrix} 12.9 \\\\ 0.674 \\end{bmatrix}$, $\\sigma_V^{(1)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n  - 组分 2：\n    - $J_T^{(2)} = \\begin{bmatrix} -0.065  0.015 \\\\ 0.11  -0.018 \\end{bmatrix}$, $b_T^{(2)} = \\begin{bmatrix} -0.0355 \\\\ 0.0586 \\end{bmatrix}$, $\\sigma_T^{(2)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(2)} = \\begin{bmatrix} 27.0  -1.8 \\\\ 1.5  -0.10 \\end{bmatrix}$, $b_V^{(2)} = \\begin{bmatrix} 13.86 \\\\ 0.77 \\end{bmatrix}$, $\\sigma_V^{(2)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n  - 组分 3：\n    - $J_T^{(3)} = \\begin{bmatrix} -0.055  0.012 \\\\ 0.105  -0.017 \\end{bmatrix}$, $b_T^{(3)} = \\begin{bmatrix} -0.0299 \\\\ 0.0559 \\end{bmatrix}$, $\\sigma_T^{(3)} = \\begin{bmatrix} 0.01 \\\\ 0.01 \\end{bmatrix}$。\n    - $J_V^{(3)} = \\begin{bmatrix} 24.0  -2.2 \\\\ 1.2  -0.13 \\end{bmatrix}$, $b_V^{(3)} = \\begin{bmatrix} 12.44 \\\\ 0.626 \\end{bmatrix}$, $\\sigma_V^{(3)} = \\begin{bmatrix} 10.0 \\\\ 1.0 \\end{bmatrix}$。\n\n答案规范：\n- 对于每个测试用例，计算如上定义的 $\\mathcal{E}$。每个输出必须是四舍五入到六位小数的浮点数。\n- 最终输出格式：您的程序必须生成一行输出，其中包含用逗号分隔并用方括号括起来的结果（例如，$[0.123456,0.000001,2.718282]$）。", "solution": "该问题提出了一个定义明确且具有科学依据的任务：形式化并实现一个交叉验证框架，以量化脂质力场参数化中的泛化误差。该方法论基于计算化学中的既定原则，包括线性响应理论、加权最小二乘优化和Tikhonov正则化。问题陈述是完整、一致的，并提供了进行求解所需的所有数学定义和数值数据。\n\n问题的核心是实现一个留一法（留一成分）交叉验证（LOOCV）方案。对于一组包含 $C$ 个不同脂质组分的数据集，我们迭代地将一个组分 $c^\\star$ 留出用于验证，并使用其余的 $S = C-1$ 个组分进行训练。该协议的独特之处在于在LOOCV的每一折内执行的“目标循环”方法。这涉及两个独立的训练和验证轮次：一轮使用结构特性 ($T$) 进行训练，用力学特性 ($V$) 进行验证；另一轮则角色互换。此过程旨在评估在一个类型的物理可观测量上训练的参数，能够多好地预测另一个独立类型的可观测量，这是对过拟合和模型可移植性的关键测试。\n\n最终度量，即泛化误差 $\\mathcal{E}$，是在所有折上计算的对称化“泛化差距”的平均值。这提供了一个单一、鲁棒的标量，用于量化模型对未见过的数据和未见过的可观测量类型的预测能力。\n\n解决方案首先定义数学组件，然后概述算法步骤。\n\n**1. 数学框架**\n\n参数优化基于最小化一个正则化的、加权的最小二乘目标函数。可观测量 $y_i$ 的预测值通过围绕参考参数集的一阶泰勒展开来近似：$y \\approx y_0 + J p$。我们的目标是找到参数校正向量 $p \\in \\mathbb{R}^d$，使其最能拟合目标值，这些目标值以残差向量 $b = y^{\\mathrm{exp}} - y_0$ 的形式给出，其中 $y^{\\mathrm{exp}}$ 是实验目标值。\n\n给定一组具有残差 $b_i$ 和相应测量不确定度 $\\sigma_i$ 的训练目标，需要最小化的目标函数是：\n$$ \\mathcal{O}(p) = \\sum_{i \\in \\text{train}} \\left(\\frac{(J p - b)_i}{\\sigma_i}\\right)^2 + \\lambda \\lVert \\Gamma p \\rVert_2^2 $$\n这里，第一项是加权残差平方和，假设误差为高斯分布，它构成一个无量纲的量。第二项是Tikhonov正则化惩罚项，其中 $\\lambda \\ge 0$ 是正则化强度，$\\Gamma$ 是一个可用于对不同参数的惩罚进行缩放的矩阵。\n\n在矩阵表示法中，设 $W$ 是一个对角矩阵，其元素为 $W_{ii} = 1/\\sigma_i$。目标函数变为：\n$$ \\mathcal{O}(p) = \\lVert W(Jp - b) \\rVert_2^2 + \\lambda \\lVert \\Gamma p \\rVert_2^2 $$\n对该目标函数关于 $p$ 进行最小化，得到正规方程：\n$$ \\left( J^\\top W^\\top W J + \\lambda \\Gamma^\\top \\Gamma \\right) \\hat p = J^\\top W^\\top W b $$\n令 $\\tilde{J} = WJ$ 和 $\\tilde{b} = Wb$，最优参数估计值 $\\hat p$ 的方程简化为：\n$$ \\left( \\tilde{J}^\\top \\tilde{J} + \\lambda \\Gamma^\\top \\Gamma \\right) \\hat p = \\tilde{J}^\\top \\tilde{b} $$\n这是一个标准的线性系统 $A\\hat p = B$，可以求解 $\\hat p$。正则化项 $\\lambda \\Gamma^\\top \\Gamma$ 确保对于 $\\lambda  0$，矩阵 $A$ 是正定的，因此是可逆的，即使 $\\tilde{J}^\\top \\tilde{J}$ 是奇异的，也能保证唯一解。\n\n问题为给定的组分 $c$ 和目标集 $X \\in \\{T, V\\}$ 定义了一个特定的无量纲损失函数：\n$$ \\mathcal{L}_X(c; \\hat p) = \\frac{1}{n_X} \\left\\lVert W_X^{(c)} \\left( J_X^{(c)} \\hat p - b_X^{(c)} \\right) \\right\\rVert_2^2 $$\n其中 $n_X$ 是单个组分在集合 $X$ 中的可观测量数量。\n\n**2. 算法实现**\n\n总泛化误差 $\\mathcal{E}$ 是通过对所有可能的留出组分 $c^\\star$ 的特定折误差 $\\mathcal{E}(c^\\star)$ 进行平均来计算的。算法如下：\n\n设 $C$ 为总组分数。对于每一折，由 $c^\\star$ 从 $1$ 到 $C$ 索引：\n\n**步骤 A：定义训练集和验证集**\n- 验证集是组分 $c^\\star$。\n- 训练集 $S$ 由所有组分 $\\{c \\mid c \\ne c^\\star\\}$ 组成。\n\n**步骤 B：第 1 轮（在 $T$ 上训练，在 $V$ 上验证）**\n1.  **组装训练数据**：连接训练集 $S$ 和目标类型 $T$ 的数据。这涉及堆叠所有 $c \\in S$ 的雅可比矩阵 $J_T^{(c)}$、残差向量 $b_T^{(c)}$ 和标准差 $\\sigma_T^{(c)}$。设堆叠后的矩阵和向量为 $J_{S,T}$、$b_{S,T}$ 和 $\\sigma_{S,T}$。\n2.  **求解参数 $\\hat p_T$**：\n    - 构建对角权重矩阵 $W_{S,T}$，其元素为训练集中所有可观测量的 $1/\\sigma_i$。\n    - 形成加权雅可比矩阵 $\\tilde{J}_{S,T} = W_{S,T} J_{S,T}$ 和加权残差向量 $\\tilde{b}_{S,T} = W_{S,T} b_{S,T}$。\n    - 求解正规方程得到 $\\hat p_T$：\n      $$ \\left( \\tilde{J}_{S,T}^\\top \\tilde{J}_{S,T} + \\lambda \\Gamma^\\top \\Gamma \\right) \\hat p_T = \\tilde{J}_{S,T}^\\top \\tilde{b}_{S,T} $$\n3.  **计算损失**：\n    - **训练损失**：计算训练集组分上的平均损失：\n      $$ \\overline{\\mathcal{L}}_T^{\\mathrm{train}}(\\hat p_T) = \\frac{1}{|S|} \\sum_{c \\in S} \\mathcal{L}_T(c; \\hat p_T) $$\n    - **验证损失**：计算在留出的验证数据上的损失：\n      $$ \\mathcal{L}_V(c^\\star; \\hat p_T) = \\frac{1}{n_V} \\left\\lVert W_V^{(c^\\star)} \\left( J_V^{(c^\\star)} \\hat p_T - b_V^{(c^\\star)} \\right) \\right\\rVert_2^2 $$\n4.  **计算泛化差距**：计算差值：\n    $$ \\Delta_{T \\rightarrow V}(c^\\star) = \\mathcal{L}_V(c^\\star; \\hat p_T) - \\overline{\\mathcal{L}}_T^{\\mathrm{train}}(\\hat p_T) $$\n\n**步骤 C：第 2 轮（在 $V$ 上训练，在 $T$ 上验证）**\n这一轮与第1轮对称。\n1.  **组装训练数据**：连接训练集 $S$ 和目标类型 $V$ 的数据，得到 $J_{S,V}$、$b_{S,V}$ 和 $\\sigma_{S,V}$。\n2.  **求解参数 $\\hat p_V$**：类似地，求解正规方程得到 $\\hat p_V$。\n3.  **计算损失**：\n    - **训练损失**：\n      $$ \\overline{\\mathcal{L}}_V^{\\mathrm{train}}(\\hat p_V) = \\frac{1}{|S|} \\sum_{c \\in S} \\mathcal{L}_V(c; \\hat p_V) $$\n    - **验证损失**：\n      $$ \\mathcal{L}_T(c^\\star; \\hat p_V) = \\frac{1}{n_T} \\left\\lVert W_T^{(c^\\star)} \\left( J_T^{(c^\\star)} \\hat p_V - b_T^{(c^\\star)} \\right) \\right\\rVert_2^2 $$\n4.  **计算泛化差距**：\n    $$ \\Delta_{V \\rightarrow T}(c^\\star) = \\mathcal{L}_T(c^\\star; \\hat p_V) - \\overline{\\mathcal{L}}_V^{\\mathrm{train}}(\\hat p_V) $$\n\n**步骤 D：计算折泛化误差**\n当前折 $c^\\star$ 的误差是两个差距的对称化平均值：\n$$ \\mathcal{E}(c^\\star) = \\frac{1}{2} \\left[ \\Delta_{T \\rightarrow V}(c^\\star) + \\Delta_{V \\rightarrow T}(c^\\star) \\right] $$\n存储该值。\n\n**步骤 E：计算最终泛化误差**\n在遍历所有 $C$ 个折之后，最终泛化误差 $\\mathcal{E}$ 是各折误差的平均值：\n$$ \\mathcal{E} = \\frac{1}{C} \\sum_{c^\\star=1}^C \\mathcal{E}(c^\\star) $$\n\n对三个提供的测试用例中的每一个都实施此程序，以计算最终的标量值 $\\mathcal{E}$。然后按规定格式化结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the computation for all test cases.\n    \"\"\"\n    test_cases = [\n        # Test Case 1: well-conditioned, realistic scales\n        {\n            \"d\": 2, \"C\": 3, \"lambda\": 0.1, \"Gamma\": np.diag([1, 1]),\n            \"compositions\": [\n                {\n                    \"J_T\": np.array([[-0.08, -0.02], [0.15, 0.05]]), \"b_T\": np.array([0.05, -0.08]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[30.0, 10.0], [1.8, 0.6]]), \"b_V\": np.array([-20.0, -1.0]), \"sigma_V\": np.array([10.0, 1.0]),\n                },\n                {\n                    \"J_T\": np.array([[-0.09, -0.01], [0.12, 0.04]]), \"b_T\": np.array([0.03, -0.05]), \"sigma_T\": np.array([0.012, 0.012]),\n                    \"J_V\": np.array([[28.0, 9.0], [1.6, 0.5]]), \"b_V\": np.array([-15.0, -0.8]), \"sigma_V\": np.array([12.0, 1.2]),\n                },\n                {\n                    \"J_T\": np.array([[-0.07, -0.015], [0.10, 0.03]]), \"b_T\": np.array([0.04, -0.07]), \"sigma_T\": np.array([0.011, 0.011]),\n                    \"J_V\": np.array([[26.0, 8.5], [1.4, 0.45]]), \"b_V\": np.array([-18.0, -0.9]), \"sigma_V\": np.array([11.0, 1.1]),\n                }\n            ]\n        },\n        # Test Case 2: near-singular training Jacobians\n        {\n            \"d\": 2, \"C\": 3, \"lambda\": 0.05, \"Gamma\": np.diag([1, 1]),\n            \"compositions\": [\n                {\n                    \"J_T\": np.array([[-0.08, -0.04], [0.16, 0.08]]), \"b_T\": np.array([0.02, -0.04]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[20.0, 5.0], [1.0, 0.25]]), \"b_V\": np.array([-10.0, -0.5]), \"sigma_V\": np.array([10.0, 1.0]),\n                },\n                {\n                    \"J_T\": np.array([[-0.081, -0.0405], [0.162, 0.081]]), \"b_T\": np.array([0.018, -0.036]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[21.0, 5.2], [1.05, 0.26]]), \"b_V\": np.array([-9.0, -0.45]), \"sigma_V\": np.array([10.0, 1.0]),\n                },\n                {\n                    \"J_T\": np.array([[-0.079, -0.0395], [0.158, 0.079]]), \"b_T\": np.array([0.022, -0.044]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[19.0, 4.8], [0.95, 0.24]]), \"b_V\": np.array([-11.0, -0.55]), \"sigma_V\": np.array([10.0, 1.0]),\n                }\n            ]\n        },\n        # Test Case 3: perfectly consistent linear model\n        {\n            \"d\": 2, \"C\": 3, \"lambda\": 1e-6, \"Gamma\": np.diag([1, 1]),\n            \"compositions\": [\n                {\n                    \"J_T\": np.array([[-0.06, 0.01], [0.12, -0.02]]), \"b_T\": np.array([-0.032, 0.064]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[25.0, -2.0], [1.3, -0.12]]), \"b_V\": np.array([12.9, 0.674]), \"sigma_V\": np.array([10.0, 1.0]),\n                },\n                {\n                    \"J_T\": np.array([[-0.065, 0.015], [0.11, -0.018]]), \"b_T\": np.array([-0.0355, 0.0586]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[27.0, -1.8], [1.5, -0.10]]), \"b_V\": np.array([13.86, 0.77]), \"sigma_V\": np.array([10.0, 1.0]),\n                },\n                {\n                    \"J_T\": np.array([[-0.055, 0.012], [0.105, -0.017]]), \"b_T\": np.array([-0.0299, 0.0559]), \"sigma_T\": np.array([0.01, 0.01]),\n                    \"J_V\": np.array([[24.0, -2.2], [1.2, -0.13]]), \"b_V\": np.array([12.44, 0.626]), \"sigma_V\": np.array([10.0, 1.0]),\n                }\n            ]\n        }\n    ]\n    \n    results = [compute_generalization_error(case) for case in test_cases]\n    formatted_results = [f\"{r:.6f}\" for r in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef compute_loss(J, b, sigma, p_hat):\n    \"\"\"\n    Computes the per-composition, per-target average normalized loss L_X(c; p_hat).\n    \"\"\"\n    n_X = len(b)\n    if n_X == 0:\n        return 0.0\n    W = np.diag(1.0 / sigma)\n    weighted_residual = W @ (J @ p_hat - b)\n    norm_sq = np.linalg.norm(weighted_residual)**2\n    return norm_sq / n_X\n\ndef solve_params(compositions, train_indices, target_type, lambda_reg, Gamma):\n    \"\"\"\n    Solves the regularized weighted least-squares problem for p_hat.\n    \"\"\"\n    J_list, b_list, sigma_list = [], [], []\n    for idx in train_indices:\n        comp = compositions[idx]\n        J_list.append(comp[f\"J_{target_type}\"])\n        b_list.append(comp[f\"b_{target_type}\"])\n        sigma_list.append(comp[f\"sigma_{target_type}\"])\n\n    J_stacked = np.vstack(J_list)\n    b_stacked = np.concatenate(b_list)\n    sigma_stacked = np.concatenate(sigma_list)\n    \n    W_stacked = np.diag(1.0 / sigma_stacked)\n    J_tilde = W_stacked @ J_stacked\n    b_tilde = W_stacked @ b_stacked\n\n    M = J_tilde.T @ J_tilde + lambda_reg * (Gamma.T @ Gamma)\n    v = J_tilde.T @ b_tilde\n    \n    # Use pinv for numerical stability, equivalent to solve for well-conditioned M\n    p_hat = np.linalg.pinv(M) @ v\n    return p_hat\n\ndef compute_avg_train_loss(p_hat, compositions, train_indices, target_type):\n    \"\"\"\n    Computes the average training loss over the training compositions.\n    \"\"\"\n    if not train_indices:\n        return 0.0\n    total_loss = 0\n    for idx in train_indices:\n        comp = compositions[idx]\n        J = comp[f\"J_{target_type}\"]\n        b = comp[f\"b_{target_type}\"]\n        sigma = comp[f\"sigma_{target_type}\"]\n        total_loss += compute_loss(J, b, sigma, p_hat)\n    return total_loss / len(train_indices)\n\ndef compute_generalization_error(case):\n    \"\"\"\n    Computes the final generalization error E for a single test case.\n    \"\"\"\n    C = case[\"C\"]\n    compositions = case[\"compositions\"]\n    lambda_reg = case[\"lambda\"]\n    Gamma = case[\"Gamma\"]\n    \n    fold_errors = []\n\n    for c_star_idx in range(C):\n        train_indices = [i for i in range(C) if i != c_star_idx]\n        val_comp = compositions[c_star_idx]\n        \n        # --- Round 1: Train on T, Validate on V ---\n        p_hat_T = solve_params(compositions, train_indices, 'T', lambda_reg, Gamma)\n        \n        train_loss_T = compute_avg_train_loss(p_hat_T, compositions, train_indices, 'T')\n        val_loss_V = compute_loss(val_comp[\"J_V\"], val_comp[\"b_V\"], val_comp[\"sigma_V\"], p_hat_T)\n        \n        delta_T_to_V = val_loss_V - train_loss_T\n        \n        # --- Round 2: Train on V, Validate on T ---\n        p_hat_V = solve_params(compositions, train_indices, 'V', lambda_reg, Gamma)\n        \n        train_loss_V = compute_avg_train_loss(p_hat_V, compositions, train_indices, 'V')\n        val_loss_T = compute_loss(val_comp[\"J_T\"], val_comp[\"b_T\"], val_comp[\"sigma_T\"], p_hat_V)\n        \n        delta_V_to_T = val_loss_T - train_loss_V\n\n        # --- Fold Generalization Error ---\n        E_c_star = 0.5 * (delta_T_to_V + delta_V_to_T)\n        fold_errors.append(E_c_star)\n\n    # --- Final Generalization Error ---\n    if not fold_errors:\n        return 0.0\n    E_final = np.mean(fold_errors)\n    return E_final\n\nsolve()\n```", "id": "3422163"}]}