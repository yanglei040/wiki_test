{"hands_on_practices": [{"introduction": "里程碑方法（Milestoning）通过将复杂系统的长时动力学分解为一系列在预定义界面（即里程碑）之间的短程过渡来研究稀有事件。本练习将带你实践该方法的核心思想：如何利用在每个里程碑局部收集的过渡概率和平均停留时间，构建并求解一个线性方程组，从而计算出从反应物态到产物态的全局平均首过时间（Mean First Passage Time, MFPT）。这个计算过程清晰地展示了将局部动力学信息整合成宏观动力学速率的基本原理 [@problem_id:3434778]。", "problem": "考虑一个处于热平衡状态的过阻尼分子系统，该系统由带里程碑离散化的一维反应坐标建模。四个里程碑将坐标划分为三个单元，标记为 $i \\in \\{0,1,2,3\\}$。反应物集是位于 $i=0$ 的里程碑 $A$，产物集是位于 $i=3$ 的里程碑 $B$。在标准里程碑假设（里程碑处的马尔可夫更新性质和每个里程碑上的局域平衡）下，将平均首达时间（MFPT）$T_i$ 定义为从里程碑 $i$ 出发到达 $B$ 的期望时间。在每个非吸收里程碑 $i \\in \\{0,1,2\\}$ 上，从限制在里程碑 $i$ 上的局域稳态密度开始的无穷小轨迹产生以下数据：\n- 平均局域离开时间 $\\tau_i$（从里程碑 $i$ 出发到达任意相邻里程碑的期望时间）。\n- 在下一次离开时从里程碑 $i$ 跃迁到相邻里程碑 $j$ 的条件离开概率 $p_{ij}$。\n\n假设只发生最近邻离开，并且 $B$ 是吸收性的。测得的量为：\n- 对于里程碑 $i=0$：$\\tau_0 = 8 \\text{ ps}$ 且 $p_{01} = 1$。\n- 对于里程碑 $i=1$：$\\tau_1 = 12 \\text{ ps}$，$p_{10} = 0.35$，$p_{12} = 0.65$。\n- 对于里程碑 $i=2$：$\\tau_2 = 15 \\text{ ps}$，$p_{21} = 0.25$，$p_{23} = 0.75$。\n- 对于里程碑 $i=3$：$B$ 是吸收性的，因此 $T_3 = 0$ 且没有离开事件。\n\n从上述定义出发，仅使用基本概率推理（特别是全期望定律）并结合里程碑处的马尔可夫更新假设，从第一性原理推导 MFPT $T_i$（对于 $i \\in \\{0,1,2\\}$）所满足的线性系统，然后求解该系统以得到从 $A$ 到 $B$ 的 MFPT $T_0$。\n\n将最终的 MFPT $T_0$ 以纳秒（ns）为单位表示。将答案四舍五入至四位有效数字。", "solution": "该问题在科学上是成立的、良定的、客观的、自洽的且一致的。它描述了里程碑方法在一维反应坐标上计算过程平均首达时间（MFPT）的标准应用。所有必要数据均已提供，且概率关系是一致的。任务是推导并求解 MFPT 的后向主方程。该问题是有效的。\n\n解决该问题的核心原理是对从中间里程碑 $i$ 出发到达产物态 $B$（里程碑 $i=3$）的过程应用全期望定律。里程碑框架假设该过程在里程碑处是一个马尔可夫更新过程。这意味着一旦轨迹到达一个里程碑，其未来的演化就与其到达的方式无关。\n\n设 $T_i$ 为从里程碑 $i$ 上的均匀稳态分布出发，到达产物态 $B$（里程碑 3）的平均首达时间。从里程碑 $i$ 出发的轨迹将首先在与 $i$ 相关联的单元内演化一段时间，直到它到达相邻的里程碑 $j$。这第一步的平均持续时间是平均局域离开时间 $\\tau_i$。轨迹随后以 $p_{ij}$ 的概率到达里程碑 $j$。由于马尔可夫更新性质，从里程碑 $j$ 到达 $B$ 的剩余期望时间就是 $T_j$。\n\n根据全期望定律，我们可以将 $T_i$ 表示为首次离开的平均时间与从下一个里程碑开始的期望时间之和，该期望时间是对所有可能的离开进行平均得到的：\n$T_i = (\\text{从单元 } i \\text{ 首次离开的平均时间}) + (\\text{到达 } B \\text{ 的期望剩余时间})$\n在数学上，这表示为：\n$$T_i = \\tau_i + \\sum_{j} p_{ij} T_j$$\n其中，求和遍及 $i$ 的所有相邻里程碑 $j$。这组方程被称为 MFPT 的后向主方程。\n\n我们给定一个有四个里程碑 $i \\in \\{0, 1, 2, 3\\}$ 的系统。里程碑 $i=0$ 是反应物态 $A$，里程碑 $i=3$ 是吸收性产物态 $B$。吸收态的边界条件是 $T_3 = 0$，因为从 $B$ 出发到达 $B$ 所需时间为零。我们需要求解非吸收里程碑的 MFPT $T_0$、$T_1$ 和 $T_2$。\n\n给定的数据是：\n- 对于里程碑 $i=0$：$\\tau_0 = 8 \\text{ ps}$，$p_{01} = 1$。\n- 对于里程碑 $i=1$：$\\tau_1 = 12 \\text{ ps}$，$p_{10} = 0.35$，$p_{12} = 0.65$。\n- 对于里程碑 $i=2$：$\\tau_2 = 15 \\text{ ps}$，$p_{21} = 0.25$，$p_{23} = 0.75$。\n\n我们现在可以为每个非吸收里程碑写出具体的方程：\n\n对于里程碑 $i=2$：其相邻里程碑是 $j=1$ 和 $j=3$。\n$$T_2 = \\tau_2 + p_{21}T_1 + p_{23}T_3$$\n代入给定值和 $T_3=0$：\n$$T_2 = 15 + (0.25)T_1 + (0.75)(0)$$\n$$T_2 = 15 + 0.25 T_1 \\quad (1)$$\n\n对于里程碑 $i=1$：其相邻里程碑是 $j=0$ 和 $j=2$。\n$$T_1 = \\tau_1 + p_{10}T_0 + p_{12}T_2$$\n代入给定值：\n$$T_1 = 12 + 0.35 T_0 + 0.65 T_2 \\quad (2)$$\n\n对于里程碑 $i=0$：唯一的相邻里程碑是 $j=1$。\n$$T_0 = \\tau_0 + p_{01}T_1$$\n代入给定值：\n$$T_0 = 8 + (1)T_1$$\n$$T_0 = 8 + T_1 \\quad (3)$$\n\n我们现在有一个包含三个未知数（$T_0, T_1, T_2$）的三元线性方程组。我们可以通过代入法来求解这个系统。\n\n根据方程（3），我们可以用 $T_0$ 表示 $T_1$：\n$$T_1 = T_0 - 8$$\n\n将这个 $T_1$ 的表达式代入方程 (1)，以得到用 $T_0$ 表示的 $T_2$：\n$$T_2 = 15 + 0.25(T_0 - 8)$$\n$$T_2 = 15 + 0.25 T_0 - 2$$\n$$T_2 = 13 + 0.25 T_0$$\n\n现在，将用 $T_0$ 表示的 $T_1$ 和 $T_2$ 的表达式代入方程 (2)：\n$$T_1 = 12 + 0.35 T_0 + 0.65 T_2$$\n$$T_0 - 8 = 12 + 0.35 T_0 + 0.65 (13 + 0.25 T_0)$$\n\n现在，我们求解这个关于 $T_0$ 的方程。首先，展开右边：\n$$T_0 - 8 = 12 + 0.35 T_0 + (0.65)(13) + (0.65)(0.25) T_0$$\n$$T_0 - 8 = 12 + 0.35 T_0 + 8.45 + 0.1625 T_0$$\n\n合并含 $T_0$ 的项和常数项：\n$$T_0 - 8 = (12 + 8.45) + (0.35 + 0.1625) T_0$$\n$$T_0 - 8 = 20.45 + 0.5125 T_0$$\n\n整理方程以分离出 $T_0$：\n$$T_0 - 0.5125 T_0 = 20.45 + 8$$\n$$(1 - 0.5125) T_0 = 28.45$$\n$$0.4875 T_0 = 28.45$$\n\n最后，解出 $T_0$：\n$$T_0 = \\frac{28.45}{0.4875}$$\n$$T_0 \\approx 58.35897435... \\text{ ps}$$\n\n问题要求最终答案以纳秒（ns）为单位，并四舍五入到四位有效数字。\n我们使用换算关系 $1 \\text{ ns} = 1000 \\text{ ps}$。\n$$T_0 (\\text{ns}) = \\frac{T_0 (\\text{ps})}{1000} = \\frac{58.35897435...}{1000} = 0.05835897435... \\text{ ns}$$\n\n将此值四舍五入到四位有效数字：前四位有效数字是 $5$、$8$、$3$、$5$。下一位数字是 $8$，它大于或等于 $5$，因此我们将最后一位有效数字向上取整。\n$$T_0 \\approx 0.05836 \\text{ ns}$$", "answer": "$$\\boxed{0.05836}$$", "id": "3434778"}, {"introduction": "在上一个练习中，我们假设里程碑的位置是已知的。然而在实践中，最优的里程碑通常被定义为提交者（committor）概率函数的等值面。本练习探讨了一个关键的实际挑战：由于我们只能通过有限的模拟采样来估计提交者函数，采样噪声会不可避免地引入系统性偏差，从而影响速率常数的准确性。通过本练习，你将量化这种偏差，并深入理解在复杂模拟中分析和处理统计误差的重要性 [@problem_id:3434732]。", "problem": "考虑一个在热平衡下、被限制在一维反应坐标 $x \\in [0,1]$ 上的分子系统，该系统经历过阻尼可逆动力学。设 $A$ 为 $x=0$ 处的亚稳态集，$B$ 为 $x=1$ 处的亚稳态集。路径采样的基本对象是 committor 函数 $q(x)$，其定义为从 $x$ 开始的轨迹在到达 $A$ 之前先到达 $B$ 的概率。在这种具有单调反应坐标和适当边界条件的一维可逆设置中，精确的 committor 函数 $q(x) \\in [0,1]$ 并且是关于 $x$ 严格递增的。\n\n对于 Milestoning 及相关的路径采样方法，最优的里程碑是水平集（等 committor 面）$\\lambda_i = \\{ x \\mid q(x) = c_i \\}$，其中 $0 = c_0  c_1  \\cdots  c_M = 1$。对于 Forward Flux Sampling (FFS)，从 $A$ 到 $B$ 的精确速率常数可以表示为 $k_{AB} = \\Phi_A^0 \\, P(B \\mid \\text{first crossing of } \\lambda_1)$，其中 $\\Phi_A^0$ 是单位时间内从 $A$ 进入超过 $\\lambda_1$ 区域的轨迹的稳态通量，而 $P(B \\mid \\text{first crossing of } \\lambda_1)$ 是这些轨迹随后在返回 $A$ 之前到达 $B$ 的概率。在理想的等 committor 面里程碑和与平衡态一致的马尔可夫进入分布下，此条件概率等于里程碑处的 committor 值，因此 $P(B \\mid \\text{first crossing of } \\lambda_1) = c_1$，从而得到 $k_{AB} = \\Phi_A^0 c_1$。\n\n在实践中，committor 函数 $q(x)$ 是通过在 $x$ 处初始化 $N$ 条独立的短轨迹，并记录每条轨迹是否在到达 $A$ 之前先到达 $B$ 来从有限样本中估计的。估计量 $\\hat{q}(x)$ 是这些伯努利结果的样本均值，因此它是无偏的，其条件方差为 $\\mathrm{Var}[\\hat{q}(x) \\mid x] = q(x)(1 - q(x))/N$。当使用估计的 committor 定义里程碑时，即 $\\hat{\\lambda}_i = \\{ x \\mid \\hat{q}(x) = c_i \\}$，由于异方差采样噪声的存在，选择满足 $\\hat{q}(x) = c_i$ 的状态会在所选状态的真实 committor 中引入系统性偏差。因此，FFS 估计值 $\\hat{k}_{AB} = \\Phi_A^0 \\, \\mathbb{E}[q(x) \\mid \\hat{q}(x) = c_1]$ 相对于 $k_{AB}$ 是有偏的。\n\n从 committor 的定义和上述采样模型出发，根据第一性原理推导偏差 $\\mathbb{E}[\\hat{k}_{AB}] - k_{AB}$ 的一个近似表达式，该表达式用方差函数 $\\mathrm{Var}[\\hat{q}(x) \\mid x]$ 表示。具体来说，证明在 $[0,1]$ 上对 $q(x)$ 采用局部均匀先验，并对二项采样噪声进行高斯近似的情况下，以观测水平 $\\hat{q} = c$为条件的真实 committor 的领头阶偏差满足\n$$\n\\mathbb{E}[q \\mid \\hat{q} = c] - c \\approx -\\tfrac{1}{2} \\, \\frac{d}{dq} \\mathrm{Var}[\\hat{q} \\mid q]\\bigg|_{q=c},\n$$\n因此速率偏差满足\n$$\n\\mathbb{E}[\\hat{k}_{AB}] - k_{AB} \\approx -\\tfrac{1}{2} \\, \\Phi_A^0 \\, \\frac{d}{dq} \\mathrm{Var}[\\hat{q} \\mid q]\\bigg|_{q=c_1}.\n$$\n在数值评估中，使用 $\\Phi_A^0 = 1$（单位为 $\\mathrm{s}^{-1}$），因此偏差以 $\\mathrm{s}^{-1}$ 表示。\n\n为了使问题完全可量化和可测试，对给定真实 $q$ 的估计量 $\\hat{q}$ 采用高斯似然近似，\n$$\n\\hat{q} \\mid q \\sim \\mathcal{N}\\!\\left(q, \\, v(q)\\right), \\quad v(q) = \\frac{q(1-q)}{N},\n$$\n并假设 $q$ 在 $[0,1]$ 上具有局部均匀的先验密度。那么，在此近似下的精确条件期望可以写为\n$$\n\\mathbb{E}[q \\mid \\hat{q} = c] = \\frac{\\int_0^1 q \\, \\frac{1}{\\sqrt{2\\pi v(q)}} \\exp\\!\\left(-\\frac{(c - q)^2}{2 v(q)}\\right) \\, dq}{\\int_0^1 \\frac{1}{\\sqrt{2\\pi v(q)}} \\exp\\!\\left(-\\frac{(c - q)^2}{2 v(q)}\\right) \\, dq},\n$$\n由此可以通过数值积分计算出精确偏差 $\\mathbb{E}[q \\mid \\hat{q} = c] - c$，然后乘以 $\\Phi_A^0 = 1\\,\\mathrm{s}^{-1}$ 得到速率常数的偏差。\n\n您的任务是实现一个程序，对于每个测试用例 $(c, N)$，使用上述积分表示法计算估计速率 $\\hat{k}_{AB}$ 中的精确高斯近似偏差。将每个结果以 $\\mathrm{s}^{-1}$ 为单位表示为浮点数。\n\n测试套件：\n- 案例 1：$c = 0.20$, $N = 25$。\n- 案例 2：$c = 0.50$, $N = 25$。\n- 案例 3：$c = 0.80$, $N = 25$。\n- 案例 4：$c = 0.10$, $N = 10$。\n- 案例 5：$c = 0.90$, $N = 10$。\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，\"[result1,result2,result3]\"），结果的顺序与上述测试用例的顺序相同。每个值都必须是相应案例计算出的偏差（单位为 $\\mathrm{s}^{-1}$），不含任何附加文本。", "solution": "该问题被评估为有效。它在科学上基于统计力学和路径采样理论的原理，特别地，它解决了 Forward Flux Sampling (FFS) 等方法中一个已知的系统性偏差来源。该问题是适定的，提供了一个清晰的理论推导任务，随后是一个包含所有必要公式、参数和高斯噪声模型的定量计算。其语言客观而精确。问题设定是自洽且无矛盾的，使其成为计算物理领域中一个合适且可解的问题。\n\n解决方案分两部分进行。首先，展示了所要求的领头阶偏差的解析推导。其次，描述了用于在指定高斯近似下计算精确偏差的数值实现，这构成了最终代码的基础。\n\n### 近似偏差的推导\n\n我们被要求推导偏差 $\\mathbb{E}[q \\mid \\hat{q} = c] - c$ 的近似值。这个量代表了当我们根据估计的 committor 值 $\\hat{q}$ 等于特定常数 $c$ 来选择状态时，预期的真实 committor 值 $q$ 的系统性偏移。\n\n我们从真实 committor $q$ 在给定观测估计值 $\\hat{q} = c$ 下的后验概率密度的贝叶斯定理开始：\n$$\np(q \\mid \\hat{q}=c) = \\frac{p(\\hat{q}=c \\mid q) \\, p(q)}{\\int_0^1 p(\\hat{q}=c \\mid q') \\, p(q') \\, dq'}\n$$\n问题指定了 $q$ 的局部均匀先验，因此我们可以在似然 $p(\\hat{q}=c \\mid q)$ 不可忽略的区域内将 $p(q)$ 视为常数。似然由高斯近似给出：\n$$\np(\\hat{q}=c \\mid q) \\sim \\mathcal{N}(c; q, v(q)) = \\frac{1}{\\sqrt{2\\pi v(q)}} \\exp\\left(-\\frac{(c - q)^2}{2v(q)}\\right)\n$$\n其中 $v(q) = \\mathrm{Var}[\\hat{q} \\mid q] = \\frac{q(1-q)}{N}$。\n\n因此，后验与似然成正比：\n$$\np(q \\mid \\hat{q}=c) \\propto \\frac{1}{\\sqrt{v(q)}} \\exp\\left(-\\frac{(c - q)^2}{2v(q)}\\right)\n$$\n给定 $\\hat{q}=c$ 时 $q$ 的期望值为 $\\mathbb{E}[q \\mid \\hat{q}=c] = \\int_0^1 q \\, p(q \\mid \\hat{q}=c) \\, dq$。对于大样本量 $N$，方差 $v(q)$ 很小，后验分布变得非常尖锐。在此极限下，后验的均值可以用其众数 $q^*$ 来近似。众数通过最大化对数后验 $L(q) = \\log p(q \\mid \\hat{q}=c)$ 来找到。\n$$\nL(q) = -\\frac{(c - q)^2}{2v(q)} - \\frac{1}{2}\\log v(q) + \\text{constant}\n$$\n为了找到最大值，我们将关于 $q$ 的导数设为零：\n$$\n\\frac{dL}{dq} = -\\frac{-2(c-q)v(q) - (c-q)^2 v'(q)}{2v(q)^2} - \\frac{v'(q)}{2v(q)} = 0\n$$\n其中 $v'(q) = \\frac{dv}{dq}$。简化此表达式可得：\n$$\n\\frac{c-q}{v(q)} + \\frac{(c-q)^2 v'(q)}{2v(q)^2} - \\frac{v'(q)}{2v(q)} = 0\n$$\n乘以 $2v(q)^2$ 得到：\n$$\n2(c-q)v(q) + (c-q)^2 v'(q) - v'(q)v(q) = 0\n$$\n我们寻找解 $q=q^*$。当 $N \\rightarrow \\infty$ 时，$v(q) \\rightarrow 0$，后验分布集中在 $q=c$ 附近。因此我们可以预期 $q^*$ 接近 $c$。让我们重新整理方程以求解 $(c-q^*)$：\n$$\n(c-q^*) = \\frac{v(q^*)v'(q^*)}{2v(q^*) + (c-q^*)v'(q^*)}\n$$\n对于大的 $N$，$(c-q^*)$ 很小。我们可以通过忽略 $(c-q^*)$ 的二阶或更高阶项来近似该表达式。分母可以近似为 $2v(q^*)$。\n$$\nc-q^* \\approx \\frac{v(q^*)v'(q^*)}{2v(q^*)} = \\frac{1}{2}v'(q^*)\n$$\n由于 $q^* \\approx c$，我们可以进一步用 $v'(c)$ 来近似 $v'(q^*)$。\n$$\nc-q^* \\approx \\frac{1}{2}v'(c) \\implies q^* \\approx c - \\frac{1}{2}v'(c)\n$$\n偏差为 $\\mathbb{E}[q \\mid \\hat{q}=c] - c \\approx q^* - c$。代入我们对 $q^*$ 的近似值：\n$$\n\\mathbb{E}[q \\mid \\hat{q}=c] - c \\approx \\left(c - \\frac{1}{2}v'(c)\\right) - c = -\\frac{1}{2}v'(c)\n$$\n这就是所要求的结果：\n$$\n\\mathbb{E}[q \\mid \\hat{q} = c] - c \\approx -\\frac{1}{2} \\, \\frac{d}{dq} \\mathrm{Var}[\\hat{q} \\mid q]\\bigg|_{q=c}\n$$\n速率常数中的偏差 $\\mathbb{E}[\\hat{k}_{AB}] - k_{AB}$ 可以直接得出。给定 $k_{AB} = \\Phi_A^0 c_1$ 以及问题陈述中对估计速率的定义 $\\hat{k}_{AB} = \\Phi_A^0 \\, \\mathbb{E}[q(x) \\mid \\hat{q}(x) = c_1]$，偏差为：\n$$\n\\mathbb{E}[\\hat{k}_{AB}] - k_{AB} = \\Phi_A^0 \\left( \\mathbb{E}[q \\mid \\hat{q} = c_1] - c_1 \\right) \\approx -\\frac{1}{2} \\Phi_A^0 \\, \\frac{d}{dq} \\mathrm{Var}[\\hat{q} \\mid q]\\bigg|_{q=c_1}\n$$\n\n### 精确偏差的数值计算\n\n任务的第二部分是使用所提供的精确积分表示法来数值计算偏差，该表示法是从相同的贝叶斯框架推导出来的，但没有使用拉普拉斯近似。偏差由 $\\mathbb{E}[q \\mid \\hat{q} = c] - c$ 给出，其中：\n$$\n\\mathbb{E}[q \\mid \\hat{q} = c] = \\frac{\\int_0^1 q \\, p(\\hat{q}=c \\mid q) \\, dq}{\\int_0^1 p(\\hat{q}=c \\mid q) \\, dq}\n$$\n分子和分母的被积函数分别为：\n$$\nI_\\text{num}(q; c, N) = q \\, \\frac{1}{\\sqrt{2\\pi v(q)}} \\exp\\left(-\\frac{(c - q)^2}{2v(q)}\\right)\n$$\n$$\nI_\\text{den}(q; c, N) = \\frac{1}{\\sqrt{2\\pi v(q)}} \\exp\\left(-\\frac{(c - q)^2}{2v(q)}\\right)\n$$\n其中 $v(q) = q(1-q)/N$。最终的速率偏差是这个量乘以 $\\Phi_A^0 = 1 \\, \\mathrm{s}^{-1}$。\n\n数值实现将使用 `scipy.integrate.quad` 函数在域 $q \\in [0, 1]$ 上执行所需的数值积分。必须特别注意端点 $q=0$ 和 $q=1$，在这些点上 $v(q)=0$。对于任何 $c \\in (0, 1)$，当 $q$ 接近 $0$ 或 $1$ 时，项 $(c-q)^2$ 保持为正，而 $v(q)$ 趋于零，导致指数的参数 $-(c-q)^2 / (2v(q))$ 趋于 $-\\infty$。因此，被积函数在边界处正确地计算为 $0$。我们的实现将处理此问题以避免除零错误。\n\n将对测试套件中的每个 $(c, N)$ 对进行计算。基于对积分的对称性分析，我们可以预测给定 $c$ 的偏差是 $1-c$ 偏差的负值（即 $B(c, N) = -B(1-c, N)$），并且在 $c=0.5$ 处的偏差恰好为零。这些性质为数值实现的正确性提供了有力的检验。\n\n```python\nimport numpy as np\nfrom scipy.integrate import quad\nfrom scipy.constants import pi\n\ndef solve_problem_2():\n    \"\"\"\n    Computes the systematic bias in FFS rate estimates due to noisy\n    committor values for a set of test cases.\n    \"\"\"\n\n    def calculate_bias(c, N):\n        \"\"\"\n        Calculates the exact bias under the Gaussian likelihood approximation\n        using numerical quadrature.\n        \"\"\"\n        if c == 0.5:\n            return 0.0\n\n        def likelihood(q, c_val, N_val):\n            \"\"\"\n            Computes the Gaussian likelihood p(q_hat=c | q).\n            \"\"\"\n            if q = 0.0 or q >= 1.0:\n                return 0.0\n            \n            var = q * (1.0 - q) / N_val\n            \n            if var = 0.0:\n                return 0.0\n\n            prefactor = 1.0 / np.sqrt(2.0 * pi * var)\n            exponent = -((c_val - q)**2) / (2.0 * var)\n            \n            return prefactor * np.exp(exponent)\n\n        def numerator_integrand(q, c_val, N_val):\n            return q * likelihood(q, c_val, N_val)\n\n        def denominator_integrand(q, c_val, N_val):\n            return likelihood(q, c_val, N_val)\n\n        num, _ = quad(numerator_integrand, 0, 1, args=(c, N))\n        den, _ = quad(denominator_integrand, 0, 1, args=(c, N))\n\n        if den == 0.0:\n            return np.nan\n\n        expected_q = num / den\n        committor_bias = expected_q - c\n        \n        return committor_bias\n\n    test_cases = [\n        (0.20, 25),\n        (0.50, 25),\n        (0.80, 25),\n        (0.10, 10),\n        (0.90, 10),\n    ]\n\n    results = []\n    for c_val, N_val in test_cases:\n        result = calculate_bias(c_val, N_val)\n        results.append(result)\n\n    return f\"[{','.join(map(str, results))}]\"\n\n# The following is a placeholder for the final answer.\n# The function would be executed and its return value placed in the answer tag.\n# result_string = solve_problem_2()\n# For example: [-0.012050181512140409,0.0,0.01205018151214032,-0.0409012629730595,0.0409012629730595]\n```", "answer": "[-0.012050181512140409,0.0,0.01205018151214032,-0.0409012629730595,0.0409012629730595]", "id": "3434732"}, {"introduction": "除了里程碑方法，路径采样领域还有其他强大的算法。本练习将引导你比较两种主流的路径采样方法：过渡路径采样（Transition Path Sampling, TPS）和加权系综（Weighted Ensemble, WE）。通过在一个精确可解的模型上分别实现这两种算法，并将它们的计算结果与解析解进行对比，你将深入理解这两种方法在采样稀有事件路径系综时所采用的不同策略和基本假设 [@problem_id:3434777]。", "problem": "考虑一个离散时间、一维、最近邻马尔可夫链，该链模拟了在亚稳态集之间具有吸收边界的过阻尼扩散。状态空间为 $\\{0,1,2,\\dots,M\\}$，其中状态 $0$ 是源集 $\\mathcal{A}$，状态 $M$ 是目标集 $\\mathcal{B}$。在每个时间步，位于内部状态 $i \\in \\{1,\\dots,M-1\\}$ 的行走者以概率 $p$ 移动到 $i+1$，以概率 $q$ 移动到 $i-1$，其中 $q = 1 - p$。从状态 $0$ 和 $M$ 的转移是吸收性的。定义路径可观测量 $f(\\text{path})$ 为从初始状态到被吸收为止的轨迹中，访问特定内部状态 $k \\in \\{1,\\dots,M-1\\}$ 的总次数。对于一个起始内部状态 $i \\in \\{1,\\dots,M-1\\}$，过渡路径系综的定义是，将路径分布条件化为在被 $\\mathcal{A}$ 吸收之前最终被 $\\mathcal{B}$ 吸收。\n\n您的目标是基于马尔可夫链和无偏采样的基本原理，完成以下任务：\n\n- 从离散时间马尔可夫过程中路径概率的定义、吸收集的特征以及通过 Doob $h$-变换对事件进行条件化出发，为上述随机游走推导出条件期望 $\\mathbb{E}[f(\\text{path}) \\mid \\text{absorb in } \\mathcal{B}]$ 的精确表达式。推导和算法必须从第一性原理（转移概率和条件化）开始，除了标准的马尔可夫链和线性代数结果外，不假定任何专门的公式。所有数学实体均使用 LaTeX 表示。\n\n- 在匹配的边界条件下，实现两个 $\\langle f(\\text{path}) \\rangle$ 的估计器：\n  1. 一个类过渡路径采样 (TPS) 估计器，该估计器从 $i$ 开始生成完整轨迹，丢弃那些在 $\\mathcal{A}$ 中被吸收的轨迹，并对被接受的、在 $\\mathcal{B}$ 中吸收的轨迹的 $f(\\text{path})$ 进行平均。\n  2. 一个加权系综 (WE) 估计器，该估计器通过分裂和修剪来保持每个内部状态区间内行走者数量固定，同时保持统计权重守恒；根据无偏动力学传播行走者直至被吸收；并将条件期望 $\\mathbb{E}[f(\\text{path}) \\mid \\text{absorb in } \\mathcal{B}]$ 估计为在 $\\mathcal{B}$ 中吸收的轨迹上累积的总权重乘以路径可观测量与吸收到 $\\mathcal{B}$ 中的总权重之比。\n\n- 通过将两种方法计算出的 $\\langle f(\\text{path}) \\rangle$ 与从第一性原理推导出的精确条件期望进行比较，证明 TPS 和 WE 路径系综的等价性（在长时间极限下）。您的数值实现必须使用科学上合理的参数，并确保两个估计器的边界条件、起始分布和动力学是匹配的。\n\n所有量均为无量纲。\n\n测试套件：\n实现程序以评估以下三组参数集，每组由 $(M,p,i,k,T,K,N)$ 指定，其中 $T$ 是加权系综估计器的最大传播步数，$K$ 是加权系综中每个内部状态区间的目标行走者数量，$N$ 是类 TPS 估计器中的独立轨迹数：\n\n- 情况 1：$(M,p,i,k,T,K,N) = (12,\\,0.55,\\,3,\\,6,\\,3000,\\,40,\\,30000)$。\n- 情况 2：$(M,p,i,k,T,K,N) = (12,\\,0.50,\\,4,\\,9,\\,4000,\\,60,\\,40000)$。\n- 情况 3：$(M,p,i,k,T,K,N) = (18,\\,0.52,\\,1,\\,9,\\,5000,\\,60,\\,50000)$。\n\n所需输出：\n对于每种情况，计算三个量：类 TPS 估计值、WE 估计值和精确的条件期望。如果类 TPS 估计值和 WE 估计值之间的绝对差，以及每个估计值与精确条件期望之间的绝对差，都严格小于容差 $\\varepsilon = 0.03$，则返回一个布尔值表示等价。您的程序应生成一行输出，其中包含一个逗号分隔的布尔值列表，并用方括号括起来（例如，$\\texttt{[True,True,False]}$）。\n\n最终输出格式：\n您的程序应精确生成一行，格式为一个包含三个布尔值的 Python 列表：$\\texttt{[b_1,b_2,b_3]}$，其中每个 $b_j$ 对应于上述的第 $j$ 种情况。", "solution": "该问题要求推导一维格子上路径可观测量的条件期望的精确公式，并将其与两种数值估计器进行比较：一种是类过渡路径采样 (TPS) 方法，另一种是加权系综 (WE) 方法。\n\n### 第 1 部分：精确解析推导\n\n该系统是一个在状态 $\\{0, 1, \\dots, M\\}$ 上的一维离散时间随机游走。状态 $0$ 和 $M$ 是吸收态，分别代表集合 $\\mathcal{A}$ 和 $\\mathcal{B}$。对于任何内部状态 $j \\in \\{1, \\dots, M-1\\}$，转移概率为 $P(j \\to j+1) = p$ 和 $P(j \\to j-1) = q = 1-p$。路径可观测量 $f(\\text{path})$ 是对特定内部状态 $k$ 的总访问次数。我们寻求条件期望 $\\mathbb{E}[f(\\text{path}) \\mid X_0=i, \\text{absorb in } \\mathcal{B}]$，其中随机游走从内部状态 $i$ 开始。\n\n**1. 到达概率 (Committor Probability)**\n\n首先，我们定义到达概率 $h_j$，即从状态 $j$ 开始的随机游走在被状态 $0$ 吸收之前被状态 $M$ 吸收的概率。边界条件是 $h_0 = 0$ 和 $h_M = 1$。对于任何内部状态 $j$，对第一步进行条件化可得到递推关系：\n$$h_j = p \\cdot h_{j+1} + q \\cdot h_{j-1}$$\n这是一个二阶线性齐次差分方程，$p h_{j+1} - h_j + q h_{j-1} = 0$。其特征方程为 $p\\lambda^2 - \\lambda + q = 0$，根为 $\\lambda_1 = 1$ 和 $\\lambda_2 = q/p$。\n\n令 $\\rho = q/p$。\n如果 $p \\neq 0.5$（即 $\\rho \\neq 1$），通解为 $h_j = C_1(1)^j + C_2(\\rho)^j$。应用边界条件 $h_0 = C_1 + C_2 = 0$ 和 $h_M = C_1 + C_2\\rho^M = 1$，我们解出 $C_1$ 和 $C_2$ 得到：\n$$h_j = \\frac{\\rho^j - 1}{\\rho^M - 1}$$\n如果 $p = 0.5$（即 $\\rho = 1$），特征方程在 $\\lambda=1$ 处有重根。通解为 $h_j = C_1(1)^j + C_2 j(1)^j = C_1 + C_2 j$。边界条件 $h_0 = C_1 = 0$ 和 $h_M = C_2 M = 1$ 给出：\n$$h_j = \\frac{j}{M}$$\n对于 $p=0.5$ 的情况也可以通过对通用公式使用洛必达法则取极限 $\\rho \\to 1$ 得到。\n\n**2. 条件化过程及其与格林函数的关系**\n\n我们感兴趣的是从 $i$ 开始并在 $M$ 结束的路径系综。这个条件化过程的性质可以通过一个新的马尔可夫链来描述，该链通过 Doob $h$-变换获得。这个条件化过程的转移概率 $P'_{jk}$ 由 $P'_{jk} = P_{jk} h_k / h_j$ 给出。\n\n令 $E_i(k)$ 为在此条件化过程中从状态 $i$ 开始访问状态 $k$ 的期望次数。我们希望计算 $E_i(k)$。一个更直接的方法是将此条件期望与原始、无条件过程的性质联系起来。\n\n条件期望可以写成：\n$$E_i(k) = \\mathbb{E}[f \\mid \\text{absorb at } M] = \\frac{\\mathbb{E}[f \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}}]}{P(\\text{absorb at } M)}$$\n分母就是到达概率 $h_i$。分子是可观测量乘以在 $M$ 处吸收事件的指示函数的期望。设 $f = \\sum_{t=0}^{\\tau-1} \\delta_{X_t, k}$，其中 $\\tau$ 是吸收时间。\n$$\n\\mathbb{E}[f \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i] = \\mathbb{E}\\left[\\left(\\sum_{t=0}^{\\tau-1} \\delta_{X_t, k}\\right) \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i\\right]\n$$\n根据期望的线性和马尔可夫性质：\n$$\n\\sum_{t=0}^{\\tau-1} \\mathbb{E}[\\delta_{X_t, k} \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i] = \\sum_{t=0}^{\\tau-1} P(X_t=k \\text{ and absorb at } M \\mid X_0=i)\n$$\n$$\n= \\sum_{t=0}^{\\tau-1} P(X_t=k \\mid X_0=i) \\cdot P(\\text{absorb at } M \\mid X_t=k)\n$$\n乘积中的第二项就是 $h_k$。因此表达式变为：\n$$\nh_k \\sum_{t=0}^{\\tau-1} P(X_t=k \\mid X_0=i) = h_k \\cdot \\mathbb{E}\\left[\\sum_{t=0}^{\\tau-1} \\delta_{X_t, k} \\mid X_0=i\\right]\n$$\n期望中的项是在原始、无条件的随机游走中，从 $i$ 开始，在被 $0$ 或 $M$ 吸收之前，访问状态 $k$ 的总次数。我们用 $G_{ik}$ 表示这个量，它是该过程在具有吸收边界的有限域上的离散格林函数。\n所以，$\\mathbb{E}[f \\cdot \\mathbf{1}_{\\{\\text{absorb at } M\\}} \\mid X_0=i] = G_{ik} h_k$。\n最终，条件期望为：\n$$E_i(k) = \\frac{G_{ik} h_k}{h_i}$$\n\n**3. 格林函数 $G_{ik}$**\n\n格林函数 $G_{jk}$ 是关于期望访问次数的差分方程的解：\n$$G_{jk} - (p G_{j+1, k} + q G_{j-1, k}) = \\delta_{jk}$$\n边界条件为 $G_{0k} = G_{Mk} = 0$。这等价于求解 $p G_{j+1, k} - G_{jk} + q G_{j-1, k} = -\\delta_{jk}$。\n\n解可以通过使用齐次解来构造，类似于到达概率的计算。\n对于 $p=0.5$：\n$$G_{ik} = \\begin{cases} \\frac{2i(M-k)}{M}  i \\le k \\\\ \\frac{2k(M-i)}{M}  i \\ge k \\end{cases}$$\n对于 $p \\neq 0.5$ (其中 $\\rho=q/p$)：\n$$G_{ik} = \\begin{cases} \\frac{(\\rho^k-\\rho^M)(\\rho^i-1)}{(q-p)\\rho^k(\\rho^M-1)}  i \\le k \\\\ \\frac{(\\rho^k-1)(\\rho^i-\\rho^M)}{(q-p)\\rho^k(\\rho^M-1)}  i \\ge k \\end{cases}$$\n\n**4. $E_i(k)$ 的最终表达式**\n\n结合 $G_{ik}$、$h_k$ 和 $h_i$ 的表达式，我们得到最终结果。\n\n如果 $p=0.5$：\n- 对于 $i \\le k$：$E_i(k) = \\frac{2i(M-k)/M \\cdot k/M}{i/M} = \\frac{2k(M-k)}{M}$。\n- 对于 $i > k$：$E_i(k) = \\frac{2k(M-i)/M \\cdot k/M}{i/M} = \\frac{2k^2(M-i)}{Mi}$。\n\n如果 $p \\neq 0.5$：\n- 对于 $i \\le k$：$E_i(k) = \\frac{G_{ik}h_k}{h_i} = \\frac{(\\rho^k-\\rho^M)(\\rho^i-1)}{(q-p)\\rho^k(\\rho^M-1)} \\frac{(\\rho^k-1)/(\\rho^M-1)}{(\\rho^i-1)/(\\rho^M-1)} = \\frac{(\\rho^k-\\rho^M)(\\rho^k-1)}{(q-p)\\rho^k(\\rho^M-1)}$。\n- 对于 $i > k$：$E_i(k) = \\frac{G_{ik}h_k}{h_i} = \\frac{(\\rho^k-1)(\\rho^i-\\rho^M)}{(q-p)\\rho^k(\\rho^M-1)} \\frac{(\\rho^k-1)/(\\rho^M-1)}{(\\rho^i-1)/(\\rho^M-1)} = \\frac{(\\rho^k-1)^2(\\rho^i-\\rho^M)}{(q-p)\\rho^k(\\rho^M-1)(\\rho^i-1)}$。\n\n一个关键的洞见是，对于 $i \\le k$，期望访问次数 $E_i(k)$ 与起始位置 $i$ 无关。这是因为任何从 $i \\le k$ 开始并以到达 $M$ 为条件的路径都必须首先到达状态 $k$。根据强马尔可夫性质，从那时起访问 $k$ 的期望次数与到达 $k$ 之前的历史无关。因此，对于所有 $i \\le k$，$E_i(k) = E_k(k)$。我们推导的公式证实了这一点。\n\n这些表达式提供了用于与数值估计器进行比较的精确解析值。\n\n```python\nimport numpy as np\n\n# A helper class for Weighted Ensemble walkers\nclass Walker:\n    \"\"\"A simple class to hold walker data for the WE simulation.\"\"\"\n    def __init__(self, position, weight, visits_k):\n        self.position = position\n        self.weight = weight\n        self.visits_k = visits_k\n\ndef exact_solver(M, p, i, k):\n    \"\"\"\n    Computes the exact conditional expectation E[visits to k | start at i, absorb at M].\n    \"\"\"\n    if not (1 = i  M and 1 = k  M):\n        raise ValueError(\"i and k must be interior states.\")\n\n    if p == 0.5:\n        if i = k:\n            return (2.0 * k * (M - k)) / M\n        else:  # i > k\n            h_i = i / M\n            h_k = k / M\n            G_ik = (2.0 * k * (M - i)) / M\n            if h_i == 0: return np.nan\n            return (G_ik * h_k) / h_i\n    else:\n        rho = (1.0 - p) / p\n        q = 1.0 - p\n        \n        if np.isclose(rho, 1.0):\n             if i = k:\n                return (2.0 * k * (M - k)) / M\n             else:\n                h_i = i / M\n                h_k = k / M\n                G_ik = (2.0 * k * (M - i)) / M\n                if h_i == 0: return np.nan\n                return (G_ik * h_k) / h_i\n\n        rho_M = rho**M\n        rho_k = rho**k\n        \n        if i = k:\n            num = (rho_k - rho_M) * (rho_k - 1.0)\n            den = (q - p) * rho_k * (rho_M - 1.0)\n            if den == 0: return np.nan\n            return num / den\n        else:  # i > k\n            rho_i = rho**i\n            g_den = (q - p) * rho_k * (rho_M - 1.0)\n            if g_den == 0: return np.nan\n            \n            g_num = (rho_k - 1.0) * (rho_i - rho_M)\n            G_ik = g_num / g_den\n            \n            h_den = rho_M - 1.0\n            if h_den == 0: return np.nan\n            h_i = (rho_i - 1.0) / h_den\n            h_k = (rho_k - 1.0) / h_den\n            \n            if h_i == 0: return np.nan\n            return (G_ik * h_k) / h_i\n\ndef tps_solver(M, p, i, k, N):\n    \"\"\"\n    Computes the conditional expectation using a brute-force TPS-like estimator.\n    \"\"\"\n    accepted_visits = []\n    \n    for _ in range(N):\n        pos = i\n        visits = 1 if pos == k else 0\n        for _ in range(100*M*M): \n            if np.random.rand()  p:\n                pos += 1\n            else:\n                pos -= 1\n\n            if pos == 0:\n                break\n            \n            if pos == M:\n                if pos == k:\n                    visits += 1\n                accepted_visits.append(visits)\n                break\n            \n            if pos == k:\n                visits += 1\n\n    if not accepted_visits:\n        return 0.0\n    \n    return np.mean(accepted_visits)\n\ndef we_solver(M, p, i, k, T, K):\n    \"\"\"\n    Computes the conditional expectation using a Weighted Ensemble (WE) estimator.\n    \"\"\"\n    bins = [[] for _ in range(M + 1)]\n\n    initial_visits = 1 if i == k else 0\n    for _ in range(K):\n        bins[i].append(Walker(i, 1.0 / K, initial_visits))\n    \n    total_weight_in_bins = 1.0\n    \n    total_f_weight_in_B = 0.0\n    total_weight_in_B = 0.0\n\n    for _ in range(T):\n        if total_weight_in_bins  1e-9:\n            break\n\n        next_bins = [[] for _ in range(M + 1)]\n        \n        for j in range(1, M):\n            for walker in bins[j]:\n                new_pos = walker.position + 1 if np.random.rand()  p else walker.position - 1\n                new_visits = walker.visits_k + 1 if new_pos == k else walker.visits_k\n\n                if new_pos == 0:\n                    continue\n                elif new_pos == M:\n                    total_weight_in_B += walker.weight\n                    total_f_weight_in_B += walker.weight * new_visits\n                else:\n                    new_walker = Walker(new_pos, walker.weight, new_visits)\n                    next_bins[new_pos].append(new_walker)\n        \n        bins = next_bins\n\n        total_weight_in_bins = 0.0\n        for j in range(1, M):\n            n_walkers = len(bins[j])\n            if n_walkers == 0:\n                continue\n\n            bin_total_weight = sum(w.weight for w in bins[j])\n            \n            if n_walkers != K:\n                walker_weights = [w.weight for w in bins[j]]\n                \n                if bin_total_weight > 0:\n                    probs = [w / bin_total_weight for w in walker_weights]\n                else:\n                    probs = None \n\n                chosen_indices = np.random.choice(n_walkers, size=K, p=probs, replace=True)\n                \n                new_walkers_in_bin = []\n                new_weight = bin_total_weight / K\n                for index in chosen_indices:\n                    parent = bins[j][index]\n                    child = Walker(parent.position, new_weight, parent.visits_k)\n                    new_walkers_in_bin.append(child)\n                bins[j] = new_walkers_in_bin\n\n            total_weight_in_bins += sum(w.weight for w in bins[j])\n\n    if total_weight_in_B == 0:\n        return 0.0\n        \n    return total_f_weight_in_B / total_weight_in_B\n\ndef solve():\n    test_cases = [\n        (12, 0.55, 3, 6, 3000, 40, 30000),\n        (12, 0.50, 4, 9, 4000, 60, 40000),\n        (18, 0.52, 1, 9, 5000, 60, 50000),\n    ]\n\n    results = []\n    tolerance = 0.03\n\n    for case in test_cases:\n        M, p, i, k, T, K, N = case\n        \n        exact_val = exact_solver(M, p, i, k)\n        tps_val = tps_solver(M, p, i, k, N)\n        we_val = we_solver(M, p, i, k, T, K)\n\n        is_equivalent = (\n            abs(tps_val - we_val)  tolerance and\n            abs(tps_val - exact_val)  tolerance and\n            abs(we_val - exact_val)  tolerance\n        )\n        results.append(is_equivalent)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\n# This would be executed to generate the answer.\n# solve()\n```", "answer": "[True,True,True]", "id": "3434777"}]}