{"hands_on_practices": [{"introduction": "要真正掌握基于模拟的推断，最有效的方法莫过于亲手构建一个推断流程。这个实践练习将指导您从零开始，为一个简化的宇宙学模型（弱引力透镜的峰值计数）实现一个近似贝叶斯计算（ABC）的拒绝采样算法。通过完成这个练习 [@problem_id:3489626]，您不仅将实现一个完整的前向生成模型和两种不同的距离度量，还将学习如何通过计算后验覆盖率来评估和诊断您推断结果的统计有效性，这是验证任何贝叶斯方法校准性的关键步骤。", "problem": "实现一个完整、可运行的程序，该程序为一个简化的弱引力透镜峰计数模型执行近似贝叶斯计算 (ABC)，并量化名义 $0.68$ 可信区间的后验覆盖率，将其作为距离度量、模拟预算 $N_{\\mathrm{sim}}$ 和容差 $\\epsilon$ 的函数。该程序必须为一组指定的测试用例估计覆盖率，这些测试用例会改变这些输入，并以文末描述的精确格式单行输出覆盖率结果。\n\n您必须遵守以下基于科学的设定。\n\n- 生成模型（弱引力透镜峰计数直方图）：\n  - 令宇宙学参数向量为 $\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\sigma_8)$。\n  - 先验是均匀分布：$\\Omega_{\\mathrm{m}} \\sim \\mathcal{U}(0.2, 0.4)$ 和 $\\sigma_8 \\sim \\mathcal{U}(0.6, 1.0)$，且两者独立。\n  - 定义 $K = 8$ 个峰高箱，单位箱宽 $\\Delta x = 1$ 且箱中心为抽象单位。设在参数 $\\boldsymbol{\\theta}$下，每个箱的期望计数为\n    $$\\lambda_k(\\boldsymbol{\\theta}) = s \\, A_k \\left(\\frac{\\sigma_8}{\\sigma_{8,\\mathrm{ref}}}\\right)^{\\alpha_k} \\left(\\frac{\\Omega_{\\mathrm{m}}}{\\Omega_{\\mathrm{m,ref}}}\\right)^{\\beta_k}, \\quad k = 1,\\dots, K,$$\n    其中 $s = 1$，$\\sigma_{8,\\mathrm{ref}} = 0.8$，$\\Omega_{\\mathrm{m,ref}} = 0.3$，以及\n    $$A_k = 200 \\exp\\!\\big(-0.4\\,(k-1)\\big), \\quad \\alpha_k = 1.1 + 0.1\\,(k-1), \\quad \\beta_k = 0.6 + 0.05\\,(k-1).$$\n  - 观测到的峰计数是作为独立的泊松变量抽取的：\n    $$N_k \\sim \\mathrm{Poisson}\\big(\\lambda_k(\\boldsymbol{\\theta})\\big), \\quad k = 1,\\dots,K.$$\n  - 摘要统计量是归一化直方图（经验概率）$\\mathbf{p} \\in \\mathbb{R}^K$，其分量为\n    $$p_k = \\frac{N_k}{\\sum_{j=1}^K N_j + \\delta}, \\quad \\delta = 10^{-12}.$$\n\n- 两个归一化直方图 $\\mathbf{p}$ 和 $\\mathbf{q}$ 之间的距离度量：\n  1. 欧几里得距离：\n     $$d_{\\mathrm{E}}(\\mathbf{p}, \\mathbf{q}) = \\left(\\sum_{k=1}^K (p_k - q_k)^2\\right)^{1/2}.$$\n  2. 一维切片 Wasserstein 距离（等于一维中的第一 Wasserstein 距離）：\n     $$d_{\\mathrm{SW}}(\\mathbf{p}, \\mathbf{q}) = \\sum_{k=1}^K \\left|F_{\\mathbf{p}}(k) - F_{\\mathbf{q}}(k)\\right| \\, \\Delta x,$$\n     其中 $F_{\\mathbf{p}}(k) = \\sum_{j=1}^k p_j$ 和 $F_{\\mathbf{q}}(k) = \\sum_{j=1}^k q_j$，且 $\\Delta x = 1$。\n\n- 通过拒绝采样实现的近似贝叶斯计算 (ABC)：\n  - 给定一个观测到的归一化直方图 $\\mathbf{p}_{\\mathrm{obs}}$、模拟预算 $N_{\\mathrm{sim}}$、容差 $\\epsilon$ 和一个选定的距离 $d \\in \\{d_{\\mathrm{E}}, d_{\\mathrm{SW}}\\}$：\n    1. 对于 $i = 1,\\dots, N_{\\mathrm{sim}}$，从先验中抽样 $\\boldsymbol{\\theta}^{(i)}$，模拟计数 $\\{N_k^{(i)}\\}_{k=1}^K$，形成 $\\mathbf{p}^{(i)}$，计算 $d\\big(\\mathbf{p}^{(i)}, \\mathbf{p}_{\\mathrm{obs}}\\big)$；如果 $d \\le \\epsilon$，则接受 $\\boldsymbol{\\theta}^{(i)}$。\n    2. 接受的样本集合近似于后验分布。\n  - 如果没有参数被接受，则将该次复现定义为非覆盖（见下文覆盖率定义）。\n\n- 覆盖率估计：\n  - 固定基准真相参数 $\\boldsymbol{\\theta}_\\star = (0.3, 0.8)$。\n  - 对每个测试用例，执行 $R$ 次独立复现，如下所示：\n    1. 从 $\\boldsymbol{\\theta}_\\star$ 生成一个新的观测数据集以获得 $\\mathbf{p}_{\\mathrm{obs}}$。\n    2. 使用指定的 $d$、$N_{\\mathrm{sim}}$ 和 $\\epsilon$ 运行 ABC 以获得接受的样本 $\\{\\boldsymbol{\\theta}^{(i)}\\}_{i=1}^{M}$。\n    3. 如果 $M = 0$，将此次复现记录为非覆盖。\n    4. 否则，根据接受的样本计算 $\\Omega_{\\mathrm{m}}$ 和 $\\sigma_8$ 的边际等尾 $0.68$ 可信区间：\n       $$I_{\\Omega} = \\big[\\mathrm{Quantile}_{0.16}\\{\\Omega_{\\mathrm{m}}^{(i)}\\},\\ \\mathrm{Quantile}_{0.84}\\{\\Omega_{\\mathrm{m}}^{(i)}\\}\\big],$$\n       $$I_{\\sigma} = \\big[\\mathrm{Quantile}_{0.16}\\{\\sigma_8^{(i)}\\},\\ \\mathrm{Quantile}_{0.84}\\{\\sigma_8^{(i)}\\}\\big].$$\n    5. 当且仅当 $\\Omega_{\\mathrm{m},\\star} \\in I_{\\Omega}$ 和 $\\sigma_{8,\\star} \\in I_{\\sigma}$ 同时成立时，宣布此次复现为覆盖。\n  - 该测试用例的覆盖率是在 $R$ 次复现中覆盖的复现所占的比例。\n\n- 测试套件：\n  - 每个测试用例使用 $R = 24$ 次复现。\n  - 评估以下六个测试用例，每个用例指定为三元组 $(d, N_{\\mathrm{sim}}, \\epsilon)$：\n    1. $(d_{\\mathrm{E}}, 400, 0.12)$\n    2. $(d_{\\mathrm{E}}, 1200, 0.12)$\n    3. $(d_{\\mathrm{E}}, 1200, 0.08)$\n    4. $(d_{\\mathrm{SW}}, 400, 0.40)$\n    5. $(d_{\\mathrm{SW}}, 1200, 0.40)$\n    6. $(d_{\\mathrm{SW}}, 1200, 0.28)$\n\n- 要求的最终输出格式：\n  - 您的程序应生成单行输出，其中包含六个测试用例的覆盖率结果，顺序与上文相同，形式为方括号内以逗号分隔的列表。\n  - 每个覆盖率值必须是四舍五入到三位小数的小数。\n  - 例如，有效的输出格式如下：\"[0.583,0.625,0.667,0.542,0.708,0.750]\"。\n\n注释：\n- 此问题中不需要物理单位；通过构造，所有量都是无量纲的。\n- 此问题中不使用角度。\n- 百分比必须表示为小数；不要使用百分号。", "solution": "用户提供了一个在数值宇宙学和基于模拟的推断领域中定义明确的计算问题。该问题的所有方面在科学和数学上都是合理、完整且无歧义的。该问题被认为是有效的，并将提供一个解决方案。\n\n核心任务是为一个简化的弱引力透镜峰计数模型实现并评估近似贝叶斯计算 (ABC) 程序。这涉及模拟数据，使用特定的距离度量将其与模拟观测进行比较，并使用结果来近似两个宇宙学参数 $\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\sigma_8)$ 的贝叶斯后验分布。这种近似的质量通过计算其可信区间的频率主义覆盖率来评估。\n\n### 原理1：正向生成模型\n\n任何基于模拟的推断的基础都是一个正向模型，该模型可以在给定一组参数的情况下生成合成数据。在这里，该模型将宇宙学参数 $\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\sigma_8)$ 映射到一个摘要统计量，即峰计数的归一化直方图。\n\n1.  **参数到期望的映射**：参数 $\\boldsymbol{\\theta}$ 首先从一个均匀先验分布中抽取：$\\Omega_{\\mathrm{m}} \\sim \\mathcal{U}(0.2, 0.4)$ 和 $\\sigma_8 \\sim \\mathcal{U}(0.6, 1.0)$。这些参数通过唯象的标度关系确定了在 $K=8$ 个箱中每个箱的期望峰计数 $\\lambda_k$：\n    $$\\lambda_k(\\boldsymbol{\\theta}) = s \\, A_k \\left(\\frac{\\sigma_8}{\\sigma_{8,\\mathrm{ref}}}\\right)^{\\alpha_k} \\left(\\frac{\\Omega_{\\mathrm{m}}}{\\Omega_{\\mathrm{m,ref}}}\\right)^{\\beta_k}$$\n    常数 $s=1$、$\\sigma_{8,\\mathrm{ref}} = 0.8$、$\\Omega_{\\mathrm{m,ref}} = 0.3$ 以及函数 $A_k$、$\\alpha_k$ 和 $\\beta_k$ 在问题中均有定义，并封装了结构形成的抽象物理学。\n\n2.  **随机数据生成**：每个箱中实际观测到的计数值 $N_k$ 是一个随机变量。与计数实验一致，它被建模为从一个具有先前计算出的期望值的泊松分布中的独立抽取：\n    $$N_k \\sim \\mathrm{Poisson}\\big(\\lambda_k(\\boldsymbol{\\theta})\\big), \\quad k = 1,\\dots,K.$$\n\n3.  **摘要统计量**：为了比较数据集，我们使用一个摘要统计量 $\\mathbf{p}$，即计数的归一化直方图。这将数据的维度从计数降低到 $K$ 个箱上的经验概率分布。\n    $$p_k = \\frac{N_k}{\\sum_{j=1}^K N_j + \\delta}$$\n    小常数 $\\delta = 10^{-12}$ 确保分母永远不为零。\n\n算法实现将需要一个函数，该函数接收参数向量 $\\boldsymbol{\\theta}$作为输入，并执行这些步骤以输出一个模拟的摘要统计量 $\\mathbf{p}$。\n\n### 原理2：通过 ABC 拒绝采样的无似然推断\n\n在贝叶斯推断中，我们寻求后验分布 $P(\\boldsymbol{\\theta}|\\mathbf{D}_{\\mathrm{obs}}) \\propto P(\\mathbf{D}_{\\mathrm{obs}}|\\boldsymbol{\\theta}) P(\\boldsymbol{\\theta})$，其中 $P(\\mathbf{D}_{\\mathrm{obs}}|\\boldsymbol{\\theta})$ 是似然，$P(\\boldsymbol{\\theta})$ 是先验。对于宇宙学中的许多复杂模型，似然函数难以处理或计算成本过高，无法评估。ABC 避免了对似然的直接评估。\n\nABC 拒绝算法通过从先验中采样并仅接受那些生成与观测数据“接近”的模拟数据的参数来近似后验。接近程度由摘要统计量上的距离度量 $d$ 来衡量。算法如下：\n\n1.  给定一个观测到的摘要统计量 $\\mathbf{p}_{\\mathrm{obs}}$、一个模拟预算 $N_{\\mathrm{sim}}$ 和一个容差 $\\epsilon$。\n2.  对于 $i = 1, \\dots, N_{\\mathrm{sim}}$：\n    a. 从其先验 $P(\\boldsymbol{\\theta})$ 中抽取一个参数向量 $\\boldsymbol{\\theta}^{(i)}$。\n    b. 使用 $\\boldsymbol{\\theta}^{(i)}$ 和正向模型生成一个合成数据集及其摘要统计量 $\\mathbf{p}^{(i)}$。\n    c. 计算距离 $d\\big(\\mathbf{p}^{(i)}, \\mathbf{p}_{\\mathrm{obs}}\\big)$。\n    d. 如果 $d \\le \\epsilon$，则接受 $\\boldsymbol{\\theta}^{(i)}$。\n3.  接受的参数集合 $\\{\\boldsymbol{\\theta}^{(i)}\\}_{\\mathrm{accepted}}$ 构成了一个从真实后验 $P(\\boldsymbol{\\theta}|\\mathbf{p}_{\\mathrm{obs}})$ 的近似分布中抽取的样本。如果 $\\epsilon \\to 0$ 且 $N_{\\mathrm{sim}} \\to \\infty$，这个近似将变得精确。\n\n实现将包括一个主函数，它负责协调这个循环，调用生成模型和距离函数。\n\n### 原理3：用于比较数据的距离度量\n\n距离度量 $d$ 的选择至关重要，因为它含蓄地定义了推断所敏感的数据方面。问题指定了两种度量，用于比较模拟直方图 $\\mathbf{p}$ 和观测直方图 $\\mathbf{q}$：\n\n1.  **欧几里得距离 ($d_{\\mathrm{E}}$)**：这是一个标准的 L2-范数，衡量直方图之间逐点的平方差。\n    $$d_{\\mathrm{E}}(\\mathbf{p}, \\mathbf{q}) = \\left(\\sum_{k=1}^K (p_k - q_k)^2\\right)^{1/2}$$\n    它独立地处理每个箱的差异。\n\n2.  **切片 Wasserstein 距离 ($d_{\\mathrm{SW}}$)**：在一维中，这等同于第一 Wasserstein 距离，它衡量将一个分布转换为另一个分布所需的“功”。它通过计算直方图累积分布函数 (CDF) 之间积分的绝对差来计算。对于箱宽 $\\Delta x = 1$ 的离散分布：\n    $$d_{\\mathrm{SW}}(\\mathbf{p}, \\mathbf{q}) = \\sum_{k=1}^K \\left|F_{\\mathbf{p}}(k) - F_{\\mathbf{q}}(k)\\right| \\Delta x$$\n    其中 $F_{\\mathbf{p}}(k) = \\sum_{j=1}^k p_j$ 是 CDF。与 $d_{\\mathrm{E}}$ 不同，此度量对箱的相对位置敏感，更自然地惩罚分布质量的移动。\n\n将为每种度量实现独立的函数。$d_{\\mathrm{SW}}$ 的实现将涉及计算直方图概率的累积和。\n\n### 原理4：通过后验覆盖率进行性能评估\n\n任何统计推断方法的关键诊断是其校准。对于贝叶斯方法，我们希望我们的 $X\\%$ 可信区间在多次重复实验中，有 $X\\%$ 的时间包含真实参数值。此属性称为频率主义覆盖率。名义覆盖率与实际覆盖率之间的不匹配表明后验近似中存在偏差或不准确性。\n\n覆盖率估计过程如下：\n\n1.  固定基准真相参数，这里为 $\\boldsymbol{\\theta}_\\star = (0.3, 0.8)$。\n2.  执行 $R=24$ 次独立复现。对于每次复现：\n    a. 从真实参数 $\\boldsymbol{\\theta}_\\star$ 生成一个新的“观测”数据集 $\\mathbf{p}_{\\mathrm{obs}}$。\n    b. 运行 ABC 算法以获得一组 $M$ 个接受的样本，从而近似后验分布。\n    c. 如果 $M=0$，则该次复现被声明为非覆盖。\n    d. 如果 $M>0$，则为 $\\Omega_{\\mathrm{m}}$ 和 $\\sigma_8$ 计算边际 $0.68$ 可信区间。这是通过找到每个参数接受样本的第 16 和第 84 百分位数来完成的。\n    e. 当且仅当*两个*参数的真实值都落在它们各自的可信区间内时，该次复现才算“覆盖”：$\\Omega_{\\mathrm{m},\\star} \\in I_{\\Omega}$ 和 $\\sigma_{8,\\star} \\in I_{\\sigma}$。\n3.  对于给定的测试用例（$d$、$N_{\\mathrm{sim}}$ 和 $\\epsilon$ 的特定组合），估计的覆盖率是覆盖的复现所占的比例。\n\n整个过程将被封装在一个主循环中，该循环遍历六个指定测试用例的 $R=24$ 次复现，计算覆盖率分数，并存储结果。最终输出是这些覆盖率分数的格式化列表。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements and evaluates an Approximate Bayesian Computation (ABC) procedure\n    for a simplified weak lensing peak-count model, and computes posterior coverage.\n    \"\"\"\n    # Fix the random seed for reproducibility\n    np.random.seed(42)\n\n    # -- Model and Global Constants --\n    K = 8  # Number of peak-height bins\n    DELTA_X = 1.0  # Bin width\n    S_SCALE = 1.0  # Overall scaling factor\n    SIGMA8_REF = 0.8\n    OMEGAM_REF = 0.3\n    DELTA_STAB = 1e-12  # Stabilization constant for normalization\n\n    # Ground-truth parameters for generating \"observed\" data\n    THETA_STAR = np.array([0.3, 0.8])  # (Omega_m_star, sigma_8_star)\n\n    # Prior bounds\n    PRIOR_BOUNDS = {\n        'om': (0.2, 0.4),\n        's8': (0.6, 1.0)\n    }\n\n    # Pre-compute model constants for k = 1,...,K\n    k_vals = np.arange(1, K + 1)\n    A_k = 200.0 * np.exp(-0.4 * (k_vals - 1))\n    ALPHA_k = 1.1 + 0.1 * (k_vals - 1)\n    BETA_k = 0.6 + 0.05 * (k_vals - 1)\n\n    # -- Generative Model and Distance Functions --\n\n    def get_lambda(theta):\n        \"\"\"Calculates the expected counts lambda_k for a given theta.\"\"\"\n        omega_m, sigma_8 = theta\n        lambda_k = S_SCALE * A_k * \\\n                   (sigma_8 / SIGMA8_REF)**ALPHA_k * \\\n                   (omega_m / OMEGAM_REF)**BETA_k\n        return lambda_k\n\n    def generate_summary_stat(theta):\n        \"\"\"Generates a normalized peak-count histogram for a given theta.\"\"\"\n        lambda_k = get_lambda(theta)\n        # Draw counts from a Poisson distribution\n        N_k = np.random.poisson(lambda_k)\n        # Compute the normalized summary statistic\n        total_counts = np.sum(N_k)\n        p_k = N_k / (total_counts + DELTA_STAB)\n        return p_k\n\n    def distance_euclidean(p, q):\n        \"\"\"Computes Euclidean distance between two histograms.\"\"\"\n        return np.linalg.norm(p - q)\n\n    def distance_sw(p, q):\n        \"\"\"Computes 1D Sliced Wasserstein distance between two histograms.\"\"\"\n        cdf_p = np.cumsum(p)\n        cdf_q = np.cumsum(q)\n        return np.sum(np.abs(cdf_p - cdf_q)) * DELTA_X\n\n    # -- ABC and Coverage Estimation --\n\n    def run_abc(p_obs, N_sim, epsilon, distance_func):\n        \"\"\"Performs ABC rejection sampling.\"\"\"\n        accepted_thetas = []\n        # Sample N_sim parameters from the prior\n        thetas_om = np.random.uniform(PRIOR_BOUNDS['om'][0], PRIOR_BOUNDS['om'][1], N_sim)\n        thetas_s8 = np.random.uniform(PRIOR_BOUNDS['s8'][0], PRIOR_BOUNDS['s8'][1], N_sim)\n        \n        for i in range(N_sim):\n            theta_i = np.array([thetas_om[i], thetas_s8[i]])\n            # Generate simulated summary statistic\n            p_sim = generate_summary_stat(theta_i)\n            # Calculate distance\n            dist = distance_func(p_sim, p_obs)\n            # Accept if distance is within tolerance\n            if dist = epsilon:\n                accepted_thetas.append(theta_i)\n        \n        return np.array(accepted_thetas)\n\n    def check_coverage(accepted_thetas, theta_star):\n        \"\"\"Checks if the true parameters are within the 0.68 credible intervals.\"\"\"\n        if accepted_thetas.shape[0] == 0:\n            return False  # Non-covering if no samples are accepted\n\n        # Calculate 16th and 84th percentiles for each parameter\n        # These define the 68% equal-tailed credible interval\n        ci_om = np.percentile(accepted_thetas[:, 0], [16, 84])\n        ci_s8 = np.percentile(accepted_thetas[:, 1], [16, 84])\n\n        # Check if true parameters fall within their respective intervals\n        om_covered = (ci_om[0] = theta_star[0] = ci_om[1])\n        s8_covered = (ci_s8[0] = theta_star[1] = ci_s8[1])\n\n        # Replicate is covering only if both parameters are covered\n        return om_covered and s8_covered\n\n    # -- Test Suite Execution --\n    R = 24  # Number of replicates per test case\n    test_cases = [\n        ('euclidean', 400, 0.12),\n        ('euclidean', 1200, 0.12),\n        ('euclidean', 1200, 0.08),\n        ('sw', 400, 0.40),\n        ('sw', 1200, 0.40),\n        ('sw', 1200, 0.28),\n    ]\n\n    distance_map = {\n        'euclidean': distance_euclidean,\n        'sw': distance_sw\n    }\n\n    results = []\n    for d_name, N_sim, epsilon in test_cases:\n        n_covering_replicates = 0\n        dist_func = distance_map[d_name]\n        \n        for _ in range(R):\n            # 1. Generate a new \"observed\" data set from the ground truth\n            p_obs = generate_summary_stat(THETA_STAR)\n            \n            # 2. Run ABC to get posterior samples\n            accepted_samples = run_abc(p_obs, N_sim, epsilon, dist_func)\n            \n            # 3. Check if the replicate covers the true parameters\n            if check_coverage(accepted_samples, THETA_STAR):\n                n_covering_replicates += 1\n        \n        # 4. Calculate coverage fraction for the test case\n        coverage = n_covering_replicates / R\n        results.append(f\"{coverage:.3f}\")\n\n    # Final print statement in the exact required format\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n\n```", "id": "3489626"}, {"introduction": "在实际的宇宙学研究中，计算模拟往往是资源最密集的部分。因此，如何智能地分配有限的模拟预算，以最高效地获取关于宇宙学参数的信息，是一个至关重要的问题。这个练习 [@problem_id:3489624] 引入了贝叶斯实验设计的核心思想，要求您通过最大化参数与数据之间的期望互信息，来推导并计算在不同参数区域之间的最优模拟分配策略。这个过程不仅能加深您对信息论与统计推断之间联系的理解，还为您展示了在基于模拟的推理中实现主动学习（active learning）的理论基础。", "problem": "考虑一个用于数值宇宙学中基于模拟的推断 (Simulation-Based Inference, SBI) 的基于模拟的设计问题。宇宙学参数空间被划分为两个不相交的区域，记为区域 $1$ 和区域 $2$，其先验质量分别为 $w_{1}$ 和 $w_{2}$，满足 $w_{1} + w_{2} = 1$。对于区域 $k \\in \\{1,2\\}$，正向模型对于一个固定的总结统计量容许一个局部线性高斯近似，参数与使用专注于区域 $k$ 的设计抽取的 $n_{k}$ 次独立模拟之间的互信息可以被精确地近似为\n$$\n\\frac{1}{2} w_{k} \\ln\\!\\big(1 + \\lambda_{k} n_{k}\\big),\n$$\n其中 $\\lambda_{k}  0$ 是一个信息率参数，它取决于设计的局部 Fisher 信息以及限制在区域 $k$ 上的先验方差。假设不同区域间的模拟在给定区域索引的条件下是条件独立的，并且对期望信息增益有加性贡献，因此对于一个分配 $\\{n_{1}, n_{2}\\}$，总互信息为\n$$\n\\mathcal{I}(n_{1}, n_{2}) = \\frac{1}{2} \\sum_{k=1}^{2} w_{k} \\ln\\!\\big(1 + \\lambda_{k} n_{k}\\big).\n$$\n给定总模拟预算为 $N$ 个单位，因此 $n_{1} + n_{2} = N$ 且 $n_{k} \\ge 0$。假设 $n_{k}$ 的连续松弛对于分配一个大批量是合适的，并且在最优点两个区域都处于激活状态（因此对于 $k=1,2$，拉格朗日乘子最优性条件等式均成立）。\n\nA部分。从高斯线性实验的互信息定义以及跨独立设计的信息可加性出发，推导在约束 $n_{1} + n_{2} = N$ 下最大化 $\\mathcal{I}(n_{1}, n_{2})$ 的最优分配 $\\{n_{1}^{\\star}, n_{2}^{\\star}\\}$。用 $w_{1}$、$w_{2}$、$\\lambda_{1}$、$\\lambda_{2}$ 和 $N$ 以闭式形式表示你的解。\n\nB部分。将其特化到数值上指定且科学上合理的案例：\n$$\nw_{1} = 0.6,\\quad w_{2} = 0.4,\\quad \\lambda_{1} = 0.02,\\quad \\lambda_{2} = 0.05,\\quad N = 120.\n$$\n计算相应的最优分配 $\\{n_{1}^{\\star}, n_{2}^{\\star}\\}$。\n\nC部分。现在假设你实施一个单步短视策略，通过对边际信息增量随机变量进行 Thompson 抽样来选择下一个区域。在当前分配 $\\{n_{1}, n_{2}\\}$ 下，将区域 $k$ 的单步边际信息增量定义为\n$$\n\\Delta I_{k}(\\lambda_{k}; n_{k}) = \\frac{1}{2} w_{k} \\ln\\!\\left(\\frac{1 + \\lambda_{k} (n_{k} + 1)}{1 + \\lambda_{k} n_{k}}\\right).\n$$\n假设由于蒙特卡洛估计噪声，你对这些增量维持独立的后验高斯分布，\n$$\n\\Delta I_{k} \\sim \\mathcal{N}\\!\\big(\\mu_{k}, s_{k}^{2}\\big),\n$$\n其后验均值设为在当前 $n_{k}$ 下的代入值 $\\mu_{k} = \\Delta I_{k}(\\lambda_{k}; n_{k})$，后验方差已知为 $s_{1}^{2} = 1.0 \\times 10^{-6}$ 和 $s_{2}^{2} = 0.8 \\times 10^{-6}$。在 Thompson 抽样下，你从每个后验分布中抽取一个样本，并选择抽样值较大的区域。对于 $K = 2$ 个区域，下一个选择区域 $1$ 的概率是\n$$\np = \\mathbb{P}\\!\\big(X_{1}  X_{2}\\big) = \\Phi\\!\\left(\\frac{\\mu_{1} - \\mu_{2}}{\\sqrt{s_{1}^{2} + s_{2}^{2}}}\\right),\n$$\n其中 $X_{k} \\sim \\mathcal{N}(\\mu_{k}, s_{k}^{2})$ 独立分布，$\\Phi$ 是标准正态累积分布函数。使用 B 部分中得到的最优分配作为当前分配 $\\{n_{1}, n_{2}\\}$，以小数形式计算 $p$。将 $p$ 四舍五入到四位有效数字。\n\n使用 $\\pmatrix{\\cdot  \\cdot  \\cdot}$ 格式以行向量 $\\big(n_{1}^{\\star}, n_{2}^{\\star}, p\\big)$ 的形式提供你的最终答案。将概率 $p$ 表示为小数（不带百分号）。如果需要进行任何数值四舍五入，请严格遵守所述的有效数字规则。", "solution": "该问题要求在宇宙学背景下对模拟预算进行最优分配，然后计算在短视 Thompson 抽样策略下的决策概率。问题分为三个部分，我们将依次解决。\n\n### A部分：最优分配\n\n目标是在预算约束下最大化总互信息 $\\mathcal{I}(n_{1}, n_{2})$。\n目标函数是：\n$$\n\\mathcal{I}(n_{1}, n_{2}) = \\frac{1}{2} \\sum_{k=1}^{2} w_{k} \\ln(1 + \\lambda_{k} n_{k}) = \\frac{1}{2} w_{1} \\ln(1 + \\lambda_{1} n_{1}) + \\frac{1}{2} w_{2} \\ln(1 + \\lambda_{2} n_{2})\n$$\n约束条件是总模拟次数固定为 $N$：\n$$\nn_{1} + n_{2} = N\n$$\n我们还已知对于 $k \\in \\{1, 2\\}$ 有 $n_{k} \\ge 0$。问题陈述最优解是内部解（即 $n_{k}^{\\star}  0$），这允许我们使用拉格朗日乘子法而无需考虑边界约束。\n\n我们通过引入一个拉格朗日乘子 $\\mu$ 来构造拉格朗日函数 $\\mathcal{L}$：\n$$\n\\mathcal{L}(n_{1}, n_{2}, \\mu) = \\mathcal{I}(n_{1}, n_{2}) - \\mu(n_{1} + n_{2} - N)\n$$\n为了找到最优分配 $\\{n_{1}^{\\star}, n_{2}^{\\star}\\}$，我们将 $\\mathcal{L}$ 关于 $n_{1}$、$n_{2}$ 和 $\\mu$ 的偏导数设为零。\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial n_{1}} = \\frac{1}{2} \\frac{w_{1} \\lambda_{1}}{1 + \\lambda_{1} n_{1}} - \\mu = 0\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial n_{2}} = \\frac{1}{2} \\frac{w_{2} \\lambda_{2}}{1 + \\lambda_{2} n_{2}} - \\mu = 0\n$$\n$$\n\\frac{\\partial \\mathcal{L}}{\\partial \\mu} = N - n_{1} - n_{2} = 0\n$$\n从前两个方程，我们可以用两种方式表示 $\\mu$ 并令它们相等。这将每个区域每次模拟的边际信息增益（按常数因子 $1/2$ 缩放）相等。\n$$\n\\mu = \\frac{1}{2} \\frac{w_{1} \\lambda_{1}}{1 + \\lambda_{1} n_{1}} = \\frac{1}{2} \\frac{w_{2} \\lambda_{2}}{1 + \\lambda_{2} n_{2}}\n$$\n让我们定义一个常数 $C' = 2\\mu$。那么我们有：\n$$\n\\frac{w_{1} \\lambda_{1}}{1 + \\lambda_{1} n_{1}} = C' \\implies 1 + \\lambda_{1} n_{1} = \\frac{w_{1} \\lambda_{1}}{C'} \\implies n_{1} = \\frac{w_{1}}{C'} - \\frac{1}{\\lambda_{1}}\n$$\n$$\n\\frac{w_{2} \\lambda_{2}}{1 + \\lambda_{2} n_{2}} = C' \\implies 1 + \\lambda_{2} n_{2} = \\frac{w_{2} \\lambda_{2}}{C'} \\implies n_{2} = \\frac{w_{2}}{C'} - \\frac{1}{\\lambda_{2}}\n$$\n现在我们使用预算约束 $n_{1} + n_{2} = N$：\n$$\n\\left(\\frac{w_{1}}{C'} - \\frac{1}{\\lambda_{1}}\\right) + \\left(\\frac{w_{2}}{C'} - \\frac{1}{\\lambda_{2}}\\right) = N\n$$\n$$\n\\frac{w_{1} + w_{2}}{C'} - \\left(\\frac{1}{\\lambda_{1}} + \\frac{1}{\\lambda_{2}}\\right) = N\n$$\n使用给定条件 $w_{1} + w_{2} = 1$：\n$$\n\\frac{1}{C'} = N + \\frac{1}{\\lambda_{1}} + \\frac{1}{\\lambda_{2}}\n$$\n现在我们可以将 $1/C'$ 的这个表达式代回到 $n_{1}$ 和 $n_{2}$ 的方程中，以找到最优分配，记为 $\\{n_{1}^{\\star}, n_{2}^{\\star}\\}$：\n$$\nn_{1}^{\\star} = w_{1} \\left(N + \\frac{1}{\\lambda_{1}} + \\frac{1}{\\lambda_{2}}\\right) - \\frac{1}{\\lambda_{1}}\n$$\n$$\nn_{2}^{\\star} = w_{2} \\left(N + \\frac{1}{\\lambda_{1}} + \\frac{1}{\\lambda_{2}}\\right) - \\frac{1}{\\lambda_{2}}\n$$\n这些就是最优分配的闭式表达式。\n\n### B部分：最优分配的数值计算\n\n我们被给予以下数值：\n$$\nw_{1} = 0.6, \\quad w_{2} = 0.4, \\quad \\lambda_{1} = 0.02, \\quad \\lambda_{2} = 0.05, \\quad N = 120\n$$\n首先，我们计算信息率参数的倒数：\n$$\n\\frac{1}{\\lambda_{1}} = \\frac{1}{0.02} = 50\n$$\n$$\n\\frac{1}{\\lambda_{2}} = \\frac{1}{0.05} = 20\n$$\n现在，我们可以计算 A 部分解中括号内的项：\n$$\nN + \\frac{1}{\\lambda_{1}} + \\frac{1}{\\lambda_{2}} = 120 + 50 + 20 = 190\n$$\n将这些值代入 $n_{1}^{\\star}$ 和 $n_{2}^{\\star}$ 的表达式中：\n$$\nn_{1}^{\\star} = w_{1} \\left(190\\right) - \\frac{1}{\\lambda_{1}} = 0.6 \\times 190 - 50 = 114 - 50 = 64\n$$\n$$\nn_{2}^{\\star} = w_{2} \\left(190\\right) - \\frac{1}{\\lambda_{2}} = 0.4 \\times 190 - 20 = 76 - 20 = 56\n$$\n作为检验，我们确认 $n_{1}^{\\star} + n_{2}^{\\star} = 64 + 56 = 120 = N$。最优分配是 $\\{64, 56\\}$。\n\n### C部分：Thompson 抽样概率\n\n我们现在考虑一个单步短视策略，其中当前分配是 B 部分中找到的最优分配，即 $n_{1} = 64$ 和 $n_{2} = 56$。我们需要计算下一个选择区域 $1$ 的概率 $p$，由下式给出：\n$$\np = \\mathbb{P}(X_{1}  X_{2}) = \\Phi\\left(\\frac{\\mu_{1} - \\mu_{2}}{\\sqrt{s_{1}^{2} + s_{2}^{2}}}\\right)\n$$\n其中 $\\Phi$ 是标准正态累积分布函数 (CDF)。\n均值 $\\mu_{k}$ 由边际信息增量给出：\n$$\n\\mu_{k} = \\Delta I_{k}(\\lambda_{k}; n_{k}) = \\frac{1}{2} w_{k} \\ln\\left(\\frac{1 + \\lambda_{k} (n_{k} + 1)}{1 + \\lambda_{k} n_{k}}\\right)\n$$\n让我们使用 B 部分的值来计算 $\\mu_{1}$ 和 $\\mu_{2}$：\n对于区域 1：$n_{1} = 64, w_{1} = 0.6, \\lambda_{1} = 0.02$。\n$$\n\\mu_{1} = \\frac{1}{2} (0.6) \\ln\\left(\\frac{1 + 0.02 (64 + 1)}{1 + 0.02 \\times 64}\\right) = 0.3 \\ln\\left(\\frac{1 + 1.3}{1 + 1.28}\\right) = 0.3 \\ln\\left(\\frac{2.3}{2.28}\\right)\n$$\n对于区域 2：$n_{2} = 56, w_{2} = 0.4, \\lambda_{2} = 0.05$。\n$$\n\\mu_{2} = \\frac{1}{2} (0.4) \\ln\\left(\\frac{1 + 0.05 (56 + 1)}{1 + 0.05 \\times 56}\\right) = 0.2 \\ln\\left(\\frac{1 + 2.85}{1 + 2.8}\\right) = 0.2 \\ln\\left(\\frac{3.85}{3.8}\\right)\n$$\n现在我们计算它们的数值：\n$$\n\\mu_{1} \\approx 0.3 \\times \\ln(1.0087719) \\approx 0.3 \\times 0.008733602 = 0.0026200806\n$$\n$$\n\\mu_{2} \\approx 0.2 \\times \\ln(1.0131579) \\approx 0.2 \\times 0.013071942 = 0.0026143884\n$$\n均值之差是：\n$$\n\\mu_{1} - \\mu_{2} \\approx 0.0026200806 - 0.0026143884 = 0.0000056922\n$$\n后验方差给定为 $s_{1}^{2} = 1.0 \\times 10^{-6}$ 和 $s_{2}^{2} = 0.8 \\times 10^{-6}$。方差之和是：\n$$\ns_{1}^{2} + s_{2}^{2} = 1.0 \\times 10^{-6} + 0.8 \\times 10^{-6} = 1.8 \\times 10^{-6}\n$$\n差值的标准差是：\n$$\n\\sqrt{s_{1}^{2} + s_{2}^{2}} = \\sqrt{1.8 \\times 10^{-6}} \\approx 0.0013416408\n$$\n现在我们计算标准正态累积分布函数的自变量，我们将其记为 $z$：\n$$\nz = \\frac{\\mu_{1} - \\mu_{2}}{\\sqrt{s_{1}^{2} + s_{2}^{2}}} \\approx \\frac{0.0000056922}{0.0013416408} \\approx 0.00424285\n$$\n最后，我们计算 $p = \\Phi(z)$：\n$$\np = \\Phi(0.00424285) \\approx 0.5016922\n$$\n问题要求将 $p$ 四舍五入到四位有效数字。\n$0.5016922...$ 的前四位有效数字是 $5, 0, 1, 6$。下一位数字是 $9$，所以我们将最后一位有效数字向上舍入。\n$$\np \\approx 0.5017\n$$\n最终答案是行向量 $(n_{1}^{\\star}, n_{2}^{\\star}, p)$。\n$$\n(64, 56, 0.5017)\n$$", "answer": "$$ \\boxed{ \\begin{pmatrix} 64  56  0.5017 \\end{pmatrix} } $$", "id": "3489624"}, {"introduction": "优化模拟资源分配的最终目的是为了获得更精确的后验推断。这个练习 [@problem_id:3489634] 从一个非常实际的角度探讨了这个问题：一个更优的模拟分配策略如何直接转化为一个更严格（即更小）的ABC接受阈值 $\\epsilon$。您将通过一个确定性的计算任务，量化比较均匀分配与根据后验不确定性进行优化的“Neyman分配”之间的差异。这个练习清晰地揭示了，在保持相同的总接受率（即相似的计算成本）下，智能化的模拟策略可以如何让我们使用更小的 $\\epsilon$，从而得到对真实后验分布更精确的近似。", "problem": "给定一个有限的参数值网格 $\\{\\theta_i\\}_{i=1}^K$，以及对于每个 $\\theta_i$，给定一个有效标准差 $\\sigma_i  0$，它描述了在一个校准良好的模拟器下一个一维汇总统计量差异的分布。在近似贝叶斯计算 (ABC) 中，如果在 $\\theta_i$ 处的一次抽样的绝对差异 $D_i = |Z_i|$ 小于或等于一个阈值 $\\epsilon \\ge 0$，则该次抽样被接受，其中，根据中心极限定理，在汇总统计量充分聚合的情况下，$Z_i \\sim \\mathcal{N}(0,\\sigma_i^2)$ 被建模为高斯分布。因此，在阈值 $\\epsilon$ 下，每个参数的接受概率为\n$$\np_i(\\epsilon) \\equiv \\mathbb{P}\\big(|Z_i| \\le \\epsilon \\mid \\theta_i\\big) = 2 \\Phi\\!\\left(\\frac{\\epsilon}{\\sigma_i}\\right) - 1 = \\operatorname{erf}\\!\\left(\\frac{\\epsilon}{\\sqrt{2}\\,\\sigma_i}\\right),\n$$\n其中 $\\Phi(\\cdot)$ 表示标准正态累积分布函数，$\\operatorname{erf}(\\cdot)$ 是误差函数。\n\n假设模拟预算根据权重 $a_i \\ge 0$（其中 $\\sum_{i=1}^K a_i = 1$）分配给 $\\{\\theta_i\\}$，因此，在阈值 $\\epsilon$ 下的预期总体 ABC 接受率是按分配加权的混合\n$$\n\\bar{p}(\\epsilon; \\mathbf{a}) \\equiv \\sum_{i=1}^K a_i\\, p_i(\\epsilon) = \\sum_{i=1}^K a_i\\, \\operatorname{erf}\\!\\left(\\frac{\\epsilon}{\\sqrt{2}\\,\\sigma_i}\\right).\n$$\n给定一个目标接受水平 $\\alpha \\in (0,1)$，将在分配 $\\mathbf{a}$ 下达到该水平所需的最小阈值定义为以下方程的唯一解 $\\epsilon^\\star(\\mathbf{a};\\alpha)$\n$$\n\\bar{p}\\big(\\epsilon^\\star(\\mathbf{a};\\alpha);\\mathbf{a}\\big) = \\alpha,\n$$\n该解存在且唯一，因为 $\\bar{p}(\\epsilon;\\mathbf{a})$ 关于 $\\epsilon$ 是连续且严格递增的，满足 $\\bar{p}(0;\\mathbf{a}) = 0$，并且 $\\lim_{\\epsilon\\to\\infty}\\bar{p}(\\epsilon;\\mathbf{a}) = 1$。\n\n在同一个网格上，为您提供了两种分配方式：\n- 基线分配 $\\mathbf{a}^{(0)}$，其值等于给定的先验权重向量 $\\mathbf{q}$，其中 $q_i \\ge 0$ 且 $\\sum_{i=1}^K q_i = 1$。\n- 一种依据分层抽样中的 Neyman 分配意义上的后验不确定性进行的“最优”重分配 $\\mathbf{a}^{(\\mathrm{opt})}$：给定正的不确定性分数 $\\{s_i\\}_{i=1}^K$，设置\n$$\na_i^{(\\mathrm{opt})} \\equiv \\frac{s_i}{\\sum_{j=1}^K s_j}.\n$$\n直观上，这将更大份额的模拟分配给了具有较大后验标准差分数 $s_i$ 的分层（参数值），这是在线性成本和独立分层假设下的一个经典方差最小化原则。\n\n对于一个固定的目标接受率 $\\alpha$，将因重分配而导致的阈值预期减少量定义为\n$$\n\\Delta(\\alpha) \\equiv \\epsilon^\\star\\!\\big(\\mathbf{a}^{(0)};\\alpha\\big) - \\epsilon^\\star\\!\\big(\\mathbf{a}^{(\\mathrm{opt})};\\alpha\\big).\n$$\n$\\Delta(\\alpha)$ 的正值意味着重分配允许使用更小的 ABC 阈值来维持相同的目标接受率；负值则意味着阈值必须增加。\n\n您的任务是为以下每个独立指定的测试用例计算 $\\Delta(\\alpha)$。在每个测试用例中，都给定了 $K$、向量 $\\boldsymbol{\\sigma} = (\\sigma_1,\\dots,\\sigma_K)$、$\\mathbf{q} = (q_1,\\dots,q_K)$、$\\mathbf{s} = (s_1,\\dots,s_K)$ 以及标量 $\\alpha$。除对 $\\epsilon^\\star(\\cdot;\\alpha)$ 进行数值求根外，请使用上述定义，不做任何近似。您必须将 $\\epsilon^\\star$ 作为每个分配的单调方程的唯一根来精确求解。无需进行模拟或抽样；该问题是确定性的。\n\n测试套件：\n- 用例 1：$K=4$，$\\boldsymbol{\\sigma} = [\\,0.5,\\,0.7,\\,1.0,\\,1.5\\,]$，$\\mathbf{q} = [\\,0.25,\\,0.25,\\,0.25,\\,0.25\\,]$，$\\mathbf{s} = [\\,2.0,\\,1.5,\\,1.0,\\,0.5\\,]$，$\\alpha = 0.2$。\n- 用例 2：$K=5$，$\\boldsymbol{\\sigma} = [\\,1.0,\\,1.0,\\,1.0,\\,1.0,\\,1.0\\,]$，$\\mathbf{q} = [\\,0.2,\\,0.2,\\,0.2,\\,0.2,\\,0.2\\,]$，$\\mathbf{s} = [\\,1.0,\\,2.0,\\,3.0,\\,4.0,\\,5.0\\,]$，$\\alpha = 0.5$。\n- 用例 3：$K=3$，$\\boldsymbol{\\sigma} = [\\,0.3,\\,1.2,\\,2.0\\,]$，$\\mathbf{q} = [\\,0.2,\\,0.3,\\,0.5\\,]$，$\\mathbf{s} = [\\,3.0,\\,1.5,\\,0.5\\,]$，$\\alpha = 0.9$。\n- 用例 4：$K=3$，$\\boldsymbol{\\sigma} = [\\,0.8,\\,1.5,\\,3.0\\,]$，$\\mathbf{q} = [\\,0.6,\\,0.3,\\,0.1\\,]$，$\\mathbf{s} = [\\,0.5,\\,1.0,\\,3.0\\,]$，$\\alpha = 0.05$。\n- 用例 5：$K=2$，$\\boldsymbol{\\sigma} = [\\,0.2,\\,2.0\\,]$，$\\mathbf{q} = [\\,0.5,\\,0.5\\,]$，$\\mathbf{s} = [\\,5.0,\\,1.0\\,]$，$\\alpha = 0.99$。\n\n最终输出格式：\n- 您的程序应生成单行，其中包含一个 Python 风格的列表，内含五个实数 $[\\,\\Delta_1,\\,\\Delta_2,\\,\\Delta_3,\\,\\Delta_4,\\,\\Delta_5\\,]$，其中 $\\Delta_j$ 是用例 $j$ 的 $\\Delta(\\alpha)$ 值，顺序与上文相同。在打印前，每个 $\\Delta_j$ 必须四舍五入到小数点后 $6$ 位。例如，格式应严格为 $[x_1,x_2,x_3,x_4,x_5]$，不含空格。\n\n在此设置中，所有答案都是无量纲的，因为阈值 $\\epsilon$ 和差异共享相同的抽象单位并被一致处理；按规定报告每个用例的实值 $\\Delta(\\alpha)$。不涉及角度单位或百分比。您的程序必须是完全自包含的，为 $\\epsilon^\\star$ 实现一个鲁棒的单调函数求根器，并且只使用标准的数值函数。", "solution": "该问题要求计算因模拟分配策略改变而导致的近似贝叶斯计算 (ABC) 接受阈值的变化量 $\\Delta(\\alpha)$。该问题是确定性的，需要针对两种不同的分配方案求解关于阈值 $\\epsilon^\\star$ 的非线性方程。\n\n首先，让我们将问题的核心形式化。对于给定的参数网格上的模拟分配 $\\mathbf{a} = \\{a_i\\}_{i=1}^K$，阈值为 $\\epsilon$ 时的预期总体接受率由以下混合给出：\n$$\n\\bar{p}(\\epsilon; \\mathbf{a}) = \\sum_{i=1}^K a_i\\, \\operatorname{erf}\\!\\left(\\frac{\\epsilon}{\\sqrt{2}\\,\\sigma_i}\\right)\n$$\n其中 $\\sigma_i$ 是参数点 $\\theta_i$ 处汇总统计量差异的有效标准差，$\\operatorname{erf}(\\cdot)$ 是误差函数。给定一个目标接受率 $\\alpha \\in (0,1)$，所需的最小阈值 $\\epsilon^\\star(\\mathbf{a};\\alpha)$ 被定义为以下方程的唯一解：\n$$\n\\bar{p}(\\epsilon^\\star; \\mathbf{a}) - \\alpha = 0\n$$\n问题陈述正确地指出，$\\bar{p}(\\epsilon; \\mathbf{a})$ 是关于 $\\epsilon \\ge 0$ 的严格单调递增函数，且有 $\\bar{p}(0; \\mathbf{a}) = 0$ 和 $\\lim_{\\epsilon\\to\\infty}\\bar{p}(\\epsilon; \\mathbf{a}) = 1$。这保证了对于任何 $\\alpha \\in (0,1)$，根 $\\epsilon^\\star$ 都存在且唯一，从而使问题成为适定问题。\n\n我们的任务是为两种不同的分配找到这个根 $\\epsilon^\\star$：\n1.  基线分配 $\\mathbf{a}^{(0)}$，其值设为给定的先验权重向量 $\\mathbf{q} = \\{q_i\\}_{i=1}^K$。\n2.  一种“最优”分配 $\\mathbf{a}^{(\\mathrm{opt})}$，根据 Neyman 分配原则从一组不确定性分数 $\\{s_i\\}_{i=1}^K$ 推导得出：\n    $$\n    a_i^{(\\mathrm{opt})} = \\frac{s_i}{\\sum_{j=1}^K s_j}\n    $$\n\n对于给定的测试用例，我们必须首先计算 $\\epsilon^\\star(\\mathbf{a}^{(0)}; \\alpha)$ 和 $\\epsilon^\\star(\\mathbf{a}^{(\\mathrm{opt})}; \\alpha)$。然后，所求量，即阈值的预期减少量，是它们的差：\n$$\n\\Delta(\\alpha) = \\epsilon^\\star(\\mathbf{a}^{(0)}; \\alpha) - \\epsilon^\\star(\\mathbf{a}^{(\\mathrm{opt})}; \\alpha)\n$$\n\n核心的算法挑战是求解非线性方程 $\\bar{p}(\\epsilon; \\mathbf{a}) - \\alpha = 0$。鉴于函数 $f(\\epsilon) = \\bar{p}(\\epsilon; \\mathbf{a}) - \\alpha$ 的单调性，这是一个标准的一维求根问题。完成此任务的一种鲁棒且高效的方法是 Brent-Dekker 算法（在 `scipy.optimize.brentq` 中实现），它结合了二分法的确定性、割线法以及逆二次插值的速度。要应用此方法，我们必须提供一个求根区间 $[\\epsilon_{\\text{low}}, \\epsilon_{\\text{high}}]$，使得 $f(\\epsilon_{\\text{low}})$ 和 $f(\\epsilon_{\\text{high}})$ 的符号相反。\n对于任何有效的分配 $\\mathbf{a}$ 和目标 $\\alpha \\in (0,1)$，我们有：\n*   $f(0) = \\bar{p}(0; \\mathbf{a}) - \\alpha = 0 - \\alpha = -\\alpha  0$。\n*   $\\lim_{\\epsilon\\to\\infty} f(\\epsilon) = 1 - \\alpha  0$。\n因此，根总是保证存在于区间 $[0, \\infty)$ 中。我们可以选择 $\\epsilon_{\\text{low}} = 0$ 和一个足够大的 $\\epsilon_{\\text{high}}$ 来确保函数值变为正。\n\n每个测试用例的总体算法如下：\n1.  根据输入向量 $\\mathbf{q}$ 和 $\\mathbf{s}$，计算两个分配向量 $\\mathbf{a}^{(0)} = \\mathbf{q}$ 和 $\\mathbf{a}^{(\\mathrm{opt})}$。向量 $\\mathbf{q}$ 已被归一化，而 $\\mathbf{a}^{(\\mathrm{opt})}$ 通过对向量 $\\mathbf{s}$ 进行归一化来构建。\n2.  定义目标函数 $f(\\epsilon, \\mathbf{a}, \\boldsymbol{\\sigma}, \\alpha) = \\left(\\sum_{i=1}^K a_i \\operatorname{erf}\\left(\\frac{\\epsilon}{\\sqrt{2}\\sigma_i}\\right)\\right) - \\alpha$。\n3.  使用一个数值求根器（例如 `scipy.optimize.brentq`）和一个合适的区间（例如 $[0, 1000]$）来求解 $f(\\epsilon, \\mathbf{a}^{(0)}, \\boldsymbol{\\sigma}, \\alpha) = 0$，得到 $\\epsilon_0^\\star = \\epsilon^\\star(\\mathbf{a}^{(0)}; \\alpha)$。\n4.  类似地，求解 $f(\\epsilon, \\mathbf{a}^{(\\mathrm{opt})}, \\boldsymbol{\\sigma}, \\alpha) = 0$，得到 $\\epsilon_{\\mathrm{opt}}^\\star = \\epsilon^\\star(\\mathbf{a}^{(\\mathrm{opt})}; \\alpha)$。\n5.  计算差值 $\\Delta(\\alpha) = \\epsilon_0^\\star - \\epsilon_{\\mathrm{opt}}^\\star$。\n6.  最终结果按要求四舍五入到小数点后 6 位。\n\n这个过程是确定性的，并依赖于标准的、经过充分检验的数值方法，从而确保解决方案的准确性和可复现性。实现将使用 `numpy` 进行高效的向量化计算，并使用 `scipy` 进行误差函数和求根运算。", "answer": "```python\nimport numpy as np\nfrom scipy.special import erf\nfrom scipy.optimize import brentq\n\ndef solve():\n    \"\"\"\n    Computes the expected reduction in ABC threshold for five test cases.\n\n    The solution involves finding the root of a monotonic function for two different\n    simulation allocation schemes and calculating the difference in the roots.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # (K, sigma, q, s, alpha)\n        (4, [0.5, 0.7, 1.0, 1.5], [0.25, 0.25, 0.25, 0.25], [2.0, 1.5, 1.0, 0.5], 0.2),\n        (5, [1.0, 1.0, 1.0, 1.0, 1.0], [0.2, 0.2, 0.2, 0.2, 0.2], [1.0, 2.0, 3.0, 4.0, 5.0], 0.5),\n        (3, [0.3, 1.2, 2.0], [0.2, 0.3, 0.5], [3.0, 1.5, 0.5], 0.9),\n        (3, [0.8, 1.5, 3.0], [0.6, 0.3, 0.1], [0.5, 1.0, 3.0], 0.05),\n        (2, [0.2, 2.0], [0.5, 0.5], [5.0, 1.0], 0.99)\n    ]\n\n    results = []\n\n    # Define a bracketing interval for the root-finding algorithm.\n    # The lower bound can be 0, where the objective function is -alpha.\n    # The upper bound must be large enough for the function to be positive.\n    # A value of 1000.0 is sufficiently large for all test cases.\n    ROOT_FINDING_BRACKET = [0.0, 1000.0]\n    \n    SQRT2 = np.sqrt(2.0)\n\n    for case in test_cases:\n        K, sigma_list, q_list, s_list, alpha = case\n        \n        # Convert inputs to numpy arrays for vectorized calculations.\n        sigma_vec = np.array(sigma_list)\n        q_vec = np.array(q_list)\n        s_vec = np.array(s_list)\n\n        # Define the objective function whose root (epsilon_star) we seek.\n        # This function computes `p_bar(epsilon) - alpha`.\n        def objective_function(epsilon, allocation_weights, sigma_vals, target_alpha):\n            # Calculate the weighted average acceptance probability p_bar.\n            p_bar = np.sum(allocation_weights * erf(epsilon / (SQRT2 * sigma_vals)))\n            return p_bar - target_alpha\n\n        # 1. Baseline allocation a^(0) = q\n        a_baseline = q_vec\n        \n        # 2. \"Optimal\" allocation a^(opt) from Neyman allocation principle\n        a_optimal = s_vec / np.sum(s_vec)\n        \n        # Find the minimal threshold epsilon_star for the baseline allocation.\n        epsilon_star_baseline = brentq(\n            objective_function,\n            ROOT_FINDING_BRACKET[0],\n            ROOT_FINDING_BRACKET[1],\n            args=(a_baseline, sigma_vec, alpha)\n        )\n        \n        # Find the minimal threshold epsilon_star for the optimal allocation.\n        epsilon_star_optimal = brentq(\n            objective_function,\n            ROOT_FINDING_BRACKET[0],\n            ROOT_FINDING_BRACKET[1],\n            args=(a_optimal, sigma_vec, alpha)\n        )\n        \n        # Compute the threshold reduction, Delta(alpha).\n        delta = epsilon_star_baseline - epsilon_star_optimal\n        \n        # Round the result to 6 decimal places as required.\n        results.append(round(delta, 6))\n\n    # Print the final result in the specified list format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3489634"}]}