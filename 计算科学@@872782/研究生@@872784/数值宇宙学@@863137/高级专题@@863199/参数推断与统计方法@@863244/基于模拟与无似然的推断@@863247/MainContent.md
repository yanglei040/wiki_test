## 引言
在现代科学的前沿，尤其是在宇宙学等领域，我们越来越依赖于复杂的计算机模拟来探索宇宙的奥秘。这些模拟器能够根据理论参数生成逼真的观测数据，但其内部的复杂性和随机性，使得计算给定参数下观测到特定数据的概率——即[似然函数](@entry_id:141927)——变得几乎不可能。这一“[难解似然](@entry_id:140896)”问题构成了连接理论与数据的一道鸿沟，也正是[基于模拟的推断](@entry_id:754873)（Simulation-Based Inference, SBI）旨在解决的核心挑战。本文将系统地引导您穿越这一前沿领域。在“原理与机制”一章中，我们将深入剖析SBI的基本思想，从经典的[近似贝叶斯计算](@entry_id:746494)（ABC）到利用机器学习的现代方法，揭示其如何绕开[似然函数](@entry_id:141927)进行有效的贝叶斯推断。接着，在“应用与[交叉](@entry_id:147634)学科联系”一章中，我们将通过宇宙学、[高能物理](@entry_id:181260)、地球科学等领域的生动案例，展示SBI在解决实际科学问题中的强大威力。最后，“动手实践”部分将提供一系列精心设计的问题，帮助您将理论知识转化为实践技能。让我们一同开始，学习如何利用模拟的力量，从复杂数据中解锁科学发现。

## 原理与机制

在“引言”章节中，我们已经了解到，在许多科学领域，尤其是宇宙学中，我们依赖于复杂的计算机模拟来连接理论模型和观测数据。这些模拟构成了所谓的**隐式**或**生成式模型**：给定一组理论参数 $\theta$，我们可以生成模拟数据 $x$，但我们往往无法写出似然函数 $p(x|\theta)$ 的解析表达式。本章将深入探讨在这种情况下进行[贝叶斯推断](@entry_id:146958)的核心原理和关键机制，即所谓的[基于模拟的推断](@entry_id:754873)（Simulation-Based Inference, SBI）或[无似然推断](@entry_id:190479)（Likelihood-Free Inference, LFI）。

### 隐式模型下的推断问题

#### [难解似然](@entry_id:140896)函数的挑战

[贝叶斯推断](@entry_id:146958)的核心在于贝叶斯定理，它通过[似然函数](@entry_id:141927) $p(x|\theta)$ 和[先验概率](@entry_id:275634) $\pi(\theta)$ 来构建参数的[后验概率](@entry_id:153467)[分布](@entry_id:182848) $p(\theta|x)$。然而，当一个科学模型是由一个复杂的、包含大量[随机过程](@entry_id:159502)和[非线性](@entry_id:637147)演化的[数值模拟](@entry_id:137087)器定义时，[似然函数](@entry_id:141927)——即在给定参数 $\theta$ 时观测到特定数据 $x$ 的[概率密度](@entry_id:175496)——通常是无法计算的。例如，在宇宙学中，从一组[宇宙学参数](@entry_id:161338)（如暗[物质密度](@entry_id:263043)、[暗能量状态方程](@entry_id:158117)等）出发，通过[N体模拟](@entry_id:157492)生成一个[星系巡天](@entry_id:749696)的模拟观测，这一过程涉及[引力](@entry_id:175476)演化、[星系形成](@entry_id:160121)、观测效应等众多随机步骤。对所有这些内在的随机自由度进行积分以求得 $p(x|\theta)$ 在计算上是不可行的。

#### 形式化：作为生成式模型的模拟器

为了严谨地处理这个问题，我们可以将模拟器形式化地表达为一个生成式过程。设参数 $\theta$ 属于参数空间 $\Theta$，模拟器的所有随机性输入（例如，初始条件的随机相位、仪器噪声的实现等）由一个潜在变量 $u$ 表示，它从一个已知的[分布](@entry_id:182848) $p(u)$ 中抽取。模拟器本身是一个确定的函数 $g$，它将参数 $\theta$ 和随机输入 $u$ 映射到观测空间 $\mathcal{X}$ 中的一个数据点 $x$：

$$
x = g(\theta, u), \quad u \sim p(u)
$$

对于每一个固定的参数 $\theta$，这个映射定义了一个从[潜变量](@entry_id:143771)空间到数据空间的**[前推](@entry_id:158718)概率测度**（pushforward probability measure）$\mathbb{P}_\theta$。这个测度描述了由模拟器给出的、以 $\theta$为条件的 $x$ 的完整[概率分布](@entry_id:146404) [@problem_id:3489611]。

#### 似然函数何时存在？

一个关键的问题是，这个由模拟器定义的概率测度 $\mathbb{P}_\theta$ 是否对应一个**[似然](@entry_id:167119)密度函数** $p(x|\theta)$。根据测度论中的**[拉东-尼科迪姆定理](@entry_id:161238)**（Radon-Nikodym theorem），一个似然密度函数的存在性，取决于测度 $\mathbb{P}_\theta$ 是否关于观测空间 $\mathcal{X}$ 上的某个参考测度（通常是[勒贝格测度](@entry_id:139781)）**绝对连续**。

在许多实际情况中，这个条件并不满足。例如，如果模拟器将高维的潜变量 $u$ 映射到数据空间 $\mathcal{X}$ 中的一个低维[流形](@entry_id:153038)上，那么由模拟器生成的 $x$ 的[分布](@entry_id:182848)将是**奇异的**（singular）。这意味着模拟数据的支撑集在 $\mathcal{X}$ 中的测度为零。在这种情况下，任何特定点观测 $\tilde{x}$ 的[概率密度](@entry_id:175496) $p(\tilde{x}|\theta)$ 都是病态的（或者说，是零或无穷大），标准的、依赖于点态似然评估的贝叶斯推断方法便无法直接应用 [@problem_id:3489611] [@problem_id:3489606]。这正是“无[似然](@entry_id:167119)”推断方法要解决的核心困难。

### 基础方法：[近似贝叶斯计算](@entry_id:746494)（ABC）

最早也是最直观的一类[无似然推断](@entry_id:190479)方法是**[近似贝叶斯计算](@entry_id:746494)**（Approximate Bayesian Computation, ABC）。其核心思想是用模拟和比较取代直接的[似然](@entry_id:167119)评估。

#### [拒绝采样](@entry_id:142084)的核心

最简单的[ABC算法](@entry_id:746190)是一个[拒绝采样](@entry_id:142084)过程：
1. 从先验分布 $\pi(\theta)$ 中抽取一个候选参数 $\theta^*$。
2. 使用 $\theta^*$ 运行模拟器，生成一个模拟数据 $x^*$。
3. 定义一个距离函数 $d(\cdot, \cdot)$ 和一个容忍度 $\epsilon > 0$。如果模拟数据与真实观测数据 $x_{obs}$ 足够接近，即 $d(x^*, x_{obs}) \le \epsilon$，则接受该参数 $\theta^*$。
4. 重复以上步骤，直到收集到足够多的接受样本，这些样本构成了对[后验分布](@entry_id:145605)的近似。

#### 摘要统计量与充分性

在处理高维数据（如宇宙学中的三维密度场或星系[分布](@entry_id:182848)图）时，直接比较 $x^*$ 和 $x_{obs}$ 是不可行的，因为在高维空间中任何两个随机点几乎总是不接近的，这被称为“[维度灾难](@entry_id:143920)”。为了解决这个问题，ABC通常在低维的**摘要统计量**（summary statistics）$s(x)$ 上进行比较，接受条件变为 $d(s(x^*), s(x_{obs})) \le \epsilon$。

摘要统计量的选择至关重要。理想情况下，我们希望使用**充分统计量**（sufficient statistic）。根据**[费雪-奈曼分解定理](@entry_id:175096)**（Fisher-Neyman factorization theorem），如果一个统计量 $s(x)$ 对于参数 $\theta$ 是充分的，那么在给定 $s(x)$ 的条件下，$x$ 的[分布](@entry_id:182848)与 $\theta$ 无关。这意味着 $s(x)$ 包含了数据 $x$ 中关于 $\theta$ 的所有信息。如果使用充分统计量，那么基于摘要的推断就不会损失任何信息 [@problem_id:3489606]。然而，在复杂的物理模型中，找到一个既是低维又具有充分性的统计量往往是不可能的。因此，实践中通常会选择一组被认为包含了大部分相关[物理信息](@entry_id:152556)的非充分统计量（例如，功率谱和[双谱](@entry_id:158545)），这在推断过程中引入了一层额外的近似 [@problem_id:3489686]。

#### ABC后验及其极限

通过上述[拒绝采样](@entry_id:142084)过程，我们实际上是从一个近似的[后验分布](@entry_id:145605)中进行采样，这个[分布](@entry_id:182848)可以写作 $p(\theta | d(s(x), s(x_{obs})) \le \epsilon)$。可以证明，在容忍度 $\epsilon \to 0$ 的极限下，ABC后验分布收敛于以摘要统计量为条件的真实后验分布 $p(\theta | s(x_{obs}))$ [@problem_id:3489606]。只有当 $s(x)$ 是充分统计量时，这个[极限分布](@entry_id:174797)才等于我们真正想要的、以完整数据为条件的后验 $p(\theta | x_{obs})$。

更具体地说，对于一个给定的 $\theta$，其被接受的概率正比于模拟的摘要 $s(x^*)$ 落在以观测摘要 $s(x_{obs})$ 为中心的 $\epsilon$-球内的概率。对于足够小的 $\epsilon$，这个概率约等于 $p_s(s(x_{obs})|\theta) \times V_\epsilon$，其中 $p_s$ 是摘要统计量的[似然函数](@entry_id:141927)，$V_\epsilon$ 是 $\epsilon$-球的体积。由于 $V_\epsilon$ 与 $\theta$ 无关，因此接受的 $\theta$ 的[分布](@entry_id:182848)正比于 $p_s(s(x_{obs})|\theta)\pi(\theta)$，这正是 $p(\theta|s(x_{obs}))$ 的形式 [@problem_id:3489606]。

### 现代[基于模拟的推断](@entry_id:754873)：超越[拒绝采样](@entry_id:142084)

ABC虽然直观，但在高维[参数空间](@entry_id:178581)或需要小 $\epsilon$ 以获得高精度时，其[采样效率](@entry_id:754496)极低。现代SBI方法通过使用机器学习技术来更有效地利用模拟数据，从而克服了这一限制。这些方法大致可分为两大类 [@problem_id:3536602]。

#### 两种主要策略

- **解析近似似然方法**（Analytical Approximate Likelihood Methods）：这类方法为[似然函数](@entry_id:141927)（或摘要统计量的[似然](@entry_id:167119)）设定一个简单、易于处理的解析形式，例如多元[高斯分布](@entry_id:154414)。然后，通过运行模拟来估计这个近似似然函数的参数（如均值和协[方差](@entry_id:200758)）。一个典型的例子是**[合成似然](@entry_id:755756)**（Synthetic Likelihood）。这种方法的主要风险在于，如果预设的函数形式与真实的似然函数相去甚远（即[模型设定错误](@entry_id:170325)），即使有无限的模拟，推断结果也可能存在系统性偏差。

- **[无似然推断](@entry_id:190479)方法**（Likelihood-Free Inference Methods）：这类方法不预设[似然](@entry_id:167119)的函数形式，而是利用灵活的[机器学习模型](@entry_id:262335)（如[神经网](@entry_id:276355)络）直接从模拟中学习一个代理模型。这个代理模型可以是后验分布本身 $p(\theta|x)$，也可以是似然 $p(x|\theta)$ 或[似然比](@entry_id:170863) $p(x|\theta_1)/p(x|\theta_0)$。在拥有足够模拟数据和灵活模型的前提下，这些方法通常是**渐进精确**的，能够收敛到真实的后验（或摘要后验）。

#### 机制一：学习似然与证据的比值（LRE）

现代SBI的一个强大机制是通过密度比值估计来推断后验。其关键是学习**[似然](@entry_id:167119)与证据的比值**（likelihood-to-evidence ratio），定义为 $r(x, \theta) = p(x|\theta) / p(x)$。根据贝叶斯定理，后验可以表示为 $p(\theta|x) = r(x, \theta) \pi(\theta)$，因此只要能估计出 $r(x, \theta)$，就能得到后验。

一种优雅的估计 $r(x, \theta)$ 的方法是将其转化为一个[二元分类](@entry_id:142257)问题 [@problem_id:3489622]。我们构造一个[分类任务](@entry_id:635433)，目标是区分两[类数](@entry_id:156164)据点 $(x, \theta)$：
- **正类 (y=1)**：样本从联合分布 $p(x, \theta) = p(x|\theta)\pi(\theta)$ 中抽取。这可以通过先从先验 $\pi(\theta)$ 中抽样 $\theta$，再用此 $\theta$ 运行模拟器得到 $x$ 来实现。
- **负类 (y=0)**：样本从边缘[分布](@entry_id:182848)的乘积 $p(x)p(\theta)$ 中抽取。这可以通过独立地从先验和所有模拟数据池中抽样 $\theta$ 和 $x$ 来实现。

一个理想的[概率分类](@entry_id:637254)器会输出一个样本属于正类的后验概率 $p(y=1|x, \theta)$。利用[贝叶斯定理](@entry_id:151040)进行分类，可以推导出：
$$
p(y=1|x, \theta) = \frac{p(x, \theta|y=1)p(y=1)}{p(x, \theta|y=1)p(y=1) + p(x, \theta|y=0)p(y=0)} = \frac{p(x|\theta)\pi(\theta)}{p(x|\theta)\pi(\theta) + p(x)\pi(\theta)} = \frac{p(x|\theta)}{p(x|\theta)+p(x)} = \frac{r(x, \theta)}{r(x, \theta)+1}
$$
（假设类别先验 $p(y=1)=p(y=0)=0.5$）。这个关系意味着，如果我们训练一个分类器（如[神经网](@entry_id:276355)络）来预测 $p(y=1|x, \theta)$，我们就可以从中代数地恢复出我们想要的比值 $r(x, \theta)$。训练这个分类器的目标函数是标准的[二元交叉熵](@entry_id:636868)损失，其期望形式为 [@problem_id:3489622]：
$$
\mathcal{L}(q) = - \frac{1}{2} \int \left[ p(x,\theta) \,\ln q(y=1 \mid x,\theta) + p(x)\,p(\theta)\,\ln \big(1 - q(y=1 \mid x,\theta)\big) \right] \, dx \, d\theta
$$
其中 $q(y=1|x, \theta)$ 是我们模型的输出。最小化这个损失函数，就能让 $q$ 逼近理想的分类器，从而得到似然与证据的比值。

#### 机制二：利用[得分函数](@entry_id:164520)的局部信息

对于在某个参考参数 $\theta_0$（例如，[标准宇宙学模型](@entry_id:159833)）附近进行的高精度推断，另一种强大的机制是利用[似然函数](@entry_id:141927)的梯度信息。**[得分函数](@entry_id:164520)**（score function）被定义为[对数似然函数](@entry_id:168593)关于参数的梯度：
$$
t(x; \theta) = \nabla_{\theta} \log p(x \mid \theta)
$$
对[对数似然比](@entry_id:274622) $\log r(x) = \log p(x|\theta) - \log p(x|\theta_0)$ 在 $\theta_0$ 附近进行一阶[泰勒展开](@entry_id:145057)，我们得到一个[局部线性近似](@entry_id:263289) [@problem_id:3536634]：
$$
\log r(x) \approx t(x; \theta_0)^{\top}(\theta - \theta_0)
$$
这个近似表明，在 $\theta_0$ 的一个小邻域内，得分向量 $t(x; \theta_0)$ 是一个“一阶最优”的摘要统计量，它捕获了数据中关于参数微小偏离 $\theta-\theta_0$ 的所有线性信息。这种方法构成了**局部推断**（local inference）的基础。对于需要探索广阔参数空间的**全局推断**（global inference），则需要包含二阶（即[费雪信息矩阵](@entry_id:750640)）甚至更高阶项，或者直接学习整个似然比的非[线性形式](@entry_id:276136) [@problem_id:3536634]。值得注意的是，即使 $p(x|\theta)$ 难解，其[得分函数](@entry_id:164520) $t(x; \theta)$ 有时也可以通过模拟来估计，这催生了一系列基于得分的SBI方法。

#### 机制三：用于梯度推断的路径导数

当模拟器 $x=g(\theta, u)$ 本身对于参数 $\theta$ 是可微的时，我们可以利用一种称为**路径导数**（pathwise derivative）或**[重参数化技巧](@entry_id:636986)**（reparameterization trick）的方法来高效地计算某些[期望值](@entry_id:153208)的梯度。这在需要通过梯度下降来优化参数或进行[变分推断](@entry_id:634275)时尤其有用。

假设我们的目标是最小化某个[损失函数](@entry_id:634569)关于模拟输出的期望，即 $J(\theta) = \mathbb{E}_{u \sim p(u)}[\ell(g(\theta,u))]$。如果 $g$ 对 $\theta$ 可微，我们可以将[梯度算子](@entry_id:275922)直接推入期望内部：
$$
\nabla_{\theta} J(\theta) = \mathbb{E}_{u \sim p(u)}[\nabla_{\theta} \ell(g(\theta, u))]
$$
这意味着我们可以通过从 $p(u)$ 中采样一个 $u$，计算内部的梯度 $\nabla_{\theta} \ell(g(\theta, u))$，并用其作为对真实梯度 $\nabla_{\theta} J(\theta)$ 的一个单样本[蒙特卡洛估计](@entry_id:637986)。这种估计量通常比其他[梯度估计](@entry_id:164549)方法（如基于[得分函数](@entry_id:164520)的REINFOR[CE算法](@entry_id:178177)）具有更低的[方差](@entry_id:200758) [@problem_id:3489613]。

### 关键考量与保证

在应用SBI方法时，我们必须关注几个基本问题，以确保推断结果的有效性和可靠性。

#### [参数可辨识性](@entry_id:197485)

在进行任何推断之前，一个根本性的问题是：从数据中是否可能唯一地确定参数？这就是**[参数可辨识性](@entry_id:197485)**（parameter identifiability）问题。一个参数是可辨识的，当且仅当不同的参数值会导致不同的可观测数据[分布](@entry_id:182848)。在我们的形式化语言中，这意味着从参数到概率测度的映射 $\theta \mapsto \mathbb{P}_\theta$ 必须是**单射**的（injective） [@problem_id:3489616]。

如果这个映射不是单射的，即存在 $\theta_1 \neq \theta_2$ 使得 $\mathbb{P}_{\theta_1} = \mathbb{P}_{\theta_2}$，那么它们的[似然函数](@entry_id:141927)也将[几乎处处相等](@entry_id:267606)，$p(x|\theta_1) = p(x|\theta_2)$。在这种情况下，数据 $x$ 将无法提供任何信息来区分 $\theta_1$ 和 $\theta_2$。后验分布将在所有具有相同[似然](@entry_id:167119)的参数构成的等价类上呈现出与先验相同的形状，这意味着模型存在**简并**（degeneracy）。

一个经典的宇宙学例子是线性星系偏置模型，其中观测到的[星系功率谱](@entry_id:161065) $P_g(k)$ 被建模为[物质功率谱](@entry_id:161407) $P_m(k)$ 的一个偏置版本 $P_g(k) = b^2 P_m(k)$。如果[物质功率谱](@entry_id:161407)的振幅 $A$ 也是一个未知参数，即 $P_m(k) \propto A$，那么模型预测的信号将正比于复合参数 $A b^2$。任何参数对 $(A, b)$，只要它们的乘积 $A b^2$ 相同，就会产生完全相同的预测信号，从而导致相同的似然函数。因此，$A$ 和 $b$ 无法被单独确定，它们是不可辨识的 [@problem_id:3489616]。

#### [模型设定错误](@entry_id:170325)

“所有模型都是错的，但有些是有用的。” 在实践中，我们的模拟器几乎肯定只是真实世界数据生成过程的一个近似。这就引出了**[模型设定错误](@entry_id:170325)**（model misspecification）的问题：当我们使用的模拟器族 $\{p(x|\theta)\}$ 并不包含真实的数据生成[分布](@entry_id:182848) $p^*(x)$ 时，我们学到的究竟是什么？

在这种情况下，大多数表现良好的推断方法（包括基于[最大似然](@entry_id:146147)和许多SBI方法）会收敛到一个所谓的**伪真参数**（pseudo-true parameter）$\theta^\dagger$。这个 $\theta^\dagger$ 是模型族中“最接近”真实[分布](@entry_id:182848)的那个参数。这里的“接近”通常是用**库尔贝克-莱布勒（KL）散度**来衡量的。伪真参数 $\theta^\dagger$ 是最小化从真实[分布](@entry_id:182848)到模型[分布](@entry_id:182848)的[KL散度](@entry_id:140001)的那个参数 [@problem_id:3489671]：
$$
\theta^{\dagger} \equiv \arg\min_{\theta} \mathrm{KL}(p^*(x) \Vert p(x | \theta))
$$
最小化这个KL散度等价于最大化模型在真实数据[分布](@entry_id:182848)下的期望[对数似然](@entry_id:273783) $\mathbb{E}_{x \sim p^*}[\log p(x|\theta)]$。对于[指数族](@entry_id:263444)[分布](@entry_id:182848)（如[高斯分布](@entry_id:154414)），这通常意味着伪真参数所对应的模型[分布](@entry_id:182848)，其矩（如均值和[方差](@entry_id:200758)）与真实数据[分布的矩](@entry_id:156454)相匹配 [@problem_id:3489671]。理解这一点至关重要，因为它告诉我们，当模型存在错误时，我们的推断结果是在寻找一个在特定意义下（如[矩匹配](@entry_id:144382)）对真实世界做出最佳描述的有效模型，而非寻找“宇宙的真实参数”。

#### 后验校准与验证

SBI方法产生的后验是近似的，其[不确定性量化](@entry_id:138597)是否可靠需要严格的验证。一个**已校准**（calibrated）的[后验分布](@entry_id:145605)应该具有这样的性质：平均而言，其 $c\%$ 的[可信区间](@entry_id:176433)（credible region）应该包含真实参数值的比例恰好为 $c\%$。例如，从大量模拟的“真实”参数 $\theta_{true}$ 出发生成模拟观测 $x_{sim}$，然后对每个 $x_{sim}$ 计算出的后验分布中，有95%的后验[可信区间](@entry_id:176433)应该包含各自的 $\theta_{true}$。

**基于模拟的校准**（Simulation-Based Calibration, SBC）是为此设计的标准诊断工具 [@problem_id:3536602]。它通过检查在大量模拟中计算出的真实参数在其对应后验中的分位数（rank）的[分布](@entry_id:182848)是否均匀，来判断校准性。

如果发现一个近似后验是**未校准**的——例如，它可能系统性地过于自信（[方差](@entry_id:200758)太小）或过于保守（[方差](@entry_id:200758)太大）——我们可以对其进行后处理校正。一种常用的技术是**温度缩放**（temperature scaling）。对于一个近似后验 $q(\theta|x)$，我们可以通过一个温度参数 $T$ 对其进行调整，得到 $q_T(\theta|x) \propto [q(\theta|x)]^{1/T}$。对于[高斯近似](@entry_id:636047)后验，这相当于将其[协方差矩阵](@entry_id:139155)乘以 $T$。通过调整 $T$，我们可以扩大或缩小后验的不确定性，以使其覆盖率（coverage）与名义可信度水平相匹配，从而提高其校准性 [@problem_id:3489662]。