{"hands_on_practices": [{"introduction": "在构建模拟器时，一个最基本的问题是：“我们需要多少次模拟？” 这个练习从理论上探讨了两种常见的模拟器架构——多项式混沌展开（PCE）和高斯过程（GP）——的样本需求。通过这个练习[@problem_id:3478376]，你将深入理解“维度灾难”的概念，并学会权衡不同模拟器选择之间的利弊。", "problem": "您正在为一个宇宙学可观测量 $y(\\boldsymbol{\\theta})$（例如，固定波数下的非线性物质功率谱）构建一个机器学习模拟器。该可观测量定义在一个有界参数域 $\\Theta \\subset \\mathbb{R}^{d}$ 上，其中 $\\boldsymbol{\\theta} \\in \\Theta$ 编码了 $d$ 个宇宙学参数。您决定使用非侵入式线性回归方法，在 $\\Theta$ 内的 $N$ 个不同设计点上进行模型评估（高保真度模拟），以拟合一个总阶为 $p$ 的多项式混沌展开 (Polynomial Chaos Expansion, PCE) 代理模型。假设 $\\Theta$ 上的输入测度是绝对连续且有界的，因此存在一个由多重指标 $\\boldsymbol{\\alpha} \\in \\mathbb{N}_{0}^{d}$ 索引的多元多项式标准正交基 $\\{\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta})\\}$，并且您将展开截断至所有总阶 $\\|\\boldsymbol{\\alpha}\\|_{1} \\le p$ 的多重指标。进一步假设评估是无噪声的，且设计使得回归设计矩阵在代数上可能的情况下具有满列秩。\n\n从截断的总阶多项式空间的定义和通过回归唯一确定截断 PCE 中所有系数的线性代数要求出发，推导唯一识别所有展开系数所需的最小模拟次数 $N_{\\min}(d,p)$（用 $d$ 和 $p$ 表示）。\n\n然后，仍然基于第一性原理，讨论在选择此 PCE 设计与选择一个在 $d$ 维空间中带有平稳核的高斯过程 (Gaussian Process, GP) 模拟器时，在样本复杂度和计算成本方面的关键权衡，包括每种方法如何随 $d$ 和 $p$ 扩展，以及对不确定性量化的影响。您的讨论应该是定性的，并从核心定义和广泛使用的性质出发进行论证；不要引用任何专门的或预先推导的抽样公式。\n\n请以单一闭式表达式的形式提供您对 $N_{\\min}(d,p)$ 的最终答案。无需进行数值评估。不包括单位。不要四舍五入。", "solution": "在进行求解之前，对问题陈述的有效性进行严格评估。\n\n### 步骤 1：提取已知条件\n- 宇宙学可观测量：$y(\\boldsymbol{\\theta})$\n- 参数域：$\\boldsymbol{\\theta} \\in \\Theta \\subset \\mathbb{R}^{d}$\n- 模拟器类型：总阶为 $p$ 的多项式混沌展开 (PCE)。\n- 拟合方法：对 $N$ 次模型评估进行非侵入式线性回归。\n- 设计点：$\\Theta$ 中的 $N$ 个不同点。\n- 输入测度：绝对连续且有界。\n- 多项式基：标准正交基 $\\{\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta})\\}$，其中 $\\boldsymbol{\\alpha} \\in \\mathbb{N}_{0}^{d}$。\n- 截断规则：总阶 $\\|\\boldsymbol{\\alpha}\\|_{1} \\le p$。\n- 评估：无噪声。\n- 设计矩阵：假定在代数上可能的情况下具有满列秩。\n- 第一个目标：推导所需的最小模拟次数 $N_{\\min}(d,p)$。\n- 第二个目标：讨论 PCE 与高斯过程 (GP) 模拟器在样本复杂度和计算成本方面的权衡，重点关注随 $d$ 和 $p$ 的扩展情况以及对不确定性量化的影响。\n\n### 步骤 2：使用提取的已知条件进行验证\n根据验证标准评估问题：\n- **科学依据**：该问题在数值宇宙学、不确定性量化和机器学习领域有充分的依据。多项式混沌展开和高斯过程是用于模拟复杂计算机模型的标准、最先进的技术。其数学表述是正确和标准的。\n- **适定性**：问题是适定的。第一部分要求在清晰且充分的假设下推导特定量 $N_{\\min}(d,p)$。设计矩阵具有满列秩的条件是使寻找最小点数问题可解的关键。第二部分要求基于既定原则进行定性但有理有据的讨论，这是一个明确定义的任务。\n- **客观性**：问题以精确、客观和技术性的语言陈述，没有歧义或主观论断。\n- **完整性和一致性**：问题提供了进行推导所需的所有必要信息和定义。这些假设（例如，总阶截断、线性回归、满秩矩阵）是自洽的，并且足以进行推导。\n- **可行性和现实性**：所描述的场景是构建代理模型的一个标准（尽管是理想化的）设置。它是该领域的一个基本问题。\n\n问题陈述没有验证清单中列出的任何缺陷。它在科学上是合理的、适定的、客观的，并且是形式上指定的。\n\n### 步骤 3：结论和行动\n问题是**有效的**。将推导解答。\n\n### $N_{\\min}(d,p)$ 的推导\n\n多项式混沌展开 (PCE) 代理模型 $\\hat{y}(\\boldsymbol{\\theta})$ 近似真实模型输出 $y(\\boldsymbol{\\theta})$。给定指定的截断方案，该展开包括所有多元多项式 $\\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta})$，其中多重指标 $\\boldsymbol{\\alpha} = (\\alpha_1, \\alpha_2, \\ldots, \\alpha_d) \\in \\mathbb{N}_0^d$ 满足其 $L_1$-范数（总阶）最多为 $p$ 的条件：\n$$ \\hat{y}(\\boldsymbol{\\theta}) = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}} c_{\\boldsymbol{\\alpha}} \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta}) \\quad \\text{其中} \\quad \\mathcal{A} = \\left\\{ \\boldsymbol{\\alpha} \\in \\mathbb{N}_0^d : \\|\\boldsymbol{\\alpha}\\|_1 = \\sum_{i=1}^d \\alpha_i \\le p \\right\\} $$\n待确定的未知量是系数 $\\{c_{\\boldsymbol{\\alpha}}\\}_{\\boldsymbol{\\alpha} \\in \\mathcal{A}}$。为了找到唯一确定这些系数所需的最小模拟次数，我们必须首先找出这些系数的总数。令这个数为 $K = |\\mathcal{A}|$。\n\n寻找 $K$ 是一个组合问题：计算不等式 $\\alpha_1 + \\alpha_2 + \\ldots + \\alpha_d \\le p$ 的非负整数解的数量。通过引入一个非负松弛变量 $s$，我们可以将这个不等式转换成一个等式：\n$$ \\alpha_1 + \\alpha_2 + \\ldots + \\alpha_d + s = p $$\n这是一个经典的“隔板法”问题。我们要求的是将 $p$ 个（“星星”）分配到 $d+1$ 个非负整数箱（变量 $\\alpha_1, \\ldots, \\alpha_d, s$）中的方法数。这等价于排列 $p$ 个星星和 $(d+1)-1 = d$ 个隔板。总的排列方式数，即解的数量，由二项式系数给出：\n$$ K = \\binom{p + (d+1) - 1}{(d+1) - 1} = \\binom{p+d}{d} $$\n所以，有 $K = \\binom{p+d}{d}$ 个系数待确定。\n\n这些系数是通过对 $N$ 次模拟运行结果进行非侵入式线性回归来找到的。我们有 $N$ 个输入-输出对 $(\\boldsymbol{\\theta}_j, y_j)$，其中 $j=1, \\ldots, N$。这就建立了一个包含 $N$ 个线性方程的方程组：\n$$ y_j = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}} c_{\\boldsymbol{\\alpha}} \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta}_j), \\quad j=1, \\ldots, N $$\n这可以写成矩阵形式 $\\mathbf{y} = \\mathbf{\\Psi c}$，其中：\n- $\\mathbf{y}$ 是观测到的模拟输出的 $N \\times 1$ 列向量。\n- $\\mathbf{c}$ 是未知 PCE 系数的 $K \\times 1$ 列向量。\n- $\\mathbf{\\Psi}$ 是 $N \\times K$ 的设计矩阵，其元素为 $\\Psi_{j, \\boldsymbol{\\alpha}} = \\Psi_{\\boldsymbol{\\alpha}}(\\boldsymbol{\\theta}_j)$。\n\n要使系数向量 $\\mathbf{c}$ 被“唯一识别”，线性方程组 $\\mathbf{y} = \\mathbf{\\Psi c}$ 必须有唯一解。线性代数的一个基本结果表明，对于一个 $N \\times K$ 的系统，$\\mathbf{c}$ 存在唯一解的充分必要条件是矩阵 $\\mathbf{\\Psi}$ 具有满列秩，这要求行数大于或等于列数，即 $N \\ge K$。如果 $N  K$，系统是欠定的，$\\mathbf{c}$ 有无穷多解。\n\n问题陈述要求假设设计（点 $\\boldsymbol{\\theta}_j$ 的选择）使得 $\\mathbf{\\Psi}$ 在代数上可能的情况下具有满列秩。使满列秩成为可能的最小 $N$ 值是 $N=K$。因此，唯一确定所有 $K$ 个系数所需的最小模拟次数是：\n$$ N_{\\min}(d, p) = K = \\binom{p+d}{d} $$\n\n### PCE 与 GP 模拟器权衡的讨论\n\n在此，我们讨论（如上设计的）多项式混沌展开与高斯过程模拟器之间的权衡。\n\n**样本复杂度与扩展性：**\n\n- **PCE：** 样本复杂度由模型结构严格确定。如上推导，最小样本数为 $N_{\\min} = \\binom{p+d}{d}$。对于固定的多项式阶数 $p$，当维度 $d$ 很大时，该数随维度 $d$ 多项式增长，即 $N_{\\min} \\propto d^p$。对于固定的维度 $d$，当阶数 $p$ 很大时，它随阶数 $p$ 多项式增长，即 $N_{\\min} \\propto p^d$。这种快速增长通常被称为“维度灾难”，使得总阶 PCE 对于中等维度（$d \\gtrsim 10$）和阶数（$p \\gtrsim 3$）的问题也不切实际，因为所需的高保真度模拟次数变得过大。\n- **GP：** GP 没有基于其结构参数的样本数 $N$ 的硬性下限。一个 GP 模型可以用任意数量的点 $N > 0$ 来构建。模拟器的质量（例如，其准确性）随着 $N$ 的增加而提高。然而，GP 也遭受维度灾难之苦，因为参数空间体积随 $d$ 呈指数增长。为了保持给定的采样密度，$N$ 必须呈指数增长，这意味着在高维空间中，对于固定的 $N$，数据点变得非常稀疏。这会降低标准平稳核（例如，平方指数核）的性能，这些核可能难以学习远距离点之间的相关性。\n\n**计算成本：**\n\n- **PCE：** 通过线性回归拟合 PCE 的主要计算成本是求解正规方程 $(\\mathbf{\\Psi}^T \\mathbf{\\Psi}) \\mathbf{c} = \\mathbf{\\Psi}^T \\mathbf{y}$。这涉及对 $K \\times K$ 矩阵 $\\mathbf{\\Psi}^T \\mathbf{\\Psi}$ 求逆，其计算复杂度为 $O(K^3)$，其中 $K = \\binom{p+d}{d}$。因此，训练成本随维度 $d$ 和阶数 $p$ 急剧增加。然而，一旦系数 $\\mathbf{c}$ 被计算出来，进行新的预测就非常快，仅涉及评估一个包含 $K$ 项的多项式和，其计算复杂度为 $O(K)$。\n- **GP：** 训练标准 GP 的主要计算成本是对训练数据的 $N \\times N$ 协方差矩阵求逆，其计算复杂度为 $O(N^3)$。此成本取决于训练点的数量 $N$，而不直接取决于维度 $d$。对于大数据集（$N \\gg 1000$），这成为主要瓶颈。对新点的预测需要矩阵-向量运算，均值的计算复杂度为 $O(N)$，方差的计算复杂度为 $O(N^2)$。因此，GP 预测的计算成本比 PCE 预测更高。\n\n**对不确定性量化 (UQ) 的影响：**\n\n- **PCE：** 在所描述的非侵入式回归设置中，PCE 提供了一个确定性的点估计 $\\hat{y}(\\boldsymbol{\\theta})$。它本身不提供对其自身预测（认知）不确定性的度量。要量化对 PCE 模型本身的置信度，需要使用外部方法，如自举法 (bootstrapping) 或交叉验证。然而，PCE 擅长传播*输入*（偶然）不确定性。如果输入参数 $\\boldsymbol{\\theta}$ 由一个概率分布描述，那么多项式基的标准正交性允许对输出 $\\hat{y}$ 的统计矩（例如，均值、方差）进行解析计算。方差就是系数（不包括常数项）的平方和，即 $\\text{Var}[\\hat{y}] = \\sum_{\\boldsymbol{\\alpha} \\in \\mathcal{A}, \\boldsymbol{\\alpha} \\neq \\mathbf{0}} c_{\\boldsymbol{\\alpha}}^2$。\n- **GP：** UQ 是 GP 框架的一个原生和主要特征。GP 是一个概率模型，它为任何新的输入点 $\\boldsymbol{\\theta}_{\\text{new}}$ 返回一个完整的后验预测分布（一个高斯分布）。该分布由一个预测均值（模拟结果）和一个预测方差来表征。这个方差是对认知不确定性的度量，在训练数据稀疏的参数空间区域中，该不确定性自然会增加。这使得 GP 在主动学习或贝叶斯优化等需要对参数空间进行有原则探索的应用中特别强大。\n\n总而言之，PCE 和 GP 之间的选择涉及一个权衡：一边是 PCE 的刚性、全局结构，它在高维下有严格的样本要求但预测速度快；另一边是 GP 的灵活、非参数性质，它具有内置的 UQ 功能，但对于大的 $N$ 计算成本高。", "answer": "$$\\boxed{\\binom{p+d}{d}}$$", "id": "3478376"}, {"introduction": "在理论上理解样本复杂度的基础上，本次实践将引入一种更实用、数据驱动的方法来规划模拟活动。我们将利用经验学习曲线——它模拟了模拟器误差如何随训练数据量的增加而减小——来确定达到目标精度所需的最佳模拟次数[@problem_id:3478390]。这是规划昂贵计算模拟活动时的一项核心任务。", "problem": "您的任务是设计一个完整、可运行的程序，该程序使用经验学习曲线来确定宇宙学可观测量的机器学习模拟器的最优拉丁超立方采样大小，并验证跨可观测量和参数空间维度的缩放行为。背景设定为高等研究生水平的数值宇宙学，程序必须基于第一性原理对学习曲线进行原则性建模。\n\n考虑一个维度为 $d$ 的参数向量 $\\theta \\in \\mathbb{R}^d$，以及一个针对宇宙学可观测量 $O$ 的模拟器，该模拟器在大小为 $N$ 的拉丁超立方设计上进行训练。在许多情况下，对于在行为良好的宇宙学响应面上使用平滑核函数构建的模拟器，其泛化误差可以建模为设计有效填充距离 $h$ 的幂律。对于 $d$ 维拉丁超立方采样，$h$ 的缩放关系为 $h \\propto N^{-1/d}$。在平滑性假设以及核回归器和高斯过程模拟器经过充分检验的收敛性质下，可观测量 $O$ 的模拟器误差可以通过以下学习曲线来建模\n$$\n\\epsilon_O(N; d) \\approx \\epsilon_{\\mathrm{floor}}(O) + c(O)\\, N^{-\\alpha_O(d)},\n$$\n其中 $c(O)  0$ 是一个常数，反映了 $O$ 的校准难度，$\\epsilon_{\\mathrm{floor}}(O) \\ge 0$ 是由数值噪声和模型失配导致的不可约误差下限，而 $\\alpha_O(d)  0$ 是一个有效指数，捕捉了平滑性和维度效应。所有误差 $\\epsilon$ 都是无量纲的。\n\n对于此问题，您将使用合成但物理上合理的经验学习曲线，这些曲线是根据上述模型构建的，并带有一个小的确定性扰动，以模拟轻微的异方差性。对于每个可观测量 $O \\in \\{\\mathrm{Pk}, \\mathrm{Cl}, \\mathrm{B}\\}$ 和维度 $d \\in \\{3,5,8\\}$，在训练样本大小为 $N \\in \\{32, 64, 128, 256, 512\\}$ 时的经验误差值由下式给出\n$$\n\\epsilon_O(N; d) = \\epsilon_{\\mathrm{floor}}(O) + c(O)\\, N^{-\\alpha_O(d)} + 0.0005 \\frac{d}{N},\n$$\n其可观测量特定的常数为\n$$\nc(\\mathrm{Pk}) = 0.8,\\quad \\epsilon_{\\mathrm{floor}}(\\mathrm{Pk}) = 0.008,\n$$\n$$\nc(\\mathrm{Cl}) = 0.5,\\quad \\epsilon_{\\mathrm{floor}}(\\mathrm{Cl}) = 0.006,\n$$\n$$\nc(\\mathrm{B}) = 1.2,\\quad \\epsilon_{\\mathrm{floor}}(\\mathrm{B}) = 0.015,\n$$\n以及依赖于维度的指数为\n$$\n\\alpha_{\\mathrm{Pk}}(d) = \\frac{0.6}{1 + 0.08 d},\\quad\n\\alpha_{\\mathrm{Cl}}(d) = \\frac{0.75}{1 + 0.05 d},\\quad\n\\alpha_{\\mathrm{B}}(d) = \\frac{0.55}{1 + 0.10 d}.\n$$\n\n您的程序必须：\n1. 对于每个请求的可观测量 $O$ 和维度 $d$，将 $N \\in \\{32,64,128,256,512\\}$ 时的上述值视为经验学习曲线数据，并使用非线性最小二乘法拟合模型\n$$\n\\hat{\\epsilon}_O(N; d) = \\hat{\\epsilon}_{\\mathrm{floor}}(O,d) + \\hat{c}(O,d)\\, N^{-\\hat{\\alpha}(O,d)}\n$$\n以从经验数据中估计 $\\hat{\\epsilon}_{\\mathrm{floor}}(O,d)$、$\\hat{c}(O,d)$ 和 $\\hat{\\alpha}(O,d)$。拟合必须遵守物理约束条件 $\\hat{\\epsilon}_{\\mathrm{floor}} \\ge 0$、$\\hat{c}  0$ 和 $\\hat{\\alpha}  0$。\n\n2. 给定一个目标误差阈值 $\\epsilon_{\\mathrm{target}}  0$，从第一性原理推导出所需的最小拉丁超立方大小 $N_{\\mathrm{opt}}(O,d;\\epsilon_{\\mathrm{target}})$，使得拟合的学习曲线满足 $\\hat{\\epsilon}_O(N_{\\mathrm{opt}}; d) \\le \\epsilon_{\\mathrm{target}}$。推导应使用拟合的模型和样本大小为整数的规则，如果 $\\epsilon_{\\mathrm{target}}  \\hat{\\epsilon}_{\\mathrm{floor}}(O,d)$，则返回\n$$\nN_{\\mathrm{opt}}(O,d;\\epsilon_{\\mathrm{target}}) =\n\\left\\lceil \\left( \\frac{\\hat{c}(O,d)}{\\epsilon_{\\mathrm{target}} - \\hat{\\epsilon}_{\\mathrm{floor}}(O,d)} \\right)^{1/\\hat{\\alpha}(O,d)} \\right\\rceil,\n$$\n如果 $\\epsilon_{\\mathrm{target}} \\le \\hat{\\epsilon}_{\\mathrm{floor}}(O,d)$，则返回 $\\infty$。\n\n3. 使用拟合的参数和推断出的最优大小，验证跨可观测量和维度的缩放行为。具体来说，检查对于固定的可观测量和 $\\epsilon_{\\mathrm{target}}$，$N_{\\mathrm{opt}}$ 是否随 $d$ 增加（反映了维度灾难），在固定的 $d$ 和 $\\epsilon_{\\mathrm{target}}$ 下，更平滑的可观测量是否需要更少的样本，以及对于更粗糙的可观测量，拟合的 $\\hat{\\alpha}(O,d)$ 是否随 $d$ 减小。\n\n实现并运行以下测试套件。对于每个测试用例，计算所要求的量，并将所有结果汇总到如下指定的单行输出中。\n\n- 测试用例 1 (正常路径): 计算 $N_{\\mathrm{opt}}(\\mathrm{Pk}, d=5; \\epsilon_{\\mathrm{target}}=0.02)$ 并返回整数。\n- 测试用例 2 (接近不可约误差下限的边界条件): 计算 $N_{\\mathrm{opt}}(\\mathrm{Pk}, d=5; \\epsilon_{\\mathrm{target}}=0.0060)$ 并返回结果；如果不可能，则返回 $\\infty$。\n- 测试用例 3 (备用可观测量，较低维度): 计算 $N_{\\mathrm{opt}}(\\mathrm{Cl}, d=3; \\epsilon_{\\mathrm{target}}=0.015)$ 并返回整数。\n- 测试用例 4 (粗糙可观测量，高维度): 计算 $N_{\\mathrm{opt}}(\\mathrm{B}, d=8; \\epsilon_{\\mathrm{target}}=0.03)$ 并返回整数。\n- 测试用例 5 (维度缩放验证): 对于 $\\mathrm{Pk}$ 且 $\\epsilon_{\\mathrm{target}}=0.02$，检查是否 $N_{\\mathrm{opt}}(d=8)  N_{\\mathrm{opt}}(d=3)$ 并返回一个布尔值。\n- 测试用例 6 (跨可观测量缩放验证): 在 $d=5$ 和 $\\epsilon_{\\mathrm{target}}=0.02$ 下，检查是否 $N_{\\mathrm{opt}}(\\mathrm{Cl})  N_{\\mathrm{opt}}(\\mathrm{Pk})$ 并返回一个布尔值。\n- 测试用例 7 (粗糙可观测量指数缩放验证): 检查是否 $\\hat{\\alpha}(\\mathrm{B}, d=8)  \\hat{\\alpha}(\\mathrm{B}, d=3)$ 并返回一个布尔值。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，“[result1,result2,result3,result4,result5,result6,result7]”）。结果必须与上述测试用例的顺序完全一致。所有结果必须是基本类型：整数、浮点数或布尔值。如果最优大小为无穷大，请使用编程语言中无穷大的表示法输出 \"inf\"。", "solution": "该问题要求设计一个程序，以确定宇宙学中机器学习模拟器的最优训练集大小。这通过将参数化学习曲线模型拟合到综合生成的数据，然后使用拟合后的模型计算达到指定误差阈值所需的样本大小来实现。解决方案分为三个主要步骤：数据生成、模型拟合和最优大小计算。\n\n首先，我们为每个宇宙学可观测量 $O \\in \\{\\mathrm{Pk}, \\mathrm{Cl}, \\mathrm{B}\\}$、参数空间维度 $d \\in \\{3, 5, 8\\}$ 以及一系列训练集大小 $N \\in \\{32, 64, 128, 256, 512\\}$，生成模拟器误差 $\\epsilon_O(N; d)$ 的合成“经验”数据。数据根据问题中指定的模型生成：\n$$\n\\epsilon_O(N; d) = \\epsilon_{\\mathrm{floor}}(O) + c(O)\\, N^{-\\alpha_O(d)} + 0.0005 \\frac{d}{N}\n$$\n可观测量特定的常数 $c(O)$ 和 $\\epsilon_{\\mathrm{floor}}(O)$ 以及依赖于维度的指数 $\\alpha_O(d)$ 由问题陈述中的定义给出。该公式模拟了一条真实的学习曲线，其具有主导的幂律衰减、不可约的误差下限，以及一个引入轻微异方差性和模型失配的小扰动项。\n\n其次，对于每一对可观测量 $O$ 和维度 $d$，我们将一个三参数学习曲线模型拟合到生成的数据点上。需要拟合的模型是：\n$$\n\\hat{\\epsilon}_O(N; d) = \\hat{\\epsilon}_{\\mathrm{floor}}(O,d) + \\hat{c}(O,d)\\, N^{-\\hat{\\alpha}(O,d)}\n$$\n待估计的参数是误差下限 $\\hat{\\epsilon}_{\\mathrm{floor}}(O,d)$、振幅 $\\hat{c}(O,d)$ 和收敛指数 $\\hat{\\alpha}(O,d)$。此估计使用非线性最小二乘法执行，这是一种将参数模型拟合到数据的标准技术。为确保模型的物理可行性，拟合过程强制执行约束条件 $\\hat{\\epsilon}_{\\mathrm{floor}} \\ge 0$、$\\hat{c}  0$ 和 $\\hat{\\alpha}  0$。这是通过使用 `scipy.optimize.curve_fit` 函数并为参数设置适当的边界来实现的。为了提高拟合的稳定性和准确性，我们提供了基于生成数据的真实值的参数初始猜测。\n\n第三，一旦针对给定的 $(O, d)$ 对估计出模型参数 $(\\hat{\\epsilon}_{\\mathrm{floor}}, \\hat{c}, \\hat{\\alpha})$，我们就可以计算达到目标误差 $\\epsilon_{\\mathrm{target}}$ 所需的最小样本大小 $N_{\\mathrm{opt}}$。这由不等式推导得出：\n$$\n\\hat{\\epsilon}_O(N_{\\mathrm{opt}}; d) \\le \\epsilon_{\\mathrm{target}}\n$$\n代入拟合的模型，我们得到：\n$$\n\\hat{\\epsilon}_{\\mathrm{floor}} + \\hat{c}\\, N_{\\mathrm{opt}}^{-\\hat{\\alpha}} \\le \\epsilon_{\\mathrm{target}}\n$$\n只有当目标误差大于不可约误差下限时，$N_{\\mathrm{opt}}$ 的解才存在，即 $\\epsilon_{\\mathrm{target}}  \\hat{\\epsilon}_{\\mathrm{floor}}$。如果不满足此条件，则目标误差无法实现，所需的样本大小实际上是无穷大，我们记为 $\\infty$。如果 $\\epsilon_{\\mathrm{target}}  \\hat{\\epsilon}_{\\mathrm{floor}}$，我们求解 $N_{\\mathrm{opt}}$：\n$$\n\\hat{c}\\, N_{\\mathrm{opt}}^{-\\hat{\\alpha}} \\le \\epsilon_{\\mathrm{target}} - \\hat{\\epsilon}_{\\mathrm{floor}}\n$$\n$$\nN_{\\mathrm{opt}}^{-\\hat{\\alpha}} \\le \\frac{\\epsilon_{\\mathrm{target}} - \\hat{\\epsilon}_{\\mathrm{floor}}}{\\hat{c}}\n$$\n由于 $N  0$ 和 $\\hat{\\alpha}  0$，我们可以将两边同时取 $-1/\\hat{\\alpha}$ 次幂，这会反转不等号：\n$$\nN_{\\mathrm{opt}} \\ge \\left( \\frac{\\hat{c}}{\\epsilon_{\\mathrm{target}} - \\hat{\\epsilon}_{\\mathrm{floor}}} \\right)^{1/\\hat{\\alpha}}\n$$\n最小样本大小必须是整数。因此，我们取右侧的向上取整（ceiling），以找到满足条件的最小整数 $N$：\n$$\nN_{\\mathrm{opt}}(O,d;\\epsilon_{\\mathrm{target}}) = \\left\\lceil \\left( \\frac{\\hat{c}(O,d)}{\\epsilon_{\\mathrm{target}} - \\hat{\\epsilon}_{\\mathrm{floor}}(O,d)} \\right)^{1/\\hat{\\alpha}(O,d)} \\right\\rceil\n$$\n这个基于第一性原理的推导为程序的核心计算提供了基础。程序实现了整个工作流程——数据生成、拟合和计算——并将其应用于指定的测试用例。为了高效处理对同一 $(O, d)$ 对的多次请求，拟合的参数被缓存起来。验证测试用例涉及比较计算出的 $N_{\\mathrm{opt}}$ 值或拟合的 $\\hat{\\alpha}$ 参数在不同维度和可观测量上的表现，以验证预期的缩放行为，例如维度灾难。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.optimize import curve_fit\n\ndef solve():\n    \"\"\"\n    Computes optimal Latin hypercube sample sizes for cosmological emulators\n    by fitting learning curves and evaluating a series of test cases.\n    \"\"\"\n    # Define constants and functions from the problem statement.\n    CONSTANTS = {\n        'Pk': {'c': 0.8, 'eps_floor': 0.008},\n        'Cl': {'c': 0.5, 'eps_floor': 0.006},\n        'B':  {'c': 1.2, 'eps_floor': 0.015},\n    }\n\n    ALPHA_FUNCS = {\n        'Pk': lambda d: 0.6 / (1.0 + 0.08 * d),\n        'Cl': lambda d: 0.75 / (1.0 + 0.05 * d),\n        'B':  lambda d: 0.55 / (1.0 + 0.10 * d),\n    }\n\n    N_VALUES = np.array([32, 64, 128, 256, 512], dtype=float)\n\n    # Cache for fitted parameters to avoid re-computation\n    fitted_params_cache = {}\n\n    def generate_empirical_data(observable, dimension):\n        \"\"\"Generates synthetic error data based on the provided model.\"\"\"\n        c = CONSTANTS[observable]['c']\n        eps_floor = CONSTANTS[observable]['eps_floor']\n        alpha = ALPHA_FUNCS[observable](dimension)\n        \n        # The given model for \"empirical\" data with a small perturbation\n        errors = eps_floor + c * N_VALUES**(-alpha) + 0.0005 * dimension / N_VALUES\n        return N_VALUES, errors\n\n    def fitting_model(N, eps_floor_hat, c_hat, alpha_hat):\n        \"\"\"The parametric model to be fitted to the data.\"\"\"\n        return eps_floor_hat + c_hat * N**(-alpha_hat)\n\n    def get_fitted_params(observable, dimension):\n        \"\"\"\n        Fits the learning curve model to the synthetic data for a given \n        observable and dimension. Caches the results.\n        \"\"\"\n        if (observable, dimension) in fitted_params_cache:\n            return fitted_params_cache[(observable, dimension)]\n\n        N_data, error_data = generate_empirical_data(observable, dimension)\n        \n        # Initial guess for the parameters using the true values to aid convergence\n        p0_guess = [\n            CONSTANTS[observable]['eps_floor'],\n            CONSTANTS[observable]['c'],\n            ALPHA_FUNCS[observable](dimension)\n        ]\n        \n        # Bounds for parameters: eps_floor >= 0, c > 0, alpha > 0\n        # A small positive lower bound is used for strict positivity.\n        bounds = ([0.0, 1e-9, 1e-9], [np.inf, np.inf, np.inf])\n        \n        popt, _ = curve_fit(fitting_model, N_data, error_data, p0=p0_guess, bounds=bounds)\n        \n        fitted_params_cache[(observable, dimension)] = popt\n        return popt\n\n    def calculate_N_opt(observable, dimension, epsilon_target):\n        \"\"\"\n        Calculates the optimal sample size N_opt for a given target error.\n        \"\"\"\n        eps_floor_hat, c_hat, alpha_hat = get_fitted_params(observable, dimension)\n        \n        if epsilon_target = eps_floor_hat:\n            return np.inf\n        \n        base = c_hat / (epsilon_target - eps_floor_hat)\n        exponent = 1.0 / alpha_hat\n        N_val = base**exponent\n        \n        # Sample size must be an integer.\n        return int(np.ceil(N_val))\n\n    results = []\n\n    # Test case 1: Happy path\n    results.append(calculate_N_opt('Pk', 5, 0.02))\n\n    # Test case 2: Boundary condition near the irreducible floor\n    # The fitted floor for Pk,d=5 is ~0.008. 0.006 is below it.\n    results.append(calculate_N_opt('Pk', 5, 0.0060))\n\n    # Test case 3: Alternate observable, lower dimension\n    results.append(calculate_N_opt('Cl', 3, 0.015))\n\n    # Test case 4: Rough observable, high dimension\n    results.append(calculate_N_opt('B', 8, 0.03))\n\n    # Test case 5: Dimension scaling validation\n    N_opt_pk_d8 = calculate_N_opt('Pk', 8, 0.02)\n    N_opt_pk_d3 = calculate_N_opt('Pk', 3, 0.02)\n    results.append(N_opt_pk_d8 > N_opt_pk_d3)\n\n    # Test case 6: Cross-observable scaling validation\n    N_opt_cl_d5 = calculate_N_opt('Cl', 5, 0.02)\n    N_opt_pk_d5 = calculate_N_opt('Pk', 5, 0.02) # Value is cached from case 1\n    results.append(N_opt_cl_d5  N_opt_pk_d5)\n\n    # Test case 7: Exponent scaling validation for rough observable\n    _, _, alpha_b_d8 = get_fitted_params('B', 8)\n    _, _, alpha_b_d3 = get_fitted_params('B', 3)\n    results.append(alpha_b_d8  alpha_b_d3)\n\n    # Format the final output string as per requirements\n    # Special handling for 'inf'\n    final_results = []\n    for res in results:\n        if res == np.inf:\n            final_results.append(\"inf\")\n        elif isinstance(res, bool):\n            final_results.append(str(res).lower())\n        else:\n            final_results.append(str(res))\n\n    print(f\"[{','.join(final_results)}]\")\n\nsolve()\n```", "id": "3478390"}, {"introduction": "当我们完成了模拟活动的设计并训练好模拟器后，最后一个关键步骤是可靠地评估其性能。这个练习旨在解决当训练数据不满足独立同分布（i.i.d.）假设时（这在宇宙学中很常见）的验证难题[@problem_id:3478357]。它专注于设计统计上稳健的交叉验证方案，以避免对误差产生过于乐观的估计。", "problem": "您正在构建一个机器学习模拟器，用于模拟以宇宙学参数矢量 $\\boldsymbol{\\theta} \\in \\mathbb{R}^6$ 为条件的物质功率谱 $P(k)$，该矢量的分量为 $\\boldsymbol{\\theta} = (\\Omega_{\\mathrm{m}}, \\Omega_{\\mathrm{b}}, h, n_{\\mathrm{s}}, \\sigma_8, w_0)$。该模拟器在一个固定的波数网格 $k$ 上提供输出 $\\mathbf{y}(\\boldsymbol{\\theta}) \\in \\mathbb{R}^M$。训练设计由 $N = 120$ 次模拟组成，由于采用了两阶段设计，这些模拟在参数空间中被安排成 $C = 10$ 个聚类：8个密集聚类围绕一个基准区域，以及2个位于极端位置的探索性聚类。每个聚类包含 $12$ 个点。距离是在马氏度量（Mahalanobis metric）下测量的，该度量相对于一个正定矩阵 $\\mathbf{\\Sigma}^{-1}$（例如，一个受费雪信息启发的度量），因此两个参数点之间的距离为\n$$\nd_{\\mathrm{M}}(\\boldsymbol{\\theta}, \\boldsymbol{\\theta}') = \\sqrt{(\\boldsymbol{\\theta} - \\boldsymbol{\\theta}')^\\top \\mathbf{\\Sigma}^{-1} (\\boldsymbol{\\theta} - \\boldsymbol{\\theta}')}.\n$$\n在每个聚类内部，对于某个相关长度 $\\ell$，所有成对距离都满足 $d_{\\mathrm{M}}(\\boldsymbol{\\theta}_i, \\boldsymbol{\\theta}_j) \\le \\ell/2$；而在聚类之间，$d_{\\mathrm{M}}(\\boldsymbol{\\theta}_i, \\boldsymbol{\\theta}_j) \\ge \\ell$。您可以假设模拟器输出在尺度 $\\gtrsim \\ell$ 上关于 $\\boldsymbol{\\theta}$ 是平滑的，因此聚类内部的输出是强相关的。\n\n您的目标是估计和比较模拟器（例如，高斯过程（GP）或神经网络（NN））的泛化性能。该性能是相对于一个目标先验密度 $\\pi(\\boldsymbol{\\theta})$ 来衡量的，此密度不等于生成模拟器输入的设计密度 $q(\\boldsymbol{\\theta})$。设目标风险为\n$$\nR = \\mathbb{E}_{\\boldsymbol{\\theta} \\sim \\pi}\\left[ L\\!\\left(\\widehat{\\mathbf{y}}(\\boldsymbol{\\theta}), \\mathbf{y}(\\boldsymbol{\\theta})\\right) \\right],\n$$\n对于一个固定的非负损失 $L(\\cdot,\\cdot)$，其中 $\\widehat{\\mathbf{y}}(\\boldsymbol{\\theta})$ 是模拟器的预测。您需要一个评估方案（包括训练/验证/测试集划分和一个$K$折交叉验证程序），该方案能够产生$R$的低偏差估计，并支持可靠的超参数选择，同时适当地考虑到聚类设计以及$\\pi \\neq q$的情况。\n\n下列哪种评估设计在统计上对该目的是合理的？请选择所有适用项。\n\n- A. 随机将$N = 120$个点划分为80个训练点、20个验证点和20个测试点，划分在点级别上进行（忽略聚类成员关系）。在100个非测试点上执行标准的$K = 10$逐点K折交叉验证来选择超参数，并报告在20个留出测试点上均等平均的测试损失作为$R$的估计。\n\n- B. 预先保留$T = 2$个完整聚类作为测试集，选择这些聚类以近似$\\pi(\\boldsymbol{\\theta})$下的高概率质量区域。在剩下的$C - T = 8$个聚类上，执行分组K折交叉验证，其中折由整个聚类构成（即，没有聚类被跨折分割）。在验证折内使用重要性权重$w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$，通过最小化加权验证损失来选择超参数。使用选定的超参数在所有$C - T$个训练聚类上重新训练，并报告在2个留出聚类上的重要性加权测试损失作为$R$的估计。\n\n- C. 对所有$C = 10$个聚类执行留一聚类交叉验证，使用交叉验证损失（在聚类间均等平均）来选择超参数并报告最终性能。不创建单独的测试集，也不使用重要性权重。\n\n- D. 构建一个距离分块K折交叉验证，通过将点分配到折中，使得对于一个折中的任何验证点$\\boldsymbol{\\theta}_v$，其对应的训练集中的所有训练点$\\boldsymbol{\\theta}_t$都满足$d_{\\mathrm{M}}(\\boldsymbol{\\theta}_v, \\boldsymbol{\\theta}_t) \\ge \\ell$。选择$K$以使每个折包含参数空间中的连续区域，而不是许多聚类的碎片。在验证折内使用重要性权重$w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$进行超参数选择。对于最终测试，留出2个空间上连续的聚类或区域，使其与所有训练/验证点的距离满足$d_{\\mathrm{M}} \\ge \\ell$，并报告在此测试集上的重要性加权损失。\n\n- E. 将$N = 120$个点根据$\\sigma_8$和$w_0$的值进行分层，忽略其他参数和聚类标签。在分层内执行逐点的$K = 10$分层K折交叉验证，通过未加权的验证损失选择超参数，并使用一个逐点抽取的随机20点测试集来报告未加权的测试损失。\n\n- F. 从2个探索性聚类中过采样验证点，以使每个折具有来自所有聚类的相同数量的点。通过平均各折的未加权损失来选择超参数，使用选定的超参数在所有$N = 120$个点上重新训练，并报告未加权的交叉验证损失作为最终估计，不使用单独的测试集。\n\n答案选项可以是多个。请通过诉诸风险估计、可交换性和聚类设计引起的依赖性的第一性原理来证明您的选择，而不是通过启发式规则。", "solution": "该问题要求为机器学习模拟器设计一个统计上合理的评估方案。该方案必须产生目标风险 $R = \\mathbb{E}_{\\boldsymbol{\\theta} \\sim \\pi}\\left[ L\\!\\left(\\widehat{\\mathbf{y}}(\\boldsymbol{\\theta}), \\mathbf{y}(\\boldsymbol{\\theta})\\right) \\right]$ 的低偏差估计，并能够进行可靠的超参数选择。一个合理的方案必须解决三个主要的统计挑战：\n\n1.  **数据中的依赖性**：训练点不是独立同分布（i.i.d.）的。它们被组织成 $C=10$ 个不同的聚类。在每个聚类内部，点是接近的（$d_{\\mathrm{M}} \\le \\ell/2$），并且模拟器输出 $\\mathbf{y}(\\boldsymbol{\\theta})$ 是平滑的，这意味着邻近点的输出之间存在强相关性。在聚类之间，点是良好分离的（$d_{\\mathrm{M}} \\ge \\ell$）。一种朴素的逐点随机划分到训练集和验证/测试集的方法，会将高度相关的点同时置于划分的两侧。这使得模型能够在验证/测试集上获得人为的低误差，从而导致对真实泛化误差的乐观偏倚（即低估）的评估。可交换性的基本假设在点级别上被违反，但在聚类级别上成立。因此，任何数据划分（用于交叉验证或用于最终测试集）都必须在整个聚类的级别上进行，或者更一般地，通过尊重相关性结构的参数空间中的空间区块来进行。这确保了验证/测试数据在训练期间对模型来说是真正“未见过”的。\n\n2.  **分布不匹配**：训练数据点 $\\{\\boldsymbol{\\theta}_i\\}$ 是从一个设计密度 $q(\\boldsymbol{\\theta})$ 生成的，但目标风险 $R$ 是相对于一个不同的目标密度 $\\pi(\\boldsymbol{\\theta})$ 定义的。对从 $q(\\boldsymbol{\\theta})$ 抽取的点集上的损失进行未加权经验平均，提供的是 $\\mathbb{E}_{\\boldsymbol{\\theta} \\sim q}[L]$ 的估计，而不是 $\\mathbb{E}_{\\boldsymbol{\\theta} \\sim \\pi}[L]$。为了获得目标风险 $R$ 的低偏差估计，必须使用重要性采样。验证集或测试集中每个点 $\\boldsymbol{\\theta}_i$ 的损失必须通过重要性权重 $w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$ 进行加权。重要性加权的风险估计是 $\\hat{R}_{\\mathrm{IW}} = \\frac{\\sum_i w_i L_i}{\\sum_i w_i}$，如果点是从 $q(\\boldsymbol{\\theta})$ 中抽取的，那么它就是 $R$ 的一个无偏估计量。\n\n3.  **无偏性能估计**：超参数选择涉及在验证数据上多次训练和评估模型。因此，所选的超参数是适应于验证数据的。如果使用相同的数据报告最终性能（例如，直接报告交叉验证得分），估计将会有乐观偏差。为了获得*最终选定模型*的泛化性能的真正无偏估计，至关重要的是在一个在训练或超参数选择过程中完全未被使用过的留出测试集上对其进行评估。\n\n基于这些原则，一个统计上合理的方案必须：\n- 对所有交叉验证和测试集创建使用分组/分块划分。\n- 在验证集和测试集上都使用重要性加权。\n- 保留一个独立的留出测试集用于最终性能评估。\n\n现在我们根据这些标准评估每个选项。\n\n- **A. 随机将$N = 120$个点划分为80个训练点、20个验证点和20个测试点，划分在点级别上进行（忽略聚类成员关系）。在100个非测试点上执行标准的$K = 10$逐点K折交叉验证来选择超参数，并报告在20个留出测试点上均等平均的测试损失作为$R$的估计。**\n\n这个方案在两个关键方面失败了。首先，通过执行逐点划分（“忽略聚类成员关系”），它保证了验证集和测试集将包含与训练集高度相关的点。这会导致对真实泛化误差的低估。其次，通过使用未加权的平均损失（“均等平均”），它估计的是关于设计密度 $q(\\boldsymbol{\\theta})$ 的风险，而不是目标密度 $\\pi(\\boldsymbol{\\theta})$，从而导致对 $R$ 的有偏估计。\n\n**结论：** 错误。\n\n- **B. 预先保留$T = 2$个完整聚类作为测试集，选择这些聚类以近似$\\pi(\\boldsymbol{\\theta})$下的高概率质量区域。在剩下的$C - T = 8$个聚类上，执行分组K折交叉验证，其中折由整个聚类构成（即，没有聚类被跨折分割）。在验证折内使用重要性权重$w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$，通过最小化加权验证损失来选择超参数。使用选定的超参数在所有$C - T$个训练聚类上重新训练，并报告在2个留出聚类上的重要性加权测试损失作为$R$的估计。**\n\n这个方案正确地解决了所有三个挑战。\n1.  **依赖性：** 它对测试集（“保留$T=2$个完整聚类”）和交叉验证（“分组K折交叉验证，其中折由整个聚类构成”）都使用了基于聚类的划分。这尊重了数据的相关性结构。\n2.  **分布不匹配：** 它正确地使用了重要性权重（“使用重要性权重 $w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$”）来进行超参数选择和最终风险估计。\n3.  **无偏估计：** 它使用了一个在超参数调整期间未被触及的、独立的留出测试集。整个流程（划分测试集，用CV选择超参数，重新训练，在测试集上评估）是标准的最佳实践。\n\n**结论：** 正确。\n\n- **C. 对所有$C = 10$个聚类执行留一聚类交叉验证，使用交叉验证损失（在聚类间均等平均）来选择超参数并报告最终性能。不创建单独的测试集，也不使用重要性权重。**\n\n这个方案有两个主要缺陷。首先，它使用相同的交叉验证程序来选择超参数和报告最终性能。这会引入乐观偏差，因为超参数是为了优化这个特定指标而被选择的。一个独立的留出测试集是获得无偏最终估计所必需的。其次，它不使用重要性权重，因此它估计了错误的量（$\\mathbb{E}_q[L]$ 而不是 $\\mathbb{E}_{\\pi}[L]$）。尽管留一聚类交叉验证正确地处理了数据依赖性，但其他缺陷使得该程序对于所述目标是不合理的。\n\n**结论：** 错误。\n\n- **D. 构建一个距离分块K折交叉验证，通过将点分配到折中，使得对于一个折中的任何验证点$\\boldsymbol{\\theta}_v$，其对应的训练集中的所有训练点$\\boldsymbol{\\theta}_t$都满足$d_{\\mathrm{M}}(\\boldsymbol{\\theta}_v, \\boldsymbol{\\theta}_t) \\ge \\ell$。选择$K$以使每个折包含参数空间中的连续区域，而不是许多聚类的碎片。在验证折内使用重要性权重$w_i \\propto \\pi(\\boldsymbol{\\theta}_i)/q(\\boldsymbol{\\theta}_i)$进行超参数选择。对于最终测试，留出2个空间上连续的聚类或区域，使其与所有训练/验证点的距离满足$d_{\\mathrm{M}} \\ge \\ell$，并报告在此测试集上的重要性加权损失。**\n\n这个方案是与选项B中相同原则的一个更通用、更严谨的实现。\n1.  **依赖性：** 它直接使用距离度量来强制训练集和验证/测试集之间的分离（$d_{\\mathrm{M}} \\ge \\ell$）。这是处理空间相关数据的第一性原理方法，而基于聚类的划分是其一个特例。\n2.  **分布不匹配：** 它正确地使用了重要性权重来进行超参数选择和最终评估。\n3.  **无偏估计：** 它正确地使用了一个留出测试集（“留出2个空间上连续的聚类或区域”），该测试集与训练数据保持了所需的空间分离。\n\n这种设计在统计上是合理且稳健的。\n\n**结论：** 正确。\n\n- **E. 将$N = 120$个点根据$\\sigma_8$和$w_0$的值进行分层，忽略其他参数和聚类标签。在分层内执行逐点的$K = 10$分层K折交叉验证，通过未加权的验证损失选择超参数，并使用一个逐点抽取的随机20点测试集来报告未加权的测试损失。**\n\n这个方案是有缺陷的。在参数的一个子集上进行分层并不能解决由完整$6$维参数空间中的聚类引起的主要相关性问题。通过忽略聚类标签并执行逐点划分，它遭受了与选项A相同的乐观偏差。此外，它没有使用重要性权重，导致对目标风险 $R$ 的有偏估计。\n\n**结论：** 错误。\n\n- **F. 从2个探索性聚类中过采样验证点，以使每个折具有来自所有聚类的相同数量的点。通过平均各折的未加权损失来选择超参数，使用选定的超参数在所有$N = 120$个点上重新训练，并报告未加权的交叉验证损失作为最终估计，不使用单独的测试集。**\n\n这个方案基于多重理由是不合理的。首先，它不使用单独的测试集，将CV损失作为最终估计报告，这是有偏的。其次，提议的划分方案（“每个折具有来自所有聚类的相同数量的点”）需要打散聚类，这违反了在划分过程中保持相关数据组完整的原则。第三，它使用未加权的损失，未能解决分布不匹配的问题。过采样是一种特设程序，不像重要性加权那样是基于原则的方法。\n\n**结论：** 错误。\n\n综上所述，选项B和D都描述了统计上合理的方法，它们正确地解决了数据依赖性、分布偏移以及对无偏性能估计的需求。", "answer": "$$\\boxed{BD}$$", "id": "3478357"}]}