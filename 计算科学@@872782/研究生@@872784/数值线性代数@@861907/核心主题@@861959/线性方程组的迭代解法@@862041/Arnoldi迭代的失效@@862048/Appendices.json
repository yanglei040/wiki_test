{"hands_on_practices": [{"introduction": "要真正掌握阿诺德迭代，没有什么比亲手进行一次计算更有效了。本练习旨在通过一个具体的例子，让您一步步执行阿诺德迭代过程。您将直接体验到格兰-施密特正交化是如何构建克雷洛夫子空间的标准正交基的，并从第一性原理出发，观察当克雷洛夫子空间成为一个 $A$-不变子空间时，算法是如何自然地发生“幸运”分解（即 $h_{k+1,k}=0$）的。", "problem": "考虑在实数上进行精确算术的 Arnoldi 迭代，应用于给定的矩阵-向量对\n$$\nA \\;=\\; \\begin{pmatrix}\n2  1  0  0\\\\\n0  2  1  0\\\\\n0  0  2  0\\\\\n0  0  0  5\n\\end{pmatrix}, \n\\qquad\nv_{1} \\;=\\; \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix}.\n$$\n使用标准的欧几里得内积。从 Arnoldi 过程的基本定义（即序列 $A q_{j}$ 对先前构造的标准正交向量进行重复的 Gram-Schmidt 正交化）出发，显式地构造前 3 个 Arnoldi 步骤，生成 $q_{1}$、$q_{2}$、$q_{3}$ 以及当 $1 \\le i \\le j+1 \\le 4$ 时的上 Hessenberg 元素 $h_{i,j}$。将得到的 $4 \\times 3$ Arnoldi 矩阵记为 $\\bar{H}_{3} = (h_{i,j})$。判断在第 3 步是否发生崩溃 (breakdown)，并根据由 $v_{1}$ 生成的 Krylov 子空间在 $A$ 作用下的不变性，从第一性原理证明你的结论。最后，以精确形式报告单个标量 $h_{4,3}$。不需要四舍五入，也不涉及单位。你的最终答案必须是这个单一的实数。", "solution": "Arnoldi 迭代是为 Krylov 子空间 $\\mathcal{K}_{k}(A, v_{1}) = \\text{span}\\{v_{1}, Av_{1}, \\dots, A^{k-1}v_{1}\\}$ 构建一个标准正交基 $\\{q_{1}, q_{2}, \\dots, q_{k}\\}$ 的过程。该过程首先将初始向量 $v_{1}$ 标准化以获得 $q_{1}$。然后，对于随后的每一步 $j=1, 2, \\dots$，使用 Gram-Schmidt 过程将向量 $Aq_{j}$ 与先前构造的标准正交向量 $\\{q_{1}, \\dots, q_{j}\\}$ 进行正交化。\n\n该算法定义如下：\n1. 初始化 $q_{1} = v_{1} / \\|v_{1}\\|_{2}$。\n2. 对于 $j=1, 2, \\dots$：\n    a. 计算候选向量 $w = Aq_{j}$。\n    b. 对于 $i=1, \\dots, j$，计算 Hessenberg 矩阵元素 $h_{i,j} = q_{i}^{T}w$ 并更新候选向量 $w \\leftarrow w - h_{i,j}q_{i}$。\n    c. 计算下一个次对角线元素 $h_{j+1,j} = \\|w\\|_{2}$。\n    d. 如果 $h_{j+1,j} = 0$，算法发生崩溃 (breakdown)。终止。\n    e. 否则，计算下一个基向量 $q_{j+1} = w / h_{j+1,j}$。\n\n我们给定了矩阵 $A$ 和起始向量 $v_{1}$：\n$$A = \\begin{pmatrix} 2  1  0  0\\\\ 0  2  1  0\\\\ 0  0  2  0\\\\ 0  0  0  5 \\end{pmatrix}, \\qquad v_{1} = \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix}.$$\n我们使用标准的欧几里得内积，因此 $q_{i}^{T}q_{j} = \\delta_{ij}$。\n\n**第1步：初始化**\n首先，我们对起始向量 $v_{1}$ 进行标准化。\n$v_{1}$ 的范数为 $\\|v_{1}\\|_{2} = \\sqrt{1^{2} + 1^{2} + 1^{2} + 0^{2}} = \\sqrt{3}$。\n第一个 Arnoldi 向量是：\n$$q_{1} = \\frac{v_{1}}{\\|v_{1}\\|_{2}} = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix}.$$\n\n**Arnoldi 迭代，第 $j=1$ 步**\n我们计算 $w = Aq_{1}$：\n$$w = A q_{1} = \\begin{pmatrix} 2  1  0  0\\\\ 0  2  1  0\\\\ 0  0  2  0\\\\ 0  0  0  5 \\end{pmatrix} \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 2(1)+1(1) \\\\ 2(1)+1(1) \\\\ 2(1) \\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{3}} \\begin{pmatrix} 3\\\\ 3\\\\ 2\\\\ 0 \\end{pmatrix}.$$\n接下来，我们将 $w$ 对 $q_{1}$ 进行正交化：\n$$h_{1,1} = q_{1}^{T}w = \\left(\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1  1  1  0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 3\\\\ 3\\\\ 2\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{3}(3+3+2) = \\frac{8}{3}.$$\n残差向量为 $w_{res} = w - h_{1,1}q_{1}$：\n$$w_{res} = \\frac{1}{\\sqrt{3}}\\begin{pmatrix} 3\\\\ 3\\\\ 2\\\\ 0 \\end{pmatrix} - \\frac{8}{3} \\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} = \\frac{1}{3\\sqrt{3}}\\left(\\begin{pmatrix} 9\\\\ 9\\\\ 6\\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 8\\\\ 8\\\\ 8\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{3\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix}.$$\n次对角线元素为 $h_{2,1} = \\|w_{res}\\|_{2}$：\n$$h_{2,1} = \\left\\|\\frac{1}{3\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix}\\right\\|_{2} = \\frac{1}{3\\sqrt{3}}\\sqrt{1^2+1^2+(-2)^2} = \\frac{\\sqrt{6}}{3\\sqrt{3}} = \\frac{\\sqrt{2}\\sqrt{3}}{3\\sqrt{3}} = \\frac{\\sqrt{2}}{3}.$$\n由于 $h_{2,1} \\neq 0$，我们进行标准化以求得 $q_{2}$：\n$$q_{2} = \\frac{w_{res}}{h_{2,1}} = \\frac{\\frac{1}{3\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix}}{\\frac{\\sqrt{2}}{3}} = \\frac{1}{\\sqrt{2}\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix}.$$\n\n**Arnoldi 迭代，第 $j=2$ 步**\n我们计算 $w = Aq_{2}$：\n$$w = A q_{2} = \\begin{pmatrix} 2  1  0  0\\\\ 0  2  1  0\\\\ 0  0  2  0\\\\ 0  0  0  5 \\end{pmatrix} \\frac{1}{\\sqrt{6}} \\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{6}} \\begin{pmatrix} 2(1)+1(1) \\\\ 2(1)+1(-2) \\\\ 2(-2) \\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{6}} \\begin{pmatrix} 3\\\\ 0\\\\ -4\\\\ 0 \\end{pmatrix}.$$\n我们将 $w$ 对 $q_{1}$ 和 $q_{2}$ 进行正交化：\n$$h_{1,2} = q_{1}^{T}w = \\left(\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1  1  1  0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 3\\\\ 0\\\\ -4\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{\\sqrt{18}}(3-4) = \\frac{-1}{3\\sqrt{2}} = -\\frac{\\sqrt{2}}{6}.$$\n$$h_{2,2} = q_{2}^{T}w = \\left(\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1  1  -2  0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 3\\\\ 0\\\\ -4\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{6}(3+8) = \\frac{11}{6}.$$\n残差向量为 $w_{res} = w - h_{1,2}q_{1} - h_{2,2}q_{2}$：\n$$w_{res} = \\frac{1}{\\sqrt{6}}\\begin{pmatrix} 3\\\\ 0\\\\ -4\\\\ 0 \\end{pmatrix} - \\left(-\\frac{1}{3\\sqrt{2}}\\right)\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} - \\frac{11}{6}\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} = \\frac{1}{6\\sqrt{6}}\\left[6\\begin{pmatrix} 3\\\\ 0\\\\ -4\\\\ 0 \\end{pmatrix} + \\frac{6\\sqrt{6}}{3\\sqrt{2}\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} - 11\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix}\\right]$$\n$$w_{res} = \\frac{1}{6\\sqrt{6}}\\left[\\begin{pmatrix} 18\\\\ 0\\\\ -24\\\\ 0 \\end{pmatrix} + \\begin{pmatrix} 2\\\\ 2\\\\ 2\\\\ 0 \\end{pmatrix} - \\begin{pmatrix} 11\\\\ 11\\\\ -22\\\\ 0 \\end{pmatrix}\\right] = \\frac{1}{6\\sqrt{6}}\\begin{pmatrix} 9\\\\ -9\\\\ 0\\\\ 0 \\end{pmatrix} = \\frac{9}{6\\sqrt{6}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix} = \\frac{3}{2\\sqrt{6}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}.$$\n次对角线元素为 $h_{3,2} = \\|w_{res}\\|_{2}$：\n$$h_{3,2} = \\left\\|\\frac{3}{2\\sqrt{6}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}\\right\\|_{2} = \\frac{3}{2\\sqrt{6}}\\sqrt{1^2+(-1)^2} = \\frac{3\\sqrt{2}}{2\\sqrt{6}} = \\frac{3}{2\\sqrt{3}} = \\frac{\\sqrt{3}}{2}.$$\n由于 $h_{3,2} \\neq 0$，我们进行标准化以求得 $q_{3}$：\n$$q_{3} = \\frac{w_{res}}{h_{3,2}} = \\frac{\\frac{3}{2\\sqrt{6}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}}{\\frac{\\sqrt{3}}{2}} = \\frac{3}{2\\sqrt{6}}\\frac{2}{\\sqrt{3}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix} = \\frac{3}{\\sqrt{18}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}.$$\n\n**Arnoldi 迭代，第 $j=3$ 步**\n我们计算 $w = Aq_{3}$：\n$$w = A q_{3} = \\begin{pmatrix} 2  1  0  0\\\\ 0  2  1  0\\\\ 0  0  2  0\\\\ 0  0  0  5 \\end{pmatrix} \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 2(1)+1(-1) \\\\ 2(-1) \\\\ 0 \\\\ 0 \\end{pmatrix} = \\frac{1}{\\sqrt{2}} \\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix}.$$\n我们将 $w$ 对 $q_{1}, q_{2}, q_{3}$ 进行正交化：\n$$h_{1,3} = q_{1}^{T}w = \\left(\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1  1  1  0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{\\sqrt{6}}(1-2) = -\\frac{1}{\\sqrt{6}} = -\\frac{\\sqrt{6}}{6}.$$\n$$h_{2,3} = q_{2}^{T}w = \\left(\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1  1  -2  0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{\\sqrt{12}}(1-2) = -\\frac{1}{2\\sqrt{3}} = -\\frac{\\sqrt{3}}{6}.$$\n$$h_{3,3} = q_{3}^{T}w = \\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1  -1  0  0 \\end{pmatrix}\\right) \\left(\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix}\\right) = \\frac{1}{2}(1+2) = \\frac{3}{2}.$$\n残差向量为 $w_{res} = w - h_{1,3}q_{1} - h_{2,3}q_{2} - h_{3,3}q_{3}$：\n$$w_{res} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix} - \\left(-\\frac{1}{\\sqrt{6}}\\right)\\frac{1}{\\sqrt{3}}\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} - \\left(-\\frac{1}{2\\sqrt{3}}\\right)\\frac{1}{\\sqrt{6}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} - \\frac{3}{2}\\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}$$\n$$w_{res} = \\frac{1}{\\sqrt{2}}\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix} + \\frac{1}{3\\sqrt{2}}\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} + \\frac{1}{6\\sqrt{2}}\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} - \\frac{3}{2\\sqrt{2}}\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix}$$\n$$w_{res} = \\frac{1}{6\\sqrt{2}} \\left[ 6\\begin{pmatrix} 1\\\\ -2\\\\ 0\\\\ 0 \\end{pmatrix} + 2\\begin{pmatrix} 1\\\\ 1\\\\ 1\\\\ 0 \\end{pmatrix} + 1\\begin{pmatrix} 1\\\\ 1\\\\ -2\\\\ 0 \\end{pmatrix} - 9\\begin{pmatrix} 1\\\\ -1\\\\ 0\\\\ 0 \\end{pmatrix} \\right]$$\n$$w_{res} = \\frac{1}{6\\sqrt{2}} \\begin{pmatrix} 6+2+1-9 \\\\ -12+2+1+9 \\\\ 2-2 \\\\ 0 \\end{pmatrix} = \\frac{1}{6\\sqrt{2}} \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.$$\n次对角线元素为 $h_{4,3} = \\|w_{res}\\|_{2}$：\n$$h_{4,3} = \\left\\|\\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}\\right\\|_{2} = 0.$$\n由于 $h_{4,3} = 0$，在第 $j=3$ 步发生崩溃 (breakdown)。矩阵 $\\bar{H}_{3}$ 为：\n$$ \\bar{H}_{3} = \\begin{pmatrix} h_{1,1} & h_{1,2} & h_{1,3} \\\\ h_{2,1} & h_{2,2} & h_{2,3} \\\\ 0 & h_{3,2} & h_{3,3} \\\\ 0 & 0 & h_{4,3} \\end{pmatrix} = \\begin{pmatrix} 8/3 & -\\sqrt{2}/6 & -\\sqrt{6}/6 \\\\ \\sqrt{2}/3 & 11/6 & -\\sqrt{3}/6 \\\\ 0 & \\sqrt{3}/2 & 3/2 \\\\ 0 & 0 & 0 \\end{pmatrix}. $$\n\n**关于崩溃 (Breakdown) 的证明**\nArnoldi 迭代在第 $j$ 步的崩溃（即 $h_{j+1,j}=0$）等价于 Krylov 子空间 $\\mathcal{K}_{j}(A, v_{1})$ 是 $A$ 的一个不变子空间。也就是说，$A\\mathcal{K}_{j}(A, v_{1}) \\subseteq \\mathcal{K}_{j}(A, v_{1})$。在这里，崩溃发生在 $j=3$。我们必须证明 $\\mathcal{K}_{3}(A, v_{1})$ 是一个不变子空间。\n\n矩阵 $A$ 是块上三角矩阵：\n$$A = \\begin{pmatrix} A_{11} & 0 \\\\ 0 & A_{22} \\end{pmatrix} \\text{ 其中 } A_{11} = \\begin{pmatrix} 2 & 1 & 0 \\\\ 0 & 2 & 1 \\\\ 0 & 0 & 2 \\end{pmatrix} \\text{ 且 } A_{22} = (5).$$\n子空间 $S = \\text{span}\\{e_{1}, e_{2}, e_{3}\\}$（其中 $e_i$ 是标准基向量）是 $A$ 的一个不变子空间。$S$ 中的任意向量 $v = (x, y, z, 0)^{T}$ 映射为 $Av = (2x+y, 2y+z, 2z, 0)^{T}$，该向量也在 $S$ 中。\n起始向量 $v_{1} = (1, 1, 1, 0)^{T}$ 位于这个 3 维不变子空间 $S$ 中。因此，整个 Krylov 序列 $\\{v_{1}, Av_{1}, A^{2}v_{1}, \\dots\\}$ 必须保持在 $S$ 内。\nArnoldi 迭代为递增的 Krylov 子空间 $\\mathcal{K}_{k}(A, v_{1})$ 构建标准正交基。由于整个序列被限制在 3 维子空间 $S$ 中，Krylov 子空间的维数不能超过 3。向量 $\\{v_{1}, Av_{1}, A^{2}v_{1}\\}$ 是线性无关的，所以 $\\dim(\\mathcal{K}_{3}(A, v_{1})) = 3$。这意味着 $\\mathcal{K}_{3}(A, v_{1}) = S$。\n\n因为 $\\mathcal{K}_{3}(A, v_{1}) = S$ 是一个不变子空间，对于任何向量 $u \\in \\mathcal{K}_{3}(A, v_{1})$，向量 $Au$ 也必须在 $\\mathcal{K}_{3}(A, v_{1})$ 中。Arnoldi 向量 $q_{3}$ 在 $\\mathcal{K}_{3}(A, v_{1})$ 中，所以 $Aq_{3}$ 必须在 $\\mathcal{K}_{3}(A, v_{1}) = \\text{span}\\{q_{1}, q_{2}, q_{3}\\}$ 中。这意味着 $Aq_{3}$ 可以写成 $q_{1}, q_{2}, q_{3}$ 的线性组合。\nArnoldi 算法计算残差 $w_{res} = Aq_{3} - h_{1,3}q_{1} - h_{2,3}q_{2} - h_{3,3}q_{3}$。由于 $\\{q_{1}, q_{2}, q_{3}\\}$ 构成了包含 $Aq_{3}$ 的空间的标准正交基，这个残差是将 $Aq_{3}$ 投影到 $\\mathcal{K}_3(A, v_1)$ 的正交补空间上的结果，而这个结果必须是零向量。因此，$w_{res}=\\mathbf{0}$，这导致 $h_{4,3} = \\|w_{res}\\|_{2} = 0$。这从第一性原理上证实了崩溃的发生。\n\n所求的单个标量是 $h_{4,3}$。根据我们的计算，$h_{4,3}=0$。", "answer": "$$\\boxed{0}$$", "id": "3535501"}, {"introduction": "在理论中，阿诺德分解是一个定义明确的事件 ($h_{k+1,k}=0$)，但在有限精度的计算机上，真正的零值非常罕见。因此，实际的数值算法必须能够处理“近似分解”的情况。本练习要求您将阿诺德迭代算法转化为一个可运行的程序，并实现一个基于容差 $\\tau$ 的分解检测机制。通过一系列精心设计的测试用例，您将学会如何编写代码来处理各种情况，包括精确分解、近似分解以及不会发生分解的“常规”路径。", "problem": "设 $A \\in \\mathbb{R}^{n \\times n}$ 是一个非奇异矩阵， $v_1 \\in \\mathbb{R}^n$ 是一个非零初始向量。考虑 Krylov 子空间 $\\mathcal{K}_m(A, v_1) = \\operatorname{span}\\{v_1, A v_1, A^2 v_1, \\dots, A^{m-1} v_1\\}$、欧几里得内积 $\\langle x, y \\rangle = x^\\top y$ 和欧几里得范数 $\\|x\\|_2 = \\sqrt{x^\\top x}$。Arnoldi 迭代通过将 $A v_j$ 与先前构建的向量进行正交化，构建一个标准正交序列 $\\{v_1, v_2, \\dots, v_{m+1}\\}$ 和一个上 Hessenberg 矩阵 $\\bar{H}_m = (h_{i,j}) \\in \\mathbb{R}^{(m+1)\\times m}$：\n1. 初始化 $v_1 \\leftarrow v_1 / \\|v_1\\|_2$。\n2. 对每个满足 $1 \\le j \\le m$ 的整数 $j$：\n   - 计算 $w \\leftarrow A v_j$。\n   - 对 $i = 1, \\dots, j$，设 $h_{i,j} \\leftarrow \\langle v_i, w \\rangle$ 并更新 $w \\leftarrow w - h_{i,j} v_i$。\n   - 设 $h_{j+1,j} \\leftarrow \\|w\\|_2$。如果 $h_{j+1,j} = 0$，则在索引 $j$ 处发生精确崩溃。\n在进行数值计算时，当对于指定的绝对容差 $\\tau > 0$ 有 $h_{j+1,j} \\le \\tau$ 时，应检测到近乎崩溃。在这种情况下，Arnoldi 迭代将终止，并报告出现 $h_{j+1,j} \\le \\tau$ 的最早索引 $j$（$j \\le m$）。\n\n您的任务是编写一个完整、可运行的程序，该程序：\n- 使用修正的 Gram-Schmidt (MGS) 正交化实现 Arnoldi 迭代，以数值方式计算 $h_{j+1,j}$ 的值。\n- 对于给定的 $A$、$v_1$、步数限制 $m$ 和容差 $\\tau$，在最早的索引 $j$ 处检测到崩溃（其中 $h_{j+1,j} \\le \\tau$）。\n- 对于每个测试用例，返回一个列表，其中包含最早的崩溃索引 $j$（使用基于 1 的索引，如果所有步数 $j = 1, \\dots, \\min\\{m, n\\}$ 都未发生崩溃，则返回 $-1$），以及迭代终止前所有计算出的值 $[h_{2,1}, h_{3,2}, \\dots, h_{m+1,m}]$ 的列表。\n\n使用以下测试套件，它探讨了不同的行为：\n- 测试用例 1（通用正常路径，在 $m$ 步内不发生崩溃）：$A = \\operatorname{diag}(1, 2, 3, 4)$，$v_1 = [1, 0.5, -0.3, 0.7]^\\top$，$m = 3$，$\\tau = 10^{-14}$。矩阵是非奇异的，且步数限制低于环境维度。\n- 测试用例 2（在 $j = 1$ 时精确崩溃）：$A = \\operatorname{diag}(2, 3, 4, 5)$，$v_1 = [1, 0, 0, 0]^\\top$，$m = 4$，$\\tau = 10^{-14}$。这里 $v_1$ 是一个特征向量，所以 $h_{2,1}$ 精确为 $0$。\n- 测试用例 3（由于低维不变子空间，在 $j = 2$ 时精确崩溃）：$A = \\operatorname{diag}(2, 3, 5)$，$v_1 = [1, 1, 0]^\\top$，$m = 3$，$\\tau = 10^{-14}$。初始向量仅在两个特征向量上有支撑，因此 Krylov 子空间的维度在 $2$ 时饱和。\n- 测试用例 4（边界维度情况）：$A = [3]$，$v_1 = [1]^\\top$，$m = 1$，$\\tau = 10^{-12}$。该空间是一维的；预计在第一步就会发生崩溃。\n- 测试用例 5（由容差检测到近乎崩溃）：$A = \\operatorname{diag}(2, 2.0000001, 5)$，$v_1 = [1, 10^{-9}, 0]^\\top$，$m = 3$，$\\tau = 10^{-12}$。初始向量几乎是一个特征向量，使得 $h_{2,1}$ 极小。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含所有测试用例的结果，形式为方括号内以逗号分隔的列表。每个测试用例的结果必须是 $[j, [h_{2,1}, h_{3,2}, \\dots]]$ 形式的列表。例如，输出必须具有以下形式：\n$[[j_1, [\\dots]], [j_2, [\\dots]], \\dots]$，\n其中数值以标准 Python 浮点数和整数表示。", "solution": "实现用于检测崩溃的 Arnoldi 迭代这一问题是有效的。它在科学上基于数值线性代数的既定原理，问题设定良好，具有清晰的确定性算法，并使用精确的数学术语进行客观陈述。所提供的测试用例探索了该算法的一系列标准和边界情况行为，使该问题成为一个定义明确且具有一定难度的实现任务。\n\n解决方案将是一个 Python 程序，它为给定的矩阵 $A$、初始向量 $v_1$、最大步数 $m$ 和崩溃容差 $\\tau$ 实现 Arnoldi 迭代。该算法的核心是为递增的 $j$ 构建 Krylov 子空间 $\\mathcal{K}_j(A, v_1)$ 的标准正交基。该过程是迭代的，在每一步 $j$，它都会生成一个新的基向量 $v_{j+1}$，该向量与所有先前的向量 $\\{v_1, \\dots, v_j\\}$ 正交。\n\n算法流程如下：\n\n1.  **初始化**：将输入的初始向量 $v_1$ 标准化，使其欧几里得范数为 $1$。这个标准化后的向量，我们也称之为 $v_1$，成为我们标准正交基 $V$ 中的第一个向量。最大迭代次数由 $k_{max} = \\min(m, n)$ 决定，因为 Krylov 子空间的维度不能超过环境空间 $n$ 的维度。\n\n2.  **迭代**：对于从 $1$ 到 $k_{max}$ 的每一步 $j$：\n    a. 通过将矩阵 $A$ 应用于最新计算的基向量来生成一个新的候选向量，$w \\leftarrow A v_j$。\n    b. 然后使用修正的 Gram-Schmidt (MGS) 过程将此向量 $w$ 与所有现有的基向量 $\\{v_1, \\dots, v_j\\}$ 正交化。选择 MGS 是因为它比经典 Gram-Schmidt 具有更好的数值稳定性。在 MGS 过程中，对于从 $1$ 到 $j$ 的每个 $i$，我们计算当前 $w$ 在 $v_i$ 上的投影并立即减去它：\n    $$h_{i,j} \\leftarrow \\langle v_i, w \\rangle$$\n    $$w \\leftarrow w - h_{i,j} v_i$$\n    系数 $h_{i,j}$ 成为上 Hessenberg 矩阵 $H_m$ 的元素。\n\n3.  **崩溃检测**：将 $w$ 与所有 $i=1, \\dots, j$ 的 $v_i$ 正交化后，计算所得向量 $w$ 的欧几里得范数。此范数是 Hessenberg 矩阵的次对角线元素 $h_{j+1,j}$。\n    $$h_{j+1,j} \\leftarrow \\|w\\|_2$$\n    如果此值为零（精确崩溃）或非常小（近乎崩溃），则发生崩溃。终止条件是 $h_{j+1,j} \\le \\tau$。如果满足此条件，则迭代停止，并将当前步骤索引 $j$ 记录为崩溃索引。\n\n4.  **继续**：如果 $h_{j+1,j} > \\tau$，则未发生崩溃。通过对残差向量 $w$ 进行标准化来获得下一个标准正交基向量：\n    $$v_{j+1} \\leftarrow w / h_{j+1,j}$$\n    将这个新向量 $v_{j+1}$ 添加到基中，然后迭代进入下一步 $j+1$。\n\n5.  **终止和输出**：当在某个步骤 $j \\le k_{max}$ 检测到崩溃时，或者在完成所有 $k_{max}$ 步而未满足崩溃条件后，迭代终止。程序返回一个包含两个元素的列表：基于 1 的崩溃索引 $j$（如果未发生崩溃则为 $-1$）以及直到终止点所有计算出的次对角线 Hessenberg 元素 $[h_{2,1}, h_{3,2}, \\dots]$ 的列表。\n\n此过程将应用于问题陈述中提供的每个测试用例，结果将汇总为单个格式化的输出字符串。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite for Arnoldi iteration breakdown.\n    This function defines the test cases, invokes the Arnoldi iteration\n    implementation for each case, and prints the results in the required format.\n    \"\"\"\n\n    def perform_arnoldi_breakdown(A_raw, v1_raw, m, tau):\n        \"\"\"\n        Implements the Arnoldi iteration with Modified Gram-Schmidt to detect breakdown.\n\n        Args:\n            A_raw: The matrix A, as a list of lists or numpy array.\n            v1_raw: The starting vector v1, as a list or numpy array.\n            m: The integer step limit.\n            tau: The float absolute tolerance for near breakdown.\n\n        Returns:\n            A list containing the 1-based breakdown index (or -1 if no breakdown)\n            and the list of computed subdiagonal Hessenberg entries h_{j+1,j}.\n        \"\"\"\n        A = np.asarray(A_raw, dtype=np.float64)\n        n = A.shape[0]\n        v1 = np.asarray(v1_raw, dtype=np.float64).reshape(-1, 1)\n\n        norm_v1 = np.linalg.norm(v1)\n        if norm_v1 == 0:\n             return [-1, []] \n        v = v1 / norm_v1\n        \n        V = [v]\n        h_subdiagonal = []\n        breakdown_index = -1\n        \n        max_steps = min(m, n)\n        \n        if max_steps == 0:\n            return [-1, []]\n        \n        for j_prob in range(1, max_steps + 1):\n            j_code = j_prob - 1\n            \n            w = A @ V[j_code]\n\n            # Modified Gram-Schmidt for orthogonalization against V = {v_1, ..., v_j}\n            for i_code in range(j_code + 1):\n                v_i = V[i_code]\n                h_ij = (v_i.T @ w).item()\n                w = w - h_ij * v_i\n            \n            h_next = np.linalg.norm(w)\n            h_subdiagonal.append(h_next)\n\n            if h_next = tau:\n                breakdown_index = j_prob\n                break\n            \n            V.append(w / h_next)\n            \n        return [breakdown_index, h_subdiagonal]\n\n    test_cases_data = [\n        {'A': np.diag([1, 2, 3, 4]), 'v1': [1, 0.5, -0.3, 0.7], 'm': 3, 'tau': 1e-14},\n        {'A': np.diag([2, 3, 4, 5]), 'v1': [1, 0, 0, 0], 'm': 4, 'tau': 1e-14},\n        {'A': np.diag([2, 3, 5]), 'v1': [1, 1, 0], 'm': 3, 'tau': 1e-14},\n        {'A': np.array([[3]]), 'v1': [1], 'm': 1, 'tau': 1e-12},\n        {'A': np.diag([2, 2.0000001, 5]), 'v1': [1, 1e-9, 0], 'm': 3, 'tau': 1e-12},\n    ]\n\n    all_results = []\n    for case in test_cases_data:\n        result = perform_arnoldi_breakdown(case['A'], case['v1'], case['m'], case['tau'])\n        all_results.append(result)\n\n    print(str(all_results))\n\nsolve()\n```", "id": "3535509"}, {"introduction": "使用一个固定的容差来检测分解虽然简单，但并不可靠，因为它没有考虑问题的尺度（例如矩阵 $A$ 的范数）或计算过程中舍入误差的累积。一个更稳健的策略是使用一个“自适应”阈值，该阈值基于浮点运算的后向误差分析模型动态调整。这个高级练习挑战您设计并实现这样一个自适应分解检测器，并将其与朴素的固定阈值方法进行比较，从而深入理解数值稳定性在算法设计中的重要性。", "problem": "您的任务是在数值线性代数的背景下，为阿诺尔迪迭代设计和评估一个鲁棒的分解检测器。回想一下，对于一个实数矩阵，阿诺尔迪过程使用一个递归关系构建克雷洛夫子空间的一个标准正交基。在精确算术中，该过程产生一个形如 $$A V_k = V_{k+1} \\bar{H}_k,$$ 的因式分解，其中 $A \\in \\mathbb{R}^{n \\times n}$，$V_k \\in \\mathbb{R}^{n \\times k}$ 具有标准正交列，$\\bar{H}_k \\in \\mathbb{R}^{(k+1) \\times k}$ 是上海森伯格矩阵。量 $h_{k+1,k}$（$\\bar{H}_k$ 的第 $k$ 列的次对角线元素）等于残差向量 $w = A v_k - \\sum_{j=1}^{k} h_{j,k} v_j$ 在正交化后的欧几里得范数，其中 $v_k$ 是第 $k$ 个阿诺尔迪向量。在精确算术中，当且仅当 $h_{k+1,k} = 0$ 时，会发生分解（也称为幸运分解）。\n\n在遵循浮点算術標準（IEEE 754）的浮點運算中，計算出的量會受到捨入誤差的擾動。您将比较一个朴素的固定绝对阈值和一个由浮点运算的第一性原理后向误差模型提供的自适应阈值，以决定何时计算出的 $h_{k+1,k}$足够小以宣布分解。\n\n您的任务是实现一个程序，该程序：\n\n- 为一组指定的测试用例构造测试矩阵 $A$ 和初始向量 $v_1$。\n- 运行阿诺尔迪迭代，直至达到指定的最大迭代次数 $m$。\n- 实现两个分解检测器：\n  1. 一个朴素的固定绝对阈值检测器，如果在第 $k$ 步计算出的 $h_{k+1,k} \\le \\tau_{\\mathrm{fix}}$，则宣布分解，其中 $\\tau_{\\mathrm{fix}}$ 是一个指定的固定阈值。\n  2. 一个自适应检测器，它使用一个与迭代相关的阈值 $\\theta_k$ 在第 $k$ 步宣布分解。该阈值源自标准浮点误差模型和后向误差推理。自适应阈值必须是单位舍入 $u$、A 的矩阵范数、$A v_k$ 的范数以及第 $k$ 个阿诺尔迪列中已计算系数 $h_{1:k,k}$ 的范数的显式函数。使用一个正缩放常数 $c$ 来聚合这些贡献。自适应阈值必须是绝对的（而非相对的），并且除了所列参数外，不得依赖任何未知或问题特定的参数。常数 $c$ 必须取一个小的正整数。\n\n- 针对每个测试用例，根据基准真相评估检测决策，返回一个布尔值，指示该检测器在该用例中是否做出了正确的决策（true）或错误的决策（false）。一个正确的决策意味着：\n  - 如果精确算术中的真实阿诺尔迪过程在某个步骤 $k^\\star \\le m$ 出现分解，则检测器必须恰好在 $k^\\star$（首次）宣布分解，不能提前也不能推迟。\n  - 如果在 $k \\le m$ 时没有发生精确分解，则检测器不得在任何 $k \\le m$ 时宣布分解。\n\n在您的推导和实现中使用的基本依据：\n\n- 标准浮点模型：对于基本运算和内积，计算结果 $\\mathrm{fl}(\\cdot)$ 满足 $\\mathrm{fl}(x \\,\\circ\\, y) = (x \\,\\circ\\, y) (1 + \\delta)$，其中 $|\\delta| \\le u$，$u$ 是单位舍入（机器ε的一半），求和与内积会产生误差放大，其界限由浮点运算次数和 $u$ 决定。\n- 诱导矩阵范数和欧几里得向量范数的基本不等式。\n- 阿诺尔迪迭代和分解的定义关系。\n\n测试套件规范（请精确使用这些矩阵和参数）：\n\n对于每个测试用例，按如下方式构造 $A \\in \\mathbb{R}^{n \\times n}$ 和初始向量 $v_1 \\in \\mathbb{R}^n$ (其中 $\\|v_1\\|_2 = 1$）。\n\n- 对于在已知步骤发生精确分解的用例，使用一个分块对角矩阵\n  $$A = \\mathrm{diag}(S_\\varepsilon, I_{n-r}),$$\n  其中 $S_\\varepsilon \\in \\mathbb{R}^{r \\times r}$ 是通过取一个严格上移位矩阵 $S$（其第一超对角线元素为1，其余为0），并加上一个扰动 $\\varepsilon G$ 得到的，其中 $G$ 是一个具有独立标准正态分布条目的稠密矩阵。单位矩阵为 $I_{n-r}$。取初始向量为 $v_1 = e_1$（第一个标准基向量）。对于 $\\varepsilon = 0$，精确的阿诺尔迪过程必须在步骤 $k^\\star = r$ 分解，因为 $S$ 的幂零指数为 $r$，且从 $e_1$ 开始的克雷洛夫子空间的维度为 $r$。对于 $\\varepsilon \\ne 0$，在 $k \\le r$ 时没有精确分解。\n- 对于没有任何特殊结构的用例，通过对一个具有独立标准正态分布条目的随机稠密矩阵进行 $Q R$ 分解来构造一个正交矩阵 $A$；取 $A=Q$，并使用固定的伪随机种子。使用一个具有独立标准正态分布条目的初始向量，并将其归一化为单位欧几里得范数。\n\n使用以下带有其参数的具体测试用例：\n\n1. 用例A（理想情况下的精确分解）：$n = 40$, $r = 10$, $\\varepsilon = 0$, $m = 20$。任何随机性的种子：$123$。\n2. 用例B（接近分解，无精确分解）：$n = 40$, $r = 10$, $\\varepsilon = 10^{-14}$, $m = 20$。扰动 $G$ 的种子：$123$。\n3. 用例C（更大尺寸的精确分解）：$n = 200$, $r = 5$, $\\varepsilon = 0$, $m = 15$。种子：$7$。\n4. 用例D（无分解）：$n = 60$, $m = 25$。通过对种子为 $7$ 的稠密随机矩阵进行 $Q R$ 分解构造 $A$ 为 $Q$，并将种子为 $7$ 的随机向量归一化为单位欧几里得范数作为 $v_1$。\n5. 用例E（立即分解）：$n = 30$, $r = 1$, $\\varepsilon = 0$, $m = 5$。种子：$2024$。\n\n检测器参数：\n\n- 使用朴素的固定阈值 $\\tau_{\\mathrm{fix}} = 10^{-12}$。\n- 对于自适应阈值，推导并实现一个具体的绝对阈值 $\\theta_k$，该阈值依赖于单位舍入 $u$、A 的一个矩阵范数、$\\|A v_k\\|_2$ 和 $\\|h_{1:k,k}\\|_2$，并带有一个小的正整数缩放因子。矩阵范数使用谱范数。使用浮点算术标准（IEEE 754）的双精度单位舍入。\n\n程序要求：\n\n- 为每个测试用例实现无重启的阿诺尔迪迭代，最多 $m$ 步，在每一步中形成必要的内积和正交化以计算 $h_{k+1,k}$。\n- 对于每个测试用例，运行两个检测器，并记录一个布尔值，指示每个检测器相对于上述定义的基准真相是否做出了正确的决策。\n- 您的程序应生成单行输出，其中包含一个遵循Python列表语法的逗-号分隔的嵌套列表，该列表包含两个列表：第一个列表按顺序包含朴素检测器在五个测试用例上的布尔结果，第二个列表包含自适应检测器在相同五个测试用例上的布尔结果。例如，形如 “[[true,false,true,false,true],[true,true,true,true,true]]” 的输出将表示朴素检测器在用例1、3和5上是正确的，而自适应检测器在所有用例上都是正确的。使用Python布尔字面量。\n\n所有量均为无量纲；不涉及物理单位。不使用角度。所有随机性必须通过设置指定的种子来保证可复现。代码必须是自包含的，不得读取输入，也不得访问网络或任何外部文件。", "solution": "该问题要求为阿诺尔迪迭代设计和评估两种分解检测器。在精确算术中，当过程生成一个已经位于先前生成的克雷洛夫子空间基向量的生成空间中的向量时，就会发生分解，特别是“幸运分解”。这表现为上海森伯格矩阵 $\\bar{H}_k$ 的次对角线元素 $h_{k+1,k}$ 变为零。在浮点运算中，这个精确的零被一个由计算舍入误差引起的微小非零值所取代。任务是区分这种计算噪声与一个真正微小但非零的 $h_{k+1,k}$，后者表示接近分解但非精确分解。\n\n我们将首先使用修正的格拉姆-施密特（MGS）算法进行正交化来实现阿诺尔迪迭代。对于给定的矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 和单位范数的起始向量 $v_1$，该过程迭代地为克雷洛夫子空间 $\\mathcal{K}_m(A, v_1)$ 构建一个标准正交基 $\\{v_1, v_2, \\dots, v_m\\}$ 和一个矩阵 $\\bar{H}_m \\in \\mathbb{R}^{(m+1) \\times m}$。在每一步 $k$（对于 $k=1, \\dots, m$）：\n1. 计算一个新的候选向量：$w = A v_k$。\n2. 向量 $w$ 与现有基 $\\{v_1, \\dots, v_k\\}$ 正交化：$h_{j,k} = v_j^T w$ 且 $w \\leftarrow w - h_{j,k} v_j$ 对于 $j=1, \\dots, k$。\n3. 计算残差向量的范数：$h_{k+1,k} = \\|w\\|_2$。\n4. 如果 $h_{k+1,k}$ 非零，通过归一化得到下一个基向量：$v_{k+1} = w / h_{k+1,k}$。\n\n任务的核心是实现并比较两种策略，以决定计算出的 $h_{k+1,k}$ 是否在数值上等同于零。\n\n第一个检测器是使用固定绝对阈值 $\\tau_{\\mathrm{fix}}$ 的朴素方法。如果在第 $k$ 步计算出的 $h_{k+1,k} \\le \\tau_{\\mathrm{fix}}$，则宣布分解。对于此问题，我们使用 $\\tau_{\\mathrm{fix}} = 10^{-12}$。这种方法很简单但缺乏鲁棒性，因为合适的阈值会随着问题的尺度（例如，矩阵范数）和浮点精度而显著变化。\n\n第二个检测器是基于第一性原理浮点误差传播模型的自适应方法。其目标是推导出一个阈值 $\\theta_k$，当真实值为零时，该阈值可近似计算出的 $h_{k+1,k}$ 的量级。计算出的 $h_{k+1,k}$ 是一个向量的范数，在精确算术中，该向量本应是零向量。在浮点运算中，由于第 $k$ 个阿诺尔迪步骤中所有运算的舍入误差累积，该向量非零。\n\n为了构造自适应阈值 $\\theta_k$，我们遵循浮点算术标准（IEEE 754），考虑误差的主要来源，其中单位舍入为 $u$。\n1.  **矩阵向量乘法**：$\\mathrm{fl}(A v_k)$ 的计算会引入误差。一个标准的前向误差模型表明，误差范数与结果的范数成正比，即量级为 $u \\|A v_k\\|_2$。而后向误差的视角表明，误差与 $u \\|A\\|_2$ 成正比，这提供了一个更一致的界。\n2.  **修正的格拉姆-施密特正交化**：此阶段包括 $k$ 个内积和 $k$ 个向量更新（saxpy 操作）。每个操作都会带来微小的舍入误差。最终残差向量中的总累积误差取决于所涉及量的量级。计算出的系数 $h_{j,k}$ 是其中的核心。这些系数的范数 $\\|h_{1:k,k}\\|_2 = \\left(\\sum_{j=1}^k h_{j,k}^2\\right)^{1/2}$，提供了被减去的投影量级的一个度量。\n\n问题要求自适应阈值 $\\theta_k$ 是单位舍入 $u$、谱范数 $\\|A\\|_2$、$\\|A v_k\\|_2$ 和 $\\|h_{1:k,k}\\|_2$ 的显式函数。一个合理的模型聚合了这些贡献，以形成对预期噪声水平的综合界限。我们提出这些范数的一个线性组合，由单位舍入 $u$ 和一个小的正整数常量 $c$ 进行缩放：\n$$\n\\theta_k = c \\cdot u \\cdot \\left( \\|A\\|_2 + \\|A v_k\\|_2 + \\|h_{1:k,k}\\|_2 \\right)\n$$\n这种形式包括了来自算子整体尺度（$\\|A\\|_2$）、正交化前向量尺度（$\\|A v_k\\|_2$）以及向现有子空间投影尺度（$\\|h_{1:k,k}\\|_2$）的贡献。接近分解时，我们有 $\\|A v_k\\|_2 \\approx \\|h_{1:k,k}\\|_2$，但按照要求包含所有三项可提供鲁棒性。引入常数 $c$ 是为了考虑维度因子（例如，对 $n$ 和 $k$ 的依赖性）以及在严格误差界中通常存在的其他常数。我们选择 $c=10$，这是一个提供安全边际的小整数。对于双精度， $u = 2^{-53} \\approx 1.11 \\times 10^{-16}$。\n\n对每个检测器性能的评估基于其正确识别分解步骤的能力。对于每个测试用例，我们有一个基准真相的分解步骤 $k_{true}$。如果一个检测器首次宣布的分解步骤 $k_{det}$ 等于 $k_{true}$，则该检测器被认为是正确的。如果在最大 $m$ 次迭代内没有发生分解（即 $k_{true}  m$），则只有当检测器在任何步骤 $k \\le m$ 都没有宣布分解时，它才是正确的。这一点通过在未找到分解时设置 $k_{det}=m+1$ 并检查 $k_{det} = k_{true}$ 是否成立来强制执行。\n\n指定的测试用例旨在探究不同情景：精确分解（用例 A、C、E）、接近分解（用例 B）以及使用通用矩阵的无分解情况（用例 D）。通过将朴素检测器和自适应检测器的决策与这些用例的已知基准真相进行比较，我们可以客观地评估它们的有效性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Designs and evaluates a naive and an adaptive breakdown detector for the Arnoldi iteration.\n    The program implements the Arnoldi process, two breakdown detection strategies,\n    and evaluates them against a suite of specified test cases.\n    \"\"\"\n\n    test_cases = [\n        {'name': 'A', 'n': 40, 'r': 10, 'eps': 0.0, 'm': 20, 'seed': 123, 'k_true': 10},\n        {'name': 'B', 'n': 40, 'r': 10, 'eps': 1e-14, 'm': 20, 'seed': 123, 'k_true': 21},\n        {'name': 'C', 'n': 200, 'r': 5, 'eps': 0.0, 'm': 15, 'seed': 7, 'k_true': 5},\n        {'name': 'D', 'n': 60, 'r': None, 'eps': None, 'm': 25, 'seed': 7, 'k_true': 26},\n        {'name': 'E', 'n': 30, 'r': 1, 'eps': 0.0, 'm': 5, 'seed': 2024, 'k_true': 1},\n    ]\n\n    tau_fix = 1e-12\n    c_adaptive = 10\n    u = np.finfo(np.float64).eps / 2\n\n    naive_results = []\n    adaptive_results = []\n\n    for case in test_cases:\n        n, m, seed, k_true = case['n'], case['m'], case['seed'], case['k_true']\n        \n        rng = np.random.default_rng(seed)\n        \n        if case['name'] in ['A', 'B', 'C', 'E']:\n            r, eps = case['r'], case['eps']\n            S = np.diag(np.ones(r - 1), 1)\n            if eps > 0:\n                G = rng.standard_normal((r, r))\n                S_eps = S + eps * G\n            else:\n                S_eps = S\n            \n            A = np.zeros((n, n), dtype=np.float64)\n            A[:r, :r] = S_eps\n            if n > r:\n                A[r:, r:] = np.eye(n - r)\n            \n            v1 = np.zeros(n)\n            v1[0] = 1.0\n        else:\n            M = rng.standard_normal((n, n))\n            Q, _ = np.linalg.qr(M)\n            A = Q\n            b = rng.standard_normal(n)\n            v1 = b / np.linalg.norm(b)\n\n        k_naive_detected = m + 1\n        k_adaptive_detected = m + 1\n        \n        V = np.zeros((n, m + 1), dtype=np.float64)\n        H = np.zeros((m + 1, m), dtype=np.float64)\n        V[:, 0] = v1\n        \n        A_norm = np.linalg.norm(A, 2)\n        \n        naive_broken = False\n        adaptive_broken = False\n\n        for k in range(m):\n            w = A @ V[:, k]\n            Avk_norm = np.linalg.norm(w)\n            \n            for j in range(k + 1):\n                H[j, k] = V[:, j].T @ w\n                w = w - H[j, k] * V[:, j]\n            \n            h_k_plus_1_k = np.linalg.norm(w)\n            H[k + 1, k] = h_k_plus_1_k\n            \n            if not naive_broken and h_k_plus_1_k = tau_fix:\n                k_naive_detected = k + 1\n                naive_broken = True\n\n            if not adaptive_broken:\n                h_col_k_norm = np.linalg.norm(H[:k + 1, k])\n                theta_k = c_adaptive * u * (A_norm + Avk_norm + h_col_k_norm)\n                if h_k_plus_1_k = theta_k:\n                    k_adaptive_detected = k + 1\n                    adaptive_broken = True\n            \n            if h_k_plus_1_k > np.finfo(np.float64).tiny:\n                V[:, k + 1] = w / h_k_plus_1_k\n            else:\n                if not naive_broken: k_naive_detected = k + 1\n                if not adaptive_broken: k_adaptive_detected = k + 1\n                break\n\n        is_naive_correct = (k_naive_detected == k_true)\n        is_adaptive_correct = (k_adaptive_detected == k_true)\n        \n        naive_results.append(is_naive_correct)\n        adaptive_results.append(is_adaptive_correct)\n\n    naive_str = [str(r).lower() for r in naive_results]\n    adaptive_str = [str(r).lower() for r in adaptive_results]\n    \n    print(f\"[[{','.join(naive_str)}],[{','.join(adaptive_str)}]]\")\n\nsolve()\n```", "id": "3535484"}]}