{"hands_on_practices": [{"introduction": "理解一个算法最好的方式之一就是亲手执行它。这个练习将逆迭代法分解为最基本的一步，让我们能够一窥其内部工作机制。我们将使用一个简单的对角矩阵，通过单步迭代，清晰地观察该方法是如何放大与最小模特征值对应的特征向量分量的。这个基础计算将为我们理解更复杂的变体打下坚实的基础。", "problem": "考虑实对角矩阵 $A=\\mathrm{diag}(1,3,10)$ 和初始向量 $x_0=(1,1,1)^{\\top}$。一步无位移的反迭代过程为：首先求解线性系统 $A\\,y_1=x_0$，然后使用欧几里得范数 $\\|x\\|_2=(x^{\\top}x)^{1/2}$ 对结果进行归一化，得到 $x_1=y_1/\\|y_1\\|_2$。请仅使用反迭代的定义和瑞利商 $r(x)=(x^{\\top}A x)/(x^{\\top}x)$ 的定义来计算：\n- 归一化后的迭代向量 $x_1$，\n- 瑞利商 $r(x_1)$，\n- 并且，根据迭代的结构和计算出的 $x_1$，解释 $x_1$ 的哪个特征分量占主导地位及其原因。\n\n请以最简精确有理数的形式提供瑞利商。仅报告瑞利商作为你的最终数值答案；无需四舍五入。", "solution": "该问题要求计算与给定矩阵 $A$ 和初始向量 $x_0$ 的一步反迭代相关的三个量。我们将按顺序计算它们。\n\n首先，给定对角矩阵 $A$ 和初始向量 $x_0$：\n$$\nA = \\mathrm{diag}(1, 3, 10) = \\begin{pmatrix} 1  0  0 \\\\ 0  3  0 \\\\ 0  0  10 \\end{pmatrix}, \\quad x_0 = \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix}\n$$\n\n反迭代步骤的第一部分是求解线性系统 $A y_1 = x_0$ 以得到向量 $y_1$。由于 $A$ 是一个对角矩阵且其所有对角线元素都非零，因此它是可逆的。其逆矩阵 $A^{-1}$ 是由 $A$ 的对角线元素的倒数构成的对角矩阵：\n$$\nA^{-1} = \\mathrm{diag}\\left(\\frac{1}{1}, \\frac{1}{3}, \\frac{1}{10}\\right) = \\begin{pmatrix} 1  0  0 \\\\ 0  \\frac{1}{3}  0 \\\\ 0  0  \\frac{1}{10} \\end{pmatrix}\n$$\n我们现在可以通过计算 $y_1 = A^{-1} x_0$ 来求解 $y_1$：\n$$\ny_1 = \\begin{pmatrix} 1  0  0 \\\\ 0  \\frac{1}{3}  0 \\\\ 0  0  \\frac{1}{10} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\cdot 1 \\\\ \\frac{1}{3} \\cdot 1 \\\\ \\frac{1}{10} \\cdot 1 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ \\frac{1}{3} \\\\ \\frac{1}{10} \\end{pmatrix}\n$$\n\n迭代步骤的第二部分是使用欧几里得范数 $\\| \\cdot \\|_2$ 对 $y_1$ 进行归一化以得到 $x_1$。首先，我们计算 $y_1$ 的欧几里得范数的平方：\n$$\n\\|y_1\\|_2^2 = y_1^{\\top} y_1 = 1^2 + \\left(\\frac{1}{3}\\right)^2 + \\left(\\frac{1}{10}\\right)^2 = 1 + \\frac{1}{9} + \\frac{1}{100}\n$$\n为了对这些分数求和，我们找到一个公分母，即 $900$：\n$$\n\\|y_1\\|_2^2 = \\frac{900}{900} + \\frac{100}{900} + \\frac{9}{900} = \\frac{1009}{900}\n$$\n欧几里得范数是该值的平方根：\n$$\n\\|y_1\\|_2 = \\sqrt{\\frac{1009}{900}} = \\frac{\\sqrt{1009}}{30}\n$$\n现在，我们求出归一化后的迭代向量 $x_1 = y_1 / \\|y_1\\|_2$：\n$$\nx_1 = \\frac{1}{\\|y_1\\|_2} y_1 = \\frac{30}{\\sqrt{1009}} \\begin{pmatrix} 1 \\\\ \\frac{1}{3} \\\\ \\frac{1}{10} \\end{pmatrix} = \\frac{1}{\\sqrt{1009}} \\begin{pmatrix} 30 \\cdot 1 \\\\ 30 \\cdot \\frac{1}{3} \\\\ 30 \\cdot \\frac{1}{10} \\end{pmatrix} = \\frac{1}{\\sqrt{1009}} \\begin{pmatrix} 30 \\\\ 10 \\\\ 3 \\end{pmatrix}\n$$\n这是第一个要求的结果。\n\n接下来，我们计算瑞利商 $r(x_1)$，其定义为 $r(x) = (x^{\\top} A x) / (x^{\\top} x)$。对于归一化向量 $x_1$，根据归一化的定义，分母 $x_1^{\\top} x_1 = \\|x_1\\|_2^2$ 等于 $1$。因此，我们只需要计算分子 $x_1^{\\top} A x_1$。\n$$\nr(x_1) = x_1^{\\top} A x_1 = \\left( \\frac{1}{\\sqrt{1009}} \\begin{pmatrix} 30 \\\\ 10 \\\\ 3 \\end{pmatrix}^{\\top} \\right) \\begin{pmatrix} 1  0  0 \\\\ 0  3  0 \\\\ 0  0  10 \\end{pmatrix} \\left( \\frac{1}{\\sqrt{1009}} \\begin{pmatrix} 30 \\\\ 10 \\\\ 3 \\end{pmatrix} \\right)\n$$\n$$\nr(x_1) = \\frac{1}{1009} \\begin{pmatrix} 30  10  3 \\end{pmatrix} \\begin{pmatrix} 1 \\cdot 30 \\\\ 3 \\cdot 10 \\\\ 10 \\cdot 3 \\end{pmatrix} = \\frac{1}{1009} \\begin{pmatrix} 30  10  3 \\end{pmatrix} \\begin{pmatrix} 30 \\\\ 30 \\\\ 30 \\end{pmatrix}\n$$\n$$\nr(x_1) = \\frac{1}{1009} (30 \\cdot 30 + 10 \\cdot 30 + 3 \\cdot 30) = \\frac{900 + 300 + 90}{1009} = \\frac{1290}{1009}\n$$\n由于 $1009$ 是一个质数，这个分数是最简形式。这是第二个要求的结果。\n\n最后，我们必须解释 $x_1$ 的哪个特征分量占主导地位及其原因。矩阵 $A$ 是对角的，所以它的特征值是其对角线元素：$\\lambda_1=1$，$\\lambda_2=3$ 和 $\\lambda_3=10$。对应的特征向量是标准基向量：$v_1=(1,0,0)^{\\top}$，$v_2=(0,1,0)^{\\top}$ 和 $v_3=(0,0,1)^{\\top}$。\n\n初始向量 $x_0=(1,1,1)^{\\top}$ 可以表示为这些特征向量的线性组合：\n$$\nx_0 = 1 \\cdot v_1 + 1 \\cdot v_2 + 1 \\cdot v_3\n$$\n无位移的反迭代等价于对矩阵 $A^{-1}$ 应用幂法。一步迭代将 $x_0$ 变换为 $y_1 = A^{-1}x_0$：\n$$\ny_1 = A^{-1}(1 \\cdot v_1 + 1 \\cdot v_2 + 1 \\cdot v_3) = 1 \\cdot A^{-1}v_1 + 1 \\cdot A^{-1}v_2 + 1 \\cdot A^{-1}v_3\n$$\n由于对于 $A$ 的一个特征值为 $\\lambda_i$ 的特征向量 $v_i$，我们有 $A^{-1}v_i = \\frac{1}{\\lambda_i}v_i$，因此：\n$$\ny_1 = 1 \\cdot \\frac{1}{\\lambda_1} v_1 + 1 \\cdot \\frac{1}{\\lambda_2} v_2 + 1 \\cdot \\frac{1}{\\lambda_3} v_3 = \\frac{1}{1} v_1 + \\frac{1}{3} v_2 + \\frac{1}{10} v_3 = 1 v_1 + \\frac{1}{3} v_2 + \\frac{1}{10} v_3\n$$\n这得到 $y_1=(1, 1/3, 1/10)^{\\top}$，与我们之前的计算一致。幂法会放大与模最大特征值对应的特征向量的分量。$A^{-1}$ 的特征值为 $1/\\lambda_1=1$，$1/\\lambda_2=1/3$ 和 $1/\\lambda_3=1/10$。其中模最大的是 $1$。\n\n因此，迭代放大了与 $A^{-1}$ 的这个最大特征值（即 $A$ 的最小特征值）对应的特征向量 $v_1$ 的分量。经过一步迭代后，向量 $y_1$ 的分量为 $(1, 1/3, 1/10)$。对应于 $v_1$ 的第一个分量的系数为 $1$，大于 $1/3$ 和 $1/10$。归一化将所有分量乘以同一个正因子，因此相对主导地位在 $x_1$ 中得以保持。$x_1$ 的分量与 $(30, 10, 3)$ 成比例。第一个分量显然是最大的。\n因此，$x_1$ 中与特征向量 $v_1$（关联于特征值 $\\lambda_1=1$）对应的特征分量占主导地位。", "answer": "$$\n\\boxed{\\frac{1290}{1009}}\n$$", "id": "3551809"}, {"introduction": "在掌握了基本逆迭代之后，我们引入一个强大的概念：平移（shift）。平移使我们能够选择性地计算任意特征值，而不仅仅是最小的那个。这个练习要求对一个非对角矩阵执行带平移的逆迭代，这更接近实际应用，因为它需要求解一个线性系统。通过这个计算，我们将体会到平移值的选择对收敛速度的直接影响，正如[@problem_id:2216123]所揭示的，收敛速度取决于平移值如何将目标特征值与其他特征值分离开来。", "problem": "考虑实对称矩阵 $A=\\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix}$ 和实数位移 $\\sigma=1.9$。对于非奇异矩阵 $A-\\sigma I$ 的位移反迭代法定义如下：给定一个非零初始向量 $x_{0}$，对于 $k\\geq 1$，求解 $(A-\\sigma I)y_{k}=x_{k-1}$ 并设置 $x_{k}=y_{k}/\\|y_{k}\\|_{2}$，其中 $\\|\\cdot\\|_{2}$ 表示欧几里得范数。非零向量 $x$ 关于矩阵 $A$ 的瑞利商为 $\\rho(x)=\\dfrac{x^{\\top}A\\,x}{x^{\\top}x}$。从 $x_{0}=\\begin{bmatrix}1\\\\0\\end{bmatrix}$ 开始，使用固定位移 $\\sigma=1.9$，执行两步位移反迭代以获得 $x_{1}$ 和 $x_{2}$，并报告瑞利商序列 $\\rho(x_{1})$ 和 $\\rho(x_{2})$。将最终的瑞利商对以精确的有理数形式表示；不要进行四舍五入。", "solution": "该问题是有效的，因为它具有科学依据、是适定且客观的。这是数值线性代数中位移反迭代法的一个标准应用。所有需要的数据都已提供，并且问题在数学上是一致的。该算法的条件，即矩阵 $A-\\sigma I$ 必须是非奇异的，得到了满足，因为位移 $\\sigma=1.9$ 不是矩阵 $A$ 的特征值。$A$ 的特征值为 $\\lambda_1=1$ 和 $\\lambda_2=3$。\n\n给定矩阵为 $A=\\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix}$，位移为 $\\sigma=1.9$。初始向量为 $x_{0}=\\begin{bmatrix}1\\\\0\\end{bmatrix}$。位移反迭代法由递推关系 $(A-\\sigma I)y_{k}=x_{k-1}$ 定义，随后进行归一化 $x_{k}=y_{k}/\\|y_{k}\\|_{2}$。瑞利商为 $\\rho(x)=\\dfrac{x^{\\top}A\\,x}{x^{\\top}x}$。对于单位向量 $x$，$\\rho(x) = x^{\\top}A\\,x$。\n\n首先，我们计算位移矩阵 $A-\\sigma I$。由于 $\\sigma=1.9=\\frac{19}{10}$，我们有：\n$$\nA-\\sigma I = \\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix} - \\frac{19}{10}\\begin{bmatrix} 1  0 \\\\ 0  1 \\end{bmatrix} = \\begin{bmatrix}2 - \\frac{19}{10}  1 \\\\ 1  2 - \\frac{19}{10}\\end{bmatrix} = \\begin{bmatrix}\\frac{1}{10}  1 \\\\ 1  \\frac{1}{10}\\end{bmatrix}\n$$\n\n**迭代的第1步 ($k=1$):**\n\n我们求解线性系统 $(A-\\sigma I)y_{1}=x_{0}$：\n$$\n\\begin{bmatrix}\\frac{1}{10}  1 \\\\ 1  \\frac{1}{10}\\end{bmatrix} y_{1} = \\begin{bmatrix}1\\\\0\\end{bmatrix}\n$$\n这对应于方程组：\n$$\n\\frac{1}{10} y_{1,1} + y_{1,2} = 1\n$$\n$$\ny_{1,1} + \\frac{1}{10} y_{1,2} = 0\n$$\n从第二个方程，我们得到 $y_{1,1} = -\\frac{1}{10} y_{1,2}$。将其代入第一个方程得到：\n$$\n\\frac{1}{10}\\left(-\\frac{1}{10} y_{1,2}\\right) + y_{1,2} = 1 \\implies -\\frac{1}{100} y_{1,2} + y_{1,2} = 1 \\implies \\frac{99}{100} y_{1,2} = 1 \\implies y_{1,2} = \\frac{100}{99}\n$$\n那么，$y_{1,1} = -\\frac{1}{10}\\left(\\frac{100}{99}\\right) = -\\frac{10}{99}$。\n所以，未归一化的向量是 $y_{1} = \\begin{bmatrix}-10/99 \\\\ 100/99\\end{bmatrix}$。\n\n接下来，我们计算瑞利商 $\\rho(x_1)$。由于瑞利商是零次齐次的（即对于任何标量 $\\alpha \\neq 0$，有 $\\rho(\\alpha x) = \\rho(x)$），我们可以使用未归一化的向量 $y_1$ 或任何与其成比例的向量来计算它，例如 $v_1 = 99 y_1 = \\begin{bmatrix}-10 \\\\ 100\\end{bmatrix}$，或更简单地 $v_1' = \\begin{bmatrix}-1 \\\\ 10\\end{bmatrix}$。我们使用 $v_1' = \\begin{bmatrix}-1 \\\\ 10\\end{bmatrix}$：\n$$\n\\rho(x_{1}) = \\rho(v_1') = \\frac{(v_1')^{\\top}A v_1'}{(v_1')^{\\top}v_1'}\n$$\n分母是 $(v_1')^{\\top}v_1' = (-1)^2 + 10^2 = 1+100=101$。\n分子的计算如下：\n$$\nA v_1' = \\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix} \\begin{bmatrix}-1\\\\10\\end{bmatrix} = \\begin{bmatrix}2(-1)+1(10) \\\\ 1(-1)+2(10)\\end{bmatrix} = \\begin{bmatrix}8\\\\19\\end{bmatrix}\n$$\n$$\n(v_1')^{\\top}A v_1' = \\begin{bmatrix}-1  10\\end{bmatrix} \\begin{bmatrix}8\\\\19\\end{bmatrix} = (-1)(8) + (10)(19) = -8+190=182\n$$\n所以，第一个瑞利商是：\n$$\n\\rho(x_{1}) = \\frac{182}{101}\n$$\n\n**迭代的第2步 ($k=2$):**\n\n首先，我们需要归一化的向量 $x_{1}$：\n$$\n\\|y_{1}\\|_{2} = \\left\\| \\begin{bmatrix}-10/99 \\\\ 100/99\\end{bmatrix} \\right\\|_{2} = \\sqrt{\\left(-\\frac{10}{99}\\right)^2 + \\left(\\frac{100}{99}\\right)^2} = \\sqrt{\\frac{100+10000}{99^2}} = \\frac{\\sqrt{10100}}{99} = \\frac{10\\sqrt{101}}{99}\n$$\n$$\nx_{1} = \\frac{y_{1}}{\\|y_{1}\\|_{2}} = \\frac{1}{\\frac{10\\sqrt{101}}{99}} \\begin{bmatrix}-10/99 \\\\ 100/99\\end{bmatrix} = \\frac{1}{\\sqrt{101}}\\begin{bmatrix}-1\\\\10\\end{bmatrix}\n$$\n现在我们求解系统 $(A-\\sigma I)y_{2}=x_{1}$：\n$$\n\\begin{bmatrix}\\frac{1}{10}  1 \\\\ 1  \\frac{1}{10}\\end{bmatrix} y_{2} = \\frac{1}{\\sqrt{101}}\\begin{bmatrix}-1\\\\10\\end{bmatrix}\n$$\n我们可以求解 $v_2 = \\sqrt{101} y_2$：\n$$\n\\begin{bmatrix}\\frac{1}{10}  1 \\\\ 1  \\frac{1}{10}\\end{bmatrix} v_2 = \\begin{bmatrix}-1\\\\10\\end{bmatrix}\n$$\n这给出了方程组：\n$$\n\\frac{1}{10} v_{2,1} + v_{2,2} = -1\n$$\n$$\nv_{2,1} + \\frac{1}{10} v_{2,2} = 10\n$$\n从第二个方程，我们得到 $v_{2,1} = 10 - \\frac{1}{10} v_{2,2}$。代入第一个方程：\n$$\n\\frac{1}{10}\\left(10 - \\frac{1}{10} v_{2,2}\\right) + v_{2,2} = -1 \\implies 1 - \\frac{1}{100} v_{2,2} + v_{2,2} = -1 \\implies \\frac{99}{100} v_{2,2} = -2 \\implies v_{2,2} = -\\frac{200}{99}\n$$\n那么，$v_{2,1} = 10 - \\frac{1}{10}\\left(-\\frac{200}{99}\\right) = 10 + \\frac{20}{99} = \\frac{990+20}{99} = \\frac{1010}{99}$。\n所以，$y_2$ 与 $v_2 = \\begin{bmatrix}1010/99 \\\\ -200/99\\end{bmatrix}$ 成比例，也与 $v_2' = 99 v_2 = \\begin{bmatrix}1010 \\\\ -200\\end{bmatrix}$ 成比例，或更简单地与 $v_2'' = \\begin{bmatrix}101 \\\\ -20\\end{bmatrix}$ 成比例。我们使用 $v_2''$ 来计算瑞利商 $\\rho(x_2)$：\n$$\n\\rho(x_{2}) = \\rho(v_2'') = \\frac{(v_2'')^{\\top}A v_2''}{(v_2'')^{\\top}v_2''}\n$$\n分母是 $(v_2'')^{\\top}v_2'' = 101^2 + (-20)^2 = 10201+400=10601$。\n分子的计算如下：\n$$\nA v_2'' = \\begin{bmatrix} 2  1 \\\\ 1  2 \\end{bmatrix} \\begin{bmatrix}101\\\\-20\\end{bmatrix} = \\begin{bmatrix}2(101)+1(-20) \\\\ 1(101)+2(-20)\\end{bmatrix} = \\begin{bmatrix}202-20\\\\101-40\\end{bmatrix} = \\begin{bmatrix}182\\\\61\\end{bmatrix}\n$$\n$$\n(v_2'')^{\\top}A v_2'' = \\begin{bmatrix}101  -20\\end{bmatrix} \\begin{bmatrix}182\\\\61\\end{bmatrix} = (101)(182) + (-20)(61) = 18382 - 1220 = 17162\n$$\n所以，第二个瑞利商是：\n$$\n\\rho(x_{2}) = \\frac{17162}{10601}\n$$\n题目要求瑞利商对 $\\rho(x_1)$ 和 $\\rho(x_2)$。它们是 $\\frac{182}{101}$ 和 $\\frac{17162}{10601}$。\n\n瑞利商序列是 $\\rho(x_1)=\\frac{182}{101}$ 和 $\\rho(x_2)=\\frac{17162}{10601}$。", "answer": "$$\n\\boxed{\\begin{pmatrix} \\frac{182}{101}  \\frac{17162}{10601} \\end{pmatrix}}\n$$", "id": "3551821"}, {"introduction": "从手动计算到计算实现，是数值方法学习的关键一步。这项综合性练习要求你实现并比较三种核心的特征值算法：幂法、固定平移的逆迭代以及强大的瑞利商迭代（Rayleigh Quotient Iteration, RQI）。RQI通过在每一步动态更新平移值，实现了惊人的收敛速度。通过在精心设计的测试矩阵上（包括具有挑战性的近简并特征值情况）运行这些算法，你将亲眼见证瑞利商迭代理论上的三次方收敛率在实践中意味着什么，以及自适应地选择平移值[@problem_id:3551807]是何等高效。", "problem": "实现一个算法，使用带瑞利商可变位移的反迭代法来近似计算实对称矩阵的特征对。对于非零向量 $x \\in \\mathbb{R}^n$，定义其瑞利商为 $R(x) = \\dfrac{x^\\mathsf{T} A x}{x^\\mathsf{T} x}$。考虑以下三种应用于实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的迭代方案，给定非零初始向量 $x_0 \\in \\mathbb{R}^n$ 和公差 $\\varepsilon  0$：\n\n- 幂迭代法：$x_{k+1} \\leftarrow \\dfrac{A x_k}{\\lVert A x_k \\rVert_2}$，使用 $\\lambda_k = R(x_k)$ 定义的残差范数为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n- 带固定位移的反迭代法：固定 $\\sigma_0 = R(x_0)$，通过求解 $(A - \\sigma_0 I) y = x_k$ 并设置 $x_{k+1} \\leftarrow \\dfrac{y}{\\lVert y \\rVert_2}$ 来计算 $x_{k+1}$，使用 $\\lambda_k = R(x_k)$ 定义的残差范数为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n- 带瑞利商可变位移的反迭代法（瑞利商迭代法）：在每次迭代中，计算 $\\sigma_k = R(x_k)$，求解 $(A - \\sigma_k I) y = x_k$，并设置 $x_{k+1} \\leftarrow \\dfrac{y}{\\lVert y \\rVert_2}$，使用 $\\lambda_k = R(x_k)$ 定义的残差范数为 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$。\n\n对于每种方案，当残差范数首次满足 $\\lVert A x_k - \\lambda_k x_k \\rVert_2 \\le \\varepsilon$ 或达到预设的最大迭代次数时停止。所有向量范数均为欧几里得范数，$I$ 表示大小为 $n$ 的单位矩阵。\n\n使用以下测试套件。在每种情况下，设置 $n = 5$，公差 $\\varepsilon = 10^{-10}$，最大迭代次数为 $1000$。\n\n- 测试用例 1（三对角对称正定矩阵）：\n  - 矩阵 $A_1 \\in \\mathbb{R}^{5 \\times 5}$：\n    $$\n    A_1 =\n    \\begin{bmatrix}\n    6  2  0  0  0 \\\\\n    2  5  2  0  0 \\\\\n    0  2  4  2  0 \\\\\n    0  0  2  3  2 \\\\\n    0  0  0  2  2\n    \\end{bmatrix}.\n    $$\n  - 初始向量 $x_0^{(1)} = \\dfrac{1}{\\sqrt{5}} [1, 1, 1, 1, 1]^\\mathsf{T}$。\n\n- 测试用例 2（具有两个非常接近的特征值的对称矩阵）：\n  - 定义对角矩阵 $D = \\mathrm{diag}(1, 1 + 10^{-6}, 2, 3, 4)$。\n  - 定义平面旋转，其旋转角 $\\theta$ 满足 $\\cos \\theta = \\dfrac{4}{5}$ 和 $\\sin \\theta = \\dfrac{3}{5}$，并设置\n    $$\n    Q = \\begin{bmatrix}\n    \\cos \\theta  -\\sin \\theta  0  0  0 \\\\\n    \\sin \\theta  \\phantom{-}\\cos \\theta  0  0  0 \\\\\n    0  0  1  0  0 \\\\\n    0  0  0  1  0 \\\\\n    0  0  0  0  1\n    \\end{bmatrix}.\n    $$\n  - 矩阵 $A_2 = Q^\\mathsf{T} D Q$。\n  - 初始向量 $x_0^{(2)} = [1, 0, 0, 0, 0]^\\mathsf{T}$。\n\n- 测试用例 3（希尔伯特矩阵）：\n  - 矩阵 $A_3 \\in \\mathbb{R}^{5 \\times 5}$，其元素为 $(A_3)_{ij} = \\dfrac{1}{i + j - 1}$，其中 $i,j \\in \\{1, 2, 3, 4, 5\\}$。\n  - 初始向量 $x_0^{(3)} = \\dfrac{1}{\\sqrt{5}} [1, -1, 1, -1, 1]^\\mathsf{T}$。\n\n对于每个测试用例，使用相同的 $A$ 和 $x_0$ 独立运行这三种方案，并记录残差范数首次满足 $\\lVert A x_k - \\lambda_k x_k \\rVert_2 \\le \\varepsilon$ 时的最小迭代次数 $k$。如果在最大迭代次数内未收敛，则记录最大迭代次数。\n\n你的程序必须输出单行，包含一个由方括号括起来的、包含 9 个整数的逗号分隔列表，顺序如下：\n$[k_{\\mathrm{RQI}}^{(1)}, k_{\\mathrm{fixed}}^{(1)}, k_{\\mathrm{power}}^{(1)}, k_{\\mathrm{RQI}}^{(2)}, k_{\\mathrm{fixed}}^{(2)}, k_{\\mathrm{power}}^{(2)}, k_{\\mathrm{RQI}}^{(3)}, k_{\\mathrm{fixed}}^{(3)}, k_{\\mathrm{power}}^{(3)}]$，其中 $k_{\\mathrm{RQI}}^{(i)}$ 是瑞利商迭代法在测试用例 $i$ 上的迭代次数，$k_{\\mathrm{fixed}}^{(i)}$ 是带固定位移 $\\sigma_0 = R(x_0^{(i)})$ 的反迭代法的迭代次数，$k_{\\mathrm{power}}^{(i)}$ 是幂迭代法的迭代次数。输出必须是严格遵循此格式的单行，除了列表表示结构上所需的字符外，不得包含任何额外的字符或空格。", "solution": "问题陈述经评估有效。它在科学上基于数值线性代数的既定原理，特别是针对特征值问题的迭代方法。该问题是适定的，所有必要的参数、矩阵、初始条件和停止准则都得到了明确无误的定义。语言客观且正式。因此，将提供一个解法。\n\n该问题要求实现并比较三种迭代算法，用于近似计算实对称矩阵 $A$ 的一个特征对 $(\\lambda, v)$，其中 $A v = \\lambda v$。一个特征对由一个特征值 $\\lambda$ 及其对应的特征向量 $v$ 组成。所考虑的方法是幂迭代法、带固定位移的反迭代法，以及带可变位移的反迭代法（也称为瑞利商迭代法，RQI）。对于一个实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其所有特征值都是实数，并且存在一个由特征向量构成的标准正交基。对于非零向量 $x \\in \\mathbb{R}^n$ 定义的瑞利商 $R(x) = \\frac{x^\\mathsf{T} A x}{x^\\mathsf{T} x}$，可提供对特征值的估计。如果 $x$ 是一个特征向量，则 $R(x)$ 是对应的精确特征值。对于所有算法，我们从一个初始向量 $x_0$ 开始，生成一个收敛到某个特征向量的向量序列 $\\{x_k\\}$，以及一个收敛到相应特征值的瑞利商序列 $\\{\\lambda_k = R(x_k)\\}$。\n\n1.  **幂迭代法**\n\n    幂迭代法是寻找矩阵主特征对的最简单算法，即特征对 $(\\lambda_1, v_1)$，其中 $|\\lambda_1|$ 是所有特征值中模最大的。迭代步骤定义为：\n    $$\n    x_{k+1} = \\frac{A x_k}{\\lVert A x_k \\rVert_2}\n    $$\n    从一个在主特征向量 $v_1$ 方向上具有非零分量的初始向量 $x_0$ 开始，序列 $x_k$ 收敛到 $v_1$。收敛是线性的，收敛速度由比率 $|\\lambda_2 / \\lambda_1|$ 决定，其中 $\\lambda_2$ 是模第二大的特征值。如果此比率接近 1，收敛可能非常慢。在每一步中，特征值通过瑞利商 $\\lambda_k = R(x_k)$ 来近似。\n\n2.  **带固定位移的反迭代法**\n\n    反迭代法是一种寻找与给定偏移量 $\\sigma$ 最接近的特征值所对应的特征对的方法。它将幂迭代法应用于矩阵 $(A - \\sigma I)^{-1}$。$(A - \\sigma I)^{-1}$ 的特征值是 $(\\lambda_i - \\sigma)^{-1}$，其中 $\\lambda_i$ 是 $A$ 的特征值。$(A - \\sigma I)^{-1}$ 的主特征值对应于 $|\\lambda_i - \\sigma|$ 的最小值，这意味着 $\\lambda_i$ 是 $A$ 的最接近 $\\sigma$ 的特征值。迭代步骤为：\n    $$\n    x_{k+1} = \\frac{(A - \\sigma I)^{-1} x_k}{\\lVert (A - \\sigma I)^{-1} x_k \\rVert_2}\n    $$\n    实践中，我们避免计算矩阵的逆。而是求解线性系统 $(A - \\sigma I) y_k = x_k$ 得到 $y_k$，然后进行归一化：\n    $$\n    x_{k+1} = \\frac{y_k}{\\lVert y_k \\rVert_2}\n    $$\n    对于本问题，在整个过程中使用固定的位移 $\\sigma_0 = R(x_0)$。收敛是线性的，但收敛速度由 $(A-\\sigma_0 I)^{-1}$ 的两个模最大特征值的比率决定。如果 $\\sigma_0$ 比其他任何特征值都更接近某个特征值 $\\lambda_j$，那么向特征向量 $v_j$ 的收敛会非常迅速。\n\n3.  **瑞利商迭代法 (RQI)**\n\n    瑞利商迭代法是反迭代法的一种强大改进，其中位移在每一步都使用对特征值的当前最佳估计——瑞利商进行更新。迭代过程定义如下：\n    1.  计算位移：$\\sigma_k = R(x_k) = \\frac{x_k^\\mathsf{T} A x_k}{x_k^\\mathsf{T} x_k}$。\n    2.  求解 $y_{k+1}$：$(A - \\sigma_k I) y_{k+1} = x_k$。\n    3.  归一化：$x_{k+1} = \\frac{y_{k+1}}{\\lVert y_{k+1} \\rVert_2}$。\n\n    对于对称矩阵，一旦迭代向量 $x_k$ 足够接近一个特征向量，RQI 会表现出三次收敛。这意味着近似值中正确数字的位数在每次迭代中大约增加三倍，从而导致极快的收敛速度。\n\n**停止准则**\n\n对于所有三种方法，当残差向量的范数 $\\lVert A x_k - \\lambda_k x_k \\rVert_2$ 小于指定的公差 $\\varepsilon$ 时，迭代终止，其中 $\\lambda_k = R(x_k)$。这个残差衡量了当前近似对 $( \\lambda_k, x_k )$ 满足特征值方程的程度。首次满足此条件的迭代次数 $k$ 是所需的输出。如果在最大迭代次数内未满足该条件，则记录最大迭代次数。\n\n实现将通过为每种算法定义一个函数来进行。每个函数将迭代地生成向量序列并在每一步检查停止准则，返回迭代次数。然后，这些函数将被应用于三个指定的测试用例。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef power_iteration(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates a dominant eigenpair using Power Iteration.\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    for k in range(1, max_iter + 1):\n        # Calculate x_k\n        v = A @ x\n        x_k = v / np.linalg.norm(v)\n\n        # Check residual for x_k\n        # Since x_k is normalized, its L2 norm squared is 1.\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n\n        if residual_norm = tol:\n            return k\n\n        # Prepare for the next iteration\n        x = x_k\n\n    return max_iter\n\ndef inverse_iteration_fixed_shift(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates an eigenpair using inverse iteration with a fixed shift.\n    The shift is the Rayleigh quotient of the initial vector.\n    \"\"\"\n    # Normalize initial vector for stability, although given vectors are normalized.\n    # The problem specifies sigma0 = R(x0), where x0 is the given initial vector.\n    # Since all given x0 are unit norm, x0.T @ x0 = 1.\n    sigma0 = (x0.T @ A @ x0) / (x0.T @ x0)\n    \n    try:\n        M = A - sigma0 * np.eye(A.shape[0])\n    except np.linalg.LinAlgError:\n        return max_iter # Fails if shift is an exact eigenvalue\n\n    x = x0 / np.linalg.norm(x0) # Start iteration with normalized vector\n\n    for k in range(1, max_iter + 1):\n        try:\n            # Solve (A - sigma0*I) y = x_{k-1}\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            # Shift is an eigenvalue or matrix is numerically singular\n            return max_iter\n\n        x_k = y / np.linalg.norm(y)\n\n        # Check residual for x_k\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n\n        if residual_norm = tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef rayleigh_quotient_iteration(A, x0, tol, max_iter):\n    \"\"\"\n    Approximates an eigenpair using Rayleigh Quotient Iteration.\n    \"\"\"\n    x = x0 / np.linalg.norm(x0)\n    \n    for k in range(1, max_iter + 1):\n        # Update shift at each step using the Rayleigh quotient of x_{k-1}\n        sigma = (x.T @ A @ x) / (x.T @ x)\n\n        try:\n            M = A - sigma * np.eye(A.shape[0])\n            # Solve (A - sigma_{k-1}*I) y = x_{k-1}\n            y = np.linalg.solve(M, x)\n        except np.linalg.LinAlgError:\n            # If the shift is an eigenvalue, the previous iterate was the eigenvector.\n            # Its residual should be zero or very small.\n            # The loop condition will have caught it in the previous iteration.\n            return k-1 if k > 1 else 1\n\n        x_k = y / np.linalg.norm(y)\n\n        # Check residual for x_k\n        lam_k = x_k.T @ A @ x_k\n        residual_norm = np.linalg.norm(A @ x_k - lam_k * x_k)\n        \n        if residual_norm = tol:\n            return k\n\n        x = x_k\n\n    return max_iter\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    n = 5\n    tol = 1e-10\n    max_iter = 1000\n\n    # Test Case 1\n    A1 = np.array([\n        [6, 2, 0, 0, 0],\n        [2, 5, 2, 0, 0],\n        [0, 2, 4, 2, 0],\n        [0, 0, 2, 3, 2],\n        [0, 0, 0, 2, 2]\n    ], dtype=float)\n    x0_1 = np.ones(n) / np.sqrt(n)\n\n    # Test Case 2\n    D = np.diag([1.0, 1.0 + 1e-6, 2.0, 3.0, 4.0])\n    cos_theta = 4.0 / 5.0\n    sin_theta = 3.0 / 5.0\n    Q = np.eye(n)\n    Q[0, 0] = cos_theta\n    Q[0, 1] = -sin_theta\n    Q[1, 0] = sin_theta\n    Q[1, 1] = cos_theta\n    A2 = Q.T @ D @ Q\n    x0_2 = np.zeros(n)\n    x0_2[0] = 1.0\n\n    # Test Case 3\n    # The problem states (A_3)_ij = 1/(i+j-1) for i,j in {1,..,5}.\n    # For numpy's 0-based indexing, this is 1/( (i_py+1) + (j_py+1) - 1 ) = 1/(i_py+j_py+1).\n    A3 = np.fromfunction(lambda i, j: 1 / (i + j + 1), (n, n), dtype=float)\n    x0_3 = np.array([1, -1, 1, -1, 1]) / np.sqrt(n)\n    \n    test_cases = [\n        (A1, x0_1),\n        (A2, x0_2),\n        (A3, x0_3)\n    ]\n\n    results = []\n    for A, x0 in test_cases:\n        k_rqi = rayleigh_quotient_iteration(A, x0, tol, max_iter)\n        k_fixed = inverse_iteration_fixed_shift(A, x0, tol, max_iter)\n        k_power = power_iteration(A, x0, tol, max_iter)\n        \n        results.extend([k_rqi, k_fixed, k_power])\n\n    # Expected output: [3,20,52,4,1000,1000,3,6,20]\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "2427128"}]}