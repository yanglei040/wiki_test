{"hands_on_practices": [{"introduction": "为了深入理解幂迭代法的核心机制，我们首先从最简单的情形——对角矩阵——入手。在此设定下，标准基向量即为特征向量，使得我们能够清晰地追踪每个分量如何独立演化。这个练习 ([@problem_id:3541831]) 旨在通过分析有限步收敛的精确条件，帮助您建立关于迭代过程如何放大主导分量并抑制次要分量的基本直觉。", "problem": "考虑一个形式为 $A = \\mathrm{diag}(\\lambda_1,\\dots,\\lambda_n)$ 的矩阵 $A \\in \\mathbb{C}^{n \\times n}$，以及对于 $k \\ge 0$ 定义的幂迭代 $y_{k+1} = A x_k$ 和 $x_{k+1} = y_{k+1} / \\lVert y_{k+1} \\rVert_2$，其中 $x_0 \\in \\mathbb{C}^n$ 是一个给定的非零初始向量。假设进行精确计算。在此设定下，$A$ 的特征向量是标准基向量，并且每个坐标在 $A$ 的作用下独立演化。定义以下概念。\n\n- 有限步收敛（到特征向量方向）：存在一个有限的 $K$，使得 $x_K$ 是 $A$ 的一个归一化特征向量，并且对于所有 $k \\ge K$，$x_k$ 都保持在该特征向量方向上（允许幺模复相位的翻转，或者在实数情况下，符号的改变）。\n- 在容差 $\\varepsilon \\in (0,1)$ 下有效消除次优势分量：对于一个指定的索引 $j^\\star$，满足 $|\\lambda_{j^\\star}| = \\max\\{|\\lambda_i| : x_0^{(i)} \\ne 0\\}$ 且 $x_0^{(j^\\star)} \\ne 0$，归一化迭代向量 $x_k$ 满足 $\\max_{i \\ne j^\\star} \\left| x_k^{(i)} / x_k^{(j^\\star)} \\right| \\le \\varepsilon$。\n\n选择所有正确的陈述。\n\nA. 最多一次迭代内发生有限步收敛的充要条件是 $x_0$ 的支撑集恰好包含一个索引 $j$ 使得 $\\lambda_j \\ne 0$（因此 $x_0$ 的所有其他非零项都位于索引 $i$ 处，其中 $\\lambda_i = 0$）。在这种情况下，$x_1$ 是方向为 $e_j$ 的归一化特征向量（相差一个幺模复相位），并且对于所有 $k \\ge 1$，$x_k$ 都保持在该方向上。\n\nB. 如果 $x_0$ 的非零项仅出现在 $|\\lambda_i|$ 在 $\\{|\\lambda_1|,\\dots,|\\lambda_n|\\}$ 中达到最大值的索引处，并且至少有两个这样的项是非零的，那么归一化迭代向量 $x_k$ 必然在有限步内收敛到一个单一的坐标向量。\n\nC. 假设 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$ 且 $x_0^{(1)} \\ne 0$。那么对于任何 $\\varepsilon \\in (0,1)$，使得 $\\max_{i \\ge 2} \\left| x_k^{(i)} / x_k^{(1)} \\right| \\le \\varepsilon$ 成立的最小 $k$ 是满足以下条件的最小整数 $k$\n$$\nk \\;\\ge\\; \\max_{\\substack{i \\ge 2 \\\\ x_0^{(i)} \\ne 0}} \\frac{\\log\\!\\left( \\dfrac{|x_0^{(i)}|}{\\varepsilon\\,|x_0^{(1)}|} \\right)}{\\log\\!\\left( \\dfrac{|\\lambda_1|}{|\\lambda_i|} \\right)} \\,.\n$$\n\nD. 如果使用 $\\ell_{\\infty}$-归一化代替 $\\ell_2$-归一化，即 $x_{k+1} = A x_k / \\lVert A x_k \\rVert_{\\infty}$，那么对于任何固定的容差 $\\varepsilon \\in (0,1)$，达到 $\\max_{i \\ge 2} |x_k^{(i)}| \\le \\varepsilon$ 所需的迭代次数与 $x_0$ 无关，只要 $x_0^{(1)} \\ne 0$ 且 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$。\n\nE. 如果 $x_0$ 在索引 $j$ 处恰好有一个非零坐标，那么无论 $\\lambda_j$ 的值是多少，归一化序列都满足 $x_k = e_j$ 对于所有 $k \\ge 0$（即，幂迭代实现了立即的有限步收敛）。\n\nF. 即使 $x_0^{(1)} = 0$ 且 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$，归一化最终会产生一个非零的第一坐标，因此 $x_k$ 在有限步内收敛到主特征向量方向 $e_1$。", "solution": "此题要求分析对角矩阵 $A \\in \\mathbb{C}^{n \\times n}$ 的幂迭代的收敛性质。\n\n题目陈述定义了一个对角矩阵 $A = \\mathrm{diag}(\\lambda_1, \\dots, \\lambda_n)$，以及从一个非零向量 $x_0 \\in \\mathbb{C}^n$ 开始的幂迭代序列 $y_{k+1} = A x_k$, $x_{k+1} = y_{k+1} / \\lVert y_{k+1} \\rVert_2$。分析应假设精确计算。$A$ 的特征向量是标准基向量 $e_i \\in \\mathbb{C}^n$，对应的特征值为 $\\lambda_i$。\n\n让我们建立迭代向量 $x_k$ 的一般形式。第 $k$ 步后的未归一化向量与 $A^k x_0$ 成比例。由于 $A$ 是对角的，$A^k = \\mathrm{diag}(\\lambda_1^k, \\dots, \\lambda_n^k)$。未归一化向量的第 $i$ 个分量是 $(\\lambda_i)^k x_0^{(i)}$。\n归一化向量 $x_k$ 的分量为：\n$$\nx_k^{(i)} = \\frac{\\lambda_i^k x_0^{(i)}}{\\sqrt{\\sum_{j=1}^n |\\lambda_j^k x_0^{(j)}|^2}}\n$$\n只要分母在每一步都不为零，此公式就有效。如果对于某个 $k$，$A^k x_0 = 0$，则迭代终止。\n\n现在，我们将分析每个陈述。\n\n**A. 最多一次迭代内发生有限步收敛的充要条件是 $x_0$ 的支撑集恰好包含一个索引 $j$ 使得 $\\lambda_j \\ne 0$（因此 $x_0$ 的所有其他非零项都位于索引 $i$ 处，其中 $\\lambda_i = 0$）。在这种情况下，$x_1$ 是方向为 $e_j$ 的归一化特征向量（相差一个幺模复相位），并且对于所有 $k \\ge 1$，$x_k$ 都保持在该方向上。**\n\n我们来证明这个“充要条件”的两个方向。\n\n($\\Rightarrow$) “仅当”部分：假设在最多一次迭代中发生有限步收敛。这意味着 $x_0$ 或 $x_1$ 是 $A$ 的一个归一化特征向量。一个特征向量必须形如 $c e_j$，其中 $j$ 是某个索引，$c$ 是一个满足 $|c|=1$ 的复标量。\n*   情况 1：$K=0$。$x_0 = c e_j$，对于某个 $j$ 且 $|c|=1$。为了使序列对于 $k \\ge 1$ 有定义，我们必须有 $y_1 = A x_0 \\ne 0$。$A x_0 = A (c e_j) = c \\lambda_j e_j$。要使其非零，我们需要 $\\lambda_j \\ne 0$。在这种情况下，$x_0$ 的支撑集是 $\\{j\\}$，且 $\\lambda_j \\ne 0$。这满足了 $x_0$ 的支撑集恰好包含一个索引 $j$ 且 $\\lambda_j \\ne 0$ 的条件。\n*   情况 2：$K=1$。$x_1$ 是一个归一化特征向量，所以 $x_1 = c e_j$，对于某个 $j$ 且 $|c|=1$，而 $x_0$ 不是特征向量。要使 $x_1$ 在 $e_j$ 的方向上，未归一化的向量 $y_1 = A x_0$ 也必须在 $e_j$ 的方向上。这意味着对于所有 $i \\ne j$，$(A x_0)^{(i)} = 0$，且 $(A x_0)^{(j)} \\ne 0$。\n    *   $(A x_0)^{(j)} = \\lambda_j x_0^{(j)} \\ne 0$ 意味着 $\\lambda_j \\ne 0$ 且 $x_0^{(j)} \\ne 0$。\n    *   对于任何 $i \\ne j$，$(A x_0)^{(i)} = \\lambda_i x_0^{(i)} = 0$。这意味着对于任何 $i \\ne j$，如果 $x_0^{(i)} \\ne 0$，那么必须有 $\\lambda_i=0$。\n    这正是选项中所述的条件：$x_0^{(i)} \\ne 0$ 的索引集合（$x_0$ 的支撑集）中恰好包含一个索引 $j$，使得 $\\lambda_j \\ne 0$。\n\n($\\Leftarrow$) “如果”部分：假设 $x_0$ 的支撑集恰好包含一个索引 $j$ 使得 $\\lambda_j \\ne 0$。令 $S = \\{i \\mid x_0^{(i)} \\ne 0 \\text{ and } \\lambda_i=0\\}$。$x_0$ 的支撑集是 $S \\cup \\{j\\}$。\n我们计算 $y_1 = A x_0$。\n*   对于 $i=j$，$y_1^{(j)} = \\lambda_j x_0^{(j)}$。由于 $\\lambda_j \\ne 0$ 和 $x_0^{(j)} \\ne 0$，该分量非零。\n*   对于任何其他索引 $i \\ne j$：如果 $x_0^{(i)}=0$，则 $y_1^{(i)} = \\lambda_i \\cdot 0 = 0$。如果 $x_0^{(i)} \\ne 0$，则根据假设 $\\lambda_i=0$，所以 $y_1^{(i)} = 0 \\cdot x_0^{(i)} = 0$。\n所以，$y_1$ 只有一个非零分量，在索引 $j$ 处。$y_1 = (\\lambda_j x_0^{(j)}) e_j$。由于 $y_1 \\ne 0$，我们可以对其进行归一化。\n$x_1 = \\frac{y_1}{\\lVert y_1 \\rVert_2} = \\frac{\\lambda_j x_0^{(j)}}{|\\lambda_j x_0^{(j)}|} e_j$。\n标量倍数 $\\frac{\\lambda_j x_0^{(j)}}{|\\lambda_j x_0^{(j)}|}$ 是一个幺模复数。因此，$x_1$ 是一个归一化特征向量。对于任何 $k \\ge 1$，$x_k$ 都是一个特征向量。例如，$y_2 = A x_1 = \\lambda_j x_1$，这是一个非零的 $e_j$ 的倍数。对其进行归一化得到 $x_2$，它也是 $e_j$ 的一个倍数（可能具有不同的相位）。对于所有 $k \\ge 1$，方向是稳定的。\n该陈述成立。\n\n判决：**正确**。\n\n**B. 如果 $x_0$ 的非零项仅出现在 $|\\lambda_i|$ 在 $\\{|\\lambda_1|,\\dots,|\\lambda_n|\\}$ 中达到最大值的索引处，并且至少有两个这样的项是非零的，那么归一化迭代向量 $x_k$ 必然在有限步内收敛到一个单一的坐标向量。**\n\n令 $\\rho = \\max_i |\\lambda_i|$。令 $S = \\{i \\mid |\\lambda_i| = \\rho\\}$。假设是 $x_0$ 的支撑集是 $S$ 的一个子集，且 $|\\mathrm{supp}(x_0)| \\ge 2$。\n迭代向量 $x_k$ 的分量 $x_k^{(i)}$ 与 $\\lambda_i^k x_0^{(i)}$ 成比例。对于 $\\mathrm{supp}(x_0)$ 中的任意两个索引 $i, j$，分量的比值为：\n$$\n\\frac{x_k^{(i)}}{x_k^{(j)}} = \\frac{\\lambda_i^k x_0^{(i)}}{\\lambda_j^k x_0^{(j)}}\n$$\n其模长的比值为：\n$$\n\\left| \\frac{x_k^{(i)}}{x_k^{(j)}} \\right| = \\frac{|\\lambda_i|^k |x_0^{(i)}|}{|\\lambda_j|^k |x_0^{(j)}|} = \\frac{\\rho^k |x_0^{(i)}|}{\\rho^k |x_0^{(j)}|} = \\frac{|x_0^{(i)}|}{|x_0^{(j)}|}\n$$\n这个比值对于所有 $k$ 都是常数。如果 $x_0$ 在索引 $i$ 和 $j$ 处有非零分量，那么 $x_k$ 在这些索引处对于所有 $k$ 也将有非零分量。$x_k$ 的支撑集与 $x_0$ 的支撑集对于所有 $k$ 都相同。由于 $x_0$ 的支撑集至少包含两个索引，所以 $x_k$ 的支撑集对于所有 $k$ 也将至少包含两个索引。因此，$x_k$ 永远不能成为一个单一的坐标向量（其支撑集大小为 1）。有限步收敛到一个单一的坐标向量是不可能的。该序列甚至可能不会收敛到一个单一向量，因为相位 $e^{i\\arg(\\lambda_i)k}$ 可能导致向量在环面上循环或游走。\n\n判决：**不正确**。\n\n**C. 假设 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$ 且 $x_0^{(1)} \\ne 0$。那么对于任何 $\\varepsilon \\in (0,1)$，使得 $\\max_{i \\ge 2} \\left| x_k^{(i)} / x_k^{(1)} \\right| \\le \\varepsilon$ 成立的最小 $k$ 是满足... [不等式] ...的最小整数 $k$。**\n\n我们关心的是对于 $i \\ge 2$ 的比值 $\\left| x_k^{(i)} / x_k^{(1)} \\right|$。\n如前所示，归一化因子在分量比值中被消去：\n$$\n\\frac{x_k^{(i)}}{x_k^{(1)}} = \\frac{\\lambda_i^k x_0^{(i)}}{\\lambda_1^k x_0^{(1)}} = \\left(\\frac{\\lambda_i}{\\lambda_1}\\right)^k \\frac{x_0^{(i)}}{x_0^{(1)}}\n$$\n取模长：\n$$\n\\left| \\frac{x_k^{(i)}}{x_k^{(1)}} \\right| = \\left| \\frac{\\lambda_i}{\\lambda_1} \\right|^k \\left| \\frac{x_0^{(i)}}{x_0^{(1)}} \\right|\n$$\n我们希望这个值对于所有 $i \\ge 2$ 都小于或等于 $\\varepsilon$。我们只需要考虑 $x_0^{(i)} \\ne 0$ 的索引 $i$，因为否则比值为 0。\n对于每个这样的 $i$，我们要求：\n$$\n\\left| \\frac{\\lambda_i}{\\lambda_1} \\right|^k \\left| \\frac{x_0^{(i)}}{x_0^{(1)}} \\right| \\le \\varepsilon\n$$\n整理并取自然对数：\n$$\nk \\log\\left(\\left| \\frac{\\lambda_i}{\\lambda_1} \\right|\\right) \\le \\log\\left(\\varepsilon \\left| \\frac{x_0^{(1)}}{x_0^{(i)}} \\right|\\right)\n$$\n因为 $|\\lambda_1|  |\\lambda_i|$，所以 $\\log(|\\lambda_i|/|\\lambda_1|)$ 是负数。两边同除以它会反转不等号：\n$$\nk \\ge \\frac{\\log\\left(\\varepsilon \\left| \\frac{x_0^{(1)}}{x_0^{(i)}} \\right|\\right)}{\\log\\left(\\left| \\frac{\\lambda_i}{\\lambda_1} \\right|\\right)}\n$$\n让我们重写对数的参数以匹配给定的公式。\n分子：$\\log\\left(\\varepsilon \\frac{|x_0^{(1)}|}{|x_0^{(i)}|}\\right) = - \\log\\left(\\frac{1}{\\varepsilon} \\frac{|x_0^{(i)}|}{|x_0^{(1)}|}\\right) = - \\log\\left(\\frac{|x_0^{(i)}|}{\\varepsilon|x_0^{(1)}|}\\right)$。\n分母：$\\log\\left(\\frac{|\\lambda_i|}{|\\lambda_1|}\\right) = -\\log\\left(\\frac{|\\lambda_1|}{|\\lambda_i|}\\right)$。\n代入这些得到：\n$$\nk \\ge \\frac{-\\log\\left(\\frac{|x_0^{(i)}|}{\\varepsilon|x_0^{(1)}|}\\right)}{-\\log\\left(\\frac{|\\lambda_1|}{|\\lambda_i|}\\right)} = \\frac{\\log\\left(\\frac{|x_0^{(i)}|}{\\varepsilon|x_0^{(1)}|}\\right)}{\\log\\left(\\frac{|\\lambda_1|}{|\\lambda_i|}\\right)}\n$$\n这个不等式必须对所有 $x_0^{(i)} \\ne 0$ 的 $i \\ge 2$ 成立。因此，$k$ 必须大于或等于这些下界的最大值。\n$$\nk \\ge \\max_{\\substack{i \\ge 2 \\\\ x_0^{(i)} \\ne 0}} \\frac{\\log\\left( \\dfrac{|x_0^{(i)}|}{\\varepsilon\\,|x_0^{(1)}|} \\right)}{\\log\\left( \\dfrac{|\\lambda_1|}{|\\lambda_i|} \\right)}\n$$\n最小的整数 $k$ 是满足此不等式的最小整数，这与选项的措辞一致。\n\n判决：**正确**。\n\n**D. 如果使用 $\\ell_{\\infty}$-归一化代替 $\\ell_2$-归一化，即 $x_{k+1} = A x_k / \\lVert A x_k \\rVert_{\\infty}$，那么对于任何固定的容差 $\\varepsilon \\in (0,1)$，达到 $\\max_{i \\ge 2} |x_k^{(i)}| \\le \\varepsilon$ 所需的迭代次数与 $x_0$ 无关，只要 $x_0^{(1)} \\ne 0$ 且 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$。**\n\n使用 $\\ell_{\\infty}$-归一化，第 $k$ 个迭代向量是 $x_k = \\frac{A^k x_0}{\\lVert A^k x_0 \\rVert_{\\infty}}$。其分量为：\n$$\nx_k^{(i)} = \\frac{\\lambda_i^k x_0^{(i)}}{\\max_{j} |\\lambda_j^k x_0^{(j)}|}\n$$\n条件是 $\\max_{i \\ge 2} |x_k^{(i)}| \\le \\varepsilon$。对于一个特定的 $i \\ge 2$，我们希望：\n$$\n|x_k^{(i)}| = \\frac{|\\lambda_i|^k |x_0^{(i)}|}{\\max_{j} |\\lambda_j^k x_0^{(j)}|} \\le \\varepsilon\n$$\n因为 $|\\lambda_1|$ 是严格占优的，对于足够大的 $k$，项 $|\\lambda_1^k x_0^{(1)}|$ 将在分母的最大值中占主导地位。我们假设 $k$ 足够大，以至于 $\\lVert A^k x_0 \\rVert_{\\infty} = |\\lambda_1^k x_0^{(1)}| = |\\lambda_1|^k |x_0^{(1)}|$。\n那么对于 $i \\ge 2$ 的条件变为：\n$$\n\\frac{|\\lambda_i|^k |x_0^{(i)}|}{|\\lambda_1|^k |x_0^{(1)}|} = \\left(\\frac{|\\lambda_i|}{|\\lambda_1|}\\right)^k \\frac{|x_0^{(i)}|}{|x_0^{(1)}|} \\le \\varepsilon\n$$\n解出 $k$ 得到一个依赖于比值 $|x_0^{(i)}|/|x_0^{(1)}|$ 的下界。由于这个比值依赖于初始向量 $x_0$，所需的迭代次数也将依赖于 $x_0$。例如，一个较大的初始分量比 $|x_0^{(i)}|/|x_0^{(1)}|$ 将需要更多次迭代才能使该项衰减到 $\\varepsilon$ 以下。该陈述是错误的。\n\n判决：**不正确**。\n\n**E. 如果 $x_0$ 在索引 $j$ 处恰好有一个非零坐标，那么无论 $\\lambda_j$ 的值是多少，归一化序列都满足 $x_k = e_j$ 对于所有 $k \\ge 0$（即，幂迭代实现了立即的有限步收敛）。**\n\n令 $x_0 = c e_j$，其中 $c \\in \\mathbb{C}$ 是一个非零标量。该陈述声称对于所有 $k \\ge 0$，$x_k = e_j$。\n对于 $k=0$ 的声明意味着 $x_0 = e_j$，所以我们必须有 $c=1$。让我们假设 $x_0=e_j$。\n该陈述声称这“无论 $\\lambda_j$ 的值是多少”都成立。\n*   情况 1：$\\lambda_j=0$。那么 $y_1 = A x_0 = A e_j = \\lambda_j e_j = 0$。范数 $\\lVert y_1 \\rVert_2 = 0$，且 $x_1$ 未定义。序列无法继续，所以该声明失败。\n*   情况 2：$\\lambda_j \\ne 0$。那么 $y_1 = \\lambda_j e_j$。范数为 $\\lVert y_1 \\rVert_2 = |\\lambda_j|$。\n    下一个迭代向量是 $x_1 = \\frac{y_1}{\\lVert y_1 \\rVert_2} = \\frac{\\lambda_j e_j}{|\\lambda_j|}$。\n    为了使 $x_1$ 等于 $e_j$，我们必须有 $\\lambda_j / |\\lambda_j| = 1$。这仅在 $\\lambda_j$ 是一个正实数时才成立。如果 $\\lambda_j$ 是负数，或一个非实数的复数，那么 $x_1 \\ne e_j$。例如，如果 $\\lambda_j=-2$，那么 $x_1 = -e_j$。\n由于该陈述必须对任何 $\\lambda_j$ 都成立，而我们已经找到了反例，所以该陈述是错误的。\n\n判决：**不正确**。\n\n**F. 即使 $x_0^{(1)} = 0$ 且 $|\\lambda_1|  \\max_{i \\ge 2} |\\lambda_i|$，归一化最终会产生一个非零的第一坐标，因此 $x_k$ 在有限步内收敛到主特征向量方向 $e_1$。**\n\n题目声明我们假设精确计算。\n让我们检查迭代向量的第一个分量。我们已知 $x_0^{(1)}=0$。\n第一个未归一化的迭代向量是 $y_1 = A x_0$。它的第一个分量是 $y_1^{(1)} = \\lambda_1 x_0^{(1)} = \\lambda_1 \\cdot 0 = 0$。\n第一个归一化的迭代向量是 $x_1 = y_1 / \\lVert y_1 \\rVert_2$。它的第一个分量是 $x_1^{(1)} = y_1^{(1)} / \\lVert y_1 \\rVert_2 = 0 / \\lVert y_1 \\rVert_2 = 0$（假设 $y_1 \\ne 0$，否则迭代停止，但 $x_1^{(1)}$ 仍然是 0 或未定义，而不是非零）。\n通过归纳法，如果我们假设 $x_k^{(1)}=0$，那么 $y_{k+1}^{(1)} = \\lambda_1 x_k^{(1)} = 0$，这意味着 $x_{k+1}^{(1)}=0$。\n由于 $x_0^{(1)}=0$，所以第一个分量 $x_k^{(1)}$ 对于所有 $k \\ge 0$ 都保持为 0。在精确计算中，一个零分量不能自发地变为非零。迭代被限制在由 $\\{e_2, \\dots, e_n\\}$ 张成的子空间中。因此，迭代不能收敛到 $e_1$ 的方向。该陈述是错误的。\n\n判决：**不正确**。\n\n判决摘要：\nA：正确\nB：不正确\nC：正确\nD：不正确\nE：不正确\nF：不正确\n\n正确的陈述是 A 和 C。", "answer": "$$\\boxed{AC}$$", "id": "3541831"}, {"introduction": "在处理实际问题，尤其是对于表现良好的对称矩阵时，我们常常使用瑞利商 $\\rho_k = x_k^\\top A x_k$ 来估计特征值。然而，瑞利商的收敛速度可能与特征向量本身的收敛速度脱节，从而误导我们对收敛性的判断。本练习 ([@problem_id:3541815]) 通过构造具体示例，揭示了特征值估计误差与主角度 $\\theta_k$ 之间的微妙关系，强调了谱隙在决定收敛行为中的关键作用。", "problem": "考虑应用于实对称矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的幂迭代法，该矩阵的特征值为 $\\lambda_1  \\lambda_2 \\ge \\cdots \\ge \\lambda_n$，对应的标准正交特征向量为 $v_1, v_2, \\ldots, v_n$。设 $x_k \\in \\mathbb{R}^n$ 为归一化迭代向量，瑞利商为 $\\rho_k = x_k^\\top A x_k$，主角 $\\theta_k \\in [0,\\pi/2]$ 为一维子空间 $\\operatorname{span}\\{x_k\\}$ 与主导特征空间 $\\mathcal{E}_1 = \\operatorname{span}\\{v_1\\}$ 之间的夹角。你可以假设已知基本的线性代数事实，例如实对称矩阵的谱定理以及瑞利商和主角的定义。\n\n选择所有正确构造了明确场景的选项，在这些场景中，瑞利商 $\\rho_k$ 看起来收敛而主角 $\\theta_k$ 却没有收敛（反之亦然），并且这些选项正确阐述了其几何原因以及对幂迭代法中停止准则的合理启示。\n\nA. 取 $n=2$，$A = \\operatorname{diag}(1, 1 - 10^{-8})$，以及 $x_0 = \\frac{1}{\\sqrt{2}}(1,1)^\\top$。那么 $\\rho_0$ 与 $\\lambda_1$ 的偏差仅为 $5 \\cdot 10^{-9}$，而主角 $\\theta_0$ 等于 $\\pi/4$。这说明当最大的几个特征值紧密聚集时，即使 $\\theta_k$ 不小，$\\rho_k$ 也可能看起来已经收敛。因此，一个仅基于 $\\rho_k$ 稳定性的停止准则可能会过早终止；建议监测一个角度的代理指标（例如，子空间间隙）或残差范数。\n\nB. 取 $n=2$，$A = \\operatorname{diag}(10^6, 0)$，以及 $x_0 = (\\cos \\theta, \\sin \\theta)^\\top$，其中 $\\theta = 10^{-2}$（以弧度为单位）。此时 $\\theta_0$ 很小，但 $\\rho_0$ 对 $\\lambda_1$ 的低估量约为 $100$，因此一个要求小的特征值绝对误差的停止准则可能需要运行更长时间，即使方向已经基本收敛。这说明大的谱隙可能使得 $\\rho_k$ 在绝对值上滞后，而此时 $\\theta_k$ 已经非常小；一个基于角度或残差的准则能更忠实地反映子空间的收敛。\n\nC. 对于实对称矩阵 $A$，量 $|\\rho_k - \\lambda_1|$ 和 $\\sin \\theta_k$ 是一致等价的，即存在一个与谱无关的常数 $C  0$，使得对于所有单位向量 $x_k$ 都有 $C^{-1} |\\rho_k - \\lambda_1| \\le \\sin \\theta_k \\le C |\\rho_k - \\lambda_1|$。因此，$\\rho_k$ 的收敛总是蕴含 $\\theta_k$ 的收敛，反之亦然，且收敛速率是可比较的，无论谱隙如何。\n\nD. 在 $n=2$ 且 $A = \\operatorname{diag}(1, 1 - 10^{-8})$ 的情况下，任何满足 $|\\rho(x) - \\lambda_1| \\le 10^{-9}$ 的单位向量 $x$ 都必须服从 $\\theta \\le 10^{-4}$。因此，当瑞利商与最大特征值的差在 $10^{-9}$ 以内时，即使在特征值聚集的情况下，主角也必然非常小。\n\n选择所有适用项。", "solution": "用户提供的问题陈述已经过验证并被认为是可靠的。这是一个在数值线性代数领域内适定的、有科学依据的问题。其语言是客观的，提供的信息是内部一致且足以进行严格分析的。因此，我们可以开始解答。\n\n这个问题的核心在于，对于一个实对称矩阵 $A$ 的单位向量 $x$，其瑞利商 $\\rho(x) = x^\\top A x$ 与该向量相对于主导特征向量 $v_1$ 的主角 $\\theta$ 之间的关系。设 $A \\in \\mathbb{R}^{n \\times n}$ 的特征值为 $\\lambda_1  \\lambda_2 \\ge \\cdots \\ge \\lambda_n$，对应的标准正交特征基为 $\\{v_1, v_2, \\ldots, v_n\\}$。\n\n任何单位向量 $x \\in \\mathbb{R}^n$ 都可以表示为该特征基下的线性组合 $x = \\sum_{i=1}^n c_i v_i$，其中 $\\sum_{i=1}^n c_i^2 = 1$。$x$ 与主导特征向量 $v_1$ 之间的主角 $\\theta$ 由 $\\cos \\theta = |x^\\top v_1| = |c_1|$ 定义。由于 $\\theta \\in [0, \\pi/2]$，我们有 $\\cos \\theta \\ge 0$。根据关系式 $\\cos^2 \\theta + \\sin^2 \\theta = 1$，可得 $\\sin^2 \\theta = 1 - c_1^2 = \\sum_{i=2}^n c_i^2$。\n\n向量 $x$ 的瑞利商为：\n$$ \\rho(x) = x^\\top A x = \\left(\\sum_{i=1}^n c_i v_i\\right)^\\top A \\left(\\sum_{j=1}^n c_j v_j\\right) = \\left(\\sum_{i=1}^n c_i v_i\\right)^\\top \\left(\\sum_{j=1}^n c_j \\lambda_j v_j\\right) $$\n由于特征向量的标准正交性 ($v_i^\\top v_j = \\delta_{ij}$)，上式可简化为：\n$$ \\rho(x) = \\sum_{i=1}^n c_i^2 \\lambda_i = c_1^2 \\lambda_1 + \\sum_{i=2}^n c_i^2 \\lambda_i $$\n瑞利商作为 $\\lambda_1$ 的近似值的误差是：\n$$ \\lambda_1 - \\rho(x) = \\lambda_1 - \\left(c_1^2 \\lambda_1 + \\sum_{i=2}^n c_i^2 \\lambda_i\\right) = (1 - c_1^2)\\lambda_1 - \\sum_{i=2}^n c_i^2 \\lambda_i $$\n代入 $1 - c_1^2 = \\sum_{i=2}^n c_i^2$，我们得到基本关系式：\n$$ \\lambda_1 - \\rho(x) = \\left(\\sum_{i=2}^n c_i^2\\right)\\lambda_1 - \\sum_{i=2}^n c_i^2 \\lambda_i = \\sum_{i=2}^n c_i^2 (\\lambda_1 - \\lambda_i) $$\n使用 $\\sin^2 \\theta = \\sum_{i=2}^n c_i^2$：\n$$ \\lambda_1 - \\rho(x) = \\sum_{i=2}^n c_i^2 (\\lambda_1 - \\lambda_i) $$\n由于 $\\lambda_1  \\lambda_2 \\ge \\cdots \\ge \\lambda_n$，对于 $i \\ge 2$ 我们有 $(\\lambda_1 - \\lambda_2) \\ge (\\lambda_1 - \\lambda_i)$，但我们也有 $(\\lambda_1 - \\lambda_i) \\ge (\\lambda_1 - \\lambda_n)$。这使我们能够对误差进行界定：\n$$ (\\lambda_1 - \\lambda_2) \\sin^2 \\theta \\le \\lambda_1 - \\rho(x) \\le (\\lambda_1 - \\lambda_n) \\sin^2 \\theta $$\n注意，由于 $\\lambda_1$ 是最大特征值，所以 $\\rho(x) \\le \\lambda_1$，因此 $\\lambda_1 - \\rho(x) = |\\rho(x) - \\lambda_1|$。这个不等式对于评估各个选项至关重要。\n\n### 选项评估\n\n**选项 A:**\n- **场景:** $n=2$，$A = \\operatorname{diag}(1, 1 - 10^{-8})$，$x_0 = \\frac{1}{\\sqrt{2}}(1,1)^\\top$。\n- **分析:** 我们有 $\\lambda_1 = 1$ 及其对应的 $v_1 = (1, 0)^\\top$ 和 $\\lambda_2 = 1 - 10^{-8}$ 及其对应的 $v_2 = (0, 1)^\\top$。初始向量为 $x_0 = \\frac{1}{\\sqrt{2}}v_1 + \\frac{1}{\\sqrt{2}}v_2$。\n- **主角 $\\theta_0$**: $v_1$ 的系数是 $c_1 = 1/\\sqrt{2}$。因此，$\\cos \\theta_0 = |c_1| = 1/\\sqrt{2}$，这给出 $\\theta_0 = \\pi/4$。这是正确的。\n- **瑞利商 $\\rho_0$**: 对于 $2 \\times 2$ 的情况，该不等式变为等式：$\\lambda_1 - \\rho_0 = (\\lambda_1 - \\lambda_2) \\sin^2 \\theta_0$。\n  谱隙为 $\\lambda_1 - \\lambda_2 = 1 - (1 - 10^{-8}) = 10^{-8}$。\n  我们有 $\\sin^2 \\theta_0 = \\sin^2(\\pi/4) = (1/\\sqrt{2})^2 = 1/2$。\n  因此，偏差为 $\\lambda_1 - \\rho_0 = (10^{-8})(1/2) = 5 \\cdot 10^{-9}$。这也是正确的。\n- **结论:** 该场景表明，当谱隙非常小 ($10^{-8}$) 时，瑞利商误差 ($5 \\cdot 10^{-9}$) 可能非常小，表明已经收敛，而此时向量却处于最大程度的未对准状态 ($\\theta_0 = \\pi/4$)。在特征值聚集的情况下，仅基于 $\\rho_k$ 的停止准则可能具有误导性，这一推论是合理的，并且是数值方法中的一个标准警示原则。建议监测其他量是恰当的。\n- **判定:** **正确**。\n\n**选项 B:**\n- **场景:** $n=2$，$A = \\operatorname{diag}(10^6, 0)$，$x_0 = (\\cos \\theta, \\sin \\theta)^\\top$，其中 $\\theta = 10^{-2}$ 弧度。\n- **分析:** 我们有 $\\lambda_1 = 10^6$ 及其对应的 $v_1 = (1, 0)^\\top$ 和 $\\lambda_2 = 0$ 及其对应的 $v_2 = (0, 1)^\\top$。初始向量 $x_0$ 与 $v_1$ 形成的角度为 $\\theta_0 = \\theta = 10^{-2}$。这个角度很小 ($\\approx 0.57^\\circ$)。\n- **瑞利商 $\\rho_0$**: 使用与选项A中相同的等式，$\\lambda_1 - \\rho_0 = (\\lambda_1 - \\lambda_2) \\sin^2 \\theta_0$。\n  谱隙很大：$\\lambda_1 - \\lambda_2 = 10^6 - 0 = 10^6$。\n  角度为 $\\theta_0 = 10^{-2}$。对于小角度，$\\sin \\theta_0 \\approx \\theta_0$。\n  偏差为 $\\lambda_1 - \\rho_0 = 10^6 \\sin^2(10^{-2}) \\approx 10^6 (10^{-2})^2 = 10^6 \\cdot 10^{-4} = 100$。所以 $\\rho_0$ 对 $\\lambda_1$ 的低估量约为 $100$。这是正确的。\n- **结论:** 这个场景正确地展示了相反的情况：大的谱隙意味着即使主角很小，瑞利商的绝对误差也可能很大。向量的方向已接近收敛，但基于特征值小绝对误差的停止准则将需要更多次迭代。该推论是合理的。\n- **判定:** **正确**。\n\n**选项 C:**\n- **陈述:** 量 $|\\rho_k - \\lambda_1|$ 和 $\\sin \\theta_k$ 是一致等价的，存在一个与谱无关的常数 $C  0$，使得 $C^{-1} |\\rho_k - \\lambda_1| \\le \\sin \\theta_k \\le C |\\rho_k - \\lambda_1|$。\n- **分析:** 这个陈述不正确，主要有两个原因。\n  1. 关系是在 $|\\rho_k - \\lambda_1|$ 和 $\\sin^2 \\theta_k$ 之间，而不是 $\\sin \\theta_k$。具体来说， $|\\rho_k - \\lambda_1| = O(\\sin^2 \\theta_k)$。对于小的 $\\theta_k$，这意味着瑞利商的收敛相对于角度的收敛是二次的，这与所提出的线性关系有根本的不同。\n  2. 基本不等式 $(\\lambda_1 - \\lambda_2) \\sin^2 \\theta \\le |\\rho(x) - \\lambda_1| \\le (\\lambda_1 - \\lambda_n) \\sin^2 \\theta$ 表明，比例“常数”是 $(\\lambda_1 - \\lambda_2)$ 和 $(\\lambda_1 - \\lambda_n)$。这些量，即谱隙，明确地依赖于矩阵 $A$ 的谱。选项A和B为“存在与谱无关的常数”这一说法提供了明确的反例。\n- **判定:** **不正确**。\n\n**选项 D:**\n- **场景:** 在 $n=2$，$A = \\operatorname{diag}(1, 1 - 10^{-8})$ 的情况下。其主张是，任何满足 $|\\rho(x) - \\lambda_1| \\le 10^{-9}$ 的单位向量 $x$ 必须有角度 $\\theta \\le 10^{-4}$。\n- **分析:** 对于这个矩阵，我们有关系式 $|\\rho(x) - \\lambda_1| = (\\lambda_1-\\lambda_2)\\sin^2\\theta = 10^{-8} \\sin^2\\theta$。\n  条件 $|\\rho(x) - \\lambda_1| \\le 10^{-9}$ 转化为：\n  $$ 10^{-8} \\sin^2\\theta \\le 10^{-9} $$\n  $$ \\sin^2\\theta \\le \\frac{10^{-9}}{10^{-8}} = 0.1 $$\n  开平方根，我们发现 $\\sin\\theta \\le \\sqrt{0.1} \\approx 0.316$。由于 $\\theta \\in [0, \\pi/2]$，这意味着 $\\theta \\le \\arcsin(\\sqrt{0.1}) \\approx 0.3217$ 弧度。\n  该陈述声称 $\\theta$ 必须小于或等于 $10^{-4}$。然而，我们的计算表明 $\\theta$ 可以大到约 $0.3217$ 弧度，这远远大于 $10^{-4}$。例如，一个角度为 $\\theta = 0.3$ 弧度的向量，其 $|\\rho(x) - \\lambda_1| = 10^{-8} \\sin^2(0.3) \\approx 8.73 \\cdot 10^{-10}$，满足 $\\le 10^{-9}$ 的条件。然而，$0.3 \\gg 10^{-4}$。\n- **结论:** 该论证在数学上是错误的。当特征值紧密聚集时，小的瑞利商误差并不能保证角度也微小。这个选项与选项A的结论相矛盾。\n- **判定:** **不正确**。", "answer": "$$\\boxed{AB}$$", "id": "3541815"}, {"introduction": "经典收敛理论告诉我们，幂迭代法的收敛速度由谱比 $|\\lambda_2 / \\lambda_1|$ 决定，但这在非正规矩阵或特征向量基条件很差的情况下可能具有欺骗性。这个动手编程练习 ([@problem_id:3541827]) 将指导您构建一些特殊的矩阵，尽管它们的谱比很小，但由于特征向量基的病态性（即巨大的条件数 $\\kappa_2(V)$），幂迭代的实际收敛会异常缓慢。通过这个实践，您将体会到理论收敛速度与实际计算性能之间的差距，并理解非正规性在数值算法中的重要影响。", "problem": "考虑对一个可对角化矩阵的经典幂迭代法。设一个实矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 可对角化为 $A = V \\Lambda V^{-1}$，其中 $V$ 是满列秩矩阵，其列为 $A$ 的右特征向量，$\\Lambda = \\mathrm{diag}(\\lambda_1,\\dots,\\lambda_n)$ 包含按 $|\\lambda_1|  |\\lambda_2| \\ge \\cdots \\ge |\\lambda_n| \\ge 0$ 排序的特征值。定义幂迭代法为 $x_{k+1} = A x_k / \\|A x_k\\|_2$（$k \\in \\mathbb{N}$），从一个非零向量 $x_0 \\in \\mathbb{R}^n$ 开始。设 $V$ 在谱范数下的条件数为 $\\kappa_2(V) = \\|V\\|_2 \\cdot \\|V^{-1}\\|_2$，其中 $\\|\\cdot\\|_2$ 是由欧几里得向量范数诱导的矩阵范数。奇异值分解 (SVD) 是指将一个实矩阵分解为 $U \\Sigma W^\\top$ 的形式，其中 $\\Sigma$ 的对角线元素是奇异值；$\\kappa_2(V)$ 等于 $V$ 的最大奇异值与最小奇异值之比。幂迭代法的经典渐近理论指出，在精确算术下，第 $k$ 次的迭代向量 $x_k$ 以由 $|\\lambda_2 / \\lambda_1|$ 决定的速率趋向于主右特征向量的方向。然而，在实践中，达到一个有效近似所需的迭代次数取决于初始向量 $x_0$ 在特征向量基中的展开，而这又对 $V$ 的条件数敏感。您的任务是构造具有大谱隙 $|\\lambda_2 / \\lambda_1| \\ll 1$ 但条件数 $\\kappa_2(V)$ 非常大的矩阵，并评估幂迭代需要多少步才能使在特征向量基中测量的非主导分量变得可以忽略不计。\n\n请使用以下精确的设置，该设置仅从基本定义和事实出发。对于每个测试，您必须执行归一化的幂迭代 $x_{k+1} = A x_k / \\|A x_k\\|_2$。在第 $k$ 次迭代时，通过计算系数向量 $c^{(k)} = V^{-1} x_k \\in \\mathbb{R}^n$ 将 $x_k$ 在特征向量基中展开。定义主导系数的大小为 $d^{(k)} = |c^{(k)}_1|$，最差污染分量的大小为 $t^{(k)} = \\max_{j \\ge 2} |c^{(k)}_j|$。当双正交污染比 $r^{(k)} = t^{(k)} / d^{(k)}$ 满足 $r^{(k)} \\le \\tau$（容差 $\\tau = 10^{-8}$）时，或达到 $10{,}000$ 次迭代上限时，宣告收敛。此处任何角度量的单位都无关紧要，因为判据完全由无量纲的 $r^{(k)}$ 定义。\n\n按如下方式构造测试套件。在每个测试中，取主特征值为 $\\lambda_1 = 1$，并令所有其余特征值相等，即 $\\lambda_2 = \\cdots = \\lambda_n = \\alpha$，其中 $\\alpha = 10^{-3}$。取 $\\varepsilon = 10^{-150}$。设 $v_1, \\dots, v_n$ 表示 $V$ 的列。对于初始向量，在所有测试中都使用标准坐标系下相同的具体选择：$x_0$ 是一个单位归一化的向量，其前两个分量分别为 $1 - \\varepsilon$ 和 $\\varepsilon$，其余所有分量均为 $0$。该初始向量与 $V$ 无关，并在标准基中指定；不要从特征向量构造 $x_0$。\n\n指定四个涵盖不同方面的测试用例：\n\n- 测试 A（良态，维度 $2$）：取 $n = 2$ 和 $V = I_2$（$2 \\times 2$ 单位矩阵），因此 $\\kappa_2(V) = 1$。使用 $\\Lambda = \\mathrm{diag}(1, \\alpha)$ 构造 $A = V \\Lambda V^{-1}$，并从指定的 $x_0$ 开始运行幂迭代。\n\n- 测试 B（病态，维度 $2$）：取 $n = 2$ 并定义 $V$ 的前两列近似共线，$v_1 = e_1$ 和 $v_2 = e_1 + \\varepsilon e_2$。使用与测试 A 中相同的 $\\Lambda$ 构造 $A = V \\Lambda V^{-1}$。这个 $V$ 是可逆的，且其 $\\kappa_2(V)$ 的数量级为 $1/\\varepsilon$。从与测试 A 相同的 $x_0$ 开始运行幂迭代。\n\n- 测试 C（良态，维度 $5$）：取 $n = 5$ 和 $V = I_5$（$5 \\times 5$ 单位矩阵），因此 $\\kappa_2(V) = 1$。令 $\\Lambda = \\mathrm{diag}(1, \\alpha, \\alpha, \\alpha, \\alpha)$，并从与上面相同的 $x_0$（用零填充至长度为 $5$）开始运行幂迭代。\n\n- 测试 D（病态，维度 $5$）：取 $n = 5$ 并定义 $V$，其中 $v_1 = e_1$，$v_2 = e_1 + \\varepsilon e_2$，且对于 $j \\in \\{3,4,5\\}$，$v_j = e_j$。使用与测试 C 中相同的 $\\Lambda$ 构造 $A = V \\Lambda V^{-1}$。这个 $V$ 是可逆的，且其 $\\kappa_2(V)$ 的数量级为 $1/\\varepsilon$。从与上面相同的 $x_0$（作适当填充）开始运行幂迭代。\n\n对于每个测试，计算使 $r^{(k)} \\le \\tau$ 成立的最小整数 $k \\ge 0$，如果在此上限内未达到，则返回 $10{,}000$。您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，\"[resultA,resultB,resultC,resultD]\"），其中每个条目是按 A、B、C、D 顺序对应的测试的整数迭代次数。不应打印任何其他文本。所有计算都在纯数学中进行，不涉及任何物理单位；所有报告的整数都是无单位的。", "solution": "用户提供的问题陈述已经过验证，被认为是科学上可靠、适定、客观和完整的。该问题描述了一个数值实验，旨在研究幂迭代法在特征向量基不同条件数情况下的收敛行为。该设置是合理的，并基于数值线性代数的既定原则。因此，我们可以着手解决。\n\n任务是确定对于四个不同的矩阵，满足特定收敛准则所需的幂迭代次数 $k$。幂迭代由序列 $x_{k+1} = A x_k / \\|A x_k\\|_2$ 定义，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是一个可对角化矩阵，$A = V \\Lambda V^{-1}$，$x_0$ 是一个起始向量。\n\n收敛性是在特征向量基中测量的。在每次迭代 $k$ 中，当前向量 $x_k$ 表示为特征向量 $v_j$（$V$ 的列）的线性组合：$x_k = \\sum_{j=1}^n c^{(k)}_j v_j$。系数向量由 $c^{(k)} = V^{-1} x_k$ 给出。收敛准则基于“双正交污染比”，定义为 $r^{(k)} = t^{(k)} / d^{(k)}$，其中 $d^{(k)} = |c^{(k)}_1|$ 是对应于主特征向量的系数的大小，而 $t^{(k)} = \\max_{j \\ge 2} |c^{(k)}_j|$ 是所有其他“污染”系数中的最大值。当 $r^{(k)} \\le \\tau$（其中容差为 $\\tau = 10^{-8}$）时，宣告收敛。最大迭代次数上限为 $10,000$。\n\n分析过程首先为每个测试用例构造指定的矩阵和初始向量，然后模拟迭代过程。进行解析性检查有助于预测结果。我们来分析系数比 $r^{(k)}$ 的演化。\n从 $x_{k+1} = A x_k / \\|A x_k\\|_2$，我们可以找到系数的变换：\n$c^{(k+1)} = V^{-1} x_{k+1} = V^{-1} \\frac{A x_k}{\\|A x_k\\|_2} = \\frac{V^{-1} (V \\Lambda V^{-1}) x_k}{\\|A x_k\\|_2} = \\frac{\\Lambda (V^{-1} x_k)}{\\|A x_k\\|_2} = \\frac{\\Lambda c^{(k)}}{\\|A x_k\\|_2}$。\n两个系数 $c^{(k+1)}_j$ 和 $c^{(k+1)}_1$ 之间的比值为：\n$$ \\frac{c^{(k+1)}_j}{c^{(k+1)}_1} = \\frac{\\lambda_j c^{(k)}_j / \\|A x_k\\|_2}{\\lambda_1 c^{(k)}_1 / \\|A x_k\\|_2} = \\frac{\\lambda_j}{\\lambda_1} \\frac{c^{(k)}_j}{c^{(k)}_1} $$\n这表明，在每一步中，任何污染系数与主导系数的比值都乘以相应的特征值比。通过归纳法，我们有：\n$$ \\frac{c^{(k)}_j}{c^{(k)}_1} = \\left(\\frac{\\lambda_j}{\\lambda_1}\\right)^k \\frac{c^{(0)}_j}{c^{(0)}_1} $$\n取模并对 $j \\ge 2$ 取最大值：\n$$ r^{(k)} = \\frac{\\max_{j \\ge 2} |c^{(k)}_j|}{|c^{(k)}_1|} = \\max_{j \\ge 2} \\left| \\left(\\frac{\\lambda_j}{\\lambda_1}\\right)^k \\frac{c^{(0)}_j}{c^{(0)}_1} \\right| $$\n在这个问题中，所有非主导特征值都相等，即 $\\lambda_2 = \\dots = \\lambda_n = \\alpha$。因此，这可以简化为：\n$$ r^{(k)} = \\left|\\frac{\\alpha}{\\lambda_1}\\right|^k \\max_{j \\ge 2} \\left| \\frac{c^{(0)}_j}{c^{(0)}_1} \\right| = \\left|\\frac{\\alpha}{\\lambda_1}\\right|^k r^{(0)} $$\n因此，迭代次数由初始污染比 $r^{(0)}$ 和谱隙决定。参数为 $\\lambda_1 = 1$，$\\alpha = 10^{-3}$，$\\varepsilon = 10^{-150}$ 和 $\\tau = 10^{-8}$。\n\n初始向量是 $x'_0$ 的归一化，其中 $x'_0$ 的前两个分量为 $1-\\varepsilon$ 和 $\\varepsilon$，其余分量为零。由于 $\\varepsilon$ 极小，$\\|x'_0\\|_2 \\approx 1$，因此 $x_0 \\approx x'_0$。\n\n**测试 A 和 C（良态情况）**\n对于测试 A（$n=2$）和测试 C（$n=5$），特征向量基是标准基，$V=I_n$。因此 $V^{-1}=I_n$。\n初始系数向量为 $c^{(0)} = V^{-1} x_0 = x_0$。\n对于 $n=5$，$x_0$ 是 $[1-\\varepsilon, \\varepsilon, 0, 0, 0]^\\top$ 的归一化。归一化因子接近 $1$。\n$c^{(0)}_1 \\approx 1-\\varepsilon$，$c^{(0)}_2 \\approx \\varepsilon$ 且 $c^{(0)}_{j2}=0$。\n初始主导系数的大小为 $d^{(0)} = |c^{(0)}_1| \\approx 1-\\varepsilon$。\n最差污染分量的大小为 $t^{(0)} = \\max(|c^{(0)}_2|, |c^{(0)}_3|, \\dots) = \\varepsilon$。\n初始比率为 $r^{(0)} = t^{(0)}/d^{(0)} \\approx \\varepsilon/(1-\\varepsilon) \\approx 10^{-150}$。\n由于 $r^{(0)} \\approx 10^{-150} \\le 10^{-8} = \\tau$，收敛条件在开始时（即 $k=0$）就已满足。测试 A 和测试 C 的结果均为 $0$。\n\n**测试 B 和 D（病态情况）**\n对于测试 B（$n=2$），特征向量矩阵为 $V = \\begin{pmatrix} 1  1 \\\\ 0  \\varepsilon \\end{pmatrix}$。其逆矩阵为 $V^{-1} = \\begin{pmatrix} 1  -1/\\varepsilon \\\\ 0  1/\\varepsilon \\end{pmatrix}$。\n初始向量为 $x_0 \\approx [1-\\varepsilon, \\varepsilon]^\\top$。初始系数向量为：\n$$ c^{(0)} = V^{-1} x_0 \\approx \\begin{pmatrix} 1  -1/\\varepsilon \\\\ 0  1/\\varepsilon \\end{pmatrix} \\begin{pmatrix} 1-\\varepsilon \\\\ \\varepsilon \\end{pmatrix} = \\begin{pmatrix} (1-\\varepsilon) - 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} -\\varepsilon \\\\ 1 \\end{pmatrix} $$\n初始大小为 $d^{(0)} \\approx \\varepsilon$ 和 $t^{(0)} \\approx 1$。\n初始比率为 $r^{(0)} = t^{(0)}/d^{(0)} \\approx 1/\\varepsilon = 10^{150}$，这是一个非常大的数。\n对于测试 D（$n=5$），矩阵 $V$ 和 $V^{-1}$ 具有相同的 $2 \\times 2$ 分块结构，影响前两个分量，而在其他部分则为单位矩阵。对 $c^{(0)}$ 的分析对于前两个分量保持不变，其他分量为零。因此，$r^{(0)} \\approx 10^{150}$ 在这里也适用。\n\n我们需要为这些情况找到迭代次数 $k$。使用推导出的 $r^{(k)}$ 公式：\n$$ r^{(k)} = \\left|\\frac{\\alpha}{\\lambda_1}\\right|^k r^{(0)} \\le \\tau $$\n$$ (10^{-3})^k \\cdot 10^{150} \\le 10^{-8} $$\n$$ 10^{-3k} \\le 10^{-158} $$\n对两边取 $\\log_{10}$：\n$$ -3k \\le -158 $$\n$$ k \\ge \\frac{158}{3} \\approx 52.667 $$\n满足此条件的最小整数 $k$ 是 $53$。这个结果对于测试 B 和测试 D 都应该成立。\n\n最终的程序将通过数值方式执行幂迭代来验证这些解析预测。测试 A、B、C 和 D 的结果预计分别为 $0$、$53$、$0$ 和 $53$。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_power_iteration(n, V, Lambda, x0_unnormalized, tau, max_iter):\n    \"\"\"\n    Performs the power iteration for a given test case.\n\n    Args:\n        n (int): The dimension of the matrix.\n        V (np.ndarray): The eigenvector matrix.\n        Lambda (np.ndarray): The diagonal eigenvalue matrix.\n        x0_unnormalized (np.ndarray): The unnormalized initial vector.\n        tau (float): The convergence tolerance.\n        max_iter (int): The maximum number of iterations.\n\n    Returns:\n        int: The number of iterations to converge, or max_iter if not converged.\n    \"\"\"\n    # Construct the matrix A and pre-compute the inverse of V\n    A = V @ Lambda @ np.linalg.inv(V)\n    V_inv = np.linalg.inv(V)\n\n    # Normalize the initial vector x_0\n    norm_x0 = np.linalg.norm(x0_unnormalized)\n    if norm_x0 == 0:\n        # This case should not occur with the problem's setup\n        return max_iter\n    x_k = x0_unnormalized / norm_x0\n\n    for k in range(max_iter + 1):  # Loop from k = 0 to 10000\n        # 1. Expand x_k in the eigenvector basis to get coefficients c_k\n        c_k = V_inv @ x_k\n        \n        # 2. Compute dominant and contaminating magnitudes\n        d_k = np.abs(c_k[0])\n\n        # Avoid division by zero if dominant component is negligible.\n        if d_k  np.finfo(np.float64).tiny:\n            # Contamination is effectively infinite; continue iterating.\n            # This path is not expected for the given problem setup.\n            pass\n        else:\n            t_k = np.max(np.abs(c_k[1:])) if n > 1 else 0\n            r_k = t_k / d_k\n            \n            # 3. Check for convergence\n            if r_k = tau:\n                return k\n        \n        if k == max_iter:\n            break\n\n        # 4. Perform the next power iteration step\n        x_next = A @ x_k\n        norm_next = np.linalg.norm(x_next)\n        \n        if norm_next == 0:\n            # This can happen if A is singular and x_k is in its null space.\n            # A is invertible in all test cases, so this is unexpected.\n            return max_iter\n            \n        x_k = x_next / norm_next\n        \n    # If the loop completes without converging, return the cap value\n    return max_iter\n    \ndef solve():\n    \"\"\"\n    Sets up and runs the four test cases as specified in the problem statement.\n    \"\"\"\n    # Define common parameters\n    alpha = 1.0e-3\n    epsilon = 1.0e-150\n    tau = 1.0e-8\n    max_iter = 10000\n\n    results = []\n    \n    # Use float64 for all computations\n    dtype = np.float64\n\n    # --- Test Case A ---\n    n_A = 2\n    V_A = np.identity(n_A, dtype=dtype)\n    Lambda_A = np.diag(np.array([1.0, alpha], dtype=dtype))\n    x0_un_A = np.zeros(n_A, dtype=dtype)\n    x0_un_A[0] = 1.0 - epsilon\n    x0_un_A[1] = epsilon\n    results.append(run_power_iteration(n_A, V_A, Lambda_A, x0_un_A, tau, max_iter))\n\n    # --- Test Case B ---\n    n_B = 2\n    V_B = np.array([[1.0, 1.0], [0.0, epsilon]], dtype=dtype)\n    Lambda_B = np.diag(np.array([1.0, alpha], dtype=dtype))\n    x0_un_B = np.zeros(n_B, dtype=dtype)\n    x0_un_B[0] = 1.0 - epsilon\n    x0_un_B[1] = epsilon\n    results.append(run_power_iteration(n_B, V_B, Lambda_B, x0_un_B, tau, max_iter))\n\n    # --- Test Case C ---\n    n_C = 5\n    V_C = np.identity(n_C, dtype=dtype)\n    Lambda_C = np.diag(np.array([1.0, alpha, alpha, alpha, alpha], dtype=dtype))\n    x0_un_C = np.zeros(n_C, dtype=dtype)\n    x0_un_C[0] = 1.0 - epsilon\n    x0_un_C[1] = epsilon\n    results.append(run_power_iteration(n_C, V_C, Lambda_C, x0_un_C, tau, max_iter))\n\n    # --- Test Case D ---\n    n_D = 5\n    V_D = np.identity(n_D, dtype=dtype)\n    V_D[0, 1] = 1.0\n    V_D[1, 1] = epsilon\n    Lambda_D = np.diag(np.array([1.0, alpha, alpha, alpha, alpha], dtype=dtype))\n    x0_un_D = np.zeros(n_D, dtype=dtype)\n    x0_un_D[0] = 1.0 - epsilon\n    x0_un_D[1] = epsilon\n    results.append(run_power_iteration(n_D, V_D, Lambda_D, x0_un_D, tau, max_iter))\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3541827"}]}