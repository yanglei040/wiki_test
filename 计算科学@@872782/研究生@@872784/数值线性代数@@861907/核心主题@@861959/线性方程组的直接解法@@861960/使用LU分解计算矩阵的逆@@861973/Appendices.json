{"hands_on_practices": [{"introduction": "理论上，计算矩阵的逆有多种方法，但它们的数值稳定性和计算效率却大相径庭。此练习旨在通过编程实践，直接比较两种截然不同的求逆方法：一种是基于高斯消去法的 LU 分解，另一种是基于伴随矩阵的理论公式。通过对一系列精心设计的测试矩阵进行误差分析，您将亲身体会到为何 LU 分解是现代科学计算中求解线性系统和矩阵求逆的首选算法。[@problem_id:3275824]", "problem": "您必须编写一个完整、可运行的程序，对于一组给定的 $4 \\times 4$ 方阵，通过两种不同的方法计算矩阵的逆，并使用一种基于线性代数核心定义的、以残差为基础的度量方法，比较每种方法的数值误差。这两种方法是：(i) 一种源于带部分主元选择的高斯消去法以及将非奇异矩阵分解为下三角矩阵和上三角矩阵的算法，以及 (ii) 一种通过子式的代数余子式展开构造伴随矩阵，并通过子式的递归展开计算标量行列式的方法。您的程序必须明确实现这两种方法，不得调用任何内置的求逆例程。比较必须基于从基本原理计算的相对弗罗贝尼乌斯范数残差。\n\n需要使用的基本原理和定义：\n- 一个非奇异方阵 $A \\in \\mathbb{R}^{n \\times n}$ 的矩阵逆是矩阵 $X \\in \\mathbb{R}^{n \\times n}$，满足 $A X = I$，其中 $I$ 是大小为 $n \\times n$ 的单位矩阵。$X$ 的存在意味着 $A$ 是非奇异的。\n- 带部分主元选择的高斯消去法将一个非奇异矩阵 $A$ 转换为一个置换矩阵 $P A = L U$ 的分解形式，其中 $P$ 是一个置换矩阵，$L$ 是一个单位下三角矩阵（对角线元素等于 $1$），$U$ 是一个上三角矩阵。求解线性系统 $A x = b$ 时，在考虑了置换之后，对 $L$ 和 $U$ 应用前向和后向代入法。\n- 基于代数余子式的伴随矩阵由 $A$ 的带符号子式构成，这些子式通过行列式的子式递归展开（拉普拉斯展开）计算得出。不要使用任何内置或封闭形式的求逆公式；相反，应从代数余子式构造伴随矩阵，并通过递归子式展开计算行列式。\n\n需要计算的误差度量：\n- 对于每种方法产生的候选逆矩阵 $X$，定义相对逆残差误差\n$$\ne = \\frac{\\lVert I - A X \\rVert_F}{\\lVert I \\rVert_F},\n$$\n其中 $\\lVert \\cdot \\rVert_F$ 表示弗罗贝尼乌斯范数。该度量直接源于逆的定义 $A X = I$，并量化了计算出的 $X$ 与满足该恒等关系的接近程度。\n\n您的程序必须为每个测试矩阵 $A$ 执行的算法任务：\n1. 通过以下方式计算 $X_{\\mathrm{LU}}$：\n   - 通过仅使用算术运算的行交换和消元乘数，进行带部分主元选择的高斯消去法，构建分解 $P A = L U$。\n   - 通过将置换应用于右侧各列，然后对 $I$ 的所有列在 $L$ 上执行前向代入，接着在 $U$ 上执行后向代入，来求解 $A X = I$，从而得到 $X_{\\mathrm{LU}}$。\n2. 通过以下方式计算 $X_{\\mathrm{cof}}$：\n   - 通过沿某一行进行递归子式展开来计算 $A$ 的行列式。\n   - 从带符号的子式构造代数余子式矩阵，然后将其转置以获得伴随矩阵。使用此伴随矩阵与标量行列式结合生成 $X_{\\mathrm{cof}}$，不使用任何内置的求逆函数。\n3. 对于每种方法，使用上述残差公式计算 $e_{\\mathrm{LU}}$ 和 $e_{\\mathrm{cof}}$。\n\n测试套件：\n在以下五个维度 $n = 4$ 的矩阵集上评估您的程序：\n- 情况 $1$ (单位矩阵边界情况):\n$$\nA_1 = I_4 =\n\\begin{bmatrix}\n1  0  0  0 \\\\\n0  1  0  0 \\\\\n0  0  1  0 \\\\\n0  0  0  1\n\\end{bmatrix}.\n$$\n- 情况 $2$ (良态的整数值结构):\n$$\nA_2 =\n\\begin{bmatrix}\n4  2  0  1 \\\\\n0  1  3  2 \\\\\n1  0  2  0 \\\\\n2  3  1  0\n\\end{bmatrix}.\n$$\n- 情况 $3$ (经典的病态例子，Hilbert 矩阵):\n$$\nA_3 = H_4, \\quad (A_3)_{i j} = \\frac{1}{i + j - 1}, \\quad i,j \\in \\{1,2,3,4\\}.\n$$\n- 情况 $4$ (具有小行列式的近奇异块上三角结构):\n令 $\\varepsilon = 10^{-6}$。定义\n$$\nA_4 =\n\\begin{bmatrix}\n1  1  1  1 \\\\\n1  1+\\varepsilon  1  1 \\\\\n0  0  1  0 \\\\\n0  0  0  1\n\\end{bmatrix}.\n$$\n- 情况 $5$ (具有宽动态范围的 Vandermonde 矩阵):\n令 $x = [10^{-4}, 1, 2, 5]$。定义 Vandermonde 矩阵\n$$\nA_5 = V(x), \\quad (A_5)_{i j} = x_i^{j-1}, \\quad i,j \\in \\{1,2,3,4\\}.\n$$\n\n输出规范：\n- 对于每个测试用例 $k \\in \\{1,2,3,4,5\\}$，计算 $e_{\\mathrm{LU}}^{(k)}$ 和 $e_{\\mathrm{cof}}^{(k)}$ 作为浮点数。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序完全如下：\n$$\n[e_{\\mathrm{LU}}^{(1)}, e_{\\mathrm{cof}}^{(1)}, e_{\\mathrm{LU}}^{(2)}, e_{\\mathrm{cof}}^{(2)}, e_{\\mathrm{LU}}^{(3)}, e_{\\mathrm{cof}}^{(3)}, e_{\\mathrm{LU}}^{(4)}, e_{\\mathrm{cof}}^{(4)}, e_{\\mathrm{LU}}^{(5)}, e_{\\mathrm{cof}}^{(5)}].\n$$\n- 每个浮点数必须以科学记数法打印，小数点后有 $6$ 位数字（例如，$1.234567\\mathrm{e}{-08}$），并且输出字符串中不能有空格。\n\n不涉及物理单位。不涉及角度。所有输出均为无单位实数。\n\n您的实现必须是完全自包含的，仅使用您自己为所需步骤编写的基本算术运算和矩阵运算（不要调用任何内置的求逆例程），并遵守指定的打印格式。运行时环境是带有 Numerical Python ($\\mathrm{NumPy}$) 的 Python。", "solution": "此问题被评估为有效。它是一个在数值线性代数领域中定义良好、有科学依据且客观的问题。任务是实现并比较两种不同的矩阵求逆算法——一种基于 LU 分解，另一种基于代数余子式/伴随矩阵方法——并使用标准的基于残差的误差度量来量化它们的数值精度。所有的定义、约束和测试用例都经过了形式化指定并且在数学上是一致的。解决方案将首先概述每种方法和误差度量的理论基础，然后提供一个实现这些概念的程序。\n\n### 方法1：通过带部分主元选择的 LU 分解进行矩阵求逆\n第一种方法通过求解矩阵方程 $AX = I$ 来计算非奇异矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的逆 $X$，其中 $I$ 是单位矩阵。该方法的核心是带部分主元选择的 $A$ 的 LU 分解。这种分解将 $A$ 的一个置换版本分解为一个单位下三角矩阵 $L$ 和一个上三角矩阵 $U$ 的乘积，即 $PA = LU$。在这里，$P$ 是一个置换矩阵，记录了在高斯消去法过程中为确保数值稳定性而进行的行交换，以避免除以小的或为零的主元。\n\n矩阵方程 $AX = I$ 利用此分解重新排列为：\n$$PAX = PI \\implies LUX = P$$\n这个单一的矩阵方程对应于 $n$ 个独立的线性方程组，每个方程组对应 $X$ 的一列。设 $x_j$ 为 $X$ 的第 $j$ 列，$p_j$ 为 $P$ 的第 $j$ 列。那么，对于每个 $j \\in \\{1, \\dots, n\\}$，我们求解：\n$$LU x_j = p_j$$\n对每一列 $j$ 的求解过程分为两步：\n1.  **前向代入：** 求解 $L y_j = p_j$ 得到中间向量 $y_j$。由于 $L$ 是单位下三角矩阵（对角线上为 $1$），这个过程很高效：\n    $$y_{j,i} = p_{j,i} - \\sum_{k=1}^{i-1} L_{ik} y_{j,k} \\quad \\text{for } i = 1, \\dots, n$$\n2.  **后向代入：** 求解 $U x_j = y_j$ 得到列向量 $x_j$。由于 $U$ 是上三角矩阵，这也可以通过后向代入轻松求解：\n    $$x_{j,i} = \\frac{1}{U_{ii}} \\left( y_{j,i} - \\sum_{k=i+1}^{n} U_{ik} x_{j,k} \\right) \\quad \\text{for } i = n, \\dots, 1$$\n这些列向量 $x_j$ 的集合构成了逆矩阵 $X_{\\mathrm{LU}} = [x_1, x_2, \\dots, x_n]$。该方法由于其计算效率（对于一个 $n$ 阶稠密矩阵，总共约需要 $\\frac{8}{3}n^3$ 次浮点运算）和在使用部分主元选择时良好的数值稳定性，在数值计算中是标准方法。\n\n### 方法2：通过伴随矩阵公式进行矩阵求逆\n第二种方法基于使用行列式和伴随矩阵的经典解析求逆公式：\n$$A^{-1} = \\frac{1}{\\det(A)} \\mathrm{adj}(A)$$\n此方法需要计算两个部分：$A$ 的标量行列式 $\\det(A)$ 和 $A$ 的伴随矩阵 $\\mathrm{adj}(A)$。按照规定，两者都通过代数余子式展开来计算。\n\n1.  **行列式计算：** 行列式通过沿某一行（例如，第一行 $i=1$）的拉普拉斯展开来计算：\n    $$\\det(A) = \\sum_{j=1}^{n} (-1)^{1+j} A_{1j} \\det(M_{1j})$$\n    其中 $M_{1j}$ 是通过删除 $A$ 的第 $1$ 行和第 $j$ 列得到的 $(n-1) \\times (n-1)$ 子矩阵（一个子式）。这个定义是递归的；每个子式 $M_{1j}$ 的行列式都通过相同的展开方式计算，直到达到 $1 \\times 1$ 矩阵的基准情况，此时 $\\det([a]) = a$。\n\n2.  **伴随矩阵构造：** $A$ 的伴随矩阵是其代数余子式矩阵 $C$ 的转置：\n    $$\\mathrm{adj}(A) = C^T$$\n    代数余子式矩阵的元素 $C_{ij}$ 是带符号的子式：\n    $$C_{ij} = (-1)^{i+j} \\det(M_{ij})$$\n    其中 $M_{ij}$ 是通过从 $A$ 中删除第 $i$ 行和第 $j$ 列形成的子矩阵。这需要计算 $n^2$ 个 $(n-1) \\times (n-1)$ 大小的行列式。\n将这些组合起来便得到逆矩阵 $X_{\\mathrm{cof}}$。这种方法的计算成本非常高，如果递归实现，其复杂度为 $O(n!)$，而且通常数值上不稳定。大量的交替加减运算可能导致浮点运算中的灾难性抵消错误。它主要具有理论和教学上的重要性，对于较大的矩阵而言并不实用。\n\n### 误差度量\n为了比较计算出的两个逆矩阵 $X_{\\mathrm{LU}}$ 和 $X_{\\mathrm{cof}}$ 的数值精度，我们使用相对逆残差误差。对于一个计算出的逆矩阵 $X$，误差 $e$ 定义为：\n$$e = \\frac{\\lVert I - A X \\rVert_F}{\\lVert I \\rVert_F}$$\n这里，$\\lVert \\cdot \\rVert_F$ 是弗罗贝尼乌斯范数，对于一个矩阵 $B \\in \\mathbb{R}^{m \\times n}$ 定义为 $\\lVert B \\rVert_F = \\sqrt{\\sum_{i=1}^{m} \\sum_{j=1}^{n} |B_{ij}|^2}$。项 $I-AX$ 是残差矩阵，如果 $X$ 是精确的逆，它理想情况下应为零矩阵。这个残差的范数量化了与真实单位矩阵的偏差大小。通过单位矩阵的范数 $\\lVert I \\rVert_F$进行归一化，使得误差度量是相对的，并且与矩阵维度尺度无关。对于指定的 $n=4$ 的情况，$\\lVert I_4 \\rVert_F = \\sqrt{1^2 + 1^2 + 1^2 + 1^2} = \\sqrt{4} = 2$。\n这个度量直接且可靠地衡量了计算出的逆矩阵 $X$ 满足基本定义 $A^{-1}A=I$ 的程度。病态的测试用例（$A_3, A_4, A_5$）预计会在基于 LU 的方法和基于代数余子式的方法之间显示出该误差度量的显著差异，从而突显前者的优越数值稳定性。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef lu_decomposition_pivoting(A_in):\n    \"\"\"\n    Performs LU decomposition with partial pivoting: PA = LU.\n    L is unit lower-triangular, U is upper-triangular.\n    \"\"\"\n    n = A_in.shape[0]\n    A = A_in.copy()\n    L = np.zeros((n, n), dtype=float)\n    P = np.identity(n, dtype=float)\n\n    for k in range(n):\n        # Find pivot (largest element in column k below diagonal)\n        pivot_row_index = k + np.argmax(np.abs(A[k:, k]))\n        \n        # Swap rows in A and P\n        if pivot_row_index != k:\n            A[[k, pivot_row_index]] = A[[pivot_row_index, k]]\n            P[[k, pivot_row_index]] = P[[pivot_row_index, k]]\n            # Swap previously computed parts of L\n            if k > 0:\n                L[[k, pivot_row_index], :k] = L[[pivot_row_index, k], :k]\n\n        # Check for singularity\n        if np.isclose(A[k, k], 0.0):\n            # This indicates singularity but we proceed to allow for large errors.\n            continue\n            \n        # Compute multipliers and update the matrix\n        for i in range(k + 1, n):\n            multiplier = A[i, k] / A[k, k]\n            L[i, k] = multiplier\n            A[i, k:] -= multiplier * A[k, k:]\n            \n    np.fill_diagonal(L, 1.0)\n    U = np.triu(A)\n    return P, L, U\n\ndef forward_substitution(L, b):\n    \"\"\"Solves Ly = b for y, where L is lower-triangular.\"\"\"\n    n = L.shape[0]\n    y = np.zeros(n, dtype=float)\n    for i in range(n):\n        y[i] = b[i] - np.dot(L[i, :i], y[:i])\n    return y\n\ndef backward_substitution(U, y):\n    \"\"\"Solves Ux = y for x, where U is upper-triangular.\"\"\"\n    n = U.shape[0]\n    x = np.zeros(n, dtype=float)\n    for i in range(n - 1, -1, -1):\n        if np.isclose(U[i, i], 0.0):\n            x[i] = np.inf\n        else:\n            x[i] = (y[i] - np.dot(U[i, i + 1:], x[i + 1:])) / U[i, i]\n    return x\n\ndef inverse_lu(A):\n    \"\"\"Computes matrix inverse using LU decomposition.\"\"\"\n    n = A.shape[0]\n    P, L, U = lu_decomposition_pivoting(A)\n    I = np.identity(n)\n    X_LU = np.zeros((n, n), dtype=float)\n    \n    for j in range(n):\n        b_permuted = P @ I[:, j]\n        y = forward_substitution(L, b_permuted)\n        x_col = backward_substitution(U, y)\n        X_LU[:, j] = x_col\n        \n    return X_LU\n\ndef get_minor_matrix(A, i, j):\n    \"\"\"Returns the minor matrix by deleting row i and column j.\"\"\"\n    return np.delete(np.delete(A, i, axis=0), j, axis=1)\n\ndef determinant_recursive(A):\n    \"\"\"Computes determinant by recursive cofactor expansion.\"\"\"\n    n = A.shape[0]\n    if n == 1:\n        return A[0, 0]\n    if n == 2:\n        return A[0, 0] * A[1, 1] - A[0, 1] * A[1, 0]\n    \n    det = 0.0\n    for j in range(n):\n        sign = (-1)**j\n        minor_matrix = get_minor_matrix(A, 0, j)\n        det += sign * A[0, j] * determinant_recursive(minor_matrix)\n    return det\n\ndef inverse_cofactor(A):\n    \"\"\"Computes matrix inverse using the adjugate method.\"\"\"\n    n = A.shape[0]\n    det_A = determinant_recursive(A)\n    \n    if np.isclose(det_A, 0.0):\n        return np.full((n, n), np.nan)\n\n    cofactor_matrix = np.zeros((n, n), dtype=float)\n    for i in range(n):\n        for j in range(n):\n            sign = (-1)**(i + j)\n            minor_matrix = get_minor_matrix(A, i, j)\n            cofactor_matrix[i, j] = sign * determinant_recursive(minor_matrix)\n    \n    adjugate_matrix = cofactor_matrix.T\n    return adjugate_matrix / det_A\n\ndef calculate_error(A, X):\n    \"\"\"Computes the relative Frobenius norm residual error.\"\"\"\n    n = A.shape[0]\n    if np.any(np.isnan(X)) or np.any(np.isinf(X)):\n        return np.inf\n\n    I = np.identity(n)\n    residual_matrix = I - A @ X\n    norm_residual = np.linalg.norm(residual_matrix, 'fro')\n    norm_identity = np.sqrt(n)\n    \n    return norm_residual / norm_identity\n\ndef solve():\n    # Define the test cases from the problem statement.\n    A1 = np.identity(4, dtype=float)\n    \n    A2 = np.array([\n        [4., 2., 0., 1.],\n        [0., 1., 3., 2.],\n        [1., 0., 2., 0.],\n        [2., 3., 1., 0.]\n    ], dtype=float)\n    \n    A3 = np.zeros((4, 4), dtype=float)\n    for i in range(4):\n        for j in range(4):\n            A3[i, j] = 1.0 / (i + j + 1.0)\n            \n    epsilon = 1e-6\n    A4 = np.array([\n        [1., 1., 1., 1.],\n        [1., 1. + epsilon, 1., 1.],\n        [0., 0., 1., 0.],\n        [0., 0., 0., 1.]\n    ], dtype=float)\n    \n    x_vals = np.array([1e-4, 1.0, 2.0, 5.0], dtype=float)\n    A5 = np.vander(x_vals, 4, increasing=True)\n\n    test_cases = [A1, A2, A3, A4, A5]\n    results = []\n\n    for A in test_cases:\n        # Method 1: LU Inversion\n        X_lu = inverse_lu(A)\n        e_lu = calculate_error(A, X_lu)\n        results.append(e_lu)\n        \n        # Method 2: Cofactor Inversion\n        X_cof = inverse_cofactor(A)\n        e_cof = calculate_error(A, X_cof)\n        results.append(e_cof)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{r:.6e}' for r in results)}]\")\n\nsolve()\n```", "id": "3275824"}, {"introduction": "在掌握了 LU 分解作为通用工具的优势之后，我们进一步探索它与具有特殊结构的矩阵之间的相互作用。本练习聚焦于一类被称为 M-矩阵的重要矩阵，它们在许多应用领域（如经济学、工程学和马尔可夫链）中频繁出现。您将通过编程实现来验证 M-矩阵求逆的理论性质，并探究部分主元选择（一种标准的稳定性增强策略）是否会保持或破坏 M-矩阵固有的代数结构，从而加深对数值算法与矩阵结构之间关系的理解。[@problem_id:3539186]", "problem": "设计并实现一个完整的程序，该程序针对一族以非奇异单调矩阵（称为$M$-矩阵）为重点的矩阵，使用基于因式分解的方法计算矩阵的逆，并经验性地验证逆矩阵和因子的预期符号模式。您的程序必须遵循以下要求。\n\n基本推理依据：\n- 使用 $M$-矩阵的定义，即一个实数方阵，它是一个 $Z$-矩阵（所有非对角线元素均为非正），并且是非奇异的，其逆矩阵为非负矩阵。或者等效地，它可以表示为 $A = s I - B$ 的形式，其中 $B \\ge 0$（逐元素），且 $s \\ge \\rho(B)$，其中 $\\rho(B)$ 表示 $B$ 的谱半径。您的推导只能使用这些性质作为起点。\n- 使用下三角-上三角（LU）分解的标准定义：给定一个非奇异矩阵 $A \\in \\mathbb{R}^{n \\times n}$，无主元选择的分解旨在找到 $A = L U$，其中 $L$ 是单位下三角矩阵，$U$ 是上三角矩阵。对于部分主元选择，旨在找到 $P A = L U$，其中 $P$ 是一个置换矩阵。\n\n程序中要执行的任务：\n1. 仅基于上述基本定义实现两种算法：\n   - 算法 $1$：使用无任何主元选择的 $L U$ 分解计算 $A^{-1}$。使用前向和后向替换逐列求解 $A X = I$，其中 $I$ 是单位矩阵，$X = A^{-1}$。\n   - 算法 $2$：使用带部分（行）主元选择的 $L U$ 分解计算 $A^{-1}$，因此有 $P A = L U$。通过首先将行置换应用于右侧项，然后求解三角系统来求解 $A X = I$。\n\n2. 对每种算法，经验性地验证以下性质：\n   - $M$-矩阵逆矩阵的非负性：检查计算出的 $\\widehat{A^{-1}}$ 的所有元素在容差范围内是否在数值上为非负。\n   - 在无主元选择的情况下，计算出的上三角因子中 $Z$-矩阵结构的保持性：检查计算出的 $\\widehat{U}$ 的严格上三角部分的元素是否满足与 $Z$-矩阵一致的符号模式，即在数值上为非正。\n   - 主元选择对结构的影响：检查部分主元选择是否执行了任何行交换，并经验性地评估计算出的 $\\widehat{U}$ 的严格上三角部分是否保持非正性。\n\n3. 鲁棒性与容差：\n   - 令 $\\epsilon$ 表示双精度浮点数的机器精度。\n   - 对每个矩阵 $A$，将验证容差定义为 $\\tau = 100 \\cdot \\kappa_1(A) \\cdot \\epsilon \\cdot n$，其中 $\\kappa_1(A)$ 是 $A$ 在 $1$-范数下的条件数，$n$ 是维度。\n   - 在无主元选择的分解中，如果在任何步骤 $k$ 中 $|u_{kk}| \\le 10 \\epsilon \\|A\\|_{\\infty}$，则声明为零主元导致分解失败。报告是否发生失败。\n   - 所有符号检查必须在容差 $\\tau$ 的前提下进行，即如果一个元素 $x \\ge -\\tau$，则视为非负；如果 $x \\le \\tau$，则视为非正。\n\n测试套件，覆盖一般、边界和边缘场景：\n- 案例 $1$（结构化的严格对角占优 $M$-矩阵）：令 $n = 5$ 并定义 $A \\in \\mathbb{R}^{n \\times n}$，其中对所有 $i$，$a_{ii} = 2$；对 $i = 1,\\dots,n-1$，$a_{i,i+1} = -1$；对 $i = 1,\\dots,n-1$，$a_{i+1,i} = -1$；所有其他元素为 $0$。\n- 案例 $2$（具有良好优势的随机稠密 $M$-矩阵）：令 $n = 6$。使用等于整数 $7$ 的固定种子生成 $B \\in \\mathbb{R}^{n \\times n}$，其独立元素在 $[0, 0.2]$ 上均匀分布，然后对所有 $i$ 设置 $b_{ii} = 0$。设置 $s = 1.5$ 并定义 $A = s I - B$。\n- 案例 $3$（近奇异 $M$-矩阵）：令 $n = 7$。使用等于整数 $11$ 的固定种子生成 $B$，其独立元素在 $[0, 0.3]$ 上均匀分布，然后对所有 $i$ 设置 $b_{ii} = 0$。令 $r_i = \\sum_{j \\ne i} b_{ij}$ 为非对角线行和，并设置 $s = \\max_i r_i + 10^{-8}$。定义 $A = s I - B$。\n- 案例 $4$（用于探究非负性失效的非 $M$-矩阵）：令 $n = 5$。定义 $A = I + \\alpha N$，其中 $\\alpha = 1/2$，$I$ 是单位矩阵，$N$ 是幂零严格上双对角矩阵，其第一超对角线上有 $n-1$ 个 $1$，其他地方为零。\n\n每个案例的所需输出：\n- 对每个案例，按以下顺序生成一个包含六个条目的列表：\n  $1$。一个布尔值，指示无主元 $L U$ 分解是否在没有零主元失败的情况下完成。\n  $2$。一个布尔值，指示部分主元选择是否执行了至少一次行交换。\n  $3$。一个布尔值，指示来自无主元 $L U$ 分解的 $\\widehat{U}$ 的严格上三角部分在容差 $\\tau$ 下是否在数值上为非正。\n  $4$。一个布尔值，指示来自部分主元 $L U$ 分解的 $\\widehat{U}$ 的严格上三角部分在容差 $\\tau$ 下是否在数值上为非正。\n  $5$。一个布尔值，指示由无主元 $L U$ 计算的逆矩阵的所有元素在容差 $\\tau$ 下是否在数值上为非负。\n  $6$。一个布尔值，指示由部分主元 $L U$ 计算的逆矩阵的所有元素在容差 $\\tau$ 下是否在数值上为非负。\n\n最终输出格式：\n- 程序必须生成单行文本，其中包含一个由四个内部列表组成的列表，每个内部列表对应一个案例，按案例 $1$ 到 $4$ 的顺序排列。该行必须采用 $[\\text{case1}, \\text{case2}, \\text{case3}, \\text{case4}]$ 的形式，其中每个 $\\text{casek}$ 是其如上所述的六元素布尔值列表，例如 $[[\\text{True},\\text{False},\\dots],[\\dots],\\dots]$。\n- 此任务不涉及物理单位。", "solution": "该问题要求实现并分析两种基于下三角-上三角（$LU$）分解计算矩阵逆 $A^{-1}$ 的算法。分析重点是一类被称为 $M$-矩阵的特殊矩阵，并验证它们的特征性质，例如逆矩阵的非负性以及 $LU$ 因子的符号模式。\n\n### 理论基础\n\n一个 $n \\times n$ 的实数矩阵 $A$ 如果其所有非对角线元素都非正（即对于所有 $i \\ne j$，$a_{ij} \\le 0$），则被称为 $Z$-矩阵。一个 $M$-矩阵是一个非奇异的 $Z$-矩阵，其逆矩阵是逐元素非负的（$A^{-1} \\ge 0$）。一个等价的特征描述（这对于构建测试案例很有用）是，如果一个矩阵 $A$ 可以表示为 $A = sI - B$，其中 $B$ 是一个具有非负元素的矩阵（$B \\ge 0$），$I$ 是单位矩阵，$s$ 是一个大于或等于 $B$ 的谱半径 $\\rho(B)$ 的标量，并且当 $s = \\rho(B)$ 时非奇异性条件成立，那么 $A$ 就是一个 $M$-矩阵。\n\n数值线性代数中的一个关键理论结果指出，如果 $A$ 是一个非奇异的 $M$-矩阵，那么其无主元选择的 $LU$ 分解存在且数值稳定，并且得到的因子 $L$ 和 $U$ 也都是非奇异的 $M$-矩阵。由于 $L$ 根据定义是单位下三角矩阵，其对角线元素为 $1$。要使 $L$ 成为一个 $M$-矩阵，其非对角线元素必须为非正。同样，要使上三角因子 $U$ 成为一个 $M$-矩阵，其对角线元素必须为正（$u_{kk} > 0$），且其非对角线元素必须为非正（对于 $i  j$, $u_{ij} \\le 0$）。这些性质构成了验证任务的基础。\n\n### 算法设计与求逆\n\n核心任务是求解矩阵方程 $AX = I$，其中 $X$ 是所求的逆矩阵 $A^{-1}$，$I$ 是单位矩阵。这是逐列求解的。对于单位矩阵的每一列 $e_j$，我们求解线性系统 $Ax_j = e_j$ 以找到 $A^{-1}$ 对应的列 $x_j$。LU 分解方法将此系统解耦为两个更简单的三角系统。\n\n**算法 1：通过无主元选择的 $LU$ 分解求逆**\n\n该算法首先将矩阵 $A$ 分解为一个单位下三角矩阵 $L$ 和一个上三角矩阵 $U$ 的乘积，使得 $A=LU$。此分解过程使用高斯消元法完成。在消元的每一步 $k$ 中，主元 $u_{kk}$ 被用来将其下方第 $k$ 列的元素消为零。所使用的乘数存储在 $L$ 的相应位置。对于一般矩阵，如果主元 $u_{kk}$ 为零或非常小，此过程可能会失败或变得数值不稳定。问题指定了一个分解失败条件：如果在任何步骤 $k$ 中 $|u_{kk}| \\le 10 \\epsilon \\|A\\|_{\\infty}$，其中 $\\epsilon$ 是机器精度，$\\|A\\|_{\\infty}$ 是 $A$ 的无穷范数，则认为分解失败。对于非奇异的 $M$-矩阵，理论保证所有主元 $u_{kk}$ 都将是正的，因此不应发生分解失败。\n\n一旦获得分解 $A=LU$，每个系统 $Ax_j=e_j$ 就变成了 $LUx_j=e_j$。这可以通过两个步骤求解：\n1.  **前向替换：** 求解 $Ly_j = e_j$ 得到中间向量 $y_j$。\n2.  **后向替换：** 求解 $Ux_j = y_j$ 得到解向量 $x_j$。\n\n向量集合 $\\{x_j\\}_{j=1}^n$ 构成了 $A^{-1}$ 的各列。\n\n**算法 2：通过部分主元选择的 $LU$ 分解求逆**\n\n为了增强一般矩阵的数值稳定性，采用了部分主元选择（行交换）。该算法寻求一个分解 $PA=LU$，其中 $P$ 是一个置换矩阵，代表了在高斯消元过程中为确保当前列中绝对值最大的元素被用作主元而执行的行交换。\n\n系统 $Ax_j=e_j$ 使用该分解重写为 $P^{-1}LUx_j = e_j$，可整理为 $LUx_j = Pe_j$。注意，$Pe_j$ 只是置换矩阵 $P$ 的第 $j$ 列，这对应于基向量 $e_j$ 的重新排序。求解过程与无主元选择的情况类似：\n1.  **前向替换：** 求解 $Ly_j = Pe_j$ 得到 $y_j$。\n2.  **后向替换：** 求解 $Ux_j = y_j$ 得到 $x_j$。\n\n虽然主元选择对于一般矩阵的稳定性至关重要，但它可能会破坏像 $M$-矩阵这类矩阵的特殊结构。具体来说，即使原始矩阵 $A$ 是一个 $M$-矩阵（对于这种矩阵，无主元 LU 分解是稳定的），得到的因子 $U$ 可能不再是 $Z$-矩阵（即其严格上三角部分的元素可能不全是非正的）。\n\n### 验证与容差\n\n使用浮点数进行的数值计算会受到舍入误差的影响。为了稳健地检查非负性（$x \\ge 0$）或非正性（$x \\le 0$），一个数值容差 $\\tau$ 是必不可少的。问题定义了一个随矩阵维度 $n$、机器精度 $\\epsilon$ 和矩阵在 $1$-范数下的条件数 $\\kappa_1(A)$ 变化的容差：\n$$ \\tau = 100 \\cdot \\kappa_1(A) \\cdot \\epsilon \\cdot n $$\n该容差考虑了这样一个事实：求解线性系统中的误差放大与条件数成正比。如果一个元素 $x \\ge -\\tau$，则认为其在数值上非负；如果 $x \\le \\tau$，则认为其在数值上非正。所要求的检查将 $M$-矩阵的理论性质与这两种算法的结果进行经验性对比，观察数值计算的现实情况和算法选择（主元选择）如何与理论相互作用。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import lu, solve_triangular\n\ndef analyze_matrix(A: np.ndarray) -> list:\n    \"\"\"\n    Performs LU-based inversion and property verification for a given matrix A.\n    \n    Returns a list of 6 boolean values corresponding to the problem checks.\n    \"\"\"\n    n = A.shape[0]\n    eps = np.finfo(float).eps\n    \n    # Calculate norms and condition number needed for tolerances.\n    # A nearly singular matrix can have an 'inf' condition number.\n    # We cap it to a large number to avoid making tau infinite.\n    cond_A_1 = np.linalg.cond(A, p=1)\n    if np.isinf(cond_A_1) or np.isnan(cond_A_1):\n        cond_A_1 = 1.0 / eps\n\n    tau = 100.0 * cond_A_1 * eps * float(n)\n    norm_A_inf = np.linalg.norm(A, ord=np.inf)\n\n    # --- Algorithm 1: No Pivoting ---\n    \n    # Custom LU implementation to include the pivot breakdown check.\n    U_no_pivot = A.copy().astype(np.float64)\n    L_no_pivot = np.identity(n, dtype=np.float64)\n    no_pivot_completed = True\n    \n    for k in range(n - 1):\n        # Pivot breakdown check\n        if abs(U_no_pivot[k, k]) = 10.0 * eps * norm_A_inf:\n            no_pivot_completed = False\n            break\n        for i in range(k + 1, n):\n            factor = U_no_pivot[i, k] / U_no_pivot[k, k]\n            L_no_pivot[i, k] = factor\n            U_no_pivot[i, k:] -= factor * U_no_pivot[k, k:]\n\n    # Final pivot check for the last element on the diagonal of U\n    if no_pivot_completed and abs(U_no_pivot[n - 1, n - 1]) = 10.0 * eps * norm_A_inf:\n        no_pivot_completed = False\n\n    # Check 1: No-pivot LU completed without zero pivot breakdown.\n    res1 = no_pivot_completed\n\n    res3 = False # Check 3: Is upper-triangular U from no-pivot a Z-matrix?\n    res5 = False # Check 5: Is inverse from no-pivot non-negative?\n\n    if res1:\n        U_strict_upper = np.triu(U_no_pivot, k=1)\n        res3 = np.all(U_strict_upper = tau)\n        \n        # Compute inverse using LU factors\n        I = np.identity(n, dtype=np.float64)\n        A_inv_no_pivot = np.zeros_like(A, dtype=np.float64)\n        for j in range(n):\n            y = solve_triangular(L_no_pivot, I[:, j], lower=True, unit_diagonal=True)\n            A_inv_no_pivot[:, j] = solve_triangular(U_no_pivot, y, lower=False)\n        \n        res5 = np.all(A_inv_no_pivot >= -tau)\n\n    # --- Algorithm 2: Partial Pivoting ---\n    \n    try:\n        P_mat, L_pivot, U_pivot = lu(A)\n        pivoting_successful = True\n    except (np.linalg.LinAlgError, ValueError):\n        # LU may fail for singular matrix, handle gracefully\n        pivoting_successful = False\n\n    res2 = False # Check 2: Partial pivoting performed at least one row swap.\n    res4 = False # Check 4: Is upper-triangular U from partial-pivot a Z-matrix?\n    res6 = False # Check 6: Is inverse from partial-pivot non-negative?\n\n    if pivoting_successful:\n        res2 = not np.array_equal(P_mat, np.identity(n))\n        \n        U_pivot_strict_upper = np.triu(U_pivot, k=1)\n        res4 = np.all(U_pivot_strict_upper = tau)\n        \n        # Compute inverse using PLU factors\n        # The equation is PA = LU => A = P.T @ L @ U\n        # To solve AX=I, it's P.T @ L @ U @ X = I => L @ U @ X = P @ I\n        PI = P_mat @ np.identity(n)\n        A_inv_pivot = np.zeros_like(A, dtype=np.float64)\n        for j in range(n):\n            y = solve_triangular(L_pivot, PI[:, j], lower=True, unit_diagonal=True)\n            A_inv_pivot[:, j] = solve_triangular(U_pivot, y, lower=False)\n        \n        res6 = np.all(A_inv_pivot >= -tau)\n\n    return [res1, res2, res3, res4, res5, res6]\n\ndef solve():\n    \"\"\"\n    Main function to run all test cases and print the final result.\n    \"\"\"\n    test_cases = []\n\n    # Case 1: Structured strictly diagonally dominant M-matrix\n    n1 = 5\n    A1 = np.diag([2.0] * n1) + np.diag([-1.0] * (n1 - 1), k=1) + np.diag([-1.0] * (n1 - 1), k=-1)\n    test_cases.append(A1)\n\n    # Case 2: Random dense M-matrix with comfortable dominance\n    n2 = 6\n    rng2 = np.random.default_rng(7)\n    B2 = rng2.uniform(0, 0.2, size=(n2, n2))\n    np.fill_diagonal(B2, 0)\n    s2 = 1.5\n    A2 = s2 * np.identity(n2) - B2\n    test_cases.append(A2)\n\n    # Case 3: Nearly singular M-matrix\n    n3 = 7\n    rng3 = np.random.default_rng(11)\n    B3 = rng3.uniform(0, 0.3, size=(n3, n3))\n    np.fill_diagonal(B3, 0)\n    r3 = np.sum(B3, axis=1) # off-diagonal row sums\n    s3 = np.max(r3) + 1e-8\n    A3 = s3 * np.identity(n3) - B3\n    test_cases.append(A3)\n\n    # Case 4: Non-M-matrix to probe failure of nonnegativity\n    n4 = 5\n    I4 = np.identity(n4)\n    N4 = np.diag([1.0] * (n4 - 1), k=1)\n    alpha4 = 0.5\n    A4 = I4 + alpha4 * N4\n    test_cases.append(A4)\n\n    results = []\n    for A in test_cases:\n        case_results = analyze_matrix(A)\n        results.append(case_results)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3539186"}, {"introduction": "对数值误差的来源和分布进行量化分析，是数值线性代数研究的核心。这个练习将引导您在一个“可控”的环境中进行误差分析，即所使用的矩阵 $A$ 具有已知的谱分解 $A = Q^\\top D Q$。这种构造使得我们可以精确知道其逆矩阵 $A^{-1}$，从而能够将 LU 分解计算出的近似逆矩阵与之对比，并最终揭示出计算误差与矩阵谱（即其特征值）之间的深刻定量关系，特别是与条件数 $\\kappa_2(A)$ 的联系。[@problem_id:3539201]", "problem": "要求您设计并实现一个完整的、可运行的程序，该程序对一类结构化矩阵通过下三角-上三角 (LU) 分解构造逆矩阵的过程进行基准测试，并定量解释观测到的数值误差如何与矩阵的谱相关。整个过程应完全以纯数学术语进行，并生成在多次执行中具有确定性和可复现性的数值输出。\n\n从以下基础出发：\n- 一个非奇异矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 的带部分主元法的 LU 分解由一个置换矩阵 $P$、一个单位下三角矩阵 $L$ 和一个上三角矩阵 $U$ 定义，使得 $P A = L U$。在应用 $P$ 后，可以通过对 $(L, U)$ 进行前向替换和后向回代来稳定地求解 $A x = b$。\n- 逆矩阵 $A^{-1}$ 是满足 $A A^{-1} = I$ 和 $A^{-1} A = I$ 的线性算子，其中 $I$ 是单位矩阵。$A^{-1}$ 的各列可以通过求解线性方程组 $A x_j = e_j$ 的唯一解来获得，其中 $e_j$ 是第 $j$ 个标准基向量。\n- 一个正交矩阵 $Q \\in \\mathbb{R}^{n \\times n}$ 满足 $Q^\\top Q = I$。一个对角矩阵 $D = \\mathrm{diag}(d_1,\\dots,d_n)$ 在对角线上的元素为 $d_i \\neq 0$，其他位置的元素为 $0$。\n\n问题设定：\n- 对于每个测试用例，考虑一个矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其构造为 $A = Q^\\top D Q$，其中 $Q$ 是正交矩阵，$D$ 是具有非零元素的对角矩阵。其逆矩阵 $A^{-1}$ 可以从第一性原理推导出闭式解，且必须仅使用上面陈述的正交矩阵和对角矩阵的性质进行推导。不要使用任何预先推导出的公式；从基本定义出发进行推理以获得解析表达式。\n- 通过计算 $A$ 的 LU 分解并使用三角求解法求解 $A X = I$ 以得到 $X$，来构造 $A^{-1}$ 的数值近似。这个 $X$ 就是您基于 LU 的 $A^{-1}$ 近似值。\n- 定义弗罗贝尼乌斯范数下的全局相对误差为\n$$\n\\mathrm{frel} = \\frac{\\lVert X - A^{-1}\\rVert_F}{\\lVert A^{-1}\\rVert_F}.\n$$\n- 为了将误差模式映射到编码在 $D$ 中的谱上，通过计算\n$$\nE = X - A^{-1}, \\quad \\widetilde{E} = Q\\, E\\, Q^\\top,\n$$\n将误差转换到 $A$ 的特征基中，使得 $\\widetilde{E}$ 在 $A$ 是对角矩阵的基中表示。对于每个特征方向 $i \\in \\{1,\\dots,n\\}$，定义逐方向相对对角误差\n$$\n\\epsilon_i = \\frac{\\left| \\widetilde{E}_{ii} \\right|}{\\left| (A^{-1})_{ii} \\text{ in the eigenbasis} \\right|}.\n$$\n通过计算 $\\log_{10}(|d_i|)$ 和 $\\log_{10}(\\epsilon_i)$ 之间的皮尔逊相关系数来聚合逐方向的趋势，在对 $\\epsilon_i$ 应用的对数中使用一个小的加性正则化项 $\\delta$ 以避免计算 $\\log_{10}(0)$。使用 $\\delta = 10^{-300}$。如果 $\\log_{10}(|d_i|)$ 的方差为零（例如，当所有 $|d_i|$ 相等时），按惯例将相关性定义为 $0.0$。\n- 通过 2-范数条件数来量化谱的条件\n$$\n\\kappa_2(A) = \\frac{\\sigma_{\\max}(A)}{\\sigma_{\\min}(A)},\n$$\n对于对称矩阵 $A$，这等于 $\\max_i |d_i| / \\min_i |d_i|$。\n\n测试套件规范：\n对于所有测试用例，使用维度 $n = 12$。对于每个用例，通过以下过程生成 $Q$ 以确保可复现性和明确定义的分布：使用指定的伪随机数生成器种子 $s$，抽取一个具有独立标准正态分布元素的矩阵 $Z \\in \\mathbb{R}^{n \\times n}$；计算一个瘦 QR 分解 $Z = Q R$；令 $S = \\mathrm{diag}(\\mathrm{sign}(R_{11}), \\dots, \\mathrm{sign}(R_{nn}))$，其中 $\\mathrm{sign}(0)$ 定义为 $1$；设置 $Q \\leftarrow Q S$。这将得到一个正交矩阵 $Q$。然后用指定的对角矩阵 $D$ 形成 $A = Q^\\top D Q$。\n\n提供以下四种情况，涵盖理想情况、病态、不定性和谱聚类：\n- 情况 1 (理想情况，良态)：种子 $s = 0$，$D = \\mathrm{diag}(1,1,\\dots,1)$。\n- 情况 2 (对称正定，高度病态)：种子 $s = 1$，$D = \\mathrm{diag}(10^{-6}, 10^{-6 + \\Delta}, \\dots, 10^{6})$，其中包含 $n$ 个从 $10^{-6}$ 到 $10^{6}$ 对数等距分布的量级。\n- 情况 3 (对称不定，中度病态，符号交替)：种子 $s = 2$，$D = \\mathrm{diag}(\\sigma_1,\\dots,\\sigma_n)$，其中 $|\\sigma_i|$ 从 $10^{-3}$ 到 $10^{3}$ 对数等距分布，且 $\\mathrm{sign}(\\sigma_i) = (-1)^{i}$。\n- 情况 4 (谱聚类，含微小和中等尺度)：种子 $s = 3$，$D$ 有十个对角元素等于 $10^{-6}$，两个元素等于 $1$，它们的顺序使用相同的种子 $s$ 随机排列。\n\n每个测试用例的所需输出：\n- 计算并返回一个包含三个实数的列表，顺序为 $[\\mathrm{frel}, \\mathrm{corr}, \\kappa_2(A)]$，其中 $\\mathrm{corr}$ 是上述的皮尔逊相关系数。\n- 您的程序应生成单行输出，其中包含四个用例的结果，格式为一个由逗号分隔的列表，并用方括号括起来，其中每个元素本身是按指定顺序排列的三元素列表（例如, $[[a_1,b_1,c_1],[a_2,b_2,c_2],[a_3,b_3,c_3],[a_4,b_4,c_4]]$）。不应打印任何其他文本。\n\n所有数值量必须以浮点运算计算，并报告为不带单位的纯实数。如果出现任何角度，必须理解为弧度，但本任务中不使用角度。", "solution": "该问题要求我们分析使用 LU 分解计算一类特定矩阵 $A = Q^\\top D Q$ 的逆矩阵时产生的数值误差，并将此误差与矩阵的谱联系起来。我们必须首先验证问题的前提，如果前提有效，则提供一个完整的解析和数值解。该问题是适定的 (well-posed)，在数值线性代数方面有科学依据，并为确定性和可复现的解决方案提供了所有必要信息。因此，我们可以继续进行。\n\n解决过程包括三个主要阶段：\n1.  从第一性原理推导逆矩阵 $A^{-1}$ 的解析形式。这将作为我们误差计算的基准真相 (ground truth)。\n2.  指定使用 LU 分解计算逆矩阵近似值 $X$ 的数值算法。\n3.  定义并计算指定的误差度量（$\\mathrm{frel}$、$\\mathrm{corr}$）和条件数（$\\kappa_2(A)$）。\n\n**1. 逆矩阵的解析推导**\n\n矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 由 $A = Q^\\top D Q$ 给出，其中 $Q$ 是满足 $Q^\\top Q = Q Q^\\top = I$ 的正交矩阵，$D = \\mathrm{diag}(d_1, \\dots, d_n)$ 是对角线元素非零 ($d_i \\neq 0$) 的对角矩阵。逆矩阵 $A^{-1}$ 由属性 $A A^{-1} = I$ 定义。\n\n为了找到 $A^{-1}$ 的表达式，我们从定义开始：\n$$\n(Q^\\top D Q) A^{-1} = I\n$$\n我们试图分离出 $A^{-1}$。我们可以在等式两边同时左乘 $Q$：\n$$\nQ (Q^\\top D Q) A^{-1} = Q I\n$$\n使用矩阵乘法的结合律，我们对项进行分组：\n$$\n(Q Q^\\top) (D Q) A^{-1} = Q\n$$\n由于 $Q$ 是正交的，$Q Q^\\top = I$。方程简化为：\n$$\nI (D Q) A^{-1} = Q \\implies (D Q) A^{-1} = Q\n$$\n接下来，我们左乘 $D$ 的逆矩阵。由于 $D$ 是一个具有非零元素 $d_i$ 的对角矩阵，其逆矩阵 $D^{-1}$ 就是对角元素为 $1/d_i$ 的对角矩阵，即 $D^{-1} = \\mathrm{diag}(1/d_1, \\dots, 1/d_n)$。左乘得到：\n$$\nD^{-1} (D Q) A^{-1} = D^{-1} Q\n$$\n$$\n(D^{-1} D) (Q A^{-1}) = D^{-1} Q\n$$\n由于 $D^{-1} D = I$，我们有：\n$$\nI (Q A^{-1}) = D^{-1} Q \\implies Q A^{-1} = D^{-1} Q\n$$\n最后，为了分离出 $A^{-1}$，我们左乘 $Q^\\top$。由于 $Q^{-1}=Q^\\top$：\n$$\nQ^\\top (Q A^{-1}) = Q^\\top D^{-1} Q\n$$\n$$\n(Q^\\top Q) A^{-1} = Q^\\top D^{-1} Q\n$$\n由于 $Q^\\top Q = I$，我们得到了解析逆矩阵的闭式表达式：\n$$\nA^{-1} = Q^\\top D^{-1} Q\n$$\n该表达式将用作精确的基准真相，与数值近似值进行比较。\n\n**2. 逆矩阵的数值计算**\n\n逆矩阵的数值近似值，记为 $X$，通过求解矩阵方程 $AX=I$ 来找到。这是一种标准方法，其中 $X$ 的每一列（设为 $x_j$）是线性系统 $Ax_j = e_j$ 的解，其中 $e_j$ 是第 $j$ 个标准基向量（单位矩阵 $I$ 的第 $j$ 列）。\n\n该过程利用带部分主元法的 LU 分解。首先，我们将 $A$ 分解为 $P A = L U$，其中 $P$ 是一个置换矩阵，$L$ 是一个单位下三角矩阵，$U$ 是一个上三角矩阵。然后，系统 $A x_j = e_j$ 被重写为 $P^{-1} L U x_j = e_j$，或 $L U x_j = P e_j$。对于每一列 $e_j$，我们分两步求解该系统：\n- 前向替换：求解 $L y_j = P e_j$ 得到中间向量 $y_j$。\n- 后向回代：求解 $U x_j = y_j$ 得到解向量 $x_j$。\n\n对所有列 $j=1, \\dots, n$ 执行这些步骤，以构建完整的矩阵 $X = [x_1, \\dots, x_n]$。\n\n**3. 误差度量与谱分析**\n\n有了精确的逆矩阵 $A^{-1}$ 及其数值近似 $X$，我们就可以量化误差及其与 $A$ 的谱的关系。\n\n- **全局相对误差 ($\\mathrm{frel}$)**：总误差以弗罗贝尼乌斯范数衡量。误差矩阵为 $E = X - A^{-1}$。相对误差为：\n$$\n\\mathrm{frel} = \\frac{\\lVert X - A^{-1}\\rVert_F}{\\lVert A^{-1}\\rVert_F} = \\frac{\\lVert E \\rVert_F}{\\lVert A^{-1}\\rVert_F}\n$$\n其中矩阵 $M$ 的弗罗贝尼乌斯范数为 $\\lVert M \\rVert_F = \\sqrt{\\sum_{i,j} |M_{ij}|^2}$。\n\n- **特征基中的误差与相关性 ($\\mathrm{corr}$)**：矩阵构造 $A = Q^\\top D Q$ 是 $A$ 的谱分解，因为 $A$ 是对称的（$A^\\top = (Q^\\top D Q)^\\top = Q^\\top D^\\top Q = Q^\\top D Q = A$）。$A$ 的特征值是 $D$ 的对角元素 $d_i$，相应的特征向量是 $Q^\\top$ 的列向量。为了在该特征基中分析误差，我们将误差矩阵 $E$ 变换到这个基中：\n$$\n\\widetilde{E} = Q E Q^\\top\n$$\n在这个基中，矩阵 $A$ 是对角的（$Q A Q^\\top = D$），其逆矩阵也是对角的（$Q A^{-1} Q^\\top = D^{-1}$）。$\\widetilde{E}$ 的对角元素（记为 $\\widetilde{E}_{ii}$）表示沿每个特征方向的误差分量。逐方向相对对角误差 $\\epsilon_i$ 定义为误差分量的幅值相对于该方向上真实逆矩阵分量幅值的比值：\n$$\n\\epsilon_i = \\frac{\\left| \\widetilde{E}_{ii} \\right|}{\\left| (A^{-1})_{ii} \\text{ in the eigenbasis} \\right|} = \\frac{|\\widetilde{E}_{ii}|}{|(D^{-1})_{ii}|} = |\\widetilde{E}_{ii}| |d_i|\n$$\n然后我们计算皮尔逊相关系数 $\\mathrm{corr}$，它衡量的是两个向量 $u$ 和 $v$ 之间的线性关系，其分量分别为 $u_i = \\log_{10}(|d_i|)$ 和 $v_i = \\log_{10}(\\epsilon_i + \\delta)$，其中 $\\delta=10^{-300}$ 是一个小的正则化项。正相关表示对于较大的特征值，误差也较大；而负相关则表示对于较小的特征值，误差较大。按照惯例，如果 $u_i$ 的方差为零（即所有 $|d_i|$ 相等），则相关性定义为 $0.0$。\n\n- **条件数 ($\\kappa_2(A)$)**：矩阵的 2-范数条件数是其最大奇异值与最小奇异值之比，$\\kappa_2(A) = \\sigma_{\\max}(A) / \\sigma_{\\min}(A)$。对于像 $A$ 这样的对称矩阵，奇异值是特征值的绝对值。由于 $A$ 的特征值是 $D$ 的元素 $d_i$，因此奇异值为 $|d_i|$。所以，条件数由下式给出：\n$$\n\\kappa_2(A) = \\frac{\\max_i |d_i|}{\\min_i |d_i|}\n$$\n该量度量了 $Ax=b$ 的解对 $A$ 和 $b$ 中扰动的敏感性。大的 $\\kappa_2(A)$ 表示矩阵是病态的，其数值计算预计精度较低。\n\n实现将按以下步骤进行：为每个测试用例构造矩阵，执行所述的数值计算，并报告三个指定的量：$[\\mathrm{frel}, \\mathrm{corr}, \\kappa_2(A)]$。", "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Computes and benchmarks matrix inverse via LU factorization for four test cases.\n    \"\"\"\n    \n    n = 12\n    delta = 10**-300.0\n\n    test_cases_spec = [\n        {'s': 0, 'case_type': 'identity'},\n        {'s': 1, 'case_type': 'spd_ill_cond'},\n        {'s': 2, 'case_type': 'indefinite_ill_cond'},\n        {'s': 3, 'case_type': 'clustered_spectrum'},\n    ]\n\n    all_results = []\n\n    for spec in test_cases_spec:\n        s = spec['s']\n        case_type = spec['case_type']\n\n        # 1. Generate the orthogonal matrix Q\n        rng = np.random.default_rng(s)\n        Z = rng.standard_normal((n, n))\n        Q_qr, R_qr = np.linalg.qr(Z)\n        \n        # Ensure a unique Q by forcing the diagonal of R to be positive\n        signs = np.sign(np.diag(R_qr))\n        signs[signs == 0] = 1.0  # As per problem, sign(0) is 1\n        S = np.diag(signs)\n        Q = Q_qr @ S\n\n        # 2. Construct the diagonal matrix D for the current case\n        if case_type == 'identity':\n            d = np.ones(n)\n        elif case_type == 'spd_ill_cond':\n            d = np.logspace(-6, 6, n)\n        elif case_type == 'indefinite_ill_cond':\n            mags = np.logspace(-3, 3, n)\n            sign_vec = (-1.0) ** np.arange(n)\n            d = mags * sign_vec\n        elif case_type == 'clustered_spectrum':\n            d_vals = [10**-6.0] * 10 + [1.0] * 2\n            rng_permute = np.random.default_rng(s)\n            rng_permute.shuffle(d_vals)\n            d = np.array(d_vals)\n        \n        D = np.diag(d)\n        \n        # 3. Construct the matrix A\n        A = Q.T @ D @ Q\n\n        # 4. Compute the analytical inverse A_inv_true\n        D_inv = np.diag(1.0 / d)\n        A_inv_true = Q.T @ D_inv @ Q\n\n        # 5. Compute the numerical inverse X using LU factorization\n        lu, piv = linalg.lu_factor(A)\n        I = np.eye(n)\n        X = linalg.lu_solve((lu, piv), I)\n\n        # 6. Compute the required metrics\n        \n        # frel: Global relative error\n        E = X - A_inv_true\n        frel = np.linalg.norm(E, 'fro') / np.linalg.norm(A_inv_true, 'fro')\n        \n        # kappa_2: Condition number\n        kappa_2 = np.max(np.abs(d)) / np.min(np.abs(d))\n        \n        # corr: Pearson correlation coefficient\n        log_d_abs = np.log10(np.abs(d))\n        \n        if np.var(log_d_abs) == 0:\n            corr = 0.0\n        else:\n            E_tilde = Q @ E @ Q.T\n            E_tilde_diag = np.diag(E_tilde)\n            \n            # Per-direction relative diagonal error\n            epsilon = np.abs(E_tilde_diag) * np.abs(d)\n            \n            log_epsilon = np.log10(epsilon + delta)\n            \n            # Pearson correlation\n            corr_matrix = np.corrcoef(log_d_abs, log_epsilon)\n            corr = corr_matrix[0, 1]\n\n        all_results.append(f\"[{frel},{corr},{kappa_2}]\")\n\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3539201"}]}