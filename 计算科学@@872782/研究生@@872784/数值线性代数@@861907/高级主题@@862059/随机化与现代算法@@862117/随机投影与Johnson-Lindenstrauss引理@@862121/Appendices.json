{"hands_on_practices": [{"introduction": "理想的 Johnson-Lindenstrauss (JL) 变换通常依赖于一个完全随机的旋转。然而，在实践中如何生成这样的旋转呢？本练习旨在通过严格的数学推导，证明一个常用且易于实现的构造方法——对高斯随机矩阵进行 QR 分解——与从理论上完美的 Haar 测度中抽样是等价的。通过解决这个问题 [@problem_id:3570509]，你将深入理解高斯分布的旋转不变性，并确认我们实践中使用的工具在理论上是完美的。", "problem": "考虑一个由映射 $F_{W} : \\mathbb{R}^{d} \\to \\mathbb{R}^{k}$ 定义的 Johnson–Lindenstrauss 嵌入，该映射由 $F_{W}(x) = \\sqrt{\\frac{d}{k}} S W x$ 给出，其中 $S \\in \\mathbb{R}^{k \\times d}$ 是选择前 $k$ 个坐标的坐标投影算子，$W \\in \\mathrm{O}(d)$ 是一个正交矩阵。考虑 $W$ 的两种构造方法：\n- 从 $\\mathrm{O}(d)$ 上的哈尔测度中抽取的矩阵 $U$，其中哈尔测度是紧拓扑群 $\\mathrm{O}(d)$ 上唯一的左不变概率测度。\n- 通过对一个随机高斯矩阵 $G \\in \\mathbb{R}^{d \\times d}$ 进行 $\\mathrm{QR}$ 分解得到的矩阵 $Q$。$G$ 的元素 $G_{ij} \\sim \\mathcal{N}(0,1)$ 是独立的。即 $G = QR$，其中按照约定，$R$ 是上三角矩阵且对角线元素严格为正。\n\n设 $v \\in \\mathbb{R}^{d}$ 是一个固定的非零向量，定义映射 $F_{W}$ 对于差分 $v$ 的平方失真比为 $D_{W} = \\frac{\\|F_{W}(v)\\|_{2}^{2}}{\\|v\\|_{2}^{2}}$。设 $\\mathcal{L}(Q)$ 表示 $Q$ 的分布，$\\mu_{\\mathrm{Haar}}$ 表示 $\\mathrm{O}(d)$ 上的哈尔概率测度。定义与哈尔测度的全变差偏差为 $\\Delta = \\sup_{B \\subset \\mathrm{O}(d)} \\left| \\mathbb{P}(Q \\in B) - \\mu_{\\mathrm{Haar}}(B) \\right|$，其中上确界取遍 $\\mathrm{O}(d)$ 的所有波莱尔子集 $B$。定义两种构造方法之间的期望失真偏差为 $\\beta = \\mathbb{E}[D_{Q}] - \\mathbb{E}[D_{U}]$。\n\n从多元正态分布的旋转不变性和哈尔测度的定义性质出发，推导 $\\Delta$ 和 $\\beta$ 的闭式表达式。以一个包含 $\\Delta$ 和 $\\beta$（按此顺序）的行矩阵形式给出你的最终答案。无需四舍五入。此问题不涉及物理单位。", "solution": "用户希望我验证问题陈述，如果有效，则提供解答。\n\n### 第一步：提取已知条件\n- **映射：** $F_{W} : \\mathbb{R}^{d} \\to \\mathbb{R}^{k}$ 定义为 $F_{W}(x) = \\sqrt{\\frac{d}{k}} S W x$。\n- **$S$：** 一个 $k \\times d$ 矩阵，表示选择前 $k$ 个坐标的坐标投影算子。\n- **$W$：** 一个正交矩阵，$W \\in \\mathrm{O}(d)$。\n- **构造 U：** 一个从正交群 $\\mathrm{O}(d)$ 上的哈尔测度 $\\mu_{\\mathrm{Haar}}$ 中抽取的矩阵 $U$。\n- **构造 Q：** 一个通过对随机高斯矩阵 $G \\in \\mathbb{R}^{d \\times d}$进行 $\\mathrm{QR}$ 分解得到的矩阵 $Q$。$G$ 的元素是独立同分布的 $G_{ij} \\sim \\mathcal{N}(0,1)$。分解为 $G = QR$，其中 $R$ 是对角线元素严格为正的上三角矩阵。\n- **向量 $v$：** $\\mathbb{R}^{d}$ 中的一个固定的非零向量。\n- **平方失真比：** $D_{W} = \\frac{\\|F_{W}(v)\\|_{2}^{2}}{\\|v\\|_{2}^{2}}$。\n- **全变差偏差：** $\\Delta = \\sup_{B \\subset \\mathrm{O}(d)} \\left| \\mathbb{P}(Q \\in B) - \\mu_{\\mathrm{Haar}}(B) \\right|$，其中上确界取遍 $\\mathrm{O}(d)$ 的所有波莱尔子集 $B$。\n- **期望失真偏差：** $\\beta = \\mathbb{E}[D_{Q}] - \\mathbb{E}[D_{U}]$。\n- **任务：** 从多元正态分布的旋转不变性和哈尔测度的性质出发，推導 $\\Delta$ 和 $\\beta$ 的闭式表达式。\n\n### 第二步：使用已知条件验证问题\n该问题在随机矩阵理论和数值线性代数这一数学领域内是良定义的。\n- **科学基础：** 所提出的概念——$\\mathrm{O}(d)$ 上的哈尔测度、高斯矩阵的 QR 分解、全变差距离以及 Johnson-Lindenstrauss 嵌入——都是标准且严格定义的数学对象和理论。$Q$ 的分布与哈尔测度相关的假设是随机矩阵理论中的一个基石性结果。\n- **良构性：** 该问题要求计算两个明确定义的量 $\\Delta$ 和 $\\beta$。从特定原理（旋转不变性）出发的指令为推导提供了清晰的路径。\n- **客观性：** 问题陈述由形式化的数学定义构成，没有歧义或主观语言。\n- **完整性与一致性：** 提供了所有必要的定义。规定 $R$ 的对角线元素严格为正，确保了 QR 分解的唯一性，这是论证中的一个关键细节。\n\n该问题没有缺陷。它提出的情景，尽管最终答案很简单，但需要基于基本原理进行严格推导，从而检验对高斯随机矩阵与哈尔测度之间关系的理解。这种设置并非微不足道或故作高深，而是该领域中构建基于证明的问题的标准方式。\n\n### 第三步：结论与行动\n该问题是**有效的**。下面将提供完整的推导过程。\n\n### 推导过程\n\n求解需要推导 $\\Delta$ 和 $\\beta$ 的值。这取决于确定矩阵 $Q$ 的概率分布。\n\n**第一部分：$\\Delta$ 的推导**\n\n量 $\\Delta$ 是 $Q$ 的分布与 $\\mathrm{O}(d)$ 上的哈尔测度之间的全变差距离。我们将证明这两个分布是相同的，这意味着 $\\Delta=0$。\n\n设 $G$ 是一个 $d \\times d$ 矩阵，其元素 $G_{ij}$ 是独立同分布的标准正态随机变量，$G_{ij} \\sim \\mathcal{N}(0,1)$。$G$ 元素的联合概率密度函数由下式给出\n$$p(G) = \\prod_{i,j=1}^{d} \\frac{1}{\\sqrt{2\\pi}} \\exp\\left(-\\frac{G_{ij}^2}{2}\\right) = (2\\pi)^{-d^2/2} \\exp\\left(-\\frac{1}{2} \\sum_{i,j=1}^{d} G_{ij}^2\\right)$$\n这可以用弗罗贝尼乌斯范数或迹来表示：\n$$p(G) = (2\\pi)^{-d^2/2} \\exp\\left(-\\frac{1}{2} \\|G\\|_{\\mathrm{F}}^2\\right) = (2\\pi)^{-d^2/2} \\exp\\left(-\\frac{1}{2} \\mathrm{Tr}(G^T G)\\right)$$\n该分布的一个关键性质是其旋转不变性。设 $H \\in \\mathrm{O}(d)$ 是任意固定的正交矩阵。考虑随机矩阵 $G' = HG$。指数中的迹项变换如下：\n$$\\mathrm{Tr}((HG)^T(HG)) = \\mathrm{Tr}(G^T H^T H G) = \\mathrm{Tr}(G^T I G) = \\mathrm{Tr}(G^T G)$$\n这里我们使用了正交矩阵的性质 $H^T H = I$。由于变换 $G \\to HG$ 是一个线性变换，其变量替换的雅可比行列式为常数 $| \\det(H) |^d = (\\pm 1)^d = 1$。因此，$G'$ 的概率密度与 $G$ 的相同。这意味着 $G$ 的分布在正交变换下是左不变的：对于任何固定的 $H \\in \\mathrm{O}(d)$，随机矩阵 $HG$ 与 $G$ 具有相同的分布。我们记为 $HG \\sim G$。\n\n现在，设 $G = QR$ 是 $G$ 的唯一 QR 分解，其中 $Q \\in \\mathrm{O}(d)$ 且 $R$ 是对角线元素严格为正的上三角矩阵。这种分解对于几乎所有的矩阵 $G$（具体来说，对于任何可逆的 $G$）都是唯一的。\n由于 $HG \\sim G$，$HG$ 的唯一 QR 因子必须与 $G$ 的 QR 因子具有相同的联合分布。设 $HG$ 的 QR 分解为 $HG = Q'R'$。那么我们有 $(Q', R') \\sim (Q, R)$。\n\n我们也可以通过代数方法找到 $(Q', R')$ 和 $(Q, R)$ 之间的关系。我们有 $HG = (HQ)R$。由于 $H$ 和 $Q$ 都在 $\\mathrm{O}(d)$ 中，它们的乘积 $HQ$ 也在 $\\mathrm{O}(d)$ 中。矩阵 $R$ 是对角线元素严格为正的上三角矩阵。因此，$(HQ)R$ 是矩阵 $HG$ 的一个有效 QR 分解。根据这种分解的唯一性，我们必须有：\n$$Q' = HQ \\quad \\text{和} \\quad R' = R$$\n将分布等式 $(Q', R') \\sim (Q, R)$ 与代数恒等式 $Q' = HQ$ 结合，我们推断出 $Q$ 的分布必须满足：\n$$Q \\sim HQ \\quad \\text{对于所有固定的 } H \\in \\mathrm{O}(d)$$\n这个性质是随机矩阵 $Q$ 概率分布的左不变性的定义。紧拓扑群（如 $\\mathrm{O}(d)$）上的哈尔测度 $\\mu_{\\mathrm{Haar}}$ 是唯一的左不变概率测度。因此，$Q$ 的分布（我们可记为 $\\mathcal{L}(Q)$）必须是哈尔测度：\n$$\\mathcal{L}(Q) = \\mu_{\\mathrm{Haar}}$$\n现在我们可以计算 $\\Delta$。根据定义，\n$$\\Delta = \\sup_{B \\subset \\mathrm{O}(d)} \\left| \\mathbb{P}(Q \\in B) - \\mu_{\\mathrm{Haar}}(B) \\right|$$\n由于支配 $Q$ 的概率测度恰好是 $\\mu_{\\mathrm{Haar}}$，我们有 $\\mathbb{P}(Q \\in B) = \\mu_{\\mathrm{Haar}}(B)$ 对于任何波莱尔集 $B$。\n$$\\Delta = \\sup_{B \\subset \\mathrm{O}(d)} \\left| \\mu_{\\mathrm{Haar}}(B) - \\mu_{\\mathrm{Haar}}(B) \\right| = \\sup_{B \\subset \\mathrm{O}(d)} |0| = 0$$\n\n**第二部分：$\\beta$ 的推导**\n\n期望失真偏差定义为 $\\beta = \\mathbb{E}[D_{Q}] - \\mathbb{E}[D_{U}]$。\n根据定义，随机矩阵 $U$ 是从哈尔测度 $\\mu_{\\mathrm{Haar}}$ 中抽取的。在第一部分中，我们证明了随机矩阵 $Q$ 也遵循哈尔测度，即 $\\mathcal{L}(Q) = \\mu_{\\mathrm{Haar}}$。\n这意味着 $Q$ 和 $U$ 是同分布的随机矩阵。\n\n平方失真比 $D_W$ 是矩阵 $W$ 的一个函数：\n$$D_{W} = \\frac{\\|F_{W}(v)\\|_{2}^{2}}{\\|v\\|_{2}^{2}}$$\n如果两个随机变量 $X$ 和 $Y$ 同分布，那么对于任何定义良好的函数 $g$， $g(X)$ 和 $g(Y)$ 的期望值相等：$\\mathbb{E}[g(X)] = \\mathbb{E}[g(Y)]$。\n在我们的例子中，随机变量是矩阵 $Q$ 和 $U$，函数是 $D_W$。由于 $Q \\sim U$，因此：\n$$\\mathbb{E}[D_{Q}] = \\mathbb{E}[D_{U}]$$\n因此，期望失真偏差 $\\beta$ 为：\n$$\\beta = \\mathbb{E}[D_{Q}] - \\mathbb{E}[D_{U}] = 0$$\n\n为了完整起见，我们也可以计算这些期望的值。设 $W$ 是一个哈尔分布的正交矩阵。\n$$\\mathbb{E}[D_W] = \\mathbb{E}\\left[\\frac{\\|\\sqrt{\\frac{d}{k}} S W v\\|_{2}^{2}}{\\|v\\|_{2}^{2}}\\right] = \\frac{d}{k \\|v\\|_{2}^{2}} \\mathbb{E}[\\|S W v\\|_{2}^{2}]$$\n令向量 $y = Wv$。由于 $W$ 是哈尔分布的正交矩阵，且 $v$ 是一个固定向量，向量 $y$ 在 $\\mathbb{R}^d$ 中半径为 $\\|v\\|_2$ 的球面上均匀分布。这是旋转对称性的一个结果。设 $y = (y_1, y_2, \\dots, y_d)^T$。\n我们有 $\\|y\\|_2^2 = \\|Wv\\|_2^2 = v^T W^T W v = v^T v = \\|v\\|_2^2$。\n矩阵 $S$ 选择前 $k$ 个坐标，所以 $\\|Sy\\|_2^2 = \\sum_{i=1}^k y_i^2$。\n根据球面上均匀分布的对称性，每个分量平方的期望值是相同的：$\\mathbb{E}[y_i^2] = c$ 对于所有 $i=1, \\dots, d$。\n我们有 $\\sum_{i=1}^d \\mathbb{E}[y_i^2] = \\mathbb{E}\\left[\\sum_{i=1}^d y_i^2\\right] = \\mathbb{E}[\\|y\\|_2^2] = \\mathbb{E}[\\|v\\|_2^2] = \\|v\\|_2^2$。\n所以，$d \\cdot c = \\|v\\|_2^2$，这给出 $c = \\frac{\\|v\\|_2^2}{d}$。\n然后，我们需要的期望是：\n$$\\mathbb{E}[\\|S W v\\|_{2}^{2}] = \\mathbb{E}[\\|Sy\\|_2^2] = \\mathbb{E}\\left[\\sum_{i=1}^k y_i^2\\right] = \\sum_{i=1}^k \\mathbb{E}[y_i^2] = k \\cdot c = k \\frac{\\|v\\|_2^2}{d}$$\n将此代回 $\\mathbb{E}[D_W]$ 的表达式中：\n$$\\mathbb{E}[D_W] = \\frac{d}{k \\|v\\|_{2}^{2}} \\left( k \\frac{\\|v\\|_2^2}{d} \\right) = 1$$\n因此，$\\mathbb{E}[D_Q] = \\mathbb{E}[D_U] = 1$，这证实了它们的差 $\\beta$ 为 $0$。\n\n**结论：**\n全变差偏差 $\\Delta$ 为 $0$，因为标准高斯矩阵的 QR 分解得到的正交因子 $Q$ 的分布恰好是 $\\mathrm{O}(d)$ 上的哈尔测度。期望失真偏差 $\\beta$ 为 $0$，因为随机矩阵 $Q$ 和 $U$ 同分布，导致对这些矩阵的任何函数（包括失真比）的期望值都相同。\n\n最终答案将是包含 $\\Delta$ 和 $\\beta$ 的行矩阵。", "answer": "$$\\boxed{\\begin{pmatrix} 0  0 \\end{pmatrix}}$$", "id": "3570509"}, {"introduction": "尽管密集的随机投影（如高斯投影）在理论上性质优良，但其存储和计算成本在高维空间中可能令人望而却步。本练习将引导你探索一种更高效的替代方案：稀疏随机投影。你将通过构建一个“对抗性”点集来发掘稀疏投影的潜在弱点，并推导出保证其性能所需的最小稀疏度 [@problem_id:3570496]，从而深刻理解计算效率与嵌入质量之间的核心权衡。", "problem": "设 $d \\in \\mathbb{N}$，$m \\in \\mathbb{N}$，且 $2 \\leq n \\leq d$。考虑两类从 $\\mathbb{R}^{d}$ 到 $\\mathbb{R}^{m}$ 的线性映射：\n\n- 一个稀疏的 CountSketch-风格映射 $R \\in \\mathbb{R}^{m \\times d}$，其中每一列恰好有 $s \\in \\mathbb{N}$ 个非零项。对于每一列 $j \\in \\{1,\\dots,d\\}$，这 $s$ 个非零项的行索引是从 $\\{1,\\dots,m\\}$ 中无放回地均匀选择的，且各列之间独立选择。对应的非零值是独立的 Rademacher 符号除以 $\\sqrt{s}$，即每个非零项以各 $1/2$ 的概率等于 $\\pm 1/\\sqrt{s}$。\n\n- 一个稠密高斯映射 $G \\in \\mathbb{R}^{m \\times d}$，其元素 $G_{ij} \\sim \\mathcal{N}(0,1/m)$ 是独立同分布的。\n\n定义对抗性点集 $V \\subset \\mathbb{R}^{d}$ 为\n$$\nV \\;=\\; \\{\\, v_{i}^{+}, v_{i}^{-} \\,:\\, i \\in \\{2,\\dots,n\\}\\,\\}, \\quad v_{i}^{\\pm} \\;=\\; e_{1} \\pm e_{i},\n$$\n其中 $e_{k}$ 表示 $\\mathbb{R}^{d}$ 中的第 $k$ 个标准基向量。\n\n对于一个失真参数 $\\varepsilon \\in (0,1/2)$，如果对于所有 $v \\in V$ 都满足下式，我们称线性映射 $A:\\mathbb{R}^{d}\\to\\mathbb{R}^{m}$ 在失真 $\\varepsilon$ 内保持了 $V$ 中向量的平方范数：\n$$\n\\left|\\, \\|A v\\|_{2}^{2} - \\|v\\|_{2}^{2} \\,\\right| \\;\\leq\\; \\varepsilon \\,\\|v\\|_{2}^{2}.\n$$\n\n从概率论和线性代数的基本原理出发，并且只使用经过充分检验的集中不等式工具（例如，用于超几何/二项分布变量的 Chernoff 界，用于 Rademacher 和的 Berry–Esseen 或 Hoeffding 不等式，以及 Paley–Zygmund 不等式），完成以下任务：\n\n1. 通过分析内积 $\\langle R e_{1}, R e_{i} \\rangle$ 及其对 $\\|R v_{i}^{\\pm}\\|_{2}^{2}$ 的影响，并与相应的高斯情况的行为进行对比，构建并论证一个显式机制，说明在相同的嵌入维度 $m$ 下，$R$ 如何可能在 $V$ 上导致比 $G$ 更大的失真。\n\n2. 通过量化 $R$ 的第 1 列和第 $i$ 列中 $s$ 个非零项的支撑集之间的重叠 $K$，以及在给定 $K$ 的条件下带符号重叠的波动，推导出一个最小列稀疏度 $s^{\\star} = s^{\\star}(n,m,\\varepsilon)$ 的渐近表达式。该表达式要满足以下条件：对于稀疏映射 $R$，其在失真 $\\varepsilon$ 内保持 $V$ 中所有向量的平方范数的概率至少为二分之一。你的推导应追踪 $n$、$m$ 和 $\\varepsilon$ 中的指数速率项，并且只要最终速率被正确捕捉，你可以忽略对数内的绝对常数因子。\n\n3. 最后给出一个关于 $s^{\\star}(n,m,\\varepsilon)$ 的闭式解析表达式，该表达式应清晰地分离其对 $n$、$m$ 和 $\\varepsilon$ 的依赖关系。你的答案必须是仅含 $n$、$m$ 和 $\\varepsilon$ 的单个解析表达式。无需进行数值计算。\n\n答案格式：仅提供 $s^{\\star}(n,m,\\varepsilon)$ 的表达式，并完全化简。无需四舍五入。不要包含单位。", "solution": "该问题要求分析一个稀疏的 CountSketch-风格随机投影 $R \\in \\mathbb{R}^{m \\times d}$，并将其保持特定向量集 $V = \\{e_1 \\pm e_i : i=2,\\dots,n\\}$ 范数的能力与一个稠密高斯投影 $G \\in \\mathbb{R}^{m \\times d}$ 进行比较。我们需要推导 $R$ 满足给定失真准则所需的最小列稀疏度 $s^{\\star}$。\n\n首先，我们来确定集合 $V$ 中向量的范数。对于任意 $v_i^{\\pm} = e_1 \\pm e_i$，其中 $e_k$ 是第 $k$ 个标准基向量，其欧几里得范数的平方为：\n$$\n\\|v_i^{\\pm}\\|_2^2 = \\|e_1 \\pm e_i\\|_2^2 = \\langle e_1 \\pm e_i, e_1 \\pm e_i \\rangle = \\|e_1\\|_2^2 \\pm 2\\langle e_1, e_i \\rangle + \\|e_i\\|_2^2\n$$\n由于标准基向量是标准正交的，对于所有 $k$，$\\|e_k\\|_2^2 = 1$，且对于 $j \\neq k$，$\\langle e_j, e_k \\rangle = 0$。因此，\n$$\n\\|v_i^{\\pm}\\|_2^2 = 1 \\pm 2(0) + 1 = 2\n$$\n所以，对于集合 $V$ 中的任意向量 $v$，其平方范数为 $\\|v\\|_2^2=2$。\n\n对于一个线性映射 $A: \\mathbb{R}^{d} \\to \\mathbb{R}^{m}$，其失真条件为：\n$$\n\\left|\\, \\|A v\\|_{2}^{2} - \\|v\\|_{2}^{2} \\,\\right| \\leq \\varepsilon \\,\\|v\\|_{2}^{2}\n$$\n代入 $\\|v\\|_2^2 = 2$，该条件变为：\n$$\n\\left|\\, \\|A v\\|_{2}^{2} - 2 \\,\\right| \\leq 2\\varepsilon\n$$\n我们来分析当 $v = v_i^{\\pm} = e_1 \\pm e_i$ 时 $\\|Av\\|_2^2$ 这一项。设 $c_j = Ae_j$ 表示矩阵 $A$ 的第 $j$ 列。那么 $Av = A(e_1 \\pm e_i) = Ae_1 \\pm Ae_i = c_1 \\pm c_i$。\n$$\n\\|Av\\|_2^2 = \\|c_1 \\pm c_i\\|_2^2 = \\|c_1\\|_2^2 + \\|c_i\\|_2^2 \\pm 2\\langle c_1, c_i \\rangle\n$$\n因此，失真条件为：\n$$\n\\left|\\, (\\|c_1\\|_2^2 + \\|c_i\\|_2^2 \\pm 2\\langle c_1, c_i \\rangle) - 2 \\,\\right| \\leq 2\\varepsilon\n$$\n\n**1. 稀疏映射中产生更大失真的机制**\n\n我们现在比较稀疏映射 $R$ 和稠密映射 $G$ 在此失真项上的行为。\n\n对于稀疏映射 $R \\in \\mathbb{R}^{m \\times d}$，其每一列 $c_j = Re_j$ 都恰好有 $s$ 个非零项，每个非零项的值为 $\\pm 1/\\sqrt{s}$。因此，任意一列的平方范数是固定的：\n$$\n\\|c_j\\|_2^2 = \\sum_{k=1}^{s} \\left(\\pm \\frac{1}{\\sqrt{s}}\\right)^2 = s \\cdot \\frac{1}{s} = 1\n$$\n对于映射 $R$，失真条件显著简化为：\n$$\n\\left|\\, (1 + 1 \\pm 2\\langle Re_1, Re_i \\rangle) - 2 \\,\\right| \\leq 2\\varepsilon\n$$\n$$\n\\left|\\, \\pm 2\\langle Re_1, Re_i \\rangle \\,\\right| \\leq 2\\varepsilon\n$$\n$$\n|\\langle Re_1, Re_i \\rangle| \\leq \\varepsilon\n$$\n对于稀疏映射 $R$，$V$ 中向量范数的保持完全取决于控制第 1 列与其他列 $i \\in \\{2,\\dots,n\\}$ 之间内积的大小。\n\n对于稠密高斯映射 $G \\in \\mathbb{R}^{m \\times d}$，其元素为 $G_{kj} \\sim \\mathcal{N}(0, 1/m)$。设 $c_j = Ge_j$。平方范数 $\\|c_j\\|_2^2 = \\sum_{k=1}^m G_{kj}^2$ 是一个随机变量。其期望为 $E[\\|c_j\\|_2^2] = \\sum_{k=1}^m E[G_{kj}^2] = \\sum_{k=1}^m (1/m) = 1$。变量 $m\\|c_j\\|_2^2$ 服从卡方分布 $\\chi_m^2$，该分布紧密集中在其均值 $m$ 附近。类似地，内积 $\\langle c_1, c_i \\rangle = \\sum_{k=1}^m G_{k1}G_{ki}$ 是均值为 0、方差为 $1/m^2$ 的独立同分布随机变量之和，因此 $E[\\langle c_1, c_i \\rangle]=0$ 且 $\\text{Var}(\\langle c_1, c_i \\rangle) = m \\cdot (1/m^2) = 1/m$。对于 $G$，失真来源于三个波动项：$(\\|c_1\\|_2^2-1)$、$(\\|c_i\\|_2^2-1)$ 和 $\\langle c_1, c_i \\rangle$。这些都是表现良好、近似高斯的变量，其方差量级为 $1/m$。\n\n$R$ 可能导致更大失真的显式机制在于内积 $\\langle Re_1, Re_i \\rangle$ 的结构。设 $S_j \\subset \\{1, \\dots, m\\}$ 是 $R$ 的第 $j$ 列具有非零项的行索引集合，因此 $|S_j|=s$。内积仅在这些支撑集的交集上非零：\n$$\n\\langle Re_1, Re_i \\rangle = \\sum_{k \\in S_1 \\cap S_i} R_{k1} R_{ki}\n$$\n设 $K = |S_1 \\cap S_i|$ 为此随机重叠的大小。对于每个 $k \\in S_1 \\cap S_i$，项 $R_{k1}R_{ki} = (\\pm 1/\\sqrt{s})(\\pm 1/\\sqrt{s}) = (1/s) \\cdot \\rho_k$，其中 $\\rho_k$ 是两个独立 Rademacher 随机变量的乘积，其本身也是一个 Rademacher 变量。所以，\n$$\n\\langle Re_1, Re_i \\rangle = \\frac{1}{s}\\sum_{k=1}^K \\rho_k = \\frac{Z_K}{s}\n$$\n其中 $Z_K$ 是 $K$ 个独立同分布 Rademacher 变量的和。关键点在于 $K$ 是一个随机变量。它服从超几何分布，因为它表示从 $m$ 个元素的总体中无放回地抽取 $s$ 个项目（第 1 列的行），然后再抽取 $s$ 个项目（第 $i$ 列的行）时，共同抽中的项目数。因此，$\\langle Re_1, Re_i \\rangle$ 的分布是关于 $K$ 的条件混合分布。$K$ 的一次偶然大波动可能导致求和项数远超平均值，从而产生内积的重尾分布，而这种情况在高斯映射中是不存在的。这使得在相同的嵌入维度 $m$ 下，$R$ 的内积出现较大值（从而导致较大失真）的概率比 $G$ 更高。\n\n**2. 最小稀疏度 $s^{\\star}$ 的推导**\n\n我们需要找到最小稀疏度 $s=s^{\\star}$，使得 $R$ 保持 $V$ 中所有向量范数的概率至少为 $1/2$。这要求对于所有 $i \\in \\{2, \\dots, n\\}$，$|\\langle Re_1, Re_i \\rangle| \\leq \\varepsilon$ 均成立。设 $F_i$ 为失败事件 $|\\langle Re_1, Re_i \\rangle|  \\varepsilon$。根据并集界，总失败概率为 $P(\\cup_{i=2}^n F_i) \\leq \\sum_{i=2}^n P(F_i)$。由对称性可知，所有 $P(F_i)$ 都相等。因此我们需要 $(n-1) P(F_2) \\le 1/2$，即 $P(F_2) \\le \\frac{1}{2(n-1)}$。\n\n失败条件是 $|\\frac{Z_K}{s}|  \\varepsilon$，即 $|Z_K|  s\\varepsilon$。\n我们来分析导致失败的原因。给定重叠 $K$，$Z_K$ 是 $K$ 个 Rademacher 变量的和，所以 $E[Z_K|K]=0$ 且 $\\text{Var}(Z_K|K)=K$。$Z_K$ 的“典型”量级是 $\\sqrt{K}$。当典型量级与阈值相当时，即 $\\sqrt{K} \\approx s\\varepsilon$，失败条件 $|Z_K|  s\\varepsilon$ 就很可能发生。这定义了一个临界重叠大小：\n$$\nK_{crit} = (s\\varepsilon)^2\n$$\n如果随机重叠 $K$ 恰好大于或等于 $K_{crit}$，失败的条件概率 $P(|Z_K|  s\\varepsilon | K \\ge K_{crit})$ 会变得显著（一个不依赖于问题参数的常数）。因此，总失败概率主要由重叠达到临界大小时的这一罕见事件的概率决定：\n$$\nP(F_2) \\approx P(K \\ge K_{crit}) = P(K \\ge s^2\\varepsilon^2)\n$$\n为确保嵌入以高概率成功，我们必须使这一事件足够罕见。我们需要对 $K$ 的尾概率进行界定。$K$ 的分布是超几何分布 Hypergeometric($N=m, K_{pop}=s, n_{draw}=s$)。当 $m \\gg s$ 时，这可以很好地用二项分布 $B(s, p=s/m)$ 来近似，因为为第 $i$ 列选中某个特定行的概率是 $s/m$。\n\n我们使用 Chernoff 界来界定二项分布的上尾。对于一个随机变量 $X \\sim B(N, p)$，观察到至少 $k$ 次成功的概率由 $P(X \\ge k) \\le \\exp(-N \\cdot D_{KL}(k/N || p))$ 界定，其中 $D_{KL}(q||p) = q\\ln(q/p) + (1-q)\\ln\\left(\\frac{1-q}{1-p}\\right)$ 是 Kullback-Leibler 散度。\n在这里，$N=s$，$k=K_{crit}=s^2\\varepsilon^2$，$p=s/m$。成功的分数是 $q=k/N = s^2\\varepsilon^2/s = s\\varepsilon^2$。我们必须满足条件 $q \\le 1$，即 $s\\varepsilon^2 \\le 1$。\n我们需要 $P(K \\ge s^2\\varepsilon^2) \\le \\frac{1}{2(n-1)}$。这导出了不等式：\n$$\n\\exp(-s \\cdot D_{KL}(s\\varepsilon^2 || s/m)) \\le \\frac{1}{2(n-1)}\n$$\n对两边取自然对数：\n$$\n-s \\cdot D_{KL}(s\\varepsilon^2 || s/m) \\le -\\ln(2(n-1))\n$$\n$$\ns \\cdot D_{KL}(s\\varepsilon^2 || s/m) \\ge \\ln(2(n-1))\n$$\n在我们感兴趣的范围内，当 $s$ 很小时，稀疏性是有效的，因此 $p=s/m$ 很小。失真参数 $\\varepsilon$ 也很小。我们感兴趣的情况是，所需的重叠数 $q=s\\varepsilon^2$ 远大于期望的重叠数 $p=s/m$。这对应于条件 $m\\varepsilon^2 \\gg 1$，这在 Johnson-Lindenstrauss 结果中是典型的。\n在这种情况下（$q \\gg p$，且两者都很小），KL 散度可以由其主导项近似：\n$$\nD_{KL}(q||p) \\approx q\\ln(q/p)\n$$\n将此近似代入我们的不等式：\n$$\ns \\cdot \\left( (s\\varepsilon^2) \\ln\\left(\\frac{s\\varepsilon^2}{s/m}\\right) \\right) \\ge \\ln(2(n-1))\n$$\n$$\ns^2 \\varepsilon^2 \\ln(m\\varepsilon^2) \\ge \\ln(2(n-1))\n$$\n根据问题要求，我们追踪指数速率项，并且对于大的 $n$ 可以忽略对数内的常数因子。因此，$\\ln(2(n-1)) \\approx \\ln(n)$。\n$$\ns^2 \\varepsilon^2 \\ln(m\\varepsilon^2) \\gtrsim \\ln(n)\n$$\n求解最小稀疏度 $s = s^{\\star}$：\n$$\ns^2 \\gtrsim \\frac{\\ln(n)}{\\varepsilon^2 \\ln(m\\varepsilon^2)}\n$$\n$$\ns^{\\star} \\approx \\frac{\\sqrt{\\ln(n)}}{\\varepsilon\\sqrt{\\ln(m\\varepsilon^2)}}\n$$\n\n**3. $s^{\\star}(n, m, \\varepsilon)$ 的闭式解析表达式**\n\n基于以上的渐近推导，能够分离其对 $n$、$m$ 和 $\\varepsilon$ 依赖关系的最小列稀疏度 $s^{\\star}$ 是：\n$$\ns^{\\star}(n, m, \\varepsilon) = \\frac{1}{\\varepsilon} \\sqrt{\\frac{\\ln(n)}{\\ln(m\\varepsilon^2)}}\n$$\n这个表达式捕捉了稀疏度随点数 $n$、嵌入维度 $m$ 和失真 $\\varepsilon$ 的所需缩放关系。", "answer": "$$\\boxed{\\frac{1}{\\varepsilon} \\sqrt{\\frac{\\ln(n)}{\\ln(m\\varepsilon^{2})}}}$$", "id": "3570496"}, {"introduction": "实际应用中的数据处理流水线常常涉及多个阶段的降维。本练习将带你超越单个投影的分析，研究顺序应用多个 JL 变换的复合效应。你的任务是推导总失真如何由各阶段的失真累积而成，并利用这一洞察力来优化一个多阶段嵌入方案的设计 [@problem_id:3570516]，以在满足总体失真预算的同时，最小化总计算资源。", "problem": "令 $\\mathcal{X} \\subset \\mathbb{R}^{d}$ 为一个包含 $m$ 个点的有限集合，并令 $v = x - y$ 表示对于 $x,y \\in \\mathcal{X}$ 的任意差分向量。考虑两个独立的随机线性映射 $R_{1} \\in \\mathbb{R}^{k_{1} \\times d}$ 和 $R_{2} \\in \\mathbb{R}^{k_{2} \\times k_{1}}$，其元素是独立同分布的标准正态随机变量，分别按 $1/\\sqrt{k_{1}}$ 和 $1/\\sqrt{k_{2}}$ 进行缩放。根据 $\\chi^{2}$ 随机变量的集中性和标准的次高斯尾部界，对于任意固定的 $v \\in \\mathbb{R}^{d}$ 和任意 $\\varepsilon \\in (0,1)$，存在一个绝对常数 $C0$ 使得\n$$\n\\mathbb{P}\\!\\left(\\left|\\|R v\\|^{2} - \\|v\\|^{2}\\right| \\geq \\varepsilon \\|v\\|^{2}\\right) \\leq 2 \\exp\\!\\big(-C k \\varepsilon^{2}\\big),\n$$\n其中 $R$ 是一个具有如上所述元素的随机矩阵， $k$ 是其行维度。然后通过对所有 $\\binom{m}{2}$ 个差分向量应用并集界，可以得到 Johnson–Lindenstrauss (JL) 引理 (Johnson–Lindenstrauss)，从而得出常规的维度规定 $k \\geq C \\varepsilon^{-2} \\ln(m/\\delta)$，以至少 $1 - \\delta$ 的概率将所有成对平方距离保持在 $(1 \\pm \\varepsilon)$ 因子内。\n\n现在，通过 $P = R_{2} R_{1}$ 依次应用 $R_{1}$ 和 $R_{2}$ 将 $\\mathcal{X}$ 嵌入到 $\\mathbb{R}^{k_{2}}$ 中，其中 $R_{1}$ 的参数为 $(\\varepsilon_{1}, \\delta_{1}, k_{1})$，$R_{2}$ 的参数为 $(\\varepsilon_{2}, \\delta_{2}, k_{2})$，如上所述。从上述基本集中界出发（而不是任何专门的复合公式），推导复合映射的总平方距离失真参数 $\\varepsilon_{\\mathrm{tot}}$ 关于 $\\varepsilon_{1}$ 和 $\\varepsilon_{2}$ 的精确表达式，以及用 $\\delta_{1}$ 和 $\\delta_{2}$ 表示的失效概率界。\n\n然后，你需要设计一个两阶段方案，该方案受总平方距离失真预算 $\\varepsilon \\in (0,1)$ 和总失效概率预算 $\\delta \\in (0,1)$ 的约束。假设有以下科学上真实的设计约束：\n- 两个阶段是独立的，它们的失效概率均等分配，即 $\\delta_{1} = \\delta_{2} = \\delta/2$。\n- 为减少不平衡，选择相等的阶段失真，即 $\\varepsilon_{1} = \\varepsilon_{2}$。\n- 每个阶段的维度由标准 JL 规定 $k_{i} = C \\varepsilon_{i}^{-2} \\ln\\!\\big(2 m / \\delta\\big)$ 设定，忽略整数取整效应，其中 $C$ 是两个阶段中相同的绝对常数。\n\n在所有精确满足总失真预算（即复合映射的总平方距离失真等于 $\\varepsilon$）的可行 $(\\varepsilon_{1}, \\varepsilon_{2})$ 中，确定在上述均等分配约束下最小化总维度 $k_{1} + k_{2}$ 的最优公共阶段失真 $\\varepsilon_{1}$ 的闭式解析表达式。将你的最终答案表示为仅含 $\\varepsilon$ 的单个闭式表达式。不要用数值代入任何符号。不需要四舍五入。", "solution": "首先将验证问题陈述的有效性，如果有效，则继续给出完整解答。\n\n### 第 1 步：提取已知条件\n- 一个包含 $m$ 个点的有限集合 $\\mathcal{X} \\subset \\mathbb{R}^{d}$。\n- 一个差分向量 $v = x - y$，其中 $x, y \\in \\mathcal{X}$。\n- 两个独立的随机线性映射 $R_{1} \\in \\mathbb{R}^{k_{1} \\times d}$ 和 $R_{2} \\in \\mathbb{R}^{k_{2} \\times k_{1}}$。\n- $R_{1}$ 的元素是独立同分布的 $ N(0, 1/k_{1}) $。\n- $R_{2}$ 的元素是独立同分布的 $ N(0, 1/k_{2}) $。\n- 对于一个大小为 $k \\times d'$ 的随机矩阵 $R$ 的集中界：对于一个固定的向量 $v \\in \\mathbb{R}^{d'}$ 和 $\\varepsilon \\in (0,1)$，$\\mathbb{P}(\\left|\\|R v\\|^{2} - \\|v\\|^{2}\\right| \\geq \\varepsilon \\|v\\|^{2}) \\leq 2 \\exp(-C k \\varepsilon^{2})$，其中 $C0$ 是一个绝对常数。\n- 复合投影为 $P = R_{2} R_{1}$。\n- $R_{1}$ 的参数为 $(\\varepsilon_{1}, \\delta_{1}, k_{1})$。\n- $R_{2}$ 的参数为 $(\\varepsilon_{2}, \\delta_{2}, k_{2})$。\n- 目标，第 1 部分：用 $\\varepsilon_{1}$ 和 $\\varepsilon_{2}$ 表示总平方距离失真 $\\varepsilon_{\\mathrm{tot}}$，用 $\\delta_{1}$ 和 $\\delta_{2}$ 表示失效概率界。\n- 目标，第 2 部分：设计一个两阶段方案，其总失真预算为 $\\varepsilon \\in (0,1)$，总失效概率预算为 $\\delta \\in (0,1)$。\n- 第 2 部分的设计约束：\n    - $\\delta_{1} = \\delta_{2} = \\delta/2$。\n    - $\\varepsilon_{1} = \\varepsilon_{2}$。\n    - 维度规定：对于 $i \\in \\{1, 2\\}$，$k_{i} = C \\varepsilon_{i}^{-2} \\ln(2 m / \\delta)$，其中 $C$ 是一个绝对常数。忽略整数取整效应。\n- 优化目标：在满足失真预算 $\\varepsilon$ 的可行对 $(\\varepsilon_{1}, \\varepsilon_{2})$ 中，找到在给定约束下最小化总维度 $k_1 + k_2$ 的最优公共阶段失真 $\\varepsilon_{1}$。结果应仅用 $\\varepsilon$ 表示。\n\n### 第 2 步：使用提取的已知条件进行验证\n- **科学依据：** 该问题牢固地植根于随机数值线性代数理论，特别是 Johnson-Lindenstrauss (JL) 引理。集中不等式是高斯随机投影的标准结果。复合投影和分析其产生的失真是该领域一个成熟的课题。该问题在科学上和数学上都是合理的。\n- **适定性：** 该问题分为两个不同的部分：推导和优化。已知条件、约束和目标都定义清晰，能够导出一个唯一且有意义的解。\n- **客观性：** 语言正式、精确，没有主观或含糊的陈述。\n- **完整性和一致性：** 提供了所有必要的定义、公式和约束。维度规定 $k_i = C \\varepsilon_i^{-2} \\ln(2m/\\delta)$ 是一个给定的建模选择，虽然这是对涉及 $\\binom{m}{2}$ 和 $\\delta_i$ 的更严格界的简化，但必须按其规定来使用。它没有引入任何内部矛盾。\n- **其他缺陷：** 该问题没有表现出任何其他列出的无效性缺陷。它不是不重要的、比喻性的或无法验证的。\n\n### 第 3 步：结论和行动\n问题有效。将提供完整解答。\n\n### 解答推导\n根据问题陈述的要求，解答分为两部分进行。\n\n**第 1 部分：复合投影分析**\n\n令 $v = x - y$ 为两点 $x, y \\in \\mathcal{X}$ 之间的任意差分向量。复合投影作用于 $v$ 的形式为 $P v = R_2 R_1 v$。我们旨在界定其平方范数 $\\|P v\\|^2$ 相对于 $\\|v\\|^2$ 的失真。\n\n分析分两个阶段进行，与投影算子的应用相对应。\n1.  **第一阶段（投影 $R_1$）**：映射 $R_1: \\mathbb{R}^d \\to \\mathbb{R}^{k_1}$ 是一个参数为 $(\\varepsilon_1, \\delta_1)$ 的 JL 映射。通过对 $\\mathcal{X}$ 中 $\\binom{m}{2}$ 个不同的差分向量应用并集界，JL 引理保证以下不等式对所有 $v = x-y$ 成立的概率至少为 $1 - \\delta_1$：\n    $$ (1 - \\varepsilon_1)\\|v\\|^2 \\leq \\|R_1 v\\|^2 \\leq (1 + \\varepsilon_1)\\|v\\|^2 $$\n    我们将此不等式对所有差分向量成立的事件记为 $\\mathcal{A}_1$。我们有 $\\mathbb{P}(\\mathcal{A}_1) \\ge 1 - \\delta_1$。\n\n2.  **第二阶段（投影 $R_2$）**：映射 $R_2: \\mathbb{R}^{k_1} \\to \\mathbb{R}^{k_2}$ 是一个参数为 $(\\varepsilon_2, \\delta_2)$ 的 JL 映射。关键在于 $R_2$ 与 $R_1$ 在统计上是独立的。因此，我们可以对 $R_1$ 的任何结果取条件，并分析 $R_2$ 对向量集合 $\\{R_1 v\\}$ 的作用。$R_2$ 的 JL 保证指出，对于集合中的 $\\binom{m}{2}$ 个向量 $\\{R_1 v \\mid x,y \\in \\mathcal{X}, x \\neq y \\}$，以下不等式成立的概率至少为 $1 - \\delta_2$：\n    $$ (1 - \\varepsilon_2)\\|R_1 v\\|^2 \\leq \\|R_2(R_1 v)\\|^2 \\leq (1 + \\varepsilon_2)\\|R_1 v\\|^2 $$\n    这对所有差分向量 $v=x-y$ 都成立。我们将此事件记为 $\\mathcal{A}_2$。由于 $\\mathcal{A}_2$ 的概率界不依赖于 $R_1$ 的具体实现，我们有 $\\mathbb{P}(\\mathcal{A}_2) \\geq 1 - \\delta_2$。\n\n现在，我们分析当事件 $\\mathcal{A}_1$ 和 $\\mathcal{A}_2$ 同时发生时的总失真。这个联合事件的概率是 $\\mathbb{P}(\\mathcal{A}_1 \\cap \\mathcal{A}_2)$。根据并集界，失效概率为 $\\mathbb{P}((\\mathcal{A}_1 \\cap \\mathcal{A}_2)^c) = \\mathbb{P}(\\mathcal{A}_1^c \\cup \\mathcal{A}_2^c) \\leq \\mathbb{P}(\\mathcal{A}_1^c) + \\mathbb{P}(\\mathcal{A}_2^c) \\leq \\delta_1 + \\delta_2$。因此，以至少 $1 - (\\delta_1 + \\delta_2)$ 的概率，两组不等式同时成立。\n\n假设 $\\mathcal{A}_1$ 和 $\\mathcal{A}_2$ 都发生，我们可以合并这两个不等式：\n对于失真的上界：\n$$ \\|P v\\|^2 = \\|R_2 R_1 v\\|^2 \\leq (1 + \\varepsilon_2) \\|R_1 v\\|^2 \\leq (1 + \\varepsilon_2) (1 + \\varepsilon_1) \\|v\\|^2 = (1 + \\varepsilon_1 + \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2) \\|v\\|^2 $$\n对于失真的下界：\n$$ \\|P v\\|^2 = \\|R_2 R_1 v\\|^2 \\geq (1 - \\varepsilon_2) \\|R_1 v\\|^2 \\geq (1 - \\varepsilon_2) (1 - \\varepsilon_1) \\|v\\|^2 = (1 - \\varepsilon_1 - \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2) \\|v\\|^2 $$\n因此，总变换满足：\n$$ (1 - (\\varepsilon_1 + \\varepsilon_2 - \\varepsilon_1 \\varepsilon_2)) \\|v\\|^2 \\leq \\|P v\\|^2 \\leq (1 + (\\varepsilon_1 + \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2)) \\|v\\|^2 $$\n总平方距离失真参数 $\\varepsilon_{\\mathrm{tot}}$ 由两个与 1 的偏差中较大的一个定义。由于 $\\varepsilon_1  0$ 和 $\\varepsilon_2  0$，正偏差更大：$\\varepsilon_1 + \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2  \\varepsilon_1 + \\varepsilon_2 - \\varepsilon_1 \\varepsilon_2$。\n因此，总失真参数为：\n$$ \\varepsilon_{\\mathrm{tot}} = \\varepsilon_1 + \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2 $$\n总失效概率的界为 $\\delta_1 + \\delta_2$。\n\n**第 2 部分：两阶段方案的最优设计**\n\n我们的任务是在一系列设计约束下，最小化总中间维度 $K = k_1 + k_2$。\n维度由 $k_i = C \\varepsilon_i^{-2} \\ln(2m / \\delta)$ 给出，其中 $i \\in \\{1, 2\\}$，常数 $C$ 和对数项对两个阶段都是共同的。令 $A = C \\ln(2m / \\delta)$。要最小化的目标函数是 $K(\\varepsilon_1, \\varepsilon_2) = A \\varepsilon_1^{-2} + A \\varepsilon_2^{-2}$。最小化 $K$ 等价于最小化 $f(\\varepsilon_1, \\varepsilon_2) = \\varepsilon_1^{-2} + \\varepsilon_2^{-2}$。\n\n约束条件是：\n1.  总失真精确满足预算 $\\varepsilon$：$\\varepsilon_{\\mathrm{tot}} = \\varepsilon_1 + \\varepsilon_2 + \\varepsilon_1 \\varepsilon_2 = \\varepsilon$。\n2.  选择相等的阶段失真：$\\varepsilon_1 = \\varepsilon_2$。\n3.  失效概率均等分配：$\\delta_1 = \\delta_2 = \\delta/2$。这个选择已经体现在给定的维度公式 $k_i = C \\varepsilon_i^{-2} \\ln(2m / \\delta)$ 中，该公式使用了总失效预算 $\\delta$。\n\n问题是要求找到最优的公共阶段失真 $\\varepsilon_1$。条件 $\\varepsilon_1 = \\varepsilon_2$ 是作为设计选择给出的。值得注意的是，对于在总失真约束下最小化 $\\varepsilon_1^{-2} + \\varepsilon_2^{-2}$ 而言，这个选择确实是最优的，这可以通过拉格朗日乘数法来验证。问题陈述指示我们从一开始就使用这个条件。\n\n令 $\\varepsilon_1 = \\varepsilon_2 = \\varepsilon'$。将其代入总失真约束中，得到：\n$$ \\varepsilon' + \\varepsilon' + \\varepsilon' \\cdot \\varepsilon' = \\varepsilon $$\n$$ (\\varepsilon')^2 + 2\\varepsilon' - \\varepsilon = 0 $$\n这是一个关于公共阶段失真 $\\varepsilon'$ 的二次方程。我们使用二次公式求解 $\\varepsilon'$：\n$$ \\varepsilon' = \\frac{-2 \\pm \\sqrt{2^2 - 4(1)(-\\varepsilon)}}{2(1)} = \\frac{-2 \\pm \\sqrt{4 + 4\\varepsilon}}{2} = \\frac{-2 \\pm 2\\sqrt{1+\\varepsilon}}{2} = -1 \\pm \\sqrt{1+\\varepsilon} $$\n由于失真参数 $\\varepsilon'$ 必须为正（因为 $\\varepsilon \\in (0,1)$ 意味着 $\\varepsilon_{\\mathrm{tot}}  0$），我们必须选择正根：\n$$ \\varepsilon' = -1 + \\sqrt{1+\\varepsilon} $$\n这就是在指定设计约束下，精确满足总失真预算 $\\varepsilon$ 的公共阶段失真 $\\varepsilon_1 = \\varepsilon_2$ 的值。问题要求给出 $\\varepsilon_1$ 的这个表达式。\n\n最优公共阶段失真 $\\varepsilon_1$ 的最终表达式为：\n$$ \\varepsilon_1 = \\sqrt{1+\\varepsilon} - 1 $$\n这完全由总失真预算 $\\varepsilon$ 表示，符合要求。", "answer": "$$\\boxed{\\sqrt{1+\\varepsilon} - 1}$$", "id": "3570516"}]}