{"hands_on_practices": [{"introduction": "多重网格方法的核心思想是通过在不同尺度的网格上传递信息来高效地消除误差。在这一过程中，“平滑器”扮演着至关重要的角色，其任务是衰减误差中的高频分量。本练习将通过实现高斯-赛德尔（Gauss-Seidel）松弛法，并量化其对特定傅里叶模式误差的衰减效果，帮助您直观地理解平滑属性的本质。[@problem_id:3480320]", "problem": "考虑单位正方形上的二维泊松方程，其带有齐次狄利克雷边界条件，写作 $$\\nabla^2 u(x,y) = 0 \\quad \\text{for} \\quad (x,y)\\in(0,1)\\times(0,1), \\quad \\text{with} \\quad u(x,y)=0 \\quad \\text{on} \\quad \\partial\\Omega.$$ 使用标准二阶中心差分格式在具有均匀间距 $h=1/(N+1)$ 的 $N\\times N$ 內部网格上进行离散化，得到离散线性系统 $$A \\mathbf{u} = \\mathbf{f},$$ 其中 $A$ 是五点离散拉普拉斯算子，$\\mathbf{u}$ 是内部未知数的数组。在多重网格方法中，Gauss-Seidel (GS) 松弛法被用作光滑子来衰减高频误差分量。其光滑特性可以通过类傅里叶误差模式的放大因子来量化。\n\n您的任务是从基本离散算子和 Gauss-Seidel 的线性迭代分裂出发，推导齐次系统（即 $\\mathbf{f}=\\mathbf{0}$，因此精确解为 $\\mathbf{u}^\\ast=\\mathbf{0}$）上字典序 Gauss-Seidel 松弛法的逐点更新公式，然后对一个由单个离散正弦模式给出的初始误差，实施两步预光滑和两步后光滑（总共四次 GS 扫描）。具体要求如下：\n\n- 构建离散正弦模式 $$\\phi_{i,j}^{(k,\\ell)} = \\sin\\!\\bigg(\\frac{k\\pi i}{N+1}\\bigg)\\,\\sin\\!\\bigg(\\frac{\\ell\\pi j}{N+1}\\bigg),\\quad 1\\le i,j\\le N,$$ 并在离散 $\\ell^2$ 范数下对其进行归一化，使得 $$\\sum_{i=1}^N\\sum_{j=1}^N \\left(\\phi_{i,j}^{(k,\\ell)}\\right)^2 = 1.$$ 使用此归一化模式作为初始误差 $\\mathbf{e}^{(0)}=\\phi^{(k,\\ell)}$。\n\n- 从 $\\mathbf{u}^{(0)}=\\mathbf{e}^{(0)}$ 开始，对齐次系统 $A\\mathbf{u}=\\mathbf{0}$ 应用从离散拉普拉斯算子的矩阵分裂推导出的字典序 Gauss-Seidel 松弛法，总共进行四次扫描。令 $\\mathbf{u}^{(4)}$ 表示四次扫描后的结果。\n\n- 通过将最终误差 $\\mathbf{u}^{(4)}$ 投影到原始模式上，量化所选模式的衰减，并将特定模式的放大因子定义为 $$\\alpha_{k,\\ell}(N) = \\left|\\frac{\\sum_{i=1}^N\\sum_{j=1}^N \\phi_{i,j}^{(k,\\ell)}\\,u^{(4)}_{i,j}}{\\sum_{i=1}^N\\sum_{j=1}^N \\phi_{i,j}^{(k,\\ell)}\\,u^{(0)}_{i,j}}\\right|.$$ 由于初始模式是归一化的，分母在数值舍入误差范围内等于 $1$。报告其绝对值以度量衰减，而不考虑任何相位反转。\n\n使用此构造来评估一组用于探测高频和各向异性行为的代表性模式的放大因子。您的程序必须从第一性原理（即离散算子和迭代分裂）出发实现字典序 Gauss-seidel 更新，并为以下测试套件计算放大因子：\n\n- 案例 1（理想情况，低频参考）：$N=32$, $k=1$, $\\ell=1$。\n- 案例 2（中高频，各向同性）：$N=32$, $k=16$, $\\ell=16$。\n- 案例 3（近奈奎斯特频率，各向同性极端情况）：$N=32$, $k=32$, $\\ell=32$。\n- 案例 4（$x$ 方向的各向异性高频）：$N=32$, $k=32$, $\\ell=1$。\n- 案例 5（更大网格，中高频，各向同性）：$N=64$, $k=32$, $\\ell=32$。\n- 案例 6（小网格边缘情况，近奈奎斯特频率）：$N=4$, $k=4$, $\\ell=4$。\n\n所有计算均为纯数值计算，不涉及物理单位。正弦模式中的角度以弧度为单位。您的程序应生成单行输出，其中包含六个放大因子，以逗号分隔并用方括号括起来，四舍五入到六位小数，顺序与上述案例相同。例如，输出格式必须与“[result1,result2,result3,result4,result5,result6]”完全一致。", "solution": "用户提供了一个数值分析领域的问题，具体涉及评估 Gauss-Seidel 光滑子的性能，这是求解椭圆偏微分方程的多重网格求解器的一个关键组成部分。该问题在科学上和数学上都是合理的、适定的，并且为解决该问题提供了所有必要的参数和定义。\n\n问题的核心是数值评估用于二维泊松方程的字典序 Gauss-Seidel (GS) 松弛格式的衰减特性。这是通过在固定次数的 GS 扫描后，测量特定误差模式的衰减来实现的。\n\n问题从单位正方形上的齐次泊松方程 $\\nabla^2 u(x,y) = 0$ 以及齐次狄利克雷边界条件 $u=0$ 开始。我们在一个具有 $N \\times N$ 内部点和网格间距 $h=1/(N+1)$ 的均匀网格上离散化该方程。在网格点 $(i,j)$ 处，对拉普拉斯算子的标准五点中心差分近似为：\n$$ (L_h u)_{i,j} = \\frac{u_{i+1,j} + u_{i-1,j} + u_{i,j+1} + u_{i,j-1} - 4u_{i,j}}{h^2} $$\n对所有内部点 $1 \\le i,j \\le N$ 设置 $(L_h u)_{i,j} = 0$，得到离散线性系统 $A\\mathbf{u} = \\mathbf{0}$。每个点 $(i,j)$ 的方程为：\n$$ 4u_{i,j} - u_{i-1,j} - u_{i+1,j} - u_{i,j-1} - u_{i,j+1} = 0 $$\n其中因子 $h^2$ 已被省略，因为它对整个系统进行缩放。\n\nGauss-Seidel 是求解此类线性系统的一种迭代法。对于系统 $A\\mathbf{u}=\\mathbf{f}$，矩阵 $A$ 被分裂为其对角（$D$）、严格下三角（$L$）和严格上三角（$U$）部分，即 $A=L+D+U$。GS 迭代则定义为 $(L+D)\\mathbf{u}^{(m+1)} = \\mathbf{f} - U\\mathbf{u}^{(m)}$。在我们的例子中，右端项为零，因此 $(L+D)\\mathbf{u}^{(m+1)} = -U\\mathbf{u}^{(m)}$。\n\n这种矩阵形式可以表示为逐点更新法则。为了在迭代步骤 $m+1$ 计算新值 $u_{i,j}^{(m+1)}$，我们重排离散方程：\n$$ u_{i,j} = \\frac{1}{4}\\left( u_{i-1,j} + u_{i+1,j} + u_{i,j-1} + u_{i,j+1} \\right) $$\n在一次字典序（逐行、逐列）扫描中，当我们更新 $u_{i,j}$ 时，“过去”邻居（例如 $u_{i-1,j}$ 和 $u_{i,j-1}$）的值已在当前扫描中被更新，而“未来”邻居（例如 $u_{i+1,j}$ 和 $u_{i,j+1}$）的值则来自上一次扫描。这导出了更新法则：\n$$ u_{i,j}^{(m+1)} = \\frac{1}{4}\\left( u_{i-1,j}^{(m+1)} + u_{i,j-1}^{(m+1)} + u_{i+1,j}^{(m)} + u_{i,j+1}^{(m)} \\right) $$\n这是通过遍历网格点 $i=1,\\dots,N$ 和 $j=1,\\dots,N$ 并就地更新网格值来实现的。\n\n初始误差由单个离散正弦模式给出，这些模式是该网格上离散拉普拉斯算子的特征函数：\n$$ \\phi_{i,j}^{(k,\\ell)} = \\sin\\!\\bigg(\\frac{k\\pi i}{N+1}\\bigg)\\,\\sin\\!\\bigg(\\frac{\\ell\\pi j}{N+1}\\bigg), \\quad 1 \\le i,j,k,\\ell \\le N $$\n这个初始模式 $\\mathbf{e}^{(0)}$ 首先在离散 $\\ell^2$ 范数下进行归一化，得到 $\\boldsymbol{\\phi}^{(k,\\ell)}$，使得 $\\sum_{i,j} (\\phi_{i,j}^{(k,\\ell)})^2 = 1$。这个归一化的模式作为迭代的网格初始状态，即 $\\mathbf{u}^{(0)} = \\boldsymbol{\\phi}^{(k,\\ell)}$。\n\n然后，我们对这个初始状态应用四次完整的字典序 Gauss-Seidel 松弛扫描，产生最终状态 $\\mathbf{u}^{(4)}$。问题要求通过将最终误差场 $\\mathbf{u}^{(4)}$ 投影回初始归一化模式 $\\boldsymbol{\\phi}^{(k,\\ell)}$ 来量化原始模式的衰减。特定模式的放大因子定义为：\n$$ \\alpha_{k,\\ell}(N) = \\left|\\frac{\\langle \\mathbf{u}^{(4)}, \\boldsymbol{\\phi}^{(k,\\ell)} \\rangle}{\\langle \\mathbf{u}^{(0)}, \\boldsymbol{\\phi}^{(k,\\ell)} \\rangle}\\right| $$\n其中 $\\langle \\cdot, \\cdot \\rangle$ 表示离散内积 $\\sum_{i,j} a_{i,j}b_{i,j}$。由于 $\\mathbf{u}^{(0)} = \\boldsymbol{\\phi}^{(k,\\ell)}$ 且 $\\boldsymbol{\\phi}^{(k,\\ell)}$ 是归一化的，分母为 $\\langle \\boldsymbol{\\phi}^{(k,\\ell)}, \\boldsymbol{\\phi}^{(k,\\ell)} \\rangle=1$。因此，放大因子简化为投影的幅度：\n$$ \\alpha_{k,\\ell}(N) = \\left| \\sum_{i=1}^N\\sum_{j=1}^N u^{(4)}_{i,j}\\,\\phi_{i,j}^{(k,\\ell)} \\right| $$\n对每个指定的测试案例 $(N,k,\\ell)$ 以数值方式执行此过程。使用一个 $(N+2) \\times (N+2)$ 的网格，通过将边界上的值固定为 $0$ 来自然地引入齐次狄利克雷边界条件。迭代和投影仅在 $N \\times N$ 的内部网格点上执行。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes the Gauss-Seidel amplification factor for specific sine modes.\n\n    This function iterates through a set of test cases, each defined by a grid\n    size N and mode numbers (k, l). For each case, it:\n    1. Constructs the initial error as a normalized discrete sine mode.\n    2. Applies four sweeps of lexicographic Gauss-Seidel relaxation.\n    3. Computes the amplification factor by projecting the final error onto\n       the initial mode.\n    The results are collected and printed in the specified format.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (32, 1, 1),    # Case 1: Low-frequency reference\n        (32, 16, 16),  # Case 2: Mid-high-frequency, isotropic\n        (32, 32, 32),  # Case 3: Near-Nyquist, isotropic extreme\n        (32, 32, 1),   # Case 4: Anisotropic high-frequency\n        (64, 32, 32),  # Case 5: Larger grid, mid-high-frequency\n        (4, 4, 4),     # Case 6: Small grid edge case, near-Nyquist\n    ]\n\n    results = []\n    \n    for case in test_cases:\n        N, k, l = case\n\n        # Grid spacing h.\n        h = 1.0 / (N + 1)\n        \n        # 1. Construct the initial error mode on an (N+2)x(N+2) grid to\n        #    include boundaries. Boundaries are initialized to 0.\n        \n        # Create coordinate arrays for the interior grid.\n        i_vals = np.arange(1, N + 1)\n        j_vals = np.arange(1, N + 1)\n        ii, jj = np.meshgrid(i_vals, j_vals, indexing='ij')\n\n        # Calculate the un-normalized sine mode on the interior.\n        phi_interior = np.sin(k * np.pi * ii * h) * np.sin(l * np.pi * jj * h)\n\n        # 2. Normalize the mode in the discrete l2 norm.\n        norm = np.linalg.norm(phi_interior)\n        \n        # Check for zero norm to prevent division by zero, although not expected here.\n        if norm == 0:\n            normalized_phi_interior = phi_interior\n        else:\n            normalized_phi_interior = phi_interior / norm\n\n        # The initial state u_0 is the normalized mode.\n        # This grid will be modified by the GS sweeps.\n        u = np.zeros((N + 2, N + 2))\n        u[1:N+1, 1:N+1] = normalized_phi_interior\n\n        # Store a copy of the normalized initial mode for the final projection.\n        phi_normalized = u.copy()\n        \n        # 3. Apply four sweeps of lexicographic Gauss-Seidel relaxation.\n        num_sweeps = 4\n        for _ in range(num_sweeps):\n            # The loops must be in lexicographic order (row-by-row, col-by-col).\n            # The update is done in-place, which is the definition of GS.\n            for i in range(1, N + 1):\n                for j in range(1, N + 1):\n                    # Pointwise update rule derived from the 5-point stencil.\n                    u[i, j] = 0.25 * (u[i-1, j] + u[i+1, j] + u[i, j-1] + u[i, j+1])\n\n        # 4. Quantify the amplification factor.\n        # The final state of the grid is u (which is u^(4)).\n        # We project u^(4) onto the initial normalized mode phi_normalized.\n        # The denominator is 1 due to normalization.\n        numerator = np.sum(phi_normalized * u)\n        \n        amplification_factor = np.abs(numerator)\n        \n        results.append(amplification_factor)\n\n    # Final print statement in the exact required format.\n    # Round results to six decimal places.\n    formatted_results = [f\"{res:.6f}\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3480320"}, {"introduction": "理解了平滑器的作用后，下一个关键是掌握多重网格循环的结构及其卓越的计算效率。一个完整的多重网格循环（如V循环或W循环）通过在各层网格之间递归地传递校正，实现了计算复杂度与问题规模的线性关系。本练习要求您从第一性原理出发，推导W循环的总计算工作量，从而从理论上验证多重网格方法的效率优势。[@problem_id:3480278]", "problem": "在广义相对论 (GR) 中构建致密天体双星的满足约束的初始数据时，通常会使用几何多重网格 (MG) 方法在均匀的矩形网格上求解一个线性椭圆型偏微分方程 (PDE)。考虑在细网格上的这样一个离散化，其在$x$和$y$方向上分别有$N_x \\times N_y$个内部自由度 (DOF)。通过均匀粗化形成一个几何网格层级，在每一层将每个维度减半，直至大小为$N_{x,c} \\times N_{y,c}$的最小粗网格。假设粗化是各向同性的，即对于某个整数$L \\geq 0$，有$N_x / N_{x,c} = N_y / N_{y,c} = 2^L$，因此该层级有$L+1$层，由$\\ell = 0,1,\\dots,L$索引，其中$\\ell=0$是细网格层，$\\ell=L$是最小粗网格层。\n\n一个多重网格W循环从细网格层开始执行：在每个非最粗层，算法在向上返回之前会两次下降到下一个更粗的层级。定义一个“工作单元”为对一个自由度进行一次处理，并假设在$\\ell$层单次访问期间的总局部操作（包括光滑、残差计算、限制、延长和校正）代价为$\\mathcal{O}(N^{(\\ell)})$个工作单元，其中$N^{(\\ell)}$是$\\ell$层的自由度数量。取比例常数为$1$，因此每次访问$\\ell$层的代价恰好是$N^{(\\ell)}$个工作单元，在最小粗网格层上的代价也是$N^{(L)}$。\n\n请用$N_x$、$N_y$、$N_{x,c}$、$N_{y,c}$和$L$显式地构建网格层级，然后，从这些定义和W循环的递归结构出发，推导出一个闭式解析表达式，表示从细网格层$\\ell=0$开始的一个W循环所需的总工作单元数$C^{(0)}$。请将您的最终答案表示为关于$N_x$、$N_y$和$L$的单个解析表达式；您可以使用定义$L = \\log_2\\!\\big(N_x/N_{x,c}\\big) = \\log_2\\!\\big(N_y/N_{y,c}\\big)$来关联$L$和网格大小。不需要进行数值计算或四舍五入。", "solution": "### 第1步：提取已知条件\n- 问题域是一个用于求解线性椭圆型偏微分方程的均匀矩形网格。\n- 细网格有$N_x \\times N_y$个内部自由度 (DOF)。\n- 通过均匀粗化（在每一层将每个维度减半）形成一个几何网格层级。\n- 最粗网格的大小为$N_{x,c} \\times N_{y,c}$。\n- 粗化是各向同性的：$N_x / N_{x,c} = N_y / N_{y,c} = 2^L$，其中$L \\ge 0$为整数。\n- 该层级有$L+1$层，由$\\ell = 0, 1, \\dots, L$索引。$\\ell=0$层是细网格，$\\ell=L$层是最粗网格。\n- 一个多重网格W循环从任何非最粗层级下降到下一个更粗的层级两次。\n- 一个“工作单元”是对一个自由度进行一次操作。\n- 在一次访问中，在$\\ell$层的总局部操作代价为$N^{(\\ell)}$个工作单元，其中$N^{(\\ell)}$是$\\ell$层的自由度数量。\n- 在最粗层求解的代价是$N^{(L)}$。\n- 任务是求出从细网格层$\\ell=0$开始的一个W循环所需的总工作单元数$C^{(0)}$。\n\n### 第2步：使用提取的已知条件进行验证\n该问题是算法分析中一个明确定义的问题，具体应用于数值分析中广泛使用的多重网格方法。\n- **科学性：** 上下文和方法（数值相对论中用于求解椭圆方程的多重网格求解器）是标准的，代表了计算科学和物理学的一个核心课题。计算代价模型是用于理论分析的常见简化。该问题不含伪科学或事实错误。\n- **适定性：** 问题提供了构建和求解计算代价的递推关系所需的所有信息。定义清晰，可以得出一个唯一的解析解。\n- **客观性：** 语言精确且技术性强，没有歧义或主观论断。\n\n该问题没有违反任何无效标准。它是一个形式化、相关、完整且结构良好的问题，植根于既定的科学计算原则。\n\n### 第3步：结论与行动\n该问题被判定为**有效**。将提供完整解答。\n\n### 解题推导\n\n求解过程首先定义网格层级中每一层的自由度（DOF）数量，然后为W循环的计算代价建立一个递推关系，最后求解该递推关系以获得一个闭式表达式。\n\n**1. 网格层级构建**\n设$N^{(\\ell)}$为网格层级第$\\ell$层的自由度数量。\n细网格在$\\ell=0$层，有$N^{(0)} = N_x N_y$个自由度。\n根据题意，$\\ell+1$层的网格是通过将$\\ell$层网格的每个维度减半而形成的。对于二维网格，这意味着自由度的数量减少了$2 \\times 2 = 4$倍。\n因此，连续层级之间自由度的关系是：\n$$N^{(\\ell+1)} = \\frac{N^{(\\ell)}}{4}$$\n通过重复应用，我们可以用细网格的自由度$N^{(0)}$来表示任意$\\ell$层上的自由度数量：\n$$N^{(\\ell)} = \\frac{N^{(0)}}{4^\\ell} = \\frac{N_x N_y}{4^\\ell}$$\n这对所有层级$\\ell = 0, 1, \\dots, L$都成立。\n\n**2. W循环代价的递推关系**\n设$C^{(\\ell)}$表示从$\\ell$层开始的一个W循环的总工作单元数。\n在非最粗层$\\ell$（其中$\\ell  L$）的一个W循环包括：\n- 在$\\ell$层上的局部操作（光滑、残差计算、限制、延长、校正）。题目说明这些操作的总代价是$N^{(\\ell)}$。\n- 对下一个更粗的层级$\\ell+1$进行两次W循环的递归调用。每次调用的代价是$C^{(\\ell+1)}$。\n\n该结构给出了总代价$C^{(\\ell)}$（对于$\\ell \\in \\{0, 1, \\dots, L-1\\}$）的以下递推关系：\n$$C^{(\\ell)} = N^{(\\ell)} + 2 C^{(\\ell+1)}$$\n在最粗层$\\ell=L$，问题被直接求解（例如，通过直接求解器或迭代光滑）。题目规定此代价为$N^{(L)}$。这为我们的递归提供了基例：\n$$C^{(L)} = N^{(L)}$$\n\n**3. 求解递推关系**\n我们想要求解$C^{(0)}$，即从细网格开始的W循环的代价。我们可以通过从$\\ell=0$开始展开递推关系来求解：\n$$C^{(0)} = N^{(0)} + 2 C^{(1)}$$\n代入$C^{(1)}$的表达式：\n$$C^{(0)} = N^{(0)} + 2 \\left( N^{(1)} + 2 C^{(2)} \\right) = N^{(0)} + 2 N^{(1)} + 4 C^{(2)}$$\n继续这个代入过程，直到达到最粗层$L$：\n$$C^{(0)} = N^{(0)} + 2 N^{(1)} + 4 N^{(2)} + \\dots + 2^{L-1} N^{(L-1)} + 2^L C^{(L)}$$\n现在，我们代入基例$C^{(L)} = N^{(L)}$：\n$$C^{(0)} = N^{(0)} + 2 N^{(1)} + 4 N^{(2)} + \\dots + 2^{L-1} N^{(L-1)} + 2^L N^{(L)}$$\n这可以用求和符号紧凑地表示为：\n$$C^{(0)} = \\sum_{j=0}^{L} 2^j N^{(j)}$$\n\n**4. 最终的闭式表达式**\n为了得到闭式表达式，我们代入第1步中$N^{(j)}$的公式，$N^{(j)} = N^{(0)} / 4^j$：\n$$C^{(0)} = \\sum_{j=0}^{L} 2^j \\left( \\frac{N^{(0)}}{4^j} \\right)$$\n提出常数$N^{(0)}$：\n$$C^{(0)} = N^{(0)} \\sum_{j=0}^{L} \\frac{2^j}{4^j} = N^{(0)} \\sum_{j=0}^{L} \\left( \\frac{2}{4} \\right)^j = N^{(0)} \\sum_{j=0}^{L} \\left( \\frac{1}{2} \\right)^j$$\n该求和是一个有限几何级数$\\sum_{k=0}^{n} r^k$，其中项数为$n=L$，公比为$r=1/2$。这种级数的和由公式$\\frac{1-r^{n+1}}{1-r}$给出。\n应用此公式，我们得到：\n$$\\sum_{j=0}^{L} \\left( \\frac{1}{2} \\right)^j = \\frac{1 - \\left(\\frac{1}{2}\\right)^{L+1}}{1 - \\frac{1}{2}} = \\frac{1 - \\frac{1}{2^{L+1}}}{\\frac{1}{2}} = 2 \\left( 1 - \\frac{1}{2^{L+1}} \\right) = 2 - \\frac{2}{2^{L+1}} = 2 - \\frac{1}{2^L}$$\n将此结果代回$C^{(0)}$的表达式中：\n$$C^{(0)} = N^{(0)} \\left( 2 - \\frac{1}{2^L} \\right)$$\n最后，将$N^{(0)}$替换为其定义$N_x N_y$，我们得到一个W循环的总工作单元数：\n$$C^{(0)} = N_x N_y \\left( 2 - \\frac{1}{2^L} \\right)$$\n这个表达式是用所需的变量$N_x$、$N_y$和$L$表示的。", "answer": "$$\n\\boxed{\nN_x N_y \\left( 2 - 2^{-L} \\right)\n}\n$$", "id": "3480278"}, {"introduction": "理论上的理想模型（如常系数泊松方程）是学习的良好起点，但实际的数值相对论问题通常涉及复杂的变系数椭圆方程。在这种情况下，如何构建粗网格算子成为一个核心挑战，直接影响求解器的稳定性和收敛性。本练习将引导您实现并对比两种主流的粗网格算子构建方法——直接重散化法与伽辽金（Galerkin）方法，通过量化它们的差异，让您深刻理解为何伽辽金方法在处理复杂问题时通常是更优越的选择。[@problem_id:3480295]", "problem": "考虑一个变系数类泊松算子，该算子出现在数值相对论的椭圆约束中，例如在构造引力波初始数据时，由以下偏微分方程给出：$- \\nabla \\cdot (\\kappa(x,y) \\nabla u(x,y)) = f(x,y)$，定义在开放单位正方形 $\\Omega = (0,1) \\times (0,1)$ 上，边界条件为齐次狄利克雷边界条件 $u(x,y) = 0$ on $\\partial \\Omega$。定义一个大小为 $N \\times N$（包括边界节点）的均匀节点网格，其间距为 $h = 1/(N-1)$，内部索引集为 $\\{1,2,\\dots,N-2\\} \\times \\{1,2,\\dots,N-2\\}$。使用基于面心系数的保守二阶有限差分离散格式，构建一个对称正定矩阵算子 $A_f \\in \\mathbb{R}^{n_f \\times n_f}$，其中 $n_f = (N_f-2)^2$，该算子作用于细网格内部未知向量，而 $N_f$ 是细网格的节点数。\n\n内部节点 $(i,j)$ 处的离散算子由通量形式定义为\n$$\n(L_h u)_{i,j} = -\\frac{1}{h^2} \\Big( \\kappa_{i+\\frac{1}{2},j} (u_{i+1,j} - u_{i,j}) - \\kappa_{i-\\frac{1}{2},j} (u_{i,j} - u_{i-1,j}) + \\kappa_{i,j+\\frac{1}{2}} (u_{i,j+1} - u_{i,j}) - \\kappa_{i,j-\\frac{1}{2}} (u_{i,j} - u_{i,j-1}) \\Big),\n$$\n其中面心系数由 $\\kappa_{i+\\frac{1}{2},j} = \\kappa(x_{i+\\frac{1}{2}}, y_j)$ 和 $\\kappa_{i,j+\\frac{1}{2}} = \\kappa(x_i, y_{j+\\frac{1}{2}})$ 给出，其中 $x_{i+\\frac{1}{2}} = x_i + h/2$ 且 $y_{j+\\frac{1}{2}} = y_j + h/2$。连续系数定义为\n$$\n\\kappa(x,y) = 1 + a \\sin(2\\pi m x)\\cos(2\\pi m y),\n$$\n其中振幅 $a \\in [0,1)$，整数频率 $m \\geq 1$，以确保 $\\kappa(x,y)  0$。\n\n设粗网格为几何嵌套，节点数为 $N_c = (N_f + 1)/2$，间距为 $H = 1/(N_c-1)$，内部大小为 $n_c = (N_c - 2)^2$。定义标准的双线性插值（延拓）算子 $P \\in \\mathbb{R}^{n_f \\times n_c}$，将粗网格内部未知数映射到细网格内部未知数，具体如下：对于每个细网格内部节点 $(i,j)$，插值是其周围粗网格节点值的双线性组合；当所需的粗网格节点位于边界上时，由于齐次狄利克雷边界条件，其贡献为零。使用如下 $3 \\times 3$ 模板权重定义全加权限制算子 $R \\in \\mathbb{R}^{n_c \\times n_f}$\n$$\n\\frac{1}{16}\n\\begin{bmatrix}\n1  2  1 \\\\\n2  4  2 \\\\\n1  2  1\n\\end{bmatrix}\n$$\n该模板以与粗网格节点重合的细网格节点为中心。\n\n基于以上定义，Galerkin 粗网格算子为 $A_c^{\\mathrm{Gal}} = R A_f P \\in \\mathbb{R}^{n_c \\times n_c}$。重新离散化的粗网格算子 $A_c^{\\mathrm{Red}} \\in \\mathbb{R}^{n_c \\times n_c}$ 是通过在粗网格上应用相同的保守二阶格式（间距为 $H$）并在粗网格面上计算连续系数 $\\kappa(x,y)$ 得到的。\n\n任务：\n- 在细网格上使用指定的通量形式离散和从 $\\kappa(x,y)$ 计算的面心系数来构建 $A_f$。\n- 根据指定的齐次狄利克雷边界条件构建使用双线性插值的 $P$ 算子，并根据指定的全加权方式构建 $R$ 算子。\n- 计算 Galerkin 粗网格算子 $A_c^{\\mathrm{Gal}} = R A_f P$。\n- 通过在粗网格上使用相同的格式和从相同的 $\\kappa(x,y)$ 计算的面心系数进行重新离散化来构建 $A_c^{\\mathrm{Red}}$。\n- 对每个测试用例，计算相对 Frobenius 范数差\n$$\n\\delta = \\frac{\\lVert A_c^{\\mathrm{Gal}} - A_c^{\\mathrm{Red}} \\rVert_F}{\\lVert A_c^{\\mathrm{Red}} \\rVert_F}。\n$$\n\n推导和算法的基本要求：\n- 从 $- \\nabla \\cdot (\\kappa \\nabla u)$ 在结构化网格上的保守二阶离散定义开始。\n- 使用 Galerkin 粗网格算子、双线性插值和全加权限制的几何多重网格定义。\n- 在适用的情况下，通过零边界贡献确保与齐次狄利克雷边界条件的一致性。\n\n测试套件：\n- 用例 1 (一般变系数，中等网格)：$N_f = 33$，$a = 0.5$，$m = 1$。\n- 用例 2 (常系数，基准)：$N_f = 33$，$a = 0.0$，$m = 1$。\n- 用例 3 (变系数，较小网格)：$N_f = 17$，$a = 0.9$，$m = 1$。\n- 用例 4 (较高频系数，中等网格)：$N_f = 33$，$a = 0.7$，$m = 4$。\n\n输出规范：\n- 程序应输出单行结果，其中包含一个方括号括起来的逗号分隔列表，列表内容是与上述四个测试用例按顺序对应的四个浮点数值 $\\delta$。例如，格式必须与 $[\\delta_1,\\delta_2,\\delta_3,\\delta_4]$ 完全一样，每个 $\\delta$ 打印为 Python 浮点数。", "solution": "该问题要求比较用于求解变系数椭圆偏微分方程的两种不同粗网格算子。该比较基于 Galerkin 粗网格算子 $A_c^{\\mathrm{Gal}}$ 与重新离散化的粗网格算子 $A_c^{\\mathrm{Red}}$ 之间的相对 Frobenius 范数差。\n\n该问题定义明确，在数值分析领域有坚实的科学基础，尤其适用于求解数值相对论中的椭圆约束方程。所有参数和定义均已提供，可以直接明确地实现。我将系统地构造所需的矩阵。\n\n### 1. 连续算子的离散化\n\n连续问题是求解偏微分方程 (PDE)\n$$\n- \\nabla \\cdot (\\kappa(x,y) \\nabla u(x,y)) = f(x,y)\n$$\n在单位正方形 $\\Omega = (0,1) \\times (0,1)$ 上，边界条件为齐次狄利克雷边界条件 $u(x,y) = 0$ on $\\partial \\Omega$。系数 $\\kappa(x,y)$ 由 $\\kappa(x,y) = 1 + a \\sin(2\\pi m x)\\cos(2\\pi m y)$ 给出。\n\n我们在一个具有 $N \\times N$ 个节点和间距 $h = 1/(N-1)$ 的均匀网格上离散此方程。令 $u_{i,j}$ 表示解在网格节点 $(x_i, y_j) = (ih, jh)$ 处的值。问题指定了保守二阶有限差分格式。对于内部节点 $(i,j)$（$i,j \\in \\{1, \\dots, N-2\\}$），离散算子 $L_h$ 为\n$$\n(L_h u)_{i,j} = -\\frac{1}{h^2} \\Big( \\kappa_{i+\\frac{1}{2},j} (u_{i+1,j} - u_{i,j}) - \\kappa_{i-\\frac{1}{2},j} (u_{i,j} - u_{i-1,j}) + \\kappa_{i,j+\\frac{1}{2}} (u_{i,j+1} - u_{i,j}) - \\kappa_{i,j-\\frac{1}{2}} (u_{i,j} - u_{i,j-1}) \\Big).\n$$\n面心系数是 $\\kappa(x,y)$ 在节点间中点处的取值，例如 $\\kappa_{i+\\frac{1}{2},j} = \\kappa(x_i + h/2, y_j)$。\n\n离散方程组为 $A \\mathbf{u} = \\mathbf{f}$，其中 $\\mathbf{u}$ 是 $n = (N-2)^2$ 个内部网格点上未知值的向量。矩阵 $A$ 表示离散算子的负值，即 $-L_h$。通过重新排列 $(L_h u)_{i,j}$ 的项，我们可以确定矩阵 $A$ 的模板：\n$$\n(A \\mathbf{u})_{i,j} = \\frac{1}{h^2} \\Big[ (\\kappa_{i+\\frac{1}{2},j} + \\kappa_{i-\\frac{1}{2},j} + \\kappa_{i,j+\\frac{1}{2}} + \\kappa_{i,j-\\frac{1}{2}}) u_{i,j} - \\kappa_{i+\\frac{1}{2},j} u_{i+1,j} - \\kappa_{i-\\frac{1}{2},j} u_{i-1,j} - \\kappa_{i,j+\\frac{1}{2}} u_{i,j+1} - \\kappa_{i,j-\\frac{1}{2}} u_{i,j-1} \\Big].\n$$\n向量 $\\mathbf{u}$ 通过将 $u_{i,j}$ 值按特定顺序（通常是行主序）排列而成。对于内部索引 $i,j \\in \\{1, \\dots, N-2\\}$，从二维网格索引 $(i,j)$到一维向量索引 $k$ 的映射是 $k = (i-1)(N-2) + (j-1)$。这种结构定义了一个大小为 $n \\times n$ 的稀疏对称正定矩阵 $A$。齐次狄利克雷边界条件的处理方式是注意到，当 $i$ 或 $j$ 为 $0$ 或 $N-1$ 时，任何 $u_{i,j}$ 都为零，因此这些项在邻近边界的内部节点的方程中被消去。\n\n细网格算子 $A_f$ 和粗网格重新离散化算子 $A_c^{\\mathrm{Red}}$ 都使用此方法构建，但分别使用不同的网格参数（$N_f, h$）和（$N_c, H$）。\n\n### 2. 网格间传输算子：延拓与限制\n\n给定一个每维有 $N_f$ 个点的细网格和一个有 $N_c = (N_f+1)/2$ 个点的粗网格。相应的内部问题大小为 $n_f = (N_f-2)^2$ 和 $n_c = (N_c-2)^2$。\n\n**延拓（插值）算子 $P$**：延拓算子 $P \\in \\mathbb{R}^{n_f \\times n_c}$ 将粗网格内部值的向量映射到细网格内部值的向量。我们使用双线性插值。对于一个细网格内部点 $(i_f, j_f)$，其值是周围四个粗网格点值的插值。权重取决于细网格点相对于粗网格的位置。\n- 与粗网格点 $(2i_c, 2j_c)$ 重合的细网格点，其值直接取自该粗网格点。\n- 位于网格边上的细网格点，例如 $(2i_c+1, 2j_c)$，是两个相邻粗网格点的平均值。\n- 位于单元中心的细网格点 $(2i_c+1, 2j_c+1)$，是周围四个粗网格点的平均值。\n由于齐次狄利克雷条件，来自粗网格边界点的贡献为零。矩阵 $P$ 的每一行都是通过确定相应细网格点的这些权重来构建的。\n\n**限制算子 $R$**：限制算子 $R \\in \\mathbb{R}^{n_c \\times n_f}$ 将细网格向量映射到粗网格向量。我们使用全加权限制。粗网格内部点 $(i_c, j_c)$ 处的值是其对应细网格位置 $(2i_c, 2j_c)$ 周围 $3 \\times 3$ 细网格点块值的加权平均。权重由以下模板给出：\n$$\n\\frac{1}{16}\n\\begin{bmatrix}\n1  2  1 \\\\\n2  4  2 \\\\\n1  2  1\n\\end{bmatrix}.\n$$\n与延拓一样，边界上的细网格点值为零，对求和没有贡献。\n\n### 3. 粗网格算子与比较\n\n定义粗网格算子有两种方法。\n\n**重新离散化的算子 $A_c^{\\mathrm{Red}}$**：该算子通过直接在间距为 $H = 1/(N_c-1)$ 的粗网格上应用相同的有限差分离散格式来构建。系数函数 $\\kappa(x,y)$ 在粗网格单元的面心处求值。这种方法很简单，但可能无法捕捉到在粗网格上发生混叠的 $\\kappa(x,y)$ 的细尺度变化。\n\n**Galerkin 算子 $A_c^{\\mathrm{Gal}}$**：该算子由所谓的 Galerkin 投影定义：$A_c^{\\mathrm{Gal}} = R A_f P$。它代表了从粗网格“视角”看到的细网格算子。这种构造方式计算成本更高，但能保证捕捉到细网格算子 $A_f$ 的性质，使其对于具有复杂或快速变化系数的问题更加稳健。\n\n这两种算子之间的根本区别在于数值误差的来源。$A_c^{\\mathrm{Red}}$ 的性质继承自粗网格上离散化的截断误差。$A_c^{\\mathrm{Gal}}$ 的性质通过投影继承自细网格算子。对于常系数 κ，两者并不相同；$A_c^{\\mathrm{Red}}$ 通常具有 5 点模板，而 $A_c^{\\mathrm{Gal}}$ 则具有 9 点模板。对于变系数 κ，差异可能更为显著。\n\n需要计算的量是相对 Frobenius 范数差：\n$$\n\\delta = \\frac{\\lVert A_c^{\\mathrm{Gal}} - A_c^{\\mathrm{Red}} \\rVert_F}{\\lVert A_c^{\\mathrm{Red}} \\rVert_F},\n$$\n其中 $\\lVert M \\rVert_F = \\sqrt{\\sum_{i,j} |M_{ij}|^2}$。该度量量化了两种粗网格算子定义之间的差异。\n\n算法的执行过程是实现函数来为给定参数构建四个矩阵（$A_f$, $A_c^{\\mathrm{Red}}$, $P$, $R$），然后执行矩阵乘法得到 $A_c^{\\mathrm{Gal}}$，最后计算 $\\delta$。对四个测试用例中的每一个都重复此过程。", "answer": "```python\nimport numpy as np\n\ndef kappa(x, y, a, m):\n    \"\"\"Computes the continuous coefficient kappa(x,y).\"\"\"\n    return 1.0 + a * np.sin(2 * np.pi * m * x) * np.cos(2 * np.pi * m * y)\n\ndef construct_operator(N, a, m):\n    \"\"\"\n    Constructs the discrete operator matrix A for a given grid size N\n    and coefficient parameters a, m.\n    \"\"\"\n    if N == 2:\n        return np.array([[]])\n    \n    n = (N - 2)**2\n    h = 1.0 / (N - 1)\n    A = np.zeros((n, n))\n    \n    width = N - 2\n    coords = np.linspace(0, 1, N)\n\n    for i in range(1, N - 1):      # 1-based row index\n        for j in range(1, N - 1):  # 1-based column index\n            k = (i - 1) * width + (j - 1) # 0-based 1D index\n            \n            x_i, y_j = coords[i], coords[j]\n            \n            k_ip12 = kappa(x_i + h / 2.0, y_j, a, m)\n            k_im12 = kappa(x_i - h / 2.0, y_j, a, m)\n            k_jp12 = kappa(x_i, y_j + h / 2.0, a, m)\n            k_jm12 = kappa(x_i, y_j - h / 2.0, a, m)\n\n            # Diagonal entry\n            A[k, k] = (k_ip12 + k_im12 + k_jp12 + k_jm12) / h**2\n            \n            # Off-diagonal entries (connections to neighbors)\n            # Connection to u_{i, j+1} (North)\n            if j  N - 2:\n                A[k, k + 1] = -k_jp12 / h**2\n            # Connection to u_{i, j-1} (South)\n            if j  1:\n                A[k, k - 1] = -k_jm12 / h**2\n            # Connection to u_{i+1, j} (East)\n            if i  N - 2:\n                A[k, k + width] = -k_ip12 / h**2\n            # Connection to u_{i-1, j} (West)\n            if i  1:\n                A[k, k - width] = -k_im12 / h**2\n                \n    return A\n\ndef construct_prolongation(N_f, N_c):\n    \"\"\"Constructs the bilinear interpolation (prolongation) operator P.\"\"\"\n    n_f = (N_f - 2)**2\n    n_c = (N_c - 2)**2\n    if n_f == 0 or n_c == 0:\n        return np.zeros((n_f, n_c))\n\n    P = np.zeros((n_f, n_c))\n    width_f = N_f - 2\n    width_c = N_c - 2\n    \n    for i_f in range(1, N_f - 1):\n        for j_f in range(1, N_f - 1):\n            k_f = (i_f - 1) * width_f + (j_f - 1)\n            \n            is_i_f_even = (i_f % 2 == 0)\n            is_j_f_even = (j_f % 2 == 0)\n\n            if is_i_f_even and is_j_f_even:\n                # Type 1: Fine node coincides with a coarse node\n                i_c, j_c = i_f // 2, j_f // 2\n                if 1 = i_c = N_c - 2 and 1 = j_c = N_c - 2:\n                    k_c = (i_c - 1) * width_c + (j_c - 1)\n                    P[k_f, k_c] = 1.0\n\n            elif not is_i_f_even and is_j_f_even:\n                # Type 2: Fine node on a vertical coarse-grid edge\n                j_c = j_f // 2\n                i_c_lo = (i_f - 1) // 2\n                i_c_hi = i_c_lo + 1\n                if 1 = j_c = N_c - 2:\n                    if 1 = i_c_lo = N_c - 2:\n                        k_c1 = (i_c_lo - 1) * width_c + (j_c - 1)\n                        P[k_f, k_c1] = 0.5\n                    if 1 = i_c_hi = N_c - 2:\n                        k_c2 = (i_c_hi - 1) * width_c + (j_c - 1)\n                        P[k_f, k_c2] = 0.5\n            \n            elif is_i_f_even and not is_j_f_even:\n                # Type 3: Fine node on a horizontal coarse-grid edge\n                i_c = i_f // 2\n                j_c_lo = (j_f - 1) // 2\n                j_c_hi = j_c_lo + 1\n                if 1 = i_c = N_c - 2:\n                    if 1 = j_c_lo = N_c - 2:\n                        k_c1 = (i_c - 1) * width_c + (j_c_lo - 1)\n                        P[k_f, k_c1] = 0.5\n                    if 1 = j_c_hi = N_c - 2:\n                        k_c2 = (i_c - 1) * width_c + (j_c_hi - 1)\n                        P[k_f, k_c2] = 0.5\n\n            elif not is_i_f_even and not is_j_f_even:\n                # Type 4: Fine node at a coarse-cell center\n                i_c_lo, j_c_lo = (i_f - 1) // 2, (j_f - 1) // 2\n                i_c_hi, j_c_hi = i_c_lo + 1, j_c_lo + 1\n                \n                nodes = [(i_c_lo, j_c_lo), (i_c_hi, j_c_lo), \n                         (i_c_lo, j_c_hi), (i_c_hi, j_c_hi)]\n                for i_c, j_c in nodes:\n                    if 1 = i_c = N_c - 2 and 1 = j_c = N_c - 2:\n                        k_c = (i_c - 1) * width_c + (j_c - 1)\n                        P[k_f, k_c] = 0.25\n    return P\n\ndef construct_restriction(N_f, N_c):\n    \"\"\"Constructs the full-weighting restriction operator R.\"\"\"\n    n_f = (N_f - 2)**2\n    n_c = (N_c - 2)**2\n    if n_f == 0 or n_c == 0:\n        return np.zeros((n_c, n_f))\n        \n    R = np.zeros((n_c, n_f))\n    width_f = N_f - 2\n    width_c = N_c - 2\n    \n    weights = np.array([[1, 2, 1], [2, 4, 2], [1, 2, 1]]) / 16.0\n    \n    for i_c in range(1, N_c - 1):\n        for j_c in range(1, N_c - 1):\n            k_c = (i_c - 1) * width_c + (j_c - 1)\n            i_f_center, j_f_center = 2 * i_c, 2 * j_c\n            \n            for di in range(-1, 2):\n                for dj in range(-1, 2):\n                    i_f, j_f = i_f_center + di, j_f_center + dj\n                    \n                    if 1 = i_f = N_f - 2 and 1 = j_f = N_f - 2:\n                        k_f = (i_f - 1) * width_f + (j_f - 1)\n                        R[k_c, k_f] = weights[di + 1, dj + 1]\n    return R\n\ndef compute_delta(N_f, a, m):\n    \"\"\"\n    Computes the relative Frobenius-norm difference for a given test case.\n    \"\"\"\n    # Grid parameters\n    N_c = (N_f + 1) // 2\n    \n    # Construct operators\n    A_f = construct_operator(N_f, a, m)\n    P = construct_prolongation(N_f, N_c)\n    R = construct_restriction(N_f, N_c)\n    A_c_red = construct_operator(N_c, a, m)\n    \n    # Compute Galerkin operator\n    A_c_gal = R @ A_f @ P\n    \n    # Compute relative difference\n    diff_norm = np.linalg.norm(A_c_gal - A_c_red, 'fro')\n    red_norm = np.linalg.norm(A_c_red, 'fro')\n    \n    if red_norm == 0:\n        return 0.0 if diff_norm == 0 else np.inf\n        \n    return diff_norm / red_norm\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    test_cases = [\n        (33, 0.5, 1),\n        (33, 0.0, 1),\n        (17, 0.9, 1),\n        (33, 0.7, 4),\n    ]\n\n    results = []\n    for case in test_cases:\n        Nf, a, m = case\n        delta = compute_delta(Nf, a, m)\n        results.append(delta)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3480295"}]}