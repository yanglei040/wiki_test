{"hands_on_practices": [{"introduction": "本练习是我们探索并行计算范式的基石。我们将从第一性原理出发，为共享内存和分布式内存系统构建性能模型，并将其应用于常见的地球物理模板计算。通过对缓存行伪共享和消息传递晕轮交换等微妙但关键的效应进行显式建模，您将对这两种主流并行架构之间的根本性能权衡获得定量的理解。[@problem_id:3614253]", "problem": "您需要设计并实现一个完整的、可运行的程序，用于预测在两种并行范式下地球物理模板更新的每时间步运行时间：多核节点上的缓存一致性共享内存，以及使用消息传递的分布式内存。该预测模型必须基于内存一致性、缓存行粒度以及用于晕轮交换的邻居通信等第一性原理构建。您的程序必须使用一个基于基本计算机体系结构和并行通信概念的原则性成本模型来计算预测的运行时间，而不是依赖经验性捷径。\n\n计算核心是在结构化网格上的最近邻模板更新。每次更新会读取固定数量的邻近元素，并为每个网格点写入一个输出元素。假设每个元素的计算成本相同，并采用写分配缓存。对于共享内存，不同的线程更新不相交的连续块，但可能会无意中写入映射到同一缓存行的不同元素，从而产生伪共享。对于分布式内存，每个进程更新其子域，并与其邻居交换宽度等于模板半径的晕轮。\n\n从以下基本原理出发：\n- 基于写失效协议的缓存一致性：一个核心对缓存行中任何字的写入都会使该行在其他核心中失效。如果两个核心在某个时间窗口内写入同一缓存行内的不同字，就会引发一致性流量。将此建模为由于失效和重新填充而导致的每个冲突缓存行的附加开销。\n- 内存以缓存行粒度进行传输。假设如果缓存行在本地不处于修改（M）状态，每次写入都会触发一次写分配。\n- 理想的工作划分：计算负载均匀分配。\n- 消息传递的邻居交换遵循标准的延迟-带宽模型：发送一个大小为 $b$ 字节的消息所需的时间为 $\\alpha + \\beta b$，其中 $\\alpha$ 是延迟，$\\beta$ 是逆带宽。\n- 在一维中，半径为 $r$ 的模板在每个时间步的每个边界需要一个宽度为 $r$ 的晕轮；在二维中，如果沿一个轴进行一维分区，则晕轮的横截面等于正交维度。\n\n推导一个运行时间模型，该模型结合了以下从第一性原理出发的组件：\n- 基于每元素成本、元素总数和并行度的计算时间贡献。\n- 由于高核心数下协议簿记的开销，每个线程存在一个与线程数量呈线性关系的通用一致性维护成本。\n- 一个与伪共享冲突数量成正比的额外一致性惩罚，冲突的判定取决于相邻线程的子域边界是否切过正在写入的数组的缓存行。\n\n对于一维网格，假设线程沿单一轴将域划分为连续的块。设每个缓存行的元素数量为 $E_{\\ell} = \\lfloor B_{\\ell}/B_{e} \\rfloor$，其中 $B_{\\ell}$ 是缓存行大小（字节），$B_{e}$ 是元素大小（字节）。如果对于 $L$ 个元素和 $N$ 个线程，每个线程的块大小为 $S = \\lfloor L/N \\rfloor$，那么线程 $k$ 和 $k+1$ 之间的边界位于索引 $k S$ 处。如果 $k S \\bmod E_{\\ell} \\neq 0$，则每个边界算作一次伪共享冲突，其中 $k \\in \\{1,\\dots,N-1\\}$。每步的总冲突数是此类未对齐边界的数量。\n\n对于行主序的二维网格，假设沿 $x$ 轴划分为 $N$ 个连续的板（slab），每个板的宽度为 $S_{x} = \\lfloor N_{x}/N \\rfloor$ 列，并跨越所有 $N_{y}$ 行。当且仅当 $k S_{x} \\bmod E_{\\ell} \\neq 0$ 时，位于列 $k S_{x}$ 的边界会切过每一行内的缓存行。对于每个未对齐的边界，每行算作一次伪共享冲突，即每个未对齐的边界总共有 $N_{y}$ 次冲突。假设只读的邻居加载不会导致失效；在计算伪共享时只考虑对输出数组的写入。\n\n对于具有一维分区的分布式内存，将每步的通信时间推导为两次邻居交换（左和右，或上和下）的总和，每次交换都有延迟 $\\alpha$ 和有效载荷字节数，该字节数由晕轮宽度乘以横截面和元素大小得出。假设每个进程每步发送两条消息，每侧一条，这些消息不与计算重叠，并且线性求和。\n\n物理单位：所有时间必须以秒表示。您的程序必须为每个测试用例生成一个四舍五入到九位有效数字的数值答案。\n\n实现该模型并计算以下测试套件的预测每步运行时间。每个测试用例都是独立的，您的程序应为其输出一个浮点数。\n\n测试套件：\n- 案例1（共享内存，一维，对齐）：$L = 1048576$ 个元素， $N = 8$ 个线程， $B_{\\ell} = 64$ 字节， $B_{e} = 8$ 字节，每元素计算成本 $c = 2 \\times 10^{-9}$ 秒，每线程一致性开销 $\\gamma = 10^{-6}$ 秒，每冲突惩罚 $\\delta = 2 \\times 10^{-7}$ 秒。\n- 案例2（共享内存，一维，未对齐）：$L = 1000000$ 个元素， $N = 6$ 个线程， $B_{\\ell} = 64$ 字节， $B_{e} = 8$ 字节， $c = 2 \\times 10^{-9}$ 秒， $\\gamma = 10^{-6}$ 秒， $\\delta = 2 \\times 10^{-7}$ 秒。\n- 案例3（共享内存，一维，多核限制）：$L = 262144$ 个元素， $N = 64$ 个线程， $B_{\\ell} = 64$ 字节， $B_{e} = 8$ 字节， $c = 2 \\times 10^{-9}$ 秒， $\\gamma = 10^{-6}$ 秒， $\\delta = 2 \\times 10^{-7}$ 秒。\n- 案例4（共享内存，二维，未对齐的 $x$ 轴分区）：$N_{x} = 4104$， $N_{y} = 256$， $N = 4$ 个线程，行主序布局，沿 $x$ 轴分区， $B_{\\ell} = 64$ 字节， $B_{e} = 8$ 字节， $c = 2 \\times 10^{-9}$ 秒， $\\gamma = 10^{-6}$ 秒， $\\delta = 2 \\times 10^{-7}$ 秒。\n- 案例5（分布式内存，二维， $x$ 轴分区）：$N_{x} = 4096$， $N_{y} = 256$， $P = 4$ 个进程，模板半径 $r = 1$，元素大小 $B_{e} = 8$ 字节，消息延迟 $\\alpha = 10^{-5}$ 秒，逆带宽 $\\beta = 10^{-9}$ 秒/字节，每元素计算成本 $c = 2 \\times 10^{-9}$ 秒。沿 $x$ 轴分区，使得晕轮横截面等于 $N_{y}$。\n\n您的程序必须计算：\n- 对于每个共享内存案例，根据您推导的模型计算预测的每步运行时间（秒），其中伪共享冲突的数量按规定计算。\n- 对于分布式内存案例，计算预测的每步运行时间（秒），即计算时间加上无伪共享的双边晕轮交换时间。\n\n最终输出格式：您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，顺序为 $[\\text{case1},\\text{case2},\\text{case3},\\text{case4},\\text{case5}]$，其中每个条目是预测的时间（秒），四舍五入到九位有效数字。例如，您的最终输出必须类似于 [$v_{1}$,$v_{2}$,$v_{3}$,$v_{4}$,$v_{5}$]，不含空格。", "solution": "该问题要求推导并应用性能模型，用于两种常见的并行架构上的模板计算：共享内存多核系统和分布式内存集群。模型必须按照规定从第一性原理推导。\n\n问题陈述被验证为科学上合理、定义明确、客观且完整。它基于计算机体系结构和并行计算的既定原则，提供了构建所需模型和计算结果所必需的所有参数和明确定义。因此，将提供一个解决方案。\n\n### 共享内存性能模型\n\n每时间步的总运行时间 $T_{\\text{shared}}$ 被建模为三个部分的总和：计算时间（$T_{\\text{compute}}$）、通用的一致性维护开销（$T_{\\text{housekeeping}}$）以及伪共享冲突的惩罚（$T_{\\text{fs}}$）。\n\n$$T_{\\text{shared}} = T_{\\text{compute}} + T_{\\text{housekeeping}} + T_{\\text{fs}}$$\n\n1.  **计算时间 ($T_{\\text{compute}}$)**：对于总共 $L$ 个网格元素，每个元素的计算成本为 $c$，在 $N$ 个线程间实现理想负载均衡，并行计算时间为：\n    $$T_{\\text{compute}} = \\frac{L \\cdot c}{N}$$\n\n2.  **一致性维护开销 ($T_{\\text{housekeeping}}$)**：这是一个每个线程固定的开销 $\\gamma$，用于说明维持缓存一致性的基线成本。它与线程数 $N$ 呈线性关系：\n    $$T_{\\text{housekeeping}} = N \\cdot \\gamma$$\n\n3.  **伪共享惩罚 ($T_{\\text{fs}}$)**：当不同线程写入恰好位于同一缓存行中的不同元素时，会发生伪共享。这会触发缓存行失效和传输，从而产生惩罚。该模型将此惩罚定义为与此类冲突的数量 $C_{\\text{fs}}$ 成正比，每个冲突的成本为 $\\delta$。\n    $$T_{\\text{fs}} = C_{\\text{fs}} \\cdot \\delta$$\n    冲突数量 $C_{\\text{fs}}$ 取决于网格的维度和分区方式。一个关键参数是单个缓存行能容纳的元素数量 $E_{\\ell}$，定义为：\n    $$E_{\\ell} = \\bigg\\lfloor \\frac{B_{\\ell}}{B_{e}} \\bigg\\rfloor$$\n    其中 $B_{\\ell}$ 是缓存行大小，$B_{e}$ 是元素大小，单位均为字节。如果新分区的起始元素未与缓存行的起始位置对齐（即其索引不是 $E_{\\ell}$ 的倍数），则在分区边界处会发生冲突。\n\n    *   **对于大小为 $L$ 的一维网格，在 $N$ 个线程间分区**：域被划分为大小为 $S = \\lfloor L/N \\rfloor$ 的连续块。线程之间有 $N-1$ 个边界。线程 $k-1$ 和线程 $k$ 之间的边界位于索引 $k \\cdot S$ 处（其中 $k=1, \\dots, N-1$）。对于每个索引未对齐的边界，算作一次冲突：\n        $$C_{\\text{fs}}^{\\text{1D}} = \\sum_{k=1}^{N-1} \\mathbb{I}\\left( (k \\cdot S) \\pmod{E_{\\ell}} \\neq 0 \\right)$$\n        其中 $\\mathbb{I}(\\cdot)$ 是 Iverson 括号，如果其参数为真则为 $1$，否则为 $0$。\n\n    *   **对于大小为 $N_x \\times N_y$ 的二维网格（行主序），沿 x 轴划分为 $N$ 个板**：每个板的宽度为 $S_x = \\lfloor N_x/N \\rfloor$。位于列 $k \\cdot S_x$ 的分区边界会切过所有 $N_y$ 行。如果此边界相对于缓存行未对齐，则在 $N_y$ 行中的每一行都会发生一次伪共享冲突。\n        $$C_{\\text{fs}}^{\\text{2D}} = N_y \\cdot \\sum_{k=1}^{N-1} \\mathbb{I}\\left( (k \\cdot S_x) \\pmod{E_{\\ell}} \\neq 0 \\right)$$\n        元素总数为 $L = N_x \\cdot N_y$。\n\n### 分布式内存性能模型\n\n每时间步的总运行时间 $T_{\\text{dist}}$ 被建模为计算时间（$T_{\\text{compute}}$）和通信时间（$T_{\\text{comm}}$）的总和，假设两者之间没有重叠。\n\n$$T_{\\text{dist}} = T_{\\text{compute}} + T_{\\text{comm}}$$\n\n1.  **计算时间 ($T_{\\text{compute}}$)**：总共 $L$ 个元素分布在 $P$ 个进程中，计算时间为：\n    $$T_{\\text{compute}} = \\frac{L \\cdot c}{P} = \\frac{N_x \\cdot N_y \\cdot c}{P}$$\n\n2.  **通信时间 ($T_{\\text{comm}}$)**：通信使用标准的延迟-带宽模型进行建模，其中发送一个大小为 $b$ 字节的消息所需的时间为 $T_{\\text{msg}}(b) = \\alpha + \\beta b$。对于二维网格的一维分区，一个内部进程必须与两个邻居（例如，左和右）交换晕轮区域。这两次交换的时间为：\n    $$T_{\\text{comm}} = 2 \\cdot T_{\\text{msg}}(b) = 2(\\alpha + \\beta b)$$\n    晕轮消息的大小 $b$ 取决于模板半径 $r$、分区的横截面维度（这里是 $N_y$）和元素大小 $B_e$。\n    $$b = r \\cdot N_y \\cdot B_e$$\n\n### 测试用例应用\n\n**案例 1：共享内存，一维，对齐**\n给定：$L = 1048576, N = 8, B_{\\ell} = 64, B_{e} = 8, c = 2 \\times 10^{-9}, \\gamma = 10^{-6}, \\delta = 2 \\times 10^{-7}$。\n$E_{\\ell} = \\lfloor 64/8 \\rfloor = 8$。\n$S = \\lfloor 1048576/8 \\rfloor = 131072$。\n由于 $131072 \\pmod 8 = 0$，对于所有 $k$，$k \\cdot S \\pmod 8 = 0$。因此，$C_{\\text{fs}} = 0$。\n$T_{\\text{compute}} = \\frac{1048576 \\cdot 2 \\times 10^{-9}}{8} = 0.000262144$ 秒。\n$T_{\\text{housekeeping}} = 8 \\cdot 10^{-6} = 0.000008$ 秒。\n$T_{\\text{fs}} = 0 \\cdot 2 \\times 10^{-7} = 0$ 秒。\n$T_1 = 0.000262144 + 0.000008 + 0 = 0.000270144$ 秒。\n\n**案例 2：共享内存，一维，未对齐**\n给定：$L = 1000000, N = 6, B_{\\ell} = 64, B_{e} = 8, c = 2 \\times 10^{-9}, \\gamma = 10^{-6}, \\delta = 2 \\times 10^{-7}$。\n$E_{\\ell} = \\lfloor 64/8 \\rfloor = 8$。\n$S = \\lfloor 1000000/6 \\rfloor = 166666$。\n$S \\pmod 8 = 166666 \\pmod 8 = 2$。\n对于 $k=1, \\dots, 5$， $k \\cdot S \\pmod 8$ 的倍数分别为 $2, 4, 6, 0, 2$。有 $4$ 个非零结果。\n$C_{\\text{fs}} = 4$。\n$T_{\\text{compute}} = \\frac{1000000 \\cdot 2 \\times 10^{-9}}{6} = 1/3 \\times 10^{-3} \\approx 0.000333333333$ 秒。\n$T_{\\text{housekeeping}} = 6 \\cdot 10^{-6} = 0.000006$ 秒。\n$T_{\\text{fs}} = 4 \\cdot 2 \\times 10^{-7} = 0.0000008$ 秒。\n$T_2 = 0.000333333333... + 0.000006 + 0.0000008 = 0.000340133333...$ 秒。\n\n**案例 3：共享内存，一维，多核**\n给定：$L = 262144, N = 64, B_{\\ell} = 64, B_{e} = 8, c = 2 \\times 10^{-9}, \\gamma = 10^{-6}, \\delta = 2 \\times 10^{-7}$。\n$E_{\\ell} = \\lfloor 64/8 \\rfloor = 8$。\n$S = \\lfloor 262144/64 \\rfloor = 4096$。\n由于 $4096 \\pmod 8 = 0$，所以 $C_{\\text{fs}} = 0$。\n$T_{\\text{compute}} = \\frac{262144 \\cdot 2 \\times 10^{-9}}{64} = 0.000008192$ 秒。\n$T_{\\text{housekeeping}} = 64 \\cdot 10^{-6} = 0.000064$ 秒。\n$T_{\\text{fs}} = 0$ 秒。\n$T_3 = 0.000008192 + 0.000064 = 0.000072192$ 秒。\n\n**案例 4：共享内存，二维，未对齐**\n给定：$N_x=4104, N_y=256, N=4, B_{\\ell}=64, B_{e}=8, c=2 \\times 10^{-9}, \\gamma=10^{-6}, \\delta=2 \\times 10^{-7}$。\n$L = 4104 \\cdot 256 = 1050624$。\n$E_{\\ell} = \\lfloor 64/8 \\rfloor = 8$。\n$S_x = \\lfloor 4104/4 \\rfloor = 1026$。\n$S_x \\pmod 8 = 1026 \\pmod 8 = 2$。\n对于 $k=1, 2, 3$， $k \\cdot S_x \\pmod 8$ 的倍数分别为 $2, 4, 6$。均为非零。未对齐边界数为 $3$。\n$C_{\\text{fs}} = N_y \\cdot 3 = 256 \\cdot 3 = 768$。\n$T_{\\text{compute}} = \\frac{1050624 \\cdot 2 \\times 10^{-9}}{4} = 0.000525312$ 秒。\n$T_{\\text{housekeeping}} = 4 \\cdot 10^{-6} = 0.000004$ 秒。\n$T_{\\text{fs}} = 768 \\cdot 2 \\times 10^{-7} = 0.0001536$ 秒。\n$T_4 = 0.000525312 + 0.000004 + 0.0001536 = 0.000682912$ 秒。\n\n**案例 5：分布式内存，二维**\n给定：$N_x=4096, N_y=256, P=4, r=1, B_{e}=8, \\alpha=10^{-5}, \\beta=10^{-9}, c=2 \\times 10^{-9}$。\n$L = 4096 \\cdot 256 = 1048576$。\n$T_{\\text{compute}} = \\frac{1048576 \\cdot 2 \\times 10^{-9}}{4} = 0.000524288$ 秒。\n消息大小 $b = r \\cdot N_y \\cdot B_e = 1 \\cdot 256 \\cdot 8 = 2048$ 字节。\n$T_{\\text{comm}} = 2 \\cdot (\\alpha + \\beta \\cdot b) = 2 \\cdot (10^{-5} + 10^{-9} \\cdot 2048) = 2 \\cdot (0.00001 + 0.000002048) = 0.000024096$ 秒。\n$T_5 = 0.000524288 + 0.000024096 = 0.000548384$ 秒。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve_shared_memory(L, N, B_ell, B_e, c, gamma, delta, grid_dim, Nx=None, Ny=None):\n    \"\"\"\n    Computes predicted runtime for the shared-memory model.\n    \"\"\"\n    # Number of elements per cache line\n    E_ell = B_ell // B_e\n\n    # Component 1: Compute time\n    # The problem specifies using L*c/N, assuming ideal load balance for this part.\n    if grid_dim == '2d':\n        L = Nx * Ny\n    T_compute = (L * c) / N\n\n    # Component 2: Coherence housekeeping overhead\n    T_housekeeping = N * gamma\n\n    # Component 3: False sharing penalty\n    C_fs = 0\n    if N > 1:\n        if grid_dim == '1d':\n            # Block size per thread\n            S = L // N\n            # Sum conflicts over N-1 boundaries\n            for k in range(1, N):\n                if (k * S) % E_ell != 0:\n                    C_fs += 1\n        elif grid_dim == '2d':\n            # Slab width per thread\n            Sx = Nx // N\n            misaligned_boundaries = 0\n            # Sum misaligned boundaries over N-1 boundaries\n            for k in range(1, N):\n                if (k * Sx) % E_ell != 0:\n                    misaligned_boundaries += 1\n            # One conflict per row for each misaligned boundary\n            C_fs = Ny * misaligned_boundaries\n\n    T_fs = C_fs * delta\n\n    return T_compute + T_housekeeping + T_fs\n\ndef solve_distributed_memory(Nx, Ny, P, r, B_e, alpha, beta, c):\n    \"\"\"\n    Computes predicted runtime for the distributed-memory model.\n    \"\"\"\n    L = Nx * Ny\n    \n    # Component 1: Compute time\n    T_compute = (L * c) / P\n\n    # Component 2: Communication time\n    # Message size in bytes for one halo\n    b = r * Ny * B_e\n    # Time for two neighbor exchanges (e.g., left and right)\n    T_comm = 2 * (alpha + beta * b)\n\n    return T_compute + T_comm\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test suite.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (shared-memory, 1D, aligned)\n        {'type': 'shared', 'params': {'L': 1048576, 'N': 8, 'B_ell': 64, 'B_e': 8, 'c': 2e-9, 'gamma': 1e-6, 'delta': 2e-7, 'grid_dim': '1d'}},\n        # Case 2 (shared-memory, 1D, misaligned)\n        {'type': 'shared', 'params': {'L': 1000000, 'N': 6, 'B_ell': 64, 'B_e': 8, 'c': 2e-9, 'gamma': 1e-6, 'delta': 2e-7, 'grid_dim': '1d'}},\n        # Case 3 (shared-memory, 1D, manycore)\n        {'type': 'shared', 'params': {'L': 262144, 'N': 64, 'B_ell': 64, 'B_e': 8, 'c': 2e-9, 'gamma': 1e-6, 'delta': 2e-7, 'grid_dim': '1d'}},\n        # Case 4 (shared-memory, 2D, misaligned)\n        {'type': 'shared', 'params': {'L': None, 'N': 4, 'B_ell': 64, 'B_e': 8, 'c': 2e-9, 'gamma': 1e-6, 'delta': 2e-7, 'grid_dim': '2d', 'Nx': 4104, 'Ny': 256}},\n        # Case 5 (distributed memory, 2D)\n        {'type': 'distributed', 'params': {'Nx': 4096, 'Ny': 256, 'P': 4, 'r': 1, 'B_e': 8, 'alpha': 1e-5, 'beta': 1e-9, 'c': 2e-9}}\n    ]\n\n    results = []\n    for case in test_cases:\n        if case['type'] == 'shared':\n            result = solve_shared_memory(**case['params'])\n        elif case['type'] == 'distributed':\n            result = solve_distributed_memory(**case['params'])\n        results.append(result)\n\n    # Format results to nine significant digits and join them into the final string.\n    formatted_results = [f\"{res:.9g}\" for res in results]\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3614253"}, {"introduction": "在我们基础性能模型的基础上，本练习深入探讨了一项针对延迟受限模拟的关键优化技术：通信与计算重叠。您将为基于 GPU 的模板代码推导并实现一个流水线执行模型，旨在将晕轮交换的成本隐藏在计算域内部的计算之后。此练习对于理解如何在现代大规模并行地球物理模拟中最大化硬件利用率和实现高吞吐量至关重要。[@problem_id:3614239]", "problem": "您正在为一个三维显式有限差分模板更新进行建模，该更新针对图形处理单元（GPU）上的单个物理状态场，并采用沿 x 轴的一维板式分解。每个时间步执行一次晕轮交换，其厚度等于模板半径，与直接的左右邻居进行。内核更新是内存受限的。并行化策略结合了设备内的共享内存风格（GPU内的单指令多线程）和通过直接互连接口在子域之间进行的消息传递。您的任务是从第一性原理出发，推导出一个稳态的通信-计算重叠调度方案，该方案将晕轮交换与GPU内核执行流水线化，并计算预期的稳态吞吐率。\n\n只能从以下基础出发：\n- 消息传递的延迟-带宽模型：传输大小为 $S$ 字节的消息所需时间为 $t_{\\mathrm{comm}} = L + S / B$，其中 $L$ 是点对点延迟（秒），$B$ 是持续点对点带宽（字节/秒）。\n- 内存受限内核的内存带宽模型：处理 $Q$ 字节内存流量所需时间为 $t_{\\mathrm{mem}} = Q / W$，其中 $W$ 是持续设备内存带宽（字节/秒）。\n\n用于指导推导的假设：\n- 每个 GPU 分配一个大小为 $N_x \\times N_y \\times N_z$ 的板块，模板半径 $r$ 仅沿 x 轴。左右晕轮消息各包含 $r$ 个大小为 $N_y \\times N_z$ 的平面，并作为连续消息进行通信。\n- 通信由非阻塞的发送和接收操作执行，这些操作可以与 GPU 内核执行重叠。两个方向的晕轮交换（左和右）可以根据硬件支持情况并发或串行进行；通过一个并发因子 $\\varphi \\in \\{1,2\\}$ 来模拟这种效应，使得每个时间步的有效通信大小是一个方向消息的 $\\varphi$ 倍。\n- 使用双缓冲流水线：不依赖于晕轮数据的内部区域在为下一次边界更新准备的晕轮通信进行时进行计算。边界区域在晕轮数据可用后进行计算。假设在多个时间步上处于稳态，因此流水线的启动和收尾开销被分摊，可以在平均计算中忽略。\n- 内核的每点内存流量为 $b_{\\mathrm{pp}}$ 字节/单元更新。每个晕轮单元值所通信的字节数为 $b_{\\mathrm{pv}}$ 字节。内核受内存带宽限制，没有其他瓶颈干预。如果 $r=0$，则通信成本为零。\n\n您的任务：\n1. 从所述基础出发，通过将内部计算与晕轮交换重叠，并加上任何未重叠的边界计算，推导出每个时间步的稳态时间表达式。根据 $N_x$、$N_y$、$N_z$ 和 $r$ 明确定义内部和边界子体积。\n2. 从每个时间步的时间，推导出稳态吞吐率（以每秒单元更新数计），作为参数 $N_x$、$N_y$、$N_z$、$r$、$b_{\\mathrm{pp}}$、$b_{\\mathrm{pv}}$、$W$、$B$、$L$ 和 $\\varphi$ 的函数。\n3. 实现一个程序，评估下面测试套件的推导吞吐率。以浮点值形式报告吞吐率，单位为每秒十亿单元更新数 ($\\mathrm{Gcell/s}$)。\n\n您的实现的输入规范：\n- 没有输入。硬编码以下测试套件参数集，每个集为一个元组 $(N_x,N_y,N_z,r,b_{\\mathrm{pp}},b_{\\mathrm{pv}},W,B,L,\\varphi)$，并带有指定的单位。\n- 单位：$N_x$、$N_y$、$N_z$、$r$ 是无量纲整数；$b_{\\mathrm{pp}}$ 和 $b_{\\mathrm{pv}}$ 以字节为单位；$W$ 和 $B$ 以字节/秒为单位；$L$ 以秒为单位；$\\varphi$ 是一个无量纲整数，等于 $1$ 或 $2$。\n- 角度单位不适用。不使用百分比。\n\n测试套件：\n- 案例 A（外围带宽受限互连，中等板块）：$(N_x,N_y,N_z,r,b_{\\mathrm{pp}},b_{\\mathrm{pv}},W,B,L,\\varphi) = (\\,512,\\,512,\\,128,\\,2,\\,64,\\,8,\\,1.6\\times 10^{12},\\,2.5\\times 10^{10},\\,1.0\\times 10^{-6},\\,2\\,)$ 代表外围组件互连标准（PCIe）与串行化定向传输。\n- 案例 B（高带宽低延迟互连，相同板块）：$(\\,512,\\,512,\\,128,\\,2,\\,64,\\,8,\\,1.6\\times 10^{12},\\,1.0\\times 10^{11},\\,3.0\\times 10^{-7},\\,1\\,)$ 代表 NVIDIA Link (NVLink) 与全双工重叠。\n- 案例 C（小板块，更高的延迟主导）：$(\\,128,\\,128,\\,64,\\,1,\\,64,\\,8,\\,8.0\\times 10^{11},\\,2.5\\times 10^{10},\\,5.0\\times 10^{-6},\\,2\\,)$ 代表 PCIe 与串行化定向传输。\n- 案例 D（由于薄板上的大半径而无内部区域）：$(\\,16,\\,1024,\\,1024,\\,8,\\,64,\\,8,\\,1.6\\times 10^{12},\\,1.0\\times 10^{11},\\,3.0\\times 10^{-7},\\,1\\,)$ 代表 NVLink 与全双工重叠。\n- 案例 E（非常大的板块，PCIe）：$(\\,2048,\\,2048,\\,64,\\,2,\\,64,\\,8,\\,1.6\\times 10^{12},\\,2.5\\times 10^{10},\\,1.0\\times 10^{-6},\\,2\\,)$ 代表 PCIe 与串行化定向传输。\n\n要求输出：\n- 您的程序应生成单行输出，其中包含案例 A–E 的吞吐率，按顺序排列，作为一个用方括号括起来的逗号分隔列表，例如 $[\\dots]$。每个值必须是浮点数，四舍五入到恰好 $6$ 位小数，并以 $\\mathrm{Gcell/s}$ 为单位解释。", "solution": "我们从所述基础开始。传输大小为 $S$ 字节的有效载荷的消息传递时间为 $t_{\\mathrm{comm}} = L + S / B$，其中 $L$ 是延迟，$B$ 是持续带宽。一个移动 $Q$ 字节的内存受限内核在 $t_{\\mathrm{mem}} = Q / W$ 的时间内执行，其中 $W$ 是持续设备内存带宽。\n\n我们考虑每个图形处理单元（GPU）一个板块，子域大小为 $N_x \\times N_y \\times N_z$，沿 x 轴进行一维分解，x 方向的模板半径为 $r$。在每个时间步，厚度为 $r$ 个平面的晕轮数据与左右邻居进行交换。设内核每次更新单元所移动的字节数为 $b_{\\mathrm{pp}}$（每点字节数），每个晕轮单元值所通信的字节数为 $b_{\\mathrm{pv}}$（每值字节数）。\n\n定义总体积和不依赖于晕轮数据的内部区域：\n- 每个时间步的总单元数：$V = N_x N_y N_z$。\n- 排除晕轮后的内部范围：$N_x^{\\mathrm{int}} = \\max(0, N_x - 2r)$。\n- 内部体积：$V_{\\mathrm{int}} = N_x^{\\mathrm{int}} N_y N_z$。\n- 边界体积：$V_{\\mathrm{bord}} = V - V_{\\mathrm{int}}$。\n\n内核内存流量因此被划分为内部和边界：\n- 内部内存流量：$Q_{\\mathrm{int}} = V_{\\mathrm{int}} \\, b_{\\mathrm{pp}}$。\n- 边界内存流量：$Q_{\\mathrm{bord}} = V_{\\mathrm{bord}} \\, b_{\\mathrm{pp}}$。\n\n因此计算时间为\n$$\nt_{\\mathrm{int}} = \\frac{Q_{\\mathrm{int}}}{W} = \\frac{V_{\\mathrm{int}} \\, b_{\\mathrm{pp}}}{W}, \n\\quad\nt_{\\mathrm{bord}} = \\frac{Q_{\\mathrm{bord}}}{W} = \\frac{V_{\\mathrm{bord}} \\, b_{\\mathrm{pp}}}{W}.\n$$\n\n每个方向的晕轮消息包含 $r$ 个面积为 $N_y N_z$ 的平面，因此一个方向的消息大小是\n$$\nS_{\\mathrm{dir}} = r \\, N_y \\, N_z \\, b_{\\mathrm{pv}}.\n$$\n令 $\\varphi \\in \\{1,2\\}$ 来模拟两个方向交换的并发性：$\\varphi = 1$ 表示完全重叠的双向传输（全双工或独立引擎），$\\varphi = 2$ 表示串行化或有效的半双工行为。每个时间步的有效通信时间是\n$$\nt_{\\mathrm{comm}} = \n\\begin{cases}\n0, & r = 0, \\\\\nL + \\dfrac{\\varphi \\, S_{\\mathrm{dir}}}{B}, & r > 0.\n\\end{cases}\n$$\n\n我们设计一个使用非阻塞消息传递接口（MPI）操作和设备常驻缓冲区的双缓冲流水线，并使用两个流：一个流启动内部内核，而另一个流进行通信。在稳态下，当前时间步的内部计算与同一时间步边界更新所需的晕轮交换重叠。边界区域必须等到晕轮数据可用。因此，在多个时间步上（为了分摊而忽略第一个和最后一个），每个时间步的稳态时间是内部计算和通信的重叠，然后是非重叠的边界计算：\n$$\nt_{\\mathrm{step}} = \\max\\left( t_{\\mathrm{int}}, \\, t_{\\mathrm{comm}} \\right) + t_{\\mathrm{bord}}.\n$$\n\n每秒单元更新数的吞吐率是每个时间步的总单元更新数除以每个时间步的时间：\n$$\n\\Theta = \\frac{V}{t_{\\mathrm{step}}} = \\frac{N_x N_y N_z}{\\max\\left( \\dfrac{V_{\\mathrm{int}} \\, b_{\\mathrm{pp}}}{W}, \\, t_{\\mathrm{comm}} \\right) + \\dfrac{V_{\\mathrm{bord}} \\, b_{\\mathrm{pp}}}{W}}.\n$$\n我们将其报告为每秒十亿单元更新数，通过除以 $10^9$：\n$$\n\\Theta_{\\mathrm{G}} = \\frac{\\Theta}{10^9}.\n$$\n\n这个表达式涵盖了几个不同的情况：\n- 有效重叠的计算受限情况：如果 $t_{\\mathrm{int}} \\gg t_{\\mathrm{comm}}$，则 $t_{\\mathrm{step}} \\approx t_{\\mathrm{int}} + t_{\\mathrm{bord}} = (Q_{\\mathrm{int}} + Q_{\\mathrm{bord}})/W$，所以 $\\Theta \\approx V W / (V b_{\\mathrm{pp}}) = W / b_{\\mathrm{pp}}$，与通信无关，达到了内存屋顶线。\n- 通信受限情况：如果 $t_{\\mathrm{comm}} \\gg t_{\\mathrm{int}}$，则 $t_{\\mathrm{step}} \\approx t_{\\mathrm{comm}} + t_{\\mathrm{bord}}$，因此吞吐率下降并依赖于 $L$、$B$ 和晕轮大小。\n- 无内部区域情况：如果 $N_x \\le 2r$，则 $V_{\\mathrm{int}} = 0$ 且 $t_{\\mathrm{int}} = 0$，所以 $t_{\\mathrm{step}} = t_{\\mathrm{comm}} + t_{\\mathrm{bord}}$，这捕捉了没有重叠的情况。\n\n从公式得出的算法设计：\n1. 计算 $V$、$N_x^{\\mathrm{int}} = \\max(0, N_x - 2r)$、$V_{\\mathrm{int}}$ 和 $V_{\\mathrm{bord}}$。\n2. 计算 $t_{\\mathrm{int}} = (V_{\\mathrm{int}} \\, b_{\\mathrm{pp}})/W$ 和 $t_{\\mathrm{bord}} = (V_{\\mathrm{bord}} \\, b_{\\mathrm{pp}})/W$。\n3. 计算 $S_{\\mathrm{dir}} = r \\, N_y \\, N_z \\, b_{\\mathrm{pv}}$，如果 $r=0$ 则 $t_{\\mathrm{comm}} = 0$，否则 $t_{\\mathrm{comm}} = L + (\\varphi \\, S_{\\mathrm{dir}})/B$。\n4. 计算 $t_{\\mathrm{step}} = \\max(t_{\\mathrm{int}}, t_{\\mathrm{comm}}) + t_{\\mathrm{bord}}$。\n5. 计算 $\\Theta_{\\mathrm{G}} = \\left( V / t_{\\mathrm{step}} \\right) / 10^9$ 并四舍五入到 $6$ 位小数。\n\n应用于具有代表外围组件互连标准（PCIe）和 NVIDIA Link (NVLink) 的给定参数的测试套件显示：\n- 案例 A、B 和 E 是计算受限的，并且当重叠隐藏了通信时，它们接近内存屋顶线；当 $t_{\\mathrm{comm}} \\ll t_{\\mathrm{int}} + t_{\\mathrm{bord}}$ 时，预测值接近 $\\Theta \\approx W / b_{\\mathrm{pp}}$。\n- 案例 C 的板块较小且延迟较大；然而，如果 $t_{\\mathrm{int}}$ 占主导地位，它在其较低的 $W$ 下仍然是计算受限的。\n- 案例 D 没有内部区域（$N_x = 2r$），因此步长时间是通信项和边界计算项之和，相对于完全重叠的计算，时间大约增加了一倍，因此在此配置下，吞吐率相对于屋顶线减半。\n\n该程序实现了上述步骤，并以单个列表的形式打印五个吞吐率，每个值以 $\\mathrm{Gcell/s}$ 为单位，四舍五入到 $6$ 位小数。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef steady_state_throughput_gcups(Nx, Ny, Nz, r, bpp, bpv, Wmem, B, L, phi):\n    \"\"\"\n    Compute steady-state throughput (Gcell/s) for a 1D slab-decomposed 3D stencil\n    with overlap between halo exchange and GPU kernel execution.\n\n    Parameters:\n        Nx, Ny, Nz : ints - subdomain dimensions per GPU\n        r          : int - stencil radius along x (halo thickness)\n        bpp        : float - bytes per point (memory traffic per cell update)\n        bpv        : float - bytes per halo cell value communicated\n        Wmem       : float - sustained GPU memory bandwidth (bytes/s)\n        B          : float - sustained interconnect bandwidth (bytes/s)\n        L          : float - interconnect point-to-point latency (s)\n        phi        : int   - concurrency factor for two directions (1=overlap, 2=serialize)\n\n    Returns:\n        float - throughput in Gcell/s\n    \"\"\"\n    # Volumes\n    V = Nx * Ny * Nz\n    Nx_int = max(0, Nx - 2 * r)\n    V_int = Nx_int * Ny * Nz\n    V_bord = V - V_int\n\n    # Compute times (memory-bound)\n    Q_int = V_int * bpp\n    Q_bord = V_bord * bpp\n    t_int = Q_int / Wmem\n    t_bord = Q_bord / Wmem\n\n    # Communication time\n    if r == 0:\n        t_comm = 0.0\n    else:\n        S_dir = r * Ny * Nz * bpv\n        t_comm = L + (phi * S_dir) / B\n\n    # Steady-state overlapped time per timestep\n    t_step = max(t_int, t_comm) + t_bord\n\n    # Throughput in Gcell/s\n    if t_step == 0.0:\n        return 0.0\n    theta = V / t_step  # cell updates per second\n    return theta / 1e9  # Gcell/s\n\ndef solve():\n    # Define the test cases from the problem statement.\n    # Each tuple: (Nx, Ny, Nz, r, bpp, bpv, Wmem, B, L, phi)\n    test_cases = [\n        # Case A: PCIe-like, serialized directions\n        (512, 512, 128, 2, 64.0, 8.0, 1.6e12, 2.5e10, 1.0e-6, 2),\n        # Case B: NVLink-like, full-duplex\n        (512, 512, 128, 2, 64.0, 8.0, 1.6e12, 1.0e11, 3.0e-7, 1),\n        # Case C: Small slab, higher latency dominance\n        (128, 128, 64, 1, 64.0, 8.0, 8.0e11, 2.5e10, 5.0e-6, 2),\n        # Case D: No interior (Nx == 2r), thin slab\n        (16, 1024, 1024, 8, 64.0, 8.0, 1.6e12, 1.0e11, 3.0e-7, 1),\n        # Case E: Very large slab, PCIe-like\n        (2048, 2048, 64, 2, 64.0, 8.0, 1.6e12, 2.5e10, 1.0e-6, 2),\n    ]\n\n    results = []\n    for case in test_cases:\n        Nx, Ny, Nz, r, bpp, bpv, Wmem, B, L, phi = case\n        result = steady_state_throughput_gcups(Nx, Ny, Nz, r, bpp, bpv, Wmem, B, L, phi)\n        results.append(f\"{result:.6f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3614239"}, {"introduction": "如果没有正确性和可复现性，高性能将毫无意义。这最后一个练习将我们的重点从速度转向并行计算的数值完整性，解决了浮点运算的非结合性问题。您将研究非确定性执行调度如何导致运行结果的差异，并实现一种确定性的成对求和算法，以保证逐位可复现性，这是科学研究中调试和验证的关键要求。[@problem_id:3614205]", "problem": "考虑一个离散地球物理反演问题的伴随状态公式，其中梯度分量通过对局部双线性贡献的全局归约进行累积。设离散正演波场表示为 $u_i$，离散伴随波场表示为 $\\lambda_i$，其中 $i$ 是组合时空网格的索引。单个模型参数的离散梯度累积可以写作对序列 $g_i = u_i \\lambda_i$（其中 $i = 1, \\dots, n$）的浮点归约，产生 $G = \\sum_{i=1}^n g_i$。在现实的共享内存和消息传递环境中，非确定性调度可能会重排 $\\{g_i\\}$ 的求和顺序，由于浮点数的非结合律而导致逐次运行间的可变性。\n\n假设算术运算在电气与电子工程师协会（IEEE）$754$ 标准的二进制 $64$ 位双精度下执行，采用“舍入到最近，偶数优先”的规则。浮点舍入通过标准一阶模型进行建模：对于实数 $a$ 和 $b$ 上的任何基本运算 $\\mathrm{op}$，计算结果 $\\mathrm{fl}(a \\ \\mathrm{op} \\ b)$ 满足 $\\mathrm{fl}(a \\ \\mathrm{op} \\ b) = (a \\ \\mathrm{op} \\ b)(1 + \\delta)$，其中 $|\\delta| \\le \\epsilon$，$epsilon$ 为单位舍入误差，其值为 $2^{-53}$。\n\n你的任务是：\n\n1. 通过模拟以下情况，评估 $G$ 在非确定性调度下的可复现性：\n   - 共享内存可变性：随机排列 $n$ 个加法的顺序，并对多个排列计算简单的从左到右求和。\n   - 消息传递可变性：将 $\\{g_i\\}$ 划分为 $p$ 个连续块（代表进程），确定性地计算每个块的和，然后随机排列块和被聚合的顺序，进行从左到右求和。\n\n2. 设计并实现一个针对 $\\sum_{i=1}^n g_i$ 的确定性归约算法，该算法使用基于序列的、与调度无关的固定二叉树归约形式组织的成对求和。该算法必须定义为：在每一层级上对相邻元素进行逐次成对相加形成新序列，如果长度为奇数，则将剩余元素不变地传递下去，直到只剩下一个值。对于给定的输入序列顺序，此过程必须是确定性的。\n\n3. 通过一个关于 $\\epsilon$ 的函数来界定确定性成对求和的舍入误差。推导并使用以下形式的界限：\n$$\n|G_{\\mathrm{pair}} - G_{\\mathrm{exact}}| \\le \\epsilon \\left\\lceil \\log_2(n) \\right\\rceil \\sum_{i=1}^n |g_i|\n$$,\n其中 $G_{\\mathrm{pair}}$ 是在二进制 $64$ 位算术中确定性成对求和的结果，而 $G_{\\mathrm{exact}}$ 是已经舍入的 $g_i$ 值的精确实数和。为了数值上检验此界限，使用高精度十进制算术计算 $G_{\\mathrm{exact}}$，该算术将每个二进制 $64$ 位 $g_i$ 精确表示为一个 Decimal，并以足够高的精度对它们求和，以避免在累积过程中产生舍入。\n\n4. 为每个测试用例报告：\n   - 共享内存可变性下的结果范围，定义为对 $K$ 个独立的随机排列和简单的从左到右求和所得到的 $\\max(G_{\\mathrm{perm}}) - \\min(G_{\\mathrm{perm}})$，其中 $G_{\\mathrm{perm}}$ 表示这样一次求和的结果。\n   - 消息传递可变性下的结果范围，在确定性地计算块和并对块聚合顺序进行 $K$ 次随机排列试验后，以类似方式定义。\n   - 确定性成对归约相对于精确实数和的绝对误差，即 $|G_{\\mathrm{pair}} - G_{\\mathrm{exact}}|$。\n   - 界限值 $B = \\epsilon \\left\\lceil \\log_2(n) \\right\\rceil \\sum_{i=1}^n |g_i|$。\n   - 一个布尔值，指示 $|G_{\\mathrm{pair}} - G_{\\mathrm{exact}}| \\le B$ 是否成立。\n\n使用的基本依据和假设：\n- 浮点非结合律和一阶舍入模型 $\\mathrm{fl}(a \\ \\mathrm{op} \\ b) = (a \\ \\mathrm{op} \\ b)(1 + \\delta)$，其中 $|\\delta| \\le \\epsilon$ 且 $\\epsilon = 2^{-53}$。\n- 结构化为平衡二叉树的确定性成对求和的深度为 $\\left\\lceil \\log_2(n) \\right\\rceil$。\n- 随机调度可变性通过随机排列加法顺序来建模；消息传递可变性通过随机排列一组固定的块和来建模。\n\n测试套件：\n对于每个案例，完全按照下述说明构造 $\\{u_i\\}$ 和 $\\{\\lambda_i\\}$，然后在进行任何归约之前，在二进制 $64$ 位算术中形成 $g_i = \\mathrm{fl}(u_i \\cdot \\lambda_i)$。不涉及角度。不需要物理单位。\n\n- 测试 $1$ (正常路径，中等规模，随机正态分布):\n  - $n = 4096$, $p = 16$, $K = 32$。\n  - 使用 $12345$ 作为随机数生成器的种子。\n  - $u_i$ 和 $\\lambda_i$ 是独立的标准正态分布抽样。\n- 测试 $2$ (强相消，奇数长度):\n  - $n = 4097$, $p = 7$, $K = 32$。\n  - $u_i = (-1)^i$，其中 $i = 0, 1, \\dots, n-1$。\n  - 对所有 $i$，$\\lambda_i = 10^{-8}$。\n- 测试 $3$ (宽动态范围，正项):\n  - $n = 2048$, $p = 8$, $K = 32$。\n  - $u_i = 10^{-i/8}$，其中 $i = 0, 1, \\dots, n-1$。\n  - 对所有 $i$，$\\lambda_i = 1$。\n- 测试 $4$ (极小量级和一阶量级的混合):\n  - $n = 1000$, $p = 10$, $K = 32$。\n  - 使用 $67890$ 作为随机数生成器的种子。\n  - 对于 $i = 0, \\dots, 499$：$u_i$ 是 $\\{-1, +1\\}$ 中的独立随机符号，$\\lambda_i = 10^{-300}$。\n  - 对于 $i = 500, \\dots, 999$：$u_i$ 是独立的标准正态分布抽样，$\\lambda_i = 1$。\n- 测试 $5$ (边界情况，单个元素):\n  - $n = 1$, $p = 1$, $K = 32$。\n  - $u_0 = 3.141592653589793$, $\\lambda_0 = 2.718281828459045$。\n\n程序要求：\n- 按所述实现确定性成对求和。\n- 通过排列 $n$ 长度的 $g_i$ 序列并对每个排列执行简单的从左到右求和，模拟 $K$ 个随机调度的共享内存可变性。\n- 通过以下方式模拟 $K$ 次随机消息传递聚合：\n  - 将序列划分为 $p$ 个大小尽可能相等的连续块，通过成对求和确定性地计算每个块的和，然后排列这 $p$ 个块的和，并对每个排列进行从左到右的聚合。\n- 使用高精度十进制算术计算精确实数和 $G_{\\mathrm{exact}}$，该算术将每个 $g_i$ 精确表示为一个 Decimal，并以至少 $200$ 个十进制数字的精度求和。\n- 对于每个测试用例，生成列表\n  $[\\text{range\\_shared}, \\text{range\\_message}, |G_{\\mathrm{pair}} - G_{\\mathrm{exact}}|, B, \\text{bound\\_ok}]$，\n  其中所有量均如上文定义。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例一个列表，按给定顺序排列，例如 $[[\\cdots],[\\cdots],\\dots]$。\n\n输出中的所有数值量必须表示为标准的 Python 字面量（浮点数和布尔值）。不应打印任何额外文本。", "solution": "该问题要求在地球物理反演问题的背景下，分析浮点求和的可复现性，比较非确定性和确定性求和算法，并验证确定性算法的理论误差界。问题的核心在于浮点加法的非结合律，这是计算机算术的一个基本属性。\n\n### 原理：浮点算术与非结合律\n\n该问题基于符合电气与电子工程师协会（IEEE）754 标准的浮点算术标准模型。对于两个实数 $a$ 和 $b$ 上的任何二元运算 $\\mathrm{op}$（如加法或乘法），计算出的结果表示为 $\\mathrm{fl}(a \\ \\mathrm{op} \\ b)$，它不是精确的。其模型为：\n$$\n\\mathrm{fl}(a \\ \\mathrm{op} \\ b) = (a \\ \\mathrm{op} \\ b)(1 + \\delta)\n$$\n其中 $|\\delta| \\le \\epsilon$。这里的 $\\epsilon$ 是单位舍入误差，对于 binary64（双精度）算术，$\\epsilon = 2^{-53}$。\n\n该舍入模型的一个直接后果是浮点加法不满足结合律。也就是说，对于三个浮点数 $x$、 $y$ 和 $z$，以下等式通常不成立：\n$$\n\\mathrm{fl}(\\mathrm{fl}(x + y) + z) = \\mathrm{fl}(x + \\mathrm{fl}(y + z))\n$$\n运算的顺序能够并且经常会改变最终结果。在并行计算环境中，线程的调度程序（在共享内存系统中）或消息的到达顺序（在消息传递系统中）可能是非确定性的。如果一个全局和，如梯度累积 $G = \\sum_{i=1}^n g_i$，是使用简单的从左到右归约来计算的，那么加法的有效顺序可能因运行而异，导致结果不可复现。这在科学计算中是一个重要问题，因为通常需要逐位可复现性来进行验证和调试。\n\n### 非确定性求和的模拟\n\n为了量化这种可变性，我们模拟了两种常见的并行编程范式。所有求和的输入序列是 $\\{g_i\\}_{i=1}^n$，其中每个 $g_i = \\mathrm{fl}(u_i \\cdot \\lambda_i)$ 都以 binary64 格式计算和存储。\n\n1.  **共享内存可变性**：这通过假设 $n$ 个项中的任何一个都可以按任何顺序相加来建模。我们通过生成序列 $\\{g_i\\}$ 的 $K$ 个独立随机排列来模拟这一点。对于每个排列，计算一个简单的从左到右的和。可变性由这 $K$ 个结果的范围来衡量：$\\max(G_{\\mathrm{perm}}) - \\min(G_{\\mathrm{perm}})$。\n\n2.  **消息传递可变性**：这模拟了一种域分解范式，其中 $p$ 个进程各自计算一个局部部分和，然后将这 $p$ 个部分和聚合（归约）成最终的全局和。序列 $\\{g_i\\}$ 被划分为 $p$ 个连续的块。每个块的和都是确定性计算的。问题指定了对这些块和的非确定性聚合。我们通过计算 $p$ 个块和，然后在 $K$ 次试验中，随机排列这 $p$ 个和，并用从左到右的求和方式进行聚合来模拟这一点。可变性是这 $K$ 个最终聚合和的范围。\n\n### 确定性成对求和\n\n为了强制实现可复现性，需要一种确定性的求和算法。问题指定了一种特定形式的成对求和，可以将其可视化为二叉树归约。给定一个数字序列，算法按层级进行：\n1.  在第一层，将相邻的数字对相加：$(g_1+g_2), (g_3+g_4), \\dots$。这会形成一个新的、更短的序列。如果原始序列的元素数量为奇数，则最后一个元素将不变地传递到下一层。\n2.  在新的序列上重复此过程，直到只剩下一个数字。\n\n该算法是确定性的：对于一个固定的输入序列 $\\{g_i\\}$，无论并行执行环境如何，结果总是相同的，因为加法的顺序是由算法的结构固定的。\n\n### 成对求和的误差分析\n\n除了确定性之外，成对求和的一个关键优势是其相对于朴素求和的更高精度，特别是对于长序列或数量级差异较大的序列。提供的误差界为：\n$$\n|G_{\\mathrm{pair}} - G_{\\mathrm{exact}}| \\le \\epsilon \\left\\lceil \\log_2(n) \\right\\rceil \\sum_{i=1}^n |g_i|\n$$\n这里，$G_{\\mathrm{pair}}$ 是通过成对求和算法计算出的和，$G_{\\mathrm{exact}} = \\sum_{i=1}^n g_i$ 是初始浮点数 $\\{g_i\\}$ 的精确数学和。\n\n这个界限可以直观地理解。求和树的深度为 $d = \\left\\lceil \\log_2(n) \\right\\rceil$。任何输入值 $g_i$ 最多参与 $d$ 次加法以对最终和做出贡献。在每次加法中，都会引入一个小的舍入误差。该界限形式化了这些误差的最坏情况累积。$\\sum_{i=1}^n |g_i|$ 项的出现是因为舍入误差是相对的，因此它们的绝对大小与被加数的大小成比例。这个界限显著优于朴素求和的相应界限，后者有一个因子 $n$ 而不是 $\\log_2(n)$。\n\n为了数值上验证这个界限，我们需要 $G_{\\mathrm{exact}}$。由于输入 $\\{g_i\\}$ 是 binary64 数字，它们有精确的有限十进制表示。我们可以使用高精度算术库（如 Python 的 `decimal` 模块）来精确表示每个 $g_i$，并以足够高的精度（例如，200位小数）对它们求和，以确保求和过程本身不引入舍入误差。结果是一个高度精确的 $G_{\\mathrm{exact}}$ 参考值。\n\n### 实现计划\n\n对于每个测试用例，执行以下步骤：\n1.  根据测试用例规范生成输入序列 $\\{u_i\\}$ 和 $\\{\\lambda_i\\}$。\n2.  计算乘积序列 $g_i = \\mathrm{fl}(u_i \\cdot \\lambda_i)$，并将其存储为 binary64 浮点数数组。\n3.  **可变性分析**：\n    -   通过计算 $\\{g_i\\}$ 的随机排列的 $K$ 次朴素求和的范围来计算共享内存可变性。\n    -   计算消息传递可变性。首先，将 $\\{g_i\\}$ 分成 $p$ 个块。对每个块计算确定性的成对和。然后，找到这些 $p$ 个块和的随机排列的 $K$ 次朴素求和的范围。\n4.  **确定性计算和误差验证**：\n    -   计算 $\\{g_i\\}$ 的确定性成对和 $G_{\\mathrm{pair}}$。\n    -   使用高精度十进制算术计算“精确”和 $G_{\\mathrm{exact}}$。\n    -   计算绝对误差 $|G_{\\mathrm{pair}} - G_{\\mathrm{exact}}|$。\n    -   计算误差界 $B = \\epsilon \\left\\lceil \\log_2(n) \\right\\rceil \\sum_{i=1}^n |g_i|$，其中 $\\epsilon=2^{-53}$。\n    -   执行布尔检查 $|G_{\\mathrm{pair}} - G_{\\mathrm{exact}}| \\le B$。\n5.  收集并报告所需的五个量——$\\text{range\\_shared}$、$\\text{range\\_message}$、 $|G_{\\mathrm{pair}} - G_{\\mathrm{exact}}|$、$B$ 和布尔结果。", "answer": "```python\nimport numpy as np\nimport decimal\nimport math\n\ndef solve():\n    \"\"\"\n    Solves the geophysical summation problem by simulating variability,\n    implementing a deterministic summation, and verifying its error bound.\n    \"\"\"\n\n    # Set precision for Decimal calculations to be safely higher than needed.\n    decimal.getcontext().prec = 200\n    \n    # IEEE 754 binary64 unit roundoff\n    EPSILON = 2**-53\n\n    # Definition of the deterministic pairwise summation algorithm.\n    def pairwise_sum(arr):\n        \"\"\"\n        Computes the sum of an array of floats using deterministic\n        pairwise summation.\n        \"\"\"\n        if not isinstance(arr, list):\n            s = arr.tolist()\n        else:\n            s = arr.copy()\n        \n        if len(s) == 0:\n            return 0.0\n        \n        while len(s) > 1:\n            next_s = []\n            # Sum adjacent pairs\n            for i in range(len(s) // 2):\n                next_s.append(s[2*i] + s[2*i+1])\n            # Propagate leftover element if length is odd\n            if len(s) % 2 == 1:\n                next_s.append(s[-1])\n            s = next_s\n        \n        return s[0]\n\n    test_cases = [\n        {\n            \"id\": 1, \"n\": 4096, \"p\": 16, \"K\": 32, \"seed\": 12345,\n            \"gen\": lambda rng, n: (rng.standard_normal(n, dtype=np.float64), rng.standard_normal(n, dtype=np.float64))\n        },\n        {\n            \"id\": 2, \"n\": 4097, \"p\": 7, \"K\": 32, \"seed\": None,\n            \"gen\": lambda rng, n: ((-1)**np.arange(n, dtype=np.float64), np.full(n, 1e-8, dtype=np.float64))\n        },\n        {\n            \"id\": 3, \"n\": 2048, \"p\": 8, \"K\": 32, \"seed\": None,\n            \"gen\": lambda rng, n: (10.0**(-np.arange(n, dtype=np.float64)/8.0), np.ones(n, dtype=np.float64))\n        },\n        {\n            \"id\": 4, \"n\": 1000, \"p\": 10, \"K\": 32, \"seed\": 67890,\n            \"gen\": lambda rng, n: (\n                np.concatenate([rng.choice([-1.0, 1.0], n//2), rng.standard_normal(n - n//2, dtype=np.float64)]),\n                np.concatenate([np.full(n//2, 1e-300, dtype=np.float64), np.ones(n - n//2, dtype=np.float64)])\n            )\n        },\n        {\n            \"id\": 5, \"n\": 1, \"p\": 1, \"K\": 32, \"seed\": None,\n            \"gen\": lambda rng, n: (np.array([3.141592653589793], dtype=np.float64), np.array([2.718281828459045], dtype=np.float64))\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        n, p, K = case[\"n\"], case[\"p\"], case[\"K\"]\n        \n        if case[\"seed\"] is not None:\n            rng = np.random.default_rng(case[\"seed\"])\n        else:\n            # Create a default RNG instance even if no seed, for consistency\n            rng = np.random.default_rng()\n\n        u, lam = case[\"gen\"](rng, n)\n        \n        # Compute g_i = fl(u_i * lambda_i) in binary64\n        g = (u * lam).astype(np.float64)\n\n        # 1. Shared-memory variability simulation\n        shared_sums = []\n        for _ in range(K):\n            perm_g = rng.permutation(g)\n            # Use Python's sum for a simple left-to-right accumulation\n            shared_sums.append(sum(perm_g))\n        range_shared = max(shared_sums) - min(shared_sums) if K > 0 and len(set(shared_sums)) > 1 else 0.0\n\n        # 2. Message-passing variability simulation\n        # Partition g into p contiguous blocks\n        blocks = np.array_split(g, p)\n        # Compute block sums deterministically using pairwise summation\n        block_sums = np.array([pairwise_sum(block) for block in blocks])\n\n        mpi_sums = []\n        for _ in range(K):\n            perm_block_sums = rng.permutation(block_sums)\n            mpi_sums.append(sum(perm_block_sums))\n        range_message = max(mpi_sums) - min(mpi_sums) if K > 0 and len(set(mpi_sums)) > 1 else 0.0\n\n        # 3. Deterministic reduction and error analysis\n        # Compute pairwise sum\n        g_pair = pairwise_sum(g)\n\n        # Compute \"exact\" sum using high-precision decimal arithmetic\n        g_decimal = [decimal.Decimal(x) for x in g]\n        g_exact = sum(g_decimal)\n        \n        # Absolute error relative to exact sum\n        abs_error = abs(decimal.Decimal(g_pair) - g_exact)\n\n        # Compute the theoretical error bound B\n        if n > 1:\n            log2n_ceil = math.ceil(math.log2(n))\n        else:\n            log2n_ceil = 0 # Depth of summation tree for n=1 is 0\n        \n        sum_abs_g = np.sum(np.abs(g))\n        bound_B = decimal.Decimal(EPSILON) * decimal.Decimal(log2n_ceil) * decimal.Decimal(sum_abs_g)\n        \n        # Check if the error is within the bound\n        bound_ok = abs_error = bound_B\n\n        all_results.append([\n            float(range_shared),\n            float(range_message),\n            float(abs_error),\n            float(bound_B),\n            bool(bound_ok)\n        ])\n\n    # Format the final output as a string representing a list of lists\n    print(f\"[{','.join(map(str, all_results))}]\")\n\nsolve()\n```", "id": "3614205"}]}