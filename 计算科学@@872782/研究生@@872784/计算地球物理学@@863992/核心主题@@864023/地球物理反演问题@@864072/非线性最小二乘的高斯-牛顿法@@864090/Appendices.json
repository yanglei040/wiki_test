{"hands_on_practices": [{"introduction": "理论的深度体现在应用之中。高斯-牛顿法的心脏是雅可比矩阵，它将模型参数的微小变化与数据的响应联系起来。为了真正掌握这一点，我们将从一个简化的解析模型出发，亲手构建雅可比矩阵。通过这个练习[@problem_id:3599237]，您不仅将推导出关键的数学表达式，还将学会如何解读其物理意义，理解数据灵敏度如何影响反演问题的稳定性和适定性。", "problem": "考虑一个双参数地球物理模型 $m=\\begin{pmatrix} m_1 \\\\ m_2 \\end{pmatrix}$，其中 $m_1$ 代表控制带限振幅响应的标量属性，$m_2$ 代表与各向异性相关的耦合参数。正演映射 $F:\\mathbb{R}^2\\to\\mathbb{R}^2$ 定义为 $F(m)=\\begin{pmatrix} \\sin(\\alpha m_1) \\\\ m_1 m_2 \\end{pmatrix}$，其中 $\\alpha0$ 是一个已知的缩放常数，其单位的选择使得正弦函数的参数为无量纲。数据加权矩阵是单位矩阵 $W_d=I$。非线性最小二乘残差定义为 $\\phi(m)=\\tfrac{1}{2}\\|F(m)-d\\|_2^2$，其中 $d\\in\\mathbb{R}^2$ 是观测数据。\n\n从 $F(m)$ 的雅可比矩阵和残差的高斯-牛顿线性化的核心定义出发，显式地导出以 $m_1$、$m_2$ 和 $\\alpha$ 表示的雅可比矩阵 $J(m)$。然后，解释 $J(m)$ 的每个元素如何反映数据对参数的物理敏感度，并阐释这些元素的大小和符号如何影响高斯-牛顿法向矩阵的条件数。你的推导应从第一性原理出发，不得引用关于 $F(m)$ 的雅可比矩阵或高斯-牛顿法的现成公式。\n\n请提供 $J(m)$ 的显式闭式解析表达式作为最终答案。不需要进行数值舍入。如果引入任何角度，必须以弧度为单位。由于最终答案是符号形式的，最终表达式中不要包含单位。", "solution": "该问题要求推导给定正演模型 $F(m)$ 的雅可比矩阵 $J(m)$，并解释其元素的物理意义及其对高斯-牛顿法的影响。对问题陈述的验证确认了其科学性、适定性和客观性。我们可以开始求解。\n\n正演模型是一个函数 $F: \\mathbb{R}^2 \\to \\mathbb{R}^2$，它将模型参数向量 $m=\\begin{pmatrix} m_1 \\\\ m_2 \\end{pmatrix}$ 映射到数据向量。正演映射的分量为：\n$$\nF(m) = \\begin{pmatrix} F_1(m_1, m_2) \\\\ F_2(m_1, m_2) \\end{pmatrix} = \\begin{pmatrix} \\sin(\\alpha m_1) \\\\ m_1 m_2 \\end{pmatrix}\n$$\n其中 $\\alpha  0$ 是一个已知常数。\n\n根据定义，向量值函数 $F(m)$ 的雅可比矩阵 $J(m)$ 是所有一阶偏导数组成的矩阵。对于一个从 $\\mathbb{R}^2$ 映射到 $\\mathbb{R}^2$ 的函数，它是一个 $2 \\times 2$ 的矩阵：\n$$\nJ(m) = \\begin{pmatrix} \\frac{\\partial F_1}{\\partial m_1}  \\frac{\\partial F_1}{\\partial m_2} \\\\ \\frac{\\partial F_2}{\\partial m_1}  \\frac{\\partial F_2}{\\partial m_2} \\end{pmatrix}\n$$\n\n我们从第一性原理出发，利用偏微分法则计算 $J(m)$ 的每个元素。\n\n第一个元素 $J_{11}$ 是 $F_1(m_1, m_2) = \\sin(\\alpha m_1)$ 关于 $m_1$ 的偏导数。应用链式法则，我们得到：\n$$\nJ_{11} = \\frac{\\partial}{\\partial m_1} \\left( \\sin(\\alpha m_1) \\right) = \\cos(\\alpha m_1) \\cdot \\frac{\\partial}{\\partial m_1}(\\alpha m_1) = \\alpha \\cos(\\alpha m_1)\n$$\n\n第二个元素 $J_{12}$ 是 $F_1(m_1, m_2) = \\sin(\\alpha m_1)$ 关于 $m_2$ 的偏导数。由于 $F_1$ 不依赖于 $m_2$，该导数为零：\n$$\nJ_{12} = \\frac{\\partial}{\\partial m_2} \\left( \\sin(\\alpha m_1) \\right) = 0\n$$\n\n第三个元素 $J_{21}$ 是 $F_2(m_1, m_2) = m_1 m_2$ 关于 $m_1$ 的偏导数：\n$$\nJ_{21} = \\frac{\\partial}{\\partial m_1} \\left( m_1 m_2 \\right) = m_2\n$$\n\n第四个元素 $J_{22}$ 是 $F_2(m_1, m_2) = m_1 m_2$ 关于 $m_2$ 的偏导数：\n$$\nJ_{22} = \\frac{\\partial}{\\partial m_2} \\left( m_1 m_2 \\right) = m_1\n$$\n\n将这些偏导数组合成矩阵，便得到雅可比矩阵 $J(m)$ 的显式形式：\n$$\nJ(m) = \\begin{pmatrix} \\alpha \\cos(\\alpha m_1)  0 \\\\ m_2  m_1 \\end{pmatrix}\n$$\n\n接下来，我们解释这些元素的物理意义及其对高斯-牛顿法向矩阵条件数的影响。每个元素 $J_{ij} = \\frac{\\partial F_i}{\\partial m_j}$ 表示第 $i$ 个数据分量对第 $j$ 个模型参数无穷小变化的敏感度。\n- $J_{11} = \\alpha \\cos(\\alpha m_1)$：该项量化了第一个数据 $F_1 = \\sin(\\alpha m_1)$ 对参数 $m_1$ 变化的敏感度。敏感度是振荡的，在 $|\\cos(\\alpha m_1)| = 1$ 时（即当 $\\alpha m_1$ 是 $\\pi$ 的整数倍时）其绝对值达到最大。在这些点上，函数 $F_1$ 穿过零点且最陡峭。相反，当 $\\cos(\\alpha m_1) = 0$ 时（即当 $\\alpha m_1 = (n + \\frac{1}{2})\\pi$ 对任意整数 $n$ 成立时），敏感度为零。这些点对应于正弦波的峰值和谷值，在这些点上，$m_1$ 的微小变化对 $F_1$ 的影响可以忽略不计。\n- $J_{12} = 0$：这表明第一个数据 $F_1$ 对参数 $m_2$ 的变化完全不敏感。根据该模型，带限振幅响应的测量与各向异性参数完全解耦。\n- $J_{21} = m_2$：这是第二个数据 $F_2 = m_1 m_2$ 对 $m_1$ 扰动的敏感度。敏感度与耦合参数 $m_2$ 的值成正比。如果 $m_2$ 接近于零，则第二个数据对 $m_1$ 变得不敏感，这意味着耦合很弱。\n- $J_{22} = m_1$：这是第二个数据 $F_2$ 对 $m_2$ 变化的敏感度。该敏感度与 $m_1$ 成正比。如果 $m_1$ 接近于零，则第二个数据对各向异性参数 $m_2$ 不敏感。\n\n高斯-牛顿法使用矩阵 $H_{GN} = J(m)^T J(m)$ 来近似残差函数 $\\phi(m)$ 的海森矩阵（因为数据加权矩阵 $W_d = I$）。这个法向矩阵的条件数对于反演的稳定性和收敛性至关重要。一个病态或奇异的 $H_{GN}$ 会导致不稳定的参数更新。\n法向矩阵为：\n$$\nH_{GN} = J^T J = \\begin{pmatrix} \\alpha \\cos(\\alpha m_1)  m_2 \\\\ 0  m_1 \\end{pmatrix} \\begin{pmatrix} \\alpha \\cos(\\alpha m_1)  0 \\\\ m_2  m_1 \\end{pmatrix} = \\begin{pmatrix} \\alpha^2 \\cos^2(\\alpha m_1) + m_2^2  m_1 m_2 \\\\ m_1 m_2  m_1^2 \\end{pmatrix}\n$$\n局部线性问题的适定性取决于 $H_{GN}$ 是否可逆。这等价于 $J(m)$ 的列向量线性无关。$H_{GN}$ 的行列式提供了对此的度量。使用方阵 $A$ 的性质 $\\det(A^T A) = (\\det A)^2$，我们可以计算：\n$$\n\\det(J) = (\\alpha \\cos(\\alpha m_1))(m_1) - (0)(m_2) = \\alpha m_1 \\cos(\\alpha m_1)\n$$\n因此，法向矩阵的行列式为：\n$$\n\\det(H_{GN}) = (\\det(J))^2 = \\alpha^2 m_1^2 \\cos^2(\\alpha m_1)\n$$\n如果 $\\det(H_{GN}) = 0$，法向矩阵 $H_{GN}$ 变为奇异矩阵，反演问题变得病态。这在两种情况下发生：\n1. $m_1 = 0$：如果振幅参数 $m_1$ 为零，雅可比矩阵变为 $J = \\begin{pmatrix} \\alpha  0 \\\\ m_2  0 \\end{pmatrix}$，其列向量是线性相关的。从物理上讲，如果 $m_1=0$，则对于任何 $m_2$ 的值，$F(m) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。数据不包含关于 $m_2$ 的任何信息，使其恢复变得不可能。\n2. $\\cos(\\alpha m_1) = 0$：这种情况发生在 $\\alpha m_1_k = \\frac{\\pi}{2} + k\\pi$（对于任意整数 $k$）时。在这种情况下，雅可比矩阵为 $J = \\begin{pmatrix} 0  0 \\\\ m_2  m_1 \\end{pmatrix}$。第一行为零，使得矩阵秩亏。从物理上讲，这对应于我们之前讨论过的第一个数据 $d_1$ 相对于 $m_1$ 的零敏感度点。在 $F_1$ 的这些极值点， $m_1$ 的微小扰动无法在第一个数据中被“观测”到，从而导致信息丢失和系统病态。\n\n元素的大小也影响条件数。如果 $m_1$ 非常小，$\\det(H_{GN})$ 会变得非常小，导致病态条件。同样，如果模型接近于 $\\cos(\\alpha m_1) \\approx 0$ 的点，问题也近似是病态的。雅可比矩阵元素的符号虽然不直接影响 $J^T J$ 的条件数（因为项被平方），但对于确定高斯-牛顿算法中参数更新步长 $\\delta m$ 的方向至关重要，因为更新依赖于乘积 $J^T (d - F(m))$。", "answer": "$$\n\\boxed{\nJ(m) = \\begin{pmatrix}\n\\alpha \\cos(\\alpha m_1)  0 \\\\\nm_2  m_1\n\\end{pmatrix}\n}\n$$", "id": "3599237"}, {"introduction": "在解决了理论基础之后，我们面临一个更为棘手的现实挑战：周期跳跃（cycle skipping）。在地震波形反演等问题中，目标函数可能因相位失配而呈现高度振荡，导致优化算法陷入局部极小值。这个实践[@problem_id:3599323]构建了一个经典的周期跳跃场景，通过对比传统的波形残差与更平滑的包络残差，您将亲身体会到如何通过巧妙地重新设计目标函数来克服这一难题，从而显著提升算法的鲁棒性。", "problem": "你需要实现一个完整的、可运行的程序，构建一个一维波形反演玩具模型。在此模型中，正演模拟算子生成一个单一的反射脉冲，其形式为时间平移后的Ricker子波。反演目标是单一的未知参数——恒定的声速，数据是在地表测量的合成地震图。目标是检验高斯-牛顿法在标准的基于振幅的最小二乘残差和另一种基于包络的失配函数下对非线性最小二乘（NLS）问题的行为，以说明前者中的周波跳跃现象，并展示后者中高斯-牛顿步长的变化。\n\n使用以下基本设置和定义：\n\n- 观测数据是在深度为 $z$ 的单个平坦地下反射层上采集的，介质为速度未知（模型变量为 $m$）的恒定速度介质。双程走时为 $ \\tau(m) = \\dfrac{2 z}{m} $。\n- 震源子波是Ricker子波 $ s(t) = \\left(1 - 2 a t^2\\right) \\exp\\left(- a t^2\\right) $，其中 $ a = \\left(\\pi f_0\\right)^2 $，$ f_0 $ 是中心频率。\n- 无噪声的正演模型是合成地震图 $ d\\!\\left(t; m\\right) = s\\!\\left(t - \\tau(m)\\right) $。\n- 基于振幅的最小二乘目标函数为 $ \\Phi_{\\mathrm{wf}}(m) = \\dfrac{1}{2} \\left\\| r_{\\mathrm{wf}}(m) \\right\\|_2^2 $，其残差为 $ r_{\\mathrm{wf}}(t; m) = d_{\\mathrm{obs}}(t) - d\\!\\left(t; m\\right) $。\n- 基于包络的替代失配函数使用振幅包络 $ e\\!\\left(t; m\\right) = \\sqrt{ d\\!\\left(t; m\\right)^2 + \\left( \\mathcal{H}\\{ d\\!\\left(t; m\\right) \\} \\right)^2 } $，其中 $ \\mathcal{H}\\{\\cdot\\} $ 表示希尔伯特变换，目标函数为 $ \\Phi_{\\mathrm{env}}(m) = \\dfrac{1}{2} \\left\\| r_{\\mathrm{env}}(m) \\right\\|_2^2 $，其残差为 $ r_{\\mathrm{env}}(t; m) = e_{\\mathrm{obs}}(t) - e\\!\\left(t; m\\right) $。\n\n从第一性原理出发，为每个目标函数推导高斯-牛顿步长：\n\n- 从非线性最小二乘目标函数 $ \\Phi(m) = \\dfrac{1}{2} \\left\\| r(m) \\right\\|_2^2 $ 的定义出发，并使用高斯-牛顿近似，即用 $ J(m)^\\top J(m) $ 替代精确的海森矩阵，其中 $ J(m) $ 是残差关于 $ m $ 的雅可比矩阵。\n- 对于波形残差，使用链式法则和Ricker子波的导数，推导雅可比矩阵的元素 $ J_{\\mathrm{wf}}(t; m) = \\dfrac{\\partial}{\\partial m} d\\!\\left(t; m\\right) $。Ricker子波的导数为 $ s'(t) = \\exp\\!\\left(- a t^2\\right) \\, t \\left( - 6 a + 4 a^2 t^2 \\right) $。请用 $ z $、$ m $ 和 $ s'\\!\\big(t - \\tau(m)\\big) $ 明确给出 $ J_{\\mathrm{wf}}(t; m) $ 的表达式。\n- 对于包络残差，利用 $ \\mathcal{H}\\{\\cdot\\} $ 是一个线性算子这一事实，通过链式法则推导雅可比矩阵的元素 $ J_{\\mathrm{env}}(t; m) = \\dfrac{\\partial}{\\partial m} e\\!\\left(t; m\\right) $：设 $ e(t; m) = \\sqrt{x(t; m)^2 + y(t; m)^2} $，其中 $ x = d(t; m) $ 且 $ y = \\mathcal{H}\\{ d(t; m) \\} $。证明 $ \\dfrac{\\partial e}{\\partial m}(t; m) = \\dfrac{ x \\, \\dfrac{\\partial x}{\\partial m} + y \\, \\dfrac{\\partial y}{\\partial m} }{ e } $ 并将 $ \\dfrac{\\partial y}{\\partial m} $ 与 $ \\mathcal{H}\\!\\left\\{ \\dfrac{\\partial x}{\\partial m} \\right\\} $ 联系起来。\n\n然后，为每个目标函数，写出单个参数 $ m $ 的高斯-牛顿更新步长：\n$$\n\\Delta m_{\\bullet} = \\dfrac{ \\sum_t J_{\\bullet}(t; m_0) \\, r_{\\bullet}(t; m_0) }{ \\sum_t J_{\\bullet}(t; m_0)^2 },\n$$\n其中 $ \\bullet \\in \\{ \\mathrm{wf}, \\mathrm{env} \\} $，$ m_0 $ 是当前的模型迭代值。解释为什么当 $ m_0 $ 与真实值相差足够远时，基于波形的残差 $ r_{\\mathrm{wf}} $ 会表现出周波跳跃现象，该现象表现为多周期的相位失配，导致 $ J_{\\mathrm{wf}}^\\top r_{\\mathrm{wf}} $ 的符号具有误导性或量级过小，从而产生一个差的 $ \\Delta m_{\\mathrm{wf}} $。将此与基于包络的残差进行对比，后者抑制了振荡的相位效应，通常能提供一个更稳健的、朝向真实解的步长 $ \\Delta m_{\\mathrm{env}} $。\n\n物理和数值参数：\n\n- 深度 $ z = 1000\\,\\mathrm{m} $。\n- 真实速度 $ m_\\star = 2000\\,\\mathrm{m/s} $。\n- 中心频率 $ f_0 = 10\\,\\mathrm{Hz} $。\n- 时间采样间隔 $ \\Delta t = 0.001\\,\\mathrm{s} $。\n- 记录长度 $ T = 2.5\\,\\mathrm{s} $。\n\n角度，包括任何可能隐式出现在解析信号中的相位，均应以弧度为单位。\n\n初始模型速度 $ m_0 $ 的测试套件：\n\n- 情况1（完美匹配）：$ m_0 = 2000\\,\\mathrm{m/s} $。\n- 情况2（接近，低于半个周期的失配）：$ m_0 = 2100\\,\\mathrm{m/s} $。\n- 情况3（中度周波跳跃，约一个周期的失配）：$ m_0 = 1800\\,\\mathrm{m/s} $。\n- 情况4（严重周波跳跃，多个周期）：$ m_0 = 1500\\,\\mathrm{m/s} $。\n\n你的程序必须：\n\n- 使用 $ m_\\star $ 构建 $ d_{\\mathrm{obs}}(t) $，并对测试套件中的每个 $ m_0 $，根据上述高斯-牛顿公式计算 $ \\Delta m_{\\mathrm{wf}} $ 和 $ \\Delta m_{\\mathrm{env}} $。\n- 使用希尔伯特变换计算包络和包络的雅可比矩阵，并采取适当的数值保护措施以避免在包络振幅极小时出现除以零的情况。\n- 将每个 $ \\Delta m $ 以米/秒（$\\mathrm{m/s}$）为单位表示，并四舍五入到 $6$ 位小数。\n\n最终输出格式：\n\n- 你的程序应生成单行输出，其中包含一个逗号分隔的列表，列表用方括号括起来。此列表的每个元素对应一个测试用例，并且本身必须是一个双元素列表，按顺序包含该用例的高斯-牛顿步长 $ \\Delta m_{\\mathrm{wf}} $ 和 $ \\Delta m_{\\mathrm{env}} $。例如，输出应类似于 $ \\left[ [\\Delta m_{\\mathrm{wf}}^{(1)}, \\Delta m_{\\mathrm{env}}^{(1)}], \\ldots, [\\Delta m_{\\mathrm{wf}}^{(4)}, \\Delta m_{\\mathrm{env}}^{(4)}] \\right] $，其中每个数字都打印为 $6$ 位小数，单位默认为 $\\mathrm{m/s}$。", "solution": "用户提供了一个有效的问题陈述。任务是分析一维波形反演问题中高斯-牛顿优化方法，并比较一个标准的基于波形的目标函数与一个基于包络的替代方案。分析的重点是周波跳跃现象。解决方案需要为每个目标函数推导高斯-牛顿步长，然后实现一个数值模拟来为几个初始模型计算这些步长。\n\n首先，我们建立理论框架。目标是找到模型参数 $m$（声速），以最小化形式为 $\\Phi(m) = \\frac{1}{2} \\|r(m)\\|_2^2$ 的非线性最小二乘目标函数，其中 $r(m)$ 是观测数据和预测数据之间的残差向量。对于离散时间序列，这表示为 $\\Phi(m) = \\frac{1}{2} \\sum_t [r(t; m)]^2$。\n\n高斯-牛顿法用 $J(m)^\\top J(m)$ 来近似目标函数的海森矩阵 $\\nabla^2 \\Phi(m)$，其中 $J(m)$ 是残差向量 $r(m)$ 关于模型参数 $m$ 的雅可比矩阵。雅可比矩阵的元素是 $J(t; m) = \\frac{\\partial r(t; m)}{\\partial m}$。模型参数的更新步长通过求解正规方程 $J(m)^\\top J(m) \\Delta m = -J(m)^\\top r(m)$ 得到。在我们的案例中，由于只有一个参数 $m$，这简化为一个标量方程。问题将残差定义为 $r(t;m) = d_{\\mathrm{obs}}(t) - d(t;m)$，所以其雅可比矩阵是 $J(t;m) = \\frac{\\partial r}{\\partial m} = -\\frac{\\partial d}{\\partial m}$。目标函数的梯度是 $\\nabla \\Phi(m) = \\sum_t r(t;m) \\frac{\\partial r(t;m)}{\\partial m} = - \\sum_t r(t;m) \\frac{\\partial d(t;m)}{\\partial m}$。标准的高斯-牛顿更新是 $m_{k+1} = m_k - (\\nabla^2 \\Phi)^{-1} \\nabla \\Phi$。步长为 $\\delta m = - (J^\\top J)^{-1} J^\\top r$。\n问题陈述中提供的步长公式 $\\Delta m$ 省略了负号：\n$$\n\\Delta m = \\left( \\sum_t J(t; m_0)^2 \\right)^{-1} \\left( \\sum_t J(t; m_0) r(t; m_0) \\right)\n$$\n这意味着如果 $J = \\frac{\\partial d}{\\partial m}$，更新规则为 $m_{k+1} = m_k - \\Delta m$；或者如果 $J = -\\frac{\\partial d}{\\partial m}$，更新规则为 $m_{k+1} = m_k + \\Delta m$。我们将遵循所提供的公式，并注意到校正方向取决于残差与数据敏感度之间的局部相关性。\n\n合成数据的正演模型是一个时间平移的Ricker子波：$d(t; m) = s(t - \\tau(m))$，其中 $s(t) = (1 - 2 a t^2) \\exp(-a t^2)$ 且 $a = (\\pi f_0)^2$，双程走时为 $\\tau(m) = \\frac{2z}{m}$。\n\n**1. 基于波形的目标函数 $\\Phi_{\\mathrm{wf}}(m)$**\n\n残差为 $r_{\\mathrm{wf}}(t; m) = d_{\\mathrm{obs}}(t) - d(t; m)$。此残差关于 $m$ 的雅可比矩阵是 $J_{\\mathrm{wf}}(t; m) = \\frac{\\partial r_{\\mathrm{wf}}}{\\partial m} = -\\frac{\\partial d(t; m)}{\\partial m}$。\n使用链式法则：\n$$\n\\frac{\\partial d(t; m)}{\\partial m} = \\frac{\\partial}{\\partial m} s(t - \\tau(m)) = s'(t - \\tau(m)) \\cdot \\left( -\\frac{\\partial \\tau(m)}{\\partial m} \\right)\n$$\n走时的导数是 $\\frac{\\partial \\tau(m)}{\\partial m} = \\frac{\\partial}{\\partial m}\\left(\\frac{2z}{m}\\right) = -\\frac{2z}{m^2}$。\n代入此式，我们得到：\n$$\n\\frac{\\partial d(t; m)}{\\partial m} = s'(t - \\tau(m)) \\cdot \\left( - \\left( -\\frac{2z}{m^2} \\right) \\right) = \\frac{2z}{m^2} s'(t - \\tau(m))\n$$\n因此，残差的雅可比矩阵为 $J_{\\mathrm{wf}}(t; m) = -\\frac{2z}{m^2} s'(t - \\tau(m))$。所提供的步长公式使用的 $J$ 未指定是针对残差还是正演模型。为确保步长是修正性的，我们来分析梯度。$\\nabla\\Phi = J_{\\mathrm{wf}}^\\top r_{\\mathrm{wf}}$。如果我们使用问题中的 $\\Delta m$ 公式，它代表了沿梯度的步长。更新 $m_{k+1} = m_k - \\lambda \\Delta m$ 将是梯度下降。我们将按照所提供的公式计算 $\\Delta m$，并将雅可比矩阵定义为*正演模型*的敏感度，即 $J(t;m) = \\frac{\\partial d(t;m)}{\\partial m}$。\n$$\nJ_{\\mathrm{wf}}(t; m) = \\frac{2z}{m^2} s'(t - \\tau(m))\n$$\n其中Ricker子波的导数由 $s'(t) = \\exp(- a t^2) \\, t \\, (-6 a + 4 a^2 t^2)$ 给出。\n高斯-牛顿步长则为：\n$$\n\\Delta m_{\\mathrm{wf}} = \\frac{\\sum_t J_{\\mathrm{wf}}(t; m_0) \\, r_{\\mathrm{wf}}(t; m_0)}{\\sum_t J_{\\mathrm{wf}}(t; m_0)^2}\n$$\n\n**2. 基于包络的目标函数 $\\Phi_{\\mathrm{env}}(m)$**\n\n残差为 $r_{\\mathrm{env}}(t; m) = e_{\\mathrm{obs}}(t) - e(t; m)$，其中 $e(t; m)$ 是信号 $d(t; m)$ 的振幅包络，定义为 $e(t; m) = |d(t;m) + i \\mathcal{H}\\{d(t;m)\\}|$，$\\mathcal{H}\\{\\cdot\\}$ 表示希尔伯特变换。\n设 $x(t; m) = d(t; m)$ 和 $y(t; m) = \\mathcal{H}\\{d(t; m)\\}$。则 $e(t; m) = \\sqrt{x^2 + y^2}$。正演模型 $e(t; m)$ 的雅可比矩阵为：\n$$\nJ_{\\mathrm{env}}(t; m) = \\frac{\\partial e}{\\partial m} = \\frac{1}{2\\sqrt{x^2+y^2}} \\left( 2x \\frac{\\partial x}{\\partial m} + 2y \\frac{\\partial y}{\\partial m} \\right) = \\frac{x \\frac{\\partial x}{\\partial m} + y \\frac{\\partial y}{\\partial m}}{e}\n$$\n我们有 $\\frac{\\partial x}{\\partial m} = \\frac{\\partial d}{\\partial m} = J_{\\mathrm{wf}}(t; m)$。由于希尔伯特变换是线性算子，其应用可与对 $m$ 的微分互换：\n$$\n\\frac{\\partial y}{\\partial m} = \\frac{\\partial}{\\partial m} \\mathcal{H}\\{d(t; m)\\} = \\mathcal{H}\\left\\{\\frac{\\partial d(t; m)}{\\partial m}\\right\\} = \\mathcal{H}\\{J_{\\mathrm{wf}}(t; m)\\}\n$$\n代入这些结果，我们得到包络雅可比矩阵的显式公式：\n$$\nJ_{\\mathrm{env}}(t; m) = \\frac{d(t; m) J_{\\mathrm{wf}}(t; m) + \\mathcal{H}\\{d(t; m)\\} \\mathcal{H}\\{J_{\\mathrm{wf}}(t; m)\\}}{e(t; m)}\n$$\n因此，包络目标函数的高斯-牛顿步长为：\n$$\n\\Delta m_{\\mathrm{env}} = \\frac{\\sum_t J_{\\mathrm{env}}(t; m_0) \\, r_{\\mathrm{env}}(t; m_0)}{\\sum_t J_{\\mathrm{env}}(t; m_0)^2}\n$$\n\n**3. 周波跳跃分析**\n\n基于波形的目标函数 $\\Phi_{\\mathrm{wf}}$ 作为模型参数 $m$ 的函数是高度振荡的，表现出众多的局部极小值。当预测子波 $d(t; m_0)$ 与观测数据 $d_{\\mathrm{obs}}(t)$ 的错位量是子波半周期的整数倍时，就会出现这些极小值。$\\Delta m_{\\mathrm{wf}}$ 公式中的分子 $\\sum_t J_{\\mathrm{wf}} r_{\\mathrm{wf}}$ 表示残差与雅可比矩阵的互相关。当初始猜测 $m_0$ 远离真实值 $m_\\star$ 时，时间偏移 $\\tau(m_0) - \\tau(m_\\star)$ 可能很大。如果这个偏移量超过子波主导周期的一半左右，相关性可能会变小甚至符号反转。符号反转会导致高斯-牛顿步长指向错误的方向，远离真实解。这种未能找到正确极小值的失败现象被称为周波跳跃。\n\n相比之下，包络 $e(t; m)$ 是一个平滑的、非振荡的时间函数，其最大值位于群到时 $\\tau(m)$。因此，基于包络的目标函数 $\\Phi_{\\mathrm{env}}$ 在更宽的 $m$ 值范围内更为平滑和凸。其全局极小值周围的吸引盆更大，使得优化过程不易受周波跳跃的影响。残差 $r_{\\mathrm{env}}$ 捕捉了到时失配，而没有振荡干扰，其与雅可比矩阵 $J_{\\mathrm{env}}$ 的相关性通常能提供一个稳健的更新方向，即使对于 $m_0$ 的较大初始误差也是如此。\n\n以下程序为指定的测试用例实现了这些计算，展示了包络失配相对于波形失配的稳健性。在 $J_{\\mathrm{env}}$ 的分母中的包络上添加了一个小常数 $\\epsilon$ 以确保数值稳定性。计算出的步长 $\\Delta m$ 是标准高斯-牛顿公式中的搜索方向乘以-1。对于更新规则 $m_{k+1} = m_k + \\Delta m_{step}$，我们计算的 $\\Delta m$ 应等于 $-\\Delta m_{step}$。这意味着如果 $m_0  m_\\star$，我们期望一个正的 $\\Delta m$，如果 $m_0  m_\\star$，则期望一个负的 $\\Delta m$。然而，对梯度的分析表明，我们的 $\\Delta m = (J^TJ)^{-1}J^Tr$ 项在 $m_0  m_\\star$ 时应为正，在 $m_0  m_\\star$ 时应为负。实现将遵循此推导，期望正步长会增加模型值。", "answer": "```python\nimport numpy as np\nfrom scipy.signal import hilbert\n\ndef solve():\n    \"\"\"\n    Computes and compares Gauss-Newton steps for waveform and envelope\n    misfit functions in a 1D seismic inversion toy problem.\n    \"\"\"\n    # Physical and numerical parameters\n    z = 1000.0  # Reflector depth in meters\n    m_true = 2000.0  # True velocity in m/s\n    f0 = 10.0  # Central frequency in Hz\n    dt = 0.001  # Time sampling interval in seconds\n    t_max = 2.5  # Record length in seconds\n    epsilon = 1e-9 # Small constant for numerical stability\n\n    # Time vector\n    t = np.arange(0, t_max, dt)\n\n    # Ricker wavelet and its derivative\n    a = (np.pi * f0)**2\n    def ricker(time_vec):\n        return (1.0 - 2.0 * a * time_vec**2) * np.exp(-a * time_vec**2)\n\n    def ricker_derivative(time_vec):\n        return np.exp(-a * time_vec**2) * time_vec * (-6.0 * a + 4.0 * a**2 * time_vec**2)\n\n    # Forward modeling operator\n    def forward_model(m, time_vec):\n        tau = 2.0 * z / m\n        return ricker(time_vec - tau)\n\n    # Generate observed data\n    d_obs = forward_model(m_true, t)\n\n    # Test cases for initial model velocities\n    test_cases = [2000.0, 2100.0, 1800.0, 1500.0]\n\n    results = []\n    \n    for m0 in test_cases:\n        # Calculate predicted data for the current model parameter m0\n        d_pred = forward_model(m0, t)\n\n        # --- 1. Waveform-based inversion step ---\n        r_wf = d_obs - d_pred\n        \n        # Calculate Jacobian for waveform misfit\n        tau0 = 2.0 * z / m0\n        # The Jacobian is d(d)/dm = s'(t-tau) * d(-tau)/dm = s'(t-tau) * (2z/m^2)\n        J_wf = (2.0 * z / m0**2) * ricker_derivative(t - tau0)\n\n        # Calculate Gauss-Newton step for waveform\n        numerator_wf = np.sum(J_wf * r_wf)\n        denominator_wf = np.sum(J_wf**2)\n        \n        if np.isclose(denominator_wf, 0):\n            delta_m_wf = 0.0\n        else:\n            # The formula in the problem is delta_m = (J^T J)^-1 J^T r.\n            # The standard Gauss-Newton update step is p = - (J^T J)^-1 J^T r.\n            # Here, J is for the forward model, not the residual.\n            # The gradient of the objective is -J^T r.\n            # The update m_k+1 = m_k + p.\n            # We are calculating -p.\n            # For m0=2100 > m_true=2000, we want a negative step p. So -p should be positive.\n            # For m0=1800  m_true=2000, we want a positive step p. So -p should be negative.\n            # The formula is (J^T J)^-1 J^T (d_obs - d_pred)\n            delta_m_wf = -1 * (numerator_wf / denominator_wf)\n\n        # --- 2. Envelope-based inversion step ---\n        \n        # Calculate analytic signals and envelopes\n        analytic_obs = hilbert(d_obs)\n        analytic_pred = hilbert(d_pred)\n        \n        e_obs = np.abs(analytic_obs)\n        e_pred = np.abs(analytic_pred)\n\n        r_env = e_obs - e_pred\n        \n        # Calculate Jacobian for envelope misfit\n        # J_env = d(e)/dm = [d*d(d)/dm + H{d}*d(H{d})/dm] / e\n        #       = [d*J_wf + H{d}*H{J_wf}] / e\n        analytic_J_wf = hilbert(J_wf)\n        \n        # The numerator is the real part of (analytic_pred_conj * analytic_J_wf)\n        numerator_J_env = np.real(np.conj(analytic_pred) * analytic_J_wf)\n        J_env = np.divide(numerator_J_env, e_pred + epsilon, \n                          out=np.zeros_like(numerator_J_env), \n                          where=(e_pred + epsilon) != 0)\n\n        # Calculate Gauss-Newton step for envelope\n        numerator_env = np.sum(J_env * r_env)\n        denominator_env = np.sum(J_env**2)\n\n        if np.isclose(denominator_env, 0):\n            delta_m_env = 0.0\n        else:\n            delta_m_env = -1 * (numerator_env / denominator_env)\n\n        results.append([round(delta_m_wf, 6), round(delta_m_env, 6)])\n\n    # Format the final output string\n    # In the provided solution, the logic was to implement the formula as is.\n    # After re-evaluation, it's clear the standard update is m_{k+1} = m_k - (J^TJ)^{-1}J^Tr,\n    # where J is Jacobian of residual. Here, J is Jacobian of forward model, and residual is d_obs - d_pred.\n    # Grad = -J^T(d_obs - d_pred) = J^T(d_pred - d_obs).\n    # Step = - (J^TJ)^{-1} Grad = - (J^TJ)^{-1} J^T (d_pred - d_obs) = (J^TJ)^{-1} J^T (d_obs - d_pred).\n    # This is exactly what the problem formula calculates. So the step direction is the update itself.\n    # Re-running the logic without the -1 multiplier.\n    \n    final_results = []\n    for m0 in test_cases:\n        d_pred = forward_model(m0, t)\n        r_wf = d_obs - d_pred\n        tau0 = 2.0 * z / m0\n        J_wf = (2.0 * z / m0**2) * ricker_derivative(t - tau0)\n        numerator_wf = np.sum(J_wf * r_wf)\n        denominator_wf = np.sum(J_wf**2)\n        delta_m_wf = 0.0 if np.isclose(denominator_wf, 0) else numerator_wf / denominator_wf\n\n        analytic_obs = hilbert(d_obs)\n        analytic_pred = hilbert(d_pred)\n        e_obs = np.abs(analytic_obs)\n        e_pred = np.abs(analytic_pred)\n        r_env = e_obs - e_pred\n        analytic_J_wf = hilbert(J_wf)\n        numerator_J_env = np.real(np.conj(analytic_pred) * analytic_J_wf)\n        J_env = np.divide(numerator_J_env, e_pred + epsilon, out=np.zeros_like(numerator_J_env), where=(e_pred + epsilon) != 0)\n        numerator_env = np.sum(J_env * r_env)\n        denominator_env = np.sum(J_env**2)\n        delta_m_env = 0.0 if np.isclose(denominator_env, 0) else numerator_env / denominator_env\n\n        final_results.append([round(delta_m_wf, 6), round(delta_m_env, 6)])\n    \n    output_str = \"[\" + \",\".join([f\"[{res[0]:.6f},{res[1]:.6f}]\" for res in final_results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3599323"}, {"introduction": "当问题规模从教学示例扩展到真实世界的应用时，计算效率和代码的正确性变得至关重要。对于拥有数百万参数的模型，显式地构建和存储雅可比矩阵是不可行的。此练习[@problem_id:3599258]将指导您实施伴随状态法（adjoint-state method），这是一种无需形成雅可比矩阵即可高效计算梯度的强大技术。更重要的是，您将学习如何通过与有限差分法进行“梯度检查”来验证您实现的正确性，这是计算科学家验证复杂代码时不可或缺的基本功。", "problem": "要求您在计算地球物理学中非线性最小二乘的高斯-牛顿法 (Gauss-Newton methods) 背景下，实现并验证一个非线性最小二乘目标的梯度计算。验证基于通过伴随式解析表达式得到的梯度与通过有限差分得到的梯度之间的夹角余弦值。本问题中的所有量均为无量纲。\n\n考虑一个由线性映射和逐点非线性变换复合而成的正演算子。具体来说，设 $W \\in \\mathbb{R}^{N \\times K}$，$B \\in \\mathbb{R}^{K \\times P}$，以及 $m \\in \\mathbb{R}^{P}$。定义正演映射 $F(m) \\in \\mathbb{R}^{N}$ 为\n$$\nF(m) = W \\sin(B m),\n$$\n其中 $\\sin(\\cdot)$ 逐元素作用于向量 $B m \\in \\mathbb{R}^{K}$。给定观测数据 $d_{\\text{obs}} \\in \\mathbb{R}^{N}$，定义残差向量 $r(m) \\in \\mathbb{R}^{N}$ 为\n$$\nr(m) = F(m) - d_{\\text{obs}},\n$$\n以及最小二乘目标\n$$\n\\phi(m) = \\frac{1}{2} \\|r(m)\\|_2^2.\n$$\n在高斯-牛顿法中，$\\phi(m)$ 的梯度是 $J(m)^{\\top} r(m)$，其中 $J(m)$ 是 $F(m)$ 关于 $m$ 的雅可比矩阵。您的任务是：\n- 基于链式法则，推导并实现一个 $J(m)^{\\top} r(m)$ 的伴随式表达式，而无需显式构造 $J(m)$。\n- 通过独立扰动 $m$ 的每个分量来估计 $\\phi(m)$ 的偏导数，从而实现 $\\phi(m)$ 梯度的中心有限差分近似。\n- 计算伴随梯度 $g_{\\text{adj}}(m) = J(m)^{\\top} r(m)$ 和有限差分梯度 $g_{\\text{fd}}(m)$ 之间的夹角余弦：\n$$\n\\cos \\theta(m) = \\frac{g_{\\text{adj}}(m) \\cdot g_{\\text{fd}}(m)}{\\|g_{\\text{adj}}(m)\\|_2 \\, \\|g_{\\text{fd}}(m)\\|_2}.\n$$\n为保证数值稳健性，请使用以下特殊情况处理规则：\n- 如果 $\\|g_{\\text{adj}}(m)\\|_2$ 和 $\\|g_{\\text{fd}}(m)\\|_2$ 都小于阈值 $10^{-12}$，则定义 $\\cos \\theta(m) = 1.0$。\n- 如果只有一个范数小于 $10^{-12}$，则定义 $\\cos \\theta(m) = 0.0$。\n- 否则，使用上述公式。\n\n实现您的程序以评估下面指定的测试套件的 $\\cos \\theta(m)$。程序必须使用双精度算术和自适应中心有限差分步长 $h_i$ (针对 $m$ 的第 $i$ 个分量)，步长由下式给出：\n$$\nh_i = 10^{-6} \\max(1, |m_i|).\n$$\n不涉及物理单位；所有量均为无量纲。\n\n测试套件规范：\n- 测试用例 1（一般情况）：$N=8, K=10, P=5$。使用均值为零、单位方差的独立高斯分布条目构造 $W$ 和 $B$，其中 $W$ 的伪随机种子为 $123$，$B$ 的伪随机种子为 $456$。设 $m_{\\text{true}}$ 为高斯分布，种子为 $789$。设 $d_{\\text{obs}} = W \\sin(B m_{\\text{true}}) + \\eta$，其中 $\\eta$ 是标准差为 $10^{-3}$、种子为 $321$ 的高斯噪声。在 $m_0 = m_{\\text{true}}$ 处评估 $\\cos \\theta$。\n- 测试用例 2（中等扰动）：使用与测试用例 1 相同的 $W$、$B$ 和 $d_{\\text{obs}}$。设 $m_0 = m_{\\text{true}} + \\delta$，其中 $\\delta$ 为高斯分布，种子为 $654$，并经过缩放使得每个分量的标准差为 $10^{-1}$。\n- 测试用例 3（边界维度）：$N=4, K=3, P=1$。种子：$W$ 为 $5$，$B$ 为 $6$。设 $m_{\\text{true}} = [0.7]^{\\top}$。设 $d_{\\text{obs}} = W \\sin(B m_{\\text{true}}) + \\eta$，其中 $\\eta$ 为标准差为 $10^{-4}$、种子为 $11$ 的高斯噪声。在 $m_0 = m_{\\text{true}}$ 处进行评估。\n- 测试用例 4（零残差边缘情况）：$N=6, K=7, P=3$。种子：$W$ 为 $7$，$B$ 为 $8$。设 $m_0$ 为高斯分布，种子为 $12$。设 $d_{\\text{obs}} = W \\sin(B m_0)$（无噪声）。在 $m_0$ 处进行评估。\n- 测试用例 5（因参数接近 $\\pi/2$ 导致的近零梯度）：$N=5, K=5, P=5$。种子：$W$ 为 $9$，$B$ 为 $10$。定义 $v = (\\pi/2) \\mathbf{1} \\in \\mathbb{R}^{K}$，并设 $m_0$ 为 $B m \\approx v$ 的最小二乘解。设 $d_{\\text{obs}} = \\mathbf{0} \\in \\mathbb{R}^{N}$。在 $m_0$ 处进行评估。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，$[result1,result2,result3]$）。这五个结果必须是测试用例 1 到 5 的 $\\cos \\theta$ 值，并按顺序排列。每个输出值必须是浮点数。", "solution": "该问题要求实现并验证一种用于计算非线性最小二乘目标函数梯度的伴随状态法。验证是通过将伴随状态梯度与通过中心有限差分近似的梯度进行比较来执行的。问题的核心在于正确推导和实现伴随状态梯度计算（该计算避免了显式构造雅可比矩阵），以及对两个所得梯度向量进行稳健的数值比较。\n\n设模型参数为向量 $m \\in \\mathbb{R}^{P}$。正演模型 $F(m)$ 将参数映射到数据空间 $\\mathbb{R}^{N}$，定义为：\n$$\nF(m) = W \\sin(B m)\n$$\n其中 $W \\in \\mathbb{R}^{N \\times K}$ 和 $B \\in \\mathbb{R}^{K \\times P}$ 是给定的矩阵，$\\sin(\\cdot)$ 函数逐元素应用于向量 $B m \\in \\mathbb{R}^{K}$。\n\n给定一个观测数据向量 $d_{\\text{obs}} \\in \\mathbb{R}^{N}$，残差向量为 $r(m) = F(m) - d_{\\text{obs}}$。非线性最小二乘目标函数 $\\phi(m)$ 定义为残差的 L2 范数平方的一半：\n$$\n\\phi(m) = \\frac{1}{2} \\|r(m)\\|_2^2 = \\frac{1}{2} r(m)^\\top r(m)\n$$\n\n目标函数 $\\phi(m)$ 关于参数 $m$ 的梯度由下式给出：\n$$\n\\nabla_m \\phi(m) = J(m)^\\top r(m)\n$$\n其中 $J(m) \\in \\mathbb{R}^{N \\times P}$ 是正演算子 $F(m)$ 的雅可比矩阵，其元素为 $J_{ij} = \\frac{\\partial F_i}{\\partial m_j}$。对于高斯-牛顿法，此梯度是关键组成部分。问题将此解析推导的梯度表示为 $g_{\\text{adj}}(m)$。\n\n**伴随状态梯度推导 ($g_{\\text{adj}}$)**\n对于大规模问题，显式构造雅可比矩阵 $J(m)$ 在计算上是不可行的。伴随状态法提供了一种有效计算梯度-向量积 $J(m)^\\top r(m)$ 的方法，而无需构造 $J(m)$。我们通过应用链式法则来推导此表达式。\n\n正演模型可以看作是三个操作的复合：\n1. 线性变换：$u(m) = B m$\n2. 逐点非线性函数：$v(u) = \\sin(u)$\n3. 线性变换：$F(v) = W v$\n\n这些中间步骤的雅可比矩阵是：\n-   $\\frac{\\partial u}{\\partial m} = B$\n-   $\\frac{\\partial v}{\\partial u} = \\text{diag}(\\cos(u)) = \\text{diag}(\\cos(Bm))$，一个 $K \\times K$ 的对角矩阵。\n-   $\\frac{\\partial F}{\\partial v} = W$\n\n根据链式法则，完整的雅可比矩阵 $J(m)$ 是这些中间雅可比矩阵的乘积：\n$$\nJ(m) = \\frac{\\partial F}{\\partial m} = \\frac{\\partial F}{\\partial v} \\frac{\\partial v}{\\partial u} \\frac{\\partial u}{\\partial m} = W \\, \\text{diag}(\\cos(Bm)) \\, B\n$$\n\n梯度 $g_{\\text{adj}}(m)$ 于是为：\n$$\ng_{\\text{adj}}(m) = J(m)^\\top r(m) = \\left( W \\, \\text{diag}(\\cos(Bm)) \\, B \\right)^\\top r(m)\n$$\n利用属性 $(ABC)^\\top = C^\\top B^\\top A^\\top$ 以及对角矩阵是对称的，我们得到：\n$$\ng_{\\text{adj}}(m) = B^\\top \\text{diag}(\\cos(Bm)) W^\\top r(m)\n$$\n这个表达式可以从右到左高效地计算，仅需要矩阵-向量积和逐元素积：\n1.  计算残差：$r(m) = W \\sin(Bm) - d_{\\text{obs}}$\n2.  计算伴随源：$s = W^\\top r(m)$，这是一个在 $\\mathbb{R}^K$ 中的向量。\n3.  应用非线性的雅可比矩阵：$z = \\cos(Bm) \\odot s$，其中 $\\odot$ 表示逐元素（哈达玛）积。这等价于乘以对角矩阵 $\\text{diag}(\\cos(Bm))$。\n4.  应用第一个线性算子的伴随：$g_{\\text{adj}}(m) = B^\\top z$。结果是梯度向量，位于 $\\mathbb{R}^P$ 中。\n\n**有限差分梯度近似 ($g_{\\text{fd}}$)**\n为了验证解析推导及其实现，我们将其与梯度的数值近似进行比较。梯度的第 $i$ 个分量 $\\frac{\\partial \\phi}{\\partial m_i}$，使用二阶精度的中心有限差分公式进行近似：\n$$\n[g_{\\text{fd}}(m)]_i = \\frac{\\phi(m + h_i e_i) - \\phi(m - h_i e_i)}{2 h_i}\n$$\n其中 $e_i$ 是第 $i$ 个标准基向量（一个在第 $i$ 个位置为 1，其余位置为零的向量）。对每个分量 $i = 1, \\dots, P$ 执行此计算，以构造完整的梯度向量 $g_{\\text{fd}}(m)$。步长 $h_i$ 被自适应地选择以平衡截断误差和舍入误差，具体规定如下：\n$$\nh_i = 10^{-6} \\max(1, |m_i|)\n$$\n\n**通过余弦相似度进行验证**\n伴随梯度 $g_{\\text{adj}}(m)$ 和有限差分梯度 $g_{\\text{fd}}(m)$ 之间的一致性通过它们之间夹角 $\\theta$ 的余弦值来量化。这是一个称为“梯度检验”的标准过程。\n$$\n\\cos \\theta(m) = \\frac{g_{\\text{adj}}(m) \\cdot g_{\\text{fd}}(m)}{\\|g_{\\text{adj}}(m)\\|_2 \\, \\|g_{\\text{fd}}(m)\\|_2}\n$$\n$\\cos \\theta(m)$ 的值接近 $1.0$ 表示两个向量指向同一方向，从而验证了伴随法的实现。\n\n为了数值稳定性，当一个或两个梯度向量的范数接近零时，需要进行特殊处理。我们使用阈值 $\\tau = 10^{-12}$：\n-   如果 $\\|g_{\\text{adj}}(m)\\|_2  \\tau$ 且 $\\|g_{\\text{fd}}(m)\\|_2  \\tau$，我们定义 $\\cos \\theta(m) = 1.0$。这处理了真实梯度为零且两种方法都正确计算出近零向量的情况。\n-   如果只有一个范数小于 $\\tau$，我们定义 $\\cos \\theta(m) = 0.0$。这表示存在差异，因为一种方法找到了零梯度而另一种没有。\n-   否则，使用标准公式。\n\n实现将通过为正演模型、目标函数、伴随梯度和有限差分梯度创建函数来继续。这些函数将应用于五个指定的测试用例，以计算相应的 $\\cos \\theta$ 值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and compute cosine similarities.\n    \"\"\"\n\n    def forward_model(W, B, m):\n        \"\"\"Computes F(m) = W * sin(B * m).\"\"\"\n        return W @ np.sin(B @ m)\n\n    def objective_function(W, B, m, d_obs):\n        \"\"\"Computes phi(m) = 0.5 * ||F(m) - d_obs||^2.\"\"\"\n        residual = forward_model(W, B, m) - d_obs\n        return 0.5 * np.linalg.norm(residual)**2\n\n    def compute_adjoint_gradient(W, B, m, d_obs):\n        \"\"\"Computes the gradient via the adjoint-state method.\"\"\"\n        # Step 1: Compute residual\n        residual = forward_model(W, B, m) - d_obs\n        \n        # Step 2: Compute adjoint source\n        adjoint_source = W.T @ residual\n        \n        # Step 3: Apply Jacobian of nonlinearity\n        u = B @ m\n        z = np.cos(u) * adjoint_source\n        \n        # Step 4: Apply adjoint of the first linear operator\n        g_adj = B.T @ z\n        return g_adj\n\n    def compute_fd_gradient(W, B, m, d_obs):\n        \"\"\"Computes the gradient via central finite differences.\"\"\"\n        P = len(m)\n        g_fd = np.zeros(P, dtype=np.float64)\n        \n        for i in range(P):\n            h_i = 1e-6 * max(1.0, abs(m[i]))\n            \n            m_plus = m.copy()\n            m_plus[i] += h_i\n            \n            m_minus = m.copy()\n            m_minus[i] -= h_i\n            \n            phi_plus = objective_function(W, B, m_plus, d_obs)\n            phi_minus = objective_function(W, B, m_minus, d_obs)\n            \n            g_fd[i] = (phi_plus - phi_minus) / (2 * h_i)\n            \n        return g_fd\n\n    def compute_cosine_similarity(g_adj, g_fd):\n        \"\"\"Computes the cosine of the angle between two vectors with robust handling.\"\"\"\n        norm_adj = np.linalg.norm(g_adj)\n        norm_fd = np.linalg.norm(g_fd)\n        threshold = 1e-12\n\n        if norm_adj  threshold and norm_fd  threshold:\n            return 1.0\n        elif norm_adj  threshold or norm_fd  threshold:\n            return 0.0\n        else:\n            dot_product = np.dot(g_adj, g_fd)\n            return dot_product / (norm_adj * norm_fd)\n\n    # --- Test Case Generation ---\n    results = []\n\n    # Test Case 1\n    N, K, P = 8, 10, 5\n    rng_W = np.random.default_rng(123)\n    W1 = rng_W.standard_normal((N, K))\n    rng_B = np.random.default_rng(456)\n    B1 = rng_B.standard_normal((K, P))\n    rng_m_true = np.random.default_rng(789)\n    m_true1 = rng_m_true.standard_normal(P)\n    rng_noise = np.random.default_rng(321)\n    eta1 = 1e-3 * rng_noise.standard_normal(N)\n    d_obs1 = forward_model(W1, B1, m_true1) + eta1\n    m0_1 = m_true1\n\n    g_adj1 = compute_adjoint_gradient(W1, B1, m0_1, d_obs1)\n    g_fd1 = compute_fd_gradient(W1, B1, m0_1, d_obs1)\n    results.append(compute_cosine_similarity(g_adj1, g_fd1))\n\n    # Test Case 2\n    rng_delta = np.random.default_rng(654)\n    delta = 1e-1 * rng_delta.standard_normal(P)\n    m0_2 = m_true1 + delta\n\n    g_adj2 = compute_adjoint_gradient(W1, B1, m0_2, d_obs1)\n    g_fd2 = compute_fd_gradient(W1, B1, m0_2, d_obs1)\n    results.append(compute_cosine_similarity(g_adj2, g_fd2))\n    \n    # Test Case 3\n    N, K, P = 4, 3, 1\n    rng_W = np.random.default_rng(5)\n    W3 = rng_W.standard_normal((N, K))\n    rng_B = np.random.default_rng(6)\n    B3 = rng_B.standard_normal((K, P))\n    m_true3 = np.array([0.7])\n    rng_noise = np.random.default_rng(11)\n    eta3 = 1e-4 * rng_noise.standard_normal(N)\n    d_obs3 = forward_model(W3, B3, m_true3) + eta3\n    m0_3 = m_true3\n\n    g_adj3 = compute_adjoint_gradient(W3, B3, m0_3, d_obs3)\n    g_fd3 = compute_fd_gradient(W3, B3, m0_3, d_obs3)\n    results.append(compute_cosine_similarity(g_adj3, g_fd3))\n\n    # Test Case 4\n    N, K, P = 6, 7, 3\n    rng_W = np.random.default_rng(7)\n    W4 = rng_W.standard_normal((N, K))\n    rng_B = np.random.default_rng(8)\n    B4 = rng_B.standard_normal((K, P))\n    rng_m0 = np.random.default_rng(12)\n    m0_4 = rng_m0.standard_normal(P)\n    d_obs4 = forward_model(W4, B4, m0_4)\n\n    g_adj4 = compute_adjoint_gradient(W4, B4, m0_4, d_obs4)\n    g_fd4 = compute_fd_gradient(W4, B4, m_0_4, d_obs4)\n    results.append(compute_cosine_similarity(g_adj4, g_fd4))\n\n    # Test Case 5\n    N, K, P = 5, 5, 5\n    rng_W = np.random.default_rng(9)\n    W5 = rng_W.standard_normal((N, K))\n    rng_B = np.random.default_rng(10)\n    B5 = rng_B.standard_normal((K, P))\n    v = (np.pi / 2) * np.ones(K)\n    m0_5 = np.linalg.lstsq(B5, v, rcond=None)[0]\n    d_obs5 = np.zeros(N)\n\n    g_adj5 = compute_adjoint_gradient(W5, B5, m0_5, d_obs5)\n    g_fd5 = compute_fd_gradient(W5, B5, m0_5, d_obs5)\n    results.append(compute_cosine_similarity(g_adj5, g_fd5))\n    \n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3599258"}]}