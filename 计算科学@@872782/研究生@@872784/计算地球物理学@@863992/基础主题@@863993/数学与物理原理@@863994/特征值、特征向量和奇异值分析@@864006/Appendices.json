{"hands_on_practices": [{"introduction": "特征值分析不仅限于研究物理系统，它同样是理解数据内在结构的强大工具。谱聚类是一种前沿技术，它利用图拉普拉斯矩阵的特征向量来识别数据中的簇。在本实践中，您将学习如何根据合成的微震事件数据构建相似性图，并利用其“Fiedler向量”（第二小特征值对应的特征向量）将事件划分到不同的人工裂缝集中[@problem_id:3587801]。这个练习将揭示特征值如何阐明复杂数据集的连通性和最优分割方式。", "problem": "给定一个与两个裂缝组相关的合成微震事件集合。每个事件都具有空间坐标、源时、矩震级和破裂持续时间。你将使用一个旨在强调破裂动力学的核函数从这些事件中构建一个亲和图，计算归一化图拉普拉斯算子，分析其特征值分布，并通过对第二小的特征向量（即 Fiedler 向量）进行阈值处理来执行双向谱聚类。你的目标是量化特征值分布如何决定谱聚类的质量，并设计一个更加强调破裂持续时间的核函数。所有推导都必须从图、特征值和瑞利商的基本定义出发，并且你必须通过这些原则来证明每个计算步骤的合理性，而不是预设任何目标公式。\n\n本问题的基础理论必须包括：带亲和权重的加权无向图的定义、度矩阵和图拉普拉斯算子、归一化图拉普拉斯算子、特征值的瑞利商表征，以及第二小特征值与松弛化分割目标之间的联系。你也可以使用对称正定核的性质以及特征矩阵的奇异值分解（SVD）。\n\n数据生成必须是确定性的和纯算法的，如下所示。共有 $N = 32$ 个事件，分为两个裂缝组 $\\mathcal{F}_A$ 和 $\\mathcal{F}_B$，每个组包含 $16$ 个事件。对于 $\\mathcal{F}_A$，用 $k \\in \\{0,1,\\ldots,15\\}$ 索引事件并定义：\n- 空间坐标（单位：米）：$\\mathbf{r}_k = (x_k,y_k,z_k)$，其中 $x_k = 5 k$，$y_k = 2 \\sin(k)$，$z_k = 0$。\n- 源时（单位：秒）：$t_k = 0.03 k$。\n- 矩震级（无量纲）：$m_k = 2.0 + 0.05\\,( (k \\bmod 4) - 1.5 )$。\n- 破裂持续时间（单位：秒）：$\\tau_k = 0.02 + 0.003\\,(k \\bmod 5)$。\n\n对于 $\\mathcal{F}_B$，用 $k \\in \\{0,1,\\ldots,15\\}$ 索引事件并定义：\n- 空间坐标（单位：米）：$\\mathbf{r}'_k = (x'_k,y'_k,z'_k)$，其中 $x'_k = 120 + 5 k$，$y'_k = 2 \\cos(k)$，$z'_k = 5$。\n- 源时（单位：秒）：$t'_k = 1.0 + 0.03 k$。\n- 矩震级（无量纲）：$m'_k = 2.0 + 0.07\\,( (k \\bmod 3) - 1.0 )$。\n- 破裂持续时间（单位：秒）：$\\tau'_k = 0.08 + 0.003\\,(k \\bmod 5)$。\n\n将这些连接成 $N = 32$ 个事件，其真实裂缝标签对于 $\\mathcal{F}_A$ 为 $0$，对于 $\\mathcal{F}_B$ 为 $1$。\n\n使用高斯核函数构建一个对称亲和矩阵 $W \\in \\mathbb{R}^{N \\times N}$，该核函数作用于一个旨在强调破裂动力学的缩放特征向量。对于每个事件 $i$，定义一个缩放特征向量\n$$\n\\mathbf{s}_i = \\left(\\frac{x_i}{\\ell}, \\frac{y_i}{\\ell}, \\frac{z_i}{\\ell}, \\frac{t_i}{T}, \\frac{m_i}{M}, \\sqrt{\\beta}\\,\\frac{\\tau_i}{\\Theta} \\right),\n$$\n其中 $\\ell$（米）、$T$（秒）、$M$（无量纲）、$\\Theta$（秒）是特征缩放参数，$\\beta$（无量纲）是强调破裂持续时间的权重参数。通过以下方式定义亲和权重\n$$\nW_{ij} = \\exp\\left(-\\left\\| \\mathbf{s}_i - \\mathbf{s}_j \\right\\|_2^2\\right), \\quad W_{ii} = 0.\n$$\n计算对角度矩阵 $D$，其条目为 $D_{ii} = \\sum_j W_{ij}$，以及归一化图拉普拉斯算子\n$$\nL_{\\mathrm{sym}} = I - D^{-1/2} W D^{-1/2}.\n$$\n将 $L_{\\mathrm{sym}}$ 的特征值排序为 $0 = \\lambda_1 \\le \\lambda_2 \\le \\cdots \\le \\lambda_N$，并附有相应的标准正交特征向量。使用第二个特征向量，通过将其条目在中值处进行阈值处理来执行双向谱聚类，从而将节点集分成两个不相交的簇。\n\n对于每个指定的参数集，你必须：\n- 计算 $L_{\\mathrm{sym}}$ 的特征值和谱隙 $g = \\lambda_3 - \\lambda_2$。\n- 通过第二个特征向量执行双向谱聚类，通过中值阈值分配簇标签，并计算相对于真实裂缝标签的聚类纯度。纯度必须以 $[0,1]$ 区间内的小数形式报告。\n- 使用亲和矩阵 $W$ 和度矩阵 $D$ 计算所得分割的归一化切割值。\n- 构建缩放后的特征矩阵 $X_s \\in \\mathbb{R}^{N \\times 6}$，其行为 $\\mathbf{s}_i$，通过奇异值分解（SVD）计算其奇异值，并报告最小奇异值与最大奇异值的比率。\n\n设计一个测试套件，通过改变尺度参数 $(\\ell,T,M,\\Theta)$ 和破裂强调参数 $\\beta$ 来探测不同的情况：\n- 情况 1（理想路径，强调破裂动力学）：$\\ell = 200$，$T = 0.5$，$M = 0.5$，$\\Theta = 0.02$，$\\beta = 5.0$。\n- 情况 2（边界情况，近乎同质的亲和度）：$\\ell = 500$，$T = 5.0$，$M = 1.0$，$\\Theta = 0.2$，$\\beta = 1.0$。\n- 情况 3（极端情况，几何主导）：$\\ell = 30$，$T = 100.0$，$M = 5.0$，$\\Theta = 10.0$，$\\beta = 0.2$。\n\n所有物理量必须按照所述单位精确处理：空间坐标以米为单位，时间和持续时间以秒为单位，震级无量纲。本问题不使用角度。你的程序必须为每种情况产生以下输出：\n- 谱隙 $g$，浮点数格式。\n- 聚类纯度，小数格式。\n- 归一化切割值，浮点数格式。\n- 奇异值比率，浮点数格式。\n\n你的程序应产生单行输出，包含一个用方括号括起来的逗号分隔列表，其中每个元素本身是包含四个浮点数（按 $[g,\\text{purity},\\text{ncut},\\text{svr}]$ 顺序，保留六位小数）的列表。例如，总体格式必须是\n$$\n\\big[\\,[g_1,\\text{purity}_1,\\text{ncut}_1,\\text{svr}_1],\\,[g_2,\\text{purity}_2,\\text{ncut}_2,\\text{svr}_2],\\,[g_3,\\text{purity}_3,\\text{ncut}_3,\\text{svr}_3]\\,\\big].\n$$", "solution": "该问题是有效的。它在科学上基于谱图理论及其在地球物理数据分析中的应用，在数学上是适定的、完全指定的和客观的。没有矛盾或模糊之处。\n\n### 1. 理论框架\n\n任务是使用谱聚类将一组 $N=32$ 个微震事件划分为两个簇，对应于两个不同的裂缝组。然后在变化的特征缩放机制下评估此聚类的质量。该方法基于图论和线性代数的原理。\n\n#### 1.1. 图表示与亲和矩阵\n将 $N$ 个事件的集合建模为一个加权无向图 $G = (V, E, W)$，其中顶点集 $V$ 代表事件，$E$ 是连接所有事件对的边集，$W \\in \\mathbb{R}^{N \\times N}$ 是对称亲和矩阵。权重 $W_{ij}$ 量化了事件 $i$ 和事件 $j$ 之间的相似性。\n\n事件首先由一组物理属性来表征：空间坐标 $\\mathbf{r}_i = (x_i, y_i, z_i)$、源时 $t_i$、矩震级 $m_i$ 和破裂持续时间 $\\tau_i$。为了构建一个有意义的相似性度量，这些异构特征被映射到一个统一的、无量纲的特征空间。为每个事件 $i$ 定义一个缩放后的特征向量 $\\mathbf{s}_i \\in \\mathbb{R}^6$：\n$$\n\\mathbf{s}_i = \\left(\\frac{x_i}{\\ell}, \\frac{y_i}{\\ell}, \\frac{z_i}{\\ell}, \\frac{t_i}{T}, \\frac{m_i}{M}, \\sqrt{\\beta}\\,\\frac{\\tau_i}{\\Theta} \\right)\n$$\n这里，$\\ell$（长度单位）、$T$（时间单位）、$M$（无量纲）和 $\\Theta$（时间单位）是用于归一化不同物理量的缩放参数。无量纲参数 $\\beta$ 是一个权重，旨在控制破裂持续时间 $\\tau_i$ 对总亲和度的影响。\n\n两个事件 $i$ 和 $j$ 之间的亲和度 $W_{ij}$ 使用高斯核计算，这是一种正定核，确保了得到的亲和矩阵是对称且半正定的：\n$$\nW_{ij} = \\exp\\left(-\\left\\| \\mathbf{s}_i - \\mathbf{s}_j \\right\\|_2^2\\right) \\quad \\text{for } i \\neq j\n$$\n按照惯例，对角线元素设置为零，$W_{ii} = 0$，以避免自环。\n\n#### 1.2. 归一化图拉普拉斯算子与谱聚类\n谱聚类利用图拉普拉斯矩阵的谱（特征值和特征向量）。我们使用对称归一化拉普拉斯算子 $L_{\\mathrm{sym}}$，其定义为：\n$$\nL_{\\mathrm{sym}} = I - D^{-1/2} W D^{-1/2}\n$$\n其中 $I$ 是单位矩阵，$D$ 是对角度矩阵，其条目为 $D_{ii} = \\sum_{j=1}^{N} W_{ij}$，表示节点 $i$ 的总亲和度。$D^{-1/2}$ 是一个对角矩阵，其条目为 $(D^{-1/2})_{ii} = 1/\\sqrt{D_{ii}}$。\n\n谱聚类的核心思想是找到图顶点 $V$ 的一个划分为两个不相交的集合 $A$ 和 $\\bar{A}$，使得归一化切割（NCut）最小化：\n$$\n\\text{NCut}(A, \\bar{A}) = \\frac{\\text{cut}(A, \\bar{A})}{\\text{vol}(A)} + \\frac{\\text{cut}(A, \\bar{A})}{\\text{vol}(\\bar{A})}\n$$\n其中 $\\text{cut}(A, \\bar{A}) = \\sum_{i \\in A, j \\in \\bar{A}} W_{ij}$ 是跨越分割的边的权重之和，$\\text{vol}(A) = \\sum_{i \\in A} D_{ii}$ 是集合 $A$ 中节点的度之和。\n\n直接最小化 NCut 是一个 NP 难的组合问题。它可以被松弛为一个连续问题。设 $\\mathbf{y} \\in \\mathbb{R}^N$ 是一个编码分割的向量。可以证明，NCut 最小化问题近似等价于最小化非归一化拉普拉斯算子 $L = D-W$ 的瑞利商：$\\min_{\\mathbf{y}} \\mathbf{y}^T L \\mathbf{y}$，约束条件为 $\\mathbf{y}^T D \\mathbf{y} = 1$ 和 $\\mathbf{y}^T D \\mathbf{1} = 0$。\n\n通过变量替换 $\\mathbf{z} = D^{1/2}\\mathbf{y}$，该问题转换为：\n$$\n\\min_{\\mathbf{z}} \\mathbf{z}^T L_{\\mathrm{sym}} \\mathbf{z} \\quad \\text{subject to} \\quad \\mathbf{z}^T\\mathbf{z} = 1 \\quad \\text{and} \\quad \\mathbf{z}^T (D^{1/2}\\mathbf{1}) = 0\n$$\n根据 Rayleigh-Ritz 定理，瑞利商 $\\mathbf{z}^T L_{\\mathrm{sym}} \\mathbf{z} / \\mathbf{z}^T\\mathbf{z}$ 的最小值是 $L_{\\mathrm{sym}}$ 的最小特征值。$L_{\\mathrm{sym}}$ 的特征值按 $0 = \\lambda_1 \\le \\lambda_2 \\le \\cdots \\le \\lambda_N$ 排序。对应于 $\\lambda_1=0$ 的特征向量是 $\\mathbf{v}_1 \\propto D^{1/2}\\mathbf{1}$，它代表一个平凡的常数解。约束条件 $\\mathbf{z}^T (D^{1/2}\\mathbf{1}) = 0$ 要求解与 $\\mathbf{v}_1$ 正交。因此，松弛问题的最优解是对应于第二小特征值 $\\lambda_2$ 的特征向量。这个特征向量 $\\mathbf{v}_2$ 被称为 Fiedler 向量。\n\nFiedler 向量 $\\mathbf{v}_2$ 的分量提供了图节点的一维嵌入。通过对这些分量进行阈值处理可以获得一个分割。在本问题中，我们在 $\\mathbf{v}_2$ 分量的中值处设置阈值，这能稳健地将节点分成两个大小相等的集合（每个集合 16 个节点），非常适合我们平衡的真实数据。\n\n#### 1.3. 评估指标\n聚类的有效性由四个指标量化：\n1.  **谱隙 ($g$)**：$g = \\lambda_3 - \\lambda_2$。大的谱隙表明双簇结构很突出，基于 $\\mathbf{v}_2$ 的分割是稳定的，并且得到了图结构的充分支持。\n2.  **聚类纯度**：这衡量了计算出的簇在多大程度上包含来自单一真实裂缝组的事件。对于两个簇 $C_0, C_1$ 和两个真实类别 $T_A, T_B$，纯度计算为 $\\frac{1}{N} \\max(\\text{correct}_{map1}, \\text{correct}_{map2})$，其中 $\\text{correct}_{map1}$ 是假设 $C_0 \\to T_A$ 和 $C_1 \\to T_B$ 时正确分配的事件数，而 $\\text{correct}_{map2}$ 是对应相反分配 $C_0 \\to T_B$ 和 $C_1 \\to T_A$ 的情况。\n3.  **归一化切割 (NCut)**：从 Fiedler 向量获得的分割的 NCut 目标函数值。较小的 NCut 值表示更好的分割。\n4.  **奇异值比率 (SVR)**：缩放后特征矩阵 $X_s$（其行为 $\\mathbf{s}_i$）的最小奇异值与最大奇异值之比，$\\sigma_{\\min}/\\sigma_{\\max}$。该比率量化了特征空间的条件性或“平坦度”。一个非常小的比率表明某些特征维度占主导地位，而一个接近 1 的比率则表明特征更具各向同性。\n\n### 2. 计算步骤\n\n对于三个测试用例中的每一个，执行以下步骤：\n\n1.  **数据生成**：根据提供的确定性公式生成 $N=32$ 个事件的属性。前 16 个事件属于裂缝组 $\\mathcal{F}_A$（标签 $0$），后 16 个属于 $\\mathcal{F}_B$（标签 $1$）。\n2.  **特征缩放**：使用给定用例的参数 $(\\ell, T, M, \\Theta, \\beta)$，将 $32 \\times 6$ 的原始数据特征矩阵缩放以产生矩阵 $X_s$。\n3.  **图构建**：从 $X_s$ 使用高斯核计算亲和矩阵 $W$。然后构建度矩阵 $D$ 和归一化拉普拉斯算子 $L_{\\mathrm{sym}}$。\n4.  **特征系统和 SVD**：计算 $L_{\\mathrm{sym}}$ 的特征值和特征向量。同时计算 $X_s$ 的奇异值。\n5.  **指标计算**：\n    -   计算谱隙为 $g = \\lambda_3 - \\lambda_2$。\n    -   识别 Fiedler 向量 $\\mathbf{v}_2$。根据其在 $\\mathbf{v}_2$ 中对应的分量是否大于 $\\mathbf{v}_2$ 的中值，将节点划分为两个簇。\n    -   根据真实标签计算此分割的纯度。\n    -   使用 $W, D$ 和该分割计算 NCut 值。\n    -   从 $X_s$ 的奇异值计算 SVR。\n6.  **输出格式化**：收集四个计算出的指标 $[g, \\text{purity}, \\text{ncut}, \\text{svr}]$ 并按指定格式进行格式化。\n\n对所有三个测试用例重复此过程，这些用例旨在探讨缩放参数的选择如何影响谱聚类恢复数据底层结构的能力。预计情况 1 会表现良好，因为它强调了具有区分性的破裂持续时间特征。预计情况 2 会表现不佳，因为过大的缩放参数会使亲和度同质化。预计情况 3 会表现良好，但基于一个不同于情况 1 的主导特征（空间位置）。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the computational geophysics problem by performing spectral clustering\n    on synthetic microseismic event data for three different parameter cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (happy path, rupture-dynamics emphasis)\n        {'l': 200.0, 'T': 0.5, 'M': 0.5, 'Theta': 0.02, 'beta': 5.0},\n        # Case 2 (boundary, near-homogeneous affinities)\n        {'l': 500.0, 'T': 5.0, 'M': 1.0, 'Theta': 0.2, 'beta': 1.0},\n        # Case 3 (edge, geometry-dominated)\n        {'l': 30.0, 'T': 100.0, 'M': 5.0, 'Theta': 10.0, 'beta': 0.2},\n    ]\n\n    results = []\n\n    # --- Data Generation ---\n    N_per_set = 16\n    N = 2 * N_per_set\n\n    # Fracture Set A\n    k_a = np.arange(N_per_set)\n    x_a = 5 * k_a\n    y_a = 2 * np.sin(k_a)\n    z_a = np.zeros(N_per_set)\n    t_a = 0.03 * k_a\n    m_a = 2.0 + 0.05 * ((k_a % 4) - 1.5)\n    tau_a = 0.02 + 0.003 * (k_a % 5)\n\n    # Fracture Set B\n    k_b = np.arange(N_per_set)\n    x_b = 120 + 5 * k_b\n    y_b = 2 * np.cos(k_b)\n    z_b = 5 * np.ones(N_per_set)\n    t_b = 1.0 + 0.03 * k_b\n    m_b = 2.0 + 0.07 * ((k_b % 3) - 1.0)\n    tau_b = 0.08 + 0.003 * (k_b % 5)\n\n    # Concatenate data\n    x = np.concatenate((x_a, x_b))\n    y = np.concatenate((y_a, y_b))\n    z = np.concatenate((z_a, z_b))\n    t = np.concatenate((t_a, t_b))\n    m = np.concatenate((m_a, m_b))\n    tau = np.concatenate((tau_a, tau_b))\n\n    # Raw feature matrix\n    X_raw = np.column_stack([x, y, z, t, m, tau])\n\n    # Ground truth labels\n    ground_truth_labels = np.array([0] * N_per_set + [1] * N_per_set)\n\n    for case_params in test_cases:\n        l, T, M, Theta, beta = case_params.values()\n\n        # --- Feature Scaling ---\n        scaling_factors = np.array([1/l, 1/l, 1/l, 1/T, 1/M, np.sqrt(beta)/Theta])\n        X_s = X_raw * scaling_factors\n\n        # --- Affinity Matrix W ---\n        # Compute pairwise squared Euclidean distances\n        dist_sq = np.sum((X_s[:, np.newaxis, :] - X_s[np.newaxis, :, :])**2, axis=2)\n        W = np.exp(-dist_sq)\n        np.fill_diagonal(W, 0)\n        \n        # --- Normalized Graph Laplacian L_sym ---\n        D_diag = np.sum(W, axis=1)\n        # Handle case of isolated nodes, though unlikely with Gaussian kernel\n        D_diag[D_diag == 0] = 1e-12 \n        D_inv_sqrt_diag = 1.0 / np.sqrt(D_diag)\n        D_inv_sqrt = np.diag(D_inv_sqrt_diag)\n        \n        I = np.identity(N)\n        L_sym = I - D_inv_sqrt @ W @ D_inv_sqrt\n\n        # --- Eigen-analysis ---\n        eigenvalues, eigenvectors = np.linalg.eigh(L_sym)\n        # Eigenvalues are sorted in ascending order\n        lambda_2 = eigenvalues[1]\n        lambda_3 = eigenvalues[2]\n        g = lambda_3 - lambda_2\n        \n        fiedler_vector = eigenvectors[:, 1]\n        \n        # --- Spectral Clustering and Purity ---\n        median_val = np.median(fiedler_vector)\n        predicted_labels = (fiedler_vector > median_val).astype(int)\n        \n        # Calculate purity\n        matches_map1 = np.sum(predicted_labels == ground_truth_labels)\n        purity = max(matches_map1, N - matches_map1) / N\n\n        # --- Normalized Cut Value ---\n        A = np.where(predicted_labels == 0)[0]\n        B = np.where(predicted_labels == 1)[0]\n        \n        cut_AB = np.sum(W[np.ix_(A, B)])\n        vol_A = np.sum(D_diag[A])\n        vol_B = np.sum(D_diag[B])\n\n        if vol_A == 0 or vol_B == 0:\n            ncut = np.inf\n        else:\n            ncut = cut_AB / vol_A + cut_AB / vol_B\n            \n        # --- Singular Value Ratio ---\n        singular_values = np.linalg.svd(X_s, compute_uv=False)\n        # svd returns sorted singular values\n        svr = singular_values[-1] / singular_values[0] if singular_values[0] > 0 else 0.0\n\n        results.append([g, purity, ncut, svr])\n\n    # Final print statement in the exact required format.\n    # [[g1,purity1,ncut1,svr1],[g2,purity2,ncut2,svr2],[g3,purity3,ncut3,svr3]]\n    result_str = ','.join(\n        f\"[{','.join(f'{v:.6f}' for v in r)}]\" for r in results\n    )\n    print(f\"[{result_str}]\")\n\nsolve()\n```", "id": "3587801"}, {"introduction": "现在，我们将焦点从数据结构分析转向优化像全波形反演（FWI）这样的大尺度反演问题。在反演中，Hessian矩阵描述了目标函数的曲率，其特征向量指向了模型空间中高敏感度或低敏感度的方向。本练习将演示如何设计一个与这些特征向量对齐的“智能”平滑算子，以缓解周期跳跃等优化难题，从而在不丢失关键模型细节的前提下有效驯服优化过程[@problem_id:3587829]。", "problem": "考虑一个简化的全波形反演（FWI）模型空间设置，其模型参数向量为 $\\mathbf{m} \\in \\mathbb{R}^3$。设数据失配在参考模型周围的局部高斯-牛顿近似由一个对称正定Hessian矩阵 $\\mathbf{H} \\in \\mathbb{R}^{3 \\times 3}$ 表示。为了以可控的方式捕捉周波跳跃行为，沿指定方向用振荡分量增强二次失配。定义合成失配函数\n$$\nJ(\\mathbf{m}) = \\tfrac{1}{2}\\,\\mathbf{m}^\\top \\mathbf{H}\\,\\mathbf{m} \\;+\\; \\gamma \\sum_{j=1}^{J} \\sin\\!\\big(\\,\\omega_j\\,\\mathbf{k}_j^\\top \\mathbf{m} + \\phi_j\\,\\big),\n$$\n其中 $\\gamma \\in \\mathbb{R}$ 控制振荡幅度，$\\omega_j \\in \\mathbb{R}$ 是角频率（单位为弧度），$\\mathbf{k}_j \\in \\mathbb{R}^3$ 是模型空间中的方向向量，$\\phi_j \\in \\mathbb{R}$ 是相位偏移（单位为弧度）。所有三角函数参数均以弧度处理。\n\n设Hessian矩阵的特征值分解为 $\\mathbf{H} = \\mathbf{Q}\\,\\mathrm{diag}(\\boldsymbol{\\lambda})\\,\\mathbf{Q}^\\top$，其中 $\\mathbf{Q}$ 是正交矩阵，$\\boldsymbol{\\lambda} = [\\lambda_1,\\lambda_2,\\lambda_3]^\\top$ 是正特征值。考虑一个与Hessian矩阵特征向量对齐的各向异性平滑算子，由阻尼函数谱定义\n$$\ns(\\lambda_i; \\alpha, p) \\;=\\; \\frac{1}{1 + \\alpha\\,\\lambda_i^{\\,p}},\n$$\n其中 $\\alpha \\ge 0$ 且 $p \\ge 0$，以及算子\n$$\n\\mathbf{S}(\\alpha,p) \\;=\\; \\mathbf{Q}\\,\\mathrm{diag}\\big(s(\\lambda_i; \\alpha,p)\\big)\\,\\mathbf{Q}^\\top.\n$$\n该算子选择性地阻尼高曲率方向（即大的 $\\lambda_i$）。\n\n根据基本微分法则，定义合成失配在 $\\mathbf{m}$ 处的梯度：\n$$\n\\nabla J(\\mathbf{m}) \\;=\\; \\mathbf{H}\\,\\mathbf{m} \\;+\\; \\gamma \\sum_{j=1}^{J} \\omega_j \\cos\\!\\big(\\,\\omega_j\\,\\mathbf{k}_j^\\top \\mathbf{m} + \\phi_j\\,\\big)\\,\\mathbf{k}_j.\n$$\n考虑使用和不使用各向异性平滑的下降方向：\n$$\n\\mathbf{d}_0 \\;=\\; -\\,\\nabla J(\\mathbf{m}), \\qquad \\mathbf{d}_\\alpha \\;=\\; -\\,\\mathbf{S}(\\alpha,p)\\,\\nabla J(\\mathbf{m}).\n$$\n对于选定的步长 $\\tau  0$，定义周波跳跃风险度量，其值为单步内沿任一振荡方向引起的最大归一化相位变化，\n$$\nR(\\mathbf{d}; \\tau) \\;=\\; \\max_{1 \\le j \\le J} \\frac{\\big|\\,\\tau\\,\\omega_j\\,\\mathbf{k}_j^\\top \\mathbf{d}\\,\\big|}{\\pi}.\n$$\n如果 $R(\\mathbf{d}; \\tau) \\ge 1$，则该步骤存在周波跳跃风险。评估平滑前的 $R(\\mathbf{d}_0; \\tau)$ 和平滑后的 $R(\\mathbf{d}_\\alpha; \\tau)$。\n\n此外，通过计算与高曲率特征方向集对齐的梯度的平方振幅分数，来量化高曲率分量的选择性阻尼。设高曲率索引集 $\\mathcal{I}_{\\mathrm{high}}$ 为那些使得 $\\lambda_i$ 处于或高于 $\\{\\lambda_1,\\lambda_2,\\lambda_3\\}$ 第75百分位的索引 $i$。在Hessian矩阵的特征基中，设 $\\mathbf{c} = \\mathbf{Q}^\\top \\nabla J(\\mathbf{m})$ 和 $\\mathbf{c}' = \\mathrm{diag}\\big(s(\\lambda_i; \\alpha,p)\\big)\\,\\mathbf{c}$。定义\n$$\nF_{\\mathrm{high}}^{\\mathrm{before}} \\;=\\; \\frac{\\sum_{i \\in \\mathcal{I}_{\\mathrm{high}}} c_i^2}{\\sum_{i=1}^{3} c_i^2}, \\qquad\nF_{\\mathrm{high}}^{\\mathrm{after}} \\;=\\; \\frac{\\sum_{i \\in \\mathcal{I}_{\\mathrm{high}}} (c'_i)^2}{\\sum_{i=1}^{3} (c'_i)^2}.\n$$\n最后，通过Hessian矩阵在平滑前后的谱条件数（二范数）评估曲率条件：\n$$\n\\kappa(\\mathbf{H}) \\;=\\; \\frac{\\sigma_{\\max}(\\mathbf{H})}{\\sigma_{\\min}(\\mathbf{H})}, \\qquad\n\\kappa\\big(\\mathbf{S}(\\alpha,p)\\,\\mathbf{H}\\big) \\;=\\; \\frac{\\sigma_{\\max}\\big(\\mathbf{S}(\\alpha,p)\\,\\mathbf{H}\\big)}{\\sigma_{\\min}\\big(\\mathbf{S}(\\alpha,p)\\,\\mathbf{H}\\big)},\n$$\n其中 $\\sigma_{\\max}$ 和 $\\sigma_{\\min}$ 分别表示最大和最小奇异值。\n\n你的任务是实现一个程序，对于下述每个测试用例，该程序通过其特征值和给定的由三个轴向旋转构成的正交矩阵 Q 来构造 H，在提供的点 m0 处评估梯度，计算平滑前后的周波跳跃风险、高曲率能量分数，以及条件数 κ(H) 和 κ(S(α,p)H)。所有角度均使用弧度。每个测试用例的最终输出必须是包含七个浮点值的列表，按以下顺序排列：\n$$\n\\big[\\,R(\\mathbf{d}_0;\\tau),\\; R(\\mathbf{d}_\\alpha;\\tau),\\; R(\\mathbf{d}_\\alpha;\\tau)/R(\\mathbf{d}_0;\\tau),\\; F_{\\mathrm{high}}^{\\mathrm{before}},\\; F_{\\mathrm{high}}^{\\mathrm{after}},\\; \\kappa(\\mathbf{H}),\\; \\kappa\\big(\\mathbf{S}(\\alpha,p)\\,\\mathbf{H}\\big)\\,\\big],\n$$\n并四舍五入到六位小数。\n\n将 $\\mathbf{Q}$ 构造为 $\\mathbf{Q} = \\mathbf{R}_z(\\theta_z)\\,\\mathbf{R}_y(\\theta_y)\\,\\mathbf{R}_x(\\theta_x)$，其中 $\\mathbf{R}_z(\\cdot)$、$\\mathbf{R}_y(\\cdot)$ 和 $\\mathbf{R}_x(\\cdot)$ 是围绕z、y和x轴按给定角度（以弧度为单位）旋转的标准旋转矩阵。然后设置 $\\mathbf{H} = \\mathbf{Q}\\,\\mathrm{diag}(\\boldsymbol{\\lambda})\\,\\mathbf{Q}^\\top$。\n\n测试套件：\n\n- 案例1（正常路径）：\n    - $\\boldsymbol{\\lambda} = [1.0,\\,5.0,\\,25.0]$, $(\\theta_z,\\theta_y,\\theta_x) = (0.6,\\,-0.3,\\,0.8)$,\n    - $\\mathbf{m}_0 = [0.2,\\,-0.1,\\,0.15]$, $\\gamma = 0.8$, $\\alpha = 0.5$, $p = 1$, $\\tau = 0.5$,\n    - $J = 3$ 个振荡项，参数为 $(\\mathbf{k}_1,\\omega_1,\\phi_1) = ([1.0,\\,2.0,\\,0.5],\\,12.0,\\,0.3)$，$(\\mathbf{k}_2,\\omega_2,\\phi_2) = ([-1.5,\\,0.0,\\,1.0],\\,8.0,\\,-0.4)$，$(\\mathbf{k}_3,\\omega_3,\\phi_3) = ([0.0,\\,-1.0,\\,2.0],\\,15.0,\\,0.2)$。\n\n- 案例2（边界情况：近各向同性曲率，无平滑）：\n    - $\\boldsymbol{\\lambda} = [2.0,\\,2.5,\\,3.0]$, $(\\theta_z,\\theta_y,\\theta_x) = (0.2,\\,0.1,\\,-0.25)$,\n    - $\\mathbf{m}_0 = [-0.05,\\,0.1,\\,0.2]$, $\\gamma = 0.6$, $\\alpha = 0.0$, $p = 1$, $\\tau = 0.5$,\n    - $J = 2$ 个振荡项，参数为 $(\\mathbf{k}_1,\\omega_1,\\phi_1) = ([0.5,\\,-1.0,\\,1.5],\\,10.0,\\,0.1)$，$(\\mathbf{k}_2,\\omega_2,\\phi_2) = ([1.0,\\,0.5,\\,-0.5],\\,7.0,\\,0.0)$。\n\n- 案例3（边缘情况：强各向异性曲率，强阻尼高曲率方向）：\n    - $\\boldsymbol{\\lambda} = [0.5,\\,10.0,\\,50.0]$, $(\\theta_z,\\theta_y,\\theta_x) = (1.0,\\,-0.5,\\,0.3)$,\n    - $\\mathbf{m}_0 = [0.3,\\,-0.25,\\,0.05]$, $\\gamma = 1.0$, $\\alpha = 10.0$, $p = 2$, $\\tau = 0.3$,\n    - $J = 3$ 个振荡项，参数为 $(\\mathbf{k}_1,\\omega_1,\\phi_1) = ([2.0,\\,0.0,\\,-1.0],\\,20.0,\\,-0.2)$，$(\\mathbf{k}_2,\\omega_2,\\phi_2) = ([-0.5,\\,1.5,\\,0.5],\\,18.0,\\,0.5)$，$(\\mathbf{k}_3,\\omega_3,\\phi_3) = ([1.0,\\,-2.0,\\,1.0],\\,25.0,\\,-0.1)$。\n\n最终输出格式：\n\n你的程序应生成单行输出，包含一个由方括号括起来的逗号分隔列表形式的结果，按顺序汇总三个案例的结果，每个案例格式化为一个包含七个元素的列表，数字四舍五入到六位小数。例如，输出必须类似于\n$$\n[\\,[r_{1,1},r_{1,2},r_{1,3},r_{1,4},r_{1,5},r_{1,6},r_{1,7}],\\,[r_{2,1},\\dots,r_{2,7}],\\,[r_{3,1},\\dots,r_{3,7}]\\,].\n$$\n不应打印任何附加文本。", "solution": "在尝试任何解决方案之前，需对问题陈述进行验证。\n\n### 第1步：提取已知条件\n已知条件如下：\n- 模型参数向量：$\\mathbf{m} \\in \\mathbb{R}^3$。\n- Hessian矩阵：$\\mathbf{H} \\in \\mathbb{R}^{3 \\times 3}$，对称正定。\n- 合成失配函数：$J(\\mathbf{m}) = \\tfrac{1}{2}\\,\\mathbf{m}^\\top \\mathbf{H}\\,\\mathbf{m} \\;+\\; \\gamma \\sum_{j=1}^{J} \\sin\\!\\big(\\,\\omega_j\\,\\mathbf{k}_j^\\top \\mathbf{m} + \\phi_j\\,\\big)$。\n- 参数：标量振幅 $\\gamma$，标量角频率 $\\omega_j$，方向向量 $\\mathbf{k}_j \\in \\mathbb{R}^3$，标量相位偏移 $\\phi_j$。\n- Hessian矩阵特征值分解：$\\mathbf{H} = \\mathbf{Q}\\,\\mathrm{diag}(\\boldsymbol{\\lambda})\\,\\mathbf{Q}^\\top$，其中 $\\mathbf{Q}$ 是正交矩阵，$\\boldsymbol{\\lambda} = [\\lambda_1,\\lambda_2,\\lambda_3]^\\top$ 是正特征值。\n- 各向异性平滑阻尼函数：$s(\\lambda_i; \\alpha, p) = \\frac{1}{1 + \\alpha\\,\\lambda_i^{\\,p}}$，其中 $\\alpha \\ge 0, p \\ge 0$。\n- 各向异性平滑算子：$\\mathbf{S}(\\alpha,p) = \\mathbf{Q}\\,\\mathrm{diag}\\big(s(\\lambda_i; \\alpha,p)\\big)\\,\\mathbf{Q}^\\top$。\n- 失配梯度：$\\nabla J(\\mathbf{m}) = \\mathbf{H}\\,\\mathbf{m} \\;+\\; \\gamma \\sum_{j=1}^{J} \\omega_j \\cos\\!\\big(\\,\\omega_j\\,\\mathbf{k}_j^\\top \\mathbf{m} + \\phi_j\\,\\big)\\,\\mathbf{k}_j$。\n- 未平滑下降方向：$\\mathbf{d}_0 = -\\,\\nabla J(\\mathbf{m})$。\n- 平滑后下降方向：$\\mathbf{d}_\\alpha = -\\,\\mathbf{S}(\\alpha,p)\\,\\nabla J(\\mathbf{m})$。\n- 步长：$\\tau  0$。\n- 周波跳跃风险度量：$R(\\mathbf{d}; \\tau) = \\max_{1 \\le j \\le J} \\frac{\\big|\\,\\tau\\,\\omega_j\\,\\mathbf{k}_j^\\top \\mathbf{d}\\,\\big|}{\\pi}$。\n- 高曲率索引集 $\\mathcal{I}_{\\mathrm{high}}$：使 $\\lambda_i$ 处于或高于 $\\{\\lambda_1,\\lambda_2,\\lambda_3\\}$ 第75百分位的索引 $i$。\n- 高曲率能量分数：$F_{\\mathrm{high}}^{\\mathrm{before}} = \\frac{\\sum_{i \\in \\mathcal{I}_{\\mathrm{high}}} c_i^2}{\\sum_{i=1}^{3} c_i^2}$ 和 $F_{\\mathrm{high}}^{\\mathrm{after}} = \\frac{\\sum_{i \\in \\mathcal{I}_{\\mathrm{high}}} (c'_i)^2}{\\sum_{i=1}^{3} (c'_i)^2}$，其中 $\\mathbf{c} = \\mathbf{Q}^\\top \\nabla J(\\mathbf{m})$ 且 $\\mathbf{c}' = \\mathrm{diag}\\big(s(\\lambda_i; \\alpha,p)\\big)\\,\\mathbf{c}$。\n- 谱条件数：$\\kappa(\\mathbf{H}) = \\frac{\\sigma_{\\max}(\\mathbf{H})}{\\sigma_{\\min}(\\mathbf{H})}$ 和 $\\kappa\\big(\\mathbf{S}(\\alpha,p)\\,\\mathbf{H}\\big) = \\frac{\\sigma_{\\max}\\big(\\mathbf{S}(\\alpha,p)\\,\\mathbf{H}\\big)}{\\sigma_{\\min}\\big(\\mathbf{S}(\\alpha,p)\\,\\mathbf{H}\\big)}$。\n- Hessian矩阵构造：$\\mathbf{H} = \\mathbf{Q}\\,\\mathrm{diag}(\\boldsymbol{\\lambda})\\,\\mathbf{Q}^\\top$，其中 $\\mathbf{Q} = \\mathbf{R}_z(\\theta_z)\\,\\mathbf{R}_y(\\theta_y)\\,\\mathbf{R}_x(\\theta_x)$。应使用标准旋转矩阵。\n- 提供了三个包含所有必要数值的完整测试案例。\n- 要求输出一个列表，为每个测试案例包含七个特定的浮点值，并四舍五入到六位小数。\n\n### 第2步：使用提取的已知条件进行验证\n根据指定标准对问题进行评估：\n- **科学依据**：该问题是计算地球物理学中一个核心问题的简化模拟，特别是针对全波形反演的数值优化。Hessian矩阵、失配函数、梯度下降、周波跳跃和谱预处理（平滑）等概念都是标准的、数学上合理的。该问题遵循线性代数和多元微积分的基本原理。\n- **适定性**：该问题是确定性的和完整的。对于每个测试案例，所有参数和函数都已明确定义，从而得到一组唯一且可计算的结果。\n- **客观性**：该问题使用精确、无歧义的数学术语陈述。没有主观或基于意见的成分。\n- **缺陷检查**：该问题未表现出任何列出的无效性缺陷。它在数学上是合理的，与指定主题相关，是完整的，计算上可行的，并且结构良好。\n\n### 第3步：结论与行动\n问题被判定为**有效**。将开发一个解决方案。\n\n该解决方案要求为每个测试案例计算七个度量指标，分析谱定义的各向异性平滑算子对基于梯度的优化的影响。步骤如下。\n\n首先，为每个测试案例构建Hessian矩阵 $\\mathbf{H}$。正交矩阵 $\\mathbf{Q}$ 由三个标准旋转矩阵的乘积形成：\n$$ \\mathbf{R}_x(\\theta_x) = \\begin{pmatrix} 1  0  0 \\\\ 0  \\cos\\theta_x  -\\sin\\theta_x \\\\ 0  \\sin\\theta_x  \\cos\\theta_x \\end{pmatrix}, \\quad\n   \\mathbf{R}_y(\\theta_y) = \\begin{pmatrix} \\cos\\theta_y  0  \\sin\\theta_y \\\\ 0  1  0 \\\\ -\\sin\\theta_y  0  \\cos\\theta_y \\end{pmatrix}, \\quad\n   \\mathbf{R}_z(\\theta_z) = \\begin{pmatrix} \\cos\\theta_z  -\\sin\\theta_z  0 \\\\ \\sin\\theta_z  \\cos\\theta_z  0 \\\\ 0  0  1 \\end{pmatrix}. $$\n矩阵 $\\mathbf{Q}$ 则是 $\\mathbf{Q} = \\mathbf{R}_z(\\theta_z)\\,\\mathbf{R}_y(\\theta_y)\\,\\mathbf{R}_x(\\theta_x)$。Hessian矩阵通过其给定的特征值 $\\boldsymbol{\\lambda}$ 进行谱分解构造：$\\mathbf{H} = \\mathbf{Q}\\,\\mathrm{diag}(\\boldsymbol{\\lambda})\\,\\mathbf{Q}^\\top$。\n\n其次，我们计算失配函数在指定模型点 $\\mathbf{m}_0$ 处的梯度 $\\nabla J(\\mathbf{m})$。公式为：\n$$ \\nabla J(\\mathbf{m}_0) = \\mathbf{H}\\,\\mathbf{m}_0 + \\gamma \\sum_{j=1}^{J} \\omega_j \\cos\\big(\\,\\omega_j\\,\\mathbf{k}_j^\\top \\mathbf{m}_0 + \\phi_j\\,\\big)\\,\\mathbf{k}_j. $$\n该向量概括了失配函数局部最陡上升的方向。\n\n第三，我们确定未平滑和平滑后的下降方向。未平滑的方向就是负梯度，$\\mathbf{d}_0 = -\\nabla J(\\mathbf{m}_0)$。平滑后的方向 $\\mathbf{d}_\\alpha$ 需要平滑算子 $\\mathbf{S}(\\alpha, p)$。该算子在 $\\mathbf{H}$ 的特征基中定义。对每个特征值 $\\lambda_i$ 计算阻尼值 $s_i$：\n$$ s_i = s(\\lambda_i; \\alpha, p) = \\frac{1}{1 + \\alpha\\,\\lambda_i^{\\,p}}. $$\n算子为 $\\mathbf{S}(\\alpha, p) = \\mathbf{Q}\\,\\mathrm{diag}(s_1, s_2, s_3)\\,\\mathbf{Q}^\\top$。平滑后的方向则是 $\\mathbf{d}_\\alpha = -\\mathbf{S}(\\alpha, p)\\,\\nabla J(\\mathbf{m}_0)$。计算上，在特征基中应用平滑更高效：首先投影梯度 $\\mathbf{c} = \\mathbf{Q}^\\top \\nabla J(\\mathbf{m}_0)$，然后缩放分量 $c'_i = s_i c_i$，最后变换回去 $\\mathbf{d}_\\alpha = -\\mathbf{Q}\\,\\mathbf{c}'$。\n\n第四，我们评估两个方向的周波跳跃风险。使用度量定义，我们计算：\n$$ R(\\mathbf{d}_0; \\tau) = \\max_{j} \\frac{|\\tau\\,\\omega_j\\,\\mathbf{k}_j^\\top \\mathbf{d}_0|}{\\pi} \\quad \\text{和} \\quad R(\\mathbf{d}_\\alpha; \\tau) = \\max_{j} \\frac{|\\tau\\,\\omega_j\\,\\mathbf{k}_j^\\top \\mathbf{d}_\\alpha|}{\\pi}. $$\n也计算比率 $R(\\mathbf{d}_\\alpha; \\tau) / R(\\mathbf{d}_0; \\tau)$。\n\n第五，我们量化高曲率分量的阻尼情况。对于一个3元素集合，第75百分位分离出单个最大特征值 $\\lambda_{\\max}$。因此，$\\mathcal{I}_{\\mathrm{high}}$ 包含对应于 $\\lambda_{\\max}$ 的索引。特征基中的梯度分量 $\\mathbf{c} = \\mathbf{Q}^\\top \\nabla J(\\mathbf{m}_0)$ 及其平滑后的对应分量 $\\mathbf{c}'$（其中 $c'_i = s_i c_i$）用于计算能量分数：\n$$ F_{\\mathrm{high}}^{\\mathrm{before}} = \\frac{\\sum_{i \\in \\mathcal{I}_{\\mathrm{high}}} c_i^2}{\\sum_{i=1}^{3} c_i^2}, \\qquad F_{\\mathrm{high}}^{\\mathrm{after}} = \\frac{\\sum_{i \\in \\mathcal{I}_{\\mathrm{high}}} (c'_i)^2}{\\sum_{i=1}^{3} (c'_i)^2}. $$\n这些度量指标衡量了在平滑前后，高曲率特征方向对梯度总能量的相对贡献。\n\n第六，我们评估问题曲率的条件。计算Hessian矩阵 $\\mathbf{H}$ 的条件数。由于 $\\mathbf{H}$ 是对称正定的，其奇异值就是其特征值。因此，$\\kappa(\\mathbf{H}) = \\lambda_{\\max}/\\lambda_{\\min}$。然后我们考虑平滑后的Hessian矩阵 $\\mathbf{S}(\\alpha, p)\\mathbf{H}$。其谱分解为：\n$$ \\mathbf{S}\\mathbf{H} = \\left( \\mathbf{Q}\\,\\mathrm{diag}(s_i)\\,\\mathbf{Q}^\\top \\right) \\left( \\mathbf{Q}\\,\\mathrm{diag}(\\lambda_i)\\,\\mathbf{Q}^\\top \\right) = \\mathbf{Q}\\,\\mathrm{diag}(s_i \\lambda_i)\\,\\mathbf{Q}^\\top. $$\n$\\mathbf{S}\\mathbf{H}$ 的特征值是 $\\lambda'_i = s_i \\lambda_i = \\frac{\\lambda_i}{1 + \\alpha\\,\\lambda_i^{\\,p}}$。由于该矩阵也是对称的且其特征值 $\\lambda'_i$ 为正，其条件数是其最大与最小特征值之比：\n$$ \\kappa\\big(\\mathbf{S}(\\alpha,p)\\,\\mathbf{H}\\big) = \\frac{\\max_i(\\lambda'_i)}{\\min_i(\\lambda'_i)}. $$\n\n这六个步骤为每个测试案例提供了所有七个必需的输出值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to solve the problem for the given test cases.\n    It orchestrates the calculation for each case and prints the final result.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        {\n            \"lambda_vals\": np.array([1.0, 5.0, 25.0]),\n            \"angles\": (0.6, -0.3, 0.8), # (theta_z, theta_y, theta_x)\n            \"m0\": np.array([0.2, -0.1, 0.15]),\n            \"gamma\": 0.8, \"alpha\": 0.5, \"p\": 1.0, \"tau\": 0.5,\n            \"osc_terms\": [\n                {\"k\": np.array([1.0, 2.0, 0.5]), \"omega\": 12.0, \"phi\": 0.3},\n                {\"k\": np.array([-1.5, 0.0, 1.0]), \"omega\": 8.0, \"phi\": -0.4},\n                {\"k\": np.array([0.0, -1.0, 2.0]), \"omega\": 15.0, \"phi\": 0.2},\n            ]\n        },\n        {\n            \"lambda_vals\": np.array([2.0, 2.5, 3.0]),\n            \"angles\": (0.2, 0.1, -0.25),\n            \"m0\": np.array([-0.05, 0.1, 0.2]),\n            \"gamma\": 0.6, \"alpha\": 0.0, \"p\": 1.0, \"tau\": 0.5,\n            \"osc_terms\": [\n                {\"k\": np.array([0.5, -1.0, 1.5]), \"omega\": 10.0, \"phi\": 0.1},\n                {\"k\": np.array([1.0, 0.5, -0.5]), \"omega\": 7.0, \"phi\": 0.0},\n            ]\n        },\n        {\n            \"lambda_vals\": np.array([0.5, 10.0, 50.0]),\n            \"angles\": (1.0, -0.5, 0.3),\n            \"m0\": np.array([0.3, -0.25, 0.05]),\n            \"gamma\": 1.0, \"alpha\": 10.0, \"p\": 2.0, \"tau\": 0.3,\n            \"osc_terms\": [\n                {\"k\": np.array([2.0, 0.0, -1.0]), \"omega\": 20.0, \"phi\": -0.2},\n                {\"k\": np.array([-0.5, 1.5, 0.5]), \"omega\": 18.0, \"phi\": 0.5},\n                {\"k\": np.array([1.0, -2.0, 1.0]), \"omega\": 25.0, \"phi\": -0.1},\n            ]\n        }\n    ]\n\n    all_results = []\n    for params in test_cases:\n        results = process_case(params)\n        all_results.append(results)\n\n    # Format the final output string as specified.\n    # Convert results to list of lists of rounded floats, then format to string.\n    # The output format in the problem statement requires 6 decimal places.\n    # Using f-string formatting for this.\n    formatted_cases = []\n    for case_res in all_results:\n        formatted_vals = [f\"{val:.6f}\" for val in case_res]\n        formatted_cases.append(f\"[{','.join(formatted_vals)}]\")\n    \n    output_str = f\"[{','.join(formatted_cases)}]\"\n    print(output_str)\n\ndef process_case(params):\n    \"\"\"\n    Processes a single test case and returns the seven required metrics.\n    \"\"\"\n    lambda_vals = params[\"lambda_vals\"]\n    theta_z, theta_y, theta_x = params[\"angles\"]\n    m0 = params[\"m0\"]\n    gamma, alpha, p, tau = params[\"gamma\"], params[\"alpha\"], params[\"p\"], params[\"tau\"]\n    osc_terms = params[\"osc_terms\"]\n    \n    # --- Step 1: Construct Hessian H ---\n    cz, sz = np.cos(theta_z), np.sin(theta_z)\n    cy, sy = np.cos(theta_y), np.sin(theta_y)\n    cx, sx = np.cos(theta_x), np.sin(theta_x)\n    \n    Rz = np.array([[cz, -sz, 0], [sz, cz, 0], [0, 0, 1]])\n    Ry = np.array([[cy, 0, sy], [0, 1, 0], [-sy, 0, cy]])\n    Rx = np.array([[1, 0, 0], [0, cx, -sx], [0, sx, cx]])\n    \n    Q = Rz @ Ry @ Rx\n    Lambda_mat = np.diag(lambda_vals)\n    H = Q @ Lambda_mat @ Q.T\n    \n    # --- Step 2: Compute Gradient at m0 ---\n    # Quadratic part of the gradient\n    grad_J_quad = H @ m0\n    \n    # Oscillatory part of the gradient\n    grad_J_osc = np.zeros(3)\n    for term in osc_terms:\n        k, omega, phi = term[\"k\"], term[\"omega\"], term[\"phi\"]\n        arg = omega * k.T @ m0 + phi\n        grad_J_osc += omega * np.cos(arg) * k\n        \n    grad_J = grad_J_quad + gamma * grad_J_osc\n    \n    # --- Step 3  4: Compute Descent Directions ---\n    d0 = -grad_J\n    \n    s_vals = 1 / (1 + alpha * lambda_vals**p)\n    # Efficient application of S: project, scale, back-project\n    c = Q.T @ grad_J\n    c_prime = s_vals * c\n    d_alpha = -Q @ c_prime\n    \n    # --- Step 5: Evaluate Cycle-Skipping Risk R ---\n    risk_d0_vals = []\n    risk_d_alpha_vals = []\n    for term in osc_terms:\n        k, omega = term[\"k\"], term[\"omega\"]\n        risk_d0_vals.append(np.abs(tau * omega * k.T @ d0) / np.pi)\n        risk_d_alpha_vals.append(np.abs(tau * omega * k.T @ d_alpha) / np.pi)\n        \n    R_d0 = np.max(risk_d0_vals) if risk_d0_vals else 0.0\n    R_d_alpha = np.max(risk_d_alpha_vals) if risk_d_alpha_vals else 0.0\n    \n    # Ratio R_alpha / R_d0\n    # Add a small epsilon to avoid division by zero in unlikely cases\n    R_ratio = R_d_alpha / (R_d0 + 1e-12)\n\n    # --- Step 6: Analyze High-Curvature Damping F_high ---\n    # For 3 elements, 75th percentile means the largest one.\n    i_high = np.argmax(lambda_vals)\n\n    # Total squared norm of gradient in eigenbasis\n    c_sq_norm = np.sum(c**2)\n    # Total squared norm of smoothed gradient in eigenbasis\n    c_prime_sq_norm = np.sum(c_prime**2)\n\n    # Add epsilon to denominators to prevent division by zero if gradient is zero\n    F_high_before = c[i_high]**2 / (c_sq_norm + 1e-12)\n    F_high_after = c_prime[i_high]**2 / (c_prime_sq_norm + 1e-12)\n    \n    # --- Step 7: Assess Conditioning kappa ---\n    # Since H is SPD, singular values are eigenvalues.\n    kappa_H = np.max(lambda_vals) / np.min(lambda_vals)\n    \n    lambda_prime = lambda_vals / (1 + alpha * lambda_vals**p)\n    # Since S*H is SPD, its singular values are its eigenvalues\n    kappa_SH = np.max(lambda_prime) / np.min(lambda_prime)\n    \n    return [R_d0, R_d_alpha, R_ratio, F_high_before, F_high_after, kappa_H, kappa_SH]\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3587829"}, {"introduction": "奇异值分解（SVD）是特征值分解在矩形矩阵上的推广，在解决地球物理学中常见的矩阵分解问题时显示出巨大威力。本实践将探讨一个经典的盲源分离问题：在仅有多炮实验记录数据的情况下，我们能否将未知的震源子波与未知的地球响应分离开？您将运用SVD来寻找震源子波的最佳子空间，并探索实现这种分离所需的数学条件（秩条件）[@problem_id:3587840]。", "problem": "在计算地球物理学中，给定一个多炮数据模型，其中数据矩阵 $\\mathbf{D} \\in \\mathbb{R}^{m \\times n}$ 可分解为 $\\mathbf{D} = \\mathbf{S} \\mathbf{R}$。这里，$\\mathbf{S} \\in \\mathbb{R}^{m \\times r}$ 代表跨炮的共同震源子波子空间，而 $\\mathbf{R} \\in \\mathbb{R}^{r \\times n}$ 代表跨炮/检波器道集聚合的地球响应。$\\mathbf{D}$ 的列由数据块 $\\mathbf{D}_1, \\dots, \\mathbf{D}_K$ 水平拼接而成，其中 $\\mathbf{D}_k \\in \\mathbb{R}^{m \\times n_k}$ 且 $\\sum_{k=1}^K n_k = n$。数据块数量 $K$ 至少为 $2$，分解秩 $r$ 满足 $1 \\le r \\le \\min\\{m,n\\}$。您需要开发一种基于分块的奇异值分解（SVD）方法，该方法从 $\\mathbf{D}$ 中估计 $\\mathbf{S}$ 的列空间，然后重构一个相容的 $\\widehat{\\mathbf{R}}$，使得 $\\mathbf{D} \\approx \\widehat{\\mathbf{S}} \\widehat{\\mathbf{R}}$，其中 $\\widehat{\\mathbf{S}} \\in \\mathbb{R}^{m \\times \\widehat{r}}$ 具有标准正交列。该方法必须仅使用以下基本原理进行推导：(i) 矩阵秩的定义，(ii) 奇异值分解的定义，以及 (iii) 矩阵乘积的基本子空间关系。您必须基于这些原理论证您的方法为何能得到震源子空间的估计，并以 $\\mathbf{S}$ 和 $\\mathbf{R}$ 的秩来陈述其可辨识性条件。您还必须使用主角量化估计子空间的精度，并将这些角度以弧度表示。\n\n任务：\n- 基于这些基本原理，推导为何 $\\mathrm{col}(\\mathbf{D}) \\subseteq \\mathrm{col}(\\mathbf{S})$ 以及在何种秩条件下等式成立。利用这一点，论证一种通过水平拼接给定数据块形成 $\\mathbf{D}$ 并对其进行分块SVD处理，以估计 $\\mathrm{col}(\\mathbf{S})$ 的一个基 $\\widehat{\\mathbf{S}}$ 的过程。然后，在给定 $\\widehat{\\mathbf{S}}$ 的情况下，仅使用由基本原理证明合理的操作，构造一个相容的 $\\widehat{\\mathbf{R}}$ 满足 $\\mathbf{D} \\approx \\widehat{\\mathbf{S}} \\widehat{\\mathbf{R}}$。\n- 陈述保证分解在乘以一个 $r \\times r$ 的可逆矩阵下唯一的辨识性条件，并通过 $\\mathbf{S}$、$\\mathbf{R}$ 和 $\\mathbf{D}$ 的数值秩验证这些条件。使用基于奇异值的数值合理阈值来确定秩。\n- 通过 $\\mathrm{col}(\\mathbf{S})$ 和 $\\mathrm{col}(\\widehat{\\mathbf{S}})$ 之间的最大主角量化子空间估计的质量，并以弧度表示。\n\n程序要求：\n- 实现一个程序，构建四个合成测试用例（如下文的测试套件），按上述方法计算 $\\widehat{\\mathbf{S}}$ 和 $\\widehat{\\mathbf{R}}$，根据推导的秩条件判断可辨识性，并为每个测试用例报告一个标量值，规则如下：如果满足可辨识性条件，则报告 $\\mathrm{col}(\\mathbf{S})$ 和 $\\mathrm{col}(\\widehat{\\mathbf{S}})$ 之间的最大主角（以弧度为单位）；如果不满足可辨识性条件，则报告哨兵值 $-1.0$。角度必须以弧度为单位。\n- 程序必须仅使用 Python 标准库、Numerical Python (NumPy) 和 Scientific Python (SciPy)，不得读取任何输入，并且必须产生仅一行输出：一个包含四个标量结果的列表，按顺序排列，格式为方括号内的逗号分隔列表，无附加文本，例如 $[\\alpha_1,\\alpha_2,\\alpha_3,\\alpha_4]$，其中每个 $\\alpha_i$ 是一个浮点数。\n\n测试套件：\n- 情况 A（良态，可辨识）：$m = 60$, $r = 5$, $K = 3$, $(n_1,n_2,n_3) = (50,40,30)$，其中 $\\mathbf{S}$ 和 $\\mathbf{R}$ 由独立的标准正态分布条目生成。使用种子 $101$ 以确保可复现性。\n- 情况 B（$\\mathbf{R}$ 行秩亏损，不可辨识）：与情况 A 维度相同，但强制 $\\mathbf{R}$ 的最后一行完全为零，从而导致 $\\mathrm{rank}(\\mathbf{R})  r$。使用种子 $202$ 以确保可复现性。\n- 情况 C（$\\mathbf{S}$ 列秩亏损，不可辨识）：与情况 A 维度相同，但强制 $\\mathbf{S}$ 的最后一列是另两列的固定线性组合（例如，前两列之和乘以一个非零标量），从而导致 $\\mathrm{rank}(\\mathbf{S})  r$。使用种子 $303$ 以确保可复现性。\n- 情况 D（病态但可辨识）：与情况 A 维度相同，但将 $\\mathbf{R}$ 的某一行乘以一个小的正因子（例如 $10^{-6}$）但不使其为零，因此 $\\mathrm{rank}(\\mathbf{R}) = r$ 但分解是病态的。使用种子 $404$ 以确保可复现性。\n\n最终输出：\n- 您的程序应产生一行输出，包含一个以方括号括起来的逗号分隔列表形式的结果，顺序为 [情况 A, 情况 B, 情况 C, 情况 D]。对于每种情况，如果可辨识，则输出最大主角（以弧度为单位），否则输出 $-1.0$。角度单位必须是弧度。此任务不涉及物理单位。", "solution": "本问题要求推导并实现一种方法，用于从遵循分解模型 $\\mathbf{D} = \\mathbf{S} \\mathbf{R}$ 的数据矩阵 $\\mathbf{D} \\in \\mathbb{R}^{m \\times n}$ 中估计源矩阵 $\\mathbf{S} \\in \\mathbb{R}^{m \\times r}$ 的列空间，其中 $\\mathbf{R} \\in \\mathbb{R}^{r \\times n}$。推导过程必须基于线性代数的基本原理。\n\n### 子空间估计算法的推导\n\n#### 子空间关系\n估计算法的核心在于数据矩阵 $\\mathbf{D}$ 的列空间（记为 $\\mathrm{col}(\\mathbf{D})$）与源矩阵 $\\mathbf{S}$ 的列空间（记为 $\\mathrm{col}(\\mathbf{S})$）之间的关系。分解形式为 $\\mathbf{D} = \\mathbf{S} \\mathbf{R}$。设 $\\mathbf{d}_j$ 为 $\\mathbf{D}$ 的第 $j$ 列，$\\mathbf{r}_j$ 为 $\\mathbf{R}$ 的第 $j$ 列。矩阵乘积可以按列表示为：\n$$\n\\mathbf{d}_j = \\mathbf{S} \\mathbf{r}_j\n$$\n对于 $j = 1, 2, \\dots, n$。根据矩阵向量乘积的定义，$\\mathbf{S} \\mathbf{r}_j$ 是 $\\mathbf{S}$ 各列的线性组合，其系数由 $\\mathbf{r}_j$ 的元素给出。因此，数据矩阵 $\\mathbf{D}$ 的每一列 $\\mathbf{d}_j$ 都是 $\\mathbf{S}$ 列空间中的一个元素。这意味着由 $\\mathbf{D}$ 的所有列张成的空间必然是 $\\mathbf{S}$ 的所有列张成的空间的子空间。形式上，\n$$\n\\mathrm{col}(\\mathbf{D}) \\subseteq \\mathrm{col}(\\mathbf{S})\n$$\n这个关系是基础性的，对任何矩阵 $\\mathbf{S}$ 和 $\\mathbf{R}$ 都成立。$\\mathbf{D}$ 作为拼接矩阵 $\\mathbf{D} = [\\mathbf{D}_1 | \\dots | \\mathbf{D}_K]$ 的分块结构并不改变这一事实，因为 $\\mathbf{D}$ 的所有列，无论其源于哪个块，都位于 $\\mathrm{col}(\\mathbf{S})$ 中。\n\n要使列空间相等，即 $\\mathrm{col}(\\mathbf{D}) = \\mathrm{col}(\\mathbf{S})$，除了子集关系成立外，它们的维度必须相等。列空间的维度是矩阵的秩。因此，我们要求：\n$$\n\\mathrm{rank}(\\mathbf{D}) = \\mathrm{rank}(\\mathbf{S})\n$$\n根据矩阵秩的性质，我们知道对于乘积 $\\mathbf{D} = \\mathbf{S} \\mathbf{R}$，其秩有上界 $\\mathrm{rank}(\\mathbf{D}) \\le \\min(\\mathrm{rank}(\\mathbf{S}), \\mathrm{rank}(\\mathbf{R}))$。如果我们假设分解是非退化的，即 $\\mathbf{S}$ 和 $\\mathbf{R}$ 均为满秩，即 $\\mathrm{rank}(\\mathbf{S}) = r$ 和 $\\mathrm{rank}(\\mathbf{R}) = r$（这要求 $r \\le m$ 和 $r \\le n$），那么西尔维斯特秩不等式给出了一个下界：$\\mathrm{rank}(\\mathbf{D}) \\ge \\mathrm{rank}(\\mathbf{S}) + \\mathrm{rank}(\\mathbf{R}) - r = r + r - r = r$。结合上界和下界，我们得到 $r \\le \\mathrm{rank}(\\mathbf{D}) \\le r$，这意味着 $\\mathrm{rank}(\\mathbf{D}) = r$。\n在这些条件下，$\\mathrm{rank}(\\mathbf{D}) = r$ 且 $\\mathrm{rank}(\\mathbf{S}) = r$，因此它们的维度相等。这一点，再加上 $\\mathrm{col}(\\mathbf{D}) \\subseteq \\mathrm{col}(\\mathbf{S})$，证明了 $\\mathrm{col}(\\mathbf{D}) = \\mathrm{col}(\\mathbf{S})$。\n\n#### 使用奇异值分解（SVD）进行估计\n在满秩条件下，$\\mathrm{col}(\\mathbf{D}) = \\mathrm{col}(\\mathbf{S})$ 这一等式为使用 $\\mathbf{D}$ 估计 $\\mathrm{col}(\\mathbf{S})$ 提供了理论依据。奇异值分解（SVD）是提取矩阵列空间标准正交基的标准工具。$\\mathbf{D}$ 的 SVD 分解为：\n$$\n\\mathbf{D} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^T\n$$\n其中 $\\mathbf{U} \\in \\mathbb{R}^{m \\times m}$ 和 $\\mathbf{V} \\in \\mathbb{R}^{n \\times n}$ 是正交矩阵，$\\mathbf{\\Sigma} \\in \\mathbb{R}^{m \\times n}$ 是一个奇异值构成的矩形对角矩阵。$\\mathbf{U}$ 的前 $\\mathrm{rank}(\\mathbf{D})$ 列构成了 $\\mathrm{col}(\\mathbf{D})$ 的一个标准正交基。\n鉴于在可辨识条件下我们期望 $\\mathrm{rank}(\\mathbf{D}) = r$，我们可以通过取 $\\mathbf{U}$ 的前 $r$ 列来估计 $\\mathrm{col}(\\mathbf{S})$ 的一个标准正交基。设这个估计基为 $\\widehat{\\mathbf{S}} \\in \\mathbb{R}^{m \\times r}$。\n$$\n\\widehat{\\mathbf{S}} = \\mathbf{U}_{:, 1:r}\n$$\n矩阵 $\\widehat{\\mathbf{S}}$ 的列是标准正交的，其列空间 $\\mathrm{col}(\\widehat{\\mathbf{S}})$ 是 $\\mathrm{col}(\\mathbf{D})$ 的最佳秩-$r$ 近似，也即我们对 $\\mathrm{col}(\\mathbf{S})$ 的估计。问题要求开发一种“基于分块的SVD方法”；通过拼接其块 $\\mathbf{D}_k$ 来形成矩阵 $\\mathbf{D}$，然后应用SVD，是由上述子空间关系所证明的最直接且有原则的方法。\n\n#### 响应矩阵估计 $\\widehat{\\mathbf{R}}$ 的构造\n给定估计的震源基 $\\widehat{\\mathbf{S}}$，我们寻求一个相容的响应矩阵 $\\widehat{\\mathbf{R}}$，使得 $\\mathbf{D} \\approx \\widehat{\\mathbf{S}} \\widehat{\\mathbf{R}}$。对于 $\\widehat{\\mathbf{R}}$ 的每一列，这都是一个线性最小二乘问题。由于 $\\widehat{\\mathbf{S}}$ 的列是标准正交的，我们有 $\\widehat{\\mathbf{S}}^T \\widehat{\\mathbf{S}} = \\mathbf{I}_r$，其中 $\\mathbf{I}_r$ 是 $r \\times r$ 的单位矩阵。从左侧将近似式乘以 $\\widehat{\\mathbf{S}}^T$ 得到：\n$$\n\\widehat{\\mathbf{S}}^T \\mathbf{D} \\approx \\widehat{\\mathbf{S}}^T (\\widehat{\\mathbf{S}} \\widehat{\\mathbf{R}}) = (\\widehat{\\mathbf{S}}^T \\widehat{\\mathbf{S}}) \\widehat{\\mathbf{R}} = \\mathbf{I}_r \\widehat{\\mathbf{R}} = \\widehat{\\mathbf{R}}\n$$\n因此，响应矩阵的估计为：\n$$\n\\widehat{\\mathbf{R}} = \\widehat{\\mathbf{S}}^T \\mathbf{D}\n$$\n乘积 $\\widehat{\\mathbf{S}}\\widehat{\\mathbf{R}} = \\widehat{\\mathbf{S}}\\widehat{\\mathbf{S}}^T\\mathbf{D}$ 表示 $\\mathbf{D}$ 在由 $\\widehat{\\mathbf{S}}$ 张成的子空间上的正交投影，这正是 Eckart-Young-Mirsky 定理所给出的 $\\mathbf{D}$ 的最佳秩-$r$ 近似。\n\n### 可辨识性条件\n分解 $\\mathbf{D} = \\mathbf{S} \\mathbf{R}$ 本质上是非唯一的。对于任意可逆矩阵 $\\mathbf{A} \\in \\mathbb{R}^{r \\times r}$，我们可以定义 $\\mathbf{S}' = \\mathbf{S} \\mathbf{A}$ 和 $\\mathbf{R}' = \\mathbf{A}^{-1} \\mathbf{R}$。那么 $\\mathbf{S}' \\mathbf{R}' = (\\mathbf{S} \\mathbf{A}) (\\mathbf{A}^{-1} \\mathbf{R}) = \\mathbf{S} (\\mathbf{A} \\mathbf{A}^{-1}) \\mathbf{R} = \\mathbf{S} \\mathbf{I} \\mathbf{R} = \\mathbf{S} \\mathbf{R} = \\mathbf{D}$。这个新的分解仅基于 $\\mathbf{D}$ 是无法与原始分解区分的。然而，列空间得以保持：$\\mathrm{col}(\\mathbf{S}') = \\mathrm{col}(\\mathbf{S} \\mathbf{A}) = \\mathrm{col}(\\mathbf{S})$，因为 $\\mathbf{A}$ 是可逆的。\n因此，可辨识性问题简化为是否能从 $\\mathbf{D}$ 唯一确定 $\\mathrm{col}(\\mathbf{S})$。如前所述，这要求 $\\mathrm{col}(\\mathbf{D}) = \\mathrm{col}(\\mathbf{S})$。此等式成立的条件是：\n1.  $\\mathrm{rank}(\\mathbf{S}) = r$：这确保源矩阵 $\\mathbf{S}$ 为一个 $r$ 维子空间提供了 $r$ 个向量的基，没有冗余。如果 $\\mathrm{rank}(\\mathbf{S})  r$，则分解秩实际上不是 $r$。\n2.  $\\mathrm{rank}(\\mathbf{R}) = r$：这确保响应矩阵 $\\mathbf{R}$ 将 $r$ 维空间 $\\mathrm{col}(\\mathbf{S})$ 映射到 $\\mathbb{R}^m$ 的一个 $r$ 维子空间，即 $\\mathrm{col}(\\mathbf{D})$。如果 $\\mathrm{rank}(\\mathbf{R})  r$，那么 $\\mathrm{rank}(\\mathbf{D}) \\le \\mathrm{rank}(\\mathbf{R})  r$。假设 $\\mathrm{rank}(\\mathbf{S})=r$，这将意味着 $\\mathrm{rank}(\\mathbf{D})  \\mathrm{rank}(\\mathbf{S})$，且 $\\mathrm{col}(\\mathbf{D})$ 将是 $\\mathrm{col}(\\mathbf{S})$ 的一个真子空间，从而无法从 $\\mathbf{D}$ 中恢复出完整的 $\\mathrm{col}(\\mathbf{S})$ 空间。\n\n因此，（对于子空间 $\\mathrm{col}(\\mathbf{S})$ 的）可辨识性条件是 $\\mathrm{rank}(\\mathbf{S}) = r$ 和 $\\mathrm{rank}(\\mathbf{R}) = r$。这些条件将通过计算矩阵 $\\mathbf{S}$ 和 $\\mathbf{R}$ 的秩来数值检验，即统计超过数值稳定阈值的奇异值数量。\n\n### 子空间估计质量的量化\n估计子空间 $\\mathrm{col}(\\widehat{\\mathbf{S}})$ 相对于真实子空间 $\\mathrm{col}(\\mathbf{S})$ 的精度可以使用主角来量化。设 $\\mathcal{U} = \\mathrm{col}(\\mathbf{S})$ 和 $\\mathcal{V} = \\mathrm{col}(\\widehat{\\mathbf{S}})$ 是 $\\mathbb{R}^m$ 中的两个 $r$ 维子空间。设 $\\mathbf{Q_S}$ 和 $\\mathbf{Q}_{\\widehat{S}}$ 是其列分别为 $\\mathcal{U}$ 和 $\\mathcal{V}$ 构成标准正交基的矩阵。$\\mathcal{U}$ 和 $\\mathcal{V}$ 之间的主角 $\\{\\theta_k\\}_{k=1}^r$ 通过其余弦定义，这些余弦值是矩阵乘积 $\\mathbf{Q_S}^T \\mathbf{Q}_{\\widehat{S}}$ 的奇异值：\n$$\n\\cos(\\theta_k) = \\sigma_k(\\mathbf{Q_S}^T \\mathbf{Q}_{\\widehat{S}})\n$$\n这些奇异值 $\\sigma_k$ 总是在区间 $[0, 1]$ 内。角度 $\\theta_k=0$ 对应于基向量的完美对齐，而 $\\theta_k=\\pi/2$ 表示正交。最大主角 $\\theta_{\\max} = \\max_k \\theta_k$ 代表两个子空间之间的最大偏差，可作为一种最坏情况下的误差度量。它由最小的奇异值计算得出：\n$$\n\\theta_{\\max} = \\arccos\\left(\\min_k \\sigma_k(\\mathbf{Q_S}^T \\mathbf{Q}_{\\widehat{S}})\\right)\n$$\n在我们的实现中，真实子空间 $\\mathrm{col}(\\mathbf{S})$ 的标准正交基 $\\mathbf{Q_S}$ 从其QR分解中获得。估计的基 $\\widehat{\\mathbf{S}}$ 通过 $\\mathbf{D}$ 的 SVD 构造，其本身已经是标准正交的。主角将以弧度计算。", "answer": "```python\nimport numpy as np\nfrom scipy import linalg\n\ndef solve():\n    \"\"\"\n    Main function to execute the required analysis for all test cases.\n    It derives and applies a block-based SVD method to estimate a source subspace,\n    checks for identifiability, and quantifies the estimation error using principal angles.\n    \"\"\"\n\n    def create_case(seed, m, r, n_vec, s_mod=None, r_mod=None):\n        \"\"\"\n        Generates matrices S, R, and D for a given test case.\n        \"\"\"\n        rng = np.random.default_rng(seed)\n        n = sum(n_vec)\n\n        # Generate base matrices with independent standard normal entries\n        S = rng.standard_normal(size=(m, r))\n        R = rng.standard_normal(size=(r, n))\n\n        # Apply modifications for specific test cases\n        if s_mod:\n            S = s_mod(S)\n        if r_mod:\n            R = r_mod(R)\n            \n        return S, R\n\n    def analyze_case(S_true, R_true, r_true):\n        \"\"\"\n        Analyzes a single case: checks identifiability and computes the principal angle.\n        \"\"\"\n        # 1. Check identifiability conditions\n        # The conditions are rank(S) = r and rank(R) = r.\n        # We use numpy's numerical rank calculation.\n        rank_S = np.linalg.matrix_rank(S_true)\n        rank_R = np.linalg.matrix_rank(R_true)\n\n        if rank_S != r_true or rank_R != r_true:\n            return -1.0\n\n        # 2. If identifiable, proceed with estimation\n        # Form the data matrix D\n        D = S_true @ R_true\n\n        # Estimate the source subspace col(S) from D.\n        # This is done by finding an orthonormal basis for col(D).\n        # We use SVD of D: D = U @ Sigma @ Vh.\n        # The first r columns of U form the estimated basis S_hat.\n        # Using full_matrices=False is generally efficient.\n        U, _, _ = np.linalg.svd(D, full_matrices=False)\n        S_hat = U[:, :r_true]\n\n        # 3. Quantify estimation quality using the largest principal angle.\n        # The principal angles are computed between col(S_true) and col(S_hat).\n        # scipy.linalg.subspace_angles handles the calculation, including\n        # internal orthonormalization if needed.\n        # Angles are returned in radians, sorted in ascending order.\n        # We need the largest one, which is the last element.\n        angles = linalg.subspace_angles(S_true, S_hat)\n        largest_angle = angles[-1]\n        \n        return largest_angle\n\n    # --- Test Suite Definition ---\n    m_val = 60\n    r_val = 5\n    n_k_vals = (50, 40, 30)\n\n    test_cases = [\n        {\n            \"name\": \"Case A (well-conditioned, identifiable)\",\n            \"seed\": 101, \"m\": m_val, \"r\": r_val, \"n_vec\": n_k_vals,\n            \"s_mod\": None,\n            \"r_mod\": None\n        },\n        {\n            \"name\": \"Case B (row-rank deficiency in R, not identifiable)\",\n            \"seed\": 202, \"m\": m_val, \"r\": r_val, \"n_vec\": n_k_vals,\n            \"s_mod\": None,\n            \"r_mod\": lambda R: np.vstack([R[:-1, :], np.zeros((1, R.shape[1]))])\n        },\n        {\n            \"name\": \"Case C (column-rank deficiency in S, not identifiable)\",\n            \"seed\": 303, \"m\": m_val, \"r\": r_val, \"n_vec\": n_k_vals,\n            \"s_mod\": lambda S: np.hstack([S[:, :-1], 0.5 * (S[:, 0] + S[:, 1]).reshape(-1, 1)]),\n            \"r_mod\": None\n        },\n        {\n            \"name\": \"Case D (ill-conditioned but identifiable)\",\n            \"seed\": 404, \"m\": m_val, \"r\": r_val, \"n_vec\": n_k_vals,\n            \"s_mod\": None,\n            \"r_mod\": lambda R: np.vstack([R[:-1, :], R[-1, :] * 1e-6])\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        S_true, R_true = create_case(\n            case[\"seed\"], case[\"m\"], case[\"r\"], case[\"n_vec\"],\n            s_mod=case[\"s_mod\"], r_mod=case[\"r_mod\"]\n        )\n        result = analyze_case(S_true, R_true, case[\"r\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{res:.10f}' for res in results)}]\")\n\nsolve()\n```", "id": "3587840"}]}