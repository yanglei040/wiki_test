## 引言
在现代科学研究中，尤其是在高能物理等前沿领域，从充满噪声的数据中提取可靠的结论是核心挑战。统计推断为此提供了关键的理论框架，但其内部存在两大思想流派：贝叶斯学派与频率派。这两种学派源于对“概率”本质的不同哲学诠释，从而发展出了一系列在方法论、实践和结果解读上均有差异的工具。理解这两种方法的内在逻辑、适用边界以及它们之间的联系与区别，对于任何希望严谨地进行数据分析的科研人员都至关重要。

本文旨在系统性地梳理和比较贝叶斯与频率派[统计推断](@entry_id:172747)。我们将首先在“原理与机制”一章中，深入探讨两种[范式](@entry_id:161181)的哲学基础、核心数学原理（如[似然](@entry_id:167119)原理、[贝叶斯定理](@entry_id:151040)、极大[似然](@entry_id:167119)估计），以及处理[讨厌参数](@entry_id:171802)和进行假设检验等关键技术环节的差异。接着，在“应用与跨学科联系”一章中，我们将展示这些理论如何在真实世界的科学问题中发挥作用，重点剖析其在高能物理信号发现、上限设定及处理系统不确定性等方面的应用，并将其延伸至其他相关学科。最后，通过“动手实践”部分提供的一系列具体问题，读者将有机会亲手应用所学知识，巩固对两种统计推断[范式](@entry_id:161181)的理解与运用能力。

## 原理与机制

本章深入探讨贝叶斯与频率派统计推断的核心原理与机制。在前一章介绍背景之后，我们现在直接进入两种思想流派的形式化定义、实际应用，以及它们在高能物理（High-Energy Physics, HEP）分析中的细微差别。本章的目标是提供一个严谨的框架，使读者能够理解和运用这些方法，并批判性地评估它们在特定科学情境下的适用性。

### 哲学基础与核心概念

[统计推断](@entry_id:172747)的核心在于如何量化不确定性，而贝叶斯学派和频率派的根本分歧源于对**概率**本身的不同诠释。

#### 概率的双重诠释

在频率派的框架中，概率被定义为在相同的条件下进行大量重复实验时，某一结果出现的**长期相对频率**。这是一个客观的属性，依附于数据生成过程本身。因此，模型参数，如一个新粒子的质量或耦合强度（在此用 $\theta$ 表示），被视为一个固定的、未知的常数。我们不能对 $\theta$ 本身赋予[概率分布](@entry_id:146404)，因为它不是一个[随机变量](@entry_id:195330)。频率派的概率陈述是关于在给定 $\theta$ 的情况下数据的行为，形式为 $P(\text{数据} \mid \theta)$。例如，在一个对撞机计数实验中，频率派概率量化的是，在假设真实参数为 $\theta$ 的情况下，通过重复实验将观察到特定事件数 $N=n$ 的频率 [@problem_id:3506252]。

相比之下，贝叶斯学派将概率诠释为对一个命题真实性的**[置信度](@entry_id:267904)（degree of belief）**。这是一种主观或逻辑上的量化，代表了基于现有信息对不确定性的度量。在这种观点下，未知参数 $\theta$ 自然地被赋予[概率分布](@entry_id:146404)，因为它正是我们不确定且希望了解的对象。这个[分布](@entry_id:182848)，称为**先验分布** $\pi(\theta)$，编码了我们在观测数据之前对 $\theta$ 的所有了解或假设。在观测到数据后，我们使用**贝叶斯定理**来更新我们的置信度，得到**[后验分布](@entry_id:145605)** $p(\theta \mid \text{数据})$。后验分布集中体现了数据和[先验信息](@entry_id:753750)结合后关于 $\theta$ 的全部知识 [@problem_id:3506252]。

[贝叶斯更新](@entry_id:179010)的核心方程为：
$$
p(\theta \mid \text{数据}) = \frac{p(\text{数据} \mid \theta) \pi(\theta)}{\int p(\text{数据} \mid \theta') \pi(\theta') d\theta'} \propto p(\text{数据} \mid \theta) \pi(\theta)
$$
这里的 $p(\text{数据} \mid \theta)$ 被视为 $\theta$ 的函数时，被称为**似然函数**（Likelihood Function），通常记作 $L(\theta; \text{数据})$。

#### 似然函数与[似然](@entry_id:167119)原理

尽管两种学派对概率的看法不同，但**似然函数** $L(\theta; \text{数据})$ 在两者中都扮演着连接数据与参数的关键角色。它量化了在不同参数值 $\theta$ 下，观测到当前这份特定数据的可能性。

这一中心角色引出了**[似然](@entry_id:167119)原理**（Likelihood Principle）。该原理指出，对于给定的观测数据，关于未知参数 $\theta$ 的所有证据都已完全包含在[似然函数](@entry_id:141927)中。更进一步，如果两个不同的实验产生了正比的似然函数（即 $L_1(\theta) \propto L_2(\theta)$），那么这两个实验对于 $\theta$ 提供的推断证据是相同的，我们应该从中得出相同的结论 [@problem_id:3506252]。

贝叶斯推断天然地遵循[似然](@entry_id:167119)原理，因为[贝叶斯更新](@entry_id:179010)完全通过[似然函数](@entry_id:141927)进行。后验分布仅依赖于[先验分布](@entry_id:141376)和[似然函数](@entry_id:141927)的乘积，因此，只要似然函数成比例，对于给定的先验，后验推断也将是相同的。

然而，许多频率派方法却可能违反[似然](@entry_id:167119)原理。一个经典的例子是比较两种实验设计 [@problem_id:3506252]：
1.  **固定曝光设计**：在一个预定的积分光度 $L$ 下，记录观测到的事件数 $N$。在这里，$N$ 是一个服从泊松分布的[随机变量](@entry_id:195330)，$P(N=n \mid \theta) = \frac{(\lambda(\theta)L)^n e^{-\lambda(\theta)L}}{n!}$，其中 $\lambda(\theta)$ 是依赖于参数 $\theta$ 的事件率。
2.  **序贯设计**：持续增加积分光度，直到观测到预定的事件数 $N$ 为止，然后记录此时所需的积分光度 $L$。在这里，$L$ 是一个服从伽马[分布](@entry_id:182848)的[随机变量](@entry_id:195330)。

假设两个实验最终都观测到了相同的结果，即在积分光度 $L$ 下观测到了 $N$ 个事件。对于固定曝光设计，似然函数是 $L_1(\theta; N, L) \propto (\lambda(\theta))^N e^{-\lambda(\theta)L}$。对于序贯设计，[似然函数](@entry_id:141927)是 $L_2(\theta; N, L) \propto (\lambda(\theta))^N e^{-\lambda(\theta)L}$。可以看出，这两个似然函数作为 $\theta$ 的函数是成正比的。

根据[似然](@entry_id:167119)原理，我们应该从这两个实验中得到关于 $\theta$ 的相同推断。然而，一个标准的频率派方法，如构造**奈曼[置信区间](@entry_id:142297)**（Neyman confidence interval），依赖于对*未观测到*的数据进行积分或求和（即计算尾部概率）。由于两种设计下的[抽样分布](@entry_id:269683)（一个是关于 $N$ 的泊松分布，另一个是关于 $L$ 的伽马[分布](@entry_id:182848)）完全不同，计算出的置信区间通常也会不同。这种对实验“意图”（即采样计划）的依赖，而不是仅仅依赖于观测到的数据所产生的[似然函数](@entry_id:141927)，构成了对[似然](@entry_id:167119)原理的违反 [@problem_id:3506252]。

### 构建模型与估计参数

在[高能物理](@entry_id:181260)实践中，我们首先需要构建一个描述数据生成过程的统计模型。然后，利用这个模型从数据中估计我们关心的物理参数。

#### 频率派方法：极大似然估计

在频率派框架中，最核心的参数估计方法是**极大[似然](@entry_id:167119)估计**（Maximum Likelihood Estimation, MLE）。其原理非常直观：选择能使观测到的数据出现的概率最大的那个参数值作为其估计值。

一个在HEP中无处不在的例子是**扩展非[分箱](@entry_id:264748)极大[似然](@entry_id:167119)拟合**（extended unbinned maximum likelihood fit）。假设我们在一组[不变质量](@entry_id:265871)数据 $\{x_i\}_{i=1}^n$ 中寻找一个共振峰。我们用一个包含信号和背景的模型来描述这些数据 [@problem_id:3506229]。

模型假设如下：
- 总事件数 $n$ 服从泊松分布，其均值 $\mu = s+b$ 是未知的信号产额 $s$ 和背景产额 $b$ 之和。
- 每个事件的质量 $x_i$ 服从一个混合[概率密度函数](@entry_id:140610)（PDF）：$g(x \mid s,b) = \frac{s}{s+b} f_s(x) + \frac{b}{s+b} f_b(x)$。其中 $f_s(x)$ 和 $f_b(x)$ 分别是信号和背景的归一化形状模板（例如，从蒙特卡洛模拟中得到）。

[联合概率](@entry_id:266356)，也就是似然函数，是观测到 $n$ 个事件 *并且* 这些事件具有特定质量 $\{x_i\}$ 的概率。它等于泊松概率乘以所有事件的[条件概率密度](@entry_id:265457)：
$$
L(s,b) = P(n \mid s,b) \times \prod_{i=1}^n g(x_i \mid s,b) = \frac{(s+b)^n e^{-(s+b)}}{n!} \prod_{i=1}^n \left( \frac{s f_s(x_i) + b f_b(x_i)}{s+b} \right)
$$
通过代数化简，分母中的 $(s+b)^n$ 项被消掉，得到一个更简洁的形式：
$$
L(s,b) = \frac{e^{-(s+b)}}{n!} \prod_{i=1}^n \left[ s f_s(x_i) + b f_b(x_i) \right]
$$
为了便于计算，我们通常最大化**[对数似然函数](@entry_id:168593)** $\ell(s,b) = \ln L(s,b)$。忽略不依赖于参数 $s$ 和 $b$ 的常数项 $- \ln(n!)$，我们得到：
$$
\ell(s,b) = -(s+b) + \sum_{i=1}^n \ln \left[ s f_s(x_i) + b f_b(x_i) \right]
$$
极大似然估计值 $(\hat{s}, \hat{b})$ 就是使 $\ell(s,b)$ 最大化的解，通过求解**得分方程**（score equations）$\frac{\partial\ell}{\partial s}=0$ 和 $\frac{\partial\ell}{\partial b}=0$ 得到。这些方程可以被重写成一组有趣的[自洽方程](@entry_id:155949) [@problem_id:3506229]：
$$
\hat{s} = \sum_{i=1}^n w_i(\hat{s},\hat{b}) \quad \text{and} \quad \hat{b} = \sum_{i=1}^n \left[ 1 - w_i(\hat{s},\hat{b}) \right]
$$
其中 $w_i(s,b) = \frac{s f_s(x_i)}{s f_s(x_i) + b f_b(x_i)}$ 可以被解释为第 $i$ 个事件是信号的概率。这个结果直观地表明，在MLE解处，估计的信号产额 $\hat{s}$ 等于所有事件是信号的概率之和。这种技术，通常称为 $sPlot$，被广泛用于从数据中分离信号和背景成分。

值得注意的是，如果信号和背景的形状无法区分，即 $f_s(x) = f_b(x)$，则[似然函数](@entry_id:141927)仅依赖于总产额 $s+b$，而无法单独确定 $s$ 和 $b$。在这种情况下，我们说这两个参数是**不可辨识的**（non-identifiable），MLE只会给出 $\hat{s}+\hat{b}=n$ [@problem_id:3506229]。

#### 贝叶斯方法：先验的选择与后验的形成

在贝叶斯推断中，我们需要为参数指定先验分布 $\pi(\theta)$。先验的选择是[贝叶斯分析](@entry_id:271788)中一个深刻且时常引起争议的方面。理想情况下，先验应反映我们已有的知识。但在缺乏此类知识时，我们可能希望选择一个“无信息”或“客观”的先验，使其对[后验分布](@entry_id:145605)的影响最小。

**[杰弗里斯先验](@entry_id:164583)（Jeffreys Prior）** 是一种基于形式化原则构造此类[客观先验](@entry_id:167984)的著名方法。它被定义为与**[费雪信息](@entry_id:144784)**（Fisher Information）的平方根成正比：
$$
\pi_J(\theta) \propto \sqrt{I(\theta)}
$$
其中，对于单参数模型，[费雪信息](@entry_id:144784)定义为[对数似然函数](@entry_id:168593)导数平方的[期望值](@entry_id:153208)：
$$
I(\theta) = \mathbb{E}\left[ \left( \frac{\partial}{\partial \theta} \ln L(X \mid \theta) \right)^2 \right]
$$
费雪信息衡量了数据 $X$ 中包含的关于参数 $\theta$ 的[信息量](@entry_id:272315)。[杰弗里斯先验](@entry_id:164583)的关键优点在于其**[参数化](@entry_id:272587)不变性**（reparameterization invariance）。这意味着，如果我们对参数 $\theta$ 进行一对一的平滑变换得到新参数 $\phi = g(\theta)$，那么通过变量变换规则从 $\pi_J(\theta)$ 导出的 $\phi$ 的先验，与直接为 $\phi$ 计算[杰弗里斯先验](@entry_id:164583)得到的结果是一致的 [@problem_id:3506273]。这确保了物理结论不应依赖于我们选择用来描述它的数学符号。

让我们看两个HEP中的核心例子 [@problem_id:3506273]：
1.  **泊松均值 $\theta$**：对于 $N \sim \text{Poisson}(\theta)$，[费雪信息](@entry_id:144784)为 $I(\theta) = 1/\theta$。因此，[杰弗里斯先验](@entry_id:164583)是 $\pi_J(\theta) \propto \theta^{-1/2}$。
2.  **高斯均值 $\mu$（已知[方差](@entry_id:200758) $\sigma^2$）**：对于 $X \sim \mathcal{N}(\mu, \sigma^2)$，费雪信息为 $I(\mu) = 1/\sigma^2$，是一个常数。因此，[杰弗里斯先验](@entry_id:164583)是 $\pi_J(\mu) \propto 1$，即在整个实数轴上的[均匀分布](@entry_id:194597)。这是一个**不恰当先验**（improper prior），因为它无法归一化，但在许多情况下仍能导出恰当的后验分布。

### 处理[讨厌参数](@entry_id:171802)

在多数实际分析中，我们的模型包含我们关心的**感兴趣参数**（parameters of interest，如信号强度 $\mu$）以及我们不关心但必须考虑其不确定性的**[讨厌参数](@entry_id:171802)**（nuisance parameters，如背景产额 $\nu$ 或[形状参数](@entry_id:270600)）。消除[讨厌参数](@entry_id:171802)是[统计推断](@entry_id:172747)中的一个核心挑战。

#### 频率派方法：剖析

频率派处理[讨厌参数](@entry_id:171802)的标准方法是**剖析**（profiling）。对于[似然函数](@entry_id:141927) $L(\mu, \nu)$，我们为每个固定的感兴趣参数值 $\mu$最大化关于[讨厌参数](@entry_id:171802) $\nu$ 的似然函数，从而构造**[剖面似然](@entry_id:269700)函数**（profile likelihood）：
$$
\tilde{L}(\mu) = \max_{\nu} L(\mu, \nu)
$$
这个过程可以理解为，对于每一个关于 $\mu$ 的假设，我们都以对我们最“不利”的方式来调整 $\nu$，即选择让该 $\mu$ 值下数据最 plausible 的 $\nu$ 值。然后，所有关于 $\mu$ 的推断都基于这个一维的[剖面似然](@entry_id:269700)函数 $\tilde{L}(\mu)$ 进行 [@problem_id:3506298]。例如，一个基于[似然比](@entry_id:170863)的置信区间就是通过剖面[似然比[检验统计](@entry_id:169778)量](@entry_id:167372)来构建的。这个过程完全不涉及为 $\nu$ 指定任何[先验分布](@entry_id:141376)。剖析的一个重要特性是，它在[讨厌参数](@entry_id:171802)的重[参数化](@entry_id:272587)下是不变的 [@problem_id:3506298] [@problem_id:3506224]。

#### 贝叶斯方法：边缘化

贝叶斯方法通过**[边缘化](@entry_id:264637)**（marginalization）来消除[讨厌参数](@entry_id:171802)。这涉及到将联合后验分布 $p(\mu, \nu \mid \text{数据})$ 对所有[讨厌参数](@entry_id:171802) $\nu$进行积分，以获得只关于 $\mu$ 的边缘后验分布：
$$
p(\mu \mid \text{数据}) = \int p(\mu, \nu \mid \text{数据}) d\nu = \int p(\mu \mid \nu, \text{数据}) p(\nu \mid \text{数据}) d\nu
$$
这个过程可以看作是在我们关于 $\nu$ 的不确定性（由其后验分布 $p(\nu \mid \text{数据})$ 描述）上进行平均。这需要为[讨厌参数](@entry_id:171802) $\nu$ 指定一个先验 $\pi(\nu)$。与剖析不同，[边缘化](@entry_id:264637)操作不是在参数重[参数化](@entry_id:272587)下不变的。如果我们将 $\nu$ 变换为 $\nu' = g(\nu)$，除非我们将先验 $\pi(\nu)$ 通过正确的[雅可比行列式](@entry_id:137120)变换为 $\pi'(\nu')$，否则关于 $\mu$ 的推断将会改变 [@problem_id:3506298] [@problem_id:3506224]。

### [区间估计](@entry_id:177880)与[假设检验](@entry_id:142556)

从模型中提取最终科学结论通常涉及设定参数的[置信区间](@entry_id:142297)/[可信区间](@entry_id:176433)或进行[假设检验](@entry_id:142556)。

#### 频率派的置信区间与p值

频率派的**[置信区间](@entry_id:142297)**是一个随机区间，其构造方法保证了在大量重复实验中，该区间以特定概率（[置信水平](@entry_id:182309)，如 $95\%$）覆盖参数的真实、固定值。这一概率被称为**覆盖概率**（coverage probability）。

[假设检验](@entry_id:142556)通常通过**[p值](@entry_id:136498)**（p-value）进行。p值是在原假设 $H_0$ 为真的前提下，获得与观测数据一样极端或更极端结果的概率。一个小[p值](@entry_id:136498)（如 $\lt 0.05$）被视为反对 $H_0$ 的证据。

- **[渐近理论](@entry_id:162631)及其局限性**：在许多“良好”条件下（如参数的真值位于参数空间的内部），基于似然比的检验统计量（如 $-2\ln\lambda$）的[分布](@entry_id:182848)在大样本下会趋近于一个**卡方分布**($\chi^2$[分布](@entry_id:182848))，这就是**[威尔克斯定理](@entry_id:169826)**（Wilks' Theorem）[@problem_id:3506269]。然而，在[高能物理](@entry_id:181260)的“发现”分析中，这个条件常常被违反。例如，当我们检验一个信号是否存在时，[原假设](@entry_id:265441)是信号强度 $\mu=0$。由于信号强度物理上不能为负，即 $\mu \ge 0$，所以原假设位于[参数空间](@entry_id:178581)的**边界**上。在这种情况下，[威尔克斯定理](@entry_id:169826)失效。根据**切尔诺夫定理**（Chernoff's Theorem），[检验统计量](@entry_id:167372)的[渐近分布](@entry_id:272575)变成了一个卡方分布与在零点的点质量的混合，对于单参数情况，通常是 $\frac{1}{2}\chi^2_0 + \frac{1}{2}\chi^2_1$ 的[混合分布](@entry_id:276506) [@problem_id:3506269]。

- **别处效应**：当我们在一个很宽的参数范围（如质量谱）内寻找信号时，会产生另一个问题，即**别处效应**（Look-Elsewhere Effect, LEE）。即使在任何一个预先指定的位置都没有显著信号，但当你在很多地方同时寻找时，仅仅由于统计涨落，在 *某个地方* 找到一个“显著”信号的可能性会大大增加。为了修正这一点，我们需要计算**[全局p值](@entry_id:749928)**（global p-value），它是在原假设下，在整个搜索范围内的任何地方观测到至少与我们发现的最显著信号一样显著的信号的概率。对于一个平滑的、相关的搜索，[全局p值](@entry_id:749928)约等于[局部p值](@entry_id:751406)乘以一个**试验因子**（trials factor） $N_{\text{eff}}$。这个因子可以被近似为总搜索范围宽度与检验统计量场的[相关长度](@entry_id:143364)之比 [@problem_id:3506253]。

- **CLs 方法**：在设定参数上限时，标准的频率派方法可能会在一个背景向下涨落的区域“排除”一个我们实际上毫无敏感度的信号模型，这在物理上是不合理的。为了解决这个问题，HEP领域广泛采用 **CLs方法**。CLs值被定义为 $CL_s = \frac{CL_{s+b}}{CL_b}$，其中 $CL_{s+b}$ 是信号+背景假设下的p值，而 $CL_b$ 是纯背景假设下的p值。通过用 $CL_b$ 来“惩罚”[p值](@entry_id:136498)，当数据与背景假设也不兼容时（即 $CL_b$ 很小），$CL_s$ 会被人为地增大。这使得在缺乏区分信号与背景能力的区域，排除信号变得更加困难，从而得到更保守和稳健的上限 [@problem_id:3506242]。

#### [贝叶斯可信区间](@entry_id:183625)与模型检验

贝叶斯推断的产物是[后验分布](@entry_id:145605) $p(\theta \mid \text{数据})$，它直接量化了我们对参数的知识。

- **可信区间**：一个 $95\%$ 的**[可信区间](@entry_id:176433)**（credible interval）是一个参数区间，根据[后验分布](@entry_id:145605)，参数有 $95\%$ 的概率落入其中。这与[置信区间](@entry_id:142297)的解释截然不同。[可信区间](@entry_id:176433)有两种常见类型 [@problem_id:3506224]：
    1.  **等尾可信区间**（Equal-tailed interval）：由[后验分布](@entry_id:145605)的 $2.5\%$ 和 $97.5\%$ [分位数](@entry_id:178417)构成。这种区间的优点是在单调的参数变换下是**等变的**（equivariant）：对区间端点进行变换，会得到变换后参数的正确等尾可信区间。
    2.  **[最高后验密度区间](@entry_id:169876)**（Highest Posterior Density, HPD, interval）：该区间内的任意一点的后验概率密度都高于区间外的任意一点。HPD区间是给定可信度下最短的区间。然而，它在[非线性](@entry_id:637147)参数变换下不是等变的。

- **后验预测[p值](@entry_id:136498)**：贝叶斯学家也可以进行模型检验。一种方法是**后验预测检验**（posterior predictive checking）。其思想是：如果模型是好的，那么从模型中生成的“复制”数据应该看起来与我们观测到的真实数据相似。我们定义一个**差异统计量** $T(\mathbf{n})$ 来衡量数据的某个特征。然后，我们计算**后验预测[p值](@entry_id:136498)**，即从[后验预测分布](@entry_id:167931)中抽样得到的复制数据 $\mathbf{N}_{\text{rep}}$，其差异统计量大于或等于观测数据的差异统计量 $T(\mathbf{n}_{\text{obs}})$ 的概率 [@problem_id:3506243]。
    $$
    p_B = P(T(\mathbf{N}_{\text{rep}}) \ge T(\mathbf{n}_{\text{obs}}) \mid \mathbf{n}_{\text{obs}}) = \int P(T(\mathbf{N}_{\text{rep}}) \ge T(\mathbf{n}_{\text{obs}}) \mid \boldsymbol{\theta}) p(\boldsymbol{\theta} \mid \mathbf{n}_{\text{obs}}) d\boldsymbol{\theta}
    $$
    这种方法存在一个被称为“**数据双重使用**”（double-use-of-data）的问题。观测数据 $\mathbf{n}_{\text{obs}}$ 被使用了两次：一次用于更新先验到后验 $p(\boldsymbol{\theta} \mid \mathbf{n}_{\text{obs}})$，第二次用于计算 $T(\mathbf{n}_{\text{obs}})$。这使得后验预测的复制数据倾向于更接近观测数据，从而导致[p值](@entry_id:136498)偏向于不那么极端的值（通常更接近0.5）。因此，与理想的频率派[p值](@entry_id:136498)不同，后验预测[p值](@entry_id:136498)在[原假设](@entry_id:265441)下通常不是[均匀分布](@entry_id:194597)的，而是**保守的** [@problem_id:3506243]。

### 渐近的桥梁：[伯恩斯坦-冯·米塞斯定理](@entry_id:635022)

尽管贝叶斯和频率派方法在哲学基础和具体操作上存在诸多差异，但在许多实际应用中，它们得出的结论却惊人地相似。**[伯恩斯坦-冯·米塞斯定理](@entry_id:635022)**（Bernstein-von Mises Theorem, BvM）为这种现象提供了理论基础 [@problem_id:3506241]。

该定理指出，在一系列“正则”条件下（例如，参数的真值位于参数空间的内部、[似然函数](@entry_id:141927)光滑、先验在真值附近连续且为正、[参数空间](@entry_id:178581)维度固定），随着样本量的增大，参数的**后验分布**会收敛到一个**[高斯分布](@entry_id:154414)**。这个高斯分布的均值是**极大[似然](@entry_id:167119)估计值** $\hat{\mu}_n$，其[方差](@entry_id:200758)等于**逆[费雪信息](@entry_id:144784)** $I_n(\hat{\mu}_n)^{-1}$。

这是一个深刻的结果。它意味着，在大样本极限下：
- 贝叶斯后验分布的中心就是频率派的[点估计](@entry_id:174544)（MLE）。
- 贝叶斯后验分布的宽度（不确定性）与频率派估计量的[抽样分布](@entry_id:269683)宽度（标准误）相匹配。

因此，[贝叶斯可信区间](@entry_id:183625)和频率派[置信区间](@entry_id:142297)（特别是基于Wald统计量的区间）在形式上将变得完全相同，从而得出数值上一致的结果 [@problem_id:3506241]。在HEP的大型模板拟合中，由于数据量巨大，BvM定理常常可以解释为什么两种方法会给出相似的参数估计和不确定性。例如，对于一个泊松模板拟合，区间宽度的收缩速度为 $L_n^{-1/2}$，其中 $L_n$ 是积分光度，这在两种框架下都是成立的 [@problem_id:3506241]。

然而，理解BvM定理的**失效条件**同样重要。当正则条件不满足时，两种方法的结果可能会显著不同。这包括我们已经讨论过的情况：当参数真值位于边界时（如 $\mu_0 = 0$），或者当模型包含随样本量增长的[讨厌参数](@entry_id:171802)时（即高维模型）[@problem_id:3506241]。在这些更复杂的场景中，对两种方法论的选择和对其结果的解释需要更加谨慎。