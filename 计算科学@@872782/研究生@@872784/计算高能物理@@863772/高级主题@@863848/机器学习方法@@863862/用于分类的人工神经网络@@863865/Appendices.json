{"hands_on_practices": [{"introduction": "在高能物理领域，神经网络分类器的输出本身并不是最终目的，其真正价值在于提升物理分析的统计显著性。本练习将引导您在一个简化的物理模型中，从第一性原理出发，将分类器的输出得分与预期的发现显著性 $Z$ 直接联系起来。通过这项实践，您将深入理解机器学习性能与物理发现目标之间的量化关系，这是将机器学习模型有效融入粒子物理实验数据分析的关键一步 [@problem_id:3505051]。", "problem": "考虑一个计算高能物理中的二元分类问题，其中人工神经网络 (ANN) 经过训练以区分信号事件和背景事件。根据 Neyman–Pearson 引理，最优分类器分数是类条件概率密度函数 (PDF) 之间似然比的单调函数。令 $x$ 为一个一维运动学可观测量，并考虑一个分类器分数 $f(x)$，它与似然比 $p(x|s)/p(x|b)$ 呈严格单调关系，其中 $p(x|s)$ 和 $p(x|b)$ 分别表示信号和背景的 PDF。\n\n假设存在以下定义明确的统计模型：\n- PDF 是方差相等的高斯分布：$p(x|s) = \\mathcal{N}(\\mu_s, \\sigma)$ 和 $p(x|b) = \\mathcal{N}(\\mu_b, \\sigma)$，其中 $\\mu_s \\in \\mathbb{R}$，$\\mu_b \\in \\mathbb{R}$，且 $\\sigma  0$。\n- 信号和背景的预选择预期事件数分别为 $S_0  0$ 和 $B_0  0$。\n- 在分类器分数 $f(x)$ 上应用一个阈值 $\\tau  0$，选择满足 $f(x)  \\tau$ 的事件。\n- 定义接受度泛函\n$$\ns(\\tau) = \\int_{\\mathbb{R}} \\mathbb{1}_{f(x)  \\tau} \\, p(x|s) \\, dx,\n\\quad\nb(\\tau) = \\int_{\\mathbb{R}} \\mathbb{1}_{f(x)  \\tau} \\, p(x|b) \\, dx,\n$$\n以及后选择预期计数\n$$\nS(\\tau) = S_0 \\, s(\\tau), \\quad B(\\tau) = B_0 \\, b(\\tau).\n$$\n\n从用于发现的似然比检验的定义和单箱计数实验的泊松对数似然出发，利用 Asimov 数据集从第一性原理推导唯背景假设的发现检验统计量，并将预期发现显著性 $Z(\\tau)$ 表示为阈值 $\\tau$、高斯参数 $(\\mu_s, \\mu_b, \\sigma)$ 和预选择计数 $(S_0, B_0)$ 的泛函。量 $Z(\\tau)$ 是无量纲的。\n\n实现一个程序，该程序：\n1. 利用方差相等的高斯 PDF 的似然比的单调性，将 $f(x)$ 上的阈值 $\\tau$ 转换为 $x$ 上的等效阈值 $t(\\tau)$。\n2. 通过互补累积分布函数，为高斯 PDF 精确计算 $s(\\tau)$ 和 $b(\\tau)$。\n3. 为每个测试用例计算 $S(\\tau)$ 和 $B(\\tau)$。\n4. 在基于泊松似然的唯背景假设发现检验统计量的 Asimov 近似下计算 $Z(\\tau)$，并严格处理 $B(\\tau) \\to 0$ 的极限情况。\n5. 生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个 $Z(\\tau)$ 值四舍五入到六位小数。\n\n使用以下参数值测试套件来评估您的实现。每个测试用例都是一个元组 $(\\mu_s, \\mu_b, \\sigma, S_0, B_0, \\tau)$：\n- 测试 $1$：$(\\mu_s, \\mu_b, \\sigma, S_0, B_0, \\tau) = (125, 100, 15, 50, 200, 1)$。\n- 测试 $2$：$(\\mu_s, \\mu_b, \\sigma, S_0, B_0, \\tau) = (125, 100, 15, 50, 200, 2)$。\n- 测试 $3$：$(\\mu_s, \\mu_b, \\sigma, S_0, B_0, \\tau) = (125, 100, 15, 50, 200, 0.5)$。\n- 测试 $4$：$(\\mu_s, \\mu_b, \\sigma, S_0, B_0, \\tau) = (125, 100, 15, 50, 200, 10)$。\n- 测试 $5$ (退化分布)：$(\\mu_s, \\mu_b, \\sigma, S_0, B_0, \\tau) = (100, 100, 15, 50, 200, 0.9)$。\n- 测试 $6$ (退化分布)：$(\\mu_s, \\mu_b, \\sigma, S_0, B_0, \\tau) = (100, 100, 15, 50, 200, 1.1)$。\n- 测试 $7$ (背景主导)：$(\\mu_s, \\mu_b, \\sigma, S_0, B_0, \\tau) = (125, 100, 15, 5, 1000, 2)$。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，例如 $[z_1,z_2,\\dots,z_7]$，其中每个 $z_i$ 是测试 $i$ 的 $Z(\\tau)$ 的浮点值，四舍五入到六位小数。由于 $Z(\\tau)$ 是无量纲的，因此不需要单位。", "solution": "该问题要求针对高能物理中的一个二元分类问题，推导并实现一个计算预期发现显著性 $Z(\\tau)$ 的公式。推导将从第一性原理出发，假设一个基于高斯概率密度函数 (PDF) 和泊松计数统计的统计模型。\n\n该问题的一个核心前提是，分类器分数 $f(x)$ 与似然比 $L(x) = p(x|s)/p(x|b)$ 呈严格单调关系。Neyman-Pearson 引理指出，对于给定的显著性水平，最强大的统计检验是基于对此似然比设置阈值。因此，最优选择标准的形式为 $L(x)  k$，其中 $k$ 为某个常数。我们给定一个截断 $f(x)  \\tau$。要使之成为最优截断，$f(x)$ 必须是 $L(x)$ 的严格递增函数。我们在本解答中采用最简单和最直接的解释，即分类器分数 $f(x)$ 就是似然比本身，即 $f(x) = L(x)$。因此，分类器分数上的阈值 $\\tau$ 也就是似然比上的阈值。\n\n解答分为四个主要步骤：\n1.  推导可观测量 $x$ 上的选择阈值。\n2.  计算信号和背景接受度 $s(\\tau)$ 和 $b(\\tau)$。\n3.  计算后选择事件计数 $S(\\tau)$ 和 $B(\\tau)$。\n4.  推导 Asimov 显著性 $Z(\\tau)$。\n\n**步骤 1：推导可观测量 $x$ 上的决策阈值**\n\n信号和背景的 PDF 被给定为具有共同标准差 $\\sigma$ 的高斯分布：\n$$\np(x|s) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x-\\mu_s)^2}{2\\sigma^2}\\right)\n\\quad \\text{和} \\quad\np(x|b) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x-\\mu_b)^2}{2\\sigma^2}\\right)\n$$\n似然比 $L(x)$ 为：\n$$\nL(x) = \\frac{p(x|s)}{p(x|b)} = \\frac{\\exp\\left(-\\frac{(x-\\mu_s)^2}{2\\sigma^2}\\right)}{\\exp\\left(-\\frac{(x-\\mu_b)^2}{2\\sigma^2}\\right)} = \\exp\\left(\\frac{(x-\\mu_b)^2 - (x-\\mu_s)^2}{2\\sigma^2}\\right)\n$$\n展开指数中的平方项：\n$$\n(x-\\mu_b)^2 - (x-\\mu_s)^2 = (x^2 - 2x\\mu_b + \\mu_b^2) - (x^2 - 2x\\mu_s + \\mu_s^2) = 2x(\\mu_s - \\mu_b) - (\\mu_s^2 - \\mu_b^2)\n$$\n因此，似然比的对数是 $x$ 的线性函数：\n$$\n\\ln L(x) = \\frac{x(\\mu_s - \\mu_b)}{\\sigma^2} - \\frac{\\mu_s^2 - \\mu_b^2}{2\\sigma^2}\n$$\n选择标准 $f(x)  \\tau$（解释为 $L(x)  \\tau$）等价于 $\\ln L(x)  \\ln \\tau$，因为对数是严格递增函数。\n$$\n\\frac{x(\\mu_s - \\mu_b)}{\\sigma^2} - \\frac{(\\mu_s - \\mu_b)(\\mu_s + \\mu_b)}{2\\sigma^2}  \\ln \\tau\n$$\n乘以 $\\sigma^2$ 并分离出含 $x$ 的项：\n$$\nx(\\mu_s - \\mu_b)  \\sigma^2 \\ln \\tau + \\frac{(\\mu_s - \\mu_b)(\\mu_s + \\mu_b)}{2}\n$$\n$x$ 的不等式方向取决于 $(\\mu_s - \\mu_b)$ 的符号：\n-   如果 $\\mu_s  \\mu_b$：项 $(\\mu_s - \\mu_b)$ 为正。选择区域是 $x  t(\\tau)$，其中\n    $$\n    t(\\tau) = \\frac{\\sigma^2 \\ln \\tau}{\\mu_s - \\mu_b} + \\frac{\\mu_s + \\mu_b}{2}\n    $$\n-   如果 $\\mu_s  \\mu_b$：项 $(\\mu_s - \\mu_b)$ 为负。不等式反向，选择区域是 $x  t(\\tau)$。\n-   如果 $\\mu_s = \\mu_b$：PDF 相同，所以对所有 $x$ 都有 $L(x) = 1$。条件变为 $1  \\tau$。\n    -   如果 $\\tau  1$，条件恒为真，所有事件都被选择。区域是 $(-\\infty, \\infty)$。\n    -   如果 $\\tau \\ge 1$，条件恒为假，没有事件被选择。区域是空集 $\\emptyset$。\n\n**步骤 2：计算信号和背景接受度**\n\n接受度 $s(\\tau)$ 和 $b(\\tau)$ 分别是信号或背景事件落入所选区域的概率。这些概率是通过在该区域上对相应的 PDF 进行积分来计算的。我们使用标准正态分布的互补累积分布函数 (CCDF)，即 Q 函数，$Q(z) = \\frac{1}{\\sqrt{2\\pi}} \\int_z^\\infty e^{-u^2/2} du$。对于一般的正态分布 $\\mathcal{N}(\\mu, \\sigma)$，概率 $P(Xx)$ 是 $Q((x-\\mu)/\\sigma)$。Q 函数通过 $Q(z) = \\frac{1}{2}\\text{erfc}(z/\\sqrt{2})$ 与互补误差函数 $\\text{erfc}(z) = \\frac{2}{\\sqrt{\\pi}}\\int_z^\\infty e^{-t^2} dt$ 相关。\n\n-   情况 $\\mu_s  \\mu_b$ (区域为 $xt(\\tau)$)：\n    $$\n    s(\\tau) = \\int_{t(\\tau)}^\\infty p(x|s) dx = Q\\left(\\frac{t(\\tau)-\\mu_s}{\\sigma}\\right)\n    $$\n    $$\n    b(\\tau) = \\int_{t(\\tau)}^\\infty p(x|b) dx = Q\\left(\\frac{t(\\tau)-\\mu_b}{\\sigma}\\right)\n    $$\n-   情况 $\\mu_s  \\mu_b$ (区域为 $x  t(\\tau)$)：\n    $$\n    s(\\tau) = \\int_{-\\infty}^{t(\\tau)} p(x|s) dx = 1 - Q\\left(\\frac{t(\\tau)-\\mu_s}{\\sigma}\\right)\n    $$\n    $$\n    b(\\tau) = \\int_{-\\infty}^{t(\\tau)} p(x|b) dx = 1 - Q\\left(\\frac{t(\\tau)-\\mu_b}{\\sigma}\\right)\n    $$\n-   情况 $\\mu_s = \\mu_b$：\n    -   如果 $\\tau  1$，$s(\\tau)=1, b(\\tau)=1$。\n    -   如果 $\\tau \\ge 1$，$s(\\tau)=0, b(\\tau)=0$。\n\n**步骤 3：计算后选择事件计数**\n\n后选择预期事件计数由预选择计数与接受度相乘得到：\n$$\nS(\\tau) = S_0 \\cdot s(\\tau)\n\\quad \\text{和} \\quad\nB(\\tau) = B_0 \\cdot b(\\tau)\n$$\n\n**步骤 4：推导 Asimov 显著性**\n\n对于一个观察到 $n$ 个事件的单箱计数实验，如果预期背景为 $B$，则在信号加背景 ($S+B$) 假设下，对数似然为 $\\ln L(S+B, B) = n \\ln(S+B) - (S+B)$。在唯背景 ($B$) 假设下，为 $\\ln L(B, B) = n \\ln B - B$。对数似然比检验统计量为 $q_0 = -2 \\ln \\frac{L(B,B)}{L(S+B,B)}$。Asimov 数据集通过将观察到的事件数 $n$ 替换为其在信号加背景假设下的期望值，即 $n_{A} = S+B$ 来定义。\n将 $n=S+B$ 代入 $q_0$：\n$$\nq_{0,A} = -2\\left( (S+B)\\ln B - B - ((S+B)\\ln(S+B) - (S+B)) \\right)\n$$\n$$\nq_{0,A} = -2\\left( (S+B)\\ln B - (S+B)\\ln(S+B) + S \\right)\n$$\n$$\nq_{0,A} = -2\\left( (S+B)\\ln\\frac{B}{S+B} + S \\right) = 2\\left( (S+B)\\ln\\frac{S+B}{B} - S \\right)\n$$\n$$\nq_{0,A} = 2\\left( (S+B)\\ln\\left(1+\\frac{S}{B}\\right) - S \\right)\n$$\n预期发现显著性定义为 $Z = \\sqrt{q_{0,A}}$。因此，对于 $S(\\tau)$ 和 $B(\\tau)$：\n$$\nZ(\\tau) = \\sqrt{2\\left((S(\\tau)+B(\\tau)) \\ln\\left(1+\\frac{S(\\tau)}{B(\\tau)}\\right) - S(\\tau)\\right)}\n$$\n这个公式在 $B(\\tau)0$ 时成立。如果 $B(\\tau)=0$ 但 $S(\\tau)0$，发现是确定的，显著性为无穷大。在实际计算中，由于我们的高斯模型，除非接受度为零，否则 $B(\\tau)$ 永远不会严格为零。如果 $B(\\tau) \\to 0$，则 $\\ln(1+S/B) \\approx \\ln(S/B)$。如果 $S(\\tau)=0$，那么 $Z(\\tau)=0$。如果 $B(\\tau)=0$ 且 $S(\\tau)=0$，那么 $Z(\\tau)=0$。Python 实现将遵循此逻辑。", "answer": "```python\nimport numpy as np\nfrom scipy.special import erfc\n\ndef solve():\n    \"\"\"\n    Calculates the expected discovery significance for a set of test cases\n    in a high-energy physics classification problem.\n    \"\"\"\n    test_cases = [\n        # (mu_s, mu_b, sigma, S0, B0, tau)\n        (125.0, 100.0, 15.0, 50.0, 200.0, 1.0),\n        (125.0, 100.0, 15.0, 50.0, 200.0, 2.0),\n        (125.0, 100.0, 15.0, 50.0, 200.0, 0.5),\n        (125.0, 100.0, 15.0, 50.0, 200.0, 10.0),\n        (100.0, 100.0, 15.0, 50.0, 200.0, 0.9),\n        (100.0, 100.0, 15.0, 50.0, 200.0, 1.1),\n        (125.0, 100.0, 15.0, 5.0, 1000.0, 2.0),\n    ]\n\n    results = []\n    \n    # Q-function using scipy's complementary error function for numerical stability\n    # Q(z) = 0.5 * erfc(z / sqrt(2))\n    sqrt2 = np.sqrt(2.0)\n    def q_function(z):\n        return 0.5 * erfc(z / sqrt2)\n\n    for case in test_cases:\n        mu_s, mu_b, sigma, s0, b0, tau = case\n\n        s_acceptance = 0.0\n        b_acceptance = 0.0\n\n        if mu_s == mu_b:\n            # PDFs are identical, L(x) = 1 for all x.\n            # Selection depends only on the threshold tau relative to 1.\n            if tau  1.0:\n                s_acceptance, b_acceptance = 1.0, 1.0\n            else:\n                s_acceptance, b_acceptance = 0.0, 0.0\n        else:\n            # Calculate the threshold t(tau) on the observable x.\n            # t(tau) = sigma^2 * ln(tau) / (mu_s - mu_b) + (mu_s + mu_b) / 2\n            t_tau = (sigma**2 * np.log(tau)) / (mu_s - mu_b) + (mu_s + mu_b) / 2.0\n\n            # Arguments for the Q-function\n            z_s = (t_tau - mu_s) / sigma\n            z_b = (t_tau - mu_b) / sigma\n\n            if mu_s > mu_b:\n                # Selection region is x > t(tau)\n                s_acceptance = q_function(z_s)\n                b_acceptance = q_function(z_b)\n            else: # mu_s  mu_b\n                # Selection region is x  t(tau)\n                s_acceptance = 1.0 - q_function(z_s)\n                b_acceptance = 1.0 - q_function(z_b)\n\n        # Post-selection expected counts\n        s_final = s0 * s_acceptance\n        b_final = b0 * b_acceptance\n\n        # Calculate Asimov significance Z\n        if b_final == 0:\n            # If B=0 and S>0, significance is infinite.\n            # If B=0 and S=0, significance is 0.\n            # The Gaussian model implies B>0 unless the acceptance region is empty,\n            # in which case S is also 0.\n            z_value = 0.0\n        elif s_final == 0:\n            # If S=0, no discovery is possible.\n            z_value = 0.0\n        else:\n            # Asimov formula: sqrt(2 * ((S+B)ln(1+S/B) - S))\n            term1 = (s_final + b_final) * np.log(1.0 + s_final / b_final)\n            term2 = s_final\n            q0_a = 2.0 * (term1 - term2)\n            # Handle potential negative results due to float precision\n            z_value = np.sqrt(max(0.0, q0_a))\n            \n        results.append(f\"{z_value:.6f}\")\n\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3505051"}, {"introduction": "一个优秀的分类模型不仅应能做出准确预测，还应能表达其预测的置信度。本练习从一个新颖的视角探讨了常见的正则化技术——Dropout，即将其诠释为一种近似贝叶斯推断方法。通过解决这个问题，您将学习如何推导单个神经网络输出的预测不确定性，从而掌握一种无需训练多个模型即可评估模型置信度的实用方法 [@problem_id:3505062]。", "problem": "在计算高能物理 (HEP) 的一个二元分类任务中，一个人工神经网络 (ANN) 被训练来区分增强的顶夸克喷注和轻量子色动力学 (QCD) 喷注，其输入是编码了子结构可观测量的特征向量 $x \\in \\mathbb{R}^{d}$。考虑一个具有 $m$ 个隐藏单元的单隐藏层 ANN，其线性输出代表 logit。对于一个特定事件 $x_{\\star}$，隐藏层的预激活值为 $a_{j}(x_{\\star}) = w_{j}^{\\top} x_{\\star} + b_{j}$，其中对于 $j \\in \\{1,\\dots,m\\}$，$w_{j} \\in \\mathbb{R}^{d}$ 且 $b_{j} \\in \\mathbb{R}$。隐藏层的非线性函数是整流线性单元 (ReLU)，并且对于这个特定的 $x_{\\star}$，您可以假设对所有 $j$ 都有 $a_{j}(x_{\\star})  0$，因此隐藏层激活值等于 $h_{j}(x_{\\star}) = a_{j}(x_{\\star})$。输出 logit 计算如下\n$$\nf(x_{\\star},z) = c + \\sum_{j=1}^{m} v_{j} \\,\\tilde{h}_{j}(x_{\\star},z_{j}),\n$$\n其中 $v_{j} \\in \\mathbb{R}$ 和 $c \\in \\mathbb{R}$ 分别是输出权重和偏置，而 $\\tilde{h}_{j}$ 是经 dropout 掩蔽的激活值。\n\n通过将 dropout 掩码视为乘性潜变量上的变分后验，将 dropout 解释为近似贝叶斯推断。使用测试时反向 dropout，其中包含独立的 Bernoulli 掩码 $z_{j} \\sim \\mathrm{Bernoulli}(p)$（对于 $j \\in \\{1,\\dots,m\\}$），$p \\in (0,1]$ 是保留概率，并定义\n$$\n\\tilde{h}_{j}(x_{\\star},z_{j}) = \\frac{z_{j}}{p}\\,h_{j}(x_{\\star}).\n$$\n假设不确定性的唯一来源是 dropout 引起的认知不确定性（忽略任何偶然噪声）。从独立随机变量之和的期望和方差的基本定义出发，推导在此 Bernoulli 变分分布下以 $x_{\\star}$ 为条件的预测均值 $\\mathbb{E}[f(x_{\\star},z)]$ 和预测方差 $\\mathrm{Var}[f(x_{\\star},z)]$。\n\n请以 $p$、$v_{j}$ 和 $h_{j}(x_{\\star})$（对于 $j=1,\\dots,m$）表示预测方差 $\\mathrm{Var}[f(x_{\\star},z)]$，并将其作为单一的闭式解析表达式提供。不包含任何单位。如果得到精确的符号表达式，请勿进行近似。最终的方框答案必须是单个表达式。", "solution": "该问题要求计算单隐藏层人工神经网络 (ANN) 输出的预测均值和方差，其中不确定性通过 dropout 引入，并被解释为一种贝叶斯近似。该问题陈述是有效的，因为它在科学上基于已建立的机器学习理论，所有必要的定义都已给出，问题是适定且客观的。我们可以开始推导。\n\n对于给定的输入 $x_{\\star}$，输出 logit 定义为 dropout 掩码 $z = (z_1, z_2, \\dots, z_m)$ 的函数：\n$$\nf(x_{\\star},z) = c + \\sum_{j=1}^{m} v_{j} \\,\\tilde{h}_{j}(x_{\\star},z_{j})\n$$\n其中 $c$ 和 $v_{j}$ 是常数。经 dropout 掩蔽的激活值 $\\tilde{h}_{j}$ 由下式给出：\n$$\n\\tilde{h}_{j}(x_{\\star},z_{j}) = \\frac{z_{j}}{p}\\,h_{j}(x_{\\star})\n$$\n变量 $z_{j}$ 是从 Bernoulli 分布 $z_{j} \\sim \\mathrm{Bernoulli}(p)$ 中抽取的独立同分布随机变量，其中 $p \\in (0,1]$ 是保留概率。对于给定的输入 $x_{\\star}$，隐藏层激活值 $h_{j}(x_{\\star})$ 是固定值。将 $\\tilde{h}_{j}$ 的表达式代入 $f(x_{\\star},z)$ 的定义，我们得到：\n$$\nf(x_{\\star},z) = c + \\sum_{j=1}^{m} v_{j} \\left(\\frac{z_{j}}{p}\\,h_{j}(x_{\\star})\\right)\n$$\n这可以重新整理以分离出随机变量 $z_{j}$：\n$$\nf(x_{\\star},z) = c + \\sum_{j=1}^{m} \\left(\\frac{v_{j} h_{j}(x_{\\star})}{p}\\right) z_{j}\n$$\n期望和方差是相对于随机向量 $z$ 的分布计算的。\n\n首先，我们推导预测均值 $\\mathbb{E}[f(x_{\\star},z)]$。我们使用期望算子的线性性：\n$$\n\\mathbb{E}[f(x_{\\star},z)] = \\mathbb{E}\\left[c + \\sum_{j=1}^{m} \\frac{v_{j} h_{j}(x_{\\star})}{p} z_{j}\\right]\n$$\n$$\n\\mathbb{E}[f(x_{\\star},z)] = \\mathbb{E}[c] + \\mathbb{E}\\left[\\sum_{j=1}^{m} \\frac{v_{j} h_{j}(x_{\\star})}{p} z_{j}\\right]\n$$\n常数 $c$ 的期望是 $c$。对于求和项，我们可以将期望移到求和符号内部：\n$$\n\\mathbb{E}[f(x_{\\star},z)] = c + \\sum_{j=1}^{m} \\mathbb{E}\\left[\\frac{v_{j} h_{j}(x_{\\star})}{p} z_{j}\\right]\n$$\n项 $\\frac{v_{j} h_{j}(x_{\\star})}{p}$ 相对于 $z_{j}$ 的期望是常数，因此可以被提取出来：\n$$\n\\mathbb{E}[f(x_{\\star},z)] = c + \\sum_{j=1}^{m} \\frac{v_{j} h_{j}(x_{\\star})}{p} \\mathbb{E}[z_{j}]\n$$\n对于一个 Bernoulli 随机变量 $z_{j} \\sim \\mathrm{Bernoulli}(p)$，其期望为 $\\mathbb{E}[z_{j}] = p$。将此代入方程中，得到：\n$$\n\\mathbb{E}[f(x_{\\star},z)] = c + \\sum_{j=1}^{m} \\frac{v_{j} h_{j}(x_{\\star})}{p} \\cdot p = c + \\sum_{j=1}^{m} v_{j} h_{j}(x_{\\star})\n$$\n这个结果是网络在没有 dropout 情况下的标准前向传播，这证实了反向 dropout 缩放的性质。\n\n接下来，我们推导预测方差 $\\mathrm{Var}[f(x_{\\star},z)]$。一个随机变量加上一个常数后的方差等于原随机变量的方差，即 $\\mathrm{Var}(X+k) = \\mathrm{Var}(X)$。因此，常数偏置项 $c$ 对 方差没有贡献：\n$$\n\\mathrm{Var}[f(x_{\\star},z)] = \\mathrm{Var}\\left[c + \\sum_{j=1}^{m} \\frac{v_{j} h_{j}(x_{\\star})}{p} z_{j}\\right] = \\mathrm{Var}\\left[\\sum_{j=1}^{m} \\frac{v_{j} h_{j}(x_{\\star})}{p} z_{j}\\right]\n$$\n问题陈述指出，对于 $j \\in \\{1, \\dots, m\\}$，dropout 掩码 $z_{j}$ 是独立的。对于独立随机变量之和，和的方差等于方差之和。具体来说，对于独立的 $X_j$ 和常数 $a_j$，$\\mathrm{Var}(\\sum_j a_j X_j) = \\sum_j \\mathrm{Var}(a_j X_j) = \\sum_j a_j^2 \\mathrm{Var}(X_j)$。在我们的例子中，随机变量是 $z_{j}$，常数系数是 $\\frac{v_{j} h_{j}(x_{\\star})}{p}$。因此：\n$$\n\\mathrm{Var}[f(x_{\\star},z)] = \\sum_{j=1}^{m} \\mathrm{Var}\\left[\\frac{v_{j} h_{j}(x_{\\star})}{p} z_{j}\\right]\n$$\n使用性质 $\\mathrm{Var}(kX) = k^2\\mathrm{Var}(X)$，其中 $k$ 是一个常数，我们有：\n$$\n\\mathrm{Var}[f(x_{\\star},z)] = \\sum_{j=1}^{m} \\left(\\frac{v_{j} h_{j}(x_{\\star})}{p}\\right)^2 \\mathrm{Var}[z_{j}]\n$$\n对于一个 Bernoulli 随机变量 $z_{j} \\sim \\mathrm{Bernoulli}(p)$，其方差为 $\\mathrm{Var}[z_{j}] = p(1-p)$。将此代入方差的表达式中：\n$$\n\\mathrm{Var}[f(x_{\\star},z)] = \\sum_{j=1}^{m} \\frac{v_{j}^{2} h_{j}(x_{\\star})^{2}}{p^2} \\cdot p(1-p)\n$$\n通过消去一个因子 $p$ 来简化表达式，得到预测方差的最终结果：\n$$\n\\mathrm{Var}[f(x_{\\star},z)] = \\sum_{j=1}^{m} v_{j}^{2} h_{j}(x_{\\star})^{2} \\frac{1-p}{p}\n$$\n这可以通过提取出依赖于 $p$ 的项来书写：\n$$\n\\mathrm{Var}[f(x_{\\star},z)] = \\frac{1-p}{p} \\sum_{j=1}^{m} v_{j}^{2} h_{j}(x_{\\star})^{2}\n$$\n这就是问题陈述所要求的预测方差的闭式解析表达式。", "answer": "$$\n\\boxed{\\frac{1-p}{p} \\sum_{j=1}^{m} v_{j}^{2} h_{j}(x_{\\star})^{2}}\n$$", "id": "3505062"}, {"introduction": "在上一练习的基础上，我们探讨一种更稳健地量化不确定性的方法：模型集成。本练习深入探讨了预测不确定性分解的基础理论，您将推导总预测方差如何分解为“偶然不确定性”（来自数据）和“认知不确定性”（来自模型）。这项实践对于构建用于科学发现的可信赖人工智能系统至关重要，因为它不仅量化了模型的不确定性，还评估了其校准性，即模型对其预测的自信程度是否合理 [@problem_id:3505082]。", "problem": "给定一个在计算高能物理中常见的二元分类场景，其中人工神经网络（ANN）会为事件类别（例如，区分信号与背景）输出预测概率。从贝叶斯建模的角度来看，一个由独立训练的ANN组成的集成可以被解释为模型参数后验分布的一个有限样本。对于给定的输入特征向量 $x$，用 $p_m(x)$ 表示集成员 $m$ 对类别 $y=1$ 的预测概率，用 $Y \\in \\{0,1\\}$ 表示随机标签。假设以下基本原理为出发点：条件分布 $Y \\mid x, w$ 是均值为 $p_w(x)$ 的伯努利分布；预测（贝叶斯）期望是模型后验的平均值；全方差定律适用于嵌套的随机性来源。\n\n仅从这些基本原理和方差的定义出发，推导在固定 $x$ 下 $Y$ 的预测方差分解，将其分解为与模型不确定性和数据不确定性相关的两个非负分量。用可从 $\\{p_m(x)\\}$ 计算的集成平均量来表示每个分量。通过引用上述基本原则，简要论证每一步。\n\n然后，使用推导出的分解，实现一个程序来为指定的测试套件估计以下指标：\n- 每个测试套件中，在所有样本上，使用给定的有限集成估计的左侧预测方差与您推导的两个分量之和的右侧之间的最大绝对差异。使用最大绝对差值聚合套件中样本的这种差异。\n- 期望校准误差 (ECE)，通过将集成均值预测概率分箱到 $[0,1]$ 上的 $M$ 个等宽的箱中，并计算每个非空箱中经验频率与平均预测概率之间绝对差的加权平均值。\n- 来自经典Brier分数分解的Brier可靠性项，使用与ECE相同的分箱方法。\n- 使用集成均值预测概率计算的每个样本的平均负对数似然 (NLL)，使用一个小的 $\\epsilon$ 进行数值安全的裁剪以避免对 $0$ 取对数。\n\n所有量必须使用以下精确定义进行计算：\n- 对于每个样本 $i$，其集成员概率为 $\\{p_{m,i}\\}_{m=1}^{M_e}$，定义集成均值 $\\bar{p}_i = \\frac{1}{M_e}\\sum_{m=1}^{M_e} p_{m,i}$。将每个样本的预测方差估计定义为 $\\bar{p}_i (1-\\bar{p}_i)$。将数据（偶然）部分定义为伯努利方差的集成均值 $\\frac{1}{M_e}\\sum_{m=1}^{M_e} p_{m,i}(1-p_{m,i})$。将模型（认知）部分定义为 $\\{p_{m,i}\\}$ 在模型间的方差，使用总体方差约定（分母为 $M_e$）。\n- 对于套件级别的ECE和Brier可靠性，令 $M$ 为箱数。对于每个样本，将 $\\bar{p}_i$ 分配到将 $[0,1]$ 划分为等宽区间的 $M$ 个箱中的一个。对于每个非空箱 $b$，令 $n_b$ 为计数，$\\hat{p}_b$ 为箱中 $\\bar{p}_i$ 的均值，$\\hat{f}_b$ 为箱中 $y_i=1$ 的经验频率。令 $N$ 为套件中的样本总数。定义\n  - $\\mathrm{ECE} = \\sum_{b} \\frac{n_b}{N} \\left| \\hat{p}_b - \\hat{f}_b \\right|$，\n  - $\\mathrm{Reliability} = \\sum_{b} \\frac{n_b}{N} \\left( \\hat{p}_b - \\hat{f}_b \\right)^2$。\n- 对于NLL，标签为 $y_i \\in \\{0,1\\}$，裁剪后的概率为 $\\tilde{p}_i = \\min(\\max(\\bar{p}_i,\\epsilon),1-\\epsilon)$，其中 $\\epsilon = 10^{-12}$，定义平均NLL为 $\\frac{1}{N}\\sum_{i=1}^N \\left( - y_i \\log \\tilde{p}_i - (1-y_i) \\log (1-\\tilde{p}_i) \\right)$。\n- 所有对数均为自然对数。\n\n您的程序必须为以下测试套件实现上述计算。在每个套件中，所有数字都是无量纲的概率。每个套件指定一个形状为 $M_e \\times N$ 的预测概率集成和一个包含 $N$ 个二元标签的向量：\n- Suite A (校准良好，中等置信度，交替标签):\n  - 集成大小 $M_e = 4$，样本数 $N = 8$，箱数 $M = 4$。\n  - 标签 $y = [\\,1,0,1,0,1,0,1,0\\,]$。\n  - 集成预测 (每行为一个模型，条目为 $p_{m,i}$):\n    - Model 1: $[\\,0.75, 0.15, 0.70, 0.30, 0.85, 0.25, 0.65, 0.20\\,]$,\n    - Model 2: $[\\,0.80, 0.10, 0.72, 0.28, 0.88, 0.22, 0.60, 0.18\\,]$,\n    - Model 3: $[\\,0.78, 0.12, 0.68, 0.32, 0.86, 0.24, 0.62, 0.16\\,]$,\n    - Model 4: $[\\,0.77, 0.14, 0.69, 0.31, 0.84, 0.26, 0.63, 0.19\\,]$。\n- Suite B (过于自信，含边界概率，混合标签):\n  - 集成大小 $M_e = 3$，样本数 $N = 8$，箱数 $M = 4$。\n  - 标签 $y = [\\,1,1,0,0,1,0,1,0\\,]$。\n  - 集成预测:\n    - Model 1: $[\\,1.00, 0.95, 0.00, 0.02, 0.99, 0.00, 0.90, 0.10\\,]$,\n    - Model 2: $[\\,0.98, 0.97, 0.02, 0.01, 1.00, 0.00, 0.92, 0.08\\,]$,\n    - Model 3: $[\\,0.97, 1.00, 0.04, 0.00, 0.98, 0.02, 0.91, 0.09\\,]$。\n- Suite C (置信度不足，概率接近模糊):\n  - 集成大小 $M_e = 3$，样本数 $N = 8$，箱数 $M = 4$。\n  - 标签 $y = [\\,1,0,1,0,1,0,1,0\\,]$。\n  - 集成预测:\n    - Model 1: $[\\,0.55, 0.45, 0.60, 0.40, 0.52, 0.48, 0.58, 0.42\\,]$,\n    - Model 2: $[\\,0.50, 0.50, 0.55, 0.45, 0.53, 0.47, 0.57, 0.43\\,]$,\n    - Model 3: $[\\,0.52, 0.48, 0.58, 0.42, 0.51, 0.49, 0.56, 0.44\\,]$。\n\n实现要求：\n- 对校准指标和NLL使用集成均值 $\\bar{p}_i$。\n- 对所有套件，在 $[0,1]$ 上精确使用 $M=4$ 个等宽的箱。将 $\\bar{p}_i=1$ 的样本分配到最后一个箱，将 $\\bar{p}_i=0$ 的样本分配到第一个箱。\n- 对于每个套件，按顺序计算并记录：方差分解在样本间的最大绝对差异、ECE、Brier可靠性和平均NLL。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表。最终列表必须按顺序连接Suite A的四个结果、Suite B的四个结果和Suite C的四个结果。将每个值表示为保留 $6$ 位小数的数字。\n\n不提供外部输入。所有输出值都是无量纲的。因此，预期的输出格式为\n$[r_{A,1}, r_{A,2}, r_{A,3}, r_{A,4}, r_{B,1}, r_{B,2}, r_{B,3}, r_{B,4}, r_{C,1}, r_{C,2}, r_{C,3}, r_{C,4}]$。", "solution": "任务是从第一性原理出发，推导预测方差的分解，然后实现一个程序来为给定的测试套件计算若干不确定性和校准指标。该问题具有科学依据，定义明确，并提供了所有必要的信息。\n\n首先，我们将推导预测方差的分解。设 $Y \\in \\{0,1\\}$ 为真实类别标签的随机变量，设 $x$ 为固定的输入特征向量。我们的模型参数（权重）用 $w$ 表示，它们被视为遵循给定训练数据 $\\mathcal{D}$ 的后验分布 $p(w|\\mathcal{D})$ 的随机变量。一个包含 $M_e$ 个模型的集成提供了一组从该后验分布中采样的参数向量 $\\{w_m\\}_{m=1}^{M_e}$。\n\n问题陈述指出，对于一组固定的参数 $w$，标签的条件分布是一个伯努利分布，$Y \\mid x, w \\sim \\mathrm{Bernoulli}(p_w(x))$，其中 $p_w(x)$ 是模型为类别 $Y=1$ 输出的概率。\n\n我们的目标是分解给定 $x$ 和训练数据 $\\mathcal{D}$ 的 $Y$ 的总预测方差，我们将其表示为 $\\mathrm{Var}(Y|x, \\mathcal{D})$。该方差来自两个随机性来源：数据的内在随机性和我们对模型参数 $w$ 的不确定性。我们可以使用全方差定律来分离它们，该定律指出，对于任意两个随机变量 $A$ 和 $B$，$\\mathrm{Var}(A) = E_B[\\mathrm{Var}_A(A|B)] + \\mathrm{Var}_B(E_A[A|B])$。\n\n将此应用于我们的问题，我们将 $Y$ 视为主随机变量，模型参数 $w$ 视为条件变量。所有的期望 $E_w[\\cdot]$ 和方差 $\\mathrm{Var}_w(\\cdot)$ 都是在后验分布 $p(w|\\mathcal{D})$ 上计算的。\n\n$$\n\\mathrm{Var}(Y|x, \\mathcal{D}) = E_{w|\\mathcal{D}}[\\mathrm{Var}_{Y}(Y | x, w)] + \\mathrm{Var}_{w|\\mathcal{D}}(E_{Y}[Y | x, w])\n$$\n\n让我们分析右侧的两项。\n\n1.  内部期望 $E_{Y}[Y | x, w]$ 是一个参数为 $p_w(x)$ 的伯努利随机变量的期望值。根据定义，这正是参数本身：\n    $$\n    E_{Y}[Y | x, w] = p_w(x)\n    $$\n\n2.  内部方差 $\\mathrm{Var}_{Y}(Y | x, w)$ 是同一个伯努利随机变量的方差。对于参数为 $p$ 的伯努利分布，方差为 $p(1-p)$。因此：\n    $$\n    \\mathrm{Var}_{Y}(Y | x, w) = p_w(x)(1 - p_w(x))\n    $$\n\n将这些代回全方差公式，我们得到：\n$$\n\\mathrm{Var}(Y|x, \\mathcal{D}) = E_{w|\\mathcal{D}}[p_w(x)(1 - p_w(x))] + \\mathrm{Var}_{w|\\mathcal{D}}(p_w(x))\n$$\n\n这个方程提供了所需的分解。右侧的两项是：\n-   **数据（偶然）不确定性**: $E_{w|\\mathcal{D}}[p_w(x)(1 - p_w(x))]$。该项是伯努利方差的期望值，在模型参数的后验分布上取平均。它代表了数据中固有的、不可约减的不确定性，即使我们完美地知道模型参数。这被称为偶然不确定性（aleatoric uncertainty）。\n-   **模型（认知）不确定性**: $\\mathrm{Var}_{w|\\mathcal{D}}(p_w(x))$。该项是模型预测概率本身的方差，在参数的后验分布上计算。它量化了由于我们对参数 $w$ 的不确定性，模型的预测会变化多少。这种不确定性可以通过更多数据来减少，被称为认知不确定性（epistemic uncertainty）。\n\n现在，我们必须将方程的左侧 $\\mathrm{Var}(Y|x, \\mathcal{D})$ 与一个可解释的量联系起来。左侧是贝叶斯预测分布 $p(Y|x, \\mathcal{D})$ 的方差。该预测分布的均值是贝叶斯模型平均（BMA）预测，通过对参数 $w$ 进行边缘化得到：\n$$\n\\bar{p}(x) = E[Y|x, \\mathcal{D}] = E_{w|\\mathcal{D}}[E_Y[Y|x,w]] = E_{w|\\mathcal{D}}[p_w(x)]\n$$\n完整的预测分布 $p(Y|x, \\mathcal{D})$ 也是一个均值为 $\\bar{p}(x)$ 的伯努利分布。因此，其方差为：\n$$\n\\mathrm{Var}(Y|x, \\mathcal{D}) = \\bar{p}(x)(1 - \\bar{p}(x))\n$$\n\n有了这个，我们可以陈述完整的恒等式：\n$$\n\\underbrace{\\bar{p}(x)(1 - \\bar{p}(x))}_{\\text{总预测方差}} = \\underbrace{E_{w|\\mathcal{D}}[p_w(x)(1 - p_w(x))]}_{\\text{偶然不确定性}} + \\underbrace{\\mathrm{Var}_{w|\\mathcal{D}}(p_w(x))}_{\\text{认知不确定性}}\n$$\n这个恒等式可以通过展开右侧来证实，因为 $\\mathrm{Var}(A) = E[A^2] - (E[A])^2$:\n$$\nE_w[p_w(x) - p_w(x)^2] + (E_w[p_w(x)^2] - (E_w[p_w(x)])^2)\n$$\n$$\n= E_w[p_w(x)] - E_w[p_w(x)^2] + E_w[p_w(x)^2] - (E_w[p_w(x)])^2\n$$\n$$\n= E_w[p_w(x)] - (E_w[p_w(x)])^2 = \\bar{p}(x) - (\\bar{p}(x))^2 = \\bar{p}(x)(1 - \\bar{p}(x))\n$$\n恒等式成立。问题要求从一个有限的集成 $\\{p_m(x)\\}_{m=1}^{M_e}$ 中计算这些量。我们用来自集成的样本估计量来近似真实的后验期望和方差。对于给定的样本 $i$：\n-   集成均值为 $\\bar{p}_i = \\frac{1}{M_e}\\sum_{m=1}^{M_e} p_{m,i}$。这估计了 $\\bar{p}(x_i)$。\n-   总预测方差（LHS）估计为 $\\bar{p}_i(1-\\bar{p}_i)$。\n-   偶然不确定性估计为单个伯努利方差的均值：$\\frac{1}{M_e}\\sum_{m=1}^{M_e} p_{m,i}(1-p_{m,i})$。\n-   认知不确定性估计为集成预测的方差：$\\frac{1}{M_e}\\sum_{m=1}^{M_e} (p_{m,i} - \\bar{p}_i)^2$，这是 $\\{p_{m,i}\\}$ 的总体方差。\n\n这样就完成了推导，并将理论量与问题中定义的估计量联系起来。问题的后续部分要求实现这些公式，以及像ECE、Brier可靠性和NLL这样的标准指标，这些也都有精确定义。实现将直接遵循这些定义。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to define test suites, compute metrics, and print results.\n    \"\"\"\n\n    test_suites = [\n        {\n            \"name\": \"Suite A\",\n            \"Me\": 4, \"N\": 8, \"M_bins\": 4,\n            \"labels\": np.array([1, 0, 1, 0, 1, 0, 1, 0]),\n            \"preds\": np.array([\n                [0.75, 0.15, 0.70, 0.30, 0.85, 0.25, 0.65, 0.20],\n                [0.80, 0.10, 0.72, 0.28, 0.88, 0.22, 0.60, 0.18],\n                [0.78, 0.12, 0.68, 0.32, 0.86, 0.24, 0.62, 0.16],\n                [0.77, 0.14, 0.69, 0.31, 0.84, 0.26, 0.63, 0.19],\n            ])\n        },\n        {\n            \"name\": \"Suite B\",\n            \"Me\": 3, \"N\": 8, \"M_bins\": 4,\n            \"labels\": np.array([1, 1, 0, 0, 1, 0, 1, 0]),\n            \"preds\": np.array([\n                [1.00, 0.95, 0.00, 0.02, 0.99, 0.00, 0.90, 0.10],\n                [0.98, 0.97, 0.02, 0.01, 1.00, 0.00, 0.92, 0.08],\n                [0.97, 1.00, 0.04, 0.00, 0.98, 0.02, 0.91, 0.09],\n            ])\n        },\n        {\n            \"name\": \"Suite C\",\n            \"Me\": 3, \"N\": 8, \"M_bins\": 4,\n            \"labels\": np.array([1, 0, 1, 0, 1, 0, 1, 0]),\n            \"preds\": np.array([\n                [0.55, 0.45, 0.60, 0.40, 0.52, 0.48, 0.58, 0.42],\n                [0.50, 0.50, 0.55, 0.45, 0.53, 0.47, 0.57, 0.43],\n                [0.52, 0.48, 0.58, 0.42, 0.51, 0.49, 0.56, 0.44],\n            ])\n        }\n    ]\n\n    all_results = []\n    for suite in test_suites:\n        results = calculate_metrics(\n            suite[\"preds\"], suite[\"labels\"], suite[\"M_bins\"]\n        )\n        all_results.extend(results)\n\n    # Format the final output string\n    print(f\"[{','.join(f'{r:.6f}' for r in all_results)}]\")\n\ndef calculate_metrics(preds, labels, M_bins, epsilon=1e-12):\n    \"\"\"\n    Computes the four required metrics for a given test suite.\n\n    Args:\n        preds (np.ndarray): Ensemble predictions of shape (Me, N).\n        labels (np.ndarray): True labels of shape (N,).\n        M_bins (int): Number of bins for ECE and Reliability.\n        epsilon (float): Clipping value for NLL calculation.\n\n    Returns:\n        tuple: A tuple containing the four computed metrics.\n    \"\"\"\n    N = labels.shape[0]\n\n    # Calculate ensemble mean probabilities\n    p_bar = np.mean(preds, axis=0)\n\n    # 1. Maximum absolute discrepancy for variance decomposition\n    lhs_variance = p_bar * (1 - p_bar)\n    aleatoric_variance = np.mean(preds * (1 - preds), axis=0)\n    epistemic_variance = np.var(preds, axis=0, ddof=0) # ddof=0 for population variance\n    rhs_variance = aleatoric_variance + epistemic_variance\n    max_discrepancy = np.max(np.abs(lhs_variance - rhs_variance))\n    \n    # 2. ECE and 3. Brier Reliability\n    ece = 0.0\n    reliability = 0.0\n    \n    # Assign samples to bins\n    # For p_bar=1.0, floor(1.0*M_bins) = M_bins. Clip to M_bins-1.\n    bin_indices = np.floor(p_bar * M_bins)\n    bin_indices = np.minimum(M_bins - 1, bin_indices).astype(int)\n\n    for b in range(M_bins):\n        in_bin_mask = (bin_indices == b)\n        n_b = np.sum(in_bin_mask)\n        \n        if n_b > 0:\n            p_hat_b = np.mean(p_bar[in_bin_mask])\n            f_hat_b = np.mean(labels[in_bin_mask])\n            \n            ece += (n_b / N) * np.abs(p_hat_b - f_hat_b)\n            reliability += (n_b / N) * (p_hat_b - f_hat_b)**2\n\n    # 4. Average Negative Log-Likelihood (NLL)\n    p_tilde = np.clip(p_bar, epsilon, 1 - epsilon)\n    nll_terms = -labels * np.log(p_tilde) - (1 - labels) * np.log(1 - p_tilde)\n    avg_nll = np.mean(nll_terms)\n\n    return (max_discrepancy, ece, reliability, avg_nll)\n\nsolve()\n```", "id": "3505082"}]}