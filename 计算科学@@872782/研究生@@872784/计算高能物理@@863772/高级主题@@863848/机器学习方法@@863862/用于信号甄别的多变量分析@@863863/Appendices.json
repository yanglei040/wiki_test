{"hands_on_practices": [{"introduction": "在深入研究复杂算法之前，理解分类器性能的理论极限至关重要。此练习从一个基础且富有启发性的场景入手：两个具有相同方差的一维高斯分布。通过解析地推导接收者操作特征（ROC）曲线，你将揭示信号与背景分布的“可分离性”如何直接决定理想分类器的性能上限，为评估任何分类器提供了基准。", "problem": "在一个用于计算高能物理中信号判别的二元分类场景下，考虑一个从事件中测量出的一维特征 $x$。这些事件要么属于信号类别 $S$，要么属于背景类别 $B$。类条件密度是具有相等方差的高斯分布，具体为 $p(x \\mid S) = \\mathcal{N}(\\mu_{S}, \\sigma^{2})$ 和 $p(x \\mid B) = \\mathcal{N}(\\mu_{B}, \\sigma^{2})$，其中 $\\mu_{S}$、$\\mu_{B}$ 和 $\\sigma > 0$ 是有限常数，且 $\\mu_{S} > \\mu_{B}$。利用奈曼-皮尔逊引理和作为假阳性约束下最优检测器的似然比检验（LRT），通过在由似然比阈值导出的判决区域上对高斯分布进行解析积分，构建受试者工作特征（ROC）曲线。消除该阈值，以获得一个闭式函数关系，该关系将真阳性率表示为所有容许阈值下假阳性率的函数。你的最终答案必须是关于 $\\mu_{S}$、$\\mu_{B}$ 和 $\\sigma$ 的单一闭式解析表达式，并且可以包含标准正态分布的累积分布函数。不要提供任何数值近似；要求给出精确表达式。", "solution": "用户希望推导出一个具有高斯类条件密度的二元分类问题的受试者工作特征（ROC）曲线。\n\n### 问题验证\n\n**步骤1：提取已知条件**\n-   **二元分类：** 信号类别 $S$ vs. 背景类别 $B$。\n-   **特征：** 一维特征 $x$。\n-   **类条件密度：**\n    -   信号：$p(x \\mid S) = \\mathcal{N}(\\mu_{S}, \\sigma^{2})$\n    -   背景：$p(x \\mid B) = \\mathcal{N}(\\mu_{B}, \\sigma^{2})$\n-   **参数：** $\\mu_{S}$、$\\mu_{B}$ 和 $\\sigma$ 是有限常数。\n-   **约束：** $\\sigma > 0$ 且 $\\mu_{S} > \\mu_{B}$。\n-   **方法论：** 奈曼-皮尔逊引理和似然比检验（LRT）。\n-   **目标：** 通过找到真阳性率（TPR）和假阳性率（FPR）之间的闭式函数关系来构建 ROC 曲线。最终表达式应以 $\\mu_{S}$、$\\mu_{B}$ 和 $\\sigma$ 表示，并可包含标准正态分布的累积分布函数。\n\n**步骤2：使用提取的已知条件进行验证**\n-   **科学依据：** 该问题是统计信号处理和决策论中的一个经典基础练习，这也是高能物理数据分析的核心组成部分。高斯分布和奈曼-皮尔逊引理的使用是标准且科学合理的。\n-   **适定性：** 该问题是适定的。分布被完全指定，条件 $\\mu_{S} > \\mu_{B}$ 确保了这是一个非平凡的判别问题。目标明确，且存在唯一的解析解。\n-   **客观性：** 问题以精确、客观的数学语言陈述。\n-   **缺陷评估：** 该问题未违反任何无效性标准。它是科学合理的、可形式化的、完整的、可行的和适定的。\n\n**步骤3：结论与行动**\n该问题是**有效的**。将提供解答。\n\n### 解答推导\n\n该问题要求推导受试者工作特征（ROC）曲线，该曲线描述了二元分类器的性能。ROC 曲线是真阳性率（TPR）对假阳性率（FPR）的图。\n\n根据奈曼-皮尔逊引理，用于区分两个简单假设 $H_B: x \\sim p(x \\mid B)$（背景）和 $H_S: x \\sim p(x \\mid S)$（信号）的最强检验是似然比检验（LRT）。似然比 $\\Lambda(x)$ 定义为：\n$$\n\\Lambda(x) = \\frac{p(x \\mid S)}{p(x \\mid B)}\n$$\n判决规则是，如果 $\\Lambda(x) > \\eta$，则将观测值 $x$ 分类为信号，其中 $\\eta$ 是一个判决阈值。$\\eta$ 的值决定了 ROC 曲线上的一个点。\n\n鉴于类条件密度是具有相等方差的高斯分布：\n$$\np(x \\mid S) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x - \\mu_{S})^2}{2\\sigma^2}\\right)\n$$\n$$\np(x \\mid B) = \\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(x - \\mu_{B})^2}{2\\sigma^2}\\right)\n$$\n似然比为：\n$$\n\\Lambda(x) = \\frac{\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(x - \\mu_{S})^2}{2\\sigma^2}\\right)}{\\frac{1}{\\sqrt{2\\pi}\\sigma}\\exp\\left(-\\frac{(x - \\mu_{B})^2}{2\\sigma^2}\\right)} = \\exp\\left( \\frac{(x - \\mu_{B})^2 - (x - \\mu_{S})^2}{2\\sigma^2} \\right)\n$$\n由于自然对数 $\\ln$ 是一个单调递增函数，不等式 $\\Lambda(x) > \\eta$ 等价于 $\\ln(\\Lambda(x)) > \\ln(\\eta)$。对似然比取对数可以简化表达式：\n$$\n\\ln(\\Lambda(x)) = \\frac{(x^2 - 2x\\mu_{B} + \\mu_{B}^2) - (x^2 - 2x\\mu_{S} + \\mu_{S}^2)}{2\\sigma^2} = \\frac{2x(\\mu_{S} - \\mu_{B}) - (\\mu_{S}^2 - \\mu_{B}^2)}{2\\sigma^2}\n$$\n$$\n\\ln(\\Lambda(x)) = \\frac{\\mu_{S} - \\mu_{B}}{\\sigma^2}x - \\frac{\\mu_{S}^2 - \\mu_{B}^2}{2\\sigma^2}\n$$\n判决规则 $\\ln(\\Lambda(x)) > \\ln(\\eta)$ 变为：\n$$\n\\frac{\\mu_{S} - \\mu_{B}}{\\sigma^2}x > \\ln(\\eta) + \\frac{\\mu_{S}^2 - \\mu_{B}^2}{2\\sigma^2}\n$$\n鉴于问题陈述 $\\mu_{S} > \\mu_{B}$，项 $\\frac{\\mu_{S} - \\mu_{B}}{\\sigma^2}$ 是正的。因此，该不等式等价于，如果 $x$ 大于某个我们记为 $x_{th}$ 的阈值，则将事件分类为信号：\n$$\nx > x_{th} \\quad \\text{其中} \\quad x_{th} = \\frac{\\sigma^2}{\\mu_{S} - \\mu_{B}}\\left(\\ln(\\eta) + \\frac{\\mu_{S}^2 - \\mu_{B}^2}{2\\sigma^2}\\right)\n$$\n信号的判决区域为 $\\Omega_{S} = \\{x \\in \\mathbb{R} \\mid x > x_{th}\\}$。将 LRT 阈值 $\\eta$ 从 $0$ 变到 $\\infty$ 对应于将 $x_{th}$ 从 $-\\infty$ 变到 $\\infty$。\n\nTPR 和 FPR 分别定义为信号或背景事件落入信号判决区域 $\\Omega_S$ 的概率：\n$$\n\\text{TPR}(x_{th}) = P(x \\in \\Omega_S \\mid S) = \\int_{x_{th}}^{\\infty} p(x \\mid S) dx\n$$\n$$\n\\text{FPR}(x_{th}) = P(x \\in \\Omega_S \\mid B) = \\int_{x_{th}}^{\\infty} p(x \\mid B) dx\n$$\n这些积分可以用标准正态分布 $\\mathcal{N}(0, 1)$ 的累积分布函数（CDF）来表示，我们记为 $\\Phi(z) = \\int_{-\\infty}^{z} \\frac{1}{\\sqrt{2\\pi}} \\exp(-t^2/2) dt$。\n对于一个一般的高斯变量 $X \\sim \\mathcal{N}(\\mu, \\sigma^2)$，概率 $P(X > a)$ 由下式给出：\n$$\nP(X > a) = P\\left(\\frac{X - \\mu}{\\sigma} > \\frac{a - \\mu}{\\sigma}\\right) = 1 - \\Phi\\left(\\frac{a - \\mu}{\\sigma}\\right)\n$$\n利用标准正态概率密度函数（PDF）的对称性，$1 - \\Phi(z) = \\Phi(-z)$，我们有：\n$$\nP(X > a) = \\Phi\\left(-\\frac{a - \\mu}{\\sigma}\\right) = \\Phi\\left(\\frac{\\mu - a}{\\sigma}\\right)\n$$\n将此应用于我们的 TPR 和 FPR 表达式：\n$$\n\\text{TPR}(x_{th}) = \\Phi\\left(\\frac{\\mu_{S} - x_{th}}{\\sigma}\\right)\n$$\n$$\n\\text{FPR}(x_{th}) = \\Phi\\left(\\frac{\\mu_{B} - x_{th}}{\\sigma}\\right)\n$$\n这两个方程提供了 ROC 曲线的参数表示，其中 $x_{th}$ 是参数。为了得到期望的将 TPR 表示为 FPR 函数的闭式关系，我们必须消去 $x_{th}$。\n从 FPR 方程中，我们使用标准正态累积分布函数的反函数（分位数函数或概率单位函数），记为 $\\Phi^{-1}$，来解出 $x_{th}$：\n$$\n\\Phi^{-1}(\\text{FPR}) = \\frac{\\mu_{B} - x_{th}}{\\sigma}\n$$\n$$\n\\sigma \\Phi^{-1}(\\text{FPR}) = \\mu_{B} - x_{th}\n$$\n$$\nx_{th} = \\mu_{B} - \\sigma \\Phi^{-1}(\\text{FPR})\n$$\n现在，将 $x_{th}$ 的这个表达式代入 TPR 方程：\n$$\n\\text{TPR} = \\Phi\\left(\\frac{\\mu_{S} - (\\mu_{B} - \\sigma \\Phi^{-1}(\\text{FPR}))}{\\sigma}\\right)\n$$\n简化 $\\Phi$ 的自变量：\n$$\n\\text{TPR} = \\Phi\\left(\\frac{\\mu_{S} - \\mu_{B} + \\sigma \\Phi^{-1}(\\text{FPR})}{\\sigma}\\right)\n$$\n$$\n\\text{TPR} = \\Phi\\left(\\frac{\\mu_{S} - \\mu_{B}}{\\sigma} + \\Phi^{-1}(\\text{FPR})\\right)\n$$\n这就是 ROC 曲线的最终闭式解析表达式，它关联了真阳性率与假阳性率。该表达式取决于指定的参数 $\\mu_S$、$\\mu_B$ 和 $\\sigma$，并涉及标准正态 CDF $\\Phi$ 及其反函数 $\\Phi^{-1}$。项 $\\frac{\\mu_S - \\mu_B}{\\sigma}$ 是以标准差为单位的两个分布之间分离度的度量。", "answer": "$$\n\\boxed{\\Phi\\left(\\frac{\\mu_{S} - \\mu_{B}}{\\sigma} + \\Phi^{-1}(\\text{FPR})\\right)}\n$$", "id": "3524097"}, {"introduction": "真实的物理分析并非处理抽象的分布，而是对物理过程和探测器响应进行建模。此练习将理论与实践相连接，要求你为一个简化的粒子散射过程构建一个判别模型，其中考虑了探测器的能量分辨率效应。你将学习如何通过卷积积分，将“真实”的物理过程（部分子级能量）与探测器的“模糊”效应（传递函数）结合，从而数值化地构建观测量的似然函数 $P(x|H)$，这是构建任何分类器的基础。", "problem": "考虑一个简化的二元假设检验问题，用于在高能物理（HEP）多变量信号判别中，一个二体到二体（$2 \\to 2$）散射过程的玩具模型，该过程在质心（CoM）系中进行。单个测量的标量可观测量 $x$ 代表一个末态粒子的量能器能量测量值。真实但潜藏的能量为 $E$。探测器响应由一个高斯传递函数建模，部分子层面的能量分布取决于假设 $H \\in \\{S,B\\}$，其中 $S$ 表示信号假设，$B$ 表示背景假设。所有能量单位必须为 $\\mathrm{GeV}$，概率密度函数（PDF）需被视为关于能量（单位 $\\mathrm{GeV}$）的函数。\n\n从全概率定律和传递函数的定义出发，在假设 $H$ 下观测到 $x$ 的条件似然由以下积分给出：\n$$\nP(x \\mid H) \\;=\\; \\int_{0}^{E_{\\max}} W(x \\mid E)\\, f_H(E)\\, dE,\n$$\n其中 $W(x \\mid E)$ 是探测器传递函数，$f_H(E)$ 是在假设 $H$ 下归一化的部分子层面能量 PDF。\n\n您必须使用以下具体的、物理上合理的建模选择：\n- 能量支撑集：$E \\in [0, E_{\\max}]$，其中 $E_{\\max} = 1000\\,\\mathrm{GeV}$。\n- 探测器传递函数（高斯型）：对于任意实数 $x$ 和 $E \\in [0,E_{\\max}]$，\n$$\nW(x \\mid E) \\;=\\; \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_{\\text{meas}}}\\,\\exp\\!\\left(-\\frac{(x - E)^2}{2\\,\\sigma_{\\text{meas}}^2}\\right), \\quad \\sigma_{\\text{meas}} = 20\\,\\mathrm{GeV}.\n$$\n- 信号先验（部分子层面）PDF：在 $[0,E_{\\max}]$ 上的截断高斯形状，均值为 $\\mu_S = 500\\,\\mathrm{GeV}$，宽度参数为 $\\tau_S = 60\\,\\mathrm{GeV}$，\n$$\nf_S(E) \\;=\\; \\frac{\\exp\\!\\left(-\\frac{(E - \\mu_S)^2}{2\\,\\tau_S^2}\\right)}{Z_S}, \\quad Z_S \\;=\\; \\int_{0}^{E_{\\max}} \\exp\\!\\left(-\\frac{(E - \\mu_S)^2}{2\\,\\tau_S^2}\\right)\\, dE.\n$$\n- 背景先验（部分子层面）PDF：在 $[0,E_{\\max}]$ 上的下降幂律分布，标度为 $E_0 = 200\\,\\mathrm{GeV}$，指数为 $n = 3.5$，\n$$\nf_B(E) \\;=\\; \\frac{\\left(1 + \\frac{E}{E_0}\\right)^{-n}}{Z_B}, \\quad Z_B \\;=\\; \\int_{0}^{E_{\\max}} \\left(1 + \\frac{E}{E_0}\\right)^{-n} dE.\n$$\n\n通过 Neyman–Pearson (NP) 构造，为两个简单假设定义最优等先验判别式 $D(x)$ 如下：\n$$\nD(x) \\;=\\; \\frac{P(x \\mid S)}{P(x \\mid S) + P(x \\mid B)}.\n$$\n\n任务：\n- 使用所提供的 $W(x \\mid E)$ 和 $f_H(E)$，明确地建立 $P(x \\mid H)$ 的积分。\n- 对每个指定的 $x$ 值，通过对能量 $E$ 在 $[0, E_{\\max}]$ 区间上进行一维数值积分，计算 $P(x \\mid S)$、$P(x \\mid B)$ 和 $D(x)$ 的数值近似。归一化常数 $Z_S$ 和 $Z_B$ 的计算必须与主似然积分使用相同的数值精度标准，以保证一致性。\n- 所有中间和最终计算都必须与所述单位一致；然而，最终报告的值是纯数字，对于 $P(x \\mid H)$ 对应于单位为 $\\mathrm{GeV}^{-1}$ 的 PDF 值，对于 $D(x)$ 则是无量纲的。\n- 将每个请求的数值四舍五入到 $6$ 位小数。\n\n测试集：\n- 使用以下 $x$ 值（单位为 $\\mathrm{GeV}$）：$x \\in \\{500.0,\\, 50.0,\\, 950.0,\\, 0.0,\\, 1000.0\\}$。\n\n最终输出格式：\n- 您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔的扁平列表，顺序如下：\n$$\n[\\;P(x_1\\mid S),\\;P(x_1\\mid B),\\;D(x_1),\\;P(x_2\\mid S),\\;P(x_2\\mid B),\\;D(x_2),\\;\\ldots\\;],\n$$\n其中每个浮点数按要求四舍五入到 $6$ 位小数。不得打印任何额外文本。\n- 程序必须完全独立，不需要用户输入，并且只使用指定的数值库。", "solution": "该问题要求为高能物理中一个简化的信号与背景假设检验计算条件似然和最优判别式。问题的核心在于通过一个探测器响应模型，将一个真实的、潜藏的能量分布与一个测量的可观测量联系起来。这种关系在数学上由一个卷积积分来描述。\n\n基本原理是全概率定律。给定一个假设 $H$（$H$ 为信号 $S$ 或背景 $B$），观测到测量能量 $x$ 的概率密度，是通过对所有可能的真实能量值 $E$ 进行边缘化得到的。这通过以下积分表示：\n$$\nP(x \\mid H) = \\int P(x, E \\mid H) \\, dE\n$$\n使用条件概率的定义，$P(x, E \\mid H) = P(x \\mid E, H) f_H(E)$，其中 $f_H(E)$ 是在假设 $H$ 下真实能量 $E$ 的概率密度。探测器响应 $W(x \\mid E)$ 被假定为独立于潜在的物理假设，因此 $P(x \\mid E, H) = W(x \\mid E)$。于是，积分变为：\n$$\nP(x \\mid H) = \\int_{0}^{E_{\\max}} W(x \\mid E) f_H(E) \\, dE\n$$\n积分在真实能量的允许范围 $E \\in [0, E_{\\max}]$ 上进行。\n\n问题为所有组成部分提供了具体的函数形式：\n能量范围由 $E_{\\max} = 1000\\,\\mathrm{GeV}$ 定义。\n探测器传递函数 $W(x \\mid E)$ 将测量分辨率建模为以真实能量 $E$ 为中心的高斯分布：\n$$\nW(x \\mid E) = \\frac{1}{\\sqrt{2\\pi}\\,\\sigma_{\\text{meas}}}\\,\\exp\\!\\left(-\\frac{(x - E)^2}{2\\,\\sigma_{\\text{meas}}^2}\\right), \\quad \\text{with } \\sigma_{\\text{meas}} = 20\\,\\mathrm{GeV}\n$$\n部分子层面能量 PDF $f_H(E)$ 必须在定义域 $[0, E_{\\max}]$ 上归一化为 1。\n\n对于信号假设（$H=S$）：\nPDF $f_S(E)$ 是一个截断高斯分布，均值为 $\\mu_S = 500\\,\\mathrm{GeV}$，宽度为 $\\tau_S = 60\\,\\mathrm{GeV}$。\n$$\nf_S(E) = \\frac{1}{Z_S} \\exp\\!\\left(-\\frac{(E - \\mu_S)^2}{2\\,\\tau_S^2}\\right)\n$$\n其中归一化常数 $Z_S$ 由未归一化分布在能量支撑集上的积分给出：\n$$\nZ_S = \\int_{0}^{E_{\\max}} \\exp\\!\\left(-\\frac{(E - \\mu_S)^2}{2\\,\\tau_S^2}\\right) dE\n$$\n\n对于背景假设（$H=B$）：\nPDF $f_B(E)$ 是一个下降幂律分布，标度为 $E_0 = 200\\,\\mathrm{GeV}$，指数为 $n = 3.5$。\n$$\nf_B(E) = \\frac{1}{Z_B} \\left(1 + \\frac{E}{E_0}\\right)^{-n}\n$$\n相应的归一化常数 $Z_B$ 为：\n$$\nZ_B = \\int_{0}^{E_{\\max}} \\left(1 + \\frac{E}{E_0}\\right)^{-n} dE\n$$\n\n将这些定义代入主卷积积分，我们得到条件似然的显式表达式：\n对于信号：\n$$\nP(x \\mid S) = \\int_{0}^{1000} \\left[ \\frac{1}{\\sqrt{2\\pi}\\,(20)}\\exp\\!\\left(-\\frac{(x - E)^2}{2\\,(20)^2}\\right) \\right] \\left[ \\frac{1}{Z_S}\\exp\\!\\left(-\\frac{(E - 500)^2}{2\\,(60)^2}\\right) \\right] dE\n$$\n对于背景：\n$$\nP(x \\mid B) = \\int_{0}^{1000} \\left[ \\frac{1}{\\sqrt{2\\pi}\\,(20)}\\exp\\!\\left(-\\frac{(x - E)^2}{2\\,(20)^2}\\right) \\right] \\left[ \\frac{1}{Z_B}\\left(1 + \\frac{E}{200}\\right)^{-3.5} \\right] dE\n$$\n这些积分，包括用于 $Z_S$ 和 $Z_B$ 的积分，并非都有简单的闭式解析解，必须进行数值计算。问题指定所有积分都应使用一致的数值方法。完成此任务的一个稳健方法是数值求积，例如 Python 中 `scipy.integrate.quad` 函数提供的功能，它实现了一种高精度的自适应积分算法。\n\n计算过程如下：\n1.  通过对未归一化的 PDF 函数从 $E=0$ 到 $E=E_{\\max}$ 进行积分，数值计算归一化常数 $Z_S$ 和 $Z_B$。\n2.  对于可观测量 $x$ 的每个指定值，数值计算 $P(x \\mid S)$ 和 $P(x \\mid B)$ 的积分。\n3.  根据这些似然值，计算 Neyman-Pearson 判别式 $D(x)$。在信号和背景的先验概率相等的情况下，该判别式等价于信号假设的后验概率：\n$$\nD(x) = \\frac{P(x \\mid S)}{P(x \\mid S) + P(x \\mid B)}\n$$\n这个量为区分两种假设提供了一个最优度量，其值趋近于 1 表示一个类信号事件，趋近于 0 表示一个类背景事件。需要对测试集 $\\{500.0, 50.0, 950.0, 0.0, 1000.0\\}$ 中的每个 $x$ 计算这些值。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import quad\n\ndef solve():\n    \"\"\"\n    Computes likelihoods and discriminant for a HEP hypothesis test.\n    \"\"\"\n    # Define the physical and model constants from the problem statement.\n    E_max = 1000.0  # GeV\n    sigma_meas = 20.0  # GeV\n    mu_S = 500.0  # GeV\n    tau_S = 60.0  # GeV\n    E_0 = 200.0  # GeV\n    n = 3.5\n\n    # Define the test cases from the problem statement.\n    test_cases = [500.0, 50.0, 950.0, 0.0, 1000.0]\n\n    # --- Step 1: Define unnormalized parton-level PDFs ---\n\n    def unnormalized_fs(E):\n        \"\"\"Unnormalized signal PDF.\"\"\"\n        return np.exp(-(E - mu_S)**2 / (2 * tau_S**2))\n\n    def unnormalized_fb(E):\n        \"\"\"Unnormalized background PDF.\"\"\"\n        return (1 + E / E_0)**(-n)\n\n    # --- Step 2: Compute normalization constants Z_S and Z_B ---\n    # The integrals are computed numerically for consistency as required.\n    Z_S, _ = quad(unnormalized_fs, 0, E_max)\n    Z_B, _ = quad(unnormalized_fb, 0, E_max)\n\n    # --- Step 3: Define normalized PDFs and the transfer function ---\n\n    def f_S(E):\n        \"\"\"Normalized signal PDF f_S(E).\"\"\"\n        return unnormalized_fs(E) / Z_S\n\n    def f_B(E):\n        \"\"\"Normalized background PDF f_B(E).\"\"\"\n        return unnormalized_fb(E) / Z_B\n\n    def W(x, E):\n        \"\"\"Detector transfer function W(x|E).\"\"\"\n        return (1 / (np.sqrt(2 * np.pi) * sigma_meas)) * np.exp(-(x - E)**2 / (2 * sigma_meas**2))\n\n    # --- Step 4: Compute likelihoods and discriminant for each x ---\n    \n    results = []\n    for x in test_cases:\n        # Define the integrands for the convolution integrals P(x|H).\n        # The integrand is the product of the transfer function and the prior PDF.\n        def integrand_S(E):\n            return W(x, E) * f_S(E)\n\n        def integrand_B(E):\n            return W(x, E) * f_B(E)\n\n        # Perform numerical integration to find the likelihoods P(x|S) and P(x|B).\n        P_x_S, _ = quad(integrand_S, 0, E_max)\n        P_x_B, _ = quad(integrand_B, 0, E_max)\n\n        # Compute the optimal discriminant D(x).\n        # A check for division by zero is prudent, though unlikely in this scenario\n        # as the likelihoods are integrals of non-negative functions.\n        denominator = P_x_S + P_x_B\n        if denominator == 0:\n            # This case corresponds to an observed x that is impossible under both hypotheses.\n            # The discriminant is undefined; a neutral value of 0.5 is a reasonable default.\n            D_x = 0.5\n        else:\n            D_x = P_x_S / denominator\n        \n        results.extend([P_x_S, P_x_B, D_x])\n\n    # --- Step 5: Format and print the final output ---\n\n    # Format each number to 6 decimal places as a string.\n    formatted_results = [f\"{val:.6f}\" for val in results]\n    \n    # Print the final result in the exact required format.\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3524159"}, {"introduction": "建立分类器后，我们需要一个可靠的方法来估计其在未知数据上的泛化性能。此高级练习深入探讨了模型评估的统计基础，特别是在处理高能物理中常见的事件权重和交叉验证折叠间相关性等复杂情况时。你的任务是为一个嵌套交叉验证方案推导出一个近似无偏的泛化AUC估计量，从而掌握评估复杂机器学习流程性能的黄金标准方法。", "problem": "考虑一个计算高能物理中的二元分类任务，其中每个事例被赋予一个标签 $y \\in \\{0,1\\}$（$y=1$ 为信号，$y=0$ 为本底）和一个正的事例权重 $w>0$。该权重源于为匹配积分亮度和截面而进行的蒙特卡洛重加权。假设有 $N$ 个事例，由 $n \\in \\{1,\\dots,N\\}$ 索引，其标签为 $y_n$，权重为 $w_n$，特征为 $x_n$。你执行 $K$ 折嵌套交叉验证（N-CV），其外层折由 $k \\in \\{1,\\dots,K\\}$ 索引，测试索引集 $T_k \\subset \\{1,\\dots,N\\}$ 构成对数据集的一个划分，即对于 $k \\neq \\ell$ 有 $T_k \\cap T_{\\ell} = \\emptyset$ 且 $\\bigcup_{k=1}^{K} T_k = \\{1,\\dots,N\\}$。对于每个外层折 $k$，使用内层交叉验证仅在训练集 $R_k = \\{1,\\dots,N\\} \\setminus T_k$ 上选择超参数，之后使用所选超参数在 $R_k$ 上训练一个模型。对于每个事例 $i \\in T_k$，记 $s_i$ 为由外层第 $k$ 折训练的模型产生的分数；根据构造，$s_i$ 是由一个未在事例 $i$ 上训练过的模型计算得出的。\n\n将此学习流程的加权泛化受试者工作特征曲线（ROC曲线）下面积（AUC）定义为：在训练样本的重复随机抽取以及由同一训练模型评分的两个独立测试事例下，一个信号事例的分数超过一个本底事例分数的期望概率（平局得半分），此概率基于事例加权测试分布：\n$$\nA^{\\star} \\equiv \\mathbb{E}\\!\\left[\\, \\mathbb{P}_{(X^{+},W^{+}),(X^{-},W^{-})}\\!\\left( S(X^{+}) > S(X^{-}) \\right) + \\tfrac{1}{2}\\,\\mathbb{P}_{(X^{+},W^{+}),(X^{-},W^{-})}\\!\\left( S(X^{+}) = S(X^{-}) \\right) \\,\\right],\n$$\n其中，$S(\\cdot)$ 表示由随机训练样本的训练模型所导出的分数函数，而 $(X^{+},W^{+})$ 和 $(X^{-},W^{-})$ 分别是从事例加权信号和本底测试分布中独立抽取的样本。\n\n令 $T_k^{+} = \\{ i \\in T_k : y_i = 1 \\}$ 且 $T_k^{-} = \\{ j \\in T_k : y_j = 0 \\}$。对于每个外层折 $k$，定义 $W_k^{+} = \\sum_{i \\in T_k^{+}} w_i$ 和 $W_k^{-} = \\sum_{j \\in T_k^{-}} w_j$，以及全局总和 $W^{+} = \\sum_{k=1}^{K} W_k^{+}$ 和 $W^{-} = \\sum_{k=1}^{K} W_k^{-}$。\n\n从上面给出的 $A^{\\star}$ 的基本事例加权定义出发，并利用嵌套交叉验证确保所有 $s_i$ 均为样本外评分的性质，推导一个 $A^{\\star}$ 的近似无偏估计量，该估计量满足：\n- 仅使用由外层折模型产生的分数 $\\{ s_i : i \\in T_k, k=1,\\dots,K \\}$，\n- 遵守每对中的两个事例都由同一训练模型评分的要求，\n- 正确地包含事例权重 $\\{ w_n \\}$，\n- 对 $s$ 中的平局给予半分。\n\n你的最终答案必须是该估计量的一个单一闭式解析表达式，用上文定义的 $\\{ s_i, w_i, T_k^{+}, T_k^{-}, W^{+}, W^{-}, K \\}$ 表示。不需要进行数值评估。\n\n此外，在你的推导中，解释在存在非均匀事例权重和外层折间相关性（例如，由于重叠的训练集和内层交叉验证的超参数选择）的情况下，你的估计量的主要方差来源，但不要提供任何方差的简化公式。讨论应自成体系，并基于 U-统计量、交叉验证和事例加权的常规性质，但最终答案应仅为上文指定的估计量表达式。", "solution": "我们首先重申目标，并确定一个推导估计量的严谨路径。一个学习流程的加权泛化受试者工作特征（ROC）曲线下面积（AUC）$A^{\\star}$ 定义为：在学习流程的随机性（源于随机训练样本和内层交叉验证的超参数选择）下，一个信号事例分数超过一个本底事例分数的事件加权概率的期望值，其中平局得半分。形式上，对于从信号测试分布中独立抽取的两个样本 $(X^{+},W^{+})$ 和从本底测试分布中独立抽取的样本 $(X^{-},W^{-})$，以及由在随机训练样本上训练一次学习流程所导出的分数函数 $S(\\cdot)$，我们有\n$$\nA^{\\star} = \\mathbb{E}\\!\\left[ \\mathbb{P}\\!\\left( S(X^{+}) > S(X^{-}) \\right) + \\tfrac{1}{2}\\,\\mathbb{P}\\!\\left( S(X^{+}) = S(X^{-}) \\right) \\right],\n$$\n其中概率是关于事例加权测试分布的。外面的期望捕捉了由依赖于数据的训练和超参数选择所产生的训练模型的随机性。\n\n为了从数据中估计 $A^{\\star}$，我们需要样本外分数以避免因在训练和测试中重复使用同一事例而产生的偏差。嵌套交叉验证（N-CV）正好提供了这一点：每个测试事例 $i \\in T_k$ 都由一个仅在 $R_k = \\{1,\\dots,N\\} \\setminus T_k$ 上训练的模型进行评分，其超参数是使用在 $R_k$ 内部进行的内层交叉验证选择的。因此，$\\{ s_i : i \\in T_k \\}$ 是对于在 $R_k$ 上训练的模型的样本外分数。\n\n一个核心的微妙之处在于，AUC 目标 $A^{\\star}$ 在概念上比较的是由*同一个*训练模型评分的两个独立测试事例。如果我们汇集所有折的样本外分数，并比较由可能不同的模型评分的事例，我们将隐含地估计一个不同的泛函：一个成对比较的平均值，其中两个分数可以来自不同的训练模型。该量与 $A^{\\star}$ 不一致，因为 $A^{\\star}$ 要求两个分数都由同一个训练模型产生。因此，为了以 $A^{\\star}$ 为目标，我们将成对比较限制在同一个外层折内的事例之间，确保 $s_i$ 和 $s_j$ 都来自在 $R_k$ 上训练的模型（对于折 $k$ 是固定的）。在随机分折和从事例加权测试分布进行独立同分布（i.i.d.）采样的条件下，每个折的测试集是测试分布的一个代表性样本，而外层折的模型是该学习流程在训练模型上导出的分布的一个代表性抽样。然后，通过在各折之间进行适当的平均，可以得到 $A^{\\star}$ 的一个近似无偏估计量。\n\n接下来，我们引入事例权重。在高能物理中，事例被赋予正权重 $w$ 以反映有效积分亮度、截面或类别重平衡。事例加权AUC可以通过在一个折内的加权成对U-统计量来估计。对于折 $k$，定义加权AUC估计量\n$$\n\\widehat{A}_k \\equiv \\frac{1}{W_k^{+} W_k^{-}} \\sum_{i \\in T_k^{+}} \\sum_{j \\in T_k^{-}} w_i\\, w_j \\left[ \\mathbb{1}\\!\\left( s_i > s_j \\right) + \\tfrac{1}{2}\\,\\mathbb{1}\\!\\left( s_i = s_j \\right) \\right],\n$$\n其中 $W_k^{+} = \\sum_{i \\in T_k^{+}} w_i$ 和 $W_k^{-} = \\sum_{j \\in T_k^{-}} w_j$，$\\mathbb{1}(\\cdot)$ 是指示函数。这是经典Mann–Whitney U-统计量的事例加权模拟，经过调整以对平局给予半分，并通过该折中信号和本底总权重的乘积进行归一化。在标准的正则性条件下（在事例加权采样方案下，各类内部的事例是独立同分布的，并且折的测试集是随机划分，独立于为该折产生分数的训练数据），$\\widehat{A}_k$ 是该学习流程特定于折的泛化AUC的近似无偏估计，其中两个测试事例都由同一个训练模型（即在 $R_k$ 上选择和训练的模型）评分。\n\n为了跨折聚合以 $A^{\\star}$ 为目标，我们用与每个折内的总配对权重（即 $W_k^{+} W_k^{-}$）成比例的权重来平均特定于折的估计量，并通过全局交叉配对权重 $W^{+} W^{-}$ 进行归一化，其中 $W^{+} = \\sum_{k=1}^{K} W_k^{+}$ 和 $W^{-} = \\sum_{k=1}^{K} W_k^{-}$。这得到\n$$\n\\widehat{A}_{\\text{nested}} \\equiv \\sum_{k=1}^{K} \\frac{W_k^{+} W_k^{-}}{W^{+} W^{-}}\\, \\widehat{A}_k.\n$$\n将 $\\widehat{A}_k$ 的定义代入 $\\widehat{A}_{\\text{nested}}$ 可立即简化：\n$$\n\\widehat{A}_{\\text{nested}} = \\sum_{k=1}^{K} \\frac{W_k^{+} W_k^{-}}{W^{+} W^{-}} \\left\\{ \\frac{1}{W_k^{+} W_k^{-}} \\sum_{i \\in T_k^{+}} \\sum_{j \\in T_k^{-}} w_i\\, w_j \\left[ \\mathbb{1}\\!\\left( s_i > s_j \\right) + \\tfrac{1}{2}\\,\\mathbb{1}\\!\\left( s_i = s_j \\right) \\right] \\right\\}.\n$$\n消去和式内部的 $W_k^{+} W_k^{-}$ 得到紧凑的闭式表达式\n$$\n\\widehat{A}_{\\text{nested}} = \\frac{1}{W^{+} W^{-}} \\sum_{k=1}^{K} \\sum_{i \\in T_k^{+}} \\sum_{j \\in T_k^{-}} w_i\\, w_j \\left[ \\mathbb{1}\\!\\left( s_i > s_j \\right) + \\tfrac{1}{2}\\,\\mathbb{1}\\!\\left( s_i = s_j \\right) \\right].\n$$\n该估计量仅使用样本外分数，在同一折内配对（因此两个分数来自同一个训练模型），并正确地包含了事例权重及对平局的半分处理。在随机分折和标准假设下（这些假设证明了将折测试集视为从事例加权测试分布中抽取的独立同分布样本，以及将外层折模型视为从训练流程在训练模型上导出的分布中抽取的独立同分布样本是合理的），$\\widehat{A}_{\\text{nested}}$ 是 $A^{\\star}$ 的近似无偏估计。\n\n我们现在解释在事例权重和折间相关性下 $\\widehat{A}_{\\text{nested}}$ 的主要方差来源。估计量 $\\widehat{A}_{\\text{nested}}$ 是折内U-统计量的加权平均。其方差在一阶近似下可分解为折级别的方差和协方差：\n$$\n\\operatorname{Var}\\!\\left( \\widehat{A}_{\\text{nested}} \\right) \\approx \\sum_{k=1}^{K} \\alpha_k^{2}\\, \\operatorname{Var}\\!\\left( \\widehat{A}_k \\right) + 2 \\sum_{1 \\leq k  \\ell \\leq K} \\alpha_k \\alpha_{\\ell}\\, \\operatorname{Cov}\\!\\left( \\widehat{A}_k, \\widehat{A}_{\\ell} \\right),\n$$\n其中 $\\alpha_k = \\frac{W_k^{+} W_k^{-}}{W^{+} W^{-}}$ 是聚合权重。方差 $\\operatorname{Var}(\\widehat{A}_k)$ 来自U-统计量的Hoeffding分解。令 $h(s_i,s_j) = \\mathbb{1}(s_i  s_j) + \\tfrac{1}{2}\\,\\mathbb{1}(s_i = s_j)$。在单个参数上的投影得出（期望是关于以折 $k$ 的训练模型为条件的信号和本底的事例加权分布来计算的）\n$$\n\\phi_k^{+}(i) = \\mathbb{E}_{j \\in T_k^{-}}\\!\\left[ \\frac{w_j}{W_k^{-}}\\, h(s_i, s_j) \\right], \\quad \\phi_k^{-}(j) = \\mathbb{E}_{i \\in T_k^{+}}\\!\\left[ \\frac{w_i}{W_k^{+}}\\, h(s_i, s_j) \\right].\n$$\n那么，在忽略低阶项的情况下，$\\widehat{A}_k$ 的方差表现为\n$$\n\\operatorname{Var}\\!\\left( \\widehat{A}_k \\right) \\approx \\operatorname{Var}\\!\\left( \\sum_{i \\in T_k^{+}} \\frac{w_i}{W_k^{+}}\\, \\phi_k^{+}(i) \\right) + \\operatorname{Var}\\!\\left( \\sum_{j \\in T_k^{-}} \\frac{w_j}{W_k^{-}}\\, \\phi_k^{-}(j) \\right).\n$$\n对于独立的事件和固定的折 $k$ 的训练模型，主导项与由权重决定的有效样本量成比例。定义有效样本量\n$$\nn_{\\mathrm{eff},k}^{+} = \\frac{\\left( \\sum_{i \\in T_k^{+}} w_i \\right)^{2}}{\\sum_{i \\in T_k^{+}} w_i^{2}}, \\quad n_{\\mathrm{eff},k}^{-} = \\frac{\\left( \\sum_{j \\in T_k^{-}} w_j \\right)^{2}}{\\sum_{j \\in T_k^{-}} w_j^{2}}.\n$$\n权重中的大离散度（重尾或大动态范围）会减小 $n_{\\mathrm{eff}}$ 并增大 $\\operatorname{Var}(\\widehat{A}_k)$，即使基数 $|T_k^{+}|$ 和 $|T_k^{-}|$ 很大。\n\n折间协方差 $\\operatorname{Cov}(\\widehat{A}_k, \\widehat{A}_{\\ell})$ 的产生是因为折 $k$ 和折 $\\ell$ 的模型是在重叠的训练集 $R_k$ 和 $R_{\\ell}$ 上训练的，并且在这些重叠的样本上共享相同的内层交叉验证协议。尽管测试集不相交且分数对于其生成折是样本外的，但学习到的模型可能相关。当学习流程的性能在不同训练样本上表现出一致的波动时（例如，在对重叠部分有相似响应的超参数下），这会在 $\\widehat{A}_k$ 和 $\\widehat{A}_{\\ell}$ 之间引入正相关。事例权重也通过折内投影和这些折间相关性来传播方差：在 $R_k \\cap R_{\\ell}$ 中权重大的事例会影响两个模型，从而进一步增加协方差。因此，主要的方差来源是：\n- 由事例加权有效样本量 $n_{\\mathrm{eff},k}^{+}$ 和 $n_{\\mathrm{eff},k}^{-}$ 以及条件投影 $\\phi_k^{+}$ 和 $\\phi_k^{-}$ 的可变性控制的折内U-统计量方差，\n- 由于重叠的训练集、共享的内层交叉验证超参数选择以及由权重引起的有影响力的训练事例的杠杆作用而产生的折间协方差，\n- 模型不稳定性（例如，随机优化或特征选择），这会放大折内方差和折间协方差。\n\n总而言之，为了忠实地以 $A^{\\star}$ 为目标，估计量必须比较同一折内的配对（确保每对使用共同的训练模型）、适当地加权事例，并按与特定于折的总配对权重成比例的方式跨折聚合。由此产生的闭式估计量如下所示。", "answer": "$$\\boxed{\\widehat{A}_{\\text{nested}}=\\frac{1}{W^{+}W^{-}}\\sum_{k=1}^{K}\\sum_{i\\in T_{k}^{+}}\\sum_{j\\in T_{k}^{-}}w_{i}\\,w_{j}\\left[\\mathbb{1}\\!\\left(s_{i}s_{j}\\right)+\\frac{1}{2}\\,\\mathbb{1}\\!\\left(s_{i}=s_{j}\\right)\\right]}$$", "id": "3524133"}]}