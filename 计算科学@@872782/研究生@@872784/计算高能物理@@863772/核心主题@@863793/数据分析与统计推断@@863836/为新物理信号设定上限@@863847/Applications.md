## 应用与[交叉](@entry_id:147634)学科联系

### 引言

前面的章节已经系统地阐述了为新物理信号设定置信上限所依据的核心统计原理与机制。我们已经学习了似然函数、检验统计量以及以 $CL_s$ 方法为代表的频率主义程序。然而，理论知识与现实世界中粒子物理实验的复杂性之间存在着巨大的鸿沟。真实的分析并非在理想化的单通道、无系统误差的环境下进行；相反，它们涉及多个数据通道的组合、大量相关或不相关的系统不确定性源，以及需要精细建模的复杂背景。

本章的旨在架设一座桥梁，连接前述的理论基础与现代科学研究中设定上限的实际操作。我们将探讨一系列面向应用的问题，展示核心原理如何在多样化、跨学科的真实场景中被运用、扩展和整合。我们的目标不是重复讲授核心概念，而是演示它们的实用性、揭示它们在面对真实数据挑战时的微妙之处，并阐明从统计结果中提取有意义物理结论的完整工作流程。通过本章的学习，读者将能够理解一个典型的粒子物理分析是如何从原始数据走向最终发表的物理结果，并体会到其中严谨的统计思维。

### 构建物理分析的[似然](@entry_id:167119)模型

任何统计推断的核心都是一个能够准确描述实验数据的[概率模型](@entry_id:265150)。在粒子物理学中，这个模型通常以似然函数 $\mathcal{L}(\boldsymbol{\mu}, \boldsymbol{\theta})$ 的形式出现，其中 $\boldsymbol{\mu}$ 是我们感兴趣的物理参数（如信号强度），而 $\boldsymbol{\theta}$ 是一组“[讨厌参数](@entry_id:171802)”（Nuisance Parameters），用于描述各种系统不确定性。构建一个真实可信的似然函数是整个分析工作的基石。

#### [分箱似然](@entry_id:746807)与模板拟合

高能物理中的许多测量是在某个[可观测量](@entry_id:267133)（如[不变质量](@entry_id:265871)、横动量）的[分布](@entry_id:182848)上寻找信号。通常，分析会将这个[分布](@entry_id:182848)划分成一系列离散的“计数箱”（bin），并将每个箱子中的事件数作为独立的泊松过程来处理。模型对第 $i$ 个箱子中事件数 $\nu_i$ 的期望由信号和背景过程的贡献相加而成。

一个标准的方法是“模板拟合”（template fit）。在这种方法中，我们利用[蒙特卡洛模拟](@entry_id:193493)为信号和各种背景过程分别生成预期的[分布](@entry_id:182848)形状，即“模板”。例如，在寻找一个新粒子时，第 $i$ 个箱子中的期望事件数可以建模为：
$$
\nu_i(\mu, \boldsymbol{\theta}) = \mu s_i(\boldsymbol{\theta}) + b_i(\boldsymbol{\theta})
$$
其中 $s_i(\boldsymbol{\theta})$ 和 $b_i(\boldsymbol{\theta})$ 分别是信号和背景模板在第 $i$ 个箱子中的期望产额，它们都可能受到[讨厌参数](@entry_id:171802) $\boldsymbol{\theta}$ 的影响。信号强度参数 $\mu$ 则负责缩放信号模板的整体归一化。$\mu=0$ 对应于纯背景假说，而 $\mu=1$ 对应于信号以其标称强度存在的假说。

由于每个箱子的计数是独立的泊松过程，总的[似然函数](@entry_id:141927)是所有箱子[似然](@entry_id:167119)的乘积。此外，[讨厌参数](@entry_id:171802)本身通常受到来自[辅助测量](@entry_id:143842)的约束，这些约束以[概率密度函数](@entry_id:140610) $\pi_k(\theta_k)$ 的形式乘入总[似然函数](@entry_id:141927)。因此，一个完整的[分箱](@entry_id:264748)模板拟合的似然函数通常具有如下形式：
$$
\mathcal{L}(\mu, \boldsymbol{\theta}) = \left[ \prod_{i=1}^{N} \mathrm{Poisson}(n_i | \mu s_i(\boldsymbol{\theta}) + b_i(\boldsymbol{\theta})) \right] \times \left[ \prod_{k=1}^{K} \pi_k(\theta_k) \right]
$$
这里，$n_i$ 是在第 $i$ 个箱子中观测到的事件数。这个结构是现代[高能物理数据分析](@entry_id:750283)（例如LHC实验中广泛使用的HistFactory框架）的基石 [@problem_id:3533276]。

#### 将系统[不确定性建模](@entry_id:268420)为[讨厌参数](@entry_id:171802)

似然模型中的[讨厌参数](@entry_id:171802) $\boldsymbol{\theta}$ 是描述系统不确定性的关键。每种不确定性来源，无论是来自探测器标定、理论计算还是背景建模，都必须被参数化并整合进似然函数中。

一种常见的不确定性是归一化不确定性，它会同等地影响所有箱子的事件率。例如，实验的积分亮度 $\mathcal{L}$ 通常具有一个小的百分比不确定性 $\delta_L$。这可以被建模为一个[讨厌参数](@entry_id:171802) $\theta_L$，其先验约束为一个标准[高斯分布](@entry_id:154414) $\theta_L \sim \mathcal{N}(0, 1)$。信号产额会因此被一个缩放因子修正，例如 $\exp(\sigma \theta_L)$ 或 $(1 + \sigma \theta_L)$，其中 $\sigma$ 与 $\delta_L$ 相关。在进行统计推断时，需要通过“剖面化”（profiling）来处理这个[讨厌参数](@entry_id:171802)，即在似然函数中找到使其最大化的值，从而将亮度的不确定性效应边际化掉 [@problem_id:3533317]。

更复杂的是形状不确定性，它会改变模板的形状，即不同箱子之间的相对大小。一种强大的技术是“模板变形”（template morphing）。假设一个[讨厌参数](@entry_id:171802) $\theta$ 的 $\pm 1 \sigma$ 变化分别对应于两个备选的信号模板 $s_i^{\mathrm{up}}$ 和 $s_i^{\mathrm{down}}$。我们可以通过对中心模板 $s_i^0$ 和这两个备选模板进行线性插值，来构建一个依赖于 $\theta$ 的连续变化的模板：
$$
s_i(\theta) = s_i^0 + \theta \frac{s_i^{\mathrm{up}} - s_i^{\mathrm{down}}}{2}
$$
这个依赖于 $\theta$ 的模板随后被代入泊松似然中。同时，$\theta$ 自身也受到一个标准[高斯先验](@entry_id:749752) $\exp(-\theta^2/2)$ 的约束。这种方法允许拟合过程利用数据本身来约束形状不确定性的实际大小，从而得到更精确的结果 [@problem_id:3533275]。

#### 利用控制区约束不确定性

[讨厌参数](@entry_id:171802)的先验约束往往来自于探测器标定、理论计算等外部信息。然而，一种更强大的约束来自于数据本身，即利用“控制区”（Control Regions）。控制区是实验数据的一个[子集](@entry_id:261956)，其设计目标是富集某一种特定的背景过程，并且几乎不包含（或包含极少量可忽略的）信号。

通过在控制区进行测量，我们可以直接约束与该背景相关的[讨厌参数](@entry_id:171802)。例如，假设信号区（SR）的期望产额为 $\mu s + b$，其中背景 $b$ 的归一化不确定性很大。我们可以设计一个不含信号的控制区（CR），其期望产额为 $\alpha b$，其中 $\alpha$ 是从模拟中得到的已知转移因子。通过同时对SR和CR的事件数 $n^{\mathrm{SR}}$ 和 $n^{\mathrm{CR}}$ 进行[似然](@entry_id:167119)拟合，我们可以构建一个[联合似然](@entry_id:750952)函数：
$$
\mathcal{L}(\mu, b) = \mathrm{Poisson}(n^{\mathrm{SR}} | \mu s + b) \times \mathrm{Poisson}(n^{\mathrm{CR}} | \alpha b)
$$
在这个模型中，CR的观测值 $n^{\mathrm{CR}}$ 为参数 $b$ 提供了一个 *in situ* 的测量。如果没有CR，$\mu s$ 和 $b$ 在SR中是完全简并的，我们无法区分一个小的信号和一个背景的向下浮动。CR的引入打破了这种简并，极大地增强了对 $b$ 的约束，从而提高了对信号强度 $\mu$ 的测量灵敏度，最终得到更强的置信上限 [@problem_id:3533273]。这是现代粒子物理分析中一项极其关键和普遍的技术。

### 组合测量与处理相关性

为了最大化发现新物理的潜力，物理学家通常会将来自不同衰变通道、不同实验甚至不同时期的测量结果组合起来。这种[组合分析](@entry_id:265559)能够有效利用所有可用的信息，但同时也引入了如何正确处理不同来源之间相关性的挑战。

#### 独立通道的统计组合

最简单的组合情况是合并几个统计独立的通道。例如，一个新粒子可能衰变到电子对（channel 1）和缪子对（channel 2）。假设这两个通道的背景和探测器效应是独立的，但它们共享一些共同的系统不确定性，例如积分亮度不确定性和信号产生的理论[截面](@entry_id:154995)不确定性。

在这种情况下，总的似然函数是各个通道似然函数的乘积，而共享的[讨厌参数](@entry_id:171802)（如 $\ell$ 代表亮度，$\tau$ 代表理论不确定性）则在所有通道中同时出现：
$$
L_{\text{total}}(\mu, \ell, \tau) = L_1(n_1 | \mu, \ell, \tau) \times L_2(n_2 | \mu, \ell, \tau) \times \pi(\ell) \times \pi(\tau)
$$
在对这个[联合似然](@entry_id:750952)进行剖面化时，所有通道的数据都会共同约束共享的[讨厌参数](@entry_id:171802) $\ell$ 和 $\tau$。有趣的是，在某些[渐近近似](@entry_id:275870)下，对于在背景之上寻找一个小信号的情况（即在 $\mu=0$ 附近），信号强度的不确定性可能与这些共享的归一化不确定性解耦。这意味着，在这种特定情况下，[组合分析](@entry_id:265559)的主要优势来自于统计量的增加（即 $\sigma_{\mu}^{-2} = \sum_i s_i^2/b_i$），而不是来自于对共享不确定性的更好约束 [@problem_id:3533288]。

#### 相关不确定性的影响

在更真实的场景中，不同通道或不同计数箱之间的系统不确定性往往是部分相关的。例如，喷注能量刻度的不确定性可能会以一种相似但非完全相同的方式影响两个不同的分析通道。这种相关性必须被正确建模，否则会导致不正确的结果。

相关性通常通过[讨厌参数](@entry_id:171802)的协方差矩阵 $\mathbf{V}$ 来描述。假设两个通道的背景不确定性分别由 $\theta_1$ 和 $\theta_2$ 描述，它们之间存在一个相关系数 $\rho$。高斯约束项将变为一个多维[高斯函数](@entry_id:261394)，其指数项包含[精度矩阵](@entry_id:264481)（协方差矩阵的逆）$\mathbf{V}^{-1}$。

相关性的影响是微妙而重要的。正相关（$\rho0$）意味着两个通道的背景倾向于向同一个方向（一起增加或一起减少）浮动。当信号本身也在两个通道中都产生正贡献时，这种背景的协同浮动行为能够更好地“模仿”信号，从而使得信号更难与背景区分开来。这降低了分析的灵敏度，导致更弱的（即数值上更大）置信上限。相反，负相关（$\rho0$）意味着背景倾向于向相反方向浮动（一个通道增加，另一个减少），这种模式与信号的模式（在两个通道都增加）截然不同，使得信号更容易被识别，从而可能得到更强的置信上限。因此，在[组合分析](@entry_id:265559)中，准确地评估和建模不确定性之间的相关性是至关重要的 [@problem_id:3533286] [@problem_id:3533313]。

#### 跨[参数空间](@entry_id:178581)的相关性：构建排除曲线

当我们在一个连续的参数（如新粒子的质量 $m$）上设定排除极限时，我们实际上是在一系列离散的质量假设点 $\{m_i\}$ 上分别进行分析。许多系统不确定性，例如信号接收度（acceptance）的不确定性，在不同的质量点之间是相关的。例如，由于喷注能量刻度不确定性导致的影响在质量为 1 TeV 和 1.1 TeV 时可能是非常相似的，但在 1 TeV 和 5 TeV 时可能就完全不同。

为了正确处理这种跨质量点的相关性，我们需要构建一个覆盖所有质量点的[联合似然](@entry_id:750952)函数。这可以通过引入一个[讨厌参数](@entry_id:171802)向量 $\boldsymbol{\theta} = (\theta_1, \dots, \theta_N)^{\top}$ 来实现，其中每个 $\theta_i$ 对应于一个质量点 $m_i$ 的不确定性。这个向量的先验约束是一个多维高斯分布，其[协方差矩阵](@entry_id:139155) $\boldsymbol{\rho}$ 的元素 $\rho_{ij}$ 描述了质量点 $m_i$ 和 $m_j$ 之间不确定性的相关性。

一种数学上等价且计算上更方便的方法是，引入一组独立的标准正态[潜变量](@entry_id:143771) $\boldsymbol{z}$，并通过一个矩阵 $\boldsymbol{L}$（例如通过[Cholesky分解](@entry_id:147066)得到，满足 $\boldsymbol{\rho} = \boldsymbol{L}\boldsymbol{L}^{\top}$）将它们与物理的[讨厌参数](@entry_id:171802)联系起来，即 $\boldsymbol{\theta} = \boldsymbol{L}\boldsymbol{z}$。通过这种方式，复杂的协方差矩阵被[对角化](@entry_id:147016)，简化了似然函数的计算，同时完整地保留了所有相关性信息。这种严谨的处理确保了最终得到的排除曲线在整个质量范围内都是统计稳健的 [@problem_id:3533269]。

### 模型构建与诠释中的高等课题

随着分析精度的提高，一些更细微的效应开始变得重要。本节将讨论几个在模型构建和结果诠释中常见的高等课题。

#### 模拟的不确定性：Barlow-Beeston方法

我们通常依赖[蒙特卡洛](@entry_id:144354)（MC）模拟来获得背景模板。然而，MC样本本身由于其有限的统计量，也存在[统计不确定性](@entry_id:267672)。如果MC统计量远大于数据统计量，这种不确定性可以忽略不计。但当某些箱子中的MC事件数很少（甚至为零）时，这种不确定性就必须被考虑在内。

处理MC[统计不确定性](@entry_id:267672)的一种标准方法是Barlow-Beeston方法。该方法为每个箱子 $i$ 引入一个独立的[讨厌参数](@entry_id:171802) $b_i$，代表该箱子中真实的背景期望产额。然后，利用MC事件数 $m_i$ 和数据事件数 $n_i$ 构建一个联合泊松似然，从而在拟合中直接约束 $b_i$。在低MC统计量的箱子中，这种方法可能会低估不确定性，导致过于激进的（反保守的）置信上限。

另一种方法是采用[分层贝叶斯模型](@entry_id:169496)，将 $b_i$ 视为一个[随机变量](@entry_id:195330)，其[先验分布](@entry_id:141376)（通常是Gamma[分布](@entry_id:182848)）由MC观测 $m_i$ 决定。然后，通过对 $b_i$ 进行积分（边际化），得到一个只依赖于 $\mu$ 的[边际似然](@entry_id:636856)。这种方法在低统计量区域通常表现得更稳健。比较这两种方法的差异，特别是在极端情况下，有助于理解[模型选择](@entry_id:155601)对最终结果的影响 [@problem_id:3533295]。

#### 与理论的互动：处理理论不确定性

新物理信号的理论预测（例如产生[截面](@entry_id:154995) $\sigma_{\mathrm{th}}$）本身也存在不确定性，这些不确定性源于如[重整化](@entry_id:143501)和因子化尺度的选择、[部分子分布函数](@entry_id:156490)（PDF）的不确定性等。这些不确定性并非统计性质，而是反映了我们理论计算的局限性。如何在实验限制中恰当地包含这些理论不确定性，是一个重要的跨学科问题。

主要有两种处理方式：
1.  **内部剖面化（Internal Profiling）**: 将理论[不确定性建模](@entry_id:268420)为一个或多个[讨厌参数](@entry_id:171802)（例如，一个缩放因子 $\tau$ 作用于信号产额上），并像处理实验系统不确定性一样，在似然函数中对其进行剖面化。这种方法的优点是提供了一个统一的统计框架。但缺点是，它可能导致信号强度 $\mu$ 和理论缩放因子 $\tau$ 之间存在简并性，使得数据可以“吸收”一部分信号到理论不确定性中，从而削弱对 $\mu$ 的限制。
2.  **外部包络法（External Envelope）**: 在设定极限的拟合过程中不包含理论不确定性（即固定 $\tau=1$），得到一个关于 $\mu$ 的极限。然后，通过在理论不确定性带（例如，$\sigma_{\mathrm{th}}$ 的 $\pm 1\sigma$ 范围）内扫描理论参数，并取最保守（最弱）的极限作为最终结果。这种方法保证了结果对于理论不确定性是保守的，并且避免了将理论不确定性“拟合掉”的问题，特别是在设定模型参数（如质量）的极限时更为稳健。

在报告结果时，通常的最佳实践是清晰地将实验测量的不确定性与理论模型的不确定性分开。例如，可以报告一个在标称理论下的 $\mu$ 的极限，并单独展示理论不确定性对该极限的影响带 [@problem_id:3533344]。

#### 与展开的联系：在展开谱上设定极限

在许多分析中，为了校正探测器效应（如有限的分辨率和效率），测量的[分布](@entry_id:182848)需要通过一个称为“展开”（unfolding）的统计过程来转换到“真实”的物理量层面。在展开后的谱上设定信号极限是一个复杂的课题，因为它需要正确地传播展开过程引入的统计和系统不确定性。

展开后的谱通常表示为一个向量 $\boldsymbol{U}$，其协方差矩阵 $\boldsymbol{C}$ 不仅包含了原始数据的[统计不确定性](@entry_id:267672)，还包含了展开过程本身引入的相关性。此外，为了稳定展开过程而使用的正则化（regularization）会引入一种“偏倚”（bias），它会系统性地扭曲真实的物理[分布](@entry_id:182848)。在设定极限时，这种偏倚必须被建模为对信号模板的修正，例如 $S_{\text{eff}} = (1-\alpha)S$，其中 $\alpha$ 是正则化强度因子。只有当[协方差矩阵](@entry_id:139155) $\boldsymbol{C}$ 和正则化偏倚都被正确地包含在[似然](@entry_id:167119)模型中时，得到的极限才是有效的和具有正确统计覆盖率的 [@problem_id:3533315]。

### 从统计结果到物理陈述

一个分析的最终目标是发布一个清晰、稳健且易于理解的物理结论。这需要从原始的[统计计算](@entry_id:637594)结果进行最后几步关键的诠释。

#### 预测灵敏度：[Asimov数据集](@entry_id:746529)与“玩具”蒙特卡洛

在真正分析数据之前，以及为了诠释最终结果，我们需要评估实验的“灵敏度”（sensitivity），即它排除或发现一个给定信号的能力。

一种高效的方法是使用“Asimov”数据集。这是一个人工构造的数据集，其中每个箱子的观测值都被设定为其在某个特定假说（通常是纯背景假说，$\mu=0$）下的[期望值](@entry_id:153208)。通过在这个没有统计涨落的“典型”数据集上计算置信上限，我们可以得到预期的[中位数](@entry_id:264877)（median expected）极限。这是一个快速评估实验灵敏度的标准方法 [@problem_id:3533278]。

为了获得对灵敏度更完整的描述，我们需要考虑统计涨落的影响。这通过生成大量“玩具”蒙特卡洛（toy MC）实验来实现。在每个玩具实验中，我们从背景假说的泊松分布中随机生成伪数据，然后对这些伪数据运行完整的限制设定程序，得到一个上限值。重复此过程数千次，我们将得到一个上限值的[分布](@entry_id:182848)。这个[分布](@entry_id:182848)的[中位数](@entry_id:264877)应该与Asimov极限一致，而其分位数（例如，$\pm 1\sigma$ 和 $\pm 2\sigma$ 区间）则构成了我们熟悉的“巴西图”（Brazil plot）中的黄色和绿色带，全面地展示了预期的灵敏度范围 [@problem_id:3533326]。

#### 确保稳健性：功率约束极限与CLs

标准的频率主义极限设定程序在某些情况下可能会产生问题。特别是当观测数据出现显著的向下浮动时（即观测值远低于背景期望），程序可能会给出一个比实验灵敏度强得多的、看似非常严格的置信上限。这样的结果是误导性的，因为它更多地反映了统计侥幸，而不是探测器的真实能力。

为了避免这种情况，发展了如“功率约束极限”（Power-Constrained Limits, PCL）和 $CL_s$ 方法等修正程序。这些方法的核心思想是，一个有效的排除不仅需要与观测数据不相容，还需要实验本身有足够的能力（统计“功率”）来排除该信号。PCL通过设定一个“灵敏度底线” $\mu_{\min}$ 来实现这一点，该底线被定义为实验有足够大概率（例如80%）可以排除的最小信号强度。最终报告的极限被取为观测极限和这个灵敏度底线中较弱（较大）的一个。这确保了即使在出现大的向下浮动时，报告的极限也不会不切实际地优于实验的内在灵敏度，从而提供了更诚实和稳健的结果 [@problem_id:3533281]。

#### 最后一步：从事件数限制到物理参数

统计分析的直接产出通常是对信号事件数 $N$ 或信号强度参数 $\mu$ 的一个置信上限。然而，物理学家和理论家更关心的是基本的物理参数，如新粒子的产生[截面](@entry_id:154995) $\sigma$ 或衰变分支比 $\mathcal{B}$。

最后一步就是将事件数层面的限制“翻译”成物理参数的限制。这需要利用一个连接两者的关系式，该关系式通常包含以下几个要素：总的产生[截面](@entry_id:154995)、积分亮度、探测器的接收度和效率等。例如，一个对分支比 $\mathcal{B}$ 的上限可以通过以下公式计算：
$$
\mathcal{B}_{95} = \frac{N_{95}}{\sigma_{\text{prod}} \times \mathcal{L} \times A \times \varepsilon}
$$
其中 $N_{95}$ 是从数据中得到的信号事件数上限，而分母中的各项则来自于理论计算和探测器模拟。完成这一步，分析就最终从探测器中的事件计数，得到了对自然界基本规律的一个有意义的约束 [@problem_id:3533335]。