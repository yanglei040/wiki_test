{"hands_on_practices": [{"introduction": "在我们着手修正探测器效应（即“展开”）之前，我们必须首先精确地构建一个前向模型，描述探测器如何扭曲真实的物理信号。这项实践提供了将原始蒙特卡洛模拟输出转化为概率响应矩阵的基本技能，该矩阵是此模型的核心。通过处理一个具体的计数实验，您将亲手计算表征探测器性能的关键量，如效率和迁移矩阵 [@problem_id:3540787]。", "problem": "一个探测器通过蒙特卡洛（MC）方法模拟一个物理过程。该过程的粒子层面（真实）相空间被划分为三个由 $i \\in \\{1,2,3\\}$ 索引的区间，其重建（reco）相空间被划分为四个由 $j \\in \\{1,2,3,4\\}$ 索引的区间。令 $N_{i}^{\\text{truth}}$ 表示在真实区间 $i$ 中生成的 MC 真实事件的总数，令 $N_{ji}$ 表示这些真实区间 $i$ 的事件中，被探测器模拟重建到重建区间 $j$ 的事件数量。MC 产额如下：\n- 真实计数：$N_{1}^{\\text{truth}}=1000$, $N_{2}^{\\text{truth}}=1200$, $N_{3}^{\\text{truth}}=800$。\n- 迁移计数（给定真实区间，重建的结果）：对于 $i=1$，$(N_{1,1},N_{2,1},N_{3,1},N_{4,1})=(320,280,100,50)$；对于 $i=2$，$(N_{1,2},N_{2,2},N_{3,2},N_{4,2})=(150,420,360,90)$；对于 $i=3$，$(N_{1,3},N_{2,3},N_{3,3},N_{4,3})=(40,160,280,120)$。\n\n从频率学派对概率和条件概率的定义出发，并将 MC 视为这些概率的大样本估计量，推导并计算：\n1. 接收度（也称为包含非效率的响应）矩阵 $A_{ji}$，其概念上定义为：给定事件位于真实区间 $i$，其被重建到重建区间 $j$ 的条件概率，此概率根据 MC 计数进行估计。\n2. 每个真实区间 $i$ 的效率 $\\epsilon_{i}$，其概念上定义为：一个位于真实区间 $i$ 的事件被重建到四个重建区间中任意一个的总概率。\n3. 接收度修正后的响应 $\\tilde{R}_{ji}$，其概念上定义为：给定事件位于真实区间 $i$ 且该事件已被重建（即以接收度为条件），其被重建到重建区间 $j$ 的条件概率，该值通过将 $A_{ji}$ 的每个真实区间列除以其对应的 $\\epsilon_i$ 进行归一化得到。\n\n假设所有估计值均为计数的精确比值，不进行任何额外的正则化或平滑处理。将所有概率表示为精确的有理数，不进行四舍五入。使用 $\\mathrm{pmatrix}$ 环境，将您的最终答案以单个行向量的形式报告，并按以下顺序列出各项：\n- 首先是矩阵 $A_{ji}$，按真实区间 $i=1,2,3$ 逐列排列，每列内按 $j=1,2,3,4$ 排列；\n- 然后是效率 $(\\epsilon_{1},\\epsilon_{2},\\epsilon_{3})$；\n- 最后是接收度修正后的响应矩阵 $\\tilde{R}_{ji}$，按同样的逐列顺序列出。", "solution": "问题陈述已经过验证，被认为是自洽的、有科学依据且定义明确的。它提出了一个高能物理学中与探测器模拟和解卷积相关的标准计算任务。所有必要的数据和定义均已提供，且内部没有矛盾。因此，我们可以着手求解。\n\n问题要求计算三个描述探测器效应的相关量：接收度矩阵 $A_{ji}$、真实区间效率 $\\epsilon_i$ 以及接收度修正后的响应矩阵 $\\tilde{R}_{ji}$。我们将基于频率学派对概率的解释，并应用于所提供的蒙特卡洛（MC）事件计数，依次推导并计算每个量。\n\n令 $T_i$ 表示粒子在真实区间 $i$ 中生成的事件，令 $R_j$ 表示其在重建区间 $j$ 中被重建的事件。给定的计数为：\n- 在真实区间 $i$ 中生成的事件总数：$N(\\text{T}_i) = N_{i}^{\\text{truth}}$。\n- 在真实区间 $i$ 中生成并在重建区间 $j$ 中重建的事件数：$N(\\text{R}_j \\cap \\text{T}_i) = N_{ji}$。\n\n提供的数值为：\n- $N_{1}^{\\text{truth}} = 1000$, $N_{2}^{\\text{truth}} = 1200$, $N_{3}^{\\text{truth}} = 800$。\n- 对于 $i=1$：$(N_{1,1}, N_{2,1}, N_{3,1}, N_{4,1}) = (320, 280, 100, 50)$。\n- 对于 $i=2$：$(N_{1,2}, N_{2,2}, N_{3,2}, N_{4,2}) = (150, 420, 360, 90)$。\n- 对于 $i=3$：$(N_{1,3}, N_{2,3}, N_{3,3}, N_{4,3}) = (40, 160, 280, 120)$。\n\n所有概率都估计为计数的比值。\n\n**1. 接收度矩阵 $A_{ji}$**\n\n接收度矩阵 $A_{ji}$ 定义为：给定一个事件起源于真实区间 $i$，它被重建在重建区间 $j$ 的条件概率。这表示为 $P(\\text{R}_j | \\text{T}_i)$。使用频率学派对条件概率的定义，我们将其估计为：\n$$\nA_{ji} = P(\\text{R}_j | \\text{T}_i) = \\frac{N(\\text{R}_j \\cap \\text{T}_i)}{N(\\text{T}_i)} = \\frac{N_{ji}}{N_{i}^{\\text{truth}}}\n$$\n我们对每个真实区间 $i \\in \\{1,2,3\\}$，逐列计算这个 $4 \\times 3$ 矩阵的元素。\n\n对于真实区间 $i=1$ ($N_{1}^{\\text{truth}}=1000$):\n$A_{11} = \\frac{N_{11}}{N_{1}^{\\text{truth}}} = \\frac{320}{1000} = \\frac{8}{25}$\n$A_{21} = \\frac{N_{21}}{N_{1}^{\\text{truth}}} = \\frac{280}{1000} = \\frac{7}{25}$\n$A_{31} = \\frac{N_{31}}{N_{1}^{\\text{truth}}} = \\frac{100}{1000} = \\frac{1}{10}$\n$A_{41} = \\frac{N_{41}}{N_{1}^{\\text{truth}}} = \\frac{50}{1000} = \\frac{1}{20}$\n\n对于真实区间 $i=2$ ($N_{2}^{\\text{truth}}=1200$):\n$A_{12} = \\frac{N_{12}}{N_{2}^{\\text{truth}}} = \\frac{150}{1200} = \\frac{1}{8}$\n$A_{22} = \\frac{N_{22}}{N_{2}^{\\text{truth}}} = \\frac{420}{1200} = \\frac{7}{20}$\n$A_{32} = \\frac{N_{32}}{N_{2}^{\\text{truth}}} = \\frac{360}{1200} = \\frac{3}{10}$\n$A_{42} = \\frac{N_{42}}{N_{2}^{\\text{truth}}} = \\frac{90}{1200} = \\frac{3}{40}$\n\n对于真实区间 $i=3$ ($N_{3}^{\\text{truth}}=800$):\n$A_{13} = \\frac{N_{13}}{N_{3}^{\\text{truth}}} = \\frac{40}{800} = \\frac{1}{20}$\n$A_{23} = \\frac{N_{23}}{N_{3}^{\\text{truth}}} = \\frac{160}{800} = \\frac{1}{5}$\n$A_{33} = \\frac{N_{33}}{N_{3}^{\\text{truth}}} = \\frac{280}{800} = \\frac{7}{20}$\n$A_{43} = \\frac{N_{43}}{N_{3}^{\\text{truth}}} = \\frac{120}{800} = \\frac{3}{20}$\n\n**2. 效率 $\\epsilon_i$**\n\n真实区间 $i$ 的效率 $\\epsilon_i$ 是指来自该区间的事件被重建到*任意一个*重建区间的总概率。这是对所有可能的重建结果 $j$ 的条件概率之和。\n$$\n\\epsilon_i = P(\\text{reconstructed} | \\text{T}_i) = \\sum_{j=1}^{4} P(\\text{R}_j | \\text{T}_i) = \\sum_{j=1}^{4} A_{ji}\n$$\n等效地，它是起源于真实区间 $i$ 的重建事件总数除以在真实区间 $i$ 中生成的事件总数。\n$$\n\\epsilon_i = \\frac{\\sum_{j=1}^{4} N_{ji}}{N_{i}^{\\text{truth}}}\n$$\n我们为每个真实区间 $i \\in \\{1,2,3\\}$ 计算 $\\epsilon_i$。\n\n对于真实区间 $i=1$:\n$\\epsilon_1 = \\frac{320+280+100+50}{1000} = \\frac{750}{1000} = \\frac{3}{4}$\n\n对于真实区间 $i=2$:\n$\\epsilon_2 = \\frac{150+420+360+90}{1200} = \\frac{1020}{1200} = \\frac{17}{20}$\n\n对于真实区间 $i=3$:\n$\\epsilon_3 = \\frac{40+160+280+120}{800} = \\frac{600}{800} = \\frac{3}{4}$\n\n**3. 接收度修正后的响应 $\\tilde{R}_{ji}$**\n\n接收度修正后的响应 $\\tilde{R}_{ji}$ 是指，给定一个事件起源于真实区间 $i$ *且*它已被重建，该事件被重建在重建区间 $j$ 的条件概率。令 ‘Reco'd’ 表示粒子在任意区间被重建的事件。那么 $\\tilde{R}_{ji} = P(\\text{R}_j | \\text{T}_i \\cap \\text{Reco'd})$。\n根据条件概率的定义：\n$$\n\\tilde{R}_{ji} = \\frac{P(\\text{R}_j \\cap (\\text{T}_i \\cap \\text{Reco'd}))}{P(\\text{T}_i \\cap \\text{Reco'd})}\n$$\n因为事件 $\\text{R}_j$ 蕴含了事件 ‘Reco'd’，所以交集 $\\text{R}_j \\cap \\text{Reco'd}$ 就是 $\\text{R}_j$。因此，分子变为 $P(\\text{R}_j \\cap \\text{T}_i)$。表达式简化为：\n$$\n\\tilde{R}_{ji} = \\frac{P(\\text{R}_j \\cap \\text{T}_i)}{P(\\text{Reco'd} \\cap \\text{T}_i)}\n$$\n将分子和分母同时除以 $P(\\text{T}_i)$ 得：\n$$\n\\tilde{R}_{ji} = \\frac{P(\\text{R}_j \\cap \\text{T}_i) / P(\\text{T}_i)}{P(\\text{Reco'd} \\cap \\text{T}_i) / P(\\text{T}_i)} = \\frac{P(\\text{R}_j | \\text{T}_i)}{P(\\text{Reco'd} | \\text{T}_i)} = \\frac{A_{ji}}{\\epsilon_i}\n$$\n这证实了将 $A_{ji}$ 的每一列除以对应的效率 $\\epsilon_i$ 进行归一化的方法是正确的。对于每个真实区间 $i$，列 $\\tilde{R}_{ji}$ 是一个经过适当归一化的概率分布，即 $\\sum_{j=1}^{4} \\tilde{R}_{ji} = 1$。\n\n对于真实区间 $i=1$ ($\\epsilon_1 = 3/4$):\n$\\tilde{R}_{11} = \\frac{A_{11}}{\\epsilon_1} = \\frac{8/25}{3/4} = \\frac{32}{75}$\n$\\tilde{R}_{21} = \\frac{A_{21}}{\\epsilon_1} = \\frac{7/25}{3/4} = \\frac{28}{75}$\n$\\tilde{R}_{31} = \\frac{A_{31}}{\\epsilon_1} = \\frac{1/10}{3/4} = \\frac{4}{30} = \\frac{2}{15}$\n$\\tilde{R}_{41} = \\frac{A_{41}}{\\epsilon_1} = \\frac{1/20}{3/4} = \\frac{4}{60} = \\frac{1}{15}$\n\n对于真实区间 $i=2$ ($\\epsilon_2 = 17/20$):\n$\\tilde{R}_{12} = \\frac{A_{12}}{\\epsilon_2} = \\frac{1/8}{17/20} = \\frac{20}{136} = \\frac{5}{34}$\n$\\tilde{R}_{22} = \\frac{A_{22}}{\\epsilon_2} = \\frac{7/20}{17/20} = \\frac{7}{17}$\n$\\tilde{R}_{32} = \\frac{A_{32}}{\\epsilon_2} = \\frac{3/10}{17/20} = \\frac{60}{170} = \\frac{6}{17}$\n$\\tilde{R}_{42} = \\frac{A_{42}}{\\epsilon_2} = \\frac{3/40}{17/20} = \\frac{60}{680} = \\frac{3}{34}$\n\n对于真实区间 $i=3$ ($\\epsilon_3 = 3/4$):\n$\\tilde{R}_{13} = \\frac{A_{13}}{\\epsilon_3} = \\frac{1/20}{3/4} = \\frac{4}{60} = \\frac{1}{15}$\n$\\tilde{R}_{23} = \\frac{A_{23}}{\\epsilon_3} = \\frac{1/5}{3/4} = \\frac{4}{15}$\n$\\tilde{R}_{33} = \\frac{A_{33}}{\\epsilon_3} = \\frac{7/20}{3/4} = \\frac{28}{60} = \\frac{7}{15}$\n$\\tilde{R}_{43} = \\frac{A_{43}}{\\epsilon_3} = \\frac{3/20}{3/4} = \\frac{12}{60} = \\frac{1}{5} = \\frac{3}{15}$\n\n按照要求将所有结果合并到一个行向量中，即可完成任务。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n\\frac{8}{25}  \\frac{7}{25}  \\frac{1}{10}  \\frac{1}{20}  \\frac{1}{8}  \\frac{7}{20}  \\frac{3}{10}  \\frac{3}{40}  \\frac{1}{20}  \\frac{1}{5}  \\frac{7}{20}  \\frac{3}{20}  \\frac{3}{4}  \\frac{17}{20}  \\frac{3}{4}  \\frac{32}{75}  \\frac{28}{75}  \\frac{2}{15}  \\frac{1}{15}  \\frac{5}{34}  \\frac{7}{17}  \\frac{6}{17}  \\frac{3}{34}  \\frac{1}{15}  \\frac{4}{15}  \\frac{7}{15}  \\frac{3}{15}\n\\end{pmatrix}\n}\n$$", "id": "3540787"}, {"introduction": "直接的逆运算（朴素展开）在处理含有噪声的数据时通常是不稳定的，会导致振荡且不符合物理实际的结果。这项编码练习将深入探讨不同的正则化策略如何解决这一问题，特别是当真实信号包含尖锐边缘（如此处的效率阈值）时。您将通过实现和比较无正则化的最小二乘法、Tikhonov ($L_2$) 正则化和总变差 ($L_1$) 正则化，直观地理解它们在平滑噪声和保持信号特征之间的权衡 [@problem_id:3540846]。", "problem": "给定一个一维展开问题，该问题模拟了探测器模糊效应以及在某个阈值处的急剧效率下降。其基本基础是连接未知真实能谱与测量能谱的线性正演模型。设 $N$ 表示区间数量，$\\mathbf{t} \\in \\mathbb{R}^{N}$ 表示未知的真实区间内容，$\\mathbf{m} \\in \\mathbb{R}^{N}$ 表示测量的区间内容。探测器响应由一个矩阵 $\\mathbf{A} \\in \\mathbb{R}^{N \\times N}$ 建模，因此正演模型为\n$$\n\\mathbf{m} = \\mathbf{A} \\mathbf{t}.\n$$\n响应矩阵包含了逐区间的效率 $\\varepsilon_i$ 和分辨率模糊。模糊效应由区间空间中宽度为 $\\sigma$ 的高斯核建模，而效率则对每个真实区间以乘法方式施加。对于每个真实区间索引 $i \\in \\{0,\\dots,N-1\\}$，$\\mathbf{A}$ 的第 $i$ 列由下式给出\n$$\nA_{j i} = \\varepsilon_i \\, \\frac{\\exp\\left( -\\frac{(j-i)^2}{2 \\sigma^2} \\right)}{\\sum\\limits_{k=0}^{N-1} \\exp\\left( -\\frac{(k-i)^2}{2 \\sigma^2} \\right)}, \\quad j \\in \\{0,\\dots,N-1\\}.\n$$\n效率模型在阈值区间索引 $\\theta$ 处存在一个急剧下降。具体来说，\n$$\n\\varepsilon_i = \\begin{cases}\n1,  i  \\theta, \\\\\n\\varepsilon_{\\mathrm{drop}},  i \\ge \\theta,\n\\end{cases}\n$$\n其中 $0  \\varepsilon_{\\mathrm{drop}}  1$。\n\n您的任务是根据上述定义构建响应矩阵，从已知的真实能谱合成测量能谱，并使用三种方法进行展开：无正则化的最小二乘法、使用一阶差分二次惩罚的 Tikhonov 正则化，以及使用一阶差分 $\\ell_1$ 惩罚的总变差 (TV) 正则化。展开后的能谱估计值分别表示为 $\\widehat{\\mathbf{t}}_{\\mathrm{LS}}$、$\\widehat{\\mathbf{t}}_{\\mathrm{Tik}}$ 和 $\\widehat{\\mathbf{t}}_{\\mathrm{TV}}$。\n\n1. 正演模型与真实能谱：\n   - 使用 $N = 50$ 个区间。\n   - 使用真实能谱 $\\mathbf{t}$，其分量为 $t_i = 1$ (对于所有 $i \\in \\{0,\\dots,N-1\\}$)。\n   - 根据测试套件中指定的参数，使用高斯模糊宽度 $\\sigma$ 以及阈值为 $\\theta$ 和下降值为 $\\varepsilon_{\\mathrm{drop}}$ 的效率模型来构建 $\\mathbf{A}$。\n\n2. 展开方法：\n   - 无正则化最小二乘法：求解\n     $$\n     \\widehat{\\mathbf{t}}_{\\mathrm{LS}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2.\n     $$\n   - Tikhonov 正则化（一阶差分二次）：设 $\\mathbf{D} \\in \\mathbb{R}^{(N-1)\\times N}$ 为一阶差分算子，定义为 $(\\mathbf{D}\\mathbf{x})_i = x_{i+1} - x_i$。对于给定的正则化强度 $\\alpha > 0$，求解\n     $$\n     \\widehat{\\mathbf{t}}_{\\mathrm{Tik}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2 + \\frac{\\alpha}{2} \\lVert \\mathbf{D}\\mathbf{x} \\rVert_2^2.\n     $$\n     这会得到正规方程组\n     $$\n     \\left( \\mathbf{A}^\\top \\mathbf{A} + \\alpha \\mathbf{D}^\\top \\mathbf{D} \\right) \\widehat{\\mathbf{t}}_{\\mathrm{Tik}} = \\mathbf{A}^\\top \\mathbf{m}.\n     $$\n   - 总变差 (TV) 正则化（一阶差分 $\\ell_1$）：对于给定的 TV 强度 $\\tau > 0$，求解\n     $$\n     \\widehat{\\mathbf{t}}_{\\mathrm{TV}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2 + \\tau \\lVert \\mathbf{D}\\mathbf{x} \\rVert_1.\n     $$\n     通过交替方向乘子法 (ADMM) 实现此方法，引入辅助变量 $\\mathbf{z} = \\mathbf{D}\\mathbf{x}$ 和惩罚参数 $\\rho > 0$，迭代过程如下\n     $$\n     \\mathbf{x}^{k+1} = \\left( \\mathbf{A}^\\top \\mathbf{A} + \\rho \\mathbf{D}^\\top \\mathbf{D} \\right)^{-1}\\left( \\mathbf{A}^\\top \\mathbf{m} + \\rho \\mathbf{D}^\\top(\\mathbf{z}^k - \\mathbf{u}^k) \\right),\n     $$\n     $$\n     \\mathbf{z}^{k+1} = \\operatorname{soft}\\left(\\mathbf{D}\\mathbf{x}^{k+1} + \\mathbf{u}^k, \\frac{\\tau}{\\rho}\\right),\n     $$\n     $$\n     \\mathbf{u}^{k+1} = \\mathbf{u}^k + \\mathbf{D}\\mathbf{x}^{k+1} - \\mathbf{z}^{k+1},\n     $$\n     其中软阈值算子按分量定义为 $\\operatorname{soft}(v, \\kappa) = \\operatorname{sign}(v)\\max(|v| - \\kappa, 0)$。\n\n3. 用于量化正则化器如何处理诱导边缘的指标：\n   对于每个展开能谱 $\\widehat{\\mathbf{t}}$ 和每个测试用例，计算：\n   - 均方误差 (MSE)：\n     $$\n     \\mathrm{MSE}(\\widehat{\\mathbf{t}}) = \\frac{1}{N} \\sum_{i=0}^{N-1} \\left( \\widehat{t}_i - t_i \\right)^2.\n     $$\n   - 阈值处的边缘残差幅度：\n     定义阈值索引为 $\\theta$。如果 $\\theta \\in \\{0,\\dots,N-2\\}$，使用\n     $$\n     E(\\widehat{\\mathbf{t}}) = \\left| \\widehat{t}_{\\theta+1} - \\widehat{t}_{\\theta} \\right|.\n     $$\n     如果 $\\theta = N-1$，使用\n     $$\n     E(\\widehat{\\mathbf{t}}) = \\left| \\widehat{t}_{\\theta} - \\widehat{t}_{\\theta-1} \\right|.\n     $$\n   - 相对于真实能谱的高能区平均偏差：\n     $$\n     B(\\widehat{\\mathbf{t}}) = \\frac{1}{N-\\theta} \\sum_{i=\\theta}^{N-1} \\widehat{t}_i - \\frac{1}{N-\\theta} \\sum_{i=\\theta}^{N-1} t_i.\n     $$\n     由于 $t_i = 1$，这可以简化为 $B(\\widehat{\\mathbf{t}}) = \\frac{1}{N-\\theta} \\sum_{i=\\theta}^{N-1} \\widehat{t}_i - 1$。\n\n4. 测试套件：\n   使用以下三组参数来构建响应矩阵，合成 $\\mathbf{m} = \\mathbf{A}\\mathbf{t}$，并进行展开：\n   - 情况 1（一般情况）：$N = 50$, $\\sigma = 1.5$, $\\theta = 30$, $\\varepsilon_{\\mathrm{drop}} = 0.05$, $\\alpha = 10^{-2}$, $\\tau = 10^{-2}$, $\\rho = 0.5$。\n   - 情况 2（边界阈值在最后一个区间）：$N = 50$, $\\sigma = 1.5$, $\\theta = 49$, $\\varepsilon_{\\mathrm{drop}} = 0.05$, $\\alpha = 10^{-2}$, $\\tau = 10^{-2}$, $\\rho = 0.5$。\n   - 情况 3（最小模糊，极端下降）：$N = 50$, $\\sigma = 0.5$, $\\theta = 25$, $\\varepsilon_{\\mathrm{drop}} = 0.01$, $\\alpha = 10^{-2}$, $\\tau = 10^{-2}$, $\\rho = 0.5$。\n\n5. 要求的最终输出格式：\n   您的程序应生成单行输出，其中包含一个列表的列表形式的结果，每个内部列表对应一个测试用例。对于每个测试用例，输出一个包含 9 个浮点数的列表，顺序如下：\n   $$\n   \\left[ \\mathrm{MSE}(\\widehat{\\mathbf{t}}_{\\mathrm{LS}}), \\, E(\\widehat{\\mathbf{t}}_{\\mathrm{LS}}), \\, B(\\widehat{\\mathbf{t}}_{\\mathrm{LS}}), \\, \\mathrm{MSE}(\\widehat{\\mathbf{t}}_{\\mathrm{Tik}}), \\, E(\\widehat{\\mathbf{t}}_{\\mathrm{Tik}}), \\, B(\\widehat{\\mathbf{t}}_{\\mathrm{Tik}}), \\, \\mathrm{MSE}(\\widehat{\\mathbf{t}}_{\\mathrm{TV}}), \\, E(\\widehat{\\mathbf{t}}_{\\mathrm{TV}}), \\, B(\\widehat{\\mathbf{t}}_{\\mathrm{TV}}) \\right].\n   $$\n   将三个测试用例按上述顺序汇总为一个列表，产生以下形式的输出\n   $$\n   \\left[ [\\cdots], [\\cdots], [\\cdots] \\right].\n   $$\n   不应打印任何其他文本。", "solution": "所提出的问题是计算高能物理学中一个明确定义的练习，具体涉及从测量的一维能谱中对探测器效应进行反卷积或“展开”。该问题具有科学依据，在数学上是一致的，并为求解提供了所有必要信息。\n\n问题的核心是线性正演模型，它通过探测器响应矩阵 $\\mathbf{A} \\in \\mathbb{R}^{N \\times N}$ 将未知的真实分布 $\\mathbf{t} \\in \\mathbb{R}^N$ 与测量分布 $\\mathbf{m} \\in \\mathbb{R}^N$ 联系起来。这种关系由下式给出：\n$$\n\\mathbf{m} = \\mathbf{A} \\mathbf{t}\n$$\n展开的目标是根据测量的能谱 $\\mathbf{m}$ 和响应矩阵 $\\mathbf{A}$ 来估计真实能谱 $\\mathbf{t}$。这是一个逆问题，由于 $\\mathbf{A}$ 的性质，通常是病态的。\n\n响应矩阵 $\\mathbf{A}$ 模拟了两种主要的探测器效应：分辨率模糊和探测效率。\n对于每个真实区间 $i$，$\\mathbf{A}$ 的相应列描述了源自区间 $i$ 的事件如何在测量的区间 $j$ 中分布。\n模糊效应由一个归一化的高斯核建模，其宽度为 $\\sigma$，代表了探测器的有限分辨率，这会使尖锐特征变得模糊。效率 $\\varepsilon_i$ 是每个真实区间的乘法因子，表示区间 $i$ 中的事件被探测到的总概率。问题指定了在阈值区间 $\\theta$ 处效率有一次急剧下降。因此，$\\mathbf{A}$ 的元素定义为：\n$$\nA_{j i} = \\varepsilon_i \\, \\frac{\\exp\\left( -\\frac{(j-i)^2}{2 \\sigma^2} \\right)}{\\sum_{k=0}^{N-1} \\exp\\left( -\\frac{(k-i)^2}{2 \\sigma^2} \\right)}\n$$\n其中效率 $\\varepsilon_i$ 是一个阶跃函数：\n$$\n\\varepsilon_i = \\begin{cases}\n1,  \\text{if } i  \\theta \\\\\n\\varepsilon_{\\mathrm{drop}},  \\text{if } i \\ge \\theta\n\\end{cases}\n$$\n利用已知的真实能谱 $\\mathbf{t}$（一个 $t_i=1$ 的平坦分布），测量的能谱 $\\mathbf{m}$ 被合成为 $\\mathbf{m} = \\mathbf{A} \\mathbf{t}$。\n\n采用三种展开方法从 $\\mathbf{m}$ 和 $\\mathbf{A}$ 估计 $\\mathbf{t}$。\n\n1.  **无正则化最小二乘法 (LS)**：这是解决逆问题的最直接方法。它旨在找到一个估计值 $\\widehat{\\mathbf{t}}_{\\mathrm{LS}}$，以最小化重新卷积后的估计值 $\\mathbf{A}\\mathbf{x}$ 与测量数据 $\\mathbf{m}$ 之间的平方差。目标函数是：\n    $$\n    \\widehat{\\mathbf{t}}_{\\mathrm{LS}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2\n    $$\n    这是一个标准的线性最小二乘问题，其解通过求解正规方程组得到：\n    $$\n    \\mathbf{A}^\\top \\mathbf{A} \\, \\widehat{\\mathbf{t}}_{\\mathrm{LS}} = \\mathbf{A}^\\top \\mathbf{m}\n    $$\n    然而，矩阵 $\\mathbf{A}^\\top \\mathbf{A}$ 通常是病态的，导致解对微小扰动高度敏感，这通常表现为大的、不符合物理规律的振荡。\n\n2.  **Tikhonov 正则化**：该方法通过添加一个正则化解并抑制振荡的惩罚项来扩展最小二乘法。这里使用的一个常见选择是惩罚解向量一阶差分的平方 $\\ell_2$-范数，以促进平滑性。一阶差分算子是一个矩阵 $\\mathbf{D} \\in \\mathbb{R}^{(N-1)\\times N}$。目标函数是：\n    $$\n    \\widehat{\\mathbf{t}}_{\\mathrm{Tik}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2 + \\frac{\\alpha}{2} \\lVert \\mathbf{D}\\mathbf{x} \\rVert_2^2\n    $$\n    这里，$\\alpha > 0$ 是正则化强度，它在拟合优度与解的平滑度之间取得平衡。这同样可以通过一组修正的正规方程组获得闭式解：\n    $$\n    \\left( \\mathbf{A}^\\top \\mathbf{A} + \\alpha \\mathbf{D}^\\top \\mathbf{D} \\right) \\widehat{\\mathbf{t}}_{\\mathrm{Tik}} = \\mathbf{A}^\\top \\mathbf{m}\n    $$\n    添加项 $\\alpha \\mathbf{D}^\\top \\mathbf{D}$ 通常会改善矩阵的条件数，从而得到更稳定的解。然而，这种正则化可能会过度平滑尖锐特征，例如由效率下降引起的边缘。\n\n3.  **总变差 (TV) 正则化**：该方法对一阶差分使用 $\\ell_1$-范数惩罚，该方法以其在平滑平坦区域的同时保留尖锐边缘的能力而闻名。目标函数是：\n    $$\n    \\widehat{\\mathbf{t}}_{\\mathrm{TV}} = \\operatorname*{arg\\,min}_{\\mathbf{x} \\in \\mathbb{R}^N} \\frac{1}{2} \\lVert \\mathbf{A}\\mathbf{x} - \\mathbf{m} \\rVert_2^2 + \\tau \\lVert \\mathbf{D}\\mathbf{x} \\rVert_1\n    $$\n    参数 $\\tau > 0$ 控制 TV 正则化的强度。与 Tikhonov 正则化不同，由于不可微的 $\\ell_1$-范数，此问题没有简单的闭式解。这里使用交替方向乘子法 (ADMM) 来求解。这种迭代算法引入一个辅助变量 $\\mathbf{z}$，并通过在主变量 $\\mathbf{x}$、辅助变量 $\\mathbf{z}$ 和对偶变量 $\\mathbf{u}$ 的更新之间交替来进行求解。按规定实现了更新步骤：\n    $\\mathbf{x}$-更新涉及求解一个与 Tikhonov 情况类似的线性系统。$\\mathbf{z}$-更新涉及一个分量的软阈值操作，这是促进差分 $\\mathbf{D}\\mathbf{x}$ 稀疏性的关键步骤，从而保留边缘。$\\mathbf{u}$-更新是强制执行约束 $\\mathbf{z} = \\mathbf{D}\\mathbf{x}$ 的简单步骤。\n\n最后，使用三个指标评估每种展开方法的性能：\n-   **均方误差 (MSE)**：$\\frac{1}{N} \\sum (\\widehat{t}_i - t_i)^2$。这提供了展开能谱准确性的全局度量。\n-   **边缘残差幅度 ($E$)**：$|\\widehat{t}_{\\theta+1} - \\widehat{t}_{\\theta}|$（或在边界处的类似形式）。这专门量化了真实能谱中的急剧下降（由效率模型隐式引入）被重建得有多好。由于真实能谱是平坦的（$t_i=1$），理想的差异是 $0$，但展开必须抵消效率阶跃的影响。这测试了正则化器处理边缘的能力。\n-   **高能区平均偏差 ($B$)**：$\\frac{1}{N-\\theta} \\sum_{i=\\theta}^{N-1} \\widehat{t}_i - 1$。这测量了在受效率下降影响的区域中，展开解的平均值与真实平均值之间的系统性偏差，量化了展开过程引入的任何偏差。\n\n实现将按部就班地进行：系统地构建矩阵，合成数据，应用三种展开算法中的每一种，并为每个测试用例计算九个指定的指标。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef run_case(N, sigma, theta, eps_drop, alpha, tau, rho):\n    \"\"\"\n    Runs a single test case for the unfolding problem.\n    \"\"\"\n    # 1. Setup: Define the true spectrum\n    t_true = np.ones(N)\n\n    # 2. Construct model matrices\n\n    # Construct efficiency vector\n    eps = np.ones(N)\n    if theta  N:\n        eps[theta:] = eps_drop\n\n    # Construct response matrix A\n    A = np.zeros((N, N))\n    indices = np.arange(N)\n    for i in range(N):\n        # Gaussian smearing kernel for column i\n        kernel_col = np.exp(-(indices - i)**2 / (2 * sigma**2))\n        # The kernel must be normalized to conserve events before efficiency\n        norm = np.sum(kernel_col)\n        if norm > 0:\n            kernel_col /= norm\n        # Apply efficiency\n        A[:, i] = eps[i] * kernel_col\n\n    # Construct first-difference operator D\n    D = np.zeros((N - 1, N))\n    row_indices = np.arange(N - 1)\n    D[row_indices, row_indices] = -1\n    D[row_indices, row_indices + 1] = 1\n\n    # 3. Synthesize measured data\n    m = A @ t_true\n\n    # 4. Perform unfolding with the three methods\n\n    # 4.1. Unregularized Least Squares\n    # Solve (A^T A) x = A^T m\n    try:\n        lhs_ls = A.T @ A\n        rhs_ls = A.T @ m\n        t_hat_ls = np.linalg.solve(lhs_ls, rhs_ls)\n    except np.linalg.LinAlgError:\n        # Use pseudo-inverse for singular matrices\n        t_hat_ls = np.linalg.pinv(A) @ m\n\n    # 4.2. Tikhonov Regularization\n    # Solve (A^T A + alpha D^T D) x = A^T m\n    lhs_tik = A.T @ A + alpha * (D.T @ D)\n    rhs_tik = A.T @ m\n    t_hat_tik = np.linalg.solve(lhs_tik, rhs_tik)\n\n    # 4.3. Total Variation Regularization via ADMM\n    def soft_threshold(v, kappa):\n        \"\"\"Soft-thresholding operator.\"\"\"\n        return np.sign(v) * np.maximum(np.abs(v) - kappa, 0)\n    \n    # Initialize ADMM variables\n    x = np.zeros(N)\n    z = np.zeros(N - 1)\n    u = np.zeros(N - 1)\n    \n    # Pre-compute the inverse matrix for the x-update step for efficiency\n    x_update_matrix = A.T @ A + rho * (D.T @ D)\n    x_update_matrix_inv = np.linalg.inv(x_update_matrix)\n    \n    # ADMM iterations\n    num_iterations = 200\n    for _ in range(num_iterations):\n        # x-update\n        rhs_x = A.T @ m + rho * D.T @ (z - u)\n        x = x_update_matrix_inv @ rhs_x\n        \n        # z-update\n        z_arg = D @ x + u\n        z = soft_threshold(z_arg, tau / rho)\n        \n        # u-update\n        u = u + D @ x - z\n    \n    t_hat_tv = x\n\n    # 5. Calculate and collect metrics\n    \n    all_results = []\n    for t_hat in [t_hat_ls, t_hat_tik, t_hat_tv]:\n        # Metric 1: Mean Squared Error (MSE)\n        mse = np.mean((t_hat - t_true)**2)\n        \n        # Metric 2: Edge Residual Magnitude (E)\n        if theta == N - 1:\n            edge_residual = np.abs(t_hat[theta] - t_hat[theta - 1])\n        elif theta  N - 1:\n            edge_residual = np.abs(t_hat[theta + 1] - t_hat[theta])\n        else: # Case where theta >= N, not in tests, but for completeness.\n            edge_residual = 0.0\n\n        # Metric 3: High-Region Mean Bias (B)\n        # The true mean in the high region is 1.0 since t_true is all ones.\n        if N > theta:\n            bias = np.mean(t_hat[theta:]) - 1.0\n        else: # Case theta >= N\n            bias = 0.0\n\n        all_results.extend([mse, edge_residual, bias])\n        \n    return all_results\n\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (general case)\n        {'N': 50, 'sigma': 1.5, 'theta': 30, 'eps_drop': 0.05, \n         'alpha': 1e-2, 'tau': 1e-2, 'rho': 0.5},\n        # Case 2 (boundary threshold)\n        {'N': 50, 'sigma': 1.5, 'theta': 49, 'eps_drop': 0.05, \n         'alpha': 1e-2, 'tau': 1e-2, 'rho': 0.5},\n        # Case 3 (minimal smearing, extreme drop)\n        {'N': 50, 'sigma': 0.5, 'theta': 25, 'eps_drop': 0.01, \n         'alpha': 1e-2, 'tau': 1e-2, 'rho': 0.5},\n    ]\n\n    results = []\n    for params in test_cases:\n        case_result = run_case(**params)\n        results.append(case_result)\n\n    # Final print statement in the exact required format.\n    # We construct the string manually to avoid spaces python's default str() adds.\n    case_strings = []\n    for res_list in results:\n        case_strings.append(f\"[{','.join(map(str, res_list))}]\")\n    \n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n\n```", "id": "3540846"}, {"introduction": "正则化展开的质量在很大程度上取决于正则化强度 $\\tau$ 的选择，这是一个平衡偏差与方差的关键参数。这项实践超越了简单的启发式方法，介绍了广义交叉验证（GCV），一种用于参数选择的稳健技术。该练习要求您推导并实现一个高效的算法来计算 GCV 分数，从而找到能产生最佳展开结果的最优 $\\tau$ 值 [@problem_id:3540844]。", "problem": "考虑一个线性逆问题，它将高能物理中的探测器弥散效应建模为 $y = \\mathbf{A} x_{\\text{true}} + \\varepsilon$，其中 $y \\in \\mathbb{R}^m$ 是测量到的能谱，$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ 是探测器响应矩阵，$x_{\\text{true}} \\in \\mathbb{R}^n$ 是待解的未知真实谱，$\\varepsilon \\in \\mathbb{R}^m$ 是一个加性噪声向量。我们假设 $\\varepsilon$ 是一个独立同分布的高斯噪声向量，其均值为零，方差有限。为了稳定反演过程，使用带有线性算子 $\\mathbf{L} \\in \\mathbb{R}^{p \\times n}$ 的 Tikhonov 正则化，并将正则化估计量 $x_\\tau$ 定义为代价函数的最小化子\n$$\nJ(x;\\tau) = \\|\\mathbf{A} x - y\\|_2^2 + \\tau \\|\\mathbf{L} x\\|_2^2,\n$$\n其中正则化强度 $\\tau > 0$。拟合的测量值为 $y_{\\text{hat}} = \\mathbf{A} x_\\tau$，帽子矩阵 $\\mathbf{H}$ 被定义为由上述 Tikhonov 估计量导出的唯一线性映射 $y \\mapsto y_{\\text{hat}}$，因此对于所有 $y$ 都有 $y_{\\text{hat}} = \\mathbf{H} y$ 成立。对于给定的 $\\tau$，广义交叉验证 (GCV) 分数定义为\n$$\n\\operatorname{GCV}(\\tau) = \\frac{\\|( \\mathbf{I}_m - \\mathbf{H} ) y \\|_2^2}{\\left(m - \\operatorname{trace}(\\mathbf{H})\\right)^2},\n$$\n其中 $\\mathbf{I}_m$ 是 $m \\times m$ 的单位矩阵，$m$ 是 $y$ 的维数。目标是选择使 $\\operatorname{GCV}(\\tau)$ 最小化的 $\\tau$。\n\n仅从 Tikhonov 估计量的标准正规方程和帽子矩阵作为从 $y$ 到 $y_{\\text{hat}}$ 的线性映射的定义出发，推导出一个算法，用于为一组指定的 $\\tau$ 值计算 $\\operatorname{GCV}(\\tau)$，而无需显式地将 $\\mathbf{H}$ 构建为稠密矩阵。利用基本的线性代数恒等式和迹的性质来设计一个数值稳定的过程。\n\n您的程序必须实现这个算法，并将其应用于以下测试套件。在每个测试用例中，将 $\\mathbf{A}$ 构建为一个列归一化的高斯响应矩阵，其元素为\n$$\nA_{ij} = \\exp\\!\\left(-\\frac{(i - s j)^2}{2 \\sigma^2}\\right),\n$$\n对于 $i \\in \\{0,1,\\dots,m-1\\}$ 和 $j \\in \\{0,1,\\dots,n-1\\}$，其中 $s = \\frac{m-1}{n-1}$。构建 $\\mathbf{A}$ 后，对每一列进行归一化，使得对所有 $j$ 都有 $\\sum_{i=0}^{m-1} A_{ij} = 1$。正则化矩阵 $\\mathbf{L}$ 应按每个案例的指定进行选择。测量向量为 $y = \\mathbf{A} x_{\\text{true}} + \\eta$，其中 $x_{\\text{true}}$ 和加性项 $\\eta$ 在测试套件中给出。要搜索的 $\\tau$ 候选值集合是几何网格\n$$\n\\{\\tau_k\\}_{k=0}^{60} = \\{10^{-8}, 10^{-8 + \\Delta}, \\dots, 10^{2}\\},\n$$\n包含 $61$ 个在 $\\log_{10}$ 尺度上等间距的点，即 $\\Delta = \\frac{2 - (-8)}{60}$。为保证数值鲁棒性，如果对于某个 $\\tau$，$m - \\operatorname{trace}(\\mathbf{H})$ 在数值上为零，则将 $\\operatorname{GCV}(\\tau)$ 视为 $+\\infty$。\n\n测试套件规范：\n- 案例 1 (理想情况，良态)：\n  - $m = 6$, $n = 5$, $\\sigma = 0.8$, $\\mathbf{L} = \\mathbf{I}_n$。\n  - $x_{\\text{true}} = [\\,12.0,\\,18.0,\\,25.0,\\,18.0,\\,12.0\\,]$。\n  - $\\eta = [\\,0.5,\\,-0.3,\\,0.2,\\,-0.1,\\,0.4,\\,-0.2\\,]$。\n- 案例 2 (病态响应，曲率正则化)：\n  - $m = 6$, $n = 6$, $\\sigma = 1.5$, $\\mathbf{L}$ 是二阶差分算子，其行实现 $[\\,1,\\,-2,\\,1\\,]$ 模板，因此 $\\mathbf{L} \\in \\mathbb{R}^{(n-2) \\times n}$，其元素对于 $k \\in \\{0,\\dots,n-3\\}$ 为 $L_{k,k} = 1$, $L_{k,k+1} = -2$, $L_{k,k+2} = 1$，其余为零。\n  - $x_{\\text{true}} = [\\,8.0,\\,12.0,\\,20.0,\\,12.0,\\,8.0,\\,5.0\\,]$。\n  - $\\eta = [\\,0.2,\\,-0.1,\\,0.3,\\,-0.2,\\,0.1,\\,-0.1\\,]$。\n- 案例 3 (欠定系统，单位正则化)：\n  - $m = 5$, $n = 7$, $\\sigma = 0.7$, $\\mathbf{L} = \\mathbf{I}_n$。\n  - $x_{\\text{true}} = [\\,5.0,\\,7.0,\\,9.0,\\,11.0,\\,13.0,\\,11.0,\\,9.0\\,]$。\n  - $\\eta = [\\,0.1,\\,-0.1,\\,0.2,\\,-0.2,\\,0.1\\,]$。\n- 案例 4 (尖锐结构，一阶差分平滑)：\n  - $m = 8$, $n = 8$, $\\sigma = 0.6$, $\\mathbf{L}$ 是一阶差分算子，有 $p = n-1$ 行，每一行 $k$ 的元素对于 $k \\in \\{0,\\dots,n-2\\}$ 为 $L_{k,k} = -1$, $L_{k,k+1} = 1$，其余为零。\n  - $x_{\\text{true}} = [\\,2.0,\\,3.0,\\,30.0,\\,3.0,\\,2.0,\\,1.5,\\,1.0,\\,0.5\\,]$。\n  - $\\eta = [\\,0.1,\\,-0.1,\\,0.0,\\,0.05,\\,-0.05,\\,0.0,\\,0.02,\\,-0.02\\,]$。\n\n您的程序应为每个案例计算指定网格中使 $\\operatorname{GCV}(\\tau)$ 最小化的 $\\tau$ 值。最终输出格式必须是单行，包含四个选定的值，以逗号分隔并用方括号括起来，例如 $[\\,\\tau_1,\\,\\tau_2,\\,\\tau_3,\\,\\tau_4\\,]$。不涉及物理单位或角度单位，所有输出必须是实值浮点数。", "solution": "从受探测器弥散和噪声影响的测量能谱 $y \\in \\mathbb{R}^m$ 中解谱真实能谱 $x_{\\text{true}} \\in \\mathbb{R}^n$ 的问题，由线性系统 $y = \\mathbf{A} x_{\\text{true}} + \\varepsilon$ 建模。这里，$\\mathbf{A} \\in \\mathbb{R}^{m \\times n}$ 是探测器响应矩阵，$\\varepsilon$ 是噪声向量。我们寻求对未知 $x_{\\text{true}}$ 的一个估计 $x$。由于 $\\mathbf{A}$ 通常具有病态性质，直接求逆是不稳定的。Tikhonov 正则化通过最小化一个惩罚代价函数来寻找一个稳定的解。\n\n问题验证如下：\n1.  **提取已知条件**：\n    -   模型：$y = \\mathbf{A} x_{\\text{true}} + \\varepsilon$，其中 $\\varepsilon$ 是独立同分布的零均值高斯噪声。\n    -   代价函数：$J(x;\\tau) = \\|\\mathbf{A} x - y\\|_2^2 + \\tau \\|\\mathbf{L} x\\|_2^2$，其中正则化参数 $\\tau > 0$，算子为 $\\mathbf{L} \\in \\mathbb{R}^{p \\times n}$。\n    -   估计量 $x_\\tau$：$x_\\tau = \\operatorname{argmin}_{x} J(x;\\tau)$。\n    -   拟合测量值：$y_{\\text{hat}} = \\mathbf{A} x_\\tau$。\n    -   帽子矩阵 $\\mathbf{H}$：满足 $y_{\\text{hat}} = \\mathbf{H} y$ 的线性映射。\n    -   广义交叉验证 (GCV) 分数：$\\operatorname{GCV}(\\tau) = \\frac{\\|( \\mathbf{I}_m - \\mathbf{H} ) y \\|_2^2}{\\left(m - \\operatorname{trace}(\\mathbf{H})\\right)^2}$，其中 $\\mathbf{I}_m$ 是 $m \\times m$ 的单位矩阵。\n    -   响应矩阵 $\\mathbf{A}$：对于 $i \\in \\{0, \\dots, m-1\\}$，$j \\in \\{0, \\dots, n-1\\}$，$A_{ij} = \\exp\\left(-\\frac{(i - s j)^2}{2 \\sigma^2}\\right)$，其中 $s = \\frac{m-1}{n-1}$。各列被归一化以使其元素和为 1。\n    -   正则化参数网格：$\\{\\tau_k\\}_{k=0}^{60} = \\{10^{-8}, 10^{-8 + \\Delta}, \\dots, 10^{2}\\}$，其中 $\\Delta = \\frac{2 - (-8)}{60}$。\n    -   测试用例：四个明确的案例，指定了 $m, n, \\sigma, \\mathbf{L}, x_{\\text{true}}, \\eta$。\n\n2.  **使用提取的已知条件进行验证**：\n    -   **科学基础**：该问题牢固地定位于逆问题和正则化理论的标准理论框架内，这是计算物理和数据分析的核心课题。所有概念（Tikhonov 正则化、GCV、响应矩阵）都是标准的并且表述正确。\n    -   **适定性**：该问题要求从一个离散网格中找到一个使函数最小化的值 $\\tau$。最小值保证存在。\n    -   **客观性**：问题以精确的数学定义和数值数据客观陈述。没有主观或模糊的元素。\n    -   **完整性**：为每个测试用例指定了所有必要的参数、矩阵、向量和函数形式，使得问题是自包含的。\n    -   **一致性**：定义和约束是相互一致的。例如，案例 2 中二阶差分算子的定义在维度和索引方面是内部一致的。\n\n3.  **结论与行动**：问题有效。将提供一个完整的、有理有据的解决方案。\n\n### GCV 计算算法的推导\n\n核心任务是设计一个算法，用于在一系列 $\\tau$ 值网格上计算 $\\operatorname{GCV}(\\tau)$，而无需显式地构建稠密的 $m \\times m$ 帽子矩阵 $\\mathbf{H}$。\n\n**1. Tikhonov 解**\n估计量 $x_\\tau$ 最小化二次代价函数 $J(x;\\tau)$。我们通过将其关于 $x$ 的梯度设为零来找到这个最小值：\n$$\n\\nabla_x J(x;\\tau) = \\nabla_x \\left( ( \\mathbf{A}x - y )^T ( \\mathbf{A}x - y ) + \\tau ( \\mathbf{L}x )^T ( \\mathbf{L}x ) \\right) = 0\n$$\n$$\n\\nabla_x \\left( x^T \\mathbf{A}^T \\mathbf{A} x - 2 y^T \\mathbf{A} x + y^T y + \\tau x^T \\mathbf{L}^T \\mathbf{L} x \\right) = 0\n$$\n$$\n2 \\mathbf{A}^T \\mathbf{A} x - 2 \\mathbf{A}^T y + 2 \\tau \\mathbf{L}^T \\mathbf{L} x = 0\n$$\n这得到了 Tikhonov 问题的正规方程：\n$$\n( \\mathbf{A}^T \\mathbf{A} + \\tau \\mathbf{L}^T \\mathbf{L} ) x = \\mathbf{A}^T y\n$$\n因此，解 $x_\\tau$ 是：\n$$\nx_\\tau = ( \\mathbf{A}^T \\mathbf{A} + \\tau \\mathbf{L}^T \\mathbf{L} )^{-1} \\mathbf{A}^T y\n$$\n对于给定的 $\\tau$，$x_\\tau$ 可以通过求解这个 $n \\times n$ 的线性系统找到。矩阵 $\\mathbf{M}_\\tau = \\mathbf{A}^T \\mathbf{A} + \\tau \\mathbf{L}^T \\mathbf{L}$ 是对称的，并且对于 $\\tau > 0$ 是正定的，确保了唯一解的存在。\n\n**2. 帽子矩阵的表达式**\n帽子矩阵 $\\mathbf{H}$ 将测量向量 $y$ 映射到拟合测量向量 $y_{\\text{hat}} = \\mathbf{A} x_\\tau$。代入 $x_\\tau$ 的表达式：\n$$\ny_{\\text{hat}} = \\mathbf{A} x_\\tau = \\mathbf{A} ( \\mathbf{A}^T \\mathbf{A} + \\tau \\mathbf{L}^T \\mathbf{L} )^{-1} \\mathbf{A}^T y\n$$\n根据定义 $y_{\\text{hat}} = \\mathbf{H} y$，我们确定帽子矩阵为：\n$$\n\\mathbf{H} = \\mathbf{A} ( \\mathbf{A}^T \\mathbf{A} + \\tau \\mathbf{L}^T \\mathbf{L} )^{-1} \\mathbf{A}^T = \\mathbf{A} \\mathbf{M}_\\tau^{-1} \\mathbf{A}^T\n$$\n\n**3. 计算 GCV 分子**\nGCV 分数的分子是残差向量的平方范数，$\\|( \\mathbf{I}_m - \\mathbf{H} ) y \\|_2^2$。\n$$\n( \\mathbf{I}_m - \\mathbf{H} ) y = y - \\mathbf{H} y = y - y_{\\text{hat}} = y - \\mathbf{A} x_\\tau\n$$\n因此，分子就是 $\\| y - \\mathbf{A} x_\\tau \\|_2^2$。这可以高效地计算：\n1.  求解正规方程得到 $x_\\tau$。\n2.  计算向量 $r = y - \\mathbf{A} x_\\tau$。\n3.  计算平方欧几里得范数 $r^T r$。\n\n**4. 计算 GCV 分母**\n分母是 $(m - \\operatorname{trace}(\\mathbf{H}))^2$。主要挑战是在不构建 $m \\times m$ 矩阵 $\\mathbf{H}$ 的情况下计算 $\\operatorname{trace}(\\mathbf{H})$。迹是对角元素之和，$\\operatorname{trace}(\\mathbf{H}) = \\sum_{i=0}^{m-1} H_{ii}$。\n第 $i$-个对角元素由 $H_{ii} = e_i^T \\mathbf{H} e_i$ 给出，其中 $e_i$ 是 $\\mathbb{R}^m$ 中的第 $i$-个标准基向量。\n$$\nH_{ii} = e_i^T \\left( \\mathbf{A} \\mathbf{M}_\\tau^{-1} \\mathbf{A}^T \\right) e_i = (e_i^T \\mathbf{A}) \\mathbf{M}_\\tau^{-1} (\\mathbf{A}^T e_i)\n$$\n令 $a_i^T$ 表示 $\\mathbf{A}$ 的第 $i$-行。那么 $e_i^T \\mathbf{A} = a_i^T$ 且 $\\mathbf{A}^T e_i = a_i$。因此：\n$$\nH_{ii} = a_i^T \\mathbf{M}_\\tau^{-1} a_i\n$$\n为了计算这个量，我们定义一个中间向量 $z_i = \\mathbf{M}_\\tau^{-1} a_i$。这个向量可以通过求解线性系统 $\\mathbf{M}_\\tau z_i = a_i$ 找到。一旦找到 $z_i$，对角元素就可以通过点积 $H_{ii} = a_i^T z_i$ 获得。\n总迹是所有对角元素的和：\n$$\n\\operatorname{trace}(\\mathbf{H}) = \\sum_{i=0}^{m-1} H_{ii} = \\sum_{i=0}^{m-1} a_i^T \\left( \\mathbf{M}_\\tau^{-1} a_i \\right)\n$$\n这个过程需要对每个 $\\tau$ 值求解 $m$ 个大小为 $n \\times n$ 的线性系统。虽然计算上比单次求解更密集，但对于给定的问题维度是可行的，并避免了构建可能很大的矩阵 $\\mathbf{H}$。\n\n**5. 完整算法**\n对于每个测试用例，执行以下算法：\n1.  按规定构建矩阵 $\\mathbf{A}$、$\\mathbf{L}$ 和向量 $y$。预先计算 $\\mathbf{A}^T\\mathbf{A}$、$\\mathbf{L}^T\\mathbf{L}$ 和 $\\mathbf{A}^T y$。\n2.  生成从 $10^{-8}$ 到 $10^2$ 的 $61$ 个候选 $\\tau$ 值的对数网格。\n3.  初始化 `min_gcv` 为无穷大，`best_tau` 为 `None`。\n4.  对于网格中的每个 $\\tau_k$：\n    a. 形成矩阵 $\\mathbf{M}_k = \\mathbf{A}^T\\mathbf{A} + \\tau_k \\mathbf{L}^T\\mathbf{L}$。\n    b. 求解系统 $\\mathbf{M}_k x_\\tau = \\mathbf{A}^T y$ 以得到正则化解 $x_\\tau$。\n    c. 计算 GCV 分子：$N = \\|y - \\mathbf{A} x_\\tau\\|_2^2$。\n    d. 计算帽子矩阵的迹：\n        i. 初始化 $\\operatorname{trace}(\\mathbf{H}) = 0$。\n        ii. 对于从 $0$ 到 $m-1$ 的每个行索引 $i$：\n           - 提取 $\\mathbf{A}$ 的第 $i$-行，记为 $a_i^T$。\n           - 求解线性系统 $\\mathbf{M}_k z_i = a_i$ 以得到 $z_i$。\n           - 计算对角元素 $H_{ii} = a_i^T z_i$。\n           - 累加迹：$\\operatorname{trace}(\\mathbf{H}) \\leftarrow \\operatorname{trace}(\\mathbf{H}) + H_{ii}$。\n    e. 计算分母项 $D = m - \\operatorname{trace}(\\mathbf{H})$。\n    f. 如果 $D$ 在数值上接近于零，则设 $\\operatorname{GCV}(\\tau_k) = \\infty$。否则，计算 $\\operatorname{GCV}(\\tau_k) = N / D^2$。\n    g. 如果 $\\operatorname{GCV}(\\tau_k)  \\text{min\\_gcv}$，则更新 $\\text{min\\_gcv} = \\operatorname{GCV}(\\tau_k)$ 和 $\\text{best\\_tau} = \\tau_k$。\n5.  该案例的最优正则化参数是 `best_tau`。\n\n该算法严格遵循定义，并遵守不构建稠密帽子矩阵 $\\mathbf{H}$ 的约束。它被实现用来解决所提供的测试用例。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to run the GCV optimization for all test cases.\n    \"\"\"\n    test_cases = [\n        {\n            \"m\": 6, \"n\": 5, \"sigma\": 0.8, \"L_type\": \"identity\",\n            \"x_true\": np.array([12.0, 18.0, 25.0, 18.0, 12.0]),\n            \"eta\": np.array([0.5, -0.3, 0.2, -0.1, 0.4, -0.2]),\n        },\n        {\n            \"m\": 6, \"n\": 6, \"sigma\": 1.5, \"L_type\": \"second_diff\",\n            \"x_true\": np.array([8.0, 12.0, 20.0, 12.0, 8.0, 5.0]),\n            \"eta\": np.array([0.2, -0.1, 0.3, -0.2, 0.1, -0.1]),\n        },\n        {\n            \"m\": 5, \"n\": 7, \"sigma\": 0.7, \"L_type\": \"identity\",\n            \"x_true\": np.array([5.0, 7.0, 9.0, 11.0, 13.0, 11.0, 9.0]),\n            \"eta\": np.array([0.1, -0.1, 0.2, -0.2, 0.1]),\n        },\n        {\n            \"m\": 8, \"n\": 8, \"sigma\": 0.6, \"L_type\": \"first_diff\",\n            \"x_true\": np.array([2.0, 3.0, 30.0, 3.0, 2.0, 1.5, 1.0, 0.5]),\n            \"eta\": np.array([0.1, -0.1, 0.0, 0.05, -0.05, 0.0, 0.02, -0.02]),\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        best_tau = find_best_tau(case)\n        results.append(f\"{best_tau}\")\n\n    print(f\"[{','.join(results)}]\")\n\ndef construct_A(m, n, sigma):\n    \"\"\"Constructs the response matrix A.\"\"\"\n    if n > 1:\n        s = (m - 1) / (n - 1)\n    else:\n        s = 0.0\n    \n    i_coords = np.arange(m).reshape(-1, 1)\n    j_coords = np.arange(n).reshape(1, -1)\n    \n    A = np.exp(-(i_coords - s * j_coords)**2 / (2 * sigma**2))\n    \n    # Normalize each column to sum to 1\n    col_sums = A.sum(axis=0)\n    # Avoid division by zero if a column is all zeros, though unlikely here\n    col_sums[col_sums == 0] = 1.0\n    A = A / col_sums\n    \n    return A\n\ndef construct_L(L_type, n):\n    \"\"\"Constructs the regularization operator L.\"\"\"\n    if L_type == \"identity\":\n        return np.eye(n)\n    elif L_type == \"first_diff\":\n        p = n - 1\n        if p = 0: return np.zeros((0, n))\n        L = np.zeros((p, n))\n        L[np.arange(p), np.arange(p)] = -1.0\n        L[np.arange(p), np.arange(p) + 1] = 1.0\n        return L\n    elif L_type == \"second_diff\":\n        p = n - 2\n        if p = 0: return np.zeros((0, n))\n        L = np.zeros((p, n))\n        L[np.arange(p), np.arange(p)] = 1.0\n        L[np.arange(p), np.arange(p) + 1] = -2.0\n        L[np.arange(p), np.arange(p) + 2] = 1.0\n        return L\n    else:\n        raise ValueError(f\"Unknown L_type: {L_type}\")\n\ndef find_best_tau(case_params):\n    \"\"\"\n    Finds the optimal tau for a given case by minimizing the GCV score.\n    \"\"\"\n    m, n, sigma = case_params[\"m\"], case_params[\"n\"], case_params[\"sigma\"]\n    L_type, x_true, eta = case_params[\"L_type\"], case_params[\"x_true\"], case_params[\"eta\"]\n\n    A = construct_A(m, n, sigma)\n    L = construct_L(L_type, n)\n    \n    y = A @ x_true + eta\n\n    AtA = A.T @ A\n    LtL = L.T @ L\n    Aty = A.T @ y\n\n    # Generate the logarithmic grid of tau values\n    # The problem statement specifies Delta = (2 - (-8)) / 60\n    taus = np.logspace(-8, 2, num=61)\n\n    min_gcv = np.inf\n    best_tau = None\n\n    for tau in taus:\n        # Form the matrix for the normal equations\n        M_tau = AtA + tau * LtL\n\n        try:\n            # Solve for the Tikhonov estimator x_tau\n            x_tau = np.linalg.solve(M_tau, Aty)\n            \n            # Compute the numerator of the GCV score\n            numerator = np.linalg.norm(A @ x_tau - y)**2\n\n            # Compute the trace of the hat matrix H without forming H\n            trace_H = 0.0\n            for i in range(m):\n                a_i_row = A[i, :]\n                z_i = np.linalg.solve(M_tau, a_i_row)\n                H_ii = a_i_row.T @ z_i\n                trace_H += H_ii\n\n            # Compute the denominator term\n            denominator_term = m - trace_H\n\n            if np.isclose(denominator_term, 0.0):\n                gcv = np.inf\n            else:\n                gcv = numerator / (denominator_term**2)\n        \n        except np.linalg.LinAlgError:\n            # If the matrix M_tau is singular, GCV is not well-defined.\n            gcv = np.inf\n\n        if gcv  min_gcv:\n            min_gcv = gcv\n            best_tau = tau\n\n    return best_tau\n\nsolve()\n```", "id": "3540844"}]}