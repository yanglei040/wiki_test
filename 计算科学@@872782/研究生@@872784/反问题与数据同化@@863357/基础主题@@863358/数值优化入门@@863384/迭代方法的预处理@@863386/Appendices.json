{"hands_on_practices": [{"introduction": "本章的第一个实践将带领我们分析一个简洁而经典的案例：将雅可比（Jacobi）预处理器应用于源自一维泊松方程离散化的矩阵。这个练习的目标是让学习者通过分析推导预处理后系统谱条件数 $\\kappa$ 的精确表达式，从而定量地评估性能提升，并将其与预处理共轭梯度（PCG）方法的理论收敛界限直接联系起来 [@problem_id:3412964]。这项实践旨在为理解预处理技术奠定坚实的分析基础。", "problem": "考虑对称正定矩阵 $A \\in \\mathbb{R}^{n \\times n}$，它来自于在区间 $[0,1]$ 上使用 $n$ 个内部网格点和均匀间距 $h = 1/(n+1)$，对带齐次狄利克雷边界条件的一维泊松方程 $-u''(x) = f(x)$ 进行标准二阶中心有限差分格式离散化。因此 $A = \\frac{1}{h^{2}} T$，其中 $T$ 是一个三对角托普利茨矩阵，主对角线元素为 $2$，第一亚对角线和第一超对角线元素为 $-1$。令 $M = \\operatorname{diag}(A)$ 为雅可比预条件子。\n\n1) 从该离散化的第一性原理出发，推导谱条件数 $\\kappa(M^{-1}A)$ 关于 $n$ 的一个精确、闭式表达式，其中对于任何对称正定矩阵 $B$，$\\kappa(B) = \\lambda_{\\max}(B) / \\lambda_{\\min}(B)$。然后将您的结果应用于 $n=127$ 的情况，并保持表达式的精确性。\n\n2) 考虑从任意初始猜测开始，使用预条件子 $M$ 对线性系统 $A x = b$ 应用预处理共轭梯度（PCG）方法。设给定容差为 $\\epsilon = 10^{-6}$（在相对 $A$-范数意义下），即停止要求为 $\\|x_{k} - x_{\\star}\\|_{A} / \\|x_{0} - x_{\\star}\\|_{A} \\le \\epsilon$，其中 $x_{\\star}$ 是精确解，$\\|y\\|_{A} = \\sqrt{y^{\\top} A y}$ 表示 $A$-范数。仅使用从 $\\kappa(M^{-1}A)$ 推导出的最坏情况信息，预测保证达到此容差的最小整数PCG迭代次数 $k$。将您的答案表示为一个闭式表达式的精确上取整，然后将其应用于 $n = 127$ 和 $\\epsilon = 10^{-6}$ 的情况。\n\n将最终答案表示为一个包含两个条目的行矩阵：第一个条目是应用于 $n = 127$ 的 $\\kappa(M^{-1}A)$ 的闭式表达式；第二个条目是在最坏情况界下，容差为 $\\epsilon = 10^{-6}$ 时的最小整数迭代次数 $k$。无需单位。不要对任何非整数进行四舍五入；如果需要整数，请提供精确整数。", "solution": "首先验证问题，以确保其在科学上是合理的、适定的、客观的和完整的。\n\n### 步骤1：提取已知条件\n- 矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 是对称正定（SPD）的，来自于对带齐次狄利克雷边界条件的一维泊松方程 $-u''(x) = f(x)$ 在 $[0,1]$ 上进行中心有限差分格式离散化。\n- 有 $n$ 个内部网格点。\n- 网格间距是均匀的，$h = 1/(n+1)$。\n- $A = \\frac{1}{h^{2}} T$，其中 $T$ 是主对角线元素为 $2$、第一亚对角线和第一超对角线元素为 $-1$ 的三对角托普利茨矩阵。\n- 预条件子是雅可比预条件子，$M = \\operatorname{diag}(A)$。\n- 第1部分要求推导谱条件数 $\\kappa(M^{-1}A) = \\lambda_{\\max}(M^{-1}A) / \\lambda_{\\min}(M^{-1}A)$ 的闭式表达式，并将其应用于 $n = 127$ 的情况。\n- 第2部分要求基于最坏情况收敛界，预测达到容差 $\\epsilon = 10^{-6}$ 的最小整数PCG迭代次数 $k$。\n- 停止准则为 $\\|x_{k} - x_{\\star}\\|_{A} / \\|x_{0} - x_{\\star}\\|_{A} \\le \\epsilon$，其中 $x_{\\star}$ 是精确解，$\\|y\\|_{A} = \\sqrt{y^{\\top} A y}$ 是 $A$-范数。\n\n### 步骤2：使用提取的已知条件进行验证\n- **科学依据：** 该问题是数值线性代数中的一个标准练习，涉及对一个由著名偏微分方程（一维泊松方程）离散化产生的预处理系统的分析。所有概念都是数值分析的基础。\n- **适定性：** 问题定义清晰。已知矩阵 $A$ 是对称正定的，这确保其对角元素为正，进而意味着雅可比预条件子 $M$ 也是对称正定且可逆的。$M^{-1}A$ 的特征值是实数且为正，使得条件数是良定义的。PCG迭代次数基于标准的先验误差界。存在唯一且有意义的解。\n- **客观性：** 问题使用精确、无歧义的数学语言陈述。\n- **完整性与一致性：** 提供了所有必要的定义和值（例如，$A$ 的结构、$M$ 的定义，以及用于特定情况的 $n$ 和 $\\epsilon$ 的值）。不存在矛盾。\n\n### 步骤3：结论与行动\n问题有效。将提供完整解答。\n\n### 第1部分：谱条件数 $\\kappa(M^{-1}A)$ 的推导\n\n矩阵 $A$ 由 $A = \\frac{1}{h^2} T$ 给出，其中 $T$ 是一个 $n \\times n$ 的矩阵：\n$$\nT = \\begin{pmatrix}\n2  -1    \\\\\n-1  2  -1   \\\\\n \\ddots  \\ddots  \\ddots  \\\\\n  -1  2  -1 \\\\\n   -1  2\n\\end{pmatrix}\n$$\n雅可比预条件子 $M$ 是 $A$ 的对角部分。由于 $T$ 的每个对角元素都是 $2$，所以 $A$ 的每个对角元素都是 $2/h^2$。因此，$M$ 是一个对角矩阵：\n$$\nM = \\operatorname{diag}(A) = \\frac{2}{h^2} I\n$$\n其中 $I$ 是 $n \\times n$ 的单位矩阵。$M$ 的逆矩阵是：\n$$\nM^{-1} = \\frac{h^2}{2} I\n$$\n现在，我们可以构造预处理矩阵 $M^{-1}A$：\n$$\nM^{-1}A = \\left(\\frac{h^2}{2} I\\right) \\left(\\frac{1}{h^2} T\\right) = \\frac{1}{2} T\n$$\n因此，$M^{-1}A$ 的特征值是 $T$ 的特征值的一半。矩阵 $T$ 的特征值是数值分析中的一个标准结果。对于这种形式的 $n \\times n$ 矩阵，其特征值 $\\mu_j$ 由下式给出：\n$$\n\\mu_j = 2 - 2\\cos\\left(\\frac{j\\pi}{n+1}\\right) \\quad \\text{for } j = 1, 2, \\ldots, n\n$$\n使用半角恒等式 $1 - \\cos(\\theta) = 2\\sin^2(\\theta/2)$，我们可以将其重写为：\n$$\n\\mu_j = 4\\sin^2\\left(\\frac{j\\pi}{2(n+1)}\\right) \\quad \\text{for } j = 1, 2, \\ldots, n\n$$\n那么 $M^{-1}A = \\frac{1}{2}T$ 的特征值 $\\lambda_j$ 是：\n$$\n\\lambda_j = \\frac{1}{2}\\mu_j = 2\\sin^2\\left(\\frac{j\\pi}{2(n+1)}\\right) \\quad \\text{for } j = 1, 2, \\ldots, n\n$$\n正弦函数在区间 $(0, \\pi/2)$ 上是严格单调递增的。对于 $j=1, \\ldots, n$，正弦函数的自变量 $\\frac{j\\pi}{2(n+1)}$ 都位于此区间内。因此，$M^{-1}A$ 的最小特征值对应于 $j=1$，最大特征值对应于 $j=n$。\n$$\n\\lambda_{\\min}(M^{-1}A) = \\lambda_1 = 2\\sin^2\\left(\\frac{\\pi}{2(n+1)}\\right)\n$$\n$$\n\\lambda_{\\max}(M^{-1}A) = \\lambda_n = 2\\sin^2\\left(\\frac{n\\pi}{2(n+1)}\\right)\n$$\n谱条件数 $\\kappa(M^{-1}A)$ 是最大特征值与最小特征值的比率：\n$$\n\\kappa(M^{-1}A) = \\frac{\\lambda_{\\max}(M^{-1}A)}{\\lambda_{\\min}(M^{-1}A)} = \\frac{2\\sin^2\\left(\\frac{n\\pi}{2(n+1)}\\right)}{2\\sin^2\\left(\\frac{\\pi}{2(n+1)}\\right)} = \\frac{\\sin^2\\left(\\frac{n\\pi}{2(n+1)}\\right)}{\\sin^2\\left(\\frac{\\pi}{2(n+1)}\\right)}\n$$\n我们可以使用恒等式 $\\sin(\\theta) = \\cos(\\pi/2 - \\theta)$ 来化简分子：\n$$\n\\sin\\left(\\frac{n\\pi}{2(n+1)}\\right) = \\sin\\left(\\frac{(n+1-1)\\pi}{2(n+1)}\\right) = \\sin\\left(\\frac{\\pi}{2} - \\frac{\\pi}{2(n+1)}\\right) = \\cos\\left(\\frac{\\pi}{2(n+1)}\\right)\n$$\n将此代入条件数的表达式中，得到：\n$$\n\\kappa(M^{-1}A) = \\frac{\\cos^2\\left(\\frac{\\pi}{2(n+1)}\\right)}{\\sin^2\\left(\\frac{\\pi}{2(n+1)}\\right)} = \\cot^2\\left(\\frac{\\pi}{2(n+1)}\\right)\n$$\n这就是条件数关于 $n$ 的闭式表达式。\n\n对于 $n=127$ 的特定情况，我们有 $n+1=128$。条件数为：\n$$\n\\kappa(M^{-1}A) = \\cot^2\\left(\\frac{\\pi}{2(128)}\\right) = \\cot^2\\left(\\frac{\\pi}{256}\\right)\n$$\n\n### 第2部分：PCG迭代次数\n\n使用预条件子 $M$ 求解 $Ax=b$ 的预处理共轭梯度（PCG）方法的收敛性由预处理矩阵的条件数 $\\kappa \\equiv \\kappa(M^{-1}A)$ 决定。$A$-范数下误差的标准最坏情况界由下式给出：\n$$\n\\frac{\\|x_k - x_{\\star}\\|_{A}}{\\|x_0 - x_{\\star}\\|_{A}} \\le 2\\left(\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right)^k\n$$\n我们希望找到满足停止准则的最小整数 $k$：\n$$\n2\\left(\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right)^k \\le \\epsilon\n$$\n为了解出 $k$，我们首先分离出以 $k$ 为幂的项：\n$$\n\\left(\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right)^k \\le \\frac{\\epsilon}{2}\n$$\n对两边取自然对数。由于 $\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}  1$，其对数为负，因此在除法后不等号反向：\n$$\nk \\ln\\left(\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right) \\le \\ln\\left(\\frac{\\epsilon}{2}\\right)\n$$\n$$\nk \\ge \\frac{\\ln(\\epsilon/2)}{\\ln\\left(\\frac{\\sqrt{\\kappa} - 1}{\\sqrt{\\kappa} + 1}\\right)} = \\frac{\\ln(2/\\epsilon)}{\\ln\\left(\\frac{\\sqrt{\\kappa} + 1}{\\sqrt{\\kappa} - 1}\\right)}\n$$\n最小整数 $k$ 是此表达式的上取整：\n$$\nk = \\left\\lceil \\frac{\\ln(2/\\epsilon)}{\\ln\\left(\\frac{\\sqrt{\\kappa} + 1}{\\sqrt{\\kappa} - 1}\\right)} \\right\\rceil\n$$\n现在我们将其应用于 $n = 127$ 和 $\\epsilon = 10^{-6}$ 的情况。从第1部分可知，$\\kappa = \\cot^2\\left(\\frac{\\pi}{256}\\right)$。因此，$\\sqrt{\\kappa} = \\cot\\left(\\frac{\\pi}{256}\\right)$，因为其自变量在 $(0, \\pi/2)$ 区间内。\n将这些值代入 $k$ 的表达式中：\n$$\nk = \\left\\lceil \\frac{\\ln(2/10^{-6})}{\\ln\\left(\\frac{\\cot(\\pi/256) + 1}{\\cot(\\pi/256) - 1}\\right)} \\right\\rceil = \\left\\lceil \\frac{\\ln(2 \\times 10^6)}{\\ln\\left(\\frac{\\cot(\\pi/256) + 1}{\\cot(\\pi/256) - 1}\\right)} \\right\\rceil\n$$\n我们现在计算上取整函数内部表达式的值。\n分子是 $\\ln(2 \\times 10^6) = \\ln(2) + 6\\ln(10) \\approx 0.693147 + 6 \\times 2.302585 \\approx 14.508657$。\n余切函数的自变量是 $\\theta = \\pi/256 \\approx 0.0122718$ 弧度。\n所以，$\\sqrt{\\kappa} = \\cot(\\pi/256) \\approx 81.48735$。\n分母是 $\\ln\\left(\\frac{81.48735 + 1}{81.48735 - 1}\\right) = \\ln\\left(\\frac{82.48735}{80.48735}\\right) \\approx \\ln(1.024848) \\approx 0.024549$。\n比值是 $\\frac{14.508657}{0.024549} \\approx 591.011$。\n最小整数迭代次数是该值的上取整：\n$$\nk = \\lceil 591.011 \\ldots \\rceil = 592\n$$", "answer": "$$\n\\boxed{\\begin{pmatrix} \\cot^{2}\\left(\\frac{\\pi}{256}\\right)  592 \\end{pmatrix}}\n$$", "id": "3412964"}, {"introduction": "在掌握了预处理的基本分析之后，我们将从纯理论分析转向实际的编程实现。这个计算练习旨在阐明共轭梯度（CG）方法的一个核心要求：算子必须是既对称又正定的。学习者将构建一个场景，其中一个“天真”的非对称预处理器会导致算法崩溃，然后将其与一个正确的、保持对称性的实现进行对比，从而巩固数值实践中的一个关键教训 [@problem_id:3566284]。", "problem": "要求您构建并分析一个计算示例，以证明在数值线性代数中，迭代方法使用保对称预处理的必要性。重点在于共轭梯度 (CG) 法、预条件共轭梯度 (PCG) 法，以及在对称正定 (SPD) 线性系统上应用非对称预条件子所产生的影响。\n\n从以下基本概念开始：\n- 矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 是对称正定 (SPD) 的定义为：对于所有非零 $x \\in \\mathbb{R}^{n}$，满足 $A = A^{\\top}$ 和 $x^{\\top} A x \\gt 0$。\n- 共轭梯度 (CG) 法是为 SPD 算子推导的，这一要求确保了当算子为 SPD 时，存在定义明确的搜索方向和正步长。\n- 观察到使用任意可逆矩阵 $M$ 进行朴素的左预处理，会将 SPD 算子 $A$ 替换为 $M^{-1} A$，而后者可能不是对称的（也可能无法定义有效的能量泛函），从而破坏了 CG 方法所依赖的假设。\n- 预条件共轭梯度 (PCG) 法要求预条件子 $M$ 本身是 SPD 的，并以保对称的方式使用，使得算子仍为 $A$，同时通过 $M^{-1}$ 的作用修改内积和残差的更新，从而保持关键量的正定性。\n\n任务：\n1. 在均匀的 $n \\times n$ 网格上，根据标准的二维离散拉普拉斯算子和狄利克雷边界条件，构建一个 SPD 矩阵 $A$。使用五点差分格式来形成维度为 $N = n^2$ 的矩阵 $A$，其主对角线元素为 $4$，对应网格邻居的非对角线元素为 $-1$（不涉及物理单位）。\n2. 定义一个非对称预条件子 $M = A J$，其中 $J \\in \\mathbb{R}^{N \\times N}$ 是一个块对角矩阵，其对角线上重复排列着 $2 \\times 2$ 的旋转 $90^\\circ$ 的块 $K = \\begin{bmatrix} 0  1 \\\\ -1  0 \\end{bmatrix}$。请注意，$J$ 是正交且斜对称的，因此 $J^{-1} = J^{\\top} = -J$，并且朴素左预处理后的算子 $B = M^{-1} A = J^{-1}$ 是斜对称的。解释为什么直接对左预处理系统 $B x = M^{-1} b$ 运行 CG 会违反 SPD 要求，并通过步长分母 $p^{\\top} B p$ 导致算法崩溃，因为当 $B$ 是斜对称时，对于任何非零 $p$，该分母都等于 $0$。\n3. 使用一个 SPD 预条件子实现保对称的 PCG。使用对角（Jacobi）预条件子 $M_{\\mathrm{sym}} = \\mathrm{diag}(A)$，对于给定的 $A$，该预条件子是 SPD 的。在这种配置下，保持 $A$ 作为算子，并使用预处理后的残差 $z_k = M_{\\mathrm{sym}}^{-1} r_k$ 应用 PCG，确保诸如 $r_k^{\\top} z_k \\gt 0$ 的不变量为正，并基于 $p_k^{\\top} A p_k \\gt 0$ 确保步长 $\\alpha_k$ 定义明确。\n4. 作为基准，对 $A$ 运行普通 CG（等效于使用单位矩阵作为预条件子的 PCG）。\n\n对于所有任务，使用右端项 $b = \\mathbf{1} \\in \\mathbb{R}^{N}$（一个全为 1 的向量）。使用 $n = 10$，因此维度为 $N = 100$。使用相对残差容差 $\\varepsilon = 10^{-10}$ 和最大迭代次数 $500$ 次。\n\n设计一个包含三个案例的测试套件：\n- 案例 1：将朴素的左预处理 CG 应用于 $B = M^{-1} A$，其中预条件子 $M = A J$ 是非对称的。如果步长分母 $p^{\\top} B p$ 非正或数值上为零（即 $|p^{\\top} B p| \\leq \\delta$，其中 $\\delta$ 是一个很小的值），则检测到算法崩溃，并返回一个标记结果。\n- 案例 2：将保对称的 PCG 应用于矩阵 $A$，使用 SPD 预条件子 $M_{\\mathrm{sym}} = \\mathrm{diag}(A)$；当相对残差 $\\|r_k\\|_2 / \\|b\\|_2 \\leq \\varepsilon$ 时停止，并报告迭代次数。\n- 案例 3：将普通 CG 应用于矩阵 $A$，使用单位矩阵作为预条件子；在相同标准下停止，并报告迭代次数。\n\n输出规格：\n- 对于每个测试案例，返回一个整数：\n    - 对于案例 1：如果在收敛前检测到崩溃，则返回 $-1$；否则返回达到容差时的迭代次数（由于 $B$ 是斜对称的特定构造，预期结果应为 $-1$）。\n    - 对于案例 2：返回 PCG 达到容差所需的迭代次数。\n    - 对于案例 3：返回普通 CG 达到容差所需的迭代次数。\n- 您的程序应生成单行输出，其中包含三个整数结果，以逗号分隔并用方括号括起，例如，$\\left[ r_1, r_2, r_3 \\right]$ 以文本形式呈现为 `[r1,r2,r3]` 的确切格式。\n\n约束条件：\n- 仅使用精确的浮点算术和线性代数运算；不使用外部随机性。\n- 通过保护 CG 迭代中的分母来确保数值稳定性，并通过 $B$ 的斜对称性为案例 1 确定性地定义崩溃。\n- 最终程序必须是完整的，无需用户输入即可运行，并且必须使用规定的参数实现这三个案例，并以指定格式返回结果。", "solution": "该问题陈述被评估为有效。它在数值线性代数方面具有科学依据，问题设定良好、客观且内部一致。构建和执行计算实验所需的所有数据和定义均已提供。\n\n目标是证明在使用共轭梯度 (CG) 法时，保对称预处理的必要性。我们将比较三种情况：(1) 一种导致算法崩溃的朴素、非对称的预处理方案，(2) 一种正确的、保对称的预处理方案 (PCG)，以及 (3) 作为基准的标准、无预处理的 CG 方法。\n\n### 系统、向量和参数\n待求解的线性系统是 $Ax=b$。\n- 矩阵 $A \\in \\mathbb{R}^{N \\times N}$ 表示在均匀的 $n \\times n$ 网格上，使用狄利克雷边界条件的二维负拉普拉斯算子的五点有限差分格式离散化。网格大小为 $n=10$，因此矩阵维度为 $N = n^2 = 100$。矩阵 $A$ 的构建方式是：主对角线元素为 $4$，对应网格中四个相邻邻居的非对角线元素为 $-1$。这种构造确保了 $A$ 是对称正定 (SPD) 的，这是标准 CG 方法收敛的基本要求。\n- 右端向量为 $b = \\mathbf{1} \\in \\mathbb{R}^{N}$，一个全为 1 的向量。\n- 解的初始猜测为 $x_0 = \\mathbf{0} \\in \\mathbb{R}^{N}$。\n- 当相对残差范数满足 $\\|r_k\\|_2 / \\|b\\|_2 \\leq \\varepsilon$ 时，迭代方法终止，其中容差为 $\\varepsilon = 10^{-10}$。最大迭代次数设置为 $500$。\n\n### 案例 1：使用非对称预条件子的朴素左预处理 CG\n这个案例说明了当 CG 的核心假设被违反时，该方法会失败。我们对一个朴素的左预处理系统应用 CG。\n预条件子定义为 $M = AJ$，其中 $J \\in \\mathbb{R}^{N \\times N}$ 是一个块对角矩阵，由 $N/2 = 50$ 个 $2 \\times 2$ 的斜对称旋转矩阵 $K = \\begin{bmatrix} 0  1 \\\\ -1  0 \\end{bmatrix}$ 组成。\n\n首先，我们分析 $J$ 的属性：\n1.  **斜对称性**：$K$ 的转置是 $K^{\\top} = \\begin{bmatrix} 0  -1 \\\\ 1  0 \\end{bmatrix} = -K$。由于 $J$ 是由 $K$ 块组成的块对角矩阵，$J^{\\top}$ 就是由 $K^{\\top}$ 块组成的块对角矩阵，这意味着 $J^{\\top} = -J$。因此，$J$ 是斜对称的。\n2.  **正交性**：我们计算 $K K^{\\top} = K(-K) = -K^2 = -\\begin{bmatrix} -1  0 \\\\ 0  -1 \\end{bmatrix} = I_2$。由于 $J J^{\\top}$ 是由 $K K^{\\top}$ 块组成的块对角矩阵，因此 $J J^{\\top} = I_N$。所以，$J$ 是一个正交矩阵，其逆矩阵是其转置，即 $J^{-1} = J^{\\top}$。\n\n结合这些属性，我们得到 $J^{-1} = J^{\\top} = -J$。\n\n左预处理系统为 $M^{-1} A x = M^{-1} b$。用于 CG 方法的算子变为 $B = M^{-1}A$。\n$$B = (AJ)^{-1}A = J^{-1}A^{-1}A = J^{-1}I = J^{-1}$$\n因此，算子为 $B = J^{-1}$。我们可以证明 $B$ 是斜对称的：\n$$B^{\\top} = (J^{-1})^{\\top} = (J^{\\top})^{-1} = (-J)^{-1} = -(J^{-1}) = -B$$\nCG 算法要求算子是 SPD 的。迭代中的一个关键步骤是计算步长：\n$$\\alpha_k = \\frac{r_k^{\\top} r_k}{p_k^{\\top} B p_k}$$\n分母是一个涉及算子 $B$ 的二次型。对于任何斜对称矩阵 $B$ 和任何非零向量 $p$，该二次型恒等于零：\n$$p^{\\top}Bp = (p^{\\top}Bp)^{\\top} = p^{\\top}B^{\\top}p = p^{\\top}(-B)p = -p^{\\top}Bp$$\n唯一一个等于其自身相反数的标量是 $0$。因此，对于任何搜索方向 $p_k$，$p_k^{\\top} B p_k = 0$。这会导致除以零，立即引起算法崩溃。我们将通过检查 $|p_k^{\\top} B p_k| \\le \\delta$（其中 $\\delta$ 为一个小的容差）来检测这一点，如果条件成立，则报告失败，结果为 $-1$。\n\n### 案例 2：保对称的预条件共轭梯度 (PCG)\n要将预处理正确地应用于 SPD 系统以供 CG 使用，预条件子 $M_{\\mathrm{sym}}$ 本身必须是 SPD 的，并且其应用方式必须保持有效算子的对称性。PCG 算法实现了这一点。\n\n在这里，我们使用一个简单而有效的 SPD 预条件子：Jacobi（或对角）预条件子 $M_{\\mathrm{sym}} = \\mathrm{diag}(A)$。对于我们特定的矩阵 $A$，所有对角元素都是 $4$，因此 $M_{\\mathrm{sym}} = 4I$，这显然是 SPD 的。其逆为 $M_{\\mathrm{sym}}^{-1} = \\frac{1}{4}I$。\n\nPCG 算法在步长计算（$p_k^\\top A p_k$）中保留了原始的 SPD 算子 $A$，确保分母始终为正。预处理步骤涉及求解系统 $M_{\\mathrm{sym}} z_k = r_k$ 以获得预处理后的残差 $z_k$。这用于更新搜索方向：\n$$p_{k+1} = z_{k+1} + \\beta_{k+1} p_k, \\quad \\text{where} \\quad \\beta_{k+1} = \\frac{r_{k+1}^{\\top} z_{k+1}}{r_k^{\\top} z_k}$$\n这种公式保证了方法的良定性，并且通常比无预处理的 CG 加速收敛。我们将报告达到收敛容差所需的迭代次数。\n\n### 案例 3：标准共轭梯度 (CG)\n这个案例作为我们的基准。我们将标准 CG 算法应用于原始的 SPD 系统 $Ax=b$。这在数学上等同于使用单位矩阵作为预条件子（$M=I$）的 PCG。由于 $A$ 是 SPD 的，预期该方法会收敛，但可能比案例 2 中良好预处理的 PCG 慢。我们将报告迭代次数以进行比较。\n\n该计算实验将产生三个整数结果：三个案例中每一个的结果，从而证明正确选择和应用预条件子的至关重要性。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Constructs and solves the three test cases as specified in the problem.\n    \"\"\"\n    n = 10\n    N = n * n\n    tol = 1e-10\n    max_iter = 500\n\n    def construct_A(n_grid):\n        \"\"\"Constructs the discrete 2D Laplacian matrix A.\"\"\"\n        n_dim = n_grid * n_grid\n        A = np.zeros((n_dim, n_dim))\n        for k in range(n_dim):\n            i, j = k // n_grid, k % n_grid\n            A[k, k] = 4\n            if i > 0: A[k, k - n_grid] = -1\n            if i  n_grid - 1: A[k, k + n_grid] = -1\n            if j > 0: A[k, k - 1] = -1\n            if j  n_grid - 1: A[k, k + 1] = -1\n        return A\n\n    A = construct_A(n)\n    b = np.ones(N)\n\n    def case1_solver():\n        \"\"\"\n        Case 1: Naive left-preconditioned CG.\n        Expected to break down. Returns -1 on breakdown or max_iter.\n        \"\"\"\n        # Construct the skew-symmetric operator B\n        J = np.zeros((N, N))\n        for i in range(N // 2):\n            J[2 * i, 2 * i + 1] = 1\n            J[2 * i + 1, 2 * i] = -1\n        \n        # Operator B = M^{-1}A = J^{-1} = -J\n        B = -J \n        # RHS b' = M^{-1}b = J^{-1}b = -Jb\n        b_prime = -J @ b\n        \n        x = np.zeros(N)\n        r_prime = b_prime.copy()  # Residual of the preconditioned system\n        p = r_prime.copy()\n        rs_old = r_prime @ r_prime\n        \n        norm_b = np.linalg.norm(b)\n        \n        for k in range(max_iter):\n            Bp = B @ p\n            pBp = p @ Bp\n            \n            # Breakdown check: denominator is zero for skew-symmetric operator\n            if abs(pBp) = 1e-15:\n                return -1\n            \n            alpha = rs_old / pBp\n            x += alpha * p\n            r_prime -= alpha * Bp\n            \n            # Convergence check uses the true residual r = b - Ax\n            r_true = b - A @ x\n            if np.linalg.norm(r_true) / norm_b = tol:\n                return k + 1\n            \n            rs_new = r_prime @ r_prime\n            beta = rs_new / rs_old\n            p = r_prime + (rs_new / rs_old) * p\n            rs_old = rs_new\n        \n        return -1 # Failure (max iterations reached)\n\n    def case2_solver():\n        \"\"\"\n        Case 2: Symmetry-preserving PCG with Jacobi preconditioner.\n        Expected to converge. Returns iteration count.\n        \"\"\"\n        x = np.zeros(N)\n        r = b.copy()\n        norm_b = np.linalg.norm(b)\n\n        # Initial residual check\n        if np.linalg.norm(r) / norm_b = tol:\n            return 0\n        \n        # Preconditioning step: M_sym = diag(A) = 4I, so z = M_inv * r = r / 4.0\n        z = r / 4.0\n        p = z.copy()\n        rz_old = r @ z\n        \n        for k in range(max_iter):\n            Ap = A @ p\n            pAp = p @ Ap\n            \n            alpha = rz_old / pAp\n            x += alpha * p\n            r -= alpha * Ap\n            \n            if np.linalg.norm(r) / norm_b = tol:\n                return k + 1\n            \n            z = r / 4.0\n            rz_new = r @ z\n            beta = rz_new / rz_old\n            p = z + beta * p\n            rz_old = rz_new\n            \n        return max_iter # Did not converge within max iterations\n\n    def case3_solver():\n        \"\"\"\n        Case 3: Standard CG (no preconditioning).\n        Expected to converge, but slower than Case 2. Returns iteration count.\n        \"\"\"\n        x = np.zeros(N)\n        r = b.copy()\n        norm_b = np.linalg.norm(b)\n\n        if np.linalg.norm(r) / norm_b = tol:\n            return 0\n        \n        p = r.copy()\n        rs_old = r @ r\n        \n        for k in range(max_iter):\n            Ap = A @ p\n            pAp = p @ Ap\n            \n            alpha = rs_old / pAp\n            x += alpha * p\n            r -= alpha * Ap\n            \n            if np.linalg.norm(r) / norm_b = tol:\n                return k + 1\n            \n            rs_new = r @ r\n            beta = rs_new / rs_old\n            p = r + (rs_new / rs_old) * p\n            rs_old = rs_new\n            \n        return max_iter # Did not converge within max iterations\n\n    # Run the three cases and collect the results\n    results = [\n        case1_solver(),\n        case2_solver(),\n        case3_solver()\n    ]\n\n    # Print the final output in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3566284"}, {"introduction": "最后，我们将视野扩展到数据同化和反演问题中的高级应用。本实践介绍了在贝叶斯框架下一个强大的概念：先验预处理（或称先验白化）。通过变量代换，我们将原问题转化为一个谱特性更优的新问题，其特征值在 $1$ 附近高度聚集，从而极大地改善了系统的条件数 [@problem_id:3412970]。这个练习表明，预处理不仅仅是一种数值技巧，更是一个与问题的统计结构紧密交织的深刻概念。", "problem": "考虑一个具有高斯先验和高斯观测噪声的贝叶斯线性逆问题。设 $A \\in \\mathbb{R}^{m \\times n}$ 为线性正演算子，$x \\in \\mathbb{R}^{n}$ 为未知量，$y \\in \\mathbb{R}^{m}$ 为数据，$R \\in \\mathbb{R}^{m \\times m}$ 为数据误差协方差（对称正定），$C \\in \\mathbb{R}^{n \\times n}$ 为先验协方差（对称正定）。最大后验（MAP）估计是通过贝叶斯法则得到的严格凸二次目标的最小化子。MAP 对应的正规方程形式如下\n$$\n\\left(A^{\\top} R^{-1} A + C^{-1}\\right) x = A^{\\top} R^{-1} y + C^{-1} x_{0},\n$$\n其中 $x_{0} \\in \\mathbb{R}^{n}$ 是先验均值。令 $H = A^{\\top} R^{-1} A + C^{-1}$ 表示目标函数在变量 $x$ 下的海森矩阵。\n\n要求您研究由变量代换 $x = x_{0} + C^{1/2} z$ 定义的先验白化（prior-whitening），对于使用对称正定（SPD）系统的共轭梯度法（CG）进行迭代求解所涉及的谱的影响。从高斯模型的基本原理和基础线性代数（谱定理和奇异值分解）出发，推导对称正定系统矩阵，其谱决定了在先验白化变量 $z$ 中的共轭梯度法，并分析其特征值如何依赖于数据项和先验项之间的相互作用。\n\n您的程序必须仅使用下面指定的确定性计算来实现以下内容。\n\n- 对于每个测试用例，按如下方式构造矩阵 $A$、$R$ 和 $C$。\n  - 使用固定的随机种子 $s$ 以确保可复现性。\n  - 抽取一个具有独立条目的标准正态矩阵，并进行瘦 QR 分解以获得一个正交矩阵 $Q$。用它通过 $Q \\, \\mathrm{diag}(\\lambda) \\, Q^{\\top}$ 构造一个对称正定协方差，其中 $\\mathrm{diag}(\\lambda)$ 是具有指定几何谱的对角矩阵。分别执行此构造以获得具有各自尺寸和谱范围的 $C$ 和 $R$。\n  - 用独立的标准正态条目构成 $A$，并按指定的标量 $\\gamma$ 进行缩放。\n- 对于每个测试用例，计算：\n  1. 原始海森矩阵 $H$ 的谱及其谱条件数 $\\kappa(H)$，定义为最大特征值与最小特征值之比。\n  2. 先验白化变量 $z$ 中的对称正定系统矩阵及其谱。从此谱中计算：\n     - 先验白化系统矩阵的谱条件数 $\\kappa$。\n     - 在绝对容差 $\\tau = 10^{-8}$ 内，特征值精确等于 $1$ 的比例（表示为 $[0,1]$ 内的小数）。\n     - 在绝对容差 $\\varepsilon = 10^{-2}$ 内，特征值接近 $1$ 的比例（表示为 $[0,1]$ 内的小数）。\n     - 所有特征值与 $1$ 的最大绝对偏差。\n  3. 比率 $\\kappa(H)/\\kappa$，其中 $\\kappa$ 是第 2 项中先验白化系统矩阵的谱条件数。\n- 实现要求：\n  - 所有线性代数必须使用标准库提供的双精度实数算术进行。\n  - 不允许显式地对 $R$ 和 $C$ 求逆；请使用线性求解或基于分解的方法。\n  - 使用谱定理构建先验白化所需的矩阵平方根。\n  - 根据情况，使用奇异值分解或特征值分解来计算谱量。\n\n使用以下参数值测试套件，其中每个元组代表 $(n, m, \\gamma, c_{\\min}, c_{\\max}, r_{\\min}, r_{\\max}, s)$：\n- 测试 1：$(60, 40, 1.0, 10^{-3}, 10^{3}, 1.0, 1.0, 1)$。\n- 测试 2：$(60, 40, 0.05, 10^{-2}, 10^{2}, 1.0, 1.0, 2)$。\n- 测试 3：$(50, 80, 2.0, 10^{-3}, 10^{3}, 10^{-2}, 10^{2}, 3)$。\n\n对于每个测试，您的程序必须按以下顺序输出一个包含四个浮点数的列表：\n- $\\kappa(H)/\\kappa$，\n- 在容差 $\\tau = 10^{-8}$ 内精确为单位一的特征值的比例，\n- 在容差 $\\varepsilon = 10^{-2}$ 内接近单位一的特征值的比例，\n- 先验白化系统特征值与 $1$ 的最大绝对偏差。\n\n最终输出格式：您的程序应生成单行输出，其中包含所有三个测试的结果，格式为逗号分隔的子列表列表，每个子列表包含相应测试的四个浮点数，并用方括号括起来（例如，$[\\,[a_{1},b_{1},c_{1},d_{1}],\\,[a_{2},b_{2},c_{2},d_{2}],\\,[a_{3},b_{3},c_{3},d_{3}]\\,]$）。不应打印任何附加文本。", "solution": "本问题旨在分析贝叶斯线性逆问题中的先验预处理。我们首先建立理论框架，然后进行数值实现。\n\n### 1. 数学表述\n\n最大后验（MAP）估计是目标函数 $J(x)$ 的最小化子，该函数结合了数据似然和先验信息：\n$$ J(x) = \\frac{1}{2}(Ax - y)^\\top R^{-1}(Ax - y) + \\frac{1}{2}(x - x_0)^\\top C^{-1}(x - x_0) $$\n此目标函数关于 $x$ 的海森矩阵由下式给出：\n$$ H = \\nabla_x^2 J(x) = A^\\top R^{-1} A + C^{-1} $$\n该矩阵是对称正定的（SPD），其谱特性，特别是其条件数 $\\kappa(H)$，决定了像共轭梯度（CG）法这样的迭代求解器的收敛速度。\n\n### 2. 先验白化与预处理系统\n\n该问题引入了一种称为先验白化（prior-whitening）或状态空间预处理的变量代换：\n$$ x = x_0 + C^{1/2} z $$\n其中 $C^{1/2}$ 是先验协方差矩阵 $C$ 的唯一对称正定平方根。新的未知量是 $z \\in \\mathbb{R}^n$。如果 $x$ 的先验是 $x \\sim \\mathcal{N}(x_0, C)$，那么这个变换意味着 $z = C^{-1/2}(x-x_0)$ 服从标准正态分布，$z \\sim \\mathcal{N}(0, I)$。\n\n我们用新变量 $z$ 重新表示目标函数 $J(x)$。设 $\\tilde{J}(z) = J(x_0 + C^{1/2}z)$。$J(x)$ 中的两项变为：\n1.  **数据保真项**：\n    $$ (A(x_0 + C^{1/2}z) - y) = A C^{1/2} z + (Ax_0 - y) $$\n    目标函数中的项变为 $\\frac{1}{2} (A C^{1/2} z + (Ax_0-y))^\\top R^{-1} (A C^{1/2} z + (Ax_0-y))$。\n2.  **先验项**：\n    $$ (x - x_0) = (x_0 + C^{1/2}z - x_0) = C^{1/2}z $$\n    目标函数中的项变为 $\\frac{1}{2} (C^{1/2}z)^\\top C^{-1} (C^{1/2}z) = \\frac{1}{2} z^\\top C^{1/2} C^{-1} C^{1/2} z = \\frac{1}{2} z^\\top I z = \\frac{1}{2} z^\\top z$。\n\n新目标函数 $\\tilde{J}(z)$ 的海森矩阵通过对 $z$ 求二阶导数得到。只有 $z$ 的二次项有贡献。$\\tilde{J}(z)$ 的二次部分是：\n$$ \\frac{1}{2} z^\\top \\left( (A C^{1/2})^\\top R^{-1} (A C^{1/2}) \\right) z + \\frac{1}{2} z^\\top z = \\frac{1}{2} z^\\top \\left( C^{1/2} A^\\top R^{-1} A C^{1/2} + I \\right) z $$\n因此，在 $z$ 坐标系中的海森矩阵，我们记为 $H_z$，是：\n$$ H_z = \\nabla_z^2 \\tilde{J}(z) = C^{1/2} A^\\top R^{-1} A C^{1/2} + I $$\n这就是 SPD 系统矩阵，其谱决定了应用于 $z$ 的最小化问题的 CG 方法的收敛性。此变换是原始海森矩阵 $H$ 的一种对称预处理形式，其中 $H_z = C^{1/2} H C^{1/2}$。\n\n### 3. 预处理后海森矩阵 $H_z$ 的谱分析\n\n我们来分析 $H_z$ 的特征值。定义一个新矩阵 $\\tilde{A} = R^{-1/2} A C^{1/2}$。由于 $R$ 和 $C$ 是 SPD 矩阵，它们的平方根和逆平方根是良定义且对称的。我们可以将 $H_z$ 重写为：\n$$ H_z = (C^{1/2})^\\top A^\\top (R^{-1/2})^\\top R^{-1/2} A C^{1/2} + I = (R^{-1/2} A C^{1/2})^\\top (R^{-1/2} A C^{1/2}) + I = \\tilde{A}^\\top \\tilde{A} + I $$\n$H_z$ 的特征值，记为 $\\lambda_i(H_z)$，与 $\\tilde{A}$ 的奇异值，记为 $\\sigma_i(\\tilde{A})$，关系如下：\n$$ \\lambda_i(H_z) = \\lambda_i(\\tilde{A}^\\top \\tilde{A} + I) = \\lambda_i(\\tilde{A}^\\top \\tilde{A}) + 1 = \\sigma_i^2(\\tilde{A}) + 1 $$\n此关系揭示了预处理系统的关键属性：\n- **正定性**：由于 $\\sigma_i^2(\\tilde{A}) \\ge 0$，所以 $H_z$ 的所有特征值都 $\\ge 1$。这保证了 $H_z$ 不仅是 SPD 的，而且在求逆方面也是良态的，因为它的最小特征值有远离零的下界。\n- **单位特征值**：一个特征值 $\\lambda_i(H_z)$ 精确等于 $1$ 当且仅当对应的奇异值 $\\sigma_i(\\tilde{A}) = 0$。零奇异值的数量等于 $\\tilde{A}$ 的零空间维度。由于 $R^{-1/2}$ 和 $C^{1/2}$ 是可逆的，所以 $\\mathrm{rank}(\\tilde{A}) = \\mathrm{rank}(A)$。对于一个 $m \\times n$ 的矩阵 $A$，其零空间的维度是 $n - \\mathrm{rank}(A)$。对于从连续分布生成的随机矩阵 $A$，其秩几乎必然是 $\\min(m, n)$。因此，单位特征值的数量预期为 $n - \\min(m, n) = \\max(0, n-m)$。\n- **特征值聚集**：如果 $\\tilde{A}$ 的奇异值很小，$H_z$ 的特征值就会聚集在 $1$ 附近。当数据相对于先验提供的信息很少时，就会发生这种情况，例如，如果算子 $A$ 的缩放因子 $\\gamma$ 很小。在这种情况下，预处理非常有效，导致条件数 $\\kappa(H_z)$ 接近 $1$。\n\n### 4. 实现计划\n\n该解决方案通过对每个测试用例执行以下步骤来实现：\n1.  **矩阵构造**：一个辅助函数使用固定的随机种子创建具有指定维度和几何谱的 SPD 矩阵 $R$ 和 $C$，以保证可复现性。正演算子 $A$ 也会被生成和缩放。\n2.  **原始海森矩阵 $H$**：组装矩阵 $H = A^\\top R^{-1} A + C^{-1}$。与逆矩阵的乘积使用 `numpy.linalg.solve` 计算以避免显式求逆。使用 `numpy.linalg.eigvalsh` 计算 $H$ 的特征值以求得其条件数 $\\kappa(H)$。\n3.  **预处理后的海森矩阵 $H_z$**：从 $C$ 的谱分解中计算平方根 $C^{1/2}$。然后，再次使用 `solve` 形成 $H_z = C^{1/2} A^\\top R^{-1} A C^{1/2} + I$。计算其特征值以求得 $\\kappa(H_z)$ 并分析其分布。\n4.  **分析**：计算并存储所需的度量——比率 $\\kappa(H)/\\kappa(H_z)$、精确单位特征值和近似单位特征值的比例，以及与 $1$ 的最大偏差。", "answer": "```python\nimport numpy as np\n\ndef create_spd_matrix(dim, spec_min, spec_max, rng):\n    \"\"\"\n    Constructs a symmetric positive definite (SPD) matrix with a prescribed geometric spectrum.\n    \n    Args:\n        dim (int): The dimension of the square matrix.\n        spec_min (float): The minimum eigenvalue.\n        spec_max (float): The maximum eigenvalue.\n        rng (np.random.Generator): A NumPy random number generator.\n    \n    Returns:\n        np.ndarray: An SPD matrix of shape (dim, dim).\n    \"\"\"\n    # Generate a random matrix\n    random_matrix = rng.standard_normal((dim, dim))\n    # Get an orthonormal basis from its QR decomposition\n    q, _ = np.linalg.qr(random_matrix)\n    \n    # Create a diagonal matrix with a geometric spectrum\n    eigenvalues = np.geomspace(spec_min, spec_max, dim)\n    lambda_diag = np.diag(eigenvalues)\n    \n    # Construct the SPD matrix using the spectral theorem M = Q * Lambda * Q^T\n    spd_matrix = q @ lambda_diag @ q.T\n    return spd_matrix\n\ndef compute_matrix_sqrt(matrix):\n    \"\"\"\n    Computes the symmetric positive definite square root of a matrix.\n    \n    Args:\n        matrix (np.ndarray): The SPD matrix.\n    \n    Returns:\n        np.ndarray: The symmetric square root matrix.\n    \"\"\"\n    eigenvalues, eigenvectors = np.linalg.eigh(matrix)\n    sqrt_eigenvalues = np.sqrt(eigenvalues)\n    return eigenvectors @ np.diag(sqrt_eigenvalues) @ eigenvectors.T\n\ndef solve():\n    \"\"\"\n    Main function to run the test cases and produce the final output.\n    \"\"\"\n    # Tuples of (n, m, gamma, c_min, c_max, r_min, r_max, s)\n    test_cases = [\n        (60, 40, 1.0, 1e-3, 1e3, 1.0, 1.0, 1),\n        (60, 40, 0.05, 1e-2, 1e2, 1.0, 1.0, 2),\n        (50, 80, 2.0, 1e-3, 1e3, 1e-2, 1e2, 3),\n    ]\n\n    all_results = []\n\n    for n, m, gamma, c_min, c_max, r_min, r_max, seed in test_cases:\n        rng = np.random.default_rng(seed)\n\n        # 1. Construct matrices A, R, and C\n        C = create_spd_matrix(n, c_min, c_max, rng)\n        R = create_spd_matrix(m, r_min, r_max, rng)\n        A = gamma * rng.standard_normal((m, n))\n        \n        # 2. Compute original Hessian H and its spectrum\n        # H = A.T @ R_inv @ A + C_inv\n        # Avoid explicit inversion using solves\n        R_inv_A = np.linalg.solve(R, A)\n        C_inv = np.linalg.solve(C, np.identity(n))\n        H = A.T @ R_inv_A + C_inv\n        \n        eig_H = np.linalg.eigvalsh(H)\n        kappa_H = eig_H.max() / eig_H.min()\n\n        # 3. Compute prior-whitened Hessian H_z and its spectrum\n        # H_z = C^(1/2) * A.T * R^(-1) * A * C^(1/2) + I\n        C_sqrt = compute_matrix_sqrt(C)\n        \n        X = A @ C_sqrt\n        # Y = R^(-1) * X\n        Y = np.linalg.solve(R, X)\n        H_z = X.T @ Y + np.identity(n)\n\n        eig_Hz = np.linalg.eigvalsh(H_z)\n        \n        # 4. Analyze the spectrum of H_z\n        kappa_z = eig_Hz.max() / eig_Hz.min()\n        \n        # Fraction of eigenvalues equal to 1 (within tolerance tau)\n        tau = 1e-8\n        frac_exact_1 = np.sum(np.abs(eig_Hz - 1.0) = tau) / n\n        \n        # Fraction of eigenvalues near 1 (within tolerance epsilon)\n        epsilon = 1e-2\n        frac_near_1 = np.sum(np.abs(eig_Hz - 1.0) = epsilon) / n\n\n        # Maximum absolute deviation from 1\n        max_dev = np.max(np.abs(eig_Hz - 1.0))\n\n        # 5. Compute the ratio of condition numbers\n        ratio_kappa = kappa_H / kappa_z\n\n        all_results.append([ratio_kappa, frac_exact_1, frac_near_1, max_dev])\n\n    # Format the final output as specified\n    # e.g., [[a1,b1,c1,d1],[a2,b2,c2,d2],[a3,b3,c3,d3]]\n    output_str = \"[\" + \",\".join([f\"[{','.join(map(str, res))}]\" for res in all_results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3412970"}]}