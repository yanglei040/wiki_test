{"hands_on_practices": [{"introduction": "雅可比矩阵是高斯-牛顿方法的核心，它通过线性化将非线性问题转化为一系列线性子问题。本练习将引导你从第一性原理出发，为一个简单的非线性正演模型构建雅可比矩阵 $J(m)$。更重要的是，它将展示如何将雅可比矩阵的各个条目解读为“灵敏度”系数，从而获得关于数据如何约束模型参数的物理直觉，并理解其如何影响反演问题的稳定性 [@problem_id:3599237]。", "problem": "考虑一个双参数地球物理模型 $m=\\begin{pmatrix} m_1 \\\\ m_2 \\end{pmatrix}$，其中 $m_1$ 代表一个控制带限振幅响应的标量属性，$m_2$ 代表一个与各向异性相关的耦合参数。正演算子 $F:\\mathbb{R}^2\\to\\mathbb{R}^2$ 定义为 $F(m)=\\begin{pmatrix} \\sin(\\alpha m_1) \\\\ m_1 m_2 \\end{pmatrix}$，其中 $\\alpha0$ 是一个已知的缩放常数，其单位的选择使得正弦函数的参数为无量纲。数据加权矩阵是单位矩阵 $W_d=I$。非线性最小二乘拟合差定义为 $\\phi(m)=\\tfrac{1}{2}\\|F(m)-d\\|_2^2$，其中 $d\\in\\mathbb{R}^2$ 是观测数据。\n\n从 $F(m)$ 的雅可比矩阵和残差的高斯-牛顿线性化的核心定义出发，显式地推导出雅可比矩阵 $J(m)$（用 $m_1$、$m_2$ 和 $\\alpha$ 表示）。然后，解释 $J(m)$ 的每个元素如何反映数据对参数的物理灵敏度，并阐释这些元素的大小和符号如何影响高斯-牛顿法向矩阵的条件性。你的推导应从第一性原理出发，而不直接使用关于 $F(m)$ 的雅可比矩阵或高斯-牛顿方法的已有公式。\n\n请给出 $J(m)$ 的显式闭式解析表达式作为最终答案。无需进行数值舍入。如果引入任何角度，必须以弧度为单位。由于最终答案是符号表达式，最终表达式中不应包含单位。", "solution": "该问题要求针对给定的正演模型 $F(m)$ 推导雅可比矩阵 $J(m)$，并阐释其元素的物理意义及其对高斯-牛顿法的影响。问题陈述具有科学依据、适定性和客观性。我们可以开始求解。\n\n正演模型是一个函数 $F: \\mathbb{R}^2 \\to \\mathbb{R}^2$，它将模型参数向量 $m=\\begin{pmatrix} m_1 \\\\ m_2 \\end{pmatrix}$ 映射到一个数据向量。正演算子的分量如下：\n$$\nF(m) = \\begin{pmatrix} F_1(m_1, m_2) \\\\ F_2(m_1, m_2) \\end{pmatrix} = \\begin{pmatrix} \\sin(\\alpha m_1) \\\\ m_1 m_2 \\end{pmatrix}\n$$\n其中 $\\alpha  0$ 是一个已知常数。\n\n根据定义，向量值函数 $F(m)$ 的雅可比矩阵 $J(m)$ 是所有一阶偏导数组成的矩阵。对于一个从 $\\mathbb{R}^2$ 映射到 $\\mathbb{R}^2$ 的函数，它是一个 $2 \\times 2$ 矩阵：\n$$\nJ(m) = \\begin{pmatrix} \\frac{\\partial F_1}{\\partial m_1}  \\frac{\\partial F_1}{\\partial m_2} \\\\ \\frac{\\partial F_2}{\\partial m_1}  \\frac{\\partial F_2}{\\partial m_2} \\end{pmatrix}\n$$\n\n接下来，我们利用偏微分法则，从第一性原理出发计算 $J(m)$ 的每个元素。\n\n第一个元素 $J_{11}$ 是 $F_1(m_1, m_2) = \\sin(\\alpha m_1)$ 对 $m_1$ 的偏导数。应用链式法则，我们得到：\n$$\nJ_{11} = \\frac{\\partial}{\\partial m_1} \\left( \\sin(\\alpha m_1) \\right) = \\cos(\\alpha m_1) \\cdot \\frac{\\partial}{\\partial m_1}(\\alpha m_1) = \\alpha \\cos(\\alpha m_1)\n$$\n\n第二个元素 $J_{12}$ 是 $F_1(m_1, m_2) = \\sin(\\alpha m_1)$ 对 $m_2$ 的偏导数。由于 $F_1$ 不依赖于 $m_2$，该导数为零：\n$$\nJ_{12} = \\frac{\\partial}{\\partial m_2} \\left( \\sin(\\alpha m_1) \\right) = 0\n$$\n\n第三个元素 $J_{21}$ 是 $F_2(m_1, m_2) = m_1 m_2$ 对 $m_1$ 的偏导数：\n$$\nJ_{21} = \\frac{\\partial}{\\partial m_1} \\left( m_1 m_2 \\right) = m_2\n$$\n\n第四个元素 $J_{22}$ 是 $F_2(m_1, m_2) = m_1 m_2$ 对 $m_2$ 的偏导数：\n$$\nJ_{22} = \\frac{\\partial}{\\partial m_2} \\left( m_1 m_2 \\right) = m_1\n$$\n\n将这些偏导数组合成矩阵，便得到雅可比矩阵 $J(m)$ 的显式形式：\n$$\nJ(m) = \\begin{pmatrix} \\alpha \\cos(\\alpha m_1)  0 \\\\ m_2  m_1 \\end{pmatrix}\n$$\n\n接下来，我们阐释这些元素的物理意义及其对高斯-牛顿法向矩阵条件性的影响。每个元素 $J_{ij} = \\frac{\\partial F_i}{\\partial m_j}$ 代表第 $i$ 个数据分量对第 $j$ 个模型参数无穷小变化的灵敏度。\n- $J_{11} = \\alpha \\cos(\\alpha m_1)$: 该项量化了第一个数据 $F_1 = \\sin(\\alpha m_1)$ 对参数 $m_1$ 变化的灵敏度。该灵敏度是振荡的，当 $|\\cos(\\alpha m_1)| = 1$ 时（即 $\\alpha m_1$ 是 $\\pi$ 的整数倍时），其幅值达到最大。在这些点上，函数 $F_1$ 穿过零点，斜率最陡。相反，当 $\\cos(\\alpha m_1) = 0$ 时（即对于任意整数 $n$，$\\alpha m_1 = (n + \\frac{1}{2})\\pi$），灵敏度为零。这些点对应于正弦波的波峰和波谷，在这些点上，$m_1$ 的微小变化对 $F_1$ 产生的影响可以忽略不计。\n- $J_{12} = 0$: 这表明第一个数据 $F_1$ 对参数 $m_2$ 的变化完全不敏感。根据该模型，带限振幅响应的测量与各向异性参数完全解耦。\n- $J_{21} = m_2$: 这是第二个数据 $F_2 = m_1 m_2$ 对 $m_1$ 扰动的灵敏度。该灵敏度与耦合参数 $m_2$ 的值成正比。如果 $m_2$ 接近于零，第二个数据对 $m_1$ 变得不敏感，意味着耦合较弱。\n- $J_{22} = m_1$: 这是第二个数据 $F_2$ 对 $m_2$ 变化的灵敏度。该灵敏度与 $m_1$ 成正比。如果 $m_1$ 接近于零，第二个数据对各向异性参数 $m_2$ 不敏感。\n\n高斯-牛顿法使用矩阵 $H_{GN} = J(m)^T J(m)$ 来近似拟合差函数 $\\phi(m)$ 的Hessian矩阵（因为数据加权矩阵 $W_d = I$）。这个法向矩阵的条件性对反演的稳定性和收敛性至关重要。一个病态或奇异的 $H_{GN}$ 会导致不稳定的参数更新。\n法向矩阵为：\n$$\nH_{GN} = J^T J = \\begin{pmatrix} \\alpha \\cos(\\alpha m_1)  m_2 \\\\ 0  m_1 \\end{pmatrix} \\begin{pmatrix} \\alpha \\cos(\\alpha m_1)  0 \\\\ m_2  m_1 \\end{pmatrix} = \\begin{pmatrix} \\alpha^2 \\cos^2(\\alpha m_1) + m_2^2  m_1 m_2 \\\\ m_1 m_2  m_1^2 \\end{pmatrix}\n$$\n局部线性问题的适定性取决于 $H_{GN}$ 是否可逆。这等价于 $J(m)$ 的列向量是否线性无关。$H_{GN}$ 的行列式提供了对此的一种度量。对于方阵 $A$，利用性质 $\\det(A^T A) = (\\det A)^2$，我们可以计算：\n$$\n\\det(J) = (\\alpha \\cos(\\alpha m_1))(m_1) - (0)(m_2) = \\alpha m_1 \\cos(\\alpha m_1)\n$$\n因此，法向矩阵的行列式为：\n$$\n\\det(H_{GN}) = (\\det(J))^2 = \\alpha^2 m_1^2 \\cos^2(\\alpha m_1)\n$$\n如果 $\\det(H_{GN}) = 0$，法向矩阵 $H_{GN}$ 会变得奇异，反演问题会变得病态。这在以下两种情况下发生：\n1. $m_1 = 0$: 如果振幅参数 $m_1$ 为零，雅可比矩阵变为 $J = \\begin{pmatrix} \\alpha  0 \\\\ m_2  0 \\end{pmatrix}$，其列向量线性相关。从物理上看，如果 $m_1=0$，那么对于任何 $m_2$ 的值，都有 $F(m) = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$。数据中不包含任何关于 $m_2$ 的信息，使其恢复变得不可能。\n2. $\\cos(\\alpha m_1) = 0$: 这发生在对于任意整数 $k$ 有 $\\alpha m_1_k = \\frac{\\pi}{2} + k\\pi$ 时。在这种情况下，雅可比矩阵为 $J = \\begin{pmatrix} 0  0 \\\\ m_2  m_1 \\end{pmatrix}$。第一行为零，使得矩阵秩亏。从物理上看，这对应于我们之前讨论过的第一个数据 $d_1$ 相对于 $m_1$ 的灵敏度为零的点。在 $F_1$ 的这些极值点，$m_1$ 的微小扰动无法在第一个数据中反映出来，从而导致信息损失和系统病态。\n\n元素的量级也影响条件性。如果 $m_1$ 非常小，$\\det(H_{GN})$ 会变得非常小，导致差的条件性。类似地，如果模型接近 $\\cos(\\alpha m_1) \\approx 0$ 的点，问题也接近病态。雅可比矩阵元素的符号虽然不直接影响 $J^T J$ 的条件性（因为项被平方了），但对于确定高斯-牛顿算法中参数更新步长 $\\delta m$ 的方向至关重要，因为更新依赖于乘积 $J^T (d - F(m))$。", "answer": "$$\n\\boxed{\nJ(m) = \\begin{pmatrix}\n\\alpha \\cos(\\alpha m_1)  0 \\\\\nm_2  m_1\n\\end{pmatrix}\n}\n$$", "id": "3599237"}, {"introduction": "反演问题中的一个主要挑战是非唯一性，即不同的模型参数可能产生完全相同的数据。本练习构建了一个具有“可辨识性脊”的情景——存在一整族解，它们都能同等地拟合数据。你将看到标准的高斯-牛顿方法在这种情况下如何失效，并亲手实现两种强大的正则化技术来恢复解的唯一性和稳定性，从而理解为何正则化在实际应用中往往是必不可少的 [@problem_id:3384262]。", "problem": "考虑一个包含两个参数的非线性最小二乘反问题，其中正演映射仅依赖于一个单一的可辨识组合。设参数向量为 $x = (x_1, x_2) \\in \\mathbb{R}^2$，正演模型 $f: \\mathbb{R}^2 \\to \\mathbb{R}^2$ 定义为\n$$\nf(x) = \\begin{bmatrix}\n\\alpha \\left( \\exp(x_1 + x_2) - 1 \\right) \\\\\n\\beta \\sin(x_1 + x_2)\n\\end{bmatrix},\n$$\n其中 $\\alpha$ 和 $\\beta$ 为已知的正常数。观测数据 $y \\in \\mathbb{R}^2$ 是通过选取一个真实值 $x^{\\star}$ 并令 $y = f(x^{\\star})$ 来人工合成的。残差为 $r(x) = f(x) - y$，代价函数为 $F(x) = \\tfrac{1}{2} \\| r(x) \\|_2^2$。这种结构产生了一个可辨识性脊，因为 $f(x)$ 仅依赖于 $s = x_1 + x_2$，所以当 $s$ 与 $y$ 中编码的可辨识组合匹配时，$F(x)$ 在正交方向 $v = x_1 - x_2$ 上是平坦的。\n\n你的任务是：\n- 从线性化和最小二乘法的基本原理出发，推导如何得到用于最小化 $F(x)$ 的 Gauss-Newton (GN) 方法。具体来说，从残差 $r(x)$ 的定义开始，进行一阶泰勒线性化 $r(x + \\delta) \\approx r(x) + J(x)\\,\\delta$，其中 $J(x)$ 是 $r(x)$ 的雅可比矩阵，并说明 GN 步长是如何通过求解每次迭代中的线性化最小二乘子问题得到的。\n- 利用 $f(x)$ 的结构，论证为何在 $s = x_1 + x_2$ 保持常数的方向上存在一个可辨识性脊，并描述其对近似 Gauss-Newton Hessian 矩阵 $J(x)^{\\top} J(x)$ 的影响。\n- 提出并通过二次先验或结构约束实现曲率注入，以消除该脊。使用一个二次先验，通过选择 $L \\in \\mathbb{R}^{1 \\times 2}$ 和正则化权重 $\\lambda  0$ 来惩罚不可辨识方向 $v = x_1 - x_2$，并推导由此产生的修改后的 Gauss-Newton 正规方程。\n\n实现一个程序，该程序：\n- 使用常数 $\\alpha = 1$, $\\beta = \\tfrac{1}{2}$ 和真实值 $x^{\\star} = (0.5, -0.3)$，使得 $y = f(x^{\\star})$。角度以弧度为单位。\n- 实现一个 Gauss-Newton 求解器，用于在没有正则化的情况下最小化 $F(x)$，并使用以下三个初始猜测值：\n  1. $x^{(0)}_{\\mathrm{A}} = (1.6, -1.0)$，\n  2. $x^{(0)}_{\\mathrm{B}} = (0.7, -0.5)$，\n  3. $x^{(0)}_{\\mathrm{C}} = (-0.5, 0.7)$。\n  对于每次运行，报告收敛后 $v = x_1 - x_2$ 的最终值。这展示了沿可辨识性脊的漂移（即 $F(x)$ 对 $v$ 的实际不敏感性）。\n- 实现一个带有二次先验（Tikhonov 型曲率注入）的 Gauss-Newton 求解器，通过最小化\n$$\n\\Phi(x) = \\tfrac{1}{2} \\| r(x) \\|_2^2 + \\tfrac{\\lambda}{2} \\| L(x - x_{\\mathrm{ref}}) \\|_2^2,\n$$\n来惩罚不可辨识方向 $v$，其中 $L = \\begin{bmatrix} 1  -1 \\end{bmatrix}$，$x_{\\mathrm{ref}} = (0,0)$，且 $\\lambda = 1$。对于与上述相同的三个初始猜测值，运行正则化的 Gauss-Newton 求解器，并报告收敛后 $v = x_1 - x_2$ 的最终值。这展示了如何通过先验注入曲率，在脊上选择一个唯一的解，从而消除漂移。\n- 通过将一个轻微扰动的正演模型\n$$\nf_{\\gamma}(x) = \\begin{bmatrix}\n\\alpha \\left( \\exp(x_1 + x_2) - 1 \\right) \\\\\n\\beta \\sin(x_1 + x_2) + \\gamma (x_1 - x_2)\n\\end{bmatrix},\n$$\n（其中 $\\gamma = 10^{-3}$）拟合到上面生成的相同数据 $y$（来自 $\\gamma = 0$ 的情况），实现一个额外的边缘情况结构测试。这模拟了在正演映射中加入一个结构约束，该约束沿着先前平坦的方向注入曲率。对于两个初始猜测值 $x^{(0)}_{\\mathrm{B}}$ 和 $x^{(0)}_{\\mathrm{C}}$，运行未正则化的 Gauss-Newton 求解器，并报告 $v = x_1 - x_2$ 的最终值。\n\n数值和算法要求：\n- 每次迭代的 Gauss-Newton 子问题必须基于线性化推导，并作为线性最小二乘问题求解。您不得使用绕过“线性化加最小二乘”原则的闭式解。\n- 如果需要，使用简单的回溯线搜索以确保目标函数的单调递减。当步长范数低于一个小容差或达到最大迭代次数时停止。\n- 此问题中没有物理单位。\n- 测试套件：\n  - 案例 1：未正则化的 Gauss-Newton，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{A}}$ 开始；输出最终的 $v$。\n  - 案例 2：未正则化的 Gauss-Newton，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{B}}$ 开始；输出最终的 $v$。\n  - 案例 3：未正则化的 Gauss-Newton，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{C}}$ 开始；输出最终的 $v$。\n  - 案例 4：带先验的正则化 Gauss-Newton，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{A}}$ 开始；输出最终的 $v$。\n  - 案例 5：带先验的正则化 Gauss-Newton，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{B}}$ 开始；输出最终的 $v$。\n  - 案例 6：带先验的正则化 Gauss-Newton，$\\gamma = 0$，从 $x^{(0)}_{\\mathrm{C}}$ 开始；输出最终的 $v$。\n  - 案例 7：使用扰动正演模型 $f_{\\gamma}$ 的未正则化 Gauss-Newton，$\\gamma = 10^{-3}$，从 $x^{(0)}_{\\mathrm{B}}$ 开始；输出最终的 $v$。\n  - 案例 8：使用扰动正演模型 $f_{\\gamma}$ 的未正则化 Gauss-Newton，$\\gamma = 10^{-3}$，从 $x^{(0)}_{\\mathrm{C}}$ 开始；输出最终的 $v$。\n- 最终输出格式：您的程序应生成单行输出，其中包含一个逗号分隔的列表，用方括号括起来，并严格按照上述案例的顺序排列结果，例如 $[v_1,v_2,v_3,v_4,v_5,v_6,v_7,v_8]$。将每个 $v$ 表示为浮点数。\n\n此问题的最终答案必须是一个完整的、可运行的程序，该程序实现所述的求解器并打印所需的单行输出。不需要用户输入。所有三角函数求值均使用弧度。", "solution": "该问题要求推导并实现 Gauss-Newton 方法，以解决一个具有结构性不可辨识性特征的非线性最小二乘问题，并演示正则化如何解决此问题。\n\n### 第 1 部分：Gauss-Newton 方法的推导\n\n目标是找到一个参数向量 $x$，以最小化由代价函数给出的残差平方和：\n$$\nF(x) = \\frac{1}{2} \\|r(x)\\|_2^2 = \\frac{1}{2} (f(x) - y)^T (f(x) - y)\n$$\nGauss-Newton 方法是一种迭代算法，在每次迭代 $k$ 中，它使用当前估计值 $x^{(k)}$ 周围的线性函数来近似非线性残差函数 $r(x)$。设建议的更新量为 $\\delta$，使得下一个估计值为 $x^{(k+1)} = x^{(k)} + \\delta$。残差向量 $r(x)$ 在 $x^{(k)}$ 周围的一阶泰勒展开为：\n$$\nr(x^{(k)} + \\delta) \\approx r(x^{(k)}) + J(x^{(k)}) \\delta\n$$\n其中 $J(x^{(k)})$ 是在 $x^{(k)}$ 处求值的残差函数 $r(x)$ 的雅可比矩阵。由于 $r(x) = f(x) - y$ 且 $y$ 是一个常数向量，因此 $r(x)$ 的雅可比矩阵与正演模型 $f(x)$ 的雅可比矩阵相同。\n\n将此线性近似代入代价函数 $F(x)$，我们得到 $F(x)$ 在 $x^{(k)}$ 周围的二次模型：\n$$\nF(x^{(k)} + \\delta) \\approx \\frac{1}{2} \\|r(x^{(k)}) + J(x^{(k)}) \\delta\\|_2^2\n$$\nGauss-Newton 方法通过在每次迭代中最小化这个二次近似来确定步长 $\\delta$。这是一个线性最小二乘问题：\n$$\n\\delta^{(k)} = \\arg \\min_{\\delta} \\frac{1}{2} \\| J(x^{(k)}) \\delta - (-r(x^{(k)})) \\|_2^2\n$$\n这个标准线性最小二乘问题的解由正规方程给出：\n$$\n(J(x^{(k)})^T J(x^{(k)})) \\delta^{(k)} = -J(x^{(k)})^T r(x^{(k)})\n$$\n矩阵 $H_{GN}(x^{(k)}) = J(x^{(k)})^T J(x^{(k)})$ 是代价函数 $F(x)$ 的 Hessian 矩阵的 Gauss-Newton 近似。因此，迭代更新由 $x^{(k+1)} = x^{(k)} + \\delta^{(k)}$ 给出，其中 $\\delta^{(k)}$ 是正规方程的解。通常采用线搜索来确定步长 $\\eta^{(k)}$，使得 $x^{(k+1)} = x^{(k)} + \\eta^{(k)} \\delta^{(k)}$ 能确保代价函数 $F(x)$ 的值减小。\n\n### 第 2 部分：可辨识性脊的分析\n\n正演模型由下式给出：\n$$\nf(x) = \\begin{bmatrix}\n\\alpha \\left( \\exp(x_1 + x_2) - 1 \\right) \\\\\n\\beta \\sin(x_1 + x_2)\n\\end{bmatrix}\n$$\n该模型仅依赖于和 $s = x_1 + x_2$。因此，代价函数 $F(x) = \\frac{1}{2}\\|f(x_1, x_2) - y\\|_2^2$ 在任何 $x_1 + x_2$ 为常数的直线上也将是恒定的。这会产生一个最小代价的“脊”或谷。在保持 $s$ 不变的方向上扰动 $x$ 不会改变 $f(x)$ 的值，因此也不会改变代价函数的值。这样的方向由任何与 $s(x) = x_1 + x_2$ 的梯度 $\\nabla s = [1, 1]^T$ 正交的向量给出。该方向的一个基是向量 $u = [1, -1]^T$。这个方向对应于在保持 $s$ 固定的同时改变 $v = x_1 - x_2$。\n\n这种结构性不可辨识性体现在 Gauss-Newton Hessian 矩阵中。$f(x)$ 的雅可比矩阵使用链式法则计算：$J(x) = \\frac{\\partial f}{\\partial s} \\frac{\\partial s}{\\partial x}$。\n$$\n\\frac{\\partial f}{\\partial s} = \\begin{bmatrix} \\alpha \\exp(s) \\\\ \\beta \\cos(s) \\end{bmatrix}, \\quad \\frac{\\partial s}{\\partial x} = \\begin{bmatrix} 1  1 \\end{bmatrix}\n$$\n因此，雅可比矩阵为：\n$$\nJ(x) = \\begin{bmatrix} \\alpha \\exp(x_1+x_2) \\\\ \\beta \\cos(x_1+x_2) \\end{bmatrix} \\begin{bmatrix} 1  1 \\end{bmatrix} = \\begin{bmatrix} \\alpha e^{x_1+x_2}  \\alpha e^{x_1+x_2} \\\\ \\beta \\cos(x_1+x_2)  \\beta \\cos(x_1+x_2) \\end{bmatrix}\n$$\n$J(x)$ 的两列是相同的，这意味着 $J(x)$ 的秩为 1。其零空间由向量 $u = [1, -1]^T$ 张成，因为 $J(x)u = 0$。\n\nGauss-Newton Hessian 矩阵为 $H_{GN} = J(x)^T J(x)$。对于 $J(x)$ 零空间中的任何向量 $u$：\n$$\nH_{GN} u = J(x)^T J(x) u = J(x)^T (0) = 0\n$$\n这表明 $H_{GN}$ 有一个零特征值，对应于特征向量 $u = [1, -1]^T$。该 Hessian 矩阵是奇异的。因此，正规方程 $(J^T J) \\delta = -J^T r$ 对于步长 $\\delta$ 没有唯一解。$\\delta$ 在零空间方向上的分量是不确定的，这导致在优化过程中沿着可辨识性脊发生漂移。\n\n### 第 3 部分：曲率注入\n\n为了获得唯一解，我们必须引入信息来区分可辨识性脊上的点。这可以通过在缺失方向上为目标函数增加曲率来实现。\n\n**方法 1：二次先验（Tikhonov 正则化）**\n\n我们修改代价函数以包含一个惩罚项：\n$$\n\\Phi(x) = \\frac{1}{2} \\| r(x) \\|_2^2 + \\frac{\\lambda}{2} \\| L(x - x_{\\mathrm{ref}}) \\|_2^2\n$$\n其中 $\\lambda  0$ 是一个正则化权重，$L \\in \\mathbb{R}^{1 \\times 2}$ 是一个惩罚算子，$x_{\\mathrm{ref}}$ 是一个参考状态。当 $L = [1, -1]$ 且 $x_{\\mathrm{ref}} = 0$ 时，惩罚项变为 $\\frac{\\lambda}{2} (x_1 - x_2)^2$。该项惩罚那些 $v = x_1 - x_2$ 远离 0 的解，从而有效地在脊上选择最接近直线 $x_1 = x_2$ 的解。\n\n为了推导修改后的 Gauss-Newton 步长，我们在 $x^{(k)}$ 周围对 $\\Phi(x)$ 中的两项进行线性化：\n$$\n\\Phi(x^{(k)} + \\delta) \\approx \\frac{1}{2} \\|r(x^{(k)}) + J(x^{(k)}) \\delta\\|_2^2 + \\frac{\\lambda}{2} \\|L(x^{(k)} - x_{\\mathrm{ref}}) + L \\delta\\|_2^2\n$$\n这可以通过定义一个增广残差和增广雅可比矩阵，将其表述为单个线性最小二乘问题：\n$$\n\\tilde{r}(x) = \\begin{bmatrix} r(x) \\\\ \\sqrt{\\lambda} L(x - x_{\\mathrm{ref}}) \\end{bmatrix}, \\quad \\tilde{J}(x) = \\begin{bmatrix} J(x) \\\\ \\sqrt{\\lambda} L \\end{bmatrix}\n$$\n步长 $\\delta^{(k)}$ 最小化 $\\frac{1}{2} \\|\\tilde{r}(x^{(k)}) + \\tilde{J}(x^{(k)}) \\delta\\|_2^2$。相应的正规方程是 $(\\tilde{J}^T \\tilde{J}) \\delta = -\\tilde{J}^T \\tilde{r}$。将其展开得到：\n$$\n(J(x^{(k)})^T J(x^{(k)}) + \\lambda L^T L) \\delta^{(k)} = -(J(x^{(k)})^T r(x^{(k)}) + \\lambda L^T L(x^{(k)} - x_{\\mathrm{ref}}))\n$$\n新的近似 Hessian 矩阵是 $H_{GN} + \\lambda L^T L$。矩阵 $L^T L = \\begin{bmatrix} 1 \\\\ -1 \\end{bmatrix} [1, -1] = \\begin{bmatrix} 1  -1 \\\\ -1  1 \\end{bmatrix}$ 的零空间由 $[1, 1]^T$ 张成，该零空间与 $H_{GN}$ 的零空间正交。因此，这两个矩阵的和是正定且可逆的，从而产生一个唯一的、良定义的步长 $\\delta^{(k)}$，解决了不可辨识性问题。\n\n**方法 2：正演模型中的结构约束**\n\n一种替代方法是修改正演模型以打破对称性，例如：\n$$\nf_{\\gamma}(x) = \\begin{bmatrix}\n\\alpha \\left( \\exp(x_1 + x_2) - 1 \\right) \\\\\n\\beta \\sin(x_1 + x_2) + \\gamma (x_1 - x_2)\n\\end{bmatrix}\n$$\n对于一个小的 $\\gamma \\neq 0$，模型现在弱依赖于 $v = x_1 - x_2$。新的雅可比矩阵是：\n$$\nJ_{\\gamma}(x) = \\begin{bmatrix} \\alpha e^{x_1+x_2}  \\alpha e^{x_1+x_2} \\\\ \\beta \\cos(x_1+x_2) + \\gamma  \\beta \\cos(x_1+x_2) - \\gamma \\end{bmatrix}\n$$\n现在 $J_{\\gamma}(x)$ 的列是线性无关的。向量 $u = [1, -1]^T$ 不再位于零空间中：\n$$\nJ_{\\gamma}(x) u = \\begin{bmatrix} 0 \\\\ 2\\gamma \\end{bmatrix} \\neq 0\n$$\n由于 $J_{\\gamma}(x)$ 是满秩的，Gauss-Newton Hessian 矩阵 $J_{\\gamma}(x)^T J_{\\gamma}(x)$ 是非奇异的，标准的（未正则化的）Gauss-Newton 方法将收敛到一个唯一最小值。这表明，即使对先前不可辨识的参数组合存在轻微的结构依赖性，也足以对问题进行正则化。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves a nonlinear least-squares problem with an identifiability ridge\n    using Gauss-Newton, and demonstrates regularization techniques.\n    \"\"\"\n    # Problem Constants\n    alpha = 1.0\n    beta = 0.5\n    x_star = np.array([0.5, -0.3])\n    \n    # Generate synthetic data y = f(x_star)\n    s_star = x_star[0] + x_star[1]\n    y_obs = np.array([\n        alpha * (np.exp(s_star) - 1.0),\n        beta * np.sin(s_star)\n    ])\n\n    # Initial guesses\n    x0_A = np.array([1.6, -1.0])\n    x0_B = np.array([0.7, -0.5])\n    x0_C = np.array([-0.5, 0.7])\n    \n    # Regularization parameters\n    lmbda_reg = 1.0\n    L_reg = np.array([[1.0, -1.0]])\n    xref_reg = np.array([0.0, 0.0])\n    \n    # Structural perturbation parameter\n    gamma_pert = 1e-3\n\n    # Algorithmic parameters\n    max_iter = 100\n    tol = 1e-8\n\n    def gauss_newton_solver(x_init, gamma, lmbda, L, xref):\n        \"\"\"\n        Generic Gauss-Newton solver for the problem.\n        - gamma: structural perturbation parameter\n        - lmbda: Tikhonov regularization weight\n        - L, xref: Tikhonov operator and reference\n        \"\"\"\n        x = x_init.copy()\n        \n        for _ in range(max_iter):\n            s = x[0] + x[1]\n            v = x[0] - x[1]\n\n            # Forward model f(x)\n            f_val = np.array([\n                alpha * (np.exp(s) - 1.0),\n                beta * np.sin(s) + gamma * v\n            ])\n            \n            # Residual r(x)\n            r = f_val - y_obs\n\n            # Jacobian J(x)\n            J = np.array([\n                [alpha * np.exp(s), alpha * np.exp(s)],\n                [beta * np.cos(s) + gamma, beta * np.cos(s) - gamma]\n            ])\n\n            if lmbda == 0:\n                # Standard or structurally-regularized GN\n                # Solve the linear least squares problem: min ||J*delta - (-r)||^2\n                delta, _, _, _ = np.linalg.lstsq(J, -r, rcond=None)\n            else:\n                # Tikhonov-regularized GN (as augmented least squares)\n                # min || [ J_aug * delta - (-r_aug) ] ||^2\n                r_prior = np.sqrt(lmbda) * L @ (x - xref)\n                r_aug = np.concatenate([r, r_prior])\n                J_aug = np.vstack([J, np.sqrt(lmbda) * L])\n                delta, _, _, _ = np.linalg.lstsq(J_aug, -r_aug, rcond=None)\n\n            if np.linalg.norm(delta)  tol:\n                break\n                \n            # Backtracking line search\n            step_size = 1.0\n            def cost_func(xk):\n                sk = xk[0] + xk[1]\n                vk = xk[0] - xk[1]\n                fk = np.array([\n                    alpha * (np.exp(sk) - 1.0),\n                    beta * np.sin(sk) + gamma * vk\n                ])\n                res_cost = 0.5 * np.linalg.norm(fk - y_obs)**2\n                if lmbda > 0:\n                    reg_cost = (lmbda / 2.0) * np.linalg.norm(L @ (xk - xref))**2\n                    return res_cost + reg_cost\n                return res_cost\n\n            cost_current = cost_func(x)\n            while step_size > 1e-8:\n                x_new = x + step_size * delta\n                if cost_func(x_new)  cost_current:\n                    x = x_new\n                    break\n                step_size /= 2.0\n            else: # Line search failed to find a decrease\n                break\n        \n        return x[0] - x[1] # Return the final v\n\n    # Test Cases\n    results = []\n\n    # Cases 1-3: Unregularized GN (gamma=0, lambda=0)\n    v1 = gauss_newton_solver(x0_A, gamma=0.0, lmbda=0.0, L=L_reg, xref=xref_reg)\n    results.append(v1)\n    \n    v2 = gauss_newton_solver(x0_B, gamma=0.0, lmbda=0.0, L=L_reg, xref=xref_reg)\n    results.append(v2)\n    \n    v3 = gauss_newton_solver(x0_C, gamma=0.0, lmbda=0.0, L=L_reg, xref=xref_reg)\n    results.append(v3)\n    \n    # Cases 4-6: Regularized GN with prior (gamma=0, lambda=1)\n    v4 = gauss_newton_solver(x0_A, gamma=0.0, lmbda=lmbda_reg, L=L_reg, xref=xref_reg)\n    results.append(v4)\n    \n    v5 = gauss_newton_solver(x0_B, gamma=0.0, lmbda=lmbda_reg, L=L_reg, xref=xref_reg)\n    results.append(v5)\n    \n    v6 = gauss_newton_solver(x0_C, gamma=0.0, lmbda=lmbda_reg, L=L_reg, xref=xref_reg)\n    results.append(v6)\n\n    # Cases 7-8: Unregularized GN with perturbed model (gamma=1e-3, lambda=0)\n    v7 = gauss_newton_solver(x0_B, gamma=gamma_pert, lmbda=0.0, L=L_reg, xref=xref_reg)\n    results.append(v7)\n    \n    v8 = gauss_newton_solver(x0_C, gamma=gamma_pert, lmbda=0.0, L=L_reg, xref=xref_reg)\n    results.append(v8)\n\n    # Final output format\n    print(f\"[{','.join(f'{r:.6f}' for r in results)}]\")\n\nsolve()\n```", "id": "3384262"}, {"introduction": "高斯-牛顿法和许多局部优化器一样，可能会陷入目标函数的局部极小值中，从而无法找到全局最优解。本练习将探讨一个地球物理学中的经典例子——“周波跳跃”，其中相位失配的子波会产生大量误导性的局部极小值。通过对比标准最小二乘目标函数下的失败与基于信号包络的替代目标函数下的成功，你将体会到目标函数设计在引导反演走向有意义结果方面的关键作用 [@problem_id:3599323]。", "problem": "您需要实现一个完整的、可运行的程序，构建一个一维波形反演玩具模型，其中正演模拟算子生成一个作为时移Ricker子波的单反射脉冲。反演目标是一个未知的单一参数，即恒定声波速度，数据是在地表测量的合成地震记录。目标是研究非线性最小二乘（NLS）的高斯-牛顿法在标准基于振幅的最小二乘残差和替代的基于包络的失配函数下的行为，说明前者中的周波跳跃现象，并展示后者中高斯-牛顿步长的变化。\n\n使用以下基本设置和定义：\n\n- 观测数据是在深度为 $z$ 的单个平坦地下反射界面上采集的，介质为常速介质，其速度 $m$（模型变量）未知。双程旅行时为 $ \\tau(m) = \\dfrac{2 z}{m} $。\n- 震源子波是Ricker子波 $ s(t) = \\left(1 - 2 a t^2\\right) \\exp\\left(- a t^2\\right) $，其中 $ a = \\left(\\pi f_0\\right)^2 $，$ f_0 $ 是中心频率。\n- 无噪声正演模型是合成地震记录 $ d\\!\\left(t; m\\right) = s\\!\\left(t - \\tau(m)\\right) $。\n- 基于振幅的最小二乘目标函数是 $ \\Phi_{\\mathrm{wf}}(m) = \\dfrac{1}{2} \\left\\| r_{\\mathrm{wf}}(m) \\right\\|_2^2 $，其残差为 $ r_{\\mathrm{wf}}(t; m) = d_{\\mathrm{obs}}(t) - d\\!\\left(t; m\\right) $。\n- 基于包络的替代失配函数使用振幅包络 $ e\\!\\left(t; m\\right) = \\sqrt{ d\\!\\left(t; m\\right)^2 + \\left( \\mathcal{H}\\{ d\\!\\left(t; m\\right) \\} \\right)^2 } $，其中 $ \\mathcal{H}\\{\\cdot\\} $ 表示希尔伯特变换，目标函数为 $ \\Phi_{\\mathrm{env}}(m) = \\dfrac{1}{2} \\left\\| r_{\\mathrm{env}}(m) \\right\\|_2^2 $，其残差为 $ r_{\\mathrm{env}}(t; m) = e_{\\mathrm{obs}}(t) - e\\!\\left(t; m\\right) $。\n\n从第一性原理出发，为每个目标函数推导高斯-牛顿步长：\n\n- 从非线性最小二乘目标函数 $ \\Phi(m) = \\dfrac{1}{2} \\left\\| r(m) \\right\\|_2^2 $ 的定义和高斯-牛顿近似开始，该近似用 $ J(m)^\\top J(m) $ 替代精确的Hessian矩阵，其中 $ J(m) $ 是残差相对于 $ m $ 的Jacobian矩阵。\n- 对于波形残差，使用链式法则和Ricker子波的导数，推导Jacobian矩阵的元素 $ J_{\\mathrm{wf}}(t; m) = \\dfrac{\\partial}{\\partial m} d\\!\\left(t; m\\right) $。Ricker子波的导数是 $ s'(t) = \\exp\\!\\left(- a t^2\\right) \\, t \\left( - 6 a + 4 a^2 t^2 \\right) $。明确地用 $ z $、$ m $ 和 $ s'\\!\\big(t - \\tau(m)\\big) $ 表示 $ J_{\\mathrm{wf}}(t; m) $。\n- 对于包络残差，利用 $ \\mathcal{H}\\{\\cdot\\} $ 是线性算子这一事实，通过链式法则推导Jacobian矩阵的元素 $ J_{\\mathrm{env}}(t; m) = \\dfrac{\\partial}{\\partial m} e\\!\\left(t; m\\right) $：设 $ x = d(t; m) $ 和 $ y = \\mathcal{H}\\{ d(t; m) \\} $，则 $ e(t; m) = \\sqrt{x(t; m)^2 + y(t; m)^2} $。证明 $ \\dfrac{\\partial e}{\\partial m}(t; m) = \\dfrac{ x \\, \\dfrac{\\partial x}{\\partial m} + y \\, \\dfrac{\\partial y}{\\partial m} }{ e } $，并将 $ \\dfrac{\\partial y}{\\partial m} $ 与 $ \\mathcal{H}\\!\\left\\{ \\dfrac{\\partial x}{\\partial m} \\right\\} $ 联系起来。\n\n然后，为每个目标函数写出单个参数 $ m $ 的高斯-牛顿更新公式：\n$$\n\\Delta m_{\\bullet} = \\dfrac{ \\sum_t J_{\\bullet}(t; m_0) \\, r_{\\bullet}(t; m_0) }{ \\sum_t J_{\\bullet}(t; m_0)^2 },\n$$\n其中 $ \\bullet \\in \\{ \\mathrm{wf}, \\mathrm{env} \\} $，$ m_0 $ 是当前模型迭代值。解释为什么当 $ m_0 $ 与真实值相差足够远时，基于波形的残差 $ r_{\\mathrm{wf}} $ 会表现出周波跳跃，这表现为多周期的相位失配，导致 $ J_{\\mathrm{wf}}^\\top r_{\\mathrm{wf}} $ 的符号具有误导性或量值过小，从而产生一个不佳的 $ \\Delta m_{\\mathrm{wf}} $。将此与基于包络的残差进行对比，后者抑制了振荡的相位效应，通常能提供一个更稳健的、朝向真实解的步长 $ \\Delta m_{\\mathrm{env}} $。\n\n物理和数值参数：\n\n- 深度 $ z = 1000\\,\\mathrm{m} $。\n- 真实速度 $ m_\\star = 2000\\,\\mathrm{m/s} $。\n- 中心频率 $ f_0 = 10\\,\\mathrm{Hz} $。\n- 时间采样间隔 $ \\Delta t = 0.001\\,\\mathrm{s} $。\n- 记录长度 $ T = 2.5\\,\\mathrm{s} $。\n\n角度，包括可能隐式出现在解析信号中的任何相位，都应以弧度为单位。\n\n初始模型速度 $ m_0 $ 的测试集：\n\n- 情况1（完美匹配）：$ m_0 = 2000\\,\\mathrm{m/s} $。\n- 情况2（接近，低于半个周期的失配）：$ m_0 = 2100\\,\\mathrm{m/s} $。\n- 情况3（中度周波跳跃，约一个周期的失配）：$ m_0 = 1800\\,\\mathrm{m/s} $。\n- 情况4（严重周波跳跃，多个周期的失配）：$ m_0 = 1500\\,\\mathrm{m/s} $。\n\n您的程序必须：\n\n- 使用 $ m_\\star $ 构建 $ d_{\\mathrm{obs}}(t) $，并对于测试集中的每个 $ m_0 $，根据上述高斯-牛顿公式计算 $ \\Delta m_{\\mathrm{wf}} $ 和 $ \\Delta m_{\\mathrm{env}} $。\n- 使用希尔伯特变换计算包络和包络的Jacobian矩阵，并采取适当的数值保护措施，以避免在包络振幅极小时发生除以零的错误。\n- 将每个 $ \\Delta m $ 以米/秒（$\\mathrm{m/s}$）表示，并四舍五入到6位小数。\n\n最终输出格式：\n\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。此列表中的每个元素对应一个测试用例，并且本身必须是一个双元素列表，按顺序包含该用例的高斯-牛顿步长 $ \\Delta m_{\\mathrm{wf}} $ 和 $ \\Delta m_{\\mathrm{env}} $。例如，输出应类似于 $ \\left[ [\\Delta m_{\\mathrm{wf}}^{(1)}, \\Delta m_{\\mathrm{env}}^{(1)}], \\ldots, [\\Delta m_{\\mathrm{wf}}^{(4)}, \\Delta m_{\\mathrm{env}}^{(4)}] \\right] $，其中每个数字都打印为6位小数，单位默认为 $\\mathrm{m/s}$。", "solution": "用户提供了一个有效的问题陈述。任务是分析用于一维波形反演问题的高斯-牛顿优化方法，比较标准基于波形的目标函数与基于包络的替代方案。分析的重点是周波跳跃现象。解决方案要求为每个目标函数推导高斯-牛顿步长，然后实现一个数值模拟来为几个初始模型计算这些步长。\n\n首先，我们建立理论框架。目标是找到模型参数 $m$（声波速度），以最小化形式为 $\\Phi(m) = \\frac{1}{2} \\|r(m)\\|_2^2$ 的非线性最小二乘目标函数，其中 $r(m)$ 是观测数据与预测数据之间的残差向量。对于离散时间序列，此函数为 $\\Phi(m) = \\frac{1}{2} \\sum_t [r(t; m)]^2$。\n\n高斯-牛顿法使用 $J(m)^\\top J(m)$ 来近似目标函数的Hessian矩阵 $\\nabla^2 \\Phi(m)$，其中 $J(m)$ 是残差向量 $r(m)$ 相对于模型参数 $m$ 的Jacobian矩阵。Jacobian矩阵的元素是 $J(t; m) = \\frac{\\partial r(t; m)}{\\partial m}$。模型参数的更新步长通过求解正规方程 $J(m)^\\top J(m) \\Delta m = -J(m)^\\top r(m)$ 得到。在我们的情况下，由于只有一个参数 $m$，这简化为一个标量方程。问题陈述中定义的残差是 $r(t;m) = d_{\\mathrm{obs}}(t) - d(t;m)$，所以其Jacobian矩阵是 $J(t;m) = \\frac{\\partial r}{\\partial m} = -\\frac{\\partial d}{\\partial m}$。目标函数的梯度是 $\\nabla \\Phi(m) = \\sum_t r(t;m) \\frac{\\partial r(t;m)}{\\partial m} = - \\sum_t r(t;m) \\frac{\\partial d(t;m)}{\\partial m}$。标准的高斯-牛顿更新将是 $m_{k+1} = m_k - (\\nabla^2 \\Phi)^{-1} \\nabla \\Phi$。步长是 $\\delta m = - (J^\\top J)^{-1} J^\\top r$。\n问题陈述中提供的步长 $\\Delta m$ 公式省略了负号：\n$$\n\\Delta m = \\left( \\sum_t J(t; m_0)^2 \\right)^{-1} \\left( \\sum_t J(t; m_0) r(t; m_0) \\right)\n$$\n这意味着更新规则的形式为 $m_{k+1} = m_k - \\Delta m$（如果 $J = \\frac{\\partial d}{\\partial m}$），或者 $m_{k+1} = m_k + \\Delta m$（如果 $J = -\\frac{\\partial d}{\\partial m}$）。我们将遵循所提供的公式，并注意到校正方向取决于残差和数据灵敏度之间的局部相关性。\n\n合成数据的正演模型是一个时移的Ricker子波：$d(t; m) = s(t - \\tau(m))$，其中 $s(t) = (1 - 2 a t^2) \\exp(-a t^2)$，$a = (\\pi f_0)^2$，双程旅行时为 $\\tau(m) = \\frac{2z}{m}$。\n\n**1. 基于波形的目标函数 $\\Phi_{\\mathrm{wf}}(m)$**\n\n残差为 $r_{\\mathrm{wf}}(t; m) = d_{\\mathrm{obs}}(t) - d(t; m)$。此残差关于 $m$ 的Jacobian矩阵为 $J_{\\mathrm{wf}}(t; m) = \\frac{\\partial r_{\\mathrm{wf}}}{\\partial m} = -\\frac{\\partial d(t; m)}{\\partial m}$。\n使用链式法则：\n$$\n\\frac{\\partial d(t; m)}{\\partial m} = \\frac{\\partial}{\\partial m} s(t - \\tau(m)) = s'(t - \\tau(m)) \\cdot \\left( -\\frac{\\partial \\tau(m)}{\\partial m} \\right)\n$$\n旅行时的导数是 $\\frac{\\partial \\tau(m)}{\\partial m} = \\frac{\\partial}{\\partial m}\\left(\\frac{2z}{m}\\right) = -\\frac{2z}{m^2}$。\n代入此式，我们得到：\n$$\n\\frac{\\partial d(t; m)}{\\partial m} = s'(t - \\tau(m)) \\cdot \\left( - \\left( -\\frac{2z}{m^2} \\right) \\right) = \\frac{2z}{m^2} s'(t - \\tau(m))\n$$\n因此，残差的Jacobian矩阵是 $J_{\\mathrm{wf}}(t; m) = -\\frac{2z}{m^2} s'(t - \\tau(m))$。所提供的步长公式使用的 $J$ 未指定是用于残差还是正演模型。为确保步长是修正性的，让我们分析梯度。$\\nabla\\Phi = J_{\\mathrm{wf}}^\\top r_{\\mathrm{wf}}$。如果我们使用问题中的 $\\Delta m$ 公式，它代表沿梯度的步长。更新 $m_{k+1} = m_k - \\lambda \\Delta m$ 将是梯度下降。我们将按照提供的公式计算 $\\Delta m$，将Jacobian矩阵定义为*正演模型*的灵敏度，即 $J(t;m) = \\frac{\\partial d(t;m)}{\\partial m}$。\n$$\nJ_{\\mathrm{wf}}(t; m) = \\frac{2z}{m^2} s'(t - \\tau(m))\n$$\n其中Ricker子波的导数由 $s'(t) = \\exp(- a t^2) \\, t \\, (-6 a + 4 a^2 t^2)$ 给出。\n高斯-牛顿步长则为：\n$$\n\\Delta m_{\\mathrm{wf}} = \\frac{\\sum_t J_{\\mathrm{wf}}(t; m_0) \\, r_{\\mathrm{wf}}(t; m_0)}{\\sum_t J_{\\mathrm{wf}}(t; m_0)^2}\n$$\n\n**2. 基于包络的目标函数 $\\Phi_{\\mathrm{env}}(m)$**\n\n残差为 $r_{\\mathrm{env}}(t; m) = e_{\\mathrm{obs}}(t) - e(t; m)$，其中 $e(t; m)$ 是信号 $d(t; m)$ 的振幅包络，定义为 $e(t; m) = |d(t;m) + i \\mathcal{H}\\{d(t;m)\\}|$，$ \\mathcal{H}\\{\\cdot\\} $ 表示希尔伯特变换。\n设 $x(t; m) = d(t; m)$ 和 $y(t; m) = \\mathcal{H}\\{d(t; m)\\}$。则 $e(t; m) = \\sqrt{x^2 + y^2}$。正演模型 $e(t; m)$ 的Jacobian矩阵是：\n$$\nJ_{\\mathrm{env}}(t; m) = \\frac{\\partial e}{\\partial m} = \\frac{1}{2\\sqrt{x^2+y^2}} \\left( 2x \\frac{\\partial x}{\\partial m} + 2y \\frac{\\partial y}{\\partial m} \\right) = \\frac{x \\frac{\\partial x}{\\partial m} + y \\frac{\\partial y}{\\partial m}}{e}\n$$\n我们有 $\\frac{\\partial x}{\\partial m} = \\frac{\\partial d}{\\partial m} = J_{\\mathrm{wf}}(t; m)$。由于希尔伯特变换是一个线性算子，其应用与关于 $m$ 的微分运算可以交换顺序：\n$$\n\\frac{\\partial y}{\\partial m} = \\frac{\\partial}{\\partial m} \\mathcal{H}\\{d(t; m)\\} = \\mathcal{H}\\left\\{\\frac{\\partial d(t; m)}{\\partial m}\\right\\} = \\mathcal{H}\\{J_{\\mathrm{wf}}(t; m)\\}\n$$\n代入这些结果，我们得到包络Jacobian矩阵的显式公式：\n$$\nJ_{\\mathrm{env}}(t; m) = \\frac{d(t; m) J_{\\mathrm{wf}}(t; m) + \\mathcal{H}\\{d(t; m)\\} \\mathcal{H}\\{J_{\\mathrm{wf}}(t; m)\\}}{e(t; m)}\n$$\n因此，包络目标函数的高斯-牛顿步长为：\n$$\n\\Delta m_{\\mathrm{env}} = \\frac{\\sum_t J_{\\mathrm{env}}(t; m_0) \\, r_{\\mathrm{env}}(t; m_0)}{\\sum_t J_{\\mathrm{env}}(t; m_0)^2}\n$$\n\n**3. 周波跳跃分析**\n\n基于波形的目标函数 $\\Phi_{\\mathrm{wf}}$ 作为模型参数 $m$ 的函数是高度振荡的，表现出许多局部极小值。当预测子波 $d(t; m_0)$ 与观测数据 $d_{\\mathrm{obs}}(t)$ 的错位量为子波半周期的整数倍时，就会出现这些极小值。$\\Delta m_{\\mathrm{wf}}$ 公式中的分子 $\\sum_t J_{\\mathrm{wf}} r_{\\mathrm{wf}}$ 表示残差与Jacobian矩阵的互相关。当初始猜测值 $m_0$ 远离真实值 $m_\\star$ 时，时移 $\\tau(m_0) - \\tau(m_\\star)$ 会很大。如果这个时移超过了子波主周期的大约一半，互相关值可能会变得很小，甚至改变符号。符号改变会导致高斯-牛顿步长指向错误的方向，远离真实解。这种无法找到正确极小值的失败现象被称为周波跳跃。\n\n相比之下，包络 $e(t; m)$ 是一个平滑、非振荡的时间函数，其最大值位于群到达时 $\\tau(m)$ 处。因此，基于包络的目标函数 $\\Phi_{\\mathrm{env}}$ 在更宽的 $m$ 值范围内更为平滑和凸。其围绕全局最小值的吸引盆更大，使得优化不易受周波跳跃的影响。残差 $r_{\\mathrm{env}}$ 捕捉了到达时间的失配，而没有振荡干扰，其与Jacobian矩阵 $J_{\\mathrm{env}}$ 的相关性通常即使在 $m_0$ 的初始误差很大时也能提供一个稳健的更新方向。\n\n下面的程序为指定的测试用例实现了这些计算，展示了与波形失配相比，包络失配的稳健性。为了确保数值稳定性，在 $J_{\\mathrm{env}}$ 的分母中的包络上添加了一个小的常数 $\\epsilon$。计算出的步长 $\\Delta m$ 是标准高斯-牛顿公式中的搜索方向乘以 $-1$。对于更新规则 $m_{k+1} = m_k + \\Delta m_{step}$，我们计算出的 $\\Delta m$ 应等于 $-\\Delta m_{step}$。这意味着如果 $m_0  m_\\star$，我们期望一个正的 $\\Delta m$，而如果 $m_0  m_\\star$，则期望一个负的 $\\Delta m$。然而，对梯度的分析表明，当 $m_0  m_\\star$ 时，我们的项 $\\Delta m = (J^TJ)^{-1}J^Tr$ 应为正，而当 $m_0  m_\\star$ 时应为负。实现将遵循此推导，期望正步长会增加模型值。", "answer": "```python\nimport numpy as np\nfrom scipy.signal import hilbert\n\ndef solve():\n    \"\"\"\n    Computes and compares Gauss-Newton steps for waveform and envelope\n    misfit functions in a 1D seismic inversion toy problem.\n    \"\"\"\n    # Physical and numerical parameters\n    z = 1000.0  # Reflector depth in meters\n    m_true = 2000.0  # True velocity in m/s\n    f0 = 10.0  # Central frequency in Hz\n    dt = 0.001  # Time sampling interval in seconds\n    t_max = 2.5  # Record length in seconds\n    epsilon = 1e-9 # Small constant for numerical stability\n\n    # Time vector\n    t = np.arange(0, t_max, dt)\n\n    # Ricker wavelet and its derivative\n    a = (np.pi * f0)**2\n    def ricker(time_vec):\n        return (1.0 - 2.0 * a * time_vec**2) * np.exp(-a * time_vec**2)\n\n    def ricker_derivative(time_vec):\n        return np.exp(-a * time_vec**2) * time_vec * (-6.0 * a + 4.0 * a**2 * time_vec**2)\n\n    # Forward modeling operator\n    def forward_model(m, time_vec):\n        tau = 2.0 * z / m\n        return ricker(time_vec - tau)\n\n    # Generate observed data\n    d_obs = forward_model(m_true, t)\n\n    # Test cases for initial model velocities\n    test_cases = [2000.0, 2100.0, 1800.0, 1500.0]\n\n    results = []\n    \n    for m0 in test_cases:\n        # Calculate predicted data for the current model parameter m0\n        d_pred = forward_model(m0, t)\n\n        # --- 1. Waveform-based inversion step ---\n        r_wf = d_obs - d_pred\n        \n        # Calculate Jacobian for waveform misfit\n        tau0 = 2.0 * z / m0\n        # The Jacobian is d(d)/dm = s'(t-tau) * d(-tau)/dm = s'(t-tau) * (2z/m^2)\n        J_wf = (2.0 * z / m0**2) * ricker_derivative(t - tau0)\n\n        # Calculate Gauss-Newton step for waveform\n        numerator_wf = np.sum(J_wf * r_wf)\n        denominator_wf = np.sum(J_wf**2)\n        \n        if np.isclose(denominator_wf, 0):\n            delta_m_wf = 0.0\n        else:\n            # The formula in the problem is delta_m = (J^T J)^-1 J^T r.\n            # The standard Gauss-Newton update would be m_k+1 = m_k - delta_m.\n            # We calculate delta_m as specified.\n            delta_m_wf = numerator_wf / denominator_wf\n\n        # --- 2. Envelope-based inversion step ---\n        \n        # Calculate analytic signals and envelopes\n        analytic_obs = hilbert(d_obs)\n        analytic_pred = hilbert(d_pred)\n        \n        e_obs = np.abs(analytic_obs)\n        e_pred = np.abs(analytic_pred)\n\n        r_env = e_obs - e_pred\n        \n        # Calculate Jacobian for envelope misfit\n        # J_env = d(e)/dm = [d*d(d)/dm + H{d}*d(H{d})/dm] / e\n        #       = [d*J_wf + H{d}*H{J_wf}] / e\n        analytic_J_wf = hilbert(J_wf)\n        \n        # The numerator is the real part of (analytic_pred_conj * analytic_J_wf)\n        numerator_J_env = np.real(np.conj(analytic_pred) * analytic_J_wf)\n        J_env = np.divide(numerator_J_env, e_pred + epsilon, \n                          out=np.zeros_like(numerator_J_env), \n                          where=(e_pred + epsilon) != 0)\n\n        # Calculate Gauss-Newton step for envelope\n        numerator_env = np.sum(J_env * r_env)\n        denominator_env = np.sum(J_env**2)\n\n        if np.isclose(denominator_env, 0):\n            delta_m_env = 0.0\n        else:\n            delta_m_env = numerator_env / denominator_env\n\n        results.append([round(delta_m_wf, 6), round(delta_m_env, 6)])\n\n    # Format the final output string\n    output_str = \"[\" + \",\".join([f\"[{res[0]:.6f},{res[1]:.6f}]\" for res in results]) + \"]\"\n    print(output_str)\n\nsolve()\n```", "id": "3599323"}]}