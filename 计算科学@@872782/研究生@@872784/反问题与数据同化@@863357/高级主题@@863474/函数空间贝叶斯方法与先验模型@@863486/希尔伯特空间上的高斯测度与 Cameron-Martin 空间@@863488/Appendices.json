{"hands_on_practices": [{"introduction": "这第一个练习将我们对高斯测度的理解建立在一个具体的计算之上。通过计算线性泛函的协方差，我们将抽象的协方差算子 $C$ 与其谱分解直接联系起来。这项练习将阐明特征值 $(\\lambda_j)$ 如何决定希尔伯特空间内部的统计相关性，从而为从理论到应用架起一座至关重要的桥梁。", "problem": "考虑一个实的、可分的希尔伯特空间 $H$，其内积为 $\\langle \\cdot,\\cdot \\rangle_H$，标准正交基为 $(e_j)_{j \\in \\mathbb{N}}$。令 $\\mu$ 为 $H$ 上的一个中心化高斯测度，其协方差算子为 $C \\colon H \\to H$，该算子是自伴的、正的且是迹类的。假设 $C$ 具有谱分解 $C e_j = \\lambda_j e_j$，其特征值 $(\\lambda_j)_{j \\in \\mathbb{N}}$ 满足 $\\lambda_j \\ge 0$ 且 $\\sum_{j=1}^{\\infty} \\lambda_j  \\infty$。令 $X$ 为一个服从分布 $\\mu$、取值于 $H$ 的随机变量。\n\n在贝叶斯数据同化的背景下，考虑由 $h,k \\in H$ 定义的线性观测泛函，以及相应的标量观测 $\\langle X,h \\rangle_H$ 和 $\\langle X,k \\rangle_H$。将 $h$ 和 $k$写作 $h = \\sum_{j=1}^{\\infty} h_j e_j$ 和 $k = \\sum_{j=1}^{\\infty} k_j e_j$，其中 $h_j = \\langle h, e_j \\rangle_H$ 且 $k_j = \\langle k, e_j \\rangle_H$。\n\n仅使用希尔伯特空间上高斯测度的基本性质和上述谱分解，用 $(\\lambda_j)$ 和系数 $(h_j)$、$(k_j)$ 的级数形式显式计算协方差 $\\mathrm{cov}(\\langle X,h \\rangle_H, \\langle X,k \\rangle_H)$。将最终答案表示为关于 $(\\lambda_j, h_j, k_j)$ 的单个解析级数；在最终表达式中不要使用算子符号。无需进行舍入。", "solution": "该问题是良定的，并包含了完整解答所需的所有信息。这是泛函分析和概率论领域的一个标准问题，特别涉及无穷维空间上的高斯测度。\n\n令 $Y_h = \\langle X,h \\rangle_H$ 和 $Y_k = \\langle X,k \\rangle_H$。这些是实值随机变量，因为实希尔伯特空间 $H$ 上的内积映射到 $\\mathbb{R}$。我们想要计算协方差 $\\mathrm{cov}(Y_h, Y_k)$。\n\n根据定义，两个实值随机变量的协方差由下式给出：\n$$\n\\mathrm{cov}(Y_h, Y_k) = \\mathbb{E}[(Y_h - \\mathbb{E}[Y_h])(Y_k - \\mathbb{E}[Y_k])]\n$$\n首先，我们计算期望值 $\\mathbb{E}[Y_h]$ 和 $\\mathbb{E}[Y_k]$。期望算子 $\\mathbb{E}$ 是线性的。由于内积 $\\langle \\cdot, \\cdot \\rangle_H$ 在其第一个参数上是线性的，我们可以写出：\n$$\n\\mathbb{E}[Y_h] = \\mathbb{E}[\\langle X,h \\rangle_H] = \\langle \\mathbb{E}[X], h \\rangle_H\n$$\n问题陈述高斯测度 $\\mu$ 是中心化的。这意味着取值于 $H$ 的随机变量 $X$ 的期望值（或均值）是 $H$ 中的零向量，即 $\\mathbb{E}[X] = 0$。因此，\n$$\n\\mathbb{E}[Y_h] = \\langle 0, h \\rangle_H = 0\n$$\n类似地，对于随机变量 $Y_k$：\n$$\n\\mathbb{E}[Y_k] = \\mathbb{E}[\\langle X,k \\rangle_H] = \\langle \\mathbb{E}[X], k \\rangle_H = \\langle 0, k \\rangle_H = 0\n$$\n将这些零均值代回协方差公式，我们得到：\n$$\n\\mathrm{cov}(Y_h, Y_k) = \\mathbb{E}[(Y_h - 0)(Y_k - 0)] = \\mathbb{E}[Y_h Y_k] = \\mathbb{E}[\\langle X,h \\rangle_H \\langle X,k \\rangle_H]\n$$\n协方差算子为 $C$ 的希尔伯特空间 $H$ 上的高斯测度 $\\mu$ 的一个基本性质是，对于任意两个元素 $h, k \\in H$，随机变量 $\\langle X,h \\rangle_H$ 和 $\\langle X,k \\rangle_H$ 的协方差由内积 $\\langle Ch, k \\rangle_H$ 给出。因此，\n$$\n\\mathrm{cov}(Y_h, Y_k) = \\langle C h, k \\rangle_H\n$$\n我们现在的任务是用特征值 $(\\lambda_j)$ 和系数 $(h_j)$、$(k_j)$ 来表示 $\\langle C h, k \\rangle_H$。给定 $h$ 和 $k$ 在标准正交基 $(e_j)_{j \\in \\mathbb{N}}$ 中的级数展开：\n$$\nh = \\sum_{j=1}^{\\infty} h_j e_j \\quad \\text{和} \\quad k = \\sum_{i=1}^{\\infty} k_i e_i\n$$\n其中 $h_j = \\langle h, e_j \\rangle_H$ 且 $k_i = \\langle k, e_i \\rangle_H$。为了后续步骤的清晰性，我们在 $k$ 的展开中使用了不同的索引 $i$。\n\n协方差算子 $C$ 是一个线性算子。由于它在希尔伯特空间上是迹类的，所以它是一个紧算子，因此是连续的。其线性性和連續性允许我们将其应用于 $h$ 的级数展开：\n$$\nCh = C\\left(\\sum_{j=1}^{\\infty} h_j e_j\\right) = \\sum_{j=1}^{\\infty} h_j C(e_j)\n$$\n给定 $C$ 关于基 $(e_j)$ 的谱分解，即 $C e_j = \\lambda_j e_j$。将此代入 $Ch$ 的表达式中：\n$$\nCh = \\sum_{j=1}^{\\infty} h_j (\\lambda_j e_j) = \\sum_{j=1}^{\\infty} \\lambda_j h_j e_j\n$$\n现在我们计算内积 $\\langle Ch, k \\rangle_H$:\n$$\n\\langle Ch, k \\rangle_H = \\left\\langle \\sum_{j=1}^{\\infty} \\lambda_j h_j e_j, \\sum_{i=1}^{\\infty} k_i e_i \\right\\rangle_H\n$$\n由于内积是连续且双线性的（在实希尔伯特空间上），我们可以交换求和与内积：\n$$\n\\langle Ch, k \\rangle_H = \\sum_{j=1}^{\\infty} \\sum_{i=1}^{\\infty} \\langle \\lambda_j h_j e_j, k_i e_i \\rangle_H = \\sum_{j=1}^{\\infty} \\sum_{i=1}^{\\infty} \\lambda_j h_j k_i \\langle e_j, e_i \\rangle_H\n$$\n基 $(e_j)_{j \\in \\mathbb{N}}$ 是标准正交的，这意味着 $\\langle e_j, e_i \\rangle_H = \\delta_{ji}$，其中 $\\delta_{ji}$ 是克罗内克δ函数。克罗内克δ函数在 $j=i$ 时为 $1$，在 $j \\neq i$ 时为 $0$。将此代入表达式：\n$$\n\\langle Ch, k \\rangle_H = \\sum_{j=1}^{\\infty} \\sum_{i=1}^{\\infty} \\lambda_j h_j k_i \\delta_{ji}\n$$\n$\\delta_{ji}$ 的存在使得内层求和（对 $i$）中除了 $i=j$ 的项外，所有项都为零。因此，双重求和坍缩为单个求和：\n$$\n\\langle Ch, k \\rangle_H = \\sum_{j=1}^{\\infty} \\lambda_j h_j k_j\n$$\n这就得到了所要求的协方差的显式级数表达式。该级数的收敛性是有保证的，因为 $h, k \\in H$ 意味着 $\\sum h_j^2  \\infty$ 和 $\\sum k_j^2  \\infty$，而 $C$ 是迹类的意味着 $\\sum \\lambda_j  \\infty$。根据柯西-施瓦茨不等式，$\\left| \\sum \\lambda_j h_j k_j \\right| \\le \\left(\\sum \\lambda_j h_j^2\\right)^{1/2} \\left(\\sum \\lambda_j k_j^2\\right)^{1/2}$，并且后两个级数是收敛的。\n因此，协方差为：\n$$\n\\mathrm{cov}(\\langle X,h \\rangle_H, \\langle X,k \\rangle_H) = \\sum_{j=1}^{\\infty} \\lambda_j h_j k_j\n$$", "answer": "$$\n\\boxed{\\sum_{j=1}^{\\infty} \\lambda_j h_j k_j}\n$$", "id": "3385102"}, {"introduction": "在理解协方差结构的基础上，本练习将深入探讨一个核心应用：贝叶斯推断。我们将考虑一个典型的线性反问题，并推导在给定含噪数据的情况下未知状态的后验分布。这个练习展示了高斯测度的性质如何导出著名的后验均值和协方差公式，这些公式是数据同化和机器学习中的基本工具。", "problem": "设 $H$ 是一个可分实希尔伯特空间，其内积为 $\\langle \\cdot,\\cdot \\rangle_H$，范数为 $|\\cdot|_H$。考虑在数据同化设定下的线性反问题，其中正向映射是 $H$ 上的恒等映射，因此观测数据 $y \\in H$ 满足\n$$\ny = u + \\eta,\n$$\n其中 $u \\in H$ 是未知状态，$\\eta \\in H$ 是观测噪声。假设 $H$ 上的高斯先验为 $u \\sim \\mathcal{N}(m_0, C_0)$，其中 $m_0 \\in H$ 且 $C_0: H \\to H$ 是一个自伴、正、迹类的协方差算子，并假设独立的高斯观测噪声为 $\\eta \\sim \\mathcal{N}(0, \\Gamma)$，其中 $\\Gamma: H \\to H$ 是有界、自伴、严格正（强制）的。令 $\\mu_0 = \\mathcal{N}(m_0, C_0)$ 和 $\\nu = \\mathcal{N}(0, \\Gamma)$ 分别表示先验测度和噪声测度，并令 $\\mathcal{H}_{C_0} = \\operatorname{ran}(C_0^{1/2})$ 和 $\\mathcal{H}_{\\Gamma} = \\operatorname{ran}(\\Gamma^{1/2})$ 表示赋予了典范内积的相关 Cameron-Martin 空间。后验测度 $\\mu^y$ 是通过贝叶斯法则定义的，具体方法是用由 $\\nu$ 和观测模型导出的似然函数对 $\\mu_0$ 进行加权。\n\n从希尔伯特空间上高斯测度的基本定义、关于高斯测度平移的 Cameron-Martin 定理，以及高斯测度的线性映象是高斯的、联合高斯向量由其前两阶矩刻画等经过充分验证的事实出发，完成以下任务：\n\n1. 证明 $(u,y) \\in H \\times H$ 的联合法则是高斯的，确定其均值和协方差算子的分块形式，并用此证明在给定 $y$ 的条件下，$u$ 的后验法则与 $u$ 的高斯条件分布一致。\n\n2. 显式计算给定 $y$ 条件下 $u$ 的后验均值 $m^y \\in H$ 和后验协方差算子 $C^y: H \\to H$，你的答案只能用 $m_0$、$C_0$、$\\Gamma$ 和 $y$ 来表示，不得引入任何无关量。你只能使用对希尔伯特空间上的自伴正算子有效的、经过充分验证的算子恒等式和性质。\n\n将你的最终答案表示为一个由后验均值和后验协方差算子组成的数对。不需要进行数值舍入，也不涉及物理单位。", "solution": "用户希望我解决一个关于贝叶斯反问题的问题，具体来说，是在希尔伯特空间上为一个线性高斯问题寻找后验均值和协方差。\n\n### 步骤 1：提取已知条件\n\n-   **希尔伯特空间**：$H$ 是一个可分实希尔伯特空间，其内积为 $\\langle \\cdot,\\cdot \\rangle_H$，范数为 $|\\cdot|_H$。\n-   **模型**：观测值 $y \\in H$ 通过 $y = u + \\eta$ 与未知状态 $u \\in H$ 相关，其中 $\\eta \\in H$ 是噪声。\n-   **先验分布**：$u \\sim \\mathcal{N}(m_0, C_0)$，其中 $m_0 \\in H$ 是先验均值，$C_0: H \\to H$ 是先验协方差算子。$C_0$ 是自伴、正、迹类的。令 $\\mu_0 = \\mathcal{N}(m_0, C_0)$。\n-   **噪声分布**：$\\eta \\sim \\mathcal{N}(0, \\Gamma)$，其中 $\\Gamma: H \\to H$ 是噪声协方差算子。$\\Gamma$ 是有界、自伴、严格正（强制）的。令 $\\nu = \\mathcal{N}(0, \\Gamma)$。\n-   **独立性**：随机变量 $u$ 和 $\\eta$ 是独立的。\n-   **后验定义**：后验测度 $\\mu^y$ 通过贝叶斯法则定义。\n-   **任务 1**：证明 $(u,y)$ 的联合法则是高斯的，求其均值和协方差，并将后验与条件分布联系起来。\n-   **任务 2**：计算后验均值 $m^y$ 和后验协方差 $C^y$。\n\n### 步骤 2：使用提取的已知条件进行验证\n\n这个问题是无限维（函数空间）设定下贝叶斯推断的一个典型例子，是反问题和数据同化领域的核心课题。\n\n-   **科学依据**：该问题在科学上和数学上都是合理的。它基于希尔伯特空间上的高斯测度理论、算子理论和贝叶斯统计。对协方差算子的假设（$C_0$ 是迹类的，$\\Gamma$ 是强制的）是标准的，并且是确保高斯测度良定义和后验适定性的必要条件。\n-   **适定性**：该问题是适定的。$\\Gamma$ 的强制性确保了算子 $C_0 + \\Gamma$ 是可逆的，这对于推导解至关重要。在这些标准假设下，存在唯一的后验分布。\n-   **客观性**：该问题以精确、客观的数学语言陈述，没有歧义或主观内容。\n\n所有有效问题的标准都已满足。该问题没有表现出任何列出的缺陷。这是其领域内一个标准的、非平凡的推导。\n\n### 步骤 3：结论和行动\n\n该问题是**有效的**。我将继续进行解答。\n\n解答将按要求分两部分呈现。\n\n**第 1 部分：联合分布及其与后验的关系**\n\n高斯概率论的一个核心原则（从有限维延伸到无限维希尔伯特空间）是，高斯随机变量的仿射变换仍然是高斯随机变量。我们利用这一点来确定 $(u, y)$ 的联合分布。\n\n状态 $u$ 和观测 $y$ 的关系如下：\n$$ u = u $$\n$$ y = u + \\eta $$\n变量 $u$ 和 $\\eta$ 是独立的高斯变量，其中 $u \\sim \\mathcal{N}(m_0, C_0)$ 且 $\\eta \\sim \\mathcal{N}(0, \\Gamma)$。我们可以将联合变量 $\\begin{pmatrix} u \\\\ y \\end{pmatrix} \\in H \\times H$ 表示为中心化的独立高斯变量 $u' = u - m_0 \\sim \\mathcal{N}(0, C_0)$ 和 $\\eta \\sim \\mathcal{N}(0, \\Gamma)$ 的仿射变换。\n向量 $\\begin{pmatrix} u' \\\\ \\eta \\end{pmatrix}$ 是 $H \\times H$ 上的零均值高斯变量。由于 $u'$ 和 $\\eta$ 的独立性，其协方差算子是分块对角算子 $\\begin{pmatrix} C_0  0 \\\\ 0  \\Gamma \\end{pmatrix}$。\n\n变换由下式给出：\n$$\n\\begin{pmatrix} u \\\\ y \\end{pmatrix} = \\begin{pmatrix} u' + m_0 \\\\ (u' + m_0) + \\eta \\end{pmatrix} = \\begin{pmatrix} I  0 \\\\ I  I \\end{pmatrix} \\begin{pmatrix} u' \\\\ \\eta \\end{pmatrix} + \\begin{pmatrix} m_0 \\\\ m_0 \\end{pmatrix}\n$$\n其中 $I$ 是 $H$ 上的恒等算子。\n\n由于 $\\begin{pmatrix} u \\\\ y \\end{pmatrix}$ 是一个高斯变量的仿射变换，它本身也是高斯的。我们现在计算它的均值和协方差算子。\n\n均值通过应用期望定律求得：\n$$\n\\mathbb{E}\\left[ \\begin{pmatrix} u \\\\ y \\end{pmatrix} \\right] = \\mathbb{E}\\left[ \\begin{pmatrix} I  0 \\\\ I  I \\end{pmatrix} \\begin{pmatrix} u' \\\\ \\eta \\end{pmatrix} + \\begin{pmatrix} m_0 \\\\ m_0 \\end{pmatrix} \\right] = \\begin{pmatrix} I  0 \\\\ I  I \\end{pmatrix} \\mathbb{E}\\left[ \\begin{pmatrix} u' \\\\ \\eta \\end{pmatrix} \\right] + \\begin{pmatrix} m_0 \\\\ m_0 \\end{pmatrix}\n$$\n由于 $\\mathbb{E}[u'] = 0$ 且 $\\mathbb{E}[\\eta] = 0$，均值为：\n$$\n\\mathbb{E}\\left[ \\begin{pmatrix} u \\\\ y \\end{pmatrix} \\right] = \\begin{pmatrix} I  0 \\\\ I  I \\end{pmatrix} \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} m_0 \\\\ m_0 \\end{pmatrix} = \\begin{pmatrix} m_0 \\\\ m_0 \\end{pmatrix}\n$$\n\n变换后变量的协方差算子由公式 $L C_{\\text{in}} L^*$ 给出，其中 $L = \\begin{pmatrix} I  0 \\\\ I  I \\end{pmatrix}$ 且 $C_{\\text{in}} = \\begin{pmatrix} C_0  0 \\\\ 0  \\Gamma \\end{pmatrix}$。在希尔伯特空间 $H \\times H$ 上的伴随算子 $L^*$ 是 $L^* = \\begin{pmatrix} I  I \\\\ 0  I \\end{pmatrix}$。\n联合协方差算子是：\n$$\n\\operatorname{Cov}\\left( \\begin{pmatrix} u \\\\ y \\end{pmatrix} \\right) = \\begin{pmatrix} I  0 \\\\ I  I \\end{pmatrix} \\begin{pmatrix} C_0  0 \\\\ 0  \\Gamma \\end{pmatrix} \\begin{pmatrix} I  I \\\\ 0  I \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} C_0  0 \\\\ C_0  \\Gamma \\end{pmatrix} \\begin{pmatrix} I  I \\\\ 0  I \\end{pmatrix}\n$$\n$$\n= \\begin{pmatrix} C_0 I + 0  C_0 I + 0 \\\\ C_0 I + 0  C_0 I + \\Gamma I \\end{pmatrix} = \\begin{pmatrix} C_0  C_0 \\\\ C_0  C_0 + \\Gamma \\end{pmatrix}\n$$\n注意到 $C_0$ 是自伴的，所以交叉协方差块 $C_{yu} = C_{uy}^* = C_0^* = C_0$，这是一致的。\n因此，$(u, y)$ 的联合分布是高斯的：\n$$\n\\begin{pmatrix} u \\\\ y \\end{pmatrix} \\sim \\mathcal{N} \\left( \\begin{pmatrix} m_0 \\\\ m_0 \\end{pmatrix}, \\begin{pmatrix} C_0  C_0 \\\\ C_0  C_0 + \\Gamma \\end{pmatrix} \\right)\n$$\n贝叶斯统计的一个基本结果是，对于线性高斯模型，后验分布 $p(u|y)$ 与从联合分布 $p(u,y)$ 推导出的给定 $y$ 的 $u$ 的条件分布相同。虽然可以用 Cameron-Martin 定理和 Radon-Nikodym 导数来形式化定义后验测度 $\\mu^y$，但这等价于对联合高斯测度取条件。因此，给定观测 $y$ 的 $u$ 的后验法则是高斯的，其矩由条件高斯分布的标准公式给出。\n\n**第 2 部分：后验均值和协方差**\n\n对于一个一般的联合高斯变量 $\\begin{pmatrix} X_1 \\\\ X_2 \\end{pmatrix} \\sim \\mathcal{N}\\left( \\begin{pmatrix} \\mu_1 \\\\ \\mu_2 \\end{pmatrix}, \\begin{pmatrix} \\Sigma_{11}  \\Sigma_{12} \\\\ \\Sigma_{21}  \\Sigma_{22} \\end{pmatrix} \\right)$，给定 $X_2 = x_2$ 时 $X_1$ 的条件分布也是高斯的，为 $\\mathcal{N}(\\mu_{1|2}, \\Sigma_{11|2})$，其均值和协方差由以下公式给出：\n$$ \\mu_{1|2} = \\mu_1 + \\Sigma_{12} \\Sigma_{22}^{-1} (x_2 - \\mu_2) $$\n$$ \\Sigma_{11|2} = \\Sigma_{11} - \\Sigma_{12} \\Sigma_{22}^{-1} \\Sigma_{21} $$\n我们通过以下对应关系将这些公式应用于我们的问题：\n$X_1 \\leftrightarrow u$，$X_2 \\leftrightarrow y$，$x_2 \\leftrightarrow y$（具体的观测值）。\n$\\mu_1 \\leftrightarrow m_0$, $\\mu_2 \\leftrightarrow m_0$.\n$\\Sigma_{11} \\leftrightarrow C_0$, $\\Sigma_{12} \\leftrightarrow C_0$, $\\Sigma_{21} \\leftrightarrow C_0$, $\\Sigma_{22} \\leftrightarrow C_0 + \\Gamma$.\n\n逆 $\\Sigma_{22}^{-1} = (C_0 + \\Gamma)^{-1}$ 存在且是 $H$ 上的有界算子。这是因为 $C_0$ 是一个正算子，而 $\\Gamma$ 是一个严格正（强制）的自伴算子，这使得它们的和 $C_0 + \\Gamma$ 也是强制的，因此根据 Lax-Milgram 定理是有界可逆的。\n\n后验均值 $m^y$ 是：\n$$\nm^y = m_0 + C_0 (C_0 + \\Gamma)^{-1} (y - m_0)\n$$\n这个表达式是著名的卡尔曼均值更新公式在希尔伯特空间上的推广。它根据新息 $(y-m_0)$ 来调整先验均值 $m_0$，并由“增益”算子 $K = C_0 (C_0 + \\Gamma)^{-1}$ 加权。\n\n后验协方差算子 $C^y$ 是：\n$$\nC^y = C_0 - C_0 (C_0 + \\Gamma)^{-1} C_0\n$$\n这个后验协方差的表达式也是基础性的，代表了由观测导致的不确定性的减少。它是一个良定义的、自伴的、正的、迹类的算子。该表达式严格地只使用了给定的算子及其良定义的逆，符合要求。\n\n数对 $(m^y, C^y)$ 完全刻画了后验高斯测度 $\\mu^y = \\mathcal{N}(m^y, C^y)$。", "answer": "$$\n\\boxed{\\begin{pmatrix} m_0 + C_0 (C_0 + \\Gamma)^{-1} (y - m_0)  C_0 - C_0 (C_0 + \\Gamma)^{-1} C_0 \\end{pmatrix}}\n$$", "id": "3385131"}, {"introduction": "我们的最后一个练习探讨了将高斯测度的解析描述转化为计算采样算法时出现的一个关键挑战。我们将研究为什么一个看似合理的算法在问题维度增加时会灾难性地失效，这是无限维设置中的一个常见病理。通过将一个朴素的基于梯度的采样器与一个为尊重底层几何而设计的预处理方法进行对比，这个练习揭示了卡梅伦-马丁空间在开发稳健数值方法方面的深远重要性。", "problem": "考虑一个可分希尔伯特空间 $H$，其标准正交基为 $\\{e_k\\}_{k \\ge 1}$。设 $C$ 是 $H$ 上的一个自伴、正定、迹类协方差算子，定义为 $C e_k = \\lambda_k e_k$，其特征值为 $\\lambda_k = k^{-2\\alpha}$，其中 $\\alpha  \\tfrac{1}{2}$ 为一个固定值。在 $H$ 上定义中心化高斯测度 $\\mu = \\mathcal{N}(0, C)$。Cameron-Martin 空间 $H_C$ 是 $C^{1/2}$ 的值域，其范数定义为 $\\|h\\|_{H_C}^2 = \\langle C^{-1/2} h, C^{-1/2} h \\rangle_H$。考虑后验分布 $\\pi$ 等于 $\\mu$（即“无数据”情况），因此目标分布为 $\\mathcal{N}(0, C)$。\n\n您将比较两种马尔可夫链蒙特卡洛 (MCMC) 提议机制在有限维截断 $H_n = \\operatorname{span}\\{e_1, \\dots, e_n\\}$ 上的表现，其中 $C_n$ 是 $C$ 在 $H_n$ 上的限制，并且在基 $\\{e_k\\}_{k=1}^n$ 下是对角的，对角线元素为 $\\lambda_k = k^{-2\\alpha}$。\n\n1.  一种在 $H_n$ 中使用单位质量矩阵的朴素 Metropolis-Adjusted Langevin Algorithm (MALA)，它使用 $H_n$ 中负对数密度的梯度步长。对于状态 $x \\in \\mathbb{R}^n$，负对数密度为 $\\Phi_n(x) = \\tfrac{1}{2} \\langle x, C_n^{-1} x \\rangle$，因此梯度为 $\\nabla \\Phi_n(x) = C_n^{-1} x$。对于步长 $\\varepsilon  0$，提议为\n    $$\n    x' \\sim q_{\\mathrm{MALA}}(\\cdot \\mid x) = \\mathcal{N}\\Big(x - \\tfrac{\\varepsilon}{2} C_n^{-1} x, \\, \\varepsilon I_n \\Big).\n    $$\n    Metropolis-Hastings 接受概率为\n    $$\n    a_{\\mathrm{MALA}}(x, x') = \\min\\left\\{1, \\frac{\\pi_n(x') \\, q_{\\mathrm{MALA}}(x \\mid x')}{\\pi_n(x) \\, q_{\\mathrm{MALA}}(x' \\mid x)} \\right\\},\n    $$\n    其中 $\\pi_n$ 是 $\\mathcal{N}(0, C_n)$ 的密度。\n\n2.  一种在 $H_n$ 上、参数为 $\\beta \\in (0,1)$ 的 Cameron-Martin 预处理、保持先验的提议（预处理的 Crank–Nicolson 机制）为\n    $$\n    x' = \\sqrt{1 - \\beta^2} \\, x + \\beta \\, \\eta, \\quad \\eta \\sim \\mathcal{N}(0, C_n).\n    $$\n    此提议保持 $\\mathcal{N}(0, C_n)$ 并且是可逆的，因此对于高斯目标 $\\mathcal{N}(0, C_n)$，接受概率为 $a_{\\mathrm{pCN}}(x, x') \\equiv 1$。\n\n您的任务：\n\n(a) 仅使用关于希尔伯特空间上高斯测度的基本事实、Cameron-Martin 空间的定义以及 Metropolis-Hastings 接受准则，构造一个反例，说明朴素 MALA 提议在无限维极限下接受率趋于零，而 Cameron-Martin 预处理提议则保持在高概率区域内。具体来说，考虑截断序列 $H_n$ (其中 $\\lambda_k = k^{-2\\alpha}$ 且 $\\varepsilon  0$ 固定)，并从第一性原理出发论证，为什么当 $n \\to \\infty$ 时，朴素 MALA 的漂移项 $\\tfrac{\\varepsilon}{2} C_n^{-1} x$ 会被不属于典型抽样 $x \\sim \\mathcal{N}(0, C)$ 的 Cameron-Martin 空间的那些方向所主导，导致提议被绝大多数拒绝；而预处理提议则沿着 Cameron-Martin 几何结构作用并保持目标分布。\n\n(b) 实现一个数值实验，估计两种提议在三个截断维度上的经验接受概率。使用以下测试套件：\n- $\\alpha = 1.5$，\n- MALA 步长 $\\varepsilon = 10^{-2}$，\n- 预处理提议参数 $\\beta = 0.2$，\n- 维度 $n \\in \\{16, 64, 256\\}$，\n- 每种情况下的独立试验次数 $T = 2000$，\n- 为保证可复现性，随机种子固定为 $12345$。\n\n对于 MALA 的情况，生成 $T$ 个独立的初始状态 $x \\sim \\mathcal{N}(0, C_n)$，通过 MALA 核提议 $x'$，计算 Metropolis-Hastings 接受概率，并估计接受率（即被接受的提议所占的比例）。对于预处理提议，您可以计算提议并统计接受比例，也可以使用不变性论证来报告接受率为 $1$。\n\n您的程序应生成单行输出，其中包含一个方括号内的逗号分隔列表。该列表必须按以下顺序展平：\n$$\n[\\mathrm{acc}_{\\mathrm{MALA}}(n{=}16), \\, \\mathrm{acc}_{\\mathrm{pCN}}(n{=}16), \\, \\mathrm{acc}_{\\mathrm{MALA}}(n{=}64), \\, \\mathrm{acc}_{\\mathrm{pCN}}(n{=}64), \\, \\mathrm{acc}_{\\mathrm{MALA}}(n{=}256), \\, \\mathrm{acc}_{\\mathrm{pCN}}(n{=}256)]。\n$$\n每个条目必须是十进制形式的浮点数。不涉及物理单位或角度。\n\n设计考量：\n- (a) 部分的反例推理必须从希尔伯特空间上的高斯测度定义、Cameron-Martin 空间定义以及 Cameron-Martin 平移定理出发，结合 Metropolis-Hastings 接受准则，并应解释为什么朴素的梯度步长会在高频模式下累积能量，而 Cameron-Martin 预处理则避免了这种病态问题。\n- (b) 部分的数值实验必须严格遵守测试套件的参数，以确保可复现性和覆盖范围。$n = 16$ 的情况是一个顺利的情况，$n = 256$ 强调高频模式，而 $n = 64$ 则是中间情况。", "solution": "该问题陈述在数学上和科学上都是合理的、良定的，并为理论分析和数值实验提供了一套完整的规范。因此，我们可以着手提供完整的解决方案。\n\n这个问题的核心在于理解无限维希尔伯特空间的几何结构如何与马尔可夫链蒙特卡洛 (MCMC) 算法相互作用。我们正在比较两种用于从可分希尔伯特空间 $H$ 上的中心化高斯测度 $\\mu = \\mathcal{N}(0, C)$ 进行采样的提议方法。这些算法在无限维极限 ($n \\to \\infty$) 下的行为揭示了朴素的基于梯度的方法中的一个关键病态问题，并凸显了预处理的必要性。\n\n$H$ 上的高斯测度 $\\mu = \\mathcal{N}(0, C)$ 是良定的，条件是协方差算子 $C$ 是迹类的，即 $\\operatorname{tr}(C) = \\sum_{k=1}^\\infty \\lambda_k  \\infty$。给定 $\\lambda_k = k^{-2\\alpha}$，迹为 $\\sum_{k=1}^\\infty k^{-2\\alpha}$，该级数当且仅当 $2\\alpha  1$（即 $\\alpha  \\tfrac{1}{2}$）时收敛。问题中 $\\alpha  \\tfrac{1}{2}$ 的约束确保了这一点。从 $\\mu$ 中抽取的典型实现 $x = \\sum_{k=1}^\\infty x_k e_k$ 具有随机、独立的系数 $x_k \\sim \\mathcal{N}(0, \\lambda_k)$。其期望平方范数是有限的：$E[\\|x\\|_H^2] = E[\\sum_{k=1}^\\infty x_k^2] = \\sum_{k=1}^\\infty E[x_k^2] = \\sum_{k=1}^\\infty \\lambda_k = \\operatorname{tr}(C)  \\infty$。这意味着从 $\\mu$ 中抽取的样本几乎必然在 $H$ 中。\n\n与 $\\mu$ 相关联的 Cameron-Martin 空间 $H_C$ 是 $H$ 的一个子空间，由满足 $\\|h\\|_{H_C}^2 = \\|C^{-1/2}h\\|_H^2 = \\sum_{k=1}^\\infty \\lambda_k^{-1} h_k^2  \\infty$ 的向量 $h$ 组成。一个基本结果，即 Feldman–Hajek 定理，指出一个典型抽样 $x \\sim \\mu$ 几乎必然*不*在 Cameron-Martin 空间 $H_C$ 中。这可以通过计算一次抽样的期望 Cameron-Martin 范数看出：$E[\\|x\\|_{H_C}^2] = E[\\sum_{k=1}^\\infty \\lambda_k^{-1}x_k^2] = \\sum_{k=1}^\\infty \\lambda_k^{-1}E[x_k^2] = \\sum_{k=1}^\\infty \\lambda_k^{-1}\\lambda_k = \\sum_{k=1}^\\infty 1 = \\infty$。Cameron-Martin 定理进一步指出，将测度 $\\mu$ 平移一个向量 $v \\in H$ 所得到的新测度与 $\\mu$ 相互绝对连续，当且仅当 $v \\in H_C$。如果 $v \\notin H_C$，则平移后的测度相对于 $\\mu$ 是奇异的。这意味着将一个样本朝着不包含在 $H_C$ 中的方向移动，就是移动到一个在 $\\mu$ 下概率为零的区域。\n\n(a) 基于此基础，我们可以分析这两种提议在有限维空间 $H_n = \\operatorname{span}\\{e_1, \\dots, e_n\\}$ 上的表现，并始终考虑 $n \\to \\infty$ 的极限情况。\n\n首先，考虑朴素的 Metropolis-Adjusted Langevin Algorithm (MALA)。提议为 $x' \\sim \\mathcal{N}(x - \\tfrac{\\varepsilon}{2} C_n^{-1} x, \\varepsilon I_n)$。更新的确定性部分，即漂移项，是 $v_n(x) = -\\tfrac{\\varepsilon}{2} C_n^{-1} x$。对于一个典型的抽样 $x \\sim \\mathcal{N}(0, C_n)$，该漂移向量的系数为 $(v_n(x))_k = -\\tfrac{\\varepsilon}{2} \\lambda_k^{-1} x_k$。这个第 $k$ 个系数的方差是 $(\\tfrac{\\varepsilon}{2})^2 \\lambda_k^{-2} E[x_k^2] = (\\tfrac{\\varepsilon}{2})^2 \\lambda_k^{-1} = (\\tfrac{\\varepsilon}{2})^2 k^{2\\alpha}$。该方差随模式数 $k$ 增长。因此，当 $n \\to \\infty$ 时，漂移向量的 $H$-范数平方的期望值发散：\n$$\nE\\left[ \\| v_n(x) \\|_H^2 \\right] = \\sum_{k=1}^n E\\left[ \\left(-\\tfrac{\\varepsilon}{2} \\lambda_k^{-1} x_k\\right)^2 \\right] = \\left(\\tfrac{\\varepsilon}{2}\\right)^2 \\sum_{k=1}^n \\lambda_k^{-1} = \\left(\\tfrac{\\varepsilon}{2}\\right)^2 \\sum_{k=1}^n k^{2\\alpha} \\to \\infty.\n$$\n对于一个典型样本，漂移项会变得无限大，将提议 $x'$ 推到离当前状态 $x$ 非常远的地方。这本身并不是致命缺陷；问题在于 Metropolis-Hastings 校正。接受概率为 $a_{\\mathrm{MALA}}(x, x') = \\min\\{1, R\\}$，其中比率 $R = \\frac{\\pi_n(x') q_{\\mathrm{MALA}}(x|x')}{\\pi_n(x) q_{\\mathrm{MALA}}(x'|x)}$。虽然漂移项朝向目标密度 $\\pi_n$ 更高的区域移动（即 $\\pi_n(x')/\\pi_n(x)$ 很大），但提议密度的比率 $q_{\\mathrm{MALA}}(x|x')/q_{\\mathrm{MALA}}(x'|x)$ 会变得极小。逆向提议概率 $q_{\\mathrm{MALA}}(x|x')$ 是在 $x$ 处取值的 $\\mathcal{N}(x' - \\tfrac{\\varepsilon}{2}C_n^{-1}x', \\varepsilon I_n)$ 密度。指数中的项与 $\\|x - (x' - \\tfrac{\\varepsilon}{2}C_n^{-1}x')\\|^2$ 成正比。分析表明，对于大的 $n$，这个平方距离中的主导项与 $\\|C_n^{-2}x\\|^2$ 同阶。该项的期望值发散得极其迅速：$E[\\|C_n^{-2}x\\|^2] = \\sum_{k=1}^n \\lambda_k^{-4}E[x_k^2] = \\sum_{k=1}^n \\lambda_k^{-3} = \\sum_{k=1}^n k^{6\\alpha} \\to \\infty$。这迫使 $q_{\\mathrm{MALA}}(x|x')$ 变得异常小，压倒了目标密度的增益，并导致接受概率 $a_{\\mathrm{MALA}}$ 在 $n \\to \\infty$ 时趋于零。MALA 提议通过为其噪声项使用单位矩阵协方差，隐含地假设了标准的欧几里得几何，这与希尔伯特空间上目标高斯测度的几何结构根本不匹配。梯度项 $C_n^{-1}x$ 放大了高频分量，将提议推向不具 $\\mathcal{N}(0, C_n)$ 典型抽样特征的“粗糙”方向，而 M-H 校正理所当然地拒绝了这些移动。\n\n现在，考虑预处理的 Crank-Nicolson (pCN) 提议，$x' = \\sqrt{1 - \\beta^2} x + \\beta \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, C_n)$。此算法的构造与目标测度的几何结构兼容。如果当前状态 $x$ 是从 $\\mathcal{N}(0, C_n)$ 中抽取的，那么 $x'$ 是两个协方差为 $C_n$ 的独立中心化高斯变量的线性组合。因此，$x'$ 也是一个中心化高斯变量。其协方差算子为 $\\operatorname{Cov}(x') = (1 - \\beta^2)\\operatorname{Cov}(x) + \\beta^2\\operatorname{Cov}(\\eta) = (1 - \\beta^2)C_n + \\beta^2C_n = C_n$。该提议机制将一个来自目标分布的状态映射到另一个来自相同分布的状态；它保持了目标测度 $\\pi_n = \\mathcal{N}(0, C_n)$。一个既保持目标测度又满足细致平衡条件 $\\pi_n(x)q(x'|x) = \\pi_n(x')q(x|x')$ 的提议，其接受概率将为 1。通过直接的代数验证可以证明 pCN 提议核关于 $\\pi_n$ 是可逆的。关键的洞见在于，该更新是使用一种“白化”表示构造的。如果我们令 $x = C_n^{1/2}y$，其中 $y \\sim \\mathcal{N}(0, I_n)$，则提议变为 $C_n^{1/2}y' = \\sqrt{1-\\beta^2}C_n^{1/2}y + \\beta C_n^{1/2}\\tilde{\\xi}$，其中 $\\tilde{\\xi} \\sim \\mathcal{N}(0, I_n)$。这简化为 $y' = \\sqrt{1-\\beta^2}y + \\beta\\tilde{\\xi}$，这是一个在白化空间中的简单旋转更新，它显然保持了标准正态分布 $\\mathcal{N}(0, I_n)$。pCN 提议有效地在一个目标是各向同性的坐标系中工作，从而避免了 MALA 遇到的病态问题。更新步长 $\\beta\\eta$ 是从 $\\mathcal{N}(0, \\beta^2 C_n)$ 中抽取的样本，这意味着探索步具有与目标测度本身相同的统计特性，确保它们总是“合理”的。这使得该算法稳健，并且其性能与维度 $n$ 无关，这一性质被称为“在函数空间上良定”。\n\n(b) 数值实验将凭经验验证这一理论推理。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements a numerical experiment to compare the acceptance rates of\n    MALA and pCN proposals for a Gaussian target on truncated Hilbert spaces.\n    \"\"\"\n    # --- Problem Parameters ---\n    alpha = 1.5\n    epsilon = 1e-2  # MALA step size\n    beta = 0.2      # pCN parameter\n    dims = [16, 64, 256]\n    T = 2000        # Number of trials\n    seed = 12345\n\n    # Initialize random number generator for reproducibility\n    rng = np.random.default_rng(seed)\n\n    results = []\n\n    for n in dims:\n        # --- Setup for dimension n ---\n        \n        # Define eigenvalues and related operators (as vectors for diagonal matrices)\n        k = np.arange(1, n + 1)\n        lambdas = k**(-2 * alpha)\n        lambdas_sqrt = k**(-alpha)\n        lambdas_inv = k**(2 * alpha)\n\n        # --- MALA Simulation ---\n        mala_accept_count = 0\n        for _ in range(T):\n            # 1. Generate an initial state x ~ N(0, C_n)\n            z = rng.normal(size=n)\n            x = lambdas_sqrt * z\n\n            # 2. Propose a new state x' via MALA kernel\n            grad_phi_x = lambdas_inv * x\n            mu_proposal = x - 0.5 * epsilon * grad_phi_x\n            xi = rng.normal(size=n)\n            xp = mu_proposal + np.sqrt(epsilon) * xi\n\n            # 3. Compute Metropolis-Hastings acceptance probability\n            # Log of target density (up to a constant)\n            log_pi_x = -0.5 * np.sum(x * x * lambdas_inv)\n            log_pi_xp = -0.5 * np.sum(xp * xp * lambdas_inv)\n            \n            # Log of proposal density (up to a constant)\n            # Forward: q(x'|x)\n            log_q_xp_given_x = -0.5 / epsilon * np.sum((xp - mu_proposal)**2)\n\n            # Reverse: q(x|x')\n            grad_phi_xp = lambdas_inv * xp\n            mu_reverse = xp - 0.5 * epsilon * grad_phi_xp\n            log_q_x_given_xp = -0.5 / epsilon * np.sum((x - mu_reverse)**2)\n\n            # Log of the full MH ratio\n            log_ratio = (log_pi_xp + log_q_x_given_xp) - (log_pi_x + log_q_xp_given_x)\n\n            # Acceptance probability\n            a_mala = min(1.0, np.exp(log_ratio))\n\n            # 4. Accept or reject\n            if rng.uniform()  a_mala:\n                mala_accept_count += 1\n        \n        mala_acceptance_rate = mala_accept_count / T\n        results.append(mala_acceptance_rate)\n        \n        # --- pCN Result ---\n        # The pCN proposal preserves the Gaussian target,\n        # and the proposal kernel is reversible with respect to the target.\n        # This guarantees an acceptance probability of 1.\n        pcn_acceptance_rate = 1.0\n        results.append(pcn_acceptance_rate)\n\n    # Print the final results in the required format\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3385118"}]}