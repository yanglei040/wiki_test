{"hands_on_practices": [{"introduction": "正则化线性逆问题的核心在于理解偏差与方差之间的权衡。这项实践是该领域的基石练习，它利用奇异值分解（SVD）这一强大的数学工具来剖析问题。通过推导一个通用谱滤波器（以吉洪诺夫正则化为例）的均方误差，并将其分解为偏差的平方和方差，你将亲手揭示正则化参数 $\\alpha$ 如何精确地调控这两个相互竞争的误差源，从而深刻理解偏差-方差权衡的本质。[@problem_id:3368363]", "problem": "考虑一个在有限维欧几里得空间中的线性逆问题，其数据模型为 $y = A x + \\varepsilon$，其中 $A$ 的奇异值分解 (SVD) 为 $A = U \\Sigma V^{\\top}$，奇异值为 $\\{\\sigma_i\\}_{i=1}^r$，左奇异向量为 $\\{u_i\\}_{i=1}^r$，右奇异向量为 $\\{v_i\\}_{i=1}^r$。假设加性噪声 $\\varepsilon$ 是零均值、正态分布（高斯分布）、独立同分布 (i.i.d.) 的，其协方差为 $\\sigma^2 I$，其中 $\\sigma^2 > 0$ 是已知的。考虑一个谱滤波正则化估计量，其形式为\n$$\n\\hat{x}_{\\alpha} \\;=\\; \\sum_{i=1}^r \\frac{f_i(\\alpha)}{\\sigma_i} \\,\\langle y, u_i \\rangle \\, v_i,\n$$\n其中 $\\alpha > 0$ 是正则化参数，$\\{f_i(\\alpha)\\}_{i=1}^r$ 是从 $[0,\\infty)$ 映射到 $[0,1]$ 的滤波函数。\n\n您的任务是：\n\n1. 仅从数据模型、奇异向量的标准正交性以及期望的线性性出发，推导均方误差 (MSE) 的闭式表达式。均方误差定义为噪声条件下的期望 $\\mathbb{E}_{\\varepsilon}\\|\\hat{x}_{\\alpha} - x\\|^2$，表达式应以 $\\{f_i(\\alpha)\\}$、$\\{\\sigma_i\\}$、系数 $\\{\\langle x, v_i\\rangle\\}$ 和 $\\sigma^2$ 表示。\n\n2. 将结果具体化到 Tikhonov 正则化，其中对每个 $i$ 都有 $f_i(\\alpha) = \\sigma_i^2/(\\sigma_i^2 + \\alpha)$。使用您在第 1 部分中得到的表达式，定性地解释增加 $\\alpha$ 如何改变通常被认为是均方误差中的偏差平方和方差的贡献。\n\n3. 在一维情况（$r=1$）下，设奇异值为 $\\sigma_1 = s > 0$，真实系数的模为 $a = |\\langle x, v_1\\rangle|$，并假设采用第 2 部分中的 Tikhonov 正则化。计算使 $\\mathbb{E}_{\\varepsilon}\\|\\hat{x}_{\\alpha} - x\\|^2$ 在 $\\alpha > 0$ 上最小化的值 $\\alpha^{\\star}$。您的最终答案应表示为以 $a$ 和 $\\sigma$ 表示的闭式解析表达式。无需四舍五入，也无需报告物理单位。", "solution": "该问题陈述是正则化线性逆问题领域的标准表述，在最后一部分信号分量非零的合理假设下，该问题在数学上是合理的、自洽的且适定的。该问题是有效的。\n\n### 第 1 部分：均方误差 (MSE) 的推导\n\n均方误差 (MSE) 定义为误差向量的平方范数在噪声实现 $\\varepsilon$ 条件下的期望：\n$$\n\\text{MSE} \\;=\\; \\mathbb{E}_{\\varepsilon}\\left[\\|\\hat{x}_{\\alpha} - x\\|^2\\right]\n$$\n$x$ 所在的向量空间可以分解为由右奇异向量 $\\{v_i\\}_{i=1}^r$ 张成的 $A$ 的零空间的正交补，以及由 $\\{v_j\\}_{j=r+1}^n$ 张成的 $A$ 的零空间。因此，我们可以将真实解 $x$ 写为：\n$$\nx \\;=\\; \\sum_{i=1}^r \\langle x, v_i \\rangle v_i + \\sum_{j=r+1}^n \\langle x, v_j \\rangle v_j\n$$\n估计量 $\\hat{x}_{\\alpha}$ 被构造为 $\\{v_i\\}_{i=1}^r$ 的线性组合，因此完全位于这些向量张成的子空间中。误差向量 $\\hat{x}_{\\alpha} - x$ 可以分为两个正交的分量：\n$$\n\\hat{x}_{\\alpha} - x \\;=\\; \\left(\\hat{x}_{\\alpha} - \\sum_{i=1}^r \\langle x, v_i \\rangle v_i\\right) - \\left(\\sum_{j=r+1}^n \\langle x, v_j \\rangle v_j\\right)\n$$\n由于这两个分量的正交性，根据勾股定理，平方范数是它们各自平方范数之和：\n$$\n\\|\\hat{x}_{\\alpha} - x\\|^2 \\;=\\; \\left\\|\\hat{x}_{\\alpha} - \\sum_{i=1}^r \\langle x, v_i \\rangle v_i\\right\\|^2 + \\left\\|\\sum_{j=r+1}^n \\langle x, v_j \\rangle v_j\\right\\|^2\n$$\n将估计量 $\\hat{x}_{\\alpha}$ 的定义代入第一项，并利用基向量 $\\{v_i\\}_{i=1}^r$ 的标准正交性：\n$$\n\\left\\|\\sum_{i=1}^r \\frac{f_i(\\alpha)}{\\sigma_i} \\langle y, u_i \\rangle v_i - \\sum_{i=1}^r \\langle x, v_i \\rangle v_i\\right\\|^2 \\;=\\; \\left\\|\\sum_{i=1}^r \\left(\\frac{f_i(\\alpha)}{\\sigma_i} \\langle y, u_i \\rangle - \\langle x, v_i \\rangle\\right) v_i\\right\\|^2 \\;=\\; \\sum_{i=1}^r \\left(\\frac{f_i(\\alpha)}{\\sigma_i} \\langle y, u_i \\rangle - \\langle x, v_i \\rangle\\right)^2\n$$\n第二项是 $x$ 在 $A$ 的零空间中的分量的平方范数，这是一个不可约的误差分量，因为估计量无法访问该子空间。该项相对于噪声 $\\varepsilon$ 是常数：\n$$\n\\left\\|\\sum_{j=r+1}^n \\langle x, v_j \\rangle v_j\\right\\|^2 \\;=\\; \\sum_{j=r+1}^n \\langle x, v_j \\rangle^2\n$$\n现在我们将数据模型 $y = Ax + \\varepsilon$ 代入项 $\\langle y, u_i \\rangle$ 中：\n$$\n\\langle y, u_i \\rangle \\;=\\; \\langle Ax + \\varepsilon, u_i \\rangle \\;=\\; \\langle Ax, u_i \\rangle + \\langle \\varepsilon, u_i \\rangle\n$$\n利用 SVD 的性质 $Av_k = \\sigma_k u_k$，因此 $A (\\sum_k \\langle x, v_k \\rangle v_k) = \\sum_k \\langle x, v_k \\rangle \\sigma_k u_k$，我们得到：\n$$\n\\langle Ax, u_i \\rangle \\;=\\; \\left\\langle \\sum_{k=1}^r \\langle x, v_k \\rangle \\sigma_k u_k, u_i \\right\\rangle \\;=\\; \\sum_{k=1}^r \\langle x, v_k \\rangle \\sigma_k \\langle u_k, u_i \\rangle \\;=\\; \\sigma_i \\langle x, v_i \\rangle\n$$\n所以，$\\langle y, u_i \\rangle = \\sigma_i \\langle x, v_i \\rangle + \\langle \\varepsilon, u_i \\rangle$。将其代回：\n$$\n\\frac{f_i(\\alpha)}{\\sigma_i} \\langle y, u_i \\rangle - \\langle x, v_i \\rangle \\;=\\; \\frac{f_i(\\alpha)}{\\sigma_i} (\\sigma_i \\langle x, v_i \\rangle + \\langle \\varepsilon, u_i \\rangle) - \\langle x, v_i \\rangle \\;=\\; (f_i(\\alpha)-1) \\langle x, v_i \\rangle + \\frac{f_i(\\alpha)}{\\sigma_i} \\langle \\varepsilon, u_i \\rangle\n$$\n平方和变为：\n$$\n\\sum_{i=1}^r \\left( (f_i(\\alpha)-1) \\langle x, v_i \\rangle + \\frac{f_i(\\alpha)}{\\sigma_i} \\langle \\varepsilon, u_i \\rangle \\right)^2\n$$\n现在我们取期望 $\\mathbb{E}_{\\varepsilon}$。噪声 $\\varepsilon$ 的均值为零，所以 $\\mathbb{E}_{\\varepsilon}[\\varepsilon] = 0$。这意味着 $\\mathbb{E}_{\\varepsilon}[\\langle \\varepsilon, u_i \\rangle] = \\langle \\mathbb{E}_{\\varepsilon}[\\varepsilon], u_i \\rangle = 0$。因此，平方展开式中的交叉项在取期望后消失。我们剩下：\n$$\n\\mathbb{E}_{\\varepsilon}\\left[\\sum_{i=1}^r \\left( (f_i(\\alpha)-1)^2 \\langle x, v_i \\rangle^2 + \\left(\\frac{f_i(\\alpha)}{\\sigma_i}\\right)^2 \\langle \\varepsilon, u_i \\rangle^2 \\right)\\right] = \\sum_{i=1}^r \\left( (f_i(\\alpha)-1)^2 \\langle x, v_i \\rangle^2 + \\left(\\frac{f_i(\\alpha)}{\\sigma_i}\\right)^2 \\mathbb{E}_{\\varepsilon}[\\langle \\varepsilon, u_i \\rangle^2] \\right)\n$$\n项 $\\mathbb{E}_{\\varepsilon}[\\langle \\varepsilon, u_i \\rangle^2]$ 是随机变量 $\\langle \\varepsilon, u_i \\rangle = u_i^\\top\\varepsilon$ 的方差。鉴于 $\\text{Cov}(\\varepsilon) = \\sigma^2 I$，方差为：\n$$\n\\mathbb{E}_{\\varepsilon}[\\langle \\varepsilon, u_i \\rangle^2] \\;=\\; \\text{Var}(u_i^\\top\\varepsilon) \\;=\\; u_i^\\top \\text{Cov}(\\varepsilon) u_i \\;=\\; u_i^\\top (\\sigma^2 I) u_i \\;=\\; \\sigma^2 (u_i^\\top u_i) \\;=\\; \\sigma^2\n$$\n因为 $u_i$ 是单位向量。\n综合所有部分，均方误差 (MSE) 是：\n$$\n\\text{MSE} \\;=\\; \\sum_{i=1}^r \\left( (f_i(\\alpha)-1)^2 \\langle x, v_i \\rangle^2 + \\frac{f_i(\\alpha)^2 \\sigma^2}{\\sigma_i^2} \\right) + \\sum_{j=r+1}^n \\langle x, v_j \\rangle^2\n$$\n\n### 第 2 部分：Tikhonov 正则化的解释\n\n对于 Tikhonov 正则化，滤波函数为 $f_i(\\alpha) = \\frac{\\sigma_i^2}{\\sigma_i^2 + \\alpha}$。均方误差由三部分组成：偏差平方、方差和不可约的零空间误差。正则化参数 $\\alpha$ 只影响前两部分。\n\n偏差平方是求和中的第一项：\n$$\n\\text{Bias}^2(\\alpha) \\;=\\; \\sum_{i=1}^r (f_i(\\alpha)-1)^2 \\langle x, v_i \\rangle^2 \\;=\\; \\sum_{i=1}^r \\left(\\frac{\\sigma_i^2}{\\sigma_i^2+\\alpha}-1\\right)^2 \\langle x, v_i \\rangle^2 \\;=\\; \\sum_{i=1}^r \\left(\\frac{-\\alpha}{\\sigma_i^2+\\alpha}\\right)^2 \\langle x, v_i \\rangle^2 \\;=\\; \\sum_{i=1}^r \\frac{\\alpha^2}{(\\sigma_i^2+\\alpha)^2} \\langle x, v_i \\rangle^2\n$$\n方差是第二项：\n$$\n\\text{Var}(\\alpha) \\;=\\; \\sum_{i=1}^r \\frac{f_i(\\alpha)^2 \\sigma^2}{\\sigma_i^2} \\;=\\; \\sum_{i=1}^r \\left(\\frac{\\sigma_i^2}{\\sigma_i^2+\\alpha}\\right)^2 \\frac{\\sigma^2}{\\sigma_i^2} \\;=\\; \\sum_{i=1}^r \\frac{\\sigma_i^2}{(\\sigma_i^2+\\alpha)^2} \\sigma^2\n$$\n分析增加 $\\alpha > 0$ 的影响：\n- **偏差平方**：对于每个分量 $i$，项 $\\frac{\\alpha}{\\sigma_i^2+\\alpha}$ 是关于 $\\alpha$ 的单调递增函数。当 $\\alpha \\to 0^+$ 时，该项趋近于 $0$。当 $\\alpha \\to \\infty$ 时，该项趋近于 $1$。因此，总偏差平方 $\\text{Bias}^2(\\alpha)$ 是关于 $\\alpha$ 的单调递增函数。增加 $\\alpha$ 会加强正则化，使估计值向 $0$ 收缩。这会引入与真实解之间更大的系统性偏差（bias）。\n- **方差**：对于每个分量 $i$，项 $\\frac{1}{(\\sigma_i^2+\\alpha)^2}$ 是关于 $\\alpha$ 的单调递减函数。当 $\\alpha \\to 0^+$ 时，该项为 $\\frac{1}{(\\sigma_i^2)^2}$，对于小的 $\\sigma_i$，方差项 $(\\sigma^2/\\sigma_i^2)$ 可能很大。当 $\\alpha \\to \\infty$ 时，该项趋近于 $0$。因此，总方差 $\\text{Var}(\\alpha)$ 是关于 $\\alpha$ 的单调递减函数。增加 $\\alpha$ 会抑制噪声的放大，特别是对于与小奇异值相关的分量，从而降低估计量的总方差。\n\n总之，增加正则化参数 $\\alpha$ 会增加偏差平方，同时减少方差。这就是正则化中典型的偏差-方差权衡。\n\n### 第 3 部分：一维情况下的最优 $\\alpha$\n\n在一维情况下，我们有 $r=1$，$\\sigma_1 = s > 0$，以及 $|\\langle x, v_1\\rangle| = a$。令 $c = \\langle x, v_1\\rangle$，则 $c^2 = a^2$。需要最小化的均方误差作为 $\\alpha$ 的函数，是偏差项和方差项之和（零空间误差是常数，不影响最小值的位置）：\n$$\nJ(\\alpha) \\;=\\; \\frac{\\alpha^2}{(s^2+\\alpha)^2} c^2 + \\frac{s^2}{(s^2+\\alpha)^2} \\sigma^2 \\;=\\; \\frac{\\alpha^2 c^2 + s^2 \\sigma^2}{(s^2+\\alpha)^2}\n$$\n为了找到使 $J(\\alpha)$ 在 $\\alpha > 0$ 上最小化的值 $\\alpha^{\\star}$，我们计算关于 $\\alpha$ 的导数并令其为零。我们假设 $a > 0$，这意味着 $c \\neq 0$。如果 $a=0$，偏差项消失，$J(\\alpha)$ 成为 $\\alpha$ 的严格递减函数，这意味着在 $(0, \\infty)$ 中不存在最小值。\n使用商法则求导：\n$$\n\\frac{dJ}{d\\alpha} \\;=\\; \\frac{(2\\alpha c^2)(s^2+\\alpha)^2 - (\\alpha^2 c^2 + s^2 \\sigma^2)(2(s^2+\\alpha))}{(s^2+\\alpha)^4}\n$$\n令分子为零，并除以非零因子 $2(s^2+\\alpha)$（因为 $s>0, \\alpha>0$）：\n$$\n(2\\alpha c^2)\\frac{1}{2}(s^2+\\alpha) - (\\alpha^2 c^2 + s^2 \\sigma^2) \\;=\\; 0\n$$\n$$\n\\alpha c^2 (s^2+\\alpha) - (\\alpha^2 c^2 + s^2 \\sigma^2) \\;=\\; 0\n$$\n$$\n\\alpha s^2 c^2 + \\alpha^2 c^2 - \\alpha^2 c^2 - s^2 \\sigma^2 \\;=\\; 0\n$$\n$$\n\\alpha s^2 c^2 - s^2 \\sigma^2 \\;=\\; 0\n$$\n由于 $s > 0$，我们可以除以 $s^2$：\n$$\n\\alpha c^2 = \\sigma^2\n$$\n解出 $\\alpha$，我们得到：\n$$\n\\alpha^{\\star} \\;=\\; \\frac{\\sigma^2}{c^2}\n$$\n代入 $c^2=a^2$，最优正则化参数为：\n$$\n\\alpha^{\\star} \\;=\\; \\frac{\\sigma^2}{a^2}\n$$\n二阶导数检验可以确认这是一个最小值。一阶导数的符号在该点附近由负变正，确认其为最小值。", "answer": "$$\\boxed{\\frac{\\sigma^2}{a^2}}$$", "id": "3368363"}, {"introduction": "偏差-方差权衡不仅存在于静态逆问题中，它同样是动态系统（如时间序列分析和数据同化）中的一个核心概念。本练习将背景设定在一个简单的线性状态空间模型中，其中正则化是通过动态模型先验来施加的。通过推导最大后验（MAP）估计的均方误差，你将量化我们对模型的信任度（由过程噪声方差 $Q$ 代表）与对新观测的信任度（由观测噪声方差 $R$ 代表）之间的平衡关系，并理解这种平衡如何直接导致状态估计中的偏差-方差权衡。[@problem_id:3368359]", "problem": "考虑一个在两步窗口 $t \\in \\{0,1\\}$ 上的标量线性状态空间模型，其动态方程为 $x_{1}=\\rho x_{0}+w_{0}$，观测方程为 $y_{t}=x_{t}+\\varepsilon_{t}$。假设 $w_{0}$ 来自一个均值为零、方差为 $Q$ 的高斯分布，$\\varepsilon_{t}$ 是均值为零、方差为 $R$ 的独立高斯随机变量，且所有这些变量相互独立。设 $x_{0}$ 的先验为非正常平坦先验，这可以理解为一个方差趋于无穷大的高斯先验的极限。在这些假设下，定义 $(x_{0},x_{1})$ 的最大后验 (MAP) 估计量。然后，将真实状态 $x_{0}$ 和 $x_{1}$ 视为固定的（未知）常数，并仅对测量噪声 $\\varepsilon_{0}$ 和 $\\varepsilon_{1}$ 求平均，推导出 $x_{1}$ 的 MAP 估计量的偏差、$x_{1}$ 的 MAP 估计量的方差，并将它们结合起来，得到在时间 $t=1$ 时的均方误差，定义为 $\\mathbb{E}\\big[(\\hat{x}_{1}-x_{1})^{2}\\big]$。该均方误差应表示为 $Q$、$R$、$\\rho$、$x_{0}$ 和 $x_{1}$ 的显式解析函数。请以单个精确的闭式解析表达式的形式给出均方误差的最终答案。不需要单位。如果进行任何数值简化，请勿四舍五入。", "solution": "该模型是线性高斯模型。由于 $x_{0}$ 的先验为非正常平坦先验且噪声为独立高斯噪声，$(x_{0},x_{1})$ 的后验密度与三个高斯似然的乘积成正比：给定 $x_{0}$ 的 $y_{0}$ 的似然，给定 $x_{1}$ 的 $y_{1}$ 的似然，以及给定 $x_{0}$ 的 $x_{1}$ 的似然。因此，负对数后验（不考虑加性常数）是加权残差平方和\n$$\nJ(x_{0},x_{1}) \\;=\\; \\frac{1}{R}\\,(y_{0}-x_{0})^{2} \\;+\\; \\frac{1}{R}\\,(y_{1}-x_{1})^{2} \\;+\\; \\frac{1}{Q}\\,(x_{1}-\\rho x_{0})^{2}.\n$$\n最大后验 (MAP) 估计 $(\\hat{x}_{0},\\hat{x}_{1})$ 最小化 $J(x_{0},x_{1})$。这是一个严格凸的二次函数，因此可以通过将其梯度设为零来求得其最小值点：\n$$\n\\frac{\\partial J}{\\partial x_{0}} \\;=\\; -\\frac{2}{R}(y_{0}-x_{0}) \\;-\\; \\frac{2\\rho}{Q}(x_{1}-\\rho x_{0}) \\;=\\; 0,\n$$\n$$\n\\frac{\\partial J}{\\partial x_{1}} \\;=\\; -\\frac{2}{R}(y_{1}-x_{1}) \\;+\\; \\frac{2}{Q}(x_{1}-\\rho x_{0}) \\;=\\; 0.\n$$\n重新整理这两个方程，得到一个关于 $(x_{0},x_{1})$ 的线性系统。定义 $A=\\frac{1}{R}$ 和 $B=\\frac{1}{Q}$ 以简化符号。那么正规方程可以写成\n$$\n\\begin{pmatrix}\nA + \\rho^{2}B & -\\rho B \\\\\n-\\rho B & A + B\n\\end{pmatrix}\n\\begin{pmatrix}\nx_{0} \\\\\nx_{1}\n\\end{pmatrix}\n=\n\\begin{pmatrix}\nA y_{0} \\\\\nA y_{1}\n\\end{pmatrix}.\n$$\n设 $M$ 为上述 $2\\times 2$ 矩阵，$b$ 为右侧向量。$M$ 的行列式为\n$$\n\\det(M) \\;=\\; (A + \\rho^{2}B)(A + B) - (\\rho B)^{2} \\;=\\; A^{2} + A B (1 + \\rho^{2}) \\;=\\; A\\big(A + B(1+\\rho^{2})\\big).\n$$\n$M$ 的逆矩阵为\n$$\nM^{-1} \\;=\\; \\frac{1}{\\det(M)} \\begin{pmatrix}\nA + B & \\rho B \\\\\n\\rho B & A + \\rho^{2}B\n\\end{pmatrix}.\n$$\n因此，MAP 估计为\n$$\n\\begin{pmatrix}\n\\hat{x}_{0} \\\\\n\\hat{x}_{1}\n\\end{pmatrix}\n\\;=\\;\nM^{-1} b\n\\;=\\;\n\\frac{1}{\\det(M)}\n\\begin{pmatrix}\n(A + B)A y_{0} + \\rho B A y_{1} \\\\\n\\rho B A y_{0} + (A + \\rho^{2}B) A y_{1}\n\\end{pmatrix}.\n$$\n特别地，\n$$\n\\hat{x}_{1} \\;=\\; \\alpha\\, y_{0} + \\beta\\, y_{1},\n\\quad\\text{with}\\quad\n\\alpha \\;=\\; \\frac{\\rho A B}{\\det(M)}, \\qquad \\beta \\;=\\; \\frac{A\\left(A + \\rho^{2}B\\right)}{\\det(M)}.\n$$\n我们现在通过将真实状态 $x_{0}$ 和 $x_{1}$ 视为固定常数，并对独立的测量噪声 $\\varepsilon_{0}$ 和 $\\varepsilon_{1}$ 进行平均，来量化 $\\hat{x}_{1}$ 的偏差-方差权衡。根据定义，\n$$\ny_{0} \\;=\\; x_{0} + \\varepsilon_{0}, \\qquad y_{1} \\;=\\; x_{1} + \\varepsilon_{1}, \\qquad \\mathbb{E}[\\varepsilon_{t}] \\;=\\; 0, \\qquad \\operatorname{Var}(\\varepsilon_{t}) \\;=\\; R, \\qquad \\operatorname{Cov}(\\varepsilon_{0},\\varepsilon_{1}) \\;=\\; 0.\n$$\n偏差是\n$$\n\\operatorname{Bias}(\\hat{x}_{1}) \\;=\\; \\mathbb{E}[\\hat{x}_{1}] - x_{1}\n\\;=\\; \\alpha\\, x_{0} + \\beta\\, x_{1} - x_{1}\n\\;=\\; \\alpha\\, x_{0} + (\\beta - 1)\\, x_{1}.\n$$\n使用 $\\det(M)=A^{2}+A B(1+\\rho^{2})$ 以及 $\\alpha$ 和 $\\beta$ 的公式，\n$$\n\\beta - 1 \\;=\\; \\frac{A(A+\\rho^{2}B)}{\\det(M)} - 1 \\;=\\; \\frac{A(A+\\rho^{2}B) - \\det(M)}{\\det(M)} \\;=\\; \\frac{-A B}{\\det(M)}.\n$$\n因此，\n$$\n\\operatorname{Bias}(\\hat{x}_{1}) \\;=\\; \\frac{\\rho A B}{\\det(M)}\\, x_{0} \\;-\\; \\frac{A B}{\\det(M)}\\, x_{1}\n\\;=\\; \\frac{A B}{\\det(M)}\\,\\big(\\rho x_{0} - x_{1}\\big).\n$$\n将 $A=\\frac{1}{R}$，$B=\\frac{1}{Q}$ 和 $\\det(M)=\\frac{1}{R}\\Big(\\frac{1}{R}+\\frac{1+\\rho^{2}}{Q}\\Big)$ 代回，偏差简化为\n$$\n\\operatorname{Bias}(\\hat{x}_{1}) \\;=\\; \\frac{\\frac{1}{R}\\cdot \\frac{1}{Q}}{\\frac{1}{R}\\left(\\frac{1}{R}+\\frac{1+\\rho^{2}}{Q}\\right)}\\,\\big(\\rho x_{0}-x_{1}\\big)\n\\;=\\; \\frac{\\frac{1}{Q}}{\\frac{1}{R}+\\frac{1+\\rho^{2}}{Q}}\\,\\big(\\rho x_{0}-x_{1}\\big)\n\\;=\\; \\frac{R}{Q + R(1+\\rho^{2})}\\,\\big(\\rho x_{0}-x_{1}\\big).\n$$\n接下来，$\\hat{x}_{1}$ 的方差是\n$$\n\\operatorname{Var}(\\hat{x}_{1}) \\;=\\; \\alpha^{2}\\operatorname{Var}(y_{0}) + \\beta^{2}\\operatorname{Var}(y_{1}) \\;=\\; R\\left(\\alpha^{2} + \\beta^{2}\\right).\n$$\n用 $A$ 和 $B$ 计算 $\\alpha^{2} + \\beta^{2}$：\n$$\n\\alpha^{2} + \\beta^{2} \\;=\\; \\frac{(\\rho A B)^{2} + \\left(A(A + \\rho^{2}B)\\right)^{2}}{\\det(M)^{2}}\n\\;=\\; \\frac{A^{2}\\left(\\rho^{2}B^{2} + (A + \\rho^{2}B)^{2}\\right)}{\\det(M)^{2}}.\n$$\n因为 $\\det(M)=A\\big(A + B(1+\\rho^{2})\\big)$，我们有 $\\det(M)^{2} = A^{2}\\big(A + B(1+\\rho^{2})\\big)^{2}$。因此\n$$\n\\operatorname{Var}(\\hat{x}_{1}) \\;=\\; R\\,\\frac{\\rho^{2}B^{2} + \\left(A + \\rho^{2}B\\right)^{2}}{\\left(A + B(1+\\rho^{2})\\right)^{2}}.\n$$\n代入 $A=\\frac{1}{R}$ 和 $B=\\frac{1}{Q}$ 得到\n$$\n\\operatorname{Var}(\\hat{x}_{1}) \\;=\\; R\\,\\frac{\\frac{\\rho^{2}}{Q^{2}} + \\left(\\frac{1}{R} + \\frac{\\rho^{2}}{Q}\\right)^{2}}{\\left(\\frac{1}{R} + \\frac{1+\\rho^{2}}{Q}\\right)^{2}}.\n$$\n为了代数表达的清晰，将分子和分母同乘以 $R^{2}Q^{2}$ 以获得等价的简化有理式形式：\n$$\n\\operatorname{Var}(\\hat{x}_{1}) = R \\frac{Q^2 + 2\\rho^2 R Q + \\rho^2(1+\\rho^2) R^2}{(Q + R(1+\\rho^2))^2}\n$$\n最后，均方误差为\n$$\n\\operatorname{MSE}(\\hat{x}_{1}) \\;=\\; \\big(\\operatorname{Bias}(\\hat{x}_{1})\\big)^{2} + \\operatorname{Var}(\\hat{x}_{1}),\n$$\n这就得到了\n$$\n\\operatorname{MSE}(\\hat{x}_{1}) \\;=\\; \\left(\\frac{R}{Q + R(1+\\rho^{2})}\\right)^{2}\\big(\\rho x_{0} - x_{1}\\big)^{2} \\;+\\; R \\frac{Q^2 + 2\\rho^2 R Q + \\rho^2(1+\\rho^2) R^2}{(Q + R(1+\\rho^2))^2}.\n$$\n这个表达式明确地量化了作为 $Q$ 和 $R$ 函数的偏差-方差权衡：当 $Q$ 减小（更强的动态正则化）时，如果真实状态偏离精确的动态关系（$\\rho x_{0} \\neq x_{1}$），偏差项会增大，而方差项会减小；反之，当 $Q$ 增大（较弱的正则化）时，偏差项会缩小，而方差项会向 $R$ 增加。", "answer": "$$\\boxed{\\left(\\frac{R}{Q + R(1+\\rho^{2})}\\right)^{2}\\left(\\rho x_{0} - x_{1}\\right)^{2} \\;+\\; R \\frac{Q^2 + 2\\rho^2 R Q + \\rho^2(1+\\rho^2) R^2}{(Q + R(1+\\rho^2))^2}}$$", "id": "3368359"}, {"introduction": "除了经典的惩罚项方法，施加硬性约束是另一种重要且普遍的正则化形式，尤其是在解必须满足物理现实（如非负性）时。这个练习探讨了这种基于约束的正则化所带来的影响。在一个看似简单的恒等映射问题中，你将分析一个非负约束如何产生一个非线性估计器，并推导其均方误差，从而揭示这种约束如何在可行域的边界附近引入独特的偏差-方差权衡。[@problem_id:3368339]", "problem": "考虑$\\mathbb{R}^{2}$中的线性逆问题，其观测模型为 $y = A x^{\\star} + \\varepsilon$，其中 $A = I_{2}$ 是单位矩阵，$x^{\\star} \\in \\mathbb{R}^{2}$ 满足分量不等式约束 $x^{\\star} \\ge 0$，且噪声 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{2})$ 是方差为 $\\sigma^{2} > 0$ 的高斯噪声。估计量 $\\hat{x}$ 定义为约束最小二乘问题 $\\min_{x \\ge 0} \\frac{1}{2}\\|y - x\\|_{2}^{2}$ 的解。仅从闭凸集上的正交投影和高斯概率密度函数的定义出发，完成以下任务：\n\n1. 推导在给定 $x^{\\star}$ 时估计量 $\\hat{x}$ 的分量分布，并用标准正态密度函数 $\\phi$ 和累积分布函数 $\\Phi$ 精确表示。特别地，对于每个分量 $i \\in \\{1,2\\}$，确定在 $0$ 处的点质量和在 $(0, \\infty)$ 上的密度。\n\n2. 对于真实值为 $X \\ge 0$ 的单个分量，推导均方误差 $\\mathrm{MSE}(X) = \\mathbb{E}\\big[(\\hat{x}_{i} - X)^{2} \\,\\big|\\, x_{i}^{\\star} = X\\big]$ 的闭式表达式，用 $X$、$\\sigma$、$\\phi$ 和 $\\Phi$ 表示。\n\n3. 将问题特化到 $x^{\\star} = (0, \\mu)$ 的双参数情况，其中 $\\mu \\ge 0$。利用噪声分量的独立性以及第2部分的结果，计算总均方误差 $\\mathbb{E}\\big[\\|\\hat{x} - x^{\\star}\\|_{2}^{2}\\big]$，并将其表示为关于 $\\mu$、$\\sigma$、$\\phi$ 和 $\\Phi$ 的单个闭式解析表达式。该表达式量化了非负约束下边界 $x_{1}^{\\star} = 0$ 附近的偏差-方差权衡。\n\n你的最终答案必须是第3部分中总均方误差的闭式表达式，表示为关于 $\\mu$、$\\sigma$、$\\phi$ 和 $\\Phi$ 的单个解析公式。不需要进行数值计算，也不涉及单位。确保每个数学实体都用 LaTeX 书写。", "solution": "该问题是有效的，因为它具有科学依据、提法恰当且客观。它提出了一个关于约束最小二乘的统计估计理论中的标准问题。我将继续进行解答。\n\n该问题要求解一个真实参数为 $x^{\\star} \\in \\mathbb{R}^{2}$ 且其分量为非负（即 $x^{\\star} \\ge 0$）的估计量 $\\hat{x}$ 的统计特性。观测模型为 $y = x^{\\star} + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{2})$ 是一个由两个独立同分布的高斯随机变量组成的向量，其均值为 $0$，方差为 $\\sigma^2$。估计量 $\\hat{x}$ 是约束最小二乘问题的解：\n$$\n\\hat{x} = \\arg\\min_{x \\ge 0} \\frac{1}{2}\\|y - x\\|_{2}^{2}\n$$\n约束 $x \\ge 0$ 意味着对于每个分量 $i \\in \\{1, 2\\}$ 都有 $x_i \\ge 0$。目标函数是可分的：\n$$\n\\frac{1}{2}\\|y - x\\|_{2}^{2} = \\frac{1}{2}\\sum_{i=1}^{2} (y_i - x_i)^2\n$$\n因此，可以对每个分量独立地进行最小化：\n$$\n\\hat{x}_i = \\arg\\min_{x_i \\ge 0} \\frac{1}{2}(y_i - x_i)^2\n$$\n这就是求标量 $y_i$ 在闭凸集 $[0, \\infty)$ 上的正交投影的问题。解决方案是将 $y_i$ 在 $0$ 处进行截断：\n- 如果 $y_i \\ge 0$，则在 $x_i = y_i$ 处达到最小值。\n- 如果 $y_i < 0$，则在边界点 $x_i = 0$ 处达到最小值。\n这可以紧凑地表示为 $\\hat{x}_i = \\max(0, y_i)$。\n\n### 第1部分：估计量的分量分布\n\n我们需要求出给定真实值 $x_i^{\\star}$ 时 $\\hat{x}_i$ 的分布。第 $i$ 个分量的观测值为 $y_i = x_i^{\\star} + \\varepsilon_i$，其中 $\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$。因此，$y_i$ 本身是一个随机变量，其分布为 $y_i \\sim \\mathcal{N}(x_i^{\\star}, \\sigma^2)$。估计量为 $\\hat{x}_i = \\max(0, y_i)$。\n\n$\\hat{x}_i$ 的分布是一个混合分布。它在 $0$ 处有一个离散部分（一个点质量），在 $(0, \\infty)$ 上有一个连续部分。\n\n1.  **在 0 处的点质量**：事件 $\\hat{x}_i = 0$ 发生当且仅当 $y_i \\le 0$。该事件的概率是：\n    $$\n    P(\\hat{x}_i = 0) = P(y_i \\le 0)\n    $$\n    令 $Z = (y_i - x_i^{\\star})/\\sigma$ 为标准化变量，则 $Z \\sim \\mathcal{N}(0, 1)$。\n    $$\n    P(y_i \\le 0) = P(x_i^{\\star} + \\sigma Z \\le 0) = P\\left(Z \\le -\\frac{x_i^{\\star}}{\\sigma}\\right)\n    $$\n    用标准正态累积分布函数 (CDF) $\\Phi(z)$ 表示，该概率为：\n    $$\n    P(\\hat{x}_i = 0) = \\Phi\\left(-\\frac{x_i^{\\star}}{\\sigma}\\right)\n    $$\n\n2.  **在 $(0, \\infty)$ 上的密度**：对于任何值 $v > 0$，事件 $\\hat{x}_i = v$ 发生当且仅当 $y_i = v$。对于 $v > 0$，$\\hat{x}_i$ 的密度（记为 $f_{\\hat{x}_i}(v)$）与 $y_i$ 在此域上的密度相同。$y_i \\sim \\mathcal{N}(x_i^{\\star}, \\sigma^2)$ 的概率密度函数 (PDF) 是 $\\frac{1}{\\sqrt{2\\pi}\\sigma} \\exp\\left(-\\frac{(y_i - x_i^{\\star})^2}{2\\sigma^2}\\right)$。使用标准正态 PDF $\\phi(z) = \\frac{1}{\\sqrt{2\\pi}} \\exp(-z^2/2)$，$y_i$ 的密度是 $\\frac{1}{\\sigma}\\phi\\left(\\frac{y_i - x_i^{\\star}}{\\sigma}\\right)$。\n    因此，对于 $v > 0$，$\\hat{x}_i$ 的密度为：\n    $$\n    f_{\\hat{x}_i}(v) = \\frac{1}{\\sigma}\\phi\\left(\\frac{v - x_i^{\\star}}{\\sigma}\\right)\n    $$\n    这是正态分布 $\\mathcal{N}(x_i^{\\star}, \\sigma^2)$ 在域 $(0, \\infty)$ 上的截断密度。\n\n### 第2部分：单个分量的均方误差\n\n我们想要推导给定 $x_i^{\\star} = X \\ge 0$ 时单个分量 $i$ 的均方误差 (MSE) 的闭式表达式：\n$$\n\\mathrm{MSE}(X) = \\mathbb{E}\\left[(\\hat{x}_i - X)^2 \\mid x_i^{\\star} = X\\right]\n$$\n期望是针对第1部分中推导出的 $\\hat{x}_i$ 的分布计算的。我们可以将期望分解为分布的两个部分：\n$$\n\\mathrm{MSE}(X) = (0 - X)^2 P(\\hat{x}_i = 0) + \\int_{0}^{\\infty} (v - X)^2 f_{\\hat{x}_i}(v) dv\n$$\n代入第1部分中 $x_i^{\\star} = X$ 的表达式：\n$$\n\\mathrm{MSE}(X) = X^2 \\Phi\\left(-\\frac{X}{\\sigma}\\right) + \\int_{0}^{\\infty} (v - X)^2 \\frac{1}{\\sigma}\\phi\\left(\\frac{v - X}{\\sigma}\\right) dv\n$$\n为了计算该积分，我们进行变量替换。令 $z = (v - X)/\\sigma$。则 $v = \\sigma z + X$ 且 $dv = \\sigma dz$。积分限相应改变：当 $v=0$ 时，$z=-X/\\sigma$；当 $v \\to \\infty$ 时，$z \\to \\infty$。积分变为：\n$$\n\\int_{-X/\\sigma}^{\\infty} (\\sigma z)^2 \\frac{1}{\\sigma}\\phi(z) (\\sigma dz) = \\sigma^2 \\int_{-X/\\sigma}^{\\infty} z^2 \\phi(z) dz\n$$\n我们使用分部积分法计算 $\\int z^2 \\phi(z) dz$，令 $u=z$ 和 $dv = z\\phi(z)dz$。由于 $\\phi'(z) = -z\\phi(z)$，我们有 $du = dz$ 和 $v = -\\phi(z)$。\n$$\n\\int z^2 \\phi(z) dz = -z\\phi(z) - \\int (-\\phi(z)) dz = -z\\phi(z) + \\Phi(z) + C\n$$\n应用积分限：\n$$\n\\int_{-X/\\sigma}^{\\infty} z^2 \\phi(z) dz = \\left[-z\\phi(z) + \\Phi(z)\\right]_{-X/\\sigma}^{\\infty}\n$$\n当 $z \\to \\infty$ 时，$z\\phi(z) \\to 0$ 且 $\\Phi(z) \\to 1$。所以上限处的值为 $1$。\n$$\n\\lim_{z\\to\\infty}(-z\\phi(z) + \\Phi(z)) = 0 + 1 = 1\n$$\n在下限 $z = -X/\\sigma$ 处：\n$$\n-\\left(-\\frac{X}{\\sigma}\\right)\\phi\\left(-\\frac{X}{\\sigma}\\right) + \\Phi\\left(-\\frac{X}{\\sigma}\\right) = \\frac{X}{\\sigma}\\phi\\left(\\frac{X}{\\sigma}\\right) + \\Phi\\left(-\\frac{X}{\\sigma}\\right)\n$$\n这里我们使用了 PDF 的偶函数性质，$\\phi(-z) = \\phi(z)$。\n因此，定积分为：\n$$\n1 - \\left(\\frac{X}{\\sigma}\\phi\\left(\\frac{X}{\\sigma}\\right) + \\Phi\\left(-\\frac{X}{\\sigma}\\right)\\right) = \\left(1 - \\Phi\\left(-\\frac{X}{\\sigma}\\right)\\right) - \\frac{X}{\\sigma}\\phi\\left(\\frac{X}{\\sigma}\\right)\n$$\n使用恒等式 $1 - \\Phi(-c) = \\Phi(c)$，我们得到：\n$$\n\\int_{-X/\\sigma}^{\\infty} z^2 \\phi(z) dz = \\Phi\\left(\\frac{X}{\\sigma}\\right) - \\frac{X}{\\sigma}\\phi\\left(\\frac{X}{\\sigma}\\right)\n$$\n乘以 $\\sigma^2$，MSE 的积分部分为 $\\sigma^2 \\Phi(X/\\sigma) - X \\sigma \\phi(X/\\sigma)$。\n结合 MSE 的两个部分：\n$$\n\\mathrm{MSE}(X) = X^2 \\Phi\\left(-\\frac{X}{\\sigma}\\right) + \\sigma^2 \\Phi\\left(\\frac{X}{\\sigma}\\right) - X\\sigma \\phi\\left(\\frac{X}{\\sigma}\\right)\n$$\n使用恒等式 $\\Phi(-X/\\sigma) = 1 - \\Phi(X/\\sigma)$，另一种形式是：\n$$\n\\mathrm{MSE}(X) = X^2 \\left(1 - \\Phi\\left(\\frac{X}{\\sigma}\\right)\\right) + \\sigma^2 \\Phi\\left(\\frac{X}{\\sigma}\\right) - X\\sigma \\phi\\left(\\frac{X}{\\sigma}\\right)\n$$\n$$\n\\mathrm{MSE}(X) = X^2 + (\\sigma^2 - X^2) \\Phi\\left(\\frac{X}{\\sigma}\\right) - X\\sigma \\phi\\left(\\frac{X}{\\sigma}\\right)\n$$\n\n### 第3部分：$x^{\\star} = (0, \\mu)$ 的总均方误差\n\n我们被要求计算在 $x^{\\star} = (0, \\mu)$ 且 $\\mu \\ge 0$ 的特定情况下的总均方误差。总 MSE 定义为：\n$$\n\\mathbb{E}\\left[\\|\\hat{x} - x^{\\star}\\|_{2}^{2}\\right] = \\mathbb{E}\\left[(\\hat{x}_1 - x_1^{\\star})^2 + (\\hat{x}_2 - x_2^{\\star})^2\\right]\n$$\n根据期望的线性性质，这等于：\n$$\n\\mathbb{E}\\left[(\\hat{x}_1 - x_1^{\\star})^2\\right] + \\mathbb{E}\\left[(\\hat{x}_2 - x_2^{\\star})^2\\right]\n$$\n这些是分量均方误差。噪声分量 $\\varepsilon_1$ 和 $\\varepsilon_2$ 是独立的。由于估计量 $\\hat{x}_i$ 仅依赖于 $y_i = x_i^{\\star} + \\varepsilon_i$，误差 $(\\hat{x}_1 - x_1^{\\star})$ 和 $(\\hat{x}_2 - x_2^{\\star})$ 也是独立的。可以分别计算期望。\n对于 $x^{\\star} = (0, \\mu)$，我们有 $x_1^{\\star} = 0$ 和 $x_2^{\\star} = \\mu$。总 MSE 是每个分量 MSE 的和：\n$$\n\\text{Total MSE} = \\mathrm{MSE}(x_1^{\\star}) + \\mathrm{MSE}(x_2^{\\star}) = \\mathrm{MSE}(0) + \\mathrm{MSE}(\\mu)\n$$\n我们对每一项使用第2部分推导出的公式。\n对于第一个分量，$X = 0$：\n$$\n\\mathrm{MSE}(0) = 0^2 + (\\sigma^2 - 0^2)\\Phi\\left(\\frac{0}{\\sigma}\\right) - 0 \\cdot \\sigma \\phi\\left(\\frac{0}{\\sigma}\\right) = \\sigma^2 \\Phi(0)\n$$\n由于 $\\Phi(0) = 1/2$，我们有：\n$$\n\\mathrm{MSE}(0) = \\frac{\\sigma^2}{2}\n$$\n对于第二个分量，$X = \\mu$：\n$$\n\\mathrm{MSE}(\\mu) = \\mu^2 + (\\sigma^2 - \\mu^2) \\Phi\\left(\\frac{\\mu}{\\sigma}\\right) - \\mu\\sigma \\phi\\left(\\frac{\\mu}{\\sigma}\\right)\n$$\n总 MSE 是这两个表达式的和：\n$$\n\\text{Total MSE} = \\frac{\\sigma^2}{2} + \\mu^2 + (\\sigma^2 - \\mu^2) \\Phi\\left(\\frac{\\mu}{\\sigma}\\right) - \\mu\\sigma \\phi\\left(\\frac{\\mu}{\\sigma}\\right)\n$$\n这就是以 $\\mu$、$\\sigma$ 以及标准正态函数 $\\phi$ 和 $\\Phi$ 表示的总均方误差的最终闭式解析表达式。", "answer": "$$\\boxed{\\frac{\\sigma^2}{2} + \\mu^2 + \\left(\\sigma^2 - \\mu^2\\right) \\Phi\\left(\\frac{\\mu}{\\sigma}\\right) - \\mu \\sigma \\phi\\left(\\frac{\\mu}{\\sigma}\\right)}$$", "id": "3368339"}]}