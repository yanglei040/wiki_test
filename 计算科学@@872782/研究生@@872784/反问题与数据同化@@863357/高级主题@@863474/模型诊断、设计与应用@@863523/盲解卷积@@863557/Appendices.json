{"hands_on_practices": [{"introduction": "盲反卷积的核心挑战在于其固有的不适定性（ill-posedness），即单个观测数据可能对应多个解。本练习 [@problem_id:3369032] 通过一个简洁明了的实例，让您亲手验证即便施加非负性这样看似很强的约束，问题仍可能存在模糊性。更重要的是，它将引导您通过引入符合科学实际的额外凸约束（如点扩散函数的归一化和单调性）来消除歧义，从而深刻理解先验知识在确保解的唯一性方面所起的决定性作用。", "problem": "考虑有限支撑序列上的一维无噪声离散盲反卷积模型，其中观测值为 $y = x * h$，其中 $x \\in \\mathbb{R}_{\\ge 0}^{2}$ 且 $h \\in \\mathbb{R}_{\\ge 0}^{2}$，* 表示离散卷积。卷积定义为 $y_{k} = \\sum_{i} x_{i} h_{k-i}$，支撑范围外的索引值视为零。假设测量数据为 $y = [2, 5, 2]$，解释为两个长度为2的序列 $x = [x_{0}, x_{1}]$ 和 $h = [h_{0}, h_{1}]$ 的完全线性卷积。利用离散卷积是双线性和交换性的，以及非负性约束是凸的这些基本事实，完成以下任务：构造一个反事实，证明仅施加 $x \\ge 0$ 和 $h \\ge 0$ 的约束允许多个与 $y$ 一致的解。然后，对 $h$ 提出对点扩散函数（PSF）来说科学上现实的额外凸约束，例如和为一约束 $\\sum_{i} h_{i} = 1$ 和单调性约束 $h_{0} \\ge h_{1}$，并解释为什么这些约束是凸的。在这些约束下，确定能通过 $y = x * h$ 精确重现 $y$ 的唯一 $(x, h)$ 对。将你的最终答案表示为一个单行矩阵，按顺序包含 $x_{0}$、$x_{1}$、$h_{0}$、$h_{1}$。不需要四舍五入，也不涉及单位。", "solution": "该问题是有效的，因为它在盲反卷积这一成熟领域有科学依据，在添加标准约束后是适定的，并且以客观、正式的语言表达。我们可以着手求解。\n\n序列 $x = [x_{0}, x_{1}]$ 和序列 $h = [h_{0}, h_{1}]$ 的一维离散卷积由 $y = x * h$ 给出。得到的序列 $y$ 的长度为 $2+2-1 = 3$。$y$ 的分量是：\n$$y_{0} = x_{0}h_{0}$$\n$$y_{1} = x_{0}h_{1} + x_{1}h_{0}$$\n$$y_{2} = x_{1}h_{1}$$\n给定测量数据 $y = [2, 5, 2]$，我们建立以下非线性方程组：\n$$\n\\begin{cases}\nx_{0}h_{0} = 2  (1) \\\\\nx_{0}h_{1} + x_{1}h_{0} = 5  (2) \\\\\nx_{1}h_{1} = 2  (3)\n\\end{cases}\n$$\n问题最初只施加非负性约束：$x_{0}, x_{1}, h_{0}, h_{1} \\ge 0$。\n\n首先，我们构造一个反事实来证明仅这些约束不足以保证唯一解。\n从方程 $(1)$ 和 $(3)$，我们可以看到 $x_{0}h_{0} = x_{1}h_{1} = 2$。由于 $y_{0}=2$ 和 $y_{2}=2$，因此 $x_{0}, x_{1}, h_{0}, h_{1}$ 都不能为零。我们可以用 $h_{0}$ 和 $h_{1}$ 来表示 $x_{0}$ 和 $x_{1}$：\n$$x_{0} = \\frac{2}{h_{0}}$$\n$$x_{1} = \\frac{2}{h_{1}}$$\n将这些代入方程 $(2)$：\n$$\\left(\\frac{2}{h_{0}}\\right)h_{1} + \\left(\\frac{2}{h_{1}}\\right)h_{0} = 5$$\n两边乘以 $h_{0}h_{1}$（非零）得到：\n$$2h_{1}^{2} + 2h_{0}^{2} = 5h_{0}h_{1}$$\n两边除以 $h_{1}^{2}$（也非零）得到一个关于比率 $r = h_{0}/h_{1}$ 的二次方程：\n$$2\\left(\\frac{h_{0}}{h_{1}}\\right)^{2} - 5\\left(\\frac{h_{0}}{h_{1}}\\right) + 2 = 0$$\n$$2r^2 - 5r + 2 = 0$$\n对这个二次方程进行因式分解，我们得到 $(2r-1)(r-2) = 0$。两个可能的根是 $r=2$ 和 $r=1/2$。这意味着核 $h$ 有两族解。\n\n情况 A：$h_{0}/h_{1} = 2$。\n我们为 $h$ 选择一个尺度。例如，令 $h_{1}=1$。那么 $h_{0}=2$，所以 $h = [2, 1]$。\n相应的信号 $x$ 计算得出为 $x_{0} = 2/h_{0} = 2/2 = 1$ 和 $x_{1} = 2/h_{1} = 2/1 = 2$。所以 $x = [1, 2]$。\n这给出了一个解对 $(x, h) = ([1, 2], [2, 1])$。$x$ 和 $h$ 都满足非负性约束。快速验证可得 $x*h = [1, 2] * [2, 1] = [2, 1 \\cdot 1 + 2 \\cdot 2, 2] = [2, 5, 2]$。\n\n情况 B：$h_{0}/h_{1} = 1/2$。\n我们再次选择一个尺度，比如令 $h_{1}=2$。那么 $h_{0}=1$，所以 $h=[1, 2]$。\n相应的信号 $x$ 为 $x_{0} = 2/h_{0} = 2/1 = 2$ 和 $x_{1} = 2/h_{1} = 2/2 = 1$。所以 $x = [2, 1]$。\n这给出了第二个解对 $(x, h) = ([2, 1], [1, 2])$。这也满足非负性约束，并得到相同的观测值 $y$。\n\n由于我们找到了至少两个不同的解 $([1, 2], [2, 1])$ 和 $([2, 1], [1, 2])$，我们证明了在仅有非负性约束下，该问题不是唯一的。\n\n接下来，我们对模糊核 $h$ 提出额外的凸约束，$h$ 通常被解释为点扩散函数（PSF）。科学上现实的PSF通常被归一化以保持能量守恒，并且通常在其中心处达到峰值。\n1.  **和为一约束**：$\\sum_{i} h_{i} = h_{0} + h_{1} = 1$。这强制了能量守恒。\n2.  **单调性约束**：$h_{0} \\ge h_{1}$。这模拟了一个以原点为中心或从原点开始衰减的PSF。\n\n这些约束是凸的。如果集合中的任意两点之间的线段也包含在该集合内，则该约束定义了一个凸集。\n- 对于约束 $h_{0} + h_{1} = 1$，设 $h_{a}$ 和 $h_{b}$ 是满足该约束的两个向量。对于任何 $\\lambda \\in [0, 1]$，凸组合 $h_{c} = \\lambda h_{a} + (1-\\lambda)h_{b}$ 的分量之和为 $\\sum (h_{c})_i = \\lambda \\sum (h_{a})_i + (1-\\lambda) \\sum (h_{b})_i = \\lambda(1) + (1-\\lambda)(1) = 1$。满足此条件的点集是一个仿射子空间，它是凸的。\n- 对于约束 $h_{0} \\ge h_{1}$，即 $h_{0} - h_{1} \\ge 0$，设 $h_{a}$ 和 $h_{b}$ 满足该约束。凸组合 $h_{c}$ 的分量满足 $(h_{c})_{0} - (h_{c})_{1} = \\lambda((h_{a})_{0}-(h_{a})_{1}) + (1-\\lambda)((h_{b})_{0}-(h_{b})_{1})$。由于 $\\lambda \\ge 0$，$1-\\lambda \\ge 0$，$(h_{a})_{0}-(h_{a})_{1} \\ge 0$ 和 $(h_{b})_{0}-(h_{b})_{1} \\ge 0$，结果是非负的。这证实了 $(h_{c})_{0} \\ge (h_{c})_{1}$。该约束定义了一个闭半空间，它是一个凸集。\n\n这些凸集与非负象限（$h_{0} \\ge 0$, $h_{1} \\ge 0$）的交集为 $h$ 定义了一个凸可行集。现在，我们应用这些新约束来找到唯一解。\n\n我们重新审视从代数系统推导出的两种情况。\n情况 A：$h_{0} = 2h_{1}$。\n应用和为一约束：$2h_{1} + h_{1} = 1 \\implies 3h_{1} = 1 \\implies h_{1} = 1/3$。\n这得到 $h_{0} = 2/3$。候选核为 $h = [2/3, 1/3]$。\n我们来检查 $h$ 的所有约束：\n- $h_{0} = 2/3 \\ge 0$, $h_{1} = 1/3 \\ge 0$（非负性：满足）。\n- $h_{0} + h_{1} = 2/3 + 1/3 = 1$（和为一：满足）。\n- $h_{0} \\ge h_{1} \\implies 2/3 \\ge 1/3$（单调性：满足）。\n这种情况是有效的。我们找到相应的信号 $x$：\n$x_{0} = 2/h_{0} = 2/(2/3) = 3$。\n$x_{1} = 2/h_{1} = 2/(1/3) = 6$。\n信号为 $x = [3, 6]$。非负性约束 $x_{0} \\ge 0$ 和 $x_{1} \\ge 0$ 得到满足。\n因此，$(x, h) = ([3, 6], [2/3, 1/3])$ 是一个有效解。\n\n情况 B：$h_{0} = h_{1}/2$。\n应用和为一约束：$h_{1}/2 + h_{1} = 1 \\implies (3/2)h_{1} = 1 \\implies h_{1} = 2/3$。\n这得到 $h_{0} = (1/2)(2/3) = 1/3$。候选核为 $h = [1/3, 2/3]$。\n我们来检查单调性约束：$h_{0} \\ge h_{1} \\implies 1/3 \\ge 2/3$。这是错误的。\n因此，这种情况被施加的约束排除了。\n\n满足所有方程和约束的唯一解是在情况 A 中找到的解。唯一解是 $x_{0}=3$，$x_{1}=6$，$h_{0}=2/3$ 和 $h_{1}=1/3$。\n最终答案要求以单行矩阵的形式给出，按顺序包含 $x_{0}$、$x_{1}$、$h_{0}$、$h_{1}$。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n3  6  \\frac{2}{3}  \\frac{1}{3}\n\\end{pmatrix}\n}\n$$", "id": "3369032"}, {"introduction": "在前一个练习的基础上，我们现在探索一种更深刻的正则化策略：利用信号的内在结构。本练习 [@problem_id:3369057] 聚焦于信号稀疏性这一强大先验，要求您从第一性原理出发，推导出一个确保信号和模糊核可唯一辨识的精确条件，即稀疏信号非零项之间的最小间隔。通过构建反例，您将证明该条件的必要性，从而深入理解现代信号处理中结构化先验是如何从根本上克服盲反卷积问题的模糊性的。", "problem": "考虑在零填充下的离散时间、有限长度实数序列的线性卷积。令 $n \\in \\mathbb{N}$ 足够大，使得在下文的分析中可以忽略边界效应。你观察到\n$$\ny = h * x + \\eta,\n$$\n其中 $h \\in \\mathbb{R}^{n}$ 是一个具有紧支撑的未知模糊核，$x \\in \\mathbb{R}^{n}$ 是一个未知的 $k$-稀疏信号，而 $\\eta \\in \\mathbb{R}^{n}$ 是加性噪声。为进行可辨识性分析，假设数据是无噪声的，即 $\\eta = 0$。为消除平凡的尺度和移位模糊性，施加一个规范，要求对于已知的支撑大小 $s \\in \\mathbb{N}$ 且 $s \\geq 2$，满足\n$$\n\\operatorname{supp}(h) \\subseteq \\{0,1,\\dots,s-1\\} \\quad \\text{and} \\quad h[0] = 1,\n$$\n信号 $x$ 是 $k$-稀疏的，其支撑集为 $T \\subset \\{0,1,\\dots,n-1\\}$，最小间隔为\n$$\n\\Delta = \\min_{\\substack{t,t' \\in T\\\\ t \\neq t'}} |t - t'|,\n$$\n使得 $x$ 的任意两个非零项之间的索引至少相隔 $\\Delta$。\n\n仅从线性卷积的定义、支撑的概念以及上述规范出发，分析在何种情况下 $(h,x)$ 可以从 $y$ 中辨识出来，即前向映射 $(h,x) \\mapsto y$ 在该模型类上是单射的。具体来说：\n- 从第一性原理推导出阈值 $\\Delta_{\\star} = \\Delta_{\\star}(s)$，使得当 $\\Delta \\geq \\Delta_{\\star}$ 时，在所述规范下，$(h,x)$ 由 $y$ 唯一确定。\n- 通过构造一个明确的反例来证明你所给出阈值的最小性，该反例在间隔条件被违反时会破坏可辨识性。具体地，对于 $s=2, k=2, \\Delta=1$ 的情况，构造两个不同的对 $(h,x)$ 和 $(\\tilde h,\\tilde x)$，它们满足相同的规范且产生相同的 $y$，但 $(h,x) \\neq (\\tilde h,\\tilde x)$。\n\n请以关于 $s$ 的闭式解析表达式形式报告你的阈值 $\\Delta_{\\star}$。你的最终答案必须是单个解析表达式。无需四舍五入，且不涉及单位。", "solution": "问题要求找出稀疏信号 $x$ 的最小间隔 $\\Delta$ 需要满足何种条件，才能保证在滤波器 $h$ 满足特定规范的情况下，对偶 $(h,x)$ 能从其卷积 $y=h*x$ 中被唯一辨识。我们将首先推导可辨识性的一个充分条件，然后通过构造一个可辨识性失效的反例来证明其必要性（并因此证明其最小性）。\n\n设问题是针对长度为 $n$ 的离散时间序列定义的。观测信号为 $y = h * x$，其中 $*$ 表示线性卷积。序列 $h \\in \\mathbb{R}^{n}$ 和 $x \\in \\mathbb{R}^{n}$ 是未知的。\n\n对 $(h,x)$ 的约束如下：\n1.  滤波器 $h$ 的支撑大小至多为 $s$，对于一个已知的整数 $s \\geq 2$，其支撑集满足 $\\operatorname{supp}(h) \\subseteq \\{0, 1, \\dots, s-1\\}$。\n2.  对 $h$ 施加一个规范：$h[0]=1$。\n3.  信号 $x$ 是 $k$-稀疏的，意味着它恰好有 $k$ 个非零项。设其支撑集为 $T = \\{t_1, t_2, \\dots, t_k\\}$，其中 $0 \\leq t_1  t_2  \\dots  t_k \\leq n-1$。\n4.  $x$ 的非零项之间的最小间隔为 $\\Delta = \\min_{i \\neq j} |t_i - t_j|$。\n\n可辨识性意味着前向映射 $(h,x) \\mapsto y$ 在容许对的集合上是单射的。假设我们有两个不同的对 $(h,x)$ 和 $(\\tilde{h},\\tilde{x})$，它们都满足给定的约束条件，并产生相同的输出：\n$$\nh * x = \\tilde{h} * \\tilde{x}\n$$\n我们的目标是找到关于 $\\Delta$ 的条件，该条件能迫使 $(h,x) = (\\tilde{h},\\tilde{x})$。\n\n让我们分析输出 $y$ 的结构。根据卷积的定义，\n$$\ny[j] = (h * x)[j] = \\sum_{m=0}^{n-1} h[m] x[j-m]\n$$\n由于 $x$ 仅在其支撑集 $T=\\{t_1, \\dots, t_k\\}$ 上非零，我们可以将 $x$ 写成缩放的狄拉克脉冲之和：$x = \\sum_{i=1}^{k} x_i \\delta_{t_i}$，其中 $x_i = x[t_i]$。于是卷积为：\n$$\ny = h * \\left( \\sum_{i=1}^{k} x_i \\delta_{t_i} \\right) = \\sum_{i=1}^{k} x_i (h * \\delta_{t_i}) = \\sum_{i=1}^{k} x_i h(\\cdot - t_i)\n$$\n这表明 $y$ 是滤波器 $h$ 的 $k$ 个副本的线性组合，每个副本都由相应的位置 $t_i \\in T$ 进行移位，并由振幅 $x_i$ 进行缩放。\n\n第 $i$ 个移位副本 $h(\\cdot - t_i)$ 的支撑集是 $\\{t_i, t_i+1, \\dots, t_i+s-1\\}$，这是一个长度为 $s$ 的区间。$y$ 的支撑集是这些区间的并集：$\\operatorname{supp}(y) \\subseteq \\bigcup_{i=1}^k [t_i, t_i+s-1]$。\n\n现在，我们对最小间隔 $\\Delta$ 施加一个条件。假设 $\\Delta \\geq s$。第 $i$ 个副本支撑的起始点与第 $(i+1)$ 个副本支撑的起始点之间的间隔是 $t_{i+1} - t_i \\geq \\Delta$。如果 $\\Delta \\geq s$，那么 $t_{i+1} - t_i \\geq s$。第 $i$ 个副本的支撑在 $t_i+s-1$ 处结束。第 $(i+1)$ 个副本的支撑从 $t_{i+1}$ 开始。条件 $t_{i+1} \\geq t_i+s$ 意味着 $t_{i+1}  t_i+s-1$。这意味着对于所有的 $i$，支撑区间 $[t_i, t_i+s-1]$ 和 $[t_{i+1}, t_{i+1}+s-1]$ 是不相交的。\n\n在 $\\Delta \\geq s$ 的条件下，输出 $y$ 是一系列 $k$ 个不相交的块。对于第一个块中的任何索引 $j \\in [t_1, t_1+s-1]$，对 $y[j]$ 的和的唯一非零贡献来自第一项，即 $i=1$：\n$$\ny[j] = x_1 h[j-t_1] \\quad \\text{for } j \\in \\{t_1, t_1+1, \\dots, t_1+s-1\\}\n$$\n对于 $i  1$，所有其他项 $x_i h[j-t_i]$ 均为零，因为 $j-t_i  (t_1+s)-t_i \\leq (t_1+s)-t_2 \\leq (t_1+s)-(t_1+s) = 0$，所以 $j-t_i$ 在 $h$ 的支撑集之外。\n\n现在，考虑方程 $h*x = \\tilde{h} * \\tilde{x}$。设 $T=\\{t_i\\}$ 和 $\\tilde{T}=\\{\\tilde{t}_i\\}$ 分别是 $x$ 和 $\\tilde{x}$ 的支撑集。假设两者都满足间隔条件 $\\Delta \\geq s$。$y=h*x$ 的支撑是区间的不交并 $\\bigcup_{i=1}^k [t_i, t_i+s-1]$。类似地，$y=\\tilde{h}*\\tilde{x}$ 的支撑是不交并 $\\bigcup_{i=1}^k [\\tilde{t}_i, \\tilde{t}_i+s-1]$。要使这两个支撑集相等，区间的集合必须完全相同。这意味着对所有 $i=1, \\dots, k$，都有 $t_i = \\tilde{t}_i$。因此，脉冲的位置是可辨识的，即 $T = \\tilde{T}$。\n\n现在，让我们来检验数值。在第一个区间 $[t_1, t_1+s-1]$ 上：\n$$\ny[j] = x_1 h[j-t_1] \\quad \\text{and} \\quad y[j] = \\tilde{x}_1 \\tilde{h}[j-t_1]\n$$\n在第一个点 $j=t_1$ 处，我们有：\n$$\ny[t_1] = x_1 h[0] \\quad \\text{and} \\quad y[t_1] = \\tilde{x}_1 \\tilde{h}[0]\n$$\n使用规范 $h[0]=1$ 和 $\\tilde{h}[0]=1$，我们得到 $y[t_1] = x_1$ 和 $y[t_1] = \\tilde{x}_1$。这意味着 $x_1 = \\tilde{x}_1$。由于 $x_1$ 必须非零，我们可以用它来除。对于任何 $j \\in [t_1, t_1+s-1]$，我们有 $x_1 h[j-t_1] = x_1 \\tilde{h}[j-t_1]$，这意味着 $h[j-t_1] = \\tilde{h}[j-t_1]$。令 $l=j-t_1$，这意味着对于所有 $l \\in \\{0, 1, \\dots, s-1\\}$，都有 $h[l] = \\tilde{h}[l]$。这证明了 $h=\\tilde{h}$。\n\n确立了 $h=\\tilde{h}$ 和 $T=\\tilde{T}$ 之后，原始方程变为 $h*x = h*\\tilde{x}$，即 $h*(x-\\tilde{x})=0$。在Z变换域中，这表示为 $H(z) (X(z) - \\tilde{X}(z)) = 0$。$h$ 的Z变换是 $H(z) = \\sum_{l=0}^{s-1} h[l]z^{-l}$，这是一个关于 $z^{-1}$ 的多项式。由于 $h[0]=1$，$H(z)$ 不是零多项式。多项式环是一个整环，所以如果一个乘积为零，则必有一个因子为零。因此，$X(z) - \\tilde{X}(z) = 0$，这意味着 $X(z) = \\tilde{X}(z)$，从而 $x = \\tilde{x}$。\n\n因此，如果 $\\Delta \\geq s$，对偶 $(h,x)$ 是唯一可辨识的。这确立了 $\\Delta \\geq s$ 是一个充分条件。\n\n接下来，我们必须证明这个阈值是最小的。我们需要证明如果 $\\Delta  s$，可辨识性可能会失效。只需构造一个反例即可。我们选择 $\\Delta = s-1$。问题特别要求为 $s=2, k=2, \\Delta=1$ 的情况构造一个反例。这里，$\\Delta = 1 = 2-1 = s-1$，这违反了充分条件 $\\Delta \\geq s$。\n\n设 $(h,x)$ 和 $(\\tilde{h},\\tilde{x})$ 是两个不同的对偶。对于 $s=2$，滤波器 $h$ 的支撑在 $\\{0,1\\}$ 内。规范给出 $h=[1, h_1]$。对于 $k=2, \\Delta=1$，信号 $x$ 有两个相邻的非零项。不失一般性，设支撑集为 $T=\\{0,1\\}$。所以 $x$ 有非零项 $x_0 = x[0]$ 和 $x_1 = x[1]$。\n\n我们要求 $h*x = \\tilde{h}*\\tilde{x}$。让我们在多项式域中分析这个问题（对于有限信号，这等价于Z变换）。令 $H(z) = 1 + h_1 z^{-1}$ 和 $X(z) = x_0 + x_1 z^{-1}$。输出为 $Y(z) = H(z)X(z) = (1+h_1 z^{-1})(x_0+x_1 z^{-1})$。\n\n我们寻找一个不同的因式分解 $Y(z) = \\tilde{H}(z)\\tilde{X}(z)$，其中 $\\tilde{H}(z)$ 和 $\\tilde{X}(z)$ 对应一个有效的对偶 $(\\tilde{h},\\tilde{x})$。$Y(z) = x_0 + (x_1+h_1 x_0) z^{-1} + h_1 x_1 z^{-2}$。多项式乘积中一个已知的模糊性是交换因子。我们可以将 $X(z)$ 写为 $x_0(1 + \\frac{x_1}{x_0} z^{-1})$。那么 $Y(z) = x_0 (1+h_1 z^{-1})(1+\\frac{x_1}{x_0} z^{-1})$。让我们通过交换多项式因子来定义一个新的对偶：\n$$\n\\tilde{H}(z) = 1 + \\frac{x_1}{x_0} z^{-1}\n$$\n$$\n\\tilde{X}(z) = x_0(1 + h_1 z^{-1}) = x_0 + x_0 h_1 z^{-1}\n$$\n根据构造，$\\tilde{H}(z)\\tilde{X}(z) = Y(z)$。现在我们检查 $(\\tilde{h},\\tilde{x})$ 是否是一个有效且不同的对偶。\n\n从 $\\tilde{H}(z)$，我们得到 $\\tilde{h} = [1, x_1/x_0]$。这满足规范 $\\tilde{h}[0]=1$ 且 $\\operatorname{supp}(\\tilde{h}) \\subseteq \\{0,1\\}$，对于 $s=2$ 是有效的。\n从 $\\tilde{X}(z)$，我们得到 $\\tilde{x}$，其在位置 $\\{0,1\\}$ 处的非零项为 $\\tilde{x}_0 = x_0$ 和 $\\tilde{x}_1 = x_0 h_1$。这是一个间隔为 $\\Delta=1$ 的 $2$-稀疏信号，对于 $k=2, \\Delta=1$ 是有效的。\n\n如果 $h \\neq \\tilde{h}$ 或 $x \\neq \\tilde{x}$，则对偶 $(\\tilde{h},\\tilde{x})$ 与 $(h,x)$ 是不同的。\n$h = \\tilde{h} \\implies [1, h_1] = [1, x_1/x_0] \\implies h_1 = x_1/x_0$。\n$x = \\tilde{x} \\implies$ 项 $(x_0, x_1)$ 等于 $(\\tilde{x}_0, \\tilde{x}_1) = (x_0, x_0 h_1) \\implies x_1 = x_0 h_1$。\n如果我们选择 $h_1 \\neq x_1/x_0$，这对偶将会是不同的。\n\n让我们构造一个数值例子。\n设 $h=[1, 2]$，所以 $h_1=2$。这是一个对于 $s=2$ 有效的滤波器。\n设 $x$ 的支撑集在 $\\{0,1\\}$，其值为 $x_0=3$ 和 $x_1=3$。所以 $(h,x) = ([1,2], [3,3,0,\\dots])$。这里 $k=2, \\Delta=1$。并且 $h_1 = 2 \\neq x_1/x_0 = 3/3 = 1$。这对偶将会是不同的。\n\n原始对偶：$(h,x)$\n- $h = [1, 2]$\n- $x$ 的项为 $(x_0, x_1) = (3, 3)$\n卷积 $y=h*x$ 得到 $[1,2]*[3,3] = [3, 3+6, 6] = [3, 9, 6]$。\n\n构造的对偶：$(\\tilde{h},\\tilde{x})$\n- $\\tilde{h} = [1, x_1/x_0] = [1, 3/3] = [1, 1]$\n- $\\tilde{x}$ 的项为 $(\\tilde{x}_0, \\tilde{x}_1) = (x_0, x_0 h_1) = (3, 3 \\cdot 2) = (3, 6)$\n这个对偶是有效的：$\\tilde{h}[0]=1$，$\\operatorname{supp}(\\tilde{h}) \\subseteq \\{0,1\\}$；$\\tilde{x}$ 是 $2$-稀疏的，且 $\\Delta=1$。\n对偶 $([1,2], [3,3,\\dots])$ 明显不同于 $([1,1], [3,6,\\dots])$。\n卷积 $\\tilde{y}=\\tilde{h}*\\tilde{x}$ 得到 $[1,1]*[3,6] = [3, 6+3, 6] = [3, 9, 6]$。\n\n由于 $y=\\tilde{y}$，我们找到了两个满足问题约束但产生相同输出的不同对偶。这证明了当 $\\Delta = 1$ 和 $s=2$ 时存在不可辨识性。这个逻辑可以推广，表明对于任何 $s \\geq 2$，如果 $\\Delta \\leq s-1$，都可以构造类似的多项式因子交换模糊性。\n\n因此，条件 $\\Delta \\geq s$ 是充分且必要的。保证可辨识性的最小阈值 $\\Delta_\\star$（使得 $\\Delta \\geq \\Delta_\\star$）是 $\\Delta_\\star = s$。", "answer": "$$\\boxed{s}$$", "id": "3369057"}, {"introduction": "理解了问题的可解性条件后，下一步是设计能够从含噪数据中恢复信号和模糊核的实用算法。本练习 [@problem_id:3369047] 将带您深入探索一种强大的贝叶斯推断技术——变分贝叶斯（Variational Bayes）。您将为盲反卷积模型推导平均场近似下的坐标上升更新方程，亲身体验如何将一个完整的概率模型（似然与先验）转化为一套具体的、可迭代的计算方案。", "problem": "考虑一个一维离散盲反卷积模型，其中信号 $x \\in \\mathbb{R}^{n}$ 和模糊核 $k \\in \\mathbb{R}^{m}$ 未知。设观测值 $y \\in \\mathbb{R}^{n}$ 由 $x$ 和 $k$ 在加性高斯噪声下的线性卷积生成，如下所示：\n$$\ny = k * x + \\varepsilon,\n$$\n其中 $*$ 表示零填充至长度为 $n$ 的线性卷积，且 $\\varepsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{n})$，噪声方差 $\\sigma^{2}  0$ 已知。为 $x$ 和 $k$ 设置独立的高斯先验：\n$$\nx \\sim \\mathcal{N}(0, \\alpha_{x}^{-1} I_{n}), \\quad k \\sim \\mathcal{N}(0, \\alpha_{k}^{-1} I_{m}),\n$$\n其中 $\\alpha_{x}  0$ 和 $\\alpha_{k}  0$ 是已知的先验精度。令 $K(k) \\in \\mathbb{R}^{n \\times n}$ 为托普利茨（或根据所选边界条件为循环）卷积矩阵，使得 $K(k) x = k * x$；并令 $X(x) \\in \\mathbb{R}^{n \\times m}$ 为卷积设计矩阵，使得 $X(x) k = k * x$。$K(k)$ 和 $X(x)$ 均对其参数呈线性关系。定义线性算子基 $\\{B_{j}\\}_{j=1}^{m}$ 和 $\\{A_{i}\\}_{i=1}^{n}$，使得\n$$\nK(k) = \\sum_{j=1}^{m} k_{j} B_{j}, \\quad X(x) = \\sum_{i=1}^{n} x_{i} A_{i},\n$$\n其中 $B_{j} \\in \\mathbb{R}^{n \\times n}$ 将 $x$ 映射到与单位核 $e_{j} \\in \\mathbb{R}^{m}$ 的卷积 $e_{j} * x$，而 $A_{i} \\in \\mathbb{R}^{n \\times m}$ 将 $k$ 映射到与单位信号 $e_{i} \\in \\mathbb{R}^{n}$ 的卷积 $k * e_{i}$。\n\n使用变分贝叶斯 (VB)，具体地，使用平均场近似 $q(x) q(k)$ 来逼近后验分布 $p(x, k \\mid y)$，并提出高斯因子\n$$\nq(x) = \\mathcal{N}(m_{x}, S_{x}), \\quad q(k) = \\mathcal{N}(m_{k}, S_{k}),\n$$\n并以闭式解的形式推导均值向量 $m_{x} \\in \\mathbb{R}^{n}$、$m_{k} \\in \\mathbb{R}^{m}$ 和协方差矩阵 $S_{x} \\in \\mathbb{R}^{n \\times n}$、$S_{k} \\in \\mathbb{R}^{m \\times m}$ 的坐标上升更新式，用 $y$、$\\sigma^{2}$、$\\alpha_{x}$、$\\alpha_{k}$ 以及算子基 $\\{B_{j}\\}$ 和 $\\{A_{i}\\}$ 来表示。您的最终表达式必须使用当前变分因子下的二阶矩期望来书写。不要假设协方差是对角的。\n\n将您的最终答案表示为四个更新量 $S_{x}$、$m_{x}$、$S_{k}$、$m_{k}$ 的解析表达式。不需要进行数值计算。", "solution": "我们首先建立概率模型。所有变量的联合概率分布由似然和先验的乘积给出：\n$p(y, x, k) = p(y | x, k) p(x) p(k)$。\n根据问题陈述，这些因子是：\n$p(y | x, k) = \\mathcal{N}(y | k*x, \\sigma^2 I_n) \\propto \\exp\\left(-\\frac{1}{2\\sigma^2} \\|y - k*x\\|_2^2\\right)$\n$p(x) = \\mathcal{N}(x | 0, \\alpha_x^{-1} I_n) \\propto \\exp\\left(-\\frac{\\alpha_x}{2} \\|x\\|_2^2\\right)$\n$p(k) = \\mathcal{N}(k | 0, \\alpha_k^{-1} I_m) \\propto \\exp\\left(-\\frac{\\alpha_k}{2} \\|k\\|_2^2\\right)$\n忽略常数项，联合分布的对数是：\n$\\ln p(y, x, k) = -\\frac{1}{2\\sigma^2} \\|y - k*x\\|_2^2 - \\frac{\\alpha_x}{2} \\|x\\|_2^2 - \\frac{\\alpha_k}{2} \\|k\\|_2^2 + C$。\n在具有平均场近似 $q(x,k) = q(x)q(k)$ 的变分贝叶斯框架中，因子 $q(x)$ 和 $q(k)$ 的最优更新是通过坐标上升法找到的。因子 $q_i(z_i)$ 的通用更新规则由下式给出：\n$\\ln q_i^*(z_i) = \\mathbb{E}_{j \\neq i}[\\ln p(y, x, k)] + \\text{const}_{z_i}$，\n其中期望是针对所有其他变量，根据它们当前的变分分布计算的。\n\n$q(x) = \\mathcal{N}(m_x, S_x)$ 的更新推导：\n最优分布 $q^*(x)$ 由下式给出：\n$\\ln q^*(x) = \\mathbb{E}_{q(k)}[\\ln p(y, x, k)] + \\text{const}_x$\n$\\ln q^*(x) = \\mathbb{E}_{q(k)}[\\ln p(y|x,k) + \\ln p(x) + \\ln p(k)] + \\text{const}_x$\n由于 $\\ln p(k)$ 不依赖于 $x$，我们有：\n$\\ln q^*(x) = \\mathbb{E}_{q(k)}[-\\frac{1}{2\\sigma^2} \\|y - K(k)x\\|_2^2] - \\frac{\\alpha_x}{2} \\|x\\|_2^2 + \\text{const}_x$\n我们展开期望内的二次项：\n$\\|y - K(k)x\\|_2^2 = (y - K(k)x)^T(y - K(k)x) = y^T y - 2y^T K(k)x + x^T K(k)^T K(k)x$。\n对 $q(k)$ 取期望：\n$\\mathbb{E}_{q(k)}[\\|y - K(k)x\\|_2^2] = y^T y - 2y^T \\mathbb{E}_{q(k)}[K(k)]x + x^T \\mathbb{E}_{q(k)}[K(k)^T K(k)]x$。\n将其代回到 $\\ln q^*(x)$ 的表达式中，并舍去不依赖于 $x$ 的项：\n$\\ln q^*(x) \\propto -\\frac{1}{2\\sigma^2} \\left( -2y^T \\mathbb{E}_{q(k)}[K(k)]x + x^T \\mathbb{E}_{q(k)}[K(k)^T K(k)]x \\right) - \\frac{\\alpha_x}{2} x^T x$\n$\\ln q^*(x) \\propto x^T \\left(\\frac{1}{\\sigma^2} \\mathbb{E}_{q(k)}[K(k)]^T y \\right) - \\frac{1}{2} x^T \\left(\\frac{1}{\\sigma^2} \\mathbb{E}_{q(k)}[K(k)^T K(k)] + \\alpha_x I_n \\right) x$。\n这个表达式是关于 $x$ 的二次型，这表明 $q^*(x)$ 是一个高斯分布。通过将其与多元高斯分布 $\\mathcal{N}(x|m_x, S_x)$ 的对数密度（正比于 $-\\frac{1}{2}(x-m_x)^T S_x^{-1} (x-m_x) = -\\frac{1}{2}x^T S_x^{-1} x + x^T S_x^{-1}m_x + \\text{const}$）进行比较，我们可以确定精度矩阵 $S_x^{-1}$ 和均值 $m_x$。\n精度矩阵是：\n$S_x^{-1} = \\frac{1}{\\sigma^2} \\mathbb{E}_{q(k)}[K(k)^T K(k)] + \\alpha_x I_n$。\n均值由下式确定：\n$S_x^{-1} m_x = \\frac{1}{\\sigma^2} \\mathbb{E}_{q(k)}[K(k)]^T y$。\n这就得出了 $q(x)$ 参数的更新方程：\n$S_x = \\left(\\frac{1}{\\sigma^2}\\mathbb{E}_{q(k)}[K(k)^T K(k)] + \\alpha_x I_n\\right)^{-1}$\n$m_x = S_x \\left(\\frac{1}{\\sigma^2} \\mathbb{E}_{q(k)}[K(k)]^T y\\right)$。\n\n$q(k) = \\mathcal{N}(m_k, S_k)$ 的更新推导：\n其推导过程与 $q(x)$ 的推导对称。我们使用卷积的另一种表示形式 $k*x = X(x)k$。\n$\\ln q^*(k) = \\mathbb{E}_{q(x)}[\\ln p(y, x, k)] + \\text{const}_k$\n$\\ln q^*(k) = \\mathbb{E}_{q(x)}[-\\frac{1}{2\\sigma^2} \\|y - X(x)k\\|_2^2] - \\frac{\\alpha_k}{2} \\|k\\|_2^2 + \\text{const}_k$。\n遵循相同的步骤，即展开二次项，对 $q(x)$ 取期望，并与高斯分布 $\\mathcal{N}(k|m_k, S_k)$ 的对数密度进行比较，我们得到：\n$S_k^{-1} = \\frac{1}{\\sigma^2} \\mathbb{E}_{q(x)}[X(x)^T X(x)] + \\alpha_k I_m$\n$S_k^{-1} m_k = \\frac{1}{\\sigma^2} \\mathbb{E}_{q(x)}[X(x)]^T y$。\n这给出了 $q(k)$ 参数的更新方程：\n$S_k = \\left(\\frac{1}{\\sigma^2}\\mathbb{E}_{q(x)}[X(x)^T X(x)] + \\alpha_k I_m\\right)^{-1}$\n$m_k = S_k \\left(\\frac{1}{\\sigma^2} \\mathbb{E}_{q(x)}[X(x)]^T y\\right)$。\n\n使用算子基表示期望：\n最后一步是用算子基 $\\{A_i\\}$ 和 $\\{B_j\\}$ 以及当前变分分布的参数来表示所需的期望。\n对于 $q(x)$ 的更新，我们需要对 $q(k) = \\mathcal{N}(k|m_k, S_k)$ 取期望。\n$\\mathbb{E}_{q(k)}[K(k)] = \\mathbb{E}_{q(k)}\\left[\\sum_{j=1}^{m} k_j B_j\\right] = \\sum_{j=1}^{m} \\mathbb{E}_{q(k)}[k_j] B_j$。\n$\\mathbb{E}_{q(k)}[K(k)^T K(k)] = \\mathbb{E}_{q(k)}\\left[\\left(\\sum_{j=1}^{m} k_j B_j\\right)^T \\left(\\sum_{l=1}^{m} k_l B_l\\right)\\right] = \\sum_{j=1}^{m}\\sum_{l=1}^{m} \\mathbb{E}_{q(k)}[k_j k_l] B_j^T B_l$。\n这里，$\\mathbb{E}_{q(k)}[k_j]$ 是均值向量 $m_k$ 的第 $j$ 个分量，而 $\\mathbb{E}_{q(k)}[k_j k_l]$ 是二阶矩矩阵 $\\mathbb{E}_{q(k)}[kk^T] = S_k + m_k m_k^T$ 的第 $(j,l)$ 个元素。\n\n对于 $q(k)$ 的更新，我们需要对 $q(x) = \\mathcal{N}(x|m_x, S_x)$ 取期望。\n$\\mathbb{E}_{q(x)}[X(x)] = \\mathbb{E}_{q(x)}\\left[\\sum_{i=1}^{n} x_i A_i\\right] = \\sum_{i=1}^{n} \\mathbb{E}_{q(x)}[x_i] A_i$。\n$\\mathbb{E}_{q(x)}[X(x)^T X(x)] = \\mathbb{E}_{q(x)}\\left[\\left(\\sum_{i=1}^{n} x_i A_i\\right)^T \\left(\\sum_{p=1}^{n} x_p A_p\\right)\\right] = \\sum_{i=1}^{n}\\sum_{p=1}^{n} \\mathbb{E}_{q(x)}[x_i x_p] A_i^T A_p$。\n这里，$\\mathbb{E}_{q(x)}[x_i]$ 是均值向量 $m_x$ 的第 $i$ 个分量，而 $\\mathbb{E}_{q(x)}[x_i x_p]$ 是二阶矩矩阵 $\\mathbb{E}_{q(x)}[xx^T] = S_x + m_x m_x^T$ 的第 $(i,p)$ 个元素。\n\n将这些代入更新规则，即可得到所要求的最终闭式表达式。\n$S_x$ 的更新式为：\n$S_x = \\left(\\frac{1}{\\sigma^2} \\sum_{j=1}^{m}\\sum_{l=1}^{m} \\mathbb{E}_{q(k)}[k_j k_l] B_j^T B_l + \\alpha_x I_n\\right)^{-1}$。\n$m_x$ 的更新式为：\n$m_x = S_x \\left(\\frac{1}{\\sigma^2} \\left(\\sum_{j=1}^{m}\\mathbb{E}_{q(k)}[k_j]B_j\\right)^T y\\right)$。\n$S_k$ 的更新式为：\n$S_k = \\left(\\frac{1}{\\sigma^2} \\sum_{i=1}^{n}\\sum_{p=1}^{n} \\mathbb{E}_{q(x)}[x_i x_p] A_i^T A_p + \\alpha_k I_m\\right)^{-1}$。\n$m_k$ 的更新式为：\n$m_k = S_k \\left(\\frac{1}{\\sigma^2} \\left(\\sum_{i=1}^{n}\\mathbb{E}_{q(x)}[x_i]A_i\\right)^T y\\right)$。\n这些表达式满足了问题陈述的所有条件。期望 $\\mathbb{E}_{q(k)}[\\cdot]$ 和 $\\mathbb{E}_{q(x)}[\\cdot]$ 是使用坐标上升算法上一步的变分分布参数计算得出的。", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\nS_{x} = \\left(\\frac{1}{\\sigma^{2}} \\sum_{j=1}^{m} \\sum_{l=1}^{m} \\mathbb{E}_{q(k)}[k_{j}k_{l}] B_{j}^T B_{l} + \\alpha_{x} I_{n}\\right)^{-1} \\\\\nm_{x} = S_{x} \\left(\\frac{1}{\\sigma^{2}} \\left(\\sum_{j=1}^{m} \\mathbb{E}_{q(k)}[k_{j}] B_{j}\\right)^{T} y\\right) \\\\\nS_{k} = \\left(\\frac{1}{\\sigma^{2}} \\sum_{i=1}^{n} \\sum_{p=1}^{n} \\mathbb{E}_{q(x)}[x_{i}x_{p}] A_{i}^T A_{p} + \\alpha_{k} I_{m}\\right)^{-1} \\\\\nm_{k} = S_{k} \\left(\\frac{1}{\\sigma^{2}} \\left(\\sum_{i=1}^{n} \\mathbb{E}_{q(x)}[x_{i}] A_{i}\\right)^{T} y\\right)\n\\end{pmatrix}\n}\n$$", "id": "3369047"}]}