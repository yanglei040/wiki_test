{"hands_on_practices": [{"introduction": "历史匹配通常依赖于基于梯度的优化算法，以最小化模拟数据与观测数据之间的差异。这些方法的核心在于高效计算目标函数关于成千上万个模型参数的梯度。本练习将引导你推导两种关键油藏数据（生产速率和示踪剂突破时间）所对应目标函数的伴随梯度。通过将解析梯度与数值近似进行比较，你不仅能验证自己的推导，还能深刻理解作为许多历史匹配算法基石的敏感性分析机制。[@problem_id:3389127]", "problem": "考虑一个长度为 $L$ 的一维油藏，它被离散化为 $N$ 个等宽 $\\Delta x = L/N$ 的网格单元，具有横截面积 $A$、孔隙度 $\\phi$ 和单相流体粘度 $\\mu$。在入口 $x=0$ 和出口 $x=L$ 之间施加一个恒定的压降。设空间变化的渗透率场以对数形式表示为 $m_i = \\log k_i$，其中网格单元索引 $i=1,\\dots,N$，并设 $k_i = \\exp(m_i)$。假设流动为不可压缩稳态流，示踪剂运移严格由对流主导（弥散可忽略），且孔隙度恒定。\n\n基本原理：\n- 一维流动的达西定律：$q = A k(x) \\left(\\frac{\\Delta p}{\\mu L}\\right)$，其中 $q$ 是体积流量，$\\Delta p$ 是施加的压降。\n- 渗流速度：$v(x) = \\frac{q}{A \\phi}$。\n- 运动前缘到达出口的传播时间：$T = \\int_0^L \\frac{dx}{v(x)}$。\n\n在具有分片常数渗透率 $k_i$ 的分层介质中的串联流动下，总水力阻力为 $R_{\\text{tot}} = \\sum_{i=1}^{N} \\frac{\\mu \\Delta x}{A k_i}$。在时变压力方案 $\\Delta p(t_j)$ 下的出口流量为 $q(t_j) = \\frac{\\Delta p(t_j)}{R_{\\text{tot}}}$，出口处的首次到达时间定义为 $T = \\int_0^L \\frac{dx}{v(x)}$，其中 $v(x)$ 由达西定律和示踪剂注入阶段的恒定压降确定。\n\n你的任务是：\n1. 在对流主导的情景下，将观测到的突破时间 $T_{\\text{obs}}$ 视为首次通过时间约束，为其构建一个统计上合理的似然函数。假设可观测的突破时间存在加性高斯误差，并以 $T(m)$ 和 $T_{\\text{obs}}$ 的形式指明负对数似然目标函数 $J_T(m)$。时间以秒为单位表示。\n2. 使用基本原理和变分法，推导到达时间泛函 $T(m)$ 相对于对数渗透率场 $m = \\{m_i\\}_{i=1}^N$ 的伴随（即泛函梯度）。你的推导必须从达西定律、渗流速度的定义和积分传播时间出发，不得使用任何未由此基础证明的快捷公式。清晰地陈述得到的 $J_T(m)$ 相对于 $m$ 的梯度表达式。\n3. 在已知压力方案 $\\{\\Delta p(t_j)\\}_{j=1}^M$ 和观测流量 $\\{q_{\\text{obs}}(t_j)\\}_{j=1}^M$ 的情况下，使用加性高斯误差定义一个常规的流量不匹配目标函数。同样从达西定律和串联电阻表示出发，推导该基于流量的目标函数 $J_q(m)$ 相对于 $m$ 的梯度。流量以 $\\mathrm{m^3/s}$ 为单位表示。\n4. 实现一个程序，对于一组给定的测试用例，计算 $J_T(m)$ 和 $J_q(m)$ 相对于 $m$ 的解析梯度，并将每个解析梯度与中心有限差分近似进行比较。使用以下方式量化“梯度质量”：\n   - 解析梯度与有限差分梯度之间夹角的余弦值。\n   - 定义为 $\\|g_{\\text{analytic}} - g_{\\text{FD}}\\|_2 / \\|g_{\\text{FD}}\\|_2$ 的相对 $\\ell_2$-范数误差。\n   这两个指标都是无量纲的，并且必须以浮点数形式报告。\n\n物理和数值单位：\n- $L$ 以米为单位， $A$ 以平方米为单位， $\\phi$ 无量纲， $\\mu$ 以帕斯卡-秒为单位， $\\Delta p$ 以帕斯卡为单位， $q$ 以 $\\mathrm{m^3/s}$ 为单位， $T$ 以秒为单位。\n- 不需要角度；将余弦值报告为无量纲浮点数。\n\n测试套件和参数：\n对于以下所有情况，使用 $N=5$, $L=100$, $A=10$, $\\phi=0.2$, $\\mu=10^{-3}$。为突破时间计算使用示踪剂注入压降 $\\Delta p_T = 10^5$。使用一个包含 $M=3$ 个时间的流量方案，其压降为 $\\Delta p(t) \\in \\{10^5, 1.2\\times 10^5, 0.8\\times 10^5\\}$。将标准差定义为 $\\sigma_T = 0.05\\, T_{\\text{obs}}$（用于时间目标函数）和 $\\sigma_q = 0.05\\, \\text{median}(\\{q_{\\text{obs}}(t_j)\\})$（用于流量目标函数）。\n\n每个测试用例提供：\n- 一个“真实”模型 $m_{\\text{true}}$，用于生成不含噪声的合成数据 $T_{\\text{obs}}$ 和 $q_{\\text{obs}}(t_j)$。\n- 一个“评估”模型 $m_{\\text{eval}}$，在此模型上计算和比较梯度。\n\n测试用例：\n- 用例 1（非均质，顺利路径）：\n  $m_{\\text{true}} = [\\log(1.0\\times 10^{-13}), \\log(2.0\\times 10^{-13}), \\log(0.5\\times 10^{-13}), \\log(1.5\\times 10^{-13}), \\log(1.0\\times 10^{-13})]$,\n  $m_{\\text{eval}} = [\\log(0.8\\times 10^{-13}), \\log(1.8\\times 10^{-13}), \\log(0.6\\times 10^{-13}), \\log(1.2\\times 10^{-13}), \\log(1.1\\times 10^{-13})]$。\n- 用例 2（均质渗透率，边界情况）：\n  $m_{\\text{true}} = [\\log(5.0\\times 10^{-13})]$ 重复 $N$ 次，\n  $m_{\\text{eval}} = [\\log(4.0\\times 10^{-13})]$ 重复 $N$ 次。\n- 用例 3（极端非均质性，边缘情况）：\n  $m_{\\text{true}} = [\\log(1.0\\times 10^{-13}), \\log(1.0\\times 10^{-14}), \\log(1.0\\times 10^{-13}), \\log(1.0\\times 10^{-12}), \\log(5.0\\times 10^{-13})]$,\n  $m_{\\text{eval}} = [\\log(1.2\\times 10^{-13}), \\log(0.8\\times 10^{-14}), \\log(0.9\\times 10^{-13}), \\log(1.1\\times 10^{-12}), \\log(4.5\\times 10^{-13})]$。\n\n程序要求：\n- 从 $m_{\\text{true}}$ 和 $\\Delta p_T$ 计算 $T_{\\text{obs}}$，并从 $m_{\\text{true}}$ 和流量方案计算 $q_{\\text{obs}}(t_j)$。\n- 在 $m_{\\text{eval}}$ 处，计算 $J_T(m)$ 和 $J_q(m)$ 相对于 $m$ 的解析梯度，以及使用中心差分和在 $m$ 的每个分量上施加一个小步长计算的有限差分梯度。\n- 对于每个用例，按顺序计算并存储 $J_T$ 的两个指标和 $J_q$ 的两个指标：$[\\text{cosine}_T, \\text{relerr}_T, \\text{cosine}_q, \\text{relerr}_q]$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试用例，并且其本身也是一个按指定顺序排列的列表。例如：\"[[cT1,errT1,cq1,errq1],[cT2,errT2,cq2,errq2],[cT3,errT3,cq3,errq3]]\"。所有输出都必须是无量纲浮点数。", "solution": "问题陈述被评估为有效。它提出了一个在反问题和数据同化领域中的适定问题，特别应用于油藏建模中的历史拟合。基于一维串联流动达西定律的物理模型在科学上是合理的且内部一致。该任务要求推导两个不同目标函数的梯度（伴随）并进行数值验证，这是该学科中一个标准且不简单的练习。达西定律的初始陈述 $q = A k(x) (\\frac{\\Delta p}{\\mu L})$ 对于非均质介质是不精确的，因为它暗示了流量 $q(x)$ 在空间上是变化的，这与不可压缩稳态流的质量守恒原理相矛盾。然而，问题陈述随后为离散化的分层介质提供了一个正确且清晰明确的模型：$q(t_j) = \\frac{\\Delta p(t_j)}{R_{\\text{tot}}}$，其中 $R_{\\text{tot}} = \\sum_{i=1}^{N} \\frac{\\mu \\Delta x}{A k_i}$。这个具体的公式对于串联流动是物理上正确的，并将作为所有推导的基础。\n\n我们着手处理问题中概述的四个任务。\n\n1.  **突破时间的似然函数和目标函数，$J_T(m)$**\n\n给定观测到的突破时间 $T_{\\text{obs}}$ 受到一个加性高斯误差的影响。设突破时间的模型预测值为 $T(m)$，它依赖于对数渗透率场 $m = \\{m_j\\}_{j=1}^N$。误差为 $e_T = T_{\\text{obs}} - T(m)$。问题陈述该误差服从均值为零、标准差为 $\\sigma_T$ 的高斯分布，即 $e_T \\sim \\mathcal{N}(0, \\sigma_T^2)$。\n\n在给定模型参数 $m$ 的情况下，观测到 $T_{\\text{obs}}$ 的似然是正态分布的概率密度函数在残差处的取值：\n$$\np(T_{\\text{obs}}|m) = \\frac{1}{\\sqrt{2\\pi \\sigma_T^2}} \\exp\\left(-\\frac{(T(m) - T_{\\text{obs}})^2}{2\\sigma_T^2}\\right)\n$$\n在反问题中，我们通常寻求最大化此似然函数，这等价于最小化其负对数。负对数似然函数为：\n$$\n-\\log p(T_{\\text{obs}}|m) = \\frac{1}{2}\\log(2\\pi \\sigma_T^2) + \\frac{1}{2\\sigma_T^2}(T(m) - T_{\\text{obs}})^2\n$$\n目标函数 $J_T(m)$ 通常定义为加权残差平方和的一半，它与负对数似然函数成正比（忽略常数项）。\n$$\nJ_T(m) = \\frac{1}{2\\sigma_T^2} (T(m) - T_{\\text{obs}})^2\n$$\n\n2.  **突破时间目标函数的伴随（梯度），$\\nabla_m J_T(m)$**\n\n为了求得 $J_T(m)$ 关于向量 $m$ 的梯度，我们应用链式法则：\n$$\n\\frac{\\partial J_T}{\\partial m_j} = \\frac{\\partial J_T}{\\partial T} \\frac{\\partial T}{\\partial m_j} = \\frac{T(m) - T_{\\text{obs}}}{\\sigma_T^2} \\frac{\\partial T}{\\partial m_j}\n$$\n核心任务是推导灵敏度项 $\\frac{\\partial T}{\\partial m_j}$。我们从正演模型 $T(m)$ 的基本原理开始。传播时间 $T$ 由渗流速度 $v(x)$ 的倒数的积分给出：\n$$\nT = \\int_0^L \\frac{dx}{v(x)}\n$$\n渗流速度为 $v(x) = \\frac{q}{A \\phi}$，其中 $q$ 是恒定的体积流量，$A$ 是横截面积，$\\phi$ 是孔隙度。对于一维系统中的不可压缩稳态流，$q$、$A$ 和 $\\phi$ 相对于位置 $x$ 是常数。因此，渗流速度 $v$ 也是恒定的。积分简化为：\n$$\nT = \\frac{1}{v} \\int_0^L dx = \\frac{L}{v} = \\frac{L A \\phi}{q}\n$$\n流量 $q$ 由示踪剂注入期间的总压降 $\\Delta p_T$ 和总水力阻力 $R_{\\text{tot}}$ 决定。\n$$\nq = \\frac{\\Delta p_T}{R_{\\text{tot}}}\n$$\n对于具有 $N$ 个宽度为 $\\Delta x = L/N$ 且渗透率为分片常数 $k_i$ 的网格单元的分层介质，总阻力是各个单元阻力的总和：\n$$\nR_{\\text{tot}} = \\sum_{i=1}^N \\frac{\\mu \\Delta x}{A k_i}\n$$\n渗透率 $k_i$ 通过 $k_i = \\exp(m_i)$ 与模型参数 $m_i$ 相关。将此代入阻力公式：\n$$\nR_{\\text{tot}}(m) = \\sum_{i=1}^N \\frac{\\mu \\Delta x}{A \\exp(m_i)} = \\frac{\\mu \\Delta x}{A} \\sum_{i=1}^N \\exp(-m_i)\n$$\n现在我们可以将 $T$ 表示为 $m$ 的函数：\n$$\nT(m) = \\frac{L A \\phi}{q} = L A \\phi \\frac{R_{\\text{tot}}(m)}{\\Delta p_T} = \\frac{L A \\phi}{\\Delta p_T} \\left( \\frac{\\mu \\Delta x}{A} \\sum_{i=1}^N \\exp(-m_i) \\right) = \\frac{\\phi \\mu L \\Delta x}{\\Delta p_T} \\sum_{i=1}^N \\exp(-m_i)\n$$\n由于 $\\Delta x = L/N$，传播时间正演模型的最终表达式为：\n$$\nT(m) = \\frac{\\phi \\mu L^2}{N \\Delta p_T} \\sum_{i=1}^N \\exp(-m_i)\n$$\n现在，我们可以计算 $T(m)$ 相对于参数向量 $m$ 的单个分量 $m_j$ 的偏导数：\n$$\n\\frac{\\partial T}{\\partial m_j} = \\frac{\\partial}{\\partial m_j} \\left( \\frac{\\phi \\mu L^2}{N \\Delta p_T} \\sum_{i=1}^N \\exp(-m_i) \\right) = \\frac{\\phi \\mu L^2}{N \\Delta p_T} \\frac{\\partial}{\\partial m_j} (\\exp(-m_j)) = -\\frac{\\phi \\mu L^2}{N \\Delta p_T} \\exp(-m_j)\n$$\n最后，我们将此灵敏度代入目标函数梯度的链式法则表达式中：\n$$\n\\frac{\\partial J_T}{\\partial m_j} = \\frac{T(m) - T_{\\text{obs}}}{\\sigma_T^2} \\left( -\\frac{\\phi \\mu L^2}{N \\Delta p_T} \\exp(-m_j) \\right)\n$$\n这是梯度向量 $\\nabla_m J_T(m)$ 的第 $j$ 个分量。\n\n3.  **产出率的目标函数和梯度，$J_q(m)$**\n\n给定一组 $M$ 个流量观测值 $\\{q_{\\text{obs}}(t_j)\\}_{j=1}^M$，对应于一个压力方案 $\\{\\Delta p(t_j)\\}_{j=1}^M$。假设误差 $e_{q, j} = q_{\\text{obs}}(t_j) - q(m, t_j) \\sim \\mathcal{N}(0, \\sigma_q^2)$ 是独立同分布的加性高斯误差，则联合似然是各个似然的乘积。相应的负对数似然目标函数是各个不匹配项之和：\n$$\nJ_q(m) = \\sum_{j=1}^M \\frac{1}{2\\sigma_q^2} (q(m, t_j) - q_{\\text{obs}}(t_j))^2\n$$\n\n4.  **流量目标函数的伴随（梯度），$\\nabla_m J_q(m)$**\n\n对 $J_q(m)$ 应用链式法则，其相对于分量 $m_s$ 的梯度为：\n$$\n\\frac{\\partial J_q}{\\partial m_s} = \\sum_{j=1}^M \\frac{\\partial}{\\partial m_s} \\left[ \\frac{1}{2\\sigma_q^2} (q(m, t_j) - q_{\\text{obs}}(t_j))^2 \\right] = \\sum_{j=1}^M \\frac{q(m, t_j) - q_{\\text{obs}}(t_j)}{\\sigma_q^2} \\frac{\\partial q(m, t_j)}{\\partial m_s}\n$$\n让我们记 $q_j(m) = q(m, t_j)$ 和 $\\Delta p_j = \\Delta p(t_j)$。在时间 $t_j$ 的流量正演模型是：\n$$\nq_j(m) = \\frac{\\Delta p_j}{R_{\\text{tot}}(m)}\n$$\n其中 $R_{\\text{tot}}(m) = \\frac{\\mu \\Delta x}{A} \\sum_{i=1}^N \\exp(-m_i)$。\n我们需要灵敏度 $\\frac{\\partial q_j}{\\partial m_s}$：\n$$\n\\frac{\\partial q_j}{\\partial m_s} = \\frac{\\partial}{\\partial m_s} \\left( \\frac{\\Delta p_j}{R_{\\text{tot}}(m)} \\right) = \\Delta p_j \\left( -\\frac{1}{R_{\\text{tot}}(m)^2} \\right) \\frac{\\partial R_{\\text{tot}}}{\\partial m_s}\n$$\n总阻力相对于 $m_s$ 的导数是：\n$$\n\\frac{\\partial R_{\\text{tot}}}{\\partial m_s} = \\frac{\\partial}{\\partial m_s} \\left( \\frac{\\mu \\Delta x}{A} \\sum_{i=1}^N \\exp(-m_i) \\right) = \\frac{\\mu \\Delta x}{A} (-\\exp(-m_s))\n$$\n将此代回 $q_j$ 的灵敏度表达式中：\n$$\n\\frac{\\partial q_j}{\\partial m_s} = -\\frac{\\Delta p_j}{R_{\\text{tot}}(m)^2} \\left( -\\frac{\\mu \\Delta x}{A} \\exp(-m_s) \\right) = \\frac{\\Delta p_j}{R_{\\text{tot}}(m)^2} \\frac{\\mu \\Delta x}{A} \\exp(-m_s)\n$$\n现在，将此灵敏度代入 $J_q(m)$ 的梯度表达式中：\n$$\n\\frac{\\partial J_q}{\\partial m_s} = \\sum_{j=1}^M \\left[ \\frac{q_j(m) - q_{\\text{obs}}(t_j)}{\\sigma_q^2} \\left( \\frac{\\Delta p_j}{R_{\\text{tot}}(m)^2} \\frac{\\mu \\Delta x}{A} \\exp(-m_s) \\right) \\right]\n$$\n我们可以提取出不依赖于求和索引 $j$ 的项。项 $\\exp(-m_s)$ 对于所有流量数据点相对于 $m_s$ 的灵敏度是公共的。\n$$\n\\frac{\\partial J_q}{\\partial m_s} = \\left( \\frac{\\mu \\Delta x}{A} \\exp(-m_s) \\right) \\sum_{j=1}^M \\left[ \\frac{q_j(m) - q_{\\text{obs}}(t_j)}{\\sigma_q^2} \\frac{\\Delta p_j}{R_{\\text{tot}}(m)^2} \\right]\n$$\n这给出了梯度向量 $\\nabla_m J_q(m)$ 的第 $s$ 个分量。它的形式是一个灵敏度项乘以数据不匹配伴随源的加权和。\n\n至此完成了所需的推导。后续的实现将编码这些最终的解析梯度表达式，并将它们与数值有限差分近似进行比较。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Main function to orchestrate the gradient computation and comparison for all test cases.\n    \"\"\"\n    # Physical and numerical parameters\n    params = {\n        'N': 5,\n        'L': 100.0,  # meters\n        'A': 10.0,   # m^2\n        'phi': 0.2,  # dimensionless\n        'mu': 1.0e-3, # Pa.s\n        'delta_p_T': 1.0e5, # Pa\n        'delta_p_schedule': np.array([1.0e5, 1.2e5, 0.8e5]) # Pa\n    }\n    params['dx'] = params['L'] / params['N']\n\n    # Test cases\n    test_cases = [\n        {\n            \"m_true\": np.log(np.array([1.0e-13, 2.0e-13, 0.5e-13, 1.5e-13, 1.0e-13])),\n            \"m_eval\": np.log(np.array([0.8e-13, 1.8e-13, 0.6e-13, 1.2e-13, 1.1e-13]))\n        },\n        {\n            \"m_true\": np.log(np.full(params['N'], 5.0e-13)),\n            \"m_eval\": np.log(np.full(params['N'], 4.0e-13))\n        },\n        {\n            \"m_true\": np.log(np.array([1.0e-13, 1.0e-14, 1.0e-13, 1.0e-12, 5.0e-13])),\n            \"m_eval\": np.log(np.array([1.2e-13, 0.8e-14, 0.9e-13, 1.1e-12, 4.5e-13]))\n        }\n    ]\n\n    all_results = []\n    for case in test_cases:\n        all_results.append(process_case(case, params))\n\n    # Format the final output string\n    output_str = f\"[{','.join([f'[{\",\".join(map(str, r))}]' for r in all_results])}]\"\n    print(output_str)\n\ndef process_case(case, params):\n    \"\"\"\n    Processes a single test case: generates data, computes gradients, and calculates metrics.\n    \"\"\"\n    m_true = case['m_true']\n    m_eval = case['m_eval']\n\n    # Generate synthetic \"observed\" data without noise\n    T_obs = compute_T(m_true, params)\n    q_obs = compute_q(m_true, params)\n\n    # Define standard deviations\n    sigma_T = 0.05 * T_obs\n    sigma_q = 0.05 * np.median(q_obs)\n\n    # --- Breakthrough Time Gradient Verification ---\n    # Analytic gradient\n    grad_T_analytic = compute_JT_gradient_analytic(m_eval, T_obs, sigma_T, params)\n    \n    # Finite-difference gradient\n    grad_T_fd = compute_JT_gradient_fd(m_eval, T_obs, sigma_T, params)\n    \n    # Calculate metrics for T\n    metrics_T = calculate_metrics(grad_T_analytic, grad_T_fd)\n\n    # --- Production Rate Gradient Verification ---\n    # Analytic gradient\n    grad_q_analytic = compute_Jq_gradient_analytic(m_eval, q_obs, sigma_q, params)\n\n    # Finite-difference gradient\n    grad_q_fd = compute_Jq_gradient_fd(m_eval, q_obs, sigma_q, params)\n\n    # Calculate metrics for q\n    metrics_q = calculate_metrics(grad_q_analytic, grad_q_fd)\n\n    return [*metrics_T, *metrics_q]\n\n# --- Forward Models ---\ndef compute_T(m, params):\n    \"\"\"Computes breakthrough time T(m).\"\"\"\n    phi, mu, L, N, delta_p_T = params['phi'], params['mu'], params['L'], params['N'], params['delta_p_T']\n    # Formula: T(m) = (phi * mu * L^2) / (N * delta_p_T) * sum(exp(-m_i))\n    coeff = (phi * mu * L**2) / (N * delta_p_T)\n    return coeff * np.sum(np.exp(-m))\n\ndef compute_Rtot(m, params):\n    \"\"\"Computes total hydraulic resistance R_tot(m).\"\"\"\n    mu, dx, A = params['mu'], params['dx'], params['A']\n    # Formula: R_tot(m) = (mu * dx / A) * sum(exp(-m_i))\n    return (mu * dx / A) * np.sum(np.exp(-m))\n\ndef compute_q(m, params):\n    \"\"\"Computes flow rates q(m) for the pressure schedule.\"\"\"\n    R_tot = compute_Rtot(m, params)\n    delta_p_schedule = params['delta_p_schedule']\n    # Formula: q_j(m) = delta_p_j / R_tot(m)\n    return delta_p_schedule / R_tot\n\n# --- Objective Functions ---\ndef compute_JT(m, T_obs, sigma_T, params):\n    \"\"\"Computes the time-of-arrival objective function J_T(m).\"\"\"\n    T_pred = compute_T(m, params)\n    return 0.5 * ((T_pred - T_obs) / sigma_T)**2\n\ndef compute_Jq(m, q_obs, sigma_q, params):\n    \"\"\"Computes the rate-misfit objective function J_q(m).\"\"\"\n    q_pred = compute_q(m, params)\n    return 0.5 * np.sum(((q_pred - q_obs) / sigma_q)**2)\n\n# --- Analytic Gradients ---\ndef compute_JT_gradient_analytic(m, T_obs, sigma_T, params):\n    \"\"\"Computes the analytic gradient of J_T(m).\"\"\"\n    phi, mu, L, N, delta_p_T = params['phi'], params['mu'], params['L'], params['N'], params['delta_p_T']\n    T_pred = compute_T(m, params)\n    \n    # dJ/dT\n    dJ_dT = (T_pred - T_obs) / (sigma_T**2)\n    \n    # dT/dm_j\n    dT_dm_coeff = -(phi * mu * L**2) / (N * delta_p_T)\n    dT_dm = dT_dm_coeff * np.exp(-m)\n    \n    return dJ_dT * dT_dm\n\ndef compute_Jq_gradient_analytic(m, q_obs, sigma_q, params):\n    \"\"\"Computes the analytic gradient of J_q(m).\"\"\"\n    mu, dx, A, delta_p_schedule = params['mu'], params['dx'], params['A'], params['delta_p_schedule']\n    \n    # Predictions needed for gradient\n    q_pred = compute_q(m, params)\n    R_tot = compute_Rtot(m, params)\n\n    # Weighted sum of adjoint sources\n    misfit_term = (q_pred - q_obs) / (sigma_q**2)\n    sum_term = np.sum(misfit_term * delta_p_schedule / R_tot**2)\n\n    # Sensitivity term d(R_tot)/dm_s\n    dR_dm_term = -(mu * dx / A) * np.exp(-m)\n    \n    # Chain rule: dJ/dm = sum[(dJ/dq)*(dq/dR)*(dR/dm)]\n    # Simplified from derivation:\n    # dJ/dm_s = (- dR/dm_s) * sum_j [ (q_j - q_obs_j)/sigma_q^2 * ( -dp_j/R_tot^2) ]\n    # dJ/dm_s = ( (mu*dx/A)*exp(-m_s) ) * sum_j [ (q_j - q_obs_j)/sigma_q^2 * ( dp_j/R_tot^2) ]\n    grad = (-dR_dm_term) * sum_term\n    \n    return grad\n\n# --- Finite-Difference Gradients ---\ndef compute_JT_gradient_fd(m, T_obs, sigma_T, params, h=1e-8):\n    \"\"\"Computes the finite-difference gradient of J_T(m).\"\"\"\n    N = params['N']\n    grad = np.zeros_like(m)\n    for i in range(N):\n        m_plus = m.copy()\n        m_plus[i] += h\n        m_minus = m.copy()\n        m_minus[i] -= h\n        \n        JT_plus = compute_JT(m_plus, T_obs, sigma_T, params)\n        JT_minus = compute_JT(m_minus, T_obs, sigma_T, params)\n        \n        grad[i] = (JT_plus - JT_minus) / (2 * h)\n    return grad\n\ndef compute_Jq_gradient_fd(m, q_obs, sigma_q, params, h=1e-8):\n    \"\"\"Computes the finite-difference gradient of J_q(m).\"\"\"\n    N = params['N']\n    grad = np.zeros_like(m)\n    for i in range(N):\n        m_plus = m.copy()\n        m_plus[i] += h\n        m_minus = m.copy()\n        m_minus[i] -= h\n\n        Jq_plus = compute_Jq(m_plus, q_obs, sigma_q, params)\n        Jq_minus = compute_Jq(m_minus, q_obs, sigma_q, params)\n        \n        grad[i] = (Jq_plus - Jq_minus) / (2 * h)\n    return grad\n\n# --- Gradient Quality Metrics ---\ndef calculate_metrics(g_analytic, g_fd):\n    \"\"\"Calculates cosine similarity and relative L2 error between two vectors.\"\"\"\n    norm_a = np.linalg.norm(g_analytic)\n    norm_fd = np.linalg.norm(g_fd)\n    \n    # Cosine of the angle\n    if norm_a == 0 or norm_fd == 0:\n        # Gradients are zero, perfectly aligned\n        cosine_sim = 1.0\n    else:\n        cosine_sim = np.dot(g_analytic, g_fd) / (norm_a * norm_fd)\n    \n    # Relative L2-norm error\n    if norm_fd == 0:\n        if norm_a == 0:\n            # Both are zero vectors\n            rel_error = 0.0\n        else:\n            # FD is zero, analytic is not: infinite error\n            rel_error = np.inf\n    else:\n        rel_error = np.linalg.norm(g_analytic - g_fd) / norm_fd\n        \n    return cosine_sim, rel_error\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3389127"}, {"introduction": "历史匹配中常用的高斯噪声假设在实践中可能存在问题，因为真实世界的测量数据常被异常值污染。这些异常值会过度影响参数估计，可能导致模型不符合物理规律。本练习将指导你为一个基于学生t分布的负对数似然函数推导并实现其梯度。通过分析其“影响函数”并与高斯情况进行对比，你将深入理解鲁棒数据同化如何有效地处理含有异常值的真实数据，从而提高历史匹配的可靠性。[@problem_id:3389148]", "problem": "您正在使用简化的递减曲线正演模型，对油藏中单井的产量进行历史拟合建模。设模型参数向量为 $m = [k,a]^{\\top}$，其中 $k$ 是一个正振幅，$a$ 是一个正递减率。设在观测时间 $t_i$ 的正演算子为 $h_i(m) = k \\exp(-a t_i)$，$h(m) \\in \\mathbb{R}^{n}$ 是将这些分量（$i=1, \\dots, n$）堆叠而成的向量。观测值 $y^{\\mathrm{obs}} \\in \\mathbb{R}^{n}$ 通过 $y^{\\mathrm{obs}} = h(m^{\\star}) + \\epsilon$ 与模型相关联，其中 $m^{\\star}$ 是未知的真实参数，$\\epsilon$ 是测量误差。在用于历史拟合的稳健数据同化中，通常使用自由度为 $\\nu$ 的学生t分布来描述测量误差，以减轻异常值的影响。\n\n从具有自由度 $\\nu$ 和每个观测值已知的正尺度 $s$ 的独立残差的学生t分布概率密度函数 (PDF) 的定义出发，并仅使用基本微积分法则（链式法则、乘法法则）和似然函数的定义，完成以下任务：\n\n1) 在独立学生t分量的假设下，推导残差向量 $r(m) = y^{\\mathrm{obs}} - h(m)$ 的负对数似然，并根据雅可比矩阵 $J(m) = \\partial h(m)/\\partial m$ 计算其关于 $m$ 的梯度。清晰地指出通过链式法则将每个残差分量 $r_i$ 映射到梯度中相应贡献的分量级“影响函数”。\n\n2) 作为比较，对每个分量方差为 $s^2$ 的独立高斯测量误差重复此推导，并指出相应的影响函数。\n\n3) 分析学生t影响函数和高斯影响函数在处理大幅值残差（异常值）和小幅值残差时的定性差异。解释哪种似然函数会降低异常值的权重，并说明原因。\n\n4) 实现一个程序，对于指定的参数值，计算学生t模型和高斯模型下负对数似然梯度的欧几里得范数，以及一个异常残差和一个典型残差的绝对影响幅度的比率。使用以下具体且完全指定的设置：\n- 观测时间 $t = [0,1,2,3,4]$。\n- 真实参数 $m^{\\star} = [1.5, 0.4]^{\\top}$。\n- 用于线性和评估的初始猜测值 $m_0 = [1.2, 0.5]^{\\top}$。\n- 基线无噪声观测值 $y^{\\mathrm{base}} = h(m^{\\star})$。\n- 在索引 $i_{\\mathrm{out}} = 2$ 处注入一个异常值（即第三个观测值），方法是在该分量上加上一个标量偏移 $\\Delta_{\\mathrm{out}}$：$y^{\\mathrm{obs}} = y^{\\mathrm{base}}$，其中 $y^{\\mathrm{obs}}[i_{\\mathrm{out}}] \\leftarrow y^{\\mathrm{obs}}[i_{\\mathrm{out}}] + \\Delta_{\\mathrm{out}}$。\n- 典型残差索引 $i_{\\mathrm{typ}} = 0$。\n- 所有观测值的独立同分布尺度 $s = 0.1$。\n- 使用正演模型定义所隐含的 $h(m)$ 相对于 $m$ 的精确雅可比矩阵。\n\n将测试套件定义为以下四种情况，每种情况由 $(\\nu, \\Delta_{\\mathrm{out}})$ 指定：\n- 情况 A: $(\\nu = 3.0, \\Delta_{\\mathrm{out}} = 1.5)$。\n- 情况 B: $(\\nu = 30.0, \\Delta_{\\mathrm{out}} = 1.5)$。\n- 情况 C: $(\\nu = 1.0, \\Delta_{\\mathrm{out}} = 1.5)$。\n- 情况 D: $(\\nu = 3.0, \\Delta_{\\mathrm{out}} = 0.0)$。\n\n对于每种情况，计算在 $m_0$ 处评估的以下四个量：\n- $g^{(t)}$-norm：学生t负对数似然梯度的欧几里得范数。\n- $g^{(g)}$-norm：高斯负对数似然梯度的欧几里得范数。\n- 异常值影响比：$\\left|\\psi^{(t)}(r_{i_{\\mathrm{out}}})\\right| \\big/ \\left|\\psi^{(g)}(r_{i_{\\mathrm{out}}})\\right|$，其中 $\\psi^{(t)}$ 和 $\\psi^{(g)}$ 分别是学生t影响函数和高斯影响函数。\n- 典型值影响比：$\\left|\\psi^{(t)}(r_{i_{\\mathrm{typ}}})\\right| \\big/ \\left|\\psi^{(g)}(r_{i_{\\mathrm{typ}}})\\right|$。\n\n所有量都是无量纲的；不需要物理单位。最终程序必须生成单行输出，包含四种情况的结果，格式为逗号分隔的列表的列表，每个内部列表按上述顺序包含四个浮点数。例如，输出格式必须严格为\n\"[[g_t_A,g_g_A,ratio_out_A,ratio_typ_A],[g_t_B,g_g_B,ratio_out_B,ratio_typ_B],[g_t_C,g_g_C,ratio_out_C,ratio_typ_C],[g_t_D,g_g_D,ratio_out_D,ratio_typ_D]]\"\n的形式，不得有额外的空格或文本。所有数值结果必须以标准十进制表示法打印。", "solution": "我们从观测模型 $y^{\\mathrm{obs}} = h(m^{\\star}) + \\epsilon$ 开始，并定义残差 $r(m) = y^{\\mathrm{obs}} - h(m) \\in \\mathbb{R}^{n}$。用于数据同化的负对数似然泛函定义为 $-\\log p(y^{\\mathrm{obs}} \\mid m)$，该定义不考虑一个与 $m$ 无关的加性常数。其关于 $m$ 的梯度可通过链式法则求得，其中使用雅可比矩阵 $J(m) = \\partial h(m)/\\partial m \\in \\mathbb{R}^{n \\times p}$，$p$ 是参数的数量。\n\n学生t误差的推导。假设残差分量是独立的，每个分量都服从自由度为 $\\nu$、正尺度为 $s$ 的学生t分布。单个分量的概率密度函数 (PDF) 为\n$$\np(r_i) = \\frac{\\Gamma\\left(\\frac{\\nu+1}{2}\\right)}{\\Gamma\\left(\\frac{\\nu}{2}\\right)\\sqrt{\\nu \\pi}\\, s} \\left(1 + \\frac{r_i^2}{\\nu s^2}\\right)^{-\\frac{\\nu+1}{2}},\n$$\n其中 $\\Gamma(\\cdot)$ 是伽马函数。独立分量的负对数似然为\n$$\n\\ell^{(t)}(m) = -\\sum_{i=1}^{n} \\log p(r_i(m)) = C + \\frac{\\nu+1}{2} \\sum_{i=1}^{n} \\log\\left(1 + \\frac{r_i(m)^2}{\\nu s^2}\\right),\n$$\n其中 $C$ 是一个与 $m$ 无关的常数。将 $\\ell^{(t)}(m)$ 对 $m$ 求导，并使用链式法则 $\\, \\mathrm{d}r_i/\\mathrm{d}m = -J_i(m)$（其中 $J_i(m)$ 表示 $J(m)$ 的第 $i$ 行），可得\n$$\n\\nabla_m \\ell^{(t)}(m) = \\sum_{i=1}^{n} \\left[ \\frac{\\nu+1}{2} \\cdot \\frac{1}{1 + \\frac{r_i^2}{\\nu s^2}} \\cdot \\frac{2 r_i}{\\nu s^2} \\right] \\left(-J_i(m) \\right)\n= - J(m)^{\\top} \\psi^{(t)}(r(m)),\n$$\n其中影响函数向量 $\\psi^{(t)}(r) \\in \\mathbb{R}^{n}$ 的分量定义为\n$$\n\\psi^{(t)}_i(r_i) = \\frac{(\\nu+1) r_i}{\\nu s^2 + r_i^2}.\n$$\n\n高斯误差的推导。对于方差为 $s^2$ 的独立高斯误差，每个分量的PDF为\n$$\np(r_i) = \\frac{1}{\\sqrt{2\\pi} s} \\exp\\left(-\\frac{r_i^2}{2 s^2}\\right).\n$$\n负对数似然为\n$$\n\\ell^{(g)}(m) = C' + \\frac{1}{2} \\sum_{i=1}^{n} \\frac{r_i(m)^2}{s^2},\n$$\n其中 $C'$ 与 $m$ 无关。通过微分和链式法则可得\n$$\n\\nabla_m \\ell^{(g)}(m) = \\sum_{i=1}^{n} \\left( \\frac{r_i}{s^2} \\right) \\left( -J_i(m) \\right)\n= - J(m)^{\\top} \\psi^{(g)}(r(m)),\n$$\n其中高斯影响函数为\n$$\n\\psi^{(g)}_i(r_i) = \\frac{r_i}{s^2}.\n$$\n\n影响分析。影响函数的大小决定了每个残差分量对梯度的贡献方式。对于小幅值残差，即 $|r_i| \\ll s \\sqrt{\\nu}$，我们有\n$$\n\\psi^{(t)}_i(r_i) \\approx \\frac{\\nu+1}{\\nu s^2} r_i,\n$$\n这与 $r_i$ 近似成线性关系，类似于高斯情况。对于大幅值残差，即 $|r_i| \\gg s \\sqrt{\\nu}$，学生t影响函数会饱和并衰减为\n$$\n\\psi^{(t)}_i(r_i) \\approx \\frac{\\nu+1}{r_i},\n$$\n因此其大小表现得像 $(\\nu+1)/|r_i|$，并随异常值的增大而减小。相比之下，高斯影响函数随 $|r_i|$ 线性增长，关系为 $|r_i|/s^2$。因此，学生t似然会强烈地降低异常值的权重，而高斯似然会放大它们的影响。\n\n正演算子与雅可比矩阵。对于 $h_i(m) = k \\exp(-a t_i)$ 和 $m = [k,a]^{\\top}$，雅可比矩阵的行是\n$$\n\\frac{\\partial h_i}{\\partial k} = \\exp(-a t_i), \\quad \\frac{\\partial h_i}{\\partial a} = -k t_i \\exp(-a t_i).\n$$\n将这些行（$i=1,\\dots,n$）堆叠起来，得到 $J(m) \\in \\mathbb{R}^{n \\times 2}$。\n\n计算每个测试用例 $(\\nu, \\Delta_{\\mathrm{out}})$ 所需输出的算法步骤：\n1) 构建 $t = [0,1,2,3,4]$ 并用 $m^{\\star} = [1.5, 0.4]^{\\top}$ 计算 $y^{\\mathrm{base}} = h(m^{\\star})$。\n2) 通过复制 $y^{\\mathrm{base}}$ 并在索引 $i_{\\mathrm{out}} = 2$ 处加上 $\\Delta_{\\mathrm{out}}$ 来形成 $y^{\\mathrm{obs}}$。\n3) 在 $m_0 = [1.2, 0.5]^{\\top}$ 处，计算残差 $r = y^{\\mathrm{obs}} - h(m_0)$ 和雅可比矩阵 $J(m_0)$。\n4) 使用 $\\psi^{(t)}_i(r_i) = (\\nu+1) r_i / (\\nu s^2 + r_i^2)$（其中 $s = 0.1$）计算 $\\psi^{(t)}(r)$，并使用 $\\psi^{(g)}_i(r_i) = r_i / s^2$ 计算 $\\psi^{(g)}(r)$。\n5) 计算梯度 $\\nabla_m \\ell^{(t)}(m_0) = - J(m_0)^{\\top} \\psi^{(t)}(r)$ 和 $\\nabla_m \\ell^{(g)}(m_0) = - J(m_0)^{\\top} \\psi^{(g)}(r)$，及其欧几里得范数。\n6) 计算异常值影响比 $\\left|\\psi^{(t)}(r_{i_{\\mathrm{out}}})\\right| / \\left|\\psi^{(g)}(r_{i_{\\mathrm{out}}})\\right|$ 和典型值影响比 $\\left|\\psi^{(t)}(r_{i_{\\mathrm{typ}}})\\right| / \\left|\\psi^{(g)}(r_{i_{\\mathrm{typ}}})\\right|$，其中 $i_{\\mathrm{typ}} = 0$。\n7) 以指定的单行列表的列表格式，为每个测试用例返回四个浮点数。\n\n定性预期。对于 $(\\nu = 3.0, \\Delta_{\\mathrm{out}} = 1.5)$ 和 $(\\nu = 1.0, \\Delta_{\\mathrm{out}} = 1.5)$，由于强烈的权重降低，异常值影响比应显著低于1，其中 $\\nu = 1.0$ 的情况将产生最小的比率。对于 $(\\nu = 30.0, \\Delta_{\\mathrm{out}} = 1.5)$，异常值影响比应更接近1，反映出近高斯行为。当 $\\Delta_{\\mathrm{out}} = 0.0$ 时，两个比率都应接近1，因为残差不受异常值主导，且两种模型在原点附近的行为相似。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef forward_model(m, t):\n    \"\"\"\n    Forward operator h(m): h_i = k * exp(-a * t_i)\n    m: array-like, shape (2,) with m = [k, a]\n    t: array-like of times\n    Returns y_pred of shape (n_times,)\n    \"\"\"\n    k, a = m\n    t = np.asarray(t, dtype=float)\n    return k * np.exp(-a * t)\n\ndef jacobian(m, t):\n    \"\"\"\n    Jacobian J(m) of h(m) with respect to m = [k, a]\n    J[i, 0] = d h_i / d k = exp(-a * t_i)\n    J[i, 1] = d h_i / d a = -k * t_i * exp(-a * t_i)\n    \"\"\"\n    k, a = m\n    t = np.asarray(t, dtype=float)\n    exp_term = np.exp(-a * t)\n    J = np.zeros((t.size, 2), dtype=float)\n    J[:, 0] = exp_term\n    J[:, 1] = -k * t * exp_term\n    return J\n\ndef influence_student_t(r, s, nu):\n    \"\"\"\n    Student-t influence function psi^(t)_i = ((nu+1) * r_i) / (nu * s^2 + r_i^2)\n    r: residual vector\n    s: scalar scale\n    nu: degrees of freedom (scalar)\n    \"\"\"\n    r = np.asarray(r, dtype=float)\n    denom = nu * (s ** 2) + r**2\n    return (nu + 1.0) * r / denom\n\ndef influence_gaussian(r, s):\n    \"\"\"\n    Gaussian influence function psi^(g)_i = r_i / s^2\n    \"\"\"\n    r = np.asarray(r, dtype=float)\n    return r / (s ** 2)\n\ndef gradient_from_influence(m, t, psi):\n    \"\"\"\n    Compute gradient of negative log-likelihood: grad = - J^T * psi\n    \"\"\"\n    J = jacobian(m, t)\n    return - J.T @ psi\n\ndef run_case(nu, delta_out):\n    # Setup constants\n    t = np.array([0.0, 1.0, 2.0, 3.0, 4.0], dtype=float)\n    m_true = np.array([1.5, 0.4], dtype=float)\n    m0 = np.array([1.2, 0.5], dtype=float)\n    s = 0.1\n    i_out = 2\n    i_typ = 0\n\n    # Build observations with specified outlier\n    y_base = forward_model(m_true, t)\n    y_obs = y_base.copy()\n    y_obs[i_out] += delta_out\n\n    # Residual at m0\n    r = y_obs - forward_model(m0, t)\n\n    # Influences\n    psi_t = influence_student_t(r, s, nu)\n    psi_g = influence_gaussian(r, s)\n\n    # Gradients\n    grad_t = gradient_from_influence(m0, t, psi_t)\n    grad_g = gradient_from_influence(m0, t, psi_g)\n\n    # Norms\n    g_t_norm = float(np.linalg.norm(grad_t))\n    g_g_norm = float(np.linalg.norm(grad_g))\n\n    # Influence ratios\n    # Guard against division by zero in ratios; if denominator is zero, define ratio as np.nan\n    denom_out = abs(psi_g[i_out])\n    denom_typ = abs(psi_g[i_typ])\n    ratio_out = float(abs(psi_t[i_out]) / denom_out) if denom_out != 0.0 else float(\"nan\")\n    ratio_typ = float(abs(psi_t[i_typ]) / denom_typ) if denom_typ != 0.0 else float(\"nan\")\n\n    return [g_t_norm, g_g_norm, ratio_out, ratio_typ]\n\ndef solve():\n    # Define the test cases from the problem statement: (nu, delta_out)\n    test_cases = [\n        (3.0, 1.5),   # Case A\n        (30.0, 1.5),  # Case B\n        (1.0, 1.5),   # Case C\n        (3.0, 0.0),   # Case D\n    ]\n\n    results = []\n    for nu, delta_out in test_cases:\n        result = run_case(nu, delta_out)\n        # Optionally round to a reasonable number of decimals for stable textual output\n        rounded = [round(x, 10) if isinstance(x, float) and np.isfinite(x) else x for x in result]\n        results.append(rounded)\n\n    # Format as required: single line, list of lists, comma-separated, no extra spaces\n    def fmt_list(lst):\n        return \"[\" + \",\".join(str(x) for x in lst) + \"]\"\n    out = \"[\" + \",\".join(fmt_list(r) for r in results) + \"]\"\n    print(out)\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3389148"}]}