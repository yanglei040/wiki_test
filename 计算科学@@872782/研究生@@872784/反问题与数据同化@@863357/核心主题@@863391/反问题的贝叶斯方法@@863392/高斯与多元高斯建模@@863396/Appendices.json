{"hands_on_practices": [{"introduction": "本练习 ([@problem_id:3384489]) 提供了一个具体的低维示例，引导你完整地走一遍贝叶斯更新的力学过程。通过手工计算后验均值和协方差，你将对先验信息如何与数据相结合形成后验估计获得切实的理解。这个基础计算是掌握更复杂数据同化方案的基石。", "problem": "考虑一个线性高斯数据同化框架下的线性反问题。设未知参数向量为 $m \\in \\mathbb{R}^{2}$，其高斯先验为 $m \\sim \\mathcal{N}(m_{0}, C_{0})$，观测模型为 $y = G m + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, \\Gamma)$ 且独立于 $m$。给定\n$$\nm_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}, \\quad\nC_{0} = \\begin{pmatrix} 1.2  0 \\\\ 0  0.8 \\end{pmatrix}, \\quad\nG = \\begin{pmatrix} 1  -0.5 \\\\ 0.2  1.5 \\end{pmatrix}, \\quad\n\\Gamma = \\begin{pmatrix} 0.5  0.1 \\\\ 0.1  0.2 \\end{pmatrix}, \\quad\ny = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}.\n$$\n从贝叶斯定理和高斯密度的二次型出发，通过对负对数后验进行配方，推导出后验分布 $m \\mid y \\sim \\mathcal{N}(m_{\\text{post}}, C_{\\text{post}})$。然后，使用给定的数值矩阵，显式计算 $m_{\\text{post}}$ 和 $C_{\\text{post}}$。验证 $C_{\\text{post}}$ 是对称正定（SPD）的，例如通过检查其顺序主子式的正性。最后，报告标量\n$$\ns \\equiv \\ln\\!\\big(\\det(C_{\\text{post}})\\big).\n$$\n将您最终报告的 $s$ 值四舍五入到 $4$ 位有效数字。最终答案以无单位的纯数表示。", "solution": "### 后验分布的推导\n根据贝叶斯定理，后验概率密度函数（PDF）$p(m|y)$ 正比于似然 $p(y|m)$ 和先验 $p(m)$ 的乘积：\n$$p(m|y) \\propto p(y|m) p(m)$$\n先验分布给定为 $m \\sim \\mathcal{N}(m_0, C_0)$，所以其 PDF 的形式为：\n$$p(m) \\propto \\exp\\left(-\\frac{1}{2}(m-m_0)^T C_0^{-1} (m-m_0)\\right)$$\n观测模型 $y = Gm + \\epsilon$ 及 $\\epsilon \\sim \\mathcal{N}(0, \\Gamma)$ 意味着在给定 $m$ 的条件下，$y$ 的条件分布为 $y|m \\sim \\mathcal{N}(Gm, \\Gamma)$。因此，似然函数为：\n$$p(y|m) \\propto \\exp\\left(-\\frac{1}{2}(y-Gm)^T \\Gamma^{-1} (y-Gm)\\right)$$\n结合以上两点，后验 PDF 为：\n$$p(m|y) \\propto \\exp\\left(-\\frac{1}{2}(y-Gm)^T \\Gamma^{-1} (y-Gm) - \\frac{1}{2}(m-m_0)^T C_0^{-1} (m-m_0)\\right)$$\n后验分布也是高斯分布，所以其 PDF 的形式为 $p(m|y) \\propto \\exp\\left(-\\frac{1}{2}(m-m_{\\text{post}})^T C_{\\text{post}}^{-1} (m-m_{\\text{post}})\\right)$。负对数后验（不计加性常数）是二次型 $J(m)$：\n$$J(m) = \\frac{1}{2}(y-Gm)^T \\Gamma^{-1} (y-Gm) + \\frac{1}{2}(m-m_0)^T C_0^{-1} (m-m_0)$$\n我们展开 $J(m)$ 中的各项，并收集关于 $m$ 的二次项和线性项：\n$$2J(m) = (y^T - m^T G^T) \\Gamma^{-1} (y - Gm) + (m^T - m_0^T) C_0^{-1} (m - m_0)$$\n$$2J(m) = y^T \\Gamma^{-1} y - y^T \\Gamma^{-1} Gm - m^T G^T \\Gamma^{-1} y + m^T G^T \\Gamma^{-1} Gm + m^T C_0^{-1} m - m^T C_0^{-1} m_0 - m_0^T C_0^{-1} m + m_0^T C_0^{-1} m_0$$\n注意到标量项 $y^T \\Gamma^{-1} Gm$ 和 $m^T C_0^{-1} m_0$ 等于其自身的转置，合并同类项可得：\n$$2J(m) = m^T (G^T \\Gamma^{-1} G + C_0^{-1}) m - 2 m^T (G^T \\Gamma^{-1} y + C_0^{-1} m_0) + \\text{const.}$$\n通过配方法，我们可以确定后验精度矩阵 $C_{\\text{post}}^{-1}$ 和后验均值 $m_{\\text{post}}$。与一般二次型 $ (m-m_{\\text{post}})^T C_{\\text{post}}^{-1} (m-m_{\\text{post}}) = m^T C_{\\text{post}}^{-1} m - 2m^T C_{\\text{post}}^{-1} m_{\\text{post}} + \\text{const.}$ 进行比较，我们发现：\n$$C_{\\text{post}}^{-1} = C_0^{-1} + G^T \\Gamma^{-1} G$$\n$$C_{\\text{post}}^{-1} m_{\\text{post}} = C_0^{-1} m_0 + G^T \\Gamma^{-1} y$$\n由此，我们得到后验协方差矩阵和均值向量：\n$$C_{\\text{post}} = (C_0^{-1} + G^T \\Gamma^{-1} G)^{-1}$$\n$$m_{\\text{post}} = C_{\\text{post}} (C_0^{-1} m_0 + G^T \\Gamma^{-1} y)$$\n\n### 数值计算\n给定：\n$m_{0} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$, $C_{0} = \\begin{pmatrix} 1.2  0 \\\\ 0  0.8 \\end{pmatrix}$, $G = \\begin{pmatrix} 1  -0.5 \\\\ 0.2  1.5 \\end{pmatrix}$, $\\Gamma = \\begin{pmatrix} 0.5  0.1 \\\\ 0.1  0.2 \\end{pmatrix}$, $y = \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix}$.\n\n首先，我们计算逆矩阵 $C_0^{-1}$ 和 $\\Gamma^{-1}$：\n$$C_0^{-1} = \\begin{pmatrix} \\frac{1}{1.2}  0 \\\\ 0  \\frac{1}{0.8} \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{6}  0 \\\\ 0  \\frac{5}{4} \\end{pmatrix}$$\n$$\\det(\\Gamma) = (0.5)(0.2) - (0.1)^2 = 0.1 - 0.01 = 0.09 = \\frac{9}{100}$$\n$$\\Gamma^{-1} = \\frac{1}{0.09} \\begin{pmatrix} 0.2  -0.1 \\\\ -0.1  0.5 \\end{pmatrix} = \\frac{100}{9} \\begin{pmatrix} \\frac{2}{10}  -\\frac{1}{10} \\\\ -\\frac{1}{10}  \\frac{5}{10} \\end{pmatrix} = \\frac{10}{9} \\begin{pmatrix} 2  -1 \\\\ -1  5 \\end{pmatrix} = \\begin{pmatrix} \\frac{20}{9}  -\\frac{10}{9} \\\\ -\\frac{10}{9}  \\frac{50}{9} \\end{pmatrix}$$\n接下来，我们计算海森项 $G^T\\Gamma^{-1}G$：\n$$G^T = \\begin{pmatrix} 1  0.2 \\\\ -0.5  1.5 \\end{pmatrix} = \\begin{pmatrix} 1  \\frac{1}{5} \\\\ -\\frac{1}{2}  \\frac{3}{2} \\end{pmatrix}$$\n$$G^T \\Gamma^{-1} = \\begin{pmatrix} 1  \\frac{1}{5} \\\\ -\\frac{1}{2}  \\frac{3}{2} \\end{pmatrix} \\begin{pmatrix} \\frac{20}{9}  -\\frac{10}{9} \\\\ -\\frac{10}{9}  \\frac{50}{9} \\end{pmatrix} = \\begin{pmatrix} \\frac{20}{9} - \\frac{2}{9}  -\\frac{10}{9} + \\frac{10}{9} \\\\ -\\frac{10}{9} - \\frac{15}{9}  \\frac{5}{9} + \\frac{75}{9} \\end{pmatrix} = \\begin{pmatrix} \\frac{18}{9}  0 \\\\ -\\frac{25}{9}  \\frac{80}{9} \\end{pmatrix} = \\begin{pmatrix} 2  0 \\\\ -\\frac{25}{9}  \\frac{80}{9} \\end{pmatrix}$$\n$$G^T \\Gamma^{-1} G = \\begin{pmatrix} 2  0 \\\\ -\\frac{25}{9}  \\frac{80}{9} \\end{pmatrix} \\begin{pmatrix} 1  -\\frac{1}{2} \\\\ \\frac{1}{5}  \\frac{3}{2} \\end{pmatrix} = \\begin{pmatrix} 2  -1 \\\\ -\\frac{25}{9} + \\frac{16}{9}  \\frac{25}{18} + \\frac{120}{9} \\end{pmatrix} = \\begin{pmatrix} 2  -1 \\\\ -1  \\frac{25}{18} + \\frac{240}{18} \\end{pmatrix} = \\begin{pmatrix} 2  -1 \\\\ -1  \\frac{265}{18} \\end{pmatrix}$$\n现在我们计算后验精度矩阵 $C_{\\text{post}}^{-1}$：\n$$C_{\\text{post}}^{-1} = C_0^{-1} + G^T \\Gamma^{-1} G = \\begin{pmatrix} \\frac{5}{6}  0 \\\\ 0  \\frac{5}{4} \\end{pmatrix} + \\begin{pmatrix} 2  -1 \\\\ -1  \\frac{265}{18} \\end{pmatrix} = \\begin{pmatrix} \\frac{5}{6} + \\frac{12}{6}  -1 \\\\ -1  \\frac{45}{36} + \\frac{530}{36} \\end{pmatrix} = \\begin{pmatrix} \\frac{17}{6}  -1 \\\\ -1  \\frac{575}{36} \\end{pmatrix}$$\n为了求得 $C_{\\text{post}}$，我们对 $C_{\\text{post}}^{-1}$ 求逆：\n$$\\det(C_{\\text{post}}^{-1}) = \\left(\\frac{17}{6}\\right)\\left(\\frac{575}{36}\\right) - (-1)^2 = \\frac{9775}{216} - 1 = \\frac{9775 - 216}{216} = \\frac{9559}{216}$$\n$$C_{\\text{post}} = \\frac{1}{\\det(C_{\\text{post}}^{-1})} \\begin{pmatrix} \\frac{575}{36}  1 \\\\ 1  \\frac{17}{6} \\end{pmatrix} = \\frac{216}{9559} \\begin{pmatrix} \\frac{575}{36}  1 \\\\ 1  \\frac{17}{6} \\end{pmatrix} = \\frac{1}{9559} \\begin{pmatrix} 6 \\cdot 575  216 \\\\ 216  36 \\cdot 17 \\end{pmatrix}$$\n$$C_{\\text{post}} = \\frac{1}{9559} \\begin{pmatrix} 3450  216 \\\\ 216  612 \\end{pmatrix}$$\n现在我们计算 $m_{\\text{post}}$。由于 $m_0 = 0$，公式简化为 $m_{\\text{post}} = C_{\\text{post}} (G^T \\Gamma^{-1} y)$。\n$$G^T \\Gamma^{-1} y = \\begin{pmatrix} 2  0 \\\\ -\\frac{25}{9}  \\frac{80}{9} \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -\\frac{25}{9} \\end{pmatrix}$$\n$$m_{\\text{post}} = C_{\\text{post}} \\begin{pmatrix} 2 \\\\ -\\frac{25}{9} \\end{pmatrix} = \\frac{1}{9559} \\begin{pmatrix} 3450  216 \\\\ 216  612 \\end{pmatrix} \\begin{pmatrix} 2 \\\\ -\\frac{25}{9} \\end{pmatrix} = \\frac{1}{9559} \\begin{pmatrix} 3450(2) + 216(-\\frac{25}{9}) \\\\ 216(2) + 612(-\\frac{25}{9}) \\end{pmatrix}$$\n$$m_{\\text{post}} = \\frac{1}{9559} \\begin{pmatrix} 6900 - 24(25) \\\\ 432 - 68(25) \\end{pmatrix} = \\frac{1}{9559} \\begin{pmatrix} 6900 - 600 \\\\ 432 - 1700 \\end{pmatrix} = \\frac{1}{9559} \\begin{pmatrix} 6300 \\\\ -1268 \\end{pmatrix}$$\n用小数形式表示，即为 $m_{\\text{post}} \\approx \\begin{pmatrix} 0.65906 \\\\ -0.13265 \\end{pmatrix}$。\n\n### 对 $C_{\\text{post}}$ 的验证\n- **对称性：** 矩阵 $C_{\\text{post}} = \\frac{1}{9559} \\begin{pmatrix} 3450  216 \\\\ 216  612 \\end{pmatrix}$ 的非对角元素相等，因此显然是对称的。\n- **正定性：** 我们检查其顺序主子式。\n第一个主子式是 $C_{\\text{post},11} = \\frac{3450}{9559} > 0$。\n第二个主子式是 $\\det(C_{\\text{post}})$。我们知道 $\\det(C_{\\text{post}}) = (\\det(C_{\\text{post}}^{-1}))^{-1}$。由于 $\\det(C_{\\text{post}}^{-1}) = \\frac{9559}{216} > 0$，我们有 $\\det(C_{\\text{post}}) = \\frac{216}{9559} > 0$。\n由于所有顺序主子式均为正，因此 $C_{\\text{post}}$ 是对称正定的。\n\n### 计算 $s$\n最后要计算的标量是 $s \\equiv \\ln(\\det(C_{\\text{post}}))$。\n$$s = \\ln\\left(\\frac{216}{9559}\\right)$$\n使用计算器：\n$$s \\approx \\ln(0.0225965059...) \\approx -3.78994114...$$\n四舍五入到 $4$ 位有效数字，我们得到：\n$$s \\approx -3.790$$", "answer": "$$\\boxed{-3.790}$$", "id": "3384489"}, {"introduction": "在实际应用中，传感器网络的测量误差往往是相关的。本编程练习 ([@problem_id:3384513]) 旨在探讨忽略这些相关性的后果，这是一种常见但有潜在风险的简化。通过量化这种简化假设所引入的系统性偏差，你将认识到在构建高斯模型时准确指定观测误差协方差矩阵 $\\Gamma$ 的重要性。", "problem": "给定一个线性反问题，其先验为多元高斯分布，似然也为多元高斯分布。正向映射是线性的，状态是有限维的，且观测误差表现出已知的互相关性。您必须通过两种方式推导后验分布：(i) 使用包含非对角项的完整观测误差协方差；(ii) 使用相同的协方差，但将所有非对角项置零（仅对角项）。然后，您必须量化因忽略非对角项而引入的系统偏差。\n\n从以下基本设定开始：\n- 未知状态向量 $x \\in \\mathbb{R}^{n}$ 的先验分布为 $\\mathcal{N}(m_0, C_0)$，其中 $m_0 \\in \\mathbb{R}^{n}$ 且 $C_0 \\in \\mathbb{R}^{n \\times n}$ 是对称正定矩阵。\n- 数据模型（似然）为 $y = H x + \\varepsilon$，其中 $H \\in \\mathbb{R}^{m \\times n}$ 是已知矩阵，$\\varepsilon \\sim \\mathcal{N}(0, \\Gamma)$，$\\Gamma \\in \\mathbb{R}^{m \\times m}$ 是对称正定矩阵，并编码了已知的传感器误差互相关性。\n- 高斯先验和高斯似然的贝叶斯法则，以及配方法会产生高斯后验这一事实。\n\n任务：\n1. 从第一性原理出发，使用完整的观测误差协方差 $\\Gamma$（包含非对角项）推导线性高斯反问题的后验均值和协方差。\n2. 在将协方差替换为其仅对角版本 $\\Gamma_{\\mathrm{diag}}$（通过将所有非对角项置零同时保留原始对角项形成）的情况下，重复此推导。\n3. 定义一个固定的基准真相状态 $x^{\\ast} \\in \\mathbb{R}^{n}$。将忽略非对角项所引起的系统偏差定义为期望后验均值之差（期望是关于观测噪声 $\\varepsilon$ 在给定 $x^{\\ast}$ 条件下计算的）：\n$$\nb \\equiv \\mathbb{E}\\big[m_{\\mathrm{post}}^{\\mathrm{diag}}(y) \\,\\big|\\, x^{\\ast} \\big] - \\mathbb{E}\\big[m_{\\mathrm{post}}^{\\mathrm{full}}(y) \\,\\big|\\, x^{\\ast} \\big] \\in \\mathbb{R}^{n}.\n$$\n您必须为下方的每个测试案例计算欧几里得范数 $\\|b\\|_{2}$。为进行此计算，请注意 $\\mathbb{E}[y \\mid x^{\\ast}] = H x^{\\ast}$。\n\n测试套件：\n为以下四个测试案例提供数值答案。在每个案例中，通过将非对角项置零并保持对角线上的原始方差来构造仅对角协方差 $\\Gamma_{\\mathrm{diag}} = \\operatorname{diag}(\\operatorname{diag}(\\Gamma))$。\n\n- 案例 A：\n  - 状态维度 $n = 2$，观测维度 $m = 2$。\n  - 正向算子：\n    $$\n    H = \\begin{bmatrix}\n    1.0  0.5 \\\\\n    0.2  1.0\n    \\end{bmatrix}.\n    $$\n  - 先验均值和协方差：\n    $$\n    m_0 = \\begin{bmatrix} 0.1 \\\\ -0.2 \\end{bmatrix}, \\quad\n    C_0 = \\begin{bmatrix} 1.0  0.3 \\\\ 0.3  1.5 \\end{bmatrix}.\n    $$\n  - 基准真相：\n    $$\n    x^{\\ast} = \\begin{bmatrix} 0.7 \\\\ -1.2 \\end{bmatrix}.\n    $$\n  - 观测误差协方差（不相关）：\n    $$\n    \\Gamma = \\begin{bmatrix} 0.04  0.0 \\\\ 0.0  0.09 \\end{bmatrix}.\n    $$\n\n- 案例 B：\n  - 与案例 A 相同的 $n$、$m$、$H$、$m_0$、$C_0$ 和 $x^{\\ast}$。\n  - 观测误差协方差（正相关传感器）：\n    $$\n    \\Gamma = \\begin{bmatrix} 0.04  0.048 \\\\ 0.048  0.09 \\end{bmatrix}.\n    $$\n\n- 案例 C：\n  - 与案例 A 相同的 $n$、$m$、$H$、$m_0$、$C_0$ 和 $x^{\\ast}$。\n  - 观测误差协方差（强相关传感器）：\n    $$\n    \\Gamma = \\begin{bmatrix} 0.04  0.0594 \\\\ 0.0594  0.09 \\end{bmatrix}.\n    $$\n\n- 案例 D：\n  - 状态维度 $n = 2$，观测维度 $m = 3$。\n  - 正向算子：\n    $$\n    H = \\begin{bmatrix}\n    1.0  0.1 \\\\\n    0.5  1.0 \\\\\n    -0.2  0.7\n    \\end{bmatrix}.\n    $$\n  - 先验均值和协方差：\n    $$\n    m_0 = \\begin{bmatrix} 0.0 \\\\ 0.0 \\end{bmatrix}, \\quad\n    C_0 = \\begin{bmatrix} 2.0  0.4 \\\\ 0.4  0.5 \\end{bmatrix}.\n    $$\n  - 基准真相：\n    $$\n    x^{\\ast} = \\begin{bmatrix} 1.5 \\\\ -0.5 \\end{bmatrix}.\n    $$\n  - 具有托普利兹相关的观测误差协方差：\n    设标准差为 $\\sigma = \\begin{bmatrix} 0.05  0.08  0.06 \\end{bmatrix}^{\\top}$ 且相关矩阵为\n    $$\n    R = \\begin{bmatrix}\n    1  \\rho  \\rho^{2} \\\\\n    \\rho  1  \\rho \\\\\n    \\rho^{2}  \\rho  1\n    \\end{bmatrix}, \\quad \\text{其中 } \\rho = 0.6.\n    $$\n    则\n    $$\n    \\Gamma = \\operatorname{diag}(\\sigma) \\, R \\, \\operatorname{diag}(\\sigma).\n    $$\n\n实现与输出要求：\n- 对于每个案例，分别使用完整的 $\\Gamma$ 和仅对角的 $\\Gamma_{\\mathrm{diag}}$ 计算后验分布，然后使用 $\\mathbb{E}[y \\mid x^{\\ast}] = H x^{\\ast}$ 计算如上定义的偏差向量 $b$，最后计算 $\\|b\\|_{2}$。\n- 您的程序必须输出一行，其中包含案例 A、B、C、D 的结果，按顺序排列，形式为方括号内以逗号分隔的列表，每个值四舍五入到 $10$ 位小数，例如：\n  $$\n  [\\text{value\\_A}, \\text{value\\_B}, \\text{value\\_C}, \\text{value\\_D}].\n  $$\n\n不涉及物理单位。不使用角度。不使用百分比。最终输出为实数（浮点数）。", "solution": "问题的核心在于推导和比较由线性高斯模型产生的后验分布。后验概率密度函数 $p(x|y)$ 由贝叶斯法则给出：\n$$\np(x|y) \\propto p(y|x) p(x)\n$$\n其中 $p(y|x)$ 是似然，$p(x)$ 是先验。\n\n状态向量 $x \\in \\mathbb{R}^{n}$ 的先验分布是多元高斯分布 $\\mathcal{N}(m_0, C_0)$：\n$$\np(x) \\propto \\exp\\left(-\\frac{1}{2}(x - m_0)^\\top C_0^{-1} (x - m_0)\\right)\n$$\n数据模型为 $y = Hx + \\varepsilon$，其中噪声 $\\varepsilon$ 是均值为零、协方差为 $\\Gamma$ 的高斯分布，即 $\\varepsilon \\sim \\mathcal{N}(0, \\Gamma)$。这意味着在给定状态 $x$ 的条件下观测到 $y$ 的似然为：\n$$\np(y|x) = \\mathcal{N}(Hx, \\Gamma) \\propto \\exp\\left(-\\frac{1}{2}(y - Hx)^\\top \\Gamma^{-1} (y - Hx)\\right)\n$$\n由于先验和似然都是高斯分布，后验分布也将是高斯分布。为求其参数，我们合并先验和似然的指数部分。后验概率的负对数与成本函数 $J(x)$ 成正比：\n$$\nJ(x) = \\frac{1}{2}(x - m_0)^\\top C_0^{-1} (x - m_0) + \\frac{1}{2}(y - Hx)^\\top \\Gamma^{-1} (y - Hx)\n$$\n我们展开 $J(x)$ 中的二次型，通过“配方法”来确定后验均值和协方差。\n$$\n2J(x) = (x - m_0)^\\top C_0^{-1} (x - m_0) + (y - Hx)^\\top \\Gamma^{-1} (y - Hx)\n$$\n$$\n2J(x) = x^\\top C_0^{-1} x - 2x^\\top C_0^{-1} m_0 + m_0^\\top C_0^{-1} m_0 + y^\\top \\Gamma^{-1} y - 2y^\\top \\Gamma^{-1} Hx + x^\\top H^\\top \\Gamma^{-1} Hx\n$$\n按 $x$ 的幂次对各项进行分组：\n$$\n2J(x) = x^\\top (C_0^{-1} + H^\\top \\Gamma^{-1} H) x - 2x^\\top (C_0^{-1} m_0 + H^\\top \\Gamma^{-1} y) + (\\text{不含 } x \\text{ 的项})\n$$\n后验分布 $p(x|y)$ 的形式为 $\\mathcal{N}(m_{\\mathrm{post}}, C_{\\mathrm{post}})$，其指数为 $\\frac{1}{2}(x - m_{\\mathrm{post}})^\\top C_{\\mathrm{post}}^{-1} (x - m_{\\mathrm{post}})$。展开此式可得：\n$$\n(x - m_{\\mathrm{post}})^\\top C_{\\mathrm{post}}^{-1} (x - m_{\\mathrm{post}}) = x^\\top C_{\\mathrm{post}}^{-1} x - 2x^\\top C_{\\mathrm{post}}^{-1} m_{\\mathrm{post}} + m_{\\mathrm{post}}^\\top C_{\\mathrm{post}}^{-1} m_{\\mathrm{post}}\n$$\n通过比较 $2J(x)$ 和后验指数中关于 $x$ 的二次项和线性项，我们便可确定后验协方差的逆和后验均值。\n\n**1. 完整模型的后验推导 (任务 1)**\n\n使用完整观测误差协方差 $\\Gamma$ 的模型的后验参数可通过直接比较得到。\n二次项给出了后验协方差的逆 $C_{\\mathrm{post}}^{\\mathrm{full}}{}^{-1}$：\n$$\nC_{\\mathrm{post}}^{\\mathrm{full}}{}^{-1} = C_0^{-1} + H^\\top \\Gamma^{-1} H\n$$\n因此，后验协方差为：\n$$\nC_{\\mathrm{post}}^{\\mathrm{full}} = (C_0^{-1} + H^\\top \\Gamma^{-1} H)^{-1}\n$$\n线性项给出了后验均值 $m_{\\mathrm{post}}^{\\mathrm{full}}$：\n$$\nC_{\\mathrm{post}}^{\\mathrm{full}}{}^{-1} m_{\\mathrm{post}}^{\\mathrm{full}} = C_0^{-1} m_0 + H^\\top \\Gamma^{-1} y\n$$\n$$\nm_{\\mathrm{post}}^{\\mathrm{full}}(y) = C_{\\mathrm{post}}^{\\mathrm{full}} (C_0^{-1} m_0 + H^\\top \\Gamma^{-1} y)\n$$\n\n**2. 仅对角模型的后验推导 (任务 2)**\n\n对于简化模型，我们将真实协方差 $\\Gamma$ 替换为其对角近似 $\\Gamma_{\\mathrm{diag}}$，该近似是通过将 $\\Gamma$ 的所有非对角元素置零而形成的。推导过程完全相同，只是将 $\\Gamma$ 替换为 $\\Gamma_{\\mathrm{diag}}$。\n后验协方差为：\n$$\nC_{\\mathrm{post}}^{\\mathrm{diag}} = (C_0^{-1} + H^\\top \\Gamma_{\\mathrm{diag}}^{-1} H)^{-1}\n$$\n后验均值为：\n$$\nm_{\\mathrm{post}}^{\\mathrm{diag}}(y) = C_{\\mathrm{post}}^{\\mathrm{diag}} (C_0^{-1} m_0 + H^\\top \\Gamma_{\\mathrm{diag}}^{-1} y)\n$$\n\n**3. 系统偏差的推导 (任务 3)**\n\n系统偏差 $b$ 被定义为期望后验均值之差，其中期望是针对以基准真相状态 $x^{\\ast}$ 为条件的观测值 $y$ 的分布计算的。\n$$\nb \\equiv \\mathbb{E}\\big[m_{\\mathrm{post}}^{\\mathrm{diag}}(y) \\,\\big|\\, x^{\\ast} \\big] - \\mathbb{E}\\big[m_{\\mathrm{post}}^{\\mathrm{full}}(y) \\,\\big|\\, x^{\\ast} \\big]\n$$\n后验均值是观测值 $y$ 的线性函数。在给定 $x^{\\ast}$ 条件下 $y$ 的期望为 $\\mathbb{E}[y \\mid x^{\\ast}] = Hx^{\\ast}$。我们将此期望观测值记为 $y^{\\ast} = Hx^{\\ast}$。根据期望的线性性质：\n$$\n\\mathbb{E}\\big[m_{\\mathrm{post}}(y) \\mid x^{\\ast}\\big] = m_{\\mathrm{post}}(\\mathbb{E}[y \\mid x^{\\ast}]) = m_{\\mathrm{post}}(y^{\\ast})\n$$\n将此应用于我们的后验均值表达式：\n$$\n\\mathbb{E}\\big[m_{\\mathrm{post}}^{\\mathrm{full}}(y) \\mid x^{\\ast}\\big] = C_{\\mathrm{post}}^{\\mathrm{full}} (H^\\top \\Gamma^{-1} y^{\\ast} + C_0^{-1} m_0)\n$$\n$$\n\\mathbb{E}\\big[m_{\\mathrm{post}}^{\\mathrm{diag}}(y) \\mid x^{\\ast}\\big] = C_{\\mathrm{post}}^{\\mathrm{diag}} (H^\\top \\Gamma_{\\mathrm{diag}}^{-1} y^{\\ast} + C_0^{-1} m_0)\n$$\n因此，偏差向量 $b$ 为：\n$$\nb = C_{\\mathrm{post}}^{\\mathrm{diag}} (H^\\top \\Gamma_{\\mathrm{diag}}^{-1} Hx^{\\ast} + C_0^{-1} m_0) - C_{\\mathrm{post}}^{\\mathrm{full}} (H^\\top \\Gamma^{-1} Hx^{\\ast} + C_0^{-1} m_0)\n$$\n可以使用卡尔曼增益公式推导出 $b$ 的一个计算上更稳定的替代表达式。后验均值可以写成 $m_{\\mathrm{post}}(y) = m_0 + K(y - Hm_0)$，其中 $K = C_0 H^\\top (H C_0 H^\\top + \\Gamma)^{-1}$ 是卡尔曼增益。期望后验均值变为 $m_0 + K(Hx^{\\ast} - Hm_0)$。则偏差为：\n$$\nb = (K_{\\mathrm{diag}} - K_{\\mathrm{full}})(Hx^{\\ast} - Hm_0)\n$$\n其中 $K_{\\mathrm{full}} = C_0 H^\\top (H C_0 H^\\top + \\Gamma)^{-1}$ 且 $K_{\\mathrm{diag}} = C_0 H^\\top (H C_0 H^\\top + \\Gamma_{\\mathrm{diag}})^{-1}$。此公式避免了对 $n \\times n$ 矩阵的多次求逆，并在实现中使用。最终需要计算的量是此偏差向量的欧几里得范数 $\\|b\\|_2$。\n对于案例 A，$\\Gamma$ 本身就是对角矩阵，所以 $\\Gamma = \\Gamma_{\\mathrm{diag}}$。这意味着 $K_{\\mathrm{full}} = K_{\\mathrm{diag}}$，从而导致偏差 $b=0$，这可作为对该公式的成功合理性检查。对于案例 B、C 和 D，其中 $\\Gamma \\neq \\Gamma_{\\mathrm{diag}}$，预计会产生非零偏差。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef compute_bias_norm(H, m_0, C_0, x_star, Gamma):\n    \"\"\"\n    Computes the Euclidean norm of the systematic bias vector.\n\n    The bias is induced by ignoring off-diagonal terms in the observation-error\n    covariance matrix Gamma. This function uses the Kalman gain formulation for\n    numerical stability and efficiency.\n\n    Args:\n        H (np.ndarray): The forward operator matrix.\n        m_0 (np.ndarray): The prior mean vector.\n        C_0 (np.ndarray): The prior covariance matrix.\n        x_star (np.ndarray): The ground-truth state vector.\n        Gamma (np.ndarray): The observation-error covariance matrix.\n\n    Returns:\n        float: The Euclidean norm of the bias vector b.\n    \"\"\"\n    # 1. Form the diagonal-only version of the observation-error covariance\n    Gamma_diag = np.diag(np.diag(Gamma))\n\n    # 2. Compute the Kalman gains for both the full and diagonal models\n    # Innovation covariance S = H * C_0 * H^T + Gamma\n    S_full = H @ C_0 @ H.T + Gamma\n    S_diag = H @ C_0 @ H.T + Gamma_diag\n\n    # Kalman gain K = C_0 * H^T * S^-1\n    # We use np.linalg.solve for better numerical stability than np.linalg.inv\n    # K_full = C_0 @ H.T @ np.linalg.inv(S_full)\n    # K_diag = C_0 @ H.T @ np.linalg.inv(S_diag)\n    \n    # Let's solve K = (S^T \\ (H C_0^T))^T = (S^T \\ H C_0)^T because C0 is symmetric\n    # This avoids forming the inverse explicitly.\n    term_to_solve = H @ C_0\n    K_full = np.linalg.solve(S_full.T, term_to_solve).T\n    K_diag = np.linalg.solve(S_diag.T, term_to_solve).T\n\n    # 3. Calculate the expected innovation term based on the ground truth x_star\n    # This is E[y - H*m_0] = H*x_star - H*m_0 = H * (x_star - m_0)\n    innovation_term = H @ (x_star - m_0)\n\n    # 4. Calculate the bias vector b = (K_diag - K_full) * innovation\n    b = (K_diag - K_full) @ innovation_term\n\n    # 5. Return the Euclidean norm of the bias vector\n    return np.linalg.norm(b)\n\ndef solve():\n    \"\"\"\n    Defines the four test cases from the problem statement and computes the\n    bias norm for each, printing the results in the required format.\n    \"\"\"\n    \n    # --- Case A ---\n    H_A = np.array([[1.0, 0.5], [0.2, 1.0]])\n    m0_A = np.array([0.1, -0.2])\n    C0_A = np.array([[1.0, 0.3], [0.3, 1.5]])\n    x_star_A = np.array([0.7, -1.2])\n    Gamma_A = np.array([[0.04, 0.0], [0.0, 0.09]])\n    \n    # --- Case B ---\n    # Parameters are the same as Case A, except for Gamma\n    Gamma_B = np.array([[0.04, 0.048], [0.048, 0.09]])\n    \n    # --- Case C ---\n    # Parameters are the same as Case A, except for Gamma\n    Gamma_C = np.array([[0.04, 0.0594], [0.0594, 0.09]])\n\n    # --- Case D ---\n    H_D = np.array([[1.0, 0.1], [0.5, 1.0], [-0.2, 0.7]])\n    m0_D = np.array([0.0, 0.0])\n    C0_D = np.array([[2.0, 0.4], [0.4, 0.5]])\n    x_star_D = np.array([1.5, -0.5])\n    sigma_D = np.array([0.05, 0.08, 0.06])\n    rho_D = 0.6\n    R_D = np.array([[1.0, rho_D, rho_D**2],\n                    [rho_D, 1.0, rho_D],\n                    [rho_D**2, rho_D, 1.0]])\n    Gamma_D = np.diag(sigma_D) @ R_D @ np.diag(sigma_D)\n\n    test_cases = [\n        (H_A, m0_A, C0_A, x_star_A, Gamma_A),\n        (H_A, m0_A, C0_A, x_star_A, Gamma_B),\n        (H_A, m0_A, C0_A, x_star_A, Gamma_C),\n        (H_D, m0_D, C0_D, x_star_D, Gamma_D)\n    ]\n\n    results = []\n    for case in test_cases:\n        H, m_0, C_0, x_star, Gamma = case\n        bias_norm = compute_bias_norm(H, m_0, C_0, x_star, Gamma)\n        results.append(f\"{bias_norm:.10f}\")\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(results)}]\")\n\nsolve()\n```", "id": "3384513"}, {"introduction": "对于现实世界中的高维系统，显式地构建和求逆密集的协方差矩阵在计算上是不可行的。本高级练习 ([@problem_id:3384561]) 将介绍强大的无矩阵方法，使用克雷洛夫子空间法（如预条件共轭梯度法和兰索斯方法）来进行后验分析。通过这个实践，你将学习到如何将高斯模型应用于前沿的大规模数据同化问题中，这对于解决实际工程和科学挑战至关重要。", "problem": "给定一个一维网格上的线性高斯逆问题，其中未知场被建模为零均值高斯随机场，并带有带噪声的点观测值。先验模型由一个对称正定精度算子指定。似然来自于点限制，并带有独立的高斯噪声。您的任务是设计并实现一种无矩阵算法，以计算后验协方差对向量的作用，并使用Krylov子空间方法从后验分布中抽取近似样本，而无需构建稠密矩阵。\n\n设未知场存在于一个有 $n$ 个点的均匀网格上。未知量记为 $x \\in \\mathbb{R}^n$，其先验为 $x \\sim \\mathcal{N}(0, C_{\\text{prior}})$，精度为 $Q = C_{\\text{prior}}^{-1}$。观测值建模为 $y = A x + \\eta$，其中 $A \\in \\mathbb{R}^{m \\times n}$ 是一个对 $m$ 个网格位置进行采样的限制算子，$\\eta \\sim \\mathcal{N}(0, \\Gamma)$，其中 $\\Gamma = \\sigma^2 I_m$。\n\n根据线性逆问题中的高斯后验定律，后验分布是高斯的，其精度由下式给出：\n$$\nH \\equiv Q + A^\\top \\Gamma^{-1} A,\n$$\n后验协方差为 $C_{\\text{post}} = H^{-1}$。本任务中要求的输出依赖于以无矩阵方式计算以下两个操作：\n1. 后验协方差对向量 $v \\in \\mathbb{R}^n$ 的作用，即计算 $C_{\\text{post}} v$，这是对称正定系统 $H w = v$ 的解 $w$。\n2. 对于给定的 $z \\in \\mathbb{R}^n$ 且 $z \\sim \\mathcal{N}(0, I_n)$，通过对算子函数 $H^{-1/2}$ 应用于 $z$ 的Lanczos近似，得到一个近似的后验样本 $s \\approx C_{\\text{post}}^{1/2} z$。\n\n您必须遵守以下建模细节和算法约束：\n- 先验精度 $Q$ 是一维离散负拉普拉斯算子，带有诺伊曼（Neumann）边界条件，外加一个逐点质量项。在一个间距为 $h$ 的均匀网格上，对每个分量 $i \\in \\{0, 1, \\dots, n-1\\}$ 定义：\n$$\n(Q x)_i = \\lambda \\left( \\frac{2 x_i - x_{i-1} - x_{i+1}}{h^2} + \\beta x_i \\right),\n$$\n边界值采用镜像方式，$x_{-1} = x_0$ 且 $x_{n} = x_{n-1}$，参数为 $\\lambda  0$ 和 $\\beta  0$。\n- 观测算子 $A$ 是在一组固定的索引 $\\mathcal{I} \\subset \\{0, 1, \\dots, n-1\\}$（基数为 $m$）上的逐点限制，因此 $A x \\in \\mathbb{R}^m$ 提取 $i \\in \\mathcal{I}$ 的条目 $x_i$。因此，\n$$\nA^\\top \\Gamma^{-1} A x = \\sum_{i \\in \\mathcal{I}} \\frac{1}{\\sigma^2} x_i e_i,\n$$\n其中 $e_i$ 是 $\\mathbb{R}^n$ 的第 $i$ 个标准基向量。\n- 您不得构建稠密矩阵 $H$ 或任何表示 $Q$、$A$ 或 $A^\\top \\Gamma^{-1} A$ 的稠密矩阵。相反，您应实现无矩阵的例程来将 $Q$ 和 $A^\\top \\Gamma^{-1} A$ 应用于向量，并组合这些操作来将 $H$ 应用于向量。\n- 为计算 $C_{\\text{post}} v$，请使用预处理共轭梯度法（PCG）。预处理器必须是雅可比（对角）预处理器，即 $M = \\operatorname{diag}(H)$，并且必须通过逐元素除法来应用 $M^{-1}$。$Q$ 的对角线由下式给出：\n$$\n\\operatorname{diag}(Q)_i = \\lambda \\left( \\beta + d_i \\right), \\quad d_i = \\begin{cases} \\dfrac{1}{h^2},  i \\in \\{0, n-1\\}, \\\\ \\dfrac{2}{h^2},  \\text{其他情况}, \\end{cases}\n$$\n$A^\\top \\Gamma^{-1} A$ 的对角线在索引集 $\\mathcal{I}$ 中的位置上贡献 $\\dfrac{1}{\\sigma^2}$，在其他位置上为 $0$。\n- 为抽取近似样本 $s \\approx H^{-1/2} z$，请实现最多 $k$ 次迭代的Lanczos方法，以构建Krylov子空间 $\\mathcal{K}_k(H, z)$ 的一个标准正交基 $Q_k = [q_1, \\dots, q_k]$ 和对应的三对角矩阵 $T_k$。然后使用标准的Lanczos函数近似：\n$$\nH^{-1/2} z \\approx \\| z \\|_2 \\, Q_k f(T_k) e_1, \\quad f(\\cdot) = (\\cdot)^{-1/2},\n$$\n通过计算 $T_k$ 的对称特征值分解，将 $f$ 应用于特征值，然后变换回来。不使用再正交化，并假设 $H$ 是对称正定的。Lanczos方法的停止准则是固定的迭代次数 $k$。\n\n为了验证和测试覆盖，请为每个测试用例计算以下两个标量诊断值：\n- $w = C_{\\text{post}} v$ 的残差范数，\n$$\nr_{\\text{norm}} = \\| H w - v \\|_2,\n$$\n作为一个浮点数。\n- $s \\approx H^{-1/2} z$ 的能量恒等式误差，\n$$\n\\varepsilon_{\\text{energy}} = \\left| s^\\top H s - \\| z \\|_2^2 \\right|,\n$$\n作为一个浮点数。对于 $s = H^{-1/2} z$，恒等式 $s^\\top H s = \\| z \\|_2^2$ 精确成立；您的近似样本应产生一个很小的误差。\n\n您必须为以下指定参数和输入的测试套件实现上述功能：\n- 情况 1 (标准情形): $n = 50$, $m = 15$, $\\lambda = 1.0$, $\\beta = 1.0$, $\\sigma = 0.2$, Lanczos迭代次数 $k = 20$，观测索引 $\\mathcal{I}$ 选择为 $m$ 个近似均匀分布的网格索引。网格间距为 $h = \\dfrac{1}{n-1}$。使用确定性探针向量 $v \\in \\mathbb{R}^{n}$，其条目为 $v_i = \\sin\\left( 2 \\pi \\left( \\dfrac{i + 0.5}{n} \\right) \\right)$，其中 $i = 0, \\dots, n-1$。对于采样，使用标准正态分布 $z \\sim \\mathcal{N}(0, I_n)$，生成时使用与情况索引相等的固定种子（1）。\n- 情况 2 (高噪声边界): $n = 50$, $m = 25$, $\\lambda = 1.0$, $\\beta = 0.5$, $\\sigma = 5.0$, $k = 25$，观测索引如上选择。使用相同的确定性 $v$ 定义。对于采样，使用 $z \\sim \\mathcal{N}(0, I_n)$，种子为 2。\n- 情况 3 (无数据边缘情况): $n = 50$, $m = 0$, $\\lambda = 2.0$, $\\beta = 0.1$, $\\sigma = 1.0$, $k = 20$，无观测索引。使用相同的确定性 $v$。对于采样，使用 $z \\sim \\mathcal{N}(0, I_n)$，种子为 3。\n- 情况 4 (低噪声、密集观测): $n = 50$, $m = 40$, $\\lambda = 1.0$, $\\beta = 1.0$, $\\sigma = 0.01$, $k = 30$，观测索引如上选择。使用相同的确定性 $v$。对于采样，使用 $z \\sim \\mathcal{N}(0, I_n)$，种子为 4。\n\n算法要求：\n- 实现一个无矩阵例程，用于对任意 $n$, $m$, $\\lambda$, $\\beta$, $\\sigma$ 和观测索引集 $\\mathcal{I}$，将 $Q$, $A^\\top \\Gamma^{-1} A$ 和 $H$ 应用于一个向量。\n- 实现带有雅可比预处理器 $M = \\operatorname{diag}(H)$ 的预处理共轭梯度法（PCG），以计算解 $w$ 满足 $H w = v$，相对残差的容差为 $10^{-8}$，最大迭代次数为 $200$。\n- 实现带有固定迭代次数 $k$ 的Lanczos方法，通过三对角投影和谱映射来近似 $H^{-1/2} z$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含四个测试用例的结果，形式为由方括号括起来的浮点数对的逗号分隔列表，不含空格。每对对应一个测试用例的 $[r_{\\text{norm}}, \\varepsilon_{\\text{energy}}]$。例如，输出应如下所示：\n$$\n[\\,[r_1,\\varepsilon_1],[r_2,\\varepsilon_2],[r_3,\\varepsilon_3],[r_4,\\varepsilon_4]\\,]\n$$\n但以单行无空格的形式打印为 \"[[r1,eps1],[r2,eps2],[r3,eps3],[r4,eps4]]\"。", "solution": "后验精度算子 $H$ 是先验精度 $Q$ 和数据精度项 $A^\\top \\Gamma^{-1} A$ 的和：\n$$\nH = Q + A^\\top \\Gamma^{-1} A\n$$\n该算子是对称正定的，因为它是一个对称正定算子 $Q$（因为 $\\lambda  0, \\beta  0$）和一个对称半正定算子 $A^\\top \\Gamma^{-1} A$ 的和。该性质对于所选数值方法的稳定性和收敛性至关重要。\n\n我们将通过首先定义算子的无矩阵应用，然后详细说明用于求解线性系统的PCG算法，最后解释基于Lanczos的近似算子平方根矩阵向量积的方法来构建解决方案。\n\n**1. 无矩阵算子实现**\n\n一个核心要求是避免构建稠密矩阵。我们实现计算算子 $Q$、$A^\\top \\Gamma^{-1} A$ 和 $H$ 对任意向量 $x \\in \\mathbb{R}^n$ 作用的函数。\n\n先验精度算子 $Q$ 定义为：\n$$\n(Q x)_i = \\lambda \\left( \\frac{2 x_i - x_{i-1} - x_{i+1}}{h^2} + \\beta x_i \\right)\n$$\n带有诺伊曼（Neumann）边界条件 $x_{-1} = x_0$ 和 $x_{n} = x_{n-1}$。这些条件可以使用数组切片高效实现。对于长度为 $n$ 的向量 $x$，其作用 $(Qx)$ 可计算如下：\n- 对于内部点 $i \\in \\{1, \\dots, n-2\\}$：$(Qx)_i = \\lambda \\left( \\frac{2x_i - x_{i-1} - x_{i+1}}{h^2} + \\beta x_i \\right)$。\n- 对于边界点 $i=0$：$(Qx)_0 = \\lambda \\left( \\frac{2x_0 - x_0 - x_1}{h^2} + \\beta x_0 \\right) = \\lambda \\left( \\frac{x_0 - x_1}{h^2} + \\beta x_0 \\right)$。\n- 对于边界点 $i=n-1$：$(Qx)_{n-1} = \\lambda \\left( \\frac{2x_{n-1} - x_{n-2} - x_{n-1}}{h^2} + \\beta x_{n-1} \\right) = \\lambda \\left( \\frac{x_{n-1} - x_{n-2}}{h^2} + \\beta x_{n-1} \\right)$。\n\n数据精度算子 $A^\\top \\Gamma^{-1} A$ 是一个对角算子，它通过缩放向量 $x$ 中对应于观测位置的分量来作用。给定观测噪声模型 $\\eta \\sim \\mathcal{N}(0, \\sigma^2 I_m)$，逆噪声协方差为 $\\Gamma^{-1} = \\frac{1}{\\sigma^2} I_m$。该算子的作用是：\n$$\n(A^\\top \\Gamma^{-1} A x)_i = \\begin{cases} \\frac{1}{\\sigma^2} x_i,  i \\in \\mathcal{I} \\\\ 0,  i \\notin \\mathcal{I} \\end{cases}\n$$\n其中 $\\mathcal{I}$ 是观测索引的集合。\n\n后验精度算子 $H$ 对向量 $x$ 的作用就是其各分量作用之和：\n$$\nH x = Q x + (A^\\top \\Gamma^{-1} A) x\n$$\n\n**2. 计算后验协方差作用**\n\n计算后验协方差作用 $w = C_{\\text{post}} v = H^{-1} v$ 的任务等价于求解线性系统 $H w = v$。由于 $H$ 是对称正定的，共轭梯度 (CG) 方法是一个理想的选择。我们使用其预处理变体 (PCG) 来提高收敛速度。\n\n所选的预处理器是雅可比 (或对角) 预处理器，$M = \\operatorname{diag}(H)$。预处理器的逆 $M^{-1}$ 是一个对角矩阵，其条目是 $H$ 对角线条目的倒数。它对向量的作用是一个简单的逐元素除法。$H$ 的对角线是 $Q$ 和 $A^\\top \\Gamma^{-1} A$ 对角线之和。\n$Q$ 的对角线由下式给出：\n$$\n\\operatorname{diag}(Q)_i = \\lambda \\left( \\beta + \\frac{1}{h^2} \\right) \\text{ for } i \\in \\{0, n-1\\}, \\quad \\operatorname{diag}(Q)_i = \\lambda \\left( \\beta + \\frac{2}{h^2} \\right) \\text{ otherwise.}\n$$\n$A^\\top \\Gamma^{-1} A$ 的对角线仅在观测索引处非零：\n$$\n\\operatorname{diag}(A^\\top \\Gamma^{-1} A)_i = \\begin{cases} \\frac{1}{\\sigma^2},  i \\in \\mathcal{I} \\\\ 0,  i \\notin \\mathcal{I} \\end{cases}\n$$\nPCG算法从一个初始猜测（例如 $w_0=0$）开始，通过生成一系列 $H$-正交的搜索方向来迭代地改进解 $w$。当相对残差范数 $\\|Hw - v\\|_2 / \\|v\\|_2$ 低于指定的容差 $10^{-8}$ 或达到最大迭代次数（$200$）时，算法终止。最终计算出的向量 $w$ 就是所需的结果 $C_{\\text{post}}v$。残差范数 $\\|Hw - v\\|_2$ 作为诊断值被计算。\n\n**3. 近似后验采样**\n\n第二个任务是从后验分布 $\\mathcal{N}(0, C_{\\text{post}})$ 中生成一个近似样本 $s$。这等价于计算 $s \\approx C_{\\text{post}}^{1/2} z = H^{-1/2} z$，其中 $z \\sim \\mathcal{N}(0, I_n)$。我们使用Lanczos方法来近似这个矩阵函数-向量积。\n\nLanczos算法是一个迭代方法，对于一个对称算子 $H$ 和一个起始向量 $z$，它构建Krylov子空间 $\\mathcal{K}_k(H, z) = \\operatorname{span}\\{z, Hz, H^2z, \\dots, H^{k-1}z\\}$ 的一个标准正交基 $\\{q_1, \\dots, q_k\\}$。在这个基中，算子 $H$ 被表示为一个小的 $k \\times k$ 对称三对角矩阵 $T_k = Q_k^\\top H Q_k$。\n\n该近似依赖于性质：对于一个函数 $f$，$f(H)z \\approx \\|z\\|_2 Q_k f(T_k) e_1$，其中 $e_1 = [1, 0, \\dots, 0]^\\top$。在我们的情况下，$f(\\cdot) = (\\cdot)^{-1/2}$。\n算法流程如下：\n1.  对 $H$ 和起始向量 $z$ 运行 $k$ 次Lanczos迭代，以获得标准正交基矩阵 $Q_k = [q_1, \\dots, q_k]$ 和三对角矩阵 $T_k$。不执行再正交化。\n2.  计算小对称矩阵 $T_k$ 的谱分解 $T_k = V \\Lambda V^\\top$，其中 $\\Lambda$ 是特征值的对角矩阵， $V$ 是特征向量的正交矩阵。这可以通过专门的数值例程（如 `scipy.linalg.eigh_tridiagonal`）高效完成。\n3.  计算 $f(T_k) = V f(\\Lambda) V^\\top = V \\Lambda^{-1/2} V^\\top$。\n4.  样本 $s$ 的最终近似值计算如下：\n    $$\n    s \\approx \\|z\\|_2 \\, Q_k \\left( V \\Lambda^{-1/2} V^\\top \\right) e_1\n    $$\n    这个计算通过计算每一项对向量 $e_1$ 的作用来高效执行，而无需构建完整的矩阵。\n\n此近似的质量通过能量恒等式误差 $\\varepsilon_{\\text{energy}} = \\left| s^\\top H s - \\|z\\|_2^2 \\right|$ 来评估。对于一个精确的样本 $s = H^{-1/2} z$，我们有 $s^\\top H s = (H^{-1/2}z)^\\top H (H^{-1/2}z) = z^\\top H^{-1/2} H H^{-1/2} z = z^\\top z = \\|z\\|_2^2$。误差 $\\varepsilon_{\\text{energy}}$ 衡量了由于Lanczos近似而导致的与该恒等式的偏差。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import eigh_tridiagonal\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and produce the final output.\n    \"\"\"\n    test_cases = [\n        # Case 1: happy path\n        {'n': 50, 'm': 15, 'lam': 1.0, 'beta': 1.0, 'sigma': 0.2, 'k': 20, 'seed': 1},\n        # Case 2: high-noise boundary\n        {'n': 50, 'm': 25, 'lam': 1.0, 'beta': 0.5, 'sigma': 5.0, 'k': 25, 'seed': 2},\n        # Case 3: no-data edge\n        {'n': 50, 'm': 0, 'lam': 2.0, 'beta': 0.1, 'sigma': 1.0, 'k': 20, 'seed': 3},\n        # Case 4: low-noise, dense observations\n        {'n': 50, 'm': 40, 'lam': 1.0, 'beta': 1.0, 'sigma': 0.01, 'k': 30, 'seed': 4},\n    ]\n\n    # --- Matrix-Free Operator Implementations ---\n    \n    def apply_Q(x, n, h, lam, beta):\n        \"\"\"Matrix-free application of the prior precision operator Q.\"\"\"\n        h_sq = h**2\n        lap_x = np.zeros(n)\n        \n        # Interior points\n        if n  2:\n            lap_x[1:-1] = (2 * x[1:-1] - x[:-2] - x[2:]) / h_sq\n        \n        # Boundary points (Neumann)\n        if n  1:\n            lap_x[0] = (x[0] - x[1]) / h_sq\n            lap_x[-1] = (x[-1] - x[-2]) / h_sq\n        elif n == 1:\n            lap_x[0] = 0 # No neighbors\n            \n        return lam * (lap_x + beta * x)\n\n    def apply_A_T_Gamma_inv_A(x, obs_indices, sigma_sq_inv):\n        \"\"\"Matrix-free application of the data precision operator.\"\"\"\n        result = np.zeros_like(x)\n        if obs_indices.size  0:\n            result[obs_indices] = x[obs_indices] * sigma_sq_inv\n        return result\n\n    # --- Preconditioner  PCG ---\n\n    def compute_diag_H(n, h, lam, beta, obs_indices, sigma_sq_inv):\n        \"\"\"Computes the diagonal of the posterior precision operator H.\"\"\"\n        h_sq = h**2\n        \n        # Diagonal of Q\n        diag_Q = np.full(n, lam * (beta + 2.0 / h_sq))\n        if n  1:\n            diag_Q[0] = lam * (beta + 1.0 / h_sq)\n            diag_Q[-1] = lam * (beta + 1.0 / h_sq)\n        elif n == 1:\n             diag_Q[0] = lam * beta\n\n        # Diagonal of A^T*Gamma^-1*A\n        diag_A_part = np.zeros(n)\n        if obs_indices.size  0:\n            diag_A_part[obs_indices] = sigma_sq_inv\n            \n        return diag_Q + diag_A_part\n\n    def pcg(apply_A, b, apply_M_inv, tol=1e-8, maxiter=200):\n        \"\"\"Preconditioned Conjugate Gradients algorithm.\"\"\"\n        x = np.zeros_like(b)\n        r = b - apply_A(x)\n        if np.linalg.norm(b) == 0:\n            return x\n            \n        norm_b = np.linalg.norm(b)\n        if norm_b == 0: norm_b = 1.0 # Handle b=0 case\n\n        z = apply_M_inv(r)\n        p = z\n        rs_old = np.dot(r, z)\n\n        for i in range(maxiter):\n            Ap = apply_A(p)\n            alpha = rs_old / np.dot(p, Ap)\n            x += alpha * p\n            r -= alpha * Ap\n            \n            if np.linalg.norm(r) / norm_b  tol:\n                break\n                \n            z = apply_M_inv(r)\n            rs_new = np.dot(r, z)\n            p = z + (rs_new / rs_old) * p\n            rs_old = rs_new\n            \n        return x\n\n    # --- Lanczos Algorithm  Function Approximation ---\n    \n    def lanczos(apply_H, z, k):\n        \"\"\"Lanczos algorithm to generate T_k and Q_k.\"\"\"\n        n = len(z)\n        Q = np.zeros((n, k))\n        alphas = np.zeros(k)\n        betas_sub = np.zeros(k - 1)\n\n        z_norm = np.linalg.norm(z)\n        if z_norm == 0:\n            return alphas, betas_sub, Q, z_norm\n        \n        q = z / z_norm\n        \n        for j in range(k):\n            Q[:, j] = q\n            u = apply_H(q)\n            alphas[j] = np.dot(q, u)\n            \n            if j  k - 1:\n                u = u - alphas[j] * q\n                if j  0:\n                    u = u - betas_sub[j-1] * Q[:, j-1]\n                \n                beta_j = np.linalg.norm(u)\n                betas_sub[j] = beta_j\n                if beta_j  1e-14: # (Near) breakdown\n                    # Resize and return what we have\n                    return alphas[:j+1], betas_sub[:j], Q[:, :j+1], z_norm\n                q = u / beta_j\n                \n        return alphas, betas_sub, Q, z_norm\n\n    results = []\n    for case in test_cases:\n        n, m, lam, beta, sigma, k, seed = case.values()\n\n        # --- Setup for the current test case ---\n        h = 1.0 / (n - 1) if n  1 else 1.0\n        sigma_sq_inv = 1.0 / sigma**2\n        obs_indices = np.unique(np.linspace(0, n - 1, m, dtype=int)) if m  0 else np.array([], dtype=int)\n        \n        # Generate input vectors\n        v = np.sin(2 * np.pi * (np.arange(n) + 0.5) / n)\n        rng = np.random.default_rng(seed)\n        z = rng.normal(size=n)\n        \n        # Define operators for this case\n        def apply_H(x):\n            return apply_Q(x, n, h, lam, beta) + \\\n                   apply_A_T_Gamma_inv_A(x, obs_indices, sigma_sq_inv)\n                   \n        # --- Part 1: PCG for C_post * v ---\n        diag_H = compute_diag_H(n, h, lam, beta, obs_indices, sigma_sq_inv)\n        def apply_M_inv(r):\n            return r / diag_H\n            \n        w = pcg(apply_H, v, apply_M_inv, tol=1e-8, maxiter=200)\n        r_norm = np.linalg.norm(apply_H(w) - v)\n\n        # --- Part 2: Lanczos for approximate sample ---\n        alphas, betas_sub, Q_k, z_norm = lanczos(apply_H, z, k)\n        \n        # Adjust k if early breakdown occurred\n        actual_k = Q_k.shape[1]\n        \n        if actual_k  0:\n            # Eigendecomposition of T_k\n            eivals, eivecs = eigh_tridiagonal(alphas, betas_sub, tol=1e-15)\n        \n            # Compute H^{-1/2} z approximation via spectral mapping\n            f_eivals = 1.0 / np.sqrt(eivals)\n            y = eivecs @ (f_eivals * eivecs[0, :])\n            s = z_norm * (Q_k @ y)\n\n            # Compute energy error\n            sHs = np.dot(s, apply_H(s))\n            z_norm_sq = z_norm**2\n            eps_energy = np.abs(sHs - z_norm_sq)\n        else: # Handle z=0 case\n            s = np.zeros(n)\n            eps_energy = 0.0\n\n        results.append(f\"[{r_norm},{eps_energy}]\")\n\n    print(f\"[[{','.join(results)}]]\")\n\nsolve()\n```", "id": "3384561"}]}