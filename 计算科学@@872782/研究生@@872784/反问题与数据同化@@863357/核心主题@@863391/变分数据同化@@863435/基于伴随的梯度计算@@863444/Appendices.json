{"hands_on_practices": [{"introduction": "伴随方法的威力在于其计算效率，但这种效率的代价是实现的复杂性。伴随代码中的一个错误可能非常微妙，并导致错误的优化结果。因此，一个稳健的验证步骤不是可有可无的，而是必不可少的。第一个实践练习 [@problem_id:3364135] 将指导您掌握方向导数检验的原理，这是一种用于确认任何梯度计算准确性的基石技术。", "problem": "考虑一个逆问题，其中通过最小化一个依赖于数值模型解的可微代价泛函 $J(p)$ 来估计参数向量 $p \\in \\mathbb{R}^n$。实现了一个伴随方法来计算梯度 $\\nabla J(p)$ 相对于 $p$。为了评估基于伴随方法得到的梯度的正确性，执行了方向导数测试，方法是选择一个方向 $\\delta p \\in \\mathbb{R}^n$，并将内积 $\\nabla J(p) \\cdot \\delta p$ 与 $J$ 沿方向 $\\delta p$ 的方向导数的有限差分近似进行比较。\n\n利用方向导数的定义和 $J$ 关于 $p$ 的 Taylor 展开，从第一性原理出发，论证该测试的预期行为。特别地，分析步长 $\\epsilon > 0$ 的选择如何影响截断误差和浮点舍入误差，并解释这些误差机制如何影响准确性以及检测伴随实现错误的能力。\n\n下列关于方向导数测试以及 $\\epsilon$ 作用的陈述中，哪些是正确的？选择所有适用的选项。\n\nA. 如果 $J$ 是二次连续可微的，那么差异\n$$E_{\\mathrm{fwd}}(\\epsilon) = \\left\\lvert \\nabla J(p)\\cdot \\delta p - \\frac{J(p+\\epsilon\\,\\delta p)-J(p)}{\\epsilon} \\right\\rvert$$\n会随着 $\\epsilon \\to 0$ 与 $\\epsilon$ 成正比地减小，直到浮点舍入误差占主导地位。因此，$E_{\\mathrm{fwd}}(\\epsilon)$ 相对于 $\\epsilon$ 的双对数图在截断误差主导的区域斜率为 $1$。如果改用中心差分\n$$\\frac{J(p+\\epsilon\\,\\delta p)-J(p-\\epsilon\\,\\delta p)}{2\\epsilon}$$\n则会得到一个截断误差主导的斜率为 $2$。\n\nB. 如果 $J$ 的数值计算产生的浮点舍入误差与机器精度 $\\varepsilon_{\\mathrm{mach}}$ 同量级，则有限差分误差的舍入分量其量级与 $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$ 成比例，因此选择过小的 $\\epsilon$ 会因灾难性抵消而导致测试误差增大。\n\nC. 平衡截断误差与舍入误差，对于前向差分，可得到最优步长为 $\\epsilon \\sim \\sqrt{\\varepsilon_{\\mathrm{mach}}}$（在对 $p$ 和 $\\delta p$ 的量级进行适当缩放后）；而对于中心差分，最优步长为 $\\epsilon \\sim \\varepsilon_{\\mathrm{mach}}^{1/3}$。\n\nD. 伴随实现中的符号错误（即返回 $-\\nabla J(p)$）对于中心差分测试是不可见的，但对于前向差分测试是可以检测到的。\n\nE. 为了稳健性，应缩放 $\\delta p$ 以使得在所选的参数范数下 $\\lVert \\delta p \\rVert = 1$，并且应测试多个随机方向；如果伴随方法是正确的，那么在截断误差主导的区域，差异会表现出预期的 $\\mathcal{O}(\\epsilon)$ 或 $\\mathcal{O}(\\epsilon^2)$ 衰减；反之，若在不同方向上都缺少这种衰减，则表明存在伴随错误。\n\nF. 如果模型求解器采用随 $p$ 和扰动 $\\epsilon\\,\\delta p$ 变化的自适应容差，方向导数测试仍然有效，因为求解器容差不影响可微性，因此不能扭曲误差行为。\n\nG. 使用中心差分可以完全消除截断误差，因此唯一剩下的误差源是舍入误差；所以，更小的 $\\epsilon$ 总能提高测试的准确性。\n\nH. 如果 $J$ 包含相对于 $p$ 的不可微部分，例如精确阈值处理或逐点取最大值，那么方向导数测试可能不会表现出预期的随 $\\epsilon$ 变化的截断率行为；在这种情况下，需要进行平滑化或重构才能进行可靠的伴随测试。", "solution": "该问题陈述是数值优化和逆问题领域中一个有效且适定的问题。它要求对方向导数测试进行第一性原理分析，这是一种用于验证基于伴随方法的梯度计算实现的标准方法。\n\n### **问题验证**\n\n**第1步：提取已知条件**\n- 待估计的参数是一个向量 $p \\in \\mathbb{R}^n$。\n- 目标是最小化一个可微的代价泛函 $J(p)$。\n- 梯度 $\\nabla J(p)$ 使用伴随方法计算。\n- 使用方向导数测试进行验证。\n- 选择一个方向向量：$\\delta p \\in \\mathbb{R}^n$。\n- 该测试将内积 $\\nabla J(p) \\cdot \\delta p$ 与 $J$ 沿方向 $\\delta p$ 的方向导数的有限差分近似进行比较。\n- 有限差分步长为 $\\epsilon > 0$。\n- 任务是分析此测试的预期行为，重点关注截断误差和舍入误差作为 $\\epsilon$ 函数的作用。\n\n**第2步：使用提取的已知条件进行验证**\n该问题具有科学依据、适定且客观。它描述了对基于梯度的优化代码的一种基本健全性检查，称为 Taylor 测试或有限差分检查。Taylor 展开、方向导数、截断误差和浮点舍入误差等概念是微积分和数值分析的基石原理。该设置是自洽的，没有矛盾或歧义。\n\n**第3步：结论与行动**\n问题是有效的。我们将继续进行推导和分析。\n\n### **第一性原理推导**\n\n分析的核心在于 Taylor 定理。可微泛函 $J(p)$ 在点 $p$ 沿方向 $\\delta p$ 的方向导数定义为：\n$$ D_{\\delta p}J(p) = \\lim_{\\epsilon \\to 0} \\frac{J(p+\\epsilon\\,\\delta p) - J(p)}{\\epsilon} $$\n对于可微泛函，这等价于梯度与方向向量的内积：\n$$ D_{\\delta p}J(p) = \\nabla J(p) \\cdot \\delta p $$\n伴随方法提供了一个 $\\nabla J(p)$ 的计算值，从而也提供了 $\\nabla J(p) \\cdot \\delta p$ 的计算值。方向导数测试通过将此计算值与导数的有限差分近似进行比较来验证其正确性。\n\n让我们分析两种最常见的有限差分格式。我们假设 $J$ 在本分析中至少是三次连续可微的 ($C^3$)。\n\n**1. 前向差分近似：**\n近似由下式给出：\n$$ D_{\\mathrm{fwd}}(\\epsilon) = \\frac{J(p+\\epsilon\\,\\delta p) - J(p)}{\\epsilon} $$\n为了分析误差，我们使用 $J(p+\\epsilon\\,\\delta p)$ 在 $p$ 点附近的 Taylor 展开：\n$$ J(p+\\epsilon\\,\\delta p) = J(p) + \\epsilon (\\nabla J(p) \\cdot \\delta p) + \\frac{\\epsilon^2}{2} (\\delta p^T H(p) \\delta p) + \\mathcal{O}(\\epsilon^3) $$\n其中 $H(p)$ 是 $J$ 在 $p$ 点的 Hessian 矩阵。重新整理并除以 $\\epsilon$ 得到：\n$$ \\frac{J(p+\\epsilon\\,\\delta p) - J(p)}{\\epsilon} = \\nabla J(p) \\cdot \\delta p + \\frac{\\epsilon}{2} (\\delta p^T H(p) \\delta p) + \\mathcal{O}(\\epsilon^2) $$\n选项 A 中定义的差异是基于伴随方法的结果与此近似之间的绝对差。如果伴随方法正确，该差异就纯粹是近似误差：\n$$ E_{\\mathrm{fwd}}(\\epsilon) = \\left\\lvert \\nabla J(p)\\cdot \\delta p - D_{\\mathrm{fwd}}(\\epsilon) \\right\\rvert = \\left\\lvert -\\frac{\\epsilon}{2} (\\delta p^T H(p) \\delta p) - \\mathcal{O}(\\epsilon^2) \\right\\rvert $$\n这是**截断误差**，其量级为 $\\mathcal{O}(\\epsilon)$。\n\n**2. 中心差分近似：**\n近似由下式给出：\n$$ D_{\\mathrm{cen}}(\\epsilon) = \\frac{J(p+\\epsilon\\,\\delta p) - J(p-\\epsilon\\,\\delta p)}{2\\epsilon} $$\n为了分析这个式子，我们需要 $J(p+\\epsilon\\,\\delta p)$ 和 $J(p-\\epsilon\\,\\delta p)$ 的 Taylor 展开：\n$$ J(p+\\epsilon\\,\\delta p) = J(p) + \\epsilon (\\nabla J \\cdot \\delta p) + \\frac{\\epsilon^2}{2} (\\delta p^T H \\delta p) + \\frac{\\epsilon^3}{6} T(p)(\\delta p, \\delta p, \\delta p) + \\mathcal{O}(\\epsilon^4) $$\n$$ J(p-\\epsilon\\,\\delta p) = J(p) - \\epsilon (\\nabla J \\cdot \\delta p) + \\frac{\\epsilon^2}{2} (\\delta p^T H \\delta p) - \\frac{\\epsilon^3}{6} T(p)(\\delta p, \\delta p, \\delta p) + \\mathcal{O}(\\epsilon^4) $$\n其中 $T(p)$ 代表三阶导数张量。用第一个式子减去第二个式子：\n$$ J(p+\\epsilon\\,\\delta p) - J(p-\\epsilon\\,\\delta p) = 2\\epsilon (\\nabla J \\cdot \\delta p) + \\frac{\\epsilon^3}{3} T(p)(\\delta p, \\delta p, \\delta p) + \\mathcal{O}(\\epsilon^5) $$\n除以 $2\\epsilon$ 得到：\n$$ \\frac{J(p+\\epsilon\\,\\delta p) - J(p-\\epsilon\\,\\delta p)}{2\\epsilon} = \\nabla J(p) \\cdot \\delta p + \\frac{\\epsilon^2}{6} T(p)(\\delta p, \\delta p, \\delta p) + \\mathcal{O}(\\epsilon^4) $$\n因此，中心差分的**截断误差**量级为 $\\mathcal{O}(\\epsilon^2)$。\n\n**3. 舍入误差：**\n使用浮点运算对 $J(p)$ 进行数值计算会引入误差。设 $\\tilde{J}(p)$ 为计算值。误差通常与机器精度 $\\varepsilon_{\\mathrm{mach}}$ 乘以函数值的量级同阶。因此，$\\tilde{J}(p) \\approx J(p) + \\mathcal{O}(\\varepsilon_{\\mathrm{mach}})$。\n对于前向差分，分子中的误差是 $\\tilde{J}(p+\\epsilon\\,\\delta p) - \\tilde{J}(p)$。当 $\\epsilon \\to 0$ 时，这两个值变得非常接近。相近数相减导致有效数字的损失，这种效应称为灾难性抵消。分子中产生的误差由浮点误差主导，其量级为 $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}})$。将其通过除以 $\\epsilon$ 传播出去，舍入误差对总误差的贡献为：\n$$ E_{\\mathrm{round}}(\\epsilon) \\sim \\frac{\\mathcal{O}(\\varepsilon_{\\mathrm{mach}})}{\\epsilon} $$\n此分析对前向差分和中心差分均成立。\n\n**4. 最优步长：**\n总误差 $E(\\epsilon)$ 是截断误差和舍入误差之和。\n- 对于前向差分：$E_{\\mathrm{fwd}}(\\epsilon) \\approx C_1 \\epsilon + C_2 \\frac{\\varepsilon_{\\mathrm{mach}}}{\\epsilon}$。关于 $\\epsilon$ 最小化该式得到 $C_1 \\approx C_2 \\varepsilon_{\\mathrm{mach}} / \\epsilon^2$，这意味着 $\\epsilon_{\\mathrm{opt}} \\sim \\sqrt{\\varepsilon_{\\mathrm{mach}}}$。\n- 对于中心差分：$E_{\\mathrm{cen}}(\\epsilon) \\approx C_3 \\epsilon^2 + C_4 \\frac{\\varepsilon_{\\mathrm{mach}}}{\\epsilon}$。最小化该式得到 $2C_3\\epsilon \\approx C_4 \\varepsilon_{\\mathrm{mach}} / \\epsilon^2$，这意味着 $\\epsilon_{\\mathrm{opt}} \\sim \\varepsilon_{\\mathrm{mach}}^{1/3}$。\n\n### **逐项分析**\n\n**A.** 如果 $J$ 是二次连续可微的，那么差异 $E_{\\mathrm{fwd}}(\\epsilon) = \\left\\lvert \\nabla J(p)\\cdot \\delta p - \\frac{J(p+\\epsilon\\,\\delta p)-J(p)}{\\epsilon} \\right\\rvert$ 会随着 $\\epsilon \\to 0$ 与 $\\epsilon$ 成正比地减小，直到浮点舍入误差占主导地位。因此，$E_{\\mathrm{fwd}}(\\epsilon)$ 相对于 $\\epsilon$ 的双对数图在截断误差主导的区域斜率为 $1$。如果改用中心差分，则会得到一个截断误差主导的斜率为 $2$。\n- **分析：** 我们的第一性原理推导表明，前向差分的截断误差为 $\\mathcal{O}(\\epsilon)$，这对应于双对数图上的斜率 $1$（$\\log E \\approx \\log C + 1 \\cdot \\log \\epsilon$）。推导还表明，对于中心差分，截断误差为 $\\mathcal{O}(\\epsilon^2)$，对应于斜率 $2$（$\\log E \\approx \\log C' + 2 \\cdot \\log \\epsilon$）。此陈述与推导完全一致。\n- **结论：** **正确**。\n\n**B.** 如果 $J$ 的数值计算产生的浮点舍入误差与机器精度 $\\varepsilon_{\\mathrm{mach}}$ 同量级，则有限差分误差的舍入分量其量级与 $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$ 成比例，因此选择过小的 $\\epsilon$ 会因灾难性抵消而导致测试误差增大。\n- **分析：** 我们对舍入误差的推导证实了这种行为。相近数 $J(p+\\epsilon\\delta p)$ 和 $J(p)$ 或 $J(p-\\epsilon\\delta p)$ 的相减导致灾难性抵消，使得分子中的舍入误差大致恒定在 $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}})$。当除以 $\\epsilon$ 时，这产生的误差贡献与 $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$ 成比例，并且随着 $\\epsilon \\to 0$ 无界增长。\n- **结论：** **正确**。\n\n**C.** 平衡截断误差与舍入误差，对于前向差分，可得到最优步长为 $\\epsilon \\sim \\sqrt{\\varepsilon_{\\mathrm{mach}}}$（在对 $p$ 和 $\\delta p$ 的量级进行适当缩放后）；而对于中心差分，最优步长为 $\\epsilon \\sim \\varepsilon_{\\mathrm{mach}}^{1/3}$。\n- **分析：** 我们通过平衡竞争的误差项对最优步长进行的分析证实了这些依赖关系。对于前向差分，平衡 $\\mathcal{O}(\\epsilon)$ 与 $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$ 得到 $\\epsilon_{\\mathrm{opt}} \\propto \\varepsilon_{\\mathrm{mach}}^{1/2}$。对于中心差分，平衡 $\\mathcal{O}(\\epsilon^2)$ 与 $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$ 得到 $\\epsilon_{\\mathrm{opt}} \\propto \\varepsilon_{\\mathrm{mach}}^{1/3}$。关于缩放的说明也是恰当的。\n- **结论：** **正确**。\n\n**D.** 伴随实现中的符号错误（即返回 $-\\nabla J(p)$）对于中心差分测试是不可见的，但对于前向差分测试是可以检测到的。\n- **分析：** 符号错误意味着计算出的量是 $-\\nabla J(p) \\cdot \\delta p$。测试将此与有限差分近似进行比较，后者近似于真实值 $+\\nabla J(p) \\cdot \\delta p$。中心差分测试的差异将是 $|(-\\nabla J \\cdot \\delta p) - (\\nabla J \\cdot \\delta p + \\mathcal{O}(\\epsilon^2))| \\approx | -2 \\nabla J \\cdot \\delta p |$。这是一个大的、$\\mathcal{O}(1)$ 阶的误差，不会随着 $\\epsilon \\to 0$ 而消失。前向差分也是如此。符号错误是最显而易见的错误之一，两种方法都能轻易检测到。该陈述是错误的。\n- **结论：** **不正确**。\n\n**E.** 为了稳健性，应缩放 $\\delta p$ 以使得在所选的参数范数下 $\\lVert \\delta p \\rVert = 1$，并且应测试多个随机方向；如果伴随方法是正确的，那么在截断误差主导的区域，差异会表现出预期的 $\\mathcal{O}(\\epsilon)$ 或 $\\mathcal{O}(\\epsilon^2)$ 衰减；反之，若在不同方向上都缺少这种衰减，则表明存在伴随错误。\n- **分析：** 此陈述描述了进行方向导数测试的标准最佳实践。缩放 $\\delta p$ 确保扰动的大小得到控制。测试多个随机方向至关重要，因为梯度计算中的错误可能与某个单一选择的 $\\delta p$ 正交，从而被测试漏掉。观察到理论上预测的收敛率（双对数图上的斜率）是实现正确的首要指标。未能观察到此速率强烈表明存在错误。\n- **结论：** **正确**。\n\n**F.** 如果模型求解器采用随 $p$ 和扰动 $\\epsilon\\,\\delta p$ 变化的自适应容差，方向导数测试仍然有效，因为求解器容差不影响可微性，因此不能扭曲误差行为。\n- **分析：** 此陈述根本上是错误的。如果求解器的行为（例如，网格加密、时间步数）随着 $p$ 的变化而离散地变化，则数值计算出的泛函 $J(p)$ 不再是 $p$ 的光滑函数。它会获得“数值噪声”或细尺度的非光滑性。当有限差分跨越这些离散变化之一时，结果不会近似于导数，也不会如 Taylor 定理所预测的那样收敛。这是实践中一个众所周知且严重的问题，可能使测试无效。\n- **结论：** **不正确**。\n\n**G.** 使用中心差分可以完全消除截断误差，因此唯一剩下的误差源是舍入误差；所以，更小的 $\\epsilon$ 总能提高测试的准确性。\n- **分析：** 此陈述包含多个谬误。首先，中心差分并不能完全消除截断误差；它只是将其降低到更高阶，即 $\\mathcal{O}(\\epsilon^2)$。其次，因为截断误差不为零，所以舍入误差不是唯一的误差源。第三，由于存在 $\\mathcal{O}(\\varepsilon_{\\mathrm{mach}}/\\epsilon)$ 的舍入误差分量，将 $\\epsilon$ 变得任意小最终将导致总误差增加，而不是无限地提高精度。\n- **结论：** **不正确**。\n\n**H.** 如果 $J$ 包含相对于 $p$ 的不可微部分，例如精确阈值处理或逐点取最大值，那么方向导数测试可能不会表现出预期的随 $\\epsilon$ 变化的截断率行为；在这种情况下，需要进行平滑化或重构才能进行可靠的伴随测试。\n- **分析：** 方向导数测试是建立在 Taylor 级数展开有效性的基础之上的，这要求泛函足够光滑（可微）。在不可微点（扭折点或跳跃点），梯度没有唯一定义，Taylor 近似失效。跨越这样一个不可微点的有限差分格式不会以预期速率收敛。标准的补救措施是在应用测试之前，用一个光滑近似来替换不可微分量（例如，用 softplus 函数替换 $\\max(x, 0)$）。此陈述准确地抓住了这个关键限制及其解决方案。\n- **结论：** **正确**。", "answer": "$$\\boxed{ABCEH}$$", "id": "3364135"}, {"introduction": "现在我们从验证转向实现，重点关注连续时间系统，这是科学建模中的一个常见场景。这个练习 [@problem_id:3333095] 要求您使用“先优化后离散化”(optimize-then-discretize)的策略，为一个神经普通微分方程(ODE)计算梯度。您将首先推导连续伴随方程，然后实现其数值解，从而将伴随方法应用于现代机器学习模型。", "problem": "考虑一个简单的双物种细胞系统，其中状态向量 $x(t) \\in \\mathbb{R}^2$ 表示信使核糖核酸（mRNA）和蛋白质的无量纲化浓度。该系统根据常微分方程 $dx/dt = f_{\\theta}(x,t)$ 演化，其中 $f_{\\theta}$ 由一个小型前馈神经网络参数化，旨在近似非线性反应动力学。时间以秒为单位。神经网络定义如下：隐藏层的预激活为 $z = W_1 x + b_1$，隐藏层的激活为 $h = \\tanh(z)$，输出为\n$$\nf_{\\theta}(x,t) = W_2 h + b_2 - k_d \\odot x,\n$$\n其中 $W_1 \\in \\mathbb{R}^{3 \\times 2}$，$b_1 \\in \\mathbb{R}^{3}$，$W_2 \\in \\mathbb{R}^{2 \\times 3}$，$b_2 \\in \\mathbb{R}^{2}$，$k_d \\in \\mathbb{R}^{2}$，且 $\\odot$ 表示按元素乘法。损失定义在时刻 $T$ 的终端状态上，由下式给出：\n$$\n\\mathcal{L}(\\theta) = \\frac{1}{2} \\| x(T; \\theta) - x_{\\mathrm{target}} \\|_2^2.\n$$\n初始条件为 $x(0) = x_0$。目标是使用伴随方法计算梯度 $d\\mathcal{L}/d\\theta$，并将其与梯度的有限差分近似进行比较，以评估正确性以及求解器离散化对偏差的影响。\n\n从微积分的链式法则和常微分方程（ODE）的伴随灵敏度定义出发，推导实现 $d\\mathcal{L}/d\\theta$ 的基于伴随的梯度计算所需的关系式，该计算需与上述连续时间神经 ODE 模型一致。您的程序必须：\n- 使用固定步长的显式四阶 Runge–Kutta 方法积分前向动力学。\n- 使用一阶显式方法实现沿时间反向的伴随积分，其中雅可比矩阵 $ \\partial f_{\\theta} / \\partial x $ 沿保存的前向轨迹求值。\n- 通过瞬时灵敏度 $a(t)^\\top \\, \\partial f_{\\theta} / \\partial \\theta$ 的时间积分来累积参数梯度，其中 $a(t)$ 表示伴随状态，并通过对参数扰动重新积分前向动力学计算出的中心有限差分来验证结果。\n\n您的实现必须是完全自包含的，不调用任何外部数据。前向模型和所有参数的数值指定如下：\n- 模型参数 $\\theta$：\n  - $W_1 = \\begin{bmatrix} 0.8  -0.5 \\\\ 0.3  0.9 \\\\ -0.7  0.2 \\end{bmatrix}$，\n  - $b_1 = \\begin{bmatrix} 0.1 \\\\ -0.2 \\\\ 0.05 \\end{bmatrix}$，\n  - $W_2 = \\begin{bmatrix} 0.5  -0.3  0.1 \\\\ -0.4  0.6  -0.2 \\end{bmatrix}$，\n  - $b_2 = \\begin{bmatrix} 0.0 \\\\ 0.05 \\end{bmatrix}$，\n  - $k_d = \\begin{bmatrix} 0.3 \\\\ 0.5 \\end{bmatrix}$。\n- 初始状态和目标：\n  - $x_0 = \\begin{bmatrix} 0.5 \\\\ 0.2 \\end{bmatrix}$，\n  - $x_{\\mathrm{target}} = \\begin{bmatrix} 0.1 \\\\ -0.1 \\end{bmatrix}$。\n- 最终时间：$T = 2.0$ 秒。\n\n您必须使用一个参数缩放因子 $s$ 来探索神经组件中近线性的区域，方法是将权重和偏置缩放为 $\\{ W_1, b_1, W_2, b_2 \\} \\mapsto s \\cdot \\{ W_1, b_1, W_2, b_2 \\}$，同时保持 $k_d$ 不变。\n\n定义以下测试用例集，每个用例由一个元组 $(N, \\epsilon, \\tau, s)$ 指定，其中 $N$ 是前向积分的 Runge–Kutta 步数（恒定步长 $\\Delta t = T/N$），$\\epsilon$ 是有限差分步长，$\\tau$ 是梯度一致性的绝对容差，$s$ 是缩放因子：\n- 用例 1：$(N=\\ 500,\\ \\epsilon=\\ 10^{-6},\\ \\tau=\\ 2 \\times 10^{-2},\\ s=\\ 1.0)$，\n- 用例 2：$(N=\\ 50,\\ \\epsilon=\\ 10^{-6},\\ \\tau=\\ 2 \\times 10^{-2},\\ s=\\ 1.0)$，\n- 用例 3：$(N=\\ 20,\\ \\epsilon=\\ 10^{-6},\\ \\tau=\\ 5 \\times 10^{-2},\\ s=\\ 1.0)$，\n- 用例 4：$(N=\\ 60,\\ \\epsilon=\\ 10^{-6},\\ \\tau=\\ 1 \\times 10^{-2},\\ s=\\ 0.05)$。\n\n对于每个用例，计算：\n- 使用连续伴随法，通过伴随方程的反向显式积分计算的基于伴随的梯度 $d\\mathcal{L}/d\\theta$。\n- 对 $\\theta$ 的每个标量分量应用扰动 $\\pm \\epsilon$（在扰动前应用缩放 $s$），计算 $d\\mathcal{L}/d\\theta$ 的中心有限差分近似。\n- 两个梯度向量之间的最大逐分量绝对差。\n\n您的程序应产生单行输出，包含用方括号括起来的、以逗号分隔的结果列表，其中每个条目是一个布尔值，指示该用例的最大绝对差是否严格小于指定的容差 $\\tau$。例如，输出格式必须与 $[b_1,b_2,b_3,b_4]$ 完全一样，其中每个 $b_i$ 是 `True` 或 `False`，且没有空格。除以秒为单位的 $T$ 外，所有数值答案都必须是无单位标量。本问题不使用角度。所有结果均由上述数据确定，不需要任何用户输入。", "solution": "本问题要求计算一个损失函数相对于一个神经（网络）常微分方程（ODE）模型参数的梯度。该梯度将使用连续伴随灵敏度方法计算，并与有限差分近似进行验证。\n\n### 基于原理的设计：伴随灵敏度分析\n\n该系统由一个带有初始条件 $x(0) = x_0$ 的 ODE $\\frac{dx}{dt} = f_{\\theta}(x,t)$ 描述。目标是计算一个依赖于最终时刻 $T$ 状态的损失函数 $\\mathcal{L}(\\theta) = g(x(T))$ 的梯度。根据链式法则，该梯度为：\n$$\n\\frac{d\\mathcal{L}}{d\\theta} = \\frac{\\partial g}{\\partial x(T)} \\frac{dx(T)}{d\\theta}\n$$\n项 $\\frac{dx(T)}{d\\theta}$ 表示最终状态对参数变化的灵敏度。其直接计算需要对每个参数积分一个灵敏度方程，这在计算上可能非常昂贵。伴随方法提供了一种更高效的替代方案，尤其是在参数数量众多时。\n\n伴随方法引入一个伴随状态向量 $a(t) \\in \\mathbb{R}^n$，它是以下终端值问题的解：\n$$\n\\frac{da}{dt} = - \\left( \\frac{\\partial f_{\\theta}}{\\partial x} \\right)^\\top a(t) \\quad \\text{其中} \\quad a(T) = \\left( \\frac{\\partial g}{\\partial x(T)} \\right)^\\top\n$$\n损失函数相对于参数 $\\theta$ 的梯度则由以下积分给出：\n$$\n\\frac{d\\mathcal{L}}{d\\theta} = \\int_0^T a(t)^\\top \\frac{\\partial f_{\\theta}(x(t), t)}{\\partial \\theta} dt\n$$\n该公式要求对伴随 ODE 进行一次沿时间反向的积分，并重用通过对原始 ODE 进行沿时间前向积分获得的状态轨迹 $x(t)$。\n\n### 在特定神经 ODE 模型上的应用\n\n问题为动力学、参数和损失函数提供了具体形式。\n\n1.  **系统动力学**：状态为 $x(t) \\in \\mathbb{R}^2$。动力学函数为 $f_{\\theta}(x,t) = W_2 h + b_2 - k_d \\odot x$，其中 $h = \\tanh(z)$ 且 $z = W_1 x + b_1$。参数为 $\\theta = \\{W_1, b_1, W_2, b_2, k_d\\}$。\n\n2.  **损失函数和伴随终端条件**：损失为 $\\mathcal{L}(\\theta) = \\frac{1}{2} \\| x(T) - x_{\\mathrm{target}} \\|_2^2$。损失相对于最终状态的梯度是 $\\frac{\\partial \\mathcal{L}}{\\partial x(T)} = (x(T) - x_{\\mathrm{target}})^\\top$。因此，伴随状态 $a(t) \\in \\mathbb{R}^2$ 的终端条件是：\n    $$\n    a(T) = x(T) - x_{\\mathrm{target}}\n    $$\n\n3.  **动力学的雅可比矩阵（$\\partial f_{\\theta} / \\partial x$）**：为了定义伴随 ODE，我们首先需要 $f_{\\theta}$ 相对于状态 $x$ 的雅可比矩阵。使用链式法则：\n    $$\n    \\frac{\\partial f_{\\theta}}{\\partial x} = W_2 \\frac{\\partial h}{\\partial z} \\frac{\\partial z}{\\partial x} - \\frac{\\partial (k_d \\odot x)}{\\partial x}\n    $$\n    导数分别为 $\\frac{\\partial z}{\\partial x} = W_1$，$\\frac{\\partial(k_d \\odot x)}{\\partial x} = \\text{diag}(k_d)$，以及 $\\frac{\\partial h}{\\partial z} = \\text{diag}(1 - \\tanh^2(z)) = \\text{diag}(1 - h^2)$，其中平方是按元素进行的。完整的雅可比矩阵是一个 $2 \\times 2$ 的矩阵：\n    $$\n    J(x, \\theta) = \\frac{\\partial f_{\\theta}}{\\partial x} = W_2 \\text{diag}(1 - h^2) W_1 - \\text{diag}(k_d)\n    $$\n    因此伴随 ODE 是 $\\frac{da}{dt} = -J(x(t), \\theta)^\\top a(t)$。\n\n4.  **参数梯度（$\\partial f_{\\theta} / \\partial \\theta$）**：我们需要 $f_{\\theta}$ 相对于每个参数块的偏导数。\n    -   **关于 $W_2$ 的梯度**：$\\frac{\\partial f_{\\theta}}{\\partial (W_2)_{ij}} = e_i h_j^\\top$，其中 $e_i$ 是第 $i$ 个标准基向量。矩阵 $W_2$ 梯度的被积函数是 $a h^\\top$。\n        $$ \\frac{d\\mathcal{L}}{dW_2} = \\int_0^T a(t) h(t)^\\top dt $$\n    -   **关于 $b_2$ 的梯度**：$\\frac{\\partial f_{\\theta}}{\\partial b_2} = I$，单位矩阵。向量 $b_2$ 梯度的被积函数是 $a$。\n        $$ \\frac{d\\mathcal{L}}{db_2} = \\int_0^T a(t) dt $$\n    -   **关于 $W_1$ 的梯度**：使用链式法则，$\\frac{\\partial f_{\\theta}}{\\partial W_1} = W_2 \\frac{\\partial h}{\\partial z} \\frac{\\partial z}{\\partial W_1}$。矩阵 $W_1$ 梯度的被积函数是 $\\text{diag}(1-h^2) (W_2^\\top a) x^\\top$。\n        $$ \\frac{d\\mathcal{L}}{dW_1} = \\int_0^T \\text{diag}(1 - h(t)^2) (W_2^\\top a(t)) x(t)^\\top dt $$\n    -   **关于 $b_1$ 的梯度**：类似地，向量 $b_1$ 梯度的被积函数是 $\\text{diag}(1-h^2) (W_2^\\top a)$。\n        $$ \\frac{d\\mathcal{L}}{db_1} = \\int_0^T \\text{diag}(1 - h(t)^2) W_2^\\top a(t) dt $$\n    -   **关于 $k_d$ 的梯度**：$\\frac{\\partial f_{\\theta}}{\\partial k_d} = -\\text{diag}(x)$。向量 $k_d$ 梯度的被积函数是 $-(a \\odot x)$。\n        $$ \\frac{d\\mathcal{L}}{dk_d} = \\int_0^T -(a(t) \\odot x(t)) dt $$\n\n### 算法设计和数值实现\n\n该算法分三个主要阶段进行：一个前向过程，用于求解状态轨迹；一个反向过程，用于求解伴随轨迹并累积参数梯度；以及一个使用有限差分的验证步骤。\n\n1.  **前向过程**：状态 ODE $\\frac{dx}{dt} = f_{\\theta}(x,t)$ 使用固定步长 $\\Delta t = T/N$ 的显式四阶 Runge–Kutta (RK4) 方法从 $t=0$ 积分到 $t=T$。在时间点 $\\{t_0, t_1, \\dots, t_N\\}$ 的状态 $\\{x_0, x_1, \\dots, x_N\\}$ 被存储起来，用于反向过程。\n\n2.  **反向过程（伴随和梯度）**：伴随 ODE 和参数梯度积分被同时求解。\n    -   伴随 ODE 从 $t=T$ 反向积分到 $t=0$。问题指定了“一阶显式方法”。这被实现为时间反转系统的显式 Euler 方法。给定在时间 $t_i$ 的 $a_i$，前一个时间步 $t_{i-1}$ 的状态近似为：\n        $$ a_{i-1} = a_i - \\Delta t \\left( \\frac{da}{dt} \\right)\\bigg|_{t_i} = a_i - \\Delta t \\left( -J(x_i, \\theta)^\\top a_i \\right) = a_i + \\Delta t J(x_i, \\theta)^\\top a_i $$\n    -   参数梯度积分使用一个简单的求积法则来近似，与反向 Euler 积分一致。使用右黎曼和，从 $i=N$ 到 $i=1$ 累积每个时间步 $t_i$ 的梯度贡献：\n        $$ \\frac{d\\mathcal{L}}{d\\theta} \\approx \\sum_{i=1}^N \\left( a_i^\\top \\frac{\\partial f_{\\theta}}{\\partial \\theta}\\bigg|_{x_i} \\right) \\Delta t $$\n    -   该过程从 $a_N = x_N - x_{\\text{target}}$ 开始并反向迭代，在每一步更新伴随状态并加到总梯度上。\n\n3.  **通过有限差分进行验证**：计算出的伴随梯度与中心有限差分近似进行比较。对于每个标量参数 $\\theta_j$，其梯度分量由下式近似：\n    $$\n    \\frac{d\\mathcal{L}}{d\\theta_j} \\approx \\frac{\\mathcal{L}(\\theta + \\epsilon e_j) - \\mathcal{L}(\\theta - \\epsilon e_j)}{2\\epsilon}\n    $$\n    其中 $e_j$ 是一个标准基向量，$\\epsilon$ 是一个小的扰动。这需要为每个参数重新积分前向 ODE 两次。然后将伴随梯度向量和有限差分梯度向量之间的最大绝对差与给定的容差 $\\tau$ 进行比较。这种比较评估了在特定数值离散化下连续伴随方法的准确性。由于连续伴随方法的“先优化后离散”性质与 RK4 求解器上的有限差分检验所隐含定义的“先离散后优化”性质之间的差异，预计会出现偏差。随着积分步长 $\\Delta t$ 趋近于 $0$，这些偏差预计会减小。具有不同 $N$ 和非线性缩放因子 $s$ 的测试用例旨在探索这种行为。", "answer": "```python\nimport numpy as np\n\nclass ModelParams:\n    \"\"\"\n    A helper class to manage model parameters, including packing to a flat vector\n    and unpacking from it, and applying scaling.\n    \"\"\"\n    def __init__(self, W1, b1, W2, b2, kd):\n        self.W1 = np.array(W1, dtype=np.float64)\n        self.b1 = np.array(b1, dtype=np.float64)\n        self.W2 = np.array(W2, dtype=np.float64)\n        self.b2 = np.array(b2, dtype=np.float64)\n        self.kd = np.array(kd, dtype=np.float64)\n        \n        self.shapes = [self.W1.shape, self.b1.shape, self.W2.shape, self.b2.shape, self.kd.shape]\n        self.sizes = [p.size for p in [self.W1, self.b1, self.W2, self.b2, self.kd]]\n        self.total_size = sum(self.sizes)\n\n    def pack(self):\n        \"\"\"Packs all parameters into a single flat numpy array.\"\"\"\n        return np.concatenate([p.flatten() for p in [self.W1, self.b1, self.W2, self.b2, self.kd]])\n\n    @classmethod\n    def from_flat(cls, theta_flat):\n        \"\"\"Creates a ModelParams object from a flat numpy array.\"\"\"\n        theta_flat = np.array(theta_flat, dtype=np.float64)\n        # Fixed shapes from the problem description\n        shapes = [(3, 2), (3,), (2, 3), (2,), (2,)]\n        sizes = [np.prod(s) for s in shapes]\n        \n        ptr = 0\n        unpacked_params = []\n        for i, shape in enumerate(shapes):\n            size = sizes[i]\n            param_flat = theta_flat[ptr:ptr+size]\n            unpacked_params.append(param_flat.reshape(shape))\n            ptr += size\n        \n        return cls(*unpacked_params)\n\n    def scale(self, s):\n        \"\"\"Applies scaling factor s to network weights and biases.\"\"\"\n        return ModelParams(self.W1 * s, self.b1 * s, self.W2 * s, self.b2 * s, self.kd)\n\ndef ode_func(x, params: ModelParams):\n    \"\"\"The ODE function dx/dt = f(x, t, theta).\"\"\"\n    z = params.W1 @ x + params.b1\n    h = np.tanh(z)\n    return params.W2 @ h + params.b2 - params.kd * x\n\ndef run_rk4(x0, T, N, params: ModelParams):\n    \"\"\"Integrates the ODE using a 4th-order Runge-Kutta method.\"\"\"\n    dt = T / N\n    x_traj = np.zeros((N + 1, x0.shape[0]), dtype=np.float64)\n    x_traj[0] = x0\n    x = x0.copy()\n    \n    for i in range(N):\n        k1 = ode_func(x, params)\n        k2 = ode_func(x + 0.5 * dt * k1, params)\n        k3 = ode_func(x + 0.5 * dt * k2, params)\n        k4 = ode_func(x + dt * k3, params)\n        x += (dt / 6.0) * (k1 + 2 * k2 + 2 * k3 + k4)\n        x_traj[i+1] = x\n        \n    return x_traj\n\ndef compute_loss(x_final, xtarget):\n    \"\"\"Computes the loss function L.\"\"\"\n    return 0.5 * np.sum((x_final - xtarget)**2)\n\ndef compute_dfdx(x, params: ModelParams):\n    \"\"\"Computes the Jacobian of the ODE function w.r.t. x.\"\"\"\n    z = params.W1 @ x + params.b1\n    h = np.tanh(z)\n    diag_1_minus_h2 = np.diag(1 - h**2)\n    return params.W2 @ diag_1_minus_h2 @ params.W1 - np.diag(params.kd)\n\ndef compute_adjoint_gradient(x0, T, N, params: ModelParams, xtarget):\n    \"\"\"Computes the gradient dL/dtheta using the adjoint method.\"\"\"\n    dt = T / N\n    x_traj = run_rk4(x0, T, N, params)\n    \n    grad_W1 = np.zeros_like(params.W1)\n    grad_b1 = np.zeros_like(params.b1)\n    grad_W2 = np.zeros_like(params.W2)\n    grad_b2 = np.zeros_like(params.b2)\n    grad_kd = np.zeros_like(params.kd)\n    \n    a = x_traj[N] - xtarget\n    \n    for i in range(N, 0, -1):\n        x = x_traj[i]\n        \n        z = params.W1 @ x + params.b1\n        h = np.tanh(z)\n        \n        # Accumulate gradient contributions from time t_i\n        grad_b2 += a * dt\n        grad_W2 += np.outer(a, h) * dt\n        grad_kd += -(a * x) * dt\n        \n        v = (1 - h**2) * (params.W2.T @ a)\n        grad_b1 += v * dt\n        grad_W1 += np.outer(v, x) * dt\n        \n        # Update adjoint state from t_i to t_{i-1}\n        jacobian = compute_dfdx(x, params)\n        a = a + dt * (jacobian.T @ a)\n        \n    packed_grads = np.concatenate([\n        grad_W1.flatten(), grad_b1.flatten(), grad_W2.flatten(),\n        grad_b2.flatten(), grad_kd.flatten()\n    ])\n    return packed_grads\n\ndef compute_fd_gradient(x0, T, N, base_params: ModelParams, xtarget, epsilon):\n    \"\"\"Computes the gradient dL/dtheta using central finite differences.\"\"\"\n    base_theta = base_params.pack()\n    grad = np.zeros_like(base_theta)\n    \n    def loss_func(theta_flat):\n        params_pert = ModelParams.from_flat(theta_flat)\n        x_traj = run_rk4(x0, T, N, params_pert)\n        return compute_loss(x_traj[-1], xtarget)\n\n    for i in range(len(base_theta)):\n        theta_plus = base_theta.copy()\n        theta_plus[i] += epsilon\n        \n        theta_minus = base_theta.copy()\n        theta_minus[i] -= epsilon\n        \n        loss_plus = loss_func(theta_plus)\n        loss_minus = loss_func(theta_minus)\n        \n        grad[i] = (loss_plus - loss_minus) / (2 * epsilon)\n        \n    return grad\n\ndef solve():\n    \"\"\"Main function to run test cases and produce the final output.\"\"\"\n    W1_base = np.array([[0.8, -0.5], [0.3, 0.9], [-0.7, 0.2]])\n    b1_base = np.array([0.1, -0.2, 0.05])\n    W2_base = np.array([[0.5, -0.3, 0.1], [-0.4, 0.6, -0.2]])\n    b2_base = np.array([0.0, 0.05])\n    kd_base = np.array([0.3, 0.5])\n    base_params_obj = ModelParams(W1_base, b1_base, W2_base, b2_base, kd_base)\n\n    x0 = np.array([0.5, 0.2])\n    xtarget = np.array([0.1, -0.1])\n    T = 2.0\n\n    test_cases = [\n        (500, 1e-6, 2e-2, 1.0),\n        (50, 1e-6, 2e-2, 1.0),\n        (20, 1e-6, 5e-2, 1.0),\n        (60, 1e-6, 1e-2, 0.05),\n    ]\n\n    results = []\n    \n    for N, epsilon, tau, s in test_cases:\n        scaled_params = base_params_obj.scale(s)\n        \n        grad_adj = compute_adjoint_gradient(x0, T, N, scaled_params, xtarget)\n        grad_fd = compute_fd_gradient(x0, T, N, scaled_params, xtarget, epsilon)\n\n        max_abs_diff = np.max(np.abs(grad_adj - grad_fd))\n        \n        results.append(max_abs_diff  tau)\n        \n    bool_str_results = [str(b) for b in results]\n    print(f\"[{','.join(bool_str_results)}]\")\n\nsolve()\n```", "id": "3333095"}, {"introduction": "现实世界的模型常常包含非光滑成分，如阈值或投影，这给基于梯度的优化带来了巨大挑战。本实践 [@problem_id:3364106] 通过一个包含干湿过程的水文模型，深入探讨了这一高级主题。您将实现一个“先离散化后优化”(discretize-then-optimize)的伴随模型，它能精确计算离散数值算法（包括其不可微部分）的梯度，这是稳健数据同化和反演问题中的一项关键技能。", "problem": "考虑在二维单位正方形上恢复一个未知标量电导率场的离散逆问题。设物理域为单位正方形，其所有边界上均为零狄利克雷（Dirichlet）边界条件，并考虑以下椭圆型偏微分方程\n$$\n-\\nabla\\cdot\\left(\\sigma(x,y)\\,\\nabla u(x,y)\\right) = s(x,y) \\quad \\text{在内部}, \\quad u(x,y)=0 \\quad \\text{在边界上},\n$$\n其中 $u$ 是状态，$\\sigma$ 是待推断的正电导率，$s$ 是一个已知源项。观测算子选择 $u$ 在一组固定的内部网格点上的值。\n\n你需要在无量纲设定下进行操作，并在一个包含 $N_x=N_y=32$ 个单元中心的均匀笛卡尔网格上离散化该问题，两个方向上的网格尺寸均为 $h=1/(N_x)$。使用对称的两点通量近似方法，并对内部界面采用调和平均，来施加零狄利克雷边界条件。设未知离散电导率 $\\sigma\\in\\mathbb{R}^{N_xN_y}$ 是定义在单元中心的，并且严格为正。离散正演算子 $A(\\sigma)$ 是由这种通量相容的离散化产生的稀疏刚度矩阵，离散正演状态 $u(\\sigma)$ 求解\n$$\nA(\\sigma)\\,u = b,\n$$\n其中 $b$ 是代表源项的离散载荷向量。\n\n使用一个选择算子 $P$ 定义数据失配项，该算子在16个均匀分布的内部网格索引处提取 $u$ 的内部值（避免最外层单元以确保在域内部）。定义目标泛函\n$$\nJ(\\sigma) = \\frac{1}{2}\\,\\|P\\,u(\\sigma) - d\\|_2^2 + \\alpha \\,\\mathrm{TV}_\\varepsilon(\\sigma),\n$$\n其中 $\\alpha0$ 是一个正则化权重，$d$ 是使用相同的正演模型从已知的 $\\sigma_{\\mathrm{true}}$ 生成的无噪声合成数据，而 $\\mathrm{TV}_\\varepsilon$ 是一个平滑的各向同性全变分，它通过每个坐标方向上的前向有限差分和带有平滑参数 $\\varepsilon0$ 的各向同性欧几里得（Euclidean）范数在网格上定义：\n$$\n\\mathrm{TV}_\\varepsilon(\\sigma) = \\sum_{i,j} \\sqrt{\\left(D_x \\sigma\\right)_{i,j}^2 + \\left(D_y \\sigma\\right)_{i,j}^2 + \\varepsilon^2}.\n$$\n此处，$(D_x \\sigma)_{i,j}$ 和 $(D_y \\sigma)_{i,j}$ 分别表示在 $x$ 和 $y$ 方向上的前向差分，对于跨越边界的差分采用齐次诺伊曼（Neumann）延拓。源项 $s(x,y)$ 是一个中心位于 $(x_c,y_c)=(0.3,0.7)$、标准差为 $0.07$ 的归一化高斯（Gaussian）函数，其离散对应物 $b$ 通过在单元中心进行逐点求值得到。\n\n任务：\n- 从带有偏微分方程约束的拉格朗日（Lagrangian）量和标准一阶最优性原理出发，推导连续伴随方程以及数据失配项关于 $\\sigma$ 的梯度的连续表达式，该表达式用状态 $u$ 和伴随状态 $\\lambda$ 表示。然后，在指定的通量相容离散化（界面上采用调和平均）下，为数据失配部分推导一个相容的离散伴随系统和相应的离散梯度。\n- 从 $\\mathrm{TV}_\\varepsilon(\\sigma)$ 的定义出发，使用离散散度作为齐次诺伊曼条件下前向差分梯度的负伴随，推导平滑各向同性全变分的离散梯度。\n- 实现一个求解器，该求解器：\n  1. 对任何容许的 $\\sigma$ 组装 $A(\\sigma)$ 并求解正演问题。\n  2. 使用观测算子构建离散伴随问题的右端项，并求解伴随问题。\n  3. 使用推导出的公式计算 $J(\\sigma)$ 及其梯度 $\\nabla J(\\sigma)$。\n  4. 对初始猜测 $\\sigma_0$ 和一个随机方向 $\\delta\\sigma$，为完整目标函数（数据失配项加平滑全变分）执行中心有限差分方向导数检验，使用步长 $h_{\\mathrm{fd}}=10^{-4}$，并进行缩放以确保 $\\sigma_0 \\pm h_{\\mathrm{fd}}\\,\\delta\\sigma$ 保持严格为正。报告由下式定义的相对梯度误差\n     $$\n     E_{\\mathrm{rel}} = \\frac{\\left|\\langle \\nabla J(\\sigma_0), \\delta\\sigma\\rangle - \\frac{J(\\sigma_0+h_{\\mathrm{fd}}\\delta\\sigma)-J(\\sigma_0-h_{\\mathrm{fd}}\\delta\\sigma)}{2h_{\\mathrm{fd}}}\\right|}{\\max\\left\\{1, \\left|\\frac{J(\\sigma_0+h_{\\mathrm{fd}}\\delta\\sigma)-J(\\sigma_0-h_{\\mathrm{fd}}\\delta\\sigma)}{2h_{\\mathrm{fd}}}\\right|, \\left|\\langle \\nabla J(\\sigma_0), \\delta\\sigma\\rangle\\right|\\right\\}}.\n     $$\n  5. 运行一个固定预算（10次迭代）的梯度下降反演来最小化 $J(\\sigma)$，采用 Armijo 回溯线搜索。每次更新后，通过投影到 $[\\sigma_{\\min},\\infty)$（其中 $\\sigma_{\\min}=0.2$）来强制 $\\sigma$ 的正性。使用初始步长 $10^{-1}$，Armijo 参数 $c=10^{-4}$，以及回溯因子 $\\beta=1/2$。\n  6. 在10次迭代后，计算恢复的 $\\sigma$ 的边缘锐度度量。该度量是在真实模型中一个圆形夹杂物边界周围一个两个单元宽度的带上，对离散梯度模 $\\sqrt{\\left(D_x \\sigma\\right)_{i,j}^2 + \\left(D_y \\sigma\\right)_{i,j}^2}$ 进行平均得到。真实模型为：在中心为 $(0.5,0.5)$、半径为 $0.25$ 的圆盘内 $\\sigma_{\\mathrm{true}}=2$，在圆盘外 $\\sigma_{\\mathrm{true}}=1$。该带定义为 $\\{(x_i,y_j): | \\sqrt{(x_i-0.5)^2+(y_j-0.5)^2} - 0.25| \\le 2h\\}$。\n\n测试套件和要求输出：\n- 使用 $\\alpha=10^{-3}$，初始猜测 $\\sigma_0 \\equiv 1$，以及通过求解上述定义的 $\\sigma_{\\mathrm{true}}$ 的正演问题生成的无噪声数据 $d$。\n- 评估以下四种情况：\n  1. $\\varepsilon=10^{-1}$ 时的梯度检验相对误差 $E_{\\mathrm{rel}}$。\n  2. $\\varepsilon=10^{-3}$ 时的梯度检验相对误差 $E_{\\mathrm{rel}}$。\n  3. 使用 $\\varepsilon=10^{-1}$ 进行10次反演迭代后的边缘锐度度量。\n  4. 使用 $\\varepsilon=10^{-3}$ 进行10次反演迭代后的边缘锐度度量。\n- 你的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表，结果按上述顺序列出，例如：$[r_1,r_2,r_3,r_4]$，其中每个 $r_k$ 都是一个浮点数。\n\n所有量都是无量纲的，并应如此处理。不使用角度（如有）。不使用百分比。最终输出必须严格遵循指定的单行格式。", "solution": "用户想要解决一个离散逆问题。\n\n**1. 问题验证**\n\n*   **步骤 1：提取已知条件**\n    *   **偏微分方程：** $-\\nabla\\cdot\\left(\\sigma(x,y)\\,\\nabla u(x,y)\\right) = s(x,y)$ 在单位正方形上。\n    *   **边界条件：** 所有边界上 $u(x,y)=0$。\n    *   **离散化：** 均匀笛卡尔网格，$N_x=N_y=32$ 个单元中心。网格尺寸 $h=1/N_x$。对称的两点通量近似，内部界面采用调和平均。\n    *   **未知量：** 单元中心的电导率 $\\sigma\\in\\mathbb{R}^{N_xN_y}$，$\\sigma0$。\n    *   **正演模型：** $A(\\sigma)\\,u = b$，其中 $A(\\sigma)$ 是稀疏刚度矩阵，$b$ 是离散载荷向量。\n    *   **目标泛函：** $J(\\sigma) = \\frac{1}{2}\\,\\|P\\,u(\\sigma) - d\\|_2^2 + \\alpha \\,\\mathrm{TV}_\\varepsilon(\\sigma)$。\n    *   **观测算子 $P$：** 提取 $u$ 在16个均匀分布的内部网格索引处的值。\n    *   **数据 $d$：** 无噪声合成数据，$d = P u(\\sigma_{\\mathrm{true}})$。\n    *   **正则化：** 平滑各向同性全变分，$\\mathrm{TV}_\\varepsilon(\\sigma) = \\sum_{i,j} \\sqrt{\\left(D_x \\sigma\\right)_{i,j}^2 + \\left(D_y \\sigma\\right)_{i,j}^2 + \\varepsilon^2}$。\n    *   **差分算子：** $D_x, D_y$ 是带齐次诺伊曼延拓的前向有限差分。\n    *   **源项 $s(x,y)$：** 中心位于 $(x_c,y_c)=(0.3,0.7)$、标准差为 $0.07$ 的归一化高斯函数。离散版本 $b$ 通过在单元中心逐点求值得到。\n    *   **真实电导率 $\\sigma_{\\mathrm{true}}$：** 在中心为 $(0.5,0.5)$、半径为 $0.25$ 的圆盘内值为 $2$，外部为 $1$。\n    *   **参数：** $\\alpha=10^{-3}$，初始猜测 $\\sigma_0 \\equiv 1$，$\\sigma_{\\min}=0.2$。\n    *   **梯度检验：** 中心有限差分检验，步长 $h_{\\mathrm{fd}}=10^{-4}$。\n    *   **反演算法：** 10次迭代的梯度下降法，采用 Armijo 回溯线搜索（初始步长 $10^{-1}$，$c=10^{-4}$，$\\beta=1/2$）。\n    *   **输出度量：** 在真实不连续性周围的一个带内的平均梯度模长作为边缘锐度度量。\n    *   **测试案例：** 基于 $\\varepsilon=10^{-1}$ 和 $\\varepsilon=10^{-3}$ 计算四个值：两个梯度检验误差和两个锐度度量。\n\n*   **步骤 2：使用提取的已知条件进行验证**\n    *   该问题**具有科学依据**，基于标准的椭圆型偏微分方程理论和逆问题的吉洪诺夫正则化方法。\n    *   该问题是**适定的**，因为正演模型是一个标准的可解边界值问题，并且优化问题的结构适合数值求解，这是非适定逆问题的标准做法。\n    *   该问题是**客观的**，并用精确的数学公式描述。\n    *   关于如何在边界处构造对称离散化矩阵 $A(\\sigma)$ 存在轻微的模糊之处。“对内部界面”这一短语暗示了对边界界面有不同的处理方式。一种为狄利克雷边界保持矩阵对称性的标准有限体积法涉及对邻近边界的界面使用特定的传输系数。这种解释与问题的整体结构一致，并在求解中被采纳。源项 $b$ 的离散化也根据标准有限体积实践假定为 $b_i = s(x_i, y_i) h^2$。这些是对轻微模糊之处的合理解决方法。\n    *   该问题没有违反任何无效标准。它是一个定义明确、非平凡且在计算科学与工程领域中的标准问题。\n\n*   **步骤 3：结论和行动**\n    *   该问题被判定为**有效的**。将提供一个解决方案。\n\n**2. 理论推导**\n\n**2.1. 连续伴随状态法**\n\n令问题域为 $\\Omega=(0,1)^2$。目标泛函为 $J(\\sigma) = \\frac{1}{2} \\int_\\Omega (P u - d)^2 d\\mathbf{x} + \\alpha \\mathrm{TV}_\\varepsilon(\\sigma)$，其中 $P$ 是一个观测算子。状态 $u$ 受偏微分方程 $-\\nabla\\cdot(\\sigma\\nabla u) = s$ 在 $\\Omega$ 中和 $u=0$ 在 $\\partial\\Omega$ 上的约束。\n\n我们通过使用伴随状态（或拉格朗日乘子）$\\lambda$ 将目标泛函与偏微分方程约束增广，形成拉格朗日量 $\\mathcal{L}$：\n$$\n\\mathcal{L}(u, \\sigma, \\lambda) = J(u, \\sigma) - \\int_\\Omega \\lambda \\left[ \\nabla\\cdot(\\sigma\\nabla u) + s \\right] d\\mathbf{x}\n$$\n一阶最优性条件要求 $\\mathcal{L}$ 关于每个变量的 Fréchet 导数为零。我们首先关注数据失配部分。令 $J_m(u) = \\frac{1}{2}\\int_\\Omega (Pu-d)^2 d\\mathbf{x}$。\n\n在方向 $\\delta u$ 上（其中在 $\\partial\\Omega$ 上 $\\delta u = 0$）关于状态 $u$ 的导数为：\n$$\nD_u\\mathcal{L}[\\delta u] = \\int_\\Omega (Pu-d) P\\delta u \\,d\\mathbf{x} - \\int_\\Omega \\lambda \\nabla\\cdot(\\sigma\\nabla \\delta u) \\,d\\mathbf{x} = 0\n$$\n对第二项使用两次格林第一恒等式，并选择伴随边界条件 $\\lambda=0$ 在 $\\partial\\Omega$ 上：\n$$\n\\int_\\Omega \\lambda \\nabla\\cdot(\\sigma\\nabla \\delta u) \\,d\\mathbf{x} = \\int_\\Omega \\delta u \\nabla\\cdot(\\sigma\\nabla \\lambda) \\,d\\mathbf{x}\n$$\n因此，条件变为：\n$$\n\\int_\\Omega \\left[ P^T(Pu-d) - \\nabla\\cdot(\\sigma\\nabla \\lambda) \\right] \\delta u \\,d\\mathbf{x} = 0\n$$\n由于这对所有容许的 $\\delta u$ 必须成立，我们得到**伴随方程**：\n$$\n-\\nabla\\cdot(\\sigma\\nabla \\lambda) = P^T(Pu-d) \\quad \\text{在 } \\Omega, \\quad \\lambda = 0 \\quad \\text{在 } \\partial\\Omega\n$$\n此处，$P^T$ 是观测算子 $P$ 的伴随算子。如果 $P$ 提取点值，则 $P^T$ 在这些点注入加权的狄拉克δ函数。\n\n接下来，我们在方向 $\\delta\\sigma$ 上对控制变量 $\\sigma$ 求导。数据失配项贡献的导数为：\n$$\nD_\\sigma\\mathcal{L}[\\delta\\sigma] = - \\int_\\Omega \\lambda \\nabla\\cdot(\\delta\\sigma\\nabla u) \\,d\\mathbf{x}\n$$\n使用格林第一恒等式：\n$$\nD_\\sigma\\mathcal{L}[\\delta\\sigma] = \\int_\\Omega \\nabla\\lambda \\cdot (\\delta\\sigma \\nabla u) \\,d\\mathbf{x} = \\int_\\Omega (\\nabla u \\cdot \\nabla \\lambda) \\delta\\sigma \\,d\\mathbf{x}\n$$\n由此，我们确定数据失配项关于 $\\sigma$ 的梯度为：\n$$\n\\nabla_\\sigma J_m(\\sigma) = \\nabla u \\cdot \\nabla \\lambda\n$$\n\n**2.2. 离散伴随和数据失配的梯度**\n\n令离散状态 $u \\in\\mathbb{R}^N$（其中 $N=N_x N_y$）求解线性系统 $A(\\sigma)u=b$。离散目标函数为 $J(\\sigma) = \\frac{1}{2}\\|Pu-d\\|_2^2 + \\alpha \\mathrm{TV}_\\varepsilon(\\sigma)$。数据失配项的离散拉格朗日量为：\n$$\n\\mathcal{L}_d(u, \\sigma, \\lambda) = \\frac{1}{2}(Pu-d)^T(Pu-d) + \\lambda^T(A(\\sigma)u-b)\n$$\n将关于 $u$ 的梯度设为零，得到离散伴随方程：\n$$\n\\frac{\\partial \\mathcal{L}_d}{\\partial u} = P^T(Pu-d) + A(\\sigma)^T\\lambda = 0 \\implies A(\\sigma)^T\\lambda = -P^T(Pu-d)\n$$\n所选择的离散化方法（采用调和平均的有限体积法和特定的边界处理）产生一个对称的刚度矩阵 $A(\\sigma)$，因此 $A(\\sigma)^T=A(\\sigma)$。伴随状态 $\\lambda$ 通过求解以下方程得到：\n$$\nA(\\sigma)\\lambda = -P^T(Pu-d)\n$$\n$\\mathcal{L}_d$ 关于单个电导率参数 $\\sigma_k$ 的梯度为：\n$$\n\\frac{\\partial \\mathcal{L}_d}{\\partial \\sigma_k} = \\lambda^T \\frac{\\partial A(\\sigma)}{\\partial \\sigma_k} u\n$$\n让我们更具体地说明。与算子相关的能量是 $\\frac{1}{2}u^T A(\\sigma) u$。对于我们的离散化，这可以表示为界面上的和：\n$$\n\\frac{1}{2} u^T A(\\sigma) u = \\frac{1}{2} \\sum_{\\langle k,m \\rangle} T_{km}(\\sigma_k, \\sigma_m)(u_k-u_m)^2 + \\frac{1}{2} \\sum_{k \\in \\partial\\Omega_d} \\sum_{f \\in \\partial B_k} T_{kf}(\\sigma_k) u_k^2\n$$\n其中 $\\langle k,m \\rangle$ 表示单元 $k$ 和 $m$ 之间的内部界面，$\\partial\\Omega_d$ 是离散边界单元的集合，$\\partial B_k$ 是单元 $k$ 的边界界面。内部界面的传输系数为 $T_{km} = \\frac{2\\sigma_k\\sigma_m}{\\sigma_k+\\sigma_m}$，边界界面的传输系数为 $T_{kf}=2\\sigma_k$。\n$\\lambda^T A(\\sigma) u$ 项具有相似的结构：\n$$\n\\lambda^T A(\\sigma) u = \\sum_{\\langle k,m \\rangle} T_{km}(\\lambda_k-\\lambda_m)(u_k-u_m) + \\sum_{k \\in \\partial\\Omega_d} \\sum_{f \\in \\partial B_k} T_{kf} \\lambda_k u_k\n$$\n对 $\\sigma_k$ 求导，得到梯度的第 $k$ 个分量：\n$$\n(\\nabla_\\sigma J_m)_k = \\sum_{m \\sim k} \\frac{\\partial T_{km}}{\\partial \\sigma_k} (\\lambda_k-\\lambda_m)(u_k-u_m) + \\sum_{f \\in \\partial B_k} \\frac{\\partial T_{kf}}{\\partial \\sigma_k} \\lambda_k u_k\n$$\n由于 $\\frac{\\partial T_{km}}{\\partial \\sigma_k} = \\frac{2\\sigma_m^2}{(\\sigma_k+\\sigma_m)^2}$ 和 $\\frac{\\partial T_{kf}}{\\partial \\sigma_k} = 2$，上式变为：\n$$\n(\\nabla_\\sigma J_m)_k = \\sum_{m \\sim k} \\frac{2\\sigma_m^2}{(\\sigma_k+\\sigma_m)^2} (\\lambda_k-\\lambda_m)(u_k-u_m) + \\sum_{f \\in \\partial B_k} 2\\lambda_k u_k\n$$\n其中第一个和是对单元 $k$ 的内部邻居求和，第二个和是对其边界界面求和。\n\n**2.3. 平滑全变分的离散梯度**\n\n平滑TV项为 $R(\\sigma) = \\mathrm{TV}_\\varepsilon(\\sigma) = \\sum_{i,j} \\sqrt{(D_x\\sigma)_{ij}^2 + (D_y\\sigma)_{ij}^2 + \\varepsilon^2}$。令 $G\\sigma = \\begin{pmatrix} D_x \\sigma \\\\ D_y \\sigma \\end{pmatrix}$。令 $w_{ij}(\\sigma) = \\sqrt{(D_x\\sigma)_{ij}^2 + (D_y\\sigma)_{ij}^2 + \\varepsilon^2}$。\n$R$ 关于 $\\sigma_k$ 的梯度通过链式法则求得：\n$$\n\\frac{\\partial R}{\\partial \\sigma_k} = \\sum_{i,j} \\frac{\\partial w_{ij}}{\\partial \\sigma_k} = \\sum_{i,j} \\frac{1}{w_{ij}} \\left( (D_x\\sigma)_{ij} \\frac{\\partial(D_x\\sigma)_{ij}}{\\partial \\sigma_k} + (D_y\\sigma)_{ij} \\frac{\\partial(D_y\\sigma)_{ij}}{\\partial \\sigma_k} \\right)\n$$\n这个表达式可以用差分算子的形式伴随（转置）来紧凑地写出。令 $v_x = (D_x\\sigma)./w$ 和 $v_y = (D_y\\sigma)./w$ 为向量场。则梯度为：\n$$\n\\nabla R(\\sigma) = -(D_x^T v_x + D_y^T v_y) = -\\mathrm{div}(v)\n$$\n前向差分算子 $D_x, D_y$ 定义时带有齐次诺伊曼延拓，意味着 $(D_x\\sigma)_{N_x-1,j}=0$ 和 $(D_y\\sigma)_{i,N_y-1}=0$。伴随算子 $D_x^T, D_y^T$ 是后向差分算子，其在边界处的结构由离散分部积分恒等式 $\\langle D\\sigma, v \\rangle = \\langle \\sigma, D^T v \\rangle$ 决定。对于指定的 $D_x$，分量 $(D_x^T v_x)_{i,j}$ 为：\n\\begin{itemize}\n    \\item $(v_x)_{i-1,j} - (v_x)_{i,j}$ 当 $i \\in \\{1,\\dots,N_x-2\\}$\n    \\item $- (v_x)_{0,j}$ 当 $i=0$\n    \\item $(v_x)_{N_x-2,j}$ 当 $i=N_x-1$\n\\end{itemize}\n类似的形式适用于 $D_y^T$。\n\n**3. 实现计划**\n该解决方案将使用 `numpy` 和 `scipy` 在 Python 中实现。\n1.  **网格和模型设置：** 一个 `InverseProblem` 类将封装网格、物理参数和离散化细节。\n2.  **矩阵组装：** 一个方法 `assemble_A(sigma)` 将根据推导的有限体积格式构造稀疏刚度矩阵 $A$。\n3.  **求解器：** `scipy.sparse.linalg.spsolve` 将用于求解正演（$A u = b$）和伴随（$A \\lambda = g$）系统。\n4.  **目标和梯度：** 方法 `compute_objective(sigma)` 和 `compute_gradient(sigma)` 将实现完整的目标泛函 $J(\\sigma)$ 及其解析梯度 $\\nabla J(\\sigma) = \\nabla J_m + \\alpha \\nabla R$。\n5.  **梯度检验：** 一个函数将把解析梯度在一个随机方向上的投影与中心有限差分近似进行比较。\n6.  **优化：** 将实现一个固定迭代次数的梯度下降循环，包括 Armijo 回溯线搜索和正性投影。\n7.  **后处理：** 将在最终反演的电导率场上计算边缘锐度度量。\n8.  **主脚本：** `solve` 函数将为两个指定的 $\\varepsilon$ 值协调这些步骤，并打印所需的四个结果。", "answer": "```python\nimport numpy as np\nfrom scipy.sparse import lil_matrix, csc_matrix\nfrom scipy.sparse.linalg import spsolve\n\nclass InverseProblem:\n    def __init__(self, Nx=32, Ny=32, alpha=1e-3, epsilon=1e-1):\n        self.Nx = Nx\n        self.Ny = Ny\n        self.N = Nx * Ny\n        self.h = 1.0 / Nx\n\n        self.alpha = alpha\n        self.epsilon = epsilon\n        \n        self.x = np.linspace(0.5 * self.h, 1.0 - 0.5 * self.h, Nx)\n        self.y = np.linspace(0.5 * self.h, 1.0 - 0.5 * self.h, Ny)\n        self.xx, self.yy = np.meshgrid(self.x, self.y)\n        \n        # Source term\n        s = np.exp(-((self.xx - 0.3)**2 + (self.yy - 0.7)**2) / (2 * 0.07**2))\n        self.b = (self.h**2 * s).flatten()\n\n        # True conductivity\n        radius_sq = 0.25**2\n        self.sigma_true = np.ones((Ny, Nx))\n        self.sigma_true[(self.xx - 0.5)**2 + (self.yy - 0.5)**2  radius_sq] = 2.0\n        self.sigma_true = self.sigma_true.flatten()\n\n        # Observation operator P\n        obs_indices_1d = np.round(np.linspace(4, self.Nx - 5, 4)).astype(int)\n        self.obs_indices = []\n        for i in obs_indices_1d:\n            for j in obs_indices_1d:\n                self.obs_indices.append(j * self.Nx + i)\n        \n        self.P = lil_matrix((len(self.obs_indices), self.N))\n        for i, idx in enumerate(self.obs_indices):\n            self.P[i, idx] = 1.0\n        self.P = self.P.tocsc()\n        \n        # Generate synthetic data\n        u_true = self.solve_forward(self.sigma_true)\n        self.d_obs = self.P @ u_true\n\n    def _to_1d(self, i, j):\n        return j * self.Nx + i\n\n    def assemble_A(self, sigma):\n        A = lil_matrix((self.N, self.N))\n        sigma_2d = sigma.reshape((self.Ny, self.Nx))\n\n        for j in range(self.Ny):\n            for i in range(self.Nx):\n                k = self._to_1d(i, j)\n                diag_val = 0.0\n                \n                # East neighbor\n                if i  self.Nx - 1:\n                    m = self._to_1d(i + 1, j)\n                    T_em = 2 * sigma_2d[j, i] * sigma_2d[j, i + 1] / (sigma_2d[j, i] + sigma_2d[j, i + 1])\n                    A[k, m] = -T_em\n                    A[m, k] = -T_em\n                    diag_val += T_em\n                else: # Boundary\n                    diag_val += 2 * sigma_2d[j, i]\n\n                # West neighbor\n                if i > 0:\n                    pass\n                else: # Boundary\n                    diag_val += 2 * sigma_2d[j, i]\n\n                # North neighbor\n                if j  self.Ny - 1:\n                    m = self._to_1d(i, j + 1)\n                    T_nm = 2 * sigma_2d[j, i] * sigma_2d[j + 1, i] / (sigma_2d[j, i] + sigma_2d[j + 1, i])\n                    A[k, m] = -T_nm\n                    A[m, k] = -T_nm\n                    diag_val += T_nm\n                else: # Boundary\n                    diag_val += 2 * sigma_2d[j, i]\n\n                # South neighbor\n                if j > 0:\n                    pass\n                else: # Boundary\n                    diag_val += 2 * sigma_2d[j, i]\n\n                A[k, k] += diag_val\n        return A.tocsc()\n\n    def solve_forward(self, sigma):\n        A = self.assemble_A(sigma)\n        return spsolve(A, self.b)\n\n    def solve_adjoint(self, sigma, u):\n        A = self.assemble_A(sigma)\n        residual = self.P @ u - self.d_obs\n        adjoint_rhs = -self.P.T @ residual\n        return spsolve(A, adjoint_rhs)\n\n    def compute_objective(self, sigma):\n        # Data misfit term\n        u = self.solve_forward(sigma)\n        residual = self.P @ u - self.d_obs\n        J_misfit = 0.5 * np.dot(residual, residual)\n        \n        # Regularization term\n        sigma_2d = sigma.reshape((self.Ny, self.Nx))\n        Dx_sigma = np.zeros_like(sigma_2d)\n        Dy_sigma = np.zeros_like(sigma_2d)\n        Dx_sigma[:, :-1] = sigma_2d[:, 1:] - sigma_2d[:, :-1]\n        Dy_sigma[:-1, :] = sigma_2d[1:, :] - sigma_2d[:-1, :]\n        \n        tv_integrand = np.sqrt(Dx_sigma**2 + Dy_sigma**2 + self.epsilon**2)\n        J_tv = np.sum(tv_integrand)\n        \n        return J_misfit + self.alpha * J_tv\n\n    def compute_gradient(self, sigma):\n        u = self.solve_forward(sigma)\n        lam = self.solve_adjoint(sigma, u)\n        \n        sigma_2d = sigma.reshape((self.Ny, self.Nx))\n        u_2d = u.reshape((self.Ny, self.Nx))\n        lam_2d = lam.reshape((self.Ny, self.Nx))\n        \n        # Misfit gradient\n        grad_J_misfit = np.zeros_like(sigma_2d)\n        for j in range(self.Ny):\n            for i in range(self.Nx):\n                grad_val = 0.0\n                s_k = sigma_2d[j, i]\n                u_k = u_2d[j,i]\n                lam_k = lam_2d[j,i]\n                \n                # East\n                if i  self.Nx - 1:\n                    s_m = sigma_2d[j, i + 1]\n                    dT_dsk = 2 * s_m**2 / (s_k + s_m)**2\n                    grad_val += dT_dsk * (u_k - u_2d[j,i+1]) * (lam_k - lam_2d[j,i+1])\n                else: # Boundary\n                    grad_val += 2 * u_k * lam_k\n                # West\n                if i > 0:\n                    s_m = sigma_2d[j, i - 1]\n                    dT_dsk = 2 * s_m**2 / (s_k + s_m)**2\n                    grad_val += dT_dsk * (u_k - u_2d[j,i-1]) * (lam_k - lam_2d[j,i-1])\n                else: # Boundary\n                    grad_val += 2 * u_k * lam_k\n                # North\n                if j  self.Ny - 1:\n                    s_m = sigma_2d[j + 1, i]\n                    dT_dsk = 2 * s_m**2 / (s_k + s_m)**2\n                    grad_val += dT_dsk * (u_k - u_2d[j+1,i]) * (lam_k - lam_2d[j+1,i])\n                else: # Boundary\n                    grad_val += 2 * u_k * lam_k\n                # South\n                if j > 0:\n                    s_m = sigma_2d[j - 1, i]\n                    dT_dsk = 2 * s_m**2 / (s_k + s_m)**2\n                    grad_val += dT_dsk * (u_k - u_2d[j-1,i]) * (lam_k - lam_2d[j-1,i])\n                else: # Boundary\n                    grad_val += 2 * u_k * lam_k\n                \n                grad_J_misfit[j, i] = grad_val\n\n        # TV gradient\n        grad_J_tv = np.zeros_like(sigma_2d)\n        Dx_sigma = np.zeros_like(sigma_2d)\n        Dy_sigma = np.zeros_like(sigma_2d)\n        Dx_sigma[:, :-1] = sigma_2d[:, 1:] - sigma_2d[:, :-1]\n        Dy_sigma[:-1, :] = sigma_2d[1:, :] - sigma_2d[:-1, :]\n        \n        w = np.sqrt(Dx_sigma**2 + Dy_sigma**2 + self.epsilon**2)\n        vx = Dx_sigma / w\n        vy = Dy_sigma / w\n        \n        # Divergence\n        grad_J_tv[:, 1:] -= (vx[:, 1:] - vx[:, :-1])\n        grad_J_tv[:, 0] -= vx[:, 0]\n        grad_J_tv[1:, :] -= (vy[1:, :] - vy[:-1, :])\n        grad_J_tv[0, :] -= vy[0, :]\n        \n        return grad_J_misfit.flatten() + self.alpha * grad_J_tv.flatten()\n\n\ndef solve():\n    np.random.seed(42)\n    s0 = np.ones(32*32)\n    ds = np.random.randn(32*32)\n    h_fd = 1e-4\n    \n    results = []\n    \n    # Cases 1 and 3: epsilon = 1e-1\n    epsilon1 = 1e-1\n    model1 = InverseProblem(epsilon=epsilon1)\n\n    # Grad check\n    grad_J = model1.compute_gradient(s0)\n    J_plus = model1.compute_objective(s0 + h_fd * ds)\n    J_minus = model1.compute_objective(s0 - h_fd * ds)\n    \n    fd_deriv = (J_plus - J_minus) / (2 * h_fd)\n    adj_deriv = np.dot(grad_J, ds)\n    \n    rel_error1 = np.abs(adj_deriv - fd_deriv) / np.max([1.0, np.abs(adj_deriv), np.abs(fd_deriv)])\n    results.append(rel_error1)\n    \n    # Inversion\n    sigma_k = np.copy(s0)\n    c_armijo = 1e-4\n    beta_armijo = 0.5\n    sigma_min = 0.2\n    \n    for k in range(10):\n        J_k = model1.compute_objective(sigma_k)\n        grad_J_k = model1.compute_gradient(sigma_k)\n        pk = -grad_J_k\n        \n        tk = 1e-1\n        while model1.compute_objective(sigma_k + tk * pk) > J_k + c_armijo * tk * np.dot(grad_J_k, pk):\n            tk *= beta_armijo\n        \n        sigma_k += tk * pk\n        sigma_k = np.maximum(sigma_k, sigma_min)\n    \n    final_sigma1 = sigma_k.reshape((32, 32))\n    \n    # Edge sharpness\n    Dx_s = np.zeros_like(final_sigma1)\n    Dy_s = np.zeros_like(final_sigma1)\n    Dx_s[:, :-1] = final_sigma1[:, 1:] - final_sigma1[:, :-1]\n    Dy_s[:-1, :] = final_sigma1[1:, :] - final_sigma1[:-1, :]\n    grad_mag = np.sqrt(Dx_s**2 + Dy_s**2)\n    \n    band_radius = np.sqrt((model1.xx - 0.5)**2 + (model1.yy - 0.5)**2)\n    band_mask = np.abs(band_radius - 0.25) = (2 * model1.h)\n    \n    sharpness1 = np.mean(grad_mag[band_mask])\n    \n    # Cases 2 and 4: epsilon = 1e-3\n    epsilon2 = 1e-3\n    model2 = InverseProblem(epsilon=epsilon2)\n\n    # Grad check\n    grad_J = model2.compute_gradient(s0)\n    J_plus = model2.compute_objective(s0 + h_fd * ds)\n    J_minus = model2.compute_objective(s0 - h_fd * ds)\n    \n    fd_deriv = (J_plus - J_minus) / (2 * h_fd)\n    adj_deriv = np.dot(grad_J, ds)\n\n    # Insert grad check error for eps2\n    rel_error2 = np.abs(adj_deriv - fd_deriv) / np.max([1.0, np.abs(adj_deriv), np.abs(fd_deriv)])\n    \n    # Inversion\n    sigma_k = np.copy(s0)\n    for k in range(10):\n        J_k = model2.compute_objective(sigma_k)\n        grad_J_k = model2.compute_gradient(sigma_k)\n        pk = -grad_J_k\n        \n        tk = 1e-1\n        while model2.compute_objective(sigma_k + tk * pk) > J_k + c_armijo * tk * np.dot(grad_J_k, pk):\n            tk *= beta_armijo\n        \n        sigma_k += tk * pk\n        sigma_k = np.maximum(sigma_k, sigma_min)\n\n    final_sigma2 = sigma_k.reshape((32, 32))\n\n    # Edge sharpness\n    Dx_s = np.zeros_like(final_sigma2)\n    Dy_s = np.zeros_like(final_sigma2)\n    Dx_s[:, :-1] = final_sigma2[:, 1:] - final_sigma2[:, :-1]\n    Dy_s[:-1, :] = final_sigma2[1:, :] - final_sigma2[:-1, :]\n    grad_mag = np.sqrt(Dx_s**2 + Dy_s**2)\n    \n    sharpness2 = np.mean(grad_mag[band_mask])\n    \n    results.insert(1, rel_error2)\n    results.append(sharpness1)\n    results.append(sharpness2)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3364106"}]}