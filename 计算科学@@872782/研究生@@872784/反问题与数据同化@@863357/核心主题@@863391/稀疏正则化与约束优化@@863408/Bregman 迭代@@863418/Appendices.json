{"hands_on_practices": [{"introduction": "Bregman迭代的核心是Bregman距离的概念。为了将这一抽象概念具体化，我们的第一个实践是亲手计算它。在这个练习中[@problem_id:3369778]，我们将为一维信号计算关于各向异性总变差（TV）泛函的Bregman距离。通过分解这个计算，你将清晰地理解Bregman距离的各个组成部分——凸泛函$J(u)$、其在某一点的次梯度$p$，以及它们如何结合起来衡量两点之间的“距离”。", "problem": "考虑长度为 $n=5$ 的离散一维信号，其中 $u,v \\in \\mathbb{R}^{5}$ 由下式给出\n$$\nu=\\begin{pmatrix}2\\\\0\\\\4\\\\2\\\\1\\end{pmatrix}, \\qquad v=\\begin{pmatrix}0\\\\2\\\\5\\\\1\\\\3\\end{pmatrix}.\n$$\n将离散信号 $w \\in \\mathbb{R}^{5}$ 的各向异性全变分 (TV) 定义为凸泛函\n$$\n\\mathrm{TV}(w)=\\sum_{i=1}^{4} |w_{i+1}-w_{i}|.\n$$\n令 $D:\\mathbb{R}^{5}\\to\\mathbb{R}^{4}$ 为前向有限差分算子，定义为 $(Dw)_{i}=w_{i+1}-w_{i}$，其中 $i=1,2,3,4$。对于一个凸泛函 $J$，关于次梯度 $p \\in \\partial J(v)$ 的布雷格曼距离 (Bregman distance) 定义为\n$$\nD_{J}^{p}(u,v)=J(u)-J(v)-\\langle p, u-v\\rangle,\n$$\n其中 $\\langle \\cdot,\\cdot\\rangle$ 表示标准的欧几里得内积。使用次梯度的链式法则来刻画 $\\mathrm{TV}$ 的次微分：存在 $s\\in\\mathbb{R}^{4}$，其中 $s_{i}\\in \\operatorname{sign}\\big((Dv)_{i}\\big)$，使得 $p=D^{\\top}s$，这里 $D^{\\top}$ 是 $D$ 在欧几里得内积下的伴随算子。此处，如果 $t0$，则 $\\operatorname{sign}(t)=1$；如果 $t0$，则 $\\operatorname{sign}(t)=-1$；并且 $\\operatorname{sign}(0)=[-1,1]$。\n\n使用 $s_{i}=\\operatorname{sign}\\big((Dv)_{i}\\big)$（其中 $i=1,2,3,4$）和 $p=D^{\\top}s$ 的选择，计算布雷格曼距离 $D_{\\mathrm{TV}}^{p}(u,v)$。您的最终答案必须是一个实数。无需四舍五入。", "solution": "问题要求计算给定离散信号 $u,v \\in \\mathbb{R}^{5}$ 的布雷格曼距离 $D_{\\mathrm{TV}}^{p}(u,v)$。关于凸泛函 $J$ 和次梯度 $p \\in \\partial J(v)$ 的布雷格曼距离公式由下式给出：\n$$\nD_{J}^{p}(u,v) = J(u) - J(v) - \\langle p, u-v \\rangle\n$$\n在这个问题中，泛函 $J$ 是各向异性全变分，$J=\\mathrm{TV}$。因此，我们需要计算：\n$$\nD_{\\mathrm{TV}}^{p}(u,v) = \\mathrm{TV}(u) - \\mathrm{TV}(v) - \\langle p, u-v \\rangle\n$$\n我们将分别计算每一项。给定的向量为 $u=\\begin{pmatrix}2\\\\0\\\\4\\\\2\\\\1\\end{pmatrix}$ 和 $v=\\begin{pmatrix}0\\\\2\\\\5\\\\1\\\\3\\end{pmatrix}$。\n\n首先，我们计算 $u$ 的全变分。其定义为 $\\mathrm{TV}(w) = \\sum_{i=1}^{4} |w_{i+1}-w_{i}|$。\n对于 $u$，差值为：\n$u_2 - u_1 = 0-2 = -2$\n$u_3 - u_2 = 4-0 = 4$\n$u_4 - u_3 = 2-4 = -2$\n$u_5 - u_4 = 1-2 = -1$\n$u$ 的全变分是这些差值的绝对值之和：\n$$\n\\mathrm{TV}(u) = |-2| + |4| + |-2| + |-1| = 2 + 4 + 2 + 1 = 9\n$$\n\n其次，我们计算 $v$ 的全变分。对于 $v$，差值为：\n$v_2 - v_1 = 2-0 = 2$\n$v_3 - v_2 = 5-2 = 3$\n$v_4 - v_3 = 1-5 = -4$\n$v_5 - v_4 = 3-1 = 2$\n$v$ 的全变分为：\n$$\n\\mathrm{TV}(v) = |2| + |3| + |-4| + |2| = 2 + 3 + 4 + 2 = 11\n$$\n\n第三，我们计算次梯度 $p \\in \\partial \\mathrm{TV}(v)$。问题指出 $p = D^{\\top}s$，其中 $s \\in \\mathbb{R}^4$ 由特定选择 $s_{i}=\\operatorname{sign}\\big((Dv)_{i}\\big)$ 决定。算子 $D:\\mathbb{R}^{5}\\to\\mathbb{R}^{4}$ 是前向有限差分算子，$(Dw)_i = w_{i+1}-w_i$。\n向量 $Dv$ 包含我们为计算 $\\mathrm{TV}(v)$ 而得出的差值：\n$$\nDv = \\begin{pmatrix} v_2 - v_1 \\\\ v_3 - v_2 \\\\ v_4 - v_3 \\\\ v_5 - v_4 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ 3 \\\\ -4 \\\\ 2 \\end{pmatrix}\n$$\n现在，我们通过取 $Dv$ 各分量的符号来找到向量 $s$。符号函数的定义为：当 $t0$ 时 $\\operatorname{sign}(t)=1$，当 $t0$ 时 $\\operatorname{sign}(t)=-1$。由于 $Dv$ 的所有分量都不为零，我们得到唯一的 $s$：\n$$\ns = \\begin{pmatrix} \\operatorname{sign}(2) \\\\ \\operatorname{sign}(3) \\\\ \\operatorname{sign}(-4) \\\\ \\operatorname{sign}(2) \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 1 \\\\ -1 \\\\ 1 \\end{pmatrix}\n$$\n接下来，我们确定伴随算子 $D^{\\top}:\\mathbb{R}^4 \\to \\mathbb{R}^5$ 的作用。伴随算子的定义性质是，对于所有 $w \\in \\mathbb{R}^5, x \\in \\mathbb{R}^4$，都有 $\\langle Dw, x \\rangle = \\langle w, D^{\\top}x \\rangle$。\n$$\n\\langle Dw, x \\rangle = \\sum_{i=1}^{4} (w_{i+1}-w_i)x_i = \\sum_{i=1}^{4} w_{i+1}x_i - \\sum_{i=1}^{4} w_i x_i\n$$\n通过重新索引并按 $w_i$ 对各项进行分组，我们得到：\n$$\n\\langle Dw, x \\rangle = -w_1 x_1 + w_2(x_1-x_2) + w_3(x_2-x_3) + w_4(x_3-x_4) + w_5 x_4\n$$\n由此，我们可以确定 $D^{\\top}x$ 的分量：\n$(D^{\\top}x)_1 = -x_1$\n$(D^{\\top}x)_2 = x_1 - x_2$\n$(D^{\\top}x)_3 = x_2 - x_3$\n$(D^{\\top}x)_4 = x_3 - x_4$\n$(D^{\\top}x)_5 = x_4$\n将此应用于我们的向量 $s = (1, 1, -1, 1)^{\\top}$，我们找到次梯度 $p=D^{\\top}s$：\n$p_1 = -s_1 = -1$\n$p_2 = s_1 - s_2 = 1 - 1 = 0$\n$p_3 = s_2 - s_3 = 1 - (-1) = 2$\n$p_4 = s_3 - s_4 = -1 - 1 = -2$\n$p_5 = s_4 = 1$\n所以，次梯度为 $p = \\begin{pmatrix} -1 \\\\ 0 \\\\ 2 \\\\ -2 \\\\ 1 \\end{pmatrix}$。\n\n第四，我们计算内积 $\\langle p, u-v \\rangle$。我们首先求向量差 $u-v$：\n$$\nu-v = \\begin{pmatrix} 2-0 \\\\ 0-2 \\\\ 4-5 \\\\ 2-1 \\\\ 1-3 \\end{pmatrix} = \\begin{pmatrix} 2 \\\\ -2 \\\\ -1 \\\\ 1 \\\\ -2 \\end{pmatrix}\n$$\n现在我们计算内积：\n$$\n\\langle p, u-v \\rangle = p_1(u_1-v_1) + p_2(u_2-v_2) + p_3(u_3-v_3) + p_4(u_4-v_4) + p_5(u_5-v_5)\n$$\n$$\n\\langle p, u-v \\rangle = (-1)(2) + (0)(-2) + (2)(-1) + (-2)(1) + (1)(-2) = -2 + 0 - 2 - 2 - 2 = -8\n$$\n\n最后，我们将所有计算出的值代回布雷格曼距离公式：\n$$\nD_{\\mathrm{TV}}^{p}(u,v) = \\mathrm{TV}(u) - \\mathrm{TV}(v) - \\langle p, u-v \\rangle = 9 - 11 - (-8)\n$$\n$$\nD_{\\mathrm{TV}}^{p}(u,v) = -2 - (-8) = -2 + 8 = 6\n$$\n所得的布雷格曼距离是一个非负值，这与它作为凸泛函的定义相符。", "answer": "$$\n\\boxed{6}\n$$", "id": "3369778"}, {"introduction": "理解了Bregman距离的静态定义后，让我们在一个最简单的场景中观察迭代过程的动态行为。这个练习[@problem_id:3369784]构建了一个标量数据同化问题，以展示Bregman迭代如何逐步强制执行数据约束，同时尊重先验信息。通过追踪几次迭代后解的演变，我们可以直观地观察到拟合数据和忠于先验之间的权衡，这是反问题中一个永恒的核心主题。", "problem": "考虑一个一维静态数据同化问题。未知状态是一个标量 $x \\in \\mathbb{R}$。观测算子是一个标量 $H \\in \\mathbb{R}$，观测值是一个标量 $y \\in \\mathbb{R}$。状态的先验信息由一个凸二次泛函 $\\phi(x) = \\tfrac{\\alpha}{2}(x - x_b)^2$ 编码，其中 $\\alpha \\in \\mathbb{R}_{0}$ 是先验权重，$x_b \\in \\mathbb{R}$ 是先验均值。该同化问题被构建为在等式约束 $H x = y$ 下最小化 $\\phi(x)$ 的凸优化问题。\n\n从凸分析和等式约束优化的第一性原理出发，推导两步 Bregman 迭代格式，该格式在满足先验 $\\phi(x)$ 的同时强制执行约束 $H x = y$。从最小化受线性等式约束的凸泛函 $\\phi(x)$ 的 Bregman 迭代的基本定义开始，并使用适用于二次可微凸函数的微分法则，来获得 $x$ 的标量更新式以及对偶变量的相应更新式。除了这些基础知识外，您不得使用或假设任何专门的快捷公式。将 $x^{(0)}$ 定义为 $\\phi(x)$ 的最小化子，并根据 $x^{(0)}$ 处的次梯度来一致地初始化对偶变量。\n\n对于每个测试用例，从 $x^{(0)}$ 和初始对偶变量开始，精确地数值实现两次 Bregman 迭代。对于每个测试用例，报告第二次迭代后的两个量：\n- 绝对约束残差 $|H x^{(2)} - y|$，\n- 绝对先验偏差 $|x^{(2)} - x_b|$。\n\n这两个量共同说明了两次迭代后在约束满足和先验遵守之间的权衡。\n\n不涉及物理单位。报告无角度的标量值。最终的数值输出必须表示为十进制数。\n\n您的程序必须生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。外层列表的每个元素对应一个测试用例，并且本身必须是按上述顺序排列的双元素列表。例如，输出格式必须为 $[[r_1,d_1],[r_2,d_2],\\dots]$ 的形式，其中每个 $r_i$ 和 $d_i$ 都是十进制数。将每个十进制数四舍五入到小数点后六位。\n\n使用以下涵盖不同场景的测试套件：\n- 测试用例 1 (基准): $H = 1.0$, $y = 3.0$, $x_b = 0.0$, $\\alpha = 1.0$, $\\lambda = 1.0$。\n- 测试用例 2 (强先验): $H = 1.0$, $y = 3.0$, $x_b = 0.0$, $\\alpha = 100.0$, $\\lambda = 1.0$。\n- 测试用例 3 (强约束惩罚): $H = 1.0$, $y = 3.0$, $x_b = 0.0$, $\\alpha = 1.0$, $\\lambda = 100.0$。\n- 测试用例 4 (弱敏感度): $H = 0.1$, $y = 3.0$, $x_b = 0.0$, $\\alpha = 1.0$, $\\lambda = 1.0$。\n- 测试用例 5 (先验等于观测): $H = 1.0$, $y = 2.0$, $x_b = 2.0$, $\\alpha = 1.0$, $\\lambda = 1.0$。\n\n在所有情况下，$\\lambda \\in \\mathbb{R}_{0}$ 是 Bregman 迭代中使用的惩罚参数。您的实现必须是确定性的和自包含的；它不能读取任何输入。单行输出必须是指定格式的精确数值列表，每个数字保留六位小数。", "solution": "我们从最小化受线性等式约束的凸泛函 $\\phi(x)$ 的凸优化问题开始。基本设置为\n$$\n\\min_{x \\in \\mathbb{R}} \\; \\phi(x) \\quad \\text{约束条件} \\quad H x = y,\n$$\n其中 $\\phi(x) = \\tfrac{\\alpha}{2} (x - x_b)^2$，$\\alpha \\in \\mathbb{R}_{0}$ 和 $x_b \\in \\mathbb{R}$ 是给定的。观测算子 $H \\in \\mathbb{R}$ 和观测值 $y \\in \\mathbb{R}$ 定义了约束。函数 $\\phi$ 是严格凸且二次连续可微的，因此其梯度对所有 $x$ 都有明确定义。\n\n用于最小化受线性等式约束的凸泛函的 Bregman 迭代，其原理是反复最小化由当前次梯度线性化的原始凸泛函，并结合一个强制执行约束的二次惩罚项，同时用残差更新一个类对偶变量。基本基础包括：\n- 凸函数及其梯度的性质：对于二次可微的 $\\phi$，$\\nabla \\phi(x)$ 存在且唯一。\n- 可微函数无约束最小化的一阶最优性条件：最小化子通过梯度等于零来表征。\n- 与对偶变量中的梯度下降步骤一致的线性约束残差更新。\n\n令 $p^{(k)}$ 表示与 Bregman 迭代相关的类对偶变量，从初始状态的次梯度初始化。对于二次可微的 $\\phi$，在 $x$ 处的次梯度就是梯度 $\\nabla \\phi(x)$。将 $x^{(0)}$ 定义为 $\\phi(x)$ 的最小化子，通过求解 $\\nabla \\phi(x) = 0$ 获得。由于\n$$\n\\nabla \\phi(x) = \\alpha (x - x_b),\n$$\n唯一的最小化子满足 $\\alpha (x^{(0)} - x_b) = 0$，因此 $x^{(0)} = x_b$。初始对偶变量选择为 $p^{(0)} \\in \\partial \\phi(x^{(0)}) = \\{\\nabla \\phi(x^{(0)})\\}$，得到 $p^{(0)} = \\alpha (x^{(0)} - x_b) = 0$。\n\n在第 $k$ 次迭代中，Bregman 最小化步骤考虑以下惩罚泛函：\n$$\nJ_k(x) = \\phi(x) - \\langle p^{(k)}, x \\rangle + \\frac{\\lambda}{2} \\|H x - y\\|^2,\n$$\n其中 $\\lambda \\in \\mathbb{R}_{0}$ 是一个惩罚参数。在一维情况下，内积简化为乘法。通过将 $J_k$ 对 $x$ 的导数设为零，可以得到最小化子 $x^{(k+1)}$。使用链式法则和线性性质，\n$$\n\\frac{d}{dx} J_k(x) = \\nabla \\phi(x) - p^{(k)} + \\lambda H \\cdot (H x - y).\n$$\n具体来说，我们有 $\\nabla \\phi(x) = \\alpha (x - x_b)$，且 $\\tfrac{\\lambda}{2} (H x - y)^2$ 对 $x$ 的导数是 $\\lambda H (H x - y)$，因为 $\\frac{d}{dx}(H x - y)^2 = 2 (H x - y) H$ 且因子 $\\tfrac{1}{2}$ 与 $2$ 相消。将导数设为零，得到一阶最优性条件：\n$$\n\\alpha (x^{(k+1)} - x_b) - p^{(k)} + \\lambda H (H x^{(k+1)} - y) = 0.\n$$\n重新整理各项以求解 $x^{(k+1)}$ 得到\n$$\n\\alpha x^{(k+1)} - \\alpha x_b - p^{(k)} + \\lambda H^2 x^{(k+1)} - \\lambda H y = 0,\n$$\n合并为\n$$\n(\\alpha + \\lambda H^2) x^{(k+1)} = \\alpha x_b + p^{(k)} + \\lambda H y,\n$$\n因此得到显式标量更新式\n$$\nx^{(k+1)} = \\frac{\\alpha x_b + p^{(k)} + \\lambda H y}{\\alpha + \\lambda H^2}.\n$$\n\n类对偶变量的更新由约束的残差驱动，这与对偶变量的梯度下降一致：\n$$\np^{(k+1)} = p^{(k)} - \\lambda H \\left(H x^{(k+1)} - y\\right).\n$$\n这直接源于 Bregman 方法中的基本迭代，该迭代累积了由惩罚和敏感度缩放的约束残差。\n\n因此，针对一维情况和二次先验的算法如下：\n- 初始化：$x^{(0)} = x_b$, $p^{(0)} = 0$。\n- 对于 $k = 0, 1, \\dots$ 的迭代更新：\n  $$\n  x^{(k+1)} = \\frac{\\alpha x_b + p^{(k)} + \\lambda H y}{\\alpha + \\lambda H^2}, \\quad r^{(k+1)} = H x^{(k+1)} - y, \\quad p^{(k+1)} = p^{(k)} - \\lambda H r^{(k+1)}.\n  $$\n\n我们精确地执行两次迭代，得到 $x^{(1)}$ 和 $x^{(2)}$。在第二次迭代后，我们计算：\n- 绝对约束残差 $|H x^{(2)} - y|$，\n- 绝对先验偏差 $|x^{(2)} - x_b|$。\n\n这两个标量量化了权衡关系：当 $\\lambda$ 或 $H$ 较大时，残差 $|H x^{(2)} - y|$ 迅速减小，表明约束满足得更强；当 $\\alpha$ 较大时，偏差 $|x^{(2)} - x_b|$ 减小，表明对先验的遵守更强。相比之下，较小的 $H$ 会降低敏感度并减慢约束的执行，使得在相同迭代次数内状态更接近先验。\n\n将算法应用于测试套件：\n- 测试用例 1: $H = 1.0$, $y = 3.0$, $x_b = 0.0$, $\\alpha = 1.0$, $\\lambda = 1.0$。\n  初始化：$x^{(0)} = 0$, $p^{(0)} = 0$。\n  第一次更新：$x^{(1)} = \\frac{1 \\cdot 0 + 0 + 1 \\cdot 1 \\cdot 3}{1 + 1 \\cdot 1^2} = \\frac{3}{2} = 1.5$, $r^{(1)} = 1 \\cdot 1.5 - 3 = -1.5$, $p^{(1)} = 0 - 1 \\cdot 1 \\cdot (-1.5) = 1.5$。\n  第二次更新：$x^{(2)} = \\frac{1 \\cdot 0 + 1.5 + 1 \\cdot 1 \\cdot 3}{1 + 1 \\cdot 1^2} = \\frac{4.5}{2} = 2.25$, $r^{(2)} = 2.25 - 3 = -0.75$。\n  度量指标：$|H x^{(2)} - y| = 0.75$, $|x^{(2)} - x_b| = 2.25$。\n- 测试用例 2: $H = 1.0$, $y = 3.0$, $x_b = 0.0$, $\\alpha = 100.0$, $\\lambda = 1.0$。\n  初始化：$x^{(0)} = 0$, $p^{(0)} = 0$。\n  第一次更新：$x^{(1)} = \\frac{100 \\cdot 0 + 0 + 1 \\cdot 1 \\cdot 3}{100 + 1 \\cdot 1^2} = \\frac{3}{101} \\approx 0.029703$, $r^{(1)} \\approx -2.970297$, $p^{(1)} \\approx 2.970297$。\n  第二次更新：$x^{(2)} = \\frac{100 \\cdot 0 + 2.970297 + 3}{101} \\approx 0.059104$, $r^{(2)} \\approx -2.940896$。\n  度量指标：$|H x^{(2)} - y| \\approx 2.940896$, $|x^{(2)} - x_b| \\approx 0.059104$。\n- 测试用例 3: $H = 1.0$, $y = 3.0$, $x_b = 0.0$, $\\alpha = 1.0$, $\\lambda = 100.0$。\n  初始化：$x^{(0)} = 0$, $p^{(0)} = 0$。\n  第一次更新：$x^{(1)} = \\frac{1 \\cdot 0 + 0 + 100 \\cdot 1 \\cdot 3}{1 + 100 \\cdot 1^2} = \\frac{300}{101} \\approx 2.970297$, $r^{(1)} \\approx -0.029703$, $p^{(1)} = 0 - 100 \\cdot 1 \\cdot (-0.029703) \\approx 2.970297$。\n  第二次更新：$x^{(2)} = \\frac{0 + 2.970297 + 300}{101} \\approx 3.000695$, $r^{(2)} \\approx 0.000695$。\n  度量指标：$|H x^{(2)} - y| \\approx 0.000695$, $|x^{(2)} - x_b| \\approx 3.000695$。\n- 测试用例 4: $H = 0.1$, $y = 3.0$, $x_b = 0.0$, $\\alpha = 1.0$, $\\lambda = 1.0$。\n  初始化：$x^{(0)} = 0$, $p^{(0)} = 0$。\n  第一次更新：$x^{(1)} = \\frac{0 + 0 + 1 \\cdot 0.1 \\cdot 3}{1 + 1 \\cdot 0.1^2} = \\frac{0.3}{1.01} \\approx 0.297030$, $r^{(1)} \\approx -2.970297$, $p^{(1)} \\approx 0.297030$。\n  第二次更新：$x^{(2)} = \\frac{0 + 0.297030 + 0.3}{1.01} \\approx 0.591089$, $r^{(2)} \\approx -2.940891$。\n  度量指标：$|H x^{(2)} - y| \\approx 2.940891$, $|x^{(2)} - x_b| \\approx 0.591089$。\n- 测试用例 5: $H = 1.0$, $y = 2.0$, $x_b = 2.0$, $\\alpha = 1.0$, $\\lambda = 1.0$。\n  初始化：$x^{(0)} = 2$, $p^{(0)} = 0$。\n  第一次更新：$x^{(1)} = \\frac{2 + 2}{2} = 2$, $r^{(1)} = 0$, $p^{(1)} = 0$。\n  第二次更新：$x^{(2)} = 2$, $r^{(2)} = 0$。\n  度量指标：$|H x^{(2)} - y| = 0$, $|x^{(2)} - x_b| = 0$。\n\n这些结果证实了定性的权衡关系：更强的约束惩罚（$\\lambda$ 大）或更高的敏感度（$H$ 大）会迅速减小约束残差，但这可能以仅两步后与先验的较大偏差为代价；而强先验（$\\alpha$ 大）则限制了与 $x_b$ 的偏差，但在相同的迭代预算内使得约束满足变慢。当先验和观测一致时，两个度量指标均为零，迭代保持在先验均值处。\n\n该实现完全遵循推导出的标量更新式，并以指定的输出格式返回四舍五入到六位小数的度量指标。", "answer": "[[0.75,2.25],[2.940896,0.059104],[0.000695,3.000695],[2.940891,0.591089],[0.0,0.0]]", "id": "3369784"}, {"introduction": "当我们对基本概念和迭代动力学有了扎实的把握后，就可以着手解决一个更接近实际应用的算法了。这个实践[@problem_id:3369799]要求你为一维总变差（TV）降噪问题实现一次完整的分裂Bregman迭代。这个练习将向你展示如何将一个复杂的非光滑优化问题分解为两个可解的子问题——一个线性系统和一个简单的收缩操作，并让你体验到利用快速傅里叶变换（FFT）求解循环矩阵等实用技巧。", "problem": "在逆问题和数据同化框架内，考虑一个针对单位正向算子的一维全变分 (TV) 降噪问题。令 $A$ 表示正向算子，并假设 $A = I$ (单位算子)。给定一个数据向量 $g \\in \\mathbb{R}^n$，我们将 Rudin–Osher–Fatemi TV 降噪目标设定为最小化一个数据保真项和一个 TV 正则化项之和，即一个泛函，其在候选信号 $u \\in \\mathbb{R}^n$ 处的值为平方数据失配项与由正则化参数缩放的 $u$ 的离散梯度的 $\\ell_1$ 范数之和。离散梯度是使用周期性边界条件下的有限差分来定义的。\n\n定义有限差分算子 $D : \\mathbb{R}^n \\to \\mathbb{R}^n$ 的分量法则如下\n$$(D u)_i = u_{(i+1) \\bmod n} - u_i \\quad \\text{for } i \\in \\{0,1,\\dots,n-1\\}.$$\n假设使用 Split Bregman 方法来解决该降噪问题。在 Split Bregman 算法中，迭代状态包括主变量 $u \\in \\mathbb{R}^n$、强制 $d \\approx D u$ 的分裂变量 $d \\in \\mathbb{R}^n$ 以及 Bregman 变量 $b \\in \\mathbb{R}^n$。迭代过程使用一个罚参数 $\\lambda  0$ 和一个 TV 正则化参数 $\\mu  0$。\n\n从初始状态 $u^{0} = 0$、$d^{0} = 0$ 和 $b^{0} = 0$（$\\mathbb{R}^n$ 中的零向量）开始，实现一次完整的 Split Bregman 迭代。使用基于增广拉格朗日视角的原理推导来计算第一次迭代中 $u$ 和 $d$ 的更新。离散算子必须严格按照规定实现，并且所有计算都必须使用双精度浮点算术进行。\n\n你的程序必须为每个指定的测试用例生成一次 Split Bregman 迭代所产生的向量 $u^{1}$ 和 $d^{1}$。在程序输出中，将向量表示为浮点数列表。\n\n使用以下测试套件，它涵盖了典型行为、近似恒定的数据、小问题规模和更高惩罚机制的情况：\n\n- 测试用例 1：$n = 6$, $g = [\\,1.0,\\,1.2,\\,0.9,\\,-0.5,\\,-0.4,\\,0.0\\,]$, $\\mu = 0.6$, $\\lambda = 2.0$。\n- 测试用例 2：$n = 6$, $g = [\\,2.0,\\,2.0,\\,2.0,\\,2.0,\\,2.0,\\,2.0\\,]$, $\\mu = 1.5$, $\\lambda = 1.0$。\n- 测试用例 3：$n = 3$, $g = [\\,0.0,\\,10.0,\\,-10.0\\,]$, $\\mu = 0.4$, $\\lambda = 0.5$。\n- 测试用例 4：$n = 8$, $g = [\\,0.0,\\,0.5,\\,1.0,\\,1.5,\\,1.25,\\,0.8,\\,0.3,\\,-0.2\\,]$, $\\mu = 2.0$, $\\lambda = 3.0$。\n\n对于每个测试用例，使用上面定义的、带有周期性边界条件的有限差分算子 $D$ 进行一次完整的 Split Bregman 迭代，以计算 $u^{1}$ 和 $d^{1}$。\n\n你的程序应生成单行输出，其中包含用方括号括起来的、以逗号分隔的结果列表。该列表的第 $i$ 个元素本身必须是一个包含两个列表的列表，其中第一个内部列表是第 $i$ 个测试用例的 $u^{1}$，第二个内部列表是第 $i$ 个测试用例的 $d^{1}$。例如，输出格式应为\n$$[\\, [\\,[u^{1}_{(1)}],\\,[d^{1}_{(1)}]\\,],\\,[\\,[u^{1}_{(2)}],\\,[d^{1}_{(2)}]\\,],\\,\\dots\\, ]$$\n打印输出中不含空格。", "solution": "该问题是有效且适定的。它描述了 Split Bregman 算法在全变分 (TV) 降噪问题中的一个标准应用，并提供了所有必要的定义、参数和初始条件。\n\n对于给定的噪声信号 $g \\in \\mathbb{R}^n$，一维 Rudin–Osher–Fatemi (ROF) TV 降噪问题旨在寻找一个信号 $u \\in \\mathbb{R}^n$，以最小化以下目标泛函：\n$$ E(u) = \\frac{1}{2} \\|u-g\\|_2^2 + \\mu \\|Du\\|_1 $$\n此处，$\\mu  0$ 是控制降噪强度的正则化参数。算子 $D: \\mathbb{R}^n \\to \\mathbb{R}^n$ 是离散梯度，在周期性边界条件下定义为 $(Du)_i = u_{(i+1) \\bmod n} - u_i$。\n\n$\\ell_1$ 范数项 $\\|Du\\|_1$ 是不可微的，这使得直接最小化变得困难。Split Bregman 方法通过引入一个分裂变量 $d \\in \\mathbb{R}^n$ 并将问题转化为一个约束优化问题来解决此问题：\n$$ \\min_{u,d} \\frac{1}{2} \\|u-g\\|_2^2 + \\mu \\|d\\|_1 \\quad \\text{subject to} \\quad d = Du $$\n\n这个约束问题通过最小化一个相关的增广拉格朗日量来求解，从而得到一个迭代格式。Split Bregman 迭代以交替方式更新主变量 $u$、分裂变量 $d$ 和 Bregman (对偶) 变量 $b \\in \\mathbb{R}^n$。对于第 $k+1$ 次迭代，其迭代格式如下：\n1.  更新 $u$：\n    $$ u^{k+1} = \\arg\\min_u \\left\\{ \\frac{1}{2} \\|u-g\\|_2^2 + \\frac{\\lambda}{2} \\|Du - d^k + b^k\\|_2^2 \\right\\} $$\n2.  更新 $d$：\n    $$ d^{k+1} = \\arg\\min_d \\left\\{ \\mu \\|d\\|_1 + \\frac{\\lambda}{2} \\|Du^{k+1} - d + b^k\\|_2^2 \\right\\} $$\n3.  更新 $b$：\n    $$ b^{k+1} = b^k + (Du^{k+1} - d^{k+1}) $$\n参数 $\\lambda  0$ 是对约束 $d=Du$ 的一个罚参数。\n\n我们的任务是从初始状态 $u^0 = 0$、$d^0 = 0$ 和 $b^0 = 0$ 开始，计算一次完整的迭代，得到 $u^1$ 和 $d^1$。\n\n**步骤 1：针对 $u^1$ 的 $u$-子问题**\n\n我们将 $k=0$ 以及初始条件 $d^0=0$ 和 $b^0=0$ 代入 $u$ 的更新规则中：\n$$ u^1 = \\arg\\min_u \\left\\{ \\frac{1}{2} \\|u-g\\|_2^2 + \\frac{\\lambda}{2} \\|Du - 0 + 0\\|_2^2 \\right\\} = \\arg\\min_u \\left\\{ \\frac{1}{2} \\|u-g\\|_2^2 + \\frac{\\lambda}{2} \\|Du\\|_2^2 \\right\\} $$\n这是一个二次最小化问题，可以通过将目标函数关于 $u$ 的梯度设为零来求解。$\\frac{1}{2}\\|u-g\\|_2^2$ 的梯度是 $u-g$。$\\frac{\\lambda}{2}\\|Du\\|_2^2 = \\frac{\\lambda}{2} u^T D^T D u$ 的梯度是 $\\lambda D^T D u$。将梯度之和设为零，得到正规方程：\n$$ (u^1 - g) + \\lambda D^T D u^1 = 0 $$\n$$ (I + \\lambda D^T D) u^1 = g $$\n其中 $I$ 是 $n \\times n$ 单位矩阵，$D^T$ 是 $D$ 的转置。矩阵 $C = I + \\lambda D^T D$ 是一个循环矩阵，因为 $D$（带周期性边界的前向差分）是一个循环矩阵。循环线性系统可以在傅里叶域中高效求解。令 $\\mathcal{F}$ 表示离散傅里叶变换 (DFT)。对该系统应用 DFT 可得：\n$$ \\mathcal{F}((I + \\lambda D^T D) u^1) = \\mathcal{F}(g) $$\n$$ \\mathcal{F}(I + \\lambda D^T D) \\mathcal{F}(u^1) = \\mathcal{F}(g) $$\n项 $\\mathcal{F}(I + \\lambda D^T D)$ 表示循环矩阵 $C$ 的特征值。这些特征值可以通过对 $C$ 的第一行进行 DFT 来找到。算子 $D^T D$ 是带周期性边界的一维离散拉普拉斯算子的负数，即 $(D^T D u)_i = -u_{(i+1) \\bmod n} + 2u_i - u_{(i-1) \\bmod n}$。因此，$C$ 的第一行是 $c = [1+2\\lambda, -\\lambda, 0, \\dots, 0, -\\lambda]$。\n那么 $u^1$ 的 DFT 是：\n$$ \\mathcal{F}(u^1)_k = \\frac{\\mathcal{F}(g)_k}{ \\mathcal{F}(c)_k } $$\n最后，我们通过应用逆 DFT 得到 $u^1$：\n$$ u^1 = \\mathcal{F}^{-1}\\left( \\frac{\\mathcal{F}(g)}{\\mathcal{F}(c)} \\right) $$\n\n**步骤 2：针对 $d^1$ 的 $d$-子问题**\n\n接下来，我们使用新计算出的 $u^1$ 和之前的 $b^0=0$ 来计算 $d^1$：\n$$ d^1 = \\arg\\min_d \\left\\{ \\mu \\|d\\|_1 + \\frac{\\lambda}{2} \\|Du^1 - d + 0\\|_2^2 \\right\\} = \\arg\\min_d \\left\\{ \\mu \\|d\\|_1 + \\frac{\\lambda}{2} \\|d - Du^1\\|_2^2 \\right\\} $$\n这个问题是可分离的，意味着我们可以独立求解每个分量 $d_i$：\n$$ d^1_i = \\arg\\min_{d_i} \\left\\{ \\mu |d_i| + \\frac{\\lambda}{2} (d_i - (Du^1)_i)^2 \\right\\} $$\n这是凸优化中的一个标准问题，其解由软阈值算子给出。令 $v_i = (Du^1)_i$，阈值为 $T = \\mu/\\lambda$。解为：\n$$ d^1_i = \\text{shrink}(v_i, T) = \\text{sign}(v_i) \\max(|v_i| - T, 0) $$\n对所有分量 $i=0, \\dots, n-1$ 进行此计算，即可获得向量 $d^1$。\n\n**单次迭代算法摘要**\n给定 $n$、$g$、$\\mu$ 和 $\\lambda$：\n1.  构造循环矩阵 $C = I + \\lambda D^T D$ 的第一行：$c = [1+2\\lambda, -\\lambda, 0, \\dots, 0, -\\lambda]$。\n2.  计算 $c$ 的 DFT 以获得 $C$ 的特征值，令其为 $\\hat{c} = \\mathcal{F}(c)$。\n3.  计算数据向量 $g$ 的 DFT，令其为 $\\hat{g} = \\mathcal{F}(g)$。\n4.  通过逐元素除法计算解 $u^1$ 的 DFT：$\\hat{u}^1_k = \\hat{g}_k / \\hat{c}_k$。\n5.  通过对 $\\hat{u}^1$ 进行逆 DFT 计算 $u^1$：$u^1 = \\mathcal{F}^{-1}(\\hat{u}^1)$。\n6.  计算 $u^1$ 的离散梯度：$v = Du^1$。\n7.  对 $v$ 应用阈值为 $T=\\mu/\\lambda$ 的软阈值算子，以获得 $d^1$。\n所有计算均使用双精度浮点算术执行。", "answer": "[[[0.7266666666666667,0.8599999999999999,0.6733333333333333,-0.040000000000000036,-0.006666666666666671,0.2866666666666666],[-0.0,0.0,0.0,0.0,-0.0,0.0]],[[2.0,2.0,2.0,2.0,2.0,2.0],[0.0,0.0,0.0,0.0,0.0,0.0]],[[1.4285714285714286,2.857142857142857,-4.285714285714286],[0.6285714285714286,-6.314285714285714,5.685714285714286]],[[0.20171994152046782,0.5014619883040935,0.8523391812865497,1.157017543859649,1.0657894736842106,0.7821637426900585,0.4312865497076023,0.10824561403508771],[0.2997420467836257,0.3508771929824561,0.3046783625730993,0.0,0.0,0.0,0.0,0.0]]]", "id": "3369799"}]}