{"hands_on_practices": [{"introduction": "确定充足的预烧期是马尔可夫链蒙特卡洛（MCMC）分析中至关重要的第一步，但单纯依赖视觉检查往往不够可靠。本练习将通过引入一个从第一性原理推导出的严格定量标准，来超越这种主观方法。通过将 Kullback-Leibler (KL) 散度与全变差距离联系起来，您将能计算出马尔可夫链的分布收敛到真实后验分布所需的最少迭代次数，从而为这一实践需求奠定坚实的理论基础 [@problem_id:3370153]。", "problem": "考虑一个线性高斯逆问题，其中未知状态向量 $x \\in \\mathbb{R}^{n}$ 通过正向模型 $y = G x + \\varepsilon$ 与数据 $y \\in \\mathbb{R}^{m}$ 相关。这里，$G \\in \\mathbb{R}^{m \\times n}$ 是已知的，观测噪声 $\\varepsilon$ 服从零均值和正定协方差矩阵 $\\Gamma \\in \\mathbb{R}^{m \\times m}$ 的高斯分布。假设一个高斯先验 $x \\sim \\mathcal{N}(m_{0}, C_{0})$，其均值为 $m_{0} \\in \\mathbb{R}^{n}$，协方差为对称正定矩阵 $C_{0} \\in \\mathbb{R}^{n \\times n}$。一个经过充分检验的标准事实是，后验分布是高斯分布，其均值 $m_{\\mathrm{post}}$ 和协方差 $C_{\\mathrm{post}}$ 由基于正规方程的线性系统的唯一解给出：\n$$\nC_{\\mathrm{post}}^{-1} = C_{0}^{-1} + G^{\\top}\\Gamma^{-1}G, \n\\quad \nm_{\\mathrm{post}} = C_{\\mathrm{post}}\\left(C_{0}^{-1} m_{0} + G^{\\top}\\Gamma^{-1}y\\right).\n$$\n\n为从后验分布中采样，考虑使 $\\mathcal{N}(m_{\\mathrm{post}}, C_{\\mathrm{post}})$ 保持不变的自回归马尔可夫链蒙特卡洛（MCMC, Markov Chain Monte Carlo）核：\n$$\nx_{k+1} = m_{\\mathrm{post}} + \\rho \\left(x_{k} - m_{\\mathrm{post}}\\right) + \\eta_{k}, \n\\quad \\eta_{k} \\sim \\mathcal{N}(0, (1 - \\rho^{2}) C_{\\mathrm{post}}),\n$$\n其中 $\\rho \\in (0,1)$ 是一个固定的收缩参数，$\\eta_{k}$ 是独立的新息。此更新产生一个线性高斯马尔可夫链，该链是遍历的，其平稳分布等于后验分布。\n\n将“预烧期”（burn-in）定义为最小的非负整数 $k$，使得在给定的确定性起始状态 $x_{0}$ 下，$x_{k}$ 的边缘分布与后验分布 $\\mathcal{N}(m_{\\mathrm{post}}, C_{\\mathrm{post}})$ 之间的全变差距离在指定的容差 $\\tau$ 之内。你的推导必须基于基本定义以及经过充分检验的事实，包括：\n- 全变差距离的定义。\n- 将全变差距离与 Kullback–Leibler 散度关联的 Pinsker 不等式。\n- 多元高斯分布的 Kullback–Leibler 散度的闭式解。\n\n你的任务是：\n- 基于第一性原理和上述经过充分检验的事实，推导出一个显式的、可计算的准则，用以确定保证全变差距离至多为 $\\tau$ 所需的最小预烧期迭代次数。此推导需分别针对两种确定性初始化情况：$x_{0} = m_{0}$（先验均值）和 $x_{0} = m_{\\mathrm{post}}$（后验均值）。\n- 通过报告这两种预烧期计数值来量化初始化的影响。\n- 此外，确定一个稀疏因子 $s \\in \\mathbb{N}$，使得稀疏链 $\\{x_{k s}\\}$ 的滞后-1 自相关至多为给定的阈值 $\\alpha \\in (0,1)$。利用此自回归链的滞后-$\\ell$ 自相关沿每个后验模态都以 $\\rho^{\\ell}$ 的形式呈几何衰减这一事实。\n\n实现一个完整的程序，对每个测试用例执行以下操作：\n1. 根据提供的输入构造 $C_{\\mathrm{post}}^{-1}$ 和 $m_{\\mathrm{post}}$。\n2. 计算当 $x_{0} = m_{0}$ 时的最小预烧期迭代次数 $k_{\\mathrm{prior}}$。\n3. 计算当 $x_{0} = m_{\\mathrm{post}}$ 时的最小预烧期迭代次数 $k_{\\mathrm{post}}$。\n4. 计算满足 $\\rho^{s_{\\min}} \\le \\alpha$ 的最小稀疏因子 $s_{\\min}$。\n\n你的程序应只使用确定性计算；不允许进行采样。对于数值线性代数，在适当时应使用直接线性求解，而不是显式矩阵求逆。\n\n测试套件：\n为以下三个科学上一致的测试用例提供结果。\n\n- 测试用例 A（一维）：\n  - $n = 1$, $m = 1$.\n  - $G = [\\,2\\,]$.\n  - $m_{0} = [\\,0\\,]$.\n  - $C_{0} = [\\,[\\,1\\,]\\,]$.\n  - $\\Gamma = [\\,[\\,0.25\\,]\\,]$.\n  - $y = [\\,1.0\\,]$.\n  - $\\rho = 0.9$.\n  - 容差 $\\tau = 0.05$.\n  - 稀疏阈值 $\\alpha = 0.2$.\n\n- 测试用例 B（二维）：\n  - $n = 2$, $m = 2$.\n  - $G = \\begin{bmatrix} 1  -1 \\\\ 0  2 \\end{bmatrix}$.\n  - $m_{0} = [\\,0, 0\\,]^{\\top}$.\n  - $C_{0} = \\mathrm{diag}([\\,4, 1\\,])$.\n  - $\\Gamma = \\mathrm{diag}([\\,0.5, 0.5\\,])$.\n  - $y = [\\,1.0, -1.0\\,]^{\\top}$.\n  - $\\rho = 0.95$.\n  - 容差 $\\tau = 0.02$.\n  - 稀疏阈值 $\\alpha = 0.1$.\n\n- 测试用例 C（五维）：\n  - $n = 5$, $m = 5$.\n  - $G = \\begin{bmatrix}\n    1  0  0  0  0 \\\\\n    0.5  1  0  0  0 \\\\\n    0  0.5  1  0  0 \\\\\n    0  0  0.5  1  0 \\\\\n    0  0  0  0.5  1\n  \\end{bmatrix}$.\n  - $m_{0} = [\\,0, 0, 0, 0, 0\\,]^{\\top}$.\n  - $C_{0} = \\mathrm{diag}([\\,9, 4, 1, 4, 9\\,])$.\n  - $\\Gamma = \\mathrm{diag}([\\,0.5, 2.0, 1.5, 1.0, 0.8\\,])$.\n  - $y = [\\,1.0, -1.0, 0.5, 2.0, -0.5\\,]^{\\top}$.\n  - $\\rho = 0.85$.\n  - 容差 $\\tau = 0.005$.\n  - 稀疏阈值 $\\alpha = 0.05$.\n\n最终输出格式：\n你的程序应生成单行输出，其中包含一个有三个条目的列表，每个条目对应一个测试用例，且每个条目本身是一个包含三个整数 $[\\,k_{\\mathrm{prior}}, k_{\\mathrm{post}}, s_{\\min}\\,]$ 的列表。最终打印的行必须严格遵循以下格式\n$$\n[\\,[k_{\\mathrm{prior}}^{A},k_{\\mathrm{post}}^{A},s_{\\min}^{A}],\\,[k_{\\mathrm{prior}}^{B},k_{\\mathrm{post}}^{B},s_{\\min}^{B}],\\,[k_{\\mathrm{prior}}^{C},k_{\\mathrm{post}}^{C},s_{\\min}^{C}]\\,],\n$$\n不含多余空格。不涉及物理单位或角度单位。所有答案必须是整数。", "solution": "该问题要求针对一个应用于线性高斯逆问题的特定马尔可夫链蒙特卡洛（MCMC）采样器，推导并实现用于确定预烧期和稀疏因子的准则。解决方案分三步进行：首先，严格推导预烧期准则；其次，推导稀疏因子；第三，实现这些准则。\n\n### 问题验证\n\n**步骤 1：提取已知条件**\n-   **正向模型**: $y = G x + \\varepsilon$, 其中 $x \\in \\mathbb{R}^{n}$, $y \\in \\mathbb{R}^{m}$, $G \\in \\mathbb{R}^{m \\times n}$。\n-   **观测噪声**: $\\varepsilon \\sim \\mathcal{N}(0, \\Gamma)$，其中 $\\Gamma \\in \\mathbb{R}^{m \\times m}$ 是一个正定协方差矩阵。\n-   **先验分布**: $x \\sim \\mathcal{N}(m_{0}, C_{0})$，其均值为 $m_{0} \\in \\mathbb{R}^{n}$，协方差为对称正定矩阵 $C_{0} \\in \\mathbb{R}^{n \\times n}$。\n-   **后验分布**: $\\mathcal{N}(m_{\\mathrm{post}}, C_{\\mathrm{post}})$，其精度矩阵为 $C_{\\mathrm{post}}^{-1} = C_{0}^{-1} + G^{\\top}\\Gamma^{-1}G$，均值为 $m_{\\mathrm{post}} = C_{\\mathrm{post}}(C_{0}^{-1} m_{0} + G^{\\top}\\Gamma^{-1}y)$。\n-   **MCMC 核**: $x_{k+1} = m_{\\mathrm{post}} + \\rho \\left(x_{k} - m_{\\mathrm{post}}\\right) + \\eta_{k}$，其中 $\\eta_{k} \\sim \\mathcal{N}(0, (1 - \\rho^{2}) C_{\\mathrm{post}})$ 且 $\\rho \\in (0,1)$。\n-   **初始状态**: 确定性起始状态 $x_{0}$。\n-   **预烧期定义**: 最小非负整数 $k$，使得 $x_k$ 的分布与后验分布之间的全变差距离至多为 $\\tau$。\n-   **工具**: 全变差距离、Pinsker 不等式、多元高斯分布的闭式 Kullback–Leibler (KL) 散度。\n-   **初始化**: $x_{0} = m_{0}$ 和 $x_{0} = m_{\\mathrm{post}}$。\n-   **稀疏定义**: 最小整数 $s \\ge 1$，使得稀疏链 $\\{x_{ks}\\}$ 的滞后-1 自相关至多为 $\\alpha$。给定滞后-$\\ell$ 自相关为 $\\rho^{\\ell}$。\n-   **测试数据**: 提供了三组不同的参数集 $(n, m, G, m_0, C_0, \\Gamma, y, \\rho, \\tau, \\alpha)$。\n\n**步骤 2：使用提取的已知条件进行验证**\n该问题具有科学依据、适定且客观。它植根于线性高斯模型的贝叶斯逆问题和基础 MCMC 理论的标准理论。后验方程是标准的。MCMC 采样器是一个众所周知的自回归过程，旨在收敛于目标高斯分布。使用如全变差距离和 KL 散度等信息论度量来分析概率分布的收敛性是标准做法。所有参数和条件都已指定，不存在歧义或矛盾。矩阵 $C_0$ 和 $\\Gamma$ 被指定为正定，确保它们的逆存在。后验精度矩阵 $C_{\\mathrm{post}}^{-1}$ 是一个正定矩阵（$C_0^{-1}$）和一个半正定矩阵（$G^T \\Gamma^{-1} G$）的和，因此 $C_{\\mathrm{post}}^{-1}$ 是正定的。从而，存在唯一的后验分布。该问题是应用概率和数值线性代数中的一个形式化练习，而非非形式化的类比或无关紧要的问题。\n\n**步骤 3：结论与行动**\n问题是**有效的**。开始进行解答。\n\n### 预烧期准则的推导\n\n预烧期定义为所需的最小迭代次数 $k$，以使链的边缘分布 $P_k$ “接近”平稳后验分布 $P_{\\mathrm{post}} = \\mathcal{N}(m_{\\mathrm{post}}, C_{\\mathrm{post}})$。接近程度由全变差距离 $d_{TV}(P_k, P_{\\mathrm{post}})$ 衡量。问题要求使用 Pinsker 不等式来获得一个上界，该不等式将全变差距离与 Kullback-Leibler (KL) 散度关联起来：\n$$d_{TV}(P_k, P_{\\mathrm{post}}) \\le \\sqrt{\\frac{1}{2} D_{KL}(P_k || P_{\\mathrm{post}})}$$\n因此，如果我们强制执行更强的条件，就可以保证预烧期条件 $d_{TV}(P_k, P_{\\mathrm{post}}) \\le \\tau$：\n$$\\sqrt{\\frac{1}{2} D_{KL}(P_k || P_{\\mathrm{post}})} \\le \\tau \\quad \\iff \\quad D_{KL}(P_k || P_{\\mathrm{post}}) \\le 2\\tau^2$$\n要使用此准则，我们必须首先找到在任何给定迭代 $k$ 下状态向量 $x_k$ 的分布 $P_k$。链从一个确定性状态 $x_0$ 开始。更新规则是线性的，新息 $\\eta_k$ 是高斯的，因此对于所有 $k \\ge 1$，$x_k$ 都将服从高斯分布。设 $x_k \\sim \\mathcal{N}(\\mu_k, \\Sigma_k)$。\n\n均值 $\\mu_k$ 的演化遵循：\n$$\\mu_{k+1} = E[x_{k+1}] = E[m_{\\mathrm{post}} + \\rho(x_k - m_{\\mathrm{post}}) + \\eta_k] = m_{\\mathrm{post}} + \\rho(\\mu_k - m_{\\mathrm{post}})$$\n这是与后验均值偏差 $\\delta_k = \\mu_k - m_{\\mathrm{post}}$ 的一个简单等比数列。我们有 $\\delta_{k+1} = \\rho \\delta_k$，这意味着 $\\delta_k = \\rho^k \\delta_0$。由于 $x_0$ 是确定性的，$\\mu_0 = x_0$，因此 $\\delta_0 = x_0 - m_{\\mathrm{post}}$。第 $k$ 次迭代的均值为：\n$$\\mu_k = m_{\\mathrm{post}} + \\rho^k(x_0 - m_{\\mathrm{post}})$$\n协方差 $\\Sigma_k$ 的演化遵循：\n$$\\Sigma_{k+1} = \\mathrm{Cov}(x_{k+1}) = \\mathrm{Cov}(\\rho(x_k - m_{\\mathrm{post}}) + \\eta_k) = \\rho^2 \\mathrm{Cov}(x_k) + \\mathrm{Cov}(\\eta_k)$$\n这里我们利用了 $x_k$ 和 $\\eta_k$ 的独立性。代入定义：\n$$\\Sigma_{k+1} = \\rho^2 \\Sigma_k + (1-\\rho^2)C_{\\mathrm{post}}$$\n从确定性 $x_0$ 开始，初始协方差为 $\\Sigma_0 = \\mathbf{0}$。递推展开为：\n$\\Sigma_1 = (1-\\rho^2)C_{\\mathrm{post}}$\n$\\Sigma_2 = \\rho^2(1-\\rho^2)C_{\\mathrm{post}} + (1-\\rho^2)C_{\\mathrm{post}} = (1-\\rho^4)C_{\\mathrm{post}}$\n根据归纳法，第 $k$ 次迭代的协方差为：\n$$\\Sigma_k = (1 - \\rho^{2k}) C_{\\mathrm{post}}$$\n对于 $k=0$，分布 $P_0$ 是在 $x_0$ 处的一个点质量。点质量与一个连续分布（后验分布）之间的全变差距离为 $1$。由于给定的容差 $\\tau \\ll 1$，条件 $d_{TV} \\le \\tau$ 在 $k=0$ 时永远无法满足。因此，我们寻求最小的整数 $k \\ge 1$。对于 $k \\ge 1$，$\\Sigma_k$ 是正定的，$P_k = \\mathcal{N}(\\mu_k, \\Sigma_k)$ 是一个有效的非退化高斯分布。\n\n从一个高斯分布 $P_1 = \\mathcal{N}(\\mu_1, \\Sigma_1)$ 到 $P_2 = \\mathcal{N}(\\mu_2, \\Sigma_2)$ 的 KL 散度为：\n$$D_{KL}(P_1 || P_2) = \\frac{1}{2} \\left( \\mathrm{Tr}(\\Sigma_2^{-1} \\Sigma_1) + (\\mu_2-\\mu_1)^{\\top} \\Sigma_2^{-1} (\\mu_2-\\mu_1) - n + \\ln\\left(\\frac{\\det \\Sigma_2}{\\det \\Sigma_1}\\right) \\right)$$\n在我们的情况下，$P_1 = P_k$ 且 $P_2 = P_{\\mathrm{post}}$。我们代入 $\\mu_1=\\mu_k, \\Sigma_1=\\Sigma_k, \\mu_2=m_{\\mathrm{post}}, \\Sigma_2=C_{\\mathrm{post}}$：\n-   迹项: $\\mathrm{Tr}(C_{\\mathrm{post}}^{-1} \\Sigma_k) = \\mathrm{Tr}(C_{\\mathrm{post}}^{-1} (1-\\rho^{2k})C_{\\mathrm{post}}) = \\mathrm{Tr}((1-\\rho^{2k})I_n) = n(1-\\rho^{2k})$。\n-   二次项: $(\\mu_2-\\mu_1)^{\\top} \\Sigma_2^{-1} (\\mu_2-\\mu_1) = (-\\rho^k(x_0 - m_{\\mathrm{post}}))^{\\top} C_{\\mathrm{post}}^{-1} (-\\rho^k(x_0 - m_{\\mathrm{post}})) = \\rho^{2k}(x_0 - m_{\\mathrm{post}})^{\\top} C_{\\mathrm{post}}^{-1} (x_0 - m_{\\mathrm{post}})$。\n-   对数行列式项: $\\ln(\\frac{\\det C_{\\mathrm{post}}}{\\det \\Sigma_k}) = \\ln(\\frac{\\det C_{\\mathrm{post}}}{\\det((1-\\rho^{2k})C_{\\mathrm{post}})}) = \\ln(\\frac{1}{(1-\\rho^{2k})^n}) = -n \\ln(1-\\rho^{2k})$。\n\n结合这些项，KL 散度为：\n$$D_{KL}(P_k || P_{\\mathrm{post}}) = \\frac{1}{2} \\left[ n(1-\\rho^{2k}) + \\rho^{2k} D^2 - n - n\\ln(1-\\rho^{2k}) \\right]$$\n其中 $D^2 = (x_0 - m_{\\mathrm{post}})^{\\top} C_{\\mathrm{post}}^{-1} (x_0 - m_{\\mathrm{post}})$ 是 $x_0$ 和 $m_{\\mathrm{post}}$ 关于 $C_{\\mathrm{post}}$ 的马氏距离的平方。\n简化此表达式得到：\n$$D_{KL}(P_k || P_{\\mathrm{post}}) = \\frac{1}{2} \\left[ \\rho^{2k} (D^2 - n) - n\\ln(1-\\rho^{2k}) \\right]$$\n预烧期准则即为找到满足以下条件的最小整数 $k \\ge 1$：\n$$\\frac{1}{2} \\left[ \\rho^{2k} (D^2 - n) - n\\ln(1-\\rho^{2k}) \\right] \\le 2\\tau^2$$\n这个不等式通过对 $k=1, 2, 3, \\dots$ 进行数值迭代来求解，直到条件满足。\n\n**情况 1：在后验均值处初始化 ($x_0 = m_{\\mathrm{post}}$)**\n此时，$x_0 - m_{\\mathrm{post}} = \\mathbf{0}$，因此 $D^2 = 0$。$k_{\\mathrm{post}}$ 的准则简化为找到满足以下条件的最小整数 $k \\ge 1$：\n$$\\frac{1}{2} \\left[ -n\\rho^{2k} - n\\ln(1-\\rho^{2k}) \\right] \\le 2\\tau^2 \\iff -\\rho^{2k} - \\ln(1-\\rho^{2k}) \\le \\frac{4\\tau^2}{n}$$\n\n**情况 2：在先验均值处初始化 ($x_0 = m_0$)**\n此时，我们首先计算马氏距离的平方 $D_{\\mathrm{prior}}^2 = (m_0 - m_{\\mathrm{post}})^{\\top} C_{\\mathrm{post}}^{-1} (m_0 - m_{\\mathrm{post}})$。$k_{\\mathrm{prior}}$ 的准则为找到满足以下条件的最小整数 $k \\ge 1$：\n$$\\rho^{2k} (D_{\\mathrm{prior}}^2 - n) - n\\ln(1-\\rho^{2k}) \\le 4\\tau^2$$\n\n### 稀疏因子的推导\n\n选择稀疏因子 $s$ 是为了减少链中的自相关。问题陈述原始链 $\\{x_k\\}$ 的滞后-$\\ell$ 自相关为 $\\rho^{\\ell}$。稀疏链是通过每 $s$ 个样本取一个来形成的：$\\{x_{ks}\\}$。这个稀疏链的滞后-1 自相关等价于原始链的滞后-$s$ 自相关。我们要求此自相关不大于给定的阈值 $\\alpha$。\n因此，条件是：\n$$\\rho^s \\le \\alpha$$\n由于 $\\rho \\in (0,1)$ 且 $\\alpha \\in (0,1)$，我们可以对两边取自然对数。因为 $\\ln(\\rho)$ 是负数，除法后必须反转不等号：\n$$s \\ln(\\rho) \\le \\ln(\\alpha) \\implies s \\ge \\frac{\\ln(\\alpha)}{\\ln(\\rho)}$$\n由于 $s$ 必须是正整数（$s \\in \\mathbb{N}$），最小稀疏因子 $s_{\\min}$ 是满足此条件的最小整数：\n$$s_{\\min} = \\left\\lceil \\frac{\\ln(\\alpha)}{\\ln(\\rho)} \\right\\rceil$$\n\n### 计算算法\n\n对于每个测试用例，算法按以下步骤进行：\n1.  读取参数 $n, m, G, m_0, C_0, \\Gamma, y, \\rho, \\tau, \\alpha$。\n2.  计算先验和噪声协方差矩阵的逆矩阵，$C_0^{-1}$ 和 $\\Gamma^{-1}$。\n3.  计算后验精度矩阵 $C_{\\mathrm{post}}^{-1} = C_{0}^{-1} + G^{\\top}\\Gamma^{-1}G$。\n4.  计算向量项 $b = C_{0}^{-1} m_{0} + G^{\\top}\\Gamma^{-1}y$。\n5.  求解线性系统 $C_{\\mathrm{post}}^{-1}m_{\\mathrm{post}} = b$ 以找到后验均值 $m_{\\mathrm{post}}$。\n6.  为了找到 $k_{\\mathrm{post}}$，迭代 $k=1, 2, \\dots$ 直到 $-\\rho^{2k} - \\ln(1-\\rho^{2k}) \\le 4\\tau^2/n$。第一个满足此条件的 $k$ 即为 $k_{\\mathrm{post}}$。\n7.  为了找到 $k_{\\mathrm{prior}}$，首先计算马氏距离的平方 $D_{\\mathrm{prior}}^2 = (m_0 - m_{\\mathrm{post}})^{\\top} C_{\\mathrm{post}}^{-1} (m_0 - m_{\\mathrm{post}})$。然后，迭代 $k=1, 2, \\dots$ 直到 $\\rho^{2k} (D_{\\mathrm{prior}}^2 - n) - n\\ln(1-\\rho^{2k}) \\le 4\\tau^2$。第一个满足此条件的 $k$ 即为 $k_{\\mathrm{prior}}$。\n8.  计算最小稀疏因子 $s_{\\min} = \\lceil \\ln(\\alpha)/\\ln(\\rho) \\rceil$。\n9.  收集整数结果 $[k_{\\mathrm{prior}}, k_{\\mathrm{post}}, s_{\\min}]$。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the MCMC burn-in and thinning problem for the given test cases.\n    \"\"\"\n\n    test_cases = [\n        {\n            \"n\": 1, \"m\": 1,\n            \"G\": np.array([[2.0]]),\n            \"m0\": np.array([0.0]),\n            \"C0\": np.array([[1.0]]),\n            \"Gamma\": np.array([[0.25]]),\n            \"y\": np.array([1.0]),\n            \"rho\": 0.9, \"tau\": 0.05, \"alpha\": 0.2,\n        },\n        {\n            \"n\": 2, \"m\": 2,\n            \"G\": np.array([[1.0, -1.0], [0.0, 2.0]]),\n            \"m0\": np.array([0.0, 0.0]),\n            \"C0\": np.diag([4.0, 1.0]),\n            \"Gamma\": np.diag([0.5, 0.5]),\n            \"y\": np.array([1.0, -1.0]),\n            \"rho\": 0.95, \"tau\": 0.02, \"alpha\": 0.1,\n        },\n        {\n            \"n\": 5, \"m\": 5,\n            \"G\": np.array([\n                [1.0, 0.0, 0.0, 0.0, 0.0],\n                [0.5, 1.0, 0.0, 0.0, 0.0],\n                [0.0, 0.5, 1.0, 0.0, 0.0],\n                [0.0, 0.0, 0.5, 1.0, 0.0],\n                [0.0, 0.0, 0.0, 0.5, 1.0]\n            ]),\n            \"m0\": np.array([0.0, 0.0, 0.0, 0.0, 0.0]),\n            \"C0\": np.diag([9.0, 4.0, 1.0, 4.0, 9.0]),\n            \"Gamma\": np.diag([0.5, 2.0, 1.5, 1.0, 0.8]),\n            \"y\": np.array([1.0, -1.0, 0.5, 2.0, -0.5]),\n            \"rho\": 0.85, \"tau\": 0.005, \"alpha\": 0.05,\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        results.append(solve_case(case))\n\n    # Format the final output string\n    formatted_results = [f\"[{','.join(map(str, res))}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\ndef get_burn_in(n, rho, D2, tau, max_iter=100000):\n    \"\"\"\n    Computes the minimal burn-in iteration count.\n    \"\"\"\n    threshold = 4 * tau**2\n    \n    # Iterate to find the smallest k >= 1 satisfying the condition\n    for k in range(1, max_iter):\n        rho_2k = rho**(2 * k)\n        \n        # This is the LHS of the inequality derived in the solution text\n        # D_KL * 2 = rho^{2k} (D^2 - n) - n ln(1-rho^{2k})\n        kl_term = rho_2k * (D2 - n) - n * np.log(1 - rho_2k)\n        \n        if kl_term <= threshold:\n            return k\n    return max_iter # Should not be reached with reasonable max_iter\n\ndef solve_case(params):\n    \"\"\"\n    Processes a single test case.\n    \"\"\"\n    n = params[\"n\"]\n    G, m0, C0, Gamma, y = params[\"G\"], params[\"m0\"], params[\"C0\"], params[\"Gamma\"], params[\"y\"]\n    rho, tau, alpha = params[\"rho\"], params[\"tau\"], params[\"alpha\"]\n\n    # Ensure vectors are column vectors for matrix operations\n    m0 = m0.reshape(-1, 1)\n    y = y.reshape(-1, 1)\n\n    # 1. Compute posterior parameters\n    C0_inv = np.linalg.inv(C0)\n    Gamma_inv = np.linalg.inv(Gamma)\n\n    C_post_inv = C0_inv + G.T @ Gamma_inv @ G\n    b = C0_inv @ m0 + G.T @ Gamma_inv @ y\n    m_post = np.linalg.solve(C_post_inv, b)\n\n    # 2. Compute burn-in for x0 = m_post\n    # D^2 = (m_post - m_post)^T C_post_inv (m_post - m_post) = 0\n    D2_post = 0.0\n    k_post = get_burn_in(n, rho, D2_post, tau)\n\n    # 3. Compute burn-in for x0 = m0\n    delta_m = m0 - m_post\n    D2_prior = (delta_m.T @ C_post_inv @ delta_m).item() # .item() to get scalar\n    k_prior = get_burn_in(n, rho, D2_prior, tau)\n    \n    # 4. Compute thinning factor\n    s_min = int(np.ceil(np.log(alpha) / np.log(rho)))\n\n    return [k_prior, k_post, s_min]\n\nsolve()\n\n```", "id": "3370153"}, {"introduction": "在理论基础之上，本练习将重点转移到实现采样器并直接对其输出应用诊断方法。您将构建一个随机游走 Metropolis MCMC 算法，然后通过监控马尔可夫链是否在后验分布的“典型集”中探索，来设计一种新颖的诊断方法以确定预烧期。这项动手实践还介绍了使用积分自相关时间 (Integrated Autocorrelation Time, IACT) 来指导稀疏过程的标准做法，使您能够全面掌握从 MCMC 生成到后处理的整个流程 [@problem_id:3370155]。", "problem": "考虑一个带有高斯观测噪声的线性反演问题，其中数据失配由负对数似然 $-\\tfrac{1}{2}\\lVert \\Gamma^{-1/2}(G(\\theta)-y)\\rVert^2$ 来衡量。令 $G(\\theta)=H\\theta$，其中 $H\\in\\mathbb{R}^{m\\times d}$ 是已知的，并令 $\\Gamma\\in\\mathbb{R}^{m\\times m}$ 是一个对称正定的观测协方差矩阵。假设一个平坦先验，因此后验密度与似然成正比。您将实现一个随机游走 Metropolis 马尔可夫链蒙特卡洛 (MCMC) 算法，并设计一个基于与由似然定义的典型集之间的 Kullback-Leibler 散度 (KL) 偏差的老化期诊断方法。\n\n推导和实现的基本依据必须从以下事实出发：高斯噪声意味着二次负对数似然，仅含噪声数据的归一化残差平方和的分布是自由度为 $m$ 的卡方分布，与给定质量水平相关联的典型集由该卡方定律的中心分位数定义，离散分布之间的 Kullback-Leibler 散度由其基本变分形式定义，对于对称提议，Random-Walk Metropolis 接受准则遵循目标密度的比率。\n\n在所有测试用例中，使用以下固定的模型组件。设置观测维度为 $m=5$，参数维度为 $d=3$。定义\n$$\nH=\\begin{bmatrix}\n1.0  0.5  0.0\\\\\n0.0  1.0  0.5\\\\\n0.2  0.0  1.0\\\\\n1.0  -0.5  0.25\\\\\n0.0  0.0  1.0\n\\end{bmatrix},\n\\quad\n\\Gamma=\\mathrm{diag}\\big(\\sigma_1^2,\\sigma_2^2,\\sigma_3^2,\\sigma_4^2,\\sigma_5^2\\big),\n\\quad\n(\\sigma_1,\\sigma_2,\\sigma_3,\\sigma_4,\\sigma_5)=(0.1,0.1,0.1,0.2,0.15).\n$$\n令 $y\\in\\mathbb{R}^5$ 固定为\n$$\ny=\\begin{bmatrix}0.475\\\\ 0.025\\\\ 0.85\\\\ 0.9125\\\\ 0.675\\end{bmatrix}.\n$$\n对于任何 $\\theta\\in\\mathbb{R}^3$，定义 Mahalanobis 失配平方\n$$\nS(\\theta)=\\left\\|\\Gamma^{-1/2}\\left(H\\theta - y\\right)\\right\\|^2=\\sum_{i=1}^m \\frac{\\left((H\\theta-y)_i\\right)^2}{\\sigma_i^2}.\n$$\n为此失配定义中心 $\\alpha$-典型集为区间 $[q_{\\mathrm{low}},q_{\\mathrm{high}}]$，其中 $q_{\\mathrm{low}}$ 和 $q_{\\mathrm{high}}$ 是自由度为 $m$ 的卡方分布的下中心分位数和上中心分位数，它们捕获了 $\\alpha$ 的中心概率质量，即，\n$$\nq_{\\mathrm{low}}=F_{\\chi^2_m}^{-1}\\left(\\frac{1-\\alpha}{2}\\right),\\qquad q_{\\mathrm{high}}=F_{\\chi^2_m}^{-1}\\left(1-\\frac{1-\\alpha}{2}\\right).\n$$\n对于一个长度为 $W$ 的连续索引 $\\{t,\\dots,t+W-1\\}$ 的有限 MCMC 子序列，定义失配值 $S(\\theta_j)$ 落入典型集 $[q_{\\mathrm{low}},q_{\\mathrm{high}}]$ 的经验分数 $f_t$。考虑在 $\\{\\text{典型},\\text{非典型}\\}$ 上的二元经验分布 $q_t$，其质量为 $f_t$ 和 $1-f_t$，并将其与在相同支撑集上质量为 $\\alpha$ 和 $1-\\alpha$ 的参考二元分布 $p_\\alpha$ 进行比较。使用离散分布的 Kullback-Leibler 散度的基本定义，为每个窗口计算散度 $D_{\\mathrm{KL}}(q_t\\|p_\\alpha)$。定义老化期指数 $b$ 为最小的起始索引 $t$，使得对于所有从索引 $t'\\ge t$ 开始的窗口，散度都满足 $D_{\\mathrm{KL}}(q_{t'}\\|p_\\alpha)\\le \\varepsilon$。如果不存在这样的索引，则按照惯例设置 $b=N$，其中 $N$ 是 MCMC 样本的总数。\n\n在丢弃最初的 $b$ 个样本后，通过计算标量失配序列 $\\{S(\\theta_j)\\}_{j=b}^{N-1}$ 的积分自相关时间 (IACT) 来估计稀疏化建议，使用应用于归一化自相关函数的初始正序列估计器。将建议的稀疏化间隔设置为 $\\lceil \\mathrm{IACT}\\rceil$。如果 $b=N$，则定义稀疏化间隔为整数 $0$。\n\n您必须实现一个 Random-Walk Metropolis MCMC，其高斯提议形式为 $\\theta'=\\theta+\\eta$，其中 $\\eta\\sim\\mathcal{N}(0,\\sigma_{\\mathrm{prop}}^2 I_d)$，$I_d$ 是 $d\\times d$ 的单位矩阵。使用基于后验密度比率和提议对称性的基本 Metropolis 接受准则。对于每个测试用例，生成一个长度为 $N$ 的链，计算滑动窗口散度 $D_{\\mathrm{KL}}(q_t\\|p_\\alpha)$，确定老化期指数 $b$，然后按规定计算稀疏化建议 $\\lceil \\mathrm{IACT}\\rceil$。\n\n测试套件。使用以下三组参数；每个用例都明确指定了链长 $N$、提议标准差 $\\sigma_{\\mathrm{prop}}$、初始参数 $\\theta_0$、典型集质量 $\\alpha$、窗口长度 $W$ 和散度阈值 $\\varepsilon$。所有其他模型组件均如上文所定义。不涉及角度，也不涉及物理单位。\n\n用例 1 (调优良好的链):\n- $N=4000$, $\\sigma_{\\mathrm{prop}}=0.35$, $\\theta_0=\\begin{bmatrix}0.0\\\\ 0.0\\\\ 0.0\\end{bmatrix}$, $\\alpha=0.9$, $W=400$, $\\varepsilon=0.02$.\n\n用例 2 (长瞬态):\n- $N=4000$, $\\sigma_{\\mathrm{prop}}=0.35$, $\\theta_0=\\begin{bmatrix}5.0\\\\ -5.0\\\\ 5.0\\end{bmatrix}$, $\\alpha=0.9$, $W=400$, $\\varepsilon=0.02$.\n\n用例 3 (混合极差):\n- $N=4000$, $\\sigma_{\\mathrm{prop}}=2.5$, $\\theta_0=\\begin{bmatrix}5.0\\\\ -5.0\\\\ 5.0\\end{bmatrix}$, $\\alpha=0.9$, $W=400$, $\\varepsilon=0.02$.\n\n最终输出格式。您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，按上文规定输出一个包含两个整数 $[b,\\lceil \\mathrm{IACT}\\rceil]$ 的列表。按顺序将三个用例的结果汇总到一个列表中，例如，形式为 $[[b_1,\\lceil \\mathrm{IACT}\\rceil_1],[b_2,\\lceil \\mathrm{IACT}\\rceil_2],[b_3,\\lceil \\mathrm{IACT}\\rceil_3]]$。", "solution": "该问题要求为马尔可夫链蒙特卡洛 (MCMC) 模拟实现并应用一个后处理工作流。该工作流涉及为从线性反演问题的后验分布中抽取的样本确定一个合适的老化期和一个稀疏化间隔。解决方案将以分步方式呈现，首先是贝叶斯反演问题的公式化，然后是 MCMC 算法的描述，最后是老化期和稀疏化诊断的详细程序。\n\n**1. 贝叶斯反演问题**\n\n我们给定一个线性正演模型 $G(\\theta) = H\\theta$，其中 $\\theta \\in \\mathbb{R}^d$ 是我们感兴趣的参数，而 $H \\in \\mathbb{R}^{m \\times d}$ 是正演算子。观测值 $y \\in \\mathbb{R}^m$ 假定被零均值和已知协方差矩阵 $\\Gamma \\in \\mathbb{R}^{m \\times m}$ 的加性高斯噪声所污染。因此，数据生成过程为 $y = H\\theta_{\\text{true}} + \\epsilon$，其中 $\\epsilon \\sim \\mathcal{N}(0, \\Gamma)$。\n\n在给定参数 $\\theta$ 的情况下，观测到数据 $y$ 的似然由高斯噪声的概率密度函数给出：\n$$\nL(y|\\theta) \\propto \\exp\\left(-\\frac{1}{2} (H\\theta - y)^T \\Gamma^{-1} (H\\theta - y)\\right)\n$$\n这可以使用 Mahalanobis 距离的平方 $S(\\theta)$ 来表示：\n$$\nS(\\theta) = \\left\\|\\Gamma^{-1/2}\\left(H\\theta - y\\right)\\right\\|^2 = (H\\theta - y)^T \\Gamma^{-1} (H\\theta - y)\n$$\n因此，似然为 $L(y|\\theta) \\propto \\exp\\left(-\\frac{1}{2}S(\\theta)\\right)$。问题指定了一个平坦先验，$\\pi(\\theta) \\propto c$，其中 $c$ 为某个常数。根据 Bayes 定理，后验分布 $\\pi(\\theta|y)$ 与似然和先验的乘积成正比：\n$$\n\\pi(\\theta|y) \\propto L(y|\\theta)\\pi(\\theta) \\propto \\exp\\left(-\\frac{1}{2}S(\\theta)\\right)\n$$\n这个后验密度是我们旨在使用 MCMC 进行采样的目标分布。\n\n具体的模型组件是固定的：维度为 $m=5$ 和 $d=3$。矩阵 $H$、数据向量 $y$ 以及对角协方差矩阵 $\\Gamma=\\mathrm{diag}(\\sigma_1^2, \\dots, \\sigma_5^2)$ 均已提供。\n\n**2. 随机游走 Metropolis (RWM) 算法**\n\n为了从后验分布 $\\pi(\\theta|y)$ 中抽取样本，我们采用 Random-Walk Metropolis 算法，这是一种特定类型的 Metropolis-Hastings MCMC。该算法流程如下：\n\n1.  **初始化**：在步骤 $j=0$ 时，从一个初始参数向量 $\\theta_0$ 开始。\n2.  **迭代**：对于每一步 $j = 0, 1, \\dots, N-2$：\n    a. **提议**：从一个对称提议分布中生成一个候选样本 $\\theta'$。对于 RWM 算法，这是一个以当前状态为中心的高斯分布：$\\theta' = \\theta_j + \\eta$，其中 $\\eta \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{prop}}^2 I_d)$。提议的对称性，$q(\\theta'|\\theta_j) = q(\\theta_j|\\theta')$，简化了接受准则。\n    b. **接受**：计算接受概率 $A$，即后验密度的比率：\n    $$\n    A(\\theta'|\\theta_j) = \\min\\left(1, \\frac{\\pi(\\theta'|y)}{\\pi(\\theta_j|y)}\\right) = \\min\\left(1, \\frac{\\exp(-\\frac{1}{2}S(\\theta'))}{\\exp(-\\frac{1}{2}S(\\theta_j))}\\right) = \\min\\left(1, \\exp\\left[-\\frac{1}{2}(S(\\theta') - S(\\theta_j))\\right]\\right)\n    $$\n    c. **更新**：从均匀分布 $U(0,1)$ 中抽取一个随机数 $u$。如果 $u < A(\\theta'|\\theta_j)$，则接受该提议，我们设置 $\\theta_{j+1} = \\theta'$。否则，拒绝该提议，链保持在当前状态，即 $\\theta_{j+1} = \\theta_j$。\n\n此过程生成一个样本序列 $\\{\\theta_0, \\theta_1, \\dots, \\theta_{N-1}\\}$，在经过足够的老化期后，该序列形成一个马尔可夫链，其平稳分布是目标后验分布 $\\pi(\\theta|y)$。\n\n**3. 通过 Kullback-Leibler 散度进行老化期诊断**\n\nMCMC 链的初始样本（老化期）可能不代表平稳分布，必须被丢弃。问题指定了一种诊断方法来确定老化期长度 $b$。\n\n该诊断基于失配值 $S(\\theta)$ 的统计行为。如果模型是完美的并且我们知道真实参数 $\\theta_{true}$，归一化的残差项 $S(\\theta_{true}) = \\| \\Gamma^{-1/2}(y-H\\theta_{true}) \\|^2$ 将服从自由度为 $m$ 的卡方随机变量分布，即 $\\chi^2_m$。该诊断检查来自 MCMC 链的失配值 $S(\\theta_j)$ 是否符合此参考分布的行为。\n\n1.  **典型集**：为 $\\chi^2_m$ 分布定义了一个中心高概率区域。对于选定的概率质量 $\\alpha$，中心 $\\alpha$-典型集是区间 $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$，其边界是 $\\chi^2_m$ 分布的分位数：\n    $$\n    q_{\\mathrm{low}} = F_{\\chi^2_m}^{-1}\\left(\\frac{1-\\alpha}{2}\\right), \\quad q_{\\mathrm{high}} = F_{\\chi^2_m}^{-1}\\left(1 - \\frac{1-\\alpha}{2}\\right)\n    $$\n    其中 $F_{\\chi^2_m}^{-1}$ 是逆累积分布函数（分位数函数）。根据构造，一个 $\\chi^2_m$ 变量落入此区间的概率恰好是 $\\alpha$。\n\n2.  **KL 散度**：该诊断是在沿链的长度为 $W$ 的滑动窗口上计算的。对于一个从索引 $t$ 开始的窗口，我们计算样本 $\\theta_j$ (其中 $j \\in \\{t, \\dots, t+W-1\\}$) 的失配值 $S(\\theta_j)$ 位于典型集 $[q_{\\mathrm{low}}, q_{\\mathrm{high}}]$ 内的经验分数 $f_t$。\n    这定义了在结果 $\\{\\text{典型}, \\text{非典型}\\}$ 上的一个二元经验分布 $q_t$，其概率为 $(f_t, 1-f_t)$。将其与理论参考分布 $p_\\alpha = (\\alpha, 1-\\alpha)$ 进行比较。差异由 Kullback-Leibler (KL) 散度衡量：\n    $$\n    D_{\\mathrm{KL}}(q_t \\| p_\\alpha) = f_t \\log\\left(\\frac{f_t}{\\alpha}\\right) + (1-f_t) \\log\\left(\\frac{1-f_t}{1-\\alpha}\\right)\n    $$\n    其中使用惯例 $0 \\log 0 = 0$。\n\n3.  **老化期指数 ($b$)**：老化期指数 $b$ 被定义为最小的窗口起始索引 $t$，使得对于所有后续窗口（即所有 $t' \\ge t$），散度保持在给定阈值 $\\varepsilon$ 以下：$D_{\\mathrm{KL}}(q_{t'} \\| p_\\alpha) \\le \\varepsilon$。为了找到 $b$，可以识别违反此条件的*最后一个*窗口的索引，记为 $t_{\\text{last\\_violating}}$。那么，老化期就是 $b = t_{\\text{last\\_violating}} + 1$。如果没有窗口违反该条件，则 $b=0$。如果不存在这样的 $t$（即，该条件在链中任意远处都被违反），问题指定了惯例 $b=N$。\n\n**4. 通过积分自相关时间 (IACT) 进行稀疏化**\n\n在丢弃老化期样本后，剩余的链在连续样本之间可能仍表现出强相关性。稀疏化是仅保留每第 $k$ 个样本以减少这种相关性的过程，其中 $k$ 是稀疏化间隔。确定 $k$ 的一种常用方法是估计积分自相关时间 (IACT)。\n\n1.  **平稳序列**：我们使用来自链的平稳部分的标量失配序列，$\\{S(\\theta_j)\\}_{j=b}^{N-1}$。\n2.  **自相关函数 (ACF)**：首先，计算该序列对于不同滞后 $k$ 的归一化 ACF $\\rho_k$。\n3.  **IACT 估计**：IACT, $\\tau$, 由 $\\tau = 1 + 2\\sum_{k=1}^{\\infty} \\rho_k$ 给出。我们使用初始正序列方法来估计它，该方法在 ACF 变为非正的第一个滞后 $M$ 处截断求和：\n    $$\n    \\mathrm{IACT} \\approx 1 + 2 \\sum_{k=1}^{M} \\rho_k, \\quad \\text{其中 } M = \\max\\{k' \\mid \\rho_k > 0 \\text{ for all } 1 \\le k \\le k'\\}\n    $$\n4.  **稀疏化间隔**：建议的稀疏化间隔是大于或等于 IACT 的最小整数，即 $\\lceil \\mathrm{IACT} \\rceil$。如果老化期包含整个链 ($b=N$)，则平稳序列为空，稀疏化间隔定义为 0。\n\n实现将为提供的每个测试用例系统地执行这些步骤。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import chi2\nfrom scipy.special import rel_entr\nimport math\n\ndef solve():\n    \"\"\"\n    Main solver function that orchestrates the MCMC simulation and analysis for all test cases.\n    \"\"\"\n    # Set a random seed for reproducibility of the stochastic MCMC process.\n    np.random.seed(0)\n\n    # --- Fixed Model Components ---\n    # Observation dimension m, parameter dimension d\n    m_dim, d_dim = 5, 3\n\n    # Forward model matrix H\n    H = np.array([\n        [1.0, 0.5, 0.0],\n        [0.0, 1.0, 0.5],\n        [0.2, 0.0, 1.0],\n        [1.0, -0.5, 0.25],\n        [0.0, 0.0, 1.0]\n    ])\n\n    # Observation vector y\n    y_obs = np.array([0.475, 0.025, 0.85, 0.9125, 0.675])\n\n    # Observation noise standard deviations and inverse variance for Mahalanobis distance\n    sigma_obs = np.array([0.1, 0.1, 0.1, 0.2, 0.15])\n    gamma_inv_diag = 1.0 / sigma_obs**2\n\n    # --- Helper Functions ---\n    def calculate_misfit(theta):\n        \"\"\"Calculates the squared Mahalanobis misfit S(theta).\"\"\"\n        residual = H @ theta - y_obs\n        return np.sum((residual**2) * gamma_inv_diag)\n\n    def run_mcmc(N, theta0, sigma_prop):\n        \"\"\"Runs the Random-Walk Metropolis MCMC sampler.\"\"\"\n        chain = np.zeros((N, d_dim))\n        misfits = np.zeros(N)\n\n        chain[0] = theta0\n        current_misfit = calculate_misfit(theta0)\n        misfits[0] = current_misfit\n\n        for j in range(N - 1):\n            proposal_theta = chain[j] + np.random.normal(0, sigma_prop, size=d_dim)\n            proposal_misfit = calculate_misfit(proposal_theta)\n            \n            # Acceptance probability on the log-scale to avoid potential overflow/underflow\n            log_acceptance_prob = -0.5 * (proposal_misfit - current_misfit)\n            \n            if np.log(np.random.uniform(0, 1)) < log_acceptance_prob:\n                chain[j + 1] = proposal_theta\n                current_misfit = proposal_misfit\n            else:\n                chain[j + 1] = chain[j]\n            \n            misfits[j + 1] = current_misfit\n        \n        return misfits\n\n    def calculate_burn_in(misfits, N, W, alpha, epsilon):\n        \"\"\"Determines the burn-in index b based on the KL divergence diagnostic.\"\"\"\n        q_low = chi2.ppf((1.0 - alpha) / 2.0, df=m_dim)\n        q_high = chi2.ppf(1.0 - (1.0 - alpha) / 2.0, df=m_dim)\n        \n        num_windows = N - W + 1\n        if num_windows <= 0:\n            return N\n\n        divergences = np.zeros(num_windows)\n        p_alpha = np.array([alpha, 1.0 - alpha])\n\n        for t in range(num_windows):\n            window = misfits[t : t + W]\n            f_t = np.mean((window >= q_low) & (window <= q_high))\n            p_t = np.array([f_t, 1.0 - f_t])\n            # rel_entr(p, q) computes p*log(p/q), sum is the KL divergence\n            divergences[t] = np.sum(rel_entr(p_t, p_alpha))\n\n        # We need the smallest t such that for all t' >= t, D_KL = epsilon.\n        # This is equivalent to finding the last t where D_KL > epsilon and adding 1.\n        # For a robust implementation, we check from the end of the chain.\n        is_good_from_here = np.zeros(num_windows, dtype=bool)\n        if num_windows > 0:\n            is_good_from_here[-1] = (divergences[-1] = epsilon)\n            for t in range(num_windows - 2, -1, -1):\n                is_good_from_here[t] = (divergences[t] = epsilon) and is_good_from_here[t + 1]\n        \n        good_starts = np.where(is_good_from_here)[0]\n        if len(good_starts) == 0:\n            return N  # Convention if no such index exists\n        else:\n            return good_starts[0]\n\n    def calculate_iact(misfits, b, N):\n        \"\"\"Estimates the Integrated Autocorrelation Time (IACT).\"\"\"\n        if b = N:\n            return 0 # Per problem spec\n\n        stat_misfits = misfits[b:]\n        if len(stat_misfits)  2:\n            return 1 # Cannot compute ACF, assume independence\n\n        x = stat_misfits - np.mean(stat_misfits)\n        autocov = np.correlate(x, x, mode='full')[len(x) - 1:]\n        \n        if autocov[0] == 0: # Variance is zero, all samples are identical\n            return 1\n\n        acf = autocov / autocov[0]\n        \n        # Initial positive sequence estimator for IACT\n        iact = 1.0\n        for k in range(1, len(acf)):\n            if acf[k]  0:\n                iact += 2.0 * acf[k]\n            else:\n                break\n        \n        return math.ceil(iact)\n    \n    # --- Test Cases ---\n    test_cases = [\n        # Case 1: well-tuned chain\n        {'N': 4000, 'sigma_prop': 0.35, 'theta0': np.array([0.0, 0.0, 0.0]),\n         'alpha': 0.9, 'W': 400, 'epsilon': 0.02},\n        # Case 2: long transient\n        {'N': 4000, 'sigma_prop': 0.35, 'theta0': np.array([5.0, -5.0, 5.0]),\n         'alpha': 0.9, 'W': 400, 'epsilon': 0.02},\n        # Case 3: very poor mixing\n        {'N': 4000, 'sigma_prop': 2.5, 'theta0': np.array([5.0, -5.0, 5.0]),\n         'alpha': 0.9, 'W': 400, 'epsilon': 0.02},\n    ]\n\n    results = []\n    for case in test_cases:\n        N = case['N']\n        theta0 = case['theta0']\n        sigma_prop = case['sigma_prop']\n        W = case['W']\n        alpha = case['alpha']\n        epsilon = case['epsilon']\n        \n        # 1. Generate the MCMC chain and get the misfit sequence\n        misfits = run_mcmc(N, theta0, sigma_prop)\n        \n        # 2. Compute the burn-in index\n        burn_in_index = calculate_burn_in(misfits, N, W, alpha, epsilon)\n        \n        # 3. Compute the thinning interval recommendation\n        thinning_interval = calculate_iact(misfits, burn_in_index, N)\n        \n        results.append([burn_in_index, thinning_interval])\n\n    # Format the final output as specified\n    print(str(results).replace(\" \", \"\"))\n\nsolve()\n\n```", "id": "3370155"}, {"introduction": "稀疏被广泛用于降低样本自相关性，但它对估计器统计效率的影响是一个更复杂的问题，有时甚至会起反作用。本练习旨在对稀疏的利弊进行直接的实证研究，这是一个关键的实践考量。通过比较从稀疏和未稀疏的马尔可夫链计算出的后验均值估计器的方差和置信区间宽度，您将对稀疏是否真正改善最终结果获得一个关键的、数据驱动的视角 [@problem_id:3370133]。", "problem": "给定一个标量线性高斯逆问题、一个保留后验的合成马尔可夫链蒙特卡罗（MCMC）采样器，以及一个要求：使用批均值在两种策略（仅使用老化期，以及老化期后进行稀疏化）下估计后验均值的不确定性。您的任务是编写一个程序，模拟马尔可夫链，计算后验均值估计量的批均值（BM）方差估计，基于学生t分布构建双侧置信区间，并比较有无稀疏化处理的区间宽度。\n\n从以下基本原理和定义开始。\n\n1.  线性高斯逆问题。假设一个一维未知数 $x$，其先验为 $x \\sim \\mathcal{N}(0,\\tau^2)$，一个线性正向算子 $h \\in \\mathbb{R}$，以及单个观测值 $y \\in \\mathbb{R}$，其加性噪声为 $\\varepsilon \\sim \\mathcal{N}(0,r^2)$，因此 $y = h x + \\varepsilon$。根据高斯共轭的贝叶斯法则，后验 $p(x \\mid y)$ 是高斯分布，其均值 $m$ 和方差 $s^2$ 由下式给出：\n    $$\n    s^2 = \\left(\\tau^{-2} + h^2 r^{-2}\\right)^{-1}, \\quad m = s^2 \\cdot h r^{-2} y.\n    $$\n\n2.  具有指定自相关的合成MCMC。考虑由下式定义的一阶自回归（AR(1)）过程：\n    $$\n    X_{t+1} = m + \\rho \\left(X_t - m\\right) + \\sqrt{\\left(1-\\rho^2\\right) s^2}\\, Z_t,\n    $$\n    其中 $\\{Z_t\\}$ 是独立同分布的标准正态随机变量，$\\rho \\in (-1,1)$ 是滞后-1自相关系数。该链是高斯的，其平稳分布为 $\\mathcal{N}(m,s^2)$。\n\n3.  老化期和稀疏化。给定一个模拟路径 $\\{X_t\\}_{t=1}^T$：\n    -   老化期（Burn-in）舍弃前 $B$ 个状态以减少初始化偏差，得到长度为 $n = T - B$ 的保留序列 $\\{X_{B+1},\\dots,X_T\\}$。\n    -   以因子 $k \\in \\mathbb{N}$ 进行稀疏化（Thinning），即保留序列中每隔 $k$ 个元素取一个，得到 $\\{X_{B+1}, X_{B+1+k}, X_{B+1+2k}, \\dots\\}$，其长度为 $n_{\\mathrm{thin}} = \\left\\lfloor \\frac{n}{k} \\right\\rfloor$。\n\n4.  用于马尔可夫链中心极限定理的批均值方差估计。令 $g(x) = x$ 为恒等函数，这样目标就是估计 $\\mu = \\mathbb{E}_{\\pi}[g(X)] = m$。假设马尔可夫链中心极限定理（CLT）成立：设 $Y_t = g(X_t)$，\n    $$\n    \\sqrt{n}\\left(\\bar{Y}_n - \\mu\\right) \\xrightarrow{d} \\mathcal{N}(0,\\sigma^2),\n    $$\n    其中 $\\bar{Y}_n = \\frac{1}{n} \\sum_{t=1}^n Y_t$，$\\sigma^2$ 是渐近方差。批均值估计量将 $Y_1,\\dots,Y_n$ 分为 $b$ 个不重叠的批次，每批大小为 $a$，因此 $n = a b$。设批均值为 $\\bar{Y}^{(i)} = \\frac{1}{a} \\sum_{t=(i-1)a+1}^{ia} Y_t$，其中 $i \\in \\{1,\\dots,b\\}$，$\\bar{Y}$ 是总均值。渐近方差的估计量为\n    $$\n    \\hat{\\sigma}^2_{\\mathrm{BM}} = a \\cdot \\frac{1}{b-1} \\sum_{i=1}^b \\left(\\bar{Y}^{(i)} - \\bar{Y}\\right)^2,\n    $$\n    因此 $\\mathrm{Var}(\\bar{Y}_n)$ 的估计量为\n    $$\n    \\widehat{\\mathrm{Var}}(\\bar{Y}_n) = \\frac{\\hat{\\sigma}^2_{\\mathrm{BM}}}{n}.\n    $$\n    在名义水平 $1-\\alpha$ 下，$\\mu$ 的双侧置信区间为\n    $$\n    \\bar{Y}_n \\pm t_{1-\\alpha/2,\\,b-1} \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)},\n    $$\n    其中 $t_{1-\\alpha/2,\\,b-1}$ 是具有 $b-1$ 个自由度的学生t分布的分位数。因此，置信区间的宽度为\n    $$\n    W = 2 \\, t_{1-\\alpha/2,\\,b-1} \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)}.\n    $$\n\n您的程序必须为每个测试用例实现以下步骤：\n\na. 使用给定的 $(h,\\tau^2,r^2,y)$ 计算后验均值 $m$ 和方差 $s^2$。\n\nb. 使用参数 $\\rho$ 模拟长度为 $T$ 的AR(1)链，以 $X_1 = m + \\delta$ 初始化，其中 $\\delta$ 是一个指定的偏移量（所有情况都使用相同的 $\\delta$），并使用独立的标准正态新息。\n\nc. 通过舍弃前 $B$ 个样本来应用老化期。对于未稀疏化的路径，使用恰好 $b$ 个批次和相应的批大小 $a = n/b$ 来计算批均值方差估计 $\\widehat{\\mathrm{Var}}(\\bar{Y}_n)$（假设参数确保在必要时截断多余样本后，整除是精确的）。构建水平为 $1-\\alpha$ 的双侧置信区间，并记录其宽度 $W_{\\mathrm{nt}}$。\n\nd. 对老化期后的路径应用因子为 $k$ 的稀疏化，使用相同的 $b$ 个批次（批大小为 $a_{\\mathrm{thin}} = n_{\\mathrm{thin}}/b$）计算批均值方差估计 $\\widehat{\\mathrm{Var}}(\\bar{Y}_{n_{\\mathrm{thin}}})$，构建置信区间，并记录其宽度 $W_{\\mathrm{th}}$。\n\ne. 对于每个测试用例，输出一个元组，包含无稀疏化的均值估计方差、有稀疏化的均值估计方差、无稀疏化的置信区间宽度 $W_{\\mathrm{nt}}$、有稀疏化的置信区间宽度 $W_{\\mathrm{th}}$，以及一个指示 $W_{\\mathrm{th}}  W_{\\mathrm{nt}}$ 是否为真的布尔值。\n\n数值和格式要求：\n\n-   使用 $\\alpha = 0.05$，即名义水平 $1-\\alpha = 0.95$。\n-   在每个测试用例中，对未稀疏化和稀疏化分析使用相同的批次数 $b$。\n-   使用初始偏移量 $\\delta = 10.0$。\n-   将所有浮点输出四舍五入到 $6$ 位小数。\n-   您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表，其中每个元素本身都是 $[\\widehat{\\mathrm{Var}}(\\bar{Y}_n), \\widehat{\\mathrm{Var}}(\\bar{Y}_{n_{\\mathrm{thin}}}), W_{\\mathrm{nt}}, W_{\\mathrm{th}}, \\text{boolean}]$ 形式的列表。输出中不包含任何空格。\n\n测试套件：\n\n为以下三个测试用例提供结果；每个用例由 $(h,\\tau^2,r^2,y,\\rho,T,B,b,k,\\text{seed})$ 定义。\n\n-   用例 1（中等自相关，中等稀疏化）：$(h=\\;1.0,\\;\\tau^2=\\;1.0,\\;r^2=\\;1.0,\\;y=\\;1.5,\\;\\rho=\\;0.5,\\;T=\\;50500,\\;B=\\;500,\\;b=\\;50,\\;k=\\;5,\\;\\text{seed}=\\;12345)$。\n\n-   用例 2（独立同分布，较强稀疏化）：$(h=\\;2.0,\\;\\tau^2=\\;1.0,\\;r^2=\\;4.0,\\;y=\\;-1.0,\\;\\rho=\\;0.0,\\;T=\\;50500,\\;B=\\;500,\\;b=\\;50,\\;k=\\;10,\\;\\text{seed}=\\;23456)$。\n\n-   用例 3（强自相关，积极稀疏化）：$(h=\\;1.0,\\;\\tau^2=\\;4.0,\\;r^2=\\;1.0,\\;y=\\;0.0,\\;\\rho=\\;0.99,\\;T=\\;200500,\\;B=\\;500,\\;b=\\;50,\\;k=\\;100,\\;\\text{seed}=\\;34567)$。\n\n最终输出格式：\n\n-   您的程序应生成单行输出，包含一个含有三个元素的列表，每个元素对应一个测试用例，格式完全如下：\n    $[[v_{1,\\mathrm{nt}},v_{1,\\mathrm{th}},w_{1,\\mathrm{nt}},w_{1,\\mathrm{th}},\\mathrm{bool}_1],[v_{2,\\mathrm{nt}},v_{2,\\mathrm{th}},w_{2,\\mathrm{nt}},w_{2,\\mathrm{th}},\\mathrm{bool}_2],[v_{3,\\mathrm{nt}},v_{3,\\mathrm{th}},w_{3,\\mathrm{nt}},w_{3,\\mathrm{th}},\\mathrm{bool}_3]]$，\n    其中 $v_{i,\\mathrm{nt}} = \\widehat{\\mathrm{Var}}(\\bar{Y}_n)$ 为用例 $i$ 的值，$v_{i,\\mathrm{th}} = \\widehat{\\mathrm{Var}}(\\bar{Y}_{n_{\\mathrm{thin}}})$ 为用例 $i$ 的值，$w_{i,\\mathrm{nt}} = W_{\\mathrm{nt}}$ 为用例 $i$ 的值，$w_{i,\\mathrm{th}} = W_{\\mathrm{th}}$ 为用例 $i$ 的值，$\\mathrm{bool}_i$ 是一个布尔值，表示在用例 $i$ 中 $W_{\\mathrm{th}}  W_{\\mathrm{nt}}$ 是否成立。所有浮点数必须四舍五入到 $6$ 位小数。打印行中不允许有空格。", "solution": "此问题被评估为有效。其前提在科学上是合理的，定义在数学和算法上是精确的，所有必要的数据都已提供，任务也阐述得很清楚。\n\n### **问题验证**\n\n#### **第一步：提取已知信息**\n\n**1. 线性高斯逆问题：**\n- 未知数：$x$，先验为 $x \\sim \\mathcal{N}(0,\\tau^2)$。\n- 正向算子：$h \\in \\mathbb{R}$。\n- 观测值：$y \\in \\mathbb{R}$，模型为 $y = h x + \\varepsilon$，其中 $\\varepsilon \\sim \\mathcal{N}(0,r^2)$。\n- 后验 $p(x \\mid y)$ 是 $\\mathcal{N}(m,s^2)$，其中：\n  $$s^2 = \\left(\\tau^{-2} + h^2 r^{-2}\\right)^{-1}$$\n  $$m = s^2 \\cdot h r^{-2} y$$\n\n**2. 合成 MCMC 采样器：**\n- AR(1) 过程：$X_{t+1} = m + \\rho \\left(X_t - m\\right) + \\sqrt{\\left(1-\\rho^2\\right) s^2}\\, Z_t$。\n- $\\{Z_t\\}$ 是独立同分布的 $\\mathcal{N}(0,1)$。\n- 自相关：$\\rho \\in (-1,1)$。\n- 平稳分布：$\\mathcal{N}(m,s^2)$。\n\n**3. 老化期与稀疏化：**\n- 总样本数：$T$。\n- 老化期长度：$B$。保留序列 $\\{X_{B+1},\\dots,X_T\\}$ 的长度为 $n = T-B$。\n- 稀疏化因子：$k \\in \\mathbb{N}$。稀疏化后序列的长度为 $n_{\\mathrm{thin}} = \\left\\lfloor \\frac{n}{k} \\right\\rfloor$。\n\n**4. 批均值方差估计：**\n- 估计量：$\\mu = \\mathbb{E}_{\\pi}[g(X)]$，其中 $g(x)=x$，因此 $\\mu=m$。\n- 设 $\\{Y_t\\}$ 为 MCMC 链（老化期后）。\n- 将 $\\{Y_1,\\dots,Y_n\\}$ 分成大小为 $a$ 的 $b$ 个批次（$n=ab$）。\n- 批均值：$\\bar{Y}^{(i)} = \\frac{1}{a} \\sum_{t=(i-1)a+1}^{ia} Y_t$。\n- 总均值：$\\bar{Y}$。\n- 渐近方差估计量：$\\hat{\\sigma}^2_{\\mathrm{BM}} = a \\cdot \\frac{1}{b-1} \\sum_{i=1}^b \\left(\\bar{Y}^{(i)} - \\bar{Y}\\right)^2$。\n- $\\mathrm{Var}(\\bar{Y}_n)$ 的估计量：$\\widehat{\\mathrm{Var}}(\\bar{Y}_n) = \\frac{\\hat{\\sigma}^2_{\\mathrm{BM}}}{n}$。\n- $\\mu$ 的 $(1-\\alpha)$ 置信区间：$\\bar{Y}_n \\pm t_{1-\\alpha/2,\\,b-1} \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)}$。\n- 置信区间宽度：$W = 2 \\, t_{1-\\alpha/2,\\,b-1} \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)}$。\n\n**5. 数值和任务参数：**\n- 置信水平：$1-\\alpha = 0.95$ ($\\alpha = 0.05$)。\n- 批次数：$b$（未稀疏化和稀疏化时相同）。\n- 初始偏移量：$\\delta = 10.0$，从真实均值 $m$ 算起。\n- 四舍五入：浮点输出保留 $6$ 位小数。\n\n**6. 测试用例：**\n- 用例 1: $(h=1.0,\\;\\tau^2=1.0,\\;r^2=1.0,\\;y=1.5,\\;\\rho=0.5,\\;T=50500,\\;B=500,\\;b=50,\\;k=5,\\;\\text{seed}=12345)$。\n- 用例 2: $(h=2.0,\\;\\tau^2=1.0,\\;r^2=4.0,\\;y=-1.0,\\;\\rho=0.0,\\;T=50500,\\;B=500,\\;b=50,\\;k=10,\\;\\text{seed}=23456)$。\n- 用例 3: $(h=1.0,\\;\\tau^2=4.0,\\;r^2=1.0,\\;y=0.0,\\;\\rho=0.99,\\;T=200500,\\;B=500,\\;b=50,\\;k=100,\\;\\text{seed}=34567)$。\n\n#### **第二步：使用提取的已知信息进行验证**\n\n该问题是一个定义明确的统计模拟和分析计算练习。\n- **科学基础**：该问题建立在贝叶斯推断（高斯共轭）、时间序列分析（AR(1)过程）和 MCMC 诊断（批均值方差估计）等基本原理之上。所有提供的公式都是标准且正确的。\n- **良构性**：为每个测试用例提供了完整的参数集。模拟和计算的指令清晰明确。使用固定的随机种子确保模拟是可复现的，从而得到唯一的解。样本大小、批次和稀疏化的参数选择得当，使得批大小是精确的整数，避免了实现中的歧义。\n- **客观性**：问题使用精确的数学符号和算法步骤进行描述，没有任何主观性语言。\n\n该问题没有表现出任何与科学不合理、不完整、矛盾或歧义相关的缺陷。在逆问题和数据同化领域，这是一个可形式化且相关的任务。\n\n#### **第三步：结论与行动**\n\n此问题是**有效**的。将提供完整的解决方案。\n\n### **基于原理的解决方案**\n\n目标是比较一个线性高斯逆问题中参数后验均值的不确定性估计，这些估计来源于一个合成 MCMC 链。比较在两种策略之间进行：一种只使用老化期，另一种使用老化期后进行稀疏化。不确定性通过置信区间的宽度来量化，该宽度使用批均值方法计算。以下步骤详细说明了每个测试用例的处理过程。\n\n**a. 后验表征**\n首先，我们表征后验分布 $p(x \\mid y)$。问题指出，对于高斯先验 $x \\sim \\mathcal{N}(0,\\tau^2)$ 和源自模型 $y = h x + \\varepsilon$（其中 $\\varepsilon \\sim \\mathcal{N}(0,r^2)$）的高斯似然，后验分布也是高斯的，$p(x \\mid y) \\sim \\mathcal{N}(m, s^2)$。我们应用提供的后验均值 $m$ 和方差 $s^2$ 的公式，这些公式是共轭高斯分布贝叶斯法则的直接结果。\n$$s^2 = \\left(\\tau^{-2} + h^2 r^{-2}\\right)^{-1}$$\n$$m = s^2 \\cdot h r^{-2} y$$\n\n**b. MCMC 模拟**\n接下来，我们模拟一个以该后验分布 $\\mathcal{N}(m,s^2)$ 为其平稳分布的马尔可夫链。问题指定为此使用高斯 AR(1) 过程。链的演化由下式给出：\n$$X_{t+1} = m + \\rho \\left(X_t - m\\right) + \\sqrt{\\left(1-\\rho^2\\right) s^2}\\, Z_t$$\n其中 $\\{Z_t\\}$ 是一个独立同分布的标准正态随机变量序列。这个过程被设计成具有平稳均值 $m$、平稳方差 $s^2$ 和滞后-1自相关 $\\rho$。我们在 $X_1 = m + \\delta$ 处初始化链，以模拟从远离平稳分布处开始的情况，这是实践中的常见场景。模拟总共运行 $T$ 步。使用特定的随机种子以确保可复现性。\n\n**c. 无稀疏化分析（仅老化期）**\nMCMC 链的初始部分可能受到起始值的影响。为减轻此影响，我们舍弃前 $B$ 个样本（“老化期”）。余下的长度为 $n = T-B$ 的序列用于分析。\n目标是估计样本均值 $\\bar{Y}_n = \\frac{1}{n} \\sum_{t=B+1}^T X_t$ 的方差。因为样本 $X_t$ 是相关的，简单的方差公式 $\\mathrm{Var}(X)/n$ 是不正确的。批均值方法通过将 $n$ 个样本分组为 $b$ 个大小为 $a=n/b$ 的大批次来解决这个问题。计算每个批次的均值。如果批次大小 $a$ 足够大，批次均值近似不相关。\n然后我们应用批均值公式计算渐近方差，$\\hat{\\sigma}^2_{\\mathrm{BM}} = a \\cdot \\mathrm{Var}(\\{\\text{批均值}\\})$，其中批均值的方差使用 $b-1$ 个自由度计算。然后，总样本均值的方差估计为 $\\widehat{\\mathrm{Var}}(\\bar{Y}_n) = \\hat{\\sigma}^2_{\\mathrm{BM}}/n$。\n最后，构建真实均值 $m$ 的 $(1-\\alpha)$ 置信区间。根据 MCMC 中心极限定理，$(\\bar{Y}_n - m)/\\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)}$ 的分布近似于具有 $b-1$ 个自由度的学生t分布。该置信区间的宽度为 $W_{\\mathrm{nt}} = 2 \\cdot t_{1-\\alpha/2, b-1} \\cdot \\sqrt{\\widehat{\\mathrm{Var}}(\\bar{Y}_n)}$。\n\n**d. 带稀疏化分析**\n稀疏化是一种技术，即只保留老化期后链的每第 $k$ 个样本。这将数据集的大小减小到 $n_{\\mathrm{thin}} = \\lfloor n/k \\rfloor$ 个样本，但也减小了它们之间的自相关。对稀疏化链的处理过程与未稀疏化情况类似。我们将 $n_{\\mathrm{thin}}$ 个样本分成 $b$ 个大小为 $a_{\\mathrm{thin}} = n_{\\mathrm{thin}}/b$ 的批次。批均值方差估计 $\\widehat{\\mathrm{Var}}(\\bar{Y}_{n_{\\mathrm{thin}}})$ 和相应的置信区间宽度 $W_{\\mathrm{th}}$ 使用与之前相同的公式计算，但应用于稀疏化数据。批次数 $b$ 以及 t 分布的自由度保持不变。\n\n**e. 比较与输出**\n对于每个测试用例，我们计算并存储五个值：未稀疏化链的均值估计方差 $\\widehat{\\mathrm{Var}}(\\bar{Y}_n)$；稀疏化链的相同值 $\\widehat{\\mathrm{Var}}(\\bar{Y}_{n_{\\mathrm{thin}}})$；它们各自的置信区间宽度 $W_{\\mathrm{nt}}$ 和 $W_{\\mathrm{th}}$；以及一个布尔标志，指示稀疏化是否导致了更宽的置信区间（$W_{\\mathrm{th}}  W_{\\mathrm{nt}}$）。稀疏化减少了样本数量，这倾向于增加均值估计量的方差。然而，通过减少自相关，它可能改善批均值方法的性能，特别是如果原始批次大小不足以确保批次均值的近似独立性。最终的比较揭示了对于给定参数，这些相互竞争的因素的净效应。最终的数值结果四舍五入到六位小数并按指定格式输出。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import t as t_dist\n\ndef solve():\n    \"\"\"\n    Main function to run the MCMC analysis for all test cases and format the output.\n    \"\"\"\n    test_cases = [\n        # (h, tau_sq, r_sq, y, rho, T, B, b, k, seed)\n        (1.0, 1.0, 1.0, 1.5, 0.5, 50500, 500, 50, 5, 12345),\n        (2.0, 1.0, 4.0, -1.0, 0.0, 50500, 500, 50, 10, 23456),\n        (1.0, 4.0, 1.0, 0.0, 0.99, 200500, 500, 50, 100, 34567),\n    ]\n\n    # Global parameters\n    delta = 10.0\n    alpha = 0.05\n    \n    results = []\n    for case in test_cases:\n        result_tuple = process_case(case, delta, alpha)\n        results.append(result_tuple)\n\n    # Format the final output string as per requirements\n    case_strings = []\n    for v_nt, v_th, w_nt, w_th, is_wider in results:\n        # Format floats to 6 decimal places and boolean to lowercase string\n        s = f\"[{v_nt:.6f},{v_th:.6f},{w_nt:.6f},{w_th:.6f},{str(is_wider).lower()}]\"\n        case_strings.append(s)\n    \n    final_output = f\"[{','.join(case_strings)}]\"\n    print(final_output)\n\ndef process_case(case, delta, alpha):\n    \"\"\"\n    Processes a single test case for MCMC simulation and analysis.\n    \"\"\"\n    h, tau_sq, r_sq, y, rho, T, B, b, k, seed = case\n    \n    # Step a: Compute posterior mean m and variance s^2\n    s_sq = 1.0 / (1.0/tau_sq + h**2 / r_sq)\n    m = s_sq * h * y / r_sq\n\n    # Step b: Simulate the AR(1) chain\n    rng = np.random.default_rng(seed)\n    X = np.zeros(T)\n    X[0] = m + delta  # Initialize with offset\n    \n    noise_std = np.sqrt((1 - rho**2) * s_sq)\n    \n    for t in range(T - 1):\n        Z_t = rng.standard_normal()\n        X[t+1] = m + rho * (X[t] - m) + noise_std * Z_t\n        \n    # Apply burn-in\n    Y_retained = X[B:]\n    n = T - B\n\n    # --- Analysis for non-thinned chain ---\n    if n % b != 0:\n        # As per problem statement, parameters are chosen to make this exact.\n        # This block is for robustness, but won't be entered for the given cases.\n        n_used_nt = (n // b) * b\n        Y_nt = Y_retained[:n_used_nt]\n    else:\n        Y_nt = Y_retained\n    \n    n_nt = len(Y_nt)\n    a_nt = n_nt // b\n    \n    batch_means_nt = np.mean(Y_nt.reshape(b, a_nt), axis=1)\n    \n    # Batch means variance estimation\n    sigma_sq_bm_hat_nt = a_nt * np.var(batch_means_nt, ddof=1)\n    var_mean_hat_nt = sigma_sq_bm_hat_nt / n_nt\n    \n    # Confidence interval calculation\n    t_quantile = t_dist.ppf(1 - alpha / 2, df=b-1)\n    width_nt = 2 * t_quantile * np.sqrt(var_mean_hat_nt)\n\n    # --- Analysis for thinned chain ---\n    Y_th = Y_retained[::k]\n    n_th = len(Y_th)\n    \n    if n_th % b != 0:\n        # As per problem statement, parameters are chosen to make this exact.\n        n_used_th = (n_th // b) * b\n        Y_th = Y_th[:n_used_th]\n\n    n_th = len(Y_th) # update length after potential truncation\n    a_th = n_th // b\n    \n    batch_means_th = np.mean(Y_th.reshape(b, a_th), axis=1)\n    \n    # Batch means variance estimation\n    sigma_sq_bm_hat_th = a_th * np.var(batch_means_th, ddof=1)\n    var_mean_hat_th = sigma_sq_bm_hat_th / n_th\n    \n    # Confidence interval calculation (t_quantile is the same)\n    width_th = 2 * t_quantile * np.sqrt(var_mean_hat_th)\n    \n    # Step e: Consolidate and return results\n    is_wider = width_th  width_nt\n    \n    return (var_mean_hat_nt, var_mean_hat_th, width_nt, width_th, is_wider)\n\nsolve()\n```", "id": "3370133"}]}