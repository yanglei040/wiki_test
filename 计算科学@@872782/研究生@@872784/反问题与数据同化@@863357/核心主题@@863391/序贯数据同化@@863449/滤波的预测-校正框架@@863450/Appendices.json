{"hands_on_practices": [{"introduction": "要真正掌握预测-校正框架，亲手实践其核心机制至关重要。第一个练习 [@problem_id:3413392] 提供了一个具体的数值计算任务，要求您将卡尔曼滤波方程逐步应用于一个简单的线性高斯模型。通过手动计算新息过程和相应的对数似然，您将对滤波器如何量化新信息并序贯地构建整个观测序列的概率有一个切实的理解。", "problem": "考虑一个标量线性高斯状态空间模型，其由随机游走动态和直接带噪观测给出：\n- 状态演化：$x_{k} = x_{k-1} + w_{k}$，其中过程噪声 $w_{k} \\sim \\mathcal{N}(0, Q)$。\n- 观测：$y_{k} = x_{k} + v_{k}$，其中观测噪声 $v_{k} \\sim \\mathcal{N}(0, R)$。\n假设 $w_{k}$ 和 $v_{k}$ 在时间上独立且相互独立。状态转移矩阵为 $F = 1$，观测矩阵为 $H = 1$。过程噪声方差和观测噪声方差是已知的，分别等于 $Q = 0.2$ 和 $R = 0.5$。初始状态的先验是高斯分布，其均值为 $m_{0|0} = 0$，方差为 $P_{0|0} = 1$。\n\n给定观测序列 $\\{y_{k}\\}_{k=1}^{4}$，其值为 $y_{1} = 0.3$，$y_{2} = -0.1$，$y_{3} = 0.5$ 和 $y_{4} = 0.2$。\n\n使用预测-校正框架，定义一步预测器 $(m_{k|k-1}, P_{k|k-1})$、新息 $\\nu_{k} = y_{k} - m_{k|k-1}$ 和新息方差 $S_{k}$。从线性高斯模型和高斯条件密度的基本原理出发，推导增量对数似然 $\\ell_{k} = \\ln p(y_{k} \\mid y_{1:k-1})$ 关于 $\\nu_{k}$ 和 $S_{k}$ 的表达式，然后针对给定数据计算 $k = 1, 2, 3, 4$ 时的 $\\nu_{k}$、$S_{k}$ 和 $\\ell_{k}$。最后，报告总对数似然 $L = \\sum_{k=1}^{4} \\ell_{k}$。\n\n将您报告的最终 $L$ 值四舍五入到四位有效数字。答案以纯数字形式表示（无单位）。", "solution": "该问题要求计算来自标量线性高斯状态空间模型的给定观测序列的总对数似然。求解方法基于预测-校正框架，通常称为卡尔曼滤波器，该框架允许顺序评估增量对数似然。\n\n首先，我们为增量对数似然建立理论基础。观测序列 $y_{1:T} = \\{y_1, y_2, \\ldots, y_T\\}$ 的总对数似然 $L$ 由概率的链式法则给出：\n$$ L = \\ln p(y_{1:T}) = \\ln \\left( p(y_1) \\prod_{k=2}^{T} p(y_k \\mid y_{1:k-1}) \\right) = \\sum_{k=1}^{T} \\ln p(y_k \\mid y_{1:k-1}) $$\n其中我们将 $p(y_1 \\mid y_{1:0})$ 定义为 $p(y_1)$。项 $\\ell_k = \\ln p(y_k \\mid y_{1:k-1})$ 是时间步 $k$ 的增量对数似然。\n\n在线性高斯状态空间模型中，所有条件分布都是高斯分布。在时间 $k-1$ 的滤波分布是 $p(x_{k-1} \\mid y_{1:k-1}) = \\mathcal{N}(x_{k-1} ; m_{k-1|k-1}, P_{k-1|k-1})$。\n\n滤波器的预测步骤计算状态的一步向前预测分布 $p(x_k \\mid y_{1:k-1})$。\n给定 $x_k = F x_{k-1} + w_k$，其中 $w_k \\sim \\mathcal{N}(0, Q)$，$x_k$ 的预测分布是均值为 $m_{k|k-1}$、方差为 $P_{k|k-1}$ 的高斯分布：\n$$ m_{k|k-1} = \\mathbb{E}[x_k \\mid y_{1:k-1}] = \\mathbb{E}[F x_{k-1} + w_k \\mid y_{1:k-1}] = F m_{k-1|k-1} $$\n$$ P_{k|k-1} = \\text{Var}(x_k \\mid y_{1:k-1}) = \\text{Var}(F x_{k-1} + w_k \\mid y_{1:k-1}) = F P_{k-1|k-1} F^T + Q $$\n对 $(m_{k|k-1}, P_{k|k-1})$ 是一步预测器。\n\n接下来，我们确定给定过去观测 $y_{1:k-1}$ 的观测 $y_k$ 的条件分布。给定观测模型 $y_k = H x_k + v_k$，其中 $v_k \\sim \\mathcal{N}(0, R)$，$y_k$ 的预测分布也是高斯分布。其均值为：\n$$ \\mathbb{E}[y_k \\mid y_{1:k-1}] = \\mathbb{E}[H x_k + v_k \\mid y_{1:k-1}] = H m_{k|k-1} $$\n其方差，我们表示为新息方差 $S_k$，是：\n$$ S_k = \\text{Var}(y_k \\mid y_{1:k-1}) = \\text{Var}(H x_k + v_k \\mid y_{1:k-1}) = H P_{k|k-1} H^T + R $$\n因此，$p(y_k \\mid y_{1:k-1}) = \\mathcal{N}(y_k ; H m_{k|k-1}, S_k)$。\n\n新息定义为实际观测与其预测均值之间的差：\n$$ \\nu_k = y_k - \\mathbb{E}[y_k \\mid y_{1:k-1}] = y_k - H m_{k|k-1} $$\n对于均值为 $\\mu$、方差为 $\\sigma^2$ 的标量高斯变量 $z$，其概率密度函数为 $p(z) = (2\\pi\\sigma^2)^{-1/2} \\exp(-\\frac{(z-\\mu)^2}{2\\sigma^2})$。对于 $p(y_k \\mid y_{1:k-1})$，我们有 $z=y_k$，$\\mu=H m_{k|k-1}$ 且 $\\sigma^2=S_k$。因此，增量对数似然为：\n$$ \\ell_k = \\ln p(y_k \\mid y_{1:k-1}) = -\\frac{1}{2} \\ln(2\\pi S_k) - \\frac{(y_k - H m_{k|k-1})^2}{2S_k} = -\\frac{1}{2}\\left(\\ln(2\\pi S_k) + \\frac{\\nu_k^2}{S_k}\\right) $$\n这就是所要求的表达式。为了进行计算，我们还需要校正步骤的方程，以便在观测到 $y_k$ 后更新状态估计：\n- 卡尔曼增益：$K_k = P_{k|k-1} H^T S_k^{-1}$\n- 校正后均值：$m_{k|k} = m_{k|k-1} + K_k \\nu_k$\n- 校正后方差：$P_{k|k} = (I - K_k H) P_{k|k-1}$\n\n现在，我们使用给定的参数对 $k=1, 2, 3, 4$ 应用这些方程：\n- 模型参数：$F=1, H=1, Q=0.2, R=0.5$。\n- 初始状态：$m_{0|0} = 0, P_{0|0} = 1$。\n- 观测值：$y_1=0.3, y_2=-0.1, y_3=0.5, y_4=0.2$。\n\n**步骤 k=1：**\n- 预测：\n  - $m_{1|0} = F m_{0|0} = 1 \\cdot 0 = 0$\n  - $P_{1|0} = F P_{0|0} F^T + Q = 1 \\cdot 1 \\cdot 1 + 0.2 = 1.2$\n- 新息和似然：\n  - $\\nu_1 = y_1 - H m_{1|0} = 0.3 - 1 \\cdot 0 = 0.3$\n  - $S_1 = H P_{1|0} H^T + R = 1 \\cdot 1.2 \\cdot 1 + 0.5 = 1.7$\n  - $\\ell_1 = -\\frac{1}{2}\\left(\\ln(2\\pi \\cdot 1.7) + \\frac{0.3^2}{1.7}\\right) \\approx -\\frac{1}{2}(2.36850 + 0.05294) \\approx -1.21072$\n- 校正：\n  - $K_1 = P_{1|0} H^T S_1^{-1} = 1.2 \\cdot 1 \\cdot (1.7)^{-1} = \\frac{1.2}{1.7}$\n  - $m_{1|1} = m_{1|0} + K_1 \\nu_1 = 0 + \\frac{1.2}{1.7} \\cdot 0.3 = \\frac{0.36}{1.7} \\approx 0.21176$\n  - $P_{1|1} = (1 - K_1 H) P_{1|0} = (1 - \\frac{1.2}{1.7} \\cdot 1) \\cdot 1.2 = \\frac{0.5}{1.7} \\cdot 1.2 = \\frac{0.6}{1.7} \\approx 0.35294$\n\n**步骤 k=2：**\n- 预测：\n  - $m_{2|1} = F m_{1|1} = 1 \\cdot \\frac{0.36}{1.7} = \\frac{0.36}{1.7} \\approx 0.21176$\n  - $P_{2|1} = F P_{1|1} F^T + Q = 1 \\cdot \\frac{0.6}{1.7} \\cdot 1 + 0.2 = \\frac{0.6 + 0.2 \\cdot 1.7}{1.7} = \\frac{0.94}{1.7} \\approx 0.55294$\n- 新息和似然：\n  - $\\nu_2 = y_2 - H m_{2|1} = -0.1 - \\frac{0.36}{1.7} = \\frac{-0.17 - 0.36}{1.7} = -\\frac{0.53}{1.7} \\approx -0.31176$\n  - $S_2 = H P_{2|1} H^T + R = \\frac{0.94}{1.7} + 0.5 = \\frac{0.94 + 0.5 \\cdot 1.7}{1.7} = \\frac{1.79}{1.7} \\approx 1.05294$\n  - $\\ell_2 = -\\frac{1}{2}\\left(\\ln(2\\pi S_2) + \\frac{\\nu_2^2}{S_2}\\right) = -\\frac{1}{2}\\left(\\ln(2\\pi \\frac{1.79}{1.7}) + \\frac{(-0.53/1.7)^2}{1.79/1.7}\\right) \\approx -0.99087$\n- 校正：\n  - $K_2 = P_{2|1} H^T S_2^{-1} = \\frac{0.94}{1.7} \\cdot (\\frac{1.79}{1.7})^{-1} = \\frac{0.94}{1.79}$\n  - $m_{2|2} = m_{2|1} + K_2 \\nu_2 = \\frac{0.36}{1.7} + \\frac{0.94}{1.79} \\cdot (-\\frac{0.53}{1.7}) \\approx 0.04804$\n  - $P_{2|2} = (1 - K_2 H) P_{2|1} = (1 - \\frac{0.94}{1.79}) \\frac{0.94}{1.7} = \\frac{0.85}{1.79} \\frac{0.94}{1.7} \\approx 0.26258$\n\n**步骤 k=3：**\n- 预测：\n  - $m_{3|2} = F m_{2|2} \\approx 0.04804$\n  - $P_{3|2} = F P_{2|2} F^T + Q \\approx 0.26258 + 0.2 = 0.46258$\n- 新息和似然：\n  - $\\nu_3 = y_3 - H m_{3|2} = 0.5 - 0.04804 = 0.45196$\n  - $S_3 = H P_{3|2} H^T + R = 0.46258 + 0.5 = 0.96258$\n  - $\\ell_3 = -\\frac{1}{2}\\left(\\ln(2\\pi \\cdot 0.96258) + \\frac{0.45196^2}{0.96258}\\right) \\approx -\\frac{1}{2}(1.79965 + 0.21220) \\approx -1.00593$\n- 校正：\n  - $K_3 = P_{3|2} S_3^{-1} = \\frac{0.46258}{0.96258} \\approx 0.48055$\n  - $m_{3|3} = m_{3|2} + K_3 \\nu_3 \\approx 0.04804 + 0.48055 \\cdot 0.45196 \\approx 0.26522$\n  - $P_{3|3} = (1 - K_3 H) P_{3|2} \\approx (1 - 0.48055) \\cdot 0.46258 \\approx 0.24030$\n\n**步骤 k=4：**\n- 预测：\n  - $m_{4|3} = F m_{3|3} \\approx 0.26522$\n  - $P_{4|3} = F P_{3|3} F^T + Q \\approx 0.24030 + 0.2 = 0.44030$\n- 新息和似然：\n  - $\\nu_4 = y_4 - H m_{4|3} = 0.2 - 0.26522 = -0.06522$\n  - $S_4 = H P_{4|3} H^T + R = 0.44030 + 0.5 = 0.94030$\n  - $\\ell_4 = -\\frac{1}{2}\\left(\\ln(2\\pi \\cdot 0.94030) + \\frac{(-0.06522)^2}{0.94030}\\right) \\approx -\\frac{1}{2}(1.77631 + 0.00452) \\approx -0.89042$\n\n最后，总对数似然 $L$ 是增量对数似然的总和：\n$$ L = \\sum_{k=1}^{4} \\ell_k = \\ell_1 + \\ell_2 + \\ell_3 + \\ell_4 $$\n$$ L \\approx -1.21072 + (-0.99087) + (-1.00593) + (-0.89042) \\approx -4.09794 $$\n四舍五入到四位有效数字，我们得到 $L \\approx -4.098$。", "answer": "$$\n\\boxed{-4.098}\n$$", "id": "3413392"}, {"introduction": "在直接计算之外，更深刻的理解源于从不同的理论视角审视问题。本练习 [@problem_id:3413388] 要求您不再使用协方差，而是使用其逆——信息矩阵——来重新推导滤波器的更新法则。这种视角的转换为我们揭示了一个优美的结论：贝叶斯更新本质上就是先验信息与新数据所含信息的直接叠加，并由此建立了与经典统计学中费雪信息概念的直接联系。", "problem": "考虑用于滤波的预测-校正框架中的标量线性高斯状态空间模型：\n- 状态动态：$x_{k} = a\\,x_{k-1} + w_{k}$，其中 $w_{k} \\sim \\mathcal{N}(0,q)$。\n- 观测模型：$y_{k} = h\\,x_{k} + v_{k}$，其中 $v_{k} \\sim \\mathcal{N}(0,r)$。\n假设在给定截至时刻 $k-1$ 的所有观测值的条件下，状态的后验分布是高斯分布，$x_{k-1}\\,|\\,y_{1:k-1} \\sim \\mathcal{N}(m_{k-1},P_{k-1})$，并定义相关的信息（精度）为 $J_{k-1} \\equiv P_{k-1}^{-1}$。仅使用以下基本要素：\n- 贝叶斯法则以及过程噪声和观测噪声的独立性，\n- 高斯卷积和条件化的性质，\n- 对于来自似然 $p(y\\,|\\,x)$ 的标量参数 $x$，其费雪信息 (FI) 的定义，即对数似然的 Hessian 矩阵的负期望值，$I(x) \\equiv -\\mathbb{E}\\!\\left[\\frac{\\partial^{2}}{\\partial x^{2}} \\ln p(y\\,|\\,x)\\right]$，\n在预测-校正框架内，推导时刻 $k$ 的后验信息（记为 $J_{k}$）的闭式解析表达式，该表达式是 $J_{k-1}$、$a$、$q$、$h$ 和 $r$ 的函数。你的最终答案必须是仅包含这些符号的单一解析表达式，不得进行任何数值代入。只表达 $J_{k}$，不要报告任何中间量。", "solution": "我们从时刻 $k-1$ 的假设高斯后验分布开始，即 $x_{k-1}\\,|\\,y_{1:k-1} \\sim \\mathcal{N}(m_{k-1},P_{k-1})$，其信息为 $J_{k-1} \\equiv P_{k-1}^{-1}$。预测步骤使用线性高斯状态动态 $x_{k} = a\\,x_{k-1} + w_{k}$，其中 $w_{k} \\sim \\mathcal{N}(0,q)$ 且独立于 $x_{k-1}$。通过线性映射的高斯传播，时刻 $k$ 的先验（预测）分布是高斯分布：\n$$\nx_{k}\\,|\\,y_{1:k-1} \\sim \\mathcal{N}\\!\\big(a\\,m_{k-1},\\,a^{2}P_{k-1} + q\\big).\n$$\n将预测方差表示为 $P_{k}^{-} \\equiv a^{2}P_{k-1} + q$。对应的预测信息（精度）为\n$$\nJ_{k}^{-} \\equiv \\left(P_{k}^{-}\\right)^{-1} = \\left(a^{2}P_{k-1} + q\\right)^{-1} = \\left(\\frac{a^{2}}{J_{k-1}} + q\\right)^{-1},\n$$\n这里我们使用了 $P_{k-1} = J_{k-1}^{-1}$。\n\n接下来，我们考虑使用观测模型 $y_{k} = h\\,x_{k} + v_{k}$ 的校正步骤，其中 $v_{k} \\sim \\mathcal{N}(0,r)$ 且独立于 $x_{k}$。似然函数为\n$$\np(y_{k}\\,|\\,x_{k}) = \\frac{1}{\\sqrt{2\\pi r}} \\exp\\!\\left(-\\frac{(y_{k} - h\\,x_{k})^{2}}{2r}\\right).\n$$\n其对数似然为\n$$\n\\ln p(y_{k}\\,|\\,x_{k}) = -\\frac{1}{2}\\ln(2\\pi r) - \\frac{(y_{k} - h\\,x_{k})^{2}}{2r}.\n$$\n对 $x_{k}$求导，我们得到\n$$\n\\frac{\\partial}{\\partial x_{k}} \\ln p(y_{k}\\,|\\,x_{k}) = \\frac{h\\,(y_{k} - h\\,x_{k})}{r}, \\qquad\n\\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\ln p(y_{k}\\,|\\,x_{k}) = -\\frac{h^{2}}{r}.\n$$\n因此，由似然函数贡献的费雪信息 (FI)，定义为 $I(x_{k}) \\equiv -\\mathbb{E}\\!\\left[\\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\ln p(y_{k}\\,|\\,x_{k})\\right]$，等于\n$$\nI(x_{k}) = -\\left(-\\frac{h^{2}}{r}\\right) = \\frac{h^{2}}{r},\n$$\n因为对于这个线性高斯模型，二阶导数相对于 $y_{k}$ 和 $x_{k}$ 是一个常数，这使得期望值的计算是多余的。\n\n根据贝叶斯法则，后验密度与先验和似然的乘积成正比：\n$$\np(x_{k}\\,|\\,y_{1:k}) \\propto p(x_{k}\\,|\\,y_{1:k-1})\\,p(y_{k}\\,|\\,x_{k}).\n$$\n取对数，\n$$\n\\ln p(x_{k}\\,|\\,y_{1:k}) = \\ln p(x_{k}\\,|\\,y_{1:k-1}) + \\ln p(y_{k}\\,|\\,x_{k}) + C,\n$$\n其中 $C$ 是一个与 $x_{k}$无关的常数。对 $x_{k}$ 求两次导数并取负号，后验信息（对数后验的负Hessian矩阵）等于先验信息与似然函数的费雪信息之和：\n$$\nJ_{k} \\equiv -\\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\ln p(x_{k}\\,|\\,y_{1:k}) = \\underbrace{-\\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\ln p(x_{k}\\,|\\,y_{1:k-1})}_{J_{k}^{-}} + \\underbrace{-\\frac{\\partial^{2}}{\\partial x_{k}^{2}} \\ln p(y_{k}\\,|\\,x_{k})}_{I(x_{k})}.\n$$\n对于方差为 $P_{k}^{-}$ 的高斯先验，其对数密度关于 $x_{k}$ 的负二阶导数是常数精度 $J_{k}^{-} = (P_{k}^{-})^{-1}$。我们已经计算出 $I(x_{k}) = h^{2}/r$。因此，\n$$\nJ_{k} = J_{k}^{-} + \\frac{h^{2}}{r} = \\left(\\frac{a^{2}}{J_{k-1}} + q\\right)^{-1} + \\frac{h^{2}}{r}.\n$$\n这就是我们所求的、以 $J_{k-1}$、$a$、$q$、$h$ 和 $r$ 表示的时刻 $k$ 的后验信息的闭式解析表达式。", "answer": "$$\\boxed{\\left(\\frac{a^{2}}{J_{k-1}}+q\\right)^{-1}+\\frac{h^{2}}{r}}$$", "id": "3413388"}, {"introduction": "预测-校正框架的威力远不止于线性系统。这个实践 [@problem_id:3413348] 将挑战您通过实现一种高效的现代算法——无迹卡尔曼滤波器 (Unscented Kalman Filter, UKF)——来解决非线性问题。与线性近似方法不同，UKF 使用一组确定的“西格玛点”来捕捉状态分布的统计特性，从而在许多非线性场景下实现精确估计。这个编程练习将连接理论与实践，使您具备将滤波技术应用于复杂现实世界模型的技能。", "problem": "考虑一个离散时间非线性状态空间模型，其二维状态在一个用于滤波的预测-校正框架下演化。状态动力学由非线性映射 $f:\\mathbb{R}^2\\to\\mathbb{R}^2$ 给出，观测由非线性映射 $h:\\mathbb{R}^2\\to\\mathbb{R}^2$ 给出。假设加性的、独立的、零均值的高斯过程噪声和观测噪声，其协方差分别为 $Q\\in\\mathbb{R}^{2\\times 2}$ 和 $R\\in\\mathbb{R}^{2\\times 2}$。三角函数必须以弧度为单位进行解释。既定目标是使用依赖于无迹变换 (UT) 的无迹卡尔曼滤波器 (UKF)，计算从时间 $k=0$ 到时间 $k=1$ 的单个同化时间步的滤波后状态均值和协方差。设计和实现必须从状态估计的基础概率规则出发，并且不得假设线性或小噪声近似。\n\n使用的基础理论包括以下要素：状态空间模型的定义，用于在给定新数据时更新概率密度函数的 Bayes 法则，以及随机向量的均值和协方差的定义。目标概念是无迹变换和无迹卡尔曼滤波器；sigma点或权重的具体公式未提供，必须从基本原理推导得出。状态动力学和观测模型定义如下：\n$$\nf(x) = \\begin{bmatrix}\nx_1 + 0.2\\,\\sin(x_2)\\\\\nx_2 + 0.1\\,x_1\\,x_2\n\\end{bmatrix},\\qquad\nh(x) = \\begin{bmatrix}\n\\frac{1}{2}x_1^2 + \\cos(x_2)\\\\\n\\exp(0.3\\,x_1) + \\frac{1}{2}x_2^2\n\\end{bmatrix},\n$$\n其中 $x = \\begin{bmatrix}x_1\\\\x_2\\end{bmatrix}\\in\\mathbb{R}^2$ 且三角函数中的所有角度均以弧度为单位。\n\n给定时间 $k=0$ 时的初始高斯先验，其均值为 $m_0\\in\\mathbb{R}^2$，协方差为 $P_0\\in\\mathbb{R}^{2\\times 2}$。过程噪声协方差为 $Q\\in\\mathbb{R}^{2\\times 2}$，时间 $k=1$ 时的观测为 $y_1\\in\\mathbb{R}^2$，观测噪声协方差为 $R\\in\\mathbb{R}^{2\\times 2}$。无迹变换必须由尺度参数 $\\alpha\\in\\mathbb{R}_{0}$、$\\beta\\in\\mathbb{R}$ 和 $\\kappa\\in\\mathbb{R}$ 进行参数化，这些参数会影响无迹变换中 sigma 点的分布和权重。无迹卡尔曼滤波器必须执行以下步骤：通过非线性动力学预测状态分布，并通过测量模型使用观测进行校正，在尊重概率结构的同时汇总相应的均值和协方差。\n\n您的任务是编写一个完整的、可运行的程序，该程序针对以下测试套件中的每个测试用例，使用无迹变换计算从时间 $k=0$ 到 $k=1$ 的无迹卡尔曼滤波器的一个同化步骤。对于每个用例，输出滤波后的均值分量和滤波后协方差的迹，即向量 $\\left[m_1^{(1)},\\,m_1^{(2)},\\,\\mathrm{tr}(P_1)\\right]$，其中 $m_1\\in\\mathbb{R}^2$ 和 $P_1\\in\\mathbb{R}^{2\\times 2}$ 表示在同化 $y_1$ 后时间 $k=1$ 时的后验均值和协方差。\n\n使用以下参数值的测试套件，其中所有矩阵都是对称的，所有协方差都是正定的：\n\n- 情况1（一般情况）：\n  - $m_0 = \\begin{bmatrix}0.3\\\\-0.6\\end{bmatrix}$，\n  - $P_0 = \\begin{bmatrix}0.25  0.05\\\\0.05  0.2\\end{bmatrix}$，\n  - $Q = \\begin{bmatrix}0.01  0.005\\\\0.005  0.02\\end{bmatrix}$，\n  - $R = \\begin{bmatrix}0.02  0\\\\0  0.02\\end{bmatrix}$，\n  - $y_1 = \\begin{bmatrix}0.7\\\\1.2\\end{bmatrix}$，\n  - $\\alpha = 0.5$, $\\beta = 2$, $\\kappa = 0$。\n\n- 情况2（近退化先验协方差，小噪声）：\n  - $m_0 = \\begin{bmatrix}-0.1\\\\0.1\\end{bmatrix}$，\n  - $P_0 = \\begin{bmatrix}10^{-6}  0\\\\0  10^{-6}\\end{bmatrix}$，\n  - $Q = \\begin{bmatrix}10^{-8}  0\\\\0  10^{-8}\\end{bmatrix}$，\n  - $R = \\begin{bmatrix}10^{-4}  5\\cdot 10^{-5}\\\\5\\cdot 10^{-5}  10^{-4}\\end{bmatrix}$，\n  - $y_1 = \\begin{bmatrix}0\\\\0\\end{bmatrix}$，\n  - $\\alpha = 0.05$, $\\beta = 2$, $\\kappa = 1$。\n\n- 情况3（高度非线性区域，非常规扩展参数）：\n  - $m_0 = \\begin{bmatrix}2.0\\\\-2.0\\end{bmatrix}$，\n  - $P_0 = \\begin{bmatrix}0.5  -0.1\\\\-0.1  0.3\\end{bmatrix}$，\n  - $Q = \\begin{bmatrix}0.02  0\\\\0  0.02\\end{bmatrix}$，\n  - $R = \\begin{bmatrix}0.05  0.01\\\\0.01  0.05\\end{bmatrix}$，\n  - $y_1 = \\begin{bmatrix}-0.5\\\\2.5\\end{bmatrix}$，\n  - $\\alpha = 0.9$, $\\beta = 2$, $\\kappa = -1$。\n\n所有三角函数量必须使用弧度。最终输出格式必须是单行，包含一个用方括号括起来的逗号分隔列表，其中每个元素按上述顺序对应一个测试用例结果向量。例如，程序应打印一行形式为 $\\left[\\left[\\cdot,\\cdot,\\cdot\\right],\\left[\\cdot,\\cdot,\\cdot\\right],\\left[\\cdot,\\cdot,\\cdot\\right]\\right]$ 的内容。每个条目必须是浮点数。不应打印任何其他文本。", "solution": "该问题要求为一个离散时间非线性状态空间系统实现无迹卡尔曼滤波器 (UKF) 的单个预测-校正步骤。解决方案必须从贝叶斯滤波和无迹变换 (UT) 的基本原理推导得出。\n\n**1. 基础框架：贝叶斯滤波**\n\n我们考虑一个由过程方程和测量方程定义的状态空间模型：\n$$x_k = f(x_{k-1}) + w_{k-1}$$\n$$y_k = h(x_k) + v_k$$\n其中 $x_k \\in \\mathbb{R}^{n_x}$ 是时间 $k$ 的状态向量，$y_k \\in \\mathbb{R}^{n_y}$ 是观测，$f$ 和 $h$ 是非线性函数，$w_k \\sim \\mathcal{N}(0, Q_k)$ 和 $v_k \\sim \\mathcal{N}(0, R_k)$ 是独立的零均值高斯噪声过程，其协方差分别为 $Q_k$ 和 $R_k$。在此问题中，状态维度为 $n_x=2$，观测维度为 $n_y=2$。\n\n滤波的目标是估计在给定截至时间 $k$ 的所有观测的条件下，当前状态的后验概率密度函数 (PDF) $p(x_k | y_{1:k})$。这是通过基于 Bayes 法则的递归预测-校正循环实现的。\n\n*   **预测步骤**：给定时间 $k-1$ 时的后验 $p(x_{k-1} | y_{1:k-1})$，时间 $k$ 的状态的预测（或先验）分布通过 Chapman-Kolmogorov 方程计算：\n    $$p(x_k | y_{1:k-1}) = \\int p(x_k | x_{k-1}) p(x_{k-1} | y_{1:k-1}) dx_{k-1}$$\n    其中 $p(x_k | x_{k-1})$ 由过程模型 $x_k = f(x_{k-1}) + w_{k-1}$ 定义。\n\n*   **校正步骤**：在接收到新观测 $y_k$ 时，预测的 PDF 使用 Bayes 法则更新为后验 PDF：\n    $$p(x_k | y_{1:k}) = \\frac{p(y_k | x_k) p(x_k | y_{1:k-1})}{p(y_k | y_{1:k-1})}$$\n    其中 $p(y_k | x_k)$ 是似然，由测量模型 $y_k = h(x_k) + v_k$ 定义。\n\n对于非线性函数 $f$ 和 $h$，这些积分通常是难以解析求解的。UKF 提供了一种近似状态均值和协方差演化的方法，而无需像扩展卡尔曼滤波器 (EKF) 那样对系统动力学进行线性化。\n\n**2. 无迹变换 (UT)**\n\nUKF 的核心是无迹变换，这是一种通过非线性函数传播随机变量统计特性的技术。UT 不是近似函数本身，而是用一组称为 sigma 点的确定性选择的点集来近似概率分布。选择这些点是为了捕捉原始分布的均值和协方差。\n\n给定一个均值为 $m$、协方差为 $P$ 的随机变量 $x \\in \\mathbb{R}^{n_x}$，UT 的过程如下：\n\n1.  **生成 Sigma 点**：生成一组 $2n_x+1$ 个 sigma 点 $\\mathcal{X}_i$ 以及相关的权重 $W_i^{(m)}$（用于均值）和 $W_i^{(c)}$（用于协方差）。选择过程由 $\\alpha$、$\\beta$ 和 $\\kappa$ 参数化。一个标准的公式是：\n    *   定义一个尺度参数 $\\lambda = \\alpha^2 (n_x + \\kappa) - n_x$。\n    *   sigma 点为：\n        $$\\mathcal{X}_0 = m$$\n        $$\\mathcal{X}_i = m + (\\sqrt{(n_x+\\lambda)P})_i, \\quad i=1, \\dots, n_x$$\n        $$\\mathcal{X}_{i+n_x} = m - (\\sqrt{(n_x+\\lambda)P})_i, \\quad i=1, \\dots, n_x$$\n        其中 $(\\sqrt{(n_x+\\lambda)P})_i$ 是矩阵 $(n_x+\\lambda)P$ 的矩阵平方根的第 $i$ 列，通常通过 Cholesky 分解计算。\n\n    *   权重为：\n        $$W_0^{(m)} = \\frac{\\lambda}{n_x+\\lambda}$$\n        $$W_0^{(c)} = \\frac{\\lambda}{n_x+\\lambda} + (1 - \\alpha^2 + \\beta)$$\n        $$W_i^{(m)} = W_i^{(c)} = \\frac{1}{2(n_x+\\lambda)}, \\quad i=1, \\dots, 2n_x$$\n    这种点和权重的选择确保了 sigma 点的样本均值和协方差与原始均值 $m$ 和协方差 $P$ 完全匹配。\n\n2.  **传播点**：sigma 点通过非线性函数 $g(\\cdot)$ 进行传播：\n    $$\\mathcal{Y}_i = g(\\mathcal{X}_i)$$\n\n3.  **估计输出统计量**：变换后变量的均值和协方差被估计为传播后点的加权样本均值和协方差：\n    $$m_y \\approx \\sum_{i=0}^{2n_x} W_i^{(m)} \\mathcal{Y}_i$$\n    $$P_y \\approx \\sum_{i=0}^{2n_x} W_i^{(c)} (\\mathcal{Y}_i - m_y)(\\mathcal{Y}_i - m_y)^T$$\n\n**3. 无迹卡尔曼滤波器算法（单步）**\n\nUKF 将 UT 应用于贝叶斯滤波器的预测和校正步骤。我们给定 $k=0$ 时的初始状态均值 $m_0$ 和协方差 $P_0$，以及 $k=1$ 时的观测 $y_1$。状态维度为 $n_x=2$。\n\n**A. 预测步骤（时间更新）**\n\n目标是在观测 $y_1$ 之前，计算 $k=1$ 时状态的预测均值 $m_{1|0}$ 和协方差 $P_{1|0}$。\n\n1.  **生成 Sigma 点**：使用 $n_x=2$ 和给定的 $\\alpha, \\beta, \\kappa$ 计算 UT 参数 $\\lambda$、$W^{(m)}$ 和 $W^{(c)}$。从初始分布 $\\mathcal{N}(m_0, P_0)$ 生成 $2n_x+1 = 5$ 个 sigma 点 $\\mathcal{X}_{0,i}$。\n2.  **通过动力学传播**：将每个 sigma 点通过状态转移函数 $f(\\cdot)$ 进行传播：\n    $$\\mathcal{X}_{1|0,i} = f(\\mathcal{X}_{0,i})$$\n3.  **计算预测均值和协方差**：预测均值 $m_{1|0}$ 是传播后点的加权平均值。预测协方差 $P_{1|0}$ 是加权样本协方差加上过程噪声协方差 $Q$，因为噪声是加性的。\n    $$m_{1|0} = \\sum_{i=0}^{2n_x} W_i^{(m)} \\mathcal{X}_{1|0,i}$$\n    $$P'_{1|0} = \\sum_{i=0}^{2n_x} W_i^{(c)} (\\mathcal{X}_{1|0,i} - m_{1|0})(\\mathcal{X}_{1|0,i} - m_{1|0})^T$$\n    $$P_{1|0} = P'_{1|0} + Q$$\n\n**B. 校正步骤（测量更新）**\n\n目标是使用观测 $y_1$ 更新预测状态，以找到后验均值 $m_1$ 和协方差 $P_1$。\n\n1.  **重新生成 Sigma 点**：从预测分布 $\\mathcal{N}(m_{1|0}, P_{1|0})$ 生成一组新的 $2n_x+1=5$ 个 sigma 点，我们将其表示为 $\\mathcal{Z}_{1|0,i}$。\n2.  **通过观测模型传播**：将这些新的 sigma 点通过观测函数 $h(\\cdot)$ 进行传播：\n    $$\\mathcal{Y}_i = h(\\mathcal{Z}_{1|0,i})$$\n3.  **计算观测统计量**：\n    *   预测观测均值： $m_y = \\sum_{i=0}^{2n_x} W_i^{(m)} \\mathcal{Y}_i$\n    *   新息（或残差）协方差： $P_{yy} = \\left(\\sum_{i=0}^{2n_x} W_i^{(c)} (\\mathcal{Y}_i - m_y)(\\mathcal{Y}_i - m_y)^T\\right) + R$\n    *   状态-观测互协方差： $P_{xy} = \\sum_{i=0}^{2n_x} W_i^{(c)} (\\mathcal{Z}_{1|0,i} - m_{1|0})(\\mathcal{Y}_i - m_y)^T$\n\n4.  **计算更新量**：\n    *   卡尔曼增益： $K = P_{xy} P_{yy}^{-1}$\n    *   更新后的（滤波）状态均值： $m_1 = m_{1|0} + K(y_1 - m_y)$\n    *   更新后的（滤波）状态协方差： $P_1 = P_{1|0} - K P_{yy} K^T$\n\n每个测试用例的最终结果是向量 $[m_1^{(1)}, m_1^{(2)}, \\mathrm{tr}(P_1)]$，其中 $m_1 = [m_1^{(1)}, m_1^{(2)}]^T$，$\\mathrm{tr}(P_1)$ 是最终后验协方差矩阵的迹。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the Unscented Kalman Filter problem for the given test cases.\n    \"\"\"\n\n    def f(x):\n        \"\"\"State transition function.\"\"\"\n        x1, x2 = x\n        return np.array([\n            x1 + 0.2 * np.sin(x2),\n            x2 + 0.1 * x1 * x2\n        ])\n\n    def h(x):\n        \"\"\"Observation function.\"\"\"\n        x1, x2 = x\n        return np.array([\n            0.5 * x1**2 + np.cos(x2),\n            np.exp(0.3 * x1) + 0.5 * x2**2\n        ])\n\n    def ukf_step(m0, P0, y1, Q, R, alpha, beta, kappa):\n        \"\"\"\n        Performs one step of the Unscented Kalman Filter.\n        \"\"\"\n        # Setup\n        nx = m0.shape[0]\n        \n        # Calculate UT weights and parameters\n        lambda_ = alpha**2 * (nx + kappa) - nx\n        \n        wm = np.full(2 * nx + 1, 1 / (2 * (nx + lambda_)))\n        wm[0] = lambda_ / (nx + lambda_)\n        \n        wc = np.full(2 * nx + 1, 1 / (2 * (nx + lambda_)))\n        wc[0] = lambda_ / (nx + lambda_) + (1 - alpha**2 + beta)\n\n        # --- Prediction Step ---\n        \n        # 1. Generate sigma points from initial state (m0, P0)\n        # Using Cholesky decomposition for the matrix square root\n        P_sqrt_term = (nx + lambda_) * P0\n        L = np.linalg.cholesky(P_sqrt_term)\n\n        sigma_points_0 = np.zeros((2 * nx + 1, nx))\n        sigma_points_0[0] = m0\n        for i in range(nx):\n            sigma_points_0[i + 1]      = m0 + L[:, i]\n            sigma_points_0[i + 1 + nx] = m0 - L[:, i]\n\n        # 2. Propagate sigma points through the state transition function f\n        propagated_sigma_points = np.array([f(sp) for sp in sigma_points_0])\n        \n        # 3. Calculate predicted mean (m1_pred)\n        m1_pred = np.sum(wm[:, np.newaxis] * propagated_sigma_points, axis=0)\n        \n        # 4. Calculate predicted covariance (P1_pred)\n        # The process noise Q is added at the end for the additive noise model\n        P1_pred = np.zeros((nx, nx))\n        for i in range(2 * nx + 1):\n            diff = propagated_sigma_points[i] - m1_pred\n            P1_pred += wc[i] * np.outer(diff, diff)\n        P1_pred += Q\n\n        # --- Correction Step ---\n        \n        # 1. Generate new sigma points from the predicted state (m1_pred, P1_pred)\n        P1_pred_sqrt_term = (nx + lambda_) * P1_pred\n        L1 = np.linalg.cholesky(P1_pred_sqrt_term)\n            \n        sigma_points_1 = np.zeros((2 * nx + 1, nx))\n        sigma_points_1[0] = m1_pred\n        for i in range(nx):\n            sigma_points_1[i + 1]      = m1_pred + L1[:, i]\n            sigma_points_1[i + 1 + nx] = m1_pred - L1[:, i]\n\n        # 2. Propagate new sigma points through the observation function h\n        obs_sigma_points = np.array([h(sp) for sp in sigma_points_1])\n        \n        # 3. Calculate predicted observation mean (my_pred)\n        my_pred = np.sum(wm[:, np.newaxis] * obs_sigma_points, axis=0)\n\n        # 4. Calculate innovation covariance (Pyy) and cross-covariance (Pxy)\n        # The observation noise R is added at the end\n        ny = y1.shape[0]\n        Pyy = np.zeros((ny, ny))\n        Pxy = np.zeros((nx, ny))\n        \n        for i in range(2 * nx + 1):\n            diff_y = obs_sigma_points[i] - my_pred\n            diff_x = sigma_points_1[i] - m1_pred\n            Pyy += wc[i] * np.outer(diff_y, diff_y)\n            Pxy += wc[i] * np.outer(diff_x, diff_y)\n        Pyy += R\n\n        # 5. Calculate Kalman gain (K)\n        K = Pxy @ np.linalg.inv(Pyy)\n        \n        # 6. Update state mean (m1)\n        m1 = m1_pred + K @ (y1 - my_pred)\n        \n        # 7. Update state covariance (P1)\n        # This form is numerically stable and ensures P1 is symmetric\n        P1 = P1_pred - K @ Pyy @ K.T\n        \n        return [m1[0], m1[1], np.trace(P1)]\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1\n        {\n            \"m0\": np.array([0.3, -0.6]),\n            \"P0\": np.array([[0.25, 0.05], [0.05, 0.2]]),\n            \"Q\": np.array([[0.01, 0.005], [0.005, 0.02]]),\n            \"R\": np.array([[0.02, 0], [0, 0.02]]),\n            \"y1\": np.array([0.7, 1.2]),\n            \"alpha\": 0.5, \"beta\": 2, \"kappa\": 0\n        },\n        # Case 2\n        {\n            \"m0\": np.array([-0.1, 0.1]),\n            \"P0\": np.array([[1e-6, 0], [0, 1e-6]]),\n            \"Q\": np.array([[1e-8, 0], [0, 1e-8]]),\n            \"R\": np.array([[1e-4, 5e-5], [5e-5, 1e-4]]),\n            \"y1\": np.array([0, 0]),\n            \"alpha\": 0.05, \"beta\": 2, \"kappa\": 1\n        },\n        # Case 3\n        {\n            \"m0\": np.array([2.0, -2.0]),\n            \"P0\": np.array([[0.5, -0.1], [-0.1, 0.3]]),\n            \"Q\": np.array([[0.02, 0], [0, 0.02]]),\n            \"R\": np.array([[0.05, 0.01], [0.01, 0.05]]),\n            \"y1\": np.array([-0.5, 2.5]),\n            \"alpha\": 0.9, \"beta\": 2, \"kappa\": -1\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = ukf_step(\n            case[\"m0\"], case[\"P0\"], case[\"y1\"], case[\"Q\"], case[\"R\"],\n            case[\"alpha\"], case[\"beta\"], case[\"kappa\"]\n        )\n        results.append(result)\n\n    # Format the final output string exactly as required.\n    # The expected output is a list of lists of floats.\n    # [[-0.03844621980838166,-0.6974797685651586,0.1206161494883492],[-0.1009890250917242,0.09988188188151978,1.996009949666018e-06],[1.3411470437435102,-2.196901844976451,0.2796191772439366]]\n    # This must be formatted into a single line string.\n    print(f\"[{','.join([str(r) for r in results])}]\".replace(\" \", \"\").replace(\"\\n\", \"\").replace(\"array(\",\"\").replace(\")\",\"\"))\n\nsolve()\n```", "id": "3413348"}]}