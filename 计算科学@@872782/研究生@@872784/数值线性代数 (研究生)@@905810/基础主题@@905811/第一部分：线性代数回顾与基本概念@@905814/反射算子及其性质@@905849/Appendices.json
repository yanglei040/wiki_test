{
        "hands_on_practices": [
            {
                "introduction": "理论上，正交变换（如反射变换）能完美保持向量的范数和向量间的欧几里得距离。然而，在计算机上使用有限精度浮点数进行计算时，舍入误差会逐渐累积，导致这些完美的理论性质发生偏移。本练习 [@problem_id:3572839] 旨在通过一个数值实验，量化这种由于有限精度算术引起的数值“漂移”效应，从而帮助我们直观地理解数值稳定性的重要性。",
                "problem": "您需要实现一个在数值线性代数领域的完全可复现的数值实验，以研究反射算子及其在有限精度算术下的行为和性质。该实验必须构建一系列随机正交反射算子的乘积，该乘积在对数据进行置乱的同时，理想情况下应保持欧几里得成对距离不变，然后使用其转置来重构数据以撤销置乱。最后，实验必须量化由浮点误差引入的漂移，这种漂移表现为 $Q^\\top Q$ 与单位矩阵的偏差。\n\n本实验的基本依据是关于欧几里得向量空间和正交变换的一组经过充分检验的定义和事实：\n- 正交矩阵保持向量的欧几里得 $2$-范数和向量间的欧几里得距离不变。\n- 反射算子（Householder变换）是一种正交线性算子，它将一个向量映射到其关于某个与单位方向正交的超平面的反射。\n- 在精确算术中，正交矩阵的乘积仍然是正交的。在浮点算术中，舍入和误差累积可能导致与精确正交性的微小偏差。\n\n您的程序必须：\n1. 生成一个实数矩阵 $X \\in \\mathbb{R}^{n \\times m}$，其各列 $x_i$ 均从标准正态分布中独立抽样，并使用固定的随机种子以保证可复现性。\n2. 构建 $r$ 个随机反射算子并形成它们的乘积 $Q \\in \\mathbb{R}^{n \\times n}$，然后计算置乱后的数据 $Y = Q X$，其中各列为 $y_i = Q x_i$。\n3. 计算以下三个量化指标：\n   - 正交性缺陷：$E_{\\mathrm{orth}} = \\lVert Q^\\top Q - I \\rVert_F$，其中 $\\lVert \\cdot \\rVert_F$ 表示 Frobenius 范数。\n   - 置乱后的最大相对成对距离误差：\n     $$E_{\\mathrm{dist}}^{\\mathrm{scramble}} = \\max_{1 \\le i  j \\le m} \\frac{\\left| \\lVert y_i - y_j \\rVert_2 - \\lVert x_i - x_j \\rVert_2 \\right|}{\\max(\\lVert x_i - x_j \\rVert_2, \\varepsilon)},$$\n     其中 $\\varepsilon$ 是一个小的正常数，取为双精度浮点数的机器ε，以确保分母接近零时的数值稳定性。\n   - 重构漂移：$E_{\\mathrm{recon}} = \\frac{\\lVert Q^\\top (Q X) - X \\rVert_F}{\\lVert X \\rVert_F}$。\n\n4. 对所有随机数生成过程使用固定的随机种子 $123456789$。\n\n5. 以与其作为超平面正交反射的定义相一致的方式，实现反射算子及其乘积的构建。不要依赖预构建的正交化例程；相反，应直接构建反射算子的乘积。\n\n6. 提供一个包含以下参数集 $(n,m,r)$ 的测试套件，这些参数集被选择用于检验各种行为，包括单位矩阵情况、单个和多个反射算子的情况，以及大量反射算子以累积舍入误差的情况：\n   - 测试用例 A: $(n,m,r) = (8,20,0)$。\n   - 测试用例 B: $(n,m,r) = (32,50,32)$。\n   - 测试用例 C: $(n,m,r) = (64,80,320)$。\n   - 测试用例 D: $(n,m,r) = (16,40,1)$。\n\n7. 对于每个测试用例，按顺序计算并返回浮点数三元组 $(E_{\\mathrm{orth}}, E_{\\mathrm{dist}}^{\\mathrm{scramble}}, E_{\\mathrm{recon}})$。\n\n您的程序应生成单行输出，其中包含所有测试用例的结果，形式为用方括号括起来的逗号分隔列表。该列表必须先包含测试A的三个浮点数，然后是测试B的三个浮点数，接着是测试C的三个浮点数，最后是测试D的三个浮点数，并保持所述顺序；也就是说，输出格式必须为\n$[E_{\\mathrm{orth}}^{A}, E_{\\mathrm{dist}}^{\\mathrm{scramble},A}, E_{\\mathrm{recon}}^{A}, E_{\\mathrm{orth}}^{B}, E_{\\mathrm{dist}}^{\\mathrm{scramble},B}, E_{\\mathrm{recon}}^{B}, E_{\\mathrm{orth}}^{C}, E_{\\mathrm{dist}}^{\\mathrm{scramble},C}, E_{\\mathrm{recon}}^{C}, E_{\\mathrm{orth}}^{D}, E_{\\mathrm{dist}}^{\\mathrm{scramble},D}, E_{\\mathrm{recon}}^{D}]$。\n所有值均为无量纲实数，不适用任何物理单位。",
                "solution": "问题陈述是一个有效且适定的线性代数数值实验。它在科学上基于正交变换理论和有限精度算术的实际情况。目标明确，所有必要的参数和定义都已提供，并且整个设置是可复现的。因此，我们可以着手解决。\n\n该实验旨在探究作为 Householder 反射算子乘积构建的正交矩阵的性质。一个 Householder 反射算子，或称 Householder 变换，是一个形如\n$$H = I - 2vv^\\top$$\n的正交矩阵，其中 $v$ 是一个欧几里得范数为 $\\lVert v \\rVert_2 = 1$ 的列向量。从几何上看，$H$ 将向量关于与 $v$ 正交的超平面进行反射。由于 $H$ 是正交的，它满足 $H^\\top H = H H^\\top = I$，并保持欧几里得范数和距离不变，即对于任意向量 $x$，都有 $\\lVert Hx \\rVert_2 = \\lVert x \\rVert_2$。\n\n该实验包含以下关键步骤：\n\n**1. 随机反射算子的生成及其乘积**\n对于要构建的 $r$ 个反射算子中的每一个，我们首先生成一个随机向量 $u \\in \\mathbb{R}^n$，其分量从标准正态分布中抽取。然后将此向量归一化，得到单位向量 $v = u / \\lVert u \\rVert_2$。这个向量 $v$ 定义了第 $k$ 个反射算子 $H_k = I - 2v_k v_k^\\top$，其中 $k \\in \\{1, 2, \\dots, r\\}$。\n总的变换矩阵 $Q$ 是这 $r$ 个反射算子的乘积：\n$$Q = H_r H_{r-1} \\cdots H_1$$\n在精确算术中，正交矩阵的乘积本身也是正交的。因此，理论上 $Q^\\top Q = I$。该数值实验将评估由于浮点误差导致的与此恒等式的偏差。矩阵 $Q$ 是迭代构建的，从单位矩阵 $Q_0 = I$ 开始，按顺序应用每个反射算子：$Q_k = H_k Q_{k-1}$，其中 $k=1, \\dots, r$。最终矩阵为 $Q = Q_r$。对于 $r=0$ 的基本情况，不应用任何变换，$Q$ 保持为单位矩阵 $I$。\n\n**2. 数据生成与变换**\n生成一个数据矩阵 $X \\in \\mathbb{R}^{n \\times m}$，其中 $m$ 个列向量均为从标准正态分布中独立抽样的 $\\mathbb{R}^n$ 向量。使用指定的固定随机种子 $123456789$ 来确保矩阵 $X$ 和随机反射算子的可复现性。然后将变换 $Q$ 应用于数据矩阵，生成“置乱”后的数据 $Y = QX$。\n\n**3. 数值误差的量化**\n计算三个指标来量化有限精度算术的影响：\n\n   - **正交性缺陷, $E_{\\mathrm{orth}}$**：该指标衡量计算出的矩阵 $Q$ 偏离完全正交的程度。它被定义为 $Q^\\top Q$ 与单位矩阵 $I$ 之差的 Frobenius 范数：\n     $$E_{\\mathrm{orth}} = \\lVert Q^\\top Q - I \\rVert_F$$\n     在完美的理论环境中，$E_{\\mathrm{orth}}$ 应为 $0$。非零值是由于在构建 $Q$ 过程中浮点舍入误差的累积所致。\n\n   - **最大相对成对距离误差, $E_{\\mathrm{dist}}^{\\mathrm{scramble}}$**：由于正交变换必须保持欧几里得距离，因此 $X$ 的任意两列 $x_i$ 和 $x_j$ 之间的距离应与 $Y$ 的相应两列 $y_i$ 和 $y_j$ 之间的距离相同。此指标捕获了所有列对的成对距离中的最大相对误差：\n     $$E_{\\mathrm{dist}}^{\\mathrm{scramble}} = \\max_{1 \\le i  j \\le m} \\frac{\\left| \\lVert y_i - y_j \\rVert_2 - \\lVert x_i - x_j \\rVert_2 \\right|}{\\max(\\lVert x_i - x_j \\rVert_2, \\varepsilon)}$$\n     此处，$\\varepsilon$ 是双精度浮点数的机器ε，用于防止分母接近零时出现除零错误。任何非零值都表示与理想距离保持性的偏差。\n\n   - **重构漂移, $E_{\\mathrm{recon}}$**：正交矩阵 $Q$ 的逆是其转置 $Q^\\top$。因此，将 $Q^\\top$ 应用于置乱后的数据 $Y$ 应能重构出原始数据 $X$，即 $Q^\\top Y = Q^\\top(QX) = (Q^\\top Q)X = IX = X$。该指标量化了此重构过程中的相对误差：\n     $$E_{\\mathrm{recon}} = \\frac{\\lVert Q^\\top Y - X \\rVert_F}{\\lVert X \\rVert_F} = \\frac{\\lVert Q^\\top (Q X) - X \\rVert_F}{\\lVert X \\rVert_F}$$\n     此值度量了与完美重构的漂移，并由原始数据的量级进行了归一化。它受到计算出的 $Q$ 的非正交性以及两次连续矩阵-矩阵乘法所带来的误差累积两方面的影响。\n\n实现将通过遍历给定的参数集 $(n,m,r)$ 来进行，对每个参数集执行这些计算步骤，并收集结果三元组 $(E_{\\mathrm{orth}}, E_{\\mathrm{dist}}^{\\mathrm{scramble}}, E_{\\mathrm{recon}})$。对于 $r=0$ 的测试用例，我们预期所有三个误差指标都精确为 $0$，因为 $Q$ 将是单位矩阵，不会有来自变换的浮点误差累积。对于 $r  0$ 的情况，我们预计会出现非零误差，且该误差会随着反射算子数量 $r$ 的增加而增大，因为更多的运算会导致更大的累积误差。",
                "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.spatial.distance import pdist\n\ndef solve():\n    \"\"\"\n    Implements a numerical experiment to study the properties of reflectors\n    under finite-precision arithmetic.\n    \"\"\"\n\n    # Fixed random seed for reproducibility as required by the problem statement.\n    seed = 123456789\n    rng = np.random.default_rng(seed)\n\n    # Machine epsilon for double precision, for numerical stability.\n    epsilon = np.finfo(np.float64).eps\n\n    # Test cases defined by the parameter sets (n, m, r).\n    test_cases = [\n        (8, 20, 0),    # Test case A\n        (32, 50, 32),   # Test case B\n        (64, 80, 320),  # Test case C\n        (16, 40, 1),    # Test case D\n    ]\n\n    results = []\n    for n, m, r in test_cases:\n        # 1. Generate the real data matrix X.\n        X = rng.standard_normal(size=(n, m))\n\n        # 2. Construct the product of r random reflectors, Q.\n        Q = np.identity(n)\n        for _ in range(r):\n            # Generate a random vector u from a standard normal distribution.\n            u = rng.standard_normal(size=(n, 1))\n            \n            # Normalize u to get a unit vector v.\n            norm_u = np.linalg.norm(u)\n            # In the unlikely event norm_u is 0, skip this reflector.\n            if norm_u == 0:\n                continue\n            v = u / norm_u\n            \n            # Construct the Householder reflector H = I - 2*v*v^T.\n            H = np.identity(n) - 2 * (v @ v.T)\n            \n            # Apply the new reflector to the product Q.\n            # Q_new = H_k * Q_old, so Q = H_r * ... * H_1 * I\n            Q = H @ Q\n\n        # Compute the scrambled data Y = QX.\n        Y = Q @ X\n\n        # 3. Compute the three quantitative metrics.\n\n        # Orthogonality defect: E_orth = ||Q^T Q - I||_F\n        e_orth = np.linalg.norm(Q.T @ Q - np.identity(n), 'fro')\n\n        # Maximum relative pairwise-distance error: E_dist\n        if m > 1:\n            # pdist computes pairwise distances between rows. We need it for columns.\n            dists_x = pdist(X.T, metric='euclidean')\n            dists_y = pdist(Y.T, metric='euclidean')\n            \n            abs_diff = np.abs(dists_y - dists_x)\n            denominator = np.maximum(dists_x, epsilon)\n            \n            # Handle the case where all pairwise distances are zero.\n            if np.all(denominator == epsilon):\n                e_dist = 0.0\n            else:\n                rel_errors = abs_diff / denominator\n                e_dist = np.max(rel_errors)\n        else:\n            e_dist = 0.0 # No pairs to compare if m = 1.\n\n        # Reconstruction drift: E_recon = ||Q^T (QX) - X||_F / ||X||_F\n        norm_X_fro = np.linalg.norm(X, 'fro')\n        # norm_X_fro will be non-zero with virtual certainty for the given parameters.\n        if norm_X_fro == 0:\n            e_recon = 0.0\n        else:\n            e_recon = np.linalg.norm(Q.T @ Y - X, 'fro') / norm_X_fro\n\n        results.extend([e_orth, e_dist, e_recon])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```",
                "id": "3572839"
            },
            {
                "introduction": "在观察到数值误差的存在后，我们来深入探究其一个具体的来源：Householder向量构造中的不稳定性。标准的Householder变换公式涉及一个符号选择，该选择对于避免灾难性的舍入误差至关重要。本练习 [@problem_id:3572880] 通过分析一个关键映射在特定点上的连续性，从理论上揭示了不当的符号选择为何会导致算法的不稳定，并量化了其影响。",
                "problem": "设 $n \\ge 2$ 且设 $e_1 \\in \\mathbb{R}^n$ 表示第一个标准基向量。对于任意 $x \\in \\mathbb{R}^n \\setminus \\{0\\}$，定义\n$$\n\\alpha(x) = -\\mathrm{sign}(x_1)\\,\\|x\\|_2, \\quad \\text{约定 } \\mathrm{sign}(0)=1,\n$$\n以及\n$$\nu(x) = \\frac{x - \\alpha(x)\\,e_1}{\\|x - \\alpha(x)\\,e_1\\|_2}.\n$$\n此构造出现在数值线性代数中构造豪斯霍尔德反射（Householder reflector）的过程中。考虑一点 $x_0 \\in \\mathbb{R}^n$，其满足 $x_{0,1} = 0$ 和 $\\|x_0\\|_2 = r  0$。为了探究映射 $x \\mapsto u(x)$ 在超平面 $x_1=0$ 上的可微性，定义单参数曲线\n$$\nx^{+}(t) = x_0 + t\\,e_1, \\quad x^{-}(t) = x_0 - t\\,e_1, \\quad t0,\n$$\n以及对应的像 $u^{+}(t) = u(x^{+}(t))$ 和 $u^{-}(t) = u(x^{-}(t))$。计算跳跃幅度\n$$\nJ \\;=\\; \\lim_{t \\to 0^+} \\big\\|\\,u^{+}(t) - u^{-}(t)\\,\\big\\|_2.\n$$\n报告 $J$ 的值。在你的推导过程中，从欧几里得范数、符号函数和极限的定义出发，并且除了这些之外不要假定任何预先推导的公式。不失一般性，你可以假设 $x_0 = (0, r, 0, \\dots, 0)^{\\top}$。在得到 $J$ 之后，简要解释这对映射 $x \\mapsto u(x)$ 在 $x_1=0$ 的点上的可微性意味着什么，以及这对通过此 $u(x)$ 构造形成豪斯霍尔德反射的算法的稳定性有何影响。最终报告的答案必须是 $J$ 的单一值，不带单位，也不进行四舍五入近似。",
                "solution": "该问题经验证是自洽的，在数值线性代数领域具有科学依据，且提法恰当。我们可以开始求解。\n\n问题要求计算函数 $u(x)$ 在超平面 $x_1=0$ 上的跳跃幅度。设 $n \\ge 2$，$e_1 \\in \\mathbb{R}^n$ 是第一个标准基向量。给定的函数是：\n$$\n\\alpha(x) = -\\mathrm{sign}(x_1)\\,\\|x\\|_2, \\quad \\text{约定 } \\mathrm{sign}(0)=1\n$$\n$$\nu(x) = \\frac{x - \\alpha(x)\\,e_1}{\\|x - \\alpha(x)\\,e_1\\|_2}\n$$\n给定一点 $x_0 \\in \\mathbb{R}^n$，其第一个分量为 $x_{0,1}=0$，其欧几里得范数为 $\\|x_0\\|_2 = r  0$。根据题目说明，我们采用简化形式 $x_0 = (0, r, 0, \\dots, 0)^{\\top}$。\n\n对于 $t0$，接近 $x_0$ 的两条曲线定义如下：\n$$\nx^{+}(t) = x_0 + t\\,e_1 = (t, r, 0, \\dots, 0)^{\\top}\n$$\n$$\nx^{-}(t) = x_0 - t\\,e_1 = (-t, r, 0, \\dots, 0)^{\\top}\n$$\n我们需要计算 $J = \\lim_{t \\to 0^+} \\|u^{+}(t) - u^{-}(t)\\|_2$，其中 $u^{+}(t) = u(x^{+}(t))$ 且 $u^{-}(t) = u(x^{-}(t))$。\n\n首先，我们分析 $u^{+}(t) = u(x^{+}(t))$。\n$x^{+}(t)$ 的第一个分量是 $x^{+}_1(t) = t$。因为 $t  0$，我们有 $\\mathrm{sign}(x^{+}_1(t)) = 1$。\n$x^{+}(t)$ 的欧几里得范数是 $\\|x^{+}(t)\\|_2 = \\sqrt{t^2 + r^2}$。\n因此，$\\alpha(x^{+}(t)) = -\\mathrm{sign}(t) \\|x^{+}(t)\\|_2 = -1 \\cdot \\sqrt{t^2 + r^2} = -\\sqrt{t^2 + r^2}$。\n\n$u^{+}(t)$ 的分子是向量 $v^{+}(t) = x^{+}(t) - \\alpha(x^{+}(t))\\,e_1$：\n$$\nv^{+}(t) = (t, r, 0, \\dots, 0)^{\\top} - (-\\sqrt{t^2+r^2}) (1, 0, \\dots, 0)^{\\top} = (t + \\sqrt{t^2+r^2}, r, 0, \\dots, 0)^{\\top}\n$$\n$u^{+}(t)$ 的分母是范数 $\\|v^{+}(t)\\|_2$。我们计算它的平方：\n$$\n\\|v^{+}(t)\\|_2^2 = (t + \\sqrt{t^2+r^2})^2 + r^2 = t^2 + 2t\\sqrt{t^2+r^2} + (t^2+r^2) + r^2 = 2t^2 + 2r^2 + 2t\\sqrt{t^2+r^2}\n$$\n因式分解此表达式：\n$$\n\\|v^{+}(t)\\|_2^2 = 2(t^2+r^2) + 2t\\sqrt{t^2+r^2} = 2\\sqrt{t^2+r^2}(\\sqrt{t^2+r^2} + t)\n$$\n所以，$u^{+}(t) = \\frac{v^{+}(t)}{\\|v^{+}(t)\\|_2} = \\frac{(t + \\sqrt{t^2+r^2}, r, 0, \\dots, 0)^{\\top}}{\\sqrt{2\\sqrt{t^2+r^2}(\\sqrt{t^2+r^2} + t)}}$。\n\n接下来，我们分析 $u^{-}(t) = u(x^{-}(t))$。\n$x^{-}(t)$ 的第一个分量是 $x^{-}_1(t) = -t$。因为 $t  0$，我们有 $\\mathrm{sign}(x^{-}_1(t)) = -1$。\n$x^{-}(t)$ 的欧几里得范数是 $\\|x^{-}(t)\\|_2 = \\sqrt{(-t)^2 + r^2} = \\sqrt{t^2 + r^2}$。\n因此，$\\alpha(x^{-}(t)) = -\\mathrm{sign}(-t) \\|x^{-}(t)\\|_2 = -(-1) \\sqrt{t^2 + r^2} = \\sqrt{t^2 + r^2}$。\n\n$u^{-}(t)$ 的分子是向量 $v^{-}(t) = x^{-}(t) - \\alpha(x^{-}(t))\\,e_1$：\n$$\nv^{-}(t) = (-t, r, 0, \\dots, 0)^{\\top} - (\\sqrt{t^2+r^2}) (1, 0, \\dots, 0)^{\\top} = (-t - \\sqrt{t^2+r^2}, r, 0, \\dots, 0)^{\\top}\n$$\n$u^{-}(t)$ 的分母是范数 $\\|v^{-}(t)\\|_2$。我们计算它的平方：\n$$\n\\|v^{-}(t)\\|_2^2 = (-t - \\sqrt{t^2+r^2})^2 + r^2 = (t + \\sqrt{t^2+r^2})^2 + r^2 = 2\\sqrt{t^2+r^2}(\\sqrt{t^2+r^2} + t)\n$$\n分母与 $u^{+}(t)$ 的分母相同。令 $D(t) = \\|v^{+}(t)\\|_2 = \\|v^{-}(t)\\|_2$。\n所以，$u^{-}(t) = \\frac{v^{-}(t)}{\\|v^{-}(t)\\|_2} = \\frac{(-t - \\sqrt{t^2+r^2}, r, 0, \\dots, 0)^{\\top}}{D(t)}$。\n\n现在我们计算差向量 $u^{+}(t) - u^{-}(t)$：\n$$\nu^{+}(t) - u^{-}(t) = \\frac{1}{D(t)} [v^{+}(t) - v^{-}(t)]\n$$\n$$\nv^{+}(t) - v^{-}(t) = ( (t + \\sqrt{t^2+r^2}) - (-t - \\sqrt{t^2+r^2}), r-r, 0-0, \\dots)^{\\top} = (2t + 2\\sqrt{t^2+r^2}, 0, \\dots, 0)^{\\top}\n$$\n所以，$u^{+}(t) - u^{-}(t) = \\frac{(2(t + \\sqrt{t^2+r^2}), 0, \\dots, 0)^{\\top}}{D(t)}$。\n\n这个差的范数是：\n$$\n\\|u^{+}(t) - u^{-}(t)\\|_2 = \\frac{\\| (2(t + \\sqrt{t^2+r^2}), 0, \\dots, 0)^{\\top} \\|_2}{D(t)} = \\frac{2(t + \\sqrt{t^2+r^2})}{D(t)}\n$$\n因为 $t0$ 且平方根项为正。\n代入 $D(t) = \\sqrt{2\\sqrt{t^2+r^2}(t + \\sqrt{t^2+r^2})}$ 的表达式：\n$$\n\\|u^{+}(t) - u^{-}(t)\\|_2 = \\frac{2(t + \\sqrt{t^2+r^2})}{\\sqrt{2\\sqrt{t^2+r^2}(t + \\sqrt{t^2+r^2})}} = \\sqrt{\\frac{4(t + \\sqrt{t^2+r^2})^2}{2\\sqrt{t^2+r^2}(t + \\sqrt{t^2+r^2})}}\n$$\n$$\n= \\sqrt{\\frac{2(t + \\sqrt{t^2+r^2})}{\\sqrt{t^2+r^2}}}\n$$\n最后，我们计算当 $t \\to 0^+$ 时的极限，以求得跳跃幅度 $J$：\n$$\nJ = \\lim_{t \\to 0^+} \\sqrt{\\frac{2(t + \\sqrt{t^2+r^2})}{\\sqrt{t^2+r^2}}}\n$$\n由于平方根内的函数在 $t=0$ 处是连续的（给定 $r0$），我们可以代入 $t=0$：\n$$\nJ = \\sqrt{\\frac{2(0 + \\sqrt{0^2+r^2})}{\\sqrt{0^2+r^2}}} = \\sqrt{\\frac{2\\sqrt{r^2}}{\\sqrt{r^2}}}\n$$\n由于 $r  0$，$\\sqrt{r^2}=r$。\n$$\nJ = \\sqrt{\\frac{2r}{r}} = \\sqrt{2}\n$$\n跳跃幅度是 $\\sqrt{2}$。\n\n这个结果对于映射 $x \\mapsto u(x)$ 的可微性以及使用它的算法的稳定性具有重要意义。\n当 $x$ 沿两条路径 $x^+(t)$ 和 $x^-(t)$ 逼近 $x_0$ 时，$u(x)$ 的极限是不同的：\n$$\n\\lim_{t \\to 0^+} u^{+}(t) = \\frac{(r,r,0,\\dots)^\\top}{\\sqrt{2r^2}} = \\frac{1}{\\sqrt{2}}(1,1,0,\\dots)^\\top\n$$\n$$\n\\lim_{t \\to 0^+} u^{-}(t) = \\frac{(-r,r,0,\\dots)^\\top}{\\sqrt{2r^2}} = \\frac{1}{\\sqrt{2}}(-1,1,0,\\dots)^\\top\n$$\n由于极限取决于逼近的路径，函数 $u(x)$ 在任何 $x_{0,1}=0$ 的点 $x_0$ 处都不是连续的。一个函数在不连续的点上是不可微的。因此，映射 $x \\mapsto u(x)$ 在超平面 $x_1=0$ 上是不可微的。\n\n非零的跳跃幅度 $J = \\sqrt{2}$ 量化了这种不连续性。在像豪斯霍尔德QR分解这样的数值算法中，这是一个不稳定的来源。如果一个输入向量 $x$ 的第一个分量 $x_1$ 非常接近 $0$，对 $x$ 的一个小扰动（例如，来自浮点舍入误差）可能会改变 $x_1$ 的符号。这个符号变化导致计算出的向量 $u(x)$ 在两个相距约 $\\sqrt{2}$ 的不同向量之间跳跃。对于 $x$ 的微小变化，$u(x)$ 的这种大的、不连续的变化会降低整个算法的准确性和稳定性。",
                "answer": "$$\\boxed{\\sqrt{2}}$$",
                "id": "3572880"
            },
            {
                "introduction": "在理解了反射变换的性质与潜在的稳定性陷阱之后，我们将这些知识应用于一个复杂且高性能的算法中：分块Hessenberg约化，它是现代特征值求解器的核心步骤。本练习 [@problem_id:3572907] 要求实现这一分块算法，它使用紧凑的 $I - Y T Y^T$ 表示法来聚合多个反射变换，从而将计算密集的部分转化为高效的矩阵-矩阵运算。通过这个实践，你将深入了解高级数值库（如LAPACK）中算法的设计思想与性能优化的权衡。",
                "problem": "给定一个实数方阵 $A \\in \\mathbb{R}^{n \\times n}$，考虑由 Householder 反射变换构建的相似变换。Householder 反射变换是一种形如 $H = I - \\tau v v^\\top$ 的正交矩阵，其中 $v \\in \\mathbb{R}^m$ 是一个非零向量，$\\tau \\in \\mathbb{R}$ 是一个标量，$I$ 表示相应大小的单位矩阵。上 Hessenberg 矩阵是指满足对所有 $i  j + 1$ 都有 $H_{i,j} = 0$ 的矩阵 $H \\in \\mathbb{R}^{n \\times n}$。\n\n您的任务是实现将矩阵 $A$ 通过相似变换 $A \\mapsto Q^\\top A Q$ 约化为上 Hessenberg 形式的分块算法。其中，$Q$ 是一个正交因子，通过使用紧凑表示法将 Householder 反射变换按面板（panel）聚合，从而隐式地表示为这些反射变换的乘积。对于每个面板，聚合应遵循紧凑乘积形式 $Q_{\\text{panel}} = I - Y T Y^\\top$。其中，$Y \\in \\mathbb{R}^{p \\times b}$ 汇集了 $b$ 个 Householder 向量（仅限于面板中的活动行），而 $T \\in \\mathbb{R}^{b \\times b}$ 是一个上三角矩阵，其仅依赖于 Householder 系数和 $Y$ 的各列之间的内积。约化过程通过将列划分为大小为 $b$ 的面板来进行，在面板内立即应用左侧的 Householder 更新，并聚合右侧的更新，以便对相关的后续列每个面板只应用一次。\n\n为了评估面板聚合（分块大小）对瞬时填充（transient fill）的影响，将面板扫描过程中任何中间步骤的次对角线凸起（subdiagonal bulge）幅度定义为矩阵第一条次对角线下方严格下三角部分的 Frobenius 范数，即 $\\operatorname{tril}(M, -2)$ 的 Frobenius 范数，其中 $M$ 是在应用其聚合的右更新之前，处理面板过程中的当前矩阵。对于给定的分块大小 $b$，将面板凸起统计量（panel bulge statistic）定义为在所有面板的所有中间步骤中这些范数的最大值。在完整的分块约化生成上 Hessenberg 矩阵 $H$ 后，对 $H$ 执行单步无移位的正交-三角（QR）分解步骤，以获得 $H_+ = R Q$，其中 $H = Q R$ 是正交-三角分解。定义一个紧缩（deflation）阈值 $\\theta = \\text{reltol} \\cdot \\|H_+\\|_1$，其中 $\\|\\cdot\\|_1$ 是诱导矩阵 $1$-范数。紧缩计数是指满足 $|H_+^{(i+1,i)}| \\le \\theta$ 的次对角线元素 $H_+^{(i+1,i)}$ 的数量，其中 $i \\in \\{1,2,\\ldots,n-1\\}$。\n\n仅从上述核心定义（Householder 反射变换为 $H = I - \\tau v v^\\top$、正交-三角分解和上 Hessenberg 结构）以及一个经过充分检验的事实——即 Householder 反射变换的乘积可以表示为紧凑形式 $I - Y T Y^\\top$（其中 $T$ 是由反射变换递归决定的上三角矩阵）出发，推导出一个有原则的算法，该算法能够：\n- 通过立即应用左 Householder 更新并在每个面板上通过 $I - Y T Y^\\top$ 聚合相应的右更新，计算面板大小为 $b$ 的分块相似变换约化 $A \\mapsto H$ 到上 Hessenberg 形式，\n- 在面板的聚合右更新之前，跟踪中间状态下第一条次对角线下方严格下三角部分的最大 Frobenius 范数（次对角线凸起幅度），\n- 对最终的 $H$ 执行一步无移位的正交-三角（QR）步骤，并计数满足上述紧缩标准的次对角线元素数量。\n\n将该算法实现为一个完整的程序，为以下固定的测试套件生成定量输出。在每个测试用例中，使用相同的实数矩阵 $A \\in \\mathbb{R}^{n \\times n}$，该矩阵由一个固定的种子确定性地生成。使用 $n = 8$，并让 $A$ 由固定的随机种子 $s = 42$ 生成的独立标准正态分布条目填充，以确保测试是可复现的。使用紧缩相对容差 $\\text{reltol} = 10^{-12}$。测试用例改变分块大小 $b$：\n- 测试 1：分块大小 $b = 1$，\n- 测试 2：分块大小 $b = 2$，\n- 测试 3：分块大小 $b = 6$。\n\n对于每个测试用例，您的程序必须输出一个数对 $[\\text{bulge}, \\text{defl}]$，其中 $\\text{bulge}$ 是四舍五入到八位小数的最大次对角线凸起幅度，$\\text{defl}$ 是作为整数的紧缩计数。您的程序应生成单行输出，其中包含三个测试的结果，格式为用方括号括起来的逗号分隔列表，例如 $[[x_1,y_1],[x_2,y_2],[x_3,y_3]]$，其中 $x_k$ 是浮点数，$y_k$ 是整数。不涉及物理单位。不使用角度。不使用百分比；任何比率都必须表示为十进制数。",
                "solution": "## 问题验证\n\n### 步骤 1：提取已知信息\n- **矩阵与变换**：一个实数方阵 $A \\in \\mathbb{R}^{n \\times n}$ 通过相似变换 $A \\mapsto Q^\\top A Q$ 被约化为上 Hessenberg 矩阵 $H$。\n- **矩阵维度**：$n = 8$。\n- **矩阵生成**：$A$ 由使用固定随机种子 $s = 42$ 生成的独立标准正态分布条目填充。\n- **Householder 反射变换**：一种形如 $H = I - \\tau v v^\\top$ 的正交矩阵，其中 $v \\in \\mathbb{R}^m$ 是一个非零向量，$\\tau \\in \\mathbb{R}$ 是一个标量。\n- **上 Hessenberg 形式**：一个矩阵 $H \\in \\mathbb{R}^{n \\times n}$，其满足对所有 $i  j + 1$ 都有 $H_{i,j} = 0$。\n- **分块算法**：约化过程使用具有指定分块大小 $b$ 的分块（面板化）方法执行。\n- **面板聚合**：在每个面板内，反射变换被聚合成一个紧凑乘积形式 $Q_{\\text{panel}} = I - Y T Y^\\top$，其中 $Y$ 汇集了 Householder 向量，$T$ 是一个上三角矩阵。\n- **更新方案**：左 Householder 更新在面板内立即应用。右更新则被聚合起来，每个面板应用一次。\n- **度量 1（次对角线凸起幅度）**：在面板处理过程中的任何中间步骤（即，在一次左更新之后但在面板的聚合右更新之前），凸起是矩阵第一条次对角线下方严格下三角部分的 Frobenius 范数，即 $\\|\\operatorname{tril}(M, -2)\\|_F$。面板凸起统计量是所有中间步骤和所有面板中这些范数的最大值。\n- **度量 2（紧缩计数）**：获得最终的 Hessenberg 矩阵 $H$ 后，执行一步无移位的 QR 步骤：$H = QR$ 后跟 $H_+ = RQ$。紧缩计数是满足 $|H_+^{(i+1,i)}| \\le \\theta$ 的次对角线元素 $|H_+^{(i+1,i)}|$ 的数量，其中阈值为 $\\theta = \\text{reltol} \\cdot \\|H_+\\|_1$。\n- **紧缩容差**：$\\text{reltol} = 10^{-12}$。\n- **测试用例**：算法将针对分块大小 $b \\in \\{1, 2, 6\\}$ 进行测试。\n- **输出格式**：对于每个测试用例，需要一个数对 $[\\text{bulge}, \\text{defl}]$，其中凸起值四舍五入到八位小数。最终输出为单行：`[[bulge1,defl1],[bulge2,defl2],[bulge3,defl3]]`。\n\n### 步骤 2：使用提取的已知信息进行验证\n- **科学基础**：该问题深深植根于数值线性代数，特别是在求解特征值问题的算法背景下。分块 Hessenberg 约化、Householder 反射变换、紧凑 WY 表示（$I - YTY^\\top$）以及 QR 算法都是标准的、成熟的概念。该问题没有违反任何科学或数学原理。\n- **适定性**：任务是实现一个确定性算法。对于给定的输入矩阵 $A$ 和分块大小 $b$，操作序列是唯一确定的，从而得到唯一的 Hessenberg 矩阵 $H$（除了中间反射变换中的符号差异，这不影响最终的相似变换），并因此得到唯一的凸起统计量和紧缩计数值。\n- **客观性**：所有术语和度量都经过了数学上的精确定义。问题中没有主观性语言或基于观点的陈述。\n- **完整性与一致性**：问题陈述是自洽的。它提供了所有必要的参数（$n$、种子 $s$、$\\text{reltol}$）、定义（Householder 反射变换、Hessenberg 形式、凸起、紧缩准则）以及算法约束（分块结构、更新方案），以便进行唯一的实现。这些约束与标准的数值算法一致。\n\n### 步骤 3：结论与行动\n该问题有效。这是一个来自数值线性代数领域的适定、有科学依据且客观的任务。将进行有原则的推导和实现。\n\n## 算法推导与求解\n\n问题的核心是使用正交相似变换 $Q$ 将矩阵 $A$ 约化为上 Hessenberg 形式 $H$，使得 $H = Q^\\top A Q$。如果一个矩阵 $H$ 的第一条次对角线下方所有元素都为零，即对于 $i  j+1$ 有 $H_{i,j}=0$，则称其为上 Hessenberg 矩阵。\n\n变换矩阵 $Q$ 被构造为 Householder 反射变换的乘积。约化过程逐列进行。对于每一列 $j$（从 $0$到 $n-2$），我们在位置 $(j+2, j), \\dots, (n-1, j)$ 引入零。这是通过一个作用于第 $j+1$ 行到第 $n-1$ 行的 Householder 反射变换 $H_j$ 来实现的。Householder 反射变换是一种形如 $H = I - \\tau v v^\\top$ 的矩阵，其中 $v$ 是非零向量，标量 $\\tau = 2/(v^\\top v)$。给定一个向量 $x$，可以构造一个反射变换 $H$ 将 $x$ 变换为第一个标准基向量的倍数，即 $H x = \\alpha e_1$。这是引入零的基本操作。\n\n标准的（非分块的）Hessenberg 约化逐个应用这些反射变换：\n$$A^{(j+1)} = H_j^\\top A^{(j)} H_j = H_j A^{(j)} H_j$$\n因为 $H_j$ 是对称的（$H_j = H_j^\\top$）和正交的（$H_j^\\top H_j = I$）。最终的 Hessenberg 矩阵是 $H = A^{(n-1)}$，变换矩阵是 $Q = H_0 H_1 \\cdots H_{n-2}$。\n\n分块算法旨在通过用更高效的矩阵-矩阵运算替代矩阵-向量运算来提高性能。这是通过将列分组为大小为 $b$ 的“面板”来实现的。对于从 $j_{\\text{start}}$ 到 $j_{\\text{end}}-1$ 的一列面板，该算法的执行方式与非分块版本不同。由反射变换引起的左乘 $H_j A$ 在生成时立即执行。然而，右乘 $A H_j$ 被聚合起来，并对整个面板应用一次。\n\n让我们详细说明从列 $j_{\\text{start}}$ 开始、分块大小为 $b$ 的单个面板的处理过程。令 $j_k = j_{\\text{start}}+k$，其中 $k=0, \\ldots, b-1$。\n此面板的变换为 $Q_{\\text{panel}} = H_{j_0} H_{j_1} \\cdots H_{j_{b-1}}$。矩阵更新如下：\n$$A \\rightarrow (H_{j_{b-1}} \\cdots H_{j_0}) A (H_{j_0} \\cdots H_{j_{b-1}})$$\n分块算法分阶段计算此过程。在面板内，对于 $k=0, \\ldots, b-1$：\n1. 根据矩阵当前第 $j_k$ 列的状态，确定反射变换 $H_{j_k} = I - \\tau_{j_k} v_{j_k} v_{j_k}^\\top$。\n2. 立即应用左更新：$A \\leftarrow H_{j_k} A$。此更新会产生“填充”——在期望的 Hessenberg 结构下方出现非零元素。这种瞬时填充就是“次对角线凸起”。在每个这样的中间步骤，我们测量其幅度 $\\|\\operatorname{tril}(A,-2)\\|_F$。\n3. 反射变换 $H_{j_k}$ 被存储起来，以备后续在聚合的右更新中使用。\n\n面板的所有左更新完成后，矩阵已变换为 $(H_{j_{b-1}} \\cdots H_{j_0}) A$。然后我们必须应用由 $Q_{\\text{panel}} = H_{j_0} \\cdots H_{j_{b-1}}$ 引起的右更新。直接计算 $H_{j_k}$ 矩阵的乘积效率低下。取而代之，我们使用紧凑 WY 表示法，它将反射变换的乘积表示为单个结构化的变换。如问题所述，此形式为 $Q_{\\text{panel}} = I - Y T Y^\\top$。\n- $Y$ 是一个矩阵，其列是 Householder 向量 $v_{j_k}$。\n- $T$ 是一个上三角矩阵，它结合了标量系数 $\\tau_{j_k}$ 和 Householder 向量的内积。\n\n矩阵 $T$ 可以递归地构造。令 $Q_k = H_{j_0} \\cdots H_{j_{k-1}} = I - Y_{k-1} T_{k-1} Y_{k-1}^\\top$。那么，\n$$Q_{k+1} = Q_k H_{j_k} = (I - Y_{k-1} T_{k-1} Y_{k-1}^\\top)(I - \\tau_{j_k} v_{j_k} v_{j_k}^\\top)$$\n展开此乘积并重新整理各项，可得到 $T$ 的更新规则：\n$$T_k = \\begin{pmatrix} T_{k-1}  -\\tau_{j_k} T_{k-1} (Y_{k-1}^\\top v_{j_k}) \\\\ 0  \\tau_{j_k} \\end{pmatrix}$$\n这表明 $T$ 确实是上三角矩阵。在实现中，当我们生成每个向量 $v_{j_k}$ 和标量 $\\tau_{j_k}$ 时，我们可以计算 $T$ 的第 $k$ 列。具体来说，$T_{k,k} = \\tau_{j_k}$，其上方的元素为 $T_{0:k, k} = -\\tau_{j_k} T_{0:k, 0:k} (Y_{:, 0:k}^\\top v_{j_k})$。\n\n一旦面板的 $Y$ 和 $T$ 完全构造好，聚合的右更新就作为 Level-3 BLAS 运算来应用：\n$$A \\leftarrow A Q_{\\text{panel}} = A (I - Y T Y^\\top) = A - (A Y) T Y^\\top$$\n令 $W = AY$。则更新为 $A \\leftarrow A - W T Y^\\top$。这个单一的矩阵-矩阵更新恢复了已处理面板中各列的 Hessenberg 结构，有效地消除了由一系列左更新产生的次对角线凸起。\n\n在遍历所有面板后，矩阵 $A$ 被变换为最终的上 Hessenberg 矩阵 $H$。任务的第二部分涉及分析 $H$。\n我们执行一步无移位的 QR 算法。首先，我们计算 $H$ 的 QR 分解：$H=QR$，其中 $Q$ 是正交的，$R$ 是上三角的。然后，我们颠倒乘法顺序以获得下一个迭代矩阵：$H_+ = RQ$。\n最后，我们计算 $H_+$ 中“可忽略”的次对角线元素的数量，这是一种在特征值算法中检测解耦子问题的启发式方法。如果一个元素 $H_+^{(i+1,i)}$ 的幅度相对于矩阵的整体幅度小于一个阈值 $\\theta$，则认为它是可忽略的。指定的阈值为 $\\theta = \\text{reltol} \\cdot \\|H_+\\|_1$，其中 $\\|H_+\\|_1 = \\max_j \\sum_i |H_+^{(i,j)}|$ 是诱导 1-范数。紧缩计数是满足 $|H_+^{(i+1,i)}| \\le \\theta$ 的索引 $i \\in \\{1,\\ldots,n-1\\}$ 的数量。\n\n实现将针对每个指定的分块大小 $b$ 遵循这个推导出的过程。",
                "answer": "```python\nimport numpy as np\n\ndef hessenberg_reduction_blocked(A_init, b, reltol):\n    \"\"\"\n    Performs blocked Hessenberg reduction on matrix A with block size b.\n\n    Args:\n        A_init (np.ndarray): The initial square matrix.\n        b (int): The block size for panel processing.\n        reltol (float): The relative tolerance for the deflation check.\n\n    Returns:\n        list: A list containing two elements:\n              - The maximum subdiagonal bulge magnitude (float, rounded).\n              - The deflation count after one QR step (int).\n    \"\"\"\n    n = A_init.shape[0]\n    A = A_init.copy()\n    max_bulge = 0.0\n\n    # Main loop over panels, striding by block size b\n    for j_start in range(0, n - 1, b):\n        j_end = min(j_start + b, n - 1)\n        b_panel = j_end - j_start\n\n        if b_panel == 0:\n            continue\n\n        Y = np.zeros((n, b_panel))\n        T = np.zeros((b_panel, b_panel))\n\n        # Inner loop over columns within the panel\n        for k in range(b_panel):\n            j = j_start + k\n\n            # Extract the vector to be modified by the reflector\n            x = A[j+1:, j]\n            m = len(x)\n\n            if m == 0:\n                # No elements to zero, reflector is identity\n                T[k, k] = 0.0\n                # Y is initialized to zeros, so Y[:,k] is zero\n                # No left update, no bulge change from this column\n                bulge = np.linalg.norm(np.tril(A, -2))\n                max_bulge = max(max_bulge, bulge)\n                continue\n\n            # Compute Householder vector u and scalar tau\n            x_norm = np.linalg.norm(x)\n            \n            # Using a small machine epsilon-like tolerance\n            if x_norm > 1e-15:\n                # Standard numerically stable Householder construction\n                sigma = np.copysign(1.0, x[0] if x[0] != 0 else 1.0)\n                u = x.copy()\n                u[0] += sigma * x_norm\n                tau = 2.0 / (u @ u)\n\n                # Store the full Householder vector in Y\n                v = np.zeros(n)\n                v[j+1:] = u\n                Y[:, k] = v\n\n                # Apply immediate left update: A = H_k * A = (I - tau*v*v.T) * A\n                w = tau * (v.T @ A)\n                A -= np.outer(v, w)\n\n                # Explicitly set the zeroed elements to avoid floating point errors\n                A[j+1, j] = -sigma * x_norm\n                if m > 1:\n                    A[j+2:, j] = 0.0\n                \n                # Update T for the compact WY representation\n                T[k, k] = tau\n                if k > 0:\n                    yTv_col = Y[:, :k].T @ v\n                    z_col = T[:k, :k] @ yTv_col\n                    T[:k, k] = -tau * z_col\n            else:\n                # x is already zeroed out, reflector is identity\n                T[k, k] = 0.0\n                # Y[:,k] remains zero\n            \n            # Measure subdiagonal bulge AFTER the left update\n            bulge = np.linalg.norm(np.tril(A, -2))\n            max_bulge = max(max_bulge, bulge)\n\n        # Apply aggregated right update for the panel: A = A * Q_panel\n        # Q_panel = I - Y * T * Y.T\n        W = A @ Y\n        A -= (W @ T) @ Y.T\n\n    H = A\n\n    # Perform one unshifted QR step on the final Hessenberg matrix H\n    if n > 0:\n        Q, R = np.linalg.qr(H)\n        H_plus = R @ Q\n\n        # Calculate deflation count\n        one_norm = np.linalg.norm(H_plus, 1)\n        threshold = reltol * one_norm\n        subdiag = np.diag(H_plus, k=-1)\n        defl_count = np.sum(np.abs(subdiag) = threshold)\n    else:\n        defl_count = 0\n\n    return [round(max_bulge, 8), int(defl_count)]\n\ndef solve():\n    \"\"\"\n    Main function to run the test suite and print results.\n    \"\"\"\n    n = 8\n    seed = 42\n    reltol = 1e-12\n    test_cases = [\n        1,  # block size b = 1\n        2,  # block size b = 2\n        6,  # block size b = 6\n    ]\n\n    # Generate the single test matrix A used for all cases\n    rng = np.random.default_rng(seed)\n    A_init = rng.standard_normal((n, n))\n\n    results = []\n    for b in test_cases:\n        result = hessenberg_reduction_blocked(A_init, b, reltol)\n        results.append(result)\n\n    # Format the output string exactly as specified\n    formatted_results = [f\"[{res[0]:.8f},{res[1]}]\" for res in results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```",
                "id": "3572907"
            }
        ]
    }