{
        "hands_on_practices": [
            {
                "introduction": "第一个实践解决了一个典型的总最小二乘问题：当数据点的 $x$ 和 $y$ 坐标都存在噪声时，如何拟合一条直线。你将从直线的几何定义和正交距离出发，推导出基于奇异值分解（SVD）的求解方法，并实现一个完整的算法。这个练习将让你通过最直观的应用，动手建立对总最小二乘法工作原理的基础理解。[@problem_id:3223301]",
                "problem": "给定若干组离散的平面数据点，其 $x$ 和 $y$ 坐标都受到大小相当的测量误差的影响。您的任务是：使用整体最小二乘法（TLS）来构建对这些数据进行直线拟合的问题，从第一性原理出发推导出一个计算上稳定的方法，并将其实现为一个程序，该程序处理指定的测试集并以精确的格式输出结果。\n\n基本原理与目标。从一条平面直线可以用齐次形式 $a x + b y + c = 0$ 及其归一化约束 $a^{2} + b^{2} = 1$ 书写的几何定义开始。由于归一化，数据点 $(x_{i}, y_{i})$ 到该直线的正交距离由 $\\lvert a x_{i} + b y_{i} + c \\rvert$ 给出。对于双变量均存在误差的直线拟合，整体最小二乘法的目标是寻找能最小化所有数据点到直线正交距离平方和的直线参数，同时满足归一化约束。这是一个离散最小二乘问题，其残差是沿垂直于模型流形的方向而不是沿坐标轴方向测量的。\n\n推导范围与算法要求。基于上述原理，推导约束最小化公式，并利用线性代数将其简化为一种数值稳定的计算方法。您的推导不能以整体最小二乘法或正交回归的特定公式作为起点；相反，必须从正交距离的定义和归一化约束开始，并且只使用广为人知的线性代数工具，如特征值问题或奇异值分解（SVD）。您的最终算法必须：\n- 以齐次形式 $a x + b y + c = 0$ 表示拟合的直线，其中 $a^{2} + b^{2} = 1$。\n- 为确保唯一性，强制采用符号约定：$a \\ge 0$，且若 $a = 0$ 则 $b \\ge 0$。\n- 确保在归一化约束下，使正交残差最小化的拟合直线穿过数据的质心 $(\\bar{x}, \\bar{y})$。\n- 对每个数据集，计算均方根（RMS）正交距离 $r = \\sqrt{\\frac{1}{n} \\sum_{i=1}^{n} (a x_{i} + b y_{i} + c)^{2}}$，其中 $n$ 是点的数量。\n\n测试集。为以下数据集实现您的算法。每个数据集是一个有序对 $(x, y)$ 的列表，所有数字均以十进制形式给出：\n- 案例 $1$（带扰动的一般斜率直线）：$[(0.02, 1.12), (0.51, 1.93), (0.98, 2.92), (1.48, 4.06), (2.02, 5.01), (2.49, 6.07)]$。\n- 案例 $2$（近乎垂直的直线）：$[(2.95, -1.00), (3.02, 0.50), (3.05, 2.00), (2.97, 3.50), (3.01, 5.00)]$。\n- 案例 $3$（原点附近对称的负斜率）：$[(-4.00, 2.10), (-2.00, 1.02), (0.00, -0.02), (2.00, -1.05), (4.00, -1.95)]$。\n- 案例 $4$（两点最小案例）：$[(1.00, 1.00), (3.01, 1.99)]$。\n\n数值与输出要求。\n- 使用齐次直线参数 $(a, b, c)$，满足 $a^{2} + b^{2} = 1$ 及前述的符号约定。\n- 对每个数据集，计算并输出四元组 $[a, b, c, r]$，其中 $r$ 是如上定义的 RMS 正交距离。\n- 将最终输出中报告的每个实数四舍五入到恰好 $6$ 位小数。\n- 最终的程序输出必须是单行，包含四个案例的结果列表，格式完全如下（空格不是必需的，但允许使用）：一个由方括号括起来的、包含四个四元组的逗号分隔列表，例如，$[[a_{1},b_{1},c_{1},r_{1}],[a_{2},b_{2},c_{2},r_{2}],[a_{3},b_{3},c_{3},r_{3}],[a_{4},b_{4},c_{4},r_{4}]]$，其中每个 $a_{k}, b_{k}, c_{k}, r_{k}$ 都四舍五入到 $6$ 位小数。\n- 不涉及角度；不需要物理单位。\n- 程序不得有外部输入；必须能按原样运行并打印出所要求的单行输出。\n\n您的程序应生成单行输出，其中包含一个用方括号括起来的、以逗号分隔的结果列表，每个案例由其自己的列表 $[a, b, c, r]$ 表示，如上所述。例如：$[[a_{1},b_{1},c_{1},r_{1}],[a_{2},b_{2},c_{2},r_{2}],[a_{3},b_{3},c_{3},r_{3}],[a_{4},b_{4},c_{4},r_{4}]]$。",
                "solution": "该问题要求阐述并实现一种整体最小二乘法（TLS），用于对一组双坐标均受误差影响的数据点 $(x_i, y_i)$ 进行直线拟合。推导过程必须从第一性原理开始。\n\n设直线以齐次形式 $a x + b y + c = 0$ 表示。参数 $(a,b)$ 被归一化，使得 $a^2 + b^2 = 1$。在此归一化下，从点 $(x_i, y_i)$ 到该直线的正交距离为 $d_i = |a x_i + b y_i + c|$。TLS 的目标是找到参数 $a, b, c$，以最小化 $n$ 个数据点的正交距离平方和：\n$$ \\text{最小化 } S(a, b, c) = \\sum_{i=1}^{n} (a x_i + b y_i + c)^2 \\quad \\text{约束条件} \\quad g(a, b) = a^2 + b^2 - 1 = 0 $$\n\n为了找到最优参数，我们可以使用微积分。取最小值的必要条件是 $S$ 对 $c$ 的偏导数必须为零：\n$$ \\frac{\\partial S}{\\partial c} = \\sum_{i=1}^{n} 2(a x_i + b y_i + c) \\cdot 1 = 0 $$\n$$ \\implies a \\sum_{i=1}^{n} x_i + b \\sum_{i=1}^{n} y_i + \\sum_{i=1}^{n} c = 0 $$\n$$ \\implies a \\left(\\frac{1}{n}\\sum_{i=1}^{n} x_i\\right) + b \\left(\\frac{1}{n}\\sum_{i=1}^{n} y_i\\right) + c = 0 $$\n令 $\\bar{x} = \\frac{1}{n}\\sum_{i=1}^{n} x_i$ 和 $\\bar{y} = \\frac{1}{n}\\sum_{i=1}^{n} y_i$ 为数据点质心的坐标。该条件变为：\n$$ a \\bar{x} + b \\bar{y} + c = 0 $$\n这表明最优直线必须穿过数据的质心 $(\\bar{x}, \\bar{y})$。这使我们能够用 $a$ 和 $b$ 来表示 $c$：\n$$ c = -(a \\bar{x} + b \\bar{y}) $$\n将 $c$ 的这个表达式代回目标函数 $S$，我们简化了问题：\n$$ S(a, b) = \\sum_{i=1}^{n} (a x_i + b y_i - (a \\bar{x} + b \\bar{y}))^2 = \\sum_{i=1}^{n} (a(x_i - \\bar{x}) + b(y_i - \\bar{y}))^2 $$\n让我们定义中心化坐标 $x'_i = x_i - \\bar{x}$ 和 $y'_i = y_i - \\bar{y}$。最小化问题现在简化为找到参数 $a$ 和 $b$，使得：\n$$ \\text{最小化 } S(a, b) = \\sum_{i=1}^{n} (a x'_i + b y'_i)^2 \\quad \\text{约束条件} \\quad a^2 + b^2 = 1 $$\n这个问题可以用线性代数优雅地解决。我们定义一个参数向量 $\\mathbf{u} = \\begin{pmatrix} a \\\\ b \\end{pmatrix}$，因此约束为 $\\mathbf{u}^T \\mathbf{u} = 1$。我们还定义一个包含中心化数据点的 $n \\times 2$ 矩阵 $\\mathbf{A}$：\n$$ \\mathbf{A} = \\begin{pmatrix} x'_1 & y'_1 \\\\ x'_2 & y'_2 \\\\ \\vdots & \\vdots \\\\ x'_n & y'_n \\end{pmatrix} $$\n平方和可以写成向量 $\\mathbf{A}\\mathbf{u}$ 的欧几里得范数的平方：\n$$ S = \\| \\mathbf{A}\\mathbf{u} \\|_2^2 = (\\mathbf{A}\\mathbf{u})^T (\\mathbf{A}\\mathbf{u}) = \\mathbf{u}^T \\mathbf{A}^T \\mathbf{A} \\mathbf{u} $$\n问题现在是在 $\\mathbf{u}$ 是单位向量的约束下，最小化二次型 $\\mathbf{u}^T (\\mathbf{A}^T \\mathbf{A}) \\mathbf{u}$。矩阵 $\\mathbf{C} = \\mathbf{A}^T \\mathbf{A}$ 是中心化数据的 $2 \\times 2$ 散布矩阵：\n$$ \\mathbf{C} = \\begin{pmatrix} \\sum (x'_i)^2 & \\sum x'_i y'_i \\\\ \\sum x'_i y'_i & \\sum (y'_i)^2 \\end{pmatrix} $$\n这个公式是一个经典的瑞利商问题。$\\mathbf{u}^T \\mathbf{C} \\mathbf{u}$ 的最小值是对称矩阵 $\\mathbf{C}$ 的最小特征值，而实现此最小值的向量 $\\mathbf{u}$ 是对应的特征向量。\n\n解决这个问题的一种数值上稳健且计算稳定的方法是通过矩阵 $\\mathbf{A}$ 的奇异值分解（SVD）。设 $\\mathbf{A}$ 的 SVD 为 $\\mathbf{A} = \\mathbf{U} \\mathbf{\\Sigma} \\mathbf{V}^T$，其中 $\\mathbf{U}$ 是一个具有标准正交列的 $n \\times 2$ 矩阵，$\\mathbf{\\Sigma}$ 是一个由奇异值 $\\sigma_1 \\ge \\sigma_2 \\ge 0$ 组成的 $2 \\times 2$ 对角矩阵，$\\mathbf{V}$ 是一个 $2 \\times 2$ 的正交矩阵，其列 $\\mathbf{v}_1, \\mathbf{v}_2$ 是右奇异向量。\n\n需要最小化的量是 $\\|\\mathbf{A}\\mathbf{u}\\|_2^2$。由于 $\\mathbf{V}$ 是正交的，它的列构成了 $\\mathbb{R}^2$ 的一个标准正交基。任何单位向量 $\\mathbf{u}$ 都可以写成线性组合 $\\mathbf{u} = c_1 \\mathbf{v}_1 + c_2 \\mathbf{v}_2$，其中 $c_1^2 + c_2^2 = 1$。乘积 $\\mathbf{A}\\mathbf{v}_j = \\sigma_j \\mathbf{u}_j$，其中 $\\mathbf{u}_j$ 是 $\\mathbf{U}$ 的第 $j$ 列。\n$$ \\|\\mathbf{A}\\mathbf{u}\\|_2^2 = \\| \\mathbf{A} (c_1 \\mathbf{v}_1 + c_2 \\mathbf{v}_2) \\|_2^2 = \\| c_1 \\mathbf{A}\\mathbf{v}_1 + c_2 \\mathbf{A}\\mathbf{v}_2 \\|_2^2 = \\| c_1 \\sigma_1 \\mathbf{u}_1 + c_2 \\sigma_2 \\mathbf{u}_2 \\|_2^2 $$\n因为 $\\mathbf{u}_1$ 和 $\\mathbf{u}_2$ 是标准正交的，这可以简化为：\n$$ \\|\\mathbf{A}\\mathbf{u}\\|_2^2 = c_1^2 \\sigma_1^2 + c_2^2 \\sigma_2^2 $$\n为了在 $c_1^2 + c_2^2 = 1$ 的约束下并考虑到 $\\sigma_1 \\ge \\sigma_2$ 来最小化此表达式，我们必须选择 $c_1 = 0$ 和 $c_2 = 1$。这使得 $\\mathbf{u} = \\mathbf{v}_2$，即对应于最小奇异值 $\\sigma_2$ 的右奇异向量。平方和的最小值为 $S_{min} = \\sigma_2^2$。\n\n因此，算法如下：\n1.  计算 $n$ 个数据点 $(x_i, y_i)$ 的质心 $(\\bar{x}, \\bar{y})$。\n2.  构造中心化数据矩阵 $\\mathbf{A}$，其行为 $(x_i - \\bar{x}, y_i - \\bar{y})$。\n3.  计算 $\\mathbf{A} = \\mathbf{U}\\mathbf{\\Sigma}\\mathbf{V}^T$ 的 SVD。SVD 产生奇异值 $\\sigma_1 \\ge \\sigma_2$ 和矩阵 $\\mathbf{V}^T$。\n4.  最优参数向量 $\\begin{pmatrix} a \\\\ b \\end{pmatrix}$ 是对应于 $\\sigma_2$ 的右奇异向量。该向量是 $\\mathbf{V}$ 的第二列，也就是 $\\mathbf{V}^T$ 的第二行。\n5.  设 $(a, b)$ 为此向量。为确保唯一性，应用符号约定：如果 $a  0$，或者如果 $a = 0$ 且 $b  0$，则将 $a$ 和 $b$ 同时取反。\n6.  计算 $c = - (a \\bar{x} + b \\bar{y})$。\n7.  正交距离的平方和为 $S_{min} = \\sigma_2^2$。均方根（RMS）正交距离为 $r = \\sqrt{S_{min}/n} = \\sigma_2 / \\sqrt{n}$。\n8.  解是四元组 $[a, b, c, r]$。",
                "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the total least squares line fitting problem for a suite of test cases.\n    \"\"\"\n    \n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case 1 (general sloped line with perturbations)\n        [(0.02, 1.12), (0.51, 1.93), (0.98, 2.92), (1.48, 4.06), (2.02, 5.01), (2.49, 6.07)],\n        # Case 2 (nearly vertical line)\n        [(2.95, -1.00), (3.02, 0.50), (3.05, 2.00), (2.97, 3.50), (3.01, 5.00)],\n        # Case 3 (negative slope near the origin with symmetry)\n        [(-4.00, 2.10), (-2.00, 1.02), (0.00, -0.02), (2.00, -1.05), (4.00, -1.95)],\n        # Case 4 (two-point minimal case)\n        [(1.00, 1.00), (3.01, 1.99)],\n    ]\n\n    def fit_tls_line(points):\n        \"\"\"\n        Fits a line using Total Least Squares based on SVD.\n        \n        Args:\n            points: A list of (x, y) tuples.\n            \n        Returns:\n            A list [a, b, c, r] representing the line a*x + b*y + c = 0\n            and the RMS orthogonal distance r.\n        \"\"\"\n        data = np.array(points)\n        n = data.shape[0]\n\n        # 1. Compute the centroid of the data\n        centroid = np.mean(data, axis=0)\n        x_bar, y_bar = centroid\n\n        # 2. Form the centered data matrix A\n        centered_data = data - centroid\n\n        # 3. Compute the SVD of the centered data matrix\n        # U: Unitary matrix (left singular vectors)\n        # s: Singular values (sorted in descending order)\n        # Vt: Unitary matrix (right singular vectors, transposed)\n        _, s, Vt = np.linalg.svd(centered_data)\n\n        # 4. The parameters (a, b) are the components of the right singular vector\n        # corresponding to the smallest singular value. This is the last row of Vt.\n        a, b = Vt[1]\n\n        # 5. Apply the sign convention for uniqueness: a = 0, and if a = 0, then b = 0.\n        # We use a small tolerance for floating point comparisons.\n        if a  0.0 or (np.isclose(a, 0.0) and b  0.0):\n            a = -a\n            b = -b\n\n        # 6. Compute c using the fact that the line passes through the centroid\n        c = -(a * x_bar + b * y_bar)\n\n        # 7. Compute the RMS orthogonal distance\n        # The smallest singular value is s[1]. The sum of squared distances is s[1]**2.\n        sigma_2 = s[1]\n        r = sigma_2 / np.sqrt(n)\n        \n        return [a, b, c, r]\n\n    results = []\n    for case_data in test_cases:\n        result_quadruple = fit_tls_line(case_data)\n        results.append(result_quadruple)\n    \n    # Format the final output string as specified\n    formatted_results = []\n    for res in results:\n        # Format each number to 6 decimal places.\n        formatted_quad = [f\"{val:.6f}\" for val in res]\n        formatted_results.append(f\"[{','.join(formatted_quad)}]\")\n    \n    final_output = f\"[{','.join(formatted_results)}]\"\n    \n    # Final print statement in the exact required format.\n    print(final_output)\n\nsolve()\n```",
                "id": "3223301"
            },
            {
                "introduction": "普通最小二乘法（OLS）虽然常用，但它有一个很强的假设，即自变量没有误差。本练习将探讨当该假设被违反时会发生什么，并引入总最小二乘法（TLS）作为合适的替代方案。通过协方差矩阵的特征向量推导出TLS解，你将发现它与主成分分析（PCA）的深刻联系，并更清楚地理解何时以及为何应选择TLS而非OLS。[@problem_id:3173554]",
                "problem": "一个实验室记录了两个物理量的配对测量值 $\\{(X_{i}, Y_{i})\\}_{i=1}^{n}$。这两个物理量联合变化大致呈线性关系，但两者在测量时都带有加性零均值噪声。假设潜在信号是线性的，并且 $X$ 和 $Y$ 中的测量噪声与信号以及彼此之间相互独立，且方差有限。研究人员希望拟合一条直线来穿过这些点云。考虑了两种建模选择：普通最小二乘法 (OLS) 和总体最小二乘法 (TLS)。\n\n- 在普通最小二乘法 (OLS) 中，模型 $Y = \\beta_{0} + \\beta_{1} X + \\varepsilon$ 假设 $X$ 的测量没有误差，并最小化 $Y$ 方向的垂直残差。\n- 在总体最小二乘法 (TLS) 中，也称为变量含误差回归，选择的直线旨在最小化各点到直线的正交距离的平方和，这承认了 $X$ 和 $Y$ 都存在测量噪声。\n\n给定从 $n$ 个观测值计算得出的中心化样本协方差矩阵，\n$$\n\\mathbf{S} \\;=\\; \\begin{pmatrix}\n3.2  2.4 \\\\\n2.4  5.0\n\\end{pmatrix},\n$$\n其中 $\\mathbf{S}$ 的元素 $s_{xx}$、$s_{xy}$ 和 $s_{yy}$ 对应于 $X$ 和 $Y$ 的样本协方差。\n\n任务：\n1. 从 OLS 目标（最小化垂直残差平方和）的定义和一阶最优性条件出发，识别关于误差的结构性假设，并用样本矩推导出 OLS 斜率，解释当 $X$ 含有噪声时，为什么 OLS 直线会与最小化正交距离的直线不同。\n2. 从 TLS 目标（最小化正交距离平方和）的定义以及直线方向向量的范数为单位长度的要求出发，推导出 TLS 方向是样本协方差矩阵 $\\mathbf{S}$ 的一个特征向量的表征。然后用 $\\mathbf{S}$ 的元素及其最大特征值将 TLS 斜率表示为该特征向量分量的比值。\n3. 使用给定的 $\\mathbf{S}$，数值计算 TLS 斜率。\n\n将你的 TLS 斜率数值答案四舍五入到四位有效数字。将斜率表示为一个无量纲的实数，并最终只报告 TLS 斜率作为你的答案。",
                "solution": "我们考虑为 $X$ 和 $Y$ 都带有测量噪声的点云拟合一条直线。设中心化数据矩阵为 $\\mathbf{Z} \\in \\mathbb{R}^{n \\times 2}$，其中每一行是 $\\mathbf{z}_{i} = (x_{i} - \\bar{x}, y_{i} - \\bar{y})$，则样本协方差矩阵为\n$$\n\\mathbf{S} \\;=\\; \\frac{1}{n} \\sum_{i=1}^{n} \\mathbf{z}_{i} \\mathbf{z}_{i}^{\\top}\n\\;=\\;\n\\begin{pmatrix}\ns_{xx}  s_{xy} \\\\\ns_{xy}  s_{yy}\n\\end{pmatrix}.\n$$\n\n第1部分 (OLS)：普通最小二乘法 (OLS) 假设模型为 $Y = \\beta_{0} + \\beta_{1} X + \\varepsilon$，其中 $X$ 被视为非随机的或测量无误差的，且残差 $\\varepsilon$ 仅代表 $Y$ 中的噪声。OLS 的目标函数是\n$$\n\\min_{\\beta_{0}, \\beta_{1}} \\sum_{i=1}^{n} \\left(y_{i} - \\beta_{0} - \\beta_{1} x_{i}\\right)^{2}.\n$$\n对 $\\beta_{0}$ 和 $\\beta_{1}$ 求偏导数并令其为零，得到正规方程组。中心化后（因此截距为 $\\beta_{0} = \\bar{y} - \\beta_{1} \\bar{x}$），关于 $\\beta_{1}$ 的一阶条件变为\n$$\n\\sum_{i=1}^{n} (x_{i} - \\bar{x})(y_{i} - \\bar{y}) \\;=\\; \\beta_{1} \\sum_{i=1}^{n} (x_{i} - \\bar{x})^{2}.\n$$\n两边同除以 $n$ 可得\n$$\ns_{xy} \\;=\\; \\beta_{1} s_{xx} \\quad \\Rightarrow \\quad \\beta_{1}^{\\mathrm{OLS}} \\;=\\; \\frac{s_{xy}}{s_{xx}}.\n$$\n此公式假定 $X$ 的测量没有误差，因此只有 $Y$ 的垂直残差被惩罚。当 $X$ 含有噪声时，仅仅最小化垂直残差会使斜率产生偏差，倾向于低估数据云的真实方向，因此 OLS 直线会与最小化正交距离的直线有显著不同。\n\n第2部分 (TLS)：总体最小二乘法 (TLS)，也称变量含误差模型，旨在寻找一条直线以最小化各点到直线的正交距离平方和，它承认两个坐标都带有噪声。用单位方向向量 $\\mathbf{v} = (v_{x}, v_{y})^{\\top}$（其中 $\\|\\mathbf{v}\\| = 1$）来参数化一条穿过数据质心 $(\\bar{x}, \\bar{y})$ 的直线。对于一个中心化点 $\\mathbf{z}_{i}$，其正交残差是与 $\\mathbf{v}$ 正交的分量：\n$$\n\\mathbf{r}_{i} \\;=\\; \\mathbf{z}_{i} - (\\mathbf{z}_{i}^{\\top}\\mathbf{v})\\,\\mathbf{v},\n\\quad\n\\|\\mathbf{r}_{i}\\|^{2} \\;=\\; \\|\\mathbf{z}_{i}\\|^{2} - (\\mathbf{z}_{i}^{\\top}\\mathbf{v})^{2}.\n$$\nTLS 的目标函数是\n$$\n\\min_{\\mathbf{v} \\in \\mathbb{R}^{2}} \\sum_{i=1}^{n} \\|\\mathbf{r}_{i}\\|^{2}\n\\quad \\text{约束条件为} \\quad \\|\\mathbf{v}\\| = 1.\n$$\n由于 $\\sum_{i=1}^{n} \\|\\mathbf{z}_{i}\\|^{2}$ 相对于 $\\mathbf{v}$ 是一个常数，最小化正交距离的平方和等价于最大化沿 $\\mathbf{v}$ 方向的投影方差：\n$$\n\\max_{\\|\\mathbf{v}\\| = 1} \\sum_{i=1}^{n} (\\mathbf{z}_{i}^{\\top}\\mathbf{v})^{2}\n\\;=\\;\n\\max_{\\|\\mathbf{v}\\| = 1} \\mathbf{v}^{\\top} \\left( \\sum_{i=1}^{n} \\mathbf{z}_{i}\\mathbf{z}_{i}^{\\top} \\right) \\mathbf{v}\n\\;=\\;\n\\max_{\\|\\mathbf{v}\\| = 1} \\mathbf{v}^{\\top} (n \\mathbf{S}) \\mathbf{v}.\n$$\n这是一个瑞利商最大化问题，其最大化向量 $\\mathbf{v}$ 是与 $\\mathbf{S}$ 的最大特征值 $\\lambda_{1}$ 相关联的特征向量。因此，TLS 方向由下式表征：\n$$\n\\mathbf{S}\\,\\mathbf{v} \\;=\\; \\lambda_{1}\\,\\mathbf{v}, \\quad \\|\\mathbf{v}\\| = 1,\n$$\n且 TLS 斜率 $m_{\\mathrm{TLS}}$ 是 $\\mathbf{v}$ 分量的比值：\n$$\nm_{\\mathrm{TLS}} \\;=\\; \\frac{v_{y}}{v_{x}}.\n$$\n根据特征向量方程，\n$$\n(s_{xx} - \\lambda_{1}) v_{x} + s_{xy} v_{y} \\;=\\; 0\n\\quad \\Rightarrow \\quad\n\\frac{v_{y}}{v_{x}} \\;=\\; \\frac{\\lambda_{1} - s_{xx}}{s_{xy}}.\n$$\n等价地，\n$$\n\\frac{v_{y}}{v_{x}} \\;=\\; \\frac{s_{xy}}{\\lambda_{1} - s_{yy}},\n$$\n对于满足 $\\mathbf{S}$ 特征方程的 $\\lambda_{1}$，这两个表达式是一致的。\n\n第3部分 (TLS 斜率的数值计算)：对于\n$$\n\\mathbf{S} \\;=\\; \\begin{pmatrix}\n3.2  2.4 \\\\\n2.4  5.0\n\\end{pmatrix},\n$$\n特征值是以下方程的根：\n$$\n\\lambda^{2} - (s_{xx} + s_{yy}) \\lambda + (s_{xx}s_{yy} - s_{xy}^{2}) \\;=\\; 0.\n$$\n计算迹和行列式：\n$$\n\\operatorname{tr}(\\mathbf{S}) \\;=\\; 3.2 + 5.0 \\;=\\; 8.2,\n\\quad\n\\det(\\mathbf{S}) \\;=\\; 3.2 \\cdot 5.0 - 2.4^{2} \\;=\\; 16.0 - 5.76 \\;=\\; 10.24.\n$$\n因此，\n$$\n\\lambda_{1,2} \\;=\\; \\frac{ \\operatorname{tr}(\\mathbf{S}) \\pm \\sqrt{ \\operatorname{tr}(\\mathbf{S})^{2} - 4 \\det(\\mathbf{S}) } }{2}\n\\;=\\;\n\\frac{ 8.2 \\pm \\sqrt{ 67.24 - 40.96 } }{2}\n\\;=\\;\n\\frac{ 8.2 \\pm \\sqrt{ 26.28 } }{2}.\n$$\n较大的特征值是\n$$\n\\lambda_{1} \\;=\\; \\frac{ 8.2 + \\sqrt{26.28} }{2}.\n$$\n将此 $\\lambda_{1}$ 代入斜率公式，\n$$\nm_{\\mathrm{TLS}} \\;=\\; \\frac{ \\lambda_{1} - s_{xx} }{ s_{xy} }\n\\;=\\;\n\\frac{ \\frac{ 8.2 + \\sqrt{26.28} }{2} - 3.2 }{ 2.4 }\n\\;=\\;\n\\frac{ 4.1 + \\frac{1}{2}\\sqrt{26.28} - 3.2 }{2.4}\n\\;=\\;\n\\frac{ 0.9 + \\frac{1}{2}\\sqrt{26.28} }{2.4}.\n$$\n数值上，$\\sqrt{26.28} \\approx 5.1265$，因此\n$$\nm_{\\mathrm{TLS}} \\;\\approx\\; \\frac{0.9 + 2.56325}{2.4} \\;=\\; \\frac{3.46325}{2.4} \\;\\approx\\; 1.443.\n$$\n四舍五入到四位有效数字，TLS 斜率为 $1.443$。\n\n作为对比，来自相同数据的 OLS 斜率为\n$$\n\\beta_{1}^{\\mathrm{OLS}} \\;=\\; \\frac{s_{xy}}{s_{xx}} \\;=\\; \\frac{2.4}{3.2} \\;=\\; 0.75,\n$$\n这个值明显更小，因为 OLS 忽略了 $X$ 中的噪声，只最小化垂直偏差。而 TLS 通过最小化正交距离，与数据云的主方向对齐，因此在这里产生了一个更陡的斜率。\n\n要求的最终答案是 TLS 斜率。",
                "answer": "$$\\boxed{1.443}$$",
                "id": "3173554"
            },
            {
                "introduction": "在探索了直线拟合的几何与统计层面之后，这个练习将你的注意力集中到使用TLS求解通用线性系统 $A \\mathbf{x} = \\mathbf{b}$ 的代数步骤上。通过一个具体的微型算例，你将直接应用增广矩阵和SVD方法。这个实践旨在巩固TLS的核心计算机制，确保你能够将其应用于简单的直线拟合场景之外。[@problem_id:1071276]",
                "problem": "考虑超定线性系统 $A \\mathbf{x} = \\mathbf{b}$，其中\n$$  \nA = \\begin{bmatrix} 1 \\\\ 0 \\end{bmatrix}, \\quad \\mathbf{b} = \\begin{bmatrix} 1 \\\\ 1 \\end{bmatrix}.  \n$$  \n使用奇异值分解 (SVD) 方法求标量 $\\mathbf{x}$ 的总体最小二乘解。构造增广矩阵 $C = [A \\mid \\mathbf{b}]$，计算其 SVD，并从对应于最小奇异值的右奇异向量中导出解。给出 $\\mathbf{x}$ 的精确值。",
                "solution": "1. 构造增广矩阵及其法矩阵：\n$$\nC = \\begin{pmatrix}1  1\\\\ 0  1\\end{pmatrix}, \n\\quad\nC^T C = \\begin{pmatrix}1  0 \\\\ 1  1\\end{pmatrix} \\begin{pmatrix}1  1\\\\ 0  1\\end{pmatrix} = \\begin{pmatrix}1  1\\\\1  2\\end{pmatrix}.\n$$\n2. 从下式求出 $C^T C$ 的特征值\n$$\n\\det\\!\\bigl(C^T C - \\lambda I\\bigr)\n= \\det\\begin{pmatrix}1-\\lambda  1\\\\1  2-\\lambda\\end{pmatrix}\n= \\lambda^2 - 3\\lambda + 1 =0,\n$$\n因此\n$$\n\\lambda_{1,2} = \\frac{3 \\pm \\sqrt{5}}{2},\n\\qquad\n\\sigma_{1,2} = \\sqrt{\\lambda_{1,2}}.\n$$\n3. 最小的奇异值为 $\\sigma_2 = \\sqrt{\\frac{3-\\sqrt5}{2}}$。其对应的右奇异向量 $v=(v_x,v_b)^T$ 满足\n$$\n(C^T C - \\lambda_2 I)\\,v = 0\n\\;\\Longrightarrow\\;\n\\begin{cases}\n\\bigl(\\tfrac{\\sqrt5-1}{2}\\bigr)v_x + v_b = 0,\\\\\nv_x + \\bigl(\\tfrac{1+\\sqrt5}{2}\\bigr)v_b = 0.\n\\end{cases}\n$$\n由第一个方程可得 $v_b = -\\tfrac{\\sqrt5 -1}{2}v_x$。选择 $v_x=2$，则 $v_b=-(\\sqrt5-1)$。\n4. 总体最小二乘解为\n$$\nx_{\\rm TLS} \\;=\\; -\\frac{v_x}{v_b}\n\\;=\\; -\\frac{2}{-(\\sqrt5-1)}\n\\;=\\;\\frac{2}{\\sqrt5-1}\n\\;=\\;\\frac{\\sqrt5+1}{2}.\n$$",
                "answer": "$$\\boxed{\\frac{1+\\sqrt{5}}{2}}$$",
                "id": "1071276"
            }
        ]
    }