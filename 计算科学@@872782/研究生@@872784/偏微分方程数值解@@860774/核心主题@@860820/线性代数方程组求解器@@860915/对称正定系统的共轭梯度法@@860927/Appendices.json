{"hands_on_practices": [{"introduction": "共轭梯度法 (CG) 的核心在于其每一步迭代都是沿着特定方向最小化一个二次能量泛函。本练习将带您从第一性原理出发，推导共轭梯度法最关键的两个组成部分：最优步长 $\\alpha_k$ 和残差更新公式 $r_{k+1}$。通过亲自推导并应用于一个具体的例子，您将不再仅仅是记忆算法步骤，而是深刻理解其背后的数学原理。[@problem_id:3373168]", "problem": "考虑线性系统 $A x = b$，该系统由一维泊松算子在 $(0,1)$ 上采用齐次狄利克雷边界条件的中心有限差分离散化得到，其系数矩阵为一个对称正定（SPD）的刚度矩阵。设相关的二次泛函为 $J(x) = \\tfrac{1}{2} x^{\\top} A x - b^{\\top} x$。共轭梯度（CG）法（Conjugate Gradient (CG)）生成迭代序列 $\\{x_k\\}$，其搜索方向为 $\\{p_k\\}$，残差为 $r_k = b - A x_k$。\n\n从第 $k$ 次迭代时线搜索最小化的基本定义出发，即最小化关于 $\\alpha \\in \\mathbb{R}$ 的 $J(x_k + \\alpha p_k)$，并仅利用以下事实：$A$ 是对称正定的，$J$ 是可微的且其梯度为 $\\nabla J(x) = A x - b$，以及CG搜索方向的标准正交性和 $A$-共轭性，完成以下任务：\n\n1. 推导使 $J(x_k + \\alpha p_k)$ 最小化的步长 $\\alpha_k$ 的闭式表达式，将结果明确地用 $r_k$ 和 $p_k$ 表示，且不使用任何未从给定前提推导出的结论。\n\n2. 仅使用残差的定义 $r_k = b - A x_k$，推导在沿 $p_k$ 方向上进行最小化步长后，更新后的残差 $r_{k+1}$ 的显式表达式。\n\n然后，对于一个具体的 $4 \\times 4$ SPD系统，\n$$\nA \\;=\\; \\begin{pmatrix}\n2  -1  0  0 \\\\\n-1  2  -1  0 \\\\\n0  -1  2  -1 \\\\\n0  0  -1  2\n\\end{pmatrix},\n\\qquad\nb \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix},\n$$\n给定初始值 $x_0 = 0$（因此 $r_0 = b$）以及标准的CG选择 $p_0 = r_0$，计算从您推导的公式中得到的步长 $\\alpha_0$ 的精确值。请以精确形式（不四舍五入）且不带单位给出您的最终数值。", "solution": "我们从在SPD设定下最小化二次泛函的基本设置开始。二次泛函为 $J(x) = \\tfrac{1}{2} x^{\\top} A x - b^{\\top} x$，其中 $A$ 是对称正定（SPD）的。其梯度为 $\\nabla J(x) = A x - b$。在共轭梯度（CG）法的第 $k$ 次迭代中，我们考虑直线 $x(\\alpha) = x_k + \\alpha p_k$，并定义标量函数 $\\phi(\\alpha) = J(x_k + \\alpha p_k)$。我们寻求 $\\alpha \\in \\mathbb{R}$ 上的最小值点。\n\n1. 步长 $\\alpha_k$ 的推导：\n\n我们显式地计算 $\\phi(\\alpha)$：\n$$\n\\phi(\\alpha) \\;=\\; \\tfrac{1}{2} (x_k + \\alpha p_k)^{\\top} A (x_k + \\alpha p_k) \\;-\\; b^{\\top} (x_k + \\alpha p_k).\n$$\n对 $\\alpha$ 求导得到\n$$\n\\phi'(\\alpha) \\;=\\; p_k^{\\top} A (x_k + \\alpha p_k) \\;-\\; b^{\\top} p_k\n\\;=\\; p_k^{\\top} (A x_k - b) \\;+\\; \\alpha \\, p_k^{\\top} A p_k.\n$$\n使用残差的定义 $r_k = b - A x_k$，我们有 $A x_k - b = - r_k$，因此\n$$\n\\phi'(\\alpha) \\;=\\; - p_k^{\\top} r_k \\;+\\; \\alpha \\, p_k^{\\top} A p_k.\n$$\n最小化步长 $\\alpha_k$ 满足一阶最优性条件 $\\phi'(\\alpha_k)=0$，所以\n$$\n- p_k^{\\top} r_k \\;+\\; \\alpha_k \\, p_k^{\\top} A p_k \\;=\\; 0,\n\\qquad\\Rightarrow\\qquad\n\\alpha_k \\;=\\; \\frac{p_k^{\\top} r_k}{p_k^{\\top} A p_k}.\n$$\n对于标准的CG递推式，搜索方向为 $p_k = r_k + \\beta_{k-1} p_{k-1}$，其中 $r_k$ 在欧几里得内积下与 $p_{k-1}$ 正交，这意味着\n$$\np_k^{\\top} r_k \\;=\\; (r_k + \\beta_{k-1} p_{k-1})^{\\top} r_k \\;=\\; r_k^{\\top} r_k \\;+\\; \\beta_{k-1} \\, p_{k-1}^{\\top} r_k \\;=\\; r_k^{\\top} r_k.\n$$\n因此，在标准CG算法下，\n$$\n\\alpha_k \\;=\\; \\frac{r_k^{\\top} r_k}{p_k^{\\top} A p_k}.\n$$\n\n2. 残差更新 $r_{k+1}$ 的推导：\n\n根据定义，\n$$\nr_{k+1} \\;=\\; b - A x_{k+1} \\;=\\; b - A(x_k + \\alpha_k p_k) \\;=\\; (b - A x_k) \\;-\\; \\alpha_k A p_k \\;=\\; r_k \\;-\\; \\alpha_k A p_k.\n$$\n这将更新后的残差直接用当前残差、步长和矩阵-方向向量乘积来表示。\n\n3. 对给定系统的具体计算：\n\n给定\n$$\nA \\;=\\; \\begin{pmatrix}\n2  -1  0  0 \\\\\n-1  2  -1  0 \\\\\n0  -1  2  -1 \\\\\n0  0  -1  2\n\\end{pmatrix},\n\\qquad\nb \\;=\\; \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix},\n\\qquad\nx_0 \\;=\\; \\begin{pmatrix} 0 \\\\ 0 \\\\ 0 \\\\ 0 \\end{pmatrix}.\n$$\n因此 $r_0 = b - A x_0 = b$，并且根据标准的CG初始化，$p_0 = r_0 = b$。使用推导出的公式，\n$$\n\\alpha_0 \\;=\\; \\frac{r_0^{\\top} r_0}{p_0^{\\top} A p_0}\n\\;=\\; \\frac{b^{\\top} b}{b^{\\top} A b}.\n$$\n计算 $b^{\\top} b$：\n$$\nb^{\\top} b \\;=\\; 1^2 + 0^2 + 0^2 + 1^2 \\;=\\; 2.\n$$\n计算 $A b$：\n$$\nA b \\;=\\; \\begin{pmatrix}\n2  -1  0  0 \\\\\n-1  2  -1  0 \\\\\n0  -1  2  -1 \\\\\n0  0  -1  2\n\\end{pmatrix}\n\\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\\\ 1 \\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix}\n2 \\cdot 1 + (-1) \\cdot 0 + 0 \\cdot 0 + 0 \\cdot 1 \\\\\n-1 \\cdot 1 + 2 \\cdot 0 + (-1) \\cdot 0 + 0 \\cdot 1 \\\\\n0 \\cdot 1 + (-1) \\cdot 0 + 2 \\cdot 0 + (-1) \\cdot 1 \\\\\n0 \\cdot 1 + 0 \\cdot 0 + (-1) \\cdot 0 + 2 \\cdot 1\n\\end{pmatrix}\n\\;=\\;\n\\begin{pmatrix} 2 \\\\ -1 \\\\ -1 \\\\ 2 \\end{pmatrix}.\n$$\n然后\n$$\nb^{\\top} A b \\;=\\; \\begin{pmatrix} 1  0  0  1 \\end{pmatrix}\n\\begin{pmatrix} 2 \\\\ -1 \\\\ -1 \\\\ 2 \\end{pmatrix}\n\\;=\\; 2 + 0 + 0 + 2 \\;=\\; 4.\n$$\n因此\n$$\n\\alpha_0 \\;=\\; \\frac{2}{4} \\;=\\; \\frac{1}{2}.\n$$\n这个值是精确的，所以不需要四舍五入。", "answer": "$$\\boxed{\\frac{1}{2}}$$", "id": "3373168"}, {"introduction": "共轭梯度法的一个理论基石是，它保证了误差在能量范数（$A$-范数）下是单调递减的，这源于其在 Krylov 子空间上的最优性。然而，一个常见且更易于计算的收敛指标——残差的欧几里得范数（$\\|r_k\\|_2$）——却不具备此特性。本练习旨在通过一个精心设计的数值实验，让您亲手构建一个线性系统，直观地观察到这两种收敛行为的差异，从而加深对共轭梯度法优化目标的理解。[@problem_id:3245089]", "problem": "要求您设计并实现一个完整的程序，构建一个对称正定线性系统，共轭梯度（CG）法在该系统上同时表现出以下两种行为：以矩阵诱导范数衡量的误差随迭代次数单调递减，而残差的欧几里得范数不一定单调递减。您必须从对称正定矩阵的基本定义、相关能量泛函的二次最小化以及表征共轭梯度法的正交性条件出发，并利用这些来指导正确且稳健的实现。\n\n基本基础：\n- 一个矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 是对称正定的，如果 $A = A^\\top$ 并且对于所有非零向量 $x \\in \\mathbb{R}^n$ 都有 $x^\\top A x  0$。\n- 求解 $A x = b$ 等价于在 $\\mathbb{R}^n$ 上最小化严格凸的二次泛函 $\\varphi(x) = \\tfrac{1}{2} x^\\top A x - b^\\top x$。\n- $\\varphi$ 在 $x$ 处的梯度是 $\\nabla \\varphi(x) = A x - b = -r$，其中 $r = b - A x$ 是残差。\n- 共轭梯度法在仿射克雷洛夫子空间 $x_0 + \\mathcal{K}_k(A, r_0)$ 中生成迭代点 $x_k$，其搜索方向是 $A$-共轭的，确保了误差更新的 $A$-正交性和历次迭代残差的正交性。\n\n需要观察的目标属性：\n- 对于对称正定矩阵 $A$，从 $x_0$ 开始的经典共轭梯度迭代，误差的A-范数 $\\|e_k\\|_A = \\sqrt{e_k^\\top A e_k}$（其中 $e_k = x_* - x_k$ 且 $A x_* = b$）随着 $k$ 的增加是单调不增的。这源于 $x_k$ 作为 $\\varphi$ 在 $x_0 + \\mathcal{K}_k$ 上的最小化子的最优性。\n- 相反，残差的欧几里得范数 $\\|r_k\\|_2$ 不必随 $k$ 单调变化。\n\n您的程序必须：\n- 仅使用上述基本基础所证明的操作，实现用于对称正定系统的经典共轭梯度法。使用 $x_0 = 0$作为初始迭代点。\n- 对于每次迭代 $k$，记录 $\\|e_k\\|_A$ 和 $\\|r_k\\|_2$。\n- 当 $k=n$（$n$ 为维度）或 $\\|r_k\\|_2 \\le \\varepsilon \\|r_0\\|_2$（其中 $\\varepsilon = 10^{-12}$）时终止。\n- 使用相对容差 $\\tau = 10^{-12}$ 来判断单调性以考虑浮点舍入误差：如果对于所有 $k \\ge 1$ 都有 $s_k \\le (1 + \\tau) s_{k-1}$，则序列 $\\{s_k\\}$ 被视为单调不增；第一个严格增加的索引是最小的 $k \\ge 1$，使得 $s_k  (1 + \\tau) s_{k-1}$，如果不存在则为 $-1$。\n\n测试套件：\n为以下每个对称正定系统提供结果，初始迭代点为 $x_0 = 0$。\n\n- 测试用例1（病态对角矩阵，旨在显示非单调的欧几里得残差）：\n  - $A_1 = \\operatorname{diag}(1, 1000)$，\n  - $b_1 = [1, 0.01]^\\top$。\n- 测试用例2（单位矩阵，残差在一步内单调递减的边界行为）：\n  - $A_2 = I_3$，\n  - $b_2 = [1, 2, 3]^\\top$。\n- 测试用例3（中等规模的稠密三对角对称正定矩阵）：\n  - $A_3 = \\begin{bmatrix} 4  1  0 \\\\ 1  3  1 \\\\ 0  1  2 \\end{bmatrix}$，\n  - $b_3 = [1, 2, 3]^\\top$。\n\n对于每个测试用例 $j \\in \\{1, 2, 3\\}$，计算并返回一个三元组 $[M^{(A)}_j, M^{(r)}_j, k^{\\uparrow}_j]$，其中：\n- $M^{(A)}_j$ 是一个布尔值，指示 $\\|e_k\\|_A$ 是否随 $k$ 单调不增，\n- $M^{(r)}_j$ 是一个布尔值，指示 $\\|r_k\\|_2$ 是否随 $k$ 单调不增，\n- $k^{\\uparrow}_j$ 是满足 $\\|r_k\\|_2  \\|r_{k-1}\\|_2$ 的最小迭代索引 $k \\ge 1$（根据上述容差规则），如果不存在这样的 $k$ 则为 $-1$。\n\n最终输出格式：\n您的程序应生成一行输出，其中包含三个测试用例的结果，形式为一个用方括号括起来的逗号分隔列表，每个用例的三元组本身也是一个用方括号括起来的、无空格的逗号分隔列表。例如，输出必须具有以下格式：\n$[ [\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot],[\\cdot,\\cdot,\\cdot] ]$\n但不能有任何空格，例如：\n$[[\\text{True},\\text{False},1],[\\text{True},\\text{True},-1],[\\text{True},\\text{False},2]]$。", "solution": "问题陈述被评估为有效。它在科学上基于数值线性代数，特别是共轭梯度（CG）法的既定理论。该问题是适定的，所有必要的数据（$A$、$b$、$x_0$）、算法参数（$\\varepsilon$、$\\tau$）和终止条件都已指定。测试用例涉及的矩阵经确认为对称正定（SPD）矩阵，所要求的分析是客观且可计算验证的。\n\n问题的核心是求解线性系统 $A x = b$，其中 $A \\in \\mathbb{R}^{n \\times n}$ 是一个对称正定矩阵，求解未知向量 $x \\in \\mathbb{R}^n$。该问题等价于找到严格凸二次泛函 $\\varphi(x) = \\frac{1}{2} x^\\top A x - b^\\top x$ 的唯一最小化子。此泛函的梯度为 $\\nabla \\varphi(x) = A x - b$，即残差 $r(x) = b - A x$ 的负值。\n\n共轭梯度（CG）法是一种利用这种等价性的迭代算法。从初始猜测 $x_0$（在本问题中，$x_0 = 0$）开始，它生成一个迭代序列 $x_k$，逐步最小化 $\\varphi(x)$。在每一步 $k$，迭代点 $x_k$ 是 $\\varphi(x)$ 在仿射克雷洛夫子空间 $x_0 + \\mathcal{K}_k(A, r_0)$ 上的精确最小化子，其中 $\\mathcal{K}_k(A, r_0) = \\operatorname{span}\\{r_0, Ar_0, \\dots, A^{k-1}r_0\\}$。\n\n标准算法如下：\n1. 初始化：$k=0$， $x_0 = 0$， $r_0 = b - A x_0 = b$， $p_0 = r_0$。\n2. 对于 $k = 0, 1, 2, \\ldots$ 直到收敛：\n   a. 计算步长：$\\alpha_k = \\frac{r_k^\\top r_k}{p_k^\\top A p_k}$。该值最小化 $\\varphi(x_k + \\alpha p_k)$。\n   b. 更新解：$x_{k+1} = x_k + \\alpha_k p_k$。\n   c. 更新残差：$r_{k+1} = r_k - \\alpha_k A p_k$。这比直接计算 $r_{k+1} = b - A x_{k+1}$ 在数值上更稳定。\n   d. 计算改进因子：$\\beta_k = \\frac{r_{k+1}^\\top r_{k+1}}{r_k^\\top r_k}$。\n   e. 更新搜索方向：$p_{k+1} = r_{k+1} + \\beta_k p_k$。搜索方向 $\\{p_k\\}$ 被构造成相互 $A$-共轭（即，对于 $i \\neq j$，有 $p_i^\\top A p_j = 0$），并且残差 $\\{r_k\\}$ 相互正交（即，对于 $i \\neq j$，有 $r_i^\\top r_j = 0$）。\n\n我们被要求监控两个量：\n1. 误差的$A$-范数：$\\|e_k\\|_A = \\sqrt{e_k^\\top A e_k}$，其中 $e_k = x_* - x_k$ 是第 $k$ 次迭代的误差，$x_*$ 是真实解（$A x_* = b$）。\n2. 残差的欧几里得范数：$\\|r_k\\|_2 = \\sqrt{r_k^\\top r_k}$。\n\n误差的$A$-范数具有一个基本的单调性。由于迭代点 $x_k$ 在 $x_0 + \\mathcal{K}_k(A, r_0)$ 上最小化 $\\varphi(x)$，它也就在同一子空间上最小化误差的$A$-范数 $\\|x_* - x\\|_A$。因为克雷洛夫子空间是嵌套的，$\\mathcal{K}_k(A, r_0) \\subseteq \\mathcal{K}_{k+1}(A, r_0)$，所以在较大子空间上的最小值必须小于或等于在较小子空间上的最小值。形式上：\n$$ \\|e_{k+1}\\|_A = \\min_{x \\in x_0 + \\mathcal{K}_{k+1}(A, r_0)} \\|x_* - x\\|_A \\le \\min_{x \\in x_0 + \\mathcal{K}_k(A, r_0)} \\|x_* - x\\|_A = \\|e_k\\|_A $$\n因此，序列 $\\{\\|e_k\\|_A\\}$ 保证是单调不增的。我们的实现应该验证这一性质，同时使用提供的容差 $\\tau = 10^{-12}$ 来处理浮点精度问题。\n\n相反，残差的欧几里得范数 $\\|r_k\\|_2$ 不保证单调递减。虽然残差是正交的，但它们的范数可能会波动。对于病态矩阵，这种行为更为明显。一个小的步长 $\\alpha_k$ 可能对于减小$A$-范数下的误差是最优的，但如果 $A p_k$ 非常大且与 $r_k$ 的方向不一致，那么得到的残差 $r_{k+1} = r_k - \\alpha_k A p_k$ 在欧几里得范数上可能比 $r_k$ 更大。问题提供的测试用例旨在展示单调和非单调的残差范数行为。\n\n对每个测试用例 $(A_j, b_j)$，实现将按以下步骤进行：\n1. 计算精确解 $x_* = A_j^{-1} b_j$，以便计算误差 $e_k = x_* - x_k$。\n2. 从 $x_0 = 0$ 开始执行 CG 算法。循环最多运行 $n$ 次迭代（$n$ 是系统的维度），或直到相对残差范数降至容差 $\\varepsilon=10^{-12}$ 以下，即 $\\|r_k\\|_2 \\le \\varepsilon \\|r_0\\|_2$。\n3. 在每次迭代 $k$（包括初始状态 $k=0$），计算并存储 $\\|e_k\\|_A$ 和 $\\|r_k\\|_2$ 的值。\n4. 算法终止后，分析存储的范数序列。\n   - 对于误差的$A$-范数序列 $\\{s_k\\}$，我们检查是否对所有 $k \\ge 1$ 都有 $s_k \\le (1 + \\tau) s_{k-1}$。结果决定了 $M^{(A)}_j$ 的布尔值。根据理论，这应该总是为真。\n   - 对于残差的欧几里得范数序列，我们执行相同的检查来确定 $M^{(r)}_j$。我们还找到第一个迭代索引 $k^{\\uparrow}_j \\ge 1$，在该索引处范数严格增加，即 $s_k  (1 + \\tau) s_{k-1}$。如果没有发生这样的增加，则将 $k^{\\uparrow}_j$ 设置为 $-1$。\n5. 为每个测试用例记录生成的三元组 $[M^{(A)}_j, M^{(r)}_j, k^{\\uparrow}_j]$。最终输出将这些三元组聚合成指定的列表格式。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the Conjugate Gradient method and analyzes its convergence\n    properties on three test cases as specified in the problem statement.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (\n            np.array([[1.0, 0.0], [0.0, 1000.0]]),\n            np.array([1.0, 0.01])\n        ),\n        (\n            np.identity(3),\n            np.array([1.0, 2.0, 3.0])\n        ),\n        (\n            np.array([[4.0, 1.0, 0.0], [1.0, 3.0, 1.0], [0.0, 1.0, 2.0]]),\n            np.array([1.0, 2.0, 3.0])\n        )\n    ]\n\n    results = []\n    eps = 1e-12\n    tau = 1e-12\n\n    for A, b in test_cases:\n        n = A.shape[0]\n        \n        # Compute exact solution to calculate error norm\n        x_star = np.linalg.solve(A, b)\n\n        # Initialize CG\n        x_k = np.zeros_like(b)\n        r_k = b - A @ x_k\n        p_k = r_k.copy()\n        rs_old = r_k @ r_k\n        \n        norm_r0 = np.sqrt(rs_old)\n        \n        e_A_norms = []\n        r_2_norms = []\n\n        # Store initial norms for k=0\n        e_k = x_star - x_k\n        e_A_norms.append(np.sqrt(e_k @ A @ e_k))\n        r_2_norms.append(norm_r0)\n\n        # CG iteration loop\n        for k in range(n):\n            Ap = A @ p_k\n            alpha = rs_old / (p_k @ Ap)\n            \n            x_k = x_k + alpha * p_k\n            r_k = r_k - alpha * Ap\n            \n            rs_new = r_k @ r_k\n            norm_r_new = np.sqrt(rs_new)\n\n            # Store norms for new iterate (k+1)\n            e_k = x_star - x_k\n            e_A_norms.append(np.sqrt(e_k @ A @ e_k))\n            r_2_norms.append(norm_r_new)\n            \n            # Check for termination\n            if norm_r_new = eps * norm_r0:\n                break\n                \n            # Update for next iteration\n            beta = rs_new / rs_old\n            p_k = r_k + beta * p_k\n            rs_old = rs_new\n\n        # Analyze norm sequences\n        # M_A: Is A-norm of error nonincreasing?\n        is_eA_nonincreasing = True\n        for k in range(1, len(e_A_norms)):\n            if e_A_norms[k] > e_A_norms[k-1] * (1 + tau):\n                is_eA_nonincreasing = False\n                break\n        \n        # M_r: Is 2-norm of residual nonincreasing? and k_up: first increase index\n        is_r2_nonincreasing = True\n        k_up = -1\n        for k in range(1, len(r_2_norms)):\n            if r_2_norms[k] > r_2_norms[k-1] * (1 + tau):\n                is_r2_nonincreasing = False\n                if k_up == -1: # record first occurrence\n                    k_up = k\n                # Do not break here to correctly determine M_r if there are later decreases\n        \n        results.append([is_eA_nonincreasing, is_r2_nonincreasing, k_up])\n\n    # Final print statement in the exact required format.\n    case_strings = [f\"[{','.join(map(str, res))}]\" for res in results]\n    print(f\"[{','.join(case_strings)}]\")\n\nsolve()\n```", "id": "3245089"}, {"introduction": "理论告诉我们，共轭梯度法的收敛速度与系统矩阵 $A$ 的谱特性，特别是其条件数 $\\kappa(A)$ 密切相关。条件数越大，收敛通常越慢。本练习将引导您通过编程实践来验证这一核心理论，您将构造一个具有特定条件数的对角矩阵，并观察 CG 方法的实际收敛迭代次数与理论收敛上界之间的关系，从而将抽象的理论与可量化的计算结果联系起来。[@problem_id:3373133]", "problem": "您需要设计并实现一个程序，使用共轭梯度法求解由一个谱呈几何级数分布的特制对角矩阵所产生的对称正定线性系统。其目标是凭经验验证与标准能量范数误差界一致的缓慢收敛行为，并量化达到预定误差缩减所需的迭代次数。\n\n构造一个对角对称正定矩阵 $A \\in \\mathbb{R}^{n \\times n}$，其特征值从 $\\lambda_{\\min}$ 到 $\\lambda_{\\max}$ 按几何级数分布，条件数为 $\\kappa = \\lambda_{\\max}/\\lambda_{\\min}$。具体来说，设\n$$\n\\lambda_i = \\lambda_{\\min} \\, q^{\\,i-1}, \\quad i = 1,2,\\dots,n, \\quad q = \\left(\\frac{\\lambda_{\\max}}{\\lambda_{\\min}}\\right)^{\\frac{1}{n-1}},\n$$\n并取 $A = \\mathrm{diag}(\\lambda_1, \\lambda_2, \\dots, \\lambda_n)$。令右端项为 $b = A x^\\star$，其中 $x^\\star$ 是 $\\mathbb{R}^n$ 中所有元素为1的向量，并将共轭梯度法的初值设为 $x_0 = 0$。令误差为 $e_k = x_k - x^\\star$，并将其能量范数缩减因子定义为\n$$\n\\rho_k = \\frac{\\|e_k\\|_A}{\\|e_0\\|_A}, \\quad \\text{其中 } \\|y\\|_A = \\sqrt{y^\\top A y}.\n$$\n\n您的任务是：\n- 针对指定的 $A$ 和 $b$ 实现共轭梯度算法，当满足 $\\rho_k \\le r$（其中 $r \\in (0,1)$ 是预设的缩减目标）或迭代次数达到 $n$ 时停止。\n- 从对称正定系统上共轭梯度法的标准能量范数误差界的第一性原理推导，根据条件数 $\\kappa$ 和目标缩减率 $r$ 推导出充分迭代次数 $k_{\\mathrm{bound}}$，使得该界保证 $\\rho_{k_{\\mathrm{bound}}} \\le r$。\n- 对每个测试用例，计算并报告达到 $\\rho_k \\le r$ 所需的观测迭代次数 $k_{\\mathrm{obs}}$，以及从理论界推导出的充分迭代次数 $k_{\\mathrm{bound}}$。\n\n使用以下参数集 $(n,\\kappa,r)$ 的测试套件：\n1. $(n,\\kappa,r) = (512, 10^4, 10^{-3})$ 作为具有显著条件数和中等缩减目标的通用情况。\n2. $(n,\\kappa,r) = (64, 1.2, 10^{-6})$ 作为应快速收敛的近似单位阵情况。\n3. $(n,\\kappa,r) = (2048, 10^6, 10^{-2})$ 作为极端条件数情况，用以说明当 $k_{\\mathrm{bound}}$ 超过 $n$ 时收敛非常缓慢以及理论界的悲观性。\n4. $(n,\\kappa,r) = (1024, 500, 10^{-4})$ 作为中等病态情况。\n\n本问题中的所有量都是无量纲的，不涉及物理单位。\n\n您的程序应生成单行输出，包含一个用方括号括起来的逗号分隔列表形式的结果。该列表必须按顺序包含每个测试用例的配对 $(k_{\\mathrm{obs}}, k_{\\mathrm{bound}})$，并展开为两个连续的整数。因此，最终输出格式为\n$$\n[ k_{\\mathrm{obs}}^{(1)}, k_{\\mathrm{bound}}^{(1)}, k_{\\mathrm{obs}}^{(2)}, k_{\\mathrm{bound}}^{(2)}, k_{\\mathrm{obs}}^{(3)}, k_{\\mathrm{bound}}^{(3)}, k_{\\mathrm{obs}}^{(4)}, k_{\\mathrm{bound}}^{(4)} ].\n$$\n不应打印任何其他文本。程序必须是自包含的，且不需要用户输入。", "solution": "该问题被评估为有效。它在科学上基于数值线性代数中成熟的理论，特别是共轭梯度法的分析。该问题是适定的，所有参数、定义和目标都以清晰、明确的语言指定。它提出了一个旨在说明理论收敛特性的标准数值实验，这是该领域中常见且有意义的练习。\n\n解决方案分为三部分：首先，推导理论迭代界 $k_{\\mathrm{bound}}$；其次，阐述数值实验的细节，包括共轭梯度算法及其实际停止准则的评估；第三，为给定的测试用例实现完整的程序。\n\n### 1. 理论迭代界的推导\n\n应用于对称正定（SPD）线性系统 $Ax = b$ 的共轭梯度（CG）法的标准能量范数误差界为：\n$$\n\\frac{\\|e_k\\|_A}{\\|e_0\\|_A} \\le 2 \\left( \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1} \\right)^k\n$$\n在此，$e_k = x_k - x^\\star$ 是第 $k$ 次迭代的误差，$x^\\star$ 是精确解，$\\|y\\|_A = \\sqrt{y^\\top A y}$ 是 A-范数或能量范数，而 $\\kappa = \\lambda_{\\max}/\\lambda_{\\min}$ 是矩阵 $A$ 的谱条件数。问题将误差缩减因子定义为 $\\rho_k = \\|e_k\\|_A / \\|e_0\\|_A$。\n\n我们的任务是找到一个充分的迭代次数 $k_{\\mathrm{bound}}$，以保证误差缩减至少为 $r$，即 $\\rho_{k_{\\mathrm{bound}}} \\le r$。该次数是满足基于该界的不等式的最小整数 $k$：\n$$\n2 \\left( \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1} \\right)^k \\le r\n$$\n为了求解 $k$，我们首先重新整理不等式：\n$$\n\\left( \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1} \\right)^k \\le \\frac{r}{2}\n$$\n对两边取自然对数。由于 $\\kappa  1$，幂的底数 $(\\sqrt{\\kappa}-1)/(\\sqrt{\\kappa}+1)$ 介于0和1之间，因此其对数为负。所以，在除以它时必须反转不等号：\n$$\nk \\ln\\left( \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1} \\right) \\le \\ln\\left( \\frac{r}{2} \\right)\n$$\n$$\nk \\ge \\frac{\\ln(r/2)}{\\ln\\left( \\frac{\\sqrt{\\kappa}-1}{\\sqrt{\\kappa}+1} \\right)}\n$$\n使用恒等式 $\\ln(1/x) = -\\ln(x)$，我们可以将其写成一个分子分母都为正的更方便形式：\n$$\nk \\ge \\frac{\\ln(2/r)}{\\ln\\left( \\frac{\\sqrt{\\kappa}+1}{\\sqrt{\\kappa}-1} \\right)}\n$$\n满足此条件的最小整数 $k$ 是其向上取整。因此，迭代次数的理论界为：\n$$\nk_{\\mathrm{bound}} = \\left\\lceil \\frac{\\ln(2/r)}{\\ln\\left( \\frac{\\sqrt{\\kappa}+1}{\\sqrt{\\kappa}-1} \\right)} \\right\\rceil\n$$\n此公式将用于计算每个测试用例的 $k_{\\mathrm{bound}}$。注意，如果 $\\kappa = 1$，分母无定义。在这种情况下，CG在一次迭代内收敛，因此 $k_{\\mathrm{bound}}=1$。当 $\\kappa \\to 1^+$ 时，该表达式的极限为 $0$，其向上取整为 $1$，与此事实一致。\n\n### 2. 数值实验设计\n\n该实验要求实现CG算法，并将其应用于一个特定构造的SPD系统。\n\n**矩阵和向量的构造：**\n矩阵 $A \\in \\mathbb{R}^{n \\times n}$ 是对角矩阵，其特征值由几何级数给出。令 $\\lambda_{\\min} = 1$。这个选择不影响条件数 $\\kappa$，因此也不影响与之相关的收敛行为。因此，$\\lambda_{\\max} = \\kappa$。特征值为：\n$$\n\\lambda_i = 1 \\cdot q^{i-1}, \\quad i=1, \\dots, n, \\quad \\text{where } q = \\kappa^{\\frac{1}{n-1}}\n$$\n因此，$A = \\mathrm{diag}(\\lambda_1, \\dots, \\lambda_n)$。精确解是 $x^\\star$，即全1向量。右端项向量 $b$ 则是 $b = Ax^\\star$，这意味着对每个 $i$ 都有 $b_i = \\lambda_i$。\n\n**共轭梯度算法：**\n给定系统 $Ax=b$、初始猜测 $x_0$、最大迭代次数 $n$ 和容差 $r$：\n1.  初始化：\n    $k = 0$\n    $x_0 = 0$ (零向量)\n    $r_0 = b - Ax_0 = b$\n    $p_0 = r_0$\n    $\\delta_0 = r_0^\\top r_0$\n2.  对 $k = 0, 1, 2, \\dots, n-1$ 进行迭代：\n    a. 计算 $Ap_k$。由于 $A$ 是对角矩阵，这是一个逐元素相乘的操作。\n    b. $\\alpha_k = \\frac{\\delta_k}{p_k^\\top A p_k}$\n    c. $x_{k+1} = x_k + \\alpha_k p_k$\n    d. $r_{k+1} = r_k - \\alpha_k A p_k$\n    e. 检查 $x_{k+1}$ 的停止准则。如果满足，则设置 $k_{\\mathrm{obs}} = k+1$ 并终止。\n    f. $\\delta_{k+1} = r_{k+1}^\\top r_{k+1}$\n    g. $\\beta_k = \\frac{\\delta_{k+1}}{\\delta_k}$\n    h. $p_{k+1} = r_{k+1} + \\beta_k p_k$\n    i. $\\delta_k \\leftarrow \\delta_{k+1}$\n3.  如果循环完成，则设置 $k_{\\mathrm{obs}} = n$。\n\n**停止准则的评估：**\n停止准则是 $\\rho_k = \\|e_k\\|_A / \\|e_0\\|_A \\le r$。直接计算 $e_k = x_k-x^\\star$ 是可能的，但在CG循环内部并不常见。一种更标准且计算上更优雅的方法是利用误差 $e_k$ 和残差 $r_k$ 之间的关系：\n$$\nr_k = b - Ax_k = Ax^\\star - Ax_k = A(x^\\star - x_k) = -Ae_k \\implies e_k = -A^{-1}r_k\n$$\n将此代入能量范数的定义：\n$$\n\\|e_k\\|_A^2 = e_k^\\top A e_k = (-A^{-1}r_k)^\\top A (-A^{-1}r_k) = r_k^\\top (A^{-1})^\\top A A^{-1} r_k\n$$\n由于 $A$ 是对称正定矩阵，$(A^{-1})^\\top = A^{-1}$。这可以简化为：\n$$\n\\|e_k\\|_A^2 = r_k^\\top A^{-1} r_k = \\|r_k\\|_{A^{-1}}^2\n$$\n对于对角矩阵 $A=\\mathrm{diag}(\\lambda_i)$，$A^{-1}=\\mathrm{diag}(1/\\lambda_i)$，因此 $\\|e_k\\|_A^2 = \\sum_{i=1}^n (r_k)_i^2 / \\lambda_i$。\n\n初始误差为 $e_0 = x_0 - x^\\star = -x^\\star$ (因为 $x_0=0$）。初始能量范数的平方为：\n$$\n\\|e_0\\|_A^2 = (-x^\\star)^\\top A (-x^\\star) = (x^\\star)^\\top A x^\\star = \\mathbf{1}^\\top A \\mathbf{1} = \\sum_{i=1}^n \\lambda_i\n$$\n因此，在第 $k+1$ 次迭代时的停止准则通过计算以下表达式来检查：\n$$\n\\rho_{k+1} = \\sqrt{\\frac{\\sum_{i=1}^n (r_{k+1})_i^2 / \\lambda_i}{\\sum_{i=1}^n \\lambda_i}} \\le r\n$$\n在每一步计算此表达式以确定 $k_{\\mathrm{obs}}$。\n\n### 3. 实现\n最终的实现将把这些推导封装到一个使用 `numpy` 库进行数值计算的Python脚本中。一个函数将处理每个测试用例 $(n, \\kappa, r)$，首先计算 $k_{\\mathrm{bound}}$，然后设置并运行CG算法以找到 $k_{\\mathrm{obs}}$，最后收集结果以进行格式化输出。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Solves the problem for the given test cases, calculating k_obs and k_bound.\n    \"\"\"\n\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (512, 1e4, 1e-3),   # (n, kappa, r)\n        (64, 1.2, 1e-6),\n        (2048, 1e6, 1e-2),\n        (1024, 500, 1e-4),\n    ]\n\n    results = []\n    for n, kappa, r in test_cases:\n        # --- Task: Calculate theoretical iteration bound k_bound ---\n        if kappa == 1.0:\n            k_bound = 1\n        else:\n            sqrt_kappa = np.sqrt(kappa)\n            # Bound formula: ceil( log(2/r) / log((sqrt(k)+1)/(sqrt(k)-1)) )\n            numerator = np.log(2.0 / r)\n            denominator = np.log((sqrt_kappa + 1.0) / (sqrt_kappa - 1.0))\n            k_bound = int(np.ceil(numerator / denominator))\n        \n        # --- Task: Implement Conjugate Gradient to find k_obs ---\n\n        # 1. Construct the matrix A (as a vector of eigenvalues) and vector b\n        if n == 1:\n            lambdas = np.array([1.0])\n        else:\n            # Set lambda_min = 1.0, so lambda_max = kappa\n            q = kappa**(1.0 / (n - 1.0))\n            # Eigenvalues: lambda_i = q^(i-1) for i=1,...,n\n            indices = np.arange(n, dtype=np.float64)\n            lambdas = q**indices\n        \n        # b = A * x_star, where x_star is all ones. For diagonal A, b_i = lambda_i.\n        b = lambdas\n\n        # 2. Initialize CG algorithm\n        x = np.zeros(n, dtype=np.float64)\n        residual = b.copy()  # r_0 = b - A*x_0 = b\n        direction = residual.copy()  # p_0 = r_0\n        rs_old_sq = residual @ residual\n\n        # 3. Calculate initial energy norm for stopping criterion\n        # ||e_0||_A^2 = x_star^T * A * x_star = 1^T * A * 1 = sum(diag(A)) = sum(lambdas)\n        e0_A_sq = np.sum(lambdas)\n        \n        k_obs = n  # Default if convergence is not met within n iterations\n        for k_iter in range(n):\n            # A is diagonal, so A*p is an element-wise product\n            A_p = lambdas * direction\n            \n            alpha = rs_old_sq / (direction @ A_p)\n            \n            x += alpha * direction\n            residual -= alpha * A_p\n            \n            # Check stopping criterion: rho_k = ||e_k||_A / ||e_0||_A = r\n            # ||e_k||_A^2 = r_k^T * A^-1 * r_k = sum(r_k[i]^2 / lambda[i])\n            ek_A_sq = np.sum(residual**2 / lambdas)\n            rho_k = np.sqrt(ek_A_sq / e0_A_sq)\n\n            if rho_k = r:\n                k_obs = k_iter + 1\n                break\n\n            # Update for next iteration\n            rs_new_sq = residual @ residual\n            beta = rs_new_sq / rs_old_sq\n            direction = residual + beta * direction\n            rs_old_sq = rs_new_sq\n\n        results.extend([k_obs, k_bound])\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3373133"}]}