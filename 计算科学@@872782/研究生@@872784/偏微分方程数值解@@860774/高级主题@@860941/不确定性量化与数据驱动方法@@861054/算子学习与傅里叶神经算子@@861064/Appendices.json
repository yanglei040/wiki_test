{"hands_on_practices": [{"introduction": "傅里叶神经算子（FNO）的核心思想是在傅里叶域中对算子的作用进行截断，只保留有限数量的模式。一个关键的设计问题是：为了达到特定的精度，我们需要保留多少个模式？这个练习将通过一个理想化的场景，让你从理论上探索截断误差与所需模式数 $k_{\\max}$ 之间的定量关系，从而加深对FNO近似原理的理解。[@problem_id:3427017]", "problem": "考虑一个一维环面上的平移不变线性算子，它表示为与一个核 $k$ 的卷积，该核的傅里叶级数系数为 $\\{\\hat{k}(n)\\}_{n \\in \\mathbb{Z}}$。傅里叶神经算子 (FNO) 近似将算子在频域中的作用截断到对称的模式频带 $\\{|n| \\leq k_{\\max}\\}$，并丢弃所有更高频率的模式。假设符号以速率 $\\alpha0$ 指数衰减，具体为 $\\hat{k}(n) = \\exp(-\\alpha |n|)$ 对所有 $n \\in \\mathbb{Z}$ 成立。为了保证被丢弃的谱尾受给定容差 $\\varepsilon \\in (0,1)$ 的限制，我们施加条件\n$$\n\\sum_{|n|k_{\\max}} |\\hat{k}(n)| \\leq \\varepsilon.\n$$\n在这些假设下，并仅使用傅里叶级数和几何级数的基本性质，确定能确保上述不等式成立的最小整数 $k_{\\max}$。请将您的最终答案表示为关于 $\\alpha$ 和 $\\varepsilon$ 的精确符号表达式。最终答案不应是不等式或方程，且不包含任何单位。", "solution": "用户希望我解决以下问题。\n\n### 问题验证\n\n#### 步骤 1：提取已知条件\n\n我将首先正式验证问题陈述。已知条件如下：\n*   上下文是一个一维环面上的平移不变线性算子，表示为卷积。\n*   卷积核 $k$ 的傅里叶级数系数由符号 $\\{\\hat{k}(n)\\}_{n \\in \\mathbb{Z}}$ 给出。\n*   符号的具体形式是 $\\hat{k}(n) = \\exp(-\\alpha |n|)$，适用于所有整数 $n \\in \\mathbb{Z}$，其中 $\\alpha  0$。\n*   傅里叶神经算子 (FNO) 近似会截断模式，仅保留满足 $|n| \\leq k_{\\max}$ 的模式。\n*   误差条件是，被丢弃的傅里叶系数的幅值之和必须受容差 $\\varepsilon$ 的限制，其中 $\\varepsilon \\in (0,1)$。\n*   需要满足的不等式是 $\\sum_{|n|k_{\\max}} |\\hat{k}(n)| \\leq \\varepsilon$。\n*   目标是找到满足此不等式的最小整数 $k_{\\max}$。\n*   最终答案必须是关于 $\\alpha$ 和 $\\varepsilon$ 的精确符号表达式。\n\n#### 步骤 2：使用提取的已知条件进行验证\n\n我现在将评估问题的有效性。\n*   **科学依据：** 该问题牢固地植根于傅里叶分析和数值分析等数学领域，特别是在算子学习和傅里叶神经算子的背景下。傅里叶级数、系数的指数衰减（对应于解析函数）和谱截断等概念都是标准且合理的。问题陈述没有违反任何科学或数学原理。\n*   **适定性：** 该问题是适定的。给定的条件充分且一致。目标是找到一个特定的量——最小整数 $k_{\\max}$——它满足一个明确定义的不等式。对参数 $\\alpha  0$ 和 $\\varepsilon \\in (0,1)$ 的约束确保了求解所需的数学运算（如对数、除法）是明确定义的，并能得出一个唯一的、有意义的结果。\n*   **客观性：** 该问题以精确、客观的数学语言陈述，没有任何主观性或模糊性。\n*   **完整性和一致性：** 提供了所有必要的信息。没有缺失的定义或矛盾的约束。\n*   **现实性和可行性：** 该设置是用于分析 FNO 近似性质的标准理论模型。这些假设在数学上是理想化的，但为理论分析提供了有效的基础。\n*   **结构与平凡性：** 这个问题不平凡，需要对无限级数求和并求解一个超越不等式。它不是伪深刻或同义反复的。\n\n#### 步骤 3：结论与行动\n\n该问题是**有效的**。这是一个适定的、有科学依据的、客观的数学问题。我现在将开始推导解答。\n\n### 解答\n\n问题要求找到满足以下不等式的最小整数 $k_{\\max}$：\n$$\n\\sum_{|n|k_{\\max}} |\\hat{k}(n)| \\leq \\varepsilon\n$$\n我们已知傅里叶系数为 $\\hat{k}(n) = \\exp(-\\alpha |n|)$，其中常数 $\\alpha  0$。由于指数函数总是正的，我们有 $|\\hat{k}(n)| = \\hat{k}(n) = \\exp(-\\alpha|n|)$。\n\n求和遍及所有满足 $|n|  k_{\\max}$ 的整数 $n$。这个索引集合可以分为两个不相交的部分：$n  k_{\\max}$ 和 $n  -k_{\\max}$。我们可以将求和写为：\n$$\n\\sum_{|n|k_{\\max}} \\exp(-\\alpha |n|) = \\sum_{n=k_{\\max}+1}^{\\infty} \\exp(-\\alpha |n|) + \\sum_{n=-\\infty}^{-(k_{\\max}+1)} \\exp(-\\alpha |n|)\n$$\n对于第一个和式，$n$ 是正数，所以 $|n|=n$。对于第二个和式，$n$ 是负数，所以 $|n|=-n$。\n$$\n\\sum_{|n|k_{\\max}} \\exp(-\\alpha |n|) = \\sum_{n=k_{\\max}+1}^{\\infty} \\exp(-\\alpha n) + \\sum_{n=-\\infty}^{-(k_{\\max}+1)} \\exp(\\alpha n)\n$$\n我们通过令 $j = -n$ 来对第二个和式重新索引。当 $n$ 从 $-(k_{\\max}+1)$ 变化到 $-\\infty$ 时，$j$ 从 $k_{\\max}+1$ 变化到 $\\infty$。第二个和式变为：\n$$\n\\sum_{j=k_{\\max}+1}^{\\infty} \\exp(-\\alpha j)\n$$\n这在形式上与第一个和式相同。因此，总和为：\n$$\n\\sum_{|n|k_{\\max}} \\exp(-\\alpha |n|) = 2 \\sum_{n=k_{\\max}+1}^{\\infty} \\exp(-\\alpha n)\n$$\n剩下的和式是一个几何级数：\n$$\n\\sum_{n=k_{\\max}+1}^{\\infty} \\exp(-\\alpha n) = \\sum_{n=k_{\\max}+1}^{\\infty} (\\exp(-\\alpha))^n\n$$\n该级数的首项是 $a = \\exp(-\\alpha (k_{\\max}+1))$，公比是 $r = \\exp(-\\alpha)$。因为给定 $\\alpha  0$，所以公比 $r$ 的范围是 $0  r  1$，这保证了级数的收敛。无穷几何级数的和由公式 $\\frac{a}{1-r}$ 给出。\n应用这个公式，我们得到：\n$$\n\\sum_{n=k_{\\max}+1}^{\\infty} \\exp(-\\alpha n) = \\frac{\\exp(-\\alpha(k_{\\max}+1))}{1 - \\exp(-\\alpha)}\n$$\n现在，我们将这个结果代入到我们最初的不等式中：\n$$\n2 \\left( \\frac{\\exp(-\\alpha(k_{\\max}+1))}{1 - \\exp(-\\alpha)} \\right) \\leq \\varepsilon\n$$\n我们的目标是求解 $k_{\\max}$。我们首先分离出包含 $k_{\\max}$ 的指数项：\n$$\n\\exp(-\\alpha(k_{\\max}+1)) \\leq \\frac{\\varepsilon}{2} (1 - \\exp(-\\alpha))\n$$\n因为 $\\alpha  0$ 且 $\\varepsilon \\in (0,1)$，所以右侧是正数。我们可以安全地对两边取自然对数。由于自然对数是一个单调递增函数，不等号的方向保持不变：\n$$\n\\ln(\\exp(-\\alpha(k_{\\max}+1))) \\leq \\ln\\left( \\frac{\\varepsilon(1 - \\exp(-\\alpha))}{2} \\right)\n$$\n$$\n-\\alpha(k_{\\max}+1) \\leq \\ln\\left( \\frac{\\varepsilon(1 - \\exp(-\\alpha))}{2} \\right)\n$$\n接下来，我们除以 $-\\alpha$。因为 $\\alpha  0$，所以 $-\\alpha$ 是负数，因此我们必须反转不等号的方向：\n$$\nk_{\\max}+1 \\geq -\\frac{1}{\\alpha} \\ln\\left( \\frac{\\varepsilon(1 - \\exp(-\\alpha))}{2} \\right)\n$$\n使用对数性质 $-\\ln(x) = \\ln(1/x)$，我们可以简化表达式：\n$$\nk_{\\max}+1 \\geq \\frac{1}{\\alpha} \\ln\\left( \\frac{2}{\\varepsilon(1 - \\exp(-\\alpha))} \\right)\n$$\n最后，我们分离出 $k_{\\max}$：\n$$\nk_{\\max} \\geq \\frac{1}{\\alpha} \\ln\\left( \\frac{2}{\\varepsilon(1 - \\exp(-\\alpha))} \\right) - 1\n$$\n问题要求满足此条件的最小整数 $k_{\\max}$。对于任何形如 $x \\geq C$ 的不等式，满足它的最小整数 $x$ 是 $C$ 的上取整，记作 $\\lceil C \\rceil$。\n因此，所求的 $k_{\\max}$ 值为：\n$$\nk_{\\max} = \\left\\lceil \\frac{1}{\\alpha} \\ln\\left( \\frac{2}{\\varepsilon(1 - \\exp(-\\alpha))} \\right) - 1 \\right\\rceil\n$$\n这就是最小整数 $k_{\\max}$ 的最终符号表达式。", "answer": "$$\n\\boxed{\\left\\lceil \\frac{1}{\\alpha} \\ln\\left( \\frac{2}{\\varepsilon(1 - \\exp(-\\alpha))} \\right) - 1 \\right\\rceil}\n$$", "id": "3427017"}, {"introduction": "在评估一个算子学习模型时，我们观察到的总误差通常是模型自身近似误差（建模误差）和用于生成“真实”解的数值求解器误差（离散化误差）的混合。能够区分这两种误差来源对于准确诊断模型性能至关重要。这个编程练习将指导你通过一个经典的网格加密研究，以实验方式分离和量化这两种性质截然不同的误差。[@problem_id:3426971]", "problem": "考虑单位区间上具有齐次狄利克雷边界条件的一维泊松方程的边值问题。令 $U = L^{2}(0,1)$ 和 $V = H_{0}^{1}(0,1)$ 为希尔伯特空间。定义线性算子 $T : U \\to V$ 如下：对于任意力函数 $f \\in U$，函数 $u = T(f)$ 是以下边值问题的唯一弱解\n$$\n- u''(x) = f(x), \\quad x \\in (0,1), \\quad u(0) = 0, \\quad u(1) = 0.\n$$\n假设 $f$ 具有在 $L^2(0,1)$ 中收敛的傅里叶正弦级数 $f(x) = \\sum_{n=1}^{\\infty} a_n \\sin(n \\pi x)$，类似地，$u$ 也具有正弦级数 $u(x) = \\sum_{n=1}^{\\infty} b_n \\sin(n \\pi x)$。\n\n受傅里叶神经算子 (FNO) 的启发，定义了一个算子学习代理 $\\hat{T}$，其通过将输出的傅里叶正弦表示截断至最低的 $k$ 个模态来定义。更准确地说，$\\hat{T}$ 的作用是仅保留 $u$ 的前 $k$ 个正弦模态，对于 $n \\le k$ 的系数与 $u$ 的系数相同，而对于 $n  k$ 的系数为零。这可以理解为作用于 $U$ 上的一个算子，它将 $f$ 映射到由截断的正弦级数给出的 $\\hat{u} = \\hat{T}(f)$。\n\n算子范数下的泛化误差定义为\n$$\nE_{\\mathrm{gen}} = \\| T - \\hat{T} \\|_{\\mathcal{L}(U,V)} = \\sup_{f \\in U, \\, \\| f \\|_{U} = 1} \\| T(f) - \\hat{T}(f) \\|_{V}.\n$$\n在实践中，人们使用一组有代表性的输入，相对于输出的 $L^2(0,1)$ 范数来估计 $E_{\\mathrm{gen}}$。\n\n另外，当在网格上使用离散数值求解器来近似连续算子 $T$ 时，会产生离散化误差。考虑一个具有 $N$ 个节点的均匀网格，网格间距为 $h = 1/(N-1)$，以及在内部点上对 $-u''(x)$ 使用标准的二阶中心有限差分格式。令 $T_N$ 表示离散算子，它将网格函数 $f$（通过在网格点上采样 $f$ 得到）映射到网格函数 $u_N$（通过求解 $u(0)=u(1)=0$ 的有限差分线性系统得到）。对给定的网格尺寸 $N$，离散化误差定义为\n$$\nE_{\\mathrm{disc}}(N) = \\sup_{f \\in \\mathcal{F}} \\| T(f) - T_{N}(f) \\|_{L^{2}(0,1)},\n$$\n其中范数通过网格上的数值积分进行评估，$\\mathcal{F}$ 是 $U$ 中一个指定的测试族。\n\n您的任务是：\n- 从第一性原理推导 $T$ 如何作用于 $f$ 的傅里叶正弦系数 $a_n$，并解释以 $L^2(0,1)$ 范数作为输出空间范数时，$E_{\\mathrm{gen}}$ 的算子范数定义。\n- 从概念上和数量上区分 $E_{\\mathrm{gen}}$ 和 $E_{\\mathrm{disc}}(N)$。\n- 提出并实施一个网格加密实验，通过比较粗网格和细网格上的测量结果，来分离 $E_{\\mathrm{gen}}$ 和 $E_{\\mathrm{disc}}(N)$ 的贡献。\n\n实验设置：\n- 使用由具有齐次狄利克雷条件的一维泊松方程确定的精确连续算子 $T$。\n- 定义代理算子 $\\hat{T}$，它截断超过截止频率 $k$ 的输出正弦模态。\n- 通过在选定的网格上使用复合梯形法则来评估 $\\| \\cdot \\|_{L^2(0,1)}$。\n- 为 $T_N$ 构建一个有限差分求解器，其中使用标准的用于二阶导数近似的三对角矩阵，并满足边界条件 $u(0)=u(1)=0$。\n\n测试套件：\n对于每组参数，定义测试族 $\\mathcal{F}$ 由三个输入组成，每个输入都是一个归一化的单一正弦模态 $f(x) = \\sqrt{2} \\sin(n \\pi x)$，其 $L^2(0,1)$ 范数为 1。对于每组参数，测量以下四个量：\n- $E_{\\mathrm{gen}}(N_{\\mathrm{low}})$: 在具有 $N_{\\mathrm{low}}$ 个节点的粗网格上计算的 $\\| T(f) - \\hat{T}(f) \\|_{L^2(0,1)}$ 在 $\\mathcal{F}$ 上的最大值。\n- $E_{\\mathrm{gen}}(N_{\\mathrm{high}})$: 在具有 $N_{\\mathrm{high}}$ 个节点的细网格上计算的相同最大值。\n- $E_{\\mathrm{disc}}(N_{\\mathrm{low}})$: 在粗网格上计算的 $\\| T(f) - T_{N_{\\mathrm{low}}}(f) \\|_{L^2(0,1)}$ 在 $\\mathcal{F}$ 上的最大值。\n- $E_{\\mathrm{disc}}(N_{\\mathrm{high}})$: 在细网格上的相同最大值。\n\n然后，对于每组参数，通过检查以下两个条件来判断网格加密是否分离了这两个误差源：\n- $|E_{\\mathrm{gen}}(N_{\\mathrm{low}}) - E_{\\mathrm{gen}}(N_{\\mathrm{high}})| \\le \\tau_{\\mathrm{gen}}$，其中 $\\tau_{\\mathrm{gen}}$ 是一个小的容差。\n- $E_{\\mathrm{disc}}(N_{\\mathrm{low}})  \\gamma \\, E_{\\mathrm{disc}}(N_{\\mathrm{high}})$，其中 $\\gamma  1$ 表明随着网格加密，离散化误差有显著减少。\n\n使用以下三组参数作为测试套件，每组以元组 $(M, k, N_{\\mathrm{low}}, N_{\\mathrm{high}}, \\text{frequencies})$ 的形式提供：\n- $\\left(64, 5, 33, 257, [6, 64, 2]\\right)$\n- $\\left(64, 64, 33, 257, [10, 20, 40]\\right)$\n- $\\left(64, 10, 17, 33, [11, 64, 5]\\right)$\n这里，$M$ 是用于评估 $T$ 的连续级数的最大正弦模态数，$k$ 是代理算子 $\\hat{T}$ 的截断阈值，$N_{\\mathrm{low}}$ 和 $N_{\\mathrm{high}}$ 是粗网格和细网格的尺寸（节点数），列表 \"frequencies\" 指定了 $\\mathcal{F}$ 中的三个单模态输入。\n\n最终输出规格：\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。每个元素都应是对应于一组参数的五个值的列表，顺序如下：\n$$\n\\left[ E_{\\mathrm{gen}}(N_{\\mathrm{low}}), \\, E_{\\mathrm{gen}}(N_{\\mathrm{high}}), \\, E_{\\mathrm{disc}}(N_{\\mathrm{low}}), \\, E_{\\mathrm{disc}}(N_{\\mathrm{high}}), \\, \\text{separation\\_flag} \\right],\n$$\n其中前四个是浮点数，最后一个是布尔值，指示两个分离条件是否都成立。程序不得读取任何输入，并且必须完全按照指定使用所提供的测试套件。此任务中没有物理单位，如果出现角度，必须视为弧度。容差应固定为 $\\tau_{\\mathrm{gen}} = 10^{-3}$，离散化改进因子应为 $\\gamma = 1.1$。", "solution": "该问题经评估为有效，因为它在数值分析和算子理论领域有科学依据，是适定的、客观的，并且包含获得唯一解所需的所有必要信息。\n\n本文提供一个完整的、有理有据的解决方案。在全文中，每个数学实体都按要求使用 LaTeX 渲染。\n\n### 1. 连续算子 $T$ 和代理算子 $\\hat{T}$\n\n问题考虑的是具有齐次狄利克雷边界条件的一维泊松方程：\n$$\n-u''(x) = f(x), \\quad x \\in (0,1), \\quad u(0) = 0, \\quad u(1) = 0\n$$\n线性算子 $T$ 将一个力函数 $f \\in L^2(0,1)$ 映射到唯一的弱解 $u \\in H_0^1(0,1)$。为了理解 $T$ 在傅里叶域中的作用，我们用傅里叶正弦级数来表示 $f(x)$ 和 $u(x)$，这些级数构成了在 $(0,1)$ 上满足边界条件的函数的完备正交基：\n$$\nf(x) = \\sum_{n=1}^{\\infty} a_n \\sin(n \\pi x)\n$$\n$$\nu(x) = \\sum_{n=1}^{\\infty} b_n \\sin(n \\pi x)\n$$\n假设具有足够的正则性可以逐项微分， $u(x)$ 的二阶导数为：\n$$\nu''(x) = \\sum_{n=1}^{\\infty} b_n \\frac{d^2}{dx^2} \\sin(n \\pi x) = \\sum_{n=1}^{\\infty} b_n (-(n \\pi)^2) \\sin(n \\pi x)\n$$\n将这些级数代入泊松方程可得：\n$$\n- \\left( \\sum_{n=1}^{\\infty} -b_n (n \\pi)^2 \\sin(n \\pi x) \\right) = \\sum_{n=1}^{\\infty} a_n \\sin(n \\pi x)\n$$\n$$\n\\sum_{n=1}^{\\infty} b_n (n \\pi)^2 \\sin(n \\pi x) = \\sum_{n=1}^{\\infty} a_n \\sin(n \\pi x)\n$$\n根据傅里叶级数系数的唯一性，我们可以对每个模态 $n$ 的系数进行等同：\n$$\nb_n (n \\pi)^2 = a_n \\implies b_n = \\frac{a_n}{(n \\pi)^2}\n$$\n这个基本关系表明，算子 $T$ 在傅里叶基中充当一个对角算子。它通过将输入 $f$ 的第 $n$ 个傅里叶系数 $a_n$ 乘以一个因子 $1/(n \\pi)^2$ 来将其转换为输出 $u$ 的第 $n$ 个系数 $b_n$。这种缩放会迅速衰减高频分量。\n\n代理算子 $\\hat{T}$ 受傅里叶神经算子 (FNO) 的启发，其定义为在截止模态 $k$ 处截断输出的傅里叶级数。对于一个系数为 $b_n$ 的解 $u = T(f)$，其代理算子解 $\\hat{u} = \\hat{T}(f)$ 为：\n$$\n\\hat{u}(x) = \\sum_{n=1}^{k} b_n \\sin(n \\pi x)\n$$\n对于模态 $n \\le k$，$\\hat{u}$ 的系数与 $u$ 的系数相同；对于 $n  k$，其系数为零。\n\n### 2. 泛化误差与离散化误差\n\n问题要求在概念上和数量上对泛化误差 $E_{\\mathrm{gen}}$ 和离散化误差 $E_{\\mathrm{disc}}(N)$ 进行区分。\n\n**泛化误差 ($E_{\\mathrm{gen}}$):** 这是一种**建模误差**，是代理模型 $\\hat{T}$ 所固有的。它量化了简化模型 $\\hat{T}$ 对真实连续算子 $T$ 的近似程度。该误差是真实解 $u$ 与代理算子解 $\\hat{u}$ 之间的差值：\n$$\nT(f) - \\hat{T}(f) = u(x) - \\hat{u}(x) = \\sum_{n=k+1}^{\\infty} b_n \\sin(n \\pi x) = \\sum_{n=k+1}^{\\infty} \\frac{a_n}{(n \\pi)^2} \\sin(n \\pi x)\n$$\n此误差源于丢弃所有频率指数 $n  k$ 的解模态所造成的信息损失。关键在于，$E_{\\mathrm{gen}}$ 是连续算子 $T$ 和 $\\hat{T}$ 的一个属性，不依赖于任何数值离散化或网格尺寸 $N$。对于一个固定的测试族 $\\mathcal{F}$，其值是恒定的。在网格上对此误差进行数值计算是一种近似，但随着网格的加密，这种近似应收敛到真实的恒定值。\n\n**离散化误差 ($E_{\\mathrm{disc}}(N)$):** 这是一种**数值近似误差**，是离散求解器 $T_N$ 所固有的。它量化了具有 $N$ 个节点的网格上的数值解 $u_N$ 对真实连续解 $u = T(f)$ 的近似程度。此误差源于用有限差分近似代替连续微分算子 $-d^2/dx^2$。对于指定的二阶中心差分格式，局部截断误差的阶数为 $O(h^2)$，其中 $h=1/(N-1)$ 是网格间距。因此，解的全局误差 $\\|T(f) - T_N(f)\\|_{L^2(0,1)}$ 预计也会随着 $N$ 的增加而减小，其收敛阶数通常与格式的精度有关。我们预期当 $N \\to \\infty$（或 $h \\to 0$）时，$E_{\\mathrm{disc}}(N) \\to 0$。\n\n总而言之，$E_{\\mathrm{gen}}$ 衡量的是**模型**的缺陷，而 $E_{\\mathrm{disc}}(N)$ 衡量的是**数值方法**的缺陷。\n\n### 3. 网格加密实验\n\n所提出的实验旨在凭经验分离这两个不同的误差来源。它依赖于它们对网格尺寸 $N$ 的不同依赖性。\n\n1.  **测量 $E_{\\mathrm{gen}}$:** 泛化误差 $\\|T(f) - \\hat{T}(f)\\|_{L^2(0,1)}$ 是算子的内在属性，与网格无关。当我们在粗网格 ($N_{\\mathrm{low}}$) 和细网格 ($N_{\\mathrm{high}}$) 上进行数值计算时，由于积分的梯形法则近似，我们引入了测量误差。然而，如果两个网格都足够精细以解析所涉及的函数，则数值结果应彼此非常接近，并且也接近于真实的解析值。条件 $|E_{\\mathrm{gen}}(N_{\\mathrm{low}}) - E_{\\mathrm{gen}}(N_{\\mathrm{high}})| \\le \\tau_{\\mathrm{gen}}$ 检查对 $E_{\\mathrm{gen}}$ 的测量是否已经稳定，这表明与 $E_{\\mathrm{gen}}$ 本身的大小相比，测量的离散化方面可以忽略不计。\n\n2.  **测量 $E_{\\mathrm{disc}}(N)$:** 根据定义，离散化误差 $\\|T(f) - T_N(f)\\|_{L^2(0,1)}$ 依赖于网格尺寸 $N$。当网格从 $N_{\\mathrm{low}}$ 加密到 $N_{\\mathrm{high}}$ 时，二阶有限差分格式的误差应该会减小。误差比率预计约为 $(h_{\\mathrm{low}}/h_{\\mathrm{high}})^2 = ((N_{\\mathrm{high}}-1)/(N_{\\mathrm{low}}-1))^2$。对于因子 $\\gamma  1$ 的条件 $E_{\\mathrm{disc}}(N_{\\mathrm{low}})  \\gamma \\, E_{\\mathrm{disc}}(N_{\\mathrm{high}})$ 证实了网格加密后误差的这种预期减少。\n\n通过观察到一个误差度量在网格加密时几乎保持不变，而另一个则系统性地减小，该实验有效地辨别并分离了建模误差和数值求解器误差。\n\n需要注意的是，参数 $M$ 通过在 $M$ 个模态处截断其级数表示来定义我们“真实”算子 $T$ 的保真度。对于特定的测试输入 $f(x) = \\sqrt{2} \\sin(n \\pi x)$，精确解 $u(x)$ 也是一个单一的正弦模态。由于所有测试频率 $n$ 都小于或等于给定的 $M$ 值，因此这种截断没有影响，可以直接使用解析解。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import solve_banded\n\ndef solve():\n    \"\"\"\n    Main function to run the mesh refinement experiment for the given test suite.\n    \"\"\"\n    test_cases = [\n        # (M, k, N_low, N_high, frequencies)\n        (64, 5, 33, 257, [6, 64, 2]),\n        (64, 64, 33, 257, [10, 20, 40]),\n        (64, 10, 17, 33, [11, 64, 5]),\n    ]\n    tau_gen = 1e-3\n    gamma = 1.1\n\n    final_results = []\n\n    for M, k, N_low, N_high, freqs in test_cases:\n        \n        errors_gen_low, errors_disc_low = [], []\n        errors_gen_high, errors_disc_high = [], []\n\n        for n in freqs:\n            # --- Coarse Mesh Calculations ---\n            egen_low, edisc_low = calculate_errors(n, k, M, N_low)\n            errors_gen_low.append(egen_low)\n            errors_disc_low.append(edisc_low)\n            \n            # --- Fine Mesh Calculations ---\n            egen_high, edisc_high = calculate_errors(n, k, M, N_high)\n            errors_gen_high.append(egen_high)\n            errors_disc_high.append(edisc_high)\n\n        # Find the maximum error over the family of test functions\n        E_gen_low = np.max(errors_gen_low)\n        E_gen_high = np.max(errors_gen_high)\n        E_disc_low = np.max(errors_disc_low)\n        E_disc_high = np.max(errors_disc_high)\n\n        # Check separation conditions\n        cond1 = np.abs(E_gen_low - E_gen_high) = tau_gen\n        cond2 = E_disc_low > gamma * E_disc_high if E_disc_high > 0 else E_disc_low > 0\n        \n        separation_flag = cond1 and cond2\n\n        final_results.append(\n            f\"[{E_gen_low:.6f},{E_gen_high:.6f},{E_disc_low:.6f},{E_disc_high:.6f},{str(separation_flag).lower()}]\"\n        )\n    \n    print(f\"[{','.join(final_results)}]\")\n\ndef calculate_errors(n, k, M, N):\n    \"\"\"\n    Calculates generalization and discretization errors for a given frequency n,\n    surrogate cutoff k, and grid size N.\n    \n    Args:\n        n (int): The frequency mode of the input function.\n        k (int): The cutoff mode for the surrogate operator.\n        M (int): The cutoff for the 'true' continuous operator.\n        N (int): The number of nodes in the grid.\n\n    Returns:\n        tuple: A tuple containing (E_gen, E_disc).\n    \"\"\"\n    # 1. Define grid and analytical solutions\n    x_grid = np.linspace(0.0, 1.0, N)\n    h = 1.0 / (N - 1) if N > 1 else 0\n\n    # Input function f(x) = sqrt(2) * sin(n*pi*x)\n    f_input = lambda x: np.sqrt(2.0) * np.sin(n * np.pi * x)\n\n    # True solution u(x) = T(f)\n    # For a single mode input, the analytical solution is also a single mode.\n    # The 'M' parameter defines the fidelity of our representation of T.\n    if n = M:\n        u_true = lambda x: np.sqrt(2.0) / (n * np.pi)**2 * np.sin(n * np.pi * x) if n != 0 else np.zeros_like(x)\n    else:\n        u_true = lambda x: np.zeros_like(x)\n\n    # Surrogate solution u_hat(x) = hat{T}(f)\n    # This is the true solution truncated at mode k.\n    if n = k:\n        u_surr = u_true # The n-th mode is kept\n    else:\n        u_surr = lambda x: np.zeros_like(x) # The n-th mode is truncated\n    \n    # Evaluate analytical solutions on the grid\n    u_true_grid = u_true(x_grid)\n    u_surr_grid = u_surr(x_grid)\n\n    # 2. Calculate Generalization Error (E_gen)\n    # E_gen = || T(f) - hat{T}(f) ||_L2 = || u_true - u_surr ||_L2\n    # Norm is computed using composite trapezoidal rule.\n    err_vec_gen = u_true_grid - u_surr_grid\n    norm_sq_gen = np.trapz(err_vec_gen**2, x_grid)\n    E_gen = np.sqrt(norm_sq_gen)\n\n    # 3. Calculate Discretization Error (E_disc)\n    # First, find the numerical solution u_N = T_N(f)\n    \n    # Set up the finite difference system Au = f_interior\n    num_interior_points = N - 2\n    if num_interior_points > 0:\n        # Forcing function on interior grid points\n        f_interior = f_input(x_grid[1:-1])\n\n        # Tridiagonal matrix A for -u'' is (1/h^2) * diag(-1, 2, -1)\n        # For scipy.linalg.solve_banded, we represent A in banded format.\n        # It has 1 lower and 1 upper diagonal.\n        ab = np.zeros((3, num_interior_points))\n        ab[0, 1:] = -1.0  # Upper diagonal\n        ab[1, :] = 2.0   # Main diagonal\n        ab[2, :-1] = -1.0 # Lower diagonal\n        \n        # Solve the linear system A * u_interior = h^2 * f_interior\n        u_interior = solve_banded((1, 1), ab, h**2 * f_interior)\n        \n        # Add boundary conditions u(0)=0, u(1)=0\n        u_N_grid = np.pad(u_interior, 1, 'constant')\n    else: # Handles N=1 or N=2 cases\n        u_N_grid = np.zeros(N)\n\n    # E_disc = || T(f) - T_N(f) ||_L2 = || u_true - u_N ||_L2\n    err_vec_disc = u_true_grid - u_N_grid\n    norm_sq_disc = np.trapz(err_vec_disc**2, x_grid)\n    E_disc = np.sqrt(norm_sq_disc)\n\n    return E_gen, E_disc\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3426971"}, {"introduction": "与许多机器学习模型一样，当测试数据的分布与训练数据不同时，傅里叶神经算子（FNO）可能会表现不佳，这暴露了其在外推能力上的局限性。这个实践练习将让你亲手构建并见证这一“外推失败”现象。你将通过在一个有限的频率范围内训练一个简单的FNO并在该范围之外进行测试，来揭示其局限性，并探索如何通过引入基于物理的正则化来显著提升模型的泛化和外推能力。[@problem_id:3427041]", "problem": "考虑单位区间上的一维周期性泊松问题，其中未知场 $u(x)$ 满足二阶常微分方程 $-u''(x) = f_{\\mu}(x)$，并具有周期性边界条件和零均值。在此设定中，参数 $\\mu$ 选择一个强迫模式 $f_{\\mu}(x)$，解算子将输入场 $f_{\\mu}(x)$ 映射到输出场 $u(x)$。目标是研究傅里叶神经算子（FNO）的算子外推能力。FNO被定义为一种在频域中通过缩放输入场的傅里叶模式，然后变换回空间域来作用的算子。\n\n您必须完全在代码中实现以下流程：\n\n1. 使用等距离散化，在定义域 $[0,1)$ 上构建一个大小为 $N$ 个点的周期性网格，其中 $N$ 是有限且适中的。定义一个由整数值组成的训练参数范围 $[\\mu_{\\min}, \\mu_{\\max}]$ 用于训练。强迫项 $f_{\\mu}(x)$ 必须是与整数频率下的周期性一致的单频实数信号。\n\n2. 对于给定的输入 $f_{\\mu}(x)$，仅基于周期性问题的傅里叶级数基本原理，使用数值上稳健的谱方法计算基准解 $u(x)$。该谱方法必须在您的代码中明确实现。\n\n3. 设计一个简化的单层傅里叶神经算子（FNO）模型，该模型将输入的每个傅里叶模式 $\\hat{f}(k)$ 乘以一个仅依赖于整数波数大小 $|k|$ 的学习到的复数标量权重 $w(k)$，然后应用傅里叶逆变换生成输出预测 $\\hat{u}(k) = w(k)\\hat{f}(k)$。限制 FNO 在频域中对角运算（逐模式缩放），不进行模式间混合。\n\n4. 训练 FNO 的两个变体：\n   - 基线 FNO：仅针对训练波数 $k \\in \\{\\mu_{\\min},\\mu_{\\min}+1,\\dots,\\mu_{\\max}\\}$，通过训练集的数据驱动拟合来估计离散权重 $w(k)$。对于训练中未出现的所有其他波数，将 $w(k)$ 保留为零。\n   - 可感知外推的正则化 FNO：通过在训练集上为一个具有物理动机的 $w(k)$ 族拟合单个标量参数，对学习到的权重施加一个频率相关的衰减结构，然后将此结构化权重扩展到所有频率 $k$（包括不在训练范围内的频率）。该结构化形式必须编码随 $|k|$ 增加的单调衰减，并且其选择必须与控制微分算子的阶数一致。正则化必须以可通过代码验证的方式实现，且不需要任何外部数据或预计算的常数。\n\n5. 在训练范围之外的参数值 $\\mu$ 上进行测试时，通过为每次测试计算至少以下定量诊断来表征外推失败模式：\n   - 预测场与基准场之间的相对 $\\ell^2$ 误差，计算为预测误差的 $\\ell^2$ 范数与基准解的 $\\ell^2$ 范数之比。\n   - 一个布尔指标，指示误差的谱能量是否主要集中在大于最大训练波数的波数上（例如，误差能量的固定比例以上部分位于 $|k|\\mu_{\\max}$）。\n\n6. 提供一个紧凑的测试套件，用于测试以下情况：\n   - 一个严格低于 $\\mu_{\\min}$ 的参数 $\\mu$（范围外低值）。\n   - 边界参数 $\\mu=\\mu_{\\min}$ 和 $\\mu=\\mu_{\\max}$（范围内边界）。\n   - 一个严格高于 $\\mu_{\\max}$ 的参数 $\\mu$（范围外高值）。\n\n在您的程序中使用以下固定的数值选择：\n- 网格大小 $N=128$。\n- 训练范围 $[\\mu_{\\min}, \\mu_{\\max}] = [2,6]$，整数训练参数为 $\\mu \\in \\{2,3,4,5,6\\}$。\n- 强迫项定义 $f_{\\mu}(x)$ 必须为 $f_{\\mu}(x) = \\sin(2\\pi \\mu x)$，以确保与单位区间上的周期性兼容。\n- 测试套件参数 $\\mu \\in \\{1,2,6,9\\}$。\n- 将谱失败模式的布尔阈值定义为由波数 $|k|\\mu_{\\max}$ 承载的误差能量比例严格大于 $0.6$。\n\n您的程序必须为每个测试参数生成一个包含四个条目的列表：\n- 基线 FNO 的相对 $\\ell^2$ 误差（一个浮点数）。\n- 正则化 FNO 的相对 $\\ell^2$ 误差（一个浮点数）。\n- 一个布尔值，指示正则化误差是否严格低于基线误差。\n- 一个布尔值，指示基线预测是否根据上述阈值表现出高频误差失败模式。\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果。此列表的每个元素本身必须是一个包含与测试参数 $\\mu \\in \\{1,2,6,9\\}$ 顺序对应的四个值的列表。例如：\"[$[r_{1}^{\\mathrm{base}},r_{1}^{\\mathrm{reg}},b_{1}^{\\mathrm{improve}},b_{1}^{\\mathrm{fail}}],[r_{2}^{\\mathrm{base}},r_{2}^{\\mathrm{reg}},b_{2}^{\\mathrm{improve}},b_{2}^{\\mathrm{fail}}],\\dots$]\"。不涉及物理单位；所有量纲均为无量纲。如果存在角度，则根据构造以弧度为单位。最终输出必须仅为基本类型（浮点数和布尔值），如上所述。", "solution": "该问题经评估有效。它在科学上是合理的、适定的、客观的，并包含构建唯一、可验证解所需的所有必要信息。我们开始进行求解。\n\n该问题要求研究简化的傅里叶神经算子（FNO）在一维周期性泊松问题上的外推能力。核心任务是比较一个仅在特定输入频率范围上训练的基线 FNO 与一个包含物理动机结构的正则化 FNO。\n\n**1. 控制方程及其谱解**\n\n该问题由以下二阶常微分方程定义：\n$$\n-u''(x) = f_{\\mu}(x)\n$$\n在定义域 $x \\in [0, 1)$ 上，具有周期性边界条件 $u(0)=u(1)$ 和 $u'(0)=u'(1)$。为了确保解的唯一性，施加了零均值的额外约束 $\\int_0^1 u(x) dx = 0$。强迫项是单频正弦函数，$f_{\\mu}(x) = \\sin(2\\pi \\mu x)$，其中 $\\mu$ 是一个整数。\n\n对于周期性问题，傅里叶级数提供了一个自然的基。一个函数 $g(x)$ 可以表示为复指数的和：\n$$\ng(x) = \\sum_{k=-\\infty}^{\\infty} \\hat{g}(k) e^{2\\pi i k x}\n$$\n其中 $\\hat{g}(k)$ 是傅里叶系数，$k$ 是整数波数。傅里叶变换的一个关键性质是空间域中的微分在频域中变为乘法。具体来说，二阶导数变换如下：\n$$\n\\mathcal{F}\\{g''(x)\\} = (2\\pi i k)^2 \\hat{g}(k) = -(2\\pi k)^2 \\hat{g}(k)\n$$\n将傅里叶变换逐项应用于泊松方程，我们将微分方程转换为代数方程：\n$$\n- (-(2\\pi k)^2 \\hat{u}(k)) = \\hat{f}_{\\mu}(k) \\implies (2\\pi k)^2 \\hat{u}(k) = \\hat{f}_{\\mu}(k)\n$$\n这使我们能够直接求解解 $u(x)$ 的傅里叶系数：\n$$\n\\hat{u}(k) = \\frac{1}{(2\\pi k)^2} \\hat{f}_{\\mu}(k) \\quad \\text{for } k \\neq 0\n$$\n对于代表均值的 $k=0$（零频率）模式，整数 $\\mu$ 的条件 $\\int_0^1 f_{\\mu}(x) dx = 0$ 确保了 $\\hat{f}_{\\mu}(0)=0$。问题中 $u(x)$ 具有零均值的约束意味着 $\\hat{u}(0)=0$。因此，解是适定的。\n\n因此，将 $f$ 映射到 $u$ 的解析解算子是在傅里叶域中与格林函数（或滤波器）$G(k)$ 的对角乘法：\n$$\n\\hat{u}(k) = G(k) \\hat{f}_{\\mu}(k) \\quad \\text{where} \\quad G(k) = \\begin{cases} \\frac{1}{(2\\pi k)^2}  k \\neq 0 \\\\ 0  k=0 \\end{cases}\n$$\n这个解析结果构成了我们基准数值求解器的基础。\n\n**2. 数值离散化与基准求解器**\n\n我们将域 $[0,1)$ 离散化为 $N=128$ 个等距点 $x_j = j/N$，其中 $j=0, 1, \\dots, N-1$。连续傅里叶变换被离散傅里叶变换（DFT）所取代，后者通过快速傅里叶变换（FFT）算法高效计算。离散波数 $k$ 由标准的 FFT 频率生成例程提供。\n\n基准求解器在数值上实现了谱方法解析解：\n1.  计算输入网格函数 $f_{\\mu}(x_j)$ 的 DFT，得到 $\\hat{f}_{\\mu}(k)$。\n2.  将每个系数 $\\hat{f}_{\\mu}(k)$ 乘以相应的离散滤波器权重 $G(k)$。\n3.  计算所得系数 $\\hat{u}(k)$ 的逆 DFT，以获得网格上的解 $u(x_j)$。\n\n**3. 傅里叶神经算子模型与训练**\n\n简化的 FNO 模型由操作 $\\hat{u}_{pred}(k) = w(k)\\hat{f}(k)$ 定义，其中 $w(k)$ 是依赖于波数大小 $|k|$ 的学习到的复数权重。\n\n**基线 FNO：** 该模型使用由整数频率 $\\mu \\in \\{2, 3, 4, 5, 6\\}$ 的强迫项生成的数据进行训练。输入 $f_{\\mu}(x) = \\sin(2\\pi \\mu x)$ 的谱能量完全集中在波数 $k=\\pm\\mu$ 处。因此，“训练”过程只能确定 $|k| \\in \\{2, 3, 4, 5, 6\\}$ 的权重。由于真实算子是已知的，我们可以直接将权重设置为其理想值：对于 $|k| \\in \\{2, \\dots, 6\\}$，$w_{base}(k) = G(k)$。对于训练期间未见过的所有其他波数 $|k|$，权重设置为零，即 $w_{base}(k)=0$。该模型有效地记忆了算子在训练频率上的行为，并假设在其他所有地方的响应为零。\n\n**正则化 FNO：** 该模型对权重施加了一个具有物理动机的结构。格林函数 $G(k) \\propto k^{-2}$ 的解析形式是基于该算子是二阶微分算子的逆算子这一事实。我们选择函数族 $w_{reg}(k) = C/k^2$（对于 $k \\ne 0$），其中 $C$ 是一个待拟合的单标量参数。为了“拟合”$C$，我们对训练波数 $|k| \\in \\{2, \\dots, 6\\}$ 的理想权重 $G(k)$ 进行最小二乘回归。由于我们的模型族与真实算子完美匹配，这个拟合过程解析地得出 $C = 1/(4\\pi^2)$。得到的正则化权重对于所有 $k \\ne 0$ 都是 $w_{reg}(k) = G(k)$。通过引入正确的物理缩放，这个 FNO 学会了适用于所有频率的真实算子，而不仅仅是训练集中的那些频率。\n\n**4. 在测试用例上进行评估**\n\n这两个模型在一个测试套件上进行评估，其中 $\\mu \\in \\{1, 2, 6, 9\\}$。\n\n*   **分布内（$\\mu=2, \\mu=6$）：** 输入频率在训练集内。基线 FNO 和正则化 FNO 对于这些频率都具有正确的权重。两个模型都将生成与基准解相同的预测，导致误差接近于零。\n\n*   **外推（低频，$\\mu=1$）：** 输入频率 $\\mu=1$ 超出训练范围 $[\\mu_{min}, \\mu_{max}]=[2,6]$。基线 FNO 对于 $|k|=1$ 有 $w_{base}(k)=0$，所以其预测为 $u_{base}(x)=0$。由此产生的相对误差为 $1.0$。而正则化 FNO 学会了通用的 $k^{-2}$ 缩放定律，具有正确的权重，并生成一个误差接近于零的近乎完美的预测。基线模型的误差集中在 $|k|=1$ 处，该值不大于 $\\mu_{max}=6$，因此不会触发高频失败模式。\n\n*   **外推（高频，$\\mu=9$）：** 输入频率 $\\mu=9$ 同样超出了训练范围。基线 FNO 再次预测 $u_{base}(x)=0$，产生 $1.0$ 的相对误差。正则化 FNO 再次成功。在这种情况下，基线模型的误差完全集中在 $|k|=9$ 处。由于 $9  \\mu_{max}=6$，该能量位于高频带，谱失败诊断将被触发，从而正确识别出模型无法泛化到未见过的高频。\n\n这个实验设计清晰地展示了朴素数据驱动模型的一个主要失败模式——糟糕的外推能力——并演示了如何通过施加物理信息正则化来实现稳健的泛化。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Implements the full pipeline for training and evaluating FNOs on a 1D Poisson problem.\n    \"\"\"\n    # Fixed numerical choices from the problem statement\n    N = 128\n    mu_train_min = 2\n    mu_train_max = 6\n    mu_train = list(range(mu_train_min, mu_train_max + 1))\n    mu_test = [1, 2, 6, 9]\n    failure_threshold = 0.6\n\n    # Step 1: Construct a periodic grid and corresponding wavenumbers\n    x = np.arange(N) / N\n    k = np.fft.fftfreq(N, d=1.0/N)\n\n    # Step 2: Implement the ground-truth spectral solver\n    def solve_poisson_spectral(f_in, k_in):\n        \"\"\"Computes the solution to -u''=f using a spectral method.\"\"\"\n        f_hat = np.fft.fft(f_in)\n        \n        # The solution operator in Fourier space is multiplication by G(k) = 1/((2*pi*k)^2) for k!=0.\n        u_hat = np.zeros_like(f_hat)\n        nonzero_k_mask = k_in != 0\n        \n        k_nonzero = k_in[nonzero_k_mask]\n        # The analytical solution for the Fourier coefficients u_hat\n        u_hat[nonzero_k_mask] = (1.0 / (2 * np.pi * k_nonzero)**2) * f_hat[nonzero_k_mask]\n        \n        # Transform back to the spatial domain\n        u_out = np.fft.ifft(u_hat)\n        return u_out.real\n\n    # Step 3: Design and \"train\" the FNO models\n    # Baseline FNO: learns weights only for training wavenumbers\n    w_base = np.zeros(N, dtype=np.complex128)\n    for mu in mu_train:\n        # The ideal weight is from the Green's function\n        weight_val = 1.0 / (2 * np.pi * mu)**2\n        # Set weights for positive and negative wavenumbers (+mu, -mu)\n        w_base[mu] = weight_val\n        w_base[N - mu] = weight_val\n\n    # Regularized FNO: learns a structured physical model for the weights.\n    # The physically motivated family is w(k) = C/k^2. Fitting C to the training\n    # data analytically yields C = 1/(4*pi^2). Thus, the regularized model\n    # learns the exact analytical Green's function for all k.\n    w_reg = np.zeros(N, dtype=np.complex128)\n    nonzero_k_mask = k != 0\n    k_nonzero = k[nonzero_k_mask]\n    w_reg[nonzero_k_mask] = 1.0 / (2 * np.pi * k_nonzero)**2\n\n    # Step 4  5: Test models on the test suite and compute diagnostics\n    results = []\n    for mu in mu_test:\n        # Generate the forcing function for the current test case\n        f = np.sin(2 * np.pi * mu * x)\n        \n        # Compute the ground-truth solution\n        u_true = solve_poisson_spectral(f, k)\n        u_hat_true = np.fft.fft(u_true)\n\n        # Get predictions from both FNO models\n        f_hat = np.fft.fft(f)\n        \n        # Baseline FNO prediction\n        u_hat_base = w_base * f_hat\n        u_base = np.fft.ifft(u_hat_base).real\n        \n        # Regularized FNO prediction\n        u_hat_reg = w_reg * f_hat\n        u_reg = np.fft.ifft(u_hat_reg).real\n        \n        # Compute quantitative diagnostics\n        norm_u_true = np.linalg.norm(u_true)\n        \n        # Relative l2 error for both models\n        # A small epsilon is added to the denominator to prevent division by zero\n        # if the true solution norm is zero (not the case here, but good practice).\n        rel_err_base = np.linalg.norm(u_base - u_true) / (norm_u_true + 1e-12)\n        rel_err_reg = np.linalg.norm(u_reg - u_true) / (norm_u_true + 1e-12)\n        \n        # Boolean indicator of whether regularized error is strictly lower\n        is_improved = rel_err_reg  rel_err_base\n        \n        # Boolean indicator of the high-frequency error failure mode for the baseline FNO\n        e_hat_base = u_hat_base - u_hat_true\n        e_hat_base_energy = np.abs(e_hat_base)**2\n        total_energy = np.sum(e_hat_base_energy)\n        \n        if total_energy  1e-24:  # If error is numerically zero, no failure mode\n            is_fail_mode = False\n        else:\n            high_freq_mask = np.abs(k) > mu_train_max\n            high_freq_energy = np.sum(e_hat_base_energy[high_freq_mask])\n            is_fail_mode = (high_freq_energy / total_energy) > failure_threshold\n            \n        results.append([rel_err_base, rel_err_reg, is_improved, is_fail_mode])\n\n    # Final print statement in the exact required format.\n    # The default string representation of a list in Python includes spaces,\n    # so I use a custom formatter to get the comma-separated format without spaces.\n    formatted_results = []\n    for res in results:\n      formatted_results.append(f\"[{res[0]},{res[1]},{str(res[2]).lower()},{str(res[3]).lower()}]\")\n    print(f\"[{','.join(formatted_results)}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3427041"}]}