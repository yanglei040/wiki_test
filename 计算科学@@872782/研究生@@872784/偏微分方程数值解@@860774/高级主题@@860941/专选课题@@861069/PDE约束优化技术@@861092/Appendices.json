{"hands_on_practices": [{"introduction": "伴随法的基础在于对偶问题的正确构建。本练习将引导您从第一性原理出发，使用拉格朗日方法和分部积分推导伴随边界条件。掌握这一推导过程对于理解物理状态的约束如何转化为伴随状态的必要条件至关重要，这是PDE约束优化的基石 [@problem_id:3429633]。", "problem": "考虑一个有界域 $\\Omega \\subset \\mathbb{R}^{d}$，其边界 $\\Gamma$ 足够光滑，单位外法向量为 $\\boldsymbol{n}$。边界被划分为三个不相交的可测部分 $\\Gamma_{D}$、$\\Gamma_{N}$ 和 $\\Gamma_{R}$，使得 $\\overline{\\Gamma_{D}} \\cup \\overline{\\Gamma_{N}} \\cup \\overline{\\Gamma_{R}} = \\Gamma$。设 $\\kappa \\in C^{1}(\\overline{\\Omega})$ 满足对于所有 $\\boldsymbol{x} \\in \\overline{\\Omega}$ 都有 $\\kappa(\\boldsymbol{x}) \\ge \\kappa_{0} > 0$。给定一个期望状态 $y_{d} \\in L^{2}(\\Omega)$ 和一个控制 $u \\in L^{2}(\\Omega)$，状态 $y$ 由以下偏微分方程控制\n$$\n- \\nabla \\cdot \\big( \\kappa \\nabla y \\big) \\;=\\; u \\quad \\text{in } \\Omega,\n$$\n并带有混合边界条件\n$$\ny \\;=\\; 0 \\quad \\text{on } \\Gamma_{D}, \\qquad \\kappa \\nabla y \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{N}, \\qquad \\alpha\\, y \\;+\\; \\beta\\, \\kappa \\nabla y \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{R},\n$$\n其中 $\\alpha, \\beta \\in C(\\Gamma_{R})$ 且在每个 $\\boldsymbol{s} \\in \\Gamma_{R}$ 处 $(\\alpha(\\boldsymbol{s}), \\beta(\\boldsymbol{s})) \\neq (0,0)$。考虑二次跟踪代价泛函\n$$\nJ(y,u) \\;=\\; \\frac{1}{2} \\int_{\\Omega} \\big( y - y_{d} \\big)^{2} \\, \\mathrm{d}\\boldsymbol{x}.\n$$\n仅使用拉格朗日方法、伴随变量 $p$ 和基本的格林恒等式（分部积分），从第一性原理推导伴随边界条件，以确保拉格朗日量对于受给定边界约束的 $y$ 的变分是平稳的。特别地：\n- 通过显式的边界项分析，论证在 $\\Gamma_{D}$ 和 $\\Gamma_{N}$ 上的伴随边界条件必须是什么，并解释为什么它们的类型不同。\n- 通过对变分施加线性化边界约束来处理 Robin 边界段 $\\Gamma_{R}$，并推导出以下形式的 Robin 型伴随边界条件\n$$\n\\alpha^{\\ast} \\, p \\;+\\; \\beta^{\\ast} \\, \\kappa \\nabla p \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{R}.\n$$\n你的答案必须是伴随 Robin 系数的有序对 $(\\alpha^{\\ast}, \\beta^{\\ast})$，表示为单个行矩阵。不需要数值近似。请以闭式解析表达式的形式提供最终答案。最终答案中不要包含任何单位。", "solution": "我们从约束优化问题的拉格朗日量开始。引入伴随变量（拉格朗日乘子）$p \\in H^{1}(\\Omega)$ 并定义\n$$\n\\mathcal{L}(y,u,p) \\;=\\; \\frac{1}{2} \\int_{\\Omega} \\big( y - y_{d} \\big)^{2} \\, \\mathrm{d}\\boldsymbol{x} \\;+\\; \\int_{\\Omega} p \\Big( - \\nabla \\cdot \\big( \\kappa \\nabla y \\big) - u \\Big) \\, \\mathrm{d}\\boldsymbol{x}.\n$$\n为了推导伴随方程和边界条件，我们考虑 $\\mathcal{L}$ 关于 $y$ 在方向 $v$ 上的第一次变分。容许变分 $v$ 必须满足由状态边界约束导出的线性化边界条件，即\n$$\nv \\;=\\; 0 \\quad \\text{on } \\Gamma_{D}, \n\\qquad \\kappa \\nabla v \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{N}, \n\\qquad \\alpha\\, v \\;+\\; \\beta\\, \\kappa \\nabla v \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{R}.\n$$\n$\\mathcal{L}$ 关于 $y$ 在方向 $v$ 上的 Gâteaux 导数为\n$$\n\\delta_{y}\\mathcal{L}(y,u,p)[v] \\;=\\; \\int_{\\Omega} (y - y_{d})\\, v \\, \\mathrm{d}\\boldsymbol{x} \\;+\\; \\int_{\\Omega} p \\big( - \\nabla \\cdot (\\kappa \\nabla v) \\big) \\, \\mathrm{d}\\boldsymbol{x}.\n$$\n对第二个积分应用格林恒等式。对于足够光滑的 $p$ 和 $v$，\n$$\n\\int_{\\Omega} p \\big( - \\nabla \\cdot (\\kappa \\nabla v) \\big) \\, \\mathrm{d}\\boldsymbol{x}\n\\;=\\;\n- \\int_{\\Omega} v \\, \\nabla \\cdot (\\kappa \\nabla p) \\, \\mathrm{d}\\boldsymbol{x}\n\\;+\\; \\int_{\\Gamma} \\kappa \\Big( v \\, \\nabla p \\cdot \\boldsymbol{n} \\;-\\; (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\Big) \\, \\mathrm{d}s.\n$$\n因此\n$$\n\\delta_{y}\\mathcal{L}(y,u,p)[v]\n\\;=\\;\n\\int_{\\Omega} \\Big( (y - y_{d}) - \\nabla \\cdot (\\kappa \\nabla p) \\Big) v \\, \\mathrm{d}\\boldsymbol{x}\n\\;+\\; \\int_{\\Gamma} \\kappa \\Big( v \\, \\nabla p \\cdot \\boldsymbol{n} \\;-\\; (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\Big) \\, \\mathrm{d}s.\n$$\n对于所有容许变分 $v$ 的平稳性要求内部项对所有 $v$ 都为零，从而得到伴随偏微分方程\n$$\n- \\nabla \\cdot (\\kappa \\nabla p) \\;=\\; y - y_{d} \\quad \\text{in } \\Omega.\n$$\n剩下的任务是强制要求边界积分对于满足每个边界段上线性化边界条件的所有容許变分 $v$ 都为零。我们分别分析每个边界段。\n\n在 $\\Gamma_{D}$ 上：容許变分满足在 $\\Gamma_{D}$ 上 $v = 0$，而 $\\nabla v \\cdot \\boldsymbol{n}$ 不受此条件约束。限制在 $\\Gamma_{D}$ 上的边界积分简化为\n$$\n\\int_{\\Gamma_{D}} \\kappa \\Big( 0 \\cdot \\nabla p \\cdot \\boldsymbol{n} \\;-\\; (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\Big) \\, \\mathrm{d}s\n\\;=\\; - \\int_{\\Gamma_{D}} \\kappa \\, (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\, \\mathrm{d}s.\n$$\n因为在 $v=0$ 的条件下，$(\\nabla v \\cdot \\boldsymbol{n})$ 可以（在迹的意义上）任意选择，所以使该积分对所有这样的 $v$ 都为零的唯一方法是施加\n$$\np \\;=\\; 0 \\quad \\text{on } \\Gamma_{D}.\n$$\n因此，Dirichlet 状态边界条件在同一边界段上导出 Dirichlet 伴随边界条件。\n\n在 $\\Gamma_{N}$ 上：容許变分满足在 $\\Gamma_{N}$ 上 $\\kappa \\nabla v \\cdot \\boldsymbol{n} = 0$，而 $v$ 在 $\\Gamma_{N}$ 上不受其他约束。限制在 $\\Gamma_{N}$ 上的边界积分变为\n$$\n\\int_{\\Gamma_{N}} \\kappa \\Big( v \\, \\nabla p \\cdot \\boldsymbol{n} \\;-\\; 0 \\cdot p \\Big) \\, \\mathrm{d}s\n\\;=\\; \\int_{\\Gamma_{N}} \\kappa \\, v \\, \\nabla p \\cdot \\boldsymbol{n} \\, \\mathrm{d}s.\n$$\n因为 $v$ 在 $\\Gamma_{N}$ 上可以任意选择，所以使该积分对所有这样的 $v$ 都为零的唯一方法是施加\n$$\n\\kappa \\nabla p \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{N}.\n$$\n因此，Neumann 状态边界条件在同一边界段上导出 Neumann 伴随边界条件。这就解释了 Dirichlet 和 Neumann 情况之间的区别：在 $\\Gamma_{D}$ 上，$v$ 的迹固定为零，迫使 $p$ 为零；在 $\\Gamma_{N}$ 上，$v$ 的法向导数固定为零，迫使 $p$ 的法向通量为零。\n\n在 $\\Gamma_{R}$ 上：容許变分满足线性化的 Robin 约束\n$$\n\\alpha \\, v \\;+\\; \\beta \\, \\kappa \\nabla v \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{R}.\n$$\n限制在 $\\Gamma_{R}$ 上的边界积分可写作\n$$\n\\int_{\\Gamma_{R}} \\kappa \\Big( v \\, \\nabla p \\cdot \\boldsymbol{n} \\;-\\; (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\Big) \\, \\mathrm{d}s.\n$$\n为了对所有这样的 $v$ 强制其为零，只需消去 $v$ 而用 $\\nabla v \\cdot \\boldsymbol{n}$ 表示（反之亦然）。当边界点上 $\\alpha(\\boldsymbol{s}) \\neq 0$ 时，我们可以写出 $v \\,=\\, - (\\beta \\kappa / \\alpha) \\, \\nabla v \\cdot \\boldsymbol{n}$。逐点代入得到被积函数\n$$\n\\kappa \\left( - \\frac{\\beta \\kappa}{\\alpha} \\, (\\nabla v \\cdot \\boldsymbol{n}) \\, \\nabla p \\cdot \\boldsymbol{n} \\;-\\; (\\nabla v \\cdot \\boldsymbol{n}) \\, p \\right)\n\\;=\\;\n- \\kappa \\, (\\nabla v \\cdot \\boldsymbol{n}) \\left( \\frac{\\beta \\kappa}{\\alpha} \\, \\nabla p \\cdot \\boldsymbol{n} \\;+\\; p \\right).\n$$\n因为在线性化约束下 $(\\nabla v \\cdot \\boldsymbol{n})$ 可以任意选择，所以括号中的因子必须为零，从而得到\n$$\n\\alpha \\, p \\;+\\; \\beta \\, \\kappa \\nabla p \\cdot \\boldsymbol{n} \\;=\\; 0 \\quad \\text{on } \\Gamma_{R} \\cap \\{ \\alpha \\neq 0 \\}.\n$$\n一个对称的论证适用于 $\\beta(\\boldsymbol{s}) \\neq 0$ 的点，此时改为求解 $\\nabla v \\cdot \\boldsymbol{n}$ (用 $v$ 表示)，也会得到相同的条件。由于 $(\\alpha,\\beta)$ 不会同时为零，我们得出结论，在 $\\Gamma_{R}$ 各处的伴随 Robin 边界条件为\n$$\n\\alpha^{\\ast} \\, p \\;+\\; \\beta^{\\ast} \\, \\kappa \\nabla p \\cdot \\boldsymbol{n} \\;=\\; 0\n\\quad \\text{with} \\quad\n\\alpha^{\\ast} \\;=\\; \\alpha, \\;\\; \\beta^{\\ast} \\;=\\; \\beta.\n$$\n总之，通过分部积分和对变分 $v$ 施加线性化边界约束，可推断出\n- 在 $\\Gamma_{D}$ 上: $p = 0$ (Dirichlet)。\n- 在 $\\Gamma_{N}$ 上: $\\kappa \\nabla p \\cdot \\boldsymbol{n} = 0$ (Neumann)。\n- 在 $\\Gamma_{R}$ 上: $\\alpha p + \\beta \\kappa \\nabla p \\cdot \\boldsymbol{n} = 0$ (系数不变的 Robin 条件)。\n因此，伴随 Robin 系数的有序对是 $(\\alpha^{\\ast}, \\beta^{\\ast}) = (\\alpha, \\beta)$。", "answer": "$$\\boxed{\\begin{pmatrix}\\alpha  \\beta\\end{pmatrix}}$$", "id": "3429633"}, {"introduction": "建立连续最优性系统后，下一个挑战是为数值求解器创建一个可计算的版本。本练习专注于有限元离散化，旨在弥合连续理论与离散实现之间的鸿沟 [@problem_id:3429645]。您将推导出简化梯度的显式代数形式，揭示刚度矩阵和质量矩阵之间的相互作用，并提供驱动梯度类优化算法所需的向量。", "problem": "考虑以下线性二次最优控制问题，该问题受限于一个在有界多边形域 $\\Omega \\subset \\mathbb{R}^{2}$ 上的线性椭圆偏微分方程，并带有齐次狄利克雷边界条件。令 $V := H_{0}^{1}(\\Omega)$，并定义双线性形式 $a(\\cdot,\\cdot)$ 和 $L^{2}(\\Omega)$ 内积 $(\\cdot,\\cdot)$ 如下\n$$\na(y,v) := \\int_{\\Omega} \\nabla y \\cdot \\nabla v \\, dx + \\int_{\\Omega} c(x) \\, y \\, v \\, dx, \\quad (u,v) := \\int_{\\Omega} u \\, v \\, dx,\n$$\n其中 $c \\in L^{\\infty}(\\Omega)$ 满足 $c(x) \\ge 0$ 几乎处处成立。对于一个给定的期望状态 $y_{d} \\in L^{2}(\\Omega)$ 和正则化参数 $\\alpha > 0$，目标泛函为\n$$\nJ(y,u) := \\frac{1}{2} \\, \\| y - y_{d} \\|_{L^{2}(\\Omega)}^{2} + \\frac{\\alpha}{2} \\, \\| u \\|_{L^{2}(\\Omega)}^{2},\n$$\n其约束为弱形式的状态方程\n$$\na(y,v) = (u,v) \\quad \\text{对所有 } v \\in V.\n$$\n令 $V_{h} \\subset V$ 为一个协调有限元空间，其基为 $\\{ \\varphi_{i} \\}_{i=1}^{n}$，并在 $V_{h}$ 中将状态、伴随和控制近似为：\n$$\ny_{h} = \\sum_{i=1}^{n} y_{i} \\, \\varphi_{i}, \\quad p_{h} = \\sum_{i=1}^{n} p_{i} \\, \\varphi_{i}, \\quad u_{h} = \\sum_{i=1}^{n} u_{i} \\, \\varphi_{i}.\n$$\n定义刚度矩阵 $\\boldsymbol{K} \\in \\mathbb{R}^{n \\times n}$ 和质量矩阵 $\\boldsymbol{M} \\in \\mathbb{R}^{n \\times n}$ 如下：\n$$\n\\boldsymbol{K}_{ij} := a(\\varphi_{j}, \\varphi_{i}), \\quad \\boldsymbol{M}_{ij} := (\\varphi_{j}, \\varphi_{i}),\n$$\n并令 $\\boldsymbol{y}_{d} \\in \\mathbb{R}^{n}$ 表示 $y_{d}$ 在 $V_{h}$ 上的 $L^{2}(\\Omega)$ 投影的系数向量，即对所有 $v_{h} \\in V_{h}$ 都有 $(y_{d,h}, v_{h}) = (y_{d}, v_{h})$。离散的状态方程和伴随方程为\n$$\n\\boldsymbol{K} \\, \\boldsymbol{y} = \\boldsymbol{M} \\, \\boldsymbol{u}, \\quad \\boldsymbol{K} \\, \\boldsymbol{p} = \\boldsymbol{M} \\, (\\boldsymbol{y} - \\boldsymbol{y}_{d}),\n$$\n离散的既约目标泛函为\n$$\nj_{h}(\\boldsymbol{u}) := \\frac{1}{2} \\, (\\boldsymbol{y} - \\boldsymbol{y}_{d})^{\\top} \\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d}) + \\frac{\\alpha}{2} \\, \\boldsymbol{u}^{\\top} \\boldsymbol{M} \\boldsymbol{u},\n$$\n其中 $\\boldsymbol{y} = \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u}$。仅从这些定义和变分形式出发，通过离散伴随方程推导关于 $\\mathbb{R}^{n}$ 上欧几里得内积的离散既约梯度，然后消去伴随变量和状态变量，将此梯度完全用 $\\boldsymbol{K}$, $\\boldsymbol{M}$, $\\alpha$, $\\boldsymbol{u}$ 和 $\\boldsymbol{y}_{d}$ 表示。最后，评论此离散既约梯度与从 $L^{2}(\\Omega)$ 表达式 $\\alpha \\, u + p$ 得到的离散化连续梯度有何关系。\n\n你的最终答案必须是离散既约梯度向量关于 $\\boldsymbol{K}$、$\\boldsymbol{M}$、$\\alpha$、$\\boldsymbol{u}$ 和 $\\boldsymbol{y}_{d}$ 的单一闭式解析表达式，并用方框括起来。无需四舍五入，且不涉及物理单位。", "solution": "目标是推导离散既约目标泛函\n$$\nj_{h}(\\boldsymbol{u}) := \\frac{1}{2} \\, (\\boldsymbol{y} - \\boldsymbol{y}_{d})^{\\top} \\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d}) + \\frac{\\alpha}{2} \\, \\boldsymbol{u}^{\\top} \\boldsymbol{M} \\boldsymbol{u}\n$$\n关于 $\\mathbb{R}^{n}$ 上欧几里得内积的梯度。状态向量 $\\boldsymbol{y}$ 通过离散状态方程 $\\boldsymbol{K} \\boldsymbol{y} = \\boldsymbol{M} \\boldsymbol{u}$ 依赖于控制向量 $\\boldsymbol{u}$。问题规定使用离散伴随方法。\n\n让我们计算 $j_{h}(\\boldsymbol{u})$ 在任意方向 $\\delta \\boldsymbol{u} \\in \\mathbb{R}^{n}$ 上的 Gâteaux 导数。令 $\\boldsymbol{y}(\\boldsymbol{u}) = \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u}$。控制中的一个扰动 $\\delta \\boldsymbol{u}$ 会在状态中引起一个扰动 $\\delta \\boldsymbol{y}$，通过线性化状态方程得到：\n$$\n\\boldsymbol{K} \\, \\delta\\boldsymbol{y} = \\boldsymbol{M} \\, \\delta\\boldsymbol{u}.\n$$\n$j_{h}$ 的一阶变分为\n$$\n\\delta j_{h} = Dj_{h}(\\boldsymbol{u})[\\delta \\boldsymbol{u}] = (\\boldsymbol{y} - \\boldsymbol{y}_{d})^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{y} + \\alpha \\, \\boldsymbol{u}^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{u}.\n$$\n通常，为了更高效地计算梯度，会避免直接计算 $\\delta \\boldsymbol{y} = \\boldsymbol{K}^{-1} \\boldsymbol{M} \\delta \\boldsymbol{u}$ 并将其代入 $\\delta j_{h}$ 的表达式。伴随方法引入一个伴随状态 $\\boldsymbol{p}$ 来消去 $\\delta \\boldsymbol{y}$。\n\n问题给出了离散伴随方程：\n$$\n\\boldsymbol{K} \\boldsymbol{p} = \\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d}).\n$$\n双线性形式 $a(\\cdot,\\cdot)$ 是对称的，这意味着刚度矩阵 $\\boldsymbol{K}$ 是对称的，即 $\\boldsymbol{K}^{\\top} = \\boldsymbol{K}$。质量矩阵 $\\boldsymbol{M}$ 根据定义也是对称的，$\\boldsymbol{M}^{\\top} = \\boldsymbol{M}$。利用 $\\boldsymbol{K}$ 的对称性，伴随方程可以写为 $\\boldsymbol{K}^{\\top} \\boldsymbol{p} = \\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d})$。\n\n现在我们处理 $\\delta j_{h}$ 表达式中的第一项：\n$$\n(\\boldsymbol{y} - \\boldsymbol{y}_{d})^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{y} = (\\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d}))^{\\top} \\delta\\boldsymbol{y}.\n$$\n从伴随方程中代入 $\\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d})$ 的表达式：\n$$\n(\\boldsymbol{y} - \\boldsymbol{y}_{d})^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{y} = (\\boldsymbol{K}^{\\top} \\boldsymbol{p})^{\\top} \\delta\\boldsymbol{y} = \\boldsymbol{p}^{\\top} \\boldsymbol{K} \\, \\delta\\boldsymbol{y}.\n$$\n接下来，我们从扰动状态方程中代入 $\\boldsymbol{K} \\, \\delta\\boldsymbol{y}$ 的表达式：\n$$\n\\boldsymbol{p}^{\\top} \\boldsymbol{K} \\, \\delta\\boldsymbol{y} = \\boldsymbol{p}^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{u}.\n$$\n将此结果代回 $\\delta j_{h}$ 的表达式中：\n$$\n\\delta j_{h} = \\boldsymbol{p}^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{u} + \\alpha \\, \\boldsymbol{u}^{\\top} \\boldsymbol{M} \\, \\delta\\boldsymbol{u}.\n$$\n利用 $\\boldsymbol{M}$ 的对称性，我们可以将其重写为：\n$$\n\\delta j_{h} = (\\boldsymbol{M} \\boldsymbol{p})^{\\top} \\delta\\boldsymbol{u} + (\\alpha \\boldsymbol{M} \\boldsymbol{u})^{\\top} \\delta\\boldsymbol{u} = (\\alpha \\boldsymbol{M} \\boldsymbol{u} + \\boldsymbol{M} \\boldsymbol{p})^{\\top} \\delta\\boldsymbol{u}.\n$$\n$j_{h}$ 关于欧几里得内积的梯度，记作 $\\nabla j_{h}(\\boldsymbol{u})$，由关系式 $\\delta j_{h} = (\\nabla j_{h}(\\boldsymbol{u}))^{\\top} \\delta \\boldsymbol{u}$ 对所有 $\\delta \\boldsymbol{u}$ 定义。因此，我们确定梯度为：\n$$\n\\nabla j_{h}(\\boldsymbol{u}) = \\alpha \\boldsymbol{M} \\boldsymbol{u} + \\boldsymbol{M} \\boldsymbol{p} = \\boldsymbol{M} (\\alpha \\boldsymbol{u} + \\boldsymbol{p}).\n$$\n\n问题要求评论此表达式与连续梯度 $\\alpha u + p$ 的关系。在连续情形下，最优性条件是 $\\nabla J(u) = \\alpha u + p = 0$。向量 $\\boldsymbol{u}$ 和 $\\boldsymbol{p}$ 分别包含有限元函数 $u_{h} = \\sum_{i=1}^{n} u_{i} \\varphi_{i}$ 和 $p_{h} = \\sum_{i=1}^{n} p_{i} \\varphi_{i}$ 的系数。因此，向量 $\\alpha \\boldsymbol{u} + \\boldsymbol{p}$ 包含了函数 $\\alpha u_{h} + p_{h}$ 的系数。表达式 $\\boldsymbol{M}(\\alpha \\boldsymbol{u} + \\boldsymbol{p})$ 代表了此函数在有限元基函数上的投影，因为其第 $i$ 个分量是 $\\sum_{j} \\boldsymbol{M}_{ij} (\\alpha u_{j} + p_{j}) = \\sum_{j} (\\varphi_{j}, \\varphi_{i}) (\\alpha u_{j} + p_{j}) = (\\alpha u_{h} + p_{h}, \\varphi_{i})$。这正是 $L^2$ 梯度在欧几里得空间中的 Riesz 表示，通常被称为欧几里得梯度。\n\n最后，我们必须消去状态变量 $\\boldsymbol{y}$ 和伴随变量 $\\boldsymbol{p}$，以便将梯度完全用 $\\boldsymbol{K}$、$\\boldsymbol{M}$、$\\alpha$、$\\boldsymbol{u}$ 和 $\\boldsymbol{y}_{d}$ 表示。我们有以下方程组：\n1. 状态：$\\boldsymbol{y} = \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u}$\n2. 伴随：$\\boldsymbol{p} = \\boldsymbol{K}^{-1} \\boldsymbol{M} (\\boldsymbol{y} - \\boldsymbol{y}_{d})$\n\n将 (1) 代入 (2)：\n$$\n\\boldsymbol{p} = \\boldsymbol{K}^{-1} \\boldsymbol{M} (\\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u} - \\boldsymbol{y}_{d}).\n$$\n现在将 $\\boldsymbol{p}$ 的这个表达式代入梯度公式 $\\nabla j_{h}(\\boldsymbol{u}) = \\boldsymbol{M} (\\alpha \\boldsymbol{u} + \\boldsymbol{p})$：\n$$\n\\nabla j_{h}(\\boldsymbol{u}) = \\boldsymbol{M} \\left( \\alpha \\boldsymbol{u} + \\boldsymbol{K}^{-1} \\boldsymbol{M} (\\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u} - \\boldsymbol{y}_{d}) \\right).\n$$\n展开此表达式得到梯度的最终形式：\n$$\n\\nabla j_{h}(\\boldsymbol{u}) = \\alpha \\boldsymbol{M} \\boldsymbol{u} + \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{u} - \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{y}_{d}.\n$$\n这可以分组为：\n$$\n\\nabla j_{h}(\\boldsymbol{u}) = (\\alpha \\boldsymbol{M} + \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M}) \\boldsymbol{u} - \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{y}_{d}.\n$$\n这就是所要求的离散既约梯度的闭式表达式。", "answer": "$$\n\\boxed{(\\alpha \\boldsymbol{M} + \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M}) \\boldsymbol{u} - \\boldsymbol{M} \\boldsymbol{K}^{-1} \\boldsymbol{M} \\boldsymbol{y}_{d}}\n$$", "id": "3429645"}, {"introduction": "伴随法的强大威力远不止于经典优化问题，它已成为现代物理知识驱动的机器学习（physics-informed machine learning）的关键引擎。这项高级练习将挑战您在一个新颖的背景下应用伴随技术：训练一个生成模型，使其产生的解符合热传导方程 [@problem_id:3429635]。通过推导离散PDE残差算子的伴随算子，您将实现一种高效的梯度计算方法，这是许多科学机器学习工作流程中的关键一步。", "problem": "考虑与单位时空域上的热方程相关的偏微分方程(PDE)残差算子，其定义为 $r(y) = \\partial_t y - \\Delta y$，其中 $y$ 是 $[0,1] \\times [0,1] \\times [0,1]$ 上的一个标量场，包含空间变量和时间。设空间域在 $x$ 方向上由 $N_x$ 个点离散化，在 $y$ 方向上由 $N_y$ 个点离散化，时间由 $N_t$ 个点离散化，所有点都均匀分布。记网格间距为 $\\Delta x = 1/(N_x - 1)$，$\\Delta y = 1/(N_y - 1)$ 和 $\\Delta t = 1/(N_t - 1)$。设内部空间索引为 $i \\in \\{1, \\dots, N_x - 2\\}$ 和 $j \\in \\{1, \\dots, N_y - 2\\}$，时间索引为 $n \\in \\{0, \\dots, N_t - 2\\}$。\n\n在内部点上，通过标准的时间显式前向差分和拉普拉斯算子的五点差分格式（齐次狄利克雷边界值为 $0$）来定义离散残差：\n$$\nr_{n,i,j}(y) = \\frac{y_{n+1,i,j} - y_{n,i,j}}{\\Delta t} - \\frac{y_{n,i+1,j} + y_{n,i-1,j} + y_{n,i,j+1} + y_{n,i,j-1} - 4 y_{n,i,j}}{\\Delta x^2},\n$$\n其中 $y_{n,i,j}$ 表示 $y$ 在时间索引 $n$ 和空间索引 $(i,j)$ 处的值，拉普拉斯算子在时间索引 $n$ 处计算。假设 $\\Delta x = \\Delta y$。\n\n设生成器通过一组固定的基函数 $\\{\\phi_k\\}_{k=1}^K$ 生成样本 $y_\\theta$，该样本由参数向量 $\\theta \\in \\mathbb{R}^K$ 线性参数化：\n$$\ny_\\theta(n,i,j) = \\sum_{k=1}^K \\theta_k \\, \\phi_k(n,i,j).\n$$\n基函数被指定为在空间边界上为零的正弦函数的可分离乘积，\n$$\n\\phi_k(n,i,j) = \\sin\\!\\left(p_x^{(k)} \\pi x_i\\right) \\, \\sin\\!\\left(p_y^{(k)} \\pi y_j\\right) \\, \\sin\\!\\left(\\beta^{(k)} \\pi t_n\\right),\n$$\n其中 $x_i = i \\Delta x$，$y_j = j \\Delta y$，$t_n = n \\Delta t$。整数 $p_x^{(k)}$、$p_y^{(k)}$ 和 $\\beta^{(k)}$ 指定了空间和时间频率。齐次狄利克雷边界条件通过空间正弦因子隐式地强制执行。\n\n定义残差惩罚泛函\n$$\nR(\\theta) = \\sum_{n=0}^{N_t-2} \\sum_{i=1}^{N_x-2} \\sum_{j=1}^{N_y-2} \\left( r_{n,i,j}\\!\\left(y_\\theta\\right) \\right)^2.\n$$\n\n任务：\n1. 在离散网格上的标准欧几里得内积下，推导残差算子 $A$（使得 $r = A y$）的离散伴随算子 $A^\\ast$，并用它将梯度 $\\nabla_\\theta R(\\theta)$ 表示为 $\\theta$ 和基函数 $\\phi_k$ 的显式函数。\n2. 实现一个程序，使用残差算子的伴随算子为给定的测试用例计算 $R(\\theta)$ 和 $\\nabla_\\theta R(\\theta)$。\n3. 对于每个测试用例，将基于伴随方法的梯度与梯度的数值中心有限差分近似进行验证，并报告由下式定义的相对误差：\n$$\n\\mathrm{err} = \\frac{\\left\\|\\nabla_\\theta R(\\theta)\\big|_{\\text{adjoint}} - \\nabla_\\theta R(\\theta)\\big|_{\\text{finite diff}}\\right\\|_2}{\\max\\!\\left(10^{-12}, \\left\\|\\nabla_\\theta R(\\theta)\\big|_{\\text{adjoint}}\\right\\|_2\\right)}.\n$$\n在中心有限差分中使用扰动大小 $\\varepsilon = 10^{-6}$。\n\n测试套件：\n为以下三个测试用例提供结果。在每个用例中，都指定了空间和时间频率 $(p_x^{(k)}, p_y^{(k)}, \\beta^{(k)})$以及参数向量 $\\theta$。\n\n- 测试用例 1 (边界情况，零参数):\n  - $N_x = 10$, $N_y = 10$, $N_t = 5$。\n  - 基函数频率: $\\left[(1,1,1), (2,1,1)\\right]$。\n  - 参数: $\\theta = [0, 0]$。\n\n- 测试用例 2 (一般情况):\n  - $N_x = 16$, $N_y = 16$, $N_t = 12$。\n  - 基函数频率: $\\left[(1,2,1), (2,2,1), (3,1,2)\\right]$。\n  - 参数: $\\theta = [0.4, -0.3, 0.2]$。\n\n- 测试用例 3 (时间边界，最少时间层级):\n  - $N_x = 12$, $N_y = 12$, $N_t = 2$。\n  - 基函数频率: $\\left[(1,1,1), (2,3,1), (3,3,1), (4,1,2)\\right]$。\n  - 参数: $\\theta = [0.1, -0.2, 0.05, 0.3]$。\n\n最终输出格式：\n你的程序应生成单行输出，其中包含三个测试用例的相对误差，格式为用方括号括起来的逗号分隔列表（例如 $\\left[ \\mathrm{err}_1, \\mathrm{err}_2, \\mathrm{err}_3 \\right]$）。列表中的条目必须是十进制数。", "solution": "### 1. 理论推导\n\n主要任务是计算残差惩罚泛函 $R(\\theta)$ 的梯度。伴随方法为计算此梯度提供了一种高效的方式。\n\n**1.1. 离散化公式**\n\n设状态向量 $y$ 是离散网格上值的集合 $\\{y_{n,i,j}\\}$。为简化起见，我们将 $y$ 视为空间 $\\mathcal{Y} = \\mathbb{R}^{N_t \\times (N_x-2) \\times (N_y-2)}$ 中的一个向量，表示所有时间步长上内部空间网格的解。基函数 $\\phi_k$ 也受限于此网格。 $\\mathcal{Y}$ 上的标准欧几里得内积定义为：\n$$\n\\langle y, p \\rangle_{\\mathcal{Y}} = \\sum_{n=0}^{N_t-1} \\sum_{i=1}^{N_x-2} \\sum_{j=1}^{N_y-2} y_{n,i,j} p_{n,i,j}\n$$\n离散残差 $r$ 是空间 $\\mathcal{R} = \\mathbb{R}^{(N_t-1) \\times (N_x-2) \\times (N_y-2)}$ 中的一个向量。 $\\mathcal{R}$ 上的内积为：\n$$\n\\langle r, q \\rangle_{\\mathcal{R}} = \\sum_{n=0}^{N_t-2} \\sum_{i=1}^{N_x-2} \\sum_{j=1}^{N_y-2} r_{n,i,j} q_{n,i,j}\n$$\n离散残差算子 $A: \\mathcal{Y} \\to \\mathcal{R}$ 是由给定公式定义的线性算子：\n$$\n(Ay)_{n,i,j} = \\frac{y_{n+1,i,j} - y_{n,i,j}}{\\Delta t} - \\frac{y_{n,i+1,j} + y_{n,i-1,j} + y_{n,i,j+1} + y_{n,i,j-1} - 4 y_{n,i,j}}{\\Delta x^2}\n$$\n其中，对于邻近边界的点，在拉普拉斯算子格式中使用了齐次狄利克雷边界条件 $y_{n,0,j} = y_{n,N_x-1,j} = y_{n,i,0} = y_{n,i,N_y-1} = 0$。我们可以将 $A$ 写为 $A = \\partial_t^+ - \\Delta_d$，其中 $\\partial_t^+$ 是前向时间差分算子，$\\Delta_d$ 是离散拉普拉斯算子。\n\n**1.2. 通过伴随方法计算梯度**\n\n泛函为 $R(\\theta) = \\langle r(y_\\theta), r(y_\\theta) \\rangle_{\\mathcal{R}}$。状态 $y_\\theta$ 是 $\\theta$ 的线性函数：$y_\\theta = \\sum_{k=1}^K \\theta_k \\phi_k$。由于 $A$ 的线性，残差对于 $\\theta$ 也是线性的：$r(y_\\theta) = A y_\\theta = \\sum_{k=1}^K \\theta_k A \\phi_k$。\n\n关于 $\\theta_m$ 的梯度分量使用链式法则求得：\n$$\n\\frac{\\partial R}{\\partial \\theta_m} = 2 \\left\\langle r(y_\\theta), \\frac{\\partial r(y_\\theta)}{\\partial \\theta_m} \\right\\rangle_{\\mathcal{R}} = 2 \\langle r(y_\\theta), A \\phi_m \\rangle_{\\mathcal{R}}\n$$\n引入伴随算子 $A^*: \\mathcal{R} \\to \\mathcal{Y}$，其定义关系为对于所有 $y \\in \\mathcal{Y}, q \\in \\mathcal{R}$ 都有 $\\langle A y, q \\rangle_{\\mathcal{R}} = \\langle y, A^* q \\rangle_{\\mathcal{Y}}$，我们可以重写梯度表达式：\n$$\n\\frac{\\partial R}{\\partial \\theta_m} = 2 \\langle \\phi_m, A^* r(y_\\theta) \\rangle_{\\mathcal{Y}}\n$$\n这是伴随方法的核心。我们定义伴随状态（或协态）向量 $p \\in \\mathcal{Y}$ 为 $p = A^* r(y_\\theta)$。然后梯度计算如下：\n$$\n(\\nabla_\\theta R(\\theta))_m = 2 \\langle \\phi_m, p \\rangle_{\\mathcal{Y}}\n$$\n计算过程如下：\n1. 对于给定的 $\\theta$，计算状态 $y_\\theta = \\sum_k \\theta_k \\phi_k$。\n2. 计算残差 $r = r(y_\\theta)$。\n3. 计算伴随状态 $p = A^* r$。这需要推导算子 $A^*$。\n4. 使用基函数 $\\phi_m$ 和伴随状态 $p$ 之间的内积计算梯度。\n\n**1.3. 伴随算子 $A^*$ 的推导**\n\n我们有 $A = \\partial_t^+ - \\Delta_d$，所以 $A^* = (\\partial_t^+)^* - \\Delta_d^*$。\n\n- **离散拉普拉斯算子 ($-\\Delta_d$) 的伴随算子**：具有齐次狄利克雷边界条件的离散五点拉普拉斯算子格式是一个对称算子。因此，它是自伴的：$(-\\Delta_d)^* = -\\Delta_d$。\n\n- **前向时间差分 ($\\partial_t^+$) 的伴随算子**：我们通过分部求和来推导伴随算子。对于任何 $y \\in \\mathcal{Y}$ 和 $q \\in \\mathcal{R}$：\n$$\n\\langle \\partial_t^+ y, q \\rangle_{\\mathcal{R}} = \\sum_{n=0}^{N_t-2} \\left\\langle \\frac{y_{n+1} - y_n}{\\Delta t}, q_n \\right\\rangle_{space}\n$$\n其中 $\\langle \\cdot, \\cdot \\rangle_{space}$ 是单个空间切片上的内积。重新排列各项：\n$$\n= \\frac{1}{\\Delta t} \\left( \\sum_{n=0}^{N_t-2} \\langle y_{n+1}, q_n \\rangle - \\sum_{n=0}^{N_t-2} \\langle y_n, q_n \\rangle \\right)\n= \\frac{1}{\\Delta t} \\left( \\sum_{n'=1}^{N_t-1} \\langle y_{n'}, q_{n'-1} \\rangle - \\sum_{n=0}^{N_t-2} \\langle y_n, q_n \\rangle \\right)\n$$\n分离时间边界项（对于 $y$，$n=0$ 和 $n=N_t-1$）：\n$$\n= \\left\\langle y_0, -\\frac{q_0}{\\Delta t} \\right\\rangle + \\sum_{n=1}^{N_t-2} \\left\\langle y_n, \\frac{q_{n-1} - q_n}{\\Delta t} \\right\\rangle + \\left\\langle y_{N_t-1}, \\frac{q_{N_t-2}}{\\Delta t} \\right\\rangle\n$$\n这必须等于 $\\langle y, (\\partial_t^+)^* q \\rangle_{\\mathcal{Y}} = \\sum_{n=0}^{N_t-1} \\langle y_n, ((\\partial_t^+)^* q)_n \\rangle$。通过比较每个 $y_n$ 的项，我们识别出 $((\\partial_t^+)^* q)$ 的分量：\n\\begin{align*}\n((\\partial_t^+)^* q)_n =  \\begin{cases} -q_0 / \\Delta t & n=0 \\\\ (q_{n-1} - q_n) / \\Delta t & 1 \\le n \\le N_t-2 \\\\ q_{N_t-2} / \\Delta t & n=N_t-1 \\end{cases}\n\\end{align*}\n\n结合空间和时间部分，伴随运算 $p = A^* q$ 由以下系统给出：\n\\begin{align*}\np_{N_t-1} &= \\frac{q_{N_t-2}}{\\Delta t} \\\\\np_n &= \\frac{q_{n-1} - q_n}{\\Delta t} - \\Delta_d q_n \\quad \\text{for } n = N_t-2, \\dots, 1 \\\\\np_0 &= -\\frac{q_0}{\\Delta t} - \\Delta_d q_0\n\\end{align*}\n这是一个必须从最终时间 $n=N_t-1$ 开始，随时间*向后*求解 $p$ 的系统。\n\n### 2. 实现策略\n\n实现直接遵循推导出的公式。\n\n1.  **网格和基函数**：对于每个测试用例，建立离散网格坐标 $x_i, y_j, t_n$。为所有的 $k,n,i,j$ 计算基函数 $\\phi_k(n,i,j)$ 并存储它们。\n2.  **伴随梯度计算**：\n    a.  使用 $y_\\theta = \\sum_k \\theta_k \\phi_k$ 在整个网格上计算状态 $y_\\theta$。使用向量化的 `einsum` 对此很高效。\n    b.  对于 $n \\in \\{0, \\dots, N_t-2\\}$，在内部网格上计算离散残差 $r = A y_\\theta$。这涉及应用离散时间导数和拉普拉斯算子。\n    c.  通过应用推导出的时间上向后的伴随方程来计算伴随状态 $p = A^* r$。计算从 $p_{N_t-1}$ 向下进行到 $p_0$。\n    d.  通过计算内积 $2\\langle\\phi_m, p\\rangle_{\\mathcal{Y}}$ 来计算梯度的每个分量 $(\\nabla_\\theta R(\\theta))_m$。\n3.  **有限差分梯度计算**：为了验证，使用中心差分公式对梯度进行数值近似：\n    $$\n    (\\nabla_\\theta R(\\theta))_m \\approx \\frac{R(\\theta + \\varepsilon e_m) - R(\\theta - \\varepsilon e_m)}{2\\varepsilon}\n    $$\n    其中 $e_m$ 是第 $m$ 个标准基向量，$\\varepsilon=10^{-6}$ 是一个小的扰动。这需要对目标泛函 $R$ 进行 $2K$ 次评估。\n4.  **误差计算**：伴随梯度 $\\nabla_{\\text{adj}}$ 和有限差分近似 $\\nabla_{\\text{fd}}$ 之间的相对误差按指定方式计算：\n    $$\n    \\mathrm{err} = \\frac{\\|\\nabla_{\\text{adj}} - \\nabla_{\\text{fd}}\\|_2}{\\max(10^{-12}, \\|\\nabla_{\\text{adj}}\\|_2)}\n    $$\n\n所提供的 Python 代码使用 `numpy` 来实现此策略，以进行高效的数组操作。", "answer": "```python\nimport numpy as np\n\ndef apply_laplacian_to_y(y_slice, dx2):\n    \"\"\"Computes the Laplacian of a 2D slice y_n, returning it on the interior.\"\"\"\n    lap = (y_slice[2:, 1:-1] + y_slice[:-2, 1:-1] + \n           y_slice[1:-1, 2:] + y_slice[1:-1, :-2] - \n           4 * y_slice[1:-1, 1:-1]) / dx2\n    return lap\n\ndef apply_laplacian_to_q(q_slice, dx2):\n    \"\"\"Computes the Laplacian of a 2D slice q_n on the interior grid, assuming zero padding.\"\"\"\n    q_padded = np.pad(q_slice, pad_width=1, mode='constant', constant_values=0)\n    lap = (q_padded[2:, 1:-1] + q_padded[:-2, 1:-1] + \n           q_padded[1:-1, 2:] + q_padded[1:-1, :-2] - \n           4 * q_padded[1:-1, 1:-1]) / dx2\n    return lap\n\ndef compute_residual(y, dx, dt):\n    \"\"\"Computes the discrete residual r = A*y.\"\"\"\n    Nt, Nx, Ny = y.shape\n    dx2 = dx**2\n    r = np.zeros((Nt - 1, Nx - 2, Ny - 2))\n    \n    for n in range(Nt - 1):\n        y_forward = y[n + 1, 1:Nx-1, 1:Ny-1]\n        y_current = y[n, 1:Nx-1, 1:Ny-1]\n        dt_term = (y_forward - y_current) / dt\n        lap_y_n = apply_laplacian_to_y(y[n], dx2)\n        r[n, :, :] = dt_term - lap_y_n\n    return r\n\ndef compute_objective(r):\n    \"\"\"Computes the objective functional R = ||r||^2.\"\"\"\n    return np.sum(r**2)\n\ndef apply_adjoint(r, dx, dt):\n    \"\"\"Computes the adjoint state p = A*r by solving the backward system.\"\"\"\n    Nt_res, Nx_int, Ny_int = r.shape\n    Nt = Nt_res + 1\n    dx2 = dx**2\n    \n    p = np.zeros((Nt, Nx_int, Ny_int))\n\n    lap_r = np.zeros_like(r)\n    for n in range(Nt_res):\n        lap_r[n, :, :] = apply_laplacian_to_q(r[n], dx2)\n\n    if Nt > 1:\n        # Final time step for adjoint state p\n        p[Nt-1] = r[Nt-2] / dt\n        \n        # Backward time stepping for n = Nt-2 down to 1\n        for n in range(Nt - 2, 0, -1):\n            p[n] = (r[n-1] - r[n]) / dt - lap_r[n]\n        \n        # Initial time step for adjoint state p\n        p[0] = -r[0] / dt - lap_r[0]\n        \n    return p\n\ndef compute_y_theta(theta, phi):\n    \"\"\"Computes y_theta = sum(theta_k * phi_k).\"\"\"\n    return np.einsum('k,knij->nij', theta, phi)\n\ndef process_case(Nx, Ny, Nt, freqs, theta, eps):\n    \"\"\"Runs a single test case to compute the gradient validation error.\"\"\"\n    dx = 1.0 / (Nx - 1)\n    dt = 1.0 / (Nt - 1) if Nt > 1 else 1.0\n\n    x = np.linspace(0, 1, Nx)\n    y_coords = np.linspace(0, 1, Ny)\n    t = np.linspace(0, 1, Nt)\n    \n    K = len(freqs)\n    phi = np.zeros((K, Nt, Nx, Ny))\n    for k in range(K):\n        px, py, beta = freqs[k]\n        sin_x = np.sin(px * np.pi * x)\n        sin_y = np.sin(py * np.pi * y_coords)\n        sin_t = np.sin(beta * np.pi * t)\n        phi[k] = np.outer(sin_t, np.outer(sin_x, sin_y)).reshape(Nt, Nx, Ny)\n\n    # --- Adjoint Gradient Calculation ---\n    y_theta = compute_y_theta(theta, phi)\n    r = compute_residual(y_theta, dx, dt)\n    p = apply_adjoint(r, dx, dt)\n    \n    grad_adj = np.zeros(K)\n    phi_interior = phi[:, :, 1:Nx-1, 1:Ny-1]\n    for k in range(K):\n        grad_adj[k] = 2 * np.sum(phi_interior[k] * p)\n        \n    # --- Finite Difference Gradient Calculation ---\n    grad_fd = np.zeros(K)\n    theta_arr = np.array(theta, dtype=float)\n    for k in range(K):\n        theta_plus =  theta_arr.copy()\n        theta_plus[k] += eps\n        y_plus = compute_y_theta(theta_plus, phi)\n        r_plus = compute_residual(y_plus, dx, dt)\n        R_plus = compute_objective(r_plus)\n        \n        theta_minus = theta_arr.copy()\n        theta_minus[k] -= eps\n        y_minus = compute_y_theta(theta_minus, phi)\n        r_minus = compute_residual(y_minus, dx, dt)\n        R_minus = compute_objective(r_minus)\n        \n        grad_fd[k] = (R_plus - R_minus) / (2 * eps)\n        \n    # --- Error Calculation ---\n    norm_adj = np.linalg.norm(grad_adj)\n    norm_diff = np.linalg.norm(grad_adj - grad_fd)\n    \n    error = norm_diff / max(1e-12, norm_adj)\n    return error\n\ndef solve():\n    \"\"\"Main function to run all test cases and print results.\"\"\"\n    test_cases = [\n        {'Nx': 10, 'Ny': 10, 'Nt': 5, 'freqs': [(1, 1, 1), (2, 1, 1)], 'theta': [0.0, 0.0]},\n        {'Nx': 16, 'Ny': 16, 'Nt': 12, 'freqs': [(1, 2, 1), (2, 2, 1), (3, 1, 2)], 'theta': [0.4, -0.3, 0.2]},\n        {'Nx': 12, 'Ny': 12, 'Nt': 2, 'freqs': [(1, 1, 1), (2, 3, 1), (3, 3, 1), (4, 1, 2)], 'theta': [0.1, -0.2, 0.05, 0.3]}\n    ]\n    eps = 1e-6\n    results = []\n    \n    for case in test_cases:\n        error = process_case(case['Nx'], case['Ny'], case['Nt'],\n                             case['freqs'], case['theta'], eps)\n        results.append(error)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n\n```", "id": "3429635"}]}