{"hands_on_practices": [{"introduction": "在计算流体动力学中，梯度重构是基于离散数据估算连续场梯度的核心任务。加权最小二乘法 (WLS) 是实现这一目标的强大工具，它允许我们为不同数据点分配不同的重要性。本实践将引导您从第一性原理推导加权最小二乘法的正规方程，并通过具体的数值算例，展示不同权重策略（例如，均匀权重与基于距离的权重）如何影响重构梯度的结果及其统计确定性 [@problem_id:3339283]。", "problem": "标量场 $u(\\boldsymbol{x})$ 在一个中心控制体质心 $\\boldsymbol{x}_{0}=(0,0)$ 周围的非结构化二维模板上进行采样。邻近点的偏移量为 $\\boldsymbol{r}_{1}=(1,0)$，$\\boldsymbol{r}_{2}=(0,1)$，$\\boldsymbol{r}_{3}=(-1,0)$，$\\boldsymbol{r}_{4}=(0,-1)$ 和 $\\boldsymbol{r}_{5}=(1,1)$。相对于中心测得的增量为 $\\Delta u_{1}=1.25$，$\\Delta u_{2}=-0.72$，$\\Delta u_{3}=-1.17$，$\\Delta u_{4}=0.69$ 和 $\\Delta u_{5}=0.54$，均为无量纲。使用线性化重构模型 $\\Delta u_{i}\\approx \\boldsymbol{r}_{i}\\cdot \\boldsymbol{g}$，其中 $\\boldsymbol{g}=(g_{x},g_{y})^{\\mathsf{T}}$ 是质心处的梯度，并构建加权最小二乘目标函数 $J(\\boldsymbol{g})=\\sum_{i=1}^{5}w_{i}\\left(\\boldsymbol{r}_{i}\\cdot \\boldsymbol{g}-\\Delta u_{i}\\right)^{2}$。\n\n从该模型和加权最小二乘的定义出发，从第一性原理推导正规方程，并求解它们以获得在以下两种权重选择下的重构梯度 $\\boldsymbol{g}$：\n- 均匀权重 $W_{1}=\\mathrm{diag}(1,1,1,1,1)$。\n- 基于距离的权重 $W_{2}=\\mathrm{diag}(1,1,1,1,1/2)$。\n\n假设测量误差是独立的且具有共同方差，因此有 $\\Delta u_{i}= \\boldsymbol{r}_{i}\\cdot \\boldsymbol{g}_{\\mathrm{true}}+\\varepsilon_{i}$，其中 $\\mathbb{E}[\\varepsilon_{i}]=0$ 且 $\\mathrm{Cov}(\\varepsilon)=\\sigma^{2}I$。在此假设下，使用从上述目标函数推导出的加权最小二乘估计量协方差的通用表达式，计算分别使用 $W_{2}$ 和 $W_{1}$ 得到的 $\\boldsymbol{g}$ 的协方差矩阵的行列式之比。\n\n将您的最终答案表示为一个单行矩阵，其中包含按以下顺序排列的五个条目：使用 $W_{1}$ 时的 $g_{x}$，使用 $W_{1}$ 时的 $g_{y}$，使用 $W_{2}$ 时的 $g_{x}$，使用 $W_{2}$ 时的 $g_{y}$，以及行列式之比 $\\det\\left(\\mathrm{Cov}_{W_{2}}(\\boldsymbol{g})\\right)/\\det\\left(\\mathrm{Cov}_{W_{1}}(\\boldsymbol{g})\\right)$。将您的数值条目四舍五入到四位有效数字。不需要物理单位。", "solution": "用户希望解决一个加权最小二乘问题来估计梯度向量。\n\n### 问题验证\n\n**第1步：提取已知条件**\n- 一个标量场表示为 $u(\\boldsymbol{x})$。\n- 中心点位于 $\\boldsymbol{x}_{0}=(0,0)$。\n- 邻近点偏移量为 $\\boldsymbol{r}_{1}=(1,0)$，$\\boldsymbol{r}_{2}=(0,1)$，$\\boldsymbol{r}_{3}=(-1,0)$，$\\boldsymbol{r}_{4}=(0,-1)$ 和 $\\boldsymbol{r}_{5}=(1,1)$。\n- 测得的增量为 $\\Delta u_{1}=1.25$，$\\Delta u_{2}=-0.72$，$\\Delta u_{3}=-1.17$，$\\Delta u_{4}=0.69$ 和 $\\Delta u_{5}=0.54$。\n- 线性化模型为 $\\Delta u_{i}\\approx \\boldsymbol{r}_{i}\\cdot \\boldsymbol{g}$，其中 $\\boldsymbol{g}=(g_{x},g_{y})^{\\mathsf{T}}$ 是梯度。\n- 加权最小二乘目标函数为 $J(\\boldsymbol{g})=\\sum_{i=1}^{5}w_{i}\\left(\\boldsymbol{r}_{i}\\cdot \\boldsymbol{g}-\\Delta u_{i}\\right)^{2}$。\n- 指定了两个权重矩阵：\n    1. 均匀权重：$W_{1}=\\mathrm{diag}(1,1,1,1,1)$。\n    2. 基于距离的权重：$W_{2}=\\mathrm{diag}(1,1,1,1,1/2)$。\n- 误差模型为 $\\Delta u_{i}= \\boldsymbol{r}_{i}\\cdot \\boldsymbol{g}_{\\mathrm{true}}+\\varepsilon_{i}$，其中 $\\mathbb{E}[\\varepsilon_{i}]=0$ 且 $\\mathrm{Cov}(\\varepsilon)=\\sigma^{2}I$。\n- 任务是推导正规方程，求解两种权重集下的 $\\boldsymbol{g}$，并计算估计量协方差矩阵的行列式之比 $\\det\\left(\\mathrm{Cov}_{W_{2}}(\\boldsymbol{g})\\right)/\\det\\left(\\mathrm{Cov}_{W_{1}}(\\boldsymbol{g})\\right)$。\n- 数值结果应四舍五入到四位有效数字。\n\n**第2步：使用提取的已知条件进行验证**\n- **科学依据：** 该问题描述了用于从散乱数据重构梯度的加权最小二乘法。这是计算流体动力学、有限元分析和其他计算科学领域中一种标准且广泛使用的技术。其基本原理基于泰勒级数展开和统计估计，这些都是已经很成熟的理论。\n- **适定性：** 该问题被构造为一个线性最小二乘问题。设计矩阵 $\\boldsymbol{A}$（其行为 $\\boldsymbol{r}_i^{\\mathsf{T}}$）是满列秩的，权重矩阵 $\\boldsymbol{W}_1$ 和 $\\boldsymbol{W}_2$ 是正定的。这确保了矩阵 $\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A}$ 是可逆的，从而保证了梯度 $\\boldsymbol{g}$ 的唯一解。\n- **客观性：** 该问题使用精确的数学语言和定义进行陈述。所有量都有明确的定义。不存在主观或基于观点的陈述。\n- 该问题是自洽的，提供了所有必要的数据和模型。它不矛盾、不切实际、不适定或微不足道。\n\n**第3步：结论与行动**\n该问题有效。将提供完整的解答。\n\n### 推导与求解\n\n问题是找到梯度向量 $\\boldsymbol{g} = (g_x, g_y)^{\\mathsf{T}}$，使其最小化加权最小二乘目标函数：\n$$ J(\\boldsymbol{g}) = \\sum_{i=1}^{5} w_i (\\boldsymbol{r}_i \\cdot \\boldsymbol{g} - \\Delta u_i)^2 $$\n这可以表示为矩阵形式。设设计矩阵 $\\boldsymbol{A}$ 是一个 $5 \\times 2$ 的矩阵，其行是向量 $\\boldsymbol{r}_i^{\\mathsf{T}}$，并设 $\\boldsymbol{b}$ 是一个 $5 \\times 1$ 的测量值向量 $\\Delta u_i$。\n$$\n\\boldsymbol{A} = \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ -1  0 \\\\ 0  -1 \\\\ 1  1 \\end{pmatrix}, \\quad \\boldsymbol{b} = \\begin{pmatrix} 1.25 \\\\ -0.72 \\\\ -1.17 \\\\ 0.69 \\\\ 0.54 \\end{pmatrix}\n$$\n方程组为 $\\boldsymbol{A}\\boldsymbol{g} \\approx \\boldsymbol{b}$。目标函数的矩阵形式是：\n$$ J(\\boldsymbol{g}) = (\\boldsymbol{A}\\boldsymbol{g} - \\boldsymbol{b})^{\\mathsf{T}} \\boldsymbol{W} (\\boldsymbol{A}\\boldsymbol{g} - \\boldsymbol{b}) $$\n其中 $\\boldsymbol{W}$ 是权重 $w_i$ 的对角矩阵。为了最小化 $J(\\boldsymbol{g})$，我们将其关于 $\\boldsymbol{g}$ 的梯度设为零。首先，展开目标函数：\n$$ J(\\boldsymbol{g}) = (\\boldsymbol{g}^{\\mathsf{T}}\\boldsymbol{A}^{\\mathsf{T}} - \\boldsymbol{b}^{\\mathsf{T}}) \\boldsymbol{W} (\\boldsymbol{A}\\boldsymbol{g} - \\boldsymbol{b}) = \\boldsymbol{g}^{\\mathsf{T}}\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A}\\boldsymbol{g} - \\boldsymbol{g}^{\\mathsf{T}}\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{b} - \\boldsymbol{b}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A}\\boldsymbol{g} + \\boldsymbol{b}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{b} $$\n由于 $\\boldsymbol{b}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A}\\boldsymbol{g}$ 是一个标量，它等于其转置 $(\\boldsymbol{b}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A}\\boldsymbol{g})^{\\mathsf{T}} = \\boldsymbol{g}^{\\mathsf{T}}\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}^{\\mathsf{T}}\\boldsymbol{b}$。因为 $\\boldsymbol{W}$ 是对角矩阵，所以 $\\boldsymbol{W}^{\\mathsf{T}} = \\boldsymbol{W}$。因此，中间两项是相同的。\n$$ J(\\boldsymbol{g}) = \\boldsymbol{g}^{\\mathsf{T}}(\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})\\boldsymbol{g} - 2\\boldsymbol{g}^{\\mathsf{T}}(\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{b}) + \\boldsymbol{b}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{b} $$\n对 $\\boldsymbol{g}$ 求导并将结果设为零，得到：\n$$ \\frac{\\partial J}{\\partial \\boldsymbol{g}} = 2(\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})\\boldsymbol{g} - 2(\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{b}) = \\boldsymbol{0} $$\n这就得到了**正规方程**：\n$$ (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})\\boldsymbol{g} = \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{b} $$\n梯度估计 $\\boldsymbol{g}$ 的解是：\n$$ \\boldsymbol{g} = (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})^{-1} (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{b}) $$\n\n**情况1：均匀权重** $\\boldsymbol{W}_1 = \\mathrm{diag}(1,1,1,1,1) = \\boldsymbol{I}$\n正规方程简化为 $(\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A})\\boldsymbol{g}_1 = \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{b}$。\n首先，我们计算 $\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A}$：\n$$ \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A} = \\begin{pmatrix} 1  0  -1  0  1 \\\\ 0  1  0  -1  1 \\end{pmatrix} \\begin{pmatrix} 1  0 \\\\ 0  1 \\\\ -1  0 \\\\ 0  -1 \\\\ 1  1 \\end{pmatrix} = \\begin{pmatrix} 1^2+(-1)^2+1^2  1(1) \\\\ 1(1)  1^2+(-1)^2+1^2 \\end{pmatrix} = \\begin{pmatrix} 3  1 \\\\ 1  3 \\end{pmatrix} $$\n接下来，我们计算 $\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{b}$：\n$$ \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{b} = \\begin{pmatrix} 1  0  -1  0  1 \\\\ 0  1  0  -1  1 \\end{pmatrix} \\begin{pmatrix} 1.25 \\\\ -0.72 \\\\ -1.17 \\\\ 0.69 \\\\ 0.54 \\end{pmatrix} = \\begin{pmatrix} 1.25 - (-1.17) + 0.54 \\\\ -0.72 - 0.69 + 0.54 \\end{pmatrix} = \\begin{pmatrix} 2.96 \\\\ -0.87 \\end{pmatrix} $$\n$\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A}$ 的逆矩阵是：\n$$ (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A})^{-1} = \\frac{1}{3(3)-1(1)} \\begin{pmatrix} 3  -1 \\\\ -1  3 \\end{pmatrix} = \\frac{1}{8} \\begin{pmatrix} 3  -1 \\\\ -1  3 \\end{pmatrix} $$\n现在我们求解 $\\boldsymbol{g}_1$：\n$$ \\boldsymbol{g}_1 = \\frac{1}{8} \\begin{pmatrix} 3  -1 \\\\ -1  3 \\end{pmatrix} \\begin{pmatrix} 2.96 \\\\ -0.87 \\end{pmatrix} = \\frac{1}{8} \\begin{pmatrix} 3(2.96) - 1(-0.87) \\\\ -1(2.96) + 3(-0.87) \\end{pmatrix} = \\frac{1}{8} \\begin{pmatrix} 8.88 + 0.87 \\\\ -2.96 - 2.61 \\end{pmatrix} = \\frac{1}{8} \\begin{pmatrix} 9.75 \\\\ -5.57 \\end{pmatrix} = \\begin{pmatrix} 1.21875 \\\\ -0.69625 \\end{pmatrix} $$\n四舍五入到四位有效数字，得到 $g_{x,1} = 1.219$ 和 $g_{y,1} = -0.6963$。\n\n**情况2：基于距离的权重** $\\boldsymbol{W}_2 = \\mathrm{diag}(1,1,1,1,1/2)$\n我们计算 $\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2\\boldsymbol{A}$：\n$$ \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2\\boldsymbol{A} = \\sum_{i=1}^5 w_i \\boldsymbol{r}_i \\boldsymbol{r}_i^{\\mathsf{T}} = 1\\begin{pmatrix}1\\\\0\\end{pmatrix}\\begin{pmatrix}1  0\\end{pmatrix} + 1\\begin{pmatrix}0\\\\1\\end{pmatrix}\\begin{pmatrix}0  1\\end{pmatrix} + 1\\begin{pmatrix}-1\\\\0\\end{pmatrix}\\begin{pmatrix}-1  0\\end{pmatrix} + 1\\begin{pmatrix}0\\\\-1\\end{pmatrix}\\begin{pmatrix}0  -1\\end{pmatrix} + \\frac{1}{2}\\begin{pmatrix}1\\\\1\\end{pmatrix}\\begin{pmatrix}1  1\\end{pmatrix} $$\n$$ = \\begin{pmatrix}10\\\\00\\end{pmatrix} + \\begin{pmatrix}00\\\\01\\end{pmatrix} + \\begin{pmatrix}10\\\\00\\end{pmatrix} + \\begin{pmatrix}00\\\\01\\end{pmatrix} + \\begin{pmatrix}0.50.5\\\\0.50.5\\end{pmatrix} = \\begin{pmatrix} 2.5  0.5 \\\\ 0.5  2.5 \\end{pmatrix} $$\n接下来，我们计算 $\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2\\boldsymbol{b}$：\n$$ \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2\\boldsymbol{b} = \\sum_{i=1}^5 w_i \\boldsymbol{r}_i \\Delta u_i = 1\\begin{pmatrix}1\\\\0\\end{pmatrix}(1.25) + 1\\begin{pmatrix}0\\\\1\\end{pmatrix}(-0.72) + 1\\begin{pmatrix}-1\\\\0\\end{pmatrix}(-1.17) + 1\\begin{pmatrix}0\\\\-1\\end{pmatrix}(0.69) + \\frac{1}{2}\\begin{pmatrix}1\\\\1\\end{pmatrix}(0.54) $$\n$$ = \\begin{pmatrix}1.25\\\\0\\end{pmatrix} + \\begin{pmatrix}0\\\\-0.72\\end{pmatrix} + \\begin{pmatrix}1.17\\\\0\\end{pmatrix} + \\begin{pmatrix}0\\\\-0.69\\end{pmatrix} + \\begin{pmatrix}0.27\\\\0.27\\end{pmatrix} = \\begin{pmatrix} 1.25+1.17+0.27 \\\\-0.72-0.69+0.27 \\end{pmatrix} = \\begin{pmatrix} 2.69 \\\\ -1.14 \\end{pmatrix} $$\n$\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2\\boldsymbol{A}$ 的逆矩阵是：\n$$ (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2\\boldsymbol{A})^{-1} = \\frac{1}{2.5^2-0.5^2} \\begin{pmatrix} 2.5  -0.5 \\\\ -0.5  2.5 \\end{pmatrix} = \\frac{1}{6} \\begin{pmatrix} 2.5  -0.5 \\\\ -0.5  2.5 \\end{pmatrix} $$\n现在我们求解 $\\boldsymbol{g}_2$：\n$$ \\boldsymbol{g}_2 = \\frac{1}{6} \\begin{pmatrix} 2.5  -0.5 \\\\ -0.5  2.5 \\end{pmatrix} \\begin{pmatrix} 2.69 \\\\ -1.14 \\end{pmatrix} = \\frac{1}{6} \\begin{pmatrix} 2.5(2.69) - 0.5(-1.14) \\\\ -0.5(2.69) + 2.5(-1.14) \\end{pmatrix} = \\frac{1}{6} \\begin{pmatrix} 6.725 + 0.57 \\\\ -1.345 - 2.85 \\end{pmatrix} = \\frac{1}{6} \\begin{pmatrix} 7.295 \\\\ -4.195 \\end{pmatrix} = \\begin{pmatrix} 1.2158\\bar{3} \\\\ -0.6991\\bar{6} \\end{pmatrix} $$\n四舍五入到四位有效数字，得到 $g_{x,2} = 1.216$ 和 $g_{y,2} = -0.6992$。\n\n**协方差矩阵之比**\n估计的梯度为 $\\hat{\\boldsymbol{g}} = (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})^{-1} \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{b}$。测量向量 $\\boldsymbol{b}$ 与真实梯度 $\\boldsymbol{g}_{\\mathrm{true}}$ 的关系为 $\\boldsymbol{b} = \\boldsymbol{A}\\boldsymbol{g}_{\\mathrm{true}} + \\boldsymbol{\\varepsilon}$，其中 $\\boldsymbol{\\varepsilon}$ 是误差向量，满足 $\\mathbb{E}[\\boldsymbol{\\varepsilon}] = \\boldsymbol{0}$ 和 $\\mathrm{Cov}(\\boldsymbol{\\varepsilon}) = \\mathbb{E}[\\boldsymbol{\\varepsilon}\\boldsymbol{\\varepsilon}^{\\mathsf{T}}] = \\sigma^2 \\boldsymbol{I}$。\n估计误差为 $\\hat{\\boldsymbol{g}} - \\boldsymbol{g}_{\\mathrm{true}} = (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})^{-1} \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{\\varepsilon}$。\n估计量 $\\hat{\\boldsymbol{g}}$ 的协方差矩阵是：\n$$ \\mathrm{Cov}(\\hat{\\boldsymbol{g}}) = \\mathbb{E}[(\\hat{\\boldsymbol{g}} - \\boldsymbol{g}_{\\mathrm{true}})(\\hat{\\boldsymbol{g}} - \\boldsymbol{g}_{\\mathrm{true}})^{\\mathsf{T}}] = \\mathbb{E}[((\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})^{-1} \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{\\varepsilon}) ((\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})^{-1} \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{\\varepsilon})^{\\mathsf{T}}] $$\n$$ \\mathrm{Cov}(\\hat{\\boldsymbol{g}}) = (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})^{-1} \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W} \\mathbb{E}[\\boldsymbol{\\varepsilon}\\boldsymbol{\\varepsilon}^{\\mathsf{T}}] \\boldsymbol{W}^{\\mathsf{T}}\\boldsymbol{A} ((\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})^{-1})^{\\mathsf{T}} $$\n由于 $\\mathbb{E}[\\boldsymbol{\\varepsilon}\\boldsymbol{\\varepsilon}^{\\mathsf{T}}] = \\sigma^2\\boldsymbol{I}$，$\\boldsymbol{W}$ 是对角矩阵，且 $\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A}$ 是对称的：\n$$ \\mathrm{Cov}_W(\\boldsymbol{g}) = \\sigma^2 (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})^{-1} (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}^2\\boldsymbol{A}) (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}\\boldsymbol{A})^{-1} $$\n对于 $\\boldsymbol{W}_1 = \\boldsymbol{I}$，我们有 $\\boldsymbol{W}_1^2 = \\boldsymbol{I}$。该公式简化为普通最小二乘（OLS）的情况：\n$$ \\mathrm{Cov}_{W_1}(\\boldsymbol{g}) = \\sigma^2 (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A})^{-1} (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A}) (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A})^{-1} = \\sigma^2 (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A})^{-1} $$\n行列式是：\n$$ \\det(\\mathrm{Cov}_{W_1}(\\boldsymbol{g})) = \\det(\\sigma^2 (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A})^{-1}) = (\\sigma^2)^2 \\det((\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A})^{-1}) = \\frac{\\sigma^4}{\\det(\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{A})} = \\frac{\\sigma^4}{8} $$\n对于 $\\boldsymbol{W}_2 = \\mathrm{diag}(1,1,1,1,1/2)$，我们有 $\\boldsymbol{W}_2^2 = \\mathrm{diag}(1,1,1,1,1/4)$。\n$$ \\det(\\mathrm{Cov}_{W_2}(\\boldsymbol{g})) = \\det\\left( \\sigma^2 (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2\\boldsymbol{A})^{-1} (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2^2\\boldsymbol{A}) (\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2\\boldsymbol{A})^{-1} \\right) $$\n$$ = (\\sigma^2)^2 \\frac{\\det(\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2^2\\boldsymbol{A})}{(\\det(\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2\\boldsymbol{A}))^2} $$\n我们已经求得 $\\det(\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2\\boldsymbol{A}) = \\det \\begin{pmatrix} 2.5  0.5 \\\\ 0.5  2.5 \\end{pmatrix} = 6$。\n我们需要计算 $\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2^2\\boldsymbol{A}$：\n$$ \\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2^2\\boldsymbol{A} = \\sum_{i=1}^5 w_i^2 \\boldsymbol{r}_i \\boldsymbol{r}_i^{\\mathsf{T}} = \\left( \\sum_{i=1}^4 1^2 \\boldsymbol{r}_i \\boldsymbol{r}_i^{\\mathsf{T}} \\right) + \\left(\\frac{1}{2}\\right)^2 \\boldsymbol{r}_5 \\boldsymbol{r}_5^{\\mathsf{T}} = \\begin{pmatrix}20\\\\02\\end{pmatrix} + \\frac{1}{4}\\begin{pmatrix}11\\\\11\\end{pmatrix} = \\begin{pmatrix} 2.25  0.25 \\\\ 0.25  2.25 \\end{pmatrix} $$\n行列式为 $\\det(\\boldsymbol{A}^{\\mathsf{T}}\\boldsymbol{W}_2^2\\boldsymbol{A}) = 2.25^2 - 0.25^2 = 5.0625 - 0.0625 = 5$。\n所以，$\\det(\\mathrm{Cov}_{W_2}(\\boldsymbol{g})) = \\sigma^4 \\frac{5}{6^2} = \\frac{5\\sigma^4}{36}$。\n比值为：\n$$ \\frac{\\det(\\mathrm{Cov}_{W_2}(\\boldsymbol{g}))}{\\det(\\mathrm{Cov}_{W_1}(\\boldsymbol{g}))} = \\frac{5\\sigma^4/36}{\\sigma^4/8} = \\frac{5}{36} \\times 8 = \\frac{40}{36} = \\frac{10}{9} = 1.111\\bar{1} $$\n四舍五入到四位有效数字，比值为 $1.111$。\n\n最终结果，四舍五入到四位有效数字，是：\n- 使用 $W_1$ 时的 $g_{x}$：$1.219$\n- 使用 $W_1$ 时的 $g_{y}$：$-0.6963$\n- 使用 $W_2$ 时的 $g_{x}$：$1.216$\n- 使用 $W_2$ 时的 $g_{y}$：$-0.6992$\n- 行列式之比：$1.111$", "answer": "$$\n\\boxed{\n\\begin{pmatrix}\n1.219  -0.6963  1.216  -0.6992  1.111\n\\end{pmatrix}\n}\n$$", "id": "3339283"}, {"introduction": "计算出梯度只是第一步，评估其质量同样至关重要。本实践将深入探讨梯度估算中的两个主要误差来源：由模型简化（例如，忽略场的曲率）引起的“偏差”，以及由测量或离散化噪声引起的“方差”。通过分析和比较不同邻居点排布（即模板）下的梯度重构效果，您将亲身体会偏差与方差之间的权衡，并理解为何简单地增加数据点并不总能提高重构精度，模板的几何构型同样关键 [@problem_id:3339276]。", "problem": "在计算流体动力学 (CFD) 中，一个点上的最小二乘 (LS) 梯度重构旨在寻找一个向量 $g \\in \\mathbb{R}^2$，该向量通过一阶泰勒展开对邻近点的增量进行建模，从而最佳地拟合局部标量场的差异。考虑一个标量场 $\\phi$，它在一个参考位置 $P$ 和一组邻近位置上被采样，这些邻近位置的位置偏移为 $r_i = (x_i, y_i)$，其中 $i = 1, \\dots, m$。对于每个邻近点，其增量满足泰勒展开：\n$$\n\\phi(P + r_i) - \\phi(P) \\;=\\; g \\cdot r_i \\;+\\; \\tfrac{1}{2}\\, r_i^\\top H\\, r_i \\;+\\; \\varepsilon_i,\n$$\n其中 $H$ 是捕捉因忽略曲率而产生的截断效应的局部 Hessian 矩阵，而 $\\varepsilon_i$ 是零均值测量或离散化噪声，满足 $\\mathbb{E}[\\varepsilon_i] = 0$ 和 $\\operatorname{Var}(\\varepsilon_i) = \\sigma^2$。具有相等权重的 LS 估计量最小化 $\\sum_i \\big(\\phi(P + r_i) - \\phi(P) - g \\cdot r_i\\big)^2$。\n\n在二维空间中，未知梯度分量的数量为 $d = 2$。一个最小模板恰好使用 $d$ 个位置良好的邻近点，其方向张成 $\\mathbb{R}^2$，而一个冗余模板使用超过 $d$ 个邻近点。构造以下三个具有相等间距 $h  0$ 和相等权重的模板：\n\n- 最小模板 $S_{\\min}$：邻近点位于 $r_1 = (h, 0)$ 和 $r_2 = (0, h)$。\n- 冗余对称模板 $S_{\\mathrm{sym}}$：邻近点位于 $r_1 = (h, 0)$、$r_2 = (-h, 0)$、$r_3 = (0, h)$ 和 $r_4 = (0, -h)$。\n- 冗余倾斜模板 $S_{\\mathrm{skew}}$：邻近点位于 $r_1 = (h, 0)$、$r_2 = (2h, 0)$、$r_3 = (h, h)$ 和 $r_4 = (0, h)$。\n\n假设 Hessian 分量为 $H_{xx} = 4$、$H_{xy} = 1$、$H_{yy} = -2$，间距为 $h = 0.1$，噪声方差为 $\\sigma^2 = 10^{-4}$。目标是，从最小模板转换到冗余模板时，从第一性原理出发，推断方差减小与潜在的截断误差放大之间的权衡关系。\n\n下列陈述中哪些是正确的？\n\nA. 对于 $S_{\\min}$，其唯一的两方程拟合将曲率吸收到梯度估计中，导致一个与坐标方向对齐的 $\\mathcal{O}(h)$ 阶的主阶偏差，而 $S_{\\mathrm{sym}}$ 通过对称性消除了这个由曲率引起的主阶偏差，并且相对于 $S_{\\min}$，将每个分量的估计量方差大约减小了 2 倍。\n\nB. 无论模板几何形状如何，增加任何额外的邻近点都会严格地同时减小方差和主阶截断偏差。\n\nC. 对于给定的 $H$、$h$ 和 $\\sigma^2$，$S_{\\mathrm{skew}}$ 的 LS 梯度估计的均方误差大于 $S_{\\min}$ 的均方误差，因为方差的减小被几何不对称性引起的曲率偏差放大所抵消。\n\nD. 在 $S_{\\min}$、$S_{\\mathrm{sym}}$ 和 $S_{\\mathrm{skew}}$ 中，当 $h = 0.1$ 和 $\\sigma^2 = 10^{-4}$ 时，最小模板 $S_{\\min}$ 的均方误差最小。", "solution": "问题陈述已经过验证，被认为是科学上合理、适定且完整的。我们可以继续进行推导。\n\n梯度 $g \\in \\mathbb{R}^2$ 的最小二乘 (LS) 估计量最小化残差平方和 $J(g_{LS}) = \\sum_{i=1}^m \\left( \\Delta \\phi_i - g_{LS} \\cdot r_i \\right)^2$，其中 $\\Delta \\phi_i = \\phi(P + r_i) - \\phi(P)$ 是位置偏移为 $r_i$ 的邻近点 $i$ 的标量增量。\n\n以矩阵形式表示，设 $R$ 是一个 $m \\times 2$ 矩阵，其行向量为 $r_i^\\top$。设 $\\Delta\\phi$ 是增量的列向量。LS 问题是 $\\min_{g_{LS}} \\| \\Delta\\phi - R g_{LS} \\|_2^2$。解由正规方程给出：\n$$ g_{LS} = (R^\\top R)^{-1} R^\\top \\Delta\\phi $$\n真实的增量 $\\Delta \\phi_i$ 由泰勒展开给出：\n$$ \\Delta \\phi_i = g \\cdot r_i + \\tfrac{1}{2} r_i^\\top H r_i + \\varepsilon_i $$\n这里，$g$ 是真实梯度，$H$ 是 Hessian 矩阵，$\\varepsilon_i$ 是方差为 $\\sigma^2$ 的零均值噪声项。以矩阵形式表示，即为 $\\Delta\\phi = R g + b_{trunc} + \\varepsilon$，其中 $b_{trunc}$ 是截断误差项 $\\frac{1}{2} r_i^\\top H r_i$ 组成的向量。\n\n将此代入 $g_{LS}$ 的 LS 解中：\n$$ g_{LS} = (R^\\top R)^{-1} R^\\top (R g + b_{trunc} + \\varepsilon) = g + (R^\\top R)^{-1} R^\\top b_{trunc} + (R^\\top R)^{-1} R^\\top \\varepsilon $$\n估计量的偏差为 $\\text{Bias}(g_{LS}) = \\mathbb{E}[g_{LS} - g]$。由于 $\\mathbb{E}[\\varepsilon] = 0$，偏差是由截断误差引起的：\n$$ \\text{Bias}(g_{LS}) = (R^\\top R)^{-1} R^\\top b_{trunc} $$\n估计量的协方差矩阵为 $\\text{Cov}(g_{LS}) = \\mathbb{E}[(g_{LS} - \\mathbb{E}[g_{LS}])(g_{LS} - \\mathbb{E}[g_{LS}])^\\top]$。由于噪声项不相关且方差为 $\\sigma^2$，我们有 $\\mathbb{E}[\\varepsilon \\varepsilon^\\top] = \\sigma^2 I$。这得出：\n$$ \\text{Cov}(g_{LS}) = \\sigma^2 (R^\\top R)^{-1} $$\n均方误差 (MSE) 是偏差大小的平方与协方差矩阵的迹之和：\n$$ \\text{MSE} = \\|\\text{Bias}(g_{LS})\\|^2 + \\text{Tr}(\\text{Cov}(g_{LS})) $$\n\n我们使用给定参数对每个模板进行评估：$h = 0.1$，$\\sigma^2 = 10^{-4}$，以及 $H = \\begin{pmatrix} 4  1 \\\\ 1  -2 \\end{pmatrix}$。因此，$H_{xx} = 4$, $H_{xy} = 1$, $H_{yy} = -2$。\n\n### 模板 $S_{\\min}$\n邻近点为 $r_1 = (h, 0)$ 和 $r_2 = (0, h)$。几何矩阵为 $R = \\begin{pmatrix} h  0 \\\\ 0  h \\end{pmatrix} = hI$。\n$R^\\top R = h^2 I$。\n$(R^\\top R)^{-1} = \\frac{1}{h^2} I$。\n\n**偏差**：截断误差向量的分量为 $b_{trunc,1} = \\frac{1}{2} r_1^\\top H r_1 = \\frac{1}{2}h^2 H_{xx}$ 和 $b_{trunc,2} = \\frac{1}{2} r_2^\\top H r_2 = \\frac{1}{2}h^2 H_{yy}$。\n$$ \\text{Bias}(g_{LS}^{min}) = \\frac{1}{h^2}I \\begin{pmatrix} h  0 \\\\ 0  h \\end{pmatrix} \\frac{h^2}{2} \\begin{pmatrix} H_{xx} \\\\ H_{yy} \\end{pmatrix} = \\frac{h}{2} \\begin{pmatrix} H_{xx} \\\\ H_{yy} \\end{pmatrix} $$\n数值上，$\\text{Bias}(g_{LS}^{min}) = \\frac{0.1}{2} \\begin{pmatrix} 4 \\\\ -2 \\end{pmatrix} = \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix}$。\n偏差范数的平方为 $\\|\\text{Bias}(g_{LS}^{min})\\|^2 = (0.2)^2 + (-0.1)^2 = 0.04 + 0.01 = 0.05$。\n\n**协方差**：\n$$ \\text{Cov}(g_{LS}^{min}) = \\sigma^2 \\frac{1}{h^2} I = \\frac{10^{-4}}{(0.1)^2} I = 10^{-2} I = \\begin{pmatrix} 0.01  0 \\\\ 0  0.01 \\end{pmatrix} $$\n迹为 $\\text{Tr}(\\text{Cov}(g_{LS}^{min})) = 0.01 + 0.01 = 0.02$。\n\n**MSE**：\n$ \\text{MSE}_{min} = 0.05 + 0.02 = 0.07 $。\n\n### 模板 $S_{\\mathrm{sym}}$\n邻近点为 $r_1 = (h, 0)$, $r_2 = (-h, 0)$, $r_3 = (0, h)$, $r_4 = (0, -h)$。\n$R = \\begin{pmatrix} h  0 \\\\ -h  0 \\\\ 0  h \\\\ 0  -h \\end{pmatrix}$。\n$R^\\top R = \\begin{pmatrix} 2h^2  0 \\\\ 0  2h^2 \\end{pmatrix} = 2h^2 I$。\n$(R^\\top R)^{-1} = \\frac{1}{2h^2} I$。\n\n**偏差**：截断误差为 $b_{trunc,1} = \\frac{1}{2}h^2 H_{xx}$, $b_{trunc,2} = \\frac{1}{2}h^2 H_{xx}$, $b_{trunc,3} = \\frac{1}{2}h^2 H_{yy}$, $b_{trunc,4} = \\frac{1}{2}h^2 H_{yy}$。\n$R^\\top b_{trunc}$ 项变为：\n$$ R^\\top b_{trunc} = \\begin{pmatrix} h  -h  0  0 \\\\ 0  0  h  -h \\end{pmatrix} \\frac{h^2}{2} \\begin{pmatrix} H_{xx} \\\\ H_{xx} \\\\ H_{yy} \\\\ H_{yy} \\end{pmatrix} = \\frac{h^3}{2} \\begin{pmatrix} H_{xx} - H_{xx} \\\\ H_{yy} - H_{yy} \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} $$\n因此，$\\text{Bias}(g_{LS}^{sym}) = (R^\\top R)^{-1} (0) = 0$。主阶偏差被对称性所抵消。\n$\\|\\text{Bias}(g_{LS}^{sym})\\|^2 = 0$。\n\n**协方差**：\n$$ \\text{Cov}(g_{LS}^{sym}) = \\sigma^2 \\frac{1}{2h^2} I = \\frac{10^{-4}}{2(0.1)^2} I = 0.005 I = \\begin{pmatrix} 0.005  0 \\\\ 0  0.005 \\end{pmatrix} $$\n$\\text{Tr}(\\text{Cov}(g_{LS}^{sym})) = 0.005 + 0.005 = 0.01$。\n\n**MSE**：\n$ \\text{MSE}_{sym} = 0 + 0.01 = 0.01 $。\n\n### 模板 $S_{\\mathrm{skew}}$\n邻近点为 $r_1 = (h,0), r_2 = (2h,0), r_3 = (h,h), r_4 = (0,h)$。\n$R = \\begin{pmatrix} h  0 \\\\ 2h  0 \\\\ h  h \\\\ 0  h \\end{pmatrix}$。\n$R^\\top R = h^2 \\begin{pmatrix} 6  1 \\\\ 1  2 \\end{pmatrix}$。\n$(R^\\top R)^{-1} = \\frac{1}{h^4(12-1)} h^2 \\begin{pmatrix} 2  -1 \\\\ -1  6 \\end{pmatrix} = \\frac{1}{11h^2} \\begin{pmatrix} 2  -1 \\\\ -1  6 \\end{pmatrix}$。\n\n**偏差**：截断误差为 $b_{trunc,1} = \\frac{1}{2}h^2 H_{xx}$, $b_{trunc,2} = \\frac{1}{2}(2h)^2 H_{xx} = 2h^2 H_{xx}$, $b_{trunc,3} = \\frac{h^2}{2}(H_{xx}+2H_{xy}+H_{yy})$, $b_{trunc,4} = \\frac{1}{2}h^2 H_{yy}$。\n$R^\\top b_{trunc} = \\frac{h^3}{2} \\begin{pmatrix} 10H_{xx}+2H_{xy}+H_{yy} \\\\ H_{xx}+2H_{xy}+2H_{yy} \\end{pmatrix}$。\n数值上，$R^\\top b_{trunc} = \\frac{0.001}{2} \\begin{pmatrix} 10(4)+2(1)+(-2) \\\\ 4+2(1)+2(-2) \\end{pmatrix} = \\frac{0.001}{2} \\begin{pmatrix} 40 \\\\ 2 \\end{pmatrix} = \\begin{pmatrix} 0.02 \\\\ 0.001 \\end{pmatrix}$。\n$$ \\text{Bias}(g_{LS}^{skew}) = \\frac{1}{11(0.1)^2} \\begin{pmatrix} 2  -1 \\\\ -1  6 \\end{pmatrix} \\begin{pmatrix} 0.02 \\\\ 0.001 \\end{pmatrix} = \\frac{1}{0.11} \\begin{pmatrix} 0.039 \\\\ -0.014 \\end{pmatrix} = \\begin{pmatrix} 39/110 \\\\ -14/110 \\end{pmatrix} \\approx \\begin{pmatrix} 0.3545 \\\\ -0.1273 \\end{pmatrix} $$\n$\\|\\text{Bias}(g_{LS}^{skew})\\|^2 = (\\frac{39}{110})^2 + (\\frac{-14}{110})^2 = \\frac{1521+196}{12100} = \\frac{1717}{12100} \\approx 0.1419$。\n\n**协方差**：\n$$ \\text{Cov}(g_{LS}^{skew}) = \\frac{\\sigma^2}{11h^2} \\begin{pmatrix} 2  -1 \\\\ -1  6 \\end{pmatrix} = \\frac{10^{-4}}{11(0.01)} \\begin{pmatrix} 2  -1 \\\\ -1  6 \\end{pmatrix} = \\frac{1}{1100} \\begin{pmatrix} 2  -1 \\\\ -1  6 \\end{pmatrix} $$\n$\\text{Tr}(\\text{Cov}(g_{LS}^{skew})) = \\frac{1}{1100}(2+6) = \\frac{8}{1100} \\approx 0.00727$。\n\n**MSE**：\n$ \\text{MSE}_{skew} \\approx 0.1419 + 0.00727 = 0.14917 $。\n\n### 选项评估\n\n**A. 对于 $S_{\\min}$，其唯一的两方程拟合将曲率吸收到梯度估计中，导致一个与坐标方向对齐的 $\\mathcal{O}(h)$ 阶的主阶偏差，而 $S_{\\mathrm{sym}}$ 通过对称性消除了这个由曲率引起的主阶偏差，并且相对于 $S_{\\min}$，将每个分量的估计量方差大约减小了 2 倍。**\n我们对 $S_{\\min}$ 的分析显示其偏差为 $\\text{Bias}(g_{LS}^{min}) = \\frac{h}{2}(H_{xx}, H_{yy})^\\top$，是 $\\mathcal{O}(h)$ 阶的。短语‘与坐标方向对齐’可以解释为 $x$-梯度分量的偏差 $\\frac{h}{2}H_{xx}$ 仅由 $x$ 方向的曲率信息 ($H_{xx}$) 引起，对 $y$-分量也是如此。这种解耦是该正交模板的一个特性。我们对 $S_{\\mathrm{sym}}$ 的分析显示其主阶偏差恰好为零。$S_{\\min}$ 的每个分量的方差是 $\\frac{\\sigma^2}{h^2}$，而 $S_{\\mathrm{sym}}$ 的是 $\\frac{\\sigma^2}{2h^2}$。这恰好是减小了 2 倍。该陈述准确地描述了这两个模板的行为。\n**结论：正确。**\n\n**B. 无论模板几何形状如何，增加任何额外的邻近点都会严格地同时减小方差和主阶截断偏差。**\n增加邻近点通常会减小（或不增加）最小二乘拟合的方差。在半正定意义下，矩阵 $(R^\\top R)^{-1}$ 会变得“更小”。然而，关于偏差的陈述是错误的。比较 $S_{min}$ 和 $S_{skew}$（后者是在 $S_{min}$ 基础上增加了两个邻近点），我们看到偏差范数的平方从 $0.05$ 增加到约 $0.1419$。新增点的倾斜几何形状放大了截断误差。\n**结论：不正确。**\n\n**C. 对于给定的 $H$、$h$ 和 $\\sigma^2$，$S_{\\mathrm{skew}}$ 的 LS 梯度估计的均方误差大于 $S_{\\min}$ 的均方误差，因为方差的减小被几何不对称性引起的曲率偏差放大所抵消。**\n我们的计算显示 $\\text{MSE}_{skew} \\approx 0.149$ 且 $\\text{MSE}_{min} = 0.07$。陈述 $\\text{MSE}_{skew}  \\text{MSE}_{min}$ 是正确的。给出的原因是方差的减小被偏差的放大所抵消。\n- 方差变化：$\\text{Tr}(\\text{Cov}_{skew}) - \\text{Tr}(\\text{Cov}_{min}) \\approx 0.0073 - 0.02 = -0.0127$。这是一个减小。\n- 偏差平方变化：$\\|\\text{Bias}_{skew}\\|^2 - \\|\\text{Bias}_{min}\\|^2 \\approx 0.1419 - 0.05 = +0.0919$。这是一个放大。\n偏差增加的幅度 ($0.0919$) 远大于方差减小的幅度 ($0.0127$)，因此净效应是更大的 MSE。这个推理完全正确。\n**结论：正确。**\n\n**D. 在 $S_{\\min}$、$S_{\\mathrm{sym}}$ 和 $S_{\\mathrm{skew}}$ 中，当 $h = 0.1$ 和 $\\sigma^2 = 10^{-4}$ 时，最小模板 $S_{\\min}$ 的均方误差最小。**\n比较计算出的 MSE 值：\n- $\\text{MSE}_{min} = 0.07$\n- $\\text{MSE}_{sym} = 0.01$\n- $\\text{MSE}_{skew} \\approx 0.149$\n最小的 MSE 属于对称模板 $S_{\\mathrm{sym}}$。该陈述是错误的。\n**结论：不正确。**\n\n陈述 A 和 C 是正确的。", "answer": "$$\\boxed{AC}$$", "id": "3339276"}, {"introduction": "梯度重构的最终目的是服务于更广泛的数值模拟框架，例如在有限体积法中实现高阶精度。然而，直接使用未经处理的梯度进行数据重构可能会产生非物理的振荡，破坏数值解的稳定性。本实践将前述概念与一个关键应用相结合，指导您如何从第一性原理出发，设计一个“限制器”，通过缩放计算出的梯度来确保重构值保持在物理边界之内，这是保证数值模拟稳定和可靠的关键一步 [@problem_id:3339339]。", "problem": "在计算流体动力学（CFD）中，考虑一个非结构化网格上标量场 $f$ 的有限体积法，其中在每个单元 $i$ 内部使用最小二乘梯度 $g$ 应用分段线性重构。与单元 $i$ 相关的采样位置 $x_i + \\Delta \\boldsymbol{x}_s$ 处的重构为 $f_i + \\phi\\, g \\cdot \\Delta \\boldsymbol{x}_s$，其中 $f_i$ 是单元 $i$ 内的单元平均值，$\\Delta \\boldsymbol{x}_s$ 是从单元形心 $x_i$ 到采样点 $s \\in S(i)$ 的向量，$\\phi \\in [0,1]$ 是一个待设计的标量限制器。最小二乘梯度 $g$ 被认为是对于线性数据是一致的，即当 $f$ 线性变化时，它能精确地重现梯度。\n\n为避免引入伪振荡并确保局部离散极值原理（DMP），在 $S(i)$ 中所有采样点的重构值必须保持在由邻近邻域中的单元平均值构成的局部极值范围内。令 $\\mathcal{N}(i)$ 表示 $i$ 的邻近单元集合。定义\n$$\nf_{\\min,i} = \\min\\left(\\{f_i\\} \\cup \\{f_j : j \\in \\mathcal{N}(i)\\}\\right), \\qquad\nf_{\\max,i} = \\max\\left(\\{f_i\\} \\cup \\{f_j : j \\in \\mathcal{N}(i)\\}\\right).\n$$\n我们寻求一个限制器 $\\phi$，使得对于所有 $s \\in S(i)$，强制满足\n$$\nf_{\\min,i} \\le f_i + \\phi \\, g \\cdot \\Delta \\boldsymbol{x}_s \\le f_{\\max,i},\n$$\n其中 $\\phi \\in [0,1]$，并且当无约束重构 $f_i + g \\cdot \\Delta \\boldsymbol{x}_s$ 对所有 $s \\in S(i)$ 都已满足这些界限时，$\\phi = 1$。设计必须从第一性原理出发进行论证：使用上述定义、不等式处理以及重构和最小二乘梯度的性质，而不是依赖于快捷公式。\n\n下列哪个关于 $\\phi$ 的候选定义满足这些要求？\n\nA. \n$$\n\\phi = \\min_{s \\in S(i)}\n\\begin{cases}\n\\min\\!\\left(1, \\dfrac{f_{\\max,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}\\right),  g \\cdot \\Delta \\boldsymbol{x}_s  0, \\\\\n\\min\\!\\left(1, \\dfrac{f_{\\min,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}\\right),  g \\cdot \\Delta \\boldsymbol{x}_s  0, \\\\\n1,  g \\cdot \\Delta \\boldsymbol{x}_s = 0,\n\\end{cases}\n$$\n\nB.\n$$\n\\phi = \\max_{s \\in S(i)}\n\\begin{cases}\n\\min\\!\\left(1, \\dfrac{f_{\\max,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}\\right),  g \\cdot \\Delta \\boldsymbol{x}_s  0, \\\\\n\\min\\!\\left(1, \\dfrac{f_{\\min,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}\\right),  g \\cdot \\Delta \\boldsymbol{x}_s  0, \\\\\n1,  g \\cdot \\Delta \\boldsymbol{x}_s = 0,\n\\end{cases}\n$$\n\nC.\n$$\n\\phi = \\min\\!\\left(1, \\min_{s \\in S(i)} \\dfrac{f_{\\max,i} - f_{\\min,i}}{\\left|g \\cdot \\Delta \\boldsymbol{x}_s\\right|}\\right),\n$$\n\nD.\n$$\n\\phi = \\min\\!\\left(1, \\max_{s \\in S(i)} \\dfrac{\\left|f_i\\right|}{\\left|g \\cdot \\Delta \\boldsymbol{x}_s\\right|}\\right).\n$$\n\n选择能够产生一个限制器 $\\phi$ 的选项，该限制器符合所述的第一性原理要求，包括对所有 $s \\in S(i)$ 强制执行局部界限、$\\phi \\in [0,1]$，以及在无约束重构已经有界时通过恢复 $\\phi = 1$ 来保持光滑区域的线性精确性。", "solution": "## 问题验证\n\n### 步骤 1：提取已知条件\n问题陈述提供了以下定义和条件：\n- 非结构化网格上的标量场 $f$。\n- 每个单元 $i$ 内的分段线性重构：$f_i + \\phi\\, g \\cdot \\Delta \\boldsymbol{x}_s$。\n- $f_i$：单元 $i$ 内的单元平均值。\n- $g$：最小二乘梯度，对线性数据一致。\n- $x_i$：单元 $i$ 的单元形心。\n- $S(i)$：与单元 $i$ 相关的一组采样位置。\n- $\\Delta \\boldsymbol{x}_s$：从形心 $x_i$ 到采样点 $s \\in S(i)$ 的向量。\n- $\\phi$：一个标量限制器，约束条件为 $\\phi \\in [0,1]$。\n- $\\mathcal{N}(i)$：$i$ 的邻近单元集合。\n- 局部极值定义：\n  $$f_{\\min,i} = \\min\\left(\\{f_i\\} \\cup \\{f_j : j \\in \\mathcal{N}(i)\\}\\right)$$\n  $$f_{\\max,i} = \\max\\left(\\{f_i\\} \\cup \\{f_j : j \\in \\mathcal{N}(i)\\}\\right)$$\n- 限制器 $\\phi$ 必须对所有 $s \\in S(i)$ 强制执行以下界限：\n  $$f_{\\min,i} \\le f_i + \\phi \\, g \\cdot \\Delta \\boldsymbol{x}_s \\le f_{\\max,i}$$\n- 一个附加要求：当无约束重构 $f_i + g \\cdot \\Delta \\boldsymbol{x}_s$ 对所有 $s \\in S(i)$ 都已满足界限时，$\\phi = 1$。\n\n### 步骤 2：使用提取的已知条件进行验证\n该问题在计算流体动力学（CFD）领域内是定义明确且有科学依据的，特别是关于高分辨率有限体积法。\n- **科学依据**：所提出的概念——有限体积法、单元平均值、梯度重构、限制器和离散极值原理（DMP）——是守恒律数值格式的标准和基本组成部分。该公式是 Barth-Jespersen 限制器的一种直接表示，这是一种公认的技术。\n- **适定性**：任务是推导一个标量 $\\phi$ 的公式，该公式满足一组明确定义的数学不等式。已知存在这样的限制器，并且问题提供了推导其形式所需的所有信息。\n- **客观性**：问题使用精确的数学语言和定义（$f_i, g, \\Delta \\boldsymbol{x}_s, f_{\\min,i}, f_{\\max,i}$）进行陈述。没有主观或模棱两可的术语。\n\n该问题不违反任何无效性标准。它是偏微分方程数值分析中的一个标准、可验证的问题。\n\n### 步骤 3：结论与行动\n问题陈述是**有效的**。开始求解。\n\n## 限制器 $\\phi$ 的推导\n\n目标是为单元 $i$ 找到限制器 $\\phi$ 的一个单一值，以确保在所有采样点 $s \\in S(i)$ 处的重构值保持在局部界限 $[f_{\\min,i}, f_{\\max,i}]$ 内。核心约束是一对必须对所有 $s \\in S(i)$ 成立的不等式：\n$$\nf_{\\min,i} \\le f_i + \\phi \\, g \\cdot \\Delta \\boldsymbol{x}_s \\le f_{\\max,i}\n$$\n我们还有约束条件 $\\phi \\in [0,1]$。根据 $f_{\\min,i}$ 和 $f_{\\max,i}$ 的定义，我们知道 $f_{\\min,i} \\le f_i \\le f_{\\max,i}$。这意味着 $f_{\\max,i} - f_i \\ge 0$ 且 $f_{\\min,i} - f_i \\le 0$。\n\n我们可以将主不等式分为两部分：\n1. $f_i + \\phi \\, g \\cdot \\Delta \\boldsymbol{x}_s \\le f_{\\max,i} \\implies \\phi \\, g \\cdot \\Delta \\boldsymbol{x}_s \\le f_{\\max,i} - f_i$\n2. $f_i + \\phi \\, g \\cdot \\Delta \\boldsymbol{x}_s \\ge f_{\\min,i} \\implies \\phi \\, g \\cdot \\Delta \\boldsymbol{x}_s \\ge f_{\\min,i} - f_i$\n\n为了分离出 $\\phi$，我们必须考虑量 $\\delta_s = g \\cdot \\Delta \\boldsymbol{x}_s$ 的符号。\n\n**情况 1：$\\delta_s = g \\cdot \\Delta \\boldsymbol{x}_s  0$**\n不等式 (1) 变为：$\\phi \\le \\dfrac{f_{\\max,i} - f_i}{\\delta_s}$。\n不等式 (2) 变为：$\\phi \\ge \\dfrac{f_{\\min,i} - f_i}{\\delta_s}$。\n由于 $f_{\\min,i} - f_i \\le 0$ 且 $\\delta_s  0$，第二个不等式的右侧是非正的。约束 $\\phi \\ge 0$ 更强。因此，对于 $\\phi \\in [0,1]$，第二个不等式自动满足。对 $\\phi$ 的唯一有效约束来自上界：\n$$\n\\phi \\le \\dfrac{f_{\\max,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}\n$$\n\n**情况 2：$\\delta_s = g \\cdot \\Delta \\boldsymbol{x}_s  0$**\n当我们除以一个负数时，不等号反转。\n不等式 (1) 变为：$\\phi \\ge \\dfrac{f_{\\max,i} - f_i}{\\delta_s}$。\n不等式 (2) 变为：$\\phi \\le \\dfrac{f_{\\min,i} - f_i}{\\delta_s}$。\n由于 $f_{\\max,i} - f_i \\ge 0$ 且 $\\delta_s  0$，第一个不等式的右侧是非正的。约束 $\\phi \\ge 0$ 更强，因此对于 $\\phi \\in [0,1]$，第一个不等式自动满足。对 $\\phi$ 的唯一有效约束来自上界：\n$$\n\\phi \\le \\dfrac{f_{\\min,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}\n$$\n请注意，由于分子（$f_{\\min,i} - f_i \\le 0$）和分母（$g \\cdot \\Delta \\boldsymbol{x}_s  0$）都是非正/负的，其比值是非负的，这是一致的。\n\n**情况 3：$\\delta_s = g \\cdot \\Delta \\boldsymbol{x}_s = 0$**\n不等式变为 $f_{\\min,i} \\le f_i \\le f_{\\max,i}$。根据定义，这始终成立。因此，在这种情况下对 $\\phi$ 没有约束。为了尽可能减少耗散，我们可以允许 $\\phi$ 取其最大值，即 $\\phi=1$。\n\n**组合约束**\n对于每个采样点 $s \\in S(i)$，我们有一个关于 $\\phi$ 的上界，我们称之为 $\\phi_s^{\\max}$。\n$$\n\\phi_s^{\\max} =\n\\begin{cases}\n\\dfrac{f_{\\max,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s},  g \\cdot \\Delta \\boldsymbol{x}_s  0 \\\\[2ex]\n\\dfrac{f_{\\min,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s},  g \\cdot \\Delta \\boldsymbol{x}_s  0 \\\\[2ex]\n\\infty,  g \\cdot \\Delta \\boldsymbol{x}_s = 0\n\\end{cases}\n$$\n单元 $i$ 的单个限制器值 $\\phi$ 必须对**所有** $s \\in S(i)$ 满足 $\\phi \\le \\phi_s^{\\max}$。为了找到满足所有这些约束的可能的最大 $\\phi$ 值，我们必须取所有上界的最小值：\n$$\n\\phi_{\\text{candidate}} = \\min_{s \\in S(i)} \\left( \\phi_s^{\\max} \\right)\n$$\n此外，问题要求 $\\phi \\in [0,1]$。如前所示，$\\phi_s^{\\max}$ 始终是非负的，因此它们的最小值也是非负的。我们只需要强制 $\\phi \\le 1$。满足所有约束的最终、最宽松（最大）的 $\\phi$ 是：\n$$\n\\phi = \\min\\left(1, \\min_{s \\in S(i)} \\left( \\phi_s^{\\max} \\right)\\right)\n$$\n这可以通过将 $\\min(1, \\cdot)$ 移到关于 $s$ 的最小值内部来重写：\n$$\n\\phi = \\min_{s \\in S(i)} \\left( \\min(1, \\phi_s^{\\max}) \\right)\n$$\n代入 $\\phi_s^{\\max}$ 的分段定义：\n$$\n\\phi = \\min_{s \\in S(i)}\n\\begin{cases}\n\\min\\!\\left(1, \\dfrac{f_{\\max,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}\\right),  g \\cdot \\Delta \\boldsymbol{x}_s  0 \\\\[2ex]\n\\min\\!\\left(1, \\dfrac{f_{\\min,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}\\right),  g \\cdot \\Delta \\boldsymbol{x}_s  0 \\\\[2ex]\n\\min(1, \\infty) = 1,  g \\cdot \\Delta \\boldsymbol{x}_s = 0\n\\end{cases}\n$$\n此表达式与选项 A 匹配。\n\n最后，我们验证条件：如果无约束重构（$f_i + g \\cdot \\Delta \\boldsymbol{x}_s$）对所有 $s$ 都已经有界，则 $\\phi = 1$。\n条件 $f_{\\min,i} \\le f_i + g \\cdot \\Delta \\boldsymbol{x}_s \\le f_{\\max,i}$ 等价于：\n- 如果 $g \\cdot \\Delta \\boldsymbol{x}_s  0$：$g \\cdot \\Delta \\boldsymbol{x}_s \\le f_{\\max,i} - f_i \\implies 1 \\le \\dfrac{f_{\\max,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}$。\n- 如果 $g \\cdot \\Delta \\boldsymbol{x}_s  0$：$g \\cdot \\Delta \\boldsymbol{x}_s \\ge f_{\\min,i} - f_i \\implies 1 \\le \\dfrac{f_{\\min,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}$。\n- 如果 $g \\cdot \\Delta \\boldsymbol{x}_s = 0$，条件不言自明地满足。\n在所有可能需要限制的情况下，定义 $\\phi_s^{\\max}$ 的比值都大于或等于 1。因此，对于每个 $s$，$\\min_{s \\in S(i)}$ 内的项是 $\\min(1, \\text{一个} \\ge 1 \\text{的值}) = 1$。最终结果是 $\\phi = \\min(1, 1, \\dots, 1) = 1$。该条件得到满足。\n\n## 逐项分析\n\n**A.**\n$$\n\\phi = \\min_{s \\in S(i)}\n\\begin{cases}\n\\min\\!\\left(1, \\dfrac{f_{\\max,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}\\right),  g \\cdot \\Delta \\boldsymbol{x}_s  0, \\\\\n\\min\\!\\left(1, \\dfrac{f_{\\min,i} - f_i}{g \\cdot \\Delta \\boldsymbol{x}_s}\\right),  g \\cdot \\Delta \\boldsymbol{x}_s  0, \\\\\n1,  g \\cdot \\Delta \\boldsymbol{x}_s = 0,\n\\end{cases}\n$$\n该选项与我们从第一性原理出发的逐步推导完全匹配。它正确地识别了 $g \\cdot \\Delta \\boldsymbol{x}_s$ 每种符号下的有效界限，对所有采样点 $s \\in S(i)$ 取最小允许因子以确保处处都遵守界限，并包含了 $\\phi \\in [0,1]$ 的约束。\n**结论：正确。**\n\n**B.**\n$$\n\\phi = \\max_{s \\in S(i)}\n\\begin{cases}\n...\n\\end{cases}\n$$\n此选项使用 $\\max_{s \\in S(i)}$ 而不是 $\\min_{s \\in S(i)}$。如果不同的采样点需要不同程度的限制（例如，对于点 $s_1$，需要 $\\phi \\le 0.5$，而对于点 $s_2$，需要 $\\phi \\le 0.8$），取最大值（$\\phi = 0.8$）将满足 $s_2$ 的条件，但会违反 $s_1$ 的条件。为了满足所有点的界限，必须选择最严格（最小）的上界。因此，需要对 $s \\in S(i)$ 取最小值。\n**结论：不正确。**\n\n**C.**\n$$\n\\phi = \\min\\!\\left(1, \\min_{s \\in S(i)} \\dfrac{f_{\\max,i} - f_{\\min,i}}{\\left|g \\cdot \\Delta \\boldsymbol{x}_s\\right|}\\right)\n$$\n此选项使用邻近值的总范围 $f_{\\max,i} - f_{\\min,i}$ 作为分子。这不能正确表示重构可用的“空间”，这个空间应该是 $f_{\\max,i} - f_i$ 或 $f_i - f_{\\min,i}$。考虑 $f_{\\min,i}=0$，$f_i=0.9$，$f_{\\max,i}=1$ 和 $g \\cdot \\Delta \\boldsymbol{x}_s = 0.2  0$。重构必须满足 $0.9 + \\phi(0.2) \\le 1$，这要求 $\\phi \\le 0.5$。选项 C 计算的限制基于 $\\dfrac{1-0}{|0.2|} = 5$，得出 $\\phi = \\min(1,5)=1$。使用 $\\phi=1$ 会得到重构值 $0.9 + 1(0.2) = 1.1$，这违反了界限 $f_{\\max,i}=1$。\n**结论：不正确。**\n\n**D.**\n$$\n\\phi = \\min\\!\\left(1, \\max_{s \\in S(i)} \\dfrac{\\left|f_i\\right|}{\\left|g \\cdot \\Delta \\boldsymbol{x}_s\\right|}\\right)\n$$\n此选项有多个缺陷。首先，它使用 $|f_i|$ 作为分子，这与界限 $f_{\\min,i}$ 和 $f_{\\max,i}$ 或可用的校正范围没有关系。其次，与选项 B 类似，它错误地使用了 $\\max_{s \\in S(i)}$，这将无法对最严格的采样点强制执行条件。使用与 C 相同的反例（$f_i=0.9$, $g \\cdot \\Delta \\boldsymbol{x}_s = 0.2$，要求 $\\phi \\le 0.5$），该公式（对于单个点）给出 $\\phi = \\min(1, \\frac{|0.9|}{|0.2|}) = \\min(1, 4.5) = 1$。这会导致超调。\n**结论：不正确。**", "answer": "$$\\boxed{A}$$", "id": "3339339"}]}