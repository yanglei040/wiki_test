{"hands_on_practices": [{"introduction": "在为复杂流动建立代理模型时，一个关键的初始步骤是降低高维仿真数据的维度。本征正交分解（POD）是实现这一目标的基础技术，它能从一系列高保真“快照”中提取出能量上最优的基函数。本练习将通过一个具体的计算任务，帮助你掌握评估POD基表示能力的核心指标——投影误差，并深入理解用于构建基的快照集合的多样性如何影响模型的压缩效率。[@problem_id:3369133]", "problem": "考虑一个在均匀网格上离散化的无量纲不可压缩流场，其离散 $L^{2}$ 内积与 $\\mathbb{R}^{3}$ 上的欧几里得点积一致。已通过对快照矩阵进行奇异值分解 (SVD)，从一个快照集成中构建了一个秩为 $r=2$ 的本征正交分解 (POD) 基。所得到的 $L^{2}$-正交归一的 POD 模态由以下矩阵的列向量给出：\n$$\nU_{r} = \\begin{pmatrix}\n\\frac{1}{\\sqrt{2}} & -\\frac{1}{\\sqrt{2}} \\\\\n\\frac{1}{\\sqrt{2}} & \\frac{1}{\\sqrt{2}} \\\\\n0 & 0\n\\end{pmatrix},\n$$\n使得 $\\phi_{1} = \\left(\\frac{1}{\\sqrt{2}},\\, \\frac{1}{\\sqrt{2}},\\, 0\\right)^{\\top}$ 且 $\\phi_{2} = \\left(-\\frac{1}{\\sqrt{2}},\\, \\frac{1}{\\sqrt{2}},\\, 0\\right)^{\\top}$。令 $P_{r}$ 表示到 $\\operatorname{span}\\{\\phi_{1},\\phi_{2}\\}$ 上的 $L^{2}$-正交投影。\n\n给定一个无量纲的离散速度场\n$$\nu = \\begin{pmatrix} 1 \\\\ 0 \\\\ \\sqrt{2} \\end{pmatrix}.\n$$\n\n从 $L^{2}$ 内积、正交归一性和正交投影算子的定义出发，计算投影误差范数 $\\|u - P_{r} u\\|_{L^{2}}$。\n\n此外，运用通过奇异值分解 (SVD) 构建 POD 的第一性原理，讨论快照的多样性（例如，宽泛的参数变化、多个相干结构或多模态动力学）如何影响与快照矩阵相关的奇异值的衰减率。您的讨论必须基于快照相关算子的性质和 POD 的最优性进行推理，而不是基于启发式规则。投影误差的最终答案必须以精确形式表示，无需四舍五入。", "solution": "该问题包含两部分。第一部分要求计算给定离散速度场在由一组给定的本征正交分解 (POD) 模态张成的子空间上的投影误差范数。第二部分要求就快照多样性与 POD 背景下奇异值衰减率之间的关系进行理论讨论。\n\n**第一部分：投影误差范数的计算**\n\n问题设置在有限维向量空间 $\\mathbb{R}^{3}$ 中，其中离散 $L^{2}$ 内积定义为标准欧几里得点积，即 $\\langle u, v \\rangle_{L^{2}} = u^{\\top}v$。相关联的范数是欧几里得范数，即 $\\|u\\|_{L^{2}} = \\sqrt{u^{\\top}u}$。\n\n我们给定了一个秩为 $r=2$ 的 POD 基，它是一个由向量 $\\{\\phi_{1}, \\phi_{2}\\}$ 构成的正交归一集。这些向量由矩阵 $U_{r}$ 的列向量给出：\n$$\n\\phi_{1} = \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{pmatrix}, \\quad \\phi_{2} = \\begin{pmatrix} -\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{pmatrix}\n$$\n通过检查内积可以确认这些基向量的正交归一性：\n$$\n\\langle \\phi_{1}, \\phi_{1} \\rangle = \\left(\\frac{1}{\\sqrt{2}}\\right)^{2} + \\left(\\frac{1}{\\sqrt{2}}\\right)^{2} + 0^{2} = \\frac{1}{2} + \\frac{1}{2} = 1\n$$\n$$\n\\langle \\phi_{2}, \\phi_{2} \\rangle = \\left(-\\frac{1}{\\sqrt{2}}\\right)^{2} + \\left(\\frac{1}{\\sqrt{2}}\\right)^{2} + 0^{2} = \\frac{1}{2} + \\frac{1}{2} = 1\n$$\n$$\n\\langle \\phi_{1}, \\phi_{2} \\rangle = \\left(\\frac{1}{\\sqrt{2}}\\right)\\left(-\\frac{1}{\\sqrt{2}}\\right) + \\left(\\frac{1}{\\sqrt{2}}\\right)\\left(\\frac{1}{\\sqrt{2}}\\right) + (0)(0) = -\\frac{1}{2} + \\frac{1}{2} = 0\n$$\n集合 $\\{\\phi_{1}, \\phi_{2}\\}$ 相对于指定的内积确实是正交归一的。\n\n一个向量 $u$ 到子空间 $W = \\operatorname{span}\\{\\phi_{1}, \\phi_{2}\\}$ 上的正交投影由算子 $P_{r}$ 给出，其定义为：\n$$\nP_{r} u = \\sum_{i=1}^{r} \\langle u, \\phi_{i} \\rangle_{L^{2}} \\phi_{i}\n$$\n在本例中，$r=2$，因此给定速度场 $u = \\begin{pmatrix} 1 \\\\ 0 \\\\ \\sqrt{2} \\end{pmatrix}$ 的投影为：\n$$\nP_{2} u = \\langle u, \\phi_{1} \\rangle_{L^{2}} \\phi_{1} + \\langle u, \\phi_{2} \\rangle_{L^{2}} \\phi_{2}\n$$\n首先，我们计算系数，即 $u$ 与基向量的内积：\n$$\n\\alpha_{1} = \\langle u, \\phi_{1} \\rangle_{L^{2}} = u^{\\top}\\phi_{1} = \\begin{pmatrix} 1 & 0 & \\sqrt{2} \\end{pmatrix} \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{pmatrix} = (1)\\left(\\frac{1}{\\sqrt{2}}\\right) + (0)\\left(\\frac{1}{\\sqrt{2}}\\right) + (\\sqrt{2})(0) = \\frac{1}{\\sqrt{2}}\n$$\n$$\n\\alpha_{2} = \\langle u, \\phi_{2} \\rangle_{L^{2}} = u^{\\top}\\phi_{2} = \\begin{pmatrix} 1 & 0 & \\sqrt{2} \\end{pmatrix} \\begin{pmatrix} -\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{pmatrix} = (1)\\left(-\\frac{1}{\\sqrt{2}}\\right) + (0)\\left(\\frac{1}{\\sqrt{2}}\\right) + (\\sqrt{2})(0) = -\\frac{1}{\\sqrt{2}}\n$$\n现在，我们构造投影向量 $P_{2}u$：\n$$\nP_{2} u = \\alpha_{1}\\phi_{1} + \\alpha_{2}\\phi_{2} = \\left(\\frac{1}{\\sqrt{2}}\\right) \\begin{pmatrix} \\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{pmatrix} + \\left(-\\frac{1}{\\sqrt{2}}\\right) \\begin{pmatrix} -\\frac{1}{\\sqrt{2}} \\\\ \\frac{1}{\\sqrt{2}} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} \\frac{1}{2} \\\\ \\frac{1}{2} \\\\ 0 \\end{pmatrix} + \\begin{pmatrix} \\frac{1}{2} \\\\ -\\frac{1}{2} \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix}\n$$\n投影误差是原始向量 $u$ 与其投影 $P_{2}u$ 之间的差：\n$$\nu - P_{2} u = \\begin{pmatrix} 1 \\\\ 0 \\\\ \\sqrt{2} \\end{pmatrix} - \\begin{pmatrix} 1 \\\\ 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0 \\\\ 0 \\\\ \\sqrt{2} \\end{pmatrix}\n$$\n最后，我们计算这个误差向量的 $L^{2}$-范数：\n$$\n\\|u - P_{2} u\\|_{L^{2}} = \\left\\| \\begin{pmatrix} 0 \\\\ 0 \\\\ \\sqrt{2} \\end{pmatrix} \\right\\|_{L^{2}} = \\sqrt{0^{2} + 0^{2} + (\\sqrt{2})^{2}} = \\sqrt{2}\n$$\n另外，根据正交投影的勾股定理，$\\|u - P_r u\\|_{L^2}^2 = \\|u\\|_{L^2}^2 - \\|P_r u\\|_{L^2}^2$。\n我们有 $\\|u\\|_{L^2}^2 = 1^2 + 0^2 + (\\sqrt{2})^2 = 3$。投影的范数为 $\\|P_r u\\|_{L^2}^2 = |\\alpha_1|^2 + |\\alpha_2|^2 = (\\frac{1}{\\sqrt{2}})^2 + (-\\frac{1}{\\sqrt{2}})^2 = \\frac{1}{2} + \\frac{1}{2} = 1$。\n因此，$\\|u - P_r u\\|_{L^2}^2 = 3 - 1 = 2$，这得出 $\\|u - P_r u\\|_{L^2} = \\sqrt{2}$。\n\n**第二部分：关于快照多样性与奇异值衰减的讨论**\n\n本征正交分解 (POD) 在最小二乘意义上为表示一组数据集成提供了一个最优基。POD 基向量 $\\{\\phi_i\\}_{i=1}^N$ 是通过对快照矩阵 $S \\in \\mathbb{R}^{N \\times M}$ 进行奇异值分解 (SVD) 得到的，其中 $N$ 是空间自由度的数量，$M$ 是快照的数量。$S$ 的列是离散的快照向量 $\\{s_j\\}_{j=1}^M$。$S$ 的 SVD 分解为 $S = U \\Sigma V^{\\top}$，其中 $U \\in \\mathbb{R}^{N \\times N}$ 的列是 POD 模态 $\\phi_i$，$\\Sigma \\in \\mathbb{R}^{N \\times M}$ 是由奇异值 $\\sigma_i \\geq 0$ 构成的对角矩阵。\n\nPOD 的最优性与奇异值相关联。对于任意秩 $r$，POD 基 $\\{\\phi_i\\}_{i=1}^r$ 能够最小化整个快照集成上的平均投影误差：\n$$\n\\min_{\\{\\psi_i\\}_{i=1}^r} \\sum_{j=1}^{M} \\left\\| s_j - \\sum_{i=1}^{r} \\langle s_j, \\psi_i \\rangle \\psi_i \\right\\|^2 = \\sum_{j=1}^{M} \\left\\| s_j - \\sum_{i=1}^{r} \\langle s_j, \\phi_i \\rangle \\phi_i \\right\\|^2 = \\sum_{i=r+1}^{k} \\sigma_i^2\n$$\n其中 $k=\\min(N,M)$。量 $\\sigma_i^2$ 可以解释为第 $i$ 个模态 $\\phi_i$ 捕获的“能量”或方差。该集成的总能量为 $\\sum_{j=1}^M \\|s_j\\|^2 = \\operatorname{tr}(S^{\\top}S) = \\sum_{i=1}^k \\sigma_i^2$。\n\n奇异值 $\\sigma_i$ 的衰减率取决于总能量如何在各个模态之间分布。这种分布与快照之间的线性相关性或关联性直接相关，而这正是其“多样性”的一种度量。让我们考虑快照相关算子，其矩阵表示为格拉姆矩阵 $C = S^{\\top}S \\in \\mathbb{R}^{M \\times M}$。元素 $C_{ij} = \\langle s_i, s_j \\rangle$ 衡量了快照 $s_i$ 和快照 $s_j$ 之间的相关性。$C$ 的特征值为 $\\lambda_i = \\sigma_i^2$。\n\n1.  **快照多样性低：** 如果快照不多样（例如，它们表示围绕一个稳态的微小波动，或描绘一个单一的、主导性的相干结构），那么快照向量 $\\{s_j\\}$ 将高度相关。这意味着这些向量几乎是线性相关的，快照矩阵 $S$ 的有效秩很低。相关矩阵 $C$ 将具有较大的非对角元素，反映了高度相关性。在这种情况下，$C$ 的特征值谱高度集中。少数几个主导特征值 $\\lambda_i$（以及奇异值 $\\sigma_i$）将捕获系统的大部分能量，而其余的值将非常小。这导致奇异值的**快速衰减**。该系统被认为是具有低内在维度的。\n\n2.  **快照多样性高：** 如果快照高度多样（例如，它们从不同的动力学模态、广泛的参数范围或具有多个活动尺度的湍流中采样），快照向量将不那么相关，并且在状态空间 $\\mathbb{R}^N$ 中倾向于更加正交。因此，相关矩阵 $C = S^{\\top}S$ 的非对角元素相对于其对角元素（$C_{jj} = \\|s_j\\|^2$）将较小。集成的能量更均匀地分布在更大的一组基础结构中。从信息论的角度来看，这意味着快照集的熵更高。这需要更多的基函数来捕获给定百分比的总能量。$C$ 的特征值 $\\lambda_i$ 将分布得更均匀，导致奇异值 $\\sigma_i$ 的**缓慢衰减**。这表明该系统具有高内在维度。\n\n总而言之，从第一性原理出发，快照集的多样性决定了快照相关矩阵 $C$ 的结构。更高的多样性导致快照向量集更加“分散”，使得 $C$ 更具对角占优性，其特征值谱也更平坦。由于 $C$ 的特征值是 $S$ 的奇异值的平方，因此更大的快照多样性直接对应于更慢的奇异值衰减率。", "answer": "$$\\boxed{\\sqrt{2}}$$", "id": "3369133"}, {"introduction": "在将流动问题简化为低维表示（例如，通过POD）或直接关注某个标量输出后，我们需要一个模型来建立输入参数与这些输出之间的映射关系。高斯过程（GP）回归是一种功能强大的非参数方法，它不仅能提供精确的预测，还能量化预测的不确定性。本实践练习聚焦于GP回归的核心数值算法，指导你通过Cholesky分解实现一个稳定且高效的GP后验预测实现，这是在实践中应用GP模型的关键一步。[@problem_id:3369162]", "problem": "考虑一个昂贵的计算流体动力学 (CFD) 流动模拟的代理建模场景，其中对一个标量感兴趣量使用高斯过程 (GP) 先验。训练输出收集在向量 $y \\in \\mathbb{R}^n$ 中，并被建模为潜在函数值的带噪观测，其独立高斯噪声的方差为 $\\sigma^2$。训练协方差矩阵为 $K \\in \\mathbb{R}^{n \\times n}$，训练输入与单个测试输入 $x_*$ 之间的交叉协方差向量为 $k_* \\in \\mathbb{R}^n$，测试输入处的自协方差为 $k(x_*,x_*) \\in \\mathbb{R}$。所有量均为无量纲。你的任务是基于多元高斯分布的条件属性，在 $x_*$ 处计算后验预测均值 $m_*(x_*)$ 和方差 $s_*^2(x_*)$，并使用一种不显式求逆任何矩阵的数值稳定算法。\n\n基本原理：高斯噪声下的高斯过程的后验分布可以通过对联合多元高斯分布进行条件化来获得。带噪训练观测和无噪测试函数值上的联合先验是高斯的，其均值为零，块协方差由 $K$、$k_*$ 和 $k(x_*,x_*)$ 构造，并且观测噪声以 $\\sigma^2 I$ 的形式加到训练块上。\n\n设计和实现要求：\n- 使用线性求解和对称正定矩阵 $K + \\sigma^2 I$ 的 Cholesky 分解来计算 $m_*(x_*)$ 和 $s_*^2(x_*)$。不要执行显式矩阵求逆。确保数值稳定性，并在必要时因数值舍入误差将 $s_*^2(x_*)$ 截断为零以强制其 $s_*^2(x_*) \\ge 0$。\n- 如果出现任何角度，均以弧度表示。在此问题中，所有量均为无量纲，不需要物理单位。\n- 最终输出应将所有提供的测试用例的结果聚合到单行中。每个测试用例的结果应为一个包含两个浮点数的列表 $[m_*, s_*^2]$，总输出应为这些列表的列表，以单行 Python 风格列表的形式打印，例如 $[[m_1,s_1],[m_2,s_2]]$。\n\n测试套件：\n提供四个测试用例的数值，用于检验计算的不同方面：\n\n- 案例 A (通用，良态)：\n  - $K = \\begin{bmatrix}\n  1.000000  0.726149  0.056135 \\\\\n  0.726149  1.000000  0.278037 \\\\\n  0.056135  0.278037  1.000000\n  \\end{bmatrix}$\n  - $k_* = \\begin{bmatrix} 0.278037 \\\\ 0.726149 \\\\ 0.726149 \\end{bmatrix}$\n  - $y = \\begin{bmatrix} 0.5 \\\\ 0.9 \\\\ -0.2 \\end{bmatrix}$\n  - $\\sigma^2 = 0.0001$\n  - $k(x_*,x_*) = 1.000000$\n\n- 案例 B (边界，单训练点)：\n  - $K = \\begin{bmatrix} 1.000000 \\end{bmatrix}$\n  - $k_* = \\begin{bmatrix} 0.600000 \\end{bmatrix}$\n  - $y = \\begin{bmatrix} 1.250000 \\end{bmatrix}$\n  - $\\sigma^2 = 0.00000001$\n  - $k(x_*,x_*) = 1.000000$\n\n- 案例 C (由噪声稳定的近奇异 $K$)：\n  - $K = \\begin{bmatrix}\n  1.000000  0.9999995 \\\\\n  0.9999995  1.000000\n  \\end{bmatrix}$\n  - $k_* = \\begin{bmatrix} 0.9999995 \\\\ 0.9999995 \\end{bmatrix}$\n  - $y = \\begin{bmatrix} 0.200000 \\\\ -0.200000 \\end{bmatrix}$\n  - $\\sigma^2 = 0.000001$\n  - $k(x_*,x_*) = 1.000000$\n\n- 案例 D (中等噪声和较大数据集)：\n  - $K = \\begin{bmatrix}\n  1.000000  0.800737  0.065810  0.000003 \\\\\n  0.800737  1.000000  0.249352  0.000084 \\\\\n  0.065810  0.249352  1.000000  0.028700 \\\\\n  0.000003  0.000084  0.028700  1.000000\n  \\end{bmatrix}$\n  - $k_* = \\begin{bmatrix} 0.135335 \\\\ 0.411789 \\\\ 0.945994 \\\\ 0.011109 \\end{bmatrix}$\n  - $y = \\begin{bmatrix} 0.000000 \\\\ 1.000000 \\\\ -0.500000 \\\\ 0.200000 \\end{bmatrix}$\n  - $\\sigma^2 = 0.050000$\n  - $k(x_*,x_*) = 1.000000$\n\n您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表形式的结果，格式应完全如下：\n$[[m_{A},s^{2}_{A}],[m_{B},s^{2}_{B}],[m_{C},s^{2}_{C}],[m_{D},s^{2}_{D}]]$\n其中 $[m_{X}, s^{2}_{X}]$ 对应于案例 $X \\in \\{A,B,C,D\\}$。", "solution": "## 问题验证\n\n### 第 1 步：提取已知条件\n该问题为高斯过程 (GP) 回归场景提供了以下量：\n-   $y \\in \\mathbb{R}^n$：一个包含 $n$ 个带噪训练输出的向量。\n-   $\\sigma^2 \\in \\mathbb{R}$：观测值上独立高斯噪声的方差。\n-   $K \\in \\mathbb{R}^{n \\times n}$：在 $n$ 个训练输入点上评估的 GP 先验的协方差矩阵。\n-   $x_*$：一个单个测试输入。\n-   $k_* \\in \\mathbb{R}^n$：训练输入和测试输入 $x_*$ 之间的交叉协方差向量。\n-   $k(x_*, x_*) \\in \\mathbb{R}$：在测试输入 $x_*$ 处的先验自协方差（方差）。\n-   任务是计算在测试输入 $x_*$ 处的后验预测均值 $m_*(x_*)$ 和方差 $s_*^2(x_*)$。\n-   要求使用特定的数值算法：使用 $K + \\sigma^2 I$ 的 Cholesky 分解，并避免显式矩阵求逆。\n-   提供了四个特定的测试用例（A, B, C, D），并给出了 $K$, $k_*$, $y$, $\\sigma^2$, 和 $k(x_*, x_*)$ 的数值。\n\n### 第 2 步：使用提取的已知条件进行验证\n根据验证标准对问题进行评估：\n\n-   **科学依据**：该问题基于高斯过程理论，这是现代统计学和机器学习的基石，常用于工程和科学领域的代理建模。其基本原理——通过对多元高斯分布进行条件化以获得后验——是一个基本且已确立的数学结果。其表述是标准且正确的。\n-   **适定性**：该问题是适定的。对于每个测试用例，都提供了所有必要的量（$K$, $k_*$, $y$, $\\sigma^2$, $k(x_*, x_*)$）。目标量，即后验均值和方差，由这些输入唯一确定。带噪观测的协方差矩阵 $K + \\sigma^2 I$ 保证是对称正定的，因为 $K$ 作为协方差矩阵是对称半正定的，并且通过加上一个正对角矩阵 $\\sigma^2 I$（因为所有给定的 $\\sigma^2 > 0$）对其进行了正则化。这确保了所需的 Cholesky 分解存在且唯一，并且相关的线性系统有唯一解。\n-   **客观性**：该问题以精确、客观的数学语言陈述，没有歧义、主观性或个人观点。\n-   **完整性和一致性**：该问题是自包含的。为所有测试用例提供的数据在维度上是一致的。没有矛盾之处。\n-   **现实性**：虽然数据是合成的，但它们代表了在真实世界代理建模应用中可能出现的值。这些案例旨在测试算法的鲁棒性，包括一个由噪声稳定的近奇异案例，这是一个现实的场景。\n\n### 第 3 步：结论与行动\n该问题是**有效的**。它在科学上是合理的、适定的，并且提供了所有必要的信息。现在将开始求解过程。\n\n## 基于原理的解决方案\n\n高斯过程回归的基础在于多元高斯分布的性质。我们将观测到的带噪训练数据 $y$ 与测试点处的潜在函数值 $f_* = f(x_*)$ 的联合分布建模为多元高斯分布。\n\n潜在函数值上的先验是一个高斯过程，因此训练点处的潜在值向量 $f$ 和测试点处的潜在值 $f_*$ 服从一个零均值的联合高斯分布：\n$$\n\\begin{pmatrix} f \\\\ f_* \\end{pmatrix} \\sim \\mathcal{N} \\left( \\begin{pmatrix} \\mathbf{0} \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} K  k_* \\\\ k_*^T  k(x_*,x_*) \\end{pmatrix} \\right)\n$$\n观测值 $y$ 是 $f$ 的带噪版本，建模为 $y = f + \\epsilon$，其中噪声 $\\epsilon$ 是独立同分布的，$\\epsilon \\sim \\mathcal{N}(\\mathbf{0}, \\sigma^2 I)$。观测值的协方差为 $\\text{Cov}(y) = \\text{Cov}(f + \\epsilon) = \\text{Cov}(f) + \\text{Cov}(\\epsilon) = K + \\sigma^2 I$。观测值 $y$ 和测试值 $f_*$ 之间的交叉协方差为 $\\text{Cov}(y, f_*) = \\text{Cov}(f + \\epsilon, f_*) = \\text{Cov}(f, f_*) = k_*$。\n\n因此，观测数据 $y$ 和潜在测试值 $f_*$ 的联合分布为：\n$$\n\\begin{pmatrix} y \\\\ f_* \\end{pmatrix} \\sim \\mathcal{N} \\left( \\begin{pmatrix} \\mathbf{0} \\\\ 0 \\end{pmatrix}, \\begin{pmatrix} K + \\sigma^2 I  k_* \\\\ k_*^T  k(x_*,x_*) \\end{pmatrix} \\right)\n$$\n后验分布 $p(f_* | y)$ 是通过对此联合高斯分布进行条件化得到的。分块高斯分布的条件均值和方差的标准公式给出了后验预测均值 $m_*(x_*)$ 和方差 $s_*^2(x_*)$：\n$$\nm_*(x_*) = k_*^T (K + \\sigma^2 I)^{-1} y\n$$\n$$\ns_*^2(x_*) = k(x_*,x_*) - k_*^T (K + \\sigma^2 I)^{-1} k_*\n$$\n\n### 数值稳定的实现\n直接计算矩阵逆 $(K + \\sigma^2 I)^{-1}$ 在数值上不稳定且计算成本高 ($O(n^3)$)。该问题正确地禁止了这种做法。我们采用一种基于 Cholesky 分解的稳定且高效的算法。\n\n令 $A = K + \\sigma^2 I$。由于 $A$ 是对称正定的，它有唯一的 Cholesky 分解 $A = L L^T$，其中 $L$ 是一个下三角矩阵。\n\n**1. 后验均值计算：**\n均值为 $m_*(x_*) = k_*^T (A^{-1} y)$。我们可以定义一个向量 $\\alpha = A^{-1} y$。那么，均值就是点积 $m_*(x_*) = k_*^T \\alpha$。为了在不求逆的情况下求出 $\\alpha$，我们求解线性系统 $A \\alpha = y$：\n$$\nL L^T \\alpha = y\n$$\n这可以通过三角替换分两步求解，该方法数值稳定且高效 ($O(n^2)$)：\n-   首先，使用前向替换求解 $L z = y$ 得到 $z$。\n-   然后，使用后向替换求解 $L^T \\alpha = z$ 得到 $\\alpha$。\n\n**2. 后验方差计算：**\n方差为 $s_*^2(x_*) = k(x_*,x_*) - k_*^T A^{-1} k_*$。二次型 $k_*^T A^{-1} k_*$ 可以更稳定地计算。使用 Cholesky 因子 $L$：\n$$\nk_*^T A^{-1} k_* = k_*^T (L L^T)^{-1} k_* = k_*^T (L^T)^{-1} L^{-1} k_* = (L^{-1} k_*)^T (L^{-1} k_*)\n$$\n令向量 $v$ 定义为三角系统 $L v = k_*$ 的解。这可以通过前向替换求得。然后，二次型就是 $v$ 的欧几里得范数的平方：\n$$\nk_*^T A^{-1} k_* = v^T v = \\|v\\|^2_2\n$$\n因此，后验方差为：\n$$\ns_*^2(x_*) = k(x_*,x_*) - v^T v\n$$\n这种方法只需要一次三角求解 ($O(n^2)$)，避免了第二次完整的线性系统求解，而且比计算乘积 $k_*^T (A^{-1} k_*)$ 在数值上更稳定。\n\n最后，由于潜在的浮点舍入误差，计算出的方差可能是一个小的负数。为确保物理有效性，将其截断为零：\n$$\ns_*^2(x_*) = \\max(0, s_*^2(x_*))\n$$\n\n### 算法总结\n1.  构造矩阵 $A = K + \\sigma^2 I$。\n2.  计算 Cholesky 分解 $L = \\text{cholesky}(A)$，其中 $L$ 是下三角矩阵。\n3.  计算后验均值 $m_*(x_*)$：\n    a. 使用前向替换求解 $L z = y$ 得到 $z$。\n    b. 使用后向替换求解 $L^T \\alpha = z$ 得到 $\\alpha$。\n    c. 计算 $m_*(x_*) = k_*^T \\alpha$。\n4.  计算后验方差 $s_*^2(x_*)$：\n    a. 使用前向替换求解 $L v = k_*$ 得到 $v$。\n    b. 计算方差项为 $v^T v$。\n    c. 计算 $s_*^2(x_*) = k(x_*,x_*) - v^T v$。\n5.  强制非负性：$s_*^2(x_*) = \\max(0, s_*^2(x_*))$。\n6.  返回数对 $[m_*(x_*), s_*^2(x_*)]$。\n\n该算法为所提供的四个测试用例中的每一个都进行了实现。", "answer": "```python\nimport numpy as np\nfrom scipy.linalg import cholesky, solve_triangular\n\ndef compute_posterior_mean_variance(K, k_star, y, sigma2, k_xx):\n    \"\"\"\n    Computes the posterior predictive mean and variance for a Gaussian Process.\n\n    This function uses a numerically stable algorithm based on Cholesky\n    factorization, avoiding explicit matrix inversion.\n\n    Args:\n        K (np.ndarray): The n x n training covariance matrix.\n        k_star (np.ndarray): The n x 1 cross-covariance vector.\n        y (np.ndarray): The n x 1 vector of training outputs.\n        sigma2 (float): The variance of the observation noise.\n        k_xx (float): The self-covariance at the test point.\n\n    Returns:\n        list: A list containing the posterior mean and posterior variance, [m_star, s2_star].\n    \"\"\"\n    # Ensure inputs are numpy arrays of appropriate dimension\n    K = np.atleast_2d(K)\n    k_star = np.atleast_1d(k_star)\n    y = np.atleast_1d(y)\n    n = K.shape[0]\n\n    # Step 1: Construct the matrix A = K + sigma^2 * I\n    A = K + sigma2 * np.eye(n)\n\n    # Step 2: Compute the Cholesky factorization A = L L^T\n    try:\n        L = cholesky(A, lower=True)\n    except np.linalg.LinAlgError:\n        # This should not happen for valid inputs as A is positive definite\n        return [np.nan, np.nan]\n\n    # Step 3: Calculate the posterior mean m_star\n    # Solve L z = y for z\n    z = solve_triangular(L, y, lower=True)\n    # Solve L^T alpha = z for alpha\n    alpha = solve_triangular(L.T, z, lower=False)\n    # Compute mean m_star = k_star^T * alpha\n    m_star = k_star.T @ alpha\n\n    # Step 4: Calculate the posterior variance s2_star\n    # Solve L v = k_star for v\n    v = solve_triangular(L, k_star, lower=True)\n    # Compute variance s2_star = k(x*,x*) - v^T v\n    s2_star = k_xx - v.T @ v\n\n    # Step 5: Enforce non-negativity of variance\n    s2_star = max(0.0, s2_star)\n\n    return [m_star, s2_star]\n\ndef solve():\n    \"\"\"\n    Defines test cases and computes the results, printing them in the required format.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A: general, well-conditioned\n        {\n            \"K\": np.array([\n                [1.000000, 0.726149, 0.056135],\n                [0.726149, 1.000000, 0.278037],\n                [0.056135, 0.278037, 1.000000]\n            ]),\n            \"k_star\": np.array([0.278037, 0.726149, 0.726149]),\n            \"y\": np.array([0.5, 0.9, -0.2]),\n            \"sigma2\": 0.0001,\n            \"k_xx\": 1.000000\n        },\n        # Case B: boundary, single training point\n        {\n            \"K\": np.array([[1.000000]]),\n            \"k_star\": np.array([0.600000]),\n            \"y\": np.array([1.250000]),\n            \"sigma2\": 0.00000001,\n            \"k_xx\": 1.000000\n        },\n        # Case C: near-singular K stabilized by noise\n        {\n            \"K\": np.array([\n                [1.000000, 0.9999995],\n                [0.9999995, 1.000000]\n            ]),\n            \"k_star\": np.array([0.9999995, 0.9999995]),\n            \"y\": np.array([0.200000, -0.200000]),\n            \"sigma2\": 0.000001,\n            \"k_xx\": 1.000000\n        },\n        # Case D: moderate noise and larger training set\n        {\n            \"K\": np.array([\n                [1.000000, 0.800737, 0.065810, 0.000003],\n                [0.800737, 1.000000, 0.249352, 0.000084],\n                [0.065810, 0.249352, 1.000000, 0.028700],\n                [0.000003, 0.000084, 0.028700, 1.000000]\n            ]),\n            \"k_star\": np.array([0.135335, 0.411789, 0.945994, 0.011109]),\n            \"y\": np.array([0.000000, 1.000000, -0.500000, 0.200000]),\n            \"sigma2\": 0.050000,\n            \"k_xx\": 1.000000\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        result = compute_posterior_mean_variance(\n            case[\"K\"], case[\"k_star\"], case[\"y\"], case[\"sigma2\"], case[\"k_xx\"]\n        )\n        results.append(result)\n\n    # Format the output string as a list of lists.\n    # The default str() for a list includes spaces, which is a standard\n    # Python-style representation and matches the template structure.\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3369162"}, {"introduction": "傅里叶神经算子（FNO）等现代方法代表了端到端的代理建模范式，能够直接学习无限维函数空间之间的映射，从而无需像POD那样显式构造降维基。然而，这些强大的模型也带来了新的挑战，尤其是在求解随时间演化的PDE时，长期部署的稳定性是一个关键问题。本练习将带你直面这一前沿挑战，通过将物理原理（谱域CFL条件）嵌入到模型中，学习如何约束一个不稳定的神经算子 surrogate，从而确保其长期预测的物理保真度和鲁棒性。[@problem_id:3369161]", "problem": "考虑一个周期性域上的一维线性平流方程，由 $\\partial_t u + c \\partial_x u = 0$ 给出，其中 $u(x,t)$ 是一个标量场，$c$ 是恒定的平流速度，$x \\in [0,L)$，且 $t \\ge 0$。其基本原理是空间傅里叶变换，以及在精确傅里叶演化下，波数为 $k$ 的模式按 $u_k(t+\\Delta t) = \\exp(-\\mathrm{i} k c \\Delta t) u_k(t)$ 的规律推进，其中复放大因子的模长为1。一个试图预测每种模式更新的傅里叶代理模型可能会产生模长超过1或相位增量与平流不一致的复放大因子，这在多步迭代应用下会导致滚动展开不稳定性（范数爆炸）。\n\n您的任务是设计并实现一个程序，该程序实例化一个简单的傅里叶神经算子代理，用于每种模式的复放大因子，并使用谱空间中的类Courant–Friedrichs–Lewy (CFL)条件对其进行约束，以经验性地绘制稳定性区域。该程序将：\n\n1. 在长度为 $L$ 的周期性域上构建一个包含 $N$ 个点的空间网格，其间距为 $\\Delta x = L/N$。考虑无量纲场，并以弧度处理角度。\n\n2. 对于与 $[0,L)$ 上的傅里叶网格一致的整数波数 $k$，定义精确的每模式复放大因子 $G_k^{\\mathrm{true}} = \\exp(-\\mathrm{i} k c \\Delta t)$。\n\n3. 定义每种模式的含噪声代理预测，模型为 $G_k^{\\mathrm{pred}} = G_k^{\\mathrm{true}} \\cdot A_k \\cdot \\exp(\\mathrm{i} \\Phi_k)$，其中 $A_k$ 和 $\\Phi_k$ 表示振幅和相位预测误差，它们是根据具有均值和标准差参数的给定分布为每种模式独立抽取的。振幅扰动的建模应使其满足 $A_k \\ge 0$ 且中心在1附近，而相位扰动中心在0附近，并以弧度为单位指定。\n\n4. 从一个随机初始场 $u(x,0)$ 开始，在 $T$ 个步骤上实现两种滚动展开变体：\n   - 无约束：在每一步于谱空间中应用 $G_k^{\\mathrm{pred}}$ 以获得 $u(x,t)$。\n   - 受约束：在滚动展开前，修改每种模式的 $G_k^{\\mathrm{pred}}$ 以强制执行谱空间类CFL条件。受约束的放大因子 $G_k^{\\mathrm{cfl}}$ 必须满足以下所有定性要求：\n     a) 振幅界：强制 $|G_k^{\\mathrm{cfl}}| \\le 1$。\n     b) 相位增量界：强制 $|\\Delta \\phi_k| \\le |k c \\Delta t|$，其中 $\\Delta \\phi_k$ 是模式 $k$ 的每步相位，该界限以弧度表示。\n     c) 当无量纲CFL比 $r = |c| \\Delta t / \\Delta x$ 超过 $1$ 时附加阻尼：引入一个单调阻尼因子，该因子随超出量 $r-1$ 和归一化波数大小 $|k|/k_{\\max}$ 的增加而增加，其中 $k_{\\max}$ 是网格上可分辨的最大波数大小。\n\n5. 将滚动展开的稳定性定义为 $u(x,t)$ 的离散 $\\ell^2$ 范数相对于初始范数保持有界。具体来说，在每一步计算离散范数 $||u^n||_2$，如果 $||u^n||_2 / ||u^0||_2$ 超过一个固定的增长阈值 $G_{\\mathrm{thr}}$，则宣告发生爆炸。如果在 $T$ 步内没有发生爆炸，则认为模拟是稳定的。离散范数应使用与网格一致的无量纲单位进行计算。\n\n6. 为了经验性地绘制稳定性区域，针对指定的参数值测试套件运行上述过程。对于每种情况，记录一个布尔对 $[\\mathrm{stable\\_unconstrained}, \\mathrm{stable\\_constrained}]$。\n\n使用以下测试套件，其中所有角度均以弧度为单位，平流速度 $c$ 的单位是米/秒，$L$ 的单位是米。通过 $\\Delta t = r \\Delta x / |c|$ 从指定的无量纲CFL比 $r$ 计算 $\\Delta t$。在所有情况下，使用周期性域长度 $L = 2\\pi$，$N = 64$ 个网格点，以及 $T = 100$ 步。设 $G_{\\mathrm{thr}} = 100$。振幅误差参数 $(\\mu_a,\\sigma_a)$ 定义了中心在 $1+\\mu_a$ 附近、变异性为 $\\sigma_a$ 的 $A_k$，相位误差标准差为 $\\sigma_\\phi$。\n\n- 案例1：$c = 1$, $r = 0.5$, $\\mu_a = -0.02$, $\\sigma_a = 0.02$, $\\sigma_\\phi = 0.05$。\n- 案例2：$c = 1$, $r = 1.0$, $\\mu_a = 0.05$, $\\sigma_a = 0.05$, $\\sigma_\\phi = 0.10$。\n- 案例3：$c = 1$, $r = 2.0$, $\\mu_a = 0.10$, $\\sigma_a = 0.05$, $\\sigma_\\phi = 0.15$。\n- 案例4：$c = 1$, $r = 3.0$, $\\mu_a = 0.20$, $\\sigma_a = 0.10$, $\\sigma_\\phi = 0.20$。\n- 案例5：$c = 1$, $r = 0.1$, $\\mu_a = 0.0$, $\\sigma_a = 0.0$, $\\sigma_\\phi = 0.0$。\n\n您的程序应生成单行输出，其中包含结果，格式为方括号括起来的逗号分隔列表，每个条目是对应测试用例的布尔对，格式完全如下：$[[b_1^{\\mathrm{uncon}},b_1^{\\mathrm{con}}],[b_2^{\\mathrm{uncon}},b_2^{\\mathrm{con}}],\\dots,[b_5^{\\mathrm{uncon}},b_5^{\\mathrm{con}}]]$，其中每个 $b_i$ 为 $\\mathrm{True}$ 或 $\\mathrm{False}$。", "solution": "用户提供的问题经评估有效。它在科学上基于计算流体动力学和数值分析的原理，特别是关于双曲型偏微分方程代理模型的稳定性。该问题是适定的、客观的，并包含足够的信息来构建唯一的解决方案，前提是对指定的定性要求进行合理和标准的解释。我们开始进行求解。\n\n核心任务是研究一维线性平流方程 $\\partial_t u + c \\partial_x u = 0$ 的傅里叶神经算子代理的稳定性。该分析通过比较代理的无约束滚动展开与一个在谱空间中强制执行类似于Courant–Friedrichs–Lewy (CFL)条件的稳定性准则的受约束版本来进行。\n\n首先，我们建立计算域和离散化。物理域是一个周期性区间 $x \\in [0, L)$，其中 $L=2\\pi$。该域被离散化为 $N=64$ 个网格点，从而得到网格间距 $\\Delta x = L/N = 2\\pi/64 = \\pi/32$。离散空间坐标为 $x_j = j \\Delta x$，其中 $j \\in \\{0, 1, \\dots, N-1\\}$。\n\n解 $u(x,t)$ 在傅里叶基中表示。离散傅里叶变换 (DFT) 及其逆变换用于在物理表示和谱表示之间切换。与网格对应的波数 $k$ 由 $k = 2\\pi f$ 给出，其中 $f$ 是来自 `numpy.fft.fftfreq(N, d=Δx)` 的离散频率。对于 $L=2\\pi$，这些波数是范围从 $-(N/2)$ 到 $(N/2)-1$ 的整数。可分辨的最大波数大小是奈奎斯特波数，$k_{\\max} = \\pi / \\Delta x = N/2$。\n\n平流方程的精确解在傅里叶域中根据规则 $u_k(t+\\Delta t) = G_k^{\\mathrm{true}} u_k(t)$ 演化，其中 $u_k(t)$ 是模式 $k$ 在时间 $t$ 的傅里叶系数。精确的复放大因子是一个纯相位旋转：\n$$\nG_k^{\\mathrm{true}} = \\exp(-\\mathrm{i} k c \\Delta t)\n$$\n其中 $\\mathrm{i} = \\sqrt{-1}$。对于所有的 $k$，模长 $|G_k^{\\mathrm{true}}| = 1$，这确保了解的范数随时间守恒。时间步长 $\\Delta t$ 由无量纲CFL比 $r = |c|\\Delta t / \\Delta x$ 确定，得到 $\\Delta t = r \\Delta x / |c|$。\n\n代理模型会引入误差。我们将代理预测的放大因子 $G_k^{\\mathrm{pred}}$ 建模为对真实因子的扰动：\n$$\nG_k^{\\mathrm{pred}} = G_k^{\\mathrm{true}} \\cdot A_k \\cdot \\exp(\\mathrm{i} \\Phi_k)\n$$\n此处，$A_k$ 是一个乘性振幅误差，$\\Phi_k$ 是一个加性相位误差。根据问题描述，我们将这些误差建模为从指定分布中抽取的随机变量：\n-   振幅扰动 $A_k$ 通过从正态分布 $\\mathcal{N}(1+\\mu_a, \\sigma_a^2)$ 中抽样并截断于零以确保非负性来建模：$A_k = \\max(0, \\mathcal{N}(1+\\mu_a, \\sigma_a^2))$。\n-   相位误差 $\\Phi_k$ 从零均值正态分布中抽取：$\\Phi_k \\sim \\mathcal{N}(0, \\sigma_\\phi^2)$。\n\n模拟滚动展开从一个随机初始条件 $u(x,0)$ 开始，该条件从标准正态分布生成。在 $T=100$ 步上的滚动展开稳定性通过监测离散 $\\ell^2$ 范数来确定，此处定义为均方根范数 $||u^n||_2 = \\sqrt{\\frac{1}{N}\\sum_{j=0}^{N-1} |u_j^n|^2}$。如果范数放大超过阈值 $G_{\\mathrm{thr}} = 100$，即对于任何步骤 $n \\in \\{1, \\dots, T\\}$ 都有 $||u^n||_2 / ||u^0||_2 > G_{\\mathrm{thr}}$，则宣布模拟不稳定。\n\n为每个测试案例模拟两种滚动展开场景：\n1.  **无约束滚动展开**：在每一步使用含噪声的预测 $u_k^{n+1} = G_k^{\\mathrm{pred}} u_k^n$ 来更新傅里叶系数。如果任何 $|G_k^{\\mathrm{pred}}| > 1$ 或相位误差发生破坏性累积，此方法容易变得不稳定。\n\n2.  **受约束滚动展开**：在每个更新步骤之前，将预测的放大因子 $G_k^{\\mathrm{pred}}$ 修改为受约束的版本 $G_k^{\\mathrm{cfl}}$，$u_k^{n+1} = G_k^{\\mathrm{cfl}} u_k^n$。$G_k^{\\mathrm{cfl}}$ 的设计遵循指定的定性要求：\n    a.  **振幅界**：放大因子的模长不得超过1。设 $G_k^{\\mathrm{pred}} = |G_k^{\\mathrm{pred}}| \\exp(\\mathrm{i} \\psi_k^{\\mathrm{pred}})$。我们通过裁剪预测的模长来强制执行 $|G_k^{\\mathrm{cfl}}| \\le 1$：$|G_k^{\\mathrm{cfl}}|' = \\min(|G_k^{\\mathrm{pred}}|, 1)$。\n    b.  **相位增量界**：放大因子的相位 $\\psi_k$ 必须满足 $|\\psi_k| \\le |k c \\Delta t|$。这是一个谱空间CFL条件，确保任何模式的数值相速度不超过物理平流速度。预测的相位是 $\\psi_k^{\\mathrm{pred}} = -kc\\Delta t + \\Phi_k$。我们通过裁剪相位来强制执行该约束：$\\psi_k^{\\mathrm{cfl}} = \\text{clip}(\\psi_k^{\\mathrm{pred}}, -|kc\\Delta t|, |kc\\Delta t|)$。\n    c.  **附加阻尼**：对于CFL比 $r > 1$ 的情况，引入一个附加的阻尼因子，该因子随CFL超出量 $r-1$ 和归一化波数 $|k|/k_{\\max}$ 的增加而增加。我们将其表述为应用于振幅的乘性因子 $D_k$：\n        $$\n        D_k = \n        \\begin{cases} \n        \\max\\left(0, 1 - (r-1) \\frac{|k|}{k_{\\max}}\\right)  \\text{if } r > 1 \\\\\n        1  \\text{if } r \\le 1 \n        \\end{cases}\n        $$\n    最终的受约束放大因子通过组合这些修改来构建：\n    $$\n    G_k^{\\mathrm{cfl}} = \\min(|G_k^{\\mathrm{pred}}|, 1) \\cdot D_k \\cdot \\exp(\\mathrm{i} \\cdot \\text{clip}(\\psi_k^{\\mathrm{pred}}, -|kc\\Delta t|, |kc\\Delta t|))\n    $$\n这种设计通过构造确保了受约束的滚动展开保持稳定，防止了振幅爆炸和不符合物理规律的信息传播速度。程序将为提供的测试套件执行这些模拟，并报告每种情况下无约束和受约束滚动展开的稳定性。为了可复现性，使用了一个固定的随机种子。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Solves the problem of mapping stability regions for a Fourier surrogate model\n    of the 1D linear advection equation.\n    \"\"\"\n\n    # --- Simulation Parameters ---\n    L = 2.0 * np.pi  # Domain length (meters)\n    N = 64           # Number of grid points\n    T = 100          # Number of time steps for roll-out\n    G_thr = 100.0    # Norm growth threshold for instability\n\n    # --- Test Suite ---\n    test_cases = [\n        # c, r, mu_a, sigma_a, sigma_phi\n        (1.0, 0.5, -0.02, 0.02, 0.05),\n        (1.0, 1.0, 0.05, 0.05, 0.10),\n        (1.0, 2.0, 0.10, 0.05, 0.15),\n        (1.0, 3.0, 0.20, 0.10, 0.20),\n        (1.0, 0.1, 0.0, 0.0, 0.0),\n    ]\n\n    # Use a fixed random seed for reproducibility\n    np.random.seed(42)\n\n    # --- Pre-computation for the grid ---\n    dx = L / N\n    k = 2.0 * np.pi * np.fft.fftfreq(N, d=dx)\n    k_max_abs = np.pi / dx # Nyquist wavenumber\n\n    # Generate a single random initial condition for all runs\n    u0 = np.random.randn(N)\n    norm_u0 = np.linalg.norm(u0) / np.sqrt(N)\n    u0_hat = np.fft.fft(u0)\n\n    results = []\n    for case in test_cases:\n        c, r, mu_a, sigma_a, sigma_phi = case\n        \n        if c == 0:\n            # Avoid division by zero, although not in test cases\n            dt = 0\n        else:\n            dt = r * dx / abs(c)\n\n        # --- Generate Surrogate Errors ---\n        # Generate noise once per case for both roll-outs\n        # Amplitude error factor\n        A_k_noise = np.maximum(0, np.random.normal(1.0 + mu_a, sigma_a, N))\n        # Phase error (in radians)\n        Phi_k_noise = np.random.normal(0.0, sigma_phi, N)\n\n        # --- Define Amplification Factors ---\n        G_k_true = np.exp(-1j * k * c * dt)\n        G_k_pred = G_k_true * A_k_noise * np.exp(1j * Phi_k_noise)\n\n        # --- Define Constrained Amplification Factor (G_k_cfl) ---\n        # a) Amplitude bound\n        mag_pred = np.abs(G_k_pred)\n        mag_cfl_1 = np.minimum(mag_pred, 1.0)\n        \n        # b) Phase increment bound\n        phase_pred = np.angle(G_k_pred)\n        phase_bound = np.abs(k * c * dt)\n        phase_cfl = np.clip(phase_pred, -phase_bound, phase_bound)\n        \n        # c) Additional damping for r > 1\n        mag_cfl_2 = mag_cfl_1\n        if r > 1.0:\n            # Damping factor is 0 for k=k_max, 1 for k=0, and linear in between\n            damping_factor = np.maximum(0, 1.0 - (r - 1.0) * np.abs(k) / k_max_abs)\n            mag_cfl_2 = mag_cfl_1 * damping_factor\n        \n        G_k_cfl = mag_cfl_2 * np.exp(1j * phase_cfl)\n\n        # --- Run Simulations ---\n        case_results = []\n        for constrained in [False, True]:\n            u_hat = u0_hat.copy()\n            is_stable = True\n            \n            G_k = G_k_cfl if constrained else G_k_pred\n\n            for _ in range(T):\n                u_hat = G_k * u_hat\n                u_n = np.fft.ifft(u_hat)\n                norm_u_n = np.linalg.norm(u_n) / np.sqrt(N)\n                \n                if norm_u_n / norm_u0 > G_thr:\n                    is_stable = False\n                    break\n            \n            case_results.append(is_stable)\n        \n        results.append(case_results)\n\n    # Format the final output string to be exactly as specified\n    # e.g., [[False,True],[False,True],...]\n    result_strings = [str(pair).replace(\" \", \"\") for pair in results]\n    final_output = f\"[{','.join(result_strings)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3369161"}]}