{"hands_on_practices": [{"introduction": "在计算流体动力学中，网格收敛性分析是验证数值解可靠性的基石。本练习将经典的理查森外推法（Richardson extrapolation）与现代贝叶斯思想相结合，旨在将离散化误差从一个确定性误差源，转化为一个可量化的不确定性来源。通过构建贝叶斯网格收敛指数（Bayesian Grid Convergence Index），你将学会如何从一系列网格上的计算结果中，不仅估计出渐近解的点值，还能为其推断出一个完整的后验分布。[@problem_id:3345875]", "problem": "考虑一个定常层流的计算流体动力学（CFD）模拟序列，其无量纲的目标量（QoI）记为 $Q$，在三个尺寸分别为 $h_1$、$h_2$ 和 $h_3$ 的连续加密的均匀网格上计算得到。假设采用二阶有限体积格式且解是光滑的，因此离散误差可以用一个从控制偏微分方程的泰勒级数一致性推导出的主阶渐近截断误差模型来描述：具体来说，对于足够小的 $h$，依赖于网格的目标量满足 $Q(h) = Q_{\\infty} + C h^{p} + \\mathcal{O}(h^{p+1})$，其中 $Q_{\\infty}$ 是在极限 $h \\to 0$ 时的渐近目标量，$C$ 是一个未知常数，$p$ 是（未知的）精度阶。定义一个常数网格加密比 $r$，使得 $h_2 = r h_1$ 且 $h_3 = r h_2$。\n\n给定来自三个网格的数据，其常数加密比为 $r$：\n- $h_1 = 5.0 \\times 10^{-2}$，$h_2 = 1.0 \\times 10^{-1}$，$h_3 = 2.0 \\times 10^{-1}$，因此 $r = 2$。\n- $Q(h_1) = 1.60125$，$Q(h_2) = 1.60500$，$Q(h_3) = 1.62000$。\n\n任务 A：从给定的渐近误差模型出发，在不预先假设 $p$ 已知的情况下，推导出仅用 $(Q(h_1), Q(h_2), Q(h_3))$ 和常数加密比 $r$ 表示的观测精度阶公式 $p$。然后，使用所提供的数据计算 $p$。\n\n任务 B：使用相同的渐近误差模型，推导用两个网格的解 $(Q(h_1), Q(h_2))$、加密比 $r$ 和精度阶 $p$ 表示的 $Q_{\\infty}$ 的理查森外推表达式。在推导出通用表达式之前，不要代入具体的数值。然后，使用任务 A 中得到的观测精度阶和所提供的数据计算 $Q_{\\infty}$。\n\n任务 C：为了表征外推中的不确定性，通过对三个观测到的目标量用关于渐近模型的加性随机偏差进行建模，构建一个贝叶斯网格收敛指数（GCI）：\n$$\nQ(h_i) = Q_{\\infty} + C h_i^{p} + \\varepsilon_i, \\quad i \\in \\{1,2,3\\},\n$$\n其中 $\\varepsilon_i$ 是独立同分布的零均值高斯随机变量，方差为 $\\sigma^{2}$，$p$ 是任务 A 中得到的观测精度阶。对 $(Q_{\\infty}, C)$ 采用非正则无信息先验 $p(Q_{\\infty}, C) \\propto 1$，并假设给定 $(Q_{\\infty}, C)$ 时数据是条件独立的。设已知噪声水平为 $\\sigma = 1.0 \\times 10^{-3}$ (无量纲)。在此模型下，推导出 $Q_{\\infty}$ 的后验分布的封闭形式。然后，使用所提供的数据数值计算 $Q_{\\infty}$ 的后验均值。\n\n将 $Q_{\\infty}$ 的后验均值的最终数值答案表示为一个无量纲数。将最终答案四舍五入到五位有效数字。", "solution": "用户提出了一个关于计算流体动力学 (CFD) 中网格收敛性分析的多部分问题。该问题被认为是有效的，因为它在科学上基于标准的数值分析技术（理查森外推），问题提法清晰，数据充分且一致，语言客观。这些任务从确定性参数估计逻辑地进展到贝叶斯不确定性表征。\n\n### 任务 A：观测精度阶 $p$ 的推导与计算\n\n问题陈述，对于足够小的网格尺寸 $h$，目标量（QoI）$Q(h)$ 服从渐近误差模型：\n$$\nQ(h) = Q_{\\infty} + C h^{p} + \\mathcal{O}(h^{p+1})\n$$\n其中 $Q_{\\infty}$ 是精确解，$C$ 是一个常数，$p$ 是精度阶。我们被给予了在三个网格上的解 $Q_1 = Q(h_1)$、$Q_2 = Q(h_2)$ 和 $Q_3 = Q(h_3)$，网格尺寸通过一个常数加密比 $r$ 相关联，使得 $h_2 = r h_1$ 且 $h_3 = r h_2 = r^2 h_1$。\n\n忽略高阶项 $\\mathcal{O}(h^{p+1})$，我们可以写出以下方程组：\n\\begin{align*}\nQ_1  \\approx Q_{\\infty} + C h_1^{p} \\quad (1) \\\\\nQ_2  \\approx Q_{\\infty} + C h_2^{p} = Q_{\\infty} + C (r h_1)^{p} = Q_{\\infty} + C r^{p} h_1^{p} \\quad (2) \\\\\nQ_3  \\approx Q_{\\infty} + C h_3^{p} = Q_{\\infty} + C (r h_2)^{p} = Q_{\\infty} + C r^{p} h_2^{p} = Q_{\\infty} + C r^{2p} h_1^{p} \\quad (3)\n\\end{align*}\n\n为了求 $p$，我们首先通过对连续方程作差来消去未知数 $Q_{\\infty}$：\n$$\nQ_2 - Q_1 \\approx (Q_{\\infty} + C r^{p} h_1^{p}) - (Q_{\\infty} + C h_1^{p}) = C h_1^{p} (r^{p} - 1)\n$$\n$$\nQ_3 - Q_2 \\approx (Q_{\\infty} + C r^{2p} h_1^{p}) - (Q_{\\infty} + C r^{p} h_1^{p}) = C h_1^{p} (r^{2p} - r^{p}) = C h_1^{p} r^{p} (r^{p} - 1)\n$$\n现在，我们可以通过对这两个差值取比率来消去未知项 $C h_1^p$：\n$$\n\\frac{Q_3 - Q_2}{Q_2 - Q_1} \\approx \\frac{C h_1^{p} r^{p} (r^{p} - 1)}{C h_1^{p} (r^{p} - 1)} = r^{p}\n$$\n对两边取自然对数求解 $p$，得到观测精度阶的公式：\n$$\n\\ln\\left(\\frac{Q_3 - Q_2}{Q_2 - Q_1}\\right) \\approx p \\ln(r) \\implies p \\approx \\frac{\\ln\\left(\\frac{Q_3 - Q_2}{Q_2 - Q_1}\\right)}{\\ln(r)}\n$$\n现在，我们代入所提供的数值数据：\n$Q_1 = Q(h_1) = 1.60125$\n$Q_2 = Q(h_2) = 1.60500$\n$Q_3 = Q(h_3) = 1.62000$\n$r = 2$\n\n首先，计算差值：\n$Q_2 - Q_1 = 1.60500 - 1.60125 = 0.00375$\n$Q_3 - Q_2 = 1.62000 - 1.60500 = 0.01500$\n\n接下来，计算比率：\n$$\n\\frac{Q_3 - Q_2}{Q_2 - Q_1} = \\frac{0.01500}{0.00375} = 4\n$$\n最后，计算 $p$：\n$$\np = \\frac{\\ln(4)}{\\ln(2)} = \\frac{\\ln(2^2)}{\\ln(2)} = \\frac{2 \\ln(2)}{\\ln(2)} = 2\n$$\n观测到的精度阶恰好为 $p=2$。\n\n### 任务 B：$Q_{\\infty}$ 的理查森外推\n\n为了推导 $Q_{\\infty}$ 的理查森外推公式，我们使用方程组中的前两个方程 (1) 和 (2)，它们构成了关于未知数 $Q_{\\infty}$ 和 $C$ 的一个二元线性方程组：\n\\begin{align*}\nQ_1  \\approx Q_{\\infty} + C h_1^{p} \\\\\nQ_2  \\approx Q_{\\infty} + C r^{p} h_1^{p}\n\\end{align*}\n为了消去 $C$，我们可以将第一个方程乘以 $r^p$ 然后减去第二个方程：\n$$\nr^{p} Q_1 \\approx r^{p} Q_{\\infty} + r^{p} C h_1^{p}\n$$\n$$\n(r^{p} Q_1) - Q_2 \\approx (r^{p} Q_{\\infty} - Q_{\\infty}) + (r^{p} C h_1^{p} - r^{p} C h_1^{p})\n$$\n$$\nr^{p} Q_1 - Q_2 \\approx Q_{\\infty} (r^{p} - 1)\n$$\n求解 $Q_{\\infty}$ 得到理查森外推公式：\n$$\nQ_{\\infty} \\approx \\frac{r^{p} Q_1 - Q_2}{r^{p} - 1}\n$$\n另一种常见的形式推导如下：\n$$\nQ_{\\infty} \\approx \\frac{r^{p} Q_1 - Q_1 + Q_1 - Q_2}{r^{p} - 1} = Q_1 + \\frac{Q_1 - Q_2}{r^{p} - 1} = Q_1 - \\frac{Q_2 - Q_1}{r^{p} - 1}\n$$\n我们现在使用推导出的公式和数据，包括任务 A 中得到的 $p=2$，来计算 $Q_{\\infty}$：\n$r=2$，$p=2 \\implies r^p = 2^2 = 4$。\n$Q_1 = 1.60125$\n$Q_2 = 1.60500$\n$$\nQ_{\\infty} \\approx \\frac{4 \\times 1.60125 - 1.60500}{4 - 1} = \\frac{6.40500 - 1.60500}{3} = \\frac{4.8}{3} = 1.6\n$$\nQoI 的外推值为 $Q_{\\infty} = 1.6$。\n\n### 任务 C：$Q_{\\infty}$ 的贝叶斯网格收敛指数\n\n问题定义了一个贝叶斯模型，其中观测到的目标量 $Q_i = Q(h_i)$ 由下式给出：\n$$\nQ_i = Q_{\\infty} + C h_i^{p} + \\varepsilon_i, \\quad i \\in \\{1,2,3\\}\n$$\n误差 $\\varepsilon_i$ 是独立同分布的零均值高斯随机变量，$\\varepsilon_i \\sim \\mathcal{N}(0, \\sigma^2)$，其方差 $\\sigma^2$ 已知。精度阶 $p$ 固定为任务 A 中得到的值 $p=2$。这是一个贝叶斯线性回归问题。我们定义向量和矩阵如下：\n$$\n\\mathbf{Q} = \\begin{pmatrix} Q_1 \\\\ Q_2 \\\\ Q_3 \\end{pmatrix}, \\quad \\mathbf{\\theta} = \\begin{pmatrix} Q_{\\infty} \\\\ C \\end{pmatrix}, \\quad \\mathbf{X} = \\begin{pmatrix} 1 & h_1^p \\\\ 1 & h_2^p \\\\ 1 & h_3^p \\end{pmatrix}, \\quad \\mathbf{\\epsilon} = \\begin{pmatrix} \\varepsilon_1 \\\\ \\varepsilon_2 \\\\ \\varepsilon_3 \\end{pmatrix}\n$$\n该模型的矩阵形式为 $\\mathbf{Q} = \\mathbf{X}\\mathbf{\\theta} + \\mathbf{\\epsilon}$。给定参数 $\\mathbf{\\theta}$ 时，数据的似然函数为：\n$$\np(\\mathbf{Q}|\\mathbf{\\theta}, \\sigma^2) = (2\\pi\\sigma^2)^{-3/2} \\exp\\left( -\\frac{1}{2\\sigma^2} (\\mathbf{Q} - \\mathbf{X}\\mathbf{\\theta})^T (\\mathbf{Q} - \\mathbf{X}\\mathbf{\\theta}) \\right)\n$$\n对参数使用非正则无信息先验：$p(\\mathbf{\\theta}) = p(Q_{\\infty}, C) \\propto 1$。\n根据贝叶斯定理，$\\mathbf{\\theta}$ 的后验分布为：\n$$\np(\\mathbf{\\theta}|\\mathbf{Q}, \\sigma^2) \\propto p(\\mathbf{Q}|\\mathbf{\\theta}, \\sigma^2) p(\\mathbf{\\theta}) \\propto \\exp\\left( -\\frac{1}{2\\sigma^2} (\\mathbf{Q} - \\mathbf{X}\\mathbf{\\theta})^T (\\mathbf{Q} - \\mathbf{X}\\mathbf{\\theta}) \\right)\n$$\n该后验是一个多元正态分布，$p(\\mathbf{\\theta}|\\mathbf{Q}, \\sigma^2) \\sim \\mathcal{N}(\\boldsymbol{\\mu}_{\\text{post}}, \\boldsymbol{\\Sigma}_{\\text{post}})$，其均值和协方差由下式给出：\n$$\n\\boldsymbol{\\mu}_{\\text{post}} = (\\mathbf{X}^T\\mathbf{X})^{-1}\\mathbf{X}^T\\mathbf{Q}\n$$\n$$\n\\boldsymbol{\\Sigma}_{\\text{post}} = \\sigma^2 (\\mathbf{X}^T\\mathbf{X})^{-1}\n$$\n后验均值 $\\boldsymbol{\\mu}_{\\text{post}}$ 是 $\\mathbf{\\theta}$ 的普通最小二乘（OLS）估计。任何单个参数的边际后验分布也是高斯分布。具体来说，$Q_{\\infty}$ 的后验分布是一个正态分布：\n$$\np(Q_{\\infty}|\\mathbf{Q}, \\sigma^2) \\sim \\mathcal{N}\\left( (\\boldsymbol{\\mu}_{\\text{post}})_1, (\\boldsymbol{\\Sigma}_{\\text{post}})_{11} \\right)\n$$\n其中 $(\\cdot)_1$ 表示向量的第一个分量，$(\\cdot)_{11}$ 表示矩阵的第一行第一列的元素。\n\n任务是计算 $Q_{\\infty}$ 的后验均值，即 $(\\boldsymbol{\\mu}_{\\text{post}})_1$。这其实就是 $Q_{\\infty}$ 的 OLS 估计。\n一个关键的观察简化了计算。在任务 A 和 B 中，我们发现所提供的数据点对于参数 $p=2$ 和 $Q_{\\infty}=1.6$ 完美地满足了确定性模型 $Q(h) = Q_{\\infty} + C h^p$。我们也可以找到给出完美拟合的 $C$ 的值。使用 $h_1$ 的数据：\n$$\n1.60125 = 1.6 + C (5.0 \\times 10^{-2})^2 \\implies 0.00125 = C (0.0025) \\implies C = 0.5\n$$\n我们可以验证 $Q(h) = 1.6 + 0.5 h^2$ 完美地拟合了所有三个数据点。\nOLS 过程旨在找到最小化残差平方和 $\\sum_{i=1}^3 (Q_i - (Q_{\\infty} + C h_i^p))^2$ 的参数值 $(\\hat{Q}_{\\infty}, \\hat{C})$。由于数据在 $(Q_{\\infty}, C) = (1.6, 0.5)$ 时完美地拟合了模型，因此可能的最小残差平方和为 $0$，并且在这些参数值下达到。因此，OLS 估计以及后验均值必定是：\n$$\n\\boldsymbol{\\mu}_{\\text{post}} = \\begin{pmatrix} \\hat{Q}_{\\infty} \\\\ \\hat{C} \\end{pmatrix} = \\begin{pmatrix} 1.6 \\\\ 0.5 \\end{pmatrix}\n$$\n$Q_{\\infty}$ 的后验均值因此恰好是 $1.6$。$\\sigma$ 的值会影响后验分布的宽度（方差），但在这种模型配置下不影响其均值。\n\n问题要求将数值答案四舍五入到五位有效数字。数值 $1.6$ 表示为五位有效数字是 $1.6000$。", "answer": "$$\n\\boxed{1.6000}\n$$", "id": "3345875"}, {"introduction": "当我们用实验数据校准一个含有多个参数的复杂模型时，一个核心问题是：我们真的能够从有限且含噪声的数据中唯一地确定每个参数的值吗？这个问题被称为参数可识别性（parameter identifiability）。本练习将引导你使用费雪信息矩阵（Fisher Information Matrix）这一强大的分析工具，来评估一个线性化校准问题中参数的局部可识别性。[@problem_id:3345885] 通过这个练习，你将理解模型灵敏度、噪声结构和模型形式误差是如何共同决定我们从数据中学习参数的能力边界的。", "problem": "使用四个传感器位置的稀疏表面压力系数数据，对一个可压缩外部空气动力学求解器进行线性化校准。设观测模型表示为\n$$\ny = y^{\\star} + S\\left(\\theta - \\theta^{\\star}\\right) + H\\,\\beta + \\varepsilon,\n$$\n其中 $y \\in \\mathbb{R}^{4}$ 收集了相对于名义参数 $\\theta^{\\star} \\in \\mathbb{R}^{3}$ 的压力系数残差，$S \\in \\mathbb{R}^{4 \\times 3}$ 是灵敏度矩阵，其元素为 $S_{ij} = \\partial y_i/\\partial \\theta_j$ 在 $\\theta^{\\star}$ 处的值，$\\beta \\in \\mathbb{R}$ 是一个标量系数，代表低秩模型形式差异，$\\varepsilon \\in \\mathbb{R}^{4}$ 是测量噪声。假设 $\\beta \\sim \\mathcal{N}(0,\\Sigma_{\\beta})$，其中 $\\Sigma_{\\beta} = \\tau^{2}$，以及 $\\varepsilon \\sim \\mathcal{N}(0,\\Sigma_{e})$，其中\n$$\n\\Sigma_{e} = \\sigma^{2}\\left((1-\\rho) I_{4} + \\rho\\,\\mathbf{1}\\mathbf{1}^{\\top}\\right),\n$$\n其中 $I_{4}$ 是 $4 \\times 4$ 单位矩阵，$\\mathbf{1} \\in \\mathbb{R}^{4}$ 是全1向量。模型形式项通过 $H \\in \\mathbb{R}^{4 \\times 1}$ 进入模型，定义为 $H = \\mathbf{1}$。\n\n给定以下数据和超参数：\n$$\nS = \\begin{pmatrix}\n1  0  1 \\\\\n1  1  0 \\\\\n1  -1  0 \\\\\n1  0  -1 \n\\end{pmatrix},\\quad\n\\sigma^{2} = 0.04,\\quad\n\\rho = 0.3,\\quad\n\\tau^{2} = 0.09.\n$$\n\n从线性高斯推断的第一性原理以及均值依赖于参数的高斯模型的 Fisher 信息定义出发，首先在边缘化模型形式差异后获得有效数据协方差，然后推导 $\\theta$ 的 Fisher 信息矩阵。利用该矩阵，通过检查 Fisher 信息的秩来判断这三个参数的局部可辨识性。最后，计算第一个参数 $\\theta_{1}$ 方差的 Cramér–Rao 下界（Fisher 信息的逆）。将最终答案表示为一个无量纲数，并四舍五入到四位有效数字。", "solution": "用户提供的问题陈述已经过验证，被认为是具有科学依据、良定且客观的。没有发现可识别的缺陷；因此，下面提供了完整的解答。\n\n该问题要求在贝叶斯推断框架内对一个线性化校准问题进行分析。观测模型由下式给出\n$$y = y^{\\star} + S\\left(\\theta - \\theta^{\\star}\\right) + H\\,\\beta + \\varepsilon$$\n其中 $y \\in \\mathbb{R}^{4}$ 是数据，$\\theta \\in \\mathbb{R}^{3}$ 是参数向量，$\\beta \\in \\mathbb{R}$ 是模型差异项，$\\varepsilon \\in \\mathbb{R}^{4}$ 是测量噪声。让我们将可观测量定义为残差数据向量 $d = y - y^{\\star}$。模型可以写成：\n$$d = S(\\theta - \\theta^{\\star}) + H\\beta + \\varepsilon$$\n统计假设为 $\\beta$ 和 $\\varepsilon$ 是独立的零均值高斯随机变量：\n$$ \\beta \\sim \\mathcal{N}(0, \\Sigma_{\\beta}) \\quad \\text{其中} \\quad \\Sigma_{\\beta} = \\tau^2 $$\n$$ \\varepsilon \\sim \\mathcal{N}(0, \\Sigma_{e}) \\quad \\text{其中} \\quad \\Sigma_{e} = \\sigma^{2}\\left((1-\\rho) I_{4} + \\rho\\,\\mathbf{1}\\mathbf{1}^{\\top}\\right) $$\n\n第一步是在边缘化掉模型形式差异参数 $\\beta$ 后，获得有效数据协方差。在这种线性高斯设定下，边缘化讨厌参数 $\\beta$ 等效于将其贡献并入总噪声项中。总噪声项为 $\\eta = H\\beta + \\varepsilon$。由于 $\\beta$ 和 $\\varepsilon$ 是独立的且均值为零，总噪声 $\\eta$ 也是一个零均值高斯变量。它的协方差，我们记作有效协方差 $\\Sigma_{\\text{eff}}$，是各个协方差之和：\n$$ \\Sigma_{\\text{eff}} = \\text{Cov}(\\eta) = \\text{Cov}(H\\beta) + \\text{Cov}(\\varepsilon) $$\n使用性质 $\\text{Cov}(AX) = A\\text{Cov}(X)A^{\\top}$，我们有：\n$$ \\text{Cov}(H\\beta) = H\\Sigma_{\\beta}H^{\\top} $$\n代入 $H=\\mathbf{1}$ 和 $\\Sigma_{\\beta}=\\tau^2$ 的给定形式：\n$$ H\\Sigma_{\\beta}H^{\\top} = \\mathbf{1}(\\tau^2)\\mathbf{1}^{\\top} = \\tau^2 \\mathbf{1}\\mathbf{1}^{\\top} $$\n因此，有效协方差为：\n$$ \\Sigma_{\\text{eff}} = \\tau^2 \\mathbf{1}\\mathbf{1}^{\\top} + \\sigma^{2}\\left((1-\\rho) I_{4} + \\rho\\,\\mathbf{1}\\mathbf{1}^{\\top}\\right) $$\n合并同类项，我们得到有效数据协方差的最终形式：\n$$ \\Sigma_{\\text{eff}} = \\sigma^2(1-\\rho)I_4 + (\\tau^2 + \\sigma^2\\rho)\\mathbf{1}\\mathbf{1}^{\\top} $$\n该矩阵具有一般形式 $aI_n + b\\mathbf{1}\\mathbf{1}^{\\top}$。我们定义标量系数 $a = \\sigma^2(1-\\rho)$ 和 $b = \\tau^2 + \\sigma^2\\rho$。\n\n第二步是推导 $\\theta$ 的 Fisher 信息矩阵 (FIM)。对于一个高斯模型，其中数据 $d$ 服从 $\\mathcal{N}(\\mu(\\theta), \\Sigma)$，且协方差 $\\Sigma$ 与参数 $\\theta$ 无关，FIM 由下式给出：\n$$ \\mathcal{I}(\\theta) = \\left(\\frac{\\partial \\mu(\\theta)}{\\partial \\theta}\\right)^{\\top} \\Sigma^{-1} \\left(\\frac{\\partial \\mu(\\theta)}{\\partial \\theta}\\right) $$\n在我们的问题中，均值为 $\\mu(\\theta) = S(\\theta - \\theta^{\\star})$，协方差为 $\\Sigma = \\Sigma_{\\text{eff}}$。均值关于 $\\theta$ 的雅可比矩阵就是灵敏度矩阵 $S$。因此，FIM 为：\n$$ \\mathcal{I} = S^{\\top} \\Sigma_{\\text{eff}}^{-1} S $$\n为了计算 $\\mathcal{I}$，我们必须首先求出 $\\Sigma_{\\text{eff}} = aI_4 + b\\mathbf{1}\\mathbf{1}^{\\top}$ 的逆。使用 Sherman-Woodbury 公式计算 $(A+uv^{\\top})^{-1}$，其中 $A=aI_4$, $u=b\\mathbf{1}$, $v=\\mathbf{1}$，我们得到：\n$$ \\Sigma_{\\text{eff}}^{-1} = \\frac{1}{a}I_4 - \\frac{b/a^2}{1+(b/a)\\mathbf{1}^{\\top}\\mathbf{1}}\\mathbf{1}\\mathbf{1}^{\\top} $$\n由于 $\\mathbf{1}^{\\top}\\mathbf{1} = 4$，逆矩阵简化为：\n$$ \\Sigma_{\\text{eff}}^{-1} = \\frac{1}{a}I_4 - \\frac{b}{a(a+4b)}\\mathbf{1}\\mathbf{1}^{\\top} $$\n现在我们将此代入 FIM 的表达式中：\n$$ \\mathcal{I} = S^{\\top} \\left( \\frac{1}{a}I_4 - \\frac{b}{a(a+4b)}\\mathbf{1}\\mathbf{1}^{\\top} \\right) S = \\frac{1}{a}S^{\\top}S - \\frac{b}{a(a+4b)}S^{\\top}\\mathbf{1}\\mathbf{1}^{\\top}S $$\n我们使用给定的矩阵 $S$ 计算矩阵乘积：\n$$ S = \\begin{pmatrix} 1  0  1 \\\\ 1  1  0 \\\\ 1  -1  0 \\\\ 1  0  -1 \\end{pmatrix} $$\n$$ S^{\\top}S = \\begin{pmatrix} 1  1  1  1 \\\\ 0  1  -1  0 \\\\ 1  0  0  -1 \\end{pmatrix} \\begin{pmatrix} 1  0  1 \\\\ 1  1  0 \\\\ 1  -1  0 \\\\ 1  0  -1 \\end{pmatrix} = \\begin{pmatrix} 4  0  0 \\\\ 0  2  0 \\\\ 0  0  2 \\end{pmatrix} $$\n$$ S^{\\top}\\mathbf{1} = \\begin{pmatrix} 1  1  1  1 \\\\ 0  1  -1  0 \\\\ 1  0  0  -1 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ 1 \\\\ 1 \\\\ 1 \\end{pmatrix} = \\begin{pmatrix} 4 \\\\ 0 \\\\ 0 \\end{pmatrix} $$\n项 $S^{\\top}\\mathbf{1}\\mathbf{1}^{\\top}S$ 变为 $(S^{\\top}\\mathbf{1})(S^{\\top}\\mathbf{1})^{\\top}$：\n$$ S^{\\top}\\mathbf{1}\\mathbf{1}^{\\top}S = \\begin{pmatrix} 4 \\\\ 0 \\\\ 0 \\end{pmatrix} \\begin{pmatrix} 4  0  0 \\end{pmatrix} = \\begin{pmatrix} 16  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix} $$\n将这些代入 $\\mathcal{I}$ 的表达式中：\n$$ \\mathcal{I} = \\frac{1}{a}\\begin{pmatrix} 4  0  0 \\\\ 0  2  0 \\\\ 0  0  2 \\end{pmatrix} - \\frac{b}{a(a+4b)}\\begin{pmatrix} 16  0  0 \\\\ 0  0  0 \\\\ 0  0  0 \\end{pmatrix} $$\nFIM 是一个对角矩阵。其元素为：\n$$ \\mathcal{I}_{11} = \\frac{4}{a} - \\frac{16b}{a(a+4b)} = \\frac{4(a+4b)-16b}{a(a+4b)} = \\frac{4a}{a(a+4b)} = \\frac{4}{a+4b} $$\n$$ \\mathcal{I}_{22} = \\frac{2}{a}, \\quad \\mathcal{I}_{33} = \\frac{2}{a} $$\nFisher 信息矩阵是：\n$$ \\mathcal{I} = \\begin{pmatrix} \\frac{4}{a+4b}  0  0 \\\\ 0  \\frac{2}{a}  0 \\\\ 0  0  \\frac{2}{a} \\end{pmatrix} $$\n\n为了判断可辨识性，我们检查 $\\mathcal{I}$ 的秩。参数是局部可辨识的，当且仅当 FIM 是满秩的。由于 $\\mathcal{I}$ 是一个 $3 \\times 3$ 的对角矩阵，如果其所有对角元素都非零，则它是满秩的。让我们计算 $a$ 和 $b$ 的数值：\n$$ a = \\sigma^2(1-\\rho) = 0.04(1-0.3) = 0.04 \\times 0.7 = 0.028 $$\n$$ b = \\tau^2 + \\sigma^2\\rho = 0.09 + 0.04(0.3) = 0.09 + 0.012 = 0.102 $$\n由于 $a > 0$ 且 $b > 0$，$\\mathcal{I}$ 的所有对角元素都是正的，因此非零。$\\mathcal{I}$ 的秩为 $3$，等于参数的数量。因此，所有三个参数都是局部可辨识的。\n\n最后，我们计算第一个参数 $\\theta_1$ 方差的 Cramér–Rao 下界 (CRLB)。CRLB 由 FIM 的逆矩阵 $C = \\mathcal{I}^{-1}$ 给出。$\\theta_1$ 的任何无偏估计量方差的下界是 $C$ 的第一个对角元素 $C_{11}$。\n由于 $\\mathcal{I}$ 是对角的，它的逆矩阵也是对角的，其元素是 $\\mathcal{I}$ 对角元素的倒数：\n$$ \\mathcal{I}^{-1} = \\begin{pmatrix} \\frac{a+4b}{4}  0  0 \\\\ 0  \\frac{a}{2}  0 \\\\ 0  0  \\frac{a}{2} \\end{pmatrix} $$\n$\\theta_1$ 方差的 CRLB 是：\n$$ \\text{CRLB}(\\theta_1) = (\\mathcal{I}^{-1})_{11} = \\frac{a+4b}{4} $$\n代入 $a$ 和 $b$ 的数值：\n$$ \\text{CRLB}(\\theta_1) = \\frac{0.028 + 4(0.102)}{4} = \\frac{0.028 + 0.408}{4} = \\frac{0.436}{4} = 0.109 $$\n按要求四舍五入到四位有效数字，最终答案是 $0.1090$。", "answer": "$$\\boxed{0.1090}$$", "id": "3345885"}, {"introduction": "理论与实践的结合是掌握不确定性量化的关键。本编程练习旨在通过一个具体的计算任务，揭示参数推断与模型误差（如此处的离散化误差）之间复杂的相互作用。你将实现一个工作流，在逐渐加密的网格上对一个模型参数进行贝叶斯推断，并观察由于忽略离散化误差而导致的参数后验均值的“漂移”现象。[@problem_id:3345874] 这个过程不仅能让你直观地理解模型设定不当（model misspecification）的后果，还将教会你如何利用这种漂移来反向推断并量化被忽略的模型误差。", "problem": "考虑雷诺平均纳维-斯托克斯 (RANS) 框架内的一种单参数封闭模型，其中涡粘度取决于一个常数 $C_\\mu$。对于一个固定的典型流场配置和一个单一标量关注量 $y$（例如，空间平均的壁面剪切替代量），在雷诺数和边界条件固定的情况下，假设存在一个局部线性代理模型 $y \\approx \\beta\\,C_\\mu$。采用有限体积法进行离散化，其网格特征尺寸为 $h$，格式阶数为 $p$，因此预测关注量的主阶离散误差大小满足 $\\delta(h) = \\alpha\\,h^p$。我们的目标是通过在逐渐加密的网格上对 $C_\\mu$ 进行贝叶斯推断，来刻画由离散化-模型耦合引起的模型形式和参数不确定性。此过程中，我们首先忽略与网格相关的差异项 $\\delta(h)$，然后诊断由此引起的后验漂移，并根据该漂移估计 $\\delta(h)$。\n\n假设一个观测模型，其中离散化求解器在尺寸为 $h$ 的网格上产生的值 $y_h$ 为 $y_h = \\beta\\,C_\\mu^\\star + \\delta(h) + \\eta$，其中 $C_\\mu^\\star$ 是真实但未知的参数，$\\eta$ 是零均值的测量或求解器噪声。在推断步骤中，采用一个高斯先验 $C_\\mu \\sim \\mathcal{N}(\\mu_0,\\sigma_0^2)$ 和一个忽略 $\\delta(h)$ 的高斯似然，即 $y_h \\mid C_\\mu \\sim \\mathcal{N}(\\beta\\,C_\\mu,\\sigma^2)$，其中 $\\sigma^2$ 是观测方差。在这些假设下，后验分布 $p(C_\\mu \\mid y_h)$ 是高斯的，并且由于当 $\\delta(h) \\neq 0$ 时推断模型存在误设，后验均值通常会依赖于 $h$。定义网格加密过程为每一步将网格尺寸 $h$减半，直到连续两次加密得到的后验均值之差小于稳定容差 $\\zeta$，或达到最大加密步数 $N_{\\max}$ 为止。\n\n您的程序必须实现以下任务：\n- 从给定的初始网格尺寸 $h_0$ 开始，重复地将 $h$ 乘以因子 $1/2$ 进行加密，并在每个网格上，根据上述误设的高斯模型计算 $C_\\mu$ 的后验均值。当 $|\\mu_{\\text{post}}(h_{k}) - \\mu_{\\text{post}}(h_{k-1})| \\le \\zeta$ 或当 $k = N_{\\max}$ 时停止。\n- 通过存储后验均值序列 $\\{\\mu_{\\text{post}}(h_k)\\}$ 来追踪后验漂移，并计算漂移幅度，即欧几里得范数 $D = \\left(\\sum_k \\left[\\mu_{\\text{post}}(h_k) - \\mu_{\\text{post}}(h_{\\text{final}})\\right]^2 \\right)^{1/2}$，其中 $h_{\\text{final}}$ 是使用的最后一个网格。\n- 通过首先定义 $\\widehat{\\delta}(h_k) = \\beta \\left[\\mu_{\\text{post}}(h_k) - \\mu_{\\text{post}}(h_{\\text{final}})\\right]$，然后通过对数坐标下的线性回归（即 $\\log|\\widehat{\\delta}(h)| \\approx \\log|\\alpha| + p \\log h$）来拟合模型 $\\widehat{\\delta}(h) \\approx \\alpha\\,h^p$，从而推断与网格相关的差异项。回归仅使用那些幅度不为零的 $\\widehat{\\delta}(h)$。恢复 $\\alpha$ 时，其符号由回归中使用的 $\\widehat{\\delta}(h)$ 值的平均符号确定。\n- 按照下文规定，报告每个测试案例的稳定性、漂移和差异项估计值。\n\n使用以下参数值测试套件：\n- 案例 A (一般情况)：$\\beta = 2.5$, $\\mu_0 = 0.08$, $\\sigma_0 = 0.1$, $\\sigma = 0.02$, $C_\\mu^\\star = 0.09$, $\\alpha = 0.4$, $p = 2.0$, $h_0 = 0.2$, $N_{\\max} = 6$, $\\zeta = 10^{-4}$，以及 $\\eta = 0$。\n- 案例 B (无离散误差)：$\\beta = 2.5$, $\\mu_0 = 0.08$, $\\sigma_0 = 0.1$, $\\sigma = 0.02$, $C_\\mu^\\star = 0.09$, $\\alpha = 0.0$, $p = 2.0$ (在此无关紧要), $h_0 = 0.2$, $N_{\\max} = 4$, $\\zeta = 10^{-6}$，以及 $\\eta = 0$。\n- 案例 C (强先验和较大噪声)：$\\beta = 2.5$, $\\mu_0 = 0.085$, $\\sigma_0 = 0.005$, $\\sigma = 0.08$, $C_\\mu^\\star = 0.09$, $\\alpha = 0.15$, $p = 1.0$, $h_0 = 0.3$, $N_{\\max} = 7$, $\\zeta = 5 \\times 10^{-5}$，以及 $\\eta = 0$。\n\n对于每个案例，您的程序必须输出一个包含五个值的列表：\n- 达到稳定时的最终网格尺寸 $h_{\\text{final}}$ (浮点数)。\n- 一个稳定性指示符，如果在达到 $N_{\\max}$ 之前实现稳定，则为 $1$，否则为 $0$ (整数)。\n- 如上定义的漂移幅度 $D$ (浮点数)。\n- 从对数-对数回归中估计的阶数 $p_{\\text{hat}}$ (浮点数；如果由于零漂移而无法估计，则返回 $0.0$)。\n- 从对数-对数回归中估计的系数 $\\alpha_{\\text{hat}}$ (浮点数；如果由于零漂移而无法估计，则返回 $0.0$)。\n\n最终输出格式：您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表。列表中的每个元素对应一个测试案例的结果，其本身也是一个按上述顺序排列的列表。例如，输出必须类似于 \"[[h_A,stab_A,D_A,p_hat_A,alpha_hat_A],[h_B,stab_B,D_B,p_hat_B,alpha_hat_B],[h_C,stab_C,D_C,p_hat_C,alpha_hat_C]]\"。输出中的所有量都是无量纲的，因此不需要进行物理单位转换。不出现角度，数值不得以百分号表示；任何分数值都必须表示为小数。", "solution": "用户提供了一个来自计算流体动力学领域的问题，具体涉及不确定性量化。任务是分析雷诺平均纳维-斯托克斯 (RANS) 封闭模型中的参数不确定性与数值离散误差之间的相互作用。此分析涉及在逐渐加密的计算网格上执行一系列贝叶斯推断计算，并诊断推斷参数中产生的漂移。\n\n### 问题验证\n\n首先，对问题陈述进行严格验证。\n\n**步骤 1：提取已知条件**\n- **模型：** 关注量 $y$ 的线性代理模型 $y \\approx \\beta\\,C_\\mu$。\n- **观测：** $y_h = \\beta\\,C_\\mu^\\star + \\delta(h) + \\eta$，其中离散误差为 $\\delta(h) = \\alpha\\,h^p$，求解器噪声为 $\\eta$。\n- **推断（误设）：** 一个忽略 $\\delta(h)$ 的贝叶斯模型，其先验为 $C_\\mu \\sim \\mathcal{N}(\\mu_0, \\sigma_0^2)$，似然为 $y_h \\mid C_\\mu \\sim \\mathcal{N}(\\beta C_\\mu, \\sigma^2)$。\n- **过程：**\n    1.  迭代加密网格（$h_k = h_0 / 2^k$）并计算后验均值 $\\mu_{\\text{post}}(h_k)$。\n    2.  当连续均值间的变化小于容差 $|\\mu_{\\text{post}}(h_k) - \\mu_{\\text{post}}(h_{k-1})| \\le \\zeta$ 或达到 $N_{\\max}$ 步时停止。\n    3.  计算漂移幅度 $D = \\left(\\sum_k [\\mu_{\\text{post}}(h_k) - \\mu_{\\text{post}}(h_{\\text{final}})]^2 \\right)^{1/2}$。\n    4.  通过对导出值 $\\widehat{\\delta}(h_k) = \\beta [\\mu_{\\text{post}}(h_k) - \\mu_{\\text{post}}(h_{\\text{final}})]$ 进行对数-对数线性回归，拟合模型 $\\widehat{\\delta}(h) \\approx \\alpha h^p$ 来估计差异项参数 $(\\alpha_{\\text{hat}}, p_{\\text{hat}})$。\n- **测试案例：** 提供了三组不同的参数（案例 A、B、C），涵盖了一般情况、无离散误差的情况以及强先验的情况。对于所有案例，$\\eta=0$。\n\n**步骤 2：验证评估**\n- **科学基础：** 该问题牢固地植根于计算模型不确定性量化（UQ）的既定原则。模型误设导致依赖于数值参数（如网格尺寸）的有偏推断，这一概念是计算科学中一个被充分研究的课题。使用贝叶斯推断、高斯模型和对数-对数回归进行误差分析都是标准的有效技术。\n- **适定性：** 该问题在数学上和算法上都是适定的。为每个案例提供了所有必要的参数和初始条件。过程明确无歧义，并且明确描述了所需的输出。终止条件清晰，并且处理了边界情况（例如，无法执行回归）。\n- **客观性：** 问题以精确、正式和客观的语言陈述，没有任何主观性或含糊之处。\n\n**步骤 3：结论**\n该问题具有科学合理性、适定性、客观性和完整性。因此，它被判定为**有效**。我们可以继续进行求解。\n\n### 基于原理的解决方案\n问题的核心在于推导和分析 RANS 参数 $C_\\mu$ 的后验分布。给定高斯先验和高斯似然，得到的后验分布也是高斯的。\n\n**1. 后验均值的推导**\n$C_\\mu$ 的先验分布为 $p(C_\\mu) = \\mathcal{N}(C_\\mu \\mid \\mu_0, \\sigma_0^2)$。\n在尺寸为 $h$ 的网格上，观测值 $y_h$ 的误设似然为 $p(y_h \\mid C_\\mu) = \\mathcal{N}(y_h \\mid \\beta C_\\mu, \\sigma^2)$。\n\n$C_\\mu$ 的后验分布为 $p(C_\\mu \\mid y_h) \\propto p(y_h \\mid C_\\mu) p(C_\\mu)$。对于共轭高斯模型，后验均值 $\\mu_{\\text{post}}$ 是先验均值和数据隐含均值的精度加权平均。后验精度 ($1/\\sigma_{\\text{post}}^2$) 是先验精度 ($1/\\sigma_0^2$) 和似然精度（对于参数 $C_\\mu$，其值为 $\\beta^2/\\sigma^2$）之和。\n$$ \\frac{1}{\\sigma_{\\text{post}}^2} = \\frac{1}{\\sigma_0^2} + \\frac{\\beta^2}{\\sigma^2} $$\n后验均值则由下式给出：\n$$ \\mu_{\\text{post}} = \\sigma_{\\text{post}}^2 \\left( \\frac{\\mu_0}{\\sigma_0^2} + \\frac{\\beta y_h}{\\sigma^2} \\right) = \\frac{\\mu_0 \\sigma^2 + \\beta y_h \\sigma_0^2}{\\sigma^2 + \\beta^2 \\sigma_0^2} $$\n“观测”数据 $y_h$ 由真实模型生成：$y_h = \\beta C_\\mu^\\star + \\delta(h) + \\eta$。当 $\\delta(h) = \\alpha h^p$ 且 $\\eta=0$ 时，该式变为 $y_h = \\beta C_\\mu^\\star + \\alpha h^p$。将此代入 $\\mu_{\\text{post}}$ 的表达式中，揭示了其对网格尺寸 $h$ 的依赖性：\n$$ \\mu_{\\text{post}}(h) = \\frac{\\mu_0 \\sigma^2 + \\beta (\\beta C_\\mu^\\star + \\alpha h^p) \\sigma_0^2}{\\sigma^2 + \\beta^2 \\sigma_0^2} = \\frac{(\\mu_0 \\sigma^2 + \\beta^2 C_\\mu^\\star \\sigma_0^2) + (\\beta \\alpha \\sigma_0^2) h^p}{\\sigma^2 + \\beta^2 \\sigma_0^2} $$\n这个表达式可以方便地结构化为一个与网格无关的部分和一个与网格相关的部分：\n$$ \\mu_{\\text{post}}(h) = A + B h^p $$\n其中 $A = \\frac{\\mu_0 \\sigma^2 + \\beta^2 C_\\mu^\\star \\sigma_0^2}{\\sigma^2 + \\beta^2 \\sigma_0^2}$ 是在无限细网格（$h \\to 0$）上的后验均值，而 $B = \\frac{\\beta \\alpha \\sigma_0^2}{\\sigma^2 + \\beta^2 \\sigma_0^2}$ 量化了在有限 $h$ 下由离散误差引入的偏差。这个解析形式将用于计算后验均值序列。\n\n**2. 算法实现**\n对于每个测试案例，我们实现以下算法：\n-   **初始化：** 为给定案例设置参数。初始化空列表以存储网格尺寸序列 `h_values` 和后验均值序列 `mu_post_values`。\n-   **加密循环：** 执行一个迭代过程，最多 $N_{\\max}$ 次。在每次迭代 $k$ 中：\n    1.  加密网格尺寸：$h_k = h_0 / 2^k$。\n    2.  使用推导出的公式计算后验均值 $\\mu_{\\text{post}}(h_k)$。\n    3.  存储 $h_k$ 和 $\\mu_{\\text{post}}(h_k)$。\n    4.  对于 $k > 0$，将绝对差 $|\\mu_{\\text{post}}(h_k) - \\mu_{\\text{post}}(h_{k-1})|$ 与稳定容差 $\\zeta$进行比较。如果满足标准，则终止循环，并将稳定标志设置为 $1$。如果循环完成而未满足标准，则将标志设置为 $0$。\n-   **漂移计算：** 确定最终的网格尺寸 $h_{\\text{final}}$ 和后验均值 $\\mu_{\\text{post}}(h_{\\text{final}})$。将漂移 $D$ 计算为每个后验均值与最终均值偏差向量的欧几里得范数。\n-   **差异项估计：**\n    1.  计算差异项代理序列：$\\widehat{\\delta}(h_k) = \\beta [\\mu_{\\text{post}}(h_k) - \\mu_{\\text{post}}(h_{\\text{final}})]$。\n    2.  收集所有 $\\widehat{\\delta}(h_k)$ 非零的 $h_k$ 的数据对 $(\\log h_k, \\log|\\widehat{\\delta}(h_k)|)$。注意 $\\widehat{\\delta}(h_{\\text{final}})$ 保证为零。\n    3.  如果可用于回归的数据点少于两个（例如，如果所有 $\\widehat{\\delta}$ 均为零，如案例 B），则将估计参数 $p_{\\text{hat}}$ 和 $\\alpha_{\\text{hat}}$ 设置为 $0.0$。\n    4.  否则，执行线性回归以拟合 $\\log|\\widehat{\\delta}| = \\log|\\alpha| + p \\log h$。拟合的斜率给出 $p_{\\text{hat}}$，截距给出 $\\log|\\alpha_{\\text{hat}}|$。\n    5.  $\\alpha_{\\text{hat}}$ 的符号由拟合中使用的非零 $\\widehat{\\delta}(h_k)$ 值的平均符号确定。\n\n将此程序应用于三个测试案例中的每一个，以生成最终结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.stats import linregress\n\ndef solve():\n    \"\"\"\n    Solves the problem of characterizing model-form and parametric uncertainty\n    by analyzing posterior drift across grid refinements.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Case A\n        {\n            \"beta\": 2.5, \"mu_0\": 0.08, \"sigma_0\": 0.1, \"sigma\": 0.02,\n            \"C_mu_star\": 0.09, \"alpha\": 0.4, \"p\": 2.0, \"h_0\": 0.2,\n            \"N_max\": 6, \"zeta\": 1e-4, \"eta\": 0.0\n        },\n        # Case B\n        {\n            \"beta\": 2.5, \"mu_0\": 0.08, \"sigma_0\": 0.1, \"sigma\": 0.02,\n            \"C_mu_star\": 0.09, \"alpha\": 0.0, \"p\": 2.0, \"h_0\": 0.2,\n            \"N_max\": 4, \"zeta\": 1e-6, \"eta\": 0.0\n        },\n        # Case C\n        {\n            \"beta\": 2.5, \"mu_0\": 0.085, \"sigma_0\": 0.005, \"sigma\": 0.08,\n            \"C_mu_star\": 0.09, \"alpha\": 0.15, \"p\": 1.0, \"h_0\": 0.3,\n            \"N_max\": 7, \"zeta\": 5e-5, \"eta\": 0.0\n        }\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        # Extract parameters for the current case\n        beta = case[\"beta\"]\n        mu_0 = case[\"mu_0\"]\n        sigma_0 = case[\"sigma_0\"]\n        sigma = case[\"sigma\"]\n        C_mu_star = case[\"C_mu_star\"]\n        alpha = case[\"alpha\"]\n        p = case[\"p\"]\n        h_0 = case[\"h_0\"]\n        N_max = case[\"N_max\"]\n        zeta = case[\"zeta\"]\n        eta = case[\"eta\"]\n\n        h_values = []\n        mu_post_values = []\n        \n        stabilized = 0\n        \n        # Common terms for posterior mean calculation\n        sigma2 = sigma**2\n        sigma0_2 = sigma_0**2\n        beta2 = beta**2\n        denominator = sigma2 + beta2 * sigma0_2\n        \n        # Grid-independent part of the posterior mean\n        A = (mu_0 * sigma2 + beta2 * C_mu_star * sigma0_2) / denominator\n        # Grid-dependent coefficient\n        B = (beta * alpha * sigma0_2) / denominator\n        \n        for k in range(N_max):\n            h_k = h_0 / (2**k)\n            \n            # The posterior mean formula derived from the problem description\n            mu_post_k = A + B * (h_k**p)\n\n            h_values.append(h_k)\n            mu_post_values.append(mu_post_k)\n            \n            if k > 0:\n                diff = abs(mu_post_values[k] - mu_post_values[k-1])\n                if diff = zeta:\n                    stabilized = 1\n                    break\n        \n        h_final = h_values[-1]\n        mu_final = mu_post_values[-1]\n        \n        # Compute drift magnitude D\n        drift_sum_sq = 0.0\n        for mu in mu_post_values:\n            drift_sum_sq += (mu - mu_final)**2\n        drift_D = np.sqrt(drift_sum_sq)\n\n        # Infer discrepancy term\n        p_hat = 0.0\n        alpha_hat = 0.0\n        \n        delta_hats = [beta * (mu - mu_final) for mu in mu_post_values]\n        \n        # Prepare data for log-log regression\n        log_h_reg = []\n        log_delta_abs_reg = []\n        delta_hat_reg = []\n        \n        for i in range(len(delta_hats)):\n            # Exclude points where delta_hat is zero (or very close)\n            # The last point where h=h_final will always be zero\n            if abs(delta_hats[i]) > 1e-15:\n                log_h_reg.append(np.log(h_values[i]))\n                log_delta_abs_reg.append(np.log(abs(delta_hats[i])))\n                delta_hat_reg.append(delta_hats[i])\n        \n        # Perform regression if at least 2 points are available\n        if len(log_h_reg) >= 2:\n            try:\n                regression_result = linregress(log_h_reg, log_delta_abs_reg)\n                p_hat = regression_result.slope\n                \n                # Calculate alpha_hat magnitude from intercept\n                alpha_hat_abs = np.exp(regression_result.intercept)\n                \n                # Determine the sign of alpha_hat\n                sign = np.sign(np.mean(delta_hat_reg)) if delta_hat_reg else 1.0\n                alpha_hat = alpha_hat_abs * sign\n\n            except ValueError:\n                p_hat = 0.0\n                alpha_hat = 0.0\n\n        case_results = [h_final, stabilized, drift_D, p_hat, alpha_hat]\n        all_results.append(case_results)\n\n    # Format output to match specification \"[[...],[...],[...]]\"\n    results_as_str_list = []\n    for res in all_results:\n        results_as_str_list.append(f\"[{','.join(map(str, res))}]\")\n    \n    final_output_str = f\"[{','.join(results_as_str_list)}]\"\n        \n    print(final_output_str)\n\nsolve()\n```", "id": "3345874"}]}