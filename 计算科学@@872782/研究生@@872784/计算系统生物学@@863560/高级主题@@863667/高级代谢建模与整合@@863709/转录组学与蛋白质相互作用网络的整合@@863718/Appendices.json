{"hands_on_practices": [{"introduction": "我们如何将基因表达谱与蛋白质相互作用网络（PPI）联系起来？最直接的方法是检验相互作用的蛋白质所对应的基因是否表现出共表达。这个练习 [@problem_id:3320742] 将指导你完成一个基本但至关重要的工作流程：使用皮尔逊相关性来量化共表达强度，并利用费雪Z变换来严格评估这种关联的统计显著性。掌握这一实践是学习更复杂网络整合方法的基础。", "problem": "给定一个针对四个基因在八个独立样本中测得的转录组学数据矩阵，以及一个蛋白质-蛋白质相互作用 (PPI) 子图。目标是将转录组共表达与 PPI 子图整合，方法是根据相应基因表达谱的皮尔逊相关性为每条 PPI 边分配权重，然后使用费雪变换来检验该边是否在指定的显著性水平下显著共表达。\n\n背景和允许的出发点：\n- 分子生物学中心法则指出，脱氧核糖核酸 (DNA) 转录为核糖核酸 (RNA)，RNA 翻译为蛋白质。转录组学测量每个基因在样本间的信使RNA (mRNA) 丰度。\n- 蛋白质-蛋白质相互作用 (PPI) 网络编码了蛋白质之间的物理相互作用关系。将转录组共表达与 PPI 边整合是一种成熟的方法，用于优先排序特定条件下的相互作用。\n- 两个样本向量 $x = (x_1,\\dots,x_n)$ 和 $y = (y_1,\\dots,y_n)$ 之间的皮尔逊积矩相关系数定义为\n  $$ r_{xy} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}}. $$\n- 对于 $n \\ge 4$，费雪 $z$-变换 $z = \\operatorname{arctanh}(r)$ 使抽样分布近似正态，当真实相关性为 $0$ 且 $(x,y)$ 近似服从二元正态分布的假设下，标准误为 $1/\\sqrt{n-3}$。\n\n您的任务：\n1. 对于给定 PPI 子图中的每条无向边 $\\{u,v\\}$，计算边权重 $w_{uv}$，其定义为基因 $u$ 和 $v$ 在样本间的表达谱之间的皮尔逊相关性 $r$。\n2. 应用费雪 $z$-变换 $z = \\operatorname{arctanh}(r)$ 并构建检验统计量\n   $$ Z = z \\cdot \\sqrt{n - 3}, $$\n   以在给定的显著性水平 $\\alpha$ 下检验双侧零假设 $H_0: \\rho = 0$，其中 $\\rho$ 表示总体相关性。\n3. 如果 $|Z| \\ge z_{1 - \\alpha/2}$，则判定一条边是显著的，其中 $z_{1 - \\alpha/2}$ 是标准正态分布的 $(1 - \\alpha/2)$ 分位数。所有角度均不相关；无物理单位适用。将 $\\alpha$ 表示为小数（例如，$0.05$）。如果由于 $r = \\pm 1$ 导致 $\\operatorname{arctanh}(r)$ 的数值计算未定义，则在应用 $\\operatorname{arctanh}$ 之前，通过将 $r$ 裁剪到 $(-1, 1)$ 区间内来使用连续极限。\n\n数据：\n- 基因数量：$4$\n- 样本数量：$8$ ($n = 8$)\n- 基因索引：$0, 1, 2, 3$ 分别对应基因 $G0, G1, G2, G3$。\n- 表达谱（基因-样本，每个谱列为包含八个样本值的向量）：\n  - $G0$：$[1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0]$\n  - $G1$：$[0.8, 1.9, 3.1, 4.0, 5.2, 5.9, 7.1, 8.2]$\n  - $G2$：$[8.2, 6.5, 6.1, 5.0, 4.1, 3.7, 2.8, 1.2]$\n  - $G3$：$[2.0, 5.0, 2.0, 5.0, 2.0, 5.0, 2.0, 5.0]$\n\n测试套件：\n提供一个程序，评估以下三个测试用例。每个测试用例指定一个无向 PPI 边集（表示为整数索引对 $(u,v)$ 且 $u \\lt v$）和一个显著性水平 $\\alpha$。\n- 测试用例 $1$：边 $E_1 = \\{(0,1),(0,2),(0,3),(1,3),(2,3)\\}$，$\\alpha_1 = 0.05$。\n- 测试用例 $2$：边 $E_2 = \\{(0,1),(0,2),(0,3),(1,3),(2,3)\\}$，$\\alpha_2 = 0.01$。\n- 测试用例 $3$：边 $E_3 = \\{(1,2),(1,3)\\}$，$\\alpha_3 = 0.05$。\n\n输出规格：\n- 对于每个测试用例，输出所有显著边的列表，形式为整数对 $[u,v]$ 列表，其中 $u \\lt v$，并按 $(u,v)$ 的升序字典序排列。\n- 您的程序应生成单行输出，包含所有三个测试用例的结果，格式为用方括号括起来的逗号分隔列表。具体来说，最终输出必须是形如\n  $$[[\\ldots],[\\ldots],[\\ldots]]$$\n  的单行，其中每个内部列表是相应测试用例的显著边列表。每条边表示为包含两个整数的列表。不应打印任何额外文本。\n\n要求：\n- 完全按照定义实现皮尔逊相关性。使用费雪变换和带有标准正态分位数 $z_{1-\\alpha/2}$ 的双侧 $Z$-检验。\n- 为使检验成立，假定样本间独立且近似服从二元正态分布。在标准误因子 $\\sqrt{n-3}$ 中使用 $n=8$。\n- 通过在计算 $\\operatorname{arctanh}(r)$ 之前将 $r$ 裁剪到开区间 $(-1,1)$ 内来处理 $r$ 接近 $\\pm 1$ 时的数值稳定性。\n- 所有计算必须在没有用户输入或外部文件的情况下完成。", "solution": "该问题是有效的，因为它具有科学依据、定义明确且客观。它提出了一个标准的计算系统生物学任务，涉及使用已建立的统计方法将转录组数据与蛋白质-蛋白质相互作用网络进行整合。所有必需的数据、公式和条件都已提供，问题没有矛盾或含糊之处。\n\n解决方案通过实现指定的统计工作流程来推进。这包括计算与蛋白质-蛋白质相互作用 (PPI) 网络中的边相对应的基因表达谱的皮尔逊相关系数，然后使用费雪 $z$-变换进行显著性检验。\n\n首先，定义所提供的 4 个基因在 8 个样本中的基因表达数据。设基因 $i$ 的表达谱由向量 $G_i$ 表示。样本数量为 $n=8$。\n\n任务的核心是为三个测试用例中的每一个分析一组 PPI 边。对于给定的边 $\\{u, v\\}$，它代表由基因 $u$ 和 $v$ 编码的蛋白质之间的相互作用，执行以下步骤：\n\n1.  **皮尔逊相关系数 ($w_{uv}$)**：边的权重 $w_{uv}$ 定义为相应基因 $G_u$ 和 $G_v$ 的表达谱之间的皮尔逊相关系数 $r$。设 $x = G_u$ 和 $y = G_v$。相关性 $r_{xy}$ 根据以下公式计算：\n    $$ r_{xy} = \\frac{\\sum_{i=1}^{n} (x_i - \\bar{x})(y_i - \\bar{y})}{\\sqrt{\\sum_{i=1}^{n} (x_i - \\bar{x})^2} \\sqrt{\\sum_{i=1}^{n} (y_i - \\bar{y})^2}} $$\n    其中 $\\bar{x}$ 和 $\\bar{y}$ 是表达谱的样本均值，且 $n=8$。\n\n2.  **费雪 $z$-变换**：为了稳定方差并近似正态性，使用反双曲正切函数 ($\\operatorname{arctanh}$) 对相关系数 $r$ 进行变换。\n    $$ z = \\operatorname{arctanh}(r) $$\n    根据要求，如果计算出的相关性 $r$ 恰好为 $\\pm 1$，则首先将其裁剪到开区间 $(-1, 1)$ 内，以确保 $\\operatorname{arctanh}(r)$ 是有限的。\n\n3.  **$Z$-显著性检验**：使用 $Z$-统计量检验零假设 $H_0: \\rho = 0$（即真实总体相关性为零）。在 $H_0$ 下，$z$ 的抽样分布近似为均值为 $0$、标准误为 $1/\\sqrt{n-3}$ 的正态分布。因此，检验统计量 $Z$ 为：\n    $$ Z = z \\cdot \\sqrt{n-3} = z \\cdot \\sqrt{8-3} = z \\cdot \\sqrt{5} $$\n    该统计量近似服从标准正态分布 $\\mathcal{N}(0,1)$。\n\n4.  **决策规则**：对于给定的双侧显著性水平 $\\alpha$，如果其 $Z$-统计量的绝对值大于或等于临界值 $z_{1-\\alpha/2}$，则该边被认为是显著的，其中 $z_{1-\\alpha/2}$ 是标准正态分布的 $(1-\\alpha/2)$-分位数。\n    $$ |Z| \\ge z_{1-\\alpha/2} $$\n\n所有测试用例中的相关边是 $\\{0,1\\}, \\{0,2\\}, \\{0,3\\}, \\{1,2\\}, \\{1,3\\}, \\{2,3\\}$。这些边的计算出的相关系数 ($r$) 和 $Z$-统计量的绝对值 ($|Z|$) 如下：\n-   边 $\\{0,1\\}$：$r \\approx 0.999$, $|Z| \\approx 8.948$\n-   边 $\\{0,2\\}$：$r \\approx -0.963$, $|Z| \\approx 4.449$\n-   边 $\\{0,3\\}$：$r \\approx 0.218$, $|Z| \\approx 0.496$\n-   边 $\\{1,2\\}$：$r \\approx -0.958$, $|Z| \\approx 4.286$\n-   边 $\\{1,3\\}$：$r \\approx 0.231$, $|Z| \\approx 0.526$\n-   边 $\\{2,3\\}$：$r \\approx -0.199$, $|Z| \\approx 0.451$\n\n现在，我们评估每个测试用例。\n\n**测试用例 1**：边 $E_1 = \\{(0,1),(0,2),(0,3),(1,3),(2,3)\\}$ 且 $\\alpha_1 = 0.05$。\n临界值为 $z_{1 - 0.05/2} = z_{0.975} \\approx 1.960$。\n-   边 $\\{0,1\\}$：$|Z| \\approx 8.948 \\ge 1.960$。显著。\n-   边 $\\{0,2\\}$：$|Z| \\approx 4.449 \\ge 1.960$。显著。\n-   边 $\\{0,3\\}$：$|Z| \\approx 0.496  1.960$。不显著。\n-   边 $\\{1,3\\}$：$|Z| \\approx 0.526  1.960$。不显著。\n-   边 $\\{2,3\\}$：$|Z| \\approx 0.451  1.960$。不显著。\n显著边按字典序排序为 $[[0,1], [0,2]]$。\n\n**测试用例 2**：边 $E_2 = \\{(0,1),(0,2),(0,3),(1,3),(2,3)\\}$ 且 $\\alpha_2 = 0.01$。\n临界值为 $z_{1 - 0.01/2} = z_{0.995} \\approx 2.576$。\n-   边 $\\{0,1\\}$：$|Z| \\approx 8.948 \\ge 2.576$。显著。\n-   边 $\\{0,2\\}$：$|Z| \\approx 4.449 \\ge 2.576$。显著。\n-   边 $\\{0,3\\}$：$|Z| \\approx 0.496  2.576$。不显著。\n-   边 $\\{1,3\\}$：$|Z| \\approx 0.526  2.576$。不显著。\n-   边 $\\{2,3\\}$：$|Z| \\approx 0.451  2.576$。不显著。\n显著边按字典序排序为 $[[0,1], [0,2]]$。\n\n**测试用例 3**：边 $E_3 = \\{(1,2),(1,3)\\}$ 且 $\\alpha_3 = 0.05$。\n临界值为 $z_{1 - 0.05/2} = z_{0.975} \\approx 1.960$。\n-   边 $\\{1,2\\}$：$|Z| \\approx 4.286 \\ge 1.960$。显著。\n-   边 $\\{1,3\\}$：$|Z| \\approx 0.526  1.960$。不显著。\n显著边为 $[[1,2]]$。\n\n综合这些结果，得出所有三个测试用例的最终列表。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import norm\n\ndef solve():\n    \"\"\"\n    Computes significant gene co-expression edges based on Pearson correlation\n    and Fisher's z-transformation test.\n    \"\"\"\n\n    # --- Data Definition ---\n    # Number of samples\n    n = 8\n\n    # Gene expression data matrix (4 genes x 8 samples)\n    gene_data = np.array([\n        [1.0, 2.0, 3.0, 4.0, 5.0, 6.0, 7.0, 8.0],  # G0\n        [0.8, 1.9, 3.1, 4.0, 5.2, 5.9, 7.1, 8.2],  # G1\n        [8.2, 6.5, 6.1, 5.0, 4.1, 3.7, 2.8, 1.2],  # G2\n        [2.0, 5.0, 2.0, 5.0, 2.0, 5.0, 2.0, 5.0]   # G3\n    ])\n\n    # Test suite definition\n    test_cases = [\n        {'edges': [(0, 1), (0, 2), (0, 3), (1, 3), (2, 3)], 'alpha': 0.05},\n        {'edges': [(0, 1), (0, 2), (0, 3), (1, 3), (2, 3)], 'alpha': 0.01},\n        {'edges': [(1, 2), (1, 3)], 'alpha': 0.05}\n    ]\n\n    # Factor for Z-statistic calculation\n    z_stat_factor = np.sqrt(n - 3)\n\n    all_results = []\n\n    # --- Processing Logic ---\n    for case in test_cases:\n        edges_to_test = case['edges']\n        alpha = case['alpha']\n\n        # Determine the critical value from the standard normal distribution\n        z_critical = norm.ppf(1 - alpha / 2.0)\n        \n        significant_edges = []\n        for u, v in edges_to_test:\n            x = gene_data[u]\n            y = gene_data[v]\n\n            # 1. Compute Pearson correlation coefficient as defined in the problem\n            mean_x = np.mean(x)\n            mean_y = np.mean(y)\n            \n            numerator = np.sum((x - mean_x) * (y - mean_y))\n            \n            sum_sq_x = np.sum((x - mean_x)**2)\n            sum_sq_y = np.sum((y - mean_y)**2)\n            denominator = np.sqrt(sum_sq_x * sum_sq_y)\n            \n            if denominator == 0:\n                r = 0.0\n            else:\n                r = numerator / denominator\n\n            # 2. Apply Fisher z-transformation and form the Z-statistic\n            # Clip r to be in (-1, 1) to handle r = +/-1 case for arctanh\n            r_clipped = np.clip(r, np.nextafter(-1.0, 1.0), np.nextafter(1.0, -1.0))\n            \n            z = np.arctanh(r_clipped)\n            Z_stat = z * z_stat_factor\n\n            # 3. Declare significance based on the two-sided test\n            if np.abs(Z_stat) >= z_critical:\n                significant_edges.append([u, v])\n        \n        # Sort the list of significant edges lexicographically\n        significant_edges.sort()\n        all_results.append(significant_edges)\n\n    # --- Final Output ---\n    # Format the results into the required single-line string format\n    # e.g., [[[0,1],[0,2]],[[0,1],[0,2]],[[1,2]]]\n    print(str(all_results).replace(' ', ''))\n\nsolve()\n\n```", "id": "3320742"}, {"introduction": "在对单个相互作用进行评分之后，下一步是利用整个网络的结构来提炼生物信号。由于转录组数据本身可能含有噪声，这个练习 [@problem_id:3320715] 介绍了一种强大的技术——网络平滑，它利用图拉普拉斯算子在相互连接的节点之间传播信息。通过这种方法，你可以学习如何降低数据噪声，并根据节点的网络邻域来增强或调整其固有属性，从而获得更稳健的生物学见解。", "problem": "考虑将转录组测量数据与一个蛋白质-蛋白质相互作用（PPI）网络相结合，该网络表示为一个无向加权图。设该图有 $5$ 个节点，对应于基因，并令 $\\mathbf{A} \\in \\mathbb{R}^{5 \\times 5}$ 表示其对称邻接矩阵。令 $\\mathbf{x} \\in \\mathbb{R}^{5}$ 表示映射到相同节点的转录丰度向量（例如，对数转换或标准化的计数）。使用以下形式化定义作为基本依据：\n- 节点 $i$ 的度中心性是与 $i$ 相关联的边的权重之和，对于邻接矩阵而言即为 $\\sum_{j=1}^{5} A_{ij}$。\n- 特征向量中心性定义为与 $\\mathbf{A}$ 的最大特征值相关联的（主）特征向量 $\\mathbf{v}$，满足 $\\mathbf{A}\\mathbf{v} = \\mu_{\\max}\\mathbf{v}$，并被标准化为欧几里得范数为 $1$。\n- 图拉普拉斯矩阵为 $\\mathbf{L} = \\mathbf{D} - \\mathbf{A}$，其中 $\\mathbf{D}$ 是对角矩阵，其对角元素为 $D_{ii} = \\sum_{j=1}^{5} A_{ij}$。\n- 拉普拉斯平滑目标将转录信号与网络结构相结合，其形式为 $J(\\mathbf{f}) = \\|\\mathbf{f} - \\mathbf{x}\\|_2^2 + \\lambda \\,\\mathbf{f}^{\\top}\\mathbf{L}\\mathbf{f}$，其中 $\\lambda  0$ 控制平滑的强度。\n\n您的任务是编写一个完整的、可运行的程序，对每个测试用例计算：\n1. 每个节点的度中心性。\n2. 每个节点的特征向量中心性，定义为 $\\mathbf{A}$ 的单位范数主特征向量。为解决符号不确定性问题，选择满足 $\\sum_{i=1}^{5} v_i \\ge 0$ 的表示形式。\n3. 当 $\\lambda = 0.5$ 时的拉普拉斯平滑分数 $\\mathbf{f}^{\\star}$，定义为给定 $\\mathbf{A}$ 和 $\\mathbf{x}$ 时 $J(\\mathbf{f})$ 的唯一最小化子。\n\n返回所有数值输出，四舍五入到六位小数。\n\n测试套件：\n- 案例 $1$（连通，无权）：\n  $$\\mathbf{A}_1 = \\begin{bmatrix}\n  0  1  1  0  0 \\\\\n  1  0  1  1  0 \\\\\n  1  1  0  0  1 \\\\\n  0  1  0  0  0 \\\\\n  0  0  1  0  0\n  \\end{bmatrix}, \\quad\n  \\mathbf{x}_1 = \\begin{bmatrix} 2.0 \\\\ 0.5 \\\\ 1.2 \\\\ 0.0 \\\\ 3.0 \\end{bmatrix}, \\quad \\lambda = 0.5.$$\n- 案例 $2$（存在孤立节点）：\n  $$\\mathbf{A}_2 = \\begin{bmatrix}\n  0  1  0  0  0 \\\\\n  1  0  1  0  0 \\\\\n  0  1  0  0  1 \\\\\n  0  0  0  0  0 \\\\\n  0  0  1  0  0\n  \\end{bmatrix}, \\quad\n  \\mathbf{x}_2 = \\begin{bmatrix} 0.0 \\\\ 1.0 \\\\ 4.0 \\\\ -1.0 \\\\ 0.5 \\end{bmatrix}, \\quad \\lambda = 0.5.$$\n- 案例 $3$（不连通，加权边）：\n  $$\\mathbf{A}_3 = \\begin{bmatrix}\n  0  1  0.5  0  0 \\\\\n  1  0  1  0  0 \\\\\n  0.5  1  0  0  0 \\\\\n  0  0  0  0  2 \\\\\n  0  0  0  2  0\n  \\end{bmatrix}, \\quad\n  \\mathbf{x}_3 = \\begin{bmatrix} 1.0 \\\\ 0.0 \\\\ 0.0 \\\\ 5.0 \\\\ 0.0 \\end{bmatrix}, \\quad \\lambda = 0.5.$$\n\n最终输出格式：\n您的程序应生成单行输出，其中包含一个由方括号括起来的逗号分隔列表形式的结果。对于每个测试用例，输出一个包含三个列表的列表：节点 $1$ 到 $5$ 的度中心性、节点 $1$ 到 $5$ 的特征向量中心性以及节点 $1$ 到 $5$ 的拉普拉斯平滑分数 $\\mathbf{f}^{\\star}$。具体而言，最终输出必须是\n$$\n[\\,[\\,[d^{(1)}_1,\\dots,d^{(1)}_5],\\,[v^{(1)}_1,\\dots,v^{(1)}_5],\\,[f^{\\star (1)}_1,\\dots,f^{\\star (1)}_5]\\,],\\,\\,[\\,[d^{(2)}_1,\\dots,d^{(2)}_5],\\,[v^{(2)}_1,\\dots,v^{(2)}_5],\\,[f^{\\star (2)}_1,\\dots,f^{\\star (2)}_5]\\,],\\,\\,[\\,[d^{(3)}_1,\\dots,d^{(3)}_5],\\,[v^{(3)}_1,\\dots,v^{(3)}_5],\\,[f^{\\star (3)}_1,\\dots,f^{\\star (3)}_5]\\,]\\,]\n$$\n的形式，其中所有数值条目均四舍五入到六位小数。", "solution": "该问题在科学上是适定的，并包含了唯一解所需的所有必要信息。我们继续对所需的三个网络指标进行推导和计算。所有数学实体均按照指定的格式规则使用 LaTeX 渲染。\n\n该问题要求为三个测试用例中的每一个计算三个量：度中心性、特征向量中心性和拉普拉斯平滑分数。每个测试用例由一个对称邻接矩阵 $\\mathbf{A} \\in \\mathbb{R}^{5 \\times 5}$ 和一个转录丰度向量 $\\mathbf{x} \\in \\mathbb{R}^{5}$ 定义。平滑参数固定为 $\\lambda = 0.5$。\n\n### 1. 度中心性\n\n度中心性是衡量网络中节点直接影响力的一个指标。对于由对称邻接矩阵 $\\mathbf{A}$ 表示的加权无向图，节点 $i$ 的度中心性 $d_i$ 定义为与其相连的所有边的权重之和。这对应于 $\\mathbf{A}$ 的第 $i$ 行（或列）的元素之和。\n\n$$\nd_i = \\sum_{j=1}^{5} A_{ij}\n$$\n\n因此，度中心性向量 $\\mathbf{d}$ 是通过对邻接矩阵 $\\mathbf{A}$ 的各行求和来计算的。\n\n### 2. 特征向量中心性\n\n特征向量中心性扩展了度中心性的概念，它不仅考虑连接的数量或权重，还考虑了所连接节点的重要性。一个节点的特征向量中心性与其邻居节点的中心性之和成正比。这个递归定义引出了一个特征向量问题。中心性向量 $\\mathbf{v}$ 是邻接矩阵 $\\mathbf{A}$ 的主特征向量，对应于最大特征值 $\\mu_{\\max}$：\n\n$$\n\\mathbf{A}\\mathbf{v} = \\mu_{\\max}\\mathbf{v}\n$$\n\n对于代表无向图的非负对称矩阵 $\\mathbf{A}$，Perron-Frobenius 定理（或其对可约矩阵的扩展）保证了 $\\mu_{\\max}$ 是实数且非负，并且存在一个相应的非负特征向量 $\\mathbf{v}$。\n\n计算过程如下：\n1.  计算矩阵 $\\mathbf{A}$ 的特征值和特征向量。\n2.  识别出最大特征值 $\\mu_{\\max}$。\n3.  选择相应的特征向量 $\\mathbf{v}_{\\text{raw}}$。\n4.  将特征向量标准化，使其欧几里得范数为 $1$：$\\mathbf{v} = \\mathbf{v}_{\\text{raw}} / \\|\\mathbf{v}_{\\text{raw}}\\|_2$。标准的数值库通常返回标准化的特征向量。\n5.  解决符号不确定性。一个特征向量 $\\mathbf{v}$ 的定义只在一个标量乘法因子内是唯一的。如果 $\\mathbf{v}$ 是一个特征向量，那么 $-\\mathbf{v}$ 也是。问题指定了一个约定：选择向量的表示形式，使其分量之和为非负。如果 $\\sum_{i=1}^{5} v_i  0$，则该向量被替换为 $-\\mathbf{v}$。否则，直接使用它。\n\n### 3. 拉普拉斯平滑分数\n\n拉普拉斯平滑，也称为网络扩散或热核平滑，将节点属性（向量 $\\mathbf{x}$）与图拓扑结构相结合，生成能够反映初始信号和网络邻近性的平滑分数 $\\mathbf{f}$。该过程被表述为一个优化问题，即最小化目标函数 $J(\\mathbf{f})$：\n\n$$\nJ(\\mathbf{f}) = \\underbrace{\\|\\mathbf{f} - \\mathbf{x}\\|_2^2}_{\\text{Fidelity to signal}} + \\underbrace{\\lambda \\,\\mathbf{f}^{\\top}\\mathbf{L}\\mathbf{f}}_{\\text{Smoothness on graph}}\n$$\n\n这里，$\\mathbf{L} = \\mathbf{D} - \\mathbf{A}$ 是图拉普拉斯矩阵，其中 $\\mathbf{D}$ 是对角度矩阵，其对角元素为 $D_{ii} = \\sum_j A_{ij}$。项 $\\mathbf{f}^{\\top}\\mathbf{L}\\mathbf{f}$ 是拉普拉斯二次型，可以写作 $\\mathbf{f}^{\\top}\\mathbf{L}\\mathbf{f} = \\frac{1}{2}\\sum_{i,j} A_{ij}(f_i - f_j)^2$。该项对相连节点之间分数的大差异进行惩罚。参数 $\\lambda  0$ 平衡了拟合原始数据 $\\mathbf{x}$ 和在网络上强制平滑之间的权衡。\n\n为了找到唯一的最小化子 $\\mathbf{f}^{\\star}$，我们计算 $J(\\mathbf{f})$ 相对于 $\\mathbf{f}$ 的梯度，并将其设为零向量。\n目标函数可以展开为：\n$J(\\mathbf{f}) = (\\mathbf{f} - \\mathbf{x})^{\\top}(\\mathbf{f} - \\mathbf{x}) + \\lambda \\mathbf{f}^{\\top}\\mathbf{L}\\mathbf{f} = \\mathbf{f}^{\\top}\\mathbf{f} - 2\\mathbf{f}^{\\top}\\mathbf{x} + \\mathbf{x}^{\\top}\\mathbf{x} + \\lambda \\mathbf{f}^{\\top}\\mathbf{L}\\mathbf{f}$。\n\n梯度为：\n$$\n\\nabla_{\\mathbf{f}} J(\\mathbf{f}) = 2\\mathbf{f} - 2\\mathbf{x} + 2\\lambda\\mathbf{L}\\mathbf{f}\n$$\n将梯度设为零可得：\n$$\n2\\mathbf{f}^{\\star} - 2\\mathbf{x} + 2\\lambda\\mathbf{L}\\mathbf{f}^{\\star} = \\mathbf{0} \\\\\n\\implies \\mathbf{f}^{\\star} + \\lambda\\mathbf{L}\\mathbf{f}^{\\star} = \\mathbf{x} \\\\\n\\implies (\\mathbf{I} + \\lambda\\mathbf{L})\\mathbf{f}^{\\star} = \\mathbf{x}\n$$\n其中 $\\mathbf{I}$ 是 $5 \\times 5$ 单位矩阵。\n\n图拉普拉斯矩阵 $\\mathbf{L}$ 是半正定的，意味着其所有特征值 $\\gamma_i$ 都是非负的（$\\gamma_i \\ge 0$）。因此，矩阵 $(\\mathbf{I} + \\lambda\\mathbf{L})$ 的特征值为 $(1 + \\lambda\\gamma_i)$。由于 $\\lambda  0$，所有的 $(1 + \\lambda\\gamma_i) \\ge 1$，所以它们是严格为正的。没有零特征值的矩阵是可逆的。因此，对于任何 $\\mathbf{x}$，$(\\mathbf{I} + \\lambda\\mathbf{L})$ 总是可逆的，从而保证了唯一的解 $\\mathbf{f}^{\\star}$。\n\n通过求解这个线性方程组可以找到平滑分数 $\\mathbf{f}^{\\star}$：\n$$\n\\mathbf{f}^{\\star} = (\\mathbf{I} + \\lambda\\mathbf{L})^{-1}\\mathbf{x}\n$$\n这在计算上通过使用标准线性求解器来处理。", "answer": "```python\nimport numpy as np\n\ndef compute_metrics(A, x, lambda_val):\n    \"\"\"\n    Computes degree centrality, eigenvector centrality, and Laplacian-smoothed scores.\n\n    Args:\n        A (np.ndarray): The 5x5 adjacency matrix.\n        x (np.ndarray): The 5-element transcript abundance vector.\n        lambda_val (float): The smoothing parameter.\n\n    Returns:\n        tuple[list[float], list[float], list[float]]: A tuple containing the\n        lists of degree centralities, eigenvector centralities, and smoothed scores.\n    \"\"\"\n    # 1. Degree Centrality\n    # Degree centrality of node i is the sum of the weights of its incident edges.\n    # This is equivalent to the sum of the i-th row of the adjacency matrix.\n    degree_centrality = np.sum(A, axis=1).tolist()\n\n    # 2. Eigenvector Centrality\n    # Defined as the principal eigenvector of the adjacency matrix A.\n    eigenvalues, eigenvectors = np.linalg.eig(A)\n    # Find the index of the largest eigenvalue\n    max_eigenvalue_idx = np.argmax(eigenvalues)\n    # Get the corresponding eigenvector (principal eigenvector)\n    # eigenvectors are stored as columns in the returned matrix.\n    principal_eigenvector = eigenvectors[:, max_eigenvalue_idx]\n    \n    # Resolve sign indeterminacy: sum of components must be non-negative.\n    if np.sum(principal_eigenvector)  0:\n        principal_eigenvector = -principal_eigenvector\n    \n    eigenvector_centrality = principal_eigenvector.tolist()\n\n    # 3. Laplacian-Smoothed Scores\n    # We solve the linear system (I + lambda*L)f* = x\n    # First, construct the graph Laplacian L = D - A\n    D = np.diag(np.sum(A, axis=1))\n    L = D - A\n    \n    # Construct the matrix M = I + lambda*L\n    I = np.identity(A.shape[0])\n    M = I + lambda_val * L\n    \n    # Solve M * f_star = x for f_star\n    f_star = np.linalg.solve(M, x)\n    laplacian_scores = f_star.tolist()\n    \n    return degree_centrality, eigenvector_centrality, laplacian_scores\n\ndef solve():\n    \"\"\"\n    Main function to process all test cases and print the final result.\n    \"\"\"\n    lambda_val = 0.5\n\n    # Test Suite\n    test_cases = [\n        # Case 1\n        (\n            np.array([\n                [0, 1, 1, 0, 0],\n                [1, 0, 1, 1, 0],\n                [1, 1, 0, 0, 1],\n                [0, 1, 0, 0, 0],\n                [0, 0, 1, 0, 0]\n            ]),\n            np.array([2.0, 0.5, 1.2, 0.0, 3.0])\n        ),\n        # Case 2\n        (\n            np.array([\n                [0, 1, 0, 0, 0],\n                [1, 0, 1, 0, 0],\n                [0, 1, 0, 0, 1],\n                [0, 0, 0, 0, 0],\n                [0, 0, 1, 0, 0]\n            ]),\n            np.array([0.0, 1.0, 4.0, -1.0, 0.5])\n        ),\n        # Case 3\n        (\n            np.array([\n                [0, 1, 0.5, 0, 0],\n                [1, 0, 1, 0, 0],\n                [0.5, 1, 0, 0, 0],\n                [0, 0, 0, 0, 2],\n                [0, 0, 0, 2, 0]\n            ]),\n            np.array([1.0, 0.0, 0.0, 5.0, 0.0])\n        )\n    ]\n\n    all_results_str = []\n    for A, x in test_cases:\n        d, v, f = compute_metrics(A, x, lambda_val)\n\n        # Format each list of numbers into the required string format,\n        # rounding to six decimal places.\n        d_str = f\"[{','.join([f'{val:.6f}' for val in d])}]\"\n        v_str = f\"[{','.join([f'{val:.6f}' for val in v])}]\"\n        f_str = f\"[{','.join([f'{val:.6f}' for val in f])}]\"\n        \n        # Combine the three lists for the current case.\n        case_str = f\"[{d_str},{v_str},{f_str}]\"\n        all_results_str.append(case_str)\n\n    # Combine all case results into the final output string.\n    final_output = f\"[{','.join(all_results_str)}]\"\n    print(final_output)\n\nsolve()\n```", "id": "3320715"}, {"introduction": "这个最终的练习 [@problem_id:3320671] 将前面的概念整合到一个先进的推断框架中，反映了计算系统生物学的研究前沿。在这里，你的任务不再仅仅是评估或平滑数据，而是通过求解一个多目标优化问题来推断潜在的“蛋白质活性”状态。该模型旨在找到一个能够同时满足多个相互竞争的目标的最佳解：既要拟合观测到的转录组数据，又要与已知的PPI网络结构保持一致，并倾向于一个更简洁（稀疏）的解释。", "problem": "给定一个计算公式，用于整合转录组学和蛋白质-蛋白质相互作用网络，以估计潜在的蛋白质活性。令 $x \\in \\mathbb{R}^m$ 表示一个转录水平的对数表达向量，$B \\in \\mathbb{R}^{m \\times n}$ 是一个从蛋白质活性到转录丰度的线性映射（例如，一个线性化的调控影响矩阵），$w \\in \\mathbb{R}^n$ 是一个潜在蛋白质活性水平的向量。令 $A \\in \\mathbb{R}^{n \\times n}$ 是一个表示无向蛋白质-蛋白质相互作用网络的对称二元邻接矩阵，$D = \\mathrm{diag}(d_1,\\dots,d_n)$ 是对角度矩阵，其中 $d_i = \\sum_j A_{ij}$，而 $L = D - A$ 是组合图拉普拉斯矩阵。为了惩罚孤立蛋白质（度为零的节点）的激活，定义孤立惩罚矩阵 $R = \\mathrm{diag}(r_1,\\dots,r_n)$，其中如果 $d_i = 0$ 则 $r_i = 1$，否则 $r_i = 0$；并定义一致性矩阵 $Q = L + R$。\n\n考虑以下三个目标：\n- 数据拟合：$f_1(w) = \\|x - B w\\|_2$，\n- 稀疏性：$f_2(w) = \\|w\\|_1$，\n- 网络一致性：$f_3(w) = \\sqrt{w^\\top Q w}$。\n\n您的任务是使用加权和标量化方法研究 $f_1$、$f_2$ 和 $f_3$ 之间的多目标权衡。对于标量权重 $(\\alpha,\\beta,\\gamma)$，其中 $\\alpha,\\beta,\\gamma \\ge 0$ 且不全为零，定义代理标量目标\n$$\nJ(w;\\alpha,\\beta,\\gamma) = \\frac{\\alpha}{2}\\,\\|x - B w\\|_2^2 + \\frac{\\gamma}{2}\\,w^\\top Q w + \\beta\\,\\|w\\|_1.\n$$\n请注意，就最小化子而言，最小化 $\\|x - B w\\|_2$ 等同于最小化 $\\tfrac{1}{2}\\|x - B w\\|_2^2$，因为平方根函数在 $[0,\\infty)$ 上是单调递增的；因此，该代理目标对于拟合分量产生相同的最小化子。对于每个给定的权重三元组 $(\\alpha,\\beta,\\gamma)$，将 $w^\\star(\\alpha,\\beta,\\gamma)$ 定义为 $J(\\cdot;\\alpha,\\beta,\\gamma)$ 的任意最小化子。\n\n请实现一个算法，该算法针对每个测试用例和每个提供的权重三元组，使用近端梯度下降法计算近似最小化子 $w^\\star(\\alpha,\\beta,\\gamma)$。其中，平滑部分 $\\tfrac{\\alpha}{2}\\|x - B w\\|_2^2 + \\tfrac{\\gamma}{2} w^\\top Q w$ 用梯度下降处理，非平滑部分 $\\beta\\|w\\|_1$ 通过软阈值处理。使用基于利普希茨常数 $L_s = \\alpha\\,\\|B\\|_2^2 + \\gamma\\,\\|Q\\|_2$ 的固定步长，其中 $\\|\\cdot\\|_2$ 表示谱范数，并进行迭代，直到 $w$ 的相对变化低于 $10^{-8}$ 或达到最大迭代次数 $5000$ 次。在 $L_s = 0$ 的边缘情况下，返回 $w^\\star = 0$ 作为纯非平滑项 $\\beta\\|w\\|_1$ 的最小化子。\n\n对于每个计算出的 $w^\\star(\\alpha,\\beta,\\gamma)$，评估目标三元组\n$$\n\\big(f_1(w^\\star),\\; f_2(w^\\star),\\; f_3(w^\\star)\\big) = \\left(\\|x - B w^\\star\\|_2,\\; \\|w^\\star\\|_1,\\; \\sqrt{(w^\\star)^\\top Q w^\\star}\\right).\n$$\n\n然后，对于每个测试用例中与提供的权重网格相对应的三元组集合，计算非支配点集（一个近似帕累托前沿）：如果不存在另一个点，其所有三个目标值都小于或等于该点，且至少有一个严格小于该点，则该点是非支配的。报告非支配三元组，需按 $(f_1,f_2,f_3)$ 的字典序升序排序。为保证数值确定性，在最终报告中将每个三元组中的每个数字四舍五入到 $6$ 位小数。所有计算都是无单位的，不需要进行物理单位转换。\n\n测试套件。对于下面的每个测试用例，请完全按照规定使用给定的矩阵和向量。每个用例都列出了一组要评估的权重三元组 $(\\alpha,\\beta,\\gamma)$。\n\n- 用例 1：\n    - 网络大小：$n = 5$，转录本数 $m = 3$。\n    - 邻接矩阵 $A$（链状图 $1\\!-\\!2\\!-\\!3\\!-\\!4\\!-\\!5$）：$A_{12} = A_{21} = A_{23} = A_{32} = A_{34} = A_{43} = A_{45} = A_{54} = 1$，其余为 $0$。\n    - 映射矩阵 $B \\in \\mathbb{R}^{3 \\times 5}$：\n      $$\n      B = \\begin{bmatrix}\n      1.0  0.5  0.0  0.0  0.2 \\\\\n      0.0  0.3  0.8  0.1  0.0 \\\\\n      0.2  0.0  0.2  0.7  0.4\n      \\end{bmatrix}\n      $$\n    - 转录向量 $x \\in \\mathbb{R}^3$：$x = [1.2,\\,0.5,\\,0.8]^\\top$。\n    - 权重：$\\{(1.0,0.0,0.0),\\,(0.6,0.4,0.0),\\,(0.6,0.0,0.4),\\,(0.34,0.33,0.33),\\,(0.0,1.0,0.0),\\,(0.0,0.2,0.8)\\}$。\n\n- 用例 2：\n    - 网络大小：$n = 4$，转录本数 $m = 4$。\n    - 邻接矩阵 $A$（路径 $1\\!-\\!2\\!-\\!3$ 和孤立节点 $4$）：$A_{12} = A_{21} = A_{23} = A_{32} = 1$，其余为 $0$。\n    - 映射矩阵 $B = I_4$（$4 \\times 4$ 单位矩阵）。\n    - 转录向量 $x \\in \\mathbb{R}^4$：$x = [0.0,\\,0.0,\\,1.0,\\,0.2]^\\top$。\n    - 权重：$\\{(1.0,0.0,0.0),\\,(0.5,0.0,0.5),\\,(0.5,0.5,0.0),\\,(0.0,1.0,0.0),\\,(0.0,0.0,1.0)\\}$。\n\n- 用例 3：\n    - 网络大小：$n = 6$，转录本数 $m = 3$。\n    - 邻接矩阵 $A$（节点 $\\{1,2,3\\}$ 上的三角形和路径 $4\\!-\\!5\\!-\\!6$）：\n      $A_{12} = A_{21} = A_{13} = A_{31} = A_{23} = A_{32} = 1$ 且 $A_{45} = A_{54} = A_{56} = A_{65} = 1$，其余为 $0$。\n    - 映射矩阵 $B \\in \\mathbb{R}^{3 \\times 6}$：\n      $$\n      B = \\begin{bmatrix}\n      0.7  0.6  0.0  0.0  0.0  0.0 \\\\\n      0.0  0.2  0.9  0.5  0.0  0.0 \\\\\n      0.0  0.0  0.0  0.3  0.8  0.6\n      \\end{bmatrix}\n      $$\n    - 转录向量 $x \\in \\mathbb{R}^3$：$x = [1.0,\\,0.7,\\,1.1]^\\top$。\n    - 权重：$\\{(1.0,0.0,0.0),\\,(0.3,0.6,0.1),\\,(0.3,0.1,0.6),\\,(0.0,1.0,0.0),\\,(0.0,0.2,0.8)\\}$。\n\n实现和输出要求。\n- 使用步长 $t = 1/L_s$（其中 $L_s = \\alpha\\,\\|B\\|_2^2 + \\gamma\\,\\|Q\\|_2$）实现带软阈值处理的近端梯度下降法，如果需要，可为数值稳定性添加一个保守因子。使用软阈值算子 $\\mathrm{soft}(u,\\tau)_i = \\mathrm{sign}(u_i)\\cdot \\max\\{|u_i| - \\tau, 0\\}$。\n- 对每个测试用例，计算所有指定权重的目标三元组列表，筛选出非支配子集，按 $(f_1,f_2,f_3)$ 升序进行字典排序，并将所有数字四舍五入到 $6$ 位小数。\n- 您的程序应生成单行输出，其中包含所有测试用例的结果，格式为一个包含三个列表的列表（每个测试用例一个），其中每个内部列表包含排序后的非支配三元组，每个三元组表示为包含三个浮点数的列表。例如：“[[[f11,f12,f13],[...],...],[[...]],[[...]]]”。不应打印其他任何文本。", "solution": "用户提供了一个系统生物学领域的计算问题，该问题要求实现一个优化算法来探索三个相互竞争的目标之间的权衡。该问题在科学上和数学上是良定的。因此，上述验证程序已通过，可以提供完整的解决方案。\n\n该问题要求我们为一个多目标优化问题找到一个近似的帕累托前沿。需要最小化的三个目标是：\n1.  数据拟合，$f_1(w) = \\|x - B w\\|_2$，它量化了观测到的转录水平表达数据 $x \\in \\mathbb{R}^m$ 与通过线性模型 $B \\in \\mathbb{R}^{m \\times n}$ 由潜在蛋白质活性 $w \\in \\mathbb{R}^n$ 预测的表达之间的差异。\n2.  稀疏性，$f_2(w) = \\|w\\|_1$，它鼓励大部分潜在蛋白质活性为零的解，这对应于一个更简单的模型，其中只有较少的蛋白质被认为是活跃的。\n3.  网络一致性，$f_3(w) = \\sqrt{w^\\top Q w}$，它惩罚在相互作用网络中相连的蛋白质活性水平不相似的解。一致性矩阵定义为 $Q = L + R$，其中 $L=D-A$ 是蛋白质相互作用网络邻接矩阵 $A$ 的图拉普拉斯矩阵，而 $R$ 是一个对角矩阵，用于惩罚没有相互作用（度 $d_i=0$）的蛋白质的活性。\n\n为了探索这些权衡，我们采用加权和标量化方法。对于一组给定的非负权重 $(\\alpha, \\beta, \\gamma)$，这三个目标被组合成一个单一的代理目标函数 $J(w;\\alpha,\\beta,\\gamma)$：\n$$\nJ(w;\\alpha,\\beta,\\gamma) = \\frac{\\alpha}{2}\\,\\|x - B w\\|_2^2 + \\beta\\,\\|w\\|_1 + \\frac{\\gamma}{2}\\,w^\\top Q w.\n$$\n注意，$f_1$ 和 $f_3$ 的二次型被用于 $J(w)$ 中，因为它们与它们的平方根对应项共享相同的最小化子，并能得到一个更易于处理的优化问题。具体来说，函数 $z \\mapsto z^2$ 对非负参数是严格递增的。\n\n目标函数 $J(w)$ 是凸函数，因为它是凸函数的非负加权和。我们可以将 $J(w)$ 分解为一个光滑、可微的部分 $g(w)$ 和一个非光滑的部分 $h(w)$：\n$$\ng(w) = \\frac{\\alpha}{2}\\|x - B w\\|_2^2 + \\frac{\\gamma}{2}w^\\top Q w\n$$\n$$\nh(w) = \\beta\\|w\\|_1\n$$\n这种结构使得 $J(w)$ 适合通过近端梯度下降（PGD）算法进行最小化，该算法在此背景下也称为迭代收缩阈值算法（ISTA）。PGD 的核心思想是迭代执行一个针对光滑部分的梯度下降步，然后是一个针对非光滑部分的近端映射步。\n\n光滑部分 $g(w)$ 的梯度 $\\nabla g(w)$ 是：\n$$\n\\nabla g(w) = \\alpha B^\\top(Bw - x) + \\gamma Qw\n$$\n对于 $L_1$-范数项 $h(w)$ 的近端算子是软阈值算子，定义为：\n$$\n\\mathrm{prox}_{t h}(u) = \\mathrm{soft}(u, t\\beta)_i = \\mathrm{sign}(u_i)\\cdot \\max\\{|u_i| - t\\beta, 0\\},\n$$\n其中 $t$ 是算法的步长。\n\n因此，PGD 的迭代公式为：\n$$\nw_{k+1} = \\mathrm{prox}_{t h}(w_k - t \\nabla g(w_k))\n$$\n为使算法收敛，步长 $t$ 的选择必须满足 $0  t \\le 1/L_s$，其中 $L_s$ 是梯度 $\\nabla g(w)$ 的利普希茨常数。问题指定使用此常数的一个上界：\n$$\nL_s = \\alpha\\,\\|B\\|_2^2 + \\gamma\\,\\|Q\\|_2,\n$$\n其中 $\\|\\cdot\\|_2$ 表示矩阵的谱范数（最大奇异值）。我们将使用步长 $t = 1/L_s$。迭代从一个初始猜测（通常为 $w_0 = \\vec{0}$）开始，并持续进行，直到向量 $w$ 的相对变化低于一个容差（例如 $10^{-8}$）或达到最大迭代次数。\n\n对于每个给定的权重三元组 $(\\alpha, \\beta, \\gamma)$，我们执行此 PGD 算法以找到一个最小化子 $w^\\star$。然后，我们评估原始的三个目标函数 $(f_1(w^\\star), f_2(w^\\star), f_3(w^\\star))$ 以获得目标空间中的一个点。\n\n在为所有指定的权重组合计算完这些三元组后，我们必须识别出非支配点的集合。如果不存在任何其他计算出的点 $p'$ 在所有目标上都优于或等于点 $p$ 并且至少在一个目标上严格优于 $p$，则点 $p$ 是非支配的。也就是说，不存在 $p' \\neq p$ 使得对于所有三个目标 $i \\in \\{1, 2, 3\\}$ 都有 $p'_i \\leq p_i$。这组非支配点构成了对真实帕累托前沿的近似。\n\n最后，对于每个测试用例，这组非支配三元组按字典序升序排序。为了最终报告，每个三元组中的数字都四舍五入到 $6$ 位小数。为每个提供的测试用例实现整个算法，并将结果汇总成指定的输出格式。", "answer": "```python\nimport numpy as np\n\ndef soft_thresholding(u, tau):\n    \"\"\"Soft-thresholding operator.\"\"\"\n    return np.sign(u) * np.maximum(np.abs(u) - tau, 0)\n\ndef proximal_gradient_descent(alpha, beta, gamma, B, x, Q, B_norm_sq, Q_norm):\n    \"\"\"\n    Minimizes the objective J(w) using proximal gradient descent.\n    J(w) = (alpha/2)*||x - Bw||^2 + beta*||w||_1 + (gamma/2)*w^T*Q*w\n    \"\"\"\n    n = Q.shape[0]\n    \n    # Lipschitz constant of the gradient of the smooth part\n    Ls = alpha * B_norm_sq + gamma * Q_norm\n\n    # Handle edge case where the smooth part is absent\n    if Ls == 0:\n        # Objective is beta*||w||_1, minimized at w=0\n        return np.zeros(n)\n\n    t = 1.0 / Ls\n    \n    max_iter = 5000\n    tol = 1e-8\n    \n    w = np.zeros(n)\n    \n    # Pre-compute constant matrix products for efficiency\n    BtB = B.T @ B\n    Btx = B.T @ x\n    \n    for _ in range(max_iter):\n        w_prev = w.copy()\n        \n        # Gradient of the smooth part: grad(g(w)) = alpha*B^T(Bw-x) + gamma*Qw\n        grad_g = alpha * (BtB @ w - Btx) + gamma * (Q @ w)\n        \n        # Gradient descent step for the smooth part\n        u = w - t * grad_g\n        \n        # Proximal step for the non-smooth part (L1 norm)\n        w = soft_thresholding(u, t * beta)\n        \n        # Check for convergence\n        norm_w_prev = np.linalg.norm(w_prev)\n        if np.linalg.norm(w - w_prev) / (norm_w_prev + np.finfo(float).eps)  tol:\n            break\n            \n    return w\n\ndef find_non_dominated(points):\n    \"\"\"\n    Filters a list of points to find the non-dominated subset.\n    A point p1 is dominated if another point p2 exists such that\n    all(p2 = p1) and any(p2  p1).\n    \"\"\"\n    num_points = len(points)\n    if num_points == 0:\n        return []\n    \n    points_arr = np.array(points)\n    is_dominated = np.zeros(num_points, dtype=bool)\n\n    for i in range(num_points):\n        for j in range(num_points):\n            if i == j:\n                continue\n            if np.all(points_arr[j] = points_arr[i]) and np.any(points_arr[j]  points_arr[i]):\n                is_dominated[i] = True\n                break\n    \n    return [points[i] for i in range(num_points) if not is_dominated[i]]\n\ndef solve_case(A, B, x, weights_grid):\n    \"\"\"\n    Solves a single test case from problem setup to final Pareto front.\n    \"\"\"\n    n = A.shape[0]\n    \n    # Pre-computation of matrices\n    d = A.sum(axis=1)\n    D = np.diag(d)\n    L = D - A\n    r = (d == 0).astype(float)\n    R = np.diag(r)\n    Q = L + R\n    \n    # Pre-compute squared spectral norm of B and spectral norm of Q\n    B_norm_sq = np.linalg.norm(B, ord=2)**2\n    Q_norm = np.linalg.norm(Q, ord=2)\n\n    objective_triplets = []\n    \n    for alpha, beta, gamma in weights_grid:\n        w_star = proximal_gradient_descent(alpha, beta, gamma, B, x, Q, B_norm_sq, Q_norm)\n        \n        f1 = np.linalg.norm(x - B @ w_star)\n        f2 = np.linalg.norm(w_star, ord=1)\n        f3_sq = w_star.T @ Q @ w_star\n        f3 = np.sqrt(f3_sq) if f3_sq > 0 else 0.0\n        \n        objective_triplets.append([f1, f2, f3])\n        \n    # Find non-dominated points\n    non_dominated_points = find_non_dominated(objective_triplets)\n    \n    # Sort lexicographically\n    sorted_points = sorted(non_dominated_points, key=lambda p: (p[0], p[1], p[2]))\n    \n    # Round to 6 decimal places for final reporting\n    final_list = [[round(val, 6) for val in p] for p in sorted_points]\n    \n    return final_list\n\ndef solve():\n    # Case 1\n    A1 = np.array([\n        [0, 1, 0, 0, 0],\n        [1, 0, 1, 0, 0],\n        [0, 1, 0, 1, 0],\n        [0, 0, 1, 0, 1],\n        [0, 0, 0, 1, 0]\n    ], dtype=float)\n    B1 = np.array([\n        [1.0, 0.5, 0.0, 0.0, 0.2],\n        [0.0, 0.3, 0.8, 0.1, 0.0],\n        [0.2, 0.0, 0.2, 0.7, 0.4]\n    ])\n    x1 = np.array([1.2, 0.5, 0.8])\n    weights1 = [(1.0, 0.0, 0.0), (0.6, 0.4, 0.0), (0.6, 0.0, 0.4), (0.34, 0.33, 0.33), (0.0, 1.0, 0.0), (0.0, 0.2, 0.8)]\n    case1 = (A1, B1, x1, weights1)\n\n    # Case 2\n    A2 = np.array([\n        [0, 1, 0, 0],\n        [1, 0, 1, 0],\n        [0, 1, 0, 0],\n        [0, 0, 0, 0]\n    ], dtype=float)\n    B2 = np.identity(4)\n    x2 = np.array([0.0, 0.0, 1.0, 0.2])\n    weights2 = [(1.0, 0.0, 0.0), (0.5, 0.0, 0.5), (0.5, 0.5, 0.0), (0.0, 1.0, 0.0), (0.0, 0.0, 1.0)]\n    case2 = (A2, B2, x2, weights2)\n\n    # Case 3\n    A3 = np.array([\n        [0, 1, 1, 0, 0, 0],\n        [1, 0, 1, 0, 0, 0],\n        [1, 1, 0, 0, 0, 0],\n        [0, 0, 0, 0, 1, 0],\n        [0, 0, 0, 1, 0, 1],\n        [0, 0, 0, 0, 1, 0]\n    ], dtype=float)\n    B3 = np.array([\n        [0.7, 0.6, 0.0, 0.0, 0.0, 0.0],\n        [0.0, 0.2, 0.9, 0.5, 0.0, 0.0],\n        [0.0, 0.0, 0.0, 0.3, 0.8, 0.6]\n    ])\n    x3 = np.array([1.0, 0.7, 1.1])\n    weights3 = [(1.0, 0.0, 0.0), (0.3, 0.6, 0.1), (0.3, 0.1, 0.6), (0.0, 1.0, 0.0), (0.0, 0.2, 0.8)]\n    case3 = (A3, B3, x3, weights3)\n\n    test_cases = [case1, case2, case3]\n    all_results = []\n    for A, B, x, weights_grid in test_cases:\n        pareto_front = solve_case(A, B, x, weights_grid)\n        all_results.append(pareto_front)\n        \n    print(repr(all_results).replace(\" \", \"\"))\n\nsolve()\n```", "id": "3320671"}]}