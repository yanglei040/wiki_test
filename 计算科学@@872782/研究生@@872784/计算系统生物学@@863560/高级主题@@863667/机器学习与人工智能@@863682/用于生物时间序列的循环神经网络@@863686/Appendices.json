{"hands_on_practices": [{"introduction": "为了掌握循环神经网络，我们首先从其最核心的计算步骤——单步状态更新——开始。这个练习将引导你手动计算一个简单RNN在一个时间步内的前向传播过程。通过将隐藏状态想象为转录调控模块的活动，我们可以直观地理解RNN如何将当前输入（如刺激信号）与前一时刻的系统状态相结合，以生成新的状态。[@problem_id:3344978]", "problem": "在计算系统生物学中，循环神经网络（Recurrent Neural Network (RNN)）被用于模拟生物时间序列，例如基因表达动态。考虑一个最小的二维隐藏状态，它代表两个转录调控模块的活动。该系统是一个离散时间非线性状态空间模型，其中下一个隐藏状态是通过对当前输入和前一个隐藏状态的仿射组合应用逐元素的饱和非线性函数 $\\phi$ 来生成的，而单个标量输出是通过对当前隐藏状态进行线性读出而产生的。饱和非线性函数是双曲正切函数 $\\phi(u) = \\tanh(u)$，逐元素应用。\n\n假设在时间索引 $t$ 处的参数化如下：\n- 输入到隐藏层矩阵 $W_{xh} = \\begin{pmatrix}1  & 0 \\\\ 0  & 1\\end{pmatrix}$，\n- 隐藏层到隐藏层矩阵 $W_{hh} = \\begin{pmatrix}0.5  & 0 \\\\ 0  & 0.8\\end{pmatrix}$，\n- 偏置向量 $b = \\begin{pmatrix}0 \\\\ 0\\end{pmatrix}$，\n- 输入向量 $x_t = \\begin{pmatrix}0.2 \\\\ -0.1\\end{pmatrix}$，\n- 前一个隐藏状态 $h_{t-1} = \\begin{pmatrix}0.0 \\\\ 0.5\\end{pmatrix}$，\n- 隐藏层到输出层读出 $W_{hy} = \\begin{pmatrix}1  & -1\\end{pmatrix}$，\n- 输出偏置 $c = 0$。\n\n从具有逐元素饱和激活和线性读出的离散时间非线性状态空间模型的核心定义出发，构建适用于此RNN的隐藏状态更新和输出映射。然后，根据给定的参数计算当前隐藏状态 $h_t$ 和标量输出 $y_t$ 的数值。将 $h_t$ 和 $y_t$ 的每个分量四舍五入到六位有效数字。这些值是无量纲的归一化量。将您的最终答案表示为单行向量 $\\begin{pmatrix}h_{t,1}  & h_{t,2}  & y_t\\end{pmatrix}$。", "solution": "该问题要求在给定一组参数、前一个隐藏状态 $h_{t-1}$ 和当前输入 $x_t$ 的情况下，计算一个简单循环神经网络（RNN）的当前隐藏状态 $h_t$ 和标量输出 $y_t$。该模型由一个离散时间非线性状态空间公式定义。\n\n首先，我们根据问题描述建立RNN的控制方程。隐藏状态的更新规则是通过对输入 $x_t$ 和前一个隐藏状态 $h_{t-1}$ 的仿射变换应用逐元素的激活函数 $\\phi$ 来给出的。通用方程为：\n$$h_t = \\phi(W_{xh}x_t + W_{hh}h_{t-1} + b)$$\n输出 $y_t$ 是当前隐藏状态 $h_t$ 的线性读出：\n$$y_t = W_{hy}h_t + c$$\n\n问题指定激活函数为双曲正切函数 $\\phi(u) = \\tanh(u)$，逐元素应用。给定的参数是：\n- 输入到隐藏层矩阵：$W_{xh} = \\begin{pmatrix} 1  & 0 \\\\ 0  & 1 \\end{pmatrix}$\n- 隐藏层到隐藏层矩阵：$W_{hh} = \\begin{pmatrix} 0.5  & 0 \\\\ 0  & 0.8 \\end{pmatrix}$\n- 偏置向量：$b = \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$\n- 输入向量：$x_t = \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix}$\n- 前一个隐藏状态：$h_{t-1} = \\begin{pmatrix} 0.0 \\\\ 0.5 \\end{pmatrix}$\n- 隐藏层到输出层读出矩阵：$W_{hy} = \\begin{pmatrix} 1  & -1 \\end{pmatrix}$\n- 输出偏置：$c = 0$\n\n我们的第一步是计算激活函数的参数，即仿射组合 $a_t = W_{xh}x_t + W_{hh}h_{t-1} + b$。\n$$a_t = \\begin{pmatrix} 1  & 0 \\\\ 0  & 1 \\end{pmatrix} \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix} + \\begin{pmatrix} 0.5  & 0 \\\\ 0  & 0.8 \\end{pmatrix} \\begin{pmatrix} 0.0 \\\\ 0.5 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix}$$\n我们分别计算矩阵-向量乘积：\n$$W_{xh}x_t = \\begin{pmatrix} (1)(0.2) + (0)(-0.1) \\\\ (0)(0.2) + (1)(-0.1) \\end{pmatrix} = \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix}$$\n$$W_{hh}h_{t-1} = \\begin{pmatrix} (0.5)(0.0) + (0)(0.5) \\\\ (0)(0.0) + (0.8)(0.5) \\end{pmatrix} = \\begin{pmatrix} 0.0 \\\\ 0.4 \\end{pmatrix}$$\n现在，我们将各项相加得到 $a_t$：\n$$a_t = \\begin{pmatrix} 0.2 \\\\ -0.1 \\end{pmatrix} + \\begin{pmatrix} 0.0 \\\\ 0.4 \\end{pmatrix} + \\begin{pmatrix} 0 \\\\ 0 \\end{pmatrix} = \\begin{pmatrix} 0.2 + 0.0 + 0 \\\\ -0.1 + 0.4 + 0 \\end{pmatrix} = \\begin{pmatrix} 0.2 \\\\ 0.3 \\end{pmatrix}$$\n\n接下来，我们通过应用逐元素的双曲正切函数来计算当前隐藏状态 $h_t$，即 $h_t = \\phi(a_t) = \\tanh(a_t)$。\n$$h_t = \\begin{pmatrix} \\tanh(0.2) \\\\ \\tanh(0.3) \\end{pmatrix}$$\n我们计算 $h_t$ 各分量的数值：\n$$h_{t,1} = \\tanh(0.2) \\approx 0.19737532...$$\n$$h_{t,2} = \\tanh(0.3) \\approx 0.29131261...$$\n根据题目要求，我们将这些值四舍五入到六位有效数字：\n$$h_{t,1} \\approx 0.197375$$\n$$h_{t,2} \\approx 0.291313$$\n所以，当前隐藏状态为 $h_t \\approx \\begin{pmatrix} 0.197375 \\\\ 0.291313 \\end{pmatrix}$。\n\n最后，我们使用线性读出方程 $y_t = W_{hy}h_t + c$ 计算标量输出 $y_t$。\n$$y_t = \\begin{pmatrix} 1  & -1 \\end{pmatrix} h_t + 0$$\n为了获得更高的精度，在进行最终四舍五入之前，我们在本次计算中使用 $h_t$ 的未舍入值。\n$$y_t = (1) \\times h_{t,1} + (-1) \\times h_{t,2} = h_{t,1} - h_{t,2}$$\n$$y_t \\approx 0.19737532 - 0.29131261 = -0.09393729...$$\n将此结果四舍五入到六位有效数字：\n$$y_t \\approx -0.0939373$$\n\n问题要求将最终答案表示为单行向量 $\\begin{pmatrix} h_{t,1}  & h_{t,2}  & y_t \\end{pmatrix}$。使用四舍五入后的值，该向量为：\n$$\\begin{pmatrix} 0.197375  & 0.291313  & -0.0939373 \\end{pmatrix}$$", "answer": "$$\\boxed{\\begin{pmatrix} 0.197375  & 0.291313  & -0.0939373 \\end{pmatrix}}$$", "id": "3344978"}, {"introduction": "简单RNN在处理长序列时会遇到梯度消失或爆炸的问题，限制了其捕捉长期依赖性的能力。门控循环单元（GRU）通过引入更新门和重置门来解决这一挑战，从而更有效地控制信息流。这个练习将带你深入GRU的内部工作机制，计算其候选状态和最终隐藏状态的更新，并解释门控机制如何帮助模型有选择地保留或遗忘过去的信息，这对于模拟复杂的生物过程至关重要。[@problem_id:3344975]", "problem": "一个使用门控循环单元（GRU）架构的二维循环神经网络（RNN）被用来为一个生物时间序列建模，该序列捕捉了两个相互作用的基因表达模块在时变刺激下的联合动力学。在时间 $t$，GRU的隐藏状态更新使用逐元素门控将过去的信息与一个受刺激调制的候选状态相结合。候选隐藏状态是通过对当前输入贡献和一个经重置门控的循环贡献的仿射和应用双曲正切非线性函数来计算的。具体来说，考虑在时间 $t$ 的以下量：\n- 更新门向量 $z_t = \\begin{bmatrix}0.1\\\\0.9\\end{bmatrix}$，\n- 重置门向量 $r_t = \\begin{bmatrix}0.5\\\\0.2\\end{bmatrix}$，\n- 输入到隐藏层的贡献 $W_{xh}x_t = \\begin{bmatrix}0.3\\\\-0.1\\end{bmatrix}$，\n- 隐藏层到隐藏层的贡献 $W_{hh}h_{t-1} = \\begin{bmatrix}0.4\\\\0.2\\end{bmatrix}$，\n- 前一个隐藏状态 $h_{t-1} = \\begin{bmatrix}0.2\\\\0.8\\end{bmatrix}$。\n\n假设采用标准的GRU逐元素更新，其中候选隐藏状态由 $\\tilde{h}_t = \\tanh\\!\\big(W_{xh}x_t + r_t \\odot (W_{hh}h_{t-1})\\big)$ 给出，新的隐藏状态为 $h_t = (1 - z_t)\\odot h_{t-1} + z_t \\odot \\tilde{h}_t$，其中 $\\odot$ 表示哈达玛（逐元素）积，$\\tanh$ 逐元素应用。\n\n任务：\n1. 计算候选隐藏状态 $\\tilde{h}_t$。\n2. 计算更新后的隐藏状态 $h_t$。\n3. 根据隐藏状态更新中的凸组合系数，确定保留更多过去信息的维度的索引 $j \\in \\{1,2\\}$，这被解释为在 $(1 - z_t)$ 中具有较大系数的维度。\n\n将所有数值条目四舍五入到四位有效数字。将最终答案以单行矩阵的形式报告，顺序为 $\\big(\\tilde{h}_{t,1}, \\tilde{h}_{t,2}, h_{t,1}, h_{t,2}, j\\big)$，其中 $j$ 以普通整数形式给出。", "solution": "本问题要求计算一个门控循环单元（GRU）的候选隐藏状态 $\\tilde{h}_t$、新的隐藏状态 $h_t$，并确定保留更多过去信息的维度。该问题提法明确，具有科学依据，并包含获得唯一解所需的所有信息。\n\n给定的量是：\n- 更新门向量：$z_t = \\begin{bmatrix}0.1\\\\0.9\\end{bmatrix}$\n- 重置门向量：$r_t = \\begin{bmatrix}0.5\\\\0.2\\end{bmatrix}$\n- 输入到隐藏层的贡献：$W_{xh}x_t = \\begin{bmatrix}0.3\\\\-0.1\\end{bmatrix}$\n- 隐藏层到隐藏层的贡献：$W_{hh}h_{t-1} = \\begin{bmatrix}0.4\\\\0.2\\end{bmatrix}$\n- 前一个隐藏状态：$h_{t-1} = \\begin{bmatrix}0.2\\\\0.8\\end{bmatrix}$\n\n更新方程是：\n- 候选隐藏状态：$\\tilde{h}_t = \\tanh\\!\\big(W_{xh}x_t + r_t \\odot (W_{hh}h_{t-1})\\big)$\n- 新的隐藏状态：$h_t = (1 - z_t)\\odot h_{t-1} + z_t \\odot \\tilde{h}_t$\n\n这里，$\\odot$ 表示逐元素哈达玛积，$\\tanh$ 函数被逐元素应用。所有最终数值都需四舍五入到四位有效数字。\n\n**任务1：计算候选隐藏状态 $\\tilde{h}_t$。**\n\n首先，我们计算经重置门控的循环贡献，即 $r_t \\odot (W_{hh}h_{t-1})$。\n$$\nr_t \\odot (W_{hh}h_{t-1}) = \\begin{bmatrix}0.5\\\\0.2\\end{bmatrix} \\odot \\begin{bmatrix}0.4\\\\0.2\\end{bmatrix} = \\begin{bmatrix}0.5 \\times 0.4\\\\0.2 \\times 0.2\\end{bmatrix} = \\begin{bmatrix}0.2\\\\0.04\\end{bmatrix}\n$$\n接下来，我们将输入贡献 $W_{xh}x_t$ 加到这个结果上。\n$$\nW_{xh}x_t + r_t \\odot (W_{hh}h_{t-1}) = \\begin{bmatrix}0.3\\\\-0.1\\end{bmatrix} + \\begin{bmatrix}0.2\\\\0.04\\end{bmatrix} = \\begin{bmatrix}0.3 + 0.2\\\\-0.1 + 0.04\\end{bmatrix} = \\begin{bmatrix}0.5\\\\-0.06\\end{bmatrix}\n$$\n最后，我们应用逐元素的双曲正切函数 $\\tanh$ 来获得 $\\tilde{h}_t$。\n$$\n\\tilde{h}_t = \\tanh\\left(\\begin{bmatrix}0.5\\\\-0.06\\end{bmatrix}\\right) = \\begin{bmatrix}\\tanh(0.5)\\\\\\tanh(-0.06)\\end{bmatrix}\n$$\n我们计算数值并四舍五入到四位有效数字。\n$$\n\\tanh(0.5) \\approx 0.462117... \\approx 0.4621\n$$\n$$\n\\tanh(-0.06) \\approx -0.059928... \\approx -0.05993\n$$\n因此，候选隐藏状态是：\n$$\n\\tilde{h}_t = \\begin{bmatrix}0.4621\\\\-0.05993\\end{bmatrix}\n$$\n\n**任务2：计算更新后的隐藏状态 $h_t$。**\n\n更新方程是 $h_t = (1 - z_t)\\odot h_{t-1} + z_t \\odot \\tilde{h}_t$。这个方程表示一个凸组合，其中更新门 $z_t$ 在前一个状态 $h_{t-1}$ 和候选状态 $\\tilde{h}_t$ 之间进行插值。\n\n首先，我们计算向量 $(1 - z_t)$。\n$$\n1 - z_t = 1 - \\begin{bmatrix}0.1\\\\0.9\\end{bmatrix} = \\begin{bmatrix}1 - 0.1\\\\1 - 0.9\\end{bmatrix} = \\begin{bmatrix}0.9\\\\0.1\\end{bmatrix}\n$$\n现在我们分别计算和的两个项。第一项，代表来自过去的贡献，是：\n$$\n(1 - z_t) \\odot h_{t-1} = \\begin{bmatrix}0.9\\\\0.1\\end{bmatrix} \\odot \\begin{bmatrix}0.2\\\\0.8\\end{bmatrix} = \\begin{bmatrix}0.9 \\times 0.2\\\\0.1 \\times 0.8\\end{bmatrix} = \\begin{bmatrix}0.18\\\\0.08\\end{bmatrix}\n$$\n第二项，代表来自新候选状态的贡献，是：\n$$\nz_t \\odot \\tilde{h}_t = \\begin{bmatrix}0.1\\\\0.9\\end{bmatrix} \\odot \\begin{bmatrix}0.4621\\\\-0.05993\\end{bmatrix} = \\begin{bmatrix}0.1 \\times 0.4621\\\\0.9 \\times (-0.05993)\\end{bmatrix} = \\begin{bmatrix}0.04621\\\\-0.053937\\end{bmatrix}\n$$\n最后，我们将这两项相加得到新的隐藏状态 $h_t$。\n$$\nh_t = \\begin{bmatrix}0.18\\\\0.08\\end{bmatrix} + \\begin{bmatrix}0.04621\\\\-0.053937\\end{bmatrix} = \\begin{bmatrix}0.18 + 0.04621\\\\0.08 - 0.053937\\end{bmatrix} = \\begin{bmatrix}0.22621\\\\0.026063\\end{bmatrix}\n$$\n将每个分量四舍五入到四位有效数字：\n$$\nh_t = \\begin{bmatrix}0.2262\\\\0.02606\\end{bmatrix}\n$$\n\n**任务3：确定保留更多过去信息的维度的索引 $j$。**\n\n从前一个隐藏状态 $h_{t-1}$ 保留的信息量由系数向量 $(1 - z_t)$ 控制。问题将保留更多过去信息的维度定义为该向量中具有较大系数的维度。我们已经计算出：\n$$\n1 - z_t = \\begin{bmatrix}0.9\\\\0.1\\end{bmatrix}\n$$\n第一个维度（$j=1$）的系数是 $(1-z_t)_1 = 0.9$。\n第二个维度（$j=2$）的系数是 $(1-z_t)_2 = 0.1$。\n比较这两个值，我们发现 $0.9 > 0.1$。因此，第一个维度保留了更多的过去信息。索引是 $j=1$。\n\n最终答案由 $\\tilde{h}_t$ 的元素、$h_t$ 的元素以及索引 $j$ 组成，排列成一个单行矩阵：$(\\tilde{h}_{t,1}, \\tilde{h}_{t,2}, h_{t,1}, h_{t,2}, j)$。\n- $\\tilde{h}_{t,1} = 0.4621$\n- $\\tilde{h}_{t,2} = -0.05993$\n- $h_{t,1} = 0.2262$\n- $h_{t,2} = 0.02606$\n- $j = 1$", "answer": "$$\n\\boxed{\\begin{pmatrix} 0.4621  & -0.05993  & 0.2262  & 0.02606  & 1 \\end{pmatrix}}\n$$", "id": "3344975"}, {"introduction": "RNN模型的前向传播过程只是第一步；为了训练模型，我们必须定义一个能够衡量其预测与真实数据拟合程度的目标函数。本练习将RNN的应用与生物数据分析的实际需求相结合，指导你为单细胞RNA测序（scRNA-seq）计数数据构建一个基于负二项分布的对数似然函数。此外，你还将学习如何通过引入平滑度正则化项来鼓励模型学习到生物学上更合理的平滑动态轨迹，这是确保模型泛化能力和可解释性的关键一步。[@problem_id:3344950]", "problem": "您正在使用循环神经网络 (RNN) 对单细胞核糖核酸测序 (scRNA-seq) 中单个基因的计数轨迹进行建模。在由 $t \\in \\{1,2,\\dots,T\\}$ 索引的每个离散时间点，RNN 输出一个非负均值参数 $ \\mu_t $ 和一个共享的离散参数 $ r > 0 $。观测到的计数为 $ y_t \\in \\{0,1,2,\\dots\\} $。在 scRNA-seq 中，一个广泛接受的计数生成模型是负二项分布，它通过均值和离散度进行参数化，能够捕捉超出泊松模型的过离散现象。\n\n从负二项分布的基本定义出发，即一个在非负整数上的计数分布，其参数化产生的期望为 $ \\mathbb{E}[Y] = \\mu $，方差为 $ \\operatorname{Var}(Y) = \\mu + \\mu^2 / r $，请推导单个时间点的对数似然表达式 $ \\ell(\\mu_t, r; y_t) $，然后对于给定的序列 $ \\{y_t\\}_{t=1}^{T} $，计算总对数似然 $ \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) $。请通过伽马函数使用与实值 $ r > 0 $ 一致的表示方法，以确保离散参数 $ r $ 不被限制为整数值。\n\n为了鼓励生成符合生物学合理性的轨迹，请基于经典正则化理论中的离散时间有限差分算子，为 RNN 的均值 $ \\{\\mu_t\\}_{t=1}^{T} $ 提出一个平滑度惩罚项。实现二阶差分惩罚\n$$\nS_2(\\mu) \\;=\\; \\sum_{t=3}^{T} \\left( \\mu_t - 2 \\mu_{t-1} + \\mu_{t-2} \\right)^2,\n$$\n该惩罚项会对离散曲率的快速变化施加惩罚，并倾向于平滑变化的 $ \\mu_t $。构建惩罚目标函数\n$$\nJ(\\mu, r; y) \\;=\\; \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) \\;-\\; \\lambda \\, S_2(\\mu),\n$$\n其中 $ \\lambda \\ge 0 $ 是用户指定的正则化强度。\n\n您的程序必须为下面的每个测试用例计算一个三元组，包括总对数似然 $ \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) $、平滑度惩罚 $ S_2(\\mu) $ 和惩罚目标函数 $ J(\\mu, r; y) $。所有输出均为实数。不涉及物理单位。不使用角度。\n\n测试套件（每个用例指定 $ y $、$ \\mu $、$ r $ 和 $ \\lambda $）：\n- 用例1（一般一致性）：$ y = [3,4,5,6,7] $，$ \\mu = [3.2,3.8,4.5,5.5,6.6] $，$ r = 10.0 $，$ \\lambda = 0.1 $。\n- 用例2（接近泊松极限和零计数）：$ y = [0,0,1,0,2] $，$ \\mu = [0.2,0.3,0.9,0.1,1.8] $，$ r = 100.0 $，$ \\lambda = 0.5 $。\n- 用例3（高过离散和突变）：$ y = [1,10,2,12,3] $，$ \\mu = [0.9,9.5,1.2,10.8,2.4] $，$ r = 0.7 $，$ \\lambda = 1.0 $。\n- 用例4（急剧峰值和其他位置的小均值）：$ y = [0,1,0,20,0] $，$ \\mu = [0.05,0.8,0.05,15.0,0.05] $，$ r = 2.0 $，$ \\lambda = 2.0 $。\n\n最终输出格式：您的程序应生成单行输出，包含一个由方括号括起来的逗号分隔列表，其中每个元素对应一个测试用例，并且本身是一个包含三个浮点数的列表 $ [\\text{LL}, \\text{S}, \\text{J}] $。例如，输出必须类似于 $ [[\\text{LL}_1,\\text{S}_1,\\text{J}_1],[\\text{LL}_2,\\text{S}_2,\\text{J}_2],\\dots] $，无任何附加文本。", "solution": "该问题要求为一个由负二项 (NB) 分布建模的计数时间序列计算一个惩罚对数似然目标函数。目标函数由 $J(\\mu, r; y) = \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) - \\lambda S_2(\\mu)$ 给出。为了计算该函数，我们必须首先推导单个时间点对数似然 $\\ell(\\mu_t, r; y_t)$ 的显式公式，然后实现总对数似然、平滑度惩罚 $S_2(\\mu)$ 和最终目标 $J$ 的计算。\n\n**1. 负二项对数似然 $\\ell(\\mu_t, r; y_t)$ 的推导**\n\n问题通过均值 $\\mathbb{E}[Y] = \\mu$ 和方差 $\\operatorname{Var}(Y) = \\mu + \\mu^2/r$ 来指定负二项分布。这是生物信息学中一种常见的参数化方法。为了找到对应的概率质量函数 (PMF)，我们将此参数化与一个更常见的由失败次数 $r$ 和成功概率 $p$ 定义的参数化关联起来。在 $r$ 次失败前观测到 $k \\in \\{0, 1, 2, \\dots\\}$ 次成功的 PMF 为：\n$$ P(Y=k|r, p) = \\binom{k+r-1}{k} p^k (1-p)^r $$\n对于此参数化，均值和方差分别为 $\\mathbb{E}[Y] = pr/(1-p)$ 和 $\\operatorname{Var}(Y) = pr/(1-p)^2$。\n\n通过将指定的均值 $\\mu$ 与期望的公式相等，我们可以用 $\\mu$ 和 $r$ 来表示 $p$：\n$$ \\mu = \\frac{pr}{1-p} \\implies \\mu(1-p) = pr \\implies \\mu - \\mu p = pr \\implies \\mu = p(\\mu+r) \\implies p = \\frac{\\mu}{\\mu+r} $$\n由此，失败的概率为 $1-p = 1 - \\frac{\\mu}{\\mu+r} = \\frac{r}{\\mu+r}$。\n\n我们可以验证这种重新参数化与给定的方差是一致的：\n$$ \\operatorname{Var}(Y) = \\frac{pr}{(1-p)^2} = \\frac{(\\mu/(\\mu+r))r}{(r/(\\mu+r))^2} = \\frac{\\mu r}{\\mu+r} \\frac{(\\mu+r)^2}{r^2} = \\frac{\\mu(\\mu+r)}{r} = \\mu + \\frac{\\mu^2}{r} $$\n重新参数化是正确的。\n\n问题要求一个适用于实值 $r > 0$ 的公式，这可以通过使用伽马函数 $\\Gamma(z)$ 和恒等式 $\\binom{n}{k} = \\frac{\\Gamma(n+1)}{\\Gamma(k+1)\\Gamma(n-k+1)}$ 来表示二项式系数以实现。对于我们的二项式系数，设 $n=k+r-1$（此处用 $y_t$ 代替 $k$）：\n$$ \\binom{y_t+r-1}{y_t} = \\frac{\\Gamma(y_t+r-1+1)}{\\Gamma(y_t+1)\\Gamma(y_t+r-1-y_t+1)} = \\frac{\\Gamma(y_t+r)}{\\Gamma(y_t+1)\\Gamma(r)} $$\n将此式以及 $p$ 和 $1-p$ 的表达式代入均值为 $\\mu_t$ 的观测值 $y_t$ 的 PMF 表达式中，可得：\n$$ P(Y=y_t|\\mu_t, r) = \\frac{\\Gamma(y_t+r)}{\\Gamma(y_t+1)\\Gamma(r)} \\left(\\frac{\\mu_t}{\\mu_t+r}\\right)^{y_t} \\left(\\frac{r}{\\mu_t+r}\\right)^r $$\n因此，单个时间点的对数似然 $\\ell(\\mu_t, r; y_t) = \\log P(Y=y_t|\\mu_t, r)$ 为：\n$$ \\ell(\\mu_t, r; y_t) = \\log\\left(\\frac{\\Gamma(y_t+r)}{\\Gamma(y_t+1)\\Gamma(r)}\\right) + y_t\\log\\left(\\frac{\\mu_t}{\\mu_t+r}\\right) + r\\log\\left(\\frac{r}{\\mu_t+r}\\right) $$\n利用对数的性质，我们可以将此表达式展开为适合计算的形式。在计算上，使用对数伽马函数 $\\log\\Gamma(z)$ 更为稳定。\n$$ \\ell(\\mu_t, r; y_t) = \\log\\Gamma(y_t+r) - \\log\\Gamma(y_t+1) - \\log\\Gamma(r) + y_t(\\log\\mu_t - \\log(\\mu_t+r)) + r(\\log r - \\log(\\mu_t+r)) $$\n合并包含 $\\log(\\mu_t+r)$ 的项，得到单个时间点的最终表达式：\n$$ \\ell(\\mu_t, r; y_t) = \\log\\Gamma(y_t+r) - \\log\\Gamma(y_t+1) - \\log\\Gamma(r) + y_t\\log\\mu_t + r\\log r - (y_t+r)\\log(\\mu_t+r) $$\n整个时间序列的总对数似然是所有时间点上对数似然的总和：\n$$ \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) $$\n\n**2. 平滑度惩罚 $S_2(\\mu)$**\n\n问题定义了一个二阶有限差分惩罚项，以鼓励均值参数序列 $\\{\\mu_t\\}_{t=1}^{T}$ 的平滑性。该惩罚项由下式给出：\n$$ S_2(\\mu) = \\sum_{t=3}^{T} \\left( \\mu_t - 2 \\mu_{t-1} + \\mu_{t-2} \\right)^2 $$\n此项惩罚均值轨迹 $\\mu(t)$ 的二阶导数的离散模拟值，偏好接近线性的轨迹。求和从 $t=3$ 开始，因此它对长度 $T \\ge 3$ 的时间序列有定义。对于 $T < 3$，惩罚为 $0$。\n\n**3. 惩罚目标函数 $J(\\mu, r; y)$**\n\n最终的目标函数结合了衡量数据拟合优度的总对数似然，以及强制施加关于轨迹形状的先验信念的平滑度惩罚。一个非负的正则化参数 $\\lambda \\ge 0$ 控制着二者之间的权衡：\n$$ J(\\mu, r; y) = \\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t) - \\lambda S_2(\\mu) $$\n程序将为每个提供的测试用例计算这三个量：总对数似然 $\\sum_{t=1}^{T} \\ell(\\mu_t, r; y_t)$、平滑度惩罚 $S_2(\\mu)$ 和惩罚目标函数 $J(\\mu, r; y)$。实现将利用数值稳定的对数伽马函数。", "answer": "```\n[[-10.97059737151323,0.23,-10.99359737151323],[-6.262529883508491,5.950000000000001,-9.237529883508492],[-14.97549219391118,178.6,-193.57549219391118],[-12.92348123281222,501.905,-1016.7334812328121]]\n```", "id": "3344950"}]}