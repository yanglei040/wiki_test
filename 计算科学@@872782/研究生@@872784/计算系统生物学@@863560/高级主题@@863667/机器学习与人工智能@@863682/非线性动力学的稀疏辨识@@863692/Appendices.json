{"hands_on_practices": [{"introduction": "这个首个练习是一个全面的实践，旨在引导你走完整个标准的SINDy工作流程。通过将SINDy应用于一个经典的、表现出阿利效应（Allee effect）的单变量种群模型，你将亲手体验从生成含噪声数据到执行稀疏回归并验证结果的每一个关键步骤。[@problem_id:3349431]这项练习是数据驱动动力学发现领域一个基础性的“Hello, World!”。", "problem": "您的任务是实现一个完整的程序，用于在计算系统生物学中对单变量细胞种群模型执行稀疏非线性动力学辨识 (SINDy)。未知动力学被假定为由种群密度的光滑函数控制，其机理设定为低密度下的合作与高密度下的拥擠共同决定净增长率。您必须使用从该机理图像模拟的时间序列数据，推导出一个数据驱动的、稀疏的、最高为三次的多项式模型，然后评估所辨识的稀疏模型是否与不同扰动水平下由底层生死过程所蕴含的预期三次典范形式相一致。该程序必须是自包含的，并且无需用户输入即可运行。\n\n基本假设：\n- 令 $x(t)$ 表示无量纲细胞密度，$t$ 表示时间（秒）。\n- 种群动力学遵循 $\\frac{dx}{dt} = f(x)$，其中 $f$ 是一个确定性光滑函数，在感兴趣的区间内，一个最高为三次的多项式近似是有效的低阶替代模型。\n- 稀疏建模方法旨在通过从候选库中选择一个最小的活动项集合，来寻求 $f$ 的一个简约表示。\n- 候选特征库仅限于三个多项式项 $\\{x, x^2, x^3\\}$。\n\n必需的建模流程：\n1. 从一个机理上合理的增长模型中模拟时间序列数据 $\\{t_i, x_i\\}_{i=0}^{N-1}$，该模型中低密度下的合作与高密度下的拥挤共存。机理参数为内在增长率 $r$、环境承载力 $K$ 和一个合作阈值 $A$ (一个 Allee 阈值)，每个都严格为正。使用真实动力学生成 $x(t)$，然后对 $x(t)$ 施加指定标准差的加性零均值高斯噪声来污染观测值，以模拟测量噪声。\n2. 使用适合含噪数据的数值稳定微分器从含噪观测值中估计 $\\frac{dx}{dt}$。您可以使用窗口长度和多项式阶数可调的多项式平滑微分器。\n3. 从平滑后的 $x(t)$ 构建设计矩阵，其列为 $x$、$x^2$ 和 $x^3$，并执行序列阈值最小二乘法以获得一个稀疏系数向量 $\\boldsymbol{\\theta} = [\\theta_1,\\theta_2,\\theta_3]^\\top$，使得\n$$\n\\frac{dx}{dt} \\approx \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3.\n$$\n该序列阈值程序必须迭代地移除幅值低于指定阈值的系数，并在剩余的活动集上重新拟合，直到收敛或达到最大迭代次数。\n\n每个测试案例的评估标准：\n- 通过解析展开由合作和拥挤效应（由 $(r,K,A)$ 表征）组合产生的典范三次增长，计算基准真相系数 $\\boldsymbol{\\theta}^{\\star}$。该增长源于一个第一性原理的生死过程表述，其中合作性出生受拥挤限制，而竞争性損失随密度增加。\n- 使用按分量定义的相对误差，将辨识出的系数 $\\boldsymbol{\\theta}$ 与 $\\boldsymbol{\\theta}^{\\star}$ 进行比较：\n$$\n\\varepsilon_j = \\frac{|\\theta_j - \\theta_j^{\\star}|}{\\max\\{10^{-12}, |\\theta_j^{\\star}|\\}}, \\quad j \\in \\{1,2,3\\}.\n$$\n- 为每个测试案例报告一个布尔值，指明所有三个系数是否满足 $\\varepsilon_j \\leq \\text{tol}$（对于指定的容差），并且与 $\\theta_j^{\\star}$ 符号相同。\n\n单位：\n- 时间 $t$ 的单位必须是秒。状态 $x$ 是无量纲的。不使用角度单位。\n\n您的程序必须实现以下测试套件。对于每个元组，参数为 $(r, K, A, x_0, T, \\Delta t, \\sigma, \\lambda, \\text{tol}, \\alpha)$，其中 $x_0$ 是初始条件，$T$ 是总模拟时间（秒），$\\Delta t$ 是采样间隔（秒），$\\sigma$ 是 $x$ 上加性高斯噪声的标准差，$\\lambda$ 是序列阈值最小二乘法的阈值，$\\text{tol}$ 是用于接受的相对误差容差，$\\alpha$ 是用于选择平滑窗口长度的样本数量的分数（窗口长度必须为奇数，并与样本大小相适应）。\n- 测试案例 1 (理想路径，低噪声): $(1.0, 1.0, 0.2, 0.05, 8.0, 0.01, 0.001, 1\\times 10^{-3}, 0.05, 0.07)$。\n- 测试案例 2 (较高噪声): $(0.8, 1.5, 0.4, 0.02, 8.0, 0.01, 0.02, 5\\times 10^{-3}, 0.15, 0.11)$。\n- 测试案例 3 (更稀疏采样和近阈值初始化): $(1.2, 1.0, 0.8, 0.9, 6.0, 0.05, 0.005, 2\\times 10^{-3}, 0.10, 0.21)$。\n- 测试案例 4 (边界挑战，弱吸引): $(0.4, 1.0, 0.95, 0.96, 10.0, 0.02, 0.01, 3\\times 10^{-3}, 0.20, 0.15)$。\n\n最终输出格式：\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表的结果（例如，\"[result1,result2,result3,result4]\"），每个\"result\"是按上述方法计算的相应测试案例的布尔接受值。", "solution": "我们从一个基于原理的生死圖像中推導辨识策略，在该图像中，低密度下的合作与高密度下的拥挤结合形成一个净增长定律。令 $x(t)$ 为充分混合环境中的无量纲细胞密度，并令 $\\frac{dx}{dt} = f(x)$ 为光滑函数。其机理是：人均出生率最初因合作而随密度上升，但在高密度时受拥挤限制；而人均损失率因竞争而随密度增加。一个能同时捕捉这两种效应的常用典范形式是三个因子的乘积：一个与密度 $x$ 成正比的因子，一个形式为 $(1 - x/K)$ 的限制项（捕捉了环境承载力 $K$），以及一个形式为 $(x/A - 1)$ 的合作项（引入了一个阈值 $A$，即 Allee 阈值，低于此阈值净增长变为负值）。\n\n基于此机理基础，我们考虑典范增长定律\n$$\n\\frac{dx}{dt} = r\\,x\\,(1 - x/K)\\,(x/A - 1),\n$$\n其中 $r0$ 是一个内在增长率，$K0$ 是环境承载力，$A0$ 是合作阈值。尽管问题陈述没有指定目标公式，但上述形式是从一个基本假设推导出来的，即净增长是密度、拥挤限制因子和合作因子的乘积，并且它是一个经过充分检验的 Allee 效应模型。\n\n为了使用稀疏非线性动力学辨识 (SINDy) 拟合一个稀疏模型，我们构建一个包含三个单项式 $\\{x, x^2, x^3\\}$ 的候选函数库，并寻求系数 $\\boldsymbol{\\theta} = [\\theta_1,\\theta_2,\\theta_3]^\\top$ 使得\n$$\n\\frac{dx}{dt} \\approx \\theta_1 x + \\theta_2 x^2 + \\theta_3 x^3.\n$$\n展开该机理定律可以得到这个三次表示中的显式系数。首先，展开乘积\n$$\n(1 - x/K)\\,(x/A - 1) = \\frac{x}{A} - 1 - \\frac{x^2}{A K} + \\frac{x}{K} = \\left(\\frac{1}{A} + \\frac{1}{K}\\right)x - 1 - \\frac{x^2}{A K}.\n$$\n乘以 $r x$ 得到\n$$\n\\frac{dx}{dt} = r\\,x\\left[\\left(\\frac{1}{A} + \\frac{1}{K}\\right)x - 1 - \\frac{1}{A K}x^3\\right]\n= r\\left[\\left(\\frac{1}{A} + \\frac{1}{K}\\right)x^2 - x - \\frac{1}{A K}x^3\\right].\n$$\n因此，真正的三次系数是\n$$\n\\theta_1^{\\star} = -r, \\quad \\theta_2^{\\star} = r\\left(\\frac{1}{A} + \\frac{1}{K}\\right), \\quad \\theta_3^{\\star} = -\\frac{r}{A K}.\n$$\n\n算法设计：\n1. 数据生成。对于给定的 $(r,K,A,x_0)$，我们使用具有指定采样间隔 $\\Delta t$ 的高阶积分器，从 $x(0)=x_0$ 开始在 $t \\in [0,T]$ 上模拟确定性系统 $\\frac{dx}{dt} = r\\,x\\,(1 - x/K)\\,(x/A - 1)$。观测轨迹被施加了标准差为 $\\sigma$ 的加性零均值高斯噪声以污染 $x$，从而模拟测量噪声。这在生物测量中是现实的，因为计数误差和荧光强度会在观测密度中引入噪声。\n\n2. 从含噪数据中估计导数。直接有限差分会放大噪声。一种经过充分检验的方法是使用多项式平滑微分器，例如 Savitzky–Golay 滤波器，它在移动窗口上拟合一个选定阶数的局部多项式，以生成平滑信号及其导数。我们通过一个分数 $\\alpha$ 和固定的多项式阶数来选择一个与样本数量成比例的奇数窗口长度，以确保窗口的可行性。这会产生适用于回归的 $\\frac{dx}{dt}$ 和 $x$ 的稳健估计。\n\n3. 使用序列阈值最小二乘法进行稀疏辨識。设 $\\Theta(x)$ 是由平滑信号构建的设计矩阵，其列为 $[x, x^2, x^3]$。初始的最小二乘拟合\n$$\n\\boldsymbol{\\theta}^{(0)} = \\arg\\min_{\\boldsymbol{\\theta}}\\|\\Theta \\boldsymbol{\\theta} - \\dot{x}\\|_2^2\n$$\n随后进行迭代稀疏化：对于一个阈值 $\\lambda  0$，我们将幅值 $|\\theta_j^{(k)}|  \\lambda$ 的项设置为零，并仅对活动集进行重新拟合。重复此过程会产生一个简约模型，它能抑制由噪声和过拟合引入的伪小系数。\n\n4. 与基准真相进行评估。对于每个测试案例，我们计算解析的三次系数 $\\boldsymbol{\\theta}^{\\star} = [-r,\\; r(1/A + 1/K),\\; -r/(A K)]^\\top$。如果所有分量 $j \\in \\{1,2,3\\}$ 的相对误差\n$$\n\\varepsilon_j = \\frac{|\\theta_j - \\theta_j^{\\star}|}{\\max\\{10^{-12},|\\theta_j^{\\star}|\\}}\n$$\n小于或等于指定的容差，并且 $\\theta_j$ 的符号与 $\\theta_j^{\\star}$ 的符号匹配，则辨識出的系数被接受。符号检查确保推断出的模型保留了机理上的增/減方向性：抑制性的线性项 ($\\theta_1^{\\star}  0$)、促进性的二次项 ($\\theta_2^{\\star} > 0$，由合作和拥挤共同作用产生)，以及抑制性的三次项 ($\\theta_3^{\\star}  0$，由拥挤饱和产生)。\n\n测试套件覆盖范围：\n- 第一个案例是低噪声和密集采样下的标称场景，期望能够直接恢复模型。\n- 第二个案例增加了测量噪声，需要稳健的平滑和阈值处理；容差也相应放宽。\n- 第三个案例使用更稀疏的采样，并在合作阈值附近初始化，强调了在更窄的动态范围内进行正确微分和保证模型可辨識性的重要性。\n- 第四个案例是一个边界挑战，其中 $A$ 接近 $K$ 且初始条件接近 $K$，这降低了合作因子的信号幅度，对可辨识性提出了挑战；容差也相应放宽。\n\n实现细节：\n- 使用可靠的常微分方程求解器生成干净的轨迹。\n- 使用 Savitzky–Golay 滤波器进行平滑和导数估计，窗口长度为奇数 $w = \\max\\{w_{\\min}, 2\\lfloor(\\alpha N)/2\\rfloor + 1\\}$，并裁剪至数据长度范围内，其中 $N$ 是样本数，$w_{\\min}$ 确保多项式可行性。\n- 实现序列阈值最小二乘法，设定固定的最大迭代次数，并以活动集的稳定性作为收敛标准。\n- 通过固定随机数生成器种子来确保可复现性。\n\n最终程序计算四个测试案例的接受布尔值，并以指定的单行格式打印它们。", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom scipy.signal import savgol_filter\n\n# Seed the random number generator for reproducibility\nrng = np.random.default_rng(42)\n\ndef logistic_allee_rhs(t, x, r, K, A):\n    # x may be array; ensure element-wise computation\n    return r * x * (1.0 - x / K) * (x / A - 1.0)\n\ndef simulate_time_series(r, K, A, x0, T, dt):\n    # Solve the ODE dx/dt = r x (1 - x/K)(x/A - 1) from t=0 to t=T\n    t_eval = np.arange(0.0, T + 1e-12, dt)\n    sol = solve_ivp(fun=lambda t, y: logistic_allee_rhs(t, y, r, K, A),\n                    t_span=(0.0, T),\n                    y0=[x0],\n                    t_eval=t_eval,\n                    method='RK45',\n                    rtol=1e-8,\n                    atol=1e-10)\n    t = sol.t\n    x = sol.y[0]\n    return t, x\n\ndef add_noise(x, sigma):\n    if sigma == 0.0:\n        return x.copy()\n    noise = rng.normal(loc=0.0, scale=sigma, size=x.shape)\n    return x + noise\n\ndef choose_window_length(n, alpha, polyorder):\n    # Compute an odd window length proportional to sample size,\n    # clipped to be feasible for Savitzky-Golay\n    # Start from alpha*n rounded to nearest odd\n    wlen = int(max(5, int(n * alpha)))\n    # Enforce odd\n    if wlen % 2 == 0:\n        wlen += 1\n    # Minimum window for polyorder\n    min_wlen = polyorder + 3\n    if min_wlen % 2 == 0:\n        min_wlen += 1\n    if wlen  min_wlen:\n        wlen = min_wlen\n    # Clip to data length - must be = n\n    if wlen > n:\n        wlen = n - 1 if (n - 1) % 2 == 1 else n - 2\n    # Final guard: ensure odd and at least polyorder+2\n    if wlen % 2 == 0:\n        wlen -= 1\n    if wlen  polyorder + 2:\n        wlen = polyorder + 3\n        if wlen % 2 == 0:\n            wlen += 1\n        if wlen > n:\n            wlen = n - 1 if (n - 1) % 2 == 1 else n - 2\n    return max(5, wlen)\n\ndef estimate_derivative(y, dt, alpha, polyorder=3):\n    n = len(y)\n    wlen = choose_window_length(n, alpha, polyorder)\n    # Smooth signal\n    y_smooth = savgol_filter(y, window_length=wlen, polyorder=polyorder, deriv=0)\n    # Derivative\n    dy_dt = savgol_filter(y, window_length=wlen, polyorder=polyorder, deriv=1, delta=dt)\n    return y_smooth, dy_dt\n\ndef stlsq(Theta, ydot, threshold, max_iter=10, rcond=None):\n    # Sequential thresholded least squares\n    # Initial least squares\n    coef, *_ = np.linalg.lstsq(Theta, ydot, rcond=rcond)\n    active = np.ones_like(coef, dtype=bool)\n    for _ in range(max_iter):\n        # Threshold small coefficients\n        new_active = np.abs(coef) >= threshold\n        # If active set hasn't changed, break\n        if np.array_equal(new_active, active):\n            break\n        active = new_active\n        if not np.any(active):\n            coef[:] = 0.0\n            break\n        # Refit on active set\n        Theta_active = Theta[:, active]\n        coef_active, *_ = np.linalg.lstsq(Theta_active, ydot, rcond=rcond)\n        # Update coefficients\n        coef = np.zeros_like(coef)\n        coef[active] = coef_active\n    return coef\n\ndef true_coefficients(r, K, A):\n    # From expansion: dx/dt = (-r) x + r(1/A + 1/K) x^2 + ( - r/(A K) ) x^3\n    return np.array([-r, r * (1.0 / A + 1.0 / K), -r / (A * K)], dtype=float)\n\ndef run_case(params):\n    r, K, A, x0, T, dt, sigma, lam, tol, alpha = params\n    # Simulate clean dynamics\n    t, x_clean = simulate_time_series(r, K, A, x0, T, dt)\n    # Add measurement noise\n    x_noisy = add_noise(x_clean, sigma)\n    # Estimate derivative from noisy data\n    x_smooth, dxdt_est = estimate_derivative(x_noisy, dt, alpha=alpha, polyorder=3)\n    # Build library Theta = [x, x^2, x^3]\n    Theta = np.column_stack([x_smooth, x_smooth**2, x_smooth**3])\n    # Fit sparse model\n    theta_hat = stlsq(Theta, dxdt_est, threshold=lam, max_iter=10, rcond=None)\n    # Ground-truth coefficients\n    theta_true = true_coefficients(r, K, A)\n    # Relative errors and sign checks\n    denom = np.maximum(1e-12, np.abs(theta_true))\n    rel_err = np.abs(theta_hat - theta_true) / denom\n    signs_match = np.all(np.sign(theta_hat) == np.sign(theta_true))\n    accepted = bool(np.all(rel_err = tol) and signs_match)\n    return accepted\n\ndef solve():\n    # Define the test cases from the problem statement:\n    # (r, K, A, x0, T, dt, sigma, lambda, tol, alpha)\n    test_cases = [\n        (1.0, 1.0, 0.2, 0.05, 8.0, 0.01, 0.001, 1e-3, 0.05, 0.07),\n        (0.8, 1.5, 0.4, 0.02, 8.0, 0.01, 0.02, 5e-3, 0.15, 0.11),\n        (1.2, 1.0, 0.8, 0.9, 6.0, 0.05, 0.005, 2e-3, 0.10, 0.21),\n        (0.4, 1.0, 0.95, 0.96, 10.0, 0.02, 0.01, 3e-3, 0.20, 0.15),\n    ]\n    results = []\n    for case in test_cases:\n        res = run_case(case)\n        results.append(res)\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3349431"}, {"introduction": "在掌握了基本的SINDy流程之后，理解一个常见的数值陷阱至关重要：矩阵的病态问题（ill-conditioning）。本次练习聚焦于候选函数库矩阵的条件数，揭示数量级差异巨大的特征（例如，当$x$很小时，$x$和$x^2$）如何破坏回归问题的数值稳定性。[@problem_id:3349468]通过这个练习，你将量化这一问题，并检验一个简单而强大的解决方案——特征缩放，以确保你的SINDy实现是鲁棒和可靠的。", "problem": "您正在研究特征缩放如何影响稀疏非线性动力学辨識 (SINDy) 中使用的库矩阵的数值条件。考虑在 $N$ 个点 $\\{x_i\\}_{i=1}^N$ 上采样的单个标量状态变量。该问题的 SINDy 库由两个特征组成：$x$ 和 $x^2$。将库矩阵 $\\Theta(x) \\in \\mathbb{R}^{N \\times 2}$ 定义为\n$$\n\\Theta(x) = \\begin{bmatrix}\nx_1  x_1^2 \\\\\nx_2  x_2^2 \\\\\n\\vdots  \\vdots \\\\\nx_N  x_N^2\n\\end{bmatrix}.\n$$\n$\\Theta(x)$ 的数值条件由 2-范数条件数衡量，该条件数根据奇异值分解 (SVD) 定义为\n$$\n\\kappa_2(\\Theta) = \\frac{\\sigma_{\\max}(\\Theta)}{\\sigma_{\\min}(\\Theta)},\n$$\n其中 $\\sigma_{\\max}(\\Theta)$ 是最大奇异值，$\\sigma_{\\min}(\\Theta)$ 是最小奇异值。一个大的 $\\kappa_2(\\Theta)$ 表示病态条件。\n\n为了扩展特征的动态范围并可能改善条件，对输入数据应用标量重缩放：\n$$\nz_i = s \\, x_i, \\quad s = \\frac{1}{\\operatorname{std}(x)},\n$$\n其中 $\\operatorname{std}(x)$ 是样本 $\\{x_i\\}_{i=1}^N$ 的总体标准差，计算时分母为 $N$。构建缩放后的库\n$$\n\\Theta(z) = \\begin{bmatrix}\nz_1  z_1^2 \\\\\nz_2  z_2^2 \\\\\n\\vdots  \\vdots \\\\\nz_N  z_N^2\n\\end{bmatrix}.\n$$\n请注意，这是对输入变量的纯粹重缩放，意味着通过对角矩阵 $\\operatorname{diag}(s, s^2)$ 对 $\\Theta(x)$ 进行列向缩放。\n\n任务：\n- 对于每个指定的测试用例，在闭区间 $[a,b]$ 内生成 $N$ 个等距样本：\n$$\nx_i = a + \\frac{i-1}{N-1}(b-a), \\quad i = 1,2,\\ldots,N,\n$$\n其中 $N \\ge 2$ 且 $a \\le b$。\n- 使用双精度浮点数通过 SVD 计算 $\\kappa_2(\\Theta(x))$ 和 $\\kappa_2(\\Theta(z))$。\n- 确定一个布尔标志 $\\mathrm{improved}$，如果 $\\kappa_2(\\Theta(z))  \\kappa_2(\\Theta(x))$，则定义为 $\\mathrm{True}$，否则为 $\\mathrm{False}$。\n\n实现细节与约束：\n- 使用分母为 $N$ 的总体标准差计算 $\\operatorname{std}(x)$。\n- 如果 $\\sigma_{\\min}(\\Theta)$ 在数值上为 $0$，则将条件数视为 $+\\infty$。\n- 所有计算都必须使用标准双精度浮点数进行。\n- 本问题不涉及物理单位。\n- 本问题不涉及角度。\n- 不要将任何值表示为百分比。\n\n测试套件：\n- 情况 A：$a = 0$，$b = 10^{-3}$，$N = 100$。\n- 情况 B：$a = -10^{-3}$，$b = 10^{-3}$，$N = 100$。\n- 情况 C：$a = 0$，$b = 10^{-6}$，$N = 50$。\n- 情况 D：$a = -\\tfrac{1}{2}$，$b = \\tfrac{1}{2}$，$N = 200$。\n\n要求的程序输出：\n- 生成单行输出，包含一个由方括号括起来的逗号分隔列表。\n- 对于每个测试用例，按 $A, B, C, D$ 的顺序，依次附加三个值：$\\kappa_2(\\Theta(x))$、$\\kappa_2(\\Theta(z))$ 和布尔值 $\\mathrm{improved}$。\n- 浮点值必须四舍五入到恰好 $6$ 位小数。\n- 因此，最终输出格式为\n$$\n[\\kappa_{A,\\mathrm{raw}},\\kappa_{A,\\mathrm{scaled}},\\mathrm{improved}_A,\\kappa_{B,\\mathrm{raw}},\\kappa_{B,\\mathrm{scaled}},\\mathrm{improved}_B,\\kappa_{C,\\mathrm{raw}},\\kappa_{C,\\mathrm{scaled}},\\mathrm{improved}_C,\\kappa_{D,\\mathrm{raw}},\\kappa_{D,\\mathrm{scaled}},\\mathrm{improved}_D].\n$$", "solution": "用户希望分析数据缩放对稀疏非线性动力学辨识 (SINDy) 方法中使用的库矩阵的数值条件的影响。该问题是自洽的、科学上合理的且良定的。我将着手解决。\n\n问题的核心在于比较两个相关矩阵的 2-范数条件数 $\\kappa_2$。条件数定义为最大奇异值与最小奇异值之比，即 $\\kappa_2(\\Theta) = \\frac{\\sigma_{\\max}(\\Theta)}{\\sigma_{\\min}(\\Theta)}$，是衡量矩阵对数值误差敏感度的标准度量。大的条件数表示矩阵是病态的，这可能导致在数值计算（如求解线性系统）中得到不可靠的结果。\n\n解决此问题的方法论涉及对由参数 $a$、$b$ 和 $N$ 指定的每个测试用例执行一系列定义明确的计算步骤。\n\n首先，我们生成状态变量样本。对于每个测试用例，使用提供的公式在闭区间 $[a,b]$ 上生成 $N$ 个等距点 $\\{x_i\\}_{i=1}^N$：\n$$\nx_i = a + \\frac{i-1}{N-1}(b-a), \\quad i = 1,2,\\ldots,N\n$$\n这等效于使用标准的数值库函数，如 `numpy.linspace(a, b, N)`。生成的样本构成一个向量 $\\mathbf{x} = [x_1, x_2, \\ldots, x_N]^T$。\n\n其次，我们构建未缩放的库矩阵 $\\Theta(\\mathbf{x})$。该矩阵包含在每个样本点上求值的基函数。对于此问题，基函数为 $f_1(x) = x$ 和 $f_2(x) = x^2$。库矩阵 $\\Theta(\\mathbf{x}) \\in \\mathbb{R}^{N \\times 2}$ 由两列构成：向量 $\\mathbf{x}$ 本身及其逐元素平方的向量 $\\mathbf{x}^2 = [x_1^2, x_2^2, \\ldots, x_N^2]^T$。\n$$\n\\Theta(\\mathbf{x}) = \\begin{bmatrix} \\mathbf{x}  \\mathbf{x}^2 \\end{bmatrix}\n$$\n\n第三，我们计算条件数 $\\kappa_2(\\Theta(\\mathbf{x}))$。这需要在 $\\Theta(\\mathbf{x})$ 上执行奇异值分解 (SVD)。SVD 提供奇异值 $\\sigma_1 \\geq \\sigma_2 \\geq \\ldots \\geq 0$。对于我们的 $N \\times 2$ 矩阵（其中 $N \\ge 2$），有两个奇异值，$\\sigma_{\\max} = \\sigma_1$ 和 $\\sigma_{\\min} = \\sigma_2$。然后将条件数计算为它们的比值。根据问题规范，如果 $\\sigma_{\\min}$ 在数值上为零，则条件数被视为无穷大。\n\n第四，我们执行数据缩放。通过将每个样本 $x_i$ 乘以一个缩放因子 $s$ 来创建数据的缩放版本 $\\mathbf{z}$。\n$$\nz_i = s \\cdot x_i, \\quad \\text{其中} \\quad s = \\frac{1}{\\operatorname{std}(\\mathbf{x})}\n$$\n标准差 $\\operatorname{std}(\\mathbf{x})$ 是总体标准差，以 $N$ 为分母进行计算：\n$$\n\\operatorname{std}(\\mathbf{x}) = \\sqrt{\\frac{1}{N} \\sum_{i=1}^N (x_i - \\mu)^2}, \\quad \\text{其中} \\quad \\mu = \\frac{1}{N} \\sum_{i=1}^N x_i\n$$\n这种缩放确保生成的数据向量 $\\mathbf{z}$ 的总体标准差恰好为 $1$。\n\n第五，我们构建缩放后的库矩阵 $\\Theta(\\mathbf{z})$ 并计算其条件数 $\\kappa_2(\\Theta(\\mathbf{z}))$。此过程与 $\\Theta(\\mathbf{x})$ 的过程相同，但使用的是缩放后的数据向量 $\\mathbf{z}$。\n$$\n\\Theta(\\mathbf{z}) = \\begin{bmatrix} \\mathbf{z}  \\mathbf{z}^2 \\end{bmatrix}\n$$\n\n最后，我们确定缩放是否有利。我们定义一个布尔标志 $\\mathrm{improved}$，如果 $\\kappa_2(\\Theta(\\mathbf{z}))  \\kappa_2(\\Theta(\\mathbf{x}))$，则将其设置为 $\\mathrm{True}$，否则设置为 $\\mathrm{False}$。\n\n对四个测试用例中的每一个都重复此完整过程。收集每个用例的结果——$\\kappa_2(\\Theta(\\mathbf{x}))$、$\\kappa_2(\\Theta(\\mathbf{z}))$ 和 $\\mathrm{improved}$——并按要求格式化为单个输出字符串。\n\n这种缩放的基本原理是减轻因库矩阵各列量级上的巨大差异而引起的病态。例如，在情况 A ($[0, 10^{-3}]$) 和 C ($[0, 10^{-6}]$) 中，第一列 ($x$) 的值很小，而第二列 ($x^2$) 的值要小几个数量级。这种尺度上的差异通常会导致非常大的条件数。通过缩放数据使得 $\\operatorname{std}(\\mathbf{z})=1$，我们将状态变量置于一个“自然”单位系统中。这倾向于平衡最终库矩阵各列（例如 $\\mathbf{z}$ 和 $\\mathbf{z}^2$）的范数，从而降低条件数。对于所有测试用例，包括那些具有中心化数据的用例（情况 B 和 D），预期这种缩放会改善条件，从而得到 $\\mathrm{improved} = \\mathrm{True}$。该实现将使用 `numpy`进行所有数值计算，利用其双精度浮点数运算和优化的线性代数例程。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    \"\"\"\n    Computes and compares condition numbers of SINDy library matrices\n    before and after feature scaling for four test cases.\n    \"\"\"\n\n    def get_condition_number(data_vector: np.ndarray) -> float:\n        \"\"\"\n        Constructs a library matrix from a data vector and computes its 2-norm\n        condition number using SVD.\n        \n        Args:\n            data_vector: A 1D numpy array of state variable samples.\n\n        Returns:\n            The condition number of the library matrix. Returns np.inf if the\n            matrix is singular.\n        \"\"\"\n        # Problem constraints ensure data_vector.size >= 2\n        \n        # Construct the library matrix from columns [v, v^2]\n        library_matrix = np.stack([data_vector, data_vector**2], axis=1)\n        \n        # Calculate singular values. SVD returns them in descending order.\n        singular_values = np.linalg.svd(library_matrix, compute_uv=False)\n        \n        sigma_max = singular_values[0]\n        # For an N x 2 matrix, there are 2 singular values.\n        sigma_min = singular_values[1]\n        \n        # Per problem spec, if sigma_min is numerically 0, kappa is +inf.\n        # We use a small epsilon for a robust floating-point comparison.\n        if sigma_min  np.finfo(np.float64).eps:\n            return np.inf\n        \n        return sigma_max / sigma_min\n\n    # Test cases defined in the problem statement\n    test_cases = [\n        # (a, b, N)\n        (0.0, 1e-3, 100),       # Case A\n        (-1e-3, 1e-3, 100),    # Case B\n        (0.0, 1e-6, 50),       # Case C\n        (-0.5, 0.5, 200),      # Case D\n    ]\n\n    all_results = []\n    for a, b, N in test_cases:\n        # Generate N equally spaced samples in [a, b] using double precision\n        x = np.linspace(a, b, N, dtype=np.float64)\n\n        # Calculate condition number for the unscaled (raw) library matrix\n        kappa_x = get_condition_number(x)\n\n        # Calculate the population standard deviation of x.\n        # numpy.std defaults to ddof=0, which corresponds to the denominator N.\n        std_x = np.std(x)\n\n        kappa_z = np.inf\n        # Scale the data only if it has a non-zero standard deviation.\n        # This avoids division by zero if all samples are identical (a=b).\n        if std_x > np.finfo(np.float64).eps:\n            s = 1.0 / std_x\n            z = s * x\n            # Calculate condition number for the scaled library matrix\n            kappa_z = get_condition_number(z)\n\n        # Determine if scaling improved the condition number\n        improved = kappa_z  kappa_x\n\n        # Append formatted results for this case to the list\n        all_results.append(f\"{kappa_x:.6f}\")\n        all_results.append(f\"{kappa_z:.6f}\")\n        all_results.append(str(improved))\n\n    # Print the final output in the specified single-line format\n    print(f\"[{','.join(all_results)}]\")\n\nsolve()\n```", "id": "3349468"}, {"introduction": "一个被正确辨识的模型只有在数据提供充分信息时才可能实现。最后的这个练习将从算法实现转向一个关键的概念性问题：模型可辨识性（model identifiability）。你将探索一个场景，其中两个结构完全不同的模型在一个受限的实验方案下无法被区分，这种现象被称为观测等价性（observational equivalence）。[@problem_id:3349463]本练习旨在让你理解实验设计如何直接影响我们揭示真实内在动力学的能力。", "problem": "考虑一个单一测量的分子种类，其浓度用 $y(t)$ 表示，受外部诱导剂输入 $u(t)$ 的影响，其中 $t$ 是以秒为单位的时间。假设其动力学由确定性常微分方程 (ODE) 控制，该方程源于净生成减去降解，这是化学动力学和基因调控中的一个标准假设：$y$ 的变化率等于生成项之和减去降解项之和。在非线性动力学的稀疏辨識 (SINDy) 框架下，$f(y,u)$ 的候选函数库包含低阶多项式和交互项的稀疏组合。如果两个模型的支撑集（具有非零系数的活动库项的集合）不同，则它们是非同构的。\n\n你必须构建并分析两个稀疏模型，每个模型都使用相同的候选函数库表示为关于 $y(t)$ 的 ODE，但具有不同的支撑集，并证明它们在指定的实验方案下是观测等效的。然后，你必须模拟对该方案提出的更改，以打破观测等效性。观测等效性意味着模型 A 和 B 的测量轨迹 $y_A(t)$ 和 $y_B(t)$ 在实验窗口内、在指定的容差范围内是无法区分的。\n\n使用以下数学上指定的设置：\n\n- 候选库 $\\Theta(y,u)$ 包含项 $\\{y, y^3, u, y\\,u\\}$。\n- 定义模型 A，其稀疏右手边为\n$$\\frac{dy}{dt} = -\\delta\\,y + \\alpha\\,u + \\beta\\,y^3,$$\n以及模型 B，其稀疏右手边为\n$$\\frac{dy}{dt} = -\\delta\\,y + \\alpha\\,u + \\gamma\\,y\\,u.$$\n- 参数固定为 $ \\delta = 0.5 $ (每秒), $ \\alpha = 1.0 $ (任意单位每秒), $ \\beta = 0.1 $ (每秒每$(\\text{任意单位})^2$), 以及 $ \\gamma = 0.2 $ (每秒)。输入 $u(t)$ 是无量纲的。浓度 $y$ 的单位是任意单位 (a.u.)。时间单位是秒。对于正弦输入，角频率 $ \\omega $ 必须以弧度每秒为单位指定。\n- 实验方案 $\\mathcal{P}_0$ (基线等效性): $y(0)=0$ 且对于所有 $t \\in [0,T]$，$u(t)=0$，其中 $T=10$ 秒。\n- 定义观测等效性容差 $ \\varepsilon = 10^{-12} $ (单位 a.u.)。\n\n你的任务是编写一个完整的、可运行的程序，在以下五个方案（测试套件）下对两个模型进行数值模拟，计算时间窗口内轨迹 $y_A(t)$ 和 $y_B(t)$ 之间的均方根误差 (RMSE)，并汇总结果：\n\n1. 方案 $\\mathcal{P}_0$: $y(0)=0$，$u(t)=0$，$t \\in [0, T]$，其中 $T=10$ 秒。输出一个布尔值，指示 RMSE 是否小于或等于 $ \\varepsilon $ (即观测等效性成立)。\n2. 方案 $\\mathcal{P}_1$: $y(0)=10^{-3}$，$u(t)=0$，$t \\in [0, T]$，其中 $T=10$ 秒。以浮点数形式输出 RMSE (单位 a.u.)。\n3. 方案 $\\mathcal{P}_2$: $y(0)=0$，$u(t)=10^{-3}$ (常数)，$t \\in [0, T]$，其中 $T=10$ 秒。以浮点数形式输出 RMSE (单位 a.u.)。\n4. 方案 $\\mathcal{P}_3$: $y(0)=0.5$，$u(t)=0$，$t \\in [0, T]$，其中 $T=10$ 秒。以浮点数形式输出 RMSE (单位 a.u.)。\n5. 方案 $\\mathcal{P}_4$: $y(0)=0.1$，$u(t)=\\sin(\\omega t)$，其中 $ \\omega = 1 $ 弧度/秒，$t \\in [0, T]$，其中 $T=10$ 秒。以浮点数形式输出 RMSE (单位 a.u.)。\n\n数值模拟要求：\n- 在 $[0, T]$ 上一个包含 $N=1001$ 个点的均匀时间网格上求解每个初值问题。\n- 使用适用于光滑右手边的高精度 ODE 积分器。\n- 使用以下公式计算 RMSE\n$$\\mathrm{RMSE} = \\sqrt{\\frac{1}{N}\\sum_{k=1}^{N}\\left(y_A(t_k) - y_B(t_k)\\right)^2},$$\n以 a.u. 表示。\n\n最终输出格式：\n- 你的程序应生成一行输出，其中包含一个用方括号括起来的逗号分隔列表，按上述五个方案的确切顺序列出结果，第一个元素为布尔值，其余四个为浮点数 (例如, $[ \\text{True}, 0.00123, 0.0456, 0.78, 0.12 ]$)。所有数值输出中，基于 $y$ 的量的单位必须是任意单位 (a.u.)，时间单位是秒。正弦输入使用弧度每秒作为 $ \\omega $ 的单位。", "solution": "此问题是有效的。它具有科学依据，设定良好，客观，并为计算系统生物学中的一个数值实验提供了完整且一致的设置。任务是分析两个不同的非线性动力学模型在各种实验方案下的观测等效性，这是系统辨识和模型验证中的一个核心概念。\n\n解决方案首先分析观测等效性的条件，然后通过数值模拟来量化模型在旨在打破这种等效性的方案下的差异。\n\n正在考虑的系统是浓度为 $y(t)$ 的单一分子种类，受外部输入 $u(t)$ 的影响。其动力学由形式为 $\\frac{dy}{dt} = f(y, u)$ 的常微分方程 (ODE) 描述。\n\n提出的两个模型，模型 A 和模型 B，是从非线性动力学的稀疏辨識 (SINDy) 框架下的候选库 $\\Theta(y,u) = \\{y, y^3, u, y\\,u\\}$ 推导出来的。它们的控制方程是：\n- **模型 A**:\n$$\n\\frac{dy_A}{dt} = -\\delta\\,y_A + \\alpha\\,u + \\beta\\,y_A^3\n$$\n- **模型 B**:\n$$\n\\frac{dy_B}{dt} = -\\delta\\,y_B + \\alpha\\,u + \\gamma\\,y_B\\,u\n$$\n\n这些模型共享线性项 ($-\\delta y$ 和 $\\alpha u$)，但在非线性项上有所不同：模型 A 具有一个立方自相互作用项 ($\\beta y_A^3$)，而模型 B 有一个与输入相关的双线性相互作用项 ($\\gamma y_B u$)。参数给定为 $\\delta = 0.5\\,\\text{s}^{-1}$，$\\alpha = 1.0\\,\\text{a.u.}\\cdot\\text{s}^{-1}$，$\\beta = 0.1\\,\\text{s}^{-1}\\cdot\\text{a.u.}^{-2}$，以及 $\\gamma = 0.2\\,\\text{s}^{-1}$。\n\n问题的核心是研究五个实验方案 ($\\mathcal{P}_0$ 到 $\\mathcal{P}_4$)，并确定所得轨迹 $y_A(t)$ 和 $y_B(t)$ 是否观测等效。\n\n**方案 $\\mathcal{P}_0$: 基线等效性**\n此方案指定初始条件 $y(0) = 0$ 和在所有时间 $t \\in [0, T]$ (其中 $T=10$ 秒) 内的零输入 $u(t) = 0$。\n对于模型 A，ODE 变为：\n$$\n\\frac{dy_A}{dt} = -\\delta\\,y_A + \\alpha(0) + \\beta\\,y_A^3 = -0.5\\,y_A + 0.1\\,y_A^3\n$$\n在初始条件 $y_A(0) = 0$ 下，显然 $y_A(t) = 0$ 是一个不动点。由于右手边是局部利普希茨的，此初值问题的解是唯一的。因此，对于所有 $t \\geq 0$，$y_A(t) = 0$。\n对于模型 B，ODE 变为：\n$$\n\\frac{dy_B}{dt} = -\\delta\\,y_B + \\alpha(0) + \\gamma\\,y_B(0) = -0.5\\,y_B\n$$\n在初始条件 $y_B(0) = 0$ 下，唯一解同样是对于所有 $t \\geq 0$，$y_B(t) = 0$。\n由于在整个时间过程中 $y_A(t) = y_B(t) = 0$，均方根误差 (RMSE) 为：\n$$\n\\mathrm{RMSE} = \\sqrt{\\frac{1}{N}\\sum_{k=1}^{N}\\left(0 - 0\\right)^2} = 0\n$$\n该值小于指定的容差 $\\varepsilon = 10^{-12}$，因此在方案 $\\mathcal{P}_0$ 下，模型是观测等效的。这展示了系统辨识中的一个关键挑战：不够丰富的实验方案可能无法区分结构上不同的模型。\n\n**方案 $\\mathcal{P}_1$ - $\\mathcal{P}_4$: 打破等效性**\n这些方案旨在激活不同的非线性项，从而打破等效性。需要采用数值方法来求解非线性 ODE，并量化它们轨迹之间的差异。\n\n数值模拟将使用高精度方法执行。`scipy.integrate.solve_ivp` 函数实现了诸如 5(4) 阶显式龙格-库塔方法 (`RK45`) 等方法，非常适合这些光滑、非刚性的 ODE。我们将在从 $t=0$ 到 $t=10$ 秒的包含 $N=1001$ 个点的均匀时间网格上求解每个初值问题。\n\n- **对于方案 $\\mathcal{P}_1$ ($y(0)=10^{-3}, u(t)=0$):** 输入 $u(t)$ 为零，因此 ODE 简化为 $\\frac{dy_A}{dt} = -0.5\\,y_A + 0.1\\,y_A^3$ 和 $\\frac{dy_B}{dt} = -0.5\\,y_B$。模型 A 中存在而在模型 B 中不存在的 $\\beta y_A^3$ 项将导致它们的轨迹从共同的非零初始条件开始发散。\n- **对于方案 $\\mathcal{P}_2$ ($y(0)=0, u(t)=10^{-3}$):** 两个模型都由常数输入 $u(t) = 10^{-3}$ 驱动。在 $t=0$ 时，两个 $\\frac{dy}{dt}$ 都等于 $\\alpha u = 1.0 \\times 10^{-3}$。然而，随着 $y(t)$ 变为非零，非线性项 $\\beta y_A^3$ 和 $\\gamma y_B u$ 将被激活。由于 $u$ 是常数，模型 B 中的项 ($\\gamma y_B u$) 将随 $y_B$ 线性增长，而模型 A 中的项 ($\\beta y_A^3$) 将随 $y_A$ 立方增长。这种函数形式的差异将导致轨迹发散。\n- **对于方案 $\\mathcal{P}_3$ ($y(0)=0.5, u(t)=0$):** 这与 $\\mathcal{P}_1$ 类似，但初始条件大得多。立方项 $\\beta y_A^3$ 的贡献对 $y_A$ 的大小高度敏感。更大的 $y_A(0)$ 将导致该项产生更大的初始效应，从而导致比 $\\mathcal{P}_1$ 大得多的 RMSE。\n- **对于方案 $\\mathcal{P}_4$ ($y(0)=0.1, u(t)=\\sin(\\omega t)$，其中 $\\omega=1$):** 该方案涉及非零初始条件和时变输入。两个不同的非线性项 $\\beta y_A^3$ 和 $\\gamma y_B u$ 都将被激活并随时间变化。正弦输入提供了一个丰富的激励信号，将持续探测两个模型的不同动态响应，从而揭示出显著的差异。\n\n接下来的程序实现了这一策略。它为两个模型 ODE 的右手边定义了函数。然后，它按顺序执行五个方案中的每一个，为每个模型调用 `solve_ivp`，计算所得轨迹 $y_A(t_k)$ 和 $y_B(t_k)$ 之间的 RMSE，并按规定格式化结果。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.integrate import solve_ivp\n\ndef solve():\n    \"\"\"\n    Simulates two SINDy-identified models under five experimental protocols\n    to test for observational equivalence and computes the RMSE between their\n    trajectories.\n    \"\"\"\n\n    # Define model parameters\n    delta = 0.5  # Degradation rate (per second)\n    alpha = 1.0  # Input-driven production rate (a.u. per second)\n    beta = 0.1   # Cubic self-interaction rate (per second per a.u.^2)\n    gamma = 0.2  # Bilinear interaction rate (per second)\n\n    # General simulation settings\n    sim_time = 10.0  # Total simulation time in seconds\n    num_points = 1001  # Number of points in the time grid\n    equivalence_tolerance = 1e-12  # Tolerance for observational equivalence\n\n    # Define the right-hand side (RHS) of the ODE for Model A\n    def model_A_rhs(t, y, u_func):\n        \"\"\"RHS for dy/dt = -delta*y + alpha*u + beta*y^3.\"\"\"\n        y_val = y[0]\n        u_val = u_func(t)\n        return [-delta * y_val + alpha * u_val + beta * y_val**3]\n\n    # Define the RHS of the ODE for Model B\n    def model_B_rhs(t, y, u_func):\n        \"\"\"RHS for dy/dt = -delta*y + alpha*u + gamma*y*u.\"\"\"\n        y_val = y[0]\n        u_val = u_func(t)\n        return [-delta * y_val + alpha * u_val + gamma * y_val * u_val]\n\n    # Define the five experimental protocols (test suite)\n    protocols = [\n        {'id': 'P0', 'y0': [0.0], 'u_func': lambda t: 0.0},\n        {'id': 'P1', 'y0': [1e-3], 'u_func': lambda t: 0.0},\n        {'id': 'P2', 'y0': [0.0], 'u_func': lambda t: 1e-3},\n        {'id': 'P3', 'y0': [0.5], 'u_func': lambda t: 0.0},\n        {'id': 'P4', 'y0': [0.1], 'u_func': lambda t: np.sin(1.0 * t)},\n    ]\n\n    results = []\n    \n    # Common time span and evaluation points for all protocols\n    t_span = [0, sim_time]\n    t_eval = np.linspace(0, sim_time, num_points)\n\n    # High-accuracy solver options\n    solver_options = {'method': 'RK45', 'rtol': 1e-8, 'atol': 1e-8}\n\n    for i, p in enumerate(protocols):\n        y0 = p['y0']\n        u_func = p['u_func']\n\n        # Solve for Model A\n        sol_A = solve_ivp(\n            model_A_rhs, t_span, y0, args=(u_func,), t_eval=t_eval, **solver_options\n        )\n        # Flatten the output array for 1D analysis\n        y_A = sol_A.y.flatten()\n\n        # Solve for Model B\n        sol_B = solve_ivp(\n            model_B_rhs, t_span, y0, args=(u_func,), t_eval=t_eval, **solver_options\n        )\n        # Flatten the output array for 1D analysis\n        y_B = sol_B.y.flatten()\n\n        # Ensure solvers were successful and returned arrays of expected shape\n        if y_A.shape[0] != num_points or y_B.shape[0] != num_points:\n            raise RuntimeError(f\"ODE solver failed for protocol {p['id']}.\")\n\n        # Compute Root-Mean-Square Error (RMSE)\n        rmse = np.sqrt(np.mean((y_A - y_B)**2))\n\n        # For the first protocol, check for observational equivalence\n        if i == 0:\n            results.append(rmse = equivalence_tolerance)\n        else:\n            results.append(rmse)\n\n    # Format the results into the required single-line string output\n    formatted_results = []\n    for r in results:\n        if isinstance(r, bool):\n            formatted_results.append(str(r))\n        else:\n            # Format floats to a reasonable precision for output consistency\n            formatted_results.append(f\"{r:.15g}\")\n\n    print(f\"[{','.join(formatted_results)}]\")\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3349463"}]}