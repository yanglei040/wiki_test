{"hands_on_practices": [{"introduction": "在分析随机轨迹时，尤其是在进行参数推断时，理解路径似然是至关重要的第一步。本练习 [@problem_id:3303233] 提供了直接的实践机会，让你为给定的连续时间马尔可夫链 (CTMC) 轨迹计算该似然的一个关键组成部分——积分风险率。掌握这一计算是构建更复杂统计模型的基础。", "problem": "在计算系统生物学中，一个生化反应网络的随机动力学可以被建模为一个连续时间马尔可夫链 (CTMC)，其中系统状态 $X_t \\in \\mathbb{N}$ 是分段常数，并在随机时间通过跳跃发生改变。瞬时总事件率（也称为风险率或强度）$\\lambda(X_t;\\theta)$ 决定了等待时间和跳跃事件的分布。考虑一个包含三种反应的单物种网络：组成性合成、一阶衰变和双分子湮灭。总风险率建模为\n$$\n\\lambda(x;\\theta) \\;=\\; \\theta_1 \\;+\\; \\theta_2\\, x \\;+\\; \\theta_3 \\binom{x}{2},\n$$\n其中 $\\theta = (\\theta_1,\\theta_2,\\theta_3)$ 是待从观测轨迹中估计的未知参数，且 $\\binom{x}{2} = \\frac{x(x-1)}{2}$。\n\n在区间 $[0,T]$ (其中 $T = 6.0$) 上观测到一条已实现的跳跃轨迹，其跳跃时间为 $t_0 = 0$、$t_1 = 0.5$、$t_2 = 1.1$、$t_3 = 2.0$、$t_4 = 4.0$ 和 $t_5 = 6.0$，其分段常数状态 $X_s = x_k$ (对于 $s \\in [t_k, t_{k+1})$) 由下式给出\n$$\nx_0 = 3,\\quad x_1 = 4,\\quad x_2 = 2,\\quad x_3 = 2,\\quad x_4 = 5.\n$$\n\n从时间非齐次跳跃过程的生存函数的基本定义以及积分风险率 $\\int_0^T \\lambda(X_s;\\theta)\\,ds$ 在路径分布中的作用出发，推导在 $X_s$ 沿轨迹的分段常数性质下，该积分如何简化。然后，对给定轨迹实现此简化，并将结果表达式简化为关于 $\\theta_1$、$\\theta_2$ 和 $\\theta_3$ 的单个闭式解析表达式。\n\n你的最终答案必须是单个解析表达式。无需四舍五入，也不涉及物理单位。", "solution": "我们从通过风险（强度）函数标准地构造连续时间马尔可夫链 (CTMC) 路径分布开始。对于一个瞬时总速率为 $\\lambda(X_t;\\theta)$ 的时间非齐次跳跃过程，在 $[0,t]$ 区间内没有事件发生的概率（以 $X_s$ 在 $s \\in [0,t]$ 的轨迹为条件）是\n$$\n\\Pr(\\text{no jump in }[0,t] \\mid \\{X_s\\}_{s \\in [0,t]}) \\;=\\; \\exp\\!\\left(-\\int_0^t \\lambda(X_s;\\theta)\\,ds\\right).\n$$\n该公式源于非齐次泊松过程 (NHPP) 的生存函数的基本定义，并通过 CTMC 框架推广到状态依赖的强度。因此，积分 $\\int_0^T \\lambda(X_s;\\theta)\\,ds$ 是进入路径似然的积分风险率。\n\n在可数状态空间上的 CTMC 中，样本路径是分段常数的，并在孤立的时间点发生跳跃。设跳跃时间为 $0 = t_0  t_1  \\dots  t_m  t_{m+1} = T$，且状态在跳跃之间是恒定的：$X_s = x_k$ 对于 $s \\in [t_k, t_{k+1}), k = 0,\\dots,m$。在此分段常数性质下，被积函数 $\\lambda(X_s;\\theta)$ 在每个区间 $[t_k, t_{k+1})$ 上是常数，等于 $\\lambda(x_k;\\theta)$。因此，积分可以分解为各区间的总和：\n$$\n\\int_0^T \\lambda(X_s;\\theta)\\,ds\n\\;=\\; \\sum_{k=0}^{m} \\int_{t_k}^{t_{k+1}} \\lambda(x_k;\\theta)\\,ds\n\\;=\\; \\sum_{k=0}^{m} \\lambda(x_k;\\theta)\\,(t_{k+1}-t_k).\n$$\n这种简化是阶梯函数黎曼积分基本性质的直接结果。\n\n我们现在对给定轨迹实现此简化。该轨迹由 $t_0 = 0$、$t_1 = 0.5$、$t_2 = 1.1$、$t_3 = 2.0$、$t_4 = 4.0$、$t_5 = 6.0$ 和 $x_0 = 3$、$x_1 = 4$、$x_2 = 2$、$x_3 = 2$、$x_4 = 5$ 指定。共有 $m = 4$ 次跳跃和 $m+1 = 5$ 个区间。各区间的时长为\n$$\n\\Delta_0 = t_1 - t_0 = 0.5,\\quad\n\\Delta_1 = t_2 - t_1 = 0.6,\\quad\n\\Delta_2 = t_3 - t_2 = 0.9,\\quad\n\\Delta_3 = t_4 - t_3 = 2.0,\\quad\n\\Delta_4 = t_5 - t_4 = 2.0,\n$$\n它们的总和为 $T = 6.0$，作为一致性检验。\n\n总风险率为\n$$\n\\lambda(x;\\theta) \\;=\\; \\theta_1 \\;+\\; \\theta_2\\, x \\;+\\; \\theta_3 \\binom{x}{2}\n\\;=\\; \\theta_1 \\;+\\; \\theta_2\\, x \\;+\\; \\theta_3 \\,\\frac{x(x-1)}{2}.\n$$\n我们对每个 $x_k$ 计算 $\\lambda(x_k;\\theta)$：\n- 对于 $x_0 = 3$，\n$$\n\\lambda(3;\\theta) \\;=\\; \\theta_1 \\;+\\; 3\\theta_2 \\;+\\; \\theta_3 \\binom{3}{2}\n\\;=\\; \\theta_1 \\;+\\; 3\\theta_2 \\;+\\; 3\\theta_3.\n$$\n- 对于 $x_1 = 4$，\n$$\n\\lambda(4;\\theta) \\;=\\; \\theta_1 \\;+\\; 4\\theta_2 \\;+\\; \\theta_3 \\binom{4}{2}\n\\;=\\; \\theta_1 \\;+\\; 4\\theta_2 \\;+\\; 6\\theta_3.\n$$\n- 对于 $x_2 = 2$，\n$$\n\\lambda(2;\\theta) \\;=\\; \\theta_1 \\;+\\; 2\\theta_2 \\;+\\; \\theta_3 \\binom{2}{2}\n\\;=\\; \\theta_1 \\;+\\; 2\\theta_2 \\;+\\; \\theta_3.\n$$\n- 对于 $x_3 = 2$，\n$$\n\\lambda(2;\\theta) \\;=\\; \\theta_1 \\;+\\; 2\\theta_2 \\;+\\; \\theta_3.\n$$\n- 对于 $x_4 = 5$，\n$$\n\\lambda(5;\\theta) \\;=\\; \\theta_1 \\;+\\; 5\\theta_2 \\;+\\; \\theta_3 \\binom{5}{2}\n\\;=\\; \\theta_1 \\;+\\; 5\\theta_2 \\;+\\; 10\\theta_3.\n$$\n\n将其乘以对应的时长并求和，得到积分风险率：\n$$\n\\int_0^{6.0} \\lambda(X_s;\\theta)\\,ds\n\\;=\\; 0.5\\big(\\theta_1 + 3\\theta_2 + 3\\theta_3\\big)\n\\;+\\; 0.6\\big(\\theta_1 + 4\\theta_2 + 6\\theta_3\\big)\n\\;+\\; 0.9\\big(\\theta_1 + 2\\theta_2 + \\theta_3\\big)\n\\;+\\; 2.0\\big(\\theta_1 + 2\\theta_2 + \\theta_3\\big)\n\\;+\\; 2.0\\big(\\theta_1 + 5\\theta_2 + 10\\theta_3\\big).\n$$\n我们按参数合并各项：\n- $\\theta_1$ 的系数：\n$$\n0.5 + 0.6 + 0.9 + 2.0 + 2.0 \\;=\\; 6.0.\n$$\n- $\\theta_2$ 的系数：\n$$\n0.5\\cdot 3 + 0.6\\cdot 4 + 0.9\\cdot 2 + 2.0\\cdot 2 + 2.0\\cdot 5\n\\;=\\; 1.5 + 2.4 + 1.8 + 4.0 + 10.0 \\;=\\; 19.7 \\;=\\; \\frac{197}{10}.\n$$\n- $\\theta_3$ 的系数：\n$$\n0.5\\cdot 3 + 0.6\\cdot 6 + 0.9\\cdot 1 + 2.0\\cdot 1 + 2.0\\cdot 10\n\\;=\\; 1.5 + 3.6 + 0.9 + 2.0 + 20.0 \\;=\\; 28.0 \\;=\\; 28.\n$$\n\n因此，积分风险率简化为以下闭式表达式\n$$\n\\int_0^{6.0} \\lambda(X_s;\\theta)\\,ds \\;=\\; 6\\,\\theta_1 \\;+\\; \\frac{197}{10}\\,\\theta_2 \\;+\\; 28\\,\\theta_3.\n$$\n该表达式通过将在分段常数状态下评估的风险率按区间时长进行加权求和，从而实现了积分项，这正是对 CTMC 中随机轨迹进行分布分析所要求的。", "answer": "$$\\boxed{6\\theta_1+\\frac{197}{10}\\theta_2+28\\theta_3}$$", "id": "3303233"}, {"introduction": "在许多实际情况中，我们无法观测到完整、连续的微观轨迹。本练习 [@problem_id:3303225] 应对了这一更贴近现实的场景，即如何从离散时间的观测数据中推断模型参数。你将实现期望最大化 (EM) 算法，这是一种处理随机模型中此类“缺失数据”问题的经典且强大的技术。", "problem": "考虑一个双态连续时间马尔可夫链（CTMC），它代表一个具有两个微观态（表示为状态 $0$ 和状态 $1$）的可逆单物种反应网络，其中的跃迁对应于反应事件 $0 \\to 1$ 和 $1 \\to 0$。无穷小生成元矩阵为 $Q(\\theta)$，其非对角线元素为 $q_{01} = \\theta_1$ 和 $q_{10} = \\theta_2$，对角线元素为 $q_{00} = -\\theta_1$ 和 $q_{11} = -\\theta_2$。参数向量为 $\\theta = (\\theta_1,\\theta_2)$，其中 $\\theta_1  0$ 且 $\\theta_2  0$。\n\n给定在时间点 $t_0, t_1, \\ldots, t_M$ 对该CTMC的离散时间、精确状态观测值，其形式为一系列状态 $x_0, x_1, \\ldots, x_M \\in \\{0,1\\}$。在观测时间点之间，CTMC的演化是未被观测的。假设时间是均匀的，并且所有时间都以相同的任意单位表示；所要求的输出是无量纲的数值。\n\n您的任务是实现期望最大化（EM）算法（Expectation-Maximization (EM)），通过在观测端点诱导的当前后验分布下，最大化未观测到的反应计数和停留时间的期望完全数据对数似然，来估计 $\\theta$。您可以引用的基本依据是：\n- 连续时间马尔可夫链的定义、其马尔可夫性质以及无穷小生成元矩阵 $Q(\\theta)$。\n- Kolmogorov 前向方程及其解，即时间 $t$ 的跃迁概率矩阵 $P(t) = \\exp(Q(\\theta) t)$。\n- CTMC轨迹的完全数据似然（用反应计数和停留时间表示），以及充分统计量是各类跃迁的总次数和在每个状态中停留的总时间这一事实。\n\n您的程序必须：\n- 从上述基本依据推导出EM算法的更新步骤。在E步中，计算在每个区间 $[t_k, t_{k+1}]$ 上以观测到的端点为条件的充分统计量的后验期望（即跃迁 $0 \\to 1$ 和 $1 \\to 0$ 的期望次数，以及在状态 $0$ 和 $1$ 中的期望总停留时间），需使用马尔可夫性质和跃迁概率 $P(t) = \\exp(Q(\\theta) t)$。在必要时，通过对未观测到的中间时间进行积分，使用数值稳定且可靠的计算方法来计算这些期望值。\n- 在M步中，相对于 $\\theta$ 最大化期望完全数据对数似然，确保 $\\theta_1  0$ 且 $\\theta_2  0$。\n\n实现EM算法，并设置收敛容差和最大迭代次数。在需要时使用数值积分来评估E步中隐含的任何期望值。解决方案必须是确定性的，并且不得依赖于随机化。\n\n测试套件。在以下三个测试用例上运行您的实现。每个测试用例包含一个观测时间列表和一个观测状态列表：\n- 测试用例1：时间 $[0.0, 0.5, 1.0, 1.5, 2.0]$，状态 $[0, 1, 0, 1, 0]$。\n- 测试用例2：时间 $[0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0]$，状态 $[0, 0, 0, 0, 0, 0, 0, 0, 0]$。\n- 测试用例3：时间 $[0.0, 1.0, 2.5, 5.0, 9.0]$，状态 $[1, 1, 0, 0, 1]$。\n\n算法配置。对于每个测试用例，使用 $\\theta^{(0)} = (1.0, 1.0)$ 进行初始化，最大迭代次数为 $50$，参数收敛的相对容差为 $10^{-8}$。\n\n输出规范。对于每个测试用例，在收敛（或达到迭代上限）后，按顺序输出估计的 $\\theta_1$ 和 $\\theta_2$。您的程序应生成单行输出，其中包含所有测试用例的结果，按顺序连接成一个逗号分隔的浮点数列表，四舍五入到 $6$ 位小数，并用方括号括起来。例如，输出格式必须为 $[\\theta_{1}^{(1)},\\theta_{2}^{(1)},\\theta_{1}^{(2)},\\theta_{2}^{(2)},\\theta_{1}^{(3)},\\theta_{2}^{(3)}]$，其中上标表示测试用例的索引。输出中不要包含物理单位。", "solution": "EM算法是一种迭代过程，用于在具有未观测（隐藏）数据的统计模型中寻找参数的最大似然估计。在此背景下，完全数据是两次观测之间CTMC的完整微观路径，而观测数据仅为特定时间点的状态。\n\n### 1. 完全数据对数似然\n\n如果在总观测时间 $T$ 内，CTMC的完整轨迹是已知的，那么估计 $\\theta$ 的充分统计量将是：\n- $N_{01}$：从状态 $0$ 到状态 $1$ 的总跃迁次数。\n- $N_{10}$：从状态 $1$ 到状态 $0$ 的总跃迁次数。\n- $T_0$：过程在状态 $0$ 中停留的总时间。\n- $T_1$：过程在状态 $1$ 中停留的总时间。\n\n完全数据似然函数 $L(\\theta)$ 由观测事件（跳跃和停留）的概率乘积给出：\n$$ L(\\theta | \\text{complete data}) = (\\theta_1^{N_{01}} e^{-\\theta_1 T_0}) \\cdot (\\theta_2^{N_{10}} e^{-\\theta_2 T_1}) $$\n对应的对数似然是：\n$$ \\log L(\\theta) = N_{01} \\log \\theta_1 - \\theta_1 T_0 + N_{10} \\log \\theta_2 - \\theta_2 T_1 $$\n\n### 2. 期望最大化（EM）算法\n\nEM算法包含两个步骤，重复进行直到收敛。\n\n**M步（最大化）：**\n在M步中，我们最大化*期望*完全数据对数似然，其中期望是针对隐藏数据的分布计算的，该分布以观测数据和当前参数估计 $\\theta^{(p)}$ 为条件。令 $\\mathbb{E}[\\cdot]$ 表示此条件期望。\n$$ Q(\\theta | \\theta^{(p)}) = \\mathbb{E}[N_{01}] \\log \\theta_1 - \\theta_1 \\mathbb{E}[T_0] + \\mathbb{E}[N_{10}] \\log \\theta_2 - \\theta_2 \\mathbb{E}[T_1] $$\n为了最大化 $Q(\\theta|\\theta^{(p)})$，我们对 $\\theta_1$ 和 $\\theta_2$ 求偏导数并将其设为零：\n$$ \\frac{\\partial Q}{\\partial \\theta_1} = \\frac{\\mathbb{E}[N_{01}]}{\\theta_1} - \\mathbb{E}[T_0] = 0 \\implies \\theta_1^{(p+1)} = \\frac{\\mathbb{E}[N_{01}]}{\\mathbb{E}[T_0]} $$\n$$ \\frac{\\partial Q}{\\partial \\theta_2} = \\frac{\\mathbb{E}[N_{10}]}{\\theta_2} - \\mathbb{E}[T_1] = 0 \\implies \\theta_2^{(p+1)} = \\frac{\\mathbb{E}[N_{10}]}{\\mathbb{E}[T_1]} $$\n这些是参数的直观更新规则。\n\n**E步（期望）：**\n问题的核心在于E步：计算充分统计量的条件期望。根据马尔可夫性质，这些期望可以对所有观测区间 $[t_k, t_{k+1}]$ 进行求和。对于每个持续时间为 $\\Delta t = t_{k+1} - t_k$、起始状态为 $i=x_k$、结束状态为 $j=x_{k+1}$ 的区间，我们需要计算：\n1.  $\\mathbb{E}[T_k | X(0)=i, X(\\Delta t)=j]$：在状态 $k \\in \\{0, 1\\}$ 中的期望停留时间。\n2.  $\\mathbb{E}[N_{lm} | X(0)=i, X(\\Delta t)=j]$：从状态 $l$到 $m$ 的期望跃迁次数。\n\n这些期望可以从跃迁概率矩阵 $P(t) = \\exp(Qt)$ 推导得出。$Q$ 的特征值为 $\\lambda_1=0$ 和 $\\lambda_2=-(\\theta_1+\\theta_2)$。令 $\\lambda = \\theta_1+\\theta_2$。平稳分布为 $\\pi = (\\pi_0, \\pi_1) = (\\frac{\\theta_2}{\\lambda}, \\frac{\\theta_1}{\\lambda})$。跃迁概率为：\n$$ P_{ab}(t) = \\pi_b + (\\delta_{ab} - \\pi_b)e^{-\\lambda t} $$\n其中 $\\delta_{ab}$ 是克罗内克（Kronecker）δ函数。\n\n条件期望由涉及对未观测时间进行积分的表达式给出。例如，在状态 $k$ 中的期望停留时间是：\n$$ \\mathbb{E}[T_k | \\dots] = \\frac{1}{P_{ij}(\\Delta t)} \\int_0^{\\Delta t} P_{ik}(s)P_{kj}(\\Delta t-s) ds $$\n从 $l$ 到 $m$ 的期望跃迁次数是：\n$$ \\mathbb{E}[N_{lm} | \\dots] = \\frac{q_{lm}}{P_{ij}(\\Delta t)} \\int_0^{\\Delta t} P_{il}(s)P_{mj}(\\Delta t-s) ds $$\n其中 $q_{01}=\\theta_1$ 和 $q_{10}=\\theta_2$。\n\n虽然问题允许数值积分，但这些积分存在解析解。令 $C_{ij}^{lm}(\\Delta t) = \\int_0^{\\Delta t} P_{il}(s) P_{mj}(\\Delta t-s) ds$。解析解为：\n$$ C_{ij}^{lm}(\\Delta t) = \\Delta t \\left[ \\pi_l \\pi_j + (\\delta_{il}-\\pi_l)(\\delta_{mj}-\\pi_j)e^{-\\lambda\\Delta t} \\right] + \\frac{1-e^{-\\lambda\\Delta t}}{\\lambda} \\left[ \\pi_j\\delta_{il} + \\pi_l\\delta_{mj} - 2\\pi_l\\pi_j \\right] $$\n由此，单个区间所需的期望值为：\n$$ \\mathbb{E}[T_k | \\dots] = \\frac{C_{ij}^{kk}(\\Delta t)}{P_{ij}(\\Delta t)} $$\n$$ \\mathbb{E}[N_{lm} | \\dots] = q_{lm} \\frac{C_{ij}^{lm}(\\Delta t)}{P_{ij}(\\Delta t)} $$\n作为一致性检验，可以证明 $\\sum_k \\mathbb{E}[T_k | \\dots] = \\Delta t$。\n\n**算法实现摘要：**\n1.  初始化 $\\theta^{(0)} = (1.0, 1.0)$。\n2.  开始迭代 $p=0, 1, 2, \\dots$：\n    a. 将总期望统计量初始化为零：$\\mathbb{E}[N_{01}]_{\\text{tot}}$，$\\mathbb{E}[N_{10}]_{\\text{tot}}$，$\\mathbb{E}[T_0]_{\\text{tot}}$，$\\mathbb{E}[T_1]_{\\text{tot}}$。\n    b. 对于每个观测区间 $[t_k, t_{k+1}]$：\n        i. 设置 $\\Delta t = t_{k+1}-t_k$，$i=x_k$，$j=x_{k+1}$。\n        ii. 使用 $\\theta^{(p)}$，计算 $\\lambda$、$\\pi$ 和 $P_{ij}(\\Delta t)$。\n        iii. 对于每个所需的统计量（例如 $T_0$、$N_{01}$），计算相应的 $C_{ij}^{lm}(\\Delta t)$，然后计算条件期望。\n        iv. 将这些区间期望值累加到总和中。\n    c. 使用M步规则更新参数：\n       $\\theta_1^{(p+1)} = \\mathbb{E}[N_{01}]_{\\text{tot}} / \\mathbb{E}[T_0]_{\\text{tot}}$\n       $\\theta_2^{(p+1)} = \\mathbb{E}[N_{10}]_{\\text{tot}} / \\mathbb{E}[T_1]_{\\text{tot}}$\n    d. 检查收敛性：如果参数向量 $\\theta$ 的相对变化小于容差 $10^{-8}$，则终止。\n3.  输出最终收敛的参数 $\\theta_1$ 和 $\\theta_2$。\n该实现将使用数值稳定的计算方法，例如使用 `scipy.special.expm1` 来计算 $(e^x - 1)$，以在参数 $x$ 接近于零时保持精度。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.special import expm1\n\ndef em_ctmc(times, states, theta_init, max_iter, tol):\n    \"\"\"\n    Estimates the parameters of a two-state Continuous-Time Markov Chain\n    using the Expectation-Maximization (EM) algorithm from discrete observations.\n\n    Args:\n        times (np.ndarray): Array of observation times.\n        states (np.ndarray): Array of observed states (0 or 1).\n        theta_init (np.ndarray): Initial guess for parameters [theta1, theta2].\n        max_iter (int): Maximum number of EM iterations.\n        tol (float): Relative tolerance for convergence.\n\n    Returns:\n        np.ndarray: The estimated parameters [theta1, theta2].\n    \"\"\"\n    theta = np.copy(theta_init)\n\n    for _ in range(max_iter):\n        theta_old = np.copy(theta)\n        \n        total_E_N01 = 0.0\n        total_E_N10 = 0.0\n        total_E_T0 = 0.0\n        total_E_T1 = 0.0\n\n        theta1, theta2 = theta[0], theta[1]\n        \n        # Parameters must be positive definite\n        if theta1 = 0 or theta2 = 0:\n            break\n            \n        lmbda = theta1 + theta2\n        pi0 = theta2 / lmbda\n        pi1 = theta1 / lmbda\n        pi = np.array([pi0, pi1])\n\n        for k in range(len(times) - 1):\n            dt = times[k+1] - times[k]\n            if dt == 0:\n                continue\n\n            i = states[k]  # start_state\n            j = states[k+1] # end_state\n            \n            e_lambda_t = np.exp(-lmbda * dt)\n            \n            # Transition probability P_ij(dt)\n            p_ij = pi[j] + ((1 if i == j else 0) - pi[j]) * e_lambda_t\n            \n            if p_ij  1e-300: # Effectively zero, skip interval to avoid division by zero\n                continue\n            \n            # This function computes the integral C_{ij}^{lm}(dt) analytically.\n            def compute_C(i_s, j_s, l_s, m_s, dt_s, lmbda_s, pi_s, e_lambda_t_s):\n                delta_il = 1 if i_s == l_s else 0\n                delta_mj = 1 if j_s == m_s else 0\n                \n                term1 = dt_s * (pi_s[l_s] * pi_s[j_s] + (delta_il - pi_s[l_s]) * (delta_mj - pi_s[j_s]) * e_lambda_t_s)\n                \n                # Use expm1 for numerical stability for small lmbda*dt\n                x = -lmbda_s * dt_s\n                if abs(x)  1e-9:\n                    # For small x, (1-e^x)/(-x) approx 1, so (1-e^x)/lmbda approx dt\n                    term2_factor = dt_s\n                else:\n                    # (1 - e^x) / lmbda === -(e^x - 1) / lmbda\n                    term2_factor = -expm1(x) / lmbda_s\n                    \n                term2 = term2_factor * (pi_s[j_s] * delta_il + pi_s[l_s] * delta_mj - 2 * pi_s[l_s] * pi_s[j_s])\n                \n                return term1 + term2\n\n            # E-Step: Compute conditional expectations for the interval\n            # Expected sojourn time in state 0\n            C_ij_00 = compute_C(i, j, 0, 0, dt, lmbda, pi, e_lambda_t)\n            E_T0 = C_ij_00 / p_ij\n            \n            # Expected sojourn time in state 1 (by conservation)\n            E_T1 = dt - E_T0\n\n            # Expected number of transitions 0 -> 1\n            C_ij_01 = compute_C(i, j, 0, 1, dt, lmbda, pi, e_lambda_t)\n            E_N01 = theta1 * C_ij_01 / p_ij\n            \n            # Expected number of transitions 1 -> 0\n            C_ij_10 = compute_C(i, j, 1, 0, dt, lmbda, pi, e_lambda_t)\n            E_N10 = theta2 * C_ij_10 / p_ij\n\n            # Accumulate totals\n            total_E_T0 += E_T0\n            total_E_T1 += E_T1\n            total_E_N01 += E_N01\n            total_E_N10 += E_N10\n\n        # M-Step: Update parameters\n        if total_E_T0  0:\n            theta[0] = total_E_N01 / total_E_T0\n        \n        if total_E_T1  0:\n            theta[1] = total_E_N10 / total_E_T1\n\n        # Convergence check\n        norm_old = np.linalg.norm(theta_old)\n        if norm_old  0:\n            rel_change = np.linalg.norm(theta - theta_old) / norm_old\n            if rel_change  tol:\n                break\n    \n    return theta\n\ndef solve():\n    \"\"\"\n    Main function to run the algorithm on the defined test cases and print the results.\n    \"\"\"\n    # Define the test cases from the problem statement.\n    test_cases = [\n        (np.array([0.0, 0.5, 1.0, 1.5, 2.0]), np.array([0, 1, 0, 1, 0])),\n        (np.array([0.0, 0.25, 0.5, 0.75, 1.0, 1.25, 1.5, 1.75, 2.0]), np.array([0, 0, 0, 0, 0, 0, 0, 0, 0])),\n        (np.array([0.0, 1.0, 2.5, 5.0, 9.0]), np.array([1, 1, 0, 0, 1])),\n    ]\n\n    # Algorithm configuration\n    theta_init = np.array([1.0, 1.0])\n    max_iter = 50\n    tol = 1e-8\n    \n    results = []\n    for times, states in test_cases:\n        estimated_theta = em_ctmc(times, states, theta_init, max_iter, tol)\n        results.extend(estimated_theta)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(f'{x:.6f}' for x in results)}]\")\n\nsolve()\n```", "id": "3303225"}, {"introduction": "最后，我们将视野从离散状态的 CTMC 扩展到由随机微分方程 (SDE) 描述的连续状态模型。本练习 [@problem_id:3303212] 涉及模拟一个细胞信号传导模型，并分析一个关键的动态特征：在高活性状态下的驻留时间分布。这项实践展示了轨迹分析不仅可用于参数拟合，还可用于表征生物系统的定性行为和记忆特性。", "problem": "给定一个用于描述丝裂原活化蛋白激酶 (MAPK) 级联中单细胞细胞外信号调节激酶 (ERK) 活性的随机模型。活性水平由一维状态变量 $Y_t \\ge 0$ 表示，该变量受带有乘性噪声的分段线性随机微分方程 (SDE) 控制。动力学由以下 Itô SDE 定义：\n$$\ndY_t =\n\\begin{cases}\n\\left(a_{\\mathrm{lo}} - b_{\\mathrm{lo}} Y_t\\right)\\,dt + \\sigma_{\\mathrm{lo}}\\, Y_t\\, dW_t,  \\text{如果 } Y_t  \\theta, \\\\\n\\left(a_{\\mathrm{hi}} - b_{\\mathrm{hi}} Y_t\\right)\\,dt + \\sigma_{\\mathrm{hi}}\\, Y_t\\, dW_t,  \\text{如果 } Y_t \\ge \\theta,\n\\end{cases}\n$$\n其中 $W_t$ 是一个标准维纳过程，$a_{\\mathrm{lo}}, b_{\\mathrm{lo}}, \\sigma_{\\mathrm{lo}}, a_{\\mathrm{hi}}, b_{\\mathrm{hi}}, \\sigma_{\\mathrm{hi}}$ 是非负参数，$\\theta  0$ 是用于高 ERK 活性的固定分类阈值。乘性噪声项与 $Y_t$ 成正比。时间 $t$ 以秒为单位。\n\n高活性状态下的停留时间定义为向上穿过阈值 $Y_t = \\theta$ 与随后向下穿过并回到 $\\theta$ 以下之间的时间间隔。即，停留时间是 $Y_t \\ge \\theta$ 的连续区间的长度。假设在 $Y_t = 0$ 处有一个反射边界。\n\n您必须使用固定时间步长 $\\Delta t$ 的 Euler–Maruyama 方法对 $Y_t$ 进行数值模拟：\n$$\nY_{n+1} = \\max\\left\\{0,\\, Y_n + \\mu(Y_n)\\,\\Delta t + \\sigma(Y_n)\\, Y_n \\sqrt{\\Delta t}\\, \\xi_n \\right\\},\n$$\n其中 $Y_0 \\ge 0$，$\\xi_n \\sim \\mathcal{N}(0,1)$ 是独立的标准正态增量，以及分段的漂移和噪声振幅\n$$\n\\mu(y) = \\begin{cases}\na_{\\mathrm{lo}} - b_{\\mathrm{lo}} y,  y  \\theta,\\\\\na_{\\mathrm{hi}} - b_{\\mathrm{hi}} y,  y \\ge \\theta,\n\\end{cases}\n\\qquad\n\\sigma(y) = \\begin{cases}\n\\sigma_{\\mathrm{lo}},  y  \\theta,\\\\\n\\sigma_{\\mathrm{hi}},  y \\ge \\theta.\n\\end{cases}\n$$\n\n您的目标是：\n- 对于每组参数，从一条长轨迹中计算高活性状态下停留时间的经验分布。\n- 通过比较经验生存函数的尾部行为，推断门控动力学是无记忆性的（与指数分布的停留时间一致），还是表现出记忆性/异质性（与重尾分布的停留时间一致）。\n\n对于尾部分类，请使用以下基于首达和更新理论的原则性方法：\n- 构建停留时间的经验生存函数 $S(t)$。\n- 在上尾数据 $t \\ge t_{\\min}$ 上比较两种尾部模型，其中 $t_{\\min}$ 选择为停留时间的经验中位数：\n  1. 指数尾：$S(t) \\approx \\exp(-\\lambda t)$，其中 $\\lambda  0$。\n  2. 帕累托型重尾：$S(t) \\approx \\left(\\frac{t}{t_{\\min}}\\right)^{-\\alpha}$，其中 $\\alpha  0$。\n- 通过对适当变换进行线性回归，在相同的尾部样本上拟合这两种模型：\n  - 通过 $\\log S(t)$ 对 $t$ 的线性回归进行指数拟合。\n  - 通过 $\\log S(t)$ 对 $\\log t$ 的线性回归进行帕累托拟合。\n- 使用决定系数 $R^2$ 比较在尾部的拟合优度。如果帕累托拟合的 $R^2$ 比指数拟合的 $R^2$ 大至少一个余量 $\\delta$，并且其估计的尾部指数 $\\alpha$ 位于重尾的合理范围（例如，$1 \\le \\alpha \\le 5$）内，则将分布分类为重尾。如果指数拟合的 $R^2$ 比帕累托拟合的 $R^2$ 大至少相同的余量 $\\delta$，则分类为指数。在有歧义的情况下（$R^2$ 绝对差值小于该余量），使用共同的 $t_{\\min}$ 通过最大似然法来决定：\n  - 指数尾最大似然估计：在尾部样本上 $\\hat{\\lambda} = 1/\\bar{t}$，对数似然为 $\\sum_{i}\\left(\\log \\hat{\\lambda} - \\hat{\\lambda} t_i\\right)$。\n  - 帕累托尾最大似然估计：对于 $t_i \\ge t_{\\min}$，$\\hat{\\alpha} = 1 + n \\big/ \\sum_i \\log \\left(t_i / t_{\\min}\\right)$，对数似然为 $n \\log \\hat{\\alpha} + n \\hat{\\alpha} \\log t_{\\min} - (\\hat{\\alpha}+1)\\sum_i \\log t_i$。\n  偏好具有更大对数似然的模型。\n\n您必须为随机数生成器设置种子以确保确定性输出，并将分类报告为整数，其中 $0$ 表示指数分布，$1$ 表示重尾分布。停留时间以秒为单位，但最终输出是无单位的整数。\n\n测试套件。使用以下参数模拟四个独立案例；在所有案例中，使用 $\\Delta t = 0.005$ 秒，总模拟时间 $T = 1500$ 秒，阈值 $\\theta = 1.0$，初始条件 $Y_0 = 1.5$，以及分类余量 $\\delta = 0.02$：\n- 案例 A（标称无记忆门控）：$a_{\\mathrm{lo}} = 0.95$, $b_{\\mathrm{lo}} = 1.0$, $\\sigma_{\\mathrm{lo}} = 0.50$, $a_{\\mathrm{hi}} = 2.0$, $b_{\\mathrm{hi}} = 1.0$, $\\sigma_{\\mathrm{hi}} = 0.25$。\n- 案例 B（弱恢复力与强乘性噪声）：$a_{\\mathrm{lo}} = 0.95$, $b_{\\mathrm{lo}} = 1.0$, $\\sigma_{\\mathrm{lo}} = 0.50$, $a_{\\mathrm{hi}} = 0.4$, $b_{\\mathrm{hi}} = 0.2$, $\\sigma_{\\mathrm{hi}} = 0.60$。\n- 案例 C（强恢复力，中等噪声）：$a_{\\mathrm{lo}} = 0.95$, $b_{\\mathrm{lo}} = 1.0$, $\\sigma_{\\mathrm{lo}} = 0.50$, $a_{\\mathrm{hi}} = 4.0$, $b_{\\mathrm{hi}} = 2.0$, $\\sigma_{\\mathrm{hi}} = 0.20$。\n- 案例 D（接近阈值的均值与强噪声）：$a_{\\mathrm{lo}} = 0.95$, $b_{\\mathrm{lo}} = 1.0$, $\\sigma_{\\mathrm{lo}} = 0.50$, $a_{\\mathrm{hi}} = 1.2$, $b_{\\mathrm{hi}} = 1.0$, $\\sigma_{\\mathrm{hi}} = 0.55$。\n\n数值要求和输出：\n- 使用指定的 Euler–Maruyama 方案，并通过 $Y_{n+1} = \\max\\{0, \\cdot\\}$ 在 $Y=0$ 处实现反射边界。\n- 提取高活性状态 $Y \\ge \\theta$ 下的所有完整停留时间，排除轨迹末端的任何不完整区间。滤除短于 $2\\Delta t$ 的虚假微小区间，以避免离散化伪影。\n- 对每个案例，执行上述尾部分类程序，并返回 $0$（指数）或 $1$（重尾）。\n- 最终输出格式：您的程序应生成单行输出，其中包含用方括号括起来的逗号分隔列表（例如，“[0,1,0,1]”），依次对应于案例 A、B、C 和 D 的结果。", "solution": "解决方案是通过遵循问题陈述中概述的任务序列来构建的。\n\n### 1. SDE 模拟\n问题的核心是 ERK 活性 $Y_t$ 的随机动力学，它由一个分段线性的 Itô SDE 控制：\n$$\ndY_t = \\mu(Y_t)\\,dt + \\sigma(Y_t) Y_t\\, dW_t\n$$\n漂移项 $\\mu(y)$ 和波动率系数 $\\sigma(y)$ 是分段常数，根据 $Y_t$ 是低于还是高于阈值 $\\theta$ 来切换其函数形式。这种结构代表了低和高 ERK 活性的不同调控机制。\n\n我们使用指定的 Euler-Maruyama 方法模拟 $Y_t$ 的轨迹。对于一个时间步长 $\\Delta t$，第 $n+1$ 步的状态由第 $n$ 步的状态更新如下：\n$$\nY_{n+1} = Y_n + \\mu(Y_n)\\,\\Delta t + \\sigma(Y_n)\\, Y_n \\sqrt{\\Delta t}\\, \\xi_n\n$$\n其中 $\\xi_n$ 是从标准正态分布 $\\mathcal{N}(0,1)$ 中抽取的独立随机变量。该项近似于随机增量 $dW_t$。通过取更新值与 $0$ 的最大值来强制执行在 $Y_t=0$ 处的反射边界条件，确保生物学状态变量保持非负：$Y_{n+1} = \\max\\{0, Y_{n+1}\\}$。\n\n### 2. 停留时间提取\n停留时间是系统在一次进入和随后的退出之间，处于高活性状态（$Y_t \\ge \\theta$）的持续时间。为计算这些时间，我们扫描模拟轨迹以识别对阈值 $\\theta$ 的穿越事件：\n1.  当轨迹从 $Y_{n-1}  \\theta$ 移动到 $Y_n \\ge \\theta$ 时，标记一个“向上穿越”事件。这开始一个停留期。\n2.  当轨迹从 $Y_{m-1} \\ge \\theta$ 移动到 $Y_m  \\theta$ 时，标记一个“向下穿越”事件。这结束该停留期。\n持续时间是向下穿越与前一次向上穿越之间的时间差。模拟结束时的任何不完整区间都将被丢弃。为减轻因轨迹可能在 $\\theta$ 附近快速振荡而产生的离散化伪影，我们滤除并丢弃任何计算出的短于两个时间步长（$2\\Delta t$）的停留时间。\n\n### 3. 统计尾部分类\n中心目标是确定停留时间的分布是无记忆的（指数尾），还是表现出长期记忆（重尾，如帕累托分布）。这是通过一个统计模型选择程序来实现的。\n\n1.  **经验生存函数**：首先，我们从收集到的停留时间 $\\{T_i\\}$ 构建经验生存函数 $S(t)$。生存函数 $S(t) = P(\\text{时间}  t)$ 给出了停留时间超过某一时长 $t$ 的概率。根据经验，对于一组 $N$ 个停留时间，其计算公式为 $S(t) = (\\text{大于 } t \\text{ 的 } T_i \\text{ 数量}) / N$。\n\n2.  **尾部定义**：我们将分析集中在分布的尾部，这对于区分指数行为和重尾行为最具信息量。尾部被定义为所有大于或等于数据经验中位数 $t_{\\min}$ 的停留时间 $t$。\n\n3.  **通过线性回归进行模型拟合**：我们比较两种关于 $S(t)$ 尾部的竞争模型：\n    *   **指数尾**：$S(t) \\propto e^{-\\lambda t}$。该关系在变换后变为线性：$\\log S(t) \\approx C - \\lambda t$。我们对尾部数据进行 $\\log S(t)$ 对 $t$ 的线性回归。\n    *   **帕累托尾**：$S(t) \\propto t^{-\\alpha}$。这在对数-对数尺度上变为线性：$\\log S(t) \\approx C - \\alpha \\log t$。我们进行 $\\log S(t)$ 对 $\\log t$ 的线性回归。\n\n4.  **拟合优度比较 ($R^2$)**：模型选择的主要标准是来自每次回归的决定系数 $R^2$。\n    *   如果 $R^2_{\\text{Pareto}}  R^2_{\\text{exp}} + \\delta$ 并且从帕累托拟合的斜率估计出的尾部指数 $\\alpha = -\\text{斜率}$ 位于合理范围 $[1, 5]$ 内，则该分布被分类为**重尾 (1)**。\n    *   如果 $R^2_{\\text{exp}}  R^2_{\\text{Pareto}} + \\delta$，则分类为**指数 (0)**。\n\n5.  **最大似然决胜**：如果 $R^2$ 值太接近（差值小于余量 $\\delta=0.02$），我们使用基于对尾部样本（$t_i \\ge t_{\\min}$）进行最大似然估计 (MLE) 的决胜规则。我们使用指定的估计量计算每个模型的对数似然，并选择具有更高对数似然值的模型。\n    *   对于指数模型，$\\hat{\\lambda} = 1/\\bar{t}$，其中 $\\bar{t}$ 是尾部样本的均值。\n    *   对于帕累托模型，$\\hat{\\alpha}$ 使用问题陈述中提供的公式计算。\n    *   计算并比较指定的相应对数似然函数，以做出最终分类。\n\n这个完整的、基于规则的程序被独立应用于四个提供的参数集中的每一个，以生成最终输出。为确保每个案例结果的独立性和可复现性，在每次模拟之前都会重新为随机数生成器设置种子。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import linregress\n\ndef solve():\n    \"\"\"\n    Main function to run simulations and classify residence time distributions\n    for the four specified cases.\n    \"\"\"\n    \n    # Common parameters for all simulations\n    dt = 0.005\n    T = 1500.0\n    theta = 1.0\n    Y0 = 1.5\n    delta = 0.02\n    \n    # Test cases as defined in the problem\n    test_cases = [\n        # Case A (nominal memoryless gating)\n        {'params': (0.95, 1.0, 0.50, 2.0, 1.0, 0.25), 'seed': 0},\n        # Case B (weak restoring force, strong noise)\n        {'params': (0.95, 1.0, 0.50, 0.4, 0.2, 0.60), 'seed': 1},\n        # Case C (strong restoring force, moderate noise)\n        {'params': (0.95, 1.0, 0.50, 4.0, 2.0, 0.20), 'seed': 2},\n        # Case D (near-threshold mean, strong noise)\n        {'params': (0.95, 1.0, 0.50, 1.2, 1.0, 0.55), 'seed': 3},\n    ]\n\n    results = []\n    for case in test_cases:\n        classification = analyze_case(case['params'], dt, T, theta, Y0, delta, case['seed'])\n        results.append(classification)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\ndef analyze_case(params, dt, T, theta, Y0, delta, seed):\n    \"\"\"\n    Analyzes a single parameter case: simulates the SDE, extracts residence times,\n    and performs tail classification.\n    \"\"\"\n    np.random.seed(seed)\n    a_lo, b_lo, sigma_lo, a_hi, b_hi, sigma_hi = params\n    \n    num_steps = int(T / dt)\n    y_traj = np.zeros(num_steps + 1)\n    y_traj[0] = Y0\n    \n    # --- 1. SDE Simulation using Euler-Maruyama ---\n    for n in range(num_steps):\n        yn = y_traj[n]\n        if yn  theta:\n            mu = a_lo - b_lo * yn\n            sigma_val = sigma_lo\n        else:\n            mu = a_hi - b_hi * yn\n            sigma_val = sigma_hi\n            \n        noise_term = sigma_val * yn * np.sqrt(dt) * np.random.randn()\n        y_traj[n+1] = max(0.0, yn + mu * dt + noise_term)\n\n    # --- 2. Residence Time Extraction ---\n    residence_times = []\n    is_high = y_traj = theta\n    in_high_state = is_high[0]\n    start_step = 0 if in_high_state else -1\n\n    for i in range(1, len(is_high)):\n        if is_high[i] and not in_high_state: # Up-crossing\n            in_high_state = True\n            start_step = i\n        elif not is_high[i] and in_high_state: # Down-crossing\n            in_high_state = False\n            duration = (i - start_step) * dt\n            if duration = 2 * dt:\n                residence_times.append(duration)\n    \n    # --- 3. Statistical Tail Classification ---\n    if len(residence_times)  10:\n        return 0 # Default to exponential if data is insufficient\n\n    residence_times = np.array(residence_times)\n    t_min = np.median(residence_times)\n    \n    tail_data = residence_times[residence_times = t_min]\n    \n    unique_tail_times = np.unique(tail_data)\n    if len(unique_tail_times)  2:\n        return 0 # Not enough unique points in tail for regression\n\n    # Calculate empirical survival function S(t) for unique tail times\n    sorted_times = np.sort(residence_times)\n    n_total = len(sorted_times)\n    s_values = np.array([(n_total - np.searchsorted(sorted_times, t, side='right')) / n_total for t in unique_tail_times])\n\n    # Filter out points where S(t) is 0 to avoid log(0)\n    valid_indices = s_values  0\n    if np.sum(valid_indices)  2:\n        return 0 # Not enough points for regression after filtering\n        \n    unique_tail_times = unique_tail_times[valid_indices]\n    s_values = s_values[valid_indices]\n\n    # Model fitting via linear regression\n    log_s = np.log(s_values)\n    \n    # Exponential fit: log(S) vs t\n    exp_fit = linregress(unique_tail_times, log_s)\n    r2_exp = exp_fit.rvalue**2 if exp_fit.rvalue is not None else 0.0\n\n    # Pareto fit: log(S) vs log(t)\n    log_t = np.log(unique_tail_times)\n    pareto_fit = linregress(log_t, log_s)\n    r2_pareto = pareto_fit.rvalue**2 if pareto_fit.rvalue is not None else 0.0\n    alpha = -pareto_fit.slope if pareto_fit.slope is not None else -1.0\n\n    # R-squared based classification\n    if r2_pareto  r2_exp + delta and 1.0 = alpha = 5.0:\n        return 1\n    elif r2_exp  r2_pareto + delta:\n        return 0\n    else:\n        # Tie-breaking with Maximum Likelihood Estimation\n        tail_sample = tail_data\n        n = len(tail_sample)\n        \n        # Exponential MLE\n        t_bar_tail = np.mean(tail_sample)\n        lambda_hat = 1.0 / t_bar_tail\n        log_L_exp = np.sum(np.log(lambda_hat) - lambda_hat * tail_sample)\n        \n        # Pareto MLE (using problem-specified formulas)\n        # The sum is over all t_i in the tail sample (t_i = t_min)\n        sum_log_ratio = np.sum(np.log(tail_sample / t_min))\n\n        if np.isclose(sum_log_ratio, 0):\n            # Avoid division by zero if all tail times equal the median\n            log_L_pareto = -np.inf\n        else:\n            alpha_hat = 1.0 + n / sum_log_ratio\n            log_tail_sample = np.log(tail_sample)\n            log_L_pareto = (n * np.log(alpha_hat) + \n                          n * alpha_hat * np.log(t_min) - \n                          (alpha_hat + 1) * np.sum(log_tail_sample))\n            \n        return 1 if log_L_pareto  log_L_exp else 0\n\nif __name__ == '__main__':\n    solve()\n```", "id": "3303212"}]}