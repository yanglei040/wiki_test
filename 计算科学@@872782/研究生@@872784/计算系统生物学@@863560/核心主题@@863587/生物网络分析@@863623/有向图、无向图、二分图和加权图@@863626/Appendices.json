{"hands_on_practices": [{"introduction": "为了对生物网络进行定量分析，我们首先需要将其转化为数学语言。本练习将介绍实现这一转化的最基本工具：加权邻接矩阵、度矩阵和图拉普拉斯矩阵。掌握它们的构建是分析网络扩散和连通性等属性的第一步。[@problem_id:3302969]", "problem": "在计算系统生物学中，分子实体之间的相互作用或耦合强度通常被建模为无向图上的正边权重，从而得到一个系统级关系的加权网络表示。考虑一个由四种标记为 $\\{1,2,3,4\\}$ 的酶组成的网络，其中酶 $i$ 和 $j$ 之间的无向边具有正的耦合强度 $w_{ij}$，并满足对称性 $w_{ij} = w_{ji} > 0$。加权邻接矩阵 $A$ 和（加权）度矩阵 $D$ 是图论中的基本构造：$A$ 编码了边的权重，$D$ 编码了每个节点上关联边的权重之和。组合拉普拉斯矩阵定义为 $L = D - A$，并被广泛用于量化扩散耦合以及定义在节点上的信号的平滑度。从核心定义出发，即对于一个无向加权图，$A$ 是对称的，其中当 $i \\neq j$ 时 $a_{ij} = w_{ij}$ 且 $a_{ii} = 0$，$D$ 是对角矩阵，其对角元素为 $d_{i} = \\sum_{j=1}^{n} a_{ij}$。请推导如何从 $\\{w_{ij}\\}$ 构建 $A$ 和 $D$，并由此构建 $L$。然后，对于一个给定的节点信号 $x$，通过计算二次型 $x^{\\top} L x$ 来求得一个从 $L$ 导出的标量。\n\n该生物网络由以下无向正权重给出：\n- $w_{12} = 3.2$, $w_{13} = 0.7$, $w_{14} = 4.1$,\n- $w_{23} = 1.8$, $w_{24} = 3.3$,\n- $w_{34} = 2.5$,\n\n对所有 $i$ 满足 $w_{ij} = w_{ji}$ 且 $w_{ii} = 0$。设节点信号（例如，酶活性的对数倍数变化）为 $x = (1,\\,-1,\\,2,\\,0)^{\\top}$。\n\n任务：\n1. 使用无向加权图的基本定义，显式地构建加权邻接矩阵 $A$ 和度矩阵 $D$。\n2. 计算拉普拉斯矩阵 $L = D - A$。\n3. 计算二次型 $x^{\\top} L x$ 的值。\n\n将最终答案表示为一个实数。无需四舍五入；请报告精确值。", "solution": "问题陈述经核实具有科学依据、良构且客观。它提供了来自计算系统生物学和图论领域的一套完整且一致的定义和数据。这些任务在计算上是直接的，并能得出一个唯一的、可验证的结果。我们开始进行解答。\n\n该问题要求为一个由四种酶组成的网络构建三个矩阵——加权邻接矩阵 $A$、度矩阵 $D$ 和组合拉普拉斯矩阵 $L$，并随后计算二次型 $x^{\\top} L x$ 的值。\n\n**任务1：构建加权邻接矩阵 $A$ 和度矩阵 $D$。**\n\n对于一个有 $n$ 个节点的无向图，其加权邻接矩阵 $A$ 是一个 $n \\times n$ 的对称矩阵。其元素 $a_{ij}$ 根据节点 $i$ 和 $j$ 之间的边权重 $w_{ij}$ 定义。当 $i \\neq j$ 时，$a_{ij} = w_{ij}$。对角线元素为零，即 $a_{ii} = 0$。\n\n给定由 $n=4$ 种酶组成的网络和所提供的权重：\n$w_{12} = 3.2$, $w_{13} = 0.7$, $w_{14} = 4.1$,\n$w_{23} = 1.8$, $w_{24} = 3.3$,\n$w_{34} = 2.5$。\n以及对称条件 $w_{ij} = w_{ji}$。\n\n$4 \\times 4$ 的邻接矩阵 $A$ 构建如下：\n$$ A = \\begin{pmatrix} a_{11}  a_{12}  a_{13}  a_{14} \\\\ a_{21}  a_{22}  a_{23}  a_{24} \\\\ a_{31}  a_{32}  a_{33}  a_{34} \\\\ a_{41}  a_{42}  a_{43}  a_{44} \\end{pmatrix} = \\begin{pmatrix} 0  w_{12}  w_{13}  w_{14} \\\\ w_{21}  0  w_{23}  w_{24} \\\\ w_{31}  w_{32}  0  w_{34} \\\\ w_{41}  w_{42}  w_{43}  0 \\end{pmatrix} $$\n代入给定的数值：\n$$ A = \\begin{pmatrix} 0  3.2  0.7  4.1 \\\\ 3.2  0  1.8  3.3 \\\\ 0.7  1.8  0  2.5 \\\\ 4.1  3.3  2.5  0 \\end{pmatrix} $$\n\n度矩阵 $D$ 是一个对角矩阵，其中每个对角线元素 $d_i$（也记作 $d_{ii}$）表示节点 $i$ 的度。对于加权图，一个节点的度是所有与该节点关联的边的权重之和。这可以通过对邻接矩阵 $A$ 中相应行（或列）的元素求和来计算：\n$$ d_i = \\sum_{j=1}^{n} a_{ij} $$\n那么，度矩阵 $D$ 为：\n$$ D = \\begin{pmatrix} d_1  0  0  0 \\\\ 0  d_2  0  0 \\\\ 0  0  d_3  0 \\\\ 0  0  0  d_4 \\end{pmatrix} $$\n我们计算各个节点的度：\n$d_1 = a_{12} + a_{13} + a_{14} = 3.2 + 0.7 + 4.1 = 8.0$\n$d_2 = a_{21} + a_{23} + a_{24} = 3.2 + 1.8 + 3.3 = 8.3$\n$d_3 = a_{31} + a_{32} + a_{34} = 0.7 + 1.8 + 2.5 = 5.0$\n$d_4 = a_{41} + a_{42} + a_{43} = 4.1 + 3.3 + 2.5 = 9.9$\n\n因此，度矩阵 $D$ 是：\n$$ D = \\begin{pmatrix} 8.0  0  0  0 \\\\ 0  8.3  0  0 \\\\ 0  0  5.0  0 \\\\ 0  0  0  9.9 \\end{pmatrix} $$\n\n**任务2：计算拉普拉斯矩阵 $L = D - A$。**\n\n组合拉普拉斯矩阵 $L$ 定义为度矩阵 $D$ 与邻接矩阵 $A$ 之差。\n$$ L = D - A $$\n$$ L = \\begin{pmatrix} 8.0  0  0  0 \\\\ 0  8.3  0  0 \\\\ 0  0  5.0  0 \\\\ 0  0  0  9.9 \\end{pmatrix} - \\begin{pmatrix} 0  3.2  0.7  4.1 \\\\ 3.2  0  1.8  3.3 \\\\ 0.7  1.8  0  2.5 \\\\ 4.1  3.3  2.5  0 \\end{pmatrix} $$\n$$ L = \\begin{pmatrix} 8.0 - 0  0 - 3.2  0 - 0.7  0 - 4.1 \\\\ 0 - 3.2  8.3 - 0  0 - 1.8  0 - 3.3 \\\\ 0 - 0.7  0 - 1.8  5.0 - 0  0 - 2.5 \\\\ 0 - 4.1  0 - 3.3  0 - 2.5  9.9 - 0 \\end{pmatrix} $$\n$$ L = \\begin{pmatrix} 8.0  -3.2  -0.7  -4.1 \\\\ -3.2  8.3  -1.8  -3.3 \\\\ -0.7  -1.8  5.0  -2.5 \\\\ -4.1  -3.3  -2.5  9.9 \\end{pmatrix} $$\n\n**任务3：计算二次型 $x^{\\top} L x$ 的值。**\n\n节点信号由列向量 $x = \\begin{pmatrix} 1  -1  2  0 \\end{pmatrix}^{\\top}$ 给出。其转置为 $x^{\\top} = \\begin{pmatrix} 1  -1  2  0 \\end{pmatrix}$。\n二次型 $x^{\\top} L x$ 通过矩阵乘法计算。首先，我们计算乘积 $L x$：\n$$ L x = \\begin{pmatrix} 8.0  -3.2  -0.7  -4.1 \\\\ -3.2  8.3  -1.8  -3.3 \\\\ -0.7  -1.8  5.0  -2.5 \\\\ -4.1  -3.3  -2.5  9.9 \\end{pmatrix} \\begin{pmatrix} 1 \\\\ -1 \\\\ 2 \\\\ 0 \\end{pmatrix} $$\n$$ L x = \\begin{pmatrix} (8.0)(1) + (-3.2)(-1) + (-0.7)(2) + (-4.1)(0) \\\\ (-3.2)(1) + (8.3)(-1) + (-1.8)(2) + (-3.3)(0) \\\\ (-0.7)(1) + (-1.8)(-1) + (5.0)(2) + (-2.5)(0) \\\\ (-4.1)(1) + (-3.3)(-1) + (-2.5)(2) + (9.9)(0) \\end{pmatrix} $$\n$$ L x = \\begin{pmatrix} 8.0 + 3.2 - 1.4 \\\\ -3.2 - 8.3 - 3.6 \\\\ -0.7 + 1.8 + 10.0 \\\\ -4.1 + 3.3 - 5.0 \\end{pmatrix} = \\begin{pmatrix} 9.8 \\\\ -15.1 \\\\ 11.1 \\\\ -5.8 \\end{pmatrix} $$\n接下来，我们计算 $x^{\\top}$ 与结果向量 $L x$ 的点积：\n$$ x^{\\top} L x = x^{\\top} (L x) = \\begin{pmatrix} 1  -1  2  0 \\end{pmatrix} \\begin{pmatrix} 9.8 \\\\ -15.1 \\\\ 11.1 \\\\ -5.8 \\end{pmatrix} $$\n$$ x^{\\top} L x = (1)(9.8) + (-1)(-15.1) + (2)(11.1) + (0)(-5.8) $$\n$$ x^{\\top} L x = 9.8 + 15.1 + 22.2 + 0 $$\n$$ x^{\\top} L x = 24.9 + 22.2 = 47.1 $$\n二次型的值为 $47.1$。", "answer": "$$\n\\boxed{47.1}\n$$", "id": "3302969"}, {"introduction": "在掌握了网络的基本表示方法之后，我们将探讨图结构如何揭示生物学功能，尤其是在基因调控通路等有向网络中。本练习将探讨拓扑排序的概念，这是一种揭示无反馈环路网络中过程的层级或顺序性质的算法。理解这一点使我们能够描绘从上游调控因子到下游靶标的生物信息流。[@problem_id:3303015]", "problem": "在计算系统生物学中使用的基因调控网络中，基因和转录因子可以表示为有向图的顶点，其中从顶点 $i$ 到顶点 $j$ 的有向边表示基因 $i$ 的产物调控基因 $j$ 的表达。考虑以下模型假设作为基本基础：基因调控遵循分子生物学的中心法则（脱氧核糖核酸到核糖核酸到蛋白质），调控影响沿着有向边传播，有向环对应于一个反馈回路。没有有向环的有向图称为有向无环图（DAG），这种图允许进行拓扑排序，即对顶点进行排列，使得所有有向边都从较早的位置指向较后的位置。\n\n给定一个顶点集为 $V=\\{A,B,C,D,E,F\\}$ 的小型有向基因调控网络，它代表转录调控，其中边的方向编码了调控影响中的优先约束。提供了加权邻接矩阵，但为了进行层级排序，只有拓扑结构（非零元素的位置）是重要的。顶点按 $(A,B,C,D,E,F)$ 排序，邻接矩阵 $M$ 为\n$$\nM \\;=\\; \\begin{pmatrix}\n0  1  1  0  0  0 \\\\\n0  0  0  1  1  0 \\\\\n0  0  0  0  1  1 \\\\\n0  0  0  0  0  1 \\\\\n0  0  0  0  0  1 \\\\\n0  0  0  0  0  0\n\\end{pmatrix}.\n$$\n矩阵项 $M_{ij}=1$ 表示一条有向边 $i\\to j$，并编码了在任何有效的层级排序中，$i$ 必须在 $j$ 之前；矩阵项 $M_{ij}=0$ 表示不存在直接的调控边。假设所有非零项都对应于正权重，其大小与优先顺序无关。\n\n任务：\n1. 仅从有向图、有向无环图、偏序和拓扑排序的定义出发，解释为什么该网络的拓扑排序能够在没有反馈回路的情况下捕捉到层级调控，以及为什么这种排序的存在性等价于有向图的无环性。\n2. 使用给定的邻接矩阵 $M$，验证该有向图是无环的，并计算：\n   - 一个与 $M$ 一致的 $V$ 的有效拓扑排序，以及\n   - 由 $M$ 编码的优先约束的所有不同有效拓扑排序（线性扩展）的总数。\n\n答案规格：为了评分，请仅报告有效拓扑排序的总数，作为一个不带单位的整数。不要四舍五入。你可能会发现生成一个有效的排序作为中间步骤很有帮助，但不要将其包含在最终答案中。", "solution": "该问题分为一个概念性解释和一个涉及特定有向图的计算任务。\n\n**第一部分：概念框架**\n\n一个有向图 $G=(V, E)$ 由一个顶点集 $V$ 和一个边集 $E$ 组成，其中每条边是顶点的有序对 $(u, v)$，表示从 $u$ 到 $v$ 的有向连接。在基因调控网络的背景下，顶点代表基因，有向边 $(i, j)$ 表示基因 $i$ 的产物调控基因 $j$。这就建立了一个优先约束：$i$ 的调控作用在逻辑上必须先于其对 $j$ 的影响。\n\n所有这些优先约束的集合可以通过传递性进行扩展。如果存在一条从顶点 $u$ 到顶点 $v$ 的有向路径，我们称 $u$ 是 $v$ 的祖先，或者说 $u$ 先于 $v$，记作 $u \\prec v$。当且仅当该图是一个有向无环图（DAG）时，这种优先关系构成一个严格偏序。严格偏序是一种满足反自反性、非对称性和传递性的二元关系。\n1.  **反自反性**：对于任意顶点 $v$，有 $v \\not\\prec v$。这意味着不存在从 $v$ 回到自身的路径，这正是一个图没有长度为1或更长的环的定义。\n2.  **非对称性**：如果 $u \\prec v$，那么 $v \\not\\prec u$。如果存在一条从 $u$ 到 $v$ 的路径和一条从 $v$ 到 $u$ 的路径，它们的拼接将形成一个有向环。因此，非对称性是无环性的直接结果。\n3.  **传递性**：如果 $u \\prec v$ 且 $v \\prec w$，那么 $u \\prec w$。如果有一条从 $u$ 到 $v$ 的路径和一条从 $v$ 到 $w$ 的路径，将它们拼接起来就构成了一条从 $u$ 到 $w$ 的路径。这在基于路径的优先关系定义中是固有的。\n\n题目指出，有向环对应于一个反馈回路。因此，没有反馈回路等价于图是无环的。在这样的系统中，调控是层级式的：存在“上游”调控者和“下游”靶标，而靶标不会反馈影响其自身的调控者。这种层级结构正是由 DAG 上的偏序关系 $\\prec$ 所捕捉的。\n\n有向图的拓扑排序是其所有顶点的一种线性排序，使得对于从顶点 $u$ 到顶点 $v$ 的每一条有向边，$u$ 在排序中都出现在 $v$ 之前。这样的排序是把偏序关系“展平”成一个全序关系，代表了调控事件展开的一种可能的有效序列。\n\n拓扑排序的存在性等价于图是一个DAG。\n-   **（DAG $\\implies$ 拓扑排序）**：一个有限DAG必须至少有一个入度为 $0$ 的顶点。这样的顶点可以放在排序的首位。移除这个顶点及其出边会得到一个更小的子图，该子图也是一个DAG。可以重复这个过程，在每一步从剩余的图中选择一个入度为 $0$ 的顶点，直到所有顶点都被排序。这种构造性算法（Kahn算法）对于DAG总是成功的。\n-   **（拓扑排序 $\\implies$ DAG）**：假设存在一个拓扑排序。设排序为 $v_1, v_2, \\ldots, v_n$。对于任何边 $(v_i, v_j)$，排序的定义要求 $i  j$。因此，任何有向路径 $v_{k_1} \\to v_{k_2} \\to \\ldots \\to v_{k_m}$ 都必须满足 $k_1  k_2  \\ldots  k_m$。一个环是起点和终点相同的路径，例如 $v_i \\to \\ldots \\to v_i$。这将意味着存在一个索引序列 $i  \\ldots  i$，这是一个矛盾。因此，不可能存在环。\n\n因此，拓扑排序代表了基因表达事件的一个有效的时间或层级序列，其存在性保证了网络没有反馈回路。\n\n**第二部分：对给定网络的分析**\n\n顶点集为 $V=\\{A,B,C,D,E,F\\}$。邻接矩阵 $M$ 定义了以下边：\n$A \\to B$, $A \\to C$\n$B \\to D$, $B \\to E$\n$C \\to E$, $C \\to F$\n$D \\to F$\n$E \\to F$\n\n**验证无环性并找到一个拓扑排序**\n我们使用Kahn算法。首先，我们计算所有顶点的入度：\n-   $\\text{in-degree}(A) = 0$\n-   $\\text{in-degree}(B) = 1$\n-   $\\text{in-degree}(C) = 1$\n-   $\\text{in-degree}(D) = 1$\n-   $\\text{in-degree}(E) = 2$\n-   $\\text{in-degree}(F) = 3$\n\n1.  用所有入度为0的顶点初始化一个队列：$Q = [A]$。\n2.  将 $A$ 出队。将其添加到已排序列表 $L$ 中：$L=(A)$。将其邻居（$B$, $C$）的入度减1。\n    -   $\\text{in-degree}(B)$ 变为 $0$。将 $B$ 入队。\n    -   $\\text{in-degree}(C)$ 变为 $0$。将 $C$ 入队。\n    -   $Q = [B, C]$。\n3.  将 $B$ 出队。$L=(A, B)$。将其邻居（$D$, $E$）的入度减1。\n    -   $\\text{in-degree}(D)$ 变为 $0$。将 $D$ 入队。\n    -   $\\text{in-degree}(E)$ 变为 $2-1=1$。\n    -   $Q = [C, D]$。\n4.  将 $C$ 出队。$L=(A, B, C)$。将其邻居（$E$, $F$）的入度减1。\n    -   $\\text{in-degree}(E)$ 变为 $1-1=0$。将 $E$ 入队。\n    -   $\\text{in-degree}(F)$ 变为 $3-1=2$。\n    -   $Q = [D, E]$。\n5.  将 $D$ 出队。$L=(A, B, C, D)$。将其邻居（$F$）的入度减1。\n    -   $\\text{in-degree}(F)$ 变为 $2-1=1$。\n    -   $Q = [E]$。\n6.  将 $E$ 出队。$L=(A, B, C, D, E)$。将其邻居（$F$）的入度减1。\n    -   $\\text{in-degree}(F)$ 变为 $1-1=0$。将 $F$ 入队。\n    -   $Q = [F]$。\n7.  将 $F$ 出队。$L=(A, B, C, D, E, F)$。$F$ 没有邻居。\n    -   $Q = []$。\n\n算法终止，已排序列表 $L$ 包含所有6个顶点。这验证了该图是一个DAG。一个有效的拓扑排序是 $(A, B, C, D, E, F)$。\n\n**计算不同拓扑排序的总数**\n\n不同拓扑排序的数量可以通过考虑排序过程中每一步可用的选择数量来计算。这等同于枚举Kahn算法的决策树表示中的所有路径。\n\n1.  **位置1**：唯一入度为0的顶点是 $A$。只有 $1$ 种选择。\n    -   排序：$(A, \\ldots)$。下一步可用的顶点：$\\{B, C\\}$。\n\n2.  **位置2**：我们可以选择 $B$ 或 $C$。这产生了两个主要分支。\n\n    -   **分支1：选择 $B$ 作为位置2。**\n        -   排序前缀：$(A, B)$。\n        -   现在，可用顶点（在剩余图中的入度为0）的集合是 $\\{C, D\\}$。\n        -   **子分支1.1：选择 $C$ 作为位置3。**\n            -   排序前缀：$(A, B, C)$。\n            -   可用集合：$\\{D, E\\}$（因为 $E$ 的前驱 $B$ 和 $C$ 都已被放置）。\n            -   对于位置4和5，我们可以按任意顺序放置 $D$ 和 $E$，因为它们现在是独立的（它们之间没有边）。这给出了 $2! = 2$ 种排列：$(D, E)$ 或 $(E, D)$。\n            -   位置6必须是 $F$。\n            -   这个子分支产生 $2$ 个排序：$(A, B, C, D, E, F)$ 和 $(A, B, C, E, D, F)$。\n        -   **子分支1.2：选择 $D$ 作为位置3。**\n            -   排序前缀：$(A, B, D)$。\n            -   唯一可用的顶点是 $C$（$E$ 仍然需要 $C$；$F$ 需要 $C, D, E$）。\n            -   **位置4**：必须是 $C$。排序前缀：$(A, B, D, C)$。\n            -   现在 $E$ 可用了（前驱 $B, C$ 已被放置）。\n            -   **位置5**：必须是 $E$。排序前缀：$(A, B, D, C, E)$。\n            -   **位置6**：必须是 $F$。\n            -   这个子分支产生 $1$ 个排序：$(A, B, D, C, E, F)$。\n        -   分支1（以 $A, B$ 开头）的总数：$2 + 1 = 3$ 个排序。\n\n    -   **分支2：选择 $C$ 作为位置2。**\n        -   排序前缀：$(A, C)$。\n        -   唯一可用的顶点是 $B$（$D$ 和 $E$ 仍然需要 $B$）。\n        -   **位置3**：必须是 $B$。排序前缀：$(A, C, B)$。\n        -   现在可用顶点的集合是 $\\{D, E\\}$。\n        -   这种情况与子分支1.1对称。我们已经放置了 $\\{A, B, C\\}$，现在必须对 $\\{D, E, F\\}$ 进行排序，其中 $D \\prec F$ 且 $E \\prec F$。可用的选择是 $D$ 和 $E$，它们是独立的。\n        -   我们可以用 $2! = 2$ 种方式放置它们：$(D,E)$ 或 $(E,D)$，然后是 $F$。\n        -   这个分支产生 $2$ 个排序：$(A, C, B, D, E, F)$ 和 $(A, C, B, E, D, F)$。\n        -   分支2（以 $A, C$ 开头）的总数：$2$ 个排序。\n\n3.  **总计数**：不同拓扑排序的总数是所有初始分支计数之和：$3 + 2 = 5$。\n\n5个不同的有效拓扑排序是：\n-   $(A,B,C,D,E,F)$\n-   $(A,B,C,E,D,F)$\n-   $(A,B,D,C,E,F)$\n-   $(A,C,B,D,E,F)$\n-   $(A,C,B,E,D,F)$\n总数为 $5$。", "answer": "$$\n\\boxed{5}\n$$", "id": "3303015"}, {"introduction": "在图表示和分析的基础上，本练习将深入一个真实的研究场景：在加权有向网络中对信号传播进行建模。你将比较不同的网络权重归一化方案，并评估哪种方案能更好地预测生物学结果。这项任务突显了网络建模中的理论选择如何对模型性能产生实际影响，并要求通过计算实验来做出有原则的决策。[@problem_id:3302995]", "problem": "给定一个由邻接矩阵表示的有向加权基因相互作用图，以及一组通路（每个通路是节点的子集）。需要比较两种用于基于扩散的通路评分的权重归一化方案：行和归一化与行最大值归一化。目标是使用一种有原则且可复现的实验设计，在交叉验证的岭回归设置中，量化哪种归一化方案对药物反应具有更好的预测性能。\n\n定义与基本原理：\n- 令 $W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$ 为一个包含 $n$ 个节点的有向加权邻接矩阵，其中 $W_{ij}$ 是从节点 $i$到节点 $j$ 的权重。\n- 行和归一化生成矩阵 $P^{(\\mathrm{sum})}$，其元素为 $P^{(\\mathrm{sum})}_{ij} = W_{ij} / \\sum_{j} W_{ij}$（对于行和为正的行），否则为零行。\n- 行最大值归一化生成矩阵 $P^{(\\mathrm{max})}$，其元素为 $P^{(\\mathrm{max})}_{ij} = W_{ij} / \\max_{j} W_{ij}$（对于行最大值为正的行），否则为零行。\n- 扩散通过归一化矩阵的矩阵指数进行建模。对于扩散时间 $\\,\\tau  0\\,$ 和归一化矩阵 $P$，定义扩散算子 $H(\\tau, P) = \\exp(\\tau P)$。这是线性常微分方程 $\\frac{d x(t)}{dt} = P x(t)$ 的解算子，满足 $x(\\tau) = \\exp(\\tau P) x(0)$。\n- 对于一个样本特异性的基因活性向量 $g \\in \\mathbb{R}^{n}$，定义扩散后的活性为 $h = H(\\tau, P) g$。\n- 对于一个通路 $p \\subset \\{0,1,\\dots,n-1\\}$，其得分定义为其节点上扩散活性的平均值：$s_{p}(g; \\tau, P) = \\frac{1}{|p|} \\sum_{i \\in p} h_{i}$。\n- 对于一个包含 $m$ 个通路的集合 $\\{p_{1},\\dots,p_{m}\\}$，将通路得分收集到一个特征向量 $f(g; \\tau, P) \\in \\mathbb{R}^{m}$ 中，其分量为 $f_{k}(g; \\tau, P) = s_{p_{k}}(g; \\tau, P)$。\n- 给定一组带有基因活性向量 $\\{g^{(r)}\\}_{r=1}^{s}$ 的样本和药物反应 $y \\in \\mathbb{R}^{s}$，使用岭回归定义一个线性预测器。对于设计矩阵 $X \\in \\mathbb{R}^{s \\times m}$（其行是 $f(g^{(r)}; \\tau, P)^{\\top}$）和正则化参数 $\\lambda  0$，岭估计量为 $\\hat{w}_{\\lambda} = (X^{\\top} X + \\lambda I)^{-1} X^{\\top} y$。预测性能通过 $K$-折交叉验证中留出数据的均方误差（MSE）来衡量：$\\mathrm{MSE} = \\frac{1}{N_{\\mathrm{val}}} \\sum_{u \\in \\mathrm{val}} (\\hat{y}^{(u)} - y^{(u)})^{2}$，其中 $\\hat{y}^{(u)} = x^{(u)\\top} \\hat{w}_{\\lambda}$ 且 $x^{(u)}$ 是第 $u$ 个验证样本的特征向量。\n\n用于选择归一化方案的实验设计：\n- 对于下述每个测试用例，首先选择一个生成归一化方案 $P^{(\\star)} \\in \\{P^{(\\mathrm{sum})}, P^{(\\mathrm{max})}\\}$ 和参数 $(\\tau, \\beta)$，然后生成一个合成数据集：\n  1. 抽取 $s$ 个独立的样本 $g^{(r)} \\sim \\mathcal{N}(0, I_{n})$。\n  2. 计算设计矩阵 $X^{(\\star)}$，其第 $r$ 行为 $f(g^{(r)}; \\tau, P^{(\\star)})^{\\top}$。\n  3. 通过 $y = X^{(\\star)} \\beta + \\epsilon$ 生成药物反应向量，其中 $\\epsilon \\sim \\mathcal{N}(0, \\sigma^{2} I_{s})$ 且 $\\sigma$ 非常小。\n- 为了进行模型选择，在同一数据集上，使用与训练中相同的 $(\\tau, \\lambda)$，通过 $K$-折交叉验证为每个候选归一化方案 $P^{(\\mathrm{sum})}$ 和 $P^{(\\mathrm{max})}$ 计算交叉验证的均方误差。选择平均均方误差较低的归一化方案；使用平局规则：如果 $|\\mathrm{MSE}_{\\mathrm{sum}} - \\mathrm{MSE}_{\\mathrm{max}}| \\le \\epsilon_{\\mathrm{tie}}$，则优先选择行和归一化。\n\n测试套件规范：\n对于所有用例，不要添加截距项，也不要对特征进行标准化。在同一个用例中，对两种归一化方案使用相同的折分区。不使用角度。没有物理单位。所有索引都是从零开始的。\n\n- 用例 A（理想情况；生成方案为行和归一化）：\n  - 图大小 $n = 7$。\n  - 邻接矩阵 $W^{(A)}$ 由以下非零项给出：\n    - 行 $0$：$(0,1) = 2.0$, $(0,2) = 0.5$。\n    - 行 $1$：$(1,2) = 1.5$, $(1,3) = 1.0$。\n    - 行 $2$：$(2,3) = 2.0$。\n    - 行 $3$：$(3,4) = 0.5$, $(3,5) = 1.5$。\n    - 行 $4$：$(4,5) = 2.0$, $(4,6) = 1.0$。\n    - 行 $5$：$(5,6) = 1.0$。\n    - 行 $6$：$(6,0) = 0.2$。\n    所有其他项均为 $0.0$。\n  - 通路：$p_{1} = \\{0,1,2\\}$, $p_{2} = \\{3,4\\}$, $p_{3} = \\{5,6\\}$；因此 $m = 3$。\n  - 扩散时间 $\\tau = 0.7$。\n  - 样本数 $s = 60$，使用随机种子 $\\mathrm{seed} = 42$ 生成。\n  - 生成归一化方案 $P^{(\\star)} = P^{(\\mathrm{sum})}$。\n  - 系数 $\\beta = [1.0, -0.6, 0.9]^{\\top}$。\n  - 噪声标准差 $\\sigma = 10^{-6}$。\n  - 交叉验证折数 $K = 5$，折分配的随机种子为 $\\mathrm{cv\\_seed} = 123$。\n  - 岭正则化 $\\lambda = 10^{-8}$。\n  - 平局阈值 $\\epsilon_{\\mathrm{tie}} = 10^{-9}$。\n\n- 用例 B（备选方案；生成方案为行最大值归一化）：\n  - 图大小 $n = 7$。\n  - 邻接矩阵 $W^{(B)}$ 由以下非零项给出：\n    - 行 $0$：$(0,1) = 10.0$, $(0,2) = 1.0$。\n    - 行 $1$：$(1,2) = 8.0$。\n    - 行 $2$：$(2,3) = 2.0$, $(2,4) = 0.5$。\n    - 行 $3$：$(3,4) = 7.0$, $(3,5) = 1.0$。\n    - 行 $4$：$(4,5) = 3.0$。\n    - 行 $5$：$(5,6) = 5.0$。\n    - 行 $6$：$(6,0) = 0.1$, $(6,2) = 4.0$。\n    所有其他项均为 $0.0$。\n  - 通路：$p_{1} = \\{0,1,2\\}$, $p_{2} = \\{3,4\\}$, $p_{3} = \\{5,6\\}$；因此 $m = 3$。\n  - 扩散时间 $\\tau = 0.9$。\n  - 样本数 $s = 80$，使用随机种子 $\\mathrm{seed} = 1337$ 生成。\n  - 生成归一化方案 $P^{(\\star)} = P^{(\\mathrm{max})}$。\n  - 系数 $\\beta = [0.7, 1.2, -0.9]^{\\top}$。\n  - 噪声标准差 $\\sigma = 10^{-6}$。\n  - 交叉验证折数 $K = 5$，折分配的随机种子为 $\\mathrm{cv\\_seed} = 321$。\n  - 岭正则化 $\\lambda = 10^{-8}$。\n  - 平局阈值 $\\epsilon_{\\mathrm{tie}} = 10^{-9}$。\n\n- 用例 C（边缘情况；每行只有一个出边，意味着两种归一化是相同的）：\n  - 图大小 $n = 7$。\n  - 邻接矩阵 $W^{(C)}$ 由以下非零项给出：\n    - 行 $0$：$(0,1) = 3.0$。\n    - 行 $1$：$(1,2) = 1.0$。\n    - 行 $2$：$(2,3) = 2.0$。\n    - 行 $3$：$(3,4) = 5.0$。\n    - 行 $4$：$(4,5) = 4.0$。\n    - 行 $5$：$(5,6) = 2.5$。\n    - 行 $6$：$(6,0) = 0.7$。\n    所有其他项均为 $0.0$。\n  - 通路：$p_{1} = \\{0,1,2\\}$, $p_{2} = \\{3,4\\}$, $p_{3} = \\{5,6\\}$；因此 $m = 3$。\n  - 扩散时间 $\\tau = 0.5$。\n  - 样本数 $s = 40$，使用随机种子 $\\mathrm{seed} = 2023$ 生成。\n  - 生成归一化方案 $P^{(\\star)} = P^{(\\mathrm{sum})}$ 或 $P^{(\\mathrm{max})}$（在这种情况下它们是相同的）。\n  - 系数 $\\beta = [0.3, -1.1, 0.5]^{\\top}$。\n  - 噪声标准差 $\\sigma = 10^{-6}$。\n  - 交叉验证折数 $K = 5$，折分配的随机种子为 $\\mathrm{cv\\_seed} = 999$。\n  - 岭正则化 $\\lambda = 10^{-8}$。\n  - 平局阈值 $\\epsilon_{\\mathrm{tie}} = 10^{-9}$。\n\n程序所需行为：\n- 实现两种归一化方案、通过矩阵指数计算的扩散算子、通过对通路上节点的扩散活性求平均值进行通路评分的方法，以及用于计算每种归一化方案的均方误差的 $K$-折交叉验证岭回归。\n- 对于每个用例，选择平均均方误差较低的归一化方案。如果绝对差小于或等于 $\\epsilon_{\\mathrm{tie}}$，则选择行和归一化。\n- 您的程序应生成一行输出，其中包含按 A、B、C 顺序排列的结果，形式为方括号内的逗号分隔列表。将行和归一化的选择编码为整数 $0$，行最大值归一化的选择编码为整数 $1$。例如，输出可以是 $[0,1,0]$。\n\n此问题中没有物理单位。不需要用户输入。所有随机性必须使用提供的种子。", "solution": "问题陈述经过严格审查，被确定为是有效的。它有科学依据，在数学上是适定的、客观且自洽的。所有必要的数据、参数和程序都以足够的精度进行了规定，从而能够得到唯一且可复现的解。该实验设计通过合成数据生成，比较两种归一化方案在交叉验证回归任务中的预测性能，是计算方法学研究中的一种标准且有原则的方法。\n\n解决方案将遵循指定的算法流程来实现。问题的核心是，针对三个不同的测试用例，确定两种图归一化方案——行和归一化或行最大值归一化——哪一种能为合成的药物反应变量提供更好的预测模型。\n\n首先，我们为给定的加权邻接矩阵 `$W \\in \\mathbb{R}_{\\ge 0}^{n \\times n}$` 定义两种归一化方案。\n1.  **行和归一化**：结果矩阵 `$P^{(\\mathrm{sum})}$` 的计算方式为 `$P^{(\\mathrm{sum})}_{ij} = W_{ij} / \\sum_{k} W_{ik}$`。如果某行的和为零，则 `$P^{(\\mathrm{sum})}$` 中的对应行也将是零向量。\n2.  **行最大值归一化**：结果矩阵 `$P^{(\\mathrm{max})}$` 的计算方式为 `$P^{(\\mathrm{max})}_{ij} = W_{ij} / \\max_{k} W_{ik}$`。如果某行的最大值为零（即该行全为零），则 `$P^{(\\mathrm{max})}$` 中的对应行也将是零向量。\n\n该生物模型的核心是网络扩散。给定一组初始基因活性，表示为向量 `$g \\in \\mathbb{R}^n$`，它们在网络中经过时间 `$\\tau > 0$` 的传播过程被建模。对于一个归一化矩阵 `$P$`，系统在时间 `$\\tau$` 的状态，记作 `$h \\in \\mathbb{R}^n$`，由线性常微分方程组 `$\\frac{d x(t)}{dt} = P x(t)$` 的解给出，初始条件为 `$x(0) = g$`。解为 `$x(\\tau) = \\exp(\\tau P) g$`。因此，扩散后的活性向量是 `$h = H(\\tau, P) g$`，其中 `$H(\\tau, P) = \\exp(\\tau P)$` 是扩散算子，通过矩阵指数计算。\n\n根据扩散后的活性 `$h$`，我们为预测模型推导特征。每个特征对应一个预定义的通路（一组基因/节点）。通路 `$p_k$` 的分数是其成员节点扩散活性的平均值：`$s_{p_k}(g; \\tau, P) = \\frac{1}{|p_k|} \\sum_{i \\in p_k} h_i$`。对于一个给定的基因活性为 `$g^{(r)}$` 的样本，我们计算一个特征向量 `$f(g^{(r)}; \\tau, P) \\in \\mathbb{R}^m$`，其中包含了所有 `$m$` 个通路的分数。\n\n主要的分析流程是一个模拟实验。对于每个测试用例，我们首先生成一个合成数据集。这个过程需要选择一个“基准真相”或生成归一化方案，`$P^{(\\star)}$`。\n1.  从标准正态分布中抽取 `$s$` 个初始基因活性向量 `$\\{g^{(r)}\\}_{r=1}^s$`，即 `$g^{(r)} \\sim \\mathcal{N}(0, I_n)$`。\n2.  使用生成方案 `$P^{(\\star)}$` 和扩散时间 `$\\tau$`，构建“真实”设计矩阵 `$X^{(\\star)} \\in \\mathbb{R}^{s \\times m}$`，其中第 `$r$` 行为特征向量 `$f(g^{(r)}; \\tau, P^{(\\star)})^{\\top}$`。\n3.  使用线性模型 `$y = X^{(\\star)} \\beta + \\epsilon$` 创建一个药物反应向量 `$y \\in \\mathbb{R}^s$`，其中 `$\\beta \\in \\mathbb{R}^m$` 是给定的真实系数向量，`$\\epsilon \\sim \\mathcal{N}(0, \\sigma^2 I_s)` 是一个小的噪声项。\n\n有了合成数据集 `$(\\{g^{(r)}\\}, y)`，我们评估两种候选归一化方案，`$P^{(\\mathrm{sum})}$` 和 `$P^{(\\mathrm{max})}$`。\n1.  对于每种方案，我们首先使用相同的初始基因活性 `$\\{g^{(r)}\\}` 生成其对应的设计矩阵，`$X^{(\\mathrm{sum})}$` 和 `$X^{(\\mathrm{max})}$`。\n2.  每种方案的性能通过其从特征（`$X^{(\\mathrm{sum})}$` 或 `$X^{(\\mathrm{max})}$`）预测 `$y$` 的能力来评估，评估方法为岭回归。该性能通过 `$K$`-折交叉验证估计的均方误差（MSE）来衡量。\n3.  在交叉验证的每一折中，使用训练部分的数据训练一个岭回归模型。权重向量 `$\\hat{w}_{\\lambda}$` 根据公式 `$\\hat{w}_{\\lambda} = (X_{\\mathrm{train}}^{\\top} X_{\\mathrm{train}} + \\lambda I)^{-1} X_{\\mathrm{train}}^{\\top} y_{\\mathrm{train}}$` 计算，其中 `$\\lambda$` 是正则化参数。\n4.  然后，这个训练好的模型被用来对留出的验证数据 `$X_{\\mathrm{val}}$` 进行预测 `$\\hat{y}_{\\mathrm{val}}$`，并计算该折的均方误差为 `$\\frac{1}{N_{\\mathrm{val}}} \\sum (\\hat{y}_{\\mathrm{val}} - y_{\\mathrm{val}})^2$`。\n5.  每种归一化方案的最终性能指标是所有 `$K$` 折的平均均方误差。为了确保公平比较，两种方案使用相同的随机折划分。\n\n最后，根据计算出的平均均方误差 `$\\mathrm{MSE}_{\\mathrm{sum}}$` 和 `$\\mathrm{MSE}_{\\mathrm{max}}$` 作出决定：\n- 如果 `$|\\mathrm{MSE}_{\\mathrm{sum}} - \\mathrm{MSE}_{\\mathrm{max}}| \\le \\epsilon_{\\mathrm{tie}}$`，则认为两种方案打平，并根据指定的平局决胜规则选择行和归一化（编码为 `$0$`）。\n- 否则，选择平均均方误差严格更低的归一化方案（行和归一化编码为 `$0$`，行最大值归一化编码为 `$1$`）。\n\n这个完整的过程将为指定的三个测试用例中的每一个实施，使用给定的参数、矩阵和随机种子以确保可复现性。该实现依赖于 `numpy` 进行线性代数和随机数生成，以及 `scipy.linalg.expm` 进行矩阵指数的数值稳定计算。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\nfrom scipy.linalg import expm\n\n# from scipy import ...\n\ndef solve():\n    \"\"\"\n    Main function to run the specified test cases and print the results.\n    \"\"\"\n\n    def construct_w(n, non_zero_entries):\n        \"\"\"Constructs the adjacency matrix W from a list of non-zero entries.\"\"\"\n        W = np.zeros((n, n), dtype=np.float64)\n        for (i, j), val in non_zero_entries:\n            W[i, j] = val\n        return W\n\n    def normalize(W, scheme):\n        \"\"\"Normalizes the matrix W using either row-sum or row-max.\"\"\"\n        P = np.zeros_like(W)\n        if scheme == 'sum':\n            row_sums = W.sum(axis=1)\n            non_zero_rows = row_sums > 0\n            P[non_zero_rows, :] = W[non_zero_rows, :] / row_sums[non_zero_rows, np.newaxis]\n        elif scheme == 'max':\n            row_maxs = W.max(axis=1)\n            non_zero_rows = row_maxs > 0\n            P[non_zero_rows, :] = W[non_zero_rows, :] / row_maxs[non_zero_rows, np.newaxis]\n        return P\n\n    def compute_features(g_samples, P, tau, pathways):\n        \"\"\"Computes pathway scores as features for a set of samples.\"\"\"\n        n = P.shape[0]\n        s = g_samples.shape[0]\n        m = len(pathways)\n        \n        H = expm(tau * P)\n        \n        X = np.zeros((s, m))\n        for r in range(s):\n            g = g_samples[r, :]\n            h = H @ g\n            for k, p in enumerate(pathways):\n                if len(p) > 0:\n                    score = np.mean(h[p])\n                else:\n                    score = 0.0\n                X[r, k] = score\n        return X\n\n    def k_fold_cross_validation(X, y, K, lambda_, cv_seed):\n        \"\"\"Performs K-fold cross-validation for ridge regression.\"\"\"\n        s = X.shape[0]\n        m = X.shape[1]\n        \n        rng = np.random.default_rng(cv_seed)\n        indices = np.arange(s)\n        rng.shuffle(indices)\n        \n        fold_indices = np.array_split(indices, K)\n        \n        fold_mses = []\n        for k in range(K):\n            val_idx = fold_indices[k]\n            train_idx = np.concatenate([fold_indices[i] for i in range(K) if i != k])\n            \n            X_train, y_train = X[train_idx], y[train_idx]\n            X_val, y_val = X[val_idx], y[val_idx]\n            \n            # Ridge regression training\n            I = np.identity(m)\n            try:\n                # w_hat = (X_train.T @ X_train + lambda_ * I)^-1 @ X_train.T @ y_train\n                term1 = np.linalg.inv(X_train.T @ X_train + lambda_ * I)\n                term2 = X_train.T @ y_train\n                w_hat = term1 @ term2\n            except np.linalg.LinAlgError:\n                # Fallback for singular matrix, although unlikely with lambda > 0\n                w_hat = np.linalg.pinv(X_train.T @ X_train + lambda_ * I) @ (X_train.T @ y_train)\n\n            # Prediction and MSE\n            y_pred = X_val @ w_hat\n            mse = np.mean((y_pred - y_val)**2)\n            fold_mses.append(mse)\n            \n        return np.mean(fold_mses)\n\n    test_cases = [\n        # Case A\n        {\n            \"name\": \"A\",\n            \"n\": 7,\n            \"W_entries\": [\n                ((0, 1), 2.0), ((0, 2), 0.5),\n                ((1, 2), 1.5), ((1, 3), 1.0),\n                ((2, 3), 2.0),\n                ((3, 4), 0.5), ((3, 5), 1.5),\n                ((4, 5), 2.0), ((4, 6), 1.0),\n                ((5, 6), 1.0),\n                ((6, 0), 0.2)\n            ],\n            \"pathways\": [[0, 1, 2], [3, 4], [5, 6]],\n            \"tau\": 0.7,\n            \"s\": 60,\n            \"seed\": 42,\n            \"gen_norm_type\": \"sum\",\n            \"beta\": np.array([1.0, -0.6, 0.9]),\n            \"sigma\": 1e-6,\n            \"K\": 5,\n            \"cv_seed\": 123,\n            \"lambda_\": 1e-8,\n            \"epsilon_tie\": 1e-9\n        },\n        # Case B\n        {\n            \"name\": \"B\",\n            \"n\": 7,\n            \"W_entries\": [\n                ((0, 1), 10.0), ((0, 2), 1.0),\n                ((1, 2), 8.0),\n                ((2, 3), 2.0), ((2, 4), 0.5),\n                ((3, 4), 7.0), ((3, 5), 1.0),\n                ((4, 5), 3.0),\n                ((5, 6), 5.0),\n                ((6, 0), 0.1), ((6, 2), 4.0)\n            ],\n            \"pathways\": [[0, 1, 2], [3, 4], [5, 6]],\n            \"tau\": 0.9,\n            \"s\": 80,\n            \"seed\": 1337,\n            \"gen_norm_type\": \"max\",\n            \"beta\": np.array([0.7, 1.2, -0.9]),\n            \"sigma\": 1e-6,\n            \"K\": 5,\n            \"cv_seed\": 321,\n            \"lambda_\": 1e-8,\n            \"epsilon_tie\": 1e-9\n        },\n        # Case C\n        {\n            \"name\": \"C\",\n            \"n\": 7,\n            \"W_entries\": [\n                ((0, 1), 3.0),\n                ((1, 2), 1.0),\n                ((2, 3), 2.0),\n                ((3, 4), 5.0),\n                ((4, 5), 4.0),\n                ((5, 6), 2.5),\n                ((6, 0), 0.7)\n            ],\n            \"pathways\": [[0, 1, 2], [3, 4], [5, 6]],\n            \"tau\": 0.5,\n            \"s\": 40,\n            \"seed\": 2023,\n            \"gen_norm_type\": \"sum\", # or max, they are identical\n            \"beta\": np.array([0.3, -1.1, 0.5]),\n            \"sigma\": 1e-6,\n            \"K\": 5,\n            \"cv_seed\": 999,\n            \"lambda_\": 1e-8,\n            \"epsilon_tie\": 1e-9\n        }\n    ]\n\n    results = []\n    for case in test_cases:\n        # Construct W matrix\n        W = construct_w(case[\"n\"], case[\"W_entries\"])\n\n        # Create data generator\n        rng_data = np.random.default_rng(case[\"seed\"])\n        \n        # 1. Generate synthetic data\n        g_samples = rng_data.standard_normal(size=(case[\"s\"], case[\"n\"]))\n        P_star = normalize(W, case[\"gen_norm_type\"])\n        X_star = compute_features(g_samples, P_star, case[\"tau\"], case[\"pathways\"])\n        epsilon = rng_data.normal(loc=0, scale=case[\"sigma\"], size=case[\"s\"])\n        y = X_star @ case[\"beta\"] + epsilon\n\n        # 2. Evaluate row-sum normalization\n        P_sum = normalize(W, 'sum')\n        X_sum = compute_features(g_samples, P_sum, case[\"tau\"], case[\"pathways\"])\n        mse_sum = k_fold_cross_validation(X_sum, y, case[\"K\"], case[\"lambda_\"], case[\"cv_seed\"])\n\n        # 3. Evaluate row-max normalization\n        P_max = normalize(W, 'max')\n        X_max = compute_features(g_samples, P_max, case[\"tau\"], case[\"pathways\"])\n        mse_max = k_fold_cross_validation(X_max, y, case[\"K\"], case[\"lambda_\"], case[\"cv_seed\"])\n\n        # 4. Make decision\n        if abs(mse_sum - mse_max) = case[\"epsilon_tie\"]:\n            results.append(0)  # Prefer row-sum in case of a tie\n        elif mse_sum  mse_max:\n            results.append(0)\n        else:\n            results.append(1)\n\n    print(f\"[{','.join(map(str, results))}]\")\n\nsolve()\n```", "id": "3302995"}]}