{"hands_on_practices": [{"introduction": "皮尔逊相关性是网络推断的常见起点，但它仅能捕捉线性关系。本练习旨在通过一个思想实验，帮助您建立关于互信息为何是检测基因调控中常见的复杂非线性相互作用的更强大工具的直觉。理解相关性的局限性对于选择合适的关联度量至关重要。[@problem_id:3331801]", "problem": "在计算系统生物学中，基因调控网络推断通常始于基因表达变量之间的基本统计依赖关系。两个随机变量 $X$ 和 $Y$ 之间的 Pearson 相关系数定义为 $\\rho_{XY} = \\dfrac{\\operatorname{Cov}(X,Y)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}}$，其中 $\\operatorname{Cov}(X,Y) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])]$。对于连续随机变量，互信息（MI）定义为 $I(X;Y) = \\int \\int p_{X,Y}(x,y) \\log \\left( \\dfrac{p_{X,Y}(x,y)}{p_X(x)p_Y(y)} \\right) \\, dx \\, dy$，其中 $p_{X,Y}$ 是联合密度，$p_X$ 和 $p_Y$ 是边缘密度。根据定义，$I(X;Y) = 0$ 当且仅当 $X$ 和 $Y$ 相互独立，而当 $Y$ 概率性地依赖于 $X$ 时，$I(X;Y) > 0$。\n\n你需要构建一对具有相同 Pearson 相关性但不同互信息的变量，并从非线性调控的角度解释其生物学意义。请考虑以下选项，每个选项都提出了一种构建和一种解释。选择唯一一个正确构建了这样一对变量，并在基因调控网络推断的框架内提供了科学合理解释的选项。\n\nA. 令 $X \\sim \\mathcal{N}(0,1)$ 且 $\\epsilon \\sim \\mathcal{N}(0,1)$ 相互独立。定义 $Y_1 = \\epsilon$ 和 $Y_2 = X + \\epsilon$。断言：$\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ 且 $I(X;Y_1) = I(X;Y_2)$，因为相关性完全决定了互信息。生物学解释：在这些情况下，相关性足以推断调控关系。\n\nB. 令 $X \\sim \\mathcal{N}(0,1)$ 且 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 相互独立，其中 $\\sigma^2 \\in (0,\\infty)$。定义 $Y_1 = \\epsilon$ 和 $Y_2 = X^2 + \\epsilon$。断言：$\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$，同时 $I(X;Y_1) = 0$ 且 $I(X;Y_2) > 0$。生物学解释：非线性调控关系（例如，阈值效应或协同激活）可以产生零相关性但为正的互信息，因此仅依赖相关性可能会错过互信息能够检测到的真实调控相互作用。\n\nC. 令 $X \\sim \\mathcal{N}(0,1)$。构建两对变量 $(X,Y_1)$ 和 $(X,Y_2)$，使得 $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0.6$。取 $Y_1 = X + \\epsilon_1$ 和 $Y_2 = \\operatorname{sign}(X) + \\epsilon_2$，其中 $\\epsilon_1,\\epsilon_2$ 是经过选择以使相关性匹配的独立零均值噪声。断言：根据数据处理不等式，$I(X;Y_1) = I(X;Y_2)$，因此相等的相关性意味着相等的互信息。生物学解释：两种相互作用在效果上都是线性的且强度相等。\n\nD. 令 $X$ 为一个对称的零均值连续变量（例如，$X \\sim \\mathcal{N}(0,1)$），并令 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 相互独立，其中 $\\sigma^2 \\in (0,\\infty)$。定义 $Y_1 = |X| + \\epsilon$ 和 $Y_2 = \\epsilon$。断言：$\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ 且 $I(X;Y_1) = I(X;Y_2) = 0$。生物学解释：当相关性为零时，没有可推断的调控关系，因此互信息没有任何增益。\n\n哪个选项是正确的？", "solution": "### 第 1 步：问题验证\n\n**1.1. 提取已知条件：**\n*   **Pearson 相关系数**: $\\rho_{XY} = \\dfrac{\\operatorname{Cov}(X,Y)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y)}}$\n*   **协方差**: $\\operatorname{Cov}(X,Y) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y - \\mathbb{E}[Y])]$\n*   **连续变量的互信息 (MI)**: $I(X;Y) = \\int \\int p_{X,Y}(x,y) \\log \\left( \\dfrac{p_{X,Y}(x,y)}{p_X(x)p_Y(y)} \\right) \\, dx \\, dy$\n*   **MI 的性质**: $I(X;Y) = 0$ 当且仅当 $X$ 和 $Y$ 相互独立。如果 $Y$ 概率性地依赖于 $X$，则 $I(X;Y) > 0$。\n*   **任务**: 构建一对具有相同 Pearson 相关性但不同互信息的变量，并从非线性调控的角度解释其生物学意义。\n*   **背景**: 计算系统生物学，基因调控网络推断。\n\n**1.2. 使用提取的已知条件进行验证：**\n*   **科学性**: Pearson 相关性和互信息的定义是标准且正确的。问题的基本前提——相关性和 MI 用于网络推断并可能得出不同结果——是计算生物学中的一个核心概念。这些概念在数学和统计上都是合理的。\n*   **良构性**: 该任务旨在找到一个例子来说明相关性与 MI 的一个已知属性。问题要求从一系列选项中选出正确的构建和解释。预计会有一个唯一的正确选项。问题是良构的。\n*   **客观性**: 问题使用标准的数学和统计定义进行陈述。语言精确且无偏见。\n*   **完整性**: 问题提供了评估选项所需的所有必要定义和背景。它是自洽的。\n*   **现实性**: 基因调控网络的背景是现实的。使用像相关性和 MI 这样的统计量是标准做法。选项中提出的模型（例如 $Y = f(X) + \\text{noise}$）是对此类关系的常见简化模型。\n*   **未检测到其他缺陷**: 该问题并非无聊、隐喻性或自相矛盾的。它解决了该领域的一个核心概念问题。\n\n**1.3. 结论与行动：**\n问题陈述是**有效**的。我将继续进行解答和选项评估。\n\n### 第 2 步：解决问题并评估选项\n\n核心思想是找到一个相关性为零但依赖关系仍然存在的场景。相关性衡量*线性*依赖关系。如果依赖关系是纯粹非线性的，相关性可能为零。而互信息则能捕捉*任何*类型的统计依赖关系，无论是线性的还是非线性的。\n\n所以，我需要寻找一个满足以下条件的选项：\n1.  构建了两对变量，例如 $(X, Y_1)$ 和 $(X, Y_2)$。\n2.  $\\rho_{X,Y_1} = \\rho_{X,Y_2}$。一个常见的选择是 $\\rho=0$。\n3.  $I(X;Y_1) \\neq I(X;Y_2)$。\n4.  其解释正确说明了发生这种情况的原因以及它对网络推断的意义。\n\n让我们分析每个选项。\n\n---\n\n**选项 A：**\n*   **构建：** $X \\sim \\mathcal{N}(0,1)$，$\\epsilon \\sim \\mathcal{N}(0,1)$ 相互独立。$Y_1 = \\epsilon$，$Y_2 = X + \\epsilon$。\n*   **断言分析：**\n    *   **对 $(X, Y_1)$ 的相关性**：$Y_1 = \\epsilon$。根据定义，$X$ 和 $Y_1$ 相互独立。因此，$\\operatorname{Cov}(X, Y_1) = 0$，这意味着 $\\rho_{X,Y_1} = 0$。\n    *   **对 $(X, Y_2)$ 的相关性**：$Y_2 = X + \\epsilon$。\n        *   $\\mathbb{E}[X] = 0$，$\\mathbb{E}[Y_2] = \\mathbb{E}[X+\\epsilon] = \\mathbb{E}[X] + \\mathbb{E}[\\epsilon] = 0 + 0 = 0$。\n        *   $\\operatorname{Cov}(X, Y_2) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y_2 - \\mathbb{E}[Y_2])] = \\mathbb{E}[X \\cdot Y_2] = \\mathbb{E}[X(X+\\epsilon)] = \\mathbb{E}[X^2 + X\\epsilon] = \\mathbb{E}[X^2] + \\mathbb{E}[X\\epsilon]$。\n        *   由于 $X$ 和 $\\epsilon$ 相互独立，$\\mathbb{E}[X\\epsilon] = \\mathbb{E}[X]\\mathbb{E}[\\epsilon] = 0 \\cdot 0 = 0$。\n        *   $\\mathbb{E}[X^2] = \\operatorname{Var}(X) + (\\mathbb{E}[X])^2 = 1 + 0^2 = 1$。\n        *   所以，$\\operatorname{Cov}(X, Y_2) = 1$。\n        *   $\\operatorname{Var}(X) = 1$。\n        *   $\\operatorname{Var}(Y_2) = \\operatorname{Var}(X+\\epsilon) = \\operatorname{Var}(X) + \\operatorname{Var}(\\epsilon)$（因为 $X, \\epsilon$ 相互独立） $= 1 + 1 = 2$。\n        *   $\\rho_{X,Y_2} = \\dfrac{\\operatorname{Cov}(X, Y_2)}{\\sqrt{\\operatorname{Var}(X)\\operatorname{Var}(Y_2)}} = \\dfrac{1}{\\sqrt{1 \\cdot 2}} = \\dfrac{1}{\\sqrt{2}}$。\n    *   **关于相关性的结论：** 断言 $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ 是**错误**的。我们有 $\\rho_{X,Y_1} = 0$ 和 $\\rho_{X,Y_2} = 1/\\sqrt{2}$。相关性不相同。\n    *   **MI 断言分析：** 断言 $I(X;Y_1) = I(X;Y_2)$ 因为相关性完全决定互信息，这在根本上是**错误**的。对于高斯变量，存在直接关系 ($I = -0.5 \\log(1-\\rho^2)$)，但这并非普遍适用。这里，$(X, Y_2)$ 是一个二元高斯分布。\n        *   $I(X;Y_1) = I(X;\\epsilon) = 0$ 因为 $X$ 和 $\\epsilon$ 相互独立。\n        *   对于对 $(X, Y_2)$，由于它们是相关的，它们不是独立的，所以 $I(X;Y_2) > 0$。\n        *   因此 $I(X;Y_1) \\neq I(X;Y_2)$。但选项中给出的原因和相关性计算都是错误的。\n*   **解释：** “在这些情况下，相关性足以推断调控关系”是错误的。这与问题的整个前提相矛盾。\n*   **对 A 的判决：** 不正确。计算错误，核心断言错误。\n\n---\n\n**选项 B：**\n*   **构建：** $X \\sim \\mathcal{N}(0,1)$，$\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 相互独立，其中 $\\sigma^2 \\in (0,\\infty)$。定义 $Y_1 = \\epsilon$ 和 $Y_2 = X^2 + \\epsilon$。\n*   **断言分析：**\n    *   **第 1 对：$(X, Y_1)$** 其中 $Y_1=\\epsilon$。\n        *   由于 $X$ 和 $Y_1$ 相互独立，$\\operatorname{Cov}(X,Y_1) = 0$，所以 $\\rho_{X,Y_1} = 0$。\n        *   由于 $X$ 和 $Y_1$ 相互独立，$I(X;Y_1) = 0$。\n    *   **第 2 对：$(X, Y_2)$** 其中 $Y_2=X^2 + \\epsilon$。\n        *   **相关性：**\n            *   $\\mathbb{E}[X] = 0$。\n            *   $\\mathbb{E}[Y_2] = \\mathbb{E}[X^2 + \\epsilon] = \\mathbb{E}[X^2] + \\mathbb{E}[\\epsilon]$。\n            *   $\\mathbb{E}[\\epsilon] = 0$。\n            *   $\\mathbb{E}[X^2] = \\operatorname{Var}(X) + (\\mathbb{E}[X])^2 = 1 + 0^2 = 1$。\n            *   所以，$\\mathbb{E}[Y_2] = 1$。\n            *   $\\operatorname{Cov}(X, Y_2) = \\mathbb{E}[(X - \\mathbb{E}[X])(Y_2 - \\mathbb{E}[Y_2])] = \\mathbb{E}[X(Y_2 - 1)] = \\mathbb{E}[X(X^2 + \\epsilon - 1)] = \\mathbb{E}[X^3 + X\\epsilon - X]$。\n            *   $\\operatorname{Cov}(X, Y_2) = \\mathbb{E}[X^3] + \\mathbb{E}[X\\epsilon] - \\mathbb{E}[X]$。\n            *   由于 $X \\sim \\mathcal{N}(0,1)$，它是一个围绕 0 的对称分布。所有奇数阶矩均为零。所以，$\\mathbb{E}[X] = 0$ 和 $\\mathbb{E}[X^3] = 0$。\n            *   由于 $X$ 和 $\\epsilon$ 相互独立且 $\\mathbb{E}[\\epsilon]=0$，$\\mathbb{E}[X\\epsilon] = \\mathbb{E}[X]\\mathbb{E}[\\epsilon] = 0 \\cdot 0 = 0$。\n            *   因此，$\\operatorname{Cov}(X, Y_2) = 0 + 0 - 0 = 0$。\n            *   这意味着 $\\rho_{X,Y_2} = 0$。\n        *   **互信息：**\n            *   $Y_2$ 被定义为 $X$ 的函数加上一些噪声。$Y_2 = f(X) + \\epsilon$ 其中 $f(X) = X^2$。\n            *   $X$ 和 $Y_2$ 是否独立？如果它们独立，则 $p(y_2|x) = p(y_2)$。\n            *   给定 $X=x$ 时 $Y_2$ 的条件密度是 $x^2 + \\epsilon$ 的密度。由于 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$，这意味着 $Y_2|X=x \\sim \\mathcal{N}(x^2, \\sigma^2)$。\n            *   条件密度为 $p(y_2|x) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}} \\exp\\left(-\\frac{(y_2-x^2)^2}{2\\sigma^2}\\right)$。\n            *   这个密度明显依赖于 $x$。所以 $X$ 和 $Y_2$ 不独立。\n            *   由于它们不独立，根据提供的 MI 定义，$I(X;Y_2) > 0$。\n    *   **关于断言的结论：**\n        *   我们有 $\\rho_{X,Y_1} = 0$ 和 $\\rho_{X,Y_2} = 0$。所以断言 $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ 是**正确**的。\n        *   我们有 $I(X;Y_1) = 0$（来自独立性）和 $I(X;Y_2) > 0$（来自依赖性）。所以断言 $I(X;Y_1) = 0$ 和 $I(X;Y_2) > 0$ 是**正确**的。\n        *   这两对变量具有相同的 Pearson 相关性（0），但互信息不同（0 vs. >0）。这满足了题目的要求。\n*   **解释：** “非线性调控关系（例如，阈值效应或协同激活）可以产生零相关性但为正的互信息，因此仅依赖相关性可能会错过互信息能够检测到的真实调控相互作用。”\n    *   关系 $Y_2 = X^2 + \\epsilon$ 是非线性关系的经典例子。二次项 $X^2$ 可以模拟一种对称的激活或抑制，其中调节因子 $X$ 无论其浓度是高正值还是高负值（相对于其均值）都具有相同的效果。在生物学上，与浓度平方成正比的项通常模拟了形成同源二聚体，然后该二聚体作为调节因子。\n    *   “零相关性不意味着没有相互作用，而 MI 对这种非线性相互作用敏感”这一解释，是 MI 在网络推断中使用的核心要点。这个解释在科学上是合理的并且直接相关。\n*   **对 B 的判决：** 正确。\n\n---\n\n**选项 C：**\n*   **构建：** $X \\sim \\mathcal{N}(0,1)$。构建两对变量 $(X,Y_1)$ 和 $(X,Y_2)$，使得 $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0.6$。取 $Y_1 = X + \\epsilon_1$ 和 $Y_2 = \\operatorname{sign}(X) + \\epsilon_2$，其中 $\\epsilon_1,\\epsilon_2$ 是经过选择以使相关性匹配的独立零均值噪声。\n*   **断言分析：** `断言：根据数据处理不等式，$I(X;Y_1) = I(X;Y_2)$，因此相等的相关性意味着相等的互信息。`\n    *   `相等的相关性意味着相等的互信息` 这一说法在根本上是**错误**的。这正是该问题旨在解决的误解。互信息和 Pearson 相关性之间的关系通常是复杂的。仅对于二元高斯变量，存在一个简单的单调关系：$I(X;Y) = -\\frac{1}{2} \\log(1 - \\rho_{XY}^2)$。\n    *   对 $(X, Y_1)$ 其中 $Y_1=X+\\epsilon_1$（$\\epsilon_1$ 是高斯噪声）将是二元高斯分布。对 $(X, Y_2)$ 其中 $Y_2=\\operatorname{sign}(X)+\\epsilon_2$ 则不是。函数 $\\operatorname{sign}(X)$ 是强非线性的。因此，没有理由仅仅因为它们的相关性匹配就期望 $I(X;Y_1) = I(X;Y_2)$。\n    *   引用 `数据处理不等式` 是不正确的。该不等式指出，对于马尔可夫链 $A \\to B \\to C$，$I(A;C) \\le I(A;B)$。它不适用于比较两个不同的系统 $(X, Y_1)$ 和 $(X, Y_2)$。\n*   **解释：** `两种相互作用在效果上都是线性的且强度相等。` 这是错误的。由于 $\\operatorname{sign}(X)$ 的阶跃函数性质，关系 $Y_2 = \\operatorname{sign}(X) + \\epsilon_2$ 显然是非线性的。\n*   **对 C 的判决：** 不正确。\n\n---\n\n**选项 D：**\n*   **构建：** $X$ 是一个对称的零均值连续变量（例如，$X \\sim \\mathcal{N}(0,1)$），并令 $\\epsilon \\sim \\mathcal{N}(0,\\sigma^2)$ 相互独立，其中 $\\sigma^2 \\in (0,\\infty)$。定义 $Y_1 = |X| + \\epsilon$ 和 $Y_2 = \\epsilon$。\n*   **断言分析：**\n    *   **第 1 对：$(X, Y_2)$** 其中 $Y_2=\\epsilon$。由于 $X$ 和 $Y_2$ 相互独立，$\\rho_{X,Y_2} = 0$ 且 $I(X;Y_2) = 0$。\n    *   **第 2 对：$(X, Y_1)$** 其中 $Y_1=|X| + \\epsilon$。\n        *   **相关性：** 根据定义 $\\mathbb{E}[X]=0$。$\\operatorname{Cov}(X, Y_1) = \\mathbb{E}[X(|X|+\\epsilon)] - \\mathbb{E}[X]\\mathbb{E}[|X|+\\epsilon] = \\mathbb{E}[X|X|] + \\mathbb{E}[X\\epsilon] - 0$。由于 $X$ 和 $\\epsilon$ 相互独立且均值为零，$\\mathbb{E}[X\\epsilon]=\\mathbb{E}[X]\\mathbb{E}[\\epsilon]=0$。项 $\\mathbb{E}[X|X|]$ 是一个奇函数（$g(x)=x|x|$）关于一个对称概率密度函数 $p_X(x)$ 的期望，其值为零。因此，$\\operatorname{Cov}(X, Y_1) = 0$ 且 $\\rho_{X,Y_1} = 0$。断言 $\\rho_{X,Y_1} = \\rho_{X,Y_2} = 0$ 是正确的。\n        *   **互信息：** 断言是 $I(X;Y_1) = I(X;Y_2) = 0$。这意味着 $I(X;Y_1) = 0$。要使 $I(X;Y_1)$ 为零，$X$ 和 $Y_1$ 必须是独立的。然而，它们并非如此。给定 $X=x$ 时 $Y_1$ 的条件分布是一个正态分布，其均值为 $|x|+\\mathbb{E}[\\epsilon]=|x|$，方差为 $\\sigma^2$。均值明显依赖于 $x$。例如，给定 $X=1$，$Y_1$ 以 $1$ 为中心，而给定 $X=5$，$Y_1$ 以 $5$ 为中心。由于 $Y_1$ 的条件分布依赖于 $X$，这些变量不是独立的，因此 $I(X;Y_1) > 0$。断言 $I(X;Y_1)=0$ 是**错误**的。\n*   **解释：** `当相关性为零时，没有可推断的调控关系，因此互信息没有任何增益。` 这与 $I(X;Y_1)>0$ 的计算结果相矛盾。这种解释正是该问题试图揭露的谬误。\n*   **对 D 的判决：** 不正确。", "answer": "$$\\boxed{B}$$", "id": "3331801"}, {"introduction": "从理论转向实践，本练习将指导您实现一个完整的计算流程。您将学习如何计算关联分数，使用非参数方法（置换检验）评估其统计显著性，并对多重检验进行校正以控制假发现率（FDR）。这套流程是计算生物学家进行网络推断的核心技能。[@problem_id:3331730]", "problem": "考虑一个基因表达数据集，它由一个包含 $n$ 个样本和 $p$ 个基因的矩阵表示。目标是通过检验成对独立性来推断基因间的无向网络，其中如果基因 $i$ 和基因 $j$ 之间独立的原假设被拒绝，则声明它们之间存在一条边。网络推断应基于以下基础：\n\n1. 两个基因 $i$ 和 $j$ 之间的 Pearson 积矩相关系数在标准化数据上定义为其线性关联的样本统计量。\n2. 在两个基因相互独立的原假设下，一个基因的样本标签是可交换的。可以通过随机置换一个基因的样本标签并重新计算相关性来构建一个基于置换的零模型。\n3. 每个成对检验的 $p$ 值应定义为在零模型下，观测到至少与已观测统计量一样极端的检验统计量的概率。\n4. 当同时检验多个假设时，错误发现率 (FDR) 是所有拒绝的假设中错误拒绝的预期比例。Benjamini–Hochberg 程序是一种在指定水平 $\\alpha$ 下控制 FDR 的方法。\n\n您的任务是实现一个程序，从第一性原理出发执行以下步骤：\n\n- 使用两个变量之间 Pearson 相关系数的定义，计算每对基因的观测绝对相关性。\n- 通过将一个基因的样本标签置换 $B$ 次来为每对基因构建一个基于置换的零模型，同时保持每个基因的边缘分布。使用这些置换来近似独立性下的绝对相关性的零分布。\n- 将每对基因的 $p$ 值定义为零分布超过或等于观测绝对相关性的尾部概率。在离散置换设置中使用有限样本调整以避免零 $p$ 值。\n- 从错误发现率的定义和原假设下有效 $p$ 值的顺序统计量属性出发，推导出 Benjamini–Hochberg 程序，以确定在名义 FDR 水平 $\\alpha$ 下应拒绝哪些假设。\n- 通过将拒绝的假设与已知的真实相关基因对的基准真相集进行比较，评估推断网络的经验错误发现比例。\n\n使用以下测试套件。对于每个测试用例，按如下方式模拟基因表达数据：生成一个 $n \\times p$ 的标准正态随机变量矩阵。对于每个植入的边 $(i,j,\\rho)$，将基因 $j$ 的表达重写为 $x_j = \\rho \\, x_i + \\sqrt{1 - \\rho^2} \\, \\epsilon_j$，其中 $\\epsilon_j$ 是一个独立的标准正态向量，使得 $i$ 和 $j$ 之间的总体相关性约为 $\\rho$。假设植入的边之间的索引是不同的。基因索引使用从 0 开始的索引。\n\n- 测试用例 1 (一般情况): $p=20$, $n=60$, $B=200$, $\\alpha=0.1$, 随机种子 $7$, 植入的边\n  $(0,1,0.8)$, $(2,3,0.7)$, $(4,5,0.75)$, $(6,7,0.6)$, $(8,9,0.65)$。\n- 测试用例 2 (全零边情况): $p=15$, $n=50$, $B=200$, $\\alpha=0.1$, 随机种子 $13$, 无植入边。\n- 测试用例 3 (混合效应大小的边界情况): $p=18$, $n=40$, $B=300$, $\\alpha=0.05$, 随机种子 $29$, 植入的边\n  中等强度 $(0,10,0.5)$, $(1,11,0.5)$, $(2,12,0.5)$, $(3,13,0.5)$ 和弱强度 $(4,14,0.3)$, $(5,15,0.3)$, $(6,16,0.3)$, $(7,17,0.3)$。\n\n需遵守的实现细节：\n\n- 使用标准化变量和样本标准差计算样本 Pearson 相关系数。\n- 对于每对 $(i,j)$，通过将基因 $j$ 的样本标签精确置换 $B$ 次来近似零分布，每次置换后重新计算绝对相关性，并计算 $p$ 值为 $(1 + \\text{number of permuted absolute correlations greater than or equal to the observed absolute correlation}) / (1 + B)$。\n- 应用从错误发现率定义推导出的 Benjamini–Hochberg 程序，在每个测试用例的总检验次数 $m = p(p-1)/2$ 中，选择在水平 $\\alpha$ 下的显著基因对。\n\n最终输出规格：\n\n- 对于每个测试用例，计算两个量：被拒绝的假设总数（一个整数）和经验错误发现比例，定义为不在植入边集合中的被拒绝假设数量除以被拒绝假设的总数，约定当没有拒绝时该比例为 $0$。将该比例表示为小数，而不是百分比。\n- 您的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果，每个测试用例的结果是一个形式为 $[D, F]$ 的双元素列表，其中 $D$ 是拒绝的整数数量，$F$ 是小数形式的错误发现比例。例如，输出格式应类似于 $[[D_1,F_1],[D_2,F_2],[D_3,F_3]]$。", "solution": "目标是通过使用 Pearson 相关系数和基于置换的零模型检验每对基因的独立性原假设，来推断基因共表达网络中的边，并使用 Benjamini–Hochberg 程序控制错误发现率。\n\n基本依据和定义：\n\n1. 设 $X \\in \\mathbb{R}^{n \\times p}$ 是包含 $n$ 个样本和 $p$ 个基因的基因表达矩阵。对于基因 $i$ 和基因 $j$，样本向量表示为 $(x_{1i}, \\ldots, x_{ni})$ 和 $(x_{1j}, \\ldots, x_{nj})$。基因 $i$ 的样本均值为 $\\bar{x}_i = \\frac{1}{n} \\sum_{t=1}^n x_{ti}$，样本标准差为 $s_i = \\sqrt{\\frac{1}{n-1} \\sum_{t=1}^n (x_{ti} - \\bar{x}_i)^2}$。标准化变量为 $z_{ti} = \\frac{x_{ti} - \\bar{x}_i}{s_i}$，基因 $j$ 的情况类似。\n2. 基因 $i$ 和 $j$ 之间的 Pearson 积矩相关系数为\n$$\nr_{ij} = \\frac{1}{n-1} \\sum_{t=1}^n z_{ti} z_{tj}.\n$$\n我们使用观测到的绝对相关性 $|r_{ij}|$ 作为独立性双边检验的检验统计量。\n3. 在基因 $i$ 和 $j$ 独立的零假设 $H_{0,ij}$ 下，当样本是独立同分布时，$(x_{ti}, x_{tj})$ 的联合分布对其中一个基因的样本标签表现出可交换性。具体来说，置换基因 $j$ 的样本标签会产生与 $H_{0,ij}$ 一致的实现，同时保持 $x_{tj}$ 的边缘分布。当解析形式不方便或未知时，这是一种构建非参数零分布的经过充分检验的方法。\n4. 检验 $H_{0,ij}$ 的 $p$ 值定义为在零模型下，观测到至少与已观测统计量一样极端的检验统计量的概率。在具有 $B$ 次置换的置换设置中，带有有限样本校正的经验 $p$ 值为\n$$\np_{ij} = \\frac{1 + \\sum_{b=1}^B \\mathbf{1}\\left\\{ \\left|r_{ij}^{(b)}\\right| \\ge \\left|r_{ij}\\right| \\right\\}}{1 + B},\n$$\n其中 $r_{ij}^{(b)}$ 是根据第 $b$ 次置换对基因 $j$ 的样本标签进行置换后计算出的相关性。分子和分母各加 1 是为了避免因离散性而产生零值。\n5. 当同时检验 $m$ 个假设时，错误发现率 (FDR) 定义为\n$$\n\\mathrm{FDR} = \\mathbb{E}\\left[ \\frac{V}{R \\vee 1} \\right],\n$$\n其中 $V$ 是错误拒绝的数量，$R$ 是总拒绝数量，$R \\vee 1$ 表示 $\\max(R, 1)$ 以避免除以零。在 $H_0$ 下，一个有效的 $p$ 值随机地大于或等于一个 Uniform$(0,1)$ 随机变量；在 $p$ 值独立或某些正相关形式下，可以使用 $p$ 值的排序来对拒绝进行阈值处理以控制 FDR。\n\nBenjamini–Hochberg 程序的推导：\n\n从 FDR 的定义和在 $H_0$ 下有效 $p$ 值是超均匀分布的属性出发，考虑将计算出的 $m$ 个 $p$ 值排序为 $p_{(1)} \\le p_{(2)} \\le \\cdots \\le p_{(m)}$，其对应的索引为 $(i_{(1)}, j_{(1)}), \\ldots, (i_{(m)}, j_{(m)})$。如果在独立性假设下，我们选择一个按 $\\frac{\\alpha k}{m}$ 比例缩放的阈值，那么在前 $k$ 个有序 $p$ 值中，预期错误发现的数量约为 $\\alpha k$，因为一个零假设下的 $p$ 值低于阈值 $t$ 的概率至多为 $t$。为了确保错误拒绝与总拒绝的比例在期望上保持在 $\\alpha$ 界限内，我们选择满足以下条件的最大索引 $k$：\n$$\np_{(k)} \\le \\frac{\\alpha k}{m}.\n$$\n然后，所有对应于 $p_{(1)}, \\ldots, p_{(k)}$ 的假设都被拒绝。这种自适应阈值方法为 $p$ 值设定了一个数据驱动的截断点，它补偿了多重性 $m$ 和秩 $k$，在独立性或某些正相关结构下，将期望比率 $V / (R \\vee 1)$ 控制在水平 $\\alpha$。这就是 Benjamini–Hochberg 程序。\n\n整合原理的算法设计：\n\n- 使用样本均值和样本标准差对每个基因在所有样本中进行标准化，以获得每个基因 $i$ 的 $z_{ti}$。\n- 对于每对 $i  j$ 的 $(i,j)$，使用标准化变量和样本相关性公式计算观测到的绝对相关性 $|r_{ij}|$。共有 $m = \\frac{p(p-1)}{2}$ 对这样的基因对。\n- 构建基于置换的零分布：生成 $B$ 个样本索引的随机置换。对于每次置换，重排基因 $j$ 的标准化向量，并重新计算其与基因 $i$ 的绝对相关性。收集 $B$ 个置换后的绝对相关性，并使用上述指定的有限样本校正计算置换 $p$ 值。\n- 收集所有基因对的 $m$ 个 $p$ 值，并应用推导出的 Benjamini–Hochberg 程序：对 $p$ 值进行排序，找到满足上述不等式的最大 $k$，并拒绝所有 $p$ 值小于或等于自适应阈值 $\\frac{\\alpha k}{m}$ 的假设。如果不存在这样的 $k$，则不拒绝任何假设。\n- 在每个测试用例中，使用已知的植入边，计算经验错误发现比例为 $V / (R \\vee 1)$，其中 $V$ 是不在植入集中的被拒绝基因对数量，$R$ 是被拒绝基因对的总数。\n- 将测试套件的结果汇总到一个列表 $[[D_1,F_1],[D_2,F_2],[D_3,F_3]]$ 中，其中 $D_c$ 是拒绝的数量，$F_c$ 是测试用例 $c$ 的经验错误发现比例。该比例应以小数表示。\n\n此解决方案具有科学依据：Pearson 相关性量化了线性关联；基于置换的零模型依赖于独立性下的可交换性，这是一种经过充分检验的非参数方法；Benjamini–Hochberg 程序源于 FDR 的定义和有效 $p$ 值的顺序统计量，可在标准条件下将错误发现率控制在水平 $\\alpha$。尽管互信息在计算系统生物学中为非线性依赖性提供了补充度量，但本问题专注于基于置换的相关性推断，以符合指定的核心要求，并保持从所呈现的基本定义中进行清晰的推导。", "answer": "```python\n# The complete and runnable Python 3 code goes here.\n# Imports must adhere to the specified execution environment.\nimport numpy as np\n\ndef simulate_data(p, n, planted_edges, seed):\n    \"\"\"\n    Simulate gene expression data with planted correlated edges.\n    Args:\n        p (int): number of genes\n        n (int): number of samples\n        planted_edges (list of tuples): [(i, j, rho), ...] with 0-based indices and correlation strength rho\n        seed (int): random seed\n    Returns:\n        X (np.ndarray): n x p data matrix\n        true_edges_set (set): set of (min(i,j), max(i,j)) tuples representing true correlated pairs\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    X = rng.standard_normal((n, p))\n    true_edges_set = set()\n    for (i, j, rho) in planted_edges:\n        # Ensure distinct indices and valid rho\n        assert 0 <= i < p and 0 <= j < p and i != j\n        assert 0.0 <= rho <= 1.0\n        # Overwrite gene j to be correlated with gene i\n        eps = rng.standard_normal(n)\n        X[:, j] = rho * X[:, i] + np.sqrt(1.0 - rho**2) * eps\n        a, b = (i, j) if i < j else (j, i)\n        true_edges_set.add((a, b))\n    return X, true_edges_set\n\ndef standardize_columns(X):\n    \"\"\"\n    Standardize each column to zero mean and unit sample standard deviation.\n    \"\"\"\n    X_centered = X - X.mean(axis=0, keepdims=True)\n    std = X_centered.std(axis=0, ddof=1, keepdims=True)\n    # Avoid division by zero: add tiny epsilon if needed\n    std = np.where(std == 0, 1.0, std)\n    X_std = X_centered / std\n    return X_std\n\ndef permutation_pvalues(X_std, B, seed):\n    \"\"\"\n    Compute permutation-based p-values for absolute Pearson correlations for all pairs.\n    Args:\n        X_std (np.ndarray): n x p standardized data\n        B (int): number of permutations\n        seed (int): random seed for permutations\n    Returns:\n        pvals (np.ndarray): array of length m with p-values\n        pairs (list): list of (i, j) pairs in the same order as pvals\n        obs_abs_corrs (np.ndarray): observed absolute correlations for each pair\n    \"\"\"\n    rng = np.random.default_rng(seed)\n    n, p = X_std.shape\n    pairs = [(i, j) for i in range(p) for j in range(i + 1, p)]\n    m = len(pairs)\n\n    # Precompute B permutations of indices\n    perms = np.array([rng.permutation(n) for _ in range(B)], dtype=np.int64)\n\n    pvals = np.empty(m, dtype=float)\n    obs_abs_corrs = np.empty(m, dtype=float)\n    denom = float(n - 1)\n\n    # Compute p-values for each pair\n    for idx, (i, j) in enumerate(pairs):\n        xi = X_std[:, i]\n        yj = X_std[:, j]\n        # Observed absolute correlation\n        obs = abs(np.dot(xi, yj) / denom)\n        obs_abs_corrs[idx] = obs\n        # Permuted correlations: permute yj by each permutation\n        # Vectorized: build matrix of shape (B, n) for yj permuted, then dot with xi\n        yj_perm = yj[perms]  # shape (B, n)\n        perm_corrs = (yj_perm @ xi) / denom  # shape (B,)\n        perm_abs = np.abs(perm_corrs)\n        count_ge = np.sum(perm_abs >= obs)\n        # Finite-sample correction to avoid zero p-values\n        pval = (count_ge + 1.0) / (B + 1.0)\n        pvals[idx] = pval\n\n    return pvals, pairs, obs_abs_corrs\n\ndef benjamini_hochberg(pvals, alpha):\n    \"\"\"\n    Apply the Benjamini–Hochberg procedure to control FDR at level alpha.\n    Args:\n        pvals (np.ndarray): p-values of length m\n        alpha (float): target FDR level\n    Returns:\n        reject_indices (np.ndarray): indices (into pvals) of rejected hypotheses\n        threshold (float): BH threshold used (0 if no rejections)\n    \"\"\"\n    m = pvals.size\n    order = np.argsort(pvals)\n    p_sorted = pvals[order]\n    ranks = np.arange(1, m + 1, dtype=float)\n    thresholds = (ranks / m) * alpha\n    # Find largest k such that p_(k) <= (k/m)*alpha\n    valid = np.where(p_sorted <= thresholds)[0]\n    if valid.size == 0:\n        return np.array([], dtype=int), 0.0\n    k = valid.max() + 1  # convert index to count\n    bh_threshold = thresholds[k - 1]\n    reject_mask = pvals <= bh_threshold\n    reject_indices = np.where(reject_mask)[0]\n    return reject_indices, bh_threshold\n\ndef evaluate_fdp(rejected_pairs, true_edges_set):\n    \"\"\"\n    Compute number of rejections and empirical false discovery proportion (FDP).\n    Args:\n        rejected_pairs (list of tuples): list of (i, j) for rejected hypotheses\n        true_edges_set (set of tuples): ground-truth correlated edges\n    Returns:\n        D (int): total number of rejections\n        fdp (float): false discovery proportion (0.0 if D == 0)\n    \"\"\"\n    D = len(rejected_pairs)\n    if D == 0:\n        return 0, 0.0\n    rejected_set = set((min(i, j), max(i, j)) for (i, j) in rejected_pairs)\n    false_discoveries = len(rejected_set - true_edges_set)\n    fdp = false_discoveries / D\n    return D, fdp\n\ndef run_test_case(p, n, B, alpha, seed, planted_edges):\n    \"\"\"\n    Execute the full pipeline for one test case.\n    Returns:\n        [D, fdp] for the test case.\n    \"\"\"\n    X, true_edges_set = simulate_data(p, n, planted_edges, seed)\n    X_std = standardize_columns(X)\n    pvals, pairs, _ = permutation_pvalues(X_std, B, seed + 12345)  # separate seed for permutations\n    reject_indices, _ = benjamini_hochberg(pvals, alpha)\n    rejected_pairs = [pairs[idx] for idx in reject_indices]\n    D, fdp = evaluate_fdp(rejected_pairs, true_edges_set)\n    return [int(D), float(fdp)]\n\ndef solve():\n    # Define the test cases from the problem statement.\n    test_cases = [\n        # Test case 1: p=20, n=60, B=200, alpha=0.1, seed=7, planted edges given\n        {\n            \"p\": 20, \"n\": 60, \"B\": 200, \"alpha\": 0.1, \"seed\": 7,\n            \"planted_edges\": [(0, 1, 0.8), (2, 3, 0.7), (4, 5, 0.75), (6, 7, 0.6), (8, 9, 0.65)]\n        },\n        # Test case 2: p=15, n=50, B=200, alpha=0.1, seed=13, no planted edges\n        {\n            \"p\": 15, \"n\": 50, \"B\": 200, \"alpha\": 0.1, \"seed\": 13,\n            \"planted_edges\": []\n        },\n        # Test case 3: p=18, n=40, B=300, alpha=0.05, seed=29, mixed effect sizes\n        {\n            \"p\": 18, \"n\": 40, \"B\": 300, \"alpha\": 0.05, \"seed\": 29,\n            \"planted_edges\": [\n                (0, 10, 0.5), (1, 11, 0.5), (2, 12, 0.5), (3, 13, 0.5),\n                (4, 14, 0.3), (5, 15, 0.3), (6, 16, 0.3), (7, 17, 0.3)\n            ]\n        },\n    ]\n\n    results = []\n    for case in test_cases:\n        result = run_test_case(case[\"p\"], case[\"n\"], case[\"B\"], case[\"alpha\"], case[\"seed\"], case[\"planted_edges\"])\n        results.append(result)\n\n    # Final print statement in the exact required format.\n    print(f\"[{','.join(map(str, results))}]\")\n\nif __name__ == \"__main__\":\n    solve()\n```", "id": "3331730"}, {"introduction": "网络推断的最后一步是评估结果的质量。生物网络通常是稀疏的，这意味着真实的连接（正例）远少于不存在的连接（负例）。本练习将演示这种类别不平衡如何影响常用的性能指标，并阐明为何在稀疏网络评估中，精确率-召回率曲线下面积（AUPRC）通常比ROC曲线下面积（AUROC）更具信息量。[@problem_id:3331731]", "problem": "在一项基因调控网络推断任务中，研究者根据从估计的互信息 (MI) 中导出的基于信息论的边分数 $s$ 对所有候选基因对进行排序。考虑两类基因对群体：真实的调控相互作用（正例）和非相互作用（负例）。假设在给定类别的情况下，分数 $s$ 会落入三个有序的区间：高 ($H$)、中 ($M$) 和低 ($L$)，其类条件概率如下：\n- 对于正例：$\\mathbb{P}(H \\mid \\text{positive}) = 0.3$，$\\mathbb{P}(M \\mid \\text{positive}) = 0.5$，$\\mathbb{P}(L \\mid \\text{positive}) = 0.2$。\n- 对于负例：$\\mathbb{P}(H \\mid \\text{negative}) = 0.05$，$\\mathbb{P}(M \\mid \\text{negative}) = 0.15$，$\\mathbb{P}(L \\mid \\text{negative}) = 0.8$。\n\n一个阈值化过程当且仅当分数 $s$ 不小于阈值时，才判定存在一条预测的边。当阈值在 $\\{H, M, L\\}$ 上依次降低时，预测边的集合是单调递增的。你通过受试者工作特征 (ROC) 分析和精确率-召回率 (PR) 分析来评估排序后的预测结果。令 $\\pi \\in (0,1)$ 表示真实边的流行率（即所有候选基因对中正例的比例），它反映了网络的稀疏性。\n\n仅使用真阳性率 (TPR)、假阳性率 (FPR)、精确率 (Precision) 和召回率 (Recall) 的基本定义，以及 ROC 曲线下面积 (AUROC) 和 PR 曲线下面积 (AUPRC) 的标准面积解释，完成以下任务：\n\n1. 从以下定义出发\n   - $\\mathrm{TPR}(\\tau) = \\mathbb{P}(s \\ge \\tau \\mid \\text{positive})$，\n   - $\\mathrm{FPR}(\\tau) = \\mathbb{P}(s \\ge \\tau \\mid \\text{negative})$，\n   - $\\mathrm{Precision}(\\tau) = \\dfrac{\\pi\\, \\mathrm{TPR}(\\tau)}{\\pi\\, \\mathrm{TPR}(\\tau) + (1-\\pi)\\, \\mathrm{FPR}(\\tau)}$，\n   - $\\mathrm{Recall}(\\tau) = \\mathrm{TPR}(\\tau)$，\n   解释为什么 $\\mathrm{AUROC}$ 仅依赖于类条件分数分布而独立于 $\\pi$，而 $\\mathrm{AUPRC}$ 依赖于 $\\pi$，过程中不得引用任何未经证明的快捷公式。你的解释必须明确指出定义中任何对 $\\pi$ 依赖或不依赖的来源。\n\n2. 对于由区间 $\\{H, M, L\\}$ 所隐含的离散三阈值设定，使用在阈值 $\\tau \\in \\{+\\infty, H, M, L\\}$ 处得到的点之间的梯形面积来计算精确的 $\\mathrm{AUROC}$。其中，$\\tau = +\\infty$ 产生 $\\mathrm{TPR} = 0$ 和 $\\mathrm{FPR} = 0$，而 $\\tau = L$ 产生 $\\mathrm{TPR} = 1$ 和 $\\mathrm{FPR} = 1$。\n\n3. 在相同的离散三阈值设定下，计算两种不同流行率下的 $\\mathrm{AUPRC}$：稀疏网络 ($\\pi = 0.01$) 和平衡评估 ($\\pi = 0.5$) 。使用离散排名的标准阶梯式面积计算约定，即按分数 $s$ 递减的顺序对阈值进行求和，加总每个召回率增量与该水平下精确率的乘积。\n\n最后，报告比值\n$$\nr \\;=\\; \\frac{\\mathrm{AUPRC}\\; \\text{at}\\; \\pi = 0.01}{\\mathrm{AUPRC}\\; \\text{at}\\; \\pi = 0.5}\n$$\n的数值，四舍五入到四位有效数字。最终答案以纯数字形式表示，不带单位。", "solution": "问题陈述经核实是科学上合理、良定且完整的。它描述了计算系统生物学中一个标准分类评估场景，并提供了推导唯一解所需的所有数据和定义。我们可以开始进行分析。\n\n该问题要求完成三项任务：首先，解释受试者工作特征曲线下面积 (AUROC) 和精确率-召回率曲线下面积 (AUPRC) 对类别流行率 $\\pi$ 的依赖性；其次，为给定的离散分数分布计算 AUROC；第三，为两个指定的 $\\pi$ 值计算 AUPRC。最后，需要计算这两个 AUPRC 值的比率。\n\n**1. AUROC 和 AUPRC 对流行率 $\\pi$ 的依赖性**\n\n受试者工作特征 (ROC) 曲线是随决策阈值 $\\tau$ 变化，以真阳性率 (TPR) 对假阳性率 (FPR) 作图得到的曲线。所提供的定义如下：\n$$\n\\mathrm{TPR}(\\tau) = \\mathbb{P}(s \\ge \\tau \\mid \\text{positive})\n$$\n$$\n\\mathrm{FPR}(\\tau) = \\mathbb{P}(s \\ge \\tau \\mid \\text{negative})\n$$\n这些定义是基于实例真实类别（正例或负例）的条件概率。它们仅依赖于每个类别内部分数 $s$ 的分布。流行率 $\\pi = \\mathbb{P}(\\text{positive})$，即一个实例为正例的先验概率，没有出现在这些定义中。因此，构成 ROC 曲线的点集 $(\\mathrm{FPR}(\\tau), \\mathrm{TPR}(\\tau))$ 对 $\\pi$ 的变化是不变的。由于 AUROC 是该曲线下的面积，它完全由曲线的几何形状决定。因此，AUROC 是一个独立于类别流行率 $\\pi$ 的性能指标。\n\n精确率-召回率 (PR) 曲线是随阈值 $\\tau$ 变化，以精确率对召回率作图得到的曲线。所提供的定义如下：\n$$\n\\mathrm{Recall}(\\tau) = \\mathrm{TPR}(\\tau)\n$$\n$$\n\\mathrm{Precision}(\\tau) = \\dfrac{\\pi\\, \\mathrm{TPR}(\\tau)}{\\pi\\, \\mathrm{TPR}(\\tau) + (1-\\pi)\\, \\mathrm{FPR}(\\tau)}\n$$\n尽管召回率与 TPR 相同，因此独立于 $\\pi$，但精确率的定义明确地包含了流行率 $\\pi$。精确率的公式源自贝叶斯定理，即 $\\mathrm{Precision}(\\tau) = \\mathbb{P}(\\text{positive} \\mid s \\ge \\tau)$，其值是 $\\pi$、$\\mathrm{TPR}(\\tau)$ 和 $\\mathrm{FPR}(\\tau)$ 的函数。由于 PR 曲线的 y 轴（精确率）是 $\\pi$ 的函数，因此随着 $\\pi$ 的变化，曲线在召回率-精确率空间中的形状和位置也会改变。AUPRC 作为该曲线下的面积，因此从根本上依赖于类别流行率 $\\pi$。\n\n**2. AUROC 的计算**\n\n离散分数区间的顺序为 $H > M > L$。我们在与这些分数水平相对应的阈值处评估性能。问题指定了阈值 $\\tau \\in \\{+\\infty, H, M, L\\}$。我们首先计算每个阈值的 (FPR, TPR) 坐标。\n\n令 $P(+) = \\text{positive}$ (正例) 且 $P(-) = \\text{negative}$ (负例)。\n累积概率为：\n$\\mathbb{P}(s \\ge H \\mid P(+)) = \\mathbb{P}(s=H \\mid P(+)) = 0.3$\n$\\mathbb{P}(s \\ge M \\mid P(+)) = \\mathbb{P}(s=H \\mid P(+)) + \\mathbb{P}(s=M \\mid P(+)) = 0.3 + 0.5 = 0.8$\n$\\mathbb{P}(s \\ge L \\mid P(+)) = \\mathbb{P}(s=H \\mid P(+)) + \\mathbb{P}(s=M \\mid P(+)) + \\mathbb{P}(s=L \\mid P(+)) = 0.3 + 0.5 + 0.2 = 1.0$\n\n$\\mathbb{P}(s \\ge H \\mid P(-)) = \\mathbb{P}(s=H \\mid P(-)) = 0.05$\n$\\mathbb{P}(s \\ge M \\mid P(-)) = \\mathbb{P}(s=H \\mid P(-)) + \\mathbb{P}(s=M \\mid P(-)) = 0.05 + 0.15 = 0.20$\n$\\mathbb{P}(s \\ge L \\mid P(-)) = \\mathbb{P}(s=H \\mid P(-)) + \\mathbb{P}(s=M \\mid P(-)) + \\mathbb{P}(s=L \\mid P(-)) = 0.05 + 0.15 + 0.8 = 1.0$\n\n这在 ROC 曲线上产生以下点 $(x,y) = (\\mathrm{FPR}, \\mathrm{TPR})$：\n- 当 $\\tau = +\\infty$ 时：$(\\mathrm{FPR}, \\mathrm{TPR}) = (0, 0)$。设此点为 $p_0$。\n- 当 $\\tau = H$ 时：$(\\mathrm{FPR}, \\mathrm{TPR}) = (\\mathbb{P}(s \\ge H \\mid P(-)), \\mathbb{P}(s \\ge H \\mid P(+))) = (0.05, 0.3)$。设此点为 $p_1$。\n- 当 $\\tau = M$ 时：$(\\mathrm{FPR}, \\mathrm{TPR}) = (\\mathbb{P}(s \\ge M \\mid P(-)), \\mathbb{P}(s \\ge M \\mid P(+))) = (0.20, 0.8)$。设此点为 $p_2$。\n- 当 $\\tau = L$ 时：$(\\mathrm{FPR}, \\mathrm{TPR}) = (\\mathbb{P}(s \\ge L \\mid P(-)), \\mathbb{P}(s \\ge L \\mid P(+))) = (1.0, 1.0)$。设此点为 $p_3$。\n\nAUROC 是通过对连接 $p_0, p_1, p_2, p_3$ 的线段下的面积使用梯形法则来计算的。\n面积 = $\\sum_{i=1}^{3} \\frac{1}{2} (y_{i-1} + y_i) (x_i - x_{i-1})$\n- $p_0=(0,0)$ 和 $p_1=(0.05, 0.3)$ 之间的梯形面积：\n  $A_1 = \\frac{1}{2} (0 + 0.3) (0.05 - 0) = 0.5 \\times 0.3 \\times 0.05 = 0.0075$\n- $p_1=(0.05, 0.3)$ 和 $p_2=(0.20, 0.8)$ 之间的梯形面积：\n  $A_2 = \\frac{1}{2} (0.3 + 0.8) (0.20 - 0.05) = 0.5 \\times 1.1 \\times 0.15 = 0.0825$\n- $p_2=(0.20, 0.8)$ 和 $p_3=(1.0, 1.0)$ 之间的梯形面积：\n  $A_3 = \\frac{1}{2} (0.8 + 1.0) (1.0 - 0.20) = 0.5 \\times 1.8 \\times 0.8 = 0.72$\n\n总 AUROC 是这些面积之和：\n$\\mathrm{AUROC} = A_1 + A_2 + A_3 = 0.0075 + 0.0825 + 0.72 = 0.81$\n\n**3. AUPRC 的计算**\n\nAUPRC 使用阶梯式面积计算约定进行计算：$\\mathrm{AUPRC} = \\sum_{k} \\mathrm{Precision}(k) \\times \\Delta \\mathrm{Recall}(k)$，其中求和是按分数递减的顺序对阈值 $k$进行的。\n召回率值就是 TPR 值：$\\mathrm{Recall}(H)=0.3$, $\\mathrm{Recall}(M)=0.8$, $\\mathrm{Recall}(L)=1.0$。\n召回率增量为：\n- $\\Delta \\mathrm{Recall}(H) = \\mathrm{Recall}(H) - 0 = 0.3$\n- $\\Delta \\mathrm{Recall}(M) = \\mathrm{Recall}(M) - \\mathrm{Recall}(H) = 0.8 - 0.3 = 0.5$\n- $\\Delta \\mathrm{Recall}(L) = \\mathrm{Recall}(L) - \\mathrm{Recall}(M) = 1.0 - 0.8 = 0.2$\n\n我们现在计算在 $\\pi=0.01$ 和 $\\pi=0.5$ 时，每个阈值 $\\tau \\in \\{H, M, L\\}$ 的精确率。\n\n情况1：稀疏网络, $\\pi = 0.01$\n- $\\mathrm{Precision}(H) = \\frac{0.01 \\times \\mathrm{TPR}(H)}{0.01 \\times \\mathrm{TPR}(H) + 0.99 \\times \\mathrm{FPR}(H)} = \\frac{0.01 \\times 0.3}{0.01 \\times 0.3 + 0.99 \\times 0.05} = \\frac{0.003}{0.003 + 0.0495} = \\frac{0.003}{0.0525} = \\frac{2}{35}$\n- $\\mathrm{Precision}(M) = \\frac{0.01 \\times \\mathrm{TPR}(M)}{0.01 \\times \\mathrm{TPR}(M) + 0.99 \\times \\mathrm{FPR}(M)} = \\frac{0.01 \\times 0.8}{0.01 \\times 0.8 + 0.99 \\times 0.20} = \\frac{0.008}{0.008 + 0.198} = \\frac{0.008}{0.206} = \\frac{4}{103}$\n- $\\mathrm{Precision}(L) = \\frac{0.01 \\times \\mathrm{TPR}(L)}{0.01 \\times \\mathrm{TPR}(L) + 0.99 \\times \\mathrm{FPR}(L)} = \\frac{0.01 \\times 1.0}{0.01 \\times 1.0 + 0.99 \\times 1.0} = 0.01$\n\n$\\mathrm{AUPRC}(\\pi=0.01) = \\mathrm{Prec}(H) \\Delta \\mathrm{Rec}(H) + \\mathrm{Prec}(M) \\Delta \\mathrm{Rec}(M) + \\mathrm{Prec}(L) \\Delta \\mathrm{Rec}(L)$\n$\\mathrm{AUPRC}(\\pi=0.01) = (\\frac{2}{35})(0.3) + (\\frac{4}{103})(0.5) + (0.01)(0.2)$\n$= \\frac{0.6}{35} + \\frac{2}{103} + 0.002 = \\frac{3}{175} + \\frac{2}{103} + \\frac{1}{500}$\n数值上，这约等于 $\\frac{13901}{360500} \\approx 0.03856033$\n\n情况2：平衡评估, $\\pi = 0.5$\n- $\\mathrm{Precision}(H) = \\frac{0.5 \\times 0.3}{0.5 \\times 0.3 + 0.5 \\times 0.05} = \\frac{0.3}{0.3 + 0.05} = \\frac{0.3}{0.35} = \\frac{6}{7}$\n- $\\mathrm{Precision}(M) = \\frac{0.5 \\times 0.8}{0.5 \\times 0.8 + 0.5 \\times 0.20} = \\frac{0.8}{0.8 + 0.2} = \\frac{0.8}{1.0} = 0.8 = \\frac{4}{5}$\n- $\\mathrm{Precision}(L) = \\frac{0.5 \\times 1.0}{0.5 \\times 1.0 + 0.5 \\times 1.0} = 0.5 = \\frac{1}{2}$\n\n$\\mathrm{AUPRC}(\\pi=0.5) = (\\frac{6}{7})(0.3) + (\\frac{4}{5})(0.5) + (\\frac{1}{2})(0.2)$\n$= \\frac{1.8}{7} + 0.4 + 0.1 = \\frac{1.8}{7} + 0.5 = \\frac{9}{35} + \\frac{1}{2} = \\frac{18+35}{70} = \\frac{53}{70}$\n数值上，这约等于 $0.75714286$\n\n**最终比率计算**\n\n最后，我们计算比率 $r = \\frac{\\mathrm{AUPRC}(\\pi=0.01)}{\\mathrm{AUPRC}(\\pi=0.5)}$：\n$$\nr = \\frac{13901/360500}{53/70} = \\frac{13901}{360500} \\times \\frac{70}{53} = \\frac{13901}{5150 \\times 53} = \\frac{13901}{272950}\n$$\n$r \\approx 0.0509287415...$\n四舍五入到四位有效数字，我们得到 $r = 0.05093$。", "answer": "$$\\boxed{0.05093}$$", "id": "3331731"}]}