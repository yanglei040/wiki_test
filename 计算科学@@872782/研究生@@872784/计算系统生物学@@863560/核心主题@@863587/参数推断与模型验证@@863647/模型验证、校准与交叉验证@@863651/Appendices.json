{"hands_on_practices": [{"introduction": "模型验证的首要任务是量化模型预测与观测数据之间的差异。本练习将通过一个具体案例，指导你计算并比较几种核心的性能指标。你不仅会实践均方根误差 ($RMSE$) 和平均绝对误差 ($MAE$) 这类衡量点预测准确度的常用方法，还将接触评估概率性预测整体质量的对数评分 (log score)，从而深入理解不同指标对模型误差的敏感性。[@problem_id:3327278]", "problem": "你的任务是定量验证一个模拟的细胞因子时程模型与在已知相移和预测不确定性下的观测数据，并分析不同性能指标的稳健性属性。考虑一个由振荡调控网络生成的单一细胞因子轨迹，在没有噪声的情况下，该轨迹可以表示为一条正弦平均轨迹。设确定性平均轨迹由 $y_{\\mathrm{true}}(t) = B + A \\sin(\\omega t)$ 给出，适用于时间 $t \\ge 0$，其中振幅为 $A$，基线水平为 $B$，角频率为 $\\omega$。观测数据在离散时间点 $t_k = k \\Delta t$ 收集，其中 $k \\in \\{0,1,\\dots,T-1\\}$，步长 $\\Delta t$ 固定。观测数据为 $y_{\\mathrm{obs}}(t_k) = y_{\\mathrm{true}}(t_k) + \\varepsilon_k$，其中 $\\varepsilon_k$ 是独立同分布的高斯扰动，均值为零，方差为 $\\sigma_{\\mathrm{obs}}^2$。模拟器输出一个相移平均轨迹 $y_{\\mathrm{sim}}(t_k;\\phi) = B + A \\sin(\\omega t_k + \\phi)$，其中 $\\phi$ 是一个相移。假设在时间 $t_k$，模拟器的预测分布是单变量正态分布，其均值为 $y_{\\mathrm{sim}}(t_k;\\phi)$，标准差为 $\\sigma_{\\mathrm{pred}}$；即 $y \\mid t_k \\sim \\mathcal{N}(y_{\\mathrm{sim}}(t_k;\\phi), \\sigma_{\\mathrm{pred}}^2)$。角度必须以弧度为单位。\n\n你的程序必须完成以下任务：\n- 使用种子固定为 $314159$ 的伪随机数生成器通过采样 $\\varepsilon_k \\sim \\mathcal{N}(0,\\sigma_{\\mathrm{obs}}^2)$ 来生成观测轨迹，以确保结果可复现。\n- 对于每个指定的测试用例，在指定的时间索引子集 $k$ 上，计算 $y_{\\mathrm{sim}}(t_k;\\phi)$ 和 $y_{\\mathrm{obs}}(t_k)$ 之间的以下指标：\n  1. 均方根误差 (RMSE)：误差平方均值的平方根。\n  2. 平均绝对误差 (MAE)：绝对误差的均值。\n  3. 时间平均对数得分：在所选时间索引上，基于均值为 $y_{\\mathrm{sim}}(t_k;\\phi)$、标准差为 $\\sigma_{\\mathrm{pred}}$ 的正态模型下的对数预测密度的经验平均值。\n\n使用以下固定设置生成数据：\n- 振幅 $A = 2.0$。\n- 基线 $B = 5.0$。\n- 角频率 $\\omega = 1.0$。\n- 时间步长 $\\Delta t = 0.05$。\n- 时间点数量 $T = 200$。\n- 观测噪声标准差 $\\sigma_{\\mathrm{obs}} = 0.5$。\n- 用于生成 $\\{\\varepsilon_k\\}_{k=0}^{T-1}$ 的随机种子 $314159$。\n\n角度以弧度为单位。本问题中细胞因子浓度没有物理单位，角度必须以弧度处理。不允许使用度为单位的角度。\n\n测试套件（每个测试用例是一个三元组 $(\\phi, \\sigma_{\\mathrm{pred}}, \\mathcal{K})$，其中 $\\mathcal{K}$ 是要包含的索引子集）：\n- 用例 1：$\\phi = 0.0$，$\\sigma_{\\mathrm{pred}} = 0.5$，$\\mathcal{K} = \\{0,1,\\dots,T-1\\}$ (所有索引)。\n- 用例 2：$\\phi = 0.2$，$\\sigma_{\\mathrm{pred}} = 0.5$，$\\mathcal{K} = \\{0,1,\\dots,T-1\\}$。\n- 用例 3：$\\phi = \\pi$，$\\sigma_{\\mathrm{pred}} = 0.5$，$\\mathcal{K} = \\{0,1,\\dots,T-1\\}$。\n- 用例 4：$\\phi = 0.2$，$\\sigma_{\\mathrm{pred}} = 2.0$，$\\mathcal{K} = \\{0,1,\\dots,T-1\\}$。\n- 用例 5：$\\phi = 0.2$，$\\sigma_{\\mathrm{pred}} = 0.1$，$\\mathcal{K} = \\{0,1,\\dots,T-1\\}$。\n- 用例 6：$\\phi = 0.2$，$\\sigma_{\\mathrm{pred}} = 0.5$，$\\mathcal{K} = \\{0,1,2,3,4\\}$ (仅前五个索引)。\n\n实现说明和要求：\n- 角度必须以弧度为单位。\n- 对于每个用例，仅在指定的索引集 $\\mathcal{K}$ 上计算三个指标。\n- 将每个指标报告为四舍五入到 $6$ 位小数的浮点数。\n- 最终的程序输出必须是单行，包含一个长度为 $6$ 的列表，其中每个元素是一个长度为 $3$ 的列表，对应于相应测试用例的 $\\left[\\mathrm{RMSE}, \\mathrm{MAE}, \\mathrm{AvgLogScore}\\right]$，顺序与上文相同。\n\n你可以无需进一步论证即可使用的基本依据包括：正态分布的性质、绝对值和平方误差的定义，以及经验均值的定义。你必须将时间平均对数得分视为在均值为 $y_{\\mathrm{sim}}(t_k;\\phi)$、标准差为 $\\sigma_{\\mathrm{pred}}$ 的正态模型下，于 $y_{\\mathrm{obs}}(t_k)$ 处评估的对数预测密度的经验平均值。\n\n你的程序应产生单行输出，其中包含一个用方括号括起来的逗号分隔列表（例如，$\\left[\\left[\\cdot,\\cdot,\\cdot\\right],\\dots\\right]$）。", "solution": "问题陈述已经过分析并被认为是有效的。它在科学上基于计算建模和统计模型验证的原理，其参数和定义完整一致，问题设定适定，并且其表述是客观的。可以计算出唯一且可验证的解。\n\n任务是计算三个性能指标（均方根误差、平均绝对误差和时间平均对数得分），以评估一个模拟的时间序列模型与人工生成的观测轨迹。该过程分为两个主要阶段：数据生成和指标计算。\n\n首先，我们生成“观测”数据。此操作仅执行一次，所有测试用例都使用相同的数据，以确保公平比较。\n离散时间点由 $t_k = k \\Delta t$ 给出，其中 $k \\in \\{0, 1, \\dots, T-1\\}$，时间点数量 $T=200$，时间步长 $\\Delta t = 0.05$。\n真实的、无噪声的潜在轨迹是一条正弦曲线：\n$$ y_{\\mathrm{true}}(t_k) = B + A \\sin(\\omega t_k) $$\n其中振幅 $A=2.0$，基线 $B=5.0$，角频率 $\\omega=1.0$。\n观测数据 $y_{\\mathrm{obs}}(t_k)$ 是通过向该真实轨迹添加高斯噪声生成的：\n$$ y_{\\mathrm{obs}}(t_k) = y_{\\mathrm{true}}(t_k) + \\varepsilon_k $$\n其中 $\\varepsilon_k$ 是从均值为 $0$、标准差为 $\\sigma_{\\mathrm{obs}}=0.5$ 的正态分布中抽取的独立同分布的随机变量。即 $\\varepsilon_k \\sim \\mathcal{N}(0, \\sigma_{\\mathrm{obs}}^2)$。序列 $\\{\\varepsilon_k\\}_{k=0}^{T-1}$ 的生成是使用以固定种子 $314159$ 初始化的伪随机数生成器执行的，以确保可复现性。\n\n其次，对于指定的六个测试用例中的每一个，我们计算验证指标。一个测试用例由一个三元组 $(\\phi, \\sigma_{\\mathrm{pred}}, \\mathcal{K})$ 定义，其中 $\\phi$ 是模拟器中的相移，$\\sigma_{\\mathrm{pred}}$ 是模拟器预测分布的标准差，$\\mathcal{K}$ 是计算指标所依据的时间索引子集。\n\n给定相移 $\\phi$ 的模拟轨迹为：\n$$ y_{\\mathrm{sim}}(t_k; \\phi) = B + A \\sin(\\omega t_k + \\phi) $$\n对于索引 $k \\in \\mathcal{K}$ 的每个时间点 $t_k$，误差定义为观测值与模拟值之间的差：\n$$ e_k = y_{\\mathrm{obs}}(t_k) - y_{\\mathrm{sim}}(t_k; \\phi) $$\n令 $N_{\\mathcal{K}} = |\\mathcal{K}|$ 为集合 $\\mathcal{K}$ 中索引的数量。三个指标计算如下：\n\n1.  **均方根误差 (RMSE)**：此指标衡量平均平方误差的平方根。\n    $$ \\mathrm{RMSE} = \\sqrt{\\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} e_k^2} $$\n\n2.  **平均绝对误差 (MAE)**：此指标衡量平均绝对误差。\n    $$ \\mathrm{MAE} = \\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} |e_k| $$\n\n3.  **时间平均对数得分**：这是一个评估概率预测质量的固有评分规则。它是对数预测概率密度的经验平均值。预测分布由 $\\mathcal{N}(y_{\\mathrm{sim}}(t_k; \\phi), \\sigma_{\\mathrm{pred}}^2)$ 给出。正态分布的概率密度函数为 $p(y; \\mu, \\sigma^2) = (2\\pi\\sigma^2)^{-1/2} \\exp(-(y-\\mu)^2 / (2\\sigma^2))$。在观测值 $y_{\\mathrm{obs}}(t_k)$ 处评估的对数密度为：\n    $$ \\log p(y_{\\mathrm{obs}}(t_k)) = \\log \\left( \\frac{1}{\\sqrt{2\\pi\\sigma_{\\mathrm{pred}}^2}} \\exp\\left(-\\frac{(y_{\\mathrm{obs}}(t_k) - y_{\\mathrm{sim}}(t_k; \\phi))^2}{2\\sigma_{\\mathrm{pred}}^2}\\right) \\right) $$\n    $$ = -\\frac{1}{2}\\log(2\\pi\\sigma_{\\mathrm{pred}}^2) - \\frac{e_k^2}{2\\sigma_{\\mathrm{pred}}^2} = -\\log(\\sigma_{\\mathrm{pred}}) - \\frac{1}{2}\\log(2\\pi) - \\frac{e_k^2}{2\\sigma_{\\mathrm{pred}}^2} $$\n    时间平均对数得分是这些值在索引集 $\\mathcal{K}$ 上的平均值：\n    $$ \\mathrm{AvgLogScore} = \\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} \\left( -\\log(\\sigma_{\\mathrm{pred}}) - \\frac{1}{2}\\log(2\\pi) - \\frac{e_k^2}{2\\sigma_{\\mathrm{pred}}^2} \\right) $$\n    这可以通过提取常数项并识别出均方误差 (MSE) 来简化，$\\mathrm{MSE} = \\frac{1}{N_{\\mathcal{K}}} \\sum_{k \\in \\mathcal{K}} e_k^2 = \\mathrm{RMSE}^2$：\n    $$ \\mathrm{AvgLogScore} = -\\log(\\sigma_{\\mathrm{pred}}) - \\frac{1}{2}\\log(2\\pi) - \\frac{\\mathrm{MSE}}{2\\sigma_{\\mathrm{pred}}^2} $$\n\n对于每个测试用例，程序将首先根据 $\\mathcal{K}$ 选择 $y_{\\mathrm{obs}}$ 和 $t$ 的相关子集，然后计算 $y_{\\mathrm{sim}}$，最后使用上述公式计算三个指标。每个得出的指标都四舍五入到 $6$ 位小数。", "answer": "```python\nimport numpy as np\n\ndef solve():\n    # Fixed settings for data generation\n    A = 2.0\n    B = 5.0\n    omega = 1.0\n    delta_t = 0.05\n    T = 200\n    sigma_obs = 0.5\n    seed = 314159\n\n    # Generate the time vector\n    t = np.arange(T) * delta_t\n\n    # Generate the true trajectory\n    y_true = B + A * np.sin(omega * t)\n\n    # Generate the observed trajectory with reproducible noise\n    rng = np.random.default_rng(seed)\n    noise = rng.normal(loc=0.0, scale=sigma_obs, size=T)\n    y_obs = y_true + noise\n\n    # Define the test suite\n    test_cases = [\n        {'phi': 0.0, 'sigma_pred': 0.5, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 0.5, 'K': range(T)},\n        {'phi': np.pi, 'sigma_pred': 0.5, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 2.0, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 0.1, 'K': range(T)},\n        {'phi': 0.2, 'sigma_pred': 0.5, 'K': range(T)[0:5]}\n    ]\n\n    all_results = []\n    \n    for case in test_cases:\n        phi = case['phi']\n        sigma_pred = case['sigma_pred']\n        # Convert K (which might be a range) to a list of indices for slicing\n        k_indices = np.array(list(case['K']))\n\n        # Select the subset of data based on indices in K\n        t_subset = t[k_indices]\n        y_obs_subset = y_obs[k_indices]\n\n        # Generate the simulated trajectory for the subset\n        y_sim_subset = B + A * np.sin(omega * t_subset + phi)\n\n        # Calculate errors\n        errors = y_obs_subset - y_sim_subset\n\n        # 1. Root Mean Squared Error (RMSE)\n        mse = np.mean(errors**2)\n        rmse = np.sqrt(mse)\n\n        # 2. Mean Absolute Error (MAE)\n        mae = np.mean(np.abs(errors))\n\n        # 3. Time-averaged log score\n        # AvgLogScore = -log(sigma_pred) - 0.5*log(2*pi) - MSE/(2*sigma_pred^2)\n        log_score_term1 = -np.log(sigma_pred)\n        log_score_term2 = -0.5 * np.log(2 * np.pi)\n        log_score_term3 = -mse / (2 * sigma_pred**2)\n        avg_log_score = log_score_term1 + log_score_term2 + log_score_term3\n\n        # Store rounded results\n        case_results = [\n            round(rmse, 6),\n            round(mae, 6),\n            round(avg_log_score, 6)\n        ]\n        all_results.append(case_results)\n\n    # Format the final output string as [[r1,r2,r3],[r1,r2,r3],...]\n    # Using str() on a list adds spaces, so we build the string manually.\n    sublist_strs = []\n    for res_list in all_results:\n        # Format each sublist as \"[v1,v2,v3]\" without spaces\n        sublist_str = f\"[{res_list[0]},{res_list[1]},{res_list[2]}]\"\n        sublist_strs.append(sublist_str)\n    \n    final_output = f\"[{','.join(sublist_strs)}]\"\n\n    print(final_output)\n\nsolve()\n```", "id": "3327278"}, {"introduction": "一个成功的计算模型不仅能解释现有数据，更应能指导未来的实验设计，帮助我们高效地获取信息以改进模型。本练习将介绍前向灵敏度分析，这是一种强大的技术，用于量化模型输出对参数微小变化的响应程度。通过计算包含这些灵敏度信息的费雪信息矩阵 ($Fisher Information Matrix$)，我们可以应用 D-最优性准则来识别最能有效约束模型参数不确定性的测量时间点。[@problem_id:3327223]", "problem": "给定一个由常微分方程描述的最小机理信号级联，其动力学参数未知。你的任务是从第一性原理推导正向灵敏度方程，为该模型实现这些方程，并使用计算出的局部灵敏度对参数进行优先级排序，并通过信息论准则选择信息丰富的测量时间点以进行参数估计。你编写的程序必须为提供的测试套件计算结果，并按下文指定的格式生成单行聚合输出。\n\n从以下基本原理出发：一个由状态方程 $\\dot{x}(t) = f(x(t), \\theta, t)$ 定义的连续可微动力系统，其中 $x(t) \\in \\mathbb{R}^{n}$ 是状态向量，$\\theta \\in \\mathbb{R}^{p}$ 是常数参数向量，$f$ 在其参数上是光滑的。定义局部正向灵敏度矩阵 $S(t) = \\frac{\\partial x(t)}{\\partial \\theta} \\in \\mathbb{R}^{n \\times p}$ 和模型输出 $y(t) \\in \\mathbb{R}^{m}$，其中 $y(t) = h(x(t), \\theta, t)$ 足够光滑。你可以假设测量值受到独立的、零均值的高斯噪声干扰，每个输出分量和时间点的方差为 $\\sigma^{2}$，并且在离散测量时间 $\\{t_i\\}_{i=1}^{N}$ 上的费雪信息矩阵（FIM）由输出灵敏度的外积之和给出，并经过噪声方差白化处理。\n\n模型定义。考虑一个具有恒定配体输入的三态受体-激酶-报告分子信号级联。令 $x(t) = [x_{1}(t), x_{2}(t), x_{3}(t)]^{\\top}$ 分别表示配体结合的受体分数、活化的激酶分数和磷酸化的报告分子分数。令受体、激酶和报告分子的总丰度为常数 $R_{\\mathrm{tot}}$、$K_{\\mathrm{tot}}$ 和 $P_{\\mathrm{tot}}$。配体浓度是恒定的阶跃输入 $L(t) = L_{0}$。动力学模型为\n$$\n\\begin{aligned}\n\\dot{x}_{1} = k_{\\mathrm{on}}\\,L_{0}\\,\\big(R_{\\mathrm{tot}} - x_{1}\\big) - k_{\\mathrm{off}}\\,x_{1}, \\\\\n\\dot{x}_{2} = k_{1}\\,x_{1}\\,\\big(K_{\\mathrm{tot}} - x_{2}\\big) - k_{2}\\,x_{2}, \\\\\n\\dot{x}_{3} = k_{3}\\,x_{2}\\,\\big(P_{\\mathrm{tot}} - x_{3}\\big) - k_{4}\\,x_{3}.\n\\end{aligned}\n$$\n参数向量为 $\\theta = [k_{\\mathrm{on}}, k_{\\mathrm{off}}, k_{1}, k_{2}, k_{3}, k_{4}]^{\\top}$。初始条件为 $x(0) = [0, 0, 0]^{\\top}$。测量输出为磷酸化的报告分子 $y(t) = x_{3}(t)$。\n\n在你的程序中为每个测试用例实现的任务：\n1. 推导并实现与上述模型相关的正向灵敏度方程 $S(t) = \\frac{\\partial x(t)}{\\partial \\theta}$。使用经典结论，$S$ 满足形式为 $\\dot{S}(t) = A(t)\\,S(t) + B(t)$ 的线性时变矩阵常微分方程，其中 $S(0) = 0$，$A(t) = \\frac{\\partial f}{\\partial x}(x(t), \\theta, t)$ 和 $B(t) = \\frac{\\partial f}{\\partial \\theta}(x(t), \\theta, t)$。并且 $y(t) = C\\,x(t)$，其中 $C = [0,0,1]$，因此 $\\frac{\\partial y}{\\partial \\theta}(t) = C\\,S(t)$。\n2. 对于给定的候选测量时间点集合 $\\{t_i\\}$，计算这些时间点的局部输出灵敏度 $\\frac{\\partial y}{\\partial \\theta}(t_i)$。\n3. 参数优先级排序：对于指定的参数子集 $\\mathcal{J} \\subset \\{0,1,2,3,4,5\\}$，为每个 $j \\in \\mathcal{J}$ 计算一个由以下公式定义的白化无量纲得分：\n$$\n\\mathrm{score}_{j} = \\left( \\sum_{i=1}^{N} \\frac{\\big(\\theta_{j}\\,\\frac{\\partial y}{\\partial \\theta_{j}}(t_{i})\\big)^{2}}{\\sigma^{2}} \\right)^{1/2}.\n$$\n报告得分最高的全局索引 $j^{\\star} \\in \\mathcal{J}$（若得分相同，则取最小的索引）。\n4. 通过 D-最优设计进行时间点选择：对于给定的整数 $K \\ge 1$，从候选集合中选择 $K$ 个不同的时间索引，以最大化所选时间上关于参数子集 $\\mathcal{J}$ 的费雪信息矩阵的行列式：\n$$\n\\mathcal{F} = \\sum_{i \\in \\mathcal{I}} \\frac{1}{\\sigma^{2}}\\,g(t_{i})\\,g(t_{i})^{\\top},\n$$\n其中 $g(t_{i}) \\in \\mathbb{R}^{|\\mathcal{J}|}$ 是在 $t_i$ 处限制于 $\\mathcal{J}$ 的输出灵敏度向量，而 $\\mathcal{I}$ 是所选的索引集，满足 $|\\mathcal{I}| = K$。返回最大化行列式的索引集中字典序最靠前的一个（以 $10^{-12}$ 的绝对容差进行行列式的数值比较）。如果 $K = 1$ 且 $|\\mathcal{J}| > 1$，行列式为零，这是可接受的。如果 $K = 1$ 且 $|\\mathcal{J}| = 1$，行列式等于标量费雪信息。\n\n单位：此问题中的所有量均为无量纲，不涉及角度单位。\n\n数值要求：\n- 使用数值稳定的方法对 $x(t)$ 和 $S(t)$ 的增广系统进行积分，并采用足够严格的容差以确保可复现性。\n- 在输出中对所有参数和时间点索引使用从零开始的索引。\n\n测试套件。你的程序必须运行以下三个测试用例，计算所需的量，并按规定汇总结果。对于每个用例，$R_{\\mathrm{tot}} = 1.0$，$K_{\\mathrm{tot}} = 1.0$，$P_{\\mathrm{tot}} = 1.0$。\n\n- 测试用例 1 (一般信息丰富区间):\n  - 参数 $\\theta = [1.0, 0.2, 0.5, 0.1, 0.7, 0.1]$。\n  - 配体水平 $L_{0} = 1.0$。\n  - 候选时间 $t_{i}$：从 $0$ 到 $40$ 的网格，步长为 $5$，即 $[0, 5, 10, 15, 20, 25, 30, 35, 40]$。\n  - 参数子集 $\\mathcal{J} = \\{0, 2, 4\\}$ (即 $k_{\\mathrm{on}}$、$k_{1}$、$k_{3}$)。\n  - 噪声标准差 $\\sigma = 0.05$。\n  - 通过 D-最优性准则选择 $K = 2$ 个时间点。\n\n- 测试用例 2 (晚期、信息贫乏区间):\n  - 参数 $\\theta = [1.0, 1.5, 0.5, 1.0, 0.7, 1.0]$。\n  - 配体水平 $L_{0} = 1.0$。\n  - 候选时间 $t_{i}$：$[50, 100, 150, 200]$。\n  - 参数子集 $\\mathcal{J} = \\{0, 2\\}$ (即 $k_{\\mathrm{on}}$、$k_{1}$)。\n  - 噪声标准差 $\\sigma = 0.05$。\n  - 通过 D-最优性准则选择 $K = 2$ 个时间点。\n\n- 测试用例 3 (单参数、单时间点选择):\n  - 参数 $\\theta = [1.0, 0.2, 0.5, 0.1, 0.7, 0.1]$。\n  - 配体水平 $L_{0} = 1.0$。\n  - 候选时间 $t_{i}$：从 $0$ 到 $20$ 的网格，步长为 $2$，即 $[0, 2, 4, 6, 8, 10, 12, 14, 16, 18, 20]$。\n  - 参数子集 $\\mathcal{J} = \\{4\\}$ (即只有 $k_{3}$)。\n  - 噪声标准差 $\\sigma = 0.10$。\n  - 通过 D-最优性准则选择 $K = 1$ 个时间点。\n\n最终输出格式。你的程序应生成单行输出，其中包含一个用方括号括起来的逗号分隔列表形式的结果。每个测试用例的结果本身必须是一个包含四个项目的列表：\n- 优先级最高的参数索引 $j^{\\star}$（一个整数，从零开始，在全局索引集 $\\{0,1,2,3,4,5\\}$ 中）。\n- 第一个选定的时间索引（一个整数，从零开始，在该测试用例的候选时间数组内）。\n- 第二个选定的时间索引（一个整数，从零开始，在该测试用例的候选时间数组内）；如果 $K=1$，则将其设置为 $-1$。\n- 所选集合的 D-最优行列式值（一个浮点数）。\n\n因此，程序必须以以下格式精确打印单行：\n[[j1,t11,t12,det1],[j2,t21,t22,det2],[j3,t31,t32,det3]]", "solution": "这个问题是计算系统生物学中一个有效且适定的练习，专门通过正向灵敏度分析解决参数可识别性和最优实验设计问题。它在科学上基于化学动力学和信息论（费雪信息）的原理。该模型虽然经过简化，但代表了一个典型的信号级联，而所需的任务——推导和积分灵敏度方程、计算参数得分以及执行 D-最优实验设计——是该领域中标准且计算上可行的方法。每个测试用例的所有必要数据和约束都已提供，且没有内部矛盾。\n\n解题过程如下：\n首先，我们推导局部正向灵敏度的控制方程。其次，我们构建一个增广常微分方程（ODE）系统，该系统将原始模型状态与其灵敏度结合起来。第三，我们对该系统进行数值积分，以获得指定时间点的状态和灵敏度轨迹。第四，利用这些灵敏度，我们基于无量纲灵敏度得分进行参数优先级排序。最后，我们通过最大化费雪信息矩阵（FIM）的行列式来选择最优测量时间点，这是一种称为 D-最优设计的准则。\n\n**正向灵敏度方程的推导**\n动力学系统由 $\\dot{x}(t) = f(x(t), \\theta)$ 给出，其状态向量为 $x(t) = [x_{1}(t), x_{2}(t), x_{3}(t)]^{\\top}$，参数向量为 $\\theta = [k_{\\mathrm{on}}, k_{\\mathrm{off}}, k_{1}, k_{2}, k_{3}, k_{4}]^{\\top}$。向量场 $f$ 为：\n$$\nf(x, \\theta) = \\begin{pmatrix}\n\\theta_0 L_0 (R_{\\text{tot}} - x_1) - \\theta_1 x_1 \\\\\n\\theta_2 x_1 (K_{\\text{tot}} - x_2) - \\theta_3 x_2 \\\\\n\\theta_4 x_2 (P_{\\text{tot}} - x_3) - \\theta_5 x_3\n\\end{pmatrix}\n$$\n灵敏度矩阵 $S(t) = \\frac{\\partial x(t)}{\\partial \\theta} \\in \\mathbb{R}^{3 \\times 6}$ 根据矩阵 ODE $\\dot{S}(t) = A(t)S(t) + B(t)$ 演化，初始条件为 $S(0) = 0$。矩阵 $A(t) = \\frac{\\partial f}{\\partial x}$（雅可比矩阵）和 $B(t) = \\frac{\\partial f}{\\partial \\theta}$ 是状态 $x(t)$ 和参数 $\\theta$ 的函数。\n\n雅可比矩阵 $A(t)$ 计算如下：\n$$\nA(t) = \\frac{\\partial f}{\\partial x} = \\begin{pmatrix}\n-\\theta_0 L_0 - \\theta_1 & 0 & 0 \\\\\n\\theta_2(K_{\\text{tot}} - x_2(t)) & -\\theta_2 x_1(t) - \\theta_3 & 0 \\\\\n0 & \\theta_4(P_{\\text{tot}} - x_3(t)) & -\\theta_4 x_2(t) - \\theta_5\n\\end{pmatrix}\n$$\n参数梯度矩阵 $B(t)$ 是一个 $3 \\times 6$ 的矩阵，计算如下：\n$$\nB(t) = \\frac{\\partial f}{\\partial \\theta} = \\begin{pmatrix}\nL_0(R_{\\text{tot}} - x_1) & -x_1 & 0 & 0 & 0 & 0 \\\\\n0 & 0 & x_1(K_{\\text{tot}} - x_2) & -x_2 & 0 & 0 \\\\\n0 & 0 & 0 & 0 & x_2(P_{\\text{tot}} - x_3) & -x_3\n\\end{pmatrix}\n$$\n为简洁起见，此处的状态依赖项 $x_i(t)$ 省略了参数。\n\n**数值实现**\n为了同时求解 $x(t)$ 和 $S(t)$，我们构建一个增广状态向量 $z(t) = [x(t)^{\\top}, \\mathrm{vec}(S(t))^{\\top}]^{\\top} \\in \\mathbb{R}^{21}$。这个增广系统 $\\dot{z}(t)$ 的动力学由原始状态方程和灵敏度方程定义。然后，从初始条件 $z(0) = 0$ 开始，使用高保真积分方案（`scipy.integrate.solve_ivp`，具有严格的容差 $rtol=10^{-8}$, $atol=10^{-10}$）对这个包含 21 个 ODE 的系统进行数值求解。解在指定的候选时间点 $\\{t_i\\}$ 处进行求值。输出为 $y(t) = x_{3}(t)$，因此关于参数 $\\theta_j$ 的输出灵敏度由 $\\frac{\\partial y}{\\partial \\theta_j}(t) = S_{3j}(t)$ 给出（对状态 $x_3$ 及其对应的灵敏度行使用从 1 开始的索引）。\n\n**参数优先级排序**\n对于指定子集 $\\mathcal{J}$ 中的每个参数 $\\theta_j$，计算一个无量纲得分。这个得分量化了在所有候选时间点上，该参数对测量输出 $y(t)$ 的总体影响，并根据参数的标称值和测量噪声进行缩放。公式为：\n$$\n\\mathrm{score}_{j} = \\left( \\sum_{i=1}^{N} \\frac{\\big(\\theta_{j}\\,\\frac{\\partial y}{\\partial \\theta_{j}}(t_{i})\\big)^{2}}{\\sigma^{2}} \\right)^{1/2}\n$$\n产生最高分的参数 $j^{\\star} \\in \\mathcal{J}$ 被确定为最具影响力的参数，因此在精确估计中具有优先权。若得分相同，则选择最小的参数索引。\n\n**D-最优时间点选择**\n目标是选择一个包含 $K$ 个测量时间的子集，该子集对于参数子集 $\\mathcal{J}$ 具有最大的信息量。我们使用 D-最优性准则，该准则旨在最大化费雪信息矩阵（FIM）$\\mathcal{F}$ 的行列式。更大的行列式对应于更小体积的参数置信椭球，这意味着更精确的参数估计。对于一个时间索引集 $\\mathcal{I}$（$|\\mathcal{I}|=K$），FIM 为：\n$$\n\\mathcal{F} = \\sum_{i \\in \\mathcal{I}} \\frac{1}{\\sigma^{2}}\\,g(t_{i})\\,g(t_{i})^{\\top}\n$$\n此处，$g(t_i) \\in \\mathbb{R}^{|\\mathcal{J}|}$ 是在时间 $t_i$ 评估的、仅限于 $\\mathcal{J}$ 中参数的输出灵敏度向量。我们对候选集中的所有可能的 $K$ 个时间点的组合进行组合搜索。对于每种组合，我们计算 $\\det(\\mathcal{F})$ 并找出产生最大行列式的时间索引集。在所选时间点数 $K$ 小于感兴趣的参数数量 $|\\mathcal{J}|$ 的情况下，FIM 将是奇异的，其行列式为零。在这种情况下，选择由平局决胜规则确定，该规则指定选择达到最大行列式值的字典序最靠前的索引集。", "answer": "```python\nimport numpy as np\nfrom scipy.integrate import solve_ivp\nfrom itertools import combinations\n\ndef solve():\n    \"\"\"\n    Main solver function that processes all test cases and prints the final result.\n    \"\"\"\n    R_TOT, K_TOT, P_TOT = 1.0, 1.0, 1.0\n\n    def augmented_ode(t, z, theta, L0):\n        \"\"\"\n        Defines the augmented ODE system for states (x) and sensitivities (S).\n        z: flattened vector [x1, x2, x3, S11, S12, ..., S36]\n        theta: parameter vector [k_on, k_off, k1, k2, k3, k4]\n        \"\"\"\n        x = z[:3]\n        S = z[3:].reshape((3, 6))\n\n        k_on, k_off, k1, k2, k3, k4 = theta\n\n        # State equations (dx/dt)\n        dx1_dt = k_on * L0 * (R_TOT - x[0]) - k_off * x[0]\n        dx2_dt = k1 * x[0] * (K_TOT - x[1]) - k2 * x[1]\n        dx3_dt = k3 * x[1] * (P_TOT - x[2]) - k4 * x[2]\n        dx_dt = np.array([dx1_dt, dx2_dt, dx3_dt])\n\n        # Jacobian matrix A = df/dx\n        A = np.zeros((3, 3))\n        A[0, 0] = -k_on * L0 - k_off\n        A[1, 0] = k1 * (K_TOT - x[1])\n        A[1, 1] = -k1 * x[0] - k2\n        A[2, 1] = k3 * (P_TOT - x[2])\n        A[2, 2] = -k3 * x[1] - k4\n        \n        # Gradient matrix B = df/d_theta\n        B = np.zeros((3, 6))\n        B[0, 0] = L0 * (R_TOT - x[0])\n        B[0, 1] = -x[0]\n        B[1, 2] = x[0] * (K_TOT - x[1])\n        B[1, 3] = -x[1]\n        B[2, 4] = x[1] * (P_TOT - x[2])\n        B[2, 5] = -x[2]\n\n        # Sensitivity equations dS/dt = A*S + B\n        dS_dt = A @ S + B\n\n        dz_dt = np.concatenate((dx_dt, dS_dt.flatten()))\n        return dz_dt\n\n    def solve_for_case(case_params):\n        \"\"\"\n        Processes a single test case.\n        \"\"\"\n        theta, L0, candidate_times, param_subset_J, sigma, K = case_params\n        \n        # 1. Integrate the augmented ODE system\n        ode_func = lambda t, z: augmented_ode(t, z, np.array(theta), L0)\n        z0 = np.zeros(3 + 3 * 6)\n        t_span = (0, max(candidate_times) if candidate_times else 0)\n        \n        if t_span[1] == 0:\n            if candidate_times:\n                 sol_y = np.tile(z0.reshape(-1, 1), (1, len(candidate_times)))\n            else:\n                 sol_y = np.array([[] for _ in range(len(z0))])\n        else:\n            sol = solve_ivp(\n                ode_func, t_span, z0, t_eval=candidate_times,\n                method='RK45', rtol=1e-8, atol=1e-10\n            )\n            sol_y = sol.y\n\n        # Output sensitivity dy/d_theta = dx3/d_theta is the 3rd row of S (index 2)\n        num_times = len(candidate_times)\n        output_sens = np.zeros((6, num_times))\n        for j in range(6):\n            output_sens[j, :] = sol_y[3 + 2 * 6 + j, :]\n\n        # 2. Parameter prioritization\n        scores = {}\n        for j in param_subset_J:\n            sens_j_values = output_sens[j, :]\n            theta_j = theta[j]\n            sum_sq = np.sum(((theta_j * sens_j_values) / sigma)**2)\n            scores[j] = np.sqrt(sum_sq)\n\n        j_star = -1\n        max_score = -1.0\n        for j in sorted(list(param_subset_J)):\n            if scores[j] > max_score:\n                max_score = scores[j]\n                j_star = j\n            \n        # 3. Time-point selection by D-optimality\n        num_candidates = len(candidate_times)\n        candidate_indices = range(num_candidates)\n        \n        best_indices = None\n        max_det = -1.0\n        \n        g_all_times = output_sens[list(sorted(list(param_subset_J))), :]\n        \n        for current_indices in combinations(candidate_indices, K):\n            fim_dim = len(param_subset_J)\n            fim = np.zeros((fim_dim, fim_dim))\n            \n            for i_time in current_indices:\n                g_ti = g_all_times[:, i_time]\n                fim += np.outer(g_ti, g_ti)\n            \n            fim /= (sigma**2)\n            current_det = np.linalg.det(fim)\n            \n            if current_det > max_det + 1e-12:\n                max_det = current_det\n                best_indices = current_indices\n        \n        if best_indices is None:\n            best_indices = next(combinations(candidate_indices, K))\n            max_det = 0.0\n\n        t_indices_out = list(best_indices)\n        if K == 1:\n            t_indices_out.append(-1)\n\n        return [j_star, t_indices_out[0], t_indices_out[1], max_det]\n\n    test_cases = [\n        # Test case 1\n        ([1.0, 0.2, 0.5, 0.1, 0.7, 0.1], 1.0, list(np.arange(0, 40.1, 5.0)),\n         {0, 2, 4}, 0.05, 2),\n        # Test case 2\n        ([1.0, 1.5, 0.5, 1.0, 0.7, 1.0], 1.0, [50., 100., 150., 200.],\n         {0, 2}, 0.05, 2),\n        # Test case 3\n        ([1.0, 0.2, 0.5, 0.1, 0.7, 0.1], 1.0, list(np.arange(0, 20.1, 2.0)),\n         {4}, 0.10, 1),\n    ]\n\n    results = []\n    for case in test_cases:\n        results.append(solve_for_case(case))\n        \n    print(f\"[{','.join(f'[{r[0]},{r[1]},{r[2]},{r[3]}]' for r in results)}]\")\n\nsolve()\n```", "id": "3327223"}, {"introduction": "在贝叶斯框架下，模型验证超越了对点估计的评估，转向对整个后验分布和预测分布的检验。本练习将带你进入现代贝叶斯工作流程，实践两种先进的验证技术：后验预测检验 ($PPC$) 和基于模拟的校准 ($SBC$)。你将学习如何使用像瓦瑟斯坦距离 ($Wasserstein distance$) 这样的度量进行 $PPC$ 分析，以判断模型是否能生成与真实数据相似的数据分布；同时，通过分析秩统计量的均匀性进行 $SBC$，以确保你的整个贝叶斯推断过程是统计上可靠的。[@problem_id:3327305]", "problem": "您的任务是为一个随机基因调控网络实施后验预测检验和基于模拟的校准。该网络被建模为信使核糖核酸 (mRNA) 计数的线性生灭过程。该模型假设单个基因以恒定的转录率 $k$ 产生 mRNA，并以速率 $\\gamma$ 降解，初始状态为 $y(0) = 0$。对于在固定时间 $t$ 独立观测的细胞，其生成模型意味着 mRNA 计数 $Y(t)$ 服从一个离散分布。\n\n基本原理和定义：\n- 具有恒定移入率 $k$ 和线性死亡率 $\\gamma$ 的线性生灭过程是化学动力学中的一个经典随机过程。$Y(t)$ 的均值 $\\mu(t)$ 满足常微分方程 $d\\mu(t)/dt = k - \\gamma \\mu(t)$，初始条件为 $\\mu(0) = 0$，其解为 $\\mu(t) = \\frac{k}{\\gamma}\\left(1 - e^{-\\gamma t}\\right)$。\n- 泊松叠加与稀疏性质意味着，具有线性衰减的恒定速率出生过程的综合效应导致计数分布为均值为 $\\mu(t)$ 的泊松分布。因此，在该模型下，对于每个固定的 $t$，$Y(t) \\sim \\operatorname{Poisson}(\\mu(t))$。\n- 对于在时间点 $\\{t_i\\}$ 进行的独立观测 $\\{y_i\\}_{i=1}^n$，且 $\\gamma$ 已知， $k$ 的似然函数可分解为 $y_i \\sim \\operatorname{Poisson}(c_i k)$，其中 $c_i = \\frac{1 - e^{-\\gamma t_i}}{\\gamma}$。\n- 在 $k$ 上使用 Gamma 先验，记作 $k \\sim \\operatorname{Gamma}(\\alpha_0, \\beta_0)$（形状-速率参数化），其后验分布为 $k \\mid \\{y_i,t_i\\} \\sim \\operatorname{Gamma}(\\alpha_0 + \\sum_i y_i, \\beta_0 + \\sum_i c_i)$。\n\n您的任务：\n1) 使用第一瓦瑟斯坦距离进行跨时间的后验预测检验。对于下面的每个测试用例，使用给定的真实参数从模型中在每个时间点 $t$ 采样指定数量的细胞，以生成观测数据集。在 $k$ 上使用 Gamma 先验，并使用模型 $y_i \\sim \\operatorname{Poisson}(c_i k)$（其中 $c_i = \\frac{1 - e^{-\\gamma_{\\text{assumed}} t_i}}{\\gamma_{\\text{assumed}}}$），通过汇集所有时间点的观测数据来计算 $k$ 的后验分布。令 $\\hat{k}$ 为后验均值 $\\hat{k} = \\frac{\\alpha_{\\text{post}}}{\\beta_{\\text{post}}}$。将在时间 $t$ 的模型预测分布定义为 $p_{\\text{pred}}(y \\mid t, \\hat{k}) = \\operatorname{Poisson}\\left(\\hat{k}\\,\\frac{1 - e^{-\\gamma_{\\text{assumed}} t}}{\\gamma_{\\text{assumed}}}\\right)$。令 $p_{\\text{obs}}(y \\mid t)$ 为在时间 $t$ 的观测样本的经验分布。对于测试用例中的每个 $t$，通过从 $p_{\\text{pred}}(\\cdot \\mid t, \\hat{k})$ 中抽取一个与观测样本大小相同的合成样本，并使用两个样本之间的标准一维瓦瑟斯坦距离，来近似一维第一瓦瑟斯坦距离 $W\\!\\left(p_{\\text{pred}}(\\cdot \\mid \\hat{k}), p_{\\text{obs}}\\right)$。将测试用例中所有时间点的这些距离的平均值作为该用例的单个浮点数报告。\n\n2) 通过秩统计量进行基于模拟的校准 (SBC)。对于每个测试用例，在转录率上定义一个先验 $k \\sim \\operatorname{Gamma}(\\alpha_0,\\beta_0)$。重复以下步骤 $R$ 次：从先验中抽样 $k^{(r)}$，使用真实的降解率 $\\gamma_{\\text{true}}$ 在指定时间点生成一个数据集，在假定的 $\\gamma_{\\text{assumed}}$ 和相同的先验下计算后验 $k \\mid \\text{data}$，抽取 $M$ 个独立的后验样本 $\\{\\tilde{k}_m^{(r)}\\}_{m=1}^M$，并计算秩统计量 $r^{(r)} = \\#\\{m : \\tilde{k}_m^{(r)}  k^{(r)}\\}$，对于连续的后验分布，该值位于 $\\{0,1,\\dots,M\\}$ 中。将 $\\{r^{(r)}\\}_{r=1}^R$ 聚合到一个覆盖 $\\{0,\\dots,M\\}$ 的直方图中，并与离散均匀分布进行卡方拟合优度检验。令 $p_{\\text{SBC}}$ 为所得的 p 值。对于测试用例中给定的显著性水平 $\\alpha$，定义一个校准通过指示符：如果 $p_{\\text{SBC}} \\ge \\alpha$，则 $\\text{pass} = \\text{True}$，否则为 $\\text{False}$。为每个用例报告此布尔值。\n\n计算和统计细节：\n- 所有随机数生成必须通过在程序开始时设置固定种子来保证可复现性。\n- 对 Gamma 分布使用形状-速率参数化。如果您使用的库是以形状-尺度参数化 Gamma 分布，则必须使用 $\\text{scale} = 1/\\text{rate}$ 进行转换。\n- 一维的第一瓦瑟斯坦距离可以使用分位数函数积分的标准定义来计算；在代码中，您可以使用任何对一维样本数值正确的实现，该实现返回一个非负实数值。\n\n测试套件：\n实现您的程序以运行以下三个测试用例。对于每个用例，使用指定的 $k_\\star$ 和 $\\gamma_{\\text{true}}$ 为后验预测检验生成一个观测数据集，并使用相同的数据计算后验和 $\\hat{k}$。\n\n- 用例 1 (设定良好，信息丰富)：\n  - $\\gamma_{\\text{true}} = 1.1$\n  - $\\gamma_{\\text{assumed}} = 1.1$\n  - 时间 $t \\in \\{0.2, 0.6, 1.0, 2.0\\}$\n  - 每个时间点的细胞数 $N = 200$\n  - $k$ 的先验：$k \\sim \\operatorname{Gamma}(\\alpha_0 = 2.0, \\beta_0 = 0.3)$\n  - 用于后验预测检验的数据生成转录率：$k_\\star = 7.0$\n  - SBC 设置：$R = 840$ 次重复，每次重复 $M = 20$ 个后验样本，显著性水平 $\\alpha = 0.01$\n\n- 用例 2 (错误的降解率设定)：\n  - $\\gamma_{\\text{true}} = 1.1$\n  - $\\gamma_{\\text{assumed}} = 2.2$\n  - 时间 $t \\in \\{0.2, 0.6, 1.0, 2.0\\}$\n  - 每个时间点的细胞数 $N = 200$\n  - $k$ 的先验：$k \\sim \\operatorname{Gamma}(\\alpha_0 = 2.0, \\beta_0 = 0.3)$\n  - 用于后验预测检验的数据生成转录率：$k_\\star = 7.0$\n  - SBC 设置：$R = 840$，$M = 20$，$\\alpha = 0.01$\n\n- 用例 3 (边缘情况：小样本和早期时间点)：\n  - $\\gamma_{\\text{true}} = 1.0$\n  - $\\gamma_{\\text{assumed}} = 1.0$\n  - 时间 $t \\in \\{0.05, 0.1, 0.2, 0.4\\}$\n  - 每个时间点的细胞数 $N = 20$\n  - $k$ 的先验：$k \\sim \\operatorname{Gamma}(\\alpha_0 = 1.5, \\beta_0 = 0.5)$\n  - 用于后验预测检验的数据生成转录率：$k_\\star = 5.0$\n  - SBC 设置：$R = 420$，$M = 20$，$\\alpha = 0.01$\n\n要求的最终输出：\n- 您的程序必须生成一行包含一个 Python 列表的内容，其中按顺序为每个用例附加两个条目：首先是跨时间的平均瓦瑟斯坦距离（浮点数）；其次是 SBC 校准通过指示符（布尔值）。\n- 因此，最终输出必须是 `\"[w1,pass1,w2,pass2,w3,pass3]\"` 这种确切格式的单行文本，不得包含任何额外文字，其中 $w1$、$w2$ 和 $w3$ 是浮点数，$pass1$、$pass2$ 和 $pass3$ 是布尔值。", "solution": "用户提供了一个计算系统生物学领域中有效、适定且有科学依据的问题。任务是为一个随机基因表达模型实施并应用两种标准的模型验证技术——后验预测检验 (PPC) 和基于模拟的校准 (SBC)。\n\n该模型描述了单个基因在时间 $t$ 的信使核糖核酸 (mRNA) 分子数 $Y(t)$。其动态被建模为一个线性生灭过程，具有恒定的转录（出生）率 $k$ 和一阶降解（死亡）率 $\\gamma$。假设初始状态为零个 mRNA 分子，即 $Y(0)=0$，则在任何时间 $t0$ 的计数 $Y(t)$ 服从泊松分布，$Y(t) \\sim \\operatorname{Poisson}(\\mu(t))$。该分布的均值 $\\mu(t)$ 由平均分子数的常微分方程的解给出，即 $\\mu(t) = \\frac{k}{\\gamma}\\left(1 - e^{-\\gamma t}\\right)$。\n\n对于转录率 $k$ 的贝叶斯推断，使用了共轭先验。给定 $k$ 的 Gamma 先验 $k \\sim \\operatorname{Gamma}(\\alpha_0, \\beta_0)$，其中 $\\alpha_0$ 是形状参数，$\\beta_0$ 是速率参数，以及在相应时间 $\\{t_i\\}_{i=1}^n$ 的一组独立观测值 $\\{y_i\\}_{i=1}^n$，$k$ 的后验分布也是一个 Gamma 分布。单个观测值 $y_i$ 的似然是 $\\operatorname{Poisson}(k \\cdot c_i)$，其中 $c_i = \\frac{1 - e^{-\\gamma t_i}}{\\gamma}$ 是一个与时间相关的常数（假设 $\\gamma$ 已知）。由于 Gamma-泊松共轭模型的性质，后验分布由下式给出：\n$$\nk \\mid \\{y_i,t_i\\} \\sim \\operatorname{Gamma}\\left(\\alpha_0 + \\sum_{i=1}^n y_i, \\beta_0 + \\sum_{i=1}^n c_i\\right)\n$$\n我们将后验参数表示为 $\\alpha_{\\text{post}} = \\alpha_0 + \\sum y_i$ 和 $\\beta_{\\text{post}} = \\beta_0 + \\sum c_i$。\n\n该实现将包含两个主要部分，对应于指定的两个任务。\n\n**任务 1：后验预测检验 (PPC)**\n\nPPC 的目标是通过将观测数据与从拟合模型中模拟的数据进行比较，来评估模型的拟合优度。对于每个测试用例，流程如下：\n1. **生成“观测”数据集**：对于测试用例中每个指定的时间 $t$，我们使用真实参数 $k_\\star$ 和 $\\gamma_{\\text{true}}$ 计算其均值，并从泊松分布中生成 $N$ 个样本。这模拟了从 $N$ 个独立细胞中收集数据的过程。均值为 $\\mu_{\\text{true}}(t) = \\frac{k_\\star}{\\gamma_{\\text{true}}}\\left(1 - e^{-\\gamma_{\\text{true}} t}\\right)$。\n2. **执行贝叶斯推断**：使用步骤 1 中生成的整个数据集（汇集所有时间点的数据），我们计算 $k$ 的后验分布。此步骤使用指定的先验 $\\operatorname{Gamma}(\\alpha_0, \\beta_0)$ 和假定的降解率 $\\gamma_{\\text{assumed}}$。后验参数为 $\\alpha_{\\text{post}} = \\alpha_0 + \\sum y_i$ 和 $\\beta_{\\text{post}} = \\beta_0 + \\sum_i N \\cdot \\frac{1 - e^{-\\gamma_{\\text{assumed}} t_i}}{\\gamma_{\\text{assumed}}}$。\n3. **估计转录率**：转录率的点估计值 $\\hat{k}$ 取为后验分布的均值，即 $\\hat{k} = \\alpha_{\\text{post}} / \\beta_{\\text{post}}$。\n4. **生成“预测”数据集**：对于每个时间 $t$，我们使用估计的参数 $\\hat{k}$ 和假定的降解率 $\\gamma_{\\text{assumed}}$，从模型中生成一个大小为 $N$ 的新合成数据集。该分布为 $p_{\\text{pred}}(y \\mid t, \\hat{k}) = \\operatorname{Poisson}\\left(\\hat{k} \\frac{1 - e^{-\\gamma_{\\text{assumed}} t}}{\\gamma_{\\text{assumed}}}\\right)$。\n5. **计算差异**：在每个时间 $t$，观测数据和预测数据之间的差异使用第一瓦瑟斯坦距离 $W_1$ 进行量化。对于由样本 $u = \\{u_j\\}_{j=1}^N$ 和 $v = \\{v_j\\}_{j=1}^N$ 表示的两个一维经验分布，距离计算为 $W_1 = \\frac{1}{N} \\sum_{j=1}^N |u_{(j)} - v_{(j)}|$，其中 $u_{(j)}$ 和 $v_{(j)}$ 是第 $j$ 个顺序统计量（即排序后的样本）。\n6. **平均差异**：此任务的最终结果是所有时间点上计算的瓦瑟斯坦距离的平均值。\n\n**任务 2：基于模拟的校准 (SBC)**\n\nSBC 是一种诊断贝叶斯推断过程中潜在校准错误的方法。它检查后验分布在平均意义上是否正确地表示了参数的不确定性。该过程需要一个模拟循环：\n1. **定义先验和模拟参数**：我们使用先验 $k \\sim \\operatorname{Gamma}(\\alpha_0,\\beta_0)$ 和模拟设置（$R$ 次重复，$M$ 个后验样本）。\n2. **执行 $R$ 次重复**：对于每次重复 $r=1, \\dots, R$：\n    a. 从先验分布中抽取一个“真实”参数值 $k^{(r)}$：$k^{(r)} \\sim \\operatorname{Gamma}(\\alpha_0, \\beta_0)$。\n    b. 使用这个 $k^{(r)}$ 和真实的降解率 $\\gamma_{\\text{true}}$ 生成一个合成数据集。\n    c. 对该合成数据集使用相同的先验和假定的降解率 $\\gamma_{\\text{assumed}}$ 进行贝叶斯推断，以获得后验分布 $\\operatorname{Gamma}(\\alpha_{\\text{post}}^{(r)}, \\beta_{\\text{post}}^{(r)})$。\n    d. 从该后验分布中抽取 $M$ 个样本 $\\{\\tilde{k}_m^{(r)}\\}_{m=1}^M$。\n    e. 计算秩统计量：$r^{(r)} = \\sum_{m=1}^M \\mathbb{I}(\\tilde{k}_m^{(r)}  k^{(r)})$，其中 $\\mathbb{I}(\\cdot)$ 是指示函数。秩计算了有多少个后验样本小于用于生成数据的真实值。\n3. **分析秩分布**：一个校准良好的推断过程应产生在整数 $\\{0, 1, \\dots, M\\}$ 上均匀分布的秩。我们收集所有 $R$ 个秩，并形成一个有 $M+1$ 个箱的直方图。\n4. **统计检验**：执行卡方 ($\\chi^2$) 拟合优度检验，以检查观测到的秩分布是否与离散均匀分布一致。每个秩的期望频率为 $E = R / (M+1)$。\n5. **校准判定**：将来自 $\\chi^2$ 检验的 p 值 $p_{\\text{SBC}}$ 与预定义的显著性水平 $\\alpha$ 进行比较。如果 $p_{\\text{SBC}} \\ge \\alpha$，则认为校准“通过”，这表示没有显著偏离均匀性。“失败” ($p_{\\text{SBC}}  \\alpha$) 表明推断过程存在校准错误，这在模型设定错误（例如 $\\gamma_{\\text{assumed}} \\ne \\gamma_{\\text{true}}$）时是预期的结果。\n\n代码将为提供的三个测试用例中的每一个实现这两个过程，通过使用固定的随机种子来确保可复现性。", "answer": "```python\nimport numpy as np\nfrom scipy.stats import chisquare\n\ndef run_posterior_predictive_check(case, rng):\n    \"\"\"\n    Performs the posterior predictive check and computes the average Wasserstein distance.\n    \"\"\"\n    # Unpack case parameters\n    gamma_true = case['gamma_true']\n    gamma_assumed = case['gamma_assumed']\n    times = np.array(case['times'])\n    N = case['N']\n    prior_alpha = case['prior_alpha']\n    prior_beta = case['prior_beta']\n    k_star = case['k_star']\n\n    # 1. Generate an \"observed\" dataset using true parameters\n    observed_data_by_time = {}\n    all_y_obs = []\n    \n    for t in times:\n        mu_true = (k_star / gamma_true) * (1 - np.exp(-gamma_true * t))\n        y_obs_at_t = rng.poisson(mu_true, size=N)\n        observed_data_by_time[t] = y_obs_at_t\n        all_y_obs.extend(y_obs_at_t)\n\n    # 2. Compute posterior using the generated data and assumed gamma\n    sum_y = np.sum(all_y_obs)\n    \n    # Calculate sum c_i for posterior beta\n    c_coeffs = (1 - np.exp(-gamma_assumed * times)) / gamma_assumed\n    sum_c = N * np.sum(c_coeffs)\n\n    alpha_post = prior_alpha + sum_y\n    beta_post = prior_beta + sum_c\n    \n    # 3. Estimate k as posterior mean\n    k_hat = alpha_post / beta_post\n    \n    # 4. Compute Wasserstein distances\n    wasserstein_distances = []\n    for i, t in enumerate(times):\n        # Generate predicted data\n        mu_pred = k_hat * c_coeffs[i]\n        \n        # Guard against non-positive means in edge cases\n        if mu_pred = 0:\n            y_pred = np.zeros(N, dtype=int)\n        else:\n            y_pred = rng.poisson(mu_pred, size=N)\n        \n        # Retrieve observed data for this time point\n        y_obs_at_t = observed_data_by_time[t]\n        \n        # Calculate 1D Wasserstein distance\n        y_obs_sorted = np.sort(y_obs_at_t)\n        y_pred_sorted = np.sort(y_pred)\n        w_dist = np.mean(np.abs(y_obs_sorted - y_pred_sorted))\n        wasserstein_distances.append(w_dist)\n        \n    return np.mean(wasserstein_distances)\n\ndef run_simulation_based_calibration(case, rng):\n    \"\"\"\n    Performs simulation-based calibration and returns the pass/fail indicator.\n    \"\"\"\n    # Unpack case parameters\n    gamma_true = case['gamma_true']\n    gamma_assumed = case['gamma_assumed']\n    times = np.array(case['times'])\n    N = case['N']\n    prior_alpha = case['prior_alpha']\n    prior_beta = case['prior_beta']\n    R = case['R']\n    M = case['M']\n    alpha_sig = case['alpha_sig']\n\n    ranks = np.zeros(R, dtype=int)\n    \n    # Pre-calculate sum of c_i coefficients, which is constant across replications\n    c_coeffs_assumed = (1 - np.exp(-gamma_assumed * times)) / gamma_assumed\n    sum_c_for_posterior = N * np.sum(c_coeffs_assumed)\n\n    for r in range(R):\n        # 1. Sample k_true from the prior\n        k_true_r = rng.gamma(shape=prior_alpha, scale=1.0/prior_beta)\n        \n        # 2. Generate synthetic data using k_true_r and gamma_true\n        sum_y = 0\n        mean_rates_true = (k_true_r / gamma_true) * (1 - np.exp(-gamma_true * times))\n        for mu_true in mean_rates_true:\n            # Poisson mean must be non-negative\n            if mu_true = 0: continue\n            y_obs_t = rng.poisson(mu_true, size=N)\n            sum_y += np.sum(y_obs_t)\n            \n        # 3. Compute posterior for k\n        alpha_post = prior_alpha + sum_y\n        beta_post = prior_beta + sum_c_for_posterior\n        \n        # 4. Draw samples from the posterior\n        k_posterior_samples = rng.gamma(shape=alpha_post, scale=1.0/beta_post, size=M)\n        \n        # 5. Compute the rank statistic\n        rank = np.sum(k_posterior_samples  k_true_r)\n        ranks[r] = rank\n        \n    # 6. Perform Chi-squared goodness-of-fit test\n    # Bins are 0, 1, ..., M, for a total of M+1 bins\n    observed_counts = np.bincount(ranks, minlength=M + 1)\n    \n    # Expected count per bin under the uniform hypothesis\n    expected_count = R / (M + 1)\n    \n    _, p_value = chisquare(f_obs=observed_counts, f_exp=expected_count)\n    \n    # 7. Return calibration pass indicator\n    return p_value >= alpha_sig\n\ndef solve():\n    # Set a fixed seed for reproducibility.\n    RNG = np.random.default_rng(seed=12345)\n\n    test_cases = [\n        # Case 1: well-specified model\n        {\n            'gamma_true': 1.1, 'gamma_assumed': 1.1, \n            'times': [0.2, 0.6, 1.0, 2.0], 'N': 200,\n            'prior_alpha': 2.0, 'prior_beta': 0.3, \n            'k_star': 7.0, 'R': 840, 'M': 20, 'alpha_sig': 0.01\n        },\n        # Case 2: misspecified model (gamma is wrong)\n        {\n            'gamma_true': 1.1, 'gamma_assumed': 2.2, \n            'times': [0.2, 0.6, 1.0, 2.0], 'N': 200,\n            'prior_alpha': 2.0, 'prior_beta': 0.3, \n            'k_star': 7.0, 'R': 840, 'M': 20, 'alpha_sig': 0.01\n        },\n        # Case 3: edge case (small samples, early times)\n        {\n            'gamma_true': 1.0, 'gamma_assumed': 1.0, \n            'times': [0.05, 0.1, 0.2, 0.4], 'N': 20,\n            'prior_alpha': 1.5, 'prior_beta': 0.5, \n            'k_star': 5.0, 'R': 420, 'M': 20, 'alpha_sig': 0.01\n        },\n    ]\n\n    final_results = []\n    \n    for case in test_cases:\n        # Task 1: Posterior Predictive Checks\n        avg_w_dist = run_posterior_predictive_check(case, RNG)\n        \n        # Task 2: Simulation-Based Calibration\n        sbc_pass = run_simulation_based_calibration(case, RNG)\n\n        final_results.extend([avg_w_dist, sbc_pass])\n\n    # Format the boolean values to lowercase as per Python's str() behavior for json compatibility\n    formatted_results = [f\"{x:.10f}\" if isinstance(x, float) else str(x) for x in final_results]\n    print(f\"[{','.join(formatted_results)}]\")\n\nsolve()\n```", "id": "3327305"}]}